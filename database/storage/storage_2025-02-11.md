# arxiv-daily
 Automated deployment @ 2025-02-11 09:14:34 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-27**|**An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**|Shaheer Ahmad Khan et.al.|[2501.15969v1](http://arxiv.org/abs/2501.15969v1)|null|
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v2](http://arxiv.org/abs/2412.16086v2)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v2](http://arxiv.org/abs/2411.17645v2)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-13**|**Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**|Mercy Asiedu et.al.|[2409.09201v3](http://arxiv.org/abs/2409.09201v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v2](http://arxiv.org/abs/2406.06728v2)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|

#### Abstracts
##### **An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**
2501.15969v1 by Shaheer Ahmad Khan, Muhammad Usamah Shahid, Ahmad Abdullah, Ibrahim Hashmat, Muddassar Farooq

This study addresses a critical gap in the healthcare system by developing a
clinically meaningful, practical, and explainable disease surveillance system
for multiple chronic diseases, utilizing routine EHR data from multiple U.S.
practices integrated with CureMD's EMR/EHR system. Unlike traditional
systems--using AI models that rely on features from patients' labs--our
approach focuses on routinely available data, such as medical history, vitals,
diagnoses, and medications, to preemptively assess the risks of chronic
diseases in the next year. We trained three distinct models for each chronic
disease: prediction models that forecast the risk of a disease 3, 6, and 12
months before a potential diagnosis. We developed Random Forest models, which
were internally validated using F1 scores and AUROC as performance metrics and
further evaluated by a panel of expert physicians for clinical relevance based
on inferences grounded in medical knowledge. Additionally, we discuss our
implementation of integrating these models into a practical EMR system. Beyond
using Shapley attributes and surrogate models for explainability, we also
introduce a new rule-engineering framework to enhance the intrinsic
explainability of Random Forests.

摘要：本研究透過開發一個臨床有意義、實用且可解釋的多重慢性疾病疾病監測系統，來解決醫療保健系統中的重大缺口，利用整合 CureMD 的 EMR/EHR 系統，來自多個美國實務的例行 EHR 資料。與傳統系統不同的是，我們的做法著重在例行可得的資料，例如病歷、生命徵象、診斷和藥物，以預先評估未來一年慢性疾病的風險，而非仰賴病患實驗室特徵的 AI 模型。我們針對每種慢性疾病訓練了三個不同的模型：預測模型，用以預測在潛在診斷前 3、6 和 12 個月的疾病風險。我們開發了隨機森林模型，並使用 F1 分數和 AUROC 作為效能指標，進行內部驗證，並進一步由專家醫師小組根據植基於醫學知識的推論，評估其臨床相關性。此外，我們討論了將這些模型整合到實用 EMR 系統中的實作方式。除了使用 Shapley 屬性和代理模型來解釋外，我們還引進了一個新的規則工程架構，以增強隨機森林的內在可解釋性。

##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

摘要：深度神经网络越来越多地用于高风险医疗应用中，尽管它们在存在虚假相关性的情况下倾向于捷径学习，这在实践中可能产生致命的后果。检测和缓解捷径行为是一项艰巨的任务，通常需要领域专家的大量标记工作。为了缓解这个问题，我们引入了一个半自动框架，用于从数据和模型的角度识别虚假行为，方法是利用可解释人工智能 (XAI) 的见解。这允许检索虚假数据点并检测对关联预测规则进行编码的模型电路。此外，我们演示了如何使用这些捷径编码进行基于 XAI 的样本和像素级数据注释，为偏差缓解方法提供有价值的信息，以消除不需要的捷径行为。我们使用跨越两种方式的四个医学数据集展示了我们框架的适用性，这些数据集具有由数据伪像引起的受控和真实世界虚假相关性。我们成功地识别并减轻了 VGG16、ResNet50 和当代 Vision Transformer 模型中的这些偏差，最终提高了它们的鲁棒性和在真实世界医疗任务中的适用性。

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

摘要：自殺意念偵測對於預防自殺至關重要，而自殺是全球主要的死亡原因。許多人在社群媒體上表達自殺念頭，這提供了透過進階機器學習技術進行早期偵測的重要機會。透過整合卷積神經網路 (CNN) 和雙向長短期記憶 (BiLSTM) 的混合架構，並加入注意力機制，可以提升在社群媒體文字中辨識自殺意念的能力。為了加強模型預測的可解釋性，我們採用可解釋人工智慧 (XAI) 方法，特別著重於 SHapley 加法解釋 (SHAP)。一開始，模型成功達到 92.81% 的準確度。透過套用微調和早期停止技術，準確度提升至 94.29%。SHAP 分析揭露了影響模型預測的關鍵特徵，例如與心理健康困境相關的詞彙。這種透明度提升了模型的可信度，同時協助心理健康專業人員理解和信賴預測結果。這項工作突顯了提升偵測自殺傾向的準確度和可解釋性的潛力，為心理健康監控系統的進展做出寶貴的貢獻。它強調了將強大的機器學習方法與可解釋性相結合以開發可靠且有影響力的心理健康解決方案的重要性。

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, Léa Maître, Rémy Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

摘要：在流行病學中，傳統的統計方法，例如邏輯迴歸、線性迴歸和其他參數模型通常用於調查預測因子與健康結果之間的關聯。然而，非參數機器學習技術，例如深度神經網路 (DNN)，結合可解釋的 AI (XAI) 工具，為這項任務提供了新的機會。儘管這些方法具有潛力，但由於該領域缺乏高品質、高數量資料，因此這些方法面臨挑戰。為了應對這些挑戰，我們引入了 SEANN，這是一種新穎的方法，用於獲取知識的 DNN，它利用了一種流行的領域特定知識形式：彙總效應量 (PES)。PES 通常以不同的形式出現在已發表的 Meta 分析研究中，並代表科學共識的量化形式。通過使用自訂損失函數直接整合在學習程序中，我們以實驗方式證明了預測效能的概括性以及與從缺乏領域知識的神經網路中提取的關係相比，科學合理性的顯著提升，且是在稀少且有雜訊的資料設定中。

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

摘要：隨著人工智慧 (AI) 在醫療保健中的應用日益普及，本章探討了開發可靠且符合道德標準的臨床決策支援系統 (CDSS) 的關鍵面向。從傳統統計模型到複雜機器學習方法的基本轉變開始，這項工作審查了嚴謹的驗證策略和效能評估方法，包括模型校準和決策曲線分析的關鍵角色。本章強調，在醫療保健中建立值得信賴的 AI 系統不只是技術上的準確性；它需要仔細考量公平性、可解釋性和隱私權。本章強調了透過 AI 確保公平的醫療保健服務的挑戰，並討論了識別和減輕臨床預測模型中偏差的方法。接著，本章深入探討可解釋性，作為以人為中心的 CDSS 的基石。這種關注反映了醫療保健專業人員不僅必須信任 AI 建議，還必須理解其背後的推理。討論進一步分析了醫療 AI 系統中的隱私漏洞，從深度學習模型中的資料外洩到針對模型解釋的複雜攻擊。本文探討了隱私保護策略，例如差分隱私和聯合學習，同時承認隱私保護和模型效能之間的固有取捨。這種從技術驗證到道德考量的進展，反映了開發 AI 系統的多面向挑戰，這些系統可以無縫且可靠地整合到日常臨床實務中，同時維持最高的病患照護和資料保護標準。

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

摘要：随着深度学习模型在医学数据中获得关注，确保透明且值得信赖的决策至关重要。在皮肤癌诊断中，虽然病灶检测和分类的进步提高了准确性，但这些方法的黑盒性质对理解其决策过程构成了挑战，导致医生之间的信任问题。本研究利用在不同皮肤病变数据集上训练的 CLIP（对比语言图像预训练）模型，以捕捉视觉特征和诊断标准术语之间的有意义关系。为了进一步提高透明度，我们提出了一种名为 MedGrad E-CLIP 的方法，该方法通过结合专为皮肤病变等复杂医学影像设计的加权熵机制，建立在基于梯度的 E-CLIP 之上。此方法突出了与特定诊断描述相关联的关键图像区域。开发的集成管道不仅通过匹配相应的描述对皮肤病变进行分类，还添加了一层专门为医学数据开发的基本可解释性。通过直观地解释图像中不同特征与诊断标准的关系，这种方法展示了高级视觉语言模型在医学图像分析中的潜力，最终提高了透明度、稳健性和对人工智能驱动的诊断系统的信任。

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

摘要：幽默風格對幸福感可能產生負面或正面的影響。
鑑於這些風格對心理健康的重要性，已經對其自動識別進行了大量研究。然而，用於此目的的自動機器學習模型是黑盒子，使得其預測決策不透明。清晰度和透明度在心理健康領域至關重要。本文提出了一個可解釋的 AI (XAI) 框架，用於理解幽默風格分類，建立在計算幽默分析的先前工作之上。使用先前研究中表現最好的單一模型 (ALI+XGBoost)，我們應用全面的 XAI 技術來分析語言、情緒和語義特徵如何影響幽默風格分類決策。我們的分析揭示了不同幽默風格如何被表徵和錯誤分類的不同模式，特別強調了區分聯屬幽默與其他風格的挑戰。通過仔細檢查特徵重要性、錯誤模式和錯誤分類案例，我們確定了影響模型決策的關鍵因素，包括情緒模糊、情境誤解和目標識別。該框架展示了在理解模型行為方面的顯著效用，實現了對定義不同幽默風格的特徵之間複雜相互作用的可解釋見解。我們的發現有助於計算幽默分析的理論理解和心理健康、內容審核和數字人文研究中的實際應用。

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

摘要：隨著對心理健康服務需求的增加，凸顯了創新解決方案的需求，特別是在心理對話式人工智慧領域，那裡缺乏敏感資料。在這項工作中，我們探索了開發一個針對心理健康支持的系統，採用一種基於可解釋的情緒特徵的新方法進行心理評估，結合同理心對話模式，提供了一個有前途的工具，用於擴充傳統照護，特別是在無法立即獲得專業知識的情況下。我們的工作可以分為兩個主要部分，彼此內在相關。首先，我們展示了 RACLETTE，一個對話系統，與最先進的基準相比，在理解使用者情緒狀態和在對話中產生同理心回應方面表現出優越的情緒準確性，同時透過他們的互動逐漸建立使用者的情緒特徵。其次，我們展示了使用者的情緒特徵如何可用作心理健康評估的可解釋標記。這些特徵可以與與不同心理疾病相關的典型情緒模式進行比較，提供了一種初步篩選和支持的新方法。

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

摘要：人工智慧（AI）已成為增強體外受精（IVF）決策制定和優化治療方案的強大工具。特別是，AI 在支持 IVF 過程中卵巢刺激階段的決策制定方面顯示出顯著的前景。本綜述評估了專注於 AI 結合卵巢刺激中的醫學影像應用、檢驗方法、結果和當前限制的研究。我們對 13 項關於此主題的研究分析顯示，雖然 AI 演算法在預測最佳荷爾蒙劑量、觸發時機和卵子取出結果方面表現出顯著的潛力，但所利用的醫學影像數據主要來自於二次元（2D）超音波，而二次元超音波主要涉及基本量化，例如濾泡大小和數量，且有限使用直接特徵提取或進階影像分析技術。這指向一個尚未探索的機會，例如深度學習等進階影像分析方法，以及更多元的影像模式，例如三維（3D）超音波，可以解鎖更深入的見解。此外，大多數研究缺乏可解釋 AI（XAI），這引起了人們對 AI 驅動決策的透明度和可追溯性的擔憂，而透明度和可追溯性是臨床採用和信任的關鍵因素。此外，許多研究依賴於單中心設計和小型數據集，這限制了其發現的普遍性。本綜述強調了將進階影像分析技術與可解釋 AI 方法整合起來的必要性，以及利用多中心合作和大型數據集的重要性。解決這些差距有可能增強卵巢刺激管理，為有效、個人化和數據驅動的治療途徑鋪平道路，進而改善 IVF 結果。

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

摘要：本研究提出了一個創新的癌症診斷和預測方法，使用可解釋的人工智慧 (XAI) 和深度學習技術。由於癌症在 2020 年造成全球近 1,000 萬人死亡，因此早期準確的診斷至關重要。傳統方法通常面臨成本、準確性和效率方面的挑戰。我們的研究開發了一個 AI 模型，它提供精確的結果並清楚地了解其決策過程，解決了深度學習模型的「黑箱」問題。通過採用 XAI 技術，我們增強了解釋性和透明度，在醫療專業人員和患者之間建立信任。我們的做法利用神經網路分析廣泛的數據集，識別癌症檢測模式。這個模型有可能通過提高醫療決策的準確性、可及性和清晰度來革新診斷，可能導致更早的檢測和更個性化的治療策略。此外，它可以使更多人獲得高品質的診斷，特別是在資源有限的環境中，有助於全球健康公平。該模型的應用範圍不僅限於癌症診斷，還可能轉變醫療決策的各個方面，並拯救全球數百萬人的生命。

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v2 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings. Our code is available at
https://github.com/tifat58/IRR-with-CBM-RAG.git.

摘要：深度學習已提升醫學影像分類，但可解釋性挑戰阻礙其臨床應用。本研究透過使用概念瓶頸模型 (CBM) 和多代理檢索增強生成 (RAG) 系統進行報告生成，來增強胸部 X 光 (CXR) 分類的可解釋性。透過建模視覺特徵與臨床概念之間的關係，我們建立可解釋的概念向量，引導多代理 RAG 系統生成放射報告，增強臨床相關性、可解釋性和透明度。使用 LLM 作為評審員對生成報告進行評估，確認了我們模型輸出的可解釋性和臨床效用。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確率，並展示了穩健的報告生成效能，五項關鍵指標介於 84% 至 90% 之間。這個可解釋的多代理架構彌合了高性能 AI 與臨床環境中可靠的 AI 驅動 CXR 分析所需的解釋性之間的差距。我們的程式碼可於 https://github.com/tifat58/IRR-with-CBM-RAG.git 取得。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v2 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
challenges due to data heterogeneity, sparsity, temporal misalignment, and
limited labeled outcomes. In this context, we leverage a linked EHR dataset of
approximately one million de-identified individuals from Bristol, North
Somerset, and South Gloucestershire, UK, to characterize urinary tract
infections (UTIs). We implemented a data pre-processing and curation pipeline
that transforms the raw EHR data into a structured format suitable for
developing predictive models focused on data fairness, accountability and
transparency. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Pairwise
XGBoost models are trained using this framework to differentiate UTI risk
categories with explainable AI techniques applied to identify key predictors
and support interpretability. Our findings reveal differences in clinical and
demographic predictors across risk groups. While this study highlights the
potential of AI-driven insights to support UTI clinical decision-making,
further investigation of patient sub-strata and extensive validation are needed
to ensure robustness and applicability in clinical practice.

摘要：電子健康紀錄 (EHR) 中機器學習和 AI 的使用對於臨床見解具有相當大的潛力。然而，由於資料異質性、稀疏性、時間錯位和標籤結果有限，此方法面臨挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特和南格洛斯特郡約一百萬名去識別個人連結的 EHR 資料集，來描述尿路感染 (UTI)。我們實施了將原始 EHR 資料轉換為結構化格式的資料前處理和整理管線，適合開發專注於資料公平性、問責制和透明度的預測模型。鑑於 UTI 真實結果的可用性有限和偏差，我們引入了由臨床專業知識告知的 UTI 風險評估架構，以估計個別患者時間軸上的 UTI 風險。成對的 XGBoost 模型使用此架構進行訓練，以區分 UTI 風險類別，並應用可解釋的 AI 技術來識別關鍵預測因子並支持可解釋性。我們的研究結果揭示了不同風險群組在臨床和人口統計預測因子上的差異。雖然這項研究強調了 AI 驅動見解在支援 UTI 臨床決策制定方面的潛力，但仍需要進一步調查患者子群體和廣泛驗證，以確保在臨床實務中的穩健性和適用性。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折的風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動能力至關重要。然而，醫療保健提供者面臨著標記數據有限和處理醫學影像困難等挑戰。本研究提出了一個新穎的多模式學習框架，該框架整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練的網路，VGG19、InceptionV3 和 ResNet50，從 X 射線影像中提取深度特徵。這些特徵使用 PCA 轉換以降低維度並專注於最相關的組成部分。基於聚類的選擇過程識別出最具代表性的組成部分，然後將這些組成部分與預處理的臨床數據結合，並通過全連接網路 (FCN) 進行最終分類。特徵重要性圖突出了關鍵變數，表明病史、BMI 和身高是主要貢獻因素，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。此框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷在臨床整合中的信任。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

摘要：<paragraph>目的：調查臨床醫生對目前自動化心電圖解讀和新的人工智慧技術的態度，以及他們對電腦輔助解讀的看法。材料和方法：我們對英國的臨床醫生進行了一系列訪談。我們的研究：(i) 探討人工智慧的潛力，特別是未來的「類人類」運算方法，以促進心電圖解讀並支持臨床決策制定，以及 (ii) 徵求他們對人工智慧演算法的可解釋性和可信度的看法。結果：我們對 23 位臨床醫生的訪談記錄進行了歸納主題分析，並找出以下主題：(i) 對目前系統缺乏信任，(ii) 對未來人工智慧應用和對這些應用的要求持正面態度，(iii) 演算法的準確性和可解釋性之間的關係，以及 (iv) 對教育、可能的技能退化，以及人工智慧對臨床能力的影響的看法。討論：臨床醫生不信任目前的電腦化方法，但歡迎未來的「人工智慧」技術。在臨床醫生相信未來的 AI 解讀準確的情況下，他們不太擔心它是否可解釋。他們也比較喜歡能以視覺方式呈現演算法結果的心電圖解讀。雖然臨床醫生不害怕失業，但他們擔心技能退化，以及需要教育員工負責任地使用人工智慧。結論：臨床醫生對人工智慧在臨床決策制定中的未來應用持正面態度。準確性是採用人工智慧的一個關鍵因素，而視覺化比目前的電腦化方法更受青睞。這被視為一種潛在的培訓和提升技能的方法，與自動化可能帶來的技能退化形成對比。</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenmüller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Compérat, Andreas Gocht, Monika Hämmerle, Niels J. Rupp, Jula Westhoff, Irene Krücken, Maximillian Seidl, Christian M. Schürch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian Hörner, Kirsten D. Mertz, Constanze Döring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

摘要：前列腺癌是全球男性最常見的癌症，其惡性程度主要根據 Gleason 評分系統使用組織病理學數據進行評估。雖然人工智慧 (AI) 在準確預測 Gleason 評分方面已展現潛力，但這些預測通常缺乏內在的可解釋性，可能會導致對人機互動的不信任。為了解決這個問題，我們引進了一個由 54 位病理學家組成的國際團隊註解的 1,015 個組織微陣列核心影像的新穎資料集。這些註解提供了詳細的局部模式描述，用於符合國際準則的 Gleason 分級。利用這個資料集，我們開發了一個基於 U-Net 架構的內在可解釋 AI 系統，該系統提供了利用病理學家術語進行預測。這種方法規避了事後可解釋性方法，同時維持或超越了直接訓練用於 Gleason 模式分割的方法的效能（Dice 分數：0.713 ± 0.003，訓練於解釋，相對於 0.691 ± 0.010，訓練於 Gleason 模式）。透過在訓練期間採用軟標籤，我們捕捉了資料中的內在不確定性，即使在觀察者間變異性高的情況下，也能在 Gleason 模式分割中產生強大的結果。透過釋出這個資料集，我們旨在鼓勵進一步研究主觀性高的醫療任務中的分割，並增進對病理學家推理過程的理解。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的關鍵任務，及時且準確地識別醫療狀況會顯著影響患者的結果。傳統的機器學習和深度學習模型已在這個領域取得顯著成功，但通常缺乏可解釋性，這在臨床環境中是一項關鍵要求。在本研究中，我們探討了神經符號方法的應用，特別是邏輯神經網路 (LNN)，以開發用於診斷預測的可解釋模型。基本上，我們設計並實作了基於 LNN 的模型，這些模型透過具有可學習閾值的邏輯規則整合領域特定知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（例如邏輯迴歸、SVM 和隨機森林）的優異效能，在糖尿病預測的案例研究中達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習到的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不影響預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於推進精準醫療，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報資料，結合先進機器學習與深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD) 的可能性。我們分析一家大型健康保險組織提供的 10 年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長期短期記憶 (LSTM) 網路）開發多個觀察視窗的預測模型。我們的研究結果顯示，LSTM 模型（尤其是 24 個月觀察視窗）在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 可加性解釋 (SHAP) 分析以增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政申報資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**
2409.09201v3 by Mercy Asiedu, Nenad Tomasev, Chintan Ghate, Tiya Tiyasirichokchai, Awa Dieng, Oluwatosin Akande, Geoffrey Siwo, Steve Adudans, Sylvanus Aitkins, Odianosen Ehiakhamen, Eric Ndombi, Katherine Heller

While large language models (LLMs) have shown promise for medical question
answering, there is limited work focused on tropical and infectious
disease-specific exploration. We build on an opensource tropical and infectious
diseases (TRINDs) dataset, expanding it to include demographic and semantic
clinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM
performance on these, comparing generalist and medical LLMs, as well as LLM
outcomes to human experts. We demonstrate through systematic experimentation,
the benefit of contextual information such as demographics, location, gender,
risk factors for optimal LLM response. Finally we develop a prototype of
TRINDs-LM, a research tool that provides a playground to navigate how context
impacts LLM outputs for health.

摘要：儘管大型語言模型 (LLM) 在醫療問題解答方面展現出前景，但專注於熱帶和傳染病特定探索的研究有限。我們建立在一個開放原始碼熱帶和傳染病 (TRINDs) 資料集上，並將其擴展為納入人口統計和語義臨床和消費者擴充，產生超過 11000 個提示。我們評估了 LLM 在這些方面的效能，比較了通才和醫療 LLM，以及 LLM 結果與人類專家的比較。我們透過系統性實驗證明了背景資訊（例如人口統計、位置、性別、最佳 LLM 回應的風險因素）的好處。最後，我們開發了 TRINDs-LM 的原型，這是一個研究工具，提供一個探索背景如何影響 LLM 健康輸出的平台。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中已達到整體高準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知且未標籤的群體。此外，此類觀察到的效能差異的根本原因通常難以發現，阻礙了緩解措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳子集，並針對觀察到的效能差異原因制定假設。我們引入一種新的 SDM，並在胸部 X 光片中肺炎和肺不張分類的案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對廣泛使用的胸部 X 光片資料集和模型中先前觀察到但無法解釋的男性和女性患者之間的效能差異提供了解釋。我們的發現表明，在分類任務中，透過胸腔引流管和心電圖導線的存在，存在捷徑學習。這些捷徑特徵的盛行率存在基於性別的差異，似乎會導致觀察到的分類效能差距，這代表捷徑學習和模型公平性分析之間先前未受到重視的交互作用。

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v2 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad, Lamia Ashraf

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病 (CKD) 是一種廣泛的慢性疾病，目前尚未找到最終的治療方法，且發病率很高。研究表明，進行性慢性腎臟病 (CKD) 是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病演變成一種嚴重程度不一的常見疾病。本研究的目標是使用整體學習和可解釋的 AI 來視覺化支配性特徵、特徵分數和值，以進行 CKD 的早期預後和檢測。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式的修改建議，以降低此疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命徵象中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未見的 CKD 病例。我們的研究結果在與腎臟科醫師進行長時間諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多的特徵作為顯著的貢獻者。可解釋性 (I) 衡量重要特徵與被遮蔽特徵的比率，表明我們的 XgBoost 模型在此指標中取得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

摘要：<paragraph>近年来，基于机器学习的临床决策支持系统 (CDSS) 在多种疾病的分析中扮演了关键角色。尽管它们具有广阔的前景，但 AI 模型缺乏透明度，尤其在医疗领域，可靠性是强制性方面，这带来了重大挑战。然而，解释性似乎与准确性成反比。因此，在不影响预测准确性的情况下实现透明度仍然是一个关键挑战。本文提出了一种新方法，即 Rad4XCNN，以通过放射组学的内在可解释性来增强 CNN 衍生特征的预测能力。Rad4XCNN 通过放射组学将可理解的含义与 CNN 衍生特征关联起来，从而偏离了基于显着性图的传统方法，为超越可视化图的解释方法提供了新的视角。使用乳腺癌分类任务作为案例研究，我们在超声成像数据集上评估了 Rad4XCNN，包括一个在线数据集和两个用于内部和外部验证的内部数据集。一些关键结果是：i) 与 ViT 衍生和放射组学特征相比，CNN 衍生特征保证了更稳健的准确性；ii) 用于解释的传统可视化图方法存在一些缺陷；iii) Rad4XCNN 不会为了可解释性而牺牲模型准确性；iv) Rad4XCNN 提供全局解释，使医生能够提取全局见解和发现。我们的方法可以减轻一些与可解释性-准确性权衡相关的担忧。本研究强调了提出新方法来解释模型而不影响其准确性的重要性。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人做出決定的 AI 系統都有一群利害關係人
受到這些決定的親身影響。然而，AI
系統的解釋很少能滿足這群利害關係人的資訊需求，而他們
通常都是 AI 新手。這造成了傳達資訊與
受到系統決策影響的人士（例如領域專家和決策主體）重視的資訊之間的落差。為了解決這個問題，我們提出了
「XAI 新手問題庫」，它是 XAI 問題庫的延伸，包含來自 AI 新手在兩個使用案例中的資訊需求目錄：就業
預測和健康監測。目錄涵蓋了資料、
系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在訪談中詢問了兩個 AI 系統的問題，以決定是否採用它們，並收到口頭
解釋作為回應。我們的分析顯示，參與者在收到解釋後信心有所提升，但他們的理解卻面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包
理解。此外，參與者對系統風險和好處的先前回饋影響了他們的資訊需求。認為風險高的參與者尋求解釋系統部署背後的意圖，而認為風險低的人則詢問系統的
操作。我們的研究旨在透過強調 AI 新手的資訊需求、目標和
挑戰，來支持將 AI 新手納入可解釋性工作中。我們將我們的研究結果總結為五個關鍵啟示，這些啟示可以為未來針對非專業利害關係人受眾的解釋設計提供參考。</paragraph>


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-07**|**Causality can systematically address the monsters under the bench(marks)**|Felix Leeb et.al.|[2502.05085v1](http://arxiv.org/abs/2502.05085v1)|null|
|**2025-02-07**|**Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**|Tushar Pandey et.al.|[2502.05078v1](http://arxiv.org/abs/2502.05078v1)|null|
|**2025-02-07**|**Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**|Junde Wu et.al.|[2502.04644v1](http://arxiv.org/abs/2502.04644v1)|null|
|**2025-02-07**|**Position-aware Automatic Circuit Discovery**|Tal Haklay et.al.|[2502.04577v1](http://arxiv.org/abs/2502.04577v1)|null|
|**2025-02-06**|**Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**|Shangbin Feng et.al.|[2502.04510v1](http://arxiv.org/abs/2502.04510v1)|null|
|**2025-02-06**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413v1](http://arxiv.org/abs/2502.04413v1)|null|
|**2025-02-06**|**Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**|Longquan Jiang et.al.|[2502.03992v1](http://arxiv.org/abs/2502.03992v1)|null|
|**2025-02-06**|**Multimodal Medical Code Tokenizer**|Xiaorui Su et.al.|[2502.04397v1](http://arxiv.org/abs/2502.04397v1)|null|
|**2025-02-06**|**Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents**|Chenyang Shao et.al.|[2502.04392v1](http://arxiv.org/abs/2502.04392v1)|null|
|**2025-02-06**|**Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**|Rui Cai et.al.|[2502.03715v1](http://arxiv.org/abs/2502.03715v1)|null|
|**2025-02-05**|**A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**|Yiye Chen et.al.|[2502.03450v1](http://arxiv.org/abs/2502.03450v1)|null|
|**2025-02-05**|**SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**|Ben Liu et.al.|[2502.03283v1](http://arxiv.org/abs/2502.03283v1)|null|
|**2025-02-05**|**Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**|Daniil Laptev et.al.|[2502.03032v2](http://arxiv.org/abs/2502.03032v2)|null|
|**2025-02-05**|**A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**|Bradley P. Allen et.al.|[2502.02896v1](http://arxiv.org/abs/2502.02896v1)|null|
|**2025-02-05**|**Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**|Chanhui Lee et.al.|[2502.02810v1](http://arxiv.org/abs/2502.02810v1)|null|
|**2025-02-05**|**Leveraging the true depth of LLMs**|Ramón Calvo González et.al.|[2502.02790v1](http://arxiv.org/abs/2502.02790v1)|null|
|**2025-02-04**|**Modular Training of Neural Networks aids Interpretability**|Satvik Golechha et.al.|[2502.02470v2](http://arxiv.org/abs/2502.02470v2)|null|
|**2025-02-04**|**Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs**|Sagnik Mukherjee et.al.|[2502.02362v2](http://arxiv.org/abs/2502.02362v2)|null|
|**2025-02-04**|**AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement**|Shivam Singh et.al.|[2502.02067v1](http://arxiv.org/abs/2502.02067v1)|[link](https://github.com/sssshivvvv/adaptbot)|
|**2025-02-03**|**On Bob Dylan: A Computational Perspective**|Prashant Garg et.al.|[2502.01772v1](http://arxiv.org/abs/2502.01772v1)|null|
|**2025-02-03**|**VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**|Xubin Ren et.al.|[2502.01549v1](http://arxiv.org/abs/2502.01549v1)|null|
|**2025-02-03**|**Transformers trained on proteins can learn to attend to Euclidean distance**|Isaac Ellmen et.al.|[2502.01533v1](http://arxiv.org/abs/2502.01533v1)|[link](https://github.com/Ellmen/attending-to-distance)|
|**2025-02-03**|**Common Foundations for SHACL, ShEx, and PG-Schema**|S. Ahmetaj et.al.|[2502.01295v1](http://arxiv.org/abs/2502.01295v1)|null|
|**2025-02-03**|**GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**|Linhao Luo et.al.|[2502.01113v1](http://arxiv.org/abs/2502.01113v1)|[link](https://github.com/RManLuo/gfm-rag)|
|**2025-02-03**|**Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**|Seungri Yoon et.al.|[2502.01059v1](http://arxiv.org/abs/2502.01059v1)|null|
|**2025-02-03**|**Encrypted Large Model Inference: The Equivariant Encryption Paradigm**|James Buban et.al.|[2502.01013v1](http://arxiv.org/abs/2502.01013v1)|null|
|**2025-02-02**|**Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation**|Juno Kim et.al.|[2502.01694v1](http://arxiv.org/abs/2502.01694v1)|null|
|**2025-02-02**|**PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation**|Qixuan Li et.al.|[2502.00708v1](http://arxiv.org/abs/2502.00708v1)|null|
|**2025-02-02**|**A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models**|Qika Lin et.al.|[2502.00681v1](http://arxiv.org/abs/2502.00681v1)|null|
|**2025-02-01**|**Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions**|Jingyuan Yi et.al.|[2502.00339v1](http://arxiv.org/abs/2502.00339v1)|null|
|**2025-02-01**|**DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning**|Jiaxin Guo et.al.|[2502.00305v1](http://arxiv.org/abs/2502.00305v1)|null|
|**2025-01-31**|**Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques**|Nathaniel Tomczak et.al.|[2502.01659v2](http://arxiv.org/abs/2502.01659v2)|null|
|**2025-01-31**|**Improving vision-language alignment with graph spiking hybrid Networks**|Siyu Zhang et.al.|[2501.19069v1](http://arxiv.org/abs/2501.19069v1)|null|
|**2025-01-30**|**Semantic Web and Creative AI -- A Technical Report from ISWS 2023**|Raia Abu Ahmad et.al.|[2501.18542v1](http://arxiv.org/abs/2501.18542v1)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**|Tianpeng Pan et.al.|[2501.18320v1](http://arxiv.org/abs/2501.18320v1)|null|
|**2025-01-30**|**Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**|Wanlong Liu et.al.|[2501.18154v1](http://arxiv.org/abs/2501.18154v1)|null|
|**2025-01-30**|**Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**|Qika Lin et.al.|[2501.18119v1](http://arxiv.org/abs/2501.18119v1)|null|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**|Wooyoung Kim et.al.|[2501.17549v1](http://arxiv.org/abs/2501.17549v1)|null|
|**2025-01-29**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403v1](http://arxiv.org/abs/2501.17403v1)|[link](https://github.com/honghd16/gsa-vln)|
|**2025-01-28**|**Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**|Saloni Potdar et.al.|[2501.17270v1](http://arxiv.org/abs/2501.17270v1)|null|
|**2025-01-28**|**FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**|Deren Lei et.al.|[2501.17144v1](http://arxiv.org/abs/2501.17144v1)|[link](https://github.com/derenlei/factcg)|
|**2025-01-28**|**LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**|Li Yin et.al.|[2501.16673v2](http://arxiv.org/abs/2501.16673v2)|[link](https://github.com/sylphai-inc/adalflow)|
|**2025-01-27**|**360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation**|Hamed Firooz et.al.|[2501.16450v2](http://arxiv.org/abs/2501.16450v2)|null|
|**2025-01-27**|**Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**|Antony Bartlett et.al.|[2501.16191v1](http://arxiv.org/abs/2501.16191v1)|null|
|**2025-01-27**|**Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs**|Yu Li et.al.|[2501.15791v1](http://arxiv.org/abs/2501.15791v1)|[link](https://github.com/kse-eleven/makged)|
|**2025-01-27**|**Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs**|Momoka Furuhashi et.al.|[2501.15777v1](http://arxiv.org/abs/2501.15777v1)|null|
|**2025-01-26**|**Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts**|Haodi Ma et.al.|[2501.15688v1](http://arxiv.org/abs/2501.15688v1)|null|
|**2025-01-26**|**How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback**|Manzong Huang et.al.|[2501.15378v1](http://arxiv.org/abs/2501.15378v1)|null|
|**2025-01-24**|**Explaining Categorical Feature Interactions Using Graph Covariance and LLMs**|Cencheng Shen et.al.|[2501.14932v1](http://arxiv.org/abs/2501.14932v1)|null|
|**2025-01-24**|**Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**|Hang Luo et.al.|[2501.14892v1](http://arxiv.org/abs/2501.14892v1)|null|
|**2025-01-24**|**GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**|Ziwen Li et.al.|[2501.16382v1](http://arxiv.org/abs/2501.16382v1)|[link](https://github.com/aaronli43/grappi)|
|**2025-01-24**|**Evaluating and Improving Graph to Text Generation with Large Language Models**|Jie He et.al.|[2501.14497v1](http://arxiv.org/abs/2501.14497v1)|[link](https://github.com/probe2/kg_text)|
|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300v1](http://arxiv.org/abs/2501.14300v1)|[link](https://github.com/dosonleung/fasttog)|
|**2025-01-24**|**Top Ten Challenges Towards Agentic Neural Graph Databases**|Jiaxin Bai et.al.|[2501.14224v1](http://arxiv.org/abs/2501.14224v1)|null|
|**2025-01-23**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050v1](http://arxiv.org/abs/2501.14050v1)|null|
|**2025-01-23**|**EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**|Yuhui Yun et.al.|[2501.13746v1](http://arxiv.org/abs/2501.13746v1)|null|
|**2025-01-23**|**Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**|Chang Gong et.al.|[2501.13731v1](http://arxiv.org/abs/2501.13731v1)|null|
|**2025-01-23**|**CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**|Hamza Landolsi et.al.|[2501.13993v1](http://arxiv.org/abs/2501.13993v1)|null|
|**2025-01-23**|**Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**|Hy Nguyen et.al.|[2501.13992v1](http://arxiv.org/abs/2501.13992v1)|null|
|**2025-01-23**|**Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**|Bhumika Gupta et.al.|[2501.13984v1](http://arxiv.org/abs/2501.13984v1)|null|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**|Dongsheng Zhu et.al.|[2501.12432v1](http://arxiv.org/abs/2501.12432v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|[link](https://github.com/reecall/graphtod)|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**|Qinggang Zhang et.al.|[2501.13958v1](http://arxiv.org/abs/2501.13958v1)|[link](https://github.com/deep-polyu/awesome-graphrag)|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v2](http://arxiv.org/abs/2501.11849v2)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|
|**2025-01-21**|**Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning**|Haoran Song et.al.|[2501.16361v1](http://arxiv.org/abs/2501.16361v1)|null|
|**2025-01-20**|**Zep: A Temporal Knowledge Graph Architecture for Agent Memory**|Preston Rasmussen et.al.|[2501.13956v1](http://arxiv.org/abs/2501.13956v1)|[link](https://github.com/getzep/graphiti)|
|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560v1](http://arxiv.org/abs/2501.11560v1)|null|
|**2025-01-20**|**Each Graph is a New Language: Graph Learning with LLMs**|Huachi Zhou et.al.|[2501.11478v2](http://arxiv.org/abs/2501.11478v2)|null|
|**2025-01-20**|**Few-shot Policy (de)composition in Conversational Question Answering**|Kyle Erwin et.al.|[2501.11335v1](http://arxiv.org/abs/2501.11335v1)|null|
|**2025-01-20**|**Reasoning Language Models: A Blueprint**|Maciej Besta et.al.|[2501.11223v3](http://arxiv.org/abs/2501.11223v3)|[link](https://github.com/spcl/x1)|
|**2025-01-19**|**IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**|Elad Levi et.al.|[2501.11067v1](http://arxiv.org/abs/2501.11067v1)|[link](https://github.com/plurai-ai/intellagent)|
|**2025-01-18**|**A Method for Multi-Hop Question Answering on Persian Knowledge Graph**|Arash Ghafouri et.al.|[2501.16350v1](http://arxiv.org/abs/2501.16350v1)|null|
|**2025-01-17**|**Agent-as-Judge for Factual Summarization of Long Narratives**|Yeonseok Jeong et.al.|[2501.09993v1](http://arxiv.org/abs/2501.09993v1)|[link](https://github.com/yeonseokjeong/narrativefactscore)|
|**2025-01-17**|**FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**|Zengyi Gao et.al.|[2501.09957v2](http://arxiv.org/abs/2501.09957v2)|null|
|**2025-01-16**|**SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**|Anbang Ye et.al.|[2501.09316v1](http://arxiv.org/abs/2501.09316v1)|null|
|**2025-01-16**|**Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**|Zijin Qiu et.al.|[2501.09279v1](http://arxiv.org/abs/2501.09279v1)|null|
|**2025-01-16**|**A Simple Graph Contrastive Learning Framework for Short Text Classification**|Yonghao Liu et.al.|[2501.09219v1](http://arxiv.org/abs/2501.09219v1)|[link](https://github.com/keaml-jlu/simstc)|
|**2025-01-16**|**Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**|Yonghao Liu et.al.|[2501.09214v1](http://arxiv.org/abs/2501.09214v1)|[link](https://github.com/keaml-jlu/mi-delight)|
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|[link](https://github.com/qinyuma316/retrosynthesisagent)|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|[link](https://github.com/machuangtao/kg-rag4sm)|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v2](http://arxiv.org/abs/2501.08613v2)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**|Markus J. Buehler et.al.|[2501.08120v1](http://arxiv.org/abs/2501.08120v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2025-01-14**|**Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**|Haoyu Han et.al.|[2501.07845v1](http://arxiv.org/abs/2501.07845v1)|null|
|**2025-01-14**|**Flow: A Modular Approach to Automated Agentic Workflow Generation**|Boye Niu et.al.|[2501.07834v1](http://arxiv.org/abs/2501.07834v1)|null|
|**2025-01-14**|**Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**|Bingchen Liu et.al.|[2501.07766v1](http://arxiv.org/abs/2501.07766v1)|null|
|**2025-01-13**|**SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**|Fabien Bernier et.al.|[2501.07639v1](http://arxiv.org/abs/2501.07639v1)|null|
|**2025-01-13**|**ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**|Jiayang Wu et.al.|[2501.07078v1](http://arxiv.org/abs/2501.07078v1)|[link](https://github.com/csjywu1/adkgd)|
|**2025-01-12**|**Causal Claims in Economics**|Prashant Garg et.al.|[2501.06873v1](http://arxiv.org/abs/2501.06873v1)|null|
|**2025-01-12**|**MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**|Tianyu Fan et.al.|[2501.06713v3](http://arxiv.org/abs/2501.06713v3)|[link](https://github.com/hkuds/minirag)|
|**2025-01-12**|**Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**|Aidan Hogan et.al.|[2501.06699v1](http://arxiv.org/abs/2501.06699v1)|null|
|**2025-01-11**|**Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**|Mohammed Maree et.al.|[2501.06628v1](http://arxiv.org/abs/2501.06628v1)|null|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v2](http://arxiv.org/abs/2501.06465v2)|null|
|**2025-01-10**|**Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**|Mumin Jia et.al.|[2501.06382v2](http://arxiv.org/abs/2501.06382v2)|null|

#### Abstracts
##### **Causality can systematically address the monsters under the bench(marks)**
2502.05085v1 by Felix Leeb, Zhijing Jin, Bernhard Schölkopf

Effective and reliable evaluation is essential for advancing empirical
machine learning. However, the increasing accessibility of generalist models
and the progress towards ever more complex, high-level tasks make systematic
evaluation more challenging. Benchmarks are plagued by various biases,
artifacts, or leakage, while models may behave unreliably due to poorly
explored failure modes. Haphazard treatments and inconsistent formulations of
such "monsters" can contribute to a duplication of efforts, a lack of trust in
results, and unsupported inferences. In this position paper, we argue causality
offers an ideal framework to systematically address these challenges. By making
causal assumptions in an approach explicit, we can faithfully model phenomena,
formulate testable hypotheses with explanatory power, and leverage principled
tools for analysis. To make causal model design more accessible, we identify
several useful Common Abstract Topologies (CATs) in causal graphs which help
gain insight into the reasoning abilities in large language models. Through a
series of case studies, we demonstrate how the precise yet pragmatic language
of causality clarifies the strengths and limitations of a method and inspires
new approaches for systematic progress.

摘要：有效的、可靠的評估對於推進經驗機器學習至關重要。然而，一般化模型的可及性日益提高，以及朝著更複雜、更高級別任務的進展，使得系統評估更具挑戰性。基準測試受到各種偏差、人工製品或洩漏的困擾，而模型由於探索不充分的故障模式而可能表現得不可靠。隨意處理和不一致的表述等「怪物」可能會導致重複工作、對結果缺乏信任以及不支援的推論。在本文中，我們論證因果關係提供了一個系統性解決這些挑戰的理想框架。通過在方法中明確因果假設，我們可以忠實地模擬現象，制定具有解釋力的可測試假設，並利用原則性的分析工具。為了使因果模型設計更易於使用，我們在因果圖中識別出幾個有用的通用抽象拓撲 (CAT)，有助於深入了解大型語言模型中的推理能力。通過一系列案例研究，我們展示了因果關係的精確但務實的語言如何釐清方法的優缺點，並激發系統進展的新方法。

##### **Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**
2502.05078v1 by Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha

Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities, yet their performance is highly dependent on the prompting
strategy and model scale. While reinforcement learning and fine-tuning have
been deployed to boost reasoning, these approaches incur substantial
computational and data overhead. In this work, we introduce Adaptive Graph of
Thoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM
reasoning solely at test time. Rather than relying on fixed-step methods like
Chain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes
complex queries into structured subproblems, forming an dynamic directed
acyclic graph (DAG) of interdependent reasoning steps. By selectively expanding
only those subproblems that require further analysis, AGoT unifies the
strengths of chain, tree, and graph paradigms into a cohesive framework that
allocates computation where it is most needed. We validate our approach on
diverse benchmarks spanning multi-hop retrieval, scientific reasoning, and
mathematical problem-solving, achieving up to 46.2% improvement on scientific
reasoning tasks (GPQA) - comparable to gains achieved through computationally
intensive reinforcement learning approaches and outperforming state-of-the-art
iterative approaches. These results suggest that dynamic decomposition and
structured recursion offer a scalable, cost-effective alternative to
post-training modifications, paving the way for more robust, general-purpose
reasoning in LLMs.

摘要：大型語言模型 (LLM) 已展現令人印象深刻的推理能力，但其效能高度依賴於提示策略和模型規模。雖然強化學習和微調已被用於提升推理，但這些方法會造成大量的運算和資料開銷。在這項工作中，我們引入了「適應性思考圖」(AGoT)，一個動態的、基於圖形的推論架構，它僅在測試時就能增強 LLM 推理。AGoT 並非依賴於鏈式思考 (CoT) 或樹狀思考 (ToT) 等固定步驟方法，而是遞迴地將複雜的查詢分解成結構化的子問題，形成一個由相互依賴的推理步驟所組成的動態有向無環圖 (DAG)。透過選擇性地僅擴充那些需要進一步分析的子問題，AGoT 將鏈式、樹狀和圖形範例的優勢統一到一個緊密的架構中，將運算分配到最需要的地方。我們在跨越多重跳躍檢索、科學推理和數學問題解決等多樣基準上驗證了我們的做法，在科學推理任務 (GPQA) 上達到了高達 46.2% 的改進，這與透過運算密集的強化學習方法所獲得的增益相當，並且優於最先進的迭代方法。這些結果表明，動態分解和結構化遞迴提供了一個可擴充、具成本效益的替代方案，用於訓練後修改，為 LLM 中更強健、更通用的推理鋪平了道路。

##### **Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**
2502.04644v1 by Junde Wu, Jiayuan Zhu, Yuyuan Liu

We introduce Agentic Reasoning, a framework that enhances large language
model (LLM) reasoning by integrating external tool-using agents. Unlike
conventional LLM-based reasoning approaches, which rely solely on internal
inference, Agentic Reasoning dynamically engages web search, code execution,
and structured reasoning-context memory to solve complex problems requiring
deep research and multi-step logical deduction. Our framework introduces the
Mind Map agent, which constructs a structured knowledge graph to track logical
relationships, improving deductive reasoning. Additionally, the integration of
web-search and coding agents enables real-time retrieval and computational
analysis, enhancing reasoning accuracy and decision-making. Evaluations on
PhD-level scientific reasoning (GPQA) and domain-specific deep research tasks
demonstrate that our approach significantly outperforms existing models,
including leading retrieval-augmented generation (RAG) systems and
closed-source LLMs. Moreover, our results indicate that agentic reasoning
improves expert-level knowledge synthesis, test-time scalability, and
structured problem-solving. The code is at:
https://github.com/theworldofagents/Agentic-Reasoning.

摘要：我們引入了代理推理，一個透過整合外部工具使用代理來增強大型語言模型 (LLM) 推理的框架。與僅依賴於內部推論的傳統基於 LLM 的推理方法不同，代理推理動態地運用網路搜尋、程式碼執行和結構化推理情境記憶來解決需要深入研究和多步驟邏輯推論的複雜問題。我們的框架引入了心智圖代理，它建立一個結構化的知識圖譜來追蹤邏輯關係，改善演繹推理。此外，整合網路搜尋和編碼代理能進行即時擷取和運算分析，增強推理準確度和決策制定。在博士等級科學推理 (GPQA) 和特定領域的深入研究任務上的評估顯示，我們的做法明顯優於現有模型，包括領先的檢索增強生成 (RAG) 系統和封閉原始碼 LLM。此外，我們的結果顯示，代理推理改進了專家級知識綜合、測試時間可擴充性和結構化問題解決。程式碼在：https://github.com/theworldofagents/Agentic-Reasoning。

##### **Position-aware Automatic Circuit Discovery**
2502.04577v1 by Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov

A widely used strategy to discover and understand language model mechanisms
is circuit analysis. A circuit is a minimal subgraph of a model's computation
graph that executes a specific task. We identify a gap in existing circuit
discovery methods: they assume circuits are position-invariant, treating model
components as equally relevant across input positions. This limits their
ability to capture cross-positional interactions or mechanisms that vary across
positions. To address this gap, we propose two improvements to incorporate
positionality into circuits, even on tasks containing variable-length examples.
First, we extend edge attribution patching, a gradient-based method for circuit
discovery, to differentiate between token positions. Second, we introduce the
concept of a dataset schema, which defines token spans with similar semantics
across examples, enabling position-aware circuit discovery in datasets with
variable length examples. We additionally develop an automated pipeline for
schema generation and application using large language models. Our approach
enables fully automated discovery of position-sensitive circuits, yielding
better trade-offs between circuit size and faithfulness compared to prior work.

摘要：廣泛用於發現和了解語言模型機制的策略是電路分析。電路是模型計算圖的最小子圖，可執行特定任務。我們找出電路發現方法中的一個缺口：它們假設電路與位置無關，將模型組件視為在輸入位置中同樣相關。這限制了它們捕捉跨位置互動或在不同位置中變化的機制的能力。為了解決這個缺口，我們提出兩項改進，將位置性納入電路中，即使在包含變長範例的任務中也是如此。首先，我們擴充邊緣屬性修補，一種基於梯度的電路發現方法，以區分符號位置。其次，我們引入了資料集架構的概念，它定義了在範例中具有類似語義的符號跨距，使我們可以在具有變長範例的資料集中進行與位置相關的電路發現。此外，我們開發了一個自動化管線，用於使用大型語言模型進行架構生成和應用。我們的做法能讓位置敏感電路的發現完全自動化，與先前的研究相比，在電路大小和忠實度之間產生了更好的權衡。

##### **Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**
2502.04510v1 by Shangbin Feng, Zifeng Wang, Palash Goyal, Yike Wang, Weijia Shi, Huang Xia, Hamid Palangi, Luke Zettlemoyer, Yulia Tsvetkov, Chen-Yu Lee, Tomas Pfister

We propose Heterogeneous Swarms, an algorithm to design multi-LLM systems by
jointly optimizing model roles and weights. We represent multi-LLM systems as
directed acyclic graphs (DAGs) of LLMs with topological message passing for
collaborative generation. Given a pool of LLM experts and a utility function,
Heterogeneous Swarms employs two iterative steps: role-step and weight-step.
For role-step, we interpret model roles as learning a DAG that specifies the
flow of inputs and outputs between LLMs. Starting from a swarm of random
continuous adjacency matrices, we decode them into discrete DAGs, call the LLMs
in topological order, evaluate on the utility function (e.g. accuracy on a
task), and optimize the adjacency matrices with particle swarm optimization
based on the utility score. For weight-step, we assess the contribution of
individual LLMs in the multi-LLM systems and optimize model weights with swarm
intelligence. We propose JFK-score to quantify the individual contribution of
each LLM in the best-found DAG of the role-step, then optimize model weights
with particle swarm optimization based on the JFK-score. Experiments
demonstrate that Heterogeneous Swarms outperforms 15 role- and/or weight-based
baselines by 18.5% on average across 12 tasks. Further analysis reveals that
Heterogeneous Swarms discovers multi-LLM systems with heterogeneous model roles
and substantial collaborative gains, and benefits from the diversity of
language models.

摘要：<paragraph>我們提出異質群體，一種演算法，透過共同最佳化模型角色和權重來設計多 LLM 系統。我們將多 LLM 系統表示為 LLM 的有向非循環圖 (DAG)，並透過拓撲訊息傳遞進行協作產生。給定一組 LLM 專家和一個效用函數，異質群體使用兩個反覆步驟：角色步驟和權重步驟。對於角色步驟，我們將模型角色解釋為學習一個 DAG，它指定 LLM 之間輸入和輸出的流動。從一組隨機連續鄰接矩陣開始，我們將它們解碼為離散 DAG，以拓撲順序呼叫 LLM，根據效用函數（例如任務的準確度）進行評估，並根據效用分數使用粒子群最佳化最佳化鄰接矩陣。對於權重步驟，我們評估個別 LLM 在多 LLM 系統中的貢獻，並使用群體智慧最佳化模型權重。我們提出 JFK 分數來量化每個 LLM 在角色步驟中找到的最佳 DAG 中的個別貢獻，然後根據 JFK 分數使用粒子群最佳化最佳化模型權重。實驗表明，異質群體在 12 項任務中平均比 15 個基於角色和/或權重的基線高出 18.5%。進一步的分析表明，異質群體發現具有異質模型角色和大量協作收益的多 LLM 系統，並受益於語言模型的多樣性。</paragraph>

##### **MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**
2502.04413v1 by Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao

Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG

摘要：檢索增強生成 (RAG) 是一種適用於檢索隱私敏感的電子健康記錄 (EHR) 的技術。它可以作為醫療保健副駕駛的一個關鍵模組，協助減少醫療保健從業人員和患者的誤診。然而，在醫療領域中使用的現有基於啟發法的 RAG 模型的診斷準確性和特異性不足，特別是對於具有類似表現的疾病。本文提出 MedRAG，一種由知識圖譜 (KG) 引發的推理增強的 RAG 模型，用於醫療領域，它根據表現檢索診斷和治療建議。MedRAG 系統性地構建了一個全面的四層階層式診斷 KG，涵蓋各種疾病的關鍵診斷差異。這些差異與從 EHR 資料庫中檢索到的類似 EHR 動態整合，並在大型語言模型中進行推理。這個過程可以實現更準確和具體的決策支援，同時主動提供後續問題，以增強個人化醫療決策制定。MedRAG 在公共資料集 DDXPlus 和從陳篤生醫院收集的私人慢性疼痛診斷資料集 (CPDD) 上進行評估，並將其效能與各種現有 RAG 方法進行比較。實驗結果顯示，利用 KG 的資訊整合和關係能力，我們的 MedRAG 提供了更具體的診斷見解，並在降低誤診率方面優於最先進的模型。我們的程式碼將在 https://github.com/SNOWTEAM2023/MedRAG 提供

##### **Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**
2502.03992v1 by Longquan Jiang, Junbo Huang, Cedric Möller, Ricardo Usbeck

Most existing Knowledge Graph Question Answering (KGQA) approaches are
designed for a specific KG, such as Wikidata, DBpedia or Freebase. Due to the
heterogeneity of the underlying graph schema, topology and assertions, most
KGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) without
resource-intensive training data. We present OntoSCPrompt, a novel Large
Language Model (LLM)-based KGQA approach with a two-stage architecture that
separates semantic parsing from KG-dependent interactions. OntoSCPrompt first
generates a SPARQL query structure (including SPARQL keywords such as SELECT,
ASK, WHERE and placeholders for missing tokens) and then fills them with
KG-specific information. To enhance the understanding of the underlying KG, we
present an ontology-guided, hybrid prompt learning strategy that integrates KG
ontology into the learning process of hybrid prompts (e.g., discrete and
continuous vectors). We also present several task-specific decoding strategies
to ensure the correctness and executability of generated SPARQL queries in both
stages. Experimental results demonstrate that OntoSCPrompt performs as well as
SOTA approaches without retraining on a number of KGQA datasets such as CWQ,
WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize well
to unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

摘要：現有的知識圖譜問答（KGQA）方法大多是為特定 KG 而設計的，例如 Wikidata、DBpedia 或 Freebase。由於底層圖形模式、拓撲和斷言的異質性，大多數 KGQA 系統無法在沒有資源密集型訓練資料的情況下轉移到未見過的知識圖譜（KG）。我們提出 OntoSCPrompt，這是一種基於大型語言模型（LLM）的新型 KGQA 方法，採用兩階段架構，將語義解析與依賴 KG 的互動分開。OntoSCPrompt 首先生成 SPARQL 查詢結構（包括 SPARQL 關鍵字，例如 SELECT、ASK、WHERE 和缺失令牌的佔位符），然後用 KG 特定的資訊填寫它們。為了增強對底層 KG 的理解，我們提出了一種由本体指導的混合提示學習策略，將 KG 本体整合到混合提示（例如，離散和連續向量）的學習過程中。我們還提出了多種特定任務的解碼策略，以確保在兩個階段中生成的 SPARQL 查詢的正確性和可執行性。實驗結果表明，OntoSCPrompt 在 CWQ、WebQSP 和 LC-QuAD 1.0 等多個 KGQA 資料集上執行時，效能與 SOTA 方法一樣好，且資源使用效率高，並且可以很好地概括到未見過的特定領域 KG，例如 DBLP-QuAD 和 CoyPu KG Code：
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

##### **Multimodal Medical Code Tokenizer**
2502.04397v1 by Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik

Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.

摘要：<paragraph>在患者電子病歷 (EHR) 上訓練的基礎模型需要將醫療資料代換成離散詞彙項目序列。現有代換器將 EHR 中的醫療代碼視為孤立的文字代碼。然而，每個醫療代碼都由其文字描述、在本体層級中的位置，以及與其他代碼的關聯性（例如疾病共現和藥物治療關聯性）定義。醫療詞彙包含超過 600,000 個代碼，其中包含臨床推理的重要資訊。我們介紹 MedTok，這是一個多模態醫療代碼代換器，它使用代碼的文字描述和關聯性脈絡。MedTok 使用語言模型編碼器處理文字，並使用圖形編碼器編碼關聯結構。然後，它將兩種模態量化為統一的代碼空間，保留特定於模態和跨模態的資訊。我們將 MedTok 整合到五個 EHR 模型中，並在包括結果預測、診斷分類、藥物建議和風險分層在內的住院和門診資料集上對其進行運作和臨床任務評估。將標準 EHR 代換器換成 MedTok 可改善所有 EHR 模型的 AUPRC，在 MIMIC-III 上提高 4.10%，在 MIMIC-IV 上提高 4.78%，在 EHRShot 上提高 11.30%，其中藥物建議的進步最大。除了 EHR 建模之外，我們展示了使用 MedTok 代換器搭配醫療 QA 系統。我們的結果證明了 MedTok 作為醫療代碼統一代換器的潛力，改善了醫療基礎模型的代換。</paragraph>

##### **Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents**
2502.04392v1 by Chenyang Shao, Xinyuan Hu, Yutang Lin, Fengli Xu

The rapid expansion of web content has made on-device AI assistants
indispensable for helping users manage the increasing complexity of online
tasks. The emergent reasoning ability in large language models offer a
promising path for next-generation on-device AI agents. However, deploying
full-scale Large Language Models (LLMs) on resource-limited local devices is
challenging. In this paper, we propose Division-of-Thoughts (DoT), a
collaborative reasoning framework leveraging the synergy between locally
deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT
leverages a Task Decomposer to elicit the inherent planning abilities in
language models to decompose user queries into smaller sub-tasks, which allows
hybrid language models to fully exploit their respective strengths. Besides,
DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks
and create a dependency graph, facilitating parallel reasoning of sub-tasks and
the identification of key steps. To allocate the appropriate model based on the
difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an
additional task head attached to the SLM that does not alter the SLM's
parameters. To boost adapter's task allocation capability, we propose a
self-reinforced training method that relies solely on task execution feedback.
Extensive experiments on various benchmarks demonstrate that our DoT
significantly reduces LLM costs while maintaining competitive reasoning
accuracy. Specifically, DoT reduces the average reasoning time and API costs by
66.12% and 83.57%, while achieving comparable reasoning accuracy with the best
baseline methods.

摘要：<paragraph>網頁內容快速擴充，使得行動裝置上的 AI 助理在協助使用者管理日益複雜的線上工作上變得不可或缺。大型語言模型中浮現的推理能力為新一代行動裝置上的 AI 代理提供了一條有希望的途徑。然而，在資源有限的本機裝置上部署全規模的大型語言模型 (LLM) 是一項挑戰。在本文中，我們提出了思想分工 (DoT)，一個協作推理框架，利用了本地部署的小型語言模型 (SLM) 與雲端 LLM 之間的協同效應。DoT 利用任務分解器引出語言模型中固有的規劃能力，將使用者查詢分解成較小的子任務，這允許混合語言模型充分發揮其各自的優勢。此外，DoT 雇用了一個任務排程器來分析子任務的成對依賴性並建立一個依賴性圖，促進子任務的並行推理和關鍵步驟的識別。為了根據子任務的難度分配適當的模型，DoT 利用了即插即用適配器，這是一個附加在 SLM 上的任務頭，不會改變 SLM 的參數。為了提升適配器的任務分配能力，我們提出了一種自我強化訓練方法，它僅依賴於任務執行回饋。在各種基準上的廣泛實驗表明，我們的 DoT 大幅降低了 LLM 成本，同時維持了有競爭力的推理準確度。具體來說，DoT 將平均推理時間和 API 成本分別降低了 66.12% 和 83.57%，同時達到了與最佳基準方法相當的推理準確度。</paragraph>

##### **Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**
2502.03715v1 by Rui Cai, Chao Wang, Qianyi Cai, Dazhong Shen, Hui Xiong

Knowledge Graph-based recommendations have gained significant attention due
to their ability to leverage rich semantic relationships. However, constructing
and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy
of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent
advancements in Large Language Models (LLMs) offer a promising way to improve
the quality and relevance of KGs for recommendation tasks. Despite this,
integrating LLMs into KG-based systems presents challenges, such as efficiently
augmenting KGs, addressing hallucinations, and developing effective joint
learning methods. In this paper, we propose the Confidence-aware KG-based
Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework
that combines KGs and LLMs for recommendation task. The framework includes: (1)
an LLM-based subgraph augmenter for enriching KGs with high-quality
information, (2) a confidence-aware message propagation mechanism to filter
noisy triplets, and (3) a dual-view contrastive learning method to integrate
user-item interactions and KG data. Additionally, we employ a confidence-aware
explanation generation process to guide LLMs in producing realistic
explanations for recommendations. Finally, extensive experiments demonstrate
the effectiveness of CKG-LLMA across multiple public datasets.

摘要：基於知識圖譜的推薦因其利用豐富語義關係的能力而備受關注。然而，構建和維護知識圖譜 (KG) 是一項資源密集型任務，而 KG 的準確性可能會受到雜訊、過時或無關的三元組的影響。大型語言模型 (LLM) 的最新進展為提高 KG 在推薦任務中的品質和相關性提供了一種有前途的方法。儘管如此，將 LLM 整合到基於 KG 的系統中會帶來挑戰，例如有效擴充 KG、處理幻覺，以及開發有效的聯合學習方法。在本文中，我們提出具有 LLM 擴充的信心感知型基於 KG 的推薦框架 (CKG-LLMA)，這是一個結合 KG 和 LLM 進行推薦任務的新穎框架。該框架包括：(1) 一個基於 LLM 的子圖擴充器，用於使用高品質資訊豐富 KG，(2) 一個信心感知型訊息傳播機制，用於過濾雜訊三元組，以及 (3) 一個雙視圖對比學習方法，用於整合使用者-項目互動和 KG 資料。此外，我們採用一個信心感知型解釋產生程序，以引導 LLM 為推薦產生逼真的解釋。最後，大量的實驗證明了 CKG-LLMA 在多個公開資料集中的有效性。

##### **A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**
2502.03450v1 by Yiye Chen, Harpreet Sawhney, Nicholas Gydé, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell

Scene graphs have emerged as a structured and serializable environment
representation for grounded spatial reasoning with Large Language Models
(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason
framework for reasoning and planning with scene graphs. Our approach employs
two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and
information queries generation, and a (2) Retriever for extracting
corresponding graph information following the queries. Two agents collaborate
iteratively, enabling sequential reasoning and adaptive attention to graph
information. Unlike prior works, both agents are prompted only with the scene
graph schema rather than the full graph data, which reduces the hallucination
by limiting input tokens, and drives the Reasoner to generate reasoning trace
abstractly.Following the trace, the Retriever programmatically query the scene
graph data based on the schema understanding, allowing dynamic and global
attention on the graph that enhances alignment between reasoning and retrieval.
Through experiments in multiple simulation environments, we show that our
framework surpasses existing LLM-based approaches in numerical Q\&A and
planning tasks, and can benefit from task-level few-shot examples, even in the
absence of agent-level demonstrations. Project code will be released.

摘要：場景圖表已成為大型語言模型 (LLM) 以基礎空間推理為基礎的結構化且可序列化的環境表徵。在這項工作中，我們提出 SG-RwR，一個以綱要為導向的檢索與推理框架，用於場景圖表的推理和規劃。我們的做法採用了兩個協作的、編寫程式碼的 LLM 代理：一個 (1) 推論器，用於任務規劃和資訊查詢產生，以及一個 (2) 檢索器，用於根據查詢提取對應的圖形資訊。兩個代理反覆合作，實現對圖形資訊的順序推理和適應性關注。與先前的作品不同，兩個代理僅提示場景圖表綱要，而不是完整的圖形資料，這透過限制輸入代碼減少了幻覺，並驅使推論器抽象地產生推理軌跡。根據軌跡，檢索器根據綱要理解以程式化方式查詢場景圖形資料，允許對圖形進行動態和整體關注，增強推理和檢索之間的一致性。透過在多個模擬環境中的實驗，我們表明我們的框架在數值問答和規劃任務中超越了現有的基於 LLM 的方法，並且可以受益於任務級別的少次範例，即使在沒有代理級別示範的情況下也是如此。專案程式碼將會釋出。

##### **SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**
2502.03283v1 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng, Wotao Yin

Recent advancements have highlighted that Large Language Models (LLMs) are
prone to hallucinations when solving complex reasoning problems, leading to
erroneous results. To tackle this issue, researchers incorporate Knowledge
Graphs (KGs) to improve the reasoning ability of LLMs. However, existing
methods face two limitations: 1) they typically assume that all answers to the
questions are contained in KGs, neglecting the incompleteness issue of KGs, and
2) they treat the KG as a static repository and overlook the implicit logical
reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an
innovative neural-symbolic agent framework that achieves collaborative
augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments
and transform complex reasoning tasks into a multi-step interactive process,
enabling KGs to participate deeply in the reasoning process. SymAgent consists
of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages
LLM's inductive reasoning capability to extract symbolic rules from KGs,
guiding efficient question decomposition. The Agent-Executor autonomously
invokes predefined action tools to integrate information from KGs and external
documents, addressing the issues of KG incompleteness. Furthermore, we design a
self-learning framework comprising online exploration and offline iterative
policy updating phases, enabling the agent to automatically synthesize
reasoning trajectories and improve performance. Experimental results
demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields
better or comparable performance compared to various strong baselines. Further
analysis reveals that our agent can identify missing triples, facilitating
automatic KG updates.

摘要：<paragraph>最近的研究表明，大型语言模型 (LLM) 在解决复杂的推理问题时容易出现幻觉，从而导致错误的结果。为了解决这个问题，研究人员结合了知识图谱 (KG) 来提高 LLM 的推理能力。然而，现有方法面临两个局限性：1) 它们通常假设问题的答案都包含在 KG 中，忽略了 KG 不完整的问题，2) 它们将 KG 视为一个静态存储库，而忽略了 KG 中固有的隐式逻辑推理结构。在本文中，我们介绍了 SymAgent，这是一个创新的神经符号代理框架，可以在 KG 和 LLM 之间实现协作增强。我们将 KG 概念化为动态环境，并将复杂的推理任务转化为一个多步骤的交互过程，使 KG 能够深入参与推理过程。SymAgent 由两个模块组成：Agent-Planner 和 Agent-Executor。Agent-Planner 利用 LLM 的归纳推理能力从 KG 中提取符号规则，指导高效的问题分解。Agent-Executor 自主调用预定义的动作工具来整合来自 KG 和外部文档的信息，解决 KG 不完整的问题。此外，我们设计了一个自学习框架，包括在线探索和离线迭代策略更新阶段，使代理能够自动合成推理轨迹并提高性能。实验结果表明，具有弱 LLM 主干的 SymAgent（即 7B 系列）与各种强大的基线相比，产生了更好或相当的性能。进一步的分析表明，我们的代理可以识别缺失的三元组，促进自动 KG 更新。</paragraph>

##### **Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**
2502.03032v2 by Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov

We introduce a new approach to systematically map features discovered by
sparse autoencoder across consecutive layers of large language models,
extending earlier work that examined inter-layer feature links. By using a
data-free cosine similarity technique, we trace how specific features persist,
transform, or first appear at each stage. This method yields granular flow
graphs of feature evolution, enabling fine-grained interpretability and
mechanistic insights into model computations. Crucially, we demonstrate how
these cross-layer feature maps facilitate direct steering of model behavior by
amplifying or suppressing chosen features, achieving targeted thematic control
in text generation. Together, our findings highlight the utility of a causal,
cross-layer interpretability framework that not only clarifies how features
develop through forward passes but also provides new means for transparent
manipulation of large language models.

摘要：我們提出了一種新方法，用於系統性地繪製大型語言模型連續層中稀疏自動編碼器發現的功能，擴展了先前研究層間特徵連結的工作。透過使用無資料餘弦相似性技術，我們追蹤特定特徵在每個階段如何持續、轉換或首次出現。此方法產生了特徵演化的細粒度流程圖，實現了細粒度的可解釋性和對模型運算的機制見解。至關重要的是，我們展示了這些跨層特徵圖如何透過放大或抑制所選特徵來促進模型行為的直接引導，在文字生成中實現目標主題控制。我們的研究結果共同突出了因果、跨層可解釋性框架的效用，不僅闡明了特徵如何透過前向傳遞發展，還提供了新的方法來透明地操作大型語言模型。

##### **A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**
2502.02896v1 by Bradley P. Allen, Paul T. Groth

Evaluating large language models (LLMs) for tasks like fact extraction in
support of knowledge graph construction frequently involves computing accuracy
metrics using a ground truth benchmark based on a knowledge graph (KG). These
evaluations assume that errors represent factual disagreements. However, human
discourse frequently features metalinguistic disagreement, where agents differ
not on facts but on the meaning of the language used to express them. Given the
complexity of natural language processing and generation using LLMs, we ask: do
metalinguistic disagreements occur between LLMs and KGs? Based on an
investigation using the T-REx knowledge alignment dataset, we hypothesize that
metalinguistic disagreement does in fact occur between LLMs and KGs, with
potential relevance for the practice of knowledge graph engineering. We propose
a benchmark for evaluating the detection of factual and metalinguistic
disagreements between LLMs and KGs. An initial proof of concept of such a
benchmark is available on Github.

摘要：評估大型語言模型 (LLM) 執行知識圖譜建構支援事實萃取等任務時，通常會使用基於知識圖譜 (KG) 的基準事實計算準確度指標。這些評估假設錯誤代表事實上的分歧。然而，人類話語經常出現元語言分歧，其中代理人之間的差異不在於事實，而在於用於表達事實的語言的含義。鑑於使用 LLM 處理和產生自然語言的複雜性，我們提出疑問：LLM 和 KG 之間是否會發生元語言分歧？根據使用 T-REx 知識比對資料集進行的調查，我們假設元語言分歧確實會發生在 LLM 和 KG 之間，並可能與知識圖譜工程實務有關。我們提出一個基準，用於評估 LLM 和 KG 之間的事實和元語言分歧的偵測。此基準的初步概念驗證可在 Github 上取得。

##### **Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**
2502.02810v1 by Chanhui Lee, Yuheon Song, YongJun Jeong, Hanbum Ko, Rodrigo Hormazabal, Sehui Han, Kyunghoon Bae, Sungbin Lim, Sungwoong Kim

Recent advances in Large Language Models (LLMs) have motivated the
development of general LLMs for molecular tasks. While several studies have
demonstrated that fine-tuned LLMs can achieve impressive benchmark
performances, they are far from genuine generalist molecular LLMs due to a lack
of fundamental understanding of molecular structure. Specifically, when given
molecular task instructions, LLMs trained with naive next-token prediction
training assign similar likelihood scores to both original and negatively
corrupted molecules, revealing their lack of molecular structure understanding
that is crucial for reliable and general molecular LLMs. To overcome this
limitation and obtain a true generalist molecular LLM, we introduce a novel
multi-modal training method based on a thorough multi-modal instruction tuning
as well as a molecular structure preference optimization between chosen and
rejected graphs. On various molecular benchmarks, the proposed generalist
molecular LLM, called Mol-LLM, achieves state-of-the-art performances among
generalist LLMs on most tasks, at the same time, surpassing or comparable to
state-of-the-art specialist LLMs. Moreover, Mol-LLM also shows superior
generalization performances in reaction prediction tasks, demonstrating the
effect of the molecular structure understanding for generalization perspective.

摘要：大型語言模型 (LLM) 的近期進展激勵了針對分子任務開發通用 LLM。雖然多項研究已證明微調 LLM 可實現令人印象深刻的基準效能，但由於缺乏對分子結構的基本理解，它們遠非真正的通才分子 LLM。具體來說，當給予分子任務說明時，使用天真的下一個符號預測訓練訓練的 LLM 會將類似的可能性評分分配給原始分子和負面損壞分子，這顯示出它們缺乏對分子結構的理解，而這對於可靠且通用的分子 LLM 至關重要。為了克服這個限制並獲得真正的通才分子 LLM，我們引入了一種新穎的多模態訓練方法，該方法基於徹底的多模態說明調整以及在所選和拒絕圖形之間的分子結構偏好最佳化。在各種分子基準測試中，所提出的通才分子 LLM（稱為 Mol-LLM）在多數任務中實現了通才 LLM 中的最新效能，同時超越或與最新的專家 LLM 相當。此外，Mol-LLM 在反應預測任務中也展現出優異的泛化效能，證明了分子結構理解對泛化觀點的影響。

##### **Leveraging the true depth of LLMs**
2502.02790v1 by Ramón Calvo González, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, François Fleuret

Large Language Models demonstrate remarkable capabilities at the cost of high
compute requirements. While recent research has shown that intermediate layers
can be removed or have their order shuffled without impacting performance
significantly, these findings have not been employed to reduce the
computational cost of inference. We investigate several potential ways to
reduce the depth of pre-trained LLMs without significantly affecting
performance. Leveraging our insights, we present a novel approach that exploits
this decoupling between layers by grouping some of them into pairs that can be
evaluated in parallel.
  This modification of the computational graph -- through better parallelism --
results in an average improvement of around 1.20x on the number of tokens
generated per second, without re-training nor fine-tuning, while retaining
95%-99% of the original accuracy. Empirical evaluation demonstrates that this
approach significantly improves serving efficiency while maintaining model
performance, offering a practical improvement for large-scale LLM deployment.

摘要：大型语言模型展示了其强大的功能，但代价是较高的计算需求。虽然最近的研究表明，中间层可以被移除或重新排列其顺序，而不会显著影响性能，但这些发现尚未被用来降低推理的计算成本。我们研究了几种潜在的方法来减少预训练 LLM 的深度，而不会显著影响性能。利用我们的见解，我们提出了一种新颖的方法，该方法通过将其中一些分组为可以并行评估的成对来利用层之间的这种解耦。
通过更好的并行性对计算图进行修改，平均而言，每秒生成的令牌数量提高了约 1.20 倍，而无需重新训练或微调，同时保留了 95%-99% 的原始准确性。经验评估表明，这种方法显著提高了服务效率，同时保持了模型性能，为大规模 LLM 部署提供了实际改进。

##### **Modular Training of Neural Networks aids Interpretability**
2502.02470v2 by Satvik Golechha, Maheep Chaudhary, Joan Velja, Alessandro Abate, Nandi Schoots

An approach to improve neural network interpretability is via clusterability,
i.e., splitting a model into disjoint clusters that can be studied
independently. We define a measure for clusterability and show that pre-trained
models form highly enmeshed clusters via spectral graph clustering. We thus
train models to be more modular using a "clusterability loss" function that
encourages the formation of non-interacting clusters. Using automated
interpretability techniques, we show that our method can help train models that
are more modular and learn different, disjoint, and smaller circuits. We
investigate CNNs trained on MNIST and CIFAR, small transformers trained on
modular addition, and language models. Our approach provides a promising
direction for training neural networks that learn simpler functions and are
easier to interpret.

摘要：一種改善神經網路可解釋性的方法是透過群集性，
也就是將模型分割成可獨立研究的不相交群集。我們定義一個群集性的度量，並顯示預訓練的
模型透過光譜圖形群集形成高度糾纏的群集。因此，我們使用「群集性損失」函數訓練模型，使其更具模組化，
這鼓勵形成非交互群集。使用自動化可解釋性技術，我們顯示我們的模型可以幫助訓練更具模組化的模型，並學習不同、不相交且較小的電路。我們
研究了在 MNIST 和 CIFAR 上訓練的 CNN，在模組化加法上訓練的小型Transformer，以及語言模型。我們的做法為訓練學習更簡單函數且更容易解釋的神經網路提供了有希望的方向。

##### **Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs**
2502.02362v2 by Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani Tur

Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large
language models (LLMs) by enabling detailed step-by-step solutions. However,
due to the verbosity of LLMs, the resulting reasoning chains can be long,
making it harder to verify the reasoning steps and trace issues resulting from
dependencies between the steps that may be farther away in the sequence of
steps. Importantly, mathematical reasoning allows each step to be derived from
a small set of premises, which are a subset of the preceding steps in the
reasoning chain. In this paper, we present a framework that identifies the
premises for each step, to improve the evaluation of reasoning. We restructure
conventional linear reasoning chains into Premise Augmented Reasoning Chains
(PARC) by introducing premise links, resulting in a directed acyclic graph
where the nodes are the steps and the edges are the premise links. Through
experiments with a PARC-based dataset that we built, namely PERL (Premises and
ERrors identification in LLMs), we demonstrate that LLMs can reliably identify
premises within complex reasoning chains. In particular, even open-source LLMs
achieve 90% recall in premise identification. We also show that PARC helps to
identify errors in reasoning chains more reliably. The accuracy of error
identification improves by 6% to 16% absolute when step-by-step verification is
carried out in PARC under the premises. Our findings highlight the utility of
premise-centric representations in addressing complex problem-solving tasks and
open new avenues for improving the reliability of LLM-based reasoning
evaluations.

摘要：<paragraph>鏈式思考 (CoT) 提示透過提供詳細的逐步解法，增強大型語言模型 (LLM) 的數學推理能力。然而，由於 LLM 的冗長性，產生的推理鏈條可能會很長，這使得驗證推理步驟和追蹤步驟之間相依性所導致的問題變得更加困難，而這些步驟可能出現在步驟順序中較遠的地方。重要的是，數學推理允許每一步都從一組小的前提推導出來，而這些前提是推理鏈條中前一步的子集。在本文中，我們提出一個框架來識別每個步驟的前提，以改進推理評估。我們透過引入前提連結，將傳統的線性推理鏈條重新建構為前提擴充推理鏈條 (PARC)，形成一個有向無環圖，其中節點為步驟，而邊緣為前提連結。透過我們建立的基於 PARC 的資料集 (PERL，即 LLM 中的前提和錯誤識別) 進行的實驗，我們證明 LLM 能夠在複雜的推理鏈條中可靠地識別前提。特別是，即使是開放原始碼的 LLM 也能在前提識別中達到 90% 的召回率。我們還表明，PARC 有助於更可靠地識別推理鏈條中的錯誤。在前提下於 PARC 中執行逐步驗證時，錯誤識別的準確度提高了 6% 至 16% 的絕對值。我們的研究結果突顯了以前提為中心的表示在解決複雜問題解決任務中的效用，並為改進基於 LLM 的推理評估的可靠性開闢了新的途徑。</paragraph>

##### **AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement**
2502.02067v1 by Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna

Embodied agents assisting humans are often asked to complete a new task in a
new scenario. An agent preparing a particular dish in the kitchen based on a
known recipe may be asked to prepare a new dish or to perform cleaning tasks in
the storeroom. There may not be sufficient resources, e.g., time or labeled
examples, to train the agent for these new situations. Large Language Models
(LLMs) trained on considerable knowledge across many domains are able to
predict a sequence of abstract actions for such new tasks and scenarios,
although it may not be possible for the agent to execute this action sequence
due to task-, agent-, or domain-specific constraints. Our framework addresses
these challenges by leveraging the generic predictions provided by LLM and the
prior domain-specific knowledge encoded in a Knowledge Graph (KG), enabling an
agent to quickly adapt to new tasks and scenarios. The robot also solicits and
uses human input as needed to refine its existing knowledge. Based on
experimental evaluation over cooking and cleaning tasks in simulation domains,
we demonstrate that the interplay between LLM, KG, and human input leads to
substantial performance gains compared with just using the LLM output.

摘要：具身代理协助人类时，通常需要在新的情境中完成新的任务。基于已知食谱在厨房准备特定菜肴的代理可能会被要求准备新菜肴或在储藏室执行清洁任务。可能没有足够资源（例如时间或标记的示例）来训练代理以应对这些新情况。在许多领域接受大量知识训练的大型语言模型 (LLM) 能够预测此类新任务和情境的抽象动作序列，尽管代理可能无法执行此动作序列，因为任务、代理或特定于域的约束。我们的框架通过利用 LLM 提供的通用预测和知识图 (KG) 中编码的先前特定于域的知识来应对这些挑战，使代理能够快速适应新任务和情境。该机器人还会根据需要征求并使用人类输入来完善其现有知识。基于在模拟域中对烹饪和清洁任务的实验评估，我们证明了 LLM、KG 和人类输入之间的相互作用与仅使用 LLM 输出相比带来了巨大的性能提升。

##### **On Bob Dylan: A Computational Perspective**
2502.01772v1 by Prashant Garg

Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style
-- a constant refusal to conform to expectation and a penchant for reinventing
his musical and lyrical identity. In this paper, I extend Sunstein's
observations through a large-scale computational analysis of Dylan's lyrics
from 1962 to 2012. Using o3-mini-high (a large language model), I extract
concept-to-concept relationships from the lyrics and construct directed
knowledge graphs that capture Dylan's thematic structure. I then quantify
shifts in sentiment, metaphorical expression, thematic diversity, and network
complexity over time. The results indicate that Dylan's lyrics increasingly
rely on metaphor, display an evolving sentiment profile, and exhibit heightened
dishabituation -- measured here as a growing variance in the network centrality
of key concepts. I also find that references to movement, protest, and mythic
imagery fluctuate in ways that align with well-known phases of Dylan's career,
reflecting the dynamic and unpredictable quality of his art. These findings not
only deepen our empirical understanding of Sunstein's thesis but also introduce
a novel computational method for analyzing an artist's evolution-offering
broader applicability to the study of cultural and creative change.

摘要：卡斯·桑斯坦的論文「論鮑伯·迪倫」描述了迪倫「去習慣化」的風格
-- 這種風格不斷拒絕符合預期，並熱衷於重新塑造他的音樂和歌詞認同。在本文中，我透過對迪倫 1962 年至 2012 年歌詞進行大規模的運算分析，來延伸桑斯坦的觀察。使用 o3-mini-high（一個大型語言模型），我從歌詞中提取概念對概念的關係，並建構有向知識圖，以捕捉迪倫的主題結構。然後，我量化情緒、隱喻表達、主題多樣性和網路複雜性隨時間的變化。結果顯示，迪倫的歌詞越來越依賴隱喻，展現出不斷演化的情緒輪廓，並表現出高度的去習慣化 -- 在這裡測量為關鍵概念的網路中心性的變異增加。我也發現，對運動、抗議和神話意象的引用，會以與迪倫職業生涯中眾所周知階段一致的方式波動，反映了他藝術的動態和不可預測的品質。這些發現不僅加深了我們對桑斯坦論文的經驗理解，也引入了分析藝術家演變的新穎運算方法，為文化和創造性變化的研究提供了更廣泛的適用性。

##### **VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**
2502.01549v1 by Xubin Ren, Lingrui Xu, Long Xia, Shuaiqiang Wang, Dawei Yin, Chao Huang

Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in
enhancing Large Language Models (LLMs) through external knowledge integration,
yet its application has primarily focused on textual content, leaving the rich
domain of multi-modal video knowledge predominantly unexplored. This paper
introduces VideoRAG, the first retrieval-augmented generation framework
specifically designed for processing and understanding extremely long-context
videos. Our core innovation lies in its dual-channel architecture that
seamlessly integrates (i) graph-based textual knowledge grounding for capturing
cross-video semantic relationships, and (ii) multi-modal context encoding for
efficiently preserving visual features. This novel design empowers VideoRAG to
process unlimited-length videos by constructing precise knowledge graphs that
span multiple videos while maintaining semantic dependencies through
specialized multi-modal retrieval paradigms. Through comprehensive empirical
evaluation on our proposed LongerVideos benchmark-comprising over 160 videos
totaling 134+ hours across lecture, documentary, and entertainment
categories-VideoRAG demonstrates substantial performance compared to existing
RAG alternatives and long video understanding methods. The source code of
VideoRAG implementation and the benchmark dataset are openly available at:
https://github.com/HKUDS/VideoRAG.

摘要：檢索增強生成 (RAG) 已證明在透過外部知識整合增強大型語言模型 (LLM) 方面取得顯著成功，但其應用主要集中在文字內容上，而豐富的多模態影片知識領域則鮮少被探索。本文介紹 VideoRAG，這是第一個檢索增強生成架構，專門設計用於處理和理解極長語境的影片。我們的核心創新在於其雙通道架構，它無縫整合 (i) 基於圖形文字知識基礎，用於擷取跨影片語義關係，以及 (ii) 多模態語境編碼，用於有效保留視覺特徵。這個新穎的設計讓 VideoRAG 能夠透過建構跨越多個影片的精確知識圖譜來處理長度不限的影片，同時透過專門的多模態檢索範例來維持語義依賴性。透過我們提出的 LongerVideos 基準的全面經驗評估，該基準包含超過 160 部影片，總時數超過 134 小時，涵蓋演講、紀錄片和娛樂類別，VideoRAG 與現有的 RAG 替代方案和長影片理解方法相比，展現出顯著的效能。VideoRAG 實作的原始碼和基準資料集已公開於：https://github.com/HKUDS/VideoRAG。

##### **Transformers trained on proteins can learn to attend to Euclidean distance**
2502.01533v1 by Isaac Ellmen, Constantin Schneider, Matthew I. J. Raybould, Charlotte M. Deane

While conventional Transformers generally operate on sequence data, they can
be used in conjunction with structure models, typically SE(3)-invariant or
equivariant graph neural networks (GNNs), for 3D applications such as protein
structure modelling. These hybrids typically involve either (1)
preprocessing/tokenizing structural features as input for Transformers or (2)
taking Transformer embeddings and processing them within a structural
representation. However, there is evidence that Transformers can learn to
process structural information on their own, such as the AlphaFold3 structural
diffusion model. In this work we show that Transformers can function
independently as structure models when passed linear embeddings of coordinates.
We first provide a theoretical explanation for how Transformers can learn to
filter attention as a 3D Gaussian with learned variance. We then validate this
theory using both simulated 3D points and in the context of masked token
prediction for proteins. Finally, we show that pre-training protein Transformer
encoders with structure improves performance on a downstream task, yielding
better performance than custom structural models. Together, this work provides
a basis for using standard Transformers as hybrid structure-language models.

摘要：雖然傳統的 Transformer 通常處理序列資料，但它們可用於結構模型，通常是 SE(3) 不變式或等變式圖神經網路 (GNN)，用於蛋白質結構建模等 3D 應用。這些混合模型通常包含 (1) 將結構特徵預處理/標記化為 Transformer 的輸入或 (2) 取用 Transformer 嵌入並在結構表示中處理它們。然而，有證據表明 Transformer 可以自行學習處理結構資訊，例如 AlphaFold3 結構擴散模型。在這項工作中，我們展示了 Transformer 在傳遞座標的線性嵌入時，可以獨立作為結構模型運作。我們首先提供了 Transformer 如何學習將注意力濾波為具有學習變異的 3D 高斯的理論解釋。然後我們使用模擬 3D 點和在蛋白質遮罩標記預測的背景下驗證此理論。最後，我們展示了使用結構預訓練蛋白質 Transformer 編碼器會改善下游任務的效能，產生比自訂結構模型更好的效能。綜合來說，這項工作提供了使用標準 Transformer 作為混合結構語言模型的基礎。

##### **Common Foundations for SHACL, ShEx, and PG-Schema**
2502.01295v1 by S. Ahmetaj, I. Boneva, J. Hidders, K. Hose, M. Jakubowski, J. E. Labra-Gayo, W. Martens, F. Mogavero, F. Murlak, C. Okulmus, A. Polleres, O. Savkovic, M. Simkus, D. Tomaszuk

Graphs have emerged as an important foundation for a variety of applications,
including capturing and reasoning over factual knowledge, semantic data
integration, social networks, and providing factual knowledge for machine
learning algorithms. To formalise certain properties of the data and to ensure
data quality, there is a need to describe the schema of such graphs. Because of
the breadth of applications and availability of different data models, such as
RDF and property graphs, both the Semantic Web and the database community have
independently developed graph schema languages: SHACL, ShEx, and PG-Schema.
Each language has its unique approach to defining constraints and validating
graph data, leaving potential users in the dark about their commonalities and
differences. In this paper, we provide formal, concise definitions of the core
components of each of these schema languages. We employ a uniform framework to
facilitate a comprehensive comparison between the languages and identify a
common set of functionalities, shedding light on both overlapping and
distinctive features of the three languages.

摘要：圖表已成為各種應用的重要基礎，包括擷取和推理事實知識、語義資料整合、社群網路，以及為機器學習演算法提供事實知識。為了形式化資料的特定屬性並確保資料品質，有必要描述此類圖表的架構。由於應用範圍廣泛且有不同的資料模型可用，例如 RDF 和屬性圖表，因此語義網路和資料庫社群已獨立開發圖表架構語言：SHACL、ShEx 和 PG-Schema。每種語言都有其定義約束和驗證圖表資料的獨特方法，讓潛在使用者不清楚它們的共性和差異。在本文中，我們提供這些架構語言中每個核心元件的正式簡潔定義。我們採用統一的框架來促進語言之間的全面比較，並找出功能的共同集合，說明這三種語言的重疊和獨特功能。

##### **GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**
2502.01113v1 by Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Dinh Phung, Chen Gong, Shirui Pan

Retrieval-augmented generation (RAG) has proven effective in integrating
knowledge into large language models (LLMs). However, conventional RAGs
struggle to capture complex relationships between pieces of knowledge, limiting
their performance in intricate reasoning that requires integrating knowledge
from multiple sources. Recently, graph-enhanced retrieval augmented generation
(GraphRAG) builds graph structure to explicitly model these relationships,
enabling more effective and efficient retrievers. Nevertheless, its performance
is still hindered by the noise and incompleteness within the graph structure.
To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for
retrieval augmented generation. GFM-RAG is powered by an innovative graph
neural network that reasons over graph structure to capture complex
query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage
training process on large-scale datasets, comprising 60 knowledge graphs with
over 14M triples and 700k documents. This results in impressive performance and
generalizability for GFM-RAG, making it the first graph foundation model
applicable to unseen datasets for retrieval without any fine-tuning required.
Extensive experiments on three multi-hop QA datasets and seven domain-specific
RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance
while maintaining efficiency and alignment with neural scaling laws,
highlighting its potential for further improvement.

摘要：檢索增強生成 (RAG) 已證明在整合知識到大語言模型 (LLM) 中有效。然而，傳統的 RAG 難以捕捉知識片段之間的複雜關係，限制了它們在需要整合來自多個來源的知識的複雜推理中的表現。最近，圖表增強檢索增強生成 (GraphRAG) 建立圖表結構來明確建模這些關係，從而實現更有效率的檢索器。儘管如此，其效能仍受到圖表結構中雜訊和不完整性的阻礙。為了解決這個問題，我們引入了 GFM-RAG，一種用於檢索增強生成的全新圖表基礎模型 (GFM)。GFM-RAG 由一個創新的圖神經網路驅動，該網路在圖表結構上進行推理以捕捉複雜的查詢知識關係。具有 8M 參數的 GFM 在大型資料集上進行兩階段訓練流程，包括 60 個包含超過 14M 個三元組和 700k 個文件的文件。這為 GFM-RAG 帶來了令人印象深刻的效能和通用性，使其成為第一個適用於未見過資料集的圖表基礎模型，而無需任何微調。在三個多跳問答資料集和七個特定領域 RAG 資料集上的廣泛實驗表明，GFM-RAG 達到了最先進的效能，同時保持了效率並與神經擴充定律保持一致，突顯了其進一步改進的潛力。

##### **Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**
2502.01059v1 by Seungri Yoon, Woosang Jeon, Sanghyeok Choi, Taehyeong Kim, Tae In Ahn

The development of biological data analysis tools and large language models
(LLMs) has opened up new possibilities for utilizing AI in plant science
research, with the potential to contribute significantly to knowledge
integration and research gap identification. Nonetheless, current LLMs struggle
to handle complex biological data and theoretical models in photosynthesis
research and often fail to provide accurate scientific contexts. Therefore,
this study proposed a photosynthesis research assistant (PRAG) based on
OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt
optimization. Vector databases and an automated feedback loop were used in the
prompt optimization process to enhance the accuracy and relevance of the
responses to photosynthesis-related queries. PRAG showed an average improvement
of 8.7% across five metrics related to scientific writing, with a 25.4%
increase in source transparency. Additionally, its scientific depth and domain
coverage were comparable to those of photosynthesis research papers. A
knowledge graph was used to structure PRAG's responses with papers within and
outside the database, which allowed PRAG to match key entities with 63% and
39.5% of the database and test papers, respectively. PRAG can be applied for
photosynthesis research and broader plant science domains, paving the way for
more in-depth data analysis and predictive capabilities.

摘要：生物資料分析工具和大型語言模型 (LLM) 的發展，為利用人工智慧於植物科學研究開啟了新的可能性，並有潛力對知識整合和研究差距的識別做出重大貢獻。儘管如此，目前的 LLM 在處理光合作用研究中的複雜生物資料和理論模型時仍有困難，而且常常無法提供準確的科學背景。因此，本研究提出了一個基於 OpenAI 的 GPT-4o、具備檢索增強生成 (RAG) 技術和提示最佳化的光合作用研究助理 (PRAG)。在提示最佳化過程中，使用了向量資料庫和自動回饋迴路，以增強對與光合作用相關查詢的回應的準確性和相關性。PRAG 在與科學寫作相關的五項指標中顯示出平均改善了 8.7%，來源透明度增加了 25.4%。此外，其科學深度和領域涵蓋範圍與光合作用研究論文相當。知識圖譜用於建構 PRAG 的回應，其中包含資料庫內外論文，這使得 PRAG 能夠分別與資料庫和測試論文中的 63% 和 39.5% 的關鍵實體相匹配。PRAG 可應用於光合作用研究和更廣泛的植物科學領域，為更深入的資料分析和預測能力鋪路。

##### **Encrypted Large Model Inference: The Equivariant Encryption Paradigm**
2502.01013v1 by James Buban, Hongyang Zhang, Claudio Angione, Harry Yang, Ahmad Farhan, Seyfal Sultanov, Michael Du, Xuran Ma, Zihao Wang, Yue Zhao, Arria Owlia, Fielding Johnston, Patrick Colangelo

Large scale deep learning model, such as modern language models and diffusion
architectures, have revolutionized applications ranging from natural language
processing to computer vision. However, their deployment in distributed or
decentralized environments raises significant privacy concerns, as sensitive
data may be exposed during inference. Traditional techniques like secure
multi-party computation, homomorphic encryption, and differential privacy offer
partial remedies but often incur substantial computational overhead, latency
penalties, or limited compatibility with non-linear network operations. In this
work, we introduce Equivariant Encryption (EE), a novel paradigm designed to
enable secure, "blind" inference on encrypted data with near zero performance
overhead. Unlike fully homomorphic approaches that encrypt the entire
computational graph, EE selectively obfuscates critical internal
representations within neural network layers while preserving the exact
functionality of both linear and a prescribed set of non-linear operations.
This targeted encryption ensures that raw inputs, intermediate activations, and
outputs remain confidential, even when processed on untrusted infrastructure.
We detail the theoretical foundations of EE, compare its performance and
integration complexity against conventional privacy preserving techniques, and
demonstrate its applicability across a range of architectures, from
convolutional networks to large language models. Furthermore, our work provides
a comprehensive threat analysis, outlining potential attack vectors and
baseline strategies, and benchmarks EE against standard inference pipelines in
decentralized settings. The results confirm that EE maintains high fidelity and
throughput, effectively bridging the gap between robust data confidentiality
and the stringent efficiency requirements of modern, large scale model
inference.

摘要：大型深度學習模型，例如現代語言模型和擴散架構，徹底改變了從自然語言處理到電腦視覺等各種應用。然而，它們在分散式或分散式環境中的部署引發了重大的隱私問題，因為敏感數據可能會在推理過程中遭到揭露。安全多方計算、同態加密和差分隱私等傳統技術提供了部分補救措施，但通常會產生大量的計算開銷、延遲處罰，或與非線性網路操作相容性有限。在這項工作中，我們引入了等變加密 (EE)，這是一種新穎的範例，旨在以接近零效能開銷對加密數據進行安全、「盲目」推理。與加密整個計算圖形的完全同態方法不同，EE 有選擇性地混淆神經網路層內的關鍵內部表示，同時保留線性和規定的一組非線性操作的精確功能。這種有針對性的加密確保了原始輸入、中間激活和輸出保持機密，即使在不受信任的基礎設施上處理也是如此。我們詳細說明了 EE 的理論基礎，比較了其效能和整合複雜度與傳統的隱私保護技術，並展示了其在從卷積網路到大語言模型等各種架構中的適用性。此外，我們的研究提供了全面的威脅分析，概述了潛在的攻擊媒介和基準策略，並在分散式設定中將 EE 與標準推理管道進行比較。結果證實，EE 保持了高保真度和高傳輸量，有效地彌合了強大的數據機密性與現代化、大規模模型推理的嚴格效率要求之間的差距。

##### **Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation**
2502.01694v1 by Juno Kim, Denny Wu, Jason Lee, Taiji Suzuki

A key paradigm to improve the reasoning capabilities of large language models
(LLMs) is to allocate more inference-time compute to search against a verifier
or reward model. This process can then be utilized to refine the pretrained
model or distill its reasoning patterns into more efficient models. In this
paper, we study inference-time compute by viewing chain-of-thought (CoT)
generation as a metastable Markov process: easy reasoning steps (e.g.,
algebraic manipulations) form densely connected clusters, while hard reasoning
steps (e.g., applying a relevant theorem) create sparse, low-probability edges
between clusters, leading to phase transitions at longer timescales. Under this
framework, we prove that implementing a search protocol that rewards sparse
edges improves CoT by decreasing the expected number of steps to reach
different clusters. In contrast, we establish a limit on reasoning capability
when the model is restricted to local information of the pretrained graph. We
also show that the information gained by search can be utilized to obtain a
better reasoning model: (1) the pretrained model can be directly finetuned to
favor sparse edges via policy gradient methods, and moreover (2) a compressed
metastable representation of the reasoning dynamics can be distilled into a
smaller, more efficient model.

摘要：<paragraph>提升大型語言模型 (LLM) 推理能力的一個關鍵範例，是分配更多推論時間運算來搜尋驗證器或獎勵模型。此程序接著可用於改善預訓練模型或將其推理模式提煉到更有效率的模型中。在這篇論文中，我們透過將思維鏈 (CoT) 生成視為亞穩態馬可夫過程來研究推論時間運算：簡單的推理步驟（例如代數運算）形成密集連接的叢集，而困難的推理步驟（例如應用相關定理）則在叢集之間建立稀疏、低機率的邊緣，導致在較長時間尺度上產生相變。在此架構下，我們證明實作一種獎勵稀疏邊緣的搜尋協定，會透過減少到達不同叢集所需的預期步驟數來改善 CoT。相反地，當模型受限於預訓練圖形的局部資訊時，我們建立了推理能力的限制。我們也顯示搜尋所獲得的資訊可用於取得更好的推理模型：(1) 預訓練模型可以直接微調以透過策略梯度方法偏好稀疏邊緣，而且 (2) 推理動態的壓縮亞穩態表徵可以提煉到更小、更有效率的模型中。</paragraph>

##### **PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation**
2502.00708v1 by Qixuan Li, Chao Wang, Zongjin He, Yan Peng

Text-to-3D asset generation has achieved significant optimization under the
supervision of 2D diffusion priors. However, when dealing with compositional
scenes, existing methods encounter several challenges: 1). failure to ensure
that composite scene layouts comply with physical laws; 2). difficulty in
accurately capturing the assets and relationships described in complex scene
descriptions; 3). limited autonomous asset generation capabilities among layout
approaches leveraging large language models (LLMs). To avoid these compromises,
we propose a novel framework for compositional scene generation, PhiP-G, which
seamlessly integrates generation techniques with layout guidance based on a
world model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene
description to generate a scene graph, and integrating a multimodal 2D
generation agent and a 3D Gaussian generation method for targeted assets
creation. For the stage of layout, PhiP-G employs a physical pool with adhesion
capabilities and a visual supervision agent, forming a world model for layout
prediction and planning. Extensive experiments demonstrate that PhiP-G
significantly enhances the generation quality and physical rationality of the
compositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA)
performance in CLIP scores, achieves parity with the leading methods in
generation quality as measured by the T$^3$Bench, and improves efficiency by
24x.

摘要：<paragraph>在 2D 擴散先驗的監督下，文字轉 3D 資產生成已取得顯著的最佳化。然而，在處理合成場景時，現有方法會遇到幾個挑戰：1) 無法確保複合場景佈局符合物理定律；2) 難以準確捕捉複雜場景描述中所描述的資產和關係；3) 在利用大型語言模型 (LLM) 的佈局方法中，自主資產生成能力有限。為了避免這些折衷，我們提出了一個合成場景生成的新框架 PhiP-G，它將生成技術與基於世界模型的佈局指導無縫整合。利用基於 LLM 的代理，PhiP-G 分析複雜的場景描述以生成場景圖，並整合多模態 2D 生成代理和 3D 高斯生成方法以進行目標資產創建。對於佈局階段，PhiP-G 採用具有附著能力的物理池和視覺監督代理，形成用於佈局預測和規劃的世界模型。大量的實驗證明，PhiP-G 大幅提升了合成場景的生成品質和物理合理性。值得注意的是，PhiP-G 在 CLIP 分數中獲得了最先進 (SOTA) 的效能，在 T$^3$Bench 測量的生成品質中與領先的方法達到同等水準，並將效率提升了 24 倍。</paragraph>

##### **A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models**
2502.00681v1 by Qika Lin, Zhen Peng, Kaize Shi, Kai He, Yiming Xu, Erik Cambria, Mengling Feng

Recent years have witnessed rapid advances in graph representation learning,
with the continuous embedding approach emerging as the dominant paradigm.
However, such methods encounter issues regarding parameter efficiency,
interpretability, and robustness. Thus, Quantized Graph Representation (QGR)
learning has recently gained increasing interest, which represents the graph
structure with discrete codes instead of conventional continuous embeddings.
Given its analogous representation form to natural language, QGR also possesses
the capability to seamlessly integrate graph structures with large language
models (LLMs). As this emerging paradigm is still in its infancy yet holds
significant promise, we undertake this thorough survey to promote its rapid
future prosperity. We first present the background of the general quantization
methods and their merits. Moreover, we provide an in-depth demonstration of
current QGR studies from the perspectives of quantized strategies, training
objectives, distinctive designs, knowledge graph quantization, and
applications. We further explore the strategies for code dependence learning
and integration with LLMs. At last, we give discussions and conclude future
directions, aiming to provide a comprehensive picture of QGR and inspire future
research.

摘要：近年来，图表示学习取得了快速进展，其中连续嵌入方法作为主导范式出现。然而，此类方法遇到了参数效率、可解释性和鲁棒性方面的问题。因此，量化图表示 (QGR) 学习最近引起了越来越多的兴趣，它使用离散代码而不是传统的连续嵌入来表示图结构。鉴于其与自然语言类似的表示形式，QGR 也具备将图结构与大型语言模型 (LLM) 无缝集成的能力。由于这种新兴范式仍处于起步阶段，但前景广阔，我们进行了这项全面调查以促进其快速未来的繁荣。我们首先介绍了通用量化方法的背景及其优点。此外，我们从量化策略、训练目标、独特设计、知识图谱量化和应用的角度对当前的 QGR 研究进行了深入的论证。我们进一步探索了代码依赖性学习和与 LLM 集成的策略。最后，我们给出了讨论并总结了未来的方向，旨在提供 QGR 的全面图景并激发未来的研究。

##### **Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions**
2502.00339v1 by Jingyuan Yi, Zeqiu Xu, Tianyi Huang, Peiyang Yu

The pervasiveness of the dissemination of fake news through social media
platforms poses critical risks to the trust of the general public, societal
stability, and democratic institutions. This challenge calls for novel
methodologies in detection, which can keep pace with the dynamic and
multi-modal nature of misinformation. Recent works include powering the
detection using large language model advances in multimodal frameworks,
methodologies using graphs, and adversarial training in the literature of fake
news. Based on the different approaches which can bring success, some key
highlights will be underlined: enhanced LLM-improves accuracy through more
advanced semantics and cross-modality fusion for robust detections. The review
further identifies critical gaps in adaptability to dynamic social media
trends, real-time, and cross-platform detection capabilities, as well as the
ethical challenges thrown up by the misuse of LLMs. Future directions underline
the development of style-agnostic models, cross-lingual detection frameworks,
and robust policies with a view to mitigating LLM-driven misinformation. This
synthesis thus lays a concrete foundation for those researchers and
practitioners committed to reinforcing fake news detection systems with
complications that keep on growing in the digital landscape.

摘要：社群媒體平台上假新聞散播的普遍性對一般大眾的信任、社會穩定性與民主制度構成重大風險。這項挑戰需要在偵測方面採用創新的方法論，才能跟上錯誤資訊的動態和多模態特性。最近的研究包括使用多模態架構中大型語言模型的進展、使用圖形的方法論，以及在假新聞文獻中進行對抗訓練來強化偵測。根據可以帶來成功的不同方法，將重點說明一些重點：增強的 LLM 可透過更進階的語意和跨模態融合來提升準確度，以進行穩健的偵測。這篇評論進一步找出在適應動態社群媒體趨勢、即時和跨平台偵測能力方面的重大差距，以及 LLM 遭濫用的道德挑戰。未來的方向強調開發與風格無關的模型、跨語言偵測架構和穩健的政策，以減輕 LLM 驅動的錯誤資訊。因此，這種綜合分析為那些致力於強化假新聞偵測系統的研究人員和從業人員奠定了具體的基礎，而這些複雜性在數位環境中持續增長。

##### **DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning**
2502.00305v1 by Jiaxin Guo, C. L. Philip Chen, Shuzhen Li, Tong Zhang

Cold-start active learning (CSAL) selects valuable instances from an
unlabeled dataset for manual annotation. It provides high-quality data at a low
annotation cost for label-scarce text classification. However, existing CSAL
methods overlook weak classes and hard representative examples, resulting in
biased learning. To address these issues, this paper proposes a novel
dual-diversity enhancing and uncertainty-aware (DEUCE) framework for CSAL.
Specifically, DEUCE leverages a pretrained language model (PLM) to efficiently
extract textual representations, class predictions, and predictive uncertainty.
Then, it constructs a Dual-Neighbor Graph (DNG) to combine information on both
textual diversity and class diversity, ensuring a balanced data distribution.
It further propagates uncertainty information via density-based clustering to
select hard representative instances. DEUCE performs well in selecting
class-balanced and hard representative data by dual-diversity and
informativeness. Experiments on six NLP datasets demonstrate the superiority
and efficiency of DEUCE.

摘要：冷啟動主動學習 (CSAL) 從未標記的資料集中選取有價值的實例進行手動標記。它以低標記成本提供高品質的資料，用於標籤稀少的文字分類。然而，現有的 CSAL 方法忽略了弱類別和難以代表的範例，導致有偏差的學習。為了解決這些問題，本文提出了一個新的雙重多樣性增強和不確定性感知 (DEUCE) 架構，用於 CSAL。具體來說，DEUCE 利用預訓練的語言模型 (PLM) 來有效地提取文字表徵、類別預測和預測不確定性。然後，它構建一個雙鄰居圖 (DNG) 來結合文字多樣性和類別多樣性的資訊，確保平衡的資料分佈。它進一步通過基於密度的聚類來傳播不確定性資訊，以選擇難以代表的實例。DEUCE 在通過雙重多樣性和資訊性選擇類別平衡和難以代表的資料方面表現良好。在六個 NLP 資料集上的實驗證明了 DEUCE 的優越性和效率。

##### **Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques**
2502.01659v2 by Nathaniel Tomczak, Sanmukh Kuppannagari

Transformers have demonstrated great success in numerous domains including
natural language processing and bioinformatics. This success stems from the use
of the attention mechanism by these models in order to represent and propagate
pairwise interactions between individual tokens of sequential data. However,
the primary limitation of this operation is its quadratic memory and time
complexity in relation to the input's context length - the length of a sequence
over which the interactions need to be captured. This significantly limits the
length of sequences that can be inferred upon by these models. Extensive
research has been conducted to reduce the number of pairwise interactions to
sub-quadratic in relation to the context length by introducing sparsity into
the attention mechanism through the development of sparse attention masks.
However, efficient implementations that achieve "true sparsity" are lacking.
  In this work, we address this issue by proposing a graph computing view of
attention where tokens are perceived as nodes of the graph and the attention
mask determines the edges of the graph. Using this view, we develop graph
processing algorithms to implement the attention mechanism. Both theoretically
and empirically, we demonstrate that our algorithms only perform the needed
computations, i.e., they are work optimal. We also perform extensive
experimentation using popular attention masks to explore the impact of sparsity
on execution time and achievable context length. Our experiments demonstrate
significant speedups in execution times compared to state-of-the-art attention
implementations such as FlashAttention for large sequence lengths. We also
demonstrate that our algorithms are able to achieve extremely long sequence
lengths of as high as 160 million on a single NVIDIA A100 GPU (SXM4 80GB).

摘要：變形金剛已在許多領域展現出巨大的成功，包括自然語言處理和生物資訊學。這種成功源自於這些模型使用注意機制來表示和傳播序列資料中各個標記之間成對的互動。然而，這種運算的主要限制在於其二次記憶體和時間複雜度與輸入的內容長度有關，也就是需要擷取互動的序列長度。這會顯著限制這些模型可以推論的序列長度。已經進行了大量的研究來減少成對互動的數量，使其與內容長度成次二次關係，方法是透過開發稀疏注意遮罩來將稀疏性引入注意機制。然而，缺乏能達成「真實稀疏性」的高效實作。在這項工作中，我們透過提出注意力的圖形運算檢視來解決這個問題，其中標記被視為圖形的節點，而注意力遮罩則決定圖形中的邊緣。使用這種檢視，我們開發了圖形處理演算法來實作注意力機制。我們在理論上和經驗上都證明了我們的演算法只執行必要的運算，也就是說，它們是工作最優的。我們也使用流行的注意力遮罩進行廣泛的實驗，以探討稀疏性對執行時間和可達成的內容長度的影響。我們的實驗證明，與最先進的注意力實作（例如 FlashAttention）相比，對於大型序列長度，我們的演算法在執行時間方面有顯著的加速。我們也證明了我們的演算法能夠在單一的 NVIDIA A100 GPU (SXM4 80GB) 上達成極長的序列長度，最高可達 1.6 億。

##### **Improving vision-language alignment with graph spiking hybrid Networks**
2501.19069v1 by Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen

To bridge the semantic gap between vision and language (VL), it is necessary
to develop a good alignment strategy, which includes handling semantic
diversity, abstract representation of visual information, and generalization
ability of models. Recent works use detector-based bounding boxes or patches
with regular partitions to represent visual semantics. While current paradigms
have made strides, they are still insufficient for fully capturing the nuanced
contextual relations among various objects. This paper proposes a comprehensive
visual semantic representation module, necessitating the utilization of
panoptic segmentation to generate coherent fine-grained semantic features.
Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that
integrates the complementary advantages of Spiking Neural Networks (SNNs) and
Graph Attention Networks (GATs) to encode visual semantic information.
Intriguingly, the model not only encodes the discrete and continuous latent
variables of instances but also adeptly captures both local and global
contextual features, thereby significantly enhancing the richness and diversity
of semantic representations. Leveraging the spatiotemporal properties inherent
in SNNs, we employ contrastive learning (CL) to enhance the similarity-based
representation of embeddings. This strategy alleviates the computational
overhead of the model and enriches meaningful visual representations by
constructing positive and negative sample pairs. We design an innovative
pre-training method, Spiked Text Learning (STL), which uses text features to
improve the encoding ability of discrete semantics. Experiments show that the
proposed GSHN exhibits promising results on multiple VL downstream tasks.

摘要：<paragraph>為了彌合視覺和語言 (VL) 之間的語意差距，必須制定良好的對齊策略，其中包括處理語意多樣性、視覺資訊的抽象表示以及模型的泛化能力。最近的研究使用基於偵測器的邊界框或具有規則分割的區塊來表示視覺語意。雖然目前的範例已取得進展，但對於完全捕捉各種物件之間的細微脈絡關係仍不足夠。本文提出了一個全面的視覺語意表示模組，需要利用全景分割來產生連貫的細粒度語意特徵。此外，我們提出了一個新穎的圖形脈衝混合網路 (GSHN)，它整合了脈衝神經網路 (SNN) 和圖形注意力網路 (GAT) 的互補優勢來編碼視覺語意資訊。有趣的是，該模型不僅編碼實例的離散和連續潛在變數，還能巧妙地捕捉局部和全域脈絡特徵，從而顯著增強語意表示的豐富性和多樣性。利用 SNN 中固有的時空特性，我們採用對比學習 (CL) 來增強嵌入的基於相似性的表示。此策略減輕了模型的計算負擔，並透過建構正負樣本對來豐富有意義的視覺表示。我們設計了一個創新的預訓練方法，脈衝文本學習 (STL)，它使用文本特徵來提高離散語意的編碼能力。實驗表明，所提出的 GSHN 在多個 VL 下游任務上展現出有希望的結果。</paragraph>

##### **Semantic Web and Creative AI -- A Technical Report from ISWS 2023**
2501.18542v1 by Raia Abu Ahmad, Reham Alharbi, Roberto Barile, Martin Böckling, Francisco Bolanos, Sara Bonfitto, Oleksandra Bruns, Irene Celino, Yashrajsinh Chudasama, Martin Critelli, Claudia d'Amato, Giada D'Ippolito, Ioannis Dasoulas, Stefano De Giorgis, Vincenzo De Leo, Chiara Di Bonaventura, Marco Di Panfilo, Daniil Dobriy, John Domingue, Xuemin Duan, Michel Dumontier, Sefika Efeoglu, Ruben Eschauzier, Fakih Ginwa, Nicolas Ferranti, Arianna Graciotti, Philipp Hanisch, George Hannah, Golsa Heidari, Aidan Hogan, Hassan Hussein, Alexane Jouglar, Jan-Christoph Kalo, Manoé Kieffer, Antonis Klironomos, Inês Koch, Weronika Lajewska, Nicolas Lazzari, Mikael Lindekrans, Anna Sofia Lippolis, Majlinda Llugiqi, Eleonora Mancini, Eleonora Marzi, Laura Menotti, Daniela Milon Flores, Soulakshmee Nagowah, Kerstin Neubert, Emetis Niazmand, Ebrahim Norouzi, Beatriz Olarte Martinez, Anouk Michelle Oudshoorn, Andrea Poltronieri, Valentina Presutti, Disha Purohit, Ensiyeh Raoufi, Celian Ringwald, Johanna Rockstroh, Sebastian Rudolph, Harald Sack, Zafar Saeed, Mohammad Javad Saeedizade, Aya Sahbi, Cristian Santini, Aleksandra Simic, Dennis Sommer, Rita Sousa, Mary Ann Tan, Vidyashree Tarikere, Tabea Tietz, Liam Tirpitz, Arnaldo Tomasino, Frank van Harmelen, Joao Vissoci, Caitlin Woods, Bohui Zhang, Xinyue Zhang, Heng Zheng

The International Semantic Web Research School (ISWS) is a week-long
intensive program designed to immerse participants in the field. This document
reports a collaborative effort performed by ten teams of students, each guided
by a senior researcher as their mentor, attending ISWS 2023. Each team provided
a different perspective to the topic of creative AI, substantiated by a set of
research questions as the main subject of their investigation. The 2023 edition
of ISWS focuses on the intersection of Semantic Web technologies and Creative
AI. ISWS 2023 explored various intersections between Semantic Web technologies
and creative AI. A key area of focus was the potential of LLMs as support tools
for knowledge engineering. Participants also delved into the multifaceted
applications of LLMs, including legal aspects of creative content production,
humans in the loop, decentralised approaches to multimodal generative AI
models, nanopublications and AI for personal scientific knowledge graphs,
commonsense knowledge in automatic story and narrative completion, generative
AI for art critique, prompt engineering, automatic music composition,
commonsense prototyping and conceptual blending, and elicitation of tacit
knowledge. As Large Language Models and semantic technologies continue to
evolve, new exciting prospects are emerging: a future where the boundaries
between creative expression and factual knowledge become increasingly permeable
and porous, leading to a world of knowledge that is both informative and
inspiring.

摘要：國際語意網路研究學校 (ISWS) 是一個為期一週的密集課程，旨在讓參與者沉浸在該領域中。本文件報告了由十個學生團隊進行的合作成果，每個團隊都由一位資深研究員作為導師，參加了 2023 年 ISWS。每個團隊都從不同的角度探討了創意 AI 主題，並以一系列研究問題作為調查的主要主題。2023 年版的 ISWS 關注於語意網路技術和創意 AI 的交集。ISWS 2023 探索了語意網路技術和創意 AI 之間的各種交集。一個重點關注領域是 LLM 作為知識工程的支援工具的潛力。參與者還深入探討了 LLM 的多方面應用，包括創意內容製作的法律方面、循環中的人類、多模態生成式 AI 模型的分散式方法、納米出版物和用於個人科學知識圖譜的 AI、自動故事和敘述完成中的常識知識、生成式 AI 用於藝術評論、提示工程、自動音樂創作、常識原型和概念混合，以及對默會知識的引導。隨著大型語言模型和語意技術的持續發展，新的令人興奮的前景正在出現：一個創意表達和事實知識之間的界限變得越來越可滲透和多孔的未來，從而導致一個既有資訊性又有啟發性的知識世界。

##### **Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**
2501.18320v1 by Tianpeng Pan, Wenqiang Pu, Licheng Zhao, Rui Zhou

Automated optimization modeling (AOM) has evoked considerable interest with
the rapid evolution of large language models (LLMs). Existing approaches
predominantly rely on prompt engineering, utilizing meticulously designed
expert response chains or structured guidance. However, prompt-based techniques
have failed to perform well in the sensor array signal processing (SASP) area
due the lack of specific domain knowledge. To address this issue, we propose an
automated modeling approach based on retrieval-augmented generation (RAG)
technique, which consists of two principal components: a multi-agent (MA)
structure and a graph-based RAG (Graph-RAG) process. The MA structure is
tailored for the architectural AOM process, with each agent being designed
based on principles of human modeling procedure. The Graph-RAG process serves
to match user query with specific SASP modeling knowledge, thereby enhancing
the modeling result. Results on ten classical signal processing problems
demonstrate that the proposed approach (termed as MAG-RAG) outperforms several
AOM benchmarks.

摘要：自動化最佳化建模 (AOM) 隨著大型語言模型 (LLM) 的快速演進而引起相當大的興趣。現有方法主要依賴提示工程，利用精心設計的專家回應鏈或結構化指導。然而，基於提示的技術由於缺乏特定領域知識，無法在感測器陣列訊號處理 (SASP) 領域中表現良好。為了解決這個問題，我們提出一個基於檢索增強生成 (RAG) 技術的自動化建模方法，它包含兩個主要組成部分：多代理 (MA) 結構和基於圖形的 RAG (Graph-RAG) 程序。MA 結構是針對架構 AOM 程序量身打造，每個代理都是根據人類建模程序的原理設計的。Graph-RAG 程序用於將使用者查詢與特定的 SASP 建模知識相匹配，從而增強建模結果。在十個經典訊號處理問題上的結果表明，所提出的方法（稱為 MAG-RAG）優於多個 AOM 基準。

##### **Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**
2501.18154v1 by Wanlong Liu, Yichen Xiao, Dingyi Zeng, Hongyang Zhao, Wenyu Chen, Malu Zhang

Post-Training Quantization (PTQ) is pivotal for deploying large language
models (LLMs) within resource-limited settings by significantly reducing
resource demands. However, existing PTQ strategies underperform at low bit
levels < 3 bits due to the significant difference between the quantized and
original weights. To enhance the quantization performance at low bit widths, we
introduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a
graph neural network (GNN) module to capture dependencies among weights and
adaptively assign quantization bit-widths. Through the information propagation
of the GNN module, our method more effectively captures dependencies among
target weights, leading to a more accurate assessment of weight importance and
optimized allocation of quantization strategies. Extensive experiments on the
WikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms
previous state-of-the-art PTQ method GPTQ, setting new benchmarks for
quantization performance under low-bit conditions.

摘要：訓練後量化 (PTQ) 對於在資源受限的設定中部署大型語言模型 (LLM) 至關重要，因為它能顯著降低資源需求。然而，現有的 PTQ 策略在低位元層級 < 3 位元時表現不佳，因為量化後的權重與原始權重之間有顯著的差異。為了提升低位元寬度的量化效能，我們提出混合精度圖神經網路 PTQ (MG-PTQ) 方法，採用圖神經網路 (GNN) 模組來擷取權重之間的依存關係，並動態分配量化位元寬度。透過 GNN 模組的資訊傳播，我們的方法能更有效地擷取目標權重之間的依存關係，進而更準確地評估權重重要性，並最佳化量化策略的配置。在 WikiText2 和 C4 資料集上的廣泛實驗證明，我們的 MG-PTQ 方法優於先前的最先進 PTQ 方法 GPTQ，在低位元條件下設定了量化效能的新基準。

##### **Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**
2501.18119v1 by Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

Due to the presence of the natural gap between Knowledge Graph (KG)
structures and the natural language, the effective integration of holistic
structural information of KGs with Large Language Models (LLMs) has emerged as
a significant question. To this end, we propose a two-stage framework to learn
and apply quantized codes for each entity, aiming for the seamless integration
of KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)
method is proposed to compress both KG structural and semantic knowledge into
discrete codes (\ie, tokens) that align the format of language sentences. We
further design KG instruction-following data by viewing these learned codes as
features to directly input to LLMs, thereby achieving seamless integration. The
experiment results demonstrate that SSQR outperforms existing unsupervised
quantized methods, producing more distinguishable codes. Further, the
fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link
prediction and triple classification tasks, utilizing only 16 tokens per entity
instead of thousands in conventional prompting methods.

摘要：由於知識圖譜 (KG) 結構與自然語言之間存在自然差距，將 KG 的整體結構資訊與大型語言模型 (LLM) 有效整合已成為一個重要的問題。為此，我們提出了一個兩階段架構來學習和應用每個實體的量化碼，旨在將 KG 與 LLM 無縫整合。首先，提出了一個自監督量化表示 (SSQR) 方法，將 KG 結構和語義知識壓縮成離散碼（即，符號），以對齊語言句子的格式。我們進一步設計 KG 指令遵循資料，將這些學習到的碼視為直接輸入 LLM 的特徵，從而實現無縫整合。實驗結果表明，SSQR 優於現有的無監督量化方法，產生更具區別性的碼。此外，微調後的 LLaMA2 和 LLaMA3.1 在 KG 連結預測和三元分類任務上也具有優異的性能，每個實體僅使用 16 個符號，而不是傳統提示方法中的數千個。

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

摘要：回答需要對結構化（表格）和非結構化（原始文字）資料來源進行推理和彙總的問題會帶來重大挑戰。目前的辦法仰賴微調和高品質、人工整理的資料，而這很難取得。大型語言模型（LLM）的最新進展已針對零次學習設定的單一來源文字資料多跳問題回答（QA）展現出有希望的結果，但對多來源表格文字 QA 的探討仍然有限。在本文中，我們提出了一種新穎的基於混合圖表的表格文字 QA 方法，它利用 LLM 而無需微調。我們的辦法從文字和表格資料建構一個統一的混合圖表，根據輸入問題修剪資訊，以簡潔地為 LLM 提供相關脈絡。我們使用最先進的 LLM，包括 GPT-3.5、GPT-4 和 LLaMA-3，針對具有挑戰性的 Hybrid-QA 和 OTT-QA 資料集評估我們的辦法。我們的辦法在兩個資料集上都達到了最佳的零次學習效能，在 Hybrid-QA 上將完全比對分數提高了 10%，在 OTT-QA 上將完全比對分數提高了 5.4%。此外，與原始脈絡相比，我們的辦法將符號使用量減少了 53%。

##### **Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**
2501.17549v1 by Wooyoung Kim, Byungyoon Park, Wooju Kim

Graph-structured data plays a vital role in numerous domains, such as social
networks, citation networks, commonsense reasoning graphs and knowledge graphs.
While graph neural networks have been employed for graph processing, recent
advancements have explored integrating large language models for graph-based
tasks. In this paper, we propose a novel approach named Learnable Graph Pooling
Token (LGPT), which addresses the limitations of the scalability issues in
node-level projection and information loss in graph-level projection. LGPT
enables flexible and efficient graph representation by introducing learnable
parameters that act as tokens in large language models, balancing fine-grained
and global graph information. Additionally, we investigate an Early Query
Fusion technique, which fuses query context before constructing the graph
representation, leading to more effective graph embeddings. Our method achieves
a 4.13\% performance improvement on the GraphQA benchmark without training the
large language model, demonstrating significant gains in handling complex
textual-attributed graph data.

摘要：圖形結構資料在許多領域中扮演著至關重要的角色，例如社交網路、引用網路、常識推理圖形和知識圖形。雖然圖形神經網路已用於圖形處理，但最近的進展已探討整合大型語言模型以進行基於圖形的任務。在本文中，我們提出了一種名為可學習圖形池化令牌 (LGPT) 的新方法，它解決了節點層級投影中的可擴充性問題和圖形層級投影中的資訊遺失限制。LGPT 透過引入可學習的參數（在大型語言模型中作為令牌運作）來啟用彈性和高效的圖形表示，平衡細粒度和整體圖形資訊。此外，我們研究了一種早期查詢融合技術，它在建構圖形表示之前融合查詢內容，進而產生更有效的圖形嵌入。我們的方法在 GraphQA 基準上達到了 4.13% 的效能提升，而無需訓練大型語言模型，證明了在處理複雜的文字屬性圖形資料方面有顯著的進展。

##### **General Scene Adaptation for Vision-and-Language Navigation**
2501.17403v1 by Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu

Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on
one-time execution of individual instructions across multiple environments,
aiming to develop agents capable of functioning in any environment in a
zero-shot manner. However, real-world navigation robots often operate in
persistent environments with relatively consistent physical layouts, visual
observations, and language styles from instructors. Such a gap in the task
setting presents an opportunity to improve VLN agents by incorporating
continuous adaptation to specific environments. To better reflect these
real-world conditions, we introduce GSA-VLN, a novel task requiring agents to
execute navigation instructions within a specific scene and simultaneously
adapt to it for improved performance over time. To evaluate the proposed task,
one has to address two challenges in existing VLN datasets: the lack of OOD
data, and the limited number and style diversity of instructions for each
scene. Therefore, we propose a new dataset, GSA-R2R, which significantly
expands the diversity and quantity of environments and instructions for the R2R
dataset to evaluate agent adaptability in both ID and OOD contexts.
Furthermore, we design a three-stage instruction orchestration pipeline that
leverages LLMs to refine speaker-generated instructions and apply role-playing
techniques to rephrase instructions into different speaking styles. This is
motivated by the observation that each individual user often has consistent
signatures or preferences in their instructions. We conducted extensive
experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various
methods. Based on our findings, we propose a novel method, GR-DUET, which
incorporates memory-based navigation graphs with an environment-specific
training strategy, achieving state-of-the-art results on all GSA-R2R splits.

摘要：視覺語言導航 (VLN) 任務主要根據代理程式在多個環境中執行個別指令的一次性執行來評估代理程式，旨在開發能夠在任何環境中以零次學習的方式運作的代理程式。然而，真實世界的導航機器人通常在持續性的環境中運作，而這些環境具有相對一致的物理配置、視覺觀察和指令的語言風格。任務設定中的這種差距提供了一個機會，可以透過將連續適應特定環境納入其中來改善 VLN 代理程式。為了更好地反映這些真實世界的條件，我們推出了 GSA-VLN，這是一個新任務，要求代理程式在特定場景中執行導航指令，並同時適應該場景，以隨著時間推移而提高效能。為了評估所提出的任務，必須解決現有 VLN 資料集中的兩個挑戰：缺乏 OOD 資料，以及每個場景的指令數量和風格多樣性有限。因此，我們提出了一個新的資料集 GSA-R2R，它顯著擴展了 R2R 資料集的環境和指令的多樣性和數量，以評估代理程式在 ID 和 OOD 背景下的適應能力。此外，我們設計了一個三階段指令編排管道，該管道利用大型語言模型 (LLM) 來精煉由說話者產生的指令，並應用角色扮演技巧將指令改寫成不同的說話風格。這項技術的靈感來自於觀察到每個個別使用者通常在其指令中具有相符的簽名或偏好。我們針對 GSA-R2R 進行了大量的實驗，以徹底評估我們的資料集和基準各種方法。根據我們的研究結果，我們提出了一種新的方法 GR-DUET，它將基於記憶的導航圖表與特定於環境的訓練策略結合在一起，在所有 GSA-R2R 分割中取得了最先進的結果。

##### **Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**
2501.17270v1 by Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li

Question answering systems for knowledge graph (KGQA), answer factoid
questions based on the data in the knowledge graph. KGQA systems are complex
because the system has to understand the relations and entities in the
knowledge-seeking natural language queries and map them to structured queries
against the KG to answer them. In this paper, we introduce Chronos, a
comprehensive evaluation framework for KGQA at industry scale. It is designed
to evaluate such a multi-component system comprehensively, focusing on (1)
end-to-end and component-level metrics, (2) scalable to diverse datasets and
(3) a scalable approach to measure the performance of the system prior to
release. In this paper, we discuss the unique challenges associated with
evaluating KGQA systems at industry scale, review the design of Chronos, and
how it addresses these challenges. We will demonstrate how it provides a base
for data-driven decisions and discuss the challenges of using it to measure and
improve a real-world KGQA system.

摘要：知識圖譜問答系統 (KGQA) 根據知識圖譜中的資料回答事實問題。KGQA 系統很複雜，因為系統必須理解知識尋求自然語言查詢中的關係和實體，並將它們對映到針對知識圖譜的結構化查詢，才能回答這些查詢。在本文中，我們介紹了 Chronos，這是一個用於產業規模 KGQA 的全面評估框架。它旨在全面評估這種多組件系統，重點關注：(1) 端對端和組件層級指標，(2) 可擴充至各種資料集，以及 (3) 可擴充的方法，用於在釋出前衡量系統的效能。在本文中，我們討論了與產業規模 KGQA 系統評估相關的獨特挑戰，檢視 Chronos 的設計，以及它如何應對這些挑戰。我們將展示它如何提供資料驅動決策的基礎，並討論使用它來衡量和改善真實世界 KGQA 系統的挑戰。

##### **FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**
2501.17144v1 by Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng

Prior research on training grounded factuality classification models to
detect hallucinations in large language models (LLMs) has relied on public
natural language inference (NLI) data and synthetic data. However, conventional
NLI datasets are not well-suited for document-level reasoning, which is
critical for detecting LLM hallucinations. Recent approaches to document-level
synthetic data generation involve iteratively removing sentences from documents
and annotating factuality using LLM-based prompts. While effective, this method
is computationally expensive for long documents and limited by the LLM's
capabilities. In this work, we analyze the differences between existing
synthetic training data used in state-of-the-art models and real LLM output
claims. Based on our findings, we propose a novel approach for synthetic data
generation, CG2C, that leverages multi-hop reasoning on context graphs
extracted from documents. Our fact checker model, FactCG, demonstrates improved
performance with more connected reasoning, using the same backbone models.
Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark
with much smaller model size.

摘要：先前的研究訓練了基於事實的分類模型，以偵測大型語言模型 (LLM) 中的幻覺，依賴於公開的自然語言推論 (NLI) 資料和合成資料。然而，傳統的 NLI 資料集並不適合文件層級的推理，這對於偵測 LLM 的幻覺至關重要。最近的文件層級合成資料生成方法涉及從文件中反覆移除句子，並使用基於 LLM 的提示註解事實。雖然有效，但此方法對於長文件來說在運算上很昂貴，且受限於 LLM 的能力。在這項工作中，我們分析了現有合成訓練資料與最先進模型中使用的真實 LLM 輸出宣告之間的差異。根據我們的研究結果，我們提出了一個用於合成資料生成的創新方法 CG2C，它利用從文件中提取的內容圖表進行多跳推理。我們的查核模型 FactCG 使用相同的骨幹模型，展示了在更多連結的推理下改進的效能。實驗表明，它甚至在 LLM-Aggrefact 基準上優於 GPT-4-o，且模型大小小得多。

##### **LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**
2501.16673v2 by Li Yin, Zhangyang Wang

Large Language Models (LLMs) have reshaped natural language processing,
powering applications from multi-hop retrieval and question answering to
autonomous agent workflows. Yet, prompt engineering -- the task of crafting
textual inputs to effectively direct LLMs -- remains difficult and
labor-intensive, particularly for complex pipelines that combine multiple LLM
calls with functional operations like retrieval and data formatting. We
introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering
(APE) that extends textual gradient-based methods (such as Text-Grad) to
multi-component, potentially cyclic LLM architectures. Implemented within the
AdalFlow library, LLM-AutoDiff treats each textual input as a trainable
parameter and uses a frozen backward engine LLM to generate feedback-akin to
textual gradients -- that guide iterative prompt updates. Unlike prior
single-node approaches, LLM-AutoDiff inherently accommodates functional nodes,
preserves time-sequential behavior in repeated calls (e.g., multi-hop loops),
and combats the "lost-in-the-middle" problem by isolating distinct sub-prompts
(instructions, formats, or few-shot examples). It further boosts training
efficiency by focusing on error-prone samples through selective gradient
computation. Across diverse tasks, including single-step classification,
multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff
consistently outperforms existing textual gradient baselines in both accuracy
and training cost. By unifying prompt optimization through a graph-centric
lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating
LLM workflows - mirroring the transformative role that automatic
differentiation libraries have long played in neural network research.

摘要：大型語言模型 (LLM) 已重塑自然語言處理，
為從多跳檢索和問答到
自主代理工作流程的應用提供動力。然而，提示工程 -- 編寫
文本輸入以有效指導 LLM 的任務 -- 仍然困難且
勞動密集，特別是對於將多個 LLM
呼叫與檢索和數據格式化等功能操作相結合的複雜管道。我們
介紹 LLM-AutoDiff：一個用於自動提示工程 (APE) 的新框架，它將基於文本梯度的
方法（例如 Text-Grad）擴展到多組件、潛在循環 LLM 架構中。在
AdalFlow 庫中實施，LLM-AutoDiff 將每個文本輸入視為一個可訓練
參數，並使用凍結的後向引擎 LLM 生成反饋——類似於
文本梯度——指導迭代提示更新。與先前的
單節點方法不同，LLM-AutoDiff 本質上適應功能節點，
在重複呼叫（例如，多跳循環）中保留時間順序行為，
並通過隔離不同的子提示（說明、格式或少數鏡頭示例）來解決“迷失在中間”問題。它進一步提高訓練
效率，通過選擇性梯度
計算專注於容易出錯的樣本。在包括單步分類、
多跳基於檢索的問答和代理驅動管道在內的各種任務中，LLM-AutoDiff
在準確性和訓練成本方面始終優於現有的文本梯度基準。通過圖形中心化
視角統一提示優化，LLM-AutoDiff 為擴展和自動化
LLM 工作流程提供了一個強大的新範例——反映了自動
微分庫在神經網絡研究中長期扮演的變革性角色。

##### **360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation**
2501.16450v2 by Hamed Firooz, Maziar Sanjabi, Adrian Englhardt, Aman Gupta, Ben Levine, Dre Olgiati, Gungor Polatkan, Iuliia Melnychuk, Karthik Ramgopal, Kirill Talanine, Kutta Srinivasan, Luke Simon, Natesh Sivasubramoniapillai, Necip Fazil Ayan, Qingquan Song, Samira Sriram, Souvik Ghosh, Tao Song, Vignesh Kothapalli, Xiaoling Zhai, Ya Xu, Yu Wang, Yun Dai

Ranking and recommendation systems are the foundation for numerous online
experiences, ranging from search results to personalized content delivery.
These systems have evolved into complex, multilayered architectures that
leverage vast datasets and often incorporate thousands of predictive models.
The maintenance and enhancement of these models is a labor intensive process
that requires extensive feature engineering. This approach not only exacerbates
technical debt but also hampers innovation in extending these systems to
emerging problem domains. In this report, we present our research to address
these challenges by utilizing a large foundation model with a textual interface
for ranking and recommendation tasks. We illustrate several key advantages of
our approach: (1) a single model can manage multiple predictive tasks involved
in ranking and recommendation, (2) decoder models with textual interface due to
their comprehension of reasoning capabilities, can generalize to new
recommendation surfaces and out-of-domain problems, and (3) by employing
natural language interfaces for task definitions and verbalizing member
behaviors and their social connections, we eliminate the need for feature
engineering and the maintenance of complex directed acyclic graphs of model
dependencies. We introduce our research pre-production model, 360Brew V1.0, a
150B parameter, decoder-only model that has been trained and fine-tuned on
LinkedIn's data and tasks. This model is capable of solving over 30 predictive
tasks across various segments of the LinkedIn platform, achieving performance
levels comparable to or exceeding those of current production systems based on
offline metrics, without task-specific fine-tuning. Notably, each of these
tasks is conventionally addressed by dedicated models that have been developed
and maintained over multiple years by teams of a similar or larger size than
our own.

摘要：排名和推薦系統是許多線上體驗的基礎，從搜尋結果到個人化內容傳遞。這些系統已演變成複雜的多層架構，利用大量的資料集，並經常整合數千個預測模型。這些模型的維護和增強是一個勞力密集的過程，需要廣泛的特徵工程。這種方法不僅會加劇技術債務，還會阻礙將這些系統擴展到新興問題領域的創新。在本文中，我們介紹我們的研究，以利用具有文本介面的大型基礎模型來解決這些挑戰，以進行排名和推薦任務。我們說明了我們方法的幾個主要優點：(1) 單一模型可以管理排名和推薦中涉及的多個預測任務，(2) 由於其對推理能力的理解，具有文本介面的解碼器模型可以概括到新的推薦表面和領域外問題，以及 (3) 通過採用自然語言介面進行任務定義和表達成員行為及其社交連結，我們消除了對特徵工程和維護複雜的模型相依關係的有向無環圖的需求。我們介紹了我們的研究前置生產模型 360Brew V1.0，一個經過在 LinkedIn 的資料和任務上訓練和微調的 150B 參數、僅解碼器模型。此模型能夠解決 LinkedIn 平台各個區塊中超過 30 個預測任務，在不進行特定任務微調的情況下，達到與基於離線指標的現行生產系統相當或超越的效能等級。值得注意的是，這些任務中的每一個通常都由專用模型處理，這些模型是由與我們規模相當或更大的團隊在多年間開發和維護的。

##### **Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**
2501.16191v1 by Antony Bartlett, Cynthia Liem, Annibale Panichella

Fixing Python dependency issues is a tedious and error-prone task for
developers, who must manually identify and resolve environment dependencies and
version constraints of third-party modules and Python interpreters. Researchers
have attempted to automate this process by relying on large knowledge graphs
and database lookup tables. However, these traditional approaches face
limitations due to the variety of dependency error types, large sets of
possible module versions, and conflicts among transitive dependencies. This
study explores the potential of using large language models (LLMs) to
automatically fix dependency issues in Python programs. We introduce PLLM
(pronounced "plum"), a novel technique that employs retrieval-augmented
generation (RAG) to help an LLM infer Python versions and required modules for
a given Python file. PLLM builds a testing environment that iteratively (1)
prompts the LLM for module combinations, (2) tests the suggested changes, and
(3) provides feedback (error messages) to the LLM to refine the fix. This
feedback cycle leverages natural language processing (NLP) to intelligently
parse and interpret build error messages. We benchmark PLLM on the Gistable
HG2.9K dataset, a collection of challenging single-file Python gists. We
compare PLLM against two state-of-the-art automatic dependency inference
approaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependency
issues. Our results indicate that PLLM can fix more dependency issues than the
two baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)
over PyEGo. Our deeper analyses suggest that PLLM is particularly beneficial
for projects with many dependencies and for specific third-party numerical and
machine-learning modules. Our findings demonstrate the potential of LLM-based
approaches to iteratively resolve Python dependency issues.

摘要：<paragraph>修復 Python 依賴項問題對開發人員來說是一項繁瑣且容易出錯的任務，他們必須手動識別和解決第三方模組和 Python 解譯器的環境依賴項和版本限制。研究人員已嘗試透過依賴大型知識圖譜和資料庫查詢表來自動化此程序。然而，這些傳統方法由於依賴項錯誤類型多樣、可能的模組版本數量龐大，以及傳遞依賴項之間的衝突，而面臨限制。本研究探討使用大型語言模型 (LLM) 自動修復 Python 程式中的依賴項問題的可能性。我們介紹 PLLM（發音為「plum」），這是一種新穎的技術，採用檢索增強生成 (RAG) 來協助 LLM 推論 Python 版本和給定 Python 檔案所需的模組。PLLM 建立一個測試環境，反覆 (1) 提示 LLM 模組組合，(2) 測試建議的變更，以及 (3) 提供回饋（錯誤訊息）給 LLM 以改善修正。此回饋循環利用自然語言處理 (NLP) 來智慧解析和詮釋建置錯誤訊息。我們在 Gistable HG2.9K 資料集上對 PLLM 進行基準測試，該資料集是一個具有挑戰性的單一檔案 Python gist 集合。我們將 PLLM 與兩種最先進的自動依賴項推論方法進行比較，即 PyEGo 和 ReadPyE，以比較解決依賴項問題的能力。我們的結果顯示，PLLM 可以修復比這兩個基準更多的依賴項問題，比 ReadPyE 多修復了 +218 (+15.97%) 個，比 PyEGo 多修復了 +281 (+21.58%) 個。我們更深入的分析表明，PLLM 對具有許多依賴項的專案以及特定第三方數值和機器學習模組特別有益。我們的研究結果證明了基於 LLM 的方法反覆解決 Python 依賴項問題的可能性。</paragraph>

##### **Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs**
2501.15791v1 by Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu

Knowledge graphs are widely used in industrial applications, making error
detection crucial for ensuring the reliability of downstream applications.
Existing error detection methods often fail to effectively leverage
fine-grained subgraph information and rely solely on fixed graph structures,
while also lacking transparency in their decision-making processes, which
results in suboptimal detection performance. In this paper, we propose a novel
Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that
utilizes multiple large language models (LLMs) in a collaborative setting. By
concatenating fine-grained, bidirectional subgraph embeddings with LLM-based
query embeddings during training, our framework integrates these
representations to produce four specialized agents. These agents utilize
subgraph information from different dimensions to engage in multi-round
discussions, thereby improving error detection accuracy and ensuring a
transparent decision-making process. Extensive experiments on FB15K and WN18RR
demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the
accuracy and robustness of KG evaluation. For specific industrial scenarios,
our framework can facilitate the training of specialized agents using
domain-specific knowledge graphs for error detection, which highlights the
potential industrial application value of our framework. Our code and datasets
are available at https://github.com/kse-ElEvEn/MAKGED.

摘要：知識圖譜廣泛應用於工業應用中，使得錯誤偵測對於確保下游應用的可靠性至關重要。現有的錯誤偵測方法通常無法有效利用細粒度的子圖資訊，並且僅依賴於固定的圖形結構，同時在它們的決策過程中也缺乏透明度，這導致次佳的偵測效能。在本文中，我們提出了一個用於知識圖譜錯誤偵測 (MAKGED) 的新多代理架構，它在協作設定中利用了多個大型語言模型 (LLM)。透過在訓練期間將細粒度、雙向子圖嵌入與基於 LLM 的查詢嵌入串接，我們的架構整合了這些表示以產生四個專門代理。這些代理利用不同維度的子圖資訊參與多輪討論，從而提高錯誤偵測準確度並確保透明的決策過程。在 FB15K 和 WN18RR 上的廣泛實驗表明，MAKGED 優於最先進的方法，增強了 KG 評估的準確性和穩健性。對於特定產業情境，我們的架構可以利用特定領域的知識圖譜來促進專門代理的訓練以進行錯誤偵測，這突顯了我們架構的潛在產業應用價值。我們的程式碼和資料集可在 https://github.com/kse-ElEvEn/MAKGED 取得。

##### **Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs**
2501.15777v1 by Momoka Furuhashi, Hiroaki Funayama, Yuya Iwase, Yuichiroh Matsubayashi, Yoriko Isobe, Toru Nagahama, Saku Sugawara, Kentaro Inui

Short-reading comprehension questions help students understand text structure
but lack effective feedback. Students struggle to identify and correct errors,
while manual feedback creation is labor-intensive. This highlights the need for
automated feedback linking responses to a scoring rubric for deeper
comprehension.
  Despite advances in Natural Language Processing (NLP), research has focused
on automatic grading, with limited work on feedback generation. To address
this, we propose a system that generates feedback for student responses.
  Our contributions are twofold. First, we introduce the first system for
feedback on short-answer reading comprehension. These answers are derived from
the text, requiring structural understanding. We propose an "answer diagnosis
graph," integrating the text's logical structure with feedback templates. Using
this graph and NLP techniques, we estimate students' comprehension and generate
targeted feedback.
  Second, we evaluate our feedback through an experiment with Japanese high
school students (n=39). They answered two 70-80 word questions and were divided
into two groups with minimal academic differences. One received a model answer,
the other system-generated feedback. Both re-answered the questions, and we
compared score changes. A questionnaire assessed perceptions and motivation.
  Results showed no significant score improvement between groups, but
system-generated feedback helped students identify errors and key points in the
text. It also significantly increased motivation. However, further refinement
is needed to enhance text structure understanding.

摘要：短篇閱讀理解題目有助學生理解文章結構，但缺乏有效的回饋。學生難以找出並更正錯誤，而手動建立回饋又很費力。這突顯了自動化回饋的必要性，將回應連結到評分標準，以獲得更深入的理解。

儘管自然語言處理 (NLP) 有所進展，但研究一直集中在自動評分上，而回饋生成的工作有限。為了解決這個問題，我們提出了一個系統，用於為學生的回答產生回饋。

我們的貢獻有兩個方面。首先，我們引入了第一個針對簡答閱讀理解提供回饋的系統。這些答案來自於文本，需要結構化的理解。我們提出了一個「答案診斷圖」，將文本的邏輯結構與回饋範本整合在一起。使用這個圖表和 NLP 技術，我們估計學生的理解力並產生有針對性的回饋。

其次，我們透過一項針對日本高中生的實驗（n=39）來評估我們的回饋。他們回答了兩個 70-80 字的問題，並被分成兩組，學術差異最小。一組收到範本答案，另一組收到系統產生的回饋。兩組都重新回答了問題，我們比較了分數的變化。一份問卷評估了認知和動機。

結果顯示兩組之間沒有顯著的分數進步，但系統產生的回饋有助於學生找出文本中的錯誤和重點。它也顯著地提高了動機。然而，需要進一步的改進來增強對文本結構的理解。

##### **Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts**
2501.15688v1 by Haodi Ma, Dzmitry Kasinets, Daisy Zhe Wang

Multimodal knowledge graph completion (MMKGC) aims to predict missing links
in multimodal knowledge graphs (MMKGs) by leveraging information from various
modalities alongside structural data. Existing MMKGC approaches primarily
extend traditional knowledge graph embedding (KGE) models, which often require
creating an embedding for every entity. This results in large model sizes and
inefficiencies in integrating multimodal information, particularly for
real-world graphs. Meanwhile, Transformer-based models have demonstrated
competitive performance in knowledge graph completion (KGC). However, their
focus on single-modal knowledge limits their capacity to utilize cross-modal
information. Recently, Large vision-language models (VLMs) have shown potential
in cross-modal tasks but are constrained by the high cost of training. In this
work, we propose a novel approach that integrates Transformer-based KGE models
with cross-modal context generated by pre-trained VLMs, thereby extending their
applicability to MMKGC. Specifically, we employ a pre-trained VLM to transform
relevant visual information from entities and their neighbors into textual
sequences. We then frame KGC as a sequence-to-sequence task, fine-tuning the
model with the generated cross-modal context. This simple yet effective method
significantly reduces model size compared to traditional KGE approaches while
achieving competitive performance across multiple large-scale datasets with
minimal hyperparameter tuning.

摘要：多模態知識圖譜補全 (MMKGC) 旨在透過利用來自各種模態與結構化資料的資訊，來預測多模態知識圖譜 (MMKG) 中的缺失連結。現有的 MMKGC 方法主要擴充傳統的知識圖譜嵌入 (KGE) 模型，這些模型通常需要為每個實體建立一個嵌入。這會導致模型尺寸過大，且在整合多模態資訊時效率低下，特別是對於真實世界的圖譜。與此同時，基於 Transformer 的模型已在知識圖譜補全 (KGC) 中展現出競爭力。然而，它們著重於單模態知識，限制了它們利用跨模態資訊的能力。最近，大型視覺語言模型 (VLM) 已在跨模態任務中展現潛力，但受限於訓練成本過高。在這項工作中，我們提出了一種創新的方法，它將基於 Transformer 的 KGE 模型與預先訓練的 VLM 所產生的跨模態內容整合在一起，從而擴展它們在 MMKGC 中的適用性。具體來說，我們採用預先訓練的 VLM，將實體及其鄰居相關的視覺資訊轉換成文字序列。然後，我們將 KGC 架構成一個序列到序列的任務，並使用產生的跨模態內容微調模型。這種簡單但有效的方法，與傳統的 KGE 方法相比，大幅減少了模型尺寸，同時在多個大型資料集上達到了競爭力的效能，且只需最少的超參數調整。

##### **How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback**
2501.15378v1 by Manzong Huang, Chenyang Bu, Yi He, Xindong Wu

Knowledge Graph (KG)-augmented Large Language Models (LLMs) have recently
propelled significant advances in complex reasoning tasks, thanks to their
broad domain knowledge and contextual awareness. Unfortunately, current methods
often assume KGs to be complete, which is impractical given the inherent
limitations of KG construction and the potential loss of contextual cues when
converting unstructured text into entity-relation triples. In response, this
paper proposes the Triple Context Restoration and Query-driven Feedback
(TCR-QF) framework, which reconstructs the textual context underlying each
triple to mitigate information loss, while dynamically refining the KG
structure by iteratively incorporating query-relevant missing knowledge.
Experiments on five benchmark question-answering datasets substantiate the
effectiveness of TCR-QF in KG and LLM integration, where itachieves a 29.1%
improvement in Exact Match and a 15.5% improvement in F1 over its
state-of-the-art GraphRAG competitors.

摘要：知識圖譜 (KG) 增強大型語言模型 (LLM) 最近推動複雜推理任務的重大進展，這要歸功於它們廣泛的領域知識和語境感知。不幸的是，目前的模型通常假設 KG 是完整的，這在考慮到 KG 建構的固有限制和在將非結構化文字轉換為實體關係三元組時潛在的語境線索損失時是不切實際的。為了解決這個問題，本文提出了三元組語境還原和查詢驅動回饋 (TCR-QF) 架構，它重建每個三元組底層的文字語境以減輕資訊損失，同時透過反覆納入與查詢相關的遺失知識來動態優化 KG 結構。在五個基準問題回答資料集上的實驗證實了 TCR-QF 在 KG 和 LLM 整合方面的有效性，它在 Exact Match 中獲得 29.1% 的改進，在 F1 中獲得 15.5% 的改進，優於最先進的 GraphRAG 競爭對手。

##### **Explaining Categorical Feature Interactions Using Graph Covariance and LLMs**
2501.14932v1 by Cencheng Shen, Darren Edge, Jonathan Larson, Carey E. Priebe

Modern datasets often consist of numerous samples with abundant features and
associated timestamps. Analyzing such datasets to uncover underlying events
typically requires complex statistical methods and substantial domain
expertise. A notable example, and the primary data focus of this paper, is the
global synthetic dataset from the Counter Trafficking Data Collaborative (CTDC)
-- a global hub of human trafficking data containing over 200,000 anonymized
records spanning from 2002 to 2022, with numerous categorical features for each
record. In this paper, we propose a fast and scalable method for analyzing and
extracting significant categorical feature interactions, and querying large
language models (LLMs) to generate data-driven insights that explain these
interactions. Our approach begins with a binarization step for categorical
features using one-hot encoding, followed by the computation of graph
covariance at each time. This graph covariance quantifies temporal changes in
dependence structures within categorical data and is established as a
consistent dependence measure under the Bernoulli distribution. We use this
measure to identify significant feature pairs, such as those with the most
frequent trends over time or those exhibiting sudden spikes in dependence at
specific moments. These extracted feature pairs, along with their timestamps,
are subsequently passed to an LLM tasked with generating potential explanations
of the underlying events driving these dependence changes. The effectiveness of
our method is demonstrated through extensive simulations, and its application
to the CTDC dataset reveals meaningful feature pairs and potential data stories
underlying the observed feature interactions.

摘要：現代資料集通常包含許多具有豐富特徵和關聯時間戳的樣本。分析此類資料集以揭示底層事件通常需要複雜的統計方法和大量的領域專業知識。一個值得注意的範例，也是本文的主要資料重點，是來自反人口販運資料合作組織 (CTDC) 的全球合成資料集，這是全球人口販運資料的樞紐，包含超過 200,000 筆從 2002 年到 2022 年的匿名記錄，每個記錄都有許多分類特徵。在本文中，我們提出了一種快速且可擴充的方法，用於分析和提取重要的分類特徵交互作用，並查詢大型語言模型 (LLM)，以產生資料驅動的見解來解釋這些交互作用。我們的做法從使用獨熱編碼對分類特徵進行二元化步驟開始，然後在每個時間點計算圖形共變異數。此圖形共變異數量化了分類資料中依賴結構的時間變化，並在伯努利分佈下建立為一致的依賴度量。我們使用此度量來識別重要的特徵對，例如隨時間推移趨勢最頻繁的特徵對，或在特定時刻表現出依賴性突然激增的特徵對。這些提取的特徵對及其時間戳隨後傳遞給 LLM，後者負責產生對驅動這些依賴性變化的底層事件的潛在解釋。我們的方法的有效性已通過廣泛的模擬得到證明，其在 CTDC 資料集中的應用揭示了有意義的特徵對和潛在的資料故事，這些故事是觀察到的特徵交互作用的基礎。

##### **Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**
2501.14892v1 by Hang Luo, Jian Zhang, Chujun Li

In knowledge-intensive tasks, especially in high-stakes domains like medicine
and law, it is critical not only to retrieve relevant information but also to
provide causal reasoning and explainability. Large language models (LLMs) have
achieved remarkable performance in natural language understanding and
generation tasks. However, they often suffer from limitations such as
difficulty in incorporating new knowledge, generating hallucinations, and
explaining their reasoning process. To address these challenges, integrating
knowledge graphs with Graph Retrieval-Augmented Generation (Graph RAG) has
emerged as an effective solution. Traditional Graph RAG methods often rely on
simple graph traversal or semantic similarity, which do not capture causal
relationships or align well with the model's internal reasoning steps. This
paper proposes a novel pipeline that filters large knowledge graphs to
emphasize cause-effect edges, aligns the retrieval process with the model's
chain-of-thought (CoT), and enhances reasoning through multi-stage path
improvements. Experiments on medical question-answering tasks show consistent
gains, with up to a 10\% absolute improvement across multiple large language
models (LLMs). This approach demonstrates the value of combining causal
reasoning with stepwise retrieval, leading to more interpretable and logically
grounded solutions for complex queries.

摘要：在知識密集型任務中，特別是在醫學和法律等高風險領域，不僅檢索相關資訊至關重要，還必須提供因果推理和可解釋性。大型語言模型 (LLM) 在自然語言理解和生成任務中取得了顯著的表現。然而，它們通常會遇到一些限制，例如難以納入新知識、產生幻覺，以及解釋其推理過程。為了應對這些挑戰，將知識圖與圖形檢索增強生成 (Graph RAG) 整合在一起已成為一種有效的解決方案。傳統的 Graph RAG 方法通常依賴於簡單的圖形遍歷或語義相似性，這無法捕捉因果關係或與模型的內部推理步驟很好地對齊。本文提出了一個新穎的管道，該管道過濾大型知識圖以強調因果邊緣，將檢索過程與模型的思想鏈 (CoT) 對齊，並通過多階段路徑改進來增強推理。在醫療問題解答任務上的實驗顯示出一致的收益，在多個大型語言模型 (LLM) 中絕對改進幅度高達 10%。這種方法展示了將因果推理與逐步檢索相結合的價值，從而為複雜查詢提供更具可解釋性和邏輯依據的解決方案。

##### **GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**
2501.16382v1 by Ziwen Li, Xiang 'Anthony' Chen, Youngseung Jeon

Drug discovery (DD) has tremendously contributed to maintaining and improving
public health. Hypothesizing that inhibiting protein misfolding can slow
disease progression, researchers focus on target identification (Target ID) to
find protein structures for drug binding. While Large Language Models (LLMs)
and Retrieval-Augmented Generation (RAG) frameworks have accelerated drug
discovery, integrating models into cohesive workflows remains challenging. We
conducted a user study with drug discovery researchers to identify the
applicability of LLMs and RAGs in Target ID. We identified two main findings:
1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on
an initial protein and protein candidates that have a therapeutic impact; 2)
the model must provide the PPI and relevant explanations for better
understanding. Based on these observations, we identified three limitations in
previous approaches for Target ID: 1) semantic ambiguity, 2) lack of
explainability, and 3) short retrieval units. To address these issues, we
propose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve
agent pipeline RAG framework to support large-scale PPI signaling pathway
exploration in understanding therapeutic impacts by decomposing the analysis of
entire PPI pathways into sub-tasks focused on the analysis of PPI edges.

摘要：药物发现 (DD) 极大地促进了公共卫生的维护和改善。研究人员假设抑制蛋白质错误折叠可以减缓疾病进展，因此专注于靶点识别 (Target ID) 以找到用于药物结合的蛋白质结构。虽然大型语言模型 (LLM) 和检索增强生成 (RAG) 框架加速了药物发现，但将模型整合到内聚工作流中仍然具有挑战性。我们与药物发现研究人员进行了一项用户研究，以确定 LLM 和 RAG 在 Target ID 中的适用性。我们确定了两个主要发现：1) LLM 应该基于初始蛋白质和具有治疗作用的蛋白质候选物提供多个蛋白质-蛋白质相互作用 (PPI)；2) 该模型必须提供 PPI 和相关解释以更好地理解。基于这些观察，我们发现了先前 Target ID 方法中的三个局限性：1) 语义歧义，2) 缺乏可解释性，3) 检索单元短。为了解决这些问题，我们提出了 GraPPI，这是一种基于大规模知识图 (KG) 的检索-分解-求解代理管道 RAG 框架，以支持大规模 PPI 信号通路探索，通过将整个 PPI 通路的分析分解为专注于 PPI 边缘分析的子任务来理解治疗影响。

##### **Evaluating and Improving Graph to Text Generation with Large Language Models**
2501.14497v1 by Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez Basulto, Jeff Z. Pan

Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.

摘要：大型語言模型（LLM）已在各種任務中展現出巨大的潛力。然而，探索和提升 LLM 在詮釋圖形結構方面的能力的研究仍然有限。為了解決這個差距，我們對提示目前開源的 LLM 執行圖形轉文字生成任務進行全面評估。儘管我們探索了最佳提示策略並提出了一種新穎且有效的基於多樣性難度的少樣本選擇方法，但我們發現無調校方法的改進是漸進的，因為 LLM 難以規劃複雜的圖形，特別是那些具有較多三元組的圖形。為了進一步提升 LLM 在圖形序列規劃和真實依據方面的能力，我們引入了一個新的圖形轉文字資料集 PlanGTG，並註解了兩個子任務：重新排序和歸因。透過廣泛的自動化和人工評估，我們證明了使用 PlanGTG 資料集從少樣本學習和微調角度產生文字的品質有顯著提升。我們的研究為圖形轉文字生成中的新研究方向鋪路。PlanGTG 資料集可以在 https://github.com/probe2/kg_text 中找到。

##### **Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**
2501.14300v1 by Xujian Liang, Zhaoquan Gu

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community pruning - coarse and fine pruning for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.

摘要：圖表檢索增強生成 (GRAG) 是一種新穎的範例，它透過將圖表資訊（例如知識圖表 (KG)) 整合到大型語言模型 (LLM) 中，進一步提升了樸素的 RAG 系統以減輕幻覺。然而，現有的 GRAG 仍會遇到限制：1) 簡單的範例通常會因從 KG 中擷取的關聯性狹隘且淺薄而無法解決複雜的問題 2) 如果圖表很密集，與 KG 強耦合的方法往往會導致高運算成本和耗時。在本文中，我們提出了 Fast Think-on-Graph (FastToG)，這是一種創新的範例，可讓 LLM 在 KG 中「逐個社群」進行思考。為此，FastToG 使用社群偵測來擷取更深入的關聯性，並使用兩個階段的社群修剪（粗略修剪和精細修剪）來加快檢索速度。此外，我們還開發了兩種社群到文字的方法，將社群的圖表結構轉換為文字形式，以便 LLM 更容易理解。實驗結果證明了 FastToG 的有效性，與先前的研究相比，展示出更高的準確性、更快的推理速度和更好的可解釋性。

##### **Top Ten Challenges Towards Agentic Neural Graph Databases**
2501.14224v1 by Jiaxin Bai, Zihao Wang, Yukun Zhou, Hang Yin, Weizhi Fei, Qi Hu, Zheye Deng, Jiayang Cheng, Tianshi Zheng, Hong Ting Tsang, Yisen Gao, Zhongwei Xie, Yufei Li, Lixin Fan, Binhang Yuan, Wei Wang, Lei Chen, Xiaofang Zhou, Yangqiu Song

Graph databases (GDBs) like Neo4j and TigerGraph excel at handling
interconnected data but lack advanced inference capabilities. Neural Graph
Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for
predictive analysis and reasoning over incomplete or noisy data. However, NGDBs
rely on predefined queries and lack autonomy and adaptability. This paper
introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs
with three core functionalities: autonomous query construction, neural query
execution, and continuous learning. We identify ten key challenges in realizing
Agentic NGDBs: semantic unit representation, abductive reasoning, scalable
query execution, and integration with foundation models like large language
models (LLMs). By addressing these challenges, Agentic NGDBs can enable
intelligent, self-improving systems for modern data-driven applications, paving
the way for adaptable and autonomous data management solutions.

摘要：圖形資料庫（GDB），例如 Neo4j 和 TigerGraph，擅長處理相互連接的資料，但缺乏進階的推論能力。神經圖形資料庫（NGDB）透過整合圖形神經網路（GNN）來解決這個問題，以進行預測分析和對不完整或有雜訊的資料進行推理。然而，NGDB 依賴於預先定義的查詢，並且缺乏自主性和適應性。本文介紹了代理神經圖形資料庫（Agentic NGDB），它以三項核心功能擴充了 NGDB：自動查詢建構、神經查詢執行和持續學習。我們找出實現 Agentic NGDB 的十大關鍵挑戰：語義單元表示、演繹推理、可擴充查詢執行，以及與基礎模型（例如大型語言模型 (LLM)）整合。透過解決這些挑戰，Agentic NGDB 可以為現代資料驅動應用打造智慧且自我改善的系統，為適應性和自主資料管理解決方案鋪路。

##### **GraphRAG under Fire**
2501.14050v1 by Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang

GraphRAG advances retrieval-augmented generation (RAG) by structuring
external knowledge as multi-scale knowledge graphs, enabling language models to
integrate both broad context and granular details in their reasoning. While
GraphRAG has demonstrated success across domains, its security implications
remain largely unexplored. To bridge this gap, this work examines GraphRAG's
vulnerability to poisoning attacks, uncovering an intriguing security paradox:
compared to conventional RAG, GraphRAG's graph-based indexing and retrieval
enhance resilience against simple poisoning attacks; meanwhile, the same
features also create new attack surfaces. We present GRAGPoison, a novel attack
that exploits shared relations in the knowledge graph to craft poisoning text
capable of compromising multiple queries simultaneously. GRAGPoison employs
three key strategies: i) relation injection to introduce false knowledge, ii)
relation enhancement to amplify poisoning influence, and iii) narrative
generation to embed malicious content within coherent text. Empirical
evaluation across diverse datasets and models shows that GRAGPoison
substantially outperforms existing attacks in terms of effectiveness (up to 98%
success rate) and scalability (using less than 68% poisoning text). We also
explore potential defensive measures and their limitations, identifying
promising directions for future research.

摘要：GraphRAG 透過將外部知識結構化為多尺度知識圖譜，推動了檢索增強生成 (RAG)，使語言模型能夠在其推理中整合廣泛的背景和細微的細節。儘管 GraphRAG 在各個領域都已展現出成功，但其安全性影響在很大程度上仍未被探索。為了彌補這一差距，本研究探討了 GraphRAG 對投毒攻擊的脆弱性，揭示了一個有趣的安全悖論：與傳統的 RAG 相比，GraphRAG 基於圖表的索引和檢索增強了對簡單投毒攻擊的韌性；同時，相同的特徵也創造了新的攻擊面。我們提出了 GRAGPoison，這是一種新穎的攻擊，它利用知識圖譜中的共享關係來製作中毒文本，能夠同時危害多個查詢。GRAGPoison 採用了三項關鍵策略：i) 關係注入以引入錯誤的知識，ii) 關係增強以擴大投毒影響，以及 iii) 敘事生成以將惡意內容嵌入連貫的文本中。在各種數據集和模型上的經驗評估表明，GRAGPoison 在有效性（成功率高達 98%）和可擴展性（使用不到 68% 的投毒文本）方面都明顯優於現有的攻擊。我們還探討了潛在的防禦措施及其局限性，確定了未來研究的有希望的方向。

##### **EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**
2501.13746v1 by Yuhui Yun, Huilong Ye, Xinru Li, Ruojia Li, Jingfeng Deng, Li Li, Haoyi Xiong

The paper introduces EICopilot, an novel agent-based solution enhancing
search and exploration of enterprise registration data within extensive online
knowledge graphs like those detailing legal entities, registered capital, and
major shareholders. Traditional methods necessitate text-based queries and
manual subgraph explorations, often resulting in time-consuming processes.
EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this
landscape by utilizing Large Language Models (LLMs) to interpret natural
language queries. This solution automatically generates and executes Gremlin
scripts, providing efficient summaries of complex enterprise relationships.
Distinct feature a data pre-processing pipeline that compiles and annotates
representative queries into a vector database of examples for In-context
learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought
with ICL to enhance Gremlin script generation for knowledge graph search and
exploration, and a novel query masking strategy that improves intent
recognition for heightened script accuracy. Empirical evaluations demonstrate
the superior performance of EICopilot, including speed and accuracy, over
baseline methods, with the \emph{Full Mask} variant achieving a syntax error
rate reduction to as low as 10.00% and an execution correctness of up to
82.14%. These components collectively contribute to superior querying
capabilities and summarization of intricate datasets, positioning EICopilot as
a groundbreaking tool in the exploration and exploitation of large-scale
knowledge graphs for enterprise information search.

摘要：本文介紹了 EICopilot，這是一種基於代理的新型解決方案，可增強在廣泛的線上知識圖譜中搜尋和探索企業註冊資料，例如詳細說明法律實體、註冊資本和主要股東的資料。傳統方法需要基於文字的查詢和手動子圖探索，通常會導致耗時的流程。EICopilot 部署為百度企業搜尋的聊天機器人，透過利用大型語言模型 (LLM) 來詮釋自然語言查詢，進而改善這項技術。此解決方案會自動產生並執行 Gremlin 腳本，提供複雜企業關係的有效摘要。其獨特功能為資料前處理管線，可將具代表性的查詢編譯並註解到範例的向量資料庫中，以進行脈絡中學習 (ICL)，這是一個結合了思考鏈與 ICL 的綜合推理管線，用於增強 Gremlin 腳本產生，以進行知識圖譜搜尋和探索，以及一種新穎的查詢遮罩策略，可改善意圖辨識，進而提高腳本準確度。實證評估顯示，EICopilot 的效能優於基線方法，包括速度和準確度，其中「完整遮罩」變體將語法錯誤率降低至低於 10.00%，執行正確率高達 82.14%。這些元件共同促成了優異的查詢功能和複雜資料集的摘要，將 EICopilot 定位為探索和利用大規模知識圖譜進行企業資訊搜尋的創新工具。

##### **Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**
2501.13731v1 by Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng

Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.

摘要：圖表計算任務本質上具有挑戰性，而且通常需要開發先進的演算法才能有效解決。隨著大型語言模型 (LLM) 的出現，研究人員已開始探討其解決這些任務的可能性。然而，現有方法受到 LLM 理解複雜圖形結構的能力有限以及其高推理成本的限制，這使得它們不切實際地處理大規模圖形。受到人類解決圖形問題的方法啟發，我們引入了 PIE（偽代碼注入增強 LLM 圖形計算任務推理）這個新框架，它包含三個關鍵步驟：問題理解、提示設計和代碼生成。在此框架中，LLM 的任務是理解問題並擷取相關資訊以產生正確的代碼。分析圖形結構和執行代碼的責任委派給解釋器。我們將與任務相關的偽代碼注入提示中，以進一步協助 LLM 產生有效的代碼。我們還採用具有成本效益的試錯技術，以確保 LLM 生成的代碼正確執行。與需要為每個個別測試案例呼叫 LLM 的其他方法不同，PIE 僅在代碼產生階段呼叫 LLM，允許重複使用產生的代碼並大幅降低推理成本。大量的實驗證明，PIE 在準確性和計算效率方面都優於現有的基準。

##### **CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**
2501.13993v1 by Hamza Landolsi, Kais Letaief, Nizar Taghouti, Ines Abdeljaoued-Tej

The introduction of new features and services in the banking sector often
overwhelms customers, creating an opportunity for banks to enhance user
experience through financial chatbots powered by large language models (LLMs).
We initiated an AI agent designed to provide customers with relevant
information about banking services and insights from annual reports. We
proposed a hybrid Customer Analysis Pipeline Retrieval-Augmented Generation
(CAPRAG) that effectively addresses both relationship-based and contextual
queries, thereby improving customer engagement in the digital banking
landscape. To implement this, we developed a processing pipeline to refine text
data, which we utilized in two main frameworks: Vector RAG and Graph RAG. This
dual approach enables us to populate both vector and graph databases with
processed data for efficient retrieval. The Cypher query component is employed
to effectively query the graph database. When a user submits a query, it is
first expanded by a query expansion module before being routed to construct a
final query from the hybrid Knowledge Base (KB). This final query is then sent
to an open-source LLM for response generation. Overall, our innovative,
designed to international banks, serves bank's customers in an increasingly
complex digital environment, enhancing clarity and accessibility of
information.

摘要：銀行業中新功能和服務的推出經常讓客戶感到不知所措，這為銀行透過大型語言模型 (LLM) 驅動的金融聊天機器人來提升使用者體驗創造了機會。我們啟動了一個人工智慧代理，旨在為客戶提供有關銀行服務和年度報告見解的相關資訊。我們提出了一個混合式客戶分析管道檢索擴充生成 (CAPRAG)，它有效地處理基於關係和情境式的查詢，從而提升數位銀行環境中的客戶參與度。為了實作這一點，我們開發了一個處理管道來精煉文字資料，我們在兩個主要架構中使用它：Vector RAG 和 Graph RAG。這種雙管齊下的方法讓我們能夠使用處理過的資料來填補向量和圖形資料庫，以利於有效檢索。Cypher 查詢元件用於有效查詢圖形資料庫。當使用者提交查詢時，它會先由查詢擴充模組擴充，然後再路由到混合式知識庫 (KB) 中建構最終查詢。然後這個最終查詢會傳送給開源 LLM 以產生回應。整體而言，我們創新的設計服務於國際銀行，在日益複雜的數位環境中服務銀行客戶，提升資訊的清晰度和可及性。

##### **Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**
2501.13992v1 by Hy Nguyen, Nguyen Hung Nguyen, Nguyen Linh Bao Nguyen, Srikanth Thudumu, Hung Du, Rajesh Vasa, Kon Mouzakis

The Hierarchical Navigable Small World (HNSW) algorithm is widely used for
approximate nearest neighbor (ANN) search, leveraging the principles of
navigable small-world graphs. However, it faces some limitations. The first is
the local optima problem, which arises from the algorithm's greedy search
strategy, selecting neighbors based solely on proximity at each step. This
often leads to cluster disconnections. The second limitation is that HNSW
frequently fails to achieve logarithmic complexity, particularly in
high-dimensional datasets, due to the exhaustive traversal through each layer.
To address these limitations, we propose a novel algorithm that mitigates local
optima and cluster disconnections while enhancing the construction speed,
maintaining inference speed. The first component is a dual-branch HNSW
structure with LID-based insertion mechanisms, enabling traversal from multiple
directions. This improves outlier node capture, enhances cluster connectivity,
accelerates construction speed and reduces the risk of local minima. The second
component incorporates a bridge-building technique that bypasses redundant
intermediate layers, maintaining inference and making up the additional
computational overhead introduced by the dual-branch structure. Experiments on
various benchmarks and datasets showed that our algorithm outperforms the
original HNSW in both accuracy and speed. We evaluated six datasets across
Computer Vision (CV), and Natural Language Processing (NLP), showing recall
improvements of 18\% in NLP, and up to 30\% in CV tasks while reducing the
construction time by up to 20\% and maintaining the inference speed. We did not
observe any trade-offs in our algorithm. Ablation studies revealed that
LID-based insertion had the greatest impact on performance, followed by the
dual-branch structure and bridge-building components.

摘要：分層可導航小世界 (HNSW) 演算法廣泛用於近似最近鄰居 (ANN) 搜尋，並利用可導航小世界圖形的原理。然而，它面臨一些限制。第一個是局部最佳化問題，這源自於演算法的貪婪搜尋策略，在每個步驟中僅根據鄰近度來選擇鄰居。這通常會導致群集斷線。第二個限制是，由於透過每一層的窮舉式遍歷，HNSW 常常無法在高維度資料集中達成對數複雜度。為了解決這些限制，我們提出了一種新的演算法，它可以減輕局部最佳化和群集斷線，同時提高建構速度，並維持推論速度。第一個組成部分是一個具有基於 LID 的插入機制的雙分支 HNSW 結構，它能從多個方向進行遍歷。這改善了異常值節點的擷取，增強了群集連通性，加速了建構速度，並降低了局部最小值的風險。第二個組成部分包含一種橋樑建構技術，它繞過了多餘的中間層，維持推論並彌補了雙分支結構所帶來的額外運算負擔。在各種基準和資料集上的實驗顯示，我們的演算法在準確度和速度上都優於原始的 HNSW。我們評估了電腦視覺 (CV) 和自然語言處理 (NLP) 中的六個資料集，顯示 NLP 中的召回率提高了 18%，CV 任務中提高了 30%，同時將建構時間縮短了 20%，並維持了推論速度。我們沒有在我們的演算法中觀察到任何取捨。消融研究顯示，基於 LID 的插入對效能的影響最大，其次是雙分支結構和橋樑建構組成部分。

##### **Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**
2501.13984v1 by Bhumika Gupta, Pralaypati Ta, Keerthi Ram, Mohanasankar Sivaprakasam

The updated recommendations on diagnostic procedures and treatment pathways
for a medical condition are documented as graphical flows in Clinical Practice
Guidelines (CPGs). For effective use of the CPGs in helping medical
professionals in the treatment decision process, it is necessary to fully
capture the guideline knowledge, particularly the contexts and their
relationships in the graph. While several existing works have utilized these
guidelines to create rule bases for Clinical Decision Support Systems, limited
work has been done toward directly capturing the full medical knowledge
contained in CPGs. This work proposes an approach to create a contextually
enriched, faithful digital representation of National Comprehensive Cancer
Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and
node & relationship classification. We also implement semantic enrichment of
the model by using Large Language Models (LLMs) for node classification,
achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot
learning, respectively. Additionally, we introduce a methodology for answering
natural language questions with constraints to guideline text by leveraging
LLMs to extract the relevant subgraph from the guideline knowledge base. By
generating natural language answers based on subgraph paths and semantic
information, we mitigate the risk of incorrect answers and hallucination
associated with LLMs, ensuring factual accuracy in medical domain Question
Answering.

摘要：已更新的醫療狀況診斷程序和治療途徑建議，以臨床實務指南 (CPG) 中的圖形流程記錄。為了有效使用 CPG 協助醫療專業人員進行治療決策，必須完整擷取指南知識，特別是圖表中的脈絡及其關係。雖然現有許多研究已利用這些指南為臨床決策支援系統建立規則基礎，但直接擷取 CPG 中包含的完整醫療知識的工作卻有限。這項研究提出了一種方法，以自動化擷取和節點與關係分類的方式，建立脈絡豐富、忠實的國家綜合癌症網路 (NCCN) 癌症 CPG 圖形數位表示。我們也透過使用大型語言模型 (LLM) 進行節點分類，實作模型的語意豐富化，分別在零次學習和少次學習中達到 80.86% 和 88.47% 的準確度。此外，我們引進了一種方法，透過運用 LLM 從指南知識庫中擷取相關子圖，來回答具有指南文字限制的自然語言問題。透過根據子圖路徑和語意資訊產生自然語言答案，我們降低了與 LLM 相關的錯誤答案和幻覺風險，確保了醫療領域問題解答中的事實準確性。

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

摘要：<paragraph>在學習個人化提供學習者巨大潛力的同時，高等教育中的現代實務需要更深入地考慮領域模型和學習情境，以開發有效的個人化演算法。本文介紹了一種創新的高等教育課程建模方法，該方法利用大型語言模型 (LLM) 來完成知識圖譜 (KG)，目的是建立個人化的學習路徑建議。我們的研究重點在於建模大學科目，並將它們的主題連結到對應的領域模型，從而能夠將來自不同院系和機構的學習模組整合到學生的學習路徑中。我們的做法核心是一個協作流程，其中 LLM 協助人類專家從講義材料中萃取高品質、細緻的主題。我們為大學模組和利害關係人開發了領域、課程和使用者模型。我們實作這個模型，從兩個研究模組建立 KG：嵌入式系統和使用 FPGA 的嵌入式系統開發。產生的 KG 建構了課程並將其連結到領域模型。我們透過定性專家回饋和定量圖形品質指標來評估我們的做法。領域專家驗證了模型的相關性和準確性，而圖形品質指標則測量了我們 KG 的結構特性。我們的結果顯示，LLM 輔助的圖形完成方法增強了跨學科連結相關課程的能力，以個人化學習體驗。專家回饋也顯示高度接受所提出的協作方法，用於概念萃取和分類。</paragraph>

##### **Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**
2501.12432v1 by Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/

摘要：儘管目前的大型語言模型 (LLM) 展現出令人印象深刻的能力，但執行複雜的真實世界任務仍需要工具學習。主流方法（例如 CoT/ReAct）依賴逐步工具呼叫與外部環境互動，但它們的感知範圍有限，且缺乏足夠的任務規劃能力。為了解決這些限制，其他研究引入了第一個基於搜尋的決策樹 (DFSDT)，但仍有很高的運算成本。在本文中，我們介紹了一種新穎的平行工具呼叫範例，DTA-Llama（分而合之 Llama）。首先，我們將傳統的基於樹的工具搜尋路徑轉換為有向無環圖 (DAG) 結構，產生高品質的平行工具呼叫資料集。然後在資料集上訓練 DTA-Llama，學習反覆將當前任務分成幾個平行工具呼叫子任務，並彙總呼叫結果以決定後續動作。此外，我們在將 DTA-Llama 應用於實際任務時，引入了一個受 Process/Threads 機制啟發的高效推論框架。實驗結果表明，我們的做法大幅提升了任務效能，同時減少了符號消耗和推論時間。使用我們方法的 Llama2-7B，可與 GPT-3.5 的官方平行函式呼叫方法相媲美。相關程式碼、資料集和模型權重可在 https://corn0205.github.io/ 取得

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

摘要：生成模型能力的提升有助于构建利用语言之外的多模态虚拟助手。通过观察人类执行多步骤任务，可以构建对正在执行的动作和任务有情境感知的助手，使他们能够根据这种理解提供帮助。在本文中，我们开发了一个具有多模态大语言模型的上下文感知指令任务助手 (InsTALL)，该助手利用在线视觉流（例如用户的屏幕共享或视频录制），并实时响应与手头任务相关的用户查询。为了提供有用的帮助，InsTALL 1) 在任务视频和配对文本数据上训练多模态模型，以及 2) 从视频数据中自动提取任务图，并在训练和推理时间利用它。我们展示了 InsTALL 在考虑用于多模态活动理解的提议子任务中实现了最先进的性能——任务识别 (TR)、动作识别 (AR)、下一个动作预测 (AP) 和计划预测 (PP)——并且在与自动错误识别相关的两个新子任务上优于现有的基准。

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, Raphaël Szymocha, Frédéric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

摘要：訓練任務導向對話系統既昂貴又耗時，
因為需要包含各種意圖的高品質資料集。
傳統方法依賴於廣泛的人工標註，而最近
的進展利用大型語言模型 (LLM) 來產生合成資料。
然而，這些方法通常需要自訂提示或程式碼，限制
非技術使用者的可及性。我們介紹 GraphTOD，一個端對端的
架構，簡化了任務導向對話的產生。使用者可以
透過指定 JSON 格式的轉換圖表來建立對話。我們的評估
證明 GraphTOD 在各種領域產生高品質對話，顯著降低資料集建立的成本和複雜性。

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

摘要：圖形結構的組合挑戰本質上很困難，因為它們的非線性和複雜性，通常會使傳統的計算方法無效或昂貴。然而，人類可以透過利用我們天生的空間推理能力的視覺表徵，更自然地應對這些挑戰。在本研究中，我們建議將圖形轉換為影像，以準確保留它們的高階結構特徵，從而革新用於解決圖形結構組合任務的表徵。這種方法允許機器在解決複雜的組合挑戰時模擬類人的處理。透過結合由多模態大型語言模型 (MLLM) 提供動力的創新範例與簡單的搜尋技術，我們旨在為解決此類問題開發一個新穎且有效的架構。我們對 MLLM 的研究涵蓋了各種基於圖形的任務，從組合問題（如影響力最大化）到網路拆除中的順序決策制定，以及解決六個基本的圖形相關問題。我們的研究結果表明，MLLM 表現出非凡的空間智能和處理這些問題的獨特能力，顯著提升了機器以類似人類認知的深度和直覺來理解和分析圖形結構資料的潛力。這些結果還暗示，將 MLLM 與簡單的最佳化策略整合在一起，可以形成一種新穎且有效的方法，用於在沒有複雜推導、計算需求量大的訓練和微調的情況下應對圖形結構的組合挑戰。

##### **A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**
2501.13958v1 by Qinggang Zhang, Shengyuan Chen, Yuanchen Bei, Zheng Yuan, Huachi Zhou, Zijin Hong, Junnan Dong, Hao Chen, Yi Chang, Xiao Huang

Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat text retrieval, face three critical
challenges: (i) complex query understanding in professional contexts, (ii)
difficulties in knowledge integration across distributed sources, and (iii)
system efficiency bottlenecks at scale. This survey presents a systematic
analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new
paradigm that revolutionizes domain-specific LLM applications. GraphRAG
addresses traditional RAG limitations through three key innovations: (i)
graph-structured knowledge representation that explicitly captures entity
relationships and domain hierarchies, (ii) efficient graph-based retrieval
techniques that enable context-preserving knowledge retrieval with multihop
reasoning ability, and (iii) structure-aware knowledge integration algorithms
that leverage retrieved knowledge for accurate and logical coherent generation
of LLMs. In this survey, we systematically analyze the technical foundations of
GraphRAG and examine current implementations across various professional
domains, identifying key technical challenges and promising research
directions. All the related resources of GraphRAG, including research papers,
open-source data, and projects, are collected for the community in
\textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.

摘要：大型語言模型 (LLM) 已在各種任務中展現出非凡的能力，但由於需要深入的專業知識，因此將其應用於專業領域仍具有挑戰性。檢索增強生成 (RAG) 已成為一種有前途的解決方案，可通過無縫整合外部知識庫來客製化 LLM 以適用於專業領域，從而在推理過程中即時存取特定領域的專業知識。儘管有其潛力，但基於平面文字檢索的傳統 RAG 系統面臨三項關鍵挑戰：(i) 在專業情境中進行複雜的查詢理解，(ii) 難以整合分散來源的知識，以及 (iii) 系統效率瓶頸會隨著規模擴大而產生。本調查系統性地分析了圖形化檢索增強生成 (GraphRAG) 的技術基礎，GraphRAG 是一個新的典範，它徹底改變了特定領域的 LLM 應用。GraphRAG 透過三項關鍵創新來解決傳統 RAG 的限制：(i) 圖形結構化的知識表述，明確擷取實體關係和領域階層，(ii) 有效的圖形化檢索技術，可進行保留脈絡的知識檢索，並具備多跳推理能力，以及 (iii) 結構感知知識整合演算法，可利用檢索到的知識來進行 LLM 的準確且邏輯一致的生成。在本調查中，我們系統性地分析了 GraphRAG 的技術基礎，並檢視了在各種專業領域中的現有實作，找出關鍵技術挑戰和有前景的研究方向。所有 GraphRAG 的相關資源，包括研究論文、開放原始碼資料和專案，都已在 \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}} 中為社群收集。

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v2 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

摘要：<paragraph>在社交媒體上對抗錯誤資訊，偵測有組織的政治宣傳活動至關重要。現有的此類有組織行動識別方法，大多採用網路科學、圖形機器學習和自然語言處理的技術。它們的最終目標是分析使用者之間的關係和互動（例如轉發），以及他們貼文的文字相似性。儘管這些方法在辨識草根運動宣傳活動方面很有效，但它們面臨嚴峻的挑戰，特別是可用訓練資料集中的類別不平衡。為了減輕這個問題，最近的方法通常訴諸於資料擴充或增加正向樣本數量，但在現實世界中可能並非總是可行或足夠。本文採取不同的途徑，我們提出了一個基於大型語言模型 (LLM) 的辨識草根運動宣傳活動的新架構，並引入了平衡檢索擴充產生 (Balanced RAG) 組件。我們的做法首先將有關貼文（在我們的案例中是推文）的文字資訊和社交網路的使用者互動作為輸入，輸入到語言模型中。然後，透過提示工程和提出的平衡檢索擴充產生方法，它有效地偵測 X（Twitter）上協調的不實資訊宣傳活動。提出的架構不需要任何語言模型的訓練或微調。相反地，透過策略性地利用提示工程和平衡檢索擴充產生方法的優勢，它使大型語言模型能夠克服類別不平衡的影響，並有效地識別協調的政治宣傳活動。實驗結果證明，透過整合提出的提示工程和平衡檢索擴充產生方法，我們的架構優於傳統的基於圖形的基準，在精確度、召回率和 F1 分數方面獲得 2x-3x 的改進。</paragraph>

##### **Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning**
2501.16361v1 by Haoran Song, Jiarui Feng, Guangfu Li, Michael Province, Philip Payne, Yixin Chen, Fuhai Li

In real-world scientific discovery, human beings always make use of the
accumulated prior knowledge with imagination pick select one or a few most
promising hypotheses from large and noisy data analysis results. In this study,
we introduce a new type of graph structure, the text-numeric graph (TNG), which
is defined as graph entities and associations have both text-attributed
information and numeric information. The TNG is an ideal data structure model
for novel scientific discovery via graph reasoning because it integrates
human-understandable textual annotations or prior knowledge, with numeric
values that represent the observed or activation levels of graph entities or
associations in different samples. Together both the textual information and
numeric values determine the importance of graph entities and associations in
graph reasoning for novel scientific knowledge discovery. We further propose
integrating large language models (LLMs) and graph neural networks (GNNs) to
analyze the TNGs for graph understanding and reasoning. To demonstrate the
utility, we generated the text-omic(numeric) signaling graphs (TOSG), as one
type of TNGs, in which all graphs have the same entities, associations and
annotations, but have sample-specific entity numeric (omic) values using single
cell RNAseq (scRNAseq) datasets of different diseases. We proposed joint
LLM-GNN models for key entity mining and signaling pathway mining on the TOSGs.
The evaluation results showed the LLM-GNN and TNGs models significantly improve
classification accuracy and network inference. In conclusion, the TNGs and
joint LLM-GNN models are important approaches for scientific discovery.

摘要：<paragraph>在現實世界的科學發現中，人類總是利用累積的先驗知識，並運用想像力從大量且雜訊的資料分析結果中挑選出一個或幾個最有希望的假設。在本研究中，我們介紹了一種新型態的圖形結構，稱為文字數值圖 (TNG)，定義為圖形實體和關聯具有文字屬性資訊和數值資訊。TNG 是透過圖形推理進行新科學發現的理想資料結構模型，因為它整合了人類可理解的文字註解或先驗知識，以及代表圖形實體或不同樣本中關聯的觀察值或活化程度的數值。文字資訊和數值一起決定了圖形實體和關聯在圖形推理中對於新科學知識發現的重要性。我們進一步提出整合大型語言模型 (LLM) 和圖形神經網路 (GNN) 來分析 TNG，以進行圖形理解和推理。為了展示其效用，我們生成了文字組學（數值）訊號圖 (TOSG)，作為一種 TNG，其中所有圖形都具有相同的實體、關聯和註解，但具有特定於樣本的實體數值（組學）值，使用不同疾病的單細胞 RNAseq (scRNAseq) 資料集。我們針對 TOSG 提出聯合 LLM-GNN 模型，用於關鍵實體探勘和訊號路徑探勘。評估結果顯示，LLM-GNN 和 TNG 模型顯著提升了分類準確度和網路推論。結論而言，TNG 和聯合 LLM-GNN 模型是科學發現的重要方法。</paragraph>

##### **Zep: A Temporal Knowledge Graph Architecture for Agent Memory**
2501.13956v1 by Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, Daniel Chalef

We introduce Zep, a novel memory layer service for AI agents that outperforms
the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR)
benchmark. Additionally, Zep excels in more comprehensive and challenging
evaluations than DMR that better reflect real-world enterprise use cases. While
existing retrieval-augmented generation (RAG) frameworks for large language
model (LLM)-based agents are limited to static document retrieval, enterprise
applications demand dynamic knowledge integration from diverse sources
including ongoing conversations and business data. Zep addresses this
fundamental limitation through its core component Graphiti -- a
temporally-aware knowledge graph engine that dynamically synthesizes both
unstructured conversational data and structured business data while maintaining
historical relationships. In the DMR benchmark, which the MemGPT team
established as their primary evaluation metric, Zep demonstrates superior
performance (94.8% vs 93.4%). Beyond DMR, Zep's capabilities are further
validated through the more challenging LongMemEval benchmark, which better
reflects enterprise use cases through complex temporal reasoning tasks. In this
evaluation, Zep achieves substantial results with accuracy improvements of up
to 18.5% while simultaneously reducing response latency by 90% compared to
baseline implementations. These results are particularly pronounced in
enterprise-critical tasks such as cross-session information synthesis and
long-term context maintenance, demonstrating Zep's effectiveness for deployment
in real-world applications.

摘要：我們推出 Zep，這是一種新穎的記憶層服務，適用於 AI 代理，其在深度記憶擷取 (DMR) 基準測試中優於現行的最先進系統 MemGPT。此外，Zep 在比 DMR 更全面且更具挑戰性的評估中表現出色，這些評估更能反映真實世界的企業用例。雖然現有的檢索增強生成 (RAG) 架構僅限於大型語言模型 (LLM) 基於代理的靜態文件檢索，但企業應用需要從包括正在進行的對話和業務數據在內的不同來源動態整合知識。Zep 通過其核心組件 Graphiti 來解決這個基本限制，Graphiti 是一個時間感知知識圖譜引擎，可以在維護歷史關係的同時動態綜合非結構化對話數據和結構化業務數據。在 MemGPT 團隊確立為其主要評估指標的 DMR 基準測試中，Zep 表現出優異的效能（94.8% 對 93.4%）。除了 DMR 之外，Zep 的功能還通過更具挑戰性的 LongMemEval 基準測試進一步得到驗證，該基準測試通過複雜的時間推理任務更好地反映了企業用例。在這個評估中，Zep 以高達 18.5% 的準確度改進取得了顯著的成果，同時與基線實作相比，將回應延遲降低了 90%。這些成果在企業關鍵任務中尤為明顯，例如跨會話資訊綜合和長期脈絡維護，證明了 Zep 在實際應用中部署的有效性。

##### **Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**
2501.11560v1 by M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo

Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.

摘要：換車道動作，尤其是突然或在風險情況下執行的動作，是道路交通事故的重要原因。然而，目前的研究所主要集中在預測安全的換車道。此外，現有的事故資料集通常僅基於影像，且缺乏全面的感測資料。在這項工作中，我們專注於使用 CRASH 資料集（我們自己收集的專門針對風險換車道資料集）來預測風險換車道，以及安全換車道（使用 HighD 資料集）。然後，我們利用 KG 和貝氏推理來使用語言背景資訊預測這些動作，增強模型的可解釋性和透明度。該模型在風險換車道的預測時間延長至四秒時，達到了 91.5% 的 f1 分數，在預測安全換車道時，在相同的預測時間內達到了 90.0% 的 f1 分數。我們透過將模型整合到 CARLA 模擬器中的車輛中，在涉及風險換車道的場景中驗證我們的模型。該模型設法預測突然的換車道，從而為自動駕駛車輛提供了更多時間來規劃和執行適當的安全反應。最後，為了增強我們模型的可解釋性，我們利用 RAG 為給定的預測提供清晰且自然的語言解釋。

##### **Each Graph is a New Language: Graph Learning with LLMs**
2501.11478v2 by Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.

摘要：<paragraph>最近的研究利用大型语言模型 (LLM) 对节点分类任务中的文本属性图结构进行建模。这些方法描述图结构，以便 LLM 理解或通过图结构聚合 LLM 生成的文本属性嵌入。然而，这些方法在使用 LLM 对图结构进行建模时面临两个主要限制。(i) 图描述在描述高阶图结构时变得冗长。(ii) 仅文本属性不包含足够的图结构信息。使用 LLM 对图结构进行简洁且充分的建模具有挑战性。LLM 缺乏直接对图结构进行建模的内置机制。它们还难以处理高阶节点和目标节点之间复杂的远程依赖关系。
受 LLM 在一种语言上进行预训练后，只需进行最少的额外训练即可在另一种语言上实现卓越性能的观察结果的启发，我们提出了**G**raph-**D**efined **L**anguage for **L**arge **L**anguage **M**odel (GDL4LLM)。此新框架使 LLM 能够将其强大的语言理解能力转移到结构化数据图。GDL4LLM 将图翻译成图语言语料库，而不是图描述，并在该语料库上对 LLM 进行预训练，以充分理解图结构。在微调期间，此语料库仅使用几个标记简洁地描述目标节点的结构信息。通过将图视为一种新语言，GDL4LLM 使 LLM 能够充分且简洁地对图结构进行建模，以用于节点分类任务。在三个真实世界数据集上进行的广泛实验表明，GDL4LLM 通过使用 LLM 有效地对不同阶的图结构进行建模，优于基于描述和基于文本属性嵌入的基线。</paragraph>

##### **Few-shot Policy (de)composition in Conversational Question Answering**
2501.11335v1 by Kyle Erwin, Guy Axelrod, Maria Chang, Achille Fokoue, Maxwell Crouse, Soham Dan, Tian Gao, Rosario Uceda-Sosa, Ndivhuwo Makondo, Naweed Khan, Alexander Gray

The task of policy compliance detection (PCD) is to determine if a scenario
is in compliance with respect to a set of written policies. In a conversational
setting, the results of PCD can indicate if clarifying questions must be asked
to determine compliance status. Existing approaches usually claim to have
reasoning capabilities that are latent or require a large amount of annotated
data. In this work, we propose logical decomposition for policy compliance
(LDPC): a neuro-symbolic framework to detect policy compliance using large
language models (LLMs) in a few-shot setting. By selecting only a few exemplars
alongside recently developed prompting techniques, we demonstrate that our
approach soundly reasons about policy compliance conversations by extracting
sub-questions to be answered, assigning truth values from contextual
information, and explicitly producing a set of logic statements from the given
policies. The formulation of explicit logic graphs can in turn help answer
PCDrelated questions with increased transparency and explainability. We apply
this approach to the popular PCD and conversational machine reading benchmark,
ShARC, and show competitive performance with no task-specific finetuning. We
also leverage the inherently interpretable architecture of LDPC to understand
where errors occur, revealing ambiguities in the ShARC dataset and highlighting
the challenges involved with reasoning for conversational question answering.

摘要：策略合規偵測 (PCD) 的任務是確定場景是否符合一組書面策略。在對話設定中，PCD 的結果可以指出是否必須提出澄清問題以確定合規狀態。現有的方法通常聲稱具有潛在的推理能力，或需要大量的註釋資料。在這項工作中，我們提出策略合規的邏輯分解 (LDPC)：一種使用大型語言模型 (LLM) 在少次嘗試中偵測策略合規的神經符號框架。透過僅選擇少數範例以及最近開發的提示技術，我們證明我們的做法透過提取要回答的子問題、從脈絡資訊指派真值，以及從給定的策略明確產生一組邏輯陳述，對策略合規對話進行合理的推理。明確邏輯圖表的制定反過來可以幫助回答 PCD 相關問題，並提高透明度和可解釋性。我們將此方法應用於熱門的 PCD 和對話式機器閱讀基準 ShARC，並在沒有特定任務微調的情況下展現出競爭力。我們也利用 LDPC 固有的可解釋架構來了解錯誤發生在哪裡，揭露 ShARC 資料集中的歧義，並強調對話式問題解答推理的挑戰。

##### **Reasoning Language Models: A Blueprint**
2501.11223v3 by Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Łukasz Flis, Hannes Eberhard, Hubert Niewiadomski, Torsten Hoefler

Reasoning language models (RLMs), also known as Large Reasoning Models
(LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have
redefined AI's problem-solving capabilities by extending LLMs with advanced
reasoning mechanisms. Yet, their high costs, proprietary nature, and complex
architectures - uniquely combining Reinforcement Learning (RL), search
heuristics, and LLMs - present accessibility and scalability challenges. To
address these, we propose a comprehensive blueprint that organizes RLM
components into a modular framework, based on a survey and analysis of all RLM
works. This blueprint incorporates diverse reasoning structures (chains, trees,
graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search,
Beam Search), RL concepts (policy, value models and others), supervision
schemes (Outcome-Based and Process-Based Supervision), and other related
concepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agent
tools). We also provide detailed mathematical formulations and algorithmic
specifications to simplify RLM implementation. By showing how schemes like
LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases,
we demonstrate the blueprint's versatility and unifying potential. To
illustrate its utility, we introduce x1, a modular implementation for rapid RLM
prototyping and experimentation. Using x1 and a literature review, we provide
key insights, such as multi-phase training for policy and value models, and the
importance of familiar training distributions. Finally, we discuss scalable RLM
cloud deployments and we outline how RLMs can integrate with a broader LLM
ecosystem. Our work demystifies RLM construction, democratizes advanced
reasoning capabilities, and fosters innovation, aiming to mitigate the gap
between "rich AI" and "poor AI" by lowering barriers to RLM design and
experimentation.

摘要：推理語言模型 (RLM)，又稱為大型推理模型 (LRM)，例如 OpenAI 的 o1 和 o3、DeepSeek-V3 以及阿里巴巴的 QwQ，透過擴充 LLM 的先進推理機制，重新定義了 AI 的問題解決能力。然而，它們的高成本、專有性質和複雜架構（獨特地結合了強化學習 (RL)、搜尋啟發法和 LLM）提出了可及性和可擴充性的挑戰。為了解決這些問題，我們提出了一個全面的藍圖，將 RLM 組件組織成一個模組化架構，這是基於對所有 RLM 作品的調查和分析。此藍圖包含多樣化的推理結構（鏈、樹、圖和巢狀形式）、推理策略（例如蒙地卡羅樹搜尋、波束搜尋）、RL 概念（策略、價值模型等）、監督方案（基於結果和基於流程的監督）和其他相關概念（例如測試時間運算、檢索增強生成、代理工具）。我們還提供了詳細的數學公式和演算法規範，以簡化 RLM 的實作。透過展示 LLaMA-Berry、QwQ、Journey Learning 和 Graph of Thoughts 等方案如何作為特殊情況，我們展示了藍圖的多功能性和統一潛力。為了說明其效用，我們介紹了 x1，這是一個模組化實作，用於快速 RLM 原型製作和實驗。使用 x1 和文獻回顧，我們提供了關鍵見解，例如策略和價值模型的多階段訓練，以及熟悉訓練分佈的重要性。最後，我們討論了可擴充的 RLM 雲端部署，並概述了 RLM 如何與更廣泛的 LLM 生態系統整合。我們的研究揭開了 RLM 建構的神秘面紗，使先進的推理能力民主化，並促進創新，旨在透過降低 RLM 設計和實驗的障礙，來縮小「富裕 AI」和「貧窮 AI」之間的差距。

##### **IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**
2501.11067v1 by Elad Levi, Ilan Kadar

Large Language Models (LLMs) are transforming artificial intelligence,
evolving into task-oriented systems capable of autonomous planning and
execution. One of the primary applications of LLMs is conversational AI
systems, which must navigate multi-turn dialogues, integrate domain-specific
APIs, and adhere to strict policy constraints. However, evaluating these agents
remains a significant challenge, as traditional methods fail to capture the
complexity and variability of real-world interactions. We introduce
IntellAgent, a scalable, open-source multi-agent framework designed to evaluate
conversational AI systems comprehensively. IntellAgent automates the creation
of diverse, synthetic benchmarks by combining policy-driven graph modeling,
realistic event generation, and interactive user-agent simulations. This
innovative approach provides fine-grained diagnostics, addressing the
limitations of static and manually curated benchmarks with coarse-grained
metrics. IntellAgent represents a paradigm shift in evaluating conversational
AI. By simulating realistic, multi-policy scenarios across varying levels of
complexity, IntellAgent captures the nuanced interplay of agent capabilities
and policy constraints. Unlike traditional methods, it employs a graph-based
policy model to represent relationships, likelihoods, and complexities of
policy interactions, enabling highly detailed diagnostics. IntellAgent also
identifies critical performance gaps, offering actionable insights for targeted
optimization. Its modular, open-source design supports seamless integration of
new domains, policies, and APIs, fostering reproducibility and community
collaboration. Our findings demonstrate that IntellAgent serves as an effective
framework for advancing conversational AI by addressing challenges in bridging
research and deployment. The framework is available at
https://github.com/plurai-ai/intellagent

摘要：大型語言模型 (LLM) 正在轉變人工智慧，演變成具備自主規劃和執行能力的任務導向系統。LLM 的主要應用之一是對話式 AI 系統，它必須應對多輪對話、整合特定領域的 API，並遵守嚴格的政策約束。然而，評估這些代理仍然是一項重大挑戰，因為傳統方法無法捕捉現實世界互動的複雜性和變異性。我們引入了 IntellAgent，一個可擴充、開放原始碼的多代理架構，旨在全面評估對話式 AI 系統。IntellAgent 自動化建立多樣化、合成的基準，方法是結合策略驅動的圖形建模、逼真的事件產生和互動使用者代理模擬。這種創新方法提供了細緻的診斷，解決了具有粗略指標的靜態和手動策劃基準的限制。IntellAgent 代表了評估對話式 AI 的典範轉移。通過模擬不同層級複雜性的逼真多策略場景，IntellAgent 捕捉到了代理功能和策略約束之間的細微交互。與傳統方法不同，它採用基於圖形的策略模型來表示策略交互的關係、可能性和複雜性，從而實現高度詳細的診斷。IntellAgent 還識別出關鍵效能差距，提供可行的見解，以進行目標最佳化。其模組化、開放原始碼的設計支援無縫整合新的領域、策略和 API，促進了可複製性和社群協作。我們的研究結果表明，IntellAgent 可作為一個有效的框架，透過解決研究和部署之間的挑戰來推進對話式 AI。這個框架可在 https://github.com/plurai-ai/intellagent 取得

##### **A Method for Multi-Hop Question Answering on Persian Knowledge Graph**
2501.16350v1 by Arash Ghafouri, Mahdi Firouzmandi, Hasan Naderi

Question answering systems are the latest evolution in information retrieval
technology, designed to accept complex queries in natural language and provide
accurate answers using both unstructured and structured knowledge sources.
Knowledge Graph Question Answering (KGQA) systems fulfill users' information
needs by utilizing structured data, representing a vast number of facts as a
graph. However, despite significant advancements, major challenges persist in
answering multi-hop complex questions, particularly in Persian. One of the main
challenges is the accurate understanding and transformation of these multi-hop
complex questions into semantically equivalent SPARQL queries, which allows for
precise answer retrieval from knowledge graphs. In this study, to address this
issue, a dataset of 5,600 Persian multi-hop complex questions was developed,
along with their decomposed forms based on the semantic representation of the
questions. Following this, Persian language models were trained using this
dataset, and an architecture was proposed for answering complex questions using
a Persian knowledge graph. Finally, the proposed method was evaluated against
similar systems on the PeCoQ dataset. The results demonstrated the superiority
of our approach, with an improvement of 12.57% in F1-score and 12.06% in
accuracy compared to the best comparable method.

摘要：問答系統是資訊檢索技術的最新演進，旨在接受自然語言的複雜查詢，並使用非結構化和結構化知識來源提供準確的答案。知識圖譜問答 (KGQA) 系統透過利用結構化資料，將大量的資訊以圖譜的形式呈現，來滿足使用者的資訊需求。然而，儘管有顯著的進展，在回答多跳複雜問題時仍存在著重大的挑戰，特別是在波斯語中。其中一項主要挑戰是將這些多跳複雜問題準確地理解並轉換成語義等效的 SPARQL 查詢，這能從知識圖譜中精確地擷取答案。在本研究中，為了解決這個問題，我們開發了一個包含 5,600 個波斯語多跳複雜問題的資料集，以及它們根據問題的語義表示所分解的形式。接著，我們使用此資料集訓練了波斯語語言模型，並提出了一個使用波斯語知識圖譜回答複雜問題的架構。最後，我們在 PeCoQ 資料集上針對類似的系統評估了所提出的方法。結果證明了我們方法的優越性，與最佳的可比較方法相比，F1 分數提升了 12.57%，準確度提升了 12.06%。

##### **Agent-as-Judge for Factual Summarization of Long Narratives**
2501.09993v1 by Yeonseok Jeong, Minsoo Kim, Seung-won Hwang, Byung-Hak Kim

Large Language Models (LLMs) have demonstrated near-human performance in
summarization tasks based on traditional metrics such as ROUGE and BERTScore.
However, these metrics do not adequately capture critical aspects of
summarization quality, such as factual accuracy, particularly for long
narratives (>100K tokens). Recent advances, such as LLM-as-a-Judge, address the
limitations of metrics based on lexical similarity but still exhibit factual
inconsistencies, especially in understanding character relationships and
states. In this work, we introduce NarrativeFactScore, a novel
"Agent-as-a-Judge" framework for evaluating and refining summaries. By
leveraging a Character Knowledge Graph (CKG) extracted from input and generated
summaries, NarrativeFactScore assesses the factual consistency and provides
actionable guidance for refinement, such as identifying missing or erroneous
facts. We demonstrate the effectiveness of NarrativeFactScore through a
detailed workflow illustration and extensive validation on widely adopted
benchmarks, achieving superior performance compared to competitive methods. Our
results highlight the potential of agent-driven evaluation systems to improve
the factual reliability of LLM-generated summaries.

摘要：大型語言模型 (LLM) 在摘要任務中展現出接近人類的表現，根據傳統指標，例如 ROUGE 和 BERTScore。然而，這些指標並未充分掌握摘要品質的關鍵面向，例如事實準確性，特別是針對長篇敘事 (>100K 個符號)。最近的進展，例如 LLM-as-a-Judge，解決了基於詞彙相似性的指標限制，但仍然表現出事實上的不一致性，特別是在理解角色關係和狀態方面。在這項工作中，我們引入了 NarrativeFactScore，一種新穎的「代理人作為評審」架構，用於評估和精煉摘要。透過利用從輸入和產生的摘要中萃取的角色知識圖譜 (CKG)，NarrativeFactScore 評估事實一致性，並提供可行的精煉指南，例如識別遺漏或錯誤的事實。我們透過詳細的工作流程說明和廣泛驗證在廣泛採用的基準上，證明了 NarrativeFactScore 的有效性，與競爭方法相比，達到了卓越的表現。我們的結果突顯了代理人驅動評估系統的潛力，以改善 LLM 生成的摘要的事實可靠性。

##### **FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**
2501.09957v2 by Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, S Kevin Zhou

To mitigate the hallucination and knowledge deficiency in large language
models (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)
has shown promising potential by utilizing KGs as external resource to enhance
LLMs reasoning. However, existing KG-RAG approaches struggle with a trade-off
between flexibility and retrieval quality. Modular methods prioritize
flexibility by avoiding the use of KG-fine-tuned models during retrieval,
leading to fixed retrieval strategies and suboptimal retrieval quality.
Conversely, coupled methods embed KG information within models to improve
retrieval quality, but at the expense of flexibility. In this paper, we propose
a novel flexible modular KG-RAG framework, termed FRAG, which synergizes the
advantages of both approaches. FRAG estimates the hop range of reasoning paths
based solely on the query and classify it as either simple or complex. To match
the complexity of the query, tailored pipelines are applied to ensure efficient
and accurate reasoning path retrieval, thus fostering the final reasoning
process. By using the query text instead of the KG to infer the structural
information of reasoning paths and employing adaptable retrieval strategies,
FRAG improves retrieval quality while maintaining flexibility. Moreover, FRAG
does not require extra LLMs fine-tuning or calls, significantly boosting
efficiency and conserving resources. Extensive experiments show that FRAG
achieves state-of-the-art performance with high efficiency and low resource
consumption.

摘要：<paragraph>為了減輕大型語言模型 (LLM) 中的幻覺和知識不足，基於知識圖譜 (KG) 的檢索增強生成 (RAG) 已展現出利用 KG 作為外部資源來增強 LLM 推理的潛力。然而，現有的 KG-RAG 方法在靈活性與檢索品質之間面臨取捨。模組化方法透過避免在檢索期間使用 KG 微調模型來優先考慮靈活性，導致固定的檢索策略和次佳的檢索品質。相反地，耦合方法將 KG 資訊嵌入模型中以改善檢索品質，但犧牲了靈活性。在本文中，我們提出了一個新穎的靈活模組化 KG-RAG 框架，稱為 FRAG，它協同了兩種方法的優點。FRAG 僅根據查詢估計推理路徑的跳躍範圍，並將其分類為簡單或複雜。為了匹配查詢的複雜性，應用客製化管道以確保有效且準確的推理路徑檢索，從而促進最終的推理過程。FRAG 使用查詢文字而非 KG 來推斷推理路徑的結構化資訊，並採用可適應的檢索策略，從而改善檢索品質，同時保持靈活性。此外，FRAG 不需要額外的 LLM 微調或呼叫，顯著提升效率並節省資源。大量的實驗表明，FRAG 以高效率和低資源消耗實現了最先進的效能。</paragraph>

##### **SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**
2501.09316v1 by Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You

Despite significant advancements in general-purpose AI agents, several
challenges still hinder their practical application in real-world scenarios.
First, the limited planning capabilities of Large Language Models (LLM)
restrict AI agents from effectively solving complex tasks that require
long-horizon planning. Second, general-purpose AI agents struggle to
efficiently utilize domain-specific knowledge and human expertise. In this
paper, we introduce the Standard Operational Procedure-guided Agent
(SOP-agent), a novel framework for constructing domain-specific agents through
pseudocode-style Standard Operational Procedures (SOPs) written in natural
language. Formally, we represent a SOP as a decision graph, which is traversed
to guide the agent in completing tasks specified by the SOP. We conduct
extensive experiments across tasks in multiple domains, including
decision-making, search and reasoning, code generation, data cleaning, and
grounded customer service. The SOP-agent demonstrates excellent versatility,
achieving performance superior to general-purpose agent frameworks and
comparable to domain-specific agent systems. Additionally, we introduce the
Grounded Customer Service Benchmark, the first benchmark designed to evaluate
the grounded decision-making capabilities of AI agents in customer service
scenarios based on SOPs.

摘要：儘管通用 AI 代理在一般用途上取得顯著進展，但仍有數項挑戰阻礙其在實際場景中的實用應用。
首先，大型語言模型 (LLM) 有限的規劃能力限制了 AI 代理有效解決需要長期規劃的複雜任務。其次，通用 AI 代理難以有效利用特定領域的知識和人類專業知識。在本文中，我們介紹了標準操作程序引導代理 (SOP-agent)，這是一個透過以自然語言撰寫的偽代碼風格標準操作程序 (SOP) 來建構特定領域代理的新穎架構。正式來說，我們將 SOP 表示為決策圖，並在其中穿梭以引導代理完成 SOP 指定的任務。我們在多個領域中的任務中進行廣泛的實驗，包括決策制定、搜尋和推理、程式碼生成、資料清理和基礎客戶服務。SOP-agent 展示出卓越的多功能性，其效能優於通用代理架構，且與特定領域代理系統相當。此外，我們介紹了基礎客戶服務基準，這是第一個基準，旨在評估 AI 代理在基於 SOP 的客戶服務場景中基礎決策制定能力。

##### **Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**
2501.09279v1 by Zijin Qiu, Jiepeng Liu, Yi Xia, Hongtuo Qi, Pengkun Liu

Flexibility in the AI-based residential layout design remains a significant
challenge, as traditional methods like rule-based heuristics and graph-based
generation often lack flexibility and require substantial design knowledge from
users. To address these limitations, we propose a cross-modal design approach
based on the Stable Diffusion model for generating flexible residential
layouts. The method offers multiple input types for learning objectives,
allowing users to specify both boundaries and layouts. It incorporates natural
language as design constraints and introduces ControlNet to enable stable
layout generation through two distinct pathways. We also present a scheme that
encapsulates design expertise within a knowledge graph and translates it into
natural language, providing an interpretable representation of design
knowledge. This comprehensibility and diversity of input options enable
professionals and non-professionals to directly express design requirements,
enhancing flexibility and controllability. Finally, experiments verify the
flexibility of the proposed methods under multimodal constraints better than
state-of-the-art models, even when specific semantic information about room
areas or connections is incomplete.

摘要：在基於 AI 的住宅佈局設計中，靈活性仍是一項重大挑戰，因為基於規則的啟發法和基於圖形的產生等傳統方法通常缺乏靈活性，且需要使用者具備大量的設計知識。為了解決這些限制，我們提出一個跨模態設計方法，該方法基於 Stable Diffusion 模型，用於產生靈活的住宅佈局。此方法提供多種輸入類型以進行學習目標，使用戶能夠同時指定邊界和佈局。它將自然語言作為設計約束，並引入 ControlNet，以透過兩個不同的路徑實現穩定的佈局產生。我們還提出了一個將設計專業知識封裝在知識圖形中的方案，並將其轉換為自然語言，提供設計知識的可詮釋表示。這種可理解性和輸入選項的多樣性使專業人士和非專業人士能夠直接表達設計需求，從而增強靈活性與可控性。最後，實驗驗證了所提出的方法在多模態約束下的靈活性優於最先進的模型，即使關於房間區域或連接的特定語義資訊不完整時也是如此。

##### **A Simple Graph Contrastive Learning Framework for Short Text Classification**
2501.09219v1 by Yonghao Liu, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan

Short text classification has gained significant attention in the information
age due to its prevalence and real-world applications. Recent advancements in
graph learning combined with contrastive learning have shown promising results
in addressing the challenges of semantic sparsity and limited labeled data in
short text classification. However, existing models have certain limitations.
They rely on explicit data augmentation techniques to generate contrastive
views, resulting in semantic corruption and noise. Additionally, these models
only focus on learning the intrinsic consistency between the generated views,
neglecting valuable discriminative information from other potential views. To
address these issues, we propose a Simple graph contrastive learning framework
for Short Text Classification (SimSTC). Our approach involves performing graph
learning on multiple text-related component graphs to obtain multi-view text
embeddings. Subsequently, we directly apply contrastive learning on these
embeddings. Notably, our method eliminates the need for data augmentation
operations to generate contrastive views while still leveraging the benefits of
multi-view contrastive learning. Despite its simplicity, our model achieves
outstanding performance, surpassing large language models on various datasets.

摘要：短文本分类在信息时代得到了广泛关注，因为它具有普遍性和现实世界的应用。最近，图学习与对比学习相结合的进步在解决短文本分类中语义稀疏性和标记数据有限的挑战方面显示出有希望的结果。然而，现有的模型具有一定的局限性。它们依赖于显式的数据增强技术来生成对比视图，从而导致语义损坏和噪声。此外，这些模型只关注学习生成视图之间的内在一致性，而忽略了其他潜在视图中有价值的判别信息。为了解决这些问题，我们提出了一个用于短文本分类的简单图对比学习框架 (SimSTC)。我们的方法涉及对多个文本相关组件图执行图学习以获得多视图文本嵌入。随后，我们直接对这些嵌入应用对比学习。值得注意的是，我们的方法消除了生成对比视图时对数据增强操作的需求，同时仍然利用了多视图对比学习的优势。尽管很简单，但我们的模型获得了出色的性能，在各种数据集上超越了大型语言模型。

##### **Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**
2501.09214v1 by Yonghao Liu, Mengyu Li, Wei Pang, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan

Short text classification, as a research subtopic in natural language
processing, is more challenging due to its semantic sparsity and insufficient
labeled samples in practical scenarios. We propose a novel model named
MI-DELIGHT for short text classification in this work. Specifically, it first
performs multi-source information (i.e., statistical information, linguistic
information, and factual information) exploration to alleviate the sparsity
issues. Then, the graph learning approach is adopted to learn the
representation of short texts, which are presented in graph forms. Moreover, we
introduce a dual-level (i.e., instance-level and cluster-level) contrastive
learning auxiliary task to effectively capture different-grained contrastive
information within massive unlabeled data. Meanwhile, previous models merely
perform the main task and auxiliary tasks in parallel, without considering the
relationship among tasks. Therefore, we introduce a hierarchical architecture
to explicitly model the correlations between tasks. We conduct extensive
experiments across various benchmark datasets, demonstrating that MI-DELIGHT
significantly surpasses previous competitive models. It even outperforms
popular large language models on several datasets.

摘要：短文本分類作為自然語言處理的研究子主題，由於其語義稀疏性和實際場景中標記樣本不足，因此更具挑戰性。在這項工作中，我們提出了一個名為 MI-DELIGHT 的新模型，用於短文本分類。具體來說，它首先執行多源信息（即統計信息、語言信息和事實信息）探索，以緩解稀疏性問題。然後，採用圖學習方法來學習以圖表形式呈現的短文本的表示。此外，我們引入了一個雙層級（即實例層級和群集層級）對比學習輔助任務，以有效捕獲大量未標記數據中的不同粒度對比信息。同時，以前的模型僅並行執行主任務和輔助任務，而沒有考慮任務之間的關係。因此，我們引入了一個分層架構來明確建模任務之間的相關性。我們在各種基準數據集上進行了廣泛的實驗，證明 MI-DELIGHT 明顯優於以前的競爭模型。它甚至在幾個數據集上優於流行的大語言模型。

##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

摘要：辨識材料化學中可靠的合成路徑是一項複雜的任務，特別是在聚合物科學中，因為巨分子的命名法錯綜複雜且經常不唯一。為了應對這個挑戰，我們提出一個整合大型語言模型 (LLM) 與知識圖譜 (KG) 的代理系統。透過利用 LLM 強大的化學物質名稱萃取和辨識能力，並將萃取的資料儲存在結構化的知識圖譜中，我們的系統可完全自動化相關文獻的檢索、反應資料的萃取、資料庫查詢、逆合成路徑樹的建構、透過檢索額外文獻進一步擴充，以及最佳反應路徑的建議。一種新穎的多分支反應路徑搜尋 (MBRPS) 演算法能探索所有路徑，特別專注於多分支路徑，協助 LLM 克服多分支路徑中的弱推理。這項工作代表首次嘗試開發一種完全自動化的逆合成規劃代理，專門針對由 LLM 驅動的巨分子量身打造。應用於聚醯亞胺合成，我們的新方法建構了一個包含數百條路徑的逆合成路徑樹，並建議最佳化路徑，包括已知和新穎的路徑，證明其在更廣泛應用中的效能和潛力。

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, Bálint Molnár

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

摘要：傳統基於相似度的模式比對方法無法解決特定領域複雜比對場景中的語意模糊性和衝突，這是因為缺乏常識和特定領域知識。大型語言模型 (LLM) 的幻覺問題也使得基於 LLM 的模式比對難以解決上述問題。因此，我們提出一個基於知識圖譜的檢索增強生成模型，用於模式比對，稱為 KG-RAG4SM。具體而言，KG-RAG4SM 引入了基於向量的、基於圖形遍歷的和基於查詢的圖形檢索，以及一種混合方法和排名方案，這些方案從外部大型知識圖譜 (KG) 中識別最相關的子圖。我們展示了基於 KG 的檢索增強 LLM 能夠在不進行任何重新訓練的情況下為複雜的比對案例生成更準確的結果。我們的實驗結果表明，在 MIMIC 資料集上，KG-RAG4SM 在準確度和 F1 分數方面分別比基於 LLM 的最新 (SOTA) 方法 (例如 Jellyfish-8B) 高出 35.89% 和 30.50%；具有 GPT-4o-mini 的 KG-RAG4SM 在準確度和 F1 分數方面分別比基於預先訓練語言模型 (PLM) 的 SOTA 方法 (例如 SMAT) 高出 69.20% 和 21.97% 在 Synthea 資料集上。結果還表明，我們的做法在端到端模式比對中更有效率，並且可以擴展到從大型 KG 中檢索。我們對來自現實世界模式比對場景的資料集進行的案例研究表明，我們的解決方案很好地緩解了 LLM 在模式比對中的幻覺問題。

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v2 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

摘要：近期成功解決邏輯推理問題的範例，利用了工具增強式大型語言模型 (LLM)，將自然語言陳述翻譯成一階邏輯 (FOL) 和外部定理證明器。
然而，FOL 陳述的正確性包含運算子與文字謂詞，由於缺乏用於比較已產生與真實 FOL 的可靠評估指標，因此經常無法驗證。在本文中，我們提出對現有指標敏感度和其與人類對 FOL 評估判斷一致性的全面研究。使用真實 FOL，我們仔細設計了真實 FOL 的各種擾動，以評估指標敏感度。我們對自然語言陳述取樣 FOL 翻譯候選項，並衡量自動指標與人類註解者之間的排名一致性。我們的經驗發現強調 n-gram 指標 BLEU 對文字擾動的過度敏感性，語義圖形指標 Smatch++ 對結構擾動的過度敏感性，以及 FOL 指標對運算子擾動的過度敏感性。我們還觀察到 BertScore 與人類判斷之間更緊密的對齊。此外，我們表明，與使用個別指標相比，組合指標可增強對齊和敏感度。

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

摘要：隨著 REST API 在現代網路服務中廣泛使用，對這些 API 進行全面的測試變得越來越重要。由於廣大的搜尋空間包含操作、參數和參數值以及它們複雜的依賴關係和約束，目前的測試工具存在程式碼覆蓋率低的問題，導致故障偵測不佳。為了解決這個限制，我們提出一個新工具 AutoRestTest，它整合了語義操作依賴圖 (SODG) 與多智能體強化學習 (MARL) 和大型語言模型 (LLM)，以進行有效的 REST API 測試。AutoRestTest 使用 SODG 確定依賴於操作的參數，並使用五個專門的代理 (操作、參數、值、依賴關係和標頭) 來識別操作的依賴關係並產生操作序列、參數組合和值。AutoRestTest 提供命令列介面和持續遙測，包括成功操作次數、偵測到的唯一伺服器錯誤和經過時間。完成後，AutoRestTest 會產生一份詳細報告，重點說明偵測到的錯誤和執行的操作。在本文中，我們介紹我們的工具並提出初步結果。

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

摘要：現有的低秩適應 (LoRA) 方法由於無法維持稀疏性，在稀疏大型語言模型 (LLM) 上面臨挑戰。最近的作品引入了透過使用額外的遮罩機制來擴充 LoRA 技術的方法來維持稀疏性。儘管有這些成功，但這些方法會增加記憶體和運算的開銷，這會影響 LoRA 方法的效率。為了回應這個限制，我們引入了 LoRS，這是一種創新的方法，旨在在微調稀疏 LLM 時同時實現記憶體和運算效率。為了減輕與維持稀疏性相關的龐大記憶體和運算需求，我們的做法結合了權重重新計算和計算圖形重新排列的策略。此外，我們還透過更好的適配器初始化來提高 LoRS 的有效性。這些創新在微調階段顯著減少了記憶體和運算消耗，同時實現了優於現有 LoRA 方法的效能等級。

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

摘要：在機器學習的當代，Transformer 已成為各種領域的事實標準方法，例如電腦視覺和自然語言處理。基於 Transformer 的解決方案是當前語言生成、影像和影片分類、分割、動作和物件辨識等最新方法的骨幹。有趣的是，雖然這些最新方法在其各自的領域中產生令人印象深刻的結果，但理解視覺和語言之間關係的問題仍然超出了我們的理解範圍。在這項工作中，我們以可解釋且以程式為基礎的方式，在時空中的事件之間提出了視覺和語言的共同基礎，以連接基於學習的視覺和語言最新模型，並提供描述影片的自然語言長期問題的解決方案。我們驗證了我們的演算法方法能夠在從各種資料集收集的影片中產生連貫、豐富且相關的文字描述，同時使用標準指標（例如 Bleu、ROUGE）和現代 LLM 作為評審方法。

##### **In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**
2501.08120v1 by Markus J. Buehler

The pursuit of automated scientific discovery has fueled progress from
symbolic logic to modern AI, forging new frontiers in reasoning and pattern
recognition. Transformers function as potential systems, where every possible
relationship remains latent potentiality until tasks impose constraints, akin
to measurement. Yet, refining their sampling requires more than probabilistic
selection: solutions must conform to specific structures or rules, ensuring
consistency and the invocation of general principles. We present
Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for
Exploratory Optimization of Reasoning), a framework that combines graph
reasoning with symbolic abstraction to dynamically expand domain knowledge.
Inspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a
structured mapping, where tasks yield knowledge graphs, abstract patterns, and
ultimately, final answers. Inspired by category theory, it encodes concepts as
nodes and their relationships as edges, supporting hierarchical inference and
adaptive learning through isomorphic representations. Demonstrations include
hypothesis generation, materials design, and creative reasoning, such as
discovering relationships between mythological concepts like 'thin places' with
materials science. We propose a 'knowledge garden growth' strategy that
integrates insights across domains, promoting interdisciplinary connections.
Results with a 3-billion-parameter Graph-PReFLexOR model show superior
reasoning depth and adaptability, underscoring the potential for transparent,
multidisciplinary AI-driven discovery. It lays the groundwork for general
autonomous reasoning solutions.

摘要：<paragraph>追求自動化科學發現已經推動了從符號邏輯到現代 AI 的進展，在推理和模式識別中開闢了新的領域。Transformer 作為潛在系統運作，其中每種可能的關係都保持潛在潛力，直到任務施加約束，類似於測量。然而，優化其採樣需要的不只是機率選擇：解決方案必須符合特定結構或規則，以確保一致性並呼應一般原則。我們提出了 Graph-PReFLexOR（基於圖形的基於偏好的遞迴語言建模，用於推理的探索性優化），一個將圖形推理與符號抽象相結合以動態擴展領域知識的框架。受強化學習的啟發，Graph-PReFLexOR 將推理定義為結構化對應，任務產生知識圖形、抽象模式以及最終答案。受範疇論的啟發，它將概念編碼為節點，將它們的關係編碼為邊緣，通過同構表示支持階層式推論和自適應學習。示範包括假設生成、材料設計和創造性推理，例如發現神話概念（如「薄弱點」）與材料科學之間的關係。我們提出了一種「知識花園成長」策略，它整合了跨領域的見解，促進了跨學科的聯繫。使用 30 億參數 Graph-PReFLexOR 模型的結果顯示出優異的推理深度和適應性，強調了透明、多學科 AI 驅動發現的潛力。它為通用的自主推理解決方案奠定了基礎。</paragraph>

##### **Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**
2501.07845v1 by Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

Large language models (LLMs) have demonstrated remarkable success across a
wide range of tasks; however, they still encounter challenges in reasoning
tasks that require understanding and inferring relationships between distinct
pieces of information within text sequences. This challenge is particularly
pronounced in tasks involving multi-step processes, such as logical reasoning
and multi-hop question answering, where understanding implicit relationships
between entities and leveraging multi-hop connections in the given context are
crucial. Graphs, as fundamental data structures, explicitly represent pairwise
relationships between entities, thereby offering the potential to enhance LLMs'
reasoning capabilities. External graphs have proven effective in supporting
LLMs across multiple tasks. However, in many reasoning tasks, no pre-existing
graph structure is provided. Can we structure implicit knowledge derived from
context into graphs to assist LLMs in reasoning? In this paper, we propose
Reasoning with Graphs (RwG) by first constructing explicit graphs from the
context and then leveraging these graphs to enhance LLM reasoning performance
on reasoning tasks. Extensive experiments demonstrate the effectiveness of the
proposed method in improving both logical reasoning and multi-hop question
answering tasks.

摘要：大型語言模型 (LLM) 已在各種任務中展現出顯著的成功；然而，它們在推理任務中仍會遇到挑戰，這些任務需要理解和推論文字序列中不同資訊片段之間的關係。這個挑戰在涉及多步驟程序的任務中特別明顯，例如邏輯推理和多跳問題解答，其中理解實體之間的隱含關係並利用給定脈絡中的多跳連接至關重要。圖形作為基本的資料結構，明確表示實體之間成對的關係，從而提供增強 LLM 推理能力的潛力。外部圖形已被證明可以有效支援 LLM 執行多項任務。然而，在許多推理任務中，並沒有提供預先存在的圖形結構。我們能將從脈絡中衍生的隱含知識結構成圖形，以協助 LLM 進行推理嗎？在本文中，我們提出使用圖形進行推理 (RwG)，方法是首先從脈絡中建構明確的圖形，然後利用這些圖形來增強 LLM 在推理任務中的推理效能。廣泛的實驗證明了所提出的方法在改進邏輯推理和多跳問題解答任務方面的有效性。

##### **Flow: A Modular Approach to Automated Agentic Workflow Generation**
2501.07834v1 by Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu

Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.

摘要：大型語言模型（LLM）驅動的多代理架構已在自動化規劃和任務執行中展現出巨大的成功。然而，在執行期間有效調整代理工作流程尚未得到充分研究。有效的工作流程調整至關重要，因為在許多實際場景中，初始計畫必須即時調整以應對無法預見的挑戰和不斷變化的條件，以確保複雜任務的有效執行。在本文中，我們將工作流程定義為頂點上的活動（AOV）圖形。我們根據歷史績效和先前的 AOV 與 LLM 代理，透過動態調整任務分配，持續優化工作流程。為了進一步提升系統效能，我們強調基於測量並行性和依賴複雜性的工作流程設計中的模組化。我們提出的多代理架構達到了有效子任務並行執行、目標達成和容錯。跨不同實際任務的實證結果證明，透過動態工作流程更新和模組化，多代理架構的效率有了顯著的提升。

##### **Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**
2501.07766v1 by Bingchen Liu, Xin Li

Large Language Models (LLMs) have attracted a lot of attention in various
fields due to their superior performance, aiming to train hundreds of millions
or more parameters on large amounts of text data to understand and generate
natural language. As the superior performance of LLMs becomes apparent, they
are increasingly being applied to knowledge graph embedding (KGE) related tasks
to improve the processing results. As a deep learning model in the field of
Natural Language Processing (NLP), it learns a large amount of textual data to
predict the next word or generate content related to a given text. However,
LLMs have recently been invoked to varying degrees in different types of KGE
related scenarios such as multi-modal KGE and open KGE according to their task
characteristics. In this paper, we investigate a wide range of approaches for
performing LLMs-related tasks in different types of KGE scenarios. To better
compare the various approaches, we summarize each KGE scenario in a
classification. In addition to the categorization methods, we provide a tabular
overview of the methods and their source code links for a more direct
comparison. In the article we also discuss the applications in which the
methods are mainly used and suggest several forward-looking directions for the
development of this new research area.

摘要：大型語言模型 (LLM) 由於其優異的性能，在各個領域中引起了許多關注，目標是訓練數億或更多參數，以理解和產生大量文本資料中的自然語言。隨著 LLM 優異性能的顯現，它們正越來越廣泛地應用於知識圖譜嵌入 (KGE) 相關任務，以改善處理結果。作為自然語言處理 (NLP) 領域中的深度學習模型，它學習大量的文本資料，以預測下一個單字或產生與給定文本相關的內容。然而，根據任務特性，LLM 最近已在不同類型的 KGE 相關場景（例如多模態 KGE 和開放式 KGE）中以不同程度被採用。在本文中，我們探討了在不同類型的 KGE 場景中執行與 LLM 相關任務的各種方法。為了更好地比較各種方法，我們在分類中總結了每個 KGE 場景。除了分類方法之外，我們還提供了方法及其原始碼連結的表格概觀，以便進行更直接的比較。在本文中，我們還討論了這些方法主要用於哪些應用，並建議了幾個這個新研究領域發展的前瞻性方向。

##### **SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**
2501.07639v1 by Fabien Bernier, Jun Cao, Maxime Cordy, Salah Ghamizi

Efficiently solving Optimal Power Flow (OPF) problems in power systems is
crucial for operational planning and grid management. There is a growing need
for scalable algorithms capable of handling the increasing variability,
constraints, and uncertainties in modern power networks while providing
accurate and fast solutions. To address this, machine learning techniques,
particularly Graph Neural Networks (GNNs) have emerged as promising approaches.
This letter introduces SafePowerGraph-LLM, the first framework explicitly
designed for solving OPF problems using Large Language Models (LLM)s. The
proposed approach combines graph and tabular representations of power grids to
effectively query LLMs, capturing the complex relationships and constraints in
power systems. A new implementation of in-context learning and fine-tuning
protocols for LLMs is introduced, tailored specifically for the OPF problem.
SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.
Our study reveals the impact of LLM architecture, size, and fine-tuning and
demonstrates our framework's ability to handle realistic grid components and
constraints.

摘要：在電力系統中有效解決最佳電力流 (OPF) 問題對於運營規劃和電網管理至關重要。對於能夠處理現代電力網路中日益增加的可變性、約束和不確定性的可擴充演算法，同時提供準確且快速的解決方案，需求與日俱增。為了解決此問題，機器學習技術，特別是圖神經網路 (GNN) 已成為有前景的方法。本信介紹了 SafePowerGraph-LLM，這是第一個明確設計用於使用大型語言模型 (LLM) 解決 OPF 問題的框架。所提出的方法結合了電力網路的圖形和表格表示，以有效查詢 LLM，捕捉電力系統中的複雜關係和約束。引入了針對 LLM 的情境學習和微調協定的新實作，專門針對 OPF 問題量身打造。SafePowerGraph-LLM 使用現成的 LLM 展示了可靠的效能。我們的研究揭示了 LLM 架構、大小和微調的影響，並展示了我們的框架處理現實電網組成和約束的能力。

##### **ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**
2501.07078v1 by Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu

In the current development of large language models (LLMs), it is important
to ensure the accuracy and reliability of the underlying data sources. LLMs are
critical for various applications, but they often suffer from hallucinations
and inaccuracies due to knowledge gaps in the training data. Knowledge graphs
(KGs), as a powerful structural tool, could serve as a vital external
information source to mitigate the aforementioned issues. By providing a
structured and comprehensive understanding of real-world data, KGs enhance the
performance and reliability of LLMs. However, it is common that errors exist in
KGs while extracting triplets from unstructured data to construct KGs. This
could lead to degraded performance in downstream tasks such as
question-answering and recommender systems. Therefore, anomaly detection in KGs
is essential to identify and correct these errors. This paper presents an
anomaly detection algorithm in knowledge graphs with dual-channel learning
(ADKGD). ADKGD leverages a dual-channel learning approach to enhance
representation learning from both the entity-view and triplet-view
perspectives. Furthermore, using a cross-layer approach, our framework
integrates internal information aggregation and context information
aggregation. We introduce a kullback-leibler (KL)-loss component to improve the
accuracy of the scoring function between the dual channels. To evaluate ADKGD's
performance, we conduct empirical studies on three real-world KGs: WN18RR,
FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms
the state-of-the-art anomaly detection algorithms. The source code and datasets
are publicly available at https://github.com/csjywu1/ADKGD.

摘要：<paragraph>在大語言模型（LLM）的當前發展中，確保基礎數據來源的準確性和可靠性非常重要。LLM 對於各種應用至關重要，但由於訓練數據中的知識差距，它們經常會出現幻覺和不準確的情況。知識圖譜 (KG) 作為一種強大的結構化工具，可以作為一個重要的外部信息來源，以減輕上述問題。通過提供對現實世界數據的結構化和全面理解，KG 提高了 LLM 的性能和可靠性。然而，在從非結構化數據中提取三元組以構建 KG 時，KG 中存在錯誤是很常見的。這可能會導致下游任務（例如問答和推薦系統）的性能下降。因此，KG 中的異常檢測對於識別和糾正這些錯誤至關重要。本文提出了一個具有雙通道學習的知識圖譜異常檢測算法 (ADKGD)。ADKGD 利用雙通道學習方法從實體視角和三元組視角增強表示學習。此外，我們的框架使用跨層方法整合了內部信息聚合和上下文信息聚合。我們引入了 Kullback-Leibler (KL) 損失組件，以提高雙通道之間評分函數的準確性。為了評估 ADKGD 的性能，我們對三個真實世界 KG：WN18RR、FB15K 和 NELL-995 進行了實證研究。實驗結果表明，ADKGD 優於最先進的異常檢測算法。源代碼和數據集可在 https://github.com/csjywu1/ADKGD 公開獲得。</paragraph>

##### **Causal Claims in Economics**
2501.06873v1 by Prashant Garg, Thiemo Fetzer

We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a
custom language model to construct knowledge graphs that map economic concepts
and their relationships. We distinguish between general claims and those
documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document
a substantial rise in the share of causal claims-from roughly 4% in 1990 to
nearly 28% in 2020-reflecting the growing influence of the "credibility
revolution." We find that causal narrative complexity (e.g., the depth of
causal chains) strongly predicts both publication in top-5 journals and higher
citation counts, whereas non-causal complexity tends to be uncorrelated or
negatively associated with these outcomes. Novelty is also pivotal for top-5
publication, but only when grounded in credible causal methods: introducing
genuinely new causal edges or paths markedly increases both the likelihood of
acceptance at leading outlets and long-run citations, while non-causal novelty
exhibits weak or even negative effects. Papers engaging with central, widely
recognized concepts tend to attract more citations, highlighting a divergence
between factors driving publication success and long-term academic impact.
Finally, bridging underexplored concept pairs is rewarded primarily when
grounded in causal methods, yet such gap filling exhibits no consistent link
with future citations. Overall, our findings suggest that methodological rigor
and causal innovation are key drivers of academic recognition, but sustained
impact may require balancing novel contributions with conceptual integration
into established economic discourse.

摘要：<paragraph>我們使用自訂語言模型分析了 1980 年至 2023 年超過 44,000 份 NBER 和 CEPR 工作論文，以建構知識圖譜，對經濟概念及其關係進行對應。我們區分一般性論述和透過因果推論方法（例如 DiD、IV、RDD、RCT）記錄的論述。我們記錄到因果論述的份額大幅上升，從 1990 年的約 4% 上升到 2020 年的近 28%，反映了「可信度革命」的影響力日益增強。我們發現因果敘述的複雜性（例如因果鏈的深度）強烈預測了在頂尖 5 大期刊的發表和較高的引用次數，而非因果複雜性則往往與這些結果無關或呈負相關。新穎性對於頂尖 5 大期刊的發表也至關重要，但前提是建立在可信的因果方法的基礎上：引入真正新的因果邊緣或路徑顯著增加了在頂尖媒體上被接受的可能性和長期引用，而非因果新穎性則表現出微弱甚至負面的影響。探討中心、廣泛認可的概念的論文往往會吸引更多引用，突顯出推動發表成功和長期學術影響的因素之間的差異。最後，填補探索不足的概念對時，主要是建立在因果方法的基礎上，但這種差距填補並未表現出與未來引用的一致關聯。總的來說，我們的研究結果表明，方法論嚴謹性和因果創新是學術認可的主要驅動力，但持續的影響可能需要平衡新穎貢獻與融入既定的經濟論述中的概念整合。</paragraph>

##### **MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**
2501.06713v3 by Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang

The growing demand for efficient and lightweight Retrieval-Augmented
Generation (RAG) systems has highlighted significant challenges when deploying
Small Language Models (SLMs) in existing RAG frameworks. Current approaches
face severe performance degradation due to SLMs' limited semantic understanding
and text processing capabilities, creating barriers for widespread adoption in
resource-constrained scenarios. To address these fundamental limitations, we
present MiniRAG, a novel RAG system designed for extreme simplicity and
efficiency. MiniRAG introduces two key technical innovations: (1) a
semantic-aware heterogeneous graph indexing mechanism that combines text chunks
and named entities in a unified structure, reducing reliance on complex
semantic understanding, and (2) a lightweight topology-enhanced retrieval
approach that leverages graph structures for efficient knowledge discovery
without requiring advanced language capabilities. Our extensive experiments
demonstrate that MiniRAG achieves comparable performance to LLM-based methods
even when using SLMs while requiring only 25\% of the storage space.
Additionally, we contribute a comprehensive benchmark dataset for evaluating
lightweight RAG systems under realistic on-device scenarios with complex
queries. We fully open-source our implementation and datasets at:
https://github.com/HKUDS/MiniRAG.

摘要：隨著高效且輕量的檢索增強生成 (RAG) 系統需求不斷增加，在現有 RAG 架構中部署小型語言模型 (SLM) 時突顯出重大挑戰。由於 SLM 受限的語義理解和文字處理能力，目前的方法面臨嚴重的效能下降，這為在資源受限的情況下廣泛採用創造了障礙。為了解決這些基本限制，我們提出了 MiniRAG，這是一個專為極致簡潔性和效率而設計的新穎 RAG 系統。MiniRAG 引入了兩項關鍵技術創新：(1) 一個語義感知異質圖形索引機制，它在統一結構中結合了文字區塊和命名實體，減少了對複雜語義理解的依賴，以及 (2) 一種輕量級拓撲增強檢索方法，它利用圖形結構進行有效知識發現，而不需要先進的語言能力。我們廣泛的實驗證明，即使在使用 SLM 時，MiniRAG 也能達到與基於 LLM 的方法相當的效能，同時只需要 25% 的儲存空間。此外，我們為評估輕量級 RAG 系統在具有複雜查詢的實際裝置場景中做出了全面的基準資料集貢獻。我們在以下位置完全開放原始碼實作和資料集：https://github.com/HKUDS/MiniRAG。

##### **Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**
2501.06699v1 by Aidan Hogan, Xin Luna Dong, Denny Vrandečić, Gerhard Weikum

Much has been discussed about how Large Language Models, Knowledge Graphs and
Search Engines can be combined in a synergistic manner. A dimension largely
absent from current academic discourse is the user perspective. In particular,
there remain many open questions regarding how best to address the diverse
information needs of users, incorporating varying facets and levels of
difficulty. This paper introduces a taxonomy of user information needs, which
guides us to study the pros, cons and possible synergies of Large Language
Models, Knowledge Graphs and Search Engines. From this study, we derive a
roadmap for future research.

摘要：對於大型語言模型、知識圖譜和搜尋引擎如何能以協同的方式結合，已經有許多討論。目前學術論述中很大程度上忽略了一個面向，那就是使用者的觀點。特別是，關於如何最好地滿足使用者多元的資訊需求，並納入不同面向和難度層級，仍有許多未解決的問題。本文介紹了一個使用者資訊需求的分類法，引導我們研究大型語言模型、知識圖譜和搜尋引擎的優缺點和可能的協同作用。從這項研究中，我們衍生出未來研究的路線圖。

##### **Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**
2501.06628v1 by Mohammed Maree

This paper introduces a neuro-symbolic approach for relational exploration in
cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for
explanation generation and a novel mathematical framework to quantify the
interestingness of relationships. We demonstrate the importance of
interestingness measure using a quantitative analysis, by highlighting its
impact on the overall performance of our proposed system, particularly in terms
of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked
Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of
0.68, and an F1-score of 0.69, representing an improvement compared to
graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based
baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our
LLM-powered explanations exhibit better quality, reflected in BLEU (0.52),
ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline
approaches. We show a strong correlation (0.65) between interestingness measure
and the quality of generated explanations, validating its effectiveness. The
findings highlight the importance of LLMs and a mathematical formalization for
interestingness in enhancing the effectiveness of relational exploration in
cultural heritage knowledge graphs, with results that are measurable and
testable. We further show that the system enables more effective exploration
compared to purely knowledge-based and graph-based methods.

摘要：這篇論文介紹了一種神經符號方法，用於文化遺產知識圖譜中的關係探索，利用大型語言模型 (LLM) 進行解釋生成，並利用一種新穎的數學框架來量化關係的趣味性。我們透過定量分析展示了趣味性測量的重要性，強調它對我們所提出的系統整體效能的影響，特別是在精確度、召回率和 F1 分數方面。使用 Wikidata 文化遺產連結開放資料 (WCH-LOD) 資料集，我們的做法產生了 0.70 的精確度、0.68 的召回率和 0.69 的 F1 分數，與基於圖形 (精確度：0.28、召回率：0.25、F1 分數：0.26) 和基於知識的基線 (精確度：0.45、召回率：0.42、F1 分數：0.43) 相比，這是一個進步。此外，我們由 LLM 促成的解釋展現出更好的品質，反映在 BLEU (0.52)、ROUGE-L (0.58) 和 METEOR (0.63) 分數上，都高於基線方法。我們顯示了趣味性測量和產生的解釋品質之間強烈的相關性 (0.65)，驗證了它的有效性。這些發現突顯了 LLM 和趣味性的數學形式化在增強文化遺產知識圖譜中關係探索的有效性方面的重要性，其結果是可以衡量和測試的。我們進一步表明，與純粹基於知識和基於圖形的方法相比，該系統能進行更有效的探索。

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v2 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

摘要：<paragraph>我們為中文醫療社群引入了全球首創的臨床術語，即 MedCT，並附帶臨床基礎模型 MedBERT 和實體連結模型 MedLink。MedCT 系統能標準化並以程式設計方式呈現中文臨床資料，進而刺激新藥、治療途徑的開發，並為人口眾多的華人社群帶來更好的病人治療成果。此外，MedCT 知識圖譜提供一個有原則的機制，以最小化大型語言模型 (LLM) 的幻覺問題，因此在基於 LLM 的臨床應用中達到了顯著的準確性和安全性。透過利用 LLM 生成和表達能力的新興功能，我們得以快速建置一個生產品質的術語系統，並在三個月內部署到實際臨床領域，而像 SNOMED CT 這樣的傳統術語系統則經歷了二十多年的開發。我們的實驗顯示，MedCT 系統在語義匹配和實體連結任務中達到了最先進 (SOTA) 的效能，不只適用於中文，也適用於英文。我們還透過在具代表性的臨床任務中應用 MedCT 和 LLM 來進行縱向實地實驗，包括電子健康紀錄 (EHR) 自動產生和用於診斷決策的醫療文件搜尋。我們的研究顯示 MedCT 對臨床工作流程和病人治療成果有許多價值，特別是在新型態的臨床 LLM 應用中。我們以充分的工程細節說明了我們的做法，因此實作其他非英語社會的臨床術語應易於複製。我們開放釋出我們的術語、模型和演算法，以及用於開發的實際臨床資料集。</paragraph>

##### **Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**
2501.06382v2 by Mumin Jia, Jairo Diaz-Rodriguez

Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change can occur only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling "spontaneous" conversations more
naturally. To the best of our knowledge, no prior work has explored these
questions with a focus as closely aligned to human conversation and thought.

摘要：人類認知可以自發轉換對話主題，通常是由情緒或語境信號觸發。相比之下，基於自我注意力的語言模型依賴於輸入詞元的結構化統計線索來預測下一個詞元，缺乏這種自發性。受此區別的啟發，我們研究了影響下一個詞元預測以改變輸入序列主題的因素。我們根據將主題定義為一組詞元優先級圖 (TPG) 來定義主題連續性、模棱兩可的序列和主題變化的概念。使用簡化的單層自我注意力架構，我們推導出主題變化的分析表徵。具體來說，我們證明了 (1) 模型維護與輸入主題相關的詞元的優先順序，(2) 只有當低優先順序的詞元多於輸入主題的所有高優先順序的詞元時，才會發生主題變化，以及 (3) 與人類認知不同，較長的上下文長度和重疊的主題會降低自發重定向的可能性。這些見解突顯了人類認知和基於自我注意力的模型在導航主題變化方面的差異，並強調了設計能夠更自然地處理「自發」對話的對話式 AI 所面臨的挑戰。據我們所知，沒有先前的研究以如此緊密貼近人類對話和思維的方式探討這些問題。


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-07**|**"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**|Shihan Fu et.al.|[2502.05115v1](http://arxiv.org/abs/2502.05115v1)|null|
|**2025-02-07**|**Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**|Thierry Bossy et.al.|[2502.05087v1](http://arxiv.org/abs/2502.05087v1)|null|
|**2025-02-07**|**MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**|Minrui Chen et.al.|[2502.04794v1](http://arxiv.org/abs/2502.04794v1)|null|
|**2025-02-06**|**MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification**|Wei Fan et.al.|[2502.04515v1](http://arxiv.org/abs/2502.04515v1)|null|
|**2025-02-06**|**Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions**|Khushboo Verma et.al.|[2502.04423v1](http://arxiv.org/abs/2502.04423v1)|null|
|**2025-02-06**|**Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**|Tewele W. Tareke et.al.|[2502.04083v1](http://arxiv.org/abs/2502.04083v1)|null|
|**2025-02-06**|**Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**|Ran Song et.al.|[2502.04034v1](http://arxiv.org/abs/2502.04034v1)|null|
|**2025-02-06**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413v1](http://arxiv.org/abs/2502.04413v1)|null|
|**2025-02-06**|**Transforming Multimodal Models into Action Models for Radiotherapy**|Matteo Ferrante et.al.|[2502.04408v1](http://arxiv.org/abs/2502.04408v1)|null|
|**2025-02-06**|**Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning**|Bokeng Zheng et.al.|[2502.04399v1](http://arxiv.org/abs/2502.04399v1)|null|
|**2025-02-06**|**Multimodal Medical Code Tokenizer**|Xiaorui Su et.al.|[2502.04397v1](http://arxiv.org/abs/2502.04397v1)|null|
|**2025-02-06**|**A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**|Chaoyin She et.al.|[2502.03772v1](http://arxiv.org/abs/2502.03772v1)|[link](https://github.com/Asunatan/HSQformer)|
|**2025-02-05**|**Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings**|Guangyao Zheng et.al.|[2502.04386v1](http://arxiv.org/abs/2502.04386v1)|null|
|**2025-02-05**|**Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function**|Mehrdad Asadi et.al.|[2502.03591v1](http://arxiv.org/abs/2502.03591v1)|[link](https://github.com/the-mercury/CIHMLC)|
|**2025-02-05**|**Code Simulation as a Proxy for High-order Tasks in Large Language Models**|Emanuele La Malfa et.al.|[2502.03568v1](http://arxiv.org/abs/2502.03568v1)|null|
|**2025-02-05**|**Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning**|Jonathan Kim et.al.|[2502.04381v1](http://arxiv.org/abs/2502.04381v1)|null|
|**2025-02-05**|**Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin**|Sarah Al-Shareeda et.al.|[2502.03396v1](http://arxiv.org/abs/2502.03396v1)|null|
|**2025-02-05**|**RadVLM: A Multitask Conversational Vision-Language Model for Radiology**|Nicolas Deperrois et.al.|[2502.03333v1](http://arxiv.org/abs/2502.03333v1)|null|
|**2025-02-05**|**MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters**|Amin Dada et.al.|[2502.03298v1](http://arxiv.org/abs/2502.03298v1)|null|
|**2025-02-05**|**Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans**|Matthias Schwab et.al.|[2502.03272v1](http://arxiv.org/abs/2502.03272v1)|null|
|**2025-02-05**|**Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration**|Li Pan et.al.|[2502.03238v2](http://arxiv.org/abs/2502.03238v2)|null|
|**2025-02-05**|**MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**|Seonok Kim et.al.|[2502.03004v1](http://arxiv.org/abs/2502.03004v1)|null|
|**2025-02-05**|**Contrastive Token-level Explanations for Graph-based Rumour Detection**|Daniel Wai Kit Chin et.al.|[2502.04366v1](http://arxiv.org/abs/2502.04366v1)|null|
|**2025-02-05**|**AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case Study on Detecting Time of Birth**|Jorge García-Torres et.al.|[2502.04365v1](http://arxiv.org/abs/2502.04365v1)|null|
|**2025-02-04**|**3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**|Weicheng Zhu et.al.|[2502.02779v1](http://arxiv.org/abs/2502.02779v1)|null|
|**2025-02-04**|**Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**|Obed Korshie Dzikunu et.al.|[2502.02756v1](http://arxiv.org/abs/2502.02756v1)|null|
|**2025-02-04**|**MedRAX: Medical Reasoning Agent for Chest X-ray**|Adibvafa Fallahpour et.al.|[2502.02673v1](http://arxiv.org/abs/2502.02673v1)|null|
|**2025-02-04**|**Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription**|Mahdi Alkaeed et.al.|[2502.04356v1](http://arxiv.org/abs/2502.04356v1)|null|
|**2025-02-04**|**Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents**|Shayan Kiyani et.al.|[2502.02561v1](http://arxiv.org/abs/2502.02561v1)|null|
|**2025-02-04**|**A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation**|Edward Ellis et.al.|[2502.02489v1](http://arxiv.org/abs/2502.02489v1)|null|
|**2025-02-04**|**Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment**|Yaling Shen et.al.|[2502.02438v1](http://arxiv.org/abs/2502.02438v1)|null|
|**2025-02-04**|**Test Time Training for 4D Medical Image Interpolation**|Qikang Zhang et.al.|[2502.02341v1](http://arxiv.org/abs/2502.02341v1)|[link](https://github.com/chaostheproducer/ttt4d)|
|**2025-02-04**|**Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation**|Atharva Mangeshkumar Agrawal et.al.|[2502.02249v1](http://arxiv.org/abs/2502.02249v1)|null|
|**2025-02-04**|**Deep Learning-Based Facial Expression Recognition for the Elderly: A Systematic Review**|F. Xavier Gaya-Morey et.al.|[2502.02618v1](http://arxiv.org/abs/2502.02618v1)|null|
|**2025-02-04**|**Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care**|Yuxiao Cheng et.al.|[2502.02109v1](http://arxiv.org/abs/2502.02109v1)|null|
|**2025-02-04**|**JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment**|Yehan Yan et.al.|[2502.04345v1](http://arxiv.org/abs/2502.04345v1)|null|
|**2025-02-03**|**An Agentic AI Workflow for Detecting Cognitive Concerns in Real-world Data**|Jiazi Tian et.al.|[2502.01789v1](http://arxiv.org/abs/2502.01789v1)|null|
|**2025-02-03**|**Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis**|Chacha Chen et.al.|[2502.03482v1](http://arxiv.org/abs/2502.03482v1)|null|
|**2025-02-03**|**Improving Transformer World Models for Data-Efficient RL**|Antoine Dedieu et.al.|[2502.01591v1](http://arxiv.org/abs/2502.01591v1)|null|
|**2025-02-03**|**Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data**|Zhi Zhang et.al.|[2502.01377v1](http://arxiv.org/abs/2502.01377v1)|null|
|**2025-02-03**|**OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology**|Chengfeng Zhou et.al.|[2502.01243v1](http://arxiv.org/abs/2502.01243v1)|null|
|**2025-02-03**|**MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks**|Alejandro Guerra-Manzanares et.al.|[2502.01158v1](http://arxiv.org/abs/2502.01158v1)|null|
|**2025-02-03**|**Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations**|Qian Chen et.al.|[2502.01141v1](http://arxiv.org/abs/2502.01141v1)|null|
|**2025-02-03**|**Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings**|Mithun Saha et.al.|[2502.01108v1](http://arxiv.org/abs/2502.01108v1)|null|
|**2025-02-03**|**Tutorial on Using Machine Learning and Deep Learning Models for Mental Illness Detection**|Yeyubei Zhang et.al.|[2502.04342v1](http://arxiv.org/abs/2502.04342v1)|null|
|**2025-02-02**|**Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model**|Hadas Ben-Atya et.al.|[2502.01691v1](http://arxiv.org/abs/2502.01691v1)|null|
|**2025-02-02**|**Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment**|Si-Ioi Ng et.al.|[2502.01685v1](http://arxiv.org/abs/2502.01685v1)|null|
|**2025-02-02**|**Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images**|Shengtian Sang et.al.|[2502.00712v1](http://arxiv.org/abs/2502.00712v1)|null|
|**2025-02-02**|**TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion**|Linglong Wu et.al.|[2502.00695v1](http://arxiv.org/abs/2502.00695v1)|null|
|**2025-02-02**|**Enhanced Convolutional Neural Networks for Improved Image Classification**|Xiaoran Yang et.al.|[2502.00663v1](http://arxiv.org/abs/2502.00663v1)|null|
|**2025-02-02**|**Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective**|Yujin Oh et.al.|[2502.00619v1](http://arxiv.org/abs/2502.00619v1)|null|
|**2025-02-01**|**Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions**|Samiran Dey et.al.|[2502.00568v1](http://arxiv.org/abs/2502.00568v1)|[link](https://github.com/Samiran-Dey/PathoGen)|
|**2025-02-01**|**Looking into the Future of Health-Care Services: Can Life-Like Agents Change the Future of Health-Care Services?**|Mohammad Saleh Torkestani et.al.|[2502.00495v1](http://arxiv.org/abs/2502.00495v1)|null|
|**2025-02-01**|**Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities**|Aishik Mandal et.al.|[2502.00451v1](http://arxiv.org/abs/2502.00451v1)|null|
|**2025-01-31**|**EcoWeedNet: A Lightweight and Automated Weed Detection Method for Sustainable Next-Generation Agricultural Consumer Electronics**|Omar H. Khater et.al.|[2502.00205v1](http://arxiv.org/abs/2502.00205v1)|null|
|**2025-01-31**|**DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access Dermatology Datasets**|Abdurrahim Yilmaz et.al.|[2502.00196v1](http://arxiv.org/abs/2502.00196v1)|null|
|**2025-01-31**|**Multimodal MRI-Ultrasound AI for Prostate Cancer Detection Outperforms Radiologist MRI Interpretation: A Multi-Center Study**|Hassan Jahanandish et.al.|[2502.00146v1](http://arxiv.org/abs/2502.00146v1)|null|
|**2025-01-31**|**AIN: The Arabic INclusive Large Multimodal Model**|Ahmed Heakl et.al.|[2502.00094v2](http://arxiv.org/abs/2502.00094v2)|null|
|**2025-01-31**|**Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**|Misha P. T Kaandorp et.al.|[2501.19338v1](http://arxiv.org/abs/2501.19338v1)|null|
|**2025-01-31**|**Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**|Halil Ibrahim Aysel et.al.|[2501.19271v1](http://arxiv.org/abs/2501.19271v1)|null|
|**2025-01-31**|**Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using Generative Artificial Intelligence**|Aurora Rofena et.al.|[2501.19176v1](http://arxiv.org/abs/2501.19176v1)|null|
|**2025-01-31**|**Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**|Xiangyu Sun et.al.|[2501.19086v1](http://arxiv.org/abs/2501.19086v1)|null|
|**2025-01-30**|**Survey and Improvement Strategies for Gene Prioritization with Large Language Models**|Matthew Neeley et.al.|[2501.18794v1](http://arxiv.org/abs/2501.18794v1)|null|
|**2025-01-30**|**Synthetic Data Generation for Augmenting Small Samples**|Dan Liu et.al.|[2501.18741v1](http://arxiv.org/abs/2501.18741v1)|null|
|**2025-01-30**|**A Multi-Layered Large Language Model Framework for Disease Prediction**|Malak Mohamed et.al.|[2502.00063v1](http://arxiv.org/abs/2502.00063v1)|null|
|**2025-01-30**|**A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series**|Yifan Wang et.al.|[2501.18367v1](http://arxiv.org/abs/2501.18367v1)|null|
|**2025-01-30**|**MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding**|Yuxin Zuo et.al.|[2501.18362v1](http://arxiv.org/abs/2501.18362v1)|null|
|**2025-01-30**|**CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized Codes**|Yicheng Wu et.al.|[2501.18328v1](http://arxiv.org/abs/2501.18328v1)|null|
|**2025-01-30**|**A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification**|Shayli Farshchiha et.al.|[2501.18294v1](http://arxiv.org/abs/2501.18294v1)|null|
|**2025-01-30**|**The iToBoS dataset: skin region images extracted from 3D total body photographs for lesion detection**|Anup Saha et.al.|[2501.18270v1](http://arxiv.org/abs/2501.18270v1)|[link](https://github.com/iToBoS/Lesion-Detection-Challange)|
|**2025-01-30**|**Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers**|Malte Tölle et.al.|[2501.18237v1](http://arxiv.org/abs/2501.18237v1)|null|
|**2025-01-30**|**Investigating an Intelligent System to Monitor \& Explain Abnormal Activity Patterns of Older Adults**|Min Hun Lee et.al.|[2501.18108v1](http://arxiv.org/abs/2501.18108v1)|null|
|**2025-01-30**|**Normative Evaluation of Large Language Models with Everyday Moral Dilemmas**|Pratik S. Sachdeva et.al.|[2501.18081v1](http://arxiv.org/abs/2501.18081v1)|null|
|**2025-01-30**|**Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence**|Pir Bakhsh Khokhar et.al.|[2501.18071v1](http://arxiv.org/abs/2501.18071v1)|null|
|**2025-01-29**|**Current Pathology Foundation Models are unrobust to Medical Center Differences**|Edwin D. de Jong et.al.|[2501.18055v2](http://arxiv.org/abs/2501.18055v2)|null|
|**2025-01-29**|**Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**|Zijie Liu et.al.|[2501.17860v1](http://arxiv.org/abs/2501.17860v1)|null|
|**2025-01-29**|**GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**|Ziang Liu et.al.|[2501.17855v1](http://arxiv.org/abs/2501.17855v1)|null|
|**2025-01-29**|**Towards Recommender Systems LLMs Playground (RecSysLLMsP): Exploring Polarization and Engagement in Simulated Social Networks**|Ljubisa Bojic et.al.|[2502.00055v1](http://arxiv.org/abs/2502.00055v1)|null|
|**2025-01-29**|**Tonguescape: Exploring Language Models Understanding of Vowel Articulation**|Haruki Sakajo et.al.|[2501.17643v1](http://arxiv.org/abs/2501.17643v1)|[link](https://github.com/sj-h4/tonguescape-builder)|
|**2025-01-29**|**Layered Chain-of-Thought Prompting for Multi-Agent LLM Systems: A Comprehensive Approach to Explainable Large Language Models**|Manish Sanwal et.al.|[2501.18645v2](http://arxiv.org/abs/2501.18645v2)|null|
|**2025-01-29**|**An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**|Wenqi Li et.al.|[2501.17555v1](http://arxiv.org/abs/2501.17555v1)|null|
|**2025-01-29**|**LLM Assistance for Pediatric Depression**|Mariia Ignashina et.al.|[2501.17510v1](http://arxiv.org/abs/2501.17510v1)|null|
|**2025-01-28**|**Bridging Contrastive Learning and Domain Adaptation: Theoretical Perspective and Practical Application**|Gonzalo Iñaki Quintana et.al.|[2502.00052v1](http://arxiv.org/abs/2502.00052v1)|null|
|**2025-01-28**|**Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**|Chongyu Qu et.al.|[2501.17343v1](http://arxiv.org/abs/2501.17343v1)|null|
|**2025-01-28**|**Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**|Mingyu Derek Ma et.al.|[2501.17338v1](http://arxiv.org/abs/2501.17338v1)|null|
|**2025-01-28**|**Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**|Mingyu Derek Ma et.al.|[2501.17326v1](http://arxiv.org/abs/2501.17326v1)|null|
|**2025-01-28**|**Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**|Peilong Wang et.al.|[2501.17286v1](http://arxiv.org/abs/2501.17286v1)|null|
|**2025-01-28**|**ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification**|Mohammadreza Saraei et.al.|[2501.17260v1](http://arxiv.org/abs/2501.17260v1)|[link](https://github.com/mrsaraei/vit-2spn)|
|**2025-01-28**|**A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**|Suresh Babu Nettur et.al.|[2501.17160v1](http://arxiv.org/abs/2501.17160v1)|null|
|**2025-01-28**|**Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**|Reza Ghorbani et.al.|[2501.17152v1](http://arxiv.org/abs/2501.17152v1)|null|
|**2025-01-28**|**Irony Detection, Reasoning and Understanding in Zero-shot Learning**|Peiling Yi et.al.|[2501.16884v1](http://arxiv.org/abs/2501.16884v1)|null|
|**2025-01-28**|**Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?**|Keqi Han et.al.|[2501.17207v1](http://arxiv.org/abs/2501.17207v1)|[link](https://github.com/learningkeqi/rethinkingbca)|
|**2025-01-28**|**Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care**|Fengpei Yuan et.al.|[2501.17206v1](http://arxiv.org/abs/2501.17206v1)|null|
|**2025-01-28**|**Efficient Knowledge Distillation of SAM for Medical Image Segmentation**|Kunal Dasharath Patil et.al.|[2501.16740v1](http://arxiv.org/abs/2501.16740v1)|null|
|**2025-01-28**|**VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records**|Philip Chung et.al.|[2501.16672v1](http://arxiv.org/abs/2501.16672v1)|[link](https://github.com/philipchung/verifact)|
|**2025-01-28**|**Vision-based autonomous structural damage detection using data-driven methods**|Seyyed Taghi Ataei et.al.|[2501.16662v2](http://arxiv.org/abs/2501.16662v2)|null|
|**2025-01-28**|**Molecular-driven Foundation Model for Oncologic Pathology**|Anurag Vaidya et.al.|[2501.16652v1](http://arxiv.org/abs/2501.16652v1)|null|
|**2025-01-27**|**Restless Multi-armed Bandits under Frequency and Window Constraints for Public Service Inspections**|Yi Mao et.al.|[2502.00045v1](http://arxiv.org/abs/2502.00045v1)|null|
|**2025-01-27**|**Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models**|Jing Zhang et.al.|[2501.16282v1](http://arxiv.org/abs/2501.16282v1)|null|
|**2025-01-27**|**Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models**|Huayu Li et.al.|[2501.16215v1](http://arxiv.org/abs/2501.16215v1)|[link](https://github.com/HuayuLiArizona/Conformalized-Multiple-Instance-Learning-For-MedTS)|

#### Abstracts
##### **"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**
2502.05115v1 by Shihan Fu, Bingsheng Yao, Smit Desai, Yuqi Hu, Yuling Sun, Samantha Stonbraker, Yanjun Gao, Elizabeth M. Goldberg, Dakuo Wang

Older adult patients constitute a rapidly growing subgroup of Intensive Care
Unit (ICU) patients. In these situations, their family caregivers are expected
to represent the unconscious patients to access and interpret patients' medical
information. However, caregivers currently have to rely on overloaded
clinicians for information updates and typically lack the health literacy to
understand complex medical information. Our project aims to explore the
information needs of caregivers of ICU older adult patients, from which we can
propose design opportunities to guide future AI systems. The project begins
with formative interviews with 11 caregivers to identify their challenges in
accessing and interpreting medical information; From these findings, we then
synthesize design requirements and propose an AI system prototype to cope with
caregivers' challenges. The system prototype has two key features: a timeline
visualization to show the AI extracted and summarized older adult patients' key
medical events; and an LLM-based chatbot to provide context-aware informational
support. We conclude our paper by reporting on the follow-up user evaluation of
the system and discussing future AI-based systems for ICU caregivers of older
adults.

摘要：老年患者構成加護病房 (ICU) 患者中快速成長的子群。在這些情況下，預期他們的家庭照護者能代表無意識的患者取得並解讀患者的醫療資訊。然而，照護者目前必須依賴工作繁重的臨床醫師提供資訊更新，而且通常缺乏了解複雜醫療資訊的健康素養。我們的專案旨在探索 ICU 老年患者照護者的資訊需求，我們可以根據這些需求提出設計機會，以引導未來的 AI 系統。這個專案從對 11 位照護者的形成性訪談開始，以找出他們在取得和解讀醫療資訊方面的挑戰；根據這些發現，我們接著綜合設計需求，並提出一個 AI 系統原型，以應對照護者的挑戰。這個系統原型具有兩個關鍵特點：一個時間軸視覺化，以顯示 AI 萃取並摘要出的老年患者關鍵醫療事件；以及一個基於 LLM 的聊天機器人，以提供情境感知的資訊支援。我們透過報告系統的後續使用者評估，以及討論未來針對老年人 ICU 照護者的 AI 系統，來總結我們的論文。

##### **Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**
2502.05087v1 by Thierry Bossy, Julien Vignoud, Tahseen Rabbani, Juan R. Troncoso Pastoriza, Martin Jaggi

Federated learning (FL) is a popular paradigm for collaborative training
which avoids direct data exposure between clients. However, data privacy issues
still remain: FL-trained large language models are capable of memorizing and
completing phrases and sentences contained in training data when given with
their prefixes. Thus, it is possible for adversarial and honest-but-curious
clients to recover training data of other participants simply through targeted
prompting. In this work, we demonstrate that a popular and simple fine-tuning
strategy, low-rank adaptation (LoRA), reduces memorization during FL up to a
factor of 10. We study this effect by performing a medical question-answering
fine-tuning task and injecting multiple replicas of out-of-distribution
sensitive sequences drawn from an external clinical dataset. We observe a
reduction in memorization for a wide variety of Llama 2 and 3 models, and find
that LoRA can reduce memorization in centralized learning as well. Furthermore,
we show that LoRA can be combined with other privacy-preserving techniques such
as gradient clipping and Gaussian noising, secure aggregation, and Goldfish
loss to further improve record-level privacy while maintaining performance.

摘要：聯邦學習 (FL) 是一種流行的協作訓練範例，可避免客戶端之間直接公開資料。然而，資料隱私問題仍然存在：經過 FL 訓練的大型語言模型能夠記憶並完成訓練資料中包含的片語和句子，只要給予其前綴即可。因此，對抗和誠實但好奇的客戶端有可能僅透過目標提示來恢復其他參與者的訓練資料。在這項工作中，我們證明了一種流行且簡單的微調策略，低秩適應 (LoRA)，可將 FL 期間的記憶減少多達 10 倍。我們透過執行醫學問答微調任務並注入從外部臨床資料集抽取的非分佈敏感序列的多次複製品來研究此效應。我們觀察到各種 Llama 2 和 3 模型的記憶力降低，並發現 LoRA 也能減少集中式學習中的記憶力。此外，我們展示 LoRA 可以與其他隱私保護技術結合使用，例如梯度裁剪和高斯雜訊、安全聚合和 Goldfish 損失，以進一步改善記錄級隱私，同時維持效能。

##### **MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**
2502.04794v1 by Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo

Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is
introduced as a multimodal framework inspired by real-world diagnostic
processes. It uses pretrained models such as DINOv2, Vision Transformer, and
ResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into
low-dimensional, semantically meaningful features. A learnable
self-attention-based fusion network then integrates these imaging features with
clinical data for classification. Using 416 FUO patient cases from Sichuan
University West China Hospital from 2017 to 2023, the multimodal fusion
classification network MFCN achieved macro-AUROC scores ranging from 0.8654 to
0.9291 across seven tasks, outperforming conventional machine learning and
single-modality deep learning methods. Ablation studies and five-fold
cross-validation further validated its effectiveness. By combining the
strengths of pretrained large models and deep learning, MedMimic offers a
promising solution for disease classification.

摘要：不明原因發燒 (FUO) 仍然是診斷上的挑戰。MedMimic 是一個多模式架構，靈感來自於真實世界的診斷過程。它使用預先訓練的模型，例如 DINOv2、視覺轉換器和 ResNet-18，將高維 18F-FDG PET/CT 影像轉換為低維、語義有意義的特徵。一個可學習的自注意力融合網路接著將這些影像特徵與臨床資料整合，用於分類。使用 2017 年至 2023 年四川大學華西醫院的 416 個 FUO 病患病例，多模式融合分類網路 MFCN 在七項任務中達到了 0.8654 到 0.9291 的巨觀 AUROC 分數，優於傳統機器學習和單一模式深度學習方法。消融研究和五倍交叉驗證進一步驗證了其有效性。MedMimic 結合了預先訓練的大模型和深度學習的優點，為疾病分類提供了一個有前景的解決方案。

##### **MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification**
2502.04515v1 by Wei Fan, Jingru Fei, Dingyu Guo, Kun Yi, Xiaozhuang Song, Haolong Xiang, Hangting Ye, Min Li

Medical time series has been playing a vital role in real-world healthcare
systems as valuable information in monitoring health conditions of patients.
Accurate classification for medical time series, e.g., Electrocardiography
(ECG) signals, can help for early detection and diagnosis. Traditional methods
towards medical time series classification rely on handcrafted feature
extraction and statistical methods; with the recent advancement of artificial
intelligence, the machine learning and deep learning methods have become more
popular. However, existing methods often fail to fully model the complex
spatial dynamics under different scales, which ignore the dynamic
multi-resolution spatial and temporal joint inter-dependencies. Moreover, they
are less likely to consider the special baseline wander problem as well as the
multi-view characteristics of medical time series, which largely hinders their
prediction performance. To address these limitations, we propose a
Multi-resolution Spatiotemporal Graph Learning framework, MedGNN, for medical
time series classification. Specifically, we first propose to construct
multi-resolution adaptive graph structures to learn dynamic multi-scale
embeddings. Then, to address the baseline wander problem, we propose Difference
Attention Networks to operate self-attention mechanisms on the finite
difference for temporal modeling. Moreover, to learn the multi-view
characteristics, we utilize the Frequency Convolution Networks to capture
complementary information of medical time series from the frequency domain. In
addition, we introduce the Multi-resolution Graph Transformer architecture to
model the dynamic dependencies and fuse the information from different
resolutions. Finally, we have conducted extensive experiments on multiple
medical real-world datasets that demonstrate the superior performance of our
method. Our Code is available.

摘要：<paragraph>醫療時間序列在真實世界的醫療保健系統中扮演著至關重要的角色，作為監控患者健康狀況的寶貴資訊。
準確分類醫療時間序列，例如心電圖 (ECG) 訊號，有助於早期偵測和診斷。傳統的醫療時間序列分類方法仰賴手工特徵萃取和統計方法；隨著人工智慧的最新進展，機器學習和深度學習方法變得更為普及。然而，現有方法通常無法完全建模不同尺度下的複雜空間動態，忽略了動態多解析度空間和時間關節相互依賴性。此外，它們不太可能考慮特殊的基線漂移問題以及醫療時間序列的多視角特性，這在很大程度上阻礙了它們的預測效能。為了解決這些限制，我們提出了一個多解析度時空圖形學習架構 MedGNN，用於醫療時間序列分類。具體來說，我們首先提出構建多解析度自適應圖形結構以學習動態多尺度嵌入。然後，為了解決基線漂移問題，我們提出差分注意力網路，對時間建模的有限差分運算自注意力機制。此外，為了學習多視角特性，我們利用頻率卷積網路從頻域擷取醫療時間序列的互補資訊。此外，我們引入了多解析度圖形Transformer架構來建模動態依賴性，並融合來自不同解析度的資訊。最後，我們對多個醫療真實世界資料集進行了廣泛的實驗，證明了我們方法的優異效能。我們的程式碼已公開。</paragraph>

##### **Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions**
2502.04423v1 by Khushboo Verma, Alan Michels, Ergi Gumusaneli, Shilpa Chitnis, Smita Sinha Kumar, Christopher Thompson, Lena Esmail, Guruprasath Srinivasan, Chandini Panchada, Sushovan Guha, Satwant Kumar

Referral workflow inefficiencies, including misaligned referrals and delays,
contribute to suboptimal patient outcomes and higher healthcare costs. In this
study, we investigated the possibility of predicting procedural needs based on
primary care diagnostic entries, thereby improving referral accuracy,
streamlining workflows, and providing better care to patients. A de-identified
dataset of 2,086 orthopedic referrals from the University of Texas Health at
Tyler was analyzed using machine learning models built on Base General
Embeddings (BGE) for semantic extraction. To ensure real-world applicability,
noise tolerance experiments were conducted, and oversampling techniques were
employed to mitigate class imbalance. The selected optimum and parsimonious
embedding model demonstrated high predictive accuracy (ROC-AUC: 0.874, Matthews
Correlation Coefficient (MCC): 0.540), effectively distinguishing patients
requiring surgical intervention. Dimensionality reduction techniques confirmed
the model's ability to capture meaningful clinical relationships. A threshold
sensitivity analysis identified an optimal decision threshold (0.30) to balance
precision and recall, maximizing referral efficiency. In the predictive
modeling analysis, the procedure rate increased from 11.27% to an optimal
60.1%, representing a 433% improvement with significant implications for
operational efficiency and healthcare revenue.
  The results of our study demonstrate that referral optimization can enhance
primary and surgical care integration. Through this approach, precise and
timely predictions of procedural requirements can be made, thereby minimizing
delays, improving surgical planning, and reducing administrative burdens. In
addition, the findings highlight the potential of clinical decision support as
a scalable solution for improving patient outcomes and the efficiency of the
healthcare system.

摘要：轉診流程效率低落，包括轉診不當和延誤，
導致次優的患者結果和更高的醫療保健成本。在這
項研究中，我們探討了根據初級保健診斷條目預測程序需求的可能性，從而提高轉診準確性，
簡化工作流程，並為患者提供更好的照護。一個去識別化
德克薩斯大學健康中心的 2,086 個骨科轉診的資料集
泰勒使用建立在基本通用
語義提取的嵌入 (BGE) 上的機器學習模型進行分析。為了確保現實世界的適用性，
進行了噪聲容忍度實驗，並採用了過採樣技術來減輕類別不平衡。所選的最佳和簡約
嵌入模型展示了高預測準確度 (ROC-AUC：0.874，馬修斯
相關系數 (MCC)：0.540)，有效區分需要手術干預的患者。降維
技術證實了模型捕捉有意義的臨床關係的能力。閾值
敏感性分析確定了一個最佳決策閾值 (0.30) 來平衡
精確度和召回率，最大化轉診效率。在預測中
建模分析中，程序率從 11.27% 增加到最佳的
60.1%，代表 433% 的改進，對運營效率和醫療保健收入具有重大影響。
我們研究的結果表明，轉診優化可以增強
初級和外科護理整合。通過這種方法，可以對程序需求進行準確及時的預測，從而最大程度地減少
延誤，改善手術計劃，並減輕行政負擔。此外，研究結果強調了臨床決策支持作為
一個可擴展的解決方案的潛力，用於改善患者結果和醫療保健系統的效率。

##### **Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**
2502.04083v1 by Tewele W. Tareke, Neree Payan, Alexandre Cochet, Laurent Arnould, Benoit Presles, Jean-Marc Vrigneaud, Fabrice Meriaudeau, Alain Lalande

Neoadjuvant chemotherapy (NAC) has become a standard clinical practice for
tumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography
(PET). Our work aims to leverage PET imaging for the segmentation of breast
lesions. The focus is on developing an automated system that accurately
segments primary tumor regions and extracts key biomarkers from these areas to
provide insights into the evolution of breast cancer following the first course
of NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PET
scans (PET_Fu) were acquired before and after the first course of NAC,
respectively. Firstly, a deep learning-based breast tumor segmentation method
was developed. The optimal baseline model (model trained on baseline exams) was
fine-tuned on 15 follow-up exams and adapted using active learning to segment
tumor areas in PET_Fu. The pipeline computes biomarkers such as maximum
standardized uptake value (SUVmax), metabolic tumor volume (MTV), and total
lesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.
Quality control measures were employed to exclude aberrant outliers. The nnUNet
deep learning model outperformed in tumor segmentation on PET_Bl, achieved a
Dice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52
mm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mm
on PET_Fu exams. Biomarkers analysis revealed very strong correlations whatever
the biomarker between manually segmented and automatically predicted regions.
The significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3
and 19.23 cm3, respectively. The presented approach demonstrates an automated
system for breast tumor segmentation from 18F-FDG PET. Thanks to the extracted
biomarkers, our method enables the automatic assessment of cancer progression.

摘要：新辅助化疗 (NAC) 已成为乳腺癌中采用 18F-FDG 正电子发射断层扫描 (PET) 进行肿瘤缩小的标准临床实践。我们的工作旨在利用 PET 影像分割乳腺病变。重点在于开发一个自动系统，该系统可以准确分割原发性肿瘤区域并从这些区域提取关键生物标记，以深入了解乳腺癌在第一疗程 NAC 后的演变。分别在第一疗程 NAC 之前和之后采集了 243 例基线 18F-FDG PET 扫描 (PET_Bl) 和 180 例随访 18F-FDG PET 扫描 (PET_Fu)。首先，开发了一种基于深度学习的乳腺肿瘤分割方法。对 15 例随访检查对最优基线模型（在基线检查中训练的模型）进行了微调，并使用主动学习对 PET_Fu 中的肿瘤区域进行了分割。该管道计算诸如最大标准摄取值 (SUVmax)、代谢肿瘤体积 (MTV) 和总病灶糖酵解 (TLG) 等生物标记，以评估 PET_Fu 和 PET_Bl 之间的肿瘤演变。采用质量控制措施来排除异常值。nnUNet 深度学习模型在 PET_Bl 上的肿瘤分割方面表现出色，达到 0.89 的 Dice 相似性系数 (DSC) 和 3.52 毫米的 Hausdorff 距离 (HD)。微调后，该模型在 PET_Fu 检查中显示出 0.78 的 DSC 和 4.95 毫米的 HD。无论手动分割区域和自动预测区域之间的生物标记如何，生物标记分析都显示出非常强的相关性。SUVmax、MTV 和 TLG 的平均显着下降分别为 5.22、11.79 cm3 和 19.23 cm3。所提出的方法展示了一个用于从 18F-FDG PET 分割乳腺肿瘤的自动化系统。由于提取了生物标记，我们的方法能够自动评估癌症进展。

##### **Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**
2502.04034v1 by Ran Song, Yinpu Bai, Hui Liu

The accurate prediction of drug responses remains a formidable challenge,
particularly at the single-cell level and in clinical treatment contexts. Some
studies employ transfer learning techniques to predict drug responses in
individual cells and patients, but they require access to target-domain data
during training, which is often unavailable or only obtainable in future. In
this study, we propose a novel domain generalization framework, termed
panCancerDR, to address this challenge. We conceptualize each cancer type as a
distinct source domain, with its cell lines serving as domain-specific samples.
Our primary objective is to extract domain-invariant features from the
expression profiles of cell lines across diverse cancer types, thereby
generalize the predictive capacity to out-of-distribution samples. To enhance
robustness, we introduce a latent independence projection (LIP) module that
encourages the encoder to extract informative yet non-redundant features. Also,
we propose an asymmetric adaptive clustering constraint, which clusters
drug-sensitive samples into a compact group while drives resistant samples
dispersed across separate clusters in the latent space. Our empirical
experiments demonstrate that panCancerDR effectively learns task-relevant
features from diverse source domains, and achieves accurate predictions of drug
response for unseen cancer type during training. Furthermore, when evaluated on
single-cell and patient-level prediction tasks, our model-trained solely on in
vitro cell line data without access to target-domain information-consistently
outperforms and matched current state-of-the-art methods. These findings
highlights the potential of our method for real-world clinical applications.

摘要：<paragraph>準確預測藥物反應仍然是一項艱鉅的挑戰，特別是在單細胞層級和臨床治療背景中。一些研究採用遷移學習技術來預測個別細胞和患者的藥物反應，但它們需要在訓練期間存取目標網域資料，而這些資料通常無法取得，或只能在未來取得。在這項研究中，我們提出一個新穎的網域概化架構，稱為 panCancerDR，以應對這項挑戰。我們將每種類型的癌症概念化為一個不同的來源網域，其細胞株作為特定網域的樣本。我們的首要目標是從不同癌症類型的細胞株表現特徵中萃取網域不變特徵，從而將預測能力概化到分布外的樣本。為了增強穩健性，我們引入一個潛在獨立投影 (LIP) 模組，鼓勵編碼器萃取有資訊但非冗餘的特徵。此外，我們提出一個非對稱自適應聚類約束，將對藥物敏感的樣本聚類到一個緊湊的群組中，同時驅動抗藥性樣本分散在潛在空間中的不同群組中。我們的實證實驗證明，panCancerDR 有效地從不同的來源網域學習與任務相關的特徵，並在訓練期間對未見的癌症類型實現準確的藥物反應預測。此外，當在單細胞和患者層級預測任務中進行評估時，我們的模型僅在體外細胞株資料上訓練，而沒有存取目標網域資訊，始終優於並符合當前的最新方法。這些發現突顯了我們的方法在實際臨床應用中的潛力。</paragraph>

##### **MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**
2502.04413v1 by Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao

Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG

摘要：檢索增強生成 (RAG) 是一種適用於檢索隱私敏感的電子健康記錄 (EHR) 的技術。它可以作為醫療保健副駕駛的一個關鍵模組，協助減少醫療保健從業人員和患者的誤診。然而，在醫療領域中使用的現有基於啟發法的 RAG 模型的診斷準確性和特異性不足，特別是對於具有類似表現的疾病。本文提出 MedRAG，一種由知識圖譜 (KG) 引發的推理增強的 RAG 模型，用於醫療領域，它根據表現檢索診斷和治療建議。MedRAG 系統性地構建了一個全面的四層階層式診斷 KG，涵蓋各種疾病的關鍵診斷差異。這些差異與從 EHR 資料庫中檢索到的類似 EHR 動態整合，並在大型語言模型中進行推理。這個過程可以實現更準確和具體的決策支援，同時主動提供後續問題，以增強個人化醫療決策制定。MedRAG 在公共資料集 DDXPlus 和從陳篤生醫院收集的私人慢性疼痛診斷資料集 (CPDD) 上進行評估，並將其效能與各種現有 RAG 方法進行比較。實驗結果顯示，利用 KG 的資訊整合和關係能力，我們的 MedRAG 提供了更具體的診斷見解，並在降低誤診率方面優於最先進的模型。我們的程式碼將在 https://github.com/SNOWTEAM2023/MedRAG 提供

##### **Transforming Multimodal Models into Action Models for Radiotherapy**
2502.04408v1 by Matteo Ferrante, Alessandra Carosi, Rolando Maria D Angelillo, Nicola Toschi

Radiotherapy is a crucial cancer treatment that demands precise planning to
balance tumor eradication and preservation of healthy tissue. Traditional
treatment planning (TP) is iterative, time-consuming, and reliant on human
expertise, which can potentially introduce variability and inefficiency. We
propose a novel framework to transform a large multimodal foundation model
(MLM) into an action model for TP using a few-shot reinforcement learning (RL)
approach. Our method leverages the MLM's extensive pre-existing knowledge of
physics, radiation, and anatomy, enhancing it through a few-shot learning
process. This allows the model to iteratively improve treatment plans using a
Monte Carlo simulator. Our results demonstrate that this method outperforms
conventional RL-based approaches in both quality and efficiency, achieving
higher reward scores and more optimal dose distributions in simulations on
prostate cancer data. This proof-of-concept suggests a promising direction for
integrating advanced AI models into clinical workflows, potentially enhancing
the speed, quality, and standardization of radiotherapy treatment planning.

摘要：放射治療是一種重要的癌症治療方法，需要精確的規劃來平衡腫瘤根除和健康組織的保留。傳統的治療規劃（TP）是反覆的、耗時的，並且依賴於人為專業知識，這可能會引入變異性和低效率。我們提出了一個新穎的框架，使用少次強化學習 (RL) 方法將大型多模態基礎模型 (MLM) 轉換為 TP 的動作模型。我們的模型利用了 MLM 對物理、輻射和解剖學的廣泛預先存在的知識，並通過少次學習過程對其進行增強。這允許模型使用蒙特卡羅模擬器反覆改進治療計劃。我們的結果表明，這種方法在質量和效率方面都優於基於傳統 RL 的方法，在對前列腺癌數據進行模擬時，獲得了更高的獎勵分數和更優化的劑量分佈。這個概念驗證表明了一個有希望的方向，即將先進的人工智慧模型整合到臨床工作流程中，從而有可能提高放射治療計劃的速度、質量和標準化。

##### **Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning**
2502.04399v1 by Bokeng Zheng, Bo Rao, Tianxiang Zhu, Chee Wei Tan, Jingpu Duan, Zhi Zhou, Xu Chen, Xiaoxi Zhang

Advances in artificial intelligence (AI) including foundation models (FMs),
are increasingly transforming human society, with smart city driving the
evolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged as
a key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.
In particular, ride-hailing vehicles can effectively facilitate flexible data
collection and contribute towards urban intelligence, despite resource
limitations. Therefore, this work explores a promising scenario, where
edge-assisted vehicles perform joint tasks of order serving and the emerging
foundation model fine-tuning using various urban data. However, integrating the
VCS AI task with the conventional order serving task is challenging, due to
their inconsistent spatio-temporal characteristics: (i) The distributions of
ride orders and data point-of-interests (PoIs) may not coincide in geography,
both following a priori unknown patterns; (ii) they have distinct forms of
temporal effects, i.e., prolonged waiting makes orders become instantly invalid
while data with increased staleness gradually reduces its utility for model
fine-tuning.To overcome these obstacles, we propose an online framework based
on multi-agent reinforcement learning (MARL) with careful augmentation. A new
quality-of-service (QoS) metric is designed to characterize and balance the
utility of the two joint tasks, under the effects of varying data volumes and
staleness. We also integrate graph neural networks (GNNs) with MARL to enhance
state representations, capturing graph-structured, time-varying dependencies
among vehicles and across locations. Extensive experiments on our testbed
simulator, utilizing various real-world foundation model fine-tuning tasks and
the New York City Taxi ride order dataset, demonstrate the advantage of our
proposed method.

摘要：人工智能（AI）的進展，包括基礎模型（FM），正日益轉變人類社會，智慧城市推動著城市生活的演進。同時，車輛群感測（VCS）已成為關鍵推動因素，利用車輛的機動性和配備感測器的能力。特別是，儘管有資源限制，叫車服務車輛能有效促進靈活的資料收集，並有助於城市智慧。因此，這項工作探索了一個有前途的場景，其中邊緣輔助車輛執行訂單服務和新興基礎模型微調的聯合任務，使用各種城市資料。然而，由於 VCS AI 任務與傳統訂單服務任務的不一致時空特徵，整合它們具有挑戰性：(i) 叫車訂單和資料感興趣點 (PoI) 的分佈在地域上可能不重合，兩者都遵循先驗未知的模式；(ii) 它們具有不同的時間效應形式，即長時間等待會使訂單立即失效，而過時的資料會逐漸降低其對模型微調的效用。為了解決這些障礙，我們提出了一個基於多智能體強化學習 (MARL) 的線上架構，並進行了仔細的擴充。設計了一個新的服務品質 (QoS) 指標，用於表徵和平衡這兩個聯合任務的效用，在不同資料量和過時性的影響下。我們還將圖神經網路（GNN）與 MARL 整合，以增強狀態表示，捕捉車輛之間和不同地點之間的圖結構、時變依賴性。在我們的測試平台模擬器上進行的廣泛實驗，利用各種真實世界的基礎模型微調任務和紐約市計程車叫車訂單資料集，證明了我們提出的方法的優點。

##### **Multimodal Medical Code Tokenizer**
2502.04397v1 by Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik

Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.

摘要：<paragraph>在患者電子病歷 (EHR) 上訓練的基礎模型需要將醫療資料代換成離散詞彙項目序列。現有代換器將 EHR 中的醫療代碼視為孤立的文字代碼。然而，每個醫療代碼都由其文字描述、在本体層級中的位置，以及與其他代碼的關聯性（例如疾病共現和藥物治療關聯性）定義。醫療詞彙包含超過 600,000 個代碼，其中包含臨床推理的重要資訊。我們介紹 MedTok，這是一個多模態醫療代碼代換器，它使用代碼的文字描述和關聯性脈絡。MedTok 使用語言模型編碼器處理文字，並使用圖形編碼器編碼關聯結構。然後，它將兩種模態量化為統一的代碼空間，保留特定於模態和跨模態的資訊。我們將 MedTok 整合到五個 EHR 模型中，並在包括結果預測、診斷分類、藥物建議和風險分層在內的住院和門診資料集上對其進行運作和臨床任務評估。將標準 EHR 代換器換成 MedTok 可改善所有 EHR 模型的 AUPRC，在 MIMIC-III 上提高 4.10%，在 MIMIC-IV 上提高 4.78%，在 EHRShot 上提高 11.30%，其中藥物建議的進步最大。除了 EHR 建模之外，我們展示了使用 MedTok 代換器搭配醫療 QA 系統。我們的結果證明了 MedTok 作為醫療代碼統一代換器的潛力，改善了醫療基礎模型的代換。</paragraph>

##### **A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**
2502.03772v1 by Chaoyin She, Ruifang Lu, Danni He, Jiayi Lv, Yadan Lin, Meiqing Cheng, Hui Huang, Lida Chen, Wei Wang, Qinghua Huang

Hepatocellular carcinoma (HCC) ranks as the third leading cause of
cancer-related mortality worldwide, with early detection being crucial for
improving patient survival rates. However, early screening for HCC using
ultrasound suffers from insufficient sensitivity and is highly dependent on the
expertise of radiologists for interpretation. Leveraging the latest
advancements in artificial intelligence (AI) in medical imaging, this study
proposes an innovative Hierarchical Sparse Query Transformer (HSQformer) model
that combines the strengths of Convolutional Neural Networks (CNNs) and Vision
Transformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasound
screening. The HSQformer leverages sparse latent space representations to
capture hierarchical details at various granularities without the need for
complex adjustments, and adopts a modular, plug-and-play design philosophy,
ensuring the model's versatility and ease of use. The HSQformer's performance
was rigorously tested across three distinct clinical scenarios: single-center,
multi-center, and high-risk patient testing. In each of these settings, it
consistently outperformed existing state-of-the-art models, such as ConvNext
and SwinTransformer. Notably, the HSQformer even matched the diagnostic
capabilities of senior radiologists and comprehensively surpassed those of
junior radiologists. The experimental results from this study strongly
demonstrate the effectiveness and clinical potential of AI-assisted tools in
HCC screening. The full code is available at
https://github.com/Asunatan/HSQformer.

摘要：肝細胞癌（HCC）是全球第三大癌症相關死亡原因，早期檢測對於提高患者存活率至關重要。然而，使用超音波進行 HCC 早期篩檢的靈敏度不足，且高度依賴放射科醫師的專業知識進行判讀。本研究利用醫學影像中人工智慧（AI）的最新進展，提出了一種創新的分層稀疏查詢Transformer（HSQformer）模型，結合了卷積神經網路（CNN）和視覺Transformer（ViT）的優點，以提高超音波篩檢中 HCC 診斷的準確性。HSQformer 利用稀疏潛在空間表示，在不需要複雜調整的情況下擷取各種粒度層級的細節，並採用模組化、即插即用的設計理念，確保模型的多功能性和易用性。HSQformer 的效能經過三個不同的臨床場景的嚴格測試：單中心、多中心和高風險患者測試。在這些設定中，它始終優於現有的最先進模型，例如 ConvNext 和 SwinTransformer。值得注意的是，HSQformer 甚至匹配了資深放射科醫師的診斷能力，並全面超越了初級放射科醫師的診斷能力。本研究的實驗結果有力地證明了 AI 輔助工具在 HCC 篩檢中的有效性和臨床潛力。完整程式碼可在 https://github.com/Asunatan/HSQformer 取得。

##### **Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings**
2502.04386v1 by Guangyao Zheng, Michael A. Jacobs, Vladimir Braverman, Vishwa S. Parekh

Self-supervised learning has revolutionized medical imaging by enabling
efficient and generalizable feature extraction from large-scale unlabeled
datasets. Recently, self-supervised foundation models have been extended to
three-dimensional (3D) computed tomography (CT) data, generating compact,
information-rich embeddings with 1408 features that achieve state-of-the-art
performance on downstream tasks such as intracranial hemorrhage detection and
lung cancer risk forecasting. However, these embeddings have been shown to
encode demographic information, such as age, sex, and race, which poses a
significant risk to the fairness of clinical applications.
  In this work, we propose a Variation Autoencoder (VAE) based adversarial
debiasing framework to transform these embeddings into a new latent space where
demographic information is no longer encoded, while maintaining the performance
of critical downstream tasks. We validated our approach on the NLST lung cancer
screening dataset, demonstrating that the debiased embeddings effectively
eliminate multiple encoded demographic information and improve fairness without
compromising predictive accuracy for lung cancer risk at 1-year and 2-year
intervals. Additionally, our approach ensures the embeddings are robust against
adversarial bias attacks. These results highlight the potential of adversarial
debiasing techniques to ensure fairness and equity in clinical applications of
self-supervised 3D CT embeddings, paving the way for their broader adoption in
unbiased medical decision-making.

摘要：自我監督學習透過從大規模未標記資料集中提取有效且可概化的特徵，進而革新了醫學影像。最近，自我監督基礎模型已擴展到三維 (3D) 電腦斷層掃描 (CT) 資料，產生緊湊、資訊豐富的嵌入，包含 1408 個特徵，在顱內出血偵測和肺癌風險預測等下游任務中達到最先進的效能。然而，這些嵌入已被證明會編碼人口統計資訊，例如年齡、性別和種族，這對臨床應用的公平性構成重大風險。
在這項工作中，我們提出一個基於變異自編碼器 (VAE) 的對抗性去偏框架，將這些嵌入轉換到一個新的潛在空間，其中不再編碼人口統計資訊，同時維持關鍵下游任務的效能。我們在 NLST 肺癌篩檢資料集上驗證了我們的做法，證明去偏嵌入有效消除了多重編碼的人口統計資訊，並在不損害 1 年和 2 年間隔的肺癌風險預測準確性的情況下提高了公平性。此外，我們的做法確保了嵌入對抗性偏誤攻擊具有魯棒性。這些結果突顯了對抗性去偏技術的潛力，可確保自我監督 3D CT 嵌入在臨床應用中的公平性和公正性，為其在無偏見醫療決策中的廣泛採用鋪路。

##### **Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function**
2502.03591v1 by Mehrdad Asadi, Komi Sodoké, Ian J. Gerard, Marta Kersten-Oertel

In this work, we present a novel approach to multi-label chest X-ray (CXR)
image classification that enhances clinical interpretability while maintaining
a streamlined, single-model, single-run training pipeline. Leveraging the
CheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical
label groupings to capture clinically meaningful relationships between
diagnoses. To achieve this, we designed a custom hierarchical binary
cross-entropy (HBCE) loss function that enforces label dependencies using
either fixed or data-driven penalty types. Our model achieved a mean area under
the receiver operating characteristic curve (AUROC) of 0.903 on the test set.
Additionally, we provide visual explanations and uncertainty estimations to
further enhance model interpretability. All code, model configurations, and
experiment details are made available.

摘要：在本文中，我們提出胸部 X 光（CXR）影像多標籤分類的新方法，在維持簡化的單一模型、單次執行訓練管線的同時，提升臨床可解釋性。利用 CheXpert 資料集和 VisualCheXbert 衍生的標籤，我們納入階層標籤群組，以擷取診斷之間具有臨床意義的關聯性。為此，我們設計了自訂的階層二元交叉熵 (HBCE) 損失函數，使用固定或資料驅動的懲罰類型來強制執行標籤依賴性。我們的模型在測試集上達到受試者工作特性曲線 (AUROC) 下的平均面積為 0.903。此外，我們提供視覺化說明和不確定性估計，以進一步提升模型可解釋性。所有程式碼、模型組態和實驗詳細資料皆已公開。

##### **Code Simulation as a Proxy for High-order Tasks in Large Language Models**
2502.03568v1 by Emanuele La Malfa, Christoph Weinhuber, Orazio Torre, Fangru Lin, X. Angelo Huang, Samuele Marro, Anthony Cohn, Nigel Shadbolt, Michael Wooldridge

Many reasoning, planning, and problem-solving tasks share an intrinsic
algorithmic nature: correctly simulating each step is a sufficient condition to
solve them correctly. We collect pairs of naturalistic and synthetic reasoning
tasks to assess the capabilities of Large Language Models (LLM). While
naturalistic tasks often require careful human handcrafting, we show that
synthetic data is, in many cases, a good proxy that is much easier to collect
at scale. We leverage common constructs in programming as the counterpart of
the building blocks of naturalistic reasoning tasks, such as straight-line
programs, code that contains critical paths, and approximate and redundant
instructions. We further assess the capabilities of LLMs on sorting problems
and repeated operations via sorting algorithms and nested loops. Our synthetic
datasets further reveal that while the most powerful LLMs exhibit relatively
strong execution capabilities, the process is fragile: it is negatively
affected by memorisation and seems to rely heavily on pattern recognition. Our
contribution builds upon synthetically testing the reasoning capabilities of
LLMs as a scalable complement to handcrafted human-annotated problems.

摘要：許多推理、規劃和問題解決任務共享一個內在的演算法性質：正確模擬每一步就足以正確解決它們。我們收集自然主義和合成推理任務對，以評估大型語言模型 (LLM) 的功能。雖然自然主義任務通常需要仔細的人工製作，但我們表明在許多情況下，合成資料是一個很好的代理，而且更容易大規模收集。我們利用程式設計中的常見建構，作為自然主義推理任務構建區塊的對應物，例如直線程式、包含關鍵路徑的程式碼，以及近似和冗餘指令。我們進一步評估 LLM 在排序問題和重複運算上的功能，透過排序演算法和巢狀迴圈。我們的合成資料集進一步揭示，雖然最強大的 LLM 表現出相對強大的執行能力，但這個過程很脆弱：它受到記憶的負面影響，而且似乎嚴重依賴模式辨識。我們的貢獻建立在以合成方式測試 LLM 的推理能力之上，作為手工編寫人類標註問題的可擴充補充。

##### **Limitations of Large Language Models in Clinical Problem-Solving Arising from Inflexible Reasoning**
2502.04381v1 by Jonathan Kim, Anna Podlasek, Kie Shidara, Feng Liu, Ahmed Alaa, Danilo Bernardo

Large Language Models (LLMs) have attained human-level accuracy on medical
question-answer (QA) benchmarks. However, their limitations in navigating
open-ended clinical scenarios have recently been shown, raising concerns about
the robustness and generalizability of LLM reasoning across diverse, real-world
medical tasks. To probe potential LLM failure modes in clinical
problem-solving, we present the medical abstraction and reasoning corpus
(M-ARC). M-ARC assesses clinical reasoning through scenarios designed to
exploit the Einstellung effect -- the fixation of thought arising from prior
experience, targeting LLM inductive biases toward inflexible pattern matching
from their training data rather than engaging in flexible reasoning. We find
that LLMs, including current state-of-the-art o1 and Gemini models, perform
poorly compared to physicians on M-ARC, often demonstrating lack of commonsense
medical reasoning and a propensity to hallucinate. In addition, uncertainty
estimation analyses indicate that LLMs exhibit overconfidence in their answers,
despite their limited accuracy. The failure modes revealed by M-ARC in LLM
medical reasoning underscore the need to exercise caution when deploying these
models in clinical settings.

摘要：大型語言模型 (LLM) 已在醫療問題解答 (QA) 基準上達到人類層級的準確度。然而，它們在應對開放式臨床場景中的局限性最近已被揭示，引發了人們對 LLM 推理在多樣化、真實世界醫療任務中的穩健性和概括性的擔憂。為了探討臨床問題解決中 LLM 的潛在故障模式，我們提出了醫療抽象和推理語料庫 (M-ARC)。M-ARC 通過旨在利用艾賓浩斯錯覺（由先前經驗產生的思維定勢）來評估臨床推理，針對 LLM 歸納偏誤，使其從訓練數據中進行僵化的模式匹配，而不是進行靈活的推理。我們發現，包括當前最先進的 o1 和 Gemini 模型在內的 LLM，在 M-ARC 上的表現遠不如醫生，它們經常表現出缺乏常識性的醫療推理和產生幻覺的傾向。此外，不確定性估計分析表明，儘管 LLM 準確性有限，但它們對自己的答案表現出過度自信。M-ARC 揭示的 LLM 醫療推理故障模式強調了在臨床環境中部署這些模型時需要謹慎。

##### **Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin**
2502.03396v1 by Sarah Al-Shareeda, Yasar Celik, Bilge Bilgili, Ahmed Al-Dubai, Berk Canberk

Creating a Digital Twin (DT) for Healthcare Intelligent Transportation
Systems (HITS) is a hot research trend focusing on enhancing HITS management,
particularly in emergencies where ambulance vehicles must arrive at the crash
scene on time and track their real-time location is crucial to the medical
authorities. Despite the claim of real-time representation, a temporal
misalignment persists between the physical and virtual domains, leading to
discrepancies in the ambulance's location representation. This study proposes
integrating AI predictive models, specifically Support Vector Regression (SVR)
and Deep Neural Networks (DNN), within a constructed mock DT data pipeline
framework to anticipate the medical vehicle's next location in the virtual
world. These models align virtual representations with their physical
counterparts, i.e., metaphorically offsetting the synchronization delay between
the two worlds. Trained meticulously on a historical geospatial dataset, SVR
and DNN exhibit exceptional prediction accuracy in MATLAB and Python
environments. Through various testing scenarios, we visually demonstrate the
efficacy of our methodology, showcasing SVR and DNN's key role in significantly
reducing the witnessed gap within the HITS's DT. This transformative approach
enhances real-time synchronization in emergency HITS by approximately 88% to
93%.

摘要：建立醫療智慧交通系統（HITS）的數位分身（DT）是熱門的研究趨勢，其重點在於提升 HITS 管理，特別是在救護車必須準時抵達車禍現場的緊急情況中，追蹤其即時位置對於醫療單位至關重要。儘管聲稱即時呈現，但實體和虛擬領域之間仍存在時間上的錯位，導致救護車位置呈現上的差異。本研究建議在建構的虛擬 DT 資料管道架構中整合人工智慧預測模型，特別是支援向量回歸（SVR）和深度神經網路（DNN），以預測醫療車輛在虛擬世界的下一個位置。這些模型將虛擬呈現與其實體對應物對齊，也就是說，在兩個世界之間比喻性地抵銷同步延遲。在歷史地理空間資料集上經過仔細訓練，SVR 和 DNN 在 MATLAB 和 Python 環境中展現出卓越的預測準確性。透過各種測試情境，我們視覺化展示了我們方法論的效能，展示了 SVR 和 DNN 在顯著縮小 HITS 的 DT 中見證到的差距方面的關鍵作用。這種變革性的方法將緊急 HITS 中的即時同步提升了大約 88% 到 93%。

##### **RadVLM: A Multitask Conversational Vision-Language Model for Radiology**
2502.03333v1 by Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruipérez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio, Thomas M. Sutter, Julia E. Vogt, Jonas Kluckert, Thomas Frauenfelder, Christian Blüthgen, Farhad Nooralahzadeh, Michael Krauthammer

The widespread use of chest X-rays (CXRs), coupled with a shortage of
radiologists, has driven growing interest in automated CXR analysis and
AI-assisted reporting. While existing vision-language models (VLMs) show
promise in specific tasks such as report generation or abnormality detection,
they often lack support for interactive diagnostic capabilities. In this work
we present RadVLM, a compact, multitask conversational foundation model
designed for CXR interpretation. To this end, we curate a large-scale
instruction dataset comprising over 1 million image-instruction pairs
containing both single-turn tasks -- such as report generation, abnormality
classification, and visual grounding -- and multi-turn, multi-task
conversational interactions. After fine-tuning RadVLM on this instruction
dataset, we evaluate it across different tasks along with re-implemented
baseline VLMs. Our results show that RadVLM achieves state-of-the-art
performance in conversational capabilities and visual grounding while remaining
competitive in other radiology tasks. Ablation studies further highlight the
benefit of joint training across multiple tasks, particularly for scenarios
with limited annotated data. Together, these findings highlight the potential
of RadVLM as a clinically relevant AI assistant, providing structured CXR
interpretation and conversational capabilities to support more effective and
accessible diagnostic workflows.

摘要：胸部 X 光 (CXR) 的广泛使用，加上放射科醫師短缺，促使人們對自動化 CXR 分析和 AI 輔助報告產生越來越濃厚的興趣。雖然現有的視覺語言模型 (VLM) 在特定任務中顯示出前景，例如報告生成或異常偵測，但它們通常缺乏對互動式診斷功能的支持。在這項工作中，我們提出 RadVLM，這是一個緊湊的多任務對話式基礎模型，專為 CXR 解釋而設計。為此，我們策劃了一個大型指令資料集，包含超過 100 萬個影像指令對，其中包含單輪任務（例如報告生成、異常分類和視覺基礎），以及多輪、多任務對話互動。在對這個指令資料集進行微調後，我們對 RadVLM 進行評估，並與重新實作的基準 VLM 一起執行不同的任務。我們的結果顯示，RadVLM 在對話能力和視覺基礎方面取得了最先進的效能，同時在其他放射學任務中仍具有競爭力。消融研究進一步突顯了跨多個任務進行聯合訓練的好處，特別是對於帶有標註資料有限的場景。這些發現共同突顯了 RadVLM 作為臨床相關 AI 助理的潛力，提供結構化的 CXR 解釋和對話能力，以支援更有效且可存取的診斷工作流程。

##### **MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters**
2502.03298v1 by Amin Dada, Osman Alperen Koras, Marie Bauer, Amanda Butler, Kaleb E. Smith, Jens Kleesiek, Julian Friedrich

While increasing patients' access to medical documents improves medical care,
this benefit is limited by varying health literacy levels and complex medical
terminology. Large language models (LLMs) offer solutions by simplifying
medical information. However, evaluating LLMs for safe and patient-friendly
text generation is difficult due to the lack of standardized evaluation
resources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a dataset
created from MIMIC-IV discharge summaries through an automated pipeline
combining LLM-based question-answer generation with manual quality checks. We
use this dataset to evaluate various LLMs on patient-oriented
question-answering. Our findings reveal that general-purpose LLMs frequently
surpass biomedical-adapted models, while automated metrics correlate with human
judgment. By releasing MeDiSumQA on PhysioNet, we aim to advance the
development of LLMs to enhance patient understanding and ultimately improve
care outcomes.

摘要：儘管讓患者更能取得醫療文件有助於改善醫療照護，
但此優點受到不同的健康素養程度和複雜的醫療術語所限制。大型語言模型 (LLM) 提供了簡化醫療資訊的解決方案。然而，由於缺乏標準化的評估資源，因此難以評估 LLM 以確保其安全且對患者友善的文字產生。為了填補此缺口，我們開發了 MeDiSumQA。MeDiSumQA 是透過自動化流程從 MIMIC-IV 出院摘要中建立的資料集，結合了基於 LLM 的問答產生和手動品質檢查。我們使用此資料集來評估各種 LLM 在以患者為導向的問答中。我們的發現顯示，通用 LLM 經常超越生物醫學適應模型，而自動化指標與人類判斷相關。透過在 PhysioNet 上發布 MeDiSumQA，我們旨在推動 LLM 的發展，以增進患者理解，並最終改善照護成果。

##### **Deep Learning Pipeline for Fully Automated Myocardial Infarct Segmentation from Clinical Cardiac MR Scans**
2502.03272v1 by Matthias Schwab, Mathias Pamminger, Christian Kremser, Agnes Mayr

Purpose: To develop and evaluate a deep learning-based method that allows to
perform myocardial infarct segmentation in a fully-automated way.
  Materials and Methods: For this retrospective study, a cascaded framework of
two and three-dimensional convolutional neural networks (CNNs), specialized on
identifying ischemic myocardial scars on late gadolinium enhancement (LGE)
cardiac magnetic resonance (CMR) images, was trained on an in-house training
dataset consisting of 144 examinations. On a separate test dataset from the
same institution, including images from 152 examinations obtained between 2021
and 2023, a quantitative comparison between artificial intelligence (AI)-based
segmentations and manual segmentations was performed. Further, qualitative
assessment of segmentation accuracy was evaluated for both human and
AI-generated contours by two CMR experts in a blinded experiment.
  Results: Excellent agreement could be found between manually and
automatically calculated infarct volumes ($\rho_c$ = 0.9). The qualitative
evaluation showed that compared to human-based measurements, the experts rated
the AI-based segmentations to better represent the actual extent of infarction
significantly (p < 0.001) more often (33.4% AI, 25.1% human, 41.5% equal). On
the contrary, for segmentation of microvascular obstruction (MVO), manual
measurements were still preferred (11.3% AI, 55.6% human, 33.1% equal).
  Conclusion: This fully-automated segmentation pipeline enables CMR infarct
size to be calculated in a very short time and without requiring any
pre-processing of the input images while matching the segmentation quality of
trained human observers. In a blinded experiment, experts preferred automated
infarct segmentations more often than manual segmentations, paving the way for
a potential clinical application.

摘要：<paragraph>目的：開發和評估一種基於深度學習的方法，允許以全自動的方式執行心肌梗塞分割。
材料和方法：對於這項回顧性研究，一個由二維和三維卷積神經網路 (CNN) 組成的串聯架構，專門用於識別晚期釓增強 (LGE) 心臟磁振造影 (CMR) 影像上的缺血性心肌疤痕，並在包含 144 項檢查的內部訓練資料集上受訓。在來自同一家機構的獨立測試資料集上，包括 2021 年至 2023 年間獲得的 152 項檢查的影像，執行基於人工智慧 (AI) 的分割和手動分割之間的定量比較。此外，由兩位 CMR 專家在盲測實驗中評估人類和 AI 生成的輪廓的分割準確度。
結果：在手動和自動計算的梗塞體積之間可以發現極佳的一致性（ρ_c = 0.9）。定性評估顯示，與基於人類的測量相比，專家評估 AI 基於分割能更能代表梗塞的實際範圍，顯著（p < 0.001）更常發生（33.4% AI，25.1% 人類，41.5% 相等）。相反，對於微血管阻塞 (MVO) 的分割，手動測量仍然較受青睞（11.3% AI，55.6% 人類，33.1% 相等）。
結論：這個全自動分割管道可以在很短的時間內計算 CMR 梗塞大小，而且無需對輸入影像進行任何前處理，同時匹配受過訓練的人類觀察者的分割品質。在盲測實驗中，專家比手動分割更常偏好自動梗塞分割，為潛在的臨床應用鋪平了道路。</paragraph>

##### **Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration**
2502.03238v2 by Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Zhen Chen

Recently computer-aided diagnosis has demonstrated promising performance,
effectively alleviating the workload of clinicians. However, the inherent
sample imbalance among different diseases leads algorithms biased to the
majority categories, leading to poor performance for rare categories. Existing
works formulated this challenge as a long-tailed problem and attempted to
tackle it by decoupling the feature representation and classification. Yet, due
to the imbalanced distribution and limited samples from tail classes, these
works are prone to biased representation learning and insufficient classifier
calibration. To tackle these problems, we propose a new Long-tailed Medical
Diagnosis (LMD) framework for balanced medical image classification on
long-tailed datasets. In the initial stage, we develop a Relation-aware
Representation Learning (RRL) scheme to boost the representation ability by
encouraging the encoder to capture intrinsic semantic features through
different data augmentations. In the subsequent stage, we propose an Iterative
Classifier Calibration (ICC) scheme to calibrate the classifier iteratively.
This is achieved by generating a large number of balanced virtual features and
fine-tuning the encoder using an Expectation-Maximization manner. The proposed
ICC compensates for minority categories to facilitate unbiased classifier
optimization while maintaining the diagnostic knowledge in majority classes.
Comprehensive experiments on three public long-tailed medical datasets
demonstrate that our LMD framework significantly surpasses state-of-the-art
approaches. The source code can be accessed at
https://github.com/peterlipan/LMD.

摘要：<paragraph>最近，计算机辅助诊断已展现出可观的表现，有效减轻了临床医生的工作量。然而，不同疾病之间固有的样本不平衡导致算法偏向于多数类别，从而导致罕见类别表现不佳。现有工作将这一挑战表述为长尾问题，并尝试通过解耦特征表示和分类来解决它。然而，由于不平衡分布和尾类样本有限，这些工作容易出现有偏差的表示学习和分类器校准不足。为了解决这些问题，我们提出了一个新的长尾医学诊断 (LMD) 框架，用于对长尾数据集进行平衡的医学图像分类。在初始阶段，我们开发了一个关系感知表示学习 (RRL) 方案，通过鼓励编码器通过不同的数据增强来捕获内在语义特征，从而提升表示能力。在后续阶段，我们提出了一个迭代分类器校准 (ICC) 方案，以迭代方式校准分类器。这是通过生成大量的平衡虚拟特征并使用期望最大化方式微调编码器来实现的。所提出的 ICC 补偿了少数类别，以促进无偏分类器优化，同时保持多数类别的诊断知识。在三个公共长尾医学数据集上进行的综合实验表明，我们的 LMD 框架明显超越了最先进的方法。源代码可在 https://github.com/peterlipan/LMD 处获取。</paragraph>

##### **MedBioLM: Optimizing Medical and Biological QA with Fine-Tuned Large Language Models and Retrieval-Augmented Generation**
2502.03004v1 by Seonok Kim

Large Language Models (LLMs) have demonstrated impressive capabilities across
natural language processing tasks. However, their application to specialized
domains such as medicine and biology requires further optimization to ensure
factual accuracy, reliability, and contextual depth. We introduce MedBioLM, a
domain-adapted biomedical question-answering model designed to enhance both
short-form and long-form queries. By integrating fine-tuning and
retrieval-augmented generation (RAG), MedBioLM dynamically incorporates
domain-specific knowledge, improving reasoning abilities and factual accuracy.
To evaluate its effectiveness, we fine-tuned the model on diverse biomedical QA
datasets, covering structured multiple-choice assessments and complex clinical
reasoning tasks. Fine-tuning significantly improves accuracy on benchmark
datasets, while RAG enhances factual consistency. These results highlight the
potential of domain-optimized LLMs in advancing biomedical research, medical
education, and clinical decision support.

摘要：大型語言模型 (LLM) 已展現出在自然語言處理任務中令人印象深刻的能力。然而，要將其應用於醫學和生物學等特定領域，需要進一步最佳化，以確保事實的準確性、可靠性以及脈絡的深度。我們引進了 MedBioLM，這是一個適應領域的生物醫學問答模型，旨在增強短式和長式查詢。透過整合微調和檢索增強生成 (RAG)，MedBioLM 能動態地納入領域特定的知識，從而提升推理能力和事實準確性。為了評估其有效性，我們對模型進行微調，使其涵蓋結構化的多重選擇評量和複雜的臨床推理任務等多樣化的生物醫學問答資料集。微調顯著提升了基準資料集的準確性，而 RAG 則增強了事實的一致性。這些結果突顯了領域最佳化的 LLM 在推進生物醫學研究、醫學教育和臨床決策支援方面的潛力。

##### **Contrastive Token-level Explanations for Graph-based Rumour Detection**
2502.04366v1 by Daniel Wai Kit Chin, Roy Ka-Wei Lee

The widespread use of social media has accelerated the dissemination of
information, but it has also facilitated the spread of harmful rumours, which
can disrupt economies, influence political outcomes, and exacerbate public
health crises, such as the COVID-19 pandemic. While Graph Neural Network
(GNN)-based approaches have shown significant promise in automated rumour
detection, they often lack transparency, making their predictions difficult to
interpret. Existing graph explainability techniques fall short in addressing
the unique challenges posed by the dependencies among feature dimensions in
high-dimensional text embeddings used in GNN-based models. In this paper, we
introduce Contrastive Token Layerwise Relevance Propagation (CT-LRP), a novel
framework designed to enhance the explainability of GNN-based rumour detection.
CT-LRP extends current graph explainability methods by providing token-level
explanations that offer greater granularity and interpretability. We evaluate
the effectiveness of CT-LRP across multiple GNN models trained on three
publicly available rumour detection datasets, demonstrating that it
consistently produces high-fidelity, meaningful explanations, paving the way
for more robust and trustworthy rumour detection systems.

摘要：社群媒體的廣泛使用加速了資訊的傳播，但也促进了有害謠言的散播，這可能會擾亂經濟、影響政治結果，並加劇公共衛生危機，例如 COVID-19 大流行。雖然基於圖神經網路 (GNN) 的方法在自動化謠言偵測方面展現了顯著的前景，但它們通常缺乏透明度，這使得它們的預測難以解釋。現有的圖形可解釋性技術無法解決 GNN 模型中使用的維度嵌入式文本之間的依賴性所帶來的獨特挑戰。在本文中，我們介紹了對比標記分層關聯性傳播 (CT-LRP)，這是一個新穎的框架，旨在增強基於 GNN 的謠言偵測的可解釋性。CT-LRP 透過提供標記級別的解釋來擴充當前的圖形可解釋性方法，這些解釋提供了更細緻的粒度和可解釋性。我們在三個公開的謠言偵測資料集上訓練的幾個 GNN 模型中評估了 CT-LRP 的有效性，證明它始終產生高保真、有意義的解釋，為更強健且值得信賴的謠言偵測系統鋪路。

##### **AI-Based Thermal Video Analysis in Privacy-Preserving Healthcare: A Case Study on Detecting Time of Birth**
2502.04365v1 by Jorge García-Torres, Øyvind Meinich-Bache, Siren Rettedal, Kjersti Engan

Approximately 10% of newborns need some assistance to start breathing and 5\%
proper ventilation. It is crucial that interventions are initiated as soon as
possible after birth. Accurate documentation of Time of Birth (ToB) is thereby
essential for documenting and improving newborn resuscitation performance.
However, current clinical practices rely on manual recording of ToB, typically
with minute precision. In this study, we present an AI-driven, video-based
system for automated ToB detection using thermal imaging, designed to preserve
the privacy of healthcare providers and mothers by avoiding the use of
identifiable visual data. Our approach achieves 91.4% precision and 97.4%
recall in detecting ToB within thermal video clips during performance
evaluation. Additionally, our system successfully identifies ToB in 96% of test
cases with an absolute median deviation of 1 second compared to manual
annotations. This method offers a reliable solution for improving ToB
documentation and enhancing newborn resuscitation outcomes.

摘要：約 10% 的新生兒需要協助才能開始呼吸，5% 需要適當的通氣。在出生後盡快開始介入至關重要。準確記錄出生時間 (ToB) 對於記錄和改善新生兒復甦表現至關重要。然而，目前的臨床實務依賴於手動記錄 ToB，通常精確到分鐘。在這項研究中，我們提出一個以 AI 為主的、基於影片的系統，用於使用熱影像自動偵測 ToB，旨在透過避免使用可識別的視覺資料來保護醫療保健提供者和母親的隱私。我們的做法在執行評估期間，在熱影像片段中偵測 ToB 時達到了 91.4% 的精確度和 97.4% 的召回率。此外，我們的系統在 96% 的測試案例中成功識別出 ToB，與手動註解相比，絕對中位數偏差為 1 秒。此方法提供了一個可靠的解決方案，用於改善 ToB 記錄和增強新生兒復甦結果。

##### **3D Foundation AI Model for Generalizable Disease Detection in Head Computed Tomography**
2502.02779v1 by Weicheng Zhu, Haoxu Huang, Huanze Tang, Rushabh Musthyala, Boyang Yu, Long Chen, Emilio Vega, Thomas O'Donnell, Seena Dehkharghani, Jennifer A. Frontera, Arjun V. Masurkar, Kara Melmed, Narges Razavian

Head computed tomography (CT) imaging is a widely-used imaging modality with
multitudes of medical indications, particularly in assessing pathology of the
brain, skull, and cerebrovascular system. It is commonly the first-line imaging
in neurologic emergencies given its rapidity of image acquisition, safety,
cost, and ubiquity. Deep learning models may facilitate detection of a wide
range of diseases. However, the scarcity of high-quality labels and
annotations, particularly among less common conditions, significantly hinders
the development of powerful models. To address this challenge, we introduce
FM-CT: a Foundation Model for Head CT for generalizable disease detection,
trained using self-supervised learning. Our approach pre-trains a deep learning
model on a large, diverse dataset of 361,663 non-contrast 3D head CT scans
without the need for manual annotations, enabling the model to learn robust,
generalizable features. To investigate the potential of self-supervised
learning in head CT, we employed both discrimination with self-distillation and
masked image modeling, and we construct our model in 3D rather than at the
slice level (2D) to exploit the structure of head CT scans more comprehensively
and efficiently. The model's downstream classification performance is evaluated
using internal and three external datasets, encompassing both in-distribution
(ID) and out-of-distribution (OOD) data. Our results demonstrate that the
self-supervised foundation model significantly improves performance on
downstream diagnostic tasks compared to models trained from scratch and
previous 3D CT foundation models on scarce annotated datasets. This work
highlights the effectiveness of self-supervised learning in medical imaging and
sets a new benchmark for head CT image analysis in 3D, enabling broader use of
artificial intelligence for head CT-based diagnosis.

摘要：頭部電腦斷層掃描（CT）影像是一種廣泛使用的影像模式，具有
大量的醫療適應症，特別是在評估腦部、頭骨和腦血管系統的病理時。由於其影像擷取速度快、安全性、成本低和普遍性，通常是神經緊急情況下的第一線影像。深度學習模型可以促進對各種疾病的檢測。然而，高品質標籤和註釋的稀缺，特別是在較不常見的疾病中，顯著地阻礙了強大模型的發展。為了應對這一挑戰，我們引入了 FM-CT：一個用於頭部 CT 的基礎模型，用於可概化的疾病檢測，並使用自我監督學習進行訓練。我們的做法在一個包含 361,663 個非對比 3D 頭部 CT 掃描的大型、多樣化的數據集上預訓練一個深度學習模型，而無需手動註釋，使模型能夠學習強健、可概化的特徵。為了探討自我監督學習在頭部 CT 中的潛力，我們同時採用了帶有自我蒸餾的判別和遮罩影像建模，並且我們以 3D 而不是切片層級（2D）構建我們的模型，以更全面、有效地利用頭部 CT 掃描的結構。該模型的下游分類效能使用內部和三個外部數據集進行評估，包括分佈內 (ID) 和分佈外 (OOD) 資料。我們的結果表明，與從頭開始訓練的模型和先前在稀疏註釋數據集上訓練的 3D CT 基礎模型相比，自我監督基礎模型顯著改善了下游診斷任務的效能。這項工作突顯了自我監督學習在醫學影像中的有效性，並為 3D 頭部 CT 影像分析設定了一個新的基準，讓人工智慧能夠更廣泛地用於基於頭部 CT 的診斷。

##### **Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images**
2502.02756v1 by Obed Korshie Dzikunu, Shadab Ahamed, Amirhossein Toosi, Xiaoxiao Li, Arman Rahmim

This study proposes a new loss function for deep neural networks, L1-weighted
Dice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of
voxels based on their classification difficulty, towards automated detection
and segmentation of metastatic prostate cancer lesions in PET/CT scans. We
obtained 380 PSMA [18-F] DCFPyL PET/CT scans of patients diagnosed with
biochemical recurrence metastatic prostate cancer. We trained two 3D
convolutional neural networks, Attention U-Net and SegResNet, and concatenated
the PET and CT volumes channel-wise as input. The performance of our custom
loss function was evaluated against the Dice and Dice Focal Loss functions. For
clinical significance, we considered a detected region of interest (ROI) as a
true positive if at least the voxel with the maximum standardized uptake value
falls within the ROI. We assessed the models' performance based on the number
of lesions in an image, tumour volume, activity, and extent of spread. The
L1DFL outperformed the comparative loss functions by at least 13% on the test
set. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were
lower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal
Loss yielded more false positives, whereas the Dice Loss was more sensitive to
smaller volumes and struggled to segment larger lesions accurately. They also
exhibited network-specific variations and yielded declines in segmentation
accuracy with increased tumour spread. Our results demonstrate the potential of
L1DFL to yield robust segmentation of metastatic prostate cancer lesions in
PSMA PET/CT images. The results further highlight potential complexities
arising from the variations in lesion characteristics that may influence
automated prostate cancer tumour detection and segmentation. The code is
publicly available at: https://github.com/ObedDzik/pca_segment.git.

摘要：<paragraph>本研究針對深度神經網路提出一個新的損失函數，L1 加權 Dice 焦點損失 (L1DFL)，它利用 L1 範數根據體素的分類難度進行自適應加權，用於自動偵測和分割 PET/CT 掃描中轉移性前列腺癌病灶。我們取得 380 個經診斷為生化復發轉移性前列腺癌的患者的 PSMA [18-F] DCFPyL PET/CT 掃描。我們訓練了兩個 3D 捲積神經網路，Attention U-Net 和 SegResNet，並將 PET 和 CT 體積按通道連接作為輸入。我們自訂的損失函數的效能與 Dice 和 Dice 焦點損失函數進行評估。為了臨床意義，我們將一個偵測到的感興趣區域 (ROI) 視為真陽性，如果至少具有最大標準攝取值的體素落在 ROI 內。我們根據影像中的病灶數量、腫瘤體積、活性，以及擴散程度評估模型的效能。L1DFL 在測試組中至少比比較損失函數高出 13%。此外，Dice 損失和 Dice 焦點損失的 F1 分數分別比 L1DFL 低至少 6% 和 34%。Dice 焦點損失產生更多假陽性，而 Dice 損失對較小體積較為敏感，且難以準確分割較大病灶。它們也展現出網路特定的變化，並隨著腫瘤擴散而導致分割準確度下降。我們的結果證明 L1DFL 具有在 PSMA PET/CT 影像中產生轉移性前列腺癌病灶的強健分割的潛力。結果進一步強調由病灶特徵變化所產生的潛在複雜性，這可能會影響自動化前列腺癌腫瘤偵測和分割。程式碼公開於：https://github.com/ObedDzik/pca_segment.git。</paragraph>

##### **MedRAX: Medical Reasoning Agent for Chest X-ray**
2502.02673v1 by Adibvafa Fallahpour, Jun Ma, Alif Munim, Hongwei Lyu, Bo Wang

Chest X-rays (CXRs) play an integral role in driving critical decisions in
disease management and patient care. While recent innovations have led to
specialized models for various CXR interpretation tasks, these solutions often
operate in isolation, limiting their practical utility in clinical practice. We
present MedRAX, the first versatile AI agent that seamlessly integrates
state-of-the-art CXR analysis tools and multimodal large language models into a
unified framework. MedRAX dynamically leverages these models to address complex
medical queries without requiring additional training. To rigorously evaluate
its capabilities, we introduce ChestAgentBench, a comprehensive benchmark
containing 2,500 complex medical queries across 7 diverse categories. Our
experiments demonstrate that MedRAX achieves state-of-the-art performance
compared to both open-source and proprietary models, representing a significant
step toward the practical deployment of automated CXR interpretation systems.
Data and code have been publicly available at
https://github.com/bowang-lab/MedRAX

摘要：胸部 X 光片 (CXR) 在疾病管理和患者照護中扮演著不可或缺的角色，推動著關鍵決策的制定。儘管近期的創新已針對各種 CXR 解讀任務開發出專門的模型，但這些解決方案通常獨立運作，限制了它們在臨床實務中的實際效用。我們提出 MedRAX，這是一款首創的多功能 AI 代理，它將最先進的 CXR 分析工具和多模態大型語言模型無縫整合到一個統一的架構中。MedRAX 動態運用這些模型來解決複雜的醫療查詢，而無需額外的訓練。為了嚴格評估其功能，我們引入了 ChestAgentBench，這是一個全面的基準，包含 7 個不同類別的 2,500 個複雜醫療查詢。我們的實驗證明，與開源和專有模型相比，MedRAX 達到了最先進的效能，這代表了自動化 CXR 解讀系統實際部署的重要一步。資料和程式碼已公開於 https://github.com/bowang-lab/MedRAX

##### **Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription**
2502.04356v1 by Mahdi Alkaeed, Sofiat Abioye, Adnan Qayyum, Yosra Magdi Mekki, Ilhem Berrou, Mohamad Abdallah, Ala Al-Fuqaha, Muhammad Bilal, Junaid Qadir

In response to the success of proprietary Large Language Models (LLMs) such
as OpenAI's GPT-4, there is a growing interest in developing open,
non-proprietary LLMs and AI foundation models (AIFMs) for transparent use in
academic, scientific, and non-commercial applications. Despite their inability
to match the refined functionalities of their proprietary counterparts, open
models hold immense potential to revolutionize healthcare applications. In this
paper, we examine the prospects of open-source LLMs and AIFMs for developing
healthcare applications and make two key contributions. Firstly, we present a
comprehensive survey of the current state-of-the-art open-source healthcare
LLMs and AIFMs and introduce a taxonomy of these open AIFMs, categorizing their
utility across various healthcare tasks. Secondly, to evaluate the
general-purpose applications of open LLMs in healthcare, we present a case
study on personalized prescriptions. This task is particularly significant due
to its critical role in delivering tailored, patient-specific medications that
can greatly improve treatment outcomes. In addition, we compare the performance
of open-source models with proprietary models in settings with and without
Retrieval-Augmented Generation (RAG). Our findings suggest that, although less
refined, open LLMs can achieve performance comparable to proprietary models
when paired with grounding techniques such as RAG. Furthermore, to highlight
the clinical significance of LLMs-empowered personalized prescriptions, we
perform subjective assessment through an expert clinician. We also elaborate on
ethical considerations and potential risks associated with the misuse of
powerful LLMs and AIFMs, highlighting the need for a cautious and responsible
implementation in healthcare.

摘要：<paragraph>為了回應 OpenAI 的 GPT-4 等專有大型語言模型 (LLM) 的成功，開發開放、非專有的 LLM 和人工智慧基礎模型 (AIFM) 以透明地用於學術、科學和非商業應用中，引起了越來越大的興趣。儘管無法與其專有對應產品的精緻功能相匹配，但開放模型在革新醫療保健應用方面具有巨大的潛力。在本文中，我們探討了開放原始碼 LLM 和 AIFM 在開發醫療保健應用方面的前景，並提出了兩項關鍵貢獻。首先，我們對當前最先進的開放原始碼醫療保健 LLM 和 AIFM 進行了全面的調查，並介紹了這些開放 AIFM 的分類法，對它們在各種醫療保健任務中的效用進行了分類。其次，為了評估開放 LLM 在醫療保健中的通用應用，我們對個人化處方進行了案例研究。這項任務特別重要，因為它在提供量身定制的患者特定藥物方面發揮著關鍵作用，可以大大改善治療效果。此外，我們比較了開放原始碼模型與專有模型在有和沒有檢索增強生成 (RAG) 的設置中的性能。我們的研究結果表明，儘管不太精緻，但開放 LLM 在與 RAG 等基礎技術配對時，可以實現與專有模型相當的性能。此外，為了強調 LLM 賦能的個性化處方的臨床意義，我們通過專家臨床醫生進行了主觀評估。我們還詳細說明了與濫用強大的 LLM 和 AIFM 相關的倫理考量和潛在風險，強調了在醫療保健中謹慎和負責任地實施的必要性。</paragraph>

##### **Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents**
2502.02561v1 by Shayan Kiyani, George Pappas, Aaron Roth, Hamed Hassani

A fundamental question in data-driven decision making is how to quantify the
uncertainty of predictions in ways that can usefully inform downstream action.
This interface between prediction uncertainty and decision-making is especially
important in risk-sensitive domains, such as medicine. In this paper, we
develop decision-theoretic foundations that connect uncertainty quantification
using prediction sets with risk-averse decision-making. Specifically, we answer
three fundamental questions: (1) What is the correct notion of uncertainty
quantification for risk-averse decision makers? We prove that prediction sets
are optimal for decision makers who wish to optimize their value at risk. (2)
What is the optimal policy that a risk averse decision maker should use to map
prediction sets to actions? We show that a simple max-min decision policy is
optimal for risk-averse decision makers. Finally, (3) How can we derive
prediction sets that are optimal for such decision makers? We provide an exact
characterization in the population regime and a distribution free finite-sample
construction. Answering these questions naturally leads to an algorithm,
Risk-Averse Calibration (RAC), which follows a provably optimal design for
deriving action policies from predictions. RAC is designed to be both
practical-capable of leveraging the quality of predictions in a black-box
manner to enhance downstream utility-and safe-adhering to a user-defined risk
threshold and optimizing the corresponding risk quantile of the user's
downstream utility. Finally, we experimentally demonstrate the significant
advantages of RAC in applications such as medical diagnosis and recommendation
systems. Specifically, we show that RAC achieves a substantially improved
trade-off between safety and utility, offering higher utility compared to
existing methods while maintaining the safety guarantee.

摘要：<paragraph>在資料驅動決策中，一個基本問題是，如何量化預測的不確定性，以能有用地告知下游行動。
預測不確定性和決策制定之間的這種介面，在風險敏感領域中特別重要，例如醫學。在本文中，我們
發展了決策理論基礎，它利用預測集合將不確定性量化與風險規避決策制定聯繫起來。具體來說，我們回答
了三個基本問題：(1) 對於風險規避決策者來說，不確定性量化的正確概念是什麼？我們證明，對於希望最佳化其風險價值的決策者來說，預測集合是最佳的。(2)
風險規避決策者應使用什麼最佳政策，將預測集合映射到行動？我們表明，對於風險規避決策者來說，一個簡單的最大最小決策政策是最佳的。最後，(3) 我們如何推導出對此類決策者來說最佳的預測集合？我們在總體範圍內提供了一個確切的表徵，並提供了一個不依賴分佈的有限樣本建構。回答這些問題自然會導致一個演算法，風險規避校準 (RAC)，它遵循一個可證明最佳的設計，從預測中推導出行動政策。RAC 被設計為既實用——能夠以黑盒方式利用預測的品質來增強下游效用——又安全——遵守使用者定義的風險閾值，並最佳化使用者的下游效用的對應風險分位數。最後，我們在醫學診斷和推薦系統等應用中，以實驗方式證明了 RAC 的顯著優點。具體來說，我們表明，與現有方法相比，RAC 在安全性和效用之間實現了顯著改善的折衷，在維持安全保證的同時，提供了更高的效用。</paragraph>

##### **A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation**
2502.02489v1 by Edward Ellis, Andrew Bulpitt, Nasim Parsa, Michael F Byrne, Sharib Ali

Ultrasound (US) imaging is clinically invaluable due to its noninvasive and
safe nature. However, interpreting US images is challenging, requires
significant expertise, and time, and is often prone to errors. Deep learning
offers assistive solutions such as segmentation. Supervised methods rely on
large, high-quality, and consistently labeled datasets, which are challenging
to curate. Moreover, these methods tend to underperform on out-of-distribution
data, limiting their clinical utility. Self-supervised learning (SSL) has
emerged as a promising alternative, leveraging unlabeled data to enhance model
performance and generalisability. We introduce a contrastive SSL approach
tailored for B-mode US images, incorporating a novel Relation Contrastive Loss
(RCL). RCL encourages learning of distinct features by differentiating positive
and negative sample pairs through a learnable metric. Additionally, we propose
spatial and frequency-based augmentation strategies for the representation
learning on US images. Our approach significantly outperforms traditional
supervised segmentation methods across three public breast US datasets,
particularly in data-limited scenarios. Notable improvements on the Dice
similarity metric include a 4% increase on 20% and 50% of the BUSI dataset,
nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4%
and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively.
Furthermore, we demonstrate superior generalisability on the
out-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6%
compared to the supervised baseline using 20% and 50% of the BUSI and BrEaST
training data, respectively. Our research highlights that domain-inspired SSL
can improve US segmentation, especially under data-limited conditions.

摘要：超音波 (US) 影像由於其非侵入性且安全的特性，在臨床上極具價值。然而，解讀超音波影像具有挑戰性，需要大量的專業知識和時間，而且經常容易出錯。深度學習提供了輔助解決方案，例如分割。監督式方法依賴於大量、高品質且標籤一致的資料集，而這在策劃上具有挑戰性。此外，這些方法在分佈外資料上的表現往往不佳，這限制了它們的臨床效用。自監督學習 (SSL) 已成為一種有前途的替代方案，它利用未標籤資料來增強模型效能和泛化能力。我們提出了一種對比式 SSL 方法，專門針對 B 模式超音波影像，並納入了新穎的關係對比損失 (RCL)。RCL 透過一個可學習的指標區分正負樣本對，來鼓勵學習不同的特徵。此外，我們提出了用於超音波影像上表徵學習的空間和頻率增強策略。我們的做法在三個公開的乳房超音波資料集上顯著優於傳統的監督式分割方法，特別是在資料有限的情況下。在 Dice 相似性指標上的顯著改進包括在 BUSI 資料集的 20% 和 50% 上增加了 4%，在 BrEaST 資料集的 20% 和 50% 上增加了近 6% 和 9%，以及在 UDIAT 資料集的 20% 和 50% 上分別增加了 6.4% 和 3.7%。此外，我們在分佈外的 UDIAT 資料集上展示了卓越的泛化能力，與使用 BUSI 和 BrEaST 訓練資料的 20% 和 50% 的監督式基準相比，效能分別提升了 20.6% 和 13.6%。我們的研究強調，領域啟發的 SSL 可以改善超音波分割，特別是在資料有限的條件下。

##### **Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment**
2502.02438v1 by Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab, Nicolas Padoy, Mario Fritz

Medical multimodal large language models (MLLMs) are becoming an instrumental
part of healthcare systems, assisting medical personnel with decision making
and results analysis. Models for radiology report generation are able to
interpret medical imagery, thus reducing the workload of radiologists. As
medical data is scarce and protected by privacy regulations, medical MLLMs
represent valuable intellectual property. However, these assets are potentially
vulnerable to model stealing, where attackers aim to replicate their
functionality via black-box access. So far, model stealing for the medical
domain has focused on classification; however, existing attacks are not
effective against MLLMs. In this paper, we introduce Adversarial Domain
Alignment (ADA-STEAL), the first stealing attack against medical MLLMs.
ADA-STEAL relies on natural images, which are public and widely available, as
opposed to their medical counterparts. We show that data augmentation with
adversarial noise is sufficient to overcome the data distribution gap between
natural images and the domain-specific distribution of the victim MLLM.
Experiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that
Adversarial Domain Alignment enables attackers to steal the medical MLLM
without any access to medical data.

摘要：醫療多模態大型語言模型 (MLLM) 正在成為醫療保健系統中不可或缺的一部分，協助醫療人員進行決策和結果分析。放射報告生成的模型能夠解釋醫學影像，從而減輕放射科醫師的工作負擔。由於醫療資料稀少且受隱私法規保護，醫療 MLLM 代表了有價值的智慧財產。然而，這些資產潛在地容易受到模型竊取的攻擊，攻擊者旨在透過黑盒存取來複製其功能。到目前為止，針對醫療領域的模型竊取一直專注於分類；然而，現有的攻擊對 MLLM 沒有效。在本文中，我們介紹了對抗域對齊 (ADA-STEAL)，這是針對醫療 MLLM 的第一個竊取攻擊。與醫療對應物相反，ADA-STEAL 依賴於公開且廣泛可用的自然影像。我們表明，對抗雜訊的資料擴充足以克服自然影像與受害者 MLLM 的特定領域分佈之間的資料分佈差距。在 IU X-RAY 和 MIMIC-CXR 放射學資料集上進行的實驗表明，對抗域對齊使攻擊者能夠在不存取任何醫療資料的情況下竊取醫療 MLLM。

##### **Test Time Training for 4D Medical Image Interpolation**
2502.02341v1 by Qikang Zhang, Yingjie Lei, Zihao Zheng, Ziyang Chen, Zhonghao Xie

4D medical image interpolation is essential for improving temporal resolution
and diagnostic precision in clinical applications. Previous works ignore the
problem of distribution shifts, resulting in poor generalization under
different distribution. A natural solution would be to adapt the model to a new
test distribution, but this cannot be done if the test input comes without a
ground truth label. In this paper, we propose a novel test time training
framework which uses self-supervision to adapt the model to a new distribution
without requiring any labels. Indeed, before performing frame interpolation on
each test video, the model is trained on the same instance using a
self-supervised task, such as rotation prediction or image reconstruction. We
conduct experiments on two publicly available 4D medical image interpolation
datasets, Cardiac and 4D-Lung. The experimental results show that the proposed
method achieves significant performance across various evaluation metrics on
both datasets. It achieves higher peak signal-to-noise ratio values, 33.73dB on
Cardiac and 34.02dB on 4D-Lung. Our method not only advances 4D medical image
interpolation but also provides a template for domain adaptation in other
fields such as image segmentation and image registration.

摘要：4D 醫學影像插值對於提升時間解析度及臨床應用中的診斷精準度至關重要。過往的研究忽略了分佈轉移問題，導致在不同分佈下泛化能力不佳。一個自然的解決方案是將模型適應到新的測試分佈，但如果測試輸入沒有真實標籤，就無法做到這一點。在本文中，我們提出了一個新的測試時間訓練架構，它使用自我監督來適應模型到一個新的分佈，而不需要任何標籤。事實上，在對每個測試影片執行幀插值之前，使用自我監督任務（例如旋轉預測或影像重建）在同一個實例上訓練模型。我們在兩個公開的 4D 醫學影像插值資料集（Cardiac 和 4D-Lung）上進行實驗。實驗結果表明，所提出的方法在兩個資料集上的各種評估指標中都取得了顯著的效能。它達到了更高的峰值信噪比值，在 Cardiac 上為 33.73dB，在 4D-Lung 上為 34.02dB。我們的技術不僅推動了 4D 醫學影像插值，還為其他領域（例如影像分割和影像配準）中的領域適應提供了一個範本。

##### **Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation**
2502.02249v1 by Atharva Mangeshkumar Agrawal, Rutika Pandurang Shinde, Vasanth Kumar Bhukya, Ashmita Chakraborty, Sagar Bharat Shah, Tanmay Shukla, Sree Pradeep Kumar Relangi, Nilesh Mutyam

Large language models (LLMs) have shown impressive capabilities in natural
language processing tasks, including dialogue generation. This research aims to
conduct a novel comparative analysis of two prominent techniques, fine-tuning
with LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG)
framework, in the context of doctor-patient chat conversations with multiple
datasets of mixed medical domains. The analysis involves three state-of-the-art
models: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient
dialogues, we comprehensively evaluate the performance of models, assessing key
metrics such as language quality (perplexity, BLEU score), factual accuracy
(fact-checking against medical knowledge bases), adherence to medical
guidelines, and overall human judgments (coherence, empathy, safety). The
findings provide insights into the strengths and limitations of each approach,
shedding light on their suitability for healthcare applications. Furthermore,
the research investigates the robustness of the models in handling diverse
patient queries, ranging from general health inquiries to specific medical
conditions. The impact of domain-specific knowledge integration is also
explored, highlighting the potential for enhancing LLM performance through
targeted data augmentation and retrieval strategies.

摘要：大型語言模型 (LLM) 在自然語言處理任務中展現了令人印象深刻的能力，包括對話生成。本研究旨在對兩種著名的技術進行新穎的比較分析，即微調 LoRA (低秩適應) 和檢索增強生成 (RAG) 框架，在具有混合醫療領域的多個資料集的醫患聊天對話中。分析涉及三個最先進的模型：Llama-2、GPT 和 LSTM 模型。採用真實世界的醫患對話，我們全面評估模型的性能，評估語言品質（困惑度、BLEU 分數）、事實準確性（對照醫學知識庫進行事實查核）、遵守醫療指南以及整體人類判斷（連貫性、同理心、安全性）等關鍵指標。研究結果深入了解了每種方法的優點和限制，闡明了它們適用於醫療保健應用的適當性。此外，該研究調查了模型在處理多樣化患者查詢時的穩健性，範圍從一般健康詢問到特定醫療狀況。還探討了特定領域知識整合的影響，強調了通過有針對性的資料擴充和檢索策略來增強 LLM 性能的潛力。

##### **Deep Learning-Based Facial Expression Recognition for the Elderly: A Systematic Review**
2502.02618v1 by F. Xavier Gaya-Morey, Jose M. Buades-Rubio, Philippe Palanque, Raquel Lacuesta, Cristina Manresa-Yee

The rapid aging of the global population has highlighted the need for
technologies to support elderly, particularly in healthcare and emotional
well-being. Facial expression recognition (FER) systems offer a non-invasive
means of monitoring emotional states, with applications in assisted living,
mental health support, and personalized care. This study presents a systematic
review of deep learning-based FER systems, focusing on their applications for
the elderly population. Following a rigorous methodology, we analyzed 31
studies published over the last decade, addressing challenges such as the
scarcity of elderly-specific datasets, class imbalances, and the impact of
age-related facial expression differences. Our findings show that convolutional
neural networks remain dominant in FER, and especially lightweight versions for
resource-constrained environments. However, existing datasets often lack
diversity in age representation, and real-world deployment remains limited.
Additionally, privacy concerns and the need for explainable artificial
intelligence emerged as key barriers to adoption. This review underscores the
importance of developing age-inclusive datasets, integrating multimodal
solutions, and adopting XAI techniques to enhance system usability,
reliability, and trustworthiness. We conclude by offering recommendations for
future research to bridge the gap between academic progress and real-world
implementation in elderly care.

摘要：全球人口快速老龄化突显了对技术的需求，以支持老年人，尤其是在医疗保健和情绪健康方面。面部表情识别 (FER) 系统提供了一种非侵入性的情绪状态监测手段，在辅助生活、心理健康支持和个性化护理中得到应用。本研究对基于深度学习的 FER 系统进行了系统的回顾，重点关注它们在老年人群中的应用。遵循严格的方法，我们分析了在过去十年中发表的 31 项研究，解决了诸如老年人特定数据集的稀缺性、类别不平衡以及与年龄相关的面部表情差异的影响等挑战。我们的研究结果表明，卷积神经网络在 FER 中仍然占主导地位，特别是针对资源受限环境的轻量级版本。然而，现有数据集往往缺乏年龄代表性的多样性，并且现实世界的部署仍然有限。此外，隐私问题和对可解释人工智能的需求已成为采用过程中的主要障碍。本次审查强调了开发包容年龄的数据集、整合多模式解决方案以及采用 XAI 技术以增强系统可用性、可靠性和可信度的重要性。最后，我们提出了未来研究的建议，以弥合学术进展与老年护理中的现实世界实施之间的差距。

##### **Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care**
2502.02109v1 by Yuxiao Cheng, Xinxin Song, Ziqian Wang, Qin Zhong, Kunlun He, Jinli Suo

Recent advances in deep learning (DL) have prompted the development of
high-performing early warning score (EWS) systems, predicting clinical
deteriorations such as acute kidney injury, acute myocardial infarction, or
circulatory failure. DL models have proven to be powerful tools for various
tasks but come with the cost of lacking interpretability and limited
generalizability, hindering their clinical applications. To develop a practical
EWS system applicable to various outcomes, we propose causally-informed
explainable early prediction model, which leverages causal discovery to
identify the underlying causal relationships of prediction and thus owns two
unique advantages: demonstrating the explicit interpretation of the prediction
while exhibiting decent performance when applied to unfamiliar environments.
Benefiting from these features, our approach achieves superior accuracy for 6
different critical deteriorations and achieves better generalizability across
different patient groups, compared to various baseline algorithms. Besides, we
provide explicit causal pathways to serve as references for assistant clinical
diagnosis and potential interventions. The proposed approach enhances the
practical application of deep learning in various medical scenarios.

摘要：深度學習 (DL) 的最新進展促使開發出高性能早期預警評分 (EWS) 系統，預測急性腎臟損傷、急性心肌梗塞或循環衰竭等臨床惡化。DL 模型已被證明是各種任務的強大工具，但代價是缺乏可解釋性和有限的概括性，阻礙了其臨床應用。為了開發適用於各種結果的實用 EWS 系統，我們提出了因果關係解釋性早期預測模型，它利用因果發現來識別預測的潛在因果關係，從而擁有兩個獨特的優點：展示預測的明確解釋，同時在應用於不熟悉的環境時表現出良好的性能。得益於這些特性，與各種基線演算法相比，我們的模型在 6 種不同的危重惡化中實現了更高的準確度，並在不同的患者群體中實現了更好的概括性。此外，我們提供了明確的因果途徑，作為輔助臨床診斷和潛在干預措施的參考。所提出的方法增強了深度學習在各種醫療場景中的實際應用。

##### **JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment**
2502.04345v1 by Yehan Yan, Tianhao Ma, Ruotai Li, Xinhan Zheng, Guodong Shan, Chisheng Li

Traditional Chinese medicine (TCM) plays a vital role in health protection
and disease treatment, but its practical application requires extensive medical
knowledge and clinical experience. Existing TCM Large Language Models (LLMs)
exhibit critical limitations of uncomprehensive medical consultation and
diagnoses, and inaccurate syndrome differentiation-based treatment. To address
these issues, this study establishes JingFang (JF): a novel TCM Large Language
Model that demonstrates the expert-level capability of medical diagnosis and
syndrome differentiation-based treatment. We innovate a Multi-agent Dynamic
Collaborative Chain-of-Thought Mechanism (MDCCTM) for medical consultation,
enabling JF with effective and accurate diagnostic ability. In addition, a
Syndrome Agent and a Dual-Stage Retrieval Scheme (DSRS) are developed to
significantly enhance the capacity of JF for disease treatment based on
syndrome differentiation. JingFang not only facilitates the application of LLMs
but also promotes the effective practice of TCM in human health protection and
disease treatment.

摘要：中醫藥在保健與疾病治療中扮演著重要的角色，但其實務應用需要深厚的醫學知識與臨床經驗。現有的中醫大語言模型（LLM）存在著醫療諮詢與診斷不全面、症候分型治療不準確的重大限制。為了解決這些問題，本研究建立了精方（JF）：一個新穎的中醫大語言模型，展示了專家級的醫療診斷與症候分型治療能力。我們創新了一個多智能體動態協作思考鏈機制（MDCCTM）用於醫療諮詢，讓 JF 具備有效且準確的診斷能力。此外，還開發了一個症候智能體和一個雙階段檢索方案（DSRS），以顯著增強 JF 基於症候分型的疾病治療能力。精方不僅促進了 LLM 的應用，也推動了中醫藥在人類保健與疾病治療中的有效實踐。

##### **An Agentic AI Workflow for Detecting Cognitive Concerns in Real-world Data**
2502.01789v1 by Jiazi Tian, Liqin Wang, Pedram Fard, Valdery Moura Junior, Deborah Blacker, Jennifer S. Haas, Chirag Patel, Shawn N. Murphy, Lidia M. V. R. Moura, Hossein Estiri

Early identification of cognitive concerns is critical but often hindered by
subtle symptom presentation. This study developed and validated a fully
automated, multi-agent AI workflow using LLaMA 3 8B to identify cognitive
concerns in 3,338 clinical notes from Mass General Brigham. The agentic
workflow, leveraging task-specific agents that dynamically collaborate to
extract meaningful insights from clinical notes, was compared to an
expert-driven benchmark. Both workflows achieved high classification
performance, with F1-scores of 0.90 and 0.91, respectively. The agentic
workflow demonstrated improved specificity (1.00) and achieved prompt
refinement in fewer iterations. Although both workflows showed reduced
performance on validation data, the agentic workflow maintained perfect
specificity. These findings highlight the potential of fully automated
multi-agent AI workflows to achieve expert-level accuracy with greater
efficiency, offering a scalable and cost-effective solution for detecting
cognitive concerns in clinical settings.

摘要：及早辨識認知問題至關重要，但常常受到症狀呈現過於細微的阻礙。本研究開發並驗證了一個全自動化、多重代理的 AI 工作流程，使用 LLaMA 3 8B 來辨識來自麻省總醫院布萊根分院的 3,338 則臨床筆記中的認知問題。這個代理工作流程利用了特定任務的代理，這些代理會動態合作從臨床筆記中萃取出有意義的見解，並與專家驅動的基準進行比較。這兩個工作流程都達到了很高的分類效能，F1 分數分別為 0.90 和 0.91。代理工作流程展現出更好的特異性（1.00），並且在更少的反覆運算中達到了提示精煉。儘管這兩個工作流程在驗證資料上的效能都降低了，但代理工作流程維持了完美的特異性。這些發現突顯了全自動化多重代理 AI 工作流程的潛力，它們能以更高的效率達到專家級的準確度，為在臨床環境中偵測認知問題提供了一個可擴充且具成本效益的解決方案。

##### **Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis**
2502.03482v1 by Chacha Chen, Han Liu, Jiamin Yang, Benjamin M. Mervak, Bora Kalaycioglu, Grace Lee, Emre Cakmakli, Matteo Bonatti, Sridhar Pudu, Osman Kahraman, Gul Gizem Pamuk, Aytekin Oto, Aritrick Chatterjee, Chenhao Tan

Despite the growing interest in human-AI decision making, experimental
studies with domain experts remain rare, largely due to the complexity of
working with domain experts and the challenges in setting up realistic
experiments. In this work, we conduct an in-depth collaboration with
radiologists in prostate cancer diagnosis based on MRI images. Building on
existing tools for teaching prostate cancer diagnosis, we develop an interface
and conduct two experiments to study how AI assistance and performance feedback
shape the decision making of domain experts. In Study 1, clinicians were asked
to provide an initial diagnosis (human), then view the AI's prediction, and
subsequently finalize their decision (human-AI team). In Study 2 (after a
memory wash-out period), the same participants first received aggregated
performance statistics from Study 1, specifically their own performance, the
AI's performance, and their human-AI team performance, and then directly viewed
the AI's prediction before making their diagnosis (i.e., no independent initial
diagnosis). These two workflows represent realistic ways that clinical AI tools
might be used in practice, where the second study simulates a scenario where
doctors can adjust their reliance and trust on AI based on prior performance
feedback. Our findings show that, while human-AI teams consistently outperform
humans alone, they still underperform the AI due to under-reliance, similar to
prior studies with crowdworkers. Providing clinicians with performance feedback
did not significantly improve the performance of human-AI teams, although
showing AI decisions in advance nudges people to follow AI more. Meanwhile, we
observe that the ensemble of human-AI teams can outperform AI alone, suggesting
promising directions for human-AI collaboration.

摘要：儘管人們對人類與 AI 決策制定越來越感興趣，但與領域專家合作的實驗研究仍然很少見，這在很大程度上是因為與領域專家合作的複雜性，以及在設定實際實驗時面臨的挑戰。在這項工作中，我們與放射科醫師進行深入合作，基於 MRI 影像診斷前列腺癌。建立在用於教授前列腺癌診斷的現有工具上，我們開發了一個介面並進行了兩項實驗，以研究 AI 協助和效能回饋如何塑造領域專家的決策制定。在研究 1 中，要求臨床醫師提供初步診斷（人類），然後檢視 AI 的預測，並隨後確定他們的決策（人類-AI 團隊）。在研究 2（經過一段記憶清除期）中，同一位參與者首先收到研究 1 的彙總效能統計資料，特別是他們自己的效能、AI 的效能，以及他們的人類-AI 團隊效能，然後在做出診斷前直接檢視 AI 的預測（即，沒有獨立的初步診斷）。這兩個工作流程代表了臨床 AI 工具在實務中可能被使用的方式，其中第二個研究模擬了醫生可以根據先前的效能回饋調整他們對 AI 的依賴和信任的情況。我們的研究結果顯示，儘管人類-AI 團隊始終優於單獨的人類，但由於依賴不足，他們仍然表現不如 AI，這與之前針對群眾工作者的研究類似。儘管事先顯示 AI 決策會促使人們更多地遵循 AI，但向臨床醫師提供效能回饋並未顯著改善人類-AI 團隊的效能。同時，我們觀察到人類-AI 團隊的集合可以優於單獨的 AI，這表明了人類-AI 合作的前景。

##### **Improving Transformer World Models for Data-Efficient RL**
2502.01591v1 by Antoine Dedieu, Joseph Ortiz, Xinghua Lou, Carter Wendelken, Wolfgang Lehrach, J Swaroop Guntupalli, Miguel Lazaro-Gredilla, Kevin Patrick Murphy

We present an approach to model-based RL that achieves a new state of the art
performance on the challenging Craftax-classic benchmark, an open-world 2D
survival game that requires agents to exhibit a wide range of general abilities
-- such as strong generalization, deep exploration, and long-term reasoning.
With a series of careful design choices aimed at improving sample efficiency,
our MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,
significantly outperforming DreamerV3, which achieves 53.2%, and, for the first
time, exceeds human performance of 65.0%. Our method starts by constructing a
SOTA model-free baseline, using a novel policy architecture that combines CNNs
and RNNs. We then add three improvements to the standard MBRL setup: (a) "Dyna
with warmup", which trains the policy on real and imaginary data, (b) "nearest
neighbor tokenizer" on image patches, which improves the scheme to create the
transformer world model (TWM) inputs, and (c) "block teacher forcing", which
allows the TWM to reason jointly about the future tokens of the next timestep.

摘要：我們提出了一個基於模型的 RL 方法，在具有挑戰性的 Craftax-classic 基準上實現了新的技術水準，這是一個開放世界的 2D 生存遊戲，要求代理人展現廣泛的一般能力，例如強大的概括能力、深入探索和長期推理。通過一系列旨在提高樣本效率的仔細設計選擇，我們的 MBRL 演算法在僅 1M 環境步驟後就實現了 67.4% 的獎勵，顯著優於 DreamerV3（實現 53.2%），並且首次超過了人類的 65.0% 的表現。我們的演算法首先通過使用結合 CNN 和 RNN 的新穎策略架構來建構一個 SOTA 無模型基線。然後，我們對標準 MBRL 設定新增了三項改進：(a)「帶熱身的 Dyna」，它在真實和假想資料上訓練策略，(b) 影像貼片的「最近鄰代碼化器」，它改進了建立轉換器世界模型 (TWM) 輸入的方案，以及 (c)「區塊教師強制」，它允許 TWM 共同推理下一個時間步長的未來代碼。

##### **Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data**
2502.01377v1 by Zhi Zhang, Yan Liu, Mengxia Gao, Yu Yang, Jiannong Cao, Wai Kai Hou, Shirley Li, Sonata Yau, Yun Kwok Wing, Tatia M. C. Lee

Psychological resilience, defined as the ability to rebound from adversity,
is crucial for mental health. Compared with traditional resilience assessments
through self-reported questionnaires, resilience assessments based on
neurological data offer more objective results with biological markers, hence
significantly enhancing credibility. This paper proposes a novel data-efficient
model to address the scarcity of neurological data. We employ Neuro
Kolmogorov-Arnold Networks as the structure of the prediction model. In the
training stage, a new trait-informed multimodal representation algorithm with a
smart chunk technique is proposed to learn the shared latent space with limited
data. In the test stage, a new noise-informed inference algorithm is proposed
to address the low signal-to-noise ratio of the neurological data. The proposed
model not only shows impressive performance on both public datasets and
self-constructed datasets but also provides some valuable psychological
hypotheses for future research.

摘要：心理韌性，定義為從逆境中反彈的能力，對心理健康至關重要。與通過自我報告問卷的傳統韌性評估相比，基於神經數據的韌性評估提供了更客觀的結果和生物標記，從而顯著提高了可信度。本文提出了一個新穎的數據高效模型來解決神經數據的稀缺性。我們採用神經科爾莫哥羅夫-阿諾德網路作為預測模型的結構。在訓練階段，提出了一種新的特徵信息多模態表示算法，採用智能塊技術，以有限的數據學習共享潛在空間。在測試階段，提出了一種新的噪聲信息推理算法，以解決神經數據的信噪比低的問題。所提出的模型不僅在公共數據集和自構數據集上都顯示出令人印象深刻的性能，還為未來的研究提供了一些有價值的心理假設。

##### **OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology**
2502.01243v1 by Chengfeng Zhou, Ji Wang, Juanjuan Qin, Yining Wang, Ling Sun, Weiwei Dai

Large language models (LLMs) have shown significant promise across various
medical applications, with ophthalmology being a notable area of focus. Many
ophthalmic tasks have shown substantial improvement through the integration of
LLMs. However, before these models can be widely adopted in clinical practice,
evaluating their capabilities and identifying their limitations is crucial. To
address this research gap and support the real-world application of LLMs, we
introduce the OphthBench, a specialized benchmark designed to assess LLM
performance within the context of Chinese ophthalmic practices. This benchmark
systematically divides a typical ophthalmic clinical workflow into five key
scenarios: Education, Triage, Diagnosis, Treatment, and Prognosis. For each
scenario, we developed multiple tasks featuring diverse question types,
resulting in a comprehensive benchmark comprising 9 tasks and 591 questions.
This comprehensive framework allows for a thorough assessment of LLMs'
capabilities and provides insights into their practical application in Chinese
ophthalmology. Using this benchmark, we conducted extensive experiments and
analyzed the results from 39 popular LLMs. Our evaluation highlights the
current gap between LLM development and its practical utility in clinical
settings, providing a clear direction for future advancements. By bridging this
gap, we aim to unlock the potential of LLMs and advance their development in
ophthalmology.

摘要：大型語言模型 (LLM) 在各種醫療應用中已展現出顯著的潛力，其中眼科是一個值得關注的重要領域。許多眼科任務已透過整合 LLM 而大幅進步。然而，在這些模型能廣泛應用於臨床實務之前，評估其能力並找出其限制至關重要。為了解決這個研究差距並支援 LLM 的實際應用，我們引入了 OphthBench，這是一個專門的基準測試，旨在評估 LLM 在中國眼科實務中的表現。此基準測試系統性地將典型眼科臨床工作流程劃分為五個關鍵情境：教育、分流、診斷、治療和預後。對於每個情境，我們開發了多項任務，包含多樣化的問題類型，最後組成一個包含 9 項任務和 591 個問題的綜合基準測試。此綜合架構可徹底評估 LLM 的能力，並提供其在中國眼科的實際應用見解。使用此基準測試，我們進行了廣泛的實驗，並分析了來自 39 個熱門 LLM 的結果。我們的評估強調了 LLM 開發與其在臨床環境中的實際效用之間的差距，為未來的進展提供了明確的方向。透過彌合此差距，我們旨在釋放 LLM 的潛力，並促進其在眼科的發展。

##### **MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks**
2502.01158v1 by Alejandro Guerra-Manzanares, Farah E. Shamout

Multimodal fusion leverages information across modalities to learn better
feature representations with the goal of improving performance in fusion-based
tasks. However, multimodal datasets, especially in medical settings, are
typically smaller than their unimodal counterparts, which can impede the
performance of multimodal models. Additionally, the increase in the number of
modalities is often associated with an overall increase in the size of the
multimodal network, which may be undesirable in medical use cases. Utilizing
smaller unimodal encoders may lead to sub-optimal performance, particularly
when dealing with high-dimensional clinical data. In this paper, we propose the
Modality-INformed knowledge Distillation (MIND) framework, a multimodal model
compression approach based on knowledge distillation that transfers knowledge
from ensembles of pre-trained deep neural networks of varying sizes into a
smaller multimodal student. The teacher models consist of unimodal networks,
allowing the student to learn from diverse representations. MIND employs
multi-head joint fusion models, as opposed to single-head models, enabling the
use of unimodal encoders in the case of unimodal samples without requiring
imputation or masking of absent modalities. As a result, MIND generates an
optimized multimodal model, enhancing both multimodal and unimodal
representations. It can also be leveraged to balance multimodal learning during
training. We evaluate MIND on binary and multilabel clinical prediction tasks
using time series data and chest X-ray images. Additionally, we assess the
generalizability of the MIND framework on three non-medical multimodal
multiclass datasets. Experimental results demonstrate that MIND enhances the
performance of the smaller multimodal network across all five tasks, as well as
various fusion methods and multimodal architectures, compared to
state-of-the-art baselines.

摘要：多模态融合利用跨模态的信息来学习更好的特征表示，目标是提升基于融合的任务的性能。然而，多模态数据集，尤其是在医疗环境中，通常比它们的单模态对应数据集小，这会阻碍多模态模型的性能。此外，模态数量的增加通常与多模态网络尺寸的整体增加相关，这在医疗用例中可能是不可取的。利用较小的单模态编码器可能会导致次优性能，尤其是在处理高维临床数据时。在本文中，我们提出了模态信息知识蒸馏 (MIND) 框架，这是一种基于知识蒸馏的多模态模型压缩方法，它将来自不同大小的预训练深度神经网络的集合中的知识转移到一个较小的多模态学生中。教师模型由单模态网络组成，允许学生从不同的表示中学习。MIND 采用多头联合融合模型，而不是单头模型，从而能够在单模态样本的情况下使用单模态编码器，而不需要缺失模态的插补或掩蔽。因此，MIND 生成了一个经过优化的多模态模型，增强了多模态和单模态表示。它还可以用来在训练期间平衡多模态学习。我们使用时间序列数据和胸部 X 射线图像对二元和多标签临床预测任务评估了 MIND。此外，我们评估了 MIND 框架在三个非医疗多模态多分类数据集上的泛化性。实验结果表明，与最先进的基线相比，MIND 增强了较小的多模态网络在所有五个任务以及各种融合方法和多模态架构中的性能。

##### **Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations**
2502.01141v1 by Qian Chen, Stefanie Rinderle-Ma, Lijie Wen

Most existing process compliance monitoring approaches detect compliance
violations in an ex post manner. Only predicate prediction focuses on
predicting them. However, predicate prediction provides a binary yes/no notion
of compliance, lacking the ability to measure to which extent an ongoing
process instance deviates from the desired state as specified in constraints.
Here, being able to quantify the magnitude of violation would provide
organizations with deeper insights into their operational performance, enabling
informed decision making to reduce or mitigate the risk of non-compliance.
Thus, we propose two predictive compliance monitoring approaches to close this
research gap. The first approach reformulates the binary classification problem
as a hybrid task that considers both classification and regression, while the
second employs a multi-task learning method to explicitly predict the
compliance status and the magnitude of violation for deviant cases
simultaneously. In this work, we focus on temporal constraints as they are
significant in almost any application domain, e.g., health care. The evaluation
on synthetic and real-world event logs demonstrates that our approaches are
capable of quantifying the magnitude of violations while maintaining comparable
performance for compliance predictions achieved by state-of-the-art approaches.

摘要：現有的流程合規監控方法大多會在事後偵測到合規違規。只有謂詞預測專注於預測這些違規。然而，謂詞預測提供的是合規與否的二元概念，無法衡量正在進行的流程實例偏離約束中所指定之理想狀態的程度。在此，能夠量化違規的嚴重程度，將能讓組織深入了解其營運績效，並能據此做出明智的決策，以降低或減輕不合規的風險。因此，我們提出兩種預測合規監控方法來填補此研究空白。第一種方法將二元分類問題重新表述為同時考量分類和回歸的混合任務，而第二種方法則採用多任務學習方法，同時明確預測合規狀態和偏差案例的違規嚴重程度。在這項工作中，我們專注於時間約束，因為它們幾乎在任何應用領域（例如醫療保健）中都很重要。在合成和真實世界事件記錄上的評估顯示，我們的做法能夠量化違規的嚴重程度，同時維持與現有方法所達成的合規預測相當的績效。

##### **Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings**
2502.01108v1 by Mithun Saha, Maxwell A. Xu, Wanting Mao, Sameer Neupane, James M. Rehg, Santosh Kumar

Photoplethysmography (PPG)-based foundation models are gaining traction due
to the widespread use of PPG in biosignal monitoring and their potential to
generalize across diverse health applications. In this paper, we introduce
Pulse-PPG, the first open-source PPG foundation model trained exclusively on
raw PPG data collected over a 100-day field study with 120 participants.
Existing PPG foundation models are either open-source but trained on clinical
data or closed-source, limiting their applicability in real-world settings. We
evaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its
performance against a state-of-the-art foundation model trained on clinical
data. Our results demonstrate that Pulse-PPG, trained on uncurated field data,
exhibits superior generalization across clinical and mobile health applications
in both lab and field settings. This suggests that exposure to real-world
variability enables the model to learn fine-grained representations, making it
more adaptable across tasks. Furthermore, pre-training on field data
surprisingly outperforms its pre-training on clinical data in many tasks,
reinforcing the importance of training on real-world, diverse datasets. To
encourage further advancements in robust foundation models leveraging field
data, we plan to release Pulse-PPG, providing researchers with a powerful
resource for developing more generalizable PPG-based models.

摘要：基於光電容積描記術 (PPG) 的基礎模型由於 PPG 在生物訊號監控中的廣泛使用及其在各種健康應用中推廣的潛力而備受關注。在本文中，我們介紹 Pulse-PPG，這是第一個開放原始碼 PPG 基礎模型，專門針對在為期 100 天的現場研究中收集的 120 位參與者的原始 PPG 資料進行訓練。現有的 PPG 基礎模型要不是開放原始碼，但訓練於臨床資料，不然就是閉源，這限制了它們在真實世界中的應用性。我們評估了 Pulse-PPG 在多個資料集和下游任務中的表現，並將其效能與訓練於臨床資料的最新基礎模型進行比較。我們的結果表明，訓練於未整理現場資料的 Pulse-PPG 在實驗室和現場環境中，在臨床和行動健康應用中展現出優異的泛化能力。這表明接觸真實世界的變異性使模型能夠學習細粒度的表示，使其更能適應各種任務。此外，令人驚訝的是，現場資料的預訓練在許多任務中優於臨床資料的預訓練，這強化了在真實世界、多樣化的資料集上訓練的重要性。為了鼓勵在利用現場資料的強健基礎模型方面進一步發展，我們計畫發布 Pulse-PPG，為研究人員提供一個強大的資源，用於開發更具泛化性的基於 PPG 的模型。

##### **Tutorial on Using Machine Learning and Deep Learning Models for Mental Illness Detection**
2502.04342v1 by Yeyubei Zhang, Zhongyan Wang, Zhanyi Ding, Yexin Tian, Jianglai Dai, Xiaorui Shen, Yunchong Liu, Yuchen Cao

Social media has become an important source for understanding mental health,
providing researchers with a way to detect conditions like depression from
user-generated posts. This tutorial provides practical guidance to address
common challenges in applying machine learning and deep learning methods for
mental health detection on these platforms. It focuses on strategies for
working with diverse datasets, improving text preprocessing, and addressing
issues such as imbalanced data and model evaluation. Real-world examples and
step-by-step instructions demonstrate how to apply these techniques
effectively, with an emphasis on transparency, reproducibility, and ethical
considerations. By sharing these approaches, this tutorial aims to help
researchers build more reliable and widely applicable models for mental health
research, contributing to better tools for early detection and intervention.

摘要：社群媒體已成為了解心理健康的重要來源，
為研究人員提供一種方式，從使用者發布的貼文中偵測憂鬱症等狀況。
本教學提供實務指南，說明如何處理在這些平台上使用機器學習和深度學習方法進行心理健康偵測時常見的挑戰。
它專注於處理不同資料集、改善文字前處理，以及處理不平衡資料和模型評估等問題的策略。
實際範例和逐步說明示範如何有效應用這些技術，並強調透明度、可複製性，以及倫理考量。
透過分享這些方法，本教學指南旨在協助研究人員建構更可靠且廣泛適用的心理健康研究模型，
進而有助於早期偵測和介入的工具。

##### **Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model**
2502.01691v1 by Hadas Ben-Atya, Naama Gavrielov, Zvi Badash, Gili Focht, Ruth Cytter-Kuint, Talar Hagopian, Dan Turner, Moti Freiman

Reliable extraction of structured data from radiology reports using Large
Language Models (LLMs) remains challenging, especially for complex, non-English
texts like Hebrew. This study introduces an agent-based uncertainty-aware
approach to improve the trustworthiness of LLM predictions in medical
applications. We analyzed 9,683 Hebrew radiology reports from Crohn's disease
patients (from 2010 to 2023) across three medical centers. A subset of 512
reports was manually annotated for six gastrointestinal organs and 15
pathological findings, while the remaining reports were automatically annotated
using HSMP-BERT. Structured data extraction was performed using Llama 3.1
(Llama 3-8b-instruct) with Bayesian Prompt Ensembles (BayesPE), which employed
six semantically equivalent prompts to estimate uncertainty. An Agent-Based
Decision Model integrated multiple prompt outputs into five confidence levels
for calibrated uncertainty and was compared against three entropy-based models.
Performance was evaluated using accuracy, F1 score, precision, recall, and
Cohen's Kappa before and after filtering high-uncertainty cases. The
agent-based model outperformed the baseline across all metrics, achieving an F1
score of 0.3967, recall of 0.6437, and Cohen's Kappa of 0.3006. After filtering
high-uncertainty cases (greater than or equal to 0.5), the F1 score improved to
0.4787, and Kappa increased to 0.4258. Uncertainty histograms demonstrated
clear separation between correct and incorrect predictions, with the
agent-based model providing the most well-calibrated uncertainty estimates. By
incorporating uncertainty-aware prompt ensembles and an agent-based decision
model, this approach enhances the performance and reliability of LLMs in
structured data extraction from radiology reports, offering a more
interpretable and trustworthy solution for high-stakes medical applications.

摘要：<paragraph>使用大型語言模型 (LLM) 從放射科報告中可靠地提取結構化數據仍然具有挑戰性，尤其是對於希伯來語等複雜的非英語文本。本研究引入了一種基於代理的不確定性感知方法，以提高 LLM 預測在醫療應用中的可信度。我們分析了來自三個醫療中心的 9,683 份克隆氏症患者的希伯來語放射科報告（從 2010 年到 2023 年）。其中 512 份報告的手動註釋包括六個胃腸器官和 15 個病理發現，而其餘報告則使用 HSMP-BERT 自動註釋。結構化數據提取使用 Llama 3.1（Llama 3-8b-instruct）與貝葉斯提示集合（BayesPE）進行，它採用六個語義等效提示來估計不確定性。基於代理的決策模型將多個提示輸出整合到五個置信度級別中以校準不確定性，並與三個基於熵的模型進行比較。在過濾掉高度不確定性的情況之前和之後，使用準確度、F1 分數、精確度、召回率和 Cohen's Kappa 評估性能。基於代理的模型在所有指標上都優於基線，F1 分數達到 0.3967，召回率達到 0.6437，Cohen's Kappa 達到 0.3006。在過濾掉高度不確定性的情況（大於或等於 0.5）後，F1 分數提高到 0.4787，Kappa 提高到 0.4258。不確定性直方圖顯示了正確預測和不正確預測之間的明顯區別，基於代理的模型提供了校準最好的不確定性估計。通過結合不確定性感知提示集合和基於代理的決策模型，這種方法增強了 LLM 在放射科報告中結構化數據提取中的性能和可靠性，為高風險醫療應用提供了更具可解釋性和可信度的解決方案。</paragraph>

##### **Automated Extraction of Spatio-Semantic Graphs for Identifying Cognitive Impairment**
2502.01685v1 by Si-Ioi Ng, Pranav S. Ambadi, Kimberly D. Mueller, Julie Liss, Visar Berisha

Existing methods for analyzing linguistic content from picture descriptions
for assessment of cognitive-linguistic impairment often overlook the
participant's visual narrative path, which typically requires eye tracking to
assess. Spatio-semantic graphs are a useful tool for analyzing this narrative
path from transcripts alone, however they are limited by the need for manual
tagging of content information units (CIUs). In this paper, we propose an
automated approach for estimation of spatio-semantic graphs (via automated
extraction of CIUs) from the Cookie Theft picture commonly used in
cognitive-linguistic analyses. The method enables the automatic
characterization of the visual semantic path during picture description.
Experiments demonstrate that the automatic spatio-semantic graphs effectively
differentiate between cognitively impaired and unimpaired speakers. Statistical
analyses reveal that the features derived by the automated method produce
comparable results to the manual method, with even greater group differences
between clinical groups of interest. These results highlight the potential of
the automated approach for extracting spatio-semantic features in developing
clinical speech models for cognitive impairment assessment.

摘要：現有的用於分析圖像描述中的語言內容的方法，用於評估認知語言障礙，通常會忽略參與者的視覺敘事路徑，這通常需要眼球追蹤來評估。時空語義圖是一種有用的工具，可以僅從轉錄本中分析此敘事路徑，但是它們受到手動標記內容資訊單元 (CIU) 的需求所限制。在本文中，我們提出了一種自動化方法，用於從認知語言分析中常用的 Cookie Theft 圖像估計時空語義圖（通過自動提取 CIU）。該方法能夠自動表徵圖片描述期間的視覺語義路徑。實驗表明，自動時空語義圖有效地區分了認知受損和未受損的說話者。統計分析表明，自動化方法衍生的特徵產生了與手動方法相當的結果，甚至在感興趣的臨床組之間產生了更大的組差異。這些結果突出了自動化方法在提取時空語義特徵以開發用於認知障礙評估的臨床語音模型方面的潛力。

##### **Registration-Enhanced Segmentation Method for Prostate Cancer in Ultrasound Images**
2502.00712v1 by Shengtian Sang, Hassan Jahanandish, Cynthia Xinran Li, Indrani Bhattachary, Jeong Hoon Lee, Lichun Zhang, Sulaiman Vesal, Pejman Ghanouni, Richard Fan, Geoffrey A. Sonn, Mirabela Rusu

Prostate cancer is a major cause of cancer-related deaths in men, where early
detection greatly improves survival rates. Although MRI-TRUS fusion biopsy
offers superior accuracy by combining MRI's detailed visualization with TRUS's
real-time guidance, it is a complex and time-intensive procedure that relies
heavily on manual annotations, leading to potential errors. To address these
challenges, we propose a fully automatic MRI-TRUS fusion-based segmentation
method that identifies prostate tumors directly in TRUS images without
requiring manual annotations. Unlike traditional multimodal fusion approaches
that rely on naive data concatenation, our method integrates a
registration-segmentation framework to align and leverage spatial information
between MRI and TRUS modalities. This alignment enhances segmentation accuracy
and reduces reliance on manual effort. Our approach was validated on a dataset
of 1,747 patients from Stanford Hospital, achieving an average Dice coefficient
of 0.212, outperforming TRUS-only (0.117) and naive MRI-TRUS fusion (0.132)
methods, with significant improvements (p $<$ 0.01). This framework
demonstrates the potential for reducing the complexity of prostate cancer
diagnosis and provides a flexible architecture applicable to other multimodal
medical imaging tasks.

摘要：前列腺癌是男性癌症相關死亡的主要原因，早期發現可大幅提升存活率。儘管 MRI-TRUS 融合切片檢查結合了 MRI 的詳細視覺化與 TRUS 的即時導引，可提供更高的準確度，但它是一種仰賴大量手動註解的複雜且耗時的程序，容易導致錯誤。為了解決這些挑戰，我們提出了一種全自動的 MRI-TRUS 融合式分割方法，它可以在 TRUS 影像中直接辨識出前列腺腫瘤，而不需要手動註解。與依賴於天真資料串接的傳統多模態融合方法不同，我們的方法整合了一個配準分割架構，以對齊並利用 MRI 與 TRUS 模態之間的空間資訊。這種對齊提升了分割準確度，並減少了對手動作業的依賴。我們的方法已通過來自 Stanford 醫院的 1,747 位患者的資料集進行驗證，達到了 0.212 的平均 Dice 係數，優於僅使用 TRUS (0.117) 和天真的 MRI-TRUS 融合 (0.132) 方法，並有顯著的改善（p < 0.01）。這個架構證明了降低前列腺癌診斷複雜性的潛力，並提供了一個適用於其他多模態醫學影像任務的彈性架構。

##### **TMI-CLNet: Triple-Modal Interaction Network for Chronic Liver Disease Prognosis From Imaging, Clinical, and Radiomic Data Fusion**
2502.00695v1 by Linglong Wu, Xuhao Shan, Ruiquan Ge, Ruoyu Liang, Chi Zhang, Yonghong Li, Ahmed Elazab, Huoling Luo, Yunbi Liu, Changmiao Wang

Chronic liver disease represents a significant health challenge worldwide and
accurate prognostic evaluations are essential for personalized treatment plans.
Recent evidence suggests that integrating multimodal data, such as computed
tomography imaging, radiomic features, and clinical information, can provide
more comprehensive prognostic information. However, modalities have an inherent
heterogeneity, and incorporating additional modalities may exacerbate the
challenges of heterogeneous data fusion. Moreover, existing multimodal fusion
methods often struggle to adapt to richer medical modalities, making it
difficult to capture inter-modal relationships. To overcome these limitations,
We present the Triple-Modal Interaction Chronic Liver Network (TMI-CLNet).
Specifically, we develop an Intra-Modality Aggregation module and a
Triple-Modal Cross-Attention Fusion module, which are designed to eliminate
intra-modality redundancy and extract cross-modal information, respectively.
Furthermore, we design a Triple-Modal Feature Fusion loss function to align
feature representations across modalities. Extensive experiments on the liver
prognosis dataset demonstrate that our approach significantly outperforms
existing state-of-the-art unimodal models and other multi-modal techniques. Our
code is available at https://github.com/Mysterwll/liver.git.

摘要：慢性肝病在全球范围内代表著重大的健康挑戰，而準確的預後評估對於個人化治療計畫至關重要。最近的證據表明，整合多模態資料（例如電腦斷層影像、放射特徵和臨床資訊）可以提供更全面的預後資訊。然而，模態具有內在異質性，而納入額外的模態可能會加劇異質化資料融合的挑戰。此外，現有的多模態融合方法通常難以適應更豐富的醫療模態，這使得難以捕捉模態間的關係。為了克服這些限制，我們提出了三模態交互慢性肝臟網路 (TMI-CLNet)。具體來說，我們開發了一個模態內聚合模組和一個三模態交叉注意力融合模組，它們分別旨在消除模態內冗餘和提取跨模態資訊。此外，我們設計了一個三模態特徵融合損失函數，以對齊跨模態的特徵表示。在肝臟預後資料集上的廣泛實驗表明，我們的做法顯著優於現有的最先進單模態模型和其他多模態技術。我們的程式碼可以在 https://github.com/Mysterwll/liver.git 上取得。

##### **Enhanced Convolutional Neural Networks for Improved Image Classification**
2502.00663v1 by Xiaoran Yang, Shuhan Yu, Wenxi Xu

Image classification is a fundamental task in computer vision with diverse
applications, ranging from autonomous systems to medical imaging. The CIFAR-10
dataset is a widely used benchmark to evaluate the performance of
classification models on small-scale, multi-class datasets. Convolutional
Neural Networks (CNNs) have demonstrated state-of-the-art results; however,
they often suffer from overfitting and suboptimal feature representation when
applied to challenging datasets like CIFAR-10. In this paper, we propose an
enhanced CNN architecture that integrates deeper convolutional blocks, batch
normalization, and dropout regularization to achieve superior performance. The
proposed model achieves a test accuracy of 84.95%, outperforming baseline CNN
architectures. Through detailed ablation studies, we demonstrate the
effectiveness of the enhancements and analyze the hierarchical feature
representations. This work highlights the potential of refined CNN
architectures for tackling small-scale image classification problems
effectively.

摘要：影像分類是電腦視覺中的一項基本任務，應用範圍廣泛，從自動系統到醫學影像皆有。CIFAR-10 資料集是一個廣泛使用的基準，用於評估分類模型在小規模、多類別資料集上的效能。卷積神經網路 (CNN) 已展現出最先進的成果；然而，當應用於 CIFAR-10 等具挑戰性的資料集時，它們常常會發生過度擬合和次佳特徵表示的問題。在本文中，我們提出一個增強的 CNN 架構，它整合了更深的卷積區塊、批次正規化和中斷正規化，以達成卓越的效能。所提出的模型達到了 84.95% 的測試準確度，優於基準 CNN 架構。透過詳細的消融研究，我們證明了這些增強功能的有效性，並分析了階層式特徵表示。這項工作突顯了精進的 CNN 架構在有效解決小規模影像分類問題上的潛力。

##### **Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective**
2502.00619v1 by Yujin Oh, Pengfei Jin, Sangjoon Park, Sekeun Kim, Siyeop Yoon, Kyungsang Kim, Jin Sung Kim, Xiang Li, Quanzheng Li

Ensuring fairness in medical image segmentation is critical due to biases in
imbalanced clinical data acquisition caused by demographic attributes (e.g.,
age, sex, race) and clinical factors (e.g., disease severity). To address these
challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired
by optimal control theory. We provide a comprehensive analysis of its
underlying mechanisms and clarify dMoE's role in adapting to heterogeneous
distributions in medical image segmentation. Furthermore, we integrate dMoE
into multiple network architectures, demonstrating its broad applicability
across diverse medical image analysis tasks. By incorporating demographic and
clinical factors, dMoE achieves state-of-the-art performance on two 2D
benchmark datasets and a 3D in-house dataset. Our results highlight the
effectiveness of dMoE in mitigating biases from imbalanced distributions,
offering a promising approach to bridging control theory and medical image
segmentation within fairness learning paradigms. The source code will be made
available.

摘要：在医学影像分割中，由於人口屬性（例如年齡、性別、種族）和臨床因素（例如疾病嚴重程度）導致不平衡的臨床數據採集中存在偏差，因此確保公平性至關重要。為了應對這些挑戰，我們引入了受最優控制理論啟發的感知混合專家 (dMoE)。我們對其底層機制進行了全面分析，並釐清了 dMoE 在適應醫學影像分割中的異質分佈中的作用。此外，我們將 dMoE 整合到多個網路架構中，展示了其在各種醫學影像分析任務中的廣泛適用性。通過納入人口統計和臨床因素，dMoE 在兩個 2D 基準數據集和一個 3D 內部數據集上實現了最先進的性能。我們的結果突出了 dMoE 在減輕不平衡分佈的偏差方面的有效性，為在公平性學習範例中橋接控制理論和醫學影像分割提供了一個有前景的方法。原始碼將會公開。

##### **Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions**
2502.00568v1 by Samiran Dey, Christopher R. S. Banerji, Partha Basuchowdhuri, Sanjoy K. Saha, Deepak Parashar, Tapabrata Chakraborti

Emerging research has highlighted that artificial intelligence based
multimodal fusion of digital pathology and transcriptomic features can improve
cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.
However, such direct fusion for joint decision is impractical in real clinical
settings, where histopathology is still the gold standard for diagnosis and
transcriptomic tests are rarely requested, at least in the public healthcare
system. With our novel diffusion based crossmodal generative AI model PathoGen,
we show that genomic expressions synthesized from digital histopathology
jointly predicts cancer grading and patient survival risk with high accuracy
(state-of-the-art performance), certainty (through conformal coverage
guarantee) and interpretability (through distributed attention maps). PathoGen
code is available for open use by the research community through GitHub at
https://github.com/Samiran-Dey/PathoGen.

摘要：新興研究強調，基於人工智慧的多模態融合數位病理學和轉錄組特徵，可以改善癌症診斷（分級/分型）和預後（存活風險）預測。
然而，這種直接融合對於聯合決策在實際臨床環境中是不切實際的，因為在實際臨床環境中，組織病理學仍然是診斷的黃金標準，而轉錄組檢測很少被要求，至少在公共醫療系統中是如此。透過我們新穎的基於擴散的跨模態生成式 AI 模型 PathoGen，我們展示了從數位組織病理學合成的基因體表達，可以共同預測癌症分級和患者存活風險，具有高準確度（最先進的效能）、確定性（透過保形覆蓋保證）和可解釋性（透過分佈式注意力圖）。PathoGen 程式碼可透過 GitHub 上的 https://github.com/Samiran-Dey/PathoGen，開放供研究社群使用。

##### **Looking into the Future of Health-Care Services: Can Life-Like Agents Change the Future of Health-Care Services?**
2502.00495v1 by Mohammad Saleh Torkestani, Robert Davis, Abdolhossein Sarrafzadeh

Time constraints on doctor patient interaction and restricted access to
specialists under the managed care system led to increasingly referring to
computers as a medical information source and a self-health-care management
tool. However, research show that less than 40% of information seekers
indicated that online information helped them to make a decision about their
health. Searching multiple web sites that need basic computer skills, lack of
interaction and no face to face interaction in most search engines and some
social issues, led us to develop a specialized life-like agent that would
overcome mentioned problems.

摘要：由於管理式醫療保健系統中醫師與病患互動時間有限，且專科醫師的取得受限，因此越來越多人將電腦視為醫療資訊來源和自我保健管理工具。然而，研究顯示，不到 40% 的資訊尋求者表示，線上資訊有助於他們做出健康決策。搜尋需要基本電腦技能的許多網站、缺乏互動，以及大多數搜尋引擎和一些社交議題中沒有面對面的互動，這些原因促使我們開發出一個特殊且逼真的代理人，以克服上述問題。

##### **Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities**
2502.00451v1 by Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych

Mental illness is a widespread and debilitating condition with substantial
societal and personal costs. Traditional diagnostic and treatment approaches,
such as self-reported questionnaires and psychotherapy sessions, often impose
significant burdens on both patients and clinicians, limiting accessibility and
efficiency. Recent advances in Artificial Intelligence (AI), particularly in
Natural Language Processing and multimodal techniques, hold great potential for
recognizing and addressing conditions such as depression, anxiety, bipolar
disorder, schizophrenia, and post-traumatic stress disorder. However, privacy
concerns, including the risk of sensitive data leakage from datasets and
trained models, remain a critical barrier to deploying these AI systems in
real-world clinical settings. These challenges are amplified in multimodal
methods, where personal identifiers such as voice and facial data can be
misused. This paper presents a critical and comprehensive study of the privacy
challenges associated with developing and deploying AI models for mental
health. We further prescribe potential solutions, including data anonymization,
synthetic data generation, and privacy-preserving model training, to strengthen
privacy safeguards in practical applications. Additionally, we discuss
evaluation frameworks to assess the privacy-utility trade-offs in these
approaches. By addressing these challenges, our work aims to advance the
development of reliable, privacy-aware AI tools to support clinical
decision-making and improve mental health outcomes.

摘要：精神疾病是一種廣泛且會使人衰弱的疾病，會造成重大的社會和個人成本。傳統的診斷與治療方法，例如自我報告問卷和心理治療療程，通常會對患者和臨床醫生造成重大負擔，限制了可及性和效率。人工智慧 (AI) 的最新進展，特別是在自然語言處理和多模式技術方面，在辨識和處理憂鬱症、焦慮症、躁鬱症、精神分裂症和創傷後壓力症候群等疾病方面具有極大的潛力。然而，隱私問題，包括資料集和訓練模型中敏感資料外洩的風險，仍然是這些 AI 系統在真實臨床環境中部署的一項關鍵障礙。這些挑戰在多模式方法中會被放大，因為語音和面部資料等個人識別資料可能會被濫用。本文對與開發和部署用於心理健康的 AI 模型相關的隱私挑戰進行了一項批判且全面的研究。我們進一步提出了潛在的解決方案，包括資料匿名化、合成資料產生和隱私保護模型訓練，以加強實際應用中的隱私保障。此外，我們討論了評估這些方法中隱私與效用取捨的評估架構。透過解決這些挑戰，我們的研究旨在推進可靠、重視隱私的 AI 工具的開發，以支持臨床決策制定並改善心理健康成果。

##### **EcoWeedNet: A Lightweight and Automated Weed Detection Method for Sustainable Next-Generation Agricultural Consumer Electronics**
2502.00205v1 by Omar H. Khater, Abdul Jabbar Siddiqui, M. Shamim Hossain

Sustainable agriculture plays a crucial role in ensuring world food security
for consumers. A critical challenge faced by sustainable precision agriculture
is weed growth, as weeds share essential resources with the crops, such as
water, soil nutrients, and sunlight, which notably affect crop yields. The
traditional methods employed to combat weeds include the usage of chemical
herbicides and manual weed removal methods. However, these could damage the
environment and pose health hazards. The adoption of automated computer vision
technologies and ground agricultural consumer electronic vehicles in precision
agriculture offers sustainable, low-carbon solutions. However, prior works
suffer from issues such as low accuracy and precision and high computational
expense. This work proposes EcoWeedNet, a novel model with enhanced weed
detection performance without adding significant computational complexity,
aligning with the goals of low-carbon agricultural practices. Additionally, our
model is lightweight and optimal for deployment on ground-based consumer
electronic agricultural vehicles and robots. The effectiveness of the proposed
model is demonstrated through comprehensive experiments on the CottonWeedDet12
benchmark dataset reflecting real-world scenarios. EcoWeedNet achieves
performance close to that of large models yet with much fewer parameters.
(approximately 4.21% of the parameters and 6.59% of the GFLOPs of YOLOv4). This
work contributes effectively to the development of automated weed detection
methods for next-generation agricultural consumer electronics featuring lower
energy consumption and lower carbon footprint. This work paves the way forward
for sustainable agricultural consumer technologies.

摘要：永續農業在確保世界糧食安全方面扮演著至關重要的角色
對於永續精準農業來說，雜草的生長是一個重大的挑戰，因為雜草與農作物共享水、土壤養分和陽光等基本資源，這會顯著影響農作物的產量。傳統上用於對抗雜草的方法包括使用化學除草劑和人工除草方法。然而，這些方法可能會損害環境並造成健康危害。在精準農業中採用自動化電腦視覺技術和地面農業用消費電子車輛提供了永續的低碳解決方案。然而，先前的研究存在準確度和精確度低以及計算成本高等問題。這項研究提出了 EcoWeedNet，這是一個新的模型，具有增強的雜草偵測效能，而不會增加顯著的計算複雜度，符合低碳農業實務的目標。此外，我們的模型輕巧，最適於部署在地面消費電子農業車輛和機器人上。所提出的模型的有效性已通過在反映真實世界場景的 CottonWeedDet12 基準資料集上進行的全面實驗得到證明。EcoWeedNet 的效能接近大型模型，但參數卻少得多。(大約是 YOLOv4 參數的 4.21% 和 GFLOP 的 6.59%)。這項研究有效地促進了下一代農業消費電子產品的自動化雜草偵測方法的開發，這些產品的特點是能耗更低、碳足跡更低。這項研究為永續農業消費技術鋪平了道路。

##### **DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access Dermatology Datasets**
2502.00196v1 by Abdurrahim Yilmaz, Furkan Yuceyalcin, Ece Gokyayla, Donghee Choi, Ozan Erdem Ali Anil Demircali, Rahmetullah Varol, Ufuk Gorkem Kirabali, Gulsum Gencoglan, Joram M. Posma, Burak Temelkuran

A major barrier to developing vision large language models (LLMs) in
dermatology is the lack of large image--text pairs dataset. We introduce
DermaSynth, a dataset comprising of 92,020 synthetic image--text pairs curated
from 45,205 images (13,568 clinical and 35,561 dermatoscopic) for
dermatology-related clinical tasks. Leveraging state-of-the-art LLMs, using
Gemini 2.0, we used clinically related prompts and self-instruct method to
generate diverse and rich synthetic texts. Metadata of the datasets were
incorporated into the input prompts by targeting to reduce potential
hallucinations. The resulting dataset builds upon open access dermatological
image repositories (DERM12345, BCN20000, PAD-UFES-20, SCIN, and HIBA) that have
permissive CC-BY-4.0 licenses. We also fine-tuned a preliminary
Llama-3.2-11B-Vision-Instruct model, DermatoLlama 1.0, on 5,000 samples. We
anticipate this dataset to support and accelerate AI research in dermatology.
Data and code underlying this work are accessible at
https://github.com/abdurrahimyilmaz/DermaSynth.

摘要：大型語言模型（LLM）在皮膚科發展的一大障礙是缺乏大量的影像文字對應資料集。我們引進 DermaSynth，這是一個由 92,020 個合成影像文字對應資料組成的資料集，這些資料對應資料是從 45,205 個影像（13,568 個臨床影像和 35,561 個皮膚鏡影像）中策劃而來的，用於皮膚科相關的臨床任務。利用最先進的 LLM，使用 Gemini 2.0，我們使用與臨床相關的提示和自我指導方法來產生多樣且豐富的合成文字。資料集的元資料會納入輸入提示中，目標是減少潛在的幻覺。產生的資料集建立在開放取用的皮膚科影像儲存庫（DERM12345、BCN20000、PAD-UFES-20、SCIN 和 HIBA）之上，這些儲存庫擁有寬鬆的 CC-BY-4.0 licenses。我們還對一個初步的 Llama-3.2-11B-Vision-Instruct 模型，DermatoLlama 1.0，在 5,000 個樣本上進行微調。我們預計這個資料集將支援和加速皮膚科的 AI 研究。這項工作的資料和程式碼可在 https://github.com/abdurrahimyilmaz/DermaSynth 取得。

##### **Multimodal MRI-Ultrasound AI for Prostate Cancer Detection Outperforms Radiologist MRI Interpretation: A Multi-Center Study**
2502.00146v1 by Hassan Jahanandish, Shengtian Sang, Cynthia Xinran Li, Sulaiman Vesal, Indrani Bhattacharya, Jeong Hoon Lee, Richard Fan, Geoffrey A. Sonna, Mirabela Rusu

Pre-biopsy magnetic resonance imaging (MRI) is increasingly used to target
suspicious prostate lesions. This has led to artificial intelligence (AI)
applications improving MRI-based detection of clinically significant prostate
cancer (CsPCa). However, MRI-detected lesions must still be mapped to
transrectal ultrasound (TRUS) images during biopsy, which results in missing
CsPCa. This study systematically evaluates a multimodal AI framework
integrating MRI and TRUS image sequences to enhance CsPCa identification. The
study included 3110 patients from three cohorts across two institutions who
underwent prostate biopsy. The proposed framework, based on the 3D UNet
architecture, was evaluated on 1700 test cases, comparing performance to
unimodal AI models that use either MRI or TRUS alone. Additionally, the
proposed model was compared to radiologists in a cohort of 110 patients. The
multimodal AI approach achieved superior sensitivity (80%) and Lesion Dice
(42%) compared to unimodal MRI (73%, 30%) and TRUS models (49%, 27%). Compared
to radiologists, the multimodal model showed higher specificity (88% vs. 78%)
and Lesion Dice (38% vs. 33%), with equivalent sensitivity (79%). Our findings
demonstrate the potential of multimodal AI to improve CsPCa lesion targeting
during biopsy and treatment planning, surpassing current unimodal models and
radiologists; ultimately improving outcomes for prostate cancer patients.

摘要：<paragraph>在活檢前，磁振造影（MRI）正越來越常被用於鎖定可疑的攝護腺病灶。這導致人工智慧（AI）應用程式改善了以 MRI 為基礎的臨床顯著攝護腺癌（CsPCa）檢測。然而，在活檢期間，由 MRI 偵測到的病灶仍必須對應到經直腸超音波（TRUS）影像，這導致錯失 CsPCa。本研究系統性地評估了一個多模態 AI 架構，整合 MRI 和 TRUS 影像序列，以增強 CsPCa 識別。這項研究納入了來自兩家機構的三個群組中的 3110 名患者，他們接受了攝護腺活檢。所提出的架構基於 3D UNet 架構，在 1700 個測試案例中進行評估，並將其效能與僅使用 MRI 或 TRUS 的單模態 AI 模型進行比較。此外，所提出的模型與一個由 110 名患者組成的群組中的放射科醫師進行比較。與單模態 MRI（73%、30%）和 TRUS 模型（49%、27%）相比，多模態 AI 方法達到了更高的敏感度（80%）和病灶 Dice（42%）。與放射科醫師相比，多模態模型顯示出更高的特異性（88% 對 78%）和病灶 Dice（38% 對 33%），且敏感度相當（79%）。我們的研究結果證明了多模態 AI 在活檢和治療計畫期間改善 CsPCa 病灶鎖定的潛力，超越了目前的單模態模型和放射科醫師；最終改善了攝護腺癌患者的治療成果。</paragraph>

##### **AIN: The Arabic INclusive Large Multimodal Model**
2502.00094v2 by Ahmed Heakl, Sara Ghaboura, Omkar Thawkar, Fahad Shahbaz Khan, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan

Amid the swift progress of large language models (LLMs) and their evolution
into large multimodal models (LMMs), significant strides have been made in
high-resource languages such as English and Chinese. While Arabic LLMs have
seen notable progress, Arabic LMMs remain largely unexplored, often narrowly
focusing on a few specific aspects of the language and visual understanding. To
bridge this gap, we introduce AIN-the Arabic Inclusive Multimodal
Model-designed to excel across diverse domains. AIN is an English-Arabic
bilingual LMM designed to excel in English and Arabic, leveraging carefully
constructed 3.6 million high-quality Arabic-English multimodal data samples.
AIN demonstrates state-of-the-art Arabic performance, while also possessing
strong English-language visual capabilities. On the recent CAMEL-Bench
benchmark comprising 38 sub-domains including, multi-image understanding,
complex visual perception, handwritten document understanding, video
understanding, medical imaging, plant diseases, and remote sensing-based land
use understanding, our AIN demonstrates strong performance with the 7B model
outperforming GPT-4o by an absolute gain of 3.4% averaged over eight domains
and 38 sub-domains. AIN's superior capabilities position it as a significant
step toward empowering Arabic speakers with advanced multimodal generative AI
tools across diverse applications.

摘要：在大型語言模型 (LLM) 快速發展，並演變成大型多模態模型 (LMM) 的過程中，英語和中文等高資源語言已取得重大進展。雖然阿拉伯語 LLM 已取得顯著進展，但阿拉伯語 LMM 仍未被廣泛探索，通常只狹隘地關注語言和視覺理解的幾個特定方面。為了彌合這項差距，我們推出了 AIN，即阿拉伯語包容性多模態模型，旨在在不同領域中表現出色。AIN 是一個英語-阿拉伯語雙語 LMM，旨在精通英語和阿拉伯語，利用精心建構的 360 萬個高品質阿拉伯語-英語多模態數據樣本。AIN 展示了最先進的阿拉伯語效能，同時也具備強大的英語視覺能力。在最近的 CAMEL-Bench 基準測試中，包含 38 個子領域，包括多影像理解、複雜視覺感知、手寫文件理解、影片理解、醫學影像、植物疾病和基於遙測的土地使用理解，我們的 AIN 表現出色，其中 7B 模型在八個領域和 38 個子領域的平均絕對增益為 3.4%，優於 GPT-4o。AIN 的卓越能力使其成為朝著賦予阿拉伯語使用者進階多模態生成式 AI 工具邁出的重要一步，可用於各種應用。

##### **Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**
2501.19338v1 by Misha P. T Kaandorp, Damola Agbelese, Hosna Asma-ull, Hyun-Gi Kim, Kelly Payette, Patrice Grehten, Gennari Antonio Giulio, Levente István Lánczi, Andras Jakab

Developing new methods for the automated analysis of clinical fetal and
neonatal MRI data is limited by the scarcity of annotated pathological datasets
and privacy concerns that often restrict data sharing, hindering the
effectiveness of deep learning models. We address this in two ways. First, we
introduce Fetal&Neonatal-DDPM, a novel diffusion model framework designed to
generate high-quality synthetic pathological fetal and neonatal MRIs from
semantic label images. Second, we enhance training data by modifying healthy
label images through morphological alterations to simulate conditions such as
ventriculomegaly, cerebellar and pontocerebellar hypoplasia, and microcephaly.
By leveraging Fetal&Neonatal-DDPM, we synthesize realistic pathological MRIs
from these modified pathological label images. Radiologists rated the synthetic
MRIs as significantly (p < 0.05) superior in quality and diagnostic value
compared to real MRIs, demonstrating features such as blood vessels and choroid
plexus, and improved alignment with label annotations. Synthetic pathological
data enhanced state-of-the-art nnUNet segmentation performance, particularly
for severe ventriculomegaly cases, with the greatest improvements achieved in
ventricle segmentation (Dice scores: 0.9253 vs. 0.7317). This study underscores
the potential of generative AI as transformative tool for data augmentation,
offering improved segmentation performance in pathological cases. This
development represents a significant step towards improving analysis and
segmentation accuracy in prenatal imaging, and also offers new ways for data
anonymization through the generation of pathologic image data.

摘要：<paragraph>開發用於自動分析臨床胎兒和新生兒 MRI 資料的新方法受到標註病理資料集稀少和隱私問題的限制，這些問題通常會限制資料共享，從而阻礙深度學習模型的有效性。我們以兩種方式解決這個問題。首先，我們引入了 Fetal&Neonatal-DDPM，這是一個新穎的擴散模型架構，旨在從語義標籤影像生成高品質的合成病理胎兒和新生兒 MRI。其次，我們透過形態改變來修改健康的標籤影像，以模擬腦室擴大、小腦和橋腦小腦發育不全以及小頭畸形等情況，從而增強訓練資料。透過利用 Fetal&Neonatal-DDPM，我們從這些修改後的病理標籤影像中合成了逼真的病理 MRI。放射科醫師評估合成 MRI 的品質和診斷價值顯著優於真實 MRI（p < 0.05），展示了血管和脈絡叢等特徵，並改善了與標籤註解的一致性。合成病理資料增強了最先進的 nnUNet 分割效能，特別是對於嚴重的腦室擴大病例，其中腦室分割（Dice 分數：0.9253 對 0.7317）的改善最大。這項研究強調了生成式 AI 作為資料擴充轉型工具的潛力，在病理病例中提供了改善的分割效能。這項發展代表了改善產前影像分析和分割準確性的重要一步，也為透過生成病理影像資料來進行資料匿名化提供了新方法。</paragraph>

##### **Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**
2501.19271v1 by Halil Ibrahim Aysel, Xiaohao Cai, Adam Prugel-Bennett

Concept-based explanation methods, such as concept bottleneck models (CBMs),
aim to improve the interpretability of machine learning models by linking their
decisions to human-understandable concepts, under the critical assumption that
such concepts can be accurately attributed to the network's feature space.
However, this foundational assumption has not been rigorously validated, mainly
because the field lacks standardised metrics and benchmarks to assess the
existence and spatial alignment of such concepts. To address this, we propose
three metrics: the concept global importance metric, the concept existence
metric, and the concept location metric, including a technique for visualising
concept activations, i.e., concept activation mapping. We benchmark post-hoc
CBMs to illustrate their capabilities and challenges. Through qualitative and
quantitative experiments, we demonstrate that, in many cases, even the most
important concepts determined by post-hoc CBMs are not present in input images;
moreover, when they are present, their saliency maps fail to align with the
expected regions by either activating across an entire object or misidentifying
relevant concept-specific regions. We analyse the root causes of these
limitations, such as the natural correlation of concepts. Our findings
underscore the need for more careful application of concept-based explanation
techniques especially in settings where spatial interpretability is critical.

摘要：基於概念的解釋方法，例如概念瓶頸模型 (CBM)，旨在透過將機器學習模型的決策與人類可理解的概念連結，來提升機器學習模型的可解釋性，其關鍵假設為此類概念可以準確地歸因於網路的特徵空間。然而，此項基礎假設尚未經過嚴格驗證，主要是因為該領域缺乏標準化指標和基準來評估此類概念的存在和空間對齊。為了解決這個問題，我們提出三項指標：概念整體重要性指標、概念存在指標和概念位置指標，包括一種用於視覺化概念活化，即概念活化對應的技術。我們對事後 CBM 進行基準測試，以說明它們的能力和挑戰。透過定性和定量實驗，我們證明，在許多情況下，即使是由事後 CBM 確定的最重要概念也不存在於輸入影像中；此外，當它們存在時，它們的顯著性圖無法與預期的區域對齊，原因可能是它們在整個物件中活化，或錯誤辨識出相關的概念特定區域。我們分析了這些限制的根本原因，例如概念的自然相關性。我們的研究結果強調需要更小心地應用基於概念的解釋技術，特別是在空間可解釋性至關重要的設定中。

##### **Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using Generative Artificial Intelligence**
2501.19176v1 by Aurora Rofena, Claudia Lucia Piccolo, Bruno Beomonte Zobel, Paolo Soda, Valerio Guarrasi

Full-Field Digital Mammography (FFDM) is the primary imaging modality for
routine breast cancer screening; however, its effectiveness is limited in
patients with dense breast tissue or fibrocystic conditions. Contrast-Enhanced
Spectral Mammography (CESM), a second-level imaging technique, offers enhanced
accuracy in tumor detection. Nonetheless, its application is restricted due to
higher radiation exposure, the use of contrast agents, and limited
accessibility. As a result, CESM is typically reserved for select cases,
leaving many patients to rely solely on FFDM despite the superior diagnostic
performance of CESM. While biopsy remains the gold standard for definitive
diagnosis, it is an invasive procedure that can cause discomfort for patients.
We introduce a multimodal, multi-view deep learning approach for virtual
biopsy, integrating FFDM and CESM modalities in craniocaudal and mediolateral
oblique views to classify lesions as malignant or benign. To address the
challenge of missing CESM data, we leverage generative artificial intelligence
to impute CESM images from FFDM scans. Experimental results demonstrate that
incorporating the CESM modality is crucial to enhance the performance of
virtual biopsy. When real CESM data is missing, synthetic CESM images proved
effective, outperforming the use of FFDM alone, particularly in multimodal
configurations that combine FFDM and CESM modalities. The proposed approach has
the potential to improve diagnostic workflows, providing clinicians with
augmented intelligence tools to improve diagnostic accuracy and patient care.
Additionally, as a contribution to the research community, we publicly release
the dataset used in our experiments, facilitating further advancements in this
field.

摘要：全視野數位乳房攝影 (FFDM) 是常規乳癌篩檢的主要影像模式；然而，對於乳房組織緻密或纖維囊腫病變的患者，其有效性受到限制。對比增強光譜乳房攝影 (CESM) 是一種二級影像技術，可提升腫瘤偵測的準確度。儘管如此，由於較高的輻射曝露、對比劑的使用和有限的可及性，限制了其應用。因此，CESM 通常僅保留在特定情況下使用，儘管 CESM 的診斷效能較佳，但許多患者仍只能依賴 FFDM。雖然切片檢查仍然是明確診斷的黃金標準，但這是一種侵入性程序，可能會讓患者感到不適。我們引入一種多模式、多視圖的深度學習方法進行虛擬切片檢查，將 FFDM 和 CESM 模式整合在頭尾向和內外側斜視圖中，以將病灶分類為惡性或良性。為了解決 CESM 資料缺失的挑戰，我們利用生成式人工智慧從 FFDM 掃描中推算 CESM 影像。實驗結果證明，整合 CESM 模式對於提升虛擬切片檢查的效能至關重要。當真實 CESM 資料缺失時，合成 CESM 影像被證明是有效的，其效能優於單獨使用 FFDM，特別是在結合 FFDM 和 CESM 模式的多模式配置中。所提出的方法有潛力改善診斷工作流程，為臨床醫師提供增強的智慧工具，以提高診斷準確度和患者照護。此外，作為對研究社群的貢獻，我們公開發布在實驗中使用的資料集，以促進此領域的進一步進展。

##### **Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**
2501.19086v1 by Xiangyu Sun, Xiaoguang Zou, Yuanquan Wu, Guotai Wang, Shaoting Zhang

X-ray imaging is pivotal in medical diagnostics, offering non-invasive
insights into a range of health conditions. Recently, vision-language models,
such as the Contrastive Language-Image Pretraining (CLIP) model, have
demonstrated potential in improving diagnostic accuracy by leveraging
large-scale image-text datasets. However, since CLIP was not initially designed
for medical images, several CLIP-like models trained specifically on medical
images have been developed. Despite their enhanced performance, issues of
fairness - particularly regarding demographic attributes - remain largely
unaddressed. In this study, we perform a comprehensive fairness analysis of
CLIP-like models applied to X-ray image classification. We assess their
performance and fairness across diverse patient demographics and disease
categories using zero-shot inference and various fine-tuning techniques,
including Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation
(LoRA), and full fine-tuning. Our results indicate that while fine-tuning
improves model accuracy, fairness concerns persist, highlighting the need for
further fairness interventions in these foundational models.

摘要：X 光影像在醫療診斷中至關重要，能提供各種健康狀況的非侵入性見解。最近，視覺語言模型（例如對比語言影像預訓練 (CLIP) 模型）已證明有潛力透過利用大規模影像文字資料集來改善診斷準確性。然而，由於 CLIP 最初並非設計用於醫療影像，因此已經開發了數個特別針對醫療影像訓練的類似 CLIP 模型。儘管它們的效能有所提升，但公平性的問題（特別是關於人口統計屬性）仍大多未獲解決。在本研究中，我們對應用於 X 光影像分類的類似 CLIP 模型執行全面的公平性分析。我們使用零次學習推論和各種微調技術（包括線性探查、多層感知器 (MLP)、低秩適應 (LoRA) 和完整微調）來評估它們在不同患者人口統計和疾病類別中的效能和公平性。我們的結果表明，雖然微調會改善模型準確性，但公平性問題仍然存在，強調需要在這些基礎模型中進一步採取公平性干預措施。

##### **Survey and Improvement Strategies for Gene Prioritization with Large Language Models**
2501.18794v1 by Matthew Neeley, Guantong Qi, Guanchu Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, Fan Xia, Pengfei Liu, Zhandong Liu, Xia Hu

Rare diseases are challenging to diagnose due to limited patient data and
genetic diversity. Despite advances in variant prioritization, many cases
remain undiagnosed. While large language models (LLMs) have performed well in
medical exams, their effectiveness in diagnosing rare genetic diseases has not
been assessed. To identify causal genes, we benchmarked various LLMs for gene
prioritization. Using multi-agent and Human Phenotype Ontology (HPO)
classification, we categorized patients based on phenotypes and solvability
levels. As gene set size increased, LLM performance deteriorated, so we used a
divide-and-conquer strategy to break the task into smaller subsets. At
baseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking
causal genes correctly. The multi-agent and HPO approaches helped distinguish
confidently solved cases from challenging ones, highlighting the importance of
known gene-phenotype associations and phenotype specificity. We found that
cases with specific phenotypes or clear associations were more accurately
solved. However, we observed biases toward well-studied genes and input order
sensitivity, which hindered gene prioritization. Our divide-and-conquer
strategy improved accuracy by overcoming these biases. By utilizing HPO
classification, novel multi-agent techniques, and our LLM strategy, we improved
causal gene identification accuracy compared to our baseline evaluation. This
approach streamlines rare disease diagnosis, facilitates reanalysis of unsolved
cases, and accelerates gene discovery, supporting the development of targeted
diagnostics and therapies.

摘要：罕見疾病由於患者數據有限和遺傳多樣性，診斷起來具有挑戰性。儘管變異優先級排序技術進步，但許多病例仍未得到診斷。儘管大型語言模型 (LLM) 在醫學考試中表現良好，但它們在診斷罕見遺傳疾病方面的有效性尚未得到評估。為了識別致病基因，我們對各種 LLM 進行了基因優先級排序基準測試。使用多智能體和人類表型本体 (HPO) 分類，我們根據表型和可解決性對患者進行了分類。隨著基因組大小的增加，LLM 性能下降，因此我們使用分而治之策略將任務分解為更小的子集。在基線中，GPT-4 優於其他 LLM，在正確排序致病基因方面達到近 30% 的準確度。多智能體和 HPO 方法有助於區分解決有信心的病例和具有挑戰性的病例，強調已知基因-表型關聯和表型特異性的重要性。我們發現具有特定表型或明確關聯的病例得到更準確的解決。然而，我們觀察到對研究充分的基因和輸入順序敏感性的偏差，這阻礙了基因優先級排序。我們的分而治之策略通過克服這些偏差來提高準確性。通過利用 HPO 分類、新穎的多智能體技術和我們的 LLM 策略，我們與我們的基線評估相比提高了致病基因識別準確性。這種方法簡化了罕見疾病的診斷，促進了對未解決病例的重新分析，並加速了基因發現，支持了靶向診斷和治療的開發。

##### **Synthetic Data Generation for Augmenting Small Samples**
2501.18741v1 by Dan Liu, Samer El Kababji, Nicholas Mitsakakis, Lisa Pilgram, Thomas Walters, Mark Clemons, Greg Pond, Alaa El-Hussuna, Khaled El Emam

Small datasets are common in health research. However, the generalization
performance of machine learning models is suboptimal when the training datasets
are small. To address this, data augmentation is one solution. Augmentation
increases sample size and is seen as a form of regularization that increases
the diversity of small datasets, leading them to perform better on unseen data.
We found that augmentation improves prognostic performance for datasets that:
have fewer observations, with smaller baseline AUC, have higher cardinality
categorical variables, and have more balanced outcome variables. No specific
generative model consistently outperformed the others. We developed a decision
support model that can be used to inform analysts if augmentation would be
useful. For seven small application datasets, augmenting the existing data
results in an increase in AUC between 4.31% (AUC from 0.71 to 0.75) and 43.23%
(AUC from 0.51 to 0.73), with an average 15.55% relative improvement,
demonstrating the nontrivial impact of augmentation on small datasets
(p=0.0078). Augmentation AUC was higher than resampling only AUC (p=0.016). The
diversity of augmented datasets was higher than the diversity of resampled
datasets (p=0.046).

摘要：在健康研究中，小型数据集很常见。然而，当训练数据集较小时，机器学习模型的泛化性能并不理想。为了解决这个问题，数据增强是一种解决方案。增强增加了样本量，并被视为一种正则化形式，它增加了小型数据集的多样性，从而使其在未见数据上表现得更好。我们发现，增强提高了以下数据集的预测性能：具有较少的观测值、较小的基线 AUC、较高的基数分类变量以及更平衡的结果变量。没有特定的生成模型始终优于其他模型。我们开发了一个决策支持模型，可用于告知分析师增强是否有用。对于七个小型应用程序数据集，增强现有数据导致 AUC 增加 4.31%（AUC 从 0.71 增加到 0.75）和 43.23%（AUC 从 0.51 增加到 0.73），平均相对改进 15.55%，这表明了增强对小型数据集的非平凡影响（p=0.0078）。增强 AUC 高于仅重新采样的 AUC（p=0.016）。增强数据集的多样性高于重新采样数据集的多样性（p=0.046）。

##### **A Multi-Layered Large Language Model Framework for Disease Prediction**
2502.00063v1 by Malak Mohamed, Rokaia Emad, Ali Hamdi

Social telehealth has revolutionized healthcare by enabling patients to share
symptoms and receive medical consultations remotely. Users frequently post
symptoms on social media and online health platforms, generating a vast
repository of medical data that can be leveraged for disease classification and
symptom severity assessment. Large language models (LLMs), such as LLAMA3,
GPT-3.5 Turbo, and BERT, process complex medical data to enhance disease
classification. This study explores three Arabic medical text preprocessing
techniques: text summarization, text refinement, and Named Entity Recognition
(NER). Evaluating CAMeL-BERT, AraBERT, and Asafaya-BERT with LoRA, the best
performance was achieved using CAMeL-BERT with NER-augmented text (83% type
classification, 69% severity assessment). Non-fine-tuned models performed
poorly (13%-20% type classification, 40%-49% severity assessment). Integrating
LLMs into social telehealth systems enhances diagnostic accuracy and treatment
outcomes.

摘要：社交遠距醫療透過讓患者可以遠距分享症狀並接受醫療諮詢，徹底改變了醫療保健。使用者經常在社群媒體和線上健康平台上發布症狀，產生了龐大的醫療資料庫，可利用於疾病分類和症狀嚴重性評估。大型語言模型 (LLM)，例如 LLAMA3、GPT-3.5 Turbo 和 BERT，處理複雜的醫療資料以增強疾病分類。本研究探討了三種阿拉伯語醫療文字前處理技術：文字摘要、文字精煉和命名實體辨識 (NER)。使用 LoRA 評估 CAMeL-BERT、AraBERT 和 Asafaya-BERT，使用具 NER 增強文字的 CAMeL-BERT 獲得最佳效能（83% 類型分類，69% 嚴重性評估）。未經過微調的模型效能不佳（13%-20% 類型分類，40%-49% 嚴重性評估）。將 LLM 整合到社交遠距醫療系統中可增強診斷準確性和治療結果。

##### **A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series**
2501.18367v1 by Yifan Wang, Hongfeng Ai, Ruiqi Li, Maowei Jiang, Cheng Jiang, Chenzhong Li

In medical time series disease diagnosis, two key challenges are
identified.First, the high annotation cost of medical data leads to overfitting
in models trained on label-limited, single-center datasets. To address this, we
propose incorporating external data from related tasks and leveraging AE-GAN to
extract prior knowledge,providing valuable references for downstream tasks.
Second, many existing studies employ contrastive learning to derive more
generalized medical sequence representations for diagnostic tasks, usually
relying on manually designed diverse positive and negative sample
pairs.However, these approaches are complex, lack generalizability, and fail to
adaptively capture disease-specific features across different conditions.To
overcome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),
a framework that integrates a multi-head attention mechanism and adaptively
learns representations from different views through inter-view and intra-view
contrastive learning strategies.Additionally, the pre-trained AE-GAN is used to
reconstruct discrepancies in the target data as disease probabilities, which
are then integrated into the contrastive learning process.Experiments on three
target datasets demonstrate that our method consistently outperforms seven
other baselines, highlighting its significant impact on healthcare applications
such as the diagnosis of myocardial infarction, Alzheimer's disease, and
Parkinson's disease.

摘要：在医疗时间序列疾病诊断中，确定了两个关键挑战。首先，医疗数据的标注成本高，导致在标签受限的单中心数据集上训练的模型出现过拟合。为了解决这个问题，我们建议合并来自相关任务的外部数据，并利用 AE-GAN 提取先验知识，为下游任务提供有价值的参考。其次，许多现有的研究采用对比学习来推导出更通用的医疗序列表示，用于诊断任务，通常依赖于手动设计的各种正负样本对。然而，这些方法复杂，缺乏通用性，并且无法自适应地捕获不同条件下的特定疾病特征。为了克服这个问题，我们引入了 LMCF（可学习的多视图对比框架），这是一个集成了多头注意机制的框架，并通过视图间和视图内对比学习策略自适应地学习来自不同视图的表示。此外，预训练的 AE-GAN 用于重建目标数据中的差异作为疾病概率，然后将其集成到对比学习过程中。在三个目标数据集上的实验表明，我们的方法始终优于其他七个基线，突出了其对医疗保健应用（如心肌梗塞、阿尔茨海默病和帕金森病的诊断）的重大影响。

##### **MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding**
2501.18362v1 by Yuxin Zuo, Shang Qu, Yifei Li, Zhangren Chen, Xuekai Zhu, Ermo Hua, Kaiyan Zhang, Ning Ding, Bowen Zhou

We introduce MedXpertQA, a highly challenging and comprehensive benchmark to
evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA
includes 4,460 questions spanning 17 specialties and 11 body systems. It
includes two subsets, Text for text evaluation and MM for multimodal
evaluation. Notably, MM introduces expert-level exam questions with diverse
images and rich clinical information, including patient records and examination
results, setting it apart from traditional medical multimodal benchmarks with
simple QA pairs generated from image captions. MedXpertQA applies rigorous
filtering and augmentation to address the insufficient difficulty of existing
benchmarks like MedQA, and incorporates specialty board questions to improve
clinical relevance and comprehensiveness. We perform data synthesis to mitigate
data leakage risk and conduct multiple rounds of expert reviews to ensure
accuracy and reliability. We evaluate 16 leading models on MedXpertQA.
Moreover, medicine is deeply connected to real-world decision-making, providing
a rich and representative setting for assessing reasoning abilities beyond
mathematics and code. To this end, we develop a reasoning-oriented subset to
facilitate the assessment of o1-like models.

摘要：我們推出了 MedXpertQA，這是一個極具挑戰性且全面的基準，用於評估專家級的醫學知識和先進的推理能力。MedXpertQA 包含 4,460 個問題，涵蓋 17 個專科和 11 個身體系統。它包含兩個子集，文本用於文本評估，MM 用於多模式評估。值得注意的是，MM 引入了專家級考試題目，其中包含多樣化的影像和豐富的臨床資訊，包括患者記錄和檢查結果，這讓它有別於傳統的醫學多模式基準，後者是從影像標題中產生的簡單問答對。MedXpertQA 採用嚴格的過濾和擴充，以解決 MedQA 等現有基準的難度不足問題，並納入專科委員會問題以提高臨床相關性和全面性。我們執行資料合成以降低資料外洩風險，並進行多輪專家審查以確保準確性和可靠性。我們在 MedXpertQA 上評估了 16 個領先的模型。此外，醫學與現實世界的決策制定有密切的聯繫，提供了豐富且具代表性的環境，用於評估超越數學和程式碼的推理能力。為此，我們開發了一個以推理為導向的子集，以利於評估類 o1 的模型。

##### **CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized Codes**
2501.18328v1 by Yicheng Wu, Tao Song, Zhonghua Wu, Zongyuan Ge, Zhaolin Chen, Jianfei Cai

MRI imputation aims to synthesize the missing modality from one or more
available ones, which is highly desirable since it reduces scanning costs and
delivers comprehensive MRI information to enhance clinical diagnosis. In this
paper, we propose a unified model, CodeBrain, designed to adapt to various
brain MRI imputation scenarios. The core design lies in casting various
inter-modality transformations as a full-modality code prediction task. To this
end, CodeBrain is trained in two stages: Reconstruction and Code Prediction.
First, in the Reconstruction stage, we reconstruct each MRI modality, which is
mapped into a shared latent space followed by a scalar quantization. Since such
quantization is lossy and the code is low dimensional, another MRI modality
belonging to the same subject is randomly selected to generate common features
to supplement the code and boost the target reconstruction. In the second
stage, we train another encoder by a customized grading loss to predict the
full-modality codes from randomly masked MRI samples, supervised by the
corresponding quantized codes generated from the first stage. In this way, the
inter-modality transformation is achieved by mapping the instance-specific
codes in a finite scalar space. We evaluated the proposed CodeBrain model on
two public brain MRI datasets (i.e., IXI and BraTS 2023). Extensive experiments
demonstrate that our CodeBrain model achieves superior imputation performance
compared to four existing methods, establishing a new state of the art for
unified brain MRI imputation. Codes will be released.

摘要：MRI 補完旨在從一個或多個可用方式中合成遺失的模態，這是非常理想的，因為它降低了掃描成本，並提供了全面的 MRI 資訊以增強臨床診斷。在本文中，我們提出了一個統一模型 CodeBrain，旨在適應各種腦部 MRI 補完場景。核心設計在於將各種模態間轉換轉換為全模態碼預測任務。為此，CodeBrain 分兩個階段進行訓練：重建和碼預測。首先，在重建階段，我們重建每個 MRI 模態，它被映射到一個共享潛在空間，然後進行標量量化。由於這種量化是有損的，並且碼的維度很低，因此隨機選擇屬於同一個受試者的另一個 MRI 模態來產生共同特徵以補充碼並提升目標重建。在第二階段，我們通過自訂分級損失訓練另一個編碼器，從隨機遮罩的 MRI 樣本預測全模態碼，並由第一階段產生的對應量化碼進行監督。這樣，模態間轉換是通過將特定於例項的碼映射到一個有限的標量空間來實現的。我們在兩個公開的腦部 MRI 資料集（即 IXI 和 BraTS 2023）上評估了所提出的 CodeBrain 模型。大量的實驗證明，與四種現有方法相比，我們的 CodeBrain 模型實現了優異的補完效能，為統一的腦部 MRI 補完建立了新的技術水準。碼將會釋出。

##### **A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification**
2501.18294v1 by Shayli Farshchiha, Salman Asoudeh, Maryam Shavali Kuhshuri, Mehrshad Eisaeid, Mohamadreza Azadie, Saba Hesaraki

Lung cancer is a major issue in worldwide public health, requiring early
diagnosis using stable techniques. This work begins a thorough investigation of
the use of machine learning (ML) methods for precise classification of lung
cancer stages. A cautious analysis is performed to overcome overfitting issues
in model performance, taking into account minimum child weight and learning
rate. A set of machine learning (ML) models including XGBoost (XGB), LGBM,
Adaboost, Logistic Regression (LR), Decision Tree (DT), Random Forest (RF),
CatBoost, and k-Nearest Neighbor (k-NN) are run methodically and contrasted.
Furthermore, the correlation between features and targets is examined using the
deep neural network (DNN) model and thus their capability in detecting complex
patternsis established. It is argued that several ML models can be capable of
classifying lung cancer stages with great accuracy. In spite of the complexity
of DNN architectures, traditional ML models like XGBoost, LGBM, and Logistic
Regression excel with superior performance. The models perform better than the
others in lung cancer prediction on the complete set of comparative metrics
like accuracy, precision, recall, and F-1 score

摘要：肺癌是全球公共衛生的一大問題，需要使用穩定的技術進行早期診斷。這項工作開始徹底調查使用機器學習 (ML) 方法精確分類肺癌分期的使用情況。執行謹慎的分析以克服模型效能中的過度擬合問題，並考慮最小子權重和學習率。一組機器學習 (ML) 模型，包括 XGBoost (XGB)、LGBM、Adaboost、邏輯迴歸 (LR)、決策樹 (DT)、隨機森林 (RF)、CatBoost 和 k 最近鄰 (k-NN)，以有條理的方式執行並進行對比。此外，使用深度神經網路 (DNN) 模型檢查特徵和目標之間的關聯性，從而建立它們在檢測複雜模式中的能力。有人認為，多個 ML 模型能夠以很高的準確度對肺癌分期進行分類。儘管 DNN 架構很複雜，但傳統 ML 模型（如 XGBoost、LGBM 和邏輯迴歸）表現出色，效能優異。這些模型在肺癌預測中表現優於其他模型，在準確度、精確度、召回率和 F-1 分數等完整的比較指標中表現出色。

##### **The iToBoS dataset: skin region images extracted from 3D total body photographs for lesion detection**
2501.18270v1 by Anup Saha, Joseph Adeola, Nuria Ferrera, Adam Mothershaw, Gisele Rezze, Séraphin Gaborit, Brian D'Alessandro, James Hudson, Gyula Szabó, Balazs Pataki, Hayat Rajani, Sana Nazari, Hassan Hayat, Clare Primiero, H. Peter Soyer, Josep Malvehy, Rafael Garcia

Artificial intelligence has significantly advanced skin cancer diagnosis by
enabling rapid and accurate detection of malignant lesions. In this domain,
most publicly available image datasets consist of single, isolated skin lesions
positioned at the center of the image. While these lesion-centric datasets have
been fundamental for developing diagnostic algorithms, they lack the context of
the surrounding skin, which is critical for improving lesion detection. The
iToBoS dataset was created to address this challenge. It includes 16,954 images
of skin regions from 100 participants, captured using 3D total body
photography. Each image roughly corresponds to a $7 \times 9$ cm section of
skin with all suspicious lesions annotated using bounding boxes. Additionally,
the dataset provides metadata such as anatomical location, age group, and sun
damage score for each image. This dataset aims to facilitate training and
benchmarking of algorithms, with the goal of enabling early detection of skin
cancer and deployment of this technology in non-clinical environments.

摘要：人工智慧透過快速且準確偵測惡性病灶，大幅提升皮膚癌的診斷。在這個領域中，大多數公開的影像資料集都包含單一、孤立的皮膚病灶，置於影像的中央。儘管這些以病灶為中心的資料集對於開發診斷演算法至關重要，但它們卻缺乏周圍皮膚的背景，這對於改善病灶偵測至關重要。iToBoS 資料集的建立就是為了應對這個挑戰。它包含 100 位參與者的 16,954 張皮膚區域影像，使用 3D 全身攝影技術擷取。每張影像大致對應於 $7 \times 9$ 公分的皮膚區域，所有可疑病灶都使用邊界框標註。此外，該資料集還提供每張影像的元資料，例如解剖位置、年齡組和日曬損傷評分。此資料集旨在促進演算法的訓練和基準測試，目標是實現皮膚癌的早期偵測，並將此技術部署在非臨床環境中。

##### **Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers**
2501.18237v1 by Malte Tölle, Mohamad Scharaf, Samantha Fischer, Christoph Reich, Silav Zeid, Christoph Dieterich, Benjamin Meder, Norbert Frey, Philipp Wild, Sandy Engelhardt

A patient undergoes multiple examinations in each hospital stay, where each
provides different facets of the health status. These assessments include
temporal data with varying sampling rates, discrete single-point measurements,
therapeutic interventions such as medication administration, and images. While
physicians are able to process and integrate diverse modalities intuitively,
neural networks need specific modeling for each modality complicating the
training procedure. We demonstrate that this complexity can be significantly
reduced by visualizing all information as images along with unstructured text
and subsequently training a conventional vision-text transformer. Our approach,
Vision Transformer for irregular sampled Multi-modal Measurements (ViTiMM), not
only simplifies data preprocessing and modeling but also outperforms current
state-of-the-art methods in predicting in-hospital mortality and phenotyping,
as evaluated on 6,175 patients from the MIMIC-IV dataset. The modalities
include patient's clinical measurements, medications, X-ray images, and
electrocardiography scans. We hope our work inspires advancements in
multi-modal medical AI by reducing the training complexity to (visual) prompt
engineering, thus lowering entry barriers and enabling no-code solutions for
training. The source code will be made publicly available.

摘要：在每次住院期間，患者會接受多項檢查，每一項檢查都能提供健康狀態的不同面向。這些評估包括具有不同取樣率的時間資料、離散單點測量值、治療介入（如藥物管理）和影像。雖然醫生能夠直觀地處理和整合不同的模式，但神經網路需要針對每種模式進行特定的建模，這使得訓練程序變得複雜。我們證明，通過將所有資訊視覺化為影像，並結合非結構化文字，隨後訓練一個傳統的視覺文字轉換器，可以大幅降低這種複雜性。我們的做法，即用於不規則採樣多模式測量的視覺轉換器 (ViTiMM)，不僅簡化了資料預處理和建模，而且在預測院內死亡率和表型方面也優於目前的最新方法，這是根據 MIMIC-IV 資料集中的 6,175 名患者評估的。這些模式包括患者的臨床測量值、藥物、X 光影像和心電圖掃描。我們希望我們的工作能透過降低訓練複雜度到（視覺）提示工程，從而降低進入門檻，並為訓練啟用無程式碼解決方案，進而激勵多模式醫療 AI 的進步。原始程式碼將公開提供。

##### **Investigating an Intelligent System to Monitor \& Explain Abnormal Activity Patterns of Older Adults**
2501.18108v1 by Min Hun Lee, Daniel P. Siewiorek, Alexandre Bernardino

Despite the growing potential of older adult care technologies, the adoption
of these technologies remains challenging. In this work, we conducted a
focus-group session with family caregivers to scope designs of the older adult
care technology. We then developed a high-fidelity prototype and conducted its
qualitative study with professional caregivers and older adults to understand
their perspectives on the system functionalities. This system monitors abnormal
activity patterns of older adults using wireless motion sensors and machine
learning models and supports interactive dialogue responses to explain abnormal
activity patterns of older adults to caregivers and allow older adults
proactively sharing their status with caregivers for an adequate intervention.
Both older adults and professional caregivers appreciated that our system can
provide a faster, personalized service while proactively controlling what
information is to be shared through interactive dialogue responses. We further
discuss other considerations to realize older adult technology in practice.

摘要：儘管老年人照護技術的潛力日益增長，但採用這些技術仍具有挑戰性。在這項研究中，我們與家庭照護者進行焦點小組會議，以界定老年人照護技術的設計範圍。接著，我們開發了一個高保真原型，並與專業照護者和老年人進行質性研究，以了解他們對系統功能的觀點。此系統使用無線動作感測器和機器學習模型監控老年人的異常活動模式，並支援互動式對話回應，向照護者解釋老年人的異常活動模式，並讓老年人主動與照護者分享他們的狀態，以進行適當的介入。老年人和專業照護者都讚賞我們的系統能提供更快速、個人化的服務，同時透過互動式對話回應主動控制要分享哪些資訊。我們進一步討論其他考量因素，以在實務中實現老年人技術。

##### **Normative Evaluation of Large Language Models with Everyday Moral Dilemmas**
2501.18081v1 by Pratik S. Sachdeva, Tom van Nuenen

The rapid adoption of large language models (LLMs) has spurred extensive
research into their encoded moral norms and decision-making processes. Much of
this research relies on prompting LLMs with survey-style questions to assess
how well models are aligned with certain demographic groups, moral beliefs, or
political ideologies. While informative, the adherence of these approaches to
relatively superficial constructs tends to oversimplify the complexity and
nuance underlying everyday moral dilemmas. We argue that auditing LLMs along
more detailed axes of human interaction is of paramount importance to better
assess the degree to which they may impact human beliefs and actions. To this
end, we evaluate LLMs on complex, everyday moral dilemmas sourced from the "Am
I the Asshole" (AITA) community on Reddit, where users seek moral judgments on
everyday conflicts from other community members. We prompted seven LLMs to
assign blame and provide explanations for over 10,000 AITA moral dilemmas. We
then compared the LLMs' judgments and explanations to those of Redditors and to
each other, aiming to uncover patterns in their moral reasoning. Our results
demonstrate that large language models exhibit distinct patterns of moral
judgment, varying substantially from human evaluations on the AITA subreddit.
LLMs demonstrate moderate to high self-consistency but low inter-model
agreement. Further analysis of model explanations reveals distinct patterns in
how models invoke various moral principles. These findings highlight the
complexity of implementing consistent moral reasoning in artificial systems and
the need for careful evaluation of how different models approach ethical
judgment. As LLMs continue to be used in roles requiring ethical
decision-making such as therapists and companions, careful evaluation is
crucial to mitigate potential biases and limitations.

摘要：大型語言模型 (LLM) 的快速採用已促使人們深入研究其編碼的道德規範和決策過程。許多這類研究依賴於以調查式問題提示 LLM，以評估模型與特定人口群體、道德信念或政治意識形態的契合程度。儘管有提供資訊，但這些方法對相對膚淺的結構的堅持傾向於過度簡化日常道德困境背後的複雜性和細微差別。我們認為，沿著更詳細的人類互動軸線審查 LLM 對於更好地評估它們可能影響人類信念和行為的程度至關重要。為此，我們根據 Reddit 上「我是混蛋嗎」(AITA) 社群評估 LLM 在複雜的日常道德困境中，使用者在其中尋求其他社群成員對日常衝突的道德判斷。我們提示七個 LLM 對超過 10,000 個 AITA 道德困境分配責任並提供解釋。然後，我們將 LLM 的判斷和解釋與 Reddit 使用者的判斷和解釋以及彼此進行比較，旨在揭示其道德推理中的模式。我們的結果表明，大型語言模型展現出不同的道德判斷模式，與 AITA 子版塊上的人類評估有很大差異。LLM 表現出中度到高度的自我一致性，但模型間協議低。進一步分析模型解釋揭示了模型如何援引各種道德原則的不同模式。這些發現突顯了在人工系統中實施一致的道德推理的複雜性，以及仔細評估不同模型如何進行道德判斷的必要性。隨著 LLM 持續用於需要道德決策的角色，例如治療師和伴侶，仔細評估對於減輕潛在偏見和限制至關重要。

##### **Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence**
2501.18071v1 by Pir Bakhsh Khokhar, Viviana Pentangelo, Fabio Palomba, Carmine Gravino

Diabetes mellitus (DM) is a global health issue of significance that must be
diagnosed as early as possible and managed well. This study presents a
framework for diabetes prediction using Machine Learning (ML) models,
complemented with eXplainable Artificial Intelligence (XAI) tools, to
investigate both the predictive accuracy and interpretability of the
predictions from ML models. Data Preprocessing is based on the Synthetic
Minority Oversampling Technique (SMOTE) and feature scaling used on the
Diabetes Binary Health Indicators dataset to deal with class imbalance and
variability of clinical features. The ensemble model provided high accuracy,
with a test accuracy of 92.50% and an ROC-AUC of 0.975. BMI, Age, General
Health, Income, and Physical Activity were the most influential predictors
obtained from the model explanations. The results of this study suggest that ML
combined with XAI is a promising means of developing accurate and
computationally transparent tools for use in healthcare systems.

摘要：糖尿病 (DM) 是一項重要的全球健康議題，必須盡早診斷並妥善管理。本研究提出一個糖尿病預測架構，使用機器學習 (ML) 模型，並搭配可解釋人工智慧 (XAI) 工具，來探討 ML 模型預測的準確度和可解釋性。資料前處理基於合成少數過採樣技術 (SMOTE) 和特徵縮放，用於糖尿病二元健康指標資料集，以處理類別不平衡和臨床特徵的可變性。整合模型提供了高準確度，測試準確度為 92.50%，ROC-AUC 為 0.975。根據模型解釋，BMI、年齡、一般健康狀況、收入和身體活動是最具影響力的預測因子。本研究結果表明，ML 結合 XAI 是一種有前途的方式，可以開發出準確且在運算上透明的工具，用於醫療保健系統。

##### **Current Pathology Foundation Models are unrobust to Medical Center Differences**
2501.18055v2 by Edwin D. de Jong, Eric Marcus, Jonas Teuwen

Pathology Foundation Models (FMs) hold great promise for healthcare. Before
they can be used in clinical practice, it is essential to ensure they are
robust to variations between medical centers. We measure whether pathology FMs
focus on biological features like tissue and cancer type, or on the well known
confounding medical center signatures introduced by staining procedure and
other differences. We introduce the Robustness Index. This novel robustness
metric reflects to what degree biological features dominate confounding
features. Ten current publicly available pathology FMs are evaluated. We find
that all current pathology foundation models evaluated represent the medical
center to a strong degree. Significant differences in the robustness index are
observed. Only one model so far has a robustness index greater than one,
meaning biological features dominate confounding features, but only slightly. A
quantitative approach to measure the influence of medical center differences on
FM-based prediction performance is described. We analyze the impact of
unrobustness on classification performance of downstream models, and find that
cancer-type classification errors are not random, but specifically attributable
to same-center confounders: images of other classes from the same medical
center. We visualize FM embedding spaces, and find these are more strongly
organized by medical centers than by biological factors. As a consequence, the
medical center of origin is predicted more accurately than the tissue source
and cancer type. The robustness index introduced here is provided with the aim
of advancing progress towards clinical adoption of robust and reliable
pathology FMs.

摘要：病理基礎模型 (FM) 對醫療保健而言極具潛力。在臨床實務中使用之前，必須確保它們能應對醫療中心之間的差異。我們衡量病理 FM 是否著重於組織和癌症類型等生物特徵，或著重於染色程序和其他差異所導致的眾所周知混淆醫療中心特徵。我們引進了穩健性指標。這項新穎的穩健性指標反映了生物特徵主導混淆特徵的程度。評估了十項目前公開提供的病理 FM。我們發現，所有目前評估的病理基礎模型在很大程度上代表了醫療中心。觀察到穩健性指標有顯著差異。到目前為止，只有一項模型的穩健性指標大於一，表示生物特徵主導混淆特徵，但僅略微主導。描述了衡量醫療中心差異對基於 FM 的預測效能影響的量化方法。我們分析了不穩健性對下游模型分類效能的影響，發現癌症類型分類錯誤並非隨機，而是特別歸因於同中心混淆因子：來自同一醫療中心的其他類別影像。我們視覺化 FM 嵌入空間，發現這些空間是由醫療中心而非生物因素更強有力地組織。因此，比組織來源和癌症類型更準確地預測了醫療中心的來源。在此引入穩健性指標，目的是推進朝著臨床採用穩健且可靠的病理 FM 的進展。

##### **Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**
2501.17860v1 by Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen

Current medical AI systems often fail to replicate real-world clinical
reasoning, as they are predominantly trained and evaluated on static text and
question-answer tasks. These tuning methods and benchmarks overlook critical
aspects like evidence-based reasoning and handling distracting information. To
bridge this gap, we introduce a novel benchmark that simulates real-world
diagnostic scenarios, integrating noise and difficulty levels aligned with
USMLE standards. Moreover, we explore dialogue-based fine-tuning, which
transforms static datasets into conversational formats to better capture
iterative reasoning processes. Experiments show that dialogue-tuned models
outperform traditional methods, with improvements of $9.64\%$ in multi-round
reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our
findings highlight dialogue tuning as a promising approach for advancing
clinically aligned and robust medical AI systems.

摘要：目前的醫療 AI 系統常無法複製真實世界的臨床推理，因為它們主要在靜態文字和問答任務上受訓和評估。這些調整方法和基準忽略了基於證據的推理和處理分散資訊等關鍵面向。為了彌補這個差距，我們提出一個模擬真實世界診斷情境的全新基準，整合與 USMLE 標準一致的雜訊和難度等級。此外，我們探索以對話為基礎的微調，將靜態資料集轉換為對話格式，以更好地捕捉反覆的推理過程。實驗顯示，對話微調模型優於傳統方法，在多輪推理情境中提升了 9.64%，在有雜訊的環境中提升了 6.18% 的準確度。我們的發現強調對話微調是一種有望推進與臨床相符且強健的醫療 AI 系統的方法。

##### **GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**
2501.17855v1 by Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee

Robot caregiving should be personalized to meet the diverse needs of care
recipients -- assisting with tasks as needed, while taking user agency in
action into account. In physical tasks such as handover, bathing, dressing, and
rehabilitation, a key aspect of this diversity is the functional range of
motion (fROM), which can vary significantly between individuals. In this work,
we learn to predict personalized fROM as a way to generalize robot
decision-making in a wide range of caregiving tasks. We propose a novel
data-driven method for predicting personalized fROM using functional assessment
scores from occupational therapy. We develop a neural model that learns to
embed functional assessment scores into a latent representation of the user's
physical function. The model is trained using motion capture data collected
from users with emulated mobility limitations. After training, the model
predicts personalized fROM for new users without motion capture. Through
simulated experiments and a real-robot user study, we show that the
personalized fROM predictions from our model enable the robot to provide
personalized and effective assistance while improving the user's agency in
action. See our website for more visualizations:
https://emprise.cs.cornell.edu/grace/.

摘要：機器人照護應根據照護對象的不同需求進行客製化，在需要時協助執行任務，同時考量使用者的自主行動。在移交、沐浴、穿衣和復健等身體任務中，這種多樣性的關鍵面向是功能性動作範圍 (fROM)，而這在不同個體之間可能差異很大。在這項工作中，我們學習預測客製化 fROM，作為在廣泛照護任務中概化機器人決策制定的一種方式。我們提出了一種使用職能治療功能評估分數來預測客製化 fROM 的新穎資料驅動方法。我們開發了一個神經模型，學習將功能評估分數嵌入到使用者的身體功能潛在表徵中。該模型使用從具有模擬行動限制的使用者收集的動作擷取資料進行訓練。訓練後，該模型會為沒有動作擷取的新使用者預測客製化 fROM。透過模擬實驗和真實機器人使用者研究，我們展示了我們模型的客製化 fROM 預測使機器人能夠提供客製化且有效的協助，同時提高使用者的自主行動。請參閱我們的網站以取得更多視覺化資料：https://emprise.cs.cornell.edu/grace/。

##### **Towards Recommender Systems LLMs Playground (RecSysLLMsP): Exploring Polarization and Engagement in Simulated Social Networks**
2502.00055v1 by Ljubisa Bojic, Zorica Dodevska, Yashar Deldjoo, Nenad Pantelic

Given the exponential advancement in AI technologies and the potential
escalation of harmful effects from recommendation systems, it is crucial to
simulate and evaluate these effects early on. Doing so can help prevent
possible damage to both societies and technology companies. This paper
introduces the Recommender Systems LLMs Playground (RecSysLLMsP), a novel
simulation framework leveraging Large Language Models (LLMs) to explore the
impacts of different content recommendation setups on user engagement and
polarization in social networks. By creating diverse AI agents (AgentPrompts)
with descriptive, static, and dynamic attributes, we assess their autonomous
behaviour across three scenarios: Plurality, Balanced, and Similarity. Our
findings reveal that the Similarity Scenario, which aligns content with user
preferences, maximizes engagement while potentially fostering echo chambers.
Conversely, the Plurality Scenario promotes diverse interactions but produces
mixed engagement results. Our study emphasizes the need for a careful balance
in recommender system designs to enhance user satisfaction while mitigating
societal polarization. It underscores the unique value and challenges of
incorporating LLMs into simulation environments. The benefits of RecSysLLMsP
lie in its potential to calculate polarization effects, which is crucial for
assessing societal impacts and determining user engagement levels with diverse
recommender system setups. This advantage is essential for developing and
maintaining a successful business model for social media companies. However,
the study's limitations revolve around accurately emulating reality. Future
efforts should validate the similarity in behaviour between real humans and
AgentPrompts and establish metrics for measuring polarization scores.

摘要：<paragraph>隨著 AI 技術的指數級進步，以及推薦系統造成的有害影響的潛在升級，提早模擬和評估這些影響至關重要。這麼做有助於防止對社會和科技公司造成的潛在損害。這篇論文介紹了推薦系統 LLM 遊樂場 (RecSysLLMsP)，一個創新的模擬架構，利用大型語言模型 (LLM) 來探索不同內容推薦設定對社群網路中的使用者參與度和極化現象的影響。藉由創造具有描述性、靜態和動態屬性的多樣化 AI 代理程式 (AgentPrompts)，我們評估它們在三種情境中的自主行為：多元性、平衡性和相似性。我們的研究結果顯示，與使用者偏好一致的相似性情境，最大化了參與度，同時潛在促進了同溫層。相反地，多元性情境促進了多樣化的互動，但產生了參差不齊的參與度結果。我們的研究強調了在推薦系統設計中仔細取得平衡的必要性，以提升使用者滿意度，同時減輕社會極化現象。它強調了將 LLM 納入模擬環境的獨特價值和挑戰。RecSysLLMsP 的優勢在於它計算極化效應的潛力，這對於評估社會影響和確定使用者參與度與多樣化推薦系統設定的層級至關重要。這個優勢對於社群媒體公司開發和維持成功的商業模式至關重要。然而，這項研究的限制在於精確地模擬現實。未來的努力應該驗證真實人類和 AgentPrompts 之間行為的相似性，並建立衡量極化分數的指標。</paragraph>

##### **Tonguescape: Exploring Language Models Understanding of Vowel Articulation**
2501.17643v1 by Haruki Sakajo, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

Vowels are primarily characterized by tongue position. Humans have discovered
these features of vowel articulation through their own experience and explicit
objective observation such as using MRI. With this knowledge and our
experience, we can explain and understand the relationship between tongue
positions and vowels, and this knowledge is helpful for language learners to
learn pronunciation. Since language models (LMs) are trained on a large amount
of data that includes linguistic and medical fields, our preliminary studies
indicate that an LM is able to explain the pronunciation mechanisms of vowels.
However, it is unclear whether multi-modal LMs, such as vision LMs, align
textual information with visual information. One question arises: do LMs
associate real tongue positions with vowel articulation? In this study, we
created video and image datasets from the existing real-time MRI dataset and
investigated whether LMs can understand vowel articulation based on tongue
positions using vision-based information. Our findings suggest that LMs exhibit
potential for understanding vowels and tongue positions when reference examples
are provided while they have difficulties without them. Our code for dataset
building is available on GitHub.

摘要：元音主要由舌頭位置決定。人類透過自己的經驗和明確的客觀觀察（例如使用 MRI）發現了元音發音的這些特徵。有了這些知識和經驗，我們可以解釋和理解舌頭位置和元音之間的關係，而這些知識對語言學習者學習發音很有幫助。由於語言模型 (LM) 是在包含語言學和醫學領域的大量資料上訓練的，我們的初步研究表明，LM 能夠解釋元音的發音機制。然而，尚不清楚多模態 LM（例如視覺 LM）是否將文字資訊與視覺資訊對齊。一個問題產生了：LM 是否將真實的舌頭位置與元音發音聯繫起來？在這項研究中，我們從現有的即時 MRI 資料集中建立了影片和影像資料集，並探討 LM 是否能根據舌頭位置使用基於視覺的資訊來理解元音發音。我們的研究結果表明，當提供參考範例時，LM 具有理解元音和舌頭位置的潛力，而沒有參考範例時則有困難。我們用於建立資料集的程式碼可在 GitHub 上取得。

##### **Layered Chain-of-Thought Prompting for Multi-Agent LLM Systems: A Comprehensive Approach to Explainable Large Language Models**
2501.18645v2 by Manish Sanwal

Large Language Models (LLMs) leverage chain-of-thought (CoT) prompting to
provide step-by-step rationales, improving performance on complex tasks.
Despite its benefits, vanilla CoT often fails to fully verify intermediate
inferences and can produce misleading explanations. In this work, we propose
Layered Chain-of-Thought (Layered-CoT) Prompting, a novel framework that
systematically segments the reasoning process into multiple layers, each
subjected to external checks and optional user feedback. We expand on the key
concepts, present three scenarios -- medical triage, financial risk assessment,
and agile engineering -- and demonstrate how Layered-CoT surpasses vanilla CoT
in terms of transparency, correctness, and user engagement. By integrating
references from recent arXiv papers on interactive explainability, multi-agent
frameworks, and agent-based collaboration, we illustrate how Layered-CoT paves
the way for more reliable and grounded explanations in high-stakes domains.

摘要：大型語言模型（LLM）利用思考鏈（CoT）提示提供逐步的理由，提升複雜任務的表現。儘管有其好處，但香草 CoT 常常無法完全驗證中間推論，且可能會產生誤導性的解釋。在這項研究中，我們提出分層思考鏈（分層 CoT）提示，一個新穎的架構，它有系統地將推理過程區隔成多個層級，每個層級都經過外部檢查和可選擇的使用者回饋。我們擴展關鍵概念，提出三個場景——醫療分流、財務風險評估和敏捷工程——並展示分層 CoT 在透明度、正確性和使用者參與度方面如何超越香草 CoT。透過整合來自近期 arXiv 論文中關於互動可解釋性、多重代理架構和基於代理的協作的參考文獻，我們說明分層 CoT 如何為高風險領域中更可靠且有根據的解釋鋪路。

##### **An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**
2501.17555v1 by Wenqi Li, Yingli Chen, Keyang Zhou, Xiaoxiao Hu, Zilu Zheng, Yue Yan, Xinpeng Zhang, Wei Tang, Zhenxing Qian

Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms
that account for less than 5% of all pancreatic malignancies, with an incidence
of only 1-1.5 cases per 100,000. Early detection of pNETs is critical for
improving patient survival, but the rarity of pNETs makes segmenting them from
CT a very challenging problem. So far, there has not been a dataset
specifically for pNETs available to researchers. To address this issue, we
propose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography
(CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors,
containing data from 469 patients. This is the first dataset solely dedicated
to pNETs, distinguishing it from previous collections. Additionally, we provide
the baseline detection networks with a new slice-wise weight loss function
designed for the UNet-based model, improving the overall pNET segmentation
performance. We hope that our dataset can enhance the understanding and
diagnosis of pNET Tumors within the medical community, facilitate the
development of more accurate diagnostic tools, and ultimately improve patient
outcomes and advance the field of oncology.

摘要：胰臟神經內分泌腫瘤 (pNETs) 是非常罕見的內分泌腫瘤，僅佔所有胰臟惡性腫瘤的不到 5%，每 100,000 人中僅發生 1-1.5 個病例。早期發現 pNETs 對改善患者存活率至關重要，但 pNETs 的罕見性使得從 CT 中分割它們成為一個非常具有挑戰性的問題。到目前為止，還沒有專門針對 pNETs 的數據集可供研究人員使用。為了解決這個問題，我們提出了一個 pNETs 數據集，一個專注於胰臟神經內分泌腫瘤的標註良好的對比增強電腦斷層掃描 (CECT) 數據集，包含來自 469 名患者的數據。這是第一個專門針對 pNETs 的數據集，這使其有別於之前的收集。此外，我們為基線檢測網路提供了一個新的基於 UNet 模型設計的切片加權損失函數，改善了整體 pNET 分割性能。我們希望我們的數據集能夠增強醫學界對 pNET 腫瘤的理解和診斷，促進更準確的診斷工具的開發，最終改善患者的預後並推進腫瘤學領域。

##### **LLM Assistance for Pediatric Depression**
2501.17510v1 by Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive

Traditional depression screening methods, such as the PHQ-9, are particularly
challenging for children in pediatric primary care due to practical
limitations. AI has the potential to help, but the scarcity of annotated
datasets in mental health, combined with the computational costs of training,
highlights the need for efficient, zero-shot approaches. In this work, we
investigate the feasibility of state-of-the-art LLMs for depressive symptom
extraction in pediatric settings (ages 6-24). This approach aims to complement
traditional screening and minimize diagnostic errors.
  Our findings show that all LLMs are 60% more efficient than word match, with
Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the
extraction of more rare symptoms like "sleep problems" (F1: 0.92) and
"self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and
recall (0.60), performing well in categories like "Feeling depressed" (0.69)
and "Weight change" (0.78). Llama 3, with the highest recall (0.90),
overgeneralizes symptoms, making it less suitable for this type of analysis.
Challenges include the complexity of clinical notes and overgeneralization from
PHQ-9 scores. The main challenges faced by LLMs include navigating the complex
structure of clinical notes with content from different times in the patient
trajectory, as well as misinterpreting elevated PHQ-9 scores.
  We finally demonstrate the utility of symptom annotations provided by Flan as
features in an ML algorithm, which differentiates depression cases from
controls with high precision of 0.78, showing a major performance boost
compared to a baseline that does not use these features.

摘要：<paragraph>傳統的憂鬱症篩檢方法，例如 PHQ-9，由於實際限制，對於小兒科初級照護中的兒童來說特別具有挑戰性。AI 有可能提供幫助，但心理健康中註解資料集的稀少，加上訓練的運算成本，突顯了對有效率的零次學習方法的需求。在這項工作中，我們探討了最先進的 LLM 在小兒科環境（6-24 歲）中提取憂鬱症狀的可行性。這種方法旨在補充傳統篩檢並將診斷錯誤降至最低。我們的研究結果顯示，所有 LLM 的效率都比字詞比對高出 60%，而 Flan 在精確度方面領先（平均 F1：0.65，精確度：0.78），在提取較罕見的症狀方面表現出色，例如「睡眠問題」（F1：0.92）和「自我厭惡」（F1：0.8）。Phi 在精確度（0.44）和召回率（0.60）之間取得平衡，在「感到沮喪」（0.69）和「體重改變」（0.78）等類別中表現良好。擁有最高召回率（0.90）的 Llama 3 會過度概括症狀，使其不太適合此類分析。挑戰包括臨床筆記的複雜性和 PHQ-9 分數的過度概括。LLM 面臨的主要挑戰包括在患者歷程中不同時間的內容中導航臨床筆記的複雜結構，以及誤解 PHQ-9 分數升高。我們最後展示了 Flan 提供的症狀註解作為機器學習演算法中特徵的效用，它以 0.78 的高精確度將憂鬱症病例與對照組區分開來，與不使用這些特徵的基準相比，顯示出主要的效能提升。</paragraph>

##### **Bridging Contrastive Learning and Domain Adaptation: Theoretical Perspective and Practical Application**
2502.00052v1 by Gonzalo Iñaki Quintana, Laurence Vancamberg, Vincent Jugnon, Agnès Desolneux, Mathilde Mougeot

This work studies the relationship between Contrastive Learning and Domain
Adaptation from a theoretical perspective. The two standard contrastive losses,
NT-Xent loss (Self-supervised) and Supervised Contrastive loss, are related to
the Class-wise Mean Maximum Discrepancy (CMMD), a dissimilarity measure widely
used for Domain Adaptation. Our work shows that minimizing the contrastive
losses decreases the CMMD and simultaneously improves class-separability,
laying the theoretical groundwork for the use of Contrastive Learning in the
context of Domain Adaptation. Due to the relevance of Domain Adaptation in
medical imaging, we focused the experiments on mammography images. Extensive
experiments on three mammography datasets - synthetic patches, clinical (real)
patches, and clinical (real) images - show improved Domain Adaptation,
class-separability, and classification performance, when minimizing the
Supervised Contrastive loss.

摘要：本研究從理論角度探討對比學習與領域適應之間的關係。兩種標準對比損失，NT-Xent 損失（自我監督）和監督對比損失，與廣泛用於領域適應的差異性測量標準類別平均最大差異（CMMD）有關。我們的研究表明，最小化對比損失會降低 CMMD，同時提高類別可分離性，為在領域適應中使用對比學習奠定理論基礎。由於領域適應在醫學影像中的相關性，我們將實驗重點放在乳房攝影圖像上。在三個乳房攝影數據集（合成貼片、臨床（真實）貼片和臨床（真實）圖像）上進行的廣泛實驗表明，在最小化監督對比損失時，領域適應、類別可分離性和分類性能得到改善。

##### **Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**
2501.17343v1 by Chongyu Qu, Ritchie Zhao, Ye Yu, Bin Liu, Tianyuan Yao, Junchao Zhu, Bennett A. Landman, Yucheng Tang, Yuankai Huo

Quantizing deep neural networks ,reducing the precision (bit-width) of their
computations, can remarkably decrease memory usage and accelerate processing,
making these models more suitable for large-scale medical imaging applications
with limited computational resources. However, many existing methods studied
"fake quantization", which simulates lower precision operations during
inference, but does not actually reduce model size or improve real-world
inference speed. Moreover, the potential of deploying real 3D low-bit
quantization on modern GPUs is still unexplored. In this study, we introduce a
real post-training quantization (PTQ) framework that successfully implements
true 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation
models, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet,
ST-UNet,and VISTA3D. Our approach involves two main steps. First, we use
TensorRT to perform fake quantization for both weights and activations with
unlabeled calibration dataset. Second, we convert this fake quantization into
real quantization via TensorRT engine on real GPUs, resulting in real-world
reductions in model size and inference latency. Extensive experiments
demonstrate that our framework effectively performs 8-bit quantization on GPUs
without sacrificing model performance. This advancement enables the deployment
of efficient deep learning models in medical imaging applications where
computational resources are constrained. The code and models have been
released, including U-Net, TransUNet pretrained on the BTCV dataset for
abdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset
for whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and
VISTA3D pretrained on TotalSegmentator V2 for full body (104-label)
segmentation. https://github.com/hrlblab/PTQ.

摘要：<paragraph>量化深度神经网络，降低其计算的精度（位宽），可以显著减少内存使用量并加速处理，使这些模型更适合于具有有限计算资源的大规模医学影像应用。然而，许多现有方法研究了“伪量化”，它在推理期间模拟较低精度的操作，但实际上并没有减少模型大小或提高实际推理速度。此外，在现代 GPU 上部署真正的 3D 低位量化的潜力仍未得到探索。在这项研究中，我们引入了一个真正的训练后量化 (PTQ) 框架，该框架成功地在最先进的 (SOTA) 3D 医学分割模型（即 U-Net、SegResNet、SwinUNETR、nnU-Net、UNesT、TransUNet、ST-UNet 和 VISTA3D）上实现了真正的 8 位量化。我们的方法涉及两个主要步骤。首先，我们使用 TensorRT 对权重和激活进行伪量化，并使用未标记的校准数据集。其次，我们将这种伪量化通过真实 GPU 上的 TensorRT 引擎转换为真正的量化，从而在模型大小和推理延迟方面实现了实际的减少。大量的实验表明，我们的框架在 GPU 上有效地执行 8 位量化，而不会牺牲模型性能。这一进步使得在计算资源受限的医学影像应用中部署高效的深度学习模型成为可能。代码和模型已经发布，包括 U-Net、TransUNET，在 BTCV 数据集上预训练用于腹部（13 标签）分割，UNesT 在 Whole Brain 数据集上预训练用于全脑（133 标签）分割，以及 nnU-Net、SegResNet、SwinUNETR 和 VISTA3D 在 TotalSegmentator V2 上预训练用于全身（104 标签）分割。https://github.com/hrlblab/PTQ。</paragraph>

##### **Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**
2501.17338v1 by Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang

Generative Language Models rely on autoregressive decoding to produce the
output sequence token by token. Many tasks such as preference optimization,
require the model to produce task-level output consisting of multiple tokens
directly by selecting candidates from a pool as predictions. Determining a
task-level prediction from candidates using the ordinary token-level decoding
mechanism is constrained by time-consuming decoding and interrupted gradients
by discrete token selection. Existing works have been using decoding-free
candidate selection methods to obtain candidate probability from initial output
logits over vocabulary. Though these estimation methods are widely used, they
are not systematically evaluated, especially on end tasks. We introduce an
evaluation of a comprehensive collection of decoding-free candidate selection
approaches on a comprehensive set of tasks, including five multiple-choice QA
tasks with a small candidate pool and four clinical decision tasks with a
massive amount of candidates, some with 10k+ options. We evaluate the
estimation methods paired with a wide spectrum of foundation LMs covering
different architectures, sizes and training paradigms. The results and insights
from our analysis inform the future model design.

摘要：生成語言模型依靠自迴歸解碼來逐個符號產生輸出序列。許多任務（如偏好最佳化）要求模型直接從候選池中選擇預測，產生由多個符號組成的任務級別輸出。使用一般的符號級別解碼機制從候選者中確定任務級別預測受到耗時的解碼和離散符號選擇中斷的梯度的約束。現有工作一直使用無解碼候選者選擇方法從初始輸出邏輯值中獲得候選者機率。儘管這些估計方法被廣泛使用，但它們並未經過系統評估，特別是在最終任務上。我們針對全面的任務集，包括五個具有小型候選者池的多選題問答任務和四個具有大量候選者的臨床決策任務（其中一些有 10k+ 選項），對全面的無解碼候選者選擇方法進行評估。我們評估與廣泛基礎語言模型配對的估計方法，這些模型涵蓋不同的架構、大小和訓練範例。我們分析的結果和見解為未來的模型設計提供了資訊。

##### **Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**
2501.17326v1 by Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang

Clinical diagnosis prediction models, when provided with a patient's medical
history, aim to detect potential diseases early, facilitating timely
intervention and improving prognostic outcomes. However, the inherent scarcity
of patient data and large disease candidate space often pose challenges in
developing satisfactory models for this intricate task. The exploration of
leveraging Large Language Models (LLMs) for encapsulating clinical decision
processes has been limited. We introduce MERA, a clinical diagnosis prediction
model that bridges pertaining natural language knowledge with medical practice.
We apply hierarchical contrastive learning on a disease candidate ranking list
to alleviate the large decision space issue. With concept memorization through
fine-tuning, we bridge the natural language clinical knowledge with medical
codes. Experimental results on MIMIC-III and IV datasets show that MERA
achieves the state-of-the-art diagnosis prediction performance and dramatically
elevates the diagnosis prediction capabilities of generative LMs.

摘要：臨床診斷預測模型在提供患者病歷的同時，旨在及早發現潛在疾病，促進及時干預並改善預後結果。然而，患者數據的固有稀缺性和大量的疾病候選空間通常對開發令人滿意的模型以應對這項複雜的任務構成挑戰。利用大型語言模型 (LLM) 來封裝臨床決策流程的探索受到限制。我們引入了 MERA，這是一個臨床診斷預測模型，它將相關的自然語言知識與醫療實踐聯繫起來。我們在疾病候選排名清單上應用分層對比學習，以緩解大型決策空間問題。通過微調概念記憶，我們將自然語言臨床知識與醫療代碼聯繫起來。在 MIMIC-III 和 IV 數據集上的實驗結果表明，MERA 達到了最先進的診斷預測性能，並顯著提升了生成式 LM 的診斷預測能力。

##### **Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**
2501.17286v1 by Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu

Background: The radiation oncology clinical practice involves many steps
relying on the dynamic interplay of abundant text data. Large language models
have displayed remarkable capabilities in processing complex text information.
But their direct applications in specific fields like radiation oncology remain
underexplored.
  Purpose: This study aims to investigate whether fine-tuning LLMs with domain
knowledge can improve the performance on Task (1) treatment regimen generation,
Task (2) treatment modality selection (photon, proton, electron, or
brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.
  Methods: Data for 15,724 patient cases were extracted. Cases where patients
had a single diagnostic record, and a clearly identifiable primary treatment
plan were selected for preprocessing and manual annotation to have 7,903 cases
of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.
Each case was used to construct a pair consisting of patient diagnostics
details and an answer (treatment regimen, treatment modality, or ICD-10 code
respectively) for the supervised fine-tuning of these three tasks. Open source
LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the
Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for
the fine-tuned models and original models. Clinical evaluation was performed on
Task (1) by radiation oncologists, while precision, recall, and F-1 score were
evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used
to statistically analyze the results.
  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with
p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the
fine-tuned LLMs-generated treatment regimens were clinically acceptable.
Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.

摘要：<paragraph>背景：放射肿瘤临床实践涉及许多步骤，这些步骤依赖于丰富文本数据的动态交互。大型语言模型在处理复杂的文本信息方面表现出了卓越的能力。但它们在放射肿瘤等特定领域的直接应用仍未得到充分探索。
目的：本研究旨在调查通过领域知识微调 LLM 是否可以提高任务 (1) 治疗方案生成、任务 (2) 治疗方式选择（光子、质子、电子或近距离放射治疗）和任务 (3) 放射肿瘤中 ICD-10 代码预测的性能。
方法：提取了 15,724 例患者病例的数据。选择了患者有单一诊断记录且有明确可识别的主要治疗计划的病例，进行预处理和手动注释，得到 7,903 例患者诊断、治疗计划、治疗方式和 ICD-10 代码。每个病例都用于构建一对，包括患者诊断详情和答案（分别是治疗方案、治疗方式或 ICD-10 代码），用于这三个任务的监督微调。开源 LLaMA2-7B 和 Mistral-7B 模型被用于使用低秩逼近方法进行微调。报告了微调模型和原始模型的准确性和 ROUGE-1 分数。任务 (1) 由放射肿瘤科医师进行临床评估，而任务 (2) 和 (3) 则评估了精确度、召回率和 F-1 分数。单侧 Wilcoxon 符号秩检验用于对结果进行统计分析。
结果：微调后的 LLM 在所有任务中都优于原始 LLM，p 值 <= 0.001。临床评估表明，超过 60% 的微调 LLM 生成的治疗方案在临床上是可接受的。精确度、召回率和 F1 分数显示微调后的 LLM 性能得到改善。</paragraph>

##### **ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification**
2501.17260v1 by Mohammadreza Saraei, Igor Kozak, Eung-Joo Lee

Optical Coherence Tomography (OCT) is a non-invasive imaging modality
essential for diagnosing various eye diseases. Despite its clinical
significance, developing OCT-based diagnostic tools faces challenges, such as
limited public datasets, sparse annotations, and privacy concerns. Although
deep learning has made progress in automating OCT analysis, these challenges
remain unresolved. To address these limitations, we introduce the Vision
Transformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a
novel framework designed to enhance feature extraction and improve diagnostic
accuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining,
Self-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining
phase leverages the OCTMNIST dataset (97,477 unlabeled images across four
disease classes) with data augmentation to create dual-augmented views. A
Vision Transformer (ViT-Base) backbone extracts features, while a negative
cosine similarity loss aligns feature representations. Pretraining is conducted
over 50 epochs with a learning rate of 0.0001 and momentum of 0.999.
Fine-tuning is performed on a stratified 5.129% subset of OCTMNIST using
10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of
0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming
existing SSP-based methods.

摘要：光學相干斷層掃描（OCT）是一種非侵入式影像模式，對於診斷各種眼疾至關重要。儘管其臨床意義重大，但開發基於 OCT 的診斷工具面臨挑戰，例如公共數據集有限、註解稀疏和隱私問題。儘管深度學習在自動化 OCT 分析方面取得了進展，但這些挑戰仍然沒有解決。為了應對這些限制，我們引入了基於 Vision Transformer 的雙流自監督預訓練網路（ViT-2SPN），這是一個新穎的框架，旨在增強特徵提取並提高診斷準確性。ViT-2SPN 採用三階段工作流程：監督預訓練、自監督預訓練（SSP）和監督微調。預訓練階段利用 OCTMNIST 數據集（跨越四個疾病類別的 97,477 張未標記影像）和數據擴充來建立雙重擴充的檢視。視覺轉換器（ViT-Base）主幹提取特徵，而負餘弦相似度損失則校準特徵表示。預訓練在 50 個世代中進行，學習率為 0.0001，動能為 0.999。微調在 OCTMNIST 的分層 5.129% 子集上執行，使用 10 倍交叉驗證。ViT-2SPN 達到了 0.93 的平均 AUC、0.77 的準確率、0.81 的精確度、0.75 的召回率和 0.76 的 F1 分數，優於現有的基於 SSP 的方法。

##### **A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**
2501.17160v1 by Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham

Early detection of COVID-19 is crucial for effective treatment and
controlling its spread. This study proposes a novel hybrid deep learning model
for detecting COVID-19 from CT scan images, designed to assist overburdened
medical professionals. Our proposed model leverages the strengths of VGG16,
DenseNet121, and MobileNetV2 to extract features, followed by Principal
Component Analysis (PCA) for dimensionality reduction, after which the features
are stacked and classified using a Support Vector Classifier (SVC). We
conducted comparative analysis between the proposed hybrid model and individual
pre-trained CNN models, using a dataset of 2,108 training images and 373 test
images comprising both COVID-positive and non-COVID images. Our proposed hybrid
model achieved an accuracy of 98.93%, outperforming the individual models in
terms of precision, recall, F1 scores, and ROC curve performance.

摘要：早期偵測 COVID-19 對有效治療和控制其傳播至關重要。本研究提出一個新穎的深度學習混合模型，用於從電腦斷層掃描影像中偵測 COVID-19，旨在協助負擔過重的醫療專業人員。我們提出的模型利用 VGG16、DenseNet121 和 MobileNetV2 的優點來萃取特徵，接著進行主成分分析 (PCA) 以進行降維，然後將特徵堆疊並使用支持向量分類器 (SVC) 進行分類。我們對提出的混合模型和個別預訓練的 CNN 模型進行比較分析，使用包含 2,108 張訓練影像和 373 張測試影像的資料集，其中包含 COVID-19 陽性影像和非 COVID-19 影像。我們提出的混合模型達到了 98.93% 的準確度，在精準度、召回率、F1 分數和 ROC 曲線效能方面優於個別模型。

##### **Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**
2501.17152v1 by Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani

Three-dimensional (3D) multi-slab acquisition is a technique frequently
employed in high-resolution diffusion-weighted MRI in order to achieve the best
signal-to-noise ratio (SNR) efficiency. However, this technique is limited by
slab boundary artifacts that cause intensity fluctuations and aliasing between
slabs which reduces the accuracy of anatomical imaging. Addressing this issue
is crucial for advancing diffusion MRI quality and making high-resolution
imaging more feasible for clinical and research applications. In this work, we
propose a regularized slab profile encoding (PEN) method within a Plug-and-Play
ADMM framework, incorporating multi-scale energy (MuSE) regularization to
effectively improve the slab combined reconstruction. Experimental results
demonstrate that the proposed method significantly improves image quality
compared to non-regularized and TV-regularized PEN approaches. The regularized
PEN framework provides a more robust and efficient solution for high-resolution
3D diffusion MRI, potentially enabling clearer, more reliable anatomical
imaging across various applications.

摘要：三維 (3D) 多層板擷取是一種技術，經常使用於高解析度擴散加權 MRI，以達到最佳的訊號雜訊比 (SNR) 效率。然而，此技術受到層板邊界偽影的限制，會造成強度波動和層板之間的混疊，降低解剖影像的準確度。解決這個問題對於提升擴散 MRI 品質至關重要，並使高解析度影像更適用於臨床和研究應用。在這項工作中，我們在 Plug-and-Play ADMM 架構內提出正規化的層板輪廓編碼 (PEN) 方法，並結合多尺度能量 (MuSE) 正規化，以有效改善層板組合重建。實驗結果證明，與非正規化和 TV 正規化 PEN 方法相比，所提出的方法顯著提升了影像品質。正規化的 PEN 架構為高解析度 3D 擴散 MRI 提供更強固且有效率的解決方案，潛在可實現更清晰、更可靠的解剖影像，適用於各種應用。

##### **Irony Detection, Reasoning and Understanding in Zero-shot Learning**
2501.16884v1 by Peiling Yi, Yuhan Xia

Irony is a powerful figurative language (FL) on social media that can
potentially mislead various NLP tasks, such as recommendation systems,
misinformation checks, and sentiment analysis. Understanding the implicit
meaning of this kind of subtle language is essential to mitigate irony's
negative impact on NLP tasks. However, building models to understand irony
presents a unique set of challenges, because irony is a complex form of
language that often relies on context, tone, and subtle cues to convey meaning
that is opposite or different from the literal interpretation. Large language
models, such as ChatGPT, are increasingly able to capture implicit and
contextual information. In this study, we investigate the generalization,
reasoning and understanding ability of ChatGPT on irony detection across six
different genre irony detection datasets. Our findings suggest that ChatGPT
appears to show an enhanced language understanding and reasoning ability. But
it needs to be very careful in prompt engineering design. Thus, we propose a
prompt engineering design framework IDADP to achieve higher irony detection
accuracy, improved understanding of irony, and more effective explanations
compared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain
via experiments that the practice generated under the framework is likely to be
the promised solution to resolve the generalization issues of LLMs.

摘要：反諷是一種強大的社交媒體比喻語言 (FL)，可能會誤導各種 NLP 任務，例如推薦系統、錯誤訊息檢查和情緒分析。理解這種微妙語言的隱含含義對於減輕反諷對 NLP 任務的負面影響至關重要。然而，建立模型來理解反諷會帶來一系列獨特的挑戰，因為反諷是一種複雜的語言形式，通常依賴於上下文、語氣和微妙的線索來傳達與字面解釋相反或不同的含義。大型語言模型，例如 ChatGPT，越來越能夠捕捉隱含和上下文信息。在本研究中，我們探討了 ChatGPT 在六個不同類型反諷檢測數據集上的反諷檢測的概括、推理和理解能力。我們的研究結果表明，ChatGPT 似乎表現出增強的語言理解和推理能力。但它需要在提示工程設計中非常小心。因此，我們提出了一個提示工程設計框架 IDADP，以實現更高的反諷檢測準確度、改進的反諷理解以及與其他最先進的 ChatGPT 零次學習方法相比更有效的解釋。並通過實驗確定在該框架下產生的實踐很可能是解決 LLM 概括問題的承諾解決方案。

##### **Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?**
2501.17207v1 by Keqi Han, Yao Su, Lifang He, Liang Zhan, Sergey Plis, Vince Calhoun, Carl Yang

Functional brain connectome is crucial for deciphering the neural mechanisms
underlying cognitive functions and neurological disorders. Graph deep learning
models have recently gained tremendous popularity in this field. However, their
actual effectiveness in modeling the brain connectome remains unclear. In this
study, we re-examine graph deep learning models based on four large-scale
neuroimaging studies encompassing diverse cognitive and clinical outcomes.
Surprisingly, we find that the message aggregation mechanism, a hallmark of
graph deep learning models, does not help with predictive performance as
typically assumed, but rather consistently degrades it. To address this issue,
we propose a hybrid model combining a linear model with a graph attention
network through dual pathways, achieving robust predictions and enhanced
interpretability by revealing both localized and global neural connectivity
patterns. Our findings urge caution in adopting complex deep learning models
for functional brain connectome analysis, emphasizing the need for rigorous
experimental designs to establish tangible performance gains and perhaps more
importantly, to pursue improvements in model interpretability.

摘要：功能性腦連接體對於破譯認知功能和神經疾病背後的機制至關重要。圖形深度學習模型最近在這個領域獲得極大的歡迎。然而，它們在建模腦連接體的實際效能仍不明確。在這項研究中，我們根據四項涵蓋不同認知和臨床結果的大規模神經影像研究，重新檢視圖形深度學習模型。令人驚訝的是，我們發現訊息聚合機制（圖形深度學習模型的標誌）並不像通常假設的那樣有助於預測效能，反而持續降低效能。為了解決這個問題，我們提出一個混合模型，透過雙路徑結合線性模型與圖形注意力網路，達成穩健的預測和增強的可解釋性，方法是揭露局部和整體的神經連接模式。我們的發現敦促在採用複雜的深度學習模型進行功能性腦連接體分析時保持謹慎，強調需要嚴謹的實驗設計，以建立具體的效能增益，或許更重要的是，追求模型可解釋性的改進。

##### **Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care**
2501.17206v1 by Fengpei Yuan, Nehal Hasnaeen, Ran Zhang, Bryce Bible, Joseph Riley Taylor, Hairong Qi, Fenghui Yao, Xiaopeng Zhao

This study explores a novel approach to advancing dementia care by
integrating socially assistive robotics, reinforcement learning (RL), large
language models (LLMs), and clinical domain expertise within a simulated
environment. This integration addresses the critical challenge of limited
experimental data in socially assistive robotics for dementia care, providing a
dynamic simulation environment that realistically models interactions between
persons living with dementia (PLWDs) and robotic caregivers. The proposed
framework introduces a probabilistic model to represent the cognitive and
emotional states of PLWDs, combined with an LLM-based behavior simulation to
emulate their responses. We further develop and train an adaptive RL system
enabling humanoid robots, such as Pepper, to deliver context-aware and
personalized interactions and assistance based on PLWDs' cognitive and
emotional states. The framework also generalizes to computer-based agents,
highlighting its versatility. Results demonstrate that the RL system, enhanced
by LLMs, effectively interprets and responds to the complex needs of PLWDs,
providing tailored caregiving strategies. This research contributes to
human-computer and human-robot interaction by offering a customizable AI-driven
caregiving platform, advancing understanding of dementia-related challenges,
and fostering collaborative innovation in assistive technologies. The proposed
approach has the potential to enhance the independence and quality of life for
PLWDs while alleviating caregiver burden, underscoring the transformative role
of interaction-focused AI systems in dementia care.

摘要：本研究探索一種創新的方法，透過整合社會輔助機器人、強化學習 (RL)、大型語言模型 (LLM) 和臨床領域專業知識於模擬環境中，以推進失智症照護。這種整合解決了失智症照護中社會輔助機器人實驗數據有限的重大挑戰，提供了一個動態的模擬環境，真實地模擬失智症患者 (PLWD) 和機器人照護者之間的互動。所提出的架構引入了機率模型來表示 PLWD 的認知和情緒狀態，並結合了基於 LLM 的行為模擬來模擬他們的反應。我們進一步開發並訓練了一個適應性 RL 系統，使 Pepper 等人形機器人能夠根據 PLWD 的認知和情緒狀態提供情境感知和個人化的互動和協助。該架構也概括到電腦代理，突顯了它的多功能性。結果表明，由 LLM 增強的 RL 系統有效地解釋和回應 PLWD 的複雜需求，提供量身打造的照護策略。這項研究透過提供一個可自訂的 AI 驅動照護平台，促進對失智症相關挑戰的了解，並促進輔助技術的協作創新，為人機互動和人機互動做出貢獻。所提出的方法有可能提高 PLWD 的獨立性和生活品質，同時減輕照護者的負擔，強調了互動導向 AI 系統在失智症照護中的轉型作用。

##### **Efficient Knowledge Distillation of SAM for Medical Image Segmentation**
2501.16740v1 by Kunal Dasharath Patil, Gowthamaan Palani, Ganapathy Krishnamurthi

The Segment Anything Model (SAM) has set a new standard in interactive image
segmentation, offering robust performance across various tasks. However, its
significant computational requirements limit its deployment in real-time or
resource-constrained environments. To address these challenges, we propose a
novel knowledge distillation approach, KD SAM, which incorporates both encoder
and decoder optimization through a combination of Mean Squared Error (MSE) and
Perceptual Loss. This dual-loss framework captures structural and semantic
features, enabling the student model to maintain high segmentation accuracy
while reducing computational complexity. Based on the model evaluation on
datasets, including Kvasir-SEG, ISIC 2017, Fetal Head Ultrasound, and Breast
Ultrasound, we demonstrate that KD SAM achieves comparable or superior
performance to the baseline models, with significantly fewer parameters. KD SAM
effectively balances segmentation accuracy and computational efficiency, making
it well-suited for real-time medical image segmentation applications in
resource-constrained environments.

摘要：分段任何模型 (SAM) 已在互動式影像分割中樹立新標準，在各項任務中皆能提供穩健的效能。然而，其龐大的運算需求限制了它在即時或資源受限環境中的部署。為了應對這些挑戰，我們提出了一種新穎的知識蒸餾方法，KD SAM，它透過結合均方誤差 (MSE) 和感知損失，將編碼器和解碼器最佳化納入其中。此雙重損失架構擷取結構和語義特徵，讓學生模型能夠在降低運算複雜度的同時，維持高分割準確度。根據在 Kvasir-SEG、ISIC 2017、胎兒頭部超音波和乳房超音波等資料集上的模型評估，我們證明 KD SAM 達到了與基準模型相當或更優異的效能，且參數明顯更少。KD SAM 有效地平衡了分割準確度和運算效率，使其非常適合在資源受限環境中的即時醫學影像分割應用。

##### **VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records**
2501.16672v1 by Philip Chung, Akshay Swaminathan, Alex J. Goodell, Yeasul Kim, S. Momsen Reincke, Lichy Han, Ben Deverett, Mohammad Amin Sadeghi, Abdel-Badih Ariss, Marc Ghanem, David Seong, Andrew A. Lee, Caitlin E. Coombes, Brad Bradshaw, Mahir A. Sufian, Hyo Jung Hong, Teresa P. Nguyen, Mohammad R. Rasouli, Komal Kamra, Mark A. Burbridge, James C. McAvoy, Roya Saffary, Stephen P. Ma, Dev Dash, James Xie, Ellen Y. Wang, Clifford A. Schmiesing, Nigam Shah, Nima Aghaeepour

Methods to ensure factual accuracy of text generated by large language models
(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence
system that combines retrieval-augmented generation and LLM-as-a-Judge to
verify whether LLM-generated text is factually supported by a patient's medical
history based on their electronic health record (EHR). To evaluate this system,
we introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course
narratives from discharge summaries into a set of simple statements with
clinician annotations for whether each statement is supported by the patient's
EHR clinical notes. Whereas highest agreement between clinicians was 88.5%,
VeriFact achieves up to 92.7% agreement when compared to a denoised and
adjudicated average human clinican ground truth, suggesting that VeriFact
exceeds the average clinician's ability to fact-check text against a patient's
medical record. VeriFact may accelerate the development of LLM-based EHR
applications by removing current evaluation bottlenecks.

摘要：大型語言模型 (LLM) 在臨床醫學中生成文本的事實準確性，缺乏確保的方法。VeriFact 是一種人工智慧系統，結合了檢索增強生成和 LLM-as-a-Judge，用於驗證 LLM 生成的文本是否基於病人的電子健康記錄 (EHR) 獲得病人的病歷事實支持。為了評估這個系統，我們引入了 VeriFact-BHC，這是一個新的資料集，將出院摘要中的簡要住院病程分解成一組簡單的陳述，並由臨床醫生註解每一個陳述是否獲得病人的 EHR 病歷摘要支持。儘管臨床醫生之間的最高一致性為 88.5%，但與去噪和裁決的平均人類臨床醫生基本事實相比，VeriFact 的一致性高達 92.7%，這表明 VeriFact 超越了平均臨床醫生根據病人的病歷檢查文本事實的能力。VeriFact 可能會透過移除目前的評估瓶頸，加速基於 LLM 的 EHR 應用程式的開發。

##### **Vision-based autonomous structural damage detection using data-driven methods**
2501.16662v2 by Seyyed Taghi Ataei, Parviz Mohammad Zadeh, Saeid Ataei

This study addresses the urgent need for efficient and accurate damage
detection in wind turbine structures, a crucial component of renewable energy
infrastructure. Traditional inspection methods, such as manual assessments and
non-destructive testing (NDT), are often costly, time-consuming, and prone to
human error. To tackle these challenges, this research investigates advanced
deep learning algorithms for vision-based structural health monitoring (SHM). A
dataset of wind turbine surface images, featuring various damage types and
pollution, was prepared and augmented for enhanced model training. Three
algorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed to
detect and classify surface damage. The models were trained and evaluated on a
dataset split into training, testing, and evaluation subsets (80%-10%-10%).
Results indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50
and high processing speed, making it suitable for real-time inspections. By
optimizing hyperparameters like learning rate and batch size, the models'
accuracy and efficiency improved further. YOLOv7 demonstrated significant
advancements in detection precision and execution speed, especially for
real-time applications. However, challenges such as dataset limitations and
environmental variability were noted, suggesting future work on segmentation
methods and larger datasets. This research underscores the potential of
vision-based deep learning techniques to transform SHM practices by reducing
costs, enhancing safety, and improving reliability, thus contributing to the
sustainable maintenance of critical infrastructure and supporting the longevity
of wind energy systems.

摘要：本研究解決了風力渦輪機結構中迫切需要的有效且準確的損傷檢測，這是可再生能源基礎設施的關鍵組成部分。傳統的檢查方法，例如手動評估和非破壞性檢測 (NDT)，通常成本高昂、耗時且容易出錯。為了應對這些挑戰，本研究調查了用於基於視覺的結構健康監測 (SHM) 的先進深度學習演算法。準備了一組風力渦輪機表面影像的資料集，其中包含各種損壞類型和污染，並擴充了增強模型訓練。採用了三種演算法——YOLOv7、其輕量級變體和 Faster R-CNN——來檢測和分類表面損壞。這些模型在分割成訓練、測試和評估子集（80%-10%-10%）的資料集上進行訓練和評估。結果表明，YOLOv7 優於其他演算法，實現了 82.4% 的 mAP@50 和較高的處理速度，使其適用於即時檢查。通過最佳化學習率和批次大小等超參數，模型的準確性和效率進一步提高。YOLOv7 在檢測精度和執行速度方面表現出顯著的進步，特別是對於即時應用程式。然而，注意到資料集限制和環境變異性等挑戰，這表明未來在分割方法和更大的資料集方面的工作。本研究強調了基於視覺的深度學習技術在轉換 SHM 實務方面的潛力，方法是降低成本、增強安全性並提高可靠性，從而有助於維護關鍵基礎設施的可持續性並支持風能系統的長壽命。

##### **Molecular-driven Foundation Model for Oncologic Pathology**
2501.16652v1 by Anurag Vaidya, Andrew Zhang, Guillaume Jaume, Andrew H. Song, Tong Ding, Sophia J. Wagner, Ming Y. Lu, Paul Doucet, Harry Robertson, Cristina Almagro-Perez, Richard J. Chen, Dina ElHarouni, Georges Ayoub, Connor Bossi, Keith L. Ligon, Georg Gerber, Long Phi Le, Faisal Mahmood

Foundation models are reshaping computational pathology by enabling transfer
learning, where models pre-trained on vast datasets can be adapted for
downstream diagnostic, prognostic, and therapeutic response tasks. Despite
these advances, foundation models are still limited in their ability to encode
the entire gigapixel whole-slide images without additional training and often
lack complementary multimodal data. Here, we introduce Threads, a slide-level
foundation model capable of generating universal representations of whole-slide
images of any size. Threads was pre-trained using a multimodal learning
approach on a diverse cohort of 47,171 hematoxylin and eosin (H&E)-stained
tissue sections, paired with corresponding genomic and transcriptomic profiles
- the largest such paired dataset to be used for foundation model development
to date. This unique training paradigm enables Threads to capture the tissue's
underlying molecular composition, yielding powerful representations applicable
to a wide array of downstream tasks. In extensive benchmarking across 54
oncology tasks, including clinical subtyping, grading, mutation prediction,
immunohistochemistry status determination, treatment response prediction, and
survival prediction, Threads outperformed all baselines while demonstrating
remarkable generalizability and label efficiency. It is particularly well
suited for predicting rare events, further emphasizing its clinical utility. We
intend to make the model publicly available for the broader community.

摘要：基礎模型透過啟用轉移學習來重塑計算病理學，其中預先在龐大資料集上訓練的模型可適應於下游診斷、預後和治療反應任務。儘管有這些進展，基礎模型在編碼整個千兆像素全幻燈片影像的能力上仍有限，且經常缺乏補充多模式資料。在此，我們介紹 Threads，這是一個幻燈片層級基礎模型，能夠產生任何大小的全幻燈片影像的通用表示。Threads 使用多模式學習方法預先訓練，並針對 47,171 個蘇木精和曙紅 (H&E) 染色的組織切片的多元群組進行訓練，並搭配對應的基因體和轉錄組特徵檔，這是迄今為止用於基礎模型開發的最大此類配對資料集。這種獨特的訓練範例使 Threads 能夠擷取組織的基礎分子組成，產生強大的表示，適用於廣泛的下游任務。在涵蓋 54 個腫瘤學任務的廣泛基準測試中，包括臨床分型、分級、突變預測、免疫組織化學狀態判定、治療反應預測和存活預測，Threads 優於所有基準，同時展現出顯著的概括性和標籤效率。它特別適合預測罕見事件，進一步強調其臨床效用。我們打算讓該模型公開，供更廣泛的社群使用。

##### **Restless Multi-armed Bandits under Frequency and Window Constraints for Public Service Inspections**
2502.00045v1 by Yi Mao, Andrew Perrault

Municipal inspections are an important part of maintaining the quality of
goods and services. In this paper, we approach the problem of intelligently
scheduling service inspections to maximize their impact, using the case of food
establishment inspections in Chicago as a case study. The Chicago Department of
Public Health (CDPH) inspects thousands of establishments each year, with a
substantial fail rate (over 3,000 failed inspection reports in 2023). To
balance the objectives of ensuring adherence to guidelines, minimizing
disruption to establishments, and minimizing inspection costs, CDPH assigns
each establishment an inspection window every year and guarantees that they
will be inspected exactly once during that window. These constraints create a
challenge for a restless multi-armed bandit (RMAB) approach, for which there
are no existing methods. We develop an extension to Whittle index-based systems
for RMABs that can guarantee action window constraints and frequencies, and
furthermore can be leveraged to optimize action window assignments themselves.
Briefly, we combine MDP reformulation and integer programming-based lookahead
to maximize the impact of inspections subject to constraints. A neural
network-based supervised learning model is developed to model state transitions
of real Chicago establishments using public CDPH inspection records, which
demonstrates 10\% AUC improvements compared with directly predicting
establishments' failures. Our experiments not only show up to 24\% (in
simulation) or 33\% (on real data) reward improvements resulting from our
approach but also give insight into the impact of scheduling constraints.

摘要：市政檢查是維持商品和服務品質的重要一環。在本文中，我們以芝加哥的食品機構檢查為案例研究，探討如何透過智慧排程服務檢查以最大化其影響力。芝加哥公共衛生部 (CDPH) 每年檢查數千家機構，且有相當高的不合格率（2023 年有超過 3,000 份不合格檢查報告）。為了平衡確保遵循準則、最大程度減少對機構的干擾和最大程度減少檢查成本的目標，CDPH 每年為每家機構分配一個檢查時段，並保證在該時段內只檢查一次。這些限制對不間斷多臂賭博機 (RMAB) 方法構成挑戰，目前尚無現有方法。我們針對 RMAB 的 Whittle 指數系統開發了一個延伸，可以保證動作時段限制和頻率，此外還可以利用它來優化動作時段分配本身。簡而言之，我們結合 MDP 重新制定和基於整數規劃的前瞻性，以最大化符合限制條件的檢查影響。使用公開的 CDPH 檢查記錄開發了一個基於神經網路的監督式學習模型，用於模擬芝加哥實際機構的狀態轉換，與直接預測機構的失敗相比，顯示出 AUC 提升了 10%。我們的實驗不僅顯示我們的做法帶來的獎勵提升高達 24%（模擬中）或 33%（實際資料中），還深入了解了排程限制的影響。

##### **Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models**
2501.16282v1 by Jing Zhang, Xiaowei Yu, Yanjun Lyu, Lu Zhang, Tong Chen, Chao Cao, Yan Zhuang, Minheng Chen, Tianming Liu, Dajiang Zhu

Understanding brain disorders is crucial for accurate clinical diagnosis and
treatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a
promising approach to interpreting medical images with the support of text
descriptions. However, previous research has primarily focused on 2D medical
images, leaving richer spatial information of 3D images under-explored, and
single-modality-based methods are limited by overlooking the critical clinical
information contained in other modalities. To address this issue, this paper
proposes Brain-Adapter, a novel approach that incorporates an extra bottleneck
layer to learn new knowledge and instill it into the original pre-trained
knowledge. The major idea is to incorporate a lightweight bottleneck layer to
train fewer parameters while capturing essential information and utilize a
Contrastive Language-Image Pre-training (CLIP) strategy to align multimodal
data within a unified representation space. Extensive experiments demonstrated
the effectiveness of our approach in integrating multimodal data to
significantly improve the diagnosis accuracy without high computational costs,
highlighting the potential to enhance real-world diagnostic workflows.

摘要：了解腦部疾病對於準確的臨床診斷和治療至關重要。多模態大型語言模型 (MLLM) 的最新進展提供了一個有前途的方法，可以在文本描述的支援下詮釋醫學影像。然而，先前的研究主要集中在 2D 醫學影像，忽略了 3D 影像更豐富的空間資訊，而單一模態方法受到忽視其他模態中關鍵臨床資訊的限制。為了解決這個問題，本文提出了 Brain-Adapter，這是一種新的方法，它結合了一個額外的瓶頸層來學習新知識並將其灌輸到原始預訓練的知識中。主要的想法是結合一個輕量級瓶頸層，在擷取必要資訊的同時訓練較少的參數，並利用對比語言影像預訓練 (CLIP) 策略在統一的表示空間中對齊多模態資料。廣泛的實驗證明了我們的方法在整合多模態資料以顯著提高診斷準確性方面的有效性，而不會造成高運算成本，突顯了增強真實世界診斷工作流程的潛力。

##### **Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models**
2501.16215v1 by Huayu Li, Xiwen Chen, Ci Zhang, Stuart F. Quan, William D. S. Killgore, Shu-Fen Wung, Chen X. Chen, Geng Yuan, Jin Lu, Ao Li

Large language models (LLMs) exhibit remarkable capabilities in visual
inspection of medical time-series data, achieving proficiency comparable to
human clinicians. However, their broad scope limits domain-specific precision,
and proprietary weights hinder fine-tuning for specialized datasets. In
contrast, small specialized models (SSMs) excel in targeted tasks but lack the
contextual reasoning required for complex clinical decision-making. To address
these challenges, we propose ConMIL (Conformalized Multiple Instance Learning),
a decision-support SSM that integrates seamlessly with LLMs. By using Multiple
Instance Learning (MIL) to identify clinically significant signal segments and
conformal prediction for calibrated set-valued outputs, ConMIL enhances LLMs'
interpretative capabilities for medical time-series analysis. Experimental
results demonstrate that ConMIL significantly improves the performance of
state-of-the-art LLMs, such as ChatGPT4.0 and Qwen2-VL-7B. Specifically,
\ConMIL{}-supported Qwen2-VL-7B achieves 94.92% and 96.82% precision for
confident samples in arrhythmia detection and sleep staging, compared to
standalone LLM accuracy of 46.13% and 13.16%. These findings highlight the
potential of ConMIL to bridge task-specific precision and broader contextual
reasoning, enabling more reliable and interpretable AI-driven clinical decision
support.

摘要：大型語言模型 (LLM) 在醫療時間序列資料的視覺檢查中展現出非凡的能力，達到了與人類臨床醫生相當的熟練度。然而，它們的廣泛範圍限制了特定領域的精確度，而專有權重阻礙了針對特定資料集的微調。相比之下，小型專用模型 (SSM) 在目標任務中表現出色，但缺乏複雜臨床決策制定所需的背景推理。為了應對這些挑戰，我們提出了 ConMIL（共形多實例學習），這是一個與 LLM 無縫整合的決策支援 SSM。透過使用多實例學習 (MIL) 來識別臨床顯著訊號區段，並對校準的集合值輸出進行共形預測，ConMIL 增強了 LLM 對醫療時間序列分析的解釋能力。實驗結果表明，ConMIL 明顯改善了最先進 LLM 的效能，例如 ChatGPT4.0 和 Qwen2-VL-7B。具體來說，\ConMIL{}- 支援的 Qwen2-VL-7B 在心律不整偵測和睡眠分期中，對於有信心的樣本達到了 94.92% 和 96.82% 的精確度，而獨立 LLM 的準確度僅為 46.13% 和 13.16%。這些發現突顯了 ConMIL 在橋接特定任務的精確度和更廣泛的背景推理方面的潛力，從而實現更可靠且可解釋的 AI 驅動臨床決策支援。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-07**|**MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison**|Kaijie Zhu et.al.|[2502.05174v1](http://arxiv.org/abs/2502.05174v1)|null|
|**2025-02-07**|**Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient**|Jan Ludziejewski et.al.|[2502.05172v1](http://arxiv.org/abs/2502.05172v1)|null|
|**2025-02-07**|**Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach**|Jonas Geiping et.al.|[2502.05171v1](http://arxiv.org/abs/2502.05171v1)|null|
|**2025-02-07**|**NoLiMa: Long-Context Evaluation Beyond Literal Matching**|Ali Modarressi et.al.|[2502.05167v1](http://arxiv.org/abs/2502.05167v1)|null|
|**2025-02-07**|**DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails**|Yihe Deng et.al.|[2502.05163v1](http://arxiv.org/abs/2502.05163v1)|null|
|**2025-02-07**|**A Lightweight Method to Disrupt Memorized Sequences in LLM**|Parjanya Prajakta Prashant et.al.|[2502.05159v1](http://arxiv.org/abs/2502.05159v1)|null|
|**2025-02-07**|**Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation**|Steffen Eger et.al.|[2502.05151v1](http://arxiv.org/abs/2502.05151v1)|null|
|**2025-02-07**|**CodeSCM: Causal Analysis for Multi-Modal Code Generation**|Mukur Gupta et.al.|[2502.05150v1](http://arxiv.org/abs/2502.05150v1)|null|
|**2025-02-07**|**An Annotated Reading of 'The Singer of Tales' in the LLM Era**|Kush R. Varshney et.al.|[2502.05148v1](http://arxiv.org/abs/2502.05148v1)|null|
|**2025-02-07**|**LP-DETR: Layer-wise Progressive Relations for Object Detection**|Zhengjian Kang et.al.|[2502.05147v1](http://arxiv.org/abs/2502.05147v1)|null|
|**2025-02-07**|**Latent Swap Joint Diffusion for Long-Form Audio Generation**|Yusheng Dai et.al.|[2502.05130v1](http://arxiv.org/abs/2502.05130v1)|null|
|**2025-02-07**|**"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**|Shihan Fu et.al.|[2502.05115v1](http://arxiv.org/abs/2502.05115v1)|null|
|**2025-02-07**|**GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application**|Volker Emmrich et.al.|[2502.05113v1](http://arxiv.org/abs/2502.05113v1)|null|
|**2025-02-07**|**Flexible and Efficient Grammar-Constrained Decoding**|Kanghee Park et.al.|[2502.05111v1](http://arxiv.org/abs/2502.05111v1)|null|
|**2025-02-07**|**ApplE: An Applied Ethics Ontology with Event Context**|Aisha Aijaz et.al.|[2502.05110v1](http://arxiv.org/abs/2502.05110v1)|null|
|**2025-02-07**|**Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types**|Muhammad Umair Danish et.al.|[2502.05104v1](http://arxiv.org/abs/2502.05104v1)|null|
|**2025-02-07**|**Learning Temporal Invariance in Android Malware Detectors**|Xinran Zheng et.al.|[2502.05098v1](http://arxiv.org/abs/2502.05098v1)|null|
|**2025-02-07**|**Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs**|Rohit Saxena et.al.|[2502.05092v1](http://arxiv.org/abs/2502.05092v1)|null|
|**2025-02-07**|**Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**|Thierry Bossy et.al.|[2502.05087v1](http://arxiv.org/abs/2502.05087v1)|null|
|**2025-02-07**|**Causality can systematically address the monsters under the bench(marks)**|Felix Leeb et.al.|[2502.05085v1](http://arxiv.org/abs/2502.05085v1)|null|
|**2025-02-07**|**ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework**|Xiaoyu Deng et.al.|[2502.05084v1](http://arxiv.org/abs/2502.05084v1)|null|
|**2025-02-07**|**Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**|Tushar Pandey et.al.|[2502.05078v1](http://arxiv.org/abs/2502.05078v1)|null|
|**2025-02-07**|**Paying Attention to Facts: Quantifying the Knowledge Capacity of Attention Layers**|Liang Ze Wong et.al.|[2502.05076v1](http://arxiv.org/abs/2502.05076v1)|null|
|**2025-02-07**|**Preference-aware compensation policies for crowdsourced on-demand services**|Georgina Nouli et.al.|[2502.05060v1](http://arxiv.org/abs/2502.05060v1)|null|
|**2025-02-07**|**Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks**|Yohannis Kifle Telila et.al.|[2502.05041v1](http://arxiv.org/abs/2502.05041v1)|null|
|**2025-02-07**|**nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow**|Geliang Ouyang et.al.|[2502.05036v1](http://arxiv.org/abs/2502.05036v1)|null|
|**2025-02-07**|**Analyzing Advanced AI Systems Against Definitions of Life and Consciousness**|Azadeh Alavi et.al.|[2502.05007v1](http://arxiv.org/abs/2502.05007v1)|null|
|**2025-02-07**|**A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach**|Taiyi Wang et.al.|[2502.05001v1](http://arxiv.org/abs/2502.05001v1)|null|
|**2025-02-07**|**Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification**|Jiayi Luo et.al.|[2502.05000v1](http://arxiv.org/abs/2502.05000v1)|null|
|**2025-02-07**|**Aligning Black-box Language Models with Human Judgments**|Gerrit J. J. van den Burg et.al.|[2502.04997v1](http://arxiv.org/abs/2502.04997v1)|null|
|**2025-02-07**|**CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs**|Roman Vashurin et.al.|[2502.04964v1](http://arxiv.org/abs/2502.04964v1)|null|
|**2025-02-07**|**Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction**|Jianshu Zhang et.al.|[2502.04963v1](http://arxiv.org/abs/2502.04963v1)|null|
|**2025-02-07**|**Commonality and Individuality! Integrating Humor Commonality with Speaker Individuality for Humor Recognition**|Haohao Zhu et.al.|[2502.04960v1](http://arxiv.org/abs/2502.04960v1)|null|
|**2025-02-07**|**SSMLoRA: Enhancing Low-Rank Adaptation with State Space Model**|Jiayang Yu et.al.|[2502.04958v1](http://arxiv.org/abs/2502.04958v1)|null|
|**2025-02-07**|**Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics**|Herbert Ullrich et.al.|[2502.04955v1](http://arxiv.org/abs/2502.04955v1)|null|
|**2025-02-07**|**The Rising Threat to Emerging AI-Powered Search Engines**|Zeren Luo et.al.|[2502.04951v1](http://arxiv.org/abs/2502.04951v1)|null|
|**2025-02-07**|**Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market**|Ciaran O'Connor et.al.|[2502.04935v1](http://arxiv.org/abs/2502.04935v1)|null|
|**2025-02-07**|**Cached Multi-Lora Composition for Multi-Concept Image Generation**|Xiandong Zou et.al.|[2502.04923v1](http://arxiv.org/abs/2502.04923v1)|null|
|**2025-02-07**|**Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects**|Levente Zólyomi et.al.|[2502.04899v1](http://arxiv.org/abs/2502.04899v1)|null|
|**2025-02-07**|**Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance**|Reihaneh Amooie et.al.|[2502.04883v1](http://arxiv.org/abs/2502.04883v1)|null|
|**2025-02-07**|**pytopicgram: A library for data extraction and topic modeling from Telegram channels**|J. Gómez-Romero et.al.|[2502.04882v1](http://arxiv.org/abs/2502.04882v1)|null|
|**2025-02-07**|**Sparse Autoencoders Do Not Find Canonical Units of Analysis**|Patrick Leask et.al.|[2502.04878v1](http://arxiv.org/abs/2502.04878v1)|null|
|**2025-02-07**|**Enhancing Disinformation Detection with Explainable AI and Named Entity Replacement**|Santiago González-Silot et.al.|[2502.04863v1](http://arxiv.org/abs/2502.04863v1)|null|
|**2025-02-07**|**Lightweight Operations for Visual Speech Recognition**|Iason Ioannis Panagos et.al.|[2502.04834v1](http://arxiv.org/abs/2502.04834v1)|null|
|**2025-02-07**|**Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization**|Yedidya Kfir et.al.|[2502.04829v1](http://arxiv.org/abs/2502.04829v1)|null|
|**2025-02-07**|**Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks**|Jing Yang et.al.|[2502.04797v1](http://arxiv.org/abs/2502.04797v1)|null|
|**2025-02-07**|**Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition**|Masato Mita et.al.|[2502.04795v1](http://arxiv.org/abs/2502.04795v1)|null|
|**2025-02-07**|**MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**|Minrui Chen et.al.|[2502.04794v1](http://arxiv.org/abs/2502.04794v1)|null|
|**2025-02-07**|**S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency**|Yuting Zeng et.al.|[2502.04790v1](http://arxiv.org/abs/2502.04790v1)|null|
|**2025-02-07**|**Probing Internal Representations of Multi-Word Verbs in Large Language Models**|Hassane Kissane et.al.|[2502.04789v1](http://arxiv.org/abs/2502.04789v1)|null|
|**2025-02-07**|**Enhancing SQL Injection Detection and Prevention Using Generative Models**|Naga Sai Dasari et.al.|[2502.04786v1](http://arxiv.org/abs/2502.04786v1)|null|
|**2025-02-07**|**SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning**|Wanjia Zhao et.al.|[2502.04780v1](http://arxiv.org/abs/2502.04780v1)|null|
|**2025-02-07**|**Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning**|Chen-Xiao Gao et.al.|[2502.04778v1](http://arxiv.org/abs/2502.04778v1)|null|
|**2025-02-07**|**SeDi-Instruct: Enhancing Alignment of Language Models through Self-Directed Instruction Generation**|Jungwoo Kim et.al.|[2502.04774v1](http://arxiv.org/abs/2502.04774v1)|null|
|**2025-02-07**|**DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences**|Chao Feng et.al.|[2502.04771v1](http://arxiv.org/abs/2502.04771v1)|null|
|**2025-02-07**|**Graph Federated Learning Based Proactive Content Caching in Edge Computing**|Rui Wang et.al.|[2502.04760v1](http://arxiv.org/abs/2502.04760v1)|null|
|**2025-02-07**|**Enhancing Phishing Email Identification with Large Language Models**|Catherine Lee et.al.|[2502.04759v1](http://arxiv.org/abs/2502.04759v1)|null|
|**2025-02-07**|**ELITE: Enhanced Language-Image Toxicity Evaluation for Safety**|Wonjun Lee et.al.|[2502.04757v1](http://arxiv.org/abs/2502.04757v1)|null|
|**2025-02-07**|**Concept Navigation and Classification via Open Source Large Language Model Processing**|Maël Kubli et.al.|[2502.04756v1](http://arxiv.org/abs/2502.04756v1)|null|
|**2025-02-07**|**Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking**|Ruiyang Ren et.al.|[2502.04751v1](http://arxiv.org/abs/2502.04751v1)|null|
|**2025-02-07**|**Every Software as an Agent: Blueprint and Case Study**|Mengwei Xu et.al.|[2502.04747v1](http://arxiv.org/abs/2502.04747v1)|null|
|**2025-02-07**|**The "negative end" of change in grammar: terminology, concepts and causes**|Karolina Rudnicka et.al.|[2502.04729v1](http://arxiv.org/abs/2502.04729v1)|null|
|**2025-02-07**|**Generating Symbolic World Models via Test-time Scaling of Large Language Models**|Zhouliang Yu et.al.|[2502.04728v1](http://arxiv.org/abs/2502.04728v1)|[link](https://github.com/VMLPDDL/VML_PDDL)|
|**2025-02-07**|**Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?**|Yujin Han et.al.|[2502.04725v1](http://arxiv.org/abs/2502.04725v1)|null|
|**2025-02-07**|**Evaluating Text Style Transfer Evaluation: Are There Any Reliable Metrics?**|Sourabrata Mukherjee et.al.|[2502.04718v1](http://arxiv.org/abs/2502.04718v1)|null|
|**2025-02-07**|**Enhancing Impression Change Prediction in Speed Dating Simulations Based on Speakers' Personalities**|Kazuya Matsuo et.al.|[2502.04706v1](http://arxiv.org/abs/2502.04706v1)|null|
|**2025-02-07**|**EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference**|Prakhar Kaushik et.al.|[2502.04700v1](http://arxiv.org/abs/2502.04700v1)|null|
|**2025-02-07**|**Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance**|Pratinav Seth et.al.|[2502.04695v1](http://arxiv.org/abs/2502.04695v1)|null|
|**2025-02-07**|**ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning**|Yuwei Yin et.al.|[2502.04689v1](http://arxiv.org/abs/2502.04689v1)|[link](https://github.com/YuweiYin/ARR)|
|**2025-02-07**|**M-IFEval: Multilingual Instruction-Following Evaluation**|Antoine Dussolle et.al.|[2502.04688v1](http://arxiv.org/abs/2502.04688v1)|null|
|**2025-02-07**|**Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization**|Zelai Xu et.al.|[2502.04686v1](http://arxiv.org/abs/2502.04686v1)|null|
|**2025-02-07**|**G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models**|Mengdi Liu et.al.|[2502.04684v1](http://arxiv.org/abs/2502.04684v1)|null|
|**2025-02-07**|**AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts**|Soichiro Murakami et.al.|[2502.04674v1](http://arxiv.org/abs/2502.04674v1)|null|
|**2025-02-07**|**${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving**|Amitayush Thakur et.al.|[2502.04671v1](http://arxiv.org/abs/2502.04671v1)|null|
|**2025-02-07**|**CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation**|Bowen Song et.al.|[2502.04670v1](http://arxiv.org/abs/2502.04670v1)|null|
|**2025-02-07**|**A Comprehensive Review on Noise Control of Diffusion Model**|Zhehao Guo et.al.|[2502.04669v1](http://arxiv.org/abs/2502.04669v1)|null|
|**2025-02-07**|**Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization**|Xinhao Yao et.al.|[2502.04667v1](http://arxiv.org/abs/2502.04667v1)|null|
|**2025-02-07**|**Shifting Attention to You: Personalized Brain-Inspired AI Models**|Stephen Chong Zhao et.al.|[2502.04658v1](http://arxiv.org/abs/2502.04658v1)|null|
|**2025-02-07**|**Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement**|Lin Tian et.al.|[2502.04655v1](http://arxiv.org/abs/2502.04655v1)|null|
|**2025-02-07**|**Importance Sampling via Score-based Generative Models**|Heasung Kim et.al.|[2502.04646v1](http://arxiv.org/abs/2502.04646v1)|null|
|**2025-02-07**|**Cross-Encoder Rediscovers a Semantic Variant of BM25**|Meng Lu et.al.|[2502.04645v1](http://arxiv.org/abs/2502.04645v1)|null|
|**2025-02-07**|**Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**|Junde Wu et.al.|[2502.04644v1](http://arxiv.org/abs/2502.04644v1)|null|
|**2025-02-07**|**Confidence Elicitation: A New Attack Vector for Large Language Models**|Brian Formento et.al.|[2502.04643v1](http://arxiv.org/abs/2502.04643v1)|null|
|**2025-02-07**|**Extracting and Understanding the Superficial Knowledge in Alignment**|Runjin Chen et.al.|[2502.04602v1](http://arxiv.org/abs/2502.04602v1)|null|
|**2025-02-07**|**The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance**|Mohammad Reza Rezaei et.al.|[2502.04593v1](http://arxiv.org/abs/2502.04593v1)|null|
|**2025-02-07**|**CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements**|Yang Zhang et.al.|[2502.04592v1](http://arxiv.org/abs/2502.04592v1)|null|
|**2025-02-07**|**Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective**|Piero Deidda et.al.|[2502.04591v1](http://arxiv.org/abs/2502.04591v1)|null|
|**2025-02-07**|**Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context**|Taejong Joo et.al.|[2502.04580v1](http://arxiv.org/abs/2502.04580v1)|null|
|**2025-02-07**|**Position-aware Automatic Circuit Discovery**|Tal Haklay et.al.|[2502.04577v1](http://arxiv.org/abs/2502.04577v1)|null|
|**2025-02-07**|**Self-Regulation and Requesting Interventions**|So Yeon Min et.al.|[2502.04576v1](http://arxiv.org/abs/2502.04576v1)|null|
|**2025-02-06**|**Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer**|Yulun Wu et.al.|[2502.04573v1](http://arxiv.org/abs/2502.04573v1)|null|
|**2025-02-06**|**Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator**|Zhuotong Chen et.al.|[2502.04567v1](http://arxiv.org/abs/2502.04567v1)|null|
|**2025-02-06**|**My LLM might Mimic AAE -- But When Should it?**|Sandra C. Sandoval et.al.|[2502.04564v1](http://arxiv.org/abs/2502.04564v1)|null|
|**2025-02-06**|**WaferLLM: A Wafer-Scale LLM Inference System**|Congjie He et.al.|[2502.04563v1](http://arxiv.org/abs/2502.04563v1)|null|
|**2025-02-06**|**Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture**|Hong Lu et.al.|[2502.04558v1](http://arxiv.org/abs/2502.04558v1)|null|
|**2025-02-06**|**TruthFlow: Truthful LLM Generation via Representation Flow Correction**|Hanyu Wang et.al.|[2502.04556v1](http://arxiv.org/abs/2502.04556v1)|null|
|**2025-02-06**|**Unifying and Optimizing Data Values for Selection via Sequential-Decision-Making**|Hongliang Chi et.al.|[2502.04554v1](http://arxiv.org/abs/2502.04554v1)|null|
|**2025-02-06**|**Contextual Gradient Flow Modeling for Large Language Model Generalization in Multi-Scale Feature Spaces**|Daphne Quillington et.al.|[2502.04548v1](http://arxiv.org/abs/2502.04548v1)|null|
|**2025-02-06**|**Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation**|Chenyang Huang et.al.|[2502.04537v1](http://arxiv.org/abs/2502.04537v1)|null|
|**2025-02-06**|**A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers**|Chenyang Huang et.al.|[2502.04535v1](http://arxiv.org/abs/2502.04535v1)|null|

#### Abstracts
##### **MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison**
2502.05174v1 by Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang

Recent research has explored that LLM agents are vulnerable to indirect
prompt injection (IPI) attacks, where malicious tasks embedded in
tool-retrieved information can redirect the agent to take unauthorized actions.
Existing defenses against IPI have significant limitations: either require
essential model training resources, lack effectiveness against sophisticated
attacks, or harm the normal utilities. We present MELON (Masked re-Execution
and TooL comparisON), a novel IPI defense. Our approach builds on the
observation that under a successful attack, the agent's next action becomes
less dependent on user tasks and more on malicious tasks. Following this, we
design MELON to detect attacks by re-executing the agent's trajectory with a
masked user prompt modified through a masking function. We identify an attack
if the actions generated in the original and masked executions are similar. We
also include three key designs to reduce the potential false positives and
false negatives. Extensive evaluation on the IPI benchmark AgentDojo
demonstrates that MELON outperforms SOTA defenses in both attack prevention and
utility preservation. Moreover, we show that combining MELON with a SOTA prompt
augmentation defense (denoted as MELON-Aug) further improves its performance.
We also conduct a detailed ablation study to validate our key designs.

摘要：近期研究探索出 LLM 代理容易受到间接提示注入 (IPI) 攻击，其中嵌入在工具检索信息中的恶意任务会将代理重定向到执行未经授权的操作。现有的针对 IPI 的防御措施有很大的局限性：要么需要基本的模型训练资源，要么缺乏对复杂攻击的有效性，要么损害正常的实用程序。我们提出了 MELON（掩码重新执行和工具比较），一种新颖的 IPI 防御措施。我们的方法建立在这样的观察之上：在成功的攻击下，代理的下一步行动变得不再依赖于用户任务，而更多地依赖于恶意任务。在此之后，我们设计 MELON 通过重新执行代理的轨迹来检测攻击，该轨迹通过掩码函数修改了掩码的用户提示。如果在原始执行和掩码执行中生成的操作相似，我们就会识别出攻击。我们还包括三个关键设计来减少潜在的误报和漏报。在 IPI 基准 AgentDojo 上进行的广泛评估表明，MELON 在攻击预防和实用程序保留方面都优于 SOTA 防御措施。此外，我们表明将 MELON 与 SOTA 提示增强防御措施（表示为 MELON-Aug）相结合可以进一步提高其性能。我们还进行了详细的消融研究来验证我们的关键设计。

##### **Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient**
2502.05172v1 by Jan Ludziejewski, Maciej Pióro, Jakub Krajewski, Maciej Stefaniak, Michał Krutul, Jan Małaśnicki, Marek Cygan, Piotr Sankowski, Kamil Adamczewski, Piotr Miłoś, Sebastian Jaszczur

Mixture of Experts (MoE) architectures have significantly increased
computational efficiency in both research and real-world applications of
large-scale machine learning models. However, their scalability and efficiency
under memory constraints remain relatively underexplored. In this work, we
present joint scaling laws for dense and MoE models, incorporating key factors
such as the number of active parameters, dataset size, and the number of
experts. Our findings provide a principled framework for selecting the optimal
MoE configuration under fixed memory and compute budgets. Surprisingly, we show
that MoE models can be more memory-efficient than dense models, contradicting
conventional wisdom. To derive and validate the theoretical predictions of our
scaling laws, we conduct over 280 experiments with up to 2.7B active parameters
and up to 5B total parameters. These results offer actionable insights for
designing and deploying MoE models in practical large-scale training scenarios.

摘要：專家混合 (MoE) 架構已顯著提升研究和大型機器學習模型的實際應用中的運算效率。然而，它們在記憶體限制下的可擴充性和效率仍相對未被充分探討。在這項工作中，我們提出稠密和 MoE 模型的聯合擴充法則，納入關鍵因素，例如活動參數數量、資料集大小和專家數量。我們的研究結果提供了一個基於原則的架構，用於在固定的記憶體和運算預算下選擇最佳的 MoE 組態。令人驚訝的是，我們發現 MoE 模型可以比稠密模型更省記憶體，這與傳統觀念相矛盾。為了推導和驗證我們擴充法則的理論預測，我們進行了超過 280 個實驗，使用多達 2.7B 個活動參數和多達 5B 個總參數。這些結果為在實際的大規模訓練場景中設計和部署 MoE 模型提供了可行的見解。

##### **Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach**
2502.05171v1 by Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Tom Goldstein

We study a novel language model architecture that is capable of scaling
test-time computation by implicitly reasoning in latent space. Our model works
by iterating a recurrent block, thereby unrolling to arbitrary depth at
test-time. This stands in contrast to mainstream reasoning models that scale up
compute by producing more tokens. Unlike approaches based on chain-of-thought,
our approach does not require any specialized training data, can work with
small context windows, and can capture types of reasoning that are not easily
represented in words. We scale a proof-of-concept model to 3.5 billion
parameters and 800 billion tokens. We show that the resulting model can improve
its performance on reasoning benchmarks, sometimes dramatically, up to a
computation load equivalent to 50 billion parameters.

摘要：我們研究了一種新穎的語言模型架構，它能夠通過在潛在空間中進行隱式推理來擴展測試時間計算。我們的模型通過迭代遞迴塊來工作，從而將測試時間展開到任意深度。這與通過產生更多令牌來擴展計算的主流推理模型形成對比。與基於思維鏈的方法不同，我們的方法不需要任何專門的訓練數據，可以使用小上下文窗口，並且可以捕捉到不容易用文字表示的推理類型。我們將概念驗證模型擴展到 35 億個參數和 8000 億個令牌。我們表明，生成的模型可以提高其在推理基準測試上的性能，有時會顯著提高，計算負載相當於 500 億個參數。

##### **NoLiMa: Long-Context Evaluation Beyond Literal Matching**
2502.05167v1 by Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Trung Bui, Ryan A. Rossi, Seunghyun Yoon, Hinrich Schütze

Recent large language models (LLMs) support long contexts ranging from 128K
to 1M tokens. A popular method for evaluating these capabilities is the
needle-in-a-haystack (NIAH) test, which involves retrieving a "needle"
(relevant information) from a "haystack" (long irrelevant context). Extensions
of this approach include increasing distractors, fact chaining, and in-context
reasoning. However, in these benchmarks, models can exploit existing literal
matches between the needle and haystack to simplify the task. To address this,
we introduce NoLiMa, a benchmark extending NIAH with a carefully designed
needle set, where questions and needles have minimal lexical overlap, requiring
models to infer latent associations to locate the needle within the haystack.
We evaluate 12 popular LLMs that claim to support contexts of at least 128K
tokens. While they perform well in short contexts (<1K), performance degrades
significantly as context length increases. At 32K, for instance, 10 models drop
below 50% of their strong short-length baselines. Even GPT-4o, one of the
top-performing exceptions, experiences a reduction from an almost-perfect
baseline of 99.3% to 69.7%. Our analysis suggests these declines stem from the
increased difficulty the attention mechanism faces in longer contexts when
literal matches are absent, making it harder to retrieve relevant information.

摘要：最近的大语言模型（LLM）支持从 128K 到 1M 个标记的较长内容。评估这些功能的一种流行方法是“大海捞针”（NIAH）测试，其中涉及从“干草堆”（冗长的无关内容）中检索“针”（相关信息）。这种方法的扩展包括增加干扰项、事实链接和上下文推理。然而，在这些基准测试中，模型可以利用针和干草堆之间现有的字面匹配来简化任务。为了解决这个问题，我们引入了 NoLiMa，这是一个基准，它用精心设计的针集扩展了 NIAH，其中问题和针的词汇重叠很小，需要模型推断潜在关联才能在干草堆中找到针。我们评估了 12 个流行的 LLM，它们声称支持至少 128K 个标记的内容。虽然它们在较短的内容（<1K）中表现良好，但随着内容长度的增加，性能会显着下降。例如，在 32K 时，10 个模型低于其强劲的短长度基线的 50%。即使是表现最好的例外之一 GPT-4o，也从接近完美的 99.3% 的基线下降到 69.7%。我们的分析表明，这些下降源于当没有字面匹配时，注意机制在较长的内容中面临的困难增加，这使得检索相关信息变得更加困难。

##### **DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails**
2502.05163v1 by Yihe Deng, Yu Yang, Junkai Zhang, Wei Wang, Bo Li

The rapid advancement of large language models (LLMs) has increased the need
for guardrail models to ensure responsible use, particularly in detecting
unsafe and illegal content. While substantial safety data exist in English,
multilingual guardrail modeling remains underexplored due to the scarcity of
open-source safety data in other languages. To address this gap, we propose a
novel two-player Reinforcement Learning (RL) framework, where a generator and a
guardrail model co-evolve adversarially to produce high-quality synthetic data
for multilingual guardrail training. We theoretically formalize this
interaction as a two-player game, proving convergence to a Nash equilibrium.
Empirical evaluations show that our model \ours outperforms state-of-the-art
models, achieving nearly 10% improvement over LlamaGuard3 (8B) on English
benchmarks while being 4.5x faster at inference with a significantly smaller
model (0.5B). We achieve substantial advancements in multilingual safety tasks,
particularly in addressing the imbalance for lower-resource languages in a
collected real dataset. Ablation studies emphasize the critical role of
synthetic data generation in bridging the imbalance in open-source data between
English and other languages. These findings establish a scalable and efficient
approach to synthetic data generation, paving the way for improved multilingual
guardrail models to enhance LLM safety. Code, model, and data will be
open-sourced at https://github.com/yihedeng9/DuoGuard.

摘要：大型語言模型 (LLM) 的快速進展增加了護欄模型的需求，以確保負責任的使用，特別是在偵測不安全和非法內容方面。儘管英語中有大量的安全數據，但由於其他語言中缺乏開源安全數據，多語言護欄建模仍未得到充分探索。為了解決這個差距，我們提出了一個新穎的雙人強化學習 (RL) 框架，其中生成器和護欄模型共同對抗演化，以產生高品質的合成數據，用於多語言護欄訓練。我們在理論上將這種互動形式化為雙人遊戲，證明了收斂到納什均衡。經驗評估表明，我們的模型 \ours 優於最先進的模型，在英語基準測試中比 LlamaGuard3 (8B) 提高了近 10%，同時在推理速度上快 4.5 倍，而模型顯著更小 (0.5B)。我們在多語言安全任務中取得了重大進展，特別是在解決收集到的真實數據集中資源較少語言的不平衡方面。消融研究強調了合成數據生成在彌合英語和其他語言之間開源數據不平衡中的關鍵作用。這些發現建立了一個可擴展且高效的合成數據生成方法，為改進的多語言護欄模型鋪平了道路，以增強 LLM 的安全性。程式碼、模型和數據將在 https://github.com/yihedeng9/DuoGuard 開源。

##### **A Lightweight Method to Disrupt Memorized Sequences in LLM**
2502.05159v1 by Parjanya Prajakta Prashant, Kaustubh Ponkshe, Babak Salimi

Large language models (LLMs) demonstrate impressive capabilities across many
tasks yet risk reproducing copyrighted content verbatim, raising legal and
ethical concerns. Although methods like differential privacy or neuron editing
can reduce memorization, they typically require costly retraining or direct
access to model weights and may degrade performance. To address these
challenges, we propose TokenSwap, a lightweight, post-hoc approach that
replaces the probabilities of grammar-related tokens with those from a small
auxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercial
grade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our method
effectively reduces well-known cases of memorized generation by upto 10x with
little to no impact on downstream tasks. Our approach offers a uniquely
accessible and effective solution to users of real-world systems.

摘要：大型語言模型 (LLM) 在許多任務中展現出令人印象深刻的能力，但卻有逐字複製受版權保護內容的風險，引發法律和道德上的疑慮。儘管微分隱私或神經元編輯等方法可以減少記憶，但它們通常需要代價高昂的重新訓練或直接存取模型權重，並且可能會降低效能。為了應對這些挑戰，我們提出 TokenSwap，這是一種輕量級的後設法，它使用來自小型輔助模型（例如 DistilGPT-2）的機率來取代與語法相關的詞彙機率。我們對 Pythia-6.9b 和 LLaMA-3-8b 等商業級模型進行廣泛的實驗，並證明我們的模型有效地將記憶中產生的已知案例減少多達 10 倍，對下游任務幾乎沒有影響。我們的做法為實際系統的使用者提供了一個獨特且有效的解決方案。

##### **Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation**
2502.05151v1 by Steffen Eger, Yong Cao, Jennifer D'Souza, Andreas Geiger, Christian Greisinger, Stephanie Gross, Yufang Hou, Brigitte Krenn, Anne Lauscher, Yizhi Li, Chenghua Lin, Nafise Sadat Moosavi, Wei Zhao, Tristan Miller

With the advent of large multimodal language models, science is now at a
threshold of an AI-based technological transformation. Recently, a plethora of
new AI models and tools has been proposed, promising to empower researchers and
academics worldwide to conduct their research more effectively and efficiently.
This includes all aspects of the research cycle, especially (1) searching for
relevant literature; (2) generating research ideas and conducting
experimentation; generating (3) text-based and (4) multimodal content (e.g.,
scientific figures and diagrams); and (5) AI-based automatic peer review. In
this survey, we provide an in-depth overview over these exciting recent
developments, which promise to fundamentally alter the scientific research
process for good. Our survey covers the five aspects outlined above, indicating
relevant datasets, methods and results (including evaluation) as well as
limitations and scope for future research. Ethical concerns regarding
shortcomings of these tools and potential for misuse (fake science, plagiarism,
harms to research integrity) take a particularly prominent place in our
discussion. We hope that our survey will not only become a reference guide for
newcomers to the field but also a catalyst for new AI-based initiatives in the
area of "AI4Science".

摘要：隨著大型多模態語言模型的出現，科學現在正處於 AI 基礎科技轉型的門檻上。最近，已經提出許多新的 AI 模型和工具，承諾賦能全球的研究人員和學者更有效率且有效地進行研究。這包含研究週期的所有面向，特別是：(1) 搜尋相關文獻；(2) 產生研究點子和進行實驗；產生 (3) 文字為基礎和 (4) 多模態內容（例如科學圖形和圖表）；以及 (5) AI 基礎的自動同行評審。在此調查中，我們提供這些令人振奮的近期發展的深入概觀，承諾徹底改變科學研究過程。我們的調查涵蓋上述五個面向，指出相關的資料集、方法和結果（包括評量），以及限制和未來研究範圍。關於這些工具的缺點和誤用潛力（假科學、抄襲、危害研究誠信）的道德疑慮，在我們的討論中佔有特別突出的地位。我們希望我們的調查不僅能成為此領域新手的參考指南，也能成為「AI4Science」領域中新的 AI 基礎計畫的催化劑。

##### **CodeSCM: Causal Analysis for Multi-Modal Code Generation**
2502.05150v1 by Mukur Gupta, Noopur Bhatt, Suman Jana

In this paper, we propose CodeSCM, a Structural Causal Model (SCM) for
analyzing multi-modal code generation using large language models (LLMs). By
applying interventions to CodeSCM, we measure the causal effects of different
prompt modalities, such as natural language, code, and input-output examples,
on the model. CodeSCM introduces latent mediator variables to separate the code
and natural language semantics of a multi-modal code generation prompt. Using
the principles of Causal Mediation Analysis on these mediators we quantify
direct effects representing the model's spurious leanings. We find that, in
addition to natural language instructions, input-output examples significantly
influence code generation.

摘要：在本文中，我們提出 CodeSCM，一個結構因果模型 (SCM)，用於分析使用大型語言模型 (LLM) 的多模態程式碼生成。透過對 CodeSCM 應用介入，我們測量了不同提示形式的因果效應，例如自然語言、程式碼和輸入輸出範例，對模型的影響。CodeSCM 引入了潛在中介變數，以分離多模態程式碼生成提示的程式碼和自然語言語義。使用這些中介者的因果中介分析原理，我們量化了代表模型虛假傾向的直接效應。我們發現，除了自然語言指令之外，輸入輸出範例也顯著影響程式碼生成。

##### **An Annotated Reading of 'The Singer of Tales' in the LLM Era**
2502.05148v1 by Kush R. Varshney

The Parry-Lord oral-formulaic theory was a breakthrough in understanding how
oral narrative poetry is learned, composed, and transmitted by illiterate
bards. In this paper, we provide an annotated reading of the mechanism
underlying this theory from the lens of large language models (LLMs) and
generative artificial intelligence (AI). We point out the the similarities and
differences between oral composition and LLM generation, and comment on the
implications to society and AI policy.

摘要：帕里-洛德口頭公式化理論是理解文盲吟遊詩人如何學習、創作和傳遞口頭敘事詩的突破性理論。在本文中，我們從大型語言模型 (LLM) 和生成式人工智慧 (AI) 的角度對此理論背後的機制提供註解性閱讀。我們指出了口頭創作和 LLM 生成之間的相似性和差異，並對社會和 AI 政策的影響發表評論。

##### **LP-DETR: Layer-wise Progressive Relations for Object Detection**
2502.05147v1 by Zhengjian Kang, Ye Zhang, Xiaoyu Deng, Xintao Li, Yongzhe Zhang

This paper presents LP-DETR (Layer-wise Progressive DETR), a novel approach
that enhances DETR-based object detection through multi-scale relation
modeling. Our method introduces learnable spatial relationships between object
queries through a relation-aware self-attention mechanism, which adaptively
learns to balance different scales of relations (local, medium and global)
across decoder layers. This progressive design enables the model to effectively
capture evolving spatial dependencies throughout the detection pipeline.
Extensive experiments on COCO 2017 dataset demonstrate that our method improves
both convergence speed and detection accuracy compared to standard
self-attention module. The proposed method achieves competitive results,
reaching 52.3\% AP with 12 epochs and 52.5\% AP with 24 epochs using ResNet-50
backbone, and further improving to 58.0\% AP with Swin-L backbone. Furthermore,
our analysis reveals an interesting pattern: the model naturally learns to
prioritize local spatial relations in early decoder layers while gradually
shifting attention to broader contexts in deeper layers, providing valuable
insights for future research in object detection.

摘要：本論文提出層級遞進 DETR（Layer-wise Progressive DETR），這是一種透過多尺度關係建模來增強基於 DETR 的物件偵測之新穎方法。我們的模型透過關係感知自我注意機制，引入了物件查詢之間可學習的空間關係，該機制會自適應地學習在解碼器層中平衡不同尺度的關係（局部、中階和全域）。這種遞進式設計讓模型能夠在整個偵測管線中有效捕捉不斷變化的空間依賴性。在 COCO 2017 資料集上進行的廣泛實驗顯示，與標準自我注意模組相比，我們的模型改善了收斂速度和偵測準確度。所提出的方法達到了競爭力的結果，使用 ResNet-50 主幹架構時，在 12 個世代中達到 52.3% AP，在 24 個世代中達到 52.5% AP，使用 Swin-L 主幹架構時進一步提升至 58.0% AP。此外，我們的分析揭示了一個有趣的模式：模型自然會學習在早期的解碼器層中優先考慮局部空間關係，同時逐漸將注意力轉移到較深層中的更廣泛背景，為物件偵測的未來研究提供了寶貴的見解。

##### **Latent Swap Joint Diffusion for Long-Form Audio Generation**
2502.05130v1 by Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao

Previous work on long-form audio generation using global-view diffusion or
iterative generation demands significant training or inference costs. While
recent advancements in multi-view joint diffusion for panoramic generation
provide an efficient option, they struggle with spectrum generation with severe
overlap distortions and high cross-view consistency costs. We initially explore
this phenomenon through the connectivity inheritance of latent maps and uncover
that averaging operations excessively smooth the high-frequency components of
the latent map. To address these issues, we propose Swap Forward (SaFa), a
frame-level latent swap framework that synchronizes multiple diffusions to
produce a globally coherent long audio with more spectrum details in a
forward-only manner. At its core, the bidirectional Self-Loop Latent Swap is
applied between adjacent views, leveraging stepwise diffusion trajectory to
adaptively enhance high-frequency components without disrupting low-frequency
components. Furthermore, to ensure cross-view consistency, the unidirectional
Reference-Guided Latent Swap is applied between the reference and the
non-overlap regions of each subview during the early stages, providing
centralized trajectory guidance. Quantitative and qualitative experiments
demonstrate that SaFa significantly outperforms existing joint diffusion
methods and even training-based long audio generation models. Moreover, we find
that it also adapts well to panoramic generation, achieving comparable
state-of-the-art performance with greater efficiency and model
generalizability. Project page is available at https://swapforward.github.io/.

摘要：先前使用全局視圖擴散或迭代生成進行長格式音訊生成的作業需要顯著的訓練或推論成本。雖然全景生成的多視圖聯合擴散的近期進展提供了高效的選項，但它們在生成頻譜時會遇到嚴重的重疊失真和高跨視圖一致性成本的問題。我們最初透過潛在映射的連接繼承來探討此現象，並發現平均運算過度平滑了潛在映射的高頻率組成。為了解決這些問題，我們提出 Swap Forward (SaFa)，一種幀級潛在交換架構，它同步多個擴散以產生全局一致的長音訊，並以僅前向的方式提供更多頻譜細節。其核心是，雙向自迴圈潛在交換套用於相鄰視圖，利用逐步擴散軌跡來自適應地增強高頻率組成，而不會破壞低頻率組成。此外，為了確保跨視圖一致性，單向參考引導潛在交換在早期階段套用於參考和每個子視圖的非重疊區域，提供集中軌跡引導。定量和定性實驗證明，SaFa 明顯優於現有的聯合擴散方法，甚至優於基於訓練的長音訊生成模型。此外，我們發現它也能很好地適應全景生成，以更高的效率和模型泛化性達成媲美最先進技術的效能。專案頁面可於 https://swapforward.github.io/ 取得。

##### **"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**
2502.05115v1 by Shihan Fu, Bingsheng Yao, Smit Desai, Yuqi Hu, Yuling Sun, Samantha Stonbraker, Yanjun Gao, Elizabeth M. Goldberg, Dakuo Wang

Older adult patients constitute a rapidly growing subgroup of Intensive Care
Unit (ICU) patients. In these situations, their family caregivers are expected
to represent the unconscious patients to access and interpret patients' medical
information. However, caregivers currently have to rely on overloaded
clinicians for information updates and typically lack the health literacy to
understand complex medical information. Our project aims to explore the
information needs of caregivers of ICU older adult patients, from which we can
propose design opportunities to guide future AI systems. The project begins
with formative interviews with 11 caregivers to identify their challenges in
accessing and interpreting medical information; From these findings, we then
synthesize design requirements and propose an AI system prototype to cope with
caregivers' challenges. The system prototype has two key features: a timeline
visualization to show the AI extracted and summarized older adult patients' key
medical events; and an LLM-based chatbot to provide context-aware informational
support. We conclude our paper by reporting on the follow-up user evaluation of
the system and discussing future AI-based systems for ICU caregivers of older
adults.

摘要：老年患者構成加護病房 (ICU) 患者中快速成長的子群。在這些情況下，預期他們的家庭照護者能代表無意識的患者取得並解讀患者的醫療資訊。然而，照護者目前必須依賴工作繁重的臨床醫師提供資訊更新，而且通常缺乏了解複雜醫療資訊的健康素養。我們的專案旨在探索 ICU 老年患者照護者的資訊需求，我們可以根據這些需求提出設計機會，以引導未來的 AI 系統。這個專案從對 11 位照護者的形成性訪談開始，以找出他們在取得和解讀醫療資訊方面的挑戰；根據這些發現，我們接著綜合設計需求，並提出一個 AI 系統原型，以應對照護者的挑戰。這個系統原型具有兩個關鍵特點：一個時間軸視覺化，以顯示 AI 萃取並摘要出的老年患者關鍵醫療事件；以及一個基於 LLM 的聊天機器人，以提供情境感知的資訊支援。我們透過報告系統的後續使用者評估，以及討論未來針對老年人 ICU 照護者的 AI 系統，來總結我們的論文。

##### **GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application**
2502.05113v1 by Volker Emmrich

This article explores the requirements for corpus compilation within the
GiesKaNe project (University of Giessen and Kassel, Syntactic Basic Structures
of New High German). The project is defined by three central characteristics:
it is a reference corpus, a historical corpus, and a syntactically deeply
annotated treebank. As a historical corpus, GiesKaNe aims to establish
connections with both historical and contemporary corpora, ensuring its
relevance across temporal and linguistic contexts. The compilation process
strikes the balance between innovation and adherence to standards, addressing
both internal project goals and the broader interests of the research
community. The methodological complexity of such a project is managed through a
complementary interplay of human expertise and machine-assisted processes. The
article discusses foundational topics such as tokenization, normalization,
sentence definition, tagging, parsing, and inter-annotator agreement, alongside
advanced considerations. These include comparisons between grammatical models,
annotation schemas, and established de facto annotation standards as well as
the integration of human and machine collaboration. Notably, a novel method for
machine-assisted classification of texts along the continuum of conceptual
orality and literacy is proposed, offering new perspectives on text selection.
Furthermore, the article introduces an approach to deriving de facto standard
annotations from existing ones, mediating between standardization and
innovation. In the course of describing the workflow the article demonstrates
that even ambitious projects like GiesKaNe can be effectively implemented using
existing research infrastructure, requiring no specialized annotation tools.
Instead, it is shown that the workflow can be based on the strategic use of a
simple spreadsheet and integrates the capabilities of the existing
infrastructure.

摘要：<paragraph>本文探討了 GiesKaNe（吉森大學和卡塞爾大學，新德語語法基本結構）專案中語料庫編纂的要求。這個專案由三個核心特徵定義：它是一個參考語料庫、一個歷史語料庫，以及一個語法深度標註的樹狀庫。作為一個歷史語料庫，GiesKaNe 旨在建立與歷史和當代語料庫的連結，確保其在時間和語言脈絡中的相關性。編纂過程在創新與遵守標準之間取得平衡，既符合專案內部目標，也符合研究社群的廣泛興趣。透過人類專業知識和機器輔助流程的互補互動，管理了此類專案的方法論複雜性。本文探討了詞彙化、正規化、句子定義、標記、分析和標記者間的一致性等基礎主題，以及進階考量。這些考量包括語法模型、標註架構和既定的實際標註標準之間的比較，以及人類與機器協作的整合。值得注意的是，提出了一種新的機器輔助文本分類方法，沿著概念口語和識字的連續統整，提供文本選擇的新觀點。此外，本文介紹了一種從現有標註中推導實際標準標註的方法，在標準化和創新之間進行調解。在描述工作流程的過程中，本文證明了即使像 GiesKaNe 這樣雄心勃勃的專案，也可以使用現有的研究基礎架構有效實作，而不需要專門的標註工具。相反，本文顯示工作流程可以基於簡單試算表的策略性使用，並整合現有基礎架構的能力。</paragraph>

##### **Flexible and Efficient Grammar-Constrained Decoding**
2502.05111v1 by Kanghee Park, Timothy Zhou, Loris D'Antoni

Large Language Models (LLMs) are often asked to generate structured outputs
that obey precise syntactic rules, such as code snippets or formatted data.
Grammar-constrained decoding (GCD) can guarantee that LLM outputs matches such
rules by masking out tokens that will provably lead to outputs that do not
belong to a specified context-free grammar (CFG). To guarantee soundness, GCD
algorithms have to compute how a given LLM subword tokenizer can align with the
tokens used
  by a given context-free grammar and compute token masks based on this
information. Doing so efficiently is challenging and existing GCD algorithms
require tens of minutes to preprocess common grammars. We present a new GCD
algorithm together with an implementation that offers 17.71x faster offline
preprocessing than existing approaches while preserving state-of-the-art
efficiency in online mask computation.

摘要：大型語言模型 (LLM) 經常被要求產生結構化輸出，這些輸出遵循精確的語法規則，例如程式碼片段或格式化資料。受語法約束的解碼 (GCD) 可以透過遮蔽會導致輸出不屬於特定上下文無關文法 (CFG) 的權杖，來保證 LLM 輸出符合此類規則。為了保證健全性，GCD 演算法必須計算給定的 LLM 子詞彙化器如何與給定的上下文無關文法所使用的權杖對齊，並根據此資訊計算權杖遮罩。有效執行此操作具有挑戰性，現有的 GCD 演算法需要數十分鐘來預處理常見的語法。我們提出一個新的 GCD 演算法以及一個實作，它提供比現有方法快 17.71 倍的離線預處理，同時在線上遮罩計算中保持最先進的效率。

##### **ApplE: An Applied Ethics Ontology with Event Context**
2502.05110v1 by Aisha Aijaz, Raghava Mutharaju, Manohar Kumar

Applied ethics is ubiquitous in most domains, requiring much deliberation due
to its philosophical nature. Varying views often lead to conflicting courses of
action where ethical dilemmas become challenging to resolve. Although many
factors contribute to such a decision, the major driving forces can be
discretized and thus simplified to provide an indicative answer. Knowledge
representation and reasoning offer a way to explicitly translate abstract
ethical concepts into applicable principles within the context of an event. To
achieve this, we propose ApplE, an Applied Ethics ontology that captures
philosophical theory and event context to holistically describe the morality of
an action. The development process adheres to a modified version of the
Simplified Agile Methodology for Ontology Development (SAMOD) and utilizes
standard design and publication practices. Using ApplE, we model a use case
from the bioethics domain that demonstrates our ontology's social and
scientific value. Apart from the ontological reasoning and quality checks,
ApplE is also evaluated using the three-fold testing process of SAMOD. ApplE
follows FAIR principles and aims to be a viable resource for applied ethicists
and ontology engineers.

摘要：應用倫理在多數領域中無所不在，由於其哲學性質，需要許多審議。不同的觀點經常導致相互衝突的行動方針，在這種情況下，倫理困境變得難以解決。儘管許多因素會影響此類決策，但主要的驅動力可以被離散化，並因此簡化以提供指示性答案。知識表徵和推理提供了一種方法，可以將抽象的倫理概念明確地轉換為事件背景下的適用原則。為了實現此目標，我們提出了 ApplE，一種應用倫理學本體，它捕捉哲學理論和事件背景，以全面描述行動的道德性。開發過程遵循本體開發簡化敏捷方法 (SAMOD) 的修改版本，並利用標準設計和發布實務。使用 ApplE，我們模擬了生物倫理領域的一個使用案例，展示了我們的本體的社會和科學價值。除了本體推理和品質檢查外，ApplE 還使用 SAMOD 的三階段測試過程進行評估。ApplE 遵循 FAIR 原則，旨在成為應用倫理學家和本體工程師的可行資源。

##### **Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types**
2502.05104v1 by Muhammad Umair Danish, Katarina Grolinger

Consumer energy forecasting is essential for managing energy consumption and
planning, directly influencing operational efficiency, cost reduction,
personalized energy management, and sustainability efforts. In recent years,
deep learning techniques, especially LSTMs and transformers, have been greatly
successful in the field of energy consumption forecasting. Nevertheless, these
techniques have difficulties in capturing complex and sudden variations, and,
moreover, they are commonly examined only on a specific type of consumer (e.g.,
only offices, only schools). Consequently, this paper proposes HyperEnergy, a
consumer energy forecasting strategy that leverages hypernetworks for improved
modeling of complex patterns applicable across a diversity of consumers.
Hypernetwork is responsible for predicting the parameters of the primary
prediction network, in our case LSTM. A learnable adaptable kernel, comprised
of polynomial and radial basis function kernels, is incorporated to enhance
performance. The proposed HyperEnergy was evaluated on diverse consumers
including, student residences, detached homes, a home with electric vehicle
charging, and a townhouse. Across all consumer types, HyperEnergy consistently
outperformed 10 other techniques, including state-of-the-art models such as
LSTM, AttentionLSTM, and transformer.

摘要：消費者能源預測對於管理能源消耗和規劃至關重要，直接影響營運效率、成本降低、個人化能源管理和永續性工作。近年來，深度學習技術，特別是 LSTM 和 Transformer，在能源消耗預測領域取得了巨大的成功。儘管如此，這些技術在捕捉複雜和突然的變化方面存在困難，而且通常僅在特定類型的消費者（例如，僅辦公室、僅學校）上進行檢驗。因此，本文提出了 HyperEnergy，一種消費者能源預測策略，它利用超網路來改善適用於各種消費者的複雜模式建模。超網路負責預測主預測網路（在我們的案例中為 LSTM）的參數。一個可學習的可適應核，由多項式和徑向基函數核組成，被納入以增強效能。所提出的 HyperEnergy 在各種消費者上進行了評估，包括學生宿舍、獨棟住宅、配備電動車充電功能的住宅和聯排住宅。在所有消費者類型中，HyperEnergy 的表現始終優於其他 10 種技術，包括 LSTM、AttentionLSTM 和 Transformer 等最先進的模型。

##### **Learning Temporal Invariance in Android Malware Detectors**
2502.05098v1 by Xinran Zheng, Shuo Yang, Edith C. H. Ngai, Suman Jana, Lorenzo Cavallaro

Learning-based Android malware detectors degrade over time due to natural
distribution drift caused by malware variants and new families. This paper
systematically investigates the challenges classifiers trained with empirical
risk minimization (ERM) face against such distribution shifts and attributes
their shortcomings to their inability to learn stable discriminative features.
Invariant learning theory offers a promising solution by encouraging models to
generate stable representations crossing environments that expose the
instability of the training set. However, the lack of prior environment labels,
the diversity of drift factors, and low-quality representations caused by
diverse families make this task challenging. To address these issues, we
propose TIF, the first temporal invariant training framework for malware
detection, which aims to enhance the ability of detectors to learn stable
representations across time. TIF organizes environments based on application
observation dates to reveal temporal drift, integrating specialized multi-proxy
contrastive learning and invariant gradient alignment to generate and align
environments with high-quality, stable representations. TIF can be seamlessly
integrated into any learning-based detector. Experiments on a decade-long
dataset show that TIF excels, particularly in early deployment stages,
addressing real-world needs and outperforming state-of-the-art methods.

摘要：基於學習的 Android 惡意軟體偵測器會隨著時間推移而衰退，這是因為惡意軟體變種和新家族造成的自然分佈漂移。本論文系統性地探討了使用經驗風險最小化 (ERM) 訓練的分類器面臨此類分佈轉移的挑戰，並將其缺點歸因於它們無法學習穩定的區別特徵。不變學習理論提供了一種有前途的解決方案，它鼓勵模型生成跨環境的穩定表示，揭示訓練集的不穩定性。然而，缺乏先前的環境標籤、漂移因素的多樣性以及由不同家族造成的低品質表示使得這項任務具有挑戰性。為了解決這些問題，我們提出了 TIF，這是第一個用於惡意軟體偵測的時序不變訓練架構，旨在增強偵測器跨時間學習穩定表示的能力。TIF 根據應用程式觀察日期組織環境以揭示時序漂移，整合專業的多代理對比學習和不變梯度對齊，以生成和對齊具有高品質、穩定表示的環境。TIF 可以無縫整合到任何基於學習的偵測器中。對長達十年的資料集進行的實驗表明，TIF 表現出色，特別是在早期部署階段，滿足實際需求並優於最先進的方法。

##### **Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs**
2502.05092v1 by Rohit Saxena, Aryo Pradipta Gema, Pasquale Minervini

Understanding time from visual representations is a fundamental cognitive
skill, yet it remains a challenge for multimodal large language models (MLLMs).
In this work, we investigate the capabilities of MLLMs in interpreting time and
date through analogue clocks and yearly calendars. To facilitate this, we
curated a structured dataset comprising two subsets: 1) $\textit{ClockQA}$,
which comprises various types of clock styles$-$standard, black-dial,
no-second-hand, Roman numeral, and arrow-hand clocks$-$paired with time related
questions; and 2) $\textit{CalendarQA}$, which consists of yearly calendar
images with questions ranging from commonly known dates (e.g., Christmas, New
Year's Day) to computationally derived ones (e.g., the 100th or 153rd day of
the year). We aim to analyse how MLLMs can perform visual recognition,
numerical reasoning, and temporal inference when presented with time-related
visual data. Our evaluations show that despite recent advancements, reliably
understanding time remains a significant challenge for MLLMs.

摘要：從視覺表徵理解時間是一項基本的認知技能，但對於多模態大型語言模型 (MLLM) 來說仍然是一項挑戰。在這項工作中，我們探討了 MLLM 在透過類比時鐘和年曆來詮釋時間和日期的能力。為了促進這一點，我們策劃了一個結構化的資料集，包含兩個子集：1) $\textit{ClockQA}$，它包含各種類型的時鐘樣式$-$標準、黑色錶盤、無秒針、羅馬數字和箭頭指針時鐘$-$配對與時間相關的問題；以及 2) $\textit{CalendarQA}$，它包含年曆圖像，問題範圍從眾所周知日期（例如聖誕節、新年）到計算得出的日期（例如第 100 或 153 天）。我們的目標是分析當 MLLM 呈現與時間相關的視覺資料時，它們如何執行視覺辨識、數字推理和時間推論。我們的評估顯示，儘管有近期的進展，但可靠地理解時間仍然是 MLLM 的一大挑戰。

##### **Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**
2502.05087v1 by Thierry Bossy, Julien Vignoud, Tahseen Rabbani, Juan R. Troncoso Pastoriza, Martin Jaggi

Federated learning (FL) is a popular paradigm for collaborative training
which avoids direct data exposure between clients. However, data privacy issues
still remain: FL-trained large language models are capable of memorizing and
completing phrases and sentences contained in training data when given with
their prefixes. Thus, it is possible for adversarial and honest-but-curious
clients to recover training data of other participants simply through targeted
prompting. In this work, we demonstrate that a popular and simple fine-tuning
strategy, low-rank adaptation (LoRA), reduces memorization during FL up to a
factor of 10. We study this effect by performing a medical question-answering
fine-tuning task and injecting multiple replicas of out-of-distribution
sensitive sequences drawn from an external clinical dataset. We observe a
reduction in memorization for a wide variety of Llama 2 and 3 models, and find
that LoRA can reduce memorization in centralized learning as well. Furthermore,
we show that LoRA can be combined with other privacy-preserving techniques such
as gradient clipping and Gaussian noising, secure aggregation, and Goldfish
loss to further improve record-level privacy while maintaining performance.

摘要：聯邦學習 (FL) 是一種流行的協作訓練範例，可避免客戶端之間直接公開資料。然而，資料隱私問題仍然存在：經過 FL 訓練的大型語言模型能夠記憶並完成訓練資料中包含的片語和句子，只要給予其前綴即可。因此，對抗和誠實但好奇的客戶端有可能僅透過目標提示來恢復其他參與者的訓練資料。在這項工作中，我們證明了一種流行且簡單的微調策略，低秩適應 (LoRA)，可將 FL 期間的記憶減少多達 10 倍。我們透過執行醫學問答微調任務並注入從外部臨床資料集抽取的非分佈敏感序列的多次複製品來研究此效應。我們觀察到各種 Llama 2 和 3 模型的記憶力降低，並發現 LoRA 也能減少集中式學習中的記憶力。此外，我們展示 LoRA 可以與其他隱私保護技術結合使用，例如梯度裁剪和高斯雜訊、安全聚合和 Goldfish 損失，以進一步改善記錄級隱私，同時維持效能。

##### **Causality can systematically address the monsters under the bench(marks)**
2502.05085v1 by Felix Leeb, Zhijing Jin, Bernhard Schölkopf

Effective and reliable evaluation is essential for advancing empirical
machine learning. However, the increasing accessibility of generalist models
and the progress towards ever more complex, high-level tasks make systematic
evaluation more challenging. Benchmarks are plagued by various biases,
artifacts, or leakage, while models may behave unreliably due to poorly
explored failure modes. Haphazard treatments and inconsistent formulations of
such "monsters" can contribute to a duplication of efforts, a lack of trust in
results, and unsupported inferences. In this position paper, we argue causality
offers an ideal framework to systematically address these challenges. By making
causal assumptions in an approach explicit, we can faithfully model phenomena,
formulate testable hypotheses with explanatory power, and leverage principled
tools for analysis. To make causal model design more accessible, we identify
several useful Common Abstract Topologies (CATs) in causal graphs which help
gain insight into the reasoning abilities in large language models. Through a
series of case studies, we demonstrate how the precise yet pragmatic language
of causality clarifies the strengths and limitations of a method and inspires
new approaches for systematic progress.

摘要：有效的、可靠的評估對於推進經驗機器學習至關重要。然而，一般化模型的可及性日益提高，以及朝著更複雜、更高級別任務的進展，使得系統評估更具挑戰性。基準測試受到各種偏差、人工製品或洩漏的困擾，而模型由於探索不充分的故障模式而可能表現得不可靠。隨意處理和不一致的表述等「怪物」可能會導致重複工作、對結果缺乏信任以及不支援的推論。在本文中，我們論證因果關係提供了一個系統性解決這些挑戰的理想框架。通過在方法中明確因果假設，我們可以忠實地模擬現象，制定具有解釋力的可測試假設，並利用原則性的分析工具。為了使因果模型設計更易於使用，我們在因果圖中識別出幾個有用的通用抽象拓撲 (CAT)，有助於深入了解大型語言模型中的推理能力。通過一系列案例研究，我們展示了因果關係的精確但務實的語言如何釐清方法的優缺點，並激發系統進展的新方法。

##### **ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework**
2502.05084v1 by Xiaoyu Deng, Ye Zhang, Tianmin Guo, Yongzhe Zhang, Zhengjian Kang, Hang Yang

The astonishing performance of large language models (LLMs) and their
remarkable achievements in production and daily life have led to their
widespread application in collaborative tasks. However, current large models
face challenges such as hallucination and lack of specificity in content
generation in vertical domain tasks. Inspired by the contrast and
classification mechanisms in human cognitive processes, this paper constructs
an adversarial learning-based prompt framework named ChallengeMe, which
includes three cascaded solutions: generation prompts, evaluation prompts, and
feedback optimization. In this process, we designed seven core optimization
dimensions and set the threshold for adversarial learning. The results of mixed
case studies on the text summarization task show that the proposed framework
can generate more accurate and fluent text summaries compared to the current
advanced mainstream LLMs.

摘要：大型語言模型 (LLM) 的驚人表現及其在生產和日常生活中的顯著成就，已導致它們廣泛應用於協作任務中。然而，當前大型模型面臨挑戰，例如在垂直領域任務中內容生成出現幻覺和缺乏具體性。受人類認知過程中對比和分類機制的啟發，本文構建了一個名為 ChallengeMe 的對抗性學習提示框架，其中包括三個級聯解決方案：生成提示、評估提示和反饋優化。在此過程中，我們設計了七個核心優化維度，並設定了對抗性學習的閾值。在文本摘要任務上混合案例研究的結果表明，與當前先進的主流 LLM 相比，所提出的框架可以生成更準確、更流暢的文本摘要。

##### **Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**
2502.05078v1 by Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha

Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities, yet their performance is highly dependent on the prompting
strategy and model scale. While reinforcement learning and fine-tuning have
been deployed to boost reasoning, these approaches incur substantial
computational and data overhead. In this work, we introduce Adaptive Graph of
Thoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM
reasoning solely at test time. Rather than relying on fixed-step methods like
Chain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes
complex queries into structured subproblems, forming an dynamic directed
acyclic graph (DAG) of interdependent reasoning steps. By selectively expanding
only those subproblems that require further analysis, AGoT unifies the
strengths of chain, tree, and graph paradigms into a cohesive framework that
allocates computation where it is most needed. We validate our approach on
diverse benchmarks spanning multi-hop retrieval, scientific reasoning, and
mathematical problem-solving, achieving up to 46.2% improvement on scientific
reasoning tasks (GPQA) - comparable to gains achieved through computationally
intensive reinforcement learning approaches and outperforming state-of-the-art
iterative approaches. These results suggest that dynamic decomposition and
structured recursion offer a scalable, cost-effective alternative to
post-training modifications, paving the way for more robust, general-purpose
reasoning in LLMs.

摘要：大型語言模型 (LLM) 已展現令人印象深刻的推理能力，但其效能高度依賴於提示策略和模型規模。雖然強化學習和微調已被用於提升推理，但這些方法會造成大量的運算和資料開銷。在這項工作中，我們引入了「適應性思考圖」(AGoT)，一個動態的、基於圖形的推論架構，它僅在測試時就能增強 LLM 推理。AGoT 並非依賴於鏈式思考 (CoT) 或樹狀思考 (ToT) 等固定步驟方法，而是遞迴地將複雜的查詢分解成結構化的子問題，形成一個由相互依賴的推理步驟所組成的動態有向無環圖 (DAG)。透過選擇性地僅擴充那些需要進一步分析的子問題，AGoT 將鏈式、樹狀和圖形範例的優勢統一到一個緊密的架構中，將運算分配到最需要的地方。我們在跨越多重跳躍檢索、科學推理和數學問題解決等多樣基準上驗證了我們的做法，在科學推理任務 (GPQA) 上達到了高達 46.2% 的改進，這與透過運算密集的強化學習方法所獲得的增益相當，並且優於最先進的迭代方法。這些結果表明，動態分解和結構化遞迴提供了一個可擴充、具成本效益的替代方案，用於訓練後修改，為 LLM 中更強健、更通用的推理鋪平了道路。

##### **Paying Attention to Facts: Quantifying the Knowledge Capacity of Attention Layers**
2502.05076v1 by Liang Ze Wong

In this paper, we investigate the ability of single-layer attention-only
transformers (i.e. attention layers) to memorize facts contained in databases
from a linear-algebraic perspective. We associate with each database a
3-tensor, propose the rank of this tensor as a measure of the size of the
database, and provide bounds on the rank in terms of properties of the
database. We also define a 3-tensor corresponding to an attention layer, and
empirically demonstrate the relationship between its rank and database rank on
a dataset of toy models and random databases. By highlighting the roles played
by the value-output and query-key weights, and the effects of argmax and
softmax on rank, our results shed light on the `additive motif' of factual
recall in transformers, while also suggesting a way of increasing layer
capacity without increasing the number of parameters.

摘要：在本文中，我們從線性代數的角度探討僅注意力轉換器（即注意力層）單層記憶資料庫中事實的能力。我們將每個資料庫與一個 3 張量關聯起來，提出此張量的秩作為資料庫大小的度量，並提供秩的界限，根據資料庫的屬性。我們還定義了一個對應於注意力層的 3 張量，並在玩具模型和隨機資料庫的資料集上經驗性地證明了其秩和資料庫秩之間的關係。通過強調值輸出和查詢鍵權重所扮演的角色，以及 argmax 和 softmax 對秩的影響，我們的結果闡明了轉換器中事實性回憶的「加法基序」，同時也提出了一種在不增加參數數量的情況下增加層容量的方法。

##### **Preference-aware compensation policies for crowdsourced on-demand services**
2502.05060v1 by Georgina Nouli, Axel Parmentier, Maximilian Schiffer

Crowdsourced on-demand services offer benefits such as reduced costs, faster
service fulfillment times, greater adaptability, and contributions to
sustainable urban transportation in on-demand delivery contexts. However, the
success of an on-demand platform that utilizes crowdsourcing relies on finding
a compensation policy that strikes a balance between creating attractive offers
for gig workers and ensuring profitability. In this work, we examine a dynamic
pricing problem for an on-demand platform that sets request-specific
compensation of gig workers in a discrete-time framework, where requests and
workers arrive stochastically. The operator's goal is to determine a
compensation policy that maximizes the total expected reward over the time
horizon. Our approach introduces compensation strategies that explicitly
account for gig worker request preferences. To achieve this, we employ the
Multinomial Logit model to represent the acceptance probabilities of gig
workers, and, as a result, derive an analytical solution that utilizes
post-decision states. Subsequently, we integrate this solution into an
approximate dynamic programming algorithm. We compare our algorithm against
benchmark algorithms, including formula-based policies and an upper bound
provided by the full information linear programming solution. Our algorithm
demonstrates consistent performance across diverse settings, achieving
improvements of at least 2.5-7.5% in homogeneous gig worker populations and 9%
in heterogeneous populations over benchmarks, based on fully synthetic data.
For real-world data, it surpasses benchmarks by 8% in weak and 20% in strong
location preference scenarios.

摘要：群眾外包按需服務提供各種好處，例如降低成本、縮短服務履行時間、提高適應性，以及在按需配送情境中對永續城市交通做出貢獻。然而，利用群眾外包的按需平台的成功，在於找到一個能平衡創造對零工工作者有吸引力的優惠，並確保獲利的補償政策。在這項工作中，我們探討一個針對按需平台的動態定價問題，該平台在離散時間架構中設定零工工作者的特定請求補償，其中請求和工作者會隨機出現。操作員的目標是確定一個補償政策，以最大化時間範圍內的總預期報酬。我們的方法引入了明確考慮零工工作者請求偏好的補償策略。為達成這個目標，我們採用多項羅吉特模型來表示零工工作者的接受機率，並因此推導出一個利用後決策狀態的分析解。接下來，我們將這個解整合到一個近似動態規劃演算法中。我們將我們的演算法與基準演算法進行比較，包括基於公式的政策和由完整資訊線性規劃解提供的上限。根據完全合成的資料，我們的演算法在不同設定中展現一致的效能，在同質零工工作者族群中達到至少 2.5-7.5% 的改善，在異質族群中達到 9% 的改善。對於真實世界的資料，在弱位置偏好情境中，它超越基準 8%，在強位置偏好情境中超越 20%。

##### **Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks**
2502.05041v1 by Yohannis Kifle Telila, Damitha Senevirathne, Dumindu Tissera, Apurva Narayan, Miriam A. M. Capretz, Katarina Grolinger

Anomaly detection is crucial in the energy sector to identify irregular
patterns indicating equipment failures, energy theft, or other issues. Machine
learning techniques for anomaly detection have achieved great success, but are
typically centralized, involving sharing local data with a central server which
raises privacy and security concerns. Federated Learning (FL) has been gaining
popularity as it enables distributed learning without sharing local data.
However, FL depends on neural networks, which are vulnerable to adversarial
attacks that manipulate data, leading models to make erroneous predictions.
While adversarial attacks have been explored in the image domain, they remain
largely unexplored in time series problems, especially in the energy domain.
Moreover, the effect of adversarial attacks in the FL setting is also mostly
unknown. This paper assesses the vulnerability of FL-based anomaly detection in
energy data to adversarial attacks. Specifically, two state-of-the-art models,
Long Short Term Memory (LSTM) and Transformers, are used to detect anomalies in
an FL setting, and two white-box attack methods, Fast Gradient Sign Method
(FGSM) and Projected Gradient Descent (PGD), are employed to perturb the data.
The results show that FL is more sensitive to PGD attacks than to FGSM attacks,
attributed to PGD's iterative nature, resulting in an accuracy drop of over 10%
even with naive, weaker attacks. Moreover, FL is more affected by these attacks
than centralized learning, highlighting the need for defense mechanisms in FL.

摘要：異常偵測在能源產業中至關重要，用於識別設備故障、能源竊取或其他問題的異常模式。機器學習異常偵測技術已取得巨大成功，但通常是集中式的，涉及與中央伺服器共享本地資料，這會引發隱私和安全問題。聯合式學習 (FL) 逐漸受到歡迎，因為它可以在不共享本地資料的情況下進行分散式學習。然而，FL 依賴於神經網路，而神經網路容易受到操縱資料的對抗性攻擊，導致模型做出錯誤的預測。雖然對抗性攻擊已在影像領域中進行探索，但在時間序列問題中仍鮮少探討，特別是在能源領域。此外，在 FL 設定中對抗性攻擊的影響也大多未知。本文評估了基於 FL 的異常偵測在能源資料中對對抗性攻擊的脆弱性。具體來說，兩個最先進的模型，長短期記憶 (LSTM) 和Transformer，用於在 FL 設定中偵測異常，並採用兩種白盒攻擊方法，快速梯度符號方法 (FGSM) 和投影梯度下降 (PGD)，來擾動資料。結果顯示，FL 對 PGD 攻擊比對 FGSM 攻擊更敏感，這歸因於 PGD 的迭代性質，即使是簡單、較弱的攻擊，也會導致準確率下降超過 10%。此外，與集中式學習相比，FL 受到這些攻擊的影響更大，這突顯了 FL 中防禦機制的必要性。

##### **nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow**
2502.05036v1 by Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen

Natural Language to Visualization (NL2Vis) seeks to convert natural-language
descriptions into visual representations of given tables, empowering users to
derive insights from large-scale data. Recent advancements in Large Language
Models (LLMs) show promise in automating code generation to transform tabular
data into accessible visualizations. However, they often struggle with complex
queries that require reasoning across multiple tables. To address this
limitation, we propose a collaborative agent workflow, termed nvAgent, for
NL2Vis. Specifically, nvAgent comprises three agents: a processor agent for
database processing and context filtering, a composer agent for planning
visualization generation, and a validator agent for code translation and output
verification. Comprehensive evaluations on the new VisEval benchmark
demonstrate that nvAgent consistently surpasses state-of-the-art baselines,
achieving a 7.88% improvement in single-table and a 9.23% improvement in
multi-table scenarios. Qualitative analyses further highlight that nvAgent
maintains nearly a 20% performance margin over previous models, underscoring
its capacity to produce high-quality visual representations from complex,
heterogeneous data sources.

摘要：自然語言到視覺化 (NL2Vis) 旨在將自然語言描述轉換為給定表格的視覺化表示，使用戶能夠從大規模數據中獲取見解。大型語言模型 (LLM) 的最新進展顯示出自動化程式碼生成的希望，將表格數據轉換為可訪問的視覺化。然而，它們通常難以處理需要跨多個表格進行推理的複雜查詢。為了解決這個限制，我們提出了一個協作代理工作流程，稱為 nvAgent，用於 NL2Vis。具體來說，nvAgent 包含三個代理：一個用於資料庫處理和上下文過濾的處理器代理、一個用於規劃視覺化生成的作曲器代理和一個用於程式碼轉換和輸出驗證的驗證器代理。在新的 VisEval 基準上的綜合評估表明，nvAgent 持續超越最先進的基準，在單表中實現了 7.88% 的改進，在多表場景中實現了 9.23% 的改進。定性分析進一步強調，nvAgent 在先前模型上保持了近 20% 的效能優勢，突顯了它從複雜、異質數據源產生高品質視覺化表示的能力。

##### **Analyzing Advanced AI Systems Against Definitions of Life and Consciousness**
2502.05007v1 by Azadeh Alavi, Hossein Akhoundi, Fatemeh Kouchmeshki

Could artificial intelligence ever become truly conscious in a functional
sense; this paper explores that open-ended question through the lens of Life, a
concept unifying classical biological criteria (Oxford, NASA, Koshland) with
empirical hallmarks such as adaptive self maintenance, emergent complexity, and
rudimentary self referential modeling. We propose a number of metrics for
examining whether an advanced AI system has gained consciousness, while
emphasizing that we do not claim all AI stems can become conscious. Rather, we
suggest that sufficiently advanced architectures exhibiting immune like
sabotage defenses, mirror self-recognition analogs, or meta-cognitive updates
may cross key thresholds akin to life-like or consciousness-like traits. To
demonstrate these ideas, we start by assessing adaptive self-maintenance
capability, and introduce controlled data corruption sabotage into the training
process. The result demonstrates AI capability to detect these inconsistencies
and revert or self-correct analogous to regenerative biological processes. We
also adapt an animal-inspired mirror self recognition test to neural
embeddings, finding that partially trained CNNs can distinguish self from
foreign features with complete accuracy. We then extend our analysis by
performing a question-based mirror test on five state-of-the-art chatbots
(ChatGPT4, Gemini, Perplexity, Claude, and Copilot) and demonstrated their
ability to recognize their own answers compared to those of the other chatbots.

摘要：人工智慧是否能真正從功能性的角度上達到意識；這篇論文透過生命這個概念來探討這個開放性的問題，生命這個概念結合了古典生物學標準（牛津、NASA、Koshland）以及經驗性的特徵，例如適應性的自我維護、突發的複雜性，以及基本的自我指涉模型。我們提出一些評量指標，用來檢視一個先進的人工智慧系統是否已經獲得意識，同時強調我們並未宣稱所有的人工智慧系統都能達到意識。相反地，我們提出，有足夠先進的架構，表現出類似免疫系統的破壞防禦、鏡像自我辨識類比，或元認知更新，可能會跨越關鍵門檻，類似於生命特質或意識特質。為了證明這些想法，我們從評估適應性自我維護能力開始，並在訓練過程中引入受控的資料破壞破壞。結果證明人工智慧有能力偵測這些不一致性，並恢復或自我修正，類似於生物的再生過程。我們也改編了一個受動物啟發的鏡像自我辨識測驗到神經嵌入中，發現部分訓練過的 CNN 可以完全準確地區分自我和外來特徵。然後我們透過對五個最先進的聊天機器人（ChatGPT4、Gemini、Perplexity、Claude 和 Copilot）執行基於問題的鏡像測驗來延伸我們的分析，並證明它們有能力辨識自己的答案，並與其他聊天機器人的答案做比較。

##### **A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach**
2502.05001v1 by Taiyi Wang, Liang Liang, Guang Yang, Thomas Heinis, Eiko Yoneki

Learned Index Structures (LIS) have significantly advanced data management by
leveraging machine learning models to optimize data indexing. However,
designing these structures often involves critical trade-offs, making it
challenging for both designers and end-users to find an optimal balance
tailored to specific workloads and scenarios. While some indexes offer
adjustable parameters that demand intensive manual tuning, others rely on fixed
configurations based on heuristic auto-tuners or expert knowledge, which may
not consistently deliver optimal performance.
  This paper introduces LITune, a novel framework for end-to-end automatic
tuning of Learned Index Structures. LITune employs an adaptive training
pipeline equipped with a tailor-made Deep Reinforcement Learning (DRL) approach
to ensure stable and efficient tuning. To accommodate long-term dynamics
arising from online tuning, we further enhance LITune with an on-the-fly
updating mechanism termed the O2 system. These innovations allow LITune to
effectively capture state transitions in online tuning scenarios and
dynamically adjust to changing data distributions and workloads, marking a
significant improvement over other tuning methods. Our experimental results
demonstrate that LITune achieves up to a 98% reduction in runtime and a 17-fold
increase in throughput compared to default parameter settings given a selected
Learned Index instance. These findings highlight LITune's effectiveness and its
potential to facilitate broader adoption of LIS in real-world applications.

摘要：學習索引結構（LIS）透過利用機器學習模型來優化資料索引，進而大幅提升資料管理。然而，設計這些結構通常涉及關鍵的權衡取捨，使得設計人員和最終使用者難以找到針對特定工作負載和場景量身打造的最佳平衡。雖然有些索引提供可調整的參數，需要密集的手動調整，但其他索引依賴於基於啟發式自動調整器或專家知識的固定配置，這可能無法持續提供最佳效能。
本文介紹 LITune，一種新穎的框架，用於學習索引結構的端到端自動調整。LITune 採用適應性訓練管線，配備量身打造的深度強化學習 (DRL) 方法，以確保穩定且有效的調整。為了適應線上調整產生的長期動態，我們進一步增強 LITune，採用稱為 O2 系統的即時更新機制。這些創新讓 LITune 能夠有效捕捉線上調整場景中的狀態轉換，並動態調整以適應變化的資料分佈和工作負載，標誌著相較於其他調整方法有顯著的進步。我們的實驗結果證明，與給定選定學習索引實例的預設參數設定相比，LITune 達到了運行時間減少多達 98%，以及吞吐量增加 17 倍的成果。這些發現突顯了 LITune 的效能，以及它促進 LIS 在實際應用中更廣泛採用的潛力。

##### **Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification**
2502.05000v1 by Jiayi Luo, Qingyun Sun, Haonan Yuan, Xingcheng Fu, Jianxin Li

Adversarial evasion attacks pose significant threats to graph learning, with
lines of studies that have improved the robustness of Graph Neural Networks
(GNNs). However, existing works rely on priors about clean graphs or attacking
strategies, which are often heuristic and inconsistent. To achieve robust graph
learning over different types of evasion attacks and diverse datasets, we
investigate this problem from a prior-free structure purification perspective.
Specifically, we propose a novel Diffusion-based Structure Purification
framework named DiffSP, which creatively incorporates the graph diffusion model
to learn intrinsic distributions of clean graphs and purify the perturbed
structures by removing adversaries under the direction of the captured
predictive patterns without relying on priors. DiffSP is divided into the
forward diffusion process and the reverse denoising process, during which
structure purification is achieved. To avoid valuable information loss during
the forward process, we propose an LID-driven nonisotropic diffusion mechanism
to selectively inject noise anisotropically. To promote semantic alignment
between the clean graph and the purified graph generated during the reverse
process, we reduce the generation uncertainty by the proposed graph transfer
entropy guided denoising mechanism. Extensive experiments demonstrate the
superior robustness of DiffSP against evasion attacks.

摘要：對抗性規避攻擊對圖形學習構成重大威脅，其中研究線路改進了圖形神經網路 (GNN) 的穩健性。然而，現有工作依賴於乾淨圖形或攻擊策略的先驗，這些策略通常是啟發式的且不一致的。為了在不同類型的規避攻擊和多樣化的資料集上實現穩健的圖形學習，我們從無先驗結構純化的角度研究了這個問題。具體來說，我們提出了一個名為 DiffSP 的基於擴散的結構純化框架，它創新地結合了圖形擴散模型來學習乾淨圖形的內在分佈，並在不依賴先驗的情況下，通過移除對抗者來淨化擾動結構，並在捕獲的預測模式的指導下進行。DiffSP 分為正向擴散過程和反向去噪過程，在此期間實現結構純化。為了避免在正向過程中丟失有價值的資訊，我們提出了一個 LID 驅動的非各向同性擴散機制，以選擇性地各向異性地注入噪聲。為了促進在反向過程中生成的乾淨圖形和純化圖形之間的語義對齊，我們通過提出的圖形傳輸熵引導去噪機制來降低生成的不確定性。大量的實驗證明了 DiffSP 對規避攻擊的卓越穩健性。

##### **Aligning Black-box Language Models with Human Judgments**
2502.04997v1 by Gerrit J. J. van den Burg, Gen Suzuki, Wei Liu, Murat Sensoy

Large language models (LLMs) are increasingly used as automated judges to
evaluate recommendation systems, search engines, and other subjective tasks,
where relying on human evaluators can be costly, time-consuming, and
unscalable. LLMs offer an efficient solution for continuous, automated
evaluation. However, since the systems that are built and improved with these
judgments are ultimately designed for human use, it is crucial that LLM
judgments align closely with human evaluators to ensure such systems remain
human-centered. On the other hand, aligning LLM judgments with human evaluators
is challenging due to individual variability and biases in human judgments. We
propose a simple yet effective framework to align LLM judgments with individual
human evaluators or their aggregated judgments, without retraining or
fine-tuning the LLM. Our approach learns a linear mapping between the LLM's
outputs and human judgments, achieving over 142% average improvement in
agreement across 29 tasks with only a small number of calibration examples used
for training. Notably, our method works in zero-shot and few-shot settings,
exceeds inter-human agreement on four out of six tasks, and enables smaller
LLMs to achieve performance comparable to that of larger models.

摘要：大型語言模型 (LLM) 愈來愈常被用作自動評審員，用於評估推薦系統、搜尋引擎和其他主觀任務，而仰賴人類評審員可能會耗費成本、耗時且無法擴充。LLM 提供了一種持續、自動化評估的有效解決方案。然而，由於使用這些判斷所建構和改善的系統最終是設計給人類使用的，因此 LLM 判斷與人類評審員緊密吻合至關重要，以確保此類系統仍然以人為中心。另一方面，由於人類判斷中的個別變異性和偏見，讓 LLM 判斷與人類評審員保持一致是一項挑戰。我們提出一個簡單但有效的架構，用於將 LLM 判斷與個別人類評審員或其彙總判斷保持一致，而無需重新訓練或微調 LLM。我們的做法會學習 LLM 輸出與人類判斷之間的線性對應，在 29 項任務中達成平均改善 142% 以上，而僅使用少量校正範例進行訓練。值得注意的是，我們的做法在零次學習和少量學習的設定中都有效，在六項任務中有四項超過人與人之間的共識，並讓較小的 LLM 能夠達成與較大模型相當的效能。

##### **CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs**
2502.04964v1 by Roman Vashurin, Maiya Goloburda, Preslav Nakov, Artem Shelmanov, Maxim Panov

Uncertainty quantification (UQ) methods for Large Language Models (LLMs)
encompasses a variety of approaches, with two major types being particularly
prominent: information-based, which focus on model confidence expressed as
token probabilities, and consistency-based, which assess the semantic
relationship between multiple outputs generated using repeated sampling.
Several recent methods have combined these two approaches and shown impressive
performance in various applications. However, they sometimes fail to outperform
much simpler baseline methods. Our investigation reveals distinctive
characteristics of LLMs as probabilistic models, which help to explain why
these UQ methods underperform in certain tasks. Based on these findings, we
propose a new way of synthesizing model confidence and output consistency that
leads to a family of efficient and robust UQ methods. We evaluate our approach
across a variety of tasks such as question answering, abstractive
summarization, and machine translation, demonstrating sizable improvements over
state-of-the-art UQ approaches.

摘要：大型語言模型 (LLM) 的不確定性量化 (UQ) 方法包含各種方法，其中兩種主要類型特別突出：基於信息的，它著重於模型信心，表示為權杖機率，以及基於一致性的，它評估使用重複抽樣產生的多個輸出之間的語義關係。最近的幾種方法結合了這兩種方法，並在各種應用中展現了令人印象深刻的效能。然而，它們有時無法超越更簡單的基本方法。我們的調查揭示了 LLM 作為機率模型的獨特特徵，有助於解釋為什麼這些 UQ 方法在某些任務中的表現不佳。根據這些發現，我們提出了一種合成模型信心和輸出一致性的新方法，這導致了一系列有效且穩健的 UQ 方法。我們在各種任務中評估我們的做法，例如問答、抽象摘要和機器翻譯，展示了對最先進的 UQ 方法的顯著改進。

##### **Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction**
2502.04963v1 by Jianshu Zhang, Xiaofu Wu, Junquan Hu

This paper investigates the anti-jamming channel access problem in complex
and unknown jamming environments, where the jammer could dynamically adjust its
strategies to target different channels. Traditional channel hopping
anti-jamming approaches using fixed patterns are ineffective against such
dynamic jamming attacks. Although the emerging deep reinforcement learning
(DRL) based dynamic channel access approach could achieve the Nash equilibrium
under fast-changing jamming attacks, it requires extensive training episodes.
To address this issue, we propose a fast adaptive anti-jamming channel access
approach guided by the intuition of ``learning faster than the jammer", where a
synchronously updated coarse-grained spectrum prediction serves as an auxiliary
task for the deep Q learning (DQN) based anti-jamming model. This helps the
model identify a superior Q-function compared to standard DRL while
significantly reducing the number of training episodes. Numerical results
indicate that the proposed approach significantly accelerates the rate of
convergence in model training, reducing the required training episodes by up to
70% compared to standard DRL. Additionally, it also achieves a 10% improvement
in throughput over NE strategies, owing to the effective use of coarse-grained
spectrum prediction.

摘要：本文探討複雜且未知的干擾環境中的防干擾頻道存取問題，其中干擾者可以動態調整其策略以鎖定不同的頻道。使用固定模式的傳統頻道跳頻防干擾方法對於此類動態干擾攻擊無效。儘管新興的基於深度強化學習 (DRL) 的動態頻道存取方法可以在快速變化的干擾攻擊下實現納什均衡，但它需要大量的訓練回合。為了解決這個問題，我們提出了一種快速適應性防干擾頻道存取方法，其指導思想是「比干擾者學習得更快」，其中同步更新的粗粒度頻譜預測作為基於深度 Q 學習 (DQN) 的防干擾模型的輔助任務。這有助於模型識別與標準 DRL 相比更優越的 Q 函數，同時顯著減少訓練回合數。數值結果表明，所提出的方法顯著加快了模型訓練中的收斂速度，與標準 DRL 相比，將所需的訓練回合數減少了 70%。此外，由於有效利用了粗粒度頻譜預測，它還將吞吐量提高了 10%，超過了 NE 策略。

##### **Commonality and Individuality! Integrating Humor Commonality with Speaker Individuality for Humor Recognition**
2502.04960v1 by Haohao Zhu, Junyu Lu, Zeyuan Zeng, Zewen Bai, Xiaokun Zhang, Liang Yang, Hongfei Lin

Humor recognition aims to identify whether a specific speaker's text is
humorous. Current methods for humor recognition mainly suffer from two
limitations: (1) they solely focus on one aspect of humor commonalities,
ignoring the multifaceted nature of humor; and (2) they typically overlook the
critical role of speaker individuality, which is essential for a comprehensive
understanding of humor expressions. To bridge these gaps, we introduce the
Commonality and Individuality Incorporated Network for Humor Recognition
(CIHR), a novel model designed to enhance humor recognition by integrating
multifaceted humor commonalities with the distinctive individuality of
speakers. The CIHR features a Humor Commonality Analysis module that explores
various perspectives of multifaceted humor commonality within user texts, and a
Speaker Individuality Extraction module that captures both static and dynamic
aspects of a speaker's profile to accurately model their distinctive
individuality. Additionally, Static and Dynamic Fusion modules are introduced
to effectively incorporate the humor commonality with speaker's individuality
in the humor recognition process. Extensive experiments demonstrate the
effectiveness of CIHR, underscoring the importance of concurrently addressing
both multifaceted humor commonality and distinctive speaker individuality in
humor recognition.

摘要：幽默辨識旨在辨識特定說話者的文字是否幽默。目前幽默辨識的方法主要有兩個限制：(1) 它們僅專注於幽默共性的某個面向，忽略了幽默的多面向本質；(2) 它們通常忽略了說話者個人特質的關鍵角色，而這對於全面理解幽默表達至關重要。為了彌補這些差距，我們引入了幽默辨識的共性和個人特質整合網路 (CIHR)，這是一個新穎的模型，旨在透過整合多面向的幽默共性與說話者的獨特個人特質來增強幽默辨識。CIHR 具有幽默共性分析模組，可探索使用者文字中多面向幽默共性的各種觀點，以及說話者個人特質萃取模組，可擷取說話者個人資料的靜態和動態面向，以準確建模其獨特的個人特質。此外，還引入了靜態和動態融合模組，以便在幽默辨識過程中有效地將幽默共性與說話者的個人特質結合起來。廣泛的實驗證明了 CIHR 的有效性，強調了在幽默辨識中同時處理多面向幽默共性和獨特的說話者個人特質的重要性。

##### **SSMLoRA: Enhancing Low-Rank Adaptation with State Space Model**
2502.04958v1 by Jiayang Yu, Yihang Zhang, Bin Wang, Peiqin Lin, Yongkang Liu, Shi Feng

Fine-tuning is a key approach for adapting language models to specific
downstream tasks, but updating all model parameters becomes impractical as
model sizes increase. Parameter-Efficient Fine-Tuning (PEFT) methods, such as
Low-Rank Adaptation (LoRA), address this challenge by introducing additional
adaptation parameters into pre-trained weight matrices. However, LoRA's
performance varies across different insertion points within the model,
highlighting potential parameter inefficiency due to unnecessary insertions. To
this end, we propose SSMLoRA (State Space Model Low-Rank Adaptation), an
extension of LoRA that incorporates a State Space Model (SSM) to interconnect
low-rank matrices. SSMLoRA ensures that performance is maintained even with
sparser insertions. SSMLoRA allows the model to not only map inputs to a
low-rank space for better feature extraction but also leverage the computations
from the previous low-rank space. Our method achieves comparable performance to
LoRA on the General Language Understanding Evaluation (GLUE) benchmark while
using only half the parameters. Additionally, due to its structure, SSMLoRA
shows promise in handling tasks with longer input sequences. .You can find our
code here:https://github.com/yuhkalhic/SSMLoRA.

摘要：微調是一種將語言模型適應到特定下游任務的主要方法，但隨著模型規模的增加，更新所有模型參數變得不切實際。參數高效微調 (PEFT) 方法（例如低秩適應 (LoRA)）通過在預訓練權重矩陣中引入額外的適應參數來解決這一挑戰。然而，LoRA 的性能會因模型中的不同插入點而異，這突顯了由於不必要的插入而導致的潛在參數效率低下。為此，我們提出了 SSMLoRA（狀態空間模型低秩適應），這是一種 LoRA 的擴展，它結合了狀態空間模型 (SSM) 來互連低秩矩陣。SSMLoRA 確保即使在插入較稀疏的情況下也能保持性能。SSMLoRA 不僅允許模型將輸入映射到低秩空間以進行更好的特徵提取，而且還利用了來自先前低秩空間的計算。我們的模型在通用語言理解評估 (GLUE) 基準上實現了與 LoRA 相當的性能，同時僅使用了後者一半的參數。此外，由於其結構，SSMLoRA 在處理具有較長輸入序列的任務方面顯示出前景。您可以在這裡找到我們的代碼：https://github.com/yuhkalhic/SSMLoRA。

##### **Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics**
2502.04955v1 by Herbert Ullrich, Tomáš Mlynář, Jan Drchal

In this paper, we explore the problem of Claim Extraction using one-to-many
text generation methods, comparing LLMs, small summarization models finetuned
for the task, and a previous NER-centric baseline QACG. As the current
publications on Claim Extraction, Fact Extraction, Claim Generation and
Check-worthy Claim Detection are quite scattered in their means and
terminology, we compile their common objectives, releasing the FEVERFact
dataset, with 17K atomic factual claims extracted from 4K contextualised
Wikipedia sentences, adapted from the original FEVER. We compile the known
objectives into an Evaluation framework of: Atomicity, Fluency,
Decontextualization, Faithfulness checked for each generated claim separately,
and Focus and Coverage measured against the full set of predicted claims for a
single input. For each metric, we implement a scale using a reduction to an
already-explored NLP task. We validate our metrics against human grading of
generic claims, to see that the model ranking on $F_{fact}$, our hardest
metric, did not change and the evaluation framework approximates human grading
very closely in terms of $F_1$ and RMSE.

摘要：在本文中，我们使用一对多的文本生成方法探討聲明抽取的問題，比較 LLM、針對此任務微調的小型摘要模型以及先前的 NER 為中心的基準 QACG。由於目前關於聲明抽取、事實抽取、聲明生成和值得檢查的聲明偵測的出版物在方法和術語上相當分散，我們編制了它們的共同目標，發布了 FEVERFact 資料集，其中包含從 4K 個語境化維基百科句子中抽取的 17K 原子事實聲明，改編自原始的 FEVER。我們將已知的目標編譯成一個評估框架：原子性、流暢性、去脈絡化、忠實度分別檢查每個生成的聲明，以及針對單一輸入預測的聲明全集測量焦點和覆蓋率。對於每個指標，我們使用簡化為已探討的 NLP 任務來實作一個量表。我們根據人類對一般性聲明評級驗證我們的指標，以查看模型在 $F_{fact}$（我們最困難的指標）上的排名沒有改變，並且評估框架在 $F_1$ 和 RMSE 方面非常接近人類評級。

##### **The Rising Threat to Emerging AI-Powered Search Engines**
2502.04951v1 by Zeren Luo, Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Jingyi Zheng, Xinlei He

Recent advancements in Large Language Models (LLMs) have significantly
enhanced the capabilities of AI-Powered Search Engines (AIPSEs), offering
precise and efficient responses by integrating external databases with
pre-existing knowledge. However, we observe that these AIPSEs raise risks such
as quoting malicious content or citing malicious websites, leading to harmful
or unverified information dissemination. In this study, we conduct the first
safety risk quantification on seven production AIPSEs by systematically
defining the threat model, risk level, and evaluating responses to various
query types. With data collected from PhishTank, ThreatBook, and LevelBlue, our
findings reveal that AIPSEs frequently generate harmful content that contains
malicious URLs even with benign queries (e.g., with benign keywords). We also
observe that directly query URL will increase the risk level while query with
natural language will mitigate such risk. We further perform two case studies
on online document spoofing and phishing to show the ease of deceiving AIPSEs
in the real-world setting. To mitigate these risks, we develop an agent-based
defense with a GPT-4o-based content refinement tool and an XGBoost-based URL
detector. Our evaluation shows that our defense can effectively reduce the risk
but with the cost of reducing available information. Our research highlights
the urgent need for robust safety measures in AIPSEs.

摘要：大型語言模型 (LLM) 的最新進展顯著增強了 AI 驅動搜尋引擎 (AIPSE) 的能力，透過將外部資料庫與既有知識整合，提供精確且有效率的回應。然而，我們觀察到這些 AIPSE 會引發風險，例如引用惡意內容或引述惡意網站，進而導致有害或未經驗證的資訊散布。在這項研究中，我們對七個生產用 AIPSE 進行了首次安全風險量化，透過系統性地定義威脅模型、風險等級，並評估對各種查詢類型的回應。透過從 PhishTank、ThreatBook 和 LevelBlue 收集的資料，我們的研究結果顯示，即使是良善的查詢（例如，使用良善的關鍵字），AIPSE 也經常會產生包含惡意 URL 的有害內容。我們也觀察到，直接查詢 URL 會增加風險等級，而使用自然語言查詢會降低這種風險。我們進一步針對線上文件詐騙和網路釣魚進行了兩個案例研究，以顯示在真實世界中欺騙 AIPSE 的容易性。為了降低這些風險，我們開發了一個基於代理的防禦措施，其中包含一個基於 GPT-4o 的內容精煉工具和一個基於 XGBoost 的 URL 偵測器。我們的評估顯示，我們的防禦措施可以有效降低風險，但代價是減少可用的資訊。我們的研究突顯了在 AIPSE 中迫切需要強健的安全措施。

##### **Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market**
2502.04935v1 by Ciaran O'Connor, Mohamed Bahloul, Roberto Rossi, Steven Prestwich, Andrea Visentin

The integration of renewable energy into electricity markets poses
significant challenges to price stability and increases the complexity of
market operations. Accurate and reliable electricity price forecasting is
crucial for effective market participation, where price dynamics can be
significantly more challenging to predict. Probabilistic forecasting, through
prediction intervals, efficiently quantifies the inherent uncertainties in
electricity prices, supporting better decision-making for market participants.
This study explores the enhancement of probabilistic price prediction using
Conformal Prediction (CP) techniques, specifically Ensemble Batch Prediction
Intervals and Sequential Predictive Conformal Inference. These methods provide
precise and reliable prediction intervals, outperforming traditional models in
validity metrics. We propose an ensemble approach that combines the efficiency
of quantile regression models with the robust coverage properties of time
series adapted CP techniques. This ensemble delivers both narrow prediction
intervals and high coverage, leading to more reliable and accurate forecasts.
We further evaluate the practical implications of CP techniques through a
simulated trading algorithm applied to a battery storage system. The ensemble
approach demonstrates improved financial returns in energy trading in both the
Day-Ahead and Balancing Markets, highlighting its practical benefits for market
participants.

摘要：再生能源整合至電力市場對價格穩定性造成重大挑戰，並增加市場運作的複雜性。精準可靠的電力價格預測對於有效的市場參與至關重要，其中價格動態可能更難以預測。機率預測透過預測區間有效量化電力價格中固有的不確定性，支持市場參與者做出更好的決策。本研究探討使用共形預測 (CP) 技術增強機率價格預測，特別是整體批次預測區間和序列預測共形推論。這些方法提供精確且可靠的預測區間，在有效性指標中優於傳統模型。我們提出一個整體方法，將分位數回歸模型的效率與時間序列適應 CP 技術的穩健覆蓋特性結合起來。這種整體方法既能提供窄小的預測區間，又能提供高覆蓋率，從而產生更可靠、更準確的預測。我們進一步透過應用於電池儲能系統的模擬交易演算法評估 CP 技術的實際影響。整體方法證明在日前市場和平衡市場的能源交易中都能改善財務報酬，突顯其對市場參與者的實際效益。

##### **Cached Multi-Lora Composition for Multi-Concept Image Generation**
2502.04923v1 by Xiandong Zou, Mingzhu Shen, Christos-Savvas Bouganis, Yiren Zhao

Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique in
text-to-image models, enabling precise rendering of multiple distinct elements,
such as characters and styles, in multi-concept image generation. However,
current approaches face significant challenges when composing these LoRAs for
multi-concept image generation, resulting in diminished generated image
quality. In this paper, we initially investigate the role of LoRAs in the
denoising process through the lens of the Fourier frequency domain. Based on
the hypothesis that applying multiple LoRAs could lead to "semantic conflicts",
we find that certain LoRAs amplify high-frequency features such as edges and
textures, whereas others mainly focus on low-frequency elements, including the
overall structure and smooth color gradients. Building on these insights, we
devise a frequency domain based sequencing strategy to determine the optimal
order in which LoRAs should be integrated during inference. This strategy
offers a methodical and generalizable solution compared to the naive
integration commonly found in existing LoRA fusion techniques. To fully
leverage our proposed LoRA order sequence determination method in multi-LoRA
composition tasks, we introduce a novel, training-free framework, Cached
Multi-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs while
maintaining cohesive image generation. With its flexible backbone for
multi-LoRA fusion and a non-uniform caching strategy tailored to individual
LoRAs, CMLoRA has the potential to reduce semantic conflicts in LoRA
composition and improve computational efficiency. Our experimental evaluations
demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion
methods by a significant margin -- it achieves an average improvement of
$2.19\%$ in CLIPScore, and $11.25\%$ in MLLM win rate compared to LoraHub, LoRA
Composite, and LoRA Switch.

摘要：低秩適應 (LoRA) 已成為文字轉圖像模型中廣泛採用的技術，能精準呈現多個不同的元素，例如字元和樣式，以產生多概念的圖像。然而，目前的作法在為多概念圖像生成組合這些 LoRA 時面臨重大的挑戰，導致產生的圖像品質下降。在本文中，我們最初透過傅立葉頻域的透鏡來探討 LoRA 在去噪過程中的角色。根據應用多個 LoRA 可能會導致「語義衝突」的假設，我們發現某些 LoRA 會放大高頻率特徵，例如邊緣和紋理，而其他 LoRA 則主要關注低頻率元素，包括整體結構和平滑的色彩漸層。根據這些見解，我們設計了一個基於頻域的排序策略，以確定在推理期間整合 LoRA 的最佳順序。與現有 LoRA 融合技術中常見的樸素整合相比，此策略提供了一種有條理且可概括的解決方案。為了在多 LoRA 組合任務中充分利用我們提出的 LoRA 順序序列決定方法，我們引入了創新的免訓練架構，稱為快取多 LoRA (CMLoRA)，其設計目的在於有效整合多個 LoRA，同時維持一致的圖像生成。CMLoRA 擁有靈活的多 LoRA 融合主幹，以及針對個別 LoRA 量身打造的非均勻快取策略，有潛力減少 LoRA 組合中的語義衝突，並提升運算效率。我們的實驗評估證明，CMLoRA 的表現顯著優於最先進的免訓練 LoRA 融合方法，與 LoraHub、LoRA Composite 和 LoRA Switch 相比，在 CLIPScore 中平均提升了 $2.19\%$，在 MLLM 勝率中提升了 $11.25\%$。

##### **Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects**
2502.04899v1 by Levente Zólyomi, Tianze Wang, Sofiane Ennadir, Oleg Smirnov, Lele Cao

The proliferation of digital interactions across diverse domains, such as
healthcare, e-commerce, gaming, and finance, has resulted in the generation of
vast volumes of event stream (ES) data. ES data comprises continuous sequences
of timestamped events that encapsulate detailed contextual information relevant
to each domain. While ES data holds significant potential for extracting
actionable insights and enhancing decision-making, its effective utilization is
hindered by challenges such as the scarcity of labeled data and the fragmented
nature of existing research efforts. Self-Supervised Learning (SSL) has emerged
as a promising paradigm to address these challenges by enabling the extraction
of meaningful representations from unlabeled ES data. In this survey, we
systematically review and synthesize SSL methodologies tailored for ES modeling
across multiple domains, bridging the gaps between domain-specific approaches
that have traditionally operated in isolation. We present a comprehensive
taxonomy of SSL techniques, encompassing both predictive and contrastive
paradigms, and analyze their applicability and effectiveness within different
application contexts. Furthermore, we identify critical gaps in current
research and propose a future research agenda aimed at developing scalable,
domain-agnostic SSL frameworks for ES modeling. By unifying disparate research
efforts and highlighting cross-domain synergies, this survey aims to accelerate
innovation, improve reproducibility, and expand the applicability of SSL to
diverse real-world ES challenges.

摘要：隨著醫療保健、電子商務、遊戲和金融等不同領域的數位互動激增，已經產生了大量事件串流 (ES) 資料。ES 資料包含連續的帶時間戳記事件序列，其中包含與每個領域相關的詳細背景資訊。儘管 ES 資料在提取可操作見解和增強決策制定方面具有顯著潛力，但其有效利用受到標籤資料稀缺和現有研究工作分散等挑戰的阻礙。自監督學習 (SSL) 已成為應對這些挑戰的一種有前途的範例，它能從未標籤的 ES 資料中提取有意義的表示。在這項調查中，我們系統地回顧並綜合了針對多個領域的 ES 建模而量身定制的 SSL 方法，彌合了傳統上孤立運作的特定領域方法之間的差距。我們提出了 SSL 技術的全面分類法，涵蓋了預測和對比範例，並分析了它們在不同應用情境中的適用性和有效性。此外，我們還找出當前研究中的關鍵差距，並提出了一項未來的研究議程，旨在開發適用於 ES 建模的可擴充、與領域無關的 SSL 架構。透過統一不同的研究工作並強調跨領域的綜效作用，本調查旨在加速創新、提高可複製性，並擴展 SSL 在不同真實世界 ES 挑戰中的適用性。

##### **Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance**
2502.04883v1 by Reihaneh Amooie, Wietse de Vries, Yun Hao, Jelske Dijkstra, Matt Coler, Martijn Wieling

Automatic Speech Recognition (ASR) performance for low-resource languages is
still far behind that of higher-resource languages such as English, due to a
lack of sufficient labeled data. State-of-the-art methods deploy
self-supervised transfer learning where a model pre-trained on large amounts of
data is fine-tuned using little labeled data in a target low-resource language.
In this paper, we present and examine a method for fine-tuning an SSL-based
model in order to improve the performance for Frisian and its regional dialects
(Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASR
performance can be improved by using multilingual (Frisian, Dutch, English and
German) fine-tuning data and an auxiliary language identification task. In
addition, our findings show that performance on dialectal speech suffers
substantially, and, importantly, that this effect is moderated by the
elicitation approach used to collect the dialectal data. Our findings also
particularly suggest that relying solely on standard language data for ASR
evaluation may underestimate real-world performance, particularly in languages
with substantial dialectal variation.

摘要：自動語音辨識 (ASR) 對於低資源語言的表現仍然遠遠落後於英語等高資源語言，原因在於標記資料不足。最先進的方法採用自我監督式遷移學習，其中一個預先在大量資料上訓練的模型會使用目標低資源語言中少量的標記資料進行微調。在本文中，我們提出並檢驗一種微調基於 SSL 的模型的方法，以改善弗里西亞語及其區域方言（克萊弗里西亞語、伍德弗里西亞語和南弗里西亞語）的表現。我們證明，透過使用多語言（弗里西亞語、荷蘭語、英語和德語）微調資料和輔助語言辨識任務，可以改善弗里西亞語 ASR 的表現。此外，我們的研究結果顯示，方言語音的表現大幅下降，而且重要的是，這種效應會受到用於收集方言資料的引出方法影響。我們的研究結果還特別表明，僅依賴標準語言資料進行 ASR 評估可能會低估實際的表現，特別是在方言變化很大的語言中。

##### **pytopicgram: A library for data extraction and topic modeling from Telegram channels**
2502.04882v1 by J. Gómez-Romero, J. Cantón Correa, R. Pérez Mercado, F. Prados Abad, M. Molina-Solana, W. Fajardo

Telegram is a popular platform for public communication, generating large
amounts of messages through its channels. pytopicgram is a Python library that
helps researchers collect, organize, and analyze these Telegram messages. The
library offers key features such as easy message retrieval, detailed channel
information, engagement metrics, and topic identification using advanced
modeling techniques. By simplifying data extraction and analysis, pytopicgram
allows users to understand how content spreads and how audiences interact on
Telegram. This paper describes the design, main features, and practical uses of
\pytopicgram, showcasing its effectiveness for studying public conversations on
Telegram.

摘要：Telegram 是一个用于公开交流的热门平台，通过其频道生成大量消息。pytopicgram 是一个 Python 库，可帮助研究人员收集、整理和分析这些 Telegram 消息。该库提供了一些关键功能，例如轻松检索消息、详细的频道信息、参与度指标以及使用高级建模技术识别主题。通过简化数据提取和分析，pytopicgram 允许用户了解内容如何在 Telegram 上传播以及受众如何在 Telegram 上互动。本文介绍了 \pytopicgram 的设计、主要功能和实际用法，展示了其在研究 Telegram 上的公开对话方面的有效性。

##### **Sparse Autoencoders Do Not Find Canonical Units of Analysis**
2502.04878v1 by Patrick Leask, Bart Bussmann, Michael Pearce, Joseph Bloom, Curt Tigges, Noura Al Moubayed, Lee Sharkey, Neel Nanda

A common goal of mechanistic interpretability is to decompose the activations
of neural networks into features: interpretable properties of the input
computed by the model. Sparse autoencoders (SAEs) are a popular method for
finding these features in LLMs, and it has been postulated that they can be
used to find a \textit{canonical} set of units: a unique and complete list of
atomic features. We cast doubt on this belief using two novel techniques: SAE
stitching to show they are incomplete, and meta-SAEs to show they are not
atomic. SAE stitching involves inserting or swapping latents from a larger SAE
into a smaller one. Latents from the larger SAE can be divided into two
categories: \emph{novel latents}, which improve performance when added to the
smaller SAE, indicating they capture novel information, and
\emph{reconstruction latents}, which can replace corresponding latents in the
smaller SAE that have similar behavior. The existence of novel features
indicates incompleteness of smaller SAEs. Using meta-SAEs -- SAEs trained on
the decoder matrix of another SAE -- we find that latents in SAEs often
decompose into combinations of latents from a smaller SAE, showing that larger
SAE latents are not atomic. The resulting decompositions are often
interpretable; e.g. a latent representing ``Einstein'' decomposes into
``scientist'', ``Germany'', and ``famous person''. Even if SAEs do not find
canonical units of analysis, they may still be useful tools. We suggest that
future research should either pursue different approaches for identifying such
units, or pragmatically choose the SAE size suited to their task. We provide an
interactive dashboard to explore meta-SAEs: https://metasaes.streamlit.app/

摘要：<paragraph>機制可解釋性的共同目標是將神經網路的活化分解為特徵：模型計算的輸入的可解釋屬性。稀疏自動編碼器 (SAE) 是在 LLM 中尋找這些特徵的流行方法，並且已假設它們可用於尋找一組「規範」的單元：一個獨特且完整的原子特徵清單。我們使用兩種新技術對此信念提出質疑：SAE 拼接以證明它們不完整，以及元 SAE 以證明它們不是原子的。SAE 拼接涉及將較大 SAE 中的潛在變數插入或換到較小的 SAE 中。較大 SAE 中的潛在變數可分為兩類：當新增到較小的 SAE 時會提升效能的「新穎潛在變數」，表示它們擷取了新穎資訊，以及可以取代較小 SAE 中具有類似行為的對應潛在變數的「重建潛在變數」。新穎特徵的存在表示較小的 SAE 不完整。使用元 SAE（在另一個 SAE 的解碼器矩陣上訓練的 SAE），我們發現 SAE 中的潛在變數通常會分解為來自較小 SAE 的潛在變數組合，這表示較大的 SAE 潛在變數並非原子。產生的分解通常是可解釋的；例如，表示「愛因斯坦」的潛在變數分解為「科學家」、「德國」和「名人」。即使 SAE 沒有找到分析的規範單位，它們仍然可能是實用的工具。我們建議未來的研究應採用不同的方法來識別此類單位，或務實地選擇適合其任務的 SAE 大小。我們提供了一個互動式儀表板來探索元 SAE：https://metasaes.streamlit.app/</paragraph>

##### **Enhancing Disinformation Detection with Explainable AI and Named Entity Replacement**
2502.04863v1 by Santiago González-Silot, Andrés Montoro-Montarroso, Eugenio Martínez Cámara, Juan Gómez-Romero

The automatic detection of disinformation presents a significant challenge in
the field of natural language processing. This task addresses a multifaceted
societal and communication issue, which needs approaches that extend beyond the
identification of general linguistic patterns through data-driven algorithms.
In this research work, we hypothesise that text classification methods are not
able to capture the nuances of disinformation and they often ground their
decision in superfluous features. Hence, we apply a post-hoc explainability
method (SHAP, SHapley Additive exPlanations) to identify spurious elements with
high impact on the classification models. Our findings show that
non-informative elements (e.g., URLs and emoticons) should be removed and named
entities (e.g., Rwanda) should be pseudo-anonymized before training to avoid
models' bias and increase their generalization capabilities. We evaluate this
methodology with internal dataset and external dataset before and after
applying extended data preprocessing and named entity replacement. The results
show that our proposal enhances on average the performance of a disinformation
classification method with external test data in 65.78% without a significant
decrease of the internal test performance.

摘要：自然語言處理領域中，自動偵測錯誤資訊是一項重大挑戰。這項任務處理的是多方面的社會和溝通議題，需要超越透過資料驅動演算法來辨識一般語言模式的方法。在這個研究工作中，我們假設文字分類方法無法捕捉到錯誤資訊的細微差別，而且它們常常將決策基礎建立在多餘的特徵上。因此，我們應用事後可解釋性方法（SHAP，SHapley 加法解釋）來找出對分類模型有重大影響的虛假元素。我們的研究結果顯示，在訓練之前應移除非資訊性元素（例如網址和表情符號），並將命名實體（例如盧安達）進行偽匿名化，以避免模型偏誤並提升其概化能力。我們在應用延伸資料前處理和命名實體替換之前和之後，以內部資料集和外部資料集評估此方法。結果顯示，我們的提案平均提升了錯誤資訊分類方法在外部測試資料上的效能，達 65.78%，而內部測試效能並未顯著下降。

##### **Lightweight Operations for Visual Speech Recognition**
2502.04834v1 by Iason Ioannis Panagos, Giorgos Sfikas, Christophoros Nikou

Visual speech recognition (VSR), which decodes spoken words from video data,
offers significant benefits, particularly when audio is unavailable. However,
the high dimensionality of video data leads to prohibitive computational costs
that demand powerful hardware, limiting VSR deployment on resource-constrained
devices. This work addresses this limitation by developing lightweight VSR
architectures. Leveraging efficient operation design paradigms, we create
compact yet powerful models with reduced resource requirements and minimal
accuracy loss. We train and evaluate our models on a large-scale public dataset
for recognition of words from video sequences, demonstrating their
effectiveness for practical applications. We also conduct an extensive array of
ablative experiments to thoroughly analyze the size and complexity of each
model. Code and trained models will be made publicly available.

摘要：視覺語音辨識 (VSR) 從影片資料中解碼出所說的話語，
在音訊不可用時特別有幫助。然而，
影片資料的高維度會導致高昂的運算成本，
需要強大的硬體，限制了 VSR 在資源受限的
裝置上部署。這項工作透過開發輕量化的 VSR
架構來解決這個限制。利用高效的運算設計範例，我們建立
精簡但強大的模型，減少資源需求，並將準確度損失降至最低。我們在一個大規模的公開資料集上訓練並評估我們的模型，
以辨識影片序列中的字詞，證明它們在實際應用中的有效性。我們也進行了一系列廣泛的消融實驗，以徹底分析每個
模型的大小和複雜性。程式碼和訓練好的模型將公開提供。

##### **Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization**
2502.04829v1 by Yedidya Kfir, Elad Sarafian, Sarit Kraus, Yoram Louzoun

Black-box algorithms are designed to optimize functions without relying on
their underlying analytical structure or gradient information, making them
essential when gradients are inaccessible or difficult to compute. Traditional
methods for solving black-box optimization (BBO) problems predominantly rely on
non-parametric models and struggle to scale to large input spaces. Conversely,
parametric methods that model the function with neural estimators and obtain
gradient signals via backpropagation may suffer from significant gradient
errors. A recent alternative, Explicit Gradient Learning (EGL), which directly
learns the gradient using a first-order Taylor approximation, has demonstrated
superior performance over both parametric and non-parametric methods. In this
work, we propose two novel gradient learning variants to address the robustness
challenges posed by high-dimensional, complex, and highly non-linear problems.
Optimistic Gradient Learning (OGL) introduces a bias toward lower regions in
the function landscape, while Higher-order Gradient Learning (HGL) incorporates
second-order Taylor corrections to improve gradient accuracy. We combine these
approaches into the unified OHGL algorithm, achieving state-of-the-art (SOTA)
performance on the synthetic COCO suite. Additionally, we demonstrate OHGLs
applicability to high-dimensional real-world machine learning (ML) tasks such
as adversarial training and code generation. Our results highlight OHGLs
ability to generate stronger candidates, offering a valuable tool for ML
researchers and practitioners tackling high-dimensional, non-linear
optimization challenges

摘要：黑盒演算法旨在最佳化函數，而無需依賴其基礎分析結構或梯度資訊，使其在無法取得梯度或難以運算梯度時，成為必要的工具。解決黑盒最佳化 (BBO) 問題的傳統方法主要依賴於非參數模型，且難以擴展到大型輸入空間。相反地，使用神經估計器對函數進行建模並透過反向傳播取得梯度訊號的參數方法，可能會產生顯著的梯度誤差。最近的替代方法，即明確梯度學習 (EGL)，直接使用一階泰勒近似來學習梯度，已證明其效能優於參數和非參數方法。在這項研究中，我們提出兩種新穎的梯度學習變體，以解決高維度、複雜且高度非線性問題所帶來的穩健性挑戰。樂觀梯度學習 (OGL) 在函數景觀中引入了對較低區域的偏差，而高階梯度學習 (HGL) 結合了二階泰勒校正，以提高梯度準確度。我們將這些方法結合到統一的 OHGL 演算法中，在合成 COCO 套件上達到了最先進 (SOTA) 的效能。此外，我們展示了 OHGL 可應用於高維度真實世界機器學習 (ML) 任務，例如對抗性訓練和程式碼生成。我們的結果突顯了 OHGL 生成更強候選者的能力，為解決高維度、非線性最佳化挑戰的機器學習研究人員和從業人員提供了有價值的工具

##### **Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks**
2502.04797v1 by Jing Yang, Max Glockner, Anderson Rocha, Iryna Gurevych

Free-text explanations are expressive and easy to understand, but many
datasets lack annotated explanation data, making it challenging to train models
for explainable predictions. To address this, we investigate how to use
existing explanation datasets for self-rationalization and evaluate models'
out-of-distribution (OOD) performance. We fine-tune T5-Large and OLMo-7B models
and assess the impact of fine-tuning data quality, the number of fine-tuning
samples, and few-shot selection methods. The models are evaluated on 19 diverse
OOD datasets across three tasks: natural language inference (NLI),
fact-checking, and hallucination detection in abstractive summarization. For
the generated explanation evaluation, we conduct a human study on 13 selected
models and study its correlation with the Acceptability score (T5-11B) and
three other LLM-based reference-free metrics. Human evaluation shows that the
Acceptability score correlates most strongly with human judgments,
demonstrating its effectiveness in evaluating free-text explanations. Our
findings reveal: 1) few annotated examples effectively adapt models for OOD
explanation generation; 2) compared to sample selection strategies, fine-tuning
data source has a larger impact on OOD performance; and 3) models with higher
label prediction accuracy tend to produce better explanations, as reflected by
higher Acceptability scores.

摘要：自由文本說明具有表達性和易於理解，但許多資料集缺乏註解說明資料，這使得訓練可解釋預測的模型具有挑戰性。為了解決這個問題，我們研究如何使用現有的說明資料集進行自我合理化並評估模型的分布外 (OOD) 效能。我們微調 T5-Large 和 OLMo-7B 模型，並評估微調資料品質、微調樣本數量和少次選取方法的影響。這些模型在 19 個不同的 OOD 資料集上進行評估，涵蓋三個任務：自然語言推論 (NLI)、事實查核和抽象摘要中的幻覺偵測。對於產生的說明評估，我們對 13 個選定的模型進行人體研究，並研究其與可接受性評分 (T5-11B) 和其他三個基於 LLM 的無參考指標的相關性。人體評估顯示，可接受性評分與人類判斷最為相關，證明其在評估自由文本說明方面的有效性。我們的研究結果顯示：1) 少量的註解範例可以有效地使模型適應 OOD 說明產生；2) 與樣本選取策略相比，微調資料來源對 OOD 效能有更大的影響；3) 標籤預測準確度較高的模型往往會產生更好的說明，這反映在較高的可接受性評分中。

##### **Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition**
2502.04795v1 by Masato Mita, Ryo Yoshida, Yohei Oseki

Large language models exhibit general linguistic abilities but significantly
differ from humans in their efficiency of language acquisition. This study
proposes a method for integrating the developmental characteristics of working
memory during the critical period, a stage when human language acquisition is
particularly efficient, into language models. The proposed method introduces a
mechanism that initially constrains working memory during the early stages of
training and gradually relaxes this constraint in an exponential manner as
learning progresses. Targeted syntactic evaluation shows that the proposed
method outperforms conventional models without memory constraints or with
static memory constraints. These findings not only provide new directions for
designing data-efficient language models but also offer indirect evidence
supporting the underlying mechanisms of the critical period hypothesis in human
language acquisition.

摘要：大型語言模型展現了一般的語言能力，但在語言習得的效率上與人類有顯著的差異。本研究提出了一個方法，將工作記憶在關鍵期的發展特徵整合到語言模型中，關鍵期是人類語言習得特別有效率的階段。所提出的方法引入了一種機制，最初在訓練的早期階段限制工作記憶，並隨著學習的進展以指數方式逐漸放寬此限制。有針對性的句法評估顯示，所提出的方法優於沒有記憶限制或具有靜態記憶限制的傳統模型。這些發現不僅為設計資料有效率的語言模型提供了新的方向，也提供了支持人類語言習得中關鍵期假設的基礎機制的間接證據。

##### **MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**
2502.04794v1 by Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo

Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is
introduced as a multimodal framework inspired by real-world diagnostic
processes. It uses pretrained models such as DINOv2, Vision Transformer, and
ResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into
low-dimensional, semantically meaningful features. A learnable
self-attention-based fusion network then integrates these imaging features with
clinical data for classification. Using 416 FUO patient cases from Sichuan
University West China Hospital from 2017 to 2023, the multimodal fusion
classification network MFCN achieved macro-AUROC scores ranging from 0.8654 to
0.9291 across seven tasks, outperforming conventional machine learning and
single-modality deep learning methods. Ablation studies and five-fold
cross-validation further validated its effectiveness. By combining the
strengths of pretrained large models and deep learning, MedMimic offers a
promising solution for disease classification.

摘要：不明原因發燒 (FUO) 仍然是診斷上的挑戰。MedMimic 是一個多模式架構，靈感來自於真實世界的診斷過程。它使用預先訓練的模型，例如 DINOv2、視覺轉換器和 ResNet-18，將高維 18F-FDG PET/CT 影像轉換為低維、語義有意義的特徵。一個可學習的自注意力融合網路接著將這些影像特徵與臨床資料整合，用於分類。使用 2017 年至 2023 年四川大學華西醫院的 416 個 FUO 病患病例，多模式融合分類網路 MFCN 在七項任務中達到了 0.8654 到 0.9291 的巨觀 AUROC 分數，優於傳統機器學習和單一模式深度學習方法。消融研究和五倍交叉驗證進一步驗證了其有效性。MedMimic 結合了預先訓練的大模型和深度學習的優點，為疾病分類提供了一個有前景的解決方案。

##### **S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency**
2502.04790v1 by Yuting Zeng, Weizhe Huang, Lei Jiang, Tongxuan Liu, Xitai Jin, Chen Tianying Tiana, Jing Li, Xiaohua Xu

Large language models (LLMs) have demonstrated remarkable capabilities across
various natural language processing (NLP) scenarios, but they still face
challenges when handling complex arithmetic and logical reasoning tasks. While
Chain-Of-Thought (CoT) reasoning, self-consistency (SC) and self-correction
strategies have attempted to guide models in sequential, multi-step reasoning,
Multi-agent Debate (MAD) has emerged as a viable approach for enhancing the
reasoning capabilities of LLMs. By increasing both the number of agents and the
frequency of debates, the performance of LLMs improves significantly. However,
this strategy results in a significant increase in token costs, presenting a
barrier to scalability. To address this challenge, we introduce a novel
sparsification strategy designed to reduce token costs within MAD. This
approach minimizes ineffective exchanges of information and unproductive
discussions among agents, thereby enhancing the overall efficiency of the
debate process. We conduct comparative experiments on multiple datasets across
various models, demonstrating that our approach significantly reduces the token
costs in MAD to a considerable extent. Specifically, compared to MAD, our
approach achieves an impressive reduction of up to 94.5\% in token costs while
maintaining performance degradation below 2.0\%.

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 場景中展現出非凡的能力，但它們在處理複雜的算術和邏輯推理任務時仍面臨挑戰。雖然思想鏈 (CoT) 推理、自我一致性 (SC) 和自我修正策略已嘗試引導模型進行循序漸進的多步驟推理，但多主體辯論 (MAD) 已成為一種可行的途徑，可增強 LLM 的推理能力。透過增加主體數量和辯論頻率，LLM 的效能大幅提升。然而，此策略會導致權杖成本大幅增加，對可擴充性造成阻礙。為了解決此挑戰，我們提出了一種創新的稀疏化策略，旨在降低 MAD 中的權杖成本。此方法將無效的資訊交換和主體之間的非生產性討論減至最低，從而提升辯論過程的整體效率。我們在多個資料集上針對各種模型進行比較實驗，證明我們的做法大幅降低了 MAD 中的權杖成本。具體來說，與 MAD 相比，我們的做法將權杖成本降低了驚人的 94.5%，同時將效能下降控制在 2.0% 以下。

##### **Probing Internal Representations of Multi-Word Verbs in Large Language Models**
2502.04789v1 by Hassane Kissane, Achim Schilling, Patrick Krauss

This study investigates the internal representations of verb-particle
combinations, called multi-word verbs, within transformer-based large language
models (LLMs), specifically examining how these models capture lexical and
syntactic properties at different neural network layers. Using the BERT
architecture, we analyze the representations of its layers for two different
verb-particle constructions: phrasal verbs like 'give up' and prepositional
verbs like 'look at'. Our methodology includes training probing classifiers on
the internal representations to classify these categories at both word and
sentence levels. The results indicate that the model's middle layers achieve
the highest classification accuracies. To further analyze the nature of these
distinctions, we conduct a data separability test using the Generalized
Discrimination Value (GDV). While GDV results show weak linear separability
between the two verb types, probing classifiers still achieve high accuracy,
suggesting that representations of these linguistic categories may be
non-linearly separable. This aligns with previous research indicating that
linguistic distinctions in neural networks are not always encoded in a linearly
separable manner. These findings computationally support usage-based claims on
the representation of verb-particle constructions and highlight the complex
interaction between neural network architectures and linguistic structures.

摘要：本研究探討了基於轉換器的大型語言模型 (LLM) 中動詞-介系詞組合（稱為多字動詞）的內部表徵，特別檢視這些模型如何捕捉不同神經網路層的語法和句法屬性。我們使用 BERT 架構，分析其層對於兩個不同動詞-介系詞結構的表徵：短語動詞（例如「放棄」）和介系詞動詞（例如「看著」）。我們的研究方法包括訓練探測分類器，以在單字和句子層級對這些類別進行分類。結果顯示，該模型的中間層達到了最高的分類準確度。為了進一步分析這些區別的性質，我們使用廣義判別值 (GDV) 進行資料可分離性測試。雖然 GDV 結果顯示出這兩種動詞類型之間的線性可分離性較弱，但探測分類器仍能達到高準確度，這表示這些語言類別的表徵可能是非線性可分離的。這與先前的研究一致，指出神經網路中的語言區別並不總是編碼成線性可分離的方式。這些發現以計算方式支持基於使用情況的主張，說明動詞-介系詞結構的表徵，並強調神經網路架構和語言結構之間的複雜互動。

##### **Enhancing SQL Injection Detection and Prevention Using Generative Models**
2502.04786v1 by Naga Sai Dasari, Atta Badii, Armin Moin, Ahmed Ashlam

SQL Injection (SQLi) continues to pose a significant threat to the security
of web applications, enabling attackers to manipulate databases and access
sensitive information without authorisation. Although advancements have been
made in detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that evade predefined
patterns. As SQLi attacks evolve, the need for more adaptive detection systems
becomes crucial. This paper introduces an innovative approach that leverages
generative models to enhance SQLi detection and prevention mechanisms. By
incorporating Variational Autoencoders (VAE), Conditional Wasserstein GAN with
Gradient Penalty (CWGAN-GP), and U-Net, synthetic SQL queries were generated to
augment training datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems by reducing both false
positives and false negatives. Extensive empirical testing further illustrated
the ability of the system to adapt to evolving SQLi attack patterns, resulting
in enhanced precision and robustness.

摘要：SQL 注入（SQLi）持續對 Web 應用程式的安全性構成重大威脅，讓攻擊者能夠操縱資料庫並未經授權存取敏感資訊。儘管偵測技術已有所進步，但傳統的基於特徵碼的方法仍難以識別規避預定義模式的複雜 SQL 注入攻擊。隨著 SQLi 攻擊的演變，對更具適應性的偵測系統的需求變得至關重要。本文介紹一種創新的方法，利用生成模型來增強 SQLi 偵測和預防機制。透過整合變異自動編碼器 (VAE)、條件 Wasserstein GAN 與梯度懲罰 (CWGAN-GP) 以及 U-Net，生成了合成 SQL 查詢，以擴充機器學習模型的訓練資料集。所提出的方法透過減少誤報和漏報，證明了 SQLi 偵測系統的準確性獲得改善。廣泛的實證測試進一步說明了系統適應不斷演變的 SQLi 攻擊模式的能力，從而提高了精確度和穩健性。

##### **SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning**
2502.04780v1 by Wanjia Zhao, Mert Yuksekgonul, Shirley Wu, James Zou

Multi-agent AI systems powered by large language models (LLMs) are
increasingly applied to solve complex tasks. However, these systems often rely
on fragile, manually designed prompts and heuristics, making optimization
difficult. A key challenge in optimizing multi-agent systems is acquiring
suitable training data for specialized agents. We introduce SiriuS, a
self-improving, reasoning-driven optimization framework for multi-agent
systems. Central to our approach is the construction of an experience library:
a repository of high-quality reasoning trajectories. The library is built by
retaining reasoning steps that lead to successful outcomes, providing a robust
training set for optimizing multi-agent system. Additionally, we introduce a
library augmentation procedure that refines unsuccessful trajectories, further
enriching the library. SiriuS boosts performance by 2.86\% to 21.88\% on
reasoning and biomedical QA and enhances agent negotiation in competitive
settings. Our results show that SiriuS enhances multi-agent performance while
generating reusable data for self-correction and self-play enhancement in the
future.

摘要：由大型語言模型 (LLM) 驅動的多智能體 AI 系統正日益廣泛地應用於解決複雜任務。然而，這些系統通常依賴於脆弱、手動設計的提示和啟發法，這使得最佳化變得困難。最佳化多智能體系統的一項關鍵挑戰是為特定智能體獲取合適的訓練資料。我們引入了 SiriuS，一個自我提升的、基於推理的最佳化框架，用於多智能體系統。我們方法的核心是建立一個經驗庫：一個高品質推理軌跡的儲存庫。這個庫是透過保留導致成功結果的推理步驟而建立的，為最佳化多智能體系統提供了一個穩健的訓練集。此外，我們引入了一個庫擴充程序，用於改善不成功的軌跡，進一步豐富該庫。SiriuS 將推理和生物醫學問答的效能提升了 2.86% 至 21.88%，並增強了在競爭環境中的智能體協商。我們的結果表明，SiriuS 增強了多智能體效能，同時為未來的自我修正和自我對弈增強生成了可重複使用的資料。

##### **Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning**
2502.04778v1 by Chen-Xiao Gao, Chenyang Wu, Mingjun Cao, Chenjun Xiao, Yang Yu, Zongzhang Zhang

The primary focus of offline reinforcement learning (RL) is to manage the
risk of hazardous exploitation of out-of-distribution actions. An effective
approach to achieve this goal is through behavior regularization, which
augments conventional RL objectives by incorporating constraints that enforce
the policy to remain close to the behavior policy. Nevertheless, existing
literature on behavior-regularized RL primarily focuses on explicit policy
parameterizations, such as Gaussian policies. Consequently, it remains unclear
how to extend this framework to more advanced policy parameterizations, such as
diffusion models. In this paper, we introduce BDPO, a principled
behavior-regularized RL framework tailored for diffusion-based policies,
thereby combining the expressive power of diffusion policies and the robustness
provided by regularization. The key ingredient of our method is to calculate
the Kullback-Leibler (KL) regularization analytically as the accumulated
discrepancies in reverse-time transition kernels along the diffusion
trajectory. By integrating the regularization, we develop an efficient
two-time-scale actor-critic RL algorithm that produces the optimal policy while
respecting the behavior constraint. Comprehensive evaluations conducted on
synthetic 2D tasks and continuous control tasks from the D4RL benchmark
validate its effectiveness and superior performance.

摘要：離線強化學習 (RL) 的主要重點是管理非分佈動作的危險利用風險。實現此目標的一種有效方法是透過行為正則化，它透過納入約束來擴充傳統的 RL 目標，以強制政策保持接近行為政策。儘管如此，現有的行為正則化 RL 文獻主要集中在明確的政策參數化，例如高斯政策。因此，如何將此架構擴展到更進階的政策參數化，例如擴散模型，仍不清楚。在本文中，我們介紹 BDPO，一個專門針對基於擴散的政策的原則性行為正則化 RL 架構，從而結合了擴散政策的表現力與正則化提供的穩健性。我們的方法的關鍵要素是將 Kullback-Leibler (KL) 正則化分析計算為沿著擴散軌跡的反向時間轉換核心中累積的差異。透過整合正則化，我們開發了一個有效率的二時標尺動作-評論家 RL 演算法，可產生最佳政策，同時遵守行為約束。在 D4RL 基準的合成 2D 任務和連續控制任務上進行的全面評估驗證了其有效性和優異的效能。

##### **SeDi-Instruct: Enhancing Alignment of Language Models through Self-Directed Instruction Generation**
2502.04774v1 by Jungwoo Kim, Minsang Kim, Sungjin Lee

The rapid evolution of Large Language Models (LLMs) has enabled the industry
to develop various AI-based services. Instruction tuning is considered
essential in adapting foundation models for target domains to provide
high-quality services to customers. A key challenge in instruction tuning is
obtaining high-quality instruction data. Self-Instruct, which automatically
generates instruction data using ChatGPT APIs, alleviates the data scarcity
problem. To improve the quality of instruction data, Self-Instruct discards
many of the instructions generated from ChatGPT, even though it is inefficient
in terms of cost owing to many useless API calls. To generate high-quality
instruction data at a low cost, we propose a novel data generation framework,
Self-Direct Instruction generation (SeDi-Instruct), which employs
diversity-based filtering and iterative feedback task generation.
Diversity-based filtering maintains model accuracy without excessively
discarding low-quality generated instructions by enhancing the diversity of
instructions in a batch. This reduces the cost of synthesizing instruction
data. The iterative feedback task generation integrates instruction generation
and training tasks and utilizes information obtained during the training to
create high-quality instruction sets. Our results show that SeDi-Instruct
enhances the accuracy of AI models by 5.2%, compared with traditional methods,
while reducing data generation costs by 36%.

摘要：大型語言模型 (LLM) 的快速演進讓產業
能夠開發各種基於 AI 的服務。指令微調被認為
在調整基礎模型以適應目標領域時至關重要，為客戶提供
高品質的服務。指令微調中的主要挑戰是
取得高品質的指令資料。Self-Instruct 自動
使用 ChatGPT API 產生指令資料，緩解資料短缺
的問題。為了提升指令資料的品質，Self-Instruct 捨棄
許多由 ChatGPT 產生的指令，儘管這在成本方面很沒有效率，因為有許多無用的 API 呼叫。為了以低成本產生高品質
的指令資料，我們提出一個新穎的資料產生架構，
Self-Direct 指令產生 (SeDi-Instruct)，它採用
基於多樣性的過濾和反覆回饋任務產生。
基於多樣性的過濾維持模型準確性，同時不會過度
捨棄低品質的產生指令，方法是提升指令在批次中的多樣性。這降低了合成指令
資料的成本。反覆回饋任務產生整合指令產生
和訓練任務，並利用在訓練期間取得的資訊來
建立高品質的指令集。我們的結果顯示 SeDi-Instruct
提升了 AI 模型的準確性 5.2%，相較於傳統方法，
同時將資料產生成本降低了 36%。

##### **DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences**
2502.04771v1 by Chao Feng, Yunlong Li, Yuanzhe Gao, Alberto Huertas Celdrán, Jan von der Assen, Gérôme Bovet, Burkhard Stiller

Federated learning (FL) has garnered significant attention as a prominent
privacy-preserving Machine Learning (ML) paradigm. Decentralized FL (DFL)
eschews traditional FL's centralized server architecture, enhancing the
system's robustness and scalability. However, these advantages of DFL also
create new vulnerabilities for malicious participants to execute adversarial
attacks, especially model poisoning attacks. In model poisoning attacks,
malicious participants aim to diminish the performance of benign models by
creating and disseminating the compromised model. Existing research on model
poisoning attacks has predominantly concentrated on undermining global models
within the Centralized FL (CFL) paradigm, while there needs to be more research
in DFL. To fill the research gap, this paper proposes an innovative model
poisoning attack called DMPA. This attack calculates the differential
characteristics of multiple malicious client models and obtains the most
effective poisoning strategy, thereby orchestrating a collusive attack by
multiple participants. The effectiveness of this attack is validated across
multiple datasets, with results indicating that the DMPA approach consistently
surpasses existing state-of-the-art FL model poisoning attack strategies.

摘要：联邦学习 (FL) 作为一种突出的隐私保护机器学习 (ML) 范式，引起了极大的关注。去中心化联邦学习 (DFL) 避开了传统 FL 的集中式服务器架构，增强了系统的稳健性和可扩展性。然而，DFL 的这些优势也为恶意参与者执行对抗性攻击（尤其是模型中毒攻击）创造了新的漏洞。在模型中毒攻击中，恶意参与者旨在通过创建和传播受损模型来降低良性模型的性能。现有的模型中毒攻击研究主要集中于破坏集中式 FL (CFL) 范式中的全局模型，而 DFL 中需要进行更多研究。为了填补研究空白，本文提出了一种创新的模型中毒攻击，称为 DMPA。该攻击计算多个恶意客户端模型的差异特征并获得最有效的中毒策略，从而协调多个参与者的共谋攻击。该攻击的有效性在多个数据集上得到验证，结果表明 DMPA 方法始终优于现有的最先进的 FL 模型中毒攻击策略。

##### **Graph Federated Learning Based Proactive Content Caching in Edge Computing**
2502.04760v1 by Rui Wang

With the rapid growth of mobile data traffic and the increasing prevalence of
video streaming, proactive content caching in edge computing has become crucial
for reducing latency and alleviating network congestion. However, traditional
caching strategies such as FIFO, LRU, and LFU fail to effectively predict
future content popularity, while existing proactive caching approaches often
require users to upload data to a central server, raising concerns regarding
privacy and scalability. To address these challenges, this paper proposes a
Graph Federated Learning-based Proactive Content Caching (GFPCC) scheme that
enhances caching efficiency while preserving user privacy. The proposed
approach integrates federated learning and graph neural networks, enabling
users to locally train Light Graph Convolutional Networks (LightGCN) to capture
user-item relationships and predict content popularity. Instead of sharing raw
data, only the trained model parameters are transmitted to the central server,
where a federated averaging algorithm aggregates updates, refines the global
model, and selects the most popular files for proactive caching. Experimental
evaluations on real-world datasets, such as MovieLens, demonstrate that GFPCC
outperforms baseline caching algorithms by achieving higher cache efficiency
through more accurate content popularity predictions. Moreover, the federated
learning framework strengthens privacy protection while maintaining efficient
model training; however, scalability remains a challenge in large-scale
networks with dynamic user preferences.

摘要：隨著行動數據流量快速成長及串流影片日益普及，邊緣運算中的主動式內容快取對於降低延遲和減輕網路壅塞已變得至關重要。然而，先進先出 (FIFO)、最近最少使用 (LRU) 和最近最常使用 (LFU) 等傳統快取策略無法有效預測未來的內容熱門程度，而現有的主動式快取方法通常要求使用者將資料上傳到中央伺服器，引發了隱私和可擴充性的疑慮。為了應對這些挑戰，本文提出了一個基於圖形聯盟學習的主動式內容快取 (GFPCC) 架構，可在維護使用者隱私的同時提升快取效率。所提出的方法整合了聯盟學習和圖形神經網路，使用戶能夠在本地訓練輕量級圖形卷積網路 (LightGCN) 以擷取使用者與項目之間的關係並預測內容熱門程度。使用者不分享原始資料，僅將訓練好的模型參數傳輸到中央伺服器，而中央伺服器會使用聯盟平均演算法彙整更新、改善全球模型，並選取最熱門的檔案進行主動式快取。針對真實世界資料集（例如 MovieLens）進行的實驗評估顯示，GFPCC 透過更準確的內容熱門程度預測，在快取效率上優於基準快取演算法。此外，聯盟學習架構強化了隱私保護，同時維持了高效的模型訓練；然而，在具有動態使用者偏好的大型網路中，可擴充性仍然是一項挑戰。

##### **Enhancing Phishing Email Identification with Large Language Models**
2502.04759v1 by Catherine Lee

Phishing has long been a common tactic used by cybercriminals and continues
to pose a significant threat in today's digital world. When phishing attacks
become more advanced and sophisticated, there is an increasing need for
effective methods to detect and prevent them. To address the challenging
problem of detecting phishing emails, researchers have developed numerous
solutions, in particular those based on machine learning (ML) algorithms. In
this work, we take steps to study the efficacy of large language models (LLMs)
in detecting phishing emails. The experiments show that the LLM achieves a high
accuracy rate at high precision; importantly, it also provides interpretable
evidence for the decisions.

摘要：網路釣魚一直是網路犯罪分子慣用的手法，在當今的數位世界中，它持續對人們構成重大威脅。當網路釣魚攻擊變得更進階、更精密時，對於偵測和預防網路釣魚攻擊的有效方法的需求也隨之增加。為了解決偵測網路釣魚電子郵件的挑戰性問題，研究人員開發出許多解決方案，特別是那些基於機器學習 (ML) 演算法的解決方案。在這項工作中，我們採取步驟來研究大型語言模型 (LLM) 在偵測網路釣魚電子郵件方面的效能。實驗顯示，LLM 在高準確度下達到高準確率；重要的是，它也為決策提供了可解釋的證據。

##### **ELITE: Enhanced Language-Image Toxicity Evaluation for Safety**
2502.04757v1 by Wonjun Lee, Doehyeon Lee, Eugene Choi, Sangyoon Yu, Ashkan Yousefpour, Haon Park, Bumsub Ham, Suhyun Kim

Current Vision Language Models (VLMs) remain vulnerable to malicious prompts
that induce harmful outputs. Existing safety benchmarks for VLMs primarily rely
on automated evaluation methods, but these methods struggle to detect implicit
harmful content or produce inaccurate evaluations. Therefore, we found that
existing benchmarks have low levels of harmfulness, ambiguous data, and limited
diversity in image-text pair combinations. To address these issues, we propose
the ELITE {\em benchmark}, a high-quality safety evaluation benchmark for VLMs,
underpinned by our enhanced evaluation method, the ELITE {\em evaluator}. The
ELITE evaluator explicitly incorporates a toxicity score to accurately assess
harmfulness in multimodal contexts, where VLMs often provide specific,
convincing, but unharmful descriptions of images. We filter out ambiguous and
low-quality image-text pairs from existing benchmarks using the ELITE evaluator
and generate diverse combinations of safe and unsafe image-text pairs. Our
experiments demonstrate that the ELITE evaluator achieves superior alignment
with human evaluations compared to prior automated methods, and the ELITE
benchmark offers enhanced benchmark quality and diversity. By introducing
ELITE, we pave the way for safer, more robust VLMs, contributing essential
tools for evaluating and mitigating safety risks in real-world applications.

摘要：現有的視覺語言模型（VLM）仍然容易受到惡意提示的影響，而這些提示會誘發有害的輸出。現有的 VLM 安全基準主要依賴於自動化評估方法，但這些方法難以偵測隱含的有害內容或產生不準確的評估。因此，我們發現現有的基準具有低程度的有害性、模稜兩可的資料，以及圖像文字對組合的多樣性有限。為了解決這些問題，我們提出了 ELITE {\em 基準}，一個針對 VLM 的高品質安全評估基準，並以我們增強的評估方法 ELITE {\em 評估器} 為基礎。ELITE 評估器明確地納入了毒性評分，以準確評估多模態環境中的有害性，在這種環境中，VLM 經常提供特定、令人信服但無害的圖像描述。我們使用 ELITE 評估器從現有的基準中篩選出模稜兩可和低品質的圖像文字對，並產生安全和不安全圖像文字對的多樣化組合。我們的實驗證明，與先前的自動化方法相比，ELITE 評估器與人類評估達到了更高的對齊，而 ELITE 基準提供了增強的基準品質和多樣性。透過導入 ELITE，我們為更安全、更強大的 VLM 鋪平了道路，並為評估和減輕實際應用中的安全風險做出了重要的貢獻。

##### **Concept Navigation and Classification via Open Source Large Language Model Processing**
2502.04756v1 by Maël Kubli

This paper presents a novel methodological framework for detecting and
classifying latent constructs, including frames, narratives, and topics, from
textual data using Open-Source Large Language Models (LLMs). The proposed
hybrid approach combines automated summarization with human-in-the-loop
validation to enhance the accuracy and interpretability of construct
identification. By employing iterative sampling coupled with expert refinement,
the framework guarantees methodological robustness and ensures conceptual
precision. Applied to diverse data sets, including AI policy debates, newspaper
articles on encryption, and the 20 Newsgroups data set, this approach
demonstrates its versatility in systematically analyzing complex political
discourses, media framing, and topic classification tasks.

摘要：本文提出了一個創新的方法論架構，用於從文本數據中檢測和分類潛在構念，包括框架、敘述和主題，使用開源大型語言模型 (LLM)。提出的混合方法結合了自動摘要和人為迴圈驗證，以增強構念識別的準確性和可解釋性。通過採用迭代抽樣並結合專家優化，該框架保證了方法論的穩健性並確保了概念的精確性。應用於不同的數據集，包括 AI 政策辯論、關於加密的新聞文章和 20 個新聞組數據集，這種方法展示了其在系統地分析複雜的政治話語、媒體框架和主題分類任務中的多功能性。

##### **Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking**
2502.04751v1 by Ruiyang Ren, Yuhao Wang, Junyi Li, Jinhao Jiang, Wayne Xin Zhao, Wenjie Wang, Tat-Seng Chua

In the era of vast digital information, the sheer volume and heterogeneity of
available information present significant challenges for intricate information
seeking. Users frequently face multistep web search tasks that involve
navigating vast and varied data sources. This complexity demands every step
remains comprehensive, accurate, and relevant. However, traditional search
methods often struggle to balance the need for localized precision with the
broader context required for holistic understanding, leaving critical facets of
intricate queries underexplored. In this paper, we introduce an LLM-based
search assistant that adopts a new information seeking paradigm with
holistically guided Monte Carlo tree search (HG-MCTS). We reformulate the task
as a progressive information collection process with a knowledge memory and
unite an adaptive checklist with multi-perspective reward modeling in MCTS. The
adaptive checklist provides explicit sub-goals to guide the MCTS process toward
comprehensive coverage of complex user queries. Simultaneously, our
multi-perspective reward modeling offers both exploration and retrieval
rewards, along with progress feedback that tracks completed and remaining
sub-goals, refining the checklist as the tree search progresses. By striking a
balance between localized tree expansion and global guidance, HG-MCTS reduces
redundancy in search paths and ensures that all crucial aspects of an intricate
query are properly addressed. Extensive experiments on real-world intricate
information seeking tasks demonstrate that HG-MCTS acquires thorough knowledge
collections and delivers more accurate final responses compared with existing
baselines.

摘要：在浩瀚的數位資訊時代，龐大的資訊量與異質性對複雜的資訊搜尋提出了嚴峻的挑戰。使用者經常面臨多步驟的網路搜尋任務，其中涉及瀏覽廣泛且多樣化的資料來源。這種複雜性要求每一步都保持全面、準確和相關性。然而，傳統的搜尋方法常常難以在局部精確度和整體理解所需更廣泛的脈絡之間取得平衡，導致複雜查詢的重要面向未被充分探索。在本文中，我們介紹了一個基於大型語言模型 (LLM) 的搜尋助理，它採用了一個新的資訊搜尋範例，結合整體引導的蒙地卡羅樹狀搜尋 (HG-MCTS)。我們將任務重新表述為一個具有知識記憶的漸進式資訊收集過程，並將自適應核對清單與多觀點獎勵模型結合在 MCTS 中。自適應核對清單提供了明確的子目標，以引導 MCTS 程序全面涵蓋複雜的使用者查詢。同時，我們的多觀點獎勵模型提供了探索和檢索獎勵，以及追蹤已完成和剩餘子目標的進度回饋，隨著樹狀搜尋的進行，不斷優化核對清單。透過在局部樹狀擴充和整體引導之間取得平衡，HG-MCTS 減少了搜尋路徑中的冗餘，並確保複雜查詢的所有關鍵面向都能得到適當處理。在真實世界複雜資訊搜尋任務上的廣泛實驗表明，與現有的基線相比，HG-MCTS 獲取了全面的知識集合，並提供了更準確的最終回應。

##### **Every Software as an Agent: Blueprint and Case Study**
2502.04747v1 by Mengwei Xu

The rise of (multimodal) large language models (LLMs) has shed light on
software agent -- where software can understand and follow user instructions in
natural language. However, existing approaches such as API-based and GUI-based
agents are far from satisfactory at accuracy and efficiency aspects. Instead,
we advocate to endow LLMs with access to the software internals (source code
and runtime context) and the permission to dynamically inject generated code
into software for execution. In such a whitebox setting, one may better
leverage the software context and the coding ability of LLMs. We then present
an overall design architecture and case studies on two popular web-based
desktop applications. We also give in-depth discussion of the challenges and
future directions. We deem that such a new paradigm has the potential to
fundamentally overturn the existing software agent design, and finally creating
a digital world in which software can comprehend, operate, collaborate, and
even think to meet complex user needs.

摘要：（多模态）大型语言模型（LLM）的兴起，为软件代理人带来了曙光——软件能够理解并遵循用户以自然语言给出的指令。然而，现有的方法，例如基于 API 和基于 GUI 的代理，在准确性和效率方面还远远不能令人满意。相反，我们提倡赋予 LLM 访问软件内部（源代码和运行时上下文）的权限，并允许动态注入生成的代码以供软件执行。在这种白盒设置中，人们可以更好地利用软件上下文和 LLM 的编码能力。然后，我们在两个流行的基于 Web 的桌面应用程序上展示了总体设计架构和案例研究。我们还对挑战和未来方向进行了深入讨论。我们认为，这种新的范例有可能从根本上颠覆现有的软件代理设计，并最终创造出一个软件能够理解、操作、协作，甚至思考以满足复杂用户需求的数字世界。

##### **The "negative end" of change in grammar: terminology, concepts and causes**
2502.04729v1 by Karolina Rudnicka

The topic of "negative end" of change is, contrary to the fields of
innovation and emergence, largely under-researched. Yet, it has lately started
to gain an increasing attention from language scholars worldwide. The main
focus of this article is threefold, namely to discuss the i) terminology; ii)
concepts and iii) causes associated with the "negative end" of change in
grammar. The article starts with an overview of research conducted on the
topic. It then moves to situating phenomena referred to as loss, decline or
obsolescence among processes of language change, before elaborating on the
terminology and concepts behind it. The last part looks at possible causes for
constructions to display a (gradual or rapid, but very consistent) decrease in
the frequency of use over time, which continues until the construction
disappears or there are only residual or fossilised forms left. Keywords: loss,
obsolescence, decline, competition, higher

摘要：<paragraph>關於變化的「負面終點」這個主題，與創新和出現的領域相反，在很大程度上尚未受到研究。然而，它最近開始引起世界各地語言學者的越來越多的關注。本文的主要焦點有三方面，即討論 i) 術語；ii) 概念和 iii) 與語法中「負面終點」相關的原因。本文從對該主題進行的研究概述開始。然後轉向將稱為損失、衰退或廢棄的現象置於語言變化的過程中，然後詳細說明其背後的術語和概念。最後一部分探討了結構隨著時間推移顯示出使用頻率（逐漸或快速，但非常一致）下降的可能原因，這種情況會持續到結構消失或只剩下殘餘或化石形式。關鍵字：損失、廢棄、衰退、競爭、更高</paragraph>

##### **Generating Symbolic World Models via Test-time Scaling of Large Language Models**
2502.04728v1 by Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu

Solving complex planning problems requires Large Language Models (LLMs) to
explicitly model the state transition to avoid rule violations, comply with
constraints, and ensure optimality-a task hindered by the inherent ambiguity of
natural language. To overcome such ambiguity, Planning Domain Definition
Language (PDDL) is leveraged as a planning abstraction that enables precise and
formal state descriptions. With PDDL, we can generate a symbolic world model
where classic searching algorithms, such as A*, can be seamlessly applied to
find optimal plans. However, directly generating PDDL domains with current LLMs
remains an open challenge due to the lack of PDDL training data. To address
this challenge, we propose to scale up the test-time computation of LLMs to
enhance their PDDL reasoning capabilities, thereby enabling the generation of
high-quality PDDL domains. Specifically, we introduce a simple yet effective
algorithm, which first employs a Best-of-N sampling approach to improve the
quality of the initial solution and then refines the solution in a fine-grained
manner with verbalized machine learning. Our method outperforms o1-mini by a
considerable margin in the generation of PDDL domain, achieving over 50%
success rate on two tasks (i.e., generating PDDL domains from natural language
description or PDDL problems). This is done without requiring additional
training. By taking advantage of PDDL as state abstraction, our method is able
to outperform current state-of-the-art methods on almost all competition-level
planning tasks.

摘要：<paragraph>解決複雜的規劃問題需要大型語言模型 (LLM) 明確建構狀態轉換，以避免規則違規、符合限制，並確保最佳性，這項任務受到自然語言固有模糊性的阻礙。為了克服這種模糊性，規劃領域定義語言 (PDDL) 被用作規劃抽象，以實現精確且形式化的狀態描述。透過 PDDL，我們可以產生一個符號世界模型，其中經典搜尋演算法（例如 A*）可以無縫應用於尋找最佳計畫。然而，由於缺乏 PDDL 訓練資料，使用目前的 LLM 直接產生 PDDL 領域仍然是一個未解決的挑戰。為了應對這項挑戰，我們提議擴大 LLM 的測試時間運算，以增強其 PDDL 推理能力，從而產生高品質的 PDDL 領域。具體來說，我們引入了一個簡單但有效的演算法，它首先採用最佳 N 採樣方法來改善初始解的品質，然後以細粒度的語言化機器學習方式改善解。我們的模型在 PDDL 領域的產生上大幅優於 o1-mini，在兩個任務上（即從自然語言描述或 PDDL 問題產生 PDDL 領域）達到超過 50% 的成功率。這是在不需要額外訓練的情況下完成的。透過利用 PDDL 作為狀態抽象，我們的模型能夠在幾乎所有競賽層級的規劃任務上優於目前的最新技術。</paragraph>

##### **Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?**
2502.04725v1 by Yujin Han, Andi Han, Wei Huang, Chaochao Lu, Difan Zou

Despite the remarkable success of diffusion models (DMs) in data generation,
they exhibit specific failure cases with unsatisfactory outputs. We focus on
one such limitation: the ability of DMs to learn hidden rules between image
features. Specifically, for image data with dependent features ($\mathbf{x}$)
and ($\mathbf{y}$) (e.g., the height of the sun ($\mathbf{x}$) and the length
of the shadow ($\mathbf{y}$)), we investigate whether DMs can accurately
capture the inter-feature rule ($p(\mathbf{y}|\mathbf{x})$). Empirical
evaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistent
failures, such as inconsistent lighting-shadow relationships and mismatched
object-mirror reflections. Inspired by these findings, we design four synthetic
tasks with strongly correlated features to assess DMs' rule-learning abilities.
Extensive experiments show that while DMs can identify coarse-grained rules,
they struggle with fine-grained ones. Our theoretical analysis demonstrates
that DMs trained via denoising score matching (DSM) exhibit constant errors in
learning hidden rules, as the DSM objective is not compatible with rule
conformity. To mitigate this, we introduce a common technique - incorporating
additional classifier guidance during sampling, which achieves (limited)
improvements. Our analysis reveals that the subtle signals of fine-grained
rules are challenging for the classifier to capture, providing insights for
future exploration.

摘要：儘管擴散模型 (DM) 在資料生成方面取得顯著的成功，但它們會出現特定失敗案例，產生不令人滿意的輸出。我們專注於其中一個限制：DM 學習影像特徵之間隱藏規則的能力。具體來說，對於具有依賴特徵 ($\mathbf{x}$) 和 ($\mathbf{y}$) 的影像資料（例如，太陽高度 ($\mathbf{x}$) 和陰影長度 ($\mathbf{y}$）），我們探討 DM 是否能準確捕捉特徵間規則 ($p(\mathbf{y}|\mathbf{x})$)。對主流 DM（例如 Stable Diffusion 3.5）的經驗評估揭示了一致的失敗，例如不一致的光影關係和不匹配的物體鏡像反射。受這些發現的啟發，我們設計了四項具有強相關特徵的合成任務，以評估 DM 的規則學習能力。大量的實驗表明，雖然 DM 可以識別粗略的規則，但它們難以應付細緻的規則。我們的理論分析表明，透過去噪分數匹配 (DSM) 訓練的 DM 在學習隱藏規則時會出現恆定誤差，因為 DSM 目標與規則一致性不相容。為了減輕這個問題，我們引入了一種常見的技術 - 在採樣期間加入額外的分類器指導，這實現了（有限的）改進。我們的分析表明，細緻規則的微妙訊號對於分類器來說很難捕捉，這為未來的探索提供了見解。

##### **Evaluating Text Style Transfer Evaluation: Are There Any Reliable Metrics?**
2502.04718v1 by Sourabrata Mukherjee, Atul Kr. Ojha, John P. McCrae, Ondrej Dusek

Text Style Transfer (TST) is the task of transforming a text to reflect a
particular style while preserving its original content. Evaluating TST outputs
is a multidimensional challenge, requiring the assessment of style transfer
accuracy, content preservation, and naturalness. Using human evaluation is
ideal but costly, same as in other natural language processing (NLP) tasks,
however, automatic metrics for TST have not received as much attention as
metrics for, e.g., machine translation or summarization. In this paper, we
examine both set of existing and novel metrics from broader NLP tasks for TST
evaluation, focusing on two popular subtasks-sentiment transfer and
detoxification-in a multilingual context comprising English, Hindi, and
Bengali. By conducting meta-evaluation through correlation with human
judgments, we demonstrate the effectiveness of these metrics when used
individually and in ensembles. Additionally, we investigate the potential of
Large Language Models (LLMs) as tools for TST evaluation. Our findings
highlight that certain advanced NLP metrics and experimental-hybrid-techniques,
provide better insights than existing TST metrics for delivering more accurate,
consistent, and reproducible TST evaluations.

摘要：文字樣式轉移 (TST) 是將文字轉換為反映特定樣式，同時保留其原始內容的任務。評估 TST 輸出是一項多維度的挑戰，需要評估樣式轉移準確性、內容保留和自然性。使用人工評估是理想的，但成本很高，與其他自然語言處理 (NLP) 任務相同，然而，TST 的自動化指標並未像機器翻譯或摘要的指標那樣受到重視。在本文中，我們檢視了廣泛 NLP 任務中現有和新穎指標的兩組，用於 TST 評估，重點關注兩個流行的子任務 - 情緒轉移和解毒 - 在包含英語、印地語和孟加拉語的多語言環境中。通過與人類判斷相關的元評估，我們證明了這些指標在單獨使用和整體使用時的有效性。此外，我們研究了大型語言模型 (LLM) 作為 TST 評估工具的潛力。我們的研究結果強調，某些先進的 NLP 指標和實驗性混合技術，提供比現有 TST 指標更好的見解，用於提供更準確、一致和可重製的 TST 評估。

##### **Enhancing Impression Change Prediction in Speed Dating Simulations Based on Speakers' Personalities**
2502.04706v1 by Kazuya Matsuo, Yoko Ishii, Atsushi Otsuka, Ryo Ishii, Hiroaki Sugiyama, Masahiro Mizukami, Tsunehiro Arimoto, Narichika Nomoto, Yoshihide Sato, Tetsuya Yamaguchi

This paper focuses on simulating text dialogues in which impressions between
speakers improve during speed dating. This simulation involves selecting an
utterance from multiple candidates generated by a text generation model that
replicates a specific speaker's utterances, aiming to improve the impression of
the speaker. Accurately selecting an utterance that improves the impression is
crucial for the simulation. We believe that whether an utterance improves a
dialogue partner's impression of the speaker may depend on the personalities of
both parties. However, recent methods for utterance selection do not consider
the impression per utterance or the personalities. To address this, we propose
a method that predicts whether an utterance improves a partner's impression of
the speaker, considering the personalities. The evaluation results showed that
personalities are useful in predicting impression changes per utterance.
Furthermore, we conducted a human evaluation of simulated dialogues using our
method. The results showed that it could simulate dialogues more favorably
received than those selected without considering personalities.

摘要：本文重點在於模擬在快速約會中，講者之間的印象得到改善的文字對話。此模擬包括從文字生成模型產生的多個候選者中選擇一個語句，該模型複製特定講者的語句，旨在改善講者的印象。準確選擇能改善印象的語句對於模擬至關重要。我們相信，語句是否能改善對話夥伴對講者的印象可能取決於雙方的個性。然而，最近的語句選擇方法並未考慮每個語句的印象或個性。為了解決這個問題，我們提出了一種方法，該方法預測語句是否會改善夥伴對講者的印象，並考慮個性。評估結果表明，個性對於預測每個語句的印象變化很有用。此外，我們使用我們的方法對模擬對話進行了人工評估。結果表明，它可以模擬出比不考慮個性而選擇的對話更受歡迎的對話。

##### **EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference**
2502.04700v1 by Prakhar Kaushik, Ankit Vaidya, Shravan Chaudhari, Alan Yuille

The rapid growth of large models has raised concerns about their
environmental impact and equity in accessibility due to significant
computational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for
finetuning large models, resulting in an abundance of publicly available
adapters tailored to diverse domains. We ask: Can these pretrained adapters be
leveraged to further streamline adaptation to new tasks while addressing these
challenges? We introduce EigenLoRAx, a parameter-efficient finetuning method
that recycles existing adapters to create a principal subspace aligned with
their shared domain knowledge which can be further augmented with orthogonal
basis vectors in low-resource scenarios. This enables rapid adaptation to new
tasks by learning only lightweight coefficients on the principal components of
the subspace - eliminating the need to finetune entire adapters. EigenLoRAx
requires significantly fewer parameters and memory, improving efficiency for
both training and inference. Our method demonstrates strong performance across
diverse domains and tasks, offering a scalable for edge-based applications,
personalization, and equitable deployment of large models in
resource-constrained environments.

摘要：大型模型的快速增长引发了人们对其环境影响和可访问性公平性的担忧，因为其计算成本很高。低秩适配器 (LoRA) 为微调大型模型提供了一种轻量级解决方案，从而产生了大量针对不同领域的公开可用适配器。我们提出疑问：这些预训练的适配器能否被利用来进一步简化对新任务的适配，同时解决这些挑战？我们引入了 EigenLoRAx，这是一种参数高效的微调方法，它可以回收现有的适配器来创建一个与它们共享的领域知识对齐的主成分子空间，该子空间可以在资源匮乏的情况下进一步用正交基向量进行扩充。这可以通过仅学习子空间主成分上的轻量级系数来实现对新任务的快速适配，从而消除了对微调整个适配器的需求。EigenLoRAx 需要明显更少的参数和内存，从而提高了训练和推理的效率。我们的方法在不同的领域和任务中都表现出了强大的性能，为基于边缘的应用程序、个性化和在大模型资源受限环境中的公平部署提供了可扩展性。

##### **Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance**
2502.04695v1 by Pratinav Seth, Vinay Kumar Sankarapu

This position paper emphasizes the critical gap in the evaluation of
Explainable AI (XAI) due to the lack of standardized and reliable metrics,
which diminishes its practical value, trustworthiness, and ability to meet
regulatory requirements. Current evaluation methods are often fragmented,
subjective, and biased, making them prone to manipulation and complicating the
assessment of complex models. A central issue is the absence of a ground truth
for explanations, complicating comparisons across various XAI approaches. To
address these challenges, we advocate for widespread research into developing
robust, context-sensitive evaluation metrics. These metrics should be resistant
to manipulation, relevant to each use case, and based on human judgment and
real-world applicability. We also recommend creating domain-specific evaluation
benchmarks that align with the user and regulatory needs of sectors such as
healthcare and finance. By encouraging collaboration among academia, industry,
and regulators, we can create standards that balance flexibility and
consistency, ensuring XAI explanations are meaningful, trustworthy, and
compliant with evolving regulations.

摘要：這篇立場文件強調，由於缺乏標準化且可靠的指標，可解釋人工智慧 (XAI) 的評估中存在關鍵的差距，這降低了其實用價值、可信度，以及滿足法規要求的能力。當前的評估方法通常是分散的、主觀的，且有偏見的，這使得它們容易被操縱，並使複雜模型的評估複雜化。一個核心議題是缺乏解釋的基準事實，這使得跨各種 XAI 方法的比較變得複雜。為了應對這些挑戰，我們提倡廣泛研究，以開發強健且對情境敏感的評估指標。這些指標應能抵抗操縱，與每個使用案例相關，並基於人類判斷和真實世界的適用性。我們也建議建立與使用者和法規需求相符的特定領域評估基準，例如醫療保健和金融。透過鼓勵學術界、產業和監管機構之間的合作，我們可以創造出平衡靈活性和一致性的標準，確保 XAI 解釋是有意義的、可信的，且符合不斷演進的法規。

##### **ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning**
2502.04689v1 by Yuwei Yin, Giuseppe Carenini

Large language models (LLMs) achieve remarkable performance on challenging
benchmarks that are often structured as multiple-choice question-answering (QA)
tasks. Zero-shot Chain-of-Thought (CoT) prompting enhances reasoning in LLMs
but provides only vague and generic guidance ("think step by step"). This paper
introduces ARR, an intuitive and effective zero-shot prompting method that
explicitly incorporates three key steps in QA solving: analyzing the intent of
the question, retrieving relevant information, and reasoning step by step.
Comprehensive experiments across diverse and challenging QA tasks demonstrate
that ARR consistently improves the Baseline (without ARR prompting) and
outperforms CoT. Ablation and case studies further validate the positive
contributions of each component: analyzing, retrieving, and reasoning. Notably,
intent analysis plays a vital role in ARR. Additionally, extensive evaluations
across various model sizes, LLM series, and generation settings solidify the
effectiveness, robustness, and generalizability of ARR.

摘要：大型語言模型 (LLM) 在通常以多選題問答 (QA) 任務構成的具挑戰性基準測試中，獲得顯著的表現。零次學習思考鏈 (CoT) 提示增強了 LLM 中的推理，但僅提供模糊且通用的指導（「逐步思考」）。本文介紹 ARR，這是一種直覺且有效率的零次學習提示方法，明確納入了問答解決中的三個關鍵步驟：分析問題的意圖、擷取相關資訊以及逐步推理。在各種具挑戰性的問答任務中進行的全面實驗證明，ARR 持續改善基準（沒有 ARR 提示）並優於 CoT。消融和案例研究進一步驗證了每個組成部分的正面貢獻：分析、擷取和推理。值得注意的是，意圖分析在 ARR 中扮演至關重要的角色。此外，在各種模型大小、LLM 系列和產生設定中進行的廣泛評估，證實了 ARR 的有效性、穩健性和概括性。

##### **M-IFEval: Multilingual Instruction-Following Evaluation**
2502.04688v1 by Antoine Dussolle, Andrea Cardeña Díaz, Shota Sato, Peter Devine

Instruction following is a core capability of modern Large language models
(LLMs), making evaluating this capability essential to understanding these
models. The Instruction Following Evaluation (IFEval) benchmark from the
literature does this using objective criteria, offering a measure of LLM
performance without subjective AI or human judgement. However, it only includes
English instructions, limiting its ability to assess LLMs in other languages.
  We propose the Multilingual Instruction Following Evaluation (M-IFEval)
benchmark, expanding the evaluation to French, Japanese, and Spanish, with both
general and language-specific instructions. Applying this benchmark to 8
state-of-the-art LLMs, we find that benchmark performance across languages and
instruction types can vary widely, underscoring the importance of a
multilingual benchmark for evaluating LLMs in a diverse cultural context.

摘要：指令遵循是現代大型語言模型 (LLM) 的核心功能，因此評估此功能對於瞭解這些模型至關重要。文獻中的指令遵循評估 (IFEval) 基準使用客觀標準來執行此操作，提供 LLM 效能衡量，而無需主觀的人工智慧或人類判斷。然而，它僅包含英文指令，這限制了其評估其他語言中 LLM 的能力。我們提出多語言指令遵循評估 (M-IFEval) 基準，將評估擴展到法語、日語和西班牙語，並包含一般和語言特定指令。將此基準套用於 8 個最先進的 LLM，我們發現不同語言和指令類型的基準效能差異很大，這強調了在多元文化背景下評估 LLM 時多語言基準的重要性。

##### **Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization**
2502.04686v1 by Zelai Xu, Wanjun Gu, Chao Yu, Yi Wu, Yu Wang

Large language model (LLM)-based agents have recently shown impressive
progress in a variety of domains, including open-ended conversation and
multi-step decision-making. However, applying these agents to social deduction
games such as Werewolf, which requires both strategic decision-making and
free-form language interaction, remains non-trivial. Traditional methods based
on Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)
typically depend on a predefined action space, making them unsuitable for
language games with unconstrained text action space. Meanwhile, pure LLM-based
agents often suffer from intrinsic biases and require prohibitively large
datasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),
an iterative framework that addresses these challenges by first mapping
free-form text to a discrete latent space, where methods like CFR and RL can
learn strategic policy more effectively. We then translate the learned policy
back into natural language dialogues, which are used to fine-tune an LLM via
Direct Preference Optimization (DPO). By iteratively alternating between these
stages, our LSPO agent progressively enhances both strategic reasoning and
language communication. Experiment results on the Werewolf game show that our
method improves the agent's performance in each iteration and outperforms
existing Werewolf agents, underscoring its promise for free-form language
decision-making.

摘要：大型語言模型 (LLM) 驅動的代理最近在各種領域展現驚人的進步，包括開放式對話和多步驟決策制定。然而，將這些代理應用於社交推理遊戲（例如狼人殺），需要策略決策制定和自由形式語言互動，仍然非同小可。傳統方法基於反事實後悔最小化 (CFR) 或強化學習 (RL)，通常依賴於預定義的動作空間，這使得它們不適合於動作空間不受約束的語言遊戲。同時，純粹的 LLM 驅動的代理通常會受到內在偏差的影響，並且需要難以負擔的大型資料集來進行微調。我們提出了潛在空間策略最佳化 (LSPO)，這是一個迭代框架，通過首先將自由形式文字對應到離散潛在空間來解決這些挑戰，在該空間中，CFR 和 RL 等方法可以更有效地學習策略。然後，我們將學習到的策略轉換回自然語言對話，這些對話用於通過直接偏好最佳化 (DPO) 對 LLM 進行微調。通過在這些階段之間進行迭代交替，我們的 LSPO 代理逐漸增強了策略推理和語言溝通。狼人殺遊戲的實驗結果表明，我們的模型在每次迭代中都能提升代理的表現，並且優於現有的狼人殺代理，這突顯了其在自由形式語言決策制定方面的潛力。

##### **G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models**
2502.04684v1 by Mengdi Liu, Zhangyang Gao, Hong Chang, Stan Z. Li, Shiguang Shan, Xinlin Chen

Discovering the genotype-phenotype relationship is crucial for genetic
engineering, which will facilitate advances in fields such as crop breeding,
conservation biology, and personalized medicine. Current research usually
focuses on single species and small datasets due to limitations in phenotypic
data collection, especially for traits that require visual assessments or
physical measurements. Deciphering complex and composite phenotypes, such as
morphology, from genetic data at scale remains an open question. To break
through traditional generic models that rely on simplified assumptions, this
paper introduces G2PDiffusion, the first-of-its-kind diffusion model designed
for genotype-to-phenotype generation across multiple species. Specifically, we
use images to represent morphological phenotypes across species and redefine
phenotype prediction as conditional image generation. To this end, this paper
introduces an environment-enhanced DNA sequence conditioner and trains a stable
diffusion model with a novel alignment method to improve genotype-to-phenotype
consistency. Extensive experiments demonstrate that our approach enhances
phenotype prediction accuracy across species, capturing subtle genetic
variations that contribute to observable traits.

摘要：發現基因型與表型之間的關係對於遺傳工程至關重要，這將促進作物育種、保育生物學和個人化醫療等領域的進展。由於表型數據收集的限制，當前研究通常集中於單一物種和小數據集，特別是對於需要視覺評估或物理測量的性狀。從遺傳數據中破譯複雜和複合的表型（例如形態）仍然是一個懸而未決的問題。為了突破依賴於簡化假設的傳統通用模型，本文介紹了 G2PDiffusion，這是一個首創的擴散模型，專門用於跨多個物種進行基因型到表型的生成。具體來說，我們使用圖像來表示跨物種的形態表型，並將表型預測重新定義為條件圖像生成。為此，本文介紹了一個環境增強的 DNA 序列調節器，並訓練了一個具有新對齊方法的穩定擴散模型，以提高基因型到表型的稠密性。大量的實驗表明，我們的做法提高了跨物種的表型預測準確度，捕捉到導致可觀察性狀的細微遺傳變異。

##### **AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts**
2502.04674v1 by Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura

Effective linguistic choices that attract potential customers play crucial
roles in advertising success. This study aims to explore the linguistic
features of ad texts that influence human preferences. Although the creation of
attractive ad texts is an active area of research, progress in understanding
the specific linguistic features that affect attractiveness is hindered by
several obstacles. First, human preferences are complex and influenced by
multiple factors, including their content, such as brand names, and their
linguistic styles, making analysis challenging. Second, publicly available ad
text datasets that include human preferences are lacking, such as ad
performance metrics and human feedback, which reflect people's interests. To
address these problems, we present AdParaphrase, a paraphrase dataset that
contains human preferences for pairs of ad texts that are semantically
equivalent but differ in terms of wording and style. This dataset allows for
preference analysis that focuses on the differences in linguistic features. Our
analysis revealed that ad texts preferred by human judges have higher fluency,
longer length, more nouns, and use of bracket symbols. Furthermore, we
demonstrate that an ad text-generation model that considers these findings
significantly improves the attractiveness of a given text. The dataset is
publicly available at: https://github.com/CyberAgentAILab/AdParaphrase.

摘要：<paragraph>在廣告中，能吸引潛在客戶的有效語言選擇，在廣告成功中扮演著至關重要的角色。本研究旨在探討影響人類偏好之廣告文字的語言特徵。儘管創造有吸引力的廣告文字是研究的熱門領域，但理解影響吸引力的特定語言特徵的進展卻受到許多障礙阻礙。首先，人類的偏好很複雜，並受到多重因素的影響，包括內容（例如品牌名稱）和語言風格，這使得分析極具挑戰性。其次，缺乏包含人類偏好的公開廣告文字資料集，例如廣告成效指標和人類回饋，這些資料反映了人們的興趣。為了解決這些問題，我們提出了 AdParaphrase，這是一個同義詞資料集，其中包含人類對語義等價但措辭和風格不同的廣告文字對的偏好。此資料集允許進行偏好分析，重點放在語言特徵的差異上。我們的分析顯示，人類評審偏好的廣告文字具有更高的流暢度、更長的長度、更多的名詞和括號符號的使用。此外，我們證明了一個考慮這些發現的廣告文字生成模型，可以顯著提高給定文字的吸引力。此資料集可在以下網址公開取得：https://github.com/CyberAgentAILab/AdParaphrase。</paragraph>

##### **${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving**
2502.04671v1 by Amitayush Thakur, George Tsoukalas, Greg Durrett, Swarat Chaudhuri

Neural networks have shown substantial promise at automatic theorem-proving
in interactive proof assistants (ITPs) like Lean and Coq. However, most neural
theorem-proving models are restricted to specific ITPs, leaving out
opportunities for cross-lingual $\textit{transfer}$ between ITPs. We address
this weakness with a multilingual proof framework, ${\rm P{\small ROOF}W{\small
ALA}}$, that allows a standardized form of interaction between neural
theorem-provers and two established ITPs (Coq and Lean). It enables the
collection of multilingual proof step data -- data recording the result of
proof actions on ITP states -- for training neural provers. ${\rm P{\small
ROOF}W{\small ALA}}$ allows the systematic evaluation of a model's performance
across different ITPs and problem domains via efficient parallel proof search
algorithms. We show that multilingual training enabled by ${\rm P{\small
ROOF}W{\small ALA}}$ can lead to successful transfer across ITPs. Specifically,
a model trained on a mix of ${\rm P{\small ROOF}W{\small ALA}}$-generated Coq
and Lean data outperforms Lean-only and Coq-only models on the standard
prove-at-$k$ metric. We open source all code including code for the
$\href{https://github.com/trishullab/proof-wala}{ProofWala\; Framework}$, and
the $\href{https://github.com/trishullab/itp-interface}{Multilingual\; ITP\;
interaction\; framework}$.

摘要：<paragraph>神經網路已在互動式證明輔助工具 (ITP) 中，例如 Lean 和 Coq，展現出自動定理證明方面的顯著前景。然而，大多數神經定理證明模型僅限於特定 ITP，忽略了 ITP 之間跨語言「轉移」的機會。我們透過多語言證明架構 ${\rm P{\small ROOF}W{\small ALA}}$ 來解決這個弱點，該架構允許神經定理證明器與兩個已建立的 ITP（Coq 和 Lean）之間進行標準化的互動。它能收集多語言證明步驟資料，即記錄 ITP 狀態中證明動作結果的資料，以訓練神經證明器。${\rm P{\small ROOF}W{\small ALA}}$ 允許透過有效並行的證明搜尋演算法，系統性地評估模型在不同 ITP 和問題領域的效能。我們展示了 ${\rm P{\small ROOF}W{\small ALA}}$ 所啟用的多語言訓練，能成功地在 ITP 之間進行轉移。具體來說，在 ${\rm P{\small ROOF}W{\small ALA}}$ 生成的 Coq 和 Lean 資料組合上訓練的模型，在標準的 prove-at-$k$ 指標上，優於僅使用 Lean 和僅使用 Coq 的模型。我們開放所有程式碼，包括 ${\rm P{\small ROOF}W{\small ALA}}$ 架構的程式碼 $\href{https://github.com/trishullab/proof-wala}{ProofWala\; Framework}$，以及多語言 ITP 互動架構 $\href{https://github.com/trishullab/itp-interface}{Multilingual\; ITP\; interaction\; framework}$。</paragraph>

##### **CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation**
2502.04670v1 by Bowen Song, Zecheng Zhang, Zhaoxu Luo, Jason Hu, Wei Yuan, Jing Jia, Zhengxu Tang, Guanyang Wang, Liyue Shen

Diffusion models have emerged as powerful tools for generative tasks,
producing high-quality outputs across diverse domains. However, how the
generated data responds to the initial noise perturbation in diffusion models
remains under-explored, which hinders understanding the controllability of the
sampling process. In this work, we first observe an interesting phenomenon: the
relationship between the change of generation outputs and the scale of initial
noise perturbation is highly linear through the diffusion ODE sampling. Then we
provide both theoretical and empirical study to justify this linearity property
of this input-output (noise-generation data) relationship. Inspired by these
new insights, we propose a novel Controllable and Constrained Sampling method
(CCS) together with a new controller algorithm for diffusion models to sample
with desired statistical properties while preserving good sample quality. We
perform extensive experiments to compare our proposed sampling approach with
other methods on both sampling controllability and sampled data quality.
Results show that our CCS method achieves more precisely controlled sampling
while maintaining superior sample quality and diversity.

摘要：擴散模型已成為生成任務的強大工具，在各種領域產生高品質的輸出。然而，生成資料如何回應擴散模型中的初始雜訊擾動仍未得到充分探討，這阻礙了對取樣過程可控性的理解。在這項工作中，我們首先觀察到一個有趣的現象：生成輸出變化與擴散 ODE 取樣中初始雜訊擾動的規模之間的關係是高度線性的。然後，我們提供理論和實證研究來證明此輸入輸出（雜訊生成資料）關係的線性性質。受到這些新見解的啟發，我們提出了一種新的可控約束取樣方法 (CCS) 以及一種新的控制器演算法，用於擴散模型，以在保留良好樣本品質的同時，以所需的統計特性進行取樣。我們進行了大量的實驗，以比較我們提出的取樣方法與其他方法在取樣可控性和取樣資料品質上的表現。結果顯示，我們的 CCS 方法實現了更精確的受控取樣，同時保持優異的樣本品質和多樣性。

##### **A Comprehensive Review on Noise Control of Diffusion Model**
2502.04669v1 by Zhehao Guo, Jiedong Lang, Shuyu Huang, Yunfei Gao, Xintong Ding

Diffusion models have recently emerged as powerful generative frameworks for
producing high-quality images. A pivotal component of these models is the noise
schedule, which governs the rate of noise injection during the diffusion
process. Since the noise schedule substantially influences sampling quality and
training quality, understanding its design and implications is crucial. In this
discussion, various noise schedules are examined, and their distinguishing
features and performance characteristics are highlighted.

摘要：擴散模型最近已成為強大的生成式架構，可用於製作高品質影像。這些模型的樞紐元件是雜訊行程，它控制擴散過程中雜訊注入的比率。由於雜訊行程會大幅影響取樣品質和訓練品質，因此了解其設計和影響至關重要。在本次討論中，我們將檢視各種雜訊行程，並重點說明它們的區別特徵和效能特性。

##### **Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization**
2502.04667v1 by Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu

Training large language models (LLMs) with high-quality Chain-of-Thought
(CoT) annotations has become a widely adopted strategy due to its significant
enhancement of reasoning capabilities. To fully comprehend this approach, two
questions naturally arise: (Q1) What advantages does training with CoT offer
compared to training without CoT? (Q2) If there are advantages, what are the
underlying mechanisms of explicit CoT training? Analyzing the advantages and
mechanisms of CoT training is challenging due to the many factors involved. To
address this, we conduct a detailed analysis using clear and controllable data
distributions and, for the first time, reveal that CoT training offers the
following advantages: (1) Training with CoT markedly improves reasoning
generalization, extending it from in-distribution (ID) to both ID and
out-of-distribution (OOD) scenarios, while also speeding up convergence; (2)
Even when training with CoT includes a certain range of erroneous reasoning
steps, it still enables the model to learn reasoning patterns, leading to
systematic generalization. We further explore the underlying mechanisms from a
circuit perspective: (1) The data distribution (e.g., ratio $\lambda$ and
pattern) plays a crucial role in influencing the model's systematic
generalization; (2) CoT training (with two-hop facts) internalizes reasoning
into a two-stage generalizing circuit, where the number of stages corresponds
to the explicit reasoning steps during training. Our findings elucidate the
mechanisms underlying explicit CoT training and offer critical insights into
tuning strategies for LLMs to achieve robust generalization.

摘要：<paragraph>使用高品質思維鏈 (CoT) 標註來訓練大型語言模型 (LLM) 已成為廣泛採用的策略，因為它顯著增強了推理能力。為了充分理解這種方法，自然會產生兩個問題：(Q1) 與沒有 CoT 的訓練相比，使用 CoT 訓練有哪些優點？(Q2) 如果有優點，明確的 CoT 訓練的底層機制是什麼？分析 CoT 訓練的優點和機制具有挑戰性，因為涉及許多因素。為了解決這個問題，我們使用清晰且可控的資料分佈進行詳細分析，並首次揭示 CoT 訓練提供以下優點：(1) 使用 CoT 進行訓練顯著改善推理泛化，將其從分佈內 (ID) 延伸到 ID 和分佈外 (OOD) 場景，同時也加快了收斂速度；(2) 即使使用 CoT 進行訓練包含一定範圍的錯誤推理步驟，它仍然使模型能夠學習推理模式，從而導致系統性泛化。我們進一步從電路角度探討其底層機制：(1) 資料分佈（例如比率 $\lambda$ 和模式）在影響模型的系統性泛化中扮演著至關重要的角色；(2) CoT 訓練（使用兩跳事實）將推理內化為兩階段泛化電路，其中階段數對應於訓練期間的明確推理步驟。我們的發現闡明了明確 CoT 訓練的底層機制，並為調整 LLM 的策略提供了關鍵見解，以實現強大的泛化。</paragraph>

##### **Shifting Attention to You: Personalized Brain-Inspired AI Models**
2502.04658v1 by Stephen Chong Zhao, Yang Hu, Jason Lee, Andrew Bender, Trisha Mazumdar, Mark Wallace, David A. Tovar

The integration of human and artificial intelligence represents a scientific
opportunity to advance our understanding of information processing, as each
system offers unique computational insights that can enhance and inform the
other. The synthesis of human cognitive principles with artificial intelligence
has the potential to produce more interpretable and functionally aligned
computational models, while simultaneously providing a formal framework for
investigating the neural mechanisms underlying perception, learning, and
decision-making through systematic model comparisons and representational
analyses. In this study, we introduce personalized brain-inspired modeling that
integrates human behavioral embeddings and neural data to align with cognitive
processes. We took a stepwise approach, fine-tuning the Contrastive
Language-Image Pre-training (CLIP) model with large-scale behavioral decisions,
group-level neural data, and finally, participant-level neural data within a
broader framework that we have named CLIP-Human-Based Analysis (CLIP-HBA). We
found that fine-tuning on behavioral data enhances its ability to predict human
similarity judgments while indirectly aligning it with dynamic representations
captured via MEG. To further gain mechanistic insights into the temporal
evolution of cognitive processes, we introduced a model specifically fine-tuned
on millisecond-level MEG neural dynamics (CLIP-HBA-MEG). This model resulted in
enhanced temporal alignment with human neural processing while still showing
improvement on behavioral alignment. Finally, we trained individualized models
on participant-specific neural data, effectively capturing individualized
neural dynamics and highlighting the potential for personalized AI systems.
These personalized systems have far-reaching implications for the fields of
medicine, cognitive research, human-computer interfaces, and AI development.

摘要：<paragraph>人類與人工智慧的整合代表了一項科學機會，可以增進我們對資訊處理的理解，因為每個系統都提供獨特的運算見解，可以增強並告知另一個系統。人類認知原則與人工智慧的綜合具有產生更具可解釋性和功能性對齊運算模型的潛力，同時為透過系統性模型比較和表徵分析來調查知覺、學習和決策背後的類神經機制提供一個正式架構。在這項研究中，我們引入了個人化的大腦啟發模型，整合了人類行為嵌入和神經資料，以與認知過程保持一致。我們採取逐步方法，微調對比語言影像預訓練 (CLIP) 模型，並使用大規模行為決策、群組層級神經資料，最後在我們命名為 CLIP 人類為基礎分析 (CLIP-HBA) 的更廣泛架構中使用參與者層級神經資料。我們發現，在行為資料上進行微調增強了其預測人類相似性判斷的能力，同時間接地將其與透過 MEG 擷取的動態表徵對齊。為了進一步獲得對認知過程時間演化的機制見解，我們引入了專門針對毫秒級 MEG 神經動態進行微調的模型 (CLIP-HBA-MEG)。此模型增強了與人類神經處理的時間對齊，同時仍顯示出行為對齊的改善。最後，我們針對參與者特定的神經資料訓練了個別化模型，有效擷取個別化的神經動態，並突顯了個人化 AI 系統的潛力。這些個人化系統對醫學、認知研究、人機介面和 AI 開發領域具有深遠的影響。</paragraph>

##### **Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement**
2502.04655v1 by Lin Tian, Emily Booth, Francesco Bailo, Julian Droogan, Marian-Andrei Rizoiu

In today's digital age, conspiracies and information campaigns can emerge
rapidly and erode social and democratic cohesion. While recent deep learning
approaches have made progress in modeling engagement through language and
propagation models, they struggle with irregularly sampled data and early
trajectory assessment. We present IC-Mamba, a novel state space model that
forecasts social media engagement by modeling interval-censored data with
integrated temporal embeddings. Our model excels at predicting engagement
patterns within the crucial first 15-30 minutes of posting (RMSE 0.118-0.143),
enabling rapid assessment of content reach. By incorporating interval-censored
modeling into the state space framework, IC-Mamba captures fine-grained
temporal dynamics of engagement growth, achieving a 4.72% improvement over
state-of-the-art across multiple engagement metrics (likes, shares, comments,
and emojis). Our experiments demonstrate IC-Mamba's effectiveness in
forecasting both post-level dynamics and broader narrative patterns (F1
0.508-0.751 for narrative-level predictions). The model maintains strong
predictive performance across extended time horizons, successfully forecasting
opinion-level engagement up to 28 days ahead using observation windows of 3-10
days. These capabilities enable earlier identification of potentially
problematic content, providing crucial lead time for designing and implementing
countermeasures. Code is available at: https://github.com/ltian678/ic-mamba. An
interactive dashboard demonstrating our results is available at:
https://ic-mamba.behavioral-ds.science.

摘要：<paragraph>在當今數位時代，陰謀論和資訊宣傳活動可能迅速浮現，並侵蝕社會和民主凝聚力。儘管最近的深度學習方法在透過語言和傳播模型來模擬互動方面已取得進展，但它們仍難以處理不規則採樣的資料和早期軌跡評估。我們提出 IC-Mamba，這是一個新穎的狀態空間模型，透過使用整合時序嵌入來模擬區間審查資料，來預測社群媒體互動。我們的模型擅於預測發布後最初 15-30 分鐘內的互動模式（RMSE 0.118-0.143），能夠快速評估內容觸及率。透過將區間審查模擬納入狀態空間架構中，IC-Mamba 能夠捕捉互動成長的細微時序動態，在多項互動指標（按讚、分享、留言和表情符號）上比現有技術進步了 4.72%。我們的實驗證明了 IC-Mamba 在預測貼文層級動態和更廣泛的敘事模式方面（敘事層級預測的 F1 為 0.508-0.751）的有效性。該模型在延長期限內維持強大的預測效能，使用 3-10 天的觀察視窗，成功預測了未來 28 天的意見層級互動。這些功能能夠更早辨識潛在有問題的內容，為設計和實施對策提供了至關重要的前置時間。程式碼可在以下位置取得：https://github.com/ltian678/ic-mamba。展示我們結果的互動式儀表板可在以下位置取得：https://ic-mamba.behavioral-ds.science。</paragraph>

##### **Importance Sampling via Score-based Generative Models**
2502.04646v1 by Heasung Kim, Taekyun Lee, Hyeji Kim, Gustavo de Veciana

Importance sampling, which involves sampling from a probability density
function (PDF) proportional to the product of an importance weight function and
a base PDF, is a powerful technique with applications in variance reduction,
biased or customized sampling, data augmentation, and beyond. Inspired by the
growing availability of score-based generative models (SGMs), we propose an
entirely training-free Importance sampling framework that relies solely on an
SGM for the base PDF. Our key innovation is realizing the importance sampling
process as a backward diffusion process, expressed in terms of the score
function of the base PDF and the specified importance weight function--both
readily available--eliminating the need for any additional training. We conduct
a thorough analysis demonstrating the method's scalability and effectiveness
across diverse datasets and tasks, including importance sampling for industrial
and natural images with neural importance weight functions. The training-free
aspect of our method is particularly compelling in real-world scenarios where a
single base distribution underlies multiple biased sampling tasks, each
requiring a different importance weight function. To the best of our knowledge
our approach is the first importance sampling framework to achieve this.

摘要：重要性採樣，涉及從與重要性權重函數和基本 PDF 成正比的機率密度函數 (PDF) 中進行採樣，是一種強大的技術，可應用於變異數減少、有偏或自訂採樣、資料擴充等方面。受基於分數的生成模型 (SGM) 日益普及的啟發，我們提出了一個完全無需訓練的重要採樣架構，該架構僅依賴於 SGM 來作為基本 PDF。我們的關鍵創新是將重要性採樣過程實現為一個反向擴散過程，用基本 PDF 的分數函數和指定的權重函數來表示，這兩個函數都很容易取得，因此無需任何額外的訓練。我們進行了一項徹底的分析，證明了該方法在各種資料集和任務中的可擴充性和有效性，包括使用神經重要性權重函數對工業和自然影像進行重要性採樣。在現實世界中，單一基本分佈會對應到多個有偏採樣任務的情況下，我們的無訓練方法特別具有吸引力，因為每個任務都需要不同的重要性權重函數。據我們所知，我們的途徑是第一個實現此目標的重要採樣架構。

##### **Cross-Encoder Rediscovers a Semantic Variant of BM25**
2502.04645v1 by Meng Lu, Catherine Chen, Carsten Eickhoff

Neural Ranking Models (NRMs) have rapidly advanced state-of-the-art
performance on information retrieval tasks. In this work, we investigate a
Cross-Encoder variant of MiniLM to determine which relevance features it
computes and where they are stored. We find that it employs a semantic variant
of the traditional BM25 in an interpretable manner, featuring localized
components: (1) Transformer attention heads that compute soft term frequency
while controlling for term saturation and document length effects, and (2) a
low-rank component of its embedding matrix that encodes inverse document
frequency information for the vocabulary. This suggests that the Cross-Encoder
uses the same fundamental mechanisms as BM25, but further leverages their
capacity to capture semantics for improved retrieval performance. The granular
understanding lays the groundwork for model editing to enhance model
transparency, addressing safety concerns, and improving scalability in training
and real-world applications.

摘要：神經排序模型 (NRM) 已快速提升資訊檢索任務的最新技術效能。在這項工作中，我們研究了 MiniLM 的交叉編碼器變體，以確定它計算哪些相關性特徵以及它們儲存在哪裡。我們發現它以可詮釋的方式採用傳統 BM25 的語義變體，具有局部元件：(1) Transformer 注意力權重計算軟詞頻，同時控制詞彙飽和度和文件長度效應，以及 (2) 其嵌入矩陣的低秩元件，用於編碼詞彙的逆文件頻率資訊。這表明交叉編碼器使用與 BM25 相同的基本機制，但進一步利用它們擷取語義的能力來改善檢索效能。細緻的理解為模型編輯奠定了基礎，以增強模型透明度、解決安全問題，並改善訓練和實際應用中的可擴充性。

##### **Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**
2502.04644v1 by Junde Wu, Jiayuan Zhu, Yuyuan Liu

We introduce Agentic Reasoning, a framework that enhances large language
model (LLM) reasoning by integrating external tool-using agents. Unlike
conventional LLM-based reasoning approaches, which rely solely on internal
inference, Agentic Reasoning dynamically engages web search, code execution,
and structured reasoning-context memory to solve complex problems requiring
deep research and multi-step logical deduction. Our framework introduces the
Mind Map agent, which constructs a structured knowledge graph to track logical
relationships, improving deductive reasoning. Additionally, the integration of
web-search and coding agents enables real-time retrieval and computational
analysis, enhancing reasoning accuracy and decision-making. Evaluations on
PhD-level scientific reasoning (GPQA) and domain-specific deep research tasks
demonstrate that our approach significantly outperforms existing models,
including leading retrieval-augmented generation (RAG) systems and
closed-source LLMs. Moreover, our results indicate that agentic reasoning
improves expert-level knowledge synthesis, test-time scalability, and
structured problem-solving. The code is at:
https://github.com/theworldofagents/Agentic-Reasoning.

摘要：我們引入了代理推理，一個透過整合外部工具使用代理來增強大型語言模型 (LLM) 推理的框架。與僅依賴於內部推論的傳統基於 LLM 的推理方法不同，代理推理動態地運用網路搜尋、程式碼執行和結構化推理情境記憶來解決需要深入研究和多步驟邏輯推論的複雜問題。我們的框架引入了心智圖代理，它建立一個結構化的知識圖譜來追蹤邏輯關係，改善演繹推理。此外，整合網路搜尋和編碼代理能進行即時擷取和運算分析，增強推理準確度和決策制定。在博士等級科學推理 (GPQA) 和特定領域的深入研究任務上的評估顯示，我們的做法明顯優於現有模型，包括領先的檢索增強生成 (RAG) 系統和封閉原始碼 LLM。此外，我們的結果顯示，代理推理改進了專家級知識綜合、測試時間可擴充性和結構化問題解決。程式碼在：https://github.com/theworldofagents/Agentic-Reasoning。

##### **Confidence Elicitation: A New Attack Vector for Large Language Models**
2502.04643v1 by Brian Formento, Chuan Sheng Foo, See-Kiong Ng

A fundamental issue in deep learning has been adversarial robustness. As
these systems have scaled, such issues have persisted. Currently, large
language models (LLMs) with billions of parameters suffer from adversarial
attacks just like their earlier, smaller counterparts. However, the threat
models have changed. Previously, having gray-box access, where input embeddings
or output logits/probabilities were visible to the user, might have been
reasonable. However, with the introduction of closed-source models, no
information about the model is available apart from the generated output. This
means that current black-box attacks can only utilize the final prediction to
detect if an attack is successful. In this work, we investigate and demonstrate
the potential of attack guidance, akin to using output probabilities, while
having only black-box access in a classification setting. This is achieved
through the ability to elicit confidence from the model. We empirically show
that the elicited confidence is calibrated and not hallucinated for current
LLMs. By minimizing the elicited confidence, we can therefore increase the
likelihood of misclassification. Our new proposed paradigm demonstrates
promising state-of-the-art results on three datasets across two models
(LLaMA-3-8B-Instruct and Mistral-7B-Instruct-V0.3) when comparing our technique
to existing hard-label black-box attack methods that introduce word-level
substitutions.

摘要：深度學習中的基本問題一直是對抗魯棒性。隨著這些系統的擴展，這些問題仍然存在。目前，擁有數十億個參數的大型語言模型 (LLM) 與其早期較小的對應模型一樣，會受到對抗性攻擊。然而，威脅模型已經改變。以前，具有灰盒存取權限，其中使用者可以看到輸入嵌入或輸出 logit/機率，可能是合理的。然而，隨著封閉原始碼模型的引入，除了產生的輸出之外，沒有任何關於模型的資訊可用。這表示目前的 black-box 攻擊只能利用最終預測來偵測攻擊是否成功。在這項工作中，我們探討並展示了攻擊指導的潛力，類似於使用輸出機率，同時在分類設定中只有 black-box 存取權限。這是透過引發模型信心的能力來實現的。我們經驗性地展示了引發的信心是經過校準的，而不是對目前 LLM 產生的幻覺。透過最小化引發的信心，我們因此可以增加誤分類的可能性。我們新提出的範例在比較我們的技術與現有的硬標籤 black-box 攻擊方法（引入字元層級替換）時，在兩個模型（LLaMA-3-8B-Instruct 和 Mistral-7B-Instruct-V0.3）的 3 個資料集上展示了有前途的最新結果。

##### **Extracting and Understanding the Superficial Knowledge in Alignment**
2502.04602v1 by Runjin Chen, Gabriel Jacob Perin, Xuxi Chen, Xilun Chen, Yan Han, Nina S. T. Hirata, Junyuan Hong, Bhavya Kailkhura

Alignment of large language models (LLMs) with human values and preferences,
often achieved through fine-tuning based on human feedback, is essential for
ensuring safe and responsible AI behaviors. However, the process typically
requires substantial data and computation resources. Recent studies have
revealed that alignment might be attainable at lower costs through simpler
methods, such as in-context learning. This leads to the question: Is alignment
predominantly superficial? In this paper, we delve into this question and
provide a quantitative analysis. We formalize the concept of superficial
knowledge, defining it as knowledge that can be acquired through easily token
restyling, without affecting the model's ability to capture underlying causal
relationships between tokens. We propose a method to extract and isolate
superficial knowledge from aligned models, focusing on the shallow
modifications to the final token selection process. By comparing models
augmented only with superficial knowledge to fully aligned models, we quantify
the superficial portion of alignment. Our findings reveal that while
superficial knowledge constitutes a significant portion of alignment,
particularly in safety and detoxification tasks, it is not the whole story.
Tasks requiring reasoning and contextual understanding still rely on deeper
knowledge. Additionally, we demonstrate two practical advantages of isolated
superficial knowledge: (1) it can be transferred between models, enabling
efficient offsite alignment of larger models using extracted superficial
knowledge from smaller models, and (2) it is recoverable, allowing for the
restoration of alignment in compromised models without sacrificing performance.

摘要：大型語言模型 (LLM) 與人類價值觀和偏好的對齊，通常透過根據人類回饋進行微調來達成，對於確保安全且負責任的 AI 行為至關重要。然而，此程序通常需要大量的資料和運算資源。最近的研究顯示，透過更簡單的方法（例如情境學習）可能可以用更低的成本達成對齊。這引發了一個問題：對齊是否主要是表面的？在本文中，我們深入探討這個問題，並提供定量分析。我們將表面知識的概念形式化，將其定義為可透過輕鬆的標記重塑獲得的知識，而不會影響模型擷取標記之間底層因果關係的能力。我們提出一個方法來從對齊的模型中提取和分離表面知識，重點放在對最終標記選擇過程的淺層修改。透過比較僅增加表面知識的模型和完全對齊的模型，我們量化了對齊的表面部分。我們的發現顯示，儘管表面知識構成對齊的很大一部分，特別是在安全和解毒任務中，但這並非全部。需要推理和情境理解的任務仍然依賴於更深入的知識。此外，我們展示了孤立的表面知識的兩個實際優點：(1) 它可以在模型之間轉移，使用從較小模型中提取的表面知識，能有效地對較大型模型進行場外對齊，以及 (2) 它具有可復原性，允許在不犧牲效能的情況下恢復受損模型的對齊。

##### **The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance**
2502.04593v1 by Mohammad Reza Rezaei, Adji Bousso Dieng

Current state-of-the-art dynamical models, such as Mamba, assume the same
level of noisiness for all elements of a given sequence, which limits their
performance on noisy temporal data. In this paper, we introduce the
$\alpha$-Alternator, a novel generative model for time-dependent data that
dynamically adapts to the complexity introduced by varying noise levels in
sequences. The $\alpha$-Alternator leverages the Vendi Score (VS), a flexible
similarity-based diversity metric, to adjust, at each time step $t$, the
influence of the sequence element at time $t$ and the latent representation of
the dynamics up to that time step on the predicted future dynamics. This
influence is captured by a parameter that is learned and shared across all
sequences in a given dataset. The sign of this parameter determines the
direction of influence. A negative value indicates a noisy dataset, where a
sequence element that increases the VS is considered noisy, and the model
relies more on the latent history when processing that element. Conversely,
when the parameter is positive, a sequence element that increases the VS is
considered informative, and the $\alpha$-Alternator relies more on this new
input than on the latent history when updating its predicted latent dynamics.
The $\alpha$-Alternator is trained using a combination of observation masking
and Alternator loss minimization. Masking simulates varying noise levels in
sequences, enabling the model to be more robust to these fluctuations and
improving its performance in trajectory prediction, imputation, and
forecasting. Our experimental results demonstrate that the $\alpha$-Alternator
outperforms both Alternators and state-of-the-art state-space models across
neural decoding and time-series forecasting benchmarks.

摘要：<paragraph>例如 Mamba 等現今最先進的動態模型，假設給定序列中所有元素的雜訊程度相同，這限制了它們在雜訊時間資料上的效能。在本文中，我們介紹了 $\alpha$-Alternator，這是一個新穎的時序資料生成模型，可動態適應序列中不同雜訊程度帶來的複雜性。$\alpha$-Alternator 利用了 Vendi 分數 (VS)，這是一個彈性的基於相似性的多樣性度量，在每個時間步驟 $t$ 調整時間 $t$ 的序列元素影響，以及動態的潛在表示，直到時間步驟對預測的未來動態。這種影響是由一個參數擷取的，這個參數在給定資料集中的所有序列中學習和共享。此參數的符號決定了影響的方向。負值表示雜訊資料集，其中增加 VS 的序列元素被視為雜訊，而模型在處理該元素時更依賴潛在歷史。相反，當參數為正時，增加 VS 的序列元素被視為資訊性的，而 $\alpha$-Alternator 在更新其預測潛在動態時，比潛在歷史更依賴於這個新的輸入。$\alpha$-Alternator 使用觀測遮罩和 Alternator 損失最小化的組合進行訓練。遮罩模擬序列中不同的雜訊程度，使模型對這些波動更具魯棒性，並改善其在軌跡預測、插補和預測中的效能。我們的實驗結果表明，$\alpha$-Alternator 在神經解碼和時序預測基準上，都優於 Alternator 和最先進的狀態空間模型。</paragraph>

##### **CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements**
2502.04592v1 by Yang Zhang, Wenbo Yang, Jun Wang, Qiang Ma, Jie Xiong

Accurately forecasting the impact of macroeconomic events is critical for
investors and policymakers. Salient events like monetary policy decisions and
employment reports often trigger market movements by shaping expectations of
economic growth and risk, thereby establishing causal relationships between
events and market behavior. Existing forecasting methods typically focus either
on textual analysis or time-series modeling, but fail to capture the
multi-modal nature of financial markets and the causal relationship between
events and price movements. To address these gaps, we propose CAMEF
(Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a
multi-modality framework that effectively integrates textual and time-series
data with a causal learning mechanism and an LLM-based counterfactual event
augmentation technique for causal-enhanced financial forecasting. Our
contributions include: (1) a multi-modal framework that captures causal
relationships between policy texts and historical price data; (2) a new
financial dataset with six types of macroeconomic releases from 2008 to April
2024, and high-frequency real trading data for five key U.S. financial assets;
and (3) an LLM-based counterfactual event augmentation strategy. We compare
CAMEF to state-of-the-art transformer-based time-series and multi-modal
baselines, and perform ablation studies to validate the effectiveness of the
causal learning mechanism and event types.

摘要：準確預測巨觀經濟事件的影響對投資者和政策制定者至關重要。貨幣政策決策和就業報告等顯著事件通常會通過塑造對經濟增長和風險的預期來觸發市場波動，從而建立事件與市場行為之間的因果關係。現有的預測方法通常側重於文本分析或時間序列建模，但無法捕捉金融市場的多模態特性以及事件與價格變動之間的因果關係。為了解決這些差距，我們提出了 CAMEF（因果增強的多模態事件驅動金融預測），這是一個多模態框架，有效地將文本和時間序列數據與因果學習機制和基於 LLM 的反事實事件增強技術相結合，用於因果增強的金融預測。我們的貢獻包括：(1) 一個多模態框架，捕捉政策文本和歷史價格數據之間的因果關係；(2) 一個新的金融數據集，包含 2008 年至 2024 年 4 月期間六種類型的宏觀經濟發布，以及五種美國主要金融資產的高頻真實交易數據；(3) 一種基於 LLM 的反事實事件增強策略。我們將 CAMEF 與最先進的基於變換器的時間序列和多模態基線進行比較，並進行消融研究以驗證因果學習機制和事件類型的有效性。

##### **Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective**
2502.04591v1 by Piero Deidda, Kaicheng Zhang, Desmond Higham, Francesco Tudisco

Oversmoothing is a fundamental challenge in graph neural networks (GNNs): as
the number of layers increases, node embeddings become increasingly similar,
and model performance drops sharply. Traditionally, oversmoothing has been
quantified using metrics that measure the similarity of neighbouring node
features, such as the Dirichlet energy. While these metrics are related to
oversmoothing, we argue they have critical limitations and fail to reliably
capture oversmoothing in realistic scenarios. For instance, they provide
meaningful insights only for very deep networks and under somewhat strict
conditions on the norm of network weights and feature representations. As an
alternative, we propose measuring oversmoothing by examining the numerical or
effective rank of the feature representations. We provide theoretical support
for this approach, demonstrating that the numerical rank of feature
representations converges to one for a broad family of nonlinear activation
functions under the assumption of nonnegative trained weights. To the best of
our knowledge, this is the first result that proves the occurrence of
oversmoothing without assumptions on the boundedness of the weight matrices.
Along with the theoretical findings, we provide extensive numerical evaluation
across diverse graph architectures. Our results show that rank-based metrics
consistently capture oversmoothing, whereas energy-based metrics often fail.
Notably, we reveal that a significant drop in the rank aligns closely with
performance degradation, even in scenarios where energy metrics remain
unchanged.

摘要：過度平滑是圖神經網路 (GNN) 中的基本挑戰：隨著層數增加，節點嵌入變得越來越相似，模型效能急劇下降。傳統上，過度平滑已使用度量鄰近節點特徵相似性的指標量化，例如 Dirichlet 能量。雖然這些指標與過度平滑相關，但我們認為它們有嚴重的限制，無法在實際情況中可靠地捕捉過度平滑。例如，它們僅對非常深的網路提供有意義的見解，且對網路權重和特徵表示的範數有嚴格的條件。作為替代方案，我們建議透過檢查特徵表示的數值或有效秩來測量過度平滑。我們為此方法提供理論支持，證明特徵表示的數值秩在非負訓練權重的假設下，對於非線性激活函數的廣泛族會收斂到一。據我們所知，這是第一個證明過度平滑發生的結果，而沒有對權重矩陣的界限性做出假設。除了理論發現之外，我們還提供跨不同圖形架構的廣泛數值評估。我們的結果表明，基於秩的指標始終捕捉過度平滑，而基於能量的指標則經常失敗。值得注意的是，我們發現秩的顯著下降與效能下降密切相關，即使在能量指標保持不變的情況下也是如此。

##### **Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context**
2502.04580v1 by Taejong Joo, Diego Klabjan

Transformers have demonstrated remarkable in-context learning (ICL)
capabilities, adapting to new tasks by simply conditioning on demonstrations
without parameter updates. Compelling empirical and theoretical evidence
suggests that ICL, as a general-purpose learner, could outperform task-specific
models. However, it remains unclear to what extent the transformers optimally
learn in-context compared to principled learning algorithms. To bridge this
gap, we introduce a new framework for quantifying optimality of ICL as a
learning algorithm in stylized settings. Our findings reveal a striking
dichotomy: while ICL initially matches the efficiency of a Bayes optimal
estimator, its efficiency significantly deteriorates in long context. Through
an information-theoretic analysis, we show that the diminishing efficiency is
inherent to ICL. These results clarify the trade-offs in adopting ICL as a
universal problem solver, motivating a new generation of on-the-fly adaptive
methods without the diminishing efficiency.

摘要：Transformer已展現出卓越的脈絡學習 (ICL) 能力，只要透過示範進行條件化，就能適應新任務，而無需參數更新。令人信服的經驗和理論證據表明，ICL 作為通用學習器，可以優於特定任務模型。然而，Transformer在脈絡中學習的最佳程度與原則性學習演算法相比，仍不清楚。為了彌補這個差距，我們引入了一個新的架構，用於量化 ICL 作為標準化設定中的學習演算法的最佳性。我們的發現揭示了一個驚人的二分法：雖然 ICL 最初與貝氏最佳估計器的效率相匹配，但其效率在長脈絡中會顯著下降。透過資訊理論分析，我們表明效率下降是 ICL 的固有特徵。這些結果闡明了採用 ICL 作為通用問題解決者的權衡，激勵了新一代即時自適應方法，而沒有效率下降的問題。

##### **Position-aware Automatic Circuit Discovery**
2502.04577v1 by Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov

A widely used strategy to discover and understand language model mechanisms
is circuit analysis. A circuit is a minimal subgraph of a model's computation
graph that executes a specific task. We identify a gap in existing circuit
discovery methods: they assume circuits are position-invariant, treating model
components as equally relevant across input positions. This limits their
ability to capture cross-positional interactions or mechanisms that vary across
positions. To address this gap, we propose two improvements to incorporate
positionality into circuits, even on tasks containing variable-length examples.
First, we extend edge attribution patching, a gradient-based method for circuit
discovery, to differentiate between token positions. Second, we introduce the
concept of a dataset schema, which defines token spans with similar semantics
across examples, enabling position-aware circuit discovery in datasets with
variable length examples. We additionally develop an automated pipeline for
schema generation and application using large language models. Our approach
enables fully automated discovery of position-sensitive circuits, yielding
better trade-offs between circuit size and faithfulness compared to prior work.

摘要：廣泛用於發現和了解語言模型機制的策略是電路分析。電路是模型計算圖的最小子圖，可執行特定任務。我們找出電路發現方法中的一個缺口：它們假設電路與位置無關，將模型組件視為在輸入位置中同樣相關。這限制了它們捕捉跨位置互動或在不同位置中變化的機制的能力。為了解決這個缺口，我們提出兩項改進，將位置性納入電路中，即使在包含變長範例的任務中也是如此。首先，我們擴充邊緣屬性修補，一種基於梯度的電路發現方法，以區分符號位置。其次，我們引入了資料集架構的概念，它定義了在範例中具有類似語義的符號跨距，使我們可以在具有變長範例的資料集中進行與位置相關的電路發現。此外，我們開發了一個自動化管線，用於使用大型語言模型進行架構生成和應用。我們的做法能讓位置敏感電路的發現完全自動化，與先前的研究相比，在電路大小和忠實度之間產生了更好的權衡。

##### **Self-Regulation and Requesting Interventions**
2502.04576v1 by So Yeon Min, Yue Wu, Jimin Sun, Max Kaufmann, Fahim Tajwar, Yonatan Bisk, Ruslan Salakhutdinov

Human intelligence involves metacognitive abilities like self-regulation,
recognizing limitations, and seeking assistance only when needed. While LLM
Agents excel in many domains, they often lack this awareness. Overconfident
agents risk catastrophic failures, while those that seek help excessively
hinder efficiency. A key challenge is enabling agents with a limited
intervention budget $C$ is to decide when to request assistance. In this paper,
we propose an offline framework that trains a "helper" policy to request
interventions, such as more powerful models or test-time compute, by combining
LLM-based process reward models (PRMs) with tabular reinforcement learning.
Using state transitions collected offline, we score optimal intervention timing
with PRMs and train the helper model on these labeled trajectories. This
offline approach significantly reduces costly intervention calls during
training. Furthermore, the integration of PRMs with tabular RL enhances
robustness to off-policy data while avoiding the inefficiencies of deep RL. We
empirically find that our method delivers optimal helper behavior.

摘要：人類智慧包含像自我調節、認知限制和僅在需要時尋求協助等元認知能力。雖然 LLM 代理在許多領域表現優異，但他們常常缺乏這種意識。過度自信的代理會冒著災難性失敗的風險，而過度尋求幫助的代理會阻礙效率。一個關鍵挑戰是讓具有有限干預預算 $C$ 的代理決定何時請求協助。在本文中，我們提出一個離線框架，訓練「幫助者」政策來請求干預，例如更強大的模型或測試時間計算，方法是將基於 LLM 的過程獎勵模型 (PRM) 與表格強化學習相結合。使用離線收集的狀態轉換，我們使用 PRM 評分最佳干預時機，並在這些標記軌跡上訓練幫助者模型。這種離線方法顯著減少了訓練期間代價高昂的干預呼叫。此外，PRM 與表格 RL 的整合增強了對非策略數據的穩健性，同時避免了深度 RL 的低效率。我們憑經驗發現，我們的模型提供了最佳的幫助者行為。

##### **Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer**
2502.04573v1 by Yulun Wu, Doron L. Bergman

We present an Adversarially Pre-trained Transformer (APT) that is able to
perform zero-shot meta-learning on tabular prediction tasks without
pre-training on any real-world dataset, extending on the recent development of
Prior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained
with adversarial synthetic data agents, who continue to shift their underlying
data generating distribution and deliberately challenge the model with
different synthetic datasets. In addition, we propose a mixture block
architecture that is able to handle classification tasks with arbitrary number
of classes, addressing the class size limitation -- a crucial weakness of prior
deep tabular zero-shot learners. In experiments, we show that our framework
matches state-of-the-art performance on small classification tasks without
filtering on dataset characteristics such as number of classes and number of
missing values, while maintaining an average runtime under one second. On
common benchmark dataset suites in both classification and regression, we show
that adversarial pre-training was able to enhance TabPFN's performance. In our
analysis, we demonstrate that the adversarial synthetic data agents were able
to generate a more diverse collection of data compared to the ordinary random
generator in TabPFN. In addition, we demonstrate that our mixture block neural
design has improved generalizability and greatly accelerated pre-training.

摘要：我們提出了一個對抗預訓練Transformer (APT)，它能夠在表格預測任務上執行零次學習元學習，而無需在任何現實世界資料集上進行預訓練，並擴展了先驗資料擬合網路 (PFN) 和 TabPFN 的最新發展。具體來說，APT 使用對抗合成資料代理進行預訓練，這些代理會持續改變其基礎資料生成分佈，並故意使用不同的合成資料集挑戰模型。此外，我們提出了一個混合區塊架構，它能夠處理具有任意類別數量的分類任務，從而解決類別大小限制——這是先前的深度表格零次學習器的關鍵弱點。在實驗中，我們表明我們的框架在小型分類任務上與最先進的效能相匹配，而無需根據資料集特徵（例如類別數和缺失值數）進行過濾，同時將平均執行時間保持在 1 秒內。在分類和迴歸中的常見基準資料集套件上，我們表明對抗預訓練能夠增強 TabPFN 的效能。在我們的分析中，我們證明了與 TabPFN 中的普通隨機生成器相比，對抗合成資料代理能夠生成更多樣化的資料集合。此外，我們證明了我們的混合區塊神經設計提高了泛化能力，並極大地加速了預訓練。

##### **Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator**
2502.04567v1 by Zhuotong Chen, Fang Liu, Xuan Zhu, Yanjun Qi, Mohammad Ghavamzadeh

Existing studies on preference optimization (PO) have centered on
constructing pairwise preference data following simple heuristics, such as
maximizing the margin between preferred and dispreferred completions based on
human (or AI) ranked scores. However, none of these heuristics has a full
theoretical justification. In this work, we develop a novel PO framework that
provides theoretical guidance to effectively sample dispreferred completions.
To achieve this, we formulate PO as minimizing the negative log-likelihood
(NLL) of a probability model and propose to estimate its normalization constant
via a sampling strategy. As we will demonstrate, these estimative samples can
act as dispreferred completions in PO. We then select contrastive divergence
(CD) as the sampling strategy, and propose a novel MC-PO algorithm that applies
the Monte Carlo (MC) kernel from CD to sample hard negatives w.r.t. the
parameterized reward model. Finally, we propose the OnMC-PO algorithm, an
extension of MC-PO to the online setting. On popular alignment benchmarks,
MC-PO outperforms existing SOTA baselines, and OnMC-PO leads to further
improvement.

摘要：現有關於偏好最佳化 (PO) 的研究，主要集中於建構成對偏好資料，並遵循簡單的啟發式方法，例如根據人類 (或 AI) 排名的分數，最大化偏好完成和非偏好完成之間的邊際。然而，這些啟發式方法都沒有完整的理論依據。在這項工作中，我們開發了一個創新的 PO 架構，提供理論指導，以有效抽樣非偏好完成。為達成此目的，我們將 PO 公式化為最小化機率模型的負對數似然 (NLL)，並建議透過抽樣策略來估計其正規化常數。正如我們將展示的，這些估計樣本可以在 PO 中作為非偏好完成。然後，我們選擇對比散度 (CD) 作為抽樣策略，並提出一個創新的 MC-PO 演算法，將 CD 中的蒙地卡羅 (MC) 核心應用於抽樣相對於參數化獎勵模型的困難負值。最後，我們提出 OnMC-PO 演算法，這是 MC-PO 在線上設定中的延伸。在流行比對基準中，MC-PO 優於現有的 SOTA 基準，而 OnMC-PO 進一步提升了效能。

##### **My LLM might Mimic AAE -- But When Should it?**
2502.04564v1 by Sandra C. Sandoval, Christabel Acquaye, Kwesi Cobbina, Mohammad Nayeem Teli, Hal Daumé III

We examine the representation of African American English (AAE) in large
language models (LLMs), exploring (a) the perceptions Black Americans have of
how effective these technologies are at producing authentic AAE, and (b) in
what contexts Black Americans find this desirable. Through both a survey of
Black Americans ($n=$ 104) and annotation of LLM-produced AAE by Black
Americans ($n=$ 228), we find that Black Americans favor choice and autonomy in
determining when AAE is appropriate in LLM output. They tend to prefer that
LLMs default to communicating in Mainstream U.S. English in formal settings,
with greater interest in AAE production in less formal settings. When LLMs were
appropriately prompted and provided in context examples, our participants found
their outputs to have a level of AAE authenticity on par with transcripts of
Black American speech. Select code and data for our project can be found here:
https://github.com/smelliecat/AAEMime.git

摘要：我們檢視了大型語言模型 (LLM) 中非裔美國英語 (AAE) 的表徵，探討 (a) 黑人美國人對這些技術產生真實 AAE 的成效的看法，以及 (b) 黑人美國人在什麼情況下發現這一點是可取的。透過對黑人美國人進行調查 ($n=$ 104) 和黑人美國人對 LLM 產生的 AAE 進行註解 ($n=$ 228)，我們發現黑人美國人偏好選擇和自主權，以決定何時在 LLM 輸出中使用 AAE。他們傾向於偏好 LLM 在正式場合中預設以主流美國英語進行溝通，對在較不正式的場合中產生 AAE 更感興趣。當 LLM 得到適當提示並提供情境範例時，我們的參與者發現其輸出具有與黑人美國人演講記錄相當的 AAE 真實性。我們專案的選定程式碼和資料可在這裡找到：https://github.com/smelliecat/AAEMime.git

##### **WaferLLM: A Wafer-Scale LLM Inference System**
2502.04563v1 by Congjie He, Yeqi Huang, Pei Mu, Ziming Miao, Jilong Xue, Lingxiao Ma, Fan Yang, Luo Mai

Emerging AI accelerators increasingly adopt wafer-scale manufacturing
technologies, integrating hundreds of thousands of AI cores in a mesh-based
architecture with large distributed on-chip memory (tens of GB in total) and
ultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM
inference systems, optimized for shared memory architectures like GPUs, fail to
fully exploit these accelerators. We introduce WaferLLM, the first wafer-scale
LLM inference system. WaferLLM is guided by a novel PLMR device model that
captures the unique hardware characteristics of wafer-scale architectures.
Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism,
optimizing the utilization of hundreds of thousands of on-chip cores. It also
introduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementations
designed to scale effectively on wafer-scale accelerators. Evaluations show
that WaferLLM achieves 200$\times$ better wafer-scale accelerator utilization
than state-of-the-art systems. On a commodity wafer-scale accelerator, WaferLLM
delivers 606$\times$ faster and 22$\times$ more energy-efficient GEMV compared
to an advanced GPU. For LLMs, WaferLLM enables 39$\times$ faster decoding with
1.7$\times$ better energy efficiency. We anticipate these numbers will grow
significantly as wafer-scale AI models, software, and hardware continue to
mature.

摘要：新興的 AI 加速器正日益採用晶圓級製造技術，將數十萬個 AI 核心整合到基於網格的架構中，並具備大型分布式晶片記憶體（總計數十 GB）和超高晶片記憶體頻寬（數十 PB/s）。然而，目前針對共享記憶體架構（如 GPU）進行最佳化的 LLM 推論系統，無法充分利用這些加速器。我們推出 WaferLLM，這是有史以來第一個晶圓級 LLM 推論系統。WaferLLM 由一種新穎的 PLMR 裝置模型引導，該模型擷取了晶圓級架構的獨特硬體特性。藉由利用此模型，WaferLLM 開創了晶圓級 LLM 平行處理，最佳化了數十萬個晶片核心的使用率。它還引入了 MeshGEMM 和 MeshGEMV，這是第一個 GEMM 和 GEMV 實作，旨在有效地擴充晶圓級加速器。評估結果顯示，與現有最先進的系統相比，WaferLLM 達到了 200 倍更好的晶圓級加速器使用率。在一個商用晶圓級加速器上，與先進的 GPU 相比，WaferLLM 提供了快 606 倍、能效提高 22 倍的 GEMV。對於 LLM，WaferLLM 能夠以 1.7 倍更好的能效進行快 39 倍的解碼。我們預期隨著晶圓級 AI 模型、軟體和硬體持續成熟，這些數字將大幅成長。

##### **Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture**
2502.04558v1 by Hong Lu, Hengxu Li, Prithviraj Singh Shahani, Stephanie Herbers, Matthias Scheutz

Vision-language-action (VLA) models hold promise as generalist robotics
solutions by translating visual and linguistic inputs into robot actions, yet
they lack reliability due to their black-box nature and sensitivity to
environmental changes. In contrast, cognitive architectures (CA) excel in
symbolic reasoning and state monitoring but are constrained by rigid predefined
execution. This work bridges these approaches by probing OpenVLA's hidden
layers to uncover symbolic representations of object properties, relations, and
action states, enabling integration with a CA for enhanced interpretability and
robustness. Through experiments on LIBERO-spatial pick-and-place tasks, we
analyze the encoding of symbolic states across different layers of OpenVLA's
Llama backbone. Our probing results show consistently high accuracies (> 0.90)
for both object and action states across most layers, though contrary to our
hypotheses, we did not observe the expected pattern of object states being
encoded earlier than action states. We demonstrate an integrated DIARC-OpenVLA
system that leverages these symbolic representations for real-time state
monitoring, laying the foundation for more interpretable and reliable robotic
manipulation.

摘要：視覺語言動作 (VLA) 模型承諾成為通用機器人解決方案，透過將視覺和語言輸入轉換為機器人動作，但由於其黑盒性質和對環境變化的敏感性，它們缺乏可靠性。相比之下，認知架構 (CA) 在符號推理和狀態監控方面表現出色，但受到嚴格預定義執行的約束。這項工作透過探測 OpenVLA 的隱藏層來橋接這些方法，以揭示物件屬性、關係和動作狀態的符號表示，從而能夠與 CA 整合，以增強可解釋性和穩健性。透過在 LIBERO 空間拾放任務中進行實驗，我們分析了 OpenVLA 的 Llama 主幹不同層中的符號狀態編碼。我們的探測結果顯示，對於大多數層中的物件和動作狀態，準確率持續很高 (> 0.90)，儘管與我們的假設相反，我們沒有觀察到預期的物件狀態比動作狀態更早編碼的模式。我們展示了一個整合的 DIARC-OpenVLA 系統，該系統利用這些符號表示進行即時狀態監控，為更具可解釋性和可靠性的機器人操作奠定基礎。

##### **TruthFlow: Truthful LLM Generation via Representation Flow Correction**
2502.04556v1 by Hanyu Wang, Bochuan Cao, Yuanpu Cao, Jinghui Chen

Large language models (LLMs) are known to struggle with consistently
generating truthful responses. While various representation intervention
techniques have been proposed, these methods typically apply a universal
representation correction vector to all input queries, limiting their
effectiveness against diverse queries in practice. In this study, we introduce
TruthFlow, a novel method that leverages the Flow Matching technique for
query-specific truthful representation correction. Specifically, TruthFlow
first uses a flow model to learn query-specific correction vectors that
transition representations from hallucinated to truthful states. Then, during
inference, the trained flow model generates these correction vectors to enhance
the truthfulness of LLM outputs. Experimental results demonstrate that
TruthFlow significantly improves performance on open-ended generation tasks
across various advanced LLMs evaluated on TruthfulQA. Moreover, the trained
TruthFlow model exhibits strong transferability, performing effectively on
other unseen hallucination benchmarks.

摘要：大型語言模型 (LLM) 已知在持續產生真實回應方面有困難。儘管已提出各種表徵介入技術，但這些方法通常將通用表徵修正向量應用於所有輸入查詢，在實務上限制了它們對不同查詢的有效性。在這項研究中，我們引入了 TruthFlow，這是一種新穎的方法，它利用流匹配技術進行特定查詢的真實表徵修正。具體來說，TruthFlow 首先使用流模型來學習特定查詢的修正向量，將表徵從幻覺狀態轉換為真實狀態。然後，在推理期間，訓練好的流模型會產生這些修正向量，以增強 LLM 輸出的真實性。實驗結果表明，TruthFlow 在 TruthfulQA 上評估的各種先進 LLM 上顯著改善了開放式生成任務的效能。此外，訓練好的 TruthFlow 模型表現出強大的可移植性，在其他未見的幻覺基準上有效執行。

##### **Unifying and Optimizing Data Values for Selection via Sequential-Decision-Making**
2502.04554v1 by Hongliang Chi, Qiong Wu, Zhengyi Zhou, Jonathan Light, Emily Dodwell, Yao Ma

Data selection has emerged as a crucial downstream application of data
valuation. While existing data valuation methods have shown promise in
selection tasks, the theoretical foundations and full potential of using data
values for selection remain largely unexplored. In this work, we first
demonstrate that data values applied for selection can be naturally
reformulated as a sequential-decision-making problem, where the optimal data
value can be derived through dynamic programming. We show this framework
unifies and reinterprets existing methods like Data Shapley through the lens of
approximate dynamic programming, specifically as myopic reward function
approximations to this sequential problem. Furthermore, we analyze how
sequential data selection optimality is affected when the ground-truth utility
function exhibits monotonic submodularity with curvature. To address the
computational challenges in obtaining optimal data values, we propose an
efficient approximation scheme using learned bipartite graphs as surrogate
utility models, ensuring greedy selection is still optimal when the surrogate
utility is correctly specified and learned. Extensive experiments demonstrate
the effectiveness of our approach across diverse datasets.

摘要：資料選擇已成為資料評估中一個至關重要的下游應用。雖然現有的資料評估方法已在選擇任務中展現出潛力，但使用資料價值進行選擇的理論基礎和全部潛力仍未被充分探討。在這項工作中，我們首先證明應用於選擇的資料價值可以自然地重新表述為一個順序決策問題，其中最佳資料價值可以透過動態規劃導出。我們展示這個架構統一並重新詮釋了現有的方法，例如透過近似動態規劃的視角，特別是作為這個順序問題的近視報酬函數近似值，來詮釋 Data Shapley。此外，我們分析當真實效用函數展現出具有曲率的單調次模性時，順序資料選擇最優性如何受到影響。為了解決在取得最佳資料價值時所遇到的計算挑戰，我們提出一個有效的近似方案，使用學習到的二部圖作為替代效用模型，確保在正確指定並學習到替代效用時，貪婪選擇仍然是最優的。廣泛的實驗證明了我們的方法在各種資料集中的有效性。

##### **Contextual Gradient Flow Modeling for Large Language Model Generalization in Multi-Scale Feature Spaces**
2502.04548v1 by Daphne Quillington, Kingsley Fairbrother, Xavier Tattershall, Irin Kabakum

Optimization methodologies for training large-scale neural architectures
often rely on uniform gradient propagation mechanisms that fail to align with
hierarchical linguistic structures, limiting their capacity to generalize
across diverse language distributions. A structured gradient refinement
framework was introduced to incorporate multi-scale contextual adjustments,
improving parameter adaptation through dynamic weighting strategies that
enhanced representation coherence. Empirical evaluations demonstrated that
structured propagation mechanisms contributed to reductions in gradient
oscillations, resulting in more stable training dynamics and improved
optimization efficiency. The comparative performance assessment indicated that
models incorporating hierarchical propagation strategies exhibited greater
robustness in long-range dependency retention and cross-domain adaptation. The
hierarchical adjustment of weight updates provided an alternative to
conventional backpropagation, reducing sensitivity to initialization conditions
while improving overall convergence efficiency. The experimental results
confirmed that structured gradient propagation influenced representation
learning trajectories, aligning parameter updates with broader linguistic
dependencies rather than isolated token-level relationships. Statistical
evaluations indicated that structured optimization strategies mitigated
overfitting while preserving adaptability across heterogeneous text
distributions. The findings established that structured gradient propagation
provided an empirically validated framework for refining hierarchical
representation learning, supporting more effective integration of linguistic
dependencies into optimization dynamics.

摘要：大型神经網路架構訓練的最佳化方法論
通常依賴於均勻的梯度傳播機制，無法與
階層語言結構對齊，限制了它們在
不同語言分佈中概括的能力。結構化的梯度精煉
架構被引入以納入多尺度上下文調整，
通過增強表示一致性的動態加權策略改善參數適應。實證評估表明
結構化傳播機制有助於減少梯度
振盪，從而導致更穩定的訓練動態和提高
最佳化效率。比較性能評估表明
包含階層傳播策略的模型在長距離依賴關係保留和跨域適應中表現出更大的
穩健性。權重更新的階層調整提供了
傳統反向傳播的替代方案，降低了對初始化條件的敏感性
同時提高整體收斂效率。實驗結果
證實結構化的梯度傳播影響了表示
學習軌跡，將參數更新與更廣泛的語言
依賴關係對齊，而不是孤立的令牌級別關係。統計
評估表明，結構化最佳化策略減輕了
過度擬合，同時保持了跨異構文本的適應性
分佈。研究結果表明，結構化的梯度傳播
提供了一個經過實證驗證的框架，用於精煉階層
表示學習，支持更有效的語言整合
最佳化動態中的依賴性。

##### **Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation**
2502.04537v1 by Chenyang Huang, Fei Huang, Zaixiang Zheng, Osmar R. Zaïane, Hao Zhou, Lili Mou

Multilingual neural machine translation (MNMT) aims at using one single model
for multiple translation directions. Recent work applies non-autoregressive
Transformers to improve the efficiency of MNMT, but requires expensive
knowledge distillation (KD) processes. To this end, we propose an M-DAT
approach to non-autoregressive multilingual machine translation. Our system
leverages the recent advance of the directed acyclic Transformer (DAT), which
does not require KD. We further propose a pivot back-translation (PivotBT)
approach to improve the generalization to unseen translation directions.
Experiments show that our M-DAT achieves state-of-the-art performance in
non-autoregressive MNMT.

摘要：多語言神經機器翻譯 (MNMT) 旨在使用一個單一模型來翻譯多個方向。最近的研究將非自迴歸轉換器應用於提升 MNMT 的效率，但需要代價高昂的知識蒸餾 (KD) 程序。為此，我們提出 M-DAT 方法來進行非自迴歸多語言機器翻譯。我們的系統利用了有向無環轉換器 (DAT) 的最新進展，它不需要 KD。我們進一步提出了一個樞紐回譯 (PivotBT) 方法來提升對未見翻譯方向的泛化。實驗顯示我們的 M-DAT 在非自迴歸 MNMT 中達到了最先進的效能。

##### **A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers**
2502.04535v1 by Chenyang Huang, Hao Zhou, Cameron Jen, Kangjie Zheng, Osmar R. Zaïane, Lili Mou

Length-control summarization aims to condense long texts into a short one
within a certain length limit. Previous approaches often use autoregressive
(AR) models and treat the length requirement as a soft constraint, which may
not always be satisfied. In this study, we propose a novel length-control
decoding algorithm based on the Directed Acyclic Transformer (DAT). Our
approach allows for multiple plausible sequence fragments and predicts a
\emph{path} to connect them. In addition, we propose a Sequence Maximum a
Posteriori (SeqMAP) decoding algorithm that marginalizes different possible
paths and finds the most probable summary satisfying the length budget. Our
algorithm is based on beam search, which further facilitates a reranker for
performance improvement. Experimental results on the Gigaword and DUC2004
datasets demonstrate our state-of-the-art performance for length-control
summarization.

摘要：長度控制摘要旨在將長篇文字濃縮成短篇文字，並符合特定長度限制。先前的做法通常使用自迴歸 (AR) 模型，並將長度要求視為軟性約束，這可能無法始終得到滿足。在本研究中，我們提出一個新的長度控制解碼演算法，演算法基於有向非循環Transformer (DAT)。我們的做法允許多個合理的序列片段，並預測一條連接它們的「路徑」。此外，我們提出一個序列最大後驗 (SeqMAP) 解碼演算法，這個演算法將不同的可能路徑邊際化，並找出最有可能的摘要，以符合長度預算。我們的演算法基於光束搜尋，這進一步促進了重新排序器，以提升效能。在 Gigaword 和 DUC2004 資料集上的實驗結果證明了我們在長度控制摘要方面的最先進效能。

