{"2410.04751": {"publish_time": "2024-10-07", "title": "Intriguing Properties of Large Language and Vision Models", "paper_summary": "Recently, large language and vision models (LLVMs) have received significant\nattention and development efforts due to their remarkable generalization\nperformance across a wide range of tasks requiring perception and cognitive\nabilities. A key factor behind their success is their simple architecture,\nwhich consists of a vision encoder, a projector, and a large language model\n(LLM). Despite their achievements in advanced reasoning tasks, their\nperformance on fundamental perception-related tasks (e.g., MMVP) remains\nsurprisingly low. This discrepancy raises the question of how LLVMs truly\nperceive images and exploit the advantages of the vision encoder. To address\nthis, we systematically investigate this question regarding several aspects:\npermutation invariance, robustness, math reasoning, alignment preserving and\nimportance, by evaluating the most common LLVM's families (i.e., LLaVA) across\n10 evaluation benchmarks. Our extensive experiments reveal several intriguing\nproperties of current LLVMs: (1) they internally process the image in a global\nmanner, even when the order of visual patch sequences is randomly permuted; (2)\nthey are sometimes able to solve math problems without fully perceiving\ndetailed numerical information; (3) the cross-modal alignment is overfitted to\ncomplex reasoning tasks, thereby, causing them to lose some of the original\nperceptual capabilities of their vision encoder; (4) the representation space\nin the lower layers (<25%) plays a crucial role in determining performance and\nenhancing visual understanding. Lastly, based on the above observations, we\nsuggest potential future directions for building better LLVMs and constructing\nmore challenging evaluation benchmarks.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u5927\u578b\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b (LLVM) \u56e0\u5176\u5728\u9700\u8981\u611f\u77e5\u548c\u8ba4\u77e5\u80fd\u529b\u7684\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u7684\u5353\u8d8a\u6cdb\u5316\u6027\u80fd\u800c\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u548c\u5f00\u53d1\u3002\u5b83\u4eec\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u5728\u4e8e\u5176\u7b80\u5355\u7684\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u7531\u89c6\u89c9\u7f16\u7801\u5668\u3001\u6295\u5f71\u4eea\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7ec4\u6210\u3002\u5c3d\u7ba1\u5b83\u4eec\u5728\u9ad8\u7ea7\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6210\u5c31\uff0c\u4f46\u5b83\u4eec\u5728\u57fa\u672c\u611f\u77e5\u76f8\u5173\u4efb\u52a1\uff08\u4f8b\u5982 MMVP\uff09\u4e0a\u7684\u8868\u73b0\u4ecd\u7136\u51fa\u4eba\u610f\u6599\u7684\u4f4e\u3002\u8fd9\u79cd\u5dee\u5f02\u63d0\u51fa\u4e86 LLVMs \u5982\u4f55\u771f\u6b63\u611f\u77e5\u56fe\u50cf\u5e76\u5229\u7528\u89c6\u89c9\u7f16\u7801\u5668\u4f18\u52bf\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u7cfb\u7edf\u5730\u4ece\u51e0\u4e2a\u65b9\u9762\u5bf9\u6b64\u95ee\u9898\u8fdb\u884c\u4e86\u8c03\u67e5\uff1a\u6392\u5217\u4e0d\u53d8\u6027\u3001\u9c81\u68d2\u6027\u3001\u6570\u5b66\u63a8\u7406\u3001\u5bf9\u9f50\u4fdd\u6301\u548c\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u5728 10 \u4e2a\u8bc4\u4f30\u57fa\u51c6\u4e0a\u8bc4\u4f30\u6700\u5e38\u89c1\u7684 LLVM \u5bb6\u65cf\uff08\u5373 LLaVA\uff09\u3002\u6211\u4eec\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524d LLVMs \u7684\u51e0\u4e2a\u6709\u8da3\u7684\u7279\u6027\uff1a(1) \u5373\u4f7f\u89c6\u89c9\u8865\u4e01\u5e8f\u5217\u7684\u987a\u5e8f\u88ab\u968f\u673a\u6392\u5217\uff0c\u5b83\u4eec\u4e5f\u4f1a\u4ee5\u5168\u5c40\u65b9\u5f0f\u5728\u5185\u90e8\u5904\u7406\u56fe\u50cf\uff1b(2) \u5b83\u4eec\u6709\u65f6\u80fd\u591f\u5728\u6ca1\u6709\u5b8c\u5168\u611f\u77e5\u8be6\u7ec6\u6570\u5b57\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u6570\u5b66\u95ee\u9898\uff1b(3) \u8de8\u6a21\u5f0f\u5bf9\u9f50\u8fc7\u5ea6\u62df\u5408\u5230\u590d\u6742\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u56e0\u6b64\u5bfc\u81f4\u5b83\u4eec\u5931\u53bb\u89c6\u89c9\u7f16\u7801\u5668\u7684\u4e00\u4e9b\u539f\u59cb\u611f\u77e5\u80fd\u529b\uff1b(4) \u8f83\u4f4e\u5c42\uff08<25%\uff09\u4e2d\u7684\u8868\u793a\u7a7a\u95f4\u5728\u786e\u5b9a\u6027\u80fd\u548c\u589e\u5f3a\u89c6\u89c9\u7406\u89e3\u4e2d\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u4e0a\u8ff0\u89c2\u5bdf\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6784\u5efa\u66f4\u597d\u7684 LLVMs \u548c\u6784\u5efa\u66f4\u5177\u6311\u6218\u6027\u7684\u8bc4\u4f30\u57fa\u51c6\u7684\u6f5c\u5728\u672a\u6765\u65b9\u5411\u3002</paragraph>", "author": "Young-Jun Lee et.al.", "authors": "Young-Jun Lee, Byungsoo Ko, Han-Gyu Kim, Yechan Hwang, Ho-Jin Choi", "id": "2410.04751v1", "paper_url": "http://arxiv.org/abs/2410.04751v1", "repo": "null"}}