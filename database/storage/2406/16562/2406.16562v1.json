{"2406.16562": {"publish_time": "2024-06-24", "title": "EvalAlign: Evaluating Text-to-Image Models through Precision Alignment of Multimodal Large Models with Supervised Fine-Tuning to Human Annotations", "paper_summary": "The recent advancements in text-to-image generative models have been\nremarkable. Yet, the field suffers from a lack of evaluation metrics that\naccurately reflect the performance of these models, particularly lacking\nfine-grained metrics that can guide the optimization of the models. In this\npaper, we propose EvalAlign, a metric characterized by its accuracy, stability,\nand fine granularity. Our approach leverages the capabilities of Multimodal\nLarge Language Models (MLLMs) pre-trained on extensive datasets. We develop\nevaluation protocols that focus on two key dimensions: image faithfulness and\ntext-image alignment. Each protocol comprises a set of detailed, fine-grained\ninstructions linked to specific scoring options, enabling precise manual\nscoring of the generated images. We Supervised Fine-Tune (SFT) the MLLM to\nalign closely with human evaluative judgments, resulting in a robust evaluation\nmodel. Our comprehensive tests across 24 text-to-image generation models\ndemonstrate that EvalAlign not only provides superior metric stability but also\naligns more closely with human preferences than existing metrics, confirming\nits effectiveness and utility in model assessment.", "paper_summary_zh": "\u6700\u8fd1\u6587\u5b57\u8f49\u5716\u50cf\u751f\u6210\u6a21\u578b\u7684\u9032\u5c55\u975e\u5e38\u986f\u8457\u3002\u7136\u800c\uff0c\u9019\u500b\u9818\u57df\u7f3a\u4e4f\u6e96\u78ba\u53cd\u6620\u9019\u4e9b\u6a21\u578b\u6548\u80fd\u7684\u8a55\u4f30\u6307\u6a19\uff0c\u7279\u5225\u662f\u7f3a\u4e4f\u53ef\u4ee5\u5f15\u5c0e\u6a21\u578b\u6700\u4f73\u5316\u7684\u7d30\u7dfb\u6307\u6a19\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa EvalAlign\uff0c\u9019\u662f\u4e00\u500b\u4ee5\u5176\u6e96\u78ba\u6027\u3001\u7a69\u5b9a\u6027\u548c\u7d30\u7dfb\u7c92\u5ea6\u70ba\u7279\u5fb5\u7684\u6307\u6a19\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u4e86\u5728\u5ee3\u6cdb\u6578\u64da\u96c6\u4e0a\u9810\u5148\u8a13\u7df4\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u529f\u80fd\u3002\u6211\u5011\u5236\u5b9a\u4e86\u8a55\u4f30\u5354\u5b9a\uff0c\u91cd\u9ede\u95dc\u6ce8\u5169\u500b\u95dc\u9375\u9762\u5411\uff1a\u5716\u50cf\u4fdd\u771f\u5ea6\u548c\u6587\u5b57\u5716\u50cf\u5c0d\u9f4a\u3002\u6bcf\u500b\u5354\u5b9a\u90fd\u5305\u542b\u4e00\u5957\u8a73\u7d30\u3001\u7d30\u7dfb\u7684\u8aaa\u660e\uff0c\u9023\u7d50\u5230\u7279\u5b9a\u7684\u8a55\u5206\u9078\u9805\uff0c\u4ee5\u4fbf\u7cbe\u78ba\u624b\u52d5\u8a55\u5206\u751f\u6210\u7684\u5716\u50cf\u3002\u6211\u5011\u76e3\u7763\u5fae\u8abf (SFT) MLLM\uff0c\u4ee5\u8207\u4eba\u985e\u8a55\u4f30\u5224\u65b7\u7dca\u5bc6\u5c0d\u9f4a\uff0c\u5f9e\u800c\u7522\u751f\u4e00\u500b\u5f37\u5927\u7684\u8a55\u4f30\u6a21\u578b\u3002\u6211\u5011\u5c0d 24 \u500b\u6587\u5b57\u8f49\u5716\u50cf\u751f\u6210\u6a21\u578b\u9032\u884c\u7684\u5168\u9762\u6e2c\u8a66\u8868\u660e\uff0cEvalAlign \u4e0d\u50c5\u63d0\u4f9b\u4e86\u512a\u8d8a\u7684\u6307\u6a19\u7a69\u5b9a\u6027\uff0c\u800c\u4e14\u6bd4\u73fe\u6709\u6307\u6a19\u66f4\u8cbc\u8fd1\u4eba\u985e\u504f\u597d\uff0c\u8b49\u5be6\u4e86\u5176\u5728\u6a21\u578b\u8a55\u4f30\u4e2d\u7684\u6709\u6548\u6027\u548c\u5be6\u7528\u6027\u3002", "author": "Zhiyu Tan et.al.", "authors": "Zhiyu Tan, Xiaomeng Yang, Luozheng Qin, Mengping Yang, Cheng Zhang, Hao Li", "id": "2406.16562v1", "paper_url": "http://arxiv.org/abs/2406.16562v1", "repo": "https://github.com/sais-fuxi/evalalign"}}