{"2406.03250": {"publish_time": "2024-06-05", "title": "Prompt-based Visual Alignment for Zero-shot Policy Transfer", "paper_summary": "Overfitting in RL has become one of the main obstacles to applications in\nreinforcement learning(RL). Existing methods do not provide explicit semantic\nconstrain for the feature extractor, hindering the agent from learning a\nunified cross-domain representation and resulting in performance degradation on\nunseen domains. Besides, abundant data from multiple domains are needed. To\naddress these issues, in this work, we propose prompt-based visual alignment\n(PVA), a robust framework to mitigate the detrimental domain bias in the image\nfor zero-shot policy transfer. Inspired that Visual-Language Model (VLM) can\nserve as a bridge to connect both text space and image space, we leverage the\nsemantic information contained in a text sequence as an explicit constraint to\ntrain a visual aligner. Thus, the visual aligner can map images from multiple\ndomains to a unified domain and achieve good generalization performance. To\nbetter depict semantic information, prompt tuning is applied to learn a\nsequence of learnable tokens. With explicit constraints of semantic\ninformation, PVA can learn unified cross-domain representation under limited\naccess to cross-domain data and achieves great zero-shot generalization ability\nin unseen domains. We verify PVA on a vision-based autonomous driving task with\nCARLA simulator. Experiments show that the agent generalizes well on unseen\ndomains under limited access to multi-domain data.", "paper_summary_zh": "RL \u4e2d\u7684\u8fc7\u62df\u5408\u5df2\u6210\u4e3a\u5f3a\u5316\u5b66\u4e60 (RL) \u5e94\u7528\u7684\u4e3b\u8981\u969c\u788d\u4e4b\u4e00\u3002\u73b0\u6709\u65b9\u6cd5\u6ca1\u6709\u4e3a\u7279\u5f81\u63d0\u53d6\u5668\u63d0\u4f9b\u660e\u786e\u7684\u8bed\u4e49\u7ea6\u675f\uff0c\u4ece\u800c\u963b\u788d\u4ee3\u7406\u5b66\u4e60\u7edf\u4e00\u7684\u8de8\u57df\u8868\u793a\uff0c\u5e76\u5bfc\u81f4\u5728\u672a\u89c1\u57df\u4e0a\u6027\u80fd\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u9700\u8981\u6765\u81ea\u591a\u4e2a\u57df\u7684\u5927\u91cf\u6570\u636e\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u57fa\u4e8e\u63d0\u793a\u7684\u89c6\u89c9\u5bf9\u9f50 (PVA)\uff0c\u8fd9\u662f\u4e00\u4e2a\u7a33\u5065\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u51cf\u8f7b\u56fe\u50cf\u4e2d\u5bf9\u96f6\u955c\u5934\u7b56\u7565\u8f6c\u79fb\u7684\u6709\u5bb3\u57df\u504f\u5dee\u3002\u53d7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (VLM) \u53ef\u4ee5\u4f5c\u4e3a\u8fde\u63a5\u6587\u672c\u7a7a\u95f4\u548c\u56fe\u50cf\u7a7a\u95f4\u7684\u6865\u6881\u7684\u542f\u53d1\uff0c\u6211\u4eec\u5229\u7528\u6587\u672c\u5e8f\u5217\u4e2d\u5305\u542b\u7684\u8bed\u4e49\u4fe1\u606f\u4f5c\u4e3a\u663e\u5f0f\u7ea6\u675f\u6765\u8bad\u7ec3\u89c6\u89c9\u5bf9\u9f50\u5668\u3002\u56e0\u6b64\uff0c\u89c6\u89c9\u5bf9\u9f50\u5668\u53ef\u4ee5\u5c06\u6765\u81ea\u591a\u4e2a\u57df\u7684\u56fe\u50cf\u6620\u5c04\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u57df\uff0c\u5e76\u5b9e\u73b0\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u63cf\u8ff0\u8bed\u4e49\u4fe1\u606f\uff0c\u5e94\u7528\u63d0\u793a\u8c03\u6574\u6765\u5b66\u4e60\u4e00\u7cfb\u5217\u53ef\u5b66\u4e60\u7684\u6807\u8bb0\u3002\u901a\u8fc7\u8bed\u4e49\u4fe1\u606f\u7684\u663e\u5f0f\u7ea6\u675f\uff0cPVA \u53ef\u4ee5\u5728\u5bf9\u8de8\u57df\u6570\u636e\u8bbf\u95ee\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u7edf\u4e00\u7684\u8de8\u57df\u8868\u793a\uff0c\u5e76\u5728\u672a\u89c1\u57df\u4e2d\u5b9e\u73b0\u51fa\u8272\u7684\u96f6\u955c\u5934\u6cdb\u5316\u80fd\u529b\u3002\u6211\u4eec\u5728\u57fa\u4e8e\u89c6\u89c9\u7684\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u4f7f\u7528 CARLA \u6a21\u62df\u5668\u9a8c\u8bc1\u4e86 PVA\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5bf9\u591a\u57df\u6570\u636e\u8bbf\u95ee\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u4ee3\u7406\u5728\u672a\u89c1\u57df\u4e0a\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "author": "Haihan Gao et.al.", "authors": "Haihan Gao, Rui Zhang, Qi Yi, Hantao Yao, Haochen Li, Jiaming Guo, Shaohui Peng, Yunkai Gao, QiCheng Wang, Xing Hu, Yuanbo Wen, Zihao Zhang, Zidong Du, Ling Li, Qi Guo, Yunji Chen", "id": "2406.03250v1", "paper_url": "http://arxiv.org/abs/2406.03250v1", "repo": "null"}}