{"2412.18424": {"publish_time": "2024-12-24", "title": "LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating", "paper_summary": "Large vision language models (LVLMs) have improved the document understanding\ncapabilities remarkably, enabling the handling of complex document elements,\nlonger contexts, and a wider range of tasks. However, existing document\nunderstanding benchmarks have been limited to handling only a small number of\npages and fail to provide a comprehensive analysis of layout elements locating.\nIn this paper, we first define three primary task categories: Long Document\nUnderstanding, numerical Reasoning, and cross-element Locating, and then\npropose a comprehensive benchmark, LongDocURL, integrating above three primary\ntasks and comprising 20 sub-tasks categorized based on different primary tasks\nand answer evidences. Furthermore, we develop a semi-automated construction\npipeline and collect 2,325 high-quality question-answering pairs, covering more\nthan 33,000 pages of documents, significantly outperforming existing\nbenchmarks. Subsequently, we conduct comprehensive evaluation experiments on\nboth open-source and closed-source models across 26 different configurations,\nrevealing critical performance gaps in this field.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5df2\u986f\u8457\u63d0\u5347\u6587\u4ef6\u7406\u89e3\u80fd\u529b\uff0c\u80fd\u8655\u7406\u8907\u96dc\u7684\u6587\u4ef6\u5143\u7d20\u3001\u8f03\u9577\u7684\u8108\u7d61\u4ee5\u53ca\u66f4\u5ee3\u6cdb\u7684\u4efb\u52d9\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u6587\u4ef6\u7406\u89e3\u57fa\u6e96\u50c5\u9650\u65bc\u8655\u7406\u5c11\u6578\u9801\u9762\uff0c\u4e14\u7121\u6cd5\u63d0\u4f9b\u7248\u9762\u5143\u7d20\u5b9a\u4f4d\u7684\u5168\u9762\u5206\u6790\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u9996\u5148\u5b9a\u7fa9\u4e09\u500b\u4e3b\u8981\u7684\u4efb\u52d9\u985e\u5225\uff1a\u9577\u6587\u4ef6\u7406\u89e3\u3001\u6578\u5b57\u63a8\u7406\u548c\u8de8\u5143\u7d20\u5b9a\u4f4d\uff0c\u7136\u5f8c\u63d0\u51fa\u4e00\u500b\u5168\u9762\u7684\u57fa\u6e96 LongDocURL\uff0c\u6574\u5408\u4e0a\u8ff0\u4e09\u500b\u4e3b\u8981\u4efb\u52d9\u4e26\u5305\u542b 20 \u500b\u5b50\u4efb\u52d9\uff0c\u6839\u64da\u4e0d\u540c\u7684\u4e3b\u8981\u4efb\u52d9\u548c\u7b54\u6848\u8b49\u64da\u9032\u884c\u5206\u985e\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u534a\u81ea\u52d5\u5316\u5efa\u69cb\u7ba1\u9053\uff0c\u4e26\u6536\u96c6\u4e86 2,325 \u500b\u9ad8\u54c1\u8cea\u554f\u7b54\u5c0d\uff0c\u6db5\u84cb\u8d85\u904e 33,000 \u9801\u7684\u6587\u4ef6\uff0c\u5927\u5e45\u512a\u65bc\u73fe\u6709\u7684\u57fa\u6e96\u3002\u96a8\u5f8c\uff0c\u6211\u5011\u5c0d 26 \u7a2e\u4e0d\u540c\u914d\u7f6e\u7684\u958b\u6e90\u548c\u9589\u6e90\u6a21\u578b\u9032\u884c\u5168\u9762\u7684\u8a55\u4f30\u5be6\u9a57\uff0c\u63ed\u9732\u4e86\u6b64\u9818\u57df\u7684\u95dc\u9375\u6548\u80fd\u5dee\u8ddd\u3002", "author": "Chao Deng et.al.", "authors": "Chao Deng, Jiale Yuan, Pi Bu, Peijie Wang, Zhong-Zhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, Cheng-Lin Liu", "id": "2412.18424v1", "paper_url": "http://arxiv.org/abs/2412.18424v1", "repo": "null"}}