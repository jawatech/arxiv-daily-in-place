{"2502.03930": {"publish_time": "2025-02-06", "title": "DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation", "paper_summary": "Several recent studies have attempted to autoregressively generate continuous\nspeech representations without discrete speech tokens by combining diffusion\nand autoregressive models, yet they often face challenges with excessive\ncomputational loads or suboptimal outcomes. In this work, we propose Diffusion\nTransformer Autoregressive Modeling (DiTAR), a patch-based autoregressive\nframework combining a language model with a diffusion transformer. This\napproach significantly enhances the efficacy of autoregressive models for\ncontinuous tokens and reduces computational demands. DiTAR utilizes a\ndivide-and-conquer strategy for patch generation, where the language model\nprocesses aggregated patch embeddings and the diffusion transformer\nsubsequently generates the next patch based on the output of the language\nmodel. For inference, we propose defining temperature as the time point of\nintroducing noise during the reverse diffusion ODE to balance diversity and\ndeterminism. We also show in the extensive scaling analysis that DiTAR has\nsuperb scalability. In zero-shot speech generation, DiTAR achieves\nstate-of-the-art performance in robustness, speaker similarity, and\nnaturalness.", "paper_summary_zh": "\u591a\u9805\u8fd1\u671f\u7814\u7a76\u5617\u8a66\u7d50\u5408\u64f4\u6563\u548c\u81ea\u8ff4\u6b78\u6a21\u578b\uff0c\u81ea\u8ff4\u6b78\u5730\u7522\u751f\u9023\u7e8c\u8a9e\u97f3\u8868\u5fb5\uff0c\u800c\u4e0d\u4f7f\u7528\u96e2\u6563\u8a9e\u97f3\u7b26\u865f\uff0c\u4f46\u5b83\u5011\u7d93\u5e38\u9762\u81e8\u8a08\u7b97\u8ca0\u8f09\u904e\u5927\u6216\u7d50\u679c\u6b21\u4f73\u7684\u6311\u6230\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u64f4\u6563\u8f49\u63db\u5668\u81ea\u8ff4\u6b78\u6a21\u578b (DiTAR)\uff0c\u4e00\u500b\u57fa\u65bc\u5340\u584a\u7684\u81ea\u8ff4\u6b78\u67b6\u69cb\uff0c\u7d50\u5408\u8a9e\u8a00\u6a21\u578b\u8207\u64f4\u6563\u8f49\u63db\u5668\u3002\u9019\u7a2e\u65b9\u6cd5\u5927\u5e45\u589e\u5f37\u81ea\u8ff4\u6b78\u6a21\u578b\u5c0d\u9023\u7e8c\u7b26\u865f\u7684\u6548\u80fd\uff0c\u4e26\u6e1b\u5c11\u8a08\u7b97\u9700\u6c42\u3002DiTAR \u5229\u7528\u5206\u800c\u6cbb\u4e4b\u7b56\u7565\u9032\u884c\u5340\u584a\u7522\u751f\uff0c\u5176\u4e2d\u8a9e\u8a00\u6a21\u578b\u8655\u7406\u805a\u96c6\u7684\u5340\u584a\u5d4c\u5165\uff0c\u800c\u64f4\u6563\u8f49\u63db\u5668\u96a8\u5f8c\u6839\u64da\u8a9e\u8a00\u6a21\u578b\u7684\u8f38\u51fa\u7522\u751f\u4e0b\u4e00\u500b\u5340\u584a\u3002\u5c0d\u65bc\u63a8\u8ad6\uff0c\u6211\u5011\u5efa\u8b70\u5c07\u6eab\u5ea6\u5b9a\u7fa9\u70ba\u5728\u53cd\u5411\u64f4\u6563 ODE \u4e2d\u5f15\u5165\u96dc\u8a0a\u7684\u6642\u9593\u9ede\uff0c\u4ee5\u5e73\u8861\u591a\u6a23\u6027\u548c\u78ba\u5b9a\u6027\u3002\u6211\u5011\u4e5f\u5728\u5ee3\u6cdb\u7684\u7e2e\u653e\u5206\u6790\u4e2d\u986f\u793a\uff0cDiTAR \u5177\u6709\u6975\u4f73\u7684\u53ef\u64f4\u5145\u6027\u3002\u5728\u96f6\u6b21\u5b78\u7fd2\u8a9e\u97f3\u7522\u751f\u4e2d\uff0cDiTAR \u5728\u7a69\u5065\u6027\u3001\u8aaa\u8a71\u8005\u76f8\u4f3c\u6027\u548c\u81ea\u7136\u5ea6\u65b9\u9762\u9054\u5230\u6700\u5148\u9032\u7684\u6548\u80fd\u3002", "author": "Dongya Jia et.al.", "authors": "Dongya Jia, Zhuo Chen, Jiawei Chen, Chenpeng Du, Jian Wu, Jian Cong, Xiaobin Zhuang, Chumin Li, Zhen Wei, Yuping Wang, Yuxuan Wang", "id": "2502.03930v1", "paper_url": "http://arxiv.org/abs/2502.03930v1", "repo": "null"}}