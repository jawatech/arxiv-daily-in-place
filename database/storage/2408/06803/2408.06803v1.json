{"2408.06803": {"publish_time": "2024-08-13", "title": "Integrating Saliency Ranking and Reinforcement Learning for Enhanced Object Detection", "paper_summary": "With the ever-growing variety of object detection approaches, this study\nexplores a series of experiments that combine reinforcement learning (RL)-based\nvisual attention methods with saliency ranking techniques to investigate\ntransparent and sustainable solutions. By integrating saliency ranking for\ninitial bounding box prediction and subsequently applying RL techniques to\nrefine these predictions through a finite set of actions over multiple time\nsteps, this study aims to enhance RL object detection accuracy. Presented as a\nseries of experiments, this research investigates the use of various image\nfeature extraction methods and explores diverse Deep Q-Network (DQN)\narchitectural variations for deep reinforcement learning-based localisation\nagent training. Additionally, we focus on optimising the detection pipeline at\nevery step by prioritising lightweight and faster models, while also\nincorporating the capability to classify detected objects, a feature absent in\nprevious RL approaches. We show that by evaluating the performance of these\ntrained agents using the Pascal VOC 2007 dataset, faster and more optimised\nmodels were developed. Notably, the best mean Average Precision (mAP) achieved\nin this study was 51.4, surpassing benchmarks set by RL-based single object\ndetectors in the literature.", "paper_summary_zh": "\u96a8\u8457\u7269\u4ef6\u5075\u6e2c\u65b9\u6cd5\u7684\u7a2e\u985e\u4e0d\u65b7\u589e\u52a0\uff0c\u672c\u7814\u7a76\u63a2\u8a0e\u4e00\u7cfb\u5217\u5be6\u9a57\uff0c\u7d50\u5408\u57fa\u65bc\u5f37\u5316\u5b78\u7fd2 (RL) \u7684\u8996\u89ba\u6ce8\u610f\u529b\u65b9\u6cd5\u8207\u986f\u8457\u6027\u6392\u540d\u6280\u8853\uff0c\u4ee5\u8abf\u67e5\u900f\u660e\u4e14\u6c38\u7e8c\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u900f\u904e\u6574\u5408\u986f\u8457\u6027\u6392\u540d\u4ee5\u9032\u884c\u521d\u59cb\u908a\u754c\u6846\u9810\u6e2c\uff0c\u4e26\u96a8\u5f8c\u61c9\u7528 RL \u6280\u8853\uff0c\u900f\u904e\u6709\u9650\u7684\u52d5\u4f5c\u96c6\u5728\u591a\u500b\u6642\u9593\u6b65\u9a5f\u4e2d\u7cbe\u7149\u9019\u4e9b\u9810\u6e2c\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u5347 RL \u7269\u4ef6\u5075\u6e2c\u6e96\u78ba\u5ea6\u3002\u672c\u7814\u7a76\u4ee5\u4e00\u7cfb\u5217\u5be6\u9a57\u7684\u5f62\u5f0f\u5448\u73fe\uff0c\u63a2\u8a0e\u4f7f\u7528\u5404\u7a2e\u5f71\u50cf\u7279\u5fb5\u8403\u53d6\u65b9\u6cd5\uff0c\u4e26\u63a2\u7d22\u5404\u7a2e\u6df1\u5ea6 Q \u7db2\u8def (DQN) \u67b6\u69cb\u8b8a\u7570\uff0c\u4ee5\u9032\u884c\u57fa\u65bc\u6df1\u5ea6\u5f37\u5316\u5b78\u7fd2\u7684\u5b9a\u4f4d\u4ee3\u7406\u8a13\u7df4\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u900f\u904e\u512a\u5148\u8003\u616e\u8f15\u91cf\u7d1a\u4e14\u66f4\u5feb\u901f\u7684\u6a21\u578b\uff0c\u5728\u6bcf\u500b\u6b65\u9a5f\u4e2d\u6700\u4f73\u5316\u5075\u6e2c\u7ba1\u7dda\uff0c\u540c\u6642\u4e5f\u7d0d\u5165\u5206\u985e\u5df2\u5075\u6e2c\u7269\u4ef6\u7684\u80fd\u529b\uff0c\u9019\u9805\u529f\u80fd\u5728\u5148\u524d\u7684 RL \u65b9\u6cd5\u4e2d\u4e26\u4e0d\u5b58\u5728\u3002\u6211\u5011\u986f\u793a\uff0c\u900f\u904e\u4f7f\u7528 Pascal VOC 2007 \u8cc7\u6599\u96c6\u8a55\u4f30\u9019\u4e9b\u8a13\u7df4\u4ee3\u7406\u7684\u6548\u80fd\uff0c\u958b\u767c\u51fa\u66f4\u5feb\u901f\u4e14\u6700\u4f73\u5316\u7684\u6a21\u578b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u672c\u7814\u7a76\u4e2d\u9054\u6210\u7684\u6700\u4f73\u5e73\u5747\u6e96\u78ba\u5ea6 (mAP) \u70ba 51.4\uff0c\u8d85\u8d8a\u4e86\u6587\u737b\u4e2d\u57fa\u65bc RL \u7684\u55ae\u4e00\u7269\u4ef6\u5075\u6e2c\u5668\u6240\u8a2d\u5b9a\u7684\u57fa\u6e96\u3002", "author": "Matthias Bartolo et.al.", "authors": "Matthias Bartolo, Dylan Seychell, Josef Bajada", "id": "2408.06803v1", "paper_url": "http://arxiv.org/abs/2408.06803v1", "repo": "https://github.com/mbar0075/sarlvision"}}