{"2410.07981": {"publish_time": "2024-10-10", "title": "MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning", "paper_summary": "In this work, we propose a simple transformer-based baseline for multimodal\nmolecular representation learning, integrating three distinct modalities:\nSMILES strings, 2D graph representations, and 3D conformers of molecules. A key\naspect of our approach is the aggregation of 3D conformers, allowing the model\nto account for the fact that molecules can adopt multiple conformations-an\nimportant factor for accurate molecular representation. The tokens for each\nmodality are extracted using modality-specific encoders: a transformer for\nSMILES strings, a message-passing neural network for 2D graphs, and an\nequivariant neural network for 3D conformers. The flexibility and modularity of\nthis framework enable easy adaptation and replacement of these encoders, making\nthe model highly versatile for different molecular tasks. The extracted tokens\nare then combined into a unified multimodal sequence, which is processed by a\ndownstream transformer for prediction tasks. To efficiently scale our model for\nlarge multimodal datasets, we utilize Flash Attention 2 and bfloat16 precision.\nDespite its simplicity, our approach achieves state-of-the-art results across\nmultiple datasets, demonstrating its effectiveness as a strong baseline for\nmultimodal molecular representation learning.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u7c21\u55ae\u7684\u57fa\u65bc Transformer \u7684\u57fa\u7dda\uff0c\u7528\u65bc\u591a\u6a21\u614b\u5206\u5b50\u8868\u793a\u5b78\u7fd2\uff0c\u6574\u5408\u4e86\u4e09\u7a2e\u4e0d\u540c\u7684\u6a21\u614b\uff1aSMILES \u5b57\u7b26\u4e32\u30012D \u5716\u5f62\u8868\u793a\u548c\u5206\u5b50\u7684 3D \u69cb\u8c61\u3002\u6211\u5011\u65b9\u6cd5\u7684\u4e00\u500b\u95dc\u9375\u65b9\u9762\u662f 3D \u69cb\u8c61\u7684\u805a\u5408\uff0c\u5141\u8a31\u6a21\u578b\u8003\u616e\u5206\u5b50\u53ef\u4ee5\u63a1\u7528\u591a\u7a2e\u69cb\u8c61\u7684\u4e8b\u5be6 - \u9019\u662f\u6e96\u78ba\u5206\u5b50\u8868\u793a\u7684\u4e00\u500b\u91cd\u8981\u56e0\u7d20\u3002\u6bcf\u500b\u6a21\u614b\u7684\u7b26\u865f\u90fd\u662f\u4f7f\u7528\u7279\u5b9a\u65bc\u6a21\u614b\u7684\u7de8\u78bc\u5668\u63d0\u53d6\u7684\uff1aSMILES \u5b57\u7b26\u4e32\u7684 Transformer\u30012D \u5716\u5f62\u7684\u8a0a\u606f\u50b3\u905e\u795e\u7d93\u7db2\u8def\u548c 3D \u69cb\u8c61\u7684\u7b49\u8b8a\u795e\u7d93\u7db2\u8def\u3002\u9019\u500b\u67b6\u69cb\u7684\u9748\u6d3b\u6027\u8207\u6a21\u7d44\u5316\u5141\u8a31\u8f15\u9b06\u8abf\u6574\u548c\u66ff\u63db\u9019\u4e9b\u7de8\u78bc\u5668\uff0c\u4f7f\u6a21\u578b\u5c0d\u4e0d\u540c\u7684\u5206\u5b50\u4efb\u52d9\u5177\u6709\u9ad8\u5ea6\u901a\u7528\u6027\u3002\u63d0\u53d6\u7684\u7b26\u865f\u7136\u5f8c\u7d44\u5408\u6210\u4e00\u500b\u7d71\u4e00\u7684\u591a\u6a21\u614b\u5e8f\u5217\uff0c\u7531\u4e0b\u6e38 Transformer \u8655\u7406\u4ee5\u9032\u884c\u9810\u6e2c\u4efb\u52d9\u3002\u70ba\u4e86\u6709\u6548\u5730\u64f4\u5c55\u6211\u5011\u7684\u6a21\u578b\u4ee5\u9069\u61c9\u5927\u578b\u591a\u6a21\u614b\u6578\u64da\u96c6\uff0c\u6211\u5011\u5229\u7528 Flash Attention 2 \u548c bfloat16 \u7cbe\u5ea6\u3002\u5118\u7ba1\u5f88\u7c21\u55ae\uff0c\u4f46\u6211\u5011\u7684\u505a\u6cd5\u5728\u591a\u500b\u6578\u64da\u96c6\u4e0a\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\uff0c\u8b49\u660e\u4e86\u5176\u4f5c\u70ba\u591a\u6a21\u614b\u5206\u5b50\u8868\u793a\u5b78\u7fd2\u7684\u5f37\u5927\u57fa\u7dda\u7684\u6709\u6548\u6027\u3002", "author": "Andrei Manolache et.al.", "authors": "Andrei Manolache, Dragos Tantaru, Mathias Niepert", "id": "2410.07981v1", "paper_url": "http://arxiv.org/abs/2410.07981v1", "repo": "null"}}