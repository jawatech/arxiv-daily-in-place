{"2501.05452": {"publish_time": "2025-01-09", "title": "ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding", "paper_summary": "Structured image understanding, such as interpreting tables and charts,\nrequires strategically refocusing across various structures and texts within an\nimage, forming a reasoning sequence to arrive at the final answer. However,\ncurrent multimodal large language models (LLMs) lack this multihop selective\nattention capability. In this work, we introduce ReFocus, a simple yet\neffective framework that equips multimodal LLMs with the ability to generate\n\"visual thoughts\" by performing visual editing on the input image through code,\nshifting and refining their visual focuses. Specifically, ReFocus enables\nmultimodal LLMs to generate Python codes to call tools and modify the input\nimage, sequentially drawing boxes, highlighting sections, and masking out\nareas, thereby enhancing the visual reasoning process. We experiment upon a\nwide range of structured image understanding tasks involving tables and charts.\nReFocus largely improves performance on all tasks over GPT-4o without visual\nediting, yielding an average gain of 11.0% on table tasks and 6.8% on chart\ntasks. We present an in-depth analysis of the effects of different visual\nedits, and reasons why ReFocus can improve the performance without introducing\nadditional information. Further, we collect a 14k training set using ReFocus,\nand prove that such visual chain-of-thought with intermediate information\noffers a better supervision than standard VQA data, reaching a 8.0% average\ngain over the same model trained with QA pairs and 2.6% over CoT.", "paper_summary_zh": "\u7d50\u69cb\u5316\u5f71\u50cf\u7406\u89e3\uff0c\u4f8b\u5982\u8a6e\u91cb\u8868\u683c\u548c\u5716\u8868\uff0c\u9700\u8981\u5728\u5f71\u50cf\u4e2d\u7684\u5404\u7a2e\u7d50\u69cb\u548c\u6587\u5b57\u4e2d\u7b56\u7565\u6027\u5730\u91cd\u65b0\u805a\u7126\uff0c\u5f62\u6210\u63a8\u7406\u5e8f\u5217\u624d\u80fd\u5f97\u51fa\u6700\u7d42\u7b54\u6848\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7f3a\u4e4f\u9019\u7a2e\u591a\u8df3\u9078\u64c7\u6027\u6ce8\u610f\u529b\u7684\u80fd\u529b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86 ReFocus\uff0c\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u6846\u67b6\uff0c\u5b83\u8ce6\u4e88\u591a\u6a21\u614b LLM \u900f\u904e\u7a0b\u5f0f\u78bc\u5c0d\u8f38\u5165\u5f71\u50cf\u9032\u884c\u8996\u89ba\u7de8\u8f2f\u3001\u8f49\u79fb\u548c\u512a\u5316\u5176\u8996\u89ba\u7126\u9ede\u7684\u80fd\u529b\uff0c\u4ee5\u7522\u751f\u300c\u8996\u89ba\u601d\u8003\u300d\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cReFocus \u80fd\u8b93\u591a\u6a21\u614b LLM \u7522\u751f Python \u7a0b\u5f0f\u78bc\u4f86\u547c\u53eb\u5de5\u5177\u4e26\u4fee\u6539\u8f38\u5165\u5f71\u50cf\uff0c\u5faa\u5e8f\u6f38\u9032\u5730\u7e6a\u88fd\u65b9\u584a\u3001\u91cd\u9ede\u6a19\u793a\u5340\u6bb5\uff0c\u4ee5\u53ca\u906e\u853d\u5340\u57df\uff0c\u5f9e\u800c\u589e\u5f37\u8996\u89ba\u63a8\u7406\u904e\u7a0b\u3002\u6211\u5011\u5728\u6d89\u53ca\u8868\u683c\u548c\u5716\u8868\u7684\u5404\u7a2e\u7d50\u69cb\u5316\u5f71\u50cf\u7406\u89e3\u4efb\u52d9\u4e2d\u9032\u884c\u5be6\u9a57\u3002ReFocus \u5927\u5e45\u63d0\u5347\u4e86 GPT-4o \u5728\u6240\u6709\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\uff0c\u5728\u6c92\u6709\u8996\u89ba\u7de8\u8f2f\u7684\u60c5\u6cc1\u4e0b\uff0c\u5728\u8868\u683c\u4efb\u52d9\u4e0a\u5e73\u5747\u63d0\u5347\u4e86 11.0%\uff0c\u5728\u5716\u8868\u4efb\u52d9\u4e0a\u63d0\u5347\u4e86 6.8%\u3002\u6211\u5011\u5c0d\u4e0d\u540c\u8996\u89ba\u7de8\u8f2f\u7684\u6548\u679c\u9032\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u4e26\u8aaa\u660e\u4e86 ReFocus \u5982\u4f55\u5728\u4e0d\u5f15\u5165\u984d\u5916\u8cc7\u8a0a\u7684\u60c5\u6cc1\u4e0b\u63d0\u5347\u8868\u73fe\u7684\u539f\u56e0\u3002\u6b64\u5916\uff0c\u6211\u5011\u4f7f\u7528 ReFocus \u6536\u96c6\u4e86\u4e00\u500b 14k \u8a13\u7df4\u96c6\uff0c\u4e26\u8b49\u660e\u9019\u7a2e\u5305\u542b\u4e2d\u9593\u8cc7\u8a0a\u7684\u8996\u89ba\u601d\u8003\u93c8\u6bd4\u6a19\u6e96\u7684 VQA \u8cc7\u6599\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u76e3\u7763\uff0c\u5728\u4f7f\u7528 QA \u5c0d\u8a13\u7df4\u7684\u76f8\u540c\u6a21\u578b\u4e0a\u5e73\u5747\u63d0\u5347\u4e86 8.0%\uff0c\u5728 CoT \u4e0a\u63d0\u5347\u4e86 2.6%\u3002", "author": "Xingyu Fu et.al.", "authors": "Xingyu Fu, Minqian Liu, Zhengyuan Yang, John Corring, Yijuan Lu, Jianwei Yang, Dan Roth, Dinei Florencio, Cha Zhang", "id": "2501.05452v1", "paper_url": "http://arxiv.org/abs/2501.05452v1", "repo": "null"}}