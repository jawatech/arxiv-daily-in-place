{"2503.20783": {"publish_time": "2025-03-26", "title": "Understanding R1-Zero-Like Training: A Critical Perspective", "paper_summary": "DeepSeek-R1-Zero has shown that reinforcement learning (RL) at scale can\ndirectly enhance the reasoning capabilities of LLMs without supervised\nfine-tuning. In this work, we critically examine R1-Zero-like training by\nanalyzing its two core components: base models and RL. We investigate a wide\nrange of base models, including DeepSeek-V3-Base, to understand how pretraining\ncharacteristics influence RL performance. Our analysis reveals that\nDeepSeek-V3-Base already exhibit ''Aha moment'', while Qwen2.5 base models\ndemonstrate strong reasoning capabilities even without prompt templates,\nsuggesting potential pretraining biases. Additionally, we identify an\noptimization bias in Group Relative Policy Optimization (GRPO), which\nartificially increases response length (especially for incorrect outputs)\nduring training. To address this, we introduce Dr. GRPO, an unbiased\noptimization method that improves token efficiency while maintaining reasoning\nperformance. Leveraging these insights, we present a minimalist R1-Zero recipe\nthat achieves 43.3% accuracy on AIME 2024 with a 7B base model, establishing a\nnew state-of-the-art. Our code is available at\nhttps://github.com/sail-sg/understand-r1-zero.", "paper_summary_zh": "<paragraph>DeepSeek-R1-Zero \u5df2\u7d93\u8b49\u660e\uff0c\u5927\u898f\u6a21\u5f37\u5316\u5b78\u7fd2 (RL) \u53ef\u4ee5\u76f4\u63a5\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u7121\u9700\u76e3\u7763\u5fae\u8abf\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u901a\u904e\u5206\u6790\u5176\u5169\u500b\u6838\u5fc3\u7d44\u6210\u90e8\u5206\uff1a\u57fa\u790e\u6a21\u578b\u548c\u5f37\u5316\u5b78\u7fd2\uff0c\u6279\u5224\u6027\u5730\u5be9\u8996\u4e86\u985e\u4f3c R1-Zero \u7684\u8a13\u7df4\u65b9\u6cd5\u3002\u6211\u5011\u7814\u7a76\u4e86\u5305\u62ec DeepSeek-V3-Base \u5728\u5167\u7684\u5404\u7a2e\u57fa\u790e\u6a21\u578b\uff0c\u4ee5\u4e86\u89e3\u9810\u8a13\u7df4\u7279\u6027\u5982\u4f55\u5f71\u97ff\u5f37\u5316\u5b78\u7fd2\u7684\u6548\u80fd\u3002\u6211\u5011\u7684\u5206\u6790\u8868\u660e\uff0cDeepSeek-V3-Base \u5df2\u7d93\u5c55\u73fe\u51fa\u300c\u9813\u609f\u6642\u523b\u300d\uff0c\u800c Qwen2.5 \u57fa\u790e\u6a21\u578b\u5373\u4f7f\u6c92\u6709\u63d0\u793a\u6a21\u677f\u4e5f\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9019\u8868\u660e\u53ef\u80fd\u5b58\u5728\u9810\u8a13\u7df4\u504f\u5dee\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u7fa4\u7d44\u76f8\u5c0d\u7b56\u7565\u512a\u5316 (GRPO) \u4e2d\u767c\u73fe\u4e86\u4e00\u500b\u512a\u5316\u504f\u5dee\uff0c\u5b83\u6703\u5728\u8a13\u7df4\u671f\u9593\u4eba\u70ba\u5730\u589e\u52a0\u56de\u61c9\u9577\u5ea6\uff08\u5c24\u5176\u662f\u4e0d\u6b63\u78ba\u7684\u8f38\u51fa\uff09\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 Dr. GRPO\uff0c\u9019\u662f\u4e00\u7a2e\u7121\u504f\u5dee\u7684\u512a\u5316\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u63a8\u7406\u6548\u80fd\u7684\u540c\u6642\u63d0\u9ad8 token \u6548\u7387\u3002\u5229\u7528\u9019\u4e9b\u898b\u89e3\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u7d04\u7684 R1-Zero \u65b9\u6848\uff0c\u4f7f\u7528 7B \u57fa\u790e\u6a21\u578b\u5728 AIME 2024 \u4e0a\u9054\u5230\u4e86 43.3% \u7684\u6e96\u78ba\u7387\uff0c\u5275\u4e0b\u4e86\u65b0\u7684\u6700\u4f73\u7d00\u9304\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/sail-sg/understand-r1-zero \u53d6\u5f97\u3002</paragraph>\n", "author": "Zichen Liu et.al.", "authors": "Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin", "id": "2503.20783v1", "paper_url": "http://arxiv.org/abs/2503.20783v1", "repo": "null"}}