{"2410.11578": {"publish_time": "2024-10-13", "title": "STA-Unet: Rethink the semantic redundant for Medical Imaging Segmentation", "paper_summary": "In recent years, significant progress has been made in the medical image\nanalysis domain using convolutional neural networks (CNNs). In particular, deep\nneural networks based on a U-shaped architecture (UNet) with skip connections\nhave been adopted for several medical imaging tasks, including organ\nsegmentation. Despite their great success, CNNs are not good at learning global\nor semantic features. Especially ones that require human-like reasoning to\nunderstand the context. Many UNet architectures attempted to adjust with the\nintroduction of Transformer-based self-attention mechanisms, and notable gains\nin performance have been noted. However, the transformers are inherently flawed\nwith redundancy to learn at shallow layers, which often leads to an increase in\nthe computation of attention from the nearby pixels offering limited\ninformation. The recently introduced Super Token Attention (STA) mechanism\nadapts the concept of superpixels from pixel space to token space, using super\ntokens as compact visual representations. This approach tackles the redundancy\nby learning efficient global representations in vision transformers, especially\nfor the shallow layers. In this work, we introduce the STA module in the UNet\narchitecture (STA-UNet), to limit redundancy without losing rich information.\nExperimental results on four publicly available datasets demonstrate the\nsuperiority of STA-UNet over existing state-of-the-art architectures in terms\nof Dice score and IOU for organ segmentation tasks. The code is available at\n\\url{https://github.com/Retinal-Research/STA-UNet}.", "paper_summary_zh": "<paragraph>\u8fd1\u5e74\u4f86\uff0c\u4f7f\u7528\u5377\u7a4d\u795e\u7d93\u7db2\u8def (CNN) \u5728\u91ab\u5b78\u5f71\u50cf\u5206\u6790\u9818\u57df\u4e2d\u53d6\u5f97\u986f\u8457\u9032\u5c55\u3002\u7279\u5225\u662f\uff0c\u57fa\u65bc U \u5f62\u67b6\u69cb (UNet) \u7684\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\uff0c\u5177\u6709\u8df3\u8e8d\u9023\u63a5\uff0c\u5df2\u88ab\u63a1\u7528\u65bc\u591a\u9805\u91ab\u5b78\u5f71\u50cf\u4efb\u52d9\uff0c\u5305\u62ec\u5668\u5b98\u5206\u5272\u3002\u5118\u7ba1 CNN \u7372\u5f97\u5de8\u5927\u7684\u6210\u529f\uff0c\u4f46\u5b83\u5011\u4e26\u4e0d\u64c5\u9577\u5b78\u7fd2\u5168\u5c40\u6216\u8a9e\u7fa9\u7279\u5fb5\u3002\u5c24\u5176\u662f\u90a3\u4e9b\u9700\u8981\u985e\u4f3c\u4eba\u985e\u7684\u63a8\u7406\u624d\u80fd\u7406\u89e3\u8108\u7d61\u7684\u7279\u5fb5\u3002\u8a31\u591a UNet \u67b6\u69cb\u5617\u8a66\u900f\u904e\u5c0e\u5165\u57fa\u65bc Transformer \u7684\u81ea\u6211\u6ce8\u610f\u6a5f\u5236\u9032\u884c\u8abf\u6574\uff0c\u4e26\u5df2\u6ce8\u610f\u5230\u6548\u80fd\u7684\u986f\u8457\u63d0\u5347\u3002\u7136\u800c\uff0cTransformer \u5728\u672c\u8cea\u4e0a\u5b58\u5728\u5b78\u7fd2\u6dfa\u5c64\u7684\u5197\u9918\u7f3a\u9677\uff0c\u9019\u901a\u5e38\u6703\u5c0e\u81f4\u8a08\u7b97\u4f86\u81ea\u9644\u8fd1\u50cf\u7d20\u7684\u6ce8\u610f\uff0c\u800c\u9019\u4e9b\u50cf\u7d20\u63d0\u4f9b\u7684\u8cc7\u8a0a\u6709\u9650\u3002\u6700\u8fd1\u63a8\u51fa\u7684\u8d85\u6a19\u8a18\u6ce8\u610f (STA) \u6a5f\u5236\u5c07\u8d85\u50cf\u7d20\u7684\u6982\u5ff5\u5f9e\u50cf\u7d20\u7a7a\u9593\u8abf\u6574\u5230\u6a19\u8a18\u7a7a\u9593\uff0c\u4f7f\u7528\u8d85\u6a19\u8a18\u4f5c\u70ba\u7dca\u6e4a\u7684\u8996\u89ba\u8868\u793a\u3002\u9019\u7a2e\u65b9\u6cd5\u900f\u904e\u5b78\u7fd2\u8996\u89ba Transformer \u4e2d\u6709\u6548\u7387\u7684\u5168\u5c40\u8868\u793a\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u6dfa\u5c64\uff0c\u4f86\u89e3\u6c7a\u5197\u9918\u554f\u984c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5728 UNet \u67b6\u69cb (STA-UNet) \u4e2d\u5c0e\u5165 STA \u6a21\u7d44\uff0c\u4ee5\u9650\u5236\u5197\u9918\uff0c\u540c\u6642\u4e0d\u907a\u5931\u8c50\u5bcc\u7684\u8cc7\u8a0a\u3002\u5728\u56db\u500b\u516c\u958b\u53ef\u7528\u7684\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86 STA-UNet \u5728\u5668\u5b98\u5206\u5272\u4efb\u52d9\u7684 Dice \u5206\u6578\u548c IOU \u65b9\u9762\u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032\u67b6\u69cb\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 \\url{https://github.com/Retinal-Research/STA-UNet} \u53d6\u5f97\u3002</paragraph>", "author": "Vamsi Krishna Vasa et.al.", "authors": "Vamsi Krishna Vasa, Wenhui Zhu, Xiwen Chen, Peijie Qiu, Xuanzhao Dong, Yalin Wang", "id": "2410.11578v1", "paper_url": "http://arxiv.org/abs/2410.11578v1", "repo": "null"}}