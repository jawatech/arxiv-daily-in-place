{"2503.06486": {"publish_time": "2025-03-09", "title": "PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training", "paper_summary": "This paper aims to address the challenge of hallucinations in Multimodal\nLarge Language Models (MLLMs) particularly for dense image captioning tasks. To\ntackle the challenge, we identify the current lack of a metric that finely\nmeasures the caption quality in concept level. We hereby introduce HalFscore, a\nnovel metric built upon the language graph and is designed to evaluate both the\naccuracy and completeness of dense captions at a granular level. Additionally,\nwe identify the root cause of hallucination as the model's over-reliance on its\nlanguage prior. To address this, we propose PerturboLLaVA, which reduces the\nmodel's reliance on the language prior by incorporating adversarially perturbed\ntext during training. This method enhances the model's focus on visual inputs,\neffectively reducing hallucinations and producing accurate, image-grounded\ndescriptions without incurring additional computational overhead. PerturboLLaVA\nsignificantly improves the fidelity of generated captions, outperforming\nexisting approaches in handling multimodal hallucinations and achieving\nimproved performance across general multimodal benchmarks.", "paper_summary_zh": "<paragraph>\u672c\u6587\u65e8\u5728\u63a2\u8a0e\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u4e2d\u7684\u5e7b\u89ba\u73fe\u8c61\uff0c\u7279\u5225\u662f\u5728\u5bc6\u96c6\u5716\u50cf\u63cf\u8ff0\u4efb\u52d9\u4e2d\u7684\u5e7b\u89ba\u554f\u984c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\uff0c\u6211\u5011\u767c\u73fe\u76ee\u524d\u7f3a\u4e4f\u4e00\u500b\u80fd\u5728\u6982\u5ff5\u5c64\u9762\u7cbe\u7d30\u8861\u91cf\u63cf\u8ff0\u54c1\u8cea\u7684\u6307\u6a19\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 HalFscore\uff0c\u9019\u662f\u4e00\u500b\u57fa\u65bc\u8a9e\u8a00\u5716\u7684\u65b0\u578b\u6307\u6a19\uff0c\u65e8\u5728\u8a55\u4f30\u5bc6\u96c6\u63cf\u8ff0\u5728\u7d30\u7c92\u5ea6\u5c64\u9762\u4e0a\u7684\u6e96\u78ba\u6027\u548c\u5b8c\u6574\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c07\u5e7b\u89ba\u7684\u6839\u672c\u539f\u56e0\u78ba\u5b9a\u70ba\u6a21\u578b\u904e\u5ea6\u4f9d\u8cf4\u5176\u8a9e\u8a00\u5148\u9a57\u77e5\u8b58\u3002\u70ba\u4e86\u61c9\u5c0d\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 PerturboLLaVA\uff0c\u5b83\u900f\u904e\u5728\u8a13\u7df4\u671f\u9593\u52a0\u5165\u5c0d\u6297\u6027\u64fe\u52d5\u7684\u6587\u672c\uff0c\u4f86\u6e1b\u5c11\u6a21\u578b\u5c0d\u8a9e\u8a00\u5148\u9a57\u77e5\u8b58\u7684\u4f9d\u8cf4\u3002\u9019\u7a2e\u65b9\u6cd5\u589e\u5f37\u4e86\u6a21\u578b\u5c0d\u8996\u89ba\u8f38\u5165\u7684\u95dc\u6ce8\uff0c\u6709\u6548\u5730\u6e1b\u5c11\u4e86\u5e7b\u89ba\uff0c\u4e26\u5728\u4e0d\u589e\u52a0\u984d\u5916\u8a08\u7b97\u958b\u92b7\u7684\u60c5\u6cc1\u4e0b\u7522\u751f\u6e96\u78ba\u7684\u3001\u57fa\u65bc\u5716\u50cf\u7684\u63cf\u8ff0\u3002PerturboLLaVA \u5927\u5927\u63d0\u9ad8\u4e86\u751f\u6210\u63cf\u8ff0\u7684\u4fdd\u771f\u5ea6\uff0c\u5728\u8655\u7406\u591a\u6a21\u614b\u5e7b\u89ba\u65b9\u9762\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\uff0c\u4e26\u5728\u4e00\u822c\u591a\u6a21\u614b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6548\u80fd\u3002</paragraph>\n", "author": "Cong Chen et.al.", "authors": "Cong Chen, Mingyu Liu, Chenchen Jing, Yizhou Zhou, Fengyun Rao, Hao Chen, Bo Zhang, Chunhua Shen", "id": "2503.06486v1", "paper_url": "http://arxiv.org/abs/2503.06486v1", "repo": "null"}}