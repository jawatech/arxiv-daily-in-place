{"2405.17357": {"publish_time": "2024-05-27", "title": "DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank Distribution", "paper_summary": "Fine-tuning large-scale pre-trained models is inherently a resource-intensive\ntask. While it can enhance the capabilities of the model, it also incurs\nsubstantial computational costs, posing challenges to the practical application\nof downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methods\nsuch as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores the\ndifferential parameter budget requirements across weight matrices, which may\nlead to suboptimal fine-tuning outcomes. To address this issue, we introduce\nthe Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRA\nlayers into structured single-rank components, allowing for dynamic pruning of\nparameter budget based on their importance to specific tasks during training,\nwhich makes the most of the limited parameter budget. Experimental results\ndemonstrate that DoRA can achieve competitive performance compared with LoRA\nand full model fine-tuning, and outperform various strong baselines with the\nsame storage parameter budget. Our code is available at\nhttps://github.com/Yulongmao1/DoRA/", "paper_summary_zh": "\u5fae\u8abf\u5927\u578b\u9810\u8a13\u7df4\u6a21\u578b\u672c\u8cea\u4e0a\u662f\u4e00\u9805\u8cc7\u6e90\u5bc6\u96c6\u578b\u4efb\u52d9\u3002\u96d6\u7136\u5b83\u53ef\u4ee5\u589e\u5f37\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u4e5f\u6703\u7522\u751f\u5927\u91cf\u7684\u8a08\u7b97\u6210\u672c\uff0c\u5c0d\u4e0b\u6e38\u4efb\u52d9\u7684\u5be6\u969b\u61c9\u7528\u69cb\u6210\u6311\u6230\u3002\u73fe\u6709\u7684\u53c3\u6578\u9ad8\u6548\u5fae\u8abf (PEFT) \u65b9\u6cd5\uff08\u4f8b\u5982\u4f4e\u79e9\u9069\u61c9 (LoRA)\uff09\u4f9d\u8cf4\u65bc\u4e00\u500b\u65c1\u8def\u6846\u67b6\uff0c\u8a72\u6846\u67b6\u5ffd\u7565\u4e86\u4e0d\u540c\u6b0a\u91cd\u77e9\u9663\u4e4b\u9593\u7684\u5dee\u5206\u53c3\u6578\u9810\u7b97\u9700\u6c42\uff0c\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u6b21\u512a\u7684\u5fae\u8abf\u7d50\u679c\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u52d5\u614b\u4f4e\u79e9\u9069\u61c9 (DoRA) \u65b9\u6cd5\u3002DoRA \u5c07\u9ad8\u79e9 LoRA \u5c64\u5206\u89e3\u70ba\u7d50\u69cb\u5316\u7684\u55ae\u79e9\u7d44\u4ef6\uff0c\u5141\u8a31\u6839\u64da\u53c3\u6578\u9810\u7b97\u5c0d\u7279\u5b9a\u4efb\u52d9\u8a13\u7df4\u671f\u9593\u7684\u91cd\u8981\u6027\u9032\u884c\u52d5\u614b\u526a\u679d\uff0c\u5f9e\u800c\u6700\u5927\u9650\u5ea6\u5730\u5229\u7528\u6709\u9650\u7684\u53c3\u6578\u9810\u7b97\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u8207 LoRA \u548c\u5b8c\u5168\u6a21\u578b\u5fae\u8abf\u76f8\u6bd4\uff0cDoRA \u53ef\u4ee5\u5be6\u73fe\u5177\u6709\u7af6\u722d\u529b\u7684\u6027\u80fd\uff0c\u4e26\u4e14\u5728\u76f8\u540c\u7684\u5b58\u5132\u53c3\u6578\u9810\u7b97\u4e0b\u512a\u65bc\u5404\u7a2e\u5f37\u5927\u7684\u57fa\u7dda\u3002\u6211\u5011\u7684\u4ee3\u78bc\u53ef\u5728 https://github.com/Yulongmao1/DoRA/ \u7372\u5f97", "author": "Yulong Mao et.al.", "authors": "Yulong Mao, Kaiyu Huang, Changhao Guan, Ganglin Bao, Fengran Mo, Jinan Xu", "id": "2405.17357v1", "paper_url": "http://arxiv.org/abs/2405.17357v1", "repo": "https://github.com/yulongmao1/dora"}}