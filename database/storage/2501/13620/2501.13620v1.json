{"2501.13620": {"publish_time": "2025-01-23", "title": "Cognitive Paradigms for Evaluating VLMs on Visual Reasoning Task", "paper_summary": "Evaluating the reasoning capabilities of Vision-Language Models (VLMs) in\ncomplex visual tasks provides valuable insights into their potential and\nlimitations. In this work, we assess the performance of VLMs on the challenging\nBongard Openworld Problems benchmark, which involves reasoning over natural\nimages. We propose and evaluate three human-inspired paradigms: holistic\nanalysis (global context processing), deductive rule learning (explicit rule\nderivation and application), and componential analysis (structured\ndecomposition of images into components). Our results demonstrate that\nstate-of-the-art models, including GPT-4o and Gemini, not only surpass human\nbenchmarks but also excel in structured reasoning tasks, with componential\nanalysis proving especially effective. However, ablation studies reveal key\nchallenges, such as handling synthetic images, making fine-grained\ndistinctions, and interpreting nuanced contextual information. These insights\nunderscore the need for further advancements in model robustness and\ngeneralization, while highlighting the transformative potential of structured\nreasoning approaches in enhancing VLM capabilities.", "paper_summary_zh": "\u8a55\u4f30\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5728\u8907\u96dc\u8996\u89ba\u4efb\u52d9\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u80fd\u63d0\u4f9b\u6709\u50f9\u503c\u7684\u898b\u89e3\uff0c\u4e86\u89e3\u5176\u6f5b\u529b\u548c\u9650\u5236\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8a55\u4f30 VLM \u5728\u5177\u6709\u6311\u6230\u6027\u7684 Bongard Openworld Problems \u57fa\u6e96\u4e0a\u7684\u6548\u80fd\uff0c\u5176\u4e2d\u6d89\u53ca\u5c0d\u81ea\u7136\u5f71\u50cf\u7684\u63a8\u7406\u3002\u6211\u5011\u63d0\u51fa\u4e26\u8a55\u4f30\u4e09\u500b\u53d7\u4eba\u985e\u555f\u767c\u7684\u7bc4\u4f8b\uff1a\u6574\u9ad4\u5206\u6790\uff08\u5168\u5c40\u8108\u7d61\u8655\u7406\uff09\u3001\u6f14\u7e79\u898f\u5247\u5b78\u7fd2\uff08\u660e\u78ba\u898f\u5247\u63a8\u5c0e\u548c\u61c9\u7528\uff09\uff0c\u4ee5\u53ca\u7d44\u6210\u5206\u6790\uff08\u5c07\u5f71\u50cf\u7d50\u69cb\u5316\u5206\u89e3\u70ba\u7d44\u6210\u90e8\u5206\uff09\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u5305\u62ec GPT-4o \u548c Gemini \u5728\u5167\u7684\u6700\u65b0\u6a21\u578b\u4e0d\u50c5\u8d85\u8d8a\u4e86\u4eba\u985e\u57fa\u6e96\uff0c\u800c\u4e14\u5728\u7d50\u69cb\u5316\u63a8\u7406\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u5176\u4e2d\u7d44\u6210\u5206\u6790\u7279\u5225\u6709\u6548\u3002\u7136\u800c\uff0c\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u95dc\u9375\u6311\u6230\uff0c\u4f8b\u5982\u8655\u7406\u5408\u6210\u5f71\u50cf\u3001\u505a\u51fa\u7d30\u5fae\u5340\u5206\u4ee5\u53ca\u8a6e\u91cb\u7d30\u5fae\u7684\u8108\u7d61\u8cc7\u8a0a\u3002\u9019\u4e9b\u898b\u89e3\u5f37\u8abf\u4e86\u9032\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7a69\u5065\u6027\u548c\u6cdb\u5316\u7684\u5fc5\u8981\u6027\uff0c\u540c\u6642\u5f37\u8abf\u4e86\u7d50\u69cb\u5316\u63a8\u7406\u65b9\u6cd5\u5728\u589e\u5f37 VLM \u80fd\u529b\u65b9\u9762\u7684\u8f49\u5316\u6f5b\u529b\u3002", "author": "Mohit Vaishnav et.al.", "authors": "Mohit Vaishnav, Tanel Tammet", "id": "2501.13620v1", "paper_url": "http://arxiv.org/abs/2501.13620v1", "repo": "null"}}