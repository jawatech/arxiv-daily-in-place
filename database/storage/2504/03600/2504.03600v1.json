{"2504.03600": {"publish_time": "2025-04-04", "title": "MedSAM2: Segment Anything in 3D Medical Images and Videos", "paper_summary": "Medical image and video segmentation is a critical task for precision\nmedicine, which has witnessed considerable progress in developing task or\nmodality-specific and generalist models for 2D images. However, there have been\nlimited studies on building general-purpose models for 3D images and videos\nwith comprehensive user studies. Here, we present MedSAM2, a promptable\nsegmentation foundation model for 3D image and video segmentation. The model is\ndeveloped by fine-tuning the Segment Anything Model 2 on a large medical\ndataset with over 455,000 3D image-mask pairs and 76,000 frames, outperforming\nprevious models across a wide range of organs, lesions, and imaging modalities.\nFurthermore, we implement a human-in-the-loop pipeline to facilitate the\ncreation of large-scale datasets resulting in, to the best of our knowledge,\nthe most extensive user study to date, involving the annotation of 5,000 CT\nlesions, 3,984 liver MRI lesions, and 251,550 echocardiogram video frames,\ndemonstrating that MedSAM2 can reduce manual costs by more than 85%. MedSAM2 is\nalso integrated into widely used platforms with user-friendly interfaces for\nlocal and cloud deployment, making it a practical tool for supporting\nefficient, scalable, and high-quality segmentation in both research and\nhealthcare environments.", "paper_summary_zh": "\u91ab\u5b78\u5f71\u50cf\u548c\u5f71\u7247\u5206\u5272\u662f\u7cbe\u6e96\u91ab\u7642\u7684\u95dc\u9375\u4efb\u52d9\uff0c\u5728\u958b\u767c\u91dd\u5c0d 2D \u5f71\u50cf\u7684\u7279\u5b9a\u4efb\u52d9\u6216\u6a21\u5f0f\u4ee5\u53ca\u901a\u7528\u6a21\u578b\u65b9\u9762\u5df2\u53d6\u5f97\u76f8\u7576\u5927\u7684\u9032\u5c55\u3002\u7136\u800c\uff0c\u91dd\u5c0d 3D \u5f71\u50cf\u548c\u5f71\u7247\u5efa\u7acb\u901a\u7528\u6a21\u578b\u4e26\u9032\u884c\u5168\u9762\u4f7f\u7528\u8005\u7814\u7a76\u7684\u76f8\u95dc\u7814\u7a76\u537b\u76f8\u7576\u6709\u9650\u3002\u5728\u9019\u88e1\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MedSAM2\uff0c\u4e00\u500b\u9069\u7528\u65bc 3D \u5f71\u50cf\u548c\u5f71\u7247\u5206\u5272\u7684\u53ef\u63d0\u793a\u5206\u5272\u57fa\u790e\u6a21\u578b\u3002\u8a72\u6a21\u578b\u662f\u900f\u904e\u5728\u4e00\u500b\u5927\u578b\u91ab\u5b78\u6578\u64da\u96c6\u4e0a\u5fae\u8abf Segment Anything Model 2 \u800c\u958b\u767c\u7684\uff0c\u8a72\u6578\u64da\u96c6\u5305\u542b\u8d85\u904e 455,000 \u500b 3D \u5f71\u50cf-\u906e\u7f69\u5c0d\u548c 76,000 \u5e40\uff0c\u5728\u5404\u7a2e\u5668\u5b98\u3001\u75c5\u7076\u548c\u6210\u50cf\u6a21\u5f0f\u4e0a\u7684\u8868\u73fe\u90fd\u512a\u65bc\u5148\u524d\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5be6\u4f5c\u4e86\u4e00\u500b\u4eba\u6a5f\u8ff4\u5708\u6d41\u7a0b\uff0c\u4ee5\u4fc3\u9032\u5927\u898f\u6a21\u6578\u64da\u96c6\u7684\u5275\u5efa\uff0c\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u6709\u53f2\u4ee5\u4f86\u6700\u5ee3\u6cdb\u7684\u4f7f\u7528\u8005\u7814\u7a76\uff0c\u6d89\u53ca 5,000 \u500b CT \u75c5\u7076\u30013,984 \u500b\u809d\u81df MRI \u75c5\u7076\u548c 251,550 \u500b\u8d85\u97f3\u6ce2\u5fc3\u52d5\u5716\u5f71\u7247\u5e40\u7684\u6a19\u8a18\uff0c\u8b49\u660e MedSAM2 \u53ef\u4ee5\u5c07\u4eba\u5de5\u6210\u672c\u964d\u4f4e 85% \u4ee5\u4e0a\u3002MedSAM2 \u4e5f\u88ab\u6574\u5408\u5230\u5ee3\u6cdb\u4f7f\u7528\u7684\u5e73\u53f0\u4e2d\uff0c\u9019\u4e9b\u5e73\u53f0\u5177\u6709\u4f7f\u7528\u8005\u53cb\u5584\u7684\u4ecb\u9762\uff0c\u53ef\u4f9b\u672c\u5730\u548c\u96f2\u7aef\u90e8\u7f72\uff0c\u4f7f\u5176\u6210\u70ba\u652f\u63f4\u5728\u7814\u7a76\u548c\u91ab\u7642\u74b0\u5883\u4e2d\u9032\u884c\u9ad8\u6548\u3001\u53ef\u64f4\u5c55\u548c\u9ad8\u54c1\u8cea\u5206\u5272\u7684\u5be6\u7528\u5de5\u5177\u3002\n", "author": "Jun Ma et.al.", "authors": "Jun Ma, Zongxin Yang, Sumin Kim, Bihui Chen, Mohammed Baharoon, Adibvafa Fallahpour, Reza Asakereh, Hongwei Lyu, Bo Wang", "id": "2504.03600v1", "paper_url": "http://arxiv.org/abs/2504.03600v1", "repo": "null"}}