{"2407.07024": {"publish_time": "2024-07-09", "title": "Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization", "paper_summary": "The vocabulary size in temporal action localization (TAL) is constrained by\nthe scarcity of large-scale annotated datasets. To address this, recent works\nincorporate powerful pre-trained vision-language models (VLMs), such as CLIP,\nto perform open-vocabulary TAL (OV-TAL). However, unlike VLMs trained on\nextensive image/video-text pairs, existing OV-TAL methods still rely on small,\nfully labeled TAL datasets for training an action localizer. In this paper, we\nexplore the scalability of self-training with unlabeled YouTube videos for\nOV-TAL. Our self-training approach consists of two stages. First, a\nclass-agnostic action localizer is trained on a human-labeled TAL dataset and\nused to generate pseudo-labels for unlabeled videos. Second, the large-scale\npseudo-labeled dataset is combined with the human-labeled dataset to train the\nlocalizer. Extensive experiments demonstrate that leveraging web-scale videos\nin self-training significantly enhances the generalizability of an action\nlocalizer. Additionally, we highlighted issues with existing OV-TAL evaluation\nschemes and proposed a new evaluation protocol. Code is released at\nhttps://github.com/HYUNJS/STOV-TAL", "paper_summary_zh": "\u6642\u5e8f\u52d5\u4f5c\u5b9a\u4f4d (TAL) \u4e2d\u7684\u8a5e\u5f59\u91cf\u53d7\u5230\u5927\u898f\u6a21\u6a19\u8a3b\u8cc7\u6599\u96c6\u7a00\u5c11\u7684\u9650\u5236\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u7d50\u5408\u4e86\u5f37\u5927\u7684\u9810\u8a13\u7df4\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u4f8b\u5982 CLIP\uff0c\u4f86\u57f7\u884c\u958b\u653e\u8a5e\u5f59 TAL (OV-TAL)\u3002\u7136\u800c\uff0c\u8207\u5728\u5927\u91cf\u7684\u5f71\u50cf/\u5f71\u7247-\u6587\u5b57\u914d\u5c0d\u4e0a\u8a13\u7df4\u7684 VLM \u4e0d\u540c\uff0c\u73fe\u6709\u7684 OV-TAL \u65b9\u6cd5\u4ecd\u7136\u4f9d\u8cf4\u65bc\u5c0f\u578b\u3001\u5b8c\u5168\u6a19\u8a3b\u7684 TAL \u8cc7\u6599\u96c6\u4f86\u8a13\u7df4\u52d5\u4f5c\u5b9a\u4f4d\u5668\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u4f7f\u7528\u672a\u6a19\u8a3b\u7684 YouTube \u5f71\u7247\u9032\u884c\u81ea\u8a13\u7df4\u5728 OV-TAL \u4e2d\u7684\u53ef\u64f4\u5145\u6027\u3002\u6211\u5011\u7684\u81ea\u8a13\u7df4\u65b9\u6cd5\u5305\u542b\u5169\u500b\u968e\u6bb5\u3002\u9996\u5148\uff0c\u5728\u4eba\u5de5\u6a19\u8a3b\u7684 TAL \u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u4e00\u500b\u8207\u985e\u5225\u7121\u95dc\u7684\u52d5\u4f5c\u5b9a\u4f4d\u5668\uff0c\u4e26\u7528\u65bc\u70ba\u672a\u6a19\u8a3b\u7684\u5f71\u7247\u7522\u751f\u507d\u6a19\u7c64\u3002\u5176\u6b21\uff0c\u5c07\u5927\u898f\u6a21\u7684\u507d\u6a19\u7c64\u8cc7\u6599\u96c6\u8207\u4eba\u5de5\u6a19\u8a3b\u7684\u8cc7\u6599\u96c6\u7d50\u5408\u8d77\u4f86\u8a13\u7df4\u5b9a\u4f4d\u5668\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u5728\u81ea\u8a13\u7df4\u4e2d\u5229\u7528\u7db2\u8def\u898f\u6a21\u7684\u5f71\u7247\u53ef\u4ee5\u986f\u8457\u589e\u5f37\u52d5\u4f5c\u5b9a\u4f4d\u5668\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f37\u8abf\u4e86\u73fe\u6709 OV-TAL \u8a55\u4f30\u65b9\u6848\u7684\u554f\u984c\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u8a55\u4f30\u5354\u5b9a\u3002\u7a0b\u5f0f\u78bc\u5df2\u767c\u5e03\u65bc https://github.com/HYUNJS/STOV-TAL", "author": "Jeongseok Hyun et.al.", "authors": "Jeongseok Hyun, Su Ho Han, Hyolim Kang, Joon-Young Lee, Seon Joo Kim", "id": "2407.07024v1", "paper_url": "http://arxiv.org/abs/2407.07024v1", "repo": "https://github.com/hyunjs/stov-tal"}}