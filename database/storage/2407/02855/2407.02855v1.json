{"2407.02855": {"publish_time": "2024-07-03", "title": "Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks", "paper_summary": "LLMs are known to be vulnerable to jailbreak attacks, even after safety\nalignment. An important observation is that, while different types of jailbreak\nattacks can generate significantly different queries, they mostly result in\nsimilar responses that are rooted in the same harmful knowledge (e.g., detailed\nsteps to make a bomb). Therefore, we conjecture that directly unlearn the\nharmful knowledge in the LLM can be a more effective way to defend against\njailbreak attacks than the mainstream supervised fine-tuning (SFT) based\napproaches. Our extensive experiments confirmed our insight and suggested\nsurprising generalizability of our unlearning-based approach: using only 20 raw\nharmful questions \\emph{without} any jailbreak prompt during training, our\nsolution reduced the Attack Success Rate (ASR) in Vicuna-7B on\n\\emph{out-of-distribution} (OOD) harmful questions wrapped with various complex\njailbreak prompts from 82.6\\% to 7.7\\%. This significantly outperforms\nLlama2-7B-Chat, which is fine-tuned on about 0.1M safety alignment samples but\nstill has an ASR of 21.9\\% even under the help of an additional safety system\nprompt. Further analysis reveals that the generalization ability of our\nsolution stems from the intrinsic relatedness among harmful responses across\nharmful questions (e.g., response patterns, shared steps and actions, and\nsimilarity among their learned representations in the LLM). Our code is\navailable at \\url{https://github.com/thu-coai/SafeUnlearning}.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u77e5\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u5373\u4f7f\u5728\u5b89\u5168\u8c03\u6574\u4e4b\u540e\u4e5f\u662f\u5982\u6b64\u3002\u4e00\u4e2a\u91cd\u8981\u7684\u89c2\u5bdf\u7ed3\u679c\u662f\uff0c\u867d\u7136\u4e0d\u540c\u7c7b\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u53ef\u4ee5\u751f\u6210\u660e\u663e\u4e0d\u540c\u7684\u67e5\u8be2\uff0c\u4f46\u5b83\u4eec\u5927\u591a\u4f1a\u5bfc\u81f4\u7c7b\u4f3c\u7684\u54cd\u5e94\uff0c\u8fd9\u4e9b\u54cd\u5e94\u690d\u6839\u4e8e\u76f8\u540c\u7684\u6709\u5bb3\u77e5\u8bc6\uff08\u4f8b\u5982\uff0c\u5236\u9020\u70b8\u5f39\u7684\u8be6\u7ec6\u6b65\u9aa4\uff09\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63a8\u6d4b\u76f4\u63a5\u53d6\u6d88\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6709\u5bb3\u77e5\u8bc6\u53ef\u80fd\u662f\u6bd4\u57fa\u4e8e\u4e3b\u6d41\u76d1\u7763\u5fae\u8c03 (SFT) \u7684\u65b9\u6cd5\u66f4\u6709\u6548\u7684\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u6211\u4eec\u7684\u89c1\u89e3\uff0c\u5e76\u8868\u660e\u4e86\u6211\u4eec\u57fa\u4e8e\u53d6\u6d88\u5b66\u4e60\u7684\u65b9\u6cd5\u4ee4\u4eba\u60ca\u8bb6\u7684\u666e\u904d\u6027\uff1a\u4ec5\u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u7528 20 \u4e2a\u539f\u59cb\u6709\u5bb3\u95ee\u9898\uff0c\u6ca1\u6709\u4efb\u4f55\u8d8a\u72f1\u63d0\u793a\uff0c\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u5c06 Vicuna-7B \u4e0a\u7684\u653b\u51fb\u6210\u529f\u7387 (ASR) \u964d\u4f4e\u4e86 82.6% \u81f3 7.7%\u3002\u8fd9\u660e\u663e\u4f18\u4e8e Llama2-7B-Chat\uff0c\u540e\u8005\u9488\u5bf9\u5927\u7ea6 0.1M \u5b89\u5168\u8c03\u6574\u6837\u672c\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4f46\u5373\u4f7f\u5728\u9644\u52a0\u5b89\u5168\u7cfb\u7edf\u63d0\u793a\u7684\u5e2e\u52a9\u4e0b\uff0c\u5176 ASR \u4ecd\u7136\u4e3a 21.9%\u3002\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u8868\u660e\uff0c\u6211\u4eec\u89e3\u51b3\u65b9\u6848\u7684\u6cdb\u5316\u80fd\u529b\u6e90\u4e8e\u6709\u5bb3\u95ee\u9898\u4e2d\u6709\u5bb3\u54cd\u5e94\u4e4b\u95f4\u7684\u5185\u5728\u76f8\u5173\u6027\uff08\u4f8b\u5982\uff0c\u54cd\u5e94\u6a21\u5f0f\u3001\u5171\u4eab\u6b65\u9aa4\u548c\u64cd\u4f5c\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5b66\u4e60\u7684\u8868\u793a\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff09\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728 https://github.com/thu-coai/SafeUnlearning \u83b7\u5f97\u3002", "author": "Zhexin Zhang et.al.", "authors": "Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang", "id": "2407.02855v1", "paper_url": "http://arxiv.org/abs/2407.02855v1", "repo": "https://github.com/thu-coai/safeunlearning"}}