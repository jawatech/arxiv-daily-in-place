
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-06**|**Accelerating Training with Neuron Interaction and Nowcasting Networks**|Boris Knyazev et.al.|[2409.04434v1](http://arxiv.org/abs/2409.04434v1)|[link](https://github.com/samsungsailmontreal/nino)|
|**2024-09-06**|**Hybrid Spiking Neural Networks for Low-Power Intra-Cortical Brain-Machine Interfaces**|Alexandru Vasilache et.al.|[2409.04428v1](http://arxiv.org/abs/2409.04428v1)|null|
|**2024-09-06**|**RLPF: Reinforcement Learning from Prediction Feedback for User Summarization with LLMs**|Jiaxing Wu et.al.|[2409.04421v1](http://arxiv.org/abs/2409.04421v1)|null|
|**2024-09-06**|**Open-MAGVIT2: An Open-Source Project Toward Democratizing Auto-regressive Visual Generation**|Zhuoyan Luo et.al.|[2409.04410v1](http://arxiv.org/abs/2409.04410v1)|null|
|**2024-09-06**|**Question-Answering Dense Video Events**|Hangyu Qin et.al.|[2409.04388v1](http://arxiv.org/abs/2409.04388v1)|null|
|**2024-09-06**|**Empirical Bayesian image restoration by Langevin sampling with a denoising diffusion implicit prior**|Charlesquin Kemajou Mbakam et.al.|[2409.04384v1](http://arxiv.org/abs/2409.04384v1)|null|
|**2024-09-06**|**The Impact of Scanner Domain Shift on Deep Learning Performance in Medical Imaging: an Experimental Study**|Gregory Szumel et.al.|[2409.04368v1](http://arxiv.org/abs/2409.04368v1)|null|
|**2024-09-06**|**Connectivity-Inspired Network for Context-Aware Recognition**|Gianluca Carloni et.al.|[2409.04360v1](http://arxiv.org/abs/2409.04360v1)|null|
|**2024-09-06**|**AGR: Age Group fairness Reward for Bias Mitigation in LLMs**|Shuirong Cao et.al.|[2409.04340v1](http://arxiv.org/abs/2409.04340v1)|null|
|**2024-09-06**|**Learning vs Retrieval: The Role of In-Context Examples in Regression with LLMs**|Aliakbar Nafar et.al.|[2409.04318v1](http://arxiv.org/abs/2409.04318v1)|null|
|**2024-09-06**|**CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis**|William Knottenbelt et.al.|[2409.04290v1](http://arxiv.org/abs/2409.04290v1)|[link](https://github.com/knottwill/CoxKAN)|
|**2024-09-06**|**Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**|Desiree Heim et.al.|[2409.04286v1](http://arxiv.org/abs/2409.04286v1)|null|
|**2024-09-06**|**Cycle Pixel Difference Network for Crisp Edge Detection**|Changsong Liu et.al.|[2409.04272v1](http://arxiv.org/abs/2409.04272v1)|null|
|**2024-09-06**|**Open Language Data Initiative: Advancing Low-Resource Machine Translation for Karakalpak**|Mukhammadsaid Mamasaidov et.al.|[2409.04269v1](http://arxiv.org/abs/2409.04269v1)|null|
|**2024-09-06**|**An overview of domain-specific foundation model: key technologies, applications and challenges**|Haolong Chen et.al.|[2409.04267v1](http://arxiv.org/abs/2409.04267v1)|null|
|**2024-09-06**|**Hermes: Memory-Efficient Pipeline Inference for Large Models on Edge Devices**|Xueyuan Han et.al.|[2409.04249v1](http://arxiv.org/abs/2409.04249v1)|null|
|**2024-09-06**|**WarpAdam: A new Adam optimizer based on Meta-Learning approach**|Chengxi Pan et.al.|[2409.04244v1](http://arxiv.org/abs/2409.04244v1)|null|
|**2024-09-06**|**Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework**|Daniel J. Tan et.al.|[2409.04224v1](http://arxiv.org/abs/2409.04224v1)|null|
|**2024-09-06**|**Fast Forwarding Low-Rank Training**|Adir Rahamim et.al.|[2409.04206v1](http://arxiv.org/abs/2409.04206v1)|null|
|**2024-09-06**|**GST: Precise 3D Human Body from a Single Image with Gaussian Splatting Transformers**|Lorenza Prospero et.al.|[2409.04196v1](http://arxiv.org/abs/2409.04196v1)|null|
|**2024-09-06**|**Towards Privacy-Preserving Relational Data Synthesis via Probabilistic Relational Models**|Malte Luttermann et.al.|[2409.04194v1](http://arxiv.org/abs/2409.04194v1)|null|
|**2024-09-06**|**Residual Stream Analysis with Multi-Layer SAEs**|Tim Lawson et.al.|[2409.04185v1](http://arxiv.org/abs/2409.04185v1)|[link](https://github.com/tim-lawson/mlsae)|
|**2024-09-06**|**GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**|Ziyin Zhang et.al.|[2409.04183v1](http://arxiv.org/abs/2409.04183v1)|null|
|**2024-09-06**|**Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**|Larissa Pusch et.al.|[2409.04181v1](http://arxiv.org/abs/2409.04181v1)|null|
|**2024-09-06**|**The Prevalence of Neural Collapse in Neural Multivariate Regression**|George Andriopoulos et.al.|[2409.04180v1](http://arxiv.org/abs/2409.04180v1)|null|
|**2024-09-06**|**From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks**|Andreas Stephan et.al.|[2409.04168v1](http://arxiv.org/abs/2409.04168v1)|null|
|**2024-09-06**|**Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation**|Luis Mayer et.al.|[2409.04164v1](http://arxiv.org/abs/2409.04164v1)|null|
|**2024-09-06**|**A Coin Has Two Sides: A Novel Detector-Corrector Framework for Chinese Spelling Correction**|Xiangke Zeng et.al.|[2409.04150v1](http://arxiv.org/abs/2409.04150v1)|null|
|**2024-09-06**|**Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers**|Gorka Abad et.al.|[2409.04142v1](http://arxiv.org/abs/2409.04142v1)|null|
|**2024-09-06**|**Prompt-based Personality Profiling: Reinforcement Learning for Relevance Filtering**|Jan Hofmann et.al.|[2409.04122v1](http://arxiv.org/abs/2409.04122v1)|null|
|**2024-09-06**|**Confidence-Aware Document OCR Error Detection**|Arthur Hemmer et.al.|[2409.04117v1](http://arxiv.org/abs/2409.04117v1)|null|
|**2024-09-06**|**Multi-Programming Language Ensemble for Code Generation in Large Language Model**|Tengfei Xue et.al.|[2409.04114v1](http://arxiv.org/abs/2409.04114v1)|[link](https://github.com/ninjatech-ai/mple)|
|**2024-09-06**|**Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers**|Chenglei Si et.al.|[2409.04109v1](http://arxiv.org/abs/2409.04109v1)|null|
|**2024-09-06**|**The Role of Graph Topology in the Performance of Biomedical Knowledge Graph Completion Models**|Alberto Cattaneo et.al.|[2409.04103v1](http://arxiv.org/abs/2409.04103v1)|null|
|**2024-09-06**|**Intelligent tutoring systems by Bayesian networks with noisy gates**|Alessandro Antonucci et.al.|[2409.04102v1](http://arxiv.org/abs/2409.04102v1)|null|
|**2024-09-06**|**Structure and dynamics of growing networks of Reddit threads**|Diletta Goglia et.al.|[2409.04085v1](http://arxiv.org/abs/2409.04085v1)|[link](https://github.com/uuinfolab/Structure_and_dynamics_of_growing_networks_of_Reddit_threads)|
|**2024-09-06**|**SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation**|Yi Tian et.al.|[2409.04082v1](http://arxiv.org/abs/2409.04082v1)|[link](https://github.com/yitian97/SDformerFlow)|
|**2024-09-06**|**UI-JEPA: Towards Active Perception of User Intent through Onscreen User Activity**|Yicheng Fu et.al.|[2409.04081v1](http://arxiv.org/abs/2409.04081v1)|null|
|**2024-09-06**|**AnyMatch -- Efficient Zero-Shot Entity Matching with a Small Language Model**|Zeyu Zhang et.al.|[2409.04073v1](http://arxiv.org/abs/2409.04073v1)|null|
|**2024-09-06**|**D4: Text-guided diffusion model-based domain adaptive data augmentation for vineyard shoot detection**|Kentaro Hirahara et.al.|[2409.04060v1](http://arxiv.org/abs/2409.04060v1)|null|
|**2024-09-06**|**Self-Harmonized Chain of Thought**|Ziqi Jin et.al.|[2409.04057v1](http://arxiv.org/abs/2409.04057v1)|null|
|**2024-09-06**|**Refining Wikidata Taxonomy using Large Language Models**|Yiwen Peng et.al.|[2409.04056v1](http://arxiv.org/abs/2409.04056v1)|null|
|**2024-09-06**|**Towards Safer Online Spaces: Simulating and Assessing Intervention Strategies for Eating Disorder Discussions**|Louis Penafiel et.al.|[2409.04043v1](http://arxiv.org/abs/2409.04043v1)|null|
|**2024-09-06**|**A First Look At Efficient And Secure On-Device LLM Inference Against KV Leakage**|Huan Yang et.al.|[2409.04040v1](http://arxiv.org/abs/2409.04040v1)|null|
|**2024-09-06**|**BFA-YOLO: Balanced multiscale object detection network for multi-view building facade attachments detection**|Yangguang Chen et.al.|[2409.04025v1](http://arxiv.org/abs/2409.04025v1)|null|
|**2024-09-06**|**Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**|Miao Fan et.al.|[2409.04009v1](http://arxiv.org/abs/2409.04009v1)|null|
|**2024-09-06**|**Searching for Effective Preprocessing Method and CNN-based Architecture with Efficient Channel Attention on Speech Emotion Recognition**|Byunggun Kim et.al.|[2409.04007v1](http://arxiv.org/abs/2409.04007v1)|null|
|**2024-09-06**|**Confidential Computing on nVIDIA H100 GPU: A Performance Benchmark Study**|Jianwei Zhu et.al.|[2409.03992v1](http://arxiv.org/abs/2409.03992v1)|null|
|**2024-09-06**|**FODA-PG for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes**|Kai Shu et.al.|[2409.03947v1](http://arxiv.org/abs/2409.03947v1)|null|
|**2024-09-06**|**On The Role of Prompt Construction In Enhancing Efficacy and Efficiency of LLM-Based Tabular Data Generation**|Banooqa Banday et.al.|[2409.03946v1](http://arxiv.org/abs/2409.03946v1)|null|
|**2024-09-05**|**HUMOS: Human Motion Model Conditioned on Body Shape**|Shashank Tripathi et.al.|[2409.03944v1](http://arxiv.org/abs/2409.03944v1)|null|
|**2024-09-05**|**Experimentation in Content Moderation using RWKV**|Umut Yildirim et.al.|[2409.03939v1](http://arxiv.org/abs/2409.03939v1)|null|
|**2024-09-05**|**Harnessing LLMs for Cross-City OD Flow Prediction**|Chenyang Yu et.al.|[2409.03937v1](http://arxiv.org/abs/2409.03937v1)|null|
|**2024-09-05**|**A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application**|Esther Lagemann et.al.|[2409.03933v1](http://arxiv.org/abs/2409.03933v1)|null|
|**2024-09-05**|**The Role of Generative Systems in Historical Photography Management: A Case Study on Catalan Archives**|Èric Śanchez et.al.|[2409.03911v1](http://arxiv.org/abs/2409.03911v1)|null|
|**2024-09-05**|**CACER: Clinical Concept Annotations for Cancer Events and Relations**|Yujuan Fu et.al.|[2409.03905v1](http://arxiv.org/abs/2409.03905v1)|null|
|**2024-09-05**|**Multi-agent Path Finding for Mixed Autonomy Traffic Coordination**|Han Zheng et.al.|[2409.03881v1](http://arxiv.org/abs/2409.03881v1)|null|
|**2024-09-05**|**Sirius: Contextual Sparsity with Correction for Efficient LLMs**|Yang Zhou et.al.|[2409.03856v1](http://arxiv.org/abs/2409.03856v1)|[link](https://github.com/infini-ai-lab/sirius)|
|**2024-09-05**|**MetaBGM: Dynamic Soundtrack Transformation For Continuous Multi-Scene Experiences With Ambient Awareness And Personalization**|Haoxuan Liu et.al.|[2409.03844v1](http://arxiv.org/abs/2409.03844v1)|null|
|**2024-09-05**|**Persona Setting Pitfall: Persistent Outgroup Biases in Large Language Models Arising from Social Identity Adoption**|Wenchao Dong et.al.|[2409.03843v1](http://arxiv.org/abs/2409.03843v1)|null|
|**2024-09-05**|**AI forecasting of higher-order wave modes of spinning binary black hole mergers**|Victoria Tiki et.al.|[2409.03833v1](http://arxiv.org/abs/2409.03833v1)|null|
|**2024-09-05**|**Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding**|Yunze Man et.al.|[2409.03757v1](http://arxiv.org/abs/2409.03757v1)|[link](https://github.com/yunzeman/lexicon3d)|
|**2024-09-05**|**Attention Heads of Large Language Models: A Survey**|Zifan Zheng et.al.|[2409.03752v1](http://arxiv.org/abs/2409.03752v1)|[link](https://github.com/iaar-shanghai/awesome-attention-heads)|
|**2024-09-05**|**LLM-CI: Assessing Contextual Integrity Norms in Language Models**|Yan Shvartzshnaider et.al.|[2409.03735v1](http://arxiv.org/abs/2409.03735v1)|null|
|**2024-09-05**|**PARCO: Learning Parallel Autoregressive Policies for Efficient Multi-Agent Combinatorial Optimization**|Federico Berto et.al.|[2409.03811v1](http://arxiv.org/abs/2409.03811v1)|null|
|**2024-09-05**|**How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data**|Yejie Wang et.al.|[2409.03810v1](http://arxiv.org/abs/2409.03810v1)|null|
|**2024-09-05**|**Planning In Natural Language Improves LLM Search For Code Generation**|Evan Wang et.al.|[2409.03733v1](http://arxiv.org/abs/2409.03733v1)|null|
|**2024-09-05**|**RAG based Question-Answering for Contextual Response Prediction System**|Sriram Veturi et.al.|[2409.03708v2](http://arxiv.org/abs/2409.03708v2)|null|
|**2024-09-05**|**A Different Level Text Protection Mechanism With Differential Privacy**|Qingwen Fu et.al.|[2409.03707v1](http://arxiv.org/abs/2409.03707v1)|null|
|**2024-09-05**|**LAST: Language Model Aware Speech Tokenization**|Arnon Turetzky et.al.|[2409.03701v1](http://arxiv.org/abs/2409.03701v1)|null|
|**2024-09-05**|**View-Invariant Policy Learning via Zero-Shot Novel View Synthesis**|Stephen Tian et.al.|[2409.03685v1](http://arxiv.org/abs/2409.03685v1)|null|
|**2024-09-05**|**TRACE-cs: Trustworthy Reasoning for Contrastive Explanations in Course Scheduling Problems**|Stylianos Loukas Vasileiou et.al.|[2409.03671v1](http://arxiv.org/abs/2409.03671v1)|null|
|**2024-09-05**|**A method to benchmark high-dimensional process drift detection**|Edgar Wolf et.al.|[2409.03669v1](http://arxiv.org/abs/2409.03669v1)|[link](https://github.com/edgarwolf/driftbench)|
|**2024-09-05**|**A Fused Large Language Model for Predicting Startup Success**|Abdurahman Maarouf et.al.|[2409.03668v1](http://arxiv.org/abs/2409.03668v1)|null|
|**2024-09-05**|**The representation landscape of few-shot learning and fine-tuning in large language models**|Diego Doimo et.al.|[2409.03662v1](http://arxiv.org/abs/2409.03662v1)|[link](https://github.com/diegodoimo/geometry_icl_finetuning)|
|**2024-09-05**|**LLM-based multi-agent poetry generation in non-cooperative environments**|Ran Zhang et.al.|[2409.03659v2](http://arxiv.org/abs/2409.03659v2)|[link](https://github.com/zhangr2021/Multiagent_poetry)|
|**2024-09-05**|**On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization**|Yong Lin et.al.|[2409.03650v1](http://arxiv.org/abs/2409.03650v1)|null|
|**2024-09-05**|**Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG**|Manshan Guo et.al.|[2409.03646v1](http://arxiv.org/abs/2409.03646v1)|null|
|**2024-09-05**|**CDM: A Reliable Metric for Fair and Accurate Formula Recognition Evaluation**|Bin Wang et.al.|[2409.03643v1](http://arxiv.org/abs/2409.03643v1)|[link](https://github.com/opendatalab/unimernet)|
|**2024-09-05**|**Attend First, Consolidate Later: On the Importance of Attention in Different LLM Layers**|Amit Ben Artzy et.al.|[2409.03621v1](http://arxiv.org/abs/2409.03621v1)|null|
|**2024-09-05**|**100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances**|Lorenzo Pacchiardi et.al.|[2409.03563v1](http://arxiv.org/abs/2409.03563v1)|null|
|**2024-09-05**|**DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture**|Qianlong Xiang et.al.|[2409.03550v1](http://arxiv.org/abs/2409.03550v1)|null|
|**2024-09-05**|**Prediction Accuracy & Reliability: Classification and Object Localization under Distribution Shift**|Fabian Diet et.al.|[2409.03543v1](http://arxiv.org/abs/2409.03543v1)|null|
|**2024-09-05**|**LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution**|Jeongsoo Kim et.al.|[2409.03516v1](http://arxiv.org/abs/2409.03516v1)|[link](https://github.com/jwgdmkj/lmlt)|
|**2024-09-05**|**From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents**|Jifan Yu et.al.|[2409.03512v1](http://arxiv.org/abs/2409.03512v1)|null|
|**2024-09-05**|**Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation**|Prerak Mody et.al.|[2409.03470v1](http://arxiv.org/abs/2409.03470v1)|[link](https://github.com/prerakmody/bayesuncertainty-error-correspondence)|
|**2024-09-05**|**Characterizing Massive Activations of Attention Mechanism in Graph Neural Networks**|Lorenzo Bini et.al.|[2409.03463v1](http://arxiv.org/abs/2409.03463v1)|[link](https://github.com/msorbi/gnn-ma)|
|**2024-09-05**|**How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes**|Inacio Vieira et.al.|[2409.03454v1](http://arxiv.org/abs/2409.03454v1)|null|
|**2024-09-05**|**Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities**|Wei Lu et.al.|[2409.03444v1](http://arxiv.org/abs/2409.03444v1)|[link](https://github.com/lamm-mit/llm-finetuning)|
|**2024-09-05**|**Rx Strategist: Prescription Verification using LLM Agents System**|Phuc Phan Van et.al.|[2409.03440v1](http://arxiv.org/abs/2409.03440v1)|null|
|**2024-09-05**|**KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale**|Wei Gao et.al.|[2409.03439v1](http://arxiv.org/abs/2409.03439v1)|null|
|**2024-09-05**|**Reinforcement Learning Approach to Optimizing Profilometric Sensor Trajectories for Surface Inspection**|Sara Roos-Hoefgeest et.al.|[2409.03429v1](http://arxiv.org/abs/2409.03429v1)|null|
|**2024-09-05**|**Mpox Screen Lite: AI-Driven On-Device Offline Mpox Screening for Low-Resource African Mpox Emergency Response**|Yudara Kularathne et.al.|[2409.03806v1](http://arxiv.org/abs/2409.03806v1)|null|
|**2024-09-05**|**Game On: Towards Language Models as RL Experimenters**|Jingwei Zhang et.al.|[2409.03402v1](http://arxiv.org/abs/2409.03402v1)|null|
|**2024-09-05**|**Hardware Acceleration of LLMs: A comprehensive survey and comparison**|Nikoletta Koilia et.al.|[2409.03384v1](http://arxiv.org/abs/2409.03384v1)|null|
|**2024-09-05**|**CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks**|Yongxin Deng et.al.|[2409.03381v2](http://arxiv.org/abs/2409.03381v2)|null|
|**2024-09-05**|**Raw Speech Enhancement with Deep State Space Modeling**|Yan Ru Pei et.al.|[2409.03377v1](http://arxiv.org/abs/2409.03377v1)|[link](https://github.com/Brainchip-Inc/aTENNuate)|
|**2024-09-05**|**Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time**|Francisco de Arriba-Pérez et.al.|[2409.03375v1](http://arxiv.org/abs/2409.03375v1)|null|
|**2024-09-05**|**Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding**|Cheng Wang et.al.|[2409.03363v1](http://arxiv.org/abs/2409.03363v1)|null|
|**2024-09-05**|**Sketch: A Toolkit for Streamlining LLM Operations**|Xin Jiang et.al.|[2409.03346v1](http://arxiv.org/abs/2409.03346v1)|null|

#### Abstracts
##### **Accelerating Training with Neuron Interaction and Nowcasting Networks**
2409.04434v1 by Boris Knyazev, Abhinav Moudgil, Guillaume Lajoie, Eugene Belilovsky, Simon Lacoste-Julien

Neural network training can be accelerated when a learnable update rule is
used in lieu of classic adaptive optimizers (e.g. Adam). However, learnable
update rules can be costly and unstable to train and use. A simpler recently
proposed approach to accelerate training is to use Adam for most of the
optimization steps and periodically, only every few steps, nowcast (predict
future) parameters. We improve this approach by Neuron interaction and
Nowcasting (NiNo) networks. NiNo leverages neuron connectivity and graph neural
networks to more accurately nowcast parameters by learning in a supervised way
from a set of training trajectories over multiple tasks. We show that in some
networks, such as Transformers, neuron connectivity is non-trivial. By
accurately modeling neuron connectivity, we allow NiNo to accelerate Adam
training by up to 50\% in vision and language tasks.

摘要：神经网络训练可以加速，当一个可学习的更新规则被用来代替经典的自适应优化器（例如 Adam）。然而，可学习的更新规则可能是昂贵且不稳定的，需要训练和使用。一种最近提出的更简单的加速训练的方法是，对于大多数的优化步骤使用 Adam，并且定期地，仅每隔几步，预测（预测未来）参数。我们通过神经元交互和预测（NiNo）网络来改进这种方法。NiNo 利用神经元连接和图神经网络，通过从多个任务中的一组训练轨迹中以监督方式学习，更准确地预测参数。我们表明，在一些网络中，例如 Transformer，神经元连接是非平凡的。通过准确地建模神经元连接，我们允许 NiNo 将 Adam 训练加速高达 50%，用于视觉和语言任务。

##### **Hybrid Spiking Neural Networks for Low-Power Intra-Cortical Brain-Machine Interfaces**
2409.04428v1 by Alexandru Vasilache, Jann Krausse, Klaus Knobloch, Juergen Becker

Intra-cortical brain-machine interfaces (iBMIs) have the potential to
dramatically improve the lives of people with paraplegia by restoring their
ability to perform daily activities. However, current iBMIs suffer from
scalability and mobility limitations due to bulky hardware and wiring. Wireless
iBMIs offer a solution but are constrained by a limited data rate. To overcome
this challenge, we are investigating hybrid spiking neural networks for
embedded neural decoding in wireless iBMIs. The networks consist of a temporal
convolution-based compression followed by recurrent processing and a final
interpolation back to the original sequence length. As recurrent units, we
explore gated recurrent units (GRUs), leaky integrate-and-fire (LIF) neurons,
and a combination of both - spiking GRUs (sGRUs) and analyze their differences
in terms of accuracy, footprint, and activation sparsity. To that end, we train
decoders on the "Nonhuman Primate Reaching with Multichannel Sensorimotor
Cortex Electrophysiology" dataset and evaluate it using the NeuroBench
framework, targeting both tracks of the IEEE BioCAS Grand Challenge on Neural
Decoding. Our approach achieves high accuracy in predicting velocities of
primate reaching movements from multichannel primary motor cortex recordings
while maintaining a low number of synaptic operations, surpassing the current
baseline models in the NeuroBench framework. This work highlights the potential
of hybrid neural networks to facilitate wireless iBMIs with high decoding
precision and a substantial increase in the number of monitored neurons, paving
the way toward more advanced neuroprosthetic technologies.

摘要：腦內皮質腦機介面 (iBMI) 有可能大幅改善截癱患者的生活，讓他們恢復執行日常活動的能力。然而，目前的 iBMI 因為笨重的硬體和線路而受限於可擴充性和行動性。無線 iBMI 提供了解決方案，但受到有限資料速率的限制。為了克服這個挑戰，我們正在研究用於無線 iBMI 中嵌入式神經解碼的混合脈衝神經網路。這些網路包含時間卷積壓縮，接著是遞迴處理，最後再插值回原始序列長度。作為遞迴單元，我們探討了閘控遞迴單元 (GRU)、漏電積分與發射 (LIF) 神經元，以及兩者的組合 - 脈衝 GRU (sGRU)，並分析它們在準確度、佔用空間和激活稀疏性方面的差異。為此，我們在「多通道感覺運動皮質電生理學非人類靈長類動物觸及」資料集上訓練解碼器，並使用 NeuroBench 框架進行評估，目標是 IEEE BioCAS 神經解碼大挑戰的兩個軌道。我們的做法在預測靈長類動物從多通道初級運動皮質記錄中觸及動作的速度方面達到了很高的準確度，同時維持低數量的突觸操作，超越了 NeuroBench 框架中的現有基準模型。這項工作突顯了混合神經網路的潛力，可以促進無線 iBMI 具有高解碼精度和大幅增加監控神經元數量，為更先進的神經輔具技術鋪路。

##### **RLPF: Reinforcement Learning from Prediction Feedback for User Summarization with LLMs**
2409.04421v1 by Jiaxing Wu, Lin Ning, Luyang Liu, Harrison Lee, Neo Wu, Chao Wang, Sushant Prakash, Shawn O'Banion, Bradley Green, Jun Xie

LLM-powered personalization agent systems employ Large Language Models (LLMs)
to predict users' behavior from their past activities. However, their
effectiveness often hinges on the ability to effectively leverage extensive,
long user historical data due to its inherent noise and length of such data.
Existing pretrained LLMs may generate summaries that are concise but lack the
necessary context for downstream tasks, hindering their utility in
personalization systems. To address these challenges, we introduce
Reinforcement Learning from Prediction Feedback (RLPF). RLPF fine-tunes LLMs to
generate concise, human-readable user summaries that are optimized for
downstream task performance. By maximizing the usefulness of the generated
summaries, RLPF effectively distills extensive user history data while
preserving essential information for downstream tasks. Our empirical evaluation
demonstrates significant improvements in both extrinsic downstream task utility
and intrinsic summary quality, surpassing baseline methods by up to 22% on
downstream task performance and achieving an up to 84.59% win rate on
Factuality, Abstractiveness, and Readability. RLPF also achieves a remarkable
74% reduction in context length while improving performance on 16 out of 19
unseen tasks and/or datasets, showcasing its generalizability. This approach
offers a promising solution for enhancing LLM personalization by effectively
transforming long, noisy user histories into informative and human-readable
representations.

摘要：由 LLM 驅動的個人化代理系統採用大型語言模型 (LLM) 來根據使用者的過往活動預測其行為。然而，其有效性通常取決於有效利用廣泛、長期的使用者歷史數據的能力，因為這些數據具有內在的雜訊和長度。現有的預訓練 LLM 可能會產生簡潔但缺乏下游任務必要背景的摘要，阻礙其在個人化系統中的效用。為了應對這些挑戰，我們引入了預測回饋強化學習 (RLPF)。RLPF 微調 LLM 以產生簡潔、人類可讀的使用者摘要，這些摘要針對下游任務效能進行了最佳化。透過最大化所產生摘要的效用，RLPF 有效地提煉了廣泛的使用者歷史數據，同時保留了下游任務的必要資訊。我們的經驗評估證明，外部下游任務效用和內在摘要品質都有顯著的改善，在 Factuality、Abstractiveness 和 Readability 方面，下游任務效能超越基線方法達 22%，獲勝率達 84.59%。RLPF 還將背景長度減少了 74%，同時改善了 19 個未見任務和/或資料集中的 16 個任務的效能，展示了其泛化性。此方法提供了一個有前景的解決方案，透過有效地將冗長、雜訊的使用者歷史轉換為資訊豐富且人類可讀的表示，來增強 LLM 個人化。

##### **Open-MAGVIT2: An Open-Source Project Toward Democratizing Auto-regressive Visual Generation**
2409.04410v1 by Zhuoyan Luo, Fengyuan Shi, Yixiao Ge, Yujiu Yang, Limin Wang, Ying Shan

We present Open-MAGVIT2, a family of auto-regressive image generation models
ranging from 300M to 1.5B. The Open-MAGVIT2 project produces an open-source
replication of Google's MAGVIT-v2 tokenizer, a tokenizer with a super-large
codebook (i.e., $2^{18}$ codes), and achieves the state-of-the-art
reconstruction performance (1.17 rFID) on ImageNet $256 \times 256$.
Furthermore, we explore its application in plain auto-regressive models and
validate scalability properties. To assist auto-regressive models in predicting
with a super-large vocabulary, we factorize it into two sub-vocabulary of
different sizes by asymmetric token factorization, and further introduce "next
sub-token prediction" to enhance sub-token interaction for better generation
quality. We release all models and codes to foster innovation and creativity in
the field of auto-regressive visual generation.

摘要：我們展示 Open-MAGVIT2，一個自動迴歸影像生成模型系列，範圍從 300M 到 1.5B。Open-MAGVIT2 專案產生 Google 的 MAGVIT-v2 分詞器的開源複製，一個具有超大型碼本（即 $2^{18}$ 個碼）的分詞器，並在 ImageNet $256 \times 256$ 上達成最先進的重建效能（1.17 rFID）。此外，我們探索其在純自動迴歸模型中的應用，並驗證其可擴充性。為了協助自動迴歸模型使用超大型詞彙預測，我們透過非對稱符號分解將其分解為兩個不同大小的子詞彙，並進一步引入「下一個子符號預測」以增強子符號互動，以提升生成品質。我們釋出所有模型和程式碼，以促進自動迴歸視覺生成領域的創新和創意。

##### **Question-Answering Dense Video Events**
2409.04388v1 by Hangyu Qin, Junbin Xiao, Angela Yao

Multimodal Large Language Models (MLLMs) have shown excellent performance in
question-answering of single-event videos. In this paper, we present
question-answering dense video events, a novel task that requires answering and
grounding the dense-event questions in long videos, thus challenging MLLMs to
faithfully comprehend and reason about multiple events occurring over extended
time periods. To facilitate the study, we construct DeVE-QA - a dataset
featuring 78K questions about 26K events on 10.6K long videos. We then
benchmark and show that existing MLLMs excelling at single-event QA struggle to
perform well in DeVE-QA. For improvement, we propose DeVi, a novel
training-free MLLM approach that highlights a hierarchical captioning module, a
temporal event memory module, and a self-consistency checking module to
respectively detect, contextualize and memorize, and ground dense-events in
long videos for question answering. Extensive experiments show that DeVi is
superior at answering dense-event questions and grounding relevant video
moments. Compared with existing MLLMs, it achieves a remarkable increase of 4.1
percent and 3.7 percent for G(round)QA accuracy on DeVE-QA and NExT-GQA
respectively.

摘要：多模态大型语言模型 (MLLM) 在单事件视频的问答中表现出色。本文中，我们提出了问答密集视频事件，这是一个需要回答和依据长视频中的密集事件问题的新任务，从而挑战 MLLM 忠实地理解和推理在延长时间段内发生的多个事件。为了促进研究，我们构建了 DeVE-QA - 一个数据集，其中包含有关 10.6K 长视频中 26K 个事件的 78K 个问题。然后，我们对现有的 MLLM 进行了基准测试，并表明在单事件问答中表现出色的 MLLM 在 DeVE-QA 中难以表现良好。为了改进，我们提出了 DeVi，这是一种新颖的无训练 MLLM 方法，它突出显示了一个分层字幕模块、一个时间事件记忆模块和一个自一致性检查模块，分别用于检测、语境化和记忆，以及在长视频中依据密集事件进行问答。大量实验表明，DeVi 在回答密集事件问题和依据相关视频时刻方面表现出色。与现有的 MLLM 相比，它在 DeVE-QA 和 NExT-GQA 上的 G(round)QA 准确率分别显着提高了 4.1 个百分点和 3.7 个百分点。

##### **Empirical Bayesian image restoration by Langevin sampling with a denoising diffusion implicit prior**
2409.04384v1 by Charlesquin Kemajou Mbakam, Jean-Francois Giovannelli, Marcelo Pereyra

Score-based diffusion methods provide a powerful strategy to solve image
restoration tasks by flexibly combining a pre-trained foundational prior model
with a likelihood function specified during test time. Such methods are
predominantly derived from two stochastic processes: reversing
Ornstein-Uhlenbeck, which underpins the celebrated denoising diffusion
probabilistic models (DDPM) and denoising diffusion implicit models (DDIM), and
the Langevin diffusion process. The solutions delivered by DDPM and DDIM are
often remarkably realistic, but they are not always consistent with
measurements because of likelihood intractability issues and the associated
required approximations. Alternatively, using a Langevin process circumvents
the intractable likelihood issue, but usually leads to restoration results of
inferior quality and longer computing times. This paper presents a novel and
highly computationally efficient image restoration method that carefully embeds
a foundational DDPM denoiser within an empirical Bayesian Langevin algorithm,
which jointly calibrates key model hyper-parameters as it estimates the model's
posterior mean. Extensive experimental results on three canonical tasks (image
deblurring, super-resolution, and inpainting) demonstrate that the proposed
approach improves on state-of-the-art strategies both in image estimation
accuracy and computing time.

摘要：基於分數的擴散方法提供了一個強大的策略來解決影像修復任務，方法是靈活地結合預先訓練好的基礎先驗模型與在測試時間指定的可能性函數。此類方法主要源自兩個隨機過程：反轉奧恩斯坦-烏倫貝克，它支撐了著名的去噪擴散機率模型 (DDPM) 和去噪擴散隱式模型 (DDIM)，以及朗之萬擴散過程。DDPM 和 DDIM 提供的解決方案通常非常逼真，但由於可能性難解問題和相關的必要近似值，它們並不總是與測量結果一致。或者，使用朗之萬過程可以避開難解的可能性問題，但通常會導致較差的修復結果和更長的運算時間。本文提出了一種新穎且高度計算效率的影像修復方法，該方法仔細地將基礎 DDPM 去噪器嵌入經驗貝氏朗之萬演算法中，該演算法在估計模型後驗平均值的同時共同校準關鍵模型超參數。在三個典型任務（影像去模糊、超解析度和內插）上的大量實驗結果證明，所提出的方法在影像估計準確度和運算時間方面都優於最先進的策略。

##### **The Impact of Scanner Domain Shift on Deep Learning Performance in Medical Imaging: an Experimental Study**
2409.04368v1 by Gregory Szumel, Brian Guo, Darui Lu, Rongze Gui, Tingyu Wang, Nicholas Konz, Maciej A. Mazurowski

Purpose: Medical images acquired using different scanners and protocols can
differ substantially in their appearance. This phenomenon, scanner domain
shift, can result in a drop in the performance of deep neural networks which
are trained on data acquired by one scanner and tested on another. This
significant practical issue is well-acknowledged, however, no systematic study
of the issue is available across different modalities and diagnostic tasks.
Materials and Methods: In this paper, we present a broad experimental study
evaluating the impact of scanner domain shift on convolutional neural network
performance for different automated diagnostic tasks. We evaluate this
phenomenon in common radiological modalities, including X-ray, CT, and MRI.
Results: We find that network performance on data from a different scanner is
almost always worse than on same-scanner data, and we quantify the degree of
performance drop across different datasets. Notably, we find that this drop is
most severe for MRI, moderate for X-ray, and quite small for CT, on average,
which we attribute to the standardized nature of CT acquisition systems which
is not present in MRI or X-ray. We also study how injecting varying amounts of
target domain data into the training set, as well as adding noise to the
training data, helps with generalization. Conclusion: Our results provide
extensive experimental evidence and quantification of the extent of performance
drop caused by scanner domain shift in deep learning across different
modalities, with the goal of guiding the future development of robust deep
learning models for medical image analysis.

摘要：<paragraph>目的：使用不同掃描儀和協定取得的醫學影像，在影像外觀上可能會有顯著差異。這種現象稱為掃描儀領域偏移，可能會導致深度神經網路的效能下降，而這些網路是針對由一種掃描儀取得的資料進行訓練，並在另一種掃描儀上進行測試。這個重要的實際問題已獲得廣泛認可，但目前尚未針對不同形式和診斷任務進行系統性研究。材料和方法：在本文中，我們提出了一項廣泛的實驗研究，評估掃描儀領域偏移對不同自動化診斷任務的卷積神經網路效能的影響。我們在常見的放射學形式中評估這種現象，包括 X 光、電腦斷層掃描和磁振造影。結果：我們發現，來自不同掃描儀的資料在網路上的效能幾乎總是比來自相同掃描儀的資料差，我們量化了不同資料集效能下降的程度。值得注意的是，我們發現這種下降在磁振造影中最为嚴重，在 X 光中為中等，在電腦斷層掃描中相當小，平均而言，我們將其歸因於電腦斷層掃描取得系統的標準化性質，而磁振造影或 X 光中不存在這種性質。我們還研究了將不同數量的目標領域資料注入訓練集，以及向訓練資料加入雜訊，如何有助於泛化。結論：我們的結果提供了廣泛的實驗證據，並量化了深度學習中由掃描儀領域偏移造成的效能下降程度，目標是引導未來針對醫學影像分析的強健深度學習模型的發展。</paragraph>

##### **Connectivity-Inspired Network for Context-Aware Recognition**
2409.04360v1 by Gianluca Carloni, Sara Colantonio

The aim of this paper is threefold. We inform the AI practitioner about the
human visual system with an extensive literature review; we propose a novel
biologically motivated neural network for image classification; and, finally,
we present a new plug-and-play module to model context awareness. We focus on
the effect of incorporating circuit motifs found in biological brains to
address visual recognition. Our convolutional architecture is inspired by the
connectivity of human cortical and subcortical streams, and we implement
bottom-up and top-down modulations that mimic the extensive afferent and
efferent connections between visual and cognitive areas. Our Contextual
Attention Block is simple and effective and can be integrated with any
feed-forward neural network. It infers weights that multiply the feature maps
according to their causal influence on the scene, modeling the co-occurrence of
different objects in the image. We place our module at different bottlenecks to
infuse a hierarchical context awareness into the model. We validated our
proposals through image classification experiments on benchmark data and found
a consistent improvement in performance and the robustness of the produced
explanations via class activation. Our code is available at
https://github.com/gianlucarloni/CoCoReco.

摘要：這篇論文的目標有三。我們透過廣泛的文獻回顧，讓 AI 從業者了解人類視覺系統；我們提出一個新的受生物啟發的神經網路進行影像分類；最後，我們提出一個新的即插即用模組，用於模擬情境感知。我們專注於加入在生物大腦中發現的電路基序，以解決視覺辨識問題。我們的卷積架構受到人類皮質和皮質下迴路的連接啟發，我們實作了自下而上和自上而下的調變，模擬視覺和認知區域之間廣泛的傳入和傳出連接。我們的脈絡注意力區塊簡單有效，可以與任何前饋神經網路整合。它推論出權重，根據特徵圖對場景的因果影響來乘以這些特徵圖，模擬影像中不同物件的共現。我們將模組放在不同的瓶頸，將階層式情境感知注入模型中。我們透過基準資料上的影像分類實驗驗證了我們的提案，發現透過類別活化，效能和產生的解釋的穩健性都有顯著的改善。我們的程式碼可在 https://github.com/gianlucarloni/CoCoReco 取得。

##### **AGR: Age Group fairness Reward for Bias Mitigation in LLMs**
2409.04340v1 by Shuirong Cao, Ruoxi Cheng, Zhiqiang Wang

LLMs can exhibit age biases, resulting in unequal treatment of individuals
across age groups. While much research has addressed racial and gender biases,
age bias remains little explored. The scarcity of instruction-tuning and
preference datasets for age bias hampers its detection and measurement, and
existing fine-tuning methods seldom address age-related fairness. In this
paper, we construct age bias preference datasets and instruction-tuning
datasets for RLHF. We introduce ARG, an age fairness reward to reduce
differences in the response quality of LLMs across different age groups.
Extensive experiments demonstrate that this reward significantly improves
response accuracy and reduces performance disparities across age groups. Our
source code and datasets are available at the anonymous
\href{https://anonymous.4open.science/r/FairRLHF-D445/readme.md}{link}.

摘要：大型語言模型可能會表現出年齡偏見，導致不同年齡組別的個人受到不平等的待遇。雖然許多研究已探討種族和性別偏見，但年齡偏見仍鮮少被探討。年齡偏見的指示微調和偏好資料集的稀少阻礙了其偵測和測量，而現有的微調方法很少探討與年齡相關的公平性。在本文中，我們建構了年齡偏見偏好資料集和 RLHF 的指示微調資料集。我們引入了 ARG，一種年齡公平獎勵，以減少不同年齡組別中 LLM 回應品質的差異。廣泛的實驗證明，此獎勵顯著提升了回應準確度，並減少了不同年齡組別之間的效能差異。我們的原始程式碼和資料集可在匿名連結取得：
\href{https://anonymous.4open.science/r/FairRLHF-D445/readme.md}{link}。

##### **Learning vs Retrieval: The Role of In-Context Examples in Regression with LLMs**
2409.04318v1 by Aliakbar Nafar, Kristen Brent Venable, Parisa Kordjamshidi

Generative Large Language Models (LLMs) are capable of being in-context
learners. However, the underlying mechanism of in-context learning (ICL) is
still a major research question, and experimental research results about how
models exploit ICL are not always consistent. In this work, we propose a
framework for evaluating in-context learning mechanisms, which we claim are a
combination of retrieving internal knowledge and learning from in-context
examples by focusing on regression tasks. First, we show that LLMs can perform
regression on real-world datasets and then design experiments to measure the
extent to which the LLM retrieves its internal knowledge versus learning from
in-context examples. We argue that this process lies on a spectrum between
these two extremes. We provide an in-depth analysis of the degrees to which
these mechanisms are triggered depending on various factors, such as prior
knowledge about the tasks and the type and richness of the information provided
by the in-context examples. We employ three LLMs and utilize multiple datasets
to corroborate the robustness of our findings. Our results shed light on how to
engineer prompts to leverage meta-learning from in-context examples and foster
knowledge retrieval depending on the problem being addressed.

摘要：生成式大型语言模型 (LLM) 能够成为情境中的学习者。然而，情境中学习 (ICL) 的底层机制仍然是重要的研究问题，关于模型如何利用 ICL 的实验研究结果并不总是一致的。在这项工作中，我们提出了一个用于评估情境中学习机制的框架，我们声称这是一种通过专注于回归任务来检索内部知识和从情境中示例中学习的组合。首先，我们表明 LLM 可以在现实世界的数据集上执行回归，然后设计实验来测量 LLM 从情境中示例中检索其内部知识与学习的程度。我们认为这个过程介于这两个极端之间的某个范围内。我们对这些机制在多大程度上被触发进行了深入分析，这取决于各种因素，例如关于任务的先验知识以及情境中示例提供的信息的类型和丰富程度。我们采用三个 LLM 并利用多个数据集来证实我们研究结果的稳健性。我们的结果阐明了如何设计提示，以利用情境中示例中的元学习，并根据要解决的问题促进知识检索。

##### **CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis**
2409.04290v1 by William Knottenbelt, Zeyu Gao, Rebecca Wray, Woody Zhidong Zhang, Jiashuai Liu, Mireia Crispin-Ortuzar

Survival analysis is a branch of statistics used for modeling the time until
a specific event occurs and is widely used in medicine, engineering, finance,
and many other fields. When choosing survival models, there is typically a
trade-off between performance and interpretability, where the highest
performance is achieved by black-box models based on deep learning. This is a
major problem in fields such as medicine where practitioners are reluctant to
blindly trust black-box models to make important patient decisions.
Kolmogorov-Arnold Networks (KANs) were recently proposed as an interpretable
and accurate alternative to multi-layer perceptrons (MLPs). We introduce
CoxKAN, a Cox proportional hazards Kolmogorov-Arnold Network for interpretable,
high-performance survival analysis. We evaluate the proposed CoxKAN on 4
synthetic datasets and 9 real medical datasets. The synthetic experiments
demonstrate that CoxKAN accurately recovers interpretable symbolic formulae for
the hazard function, and effectively performs automatic feature selection.
Evaluation on the 9 real datasets show that CoxKAN consistently outperforms the
Cox proportional hazards model and achieves performance that is superior or
comparable to that of tuned MLPs. Furthermore, we find that CoxKAN identifies
complex interactions between predictor variables that would be extremely
difficult to recognise using existing survival methods, and automatically finds
symbolic formulae which uncover the precise effect of important biomarkers on
patient risk.

摘要：生存分析是統計學的一個分支，用於建模特定事件發生的時間，並廣泛用於醫學、工程、金融和許多其他領域。在選擇生存模型時，通常在性能和可解釋性之間進行權衡，其中最高性能是由基於深度學習的黑盒模型實現的。這在醫學等領域是一個主要問題，因為從業者不願意盲目信任黑盒模型來做出重要的患者決策。Kolmogorov-阿諾德網絡 (KAN) 最近被提議作為多層感知器 (MLP) 的可解釋且準確的替代方案。我們引入了 CoxKAN，這是一個用於可解釋、高性能生存分析的 Cox 比例風險 Kolmogorov-Arnold 網絡。我們在 4 個合成數據集和 9 個真實醫療數據集上評估了所提出的 CoxKAN。合成實驗表明，CoxKAN 準確地恢復了風險函數的可解釋符號公式，並有效地執行自動特徵選擇。對 9 個真實數據集的評估表明，CoxKAN 始終優於 Cox 比例風險模型，並且達到了優於或與調整後的 MLP 相當的性能。此外，我們發現 CoxKAN 識別了預測變量之間的複雜交互作用，這些交互作用使用現有的生存方法極難識別，並自動找到揭示重要生物標誌物對患者風險的準確影響的符號公式。

##### **Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**
2409.04286v1 by Desiree Heim, Christian Jilek, Adrian Ulges, Andreas Dengel

Current publicly available knowledge work data collections lack diversity,
extensive annotations, and contextual information about the users and their
documents. These issues hinder objective and comparable data-driven evaluations
and optimizations of knowledge work assistance systems. Due to the considerable
resources needed to collect such data in real-life settings and the necessity
of data censorship, collecting such a dataset appears nearly impossible. For
this reason, we propose a configurable, multi-agent knowledge work dataset
generator. This system simulates collaborative knowledge work among agents
producing Large Language Model-generated documents and accompanying data
traces. Additionally, the generator captures all background information, given
in its configuration or created during the simulation process, in a knowledge
graph. Finally, the resulting dataset can be utilized and shared without
privacy or confidentiality concerns.
  This paper introduces our approach's design and vision and focuses on
generating authentic knowledge work documents using Large Language Models. Our
study involving human raters who assessed 53% of the generated and 74% of the
real documents as realistic demonstrates the potential of our approach.
Furthermore, we analyze the authenticity criteria mentioned in the
participants' comments and elaborate on potential improvements for identified
common issues.

摘要：<paragraph>目前公開可用的知識工作資料蒐集缺乏多元性、廣泛註解和使用者及其文件背景資訊。這些問題阻礙了客觀且可比較的資料驅動評估，以及知識工作協助系統的最佳化。由於在現實生活中蒐集此類資料需要大量資源，而且必須審查資料，蒐集此類資料組顯然幾乎不可能。因此，我們提出一個可設定的多重代理知識工作資料組產生器。此系統模擬代理之間的協作知識工作，產生大型語言模型產生的文件和隨附的資料追蹤。此外，產生器會擷取所有背景資訊，在組態中提供或在模擬過程中建立，並將其儲存在知識圖譜中。最後，產生的資料組可以使用和分享，無須擔心隱私或機密性。
本文介紹我們方法的設計和願景，並專注於使用大型語言模型產生真實的知識工作文件。我們的研究涉及人類評分員，他們評估了 53% 的產生文件和 74% 的真實文件為真實，這證明了我們方法的潛力。此外，我們分析參與者評論中提到的真實性標準，並詳細說明已識別常見問題的潛在改善方法。</paragraph>

##### **Cycle Pixel Difference Network for Crisp Edge Detection**
2409.04272v1 by Changsong Liu, Wei Zhang, Yanyan Liu, Mingyang Li, Wenlin Li, Yimeng Fan, Xiangnan Bai, Liang Zhangd

Edge detection, as a fundamental task in computer vision, has garnered
increasing attention. The advent of deep learning has significantly advanced
this field. However, recent deep learning-based methods which rely on
large-scale pre-trained weights cannot be trained from scratch, with very
limited research addressing this issue. This paper proposes a novel cycle pixel
difference convolution (CPDC), which effectively integrates image gradient
information with modern convolution operations. Based on the CPDC, we develop a
U-shape encoder-decoder model named CPD-Net, which is a purely end-to-end
network. Additionally, to address the issue of edge thickness produced by most
existing methods, we construct a multi-scale information enhancement module
(MSEM) to enhance the discriminative ability of the model, thereby generating
crisp and clean contour maps. Comprehensive experiments conducted on three
standard benchmarks demonstrate that our method achieves competitive
performance on the BSDS500 dataset (ODS=0.813), NYUD-V2 (ODS=0.760), and BIPED
dataset (ODS=0.898). Our approach provides a novel perspective for addressing
these challenges in edge detection.

摘要：邊緣檢測作為電腦視覺中的一項基本任務，已獲得越來越多的關注。深度學習的出現顯著推動了這一領域的發展。然而，依賴於大規模預訓練權重的近期深度學習方法無法從頭開始訓練，而針對此問題的研究非常有限。本文提出了一種新穎的循環像素差分卷積 (CPDC)，它有效地將圖像梯度資訊與現代卷積運算整合在一起。基於 CPDC，我們開發了一個名為 CPD-Net 的 U 形編碼器-解碼器模型，它是一個純粹的端到端網路。此外，為了解決大多數現有方法產生的邊緣粗細問題，我們構建了一個多尺度資訊增強模組 (MSEM) 來增強模型的辨別能力，從而生成清晰乾淨的輪廓圖。在三個標準基準上進行的綜合實驗表明，我們的模型在 BSDS500 資料集 (ODS=0.813)、NYUD-V2 (ODS=0.760) 和 BIPED 資料集 (ODS=0.898) 上取得了有競爭力的效能。我們的模型為解決邊緣檢測中的這些挑戰提供了一個新的視角。

##### **Open Language Data Initiative: Advancing Low-Resource Machine Translation for Karakalpak**
2409.04269v1 by Mukhammadsaid Mamasaidov, Abror Shopulatov

This study presents several contributions for the Karakalpak language: a
FLORES+ devtest dataset translated to Karakalpak, parallel corpora for
Uzbek-Karakalpak, Russian-Karakalpak and English-Karakalpak of 100,000 pairs
each and open-sourced fine-tuned neural models for translation across these
languages. Our experiments compare different model variants and training
approaches, demonstrating improvements over existing baselines. This work,
conducted as part of the Open Language Data Initiative (OLDI) shared task, aims
to advance machine translation capabilities for Karakalpak and contribute to
expanding linguistic diversity in NLP technologies.

摘要：本研究為卡拉卡爾帕克語提供了數項貢獻：一個翻譯成卡拉卡爾帕克語的 FLORES+ devtest 資料集、烏茲別克語-卡拉卡爾帕克語、俄語-卡拉卡爾帕克語和英語-卡拉卡爾帕克語的平行語料庫，每個語料庫包含 100,000 對句子，以及針對這些語言翻譯進行微調的開源神經網路模型。我們的實驗比較了不同的模型變體和訓練方法，證明了對現有基準的改進。這項工作作為開放語言資料倡議 (OLDI) 共享任務的一部分進行，旨在提升卡拉卡爾帕克語的機器翻譯能力，並為擴展自然語言處理技術中的語言多樣性做出貢獻。

##### **An overview of domain-specific foundation model: key technologies, applications and challenges**
2409.04267v1 by Haolong Chen, Hanzhi Chen, Zijian Zhao, Kaifeng Han, Guangxu Zhu, Yichen Zhao, Ying Du, Wei Xu, Qingjiang Shi

The impressive performance of ChatGPT and other foundation-model-based
products in human language understanding has prompted both academia and
industry to explore how these models can be tailored for specific industries
and application scenarios. This process, known as the customization of
domain-specific foundation models, addresses the limitations of general-purpose
models, which may not fully capture the unique patterns and requirements of
domain-specific data. Despite its importance, there is a notable lack of
comprehensive overview papers on building domain-specific foundation models,
while numerous resources exist for general-purpose models. To bridge this gap,
this article provides a timely and thorough overview of the methodology for
customizing domain-specific foundation models. It introduces basic concepts,
outlines the general architecture, and surveys key methods for constructing
domain-specific models. Furthermore, the article discusses various domains that
can benefit from these specialized models and highlights the challenges ahead.
Through this overview, we aim to offer valuable guidance and reference for
researchers and practitioners from diverse fields to develop their own
customized foundation models.

摘要：ChatGPT 等大型語言模型在人類語言理解上的出色表現，促使學術界和產業探索如何針對特定產業和應用場景調整這些模型。此程序稱為特定領域基礎模型的客製化，用於解決通用模型的限制，這些模型可能無法完全掌握特定領域資料的獨特模式和需求。儘管其重要性，但對於建立特定領域基礎模型的全面綜述論文卻明顯不足，而針對通用模型卻有許多資源。為了彌補這個差距，本文針對客製化特定領域基礎模型的方法論提供及時且全面的綜述。本文介紹基本概念、概述一般架構，並調查建構特定領域模型的主要方法。此外，本文探討了各種可以從這些專用模型中受益的領域，並強調未來的挑戰。透過此綜述，我們旨在為來自不同領域的研究人員和從業人員提供有價值的指導和參考，以開發他們自己的客製化基礎模型。

##### **Hermes: Memory-Efficient Pipeline Inference for Large Models on Edge Devices**
2409.04249v1 by Xueyuan Han, Zinuo Cai, Yichu Zhang, Chongxin Fan, Junhan Liu, Ruhui Ma, Rajkumar Buyya

The application of Transformer-based large models has achieved numerous
success in recent years. However, the exponential growth in the parameters of
large models introduces formidable memory challenge for edge deployment. Prior
works to address this challenge mainly focus on optimizing the model structure
and adopting memory swapping methods. However, the former reduces the inference
accuracy, and the latter raises the inference latency. This paper introduces
PIPELOAD, a novel memory-efficient pipeline execution mechanism. It reduces
memory usage by incorporating dynamic memory management and minimizes inference
latency by employing parallel model loading. Based on PIPELOAD mechanism, we
present Hermes, a framework optimized for large model inference on edge
devices. We evaluate Hermes on Transformer-based models of different sizes. Our
experiments illustrate that Hermes achieves up to 4.24 X increase in inference
speed and 86.7% lower memory consumption than the state-of-the-art pipeline
mechanism for BERT and ViT models, 2.58 X increase in inference speed and 90.3%
lower memory consumption for GPT-style models.

摘要：近年來，基於 Transformer 的大型模型應用已取得許多成功。然而，大型模型引數的指數成長為邊緣部署帶來了嚴峻的記憶體挑戰。先前針對此挑戰的解決方案主要專注於最佳化模型結構和採用記憶體交換方法。但是，前者會降低推論準確度，而後者會增加推論延遲。本文介紹 PIPELOAD，一種新穎的省記憶體管道執行機制。它透過整合動態記憶體管理來減少記憶體使用量，並透過採用平行模型載入來最小化推論延遲。基於 PIPELOAD 機制，我們提出 Hermes，一個針對邊緣裝置上的大型模型推論最佳化的框架。我們在不同大小的基於 Transformer 的模型上評估 Hermes。我們的實驗表明，對於 BERT 和 ViT 模型，Hermes 的推論速度提高了 4.24 倍，記憶體消耗降低了 86.7%，而對於 GPT 類型的模型，推論速度提高了 2.58 倍，記憶體消耗降低了 90.3%，優於現有最先進的管道機制。

##### **WarpAdam: A new Adam optimizer based on Meta-Learning approach**
2409.04244v1 by Chengxi Pan, Junshang Chen, Jingrui Ye

Optimal selection of optimization algorithms is crucial for training deep
learning models. The Adam optimizer has gained significant attention due to its
efficiency and wide applicability. However, to enhance the adaptability of
optimizers across diverse datasets, we propose an innovative optimization
strategy by integrating the 'warped gradient descend'concept from Meta Learning
into the Adam optimizer. In the conventional Adam optimizer, gradients are
utilized to compute estimates of gradient mean and variance, subsequently
updating model parameters. Our approach introduces a learnable distortion
matrix, denoted as P, which is employed for linearly transforming gradients.
This transformation slightly adjusts gradients during each iteration, enabling
the optimizer to better adapt to distinct dataset characteristics. By learning
an appropriate distortion matrix P, our method aims to adaptively adjust
gradient information across different data distributions, thereby enhancing
optimization performance. Our research showcases the potential of this novel
approach through theoretical insights and empirical evaluations. Experimental
results across various tasks and datasets validate the superiority of our
optimizer that integrates the 'warped gradient descend' concept in terms of
adaptability. Furthermore, we explore effective strategies for training the
adaptation matrix P and identify scenarios where this method can yield optimal
results. In summary, this study introduces an innovative approach that merges
the 'warped gradient descend' concept from Meta Learning with the Adam
optimizer. By introducing a learnable distortion matrix P within the optimizer,
we aim to enhance the model's generalization capability across diverse data
distributions, thus opening up new possibilities in the field of deep learning
optimization.

摘要：優化演算法的最佳選擇對於訓練深度學習模型至關重要。Adam 優化器因為其效率和廣泛的適用性而備受關注。然而，為了增強優化器在不同資料集中的適應性，我們提出了一種創新的最佳化策略，將元學習中的「扭曲梯度下降」概念整合到 Adam 優化器中。在傳統的 Adam 優化器中，梯度用於計算梯度平均值和變異數的估計值，然後更新模型參數。我們的做法引入了一個可學習的扭曲矩陣，表示為 P，用於線性轉換梯度。此轉換在每次迭代過程中微調梯度，使優化器能夠更好地適應不同的資料集特徵。通過學習適當的扭曲矩陣 P，我們的方法旨在適應性地調整不同資料分佈中的梯度資訊，從而增強最佳化效能。我們的研究透過理論見解和實證評估展示了這種新方法的潛力。各種任務和資料集的實驗結果驗證了我們整合「扭曲梯度下降」概念的優化器的適應性優越性。此外，我們探討了訓練適應矩陣 P 的有效策略，並找出此方法可以產生最佳結果的情境。總之，本研究介紹了一種創新的方法，將元學習中的「扭曲梯度下降」概念與 Adam 優化器合併。透過在優化器中引入可學習的扭曲矩陣 P，我們旨在增強模型在不同資料分佈中的泛化能力，從而為深度學習最佳化領域開啟新的可能性。

##### **Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework**
2409.04224v1 by Daniel J. Tan, Qianyi Xu, Kay Choong See, Dilruk Perera, Mengling Feng

Multi-organ diseases present significant challenges due to their simultaneous
impact on multiple organ systems, necessitating complex and adaptive treatment
strategies. Despite recent advancements in AI-powered healthcare decision
support systems, existing solutions are limited to individual organ systems.
They often ignore the intricate dependencies between organ system and thereby
fails to provide holistic treatment recommendations that are useful in
practice. We propose a novel hierarchical multi-agent reinforcement learning
(HMARL) framework to address these challenges. This framework uses dedicated
agents for each organ system, and model dynamic through explicit inter-agent
communication channels, enabling coordinated treatment strategies across
organs. Furthermore, we introduce a dual-layer state representation technique
to contextualize patient conditions at various hierarchical levels, enhancing
the treatment accuracy and relevance. Through extensive qualitative and
quantitative evaluations in managing sepsis (a complex multi-organ disease),
our approach demonstrates its ability to learn effective treatment policies
that significantly improve patient survival rates. This framework marks a
substantial advancement in clinical decision support systems, pioneering a
comprehensive approach for multi-organ treatment recommendations.

摘要：多器官疾病由於同時影響多個器官系統，因此會帶來重大的挑戰，需要複雜且具有適應性的治療策略。儘管 AI 驅動的醫療保健決策支援系統最近有進展，但現有解決方案僅限於個別器官系統。它們常常忽略器官系統之間的複雜依賴性，因此無法提供實務上有用的整體治療建議。我們提出一個新穎的分層多智能體強化學習 (HMARL) 架構來解決這些挑戰。此架構為每個器官系統使用專用智能體，並透過明確的智能體間通訊管道建模動態，讓不同器官之間的治療策略能夠協調。此外，我們引入雙層狀態表示技術，在各種層級語境化病患狀況，以提升治療準確性和相關性。透過在敗血症（一種複雜的多器官疾病）管理中進行廣泛的定性和定量評估，我們的做法展示了它學習有效治療政策的能力，可顯著改善病患存活率。此架構標誌著臨床決策支援系統的一大進步，開創了多器官治療建議的全面性方法。

##### **Fast Forwarding Low-Rank Training**
2409.04206v1 by Adir Rahamim, Naomi Saphra, Sara Kangaslahti, Yonatan Belinkov

Parameter efficient finetuning methods like low-rank adaptation (LoRA) aim to
reduce the computational costs of finetuning pretrained Language Models (LMs).
Enabled by these low-rank settings, we propose an even more efficient
optimization strategy: Fast Forward, a simple and effective approach to
accelerate large segments of training. In a Fast Forward stage, we repeat the
most recent optimizer step until the loss stops improving on a tiny validation
set. By alternating between regular optimization steps and Fast Forward stages,
Fast Forward provides up to an 87\% reduction in FLOPs and up to an 81\%
reduction in train time over standard SGD with Adam. We validate Fast Forward
by finetuning various models on different tasks and demonstrate that it speeds
up training without compromising model performance. Additionally, we analyze
when and how to apply Fast Forward.

摘要：參數高效微調方法，例如低階改編 (LoRA)，旨在降低預訓練語言模型 (LM) 微調的計算成本。在這些低階設定的加持下，我們提出更有效率的最佳化策略：快轉，一種加速大部分訓練的簡單有效方法。在快轉階段，我們重複最近的最佳化步驟，直到損失在微小的驗證集中停止改善。透過在一般最佳化步驟和快轉階段之間交替，快轉可提供高達 87% 的 FLOP 減少量，以及高達 81% 的訓練時間減少量，優於使用 Adam 的標準 SGD。我們透過在不同任務上微調各種模型來驗證快轉，並證明它能在不損害模型效能的情況下加速訓練。此外，我們分析何時以及如何應用快轉。

##### **GST: Precise 3D Human Body from a Single Image with Gaussian Splatting Transformers**
2409.04196v1 by Lorenza Prospero, Abdullah Hamdi, Joao F. Henriques, Christian Rupprecht

Reconstructing realistic 3D human models from monocular images has
significant applications in creative industries, human-computer interfaces, and
healthcare. We base our work on 3D Gaussian Splatting (3DGS), a scene
representation composed of a mixture of Gaussians. Predicting such mixtures for
a human from a single input image is challenging, as it is a non-uniform
density (with a many-to-one relationship with input pixels) with strict
physical constraints. At the same time, it needs to be flexible to accommodate
a variety of clothes and poses. Our key observation is that the vertices of
standardized human meshes (such as SMPL) can provide an adequate density and
approximate initial position for Gaussians. We can then train a transformer
model to jointly predict comparatively small adjustments to these positions, as
well as the other Gaussians' attributes and the SMPL parameters. We show
empirically that this combination (using only multi-view supervision) can
achieve fast inference of 3D human models from a single image without test-time
optimization, expensive diffusion models, or 3D points supervision. We also
show that it can improve 3D pose estimation by better fitting human models that
account for clothes and other variations. The code is available on the project
website https://abdullahamdi.com/gst/ .

摘要：從單眼影像重建逼真的 3D 人體模型在創意產業、人機介面和醫療保健領域有重要的應用。我們的研究基於 3D 高斯點繪製 (3DGS)，這是一種由高斯混合組成的場景表示。從單一輸入影像預測人類的這種混合物具有挑戰性，因為它是一種非均勻密度（與輸入像素呈多對一關係），且具有嚴格的物理約束。同時，它需要靈活地適應各種服裝和姿勢。我們的關鍵觀察是標準化人體網格（例如 SMPL）的頂點可以提供適當的密度和高斯近似初始位置。然後，我們可以訓練一個Transformer模型來聯合預測這些位置的相對較小調整，以及其他高斯的屬性和 SMPL 參數。我們以實證方式表明，這種組合（僅使用多視圖監督）可以在沒有測試時優化、昂貴的擴散模型或 3D 點監督的情況下，從單一影像快速推論 3D 人體模型。我們還表明，它可以通過更好地擬合考量服裝和其他變化的 3D 人體模型來改善 3D 姿勢估計。程式碼可在專案網站 https://abdullahamdi.com/gst/ 取得。

##### **Towards Privacy-Preserving Relational Data Synthesis via Probabilistic Relational Models**
2409.04194v1 by Malte Luttermann, Ralf Möller, Mattis Hartwig

Probabilistic relational models provide a well-established formalism to
combine first-order logic and probabilistic models, thereby allowing to
represent relationships between objects in a relational domain. At the same
time, the field of artificial intelligence requires increasingly large amounts
of relational training data for various machine learning tasks. Collecting
real-world data, however, is often challenging due to privacy concerns, data
protection regulations, high costs, and so on. To mitigate these challenges,
the generation of synthetic data is a promising approach. In this paper, we
solve the problem of generating synthetic relational data via probabilistic
relational models. In particular, we propose a fully-fledged pipeline to go
from relational database to probabilistic relational model, which can then be
used to sample new synthetic relational data points from its underlying
probability distribution. As part of our proposed pipeline, we introduce a
learning algorithm to construct a probabilistic relational model from a given
relational database.

摘要：機率關係模型提供了完善的形式化，可以結合一階邏輯和機率模型，從而表示關係領域中物件之間的關係。同時，人工智慧領域需要越來越大量的關係訓練資料，以供各種機器學習任務使用。然而，收集真實世界的資料通常很具挑戰性，原因在於隱私疑慮、資料保護法規、高成本等因素。為了緩解這些挑戰，生成合成資料是一種很有前景的方法。在本文中，我們解決了透過機率關係模型生成合成關係資料的問題。具體來說，我們提出了一個完整的管道，從關係資料庫到機率關係模型，然後可以使用該模型從其底層機率分佈中抽取新的合成關係資料點。作為我們提出的管道的一部分，我們引入了一個學習演算法，從給定的關係資料庫中建構機率關係模型。

##### **Residual Stream Analysis with Multi-Layer SAEs**
2409.04185v1 by Tim Lawson, Lucy Farnik, Conor Houghton, Laurence Aitchison

Sparse autoencoders (SAEs) are a promising approach to interpreting the
internal representations of transformer language models. However, standard SAEs
are trained separately on each transformer layer, making it difficult to use
them to study how information flows across layers. To solve this problem, we
introduce the multi-layer SAE (MLSAE): a single SAE trained on the residual
stream activation vectors from every transformer layer simultaneously. The
residual stream is usually understood as preserving information across layers,
so we expected to, and did, find individual SAE features that are active at
multiple layers. Interestingly, while a single SAE feature is active at
different layers for different prompts, for a single prompt, we find that a
single feature is far more likely to be active at a single layer. For larger
underlying models, we find that the cosine similarities between adjacent layers
in the residual stream are higher, so we expect more features to be active at
multiple layers. These results show that MLSAEs are a promising method to study
information flow in transformers. We release our code to train and analyze
MLSAEs at https://github.com/tim-lawson/mlsae.

摘要：稀疏自動編碼器 (SAE) 是一種解釋Transformer語言模型內部表示的有前景方法。然而，標準 SAE 在每個Transformer層上分開訓練，這使得使用它們來研究資訊如何在層之間流動變得困難。為了解決這個問題，我們引入了多層 SAE (MLSAE)：一個同時在每個Transformer層的殘差串流啟用向量上訓練的單一 SAE。殘差串流通常被理解為跨層保留資訊，因此我們預期會找到，而且確實找到了，在多個層上都處於活動狀態的個別 SAE 特徵。有趣的是，儘管對於不同的提示，單一 SAE 特徵在不同的層上處於活動狀態，但對於單一提示，我們發現單一特徵在單一層上處於活動狀態的可能性要高得多。對於較大的底層模型，我們發現殘差串流中相鄰層之間的餘弦相似性較高，因此我們預期會有更多特徵在多個層上處於活動狀態。這些結果表明 MLSAE 是一種研究Transformer中資訊流的有前景方法。我們在 https://github.com/tim-lawson/mlsae 上發布了我們用於訓練和分析 MLSAE 的程式碼。

##### **GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**
2409.04183v1 by Ziyin Zhang, Hang Yu, Shijie Li, Peng Di, Jianguo Li, Rui Wang

Programming languages possess rich semantic information such as data flow
that is represented by graphs and not available from the surface form of source
code. Recent code language models have scaled to billions of parameters, but
model source code solely as text tokens while ignoring any other structural
information. Conversely, models that do encode structural information of code
make modifications to the Transformer architecture, limiting their scale and
compatibility with pretrained LLMs. In this work, we take the best of both
worlds with GALLa - Graph Aligned Large Language Model. GALLa utilizes graph
neural networks and cross-modal alignment technologies to inject the structural
information of code into LLMs as an auxiliary task during finetuning. This
framework is both model-agnostic and task-agnostic, as it can be applied to any
code LLM for any code downstream task, and requires the structural graph data
only at training time from a corpus unrelated to the finetuning data, while
incurring no cost at inference time over the baseline LLM. Experiments on five
code tasks with four different baseline LLMs ranging in size from 350M to 8B
validate the effectiveness of GALLa, demonstrating consistent improvement over
the baseline, even for powerful models such as LLaMA3.

摘要：程式語言擁有豐富的語意資訊，例如由圖形表示且無法從原始碼表面形式取得的資料流程。最近的程式碼語言模型已擴充至數十億個參數，但模型原始碼僅作為文字符號，而忽略任何其他結構資訊。反之，編碼程式碼結構資訊的模型會修改 Transformer 架構，限制其規模和與預先訓練的 LLM 的相容性。在這項工作中，我們採用 GALLa（圖形對齊大型語言模型）擷取兩全其美的優點。GALLa 利用圖形神經網路和跨模態對齊技術，在微調期間將程式碼的結構資訊注入 LLM 作為輔助任務。此架構同時不依賴模型和任務，因為它可以應用於任何程式碼 LLM 的任何程式碼下游任務，並且僅在訓練期間從與微調資料無關的語料庫取得結構圖形資料，同時在推論期間不產生比基準 LLM 更高的成本。在五個程式碼任務中進行實驗，使用四個不同的基準 LLM，規模從 350M 到 8B，驗證 GALLa 的有效性，證明即使對於 LLaMA3 等強大模型，也能持續優於基準。

##### **Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**
2409.04181v1 by Larissa Pusch, Tim O. F. Conrad

Advancements in natural language processing have revolutionized the way we
can interact with digital information systems, such as databases, making them
more accessible. However, challenges persist, especially when accuracy is
critical, as in the biomedical domain. A key issue is the hallucination
problem, where models generate information unsupported by the underlying data,
potentially leading to dangerous misinformation. This paper presents a novel
approach designed to bridge this gap by combining Large Language Models (LLM)
and Knowledge Graphs (KG) to improve the accuracy and reliability of
question-answering systems, on the example of a biomedical KG. Built on the
LangChain framework, our method incorporates a query checker that ensures the
syntactical and semantic validity of LLM-generated queries, which are then used
to extract information from a Knowledge Graph, substantially reducing errors
like hallucinations. We evaluated the overall performance using a new benchmark
dataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo
and llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other
models in generating accurate queries, open-source models like llama3:70b show
promise with appropriate prompt engineering. To make this approach accessible,
a user-friendly web-based interface has been developed, allowing users to input
natural language queries, view generated and corrected Cypher queries, and
verify the resulting paths for accuracy. Overall, this hybrid approach
effectively addresses common issues such as data gaps and hallucinations,
offering a reliable and intuitive solution for question answering systems. The
source code for generating the results of this paper and for the user-interface
can be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui

摘要：自然語言處理的進展徹底改變了我們與數位資訊系統（例如資料庫）互動的方式，讓這些系統變得更易於存取。然而，挑戰仍然存在，尤其是在準確性至關重要的情況下，例如在生物醫學領域。一個關鍵問題是幻覺問題，其中模型會產生未經基礎資料驗證的資訊，可能導致危險的錯誤資訊。本文提出了一種新穎的方法，旨在透過結合大型語言模型 (LLM) 和知識圖譜 (KG) 來彌補這個差距，以提高生物醫學 KG 中問答系統的準確性和可靠性。我們的技術建立在 LangChain 框架上，結合了一個查詢檢查器，可確保 LLM 生成的查詢在語法和語意上有效，然後用於從知識圖譜中萃取資訊，大幅減少幻覺等錯誤。我們使用一個新的 50 個生物醫學問題基準資料集評估了整體效能，測試了包括 GPT-4 Turbo 和 llama3:70b 在內的幾個 LLM。我們的結果顯示，雖然 GPT-4 Turbo 在產生準確查詢方面優於其他模型，但像 llama3:70b 這樣的開源模型在適當的提示工程下顯示出前景。為了讓這種方法易於使用，我們開發了一個使用者友善的網路介面，讓使用者可以輸入自然語言查詢、檢視產生和更正的 Cypher 查詢，並驗證結果路徑的準確性。總體而言，這種混合方法有效地解決了資料差距和幻覺等常見問題，為問答系統提供了一個可靠且直觀的解決方案。本文結果產生的原始碼和使用者介面的原始碼可以在我們的 Git 儲存庫中找到：https://git.zib.de/lpusch/cyphergenkg-gui

##### **The Prevalence of Neural Collapse in Neural Multivariate Regression**
2409.04180v1 by George Andriopoulos, Zixuan Dong, Li Guo, Zifan Zhao, Keith Ross

Recently it has been observed that neural networks exhibit Neural Collapse
(NC) during the final stage of training for the classification problem. We
empirically show that multivariate regression, as employed in imitation
learning and other applications, exhibits Neural Regression Collapse (NRC), a
new form of neural collapse: (NRC1) The last-layer feature vectors collapse to
the subspace spanned by the $n$ principal components of the feature vectors,
where $n$ is the dimension of the targets (for univariate regression, $n=1$);
(NRC2) The last-layer feature vectors also collapse to the subspace spanned by
the last-layer weight vectors; (NRC3) The Gram matrix for the weight vectors
converges to a specific functional form that depends on the covariance matrix
of the targets. After empirically establishing the prevalence of (NRC1)-(NRC3)
for a variety of datasets and network architectures, we provide an explanation
of these phenomena by modeling the regression task in the context of the
Unconstrained Feature Model (UFM), in which the last layer feature vectors are
treated as free variables when minimizing the loss function. We show that when
the regularization parameters in the UFM model are strictly positive, then
(NRC1)-(NRC3) also emerge as solutions in the UFM optimization problem. We also
show that if the regularization parameters are equal to zero, then there is no
collapse. To our knowledge, this is the first empirical and theoretical study
of neural collapse in the context of regression. This extension is significant
not only because it broadens the applicability of neural collapse to a new
category of problems but also because it suggests that the phenomena of neural
collapse could be a universal behavior in deep learning.

摘要：<paragraph>最近观察到，神经网络在分类问题的训练最后阶段会表现出神经崩溃 (NC)。我们凭经验表明，多变量回归（如在模仿学习和其他应用中所用）表现出神经回归崩溃 (NRC)，一种新的神经崩溃形式：(NRC1) 最后一层的特征向量崩溃到特征向量的 n 个主成分所跨越的子空间，其中 n 是目标的维度（对于单变量回归，n=1）；(NRC2) 最后一层的特征向量也崩溃到最后一层的权重向量所跨越的子空间；(NRC3) 权重向量的 Gram 矩阵收敛到一种特定函数形式，该形式取决于目标的协方差矩阵。在根据各种数据集和网络架构凭经验确定 (NRC1)-(NRC3) 的普遍性后，我们通过在无约束特征模型 (UFM) 的背景下对回归任务进行建模来解释这些现象，其中在最小化损失函数时，最后一层的特征向量被视为自由变量。我们表明，当 UFM 模型中的正则化参数严格为正时，(NRC1)-(NRC3) 也作为 UFM 优化问题中的解出现。我们还表明，如果正则化参数等于零，那么就不会发生崩溃。据我们所知，这是第一个在回归背景下对神经崩溃进行的经验和理论研究。这一扩展不仅具有重要意义，因为它将神经崩溃的适用性扩展到了一个新的问题类别，还因为它表明神经崩溃现象可能是深度学习中的普遍行为。</paragraph>

##### **From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks**
2409.04168v1 by Andreas Stephan, Dawei Zhu, Matthias Aßenmacher, Xiaoyu Shen, Benjamin Roth

To reduce the need for human annotations, large language models (LLMs) have
been proposed as judges of the quality of other candidate models. LLM judges
are typically evaluated by measuring the correlation with human judgments on
generation tasks such as summarization or machine translation. In contrast, we
study LLM judges on mathematical reasoning tasks. These tasks require
multi-step reasoning, and the correctness of their solutions is verifiable,
enabling a more objective evaluation. We perform a detailed performance
analysis and find that the used judges are mostly unable to improve task
performance but are able to pick the better model. Our analysis uncovers a
strong correlation between judgment performance and the candidate model task
performance. We observe that judges tend to choose the model of higher quality
even if its answer is incorrect. Further, we show that it is possible to use
statistics, such as the task performances of the individual models, to predict
judgment performance. In an ablation, we either swap or mask the candidate
answers and observe that judges often keep the original judgment, providing
evidence that judges incorporate writing style in their judgments. In summary,
we find that regularities in the judgments are quantifiable using statistical
measures and provide various angles on exploiting them.

摘要：<paragraph>為了減少人工標註的需求，大型語言模型 (LLM) 已被提議用作其他候選模型品質的評審。LLM 評審通常透過衡量在生成任務（例如摘要或機器翻譯）上與人類判斷相關性來評估。相反地，我們在數學推理任務上研究 LLM 評審。這些任務需要多步驟推理，且其解的正確性可驗證，能進行更客觀的評估。我們執行詳細的效能分析，發現所使用的評審大多無法改善任務效能，但能夠挑選出更好的模型。我們的分析揭露判斷效能與候選模型任務效能之間有很強的關聯性。我們觀察到，評審傾向選擇品質較高的模型，即使其答案不正確。此外，我們展示了可以使用統計資料（例如個別模型的任務效能）來預測判斷效能。在消融實驗中，我們調換或遮蔽候選答案，並觀察到評審經常保留原始判斷，這提供了評審在判斷中納入寫作風格的證據。總之，我們發現判斷中的規律性可以使用統計量化，並提供各種角度來利用它們。</paragraph>

##### **Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation**
2409.04164v1 by Luis Mayer, Christian Heumann, Matthias Aßenmacher

In recent years, large language models (LLMs) have emerged as powerful tools
with potential applications in various fields, including software engineering.
Within the scope of this research, we evaluate five different state-of-the-art
LLMs - Bard, BingChat, ChatGPT, Llama2, and Code Llama - concerning their
capabilities for text-to-code generation. In an empirical study, we feed
prompts with textual descriptions of coding problems sourced from the
programming website LeetCode to the models with the task of creating solutions
in Python. Subsequently, the quality of the generated outputs is assessed using
the testing functionalities of LeetCode. The results indicate large differences
in performance between the investigated models. ChatGPT can handle these
typical programming challenges by far the most effectively, surpassing even
code-specialized models like Code Llama. To gain further insights, we measure
the runtime as well as the memory usage of the generated outputs and compared
them to the other code submissions on Leetcode. A detailed error analysis,
encompassing a comparison of the differences concerning correct indentation and
form of the generated code as well as an assignment of the incorrectly solved
tasks to certain error categories allows us to obtain a more nuanced picture of
the results and potential for improvement. The results also show a clear
pattern of increasingly incorrect produced code when the models are facing a
lot of context in the form of longer prompts.

摘要：近年來，大型語言模型 (LLM) 已成為強大的工具，在各種領域中具有潛在應用，包括軟體工程。在此研究範圍內，我們評估五種不同的最先進 LLM - Bard、BingChat、ChatGPT、Llama2 和 Code Llama - 關於它們在文字轉程式碼生成的效能。在實證研究中，我們將來自程式設計網站 LeetCode 的編碼問題文字描述作為提示輸入模型，並賦予它們使用 Python 建立解決方案的任務。隨後，使用 LeetCode 的測試功能評估所產生輸出的品質。結果顯示，所調查模型之間的效能差異很大。ChatGPT 可以最有效地處理這些典型的程式設計挑戰，甚至超越了像 Code Llama 這樣的程式碼專用模型。為了獲得進一步的見解，我們測量了執行時間以及所產生輸出的記憶體使用量，並將它們與 Leetcode 上的其他程式碼提交進行比較。詳細的錯誤分析，包括比較正確縮排和所產生程式碼形式的差異，以及將錯誤解決的任務分配到特定錯誤類別，讓我們能夠獲得更細緻的結果和改善潛力。結果還顯示了一個明確的模式，即當模型面對大量以較長提示形式出現的內容時，產生的程式碼不正確的情況會越來越多。

##### **A Coin Has Two Sides: A Novel Detector-Corrector Framework for Chinese Spelling Correction**
2409.04150v1 by Xiangke Zeng, Zuchao Li, Lefei Zhang, Ping Wang, Hongqiu Wu, Hai Zhao

Chinese Spelling Correction (CSC) stands as a foundational Natural Language
Processing (NLP) task, which primarily focuses on the correction of erroneous
characters in Chinese texts. Certain existing methodologies opt to disentangle
the error correction process, employing an additional error detector to
pinpoint error positions. However, owing to the inherent performance
limitations of error detector, precision and recall are like two sides of the
coin which can not be both facing up simultaneously. Furthermore, it is also
worth investigating how the error position information can be judiciously
applied to assist the error correction. In this paper, we introduce a novel
approach based on error detector-corrector framework. Our detector is designed
to yield two error detection results, each characterized by high precision and
recall. Given that the occurrence of errors is context-dependent and detection
outcomes may be less precise, we incorporate the error detection results into
the CSC task using an innovative feature fusion strategy and a selective
masking strategy. Empirical experiments conducted on mainstream CSC datasets
substantiate the efficacy of our proposed method.

摘要：中文拼寫更正 (CSC) 是自然語言處理 (NLP) 的基礎任務，主要專注於更正中文文本中的錯誤字元。某些現有方法選擇解開錯誤更正程序，採用額外的錯誤偵測器來精確定位錯誤位置。然而，由於錯誤偵測器固有的效能限制，精確度和召回率就像一枚硬幣的兩面，無法同時朝上。此外，探討如何明智地應用錯誤位置資訊來協助錯誤更正也是值得的。在本文中，我們介紹一種基於錯誤偵測器更正器架構的新方法。我們的偵測器旨在產生兩個錯誤偵測結果，每個結果的特徵都是高精確度和召回率。由於錯誤的發生取決於上下文，而偵測結果可能不太精確，因此我們使用創新的特徵融合策略和選擇性遮罩策略將錯誤偵測結果納入 CSC 任務。在主流 CSC 資料集上進行的實證實驗證實了我們提出的方法的功效。

##### **Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers**
2409.04142v1 by Gorka Abad, Stjepan Picek, Lorenzo Cavallaro, Aitor Urbieta

Due to the high cost of training, large model (LM) practitioners commonly use
pretrained models downloaded from untrusted sources, which could lead to owning
compromised models. In-context learning is the ability of LMs to perform
multiple tasks depending on the prompt or context. This can enable new attacks,
such as backdoor attacks with dynamic behavior depending on how models are
prompted.
  In this paper, we leverage the ability of vision transformers (ViTs) to
perform different tasks depending on the prompts. Then, through data poisoning,
we investigate two new threats: i) task-specific backdoors where the attacker
chooses a target task to attack, and only the selected task is compromised at
test time under the presence of the trigger. At the same time, any other task
is not affected, even if prompted with the trigger. We succeeded in attacking
every tested model, achieving up to 89.90\% degradation on the target task. ii)
We generalize the attack, allowing the backdoor to affect \emph{any} task, even
tasks unseen during the training phase. Our attack was successful on every
tested model, achieving a maximum of $13\times$ degradation. Finally, we
investigate the robustness of prompts and fine-tuning as techniques for
removing the backdoors from the model. We found that these methods fall short
and, in the best case, reduce the degradation from 89.90\% to 73.46\%.

摘要：由於訓練成本高，大型模型 (LM) 的從業者通常會使用從不可信來源下載的預訓練模型，這可能導致擁有受損的模型。情境學習是 LM 根據提示或情境執行多項任務的能力。這可能會導致新的攻擊，例如根據模型提示方式而具有動態行為的後門攻擊。
在本文中，我們利用視覺Transformer (ViT) 根據提示執行不同任務的能力。然後，透過資料中毒，我們調查兩種新的威脅：i) 任務特定的後門，攻擊者選擇要攻擊的目標任務，並且在觸發器存在下，只有所選的任務在測試時受到損害。同時，任何其他任務都不受影響，即使提示了觸發器。我們成功攻擊了每個受測模型，在目標任務上實現了高達 89.90% 的降解。ii) 我們概括攻擊，允許後門影響任何任務，即使是在訓練階段中未見過的任務。我們的攻擊對每個受測模型都成功，實現了最高 $13\times$ 的降解。最後，我們調查了提示和微調作為從模型中移除後門的技術的穩健性。我們發現這些方法不足，並且在最好的情況下，將降解從 89.90% 降低到 73.46%。

##### **Prompt-based Personality Profiling: Reinforcement Learning for Relevance Filtering**
2409.04122v1 by Jan Hofmann, Cornelia Sindermann, Roman Klinger

Author profiling is the task of inferring characteristics about individuals
by analyzing content they share. Supervised machine learning still dominates
automatic systems that perform this task, despite the popularity of prompting
large language models to address natural language understanding tasks. One
reason is that the classification instances consist of large amounts of posts,
potentially a whole user profile, which may exceed the input length of
Transformers. Even if a model can use a large context window, the entirety of
posts makes the application of API-accessed black box systems costly and slow,
next to issues which come with such "needle-in-the-haystack" tasks. To mitigate
this limitation, we propose a new method for author profiling which aims at
distinguishing relevant from irrelevant content first, followed by the actual
user profiling only with relevant data. To circumvent the need for
relevance-annotated data, we optimize this relevance filter via reinforcement
learning with a reward function that utilizes the zero-shot capabilities of
large language models. We evaluate our method for Big Five personality trait
prediction on two Twitter corpora. On publicly available real-world data with a
skewed label distribution, our method shows similar efficacy to using all posts
in a user profile, but with a substantially shorter context. An evaluation on a
version of these data balanced with artificial posts shows that the filtering
to relevant posts leads to a significantly improved accuracy of the
predictions.

摘要：作者画像是透過分析個人分享的內容來推論其特質的任務。儘管提示大型語言模型來處理自然語言理解任務很受歡迎，但監督式機器學習仍主導執行此任務的自動系統。原因之一是分類實例包含大量的貼文，可能是一個完整的使用者檔案，這可能會超過 Transformers 的輸入長度。即使模型可以使用大型背景視窗，但貼文的完整性會讓存取 API 的黑盒子系統應用起來代價高昂且緩慢，這類「大海撈針」任務會出現的問題也不少。為了減輕這個限制，我們提出一個新的作者画像方法，其目標是先區分相關與不相關的內容，然後只使用相關資料進行實際的使用者画像。為了避免需要標註相關性的資料，我們透過強化學習來最佳化這個相關性篩選器，並使用利用大型語言模型的零次學習功能的獎勵函數。我們評估了我們的方法在兩個 Twitter 語料庫上的五大性格特質預測。在具有偏斜標籤分佈的公開可用的真實世界資料上，我們的模型顯示出與在使用者檔案中使用所有貼文類似的效力，但背景語境顯著較短。在使用人工貼文平衡這些資料的版本中進行評估，顯示出過濾相關貼文會大幅提升預測的準確度。

##### **Confidence-Aware Document OCR Error Detection**
2409.04117v1 by Arthur Hemmer, Mickaël Coustaty, Nicola Bartolo, Jean-Marc Ogier

Optical Character Recognition (OCR) continues to face accuracy challenges
that impact subsequent applications. To address these errors, we explore the
utility of OCR confidence scores for enhancing post-OCR error detection. Our
study involves analyzing the correlation between confidence scores and error
rates across different OCR systems. We develop ConfBERT, a BERT-based model
that incorporates OCR confidence scores into token embeddings and offers an
optional pre-training phase for noise adjustment. Our experimental results
demonstrate that integrating OCR confidence scores can enhance error detection
capabilities. This work underscores the importance of OCR confidence scores in
improving detection accuracy and reveals substantial disparities in performance
between commercial and open-source OCR technologies.

摘要：光學字元辨識 (OCR) 持續面臨影響後續應用程式的準確度挑戰。為了處理這些錯誤，我們探討使用 OCR 信心分數來增強 OCR 後錯誤偵測的效用。我們的研究包含分析不同 OCR 系統中信心分數與錯誤率之間的關聯性。我們開發 ConfBERT，這是一個基於 BERT 的模型，將 OCR 信心分數納入符號嵌入，並提供一個用於雜訊調整的選用預訓練階段。我們的實驗結果證明，整合 OCR 信心分數可以增強錯誤偵測能力。這項工作強調了 OCR 信心分數在提升偵測準確度上的重要性，並揭露商用與開放原始碼 OCR 技術之間的顯著效能差異。

##### **Multi-Programming Language Ensemble for Code Generation in Large Language Model**
2409.04114v1 by Tengfei Xue, Xuefeng Li, Tahir Azim, Roman Smirnov, Jianhui Yu, Arash Sadrieh, Babak Pahlavan

Large language models (LLMs) have significantly improved code generation,
particularly in one-pass code generation. However, most existing approaches
focus solely on generating code in a single programming language, overlooking
the potential of leveraging the multi-language capabilities of LLMs. LLMs have
varying patterns of errors across different languages, suggesting that a more
robust approach could be developed by leveraging these multi-language outputs.
In this study, we propose Multi-Programming Language Ensemble (MPLE), a novel
ensemble-based method that utilizes code generation across multiple programming
languages to enhance overall performance. By treating each language-specific
code generation process as an individual "weak expert" and effectively
integrating their outputs, our method mitigates language-specific errors and
biases. This multi-language ensemble strategy leverages the complementary
strengths of different programming languages, enabling the model to produce
more accurate and robust code. Our approach can be seamlessly integrated with
commonly used techniques such as the reflection algorithm and Monte Carlo tree
search to improve code generation quality further. Experimental results show
that our framework consistently enhances baseline performance by up to 17.92%
on existing benchmarks (HumanEval and HumanEval-plus), with a standout result
of 96.25% accuracy on the HumanEval benchmark, achieving new state-of-the-art
results across various LLM models. The code will be released at
https://github.com/NinjaTech-AI/MPLE

摘要：大型語言模型 (LLM) 已顯著改進程式碼產生，特別是在單次通過程式碼產生中。然而，現有的方法大多僅專注於使用單一程式語言產生程式碼，忽略了利用 LLM 多語言功能的潛力。LLM 在不同語言中存在不同的錯誤模式，這表明可以透過利用這些多語言輸出開發更強大的方法。在這個研究中，我們提出多程式語言合奏 (MPLE)，這是一個新穎的基於合奏的方法，它利用多種程式語言的程式碼產生來增強整體效能。透過將每個特定語言的程式碼產生程序視為一個單一的「弱專家」，並有效地整合其輸出，我們的程式碼減輕了特定語言的錯誤和偏誤。這個多語言合奏策略利用不同程式語言的互補優勢，使模型能夠產生更準確且強大的程式碼。我們的程式碼可以無縫地與常用的技術（例如反射演算法和蒙地卡羅樹搜尋）整合，以進一步提高程式碼產生品質。實驗結果顯示，我們的架構在現有的基準（HumanEval 和 HumanEval-plus）上持續提升基準效能達 17.92%，在 HumanEval 基準上獲得 96.25% 的準確度，在各種 LLM 模型中取得新的最先進成果。程式碼將在 https://github.com/NinjaTech-AI/MPLE 發布

##### **Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers**
2409.04109v1 by Chenglei Si, Diyi Yang, Tatsunori Hashimoto

Recent advancements in large language models (LLMs) have sparked optimism
about their potential to accelerate scientific discovery, with a growing number
of works proposing research agents that autonomously generate and validate new
ideas. Despite this, no evaluations have shown that LLM systems can take the
very first step of producing novel, expert-level ideas, let alone perform the
entire research process. We address this by establishing an experimental design
that evaluates research idea generation while controlling for confounders and
performs the first head-to-head comparison between expert NLP researchers and
an LLM ideation agent. By recruiting over 100 NLP researchers to write novel
ideas and blind reviews of both LLM and human ideas, we obtain the first
statistically significant conclusion on current LLM capabilities for research
ideation: we find LLM-generated ideas are judged as more novel (p < 0.05) than
human expert ideas while being judged slightly weaker on feasibility. Studying
our agent baselines closely, we identify open problems in building and
evaluating research agents, including failures of LLM self-evaluation and their
lack of diversity in generation. Finally, we acknowledge that human judgements
of novelty can be difficult, even by experts, and propose an end-to-end study
design which recruits researchers to execute these ideas into full projects,
enabling us to study whether these novelty and feasibility judgements result in
meaningful differences in research outcome.

摘要：大型語言模型 (LLM) 的近期進展點燃了人們對其加速科學發現潛力的樂觀情緒，越來越多的作品提出了自動生成和驗證新思想的研究代理。儘管如此，沒有任何評估表明 LLM 系統可以邁出產生新穎的專家級別思想的第一步，更不用說執行整個研究過程了。我們通過建立一個實驗設計來解決這個問題，該設計評估研究思想的產生，同時控制混雜因素，並對專家 NLP 研究人員和 LLM 構思代理進行首次正面比較。通過招募超過 100 名 NLP 研究人員撰寫新穎的思想並對 LLM 和人類思想進行盲審，我們得出了關於當前 LLM 研究構思能力的第一個具有統計意義的結論：我們發現 LLM 生成的思想被評為比人類專家思想更新穎 (p < 0.05)，同時在可行性上被評為稍弱。通過仔細研究我們的代理基準，我們發現了構建和評估研究代理的開放性問題，包括 LLM 自我評估的失敗及其生成缺乏多樣性。最後，我們承認即使是專家也很難對新穎性做出判斷，並提出了一個端到端的研究所設計，該設計招募研究人員將這些思想執行為完整的項目，使我們能夠研究這些新穎性和可行性判斷是否會導致研究結果的顯著差異。

##### **The Role of Graph Topology in the Performance of Biomedical Knowledge Graph Completion Models**
2409.04103v1 by Alberto Cattaneo, Stephen Bonner, Thomas Martynec, Carlo Luschi, Ian P Barrett, Daniel Justus

Knowledge Graph Completion has been increasingly adopted as a useful method
for several tasks in biomedical research, like drug repurposing or drug-target
identification. To that end, a variety of datasets and Knowledge Graph
Embedding models has been proposed over the years. However, little is known
about the properties that render a dataset useful for a given task and, even
though theoretical properties of Knowledge Graph Embedding models are well
understood, their practical utility in this field remains controversial. We
conduct a comprehensive investigation into the topological properties of
publicly available biomedical Knowledge Graphs and establish links to the
accuracy observed in real-world applications. By releasing all model
predictions and a new suite of analysis tools we invite the community to build
upon our work and continue improving the understanding of these crucial
applications.

摘要：知識圖譜補全已逐漸被採用為生物醫學研究中多項任務的有用方法，例如藥物再利用或藥物靶標識別。為此，多年來已提出各種資料集和知識圖譜嵌入模型。然而，對於讓資料集對特定任務有用的屬性所知甚少，儘管知識圖譜嵌入模型的理論屬性已廣為理解，它們在該領域的實用性仍存在爭議。我們對公開的生物醫學知識圖譜的拓撲屬性進行了全面調查，並建立了與實際應用中觀察到的準確性之間的聯繫。透過釋出所有模型預測和一套新的分析工具，我們邀請社群建立在我們的研究之上，並持續改善對這些關鍵應用程式的理解。

##### **Intelligent tutoring systems by Bayesian networks with noisy gates**
2409.04102v1 by Alessandro Antonucci, Francesca Mangili, Claudio Bonesana, Giorgia Adorni

Directed graphical models such as Bayesian nets are often used to implement
intelligent tutoring systems able to interact in real-time with learners in a
purely automatic way. When coping with such models, keeping a bound on the
number of parameters might be important for multiple reasons. First, as these
models are typically based on expert knowledge, a huge number of parameters to
elicit might discourage practitioners from adopting them. Moreover, the number
of model parameters affects the complexity of the inferences, while a fast
computation of the queries is needed for real-time feedback. We advocate
logical gates with uncertainty for a compact parametrization of the conditional
probability tables in the underlying Bayesian net used by tutoring systems. We
discuss the semantics of the model parameters to elicit and the assumptions
required to apply such approach in this domain. We also derive a dedicated
inference scheme to speed up computations.

摘要：有向圖形模型（例如貝氏網路）常被用於實作智慧型教學系統，此系統能夠以純自動化的方式與學習者進行即時互動。在應對此類模型時，基於多項原因，控制參數數量可能很重要。首先，由於這些模型通常基於專家知識，因此可能需要大量參數，這可能會讓從業者卻步。此外，模型參數數量會影響推論的複雜度，而即時回饋需要快速運算查詢。我們提倡使用具有不確定性的邏輯閘，以對教學系統所使用的基礎貝氏網路中的條件機率表進行精簡參數化。我們討論模型參數的語意，以引發並假設在這個領域中套用此方法時所需要的假設。我們也推導出專門的推論架構，以加速運算。

##### **Structure and dynamics of growing networks of Reddit threads**
2409.04085v1 by Diletta Goglia, Davide Vega

Millions of people use online social networks to reinforce their sense of
belonging, for example by giving and asking for feedback as a form of social
validation and self-recognition. It is common to observe disagreement among
people beliefs and points of view when expressing this feedback. Modeling and
analyzing such interactions is crucial to understand social phenomena that
happen when people face different opinions while expressing and discussing
their values. In this work, we study a Reddit community in which people
participate to judge or be judged with respect to some behavior, as it
represents a valuable source to study how users express judgments online. We
model threads of this community as complex networks of user interactions
growing in time, and we analyze the evolution of their structural properties.
We show that the evolution of Reddit networks differ from other real social
networks, despite falling in the same category. This happens because their
global clustering coefficient is extremely small and the average shortest path
length increases over time. Such properties reveal how users discuss in
threads, i.e. with mostly one other user and often by a single message. We
strengthen such result by analyzing the role that disagreement and reciprocity
play in such conversations. We also show that Reddit thread's evolution over
time is governed by two subgraphs growing at different speeds. We discover
that, in the studied community, the difference of such speed is higher than in
other communities because of the user guidelines enforcing specific user
interactions. Finally, we interpret the obtained results on user behavior
drawing back to Social Judgment Theory.

摘要：<paragraph>數百萬人使用線上社群網路來加強他們的歸屬感，例如透過給予和尋求回饋，作為一種社會認證和自我認同。當表達這種回饋時，人們的信念和觀點之間出現分歧是很常見的。對這種互動進行建模和分析對於理解人們在表達和討論他們的價值觀時面對不同意見時所發生的社會現象至關重要。在這項工作中，我們研究了一個 Reddit 社群，人們在其中參與對某種行為的評判或被評判，因為它代表了一個寶貴的來源，可以研究使用者如何在線上表達判斷。我們將這個社群的討論串建模為隨著時間推移而增長的使用者互動複雜網路，並分析它們結構屬性的演變。我們表明，儘管 Reddit 網路屬於同一類別，但它們的演變與其他真實的社交網路不同。這是因為它們的全局群集係數極小，並且平均最短路徑長度會隨著時間而增加。這些屬性揭示了使用者如何在討論串中進行討論，即主要與另一個使用者進行討論，而且通常只透過單一訊息。我們透過分析分歧和互惠在這些對話中所扮演的角色，來強化這樣的結果。我們也表明，Reddit 討論串隨著時間的演變是由兩個以不同速度增長的子圖所控制。我們發現，在所研究的社群中，這種速度差異高於其他社群，這是因為使用者指南強制執行特定的使用者互動。最後，我們根據社會判斷理論，詮釋在使用者行為上獲得的結果。</paragraph>

##### **SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation**
2409.04082v1 by Yi Tian, Juan Andrade-Cetto

Event cameras generate asynchronous and sparse event streams capturing
changes in light intensity. They offer significant advantages over conventional
frame-based cameras, such as a higher dynamic range and an extremely faster
data rate, making them particularly useful in scenarios involving fast motion
or challenging lighting conditions. Spiking neural networks (SNNs) share
similar asynchronous and sparse characteristics and are well-suited for
processing data from event cameras. Inspired by the potential of transformers
and spike-driven transformers (spikeformers) in other computer vision tasks, we
propose two solutions for fast and robust optical flow estimation for event
cameras: STTFlowNet and SDformerFlow. STTFlowNet adopts a U-shaped artificial
neural network (ANN) architecture with spatiotemporal shifted window
self-attention (swin) transformer encoders, while SDformerFlow presents its
fully spiking counterpart, incorporating swin spikeformer encoders.
Furthermore, we present two variants of the spiking version with different
neuron models. Our work is the first to make use of spikeformers for dense
optical flow estimation. We conduct end-to-end training for all models using
supervised learning. Our results yield state-of-the-art performance among
SNN-based event optical flow methods on both the DSEC and MVSEC datasets, and
show significant reduction in power consumption compared to the equivalent
ANNs.

摘要：事件攝影機會產生非同步且稀疏的事件串流，用以捕捉光線強度變化。與傳統的基於幀的攝影機相比，它們提供顯著的優勢，例如更高的動態範圍和極快的資料速率，這使它們在涉及快速運動或具有挑戰性的光線條件的場景中特別有用。脈衝神經網路 (SNN) 共享類似的非同步和稀疏特性，非常適合處理來自事件攝影機的資料。受到Transformer和脈衝驅動Transformer (spikeformer) 在其他電腦視覺任務中的潛力啟發，我們提出了兩種解決方案，用於事件攝影機的快速且穩健的光流估計：STTFlowNet 和 SDformerFlow。STTFlowNet 採用 U 形人工神經網路 (ANN) 架構，帶有時空位移視窗自注意力 (swin) Transformer編碼器，而 SDformerFlow 呈現其完全脈衝對應物，結合 swin spikeformer 編碼器。此外，我們提出了脈衝版本的兩個變體，它們具有不同的神經元模型。我們的研究首次使用 spikeformer 進行密集光流估計。我們使用監督式學習對所有模型進行端到端訓練。我們的結果在 DSEC 和 MVSEC 資料集上，在基於 SNN 的事件光流方法中產生了最先進的效能，並且與等效的 ANN 相比，顯著降低了功耗。

##### **UI-JEPA: Towards Active Perception of User Intent through Onscreen User Activity**
2409.04081v1 by Yicheng Fu, Raviteja Anantha, Prabal Vashisht, Jianpeng Cheng, Etai Littwin

Generating user intent from a sequence of user interface (UI) actions is a
core challenge in comprehensive UI understanding. Recent advancements in
multimodal large language models (MLLMs) have led to substantial progress in
this area, but their demands for extensive model parameters, computing power,
and high latency makes them impractical for scenarios requiring lightweight,
on-device solutions with low latency or heightened privacy. Additionally, the
lack of high-quality datasets has hindered the development of such lightweight
models. To address these challenges, we propose UI-JEPA, a novel framework that
employs masking strategies to learn abstract UI embeddings from unlabeled data
through self-supervised learning, combined with an LLM decoder fine-tuned for
user intent prediction. We also introduce two new UI-grounded multimodal
datasets, "Intent in the Wild" (IIW) and "Intent in the Tame" (IIT), designed
for few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos
across 219 intent categories, while IIT contains 914 videos across 10
categories. We establish the first baselines for these datasets, showing that
representations learned using a JEPA-style objective, combined with an LLM
decoder, can achieve user intent predictions that match the performance of
state-of-the-art large MLLMs, but with significantly reduced annotation and
deployment resources. Measured by intent similarity scores, UI-JEPA outperforms
GPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged
across two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x
reduction in computational cost and a 6.6x improvement in latency in the IIW
dataset. These results underscore the effectiveness of UI-JEPA, highlighting
its potential for lightweight, high-performance UI understanding.

摘要：<paragraph>從使用者介面 (UI) 動作序列中產生使用者意圖，是全面理解 UI 的核心挑戰。多模態大型語言模型 (MLLM) 的最新進展已促使此領域取得實質進展，但其對大量模型參數、運算能力和高延遲性的需求，使其不適用於需要輕量級、低延遲或高度隱私的裝置解決方案。此外，缺乏高品質資料集已阻礙此類輕量級模型的開發。為了應對這些挑戰，我們提出了 UI-JEPA，這是一個新穎的架構，採用遮罩策略，透過自監督學習從未標註的資料中學習抽象 UI 內嵌，並結合一個針對使用者意圖預測進行微調的 LLM 解碼器。我們還引入了兩個新的 UI 基礎多模態資料集，「Intent in the Wild」(IIW) 和「Intent in the Tame」(IIT)，專為少量樣本和零樣本 UI 理解任務而設計。IIW 包含 219 個意圖類別中的 1.7K 個影片，而 IIT 則包含 10 個類別中的 914 個影片。我們為這些資料集建立了第一個基準，表明使用 JEPA 風格目標學習的表徵，結合 LLM 解碼器，可以達成與最先進的大型 MLLM 相匹配的使用者意圖預測，但標註和部署資源卻大幅減少。以意圖相似性分數衡量，UI-JEPA 在兩個資料集的平均表現優於 GPT-4 Turbo 和 Claude 3.5 Sonnet，分別高出 10.0% 和 7.2%。值得注意的是，UI-JEPA 以 50.5 倍的運算成本降低和 6.6 倍的 IIW 資料集延遲性改善，達到了此效能。這些結果強調了 UI-JEPA 的有效性，突顯其在輕量級、高性能 UI 理解方面的潛力。</paragraph>

##### **AnyMatch -- Efficient Zero-Shot Entity Matching with a Small Language Model**
2409.04073v1 by Zeyu Zhang, Paul Groth, Iacer Calixto, Sebastian Schelter

Entity matching (EM) is the problem of determining whether two records refer
to same real-world entity, which is crucial in data integration, e.g., for
product catalogs or address databases. A major drawback of many EM approaches
is their dependence on labelled examples. We thus focus on the challenging
setting of zero-shot entity matching where no labelled examples are available
for an unseen target dataset. Recently, large language models (LLMs) have shown
promising results for zero-shot EM, but their low throughput and high
deployment cost limit their applicability and scalability.
  We revisit the zero-shot EM problem with AnyMatch, a small language model
fine-tuned in a transfer learning setup. We propose several novel data
selection techniques to generate fine-tuning data for our model, e.g., by
selecting difficult pairs to match via an AutoML filter, by generating
additional attribute-level examples, and by controlling label imbalance in the
data.
  We conduct an extensive evaluation of the prediction quality and deployment
cost of our model, in a comparison to thirteen baselines on nine benchmark
datasets. We find that AnyMatch provides competitive prediction quality despite
its small parameter size: it achieves the second-highest F1 score overall, and
outperforms several other approaches that employ models with hundreds of
billions of parameters. Furthermore, our approach exhibits major cost benefits:
the average prediction quality of AnyMatch is within 4.4% of the
state-of-the-art method MatchGPT with the proprietary trillion-parameter model
GPT-4, yet AnyMatch requires four orders of magnitude less parameters and
incurs a 3,899 times lower inference cost (in dollars per 1,000 tokens).

摘要：實體配對 (EM) 是個問題，在於決定兩筆記錄是否指涉同一個真實世界實體，這在資料整合中至關重要，例如產品目錄或地址資料庫。許多 EM 方法的一個主要缺點是它們依賴於標記範例。因此，我們專注於零次學習實體配對的挑戰性設定，其中沒有標記範例可供未見目標資料集使用。最近，大型語言模型 (LLM) 已顯示出零次學習 EM 的有希望結果，但它們的低處理量和高部署成本限制了它們的適用性和可擴充性。
我們使用 AnyMatch 重新審視零次學習 EM 問題，AnyMatch 是在遷移學習設定中微調的小型語言模型。我們提出幾種新穎的資料選擇技術，為我們的模型產生微調資料，例如透過自動機器學習篩選器選擇難以配對的配對、產生額外的屬性層級範例，以及控制資料中的標籤不平衡。
我們對我們的模型的預測品質和部署成本進行廣泛評估，並與九個基準資料集上的十三個基準進行比較。我們發現，儘管 AnyMatch 的參數規模小，但它提供了有競爭力的預測品質：它達到了第二高的 F1 分數，並且優於其他採用數百億個參數模型的方法。此外，我們的做法展現出主要的成本效益：AnyMatch 的平均預測品質在最先進的方法 MatchGPT 的 4.4% 範圍內，MatchGPT 使用專有的兆參數模型 GPT-4，但 AnyMatch 所需的參數少四個數量級，並且產生低 3,899 倍的推論成本（以每 1,000 個權杖為單位）。

##### **D4: Text-guided diffusion model-based domain adaptive data augmentation for vineyard shoot detection**
2409.04060v1 by Kentaro Hirahara, Chikahito Nakane, Hajime Ebisawa, Tsuyoshi Kuroda, Yohei Iwaki, Tomoyoshi Utsumi, Yuichiro Nomura, Makoto Koike, Hiroshi Mineno

In an agricultural field, plant phenotyping using object detection models is
gaining attention. However, collecting the training data necessary to create
generic and high-precision models is extremely challenging due to the
difficulty of annotation and the diversity of domains. Furthermore, it is
difficult to transfer training data across different crops, and although
machine learning models effective for specific environments, conditions, or
crops have been developed, they cannot be widely applied in actual fields. In
this study, we propose a generative data augmentation method (D4) for vineyard
shoot detection. D4 uses a pre-trained text-guided diffusion model based on a
large number of original images culled from video data collected by unmanned
ground vehicles or other means, and a small number of annotated datasets. The
proposed method generates new annotated images with background information
adapted to the target domain while retaining annotation information necessary
for object detection. In addition, D4 overcomes the lack of training data in
agriculture, including the difficulty of annotation and diversity of domains.
We confirmed that this generative data augmentation method improved the mean
average precision by up to 28.65% for the BBox detection task and the average
precision by up to 13.73% for the keypoint detection task for vineyard shoot
detection. Our generative data augmentation method D4 is expected to
simultaneously solve the cost and domain diversity issues of training data
generation in agriculture and improve the generalization performance of
detection models.

摘要：<paragraph>在農業領域，利用物件偵測模型進行植物表型分析正受到關注。然而，由於標註的困難和領域的多樣性，收集用於建立通用且高精確度模型的訓練資料極具挑戰性。此外，難以將訓練資料轉移到不同的作物上，儘管已經開發出對特定環境、條件或作物有效的機器學習模型，但它們無法廣泛應用於實際領域。在本研究中，我們提出了一種用於葡萄園枝條偵測的生成式資料擴充方法 (D4)。D4 使用預先訓練的文字引導擴散模型，該模型基於大量原始影像，這些影像是由無人地面載具或其他方式收集的影片資料中篩選出來的，以及少量的標註資料集。所提出的方法會產生新的標註影像，其中包含適應目標領域的背景資訊，同時保留物件偵測所需的標註資訊。此外，D4 克服了農業中訓練資料不足的問題，包括標註的困難和領域的多樣性。我們確認，這種生成式資料擴充方法將 BBox 偵測任務的平均準確度提高了 28.65%，將葡萄園枝條偵測的關鍵點偵測任務的平均準確度提高了 13.73%。我們預期，我們的生成式資料擴充方法 D4 能同時解決農業中訓練資料產生的成本和領域多樣性問題，並改善偵測模型的泛化效能。</paragraph>

##### **Self-Harmonized Chain of Thought**
2409.04057v1 by Ziqi Jin, Wei Lu

Chain-of-Thought (CoT) prompting reveals that large language models are
capable of performing complex reasoning via intermediate steps. CoT prompting
is primarily categorized into three approaches. The first approach utilizes
straightforward prompts like ``Let's think step by step'' to generate a
sequential thought process before yielding an answer. The second approach makes
use of human-crafted, step-by-step demonstrations to guide the model's
reasoning process. The third automates the generation of reasoned
demonstrations with the 'Let's think step by step'.This approach sometimes
leads to reasoning errors, highlighting the need to diversify demonstrations to
mitigate its misleading effects. However, diverse demonstrations pose
challenges for effective representations. In this work, we propose ECHO, a
self-harmonized chain-of-thought prompting method. It consolidates diverse
solution paths into a uniform and effective solution pattern.ECHO demonstrates
the best overall performance across three reasoning domains.

摘要：鏈式思考（CoT）提示揭示了大型語言模型能夠通過中間步驟執行複雜的推理。CoT 提示主要分為三種方法。第一種方法利用直接的提示，例如 ``讓我們一步一步思考''，在得出答案之前生成一個順序的思考過程。第二種方法利用人工製作的、逐步的演示來指導模型的推理過程。第三種方法通過 ``讓我們一步一步思考'' 自動生成合理的演示。這種方法有時會導致推理錯誤，強調了多樣化演示以減輕其誤導效應的必要性。然而，多樣化的演示對有效表示提出了挑戰。在這項工作中，我們提出了 ECHO，一種自我和諧的鏈式思考提示方法。它將不同的解決方案路徑整合到一個統一且有效的解決方案模式中。ECHO 在三個推理領域中展示了最佳的整體性能。

##### **Refining Wikidata Taxonomy using Large Language Models**
2409.04056v1 by Yiwen Peng, Thomas Bonald, Mehwish Alam

Due to its collaborative nature, Wikidata is known to have a complex
taxonomy, with recurrent issues like the ambiguity between instances and
classes, the inaccuracy of some taxonomic paths, the presence of cycles, and
the high level of redundancy across classes. Manual efforts to clean up this
taxonomy are time-consuming and prone to errors or subjective decisions. We
present WiKC, a new version of Wikidata taxonomy cleaned automatically using a
combination of Large Language Models (LLMs) and graph mining techniques.
Operations on the taxonomy, such as cutting links or merging classes, are
performed with the help of zero-shot prompting on an open-source LLM. The
quality of the refined taxonomy is evaluated from both intrinsic and extrinsic
perspectives, on a task of entity typing for the latter, showing the practical
interest of WiKC.

摘要：由於其協作性質，Wikidata 已知具有複雜的分類法，並有重複發生的問題，例如實例和類別之間的歧義、某些分類路徑的不準確性、循環的存在，以及類別之間的高冗餘。手動清理此分類法的工作既耗時又容易出現錯誤或主觀判斷。我們提出 WiKC，這是 Wikidata 分類法的新版本，使用大型語言模型 (LLM) 和圖形挖掘技術自動清理。分類法上的操作，例如剪切鏈接或合併類別，是在開源 LLM 上借助零次提示的幫助下執行的。精煉分類法的品質從內在和外在的觀點進行評估，在後者的實體分型任務上，顯示了 WiKC 的實際興趣。

##### **Towards Safer Online Spaces: Simulating and Assessing Intervention Strategies for Eating Disorder Discussions**
2409.04043v1 by Louis Penafiel, Hsien-Te Kao, Isabel Erickson, David Chu, Robert McCormack, Kristina Lerman, Svitlana Volkova

Eating disorders are complex mental health conditions that affect millions of
people around the world. Effective interventions on social media platforms are
crucial, yet testing strategies in situ can be risky. We present a novel
LLM-driven experimental testbed for simulating and assessing intervention
strategies in ED-related discussions. Our framework generates synthetic
conversations across multiple platforms, models, and ED-related topics,
allowing for controlled experimentation with diverse intervention approaches.
We analyze the impact of various intervention strategies on conversation
dynamics across four dimensions: intervention type, generative model, social
media platform, and ED-related community/topic. We employ cognitive domain
analysis metrics, including sentiment, emotions, etc., to evaluate the
effectiveness of interventions. Our findings reveal that civility-focused
interventions consistently improve positive sentiment and emotional tone across
all dimensions, while insight-resetting approaches tend to increase negative
emotions. We also uncover significant biases in LLM-generated conversations,
with cognitive metrics varying notably between models (Claude-3 Haiku $>$
Mistral $>$ GPT-3.5-turbo $>$ LLaMA3) and even between versions of the same
model. These variations highlight the importance of model selection in
simulating realistic discussions related to ED. Our work provides valuable
information on the complex dynamics of ED-related discussions and the
effectiveness of various intervention strategies.

摘要：飲食失調症是一種複雜的精神健康疾病，影響著全球數百萬人。在社群媒體平台上進行有效的干預至關重要，但現場測試策略可能會帶來風險。我們提出了一個由 LLM 驅動的新型實驗測試平台，用於模擬和評估 ED 相關討論中的干預策略。我們的架構會在多個平台、模型和 ED 相關主題中產生合成對話，允許使用多種干預方法進行受控實驗。我們分析了各種干預策略對對話動態的影響，包括四個面向：干預類型、生成模型、社群媒體平台和 ED 相關社群/主題。我們採用認知領域分析指標，包括情緒、情感等，來評估干預的有效性。我們的研究結果顯示，以禮貌為重點的干預措施在所有面向中都能持續改善正向情緒和情感基調，而見解重設方法則傾向於增加負面情緒。我們還發現 LLM 生成的對話中存在顯著的偏差，認知指標在模型之間（Claude-3 Haiku > Mistral > GPT-3.5-turbo > LLaMA3）甚至在同一個模型的不同版本之間都有顯著差異。這些差異突顯了在模擬與 ED 相關的現實討論時，模型選擇的重要性。我們的研究提供了有關 ED 相關討論的複雜動態以及各種干預策略的有效性的寶貴資訊。

##### **A First Look At Efficient And Secure On-Device LLM Inference Against KV Leakage**
2409.04040v1 by Huan Yang, Deyu Zhang, Yudong Zhao, Yuanchun Li, Yunxin Liu

Running LLMs on end devices has garnered significant attention recently due
to their advantages in privacy preservation. With the advent of lightweight LLM
models and specially designed GPUs, on-device LLM inference has achieved the
necessary accuracy and performance metrics. However, we have identified that
LLM inference on GPUs can leak privacy-sensitive intermediate information,
specifically the KV pairs. An attacker could exploit these KV pairs to
reconstruct the entire user conversation, leading to significant
vulnerabilities. Existing solutions, such as Fully Homomorphic Encryption (FHE)
and Trusted Execution Environments (TEE), are either too computation-intensive
or resource-limited. To address these issues, we designed KV-Shield, which
operates in two phases. In the initialization phase, it permutes the weight
matrices so that all KV pairs are correspondingly permuted. During the runtime
phase, the attention vector is inversely permuted to ensure the correctness of
the layer output. All permutation-related operations are executed within the
TEE, ensuring that insecure GPUs cannot access the original KV pairs, thus
preventing conversation reconstruction. Finally, we theoretically analyze the
correctness of KV-Shield, along with its advantages and overhead.

摘要：最近，在终端设备上运行 LLM 已引起广泛关注，因为它在隐私保护方面具有优势。随着轻量级 LLM 模型和专门设计的 GPU 的出现，设备上的 LLM 推断已达到必要的准确性和性能指标。然而，我们发现 GPU 上的 LLM 推断可能会泄露隐私敏感的中间信息，特别是 KV 对。攻击者可以利用这些 KV 对重建整个用户对话，从而导致重大漏洞。现有的解决方案，例如全同态加密 (FHE) 和可信执行环境 (TEE)，要么计算密集，要么资源有限。为了解决这些问题，我们设计了 KV-Shield，它分两个阶段运行。在初始化阶段，它对权重矩阵进行排列，以便所有 KV 对相应地进行排列。在运行时阶段，对注意力向量进行反向排列，以确保层输出的正确性。所有与排列相关的操作都在 TEE 内执行，确保不安全的 GPU 无法访问原始 KV 对，从而防止对话重建。最后，我们从理论上分析了 KV-Shield 的正确性，以及它的优点和开销。

##### **BFA-YOLO: Balanced multiscale object detection network for multi-view building facade attachments detection**
2409.04025v1 by Yangguang Chen, Tong Wang, Guanzhou Chen, Kun Zhu, Xiaoliang Tan, Jiaqi Wang, Hong Xie, Wenlin Zhou, Jingyi Zhao, Qing Wang, Xiaolong Luo, Xiaodong Zhang

Detection of building facade attachments such as doors, windows, balconies,
air conditioner units, billboards, and glass curtain walls plays a pivotal role
in numerous applications. Building facade attachments detection aids in
vbuilding information modeling (BIM) construction and meeting Level of Detail 3
(LOD3) standards. Yet, it faces challenges like uneven object distribution,
small object detection difficulty, and background interference. To counter
these, we propose BFA-YOLO, a model for detecting facade attachments in
multi-view images. BFA-YOLO incorporates three novel innovations: the Feature
Balanced Spindle Module (FBSM) for addressing uneven distribution, the Target
Dynamic Alignment Task Detection Head (TDATH) aimed at improving small object
detection, and the Position Memory Enhanced Self-Attention Mechanism (PMESA) to
combat background interference, with each component specifically designed to
solve its corresponding challenge. Detection efficacy of deep network models
deeply depends on the dataset's characteristics. Existing open source datasets
related to building facades are limited by their single perspective, small
image pool, and incomplete category coverage. We propose a novel method for
building facade attachments detection dataset construction and construct the
BFA-3D dataset for facade attachments detection. The BFA-3D dataset features
multi-view, accurate labels, diverse categories, and detailed classification.
BFA-YOLO surpasses YOLOv8 by 1.8% and 2.9% in mAP@0.5 on the multi-view BFA-3D
and street-view Facade-WHU datasets, respectively. These results underscore
BFA-YOLO's superior performance in detecting facade attachments.

摘要：<paragraph>偵測建築物立面附件（例如門、窗戶、陽台、空調機組、廣告看板和玻璃帷幕牆）在許多應用中扮演著關鍵角色。建築物立面附件偵測有助於建築資訊模型（BIM）的施工和達到詳細程度 3（LOD3）標準。然而，它面臨著不均勻的物件分佈、小物件偵測困難和背景干擾等挑戰。為了應對這些挑戰，我們提出了 BFA-YOLO，這是一個用於偵測多視圖影像中立面附件的模型。BFA-YOLO 結合了三項創新：用於解決不均勻分佈的特徵平衡主軸模組（FBSM）、用於改善小物件偵測的目標動態對齊任務偵測頭（TDATH）和用於對抗背景干擾的位置記憶增強自注意力機制（PMESA），每個元件都經過特別設計，以解決其對應的挑戰。深度網路模型的偵測效能高度依賴於資料集的特性。現有的開放原始碼資料集與建築立面相關，但受到單一視角、小影像池和不完整的類別涵蓋範圍的限制。我們提出了一種創新的建築立面附件偵測資料集建構方法，並建構了用於立面附件偵測的 BFA-3D 資料集。BFA-3D 資料集具有多視角、精確標籤、多樣類別和詳細分類。在多視角 BFA-3D 和街景 Facade-WHU 資料集上，BFA-YOLO 在 mAP@0.5 方面分別比 YOLOv8 高出 1.8% 和 2.9%。這些結果突顯了 BFA-YOLO 在偵測立面附件方面的卓越效能。</paragraph>

##### **Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**
2409.04009v1 by Miao Fan, Yeqi Bai, Mingming Sun, Ping Li

Relation classification (RC) plays a pivotal role in both natural language
understanding and knowledge graph completion. It is generally formulated as a
task to recognize the relationship between two entities of interest appearing
in a free-text sentence. Conventional approaches on RC, regardless of feature
engineering or deep learning based, can obtain promising performance on
categorizing common types of relation leaving a large proportion of
unrecognizable long-tail relations due to insufficient labeled instances for
training. In this paper, we consider few-shot learning is of great practical
significance to RC and thus improve a modern framework of metric learning for
few-shot RC. Specifically, we adopt the large-margin ProtoNet with fine-grained
features, expecting they can generalize well on long-tail relations. Extensive
experiments were conducted by FewRel, a large-scale supervised few-shot RC
dataset, to evaluate our framework: LM-ProtoNet (FGF). The results demonstrate
that it can achieve substantial improvements over many baseline approaches.

摘要：關係分類 (RC) 在自然語言理解和知識圖譜完成中扮演著關鍵角色。它通常被表述為一個任務，用於辨識出現在自由文字句子中的兩個感興趣實體之間的關係。無論是基於特徵工程還是深度學習的傳統 RC 方法，都可以對常見的關係類型進行分類，從而獲得有希望的效能，但由於訓練標籤實例不足，因此無法辨識出大量的長尾關係。在本文中，我們認為少樣本學習對 RC 具有重要的實用意義，因此改進了度量學習的現代框架，以進行少樣本 RC。具體來說，我們採用具有細粒度特徵的大邊距 ProtoNet，期望它們能在長尾關係上很好地概括。我們使用大型監督少樣本 RC 資料集 FewRel 進行了廣泛的實驗，以評估我們的框架：LM-ProtoNet (FGF)。結果表明，它可以比許多基線方法獲得顯著改進。

##### **Searching for Effective Preprocessing Method and CNN-based Architecture with Efficient Channel Attention on Speech Emotion Recognition**
2409.04007v1 by Byunggun Kim, Younghun Kwon

Speech emotion recognition (SER) classifies human emotions in speech with a
computer model. Recently, performance in SER has steadily increased as deep
learning techniques have adapted. However, unlike many domains that use speech
data, data for training in the SER model is insufficient. This causes
overfitting of training of the neural network, resulting in performance
degradation. In fact, successful emotion recognition requires an effective
preprocessing method and a model structure that efficiently uses the number of
weight parameters. In this study, we propose using eight dataset versions with
different frequency-time resolutions to search for an effective emotional
speech preprocessing method. We propose a 6-layer convolutional neural network
(CNN) model with efficient channel attention (ECA) to pursue an efficient model
structure. In particular, the well-positioned ECA blocks can improve channel
feature representation with only a few parameters. With the interactive
emotional dyadic motion capture (IEMOCAP) dataset, increasing the frequency
resolution in preprocessing emotional speech can improve emotion recognition
performance. Also, ECA after the deep convolution layer can effectively
increase channel feature representation. Consequently, the best result (79.37UA
79.68WA) can be obtained, exceeding the performance of previous SER models.
Furthermore, to compensate for the lack of emotional speech data, we experiment
with multiple preprocessing data methods that augment trainable data
preprocessed with all different settings from one sample. In the experiment, we
can achieve the highest result (80.28UA 80.46WA).

摘要：語音情緒辨識 (SER) 利用電腦模型對人類在語音中的情緒進行分類。最近，隨著深度學習技術的應用，SER 的表現持續提升。然而，與許多使用語音資料的領域不同，訓練 SER 模型的資料不足。這會造成神經網路訓練過度擬合，導致效能下降。事實上，成功的語音辨識需要一個有效的前處理方法和一個有效利用權重參數數量之模型結構。在本研究中，我們提出使用八個具有不同頻率時間解析度的資料集版本來搜尋一個有效的情緒化語音前處理方法。我們提出一個具有高效通道注意力 (ECA) 的 6 層卷積神經網路 (CNN) 模型，以追求一個高效的模型結構。特別是，位置良好的 ECA 區塊僅使用少數參數就能改善通道特徵表示。透過互動式情緒化二元動作捕捉 (IEMOCAP) 資料集，提升前處理情緒化語音中的頻率解析度可以改善情緒辨識效能。此外，深度卷積層之後的 ECA 可以有效提升通道特徵表示。因此，可以獲得最佳結果 (79.37UA 79.68WA)，超越先前的 SER 模型效能。此外，為了解決情緒化語音資料不足的問題，我們嘗試使用多重前處理資料方法，這些方法會擴增來自一個範例的所有不同設定中經過前處理的可訓練資料。在實驗中，我們可以獲得最高結果 (80.28UA 80.46WA)。

##### **Confidential Computing on nVIDIA H100 GPU: A Performance Benchmark Study**
2409.03992v1 by Jianwei Zhu, Hang Yin, Shunfan Zhou

This report evaluates the performance impact of enabling Trusted Execution
Environments (TEE) on NVIDIA H100 GPUs for large language model (LLM) inference
tasks. We benchmark the overhead introduced by TEE mode across various models
and token lengths, focusing on the bottleneck caused by CPU-GPU data transfers
via PCIe. Our results show that while there is minimal computational overhead
within the GPU, the overall performance penalty is primarily due to data
transfer. For most typical LLM queries, the overhead remains below 5%, with
larger models and longer sequences experiencing near-zero overhead.

摘要：本報告評估在 NVIDIA H100 GPU 上啟用可信執行環境 (TEE) 對大型語言模型 (LLM) 推論任務的效能影響。我們比較了 TEE 模式在各種模型和令牌長度下產生的額外負擔，重點在於 CPU-GPU 資料傳輸透過 PCIe 造成的瓶頸。我們的結果顯示，儘管 GPU 內部運算負擔很小，整體效能損失主要來自資料傳輸。對於大多數典型的 LLM 查詢，額外負擔低於 5%，而較大的模型和較長的序列則幾乎沒有額外負擔。

##### **FODA-PG for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes**
2409.03947v1 by Kai Shu, Yuzhuo Jia, Ziyang Zhang, Jiechao Gao

Automatic Medical Imaging Narrative generation aims to alleviate the workload
of radiologists by producing accurate clinical descriptions directly from
radiological images. However, the subtle visual nuances and domain-specific
terminology in medical images pose significant challenges compared to generic
image captioning tasks. Existing approaches often neglect the vital distinction
between normal and abnormal findings, leading to suboptimal performance. In
this work, we propose FODA-PG, a novel Fine-grained Organ-Disease Adaptive
Partitioning Graph framework that addresses these limitations through
domain-adaptive learning. FODA-PG constructs a granular graphical
representation of radiological findings by separating disease-related
attributes into distinct "disease-specific" and "disease-free" categories based
on their clinical significance and location. This adaptive partitioning enables
our model to capture the nuanced differences between normal and pathological
states, mitigating the impact of data biases. By integrating this fine-grained
semantic knowledge into a powerful transformer-based architecture and providing
rigorous mathematical justifications for its effectiveness, FODA-PG generates
precise and clinically coherent reports with enhanced generalization
capabilities. Extensive experiments on the IU-Xray and MIMIC-CXR benchmarks
demonstrate the superiority of our approach over state-of-the-art methods,
highlighting the importance of domain adaptation in medical report generation.

摘要：自動醫學影像敘述生成旨在透過直接從放射影像產生精確的臨床描述，減輕放射科醫師的工作負擔。然而，與一般影像標題任務相比，醫學影像中的細微視覺差異和特定領域術語會帶來重大挑戰。現有方法常常忽略正常與異常發現之間的重要區別，導致次佳效能。在這項工作中，我們提出 FODA-PG，這是一個新穎的細粒度器官疾病自適應分割圖形架構，透過領域自適應學習來解決這些限制。FODA-PG 透過將疾病相關屬性依據其臨床重要性和位置分為不同的「特定疾病」和「無疾病」類別，來建構放射學發現的細粒度圖形表示。這種自適應分割使我們的模型能夠捕捉正常與病理狀態之間的細微差異，減輕資料偏差的影響。透過將這種細粒度語義知識整合到強大的基於轉換器的架構中，並提供其有效性的嚴謹數學證明，FODA-PG 能夠生成精確且臨床上連貫的報告，並具備增強的概括能力。在 IU-Xray 和 MIMIC-CXR 基準上的廣泛實驗證明了我們的方法優於最先進的方法，突顯了領域適應在醫學報告生成中的重要性。

##### **On The Role of Prompt Construction In Enhancing Efficacy and Efficiency of LLM-Based Tabular Data Generation**
2409.03946v1 by Banooqa Banday, Kowshik Thopalli, Tanzima Z. Islam, Jayaraman J. Thiagarajan

LLM-based data generation for real-world tabular data can be challenged by
the lack of sufficient semantic context in feature names used to describe
columns. We hypothesize that enriching prompts with domain-specific insights
can improve both the quality and efficiency of data generation. To test this
hypothesis, we explore three prompt construction protocols: Expert-guided,
LLM-guided, and Novel-Mapping. Through empirical studies with the recently
proposed GReaT framework, we find that context-enriched prompts lead to
significantly improved data generation quality and training efficiency.

摘要：基於 LLM 的真實世界表格資料資料生成可能會受到用於描述欄位的特徵名稱中缺乏足夠語義背景的挑戰。我們假設使用特定領域的見解豐富提示可以改善資料生成的品質和效率。為了測試這個假設，我們探討了三種提示建構協定：專家指導、LLM 指導和新穎對應。透過與最近提出的 GReaT 架構進行實證研究，我們發現語境豐富的提示可以顯著改善資料生成品質和訓練效率。

##### **HUMOS: Human Motion Model Conditioned on Body Shape**
2409.03944v1 by Shashank Tripathi, Omid Taheri, Christoph Lassner, Michael J. Black, Daniel Holden, Carsten Stoll

Generating realistic human motion is essential for many computer vision and
graphics applications. The wide variety of human body shapes and sizes greatly
impacts how people move. However, most existing motion models ignore these
differences, relying on a standardized, average body. This leads to uniform
motion across different body types, where movements don't match their physical
characteristics, limiting diversity. To solve this, we introduce a new approach
to develop a generative motion model based on body shape. We show that it's
possible to train this model using unpaired data by applying cycle consistency,
intuitive physics, and stability constraints, which capture the relationship
between identity and movement. The resulting model generates diverse,
physically plausible, and dynamically stable human motions that are both
quantitatively and qualitatively more realistic than current state-of-the-art
methods. More details are available on our project page
https://CarstenEpic.github.io/humos/.

摘要：生成逼真的擬真動作對於許多電腦視覺和圖形應用程式而言至關重要。人體形狀和尺寸的多樣性極大地影響了人們的移動方式。然而，大多數現有的動作模型忽略了這些差異，依賴於標準化的平均身體。這導致了不同體型之間的動作統一，其中動作與其物理特徵不符，限制了多樣性。為了解決這個問題，我們引入了一種基於身體形狀開發生成式動作模型的新方法。我們表明，通過應用循環一致性、直觀物理和穩定性約束，可以訓練這個模型使用未配對的資料，這些約束捕捉了身份和動作之間的關係。生成的模型產生了多樣化、物理上合理的、動態穩定的擬真動作，在質量和數量上都比當前最先進的方法更逼真。更多詳細資訊可在我們的專案頁面 https://CarstenEpic.github.io/humos/ 中找到。

##### **Experimentation in Content Moderation using RWKV**
2409.03939v1 by Umut Yildirim, Rohan Dutta, Burak Yildirim, Atharva Vaidya

This paper investigates the RWKV model's efficacy in content moderation
through targeted experimentation. We introduce a novel dataset specifically
designed for distillation into smaller models, enhancing content moderation
practices. This comprehensive dataset encompasses images, videos, sounds, and
text data that present societal challenges. Leveraging advanced Large Language
Models (LLMs), we generated an extensive set of responses -- 558,958 for text
and 83,625 for images -- to train and refine content moderation systems. Our
core experimentation involved fine-tuning the RWKV model, capitalizing on its
CPU-efficient architecture to address large-scale content moderation tasks. By
highlighting the dataset's potential for knowledge distillation, this study not
only demonstrates RWKV's capability in improving the accuracy and efficiency of
content moderation systems but also paves the way for developing more compact,
resource-efficient models in this domain. Datasets and models can be found in
HuggingFace: https://huggingface.co/modrwkv

摘要：本文透過有針對性的實驗，探討 RWKV 模型在內容審核中的效能。我們引入一個專為小型模型知識蒸餾而設計的新穎資料集，以增強內容審核實務。這個全面的資料集包含了呈現社會挑戰的圖片、影片、聲音和文字資料。我們利用進階的大語言模型 (LLM)，產生了一組廣泛的回應，包括 558,958 個文字回應和 83,625 個圖片回應，用於訓練和優化內容審核系統。我們的核心實驗包括微調 RWKV 模型，利用其 CPU 效率高的架構來處理大規模的內容審核任務。透過強調資料集在知識蒸餾方面的潛力，本研究不僅證明了 RWKV 模型在提升內容審核系統的準確度和效率方面的能力，也為在這個領域開發更精簡、更省資源的模型鋪路。資料集和模型可以在 HuggingFace 中找到：https://huggingface.co/modrwkv

##### **Harnessing LLMs for Cross-City OD Flow Prediction**
2409.03937v1 by Chenyang Yu, Xinpeng Xie, Yan Huang, Chenxi Qiu

Understanding and predicting Origin-Destination (OD) flows is crucial for
urban planning and transportation management. Traditional OD prediction models,
while effective within single cities, often face limitations when applied
across different cities due to varied traffic conditions, urban layouts, and
socio-economic factors. In this paper, by employing Large Language Models
(LLMs), we introduce a new method for cross-city OD flow prediction. Our
approach leverages the advanced semantic understanding and contextual learning
capabilities of LLMs to bridge the gap between cities with different
characteristics, providing a robust and adaptable solution for accurate OD flow
prediction that can be transferred from one city to another. Our novel
framework involves four major components: collecting OD training datasets from
a source city, instruction-tuning the LLMs, predicting destination POIs in a
target city, and identifying the locations that best match the predicted
destination POIs. We introduce a new loss function that integrates POI
semantics and trip distance during training. By extracting high-quality
semantic features from human mobility and POI data, the model understands
spatial and functional relationships within urban spaces and captures
interactions between individuals and various POIs. Extensive experimental
results demonstrate the superiority of our approach over the state-of-the-art
learning-based methods in cross-city OD flow prediction.

摘要：了解和預測原點-目的地 (OD) 流量對於城市規劃和交通管理至關重要。傳統的 OD 預測模型在單一城市中很有效，但在應用於不同城市時，由於交通狀況、城市佈局和社會經濟因素的不同，通常會面臨限制。在本文中，通過使用大型語言模型 (LLM)，我們介紹了一種新的跨城市 OD 流量預測方法。我們的做法利用了 LLM 的先進語義理解和上下文學習能力，彌合了不同特徵城市之間的差距，提供了一個穩健且適應性強的解決方案，可以準確預測 OD 流量，並可以從一個城市轉移到另一個城市。我們的新框架包含四個主要組成部分：從源城市收集 OD 訓練數據集、對 LLM 進行指令微調、預測目標城市中的目的地 POI，以及識別與預測目的地 POI 最匹配的位置。我們引入了一個新的損失函數，它在訓練期間整合了 POI 語義和行程距離。通過從人類流動性和 POI 數據中提取高質量的語義特徵，該模型理解了城市空間內的空間和功能關係，並捕捉了個人與各種 POI 之間的互動。大量的實驗結果證明了我們的方法在跨城市 OD 流量預測中優於最先進的基於學習的方法。

##### **A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application**
2409.03933v1 by Esther Lagemann, Julia Roeb, Steven L. Brunton, Christian Lagemann

The accurate quantification of wall-shear stress dynamics is of substantial
importance for various applications in fundamental and applied research,
spanning areas from human health to aircraft design and optimization. Despite
significant progress in experimental measurement techniques and post-processing
algorithms, temporally resolved wall-shear stress dynamics with adequate
spatial resolution and within a suitable spatial domain remain an elusive goal.
To address this gap, we introduce a deep learning architecture that ingests
wall-parallel velocity fields from the logarithmic layer of turbulent
wall-bounded flows and outputs the corresponding 2D wall-shear stress fields
with identical spatial resolution and domain size. From a physical perspective,
our framework acts as a surrogate model encapsulating the various mechanisms
through which highly energetic outer-layer flow structures influence the
governing wall-shear stress dynamics. The network is trained in a supervised
fashion on a unified dataset comprising direct numerical simulations of
statistically 1D turbulent channel and spatially developing turbulent boundary
layer flows at friction Reynolds numbers ranging from 390 to 1,500. We
demonstrate a zero-shot applicability to experimental velocity fields obtained
from Particle-Image Velocimetry measurements and verify the physical accuracy
of the wall-shear stress estimates with synchronized wall-shear stress
measurements using the Micro-Pillar Shear-Stress Sensor for Reynolds numbers up
to 2,000. In summary, the presented framework lays the groundwork for
extracting inaccessible experimental wall-shear stress information from readily
available velocity measurements and thus, facilitates advancements in a variety
of experimental applications.

摘要：<paragraph>準確量化壁面剪應力動態對於基礎和應用研究中的各種應用具有實質性的重要性，涵蓋從人類健康到飛機設計和優化的領域。儘管在實驗測量技術和後處理演算法方面取得了顯著進展，但時間解析壁面剪應力動態仍具有足夠的空間解析度和在合適的空間域中仍然是一個難以捉摸的目標。為了解決這個差距，我們引入了一個深度學習架構，它從湍流壁面約束流的對數層中攝取壁面平行速度場，並輸出相應的 2D 壁面剪應力場，具有相同的空間解析度和域大小。從物理角度來看，我們的框架充當一個代理模型，概括了高能量外層流結構影響控制壁面剪應力動態的各種機制。該網路以監督方式在一個統一的數據集上進行訓練，該數據集包含統計 1D 湍流通道的直接數值模擬和空間發展的湍流邊界層流，摩擦雷諾數範圍從 390 到 1,500。我們展示了對從粒子影像測速測量中獲得的實驗速度場的零次應用，並使用微柱剪應力感測器對雷諾數最高 2,000 的同步壁面剪應力測量驗證了壁面剪應力估計的物理準確性。總之，所提出的框架為從容易獲得的速度測量中提取無法獲得的實驗壁面剪應力資訊奠定了基礎，從而促進了各種實驗應用中的進展。</paragraph>

##### **The Role of Generative Systems in Historical Photography Management: A Case Study on Catalan Archives**
2409.03911v1 by Èric Śanchez, Adrià Molina, Oriol Ramos Terrades

The use of image analysis in automated photography management is an
increasing trend in heritage institutions. Such tools alleviate the human cost
associated with the manual and expensive annotation of new data sources while
facilitating fast access to the citizenship through online indexes and search
engines. However, available tagging and description tools are usually designed
around modern photographs in English, neglecting historical corpora in
minoritized languages, each of which exhibits intrinsic particularities. The
primary objective of this research is to study the quantitative contribution of
generative systems in the description of historical sources. This is done by
contextualizing the task of captioning historical photographs from the Catalan
archives as a case study. Our findings provide practitioners with tools and
directions on transfer learning for captioning models based on visual
adaptation and linguistic proximity.

摘要：在自動化攝影管理中使用影像分析是文化遺產機構日益增長的趨勢。此類工具減輕了與人工和昂貴的新資料來源註解相關的人力成本，同時透過線上索引和搜尋引擎促進快速取得公民資格。然而，現有的標記和描述工具通常是針對英文的現代照片而設計，忽略了少數語言的歷史語料庫，而每種語言都展現出內在的特殊性。本研究的主要目的是研究生成式系統在歷史來源描述中的量化貢獻。這是透過將加泰隆尼亞檔案館的歷史照片加註標題的任務脈絡化為案例研究來完成的。我們的研究結果為從業人員提供了基於視覺適應和語言接近性的標題模型轉移學習的工具和方向。

##### **CACER: Clinical Concept Annotations for Cancer Events and Relations**
2409.03905v1 by Yujuan Fu, Giridhar Kaushik Ramachandran, Ahmad Halwani, Bridget T. McInnes, Fei Xia, Kevin Lybarger, Meliha Yetisgen, Özlem Uzuner

Clinical notes contain unstructured representations of patient histories,
including the relationships between medical problems and prescription drugs. To
investigate the relationship between cancer drugs and their associated symptom
burden, we extract structured, semantic representations of medical problem and
drug information from the clinical narratives of oncology notes. We present
Clinical Concept Annotations for Cancer Events and Relations (CACER), a novel
corpus with fine-grained annotations for over 48,000 medical problems and drug
events and 10,000 drug-problem and problem-problem relations. Leveraging CACER,
we develop and evaluate transformer-based information extraction (IE) models
such as BERT, Flan-T5, Llama3, and GPT-4 using fine-tuning and in-context
learning (ICL). In event extraction, the fine-tuned BERT and Llama3 models
achieved the highest performance at 88.2-88.0 F1, which is comparable to the
inter-annotator agreement (IAA) of 88.4 F1. In relation extraction, the
fine-tuned BERT, Flan-T5, and Llama3 achieved the highest performance at
61.8-65.3 F1. GPT-4 with ICL achieved the worst performance across both tasks.
The fine-tuned models significantly outperformed GPT-4 in ICL, highlighting the
importance of annotated training data and model optimization. Furthermore, the
BERT models performed similarly to Llama3. For our task, LLMs offer no
performance advantage over the smaller BERT models. The results emphasize the
need for annotated training data to optimize models. Multiple fine-tuned
transformer models achieved performance comparable to IAA for several
extraction tasks.

摘要：<paragraph>臨床筆記包含患者病史的非結構化表示，包括醫療問題和處方藥之間的關係。為了調查癌症藥物及其相關症狀負擔之間的關係，我們從腫瘤學筆記的臨床敘述中提取了醫療問題和藥物信息的結構化語義表示。我們提出了癌症事件和關係的臨床概念註釋 (CACER)，這是一個新的語料庫，對超過 48,000 個醫療問題和藥物事件以及 10,000 個藥物問題和問題問題關係進行了細粒度註釋。利用 CACER，我們開發並評估了基於Transformer的信息提取 (IE) 模型，例如 BERT、Flan-T5、Llama3 和 GPT-4，使用微調和上下文學習 (ICL)。在事件提取中，微調後的 BERT 和 Llama3 模型在 88.2-88.0 F1 中實現了最高性能，這與 88.4 F1 的標註間協議 (IAA) 相當。在關係提取中，微調後的 BERT、Flan-T5 和 Llama3 在 61.8-65.3 F1 中實現了最高性能。具有 ICL 的 GPT-4 在兩項任務中的表現最差。微調後的模型在 ICL 中明顯優於 GPT-4，突顯了註釋訓練數據和模型優化的重要性。此外，BERT 模型的性能與 Llama3 類似。對於我們的任務，LLM 對較小的 BERT 模型沒有性能優勢。結果強調了對註釋訓練數據以優化模型的需求。多個微調後的Transformer模型實現了與 IAA 相當的性能，用於多項提取任務。</paragraph>

##### **Multi-agent Path Finding for Mixed Autonomy Traffic Coordination**
2409.03881v1 by Han Zheng, Zhongxia Yan, Cathy Wu

In the evolving landscape of urban mobility, the prospective integration of
Connected and Automated Vehicles (CAVs) with Human-Driven Vehicles (HDVs)
presents a complex array of challenges and opportunities for autonomous driving
systems. While recent advancements in robotics have yielded Multi-Agent Path
Finding (MAPF) algorithms tailored for agent coordination task characterized by
simplified kinematics and complete control over agent behaviors, these
solutions are inapplicable in mixed-traffic environments where uncontrollable
HDVs must coexist and interact with CAVs. Addressing this gap, we propose the
Behavior Prediction Kinematic Priority Based Search (BK-PBS), which leverages
an offline-trained conditional prediction model to forecast HDV responses to
CAV maneuvers, integrating these insights into a Priority Based Search (PBS)
where the A* search proceeds over motion primitives to accommodate kinematic
constraints. We compare BK-PBS with CAV planning algorithms derived by
rule-based car-following models, and reinforcement learning. Through
comprehensive simulation on a highway merging scenario across diverse scenarios
of CAV penetration rate and traffic density, BK-PBS outperforms these baselines
in reducing collision rates and enhancing system-level travel delay. Our work
is directly applicable to many scenarios of multi-human multi-robot
coordination.

摘要：在不斷變化的城市交通環境中，連網自動駕駛車輛 (CAV) 與人類駕駛車輛 (HDV) 的潛在整合為自動駕駛系統帶來了複雜的挑戰和機遇。雖然機器人技術的最新進展已經產生了多主體路徑尋找 (MAPF) 演算法，該演算法專為協調任務而設計，其特點是運動學簡化且對主體行為有完全控制，但這些解決方案不適用於不可控 HDV 必須與 CAV 共存並互動的混合交通環境。為了解決這個差距，我們提出了基於行為預測運動學優先級搜尋 (BK-PBS)，它利用離線訓練的條件預測模型來預測 HDV 對 CAV 機動的反應，將這些見解整合到優先級搜尋 (PBS) 中，其中 A* 搜尋會根據運動原語進行，以適應運動學約束。我們將 BK-PBS 與由基於規則的跟車模型和強化學習衍生的 CAV 規劃演算法進行比較。透過在高速公路匯入場景中進行全面的模擬，涵蓋 CAV 滲透率和交通密度的不同場景，BK-PBS 在降低碰撞率和縮短系統級旅行延誤方面優於這些基準。我們的研究成果可直接應用於多人多機器人協調的許多場景。

##### **Sirius: Contextual Sparsity with Correction for Efficient LLMs**
2409.03856v1 by Yang Zhou, Zhuoming Chen, Zhaozhuo Xu, Victoria Lin, Beidi Chen

With the blossom of large language models (LLMs), inference efficiency
becomes increasingly important. Various approximation methods are proposed to
reduce the cost at inference time. Contextual Sparsity (CS) is appealing for
its training-free nature and its ability to reach a higher compression ratio
seemingly without quality degradation. However, after a comprehensive
evaluation of contextual sparsity methods on various complex generation tasks,
we find that although CS succeeds in prompt-understanding tasks, CS
significantly degrades the model performance for reasoning, deduction, and
knowledge-based tasks. Despite the gap in end-to-end accuracy, we observed that
sparse models often share general problem-solving logic and require only a few
token corrections to recover the original model performance. This paper
introduces Sirius, an efficient correction mechanism, which significantly
recovers CS models quality on reasoning tasks while maintaining its efficiency
gain. Sirius is evaluated on 6 models with 8 difficult generation tasks in
reasoning, math, and coding and shows consistent effectiveness and efficiency.
Also, we carefully develop a system implementation for Sirius and show that
Sirius achieves roughly 20% reduction in latency for 8B model on-chip and 35%
reduction for 70B model offloading. We open-source our implementation of Sirius
at https://github.com/Infini-AI-Lab/Sirius.git.

摘要：隨著大型語言模型 (LLM) 的蓬勃發展，推理效率變得越來越重要。各種近似方法被提出，以降低推理時間的成本。情境稀疏性 (CS) 因其無需訓練的特性和看似在不降低品質的情況下達到更高壓縮比的能力而具有吸引力。然而，在對各種複雜生成任務進行情境稀疏性方法的全面評估後，我們發現，儘管 CS 在提示理解任務中取得成功，但 CS 顯著降低了模型在推理、演繹和基於知識的任務中的效能。儘管在端到端準確性方面存在差距，我們觀察到稀疏模型通常共享一般的問題解決邏輯，並且只需要進行一些權標校正即可恢復原始模型效能。本文介紹了 Sirius，這是一種高效的校正機制，它顯著恢復了 CS 模型在推理任務中的品質，同時保持了其效率優勢。Sirius 在 6 個模型上進行了評估，這些模型在推理、數學和編碼方面有 8 項困難的生成任務，並顯示出一致的有效性和效率。此外，我們仔細地為 Sirius 開發了一個系統實作，並展示了 Sirius 在晶片上實現了 8B 模型大約 20% 的延遲減少，以及在離線載入 70B 模型時實現了 35% 的延遲減少。我們在 https://github.com/Infini-AI-Lab/Sirius.git 上開源了 Sirius 的實作。

##### **MetaBGM: Dynamic Soundtrack Transformation For Continuous Multi-Scene Experiences With Ambient Awareness And Personalization**
2409.03844v1 by Haoxuan Liu, Zihao Wang, Haorong Hong, Youwei Feng, Jiaxin Yu, Han Diao, Yunfei Xu, Kejun Zhang

This paper introduces MetaBGM, a groundbreaking framework for generating
background music that adapts to dynamic scenes and real-time user interactions.
We define multi-scene as variations in environmental contexts, such as
transitions in game settings or movie scenes. To tackle the challenge of
converting backend data into music description texts for audio generation
models, MetaBGM employs a novel two-stage generation approach that transforms
continuous scene and user state data into these texts, which are then fed into
an audio generation model for real-time soundtrack creation. Experimental
results demonstrate that MetaBGM effectively generates contextually relevant
and dynamic background music for interactive applications.

摘要：本文介紹 MetaBGM，這是一個創新的架構，用於產生能適應動態場景和使用者即時互動的背景音樂。
我們將多場景定義為環境背景的變化，例如遊戲中的場景轉換或電影場景。為了解決將後端資料轉換為音訊產生模型的音樂描述文字的挑戰，MetaBGM 採用了一種新穎的兩階段產生方法，將連續的場景和使用者狀態資料轉換為這些文字，然後將這些文字輸入音訊產生模型，以進行即時配樂創作。實驗結果證明，MetaBGM 能有效地為互動式應用程式產生與背景相關且動態的背景音樂。

##### **Persona Setting Pitfall: Persistent Outgroup Biases in Large Language Models Arising from Social Identity Adoption**
2409.03843v1 by Wenchao Dong, Assem Zhunis, Dongyoung Jeong, Hyojin Chin, Jiyoung Han, Meeyoung Cha

Drawing parallels between human cognition and artificial intelligence, we
explored how large language models (LLMs) internalize identities imposed by
targeted prompts. Informed by Social Identity Theory, these identity
assignments lead LLMs to distinguish between "we" (the ingroup) and "they" (the
outgroup). This self-categorization generates both ingroup favoritism and
outgroup bias. Nonetheless, existing literature has predominantly focused on
ingroup favoritism, often overlooking outgroup bias, which is a fundamental
source of intergroup prejudice and discrimination. Our experiment addresses
this gap by demonstrating that outgroup bias manifests as strongly as ingroup
favoritism. Furthermore, we successfully mitigated the inherent pro-liberal,
anti-conservative bias in LLMs by guiding them to adopt the perspectives of the
initially disfavored group. These results were replicated in the context of
gender bias. Our findings highlight the potential to develop more equitable and
balanced language models.

摘要：透過描繪人類認知與人工智慧之間的相似之處，我們探討大型語言模型 (LLM) 如何內化由特定提示所施加的身分。在社會認同理論的啟發下，這些身分指派會讓 LLM 區分「我們」(內團體) 和「他們」(外團體)。這種自我分類會產生內團體偏愛和外團體偏見。儘管如此，現有文獻主要關注於內團體偏愛，常常忽略外團體偏見，而這正是群際偏見和歧視的基本來源。我們的實驗透過證明外團體偏見與內團體偏愛一樣強烈，來解決這個差距。此外，我們透過引導 LLM 採用最初不受青睞的群體觀點，成功減輕了 LLM 中固有的親自由派、反保守派的偏見。這些結果在性別偏見的背景下得到驗證。我們的發現突顯出開發更公平、更平衡的語言模型的可能性。

##### **AI forecasting of higher-order wave modes of spinning binary black hole mergers**
2409.03833v1 by Victoria Tiki, Kiet Pham, Eliu Huerta

We present a physics-inspired transformer model that predicts the non-linear
dynamics of higher-order wave modes emitted by quasi-circular, spinning,
non-precessing binary black hole mergers. The model forecasts the waveform
evolution from the pre-merger phase through the ringdown, starting with an
input time-series spanning $ t \in [-5000\textrm{M}, -100\textrm{M}) $. The
merger event, defined as the peak amplitude of waveforms that include the $l =
|m| = 2$ modes, occurs at $ t = 0\textrm{M} $. The transformer then generates
predictions over the time range $ t \in [-100\textrm{M}, 130\textrm{M}] $. We
produced training, evaluation and test sets using the NRHybSur3dq8 model,
considering a signal manifold defined by mass ratios $ q \in [1, 8] $; spin
components $ s^z_{\{1,2\}} \in [-0.8, 0.8] $; modes up to $l \leq 4$, including
the $(5,5)$ mode but excluding the $(4,0)$ and $(4,1)$ modes; and inclination
angles $\theta \in [0, \pi]$. We trained the model on 14,440,761 waveforms,
completing the training in 15 hours using 16 NVIDIA A100 GPUs in the Delta
supercomputer. We used 4 H100 GPUs in the DeltaAI supercomputer to compute,
within 7 hours, the overlap between ground truth and predicted waveforms using
a test set of 840,000 waveforms, finding that the mean and median overlaps over
the test set are 0.996 and 0.997, respectively. Additionally, we conducted
interpretability studies to elucidate the waveform features utilized by our
transformer model to produce accurate predictions. The scientific software used
for this work is released with this manuscript.

摘要：<paragraph>我們提出了一個受物理啟發的 Transformer 模型，它可以預測準圓形、自旋、非進動二元黑洞合併所發射的高階波模的非線性動力學。該模型預測了從合併前階段到衰變的波形演化，從輸入時間序列開始，跨越 $ t \in [-5000\textrm{M}, -100\textrm{M}) $。合併事件定義為包含 $l = |m| = 2$ 模式的波形的峰值振幅，發生在 $ t = 0\textrm{M} $。然後，Transformer在時間範圍 $ t \in [-100\textrm{M}, 130\textrm{M}] $ 上生成預測。我們使用 NRHybSur3dq8 模型生成了訓練、評估和測試集，考慮了由質量比 $ q \in [1, 8] $ 定義的信號流形；自旋分量 $ s^z_{\{1,2\}} \in [-0.8, 0.8] $；模態高達 $l \leq 4$，包括 $(5,5)$ 模態，但不包括 $(4,0)$ 和 $(4,1)$ 模態；和傾角 $\theta \in [0, \pi]$。我們在 14,440,761 個波形上訓練了該模型，使用 Delta 超級計算機中的 16 個 NVIDIA A100 GPU，在 15 小時內完成了訓練。我們在 DeltaAI 超級計算機中使用了 4 個 H100 GPU，在 7 小時內計算了使用 840,000 個波形的測試集的真實波形和預測波形之間的重疊，發現測試集上的平均和中值重疊分別為 0.996 和 0.997。此外，我們進行了解釋性研究，以闡明我們的 Transformer 模型用於產生準確預測的波形特徵。用於這項工作的科學軟件隨此手稿一起發布。</paragraph>

##### **Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding**
2409.03757v1 by Yunze Man, Shuhong Zheng, Zhipeng Bao, Martial Hebert, Liang-Yan Gui, Yu-Xiong Wang

Complex 3D scene understanding has gained increasing attention, with scene
encoding strategies playing a crucial role in this success. However, the
optimal scene encoding strategies for various scenarios remain unclear,
particularly compared to their image-based counterparts. To address this issue,
we present a comprehensive study that probes various visual encoding models for
3D scene understanding, identifying the strengths and limitations of each model
across different scenarios. Our evaluation spans seven vision foundation
encoders, including image-based, video-based, and 3D foundation models. We
evaluate these models in four tasks: Vision-Language Scene Reasoning, Visual
Grounding, Segmentation, and Registration, each focusing on different aspects
of scene understanding. Our evaluations yield key findings: DINOv2 demonstrates
superior performance, video models excel in object-level tasks, diffusion
models benefit geometric tasks, and language-pretrained models show unexpected
limitations in language-related tasks. These insights challenge some
conventional understandings, provide novel perspectives on leveraging visual
foundation models, and highlight the need for more flexible encoder selection
in future vision-language and scene-understanding tasks.

摘要：複雜的 3D 場景理解獲得越來越多的關注，場景編碼策略在這個成功中扮演著至關重要的角色。然而，各種場景的最佳場景編碼策略仍然不明確，特別是與它們基於影像的對應物相比。為了解決這個問題，我們提出了一項全面的研究，探討了各種視覺編碼模型以進行 3D 場景理解，並確定了每個模型在不同場景中的優點和限制。我們的評估涵蓋了七個視覺基礎編碼器，包括基於影像、基於影片和 3D 基礎模型。我們在四項任務中評估了這些模型：視覺語言場景推理、視覺接地、分割和配準，每項任務都專注於場景理解的不同方面。我們的評估產生了關鍵發現：DINOv2 表現出優異的效能，影片模型在物件層級任務中表現出色，擴散模型受益於幾何任務，而語言預訓練模型在語言相關任務中表現出令人意外的限制。這些見解挑戰了一些傳統的理解，提供了利用視覺基礎模型的新觀點，並強調了在未來的視覺語言和場景理解任務中需要更靈活的編碼器選擇。

##### **Attention Heads of Large Language Models: A Survey**
2409.03752v1 by Zifan Zheng, Yezhaohui Wang, Yuxin Huang, Shichao Song, Bo Tang, Feiyu Xiong, Zhiyu Li

Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in
various tasks but remain largely as black-box systems. Consequently, their
development relies heavily on data-driven approaches, limiting performance
enhancement through changes in internal architecture and reasoning pathways. As
a result, many researchers have begun exploring the potential internal
mechanisms of LLMs, aiming to identify the essence of their reasoning
bottlenecks, with most studies focusing on attention heads. Our survey aims to
shed light on the internal reasoning processes of LLMs by concentrating on the
interpretability and underlying mechanisms of attention heads. We first distill
the human thought process into a four-stage framework: Knowledge Recalling,
In-Context Identification, Latent Reasoning, and Expression Preparation. Using
this framework, we systematically review existing research to identify and
categorize the functions of specific attention heads. Furthermore, we summarize
the experimental methodologies used to discover these special heads, dividing
them into two categories: Modeling-Free methods and Modeling-Required methods.
Also, we outline relevant evaluation methods and benchmarks. Finally, we
discuss the limitations of current research and propose several potential
future directions. Our reference list is open-sourced at
\url{https://github.com/IAAR-Shanghai/Awesome-Attention-Heads}.

摘要：自 ChatGPT 問世以來，大型語言模型 (LLM) 在各種任務中表現出色，但仍很大程度上是黑箱系統。因此，它們的發展很大程度上依賴於數據驅動的方法，限制了通過內部架構和推理路徑的改變來提升性能。因此，許多研究人員開始探索 LLM 的潛在內部機制，旨在找出其推理瓶頸的本質，大多數研究都集中在注意力頭部。我們的調查旨在通過專注於注意力頭部的可解釋性和底層機制，闡明 LLM 的內部推理過程。我們首先將人類的思維過程提煉成一個四階段框架：知識回憶、語境識別、潛在推理和表達準備。使用這個框架，我們系統地回顧現有研究，以識別和分類特定注意力頭部的功能。此外，我們總結了用於發現這些特殊頭部的實驗方法，將它們分為兩類：無建模方法和需要建模的方法。此外，我們概述了相關的評估方法和基準。最後，我們討論了當前研究的局限性，並提出了幾個潛在的未來方向。我們的參考清單在 \url{https://github.com/IAAR-Shanghai/Awesome-Attention-Heads} 開源。

##### **LLM-CI: Assessing Contextual Integrity Norms in Language Models**
2409.03735v1 by Yan Shvartzshnaider, Vasisht Duddu, John Lacalamita

Large language models (LLMs), while memorizing parts of their training data
scraped from the Internet, may also inadvertently encode societal preferences
and norms. As these models are integrated into sociotechnical systems, it is
crucial that the norms they encode align with societal expectations. These
norms could vary across models, hyperparameters, optimization techniques, and
datasets. This is especially challenging due to prompt sensitivity$-$small
variations in prompts yield different responses, rendering existing assessment
methodologies unreliable. There is a need for a comprehensive framework
covering various models, optimization, and datasets, along with a reliable
methodology to assess encoded norms.
  We present LLM-CI, the first open-sourced framework to assess privacy norms
encoded in LLMs. LLM-CI uses a Contextual Integrity-based factorial vignette
methodology to assess the encoded norms across different contexts and LLMs. We
propose the multi-prompt assessment methodology to address prompt sensitivity
by assessing the norms from only the prompts that yield consistent responses
across multiple variants. Using LLM-CI and our proposed methodology, we
comprehensively evaluate LLMs using IoT and COPPA vignettes datasets from prior
work, examining the impact of model properties (e.g., hyperparameters,
capacity) and optimization strategies (e.g., alignment, quantization).

摘要：大型語言模型 (LLM) 在記憶從網際網路擷取的部分訓練資料時，也可能無意間編碼社會偏好和規範。隨著這些模型整合到社會技術系統中，它們編碼的規範與社會期望一致至關重要。這些規範可能會因模型、超參數、最佳化技術和資料集而異。由於提示敏感性，這尤其具有挑戰性$-$提示的微小變化會產生不同的回應，使得現有的評估方法論不可靠。需要一個涵蓋各種模型、最佳化和資料集的綜合架構，以及一個可靠的方法論來評估編碼的規範。
我們提出 LLM-CI，這是第一個用於評估 LLM 中編碼的隱私規範的開源架構。LLM-CI 使用基於情境完整性的階乘小插曲方法論來評估不同情境和 LLM 中編碼的規範。我們提出多提示評估方法論來解決提示敏感性，方法是僅從在多個變體中產生一致回應的提示中評估規範。使用 LLM-CI 和我們提出的方法論，我們使用先前工作中的 IoT 和 COPPA 小插曲資料集全面評估 LLM，檢查模型屬性（例如，超參數、容量）和最佳化策略（例如，對齊、量化）的影響。

##### **PARCO: Learning Parallel Autoregressive Policies for Efficient Multi-Agent Combinatorial Optimization**
2409.03811v1 by Federico Berto, Chuanbo Hua, Laurin Luttmann, Jiwoo Son, Junyoung Park, Kyuree Ahn, Changhyun Kwon, Lin Xie, Jinkyoo Park

Multi-agent combinatorial optimization problems such as routing and
scheduling have great practical relevance but present challenges due to their
NP-hard combinatorial nature, hard constraints on the number of possible
agents, and hard-to-optimize objective functions. This paper introduces PARCO
(Parallel AutoRegressive Combinatorial Optimization), a novel approach that
learns fast surrogate solvers for multi-agent combinatorial problems with
reinforcement learning by employing parallel autoregressive decoding. We
propose a model with a Multiple Pointer Mechanism to efficiently decode
multiple decisions simultaneously by different agents, enhanced by a
Priority-based Conflict Handling scheme. Moreover, we design specialized
Communication Layers that enable effective agent collaboration, thus enriching
decision-making. We evaluate PARCO in representative multi-agent combinatorial
problems in routing and scheduling and demonstrate that our learned solvers
offer competitive results against both classical and neural baselines in terms
of both solution quality and speed. We make our code openly available at
https://github.com/ai4co/parco.

摘要：多代理組合優化問題，如路由和排程，具有極大的實用性，但由於其 NP 難組合性質、代理數量上的硬約束和難以最佳化的目標函數，因此提出了挑戰。本文介紹了 PARCO（並行自回歸組合優化），這是一種新穎的方法，它通過採用並行自回歸解碼，學習多代理組合問題的快速代理求解器，並進行強化學習。我們提出了一個具有多指標機制的模型，以通過不同的代理同時有效地解碼多個決策，並通過基於優先級的衝突處理方案進行增強。此外，我們設計了專門的通信層，以實現有效的代理協作，從而豐富決策制定。我們在路由和排程中的代表性多代理組合問題中評估了 PARCO，並證明我們的學習求解器在解決方案質量和速度方面都提供了與經典和神經基線相比具有競爭力的結果。我們在 https://github.com/ai4co/parco 上公開了我們的代碼。

##### **How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data**
2409.03810v1 by Yejie Wang, Keqing He, Dayuan Fu, Zhuoma Gongque, Heyang Xu, Yanxu Chen, Zhexu Wang, Yujia Fu, Guanting Dong, Muxi Diao, Jingang Wang, Mengdi Zhang, Xunliang Cai, Weiran Xu

Recently, there has been a growing interest in studying how to construct
better code instruction tuning data. However, we observe Code models trained
with these datasets exhibit high performance on HumanEval but perform worse on
other benchmarks such as LiveCodeBench. Upon further investigation, we find
that many datasets suffer from severe data leakage. After cleaning up most of
the leaked data, some well-known high-quality datasets perform poorly. This
discovery reveals a new challenge: identifying which dataset genuinely qualify
as high-quality code instruction data. To address this, we propose an efficient
code data pruning strategy for selecting good samples. Our approach is based on
three dimensions: instruction complexity, response quality, and instruction
diversity. Based on our selected data, we present XCoder, a family of models
finetuned from LLaMA3. Our experiments show XCoder achieves new
state-of-the-art performance using fewer training data, which verify the
effectiveness of our data strategy. Moreover, we perform a comprehensive
analysis on the data composition and find existing code datasets have different
characteristics according to their construction methods, which provide new
insights for future code LLMs. Our models and dataset are released in
https://github.com/banksy23/XCoder

摘要：<paragraph>最近，研究如何构建更好的代码指令调整数据引起了越来越多的兴趣。然而，我们观察到使用这些数据集训练的代码模型在 HumanEval 上表现出很高的性能，但在 LiveCodeBench 等其他基准上表现较差。经过进一步调查，我们发现许多数据集存在严重的数据泄露。在清理了大部分泄露数据后，一些著名的高质量数据集表现不佳。这一发现揭示了一个新的挑战：识别哪些数据集真正符合高质量代码指令数据。为了解决这个问题，我们提出了一种有效的代码数据剪枝策略来选择好的样本。我们的方法基于三个维度：指令复杂性、响应质量和指令多样性。基于我们选择的数据，我们提出了 XCoder，这是一个从 LLaMA3 微调的模型系列。我们的实验表明，XCoder 使用更少的训练数据实现了新的最先进的性能，这验证了我们数据策略的有效性。此外，我们对数据构成进行了全面分析，发现现有的代码数据集根据其构建方法具有不同的特征，这为未来的代码 LLM 提供了新的见解。我们的模型和数据集已在 https://github.com/banksy23/XCoder 中发布</paragraph>

##### **Planning In Natural Language Improves LLM Search For Code Generation**
2409.03733v1 by Evan Wang, Federico Cassano, Catherine Wu, Yunfeng Bai, Will Song, Vaskar Nath, Ziwen Han, Sean Hendryx, Summer Yue, Hugh Zhang

While scaling training compute has led to remarkable improvements in large
language models (LLMs), scaling inference compute has not yet yielded analogous
gains. We hypothesize that a core missing component is a lack of diverse LLM
outputs, leading to inefficient search due to models repeatedly sampling highly
similar, yet incorrect generations. We empirically demonstrate that this lack
of diversity can be mitigated by searching over candidate plans for solving a
problem in natural language. Based on this insight, we propose PLANSEARCH, a
novel search algorithm which shows strong results across HumanEval+, MBPP+, and
LiveCodeBench (a contamination-free benchmark for competitive coding).
PLANSEARCH generates a diverse set of observations about the problem and then
uses these observations to construct plans for solving the problem. By
searching over plans in natural language rather than directly over code
solutions, PLANSEARCH explores a significantly more diverse range of potential
solutions compared to baseline search methods. Using PLANSEARCH on top of
Claude 3.5 Sonnet achieves a state-of-the-art pass@200 of 77.0% on
LiveCodeBench, outperforming both the best score achieved without search
(pass@1 = 41.4%) and using standard repeated sampling (pass@200 = 60.6%).
Finally, we show that, across all models, search algorithms, and benchmarks
analyzed, we can accurately predict performance gains due to search as a direct
function of the diversity over generated ideas.

摘要：<paragraph>儘管擴展訓練運算已大幅改善大型語言模型 (LLM)，但擴展推論運算尚未產生類似的優勢。我們假設一個核心遺失的組成部分是缺乏多樣化的 LLM 輸出，這會導致模型反覆取樣高度相似但錯誤的生成，進而導致搜尋效率低下。我們實證證明，透過搜尋以自然語言解決問題的候選計畫，可以減輕這種缺乏多樣性的問題。根據這個見解，我們提出了 PLANSEARCH，這是一種新穎的搜尋演算法，在 HumanEval+、MBPP+ 和 LiveCodeBench（一種無污染的競爭編碼基準）中展現強勁的結果。PLANSEARCH 會產生一組關於問題的多樣化觀察，然後使用這些觀察來建構解決問題的計畫。透過以自然語言而非直接以程式碼解決方案搜尋計畫，與基準搜尋方法相比，PLANSEARCH 探索了更多樣化的潛在解決方案範圍。在 Claude 3.5 Sonnet 上使用 PLANSEARCH，在 LiveCodeBench 上達到了 77.0% 的最佳 pass@200，優於未搜尋獲得的最佳分數 (pass@1 = 41.4%) 和使用標準重複取樣 (pass@200 = 60.6%)。最後，我們證明，在分析的所有模型、搜尋演算法和基準中，我們可以準確預測由於搜尋而產生的效能提升，作為生成想法多樣性的直接函數。</paragraph>

##### **RAG based Question-Answering for Contextual Response Prediction System**
2409.03708v2 by Sriram Veturi, Saurabh Vaichal, Reshma Lal Jagadheesh, Nafis Irtiza Tripto, Nian Yan

Large Language Models (LLMs) have shown versatility in various Natural
Language Processing (NLP) tasks, including their potential as effective
question-answering systems. However, to provide precise and relevant
information in response to specific customer queries in industry settings, LLMs
require access to a comprehensive knowledge base to avoid hallucinations.
Retrieval Augmented Generation (RAG) emerges as a promising technique to
address this challenge. Yet, developing an accurate question-answering
framework for real-world applications using RAG entails several challenges: 1)
data availability issues, 2) evaluating the quality of generated content, and
3) the costly nature of human evaluation. In this paper, we introduce an
end-to-end framework that employs LLMs with RAG capabilities for industry use
cases. Given a customer query, the proposed system retrieves relevant knowledge
documents and leverages them, along with previous chat history, to generate
response suggestions for customer service agents in the contact centers of a
major retail company. Through comprehensive automated and human evaluations, we
show that this solution outperforms the current BERT-based algorithms in
accuracy and relevance. Our findings suggest that RAG-based LLMs can be an
excellent support to human customer service representatives by lightening their
workload.

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 任務中展現其多功能性，包括其作為有效問答系統的潛力。然而，要在產業環境中針對特定客戶查詢提供精確且相關的資訊，LLM 需要存取全面的知識庫，以避免產生幻覺。檢索擴充生成 (RAG) 浮現為解決此挑戰的一項有前途的技術。然而，使用 RAG 為真實世界應用開發準確的問答架構會帶來多項挑戰：1) 資料可用性問題、2) 評估生成內容的品質，以及 3) 人工評估的昂貴性質。在本文中，我們介紹了一個端到端架構，它採用具備 RAG 功能的 LLM，以適用於產業用例。針對客戶查詢，所提出的系統會檢索相關的知識文件，並利用這些文件以及先前的聊天記錄，為大型零售公司的聯絡中心中的客戶服務代理產生回應建議。透過全面的自動化和人工評估，我們證明此解決方案在準確性和相關性方面優於目前的 BERT-based 演算法。我們的研究結果顯示，基於 RAG 的 LLM 可以透過減輕人類客服人員的工作負擔，成為其絕佳的支援。

##### **A Different Level Text Protection Mechanism With Differential Privacy**
2409.03707v1 by Qingwen Fu

The article introduces a method for extracting words of different degrees of
importance based on the BERT pre-training model and proves the effectiveness of
this method. The article also discusses the impact of maintaining the same
perturbation results for words of different importance on the overall text
utility. This method can be applied to long text protection.

摘要：本文提出了一种基于BERT预训练模型提取不同重要程度词语的方法，并论证了该方法的有效性。文章还探讨了对不同重要程度的词语保持相同的扰动结果对整体文本效用的影响。该方法可应用于长文本保护。

##### **LAST: Language Model Aware Speech Tokenization**
2409.03701v1 by Arnon Turetzky, Yossi Adi

Speech tokenization serves as the foundation of speech language model (LM),
enabling them to perform various tasks such as spoken language modeling,
text-to-speech, speech-to-text, etc. Most speech tokenizers are trained
independently of the LM training process, relying on separate acoustic models
and quantization methods. Following such an approach may create a mismatch
between the tokenization process and its usage afterward. In this study, we
propose a novel approach to training a speech tokenizer by leveraging
objectives from pre-trained textual LMs. We advocate for the integration of
this objective into the process of learning discrete speech representations.
Our aim is to transform features from a pre-trained speech model into a new
feature space that enables better clustering for speech LMs. We empirically
investigate the impact of various model design choices, including speech
vocabulary size and text LM size. Our results demonstrate the proposed
tokenization method outperforms the evaluated baselines considering both spoken
language modeling and speech-to-text. More importantly, unlike prior work, the
proposed method allows the utilization of a single pre-trained LM for
processing both speech and text inputs, setting it apart from conventional
tokenization approaches.

摘要：語音標記化作為語音語言模型 (LM) 的基礎，
使它們能夠執行各種任務，例如口語語言建模、
文字轉語音、語音轉文字等。大多數語音標記器都是獨立於 LM 訓練過程進行訓練，依賴於單獨的聲學模型
和量化方法。遵循這種方法可能會在標記化過程及其後續使用之間造成不匹配。在本研究中，我們
提出了一種通過利用預訓練文本 LM 的目標來訓練語音標記器的全新方法。我們提倡將
此目標整合到學習離散語音表示的過程中。我們的目標是將預訓練語音模型中的特徵轉換為新的
特徵空間，以便為語音 LM 實現更好的聚類。我們憑經驗
研究了各種模型設計選擇的影響，包括語音詞彙量大小和文本 LM 大小。我們的結果表明，所提出的
標記化方法在口語語言建模和語音轉文字方面都優於評估的基準。更重要的是，與先前的研究不同，
所提出的方法允許利用單個預訓練 LM 來處理語音和文字輸入，這使其有別於傳統的
標記化方法。

##### **View-Invariant Policy Learning via Zero-Shot Novel View Synthesis**
2409.03685v1 by Stephen Tian, Blake Wulfe, Kyle Sargent, Katherine Liu, Sergey Zakharov, Vitor Guizilini, Jiajun Wu

Large-scale visuomotor policy learning is a promising approach toward
developing generalizable manipulation systems. Yet, policies that can be
deployed on diverse embodiments, environments, and observational modalities
remain elusive. In this work, we investigate how knowledge from large-scale
visual data of the world may be used to address one axis of variation for
generalizable manipulation: observational viewpoint. Specifically, we study
single-image novel view synthesis models, which learn 3D-aware scene-level
priors by rendering images of the same scene from alternate camera viewpoints
given a single input image. For practical application to diverse robotic data,
these models must operate zero-shot, performing view synthesis on unseen tasks
and environments. We empirically analyze view synthesis models within a simple
data-augmentation scheme that we call View Synthesis Augmentation (VISTA) to
understand their capabilities for learning viewpoint-invariant policies from
single-viewpoint demonstration data. Upon evaluating the robustness of policies
trained with our method to out-of-distribution camera viewpoints, we find that
they outperform baselines in both simulated and real-world manipulation tasks.
Videos and additional visualizations are available at
https://s-tian.github.io/projects/vista.

摘要：大規模視覺運動策略學習是一種很有前景的方法，用於開發可概括的操縱系統。然而，可以在不同的具體實施、環境和觀察方式中部署的策略仍然難以捉摸。在這項工作中，我們研究了來自世界的大規模視覺數據的知識如何用於解決可概括操縱的一個變異軸：觀察視點。具體來說，我們研究單圖像新視圖合成模型，該模型通過給定單個輸入圖像從備用相機視點渲染同一場景的圖像，學習具有 3D 感知能力的場景級先驗。對於對各種機器人數據的實際應用，這些模型必須進行零次學習，對未見任務和環境執行視圖合成。我們在一個簡單的數據擴充方案中對視圖合成模型進行經驗分析，我們稱之為視圖合成擴充 (VISTA)，以了解它們從單視點演示數據中學習視點不變策略的能力。在評估使用我們的視點外分佈相機視點訓練的策略的穩健性後，我們發現它們在模擬和真實世界操縱任務中都優於基準。視頻和其他視覺化效果可在 https://s-tian.github.io/projects/vista 上獲得。

##### **TRACE-cs: Trustworthy Reasoning for Contrastive Explanations in Course Scheduling Problems**
2409.03671v1 by Stylianos Loukas Vasileiou, William Yeoh

We present TRACE-cs, a novel hybrid system that combines symbolic reasoning
with large language models (LLMs) to address contrastive queries in scheduling
problems. TRACE-cs leverages SAT solving techniques to encode scheduling
constraints and generate explanations for user queries, while utilizing an LLM
to process the user queries into logical clauses as well as refine the
explanations generated by the symbolic solver to natural language sentences. By
integrating these components, our approach demonstrates the potential of
combining symbolic methods with LLMs to create explainable AI agents with
correctness guarantees.

摘要：我們提出 TRACE-cs，這是一個新穎的混合系統，它結合了符號推理和大型語言模型 (LLM)，以解決排程問題中的對比查詢。TRACE-cs 利用 SAT 求解技術來編碼排程約束並為使用者查詢產生解釋，同時利用 LLM 將使用者查詢處理成邏輯子句，並將符號求解器產生的解釋精煉成自然語言句子。透過整合這些元件，我們的做法展示了結合符號方法與 LLM 的潛力，以建立具有正確性保證的可解釋 AI 代理。

##### **A method to benchmark high-dimensional process drift detection**
2409.03669v1 by Edgar Wolf, Tobias Windisch

Process curves are multi-variate finite time series data coming from
manufacturing processes. This paper studies machine learning methods for drifts
of process curves. A theoretic framework to synthetically generate process
curves in a controlled way is introduced in order to benchmark machine learning
algorithms for process drift detection. A evaluation score, called the temporal
area under the curve, is introduced, which allows to quantify how well machine
learning models unveil curves belonging to drift segments. Finally, a benchmark
study comparing popular machine learning approaches on synthetic data generated
with the introduced framework shown.

摘要：製程曲線是來自製造製程的多變量有限時間序列資料。本文探討製程曲線偏移的機器學習方法。引進一個理論架構，以受控方式合成產生製程曲線，以基準機器學習演算法用於製程偏移偵測。引進一個評估分數，稱為曲線下的時間區域，用於量化機器學習模型揭露屬於偏移區段的曲線的程度。最後，一個基準研究比較了在以引進的架構產生的合成資料上流行的機器學習方法。

##### **A Fused Large Language Model for Predicting Startup Success**
2409.03668v1 by Abdurahman Maarouf, Stefan Feuerriegel, Nicolas Pröllochs

Investors are continuously seeking profitable investment opportunities in
startups and, hence, for effective decision-making, need to predict a startup's
probability of success. Nowadays, investors can use not only various
fundamental information about a startup (e.g., the age of the startup, the
number of founders, and the business sector) but also textual description of a
startup's innovation and business model, which is widely available through
online venture capital (VC) platforms such as Crunchbase. To support the
decision-making of investors, we develop a machine learning approach with the
aim of locating successful startups on VC platforms. Specifically, we develop,
train, and evaluate a tailored, fused large language model to predict startup
success. Thereby, we assess to what extent self-descriptions on VC platforms
are predictive of startup success. Using 20,172 online profiles from
Crunchbase, we find that our fused large language model can predict startup
success, with textual self-descriptions being responsible for a significant
part of the predictive power. Our work provides a decision support tool for
investors to find profitable investment opportunities.

摘要：<paragraph>投資者持續尋找新創公司的獲利投資機會，因此，為了做出有效的決策，需要預測新創公司的成功機率。現今，投資者不僅可以使用各種新創公司的基本資訊（例如，新創公司的年齡、創辦人數和產業別），還能使用新創公司創新和商業模式的文字說明，這些說明可透過 Crunchbase 等線上創投平台廣泛取得。為了協助投資者進行決策，我們開發了一種機器學習方法，目的是在創投平台上找出成功的公司。具體來說，我們開發、訓練和評估一個量身打造的融合式大型語言模型，以預測新創公司的成功。藉此，我們評估創投平台上的自我描述在多大程度上可以預測新創公司的成功。我們使用 Crunchbase 中的 20,172 個線上個人資料，發現我們的融合式大型語言模型可以預測新創公司的成功，而文字自我描述在預測能力中扮演了重要的角色。我們的研究為投資者提供了一個決策支援工具，以找出獲利的投資機會。</paragraph>

##### **The representation landscape of few-shot learning and fine-tuning in large language models**
2409.03662v1 by Diego Doimo, Alessandro Serra, Alessio Ansuini, Alberto Cazzaniga

In-context learning (ICL) and supervised fine-tuning (SFT) are two common
strategies for improving the performance of modern large language models (LLMs)
on specific tasks. Despite their different natures, these strategies often lead
to comparable performance gains. However, little is known about whether they
induce similar representations inside LLMs. We approach this problem by
analyzing the probability landscape of their hidden representations in the two
cases. More specifically, we compare how LLMs solve the same question-answering
task, finding that ICL and SFT create very different internal structures, in
both cases undergoing a sharp transition in the middle of the network. In the
first half of the network, ICL shapes interpretable representations
hierarchically organized according to their semantic content. In contrast, the
probability landscape obtained with SFT is fuzzier and semantically mixed. In
the second half of the model, the fine-tuned representations develop
probability modes that better encode the identity of answers, while the
landscape of ICL representations is characterized by less defined peaks. Our
approach reveals the diverse computational strategies developed inside LLMs to
solve the same task across different conditions, allowing us to make a step
towards designing optimal methods to extract information from language models.

摘要：文本内学习 (ICL) 和监督微调 (SFT) 是两种常见的策略，用于提升现代大型语言模型 (LLM) 在特定任务上的性能。尽管其本质不同，但这些策略通常会导致可比的性能提升。然而，对于它们是否会在 LLM 内诱发类似的表征，我们所知甚少。我们通过分析这两种情况下其隐藏表征的概率分布来解决这个问题。更具体地说，我们比较了 LLM 如何解决相同的问答任务，发现 ICL 和 SFT 创建了非常不同的内部结构，在这两种情况下，网络中间都经历了急剧的转变。在网络的前半部分，ICL 根据语义内容分层组织可解释的表征。相比之下，使用 SFT 获得的概率分布则更加模糊且语义混合。在模型的后半部分，微调后的表征发展出概率模式，更好地编码答案的身份，而 ICL 表征的分布则以不太明确的峰值为特征。我们的方法揭示了 LLM 内部开发的不同计算策略，以解决不同条件下的相同任务，使我们能够朝着设计从语言模型中提取信息的最优方法迈出一步。

##### **LLM-based multi-agent poetry generation in non-cooperative environments**
2409.03659v2 by Ran Zhang, Steffen Eger

Despite substantial progress of large language models (LLMs) for automatic
poetry generation, the generated poetry lacks diversity while the training
process differs greatly from human learning. Under the rationale that the
learning process of the poetry generation systems should be more human-like and
their output more diverse and novel, we introduce a framework based on social
learning where we emphasize non-cooperative interactions besides cooperative
interactions to encourage diversity. Our experiments are the first attempt at
LLM-based multi-agent systems in non-cooperative environments for poetry
generation employing both TRAINING-BASED agents (GPT-2) and PROMPTING-BASED
agents (GPT-3 and GPT-4). Our evaluation based on 96k generated poems shows
that our framework benefits the poetry generation process for TRAINING-BASED
agents resulting in 1) a 3.0-3.7 percentage point (pp) increase in diversity
and a 5.6-11.3 pp increase in novelty according to distinct and novel n-grams.
The generated poetry from TRAINING-BASED agents also exhibits group divergence
in terms of lexicons, styles and semantics. PROMPTING-BASED agents in our
framework also benefit from non-cooperative environments and a more diverse
ensemble of models with non-homogeneous agents has the potential to further
enhance diversity, with an increase of 7.0-17.5 pp according to our
experiments. However, PROMPTING-BASED agents show a decrease in lexical
diversity over time and do not exhibit the group-based divergence intended in
the social network. Our paper argues for a paradigm shift in creative tasks
such as automatic poetry generation to include social learning processes (via
LLM-based agent modeling) similar to human interaction.

摘要：儘管大型語言模型（LLM）在自動詩歌生成方面取得了重大進展，但生成的詩歌缺乏多樣性，而訓練過程與人類學習有很大不同。基於詩歌生成系統的學習過程應更像人類，且其輸出應更多樣化和新穎的論據，我們引入了一個基於社會學習的框架，在其中我們除了強調合作互動之外，還強調非合作互動以鼓勵多樣性。我們的實驗是 LLM 基於非合作環境的多主體系統在詩歌生成中的首次嘗試，採用了基於訓練的主體（GPT-2）和基於提示的主體（GPT-3 和 GPT-4）。我們根據 96k 首生成的詩歌進行的評估表明，我們的框架有利於基於訓練的主體的詩歌生成過程，導致 1) 多樣性增加 3.0-3.7 個百分點（pp），根據不同的新穎 n-gram，新穎性增加 5.6-11.3 pp。基於訓練的主體生成的詩歌在詞彙、風格和語義方面也表現出群體差異。我們框架中的基於提示的主體也受益於非合作環境，並且具有非同質主體的多樣化模型集合有可能進一步提高多樣性，根據我們的實驗，增加了 7.0-17.5 pp。然而，基於提示的主體隨著時間的推移表現出詞彙多樣性的下降，並且沒有表現出社交網路中預期的基於群體的差異。我們的論文主張在創意任務中進行範式轉變，例如自動詩歌生成，以納入類似於人類互動的社會學習過程（通過基於 LLM 的主體建模）。

##### **On the Limited Generalization Capability of the Implicit Reward Model Induced by Direct Preference Optimization**
2409.03650v1 by Yong Lin, Skyler Seto, Maartje ter Hoeve, Katherine Metcalf, Barry-John Theobald, Xuan Wang, Yizhe Zhang, Chen Huang, Tong Zhang

Reinforcement Learning from Human Feedback (RLHF) is an effective approach
for aligning language models to human preferences. Central to RLHF is learning
a reward function for scoring human preferences. Two main approaches for
learning a reward model are 1) training an EXplicit Reward Model (EXRM) as in
RLHF, and 2) using an implicit reward learned from preference data through
methods such as Direct Preference Optimization (DPO). Prior work has shown that
the implicit reward model of DPO (denoted as DPORM) can approximate an EXRM in
the limit. DPORM's effectiveness directly implies the optimality of the learned
policy, and also has practical implication for LLM alignment methods including
iterative DPO. However, it is unclear how well DPORM empirically matches the
performance of EXRM. This work studies the accuracy at distinguishing preferred
and rejected answers for both DPORM and EXRM. Our findings indicate that even
though DPORM fits the training dataset comparably, it generalizes less
effectively than EXRM, especially when the validation datasets contain
distribution shifts. Across five out-of-distribution settings, DPORM has a mean
drop in accuracy of 3% and a maximum drop of 7%. These findings highlight that
DPORM has limited generalization ability and substantiates the integration of
an explicit reward model in iterative DPO approaches.

摘要：人類回饋強化學習 (RLHF) 是一種有效的方法，可以將語言模型調整到人類偏好。RLHF 的核心是學習一個獎勵函數來評分人類偏好。學習獎勵模型的兩種主要方法為 1) 訓練一個明確獎勵模型 (EXRM)，如同 RLHF 中，2) 使用從偏好數據中學習到的隱含獎勵，透過直接偏好最佳化 (DPO) 等方法。先前的研究顯示，DPO 的隱含獎勵模型 (表示為 DPORM) 可在極限中近似 EXRM。DPORM 的效能直接暗示學習到的政策的最佳性，且對 LLM 調整方法（包括反覆 DPO）也有實際的意義。然而，尚不清楚 DPORM 在經驗上有多符合 EXRM 的效能。本研究探討區分 DPORM 和 EXRM 的偏好和拒絕答案的準確性。我們的發現顯示，儘管 DPORM 符合訓練資料集的程度相當，但其泛化效果不如 EXRM，特別是在驗證資料集包含分配轉移時。在五個非分配設定中，DPORM 的準確性平均下降 3%，最大下降 7%。這些發現強調 DPORM 的泛化能力有限，並證實了在反覆 DPO 方法中整合明確獎勵模型。

##### **Limited but consistent gains in adversarial robustness by co-training object recognition models with human EEG**
2409.03646v1 by Manshan Guo, Bhavin Choksi, Sari Sadiya, Alessandro T. Gifford, Martina G. Vilas, Radoslaw M. Cichy, Gemma Roig

In contrast to human vision, artificial neural networks (ANNs) remain
relatively susceptible to adversarial attacks. To address this vulnerability,
efforts have been made to transfer inductive bias from human brains to ANNs,
often by training the ANN representations to match their biological
counterparts. Previous works relied on brain data acquired in rodents or
primates using invasive techniques, from specific regions of the brain, under
non-natural conditions (anesthetized animals), and with stimulus datasets
lacking diversity and naturalness. In this work, we explored whether aligning
model representations to human EEG responses to a rich set of real-world images
increases robustness to ANNs. Specifically, we trained ResNet50-backbone models
on a dual task of classification and EEG prediction; and evaluated their EEG
prediction accuracy and robustness to adversarial attacks. We observed
significant correlation between the networks' EEG prediction accuracy, often
highest around 100 ms post stimulus onset, and their gains in adversarial
robustness. Although effect size was limited, effects were consistent across
different random initializations and robust for architectural variants. We
further teased apart the data from individual EEG channels and observed
strongest contribution from electrodes in the parieto-occipital regions. The
demonstrated utility of human EEG for such tasks opens up avenues for future
efforts that scale to larger datasets under diverse stimuli conditions with the
promise of stronger effects.

摘要：相較於人類視覺，人工神經網路 (ANN) 仍然
容易受到對抗攻擊。為了解決此弱點，
已致力於將歸納偏誤從人腦轉移到 ANN，
通常透過訓練 ANN 表徵以符合其生物
對應物。先前的研究依賴於在特定大腦區域中，使用侵入式技術在齧齒動物或靈長類動物中獲得的大腦資料，在非自然條件（麻醉動物）下，且刺激資料集缺乏多樣性和自然性。在這項研究中，我們探討了將模型表徵與人類 EEG 對應於豐富的真實世界影像集合，是否會增加 ANN 的穩健性。具體來說，我們在分類和 EEG 預測的雙重任務上訓練了 ResNet50 骨幹模型；並評估其 EEG 預測準確度和對抗攻擊的穩健性。我們觀察到網路的 EEG 預測準確度之間存在顯著相關性，通常在刺激開始後約 100 毫秒時最高，以及它們在對抗穩健性方面的增益。儘管效應量有限，但效應在不同的隨機初始化和架構變體中是一致的。我們進一步區分來自個別 EEG 通道的資料，並觀察到來自頂枕區域電極的最強貢獻。人類 EEG 在此類任務中展現的效用，為未來在不同刺激條件下擴展到更大資料集的努力開啟了道路，並有望產生更強大的效應。

##### **CDM: A Reliable Metric for Fair and Accurate Formula Recognition Evaluation**
2409.03643v1 by Bin Wang, Fan Wu, Linke Ouyang, Zhuangcheng Gu, Rui Zhang, Renqiu Xia, Bo Zhang, Conghui He

Formula recognition presents significant challenges due to the complicated
structure and varied notation of mathematical expressions. Despite continuous
advancements in formula recognition models, the evaluation metrics employed by
these models, such as BLEU and Edit Distance, still exhibit notable
limitations. They overlook the fact that the same formula has diverse
representations and is highly sensitive to the distribution of training data,
thereby causing the unfairness in formula recognition evaluation. To this end,
we propose a Character Detection Matching (CDM) metric, ensuring the evaluation
objectivity by designing a image-level rather than LaTex-level metric score.
Specifically, CDM renders both the model-predicted LaTeX and the ground-truth
LaTeX formulas into image-formatted formulas, then employs visual feature
extraction and localization techniques for precise character-level matching,
incorporating spatial position information. Such a spatially-aware and
character-matching method offers a more accurate and equitable evaluation
compared with previous BLEU and Edit Distance metrics that rely solely on
text-based character matching. Experimentally, we evaluated various formula
recognition models using CDM, BLEU, and ExpRate metrics. Their results
demonstrate that the CDM aligns more closely with human evaluation standards
and provides a fairer comparison across different models by eliminating
discrepancies caused by diverse formula representations.

摘要：公式辨識由於數學表達式的複雜結構和多樣符號，因此面臨重大挑戰。儘管公式辨識模型持續進步，這些模型所採用的評估指標，例如 BLEU 和編輯距離，仍存在顯著的限制。它們忽略了同一個公式有多種表示法，且對訓練資料的分配高度敏感，從而導致公式辨識評估的不公平性。為此，我們提出一個字元偵測比對 (CDM) 指標，透過設計一個影像層級而非 LaTex 層級的指標分數，確保評估的客觀性。具體而言，CDM 將模型預測的 LaTeX 和真實的 LaTeX 公式都轉換成影像格式的公式，然後採用視覺特徵萃取和定位技術進行精確的字元層級比對，並納入空間位置資訊。這種具有空間感知和字元比對的方法，與僅依賴於基於文字的字元比對的先前 BLEU 和編輯距離指標相比，提供了更準確和公平的評估。在實驗中，我們使用 CDM、BLEU 和 ExpRate 指標評估了各種公式辨識模型。其結果表明，CDM 與人類評估標準更為一致，並透過消除由不同公式表示法所造成的差異，提供了不同模型之間更公平的比較。

##### **Attend First, Consolidate Later: On the Importance of Attention in Different LLM Layers**
2409.03621v1 by Amit Ben Artzy, Roy Schwartz

In decoder-based LLMs, the representation of a given layer serves two
purposes: as input to the next layer during the computation of the current
token; and as input to the attention mechanism of future tokens. In this work,
we show that the importance of the latter role might be overestimated. To show
that, we start by manipulating the representations of previous tokens; e.g. by
replacing the hidden states at some layer k with random vectors. Our
experimenting with four LLMs and four tasks show that this operation often
leads to small to negligible drop in performance. Importantly, this happens if
the manipulation occurs in the top part of the model-k is in the final 30-50%
of the layers. In contrast, doing the same manipulation in earlier layers might
lead to chance level performance. We continue by switching the hidden state of
certain tokens with hidden states of other tokens from another prompt; e.g.,
replacing the word "Italy" with "France" in "What is the capital of Italy?". We
find that when applying this switch in the top 1/3 of the model, the model
ignores it (answering "Rome"). However if we apply it before, the model
conforms to the switch ("Paris"). Our results hint at a two stage process in
transformer-based LLMs: the first part gathers input from previous tokens,
while the second mainly processes that information internally.

摘要：在基於解碼器的 LLM 中，給定層的表示有兩個目的：作為當前代幣計算期間下一層的輸入；以及作為未來代幣的注意力機制的輸入。在這項工作中，我們表明後者的重要性可能被高估了。為了證明這一點，我們從操縱先前代幣的表示開始；例如，通過用隨機向量替換某些層 k 的隱藏狀態。我們對四個 LLM 和四個任務的實驗表明，此操作通常會導致性能下降很小或可以忽略不計。重要的是，如果操作發生在模型的頂部，則會發生這種情況——k 在最後 30-50% 的層中。相比之下，在較早的層中進行相同的操作可能會導致機會級別的性能。我們繼續將某些代幣的隱藏狀態與來自另一個提示的其他代幣的隱藏狀態進行切換；例如，在「義大利的首都是什麼？」中將「義大利」替換為「法國」。我們發現，當在模型的前 1/3 中應用此切換時，模型會忽略它（回答「羅馬」）。但是，如果我們在之前應用它，模型會符合切換（「巴黎」）。我們的結果暗示了基於Transformer的 LLM 中的兩階段過程：第一部分從先前的代幣收集輸入，而第二部分主要在內部處理該信息。

##### **100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances**
2409.03563v1 by Lorenzo Pacchiardi, Lucy G. Cheke, José Hernández-Orallo

Predicting the performance of LLMs on individual task instances is essential
to ensure their reliability in high-stakes applications. To do so, a
possibility is to evaluate the considered LLM on a set of task instances and
train an assessor to predict its performance based on features of the
instances. However, this approach requires evaluating each new LLM on a
sufficiently large set of task instances to train an assessor specific to it.
In this work, we leverage the evaluation results of previously tested LLMs to
reduce the number of evaluations required to predict the performance of a new
LLM. In practice, we propose to test the new LLM on a small set of reference
instances and train a generic assessor which predicts the performance of the
LLM on an instance based on the performance of the former on the reference set
and features of the instance of interest. We conduct empirical studies on
HELM-Lite and KindsOfReasoning, a collection of existing reasoning datasets
that we introduce, where we evaluate all instruction-fine-tuned OpenAI models
until the January 2024 version of GPT4. When predicting performance on
instances with the same distribution as those used to train the generic
assessor, we find this achieves performance comparable to the LLM-specific
assessors trained on the full set of instances. Additionally, we find that
randomly selecting the reference instances performs as well as some advanced
selection methods we tested. For out of distribution, however, no clear winner
emerges and the overall performance is worse, suggesting that the inherent
predictability of LLMs is low.

摘要：預測 LLM 在個別任務實例中的表現對於確保它們在高風險應用中的可靠性至關重要。為此，一種可能性是在一組任務實例上評估所考慮的 LLM，並訓練評估器根據實例的特徵來預測其表現。然而，這種方法需要在足夠大的任務實例集上評估每個新的 LLM，以訓練專門針對它的評估器。在這項工作中，我們利用先前測試的 LLM 的評估結果來減少預測新 LLM 的表現所需的評估次數。在實務上，我們建議在少量參考實例上測試新的 LLM，並訓練一個通用評估器，該評估器根據前者在參考集上的表現和感興趣實例的特徵來預測 LLM 在實例上的表現。我們對 HELM-Lite 和 KindsOfReasoning 進行實證研究，這是一個我們介紹的現有推理資料集集合，我們在其中評估所有微調 OpenAI 模型，直到 GPT4 的 2024 年 1 月版本。在預測與用於訓練通用評估器的那些具有相同分佈的實例上的表現時，我們發現這達到了與在全組實例上訓練的 LLM 專用評估器相當的表現。此外，我們發現隨機選擇參考實例的表現與我們測試的一些進階選擇方法一樣好。然而，對於分佈外，沒有明確的贏家出現，而且整體表現較差，這表明 LLM 的內在可預測性較低。

##### **DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture**
2409.03550v1 by Qianlong Xiang, Miao Zhang, Yuzhang Shang, Jianlong Wu, Yan Yan, Liqiang Nie

Diffusion models (DMs) have demonstrated exceptional generative capabilities
across various areas, while they are hindered by slow inference speeds and high
computational demands during deployment. The most common way to accelerate DMs
involves reducing the number of denoising steps during generation, achieved
through faster sampling solvers or knowledge distillation (KD). In contrast to
prior approaches, we propose a novel method that transfers the capability of
large pretrained DMs to faster architectures. Specifically, we employ KD in a
distinct manner to compress DMs by distilling their generative ability into
more rapid variants. Furthermore, considering that the source data is either
unaccessible or too enormous to store for current generative models, we
introduce a new paradigm for their distillation without source data, termed
Data-Free Knowledge Distillation for Diffusion Models (DKDM). Generally, our
established DKDM framework comprises two main components: 1) a DKDM objective
that uses synthetic denoising data produced by pretrained DMs to optimize
faster DMs without source data, and 2) a dynamic iterative distillation method
that flexibly organizes the synthesis of denoising data, preventing it from
slowing down the optimization process as the generation is slow. To our
knowledge, this is the first attempt at using KD to distill DMs into any
architecture in a data-free manner. Importantly, our DKDM is orthogonal to most
existing acceleration methods, such as denoising step reduction, quantization
and pruning. Experiments show that our DKDM is capable of deriving 2x faster
DMs with performance remaining on par with the baseline. Notably, our DKDM
enables pretrained DMs to function as "datasets" for training new DMs.

摘要：擴散模型 (DM) 已在各種領域展現出卓越的生成能力，但它們在部署期間受到推理速度慢和高運算需求的阻礙。加速 DM 最常見的方法包括減少生成期間的去噪步驟數，透過更快速的取樣求解器或知識蒸餾 (KD) 來實現。與先前的做法不同，我們提出了一種新方法，將大型預訓練 DM 的能力轉移到更快的架構中。具體來說，我們以不同方式採用 KD，透過將其生成能力蒸餾到更快速的變體中來壓縮 DM。此外，考慮到原始資料對於當前生成模型來說無法存取或過於龐大，我們引入了在沒有原始資料的情況下進行蒸餾的新範例，稱為擴散模型的無資料知識蒸餾 (DKDM)。一般來說，我們建立的 DKDM 框架包含兩個主要組成部分：1) 一個 DKDM 目標，它使用預訓練 DM 產生的合成去噪資料，在沒有原始資料的情況下最佳化更快速的 DM，以及 2) 一個動態反覆蒸餾方法，它靈活地組織去噪資料的合成，防止它在生成速度慢時拖慢最佳化流程。據我們所知，這是第一次嘗試使用 KD 以無資料的方式將 DM 蒸餾到任何架構中。重要的是，我們的 DKDM 與大多數現有的加速方法正交，例如去噪步驟減少、量化和剪枝。實驗表明，我們的 DKDM 能夠衍生出速度快 2 倍的 DM，其效能仍與基線相當。值得注意的是，我們的 DKDM 使預訓練的 DM 能夠作為「資料集」，用於訓練新的 DM。

##### **Prediction Accuracy & Reliability: Classification and Object Localization under Distribution Shift**
2409.03543v1 by Fabian Diet, Moussa Kassem Sbeyti, Michelle Karg

Natural distribution shift causes a deterioration in the perception
performance of convolutional neural networks (CNNs). This comprehensive
analysis for real-world traffic data addresses: 1) investigating the effect of
natural distribution shift and weather augmentations on both detection quality
and confidence estimation, 2) evaluating model performance for both
classification and object localization, and 3) benchmarking two common
uncertainty quantification methods - Ensembles and different variants of
Monte-Carlo (MC) Dropout - under natural and close-to-natural distribution
shift. For this purpose, a novel dataset has been curated from publicly
available autonomous driving datasets. The in-distribution (ID) data is based
on cutouts of a single object, for which both class and bounding box
annotations are available. The six distribution-shift datasets cover adverse
weather scenarios, simulated rain and fog, corner cases, and
out-of-distribution data. A granular analysis of CNNs under distribution shift
allows to quantize the impact of different types of shifts on both, task
performance and confidence estimation: ConvNeXt-Tiny is more robust than
EfficientNet-B0; heavy rain degrades classification stronger than localization,
contrary to heavy fog; integrating MC-Dropout into selected layers only has the
potential to enhance task performance and confidence estimation, whereby the
identification of these layers depends on the type of distribution shift and
the considered task.

摘要：自然分布轉移會導致卷積神經網路 (CNN) 的感知效能下降。針對真實世界交通數據的這項全面分析探討了：1) 調查自然分布轉移和天氣增強對偵測品質和信心估計的影響，2) 評估模型效能，同時涵蓋分類和物件定位，以及 3) 在自然和接近自然的分布轉移下，對兩種常見的不確定性量化方法進行基準測試，分別為集成法和蒙地卡羅 (MC) Dropout 的不同變體。為此，已經從公開的自動駕駛數據集中策劃了一個新穎的數據集。分佈內 (ID) 資料是根據單一物件的切口建立，而該物件同時有類別和邊界框註解。六個分佈轉移數據集涵蓋了惡劣天氣情境、模擬雨和霧、臨界情況和分佈外資料。在分佈轉移下對 CNN 進行細緻分析，可以量化不同類型轉移對任務效能和信心估計的影響：ConvNeXt-Tiny 比 EfficientNet-B0 更強大；大雨比濃霧更嚴重地降低分類，這與濃霧相反；僅將 MC-Dropout 整合到選定的層中，就有可能提升任務效能和信心估計，而這些層的識別取決於分佈轉移的類型和考量的任務。

##### **LMLT: Low-to-high Multi-Level Vision Transformer for Image Super-Resolution**
2409.03516v1 by Jeongsoo Kim, Jongho Nang, Junsuk Choe

Recent Vision Transformer (ViT)-based methods for Image Super-Resolution have
demonstrated impressive performance. However, they suffer from significant
complexity, resulting in high inference times and memory usage. Additionally,
ViT models using Window Self-Attention (WSA) face challenges in processing
regions outside their windows. To address these issues, we propose the
Low-to-high Multi-Level Transformer (LMLT), which employs attention with
varying feature sizes for each head. LMLT divides image features along the
channel dimension, gradually reduces spatial size for lower heads, and applies
self-attention to each head. This approach effectively captures both local and
global information. By integrating the results from lower heads into higher
heads, LMLT overcomes the window boundary issues in self-attention. Extensive
experiments show that our model significantly reduces inference time and GPU
memory usage while maintaining or even surpassing the performance of
state-of-the-art ViT-based Image Super-Resolution methods. Our codes are
availiable at https://github.com/jwgdmkj/LMLT.

摘要：最近基于视觉转换器 (ViT) 的图像超分辨率方法已经证明了令人印象深刻的性能。然而，它们遭受着巨大的复杂性，导致较高的推理时间和内存使用。此外，使用窗口自注意力 (WSA) 的 ViT 模型在处理窗口外的区域时面临挑战。为了解决这些问题，我们提出了低到高的多级转换器 (LMLT)，它为每个头采用具有不同特征大小的注意力。LMLT 沿通道维度划分图像特征，逐渐减小较低头的空间大小，并对每个头应用自注意力。这种方法有效地捕获了局部和全局信息。通过将较低头的结果整合到较高头中，LMLT 克服了自注意力中的窗口边界问题。大量的实验表明，我们的模型显着减少了推理时间和 GPU 内存使用，同时保持或甚至超越了最先进的基于 ViT 的图像超分辨率方法的性能。我们的代码可在 https://github.com/jwgdmkj/LMLT 获得。

##### **From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents**
2409.03512v1 by Jifan Yu, Zheyuan Zhang, Daniel Zhang-li, Shangqing Tu, Zhanxin Hao, Rui Miao Li, Haoxuan Li, Yuanchun Wang, Hanming Li, Linlu Gong, Jie Cao, Jiayin Lin, Jinchang Zhou, Fei Qin, Haohua Wang, Jianxiao Jiang, Lijun Deng, Yisi Zhan, Chaojun Xiao, Xusheng Dai, Xuan Yan, Nianyi Lin, Nan Zhang, Ruixin Ni, Yang Dang, Lei Hou, Yu Zhang, Xu Han, Manli Li, Juanzi Li, Zhiyuan Liu, Huiqin Liu, Maosong Sun

Since the first instances of online education, where courses were uploaded to
accessible and shared online platforms, this form of scaling the dissemination
of human knowledge to reach a broader audience has sparked extensive discussion
and widespread adoption. Recognizing that personalized learning still holds
significant potential for improvement, new AI technologies have been
continuously integrated into this learning format, resulting in a variety of
educational AI applications such as educational recommendation and intelligent
tutoring. The emergence of intelligence in large language models (LLMs) has
allowed for these educational enhancements to be built upon a unified
foundational model, enabling deeper integration. In this context, we propose
MAIC (Massive AI-empowered Course), a new form of online education that
leverages LLM-driven multi-agent systems to construct an AI-augmented
classroom, balancing scalability with adaptivity. Beyond exploring the
conceptual framework and technical innovations, we conduct preliminary
experiments at Tsinghua University, one of China's leading universities.
Drawing from over 100,000 learning records of more than 500 students, we obtain
a series of valuable observations and initial analyses. This project will
continue to evolve, ultimately aiming to establish a comprehensive open
platform that supports and unifies research, technology, and applications in
exploring the possibilities of online education in the era of large model AI.
We envision this platform as a collaborative hub, bringing together educators,
researchers, and innovators to collectively explore the future of AI-driven
online education.

摘要：<paragraph>自線上教育首次出現，課程上傳至可存取且共用的線上平台以來，這種擴展人類知識傳播以接觸更廣泛受眾的形式，已引發廣泛討論並被廣泛採用。認知到個人化學習仍具有顯著的改善潛力，新的 AI 技術已持續整合到這種學習格式中，產生了各種教育 AI 應用程式，例如教育建議和智慧型家教。大型語言模型 (LLM) 中出現的智慧，已允許這些教育增強功能建立在統一的基礎模型上，實現更深入的整合。在此背景下，我們提出 MAIC（大規模 AI 驅動課程），一種新的線上教育形式，利用 LLM 驅動的多重代理系統來建構 AI 增強型教室，在可擴充性與適應性之間取得平衡。除了探討概念架構和技術創新之外，我們還在中國頂尖大學之一的清華大學進行初步實驗。從 500 多名學生的 10 萬多筆學習記錄中，我們獲得一系列有價值的觀察和初步分析。此專案將持續演進，最終目標是建立一個全面的開放平台，支援並統一研究、技術和應用程式，以探索大型模型 AI 時代線上教育的可能性。我們將這個平台視為一個協作中心，匯集教育工作者、研究人員和創新者，共同探索 AI 驅動線上教育的未來。</paragraph>

##### **Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation**
2409.03470v1 by Prerak Mody, Nicolas F. Chaves-de-Plaza, Chinmay Rao, Eleftheria Astrenidou, Mischa de Ridder, Nienke Hoekstra, Klaus Hildebrandt, Marius Staring

Increased usage of automated tools like deep learning in medical image
segmentation has alleviated the bottleneck of manual contouring. This has
shifted manual labour to quality assessment (QA) of automated contours which
involves detecting errors and correcting them. A potential solution to
semi-automated QA is to use deep Bayesian uncertainty to recommend potentially
erroneous regions, thus reducing time spent on error detection. Previous work
has investigated the correspondence between uncertainty and error, however, no
work has been done on improving the "utility" of Bayesian uncertainty maps such
that it is only present in inaccurate regions and not in the accurate ones. Our
work trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which
promotes uncertainty to be present only in inaccurate regions. We apply this
method on datasets of two radiotherapy body sites, c.f. head-and-neck CT and
prostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated
against voxel inaccuracies using Receiver Operating Characteristic (ROC) and
Precision-Recall (PR) curves. Numerical results show that when compared to the
Bayesian baseline the proposed method successfully suppresses uncertainty for
accurate voxels, with similar presence of uncertainty for inaccurate voxels.
Code to reproduce experiments is available at
https://github.com/prerakmody/bayesuncertainty-error-correspondence

摘要：深度學習等自動化工具在醫學影像分割中使用率提升，減輕了手動輪廓描繪的瓶頸。這已將手動勞動轉移到自動輪廓的品質評估 (QA)，其中包含偵測錯誤並修正它們。半自動化 QA 的潛在解決方案是使用深度貝氏不確定性來建議潛在的錯誤區域，從而減少花費在錯誤偵測上的時間。先前的研究已調查不確定性和錯誤之間的對應關係，然而，尚未對改善貝氏不確定性地圖的「效用」進行研究，以使其僅出現在不準確區域，而不出現在準確區域。我們的研究使用準確度對抗不確定性 (AvU) 損失來訓練 FlipOut 模型，這會促使不確定性僅出現在不準確區域。我們將此方法應用於兩個放射治療部位的資料集，即頭頸部電腦斷層掃描和前列腺核磁共振掃描。使用接收器操作特性 (ROC) 和精確度召回率 (PR) 曲線，針對體素不準確性評估不確定性熱圖（即預測熵）。數值結果顯示，與貝氏基準相比，所提出的方法成功地抑制準確體素的不確定性，對於不準確體素的不確定性存在類似情況。可在 https://github.com/prerakmody/bayesuncertainty-error-correspondence 取得重現實驗的程式碼

##### **Characterizing Massive Activations of Attention Mechanism in Graph Neural Networks**
2409.03463v1 by Lorenzo Bini, Marco Sorbi, Stephane Marchand-Maillet

Graph Neural Networks (GNNs) have become increasingly popular for effectively
modeling data with graph structures. Recently, attention mechanisms have been
integrated into GNNs to improve their ability to capture complex patterns. This
paper presents the first comprehensive study revealing a critical, unexplored
consequence of this integration: the emergence of Massive Activations (MAs)
within attention layers. We introduce a novel method for detecting and
analyzing MAs, focusing on edge features in different graph transformer
architectures. Our study assesses various GNN models using benchmark datasets,
including ZINC, TOX21, and PROTEINS. Key contributions include (1) establishing
the direct link between attention mechanisms and MAs generation in GNNs, (2)
developing a robust definition and detection method for MAs based on activation
ratio distributions, (3) introducing the Explicit Bias Term (EBT) as a
potential countermeasure and exploring it as an adversarial framework to assess
models robustness based on the presence or absence of MAs. Our findings
highlight the prevalence and impact of attention-induced MAs across different
architectures, such as GraphTransformer, GraphiT, and SAN. The study reveals
the complex interplay between attention mechanisms, model architecture, dataset
characteristics, and MAs emergence, providing crucial insights for developing
more robust and reliable graph models.

摘要：圖形神經網路 (GNN) 已變得越來越受歡迎，可有效建模具有圖形結構的資料。最近，注意力機制已被整合到 GNN 中，以提升其擷取複雜模式的能力。本文提出第一個全面的研究，揭示了這種整合的一個關鍵、未探索的後果：注意力層中出現大量活化 (MA)。我們引入一種新的方法來偵測和分析 MA，重點放在不同圖形Transformer架構中的邊緣特徵。我們的研究使用基準資料集評估各種 GNN 模型，包括 ZINC、TOX21 和 PROTEINS。主要貢獻包括：(1) 建立注意力機制和 GNN 中 MA 產生的直接連結，(2) 根據活化率分佈開發一個穩健的定義和偵測 MA 的方法，(3) 引入顯式偏差項 (EBT) 作為一個潛在的對策，並將其作為一個對抗框架來探索模型的穩健性，根據 MA 的存在或不存在。我們的研究結果突顯了注意力誘導的 MA 在不同架構（例如 GraphTransformer、GraphiT 和 SAN）中的普遍性和影響。該研究揭示了注意力機制、模型架構、資料集特徵和 MA 出現之間的複雜交互作用，為開發更穩健、更可靠的圖形模型提供了重要的見解。

##### **How Much Data is Enough Data? Fine-Tuning Large Language Models for In-House Translation: Performance Evaluation Across Multiple Dataset Sizes**
2409.03454v1 by Inacio Vieira, Will Allred, Seamus Lankford, Sheila Castilho Monteiro De Sousa, Andy Way

Decoder-only LLMs have shown impressive performance in MT due to their
ability to learn from extensive datasets and generate high-quality
translations. However, LLMs often struggle with the nuances and style required
for organisation-specific translation. In this study, we explore the
effectiveness of fine-tuning Large Language Models (LLMs), particularly Llama 3
8B Instruct, leveraging translation memories (TMs), as a valuable resource to
enhance accuracy and efficiency. We investigate the impact of fine-tuning the
Llama 3 model using TMs from a specific organisation in the software sector.
Our experiments cover five translation directions across languages of varying
resource levels (English to Brazilian Portuguese, Czech, German, Finnish, and
Korean). We analyse diverse sizes of training datasets (1k to 207k segments) to
evaluate their influence on translation quality. We fine-tune separate models
for each training set and evaluate their performance based on automatic
metrics, BLEU, chrF++, TER, and COMET. Our findings reveal improvement in
translation performance with larger datasets across all metrics. On average,
BLEU and COMET scores increase by 13 and 25 points, respectively, on the
largest training set against the baseline model. Notably, there is a
performance deterioration in comparison with the baseline model when
fine-tuning on only 1k and 2k examples; however, we observe a substantial
improvement as the training dataset size increases. The study highlights the
potential of integrating TMs with LLMs to create bespoke translation models
tailored to the specific needs of businesses, thus enhancing translation
quality and reducing turn-around times. This approach offers a valuable insight
for organisations seeking to leverage TMs and LLMs for optimal translation
outcomes, especially in narrower domains.

摘要：<paragraph>僅解碼的 LLM 在機器翻譯中展現出令人驚豔的效能，因為它們能從廣泛的資料集學習，並產生高品質的翻譯。然而，LLM 通常難以處理組織特定翻譯所需的細微差別和風格。在此研究中，我們探討微調大型語言模型 (LLM) 的有效性，特別是 Llama 3 8B Instruct，利用翻譯記憶體 (TM) 作為有價值的資源，以提升準確度和效率。我們探討使用來自軟體部門特定組織的 TM 微調 Llama 3 模型的影響。我們的實驗涵蓋五種翻譯方向，橫跨不同資源層級的語言（英語到巴西葡萄牙語、捷克語、德語、芬蘭語和韓語）。我們分析不同大小的訓練資料集（1k 到 207k 段落），以評估其對翻譯品質的影響。我們針對每個訓練集微調不同的模型，並根據自動化指標（BLEU、chrF++、TER 和 COMET）評估其效能。我們的研究結果顯示，在所有指標中，隨著資料集的擴大，翻譯效能都有所提升。平均而言，在最大的訓練集上，與基準模型相比，BLEU 和 COMET 分數分別增加了 13 和 25 分。值得注意的是，當僅針對 1k 和 2k 個範例進行微調時，與基準模型相比，效能會下降；然而，我們觀察到隨著訓練資料集大小的增加，效能有顯著的提升。這項研究強調了將 TM 與 LLM 整合以建立客製化翻譯模型的潛力，這些模型專門針對企業的特定需求，從而提升翻譯品質並縮短週轉時間。此方法為尋求利用 TM 和 LLM 以獲得最佳翻譯成果的組織提供了有價值的見解，尤其是在較狹窄的領域中。</paragraph>

##### **Fine-tuning large language models for domain adaptation: Exploration of training strategies, scaling, model merging and synergistic capabilities**
2409.03444v1 by Wei Lu, Rachel K. Luu, Markus J. Buehler

The advancement of Large Language Models (LLMs) for domain applications in
fields such as materials science and engineering depends on the development of
fine-tuning strategies that adapt models for specialized, technical
capabilities. In this work, we explore the effects of Continued Pretraining
(CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization
approaches, including Direct Preference Optimization (DPO) and Odds Ratio
Preference Optimization (ORPO), on fine-tuned LLM performance. Our analysis
shows how these strategies influence model outcomes and reveals that the
merging of multiple fine-tuned models can lead to the emergence of capabilities
that surpass the individual contributions of the parent models. We find that
model merging leads to new functionalities that neither parent model could
achieve alone, leading to improved performance in domain-specific assessments.
Experiments with different model architectures are presented, including Llama
3.1 8B and Mistral 7B models, where similar behaviors are observed. Exploring
whether the results hold also for much smaller models, we use a tiny LLM with
1.7 billion parameters and show that very small LLMs do not necessarily feature
emergent capabilities under model merging, suggesting that model scaling may be
a key component. In open-ended yet consistent chat conversations between a
human and AI models, our assessment reveals detailed insights into how
different model variants perform and show that the smallest model achieves a
high intelligence score across key criteria including reasoning depth,
creativity, clarity, and quantitative precision. Other experiments include the
development of image generation prompts based on disparate biological material
design concepts, to create new microstructures, architectural concepts, and
urban design based on biological materials-inspired construction principles.

摘要：大型語言模型 (LLM) 在材料科學和工程等領域的領域應用進步取決於微調策略的發展，這些策略可調整模型以適應專業的技術能力。在這項工作中，我們探討了持續預訓練 (CPT)、監督微調 (SFT) 和各種基於偏好的最佳化方法（包括直接偏好最佳化 (DPO) 和機率比偏好最佳化 (ORPO)）對微調後的 LLM 效能的影響。我們的分析顯示這些策略如何影響模型結果，並揭示多個微調模型的合併可能導致出現超越父模型個別貢獻的能力。我們發現模型合併導致新的功能，而任何父模型都無法單獨實現，從而提高特定領域評估的效能。我們展示了使用不同模型架構的實驗，包括 Llama 3.1 8B 和 Mistral 7B 模型，其中觀察到類似的行為。為了探討結果是否也適用於更小的模型，我們使用一個只有 17 億個參數的小型 LLM，並顯示非常小的 LLM 在模型合併下不一定具有浮現的能力，這表示模型縮放可能是關鍵組成部分。在人類和 AI 模型之間開放式但一致的聊天對話中，我們的評估揭示了不同模型變體的執行方式的詳細見解，並顯示最小的模型在包括推理深度、創造力、清晰度和定量精確度等關鍵標準中都獲得了很高的智力分數。其他實驗包括基於不同的生物材料設計概念開發圖像生成提示，以根據受生物材料啟發的建築原理建立新的微結構、建築概念和城市設計。

##### **Rx Strategist: Prescription Verification using LLM Agents System**
2409.03440v1 by Phuc Phan Van, Dat Nguyen Minh, An Dinh Ngoc, Huy Phan Thanh

To protect patient safety, modern pharmaceutical complexity demands strict
prescription verification. We offer a new approach - Rx Strategist - that makes
use of knowledge graphs and different search strategies to enhance the power of
Large Language Models (LLMs) inside an agentic framework. This multifaceted
technique allows for a multi-stage LLM pipeline and reliable information
retrieval from a custom-built active ingredient database. Different facets of
prescription verification, such as indication, dose, and possible drug
interactions, are covered in each stage of the pipeline. We alleviate the
drawbacks of monolithic LLM techniques by spreading reasoning over these
stages, improving correctness and reliability while reducing memory demands.
Our findings demonstrate that Rx Strategist surpasses many current LLMs,
achieving performance comparable to that of a highly experienced clinical
pharmacist. In the complicated world of modern medications, this combination of
LLMs with organized knowledge and sophisticated search methods presents a
viable avenue for reducing prescription errors and enhancing patient outcomes.

摘要：為了保護患者安全，現代藥品複雜性要求嚴格的處方驗證。我們提供一種新方法 - Rx Strategist - 它利用知識圖譜和不同的搜尋策略來增強代理架構內大型語言模型 (LLM) 的功能。這種多方面的技術允許多階段的 LLM 管線和從自訂主動成分資料庫中可靠地擷取資訊。處方驗證的不同面向，例如適應症、劑量和可能的藥物交互作用，都在管線的每個階段中涵蓋。我們透過將推理分散在這些階段來減輕單一 LLM 技術的缺點，同時提高正確性和可靠性，並減少記憶體需求。我們的研究結果表明，Rx Strategist 超越許多現有的 LLM，達到與經驗豐富的臨床藥劑師相當的表現。在現代藥物複雜的世界中，這種將 LLM 與有組織的知識和先進搜尋方法相結合，為減少處方錯誤和改善患者預後提供了可行的途徑。

##### **KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale**
2409.03439v1 by Wei Gao, Jingqiang Wang, Xinv Zhu, Jun Zhong, Yue Shen, Youshuang Ding

We would like industrial robots to handle unstructured environments with
cameras and perception pipelines. In contrast to traditional industrial robots
that replay offline-crafted trajectories, online behavior planning is required
for these perception-guided industrial applications. Aside from perception and
planning algorithms, deploying perception-guided manipulators also requires
substantial effort in integration. One approach is writing scripts in a
traditional language (such as Python) to construct the planning problem and
perform integration with other algorithmic modules & external devices. While
scripting in Python is feasible for a handful of robots and applications,
deploying perception-guided manipulation at scale (e.g., more than 10000 robot
workstations in over 2000 customer sites) becomes intractable. To resolve this
challenge, we propose a Domain-Specific Language (DSL) for perception-guided
manipulation applications. To scale up the deployment,our DSL provides: 1) an
easily accessible interface to construct & solve a sub-class of Task and Motion
Planning (TAMP) problems that are important in practical applications; and 2) a
mechanism to implement flexible control flow to perform integration and address
customized requirements of distinct industrial application. Combined with an
intuitive graphical programming frontend, our DSL is mainly used by machine
operators without coding experience in traditional programming languages.
Within hours of training, operators are capable of orchestrating interesting
sophisticated manipulation behaviors with our DSL. Extensive practical
deployments demonstrate the efficacy of our method.

摘要：我們希望工業機器人能透過相機和感知管道來處理非結構化環境。與傳統工業機器人重播離線製作的軌跡不同，這些感知導向的工業應用需要線上行為規劃。除了感知和規劃演算法外，部署感知導向的機械手還需要大量的整合工作。一種方法是用傳統語言（例如 Python）撰寫腳本，以建構規劃問題並與其他演算法模組和外部裝置進行整合。雖然用 Python 撰寫腳本對少數機器人和應用程式來說是可行的，但要大規模部署感知導向的機械手（例如，超過 2000 個客戶地點的 10000 個機器人工作站）就會變得難以處理。為了解決這個挑戰，我們提出了一個感知導向機械手應用程式的特定領域語言 (DSL)。為了擴大部署規模，我們的 DSL 提供：1) 一個易於存取的介面，用於建構和解決在實際應用中很重要的任務和動作規劃 (TAMP) 問題的子類別；以及 2) 一個實作彈性控制流程的機制，以執行整合並滿足不同工業應用程式的自訂需求。我們的 DSL 結合了一個直覺的圖形化程式設計前端，主要由沒有傳統程式語言編碼經驗的機器操作員使用。經過數小時的訓練，操作員就能用我們的 DSL 編排出有趣且複雜的機械手行為。廣泛的實際部署證明了我們方法的有效性。

##### **Reinforcement Learning Approach to Optimizing Profilometric Sensor Trajectories for Surface Inspection**
2409.03429v1 by Sara Roos-Hoefgeest, Mario Roos-Hoefgeest, Ignacio Alvarez, Rafael C. González

High-precision surface defect detection in manufacturing is essential for
ensuring quality control. Laser triangulation profilometric sensors are key to
this process, providing detailed and accurate surface measurements over a line.
To achieve a complete and precise surface scan, accurate relative motion
between the sensor and the workpiece is required. It is crucial to control the
sensor pose to maintain optimal distance and relative orientation to the
surface. It is also important to ensure uniform profile distribution throughout
the scanning process. This paper presents a novel Reinforcement Learning (RL)
based approach to optimize robot inspection trajectories for profilometric
sensors. Building upon the Boustrophedon scanning method, our technique
dynamically adjusts the sensor position and tilt to maintain optimal
orientation and distance from the surface, while also ensuring a consistent
profile distance for uniform and high-quality scanning. Utilizing a simulated
environment based on the CAD model of the part, we replicate real-world
scanning conditions, including sensor noise and surface irregularities. This
simulation-based approach enables offline trajectory planning based on CAD
models. Key contributions include the modeling of the state space, action
space, and reward function, specifically designed for inspection applications
using profilometric sensors. We use Proximal Policy Optimization (PPO)
algorithm to efficiently train the RL agent, demonstrating its capability to
optimize inspection trajectories with profilometric sensors. To validate our
approach, we conducted several experiments where a model trained on a specific
training piece was tested on various parts in simulation. Also, we conducted a
real-world experiment by executing the optimized trajectory, generated offline
from a CAD model, to inspect a part using a UR3e robotic arm model.

摘要：在製造業中，高精度的表面缺陷偵測對於確保品質管控至關重要。雷射三角測量輪廓儀感測器是此過程中關鍵的元件，能夠提供一條線上詳細且精確的表面測量。為了達成完整且精確的表面掃描，感測器和工件之間需要精確的相對運動。控制感測器姿勢以維持與表面之間最佳距離和相對方位至關重要。在整個掃描過程中確保均勻的輪廓分佈也很重要。本文提出了一種基於強化學習 (RL) 的新穎方法，用於優化輪廓儀感測器的機器人檢測軌跡。我們的技術建立在 Boustrophedon 掃描方法之上，可以動態調整感測器的位置和傾斜度，以維持與表面的最佳方位和距離，同時也確保一致的輪廓距離，以進行均勻且高品質的掃描。利用基於零件 CAD 模型的模擬環境，我們複製了真實世界的掃描條件，包括感測器雜訊和表面不規則性。這種基於模擬的方法能夠根據 CAD 模型進行離線軌跡規劃。主要的貢獻包括狀態空間、動作空間和獎勵函數的建模，這些函數專門設計用於使用輪廓儀感測器的檢測應用。我們使用近端策略最佳化 (PPO) 演算法來有效訓練 RL 代理，展示其優化使用輪廓儀感測器的檢測軌跡的能力。為了驗證我們的做法，我們進行了多項實驗，其中在模擬中對在特定訓練件上訓練的模型進行了各種零件測試。此外，我們還進行了一項真實世界的實驗，通過執行從 CAD 模型離線生成的最佳化軌跡，使用 UR3e 機器人手臂模型來檢測零件。

##### **Mpox Screen Lite: AI-Driven On-Device Offline Mpox Screening for Low-Resource African Mpox Emergency Response**
2409.03806v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya

Background: The 2024 Mpox outbreak, particularly severe in Africa with clade
1b emergence, has highlighted critical gaps in diagnostic capabilities in
resource-limited settings. This study aimed to develop and validate an
artificial intelligence (AI)-driven, on-device screening tool for Mpox,
designed to function offline in low-resource environments.
  Methods: We developed a YOLOv8n-based deep learning model trained on 2,700
images (900 each of Mpox, other skin conditions, and normal skin), including
synthetic data. The model was validated on 360 images and tested on 540 images.
A larger external validation was conducted using 1,500 independent images.
Performance metrics included accuracy, precision, recall, F1-score,
sensitivity, and specificity.
  Findings: The model demonstrated high accuracy (96%) in the final test set.
For Mpox detection, it achieved 93% precision, 97% recall, and an F1-score of
95%. Sensitivity and specificity for Mpox detection were 97% and 96%,
respectively. Performance remained consistent in the larger external
validation, confirming the model's robustness and generalizability.
  Interpretation: This AI-driven screening tool offers a rapid, accurate, and
scalable solution for Mpox detection in resource-constrained settings. Its
offline functionality and high performance across diverse datasets suggest
significant potential for improving Mpox surveillance and management,
particularly in areas lacking traditional diagnostic infrastructure.

摘要：<paragraph>背景：2024 年 Mpox 爆發，在非洲特別嚴重，並出現 1b 分支，突顯了資源有限地區診斷能力的嚴重不足。本研究旨在開發和驗證一種人工智慧 (AI) 驅動的 Mpox 裝置篩選工具，旨在在資源不足的環境中離線運作。
方法：我們開發了一個基於 YOLOv8n 的深度學習模型，並使用 2,700 張影像（Mpox、其他皮膚狀況和正常皮膚各 900 張）進行訓練，包括合成資料。該模型經過 360 張影像驗證，並在 540 張影像上進行測試。使用 1,500 張獨立影像進行了更大規模的外部驗證。效能指標包括準確度、精確度、召回率、F1 分數、敏感度和特異性。
結果：該模型在最終測試集中表現出很高的準確度（96%）。對於 Mpox 檢測，其達到了 93% 的精確度、97% 的召回率和 95% 的 F1 分數。Mpox 檢測的敏感度和特異性分別為 97% 和 96%。在更大規模的外部驗證中，效能保持一致，這證實了該模型的穩健性和普遍性。
詮釋：這種 AI 驅動的篩選工具為資源受限地區的 Mpox 檢測提供了一個快速、準確且可擴充的解決方案。其離線功能和在不同資料集中的高效能表明在改善 Mpox 監控和管理方面具有顯著潛力，特別是在缺乏傳統診斷基礎設施的地區。</paragraph>

##### **Game On: Towards Language Models as RL Experimenters**
2409.03402v1 by Jingwei Zhang, Thomas Lampe, Abbas Abdolmaleki, Jost Tobias Springenberg, Martin Riedmiller

We propose an agent architecture that automates parts of the common
reinforcement learning experiment workflow, to enable automated mastery of
control domains for embodied agents. To do so, it leverages a VLM to perform
some of the capabilities normally required of a human experimenter, including
the monitoring and analysis of experiment progress, the proposition of new
tasks based on past successes and failures of the agent, decomposing tasks into
a sequence of subtasks (skills), and retrieval of the skill to execute -
enabling our system to build automated curricula for learning. We believe this
is one of the first proposals for a system that leverages a VLM throughout the
full experiment cycle of reinforcement learning. We provide a first prototype
of this system, and examine the feasibility of current models and techniques
for the desired level of automation. For this, we use a standard Gemini model,
without additional fine-tuning, to provide a curriculum of skills to a
language-conditioned Actor-Critic algorithm, in order to steer data collection
so as to aid learning new skills. Data collected in this way is shown to be
useful for learning and iteratively improving control policies in a robotics
domain. Additional examination of the ability of the system to build a growing
library of skills, and to judge the progress of the training of those skills,
also shows promising results, suggesting that the proposed architecture
provides a potential recipe for fully automated mastery of tasks and domains
for embodied agents.

摘要：我們提出了一種代理架構，該架構自動化了常見的強化學習實驗工作流程的部分，以實現對具身代理的控制領域的自動化掌握。為此，它利用 VLM 來執行通常人類實驗者所需的部分能力，包括監控和分析實驗進度、根據代理過去的成功和失敗提出新任務、將任務分解為一系列子任務（技能），以及檢索要執行的技能 - 使我們的系統能夠建立自動化的學習課程。我們相信這是第一個提出在強化學習的整個實驗週期中利用 VLM 的系統建議之一。我們提供了這個系統的第一個原型，並檢查了當前模型和技術對於所需自動化級別的可行性。為此，我們使用標準的 Gemini 模型，沒有額外的微調，為語言條件的 Actor-Critic 演算法提供技能課程，以便引導數據收集，以幫助學習新技能。以這種方式收集的數據被證明對於學習和反覆改進機器人領域的控制策略很有用。對系統構建不斷增長的技能庫以及判斷這些技能訓練進度的能力的進一步檢查也顯示出有希望的結果，表明所提出的架構為具身代理的任務和領域的完全自動化掌握提供了一個潛在的途徑。

##### **Hardware Acceleration of LLMs: A comprehensive survey and comparison**
2409.03384v1 by Nikoletta Koilia, Christoforos Kachris

Large Language Models (LLMs) have emerged as powerful tools for natural
language processing tasks, revolutionizing the field with their ability to
understand and generate human-like text. In this paper, we present a
comprehensive survey of the several research efforts that have been presented
for the acceleration of transformer networks for Large Language Models using
hardware accelerators.
  The survey presents the frameworks that have been proposed and then performs
a qualitative and quantitative comparison regarding the technology, the
processing platform (FPGA, ASIC, In-Memory, GPU), the speedup, the energy
efficiency, the performance (GOPs), and the energy efficiency (GOPs/W) of each
framework. The main challenge in comparison is that every proposed scheme is
implemented on a different process technology making hard a fair comparison.
The main contribution of this paper is that we extrapolate the results of the
performance and the energy efficiency on the same technology to make a fair
comparison; one theoretical and one more practical. We implement part of the
LLMs on several FPGA chips to extrapolate the results to the same process
technology and then we make a fair comparison of the performance.

摘要：大型語言模型 (LLM) 已成為自然語言處理任務的強大工具，它們能夠理解和生成類似人類的文字，因而徹底改變了這個領域。在本文中，我們對使用硬體加速器來加速大型語言模型的Transformer網路所提出的多項研究工作進行了全面的調查。
調查介紹了已提出的框架，然後對技術、處理平台 (FPGA、ASIC、In-Memory、GPU)、加速、能效、效能 (GOP) 和能效 (GOP/W) 進行定性和定量比較。比較中的主要挑戰在於，每項提出的方案都是在不同的製程技術上實作，這使得公平比較變得困難。本文的主要貢獻在於，我們將效能和能效的結果外推到相同的技術上，以進行公平的比較；一種是理論上的，一種是更實際的。我們在多個 FPGA 晶片上實作部分 LLM，以將結果外推到相同的製程技術，然後公平地比較效能。

##### **CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks**
2409.03381v2 by Yongxin Deng, Xihe Qiu, Xiaoyu Tan, Chao Qu, Jing Pan, Yuan Cheng, Yinghui Xu, Wei Chu

Cognitive psychology investigates perception, attention, memory, language,
problem-solving, decision-making, and reasoning. Kahneman's dual-system theory
elucidates the human decision-making process, distinguishing between the rapid,
intuitive System 1 and the deliberative, rational System 2. Recent advancements
have positioned large language Models (LLMs) as formidable tools nearing
human-level proficiency in various cognitive tasks. Nonetheless, the presence
of a dual-system framework analogous to human cognition in LLMs remains
unexplored. This study introduces the \textbf{CogniDual Framework for LLMs}
(CFLLMs), designed to assess whether LLMs can, through self-training, evolve
from deliberate deduction to intuitive responses, thereby emulating the human
process of acquiring and mastering new information. Our findings reveal the
cognitive mechanisms behind LLMs' response generation, enhancing our
understanding of their capabilities in cognitive psychology. Practically,
self-trained models can provide faster responses to certain queries, reducing
computational demands during inference.

摘要：認知心理學探討知覺、注意力、記憶、語言、問題解決、決策制定和推理。卡尼曼的雙系統理論闡明了人類決策制定流程，區分了快速、直覺的系統 1 和審慎、理性的系統 2。最近的進展已將大型語言模型 (LLM) 定位為強大的工具，在各種認知任務中接近人類層級的熟練度。儘管如此，在 LLM 中類似人類認知的雙系統架構的存在仍未被探索。本研究引入了 LLM 的認知雙重架構 (CFLLM)，旨在評估 LLM 是否能透過自我訓練從審慎的演繹演變成直覺的反應，從而模擬人類獲取和掌握新資訊的過程。我們的發現揭示了 LLM 回應生成背後的認知機制，增強了我們對其在認知心理學中的能力的理解。實際上，經過自我訓練的模型可以對某些查詢提供更快速的回應，在推理過程中減少運算需求。

##### **Raw Speech Enhancement with Deep State Space Modeling**
2409.03377v1 by Yan Ru Pei, Ritik Shrivastava, FNU Sidharth

We present aTENNuate, a simple deep state-space autoencoder configured for
efficient online raw speech enhancement in an end-to-end fashion. The network's
performance is primarily evaluated on raw speech denoising, with additional
assessments on tasks such as super-resolution and de-quantization. We benchmark
aTENNuate on the VoiceBank + DEMAND and the Microsoft DNS1 synthetic test sets.
The network outperforms previous real-time denoising models in terms of PESQ
score, parameter count, MACs, and latency. Even as a raw waveform processing
model, the model maintains high fidelity to the clean signal with minimal
audible artifacts. In addition, the model remains performant even when the
noisy input is compressed down to 4000Hz and 4 bits, suggesting general speech
enhancement capabilities in low-resource environments.

摘要：我們提出 aTENNuate，一種簡單的深度狀態空間自動編碼器，以端到端的方式配置用於高效的線上原始語音增強。該網路的效能主要評估於原始語音去噪，並對超解析度和去量化等任務進行額外評估。我們在 VoiceBank + DEMAND 和 Microsoft DNS1 合成測試集中對 aTENNuate 進行基準測試。該網路在 PESQ 分數、參數數量、MAC 和延遲方面優於先前的即時去噪模型。即使作為原始波形處理模型，該模型也能以最小的可聽見的人工製品保持對乾淨訊號的高保真度。此外，即使將雜訊輸入壓縮到 4000Hz 和 4 位元，該模型仍保持效能，這表明在低資源環境中具備一般的語音增強能力。

##### **Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time**
2409.03375v1 by Francisco de Arriba-Pérez, Silvia García-Méndez

Based on official estimates, 50 million people worldwide are affected by
dementia, and this number increases by 10 million new patients every year.
Without a cure, clinical prognostication and early intervention represent the
most effective ways to delay its progression. To this end, Artificial
Intelligence and computational linguistics can be exploited for natural
language analysis, personalized assessment, monitoring, and treatment. However,
traditional approaches need more semantic knowledge management and
explicability capabilities. Moreover, using Large Language Models (LLMs) for
cognitive decline diagnosis is still scarce, even though these models represent
the most advanced way for clinical-patient communication using intelligent
systems. Consequently, we leverage an LLM using the latest Natural Language
Processing (NLP) techniques in a chatbot solution to provide interpretable
Machine Learning prediction of cognitive decline in real-time.
Linguistic-conceptual features are exploited for appropriate natural language
analysis. Through explainability, we aim to fight potential biases of the
models and improve their potential to help clinical workers in their diagnosis
decisions. More in detail, the proposed pipeline is composed of (i) data
extraction employing NLP-based prompt engineering; (ii) stream-based data
processing including feature engineering, analysis, and selection; (iii)
real-time classification; and (iv) the explainability dashboard to provide
visual and natural language descriptions of the prediction outcome.
Classification results exceed 80 % in all evaluation metrics, with a recall
value for the mental deterioration class about 85 %. To sum up, we contribute
with an affordable, flexible, non-invasive, personalized diagnostic system to
this work.

摘要：<paragraph>根據官方的估計，全球約有 5000 萬人罹患失智症，且這個數字每年增加 1000 萬名新患者。在沒有治癒方法的情況下，臨床預後和早期介入是延緩其惡化的最有效方法。為此，人工智慧和計算語言學可被用於自然語言分析、個人化評估、監控和治療。然而，傳統方法需要更多語義知識管理和可解釋性能力。此外，儘管這些模型代表了使用智慧系統進行臨床患者溝通的最先進方式，但將大型語言模型 (LLM) 用於認知能力下降診斷仍然很少見。因此，我們利用聊天機器人解決方案中使用最新自然語言處理 (NLP) 技術的 LLM，以提供對認知能力下降的機器學習預測。語言概念特徵被用於適當的自然語言分析。透過可解釋性，我們旨在消除模型的潛在偏差，並提高其在診斷決策中協助臨床工作者的潛力。更詳細地說，所提出的管道包括：(i) 使用基於 NLP 的提示工程進行資料萃取；(ii) 串流式資料處理，包括特徵工程、分析和選擇；(iii) 即時分類；以及 (iv) 可解釋性儀表板，以提供預測結果的可視化和自然語言描述。分類結果在所有評估指標中都超過 80%，心智退化類別的召回率約為 85%。總而言之，我們為這項工作貢獻了一個經濟實惠、靈活、非侵入性、個人化的診斷系統。</paragraph>

##### **Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding**
2409.03363v1 by Cheng Wang, Yiwei Wang, Bryan Hooi, Yujun Cai, Nanyun Peng, Kai-Wei Chang

The training data in large language models is key to their success, but it
also presents privacy and security risks, as it may contain sensitive
information. Detecting pre-training data is crucial for mitigating these
concerns. Existing methods typically analyze target text in isolation or solely
with non-member contexts, overlooking potential insights from simultaneously
considering both member and non-member contexts. While previous work suggested
that member contexts provide little information due to the minor distributional
shift they induce, our analysis reveals that these subtle shifts can be
effectively leveraged when contrasted with non-member contexts. In this paper,
we propose Con-ReCall, a novel approach that leverages the asymmetric
distributional shifts induced by member and non-member contexts through
contrastive decoding, amplifying subtle differences to enhance membership
inference. Extensive empirical evaluations demonstrate that Con-ReCall achieves
state-of-the-art performance on the WikiMIA benchmark and is robust against
various text manipulation techniques.

摘要：大型語言模型中的訓練資料是其成功的關鍵，但它也存在隱私和安全風險，因為它可能包含敏感資訊。偵測預訓練資料對於降低這些疑慮至關重要。現有方法通常孤立分析目標文字或僅使用非成員背景，忽略同時考慮成員和非成員背景的潛在見解。雖然先前的研究表明，由於成員背景會導致輕微的分配轉移，因此提供的信息很少，但我們的分析表明，當與非成員背景進行對比時，這些細微的轉移可以被有效利用。在本文中，我們提出 Con-ReCall，一種新穎的方法，它利用對比解碼來利用成員和非成員背景所引發的不對稱分配轉移，放大細微差異以增強成員推論。廣泛的實證評估表明，Con-ReCall 在 WikiMIA 基準上達到了最先進的效能，並且對於各種文字操作技術具有穩健性。

##### **Sketch: A Toolkit for Streamlining LLM Operations**
2409.03346v1 by Xin Jiang, Xiang Li, Wenjia Ma, Xuezhi Fang, Yiqun Yao, Naitong Yu, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang

Large language models (LLMs) represented by GPT family have achieved
remarkable success. The characteristics of LLMs lie in their ability to
accommodate a wide range of tasks through a generative approach. However, the
flexibility of their output format poses challenges in controlling and
harnessing the model's outputs, thereby constraining the application of LLMs in
various domains. In this work, we present Sketch, an innovative toolkit
designed to streamline LLM operations across diverse fields. Sketch comprises
the following components: (1) a suite of task description schemas and prompt
templates encompassing various NLP tasks; (2) a user-friendly, interactive
process for building structured output LLM services tailored to various NLP
tasks; (3) an open-source dataset for output format control, along with tools
for dataset construction; and (4) an open-source model based on
LLaMA3-8B-Instruct that adeptly comprehends and adheres to output formatting
instructions. We anticipate this initiative to bring considerable convenience
to LLM users, achieving the goal of ''plug-and-play'' for various applications.
The components of Sketch will be progressively open-sourced at
https://github.com/cofe-ai/Sketch.

摘要：由 GPT 家族代表的大型語言模型 (LLM) 已取得顯著的成功。LLM 的特點在於它們能夠透過生成式方法來適應廣泛的任務。然而，它們的輸出格式靈活性在控制和利用模型輸出方面構成了挑戰，從而限制了 LLM 在各種領域中的應用。在這項工作中，我們展示了 Sketch，這是一個創新的工具包，旨在簡化 LLM 在不同領域中的操作。Sketch 包含以下組件：(1) 一套任務描述架構和提示範本，涵蓋各種 NLP 任務；(2) 一個友善、互動的流程，用於建立針對各種 NLP 任務量身打造的結構化輸出 LLM 服務；(3) 一個用於輸出格式控制的開源資料集，以及用於資料集建構的工具；(4) 一個基於 LLaMA3-8B-Instruct 的開源模型，它能靈活地理解並遵守輸出格式化指示。我們預期這個計畫將為 LLM 使用者帶來極大的便利性，實現各種應用程式的「即插即用」目標。Sketch 的組件將在 https://github.com/cofe-ai/Sketch 逐步開放原始碼。

