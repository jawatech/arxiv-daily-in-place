{"2409.04114": {"publish_time": "2024-09-06", "title": "Multi-Programming Language Ensemble for Code Generation in Large Language Model", "paper_summary": "Large language models (LLMs) have significantly improved code generation,\nparticularly in one-pass code generation. However, most existing approaches\nfocus solely on generating code in a single programming language, overlooking\nthe potential of leveraging the multi-language capabilities of LLMs. LLMs have\nvarying patterns of errors across different languages, suggesting that a more\nrobust approach could be developed by leveraging these multi-language outputs.\nIn this study, we propose Multi-Programming Language Ensemble (MPLE), a novel\nensemble-based method that utilizes code generation across multiple programming\nlanguages to enhance overall performance. By treating each language-specific\ncode generation process as an individual \"weak expert\" and effectively\nintegrating their outputs, our method mitigates language-specific errors and\nbiases. This multi-language ensemble strategy leverages the complementary\nstrengths of different programming languages, enabling the model to produce\nmore accurate and robust code. Our approach can be seamlessly integrated with\ncommonly used techniques such as the reflection algorithm and Monte Carlo tree\nsearch to improve code generation quality further. Experimental results show\nthat our framework consistently enhances baseline performance by up to 17.92%\non existing benchmarks (HumanEval and HumanEval-plus), with a standout result\nof 96.25% accuracy on the HumanEval benchmark, achieving new state-of-the-art\nresults across various LLM models. The code will be released at\nhttps://github.com/NinjaTech-AI/MPLE", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u986f\u8457\u6539\u9032\u7a0b\u5f0f\u78bc\u7522\u751f\uff0c\u7279\u5225\u662f\u5728\u55ae\u6b21\u901a\u904e\u7a0b\u5f0f\u78bc\u7522\u751f\u4e2d\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u65b9\u6cd5\u5927\u591a\u50c5\u5c08\u6ce8\u65bc\u4f7f\u7528\u55ae\u4e00\u7a0b\u5f0f\u8a9e\u8a00\u7522\u751f\u7a0b\u5f0f\u78bc\uff0c\u5ffd\u7565\u4e86\u5229\u7528 LLM \u591a\u8a9e\u8a00\u529f\u80fd\u7684\u6f5b\u529b\u3002LLM \u5728\u4e0d\u540c\u8a9e\u8a00\u4e2d\u5b58\u5728\u4e0d\u540c\u7684\u932f\u8aa4\u6a21\u5f0f\uff0c\u9019\u8868\u660e\u53ef\u4ee5\u900f\u904e\u5229\u7528\u9019\u4e9b\u591a\u8a9e\u8a00\u8f38\u51fa\u958b\u767c\u66f4\u5f37\u5927\u7684\u65b9\u6cd5\u3002\u5728\u9019\u500b\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u591a\u7a0b\u5f0f\u8a9e\u8a00\u5408\u594f (MPLE)\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u57fa\u65bc\u5408\u594f\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u591a\u7a2e\u7a0b\u5f0f\u8a9e\u8a00\u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u4f86\u589e\u5f37\u6574\u9ad4\u6548\u80fd\u3002\u900f\u904e\u5c07\u6bcf\u500b\u7279\u5b9a\u8a9e\u8a00\u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u7a0b\u5e8f\u8996\u70ba\u4e00\u500b\u55ae\u4e00\u7684\u300c\u5f31\u5c08\u5bb6\u300d\uff0c\u4e26\u6709\u6548\u5730\u6574\u5408\u5176\u8f38\u51fa\uff0c\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u6e1b\u8f15\u4e86\u7279\u5b9a\u8a9e\u8a00\u7684\u932f\u8aa4\u548c\u504f\u8aa4\u3002\u9019\u500b\u591a\u8a9e\u8a00\u5408\u594f\u7b56\u7565\u5229\u7528\u4e0d\u540c\u7a0b\u5f0f\u8a9e\u8a00\u7684\u4e92\u88dc\u512a\u52e2\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u7522\u751f\u66f4\u6e96\u78ba\u4e14\u5f37\u5927\u7684\u7a0b\u5f0f\u78bc\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u7121\u7e2b\u5730\u8207\u5e38\u7528\u7684\u6280\u8853\uff08\u4f8b\u5982\u53cd\u5c04\u6f14\u7b97\u6cd5\u548c\u8499\u5730\u5361\u7f85\u6a39\u641c\u5c0b\uff09\u6574\u5408\uff0c\u4ee5\u9032\u4e00\u6b65\u63d0\u9ad8\u7a0b\u5f0f\u78bc\u7522\u751f\u54c1\u8cea\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u67b6\u69cb\u5728\u73fe\u6709\u7684\u57fa\u6e96\uff08HumanEval \u548c HumanEval-plus\uff09\u4e0a\u6301\u7e8c\u63d0\u5347\u57fa\u6e96\u6548\u80fd\u9054 17.92%\uff0c\u5728 HumanEval \u57fa\u6e96\u4e0a\u7372\u5f97 96.25% \u7684\u6e96\u78ba\u5ea6\uff0c\u5728\u5404\u7a2e LLM \u6a21\u578b\u4e2d\u53d6\u5f97\u65b0\u7684\u6700\u5148\u9032\u6210\u679c\u3002\u7a0b\u5f0f\u78bc\u5c07\u5728 https://github.com/NinjaTech-AI/MPLE \u767c\u5e03", "author": "Tengfei Xue et.al.", "authors": "Tengfei Xue, Xuefeng Li, Tahir Azim, Roman Smirnov, Jianhui Yu, Arash Sadrieh, Babak Pahlavan", "id": "2409.04114v1", "paper_url": "http://arxiv.org/abs/2409.04114v1", "repo": "https://github.com/ninjatech-ai/mple"}}