{"2408.13860": {"publish_time": "2024-08-25", "title": "Knowledge-Aware Reasoning over Multimodal Semi-structured Tables", "paper_summary": "Existing datasets for tabular question answering typically focus exclusively\non text within cells. However, real-world data is inherently multimodal, often\nblending images such as symbols, faces, icons, patterns, and charts with\ntextual content in tables. With the evolution of AI models capable of\nmultimodal reasoning, it is pertinent to assess their efficacy in handling such\nstructured data. This study investigates whether current AI models can perform\nknowledge-aware reasoning on multimodal structured data. We explore their\nability to reason on tables that integrate both images and text, introducing\nMMTabQA, a new dataset designed for this purpose. Our experiments highlight\nsubstantial challenges for current AI models in effectively integrating and\ninterpreting multiple text and image inputs, understanding visual context, and\ncomparing visual content across images. These findings establish our dataset as\na robust benchmark for advancing AI's comprehension and capabilities in\nanalyzing multimodal structured data.", "paper_summary_zh": "\u73fe\u6709\u7684\u8868\u683c\u554f\u7b54\u8cc7\u6599\u96c6\u901a\u5e38\u53ea\u5c08\u6ce8\u65bc\u5132\u5b58\u683c\u5167\u7684\u6587\u5b57\u3002\u7136\u800c\uff0c\u771f\u5be6\u4e16\u754c\u7684\u8cc7\u6599\u672c\u8cea\u4e0a\u662f\u591a\u6a21\u614b\u7684\uff0c\u901a\u5e38\u6703\u5c07\u7b26\u865f\u3001\u4eba\u81c9\u3001\u5716\u793a\u3001\u5716\u6848\u548c\u5716\u8868\u7b49\u5f71\u50cf\u8207\u8868\u683c\u4e2d\u7684\u6587\u5b57\u5167\u5bb9\u6df7\u5408\u5728\u4e00\u8d77\u3002\u96a8\u8457\u5177\u5099\u591a\u6a21\u614b\u63a8\u7406\u80fd\u529b\u7684\u4eba\u5de5\u667a\u6167\u6a21\u578b\u7684\u767c\u5c55\uff0c\u8a55\u4f30\u5b83\u5011\u5728\u8655\u7406\u6b64\u985e\u7d50\u69cb\u5316\u8cc7\u6599\u6642\u7684\u6548\u80fd\u81f3\u95dc\u91cd\u8981\u3002\u672c\u7814\u7a76\u63a2\u8a0e\u4e86\u7576\u524d\u7684\u4eba\u5de5\u667a\u6167\u6a21\u578b\u662f\u5426\u80fd\u5920\u5c0d\u591a\u6a21\u614b\u7d50\u69cb\u5316\u8cc7\u6599\u57f7\u884c\u77e5\u8b58\u611f\u77e5\u63a8\u7406\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u5b83\u5011\u5c0d\u6574\u5408\u5f71\u50cf\u548c\u6587\u5b57\u7684\u8868\u683c\u9032\u884c\u63a8\u7406\u7684\u80fd\u529b\uff0c\u4e26\u4ecb\u7d39\u4e86\u70ba\u6b64\u76ee\u7684\u8a2d\u8a08\u7684\u65b0\u8cc7\u6599\u96c6 MMTabQA\u3002\u6211\u5011\u7684\u5be6\u9a57\u7a81\u986f\u4e86\u7576\u524d\u7684\u4eba\u5de5\u667a\u6167\u6a21\u578b\u5728\u6709\u6548\u6574\u5408\u548c\u8a6e\u91cb\u591a\u500b\u6587\u5b57\u548c\u5f71\u50cf\u8f38\u5165\u3001\u7406\u89e3\u8996\u89ba\u8108\u7d61\u4ee5\u53ca\u6bd4\u8f03\u5f71\u50cf\u4e2d\u7684\u8996\u89ba\u5167\u5bb9\u65b9\u9762\u9762\u81e8\u7684\u91cd\u5927\u6311\u6230\u3002\u9019\u4e9b\u767c\u73fe\u78ba\u7acb\u4e86\u6211\u5011\u7684\u8cc7\u6599\u96c6\u4f5c\u70ba\u4fc3\u9032\u4eba\u5de5\u667a\u6167\u7406\u89e3\u548c\u5206\u6790\u591a\u6a21\u614b\u7d50\u69cb\u5316\u8cc7\u6599\u7684\u80fd\u529b\u7684\u5f37\u5927\u57fa\u6e96\u3002", "author": "Suyash Vardhan Mathur et.al.", "authors": "Suyash Vardhan Mathur, Jainit Sushil Bafna, Kunal Kartik, Harshita Khandelwal, Manish Shrivastava, Vivek Gupta, Mohit Bansal, Dan Roth", "id": "2408.13860v1", "paper_url": "http://arxiv.org/abs/2408.13860v1", "repo": "null"}}