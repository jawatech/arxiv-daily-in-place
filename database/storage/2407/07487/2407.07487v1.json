{"2407.07487": {"publish_time": "2024-07-10", "title": "Review-LLM: Harnessing Large Language Models for Personalized Review Generation", "paper_summary": "Product review generation is an important task in recommender systems, which\ncould provide explanation and persuasiveness for the recommendation. Recently,\nLarge Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling\nand generating ability, which could be applied in review generation. However,\ndirectly applying the LLMs for generating reviews might be troubled by the\n``polite'' phenomenon of the LLMs and could not generate personalized reviews\n(e.g., negative reviews). In this paper, we propose Review-LLM that customizes\nLLMs for personalized review generation. Firstly, we construct the prompt input\nby aggregating user historical behaviors, which include corresponding item\ntitles and reviews. This enables the LLMs to capture user interest features and\nreview writing style. Secondly, we incorporate ratings as indicators of\nsatisfaction into the prompt, which could further improve the model's\nunderstanding of user preferences and the sentiment tendency control of\ngenerated reviews. Finally, we feed the prompt text into LLMs, and use\nSupervised Fine-Tuning (SFT) to make the model generate personalized reviews\nfor the given user and target item. Experimental results on the real-world\ndataset show that our fine-tuned model could achieve better review generation\nperformance than existing close-source LLMs.", "paper_summary_zh": "\u7522\u54c1\u8a55\u8ad6\u751f\u6210\u5728\u63a8\u85a6\u7cfb\u7d71\u4e2d\u662f\u4e00\u9805\u91cd\u8981\u7684\u4efb\u52d9\uff0c\u5b83\u53ef\u4ee5\u70ba\u63a8\u85a6\u63d0\u4f9b\u89e3\u91cb\u548c\u8aaa\u670d\u529b\u3002\u6700\u8fd1\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff0c\u4f8b\u5982 ChatGPT\uff09\u5c55\u793a\u4e86\u51fa\u8272\u7684\u6587\u672c\u5efa\u6a21\u548c\u751f\u6210\u80fd\u529b\uff0c\u53ef\u4ee5\u61c9\u7528\u65bc\u8a55\u8ad6\u751f\u6210\u3002\u7136\u800c\uff0c\u76f4\u63a5\u61c9\u7528 LLM \u4f86\u751f\u6210\u8a55\u8ad6\u53ef\u80fd\u6703\u53d7\u5230 LLM \u7684\u300c\u79ae\u8c8c\u300d\u73fe\u8c61\u7684\u56f0\u64fe\uff0c\u4e26\u4e14\u7121\u6cd5\u751f\u6210\u500b\u6027\u5316\u8a55\u8ad6\uff08\u4f8b\u5982\u8ca0\u9762\u8a55\u8ad6\uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 Review-LLM\uff0c\u5b83\u81ea\u8a02\u4e86 LLM \u4ee5\u9032\u884c\u500b\u6027\u5316\u8a55\u8ad6\u751f\u6210\u3002\u9996\u5148\uff0c\u6211\u5011\u901a\u904e\u5f59\u7e3d\u7528\u6236\u6b77\u53f2\u884c\u70ba\uff08\u5305\u62ec\u5c0d\u61c9\u7684\u5546\u54c1\u6a19\u984c\u548c\u8a55\u8ad6\uff09\u4f86\u69cb\u5efa\u63d0\u793a\u8f38\u5165\u3002\u9019\u4f7f LLM \u80fd\u5920\u6355\u6349\u7528\u6236\u8208\u8da3\u7279\u5fb5\u548c\u8a55\u8ad6\u5beb\u4f5c\u98a8\u683c\u3002\u5176\u6b21\uff0c\u6211\u5011\u5c07\u8a55\u5206\u4f5c\u70ba\u6eff\u610f\u5ea6\u7684\u6307\u6a19\u7d0d\u5165\u63d0\u793a\u4e2d\uff0c\u9019\u53ef\u4ee5\u9032\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u5c0d\u7528\u6236\u504f\u597d\u548c\u751f\u6210\u8a55\u8ad6\u7684\u60c5\u7dd2\u50be\u5411\u63a7\u5236\u7684\u7406\u89e3\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c07\u63d0\u793a\u6587\u672c\u8f38\u5165 LLM\uff0c\u4e26\u4f7f\u7528\u76e3\u7763\u5fae\u8abf (SFT) \u4f7f\u6a21\u578b\u70ba\u7d66\u5b9a\u7684\u7528\u6236\u548c\u76ee\u6a19\u5546\u54c1\u751f\u6210\u500b\u6027\u5316\u8a55\u8ad6\u3002\u5728\u771f\u5be6\u4e16\u754c\u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u5fae\u8abf\u7684\u6a21\u578b\u53ef\u4ee5\u6bd4\u73fe\u6709\u7684\u9589\u6e90 LLM \u7372\u5f97\u66f4\u597d\u7684\u8a55\u8ad6\u751f\u6210\u6027\u80fd\u3002", "author": "Qiyao Peng et.al.", "authors": "Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun Wang", "id": "2407.07487v1", "paper_url": "http://arxiv.org/abs/2407.07487v1", "repo": "null"}}