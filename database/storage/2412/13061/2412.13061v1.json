{"2412.13061": {"publish_time": "2024-12-17", "title": "VidTok: A Versatile and Open-Source Video Tokenizer", "paper_summary": "Encoding video content into compact latent tokens has become a fundamental\nstep in video generation and understanding, driven by the need to address the\ninherent redundancy in pixel-level representations. Consequently, there is a\ngrowing demand for high-performance, open-source video tokenizers as\nvideo-centric research gains prominence. We introduce VidTok, a versatile video\ntokenizer that delivers state-of-the-art performance in both continuous and\ndiscrete tokenizations. VidTok incorporates several key advancements over\nexisting approaches: 1) model architecture such as convolutional layers and\nup/downsampling modules; 2) to address the training instability and codebook\ncollapse commonly associated with conventional Vector Quantization (VQ), we\nintegrate Finite Scalar Quantization (FSQ) into discrete video tokenization; 3)\nimproved training strategies, including a two-stage training process and the\nuse of reduced frame rates. By integrating these advancements, VidTok achieves\nsubstantial improvements over existing methods, demonstrating superior\nperformance across multiple metrics, including PSNR, SSIM, LPIPS, and FVD,\nunder standardized evaluation settings.", "paper_summary_zh": "\u5c07\u5f71\u7247\u5167\u5bb9\u7de8\u78bc\u6210\u7dca\u6e4a\u7684\u6f5b\u5728\u7b26\u865f\u5df2\u6210\u70ba\u5f71\u7247\u751f\u6210\u548c\u7406\u89e3\u7684\u57fa\u672c\u6b65\u9a5f\uff0c\u5176\u9a45\u52d5\u529b\u662f\u70ba\u4e86\u8655\u7406\u756b\u7d20\u7d1a\u5225\u8868\u793a\u4e2d\u56fa\u6709\u7684\u5197\u9918\u3002\u56e0\u6b64\uff0c\u96a8\u8457\u4ee5\u5f71\u7247\u70ba\u4e2d\u5fc3\u7684\u7814\u7a76\u6240\u7372\u5f97\u986f\u8457\u5730\u4f4d\uff0c\u5c0d\u65bc\u9ad8\u6027\u80fd\u7684\u958b\u653e\u539f\u59cb\u78bc\u5f71\u7247\u4ee3\u5e63\u7522\u751f\u5668\u7684\u9700\u6c42\u4e5f\u8207\u65e5\u4ff1\u589e\u3002\u6211\u5011\u4ecb\u7d39\u4e86 VidTok\uff0c\u9019\u662f\u4e00\u500b\u591a\u529f\u80fd\u7684\u5f71\u7247\u4ee3\u5e63\u7522\u751f\u5668\uff0c\u5728\u9023\u7e8c\u548c\u96e2\u6563\u4ee3\u5e63\u5316\u4e2d\u90fd\u80fd\u63d0\u4f9b\u6700\u5148\u9032\u7684\u6548\u80fd\u3002VidTok \u6574\u5408\u4e86\u591a\u9805\u95dc\u9375\u9032\u5c55\uff0c\u8d85\u8d8a\u4e86\u73fe\u6709\u7684\u65b9\u6cd5\uff1a1) \u6a21\u578b\u67b6\u69cb\uff0c\u4f8b\u5982\u5377\u7a4d\u5c64\u548c\u4e0a/\u4e0b\u63a1\u6a23\u6a21\u7d44\uff1b2) \u70ba\u4e86\u8655\u7406\u8207\u50b3\u7d71\u5411\u91cf\u91cf\u5316 (VQ) \u901a\u5e38\u76f8\u95dc\u7684\u8a13\u7df4\u4e0d\u7a69\u5b9a\u6027\u548c\u4ee3\u78bc\u7c3f\u5d29\u6f70\uff0c\u6211\u5011\u5c07\u6709\u9650\u7d14\u91cf\u91cf\u5316 (FSQ) \u6574\u5408\u5230\u96e2\u6563\u5f71\u7247\u4ee3\u5e63\u5316\u4e2d\uff1b3) \u6539\u826f\u7684\u8a13\u7df4\u7b56\u7565\uff0c\u5305\u62ec\u5169\u968e\u6bb5\u8a13\u7df4\u6d41\u7a0b\u548c\u4f7f\u7528\u964d\u4f4e\u7684\u5e40\u7387\u3002\u900f\u904e\u6574\u5408\u9019\u4e9b\u9032\u5c55\uff0cVidTok \u5728\u73fe\u6709\u65b9\u6cd5\u4e0a\u7372\u5f97\u4e86\u986f\u8457\u7684\u6539\u9032\uff0c\u5728\u6a19\u6e96\u5316\u8a55\u4f30\u8a2d\u5b9a\u4e0b\uff0c\u5c55\u793a\u4e86\u591a\u9805\u6307\u6a19\u7684\u5353\u8d8a\u6548\u80fd\uff0c\u5305\u62ec PSNR\u3001SSIM\u3001LPIPS \u548c FVD\u3002", "author": "Anni Tang et.al.", "authors": "Anni Tang, Tianyu He, Junliang Guo, Xinle Cheng, Li Song, Jiang Bian", "id": "2412.13061v1", "paper_url": "http://arxiv.org/abs/2412.13061v1", "repo": "https://github.com/microsoft/vidtok"}}