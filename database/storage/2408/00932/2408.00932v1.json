{"2408.00932": {"publish_time": "2024-08-01", "title": "Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper)", "paper_summary": "Equitable urban transportation applications require high-fidelity digital\nrepresentations of the built environment: not just streets and sidewalks, but\nbike lanes, marked and unmarked crossings, curb ramps and cuts, obstructions,\ntraffic signals, signage, street markings, potholes, and more. Direct\ninspections and manual annotations are prohibitively expensive at scale.\nConventional machine learning methods require substantial annotated training\ndata for adequate performance. In this paper, we consider vision language\nmodels as a mechanism for annotating diverse urban features from satellite\nimages, reducing the dependence on human annotation to produce large training\nsets. While these models have achieved impressive results in describing common\nobjects in images captured from a human perspective, their training sets are\nless likely to include strong signals for esoteric features in the built\nenvironment, and their performance in these settings is therefore unclear. We\ndemonstrate proof-of-concept combining a state-of-the-art vision language model\nand variants of a prompting strategy that asks the model to consider segmented\nelements independently of the original image. Experiments on two urban features\n-- stop lines and raised tables -- show that while direct zero-shot prompting\ncorrectly annotates nearly zero images, the pre-segmentation strategies can\nannotate images with near 40% intersection-over-union accuracy. We describe how\nthese results inform a new research agenda in automatic annotation of the built\nenvironment to improve equity, accessibility, and safety at broad scale and in\ndiverse environments.", "paper_summary_zh": "\u516c\u5e73\u7684\u57ce\u5e02\u4ea4\u901a\u61c9\u7528\u7a0b\u5f0f\u9700\u8981\u9ad8\u4fdd\u771f\u7684\u6578\u4f4d\u5316\u5efa\u6210\u74b0\u5883\u8868\u793a\uff1a\u4e0d\u50c5\u50c5\u662f\u8857\u9053\u548c\u4eba\u884c\u9053\uff0c\u9084\u6709\u81ea\u884c\u8eca\u9053\u3001\u6a19\u793a\u548c\u672a\u6a19\u793a\u7684\u8def\u53e3\u3001\u8def\u7de3\u5761\u9053\u548c\u5207\u53e3\u3001\u969c\u7919\u7269\u3001\u4ea4\u901a\u865f\u8a8c\u3001\u6a19\u8a8c\u3001\u8857\u9053\u6a19\u7dda\u3001\u5751\u6d1e\u7b49\u7b49\u3002\u76f4\u63a5\u6aa2\u67e5\u548c\u624b\u52d5\u8a3b\u89e3\u5728\u898f\u6a21\u4e0a\u6210\u672c\u904e\u65bc\u9ad8\u6602\u3002\u50b3\u7d71\u7684\u6a5f\u5668\u5b78\u7fd2\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u8a3b\u89e3\u8a13\u7df4\u8cc7\u6599\u624d\u80fd\u6709\u8db3\u5920\u7684\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c07\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u8996\u70ba\u4e00\u7a2e\u5f9e\u885b\u661f\u5f71\u50cf\u4e2d\u8a3b\u89e3\u5404\u7a2e\u57ce\u5e02\u7279\u5fb5\u7684\u6a5f\u5236\uff0c\u6e1b\u5c11\u5c0d\u4eba\u5de5\u8a3b\u89e3\u7684\u4f9d\u8cf4\u4ee5\u7522\u751f\u5927\u91cf\u7684\u8a13\u7df4\u96c6\u3002\u5118\u7ba1\u9019\u4e9b\u6a21\u578b\u5728\u63cf\u8ff0\u5f9e\u4eba\u985e\u8996\u89d2\u62cd\u651d\u7684\u5f71\u50cf\u4e2d\u5e38\u898b\u7269\u9ad4\u65b9\u9762\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6210\u679c\uff0c\u4f46\u5176\u8a13\u7df4\u96c6\u4e0d\u592a\u53ef\u80fd\u5305\u542b\u5efa\u6210\u74b0\u5883\u4e2d\u6df1\u5967\u7279\u5fb5\u7684\u5f37\u8a0a\u865f\uff0c\u56e0\u6b64\u5b83\u5011\u5728\u9019\u4e9b\u8a2d\u5b9a\u4e2d\u7684\u6548\u80fd\u5c1a\u4e0d\u6e05\u695a\u3002\u6211\u5011\u5c55\u793a\u4e86\u6982\u5ff5\u9a57\u8b49\uff0c\u7d50\u5408\u4e86\u6700\u5148\u9032\u7684\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u7684\u8b8a\u9ad4\uff0c\u8981\u6c42\u6a21\u578b\u7368\u7acb\u65bc\u539f\u59cb\u5f71\u50cf\u8003\u616e\u5206\u5272\u5143\u7d20\u3002\u5728\u5169\u500b\u57ce\u5e02\u7279\u5fb5\uff08\u505c\u6b62\u7dda\u548c\u9ad8\u67b6\u684c\u9762\uff09\u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0c\u96d6\u7136\u76f4\u63a5\u7684\u96f6\u6b21\u63d0\u793a\u6b63\u78ba\u8a3b\u89e3\u4e86\u63a5\u8fd1\u65bc\u96f6\u7684\u5f71\u50cf\uff0c\u4f46\u9810\u5206\u5272\u7b56\u7565\u53ef\u4ee5\u8a3b\u89e3\u63a5\u8fd1 40% \u7684\u4ea4\u96c6\u806f\u96c6\u6e96\u78ba\u5ea6\u7684\u5f71\u50cf\u3002\u6211\u5011\u63cf\u8ff0\u4e86\u9019\u4e9b\u7d50\u679c\u5982\u4f55\u544a\u77e5\u5efa\u6210\u74b0\u5883\u81ea\u52d5\u8a3b\u89e3\u7684\u65b0\u7814\u7a76\u8b70\u7a0b\uff0c\u4ee5\u5728\u5ee3\u6cdb\u898f\u6a21\u548c\u591a\u6a23\u5316\u7684\u74b0\u5883\u4e2d\u6539\u5584\u516c\u5e73\u6027\u3001\u53ef\u53ca\u6027\u548c\u5b89\u5168\u6027\u3002", "author": "Bin Han et.al.", "authors": "Bin Han, Yiwei Yang, Anat Caspi, Bill Howe", "id": "2408.00932v1", "paper_url": "http://arxiv.org/abs/2408.00932v1", "repo": "null"}}