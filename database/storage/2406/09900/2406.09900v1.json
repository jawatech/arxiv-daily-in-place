{"2406.09900": {"publish_time": "2024-06-14", "title": "GEB-1.3B: Open Lightweight Large Language Model", "paper_summary": "Recently developed large language models (LLMs) such as ChatGPT, Claude, and\nLlama have demonstrated impressive abilities, and even surpass human-level\nperformance in several tasks. Despite their success, the resource-intensive\ndemands of these models, requiring significant computational power for both\ntraining and inference, limit their deployment to high-performance servers.\nAdditionally, the extensive calculation requirements of the models often lead\nto increased latency in response times. With the increasing need for LLMs to\noperate efficiently on CPUs, research about lightweight models that are\noptimized for CPU inference has emerged. In this work, we introduce GEB-1.3B, a\nlightweight LLM trained on 550 billion tokens in both Chinese and English\nlanguages. We employ novel training techniques, including ROPE,\nGroup-Query-Attention, and FlashAttention-2, to accelerate training while\nmaintaining model performance. Additionally, we fine-tune the model using 10\nmillion samples of instruction data to enhance alignment. GEB-1.3B exhibits\noutstanding performance on general benchmarks such as MMLU, C-Eval, and CMMLU,\noutperforming comparative models such as MindLLM-1.3B and TinyLLaMA-1.1B.\nNotably, the FP32 version of GEB-1.3B achieves commendable inference times on\nCPUs, with ongoing efforts to further enhance speed through advanced\nquantization techniques. The release of GEB-1.3B as an open-source model marks\na significant contribution to the development of lightweight LLMs, promising to\nfoster further research and innovation in the field.", "paper_summary_zh": "\u8fd1\u671f\u958b\u767c\u7684\u5927\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u4f8b\u5982 ChatGPT\u3001Claude \u548c Llama\uff0c\u5df2\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u751a\u81f3\u5728\u591a\u9805\u4efb\u52d9\u4e2d\u8d85\u8d8a\u4eba\u985e\u6c34\u6e96\u7684\u8868\u73fe\u3002\u5118\u7ba1\u9019\u4e9b\u6a21\u578b\u5f88\u6210\u529f\uff0c\u4f46\u5b83\u5011\u9700\u8981\u5927\u91cf\u8cc7\u6e90\uff0c\u5728\u8a13\u7df4\u548c\u63a8\u7406\u6642\u90fd\u9700\u8981\u5927\u91cf\u7684\u904b\u7b97\u80fd\u529b\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u9ad8\u6027\u80fd\u4f3a\u670d\u5668\u4e0a\u7684\u90e8\u7f72\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u6a21\u578b\u9f90\u5927\u7684\u904b\u7b97\u9700\u6c42\u901a\u5e38\u6703\u5c0e\u81f4\u56de\u61c9\u6642\u9593\u5ef6\u9072\u3002\u7531\u65bc LLM \u5728 CPU \u4e0a\u9ad8\u6548\u904b\u4f5c\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\uff0c\u56e0\u6b64\u91dd\u5c0d CPU \u63a8\u8ad6\u9032\u884c\u6700\u4f73\u5316\u7684\u8f15\u91cf\u7d1a\u6a21\u578b\u7684\u7814\u7a76\u61c9\u904b\u800c\u751f\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 GEB-1.3B\uff0c\u9019\u662f\u4e00\u500b\u8f15\u91cf\u7d1a LLM\uff0c\u4f7f\u7528 5500 \u5104\u500b\u4e2d\u6587\u548c\u82f1\u6587\u8a9e\u8a00\u7684\u5b57\u5143\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u63a1\u7528\u5275\u65b0\u7684\u8a13\u7df4\u6280\u8853\uff0c\u5305\u62ec ROPE\u3001Group-Query-Attention \u548c FlashAttention-2\uff0c\u4ee5\u5728\u7dad\u6301\u6a21\u578b\u6548\u80fd\u7684\u540c\u6642\u52a0\u901f\u8a13\u7df4\u3002\u6b64\u5916\uff0c\u6211\u5011\u4f7f\u7528 1000 \u842c\u500b\u6307\u4ee4\u8cc7\u6599\u7bc4\u672c\u4f86\u5fae\u8abf\u6a21\u578b\uff0c\u4ee5\u589e\u5f37\u5c0d\u9f4a\u3002GEB-1.3B \u5728 MMLU\u3001C-Eval \u548c CMMLU \u7b49\u4e00\u822c\u57fa\u6e96\u6e2c\u8a66\u4e2d\u5c55\u73fe\u51fa\u5091\u51fa\u7684\u6548\u80fd\uff0c\u512a\u65bc MindLLM-1.3B \u548c TinyLLaMA-1.1B \u7b49\u6bd4\u8f03\u6a21\u578b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cGEB-1.3B \u7684 FP32 \u7248\u672c\u5728 CPU \u4e0a\u5be6\u73fe\u4e86\u503c\u5f97\u8b9a\u8cde\u7684\u63a8\u8ad6\u6642\u9593\uff0c\u6211\u5011\u6b63\u6301\u7e8c\u52aa\u529b\u900f\u904e\u9032\u968e\u91cf\u5316\u6280\u8853\u9032\u4e00\u6b65\u63d0\u5347\u901f\u5ea6\u3002GEB-1.3B \u4f5c\u70ba\u4e00\u500b\u958b\u6e90\u6a21\u578b\u7684\u767c\u5e03\u70ba\u8f15\u91cf\u7d1a LLM \u7684\u767c\u5c55\u505a\u51fa\u4e86\u91cd\u5927\u8ca2\u737b\uff0c\u6709\u671b\u4fc3\u9032\u8a72\u9818\u57df\u9032\u4e00\u6b65\u7684\u7814\u7a76\u548c\u5275\u65b0\u3002", "author": "Jie Wu et.al.", "authors": "Jie Wu, Yufeng Zhu, Lei Shen, Xuqing Lu", "id": "2406.09900v1", "paper_url": "http://arxiv.org/abs/2406.09900v1", "repo": "null"}}