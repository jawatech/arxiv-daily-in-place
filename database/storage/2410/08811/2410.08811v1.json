{"2410.08811": {"publish_time": "2024-10-11", "title": "PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning", "paper_summary": "Preference learning is a central component for aligning current LLMs, but\nthis process can be vulnerable to data poisoning attacks. To address this\nconcern, we introduce PoisonBench, a benchmark for evaluating large language\nmodels' susceptibility to data poisoning during preference learning. Data\npoisoning attacks can manipulate large language model responses to include\nhidden malicious content or biases, potentially causing the model to generate\nharmful or unintended outputs while appearing to function normally. We deploy\ntwo distinct attack types across eight realistic scenarios, assessing 21\nwidely-used models. Our findings reveal concerning trends: (1) Scaling up\nparameter size does not inherently enhance resilience against poisoning\nattacks; (2) There exists a log-linear relationship between the effects of the\nattack and the data poison ratio; (3) The effect of data poisoning can\ngeneralize to extrapolated triggers that are not included in the poisoned data.\nThese results expose weaknesses in current preference learning techniques,\nhighlighting the urgent need for more robust defenses against malicious models\nand data manipulation.", "paper_summary_zh": "\u504f\u597d\u5b78\u7fd2\u662f\u8abf\u6574\u7576\u524d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u4e2d\u5fc3\u7d44\u6210\u90e8\u5206\uff0c\u4f46\u9019\u500b\u904e\u7a0b\u53ef\u80fd\u5bb9\u6613\u53d7\u5230\u8cc7\u6599\u4e2d\u6bd2\u653b\u64ca\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 PoisonBench\uff0c\u4e00\u500b\u7528\u65bc\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5728\u504f\u597d\u5b78\u7fd2\u904e\u7a0b\u4e2d\u5c0d\u8cc7\u6599\u4e2d\u6bd2\u7684\u654f\u611f\u6027\u7684\u57fa\u6e96\u3002\u8cc7\u6599\u4e2d\u6bd2\u653b\u64ca\u53ef\u4ee5\u64cd\u7e31\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u56de\u61c9\uff0c\u5305\u62ec\u96b1\u85cf\u7684\u60e1\u610f\u5167\u5bb9\u6216\u504f\u898b\uff0c\u53ef\u80fd\u5c0e\u81f4\u6a21\u578b\u5728\u770b\u4f3c\u6b63\u5e38\u904b\u4f5c\u6642\u7522\u751f\u6709\u5bb3\u6216\u610f\u5916\u7684\u8f38\u51fa\u3002\u6211\u5011\u5728\u516b\u500b\u5be6\u969b\u5834\u666f\u4e2d\u90e8\u7f72\u4e86\u5169\u7a2e\u4e0d\u540c\u7684\u653b\u64ca\u985e\u578b\uff0c\u8a55\u4f30\u4e86 21 \u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u6a21\u578b\u3002\u6211\u5011\u7684\u767c\u73fe\u63ed\u793a\u4e86\u4ee4\u4eba\u64d4\u6182\u7684\u8da8\u52e2\uff1a(1) \u64f4\u5927\u53c3\u6578\u898f\u6a21\u4e26\u4e0d\u80fd\u5f9e\u672c\u8cea\u4e0a\u589e\u5f37\u5c0d\u4e2d\u6bd2\u653b\u64ca\u7684\u97cc\u6027\uff1b(2) \u653b\u64ca\u7684\u5f71\u97ff\u8207\u8cc7\u6599\u4e2d\u6bd2\u7387\u4e4b\u9593\u5b58\u5728\u5c0d\u6578\u7dda\u6027\u95dc\u4fc2\uff1b(3) \u8cc7\u6599\u4e2d\u6bd2\u7684\u5f71\u97ff\u53ef\u4ee5\u63a8\u5ee3\u5230\u672a\u5305\u542b\u5728\u4e2d\u6bd2\u8cc7\u6599\u4e2d\u7684\u5916\u63a8\u89f8\u767c\u5668\u3002\u9019\u4e9b\u7d50\u679c\u66b4\u9732\u4e86\u7576\u524d\u504f\u597d\u5b78\u7fd2\u6280\u8853\u4e2d\u7684\u5f31\u9ede\uff0c\u5f37\u8abf\u4e86\u5c0d\u6297\u60e1\u610f\u6a21\u578b\u548c\u8cc7\u6599\u64cd\u7e31\u7684\u66f4\u5f37\u5927\u9632\u79a6\u63aa\u65bd\u7684\u8feb\u5207\u9700\u8981\u3002", "author": "Tingchen Fu et.al.", "authors": "Tingchen Fu, Mrinank Sharma, Philip Torr, Shay B. Cohen, David Krueger, Fazl Barez", "id": "2410.08811v1", "paper_url": "http://arxiv.org/abs/2410.08811v1", "repo": "null"}}