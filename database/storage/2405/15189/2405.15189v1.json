{"2405.15189": {"publish_time": "2024-05-24", "title": "SOAP: Enhancing Efficiency of Generated Code via Self-Optimization", "paper_summary": "Large language models (LLMs) have shown remarkable progress in code\ngeneration, but their generated code often suffers from inefficiency, resulting\nin longer execution times and higher memory consumption. To address this issue,\nwe propose Self Optimization based on OverheAd Profile (SOAP), a\nself-optimization framework that utilizes execution overhead profiles to\nimprove the efficiency of LLM-generated code. SOAP first generates code using\nan LLM, then executes it locally to capture execution time and memory usage\nprofiles. These profiles are fed back to the LLM, which then revises the code\nto reduce overhead. To evaluate the effectiveness of SOAP, we conduct extensive\nexperiments on the EffiBench, HumanEval, and MBPP with 16 open-source and 6\nclosed-source models. Our evaluation results demonstrate that through iterative\nself-optimization, SOAP significantly enhances the efficiency of LLM-generated\ncode. For example, the execution time (ET) of StarCoder2-15B for the EffiBench\ndecreases from 0.93 (s) to 0.12 (s) which reduces 87.1% execution time\nrequirement compared with the initial code. The total memory usage (TMU) of\nStarCoder2-15B also decreases from 22.02 (Mb*s) to 2.03 (Mb*s), which decreases\n90.8% total memory consumption during the execution process. The source code of\nSOAP was released in https://github.com/huangd1999/SOAP.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u7a0b\u5f0f\u78bc\u751f\u6210\u65b9\u9762\u5c55\u73fe\u4e86\u986f\u8457\u7684\u9032\u5c55\uff0c\u4f46\u5176\u751f\u6210\u7684\u7a0b\u5f0f\u78bc\u5e38\u5e38\u6548\u7387\u4e0d\u5f70\uff0c\u5c0e\u81f4\u57f7\u884c\u6642\u9593\u8f03\u9577\u4e14\u8a18\u61b6\u9ad4\u6d88\u8017\u8f03\u9ad8\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u57fa\u65bc\u958b\u92b7\u5256\u6790\u7684\u81ea\u6700\u4f73\u5316 (SOAP)\uff0c\u9019\u662f\u4e00\u500b\u81ea\u6700\u4f73\u5316\u67b6\u69cb\uff0c\u5229\u7528\u57f7\u884c\u958b\u92b7\u5256\u6790\u4f86\u6539\u5584 LLM \u751f\u6210\u7684\u7a0b\u5f0f\u78bc\u6548\u7387\u3002SOAP \u9996\u5148\u4f7f\u7528 LLM \u7522\u751f\u7a0b\u5f0f\u78bc\uff0c\u7136\u5f8c\u5728\u672c\u5730\u57f7\u884c\u5b83\u4ee5\u64f7\u53d6\u57f7\u884c\u6642\u9593\u548c\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u5256\u6790\u3002\u9019\u4e9b\u5256\u6790\u6703\u56de\u994b\u7d66 LLM\uff0c\u7136\u5f8c LLM \u6703\u4fee\u6539\u7a0b\u5f0f\u78bc\u4ee5\u6e1b\u5c11\u958b\u92b7\u3002\u70ba\u4e86\u8a55\u4f30 SOAP \u7684\u6709\u6548\u6027\uff0c\u6211\u5011\u5728 EffiBench\u3001HumanEval \u548c MBPP \u4e0a\u91dd\u5c0d 16 \u500b\u958b\u6e90\u6a21\u578b\u548c 6 \u500b\u9589\u6e90\u6a21\u578b\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\u3002\u6211\u5011\u7684\u8a55\u4f30\u7d50\u679c\u8868\u660e\uff0c\u900f\u904e\u53cd\u8986\u7684\u81ea\u6700\u4f73\u5316\uff0cSOAP \u5927\u5e45\u63d0\u5347\u4e86 LLM \u751f\u6210\u7684\u7a0b\u5f0f\u78bc\u6548\u7387\u3002\u4f8b\u5982\uff0cEffiBench \u4e2d StarCoder2-15B \u7684\u57f7\u884c\u6642\u9593 (ET) \u5f9e 0.93 (\u79d2) \u6e1b\u5c11\u5230 0.12 (\u79d2)\uff0c\u8207\u521d\u59cb\u7a0b\u5f0f\u78bc\u76f8\u6bd4\uff0c\u6e1b\u5c11\u4e86 87.1% \u7684\u57f7\u884c\u6642\u9593\u9700\u6c42\u3002StarCoder2-15B \u7684\u7e3d\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf (TMU) \u4e5f\u5f9e 22.02 (Mb*s) \u6e1b\u5c11\u5230 2.03 (Mb*s)\uff0c\u5728\u57f7\u884c\u904e\u7a0b\u4e2d\u6e1b\u5c11\u4e86 90.8% \u7684\u7e3d\u8a18\u61b6\u9ad4\u6d88\u8017\u3002SOAP \u7684\u539f\u59cb\u7a0b\u5f0f\u78bc\u5df2\u767c\u5e03\u5728 https://github.com/huangd1999/SOAP\u3002", "author": "Dong Huang et.al.", "authors": "Dong Huang, Jianbo Dai, Han Weng, Puzhen Wu, Yuhao Qing, Jie M. Zhang, Heming Cui, Zhijiang Guo", "id": "2405.15189v1", "paper_url": "http://arxiv.org/abs/2405.15189v1", "repo": "https://github.com/huangd1999/soap"}}