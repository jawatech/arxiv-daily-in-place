{"2409.08797": {"publish_time": "2024-09-13", "title": "Exploring SSL Discrete Speech Features for Zipformer-based Contextual ASR", "paper_summary": "Self-supervised learning (SSL) based discrete speech representations are\nhighly compact and domain adaptable. In this paper, SSL discrete speech\nfeatures extracted from WavLM models are used as additional cross-utterance\nacoustic context features in Zipformer-Transducer ASR systems. The efficacy of\nreplacing Fbank features with discrete token features for modelling either\ncross-utterance contexts (from preceding and future segments), or current\nutterance's internal contexts alone, or both at the same time, are demonstrated\nthoroughly on the Gigaspeech 1000-hr corpus. The best Zipformer-Transducer\nsystem using discrete tokens based cross-utterance context features outperforms\nthe baseline using utterance internal context only with statistically\nsignificant word error rate (WER) reductions of 0.32% to 0.41% absolute (2.78%\nto 3.54% relative) on the dev and test data. The lowest published WER of 11.15%\nand 11.14% were obtained on the dev and test sets. Our work is open-source and\npublicly available at\nhttps://github.com/open-creator/icefall/tree/master/egs/gigaspeech/Context\\_ASR.", "paper_summary_zh": "\u57fa\u65bc\u81ea\u6211\u76e3\u7763\u5b78\u7fd2 (SSL) \u7684\u96e2\u6563\u8a9e\u97f3\u8868\u5fb5\u9ad8\u5ea6\u7dca\u6e4a\u4e14\u5177\u5099\u9818\u57df\u9069\u61c9\u6027\u3002\u672c\u6587\u4f7f\u7528\u5f9e WavLM \u6a21\u578b\u4e2d\u8403\u53d6\u7684 SSL \u96e2\u6563\u8a9e\u97f3\u7279\u5fb5\uff0c\u4f5c\u70ba Zipformer-Transducer ASR \u7cfb\u7d71\u4e2d\u984d\u5916\u7684\u8de8 utterance \u97f3\u97ff\u80cc\u666f\u7279\u5fb5\u3002\u50c5\u91dd\u5c0d\u8de8 utterance \u80cc\u666f\uff08\u4f86\u81ea\u524d\u6bb5\u548c\u5f8c\u6bb5\uff09\u3001\u6216\u50c5\u91dd\u5c0d\u7576\u524d utterance \u7684\u5167\u90e8\u80cc\u666f\uff0c\u6216\u540c\u6642\u91dd\u5c0d\u5169\u8005\u5efa\u6a21\uff0c\u4ee5\u96e2\u6563\u4ee3\u865f\u7279\u5fb5\u53d6\u4ee3 Fbank \u7279\u5fb5\u7684\u6548\u80fd\uff0c\u5df2\u5728 Gigaspeech 1000 \u5c0f\u6642\u8a9e\u6599\u5eab\u4e0a\u7372\u5f97\u5fb9\u5e95\u9a57\u8b49\u3002\u4f7f\u7528\u57fa\u65bc\u96e2\u6563\u4ee3\u865f\u7684\u8de8 utterance \u80cc\u666f\u7279\u5fb5\u7684\u6700\u4f73 Zipformer-Transducer \u7cfb\u7d71\uff0c\u5176\u6548\u80fd\u512a\u65bc\u50c5\u4f7f\u7528 utterance \u5167\u90e8\u80cc\u666f\u7684\u57fa\u6e96\uff0c\u5728\u958b\u767c\u548c\u6e2c\u8a66\u8cc7\u6599\u4e0a\uff0c\u5b57\u5143\u932f\u8aa4\u7387 (WER) \u7d55\u5c0d\u964d\u4f4e 0.32% \u81f3 0.41%\uff08\u76f8\u5c0d\u964d\u4f4e 2.78% \u81f3 3.54%\uff09\uff0c\u4e14\u5177\u6709\u7d71\u8a08\u986f\u8457\u6027\u3002\u5728\u958b\u767c\u548c\u6e2c\u8a66\u96c6\u4e0a\uff0c\u7372\u5f97\u6700\u4f4e\u5df2\u767c\u8868\u7684 WER\uff0c\u5206\u5225\u70ba 11.15% \u548c 11.14%\u3002\u6211\u5011\u7684\u4f5c\u54c1\u662f\u958b\u6e90\u7684\uff0c\u4e14\u53ef\u65bc https://github.com/open-creator/icefall/tree/master/egs/gigaspeech/Context\\_ASR \u516c\u958b\u53d6\u5f97\u3002", "author": "Mingyu Cui et.al.", "authors": "Mingyu Cui, Yifan Yang, Jiajun Deng, Jiawen Kang, Shujie Hu, Tianzi Wang, Zhaoqing Li, Shiliang Zhang, Xie Chen, Xunying Liu", "id": "2409.08797v1", "paper_url": "http://arxiv.org/abs/2409.08797v1", "repo": "https://github.com/open-creator/icefall"}}