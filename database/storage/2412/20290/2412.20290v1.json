{"2412.20290": {"publish_time": "2024-12-28", "title": "Transformer-Based Contrastive Meta-Learning For Low-Resource Generalizable Activity Recognition", "paper_summary": "Deep learning has been widely adopted for human activity recognition (HAR)\nwhile generalizing a trained model across diverse users and scenarios remains\nchallenging due to distribution shifts. The inherent low-resource challenge in\nHAR, i.e., collecting and labeling adequate human-involved data can be\nprohibitively costly, further raising the difficulty of tackling DS. We propose\nTACO, a novel transformer-based contrastive meta-learning approach for\ngeneralizable HAR. TACO addresses DS by synthesizing virtual target domains in\ntraining with explicit consideration of model generalizability. Additionally,\nwe extract expressive feature with the attention mechanism of Transformer and\nincorporate the supervised contrastive loss function within our\nmeta-optimization to enhance representation learning. Our evaluation\ndemonstrates that TACO achieves notably better performance across various\nlow-resource DS scenarios.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u5df2\u88ab\u5ee3\u6cdb\u63a1\u7528\u65bc\u4eba\u985e\u6d3b\u52d5\u8fa8\u8b58 (HAR)\uff0c\u7136\u800c\uff0c\u7531\u65bc\u5206\u4f48\u8f49\u79fb\uff0c\u5728\u4e0d\u540c\u4f7f\u7528\u8005\u548c\u5834\u666f\u4e2d\u63a8\u5ee3\u5df2\u8a13\u7df4\u6a21\u578b\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002HAR \u4e2d\u56fa\u6709\u7684\u4f4e\u8cc7\u6e90\u6311\u6230\uff0c\u5373\u6536\u96c6\u548c\u6a19\u8a18\u8db3\u5920\u7684\u4eba\u985e\u53c3\u8207\u8cc7\u6599\u53ef\u80fd\u6210\u672c\u9ad8\u6602\uff0c\u9032\u4e00\u6b65\u589e\u52a0\u4e86\u61c9\u5c0d DS \u7684\u96e3\u5ea6\u3002\u6211\u5011\u63d0\u51fa TACO\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u57fa\u65bc Transformer \u7684\u5c0d\u6bd4\u5143\u5b78\u7fd2\u65b9\u6cd5\uff0c\u7528\u65bc\u53ef\u63a8\u5ee3\u7684 HAR\u3002TACO \u901a\u904e\u5728\u8a13\u7df4\u4e2d\u5408\u6210\u865b\u64ec\u76ee\u6a19\u57df\u4f86\u89e3\u6c7a DS\uff0c\u4e26\u660e\u78ba\u8003\u616e\u6a21\u578b\u7684\u53ef\u63a8\u5ee3\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u5229\u7528 Transformer \u7684\u6ce8\u610f\u529b\u6a5f\u5236\u63d0\u53d6\u8868\u9054\u6027\u7279\u5fb5\uff0c\u4e26\u5728\u6211\u5011\u7684\u5143\u512a\u5316\u4e2d\u7d0d\u5165\u76e3\u7763\u5c0d\u6bd4\u640d\u5931\u51fd\u6578\uff0c\u4ee5\u589e\u5f37\u8868\u793a\u5b78\u7fd2\u3002\u6211\u5011\u7684\u8a55\u4f30\u8868\u660e\uff0cTACO \u5728\u5404\u7a2e\u4f4e\u8cc7\u6e90 DS \u5834\u666f\u4e2d\u53d6\u5f97\u4e86\u986f\u8457\u66f4\u597d\u7684\u6548\u80fd\u3002", "author": "Junyao Wang et.al.", "authors": "Junyao Wang, Mohammad Abdullah Al Faruque", "id": "2412.20290v1", "paper_url": "http://arxiv.org/abs/2412.20290v1", "repo": "null"}}