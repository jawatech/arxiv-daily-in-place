{"2412.04806": {"publish_time": "2024-12-06", "title": "Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning", "paper_summary": "Adapting Large Language Models (LLMs) that are extensively trained on\nabundant text data, and customizing the input prompt to enable time series\nforecasting has received considerable attention. While recent work has shown\ngreat potential for adapting the learned prior of LLMs, the formulation of the\nprompt to finetune LLMs remains challenging as prompt should be aligned with\ntime series data. Additionally, current approaches do not effectively leverage\nword token embeddings which embody the rich representation space learned by\nLLMs. This emphasizes the need for a robust approach to formulate the prompt\nwhich utilizes the word token embeddings while effectively representing the\ncharacteristics of the time series. To address these challenges, we propose\nNNCL-TLLM: Nearest Neighbor Contrastive Learning for Time series forecasting\nvia LLMs. First, we generate time series compatible text prototypes such that\neach text prototype represents both word token embeddings in its neighborhood\nand time series characteristics via end-to-end finetuning. Next, we draw\ninspiration from Nearest Neighbor Contrastive Learning to formulate the prompt\nwhile obtaining the top-$k$ nearest neighbor time series compatible text\nprototypes. We then fine-tune the layer normalization and positional embeddings\nof the LLM, keeping the other layers intact, reducing the trainable parameters\nand decreasing the computational cost. Our comprehensive experiments\ndemonstrate that NNCL-TLLM outperforms in few-shot forecasting while achieving\ncompetitive or superior performance over the state-of-the-art methods in\nlong-term and short-term forecasting tasks.", "paper_summary_zh": "<paragraph>\u91dd\u5c0d\u5927\u91cf\u6587\u672c\u8cc7\u6599\u9032\u884c\u5ee3\u6cdb\u8a13\u7df4\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9069\u61c9\uff0c\u4e26\u81ea\u8a02\u8f38\u5165\u63d0\u793a\u4ee5\u555f\u7528\u6642\u9593\u5e8f\u5217\u9810\u6e2c\uff0c\u5df2\u53d7\u5230\u76f8\u7576\u5927\u7684\u95dc\u6ce8\u3002\u96d6\u7136\u6700\u8fd1\u7684\u7814\u7a76\u986f\u793a\u51fa\u9069\u61c9 LLM \u5b78\u7fd2\u5148\u9a57\u6709\u5f88\u5927\u7684\u6f5b\u529b\uff0c\u4f46\u91dd\u5c0d LLM \u9032\u884c\u5fae\u8abf\u7684\u63d0\u793a\u5236\u5b9a\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u70ba\u63d0\u793a\u61c9\u8207\u6642\u9593\u5e8f\u5217\u8cc7\u6599\u4fdd\u6301\u4e00\u81f4\u3002\u6b64\u5916\uff0c\u76ee\u524d\u7684\u4f5c\u6cd5\u4e26\u672a\u6709\u6548\u5229\u7528\u5b57\u5143\u6a19\u8a18\u5d4c\u5165\uff0c\u800c\u5b57\u5143\u6a19\u8a18\u5d4c\u5165\u9ad4\u73fe\u4e86 LLM \u6240\u5b78\u7fd2\u7684\u8c50\u5bcc\u8868\u793a\u7a7a\u9593\u3002\u9019\u5f37\u8abf\u4e86\u5236\u5b9a\u63d0\u793a\u7684\u5065\u5168\u4f5c\u6cd5\u4e4b\u5fc5\u8981\u6027\uff0c\u8a72\u4f5c\u6cd5\u5229\u7528\u5b57\u5143\u6a19\u8a18\u5d4c\u5165\uff0c\u540c\u6642\u6709\u6548\u5730\u8868\u793a\u6642\u9593\u5e8f\u5217\u7684\u7279\u5fb5\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa NNCL-TLLM\uff1a\u6642\u9593\u5e8f\u5217\u9810\u6e2c\u7684\u6700\u8fd1\u9130\u5c0d\u6bd4\u5b78\u7fd2\uff0c\u900f\u904e LLM\u3002\u9996\u5148\uff0c\u6211\u5011\u7522\u751f\u6642\u9593\u5e8f\u5217\u76f8\u5bb9\u7684\u6587\u5b57\u539f\u578b\uff0c\u4f7f\u5f97\u6bcf\u500b\u6587\u5b57\u539f\u578b\u540c\u6642\u8868\u793a\u5176\u9130\u57df\u4e2d\u7684\u5b57\u5143\u6a19\u8a18\u5d4c\u5165\u548c\u900f\u904e\u7aef\u5c0d\u7aef\u5fae\u8abf\u7684\u6642\u9593\u5e8f\u5217\u7279\u5fb5\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u5f9e\u6700\u8fd1\u9130\u5c0d\u6bd4\u5b78\u7fd2\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u4ee5\u5236\u5b9a\u63d0\u793a\uff0c\u540c\u6642\u53d6\u5f97\u524d $k$ \u500b\u6700\u8fd1\u9130\u6642\u9593\u5e8f\u5217\u76f8\u5bb9\u7684\u6587\u5b57\u539f\u578b\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5fae\u8abf LLM \u7684\u5c64\u6b63\u898f\u5316\u548c\u4f4d\u7f6e\u5d4c\u5165\uff0c\u4fdd\u6301\u5176\u4ed6\u5c64\u4e0d\u8b8a\uff0c\u6e1b\u5c11\u53ef\u8a13\u7df4\u53c3\u6578\u4e26\u964d\u4f4e\u904b\u7b97\u6210\u672c\u3002\u6211\u5011\u7684\u7d9c\u5408\u5be6\u9a57\u8b49\u660e\uff0cNNCL-TLLM \u5728\u5c11\u6b21\u9810\u6e2c\u4e2d\u8868\u73fe\u512a\u65bc\u5176\u4ed6\u65b9\u6cd5\uff0c\u540c\u6642\u5728\u9577\u671f\u548c\u77ed\u671f\u9810\u6e2c\u4efb\u52d9\u4e2d\u9054\u5230\u8207\u6700\u5148\u9032\u7684\u65b9\u6cd5\u7af6\u722d\u6216\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\u7684\u6548\u80fd\u3002</paragraph>", "author": "Jayanie Bogahawatte et.al.", "authors": "Jayanie Bogahawatte, Sachith Seneviratne, Maneesha Perera, Saman Halgamuge", "id": "2412.04806v1", "paper_url": "http://arxiv.org/abs/2412.04806v1", "repo": "null"}}