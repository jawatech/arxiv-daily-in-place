{"2410.22888": {"publish_time": "2024-10-30", "title": "Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector", "paper_summary": "Visual Language Models (VLMs) are vulnerable to adversarial attacks,\nespecially those from adversarial images, which is however under-explored in\nliterature. To facilitate research on this critical safety problem, we first\nconstruct a new laRge-scale Adervsarial images dataset with Diverse hArmful\nResponses (RADAR), given that existing datasets are either small-scale or only\ncontain limited types of harmful responses. With the new RADAR dataset, we\nfurther develop a novel and effective iN-time Embedding-based AdveRSarial Image\nDEtection (NEARSIDE) method, which exploits a single vector that distilled from\nthe hidden states of VLMs, which we call the attacking direction, to achieve\nthe detection of adversarial images against benign ones in the input. Extensive\nexperiments with two victim VLMs, LLaVA and MiniGPT-4, well demonstrate the\neffectiveness, efficiency, and cross-model transferrability of our proposed\nmethod. Our code is available at https://github.com/mob-scu/RADAR-NEARSIDE", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u653b\u64ca\uff0c\u7279\u5225\u662f\u4f86\u81ea\u5c0d\u6297\u6027\u5f71\u50cf\u7684\u653b\u64ca\uff0c\u800c\u9019\u5728\u6587\u737b\u4e2d\u537b\u9bae\u5c11\u63a2\u8a0e\u3002\u70ba\u4e86\u4fc3\u9032\u5c0d\u9019\u500b\u95dc\u9375\u5b89\u5168\u554f\u984c\u7684\u7814\u7a76\uff0c\u6211\u5011\u9996\u5148\u5efa\u69cb\u4e86\u4e00\u500b\u65b0\u7684\u5177\u5099\u591a\u6a23\u5316\u6709\u5bb3\u56de\u61c9\u7684\u5927\u898f\u6a21\u5c0d\u6297\u6027\u5f71\u50cf\u8cc7\u6599\u96c6 (RADAR)\uff0c\u56e0\u70ba\u73fe\u6709\u7684\u8cc7\u6599\u96c6\u898f\u6a21\u904e\u5c0f\u6216\u50c5\u5305\u542b\u6709\u9650\u985e\u578b\u7684\u6709\u5bb3\u56de\u61c9\u3002\u6709\u4e86\u65b0\u7684 RADAR \u8cc7\u6599\u96c6\uff0c\u6211\u5011\u9032\u4e00\u6b65\u958b\u767c\u4e86\u4e00\u7a2e\u65b0\u7a4e\u4e14\u6709\u6548\u7684\u5373\u6642\u5d4c\u5165\u5f0f\u5c0d\u6297\u6027\u5f71\u50cf\u5075\u6e2c (NEARSIDE) \u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u5f9e VLM \u7684\u96b1\u85cf\u72c0\u614b\u4e2d\u8403\u53d6\u51fa\u7684\u55ae\u4e00\u5411\u91cf\uff08\u6211\u5011\u7a31\u4e4b\u70ba\u653b\u64ca\u65b9\u5411\uff09\u4f86\u5075\u6e2c\u8f38\u5165\u4e2d\u7684\u5c0d\u6297\u6027\u5f71\u50cf\u548c\u826f\u6027\u5f71\u50cf\u3002\u4f7f\u7528\u5169\u500b\u53d7\u5bb3\u8005 VLM\uff08LLaVA \u548c MiniGPT-4\uff09\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u5145\u5206\u8b49\u660e\u4e86\u6211\u5011\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u8de8\u6a21\u578b\u53ef\u50b3\u905e\u6027\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u65bc https://github.com/mob-scu/RADAR-NEARSIDE \u53d6\u5f97", "author": "Youcheng Huang et.al.", "authors": "Youcheng Huang, Fengbin Zhu, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua", "id": "2410.22888v1", "paper_url": "http://arxiv.org/abs/2410.22888v1", "repo": "https://github.com/mob-scu/radar-nearside"}}