{"2410.05265": {"publish_time": "2024-10-07", "title": "PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers in LLMs", "paper_summary": "Quantization is essential for deploying Large Language Models (LLMs) by\nenhancing memory efficiency and inference speed. Existing methods for\nactivation quantization mainly address channel-wise outliers, often neglecting\ntoken-wise outliers, leading to reliance on costly per-token dynamic\nquantization. To address this, we introduce PrefixQuant, a novel technique that\nisolates outlier tokens offline without re-training. Specifically, PrefixQuant\nidentifies high-frequency outlier tokens and prefixes them in the KV cache,\npreventing the generation of outlier tokens during inference and simplifying\nquantization. To our knowledge, PrefixQuant is the first to enable efficient\nper-tensor static quantization to outperform expensive per-token dynamic\nquantization. For instance, in W4A4KV4 (4- bit weight, 4-bit activation, and\n4-bit KV cache) Llama-3-8B, PrefixQuant with per-tensor static quantization\nachieves a 7.43 WikiText2 perplexity and 71.08% average accuracy on 5\ncommon-sense reasoning tasks, outperforming previous per-token dynamic\nquantization methods like QuaRot with 0.98 perplexity improvement and +5.98\npoints accuracy. Additionally, the inference speed of W4A4 quantized models\nusing PrefixQuant is 1.60x to 2.81x faster than FP16 models and exceeds QuaRot\nmodels by 1.2x to 1.3x. Our code is available at\n\\url{https://github.com/ChenMnZ/PrefixQuant}.", "paper_summary_zh": "\u91cf\u5316\u5c0d\u65bc\u90e8\u7f72\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u81f3\u95dc\u91cd\u8981\uff0c\u56e0\u70ba\u5b83\u80fd\u63d0\u5347\u8a18\u61b6\u9ad4\u6548\u7387\u548c\u63a8\u8ad6\u901f\u5ea6\u3002\u73fe\u6709\u7528\u65bc\u6fc0\u6d3b\u91cf\u5316\u7684\u65b9\u6cd5\u4e3b\u8981\u91dd\u5c0d\u901a\u9053\u5916\u7570\u5e38\u503c\uff0c\u5e38\u5e38\u5ffd\u7565\u4e86\u4ee4\u724c\u5916\u7570\u5e38\u503c\uff0c\u5c0e\u81f4\u4f9d\u8cf4\u65bc\u6602\u8cb4\u7684\u9010\u4ee4\u724c\u52d5\u614b\u91cf\u5316\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 PrefixQuant\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u6280\u8853\uff0c\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u96e2\u7dda\u9694\u96e2\u7570\u5e38\u4ee4\u724c\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cPrefixQuant \u6703\u8b58\u5225\u9ad8\u983b\u7387\u7570\u5e38\u4ee4\u724c\uff0c\u4e26\u5c07\u5b83\u5011\u7f6e\u65bc KV \u5feb\u53d6\u4e2d\uff0c\u9632\u6b62\u5728\u63a8\u8ad6\u671f\u9593\u7522\u751f\u7570\u5e38\u4ee4\u724c\uff0c\u4e26\u7c21\u5316\u91cf\u5316\u3002\u64da\u6211\u5011\u6240\u77e5\uff0cPrefixQuant \u662f\u7b2c\u4e00\u500b\u80fd\u8b93\u9ad8\u6548\u7684\u9010\u5f35\u91cf\u975c\u614b\u91cf\u5316\u512a\u65bc\u6602\u8cb4\u7684\u9010\u4ee4\u724c\u52d5\u614b\u91cf\u5316\u7684\u6280\u8853\u3002\u4f8b\u5982\uff0c\u5728 W4A4KV4\uff084 \u4f4d\u5143\u6b0a\u91cd\u30014 \u4f4d\u5143\u555f\u52d5\u548c 4 \u4f4d\u5143 KV \u5feb\u53d6\uff09Llama-3-8B \u4e2d\uff0c\u63a1\u7528\u9010\u5f35\u91cf\u975c\u614b\u91cf\u5316\u7684 PrefixQuant \u9054\u5230\u4e86 7.43 WikiText2 \u56f0\u60d1\u5ea6\u548c 5 \u9805\u5e38\u8b58\u63a8\u7406\u4efb\u52d9\u7684 71.08% \u5e73\u5747\u6e96\u78ba\u5ea6\uff0c\u512a\u65bc\u5148\u524d\u7684\u9010\u4ee4\u724c\u52d5\u614b\u91cf\u5316\u65b9\u6cd5\uff0c\u4f8b\u5982 QuaRot\uff0c\u56f0\u60d1\u5ea6\u6539\u5584\u4e86 0.98\uff0c\u6e96\u78ba\u5ea6\u63d0\u9ad8\u4e86 +5.98 \u9ede\u3002\u6b64\u5916\uff0c\u4f7f\u7528 PrefixQuant \u7684 W4A4 \u91cf\u5316\u6a21\u578b\u7684\u63a8\u8ad6\u901f\u5ea6\u6bd4 FP16 \u6a21\u578b\u5feb 1.60 \u500d\u5230 2.81 \u500d\uff0c\u4e26\u8d85\u904e QuaRot \u6a21\u578b 1.2 \u500d\u5230 1.3 \u500d\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 \\url{https://github.com/ChenMnZ/PrefixQuant} \u53d6\u5f97\u3002", "author": "Mengzhao Chen et.al.", "authors": "Mengzhao Chen, Yi Liu, Jiahao Wang, Yi Bin, Wenqi Shao, Ping Luo", "id": "2410.05265v1", "paper_url": "http://arxiv.org/abs/2410.05265v1", "repo": "https://github.com/chenmnz/prefixquant"}}