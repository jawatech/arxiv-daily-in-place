{"2502.14581": {"publish_time": "2025-02-20", "title": "A Statistical Case Against Empirical Human-AI Alignment", "paper_summary": "Empirical human-AI alignment aims to make AI systems act in line with\nobserved human behavior. While noble in its goals, we argue that empirical\nalignment can inadvertently introduce statistical biases that warrant caution.\nThis position paper thus advocates against naive empirical alignment, offering\nprescriptive alignment and a posteriori empirical alignment as alternatives. We\nsubstantiate our principled argument by tangible examples like human-centric\ndecoding of language models.", "paper_summary_zh": "\u7d93\u9a57\u4e3b\u7fa9\u7684\u4eba\u5de5\u667a\u6167\u6821\u6e96\u65e8\u5728\u4f7f\u4eba\u5de5\u667a\u6167\u7cfb\u7d71\u6839\u64da\u89c0\u5bdf\u5230\u7684\u4eba\u985e\u884c\u70ba\u63a1\u53d6\u884c\u52d5\u3002\u5118\u7ba1\u76ee\u6a19\u5d07\u9ad8\uff0c\u6211\u5011\u8a8d\u70ba\u7d93\u9a57\u4e3b\u7fa9\u6821\u6e96\u53ef\u80fd\u6703\u7121\u610f\u4e2d\u5f15\u5165\u9700\u8981\u8b39\u614e\u5c0d\u5f85\u7684\u7d71\u8a08\u504f\u5dee\u3002\u56e0\u6b64\uff0c\u672c\u7acb\u5834\u6587\u4ef6\u4e3b\u5f35\u53cd\u5c0d\u5929\u771f\u7684\u7d93\u9a57\u4e3b\u7fa9\u6821\u6e96\uff0c\u63d0\u4f9b\u898f\u7bc4\u6027\u6821\u6e96\u548c\u5f8c\u9a57\u7d93\u9a57\u4e3b\u7fa9\u6821\u6e96\u4f5c\u70ba\u66ff\u4ee3\u65b9\u6848\u3002\u6211\u5011\u4ee5\u5177\u9ad4\u7684\u4f8b\u5b50\uff08\u4f8b\u5982\u4ee5\u4eba\u70ba\u4e2d\u5fc3\u7684\u8a9e\u8a00\u6a21\u578b\u89e3\u78bc\uff09\u4f86\u8b49\u660e\u6211\u5011\u7684\u539f\u5247\u6027\u8ad6\u9ede\u3002", "author": "Julian Rodemann et.al.", "authors": "Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin", "id": "2502.14581v1", "paper_url": "http://arxiv.org/abs/2502.14581v1", "repo": "null"}}