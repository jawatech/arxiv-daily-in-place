{"2405.19313": {"publish_time": "2024-05-29", "title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice", "paper_summary": "The observed similarities in the behavior of humans and Large Language Models\n(LLMs) have prompted researchers to consider the potential of using LLMs as\nmodels of human cognition. However, several significant challenges must be\naddressed before LLMs can be legitimately regarded as cognitive models. For\ninstance, LLMs are trained on far more data than humans typically encounter,\nand may have been directly trained on human data in specific cognitive tasks or\naligned with human preferences. Consequently, the origins of these behavioral\nsimilarities are not well understood. In this paper, we propose a novel way to\nenhance the utility of LLMs as cognitive models. This approach involves (i)\nleveraging computationally equivalent tasks that both an LLM and a rational\nagent need to master for solving a cognitive problem and (ii) examining the\nspecific task distributions required for an LLM to exhibit human-like\nbehaviors. We apply this approach to decision-making -- specifically risky and\nintertemporal choice -- where the key computationally equivalent task is the\narithmetic of expected value calculations. We show that an LLM pretrained on an\necologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts\nhuman behavior better than many traditional cognitive models. Pretraining LLMs\non ecologically valid arithmetic datasets is sufficient to produce a strong\ncorrespondence between these models and human decision-making. Our results also\nsuggest that LLMs used as cognitive models should be carefully investigated via\nablation studies of the pretraining data.", "paper_summary_zh": "\u5728\u4eba\u985e\u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u884c\u70ba\u4e2d\u89c0\u5bdf\u5230\u7684\u76f8\u4f3c\u6027\u4fc3\u4f7f\u7814\u7a76\u4eba\u54e1\u8003\u616e\u5c07 LLM \u7528\u4f5c\u4eba\u985e\u8a8d\u77e5\u6a21\u578b\u7684\u53ef\u80fd\u6027\u3002\u7136\u800c\uff0c\u5728 LLM \u53ef\u4ee5\u88ab\u5408\u6cd5\u5730\u8996\u70ba\u8a8d\u77e5\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u9808\u89e3\u6c7a\u5e7e\u500b\u91cd\u5927\u7684\u6311\u6230\u3002\u4f8b\u5982\uff0cLLM \u63a5\u53d7\u7684\u8a13\u7df4\u6578\u64da\u9060\u591a\u65bc\u4eba\u985e\u901a\u5e38\u9047\u5230\u7684\u6578\u64da\uff0c\u4e26\u4e14\u53ef\u80fd\u5728\u7279\u5b9a\u8a8d\u77e5\u4efb\u52d9\u4e2d\u76f4\u63a5\u63a5\u53d7\u904e\u4eba\u985e\u6578\u64da\u7684\u8a13\u7df4\uff0c\u6216\u8207\u4eba\u985e\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u56e0\u6b64\uff0c\u9019\u4e9b\u884c\u70ba\u76f8\u4f3c\u6027\u7684\u8d77\u6e90\u4e26\u672a\u5f97\u5230\u5f88\u597d\u7684\u7406\u89e3\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\u4f86\u589e\u5f37 LLM \u4f5c\u70ba\u8a8d\u77e5\u6a21\u578b\u7684\u6548\u7528\u3002\u6b64\u65b9\u6cd5\u5305\u62ec\uff1a(i) \u5229\u7528 LLM \u548c\u7406\u6027\u4ee3\u7406\u90fd\u5fc5\u9808\u638c\u63e1\u7684\u8a08\u7b97\u7b49\u6548\u4efb\u52d9\u4f86\u89e3\u6c7a\u8a8d\u77e5\u554f\u984c\uff0c\u4ee5\u53ca (ii) \u6aa2\u67e5 LLM \u8868\u73fe\u51fa\u985e\u4eba\u884c\u70ba\u6240\u9700\u7684\u7279\u5b9a\u4efb\u52d9\u5206\u4f48\u3002\u6211\u5011\u5c07\u6b64\u65b9\u6cd5\u61c9\u7528\u65bc\u6c7a\u7b56\u5236\u5b9a\u2014\u2014\u7279\u5225\u662f\u5192\u96aa\u548c\u6642\u9593\u9593\u9078\u64c7\u2014\u2014\u5176\u4e2d\u95dc\u9375\u7684\u8a08\u7b97\u7b49\u6548\u4efb\u52d9\u662f\u9810\u671f\u503c\u8a08\u7b97\u7684\u7b97\u8853\u3002\u6211\u5011\u8868\u660e\uff0c\u5728\u751f\u614b\u5b78\u4e0a\u6709\u6548\u7684\u7b97\u8853\u6578\u64da\u96c6\uff08\u6211\u5011\u7a31\u4e4b\u70ba Arithmetic-GPT\uff09\u4e0a\u9810\u5148\u8a13\u7df4\u7684 LLM \u6bd4\u8a31\u591a\u50b3\u7d71\u8a8d\u77e5\u6a21\u578b\u66f4\u597d\u5730\u9810\u6e2c\u4eba\u985e\u884c\u70ba\u3002\u5728\u751f\u614b\u5b78\u4e0a\u6709\u6548\u7684\u7b97\u8853\u6578\u64da\u96c6\u4e0a\u5c0d LLM \u9032\u884c\u9810\u8a13\u7df4\u8db3\u4ee5\u5728\u9019\u4e9b\u6a21\u578b\u548c\u4eba\u985e\u6c7a\u7b56\u5236\u5b9a\u4e4b\u9593\u7522\u751f\u5f37\u70c8\u7684\u5c0d\u61c9\u95dc\u4fc2\u3002\u6211\u5011\u7684\u7d50\u679c\u9084\u8868\u660e\uff0c\u7528\u4f5c\u8a8d\u77e5\u6a21\u578b\u7684 LLM \u61c9\u901a\u904e\u9810\u8a13\u7df4\u6578\u64da\u7684\u6d88\u878d\u7814\u7a76\u9032\u884c\u4ed4\u7d30\u8abf\u67e5\u3002", "author": "Jian-Qiao Zhu et.al.", "authors": "Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths", "id": "2405.19313v1", "paper_url": "http://arxiv.org/abs/2405.19313v1", "repo": "null"}}