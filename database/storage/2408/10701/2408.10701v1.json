{"2408.10701": {"publish_time": "2024-08-20", "title": "Ferret: Faster and Effective Automated Red Teaming with Reward-Based Scoring Technique", "paper_summary": "In today's era, where large language models (LLMs) are integrated into\nnumerous real-world applications, ensuring their safety and robustness is\ncrucial for responsible AI usage. Automated red-teaming methods play a key role\nin this process by generating adversarial attacks to identify and mitigate\npotential vulnerabilities in these models. However, existing methods often\nstruggle with slow performance, limited categorical diversity, and high\nresource demands. While Rainbow Teaming, a recent approach, addresses the\ndiversity challenge by framing adversarial prompt generation as a\nquality-diversity search, it remains slow and requires a large fine-tuned\nmutator for optimal performance. To overcome these limitations, we propose\nFerret, a novel approach that builds upon Rainbow Teaming by generating\nmultiple adversarial prompt mutations per iteration and using a scoring\nfunction to rank and select the most effective adversarial prompt. We explore\nvarious scoring functions, including reward models, Llama Guard, and\nLLM-as-a-judge, to rank adversarial mutations based on their potential harm to\nimprove the efficiency of the search for harmful mutations. Our results\ndemonstrate that Ferret, utilizing a reward model as a scoring function,\nimproves the overall attack success rate (ASR) to 95%, which is 46% higher than\nRainbow Teaming. Additionally, Ferret reduces the time needed to achieve a 90%\nASR by 15.2% compared to the baseline and generates adversarial prompts that\nare transferable i.e. effective on other LLMs of larger size. Our codes are\navailable at https://github.com/declare-lab/ferret.", "paper_summary_zh": "<paragraph>\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u6574\u5408\u81f3\u8a31\u591a\u771f\u5be6\u4e16\u754c\u7684\u61c9\u7528\u7a0b\u5f0f\u4e2d\uff0c\u78ba\u4fdd\u5176\u5b89\u5168\u6027\u548c\u7a69\u5065\u6027\u5c0d\u65bc\u8ca0\u8cac\u4efb\u7684 AI \u4f7f\u7528\u81f3\u95dc\u91cd\u8981\u3002\u81ea\u52d5\u5316\u7d05\u968a\u65b9\u6cd5\u5728\u9019\u500b\u904e\u7a0b\u4e2d\u626e\u6f14\u95dc\u9375\u89d2\u8272\uff0c\u900f\u904e\u7522\u751f\u5c0d\u6297\u6027\u653b\u64ca\u4f86\u627e\u51fa\u4e26\u6e1b\u8f15\u9019\u4e9b\u6a21\u578b\u4e2d\u7684\u6f5b\u5728\u6f0f\u6d1e\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u65b9\u6cd5\u7d93\u5e38\u9762\u81e8\u6548\u80fd\u7de9\u6162\u3001\u5206\u985e\u591a\u6a23\u6027\u53d7\u9650\u548c\u8cc7\u6e90\u9700\u6c42\u9ad8\u7684\u554f\u984c\u3002\u96d6\u7136 Rainbow Teaming \u9019\u500b\u8fd1\u671f\u65b9\u6cd5\u900f\u904e\u5c07\u5c0d\u6297\u6027\u63d0\u793a\u7522\u751f\u67b6\u69cb\u70ba\u54c1\u8cea\u591a\u6a23\u6027\u641c\u5c0b\u4f86\u89e3\u6c7a\u591a\u6a23\u6027\u6311\u6230\uff0c\u4f46\u5b83\u4ecd\u7136\u7de9\u6162\u4e14\u9700\u8981\u4e00\u500b\u7d93\u904e\u5927\u91cf\u5fae\u8abf\u7684\u8b8a\u7570\u5668\u624d\u80fd\u9054\u5230\u6700\u4f73\u6548\u80fd\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa Ferret\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u900f\u904e\u5728\u6bcf\u6b21\u53cd\u8986\u904b\u7b97\u4e2d\u7522\u751f\u591a\u500b\u5c0d\u6297\u6027\u63d0\u793a\u8b8a\u7570\u4e26\u4f7f\u7528\u8a55\u5206\u51fd\u6578\u4f86\u6392\u540d\u4e26\u9078\u51fa\u6700\u6709\u6548\u7684\u5c0d\u6297\u6027\u63d0\u793a\uff0c\u9032\u800c\u5efa\u7acb\u5728 Rainbow Teaming \u4e4b\u4e0a\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u5404\u7a2e\u8a55\u5206\u51fd\u6578\uff0c\u5305\u62ec\u734e\u52f5\u6a21\u578b\u3001Llama Guard \u548c LLM-as-a-judge\uff0c\u6839\u64da\u5c0d\u6297\u6027\u8b8a\u7570\u5c0d\u6709\u5bb3\u8b8a\u7570\u641c\u5c0b\u6548\u7387\u7684\u6f5b\u5728\u5371\u5bb3\u4f86\u5c0d\u5176\u9032\u884c\u6392\u540d\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\uff0cFerret \u5229\u7528\u734e\u52f5\u6a21\u578b\u4f5c\u70ba\u8a55\u5206\u51fd\u6578\uff0c\u5c07\u6574\u9ad4\u653b\u64ca\u6210\u529f\u7387 (ASR) \u63d0\u5347\u81f3 95%\uff0c\u6bd4 Rainbow Teaming \u9ad8\u51fa 46%\u3002\u6b64\u5916\uff0c\u8207\u57fa\u6e96\u76f8\u6bd4\uff0cFerret \u5c07\u9054\u5230 90% ASR \u6240\u9700\u7684\u6642\u9593\u6e1b\u5c11\u4e86 15.2%\uff0c\u4e26\u7522\u751f\u53ef\u8f49\u79fb\u7684\u5c0d\u6297\u6027\u63d0\u793a\uff0c\u4ea6\u5373\u5c0d\u66f4\u5927\u898f\u6a21\u7684\u5176\u4ed6 LLM \u6709\u6548\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/declare-lab/ferret \u53d6\u5f97\u3002</paragraph>", "author": "Tej Deep Pala et.al.", "authors": "Tej Deep Pala, Vernon Y. H. Toh, Rishabh Bhardwaj, Soujanya Poria", "id": "2408.10701v1", "paper_url": "http://arxiv.org/abs/2408.10701v1", "repo": "https://github.com/declare-lab/ferret"}}