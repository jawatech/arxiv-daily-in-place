{"2410.22099": {"publish_time": "2024-10-29", "title": "TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds", "paper_summary": "Brain imaging studies have demonstrated that diffusion MRI tractography\ngeometric shape descriptors can inform the study of the brain's white matter\npathways and their relationship to brain function. In this work, we investigate\nthe possibility of utilizing a deep learning model to compute shape measures of\nthe brain's white matter connections. We introduce a novel framework,\nTractShapeNet, that leverages a point cloud representation of tractography to\ncompute five shape measures: length, span, volume, total surface area, and\nirregularity. We assess the performance of the method on a large dataset\nincluding 1065 healthy young adults. Experiments for shape measure computation\ndemonstrate that our proposed TractShapeNet outperforms other point cloud-based\nneural network models in both the Pearson correlation coefficient and\nnormalized error metrics. We compare the inference runtime results with the\nconventional shape computation tool DSI-Studio. Our results demonstrate that a\ndeep learning approach enables faster and more efficient shape measure\ncomputation. We also conduct experiments on two downstream language cognition\nprediction tasks, showing that shape measures from TractShapeNet perform\nsimilarly to those computed by DSI-Studio. Our code will be available at:\nhttps://github.com/SlicerDMRI/TractShapeNet.", "paper_summary_zh": "\u8166\u90e8\u5f71\u50cf\u7814\u7a76\u5df2\u8b49\u5be6\uff0c\u64f4\u6563\u78c1\u632f\u9020\u5f71\u7e96\u7dad\u8ffd\u8e64\n\u5e7e\u4f55\u5f62\u72c0\u63cf\u8ff0\u7b26\u53ef\u70ba\u8166\u90e8\u767d\u8cea\n\u8def\u5f91\u53ca\u5176\u8207\u8166\u90e8\u529f\u80fd\u7684\u95dc\u4fc2\u7814\u7a76\u63d0\u4f9b\u8cc7\u8a0a\u3002\u5728\u6b64\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\n\u5229\u7528\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u4f86\u8a08\u7b97\u8166\u90e8\u767d\u8cea\u9023\u63a5\u7684\u5f62\u72c0\u6e2c\u91cf\u503c\u7684\u53ef\u80fd\u6027\u3002\u6211\u5011\u4ecb\u7d39\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\nTractShapeNet\uff0c\u5b83\u5229\u7528\u7e96\u7dad\u8ffd\u8e64\u7684\u9ede\u96f2\u8868\u793a\u6cd5\u4f86\n\u8a08\u7b97\u4e94\u500b\u5f62\u72c0\u6e2c\u91cf\u503c\uff1a\u9577\u5ea6\u3001\u8de8\u5ea6\u3001\u9ad4\u7a4d\u3001\u7e3d\u8868\u9762\u7a4d\u548c\n\u4e0d\u898f\u5247\u6027\u3002\u6211\u5011\u5728\u4e00\u500b\u5305\u542b 1065 \u540d\u5065\u5eb7\u5e74\u8f15\u4eba\u7684\u5927\u578b\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30\u8a72\u65b9\u6cd5\u7684\u6548\u80fd\u3002\u5f62\u72c0\u6e2c\u91cf\u503c\u8a08\u7b97\u7684\u5be6\u9a57\n\u8b49\u660e\u6211\u5011\u63d0\u51fa\u7684 TractShapeNet \u5728 Pearson \u76f8\u95dc\u4fc2\u6578\u548c\n\u6a19\u6e96\u5316\u8aa4\u5dee\u6307\u6a19\u65b9\u9762\u512a\u65bc\u5176\u4ed6\u57fa\u65bc\u9ede\u96f2\u7684\u795e\u7d93\u7db2\u8def\u6a21\u578b\u3002\u6211\u5011\u5c07\u63a8\u8ad6\u57f7\u884c\u6642\u9593\u7d50\u679c\u8207\n\u50b3\u7d71\u5f62\u72c0\u8a08\u7b97\u5de5\u5177 DSI-Studio \u9032\u884c\u6bd4\u8f03\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\u6df1\u5ea6\u5b78\u7fd2\u65b9\u6cd5\u80fd\u5be6\u73fe\u66f4\u5feb\u3001\u66f4\u6709\u6548\u7387\u7684\u5f62\u72c0\u6e2c\u91cf\u503c\n\u8a08\u7b97\u3002\u6211\u5011\u9084\u5c0d\u5169\u500b\u4e0b\u6e38\u8a9e\u8a00\u8a8d\u77e5\u9810\u6e2c\u4efb\u52d9\u9032\u884c\u5be6\u9a57\uff0c\u7d50\u679c\u986f\u793a TractShapeNet \u7684\u5f62\u72c0\u6e2c\u91cf\u503c\u57f7\u884c\n\u985e\u4f3c\u65bc DSI-Studio \u8a08\u7b97\u7684\u5f62\u72c0\u6e2c\u91cf\u503c\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5c07\u53ef\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u53d6\u5f97\uff1a\nhttps://github.com/SlicerDMRI/TractShapeNet\u3002", "author": "Yui Lo et.al.", "authors": "Yui Lo, Yuqian Chen, Dongnan Liu, Jon Haitz Legarreta, Leo Zekelman, Fan Zhang, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell", "id": "2410.22099v1", "paper_url": "http://arxiv.org/abs/2410.22099v1", "repo": "null"}}