
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-02**|**MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**|Binxu Li et.al.|[2407.02483v1](http://arxiv.org/abs/2407.02483v1)|null|
|**2024-07-02**|**CALICO: Confident Active Learning with Integrated Calibration**|Lorenzo S. Querol et.al.|[2407.02335v1](http://arxiv.org/abs/2407.02335v1)|null|
|**2024-07-02**|**A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**|Minghao Zhou et.al.|[2407.02283v1](http://arxiv.org/abs/2407.02283v1)|[link](https://github.com/zmhhmz/resfu)|
|**2024-07-02**|**FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**|Yangyang Xiang et.al.|[2407.02280v1](http://arxiv.org/abs/2407.02280v1)|[link](https://github.com/hustxyy/fedia)|
|**2024-07-02**|**Generative Monoculture in Large Language Models**|Fan Wu et.al.|[2407.02209v1](http://arxiv.org/abs/2407.02209v1)|null|
|**2024-07-02**|**Abstract Dialectical Frameworks are Boolean Networks (full version)**|Jesse Heyninck et.al.|[2407.02055v1](http://arxiv.org/abs/2407.02055v1)|null|
|**2024-07-02**|**A Method to Facilitate Membership Inference Attacks in Deep Learning Models**|Zitao Chen et.al.|[2407.01919v1](http://arxiv.org/abs/2407.01919v1)|null|
|**2024-07-01**|**Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**|Sebastian A. Cruz Romero et.al.|[2407.01705v1](http://arxiv.org/abs/2407.01705v1)|null|
|**2024-07-01**|**Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**|Ana Carolina Alves et.al.|[2407.01318v1](http://arxiv.org/abs/2407.01318v1)|null|
|**2024-07-01**|**MIRAI: Evaluating LLM Agents for Event Forecasting**|Chenchen Ye et.al.|[2407.01231v1](http://arxiv.org/abs/2407.01231v1)|null|
|**2024-07-01**|**Integrated feature analysis for deep learning interpretation and class activation maps**|Yanli Li et.al.|[2407.01142v1](http://arxiv.org/abs/2407.01142v1)|[link](https://github.com/yanlili27/ifa)|
|**2024-07-01**|**Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**|Wenqiang Zu et.al.|[2407.01003v2](http://arxiv.org/abs/2407.01003v2)|null|
|**2024-07-01**|**Individual brain parcellation: Review of methods, validations and applications**|Chengyi Li et.al.|[2407.00984v1](http://arxiv.org/abs/2407.00984v1)|null|
|**2024-07-01**|**Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**|Cheng Su et.al.|[2407.00978v1](http://arxiv.org/abs/2407.00978v1)|null|
|**2024-07-01**|**Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**|Parviz Ghafariasl et.al.|[2407.01647v1](http://arxiv.org/abs/2407.01647v1)|null|
|**2024-07-01**|**Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**|Sepehr Salem Ghahfarokhi et.al.|[2407.00967v1](http://arxiv.org/abs/2407.00967v1)|null|
|**2024-06-30**|**Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**|Stefan Arnold et.al.|[2407.00764v1](http://arxiv.org/abs/2407.00764v1)|null|
|**2024-06-30**|**Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**|Peng Huang et.al.|[2407.00752v1](http://arxiv.org/abs/2407.00752v1)|null|
|**2024-06-30**|**Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**|Qiuhao Lu et.al.|[2407.00731v1](http://arxiv.org/abs/2407.00731v1)|null|
|**2024-06-30**|**SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**|Zekang Yang et.al.|[2407.00664v1](http://arxiv.org/abs/2407.00664v1)|[link](https://github.com/yang-ze-kang/scmil)|
|**2024-06-30**|**TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**|Jintai Chen et.al.|[2407.00631v1](http://arxiv.org/abs/2407.00631v1)|[link](https://github.com/ml2health/ml2clinicaltrials)|
|**2024-06-29**|**Answering real-world clinical questions using large language model based systems**|Yen Sia Low et.al.|[2407.00541v1](http://arxiv.org/abs/2407.00541v1)|null|
|**2024-06-29**|**Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**|Kiarash Sedghighadikolaei et.al.|[2407.00538v1](http://arxiv.org/abs/2407.00538v1)|null|
|**2024-06-29**|**Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**|Hok-Shing Lau et.al.|[2407.00531v1](http://arxiv.org/abs/2407.00531v1)|null|
|**2024-06-29**|**ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**|Zhiyuan Wang et.al.|[2407.00499v1](http://arxiv.org/abs/2407.00499v1)|null|
|**2024-06-29**|**MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**|Luyuan Xie et.al.|[2407.00474v1](http://arxiv.org/abs/2407.00474v1)|null|
|**2024-06-29**|**pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**|Luyuan Xie et.al.|[2407.00462v1](http://arxiv.org/abs/2407.00462v1)|null|
|**2024-06-29**|**Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**|Omer Goldman et.al.|[2407.00402v1](http://arxiv.org/abs/2407.00402v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-28**|**Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**|Dat Hong et.al.|[2407.00147v1](http://arxiv.org/abs/2407.00147v1)|null|
|**2024-06-28**|**BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration**|Noel Crawford et.al.|[2406.20041v3](http://arxiv.org/abs/2406.20041v3)|null|
|**2024-06-28**|**Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work**|Christopher Irwin et.al.|[2407.00142v1](http://arxiv.org/abs/2407.00142v1)|null|
|**2024-06-28**|**Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**|Haojun Jiang et.al.|[2406.19756v1](http://arxiv.org/abs/2406.19756v1)|null|
|**2024-06-28**|**Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction**|Akash Awasthi et.al.|[2407.00129v1](http://arxiv.org/abs/2407.00129v1)|null|
|**2024-06-28**|**ACES: Automatic Cohort Extraction System for Event-Stream Datasets**|Justin Xu et.al.|[2406.19653v1](http://arxiv.org/abs/2406.19653v1)|[link](https://github.com/justin13601/aces)|
|**2024-06-28**|**Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**|Huajun Zhou et.al.|[2406.19611v1](http://arxiv.org/abs/2406.19611v1)|null|
|**2024-06-27**|**PathAlign: A vision-language model for whole slide images in histopathology**|Faruk Ahmed et.al.|[2406.19578v1](http://arxiv.org/abs/2406.19578v1)|null|
|**2024-06-27**|**Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques**|Abraham G Taye et.al.|[2407.00120v1](http://arxiv.org/abs/2407.00120v1)|null|
|**2024-06-27**|**HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**|Junying Chen et.al.|[2406.19280v1](http://arxiv.org/abs/2406.19280v1)|[link](https://github.com/freedomintelligence/huatuogpt-vision)|
|**2024-06-27**|**Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges**|Mahmoud Ibrahim et.al.|[2407.00116v2](http://arxiv.org/abs/2407.00116v2)|null|
|**2024-06-27**|**Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**|Fuseini Mumuni et.al.|[2406.19057v2](http://arxiv.org/abs/2406.19057v2)|null|
|**2024-06-27**|**FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**|Alexander Herzog et.al.|[2406.19050v1](http://arxiv.org/abs/2406.19050v1)|null|
|**2024-06-27**|**CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI**|Zi Wang et.al.|[2406.19043v1](http://arxiv.org/abs/2406.19043v1)|[link](https://github.com/cmrxrecon/cmrxrecon2024)|
|**2024-06-27**|**Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes**|Joachim Schaeffer et.al.|[2406.19015v1](http://arxiv.org/abs/2406.19015v1)|null|
|**2024-06-27**|**Multiple Kronecker RLS fusion-based link propagation for drug-side effect prediction**|Yuqing Qian et.al.|[2407.00105v1](http://arxiv.org/abs/2407.00105v1)|null|
|**2024-06-27**|**FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity**|Zhaobin Sun et.al.|[2406.18995v1](http://arxiv.org/abs/2406.18995v1)|[link](https://github.com/szbonaldo/fedmlp)|
|**2024-06-27**|**Alignment For Performance Improvement in Conversation Bots**|Raghav Garg et.al.|[2406.18954v1](http://arxiv.org/abs/2406.18954v1)|null|
|**2024-06-27**|**AI-Driven Skin Cancer Diagnosis: Grad-CAM and Expert Annotations for Enhanced Interpretability**|Iv√°n Matas et.al.|[2407.00104v1](http://arxiv.org/abs/2407.00104v1)|null|
|**2024-06-27**|**Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised Clustering Analysis**|Mingyang Zhao et.al.|[2406.18817v1](http://arxiv.org/abs/2406.18817v1)|[link](https://github.com/zikai1/cvpr24_pointsetreg)|
|**2024-06-26**|**WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model**|Yi Zhu et.al.|[2406.18731v1](http://arxiv.org/abs/2406.18731v1)|[link](https://github.com/zhu00121/wavrx)|
|**2024-06-26**|**Petal-X: Human-Centered Visual Explanations to Improve Cardiovascular Risk Communication**|Diego Rojo et.al.|[2406.18690v1](http://arxiv.org/abs/2406.18690v1)|null|
|**2024-06-26**|**Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process**|Tianyu Lin et.al.|[2406.18361v2](http://arxiv.org/abs/2406.18361v2)|[link](https://github.com/lin-tianyu/stable-diffusion-seg)|
|**2024-06-26**|**Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer**|Liming Wang et.al.|[2406.18625v1](http://arxiv.org/abs/2406.18625v1)|null|
|**2024-06-26**|**EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models**|Chun-Chieh Liao et.al.|[2406.18087v1](http://arxiv.org/abs/2406.18087v1)|null|
|**2024-06-26**|**Few-Shot Medical Image Segmentation with High-Fidelity Prototypes**|Song Tang et.al.|[2406.18074v1](http://arxiv.org/abs/2406.18074v1)|[link](https://github.com/tntek/dspnet)|
|**2024-06-26**|**Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources**|Yiming Li et.al.|[2406.18049v1](http://arxiv.org/abs/2406.18049v1)|null|
|**2024-06-26**|**Automated Clinical Data Extraction with Knowledge Conditioned LLMs**|Diya Li et.al.|[2406.18027v1](http://arxiv.org/abs/2406.18027v1)|null|
|**2024-06-26**|**AutoOPE: Automated Off-Policy Estimator Selection**|Nicol√≤ Felicioni et.al.|[2406.18022v1](http://arxiv.org/abs/2406.18022v1)|null|
|**2024-06-26**|**Multi-step Knowledge Retrieval and Inference over Unstructured Data**|Aditya Kalyanpur et.al.|[2406.17987v1](http://arxiv.org/abs/2406.17987v1)|null|
|**2024-06-25**|**Domain Adaptation of Echocardiography Segmentation Via Reinforcement Learning**|Arnaud Judge et.al.|[2406.17902v1](http://arxiv.org/abs/2406.17902v1)|null|
|**2024-06-25**|**CTBench: A Comprehensive Benchmark for Evaluating Language Model Capabilities in Clinical Trial Design**|Nafis Neehal et.al.|[2406.17888v1](http://arxiv.org/abs/2406.17888v1)|[link](https://github.com/nafis-neehal/CTBench_LLM)|
|**2024-06-25**|**BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging**|Zeinab Sherkatghanad et.al.|[2406.17640v1](http://arxiv.org/abs/2406.17640v1)|[link](https://github.com/z-sherkat/baytta)|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-25**|**On the consistency of hyper-parameter selection in value-based deep reinforcement learning**|Johan Obando-Ceron et.al.|[2406.17523v2](http://arxiv.org/abs/2406.17523v2)|null|
|**2024-06-25**|**TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification**|Joshua Niemeijer et.al.|[2406.17473v1](http://arxiv.org/abs/2406.17473v1)|null|
|**2024-06-25**|**AI for the prediction of early stages of Alzheimer's disease from neuroimaging biomarkers -- A narrative review of a growing field**|Thorsten Rudroff et.al.|[2406.17822v1](http://arxiv.org/abs/2406.17822v1)|null|
|**2024-06-25**|**Task-Agnostic Federated Learning**|Zhengtao Yao et.al.|[2406.17235v1](http://arxiv.org/abs/2406.17235v1)|null|
|**2024-06-24**|**Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars**|Wesley Brewer et.al.|[2406.17812v1](http://arxiv.org/abs/2406.17812v1)|null|
|**2024-06-24**|**PIC2O-Sim: A Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator for Ultra-Fast Photonic Device FDTD Simulation**|Pingchuan Ma et.al.|[2406.17810v1](http://arxiv.org/abs/2406.17810v1)|[link](https://github.com/ScopeX-ASU/PIC2O-Sim)|
|**2024-06-24**|**The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources**|Shayne Longpre et.al.|[2406.16746v2](http://arxiv.org/abs/2406.16746v2)|null|
|**2024-06-24**|**Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings**|Andrea Posada et.al.|[2406.16611v1](http://arxiv.org/abs/2406.16611v1)|[link](https://github.com/anpoc/language-models-in-medicine)|
|**2024-06-24**|**Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models**|Daniel Lopez-Martinez et.al.|[2406.16455v1](http://arxiv.org/abs/2406.16455v1)|null|
|**2024-06-24**|**A large language model for predicting T cell receptor-antigen binding specificity**|Xing Fang et.al.|[2406.16995v1](http://arxiv.org/abs/2406.16995v1)|[link](https://github.com/hliulab/tcrlm)|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**Continuous Output Personality Detection Models via Mixed Strategy Training**|Rong Wang et.al.|[2406.16223v1](http://arxiv.org/abs/2406.16223v1)|null|
|**2024-06-23**|**On Instabilities of Unsupervised Denoising Diffusion Models in Magnetic Resonance Imaging Reconstruction**|Tianyu Han et.al.|[2406.16983v1](http://arxiv.org/abs/2406.16983v1)|null|
|**2024-06-23**|**Research on Disease Prediction Model Construction Based on Computer AI deep Learning Technology**|Yang Lin et.al.|[2406.16982v1](http://arxiv.org/abs/2406.16982v1)|null|
|**2024-06-23**|**Towards Open Respiratory Acoustic Foundation Models: Pretraining and Benchmarking**|Yuwei Zhang et.al.|[2406.16148v1](http://arxiv.org/abs/2406.16148v1)|[link](https://github.com/evelyn0414/opera)|
|**2024-06-23**|**Predicting Individual Depression Symptoms from Acoustic Features During Speech**|Sebastian Rodriguez et.al.|[2406.16000v1](http://arxiv.org/abs/2406.16000v1)|null|
|**2024-06-23**|**Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care**|Hassan Alhuzali et.al.|[2406.15966v1](http://arxiv.org/abs/2406.15966v1)|null|
|**2024-06-22**|**SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery**|Jialang Xu et.al.|[2406.15920v1](http://arxiv.org/abs/2406.15920v1)|null|
|**2024-06-22**|**Real-time Speech Summarization for Medical Conversations**|Khai Le-Duc et.al.|[2406.15888v1](http://arxiv.org/abs/2406.15888v1)|[link](https://github.com/leduckhai/multimed)|
|**2024-06-21**|**Automated radiotherapy treatment planning guided by GPT-4Vision**|Sheng Liu et.al.|[2406.15609v2](http://arxiv.org/abs/2406.15609v2)|null|
|**2024-06-21**|**Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach**|Chengzhe Piao et.al.|[2406.15346v1](http://arxiv.org/abs/2406.15346v1)|[link](https://github.com/chengzhepiao/coldstartbglp)|
|**2024-06-21**|**Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms**|Santiago Berrezueta-Guzman et.al.|[2406.15198v1](http://arxiv.org/abs/2406.15198v1)|null|
|**2024-06-21**|**This actually looks like that: Proto-BagNets for local and global interpretability-by-design**|Kerol Djoumessi et.al.|[2406.15168v2](http://arxiv.org/abs/2406.15168v2)|[link](https://github.com/kdjoumessi/proto-bagnets)|
|**2024-06-21**|**FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays**|Ayush Roy et.al.|[2406.15117v1](http://arxiv.org/abs/2406.15117v1)|[link](https://github.com/ayushroy2001/fa-net)|
|**2024-06-21**|**Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis**|Lin Fan et.al.|[2406.15050v1](http://arxiv.org/abs/2406.15050v1)|null|
|**2024-06-21**|**Human-AI collectives produce the most accurate differential diagnoses**|N. Z√∂ller et.al.|[2406.14981v1](http://arxiv.org/abs/2406.14981v1)|[link](https://github.com/nikozoe/human_ai_collectives)|
|**2024-06-21**|**Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health**|Guangkun Nie et.al.|[2406.14953v2](http://arxiv.org/abs/2406.14953v2)|[link](https://github.com/Ngk03/Dist-Loss)|
|**2024-06-21**|**Extraction of 3D trajectories of mandibular condyles from 2D real-time MRI**|Karyna Isaieva et.al.|[2406.14925v1](http://arxiv.org/abs/2406.14925v1)|null|
|**2024-06-21**|**AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics**|Jonas Dippel et.al.|[2406.14866v1](http://arxiv.org/abs/2406.14866v1)|null|
|**2024-06-20**|**ACR: A Benchmark for Automatic Cohort Retrieval**|Dung Ngoc Thai et.al.|[2406.14780v2](http://arxiv.org/abs/2406.14780v2)|null|
|**2024-06-20**|**A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes**|Syed I. Munzir et.al.|[2406.14757v1](http://arxiv.org/abs/2406.14757v1)|null|
|**2024-06-20**|**An updated overview of radiomics-based artificial intelligence (AI) methods in breast cancer screening and diagnosis**|Reza Elahi et.al.|[2406.14735v1](http://arxiv.org/abs/2406.14735v1)|null|
|**2024-06-20**|**This Looks Better than That: Better Interpretable Models with ProtoPNeXt**|Frank Willard et.al.|[2406.14675v1](http://arxiv.org/abs/2406.14675v1)|null|
|**2024-06-20**|**Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection**|Rushuang Zhou et.al.|[2406.14377v1](http://arxiv.org/abs/2406.14377v1)|null|
|**2024-06-20**|**Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning**|Niccol√≤ Marini et.al.|[2406.14351v1](http://arxiv.org/abs/2406.14351v1)|[link](https://github.com/ilmaro8/wsi_analysis)|
|**2024-06-20**|**Infusing clinical knowledge into tokenisers for language models**|Abul Hasan et.al.|[2406.14312v1](http://arxiv.org/abs/2406.14312v1)|null|
|**2024-06-20**|**Enhancing robustness of data-driven SHM models: adversarial training with circle loss**|Xiangli Yang et.al.|[2406.14232v1](http://arxiv.org/abs/2406.14232v1)|null|

#### Abstracts
##### **MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**
2407.02483v1 by Binxu Li, Tiankai Yan, Yuanting Pan, Zhe Xu, Jie Luo, Ruiyang Ji, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang

Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit
limited generality and often fall short when compared to specialized models.
Recently, LLM-based agents have been developed to address these challenges by
selecting appropriate specialized models as tools based on user inputs.
However, such advancements have not been extensively explored within the
medical domain. To bridge this gap, this paper introduces the first agent
explicitly designed for the medical field, named \textbf{M}ulti-modal
\textbf{Med}ical \textbf{Agent} (MMedAgent). We curate an instruction-tuning
dataset comprising six medical tools solving seven tasks, enabling the agent to
choose the most suitable tools for a given task. Comprehensive experiments
demonstrate that MMedAgent achieves superior performance across a variety of
medical tasks compared to state-of-the-art open-source methods and even the
closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in
updating and integrating new medical tools.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÊàêÂäüÔºå‰ΩÜÂÖ∂ÊôÆÈÅçÊÄßÊúâÈôêÔºåËàáÂ∞àÁî®Ê®°ÂûãÁõ∏ÊØîÊôÇÂ∏∏ÊúâÊâÄ‰∏çË∂≥„ÄÇ
ÊúÄËøëÔºåÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÂ∑≤Ë¢´ÈñãÁôºÂá∫‰æÜÔºå‰ª•ÈÄèÈÅéÊ†πÊìö‰ΩøÁî®ËÄÖËº∏ÂÖ•ÈÅ∏ÊìáÈÅ©Áï∂ÁöÑÂ∞àÁî®Ê®°Âûã‰ΩúÁÇ∫Â∑•ÂÖ∑‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇ
ÁÑ∂ËÄåÔºåÊ≠§È°ûÈÄ≤Â±ïÂ∞öÊú™Âú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠Âª£Ê≥õÊé¢Ë®é„ÄÇÁÇ∫‰∫ÜÂΩåË£úÊ≠§Â∑ÆË∑ùÔºåÊú¨Êñá‰ªãÁ¥π‰∫ÜÁ¨¨‰∏ÄÂÄãÂ∞àÈñÄÁÇ∫ÈÜ´ÁôÇÈ†òÂüüË®≠Ë®àÁöÑ‰ª£ÁêÜÔºåÂêçÁÇ∫**M**ulti-modal **Med**ical **Agent** (MMedAgent)„ÄÇÊàëÂÄëÊï¥ÁêÜ‰∫Ü‰∏ÄÂÄãÁî±ÂÖ≠Á®ÆËß£Ê±∫‰∏ÉÈ†Ö‰ªªÂãôÁöÑÈÜ´ÁôÇÂ∑•ÂÖ∑ÁµÑÊàêÁöÑÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÈõÜÔºåËÆì‰ª£ÁêÜËÉΩÂ§†ÁÇ∫ÁâπÂÆö‰ªªÂãôÈÅ∏ÊìáÊúÄÂêàÈÅ©ÁöÑÂ∑•ÂÖ∑„ÄÇÂÖ®Èù¢ÁöÑÂØ¶È©óË≠âÊòéÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÈñãÊ∫êÊñπÊ≥ïÔºåÁîöËá≥ÈñâÊ∫êÊ®°Âûã GPT-4o Áõ∏ÊØîÔºåMMedAgent Âú®ÂêÑÁ®ÆÈÜ´ÁôÇ‰ªªÂãô‰∏≠ÈÉΩÂèñÂæó‰∫ÜÂÑ™Áï∞ÁöÑË°®Áèæ„ÄÇÊ≠§Â§ñÔºåMMedAgent Âú®Êõ¥Êñ∞ÂíåÊï¥ÂêàÊñ∞ÁöÑÈÜ´ÁôÇÂ∑•ÂÖ∑ÊñπÈù¢Â±ïÁèæÂá∫ÊïàÁéá„ÄÇ

##### **CALICO: Confident Active Learning with Integrated Calibration**
2407.02335v1 by Lorenzo S. Querol, Hajime Nagahara, Hideaki Hayashi

The growing use of deep learning in safety-critical applications, such as
medical imaging, has raised concerns about limited labeled data, where this
demand is amplified as model complexity increases, posing hurdles for domain
experts to annotate data. In response to this, active learning (AL) is used to
efficiently train models with limited annotation costs. In the context of deep
neural networks (DNNs), AL often uses confidence or probability outputs as a
score for selecting the most informative samples. However, modern DNNs exhibit
unreliable confidence outputs, making calibration essential. We propose an AL
framework that self-calibrates the confidence used for sample selection during
the training process, referred to as Confident Active Learning with Integrated
CalibratiOn (CALICO). CALICO incorporates the joint training of a classifier
and an energy-based model, instead of the standard softmax-based classifier.
This approach allows for simultaneous estimation of the input data distribution
and the class probabilities during training, improving calibration without
needing an additional labeled dataset. Experimental results showcase improved
classification performance compared to a softmax-based classifier with fewer
labeled samples. Furthermore, the calibration stability of the model is
observed to depend on the prior class distribution of the data.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂú®ÂÆâÂÖ®ÈóúÈçµÊáâÁî®‰∏≠‰ΩøÁî®Êó•ÁõäÂª£Ê≥õÔºå‰æãÂ¶ÇÈÜ´Â≠∏ÂΩ±ÂÉèÔºåÈÄôÂºïÁôº‰∫ÜÂ∞çÊ®ôÁ±§Êï∏ÊìöÊúâÈôêÁöÑÊìîÊÜÇÔºåÈö®ËëóÊ®°ÂûãË§áÈõúÊÄßÁöÑÂ¢ûÂä†ÔºåÈÄôÁ®ÆÈúÄÊ±ÇÊúÉË¢´ÊîæÂ§ßÔºåÈÄôÂ∞çÈ†òÂüüÂ∞àÂÆ∂Ë®ªËß£Êï∏ÊìöÊßãÊàê‰∫ÜÈöúÁ§ô„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÂïèÈ°åÔºå‰∏ªÂãïÂ≠∏Áøí (AL) Ë¢´Áî®Êñº‰ª•ÊúâÈôêÁöÑË®ªËß£ÊàêÊú¨ÊúâÊïàÂú∞Ë®ìÁ∑¥Ê®°Âûã„ÄÇÂú®Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø (DNN) ÁöÑËÉåÊôØ‰∏ãÔºåAL Á∂ìÂ∏∏‰ΩøÁî®ÁΩÆ‰ø°Â∫¶ÊàñÊ©üÁéáËº∏Âá∫‰ΩúÁÇ∫ÈÅ∏ÊìáÊúÄÊúâË≥áË®äÊÄßÁöÑÊ®£Êú¨ÁöÑÂàÜÊï∏„ÄÇÁÑ∂ËÄåÔºåÁèæ‰ª£ DNN Ë°®ÁèæÂá∫‰∏çÂèØÈù†ÁöÑÁΩÆ‰ø°Â∫¶Ëº∏Âá∫ÔºåÈÄô‰ΩøÂæóÊ†°Ê∫ñËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã AL Ê°ÜÊû∂ÔºåÂÆÉÊúÉÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠Ëá™Ë°åÊ†°Ê∫ñÁî®ÊñºÊ®£Êú¨ÈÅ∏ÊìáÁöÑÁΩÆ‰ø°Â∫¶ÔºåÁ®±ÁÇ∫ÂÖ∑ÊúâÊï¥ÂêàÊ†°Ê∫ñÁöÑËá™‰ø°‰∏ªÂãïÂ≠∏Áøí (CALICO)„ÄÇCALICO ÁµêÂêà‰∫ÜÂàÜÈ°ûÂô®ÂíåÂü∫ÊñºËÉΩÈáèÁöÑÊ®°ÂûãÁöÑËÅØÂêàË®ìÁ∑¥ÔºåËÄå‰∏çÊòØÊ®ôÊ∫ñÁöÑÂü∫Êñº softmax ÁöÑÂàÜÈ°ûÂô®„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±Âú®Ë®ìÁ∑¥ÊúüÈñìÂêåÊôÇ‰º∞Ë®àËº∏ÂÖ•Êï∏ÊìöÂàÜ‰ΩàÂíåÈ°ûÂà•Ê©üÁéáÔºåÂæûËÄåÊîπÈÄ≤Ê†°Ê∫ñÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑÊ®ôÁ±§Êï∏ÊìöÈõÜ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂü∫Êñº softmax ÁöÑÂàÜÈ°ûÂô®Áõ∏ÊØîÔºåÂú®Ê®ôÁ±§Ê®£Êú¨ËºÉÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂàÜÈ°ûÊÄßËÉΩÂæóÂà∞‰∫ÜÊîπÂñÑ„ÄÇÊ≠§Â§ñÔºåËßÄÂØüÂà∞Ê®°ÂûãÁöÑÊ†°Ê∫ñÁ©©ÂÆöÊÄßÂèñÊ±∫ÊñºÊï∏ÊìöÁöÑÂÖàÈ©óÈ°ûÂà•ÂàÜ‰Ωà„ÄÇ

##### **A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**
2407.02283v1 by Minghao Zhou, Hong Wang, Yefeng Zheng, Deyu Meng

Feature upsampling is a fundamental and indispensable ingredient of almost
all current network structures for image segmentation tasks. Recently, a
popular similarity-based feature upsampling pipeline has been proposed, which
utilizes a high-resolution feature as guidance to help upsample the
low-resolution deep feature based on their local similarity. Albeit achieving
promising performance, this pipeline has specific limitations: 1) HR query and
LR key features are not well aligned; 2) the similarity between query-key
features is computed based on the fixed inner product form; 3) neighbor
selection is coarsely operated on LR features, resulting in mosaic artifacts.
These shortcomings make the existing methods along this pipeline primarily
applicable to hierarchical network architectures with iterative features as
guidance and they are not readily extended to a broader range of structures,
especially for a direct high-ratio upsampling. Against the issues, we
meticulously optimize every methodological design. Specifically, we firstly
propose an explicitly controllable query-key feature alignment from both
semantic-aware and detail-aware perspectives, and then construct a
parameterized paired central difference convolution block for flexibly
calculating the similarity between the well-aligned query-key features.
Besides, we develop a fine-grained neighbor selection strategy on HR features,
which is simple yet effective for alleviating mosaic artifacts. Based on these
careful designs, we systematically construct a refreshed similarity-based
feature upsampling framework named ReSFU. Extensive experiments substantiate
that our proposed ReSFU is finely applicable to various types of architectures
in a direct high-ratio upsampling manner, and consistently achieves
satisfactory performance on different segmentation applications, showing
superior generality and ease of deployment.

ÊëòË¶ÅÔºöÁâπÂæµ‰∏äÊé°Ê®£ÊòØÁõÆÂâçÂπæ‰πéÊâÄÊúâÁî®ÊñºÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂãôÁöÑÁ∂≤Ë∑ØÁµêÊßã‰∏≠‰∏çÂèØÊàñÁº∫ÁöÑÂü∫Êú¨Ë¶ÅÁ¥†„ÄÇÊúÄËøëÔºåÊúâ‰∫∫ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁõ∏‰ººÂ∫¶ÁöÑÁâπÂæµ‰∏äÊé°Ê®£ÁÆ°ÈÅìÔºåÂÆÉÂà©Áî®È´òËß£ÊûêÂ∫¶ÁâπÂæµ‰ΩúÁÇ∫ÊåáÂºïÔºåÊ†πÊìöÂÖ∂Â±ÄÈÉ®Áõ∏‰ººÂ∫¶Âπ´Âä©‰∏äÊé°Ê®£‰ΩéËß£ÊûêÂ∫¶Ê∑±Â∫¶ÁâπÂæµ„ÄÇÂÑòÁÆ°ÂèñÂæó‰∫ÜÊúâÂ∏åÊúõÁöÑÊïàËÉΩÔºå‰ΩÜÊ≠§ÁÆ°ÈÅìÊúâÁâπÂÆöÁöÑÈôêÂà∂Ôºö1ÔºâHR Êü•Ë©¢Âíå LR ÈóúÈçµÁâπÂæµÊú™Â∞çÈΩäÔºõ2ÔºâÊü•Ë©¢ÈçµÁâπÂæµ‰πãÈñìÁöÑÁõ∏‰ººÂ∫¶ÊòØÊ†πÊìöÂõ∫ÂÆöÁöÑÂÖßÁ©çÂΩ¢ÂºèË®àÁÆóÁöÑÔºõ3ÔºâÈÑ∞Â±ÖÈÅ∏ÊìáÊòØÁ≤óÁï•Âú∞Â∞ç LR ÁâπÂæµÈÄ≤Ë°åÊìç‰ΩúÔºåÂ∞éËá¥È¶¨Ë≥ΩÂÖãÂÅΩÂΩ±„ÄÇÈÄô‰∫õÁº∫Èªû‰ΩøÂæóÊ≤øËëóÊ≠§ÁÆ°ÈÅìÁöÑÁèæÊúâÊñπÊ≥ï‰∏ªË¶ÅÈÅ©Áî®ÊñºÂÖ∑ÊúâËø≠‰ª£ÁâπÂæµ‰ΩúÁÇ∫ÊåáÂºïÁöÑÂàÜÂ±§Á∂≤Ë∑ØÊû∂ÊßãÔºå‰∏¶‰∏îÂÆÉÂÄë‰∏çÂÆπÊòìÊì¥ÂÖÖÂ•ó‰ª∂Âà∞Êõ¥Âª£Ê≥õÁöÑÁµêÊßãÔºåÁâπÂà•ÊòØÂ∞çÊñºÁõ¥Êé•ÁöÑÈ´òÊØîÁéá‰∏äÊé°Ê®£„ÄÇÈáùÂ∞çÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄë‰ªîÁ¥∞ÂÑ™Âåñ‰∫ÜÊØè‰∏ÄÂÄãÊñπÊ≥ïË´ñË®≠Ë®à„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∫ÜÂæûË™ûÁæ©ÊÑüÁü•ÂíåÁ¥∞ÁØÄÊÑüÁü•ÁöÑËßíÂ∫¶ÈÄ≤Ë°åÊòéÁ¢∫ÂèØÊéßÁöÑÊü•Ë©¢ÈçµÁâπÂæµÂ∞çÈΩäÔºåÁÑ∂ÂæåÊßãÂª∫‰∏ÄÂÄãÂèÉÊï∏ÂåñÁöÑÈÖçÂ∞ç‰∏≠ÂøÉÂ∑ÆÂàÜÂç∑Á©çÂ°äÔºå‰ª•ÈùàÊ¥ªÂú∞Ë®àÁÆóÂ∞çÈΩäËâØÂ•ΩÁöÑÊü•Ë©¢ÈçµÁâπÂæµ‰πãÈñìÁöÑÁõ∏‰ººÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú® HR ÁâπÂæµ‰∏äÈñãÁôº‰∫Ü‰∏ÄÂÄãÁ¥∞Á≤íÂ∫¶ÁöÑÈÑ∞Â±ÖÈÅ∏ÊìáÁ≠ñÁï•ÔºåÂÆÉÂ∞çÊñºÊ∏õËºïÈ¶¨Ë≥ΩÂÖãÂÅΩÂΩ±Êó¢Á∞°ÂñÆÂèàÊúâÊïà„ÄÇÊ†πÊìöÈÄô‰∫õ‰ªîÁ¥∞ÁöÑË®≠Ë®àÔºåÊàëÂÄëÁ≥ªÁµ±Âú∞ÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ ReSFU ÁöÑÊõ¥Êñ∞ÁöÑÂü∫ÊñºÁõ∏‰ººÂ∫¶ÁöÑÁâπÂæµ‰∏äÊé°Ê®£Ê°ÜÊû∂„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË≠âÂØ¶ÔºåÊàëÂÄëÊèêÂá∫ÁöÑ ReSFU Á≤æÁ¥∞Âú∞ÈÅ©Áî®ÊñºÂêÑÁ®ÆÈ°ûÂûãÁöÑÊû∂ÊßãÔºåÊé°Áî®Áõ¥Êé•ÁöÑÈ´òÊØîÁéá‰∏äÊé°Ê®£ÊñπÂºèÔºå‰∏¶‰∏îÂú®‰∏çÂêåÁöÑÂàÜÂâ≤ÊáâÁî®‰∏≠ÂßãÁµÇÂ¶Ç‰∏ÄÂú∞ÂèñÂæó‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩÔºåÂ±ïÁèæÂá∫ÂÑ™Ë∂äÁöÑÈÄöÁî®ÊÄßÂíåÊòìÊñºÈÉ®ÁΩ≤ÊÄß„ÄÇ

##### **FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**
2407.02280v1 by Yangyang Xiang, Nannan Wu, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

Federated learning has emerged as a compelling paradigm for medical image
segmentation, particularly in light of increasing privacy concerns. However,
most of the existing research relies on relatively stringent assumptions
regarding the uniformity and completeness of annotations across clients.
Contrary to this, this paper highlights a prevalent challenge in medical
practice: incomplete annotations. Such annotations can introduce incorrectly
labeled pixels, potentially undermining the performance of neural networks in
supervised learning. To tackle this issue, we introduce a novel solution, named
FedIA. Our insight is to conceptualize incomplete annotations as noisy data
(\textit{i.e.}, low-quality data), with a focus on mitigating their adverse
effects. We begin by evaluating the completeness of annotations at the client
level using a designed indicator. Subsequently, we enhance the influence of
clients with more comprehensive annotations and implement corrections for
incomplete ones, thereby ensuring that models are trained on accurate data. Our
method's effectiveness is validated through its superior performance on two
extensively used medical image segmentation datasets, outperforming existing
solutions. The code is available at https://github.com/HUSTxyy/FedIA.

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π†Â∑≤Êàê‰∏∫ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑ‰∏Ä‰∏™Âºï‰∫∫Ê≥®ÁõÆÁöÑËåÉ‰æãÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈöêÁßÅÈóÆÈ¢òÊó•Áõä‰∏•ÈáçÁöÑËÉåÊôØ‰∏ã„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂ§ßÈÉ®ÂàÜÁ†îÁ©∂ÈÉΩ‰æùËµñ‰∫éÁõ∏ÂØπ‰∏•Ê†ºÁöÑÂÅáËÆæÔºåÂç≥Ë∑®ÂÆ¢Êà∑Á´ØÊ≥®ÈáäÁöÑ‰∏ÄËá¥ÊÄßÂíåÂÆåÊï¥ÊÄß„ÄÇ‰∏éÊ≠§Áõ∏ÂèçÔºåÊú¨ÊñáÈáçÁÇπ‰ªãÁªç‰∫ÜÂåªÂ≠¶ÂÆûË∑µ‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑÊåëÊàòÔºö‰∏çÂÆåÊï¥Ê≥®Èáä„ÄÇÊ≠§Á±ªÊ≥®ÈáäÂèØËÉΩ‰ºöÂºïÂÖ•ÈîôËØØÊ†áËÆ∞ÁöÑÂÉèÁ¥†Ôºå‰ªéËÄåÂèØËÉΩÊçüÂÆ≥Á•ûÁªèÁΩëÁªúÂú®ÁõëÁù£Â≠¶‰π†‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂêç‰∏∫ FedIA ÁöÑÊñ∞È¢ñËß£ÂÜ≥ÊñπÊ°à„ÄÇÊàë‰ª¨ÁöÑËßÅËß£ÊòØÂ∞Ü‰∏çÂÆåÊï¥Ê≥®ÈáäÊ¶ÇÂøµÂåñ‰∏∫Âô™Â£∞Êï∞ÊçÆÔºàÂç≥‰ΩéË¥®ÈáèÊï∞ÊçÆÔºâÔºåÈáçÁÇπÂú®‰∫éÂáèËΩªÂÖ∂‰∏çÂà©ÂΩ±Âìç„ÄÇÊàë‰ª¨È¶ñÂÖà‰ΩøÁî®ËÆæËÆ°ÁöÑÊåáÁ§∫Á¨¶ËØÑ‰º∞ÂÆ¢Êà∑Á´ØÁ∫ßÂà´ÁöÑÊ≥®ÈáäÁöÑÂÆåÊï¥ÊÄß„ÄÇÈöèÂêéÔºåÊàë‰ª¨Â¢ûÂº∫‰∫ÜÂÖ∑ÊúâÊõ¥ÂÖ®Èù¢Ê≥®ÈáäÁöÑÂÆ¢Êà∑Á´ØÁöÑÂΩ±ÂìçÂäõÔºåÂπ∂ÂØπ‰∏çÂÆåÊï¥ÁöÑÊ≥®ÈáäÂÆûÊñΩ‰∫ÜÊõ¥Ê≠£Ôºå‰ªéËÄåÁ°Æ‰øùÊ®°ÂûãÂú®ÂáÜÁ°ÆÁöÑÊï∞ÊçÆ‰∏äËøõË°åËÆ≠ÁªÉ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄöËøáÂÖ∂Âú®‰∏§‰∏™ÂπøÊ≥õ‰ΩøÁî®ÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤Êï∞ÊçÆÈõÜ‰∏äÁöÑÂçìË∂äÊÄßËÉΩÂæóÂà∞È™åËØÅÔºå‰ºò‰∫éÁé∞ÊúâÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/HUSTxyy/FedIA Ëé∑Âæó„ÄÇ

##### **Generative Monoculture in Large Language Models**
2407.02209v1 by Fan Wu, Emily Black, Varun Chandrasekaran

We introduce {\em generative monoculture}, a behavior observed in large
language models (LLMs) characterized by a significant narrowing of model output
diversity relative to available training data for a given task: for example,
generating only positive book reviews for books with a mixed reception. While
in some cases, generative monoculture enhances performance (e.g., LLMs more
often produce efficient code), the dangers are exacerbated in others (e.g.,
LLMs refuse to share diverse opinions). As LLMs are increasingly used in
high-impact settings such as education and web search, careful maintenance of
LLM output diversity is essential to ensure a variety of facts and perspectives
are preserved over time. We experimentally demonstrate the prevalence of
generative monoculture through analysis of book review and code generation
tasks, and find that simple countermeasures such as altering sampling or
prompting strategies are insufficient to mitigate the behavior. Moreover, our
results suggest that the root causes of generative monoculture are likely
embedded within the LLM's alignment processes, suggesting a need for developing
fine-tuning paradigms that preserve or promote diversity.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥π‰∫Ü„ÄåÁîüÊàêÂñÆ‰∏ÄÊñáÂåñ„ÄçÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ËßÄÂØüÂà∞ÁöÑË°åÁÇ∫ÔºåÂÖ∂ÁâπÂæµÊòØÊ®°ÂûãËº∏Âá∫Â§öÊ®£ÊÄßÁõ∏Â∞çÊñºÁµ¶ÂÆö‰ªªÂãôÁöÑÂèØÁî®Ë®ìÁ∑¥Ë≥áÊñôÈ°ØËëóËÆäÁ™ÑÔºö‰æãÂ¶ÇÔºåÂè™ÁÇ∫Ë©ïÂÉπË§íË≤∂‰∏ç‰∏ÄÁöÑÊõ∏Á±çÁîüÊàêÊ≠£Èù¢ÁöÑÊõ∏Ë©ï„ÄÇÈõñÁÑ∂Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºåÁîüÊàêÂñÆ‰∏ÄÊñáÂåñÊúÉÂ¢ûÂº∑ÊïàËÉΩÔºà‰æãÂ¶ÇÔºåLLM Êõ¥Â∏∏Áî¢ÁîüÈ´òÊïàÁöÑÁ®ãÂºèÁ¢ºÔºâÔºå‰ΩÜÂÖ∂Âç±Èö™ÊÄßÂú®ÂÖ∂‰ªñÊÉÖÊ≥Å‰∏ãÊúÉÂä†ÂäáÔºà‰æãÂ¶ÇÔºåLLM ÊãíÁµïÂàÜ‰∫´‰∏çÂêåÁöÑÊÑèË¶ãÔºâ„ÄÇÁî±Êñº LLM ÊÑà‰æÜÊÑàÂ§öÂú∞Áî®ÊñºÊïôËÇ≤ÂíåÁ∂≤Ë∑ØÊêúÂ∞ãÁ≠âÈ´òÂΩ±ÈüøÂäõÁöÑÁí∞Â¢É‰∏≠Ôºå‰ªîÁ¥∞Á∂≠Ë≠∑ LLM Ëº∏Âá∫ÁöÑÂ§öÊ®£ÊÄßÂ∞çÊñºÁ¢∫‰øùÈö®ËëóÊôÇÈñìÊé®ÁßªÔºåÂêÑÁ®Æ‰∫ãÂØ¶ÂíåËßÄÈªûÈÉΩËÉΩË¢´‰øùÁïô‰∏ã‰æÜËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÈÄèÈÅéÂàÜÊûêÊõ∏Ë©ïÂíåÁ®ãÂºèÁ¢ºÁîüÊàê‰ªªÂãôÔºå‰ª•ÂØ¶È©óÊñπÂºèË≠âÊòé‰∫ÜÁîüÊàêÂñÆ‰∏ÄÊñáÂåñÁöÑÊôÆÈÅçÊÄßÔºå‰∏¶ÁôºÁèæÁ∞°ÂñÆÁöÑÂ∞çÁ≠ñÔºå‰æãÂ¶ÇÊîπËÆäÊäΩÊ®£ÊàñÊèêÁ§∫Á≠ñÁï•Ôºå‰∏çË∂≥‰ª•Ê∏õËºïÈÄôÁ®ÆË°åÁÇ∫„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÁîüÊàêÂñÆ‰∏ÄÊñáÂåñÁöÑÊ†πÊú¨ÂéüÂõ†ÂèØËÉΩÂ≠òÂú®Êñº LLM ÁöÑÊØîÂ∞çÈÅéÁ®ã‰∏≠ÔºåÈÄôË°®ÊòéÈúÄË¶ÅÈñãÁôºËÉΩ‰øùÁïôÊàñ‰øÉÈÄ≤Â§öÊ®£ÊÄßÁöÑÂæÆË™øÁØÑ‰æã„ÄÇ</paragraph>

##### **Abstract Dialectical Frameworks are Boolean Networks (full version)**
2407.02055v1 by Jesse Heyninck, Matthias Knorr, Jo√£o Leite

Dialectical frameworks are a unifying model of formal argumentation, where
argumentative relations between arguments are represented by assigning
acceptance conditions to atomic arguments. Their generality allow them to cover
a number of different approaches with varying forms of representing the
argumentation structure. Boolean regulatory networks are used to model the
dynamics of complex biological processes, taking into account the interactions
of biological compounds, such as proteins or genes. These models have proven
highly useful for comprehending such biological processes, allowing to
reproduce known behaviour and testing new hypotheses and predictions in silico,
for example in the context of new medical treatments. While both these
approaches stem from entirely different communities, it turns out that there
are striking similarities in their appearence. In this paper, we study the
relation between these two formalisms revealing their communalities as well as
their differences, and introducing a correspondence that allows to establish
novel results for the individual formalisms.

ÊëòË¶ÅÔºöËæØË≠âÊ°ÜÊû∂ÊòØÂΩ¢ÂºèË´ñË≠âÁöÑÁµ±‰∏ÄÊ®°ÂûãÔºåÂÖ∂‰∏≠Ë´ñË≠â‰πãÈñìÁöÑË´ñË≠âÈóú‰øÇÊòØÈÄèÈÅéÊåáÊ¥æÊé•ÂèóÊ¢ù‰ª∂Áµ¶ÂéüÂ≠êË´ñË≠â‰æÜË°®Á§∫„ÄÇÂÆÉÂÄëÁöÑÊôÆÈÅçÊÄßÂÖÅË®±ÂÆÉÂÄëÊ∂µËìãË®±Â§ö‰∏çÂêåÁöÑÊñπÊ≥ïÔºå‰∏¶‰ª•‰∏çÂêåÁöÑÂΩ¢ÂºèË°®Á§∫Ë´ñË≠âÁµêÊßã„ÄÇÂ∏ÉÊûóÊ≥ïË¶èÁ∂≤Ë∑ØÁî®ÊñºÊ®°Êì¨Ë§áÈõúÁîüÁâ©ÈÅéÁ®ãÁöÑÂãïÊÖãÔºåËÄÉÈáèÁîüÁâ©ÂåñÂêàÁâ©Ôºà‰æãÂ¶ÇËõãÁôΩË≥™ÊàñÂü∫Âõ†ÔºâÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∑≤Ë¢´Ë≠âÊòéÂ∞çÊñºÁêÜËß£Ê≠§È°ûÁîüÁâ©ÈÅéÁ®ãÈùûÂ∏∏ÊúâÁî®ÔºåÂÖÅË®±Ë§áË£ΩÂ∑≤Áü•ÁöÑË°åÁÇ∫‰∏¶Âú®ÈõªËÖ¶Ê®°Êì¨‰∏≠Ê∏¨Ë©¶Êñ∞ÁöÑÂÅáË®≠ÂíåÈ†êÊ∏¨Ôºå‰æãÂ¶ÇÂú®Êñ∞ÁöÑÈÜ´ÁôÇÊ≤ªÁôÇÁöÑËÉåÊôØ‰∏ã„ÄÇÂÑòÁÆ°ÈÄôÂÖ©Á®ÆÊñπÊ≥ïÂÆåÂÖ®‰æÜËá™‰∏çÂêåÁöÑÁ§æÁæ§Ôºå‰ΩÜ‰∫ãÂØ¶Ë≠âÊòéÂÆÉÂÄëÁöÑÂ§ñËßÄÊúâÈ©ö‰∫∫ÁöÑÁõ∏‰ººÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂ÈÄôÂÖ©Á®ÆÂΩ¢Âºè‰∏ªÁæ©‰πãÈñìÁöÑÈóú‰øÇÔºåÊè≠Á§∫ÂÆÉÂÄëÁöÑÂÖ±ÊÄß‰ª•ÂèäÂÆÉÂÄëÁöÑÂ∑ÆÁï∞Ôºå‰∏¶ÂºïÂÖ•‰∏ÄÁ®ÆÂ∞çÊáâÈóú‰øÇÔºåÂÖÅË®±ÁÇ∫ÂÄãÂà•ÂΩ¢Âºè‰∏ªÁæ©Âª∫Á´ãÊñ∞ÁöÑÁµêÊûú„ÄÇ

##### **A Method to Facilitate Membership Inference Attacks in Deep Learning Models**
2407.01919v1 by Zitao Chen, Karthik Pattabiraman

Modern machine learning (ML) ecosystems offer a surging number of ML
frameworks and code repositories that can greatly facilitate the development of
ML models. Today, even ordinary data holders who are not ML experts can apply
off-the-shelf codebase to build high-performance ML models on their data, many
of which are sensitive in nature (e.g., clinical records).
  In this work, we consider a malicious ML provider who supplies model-training
code to the data holders, does not have access to the training process, and has
only black-box query access to the resulting model. In this setting, we
demonstrate a new form of membership inference attack that is strictly more
powerful than prior art. Our attack empowers the adversary to reliably
de-identify all the training samples (average >99% attack TPR@0.1% FPR), and
the compromised models still maintain competitive performance as their
uncorrupted counterparts (average <1% accuracy drop). Moreover, we show that
the poisoned models can effectively disguise the amplified membership leakage
under common membership privacy auditing, which can only be revealed by a set
of secret samples known by the adversary.
  Overall, our study not only points to the worst-case membership privacy
leakage, but also unveils a common pitfall underlying existing privacy auditing
methods, which calls for future efforts to rethink the current practice of
auditing membership privacy in machine learning models.

ÊëòË¶ÅÔºöÁèæ‰ª£Ê©üÂô®Â≠∏Áøí (ML) ÁîüÊÖãÁ≥ªÁµ±Êèê‰æõ‰∫ÜÂ§ßÈáèÁöÑ ML Ê°ÜÊû∂ÂíåÁ®ãÂºèÁ¢ºÂÑ≤Â≠òÂ∫´ÔºåÂèØ‰ª•Ê•µÂ§ßÂú∞‰øÉÈÄ≤ ML Ê®°ÂûãÁöÑÈñãÁôº„ÄÇÂ¶Ç‰ªäÔºåÂç≥‰Ωø‰∏çÊòØ ML Â∞àÂÆ∂ÁöÑÊôÆÈÄöË≥áÊñôÊåÅÊúâËÄÖ‰πüÂèØ‰ª•Â•óÁî®ÁèæÊàêÁöÑÁ®ãÂºèÁ¢ºÂ∫´ÔºåÊ†πÊìöÂÖ∂Ë≥áÊñôÂª∫Á´ãÈ´òÊÄßËÉΩ ML Ê®°ÂûãÔºåÂÖ∂‰∏≠Ë®±Â§öË≥áÊñôÊú¨Ë≥™‰∏äÂæàÊïèÊÑüÔºà‰æãÂ¶ÇÔºöËá®Â∫äÁ¥ÄÈåÑÔºâ„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëËÄÉÊÖÆ‰∫Ü‰∏ÄÂÄãÊÉ°ÊÑèÁöÑ ML Êèê‰æõËÄÖÔºå‰ªñÂêëË≥áÊñôÊåÅÊúâËÄÖÊèê‰æõÊ®°ÂûãË®ìÁ∑¥Á®ãÂºèÁ¢ºÔºåÁÑ°Ê≥ïÂ≠òÂèñË®ìÁ∑¥Á®ãÂ∫èÔºåËÄå‰∏îÂè™ËÉΩÈÄèÈÅéÈªëÁõíÂ≠êÊü•Ë©¢Â≠òÂèñÁî¢ÁîüÁöÑÊ®°Âûã„ÄÇÂú®Ê≠§Ë®≠ÂÆö‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊàêÂì°Êé®Ë´ñÊîªÊìäÂΩ¢ÂºèÔºåÂÆÉÊØîÂÖàÂâçÁöÑÊäÄË°ìÊõ¥Âº∑Â§ß„ÄÇÊàëÂÄëÁöÑÊîªÊìäËÆìÂ∞çÊâãËÉΩÂ§†ÂèØÈù†Âú∞ÂèñÊ∂àË≠òÂà•ÊâÄÊúâË®ìÁ∑¥ÁØÑ‰æãÔºàÂπ≥Âùá >99% ÊîªÊìä TPR@0.1% FPRÔºâÔºåËÄå‰∏îÂèóÊêçÁöÑÊ®°Âûã‰ªçÁÑ∂‰øùÊåÅËàáÊú™ÂèóÊêçÁöÑÊ®°Âûã‰∏ÄÊ®£ÁöÑÁ´∂Áà≠ÂäõÔºàÂπ≥Âùá <1% Ê∫ñÁ¢∫Â∫¶‰∏ãÈôçÔºâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏≠ÊØíÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂú∞Èö±ËóèÂú®Â∏∏Ë¶ãÊàêÂì°Èö±ÁßÅÁ®ΩÊ†∏‰∏ãÁöÑÊì¥Â¢ûÊàêÂì°Ê¥©ÊºèÔºåÈÄôÂè™ËÉΩÁî±Â∞çÊâãÁü•ÈÅìÁöÑÁßòÂØÜÁØÑ‰æãÈõÜÊè≠Èú≤„ÄÇ
  Á∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰∏çÂÉÖÊåáÂá∫ÊúÄÂ£ûÊÉÖÊ≥ÅÁöÑÊàêÂì°Èö±ÁßÅÊ¥©ÊºèÔºåÈÇÑÊè≠Á§∫‰∫ÜÁèæÊúâÈö±ÁßÅÁ®ΩÊ†∏ÊñπÊ≥ï‰∏≠ÁöÑ‰∏ÄÂÄãÂ∏∏Ë¶ãÈô∑Èò±ÔºåÈÄôÈúÄË¶ÅÊú™‰æÜÁöÑÂä™Âäõ‰æÜÈáçÊñ∞ÊÄùËÄÉÁõÆÂâçÂú®Ê©üÂô®Â≠∏ÁøíÊ®°Âûã‰∏≠Á®ΩÊ†∏ÊàêÂì°Èö±ÁßÅÁöÑÂÅöÊ≥ï„ÄÇ

##### **Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**
2407.01705v1 by Sebastian A. Cruz Romero, Ivanelyz Rivera de Jesus, Dariana J. Troche Quinones, Wilson Rivera Gallego

X-ray image-based disease diagnosis lies in ensuring the precision of
identifying afflictions within the sample, a task fraught with challenges
stemming from the occurrence of false positives and false negatives. False
positives introduce the risk of erroneously identifying non-existent
conditions, leading to misdiagnosis and a decline in patient care quality.
Conversely, false negatives pose the threat of overlooking genuine
abnormalities, potentially causing delays in treatment and interventions,
thereby resulting in adverse patient outcomes. The urgency to overcome these
challenges compels ongoing efforts to elevate the precision and reliability of
X-ray image analysis algorithms within the computational framework. This study
introduces modified pre-trained ResNet models tailored for multi-class disease
diagnosis of X-ray images, incorporating advanced optimization strategies to
reduce the execution runtime of training and inference tasks. The primary
objective is to achieve tangible performance improvements through accelerated
implementations of PyTorch, CUDA, Mixed- Precision Training, and Learning Rate
Scheduler. While outcomes demonstrate substantial improvements in execution
runtimes between normal training and CUDA-accelerated training, negligible
differences emerge between various training optimization modalities. This
research marks a significant advancement in optimizing computational approaches
to reduce training execution time for larger models. Additionally, we explore
the potential of effective parallel data processing using MPI4Py for the
distribution of gradient descent optimization across multiple nodes and
leverage multiprocessing to expedite data preprocessing for larger datasets.

ÊëòË¶ÅÔºöX ÂÖâÂΩ±ÂÉèÁñæÁóÖË®∫Êñ∑Âú®ÊñºÁ¢∫‰øùË≠òÂà•Ê®£Êú¨‰∏≠ÁñæÁóÖÁöÑÁ≤æÁ¢∫ÊÄßÔºåÈÄôÈ†Ö‰ªªÂãôÂÖÖÊªø‰∫ÜÊåëÊà∞ÔºåÊ∫êËá™ÊñºÂÅáÈôΩÊÄßÂíåÂÅáÈô∞ÊÄßÁöÑÁôºÁîü„ÄÇÂÅáÈôΩÊÄßÊúÉÂ∏∂‰æÜÈåØË™§Ë≠òÂà•‰∏çÂ≠òÂú®ÁöÑÁñæÁóÖÁöÑÈ¢®Èö™ÔºåÂ∞éËá¥Ë™§Ë®∫ÂíåÊÇ£ËÄÖÁÖßË≠∑ÂìÅË≥™‰∏ãÈôç„ÄÇÁõ∏ÂèçÂú∞ÔºåÂÅáÈô∞ÊÄßÊúÉÂ∏∂‰æÜÂøΩÁï•ÁúüÊ≠£Áï∞Â∏∏ÁöÑÂ®ÅËÑÖÔºåÂèØËÉΩÊúÉÂ∞éËá¥Ê≤ªÁôÇÂíå‰ªãÂÖ•Âª∂Ë™§ÔºåÂæûËÄåÂ∞éËá¥ÊÇ£ËÄÖÈ†êÂæå‰∏çËâØ„ÄÇÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÁöÑËø´ÂàáÊÄß‰øÉ‰ΩøÊåÅÁ∫åÂä™ÂäõÊèêÂçáË®àÁÆóÊû∂Êßã‰∏≠ X ÂÖâÂΩ±ÂÉèÂàÜÊûêÊºîÁÆóÊ≥ïÁöÑÁ≤æÁ¢∫Â∫¶ÂíåÂèØÈù†ÊÄß„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÈáùÂ∞ç X ÂÖâÂΩ±ÂÉèÁöÑÂ§öÈ°ûÁñæÁóÖË®∫Êñ∑ÈáèË∫´ÊâìÈÄ†ÁöÑ‰øÆÊîπÂæåÈ†êÂÖàË®ìÁ∑¥ÁöÑ ResNet Ê®°ÂûãÔºå‰∏¶ÁµêÂêàÂÖàÈÄ≤ÁöÑÊúÄ‰Ω≥ÂåñÁ≠ñÁï•‰ª•Ê∏õÂ∞ëË®ìÁ∑¥ÂíåÊé®Ë´ñ‰ªªÂãôÁöÑÂü∑Ë°åÂü∑Ë°åÊôÇÈñì„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØÈÄèÈÅéÂä†ÈÄüÂØ¶‰Ωú PyTorch„ÄÅCUDA„ÄÅÊ∑∑ÂêàÁ≤æÂ∫¶Ë®ìÁ∑¥ÂíåÂ≠∏ÁøíÁéáÊéíÁ®ãÂô®Ôºå‰æÜÈÅîÊàêÂÖ∑È´îÁöÑÊïàËÉΩÊèêÂçá„ÄÇÈõñÁÑ∂ÁµêÊûúÈ°ØÁ§∫Ê≠£Â∏∏Ë®ìÁ∑¥Âíå CUDA Âä†ÈÄüË®ìÁ∑¥‰πãÈñìÁöÑÂü∑Ë°åÂü∑Ë°åÊôÇÈñìÊúâÂ§ßÂπÖÊîπÂñÑÔºå‰ΩÜÂêÑÁ®ÆË®ìÁ∑¥ÊúÄ‰Ω≥ÂåñÊ®°Âºè‰πãÈñìÁöÑÂ∑ÆÁï∞ÂèØ‰ª•ÂøΩÁï•‰∏çË®à„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ê®ôË™åËëóÊúÄ‰Ω≥ÂåñË®àÁÆóÊñπÊ≥ï‰ª•Ê∏õÂ∞ëËºÉÂ§ßÂûãÊ®°ÂûãË®ìÁ∑¥Âü∑Ë°åÊôÇÈñìÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Á¥¢‰ΩøÁî® MPI4Py ÈÄ≤Ë°åÊúâÊïàÂπ≥Ë°åË≥áÊñôËôïÁêÜÁöÑÂèØËÉΩÊÄßÔºå‰ª•Âú®Â§öÂÄãÁØÄÈªû‰∏äÈÄ≤Ë°åÊ¢ØÂ∫¶‰∏ãÈôçÊúÄ‰Ω≥ÂåñÔºå‰∏¶Âà©Áî®Â§öËôïÁêÜ‰æÜÂä†ÈÄüËºÉÂ§ßÂûãË≥áÊñôÈõÜÁöÑË≥áÊñôÂâçËôïÁêÜ„ÄÇ

##### **Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**
2407.01318v1 by Ana Carolina Alves, Andr√© Ferreira, Behrus Puladi, Jan Egger, Victor Alves

The development of magnetic resonance imaging (MRI) for medical imaging has
provided a leap forward in diagnosis, providing a safe, non-invasive
alternative to techniques involving ionising radiation exposure for diagnostic
purposes. It was described by Block and Purcel in 1946, and it was not until
1980 that the first clinical application of MRI became available. Since that
time the MRI has gone through many advances and has altered the way diagnosing
procedures are performed. Due to its ability to improve constantly, MRI has
become a commonly used practice among several specialisations in medicine.
Particularly starting 0.55T and 7T MRI technologies have pointed out enhanced
preservation of image detail and advanced tissue characterisation. This review
examines the integration of deep learning (DL) techniques into these MRI
modalities, disseminating and exploring the study applications. It highlights
how DL contributes to 0.55T and 7T MRI data, showcasing the potential of DL in
improving and refining these technologies. The review ends with a brief
overview of how MRI technology will evolve in the coming years.

ÊëòË¶ÅÔºöÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) Âú®ÂåªÂ≠¶ÂΩ±ÂÉè‰∏äÁöÑÁôºÂ±ïÔºåÁÇ∫Ë®∫Êñ∑ÊäÄË°ìÂ∏∂‰æÜÈáçÂ§ßÈÄ≤Â±ïÔºåÊèê‰æõ‰∏ÄÁ®ÆÂÆâÂÖ®„ÄÅÈùû‰æµÂÖ•ÊÄßÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ª•Âèñ‰ª£‰ΩøÁî®ÈõªÈõ¢ËºªÂ∞ÑÈÄ≤Ë°åË®∫Êñ∑ÁöÑÊäÄË°ì„ÄÇÊ≠§ÊäÄË°ìÁî±Â∏ÉÊ¥õÂÖãËàáÁèÄÂ°ûÁàæÊñº 1946 Âπ¥ÊèêÂá∫ÔºåÁõ¥Âà∞ 1980 Âπ¥ÔºåMRI ÊâçÈ¶ñÊ¨°ÊáâÁî®ÊñºËá®Â∫ä„ÄÇËá™ÈÇ£ÊôÇËµ∑ÔºåMRI Á∂ìÊ≠∑‰∫ÜË®±Â§öÈÄ≤Ê≠•Ôºå‰∏¶ÊîπËÆä‰∫ÜË®∫Êñ∑Á®ãÂ∫èÁöÑÂü∑Ë°åÊñπÂºè„ÄÇÁî±Êñº MRI ËÉΩÊåÅÁ∫åÊîπÈÄ≤ÔºåÂõ†Ê≠§Â∑≤ÊàêÁÇ∫ÈÜ´Â≠∏‰∏≠Â§öÁ®ÆÂ∞àÁßëÁöÑÂ∏∏Áî®ÊäÄË°ì„ÄÇÁâπÂà•ÊòØÂæû 0.55T Âíå 7T MRI ÊäÄË°ìÈñãÂßãÔºåÂ∑≤ÊåáÂá∫Â¢ûÂº∑ÂΩ±ÂÉèÁ¥∞ÁØÄÁöÑ‰øùÂ≠òÂíåÈÄ≤ÈöéÁµÑÁπîË°®Âæµ„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®éÊ∑±Â∫¶Â≠∏Áøí (DL) ÊäÄË°ìÊï¥ÂêàÂà∞ÈÄô‰∫õ MRI Ê®°Âºè‰∏≠ÔºåÂÇ≥Êí≠‰∏¶Êé¢Ë®éÁ†îÁ©∂ÊáâÁî®„ÄÇÂÆÉÂº∑Ë™ø DL Â¶Ç‰ΩïË≤¢ÁçªÊñº 0.55T Âíå 7T MRI Ë≥áÊñôÔºåÂ±ïÁ§∫ DL Âú®ÊîπÂñÑÂíåÁ≤æÈÄ≤ÈÄô‰∫õÊäÄË°ìÁöÑÊΩõÂäõ„ÄÇÊú¨Ë©ïË´ñÊúÄÂæåÁ∞°Ë¶ÅÊ¶ÇËø∞ MRI ÊäÄË°ìÂú®Êú™‰æÜÂπæÂπ¥ÁöÑÁôºÂ±ïÊñπÂºè„ÄÇ

##### **MIRAI: Evaluating LLM Agents for Event Forecasting**
2407.01231v1 by Chenchen Ye, Ziniu Hu, Yihe Deng, Zijie Huang, Mingyu Derek Ma, Yanqiao Zhu, Wei Wang

Recent advancements in Large Language Models (LLMs) have empowered LLM agents
to autonomously collect world information, over which to conduct reasoning to
solve complex problems. Given this capability, increasing interests have been
put into employing LLM agents for predicting international events, which can
influence decision-making and shape policy development on an international
scale. Despite such a growing interest, there is a lack of a rigorous benchmark
of LLM agents' forecasting capability and reliability. To address this gap, we
introduce MIRAI, a novel benchmark designed to systematically evaluate LLM
agents as temporal forecasters in the context of international events. Our
benchmark features an agentic environment with tools for accessing an extensive
database of historical, structured events and textual news articles. We refine
the GDELT event database with careful cleaning and parsing to curate a series
of relational prediction tasks with varying forecasting horizons, assessing LLM
agents' abilities from short-term to long-term forecasting. We further
implement APIs to enable LLM agents to utilize different tools via a code-based
interface. In summary, MIRAI comprehensively evaluates the agents' capabilities
in three dimensions: 1) autonomously source and integrate critical information
from large global databases; 2) write codes using domain-specific APIs and
libraries for tool-use; and 3) jointly reason over historical knowledge from
diverse formats and time to accurately predict future events. Through
comprehensive benchmarking, we aim to establish a reliable framework for
assessing the capabilities of LLM agents in forecasting international events,
thereby contributing to the development of more accurate and trustworthy models
for international relation analysis.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïË≥¶‰∫à‰∫Ü LLM ‰ª£ÁêÜËá™‰∏ªÊî∂ÈõÜ‰∏ñÁïåË≥áË®äÁöÑËÉΩÂäõÔºå‰∏¶Âü∫ÊñºÈÄô‰∫õË≥áË®äÈÄ≤Ë°åÊé®ÁêÜ‰ª•Ëß£Ê±∫Ë§áÈõúÂïèÈ°å„ÄÇÈëëÊñºÊ≠§ÂäüËÉΩÔºåÂ∞á LLM ‰ª£ÁêÜÁî®ÊñºÈ†êÊ∏¨ÂúãÈöõ‰∫ã‰ª∂ÁöÑËààË∂£Êó•ÁõäÊøÉÂéöÔºåÈÄôÂèØËÉΩÊúÉÂΩ±ÈüøÊ±∫Á≠ñÂà∂ÂÆö‰∏¶Âú®ÂúãÈöõÂ±§Èù¢‰∏äÂ°ëÈÄ†ÊîøÁ≠ñÁôºÂ±ï„ÄÇÂÑòÁÆ°ÊúâÂ¶ÇÊ≠§ÊøÉÂéöÁöÑËààË∂£Ôºå‰ΩÜÁº∫‰πèÂ∞ç LLM ‰ª£ÁêÜÈ†êÊ∏¨ËÉΩÂäõÂíåÂèØÈù†ÊÄßÁöÑÂö¥Ê†ºÂü∫Ê∫ñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MIRAIÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Âü∫Ê∫ñÔºåÊó®Âú®Á≥ªÁµ±Âú∞Ë©ï‰º∞ LLM ‰ª£ÁêÜ‰ΩúÁÇ∫ÂúãÈöõ‰∫ã‰ª∂ÊôÇÈñìÈ†êÊ∏¨ËÄÖÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÁâπÈªûÊòØÊèê‰æõ‰∏ÄÂÄã‰ª£ÁêÜÁí∞Â¢ÉÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë®™ÂïèÂ§ßÈáèÊ≠∑Âè≤ÁµêÊßãÂåñ‰∫ã‰ª∂ÂíåÊñáÂ≠óÊñ∞ËÅûÊñáÁ´†ÁöÑÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÈÄöÈÅé‰ªîÁ¥∞Ê∏ÖÁêÜÂíåËß£Êûê GDELT ‰∫ã‰ª∂Ë≥áÊñôÂ∫´ÔºåÁ≠ñÂäÉ‰∫Ü‰∏ÄÁ≥ªÂàóÂÖ∑Êúâ‰∏çÂêåÈ†êÊ∏¨ÁØÑÂúçÁöÑÈóú‰øÇÈ†êÊ∏¨‰ªªÂãôÔºåË©ï‰º∞ LLM ‰ª£ÁêÜÂæûÁü≠ÊúüÂà∞Èï∑ÊúüÈ†êÊ∏¨ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂØ¶‰Ωú APIÔºå‰Ωø LLM ‰ª£ÁêÜËÉΩÂ§†ÈÄèÈÅéÂü∫ÊñºÁ®ãÂºèÁ¢ºÁöÑ‰ªãÈù¢‰ΩøÁî®‰∏çÂêåÁöÑÂ∑•ÂÖ∑„ÄÇÁ∏Ω‰πãÔºåMIRAI ÂÖ®Èù¢Ë©ï‰º∞‰∫Ü‰ª£ÁêÜÂú®‰∏âÂÄãÁ∂≠Â∫¶‰∏äÁöÑËÉΩÂäõÔºö1) Ëá™‰∏ªÂú∞ÂæûÂ§ßÂûãÂÖ®ÁêÉË≥áÊñôÂ∫´‰∏≠Áç≤ÂèñÂíåÊï¥ÂêàÈóúÈçµË≥áË®äÔºõ2) ‰ΩøÁî®ÁâπÂÆöÈ†òÂüüÁöÑ API ÂíåÁ®ãÂºèÂ∫´Á∑®ÂØ´Á®ãÂºèÁ¢º‰ª•‰ΩøÁî®Â∑•ÂÖ∑Ôºõ3) ÂÖ±ÂêåÊé®ÁêÜ‰æÜËá™‰∏çÂêåÊ†ºÂºèÂíåÊôÇÈñìÁöÑÊ≠∑Âè≤Áü•Ë≠òÔºå‰ª•Ê∫ñÁ¢∫È†êÊ∏¨Êú™‰æÜ‰∫ã‰ª∂„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÊàëÂÄëÊó®Âú®Âª∫Á´ã‰∏ÄÂÄãÂèØÈù†ÁöÑÊ°ÜÊû∂ÔºåÁî®ÊñºË©ï‰º∞ LLM ‰ª£ÁêÜÂú®È†êÊ∏¨ÂúãÈöõ‰∫ã‰ª∂ÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂæûËÄåÁÇ∫ÂúãÈöõÈóú‰øÇÂàÜÊûêÁöÑÊõ¥Ê∫ñÁ¢∫ÂíåÂÄºÂæó‰ø°Ë≥¥ÁöÑÊ®°ÂûãÁöÑÈñãÁôºÂÅöÂá∫Ë≤¢Áçª„ÄÇ</paragraph>

##### **Integrated feature analysis for deep learning interpretation and class activation maps**
2407.01142v1 by Yanli Li, Tahereh Hassanzadeh, Denis P. Shamonin, Monique Reijnierse, Annette H. M. van der Helm-van Mil, Berend C. Stoel

Understanding the decisions of deep learning (DL) models is essential for the
acceptance of DL to risk-sensitive applications. Although methods, like class
activation maps (CAMs), give a glimpse into the black box, they do miss some
crucial information, thereby limiting its interpretability and merely providing
the considered locations of objects. To provide more insight into the models
and the influence of datasets, we propose an integrated feature analysis
method, which consists of feature distribution analysis and feature
decomposition, to look closer into the intermediate features extracted by DL
models. This integrated feature analysis could provide information on
overfitting, confounders, outliers in datasets, model redundancies and
principal features extracted by the models, and provide distribution
information to form a common intensity scale, which are missing in current CAM
algorithms. The integrated feature analysis was applied to eight different
datasets for general validation: photographs of handwritten digits, two
datasets of natural images and five medical datasets, including skin
photography, ultrasound, CT, X-rays and MRIs. The method was evaluated by
calculating the consistency between the CAMs average class activation levels
and the logits of the model. Based on the eight datasets, the correlation
coefficients through our method were all very close to 100%, and based on the
feature decomposition, 5%-25% of features could generate equally informative
saliency maps and obtain the same model performances as using all features.
This proves the reliability of the integrated feature analysis. As the proposed
methods rely on very few assumptions, this is a step towards better model
interpretation and a useful extension to existing CAM algorithms. Codes:
https://github.com/YanliLi27/IFA

ÊëòË¶ÅÔºö<paragraph>‰∫ÜËß£Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÊ®°ÂûãÁöÑÊ±∫Á≠ñÂ∞çÊñºÈ¢®Èö™ÊïèÊÑüÊáâÁî®Á®ãÂºèÊé•Âèó DL Ëá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°ÊñπÊ≥ïÔºàÂ¶ÇÈ°ûÂà•ÊøÄÂãµÊò†Â∞Ñ (CAM)ÔºâËÆìÈªëÁõíÂ≠êÂæó‰ª•‰∏ÄÁ™∫Á©∂Á´üÔºå‰ΩÜÂÆÉÂÄë‰ªçÈÅ∫Êºè‰∫Ü‰∏Ä‰∫õÈóúÈçµË≥áË®äÔºåÂõ†ËÄåÈôêÂà∂‰∫ÜËß£ÈáãËÉΩÂäõÔºåÂÉÖÊèê‰æõÁâ©‰ª∂Ë¢´ËÄÉÊÖÆÁöÑ‰ΩçÁΩÆ„ÄÇÁÇ∫‰∫ÜÊõ¥Ê∑±ÂÖ•Áû≠Ëß£Ê®°ÂûãÂíåË≥áÊñôÈõÜÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊï¥ÂêàÁâπÂæµÂàÜÊûêÊñπÊ≥ïÔºåÂåÖÊã¨ÁâπÂæµÂàÜ‰ΩàÂàÜÊûêÂíåÁâπÂæµÂàÜËß£Ôºå‰ª•Êõ¥‰ªîÁ¥∞Âú∞Ê™¢Ë¶ñ DL Ê®°ÂûãÊèêÂèñÁöÑ‰∏≠ÈñìÁâπÂæµ„ÄÇÈÄôÁ®ÆÊï¥ÂêàÁâπÂæµÂàÜÊûêÂèØ‰ª•Êèê‰æõÊúâÈóúÈÅéÂ∫¶Êì¨Âêà„ÄÅÊ∑∑Ê∑ÜËÆäÊï∏„ÄÅË≥áÊñôÈõÜ‰∏≠ÁöÑÁï∞Â∏∏ÂÄº„ÄÅÊ®°ÂûãÂÜóÈ§òÂíåÊ®°ÂûãÊèêÂèñÁöÑ‰∏ªË¶ÅÁâπÂæµÁöÑË≥áË®äÔºå‰∏¶Êèê‰æõÂàÜ‰ΩàË≥áË®ä‰ª•ÂΩ¢ÊàêÂÖ±ÂêåÁöÑÂº∑Â∫¶ÈáèË°®ÔºåÈÄôÊòØÁõÆÂâç CAM ÊºîÁÆóÊ≥ïÊâÄÁº∫Â∞ëÁöÑ„ÄÇÊï¥ÂêàÁâπÂæµÂàÜÊûêÂ∑≤ÊáâÁî®ÊñºÂÖ´ÂÄã‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰ª•ÈÄ≤Ë°å‰∏ÄËà¨È©óË≠âÔºöÊâãÂØ´Êï∏Â≠óÁÖßÁâá„ÄÅÂÖ©ÂÄãËá™ÁÑ∂ÂΩ±ÂÉèË≥áÊñôÈõÜÂíå‰∫îÂÄãÈÜ´Â≠∏Ë≥áÊñôÈõÜÔºåÂåÖÊã¨ÁöÆËÜöÊîùÂΩ±„ÄÅË∂ÖÈü≥Ê≥¢„ÄÅÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè„ÄÅX ÂÖâÂíå MRI„ÄÇË©≤ÊñπÊ≥ïÈÄèÈÅéË®àÁÆó CAM Âπ≥ÂùáÈ°ûÂà•ÊøÄÂãµÂ±§Á¥öËàáÊ®°ÂûãÁöÑ logit ÂÄº‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄß‰æÜË©ï‰º∞„ÄÇÊ†πÊìöÈÄôÂÖ´ÂÄãË≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂæóÂá∫ÁöÑÁõ∏Èóú‰øÇÊï∏ÈÉΩÈùûÂ∏∏Êé•Ëøë 100%ÔºåÊ†πÊìöÁâπÂæµÂàÜËß£Ôºå5%-25% ÁöÑÁâπÂæµÂèØ‰ª•Áî¢ÁîüÂêåÊ®£ÂÖ∑ÊúâË≥áË®äÊÄßÁöÑÈ°ØËëóÊÄßÂúñÔºå‰∏¶Áç≤ÂæóËàá‰ΩøÁî®ÊâÄÊúâÁâπÂæµÁõ∏ÂêåÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÈÄôË≠âÊòé‰∫ÜÊï¥ÂêàÁâπÂæµÂàÜÊûêÁöÑÂèØÈù†ÊÄß„ÄÇÁî±ÊñºÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰æùË≥¥ÁöÑÂÅáË®≠ÂæàÂ∞ëÔºåÂõ†Ê≠§ÈÄôÊòØÊúùÂêëÊõ¥Â•ΩÁöÑÊ®°ÂûãËß£ÈáãÈÇÅÂá∫ÁöÑ‰∏ÄÊ≠•Ôºå‰πüÊòØÂ∞çÁèæÊúâ CAM ÊºîÁÆóÊ≥ïÊúâÁî®ÁöÑÂª∂‰º∏„ÄÇÁ®ãÂºèÁ¢ºÔºöhttps://github.com/YanliLi27/IFA</paragraph>

##### **Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**
2407.01003v2 by Wenqiang Zu, Shenghao Xie, Qing Zhao, Guoqi Li, Lei Ma

Foundation models pre-trained on large-scale data have been widely witnessed
to achieve success in various natural imaging downstream tasks.
Parameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models
to new domains by updating only a small portion of parameters in order to
reduce computational overhead. However, the effectiveness of these PEFT
methods, especially in cross-domain few-shot scenarios, e.g., medical image
analysis, has not been fully explored. In this work, we facilitate the study of
the performance of PEFT when adapting foundation models to medical image
classification tasks. Furthermore, to alleviate the limitations of prompt
introducing ways and approximation capabilities on Transformer architectures of
mainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)
method by embedding prompt tokens into the expanded channels. We also find that
there are anomalies in the feature space distribution of foundation models
during pre-training process, and prompt tuning can help mitigate this negative
impact. To explain this phenomenon, we also introduce a novel perspective to
understand prompt tuning: Prompt tuning is a distribution calibrator. And we
support it by analyzing patch-wise scaling and feature separation operations
contained in EPT. Our experiments show that EPT outperforms several
state-of-the-art fine-tuning methods by a significant margin on few-shot
medical image classification tasks, and completes the fine-tuning process
within highly competitive time, indicating EPT is an effective PEFT method. The
source code is available at github.com/zuwenqiang/EPT.

ÊëòË¶ÅÔºö<paragraph>Âú®Â§ßË¶èÊ®°Ë≥áÊñô‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑÂü∫Á§éÊ®°ÂûãÂ∑≤Ë¢´Âª£Ê≥õË≠âÊòé
Âú®ÂêÑÁ®ÆËá™ÁÑ∂ÂΩ±ÂÉè‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÂèñÂæóÊàêÂäü„ÄÇ
ÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊñπÊ≥ïÊó®Âú®ÈÄöÈÅéÂÉÖÊõ¥Êñ∞‰∏ÄÂ∞èÈÉ®ÂàÜÂèÉÊï∏‰æÜÈÅ©ÊáâÂü∫Á§éÊ®°Âûã
Âà∞Êñ∞Á∂≤ÂüüÔºå‰ª•Ê∏õÂ∞ëÈÅãÁÆóÈñãÈä∑„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ PEFT ÁöÑÊúâÊïàÊÄß
ÊñπÊ≥ïÔºåÁâπÂà•ÊòØÂú®Ë∑®Á∂≤ÂüüÂ∞ëÊ¨°ÊãçÊîùÂ†¥ÊôØ‰∏≠Ôºå‰æãÂ¶ÇÈÜ´Â≠∏ÂΩ±ÂÉè
ÂàÜÊûêÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰øÉÈÄ≤‰∫Ü
Á†îÁ©∂ PEFT Âú®ÈÅ©ÊáâÂü∫Á§éÊ®°ÂûãÂà∞ÈÜ´Â≠∏ÂΩ±ÂÉèÊôÇÁöÑÊïàÊûú
ÂàÜÈ°û‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÁ∑©Ëß£ÊèêÁ§∫ÁöÑÈôêÂà∂
Âú®‰∏ªÊµÅÊèêÁ§∫Ë™øÊï¥ÊñπÊ≥ïÁöÑ Transformer Êû∂Êßã‰∏äÂºïÂÖ•ÊñπÂºèÂíåËøë‰ººËÉΩÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂµåÂÖ•ÂºèÊèêÁ§∫Ë™øÊï¥ (EPT)
ÊñπÊ≥ïÊòØÂ∞áÊèêÁ§∫‰ª£Âπ£ÂµåÂÖ•Âà∞Êì¥Â±ïÁöÑÈÄöÈÅì‰∏≠„ÄÇÊàëÂÄëÈÇÑÁôºÁèæ
Âú®È†êË®ìÁ∑¥ÈÅéÁ®ã‰∏≠ÔºåÂü∫Á§éÊ®°ÂûãÁöÑÁâπÂæµÁ©∫ÈñìÂàÜ‰ΩàÂ≠òÂú®Áï∞Â∏∏Ôºå‰∏¶‰∏îÊèêÁ§∫Ë™øÊï¥ÂèØ‰ª•Âπ´Âä©Ê∏õËºïÈÄôÁ®ÆË≤†Èù¢
ÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£ÈáãÈÄôÁ®ÆÁèæË±°ÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑËßÄÈªû‰æÜ
‰∫ÜËß£ÊèêÁ§∫Ë™øÊï¥ÔºöÊèêÁ§∫Ë™øÊï¥ÊòØ‰∏ÄÂÄãÂàÜ‰ΩàÊ†°Ê∫ñÂô®„ÄÇÊàëÂÄë
ÈÄöÈÅéÂàÜÊûê EPT ‰∏≠ÂåÖÂê´ÁöÑË£ú‰∏ÅÂºèÁ∏ÆÊîæÂíåÁâπÂæµÂàÜÈõ¢Êìç‰Ωú‰æÜÊîØÊåÅÂÆÉ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåEPT Âú®Â∞ëÊ¨°ÊãçÊîù‰∏≠ÂÑ™ÊñºÂπæÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑÂæÆË™øÊñπÊ≥ï
ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÁöÑÈÇäÈöõÔºå‰∏¶Âú®Ê•µÂÖ∑Á´∂Áà≠ÂäõÁöÑÊôÇÈñìÂÖßÂÆåÊàêÂæÆË™øÈÅéÁ®ãÔºåË°®Êòé EPT ÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑ PEFT ÊñπÊ≥ï„ÄÇ
Ê∫ê‰ª£Á¢ºÂèØÂú® github.com/zuwenqiang/EPT ‰∏≠Áç≤Âæó„ÄÇ</paragraph>

##### **Individual brain parcellation: Review of methods, validations and applications**
2407.00984v1 by Chengyi Li, Shan Yu, Yue Cui

Individual brains vary greatly in morphology, connectivity and organization.
The applicability of group-level parcellations is limited by the rapid
development of precision medicine today because they do not take into account
the variation of parcels at the individual level. Accurate mapping of brain
functional regions at the individual level is pivotal for a comprehensive
understanding of the variations in brain function and behaviors, early and
precise identification of brain abnormalities, as well as personalized
treatments for neuropsychiatric disorders. With the development of neuroimaging
and machine learning techniques, studies on individual brain parcellation are
booming. In this paper, we offer an overview of recent advances in the
methodologies of individual brain parcellation, including optimization- and
learning-based methods. Comprehensive evaluation metrics to validate individual
brain mapping have been introduced. We also review the studies of how
individual brain mapping promotes neuroscience research and clinical medicine.
Finally, we summarize the major challenges and important future directions of
individualized brain parcellation. Collectively, we intend to offer a thorough
overview of individual brain parcellation methods, validations, and
applications, along with highlighting the current challenges that call for an
urgent demand for integrated platforms that integrate datasets, methods, and
validations.

ÊëòË¶ÅÔºöÂêÑÂÄãÂ§ßËÖ¶Âú®ÂΩ¢ÊÖã„ÄÅÈÄ£Êé•ÊÄßÂíåÁµÑÁπî‰∏äÂ∑ÆÁï∞Ê•µÂ§ß„ÄÇ
Áæ§È´îÂ±§Á¥öÁöÑÂçÄÂ°äÂåñÈÅ©Áî®ÊÄßÂèóÂà∞Áï∂‰ªäÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÂø´ÈÄüÁôºÂ±ïÊâÄÈôêÂà∂ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊ≤íÊúâËÄÉÊÖÆÂà∞ÂÄãÈ´îÂ±§Á¥öÁöÑÂçÄÂ°äËÆäÁï∞„ÄÇÂú®ÂÄãÈ´îÂ±§Á¥öÊ∫ñÁ¢∫Áπ™Ë£ΩÂ§ßËÖ¶ÂäüËÉΩÂçÄÂüüÂ∞çÊñºÂÖ®Èù¢‰∫ÜËß£Â§ßËÖ¶ÂäüËÉΩÂíåË°åÁÇ∫ÁöÑËÆäÁï∞„ÄÅÊó©Êúü‰∏îÁ≤æÁ¢∫Âú∞Ë≠òÂà•Â§ßËÖ¶Áï∞Â∏∏Ôºå‰ª•ÂèäÁ•ûÁ∂ìÁ≤æÁ•ûÁñæÁóÖÁöÑÂÄã‰∫∫ÂåñÊ≤ªÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÈö®ËëóÁ•ûÁ∂ìÂΩ±ÂÉèÂíåÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÁöÑÁôºÂ±ïÔºåÈóúÊñºÂÄãÂà•Â§ßËÖ¶ÂçÄÂ°äÂåñÁöÑÁ†îÁ©∂Ê≠£Âú®Ëì¨ÂãÉÁôºÂ±ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ¶ÇËø∞‰∫ÜÂÄãÂà•Â§ßËÖ¶ÂçÄÂ°äÂåñÊñπÊ≥ïÂ≠∏ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂåÖÊã¨Âü∫ÊñºÊúÄ‰Ω≥ÂåñÂíåÂ≠∏ÁøíÁöÑÊñπÊ≥ï„ÄÇÂ∑≤Á∂ìÂºïÂÖ•‰∫ÜÂÖ®Èù¢ÁöÑË©ï‰º∞ÊåáÊ®ô‰æÜÈ©óË≠âÂÄãÂà•Â§ßËÖ¶Â∞çÊáâ„ÄÇÊàëÂÄëÈÇÑÂõûÈ°ß‰∫ÜÂÄãÂà•Â§ßËÖ¶Â∞çÊáâÂ¶Ç‰Ωï‰øÉÈÄ≤Á•ûÁ∂ìÁßëÂ≠∏Á†îÁ©∂ÂíåËá®Â∫äÈÜ´Â≠∏ÁöÑÁ†îÁ©∂„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁ∏ΩÁµê‰∫ÜÂÄãÂà•ÂåñÂ§ßËÖ¶ÂçÄÂ°äÂåñÁöÑ‰∏ªË¶ÅÊåëÊà∞ÂíåÈáçË¶ÅÁöÑÊú™‰æÜÊñπÂêë„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÊâìÁÆóÂ∞çÂÄãÂà•Â§ßËÖ¶ÂçÄÂ°äÂåñÊñπÊ≥ï„ÄÅÈ©óË≠âÂíåÊáâÁî®Êèê‰æõÂÖ®Èù¢ÁöÑÊ¶ÇËø∞ÔºåÂêåÊôÇÂº∑Ë™øÁï∂ÂâçÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞Ëø´ÂàáÈúÄË¶ÅÊï¥ÂêàÊï∏ÊìöÈõÜ„ÄÅÊñπÊ≥ïÂíåÈ©óË≠âÁöÑÊï¥ÂêàÂπ≥Âè∞„ÄÇ

##### **Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**
2407.00978v1 by Cheng Su, Jinbo Wen, Jiawen Kang, Yonghua Wang, Hudan Pan, M. Shamim Hossain

Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape. The advancement of generative
artificial intelligence has positioned Multi-modal Large Language Models
(MLLMs) as crucial tools for managing healthcare data. MLLMs can support
multi-modal inputs and generate diverse types of content by leveraging
large-scale training on vast amounts of multi-modal data. However, critical
challenges persist in developing medical MLLMs, including healthcare data
security and freshness issues, affecting the output quality of MLLMs. In this
paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered
medical MLLMs framework for healthcare data management. This framework
leverages a hierarchical cross-chain architecture to facilitate secure data
training. Moreover, it enhances the output quality of MLLMs through hybrid RAG,
which employs multi-modal metrics to filter various unimodal RAG results and
incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share fresh data, mitigating information asymmetry in data
sharing. Finally, we utilize a generative diffusion model-based reinforcement
learning algorithm to identify the optimal contract for efficient data sharing.
Numerical results demonstrate the effectiveness of the proposed schemes, which
achieve secure and efficient healthcare data management.

ÊëòË¶ÅÔºöÂú®Âø´ÈÄüËÆäÂåñÁöÑÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÔºåÂÆâÂÖ®Êï∏ÊìöÁÆ°ÁêÜÂíåÊúâÊïàÊï∏ÊìöÂÖ±‰∫´Â∑≤ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÁîüÊàêÂºè‰∫∫Â∑•Êô∫ÊÖßÁöÑÈÄ≤Ê≠•Â∑≤Â∞áÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÂÆö‰ΩçÁÇ∫ÁÆ°ÁêÜÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÁöÑÈóúÈçµÂ∑•ÂÖ∑„ÄÇMLLM ÂèØÊîØÊè¥Â§öÊ®°ÊÖãËº∏ÂÖ•Ôºå‰∏¶ÈÄèÈÅéÂà©Áî®Â§ßÈáèÂ§öÊ®°ÊÖãÊï∏ÊìöÈÄ≤Ë°åÂ§ßË¶èÊ®°Ë®ìÁ∑¥‰æÜÁî¢ÁîüÂêÑÁ®ÆÈ°ûÂûãÁöÑÂÖßÂÆπ„ÄÇÁÑ∂ËÄåÔºåÂú®ÈñãÁôºÈÜ´ÁôÇ MLLM ÊôÇ‰ªçÂ≠òÂú®ÈóúÈçµÊåëÊà∞ÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÂÆâÂÖ®ÊÄßËàáÊñ∞Á©éÊÄßÂïèÈ°åÔºåÂΩ±Èüø MLLM ÁöÑËº∏Âá∫ÂìÅË≥™„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁî±Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Ë≥¶ËÉΩÁöÑÊ∑∑ÂêàÈÜ´ÁôÇ MLLM Ê°ÜÊû∂ÔºåÁî®ÊñºÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÁÆ°ÁêÜ„ÄÇÊ≠§Ê°ÜÊû∂Âà©Áî®ÈöéÂ±§ÂºèË∑®ÈèàÊû∂ÊßãÔºå‰ª•Âà©ÊñºÂÆâÂÖ®Êï∏ÊìöË®ìÁ∑¥„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÄèÈÅéÊ∑∑Âêà RAG ‰æÜÊèêÂçá MLLM ÁöÑËº∏Âá∫ÂìÅË≥™ÔºåÊ≠§ÊñπÊ≥ïÊé°Áî®Â§öÊ®°ÊÖãÊåáÊ®ô‰æÜÈÅéÊøæÂêÑÁ®ÆÂñÆÊ®°ÊÖã RAG ÁµêÊûúÔºå‰∏¶Â∞áÈÄô‰∫õÊ™¢Á¥¢ÁµêÊûú‰ΩúÁÇ∫È°çÂ§ñËº∏ÂÖ•Á¥çÂÖ• MLLM„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî®Ë≥áË®äÂπ¥ÈΩ°‰æÜÈñìÊé•Ë©ï‰º∞ MLLM ÁöÑÊï∏ÊìöÊñ∞Á©éÊÄßÂΩ±ÈüøÔºå‰∏¶Âà©Áî®Â•ëÁ¥ÑÁêÜË´ñ‰æÜÊøÄÂãµÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÊåÅÊúâËÄÖÂÖ±‰∫´Êñ∞Á©éÊï∏ÊìöÔºåÂæûËÄåÊ∏õËºïÊï∏ÊìöÂÖ±‰∫´‰∏≠ÁöÑË≥áË®ä‰∏çÂ∞çÁ®±„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂà©Áî®ÁîüÊàêÊì¥Êï£Ê®°ÂûãÁÇ∫Âü∫Á§éÁöÑÂº∑ÂåñÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºå‰ª•ÊâæÂá∫ÊúÄ‰Ω≥Â•ëÁ¥ÑÔºå‰ª•ÈÄ≤Ë°åÊúâÊïàÁéáÁöÑÊï∏ÊìöÂÖ±‰∫´„ÄÇÊï∏ÂÄºÁµêÊûúË≠âÊòéÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÊúâÊïàÔºåÂèØÈÅîÊàêÂÆâÂÖ®‰∏îÊúâÊïàÁéáÁöÑÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÁÆ°ÁêÜ„ÄÇ

##### **Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**
2407.01647v1 by Parviz Ghafariasl, Masoomeh Zeinalnezhad, Amir Ahmadishokooh

Timely alerts about hazardous air pollutants are crucial for public health.
However, existing forecasting models often overlook key factors like baseline
parameters and missing data, limiting their accuracy. This study introduces a
hybrid approach to address these issues, focusing on forecasting hourly PM2.5
concentrations using Support Vector Regression (SVR). Meta-heuristic
algorithms, Grey Wolf Optimization (GWO) and Particle Swarm Optimization (PSO),
optimize SVR Hyper-parameters "C" and "Gamma" to enhance prediction accuracy.
Evaluation metrics include R-squared (R2), Root Mean Square Error (RMSE), and
Mean Absolute Error (MAE). Results show significant improvements with PSO-SVR
(R2: 0.9401, RMSE: 0.2390, MAE: 0.1368) and GWO-SVR (R2: 0.9408, RMSE: 0.2376,
MAE: 0.1373), indicating robust and accurate models suitable for similar
research applications.

ÊëòË¶ÅÔºöÂèäÊôÇÁôºÂ∏ÉÊúâÈóúÊúâÂÆ≥Á©∫Ê∞£Ê±°ÊüìÁâ©ÁöÑË≠¶Â†±Â∞çÂÖ¨ÂÖ±Ë°õÁîüËá≥ÈóúÈáçË¶Å„ÄÇ
ÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈ†êÊ∏¨Ê®°ÂûãÈÄöÂ∏∏ÊúÉÂøΩÁï•Âü∫Á∑öÂèÉÊï∏ÂíåÁº∫Â§±Ë≥áÊñôÁ≠âÈóúÈçµÂõ†Á¥†ÔºåÂæûËÄåÈôêÂà∂‰∫ÜÂÖ∂Ê∫ñÁ¢∫ÊÄß„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊ∑∑ÂêàÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÈáçÈªûÈóúÊ≥®‰ΩøÁî®ÊîØÊåÅÂêëÈáèÂõûÊ≠∏ (SVR) È†êÊ∏¨ÊØèÂ∞èÊôÇ PM2.5 ÊøÉÂ∫¶„ÄÇÂÖÉÂïüÁôºÂºèÊºîÁÆóÊ≥ï„ÄÅÁÅ∞ÁãºÂÑ™Âåñ (GWO) ÂíåÁ≤íÂ≠êÁæ§ÂÑ™Âåñ (PSO) ÂÑ™Âåñ SVR Ë∂ÖÂèÉÊï∏„ÄåC„ÄçÂíå„ÄåGamma„Äç‰ª•ÊèêÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇË©ï‰º∞ÊåáÊ®ôÂåÖÊã¨ R Âπ≥Êñπ (R2)„ÄÅÂùáÊñπÊ†πË™§Â∑Æ (RMSE) ÂíåÂπ≥ÂùáÁµïÂ∞çË™§Â∑Æ (MAE)„ÄÇÁµêÊûúÈ°ØÁ§∫ PSO-SVR (R2Ôºö0.9401„ÄÅRMSEÔºö0.2390„ÄÅMAEÔºö0.1368) Âíå GWO-SVR (R2Ôºö0.9408„ÄÅRMSEÔºö0.2376„ÄÅMAEÔºö0.1373) ÊúâÈ°ØËëóÊîπÂñÑÔºåË°®ÊòéÈÅ©Áî®ÊñºÈ°û‰ººÁ†îÁ©∂ÊáâÁî®Á®ãÂºèÁöÑÁ©©ÂÅ•‰∏îÊ∫ñÁ¢∫ÁöÑÊ®°Âûã„ÄÇ

##### **Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**
2407.00967v1 by Sepehr Salem Ghahfarokhi, Tyrell To, Julie Jorns, Tina Yen, Bing Yu, Dong Hye Ye

Data limitation is a significant challenge in applying deep learning to
medical images. Recently, the diffusion probabilistic model (DPM) has shown the
potential to generate high-quality images by converting Gaussian random noise
into realistic images. In this paper, we apply the DPM to augment the deep
ultraviolet fluorescence (DUV) image dataset with an aim to improve breast
cancer classification for intraoperative margin assessment. For classification,
we divide the whole surface DUV image into small patches and extract
convolutional features for each patch by utilizing the pre-trained ResNet.
Then, we feed them into an XGBoost classifier for patch-level decisions and
then fuse them with a regional importance map computed by Grad-CAM++ for whole
surface-level prediction. Our experimental results show that augmenting the
training dataset with the DPM significantly improves breast cancer detection
performance in DUV images, increasing accuracy from 93% to 97%, compared to
using Affine transformations and ProGAN.

ÊëòË¶ÅÔºöË≥áÊñôÈôêÂà∂ÊòØÊáâÁî®Ê∑±Â∫¶Â≠∏ÁøíÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑ‰∏ÄÂ§ßÊåëÊà∞„ÄÇÊúÄËøëÔºåÊì¥Êï£Ê©üÁéáÊ®°Âûã (DPM) Â∑≤Â±ïÁèæÂ∞áÈ´òÊñØÈö®Ê©üÈõúË®äËΩâÊèõÁÇ∫ÈÄºÁúüÂΩ±ÂÉèÁöÑÊΩõÂäõÔºåÁî®‰ª•Áî¢ÁîüÈ´òÂìÅË≥™ÂΩ±ÂÉè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á DPM ÊáâÁî®ÊñºÊì¥ÂÖÖÊ∑±Â∫¶Á¥´Â§ñËû¢ÂÖâ (DUV) ÂΩ±ÂÉèË≥áÊñôÈõÜÔºåÁõÆÊ®ôÊòØÊîπÂñÑ‰π≥ÁôåÂàÜÈ°ûÔºåÁî®ÊñºË°ì‰∏≠ÈÇäÁ∑£Ë©ï‰º∞„ÄÇÂ∞çÊñºÂàÜÈ°ûÔºåÊàëÂÄëÂ∞áÊï¥ÂÄãË°®Èù¢ DUV ÂΩ±ÂÉèÂàÜÂâ≤ÊàêÂ∞èÂçÄÂ°äÔºå‰∏¶Âà©Áî®È†êË®ìÁ∑¥ÁöÑ ResNet ÁÇ∫ÊØèÂÄãÂçÄÂ°äËêÉÂèñÂç∑Á©çÁâπÂæµ„ÄÇÊé•ËëóÔºåÊàëÂÄëÂ∞áÂÆÉÂÄëËº∏ÂÖ• XGBoost ÂàÜÈ°ûÂô®ÔºåÁî®ÊñºÂçÄÂ°äÂ±§Á¥öÁöÑÊ±∫Á≠ñÔºåÁÑ∂ÂæåÂ∞áÂÆÉÂÄëËàá Grad-CAM++ Ë®àÁÆóÂá∫ÁöÑÂçÄÂüüÈáçË¶ÅÊÄßÂúñËûçÂêàÔºåÁî®ÊñºÊï¥ÂÄãË°®Èù¢Â±§Á¥öÁöÑÈ†êÊ∏¨„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫Ôºå‰ΩøÁî® DPM Êì¥ÂÖÖË®ìÁ∑¥Ë≥áÊñôÈõÜÂèØÈ°ØËëóÊèêÂçá DUV ÂΩ±ÂÉèÁöÑ‰π≥ÁôåÂÅµÊ∏¨ÊïàËÉΩÔºåËàá‰ΩøÁî®‰ªøÂ∞ÑËΩâÊèõÂíå ProGAN Áõ∏ÊØîÔºåÊ∫ñÁ¢∫ÁéáÂæû 93% ÊèêÂçáËá≥ 97%„ÄÇ

##### **Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**
2407.00764v1 by Stefan Arnold, Rene Gr√∂bner, Annika Schreiner

Differential Privacy (DP) can be applied to raw text by exploiting the
spatial arrangement of words in an embedding space. We investigate the
implications of such text privatization on Language Models (LMs) and their
tendency towards stereotypical associations. Since previous studies documented
that linguistic proficiency correlates with stereotypical bias, one could
assume that techniques for text privatization, which are known to degrade
language modeling capabilities, would cancel out undesirable biases. By testing
BERT models trained on texts containing biased statements primed with varying
degrees of privacy, our study reveals that while stereotypical bias generally
diminishes when privacy is tightened, text privatization does not uniformly
equate to diminishing bias across all social domains. This highlights the need
for careful diagnosis of bias in LMs that undergo text privatization.

ÊëòË¶ÅÔºöÂ∑ÆÂàÜÈö±ÁßÅ (DP) ÂèØÈÄèÈÅéÂà©Áî®ÂµåÂÖ•Á©∫Èñì‰∏≠Â≠óË©ûÁöÑÁ©∫ÈñìÊéíÂàó‰æÜÊáâÁî®ÊñºÂéüÂßãÊñáÂ≠ó„ÄÇÊàëÂÄëÊé¢Ë®éÈÄôÁ®ÆÊñáÂ≠óÁßÅÊúâÂåñÂ∞çË™ûË®ÄÊ®°Âûã (LM) ÂèäÂÖ∂Â∞çÂàªÊùøÂç∞Ë±°ÈóúËÅØÁöÑÂÇæÂêëÊâÄÈÄ†ÊàêÁöÑÂΩ±Èüø„ÄÇÁî±ÊñºÂÖàÂâçÁöÑÁ†îÁ©∂Ë®òÈåÑË™ûË®ÄËÉΩÂäõËàáÂàªÊùøÂç∞Ë±°ÂÅèË™§Áõ∏ÈóúÔºåÂõ†Ê≠§ÂèØ‰ª•ÂÅáË®≠Â∑≤Áü•ÊúÉÈôç‰ΩéË™ûË®ÄÂª∫Ê®°ËÉΩÂäõÁöÑÊñáÂ≠óÁßÅÊúâÂåñÊäÄË°ìÊúÉÊ∂àÈô§‰∏çËâØÂÅèË™§„ÄÇÈÄèÈÅéÊ∏¨Ë©¶Âú®ÂåÖÂê´‰ª•‰∏çÂêåÁ®ãÂ∫¶Èö±ÁßÅÁÇ∫ÂâçÊèêÁöÑÂÅèË¶ãÈô≥Ëø∞ÁöÑÊñáÂ≠ó‰∏äË®ìÁ∑¥ÁöÑ BERT Ê®°ÂûãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÈõñÁÑ∂Âú®Âä†Âº∑Èö±ÁßÅÊôÇÂàªÊùøÂç∞Ë±°ÂÅèË™§ÈÄöÂ∏∏ÊúÉÊ∏õÂ∞ëÔºå‰ΩÜÊñáÂ≠óÁßÅÊúâÂåñ‰∏¶ÈùûÂú®ÊâÄÊúâÁ§æÊúÉÈ†òÂüüÈÉΩÁ≠âÊñºÊ∏õÂ∞ëÂÅèË™§„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÂú®Á∂ìÈÅéÊñáÂ≠óÁßÅÊúâÂåñÁöÑ LM ‰∏≠‰ªîÁ¥∞Ë®∫Êñ∑ÂÅèË™§ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**
2407.00752v1 by Peng Huang, Xue Gao, Lihong Huang, Jing Jiao, Xiaokang Li, Yuanyuan Wang, Yi Guo

Text-to-image generation has important implications for generation of diverse
and controllable images. Several attempts have been made to adapt Stable
Diffusion (SD) to the medical domain. However, the large distribution
difference between medical reports and natural texts, as well as high
computational complexity in common stable diffusion limit the authenticity and
feasibility of the generated medical images. To solve above problems, we
propose a novel light-weight transformer-based diffusion model learning
framework, Chest-Diffusion, for report-to-CXR generation. Chest-Diffusion
employs a domain-specific text encoder to obtain accurate and expressive text
features to guide image generation, improving the authenticity of the generated
images. Meanwhile, we introduce a light-weight transformer architecture as the
denoising model, reducing the computational complexity of the diffusion model.
Experiments demonstrate that our Chest-Diffusion achieves the lowest FID score
24.456, under the computation budget of 118.918 GFLOPs, which is nearly
one-third of the computational complexity of SD.

ÊëòË¶ÅÔºöÊñáÊú¨Âà∞ÂõæÂÉèÁîüÊàêÂØπ‰∫éÁîüÊàêÂ§öÊ†∑‰∏îÂèØÊéßÁöÑÂõæÂÉèÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇÂ∑≤ÁªèÂÅöÂá∫‰∫Ü‰∏Ä‰∫õÂ∞ùËØïÊù•Â∞Ü Stable Diffusion (SD) Ë∞ÉÊï¥Âà∞ÂåªÂ≠¶È¢ÜÂüü„ÄÇÁÑ∂ËÄåÔºåÂåªÂ≠¶Êä•ÂëäÂíåËá™ÁÑ∂ÊñáÊú¨‰πãÈó¥Â≠òÂú®ËæÉÂ§ßÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇÔºå‰ª•ÂèäÂ∏∏ËßÅÁöÑÁ®≥ÂÆöÊâ©Êï£‰∏≠ÁöÑÈ´òËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÈôêÂà∂‰∫ÜÁîüÊàêÂåªÂ≠¶ÂõæÂÉèÁöÑÁúüÂÆûÊÄßÂíåÂèØË°åÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥‰∏äËø∞ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑËΩªÈáèÁ∫ßÂü∫‰∫é transformer ÁöÑÊâ©Êï£Ê®°ÂûãÂ≠¶‰π†Ê°ÜÊû∂ Chest-DiffusionÔºåÁî®‰∫éÊä•ÂëäÂà∞ CXR ÁîüÊàê„ÄÇChest-Diffusion ‰ΩøÁî®ÁâπÂÆö‰∫éÈ¢ÜÂüüÁöÑÊñáÊú¨ÁºñÁ†ÅÂô®Êù•Ëé∑ÂèñÂáÜÁ°Æ‰∏îÂØåÊúâË°®Áé∞ÂäõÁöÑÊñáÊú¨ÁâπÂæÅ‰ª•ÊåáÂØºÂõæÂÉèÁîüÊàêÔºå‰ªéËÄåÊèêÈ´òÁîüÊàêÂõæÂÉèÁöÑÁúüÂÆûÊÄß„ÄÇÂêåÊó∂ÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑ transformer Êû∂ÊûÑ‰Ωú‰∏∫ÂéªÂô™Ê®°ÂûãÔºåÈôç‰Ωé‰∫ÜÊâ©Êï£Ê®°ÂûãÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑ Chest-Diffusion Âú® 118.918 GFLOP ÁöÑËÆ°ÁÆóÈ¢ÑÁÆó‰∏ãÂÆûÁé∞‰∫ÜÊúÄ‰ΩéÁöÑ FID ÂàÜÊï∞ 24.456ÔºåËøôÂá†‰πéÊòØ SD ËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÁöÑ‰∏âÂàÜ‰πã‰∏Ä„ÄÇ

##### **Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**
2407.00731v1 by Qiuhao Lu, Rui Li, Andrew Wen, Jinlian Wang, Liwei Wang, Hongfang Liu

Large Language Models (LLMs) have revolutionized various sectors, including
healthcare where they are employed in diverse applications. Their utility is
particularly significant in the context of rare diseases, where data scarcity,
complexity, and specificity pose considerable challenges. In the clinical
domain, Named Entity Recognition (NER) stands out as an essential task and it
plays a crucial role in extracting relevant information from clinical texts.
Despite the promise of LLMs, current research mostly concentrates on
document-level NER, identifying entities in a more general context across
entire documents, without extracting their precise location. Additionally,
efforts have been directed towards adapting ChatGPT for token-level NER.
However, there is a significant research gap when it comes to employing
token-level NER for clinical texts, especially with the use of local
open-source LLMs. This study aims to bridge this gap by investigating the
effectiveness of both proprietary and local LLMs in token-level clinical NER.
Essentially, we delve into the capabilities of these models through a series of
experiments involving zero-shot prompting, few-shot prompting,
retrieval-augmented generation (RAG), and instruction-fine-tuning. Our
exploration reveals the inherent challenges LLMs face in token-level NER,
particularly in the context of rare diseases, and suggests possible
improvements for their application in healthcare. This research contributes to
narrowing a significant gap in healthcare informatics and offers insights that
could lead to a more refined application of LLMs in the healthcare sector.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÂæπÂ∫ïÊîπËÆä‰∫ÜÂêÑÂÄãÈ†òÂüüÔºåÂåÖÊã¨ÈÜ´ÁôÇ‰øùÂÅ•ÔºåÂÆÉÂÄëÂú®ÂÖ∂‰∏≠Ë¢´Áî®ÊñºÂêÑÁ®ÆÊáâÁî®Á®ãÂºè„ÄÇÂÆÉÂÄëÁöÑÂØ¶Áî®ÊÄßÂú®ÁΩïË¶ãÁñæÁóÖÁöÑËÉåÊôØ‰∏ãÂ∞§ÂÖ∂ÈáçË¶ÅÔºåÂõ†ÁÇ∫Ë≥áÊñôÁ®ÄÂ∞ë„ÄÅË§áÈõú‰∏îÂÖ∑ÁâπÁï∞ÊÄßÔºåÂ∞çÊ≠§ÊßãÊàêÁõ∏Áï∂Â§ßÁöÑÊåëÊà∞„ÄÇÂú®Ëá®Â∫äÈ†òÂüü‰∏≠ÔºåÂëΩÂêçÂØ¶È´îË≠òÂà• (NER) ÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂú®ÂæûËá®Â∫äÊñáÊú¨‰∏≠Êì∑ÂèñÁõ∏ÈóúË≥áË®äÊñπÈù¢ÊâÆÊºîËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂÑòÁÆ° LLM ÂâçÊôØÁúãÂ•ΩÔºå‰ΩÜÁõÆÂâçÁöÑÁ†îÁ©∂Â§ßÂ§öÈõÜ‰∏≠Âú®Êñá‰ª∂Â±§Á¥öÁöÑ NERÔºåÂú®Êï¥ÂÄãÊñá‰ª∂‰∏≠Ë≠òÂà•Êõ¥ÈÄöÁî®ÁöÑËÉåÊôØ‰∏≠ÁöÑÂØ¶È´îÔºåËÄå‰∏çÊúÉÊì∑ÂèñÂÆÉÂÄëÁ≤æÁ¢∫ÁöÑ‰ΩçÁΩÆ„ÄÇÊ≠§Â§ñÔºåÂ∑≤Â∞áÁ≤æÂäõÊäïÂÖ•ÊñºË™øÊï¥ ChatGPT ‰ª•ÈÄ≤Ë°å‰ª£Âπ£Â±§Á¥öÁöÑ NER„ÄÇÁÑ∂ËÄåÔºåÂú®‰ΩøÁî®‰ª£Âπ£Â±§Á¥öÁöÑ NER ‰æÜËôïÁêÜËá®Â∫äÊñáÊú¨ÊôÇÔºåÁâπÂà•ÊòØÂú®‰ΩøÁî®Êú¨Âú∞ÁöÑÈñãÊ∫ê LLM ÊôÇÔºåÂ≠òÂú®ÈáçÂ§ßÁöÑÁ†îÁ©∂Â∑ÆË∑ù„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéÊé¢Ë®éÂ∞àÊúâÂíåÊú¨Âú∞ LLM Âú®‰ª£Âπ£Â±§Á¥öËá®Â∫ä NER ‰∏≠ÁöÑÊúâÊïàÊÄß‰æÜÂΩåË£úÊ≠§Â∑ÆË∑ù„ÄÇÂü∫Êú¨‰∏äÔºåÊàëÂÄëÈÄèÈÅé‰∏ÄÁ≥ªÂàóÊ∂âÂèäÈõ∂Ê¨°ÊèêÁ§∫„ÄÅÂ∞ëÊ¨°ÊèêÁ§∫„ÄÅÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÂíåÊåá‰ª§ÂæÆË™øÁöÑÂØ¶È©óÔºåÊ∑±ÂÖ•Êé¢Ë®éÈÄô‰∫õÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊé¢Á¥¢Êè≠Á§∫‰∫Ü LLM Âú®‰ª£Âπ£Â±§Á¥ö NER ‰∏≠Èù¢Ëá®ÁöÑÂõ∫ÊúâÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÁΩïË¶ãÁñæÁóÖÁöÑËÉåÊôØ‰∏ãÔºå‰∏¶Âª∫Ë≠∞‰∫ÜÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠ÂèØËÉΩÁöÑÊîπÈÄ≤„ÄÇÊú¨Á†îÁ©∂ÊúâÂä©ÊñºÁ∏ÆÂ∞èÈÜ´ÁôÇ‰øùÂÅ•Ë≥áË®äÂ≠∏‰∏≠ÁöÑ‰∏ÄÂÄãÈáçÂ§ßÂ∑ÆË∑ùÔºå‰∏¶Êèê‰æõÂèØÊúõÂ∞éËá¥Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÊõ¥Á≤æÁ∑ªÂú∞ÊáâÁî® LLM ÁöÑË¶ãËß£„ÄÇ

##### **SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**
2407.00664v1 by Zekang Yang, Hong Liu, Xiangdong Wang

Cancer survival prediction is a challenging task that involves analyzing of
the tumor microenvironment within Whole Slide Image (WSI). Previous methods
cannot effectively capture the intricate interaction features among instances
within the local area of WSI. Moreover, existing methods for cancer survival
prediction based on WSI often fail to provide better clinically meaningful
predictions. To overcome these challenges, we propose a Sparse Context-aware
Multiple Instance Learning (SCMIL) framework for predicting cancer survival
probability distributions. SCMIL innovatively segments patches into various
clusters based on their morphological features and spatial location
information, subsequently leveraging sparse self-attention to discern the
relationships between these patches with a context-aware perspective.
Considering many patches are irrelevant to the task, we introduce a learnable
patch filtering module called SoftFilter, which ensures that only interactions
between task-relevant patches are considered. To enhance the clinical relevance
of our prediction, we propose a register-based mixture density network to
forecast the survival probability distribution for individual patients. We
evaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas
(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal
clear cell carcinoma (KIRC). Our experimental results indicate that SCMIL
outperforms current state-of-the-art methods for survival prediction, offering
more clinically meaningful and interpretable outcomes. Our code is accessible
at https://github.com/yang-ze-kang/SCMIL.

ÊëòË¶ÅÔºöÁôåÁóáÂ≠òÊ¥ªÈ†êÊ∏¨ÊòØ‰∏ÄÈ†ÖËâ±ÈâÖÁöÑ‰ªªÂãôÔºåÊ∂âÂèäÂàÜÊûêÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè (WSI) ‰∏≠ÁöÑËÖ´Áò§ÂæÆÁí∞Â¢É„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÊñπÊ≥ïÁÑ°Ê≥ïÊúâÊïàÊì∑Âèñ WSI Â±ÄÈÉ®ÂçÄÂüüÂÖßÂØ¶‰æã‰πãÈñìÁöÑË§áÈõú‰∫íÂãïÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÁèæÊúâÁöÑÂü∫Êñº WSI ÁöÑÁôåÁóáÂ≠òÊ¥ªÈ†êÊ∏¨ÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÊèê‰æõÊõ¥ÊúâÊÑèÁæ©ÁöÑËá®Â∫äÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®ÄÁñè‰∏ä‰∏ãÊñáÊÑüÁü•Â§öÂØ¶‰æãÂ≠∏Áøí (SCMIL) Ê°ÜÊû∂ÔºåÁî®ÊñºÈ†êÊ∏¨ÁôåÁóáÂ≠òÊ¥ªÊ©üÁéáÂàÜ‰Ωà„ÄÇSCMIL ÂâµÊñ∞Âú∞Ê†πÊìöÂΩ¢ÊÖãÁâπÂæµÂíåÁ©∫Èñì‰ΩçÁΩÆË≥áË®äÂ∞áÂçÄÂ°äÂàÜÂâ≤ÊàêÂêÑÁ®ÆÂè¢ÈõÜÔºåÈö®ÂæåÂà©Áî®Á®ÄÁñèËá™Ê≥®ÊÑèÂäõ‰æÜËæ®Âà•ÈÄô‰∫õÂçÄÂ°ä‰πãÈñìÁöÑÈóú‰øÇÔºå‰∏¶ÂÖ∑ÂÇô‰∏ä‰∏ãÊñáÊÑüÁü•ËßÄÈªû„ÄÇËÄÉÈáèÂà∞Ë®±Â§öÂçÄÂ°äËàá‰ªªÂãôÁÑ°ÈóúÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØÂ≠∏ÁøíÁöÑÂçÄÂ°äÈÅéÊøæÊ®°ÁµÑ SoftFilterÔºå‰ª•Á¢∫‰øùÂÉÖËÄÉÊÖÆËàá‰ªªÂãôÁõ∏ÈóúÂçÄÂ°ä‰πãÈñìÁöÑ‰∫íÂãï„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑ÊàëÂÄëÈ†êÊ∏¨ÁöÑËá®Â∫äÁõ∏ÈóúÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË®ªÂÜäÁöÑÊ∑∑ÂêàÂØÜÂ∫¶Á∂≤Ë∑ØÔºå‰ª•È†êÊ∏¨ÂÄãÂà•ÊÇ£ËÄÖÁöÑÂ≠òÊ¥ªÊ©üÁéáÂàÜ‰Ωà„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã‰æÜËá™ÁôåÁóáÂü∫Âõ†ÂúñË≠ú (TCGA) ÁöÑÂÖ¨ÂÖ± WSI Ë≥áÊñôÈõÜ‰∏äË©ï‰º∞ SCMILÔºåÁâπÂà•ÈóúÊ≥®ËÇ∫ËÖ∫Áôå (LUAD) ÂíåËÖéÈÄèÊòéÁ¥∞ËÉûÁôå (KIRC)„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåSCMIL Âú®Â≠òÊ¥ªÈ†êÊ∏¨ÊñπÈù¢ÂÑ™ÊñºÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÊèê‰æõ‰∫ÜÊõ¥ÊúâÊÑèÁæ©‰∏îÂèØËß£ÈáãÁöÑËá®Â∫äÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/yang-ze-kang/SCMIL ÂèñÂæó„ÄÇ

##### **TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**
2407.00631v1 by Jintai Chen, Yaojun Hu, Yue Wang, Yingzhou Lu, Xu Cao, Miao Lin, Hongxia Xu, Jian Wu, Cao Xiao, Jimeng Sun, Lucas Glass, Kexin Huang, Marinka Zitnik, Tianfan Fu

Clinical trials are pivotal for developing new medical treatments, yet they
typically pose some risks such as patient mortality, adverse events, and
enrollment failure that waste immense efforts spanning over a decade. Applying
artificial intelligence (AI) to forecast or simulate key events in clinical
trials holds great potential for providing insights to guide trial designs.
However, complex data collection and question definition requiring medical
expertise and a deep understanding of trial designs have hindered the
involvement of AI thus far. This paper tackles these challenges by presenting a
comprehensive suite of meticulously curated AIready datasets covering
multi-modal data (e.g., drug molecule, disease code, text,
categorical/numerical features) and 8 crucial prediction challenges in clinical
trial design, encompassing prediction of trial duration, patient dropout rate,
serious adverse event, mortality rate, trial approval outcome, trial failure
reason, drug dose finding, design of eligibility criteria. Furthermore, we
provide basic validation methods for each task to ensure the datasets'
usability and reliability. We anticipate that the availability of such
open-access datasets will catalyze the development of advanced AI approaches
for clinical trial design, ultimately advancing clinical trial research and
accelerating medical solution development. The curated dataset, metrics, and
basic models are publicly available at
https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.

ÊëòË¶ÅÔºöËá®Â∫äË©¶È©óÂ∞çÊñºÈñãÁôºÊñ∞ÁöÑÈÜ´ÁôÇÁôÇÊ≥ïËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏ÊúÉÂ∏∂‰æÜ‰∏Ä‰∫õÈ¢®Èö™Ôºå‰æãÂ¶ÇÊÇ£ËÄÖÊ≠ª‰∫°Áéá„ÄÅ‰∏çËâØ‰∫ã‰ª∂ÂíåË®ªÂÜäÂ§±ÊïóÔºåÈÄô‰∫õÈ¢®Èö™ÊúÉÊµ™Ë≤ªÈï∑ÈÅîÂçÅÂπ¥ÁöÑÂ∑®Â§ßÂä™Âäõ„ÄÇÂ∞á‰∫∫Â∑•Êô∫ÊÖß (AI) ÊáâÁî®ÊñºÈ†êÊ∏¨ÊàñÊ®°Êì¨Ëá®Â∫äË©¶È©ó‰∏≠ÁöÑÈóúÈçµ‰∫ã‰ª∂ÔºåÂ∞çÊñºÊèê‰æõË¶ãËß£‰ª•ÊåáÂ∞éË©¶È©óË®≠Ë®àÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÈúÄË¶ÅÈÜ´Â≠∏Â∞àÊ•≠Áü•Ë≠òÂíåÂ∞çË©¶È©óË®≠Ë®àÁöÑÊ∑±ÂÖ•‰∫ÜËß£ÁöÑË§áÈõúÊï∏ÊìöÊî∂ÈõÜÂíåÂïèÈ°åÂÆöÁæ©ÔºåËøÑ‰ªäÁÇ∫Ê≠¢ÈòªÁ§ô‰∫Ü AI ÁöÑÂèÉËàá„ÄÇÊú¨ÊñáÈÄöÈÅéÊèê‰æõ‰∏ÄÂ•óÂÖ®Èù¢ÁöÑÁ≤æÂøÉÁ≠ñÂäÉÁöÑ AIready Êï∏ÊìöÈõÜ‰æÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊ∂µËìãÂ§öÊ®°ÂºèÊï∏ÊìöÔºà‰æãÂ¶ÇÔºåËó•Áâ©ÂàÜÂ≠ê„ÄÅÁñæÁóÖ‰ª£Á¢º„ÄÅÊñáÊú¨„ÄÅÂàÜÈ°û/Êï∏ÂÄºÁâπÂæµÔºâÂíåËá®Â∫äË©¶È©óË®≠Ë®à‰∏≠ÁöÑ 8 È†ÖÈóúÈçµÈ†êÊ∏¨ÊåëÊà∞ÔºåÂåÖÊã¨È†êÊ∏¨Ë©¶È©óÊåÅÁ∫åÊôÇÈñì„ÄÅÊÇ£ËÄÖËºüÂ≠∏Áéá„ÄÅÂö¥Èáç‰∏çËâØ‰∫ã‰ª∂„ÄÅÊ≠ª‰∫°Áéá„ÄÅË©¶È©óÊâπÂáÜÁµêÊûú„ÄÅË©¶È©óÂ§±ÊïóÂéüÂõ†„ÄÅËó•Áâ©ÂäëÈáèÁôºÁèæ„ÄÅË≥áÊ†ºÊ®ôÊ∫ñÁöÑË®≠Ë®à„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁÇ∫ÊØèÂÄã‰ªªÂãôÊèê‰æõÂü∫Êú¨ÁöÑÈ©óË≠âÊñπÊ≥ïÔºå‰ª•Á¢∫‰øùÊï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÈ†êË®àÈÄô‰∫õÈñãÊîæË®™ÂïèÊï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÂ∞áÂÇ¨ÂåñÂÖàÈÄ≤ AI ÊñπÊ≥ïÂú®Ëá®Â∫äË©¶È©óË®≠Ë®à‰∏≠ÁöÑÈñãÁôºÔºåÊúÄÁµÇÊé®ÈÄ≤Ëá®Â∫äË©¶È©óÁ†îÁ©∂‰∏¶Âä†ÈÄüÈÜ´ÁôÇËß£Ê±∫ÊñπÊ°àÁöÑÈñãÁôº„ÄÇÁ≠ñÂ±ïÁöÑÊï∏ÊìöÈõÜ„ÄÅÊåáÊ®ôÂíåÂü∫Êú¨Ê®°ÂûãÂú® https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial ‰∏äÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Answering real-world clinical questions using large language model based systems**
2407.00541v1 by Yen Sia Low, Michael L. Jackson, Rebecca J. Hyde, Robert E. Brown, Neil M. Sanghavi, Julian D. Baldwin, C. William Pike, Jananee Muralidharan, Gavin Hui, Natasha Alexander, Hadeel Hassan, Rahul V. Nene, Morgan Pike, Courtney J. Pokrzywa, Shivam Vedak, Adam Paul Yan, Dong-han Yao, Amy R. Zipursky, Christina Dinh, Philip Ballentine, Dan C. Derieg, Vladimir Polony, Rehan N. Chawdry, Jordan Davies, Brigham B. Hyde, Nigam H. Shah, Saurabh Gombar

Evidence to guide healthcare decisions is often limited by a lack of relevant
and trustworthy literature as well as difficulty in contextualizing existing
research for a specific patient. Large language models (LLMs) could potentially
address both challenges by either summarizing published literature or
generating new studies based on real-world data (RWD). We evaluated the ability
of five LLM-based systems in answering 50 clinical questions and had nine
independent physicians review the responses for relevance, reliability, and
actionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,
Gemini Pro 1.5) rarely produced answers that were deemed relevant and
evidence-based (2% - 10%). In contrast, retrieval augmented generation
(RAG)-based and agentic LLM systems produced relevant and evidence-based
answers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic
ChatRWD was able to answer novel questions compared to other LLMs (65% vs.
0-9%). These results suggest that while general-purpose LLMs should not be used
as-is, a purpose-built system for evidence summarization based on RAG and one
for generating novel evidence working synergistically would improve
availability of pertinent evidence for patient care.

ÊëòË¶ÅÔºöÈÜ´ÁôÇ‰øùÂÅ•Ê±∫Á≠ñÁöÑÊåáÂ∞éË≠âÊìöÈÄöÂ∏∏ÂèóÂà∞Áº∫‰πèÁõ∏Èóú‰∏îÂèØ‰ø°Ë≥¥ÊñáÁçªÁöÑÈôêÂà∂Ôºå‰ª•ÂèäÈõ£‰ª•Â∞áÁèæÊúâÁ†îÁ©∂ËÉåÊôØÂåñ‰ª•ÈÅ©Áî®ÊñºÁâπÂÆöÊÇ£ËÄÖ„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊΩõÂú®ÂèØÈÄèÈÅéÊëòË¶ÅÂ∑≤ÁôºË°®ÁöÑÊñáÁçªÊàñÊ†πÊìöÁúüÂØ¶‰∏ñÁïåË≥áÊñô (RWD) Áî¢ÁîüÊñ∞ÁöÑÁ†îÁ©∂‰æÜËß£Ê±∫ÈÄôÂÖ©ÂÄãÊåëÊà∞„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü‰∫îÂÄãÂü∫Êñº LLM ÁöÑÁ≥ªÁµ±ÂõûÁ≠î 50 ÂÄãËá®Â∫äÂïèÈ°åÁöÑËÉΩÂäõÔºå‰∏¶ËÆì‰πù‰ΩçÁç®Á´ãÁöÑÈÜ´Â∏´Ê™¢Ë¶ñÂõûÊáâÁöÑÁõ∏ÈóúÊÄß„ÄÅÂèØÈù†ÊÄßÔºå‰ª•ÂèäÂèØË°åÊÄß„ÄÇÁõÆÂâçÔºåÈÄöÁî® LLMÔºàChatGPT-4„ÄÅClaude 3 Opus„ÄÅGemini Pro 1.5ÔºâÂæàÂ∞ëÁî¢ÁîüË¢´Ë™çÁÇ∫Áõ∏Èóú‰∏îÂü∫ÊñºË≠âÊìöÁöÑÁ≠îÊ°àÔºà2% - 10%Ôºâ„ÄÇÁõ∏ÂèçÂú∞ÔºåÂü∫ÊñºÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂíå‰ª£ÁêÜ LLM Á≥ªÁµ±Áî¢ÁîüÁöÑÁ≠îÊ°àÔºåÊúâ 24%ÔºàOpenEvidenceÔºâËá≥ 58%ÔºàChatRWDÔºâÁöÑÂïèÈ°åÊòØÁõ∏Èóú‰∏îÂü∫ÊñºË≠âÊìöÁöÑ„ÄÇËàáÂÖ∂‰ªñ LLM Áõ∏ÊØîÔºåÂè™Êúâ‰ª£ÁêÜ ChatRWD ËÉΩÂ§†ÂõûÁ≠îÊñ∞ÂïèÈ°åÔºà65% Â∞ç 0-9%Ôºâ„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÈõñÁÑ∂‰∏çÊáâÊåâÂéüÊ®£‰ΩøÁî®ÈÄöÁî® LLMÔºå‰ΩÜ‰∏ÄÂÄãÂü∫Êñº RAG ÁöÑÂ∞àÈñÄÂª∫ÁΩÆÁ≥ªÁµ±ÔºåÁî®ÊñºË≠âÊìöÊëòË¶ÅÔºå‰ª•Âèä‰∏ÄÂÄãÁî®ÊñºÁî¢ÁîüÊñ∞Ë≠âÊìöÁöÑÁ≥ªÁµ±ÔºåÂçîÂêåÈÅã‰ΩúÔºåÂ∞áÂèØÊîπÂñÑËàáÊÇ£ËÄÖÁÖßË≠∑Áõ∏ÈóúË≠âÊìöÁöÑÂèØÁî®ÊÄß„ÄÇ

##### **Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**
2407.00538v1 by Kiarash Sedghighadikolaei, Attila A Yavuz

The shift towards efficient and automated data analysis through Machine
Learning (ML) has notably impacted healthcare systems, particularly Radiomics.
Radiomics leverages ML to analyze medical images accurately and efficiently for
precision medicine. Current methods rely on Deep Learning (DL) to improve
performance and accuracy (Deep Radiomics). Given the sensitivity of medical
images, ensuring privacy throughout the Deep Radiomics pipeline-from data
generation and collection to model training and inference-is essential,
especially when outsourced. Thus, Privacy-Enhancing Technologies (PETs) are
crucial tools for Deep Radiomics. Previous studies and systematization efforts
have either broadly overviewed PETs and their applications or mainly focused on
subsets of PETs for ML algorithms. In Deep Radiomics, where efficiency,
accuracy, and privacy are crucial, many PETs, while theoretically applicable,
may not be practical without specialized optimizations or hybrid designs.
Additionally, not all DL models are suitable for Radiomics. Consequently, there
is a need for specialized studies that investigate and systematize the
effective and practical integration of PETs into the Deep Radiomics pipeline.
This work addresses this research gap by (1) classifying existing PETs,
presenting practical hybrid PETS constructions, and a taxonomy illustrating
their potential integration with the Deep Radiomics pipeline, with comparative
analyses detailing assumptions, architectural suitability, and security, (2)
Offering technical insights, describing potential challenges and means of
combining PETs into the Deep Radiomics pipeline, including integration
strategies, subtilities, and potential challenges, (3) Proposing potential
research directions, identifying challenges, and suggesting solutions to
enhance the PETs in Deep Radiomics.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÔºàMLÔºâÊúùÂêëÈ´òÊïà‰∏îËá™ÂãïÂåñÁöÑË≥áÊñôÂàÜÊûêËΩâËÆäÔºåÈ°ØËëóÂΩ±Èüø‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÔºåÂ∞§ÂÖ∂ÊòØÊîæÂ∞ÑÁµÑÂ≠∏„ÄÇÊîæÂ∞ÑÁµÑÂ≠∏Âà©Áî®Ê©üÂô®Â≠∏ÁøíÁ≤æÊ∫ñ‰∏îÊúâÊïàÂú∞ÂàÜÊûêÈÜ´Â≠∏ÂΩ±ÂÉèÔºå‰ª•ÈÄ≤Ë°åÁ≤æÊ∫ñÈÜ´ÁôÇ„ÄÇÁõÆÂâçÁöÑÊäÄË°ì‰ª∞Ë≥¥Ê∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâ‰æÜÊèêÂçáÊïàËÉΩÂíåÊ∫ñÁ¢∫Â∫¶ÔºàÊ∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏Ôºâ„ÄÇËÄÉÈáèÂà∞ÈÜ´Â≠∏ÂΩ±ÂÉèÁöÑÊïèÊÑüÊÄßÔºåÁ¢∫‰øùÂú®Ê∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏ÊµÅÁ®ã‰∏≠ÔºàÂæûË≥áÊñôÁî¢ÁîüÂíåÊî∂ÈõÜÂà∞Ê®°ÂûãË®ìÁ∑¥ÂíåÊé®Ë´ñÔºâÁöÑÈö±ÁßÅËá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®Â§ñÂåÖÊôÇ„ÄÇÂõ†Ê≠§ÔºåÈö±ÁßÅÂº∑ÂåñÊäÄË°ìÔºàPETÔºâÊòØÊ∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏ÁöÑÈóúÈçµÂ∑•ÂÖ∑„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÂíåÁ≥ªÁµ±ÂåñÂ∑•‰ΩúÔºå‰∏çÊòØÂª£Ê≥õÊ¶ÇËø∞ PET ÂíåÂÖ∂ÊáâÁî®ÔºåÂ∞±ÊòØ‰∏ªË¶ÅÈóúÊ≥® PET Âú®Ê©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ï‰∏≠ÁöÑÂ≠êÈõÜ„ÄÇÂú®Ê∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏‰∏≠ÔºåÊïàÁéá„ÄÅÊ∫ñÁ¢∫Â∫¶ÂíåÈö±ÁßÅËá≥ÈóúÈáçË¶ÅÔºåË®±Â§ö PET ÈõñÁÑ∂ÁêÜË´ñ‰∏äÈÅ©Áî®Ôºå‰ΩÜËã•Ê≤íÊúâÂ∞àÈñÄÁöÑÊúÄ‰Ω≥ÂåñÊàñÊ∑∑ÂêàË®≠Ë®àÔºåÂèØËÉΩ‰∏çÂàáÂØ¶Èöõ„ÄÇÊ≠§Â§ñÔºå‰∏¶ÈùûÊâÄÊúâÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÈÉΩÈÅ©ÂêàÊîæÂ∞ÑÁµÑÂ≠∏„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶ÅÂ∞àÈñÄÁöÑÁ†îÁ©∂ÔºåË™øÊü•ÂíåÁ≥ªÁµ±Âåñ PET Âú®Ê∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏ÊµÅÁ®ã‰∏≠ÁöÑÊúâÊïà‰∏îÂØ¶ÈöõÊï¥Âêà„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÈÄèÈÅéÔºà1ÔºâÂàÜÈ°ûÁèæÊúâÁöÑ PETÔºåÊèêÂá∫ÂØ¶ÈöõÁöÑÊ∑∑Âêà PET Âª∫ÊßãÔºå‰ª•Âèä‰∏ÄÂÄãË™™ÊòéÂÖ∂ËàáÊ∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏ÊµÅÁ®ãÊΩõÂú®Êï¥ÂêàÁöÑÂàÜÈ°ûÊ≥ïÔºå‰∏¶Êèê‰æõË©≥Á¥∞Ë™™ÊòéÂÅáË®≠„ÄÅÊû∂ÊßãÈÅ©Áî®ÊÄßÂíåÂÆâÂÖ®ÊÄßÔºåÔºà2ÔºâÊèê‰æõÊäÄË°ìË¶ãËß£ÔºåË™™ÊòéÂ∞á PET Êï¥ÂêàÂà∞Ê∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏ÊµÅÁ®ã‰∏≠ÁöÑÊΩõÂú®ÊåëÊà∞ÂíåÊñπÊ≥ïÔºåÂåÖÊã¨Êï¥ÂêàÁ≠ñÁï•„ÄÅÁ¥∞ÂæÆÂ∑ÆÂà•ÂíåÊΩõÂú®ÊåëÊà∞ÔºåÔºà3ÔºâÊèêÂá∫ÊΩõÂú®ÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÊâæÂá∫ÊåëÊà∞Ôºå‰∏¶Âª∫Ë≠∞Ëß£Ê±∫ÊñπÊ°àÔºå‰ª•Âº∑ÂåñÊ∑±Â∫¶ÊîæÂ∞ÑÁµÑÂ≠∏‰∏≠ÁöÑ PET„ÄÇ

##### **Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**
2407.00531v1 by Hok-Shing Lau, Mark Huntly, Nathon Morgan, Adesua Iyenoma, Biao Zeng, Tim Bashford

Speech contains information that is clinically relevant to some diseases,
which has the potential to be used for health assessment. Recent work shows an
interest in applying deep learning algorithms, especially pretrained large
speech models to the applications of Automatic Speech Assessment. One question
that has not been explored is how these models output the results based on
their inputs. In this work, we train and compare two configurations of Audio
Spectrogram Transformer in the context of Voice Disorder Detection and apply
the attention rollout method to produce model relevance maps, the computed
relevance of the spectrogram regions when the model makes predictions. We use
these maps to analyse how models make predictions in different conditions and
to show that the spread of attention is reduced as a model is finetuned, and
the model attention is concentrated on specific phoneme regions.

ÊëòË¶ÅÔºöËØ≠Èü≥ÂåÖÂê´‰∏Ä‰∫õÁñæÁóÖÁöÑ‰∏¥Â∫äÁõ∏ÂÖ≥‰ø°ÊÅØÔºå
ËøôÊúâÊΩúÂäõÁî®‰∫éÂÅ•Â∫∑ËØÑ‰º∞„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÊúâÂÖ¥Ë∂£Â∫îÁî®Ê∑±Â∫¶Â≠¶‰π†ÁÆóÊ≥ïÔºåÂ∞§ÂÖ∂ÊòØÈ¢ÑËÆ≠ÁªÉÁöÑÂ§ßÂûã
ËØ≠Èü≥Ê®°ÂûãÁî®‰∫éËá™Âä®ËØ≠Èü≥ËØÑ‰º∞ÁöÑÂ∫îÁî®„ÄÇ‰∏Ä‰∏™Â∞öÊú™Êé¢Á¥¢ÁöÑÈóÆÈ¢òÊòØËøô‰∫õÊ®°ÂûãÂ¶Ç‰ΩïÊ†πÊçÆ
ÂÖ∂ËæìÂÖ•ËæìÂá∫ÁªìÊûú„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Âú®ËØ≠Èü≥ÈöúÁ¢çÊ£ÄÊµãÁöÑËÉåÊôØ‰∏ãËÆ≠ÁªÉÂíåÊØîËæÉ‰∫Ü‰∏§‰∏™Èü≥È¢ë
È¢ëË∞±ÂõæËΩ¨Êç¢Âô®ÁöÑÈÖçÁΩÆÔºåÂπ∂Â∫îÁî®Ê≥®ÊÑèÂäõÂ±ïÂºÄÊñπÊ≥ïÊù•ÁîüÊàêÊ®°ÂûãÁõ∏ÂÖ≥ÊÄßÂõæÔºåÂç≥Ê®°ÂûãÂÅöÂá∫È¢ÑÊµãÊó∂È¢ëË∞±ÂõæÂå∫ÂüüÁöÑËÆ°ÁÆóÁõ∏ÂÖ≥ÊÄß„ÄÇÊàë‰ª¨‰ΩøÁî®
Ëøô‰∫õÂõæÊù•ÂàÜÊûêÊ®°ÂûãÂ¶Ç‰ΩïÂú®‰∏çÂêåÊù°‰ª∂‰∏ãÂÅöÂá∫È¢ÑÊµãÔºåÂπ∂Ë°®ÊòéÈöèÁùÄÊ®°ÂûãÁöÑÂæÆË∞ÉÔºåÊ≥®ÊÑèÂäõÁöÑÂàÜÂ∏É‰ºöÂáèÂ∞ëÔºåÂπ∂‰∏î
Ê®°ÂûãÊ≥®ÊÑèÂäõÈõÜ‰∏≠Âú®ÁâπÂÆöÁöÑÈü≥Á¥†Âå∫Âüü„ÄÇ

##### **ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**
2407.00499v1 by Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Hengtao Shen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu

Uncertainty quantification (UQ) in natural language generation (NLG) tasks
remains an open challenge, exacerbated by the intricate nature of the recent
large language models (LLMs). This study investigates adapting conformal
prediction (CP), which can convert any heuristic measure of uncertainty into
rigorous theoretical guarantees by constructing prediction sets, for black-box
LLMs in open-ended NLG tasks. We propose a sampling-based uncertainty measure
leveraging self-consistency and develop a conformal uncertainty criterion by
integrating the uncertainty condition aligned with correctness into the design
of the CP algorithm. Experimental results indicate that our uncertainty measure
generally surpasses prior state-of-the-art methods. Furthermore, we calibrate
the prediction sets within the model's unfixed answer distribution and achieve
strict control over the correctness coverage rate across 6 LLMs on 4 free-form
NLG datasets, spanning general-purpose and medical domains, while the small
average set size further highlights the efficiency of our method in providing
trustworthy guarantees for practical open-ended NLG applications.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄÁîüÊàê (NLG) ‰ªªÂãô‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñ (UQ) ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈñãÊîæÊÄßÁöÑÊåëÊà∞ÔºåÊúÄËøëÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË§áÈõúÊÄßË≥™Âä†Âäá‰∫ÜÈÄô‰∏ÄÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÈÅ©ÊáâÂÖ±ÂΩ¢È†êÊ∏¨ (CP)ÔºåÂÆÉÂèØ‰ª•ÈÄöÈÅéÊßãÈÄ†È†êÊ∏¨ÈõÜÂ∞á‰ªª‰Ωï‰∏çÁ¢∫ÂÆöÊÄßÁöÑÂïüÁôºÂºèÊ∏¨ÈáèËΩâÊèõÁÇ∫Âö¥Ê†ºÁöÑÁêÜË´ñ‰øùË≠âÔºåÁî®ÊñºÈñãÊîæÂºè NLG ‰ªªÂãô‰∏≠ÁöÑÈªëÁõí LLM„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÊäΩÊ®£ÁöÑÊ∏¨Èáè‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊñπÊ≥ïÔºåÂà©Áî®‰∫ÜËá™Ê¥ΩÊÄßÔºå‰∏¶ÈÄöÈÅéÂ∞áËàáÊ≠£Á¢∫ÊÄß‰∏ÄËá¥ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊ¢ù‰ª∂Êï¥ÂêàÂà∞ CP ÊºîÁÆóÊ≥ïÁöÑË®≠Ë®à‰∏≠ÔºåÈñãÁôº‰∫Ü‰∏ÄÂÄãÂÖ±ÂΩ¢‰∏çÁ¢∫ÂÆöÊÄßÊ∫ñÂâá„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ∏¨Èáè‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÂÑ™ÊñºÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®Ê®°ÂûãÁöÑÊú™Âõ∫ÂÆöÁ≠îÊ°àÂàÜ‰ΩàÂÖßÊ†°Ê≠£‰∫ÜÈ†êÊ∏¨ÈõÜÔºå‰∏¶Âú® 4 ÂÄãËá™Áî±ÂΩ¢Âºè NLG Ë≥áÊñôÈõÜ‰∏äÂ∞ç 6 ÂÄã LLM ÁöÑÊ≠£Á¢∫ÊÄßË¶ÜËìãÁéáÈÄ≤Ë°å‰∫ÜÂö¥Ê†ºÊéßÂà∂ÔºåÊ∂µËìã‰∫ÜÈÄöÁî®ÂíåÈÜ´ÁôÇÈ†òÂüüÔºåËÄåËºÉÂ∞èÁöÑÂπ≥ÂùáÈõÜÂêàÂ§ßÂ∞èÈÄ≤‰∏ÄÊ≠•Á™ÅÂá∫‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÁÇ∫ÂØ¶Áî®ÁöÑÈñãÊîæÂºè NLG ÊáâÁî®Êèê‰æõÂèØ‰ø°‰øùË≠âÊñπÈù¢ÁöÑÊïàÁéá„ÄÇ

##### **MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**
2407.00474v1 by Luyuan Xie, Manqing Lin, ChenMing Xu, Tianyu Luan, Zhipeng Zeng, Wenjun Qian, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In the evolving application of medical artificial intelligence, federated
learning is notable for its ability to protect training data privacy. Federated
learning facilitates collaborative model development without the need to share
local data from healthcare institutions. Yet, the statistical and system
heterogeneity among these institutions poses substantial challenges, which
affects the effectiveness of federated learning and hampers the exchange of
information between clients. To address these issues, we introduce a novel
approach, MH-pFLGB, which employs a global bypass strategy to mitigate the
reliance on public datasets and navigate the complexities of non-IID data
distributions. Our method enhances traditional federated learning by
integrating a global bypass model, which would share the information among the
clients, but also serves as part of the network to enhance the performance on
each client. Additionally, MH-pFLGB provides a feature fusion module to better
combine the local and global features. We validate \model{}'s effectiveness and
adaptability through extensive testing on different medical tasks,
demonstrating superior performance compared to existing state-of-the-art
methods.

ÊëòË¶ÅÔºöÂú®ÈÜ´ÁôÇ‰∫∫Â∑•Êô∫ÊÖßÁöÑÊáâÁî®ÊºîÈÄ≤‰∏≠ÔºåËÅØÈÇ¶Â≠∏ÁøíÂõ†ÂÖ∂‰øùË≠∑Ë®ìÁ∑¥Ë≥áÊñôÈö±ÁßÅÁöÑËÉΩÂäõËÄåÂÇôÂèóÁüöÁõÆ„ÄÇËÅØÈÇ¶Â≠∏Áøí‰øÉÈÄ≤Âçî‰ΩúÊ®°ÂûãÈñãÁôºÔºåÁÑ°ÈúÄÂàÜ‰∫´ÈÜ´ÁôÇ‰øùÂÅ•Ê©üÊßãÁöÑÊú¨Âú∞Ë≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ©üÊßã‰πãÈñìÁöÑÁµ±Ë®àÂíåÁ≥ªÁµ±Áï∞Ë≥™ÊÄßÂ∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞ÔºåÂΩ±Èüø‰∫ÜËÅØÈÇ¶Â≠∏ÁøíÁöÑÊúâÊïàÊÄßÔºå‰∏¶ÈòªÁ§ô‰∫ÜÂÆ¢Êà∂Á´Ø‰πãÈñìÁöÑË≥áË®ä‰∫§Êèõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ï MH-pFLGBÔºåÂÆÉÊé°Áî®ÂÖ®ÁêÉÊóÅË∑ØÁ≠ñÁï•‰æÜÊ∏õËºïÂ∞çÂÖ¨ÂÖ±Ë≥áÊñôÈõÜÁöÑ‰æùË≥¥Ôºå‰∏¶ÊáâÂ∞çÈùû IID Ë≥áÊñôÂàÜ‰ΩàÁöÑË§áÈõúÊÄß„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÊï¥Âêà‰∏ÄÂÄãÂÖ®ÁêÉÊóÅË∑ØÊ®°Âûã‰æÜÂ¢ûÂº∑ÂÇ≥Áµ±ÁöÑËÅØÈÇ¶Â≠∏ÁøíÔºåË©≤Ê®°ÂûãÂ∞áÂú®ÂÆ¢Êà∂Á´Ø‰πãÈñìÂÖ±‰∫´Ë≥áË®äÔºå‰ΩÜ‰πü‰ΩúÁÇ∫Á∂≤Ë∑ØÁöÑ‰∏ÄÈÉ®ÂàÜ‰æÜÂ¢ûÂº∑ÊØèÂÄãÂÆ¢Êà∂Á´ØÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåMH-pFLGB Êèê‰æõ‰∫Ü‰∏ÄÂÄãÁâπÂæµËûçÂêàÊ®°ÁµÑÔºå‰ª•Êõ¥Â•ΩÂú∞ÁµêÂêàÊú¨Âú∞ÂíåÂÖ®ÁêÉÁâπÂæµ„ÄÇÊàëÂÄëÈÄèÈÅéÂú®‰∏çÂêåÁöÑÈÜ´ÁôÇ‰ªªÂãô‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÊ∏¨Ë©¶‰æÜÈ©óË≠âÊ®°ÂûãÁöÑÊúâÊïàÊÄßÂíåÈÅ©ÊáâÊÄßÔºåË≠âÊòéÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇ

##### **pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**
2407.00462v1 by Luyuan Xie, Manqing Lin, Siyuan Liu, ChenMing Xu, Tianyu Luan, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In medical image segmentation, personalized cross-silo federated learning
(FL) is becoming popular for utilizing varied data across healthcare settings
to overcome data scarcity and privacy concerns. However, existing methods often
suffer from client drift, leading to inconsistent performance and delayed
training. We propose a new framework, Personalized Federated Learning via
Feature Enhancement (pFLFE), designed to mitigate these challenges. pFLFE
consists of two main stages: feature enhancement and supervised learning. The
first stage improves differentiation between foreground and background
features, and the second uses these enhanced features for learning from
segmentation masks. We also design an alternative training approach that
requires fewer communication rounds without compromising segmentation quality,
even with limited communication resources. Through experiments on three medical
segmentation tasks, we demonstrate that pFLFE outperforms the state-of-the-art
methods.

ÊëòË¶ÅÔºöÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤‰∏≠ÔºåÂÄã‰∫∫ÂåñË∑®Ë≥áÊñôÂ≠§Â≥∂ÁöÑËÅØÈÇ¶Â≠∏Áøí (FL) ÈÄêÊº∏ÁõõË°åÔºåÁî®ÊñºÂà©Áî®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑÂêÑÁ®ÆË≥áÊñô‰æÜÂÖãÊúçË≥áÊñôÁ®ÄÂ∞ëÂíåÈö±ÁßÅÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÁ∂ìÂ∏∏ÊúÉÂá∫ÁèæÂÆ¢Êà∂Á´ØÂÅèÁßªÔºåÂ∞éËá¥ÊïàËÉΩ‰∏ç‰∏ÄËá¥‰∏îË®ìÁ∑¥Âª∂ÈÅ≤„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊû∂ÊßãÔºåÈÄèÈÅéÂäüËÉΩÂ¢ûÂº∑ (pFLFE) ÈÄ≤Ë°åÂÄã‰∫∫ÂåñËÅØÈÇ¶Â≠∏ÁøíÔºåÊó®Âú®Ê∏õËºïÈÄô‰∫õÊåëÊà∞„ÄÇpFLFE ÂåÖÂê´ÂÖ©ÂÄã‰∏ªË¶ÅÈöéÊÆµÔºöÂäüËÉΩÂ¢ûÂº∑ÂíåÁõ£Áù£ÂºèÂ≠∏Áøí„ÄÇÁ¨¨‰∏ÄÂÄãÈöéÊÆµÊîπÂñÑÂâçÊôØÂíåËÉåÊôØÂäüËÉΩ‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåËÄåÁ¨¨‰∫åÂÄãÈöéÊÆµ‰ΩøÁî®ÈÄô‰∫õÂ¢ûÂº∑ÁöÑÂäüËÉΩÂæûÂàÜÂâ≤ÈÅÆÁΩ©‰∏≠Â≠∏Áøí„ÄÇÊàëÂÄëÈÇÑË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂÇôÁî®Ë®ìÁ∑¥ÊñπÊ≥ïÔºåÂç≥‰ΩøÂú®ÈÄöË®äË≥áÊ∫êÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πü‰∏çÂΩ±ÈüøÂàÜÂâ≤ÂìÅË≥™ÔºåÂè™ÈúÄË¶ÅËºÉÂ∞ëÁöÑÈÄöË®äÂõûÂêà„ÄÇÈÄèÈÅéÂú®‰∏âÂÄãÈÜ´Â≠∏ÂàÜÂâ≤‰ªªÂãô‰∏≠ÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé pFLFE ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**
2407.00402v1 by Omer Goldman, Alon Jacovi, Aviv Slobodkin, Aviya Maimon, Ido Dagan, Reut Tsarfaty

Improvements in language models' capabilities have pushed their applications
towards longer contexts, making long-context evaluation and development an
active research area. However, many disparate use-cases are grouped together
under the umbrella term of "long-context", defined simply by the total length
of the model's input, including - for example - Needle-in-a-Haystack tasks,
book summarization, and information aggregation. Given their varied difficulty,
in this position paper we argue that conflating different tasks by their
context length is unproductive. As a community, we require a more precise
vocabulary to understand what makes long-context tasks similar or different. We
propose to unpack the taxonomy of long-context based on the properties that
make them more difficult with longer contexts. We propose two orthogonal axes
of difficulty: (I) Diffusion: How hard is it to find the necessary information
in the context? (II) Scope: How much necessary information is there to find? We
survey the literature on long-context, provide justification for this taxonomy
as an informative descriptor, and situate the literature with respect to it. We
conclude that the most difficult and interesting settings, whose necessary
information is very long and highly diffused within the input, is severely
under-explored. By using a descriptive vocabulary and discussing the relevant
properties of difficulty in long-context, we can implement more informed
research in this area. We call for a careful design of tasks and benchmarks
with distinctly long context, taking into account the characteristics that make
it qualitatively different from shorter context.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãËÉΩÂäõÁöÑÊèêÂçáÂ∑≤Â∞áÂÖ∂ÊáâÁî®Êé®ÂêëÊõ¥Èï∑ÁöÑËÑàÁµ°Ôºå‰ΩøÂæóÈï∑ËÑàÁµ°Ë©ï‰º∞ÂíåÈñãÁôºÊàêÁÇ∫‰∏ÄÂÄãÊ¥ªË∫çÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÁÑ∂ËÄåÔºåË®±Â§ö‰∏çÂêåÁöÑÁî®‰æãË¢´Ê≠∏È°ûÂú®„ÄåÈï∑ËÑàÁµ°„ÄçÈÄôÂÄãÁ∏ΩÁ®±‰πã‰∏ãÔºåÂÉÖÁî±Ê®°ÂûãËº∏ÂÖ•ÁöÑÁ∏ΩÈï∑Â∫¶ÂÆöÁæ©ÔºåÂåÖÊã¨‰æãÂ¶ÇÂ§ßÊµ∑ÊíàÈáù‰ªªÂãô„ÄÅÊõ∏Á±çÊëòË¶ÅÂíåË≥áË®äÂΩôÊï¥„ÄÇÈëëÊñºÂÖ∂Èõ£ÊòìÂ∫¶‰∏çÂêåÔºåÊàëÂÄëÂú®ÈÄôÁØáÁ´ãÂ†¥Êñá‰ª∂‰∏≠‰∏ªÂºµÔºåÂ∞á‰∏çÂêåÁöÑ‰ªªÂãôÊ∑∑ÁÇ∫‰∏ÄË´áÊòØ‰∏çÂÖ∑ÁîüÁî¢ÂäõÁöÑ„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãÁ§æÁæ§ÔºåÊàëÂÄëÈúÄË¶ÅÊõ¥Á≤æÁ¢∫ÁöÑË©ûÂΩô‰æÜÁêÜËß£ÊòØ‰ªÄÈ∫ºËÆìÈï∑ËÑàÁµ°‰ªªÂãôÈ°û‰ººÊàñ‰∏çÂêå„ÄÇÊàëÂÄëÊèêË≠∞Ê†πÊìö‰ΩøÂÆÉÂÄëÂú®ËºÉÈï∑ËÑàÁµ°‰∏≠Êõ¥Âõ∞Èõ£ÁöÑÂ±¨ÊÄß‰æÜËß£ÊßãÈï∑ËÑàÁµ°ÁöÑÂàÜÈ°û„ÄÇÊàëÂÄëÊèêÂá∫ÂÖ©ÂÄãÊ≠£‰∫§ÁöÑÈõ£Â∫¶Ëª∏Ôºö(I) Êì¥Êï£ÔºöÂú®ËÑàÁµ°‰∏≠ÊâæÂà∞ÂøÖË¶ÅË≥áË®äÊúâÂ§öÂõ∞Èõ£Ôºü(II) ÁØÑÂúçÔºöÊúâÂ§öÂ∞ëÂøÖË¶ÅÁöÑË≥áË®äÈúÄË¶ÅÊâæÂà∞ÔºüÊàëÂÄëË™øÊü•‰∫ÜÈóúÊñºÈï∑ËÑàÁµ°ÁöÑÊñáÁçªÔºåÁÇ∫Ê≠§ÂàÜÈ°ûÊèê‰æõ‰ΩúÁÇ∫ÊúâÊÑèÁæ©ÊèèËø∞Á¨¶ÁöÑ‰æùÊìöÔºå‰∏¶Ê†πÊìöÂÆÉ‰æÜÂÆö‰ΩçÊñáÁçª„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÊúÄÂõ∞Èõ£‰∏îÊúÄÊúâË∂£ÁöÑË®≠ÂÆöÔºåÂÖ∂ÂøÖË¶ÅË≥áË®äÈùûÂ∏∏Èï∑‰∏îÈ´òÂ∫¶ÂàÜÊï£Âú®Ëº∏ÂÖ•‰∏≠ÔºåÂö¥ÈáçÂú∞Êú™Ë¢´Êé¢Á¥¢„ÄÇÈÄèÈÅé‰ΩøÁî®ÊèèËø∞ÊÄßË©ûÂΩôÂíåË®éË´ñÈï∑ËÑàÁµ°‰∏≠Âõ∞Èõ£ÁöÑÁõ∏ÈóúÂ±¨ÊÄßÔºåÊàëÂÄëÂèØ‰ª•Âú®ÈÄôÂÄãÈ†òÂüüÂØ¶ÊñΩÊõ¥ÊòéÊô∫ÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÂëºÁ±≤‰ªîÁ¥∞Ë®≠Ë®àÂÖ∑ÊúâÊòéÈ°ØÈï∑ËÑàÁµ°ÁöÑ‰ªªÂãôÂíåÂü∫Ê∫ñÔºåËÄÉÈáè‰ΩøÂÖ∂Âú®Ë≥™‰∏ä‰∏çÂêåÊñºËºÉÁü≠ËÑàÁµ°ÁöÑÁâπÊÄß„ÄÇ

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÁæéÂúãË¶ãË≠â‰∫ÜÈõªÂ≠êÁÖôÊàñÈõªÂ≠êÈ¶ôËè∏‰ΩøÁî®ÁéáÂ§ßÂπÖÊøÄÂ¢ûÔºåÂ∞éËá¥ÈõªÂ≠êÁÖôÂíåÈõªÂ≠êÁÖô‰ΩøÁî®Áõ∏ÈóúËÇ∫ÊêçÂÇ∑ (EVALI) ÁóÖ‰æãÈ°ØËëóÂ¢ûÂä†ÔºåÂú® 2019 Âπ¥ EVALI ÁàÜÁôºÊúüÈñìÈÄ†Êàê‰ΩèÈô¢ÂíåÊ≠ª‰∫°ÔºåÂá∏È°Ø‰∫ÜÁêÜËß£ÈõªÂ≠êÁÖôË°åÁÇ∫ÂíåÂà∂ÂÆöÊúâÊïàÊàíËè∏Á≠ñÁï•ÁöÑËø´ÂàáÊÄß„ÄÇÁî±ÊñºÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÁöÑÊôÆÂèäÔºåÂÖ®ÁêÉË∂ÖÈÅé 47 ÂÑÑ‰ΩøÁî®ËÄÖ‰ΩøÁî®ÂÆÉÂÄëÈÄ≤Ë°åÈÄ£Áµê„ÄÅÊ∫ùÈÄö„ÄÅÊñ∞ËÅûÂíåÂ®õÊ®ÇÔºåÂÖ∂‰∏≠ÂæàÂ§ß‰∏ÄÈÉ®ÂàÜËàáÂÅ•Â∫∑Áõ∏ÈóúÔºåÂõ†Ê≠§Â∞áÁ§æÁæ§Â™íÈ´îË≥áÊñôÂª∫Á´ãÁÇ∫ÂÖ¨ÂÖ±Ë°õÁîüÁ†îÁ©∂‰∏≠ÁÑ°ÂÉπÁöÑÊúâÊ©üË≥áÊñôË≥áÊ∫ê„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû Reddit ‰∏ä‰∏ÄÂÄãÈõªÂ≠êÁÖôÂ≠êÁ§æÁæ§‰∏≠ÊèêÂèñ‰∏ÄÂÄãÁØÑ‰æãË≥áÊñôÈõÜÔºå‰ª•ÂàÜÊûê‰ΩøÁî®ËÄÖÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñ„ÄÇÂà©Áî® OpenAI ÊúÄÊñ∞ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã GPT-4 ÈÄ≤Ë°åÂè•Â≠êÂ±§Á¥öÁöÑÊàíÈõªÂ≠êÁÖôÊÑèÂúñÂÅµÊ∏¨ÔºåÊú¨Á†îÁ©∂ÊØîËºÉ‰∫ÜÊ≠§Ê®°ÂûãÁöÑÁµêÊûúËàáÂ§ñË°å‰∫∫ÂíåËá®Â∫äÂ∞àÂÆ∂Ë®ªËß£„ÄÇ‰ΩøÁî®‰∏çÂêåÁöÑÊèêÁ§∫Á≠ñÁï•Ôºå‰æãÂ¶ÇÈõ∂Ê¨°Â≠∏Áøí„ÄÅ‰∏ÄÊ¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÂíåÊÄùËÄÉÈèàÊèêÁ§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü 8 ÂÄãÊèêÁ§∫ÔºåË©≥Á¥∞Á®ãÂ∫¶‰∏çÂêåÔºåÂêë GPT-4 Ëß£Èáã‰ªªÂãôÔºå‰∏¶Ë©ï‰º∞ÈÄô‰∫õÁ≠ñÁï•ÂΩºÊ≠§‰πãÈñìÁöÑÊïàËÉΩ„ÄÇÈÄô‰∫õÂàùÊ≠•ÁôºÁèæÂº∑Ë™ø‰∫Ü GPT-4 Âú®Á§æÁæ§Â™íÈ´îË≥áÊñôÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõÔºåÁâπÂà•ÊòØÂú®Ë≠òÂà•‰∫∫È°ûÂÅµÊ∏¨ÂèØËÉΩÁÑ°Ê≥ïÂØüË¶∫ÁöÑ‰ΩøÁî®ËÄÖÂæÆÂ¶ôÊÑèÂúñÊñπÈù¢„ÄÇ

##### **Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**
2407.00147v1 by Dat Hong, Philip M. Polgreen, Alberto Maria Segre

Hospitalizations that follow closely on the heels of one or more emergency
department visits are often symptoms of missed opportunities to form a proper
diagnosis. These diagnostic errors imply a failure to recognize the need for
hospitalization and deliver appropriate care, and thus also bear important
connotations for patient safety. In this paper, we show how data mining
techniques can be applied to a large existing hospitalization data set to learn
useful models that predict these upcoming hospitalizations with high accuracy.
Specifically, we use an ensemble of logistics regression, na\"ive Bayes and
association rule classifiers to successfully predict hospitalization within 3,
7 and 14 days of an emergency department discharge. Aside from high accuracy,
one of the advantages of the techniques proposed here is that the resulting
classifier is easily inspected and interpreted by humans so that the learned
rules can be readily operationalized. These rules can then be easily
distributed and applied directly by physicians in emergency department settings
to predict the risk of early admission prior to discharging their emergency
department patients.

ÊëòË¶ÅÔºöÁ∑äÊé•Âú®‰∏ÄÊ¨°ÊàñÂ§öÊ¨°ÊÄ•Ë®∫ÁßëÂ∞±Ë®∫Âæå‰ΩèÈô¢ÔºåÈÄöÂ∏∏ÊòØÈåØÂ§±ÈÅ©Áï∂Ë®∫Êñ∑Ê©üÊúÉÁöÑÂæµÂÖÜ„ÄÇÈÄô‰∫õË®∫Êñ∑ÈåØË™§ÊÑèÂë≥ËëóÊú™ËÉΩÂØüË¶∫‰ΩèÈô¢ÈúÄÊ±Ç‰∏¶Êèê‰æõÈÅ©Áï∂ÁÖßË≠∑ÔºåÂõ†Ê≠§‰πüÂ∞çÁóÖÊÇ£ÂÆâÂÖ®ÈÄ†ÊàêÈáçÂ§ßÂΩ±Èüø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞áÂ±ïÁ§∫Ë≥áÊñôÊé¢ÂãòÊäÄË°ìÂ¶Ç‰ΩïÊáâÁî®ÊñºÁèæÊúâÁöÑÂ§ßÂûã‰ΩèÈô¢Ë≥áÊñôÈõÜÔºå‰ª•Â≠∏ÁøíÈ†êÊ∏¨ÈÄô‰∫õÂç≥Â∞áÂà∞‰æÜÁöÑ‰ΩèÈô¢‰∫ã‰ª∂‰∏îÊ∫ñÁ¢∫Â∫¶Ê•µÈ´òÁöÑÊúâÁî®Ê®°Âûã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄë‰ΩøÁî®ÈÇèËºØËø¥Ê≠∏„ÄÅÊ®∏Á¥†Ë≤ùÊ∞èÂíåÈóúËÅØË¶èÂâáÂàÜÈ°ûÂô®ÁöÑÁµÑÂêàÔºåÊàêÂäüÈ†êÊ∏¨ÊÄ•Ë®∫ÁßëÂá∫Èô¢Âæå 3„ÄÅ7 Âíå 14 Â§©ÂÖßÁöÑ‰ΩèÈô¢„ÄÇÈô§‰∫ÜÈ´òÊ∫ñÁ¢∫Â∫¶‰πãÂ§ñÔºåÊú¨ÊñáÊèêÂá∫ÁöÑÊäÄË°ìÂÑ™Âã¢‰πã‰∏ÄÊòØÔºåÁî¢ÁîüÁöÑÂàÜÈ°ûÂô®ÂÆπÊòìË¢´‰∫∫È°ûÊ™¢Êü•ÂíåËß£ËÆÄÔºåÂõ†Ê≠§ÂèØ‰ª•ËºïÈ¨ÜÂú∞Â∞áÂ≠∏ÁøíÂà∞ÁöÑË¶èÂâá‰ªòË´∏ÂØ¶Ë°å„ÄÇÁÑ∂ÂæåÔºåÈÄô‰∫õË¶èÂâáÂèØ‰ª•ËºïÊòìÂú∞Ë¢´ÂàÜÁôºÔºå‰∏¶Áî±ÊÄ•Ë®∫ÁßëÁöÑÈÜ´Â∏´Áõ¥Êé•ÊáâÁî®Ôºå‰ª•Âú®Âá∫Èô¢ÂâçÈ†êÊ∏¨ÊÄ•Ë®∫ÁßëÁóÖÊÇ£Êó©ÊúüÂÖ•Èô¢ÁöÑÈ¢®Èö™„ÄÇ

##### **BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration**
2406.20041v3 by Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski

Autonomous agents driven by Large Language Models (LLMs) offer enormous
potential for automation. Early proof of this technology can be found in
various demonstrations of agents solving complex tasks, interacting with
external systems to augment their knowledge, and triggering actions. In
particular, workflows involving multiple agents solving complex tasks in a
collaborative fashion exemplify their capacity to operate in less strict and
less well-defined environments. Thus, a multi-agent approach has great
potential for serving as a backbone in many industrial applications, ranging
from complex knowledge retrieval systems to next generation robotic process
automation. Given the reasoning abilities within the current generation of
LLMs, complex processes require a multi-step approach that includes a plan of
well-defined and modular tasks. Depending on the level of complexity, these
tasks can be executed either by a single agent or a group of agents. In this
work, we focus on designing a flexible agent engineering framework with careful
attention to planning and execution, capable of handling complex use case
applications across various domains. The proposed framework provides
reliability in industrial applications and presents techniques to ensure a
scalable, flexible, and collaborative workflow for multiple autonomous agents
working together towards solving tasks.

ÊëòË¶ÅÔºöÁî±Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È©ÖÂãïÁöÑËá™‰∏ª‰ª£ÁêÜ‰∫∫Êèê‰æõ‰∫ÜÂ∑®Â§ßÁöÑËá™ÂãïÂåñÊΩõÂäõ„ÄÇÊ≠§ÊäÄË°ìÁöÑÊó©ÊúüË≠âÊòéÂèØ‰ª•Âú®‰ª£ÁêÜ‰∫∫Ëß£Ê±∫Ë§áÈõú‰ªªÂãô„ÄÅËàáÂ§ñÈÉ®Á≥ªÁµ±‰∫íÂãï‰ª•Êì¥ÂÖÖÂÖ∂Áü•Ë≠òÔºå‰ª•ÂèäËß∏ÁôºÂãï‰ΩúÁöÑÂêÑÁ®ÆÊºîÁ§∫‰∏≠ÊâæÂà∞„ÄÇÁâπÂà•ÊòØÔºåÊ∂âÂèäÂ§öÂÄã‰ª£ÁêÜ‰∫∫‰ª•Âçî‰ΩúÊñπÂºèËß£Ê±∫Ë§áÈõú‰ªªÂãôÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåË™™Êòé‰∫ÜÂÆÉÂÄëÂú®ËºÉ‰∏çÂö¥Ê†ºÂíåÂÆöÁæ©ËºÉ‰∏çÂÆåÂñÑÁöÑÁí∞Â¢É‰∏≠ÈÅã‰ΩúÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÂ§ö‰ª£ÁêÜ‰∫∫ÊñπÊ≥ïÊ•µÊúâÂèØËÉΩÊàêÁÇ∫Ë®±Â§öÁî¢Ê•≠ÊáâÁî®‰∏≠ÁöÑÈ™®ÂππÔºåÁØÑÂúçÂæûË§áÈõúÁöÑÁü•Ë≠òÊ™¢Á¥¢Á≥ªÁµ±Âà∞‰∏ã‰∏Ä‰ª£Ê©üÂô®‰∫∫ÊµÅÁ®ãËá™ÂãïÂåñ„ÄÇÈëëÊñºÁï∂Ââç‰∏Ä‰ª£ LLM ‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõÔºåË§áÈõúÁöÑÊµÅÁ®ãÈúÄË¶ÅÂ§öÊ≠•È©üÁöÑÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÊòéÁ¢∫‰∏îÊ®°ÁµÑÂåñÁöÑ‰ªªÂãôË®àÁï´„ÄÇÊ†πÊìöË§áÈõúÁ®ãÂ∫¶ÔºåÈÄô‰∫õ‰ªªÂãôÂèØ‰ª•Áî±ÂñÆ‰∏Ä‰ª£ÁêÜ‰∫∫Êàñ‰∏ÄÁæ§‰ª£ÁêÜ‰∫∫Âü∑Ë°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºË®≠Ë®à‰∏ÄÂÄãÈùàÊ¥ªÁöÑ‰ª£ÁêÜ‰∫∫Â∑•Á®ãÊû∂ÊßãÔºå‰ªîÁ¥∞Ê≥®ÊÑèË®àÁï´ÂíåÂü∑Ë°åÔºåËÉΩÂ§†ËôïÁêÜË∑®Ë∂äÂêÑÁ®ÆÈ†òÂüüÁöÑË§áÈõúÁî®‰æãÊáâÁî®„ÄÇÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÂú®Áî¢Ê•≠ÊáâÁî®‰∏≠Êèê‰æõ‰∫ÜÂèØÈù†ÊÄßÔºå‰∏¶ÊèêÂá∫‰∫ÜÊäÄË°ìÔºå‰ª•Á¢∫‰øùÂ§öÂÄãËá™‰∏ª‰ª£ÁêÜ‰∫∫ÂÖ±ÂêåÂä™ÂäõËß£Ê±∫‰ªªÂãôÁöÑÂèØÊì¥ÂÖÖÊÄß„ÄÅÈùàÊ¥ªÊÄßÔºå‰ª•ÂèäÂçî‰ΩúÂ∑•‰ΩúÊµÅÁ®ã„ÄÇ

##### **Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work**
2407.00142v1 by Christopher Irwin, Flavio Mignone, Stefania Montani, Luigi Portinale

The gut microbiome, crucial for human health, presents challenges in
analyzing its complex metaomic data due to high dimensionality and sparsity.
Traditional methods struggle to capture its intricate relationships. We
investigate graph neural networks (GNNs) for this task, aiming to derive
meaningful representations of individual gut microbiomes. Unlike methods
relying solely on taxa abundance, we directly leverage phylogenetic
relationships, in order to obtain a generalized encoder for taxa networks. The
representation learnt from the encoder are then used to train a model for
phenotype prediction such as Inflammatory Bowel Disease (IBD).

ÊëòË¶ÅÔºöËÖ∏ÈÅìÂæÆÁîüÁâ©ÁµÑÂ∞çÊñº‰∫∫È°ûÂÅ•Â∫∑Ëá≥ÈóúÈáçË¶ÅÔºåÁî±ÊñºÂÖ∂Ë§áÈõúÁöÑÂÆèÁµÑÊï∏ÊìöÂÖ∑ÊúâÈ´òÁ∂≠Â∫¶ÂíåÁ®ÄÁñèÊÄßÁöÑÁâπÈªûÔºåÂõ†Ê≠§Âú®ÂàÜÊûêÊôÇÊúÉÈù¢Ëá®ÊåëÊà∞„ÄÇÂÇ≥Áµ±ÁöÑÊñπÊ≥ïÈõ£‰ª•ÊçïÊçâÂÖ∂Ë§áÈõúÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫ÜÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN)ÔºåÊó®Âú®Êé®Â∞éÂá∫ÂÄãÂà•ËÖ∏ÈÅìÂæÆÁîüÁâ©ÁµÑÁöÑÊÑèÁæ©Ë°®Á§∫„ÄÇËàáÂÉÖ‰æùË≥¥ÂàÜÈ°ûÁæ§Ë±êÂ∫¶ÁöÑÂÖ∂‰ªñÊñπÊ≥ï‰∏çÂêåÔºåÊàëÂÄëÁõ¥Êé•Âà©Áî®Á≥ªÁµ±ÁôºÁîüÈóú‰øÇÔºå‰ª•Áç≤ÂæóÂàÜÈ°ûÁæ§Á∂≤Ë∑ØÁöÑÂª£Áæ©Á∑®Á¢ºÂô®„ÄÇÁÑ∂ÂæåÔºåÂæûÁ∑®Á¢ºÂô®Â≠∏ÁøíÂà∞ÁöÑË°®Á§∫Áî®ÊñºË®ìÁ∑¥Ë°®ÂûãÈ†êÊ∏¨Ê®°ÂûãÔºå‰æãÂ¶ÇÁÇéÁóáÊÄßËÖ∏ÁóÖ (IBD)„ÄÇ

##### **Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**
2406.19756v1 by Haojun Jiang, Meng Li, Zhenguo Sun, Ning Jia, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang

The complex structure of the heart leads to significant challenges in
echocardiography, especially in acquisition cardiac ultrasound images.
Successful echocardiography requires a thorough understanding of the structures
on the two-dimensional plane and the spatial relationships between planes in
three-dimensional space. In this paper, we innovatively propose a large-scale
self-supervised pre-training method to acquire a cardiac structure-aware world
model. The core innovation lies in constructing a self-supervised task that
requires structural inference by predicting masked structures on a 2D plane and
imagining another plane based on pose transformation in 3D space. To support
large-scale pre-training, we collected over 1.36 million echocardiograms from
ten standard views, along with their 3D spatial poses. In the downstream probe
guidance task, we demonstrate that our pre-trained model consistently reduces
guidance errors across the ten most common standard views on the test set with
0.29 million samples from 74 routine clinical scans, indicating that
structure-aware pre-training benefits the scanning.

ÊëòË¶ÅÔºöÂøÉËÑèÂ§çÊùÇÁöÑÁªìÊûÑÂØºËá¥Ë∂ÖÈü≥Ê≥¢ÂøÉÂä®ÂõæÊ£ÄÊü•Èù¢‰∏¥ÈáçÂ§ßÊåëÊàòÔºåÁâπÂà´ÊòØÂú®Ëé∑ÂèñÂøÉËÑèË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÊó∂„ÄÇÊàêÂäüÁöÑË∂ÖÈü≥Ê≥¢ÂøÉÂä®ÂõæÊ£ÄÊü•ÈúÄË¶ÅÈÄèÂΩª‰∫ÜËß£‰∫åÁª¥Âπ≥Èù¢‰∏äÁöÑÁªìÊûÑ‰ª•Âèä‰∏âÁª¥Á©∫Èó¥‰∏≠ÂêÑÂπ≥Èù¢‰πãÈó¥ÁöÑÁ©∫Èó¥ÂÖ≥Á≥ª„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂàõÊñ∞ÊÄßÂú∞ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ§ßËßÑÊ®°Ëá™ÊàëÁõëÁù£È¢ÑËÆ≠ÁªÉÊñπÊ≥ïÔºå‰ª•Ëé∑ÂèñÂøÉËÑèÁªìÊûÑÊÑüÁü•ÁöÑ‰∏ñÁïåÊ®°Âûã„ÄÇÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÊûÑÂª∫‰∏ÄÈ°πËá™ÊàëÁõëÁù£‰ªªÂä°ÔºåËØ•‰ªªÂä°ÈúÄË¶ÅÈÄöËøáÈ¢ÑÊµã 2D Âπ≥Èù¢‰∏äÁöÑÈÅÆÁΩ©ÁªìÊûÑÂπ∂Âú® 3D Á©∫Èó¥‰∏≠Âü∫‰∫éÂßøÊÄÅËΩ¨Êç¢ÊÉ≥Ë±°Âè¶‰∏Ä‰∏™Âπ≥Èù¢Êù•ËøõË°åÁªìÊûÑÊé®ÁêÜ„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÂ§ßËßÑÊ®°È¢ÑËÆ≠ÁªÉÔºåÊàë‰ª¨‰ªéÂçÅ‰∏™Ê†áÂáÜËßÜÂõæ‰∏≠Êî∂ÈõÜ‰∫ÜË∂ÖËøá 136 ‰∏á‰∏™Ë∂ÖÈü≥Ê≥¢ÂøÉÂä®ÂõæÔºå‰ª•ÂèäÂÆÉ‰ª¨ÁöÑ 3D Á©∫Èó¥ÂßøÊÄÅ„ÄÇÂú®‰∏ãÊ∏∏Êé¢Â§¥ÂºïÂØº‰ªªÂä°‰∏≠ÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂú®ÊµãËØïÈõÜ‰∏äÊåÅÁª≠ÂáèÂ∞ë‰∫ÜÂçÅ‰∏™ÊúÄÂ∏∏ËßÅÊ†áÂáÜËßÜÂõæÁöÑÂºïÂØºËØØÂ∑ÆÔºåÂÖ∂‰∏≠ÂåÖÂê´Êù•Ëá™ 74 ‰∏™Â∏∏ËßÑ‰∏¥Â∫äÊâ´ÊèèÁöÑ 0.29 Áôæ‰∏á‰∏™Ê†∑Êú¨ÔºåË°®ÊòéÊÑüÁü•ÁªìÊûÑÁöÑÈ¢ÑËÆ≠ÁªÉÊúâÂà©‰∫éÊâ´Êèè„ÄÇ

##### **Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction**
2407.00129v1 by Akash Awasthi, Ngan Le, Zhigang Deng, Rishi Agrawal, Carol C. Wu, Hien Van Nguyen

Predicting human gaze behavior within computer vision is integral for
developing interactive systems that can anticipate user attention, address
fundamental questions in cognitive science, and hold implications for fields
like human-computer interaction (HCI) and augmented/virtual reality (AR/VR)
systems. Despite methodologies introduced for modeling human eye gaze behavior,
applying these models to medical imaging for scanpath prediction remains
unexplored. Our proposed system aims to predict eye gaze sequences from
radiology reports and CXR images, potentially streamlining data collection and
enhancing AI systems using larger datasets. However, predicting human scanpaths
on medical images presents unique challenges due to the diverse nature of
abnormal regions. Our model predicts fixation coordinates and durations
critical for medical scanpath prediction, outperforming existing models in the
computer vision community. Utilizing a two-stage training process and large
publicly available datasets, our approach generates static heatmaps and eye
gaze videos aligned with radiology reports, facilitating comprehensive
analysis. We validate our approach by comparing its performance with
state-of-the-art methods and assessing its generalizability among different
radiologists, introducing novel strategies to model radiologists' search
patterns during CXR image diagnosis. Based on the radiologist's evaluation,
MedGaze can generate human-like gaze sequences with a high focus on relevant
regions over the CXR images. It sometimes also outperforms humans in terms of
redundancy and randomness in the scanpaths.

ÊëòË¶ÅÔºöÈ†êÊ∏¨ÈõªËÖ¶Ë¶ñË¶∫‰∏≠ÁöÑ‰∫∫È°ûË¶ñÁ∑öË°åÁÇ∫Â∞çÊñºÈñãÁôº‰∫íÂãïÂºèÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶ÅÔºåÈÄô‰∫õÁ≥ªÁµ±ÂèØ‰ª•È†êÊ∏¨‰ΩøÁî®ËÄÖÊ≥®ÊÑèÂäõ„ÄÅËß£Ê±∫Ë™çÁü•ÁßëÂ≠∏‰∏≠ÁöÑÂü∫Êú¨ÂïèÈ°åÔºå‰∏¶Â∞ç‰∫∫Ê©ü‰∫íÂãï (HCI) ÂíåÊì¥Â¢û/ËôõÊì¨ÂØ¶Â¢É (AR/VR) Á≥ªÁµ±Á≠âÈ†òÂüüÁî¢ÁîüÂΩ±Èüø„ÄÇÂÑòÁÆ°ÂºïÂÖ•‰∫ÜÁî®ÊñºÂª∫Ê®°‰∫∫È°ûË¶ñÁ∑öË°åÁÇ∫ÁöÑÊñπÊ≥ïÔºå‰ΩÜÂ∞áÈÄô‰∫õÊ®°ÂûãÊáâÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉè‰ª•ÈÄ≤Ë°åÊéÉÊèèË∑ØÂæëÈ†êÊ∏¨‰ªçÊú™ÂæóÂà∞Êé¢Á¥¢„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÁ≥ªÁµ±Êó®Âú®Ê†πÊìöÊîæÂ∞ÑÁßëÂ†±ÂëäÂíå CXR ÂΩ±ÂÉèÈ†êÊ∏¨Ë¶ñÁ∑öÂ∫èÂàóÔºåÈÄôÊúâÂèØËÉΩÁ∞°ÂåñË≥áÊñôÊî∂ÈõÜ‰∏¶‰ΩøÁî®Êõ¥Â§ßÁöÑË≥áÊñôÈõÜ‰æÜÂ¢ûÂº∑ AI Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁï∞Â∏∏ÂçÄÂüüÁöÑÂ§öÊ®£ÊÄßÔºåÈ†êÊ∏¨ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏äÁöÑ‰∫∫È°ûÊéÉÊèèË∑ØÂæëÊèêÂá∫‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÈ†êÊ∏¨‰∫ÜÂ∞çÈÜ´Â≠∏ÊéÉÊèèË∑ØÂæëÈ†êÊ∏¨Ëá≥ÈóúÈáçË¶ÅÁöÑÊ≥®Ë¶ñÂùêÊ®ôÂíåÊåÅÁ∫åÊôÇÈñìÔºåË°®ÁèæÂÑ™ÊñºÈõªËÖ¶Ë¶ñË¶∫Á§æÁæ§‰∏≠ÁèæÊúâÁöÑÊ®°Âûã„ÄÇÂà©Áî®ÂÖ©ÈöéÊÆµË®ìÁ∑¥ÊµÅÁ®ãÂíåÂ§ßÈáèÁöÑÂÖ¨ÈñãÂèØÁî®Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁî¢Áîü‰∫ÜËàáÊîæÂ∞ÑÁßëÂ†±ÂëäÁõ∏Á¨¶ÁöÑÈùúÊÖãÁÜ±ÂúñÂíåË¶ñÁ∑öÂΩ±ÁâáÔºåÂæûËÄå‰øÉÊàê‰∫ÜÂÖ®Èù¢ÁöÑÂàÜÊûê„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áÂÖ∂ÊïàËÉΩËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ‰∏¶Ë©ï‰º∞ÂÖ∂Âú®‰∏çÂêåÊîæÂ∞ÑÁßëÈÜ´Â∏´‰πãÈñìÁöÑÊ¶ÇÊã¨ÊÄß‰æÜÈ©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂºïÂÖ•‰∫ÜÊñ∞ÁöÑÁ≠ñÁï•‰æÜÂª∫Ê®°ÊîæÂ∞ÑÁßëÈÜ´Â∏´Âú® CXR ÂΩ±ÂÉèË®∫Êñ∑ÊúüÈñìÁöÑÊêúÂ∞ãÊ®°Âºè„ÄÇÊ†πÊìöÊîæÂ∞ÑÁßëÈÜ´Â∏´ÁöÑË©ï‰º∞ÔºåMedGaze ÂèØ‰ª•Áî¢ÁîüÈ°û‰ºº‰∫∫È°ûÁöÑË¶ñÁ∑öÂ∫èÂàóÔºåÈ´òÂ∫¶ÈóúÊ≥® CXR ÂΩ±ÂÉè‰∏äÁöÑÁõ∏ÈóúÂçÄÂüü„ÄÇÂú®ÊéÉÊèèË∑ØÂæëÁöÑÂÜóÈ§òÊÄßÂíåÈö®Ê©üÊÄßÊñπÈù¢ÔºåÂÆÉÊúâÊôÇ‰πüÂÑ™Êñº‰∫∫È°û„ÄÇ

##### **ACES: Automatic Cohort Extraction System for Event-Stream Datasets**
2406.19653v1 by Justin Xu, Jack Gallifant, Alistair E. W. Johnson, Matthew B. A. McDermott

Reproducibility remains a significant challenge in machine learning (ML) for
healthcare. In this field, datasets, model pipelines, and even task/cohort
definitions are often private, leading to a significant barrier in sharing,
iterating, and understanding ML results on electronic health record (EHR)
datasets. In this paper, we address a significant part of this problem by
introducing the Automatic Cohort Extraction System for Event-Stream Datasets
(ACES). This tool is designed to simultaneously simplify the development of
task/cohorts for ML in healthcare and enable the reproduction of these cohorts,
both at an exact level for single datasets and at a conceptual level across
datasets. To accomplish this, ACES provides (1) a highly intuitive and
expressive configuration language for defining both dataset-specific concepts
and dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to
automatically extract patient records that meet these defined criteria from
real-world data. ACES can be automatically applied to any dataset in either the
Medical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to
*any* dataset for which the necessary task-specific predicates can be extracted
in an event-stream form. ACES has the potential to significantly lower the
barrier to entry for defining ML tasks, redefine the way researchers interact
with EHR datasets, and significantly improve the state of reproducibility for
ML studies in this modality. ACES is available at
https://github.com/justin13601/aces.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÔºåÂèØË§áË£ΩÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÂú®ÈÄôÂÄãÈ†òÂüü‰∏≠ÔºåË≥áÊñôÈõÜ„ÄÅÊ®°ÂûãÁÆ°Á∑öÔºåÁîöËá≥‰ªªÂãô/Áæ§ÁµÑÂÆöÁæ©ÈÄöÂ∏∏ÈÉΩÊòØÁßÅÊúâÁöÑÔºåÈÄôÂ∞éËá¥Âú®ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Ë≥áÊñôÈõÜ‰∏äÂàÜ‰∫´„ÄÅÈáçË§áÂíåÁêÜËß£ ML ÁµêÊûúÊôÇÁî¢ÁîüÈáçÂ§ßÁöÑÈöúÁ§ô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂ∞éÂÖ•‰∫ã‰ª∂‰∏≤ÊµÅË≥áÊñôÈõÜÁöÑËá™ÂãïÁæ§ÁµÑËêÉÂèñÁ≥ªÁµ± (ACES) ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÁöÑÂÖ∂‰∏≠‰∏ÄÂÄãÈáçË¶ÅÈÉ®ÂàÜ„ÄÇÊ≠§Â∑•ÂÖ∑Êó®Âú®ÂêåÊôÇÁ∞°ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ ML ÁöÑ‰ªªÂãô/Áæ§ÁµÑÈñãÁôºÔºå‰∏¶ËÆìÈÄô‰∫õÁæ§ÁµÑÂæó‰ª•Ë§áË£ΩÔºåÁÑ°Ë´ñÊòØÂú®ÂñÆ‰∏ÄË≥áÊñôÈõÜÁöÑÁ≤æÁ¢∫Â±§Á¥öÔºåÈÇÑÊòØÂú®Ë∑®Ë≥áÊñôÈõÜÁöÑÊ¶ÇÂøµÂ±§Á¥ö‰∏ä„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåACES Êèê‰æõ‰∫Ü (1) ‰∏ÄÁ®ÆÈ´òÂ∫¶Áõ¥Ë¶∫‰∏îÂÖ∑Ë°®ÁèæÂäõÁöÑÁµÑÊÖãË™ûË®ÄÔºåÁî®ÊñºÂÆöÁæ©Ë≥áÊñôÈõÜÁâπÂÆöÁöÑÊ¶ÇÂøµÂíåËàáË≥áÊñôÈõÜÁÑ°ÈóúÁöÑÂåÖÂê´/ÊéíÈô§Ê®ôÊ∫ñÔºå‰ª•Âèä (2) ‰∏ÄÂÄãÁÆ°Á∑öÔºåÁî®ÊñºËá™ÂãïÂæûÁúüÂØ¶‰∏ñÁïåË≥áÊñô‰∏≠ËêÉÂèñÁ¨¶ÂêàÈÄô‰∫õÂÆöÁæ©Ê®ôÊ∫ñÁöÑÁóÖÊÇ£Ë®òÈåÑ„ÄÇACES ÂèØ‰ª•Ëá™ÂãïÂ•óÁî®Ëá≥ÈÜ´ÁôÇ‰∫ã‰ª∂Ë≥áÊñôÊ®ôÊ∫ñ (MEDS) Êàñ EventStreamGPT (ESGPT) Ê†ºÂºè‰∏≠ÁöÑ‰ªª‰ΩïË≥áÊñôÈõÜÔºåÊàñÂ•óÁî®Ëá≥ *‰ªª‰Ωï* ÂèØ‰ª•‰ª•‰∫ã‰ª∂‰∏≤ÊµÅÂΩ¢ÂºèËêÉÂèñÂøÖË¶ÅÁöÑÁâπÂÆö‰ªªÂãôË¨ÇË©ûÁöÑË≥áÊñôÈõÜ„ÄÇACES ÊúâÂèØËÉΩÂ§ßÂπÖÈôç‰ΩéÂÆöÁæ© ML ‰ªªÂãôÁöÑÈÄ≤ÂÖ•ÈñÄÊ™ªÔºåÈáçÊñ∞ÂÆöÁæ©Á†îÁ©∂‰∫∫Âì°Ëàá EHR Ë≥áÊñôÈõÜ‰∫íÂãïÁöÑÊñπÂºèÔºå‰∏¶È°ØËëóÊîπÂñÑÊ≠§ÊñπÂºè‰∏≠ ML Á†îÁ©∂ÁöÑÂèØË§áË£ΩÊÄß„ÄÇACES ÂèØÂú® https://github.com/justin13601/aces ÂèñÂæó„ÄÇ

##### **Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**
2406.19611v1 by Huajun Zhou, Fengtao Zhou, Chenyu Zhao, Yingxue Xu, Luyang Luo, Hao Chen

The essence of precision oncology lies in its commitment to tailor targeted
treatments and care measures to each patient based on the individual
characteristics of the tumor. The inherent heterogeneity of tumors necessitates
gathering information from diverse data sources to provide valuable insights
from various perspectives, fostering a holistic comprehension of the tumor.
Over the past decade, multimodal data integration technology for precision
oncology has made significant strides, showcasing remarkable progress in
understanding the intricate details within heterogeneous data modalities. These
strides have exhibited tremendous potential for improving clinical
decision-making and model interpretation, contributing to the advancement of
cancer care and treatment. Given the rapid progress that has been achieved, we
provide a comprehensive overview of about 300 papers detailing cutting-edge
multimodal data integration techniques in precision oncology. In addition, we
conclude the primary clinical applications that have reaped significant
benefits, including early assessment, diagnosis, prognosis, and biomarker
discovery. Finally, derived from the findings of this survey, we present an
in-depth analysis that explores the pivotal challenges and reveals essential
pathways for future research in the field of multimodal data integration for
precision oncology.

ÊëòË¶ÅÔºöÁ≤æÊ∫ñËÖ´Áò§Â≠∏ÁöÑÁ≤æÈ´ìÂú®ÊñºÈáùÂ∞çÊØè‰ΩçÊÇ£ËÄÖÈáèË∫´ÊâìÈÄ†Ê®ôÈù∂Ê≤ªÁôÇÂíåÁÖßË≠∑Êé™ÊñΩÔºåËÄåÊ†πÊìöËÖ´Áò§ÁöÑÂÄãÂà•ÁâπÂæµ„ÄÇËÖ´Áò§ÁöÑÂÖßÂú®Áï∞Ë≥™ÊÄßÈúÄË¶ÅÂæû‰∏çÂêåÁöÑË≥áÊñô‰æÜÊ∫êËíêÈõÜË≥áË®äÔºå‰ª•Êèê‰æõ‰æÜËá™‰∏çÂêåËßÄÈªûÁöÑÂØ∂Ë≤¥Ë¶ãËß£Ôºå‰øÉÈÄ≤Â∞çËÖ´Áò§ÁöÑÊï¥È´îÁêÜËß£„ÄÇÂú®ÈÅéÂéªÂçÅÂπ¥‰∏≠ÔºåÁ≤æÊ∫ñËÖ´Áò§Â≠∏ÁöÑÂ§öÊ®°ÂºèË≥áÊñôÊï¥ÂêàÊäÄË°ìÂ∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºåÂú®‰∫ÜËß£Áï∞Ë≥™ÊÄßË≥áÊñôÊ®°Âºè‰∏≠ÁöÑË§áÈõúÁ¥∞ÁØÄÊñπÈù¢Â±ïÁèæÂá∫È°ØËëóÁöÑÈÄ≤Â±ï„ÄÇÈÄô‰∫õÈÄ≤Â±ïÂ∑≤Â±ïÁèæÂá∫Ê•µÂ§ßÁöÑÊΩõÂäõÔºåÂèØÊîπÂñÑËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÂíåÊ®°ÂûãË©ÆÈáãÔºåÊúâÂä©ÊñºÁôåÁóáÁÖßË≠∑ÂíåÊ≤ªÁôÇÁöÑÈÄ≤Ê≠•„ÄÇÈëëÊñºÂ∑≤ÂèñÂæóÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÁ¥Ñ 300 ÁØáË´ñÊñáÁöÑÂÖ®Èù¢Ê¶ÇËø∞ÔºåË©≥Á¥∞Ë™™ÊòéÁ≤æÊ∫ñËÖ´Áò§Â≠∏‰∏≠Â∞ñÁ´ØÁöÑÊ®°ÊÖãË≥áÊñôÊï¥ÂêàÊäÄË°ì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ∏ΩÁµê‰∫ÜÂ∑≤Áç≤ÂæóÈ°ØËëóÂ•ΩËôïÁöÑ‰∏ªË¶ÅËá®Â∫äÊáâÁî®ÔºåÂåÖÊã¨Êó©ÊúüË©ï‰º∞„ÄÅË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁîüÁâ©Ê®ôË®òÁôºÁèæ„ÄÇÊúÄÂæåÔºåÊ†πÊìöÈÄôÈ†ÖË™øÊü•ÁµêÊûúÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÊ∑±ÂÖ•ÂàÜÊûêÔºåÊé¢Ë®é‰∫ÜÈóúÈçµÊåëÊà∞Ôºå‰∏¶Êè≠Á§∫‰∫ÜÁ≤æÊ∫ñËÖ´Áò§Â≠∏‰∏≠Â§öÊ®°ÂºèË≥áÊñôÊï¥ÂêàÈ†òÂüüÊú™‰æÜÁ†îÁ©∂ÁöÑÈáçË¶ÅÈÄîÂæë„ÄÇ

##### **PathAlign: A vision-language model for whole slide images in histopathology**
2406.19578v1 by Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn

Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.

ÊëòË¶ÅÔºöÈ°ØÂæÆÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèÁöÑÂæÆËßÄË©ÆÈáãÊòØË®±Â§öÈáçË¶ÅÁöÑË®∫Êñ∑ÂíåÊ≤ªÁôÇÊ±∫Á≠ñÁöÑÂü∫Á§é„ÄÇÈõñÁÑ∂Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÈÄ≤Â±ïÁÇ∫Ê≠§È°ûÂΩ±ÂÉèÁöÑÂàÜÊûêÂ∏∂‰æÜ‰∫ÜÊñ∞ÁöÑÂ•ëÊ©üÔºå‰ΩÜÂÖ®ÂàáÁâáÂΩ±ÂÉè (WSI) ÁöÑÂçÉÂÖÜÂÉèÁ¥†Á≠âÁ¥öÂ§ßÂ∞èÂ∏∂‰æÜ‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÁóÖÁêÜÂ†±ÂëäÂêåÊôÇÂº∑Ë™ø‰∫ÜÂ∞èÂçÄÂüüÁöÑÈóúÈçµÁôºÁèæÔºåÂêåÊôÇ‰πüÂΩôÁ∏Ω‰∫ÜÂ§öÂÄãÂàáÁâáÁöÑË©ÆÈáãÔºåÈÄôÈÄöÂ∏∏‰ΩøÂæóÂª∫Á´ãÁ©©ÂÅ•ÁöÑÂΩ±ÂÉèÊñáÂ≠óÂ∞çËÆäÂæóÂõ∞Èõ£„ÄÇÂõ†Ê≠§ÔºåÁóÖÁêÜÂ†±Âëä‰ªçÁÑ∂ÊòØË®àÁÆóÁóÖÁêÜÂ≠∏‰∏≠‰∏ÄÂÄãÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊú™ÈñãÁôºÁöÑÁõ£Áù£‰æÜÊ∫êÔºåÂ§ßÂ§öÊï∏Â∑•‰Ωú‰æùË≥¥ÊñºÊÑüËààË∂£ÂçÄÂüüË®ªËß£ÊàñÂú®Ë≤ºÁâáÁöÑÂ±§Á¥ö‰∏äÈÄ≤Ë°åËá™ÊàëÁõ£Áù£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂü∫Êñº BLIP-2 Ê°ÜÊû∂ÈñãÁôº‰∫Ü‰∏ÄÂÄãË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºå‰ΩøÁî®Ëàá‰æÜËá™ÁóÖÁêÜÂ†±ÂëäÁöÑÁ≠ñÂ±ïÊñáÂ≠óÈÖçÂ∞çÁöÑ WSI„ÄÇÈÄô‰ΩøÂæóÊáâÁî®Á®ãÂºèËÉΩÂ§†‰ΩøÁî®ÂÖ±‰∫´ÁöÑÂΩ±ÂÉèÊñáÂ≠óÂµåÂÖ•Á©∫ÈñìÔºå‰æãÂ¶ÇÊñáÂ≠óÊàñÂΩ±ÂÉèÊ™¢Á¥¢‰æÜÂ∞ãÊâæÊÑüËààË∂£ÁöÑÊ°à‰æãÔºå‰ª•ÂèäÂ∞á WSI Á∑®Á¢ºÂô®ËàáÂáçÁµêÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÔºåÁî®Êñº WSI Âü∫ÊñºÁîüÊàêÊñáÂ≠óÁöÑËÉΩÂäõÔºå‰æãÂ¶ÇÂ†±ÂëäÁî¢ÁîüÊàñ AI Âæ™Áí∞‰∫íÂãï„ÄÇÊàëÂÄëÂà©Áî®‰∫Ü‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 350,000 ÂÄã WSI ÂíåË®∫Êñ∑ÊñáÂ≠óÂ∞çÁöÑÂéªË≠òÂà•ÂåñË≥áÊñôÈõÜÔºåÊ∂µËìã‰∫ÜÂª£Ê≥õÁöÑË®∫Êñ∑„ÄÅÁ®ãÂ∫èÈ°ûÂûãÂíåÁµÑÁπîÈ°ûÂûã„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁóÖÁêÜÂ≠∏ÂÆ∂Â∞ç‰ΩøÁî® WSI ÂµåÂÖ•ÁöÑÊñáÂ≠óÁî¢ÁîüÂíåÊñáÂ≠óÊ™¢Á¥¢ÁöÑË©ï‰º∞Ôºå‰ª•Âèä WSI ÂàÜÈ°ûÂíåÂ∑•‰ΩúÊµÅÁ®ãÂÑ™ÂÖàÈ†ÜÂ∫èÔºàÂàáÁâáÁ¥öÂà•ÂàÜÈ°ûÔºâÁöÑÁµêÊûú„ÄÇÁóÖÁêÜÂ≠∏ÂÆ∂Ë©ï‰º∞‰∫Ü WSI ÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑÊñáÂ≠óÔºåÂπ≥ÂùáËÄåË®ÄÔºå78% ÁöÑ WSI Ê∫ñÁ¢∫ÁÑ°Ëá®Â∫äÈ°ØËëóÈåØË™§ÊàñÈÅ∫Êºè„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ±ïÁ§∫‰∫ÜË™ûË®ÄÂ∞çÈΩä WSI ÂµåÂÖ•ÁöÑ‰ª§‰∫∫ËààÂ•ÆÁöÑÊΩõÂú®ËÉΩÂäõ„ÄÇ

##### **Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques**
2407.00120v1 by Abraham G Taye, Sador Yemane, Eshetu Negash, Yared Minwuyelet, Moges Abebe, Melkamu Hunegnaw Asmare

Malaria parasites pose a significant global health burden, causing widespread
suffering and mortality. Detecting malaria infection accurately is crucial for
effective treatment and control. However, existing automated detection
techniques have shown limitations in terms of accuracy and generalizability.
Many studies have focused on specific features without exploring more
comprehensive approaches. In our case, we formulate a deep learning technique
for malaria-infected cell classification using traditional CNNs and transfer
learning models notably VGG19, InceptionV3, and Xception. The models were
trained using NIH datasets and tested using different performance metrics such
as accuracy, precision, recall, and F1-score. The test results showed that deep
CNNs achieved the highest accuracy -- 97%, followed by Xception with an
accuracy of 95%. A machine learning model SVM achieved an accuracy of 83%,
while an Inception-V3 achieved an accuracy of 94%. Furthermore, the system can
be accessed through a web interface, where users can upload blood smear images
for malaria detection.

ÊëòË¶ÅÔºöÁòßÁñæÂØÑÁîüËü≤Â∞çÂÖ®ÁêÉÂÅ•Â∫∑ÈÄ†ÊàêÈáçÂ§ßË≤†ÊìîÔºåÂ∞éËá¥Âª£Ê≥õÁöÑÁóõËã¶ÂíåÊ≠ª‰∫°„ÄÇÊ∫ñÁ¢∫Ê™¢Ê∏¨ÁòßÁñæÊÑüÊüìÂ∞çÊñºÊúâÊïàÊ≤ªÁôÇÂíåÊéßÂà∂Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑËá™ÂãïÊ™¢Ê∏¨ÊäÄË°ìÂú®Ê∫ñÁ¢∫ÊÄßÂíåÊôÆÈÅçÊÄßÊñπÈù¢È°ØÁ§∫Âá∫Â±ÄÈôêÊÄß„ÄÇË®±Â§öÁ†îÁ©∂Â∞àÊ≥®ÊñºÁâπÂÆöÁâπÂæµÔºåËÄåÊ≤íÊúâÊé¢Á¥¢Êõ¥ÂÖ®Èù¢ÁöÑÊñπÊ≥ï„ÄÇÂú®ÊàëÂÄëÁöÑÊ°à‰æã‰∏≠ÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÁ®ÆÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÔºå‰ΩøÁî®ÂÇ≥Áµ±ÁöÑ CNN ÂíåËΩâÁßªÂ≠∏ÁøíÊ®°ÂûãÔºåÁâπÂà•ÊòØ VGG19„ÄÅInceptionV3 Âíå XceptionÔºåÈÄ≤Ë°åÁòßÁñæÊÑüÊüìÁ¥∞ËÉûÂàÜÈ°û„ÄÇÈÄô‰∫õÊ®°Âûã‰ΩøÁî® NIH Ë≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰∏¶‰ΩøÁî®‰∏çÂêåÁöÑÊïàËÉΩÊåáÊ®ôÈÄ≤Ë°åÊ∏¨Ë©¶Ôºå‰æãÂ¶ÇÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏„ÄÇÊ∏¨Ë©¶ÁµêÊûúË°®ÊòéÔºåÊ∑±Â∫¶ CNN ÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶‚Äî‚Äî97%ÔºåÂÖ∂Ê¨°ÊòØ XceptionÔºåÊ∫ñÁ¢∫Â∫¶ÁÇ∫ 95%„ÄÇÊ©üÂô®Â≠∏ÁøíÊ®°Âûã SVM ÈÅîÂà∞‰∫Ü 83% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåËÄå Inception-V3 ÈÅîÂà∞‰∫Ü 94% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÊ≠§Â§ñÔºåË©≤Á≥ªÁµ±ÂèØÈÄèÈÅéÁ∂≤Ë∑Ø‰ªãÈù¢Â≠òÂèñÔºå‰ΩøÁî®ËÄÖÂèØ‰ª•Âú®Ê≠§‰ªãÈù¢‰∏≠‰∏äÂÇ≥Ë°ÄÂ°óÁâáÂΩ±ÂÉè‰ª•ÈÄ≤Ë°åÁòßÁñæÊ™¢Ê∏¨„ÄÇ

##### **HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**
2406.19280v1 by Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang

The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÁöÑÂø´ÈÄüÂèëÂ±ïÔºå‰æãÂ¶Ç GPT-4VÔºåÂ∏¶Êù•‰∫ÜÈáçÂ§ßÁöÑËøõÊ≠•„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÂåªÁñóËßÜËßâÊñáÊú¨Êï∞ÊçÆÁöÑÊï∞ÈáèÂíåË¥®ÈáèÁöÑÈôêÂà∂ÔºåËøô‰∫õÊ®°ÂûãÂú®ÂåªÁñóÂ§öÊ®°ÊÄÅËÉΩÂäõÊñπÈù¢‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàòÔºåËøôÊ∫ê‰∫éÊï∞ÊçÆÈöêÁßÅÈóÆÈ¢òÂíåÈ´òÊòÇÁöÑÊ†áÊ≥®ÊàêÊú¨„ÄÇËôΩÁÑ∂ÂºÄÂàõÊÄßÁöÑÊñπÊ≥ïÂà©Áî® PubMed ÁöÑÂ§ßËßÑÊ®°„ÄÅÂéªÊ†áËØÜÂåñÁöÑÂåªÂ≠¶ÂõæÂÉèÊñáÊú¨ÂØπÊù•Ëß£ÂÜ≥Ëøô‰∫õÈôêÂà∂Ôºå‰ΩÜÁî±‰∫éÂõ∫ÊúâÁöÑÊï∞ÊçÆÂô™Â£∞ÔºåÂÆÉ‰ª¨‰ªçÁÑ∂Â≠òÂú®‰∏çË∂≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨‰ªé PubMed ‰∏≠‰ºòÂåñ‰∫ÜÂåªÂ≠¶ÂõæÂÉèÊñáÊú¨ÂØπÔºåÂπ∂‰ª•‚ÄúÈùûÁõ≤‚ÄùÁöÑÊñπÂºèÈááÁî®‰∫Ü MLLMÔºàGPT-4VÔºâÊù•ÂØπÊï∞ÊçÆËøõË°åÂéªÂô™ÂíåÈáçÊñ∞Ê†ºÂºèÂåñÔºå‰ªéËÄåÂàõÂª∫‰∫ÜÂåÖÂê´ 130 ‰∏á‰∏™ÂåªÂ≠¶ VQA Ê†∑Êú¨ÁöÑ PubMedVision Êï∞ÊçÆÈõÜ„ÄÇÊàë‰ª¨ÁöÑÈ™åËØÅË°®ÊòéÔºö(1) PubMedVision ÂèØ‰ª•ÊòæËëóÂ¢ûÂº∫ÂΩìÂâç MLLM ÁöÑÂåªÁñóÂ§öÊ®°ÊÄÅËÉΩÂäõÔºåÂú®ÂåÖÊã¨ MMMU ÂÅ•Â∫∑‰∏éÂåªÂ≠¶ËΩ®ÈÅìÂú®ÂÜÖÁöÑÂü∫ÂáÜÊµãËØï‰∏≠ÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊîπËøõÔºõ(2) ÂåªÂ≠¶‰∏ìÂÆ∂ÁöÑÊâãÂä®Ê£ÄÊü•ÂíåÂÆûËØÅÁªìÊûúÈ™åËØÅ‰∫ÜÊàë‰ª¨Êï∞ÊçÆÈõÜ‰∏éÂÖ∂‰ªñÊï∞ÊçÆÊûÑÂª∫ÊñπÊ≥ïÁõ∏ÊØîÁöÑÂçìË∂äÊï∞ÊçÆË¥®Èáè„ÄÇ‰ΩøÁî® PubMedVisionÔºåÊàë‰ª¨ËÆ≠ÁªÉ‰∫Ü‰∏Ä‰∏™ 34B ÂåªÂ≠¶ MLLM HuatuoGPT-VisionÔºåÂÆÉÂú®ÂºÄÊ∫ê MLLM ‰∏≠ÁöÑÂåªÂ≠¶Â§öÊ®°ÊÄÅÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫ÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇ

##### **Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges**
2407.00116v2 by Mahmoud Ibrahim, Yasmina Al Khalil, Sina Amirrajab, Chang Sun, Marcel Breeuwer, Josien Pluim, Bart Elen, Gokhan Ertaylan, Michel Dumontier

This paper presents a comprehensive systematic review of generative models
(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,
including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),
text, time-series, and tabular data (EHR). Unlike previous narrowly focused
reviews, our study encompasses a broad array of medical data modalities and
explores various generative models. Our search strategy queries databases such
as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to
November 2023, excluding reviews and perspectives. This period emphasizes
recent advancements beyond GANs, which have been extensively covered
previously.
  The survey reveals insights from three key aspects: (1) Synthesis
applications and purpose of synthesis, (2) generation techniques, and (3)
evaluation methods. It highlights clinically valid synthesis applications,
demonstrating the potential of synthetic data to tackle diverse clinical
requirements. While conditional models incorporating class labels, segmentation
masks and image translations are prevalent, there is a gap in utilizing prior
clinical knowledge and patient-specific context, suggesting a need for more
personalized synthesis approaches and emphasizing the importance of tailoring
generative approaches to the unique characteristics of medical data.
Additionally, there is a significant gap in using synthetic data beyond
augmentation, such as for validation and evaluation of downstream medical AI
models. The survey uncovers that the lack of standardized evaluation
methodologies tailored to medical images is a barrier to clinical application,
underscoring the need for in-depth evaluation approaches, benchmarking, and
comparative studies to promote openness and collaboration.

ÊëòË¶ÅÔºö<paragraph>Êú¨ÊñáÊèêÂá∫‰∫ÜÁîüÊàêÂºèÊ®°ÂûãÔºàGAN„ÄÅVAE„ÄÅDM Âíå LLMÔºâÁöÑÂÖ®Èù¢Á≥ªÁªüÊÄßÂõûÈ°æÔºåËøô‰∫õÊ®°ÂûãÁî®‰∫éÂêàÊàêÂêÑÁßçÂåªÂ≠¶Êï∞ÊçÆÁ±ªÂûãÔºåÂåÖÊã¨ÂΩ±ÂÉèÔºàÁöÆËÇ§Èïú„ÄÅ‰π≥Êàø X ÂÖâÊ£ÄÊü•„ÄÅË∂ÖÂ£∞Ê≥¢„ÄÅCT„ÄÅMRI Âíå X Â∞ÑÁ∫øÔºâ„ÄÅÊñáÊú¨„ÄÅÊó∂Èó¥Â∫èÂàóÂíåË°®Ê†ºÊï∞ÊçÆÔºàEHRÔºâ„ÄÇ‰∏é‰ª•ÂæÄÈíàÂØπÁâπÂÆöÈ¢ÜÂüüÁöÑÁã≠Á™ÑÁªºËø∞‰∏çÂêåÔºåÊàë‰ª¨ÁöÑÁ†îÁ©∂Ê∂µÁõñ‰∫ÜÂπøÊ≥õÁöÑÂåªÂ≠¶Êï∞ÊçÆÊ®°ÂºèÔºåÂπ∂Êé¢ËÆ®‰∫ÜÂêÑÁßçÁîüÊàêÂºèÊ®°Âûã„ÄÇÊàë‰ª¨ÁöÑÊêúÁ¥¢Á≠ñÁï•Êü•ËØ¢‰∫Ü Scopus„ÄÅPubMed Âíå ArXiv Á≠âÊï∞ÊçÆÂ∫ìÔºåÈáçÁÇπÂÖ≥Ê≥® 2021 Âπ¥ 1 ÊúàËá≥ 2023 Âπ¥ 11 ÊúàÁöÑËøëÊúü‰ΩúÂìÅÔºå‰∏çÂåÖÊã¨ËØÑËÆ∫ÂíåËßÇÁÇπ„ÄÇËØ•Êó∂ÊÆµÁùÄÈáçÂº∫Ë∞É‰∫Ü GAN ‰πãÂ§ñÁöÑÊúÄÊñ∞ËøõÂ±ïÔºåËÄå GAN Â∑≤Âú®‰πãÂâçÂæóÂà∞ÂπøÊ≥õ‰ªãÁªç„ÄÇ
Ë∞ÉÊü•‰ªé‰∏â‰∏™ÂÖ≥ÈîÆÊñπÈù¢Êè≠Á§∫‰∫ÜËßÅËß£Ôºö(1) ÂêàÊàêÂ∫îÁî®ÂíåÂêàÊàêÁöÑÁõÆÁöÑÔºå(2) ÁîüÊàêÊäÄÊúØÔºå‰ª•Âèä (3) ËØÑ‰º∞ÊñπÊ≥ï„ÄÇÂÆÉÁ™ÅÂá∫‰∫Ü‰∏¥Â∫ä‰∏äÊúâÊïàÁöÑÂêàÊàêÂ∫îÁî®ÔºåÂ±ïÁ§∫‰∫ÜÂêàÊàêÊï∞ÊçÆËß£ÂÜ≥ÂêÑÁßç‰∏¥Â∫äÈúÄÊ±ÇÁöÑÊΩúÂäõ„ÄÇËôΩÁÑ∂ÂåÖÂê´Á±ªÂà´Ê†áÁ≠æ„ÄÅÂàÜÂâ≤Êé©Ê®°ÂíåÂõæÂÉèËΩ¨Êç¢ÁöÑÊù°‰ª∂Ê®°ÂûãÂæàÊôÆÈÅçÔºå‰ΩÜÂú®Âà©Áî®ÂÖàÈ™å‰∏¥Â∫äÁü•ËØÜÂíåÊÇ£ËÄÖÁâπÂÆöËÉåÊôØÊñπÈù¢Â≠òÂú®Â∑ÆË∑ùÔºåËøôË°®ÊòéÈúÄË¶ÅÊõ¥Â§ö‰∏™ÊÄßÂåñÁöÑÂêàÊàêÊñπÊ≥ïÔºåÂπ∂Âº∫Ë∞ÉÊ†πÊçÆÂåªÂ≠¶Êï∞ÊçÆÁöÑÁã¨ÁâπÁâπÂæÅÂÆöÂà∂ÁîüÊàêÊñπÊ≥ïÁöÑÈáçË¶ÅÊÄß„ÄÇÊ≠§Â§ñÔºåÂú®ÂêàÊàêÊï∞ÊçÆÁöÑÂ∫îÁî®‰∏≠Â≠òÂú®‰∏Ä‰∏™ÊòéÊòæÁöÑÂ∑ÆË∑ùÔºåË∂ÖÂá∫‰∫ÜÂ¢ûÂº∫‰πãÂ§ñÔºå‰æãÂ¶ÇÁî®‰∫éÈ™åËØÅÂíåËØÑ‰º∞‰∏ãÊ∏∏ÂåªÂ≠¶ AI Ê®°Âûã„ÄÇË∞ÉÊü•ÂèëÁé∞ÔºåÁº∫‰πèÈíàÂØπÂåªÂ≠¶ÂõæÂÉèÂÆöÂà∂ÁöÑÊ†áÂáÜÂåñËØÑ‰º∞ÊñπÊ≥ïÊòØ‰∏¥Â∫äÂ∫îÁî®ÁöÑÈöúÁ¢çÔºåËøôÂº∫Ë∞É‰∫ÜÂØπÊ∑±ÂÖ•ËØÑ‰º∞ÊñπÊ≥ï„ÄÅÂü∫ÂáÜÊµãËØïÂíåÊØîËæÉÁ†îÁ©∂ÁöÑÈúÄÊ±ÇÔºå‰ª•‰øÉËøõÂºÄÊîæÊÄßÂíåÂçè‰Ωú„ÄÇ</paragraph>

##### **Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**
2406.19057v2 by Fuseini Mumuni, Alhassan Mumuni

Grounding DINO and the Segment Anything Model (SAM) have achieved impressive
performance in zero-shot object detection and image segmentation, respectively.
Together, they have a great potential to revolutionize applications in
zero-shot semantic segmentation or data annotation. Yet, in specialized domains
like medical image segmentation, objects of interest (e.g., organs, tissues,
and tumors) may not fall in existing class names. To address this problem, the
referring expression comprehension (REC) ability of Grounding DINO is leveraged
to detect arbitrary targets by their language descriptions. However, recent
studies have highlighted severe limitation of the REC framework in this
application setting owing to its tendency to make false positive predictions
when the target is absent in the given image. And, while this bottleneck is
central to the prospect of open-set semantic segmentation, it is still largely
unknown how much improvement can be achieved by studying the prediction errors.
To this end, we perform empirical studies on six publicly available datasets
across different domains and reveal that these errors consistently follow a
predictable pattern and can, thus, be mitigated by a simple strategy.
Specifically, we show that false positive detections with appreciable
confidence scores generally occupy large image areas and can usually be
filtered by their relative sizes. More importantly, we expect these
observations to inspire future research in improving REC-based detection and
automated segmentation. Meanwhile, we evaluate the performance of SAM on
multiple datasets from various specialized domains and report significant
improvements in segmentation performance and annotation time savings over
manual approaches.

ÊëòË¶ÅÔºöGrounding DINO Âíå Segment Anything Model (SAM) ÂàÜÂà•Âú®Èõ∂Ê¨°Â≠∏ÁøíÁõÆÊ®ôÂÅµÊ∏¨ÂíåÂΩ±ÂÉèÂàÜÂâ≤ÊñπÈù¢ÂèñÂæó‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË°®Áèæ„ÄÇÂÖ©ËÄÖÁµêÂêàËµ∑‰æÜÔºåÊ•µÊúâÂèØËÉΩÂæπÂ∫ïÊîπËÆäÈõ∂Ê¨°Â≠∏ÁøíË™ûÊÑèÂàÜÂâ≤ÊàñË≥áÊñôÊ®ôË®ªÁöÑÊáâÁî®„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÂâ≤Á≠âÂ∞àÊ•≠È†òÂüü‰∏≠ÔºåÊÑüËààË∂£ÁöÑÁâ©È´îÔºà‰æãÂ¶ÇÂô®ÂÆò„ÄÅÁµÑÁπîÂíåËÖ´Áò§ÔºâÂèØËÉΩ‰∏çÂú®ÁèæÊúâÁöÑÈ°ûÂà•ÂêçÁ®±‰∏≠„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåGrounding DINO ÁöÑÊåáÁ®±Ë°®ÈÅîÁêÜËß£ (REC) ËÉΩÂäõË¢´Áî®ÊñºÈÄèÈÅéË™ûË®ÄÊèèËø∞‰æÜÂÅµÊ∏¨‰ªªÊÑèÁõÆÊ®ô„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫Ü REC Ê°ÜÊû∂Âú®ÈÄôÁ®ÆÊáâÁî®Ë®≠ÂÆö‰∏≠ÁöÑÂö¥ÈáçÈôêÂà∂ÔºåÂõ†ÁÇ∫Áï∂ÁõÆÊ®ô‰∏çÂ≠òÂú®ÊñºÁµ¶ÂÆöÁöÑÂΩ±ÂÉè‰∏≠ÊôÇÔºåÂÆÉÂÇæÂêëÊñºÂÅöÂá∫ÈåØË™§ÁöÑÊ≠£ÂêëÈ†êÊ∏¨„ÄÇËÄå‰∏îÔºåÂÑòÁÆ°ÈÄôÂÄãÁì∂È†∏Â∞çÊñºÈñãÊîæÂºèË™ûÊÑèÂàÜÂâ≤ÁöÑÂâçÊôØËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÈÄèÈÅéÁ†îÁ©∂È†êÊ∏¨Ë™§Â∑ÆÂèØ‰ª•Áç≤ÂæóÂ§öÂ∞ëÊîπÈÄ≤‰ªçÁÑ∂ weitgehendÊú™Áü•„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂ∞çÂÖ≠ÂÄã‰∏çÂêåÈ†òÂüüÁöÑÂÖ¨ÈñãÂèØÁî®Ë≥áÊñôÈõÜÈÄ≤Ë°åÂØ¶Ë≠âÁ†îÁ©∂Ôºå‰∏¶Êè≠Á§∫ÈÄô‰∫õË™§Â∑ÆÂßãÁµÇÈÅµÂæ™ÂèØÈ†êÊ∏¨ÁöÑÊ®°ÂºèÔºåÂõ†Ê≠§ÂèØ‰ª•ÈÄèÈÅé‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÁ≠ñÁï•‰æÜÊ∏õËºï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË°®ÊòéÂÖ∑ÊúâÂèØËßÄÁΩÆ‰ø°Â∫¶ÂàÜÊï∏ÁöÑÈåØË™§Ê≠£ÂêëÂÅµÊ∏¨ÈÄöÂ∏∏‰ΩîÊìöËºÉÂ§ßÁöÑÂΩ±ÂÉèÂçÄÂüüÔºåÈÄöÂ∏∏ÂèØ‰ª•ÈÄèÈÅéÂÆÉÂÄëÁöÑÁõ∏Â∞çÂ§ßÂ∞è‰æÜÈÅéÊøæ„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÈ†êÊúüÈÄô‰∫õËßÄÂØüÁµêÊûúÂ∞áÊøÄÂãµÊú™‰æÜÂú®ÊîπÈÄ≤Âü∫Êñº REC ÁöÑÂÅµÊ∏¨ÂíåËá™ÂãïÂàÜÂâ≤ÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇÂêåÊôÇÔºåÊàëÂÄëË©ï‰º∞‰∫Ü SAM Âú®‰æÜËá™ÂêÑÁ®ÆÂ∞àÊ•≠È†òÂüüÁöÑÂ§öÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩÔºå‰∏¶Â†±Âëä‰∫ÜÂàÜÂâ≤ÊïàËÉΩÂíåÊ®ôË®ªÊôÇÈñìÁõ∏ËºÉÊñºÊâãÂãïÊñπÊ≥ïÊúâÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇ

##### **FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**
2406.19050v1 by Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan

Federated Learning (FL) is a distributed machine learning approach that
enables training on decentralized data while preserving privacy. However, FL
systems often involve resource-constrained client devices with limited
computational power, memory, storage, and bandwidth. This paper introduces
FedMap, a novel method that aims to enhance the communication efficiency of FL
deployments by collaboratively learning an increasingly sparse global model
through iterative, unstructured pruning. Importantly, FedMap trains a global
model from scratch, unlike other methods reported in the literature, making it
ideal for privacy-critical use cases such as in the medical and finance
domains, where suitable pre-training data is often limited. FedMap adapts
iterative magnitude-based pruning to the FL setting, ensuring all clients prune
and refine the same subset of the global model parameters, therefore gradually
reducing the global model size and communication overhead. The iterative nature
of FedMap, forming subsequent models as subsets of predecessors, avoids
parameter reactivation issues seen in prior work, resulting in stable
performance. In this paper we provide an extensive evaluation of FedMap across
diverse settings, datasets, model architectures, and hyperparameters, assessing
performance in both IID and non-IID environments. Comparative analysis against
the baseline approach demonstrates FedMap's ability to achieve more stable
client model performance. For IID scenarios, FedMap achieves over $90$\%
pruning without significant performance degradation. In non-IID settings, it
achieves at least $~80$\% pruning while maintaining accuracy. FedMap offers a
promising solution to alleviate communication bottlenecks in FL systems while
retaining model accuracy.

ÊëòË¶ÅÔºöËÅîÈÇ¶Â≠¶‰π† (FL) ÊòØ‰∏ÄÁßçÂàÜÂ∏ÉÂºèÊú∫Âô®Â≠¶‰π†ÊñπÊ≥ïÔºåÂèØÂú®‰øùÊä§ÈöêÁßÅÁöÑÂêåÊó∂ÂØπÂàÜÊï£Êï∞ÊçÆËøõË°åËÆ≠ÁªÉ„ÄÇÁÑ∂ËÄåÔºåFL Á≥ªÁªüÈÄöÂ∏∏Ê∂âÂèäËµÑÊ∫êÂèóÈôêÁöÑÂÆ¢Êà∑Á´ØËÆæÂ§áÔºåÂÖ∂ËÆ°ÁÆóËÉΩÂäõ„ÄÅÂÜÖÂ≠ò„ÄÅÂ≠òÂÇ®ÂíåÂ∏¶ÂÆΩÊúâÈôê„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü FedMapÔºåËøôÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑÊñπÊ≥ïÔºåÊó®Âú®ÈÄöËøáÂçè‰ΩúÂ≠¶‰π†‰∏Ä‰∏™‰∏çÊñ≠Á®ÄÁñèÁöÑÂÖ®Â±ÄÊ®°ÂûãÔºàÈÄöËøáËø≠‰ª£ÁöÑÈùûÁªìÊûÑÂåñÂâ™ÊûùÔºâÊù•ÊèêÈ´ò FL ÈÉ®ÁΩ≤ÁöÑÈÄö‰ø°ÊïàÁéá„ÄÇÈáçË¶ÅÁöÑÊòØÔºåFedMap ‰ªéÂ§¥ÂºÄÂßãËÆ≠ÁªÉ‰∏Ä‰∏™ÂÖ®Â±ÄÊ®°ÂûãÔºåËøô‰∏éÊñáÁåÆ‰∏≠Êä•ÈÅìÁöÑÂÖ∂‰ªñÊñπÊ≥ï‰∏çÂêåÔºå‰ΩøÂÖ∂ÈùûÂ∏∏ÈÄÇÂêàÈöêÁßÅËá≥ÂÖ≥ÈáçË¶ÅÁöÑÁî®‰æãÔºå‰æãÂ¶ÇÂåªÁñóÂíåÈáëËûçÈ¢ÜÂüüÔºåÂÖ∂‰∏≠ÂêàÈÄÇÁöÑÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈÄöÂ∏∏ÊúâÈôê„ÄÇFedMap Â∞ÜÂü∫‰∫éËø≠‰ª£ÂπÖÂ∫¶ÁöÑÂâ™ÊûùË∞ÉÊï¥Âà∞ FL ËÆæÁΩÆ‰∏≠ÔºåÁ°Æ‰øùÊâÄÊúâÂÆ¢Êà∑Á´ØÈÉΩÂâ™ÊûùÂπ∂‰ºòÂåñÂÖ®Â±ÄÊ®°ÂûãÂèÇÊï∞ÁöÑÁõ∏ÂêåÂ≠êÈõÜÔºå‰ªéËÄåÈÄêÊ∏êÂáèÂ∞ëÂÖ®Â±ÄÊ®°ÂûãÂ§ßÂ∞èÂíåÈÄö‰ø°ÂºÄÈîÄ„ÄÇFedMap ÁöÑËø≠‰ª£ÊÄßË¥®ÔºåÂ∞ÜÂêéÁª≠Ê®°ÂûãÂΩ¢Êàê‰∏∫Ââç‰ª£Ê®°ÂûãÁöÑÂ≠êÈõÜÔºåÈÅøÂÖç‰∫ÜÂÖàÂâçÂ∑•‰Ωú‰∏≠ÁúãÂà∞ÁöÑÂèÇÊï∞ÈáçÊñ∞ÊøÄÊ¥ªÈóÆÈ¢òÔºå‰ªéËÄå‰∫ßÁîü‰∫ÜÁ®≥ÂÆöÁöÑÊÄßËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÂØπ FedMap Âú®‰∏çÂêåËÆæÁΩÆ„ÄÅÊï∞ÊçÆÈõÜ„ÄÅÊ®°ÂûãÊû∂ÊûÑÂíåË∂ÖÂèÇÊï∞‰∏≠ËøõË°å‰∫ÜÂπøÊ≥õËØÑ‰º∞ÔºåËØÑ‰º∞‰∫ÜÂú® IID ÂíåÈùû IID ÁéØÂ¢É‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ‰∏éÂü∫ÂáÜÊñπÊ≥ïÁöÑÊØîËæÉÂàÜÊûêËØÅÊòé‰∫Ü FedMap ËÉΩÂ§üÂÆûÁé∞Êõ¥Á®≥ÂÆöÁöÑÂÆ¢Êà∑Á´ØÊ®°ÂûãÊÄßËÉΩ„ÄÇÂØπ‰∫é IID Âú∫ÊôØÔºåFedMap Âú®‰∏çÊòæÁùÄÈôç‰ΩéÊÄßËÉΩÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞‰∫ÜË∂ÖËøá 90% ÁöÑÂâ™Êûù„ÄÇÂú®Èùû IID ËÆæÁΩÆ‰∏≠ÔºåÂÆÉÂú®‰øùÊåÅÂáÜÁ°ÆÊÄßÁöÑÂêåÊó∂ÂÆûÁé∞‰∫ÜËá≥Â∞ë 80% ÁöÑÂâ™Êûù„ÄÇFedMap ‰∏∫ÁºìËß£ FL Á≥ªÁªü‰∏≠ÁöÑÈÄö‰ø°Áì∂È¢àÂêåÊó∂‰øùÊåÅÊ®°ÂûãÂáÜÁ°ÆÊÄßÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÂ∏åÊúõÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

##### **CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI**
2406.19043v1 by Zi Wang, Fanwen Wang, Chen Qin, Jun Lyu, Ouyang Cheng, Shuo Wang, Yan Li, Mengyao Yu, Haoyu Zhang, Kunyuan Guo, Zhang Shi, Qirong Li, Ziqiang Xu, Yajing Zhang, Hao Li, Sha Hua, Binghua Chen, Longyu Sun, Mengting Sun, Qin Li, Ying-Hua Chu, Wenjia Bai, Jing Qin, Xiahai Zhuang, Claudia Prieto, Alistair Young, Michael Markl, He Wang, Lianming Wu, Guang Yang, Xiaobo Qu, Chengyan Wang

Cardiac magnetic resonance imaging (MRI) has emerged as a clinically
gold-standard technique for diagnosing cardiac diseases, thanks to its ability
to provide diverse information with multiple modalities and anatomical views.
Accelerated cardiac MRI is highly expected to achieve time-efficient and
patient-friendly imaging, and then advanced image reconstruction approaches are
required to recover high-quality, clinically interpretable images from
undersampled measurements. However, the lack of publicly available cardiac MRI
k-space dataset in terms of both quantity and diversity has severely hindered
substantial technological progress, particularly for data-driven artificial
intelligence. Here, we provide a standardized, diverse, and high-quality
CMRxRecon2024 dataset to facilitate the technical development, fair evaluation,
and clinical transfer of cardiac MRI reconstruction approaches, towards
promoting the universal frameworks that enable fast and robust reconstructions
across different cardiac MRI protocols in clinical practice. To the best of our
knowledge, the CMRxRecon2024 dataset is the largest and most diverse publicly
available cardiac k-space dataset. It is acquired from 330 healthy volunteers,
covering commonly used modalities, anatomical views, and acquisition
trajectories in clinical cardiac MRI workflows. Besides, an open platform with
tutorials, benchmarks, and data processing tools is provided to facilitate data
usage, advanced method development, and fair performance evaluation.

ÊëòË¶ÅÔºöÂøÉËáüÁ£ÅÂÖ±ÊåØÈÄ†ÂΩ± (MRI) Â∑≤ÊàêÁÇ∫Ë®∫Êñ∑ÂøÉËáüÁñæÁóÖÁöÑËá®Â∫äÈáëÊ®ôÊ∫ñÊäÄË°ìÔºåÂõ†ÁÇ∫ÂÆÉËÉΩÂ§†ÈÄèÈÅéÂ§öÁ®ÆÊ®°ÂºèÂíåËß£ÂâñË¶ñÂúñÊèê‰æõÂ§öÊ®£ÂåñÁöÑË≥áË®ä„ÄÇÂä†ÈÄüÂøÉËáü MRI Ê•µÊúâÊúõÂØ¶ÁèæÁúÅÊôÇ‰∏îÂ∞çÊÇ£ËÄÖÂèãÂñÑÁöÑÂΩ±ÂÉèÔºåÁÑ∂ÂæåÈúÄË¶ÅÈÄ≤ÈöéÂΩ±ÂÉèÈáçÂª∫ÊñπÊ≥ïÂæûÊ¨†Êé°Ê®£Ê∏¨Èáè‰∏≠ÈÇÑÂéüÈ´òÂìÅË≥™„ÄÅËá®Â∫ä‰∏äÂèØËß£ËÆÄÁöÑÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÂú®Êï∏ÈáèÂíåÂ§öÊ®£ÊÄßÊñπÈù¢Áº∫‰πèÂÖ¨ÈñãÁöÑÂøÉËáü MRI k Á©∫ÈñìË≥áÊñôÈõÜÂö¥ÈáçÈòªÁ§ô‰∫ÜÊäÄË°ìÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂ∞çÊñºË≥áÊñôÈ©ÖÂãïÁöÑ‰∫∫Â∑•Êô∫ÊÖß„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèê‰æõÊ®ôÊ∫ñÂåñ„ÄÅÂ§öÊ®£Âåñ‰∏îÈ´òÂìÅË≥™ÁöÑ CMRxRecon2024 Ë≥áÊñôÈõÜÔºå‰ª•‰øÉÈÄ≤ÊäÄË°ìÁôºÂ±ï„ÄÅÂÖ¨Ê≠£Ë©ï‰º∞ÂíåÂøÉËáü MRI ÈáçÂª∫ÊñπÊ≥ïÁöÑËá®Â∫äËΩâÁßªÔºåÊúùÂêëÊé®ÂãïÈÄöÁî®Ê°ÜÊû∂Ôºå‰ΩøËá®Â∫äÂØ¶Âãô‰∏≠ÁöÑ‰∏çÂêåÂøÉËáü MRI ÂçîÂÆöËÉΩÂ§†ÈÄ≤Ë°åÂø´ÈÄü‰∏îÁ©©ÂÅ•ÁöÑÈáçÂª∫„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåCMRxRecon2024 Ë≥áÊñôÈõÜÊòØÊúÄÂ§ß‰∏îÊúÄÂ§öÊ®£ÂåñÁöÑÂÖ¨ÈñãÂøÉËáü k Á©∫ÈñìË≥áÊñôÈõÜ„ÄÇÂÆÉÊòØÂæû 330 ‰ΩçÂÅ•Â∫∑ÂøóÈ°òËÄÖÂèñÂæóÔºåÊ∂µËìãËá®Â∫äÂøÉËáü MRI Â∑•‰ΩúÊµÅÁ®ã‰∏≠Â∏∏Áî®ÁöÑÊ®°Âºè„ÄÅËß£ÂâñË¶ñÂúñÂíåÊì∑ÂèñËªåË∑°„ÄÇÊ≠§Â§ñÔºåÊèê‰æõ‰∏ÄÂÄãÂåÖÂê´ÊïôÂ≠∏Ë™≤Á®ã„ÄÅÂü∫Ê∫ñÂíåË≥áÊñôËôïÁêÜÂ∑•ÂÖ∑ÁöÑÈñãÊîæÂπ≥Âè∞Ôºå‰ª•‰øÉÈÄ≤Ë≥áÊñô‰ΩøÁî®„ÄÅÈÄ≤ÈöéÊñπÊ≥ïÈñãÁôºÂíåÂÖ¨Ê≠£ÁöÑÊïàËÉΩË©ï‰º∞„ÄÇ

##### **Lithium-Ion Battery System Health Monitoring and Fault Analysis from Field Data Using Gaussian Processes**
2406.19015v1 by Joachim Schaeffer, Eric Lenz, Duncan Gulla, Martin Z. Bazant, Richard D. Braatz, Rolf Findeisen

Health monitoring, fault analysis, and detection are critical for the safe
and sustainable operation of battery systems. We apply Gaussian process
resistance models on lithium iron phosphate battery field data to effectively
separate the time-dependent and operating point-dependent resistance. The data
set contains 29 battery systems returned to the manufacturer for warranty, each
with eight cells in series, totaling 232 cells and 131 million data rows. We
develop probabilistic fault detection rules using recursive spatiotemporal
Gaussian processes. These processes allow the quick processing of over a
million data points, enabling advanced online monitoring and furthering the
understanding of battery pack failure in the field. The analysis underlines
that often, only a single cell shows abnormal behavior or a knee point,
consistent with weakest-link failure for cells connected in series, amplified
by local resistive heating. The results further the understanding of how
batteries degrade and fail in the field and demonstrate the potential of
efficient online monitoring based on data. We open-source the code and publish
the large data set upon completion of the review of this article.

ÊëòË¶ÅÔºöÂÅ•Â∫∑Áõ£Êéß„ÄÅÊïÖÈöúÂàÜÊûêÂíåÊ™¢Ê∏¨Â∞çÊñºÈõªÊ±†Á≥ªÁµ±ÁöÑÂÆâÂÖ®ÂíåÂèØÊåÅÁ∫åÈÅã‰ΩúËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÂ∞áÈ´òÊñØÈÅéÁ®ãÈõªÈòªÊ®°ÂûãÊáâÁî®ÊñºÁ£∑ÈÖ∏ÈêµÈã∞ÈõªÊ±†ÁèæÂ†¥Êï∏ÊìöÔºå‰ª•ÊúâÊïàÂàÜÈõ¢ÊôÇÈñìÁõ∏ÈóúÂíåÈÅã‰ΩúÈªûÁõ∏ÈóúÁöÑÈõªÈòª„ÄÇË©≤Êï∏ÊìöÈõÜÂåÖÂê´ 29 ÂÄãÈÄÄÂõûÁµ¶Ë£ΩÈÄ†ÂïÜÈÄ≤Ë°å‰øùÂõ∫ÁöÑÈõªÊ±†Á≥ªÁµ±ÔºåÊØèÂÄãÁ≥ªÁµ±ÊúâÂÖ´ÂÄã‰∏≤ËÅØÈõªÊ±†ÔºåÁ∏ΩË®à 232 ÂÄãÈõªÊ±†Âíå 1.31 ÂÑÑÂàóÊï∏Êìö„ÄÇÊàëÂÄë‰ΩøÁî®ÈÅûËø¥ÊôÇÁ©∫È´òÊñØÈÅéÁ®ãÈñãÁôºÂá∫Ê©üÁéáÊÄßÊïÖÈöúÊ™¢Ê∏¨Ë¶èÂâá„ÄÇÈÄô‰∫õÈÅéÁ®ãÂÖÅË®±Âø´ÈÄüËôïÁêÜË∂ÖÈÅé‰∏ÄÁôæËê¨ÂÄãÊï∏ÊìöÈªûÔºåÂØ¶ÁèæÈÄ≤ÈöéÁ∑ö‰∏äÁõ£ÊéßÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•‰∫ÜËß£ÈõªÊ±†ÁµÑÂú®ÁèæÂ†¥ÁöÑÊïÖÈöú„ÄÇÂàÜÊûêÂº∑Ë™øÔºåÈÄöÂ∏∏Âè™Êúâ‰∏ÄÂÄãÈõªÊ±†È°ØÁ§∫Âá∫Áï∞Â∏∏Ë°åÁÇ∫ÊàñÊãêÈªûÔºåÈÄôËàá‰∏≤ËÅØÈÄ£Êé•ÈõªÊ±†ÁöÑÂº±Áí∞ÊïÖÈöú‰∏ÄËá¥Ôºå‰∏¶Âõ†Â±ÄÈÉ®ÈõªÈòªÂä†ÁÜ±ËÄåÊîæÂ§ß„ÄÇÁµêÊûúÈÄ≤‰∏ÄÊ≠•‰∫ÜËß£ÈõªÊ±†Â¶Ç‰ΩïÂú®ÁèæÂ†¥ÈÄÄÂåñÂíåÊïÖÈöúÔºå‰∏¶Â±ïÁ§∫Âü∫ÊñºÊï∏ÊìöÁöÑÊúâÊïàÁ∑ö‰∏äÁõ£ÊéßÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÂú®ÂÆåÊàêÊú¨ÊñáÂØ©Êü•ÂæåÈñãÊ∫êÁ®ãÂºèÁ¢º‰∏¶ÁôºÂ∏ÉÂ§ßÂûãÊï∏ÊìöÈõÜ„ÄÇ

##### **Multiple Kronecker RLS fusion-based link propagation for drug-side effect prediction**
2407.00105v1 by Yuqing Qian, Ziyu Zheng, Prayag Tiwari, Yijie Ding, Quan Zou

Drug-side effect prediction has become an essential area of research in the
field of pharmacology. As the use of medications continues to rise, so does the
importance of understanding and mitigating the potential risks associated with
them. At present, researchers have turned to data-driven methods to predict
drug-side effects. Drug-side effect prediction is a link prediction problem,
and the related data can be described from various perspectives. To process
these kinds of data, a multi-view method, called Multiple Kronecker RLS
fusion-based link propagation (MKronRLSF-LP), is proposed. MKronRLSF-LP extends
the Kron-RLS by finding the consensus partitions and multiple graph Laplacian
constraints in the multi-view setting. Both of these multi-view settings
contribute to a higher quality result. Extensive experiments have been
conducted on drug-side effect datasets, and our empirical results provide
evidence that our approach is effective and robust.

ÊëòË¶ÅÔºöËó•Áâ©ÂâØ‰ΩúÁî®È†êÊ∏¨Â∑≤ÊàêÁÇ∫Ëó•ÁêÜÂ≠∏È†òÂüüÁöÑÁ†îÁ©∂ÈáçÈªû„ÄÇÈö®ËëóËó•Áâ©‰ΩøÁî®ÊåÅÁ∫åÂ¢ûÂä†Ôºå‰∫ÜËß£ÂíåÊ∏õËºïËàáËó•Áâ©Áõ∏ÈóúÁöÑÊΩõÂú®È¢®Èö™‰πüËÆäÂæóË∂ä‰æÜË∂äÈáçË¶Å„ÄÇÁõÆÂâçÔºåÁ†îÁ©∂‰∫∫Âì°Â∑≤ËΩâÂêëË≥áÊñôÈ©ÖÂãïÁöÑÊñπÊ≥ï‰æÜÈ†êÊ∏¨Ëó•Áâ©ÂâØ‰ΩúÁî®„ÄÇËó•Áâ©ÂâØ‰ΩúÁî®È†êÊ∏¨ÊòØ‰∏ÄÂÄãÈÄ£ÁµêÈ†êÊ∏¨ÂïèÈ°åÔºåÂÖ∂Áõ∏ÈóúË≥áÊñôÂèØ‰ª•Âæû‰∏çÂêåÁöÑËßíÂ∫¶‰æÜÊèèËø∞„ÄÇÁÇ∫‰∫ÜËôïÁêÜÈÄô‰∫õÈ°ûÂûãÁöÑË≥áÊñôÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Â§öÈáç Kronecker RLS ËûçÂêàÂºèÈÄ£ÁµêÂÇ≥Êí≠ (MKronRLSF-LP) ÁöÑÂ§öË¶ñËßíÊñπÊ≥ï„ÄÇMKronRLSF-LP ÈÄèÈÅéÂú®Â§öË¶ñËßíË®≠ÂÆö‰∏≠ÊâæÂá∫ÂÖ±Ë≠òÂàÜÂâ≤ÂíåÂ§öÈáçÂúñÊãâÊôÆÊãâÊñØÁ¥ÑÊùüÔºå‰æÜÂª∂‰º∏ Kron-RLS„ÄÇÈÄôÂÖ©ÂÄãÂ§öË¶ñËßíË®≠ÂÆöÈÉΩÊúâÂä©ÊñºÊèêÂçáÁµêÊûúÂìÅË≥™„ÄÇÊàëÂÄëÂ∑≤Âú®Ëó•Áâ©ÂâØ‰ΩúÁî®Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÊúâÊïà‰∏îÂº∑ÂÅ•„ÄÇ

##### **FedMLP: Federated Multi-Label Medical Image Classification under Task Heterogeneity**
2406.18995v1 by Zhaobin Sun, Nannan Wu, Junjie Shi, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

Cross-silo federated learning (FL) enables decentralized organizations to
collaboratively train models while preserving data privacy and has made
significant progress in medical image classification. One common assumption is
task homogeneity where each client has access to all classes during training.
However, in clinical practice, given a multi-label classification task,
constrained by the level of medical knowledge and the prevalence of diseases,
each institution may diagnose only partial categories, resulting in task
heterogeneity. How to pursue effective multi-label medical image classification
under task heterogeneity is under-explored. In this paper, we first formulate
such a realistic label missing setting in the multi-label FL domain and propose
a two-stage method FedMLP to combat class missing from two aspects: pseudo
label tagging and global knowledge learning. The former utilizes a warmed-up
model to generate class prototypes and select samples with high confidence to
supplement missing labels, while the latter uses a global model as a teacher
for consistency regularization to prevent forgetting missing class knowledge.
Experiments on two publicly-available medical datasets validate the superiority
of FedMLP against the state-of-the-art both federated semi-supervised and noisy
label learning approaches under task heterogeneity. Code is available at
https://github.com/szbonaldo/FedMLP.

ÊëòË¶ÅÔºöË∑®Ë≥áÊñôÂ∫´ËÅØÈÇ¶Â≠∏Áøí (FL) ËÆìÂàÜÊï£ÂºèÁµÑÁπîËÉΩÂ§†Âú®‰øùÁïôË≥áÊñôÈö±ÁßÅÁöÑÂêåÊôÇÂçî‰ΩúË®ìÁ∑¥Ê®°ÂûãÔºå‰∏¶Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÊñπÈù¢ÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇ‰∏ÄÂÄãÂ∏∏Ë¶ãÁöÑÂÅáË®≠ÊòØ‰ªªÂãôÂêåË≥™ÊÄßÔºåÂÖ∂‰∏≠ÊØèÂÄãÂÆ¢Êà∂Á´ØÂú®Ë®ìÁ∑¥ÊúüÈñìÈÉΩÂèØ‰ª•Â≠òÂèñÊâÄÊúâÈ°ûÂà•„ÄÇÁÑ∂ËÄåÔºåÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÔºåÁµ¶ÂÆö‰∏ÄÂÄãÂ§öÊ®ôÁ±§ÂàÜÈ°û‰ªªÂãôÔºåÂèóÈôêÊñºÈÜ´Â≠∏Áü•Ë≠òÁöÑÂ±§Á¥öÂíåÁñæÁóÖÁöÑÊµÅË°åÁéáÔºåÊØèÂÄãÊ©üÊßãÂèØËÉΩÂè™Ë®∫Êñ∑ÈÉ®ÂàÜÈ°ûÂà•ÔºåÂ∞éËá¥‰ªªÂãôÁï∞Ë≥™ÊÄß„ÄÇÂ¶Ç‰ΩïÂú®‰ªªÂãôÁï∞Ë≥™ÊÄß‰∏ãËøΩÊ±ÇÊúâÊïàÁöÑÂ§öÊ®ôÁ±§ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°û‰ªçÊúâÂæÖÊé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÂú®Â§öÊ®ôÁ±§ FL È†òÂüü‰∏≠Âà∂ÂÆöÈÄôÁ®ÆÁèæÂØ¶ÁöÑÊ®ôÁ±§ÈÅ∫Â§±Ë®≠ÂÆöÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂÖ©ÈöéÊÆµÊñπÊ≥ï FedMLP ‰æÜÂæûÂÖ©ÂÄãÊñπÈù¢Ëß£Ê±∫È°ûÂà•ÈÅ∫Â§±ÂïèÈ°åÔºöÂÅΩÊ®ôÁ±§Ê®ôË®òÂíåÂÖ®Â±ÄÁü•Ë≠òÂ≠∏Áøí„ÄÇÂâçËÄÖÂà©Áî®ÁÜ±Ë∫´Ê®°ÂûãÁî¢ÁîüÈ°ûÂà•ÂéüÂûãÔºå‰∏¶ÈÅ∏ÊìáÂÖ∑ÊúâÈ´òÂ∫¶‰ø°ÂøÉÁöÑÊ®£Êú¨‰æÜË£úÂÖÖÈÅ∫Â§±Ê®ôÁ±§ÔºåËÄåÂæåËÄÖ‰ΩøÁî®ÂÖ®Â±ÄÊ®°Âûã‰ΩúÁÇ∫ÊïôÂ∏´ÈÄ≤Ë°å‰∏ÄËá¥ÊÄßÊ≠£ÂâáÂåñÔºå‰ª•Èò≤Ê≠¢ÈÅ∫ÂøòÈÅ∫Â§±È°ûÂà•ÁöÑÁü•Ë≠ò„ÄÇÂú®ÂÖ©ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÈ©óË≠â‰∫Ü FedMLP Âú®‰ªªÂãôÁï∞Ë≥™ÊÄß‰∏ãÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑËÅØÂêàÂçäÁõ£Áù£ÂíåÈõúË®äÊ®ôÁ±§Â≠∏ÁøíÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/szbonaldo/FedMLP ÂèñÂæó„ÄÇ

##### **Alignment For Performance Improvement in Conversation Bots**
2406.18954v1 by Raghav Garg, Kapil Sharma, Shrey Singla

This paper shows that alignment methods can achieve superior adherence to
guardrails compared to instruction fine-tuning alone in conversational agents,
also known as bots, within predefined guidelines or 'guardrails'. It examines
traditional training approaches such as instruction fine-tuning and the recent
advancements in direct alignment methods like Identity Preference Optimization
(IPO), and Kahneman-Tversky Optimization (KTO). The effectiveness of alignment
techniques both pre and post-instruction tuning is highlighted, illustrating
their potential to optimize conversational bots in domains that require strict
adherence to specified rules, such as customer care.

ÊëòË¶ÅÔºöÊú¨ÊñáÈ°ØÁ§∫ÔºåÂú®Â∞çË©±‰ª£ÁêÜÔºà‰πüÁ®±ÁÇ∫Ê©üÂô®‰∫∫Ôºâ‰∏≠ÔºåËàáÂñÆÁç®Â∞çÊåá‰ª§ÈÄ≤Ë°åÂæÆË™øÁõ∏ÊØîÔºåÂ∞çÈΩäÊñπÊ≥ïÂèØ‰ª•ÂØ¶ÁèæÂ∞çÈò≤Ë≠∑Ê¨ÑÁöÑÊõ¥‰Ω≥ÈÅµÂÆàÔºåÈÄôÂú®È†êÂÆöÁæ©ÁöÑÊ∫ñÂâáÊàñ„ÄåÈò≤Ë≠∑Ê¨Ñ„Äç‰∏≠„ÄÇÂÆÉÊé¢Ë®é‰∫ÜÂÇ≥Áµ±ÁöÑË®ìÁ∑¥ÊñπÊ≥ïÔºå‰æãÂ¶ÇÊåá‰ª§ÂæÆË™øÂíåÁõ¥Êé•Â∞çÈΩäÊñπÊ≥ïÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºå‰æãÂ¶ÇË∫´ÂàÜÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (IPO) Âíå Kahneman-Tversky ÊúÄ‰Ω≥Âåñ (KTO)„ÄÇÂº∑Ë™ø‰∫ÜÂ∞çÈΩäÊäÄË°ìÂú®Êåá‰ª§Ë™øÊï¥ÂâçÂæåÁöÑÊúâÊïàÊÄßÔºåË™™Êòé‰∫ÜÂÆÉÂÄëÂú®ÈúÄË¶ÅÂö¥Ê†ºÈÅµÂÆàÁâπÂÆöË¶èÂâáÔºà‰æãÂ¶ÇÂÆ¢Êà∂ÊúçÂãôÔºâÁöÑÈ†òÂüü‰∏≠ÊúÄ‰Ω≥ÂåñÂ∞çË©±Ê©üÂô®‰∫∫ÁöÑÊΩõÂäõ„ÄÇ

##### **AI-Driven Skin Cancer Diagnosis: Grad-CAM and Expert Annotations for Enhanced Interpretability**
2407.00104v1 by Iv√°n Matas, Carmen Serrano, Francisca Silva, Amalia Serrano, Tom√°s Toledo-Pastrana, Bego√±a Acha

An AI tool has been developed to provide interpretable support for the
diagnosis of BCC via teledermatology, thus speeding up referrals and optimizing
resource utilization. The interpretability is provided in two ways: on the one
hand, the main BCC dermoscopic patterns are found in the image to justify the
BCC/Non BCC classification. Secondly, based on the common visual XAI Grad-CAM,
a clinically inspired visual explanation is developed where the relevant
features for diagnosis are located. Since there is no established ground truth
for BCC dermoscopic features, a standard reference is inferred from the
diagnosis of four dermatologists using an Expectation Maximization (EM) based
algorithm. The results demonstrate significant improvements in classification
accuracy and interpretability, positioning this approach as a valuable tool for
early BCC detection and referral to dermatologists. The BCC/non-BCC
classification achieved an accuracy rate of 90%. For Clinically-inspired XAI
results, the detection of BCC patterns useful to clinicians reaches 99%
accuracy. As for the Clinically-inspired Visual XAI results, the mean of the
Grad-CAM normalized value within the manually segmented clinical features is
0.57, while outside this region it is 0.16. This indicates that the model
struggles to accurately identify the regions of the BCC patterns. These results
prove the ability of the AI tool to provide a useful explanation.

ÊëòË¶ÅÔºö<paragraph>Â∑≤ÈñãÁôºÂá∫ AI Â∑•ÂÖ∑ÔºåÈÄèÈÅéÈÅ†Ë∑ùÁöÆËÜöÁßëÊèê‰æõÂèØËß£ÈáãÁöÑÊîØÊè¥‰ª•Ë®∫Êñ∑ BCCÔºåÈÄ≤ËÄåÂä†ÈÄüËΩâË®∫‰∏¶ÂÑ™ÂåñË≥áÊ∫êÂà©Áî®„ÄÇÂèØËß£ÈáãÊÄßÈÄèÈÅéÂÖ©Á®ÆÊñπÂºèÊèê‰æõÔºö‰∏ÄÊñπÈù¢ÔºåÂú®ÂΩ±ÂÉè‰∏≠ÊâæÂà∞‰∏ªË¶ÅÁöÑ BCC ÁöÆËÜöÈè°Ê®°Âºè‰ª•Ë≠âÊòé BCC/Èùû BCC ÂàÜÈ°û„ÄÇÂÖ∂Ê¨°ÔºåÊ†πÊìöÂ∏∏Ë¶ãÁöÑË¶ñË¶∫ XAI Grad-CAMÔºåÈñãÁôºÂá∫‰ª•Ëá®Â∫äÁÇ∫ÈùàÊÑüÁöÑË¶ñË¶∫Ë™™ÊòéÔºåË™™ÊòéË®∫Êñ∑Áõ∏ÈóúÁâπÂæµÁöÑ‰ΩçÁΩÆ„ÄÇÁî±Êñº BCC ÁöÆËÜöÈè°ÁâπÂæµÊ≤íÊúâÊó¢ÂÆöÁöÑÂü∫Êú¨‰∫ãÂØ¶ÔºåÂõ†Ê≠§ÂæûÂõõ‰ΩçÁöÆËÜöÁßëÈÜ´Â∏´ÁöÑË®∫Êñ∑Êé®Ë´ñÂá∫Ê®ôÊ∫ñÂèÉËÄÉÔºå‰ΩøÁî®Âü∫ÊñºÊúüÊúõÊúÄÂ§ßÂåñ (EM) ÁöÑÊºîÁÆóÊ≥ï„ÄÇÁµêÊûúÈ°ØÁ§∫ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÂíåÂèØËß£ÈáãÊÄßÊúâÈ°ØËëóÊîπÂñÑÔºåÂ∞áÊ≠§ÊñπÊ≥ïÂÆö‰ΩçÁÇ∫Êó©Êúü BCC ÂÅµÊ∏¨ÂíåËΩâË®∫Áµ¶ÁöÆËÜöÁßëÈÜ´Â∏´ÁöÑÂØ∂Ë≤¥Â∑•ÂÖ∑„ÄÇBCC/Èùû BCC ÂàÜÈ°ûÈÅîÂà∞ 90% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÂ∞çÊñº‰ª•Ëá®Â∫äÁÇ∫ÈùàÊÑüÁöÑ XAI ÁµêÊûúÔºåÂÅµÊ∏¨Â∞çËá®Â∫äÈÜ´Â∏´ÊúâÁî®ÁöÑ BCC Ê®°ÂºèÈÅîÂà∞ 99% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇËá≥Êñº‰ª•Ëá®Â∫äÁÇ∫ÈùàÊÑüÁöÑË¶ñË¶∫ XAI ÁµêÊûúÔºåÊâãÂãïÂàÜÂâ≤ÁöÑËá®Â∫äÁâπÂæµ‰∏≠ Grad-CAM Ê®ôÊ∫ñÂåñÂÄºÁöÑÂπ≥ÂùáÂÄºÁÇ∫ 0.57ÔºåËÄåÊ≠§ÂçÄÂüüÂ§ñÁöÑÂπ≥ÂùáÂÄºÁÇ∫ 0.16„ÄÇÈÄôË°®Á§∫Ê®°ÂûãÈõ£‰ª•Ê∫ñÁ¢∫Ëæ®Ë≠ò BCC Ê®°ÂºèÁöÑÂçÄÂüü„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé AI Â∑•ÂÖ∑ÊúâËÉΩÂäõÊèê‰æõÊúâÁî®ÁöÑË™™Êòé„ÄÇ</paragraph>

##### **Correspondence-Free Non-Rigid Point Set Registration Using Unsupervised Clustering Analysis**
2406.18817v1 by Mingyang Zhao, Jingen Jiang, Lei Ma, Shiqing Xin, Gaofeng Meng, Dong-Ming Yan

This paper presents a novel non-rigid point set registration method that is
inspired by unsupervised clustering analysis. Unlike previous approaches that
treat the source and target point sets as separate entities, we develop a
holistic framework where they are formulated as clustering centroids and
clustering members, separately. We then adopt Tikhonov regularization with an
$\ell_1$-induced Laplacian kernel instead of the commonly used Gaussian kernel
to ensure smooth and more robust displacement fields. Our formulation delivers
closed-form solutions, theoretical guarantees, independence from dimensions,
and the ability to handle large deformations. Subsequently, we introduce a
clustering-improved Nystr\"om method to effectively reduce the computational
complexity and storage of the Gram matrix to linear, while providing a rigorous
bound for the low-rank approximation. Our method achieves high accuracy results
across various scenarios and surpasses competitors by a significant margin,
particularly on shapes with substantial deformations. Additionally, we
demonstrate the versatility of our method in challenging tasks such as shape
transfer and medical registration.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈùûÂâõÊÄßÈªûÈõÜÈÖçÊ∫ñÊñπÊ≥ïÔºåÂÖ∂ÈùàÊÑü‰æÜËá™ÁÑ°Áõ£Áù£ËÅöÈ°ûÂàÜÊûê„ÄÇËàáÂ∞áÊ∫êÈªûÈõÜÂíåÁõÆÊ®ôÈªûÈõÜË¶ñÁÇ∫Áç®Á´ãÂØ¶È´îÁöÑÂÖàÂâçÊñπÊ≥ï‰∏çÂêåÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊï¥È´îÊ°ÜÊû∂ÔºåÂÖ∂‰∏≠ÂÆÉÂÄëÂàÜÂà•Ë¢´Ë°®Ëø∞ÁÇ∫ËÅöÈ°ûË≥™ÂøÉÂíåËÅöÈ°ûÊàêÂì°„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé°Áî® Tikhonov Ê≠£ÂâáÂåñÂíå $\ell_1$ Ë™òÂ∞éÁöÑÊãâÊôÆÊãâÊñØÊ†∏ÔºåËÄå‰∏çÊòØÂ∏∏Áî®ÁöÑÈ´òÊñØÊ†∏Ôºå‰ª•Á¢∫‰øùÂπ≥Êªë‰∏îÊõ¥Á©©ÂÅ•ÁöÑ‰ΩçÁßªÂ†¥„ÄÇÊàëÂÄëÁöÑÂÖ¨ÂºèÊèê‰æõ‰∫ÜÈñâÂºèËß£„ÄÅÁêÜË´ñ‰øùË≠â„ÄÅÁç®Á´ãÊñºÁ∂≠Â∫¶‰ª•ÂèäËôïÁêÜÂ§ßËÆäÂΩ¢ÁöÑÁöÑËÉΩÂäõ„ÄÇÈö®ÂæåÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆËÅöÈ°ûÊîπÈÄ≤ÁöÑ Nystr\"om ÊñπÊ≥ïÔºå‰ª•ÊúâÊïàÂú∞Â∞á Gram Áü©Èô£ÁöÑË®àÁÆóË§áÈõúÂ∫¶ÂíåÂ≠òÂÑ≤Á©∫ÈñìÈôç‰ΩéÂà∞Á∑öÊÄßÔºåÂêåÊôÇÁÇ∫‰ΩéÁß©Ëøë‰ººÊèê‰æõÂö¥Ê†ºÁöÑÁïåÈôê„ÄÇÊàëÂÄëÁöÑÁÆóÊ≥ïÂú®ÂêÑÁ®ÆÂ†¥ÊôØ‰∏≠ÈÉΩËÉΩÂèñÂæóÈ´òÁ≤æÂ∫¶ÁöÑÁµêÊûúÔºå‰∏¶‰∏îÂ§ßÂπÖË∂ÖË∂äÁ´∂Áà≠Â∞çÊâãÔºåÁâπÂà•ÊòØÂú®ÂΩ¢ÁãÄËÆäÂΩ¢ÂæàÂ§ßÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®ÂΩ¢ÁãÄËΩâÁßªÂíåÈÜ´Â≠∏ÈÖçÊ∫ñÁ≠âÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô‰∏≠Ë≠âÊòé‰∫ÜÊàëÂÄëÁÆóÊ≥ïÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇ

##### **WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech Health Diagnostic Model**
2406.18731v1 by Yi Zhu, Tiago Falk

Speech is known to carry health-related attributes, which has emerged as a
novel venue for remote and long-term health monitoring. However, existing
models are usually tailored for a specific type of disease, and have been shown
to lack generalizability across datasets. Furthermore, concerns have been
raised recently towards the leakage of speaker identity from health embeddings.
To mitigate these limitations, we propose WavRx, a speech health diagnostics
model that captures the respiration and articulation related dynamics from a
universal speech representation. Our in-domain and cross-domain experiments on
six pathological speech datasets demonstrate WavRx as a new state-of-the-art
health diagnostic model. Furthermore, we show that the amount of speaker
identity entailed in the WavRx health embeddings is significantly reduced
without extra guidance during training. An in-depth analysis of the model was
performed, thus providing physiological interpretation of its improved
generalizability and privacy-preserving ability.

ÊëòË¶ÅÔºöË™ûÈü≥Â∑≤Áü•ÊúÉÊâøËºâËàáÂÅ•Â∫∑Áõ∏ÈóúÁöÑÂ±¨ÊÄßÔºåÈÄôÂ∑≤ÊàêÁÇ∫ÈÅ†Ë∑ùÂíåÈï∑ÊúüÂÅ•Â∫∑Áõ£ÊéßÁöÑÊñ∞ÈÄîÂæë„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊ®°ÂûãÈÄöÂ∏∏ÈáùÂ∞çÁâπÂÆöÈ°ûÂûãÁöÑÁñæÁóÖÈáèË∫´ÊâìÈÄ†Ôºå‰∏îÂ∑≤È°ØÁ§∫Âá∫Áº∫‰πèË∑®Ë≥áÊñôÈõÜÁöÑÊ¶ÇÊã¨ÊÄß„ÄÇÊ≠§Â§ñÔºåÊúÄËøëÂ∑≤Â∞çÂæûÂÅ•Â∫∑ÂµåÂÖ•‰∏≠Ê¥©ÊºèË™™Ë©±ËÄÖË∫´ÂàÜÊèêÂá∫ÁñëÊÖÆ„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫ WavRxÔºåÈÄôÊòØ‰∏ÄÁ®ÆË™ûÈü≥ÂÅ•Â∫∑Ë®∫Êñ∑Ê®°ÂûãÔºåÂÆÉÊúÉÊì∑Âèñ‰æÜËá™ÈÄöÁî®Ë™ûÈü≥Ë°®Á§∫ÁöÑÂëºÂê∏ÂíåÁôºÈü≥Áõ∏ÈóúÂãïÊÖã„ÄÇÊàëÂÄëÂú®ÂÖ≠ÂÄãÁóÖÁêÜÊÄßË™ûÈü≥Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÈ†òÂüüÂÖßÂíåË∑®È†òÂüüÂØ¶È©óÔºåË≠âÊòé WavRx ÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÂÅ•Â∫∑Ë®∫Êñ∑Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ°ØÁ§∫ÔºåÂú®Ë®ìÁ∑¥ÊúüÈñìÊ≤íÊúâÈ°çÂ§ñÁöÑÊåáÂ∞é‰∏ãÔºåWavRx ÂÅ•Â∫∑ÂµåÂÖ•‰∏≠ÂåÖÂê´ÁöÑË™™Ë©±ËÄÖË∫´ÂàÜÊï∏ÈáèÂ∑≤È°ØËëóÊ∏õÂ∞ë„ÄÇÂ∞çÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÊ∑±ÂÖ•ÂàÜÊûêÔºåÂæûËÄåÊèê‰æõ‰∫ÜÂÖ∂ÊîπÂñÑÁöÑÊ¶ÇÊã¨ÊÄßÂíåÈö±ÁßÅ‰øùË≠∑ËÉΩÂäõÁöÑÁîüÁêÜËß£Èáã„ÄÇ

##### **Petal-X: Human-Centered Visual Explanations to Improve Cardiovascular Risk Communication**
2406.18690v1 by Diego Rojo, Houda Lamqaddam, Lucija Gosak, Katrien Verbert

Cardiovascular diseases (CVDs), the leading cause of death worldwide, can be
prevented in most cases through behavioral interventions. Therefore, effective
communication of CVD risk and projected risk reduction by risk factor
modification plays a crucial role in reducing CVD risk at the individual level.
However, despite interest in refining risk estimation with improved prediction
models such as SCORE2, the guidelines for presenting these risk estimations in
clinical practice remained essentially unchanged in the last few years, with
graphical score charts (GSCs) continuing to be one of the prevalent systems.
This work describes the design and implementation of Petal-X, a novel tool to
support clinician-patient shared decision-making by explaining the CVD risk
contributions of different factors and facilitating what-if analysis. Petal-X
relies on a novel visualization, Petal Product Plots, and a tailor-made global
surrogate model of SCORE2, whose fidelity is comparable to that of the GSCs
used in clinical practice. We evaluated Petal-X compared to GSCs in a
controlled experiment with 88 healthcare students, all but one with experience
with chronic patients. The results show that Petal-X outperforms GSC in
critical tasks, such as comparing the contribution to the patient's 10-year CVD
risk of each modifiable risk factor, without a significant loss of perceived
transparency, trust, or intent to use. Our study provides an innovative
approach to the visualization and explanation of risk in clinical practice
that, due to its model-agnostic nature, could continue to support
next-generation artificial intelligence risk assessment models.

ÊëòË¶ÅÔºöÂøÉË°ÄÁÆ°ÁñæÁóÖ (CVD) ÊòØÂÖ®ÁêÉ‰∏ªË¶ÅÁöÑÊ≠ª‰∫°ÂéüÂõ†ÔºåÂú®Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÂèØ‰ª•ÈÄöËøáË°å‰∏∫Âπ≤È¢ÑÊù•È¢ÑÈò≤„ÄÇÂõ†Ê≠§ÔºåÈÄöËøáÊîπÂèòÂç±Èô©Âõ†Â≠êÊù•ÊúâÊïàÊ≤üÈÄö CVD È£éÈô©ÂíåÈ¢ÑÊµãÁöÑÈ£éÈô©Èôç‰ΩéÂú®Èôç‰Ωé‰∏™‰∫∫Â±ÇÈù¢ÁöÑ CVD È£éÈô©‰∏≠Ëµ∑ÁùÄËá≥ÂÖ≥ÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇÁÑ∂ËÄåÔºåÂ∞ΩÁÆ°ÊúâÂÖ¥Ë∂£ÈÄöËøáÊîπËøõÁöÑÈ¢ÑÊµãÊ®°ÂûãÔºà‰æãÂ¶Ç SCORE2ÔºâÊù•‰ºòÂåñÈ£éÈô©‰º∞ËÆ°Ôºå‰ΩÜÂú®‰∏¥Â∫äÂÆûË∑µ‰∏≠ÂëàÁé∞Ëøô‰∫õÈ£éÈô©‰º∞ËÆ°ÁöÑÊåáÂçóÂú®ËøáÂéªÂá†Âπ¥‰∏≠Âü∫Êú¨‰∏ä‰øùÊåÅ‰∏çÂèòÔºåÂõæÂΩ¢ËØÑÂàÜÂõæË°® (GSC) ‰ªçÁÑ∂ÊòØÊµÅË°åÁöÑÁ≥ªÁªü‰πã‰∏Ä„ÄÇËøôÈ°πÂ∑•‰ΩúÊèèËø∞‰∫Ü Petal-X ÁöÑËÆæËÆ°ÂíåÂÆûÁé∞ÔºåPetal-X ÊòØ‰∏ÄÁßçÊñ∞Â∑•ÂÖ∑ÔºåÈÄöËøáËß£Èáä‰∏çÂêåÂõ†Á¥†ÂØπ CVD È£éÈô©ÁöÑË¥°ÁåÆÂπ∂‰øÉËøõÂÅáËÆæÂàÜÊûêÊù•ÊîØÊåÅ‰∏¥Â∫äÂåªÁîüÂíåÊÇ£ËÄÖÁöÑÂÖ±ÂêåÂÜ≥Á≠ñ„ÄÇPetal-X ‰æùËµñ‰∫é‰∏ÄÁßçÊñ∞È¢ñÁöÑÂèØËßÜÂåñÂ∑•ÂÖ∑‚Äî‚ÄîËä±Áì£‰∫ßÂìÅÂõæÔºå‰ª•Âèä SCORE2 ÁöÑÂÆöÂà∂ÂÖ®Â±ÄÊõø‰ª£Ê®°ÂûãÔºåÂÖ∂‰øùÁúüÂ∫¶‰∏é‰∏¥Â∫äÂÆûË∑µ‰∏≠‰ΩøÁî®ÁöÑ GSC Áõ∏ÂΩì„ÄÇÊàë‰ª¨Âú®‰∏Ä‰∏™ÂèóÊéßÂÆûÈ™å‰∏≠ËØÑ‰º∞‰∫Ü Petal-X ‰∏é GSC ÁöÑÂØπÊØîÔºåÂÆûÈ™åÂØπË±°‰∏∫ 88 ÂêçÂåªÂ≠¶ÁîüÔºåÈô§‰∏Ä‰∫∫Â§ñÔºåÊâÄÊúâÂ≠¶ÁîüÈÉΩÊúâÊÖ¢ÊÄßÁóÖÊÇ£ËÄÖÁöÑÁªèÈ™å„ÄÇÁªìÊûúË°®ÊòéÔºåPetal-X Âú®ÂÖ≥ÈîÆ‰ªªÂä°‰∏≠‰ºò‰∫é GSCÔºå‰æãÂ¶ÇÊØîËæÉÂèØÊîπÂèòÂç±Èô©Âõ†Â≠êÂØπÊÇ£ËÄÖ 10 Âπ¥ CVD È£éÈô©ÁöÑË¥°ÁåÆÔºåËÄå‰∏ç‰ºöÊòæÁùÄÈôç‰ΩéÊÑüÁü•ÁöÑÈÄèÊòéÂ∫¶„ÄÅ‰ø°‰ªªÂ∫¶Êàñ‰ΩøÁî®ÊÑèÊÑø„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÁßçÂàõÊñ∞ÁöÑÊñπÊ≥ïÊù•ÂèØËßÜÂåñÂíåËß£Èáä‰∏¥Â∫äÂÆûË∑µ‰∏≠ÁöÑÈ£éÈô©ÔºåÁî±‰∫éÂÖ∂‰∏éÊ®°ÂûãÊó†ÂÖ≥ÁöÑÊÄßË¥®ÔºåÂèØ‰ª•ÁªßÁª≠ÊîØÊåÅ‰∏ã‰∏Ä‰ª£‰∫∫Â∑•Êô∫ËÉΩÈ£éÈô©ËØÑ‰º∞Ê®°Âûã„ÄÇ

##### **Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process**
2406.18361v2 by Tianyu Lin, Zhiguang Chen, Zhonghao Yan, Weijiang Yu, Fudan Zheng

Diffusion models have demonstrated their effectiveness across various
generative tasks. However, when applied to medical image segmentation, these
models encounter several challenges, including significant resource and time
requirements. They also necessitate a multi-step reverse process and multiple
samples to produce reliable predictions. To address these challenges, we
introduce the first latent diffusion segmentation model, named SDSeg, built
upon stable diffusion (SD). SDSeg incorporates a straightforward latent
estimation strategy to facilitate a single-step reverse process and utilizes
latent fusion concatenation to remove the necessity for multiple samples.
Extensive experiments indicate that SDSeg surpasses existing state-of-the-art
methods on five benchmark datasets featuring diverse imaging modalities.
Remarkably, SDSeg is capable of generating stable predictions with a solitary
reverse step and sample, epitomizing the model's stability as implied by its
name. The code is available at
https://github.com/lin-tianyu/Stable-Diffusion-Seg

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÂ∑≤Ë≠âÊòéÂÖ∂Âú®ÂêÑÁ®ÆÁîüÊàê‰ªªÂãô‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ËÄåÔºåÁï∂ÊáâÁî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊôÇÔºåÈÄô‰∫õÊ®°ÂûãÊúÉÈÅáÂà∞‰∏Ä‰∫õÊåëÊà∞ÔºåÂåÖÊã¨È°ØËëóÁöÑË≥áÊ∫êÂíåÊôÇÈñìÈúÄÊ±Ç„ÄÇÂÆÉÂÄëÈÇÑÈúÄË¶Å‰∏ÄÂÄãÂ§öÊ≠•È©üÁöÑÂèçÂêëËôïÁêÜÂíåÂ§öÂÄãÊ®£Êú¨ÊâçËÉΩÁî¢ÁîüÂèØÈù†ÁöÑÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ¨¨‰∏ÄÂÄãÊΩõÂú®Êì¥Êï£ÂàÜÂâ≤Ê®°ÂûãÔºåÂêçÁÇ∫ SDSegÔºåÂª∫Á´ãÂú®Á©©ÂÆöÊì¥Êï£ (SD) ‰πã‰∏ä„ÄÇSDSeg ÁµêÂêà‰∫Ü‰∏ÄÂÄãÁõ¥Êé•ÁöÑÊΩõÂú®‰º∞Ë®àÁ≠ñÁï•Ôºå‰ª•‰øÉÈÄ≤ÂñÆÊ≠•ÂèçÂêëËôïÁêÜÔºå‰∏¶Âà©Áî®ÊΩõÂú®ËûçÂêà‰∏≤Êé•‰æÜÊ∂àÈô§Â∞çÂ§öÂÄãÊ®£Êú¨ÁöÑÈúÄË¶Å„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË°®ÊòéÔºåSDSeg Âú®ÂÖ∑Êúâ‰∏çÂêåÂΩ±ÂÉèÊ®°ÂºèÁöÑ‰∫îÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÊñπÊ≥ï„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåSDSeg ËÉΩÂ§†ÈÄöÈÅéÂñÆÁç®ÁöÑÂèçÂêëÊ≠•È©üÂíåÊ®£Êú¨ÁîüÊàêÁ©©ÂÆöÁöÑÈ†êÊ∏¨ÔºåÈÄôÈ´îÁèæ‰∫ÜË©≤Ê®°ÂûãÁöÑÁ©©ÂÆöÊÄßÔºåÊ≠£Â¶ÇÂÖ∂ÂêçÁ®±ÊâÄÊöóÁ§∫ÁöÑÈÇ£Ê®£„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/lin-tianyu/Stable-Diffusion-Seg Áç≤Âæó

##### **Automatic Prediction of Amyotrophic Lateral Sclerosis Progression using Longitudinal Speech Transformer**
2406.18625v1 by Liming Wang, Yuan Gong, Nauman Dawalatabad, Marco Vilela, Katerina Placek, Brian Tracey, Yishu Gong, Alan Premasiri, Fernando Vieira, James Glass

Automatic prediction of amyotrophic lateral sclerosis (ALS) disease
progression provides a more efficient and objective alternative than manual
approaches. We propose ALS longitudinal speech transformer (ALST), a neural
network-based automatic predictor of ALS disease progression from longitudinal
speech recordings of ALS patients. By taking advantage of high-quality
pretrained speech features and longitudinal information in the recordings, our
best model achieves 91.0\% AUC, improving upon the previous best model by 5.6\%
relative on the ALS TDI dataset. Careful analysis reveals that ALST is capable
of fine-grained and interpretable predictions of ALS progression, especially
for distinguishing between rarer and more severe cases. Code is publicly
available.

ÊëòË¶ÅÔºöËÇåËêéÁº©ÊÄß‰æßÁ¥¢Á°¨ÂåñÁóá (ALS) ÁñæÁóÖËøõÂ±ïÁöÑËá™Âä®È¢ÑÊµãÊèê‰æõ‰∫ÜÊØîÊâãÂä®ÊñπÊ≥ïÊõ¥ÊúâÊïà‰∏îÂÆ¢ËßÇÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü ALS Á∫µÂêëËØ≠Èü≥ËΩ¨Êç¢Âô® (ALST)ÔºåËøôÊòØ‰∏ÄÁßçÂü∫‰∫éÁ•ûÁªèÁΩëÁªúÁöÑ ALS ÁñæÁóÖËøõÂ±ïËá™Âä®È¢ÑÊµãÂô®ÔºåÂèØ‰ªé ALS ÊÇ£ËÄÖÁöÑÁ∫µÂêëËØ≠Èü≥ËÆ∞ÂΩï‰∏≠ËøõË°åÈ¢ÑÊµã„ÄÇÈÄöËøáÂà©Áî®ÂΩïÈü≥‰∏≠È´òË¥®ÈáèÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Èü≥ÁâπÂæÅÂíåÁ∫µÂêë‰ø°ÊÅØÔºåÊàë‰ª¨ÁöÑÊúÄ‰Ω≥Ê®°ÂûãÂÆûÁé∞‰∫Ü 91.0% ÁöÑ AUCÔºåÁõ∏ÂØπ‰∫é ALS TDI Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÖàÂâçÊúÄ‰Ω≥Ê®°ÂûãÊèêÈ´ò‰∫Ü 5.6%„ÄÇ‰ªîÁªÜÂàÜÊûêË°®ÊòéÔºåALST ËÉΩÂ§üÂØπ ALS ËøõÂ±ïËøõË°åÁªÜÁ≤íÂ∫¶‰∏îÂèØËß£ÈáäÁöÑÈ¢ÑÊµãÔºåÂ∞§ÂÖ∂ÊòØÂú®Âå∫ÂàÜÁΩïËßÅÁóÖ‰æãÂíå‰∏•ÈáçÁóÖ‰æãÊñπÈù¢„ÄÇ‰ª£Á†ÅÂ∑≤ÂÖ¨ÂºÄ„ÄÇ

##### **EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models**
2406.18087v1 by Chun-Chieh Liao, Wei-Ting Kuo, I-Hsuan Hu, Yen-Chen Shih, Jun-En Ding, Feng Liu, Fang-Ming Hung

Traditional diagnosis of chronic diseases involves in-person consultations
with physicians to identify the disease. However, there is a lack of research
focused on predicting and developing application systems using clinical notes
and blood test values. We collected five years of Electronic Health Records
(EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database.
Furthermore, we developed an EHR-based chronic disease prediction platform
utilizing Large Language Multimodal Models (LLMMs), successfully integrating
with frontend web and mobile applications for prediction. This prediction
platform can also connect to the hospital's backend database, providing
physicians with real-time risk assessment diagnostics. The demonstration link
can be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.

ÊëòË¶ÅÔºöÂÇ≥Áµ±ÊÖ¢ÊÄßÁóÖÁöÑË®∫Êñ∑Ê∂âÂèäË¶™Ëá™Ë´ÆË©¢ÈÜ´Â∏´‰ª•ÊâæÂá∫ÁñæÁóÖ„ÄÇÁÑ∂ËÄåÔºåÁº∫‰πèÈáùÂ∞ç‰ΩøÁî®Ëá®Â∫äÁ≠ÜË®òÂíåË°ÄÊ∂≤Ê™¢È©óÂÄº‰æÜÈ†êÊ∏¨ÂíåÈñãÁôºÊáâÁî®Á≥ªÁµ±ÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÂæû2017Âπ¥Âà∞2021Âπ¥ÈñìÊî∂ÈõÜ‰∫ÜÂè∞ÁÅ£ÈÜ´Èô¢Ë≥áÊñôÂ∫´‰∏≠‰∫îÂπ¥ÁöÑÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑÔºàEHRÔºâ‰ΩúÁÇ∫AIË≥áÊñôÂ∫´„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂü∫ÊñºEHRÁöÑÊÖ¢ÊÄßÁóÖÈ†êÊ∏¨Âπ≥Âè∞ÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÂ§öÊ®°ÊÖãÊ®°ÂûãÔºàLLMMÔºâÔºåÊàêÂäüÊï¥ÂêàÂâçÁ´ØÁ∂≤Ë∑ØÂíåË°åÂãïÊáâÁî®Á®ãÂºèÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇÈÄôÂÄãÈ†êÊ∏¨Âπ≥Âè∞‰πüÂèØ‰ª•ÈÄ£Êé•Âà∞ÈÜ´Èô¢ÁöÑÂæåÁ´ØË≥áÊñôÂ∫´ÔºåÁÇ∫ÈÜ´Â∏´Êèê‰æõÂç≥ÊôÇÈ¢®Èö™Ë©ï‰º∞Ë®∫Êñ∑„ÄÇÁ§∫ÁØÑÈÄ£ÁµêÂèØ‰ª•Âú®https://www.youtube.com/watch?v=oqmL9DEDFgAÊâæÂà∞„ÄÇ

##### **Few-Shot Medical Image Segmentation with High-Fidelity Prototypes**
2406.18074v1 by Song Tang, Shaxu Yan, Xiaozhi Qi, Jianxin Gao, Mao Ye, Jianwei Zhang, Xiatian Zhu

Few-shot Semantic Segmentation (FSS) aims to adapt a pretrained model to new
classes with as few as a single labelled training sample per class. Despite the
prototype based approaches have achieved substantial success, existing models
are limited to the imaging scenarios with considerably distinct objects and not
highly complex background, e.g., natural images. This makes such models
suboptimal for medical imaging with both conditions invalid. To address this
problem, we propose a novel Detail Self-refined Prototype Network (DSPNet) to
constructing high-fidelity prototypes representing the object foreground and
the background more comprehensively. Specifically, to construct global
semantics while maintaining the captured detail semantics, we learn the
foreground prototypes by modelling the multi-modal structures with clustering
and then fusing each in a channel-wise manner. Considering that the background
often has no apparent semantic relation in the spatial dimensions, we integrate
channel-specific structural information under sparse channel-aware regulation.
Extensive experiments on three challenging medical image benchmarks show the
superiority of DSPNet over previous state-of-the-art methods.

ÊëòË¶ÅÔºöÂ∞ëÊ†∑Êú¨ËØ≠‰πâÂàÜÂâ≤ (FSS) Êó®Âú®‰ª•ÊØèÁ±ª‰ªÖ‰∏Ä‰∏™Ê†áËÆ∞ËÆ≠ÁªÉÊ†∑Êú¨ÁöÑÊñπÂºèÂ∞ÜÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãË∞ÉÊï¥Âà∞Êñ∞Á±ª„ÄÇÂ∞ΩÁÆ°Âü∫‰∫éÂéüÂûãÁöÑÂäûÊ≥ïÂ∑≤ÂèñÂæóÈáçÂ§ßÊàêÂäüÔºå‰ΩÜÁé∞ÊúâÊ®°Âûã‰ªÖÈôê‰∫éÂØπË±°ÊòéÊòæ‰∏çÂêå‰∏îËÉåÊôØ‰∏çÂ§™Â§çÊùÇÁöÑÊàêÂÉèÂú∫ÊôØÔºå‰æãÂ¶ÇËá™ÁÑ∂ÂõæÂÉè„ÄÇËøô‰ΩøÂæóÊ≠§Á±ªÊ®°Âûã‰∏çÈÄÇÁî®‰∫éÂêåÊó∂‰∏çÊª°Ë∂≥Ëøô‰∏§‰∏™Êù°‰ª∂ÁöÑÂåªÂ≠¶ÂΩ±ÂÉè„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁªÜËäÇËá™Á≤æÁÇºÂéüÂûãÁΩëÁªú (DSPNet)Ôºå‰ª•ÊûÑÂª∫È´ò‰øùÁúüÂéüÂûãÔºåÊõ¥ÂÖ®Èù¢Âú∞Ë°®Á§∫ÂØπË±°ÂâçÊôØÂíåËÉåÊôØ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰∏∫‰∫ÜÂú®‰øùÊåÅÊçïËé∑ÁöÑÁªÜËäÇËØ≠‰πâÁöÑÂêåÊó∂ÊûÑÂª∫ÂÖ®Â±ÄËØ≠‰πâÔºåÊàë‰ª¨ÈÄöËøá‰ΩøÁî®ËÅöÁ±ªÂØπÂ§öÊ®°ÊÄÅÁªìÊûÑËøõË°åÂª∫Ê®°ÔºåÁÑ∂Âêé‰ª•ÈÄêÈÄöÈÅìÁöÑÊñπÂºèËûçÂêàÊØè‰∏™ÁªìÊûÑÔºå‰ªéËÄåÂ≠¶‰π†ÂâçÊôØÂéüÂûã„ÄÇËÄÉËôëÂà∞ËÉåÊôØÂú®Á©∫Èó¥Áª¥Â∫¶‰∏äÈÄöÂ∏∏Ê≤°ÊúâÊòéÊòæÁöÑËØ≠‰πâÂÖ≥Á≥ªÔºåÊàë‰ª¨Âú®Á®ÄÁñèÈÄöÈÅìÊÑüÁü•Ë∞ÉËäÇ‰∏ãÊï¥ÂêàÁâπÂÆö‰∫éÈÄöÈÅìÁöÑÁªìÊûÑ‰ø°ÊÅØ„ÄÇÂú®‰∏â‰∏™ÊûÅÂÖ∑ÊåëÊàòÊÄßÁöÑÂåªÂ≠¶ÂΩ±ÂÉèÂü∫ÂáÜ‰∏äËøõË°åÁöÑÂπøÊ≥õÂÆûÈ™åË°®ÊòéÔºåDSPNet ‰ºò‰∫é‰ª•ÂâçÊúÄÂÖàËøõÁöÑÊñπÊ≥ï„ÄÇ

##### **Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources**
2406.18049v1 by Yiming Li, Deepthi Viswaroopan, William He, Jianfu Li, Xu Zuo, Hua Xu, Cui Tao

Adverse event (AE) extraction following COVID-19 vaccines from text data is
crucial for monitoring and analyzing the safety profiles of immunizations.
Traditional deep learning models are adept at learning intricate feature
representations and dependencies in sequential data, but often require
extensive labeled data. In contrast, large language models (LLMs) excel in
understanding contextual information, but exhibit unstable performance on named
entity recognition tasks, possibly due to their broad but unspecific training.
This study aims to evaluate the effectiveness of LLMs and traditional deep
learning models in AE extraction, and to assess the impact of ensembling these
models on performance. In this study, we utilized reports and posts from the
VAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal
was to extract three types of entities: "vaccine", "shot", and "ae". We
explored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,
GPT-4, and Llama-2, as well as traditional deep learning models like RNN and
BioBERT. To enhance performance, we created ensembles of the three models with
the best performance. For evaluation, we used strict and relaxed F1 scores to
evaluate the performance for each entity type, and micro-average F1 was used to
assess the overall performance. The ensemble model achieved the highest
performance in "vaccine", "shot", and "ae" with strict F1-scores of 0.878,
0.930, and 0.925, respectively, along with a micro-average score of 0.903. In
conclusion, this study demonstrates the effectiveness and robustness of
ensembling fine-tuned traditional deep learning models and LLMs, for extracting
AE-related information. This study contributes to the advancement of biomedical
natural language processing, providing valuable insights into improving AE
extraction from text data for pharmacovigilance and public health surveillance.

ÊëòË¶ÅÔºöÂæûÊñáÊú¨Ë≥áÊñô‰∏≠Êì∑Âèñ COVID-19 Áñ´ËãóÁöÑ‰∏çËâØ‰∫ã‰ª∂ (AE) Â∞çÊñºÁõ£ÊéßÂíåÂàÜÊûêÂÖçÁñ´ÁöÑÂÆâÂÖ®ÊÄßÈùûÂ∏∏ÈáçË¶Å„ÄÇÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÊìÖÈï∑Â≠∏ÁøíÂ∫èÂàóË≥áÊñô‰∏≠ÁöÑË§áÈõúÁâπÂæµË°®Á§∫Âíå‰æùË≥¥Èóú‰øÇÔºå‰ΩÜÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊ®ôÁ±§Ë≥áÊñô„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÖÈï∑ÁêÜËß£‰∏ä‰∏ãÊñáË≥áË®äÔºå‰ΩÜÂú®ÂëΩÂêçÂØ¶È´îË≠òÂà•‰ªªÂãô‰∏äÁöÑË°®Áèæ‰∏çÁ©©ÂÆöÔºåÈÄôÂèØËÉΩÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÁöÑË®ìÁ∑¥ÁØÑÂúçÂª£Ê≥õ‰ΩÜÁº∫‰πèÈáùÂ∞çÊÄß„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Ë©ï‰º∞ LLM ÂíåÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂú® AE Êì∑Âèñ‰∏≠ÁöÑÊúâÊïàÊÄßÔºå‰∏¶Ë©ï‰º∞Â∞áÈÄô‰∫õÊ®°ÂûãÁµÑÊàêÁöÑÂΩ±Èüø„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂà©Áî® VAERS (n=621)„ÄÅTwitter (n=9,133) Âíå Reddit (n=131) ÁöÑÂ†±ÂëäÂíåÊñáÁ´†‰ΩúÁÇ∫Ë™ûÊñôÂ∫´„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÊì∑Âèñ‰∏âÁ®ÆÈ°ûÂûãÁöÑÂØ¶È´îÔºö„ÄåÁñ´Ëãó„Äç„ÄÅ„ÄåÊ≥®Â∞Ñ„ÄçÂíå„Äå‰∏çËâØ‰∫ã‰ª∂„Äç„ÄÇÊàëÂÄëÊé¢Á¥¢‰∏¶ÂæÆË™ø‰∫ÜÂ§öÂÄã LLMÔºåÂåÖÊã¨ GPT-2„ÄÅGPT-3.5„ÄÅGPT-4 Âíå Llama-2Ôºå‰ª•ÂèäÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºå‰æãÂ¶Ç RNN Âíå BioBERTÔºàGPT-4 Èô§Â§ñÔºâ„ÄÇÁÇ∫‰∫ÜÊèêÂçáÊïàËÉΩÔºåÊàëÂÄëÂª∫Á´ã‰∫ÜË°®ÁèæÊúÄ‰Ω≥ÁöÑ‰∏âÂÄãÊ®°ÂûãÁöÑÈõÜÂêà„ÄÇÂú®Ë©ï‰º∞ÊñπÈù¢ÔºåÊàëÂÄë‰ΩøÁî®Âö¥Ê†ºÂíåÊîæÂØ¨ÁöÑ F1 ÂàÜÊï∏‰æÜË©ï‰º∞ÊØèÂÄãÂØ¶È´îÈ°ûÂûãÁöÑÊïàËÉΩÔºå‰∏¶‰ΩøÁî®ÂæÆÂπ≥Âùá F1 ‰æÜË©ï‰º∞Êï¥È´îÊïàËÉΩ„ÄÇÁµÑÂêàÊ®°ÂûãÂú®„ÄåÁñ´Ëãó„Äç„ÄÅ„ÄåÊ≥®Â∞Ñ„ÄçÂíå„Äå‰∏çËâØ‰∫ã‰ª∂„Äç‰∏≠ÂàÜÂà•‰ª• 0.878„ÄÅ0.930 Âíå 0.925 ÁöÑÂö¥Ê†º F1 ÂàÜÊï∏Áç≤ÂæóÊúÄÈ´òÊïàËÉΩÔºåÂæÆÂπ≥ÂùáÂàÜÊï∏ÁÇ∫ 0.903„ÄÇÁµêË´ñÊòØÔºåÊú¨Á†îÁ©∂Ë≠âÊòé‰∫ÜÂæÆË™øÂæåÁöÑÂÇ≥Áµ±Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂíå LLM ÁöÑÈõÜÂêàÂú®Êì∑ÂèñËàá AE Áõ∏ÈóúÁöÑË≥áË®äÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇÊú¨Á†îÁ©∂ÊúâÂä©Êñº‰øÉÈÄ≤ÁîüÁâ©ÈÜ´Â≠∏Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºå‰∏¶Êèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£Ôºå‰ª•ÊîπÂñÑËó•Áâ©Ë≠¶ÊàíÂíåÂÖ¨ÂÖ±Ë°õÁîüÁõ£Ê∏¨‰∏≠ÂæûÊñáÊú¨Ë≥áÊñô‰∏≠Êì∑Âèñ AE ÁöÑÊñπÂºè„ÄÇ

##### **Automated Clinical Data Extraction with Knowledge Conditioned LLMs**
2406.18027v1 by Diya Li, Asim Kadav, Aijing Gao, Rui Li, Richard Bourgon

The extraction of lung lesion information from clinical and medical imaging
reports is crucial for research on and clinical care of lung-related diseases.
Large language models (LLMs) can be effective at interpreting unstructured text
in reports, but they often hallucinate due to a lack of domain-specific
knowledge, leading to reduced accuracy and posing challenges for use in
clinical settings. To address this, we propose a novel framework that aligns
generated internal knowledge with external knowledge through in-context
learning (ICL). Our framework employs a retriever to identify relevant units of
internal or external knowledge and a grader to evaluate the truthfulness and
helpfulness of the retrieved internal-knowledge rules, to align and update the
knowledge bases. Our knowledge-conditioned approach also improves the accuracy
and reliability of LLM outputs by addressing the extraction task in two stages:
(i) lung lesion finding detection and primary structured field parsing,
followed by (ii) further parsing of lesion description text into additional
structured fields. Experiments with expert-curated test datasets demonstrate
that this ICL approach can increase the F1 score for key fields (lesion size,
margin and solidity) by an average of 12.9% over existing ICL methods.

ÊëòË¶ÅÔºöÂæûËá®Â∫äÂíåÈÜ´Â≠∏ÂΩ±ÂÉèÂ†±Âëä‰∏≠ËêÉÂèñËÇ∫ÈÉ®ÁóÖÁÅ∂Ë≥áË®äÂ∞çÊñºËÇ∫ÈÉ®Áõ∏ÈóúÁñæÁóÖÁöÑÁ†îÁ©∂ÂíåËá®Â∫äÁÖßË≠∑Ëá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•ÊúâÊïàËß£ËÆÄÂ†±Âëä‰∏≠ÁöÑÈùûÁµêÊßãÂåñÊñáÂ≠óÔºå‰ΩÜÁî±ÊñºÁº∫‰πèÁâπÂÆöÈ†òÂüüÁü•Ë≠òÔºåÂÆÉÂÄëÁ∂ìÂ∏∏ÊúÉÂá∫ÁèæÂπªË¶∫ÔºåÂ∞éËá¥Ê∫ñÁ¢∫Â∫¶Èôç‰ΩéÔºå‰∏¶Â∞çÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠‰ΩøÁî®Â∏∂‰æÜÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊ°ÜÊû∂ÔºåÈÄèÈÅéËÑàÁµ°‰∏≠Â≠∏Áøí (ICL) Â∞áÁî¢ÁîüÁöÑÂÖßÈÉ®Áü•Ë≠òËàáÂ§ñÈÉ®Áü•Ë≠òÂ∞çÈΩä„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂Êé°Áî®Ê™¢Á¥¢Âô®‰æÜË≠òÂà•ÂÖßÈÉ®ÊàñÂ§ñÈÉ®Áü•Ë≠òÁöÑÁõ∏ÂÖ≥ÂñÆÂÖÉÔºå‰∏¶Êé°Áî®Ë©ïÂàÜÂô®‰æÜË©ï‰º∞Ê™¢Á¥¢Âà∞ÁöÑÂÖßÈÉ®Áü•Ë≠òË¶èÂâáÁöÑÁúüÂØ¶ÊÄßÂíåÊúâÁõäÊÄßÔºå‰ª•Â∞çÈΩäÂíåÊõ¥Êñ∞Áü•Ë≠òÂ∫´„ÄÇÊàëÂÄë‰ª•Áü•Ë≠òÁÇ∫Ê¢ù‰ª∂ÁöÑÊñπÊ≥ï‰πüÈÄèÈÅé‰ª•‰∏ãÂÖ©ÂÄãÈöéÊÆµ‰æÜËôïÁêÜËêÉÂèñ‰ªªÂãôÔºåÈÄ≤ËÄåÊèêÈ´ò LLM Ëº∏Âá∫ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄßÔºö(i) ËÇ∫ÈÉ®ÁóÖÁÅ∂ÁôºÁèæÂÅµÊ∏¨Âíå‰∏ªË¶ÅÁµêÊßãÂåñÊ¨Ñ‰ΩçÂàÜÊûêÔºåÊé•ËëóÊòØ (ii) ÈÄ≤‰∏ÄÊ≠•Â∞áÁóÖÁÅ∂ÊèèËø∞ÊñáÂ≠óÂàÜÊûêÁÇ∫ÂÖ∂‰ªñÁµêÊßãÂåñÊ¨Ñ‰Ωç„ÄÇ‰ΩøÁî®Â∞àÂÆ∂Á≠ñÂ±ïÁöÑÊ∏¨Ë©¶Ë≥áÊñôÈõÜÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòéÔºåÈÄôÂÄã ICL ÊñπÊ≥ïÂèØ‰ª•Â∞áÈóúÈçµÊ¨Ñ‰Ωç (ÁóÖÁÅ∂Â§ßÂ∞è„ÄÅÈÇäÁ∑£ÂíåÂØ¶ÂøÉÂ∫¶) ÁöÑ F1 ÂàÜÊï∏Âπ≥ÂùáÊèêÈ´ò 12.9%ÔºåÂÑ™ÊñºÁèæÊúâÁöÑ ICL ÊñπÊ≥ï„ÄÇ

##### **AutoOPE: Automated Off-Policy Estimator Selection**
2406.18022v1 by Nicol√≤ Felicioni, Michael Benigni, Maurizio Ferrari Dacrema

The Off-Policy Evaluation (OPE) problem consists of evaluating the
performance of counterfactual policies with data collected by another one. This
problem is of utmost importance for various application domains, e.g.,
recommendation systems, medical treatments, and many others. To solve the OPE
problem, we resort to estimators, which aim to estimate in the most accurate
way possible the performance that the counterfactual policies would have had if
they were deployed in place of the logging policy. In the literature, several
estimators have been developed, all with different characteristics and
theoretical guarantees. Therefore, there is no dominant estimator, and each
estimator may be the best one for different OPE problems, depending on the
characteristics of the dataset at hand. While the selection of the estimator is
a crucial choice for an accurate OPE, this problem has been widely overlooked
in the literature. We propose an automated data-driven OPE estimator selection
method based on machine learning. In particular, the core idea we propose in
this paper is to create several synthetic OPE tasks and use a machine learning
model trained to predict the best estimator for those synthetic tasks. We
empirically show how our method is able to generalize to unseen tasks and make
a better estimator selection compared to a baseline method on several
real-world datasets, with a computational cost significantly lower than the one
of the baseline.

ÊëòË¶ÅÔºöÈõ¢Á∑öÁ≠ñÁï•Ë©ï‰º∞ (OPE) ÂïèÈ°åÂåÖÂê´‰ΩøÁî®Áî±ÂÖ∂‰ªñÊîøÁ≠ñÊî∂ÈõÜÁöÑË≥áÊñôË©ï‰º∞Âèç‰∫ãÂØ¶ÊîøÁ≠ñÁöÑÊïàËÉΩ„ÄÇÊ≠§ÂïèÈ°åÂ∞çÊñºÂêÑÁ®ÆÊáâÁî®È†òÂüüËá≥ÈóúÈáçË¶ÅÔºå‰æãÂ¶ÇÊé®Ëñ¶Á≥ªÁµ±„ÄÅÈÜ´ÁôÇÊ≤ªÁôÇÁ≠â„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ OPE ÂïèÈ°åÔºåÊàëÂÄëÊ±ÇÂä©Êñº‰º∞Ë®àÂô®ÔºåÂÖ∂ÁõÆÊ®ôÊòØ‰ª•ÊúÄÁ≤æÁ¢∫ÁöÑÊñπÂºè‰º∞Ë®àÂèç‰∫ãÂØ¶ÊîøÁ≠ñÂú®ÈÉ®ÁΩ≤ÊñºË®òÈåÑÊîøÁ≠ñÊôÇÊâÄÂÖ∑ÂÇôÁöÑÊïàËÉΩ„ÄÇÂú®ÊñáÁçª‰∏≠ÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Â§öÂÄã‰º∞Ë®àÂô®ÔºåÊØèÂÄã‰º∞Ë®àÂô®ÈÉΩÂÖ∑Êúâ‰∏çÂêåÁöÑÁâπÊÄßÂíåÁêÜË´ñ‰øùË≠â„ÄÇÂõ†Ê≠§ÔºåÊ≤íÊúâ‰∏ªÂ∞é‰º∞Ë®àÂô®ÔºåÊØèÂÄã‰º∞Ë®àÂô®ÂèØËÉΩÊòØ‰∏çÂêå OPE ÂïèÈ°åÁöÑÊúÄ‰Ω≥‰º∞Ë®àÂô®ÔºåÂÖ∑È´îÂèñÊ±∫ÊñºÊâãÈÇäË≥áÊñôÈõÜÁöÑÁâπÂæµ„ÄÇÈõñÁÑ∂‰º∞Ë®àÂô®ÁöÑÈÅ∏ÊìáÂ∞çÊñºÊ∫ñÁ¢∫ÁöÑ OPE Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÈÄôÂÄãÂïèÈ°åÂú®ÊñáÁçª‰∏≠Â∑≤Ë¢´Âª£Ê≥õÂøΩË¶ñ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÊ©üÂô®Â≠∏ÁøíÁöÑËá™ÂãïÂåñË≥áÊñôÈ©ÖÂãï OPE ‰º∞Ë®àÂô®ÈÅ∏ÊìáÊñπÊ≥ï„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂú®ÈÄôÁØáË´ñÊñá‰∏≠ÊèêÂá∫ÁöÑÊ†∏ÂøÉÊ¶ÇÂøµÊòØÂª∫Á´ãÂπæÂÄãÂêàÊàê OPE ‰ªªÂãôÔºå‰∏¶‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãË®ìÁ∑¥‰æÜÈ†êÊ∏¨ÈÄô‰∫õÂêàÊàê‰ªªÂãôÁöÑÊúÄ‰Ω≥‰º∞Ë®àÂô®„ÄÇÊàëÂÄë‰ª•ÂØ¶Ë≠âÊñπÂºèË™™ÊòéÊàëÂÄëÁöÑÊ®°ÂûãÂ¶Ç‰ΩïËÉΩÂ§†Ê¶ÇÂåñÁÇ∫Êú™Ë¶ã‰ªªÂãôÔºå‰∏¶Âú®ÂπæÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äËàáÂü∫Á∑öÊñπÊ≥ïÁõ∏ÊØîÔºåÂÅöÂá∫Êõ¥Â•ΩÁöÑ‰º∞Ë®àÂô®ÈÅ∏ÊìáÔºå‰∏îÈÅãÁÆóÊàêÊú¨ÈÅ†‰ΩéÊñºÂü∫Á∑öÊñπÊ≥ï„ÄÇ

##### **Multi-step Knowledge Retrieval and Inference over Unstructured Data**
2406.17987v1 by Aditya Kalyanpur, Kailash Saravanakumar, Victor Barres, CJ McFate, Lori Moon, Nati Seifu, Maksim Eremeev, Jose Barrera, Eric Brown, David Ferrucci

The advent of Large Language Models (LLMs) and Generative AI has
revolutionized natural language applications across various domains. However,
high-stakes decision-making tasks in fields such as medical, legal and finance
require a level of precision, comprehensiveness, and logical consistency that
pure LLM or Retrieval-Augmented-Generation (RAG) approaches often fail to
deliver. At Elemental Cognition (EC), we have developed a neuro-symbolic AI
platform to tackle these problems. The platform integrates fine-tuned LLMs for
knowledge extraction and alignment with a robust symbolic reasoning engine for
logical inference, planning and interactive constraint solving. We describe
Cora, a Collaborative Research Assistant built on this platform, that is
designed to perform complex research and discovery tasks in high-stakes
domains. This paper discusses the multi-step inference challenges inherent in
such domains, critiques the limitations of existing LLM-based methods, and
demonstrates how Cora's neuro-symbolic approach effectively addresses these
issues. We provide an overview of the system architecture, key algorithms for
knowledge extraction and formal reasoning, and present preliminary evaluation
results that highlight Cora's superior performance compared to well-known LLM
and RAG baselines.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÁîüÊàêÂºè AI ÁöÑÂá∫ÁèæÂæπÂ∫ïÊîπËÆä‰∫ÜÂêÑÂÄãÈ†òÂüüÁöÑËá™ÁÑ∂Ë™ûË®ÄÊáâÁî®„ÄÇÁÑ∂ËÄåÔºåÈÜ´ÁôÇ„ÄÅÊ≥ïÂæãÂíåÈáëËûçÁ≠âÈ†òÂüüÁöÑÈ´òÈ¢®Èö™Ê±∫Á≠ñÂà∂ÂÆö‰ªªÂãôÈúÄË¶ÅÁ≤æÁ¢∫Â∫¶„ÄÅÂÖ®Èù¢ÊÄßÂíåÈÇèËºØ‰∏ÄËá¥ÊÄßÔºåËÄåÁ¥îÁ≤πÁöÑ LLM ÊàñÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÊèê‰æõ„ÄÇÂú® Elemental Cognition (EC)ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÁ•ûÁ∂ìÁ¨¶Ëôü AI Âπ≥Âè∞‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇË©≤Âπ≥Âè∞Êï¥Âêà‰∫ÜÁ∂ìÈÅéÂæÆË™øÁöÑ LLMÔºåÁî®ÊñºÁü•Ë≠òÊèêÂèñÂíåËàáÂº∑Â§ßÁöÑÁ¨¶ËôüÊé®ÁêÜÂºïÊìéÂ∞çÈΩäÔºåÁî®ÊñºÈÇèËºØÊé®ÁêÜ„ÄÅË¶èÂäÉÂíå‰∫íÂãïÁ¥ÑÊùüÊ±ÇËß£„ÄÇÊàëÂÄëÊèèËø∞‰∫Ü CoraÔºå‰∏ÄÂÄãÂª∫Á´ãÂú®ÈÄôÂÄãÂπ≥Âè∞‰∏äÁöÑÂçî‰ΩúÁ†îÁ©∂Âä©ÁêÜÔºåÂÆÉË¢´Ë®≠Ë®àÁî®ÊñºÂú®È´òÈ¢®Èö™È†òÂüüÂü∑Ë°åË§áÈõúÁöÑÁ†îÁ©∂ÂíåÁôºÁèæ‰ªªÂãô„ÄÇÊú¨ÊñáË®éË´ñ‰∫ÜÊ≠§È°ûÈ†òÂüü‰∏≠Âõ∫ÊúâÁöÑÂ§öÊ≠•È©üÊé®ÁêÜÊåëÊà∞ÔºåÊâπË©ï‰∫ÜÁèæÊúâÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄßÔºå‰∏¶Â±ïÁ§∫‰∫Ü Cora ÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂ¶Ç‰ΩïÊúâÊïàÂú∞Ëß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÊ¶ÇËø∞‰∫ÜÁ≥ªÁµ±Êû∂Êßã„ÄÅÁü•Ë≠òÊèêÂèñÂíåÂΩ¢ÂºèÊé®ÁêÜÁöÑÈóúÈçµÊºîÁÆóÊ≥ïÔºå‰∏¶Êèê‰æõ‰∫ÜÂàùÊ≠•Ë©ï‰º∞ÁµêÊûúÔºåÁ™ÅÂá∫‰∫Ü Cora ËàáÁúæÊâÄÂë®Áü•ÁöÑ LLM Âíå RAG Âü∫Ê∫ñÁõ∏ÊØîÁöÑÂÑ™Áï∞ÊÄßËÉΩ„ÄÇ

##### **Domain Adaptation of Echocardiography Segmentation Via Reinforcement Learning**
2406.17902v1 by Arnaud Judge, Thierry Judge, Nicolas Duchateau, Roman A. Sandler, Joseph Z. Sokol, Olivier Bernard, Pierre-Marc Jodoin

Performance of deep learning segmentation models is significantly challenged
in its transferability across different medical imaging domains, particularly
when aiming to adapt these models to a target domain with insufficient
annotated data for effective fine-tuning. While existing domain adaptation (DA)
methods propose strategies to alleviate this problem, these methods do not
explicitly incorporate human-verified segmentation priors, compromising the
potential of a model to produce anatomically plausible segmentations. We
introduce RL4Seg, an innovative reinforcement learning framework that reduces
the need to otherwise incorporate large expertly annotated datasets in the
target domain, and eliminates the need for lengthy manual human review. Using a
target dataset of 10,000 unannotated 2D echocardiographic images, RL4Seg not
only outperforms existing state-of-the-art DA methods in accuracy but also
achieves 99% anatomical validity on a subset of 220 expert-validated subjects
from the target domain. Furthermore, our framework's reward network offers
uncertainty estimates comparable with dedicated state-of-the-art uncertainty
methods, demonstrating the utility and effectiveness of RL4Seg in overcoming
domain adaptation challenges in medical image segmentation.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂàÜÂâ≤Ê®°ÂûãÁöÑÊïàËÉΩÔºåÂú®‰∏çÂêåÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüüÁöÑËΩâÁßªÊÄß‰∏äÂèóÂà∞È°ØËëóÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÁõÆÊ®ôÈ†òÂüüÁöÑÈÅ©ÊáâÔºåË≥áÊñô‰∏çË∂≥‰ª•ÈÄ≤Ë°åÊúâÊïàÂæÆË™øÊôÇ„ÄÇÁèæÊúâÁöÑÈ†òÂüüÈÅ©Êáâ (DA) ÊñπÊ≥ïÊèêÂá∫Á≠ñÁï•‰æÜÁ∑©Ëß£Ê≠§ÂïèÈ°åÔºå‰ΩÜÈÄô‰∫õÊñπÊ≥ï‰∏¶Êú™ÊòéÁ¢∫Á¥çÂÖ•‰∫∫ÁÇ∫È©óË≠âÁöÑÂàÜÂâ≤ÂÖàÈ©óÔºåÈÄôÊúÉÂΩ±ÈüøÊ®°ÂûãÁî¢ÁîüËß£ÂâñÂ≠∏‰∏äÂêàÁêÜÁöÑÂàÜÂâ≤ÁöÑÂèØËÉΩÊÄß„ÄÇÊàëÂÄëÂºïÈÄ≤ RL4SegÔºå‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂº∑ÂåñÂ≠∏ÁøíÊû∂ÊßãÔºåÂÆÉÊ∏õÂ∞ë‰∫ÜÂú®ÁõÆÊ®ôÈ†òÂüü‰∏≠Á¥çÂÖ•Â§ßÈáèÂ∞àÂÆ∂Ë®ªËß£Ë≥áÊñôÈõÜÁöÑÈúÄÊ±ÇÔºå‰∏¶Ê∂àÈô§‰∫ÜÂÜóÈï∑ÁöÑ„ÄÅÊâãÂãïÁöÑ‰∫∫Â∑•ÂØ©Êü•ÈúÄÊ±Ç„ÄÇ‰ΩøÁî®ÂåÖÂê´ 10,000 ÂÄãÊú™Ë®ªËß£ÁöÑ 2D Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁöÑÁõÆÊ®ôË≥áÊñôÈõÜÔºåRL4Seg ‰∏çÂÉÖÂú®Ê∫ñÁ¢∫ÊÄß‰∏äÂÑ™ÊñºÁèæÊúâÁöÑÊúÄÂÖàÈÄ≤ÁöÑ DA ÊñπÊ≥ïÔºåËÄå‰∏îÂú®ÁõÆÊ®ôÈ†òÂüü‰∏≠Ôºå220 ÂÄãÂ∞àÂÆ∂È©óË≠âÁöÑÂèóË©¶ËÄÖÁöÑÂ≠êÈõÜ‰∏≠ÔºåËß£ÂâñÂ≠∏ÊïàÂ∫¶ÈÅîÂà∞ 99%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊû∂ÊßãÁöÑÁçéÂãµÁ∂≤Ë∑ØÊèê‰æõ‰∫ÜËàáÂ∞àÈñÄÁöÑÊúÄÂÖàÈÄ≤ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÊñπÊ≥ïÁõ∏Áï∂ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÔºåÈÄôË≠âÊòé‰∫Ü RL4Seg Âú®ÂÖãÊúçÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤‰∏≠ÁöÑÈ†òÂüüÈÅ©ÊáâÊåëÊà∞ÊñπÈù¢ÁöÑÊïàÁî®ÂíåÊúâÊïàÊÄß„ÄÇ

##### **CTBench: A Comprehensive Benchmark for Evaluating Language Model Capabilities in Clinical Trial Design**
2406.17888v1 by Nafis Neehal, Bowen Wang, Shayom Debopadhaya, Soham Dan, Keerthiram Murugesan, Vibha Anand, Kristin P. Bennett

CTBench is introduced as a benchmark to assess language models (LMs) in
aiding clinical study design. Given study-specific metadata, CTBench evaluates
AI models' ability to determine the baseline features of a clinical trial (CT),
which include demographic and relevant features collected at the trial's start
from all participants. These baseline features, typically presented in CT
publications (often as Table 1), are crucial for characterizing study cohorts
and validating results. Baseline features, including confounders and
covariates, are also necessary for accurate treatment effect estimation in
studies involving observational data. CTBench consists of two datasets:
"CT-Repo," containing baseline features from 1,690 clinical trials sourced from
clinicaltrials.gov, and "CT-Pub," a subset of 100 trials with more
comprehensive baseline features gathered from relevant publications. Two
LM-based evaluation methods are developed to compare the actual baseline
feature lists against LM-generated responses. "ListMatch-LM" and
"ListMatch-BERT" use GPT-4o and BERT scores (at various thresholds),
respectively, for evaluation. To establish baseline results, advanced prompt
engineering techniques using LLaMa3-70B-Instruct and GPT-4o in zero-shot and
three-shot learning settings are applied to generate potential baseline
features. The performance of GPT-4o as an evaluator is validated through
human-in-the-loop evaluations on the CT-Pub dataset, where clinical experts
confirm matches between actual and LM-generated features. The results highlight
a promising direction with significant potential for improvement, positioning
CTBench as a useful tool for advancing research on AI in CT design and
potentially enhancing the efficacy and robustness of CTs.

ÊëòË¶ÅÔºöCTBench Ë¢´ÂºïÂÖ•‰ΩúÁÇ∫‰∏ÄÂÄãÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞Ë™ûË®ÄÊ®°Âûã (LM) Âú®Âπ´Âä©Ëá®Â∫äÁ†îÁ©∂Ë®≠Ë®à‰∏≠ÁöÑ‰ΩúÁî®„ÄÇCTBench ÊúÉË©ï‰º∞ AI Ê®°ÂûãÂú®Áµ¶ÂÆöÁâπÂÆöÁ†îÁ©∂ÁöÑÂÖÉÊï∏ÊìöÂæåÔºåÊ±∫ÂÆöËá®Â∫äË©¶È©ó (CT) Âü∫Á∑öÁâπÂæµÁöÑËÉΩÂäõÔºåÂÖ∂‰∏≠ÂåÖÊã¨Âú®Ë©¶È©óÈñãÂßãÊôÇÂæûÊâÄÊúâÂèÉËàáËÄÖÊî∂ÈõÜÁöÑ‰∫∫Âè£Áµ±Ë®àÂíåÁõ∏ÈóúÁâπÂæµ„ÄÇÈÄô‰∫õÂü∫Á∑öÁâπÂæµÈÄöÂ∏∏ÊúÉÂú® CT Âá∫ÁâàÁâ©‰∏≠ÂëàÁèæÔºàÈÄöÂ∏∏ÊòØË°®Ê†º 1ÔºâÔºåÂ∞çÊñºË°®ÂæµÁ†îÁ©∂Áæ§ÁµÑÂíåÈ©óË≠âÁµêÊûúËá≥ÈóúÈáçË¶Å„ÄÇÂü∫Á∑öÁâπÂæµÔºàÂåÖÊã¨Ê∑∑Ê∑ÜÂõ†Â≠êÂíåÂçîËÆäÈáèÔºâÂ∞çÊñºÊ∫ñÁ¢∫‰º∞Ë®àÊ∂âÂèäËßÄÂØüÊï∏ÊìöÁöÑÁ†îÁ©∂‰∏≠ÁöÑÊ≤ªÁôÇÊïàÊûú‰πüÂæàÊúâÂøÖË¶Å„ÄÇCTBench ÂåÖÂê´ÂÖ©ÂÄãÊï∏ÊìöÈõÜÔºö„ÄåCT-Repo„ÄçÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ clinicaltrials.gov ÁöÑ 1,690 ÂÄãËá®Â∫äË©¶È©óÁöÑÂü∫Á∑öÁâπÂæµÔºå‰ª•Âèä„ÄåCT-Pub„ÄçÔºå‰∏ÄÂÄãÂåÖÂê´ 100 ÂÄãË©¶È©óÁöÑÂ≠êÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂæûÁõ∏ÈóúÂá∫ÁâàÁâ©Êî∂ÈõÜÁöÑÊõ¥ÂÖ®Èù¢ÁöÑÂü∫Á∑öÁâπÂæµ„ÄÇÈñãÁôº‰∫ÜÂÖ©Á®ÆÂü∫Êñº LM ÁöÑË©ï‰º∞ÊñπÊ≥ïÔºåÁî®ÊñºÊØîËºÉÂØ¶ÈöõÁöÑÂü∫Á∑öÁâπÂæµÂàóË°®Âíå LM ÁîüÊàêÁöÑÂõûÊáâ„ÄÇ„ÄåListMatch-LM„ÄçÂíå„ÄåListMatch-BERT„ÄçÂàÜÂà•‰ΩøÁî® GPT-4o Âíå BERT ÂàÜÊï∏ÔºàÂú®ÂêÑÁ®ÆÈñæÂÄº‰∏ãÔºâÈÄ≤Ë°åË©ï‰º∞„ÄÇÁÇ∫‰∫ÜÂª∫Á´ãÂü∫Á∑öÁµêÊûúÔºåÂú®Èõ∂Ê¨°Â≠∏ÁøíÂíå‰∏âÊ¨°Â≠∏ÁøíË®≠ÁΩÆ‰∏≠‰ΩøÁî® LLaMa3-70B-Instruct Âíå GPT-4o ÁöÑÈÄ≤ÈöéÊèêÁ§∫Â∑•Á®ãÊäÄË°ìÔºåÁî®ÊñºÁîüÊàêÊΩõÂú®ÁöÑÂü∫Á∑öÁâπÂæµ„ÄÇGPT-4o ‰ΩúÁÇ∫Ë©ï‰º∞Âô®ÁöÑÊÄßËÉΩÈÄöÈÅéÂú® CT-Pub Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°å‰∫∫Ê©ü‰∫§‰∫íË©ï‰º∞ÂæóÂà∞È©óË≠âÔºåÂú®Ë©≤Ë©ï‰º∞‰∏≠ÔºåËá®Â∫äÂ∞àÂÆ∂Á¢∫Ë™çÂØ¶ÈöõÁâπÂæµÂíå LM ÁîüÊàêÁöÑÁâπÂæµ‰πãÈñìÁöÑÂåπÈÖç„ÄÇÁµêÊûúÁ™ÅÈ°Ø‰∫Ü‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÊñπÂêëÔºåÂÖ∑ÊúâÈ°ØËëóÁöÑÊîπÈÄ≤ÊΩõÂäõÔºåÂ∞á CTBench ÂÆö‰ΩçÁÇ∫‰øÉÈÄ≤ CT Ë®≠Ë®à‰∏≠ AI Á†îÁ©∂ÁöÑÊúâÁî®Â∑•ÂÖ∑Ôºå‰∏¶ÊúâÂèØËÉΩÊèêÈ´ò CT ÁöÑÂäüÊïàÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging**
2406.17640v1 by Zeinab Sherkatghanad, Moloud Abdar, Mohammadreza Bakhtyari, Vladimir Makarenkov

Test-time augmentation (TTA) is a well-known technique employed during the
testing phase of computer vision tasks. It involves aggregating multiple
augmented versions of input data. Combining predictions using a simple average
formulation is a common and straightforward approach after performing TTA. This
paper introduces a novel framework for optimizing TTA, called BayTTA
(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,
we generate a model list associated with different variations of the input data
created through TTA. Then, we use BMA to combine model predictions weighted by
their respective posterior probabilities. Such an approach allows one to take
into account model uncertainty, and thus to enhance the predictive performance
of the related machine learning or deep learning model. We evaluate the
performance of BayTTA on various public data, including three medical image
datasets comprising skin cancer, breast cancer, and chest X-ray images and two
well-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental
results indicate that BayTTA can be effectively integrated into
state-of-the-art deep learning models used in medical image analysis as well as
into some popular pre-trained CNN models such as VGG-16, MobileNetV2,
DenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in
their accuracy and robustness performance.

ÊëòË¶ÅÔºöÊ∏¨Ë©¶ÊôÇÈñìÊì¥ÂÖÖ (TTA) ÊòØ‰∏ÄÁ®ÆÂú®ÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãôÁöÑÊ∏¨Ë©¶ÈöéÊÆµ‰∏≠Âª£Ê≥õ‰ΩøÁî®ÁöÑÊäÄË°ì„ÄÇÂÆÉÊ∂âÂèäËÅöÂêàËº∏ÂÖ•Ë≥áÊñôÁöÑË®±Â§öÊì¥ÂÖÖÁâàÊú¨„ÄÇÂú®Âü∑Ë°å TTA ‰πãÂæåÔºå‰ΩøÁî®Á∞°ÂñÆÂπ≥ÂùáÂÖ¨ÂºèÁµÑÂêàÈ†êÊ∏¨ÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ã‰∏îÁõ¥Êé•ÁöÑÊñπÊ≥ï„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®ÊñºÊúÄ‰Ω≥Âåñ TTA ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁ®±ÁÇ∫ BayTTAÔºàÂü∫ÊñºË≤ùÊ∞èÁöÑ TTAÔºâÔºåÂÆÉÂü∫ÊñºË≤ùÊ∞èÊ®°ÂûãÂπ≥Âùá (BMA)„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÁî¢Áîü‰∏ÄÂÄãËàáËº∏ÂÖ•Ë≥áÊñôÁöÑ‰∏çÂêåËÆäÁï∞Áõ∏ÈóúÁöÑÊ®°ÂûãÊ∏ÖÂñÆÔºåÈÄô‰∫õËÆäÁï∞ÊòØÈÄèÈÅé TTA Âª∫Á´ãÁöÑ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® BMA ‰æÜÁµÑÂêàÊ®°ÂûãÈ†êÊ∏¨ÔºåÂÖ∂Ê¨äÈáçÁî±ÂÆÉÂÄëÂêÑËá™ÁöÑÂæåÈ©óÊ©üÁéáÊ±∫ÂÆö„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±ËÄÉÊÖÆÊ®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂæûËÄåÂ¢ûÂº∑Áõ∏ÈóúÊ©üÂô®Â≠∏ÁøíÊàñÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÈ†êÊ∏¨ÊÄßËÉΩ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÂÖ¨ÈñãË≥áÊñô‰∏äË©ï‰º∞ BayTTA ÁöÑÊÄßËÉΩÔºåÂåÖÊã¨‰∏âÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁöÆËÜöÁôå„ÄÅ‰π≥ÁôåÂíåËÉ∏ÈÉ® X ÂÖâÂΩ±ÂÉèÔºå‰ª•ÂèäÂÖ©ÂÄãËëóÂêçÁöÑÂü∫Âõ†Á∑®ËºØË≥áÊñôÈõÜÔºåCRISPOR Âíå GUIDE-seq„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåBayTTA ÂèØ‰ª•ÊúâÊïàÊï¥ÂêàÂà∞Áî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁöÑÊúÄÊñ∞Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏≠Ôºå‰ª•Âèä‰∏Ä‰∫õÊµÅË°åÁöÑÈ†êË®ìÁ∑¥ CNN Ê®°Âûã‰∏≠Ôºå‰æãÂ¶Ç VGG-16„ÄÅMobileNetV2„ÄÅDenseNet201„ÄÅResNet152V2 Âíå InceptionRes-NetV2ÔºåÂæûËÄåÊèêÂçáÂÆÉÂÄëÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÂÅ•Â£ØÊÄßË°®Áèæ„ÄÇ

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁõÆÂâçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÂèØËß£ÈáãÊÄß‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÈ†òÂüüËá¥ÂäõÊñºËß£Ê±∫ÈÄôÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÈÄôÂú®ÈáëËûç„ÄÅÊ≥ïÂæãÂíåÂÅ•Â∫∑Á≠âÈ´òÈ¢®Èö™È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁØÑÁñáË´ñÂÆöÁæ© AI Ê®°ÂûãÂèäÂÖ∂ÂèØËß£ÈáãÊÄßÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊé°Áî®ÁµÑÂêàÊ®°ÂûãÁöÑÊ¶ÇÂøµÔºåÂÆÉ‰ª•ÂΩ¢ÂºèÂº¶ÂúñÁöÑÂΩ¢ÂºèÁúãÂæÖÊ®°ÂûãÔºåÈÄô‰∫õÂº¶ÂúñÊçïÁç≤‰∫ÜÊ®°ÂûãÁöÑÊäΩË±°ÁµêÊßãÂèäÂÖ∂ÂÖ∑È´îÂØ¶Áèæ„ÄÇÈÄôÁ®ÆÁ∂úÂêàËßÄÈªûÂåÖÂê´‰∫ÜÁ¢∫ÂÆöÊÄß„ÄÅÊ¶ÇÁéáÊÄßÂíåÈáèÂ≠êÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂêÑÁ®Æ AI Ê®°Âûã‰ΩúÁÇ∫ÁµÑÂêàÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂåÖÊã¨Á∑öÊÄßÂíåÂü∫ÊñºË¶èÂâáÁöÑÊ®°Âûã„ÄÅÔºàÈÅûËø¥ÔºâÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformer„ÄÅVAEÔºå‰ª•ÂèäÂõ†ÊûúÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÊ†πÊìöÊ®°ÂûãÁöÑÁµÑÂêàÁµêÊßãÁµ¶Âá∫Ê®°ÂûãËß£ÈáãÁöÑÂÆöÁæ©ÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÊæÑÊ∏Ö XAI ‰∏≠ÁöÑÂ∏∏Ë¶ã‰∏ªÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåËÆìÊ®ôÊ∫ñÁöÑ„ÄåÂÖßÂú®ÂèØËß£Èáã„ÄçÊ®°ÂûãÂ¶ÇÊ≠§ÈÄèÊòéÁöÑÂéüÂõ†Âú®ÂúñË°®‰∏≠Ë°®ÁèæÂæóÊúÄÁÇ∫Ê∏ÖÊ•ö„ÄÇÈÄôÂºïÂ∞éÊàëÂÄëÂæóÂá∫Êõ¥‰∏ÄËà¨ÁöÑÁµÑÂêàÂèØËß£ÈáãÔºàCIÔºâÊ®°ÂûãÊ¶ÇÂøµÔºåÂÆÉÂè¶Â§ñÈÇÑÂåÖÊã¨Âõ†Êûú„ÄÅÊ¶ÇÂøµÁ©∫ÈñìÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü CI Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂÄëÁöÑÁµÑÂêàÁµêÊßãÂÖÅË®±Ë®àÁÆóÂÖ∂‰ªñÊÑüËààË∂£ÁöÑÈáèÔºå‰∏¶ÂèØËÉΩÈÄöÈÅéÂåπÈÖçÊ®°ÂûãÁöÑÁµêÊßã‰æÜ‰øÉÈÄ≤ÂæûÊ®°ÂûãÂà∞Ë¢´Âª∫Ê®°ÁèæË±°ÁöÑÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂÄëÂÖÅË®±Â∞çÂÖ∂Ë°åÁÇ∫ÈÄ≤Ë°åÂúñËß£Ë™™ÊòéÔºåÈÄô‰∫õË™™ÊòéÂü∫ÊñºÂΩ±ÈüøÁ¥ÑÊùü„ÄÅÂúñËß£ÊâãË°ìÂíåÈáçÂØ´Ë™™Êòé„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑË®±Â§öÊú™‰æÜÊñπÂêëÔºåÊèêÂá∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØ¶Ë∏ê‰∏≠Â≠∏ÁøíÈÄôÁ®ÆÊúâÊÑèÁæ©ÁöÑÁµêÊßãÂåñÊ®°ÂûãÁöÑÂïèÈ°å„ÄÇ</paragraph>

##### **On the consistency of hyper-parameter selection in value-based deep reinforcement learning**
2406.17523v2 by Johan Obando-Ceron, Jo√£o G. M. Ara√∫jo, Aaron Courville, Pablo Samuel Castro

Deep reinforcement learning (deep RL) has achieved tremendous success on
various domains through a combination of algorithmic design and careful
selection of hyper-parameters. Algorithmic improvements are often the result of
iterative enhancements built upon prior approaches, while hyper-parameter
choices are typically inherited from previous methods or fine-tuned
specifically for the proposed technique. Despite their crucial impact on
performance, hyper-parameter choices are frequently overshadowed by algorithmic
advancements. This paper conducts an extensive empirical study focusing on the
reliability of hyper-parameter selection for value-based deep reinforcement
learning agents, including the introduction of a new score to quantify the
consistency and reliability of various hyper-parameters. Our findings not only
help establish which hyper-parameters are most critical to tune, but also help
clarify which tunings remain consistent across different training regimes.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÔºàÊ∑±Â∫¶ RLÔºâÈÄèÈÅéÊºîÁÆóÊ≥ïË®≠Ë®àÂíå‰ªîÁ¥∞ÈÅ∏ÊìáË∂ÖÂèÉÊï∏ÁöÑÁµÑÂêàÔºåÂú®ÂêÑÁ®ÆÈ†òÂüü‰∏äÂèñÂæó‰∫ÜÂ∑®Â§ßÁöÑÊàêÂäü„ÄÇÊºîÁÆóÊ≥ïÁöÑÊîπÈÄ≤ÈÄöÂ∏∏ÊòØÂª∫Á´ãÂú®ÂÖàÂâçÊñπÊ≥ï‰∏äÁöÑÂèçË¶ÜÂ¢ûÂº∑ÁöÑÁµêÊûúÔºåËÄåË∂ÖÂèÉÊï∏ÁöÑÈÅ∏ÊìáÈÄöÂ∏∏ÂæûÂÖàÂâçÁöÑÊäÄË°ì‰∏≠ÁπºÊâøÔºåÊàñÈáùÂ∞çÂª∫Ë≠∞ÁöÑÊäÄË°ìÈÄ≤Ë°åÂæÆË™ø„ÄÇÂÑòÁÆ°Ë∂ÖÂèÉÊï∏ÁöÑÈÅ∏ÊìáÂ∞çÊïàËÉΩÊúâËá≥ÈóúÈáçË¶ÅÁöÑÂΩ±ÈüøÔºå‰ΩÜÂÆÉÂÄëÁ∂ìÂ∏∏Ë¢´ÊºîÁÆóÊ≥ïÁöÑÈÄ≤Ê≠•ÊâÄÊé©Ëìã„ÄÇÊú¨ÊñáÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂª£Ê≥õÁöÑÂØ¶Ë≠âÁ†îÁ©∂ÔºåÈáçÈªûÂú®ÊñºÂü∫ÊñºÂÉπÂÄºÁöÑÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí‰ª£ÁêÜÁöÑË∂ÖÂèÉÊï∏ÈÅ∏ÊìáÁöÑÂèØÈù†ÊÄßÔºåÂåÖÊã¨ÂºïÂÖ•‰∏ÄÂÄãÊñ∞ÁöÑË©ïÂàÜ‰æÜÈáèÂåñÂêÑÁ®ÆË∂ÖÂèÉÊï∏ÁöÑ‰∏ÄËá¥ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÁöÑÁôºÁèæ‰∏çÂÉÖÊúâÂä©ÊñºÁ¢∫ÂÆöÂì™‰∫õË∂ÖÂèÉÊï∏ÊúÄÈóúÈçµÔºåËÄå‰∏îÊúâÂä©ÊñºÈáêÊ∏ÖÂì™‰∫õË™øÊï¥Âú®‰∏çÂêåÁöÑË®ìÁ∑¥Âà∂Â∫¶‰∏≠‰øùÊåÅ‰∏ÄËá¥„ÄÇ

##### **TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification**
2406.17473v1 by Joshua Niemeijer, Jan Ehrhardt, Hristina Uzunova, Heinz Handels

The usage of medical image data for the training of large-scale machine
learning approaches is particularly challenging due to its scarce availability
and the costly generation of data annotations, typically requiring the
engagement of medical professionals. The rapid development of generative models
allows towards tackling this problem by leveraging large amounts of realistic
synthetically generated data for the training process. However, randomly
choosing synthetic samples, might not be an optimal strategy.
  In this work, we investigate the targeted generation of synthetic training
data, in order to improve the accuracy and robustness of image classification.
Therefore, our approach aims to guide the generative model to synthesize data
with high epistemic uncertainty, since large measures of epistemic uncertainty
indicate underrepresented data points in the training set. During the image
generation we feed images reconstructed by an auto encoder into the classifier
and compute the mutual information over the class-probability distribution as a
measure for uncertainty.We alter the feature space of the autoencoder through
an optimization process with the objective of maximizing the classifier
uncertainty on the decoded image. By training on such data we improve the
performance and robustness against test time data augmentations and adversarial
attacks on several classifications tasks.

ÊëòË¶ÅÔºöÁî±ÊñºÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñôÁöÑÂèñÂæó‰∏çÊòìÔºå‰∏îË≥áÊñôÊ®ôË®ªÁöÑÁî¢ÁîüÊàêÊú¨È´òÊòÇÔºåÈÄöÂ∏∏ÈúÄË¶ÅÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÂèÉËàáÔºåÂõ†Ê≠§‰ΩøÁî®ÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñô‰æÜË®ìÁ∑¥Â§ßÂûãÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁîüÊàêÂºèÊ®°ÂûãÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂÖÅË®±ÈÄèÈÅéÂà©Áî®Â§ßÈáèÈÄºÁúüÁöÑÂêàÊàêË≥áÊñô‰æÜË®ìÁ∑¥ÊµÅÁ®ãÔºå‰ª•Ëß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÈö®Ê©üÈÅ∏ÊìáÂêàÊàêÊ®£Êú¨ÂèØËÉΩ‰∏çÊòØÊúÄ‰Ω≥Á≠ñÁï•„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂ÂêàÊàêË®ìÁ∑¥Ë≥áÊñôÁöÑÁõÆÊ®ôÁîüÊàêÔºå‰ª•ÊèêÈ´òÂΩ±ÂÉèÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊó®Âú®ÂºïÂ∞éÁîüÊàêÂºèÊ®°ÂûãÂêàÊàêÂÖ∑ÊúâÈ´òË™çË≠òË´ñ‰∏çÁ¢∫ÂÆöÊÄßÁöÑË≥áÊñôÔºåÂõ†ÁÇ∫Ë™çË≠òË´ñ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÈ´òÊåáÊ®ôË°®Á§∫Ë®ìÁ∑¥ÈõÜ‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑË≥áÊñôÈªû„ÄÇÂú®ÂΩ±ÂÉèÁîüÊàêÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëÂ∞áËá™ÂãïÁ∑®Á¢ºÂô®ÈáçÂª∫ÁöÑÂΩ±ÂÉèËº∏ÂÖ•ÂàÜÈ°ûÂô®Ôºå‰∏¶Ë®àÁÆóÈ°ûÂà•Ê©üÁéáÂàÜ‰ΩàÁöÑ‰∫íË≥áË®ä‰ΩúÁÇ∫‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊåáÊ®ô„ÄÇÊàëÂÄëÈÄèÈÅéÂÑ™ÂåñÊµÅÁ®ã‰æÜÊîπËÆäËá™ÂãïÁ∑®Á¢ºÂô®ÁöÑÁâπÂæµÁ©∫ÈñìÔºåÁõÆÊ®ôÊòØÊúÄÂ§ßÂåñËß£Á¢ºÂΩ±ÂÉè‰∏äÂàÜÈ°ûÂô®ÁöÑÊú™Á¢∫ÂÆöÊÄß„ÄÇÈÄèÈÅéË®ìÁ∑¥Ê≠§È°ûË≥áÊñôÔºåÊàëÂÄëÊîπÂñÑ‰∫ÜÂú®Â§öÈ†ÖÂàÜÈ°û‰ªªÂãô‰∏≠Â∞çÊ∏¨Ë©¶ÊôÇÈñìË≥áÊñôÊì¥ÂÖÖÂíåÂ∞çÊäóÊîªÊìäÁöÑÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **AI for the prediction of early stages of Alzheimer's disease from neuroimaging biomarkers -- A narrative review of a growing field**
2406.17822v1 by Thorsten Rudroff, Oona Rainio, Riku Kl√©n

Objectives: The objectives of this narrative review are to summarize the
current state of AI applications in neuroimaging for early Alzheimer's disease
(AD) prediction and to highlight the potential of AI techniques in improving
early AD diagnosis, prognosis, and management.
  Methods: We conducted a narrative review of studies using AI techniques
applied to neuroimaging data for early AD prediction. We examined
single-modality studies using structural MRI and PET imaging, as well as
multi-modality studies integrating multiple neuroimaging techniques and
biomarkers. Furthermore, they reviewed longitudinal studies that model AD
progression and identify individuals at risk of rapid decline.
  Results: Single-modality studies using structural MRI and PET imaging have
demonstrated high accuracy in classifying AD and predicting progression from
mild cognitive impairment (MCI) to AD. Multi-modality studies, integrating
multiple neuroimaging techniques and biomarkers, have shown improved
performance and robustness compared to single-modality approaches. Longitudinal
studies have highlighted the value of AI in modeling AD progression and
identifying individuals at risk of rapid decline. However, challenges remain in
data standardization, model interpretability, generalizability, clinical
integration, and ethical considerations.
  Conclusion: AI techniques applied to neuroimaging data have the potential to
improve early AD diagnosis, prognosis, and management. Addressing challenges
related to data standardization, model interpretability, generalizability,
clinical integration, and ethical considerations is crucial for realizing the
full potential of AI in AD research and clinical practice. Collaborative
efforts among researchers, clinicians, and regulatory agencies are needed to
develop reliable, robust, and ethical AI tools that can benefit AD patients and
society.

ÊëòË¶ÅÔºö<paragraph>ÁõÆÊ®ôÔºöÊú¨ÊïòËø∞ÊÄßÂõûÈ°ßÁöÑÁõÆÊ®ôÊòØÁ∏ΩÁµê AI ÊáâÁî®ÊñºÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏‰ª•ÈÄ≤Ë°åÈòøËå≤Êµ∑ÈªòÁóá (AD) Êó©ÊúüÈ†êÊ∏¨ÁöÑÁèæÊ≥ÅÔºå‰∏¶Âº∑Ë™ø AI ÊäÄË°ìÂú®ÊîπÂñÑ AD Êó©ÊúüË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÂ∞ç‰ΩøÁî® AI ÊäÄË°ìÊáâÁî®ÊñºÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏Êï∏Êìö‰ª•ÈÄ≤Ë°åÊó©Êúü AD È†êÊ∏¨ÁöÑÁ†îÁ©∂ÈÄ≤Ë°å‰∫ÜÊïòËø∞ÊÄßÂõûÈ°ß„ÄÇÊàëÂÄëÊ™¢Ë¶ñ‰∫Ü‰ΩøÁî®ÁµêÊßãÊÄß MRI Âíå PET ÂΩ±ÂÉèÁöÑÂñÆ‰∏ÄÊñπÂºèÁ†îÁ©∂Ôºå‰ª•ÂèäÊï¥ÂêàÂ§öÁ®ÆÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏ÊäÄË°ìÂíåÁîüÁâ©Ê®ôË®òÁöÑÂ§öÊñπÂºèÁ†îÁ©∂„ÄÇÊ≠§Â§ñÔºå‰ªñÂÄëÂõûÈ°ß‰∫ÜÂ∞ç AD ÈÄ≤Á®ãÂª∫Ê®°‰∏¶ÊâæÂá∫Âø´ÈÄüÊÉ°ÂåñÈ¢®Èö™ÂÄãÈ´îÁöÑÁ∏±ÂêëÁ†îÁ©∂„ÄÇ
ÁµêÊûúÔºö‰ΩøÁî®ÁµêÊßãÊÄß MRI Âíå PET ÂΩ±ÂÉèÁöÑÂñÆ‰∏ÄÊñπÂºèÁ†îÁ©∂Â∑≤Ë≠âÊòéÂú®ÂàÜÈ°û AD ÂíåÈ†êÊ∏¨ÂæûËºïÂ∫¶Ë™çÁü•ÈöúÁ§ô (MCI) Âà∞ AD ÁöÑÈÄ≤Á®ãÊñπÈù¢ÂÖ∑ÊúâÂæàÈ´òÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊï¥ÂêàÂ§öÁ®ÆÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏ÊäÄË°ìÂíåÁîüÁâ©Ê®ôË®òÁöÑÂ§öÊñπÂºèÁ†îÁ©∂Â∑≤È°ØÁ§∫Âá∫ËàáÂñÆ‰∏ÄÊñπÂºèÊñπÊ≥ïÁõ∏ÊØîÔºåÊîπÈÄ≤ÁöÑÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄß„ÄÇÁ∏±ÂêëÁ†îÁ©∂Âº∑Ë™ø‰∫Ü AI Âú®Â∞ç AD ÈÄ≤Á®ãÂª∫Ê®°ÂíåÊâæÂá∫Âø´ÈÄüÊÉ°ÂåñÈ¢®Èö™ÂÄãÈ´îÊñπÈù¢ÁöÑÂÉπÂÄº„ÄÇÁÑ∂ËÄåÔºåÊï∏ÊìöÊ®ôÊ∫ñÂåñ„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÅÂèØÊ¶ÇÂåñÊÄß„ÄÅËá®Â∫äÊï¥ÂêàÂíåÂÄ´ÁêÜËÄÉÈáè‰ªçÂ≠òÂú®ÊåëÊà∞„ÄÇ
ÁµêË´ñÔºöÊáâÁî®ÊñºÁ•ûÁ∂ìÂΩ±ÂÉèÂ≠∏Êï∏ÊìöÁöÑ AI ÊäÄË°ìÊúâÊΩõÂäõÊîπÂñÑ AD Êó©ÊúüË®∫Êñ∑„ÄÅÈ†êÂæåÂíåÁÆ°ÁêÜ„ÄÇËß£Ê±∫ËàáÊï∏ÊìöÊ®ôÊ∫ñÂåñ„ÄÅÊ®°ÂûãÂèØËß£ÈáãÊÄß„ÄÅÂèØÊ¶ÇÂåñÊÄß„ÄÅËá®Â∫äÊï¥ÂêàÂíåÂÄ´ÁêÜËÄÉÈáèÁõ∏ÈóúÁöÑÊåëÊà∞Â∞çÊñºÂØ¶Áèæ AI Âú® AD Á†îÁ©∂ÂíåËá®Â∫äÂØ¶Âãô‰∏≠ÁöÑÂÖ®ÈÉ®ÊΩõÂäõËá≥ÈóúÈáçË¶Å„ÄÇÁ†îÁ©∂‰∫∫Âì°„ÄÅËá®Â∫äÈÜ´ÁîüÂíåÊ≥ïË¶èÊ©üÊßã‰πãÈñìÁöÑÂêà‰ΩúÂä™ÂäõÂ∞çÊñºÈñãÁôºÂèØÈù†„ÄÅÁ©©ÂÅ•‰∏îÁ¨¶ÂêàÂÄ´ÁêÜÁöÑ AI Â∑•ÂÖ∑ÊòØÂøÖË¶ÅÁöÑÔºåÈÄô‰∫õÂ∑•ÂÖ∑ÂèØ‰ª•‰Ωø AD ÊÇ£ËÄÖÂíåÁ§æÊúÉÂèóÁõä„ÄÇ</paragraph>

##### **Task-Agnostic Federated Learning**
2406.17235v1 by Zhengtao Yao, Hong Nguyen, Ajitesh Srivastava, Jose Luis Ambite

In the realm of medical imaging, leveraging large-scale datasets from various
institutions is crucial for developing precise deep learning models, yet
privacy concerns frequently impede data sharing. federated learning (FL)
emerges as a prominent solution for preserving privacy while facilitating
collaborative learning. However, its application in real-world scenarios faces
several obstacles, such as task & data heterogeneity, label scarcity,
non-identically distributed (non-IID) data, computational vaiation, etc. In
real-world, medical institutions may not want to disclose their tasks to FL
server and generalization challenge of out-of-network institutions with un-seen
task want to join the on-going federated system. This study address
task-agnostic and generalization problem on un-seen tasks by adapting
self-supervised FL framework. Utilizing Vision Transformer (ViT) as consensus
feature encoder for self-supervised pre-training, no initial labels required,
the framework enabling effective representation learning across diverse
datasets and tasks. Our extensive evaluations, using various real-world non-IID
medical imaging datasets, validate our approach's efficacy, retaining 90\% of
F1 accuracy with only 5\% of the training data typically required for
centralized approaches and exhibiting superior adaptability to
out-of-distribution task. The result indicate that federated learning
architecture can be a potential approach toward multi-task foundation modeling.

ÊëòË¶ÅÔºöÂú®ÂåªÂ≠¶ÂΩ±ÂÉèÈ¢ÜÂüüÔºåÂà©Áî®Êù•Ëá™‰∏çÂêåÊú∫ÊûÑÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÂØπ‰∫éÂºÄÂèëÁ≤æÁ°ÆÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãËá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜÈöêÁßÅÈóÆÈ¢òÁªèÂ∏∏ÈòªÁ¢çÊï∞ÊçÆÂÖ±‰∫´„ÄÇËÅîÈÇ¶Â≠¶‰π† (FL) ‰Ωú‰∏∫‰∏ÄÁßçÊó¢ËÉΩ‰øùÊä§ÈöêÁßÅÂèàËÉΩ‰øÉËøõÂçè‰ΩúÂ≠¶‰π†ÁöÑÁ™ÅÂá∫Ëß£ÂÜ≥ÊñπÊ°àËÄåÂá∫Áé∞„ÄÇÁÑ∂ËÄåÔºåÂÖ∂Âú®Áé∞ÂÆûÂú∫ÊôØ‰∏≠ÁöÑÂ∫îÁî®Èù¢‰∏¥ÁùÄ‰∏Ä‰∫õÈöúÁ¢çÔºå‰æãÂ¶Ç‰ªªÂä°ÂíåÊï∞ÊçÆÂºÇÊûÑÊÄß„ÄÅÊ†áÁ≠æÁ®ÄÁº∫ÊÄß„ÄÅÈùûÂêåÂàÜÂ∏ÉÔºàÈùû IIDÔºâÊï∞ÊçÆ„ÄÅËÆ°ÁÆóÂèòÂºÇÁ≠â„ÄÇÂú®Áé∞ÂÆû‰∏ñÁïå‰∏≠ÔºåÂåªÁñóÊú∫ÊûÑÂèØËÉΩ‰∏çÊÉ≥Âêë FL ÊúçÂä°Âô®ÈÄèÈú≤ÂÖ∂‰ªªÂä°ÔºåÂπ∂‰∏îÁΩëÁªúÂ§ñÊú∫ÊûÑÂú®ÈÅáÂà∞Êú™ËßÅ‰ªªÂä°Êó∂ÊÉ≥Ë¶ÅÂä†ÂÖ•Ê≠£Âú®ËøõË°åÁöÑËÅîÈÇ¶Á≥ªÁªüÁöÑÊ≥õÂåñÊåëÊàò„ÄÇÊú¨Á†îÁ©∂ÈÄöËøáÈááÁî®Ëá™ÁõëÁù£ FL Ê°ÜÊû∂Êù•Ëß£ÂÜ≥‰∏é‰ªªÂä°Êó†ÂÖ≥ÂíåÊú™ËßÅ‰ªªÂä°ÁöÑÊ≥õÂåñÈóÆÈ¢ò„ÄÇÂà©Áî®ËßÜËßâ Transformer (ViT) ‰Ωú‰∏∫Ëá™ÁõëÁù£È¢ÑËÆ≠ÁªÉÁöÑÂÖ±ËØÜÁâπÂæÅÁºñÁ†ÅÂô®ÔºåÊó†ÈúÄÂàùÂßãÊ†áÁ≠æÔºåËØ•Ê°ÜÊû∂ËÉΩÂ§üÂú®‰∏çÂêåÁöÑÊï∞ÊçÆÈõÜÂíå‰ªªÂä°‰∏≠ËøõË°åÊúâÊïàÁöÑË°®Á§∫Â≠¶‰π†„ÄÇÊàë‰ª¨‰ΩøÁî®ÂêÑÁßçÁé∞ÂÆû‰∏ñÁïåÈùû IID ÂåªÂ≠¶ÂΩ±ÂÉèÊï∞ÊçÆÈõÜËøõË°åÁöÑÂπøÊ≥õËØÑ‰º∞È™åËØÅ‰∫ÜÊàë‰ª¨ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰ªÖ‰ΩøÁî®ÈõÜ‰∏≠ÂºèÊñπÊ≥ïÈÄöÂ∏∏ÊâÄÈúÄÁöÑ 5% ÁöÑËÆ≠ÁªÉÊï∞ÊçÆÂ∞±‰øùÁïô‰∫Ü 90% ÁöÑ F1 ÂáÜÁ°ÆÂ∫¶ÔºåÂπ∂‰∏îË°®Áé∞Âá∫ÂØπÂàÜÂ∏ÉÂ§ñ‰ªªÂä°ÁöÑÂçìË∂äÈÄÇÂ∫îÊÄß„ÄÇÁªìÊûúË°®ÊòéÔºåËÅîÈÇ¶Â≠¶‰π†Êû∂ÊûÑÂèØ‰ª•Êàê‰∏∫Â§ö‰ªªÂä°Âü∫Á°ÄÂª∫Ê®°ÁöÑÊΩúÂú®ÊñπÊ≥ï„ÄÇ

##### **Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars**
2406.17812v1 by Wesley Brewer, Aditya Kashi, Sajal Dash, Aristeidis Tsaris, Junqi Yin, Mallikarjun Shankar, Feiyi Wang

In a post-ChatGPT world, this paper explores the potential of leveraging
scalable artificial intelligence for scientific discovery. We propose that
scaling up artificial intelligence on high-performance computing platforms is
essential to address such complex problems. This perspective focuses on
scientific use cases like cognitive simulations, large language models for
scientific inquiry, medical image analysis, and physics-informed approaches.
The study outlines the methodologies needed to address such challenges at scale
on supercomputers or the cloud and provides exemplars of such approaches
applied to solve a variety of scientific problems.

ÊëòË¶ÅÔºöÂú® ChatGPT ÂæåÁöÑ‰∏ñÁïå‰∏≠ÔºåÊú¨ÊñáÊé¢Ë®é‰∫ÜÂà©Áî®ÂèØÊì¥ÂÖÖÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÄ≤Ë°åÁßëÂ≠∏ÁôºÁèæÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÊèêÂá∫ÔºåÂú®È´òÊÄßËÉΩÈÅãÁÆóÂπ≥Âè∞‰∏äÊì¥ÂÖÖ‰∫∫Â∑•Êô∫ÊÖßÂ∞çÊñºËß£Ê±∫ÈÄô‰∫õË§áÈõúÂïèÈ°åËá≥ÈóúÈáçË¶Å„ÄÇÊ≠§ËßÄÈªûËëóÈáçÊñºÁßëÂ≠∏Áî®‰æãÔºå‰æãÂ¶ÇË™çÁü•Ê®°Êì¨„ÄÅÁî®ÊñºÁßëÂ≠∏Êé¢Á©∂ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÂíåÁâ©ÁêÜË≥áË®äÊñπÊ≥ï„ÄÇÊú¨Á†îÁ©∂Ê¶ÇËø∞‰∫ÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÊâÄÈúÄÁöÑÊäÄË°ìÔºå‰ª•‰æøÂú®Ë∂ÖÁ¥öÈõªËÖ¶ÊàñÈõ≤Á´ØÊì¥ÂÖÖÔºå‰∏¶Êèê‰æõÊ≠§È°ûÊñπÊ≥ïÁöÑÁØÑ‰æãÔºå‰ª•Ëß£Ê±∫ÂêÑÁ®ÆÁßëÂ≠∏ÂïèÈ°å„ÄÇ

##### **PIC2O-Sim: A Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator for Ultra-Fast Photonic Device FDTD Simulation**
2406.17810v1 by Pingchuan Ma, Haoyu Yang, Zhengqi Gao, Duane S. Boning, Jiaqi Gu

The finite-difference time-domain (FDTD) method, which is important in
photonic hardware design flow, is widely adopted to solve time-domain Maxwell
equations. However, FDTD is known for its prohibitive runtime cost, taking
minutes to hours to simulate a single device. Recently, AI has been applied to
realize orders-of-magnitude speedup in partial differential equation (PDE)
solving. However, AI-based FDTD solvers for photonic devices have not been
clearly formulated. Directly applying off-the-shelf models to predict the
optical field dynamics shows unsatisfying fidelity and efficiency since the
model primitives are agnostic to the unique physical properties of Maxwell
equations and lack algorithmic customization. In this work, we thoroughly
investigate the synergy between neural operator designs and the physical
property of Maxwell equations and introduce a physics-inspired AI-based FDTD
prediction framework PIC2O-Sim which features a causality-aware dynamic
convolutional neural operator as its backbone model that honors the space-time
causality constraints via careful receptive field configuration and explicitly
captures the permittivity-dependent light propagation behavior via an efficient
dynamic convolution operator. Meanwhile, we explore the trade-offs among
prediction scalability, fidelity, and efficiency via a multi-stage partitioned
time-bundling technique in autoregressive prediction. Multiple key techniques
have been introduced to mitigate iterative error accumulation while maintaining
efficiency advantages during autoregressive field prediction. Extensive
evaluations on three challenging photonic device simulation tasks have shown
the superiority of our PIC2O-Sim method, showing 51.2% lower roll-out
prediction error, 23.5 times fewer parameters than state-of-the-art neural
operators, providing 300-600x higher simulation speed than an open-source FDTD
numerical solver.

ÊëòË¶ÅÔºöÊôÇÂüüÊúâÈôêÂ∑ÆÂàÜÊ≥ï (FDTD) „ÅØ„ÄÅÂÖâ„Éè„Éº„Éâ„Ç¶„Çß„Ç¢Ë®≠Ë®à„Éï„É≠„Éº„Å´„Åä„ÅÑ„Å¶ÈáçË¶Å„Å™ÊâãÊ≥ï„Åß„ÄÅÊôÇÈ†òÂüü„Éû„ÇØ„Çπ„Ç¶„Çß„É´ÊñπÁ®ãÂºè„ÇíËß£„Åè„Åü„ÇÅ„Å´Â∫É„ÅèÊé°Áî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åü„Å†„Åó„ÄÅFDTD „ÅØ„Åù„ÅÆËÜ®Â§ß„Å™„É©„É≥„Çø„Ç§„É†„Ç≥„Çπ„Éà„ÅßÁü•„Çâ„Çå„Å¶„Åä„Çä„ÄÅ1 „Å§„ÅÆ„Éá„Éê„Ç§„Çπ„Çí„Ç∑„Éü„É•„É¨„Éº„Éà„Åô„Çã„ÅÆ„Å´Êï∞ÂàÜ„Åã„ÇâÊï∞ÊôÇÈñì„Åã„Åã„Çä„Åæ„Åô„ÄÇÊúÄËøë„ÄÅAI „ÅåÂÅèÂæÆÂàÜÊñπÁ®ãÂºè (PDE) „ÅÆËß£Ê≥ï„Å´„Åä„Åë„ÇãÊ°ÅÈÅï„ÅÑ„ÅÆÈ´òÈÄüÂåñ„ÇíÂÆüÁèæ„Åô„Çã„Åü„ÇÅ„Å´ÈÅ©Áî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åó„Åã„Åó„ÄÅÂÖâ„Éá„Éê„Ç§„ÇπÂêë„Åë„ÅÆ AI „Éô„Éº„Çπ„ÅÆ FDTD „ÇΩ„É´„Éê„Éº„ÅØÊòéÁ¢∫„Å´ÂÆöÂºèÂåñ„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇÂ∏ÇË≤©„ÅÆ„É¢„Éá„É´„Çí„Åù„ÅÆ„Åæ„ÅæÈÅ©Áî®„Åó„Å¶ÂÖâÂ†¥„ÅÆ„ÉÄ„Ç§„Éä„Éü„ÇØ„Çπ„Çí‰∫àÊ∏¨„Åô„Çã„Å®„ÄÅ„É¢„Éá„É´„ÅÆÂü∫Êú¨Ë¶ÅÁ¥†„Åå„Éû„ÇØ„Çπ„Ç¶„Çß„É´ÊñπÁ®ãÂºè„ÅÆÂõ∫Êúâ„ÅÆÁâ©ÁêÜÁâπÊÄß„Å´ÁÑ°Èñ¢‰øÇ„Åß„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÅÆ„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„ÅåÊ¨†Â¶Ç„Åó„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅÂø†ÂÆüÂ∫¶„Å®ÂäπÁéá„Åå‰∏çÂçÅÂàÜ„Å´„Å™„Çä„Åæ„Åô„ÄÇ„Åì„ÅÆÁ†îÁ©∂„Åß„ÅØ„ÄÅ„Éã„É•„Éº„É©„É´ÊºîÁÆóÂ≠ê„ÅÆË®≠Ë®à„Å®„Éû„ÇØ„Çπ„Ç¶„Çß„É´ÊñπÁ®ãÂºè„ÅÆÁâ©ÁêÜÁâπÊÄß„Å®„ÅÆÁõ∏‰πóÂäπÊûú„ÇíÂæπÂ∫ïÁöÑ„Å´Ë™øÊüª„Åó„ÄÅÁâ©ÁêÜÂ≠¶„Å´Âü∫„Å•„Åè AI „Éô„Éº„Çπ„ÅÆ FDTD ‰∫àÊ∏¨„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ PIC2O-Sim „ÇíÂ∞éÂÖ•„Åó„Åæ„Åô„ÄÇPIC2O-Sim „ÅØ„ÄÅÊÖéÈáç„Å™ÂèóÂÆπÈáéÊßãÊàê„Å´„Çà„Å£„Å¶ÊôÇÁ©∫ÈñìÂõ†ÊûúÂæãÂà∂Á¥Ñ„ÇíÂ∞äÈáç„Åó„ÄÅÂäπÁéáÁöÑ„Å™ÂãïÁöÑÁï≥„ÅøËæº„ÅøÊºîÁÆóÂ≠ê„Å´„Çà„Å£„Å¶Ë™òÈõªÁéá‰æùÂ≠ò„ÅÆÂÖâ‰ºùÊê¨ÊåôÂãï„ÇíÊòéÁ§∫ÁöÑ„Å´Êçâ„Åà„Çã„ÄÅÂõ†ÊûúÂæã„ÇíË™çË≠ò„Åô„ÇãÂãïÁöÑÁï≥„ÅøËæº„Åø„Éã„É•„Éº„É©„É´ÊºîÁÆóÂ≠ê„Çí„Éê„ÉÉ„ÇØ„Éú„Éº„É≥„É¢„Éá„É´„Å®„Åó„Å¶ÂÇô„Åà„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åù„ÅÆ‰∏ÄÊñπ„Åß„ÄÅËá™Â∑±ÂõûÂ∏∞‰∫àÊ∏¨„Å´„Åä„Åë„Çã„Éû„É´„ÉÅ„Çπ„ÉÜ„Éº„Ç∏„Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„É≥ÊôÇÈñì„Éê„É≥„Éâ„É™„É≥„Ç∞ÊâãÊ≥ï„Å´„Çà„Å£„Å¶„ÄÅ‰∫àÊ∏¨„ÅÆ„Çπ„Ç±„Éº„É©„Éì„É™„ÉÜ„Ç£„ÄÅÂø†ÂÆüÂ∫¶„ÄÅÂäπÁéá„ÅÆÈñì„ÅÆ„Éà„É¨„Éº„Éâ„Ç™„Éï„ÇíË™øÊüª„Åó„Åæ„Åô„ÄÇËá™Â∑±ÂõûÂ∏∞Â†¥„ÅÆ‰∫àÊ∏¨‰∏≠„Å´ÂäπÁéá„ÅÆÂà©ÁÇπ„ÇíÁ∂≠ÊåÅ„Åó„Å™„Åå„ÇâÂèçÂæ©ÁöÑ„Å™Ë™§„Çä„ÅÆËìÑÁ©ç„ÇíËªΩÊ∏õ„Åô„Çã„Åü„ÇÅ„Å´„ÄÅË§áÊï∞„ÅÆ‰∏ªË¶Å„Å™ÊâãÊ≥ï„ÅåÂ∞éÂÖ•„Åï„Çå„Åæ„Åó„Åü„ÄÇ3 „Å§„ÅÆÂõ∞Èõ£„Å™ÂÖâ„Éá„Éê„Ç§„Çπ„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥„Çø„Çπ„ÇØ„Å´Èñ¢„Åô„ÇãÂ∫ÉÁØÑ„Å™Ë©ï‰æ°„Å´„Çà„Çä„ÄÅPIC2O-Sim ÊâãÊ≥ï„ÅÆÂÑ™‰ΩçÊÄß„ÅåÁ§∫„Åï„Çå„ÄÅ51.2% ‰Ωé„ÅÑ„É≠„Éº„É´„Ç¢„Ç¶„Éà‰∫àÊ∏¨Ë™§Â∑Æ„ÄÅÊúÄÂÖàÁ´Ø„ÅÆ„Éã„É•„Éº„É©„É´ÊºîÁÆóÂ≠ê„Çà„Çä„ÇÇ 23.5 ÂÄçÂ∞ë„Å™„ÅÑ„Éë„É©„É°„Éº„Çø„Éº„ÄÅ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ FDTD Êï∞ÂÄ§„ÇΩ„É´„Éê„Éº„Çà„Çä„ÇÇ 300 ÔΩû 600 ÂÄçÈ´òÈÄü„Å™„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥ÈÄüÂ∫¶„ÅåÊèê‰æõ„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

##### **The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources**
2406.16746v2 by Shayne Longpre, Stella Biderman, Alon Albalak, Hailey Schoelkopf, Daniel McDuff, Sayash Kapoor, Kevin Klyman, Kyle Lo, Gabriel Ilharco, Nay San, Maribeth Rauh, Aviya Skowron, Bertie Vidgen, Laura Weidinger, Arvind Narayanan, Victor Sanh, David Adelani, Percy Liang, Rishi Bommasani, Peter Henderson, Sasha Luccioni, Yacine Jernite, Luca Soldaini

Foundation model development attracts a rapidly expanding body of
contributors, scientists, and applications. To help shape responsible
development practices, we introduce the Foundation Model Development
Cheatsheet: a growing collection of 250+ tools and resources spanning text,
vision, and speech modalities. We draw on a large body of prior work to survey
resources (e.g. software, documentation, frameworks, guides, and practical
tools) that support informed data selection, processing, and understanding,
precise and limitation-aware artifact documentation, efficient model training,
advance awareness of the environmental impact from training, careful model
evaluation of capabilities, risks, and claims, as well as responsible model
release, licensing and deployment practices. We hope this curated collection of
resources helps guide more responsible development. The process of curating
this list, enabled us to review the AI development ecosystem, revealing what
tools are critically missing, misused, or over-used in existing practices. We
find that (i) tools for data sourcing, model evaluation, and monitoring are
critically under-serving ethical and real-world needs, (ii) evaluations for
model safety, capabilities, and environmental impact all lack reproducibility
and transparency, (iii) text and particularly English-centric analyses continue
to dominate over multilingual and multi-modal analyses, and (iv) evaluation of
systems, rather than just models, is needed so that capabilities and impact are
assessed in context.

ÊëòË¶ÅÔºöÂü∫Á§éÊ®°ÂûãÈñãÁôºÂê∏Âºï‰∫ÜËøÖÈÄüÊì¥Â±ïÁöÑË≤¢ÁçªËÄÖ„ÄÅÁßëÂ≠∏ÂÆ∂ÂíåÊáâÁî®Á®ãÂºè‰∏ªÈ´î„ÄÇÁÇ∫‰∫ÜÂçîÂä©Â°ëÈÄ†Ë≤†Ë≤¨‰ªªÁöÑÈñãÁôºÂØ¶ÂãôÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü„ÄåÂü∫Á§éÊ®°ÂûãÈñãÁôºÁßòÁ¨à„ÄçÔºö‰∏ÄÂÄãÂåÖÂê´Ë∂ÖÈÅé 250 ÂÄãÂ∑•ÂÖ∑ÂíåË≥áÊ∫êÁöÑÊàêÈï∑‰∏≠ÈõÜÂêàÔºåÊ∂µËìãÊñáÂ≠ó„ÄÅË¶ñË¶∫ÂíåË™ûÈü≥Ê®°Âºè„ÄÇÊàëÂÄëÂà©Áî®Â§ßÈáèÁöÑÂÖàÂâçÂ∑•‰Ωú‰æÜË™øÊü•Ë≥áÊ∫êÔºà‰æãÂ¶ÇËªüÈ´î„ÄÅÊñá‰ª∂„ÄÅÊû∂Êßã„ÄÅÊåáÂçóÂíåÂØ¶Áî®Â∑•ÂÖ∑ÔºâÔºåÈÄô‰∫õË≥áÊ∫êÊîØÊè¥ÊòéÊô∫ÁöÑË≥áÊñôÈÅ∏Êìá„ÄÅËôïÁêÜÂíåÁêÜËß£„ÄÅÁ≤æÁ¢∫‰∏îÂÖ∑ÂÇôÈôêÂà∂ÊÑèË≠òÁöÑ‰∫∫Â∑•Áî¢Âá∫Êñá‰ª∂„ÄÅÊúâÊïàÁéáÁöÑÊ®°ÂûãË®ìÁ∑¥„ÄÅÊèêÂâç‰∫ÜËß£Ë®ìÁ∑¥Â∞çÁí∞Â¢ÉÁöÑÂΩ±Èüø„ÄÅ‰ªîÁ¥∞Ë©ï‰º∞Ê®°ÂûãÁöÑËÉΩÂäõ„ÄÅÈ¢®Èö™ÂíåËÅ≤ÊòéÔºå‰ª•ÂèäË≤†Ë≤¨‰ªªÁöÑÊ®°ÂûãÁôºÂ∏É„ÄÅÊéàÊ¨äÂíåÈÉ®ÁΩ≤ÂØ¶Âãô„ÄÇÊàëÂÄëÂ∏åÊúõÈÄôÂÄãÁ∂ìÈÅéÊï¥ÁêÜÁöÑË≥áÊ∫êÈõÜÂêàÊúâÂä©ÊñºÂºïÂ∞éÊõ¥Ë≤†Ë≤¨‰ªªÁöÑÈñãÁôº„ÄÇÊï¥ÁêÜÈÄôÂÄãÊ∏ÖÂñÆÁöÑÈÅéÁ®ãËÆìÊàëÂÄëÂæó‰ª•Ê™¢Ë¶ñ AI ÈñãÁôºÁîüÊÖãÁ≥ªÁµ±ÔºåÊè≠Èú≤ÁèæÊúâÂØ¶Âãô‰∏≠Âì™‰∫õÂ∑•ÂÖ∑Âö¥Èáç‰∏çË∂≥„ÄÅ‰ΩøÁî®‰∏çÁï∂ÊàñÈÅéÂ∫¶‰ΩøÁî®„ÄÇÊàëÂÄëÁôºÁèæÔºö(i) Ë≥áÊñô‰æÜÊ∫ê„ÄÅÊ®°ÂûãË©ï‰º∞ÂíåÁõ£ÊéßÁöÑÂ∑•ÂÖ∑Âö¥ÈáçÁÑ°Ê≥ïÊªøË∂≥ÈÅìÂæ∑ÂíåÁèæÂØ¶‰∏ñÁïåÁöÑÈúÄÊ±ÇÔºå(ii) Ê®°ÂûãÂÆâÂÖ®ÊÄß„ÄÅËÉΩÂäõÂíåÁí∞Â¢ÉÂΩ±ÈüøÁöÑË©ï‰º∞ÈÉΩÁº∫‰πèÂèØË§áË£ΩÊÄßÂíåÈÄèÊòéÂ∫¶Ôºå(iii) ÊñáÂ≠óÂíåÁâπÂà•ÊòØËã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑÂàÜÊûêÊåÅÁ∫å‰∏ªÂ∞éÂ§öË™ûË®ÄÂíåÂ§öÊ®°ÂºèÂàÜÊûêÔºåËÄå‰∏î (iv) ÈúÄË¶ÅË©ï‰º∞Á≥ªÁµ±ÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÊ®°ÂûãÔºå‰ª•‰æøÂú®‰∏ä‰∏ãÊñá‰∏≠Ë©ï‰º∞ËÉΩÂäõÂíåÂΩ±Èüø„ÄÇ

##### **Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings**
2406.16611v1 by Andrea Posada, Daniel Rueckert, Felix Meissen, Philip M√ºller

Since the emergence of the Transformer architecture, language model
development has increased, driven by their promising potential. However,
releasing these models into production requires properly understanding their
behavior, particularly in sensitive domains such as medicine. Despite this
need, the medical literature still lacks technical assessments of pre-trained
language models, which are especially valuable in resource-constrained settings
in terms of computational power or limited budget. To address this gap, we
provide a comprehensive survey of language models in the medical domain. In
addition, we selected a subset of these models for thorough evaluation,
focusing on classification and text generation tasks. Our subset encompasses 53
models, ranging from 110 million to 13 billion parameters, spanning the three
families of Transformer-based models and from diverse knowledge domains. This
study employs a series of approaches for text classification together with
zero-shot prompting instead of model training or fine-tuning, which closely
resembles the limited resource setting in which many users of language models
find themselves. Encouragingly, our findings reveal remarkable performance
across various tasks and datasets, underscoring the latent potential of certain
models to contain medical knowledge, even without domain specialization.
Consequently, our study advocates for further exploration of model applications
in medical contexts, particularly in resource-constrained settings. The code is
available on https://github.com/anpoc/Language-models-in-medicine.

ÊëòË¶ÅÔºöËá™ Transformer Êû∂ÊßãÂïè‰∏ñ‰ª•‰æÜÔºåË™ûË®ÄÊ®°ÂûãÂú®ÊΩõÂäõÂÇôÂèóÁúãÂ•Ω‰∏ãÔºåÁôºÂ±ïÂ¶ÇÁÅ´Â¶ÇËçº„ÄÇÁÑ∂ËÄåÔºåÂ∞áÈÄô‰∫õÊ®°ÂûãÊáâÁî®ÊñºÁîüÁî¢Áí∞Â¢ÉÔºåÈúÄË¶ÅÈÅ©Áï∂Âú∞‰∫ÜËß£ÂÖ∂Ë°åÁÇ∫ÔºåÁâπÂà•ÊòØÂú®ÈÜ´Â≠∏Á≠âÊïèÊÑüÈ†òÂüü„ÄÇÂÑòÁÆ°ÊúâÊ≠§ÈúÄÊ±ÇÔºåÈÜ´Â≠∏ÊñáÁçª‰ªçÁº∫‰πèÂ∞çÈ†êÂÖàË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÊäÄË°ìË©ï‰º∞ÔºåËÄåÈÄôÂú®ÈÅãÁÆóËÉΩÂäõÊàñÈ†êÁÆóÊúâÈôêÁöÑË≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÁâπÂà•ÊúâÂÉπÂÄº„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÂ∞çÈÜ´Â≠∏È†òÂüüÁöÑË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊåëÈÅ∏‰∫ÜÂÖ∂‰∏≠‰∏ÄÈÉ®ÂàÜÊ®°ÂûãÈÄ≤Ë°åÂæπÂ∫ïË©ï‰º∞ÔºåÈáçÈªûÂú®ÊñºÂàÜÈ°ûÂíåÊñáÂ≠óÁîüÊàê‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÂ≠êÈõÜÊ∂µËìã 53 ÂÄãÊ®°ÂûãÔºåÂèÉÊï∏Âæû 1.1 ÂÑÑÂà∞ 130 ÂÑÑ‰∏çÁ≠âÔºåÊ©´Ë∑® Transformer ÁÇ∫Âü∫Á§éÁöÑÊ®°ÂûãÁöÑ‰∏âÂÄãÁ≥ªÂàóÔºå‰∏îÊ∂µËìãÂ§öÂÖÉÁöÑÁü•Ë≠òÈ†òÂüü„ÄÇÊú¨Á†îÁ©∂Êé°Áî®‰∏ÄÁ≥ªÂàóÊñáÂ≠óÂàÜÈ°ûÊñπÊ≥ïÔºå‰∏¶Êê≠ÈÖçÈõ∂Ê¨°ÊèêÁ§∫ÔºåËÄåÈùûÊ®°ÂûãË®ìÁ∑¥ÊàñÂæÆË™øÔºåÈÄôËàáË®±Â§öË™ûË®ÄÊ®°Âûã‰ΩøÁî®ËÄÖË∫´ËôïÁöÑË≥áÊ∫êÂèóÈôêÁí∞Â¢ÉÈùûÂ∏∏È°û‰ºº„ÄÇ‰ª§‰∫∫ÊåØÂ•ÆÁöÑÊòØÔºåÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫Âú®ÂêÑÁ®Æ‰ªªÂãôÂíåË≥áÊñôÈõÜ‰∏äÈÉΩÊúâÂÇëÂá∫ÁöÑË°®ÁèæÔºåÂº∑Ë™ø‰∫ÜÊüê‰∫õÊ®°ÂûãÂú®Ê≤íÊúâÈ†òÂüüÂ∞àÊ•≠Áü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ãÔºåËòäÂê´ÈÜ´Â≠∏Áü•Ë≠òÁöÑÊΩõÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂‰∏ªÂºµÈÄ≤‰∏ÄÊ≠•Êé¢Ë®éÊ®°ÂûãÂú®ÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/anpoc/Language-models-in-medicine ÂèñÂæó„ÄÇ

##### **Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models**
2406.16455v1 by Daniel Lopez-Martinez

Generative AI (GenAI) models have demonstrated remarkable capabilities in a
wide variety of medical tasks. However, as these models are trained using
generalist datasets with very limited human oversight, they can learn uses of
medical products that have not been adequately evaluated for safety and
efficacy, nor approved by regulatory agencies. Given the scale at which GenAI
may reach users, unvetted recommendations pose a public health risk. In this
work, we propose an approach to identify potentially harmful product
recommendations, and demonstrate it using a recent multimodal large language
model.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI (GenAI) Ê®°ÂûãÂú®ÂêÑÁßçÂåªÁñó‰ªªÂãô‰∏≠Â±ïÁ§∫Âá∫ÈùûÂá°ÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈÄô‰∫õÊ®°ÂûãÊòØ‰ΩøÁî®ÈùûÂ∏∏ÊúâÈôêÁöÑ‰∫∫È°ûÁõ£Áù£ÁöÑ‰∏ÄËà¨Ë≥áÊñôÈõÜÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂõ†Ê≠§ÂÆÉÂÄëÂèØ‰ª•Â≠∏ÁøíÂ∞öÊú™ÂÖÖÂàÜË©ï‰º∞ÂÖ∂ÂÆâÂÖ®ÊÄßÂíåÊúâÊïàÊÄßÔºå‰πüÊú™Á∂ìÁõ£ÁÆ°Ê©üÊßãÊâπÂáÜÁöÑÈÜ´ÁôÇÁî¢ÂìÅÁî®ÈÄî„ÄÇÈëëÊñº GenAI ÂèØËÉΩÊé•Ëß∏‰ΩøÁî®ËÄÖÁöÑË¶èÊ®°ÔºåÊú™Á∂ìÂØ©Êü•ÁöÑÂª∫Ë≠∞ÊúÉÊßãÊàêÂÖ¨ÂÖ±ÂÅ•Â∫∑È¢®Èö™„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆË≠òÂà•ÊΩõÂú®ÊúâÂÆ≥Áî¢ÂìÅÂª∫Ë≠∞ÁöÑÊñπÊ≥ïÔºå‰∏¶‰ΩøÁî®ÊúÄËøëÁöÑÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÁ§∫ÁØÑ„ÄÇ

##### **A large language model for predicting T cell receptor-antigen binding specificity**
2406.16995v1 by Xing Fang, Chenpeng Yu, Shiye Tian, Hui Liu

The human immune response depends on the binding of T-cell receptors (TCRs)
to antigens (pTCR), which elicits the T cells to eliminate viruses, tumor
cells, and other pathogens. The ability of human immunity system responding to
unknown viruses and bacteria stems from the TCR diversity. However, this vast
diversity poses challenges on the TCR-antigen binding prediction methods. In
this study, we propose a Masked Language Model (MLM), referred to as tcrLM, to
overcome limitations in model generalization. Specifically, we randomly masked
sequence segments and train tcrLM to infer the masked segment, thereby extract
expressive feature from TCR sequences. Meanwhile, we introduced virtual
adversarial training techniques to enhance the model's robustness. We built the
largest TCR CDR3 sequence dataset to date (comprising 2,277,773,840 residuals),
and pre-trained tcrLM on this dataset. Our extensive experimental results
demonstrate that tcrLM achieved AUC values of 0.937 and 0.933 on independent
test sets and external validation sets, respectively, which remarkably
outperformed four previously published prediction methods. On a large-scale
COVID-19 pTCR binding test set, our method outperforms the current
state-of-the-art method by at least 8%, highlighting the generalizability of
our method. Furthermore, we validated that our approach effectively predicts
immunotherapy response and clinical outcomes on a clinical cohorts. These
findings clearly indicate that tcrLM exhibits significant potential in
predicting antigenic immunogenicity.

ÊëòË¶ÅÔºö‰∫∫È´îÂÖçÁñ´ÂèçÊáâÂèñÊ±∫Êñº T Á¥∞ËÉûÂèóÈ´î (TCR) ËàáÊäóÂéü (pTCR) ÁöÑÁµêÂêàÔºåÈÄôÊúÉÂºïÁôº T Á¥∞ËÉûÊ∂àÈô§ÁóÖÊØí„ÄÅËÖ´Áò§Á¥∞ËÉûÂíåÂÖ∂‰ªñÁóÖÂéüÈ´î„ÄÇ‰∫∫È´îÂÖçÁñ´Á≥ªÁµ±Â∞çÊú™Áü•ÁóÖÊØíÂíåÁ¥∞ËèåÂÅöÂá∫ÂèçÊáâÁöÑËÉΩÂäõÊ∫êÊñº TCR ÁöÑÂ§öÊ®£ÊÄß„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÂª£Ê≥õÁöÑÂ§öÊ®£ÊÄßÂ∞ç TCR-ÊäóÂéüÁµêÂêàÈ†êÊ∏¨ÊñπÊ≥ïÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ tcrLM ÁöÑÈÅÆÁΩ©Ë™ûË®ÄÊ®°Âûã (MLM)Ôºå‰ª•ÂÖãÊúçÊ®°ÂûãÊ¶ÇÊã¨‰∏≠ÁöÑÈôêÂà∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈö®Ê©üÈÅÆÁΩ©Â∫èÂàóÁâáÊÆµ‰∏¶Ë®ìÁ∑¥ tcrLM Êé®Êñ∑ÈÅÆÁΩ©ÁâáÊÆµÔºåÂæûËÄåÂæû TCR Â∫èÂàó‰∏≠ÊèêÂèñË°®ÈÅîÁâπÂæµ„ÄÇÂêåÊôÇÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËôõÊì¨Â∞çÊäóË®ìÁ∑¥ÊäÄË°ì‰æÜÂ¢ûÂº∑Ê®°ÂûãÁöÑÈ≠ØÊ£íÊÄß„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÂ§ßÁöÑ TCR CDR3 Â∫èÂàóÊï∏ÊìöÈõÜÔºàÂåÖÂê´ 2,277,773,840 ÂÄãÊÆòÂü∫ÔºâÔºå‰∏¶Âú®Ë©≤Êï∏ÊìöÈõÜ‰∏äÈ†êË®ìÁ∑¥‰∫Ü tcrLM„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåtcrLM Âú®Áç®Á´ãÊ∏¨Ë©¶ÈõÜÂíåÂ§ñÈÉ®È©óË≠âÈõÜ‰∏äÂàÜÂà•ÂØ¶Áèæ‰∫Ü 0.937 Âíå 0.933 ÁöÑ AUC ÂÄºÔºåÈÄôÈ°ØËëóÂÑ™ÊñºÂõõÁ®ÆÂÖàÂâçÁôºË°®ÁöÑÈ†êÊ∏¨ÊñπÊ≥ï„ÄÇÂú®‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑ COVID-19 pTCR ÁµêÂêàÊ∏¨Ë©¶ÈõÜ‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊØîÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãËá≥Â∞ëÈ´òÂá∫ 8%ÔºåÁ™ÅÂá∫‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÊ¶ÇÊã¨ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÊúâÊïàÈ†êÊ∏¨‰∫ÜËá®Â∫ä‰∫∫Áæ§ÁöÑÂÖçÁñ´Ê≤ªÁôÇÂèçÊáâÂíåËá®Â∫äÁµêÊûú„ÄÇÈÄô‰∫õÁôºÁèæÊòéÁ¢∫Ë°®Êòé tcrLM Âú®È†êÊ∏¨ÊäóÂéüÂÖçÁñ´ÂéüÊÄßÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇ

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

ÊëòË¶ÅÔºöÂÅ•Â∫∑Áõ£ÊéßÁ≥ªÁµ±ÈÄèÈÅéÊåÅÁ∫åÊî∂ÈõÜÁîüÁêÜÂíåË°åÁÇ∫Ë≥áÊñôÔºåÂæπÂ∫ïÊîπËÆä‰∫ÜÁèæ‰ª£ÈÜ´ÁôÇ‰øùÂÅ•ÔºåÈÄô‰∫õË≥áÊñôÂ∞çÊñºÈ†êÈò≤Êé™ÊñΩÂíåÊó©ÊúüÂÅ•Â∫∑Âπ≤È†êËá≥ÈóúÈáçË¶Å„ÄÇÈõñÁÑ∂Â∞áÈÄô‰∫õË≥áÊñôËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êï¥ÂêàÔºåÂ∑≤Â±ïÁèæÂá∫Êèê‰æõ‰∫íÂãïÂºèÂÅ•Â∫∑Âª∫Ë≠∞ÁöÑÊΩõÂäõÔºå‰ΩÜÂÇ≥Áµ±ÊñπÊ≥ïÔºà‰æãÂ¶ÇÊ™¢Á¥¢Êì¥ÂÖÖÁîüÊàê (RAG) ÂíåÂæÆË™øÔºâÈÄöÂ∏∏ÁÑ°Ê≥ïÂÖÖÂàÜÂà©Áî®Á©øÊà¥ÂºèË£ùÁΩÆ‰∏≠Ë§áÈõú„ÄÅÂ§öÈù¢Âêë‰∏îËàáÊôÇÈñìÁõ∏ÈóúÁöÑË≥áÊñô„ÄÇÈÄô‰∫õÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏ÊúÉÊèê‰æõÊúâÈôêÁöÑÂèØË°å‰∏îÂÄã‰∫∫ÂåñÁöÑÂÅ•Â∫∑Ë¶ãËß£ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁÑ°Ê≥ïÂãïÊÖãÊï¥ÂêàÂíåË©ÆÈáã‰∏çÂêåÁöÑÂÅ•Â∫∑Ë≥áÊñô‰∏≤ÊµÅ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂúñÂΩ¢Êì¥ÂÖÖ LLM Êû∂ÊßãÔºåÊó®Âú®Â§ßÂπÖÊèêÂçáÂÅ•Â∫∑Ë¶ãËß£ÁöÑÂÄã‰∫∫ÂåñÂíåÊ∏ÖÊô∞Â∫¶„ÄÇÈÄôÂÄãÊû∂ÊßãÂà©Áî®ÈöéÂ±§ÂºèÂúñÂΩ¢ÁµêÊßãÔºåÊì∑ÂèñÊÇ£ËÄÖ‰πãÈñìÂíåÊÇ£ËÄÖÂÖßÈÉ®ÁöÑÈóú‰øÇÔºå‰∏¶‰ΩøÁî®Âæû Random Forest Ê®°ÂûãË°çÁîüÁöÑÂãïÊÖãÁâπÂæµÈáçË¶ÅÊÄßË©ïÂàÜÔºåË±êÂØå LLM ÊèêÁ§∫„ÄÇÈÄèÈÅé‰∏ÄÈ†ÖÁù°Áú†ÂàÜÊûêÊ°à‰æãÁ†îÁ©∂ÔºàÂú® COVID-19 Â∞ÅÈéñÊúüÈñìÈáùÂ∞ç 20 ÂêçÂ§ßÂ≠∏ÁîüÈÄ≤Ë°åÔºâË≠âÊòé‰∫ÜÈÄôÂÄãÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊúâÊïàÁî¢ÁîüÂèØË°å‰∏îÂÄã‰∫∫ÂåñÁöÑÂÅ•Â∫∑Ë¶ãËß£ÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÂà©Áî®Âè¶‰∏ÄÂÄã LLM Ë©ï‰º∞Ë¶ãËß£ÁöÑÁõ∏ÈóúÊÄß„ÄÅÂÖ®Èù¢ÊÄß„ÄÅÂèØË°åÊÄßÂíåÂÄã‰∫∫ÂåñÔºåÊªøË∂≥‰∫ÜÊ®°ÂûãÊúâÊïàËôïÁêÜÂíåË©ÆÈáãË§áÈõúÂÅ•Â∫∑Ë≥áÊñôÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå‰ΩøÁî®ÊàëÂÄëÁöÑÊû∂ÊßãÊì¥ÂÖÖÊèêÁ§∫ÔºåÂèØ‰ª•Âú®ÊâÄÊúâ 4 ÂÄãÊ®ôÊ∫ñ‰∏≠Â§ßÂπÖÊîπÂñÑ„ÄÇÈÄèÈÅéÊàëÂÄëÁöÑÊû∂ÊßãÔºåÊàëÂÄëÂèØ‰ª•ÂºïÁôºÁ≤æÂøÉË®≠Ë®à„ÄÅÊõ¥Âë®ÂÖ®ÁöÑÂõûÊáâÔºåÈáùÂ∞çÁâπÂÆöÊÇ£ËÄÖÈáèË∫´ÊâìÈÄ†„ÄÇ

##### **Continuous Output Personality Detection Models via Mixed Strategy Training**
2406.16223v1 by Rong Wang, Kun Sun

The traditional personality models only yield binary results. This paper
presents a novel approach for training personality detection models that
produce continuous output values, using mixed strategies. By leveraging the
PANDORA dataset, which includes extensive personality labeling of Reddit
comments, we developed models that predict the Big Five personality traits with
high accuracy. Our approach involves fine-tuning a RoBERTa-base model with
various strategies such as Multi-Layer Perceptron (MLP) integration, and
hyperparameter tuning. The results demonstrate that our models significantly
outperform traditional binary classification methods, offering precise
continuous outputs for personality traits, thus enhancing applications in AI,
psychology, human resources, marketing and health care fields.

ÊëòË¶ÅÔºöÂÇ≥Áµ±ÁöÑ‰∫∫Ê†ºÊ®°ÂûãÂè™Áî¢Áîü‰∫åÈÄ≤Âà∂ÁµêÊûú„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁî®Ê∑∑ÂêàÁ≠ñÁï•Ë®ìÁ∑¥‰∫∫Ê†ºÊ™¢Ê∏¨Ê®°ÂûãÔºå‰ª•Áî¢ÁîüÈÄ£Á∫åÁöÑËº∏Âá∫ÂÄº„ÄÇÈÄöÈÅéÂà©Áî® PANDORA Êï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨Â∞ç Reddit Ë©ïË´ñÁöÑÂª£Ê≥õ‰∫∫Ê†ºÊ®ôÁ±§ÔºåÊàëÂÄëÈñãÁôº‰∫ÜÂèØ‰ª•È´òÁ≤æÂ∫¶È†êÊ∏¨‰∫îÂ§ßÊÄßÊ†ºÁâπË≥™ÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊ∂âÂèä‰ΩøÁî®Â§öÂ±§ÊÑüÁü•Âô® (MLP) ÈõÜÊàêÂíåË∂ÖÂèÉÊï∏Ë™øÊï¥Á≠âÂêÑÁ®ÆÁ≠ñÁï•‰æÜÂæÆË™ø RoBERTa Âü∫Á§éÊ®°Âûã„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊòéÈ°ØÂÑ™ÊñºÂÇ≥Áµ±ÁöÑ‰∫åÂÖÉÂàÜÈ°ûÊñπÊ≥ïÔºåÁÇ∫‰∫∫Ê†ºÁâπË≥™Êèê‰æõ‰∫ÜÁ≤æÁ¢∫ÁöÑÈÄ£Á∫åËº∏Âá∫ÔºåÂæûËÄåÂ¢ûÂº∑‰∫ÜÂú® AI„ÄÅÂøÉÁêÜÂ≠∏„ÄÅ‰∫∫ÂäõË≥áÊ∫ê„ÄÅÁáüÈä∑ÂíåÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑÊáâÁî®„ÄÇ

##### **On Instabilities of Unsupervised Denoising Diffusion Models in Magnetic Resonance Imaging Reconstruction**
2406.16983v1 by Tianyu Han, Sven Nebelung, Firas Khader, Jakob Nikolas Kather, Daniel Truhn

Denoising diffusion models offer a promising approach to accelerating
magnetic resonance imaging (MRI) and producing diagnostic-level images in an
unsupervised manner. However, our study demonstrates that even tiny worst-case
potential perturbations transferred from a surrogate model can cause these
models to generate fake tissue structures that may mislead clinicians. The
transferability of such worst-case perturbations indicates that the robustness
of image reconstruction may be compromised due to MR system imperfections or
other sources of noise. Moreover, at larger perturbation strengths, diffusion
models exhibit Gaussian noise-like artifacts that are distinct from those
observed in supervised models and are more challenging to detect. Our results
highlight the vulnerability of current state-of-the-art diffusion-based
reconstruction models to possible worst-case perturbations and underscore the
need for further research to improve their robustness and reliability in
clinical settings.

ÊëòË¶ÅÔºöÂéªÂô™Êì¥Êï£Ê®°ÂûãÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•Âä†ÈÄüÁ£ÅÂÖ±ÊåØÊàêÂÉè (MRI) ‰∏¶‰ª•ÁÑ°Áõ£Áù£ÁöÑÊñπÂºèÁî¢ÁîüË®∫Êñ∑Á¥öÂà•ÁöÑÂΩ±ÂÉè„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂç≥‰ΩøÊòØÂæû‰ª£ÁêÜÊ®°ÂûãÂÇ≥Ëº∏ÁöÑÊ•µÂ∞èÊúÄÂ£ûÊÉÖÊ≥ÅÊΩõÂú®ÊìæÂãïÔºå‰πüÊúÉÂ∞éËá¥ÈÄô‰∫õÊ®°ÂûãÁî¢ÁîüÂèØËÉΩË™§Â∞éËá®Â∫äÈÜ´ÁîüÁöÑÂÅáÁµÑÁπîÁµêÊßã„ÄÇÈÄôÁ®ÆÊúÄÂ£ûÊÉÖÊ≥ÅÊìæÂãïÁöÑÂèØÂÇ≥ÈÅûÊÄßË°®ÊòéÔºåÁî±Êñº MR Á≥ªÁµ±Áº∫Èô∑ÊàñÂÖ∂‰ªñÈõúË®ä‰æÜÊ∫êÔºåÂΩ±ÂÉèÈáçÂª∫ÁöÑÁ©©ÂÅ•ÊÄßÂèØËÉΩÊúÉÂèóÂà∞ÊêçÂÆ≥„ÄÇÊ≠§Â§ñÔºåÂú®ËºÉÂ§ßÁöÑÊìæÂãïÂº∑Â∫¶‰∏ãÔºåÊì¥Êï£Ê®°ÂûãÊúÉË°®ÁèæÂá∫ËàáÁõ£Áù£Ê®°Âûã‰∏≠ËßÄÂØüÂà∞ÁöÑ‰∏çÂêåÁöÑÈ´òÊñØÈõúË®äÊ®£ÂºèÁöÑ‰∫∫Â∑•Ë£ΩÂìÅÔºå‰∏¶‰∏îÊõ¥Èõ£‰ª•Ê™¢Ê∏¨„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÊì¥Êï£ÁöÑÈáçÂª∫Ê®°ÂûãÂ∞çÂèØËÉΩÁöÑÊúÄÂ£ûÊÉÖÊ≥ÅÊìæÂãïÁöÑËÑÜÂº±ÊÄßÔºå‰∏¶Âº∑Ë™øÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂‰ª•ÊèêÈ´òÂÖ∂Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÁ©©ÂÅ•ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

##### **Research on Disease Prediction Model Construction Based on Computer AI deep Learning Technology**
2406.16982v1 by Yang Lin, Muqing Li, Ziyi Zhu, Yinqiu Feng, Lingxi Xiao, Zexi Chen

The prediction of disease risk factors can screen vulnerable groups for
effective prevention and treatment, so as to reduce their morbidity and
mortality. Machine learning has a great demand for high-quality labeling
information, and labeling noise in medical big data poses a great challenge to
efficient disease risk warning methods. Therefore, this project intends to
study the robust learning algorithm and apply it to the early warning of
infectious disease risk. A dynamic truncated loss model is proposed, which
combines the traditional mutual entropy implicit weight feature with the mean
variation feature. It is robust to label noise. A lower bound on training loss
is constructed, and a method based on sampling rate is proposed to reduce the
gradient of suspected samples to reduce the influence of noise on training
results. The effectiveness of this method under different types of noise was
verified by using a stroke screening data set as an example. This method
enables robust learning of data containing label noise.

ÊëòË¶ÅÔºöÁñæÁóÖÈ¢®Èö™Âõ†Â≠êÁöÑÈ†êÊ∏¨ÂèØ‰ª•ÁØ©ÈÅ∏Âá∫ËÑÜÂº±ÊóèÁæ§ÔºåÈÄ≤Ë°åÊúâÊïàÁöÑÈ†êÈò≤ÂíåÊ≤ªÁôÇÔºå‰ª•Èôç‰ΩéÂÖ∂ÁΩπÁóÖÁéáÂíåÊ≠ª‰∫°Áéá„ÄÇÊ©üÂô®Â≠∏ÁøíÂ∞çÊñºÈ´òÂìÅË≥™ÁöÑÊ®ôÁ±§Ë≥áË®äÊúâÊ•µÂ§ßÁöÑÈúÄÊ±ÇÔºåËÄåÈÜ´ÁôÇÂ§ßÊï∏Êìö‰∏≠ÁöÑÊ®ôÁ±§ÈõúË®äÂ∞çÊñºÁñæÁóÖÈ¢®Èö™È†êË≠¶ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄ†ÊàêÊ•µÂ§ßÁöÑÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊú¨Ë®àÁï´Êì¨Êé¢Ë®éÂ∞çÊäóÂºèÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºå‰∏¶Â∞áÂÖ∂ÊáâÁî®ÊñºÂÇ≥ÊüìÁóÖÈ¢®Èö™ÁöÑÈ†êË≠¶„ÄÇÊèêÂá∫‰∏ÄÂÄãÂãïÊÖãÊà™Êñ∑ÊêçÂ§±Ê®°ÂûãÔºåÂ∞áÂÇ≥Áµ±ÁöÑ‰∫íË≥áË®äÈö±Âê´Ê¨äÈáçÁâπÂæµËàáÂπ≥ÂùáËÆäÁï∞ÁâπÂæµÁµêÂêàÔºåÂ∞çÊ®ôÁ±§ÈõúË®äÂÖ∑ÊúâÈ≠ØÊ£íÊÄß„ÄÇÂª∫ÊßãË®ìÁ∑¥ÊêçÂ§±ÁöÑ‰∏ãÁïåÔºå‰∏¶ÊèêÂá∫Âü∫ÊñºÊäΩÊ®£ÁéáÁöÑÊñπÊ≥ïÔºåÈôç‰ΩéÁñë‰ººÊ®£Êú¨ÁöÑÊ¢ØÂ∫¶Ôºå‰ª•Èôç‰ΩéÈõúË®äÂ∞çË®ìÁ∑¥ÁµêÊûúÁöÑÂΩ±Èüø„ÄÇ‰ª•‰∏≠È¢®ÁØ©Ê™¢Ë≥áÊñôÈõÜÁÇ∫‰æãÔºåÈ©óË≠âÊ≠§ÊñπÊ≥ïÂú®‰∏çÂêåÂûãÊÖãÈõúË®ä‰∏ãÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§ÊñπÊ≥ïËÉΩÂ∞çÂê´ÊúâÊ®ôÁ±§ÈõúË®äÁöÑË≥áÊñôÈÄ≤Ë°åÈ≠ØÊ£íÂ≠∏Áøí„ÄÇ

##### **Towards Open Respiratory Acoustic Foundation Models: Pretraining and Benchmarking**
2406.16148v1 by Yuwei Zhang, Tong Xia, Jing Han, Yu Wu, Georgios Rizos, Yang Liu, Mohammed Mosuily, Jagmohan Chauhan, Cecilia Mascolo

Respiratory audio, such as coughing and breathing sounds, has predictive
power for a wide range of healthcare applications, yet is currently
under-explored. The main problem for those applications arises from the
difficulty in collecting large labeled task-specific data for model
development. Generalizable respiratory acoustic foundation models pretrained
with unlabeled data would offer appealing advantages and possibly unlock this
impasse. However, given the safety-critical nature of healthcare applications,
it is pivotal to also ensure openness and replicability for any proposed
foundation model solution. To this end, we introduce OPERA, an OPEn Respiratory
Acoustic foundation model pretraining and benchmarking system, as the first
approach answering this need. We curate large-scale respiratory audio datasets
(~136K samples, 440 hours), pretrain three pioneering foundation models, and
build a benchmark consisting of 19 downstream respiratory health tasks for
evaluation. Our pretrained models demonstrate superior performance (against
existing acoustic models pretrained with general audio on 16 out of 19 tasks)
and generalizability (to unseen datasets and new respiratory audio modalities).
This highlights the great promise of respiratory acoustic foundation models and
encourages more studies using OPERA as an open resource to accelerate research
on respiratory audio for health. The system is accessible from
https://github.com/evelyn0414/OPERA.

ÊëòË¶ÅÔºöÂëºÂê∏Èü≥Ë®äÔºå‰æãÂ¶ÇÂí≥ÂóΩÂíåÂëºÂê∏ËÅ≤ÔºåÂ∞çÊñºÂª£Ê≥õÁöÑÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÂÖ∑ÊúâÈ†êÊ∏¨ËÉΩÂäõÔºå‰ΩÜÁõÆÂâç‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÁöÑÊé¢Ë®é„ÄÇÂ∞çÊñºÈÄô‰∫õÊáâÁî®‰æÜË™™Ôºå‰∏ªË¶ÅÂïèÈ°åÂú®ÊñºÈõ£‰ª•Êî∂ÈõÜÁî®ÊñºÊ®°ÂûãÈñãÁôºÁöÑÂ§ßÈáèÊ®ôË®òÁâπÂÆö‰ªªÂãôË≥áÊñô„ÄÇ‰ΩøÁî®Êú™Ê®ôË®òË≥áÊñôÈ†êÂÖàË®ìÁ∑¥ÁöÑÂèØÊ¶ÇÂåñÂëºÂê∏ËÅ≤Â≠∏Âü∫Á§éÊ®°ÂûãÂ∞áÊèê‰æõÊúâÂê∏ÂºïÂäõÁöÑÂÑ™Âã¢Ôºå‰∏¶ÊúâÂèØËÉΩÊâìÁ†¥ÈÄôÁ®ÆÂÉµÂ±Ä„ÄÇÁÑ∂ËÄåÔºåÈëëÊñºÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®ÁöÑÂÆâÂÖ®ÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂõ†Ê≠§Â∞çÊñº‰ªª‰ΩïÊèêÂá∫ÁöÑÂü∫Á§éÊ®°ÂûãËß£Ê±∫ÊñπÊ°àÔºåÁ¢∫‰øùÈñãÊîæÊÄßÂíåÂèØË§áË£ΩÊÄß‰πüËá≥ÈóúÈáçË¶Å„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü OPERAÔºå‰∏ÄÂÄãÈñãÊîæÁöÑÂëºÂê∏ËÅ≤Â≠∏Âü∫Á§éÊ®°ÂûãÈ†êË®ìÁ∑¥ÂíåÂü∫Ê∫ñÁ≥ªÁµ±Ôºå‰ΩúÁÇ∫ÊªøË∂≥Ê≠§ÈúÄÊ±ÇÁöÑÁ¨¨‰∏ÄÁ®ÆÊñπÊ≥ï„ÄÇÊàëÂÄëÁ≠ñÂäÉ‰∫ÜÂ§ßË¶èÊ®°ÁöÑÂëºÂê∏Èü≥Ë®äË≥áÊñôÈõÜÔºàÁ¥Ñ 136K ÂÄãÊ®£Êú¨Ôºå440 Â∞èÊôÇÔºâÔºåÈ†êÂÖàË®ìÁ∑¥‰∫Ü‰∏âÂÄãÈñãÂâµÊÄßÁöÑÂü∫Á§éÊ®°ÂûãÔºå‰∏¶Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 19 ÂÄã‰∏ãÊ∏∏ÂëºÂê∏ÂÅ•Â∫∑‰ªªÂãô‰ª•‰æõË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÂ±ïÁ§∫Âá∫ÂçìË∂äÁöÑÊïàËÉΩÔºàÂú® 19 ÂÄã‰ªªÂãô‰∏≠Êúâ 16 ÂÄã‰ªªÂãôÂÑ™Êñº‰ΩøÁî®‰∏ÄËà¨Èü≥Ë®äÈ†êÂÖàË®ìÁ∑¥ÁöÑÁèæÊúâËÅ≤Â≠∏Ê®°ÂûãÔºâÂíåÊ¶ÇÂåñËÉΩÂäõÔºàÂ∞çÊú™Ë¶ãÈÅéÁöÑË≥áÊñôÈõÜÂíåÊñ∞ÁöÑÂëºÂê∏Èü≥Ë®äÊñπÂºèÔºâ„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÂëºÂê∏ËÅ≤Â≠∏Âü∫Á§éÊ®°ÂûãÁöÑÂ∑®Â§ßÂâçÊôØÔºå‰∏¶ÈºìÂãµÊõ¥Â§öÁ†îÁ©∂‰ΩøÁî® OPERA ‰ΩúÁÇ∫ÈñãÊîæË≥áÊ∫êÔºå‰ª•Âä†ÈÄüÂëºÂê∏Èü≥Ë®äÂú®ÂÅ•Â∫∑ÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇË©≤Á≥ªÁµ±ÂèØÂæû https://github.com/evelyn0414/OPERA ÂèñÂæó„ÄÇ

##### **Predicting Individual Depression Symptoms from Acoustic Features During Speech**
2406.16000v1 by Sebastian Rodriguez, Sri Harsha Dumpala, Katerina Dikaios, Sheri Rempel, Rudolf Uher, Sageev Oore

Current automatic depression detection systems provide predictions directly
without relying on the individual symptoms/items of depression as denoted in
the clinical depression rating scales. In contrast, clinicians assess each item
in the depression rating scale in a clinical setting, thus implicitly providing
a more detailed rationale for a depression diagnosis. In this work, we make a
first step towards using the acoustic features of speech to predict individual
items of the depression rating scale before obtaining the final depression
prediction. For this, we use convolutional (CNN) and recurrent (long short-term
memory (LSTM)) neural networks. We consider different approaches to learning
the temporal context of speech. Further, we analyze two variants of voting
schemes for individual item prediction and depression detection. We also
include an animated visualization that shows an example of item prediction over
time as the speech progresses.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Á≥ªÁµ±ÊúÉÁõ¥Êé•Êèê‰æõÈ†êÊ∏¨ÔºåËÄå‰∏ç‰æùË≥¥Ëá®Â∫äÊÜÇÈ¨±ÁóáË©ïÂàÜÈáèË°®‰∏≠ÊâÄË°®Á§∫ÁöÑÂÄãÂà•ÁóáÁãÄ/È†ÖÁõÆ„ÄÇÁõ∏ËºÉ‰πã‰∏ãÔºåËá®Â∫äÈÜ´ÁîüÊúÉÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠Ë©ï‰º∞ÊÜÇÈ¨±ÁóáË©ïÂàÜÈáèË°®‰∏≠ÁöÑÊØèÂÄãÈ†ÖÁõÆÔºåÂõ†Ê≠§ÊúÉÈö±Âê´Êèê‰æõÊÜÇÈ¨±ÁóáË®∫Êñ∑ÁöÑÊõ¥Ë©≥Á¥∞‰æùÊìö„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË∏èÂá∫Á¨¨‰∏ÄÊ≠•Ôºå‰ΩøÁî®Ë™ûÈü≥ÁöÑÈü≥Ë®äÁâπÂæµ‰æÜÈ†êÊ∏¨ÊÜÇÈ¨±ÁóáË©ïÂàÜÈáèË°®ÁöÑÂÄãÂà•È†ÖÁõÆÔºåÁÑ∂ÂæåÂÜçÂèñÂæóÊúÄÁµÇÁöÑÊÜÇÈ¨±ÁóáÈ†êÊ∏¨„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄë‰ΩøÁî®Âç∑Á©ç (CNN) ÂíåÈÅûËø¥ (Èï∑Áü≠ÊúüË®òÊÜ∂ (LSTM)) Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÊàëÂÄëËÄÉÊÖÆ‰∏çÂêåÁöÑÊñπÊ≥ï‰æÜÂ≠∏ÁøíË™ûÈü≥ÁöÑÊôÇÈñìËÑàÁµ°„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂàÜÊûêÂÖ©Á®ÆÊäïÁ•®ÊñπÊ°àÁöÑËÆäÈ´îÔºåÁî®ÊñºÂÄãÂà•È†ÖÁõÆÈ†êÊ∏¨ÂíåÊÜÇÈ¨±ÁóáÂÅµÊ∏¨„ÄÇÊàëÂÄë‰πüÂåÖÂê´‰∏ÄÂÄãÂãïÁï´Ë¶ñË¶∫ÂåñÔºåÈ°ØÁ§∫Èö®ËëóË™ûÈü≥ÈÄ≤Â±ïÔºåÈ†ÖÁõÆÈ†êÊ∏¨ÁöÑ‰∏ÄÂÄãÁØÑ‰æã„ÄÇ

##### **Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care**
2406.15966v1 by Hassan Alhuzali, Ashwag Alasmari

Pre-trained Language Models (PLMs) have the potential to transform mental
health support by providing accessible and culturally sensitive resources.
However, despite this potential, their effectiveness in mental health care and
specifically for the Arabic language has not been extensively explored. To
bridge this gap, this study evaluates the effectiveness of foundational models
for classification of Questions and Answers (Q&A) in the domain of mental
health care. We leverage the MentalQA dataset, an Arabic collection featuring
Q&A interactions related to mental health. In this study, we conducted
experiments using four different types of learning approaches: traditional
feature extraction, PLMs as feature extractors, Fine-tuning PLMs and prompting
large language models (GPT-3.5 and GPT-4) in zero-shot and few-shot learning
settings. While traditional feature extractors combined with Support Vector
Machines (SVM) showed promising performance, PLMs exhibited even better results
due to their ability to capture semantic meaning. For example, MARBERT achieved
the highest performance with a Jaccard Score of 0.80 for question
classification and a Jaccard Score of 0.86 for answer classification. We
further conducted an in-depth analysis including examining the effects of
fine-tuning versus non-fine-tuning, the impact of varying data size, and
conducting error analysis. Our analysis demonstrates that fine-tuning proved to
be beneficial for enhancing the performance of PLMs, and the size of the
training data played a crucial role in achieving high performance. We also
explored prompting, where few-shot learning with GPT-3.5 yielded promising
results. There was an improvement of 12% for question and classification and
45% for answer classification. Based on our findings, it can be concluded that
PLMs and prompt-based approaches hold promise for mental health support in
Arabic.

ÊëòË¶ÅÔºö<paragraph>È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÊúâÊΩõÂäõÈÄèÈÅéÊèê‰æõÂèØÂ≠òÂèñ‰∏îÂÖ∑ÊñáÂåñÊïèÊÑüÂ∫¶ÁöÑË≥áÊ∫ê‰æÜËΩâÂåñÂøÉÁêÜÂÅ•Â∫∑ÊîØÊåÅ„ÄÇ
ÁÑ∂ËÄåÔºåÂÑòÁÆ°ÊúâÊ≠§ÊΩõÂäõÔºåÂÆÉÂÄëÂú®ÂøÉÁêÜ‰øùÂÅ•‰∏≠ÁöÑÊúâÊïàÊÄßÔºåÁâπÂà•ÊòØÂ∞çÊñºÈòøÊãâ‰ºØË™ûÔºåÂ∞öÊú™Âª£Ê≥õÊé¢Ë®é„ÄÇÁÇ∫‰∫ÜÂΩåË£úÊ≠§Â∑ÆË∑ùÔºåÊú¨Á†îÁ©∂Ë©ï‰º∞Âü∫Á§éÊ®°ÂûãÂú®ÂøÉÁêÜ‰øùÂÅ•È†òÂüü‰∏≠Â∞çÂïèÈ°åËàáËß£Á≠î (Q&A) ÈÄ≤Ë°åÂàÜÈ°ûÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÂà©Áî® MentalQA Ë≥áÊñôÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄã‰ª•ÈòøÊãâ‰ºØË™ûÁÇ∫ÁâπËâ≤ÁöÑÈõÜÂêàÔºåÂåÖÂê´ËàáÂøÉÁêÜÂÅ•Â∫∑Áõ∏ÈóúÁöÑ Q&A ‰∫íÂãï„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®ÂõõÁ®Æ‰∏çÂêåÈ°ûÂûãÁöÑÂ≠∏ÁøíÊñπÊ≥ïÈÄ≤Ë°åÂØ¶È©óÔºöÂÇ≥Áµ±ÁâπÂæµËêÉÂèñ„ÄÅPLM ‰ΩúÁÇ∫ÁâπÂæµËêÉÂèñÂô®„ÄÅÂæÆË™ø PLMÔºå‰ª•ÂèäÂú®Èõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÊ¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠ÊèêÁ§∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (GPT-3.5 Âíå GPT-4)„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÁâπÂæµËêÉÂèñÂô®ÁµêÂêàÊîØÊè¥ÂêëÈáèÊ©ü (SVM) È°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÊïàËÉΩÔºå‰ΩÜ PLM Áî±ÊñºËÉΩÂ§†Êì∑ÂèñË™ûÁæ©ÊÑèÁæ©ÔºåÂõ†Ê≠§Ë°®ÁèæÂæóÊõ¥Â•Ω„ÄÇ‰æãÂ¶ÇÔºåMARBERT Âú®ÂïèÈ°åÂàÜÈ°û‰∏≠ÈÅîÂà∞ÊúÄÈ´òÊïàËÉΩÔºåJaccard ÂæóÂàÜÁÇ∫ 0.80ÔºåÂú®Á≠îÊ°àÂàÜÈ°û‰∏≠ Jaccard ÂæóÂàÜÁÇ∫ 0.86„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄ≤Ë°åÊ∑±ÂÖ•ÂàÜÊûêÔºåÂåÖÊã¨Ê™¢Êü•ÂæÆË™øËàáÈùûÂæÆË™øÁöÑÂΩ±Èüø„ÄÅ‰∏çÂêåË≥áÊñôÂ§ßÂ∞èÁöÑÂΩ±ÈüøÔºå‰ª•ÂèäÈÄ≤Ë°åÈåØË™§ÂàÜÊûê„ÄÇÊàëÂÄëÁöÑÂàÜÊûêË°®ÊòéÔºåÂæÆË™øË¢´Ë≠âÊòéÊúâÂä©ÊñºÊèêÂçá PLM ÁöÑÊïàËÉΩÔºåËÄåË®ìÁ∑¥Ë≥áÊñôÁöÑÂ§ßÂ∞èÂú®ÈÅîÊàêÈ´òÊïàËÉΩ‰∏≠ÊâÆÊºîËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÊàëÂÄë‰πüÊé¢Ë®é‰∫ÜÊèêÁ§∫ÔºåÂÖ∂‰∏≠‰ΩøÁî® GPT-3.5 ÁöÑÂ∞ëÊ¨°Â≠∏ÁøíÁî¢ÁîüÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇÂïèÈ°åËàáÂàÜÈ°ûÈÄ≤Ê≠•‰∫Ü 12%ÔºåÁ≠îÊ°àÂàÜÈ°ûÈÄ≤Ê≠•‰∫Ü 45%„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÂèØ‰ª•ÂæóÂá∫ÁµêË´ñÔºåPLM ÂíåÂü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÊúâÊúõÁÇ∫ÈòøÊãâ‰ºØË™ûÁöÑÂøÉÁêÜÂÅ•Â∫∑Êèê‰æõÊîØÊåÅ„ÄÇ</paragraph>

##### **SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery**
2406.15920v1 by Jialang Xu, Nazir Sirajudeen, Matthew Boal, Nader Francis, Danail Stoyanov, Evangelos Mazomenos

Automated detection of surgical errors can improve robotic-assisted surgery.
Despite promising progress, existing methods still face challenges in capturing
rich temporal context to establish long-term dependencies while maintaining
computational efficiency. In this paper, we propose a novel hierarchical model
named SEDMamba, which incorporates the selective state space model (SSM) into
surgical error detection, facilitating efficient long sequence modelling with
linear complexity. SEDMamba enhances selective SSM with bottleneck mechanism
and fine-to-coarse temporal fusion (FCTF) to detect and temporally localize
surgical errors in long videos. The bottleneck mechanism compresses and
restores features within their spatial dimension, thereby reducing
computational complexity. FCTF utilizes multiple dilated 1D convolutional
layers to merge temporal information across diverse scale ranges, accommodating
errors of varying durations. Besides, we deploy an established observational
clinical human reliability assessment tool (OCHRA) to annotate the errors of
suturing tasks in an open-source radical prostatectomy dataset (SAR-RARP50),
constructing the first frame-level in-vivo surgical error detection dataset to
support error detection in real-world scenarios. Experimental results
demonstrate that our SEDMamba outperforms state-of-the-art methods with at
least 1.82% AUC and 3.80% AP performance gain with significantly reduced
computational complexity.

ÊëòË¶ÅÔºöËá™ÂãïÂÅµÊ∏¨ÊâãË°ìÈåØË™§ÂèØ‰ª•ÊîπÂñÑÊ©üÂô®‰∫∫ËºîÂä©ÊâãË°ì„ÄÇ
ÂÑòÁÆ°Êúâ‰ª§‰∫∫ÊåØÂ•ÆÁöÑÈÄ≤Â±ïÔºåÁèæÊúâÊñπÊ≥ïÂú®ÊçïÊçâË±êÂØåÁöÑÊôÇÈñìËÉåÊôØ‰ª•Âª∫Á´ãÈï∑Êúü‰æùË≥¥Èóú‰øÇÁöÑÂêåÊôÇÔºåÂú®Á∂≠ÊåÅÈÅãÁÆóÊïàÁéáÊñπÈù¢‰ªçÈù¢Ëá®ÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ SEDMamba ÁöÑÊñ∞ÂàÜÂ±§Ê®°ÂûãÔºåÂÆÉÂ∞áÈÅ∏ÊìáÊÄßÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) Á¥çÂÖ•ÊâãË°ìÈåØË™§ÂÅµÊ∏¨‰∏≠Ôºå‰øÉÈÄ≤ÂÖ∑ÊúâÁ∑öÊÄßË§áÈõúÂ∫¶ÁöÑÊúâÊïàÈï∑Â∫èÂàóÂª∫Ê®°„ÄÇSEDMamba ‰ª•Áì∂È†∏Ê©üÂà∂ÂíåÁ≤æÁ¥∞Âà∞Á≤óÁï•ÁöÑÊôÇÈñìËûçÂêà (FCTF) Â¢ûÂº∑ÈÅ∏ÊìáÊÄß SSMÔºå‰ª•ÂÅµÊ∏¨ÂíåÊö´ÊôÇÂÆö‰ΩçÈï∑ÂΩ±Áâá‰∏≠ÁöÑÊâãË°ìÈåØË™§„ÄÇÁì∂È†∏Ê©üÂà∂Âú®ÂÆÉÂÄëÁöÑÁ©∫ÈñìÁ∂≠Â∫¶ÂÖßÂ£ìÁ∏ÆÂíåÈÇÑÂéüÁâπÂæµÔºåÂæûËÄåÈôç‰ΩéÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇFCTF ‰ΩøÁî®Â§öÂÄãËÜ®ËÑπÁöÑ 1D Êç≤Á©çÂ±§‰æÜÂêà‰Ωµ‰∏çÂêåÁØÑÂúçÁöÑÊôÇÈñìË≥áË®äÔºåÂÆπÁ¥ç‰∏çÂêåÊåÅÁ∫åÊôÇÈñìÁöÑÈåØË™§„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÉ®ÁΩ≤‰∏ÄÂÄãÂ∑≤Âª∫Á´ãÁöÑËßÄÂØüÊÄßËá®Â∫ä‰∫∫È°ûÂèØÈù†ÊÄßË©ï‰º∞Â∑•ÂÖ∑ (OCHRA) ‰æÜË®ªËß£ÈñãÊ∫êÊ†πÊ≤ªÊÄßÂâçÂàóËÖ∫ÂàáÈô§Ë°ìË≥áÊñôÈõÜ (SAR-RARP50) ‰∏≠Á∏´Âêà‰ªªÂãôÁöÑÈåØË™§ÔºåÂª∫ÊßãÁ¨¨‰∏ÄÂÄãÂπÄÁ¥öÂà•ÁöÑÈ´îÂÖßÊâãË°ìÈåØË™§ÂÅµÊ∏¨Ë≥áÊñôÈõÜÔºå‰ª•ÊîØÊè¥Âú®ÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÂÅµÊ∏¨ÈåØË™§„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑ SEDMamba ‰ª•Ëá≥Â∞ë 1.82% AUC Âíå 3.80% AP ÊïàËÉΩÊèêÂçáÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂêåÊôÇÂ§ßÂπÖÈôç‰ΩéÈÅãÁÆóË§áÈõúÂ∫¶„ÄÇ

##### **Real-time Speech Summarization for Medical Conversations**
2406.15888v1 by Khai Le-Duc, Khai-Nguyen Nguyen, Long Vo-Dang, Truong-Son Hy

In doctor-patient conversations, identifying medically relevant information
is crucial, posing the need for conversation summarization. In this work, we
propose the first deployable real-time speech summarization system for
real-world applications in industry, which generates a local summary after
every N speech utterances within a conversation and a global summary after the
end of a conversation. Our system could enhance user experience from a business
standpoint, while also reducing computational costs from a technical
perspective. Secondly, we present VietMed-Sum which, to our knowledge, is the
first speech summarization dataset for medical conversations. Thirdly, we are
the first to utilize LLM and human annotators collaboratively to create gold
standard and synthetic summaries for medical conversation summarization.
Finally, we present baseline results of state-of-the-art models on VietMed-Sum.
All code, data (English-translated and Vietnamese) and models are available
online: https://github.com/leduckhai/MultiMed

ÊëòË¶ÅÔºöÂú®ÈÜ´ÁîüÂíåÁóÖ‰∫∫ÁöÑÂ∞çË©±‰∏≠ÔºåË≠òÂà•ËàáÈÜ´ÁôÇÁõ∏ÈóúÁöÑË≥áË®äËá≥ÈóúÈáçË¶ÅÔºåÈÄôÊèêÂá∫‰∫ÜÂ∞çË©±ÊëòË¶ÅÁöÑÈúÄÊ±Ç„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁ¨¨‰∏ÄÂÄãÂèØÈÉ®ÁΩ≤ÁöÑÂç≥ÊôÇË™ûÈü≥ÊëòË¶ÅÁ≥ªÁµ±ÔºåÁî®ÊñºÁî¢Ê•≠‰∏≠ÁöÑÁúüÂØ¶‰∏ñÁïåÊáâÁî®ÔºåÂÆÉÊúÉÂú®Â∞çË©±‰∏≠ÁöÑÊØè N ÂÄãË™ûÈü≥ÁôºË©±ÂæåÁî¢Áîü‰∏ÄÂÄãÂ±ÄÈÉ®ÊëòË¶ÅÔºå‰∏¶Âú®Â∞çË©±ÁµêÊùüÂæåÁî¢Áîü‰∏ÄÂÄãÂÖ®Â±ÄÊëòË¶Å„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÂèØ‰ª•ÂæûÂïÜÊ•≠ËßíÂ∫¶ÊèêÂçá‰ΩøÁî®ËÄÖÈ´îÈ©óÔºåÂêåÊôÇÂæûÊäÄË°ìËßíÂ∫¶Èôç‰ΩéÈÅãÁÆóÊàêÊú¨„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü VietMed-SumÔºåÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈáùÂ∞çÈÜ´ÁôÇÂ∞çË©±ÁöÑË™ûÈü≥ÊëòË¶ÅË≥áÊñôÈõÜ„ÄÇÁ¨¨‰∏âÔºåÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÂà©Áî® LLM Âíå‰∫∫Â∑•Ê®ôË®ªËÄÖÂçî‰ΩúÔºåÁÇ∫ÈÜ´ÁôÇÂ∞çË©±ÊëòË¶ÅÂª∫Á´ãÈªÉÈáëÊ®ôÊ∫ñÂíåÂêàÊàêÊëòË¶Å„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü VietMed-Sum ‰∏äÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÂü∫Ê∫ñÁµêÊûú„ÄÇÊâÄÊúâÁ®ãÂºèÁ¢º„ÄÅË≥áÊñôÔºàÂ∑≤ÁøªË≠ØÊàêËã±ÊñáÂíåË∂äÂçóË™ûÔºâÂíåÊ®°ÂûãÈÉΩÂèØ‰ª•Âú®Á∑ö‰∏äÂèñÂæóÔºöhttps://github.com/leduckhai/MultiMed

##### **Automated radiotherapy treatment planning guided by GPT-4Vision**
2406.15609v2 by Sheng Liu, Oscar Pastor-Serrano, Yizheng Chen, Matthew Gopaulchan, Weixing Liang, Mark Buyyounouski, Erqi Pollom, Quynh-Thu Le, Michael Gensheimer, Peng Dong, Yong Yang, James Zou, Lei Xing

Radiotherapy treatment planning is a time-consuming and potentially
subjective process that requires the iterative adjustment of model parameters
to balance multiple conflicting objectives. Recent advancements in large
foundation models offer promising avenues for addressing the challenges in
planning and clinical decision-making. This study introduces GPT-RadPlan, a
fully automated treatment planning framework that harnesses prior radiation
oncology knowledge encoded in multi-modal large language models, such as
GPT-4Vision (GPT-4V) from OpenAI. GPT-RadPlan is made aware of planning
protocols as context and acts as an expert human planner, capable of guiding a
treatment planning process. Via in-context learning, we incorporate clinical
protocols for various disease sites as prompts to enable GPT-4V to acquire
treatment planning domain knowledge. The resulting GPT-RadPlan agent is
integrated into our in-house inverse treatment planning system through an API.
The efficacy of the automated planning system is showcased using multiple
prostate and head & neck cancer cases, where we compared GPT-RadPlan results to
clinical plans. In all cases, GPT-RadPlan either outperformed or matched the
clinical plans, demonstrating superior target coverage and organ-at-risk
sparing. Consistently satisfying the dosimetric objectives in the clinical
protocol, GPT-RadPlan represents the first multimodal large language model
agent that mimics the behaviors of human planners in radiation oncology
clinics, achieving remarkable results in automating the treatment planning
process without the need for additional training.

ÊëòË¶ÅÔºöÊîæÂ∞ÑÊ≤ªÁôÇË®àÁï´ÁöÑÂà∂ÂÆöÊòØ‰∏ÄÂÄãËÄóÊôÇ‰∏îÂèØËÉΩ‰∏ªËßÄÁöÑÈÅéÁ®ãÔºåÈúÄË¶ÅÂèçË¶ÜË™øÊï¥Ê®°ÂûãÂèÉÊï∏Ôºå‰ª•Âπ≥Ë°°Â§öÂÄãÁõ∏‰∫íË°ùÁ™ÅÁöÑÁõÆÊ®ô„ÄÇÂ§ßÂûãÂü∫Á§éÊ®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁÇ∫‰∫ÜËß£Ê±∫Ë¶èÂäÉÂíåËá®Â∫äÊ±∫Á≠ñ‰∏≠ÁöÑÊåëÊà∞Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄîÂæë„ÄÇÊú¨Á†îÁ©∂‰ªãÁ¥π‰∫Ü GPT-RadPlanÔºåÈÄôÊòØ‰∏ÄÂÄãÂÆåÂÖ®Ëá™ÂãïÂåñÁöÑÊ≤ªÁôÇË®àÁï´Êû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºà‰æãÂ¶Ç OpenAI ÁöÑ GPT-4Vision (GPT-4V)Ôºâ‰∏≠Á∑®Á¢ºÁöÑÂÖàÂâçÁöÑÊîæÂ∞ÑËÖ´Áò§Áü•Ë≠ò„ÄÇGPT-RadPlan ÊÑèË≠òÂà∞Ë¶èÂäÉÂçîÂÆö‰ΩúÁÇ∫ËÉåÊôØÔºå‰∏¶‰ΩúÁÇ∫‰∏ÄÂêçÂ∞àÂÆ∂‰∫∫È°ûË¶èÂäÉÂ∏´ÔºåËÉΩÂ§†ÊåáÂ∞éÊ≤ªÁôÇË®àÁï´ÈÅéÁ®ã„ÄÇÈÄèÈÅéÊÉÖÂ¢ÉÂ≠∏ÁøíÔºåÊàëÂÄëÂ∞áÂêÑÁ®ÆÁñæÁóÖÈÉ®‰ΩçÁöÑËá®Â∫äÂçîÂÆöÁ¥çÂÖ•ÊèêÁ§∫Ôºå‰ª•‰Ωø GPT-4V Áç≤ÂæóÊ≤ªÁôÇË®àÁï´È†òÂüüÁü•Ë≠ò„ÄÇÁî±Ê≠§Áî¢ÁîüÁöÑ GPT-RadPlan ‰ª£ÁêÜÈÄèÈÅé API Êï¥ÂêàÂà∞ÊàëÂÄëÂÖßÈÉ®ÁöÑÈÄÜÂêëÊ≤ªÁôÇË®àÁï´Á≥ªÁµ±‰∏≠„ÄÇËá™ÂãïÂåñË®àÁï´Á≥ªÁµ±ÁöÑÂäüÊïàÈÄèÈÅéÂ§öÂÄãÂâçÂàóËÖ∫ÂíåÈ†≠È†∏ÁôåÁóÖ‰æãÂ±ïÁ§∫ÔºåÊàëÂÄëÂ∞á GPT-RadPlan ÁöÑÁµêÊûúËàáËá®Â∫äË®àÁï´ÈÄ≤Ë°åÊØîËºÉ„ÄÇÂú®ÊâÄÊúâÊÉÖÊ≥Å‰∏ãÔºåGPT-RadPlan ÈÉΩÂÑ™ÊñºÊàñÁ¨¶ÂêàËá®Â∫äË®àÁï´ÔºåÂ±ïÁèæÂá∫ÂÑ™Ë∂äÁöÑÁõÆÊ®ôË¶ÜËìãÁéáÂíåÂô®ÂÆòÂú®È¢®Èö™‰∏≠‰øùË≠∑„ÄÇGPT-RadPlan ‰∏ÄËá¥ÊªøË∂≥Ëá®Â∫äÂçîÂÆö‰∏≠ÁöÑÂäëÈáèÊ∏¨ÈáèÁõÆÊ®ôÔºå‰ª£Ë°®‰∫ÜÁ¨¨‰∏ÄÂÄãÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰ª£ÁêÜÔºåÂÆÉÊ®°Êì¨‰∫ÜÊîæÂ∞ÑËÖ´Áò§Ë®∫ÊâÄ‰∏≠‰∫∫È°ûË¶èÂäÉÂ∏´ÁöÑË°åÁÇ∫ÔºåÂú®ÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÂØ¶Áèæ‰∫ÜËá™ÂãïÂåñÊ≤ªÁôÇË®àÁï´ÈÅéÁ®ãÁöÑÈ°ØËëóÊàêÊûú„ÄÇ

##### **Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach**
2406.15346v1 by Chengzhe Piao, Taiyu Zhu, Yu Wang, Stephanie E Baldeweg, Paul Taylor, Pantelis Georgiou, Jiahao Sun, Jun Wang, Kezhi Li

Newly diagnosed Type 1 Diabetes (T1D) patients often struggle to obtain
effective Blood Glucose (BG) prediction models due to the lack of sufficient BG
data from Continuous Glucose Monitoring (CGM), presenting a significant "cold
start" problem in patient care. Utilizing population models to address this
challenge is a potential solution, but collecting patient data for training
population models in a privacy-conscious manner is challenging, especially
given that such data is often stored on personal devices. Considering the
privacy protection and addressing the "cold start" problem in diabetes care, we
propose "GluADFL", blood Glucose prediction by Asynchronous Decentralized
Federated Learning. We compared GluADFL with eight baseline methods using four
distinct T1D datasets, comprising 298 participants, which demonstrated its
superior performance in accurately predicting BG levels for cross-patient
analysis. Furthermore, patients' data might be stored and shared across various
communication networks in GluADFL, ranging from highly interconnected (e.g.,
random, performs the best among others) to more structured topologies (e.g.,
cluster and ring), suitable for various social networks. The asynchronous
training framework supports flexible participation. By adjusting the ratios of
inactive participants, we found it remains stable if less than 70% are
inactive. Our results confirm that GluADFL offers a practical,
privacy-preserving solution for BG prediction in T1D, significantly enhancing
the quality of diabetes management.

ÊëòË¶ÅÔºöÊñ∞Ë®∫Êñ∑ÁöÑ 1 ÂûãÁ≥ñÂ∞øÁóÖ (T1D) ÊÇ£ËÄÖÁî±ÊñºÁº∫‰πè‰æÜËá™ÈÄ£Á∫åË°ÄÁ≥ñÁõ£Ê∏¨ (CGM) ÁöÑË∂≥Â§†Ë°ÄÁ≥ñ (BG) Ë≥áÊñôÔºåÂõ†Ê≠§Â∏∏Â∏∏Èõ£‰ª•ÂèñÂæóÊúâÊïàÁöÑË°ÄÁ≥ñÈ†êÊ∏¨Ê®°ÂûãÔºåÈÄôÂú®ÊÇ£ËÄÖÁÖßË≠∑‰∏≠ÂëàÁèæÂá∫È°ØËëóÁöÑ„ÄåÂÜ∑ÂïüÂãï„ÄçÂïèÈ°å„ÄÇÂà©Áî®ÊóèÁæ§Ê®°Âûã‰æÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÊòØ‰∏ÄÁ®ÆÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ΩÜ‰ª•Ê≥®ÈáçÈö±ÁßÅÁöÑÊñπÂºèÊî∂ÈõÜÊÇ£ËÄÖË≥áÊñô‰æÜË®ìÁ∑¥ÊóèÁæ§Ê®°ÂûãÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÁâπÂà•ÊòØÂú®Ê≠§È°ûË≥áÊñôÈÄöÂ∏∏ÂÑ≤Â≠òÂú®ÂÄã‰∫∫Ë£ùÁΩÆ‰∏≠„ÄÇËÄÉÈáèÂà∞Èö±ÁßÅ‰øùË≠∑‰∏¶Ëß£Ê±∫Á≥ñÂ∞øÁóÖÁÖßË≠∑‰∏≠ÁöÑ„ÄåÂÜ∑ÂïüÂãï„ÄçÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫„ÄåGluADFL„ÄçÔºåÈÄèÈÅéÈùûÂêåÊ≠•ÂàÜÊï£ÂºèËÅØÂêàÂ≠∏Áøí‰æÜÈ†êÊ∏¨Ë°ÄÁ≥ñ„ÄÇÊàëÂÄë‰ΩøÁî®ÂõõÂÄã‰∏çÂêåÁöÑ T1D Ë≥áÊñôÈõÜÔºàÂåÖÂê´ 298 ‰ΩçÂèÉËàáËÄÖÔºâÂ∞á GluADFL ËàáÂÖ´Á®ÆÂü∫Ê∫ñÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉÔºåÈÄôË≠âÊòé‰∫ÜÂÖ∂Âú®Ê∫ñÁ¢∫È†êÊ∏¨Ë∑®ÊÇ£ËÄÖÂàÜÊûêÁöÑ BG ÂÄºÊñπÈù¢ÁöÑÂÑ™Áï∞ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊÇ£ËÄÖÁöÑË≥áÊñôÂèØËÉΩÂÑ≤Â≠òÂú® GluADFL ‰∏≠‰∏¶ÈÄèÈÅéÂêÑÁ®ÆÈÄöË®äÁ∂≤Ë∑ØÂàÜ‰∫´ÔºåÁØÑÂúçÂæûÈ´òÂ∫¶‰∫íÈÄ£Ôºà‰æãÂ¶ÇÔºåÈö®Ê©üÔºåÂú®ÂÖ∂‰ªñÁ∂≤Ë∑Ø‰∏≠Ë°®ÁèæÊúÄ‰Ω≥ÔºâÂà∞Êõ¥ÁµêÊßãÂåñÁöÑÊãìÊí≤Ôºà‰æãÂ¶ÇÔºåÂè¢ÈõÜÂíåÁí∞ÔºâÔºåÈÅ©Áî®ÊñºÂêÑÁ®ÆÁ§æÁæ§Á∂≤Ë∑Ø„ÄÇÈùûÂêåÊ≠•Ë®ìÁ∑¥Êû∂ÊßãÊîØÊè¥ÂΩàÊÄßÂèÉËàá„ÄÇÈÄèÈÅéË™øÊï¥ÈùûÊ¥ªË∫çÂèÉËàáËÄÖÁöÑÊØîÁéáÔºåÊàëÂÄëÁôºÁèæÂ¶ÇÊûúÈùûÊ¥ªË∫çÂèÉËàáËÄÖÂ∞ëÊñº 70%ÔºåÂÆÉ‰ªçÁÑ∂‰øùÊåÅÁ©©ÂÆö„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÂØ¶ GluADFL Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®ÁöÑ„ÄÅ‰øùË≠∑Èö±ÁßÅÁöÑ T1D BG È†êÊ∏¨Ëß£Ê±∫ÊñπÊ°àÔºåÂ§ßÂπÖÊèêÂçá‰∫ÜÁ≥ñÂ∞øÁóÖÁÆ°ÁêÜÁöÑÂìÅË≥™„ÄÇ

##### **Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms**
2406.15198v1 by Santiago Berrezueta-Guzman, Mohanad Kandil, Mar√≠a-Luisa Mart√≠n-Ruiz, Iv√°n Pau-de-la-Cruz, Stephan Krusche

Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmental
condition characterized by inattention, hyperactivity, and impulsivity, which
can significantly impact an individual's daily functioning and quality of life.
Occupational therapy plays a crucial role in managing ADHD by fostering the
development of skills needed for daily living and enhancing an individual's
ability to participate fully in school, home, and social situations. Recent
studies highlight the potential of integrating Large Language Models (LLMs)
like ChatGPT and Socially Assistive Robots (SAR) to improve psychological
treatments. This integration aims to overcome existing limitations in mental
health therapy by providing tailored support and adapting to the unique needs
of this sensitive group. However, there remains a significant gap in research
exploring the combined use of these advanced technologies in ADHD therapy,
suggesting an opportunity for novel therapeutic approaches.
  Thus, we integrated two advanced language models, ChatGPT-4 Turbo and
Claude-3 Opus, into a robotic assistant to explore how well each model performs
in robot-assisted interactions. Additionally, we have compared their
performance in a simulated therapy scenario to gauge their effectiveness
against a clinically validated customized model. The results of this study show
that ChatGPT-4 Turbo excelled in performance and responsiveness, making it
suitable for time-sensitive applications. Claude-3 Opus, on the other hand,
showed strengths in understanding, coherence, and ethical considerations,
prioritizing safe and engaging interactions. Both models demonstrated
innovation and adaptability, but ChatGPT-4 Turbo offered greater ease of
integration and broader language support. The selection between them hinges on
the specific demands of ADHD therapy.

ÊëòË¶ÅÔºöÊ≥®ÊÑèÂäõ‰∏çË∂≥ÈÅéÂãïÁóá (ADHD) ÊòØ‰∏ÄÁ®ÆÁ•ûÁ∂ìÁôºÂ±ïÁãÄÊ≥ÅÔºåÂÖ∂ÁâπÂæµÁÇ∫Ê≥®ÊÑèÂäõ‰∏çÈõÜ‰∏≠„ÄÅÈÅéÂãïÂíåË°ùÂãïÔºåÂèØËÉΩÊúÉÂ∞çÂÄã‰∫∫ÁöÑÊó•Â∏∏ÁîüÊ¥ªÂäüËÉΩÂíåÁîüÊ¥ªÂìÅË≥™ÈÄ†ÊàêÈáçÂ§ßÂΩ±Èüø„ÄÇËÅ∑ËÉΩÊ≤ªÁôÇÂú®ÁÆ°ÁêÜ ADHD ÊñπÈù¢ÁôºÊèÆËëóËá≥ÈóúÈáçË¶ÅÁöÑ‰ΩúÁî®ÔºåÈÄöÈÅéÂüπÈ§äÊó•Â∏∏ÁîüÊ¥ªÊâÄÈúÄÁöÑÊäÄËÉΩ‰∏¶Â¢ûÂº∑ÂÄã‰∫∫Âú®Â≠∏Ê†°„ÄÅÂÆ∂Â∫≠ÂíåÁ§æ‰∫§Â†¥ÂêàÂÖÖÂàÜÂèÉËàáÁöÑËÉΩÂäõ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊï¥ÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºàÂ¶Ç ChatGPTÔºâÂíåÁ§æ‰∫§ËºîÂä©Ê©üÂô®‰∫∫ (SAR) ‰ª•ÊîπÂñÑÂøÉÁêÜÊ≤ªÁôÇÁöÑÊΩõÂäõ„ÄÇÈÄôÁ®ÆÊï¥ÂêàÊó®Âú®ÈÄöÈÅéÊèê‰æõÈáèË∫´ÂÆöÂà∂ÁöÑÊîØÊåÅ‰∏¶ÈÅ©ÊáâÈÄô‰∏ÄÊïèÊÑüÁæ§È´îÁöÑÁç®ÁâπÈúÄÊ±ÇÔºå‰æÜÂÖãÊúçÂøÉÁêÜÂÅ•Â∫∑Ê≤ªÁôÇ‰∏≠ÁèæÊúâÁöÑÈôêÂà∂„ÄÇÁÑ∂ËÄåÔºåÂú®Êé¢Á¥¢ÈÄô‰∫õÂÖàÈÄ≤ÊäÄË°ìÂú® ADHD Ê≤ªÁôÇ‰∏≠ÁöÑÁ∂úÂêàÊáâÁî®ÊñπÈù¢ÔºåÁ†îÁ©∂‰ªçÂ≠òÂú®È°ØËëóÂ∑ÆË∑ùÔºåÈÄôË°®ÊòéÊúâÊ©üÊúÉÊé°Áî®Êñ∞ÁöÑÊ≤ªÁôÇÊñπÊ≥ï„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂ∞áÂÖ©ÂÄãÂÖàÈÄ≤ÁöÑË™ûË®ÄÊ®°Âûã ChatGPT-4 Turbo Âíå Claude-3 Opus Êï¥ÂêàÂà∞Ê©üÂô®‰∫∫Âä©ÊâãÔºå‰ª•Êé¢Á¥¢ÊØèÂÄãÊ®°ÂûãÂú®Ê©üÂô®‰∫∫ËºîÂä©‰∫íÂãï‰∏≠ÁöÑË°®Áèæ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÂÆÉÂÄëÂú®Ê®°Êì¨Ê≤ªÁôÇÂ†¥ÊôØ‰∏≠ÁöÑË°®ÁèæÔºå‰ª•Ë©ï‰º∞ÂÆÉÂÄëÂ∞çËá®Â∫äÈ©óË≠âÁöÑËá™Ë®ÇÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇÊú¨Á†îÁ©∂ÁöÑÁµêÊûúË°®ÊòéÔºåChatGPT-4 Turbo Âú®ÊÄßËÉΩÂíåÈüøÊáâËÉΩÂäõÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩøÂÖ∂ÈÅ©Áî®ÊñºÂ∞çÊôÇÈñìÊïèÊÑüÁöÑÊáâÁî®„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåClaude-3 Opus Âú®ÁêÜËß£„ÄÅÈÄ£Ë≤´ÊÄßÂíåÈÅìÂæ∑ËÄÉÈáèÊñπÈù¢Ë°®ÁèæÂá∫ÂÑ™Âã¢ÔºåÂÑ™ÂÖàËÄÉÊÖÆÂÆâÂÖ®ÂíåÂºï‰∫∫ÂÖ•ÂãùÁöÑ‰∫íÂãï„ÄÇÈÄôÂÖ©ÂÄãÊ®°ÂûãÈÉΩÂ±ïÁ§∫‰∫ÜÂâµÊñ∞ÂíåÈÅ©ÊáâÊÄßÔºå‰ΩÜ ChatGPT-4 Turbo Êèê‰æõ‰∫ÜÊõ¥ËºïÈ¨ÜÁöÑÊï¥ÂêàÂíåÊõ¥Âª£Ê≥õÁöÑË™ûË®ÄÊîØÊåÅ„ÄÇÂÆÉÂÄë‰πãÈñìÁöÑÈÅ∏ÊìáÂèñÊ±∫Êñº ADHD Ê≤ªÁôÇÁöÑÂÖ∑È´îÈúÄÊ±Ç„ÄÇ

##### **This actually looks like that: Proto-BagNets for local and global interpretability-by-design**
2406.15168v2 by Kerol Djoumessi, Bubacarr Bah, Laura K√ºhlewein, Philipp Berens, Lisa Koch

Interpretability is a key requirement for the use of machine learning models
in high-stakes applications, including medical diagnosis. Explaining black-box
models mostly relies on post-hoc methods that do not faithfully reflect the
model's behavior. As a remedy, prototype-based networks have been proposed, but
their interpretability is limited as they have been shown to provide coarse,
unreliable, and imprecise explanations. In this work, we introduce
Proto-BagNets, an interpretable-by-design prototype-based model that combines
the advantages of bag-of-local feature models and prototype learning to provide
meaningful, coherent, and relevant prototypical parts needed for accurate and
interpretable image classification tasks. We evaluated the Proto-BagNet for
drusen detection on publicly available retinal OCT data. The Proto-BagNet
performed comparably to the state-of-the-art interpretable and
non-interpretable models while providing faithful, accurate, and clinically
meaningful local and global explanations. The code is available at
https://github.com/kdjoumessi/Proto-BagNets.

ÊëòË¶ÅÔºöÂèØËß£ÈáãÊÄßÊòØÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂú®È´òÈ¢®Èö™ÊáâÁî®ÔºàÂåÖÊã¨ÈÜ´ÁôÇË®∫Êñ∑Ôºâ‰∏≠‰ΩøÁî®ÁöÑÈóúÈçµË¶ÅÊ±Ç„ÄÇËß£ÈáãÈªëÁõíÊ®°Âûã‰∏ªË¶Å‰æùË≥¥Êñº‰∫ãÂæåÊñπÊ≥ïÔºåËÄåÈÄô‰∫õÊñπÊ≥ïÁÑ°Ê≥ïÂø†ÂØ¶Âú∞ÂèçÊò†Ê®°ÂûãÁöÑË°åÁÇ∫„ÄÇ‰ΩúÁÇ∫Ë£úÊïëÊé™ÊñΩÔºåÂ∑≤Á∂ìÊèêÂá∫‰∫ÜÂü∫ÊñºÂéüÂûãÁöÑÁ∂≤Ë∑ØÔºå‰ΩÜÁî±ÊñºÂÆÉÂÄëÂ∑≤Ë¢´Ë≠âÊòéÊúÉÊèê‰æõÁ≤óÁï•„ÄÅ‰∏çÂèØÈù†‰∏î‰∏çÁ≤æÁ¢∫ÁöÑËß£ÈáãÔºåÂõ†Ê≠§ÂÆÉÂÄëÁöÑÂèØËß£ÈáãÊÄßÂèóÂà∞ÈôêÂà∂„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Proto-BagNetsÔºåÈÄôÊòØ‰∏ÄÂÄãÂèØËß£ÈáãÁöÑÂü∫ÊñºË®≠Ë®àÁöÑÂéüÂûãÊ®°ÂûãÔºåÂÆÉÁµêÂêà‰∫ÜÂ±ÄÈÉ®ÁâπÂæµÊ®°ÂûãÂíåÂéüÂûãÂ≠∏ÁøíÁöÑÂÑ™ÈªûÔºå‰ª•Êèê‰æõÊ∫ñÁ¢∫‰∏îÂèØËß£ÈáãÁöÑÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÊâÄÈúÄÁöÑ„ÄÅÊúâÊÑèÁæ©„ÄÅÈÄ£Ë≤´‰∏îÁõ∏ÈóúÁöÑÂéüÂûãÈÉ®ÂàÜ„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü Proto-BagNet Âú®ÂÖ¨ÈñãÂèØÁî®ÁöÑË¶ñÁ∂≤ËÜú OCT Ë≥áÊñô‰∏äÁöÑÈªÉÊñëÈªûÊ™¢Ê∏¨„ÄÇProto-BagNet ÁöÑË°®ÁèæËàáÊúÄÂÖàÈÄ≤ÁöÑÂèØËß£ÈáãÂíå‰∏çÂèØËß£ÈáãÊ®°ÂûãÁõ∏Áï∂ÔºåÂêåÊôÇÊèê‰æõ‰∫ÜÂø†ÂØ¶„ÄÅÊ∫ñÁ¢∫‰∏îÂú®Ëá®Â∫ä‰∏äÊúâÊÑèÁæ©ÁöÑÂ±ÄÈÉ®ÂíåÊï¥È´îËß£Èáã„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/kdjoumessi/Proto-BagNets ÂèñÂæó„ÄÇ

##### **FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays**
2406.15117v1 by Ayush Roy, Anurag Bhattacharjee, Diego Oliva, Oscar Ramos-Soto, Francisco J. Alvarez-Padilla, Ram Sarkar

Pneumonia is a respiratory infection caused by bacteria, fungi, or viruses.
It affects many people, particularly those in developing or underdeveloped
nations with high pollution levels, unhygienic living conditions, overcrowding,
and insufficient medical infrastructure. Pneumonia can cause pleural effusion,
where fluids fill the lungs, leading to respiratory difficulty. Early diagnosis
is crucial to ensure effective treatment and increase survival rates. Chest
X-ray imaging is the most commonly used method for diagnosing pneumonia.
However, visual examination of chest X-rays can be difficult and subjective. In
this study, we have developed a computer-aided diagnosis system for automatic
pneumonia detection using chest X-ray images. We have used DenseNet-121 and
ResNet50 as the backbone for the binary class (pneumonia and normal) and
multi-class (bacterial pneumonia, viral pneumonia, and normal) classification
tasks, respectively. We have also implemented a channel-specific spatial
attention mechanism, called Fuzzy Channel Selective Spatial Attention Module
(FCSSAM), to highlight the specific spatial regions of relevant channels while
removing the irrelevant channels of the extracted features by the backbone. We
evaluated the proposed approach on a publicly available chest X-ray dataset,
using binary and multi-class classification setups. Our proposed method
achieves accuracy rates of 97.15\% and 79.79\% for the binary and multi-class
classification setups, respectively. The results of our proposed method are
superior to state-of-the-art (SOTA) methods. The code of the proposed model
will be available at: https://github.com/AyushRoy2001/FA-Net.

ÊëòË¶ÅÔºöËÇ∫ÁÇéÊòØ‰∏ÄÁ®ÆÁî±Á¥∞Ëèå„ÄÅÁúüËèåÊàñÁóÖÊØíÂºïËµ∑ÁöÑÂëºÂê∏ÈÅìÊÑüÊüì„ÄÇ
ÂÆÉÂΩ±ÈüøË®±Â§ö‰∫∫ÔºåÁâπÂà•ÊòØÁôºÂ±ï‰∏≠ÂúãÂÆ∂ÊàñÊú™ÈñãÁôºÂúãÂÆ∂ÔºåÈÄô‰∫õÂúãÂÆ∂Ê±°ÊüìÁ®ãÂ∫¶È´ò„ÄÅÁîüÊ¥ªÊ¢ù‰ª∂‰∏çË°õÁîü„ÄÅ‰∫∫Âè£ÈÅéÊñºÁ®†ÂØÜÔºå‰∏îÈÜ´ÁôÇÂü∫Á§éË®≠ÊñΩ‰∏çË∂≥„ÄÇËÇ∫ÁÇéÊúÉÂ∞éËá¥ËÉ∏ËÖîÁ©çÊ∂≤ÔºåÊ∂≤È´îÊúÉÂÖÖÊªøËÇ∫ÈÉ®ÔºåÂ∞éËá¥ÂëºÂê∏Âõ∞Èõ£„ÄÇÊó©ÊúüË®∫Êñ∑Â∞çÊñºÁ¢∫‰øùÊúâÊïàÊ≤ªÁôÇÂíåÊèêÈ´òÂ≠òÊ¥ªÁéáËá≥ÈóúÈáçË¶Å„ÄÇËÉ∏ÈÉ® X ÂÖâÂΩ±ÂÉèÊ™¢Êü•ÊòØË®∫Êñ∑ËÇ∫ÁÇéÊúÄÂ∏∏Áî®ÁöÑÊñπÊ≥ï„ÄÇ
ÁÑ∂ËÄåÔºåËÉ∏ÈÉ® X ÂÖâÁöÑË¶ñË¶∫Ê™¢Êü•ÂèØËÉΩÂõ∞Èõ£‰∏î‰∏ªËßÄ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÈõªËÖ¶ËºîÂä©Ë®∫Êñ∑Á≥ªÁµ±ÔºåÁî®Êñº‰ΩøÁî®ËÉ∏ÈÉ® X ÂÖâÂΩ±ÂÉèËá™ÂãïÂÅµÊ∏¨ËÇ∫ÁÇé„ÄÇÊàëÂÄë‰ΩøÁî® DenseNet-121 Âíå ResNet50 ‰ΩúÁÇ∫‰∫åÂÖÉÈ°ûÂà•ÔºàËÇ∫ÁÇéÂíåÊ≠£Â∏∏ÔºâÂíåÂ§öÈ°ûÂà•ÔºàÁ¥∞ËèåÊÄßËÇ∫ÁÇé„ÄÅÁóÖÊØíÊÄßËÇ∫ÁÇéÂíåÊ≠£Â∏∏ÔºâÂàÜÈ°û‰ªªÂãôÁöÑ‰∏ªÂππ„ÄÇÊàëÂÄëÈÇÑÂØ¶‰Ωú‰∫Ü‰∏ÄÂÄãÈÄöÈÅìÁâπÂÆöÁöÑÁ©∫ÈñìÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÁ®±ÁÇ∫Ê®°Á≥äÈÄöÈÅìÈÅ∏ÊìáÊÄßÁ©∫ÈñìÊ≥®ÊÑèÂäõÊ®°ÁµÑ (FCSSAM)Ôºå‰ª•Á™ÅÈ°ØÁõ∏ÈóúÈÄöÈÅìÁöÑÁâπÂÆöÁ©∫ÈñìÂçÄÂüüÔºåÂêåÊôÇÁßªÈô§‰∏ªÂππÊèêÂèñÁâπÂæµÁöÑÁÑ°ÈóúÈÄöÈÅì„ÄÇÊàëÂÄëÂú®ÂÖ¨ÈñãÁöÑËÉ∏ÈÉ® X ÂÖâË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®‰∫åÂÖÉÂíåÂ§öÈ°ûÂà•ÂàÜÈ°ûË®≠ÂÆö„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®‰∫åÂÖÉÂíåÂ§öÈ°ûÂà•ÂàÜÈ°ûË®≠ÂÆö‰∏≠ÂàÜÂà•ÈÅîÂà∞ 97.15% Âíå 79.79% ÁöÑÊ∫ñÁ¢∫Áéá„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÁµêÊûúÂÑ™ÊñºÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊñπÊ≥ï„ÄÇÊâÄÊèêÂá∫Ê®°ÂûãÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂèñÂæóÔºöhttps://github.com/AyushRoy2001/FA-Net„ÄÇ

##### **Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis**
2406.15050v1 by Lin Fan, Xun Gong, Cenyang Zheng, Yafei Ou

The intersection of medical Visual Question Answering (Med-VQA) is a
challenging research topic with advantages including patient engagement and
clinical expert involvement for second opinions. However, existing Med-VQA
methods based on joint embedding fail to explain whether their provided results
are based on correct reasoning or coincidental answers, which undermines the
credibility of VQA answers. In this paper, we investigate the construction of a
more cohesive and stable Med-VQA structure. Motivated by causal effect, we
propose a novel Triangular Reasoning VQA (Tri-VQA) framework, which constructs
reverse causal questions from the perspective of "Why this answer?" to
elucidate the source of the answer and stimulate more reasonable forward
reasoning processes. We evaluate our method on the Endoscopic Ultrasound (EUS)
multi-attribute annotated dataset from five centers, and test it on medical VQA
datasets. Experimental results demonstrate the superiority of our approach over
existing methods. Our codes and pre-trained models are available at
https://anonymous.4open.science/r/Tri_VQA.

ÊëòË¶ÅÔºöÈÜ´Â≠∏Ë¶ñË¶∫ÂïèÁ≠î (Med-VQA) ÁöÑ‰∫§ÂèâÈ†òÂüüÊòØ‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ†îÁ©∂‰∏ªÈ°åÔºåÂÖ∂ÂÑ™ÈªûÂåÖÊã¨ÊÇ£ËÄÖÂèÉËàáÂíåËá®Â∫äÂ∞àÂÆ∂ÁöÑÂèÉËàá‰ª•Êèê‰æõÁ¨¨‰∫åÊÑèË¶ã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫ÊñºËÅØÂêàÂµåÂÖ•ÁöÑ Med-VQA ÊñπÊ≥ïÁÑ°Ê≥ïËß£ÈáãÂÖ∂Êèê‰æõÁöÑÁµêÊûúÊòØÂü∫ÊñºÊ≠£Á¢∫ÁöÑÊé®ÁêÜÈÇÑÊòØÂ∑ßÂêàÁöÑÁ≠îÊ°àÔºåÈÄôÊúÉÊêçÂÆ≥ VQA Á≠îÊ°àÁöÑÂèØ‰ø°Â∫¶„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊßãÂª∫Êõ¥Á∑äÂØÜ‰∏îÁ©©ÂÆöÁöÑ Med-VQA ÁµêÊßã„ÄÇÂèóÂà∞Âõ†ÊûúÈóú‰øÇÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ‰∏âËßíÊé®ÁêÜ VQA (Tri-VQA) Ê°ÜÊû∂ÔºåË©≤Ê°ÜÊû∂Âæû„ÄåÁÇ∫‰ªÄÈ∫ºÈÄôÂÄãÁ≠îÊ°àÔºü„ÄçÁöÑËßíÂ∫¶ÊßãÂª∫ÂèçÂêëÂõ†ÊûúÂïèÈ°åÔºå‰ª•Èó°ÊòéÁ≠îÊ°àÁöÑ‰æÜÊ∫ê‰∏¶ÊøÄÁôºÊõ¥ÂêàÁêÜÁöÑÊ≠£ÂêëÊé®ÁêÜÈÅéÁ®ã„ÄÇÊàëÂÄëÂú®‰æÜËá™‰∫îÂÄã‰∏≠ÂøÉÁöÑÂÖßË¶ñÈè°Ë∂ÖÈü≥Ê≥¢ (EUS) Â§öÂ±¨ÊÄßË®ªÈáãË≥áÊñôÈõÜ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãÔºå‰∏¶Âú®ÈÜ´Â≠∏ VQA Ë≥áÊñôÈõÜ‰∏äÂ∞çÂÖ∂ÈÄ≤Ë°åÊ∏¨Ë©¶„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÈ†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÂèØÂú® https://anonymous.4open.science/r/Tri_VQA ÂèñÂæó„ÄÇ

##### **Human-AI collectives produce the most accurate differential diagnoses**
2406.14981v1 by N. Z√∂ller, J. Berger, I. Lin, N. Fu, J. Komarneni, G. Barabucci, K. Laskowski, V. Shia, B. Harack, E. A. Chu, V. Trianni, R. H. J. M. Kurvers, S. M. Herzog

Artificial intelligence systems, particularly large language models (LLMs),
are increasingly being employed in high-stakes decisions that impact both
individuals and society at large, often without adequate safeguards to ensure
safety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are
biased - shortcomings that may reflect LLMs' inherent limitations and thus may
not be remedied by more sophisticated architectures, more data, or more human
feedback. Relying solely on LLMs for complex, high-stakes decisions is
therefore problematic. Here we present a hybrid collective intelligence system
that mitigates these risks by leveraging the complementary strengths of human
experience and the vast information processed by LLMs. We apply our method to
open-ended medical diagnostics, combining 40,762 differential diagnoses made by
physicians with the diagnoses of five state-of-the art LLMs across 2,133
medical cases. We show that hybrid collectives of physicians and LLMs
outperform both single physicians and physician collectives, as well as single
LLMs and LLM ensembles. This result holds across a range of medical specialties
and professional experience, and can be attributed to humans' and LLMs'
complementary contributions that lead to different kinds of errors. Our
approach highlights the potential for collective human and machine intelligence
to improve accuracy in complex, open-ended domains like medical diagnostics.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)Ôºå
Ë∂ä‰æÜË∂äÂ∏∏Ë¢´Áî®ÊñºÂΩ±ÈüøÂÄã‰∫∫ÂíåÊï¥ÂÄãÁ§æÊúÉÁöÑÈ´òÈ¢®Èö™Ê±∫Á≠ñÔºå‰ΩÜÈÄöÂ∏∏Ê≤íÊúâË∂≥Â§†ÁöÑÈò≤Ë≠∑Êé™ÊñΩ‰æÜÁ¢∫‰øù
ÂÆâÂÖ®„ÄÅÂìÅË≥™ÂíåÂÖ¨Âπ≥ÊÄß„ÄÇÁÑ∂ËÄåÔºåLLM ÊúÉÁî¢ÁîüÂπªË¶∫„ÄÅÁº∫‰πèÂ∏∏Ë≠òÔºå‰∏¶‰∏îÊúâÂÅèË¶ã - ÈÄô‰∫õÁº∫ÈªûÂèØËÉΩÂèçÊò†Âá∫ LLM Âõ∫ÊúâÁöÑÈôêÂà∂ÔºåÂõ†Ê≠§ÂèØËÉΩÁÑ°Ê≥ïÈÄèÈÅéÊõ¥Á≤æÂØÜÁöÑÊû∂Êßã„ÄÅÊõ¥Â§öË≥áÊñôÊàñÊõ¥Â§ö‰∫∫È°ûÂõûÈ•ã‰æÜË£úÊïë„ÄÇÂõ†Ê≠§ÔºåÂÉÖ‰æùË≥¥ LLM ‰æÜÂÅöÂá∫Ë§áÈõú„ÄÅÈ´òÈ¢®Èö™ÁöÑÊ±∫Á≠ñÊòØÊúâÂïèÈ°åÁöÑ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ∑∑ÂêàÈõÜÈ´îÊô∫ÊÖßÁ≥ªÁµ±ÔºåÈÄèÈÅéÂà©Áî®‰∫∫È°ûÁ∂ìÈ©óÂíå LLM ËôïÁêÜÁöÑÈæêÂ§ßË≥áË®äÁöÑ‰∫íË£úÂÑ™Âã¢‰æÜÈôç‰ΩéÈÄô‰∫õÈ¢®Èö™„ÄÇÊàëÂÄëÂ∞áÊñπÊ≥ïÊáâÁî®ÊñºÈñãÊîæÂºèÈÜ´ÁôÇË®∫Êñ∑ÔºåÁµêÂêàÈÜ´Â∏´ÂÅöÂá∫ÁöÑ 40,762 ÂÄãÈëëÂà•Ë®∫Êñ∑Ôºå‰ª•Âèä‰∫îÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú® 2,133 ÂÄãÈÜ´ÁôÇÊ°à‰æã‰∏≠ÁöÑË®∫Êñ∑„ÄÇÊàëÂÄëË≠âÊòéÔºåÈÜ´Â∏´Âíå LLM ÁöÑÊ∑∑ÂêàÈõÜÈ´îÂÑ™ÊñºÂñÆ‰∏ÄÈÜ´Â∏´ÂíåÈÜ´Â∏´ÈõÜÈ´îÔºå‰ª•ÂèäÂñÆ‰∏Ä LLM Âíå LLM Êï¥Âêà„ÄÇÈÄôÂÄãÁµêÊûúÈÅ©Áî®ÊñºÂêÑÁ®ÆÈÜ´ÁôÇÂ∞àÁßëÂíåÂ∞àÊ•≠Á∂ìÈ©óÔºå‰∏¶‰∏îÂèØ‰ª•Ê≠∏Âõ†Êñº‰∫∫È°ûÂíå LLM ÁöÑ‰∫íË£úË≤¢ÁçªÔºåÂ∞éËá¥‰∏çÂêåÈ°ûÂûãÁöÑÈåØË™§„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁ™ÅÈ°Ø‰∫ÜÈõÜÈ´î‰∫∫È°ûÂíåÊ©üÂô®Êô∫ÊÖßÂú®ÊîπÂñÑÈÜ´ÁôÇË®∫Êñ∑Á≠âË§áÈõú„ÄÅÈñãÊîæÂºèÈ†òÂüü‰∏≠ÁöÑÊ∫ñÁ¢∫ÊÄßÁöÑÊΩõÂäõ„ÄÇ

##### **Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health**
2406.14953v2 by Guangkun Nie, Qinghao Zhao, Gongzheng Tang, Jun Li, Shenda Hong

Photoplethysmography (PPG) is emerging as a crucial tool for monitoring human
hemodynamics, with recent studies highlighting its potential in assessing
vascular aging through deep learning. However, real-world age distributions are
often imbalanced, posing significant challenges for deep learning models. In
this paper, we introduce a novel, simple, and effective loss function named the
Dist Loss to address deep imbalanced regression tasks. We trained a
one-dimensional convolutional neural network (Net1D) incorporating the Dist
Loss on the extensive UK Biobank dataset (n=502,389) to estimate vascular age
from PPG signals and validate its efficacy in characterizing cardiovascular
health. The model's performance was validated on a 40% held-out test set,
achieving state-of-the-art results, especially in regions with small sample
sizes. Furthermore, we divided the population into three subgroups based on the
difference between predicted vascular age and chronological age: less than -10
years, between -10 and 10 years, and greater than 10 years. We analyzed the
relationship between predicted vascular age and several cardiovascular events
over a follow-up period of up to 10 years, including death, coronary heart
disease, and heart failure. Our results indicate that the predicted vascular
age has significant potential to reflect an individual's cardiovascular health
status. Our code will be available at https://github.com/Ngk03/AI-vascular-age.

ÊëòË¶ÅÔºöÂÖâÈõªÂÆπÁ©çÊèèË®òÊ≥ï (PPG) Ê≠£ÊàêÁÇ∫Áõ£Êéß‰∫∫È°ûË°ÄÊµÅÂãïÂäõÂ≠∏ÁöÑÈóúÈçµÂ∑•ÂÖ∑ÔºåÊúÄËøëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÂÖ∂ÈÄöÈÅéÊ∑±Â∫¶Â≠∏ÁøíË©ï‰º∞Ë°ÄÁÆ°ËÄÅÂåñÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁèæÂØ¶‰∏ñÁïåÁöÑÂπ¥ÈΩ°ÂàÜ‰ΩàÈÄöÂ∏∏‰∏çÂπ≥Ë°°ÔºåÂ∞çÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©é„ÄÅÁ∞°ÂñÆ‰∏îÊúâÊïàÁöÑÊêçÂ§±ÂáΩÊï∏ÔºåÁ®±ÁÇ∫ Dist LossÔºå‰ª•Ëß£Ê±∫Ê∑±Â∫¶‰∏çÂπ≥Ë°°Ëø¥Ê≠∏‰ªªÂãô„ÄÇÊàëÂÄëÂú®Âª£Ê≥õÁöÑËã±ÂúãÁîüÁâ©ÈäÄË°åÊï∏ÊìöÈõÜ (n=502,389) ‰∏äË®ìÁ∑¥‰∫Ü‰∏ÄÂÄã‰∏ÄÁ∂≠Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (Net1D)ÔºåÁµêÂêà Dist Loss Âæû PPG ‰ø°Ëôü‰º∞Ë®àË°ÄÁÆ°Âπ¥ÈΩ°Ôºå‰∏¶È©óË≠âÂÖ∂Âú®Ë°®ÂæµÂøÉË°ÄÁÆ°ÂÅ•Â∫∑ÊñπÈù¢ÁöÑÂäüÊïà„ÄÇË©≤Ê®°ÂûãÁöÑÊÄßËÉΩÂú® 40% ÁöÑÁïôÂá∫Ê∏¨Ë©¶ÈõÜ‰∏äÂæóÂà∞È©óË≠âÔºåÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåÁâπÂà•ÊòØÂú®Ê®£Êú¨ÈáèÂ∞èÁöÑÂçÄÂüü„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊ†πÊìöÈ†êÊ∏¨Ë°ÄÁÆ°Âπ¥ÈΩ°ÂíåÂØ¶ÈöõÂπ¥ÈΩ°‰πãÈñìÁöÑÂ∑ÆÁï∞Â∞á‰∫∫Áæ§ÂàÜÁÇ∫‰∏âÁµÑÔºöÂ∞èÊñº -10 Ê≠≤„ÄÅÂú® -10 Ê≠≤Âà∞ 10 Ê≠≤‰πãÈñì‰ª•ÂèäÂ§ßÊñº 10 Ê≠≤„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÈ†êÊ∏¨Ë°ÄÁÆ°Âπ¥ÈΩ°ËàáÂπæÁ®ÆÂøÉË°ÄÁÆ°‰∫ã‰ª∂‰πãÈñìÁöÑÈóú‰øÇÔºåÂåÖÊã¨Ê≠ª‰∫°„ÄÅÂÜ†ÂøÉÁóÖÂíåÂøÉÂäõË°∞Á´≠ÔºåÈö®Ë®™ÊúüÈï∑ÈÅî 10 Âπ¥„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÈ†êÊ∏¨ÁöÑË°ÄÁÆ°Âπ¥ÈΩ°ÂÖ∑ÊúâÂèçÊò†ÂÄã‰∫∫ÂøÉË°ÄÁÆ°ÂÅ•Â∫∑ÁãÄÊ≥ÅÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÂ∞áÂú® https://github.com/Ngk03/AI-vascular-age ‰∏äÊèê‰æõ„ÄÇ

##### **Extraction of 3D trajectories of mandibular condyles from 2D real-time MRI**
2406.14925v1 by Karyna Isaieva, Justine Lecl√®re, Guillaume Paillart, Guillaume Drouot, Jacques Felblinger, Xavier Dubernard, Pierre-Andr√© Vuissoz

Computing the trajectories of mandibular condyles directly from MRI could
provide a comprehensive examination, allowing for the extraction of both
anatomical and kinematic details. This study aimed to investigate the
feasibility of extracting 3D condylar trajectories from 2D real-time MRI and to
assess their precision.Twenty healthy subjects underwent real-time MRI while
opening and closing their jaws. One axial and two sagittal slices were
segmented using a U-Net-based algorithm. The centers of mass of the resulting
masks were projected onto the coordinate system based on anatomical markers and
temporally adjusted using a common projection. The quality of the computed
trajectories was evaluated using metrics designed to estimate movement
reproducibility, head motion, and slice placement symmetry.The segmentation of
the axial slices demonstrated good-to-excellent quality; however, the
segmentation of the sagittal slices required some fine-tuning. The movement
reproducibility was acceptable for most cases; nevertheless, head motion
displaced the trajectories by 1 mm on average. The difference in the
superior-inferior coordinate of the condyles in the closed jaw position was 1.7
mm on average.Despite limitations in precision, real-time MRI enables the
extraction of condylar trajectories with sufficient accuracy for evaluating
clinically relevant parameters such as condyle displacement, trajectories
aspect, and symmetry.

ÊëòË¶ÅÔºöÈÄèÈÅé MRI Áõ¥Êé•Ë®àÁÆó‰∏ãÈ°éÈ´ÅÁöÑËªåË∑°ÂèØ‰ª•Êèê‰æõÂÖ®Èù¢ÁöÑÊ™¢Êü•Ôºå‰∏¶ÂÖÅË®±ÊèêÂèñËß£ÂâñÂíåÈÅãÂãïÁ¥∞ÁØÄ„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®éÂæû 2D Âç≥ÊôÇ MRI ‰∏≠ÊèêÂèñ 3D È´ÅÁãÄËªåË∑°ÁöÑÂèØË°åÊÄßÔºå‰∏¶Ë©ï‰º∞ÂÖ∂Ê∫ñÁ¢∫Â∫¶„ÄÇ‰∫åÂçÅ‰ΩçÂÅ•Â∫∑ÂèóË©¶ËÄÖÂú®ÂºµÈñâ‰∏ãÈ°éÊôÇÊé•ÂèóÂç≥ÊôÇ MRI„ÄÇ‰ΩøÁî®Âü∫Êñº U-Net ÁöÑÊºîÁÆóÊ≥ïÂàÜÂâ≤‰∏ÄÂÄãËª∏ÂêëÂàáÁâáÂíåÂÖ©ÂÄãÁü¢ÁãÄÂàáÁâá„ÄÇÂ∞áÊâÄÂæóÈÅÆÁΩ©ÁöÑË≥™ÂøÉÊäïÂΩ±Âà∞Âü∫ÊñºËß£ÂâñÊ®ôË®òÁöÑÂ∫ßÊ®ôÁ≥ªÁµ±‰∏äÔºå‰∏¶‰ΩøÁî®ÂÖ±ÂêåÊäïÂΩ±ÈÄ≤Ë°åÊôÇÈñìË™øÊï¥„ÄÇË®àÁÆóËªåË∑°ÁöÑÂìÅË≥™‰ΩøÁî®ÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞ÔºåÈÄô‰∫õÊåáÊ®ôÊó®Âú®‰º∞Ë®àÈÅãÂãïÈáçÁèæÊÄß„ÄÅÈ†≠ÈÉ®ÈÅãÂãïÂíåÂàáÁâáÊîæÁΩÆÂ∞çÁ®±ÊÄß„ÄÇËª∏ÂêëÂàáÁâáÁöÑÂàÜÂâ≤È°ØÁ§∫Âá∫ËâØÂ•ΩÂà∞Ê•µ‰Ω≥ÁöÑÂìÅË≥™ÔºõÁÑ∂ËÄåÔºåÁü¢ÁãÄÂàáÁâáÁöÑÂàÜÂâ≤ÈúÄË¶Å‰∏Ä‰∫õÂæÆË™ø„ÄÇÂú®Â§öÊï∏ÊÉÖÊ≥Å‰∏ãÔºåÈÅãÂãïÈáçÁèæÊÄßÊòØÂèØ‰ª•Êé•ÂèóÁöÑÔºõÁÑ∂ËÄåÔºåÈ†≠ÈÉ®ÈÅãÂãïÂπ≥ÂùáÂ∞áËªåË∑°Áßª‰Ωç 1 mm„ÄÇÈñâÂêà‰∏ãÈ°é‰ΩçÁΩÆ‰∏≠È´ÅÁãÄÁ™ÅÁöÑ‰∏ä‰∏ãÂ∫ßÊ®ôÂ∑ÆÁï∞Âπ≥ÂùáÁÇ∫ 1.7 mm„ÄÇÂÑòÁÆ°Ê∫ñÁ¢∫Â∫¶ÊúâÂÖ∂ÈôêÂà∂ÔºåÂç≥ÊôÇ MRI ËÉΩÂ§†ÊèêÂèñÈ´ÅÁãÄËªåË∑°ÔºåÂÖ∂Ê∫ñÁ¢∫Â∫¶Ë∂≥‰ª•Ë©ï‰º∞‰∏ãÈ°éÈ´Å‰ΩçÁßª„ÄÅËªåË∑°Â§ñËßÄÂíåÂ∞çÁ®±ÊÄßÁ≠âËá®Â∫äÁõ∏ÈóúÂèÉÊï∏„ÄÇ

##### **AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics**
2406.14866v1 by Jonas Dippel, Niklas Preni√ül, Julius Hense, Philipp Liznerski, Tobias Winterhoff, Simon Schallenberg, Marius Kloft, Oliver Buchstab, David Horst, Maximilian Alber, Lukas Ruff, Klaus-Robert M√ºller, Frederick Klauschen

While previous studies have demonstrated the potential of AI to diagnose
diseases in imaging data, clinical implementation is still lagging behind. This
is partly because AI models require training with large numbers of examples
only available for common diseases. In clinical reality, however, only few
diseases are common, whereas the majority of diseases are less frequent
(long-tail distribution). Current AI models overlook or misclassify these
diseases. We propose a deep anomaly detection approach that only requires
training data from common diseases to detect also all less frequent diseases.
We collected two large real-world datasets of gastrointestinal biopsies, which
are prototypical of the problem. Herein, the ten most common findings account
for approximately 90% of cases, whereas the remaining 10% contained 56 disease
entities, including many cancers. 17 million histological images from 5,423
cases were used for training and evaluation. Without any specific training for
the diseases, our best-performing model reliably detected a broad spectrum of
infrequent ("anomalous") pathologies with 95.0% (stomach) and 91.0% (colon)
AUROC and generalized across scanners and hospitals. By design, the proposed
anomaly detection can be expected to detect any pathological alteration in the
diagnostic tail of gastrointestinal biopsies, including rare primary or
metastatic cancers. This study establishes the first effective clinical
application of AI-based anomaly detection in histopathology that can flag
anomalous cases, facilitate case prioritization, reduce missed diagnoses and
enhance the general safety of AI models, thereby driving AI adoption and
automation in routine diagnostics and beyond.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Á∂ìË≠âÊòé AI Âú®ÂΩ±ÂÉèË≥áÊñô‰∏≠Ë®∫Êñ∑ÁñæÁóÖÁöÑÊΩõÂäõÔºå‰ΩÜËá®Â∫äÂØ¶Âãô‰ªçËêΩÂæåË®±Â§ö„ÄÇÈÄôÊòØÈÉ®ÂàÜÂéüÂõ†Âú®Êñº AI Ê®°ÂûãÈúÄË¶ÅÂ§ßÈáèÁØÑ‰æãÈÄ≤Ë°åË®ìÁ∑¥ÔºåËÄåÈÄô‰∫õÁØÑ‰æãÂÉÖÈÅ©Áî®ÊñºÂ∏∏Ë¶ãÁñæÁóÖ„ÄÇÁÑ∂ËÄåÔºåÂú®Ëá®Â∫äÁèæÂØ¶‰∏≠ÔºåÂè™ÊúâÂ∞ëÊï∏ÁñæÁóÖÊòØÂ∏∏Ë¶ãÁöÑÔºåËÄåÂ§ßÂ§öÊï∏ÁñæÁóÖËºÉ‰∏çÂ∏∏Ë¶ãÔºàÈï∑Â∞æÂàÜ‰ΩàÔºâ„ÄÇÁõÆÂâçÁöÑ AI Ê®°ÂûãÊúÉÂøΩÁï•ÊàñÈåØË™§ÂàÜÈ°ûÈÄô‰∫õÁñæÁóÖ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ∑±Â∫¶Áï∞Â∏∏ÂÅµÊ∏¨ÊñπÊ≥ïÔºåÂÆÉÂè™ÈúÄË¶Å‰æÜËá™Â∏∏Ë¶ãÁñæÁóÖÁöÑË®ìÁ∑¥Ë≥áÊñôÔºåÂ∞±ËÉΩÂÅµÊ∏¨ÊâÄÊúâËºÉ‰∏çÂ∏∏Ë¶ãÁöÑÁñæÁóÖ„ÄÇÊàëÂÄëÊî∂ÈõÜ‰∫ÜÂÖ©ÂÄãÂ§ßÂûãÁöÑËÉÉËÖ∏ÈÅìÂàáÁâáÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÔºåÂÆÉÂÄëÊòØÊ≠§ÂïèÈ°åÁöÑÂÖ∏ÂûãÁØÑ‰æã„ÄÇÂú®Ê≠§ÔºåÊúÄÂ∏∏Ë¶ãÁöÑÂçÅÁ®ÆÁôºÁèæÁ¥Ñ‰ΩîÁóÖ‰æãÁöÑ 90%ÔºåËÄåÂÖ∂È§ò 10% ÂâáÂåÖÂê´ 56 Á®ÆÁñæÁóÖÂØ¶È´îÔºåÂåÖÊã¨Ë®±Â§öÁôåÁóá„ÄÇ1700 Ëê¨Âºµ‰æÜËá™ 5,423 ÂÄãÁóÖ‰æãÁöÑÁµÑÁπîÂ≠∏ÂΩ±ÂÉèÁî®ÊñºË®ìÁ∑¥ÂíåË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÊúÄ‰Ω≥ÊïàËÉΩÊ®°ÂûãÂú®Ê≤íÊúâÈáùÂ∞çÈÄô‰∫õÁñæÁóÖÈÄ≤Ë°å‰ªª‰ΩïÁâπÂÆöË®ìÁ∑¥ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂèØÈù†Âú∞ÂÅµÊ∏¨Âà∞Âª£Ê≥õÁöÑÁΩïË¶ãÔºà„ÄåÁï∞Â∏∏„ÄçÔºâÁóÖÁêÜÔºåÂÖ∂ AUROC ÂàÜÂà•ÁÇ∫ 95.0%ÔºàËÉÉÔºâÂíå 91.0%ÔºàÁµêËÖ∏ÔºâÔºå‰∏¶Âª£Ê≥õÊáâÁî®ÊñºÊéÉÊèèÂÑÄÂíåÈÜ´Èô¢„ÄÇ‰æùÊìöË®≠Ë®àÔºåÊâÄÊèêÂá∫ÁöÑÁï∞Â∏∏ÂÅµÊ∏¨È†êË®àÂèØ‰ª•ÂÅµÊ∏¨ËÉÉËÖ∏ÈÅìÂàáÁâáË®∫Êñ∑Â∞æÁ´ØÁöÑ‰ªª‰ΩïÁóÖÁêÜÊÄßÊîπËÆäÔºåÂåÖÊã¨ÁΩïË¶ãÁöÑÂéüÁôºÊÄßÊàñËΩâÁßªÊÄßÁôåÁóá„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âª∫Á´ã‰∫ÜÁ¨¨‰∏ÄÂÄãÊúâÊïàÁöÑ AI Áï∞Â∏∏ÂÅµÊ∏¨Ëá®Â∫äÊáâÁî®ÔºåÂÆÉÂèØ‰ª•Âú®ÁµÑÁπîÁóÖÁêÜÂ≠∏‰∏≠Ê®ôË®òÁï∞Â∏∏ÁóÖ‰æã„ÄÅ‰øÉÈÄ≤ÁóÖ‰æãÂÑ™ÂÖàÈ†ÜÂ∫è„ÄÅÊ∏õÂ∞ëÊºèË®∫‰∏¶ÊèêÂçá AI Ê®°ÂûãÁöÑÊï¥È´îÂÆâÂÖ®ÊÄßÔºåÂæûËÄåÊé®Âãï AI Âú®Â∏∏Ë¶èË®∫Êñ∑ÂèäÂÖ∂‰ªñÈ†òÂüüÁöÑÊé°Áî®ÂíåËá™ÂãïÂåñ„ÄÇ

##### **ACR: A Benchmark for Automatic Cohort Retrieval**
2406.14780v2 by Dung Ngoc Thai, Victor Ardulov, Jose Ulises Mena, Simran Tiwari, Gleb Erofeev, Ramy Eskander, Karim Tarabishy, Ravi B Parikh, Wael Salloum

Identifying patient cohorts is fundamental to numerous healthcare tasks,
including clinical trial recruitment and retrospective studies. Current cohort
retrieval methods in healthcare organizations rely on automated queries of
structured data combined with manual curation, which are time-consuming,
labor-intensive, and often yield low-quality results. Recent advancements in
large language models (LLMs) and information retrieval (IR) offer promising
avenues to revolutionize these systems. Major challenges include managing
extensive eligibility criteria and handling the longitudinal nature of
unstructured Electronic Medical Records (EMRs) while ensuring that the solution
remains cost-effective for real-world application. This paper introduces a new
task, Automatic Cohort Retrieval (ACR), and evaluates the performance of LLMs
and commercial, domain-specific neuro-symbolic approaches. We provide a
benchmark task, a query dataset, an EMR dataset, and an evaluation framework.
Our findings underscore the necessity for efficient, high-quality ACR systems
capable of longitudinal reasoning across extensive patient databases.

ÊëòË¶ÅÔºöË≠òÂà•ÊÇ£ËÄÖÁæ§ÁµÑÊòØË®±Â§öÈÜ´ÁôÇ‰øùÂÅ•‰ªªÂãôÁöÑÂü∫Á§éÔºåÂåÖÊã¨Ëá®Â∫äË©¶È©óÊãõÂãüÂíåÂõûÈ°ßÊÄßÁ†îÁ©∂„ÄÇÁï∂ÂâçÈÜ´ÁôÇ‰øùÂÅ•ÁµÑÁπî‰∏≠ÁöÑÁæ§ÁµÑÊ™¢Á¥¢ÊñπÊ≥ï‰æùË≥¥ÊñºÁµêÊßãÂåñË≥áÊñôÁöÑËá™ÂãïÂåñÊü•Ë©¢Ôºå‰∏¶ÁµêÂêà‰∫∫Â∑•Êï¥ÁêÜÔºåÈÄôÊó¢ËÄóÊôÇÂèàË≤ªÂäõÔºåËÄå‰∏îÁ∂ìÂ∏∏Áî¢Áîü‰ΩéÂìÅË≥™ÁöÑÁµêÊûú„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåË≥áË®äÊ™¢Á¥¢ (IR) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÁÇ∫Èù©Êñ∞ÈÄô‰∫õÁ≥ªÁµ±Êèê‰æõ‰∫ÜÊúâÂ∏åÊúõÁöÑÈÄîÂæë„ÄÇ‰∏ªË¶ÅÁöÑÊåëÊà∞ÂåÖÊã¨ÁÆ°ÁêÜÂª£Ê≥õÁöÑË≥áÊ†ºÊ®ôÊ∫ñÔºå‰ª•ÂèäËôïÁêÜÈùûÁµêÊßãÂåñÈõªÂ≠êÁóÖÊ≠∑ (EMR) ÁöÑÁ∏±ÂêëÊÄßË≥™ÔºåÂêåÊôÇÁ¢∫‰øùËß£Ê±∫ÊñπÊ°àÂ∞çÂØ¶ÈöõÊáâÁî®ÂÖ∑ÊúâÊàêÊú¨ÊïàÁõä„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÈ†ÖÊñ∞‰ªªÂãôÔºåËá™ÂãïÁæ§ÁµÑÊ™¢Á¥¢ (ACR)Ôºå‰∏¶Ë©ï‰º∞‰∫Ü LLM ÂíåÂïÜÊ•≠Âåñ„ÄÅÁâπÂÆöÈ†òÂüüÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÊèê‰æõÂü∫Ê∫ñ‰ªªÂãô„ÄÅÊü•Ë©¢Ë≥áÊñôÈõÜ„ÄÅEMR Ë≥áÊñôÈõÜÂíåË©ï‰º∞Êû∂Êßã„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™ø‰∫ÜÂ∞çÊúâÊïà„ÄÅÈ´òÂìÅË≥™ÁöÑ ACR Á≥ªÁµ±ÁöÑÈúÄÊ±ÇÔºåÈÄô‰∫õÁ≥ªÁµ±ËÉΩÂ§†Ë∑®Âª£Ê≥õÁöÑÊÇ£ËÄÖË≥áÊñôÂ∫´ÈÄ≤Ë°åÁ∏±ÂêëÊé®ÁêÜ„ÄÇ

##### **A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes**
2406.14757v1 by Syed I. Munzir, Daniel B. Hier, Chelsea Oommen, Michael D. Carrithers

High-throughput phenotyping, the automated mapping of patient signs and
symptoms to standardized ontology concepts, is essential to gaining value from
electronic health records (EHR) in the support of precision medicine. Despite
technological advances, high-throughput phenotyping remains a challenge. This
study compares three computational approaches to high-throughput phenotyping: a
Large Language Model (LLM) incorporating generative AI, a Natural Language
Processing (NLP) approach utilizing deep learning for span categorization, and
a hybrid approach combining word vectors with machine learning. The approach
that implemented GPT-4 (a Large Language Model) demonstrated superior
performance, suggesting that Large Language Models are poised to be the
preferred method for high-throughput phenotyping of physician notes.

ÊëòË¶ÅÔºöÈ´òÈÄöÈáèË°®ÂûãÂàÜÊûêÔºåÂ∞áÊÇ£ËÄÖÁóáÁãÄÂíåÈ´îÂæµËá™ÂãïÂ∞çÊáâÂà∞Ê®ôÊ∫ñÂåñÊú¨È´îÊ¶ÇÂøµÔºåÂ∞çÊñºÂú®Á≤æÊ∫ñÈÜ´ÁôÇ‰∏≠Áç≤ÂèñÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑÔºàEHRÔºâÁöÑÂÉπÂÄºËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°ÊúâÊäÄË°ìÈÄ≤Â±ïÔºåÈ´òÈÄöÈáèË°®ÂûãÂàÜÊûê‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÊØîËºÉ‰∫Ü‰∏âÁ®ÆÈ´òÈÄöÈáèË°®ÂûãÂàÜÊûêÁöÑË®àÁÆóÊñπÊ≥ïÔºö‰∏ÄÂÄãÁµêÂêàÁîüÊàêÂºè AI ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ„ÄÅ‰∏ÄÂÄãÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÈÄ≤Ë°åË∑®Â∫¶ÂàÜÈ°ûÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºàNLPÔºâÊñπÊ≥ïÔºå‰ª•Âèä‰∏ÄÂÄãÁµêÂêàË©ûÂêëÈáèËàáÊ©üÂô®Â≠∏ÁøíÁöÑÊ∑∑ÂêàÊñπÊ≥ï„ÄÇÂØ¶‰Ωú GPT-4Ôºà‰∏ÄÂÄãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºâÁöÑÊñπÊ≥ïË°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÈÄôË°®Á§∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊúâÊúõÊàêÁÇ∫ÈÜ´Â∏´ÂÇôÂøòÈåÑÁöÑÈ´òÈÄöÈáèË°®ÂûãÂàÜÊûêÈ¶ñÈÅ∏ÊñπÊ≥ï„ÄÇ

##### **An updated overview of radiomics-based artificial intelligence (AI) methods in breast cancer screening and diagnosis**
2406.14735v1 by Reza Elahi, Mahdis Nazari

Current imaging methods for diagnosing BC are associated with limited
sensitivity and specificity and modest positive predictive power. The recent
progress in image analysis using artificial intelligence (AI) has created great
promise to improve breast cancer (BC) diagnosis and subtype differentiation. In
this case, novel quantitative computational methods, such as radiomics, have
been developed to improve the sensitivity and specificity of early BC diagnosis
and classification. The potential of radiomics in improving the diagnostic
efficacy of imaging studies has been shown in several studies. In this review
article, we discuss the radiomics workflow and current hand-crafted radiomics
methods in the diagnosis and classification of BC based on most recent studies
on different imaging modalities, e.g. MRI, mammography, contrast-enhanced
spectral mammography (CESM), ultrasound imaging, and digital breast
tumosynthesis (DBT). We also discuss current challenges and potential
strategies to improve the specificity and sensitivity of radiomics in breast
cancer to help achieve a higher level of BC classification and diagnosis in the
clinical setting. The growing field of AI incorporation with imaging
information has opened a great opportunity to provide a higher level of care
for BC patients.

ÊëòË¶ÅÔºöÁõÆÂâçÁî®ÊñºË®∫Êñ∑‰π≥ÁôåÁöÑÂΩ±ÂÉèÊñπÊ≥ïËàáÊúâÈôêÁöÑÊïèÊÑüÂ∫¶ÂíåÁâπÁï∞Â∫¶‰ª•ÂèäÈÅ©Â∫¶ÁöÑÈôΩÊÄßÈ†êÊ∏¨ËÉΩÂäõÊúâÈóú„ÄÇËøëÊúü‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂΩ±ÂÉèÂàÜÊûêÈÄ≤Â±ïÁÇ∫ÊîπÂñÑ‰π≥Áôå (BC) Ë®∫Êñ∑Âíå‰∫ûÂûãÂçÄÂàÜÂâµÈÄ†‰∫ÜÊ•µÂ§ßÁöÑÂ∏åÊúõ„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÂ∑≤Á∂ìÈñãÁôºÂá∫Êñ∞ÁöÑÂÆöÈáèË®àÁÆóÊñπÊ≥ïÔºà‰æãÂ¶ÇÊîæÂ∞ÑÁâπÂæµÁµÑÂ≠∏Ôºâ‰æÜÊèêÈ´òÊó©Êúü‰π≥ÁôåË®∫Êñ∑ÂíåÂàÜÈ°ûÁöÑÊïèÊÑüÂ∫¶ÂíåÁâπÁï∞Â∫¶„ÄÇÊîæÂ∞ÑÁâπÂæµÁµÑÂ≠∏Âú®ÊèêÈ´òÂΩ±ÂÉèÁ†îÁ©∂Ë®∫Êñ∑ÊïàËÉΩÁöÑÊΩõÂäõÂ∑≤Âú®Â§öÈ†ÖÁ†îÁ©∂‰∏≠ÂæóÂà∞Ë≠âÂØ¶„ÄÇÂú®ÈÄôÁØáË©ïË´ñÊñáÁ´†‰∏≠ÔºåÊàëÂÄëÊ†πÊìö‰∏çÂêåÂΩ±ÂÉèÊ®°ÂºèÔºà‰æãÂ¶Ç MRI„ÄÅ‰π≥ÊàøÊîùÂΩ±„ÄÅÂ∞çÊØîÂ¢ûÂº∑ÂÖâË≠ú‰π≥ÊàøÊîùÂΩ± (CESM)„ÄÅË∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂíåÊï∏‰Ωç‰π≥ÊàøÊñ∑Â±§ÂêàÊàê (DBT)ÔºâÁöÑÊúÄÊñ∞Á†îÁ©∂ÔºåË®éË´ñÊîæÂ∞ÑÁâπÂæµÁµÑÂ≠∏Â∑•‰ΩúÊµÅÁ®ãÂíåÁõÆÂâçÊâãÂ∑•Ë£Ω‰ΩúÁöÑÊîæÂ∞ÑÁâπÂæµÁµÑÂ≠∏ÊñπÊ≥ïÂú®‰π≥ÁôåË®∫Êñ∑ÂíåÂàÜÈ°û‰∏≠ÁöÑÊáâÁî®„ÄÇÊàëÂÄë‰πüË®éË´ñ‰∫ÜÁï∂ÂâçÊåëÊà∞ÂíåÊΩõÂú®Á≠ñÁï•Ôºå‰ª•ÊèêÈ´òÊîæÂ∞ÑÁâπÂæµÁµÑÂ≠∏Âú®‰π≥Áôå‰∏≠ÁöÑÁâπÁï∞Â∫¶ÂíåÊïèÊÑüÂ∫¶Ôºå‰ª•ÂçîÂä©Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠ÈÅîÂà∞Êõ¥È´òÂ±§Á¥öÁöÑ‰π≥ÁôåÂàÜÈ°ûÂíåË®∫Êñ∑„ÄÇÂ∞á AI Á¥çÂÖ•ÂΩ±ÂÉèË≥áË®äÁöÑÈ†òÂüüÊ≠£Âú®ÊàêÈï∑ÔºåÈÄôÁÇ∫Êèê‰æõÊõ¥È´òÂ±§Á¥öÁöÑ‰π≥ÁôåÊÇ£ËÄÖÁÖßË≠∑ÈñãÂïü‰∫Ü‰∏ÄÂÄãÁµï‰Ω≥Ê©üÊúÉ„ÄÇ

##### **This Looks Better than That: Better Interpretable Models with ProtoPNeXt**
2406.14675v1 by Frank Willard, Luke Moffett, Emmanuel Mokel, Jon Donnelly, Stark Guo, Julia Yang, Giyoung Kim, Alina Jade Barnett, Cynthia Rudin

Prototypical-part models are a popular interpretable alternative to black-box
deep learning models for computer vision. However, they are difficult to train,
with high sensitivity to hyperparameter tuning, inhibiting their application to
new datasets and our understanding of which methods truly improve their
performance. To facilitate the careful study of prototypical-part networks
(ProtoPNets), we create a new framework for integrating components of
prototypical-part models -- ProtoPNeXt. Using ProtoPNeXt, we show that applying
Bayesian hyperparameter tuning and an angular prototype similarity metric to
the original ProtoPNet is sufficient to produce new state-of-the-art accuracy
for prototypical-part models on CUB-200 across multiple backbones. We further
deploy this framework to jointly optimize for accuracy and prototype
interpretability as measured by metrics included in ProtoPNeXt. Using the same
resources, this produces models with substantially superior semantics and
changes in accuracy between +1.3% and -1.5%. The code and trained models will
be made publicly available upon publication.

ÊëòË¶ÅÔºöÂéüÂûãÈÉ®ÂàÜÊ®°ÂûãÊòØËÆ°ÁÆóÊú∫ËßÜËßâ‰∏≠‰∏ÄÁßçÊµÅË°åÁöÑÂèØËß£ÈáäÁöÑÈªëÁõíÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÊõø‰ª£ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂÆÉ‰ª¨ÂæàÈöæËÆ≠ÁªÉÔºåÂØπË∂ÖÂèÇÊï∞Ë∞ÉÊï¥È´òÂ∫¶ÊïèÊÑüÔºåËøôÊäëÂà∂‰∫ÜÂÆÉ‰ª¨Âú®Êñ∞Êï∞ÊçÆÈõÜ‰∏äÁöÑÂ∫îÁî®Ôºå‰ª•ÂèäÊàë‰ª¨ÂØπÁúüÊ≠£ÊèêÈ´òÂÖ∂ÊÄßËÉΩÁöÑÊñπÊ≥ïÁöÑÁêÜËß£„ÄÇ‰∏∫‰∫Ü‰øÉËøõÂØπÂéüÂûãÈÉ®ÂàÜÁΩëÁªú (ProtoPNets) ÁöÑ‰ªîÁªÜÁ†îÁ©∂ÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÊ°ÜÊû∂Êù•ÈõÜÊàêÂéüÂûãÈÉ®ÂàÜÊ®°ÂûãÁöÑÁªÑ‰ª∂‚Äî‚ÄîProtoPNeXt„ÄÇ‰ΩøÁî® ProtoPNeXtÔºåÊàë‰ª¨Ë°®ÊòéÂØπÂéüÂßã ProtoPNet Â∫îÁî®Ë¥ùÂè∂ÊñØË∂ÖÂèÇÊï∞Ë∞ÉÊï¥ÂíåËßíÂ∫¶ÂéüÂûãÁõ∏‰ººÊÄßÂ∫¶ÈáèË∂≥‰ª•Âú®Â§ö‰∏™È™®Âπ≤ÁΩë‰∏ä‰∏∫ CUB-200 ‰∏äÁöÑÂéüÂûãÈÉ®ÂàÜÊ®°Âûã‰∫ßÁîüÊñ∞ÁöÑÊúÄÂÖàËøõÁöÑÂáÜÁ°ÆÊÄß„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÈÉ®ÁΩ≤Ê≠§Ê°ÜÊû∂‰ª•Ê†πÊçÆ ProtoPNeXt ‰∏≠ÂåÖÂê´ÁöÑÊåáÊ†áÂÖ±Âêå‰ºòÂåñÂáÜÁ°ÆÊÄßÂíåÂéüÂûãÂèØËß£ÈáäÊÄß„ÄÇ‰ΩøÁî®Áõ∏ÂêåÁöÑËµÑÊ∫êÔºåËøô‰ºö‰∫ßÁîüÂÖ∑ÊúâÊòéÊòæ‰ºòË∂äÁöÑËØ≠‰πâÂíåÂáÜÁ°ÆÊÄßÂèòÂåñÁöÑÊ®°ÂûãÔºå‰ªã‰∫é +1.3% Âíå -1.5% ‰πãÈó¥„ÄÇ‰ª£Á†ÅÂíåËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÂ∞ÜÂú®ÂèëÂ∏ÉÂêéÂÖ¨ÂºÄ„ÄÇ

##### **Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection**
2406.14377v1 by Rushuang Zhou, Zijun Liu, Lei Clifton, David A. Clifton, Kannie W. Y. Chan, Yuan-Ting Zhang, Yining Dong

Label scarcity problem is the main challenge that hinders the wide
application of deep learning systems in automatic cardiovascular diseases
(CVDs) detection using electrocardiography (ECG). Tuning pre-trained models
alleviates this problem by transferring knowledge learned from large datasets
to downstream small datasets. However, bottlenecks in computational efficiency
and CVDs detection performance limit its clinical applications. It is difficult
to improve the detection performance without significantly sacrificing model
computational efficiency. Here, we propose a computation-efficient
semi-supervised learning paradigm (FastECG) for robust and
computation-efficient CVDs detection using ECG. It enables a robust adaptation
of pre-trained models on downstream datasets with limited supervision and high
computational efficiency. First, a random-deactivation technique is developed
to achieve robust and fast low-rank adaptation of pre-trained weights.
Subsequently, we propose a one-shot rank allocation module to determine the
optimal ranks for the update matrices of the pre-trained weights. Finally, a
lightweight semi-supervised learning pipeline is introduced to enhance model
performance by leveraging labeled and unlabeled data with high computational
efficiency. Extensive experiments on four downstream ECG datasets demonstrate
that FastECG not only outperforms the state-of-the-art methods in multi-label
CVDs detection but also consumes fewer GPU footprints, training time, and
parameter storage space. As such, this paradigm provides an effective solution
for achieving high computational efficiency and robust detection performance in
the clinical applications of pre-trained models under limited supervision.

ÊëòË¶ÅÔºöÊ®ôÁ±§Á®ÄÁº∫ÂïèÈ°åÊòØÈòªÁ§ôÊ∑±Â∫¶Â≠∏ÁøíÁ≥ªÁµ±Âú®Ëá™ÂãïÂøÉË°ÄÁÆ°ÁñæÁóÖ (CVD) ‰ΩøÁî®ÂøÉÈõªÂúñ (ECG) Ê™¢Ê∏¨‰∏≠Âª£Ê≥õÊáâÁî®‰πã‰∏ªË¶ÅÊåëÊà∞„ÄÇË™øÊï¥È†êË®ìÁ∑¥Ê®°ÂûãÈÄèÈÅéÂ∞áÂæûÂ§ßÂûãË≥áÊñôÈõÜÂ≠∏Âà∞ÁöÑÁü•Ë≠òËΩâÁßªÂà∞‰∏ãÊ∏∏Â∞èÂûãË≥áÊñôÈõÜÔºå‰æÜÁ∑©Ëß£Ê≠§ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÈÅãÁÆóÊïàÁéáÂíå CVD Ê™¢Ê∏¨ÊïàËÉΩÁöÑÁì∂È†∏ÈôêÂà∂‰∫ÜÂÖ∂Ëá®Â∫äÊáâÁî®„ÄÇÂú®‰∏çÈ°ØËëóÁäßÁâ≤Ê®°ÂûãÈÅãÁÆóÊïàÁéáÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈõ£‰ª•ÊîπÂñÑÊ™¢Ê∏¨ÊïàËÉΩ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈÅãÁÆóÊïàÁéáÁöÑÂçäÁõ£Áù£Â≠∏ÁøíÁØÑ‰æã (FastECG)ÔºåÁî®Êñº‰ΩøÁî® ECG ÈÄ≤Ë°åÁ©©ÂÅ•‰∏îÈÅãÁÆóÊïàÁéáÈ´òÁöÑ CVD Ê™¢Ê∏¨„ÄÇÂÆÉËÉΩËÆìÈ†êË®ìÁ∑¥Ê®°ÂûãÂú®Áõ£Áù£ÊúâÈôê‰∏îÈÅãÁÆóÊïàÁéáÈ´òÁöÑ‰∏ãÊ∏∏Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁ©©ÂÅ•ÁöÑË™øÊï¥„ÄÇÈ¶ñÂÖàÔºåÈñãÁôºÂá∫‰∏ÄÁ®ÆÈö®Ê©üÂÅúÁî®ÊäÄË°ìÔºå‰ª•ÈÅîÊàêÈ†êË®ìÁ∑¥Ê¨äÈáçÁöÑÁ©©ÂÅ•‰∏îÂø´ÈÄüÁöÑ‰ΩéÁß©Ë™øÊï¥„ÄÇÊé•ËëóÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰∏ÄÊ¨°ÊÄßÁß©ÈÖçÁΩÆÊ®°ÁµÑÔºåÁî®ÊñºÁ¢∫ÂÆöÈ†êË®ìÁ∑¥Ê¨äÈáçÁöÑÊõ¥Êñ∞Áü©Èô£‰πãÊúÄ‰Ω≥Áß©„ÄÇÊúÄÂæåÔºåÂºïÂÖ•‰∏ÄÂÄãËºïÈáèÁ¥öÁöÑÂçäÁõ£Áù£Â≠∏ÁøíÁÆ°Á∑öÔºå‰ª•Âà©Áî®Ê®ôÁ±§ÂíåÊú™Ê®ôÁ±§Ë≥áÊñôÔºå‰∏¶Âú®È´òÈÅãÁÆóÊïàÁéá‰∏ãÊèêÂçáÊ®°ÂûãÊïàËÉΩ„ÄÇÂú®ÂõõÂÄã‰∏ãÊ∏∏ ECG Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåFastECG ‰∏çÂÉÖÂú®Â§öÊ®ôÁ±§ CVD Ê™¢Ê∏¨‰∏≠ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåËÄå‰∏îÊ∂àËÄóÊõ¥Â∞ëÁöÑ GPU Âç†Áî®Á©∫Èñì„ÄÅË®ìÁ∑¥ÊôÇÈñìÂíåÂèÉÊï∏ÂÑ≤Â≠òÁ©∫Èñì„ÄÇÂõ†Ê≠§ÔºåÊ≠§ÁØÑ‰æãÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁî®ÊñºÂú®Áõ£Áù£ÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊñºÈ†êË®ìÁ∑¥Ê®°ÂûãÁöÑËá®Â∫äÊáâÁî®‰∏≠ÈÅîÊàêÈ´òÈÅãÁÆóÊïàÁéáÂíåÁ©©ÂÅ•ÁöÑÊ™¢Ê∏¨ÊïàËÉΩ„ÄÇ

##### **Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning**
2406.14351v1 by Niccol√≤ Marini, Stefano Marchesin, Lluis Borras Ferris, Simon P√ºttmann, Marek Wodzinski, Riccardo Fratti, Damian Podareanu, Alessandro Caputo, Svetla Boytcheva, Simona Vatrano, Filippo Fraggetta, Iris Nagtegaal, Gianmaria Silvello, Manfredo Atzori, Henning M√ºller

The increasing availability of biomedical data is helping to design more
robust deep learning (DL) algorithms to analyze biomedical samples. Currently,
one of the main limitations to train DL algorithms to perform a specific task
is the need for medical experts to label data. Automatic methods to label data
exist, however automatic labels can be noisy and it is not completely clear
when automatic labels can be adopted to train DL models. This paper aims to
investigate under which circumstances automatic labels can be adopted to train
a DL model on the classification of Whole Slide Images (WSI). The analysis
involves multiple architectures, such as Convolutional Neural Networks (CNN)
and Vision Transformer (ViT), and over 10000 WSIs, collected from three use
cases: celiac disease, lung cancer and colon cancer, which one including
respectively binary, multiclass and multilabel data. The results allow
identifying 10% as the percentage of noisy labels that lead to train
competitive models for the classification of WSIs. Therefore, an algorithm
generating automatic labels needs to fit this criterion to be adopted. The
application of the Semantic Knowledge Extractor Tool (SKET) algorithm to
generate automatic labels leads to performance comparable to the one obtained
with manual labels, since it generates a percentage of noisy labels between
2-5%. Automatic labels are as effective as manual ones, reaching solid
performance comparable to the one obtained training models with manual labels.

ÊëòË¶ÅÔºöÈö®ËëóÁîüÁâ©ÈÜ´Â≠∏Ë≥áÊñôÁöÑÊó•ÁõäÊôÆÂèäÔºåÊúâÂä©ÊñºË®≠Ë®àÊõ¥Á©©ÂÅ•ÁöÑÊ∑±Â∫¶Â≠∏Áøí (DL) ÊºîÁÆóÊ≥ï‰æÜÂàÜÊûêÁîüÁâ©ÈÜ´Â≠∏Ê®£Êú¨„ÄÇÁõÆÂâçÔºåË®ìÁ∑¥ DL ÊºîÁÆóÊ≥ïÂü∑Ë°åÁâπÂÆö‰ªªÂãôÁöÑ‰∏ªË¶ÅÈôêÂà∂‰πã‰∏ÄÂú®ÊñºÈÜ´Â≠∏Â∞àÂÆ∂Ê®ôË®òË≥áÊñôÁöÑÈúÄÊ±Ç„ÄÇÊ®ôË®òË≥áÊñôÁöÑËá™ÂãïÂåñÊñπÊ≥ïÁ¢∫ÂØ¶Â≠òÂú®ÔºåÁÑ∂ËÄåËá™ÂãïÂåñÊ®ôÁ±§ÂèØËÉΩÊúÉÁî¢ÁîüÈõúË®äÔºåËÄå‰∏îÂ∞ö‰∏çÊ∏ÖÊ•ö‰ΩïÊôÇÂèØ‰ª•Êé°Áî®Ëá™ÂãïÂåñÊ®ôÁ±§‰æÜË®ìÁ∑¥ DL Ê®°Âûã„ÄÇÊú¨ÊñáÊó®Âú®Êé¢Ë®éÂú®‰ΩïÁ®ÆÊÉÖÊ≥Å‰∏ãÂèØ‰ª•Êé°Áî®Ëá™ÂãïÂåñÊ®ôÁ±§‰æÜË®ìÁ∑¥ DL Ê®°ÂûãÂ∞çÂÖ®ÂàáÁâáÂΩ±ÂÉè (WSI) ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂàÜÊûêÊ∂âÂèäÂ§öÁ®ÆÊû∂ÊßãÔºå‰æãÂ¶ÇÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåË¶ñË¶∫Transformer (ViT)Ôºå‰ª•ÂèäË∂ÖÈÅé 10000 ÂÄã WSIÔºåÈÄô‰∫õ WSI ‰æÜËá™‰∏âÁ®Æ‰ΩøÁî®Ê°à‰æãÔºö‰π≥Á≥úÁÄâ„ÄÅËÇ∫ÁôåÂíåÁµêËÖ∏ÁôåÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÂàÜÂà•ÂåÖÊã¨‰∫åÂÖÉ„ÄÅÂ§öÈ°ûÂíåÂ§öÊ®ôÁ±§Ë≥áÊñô„ÄÇÁµêÊûúÂèØ‰ª•Â∞áÁî¢ÁîüÈõúË®äÊ®ôÁ±§ÁöÑÊØî‰æãÁ¢∫ÂÆöÁÇ∫ 10%ÔºåÈÄôÂ∞áÂ∞éËá¥Ë®ìÁ∑¥Âá∫ÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑ WSI ÂàÜÈ°ûÊ®°Âûã„ÄÇÂõ†Ê≠§ÔºåÁî¢ÁîüËá™ÂãïÂåñÊ®ôÁ±§ÁöÑÊºîÁÆóÊ≥ïÈúÄË¶ÅÁ¨¶ÂêàÊ≠§Ê∫ñÂâáÊâçËÉΩË¢´Êé°Áî®„ÄÇÂ∞áË™ûÁæ©Áü•Ë≠òËêÉÂèñÂ∑•ÂÖ∑ (SKET) ÊºîÁÆóÊ≥ïÊáâÁî®ÊñºÁî¢ÁîüËá™ÂãïÂåñÊ®ôÁ±§ÔºåÂÖ∂ÊïàËÉΩÂèØËàá‰ΩøÁî®‰∫∫Â∑•Ê®ôÁ±§Áç≤ÂæóÁöÑÊïàËÉΩÁõ∏Â™≤ÁæéÔºåÂõ†ÁÇ∫ÂÆÉÁî¢ÁîüÁöÑÈõúË®äÊ®ôÁ±§ÊØî‰æãÂú® 2-5% ‰πãÈñì„ÄÇËá™ÂãïÂåñÊ®ôÁ±§Ëàá‰∫∫Â∑•Ê®ôÁ±§‰∏ÄÊ®£ÊúâÊïàÔºåÂèØÈÅîÂà∞Ëàá‰ΩøÁî®‰∫∫Â∑•Ê®ôÁ±§Ë®ìÁ∑¥Ê®°ÂûãÊâÄÁç≤ÂæóÁöÑÊïàËÉΩÁõ∏Áï∂ÁöÑÁ©©ÂÅ•ÊïàËÉΩ„ÄÇ

##### **Infusing clinical knowledge into tokenisers for language models**
2406.14312v1 by Abul Hasan, Jinge Wu, Quang Ngoc Nguyen, Salom√© Andres, Imane Guellil, Huayu Zhang, Arlene Casey, Beatrice Alex, Bruce Guthrie, Honghan Wu

This study introduces a novel knowledge enhanced tokenisation mechanism,
K-Tokeniser, for clinical text processing. Technically, at initialisation
stage, K-Tokeniser populates global representations of tokens based on semantic
types of domain concepts (such as drugs or diseases) from either a domain
ontology like Unified Medical Language System or the training data of the task
related corpus. At training or inference stage, sentence level localised
context will be utilised for choosing the optimal global token representation
to realise the semantic-based tokenisation. To avoid pretraining using the new
tokeniser, an embedding initialisation approach is proposed to generate
representations for new tokens. Using three transformer-based language models,
a comprehensive set of experiments are conducted on four real-world datasets
for evaluating K-Tokeniser in a wide range of clinical text analytics tasks
including clinical concept and relation extraction, automated clinical coding,
clinical phenotype identification, and clinical research article
classification. Overall, our models demonstrate consistent improvements over
their counterparts in all tasks. In particular, substantial improvements are
observed in the automated clinical coding task with 13\% increase on Micro
$F_1$ score. Furthermore, K-Tokeniser also shows significant capacities in
facilitating quicker converge of language models. Specifically, using
K-Tokeniser, the language models would only require 50\% of the training data
to achieve the best performance of the baseline tokeniser using all training
data in the concept extraction task and less than 20\% of the data for the
automated coding task. It is worth mentioning that all these improvements
require no pre-training process, making the approach generalisable.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁü•Ë≠òÂ¢ûÂº∑Ê®ôË®òÂåñÊ©üÂà∂ÔºåK-TokeniserÔºåÁî®ÊñºËá®Â∫äÊñáÊú¨ËôïÁêÜ„ÄÇÊäÄË°ì‰∏äÔºåÂú®ÂàùÂßãÂåñÈöéÊÆµÔºåK-Tokeniser ÊúÉÊ†πÊìö‰æÜËá™È†òÂüüÊ¶ÇÂøµÔºà‰æãÂ¶ÇËó•Áâ©ÊàñÁñæÁóÖÔºâÁöÑË™ûÁæ©È°ûÂûãÔºåÂæûÁµ±‰∏ÄÈÜ´Â≠∏Ë™ûË®ÄÁ≥ªÁµ±Êàñ‰ªªÂãôÁõ∏ÈóúË™ûÊñôÂ∫´ÁöÑË®ìÁ∑¥Ë≥áÊñô‰∏≠ÔºåÂ°´ÂÖÖÊ®ôË®òÁöÑÂÖ®Â±ÄË°®Á§∫„ÄÇÂú®Ë®ìÁ∑¥ÊàñÊé®Ë´ñÈöéÊÆµÔºåÂè•Â≠êÁ¥öÂà•ÁöÑÂ±ÄÈÉ®Âåñ‰∏ä‰∏ãÊñáÂ∞áË¢´Áî®ÊñºÈÅ∏ÊìáÊúÄ‰Ω≥ÁöÑÂÖ®Â±ÄÊ®ôË®òË°®Á§∫Ôºå‰ª•ÂØ¶ÁèæÂü∫ÊñºË™ûÁæ©ÁöÑÊ®ôË®òÂåñ„ÄÇÁÇ∫‰∫ÜÈÅøÂÖç‰ΩøÁî®Êñ∞ÁöÑÊ®ôË®òÂåñÂô®ÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂµåÂÖ•ÂàùÂßãÂåñÊñπÊ≥ïÔºå‰ª•Áî¢ÁîüÊñ∞Ê®ôË®òÁöÑË°®Á§∫„ÄÇ‰ΩøÁî®‰∏âÁ®ÆÂü∫ÊñºTransformerÁöÑË™ûË®ÄÊ®°ÂûãÔºåÂ∞çÂõõÂÄãÁúüÂØ¶‰∏ñÁïåÊï∏ÊìöÈõÜÈÄ≤Ë°å‰∫Ü‰∏ÄÁµÑÂÖ®Èù¢ÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞ K-Tokeniser Âú®Âª£Ê≥õÁöÑËá®Â∫äÊñáÊú¨ÂàÜÊûê‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÔºåÂåÖÊã¨Ëá®Â∫äÊ¶ÇÂøµÂíåÈóú‰øÇÊèêÂèñ„ÄÅËá™ÂãïËá®Â∫äÁ∑®Á¢º„ÄÅËá®Â∫äË°®ÂûãË≠òÂà•ÂíåËá®Â∫äÁ†îÁ©∂ÊñáÁ´†ÂàÜÈ°û„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊâÄÊúâ‰ªªÂãô‰∏≠ÈÉΩÂ±ïÁ§∫Âá∫ÊØîÂÖ∂Â∞çÊáâÊ®°ÂûãÊõ¥‰∏ÄËá¥ÁöÑÊîπÈÄ≤„ÄÇÁâπÂà•ÊòØÔºåÂú®Ëá™ÂãïËá®Â∫äÁ∑®Á¢º‰ªªÂãô‰∏≠ËßÄÂØüÂà∞‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåMicro $F_1$ ÂæóÂàÜÊèêÈ´ò‰∫Ü 13%„ÄÇÊ≠§Â§ñÔºåK-Tokeniser ÈÇÑÈ°ØÁ§∫Âá∫È°ØËëóÁöÑËÉΩÂäõÔºåÂèØ‰ª•‰øÉÈÄ≤Ë™ûË®ÄÊ®°ÂûãÊõ¥Âø´ÁöÑÊî∂ÊñÇ„ÄÇÂÖ∑È´î‰æÜË™™Ôºå‰ΩøÁî® K-TokeniserÔºåË™ûË®ÄÊ®°ÂûãÂè™ÈúÄË¶Å 50% ÁöÑË®ìÁ∑¥Êï∏ÊìöÂç≥ÂèØÂú®Ê¶ÇÂøµÊèêÂèñ‰ªªÂãô‰∏≠ÈÅîÂà∞Âü∫Á∑öÊ®ôË®òÂåñÂô®‰ΩøÁî®ÊâÄÊúâË®ìÁ∑¥Êï∏ÊìöÁöÑÊúÄ‰Ω≥ÊÄßËÉΩÔºåËÄåËá™ÂãïÁ∑®Á¢º‰ªªÂãôÂâá‰∏çÂà∞ 20% ÁöÑÊï∏Êìö„ÄÇÂÄºÂæó‰∏ÄÊèêÁöÑÊòØÔºåÊâÄÊúâÈÄô‰∫õÊîπÈÄ≤ÈÉΩ‰∏çÈúÄË¶ÅÈ†êË®ìÁ∑¥ÈÅéÁ®ãÔºåÈÄô‰ΩøÂæóË©≤ÊñπÊ≥ïÂÖ∑ÊúâÊôÆÈÅçÊÄß„ÄÇ

##### **Enhancing robustness of data-driven SHM models: adversarial training with circle loss**
2406.14232v1 by Xiangli Yang, Xijie Deng, Hanwei Zhang, Yang Zou, Jianxi Yang

Structural health monitoring (SHM) is critical to safeguarding the safety and
reliability of aerospace, civil, and mechanical infrastructure. Machine
learning-based data-driven approaches have gained popularity in SHM due to
advancements in sensors and computational power. However, machine learning
models used in SHM are vulnerable to adversarial examples -- even small changes
in input can lead to different model outputs. This paper aims to address this
problem by discussing adversarial defenses in SHM. In this paper, we propose an
adversarial training method for defense, which uses circle loss to optimize the
distance between features in training to keep examples away from the decision
boundary. Through this simple yet effective constraint, our method demonstrates
substantial improvements in model robustness, surpassing existing defense
mechanisms.

ÊëòË¶ÅÔºöÁµêÊßãÂÅ•Â∫∑Áõ£Ê∏¨ (SHM) Â∞ç‰øùÈöúËà™Â§™„ÄÅÂúüÊú®ÂíåÊ©üÊ¢∞Âü∫Á§éË®≠ÊñΩÁöÑÂÆâÂÖ®ÂíåÂèØÈù†ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÊ©üÂô®Â≠∏ÁøíÁÇ∫Âü∫Á§éÁöÑË≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÁî±ÊñºÊÑüÊ∏¨Âô®ÂíåË®àÁÆóËÉΩÂäõÁöÑÈÄ≤Ê≠•ÔºåÂú® SHM ‰∏≠Áç≤ÂæóÊôÆÂèä„ÄÇÁÑ∂ËÄåÔºåÁî®Êñº SHM ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÁØÑ‰æãÁöÑÂΩ±Èüø‚Äî‚ÄîËº∏ÂÖ•ÁöÑÂæÆÂ∞èËÆäÊõ¥ÁîöËá≥ÂèØËÉΩÂ∞éËá¥‰∏çÂêåÁöÑÊ®°ÂûãËº∏Âá∫„ÄÇÊú¨ÊñáÊó®Âú®ÈÄèÈÅéË®éË´ñ SHM ‰∏≠ÁöÑÂ∞çÊäóÊÄßÈò≤Á¶¶‰æÜËß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁî®ÊñºÈò≤Á¶¶ÁöÑÂ∞çÊäóÊÄßË®ìÁ∑¥ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®ÂúìÂΩ¢ÊêçÂ§±‰æÜÊúÄ‰Ω≥ÂåñË®ìÁ∑¥‰∏≠ÁâπÂæµ‰πãÈñìÁöÑË∑ùÈõ¢Ôºå‰ª•‰ΩøÁØÑ‰æãÈÅ†Èõ¢Ê±∫Á≠ñÈÇäÁïå„ÄÇÈÄèÈÅéÈÄôÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÁ¥ÑÊùüÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÊ®°ÂûãÁ©©ÂÅ•ÊÄßÁöÑÈ°ØËëóÊîπÂñÑÔºåË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÈò≤Á¶¶Ê©üÂà∂„ÄÇ

