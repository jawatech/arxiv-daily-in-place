{"2502.13791": {"publish_time": "2025-02-19", "title": "From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions", "paper_summary": "Large Language Models (LLMs) are increasingly used in working environments\nfor a wide range of tasks, excelling at solving individual problems in\nisolation. However, are they also able to effectively collaborate over\nlong-term interactions? To investigate this, we introduce MemoryCode, a\nsynthetic multi-session dataset designed to test LLMs' ability to track and\nexecute simple coding instructions amid irrelevant information, simulating a\nrealistic setting. While all the models we tested handle isolated instructions\nwell, even the performance of state-of-the-art models like GPT-4o deteriorates\nwhen instructions are spread across sessions. Our analysis suggests this is due\nto their failure to retrieve and integrate information over long instruction\nchains. Our results highlight a fundamental limitation of current LLMs,\nrestricting their ability to collaborate effectively in long interactions.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)  zunehmend in Arbeitsumgebungen f\u00fcr eine Vielzahl von Aufgaben verwendet, die sich bei der isolierten L\u00f6sung einzelner Probleme auszeichnen. Sind sie jedoch auch in der Lage, bei langfristigen Interaktionen effektiv zusammenzuarbeiten? Um dies zu untersuchen, f\u00fchren wir MemoryCode ein, einen synthetischen Multi-Session-Datensatz, der entwickelt wurde, um die F\u00e4higkeit von LLMs zu testen, einfache Codierungsanweisungen inmitten irrelevanter Informationen zu verfolgen und auszuf\u00fchren, und so eine realistische Umgebung zu simulieren. W\u00e4hrend alle von uns getesteten Modelle isolierte Anweisungen gut handhaben, verschlechtert sich selbst die Leistung modernster Modelle wie GPT-4o, wenn Anweisungen \u00fcber Sitzungen verteilt werden. Unsere Analyse legt nahe, dass dies auf ihr Versagen zur\u00fcckzuf\u00fchren ist, Informationen \u00fcber lange Befehlsketten abzurufen und zu integrieren. Unsere Ergebnisse zeigen eine grundlegende Einschr\u00e4nkung aktueller LLMs auf und schr\u00e4nken ihre F\u00e4higkeit ein, bei langen Interaktionen effektiv zusammenzuarbeiten.", "author": "Nathana\u00ebl Carraz Rakotonirina et.al.", "authors": "Nathana\u00ebl Carraz Rakotonirina, Mohammed Hamdy, Jon Ander Campos, Lucas Weber, Alberto Testoni, Marzieh Fadaee, Sandro Pezzelle, Marco Del Tredici", "id": "2502.13791v1", "paper_url": "http://arxiv.org/abs/2502.13791v1", "repo": "null"}}