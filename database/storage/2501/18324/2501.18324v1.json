{"2501.18324": {"publish_time": "2025-01-30", "title": "A Video-grounded Dialogue Dataset and Metric for Event-driven Activities", "paper_summary": "This paper presents VDAct, a dataset for a Video-grounded Dialogue on\nEvent-driven Activities, alongside VDEval, a session-based context evaluation\nmetric specially designed for the task. Unlike existing datasets, VDAct\nincludes longer and more complex video sequences that depict a variety of\nevent-driven activities that require advanced contextual understanding for\naccurate response generation. The dataset comprises 3,000 dialogues with over\n30,000 question-and-answer pairs, derived from 1,000 videos with diverse\nactivity scenarios. VDAct displays a notably challenging characteristic due to\nits broad spectrum of activity scenarios and wide range of question types.\nEmpirical studies on state-of-the-art vision foundation models highlight their\nlimitations in addressing certain question types on our dataset. Furthermore,\nVDEval, which integrates dialogue session history and video content summaries\nextracted from our supplementary Knowledge Graphs to evaluate individual\nresponses, demonstrates a significantly higher correlation with human\nassessments on the VDAct dataset than existing evaluation metrics that rely\nsolely on the context of single dialogue turns.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86 VDAct\uff0c\u4e00\u4e2a\u7528\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u6d3b\u52a8\u4e2d\u7684\u89c6\u9891\u57fa\u7840\u5bf9\u8bdd\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u53ca VDEval\uff0c\u4e00\u79cd\u4e13\u95e8\u4e3a\u8be5\u4efb\u52a1\u8bbe\u8ba1\u7684\u57fa\u4e8e\u4f1a\u8bdd\u7684\u4e0a\u4e0b\u6587\u8bc4\u4f30\u6307\u6807\u3002\u4e0e\u73b0\u6709\u6570\u636e\u96c6\u4e0d\u540c\uff0cVDAct \u5305\u542b\u66f4\u957f\u4e14\u66f4\u590d\u6742\u7684\u89c6\u9891\u5e8f\u5217\uff0c\u8fd9\u4e9b\u5e8f\u5217\u63cf\u8ff0\u4e86\u5404\u79cd\u4e8b\u4ef6\u9a71\u52a8\u7684\u6d3b\u52a8\uff0c\u8fd9\u4e9b\u6d3b\u52a8\u9700\u8981\u9ad8\u7ea7\u4e0a\u4e0b\u6587\u7406\u89e3\u624d\u80fd\u751f\u6210\u51c6\u786e\u7684\u54cd\u5e94\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b 3,000 \u4e2a\u5bf9\u8bdd\uff0c\u5176\u4e2d\u5305\u542b\u8d85\u8fc7 30,000 \u4e2a\u95ee\u7b54\u5bf9\uff0c\u8fd9\u4e9b\u5bf9\u8bdd\u6765\u81ea 1,000 \u4e2a\u5177\u6709\u4e0d\u540c\u6d3b\u52a8\u573a\u666f\u7684\u89c6\u9891\u3002\u7531\u4e8e\u5176\u5e7f\u6cdb\u7684\u6d3b\u52a8\u573a\u666f\u548c\u5e7f\u6cdb\u7684\u95ee\u9898\u7c7b\u578b\uff0cVDAct \u8868\u73b0\u51fa\u663e\u7740\u7684\u6311\u6218\u6027\u7279\u5f81\u3002\u5bf9\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7684\u5b9e\u8bc1\u7814\u7a76\u7a81\u51fa\u4e86\u5b83\u4eec\u5728\u89e3\u51b3\u6211\u4eec\u6570\u636e\u96c6\u4e2d\u7684\u67d0\u4e9b\u95ee\u9898\u7c7b\u578b\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u6b64\u5916\uff0cVDEval \u96c6\u6210\u4e86\u5bf9\u8bdd\u4f1a\u8bdd\u5386\u53f2\u8bb0\u5f55\u548c\u4ece\u6211\u4eec\u7684\u8865\u5145\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63d0\u53d6\u7684\u89c6\u9891\u5185\u5bb9\u6458\u8981\uff0c\u4ee5\u8bc4\u4f30\u5404\u4e2a\u54cd\u5e94\uff0c\u4e0e\u4ec5\u4f9d\u8d56\u4e8e\u5355\u4e2a\u5bf9\u8bdd\u8f6e\u6b21\u4e0a\u4e0b\u6587\u7684\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u76f8\u6bd4\uff0c\u5b83\u4e0e VDAct \u6570\u636e\u96c6\u4e0a\u7684\u4eba\u7c7b\u8bc4\u4f30\u5177\u6709\u663e\u7740\u66f4\u9ad8\u7684\u76f8\u5173\u6027\u3002", "author": "Wiradee Imrattanatrai et.al.", "authors": "Wiradee Imrattanatrai, Masaki Asada, Kimihiro Hasegawa, Zhi-Qi Cheng, Ken Fukuda, Teruko Mitamura", "id": "2501.18324v1", "paper_url": "http://arxiv.org/abs/2501.18324v1", "repo": "null"}}