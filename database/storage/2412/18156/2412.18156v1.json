{"2412.18156": {"publish_time": "2024-12-24", "title": "scReader: Prompting Large Language Models to Interpret scRNA-seq Data", "paper_summary": "Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u986f\u8457\u7684\u9032\u6b65\uff0c\u9019\u4e3b\u8981\u6b78\u56e0\u65bc\u5b83\u5011\u5728\u5efa\u6a21\u6587\u5b57\u5e8f\u5217\u4e2d\u96b1\u85cf\u95dc\u4fc2\u7684\u80fd\u529b\u3002\u9019\u9805\u5275\u65b0\u70ba\u751f\u547d\u79d1\u5b78\u9818\u57df\u5e36\u4f86\u4e86\u7368\u7279\u7684\u5951\u6a5f\uff0c\u5176\u4e2d\u4f86\u81ea\u591a\u500b\u7269\u7a2e\u7684\u55ae\u7d30\u80de\u7d44\u5b78\u6578\u64da\u7684\u9f90\u5927\u96c6\u5408\u70ba\u8a13\u7df4\u57fa\u790e\u6a21\u578b\u63d0\u4f9b\u4e86\u57fa\u790e\u3002\u7136\u800c\uff0c\u6311\u6230\u5728\u65bc\u4e0d\u540c\u7269\u7a2e\u4e4b\u9593\u7684\u6578\u64da\u898f\u6a21\u5dee\u7570\uff0c\u9019\u963b\u7919\u4e86\u958b\u767c\u4e00\u500b\u7528\u65bc\u89e3\u91cb\u4e0d\u540c\u751f\u7269\u9ad4\u907a\u50b3\u6578\u64da\u7684\u7d9c\u5408\u6a21\u578b\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u5275\u65b0\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5b83\u5c07 LLM \u7684\u4e00\u822c\u77e5\u8b58\u80fd\u529b\u8207\u55ae\u7d30\u80de\u7d44\u5b78\u6578\u64da\u89e3\u91cb\u7684\u7279\u5b9a\u9818\u57df\u8868\u793a\u6a21\u578b\u76f8\u7d50\u5408\u3002\u6211\u5011\u5f9e\u5c07\u57fa\u56e0\u4f5c\u70ba\u8868\u793a\u7684\u57fa\u672c\u55ae\u4f4d\u958b\u59cb\u3002\u57fa\u56e0\u8868\u793a\u662f\u4f7f\u7528\u529f\u80fd\u63cf\u8ff0\u521d\u59cb\u5316\u7684\uff0c\u5229\u7528\u4e86\u6210\u719f\u8a9e\u8a00\u6a21\u578b\uff08\u4f8b\u5982 LLaMA-2\uff09\u7684\u512a\u52e2\u3002\u901a\u904e\u4f7f\u7528\u63d0\u793a\u8f38\u5165\u55ae\u7d30\u80de\u57fa\u56e0\u5c64\u7d1a\u7684\u8868\u9054\u6578\u64da\uff0c\u6211\u5011\u6709\u6548\u5730\u6839\u64da\u4e0d\u540c\u7269\u7a2e\u548c\u7d30\u80de\u985e\u578b\u7684\u57fa\u56e0\u5dee\u7570\u8868\u9054\u5c64\u7d1a\u5c0d\u7d30\u80de\u8868\u793a\u9032\u884c\u5efa\u6a21\u3002\u5728\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u69cb\u5efa\u4e86\u4eba\u985e\u548c\u5c0f\u9f20\u7684\u767c\u80b2\u7d30\u80de\uff0c\u7279\u5225\u91dd\u5c0d\u96e3\u4ee5\u8a3b\u89e3\u7684\u7d30\u80de\u3002\u6211\u5011\u900f\u904e\u7d30\u80de\u8a3b\u89e3\u548c\u8996\u89ba\u5316\u5206\u6790\u7b49\u57fa\u672c\u4efb\u52d9\u8a55\u4f30\u4e86\u6211\u5011\u7684\u6280\u8853\u3002\u7d50\u679c\u8b49\u660e\uff0c\u8207\u4f7f\u7528 LLM \u7684\u5176\u4ed6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6280\u8853\u65b9\u6cd5\u6709\u6548\uff0c\u7a81\u986f\u4e86\u6e96\u78ba\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u7684\u986f\u8457\u6539\u9032\u3002\u6211\u5011\u7684\u6df7\u5408\u65b9\u6cd5\u589e\u5f37\u4e86\u55ae\u7d30\u80de\u6578\u64da\u7684\u8868\u793a\uff0c\u4e26\u70ba\u8de8\u7269\u7a2e\u907a\u50b3\u5206\u6790\u7684\u672a\u4f86\u7814\u7a76\u63d0\u4f9b\u4e86\u5f37\u5927\u7684\u67b6\u69cb\u3002", "author": "Cong Li et.al.", "authors": "Cong Li, Qingqing Long, Yuanchun Zhou, Meng Xiao", "id": "2412.18156v1", "paper_url": "http://arxiv.org/abs/2412.18156v1", "repo": "null"}}