{"2501.05790": {"publish_time": "2025-01-10", "title": "Understanding Impact of Human Feedback via Influence Functions", "paper_summary": "In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn\nsuitable reward models from human feedback to align large language models\n(LLMs) with human intentions. However, human feedback can often be noisy,\ninconsistent, or biased, especially when evaluating complex responses. Such\nfeedback can lead to misaligned reward signals, potentially causing unintended\nside effects during the RLHF process. To address these challenges, we explore\nthe use of influence functions to measure the impact of human feedback on the\nperformance of reward models. We propose a compute-efficient approximation\nmethod that enables the application of influence functions to LLM-based reward\nmodels and large-scale preference datasets. In our experiments, we demonstrate\ntwo key applications of influence functions: (1) detecting common forms of\nlabeler bias in human feedback datasets and (2) guiding labelers to refine\ntheir strategies to align more closely with expert feedback. By quantifying the\nimpact of human feedback on reward models, we believe that influence functions\ncan enhance feedback interpretability and contribute to scalable oversight in\nRLHF, helping labelers provide more accurate and consistent feedback. Source\ncode is available at https://github.com/mintaywon/IF_RLHF", "paper_summary_zh": "\u5728\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF) \u4e2d\uff0c\u5f9e\u4eba\u985e\u56de\u994b\u5b78\u7fd2\u5408\u9069\u7684\u734e\u52f5\u6a21\u578b\u4ee5\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u4eba\u985e\u610f\u5716\u4fdd\u6301\u4e00\u81f4\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u4eba\u985e\u56de\u994b\u901a\u5e38\u6703\u5f88\u96dc\u4e82\u3001\u4e0d\u4e00\u81f4\u6216\u6709\u504f\u898b\uff0c\u7279\u5225\u662f\u5728\u8a55\u4f30\u8907\u96dc\u56de\u61c9\u6642\u3002\u9019\u7a2e\u56de\u994b\u53ef\u80fd\u6703\u5c0e\u81f4\u734e\u52f5\u4fe1\u865f\u932f\u4f4d\uff0c\u6f5b\u5728\u6703\u5728 RLHF \u904e\u7a0b\u4e2d\u9020\u6210\u610f\u60f3\u4e0d\u5230\u7684\u526f\u4f5c\u7528\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63a2\u7d22\u4f7f\u7528\u5f71\u97ff\u51fd\u6578\u4f86\u8861\u91cf\u4eba\u985e\u56de\u994b\u5c0d\u734e\u52f5\u6a21\u578b\u6548\u80fd\u7684\u5f71\u97ff\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u904b\u7b97\u6548\u7387\u8fd1\u4f3c\u6cd5\uff0c\u8b93\u5f71\u97ff\u51fd\u6578\u80fd\u5920\u61c9\u7528\u65bc\u57fa\u65bc LLM \u7684\u734e\u52f5\u6a21\u578b\u548c\u5927\u898f\u6a21\u504f\u597d\u8cc7\u6599\u96c6\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5f71\u97ff\u51fd\u6578\u7684\u5169\u500b\u95dc\u9375\u61c9\u7528\uff1a(1) \u5075\u6e2c\u4eba\u985e\u56de\u994b\u8cc7\u6599\u96c6\u4e2d\u5e38\u898b\u7684\u6a19\u7c64\u54e1\u504f\u898b\u5f62\u5f0f\uff0c\u4ee5\u53ca (2) \u5f15\u5c0e\u6a19\u7c64\u54e1\u6539\u5584\u5176\u7b56\u7565\u4ee5\u66f4\u8cbc\u8fd1\u5c08\u5bb6\u56de\u994b\u3002\u900f\u904e\u91cf\u5316\u4eba\u985e\u56de\u994b\u5c0d\u734e\u52f5\u6a21\u578b\u7684\u5f71\u97ff\uff0c\u6211\u5011\u76f8\u4fe1\u5f71\u97ff\u51fd\u6578\u53ef\u4ee5\u589e\u5f37\u56de\u994b\u53ef\u89e3\u91cb\u6027\uff0c\u4e26\u6709\u52a9\u65bc RLHF \u4e2d\u53ef\u64f4\u5145\u7684\u76e3\u7763\uff0c\u5e6b\u52a9\u6a19\u7c64\u54e1\u63d0\u4f9b\u66f4\u6e96\u78ba\u4e14\u4e00\u81f4\u7684\u56de\u994b\u3002\u539f\u59cb\u7a0b\u5f0f\u78bc\u53ef\u65bc https://github.com/mintaywon/IF_RLHF \u53d6\u5f97", "author": "Taywon Min et.al.", "authors": "Taywon Min, Haeone Lee, Hanho Ryu, Yongchan Kwon, Kimin Lee", "id": "2501.05790v1", "paper_url": "http://arxiv.org/abs/2501.05790v1", "repo": "https://github.com/mintaywon/if_rlhf"}}