{"2412.15204": {"publish_time": "2024-12-19", "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks", "paper_summary": "This paper introduces LongBench v2, a benchmark designed to assess the\nability of LLMs to handle long-context problems requiring deep understanding\nand reasoning across real-world multitasks. LongBench v2 consists of 503\nchallenging multiple-choice questions, with contexts ranging from 8k to 2M\nwords, across six major task categories: single-document QA, multi-document QA,\nlong in-context learning, long-dialogue history understanding, code repository\nunderstanding, and long structured data understanding. To ensure the breadth\nand the practicality, we collect data from nearly 100 highly educated\nindividuals with diverse professional backgrounds. We employ both automated and\nmanual review processes to maintain high quality and difficulty, resulting in\nhuman experts achieving only 53.7% accuracy under a 15-minute time constraint.\nOur evaluation reveals that the best-performing model, when directly answers\nthe questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,\nwhich includes longer reasoning, achieves 57.7%, surpassing the human baseline\nby 4%. These results highlight the importance of enhanced reasoning ability and\nscaling inference-time compute to tackle the long-context challenges in\nLongBench v2. The project is available at https://longbench2.github.io.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39 LongBench v2\uff0c\u9019\u662f\u4e00\u500b\u57fa\u6e96\u6e2c\u8a66\uff0c\u7528\u4f86\u8a55\u4f30 LLM \u8655\u7406\u9700\u8981\u8de8\u8d8a\u771f\u5be6\u4e16\u754c\u591a\u4efb\u52d9\u9032\u884c\u6df1\u5165\u7406\u89e3\u548c\u63a8\u7406\u7684\u9577\u8108\u7d61\u554f\u984c\u7684\u80fd\u529b\u3002LongBench v2 \u5305\u542b 503 \u500b\u5177\u6709\u6311\u6230\u6027\u7684\u591a\u9078\u984c\uff0c\u8108\u7d61\u7bc4\u570d\u5f9e 8k \u5230 2M \u500b\u5b57\uff0c\u6db5\u84cb\u516d\u500b\u4e3b\u8981\u7684\u4efb\u52d9\u985e\u5225\uff1a\u55ae\u4e00\u6587\u4ef6\u554f\u7b54\u3001\u591a\u6587\u4ef6\u554f\u7b54\u3001\u9577\u8108\u7d61\u5b78\u7fd2\u3001\u9577\u5c0d\u8a71\u6b77\u7a0b\u7406\u89e3\u3001\u7a0b\u5f0f\u78bc\u5132\u5b58\u5eab\u7406\u89e3\uff0c\u4ee5\u53ca\u9577\u7d50\u69cb\u5316\u8cc7\u6599\u7406\u89e3\u3002\u70ba\u4e86\u78ba\u4fdd\u5ee3\u5ea6\u548c\u5be6\u7528\u6027\uff0c\u6211\u5011\u5f9e\u8fd1 100 \u4f4d\u53d7\u904e\u9ad8\u7b49\u6559\u80b2\u3001\u5177\u6709\u4e0d\u540c\u5c08\u696d\u80cc\u666f\u7684\u4eba\u54e1\u6536\u96c6\u8cc7\u6599\u3002\u6211\u5011\u63a1\u7528\u81ea\u52d5\u5316\u548c\u624b\u52d5\u6aa2\u95b1\u6d41\u7a0b\u4f86\u7dad\u6301\u9ad8\u54c1\u8cea\u548c\u96e3\u5ea6\uff0c\u5c0e\u81f4\u4eba\u985e\u5c08\u5bb6\u5728 15 \u5206\u9418\u7684\u6642\u9593\u9650\u5236\u4e0b\u53ea\u80fd\u9054\u5230 53.7% \u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u5728\u76f4\u63a5\u56de\u7b54\u554f\u984c\u6642\uff0c\u8868\u73fe\u6700\u4f73\u7684\u6a21\u578b\u53ea\u80fd\u9054\u5230 50.1% \u7684\u6e96\u78ba\u5ea6\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5305\u542b\u8f03\u9577\u63a8\u7406\u7684 o1-preview \u6a21\u578b\u9054\u5230 57.7%\uff0c\u6bd4\u4eba\u985e\u57fa\u6e96\u9ad8\u51fa 4%\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u986f\u4e86\u589e\u5f37\u63a8\u7406\u80fd\u529b\u548c\u64f4\u5145\u63a8\u8ad6\u6642\u9593\u904b\u7b97\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u61c9\u5c0d LongBench v2 \u4e2d\u7684\u9577\u8108\u7d61\u6311\u6230\u3002\u6b64\u5c08\u6848\u53ef\u5728 https://longbench2.github.io/ \u53d6\u5f97\u3002", "author": "Yushi Bai et.al.", "authors": "Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li", "id": "2412.15204v1", "paper_url": "http://arxiv.org/abs/2412.15204v1", "repo": "null"}}