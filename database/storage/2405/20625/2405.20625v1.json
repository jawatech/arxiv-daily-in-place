{"2405.20625": {"publish_time": "2024-05-31", "title": "Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning", "paper_summary": "As the applicability of Large Language Models (LLMs) extends beyond\ntraditional text processing tasks, there is a burgeoning interest in their\npotential to excel in planning and reasoning assignments, realms traditionally\nreserved for System 2 cognitive competencies. Despite their perceived\nversatility, the research community is still unraveling effective strategies to\nharness these models in such complex domains. The recent discourse introduced\nby the paper on LLM Modulo marks a significant stride, proposing a conceptual\nframework that enhances the integration of LLMs into diverse planning and\nreasoning activities. This workshop paper delves into the practical application\nof this framework within the domain of travel planning, presenting a specific\ninstance of its implementation. We are using the Travel Planning benchmark by\nthe OSU NLP group, a benchmark for evaluating the performance of LLMs in\nproducing valid itineraries based on user queries presented in natural\nlanguage. While popular methods of enhancing the reasoning abilities of LLMs\nsuch as Chain of Thought, ReAct, and Reflexion achieve a meager 0%, 0.6%, and\n0% with GPT3.5-Turbo respectively, our operationalization of the LLM-Modulo\nframework for TravelPlanning domain provides a remarkable improvement,\nenhancing baseline performances by 4.6x for GPT4-Turbo and even more for older\nmodels like GPT3.5-Turbo from 0% to 5%. Furthermore, we highlight the other\nuseful roles of LLMs in the planning pipeline, as suggested in LLM-Modulo,\nwhich can be reliably operationalized such as extraction of useful critics and\nreformulator for critics.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9069\u7528\u6027\u8d85\u8d8a\u50b3\u7d71\u7684\u6587\u5b57\u8655\u7406\u4efb\u52d9\uff0c\u5b83\u5011\u5728\u898f\u5283\u548c\u63a8\u7406\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\u7684\u6f5b\u529b\u5f15\u8d77\u4e86\u6975\u5927\u7684\u8208\u8da3\uff0c\u9019\u4e9b\u9818\u57df\u50b3\u7d71\u4e0a\u662f System 2 \u8a8d\u77e5\u80fd\u529b\u7684\u5c08\u5c6c\u9818\u57df\u3002\u5118\u7ba1\u5b83\u5011\u88ab\u8a8d\u70ba\u5177\u6709\u591a\u529f\u80fd\u6027\uff0c\u4f46\u7814\u7a76\u793e\u7fa4\u4ecd\u5728\u63a2\u8a0e\u5728\u5982\u6b64\u8907\u96dc\u7684\u9818\u57df\u4e2d\u6709\u6548\u5229\u7528\u9019\u4e9b\u6a21\u578b\u7684\u7b56\u7565\u3002LLM Modulo \u8ad6\u6587\u4e2d\u6700\u8fd1\u63d0\u51fa\u7684\u8ad6\u8ff0\u6a19\u8a8c\u8457\u4e00\u500b\u91cd\u8981\u7684\u9032\u5c55\uff0c\u63d0\u51fa\u4e86\u589e\u5f37 LLM \u8207\u5404\u7a2e\u898f\u5283\u548c\u63a8\u7406\u6d3b\u52d5\u6574\u5408\u7684\u6982\u5ff5\u6846\u67b6\u3002\u9019\u7bc7\u7814\u8a0e\u6703\u8ad6\u6587\u6df1\u5165\u63a2\u8a0e\u4e86\u9019\u500b\u6846\u67b6\u5728\u65c5\u904a\u898f\u5283\u9818\u57df\u4e2d\u7684\u5be6\u969b\u61c9\u7528\uff0c\u4e26\u5c55\u793a\u4e86\u4e00\u500b\u5177\u9ad4\u7684\u5be6\u4f5c\u7bc4\u4f8b\u3002\u6211\u5011\u4f7f\u7528\u4e86\u4fc4\u4ea5\u4fc4\u5dde\u7acb\u5927\u5b78\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u5c0f\u7d44\u7684\u65c5\u904a\u898f\u5283\u57fa\u6e96\uff0c\u9019\u500b\u57fa\u6e96\u7528\u65bc\u8a55\u4f30 LLM \u5728\u6839\u64da\u4ee5\u81ea\u7136\u8a9e\u8a00\u5448\u73fe\u7684\u4f7f\u7528\u8005\u67e5\u8a62\u7522\u751f\u6709\u6548\u884c\u7a0b\u65b9\u9762\u7684\u8868\u73fe\u3002\u96d6\u7136\u589e\u5f37 LLM \u63a8\u7406\u80fd\u529b\u7684\u6d41\u884c\u65b9\u6cd5\uff0c\u4f8b\u5982\u601d\u7dad\u93c8\u3001ReAct \u548c Reflexion\uff0c\u5206\u5225\u4f7f\u7528 GPT3.5-Turbo \u9054\u5230\u4e86\u5fae\u4e0d\u8db3\u9053\u7684 0%\u30010.6% \u548c 0%\uff0c\u4f46\u6211\u5011\u5c07 LLM-Modulo \u6846\u67b6\u64cd\u4f5c\u5316\u5230\u65c5\u904a\u898f\u5283\u9818\u57df\uff0c\u63d0\u4f9b\u4e86\u986f\u8457\u7684\u6539\u9032\uff0c\u5c07 GPT4-Turbo \u7684\u57fa\u6e96\u8868\u73fe\u63d0\u5347\u4e86 4.6 \u500d\uff0c\u751a\u81f3\u5c07 GPT3.5-Turbo \u7b49\u8f03\u820a\u6a21\u578b\u5f9e 0% \u63d0\u5347\u5230 5%\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f37\u8abf\u4e86 LLM \u5728\u898f\u5283\u6d41\u7a0b\u4e2d\u5176\u4ed6\u6709\u7528\u7684\u89d2\u8272\uff0c\u6b63\u5982 LLM-Modulo \u6240\u5efa\u8b70\u7684\uff0c\u9019\u4e9b\u89d2\u8272\u53ef\u4ee5\u88ab\u53ef\u9760\u5730\u64cd\u4f5c\u5316\uff0c\u4f8b\u5982\u63d0\u53d6\u6709\u7528\u7684\u6279\u8a55\u548c\u6279\u8a55\u7684\u91cd\u65b0\u8868\u8ff0\u3002", "author": "Atharva Gundawar et.al.", "authors": "Atharva Gundawar, Mudit Verma, Lin Guan, Karthik Valmeekam, Siddhant Bhambri, Subbarao Kambhampati", "id": "2405.20625v1", "paper_url": "http://arxiv.org/abs/2405.20625v1", "repo": "null"}}