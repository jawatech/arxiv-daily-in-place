{"2407.15621": {"publish_time": "2024-07-22", "title": "RadioRAG: Factual Large Language Models for Enhanced Diagnostics in Radiology Using Dynamic Retrieval Augmented Generation", "paper_summary": "Large language models (LLMs) have advanced the field of artificial\nintelligence (AI) in medicine. However LLMs often generate outdated or\ninaccurate information based on static training datasets. Retrieval augmented\ngeneration (RAG) mitigates this by integrating outside data sources. While\nprevious RAG systems used pre-assembled, fixed databases with limited\nflexibility, we have developed Radiology RAG (RadioRAG) as an end-to-end\nframework that retrieves data from authoritative radiologic online sources in\nreal-time. RadioRAG is evaluated using a dedicated radiologic\nquestion-and-answer dataset (RadioQA). We evaluate the diagnostic accuracy of\nvarious LLMs when answering radiology-specific questions with and without\naccess to additional online information via RAG. Using 80 questions from RSNA\nCase Collection across radiologic subspecialties and 24 additional\nexpert-curated questions, for which the correct gold-standard answers were\navailable, LLMs (GPT-3.5-turbo, GPT-4, Mistral-7B, Mixtral-8x7B, and Llama3 [8B\nand 70B]) were prompted with and without RadioRAG. RadioRAG retrieved\ncontext-specific information from www.radiopaedia.org in real-time and\nincorporated them into its reply. RadioRAG consistently improved diagnostic\naccuracy across all LLMs, with relative improvements ranging from 2% to 54%. It\nmatched or exceeded question answering without RAG across radiologic\nsubspecialties, particularly in breast imaging and emergency radiology.\nHowever, degree of improvement varied among models; GPT-3.5-turbo and\nMixtral-8x7B-instruct-v0.1 saw notable gains, while Mistral-7B-instruct-v0.2\nshowed no improvement, highlighting variability in its effectiveness. LLMs\nbenefit when provided access to domain-specific data beyond their training\ndata. For radiology, RadioRAG establishes a robust framework that substantially\nimproves diagnostic accuracy and factuality in radiological question answering.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63d0\u5347\u4e86\u4eba\u5de5\u667a\u6167 (AI) \u5728\u91ab\u5b78\u9818\u57df\u7684\u9032\u5c55\u3002\u7136\u800c\uff0cLLM \u7d93\u5e38\u6839\u64da\u975c\u614b\u8a13\u7df4\u8cc7\u6599\u96c6\u7522\u751f\u904e\u6642\u6216\u4e0d\u6e96\u78ba\u7684\u8cc7\u8a0a\u3002\u6aa2\u7d22\u64f4\u589e\u751f\u6210 (RAG) \u900f\u904e\u6574\u5408\u5916\u90e8\u8cc7\u6599\u4f86\u6e90\u4f86\u6e1b\u8f15\u9019\u500b\u554f\u984c\u3002\u96d6\u7136\u5148\u524d\u7684 RAG \u7cfb\u7d71\u4f7f\u7528\u9810\u5148\u7d44\u88dd\u3001\u5177\u6709\u6709\u9650\u5f48\u6027\u7684\u56fa\u5b9a\u8cc7\u6599\u5eab\uff0c\u4f46\u6211\u5011\u5df2\u958b\u767c\u653e\u5c04\u79d1 RAG (RadioRAG) \u4f5c\u70ba\u4e00\u500b\u7aef\u5c0d\u7aef\u67b6\u69cb\uff0c\u53ef\u5f9e\u6b0a\u5a01\u7684\u7dda\u4e0a\u653e\u5c04\u79d1\u4f86\u6e90\u5373\u6642\u6aa2\u7d22\u8cc7\u6599\u3002RadioRAG \u4f7f\u7528\u5c08\u9580\u7684\u653e\u5c04\u79d1\u554f\u7b54\u8cc7\u6599\u96c6 (RadioQA) \u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u8a55\u4f30\u5404\u7a2e LLM \u5728\u56de\u7b54\u653e\u5c04\u79d1\u7279\u5b9a\u554f\u984c\u6642\u7684\u8a3a\u65b7\u6e96\u78ba\u6027\uff0c\u7121\u8ad6\u662f\u5426\u900f\u904e RAG \u5b58\u53d6\u984d\u5916\u7684\u7dda\u4e0a\u8cc7\u8a0a\u3002\u4f7f\u7528\u4f86\u81ea RSNA \u6848\u4f8b\u5f59\u7de8\u7684 80 \u500b\u6db5\u84cb\u653e\u5c04\u79d1\u6b21\u5c08\u79d1\u7684\u554f\u984c\u548c 24 \u500b\u984d\u5916\u7684\u5c08\u5bb6\u7b56\u5283\u554f\u984c\uff08\u6709\u6b63\u78ba\u7684\u91d1\u6a19\u6e96\u7b54\u6848\uff09\uff0c\u63d0\u793a LLM\uff08GPT-3.5-turbo\u3001GPT-4\u3001Mistral-7B\u3001Mixtral-8x7B \u548c Llama3 [8B \u548c 70B]\uff09\uff0c\u7121\u8ad6\u662f\u5426\u4f7f\u7528 RadioRAG\u3002RadioRAG \u5f9e www.radiopaedia.org \u5373\u6642\u6aa2\u7d22\u7279\u5b9a\u65bc\u8108\u7d61\u7684\u8cc7\u8a0a\uff0c\u4e26\u5c07\u5176\u7d0d\u5165\u56de\u8986\u4e2d\u3002RadioRAG \u6301\u7e8c\u6539\u5584\u6240\u6709 LLM \u7684\u8a3a\u65b7\u6e96\u78ba\u6027\uff0c\u76f8\u5c0d\u6539\u5584\u5e45\u5ea6\u5f9e 2% \u5230 54%\u3002\u5b83\u5728\u653e\u5c04\u79d1\u6b21\u5c08\u79d1\u4e2d\u9054\u5230\u6216\u8d85\u904e\u6c92\u6709 RAG \u7684\u554f\u7b54\u6e96\u78ba\u6027\uff0c\u7279\u5225\u662f\u5728\u4e73\u623f\u5f71\u50cf\u548c\u6025\u8a3a\u653e\u5c04\u79d1\u4e2d\u3002\u7136\u800c\uff0c\u4e0d\u540c\u6a21\u578b\u4e4b\u9593\u7684\u6539\u5584\u7a0b\u5ea6\u6709\u6240\u4e0d\u540c\uff1bGPT-3.5-turbo \u548c Mixtral-8x7B-instruct-v0.1 \u6709\u986f\u8457\u7684\u9032\u6b65\uff0c\u800c Mistral-7B-instruct-v0.2 \u6c92\u6709\u6539\u5584\uff0c\u7a81\u986f\u5176\u6709\u6548\u6027\u7684\u8b8a\u7570\u6027\u3002LLM \u5728\u7372\u5f97\u8d85\u51fa\u5176\u8a13\u7df4\u8cc7\u6599\u7684\u7279\u5b9a\u9818\u57df\u8cc7\u6599\u6642\u6703\u53d7\u76ca\u3002\u5c0d\u65bc\u653e\u5c04\u79d1\uff0cRadioRAG \u5efa\u7acb\u4e86\u4e00\u500b\u5f37\u5927\u7684\u67b6\u69cb\uff0c\u53ef\u5927\u5e45\u6539\u5584\u653e\u5c04\u79d1\u554f\u7b54\u4e2d\u7684\u8a3a\u65b7\u6e96\u78ba\u6027\u548c\u771f\u5be6\u6027\u3002", "author": "Soroosh Tayebi Arasteh et.al.", "authors": "Soroosh Tayebi Arasteh, Mahshad Lotfinia, Keno Bressem, Robert Siepmann, Dyke Ferber, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn", "id": "2407.15621v1", "paper_url": "http://arxiv.org/abs/2407.15621v1", "repo": "null"}}