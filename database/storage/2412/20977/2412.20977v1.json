{"2412.20977": {"publish_time": "2024-12-30", "title": "UnrealZoo: Enriching Photo-realistic Virtual Worlds for Embodied AI", "paper_summary": "We introduce UnrealZoo, a rich collection of photo-realistic 3D virtual\nworlds built on Unreal Engine, designed to reflect the complexity and\nvariability of the open worlds. Additionally, we offer a variety of playable\nentities for embodied AI agents. Based on UnrealCV, we provide a suite of\neasy-to-use Python APIs and tools for various potential applications, such as\ndata collection, environment augmentation, distributed training, and\nbenchmarking. We optimize the rendering and communication efficiency of\nUnrealCV to support advanced applications, such as multi-agent interaction. Our\nexperiments benchmark agents in various complex scenes, focusing on visual\nnavigation and tracking, which are fundamental capabilities for embodied visual\nintelligence. The results yield valuable insights into the advantages of\ndiverse training environments for reinforcement learning (RL) agents and the\nchallenges faced by current embodied vision agents, including those based on RL\nand large vision-language models (VLMs), in open worlds. These challenges\ninvolve latency in closed-loop control in dynamic scenes and reasoning about 3D\nspatial structures in unstructured terrain.", "paper_summary_zh": "\u6211\u5011\u4ecb\u7d39 UnrealZoo\uff0c\u9019\u662f\u5efa\u7acb\u5728 Unreal Engine \u4e0a\u7684\u4e00\u7cfb\u5217\u8c50\u5bcc\u7684\u5beb\u5be6 3D \u865b\u64ec\u4e16\u754c\uff0c\u65e8\u5728\u53cd\u6620\u958b\u653e\u4e16\u754c\u7684\u8907\u96dc\u6027\u548c\u53ef\u8b8a\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u63d0\u4f9b\u5404\u7a2e\u53ef\u73a9\u5be6\u9ad4\uff0c\u4f9b\u5177\u8eab AI \u4ee3\u7406\u4f7f\u7528\u3002\u57fa\u65bc UnrealCV\uff0c\u6211\u5011\u63d0\u4f9b\u4e00\u7cfb\u5217\u6613\u65bc\u4f7f\u7528\u7684 Python API \u548c\u5de5\u5177\uff0c\u9069\u7528\u65bc\u5404\u7a2e\u6f5b\u5728\u61c9\u7528\uff0c\u4f8b\u5982\u6578\u64da\u6536\u96c6\u3001\u74b0\u5883\u64f4\u5145\u3001\u5206\u6563\u5f0f\u8a13\u7df4\u548c\u57fa\u6e96\u6e2c\u8a66\u3002\u6211\u5011\u6700\u4f73\u5316 UnrealCV \u7684\u6e32\u67d3\u548c\u901a\u8a0a\u6548\u7387\uff0c\u4ee5\u652f\u63f4\u9032\u968e\u61c9\u7528\uff0c\u4f8b\u5982\u591a\u91cd\u4ee3\u7406\u4e92\u52d5\u3002\u6211\u5011\u7684\u5be6\u9a57\u5728\u5404\u7a2e\u8907\u96dc\u5834\u666f\u4e2d\u5c0d\u4ee3\u7406\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\uff0c\u5c08\u6ce8\u65bc\u8996\u89ba\u5c0e\u822a\u548c\u8ffd\u8e64\uff0c\u9019\u662f\u5177\u8eab\u8996\u89ba\u667a\u6167\u7684\u57fa\u672c\u80fd\u529b\u3002\u7d50\u679c\u5c0d\u5f37\u5316\u5b78\u7fd2 (RL) \u4ee3\u7406\u7684\u4e0d\u540c\u8a13\u7df4\u74b0\u5883\u7684\u512a\u52e2\u4ee5\u53ca\u7576\u524d\u5177\u8eab\u8996\u89ba\u4ee3\u7406\uff08\u5305\u62ec\u57fa\u65bc RL \u548c\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u4ee3\u7406\uff09\u5728\u958b\u653e\u4e16\u754c\u4e2d\u6240\u9762\u81e8\u7684\u6311\u6230\uff0c\u7522\u751f\u4e86\u6709\u50f9\u503c\u7684\u898b\u89e3\u3002\u9019\u4e9b\u6311\u6230\u6d89\u53ca\u52d5\u614b\u5834\u666f\u4e2d\u9589\u74b0\u63a7\u5236\u7684\u5ef6\u9072\uff0c\u4ee5\u53ca\u5c0d\u975e\u7d50\u69cb\u5316\u5730\u5f62\u4e2d 3D \u7a7a\u9593\u7d50\u69cb\u7684\u63a8\u7406\u3002", "author": "Fangwei Zhong et.al.", "authors": "Fangwei Zhong, Kui Wu, Churan Wang, Hao Chen, Hai Ci, Zhoujun Li, Yizhou Wang", "id": "2412.20977v1", "paper_url": "http://arxiv.org/abs/2412.20977v1", "repo": "null"}}