{"2411.02788": {"publish_time": "2024-11-05", "title": "When to Localize? A Risk-Constrained Reinforcement Learning Approach", "paper_summary": "In a standard navigation pipeline, a robot localizes at every time step to\nlower navigational errors. However, in some scenarios, a robot needs to\nselectively localize when it is expensive to obtain observations. For example,\nan underwater robot surfacing to localize too often hinders it from searching\nfor critical items underwater, such as black boxes from crashed aircraft. On\nthe other hand, if the robot never localizes, poor state estimates cause\nfailure to find the items due to inadvertently leaving the search area or\nentering hazardous, restricted areas. Motivated by these scenarios, we\ninvestigate approaches to help a robot determine \"when to localize?\" We\nformulate this as a bi-criteria optimization problem: minimize the number of\nlocalization actions while ensuring the probability of failure (due to\ncollision or not reaching a desired goal) remains bounded. In recent work, we\nshowed how to formulate this active localization problem as a constrained\nPartially Observable Markov Decision Process (POMDP), which was solved using an\nonline POMDP solver. However, this approach is too slow and requires full\nknowledge of the robot transition and observation models. In this paper, we\npresent RiskRL, a constrained Reinforcement Learning (RL) framework that\novercomes these limitations. RiskRL uses particle filtering and recurrent Soft\nActor-Critic network to learn a policy that minimizes the number of\nlocalizations while ensuring the probability of failure constraint is met. Our\nnumerical experiments show that RiskRL learns a robust policy that outperforms\nthe baseline by at least 13% while also generalizing to unseen environments.", "paper_summary_zh": "\u5728\u6a19\u6e96\u5c0e\u822a\u7ba1\u7dda\u4e2d\uff0c\u6a5f\u5668\u4eba\u5728\u6bcf\u500b\u6642\u9593\u6b65\u9a5f\u9032\u884c\u5b9a\u4f4d\u4ee5\u964d\u4f4e\u5c0e\u822a\u932f\u8aa4\u3002\u7136\u800c\uff0c\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\uff0c\u6a5f\u5668\u4eba\u5728\u53d6\u5f97\u89c0\u6e2c\u503c\u6210\u672c\u904e\u9ad8\u6642\uff0c\u9700\u8981\u9078\u64c7\u6027\u5b9a\u4f4d\u3002\u4f8b\u5982\uff0c\u6c34\u4e0b\u6a5f\u5668\u4eba\u904e\u65bc\u983b\u7e41\u5730\u6d6e\u51fa\u6c34\u9762\u9032\u884c\u5b9a\u4f4d\uff0c\u6703\u59a8\u7919\u5b83\u5728\u6c34\u4e0b\u5c0b\u627e\u95dc\u9375\u7269\u54c1\uff0c\u4f8b\u5982\u589c\u6bc0\u98db\u6a5f\u7684\u9ed1\u76d2\u5b50\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5982\u679c\u6a5f\u5668\u4eba\u5f9e\u672a\u9032\u884c\u5b9a\u4f4d\uff0c\u5247\u72c0\u614b\u4f30\u8a08\u4e0d\u4f73\u6703\u5c0e\u81f4\u7121\u6cd5\u627e\u5230\u7269\u54c1\uff0c\u56e0\u70ba\u5b83\u6703\u7121\u610f\u9593\u96e2\u958b\u641c\u5c0b\u5340\u57df\u6216\u9032\u5165\u5371\u96aa\u7684\u53d7\u9650\u5340\u57df\u3002\u53d7\u5230\u9019\u4e9b\u60c5\u6cc1\u7684\u555f\u767c\uff0c\u6211\u5011\u7814\u7a76\u4e86\u5e6b\u52a9\u6a5f\u5668\u4eba\u78ba\u5b9a\u300c\u4f55\u6642\u5b9a\u4f4d\u300d\u7684\u65b9\u6cd5\u3002\u6211\u5011\u5c07\u6b64\u8868\u8ff0\u70ba\u96d9\u6e96\u5247\u6700\u4f73\u5316\u554f\u984c\uff1a\u6700\u5c0f\u5316\u5b9a\u4f4d\u52d5\u4f5c\u7684\u6b21\u6578\uff0c\u540c\u6642\u78ba\u4fdd\u5931\u6557\u7684\u6a5f\u7387\uff08\u7531\u65bc\u78b0\u649e\u6216\u672a\u9054\u5230\u9810\u671f\u76ee\u6a19\uff09\u4fdd\u6301\u5728\u6709\u754c\u9650\u7684\u72c0\u614b\u3002\u5728\u6700\u8fd1\u7684\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5982\u4f55\u5c07\u6b64\u4e3b\u52d5\u5b9a\u4f4d\u554f\u984c\u8868\u8ff0\u70ba\u53d7\u9650\u90e8\u5206\u53ef\u89c0\u5bdf\u99ac\u53ef\u592b\u6c7a\u7b56\u904e\u7a0b (POMDP)\uff0c\u4e26\u4f7f\u7528\u7dda\u4e0a POMDP \u6c42\u89e3\u5668\u6c42\u89e3\u3002\u7136\u800c\uff0c\u6b64\u65b9\u6cd5\u592a\u6162\uff0c\u4e14\u9700\u8981\u6a5f\u5668\u4eba\u8f49\u63db\u548c\u89c0\u6e2c\u6a21\u578b\u7684\u5b8c\u6574\u77e5\u8b58\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 RiskRL\uff0c\u9019\u662f\u4e00\u500b\u53d7\u9650\u5f37\u5316\u5b78\u7fd2 (RL) \u67b6\u69cb\uff0c\u514b\u670d\u4e86\u9019\u4e9b\u9650\u5236\u3002RiskRL \u4f7f\u7528\u7c92\u5b50\u6ffe\u6ce2\u548c\u905e\u8ff4\u8edf\u6027\u52d5\u4f5c-\u8a55\u8ad6\u5bb6\u7db2\u8def\uff0c\u4f86\u5b78\u7fd2\u4e00\u7a2e\u7b56\u7565\uff0c\u4ee5\u6700\u5c0f\u5316\u5b9a\u4f4d\u6b21\u6578\uff0c\u540c\u6642\u78ba\u4fdd\u6eff\u8db3\u5931\u6557\u6a5f\u7387\u9650\u5236\u3002\u6211\u5011\u7684\u6578\u503c\u5be6\u9a57\u8868\u660e\uff0cRiskRL \u5b78\u7fd2\u5230\u4e00\u7a2e\u7a69\u5065\u7684\u7b56\u7565\uff0c\u5176\u6548\u80fd\u81f3\u5c11\u6bd4\u57fa\u6e96\u9ad8\u51fa 13%\uff0c\u540c\u6642\u4e5f\u80fd\u6cdb\u5316\u5230\u672a\u898b\u904e\u7684\u74b0\u5883\u3002", "author": "Chak Lam Shek et.al.", "authors": "Chak Lam Shek, Kasra Torshizi, Troi Williams, Pratap Tokekar", "id": "2411.02788v1", "paper_url": "http://arxiv.org/abs/2411.02788v1", "repo": "null"}}