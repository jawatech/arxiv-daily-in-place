{"2411.00830": {"publish_time": "2024-10-29", "title": "Unsupervised Training of a Dynamic Context-Aware Deep Denoising Framework for Low-Dose Fluoroscopic Imaging", "paper_summary": "Fluoroscopy is critical for real-time X-ray visualization in medical imaging.\nHowever, low-dose images are compromised by noise, potentially affecting\ndiagnostic accuracy. Noise reduction is crucial for maintaining image quality,\nespecially given such challenges as motion artifacts and the limited\navailability of clean data in medical imaging. To address these issues, we\npropose an unsupervised training framework for dynamic context-aware denoising\nof fluoroscopy image sequences. First, we train the multi-scale recurrent\nattention U-Net (MSR2AU-Net) without requiring clean data to address the\ninitial noise. Second, we incorporate a knowledge distillation-based\nuncorrelated noise suppression module and a recursive filtering-based\ncorrelated noise suppression module enhanced with motion compensation to\nfurther improve motion compensation and achieve superior denoising performance.\nFinally, we introduce a novel approach by combining these modules with a\npixel-wise dynamic object motion cross-fusion matrix, designed to adapt to\nmotion, and an edge-preserving loss for precise detail retention. To validate\nthe proposed method, we conducted extensive numerical experiments on medical\nimage datasets, including 3500 fluoroscopy images from dynamic phantoms (2,400\nimages for training, 1,100 for testing) and 350 clinical images from a spinal\nsurgery patient. Moreover, we demonstrated the robustness of our approach\nacross different imaging modalities by testing it on the publicly available\n2016 Low Dose CT Grand Challenge dataset, using 4,800 images for training and\n1,136 for testing. The results demonstrate that the proposed approach\noutperforms state-of-the-art unsupervised algorithms in both visual quality and\nquantitative evaluation while achieving comparable performance to\nwell-established supervised learning methods across low-dose fluoroscopy and CT\nimaging.", "paper_summary_zh": "<paragraph>\u87a2\u5149\u900f\u8996\u5c0d\u65bc\u91ab\u5b78\u5f71\u50cf\u4e2d\u7684\u5373\u6642 X \u5149\u8996\u89ba\u5316\u81f3\u95dc\u91cd\u8981\u3002\n\u7136\u800c\uff0c\u4f4e\u5291\u91cf\u5f71\u50cf\u6703\u53d7\u5230\u96dc\u8a0a\u5f71\u97ff\uff0c\u53ef\u80fd\u5f71\u97ff\u8a3a\u65b7\u6e96\u78ba\u6027\u3002\u96dc\u8a0a\u6291\u5236\u5c0d\u65bc\u7dad\u6301\u5f71\u50cf\u54c1\u8cea\u81f3\u95dc\u91cd\u8981\uff0c\u7279\u5225\u662f\u5728\u91ab\u5b78\u5f71\u50cf\u4e2d\u5b58\u5728\u904b\u52d5\u507d\u5f71\u548c\u4e7e\u6de8\u8cc7\u6599\u6709\u9650\u7b49\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7121\u76e3\u7763\u8a13\u7df4\u67b6\u69cb\uff0c\u7528\u65bc\u87a2\u5149\u900f\u8996\u5f71\u50cf\u5e8f\u5217\u7684\u52d5\u614b\u60c5\u5883\u611f\u77e5\u53bb\u96dc\u8a0a\u3002\u9996\u5148\uff0c\u6211\u5011\u8a13\u7df4\u591a\u5c3a\u5ea6\u905e\u8ff4\u6ce8\u610f\u529b U-Net (MSR2AU-Net)\uff0c\u7121\u9700\u4e7e\u6de8\u8cc7\u6599\u5373\u53ef\u8655\u7406\u521d\u59cb\u96dc\u8a0a\u3002\u5176\u6b21\uff0c\u6211\u5011\u7d50\u5408\u4e86\u4e00\u500b\u57fa\u65bc\u77e5\u8b58\u84b8\u993e\u7684\u975e\u76f8\u95dc\u96dc\u8a0a\u6291\u5236\u6a21\u7d44\u548c\u4e00\u500b\u57fa\u65bc\u905e\u8ff4\u6ffe\u6ce2\u7684\u76f8\u95dc\u96dc\u8a0a\u6291\u5236\u6a21\u7d44\uff0c\u4e26\u589e\u5f37\u4e86\u904b\u52d5\u88dc\u511f\uff0c\u4ee5\u9032\u4e00\u6b65\u6539\u5584\u904b\u52d5\u88dc\u511f\u4e26\u5be6\u73fe\u5353\u8d8a\u7684\u53bb\u96dc\u8a0a\u6548\u80fd\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5c07\u9019\u4e9b\u6a21\u7d44\u8207\u9010\u50cf\u7d20\u52d5\u614b\u7269\u4ef6\u904b\u52d5\u4ea4\u53c9\u878d\u5408\u77e9\u9663\u7d50\u5408\u8d77\u4f86\uff0c\u8a72\u77e9\u9663\u65e8\u5728\u9069\u61c9\u904b\u52d5\uff0c\u4e26\u63a1\u7528\u908a\u7de3\u4fdd\u7559\u640d\u5931\u4ee5\u7cbe\u78ba\u4fdd\u7559\u7d30\u7bc0\u3002\u70ba\u4e86\u9a57\u8b49\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u6211\u5011\u5c0d\u91ab\u5b78\u5f71\u50cf\u8cc7\u6599\u96c6\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u6578\u503c\u5be6\u9a57\uff0c\u5305\u62ec\u4f86\u81ea\u52d5\u614b\u6a21\u64ec\u4eba\u9ad4\u7684 3500 \u5f35\u87a2\u5149\u900f\u8996\u5f71\u50cf\uff082,400 \u5f35\u7528\u65bc\u8a13\u7df4\uff0c1,100 \u5f35\u7528\u65bc\u6e2c\u8a66\uff09\u548c\u4f86\u81ea\u810a\u690e\u624b\u8853\u60a3\u8005\u7684 350 \u5f35\u81e8\u5e8a\u5f71\u50cf\u3002\u6b64\u5916\uff0c\u6211\u5011\u900f\u904e\u5728\u516c\u958b\u7684 2016 \u5e74\u4f4e\u5291\u91cf CT \u5927\u6311\u6230\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u6e2c\u8a66\uff0c\u4f7f\u7528 4,800 \u5f35\u5f71\u50cf\u9032\u884c\u8a13\u7df4\u548c 1,136 \u5f35\u9032\u884c\u6e2c\u8a66\uff0c\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u5f71\u50cf\u6a21\u5f0f\u4e0b\u7684\u7a69\u5065\u6027\u3002\u7d50\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8996\u89ba\u54c1\u8cea\u548c\u91cf\u5316\u8a55\u4f30\u4e2d\u90fd\u512a\u65bc\u6700\u5148\u9032\u7684\u7121\u76e3\u7763\u6f14\u7b97\u6cd5\uff0c\u540c\u6642\u5728\u4f4e\u5291\u91cf\u87a2\u5149\u900f\u8996\u548c CT \u5f71\u50cf\u4e2d\u5be6\u73fe\u4e86\u8207\u5b8c\u5584\u7684\u76e3\u7763\u5f0f\u5b78\u7fd2\u65b9\u6cd5\u76f8\u7576\u7684\u6548\u80fd\u3002</paragraph>", "author": "Sun-Young Jeon et.al.", "authors": "Sun-Young Jeon, Sen Wang, Adam S. Wang, Garry E. Gold, Jang-Hwan Choi", "id": "2411.00830v1", "paper_url": "http://arxiv.org/abs/2411.00830v1", "repo": "null"}}