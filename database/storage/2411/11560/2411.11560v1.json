{"2411.11560": {"publish_time": "2024-11-18", "title": "Topology-aware Preemptive Scheduling for Co-located LLM Workloads", "paper_summary": "Hosting diverse large language model workloads in a unified resource pool\nthrough co-location is cost-effective. For example, long-running chat services\ngenerally follow diurnal traffic patterns, which inspire co-location of batch\njobs to fulfill resource valleys between successive peaks, and thus to saturate\nresource allocation in cluster-wide scope. These heterogeneous workloads often\nhave different business priorities, and therefore preemption can be leveraged\nfor resource elasticity. However, workloads often have distinct topology\npreferences as well. The resources released by lower-priority instances may\nfail to meet the requirements of high-priority online services which are\nusually latency-sensitive. The root cause behind such mis-match is a lack of\ntopology awareness of resource scheduler, especially during preemption. To\nbridge this gap, we develop a fine-grained topology-aware method for preemptive\nscheduling of hybrid workloads. The method ensures that the resources freed by\npreempted tasks adhere to the topological affinity needs of high-priority\npreemptors in a guaranteed or best-effort manner. This dynamic alignment\nsignificantly increases the efficiency of preemption and improves overall\nscheduled performance for LLM workloads by $55\\%$.", "paper_summary_zh": "\u5c07\u5404\u7a2e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5de5\u4f5c\u8ca0\u8f09\u900f\u904e\u5171\u7f6e\u65bc\u7d71\u4e00\u7684\u8cc7\u6e90\u6c60\u4e2d\u9032\u884c\u8a17\u7ba1\uff0c\u9019\u662f\u4e00\u7a2e\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u505a\u6cd5\u3002\u4f8b\u5982\uff0c\u9577\u6642\u9593\u57f7\u884c\u7684\u804a\u5929\u670d\u52d9\u901a\u5e38\u9075\u5faa\u665d\u591c\u6d41\u91cf\u6a21\u5f0f\uff0c\u9019\u6703\u6fc0\u52f5\u6279\u6b21\u4f5c\u696d\u5171\u7f6e\u4ee5\u586b\u88dc\u9023\u7e8c\u9ad8\u5cf0\u4e4b\u9593\u7684\u8cc7\u6e90\u8c37\uff0c\u5f9e\u800c\u4f7f\u6574\u500b\u53e2\u96c6\u7bc4\u570d\u7684\u8cc7\u6e90\u914d\u7f6e\u98fd\u548c\u3002\u9019\u4e9b\u7570\u8cea\u5de5\u4f5c\u8ca0\u8f09\u901a\u5e38\u5177\u6709\u4e0d\u540c\u7684\u696d\u52d9\u512a\u5148\u9806\u5e8f\uff0c\u56e0\u6b64\u53ef\u4ee5\u5229\u7528\u6436\u5360\u4f86\u63d0\u9ad8\u8cc7\u6e90\u5f48\u6027\u3002\u7136\u800c\uff0c\u5de5\u4f5c\u8ca0\u8f09\u901a\u5e38\u4e5f\u6709\u4e0d\u540c\u7684\u62d3\u64b2\u504f\u597d\u3002\u4f4e\u512a\u5148\u9806\u5e8f\u5be6\u4f8b\u91cb\u653e\u7684\u8cc7\u6e90\u53ef\u80fd\u7121\u6cd5\u6eff\u8db3\u901a\u5e38\u5c0d\u5ef6\u9072\u5f88\u654f\u611f\u7684\u9ad8\u512a\u5148\u9806\u5e8f\u7dda\u4e0a\u670d\u52d9\u7684\u9700\u6c42\u3002\u9019\u7a2e\u4e0d\u5339\u914d\u80cc\u5f8c\u7684\u4e3b\u8981\u539f\u56e0\u662f\u8cc7\u6e90\u6392\u7a0b\u5668\u7f3a\u4e4f\u62d3\u64b2\u611f\u77e5\uff0c\u7279\u5225\u662f\u5728\u6436\u5360\u671f\u9593\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u7d30\u7dfb\u7684\u62d3\u64b2\u611f\u77e5\u65b9\u6cd5\uff0c\u7528\u65bc\u6df7\u5408\u5de5\u4f5c\u8ca0\u8f09\u7684\u6436\u5360\u5f0f\u6392\u7a0b\u3002\u6b64\u65b9\u6cd5\u78ba\u4fdd\u88ab\u6436\u5360\u4efb\u52d9\u91cb\u653e\u7684\u8cc7\u6e90\u4ee5\u4fdd\u8b49\u6216\u76e1\u529b\u800c\u70ba\u7684\u65b9\u5f0f\u7b26\u5408\u9ad8\u512a\u5148\u9806\u5e8f\u6436\u5360\u8005\u7684\u62d3\u64b2\u89aa\u548c\u6027\u9700\u6c42\u3002\u9019\u7a2e\u52d5\u614b\u8abf\u6574\u986f\u8457\u63d0\u9ad8\u4e86\u6436\u5360\u6548\u7387\uff0c\u4e26\u5c07 LLM \u5de5\u4f5c\u8ca0\u8f09\u7684\u6574\u9ad4\u6392\u7a0b\u6548\u80fd\u63d0\u5347\u4e86 55%\u3002", "author": "Ping Zhang et.al.", "authors": "Ping Zhang, Lei Su, Jinjie Yang, Xin Chen", "id": "2411.11560v1", "paper_url": "http://arxiv.org/abs/2411.11560v1", "repo": "null"}}