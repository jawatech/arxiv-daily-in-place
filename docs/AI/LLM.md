
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-17**|**DINO as a von Mises-Fisher mixture model**|Hariprasath Govindarajan et.al.|[2405.10939v1](http://arxiv.org/abs/2405.10939v1)|null|
|**2024-05-17**|**Observational Scaling Laws and the Predictability of Language Model Performance**|Yangjun Ruan et.al.|[2405.10938v1](http://arxiv.org/abs/2405.10938v1)|null|
|**2024-05-17**|**A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers**|Kaiyu Huang et.al.|[2405.10936v1](http://arxiv.org/abs/2405.10936v1)|[link](https://github.com/kaiyuhwang/mllm-survey)|
|**2024-05-17**|**High-dimensional multiple imputation (HDMI) for partially observed confounders including natural language processing-derived auxiliary covariates**|Janick Weberpals et.al.|[2405.10925v1](http://arxiv.org/abs/2405.10925v1)|null|
|**2024-05-17**|**GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification**|D. Subhalingam et.al.|[2405.10918v1](http://arxiv.org/abs/2405.10918v1)|null|
|**2024-05-17**|**COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain**|Dimitrios P. Panagoulias et.al.|[2405.10893v1](http://arxiv.org/abs/2405.10893v1)|null|
|**2024-05-17**|**A Versatile Framework for Analyzing Galaxy Image Data by Implanting Human-in-the-loop on a Large Vision Model**|Mingxiang Fu et.al.|[2405.10890v1](http://arxiv.org/abs/2405.10890v1)|null|
|**2024-05-17**|**Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review**|Hongyi Yang et.al.|[2405.10883v1](http://arxiv.org/abs/2405.10883v1)|null|
|**2024-05-17**|**WEITS: A Wavelet-enhanced residual framework for interpretable time series forecasting**|Ziyou Guo et.al.|[2405.10877v1](http://arxiv.org/abs/2405.10877v1)|null|
|**2024-05-17**|**Tailoring Vaccine Messaging with Common-Ground Opinions**|Rickard Stureborg et.al.|[2405.10861v1](http://arxiv.org/abs/2405.10861v1)|[link](https://github.com/rickardstureborg/tailor-cgo)|
|**2024-05-17**|**ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains**|Zhaopei Huang et.al.|[2405.10860v1](http://arxiv.org/abs/2405.10860v1)|[link](https://github.com/hzp3517/ecr-chain)|
|**2024-05-17**|**The Future of Large Language Model Pre-training is Federated**|Lorenzo Sani et.al.|[2405.10853v1](http://arxiv.org/abs/2405.10853v1)|null|
|**2024-05-17**|**KernelSHAP-IQ: Weighted Least-Square Optimization for Shapley Interactions**|Fabian Fumagalli et.al.|[2405.10852v1](http://arxiv.org/abs/2405.10852v1)|null|
|**2024-05-17**|**ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios**|Markus Bayer et.al.|[2405.10808v1](http://arxiv.org/abs/2405.10808v1)|null|
|**2024-05-17**|**What should be observed for optimal reward in POMDPs?**|Alyzia-Maria Konsta et.al.|[2405.10768v1](http://arxiv.org/abs/2405.10768v1)|[link](https://github.com/alyziakonsta/optimal-observability-problem)|
|**2024-05-17**|**Evaluating Saliency Explanations in NLP by Crowdsourcing**|Xiaotian Lu et.al.|[2405.10767v1](http://arxiv.org/abs/2405.10767v1)|[link](https://github.com/xtlu/lreccoling_evaluation)|
|**2024-05-17**|**Research on Credit Risk Early Warning Model of Commercial Banks Based on Neural Network Algorithm**|Yu Cheng et.al.|[2405.10762v1](http://arxiv.org/abs/2405.10762v1)|null|
|**2024-05-17**|**Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings**|Albert Sawczyn et.al.|[2405.10745v1](http://arxiv.org/abs/2405.10745v1)|null|
|**2024-05-17**|**SBAAM! Eliminating Transcript Dependency in Automatic Subtitling**|Marco Gaido et.al.|[2405.10741v1](http://arxiv.org/abs/2405.10741v1)|[link](https://github.com/hlt-mt/subsonar)|
|**2024-05-17**|**Efficient Multimodal Large Language Models: A Survey**|Yizhang Jin et.al.|[2405.10739v1](http://arxiv.org/abs/2405.10739v1)|[link](https://github.com/lijiannuist/efficient-multimodal-llms-survey)|
|**2024-05-17**|**Feature-Adaptive and Data-Scalable In-Context Learning**|Jiahao Li et.al.|[2405.10738v1](http://arxiv.org/abs/2405.10738v1)|[link](https://github.com/jiahaozhenbang/fads-icl)|
|**2024-05-17**|**INDUS: Effective and Efficient Language Models for Scientific Applications**|Bishwaranjan Bhattacharjee et.al.|[2405.10725v1](http://arxiv.org/abs/2405.10725v1)|null|
|**2024-05-17**|**SignLLM: Sign Languages Production Large Language Models**|Sen Fang et.al.|[2405.10718v1](http://arxiv.org/abs/2405.10718v1)|null|
|**2024-05-17**|**Persian Pronoun Resolution: Leveraging Neural Networks and Language Models**|Hassan Haji Mohammadi et.al.|[2405.10714v1](http://arxiv.org/abs/2405.10714v1)|null|
|**2024-05-17**|**Development of Semantics-Based Distributed Middleware for Heterogeneous Data Integration and its Application for Drought**|A Akanbi et.al.|[2405.10713v1](http://arxiv.org/abs/2405.10713v1)|null|
|**2024-05-17**|**Empowering Prior to Court Legal Analysis: A Transparent and Accessible Dataset for Defensive Statement Classification and Interpretation**|Yannis Spyridis et.al.|[2405.10702v1](http://arxiv.org/abs/2405.10702v1)|null|
|**2024-05-17**|**SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks**|Michael Shliselberg et.al.|[2405.10700v1](http://arxiv.org/abs/2405.10700v1)|null|
|**2024-05-17**|**Revolutionizing Process Mining: A Novel Architecture for ChatGPT Integration and Enhanced User Experience through Optimized Prompt Engineering**|Mehrdad Agha Mohammad Ali Kermani et.al.|[2405.10689v1](http://arxiv.org/abs/2405.10689v1)|null|
|**2024-05-17**|**Off-the-Shelf Neural Network Architectures for Forex Time Series Prediction come at a Cost**|Theodoros Zafeiriou et.al.|[2405.10679v1](http://arxiv.org/abs/2405.10679v1)|null|
|**2024-05-17**|**Realistic Evaluation of Toxicity in Large Language Models**|Tinh Son Luong et.al.|[2405.10659v1](http://arxiv.org/abs/2405.10659v1)|null|
|**2024-05-17**|**SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation**|Ziyao Xu et.al.|[2405.10650v1](http://arxiv.org/abs/2405.10650v1)|[link](https://github.com/xzy-xzy/spor)|
|**2024-05-17**|**Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning**|Haoyue Song et.al.|[2405.10647v1](http://arxiv.org/abs/2405.10647v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-17**|**Layer-Condensed KV Cache for Efficient Inference of Large Language Models**|Haoyi Wu et.al.|[2405.10637v1](http://arxiv.org/abs/2405.10637v1)|null|
|**2024-05-17**|**Beyond static AI evaluations: advancing human interaction evaluations for LLM harms and risks**|Lujain Ibrahim et.al.|[2405.10632v1](http://arxiv.org/abs/2405.10632v1)|null|
|**2024-05-17**|**Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges**|Xiaoming Shi et.al.|[2405.10630v1](http://arxiv.org/abs/2405.10630v1)|null|
|**2024-05-17**|**Dynamic data sampler for cross-language transfer learning in large language models**|Yudong Li et.al.|[2405.10626v1](http://arxiv.org/abs/2405.10626v1)|[link](https://github.com/cvi-szu/linly)|
|**2024-05-17**|**Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction**|Jiayun Pang et.al.|[2405.10625v1](http://arxiv.org/abs/2405.10625v1)|null|
|**2024-05-17**|**Historically Relevant Event Structuring for Temporal Knowledge Graph Reasoning**|Jinchuan Zhang et.al.|[2405.10621v1](http://arxiv.org/abs/2405.10621v1)|null|
|**2024-05-17**|**MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains**|Zhaohuan Zhan et.al.|[2405.10620v1](http://arxiv.org/abs/2405.10620v1)|null|
|**2024-05-17**|**Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization**|Yixin Ji et.al.|[2405.10616v1](http://arxiv.org/abs/2405.10616v1)|[link](https://github.com/dereck0602/bolaco)|
|**2024-05-17**|**A Certified Proof Checker for Deep Neural Network Verification**|Remi Desmartin et.al.|[2405.10611v1](http://arxiv.org/abs/2405.10611v1)|null|
|**2024-05-17**|**ECATS: Explainable-by-design concept-based anomaly detection for time series**|Irene Ferfoglia et.al.|[2405.10608v1](http://arxiv.org/abs/2405.10608v1)|null|
|**2024-05-17**|**UniCL: A Universal Contrastive Learning Framework for Large Time Series Models**|Jiawei Li et.al.|[2405.10597v1](http://arxiv.org/abs/2405.10597v1)|null|
|**2024-05-17**|**Improving Point-based Crowd Counting and Localization Based on Auxiliary Point Guidance**|I-Hsiang Chen et.al.|[2405.10589v1](http://arxiv.org/abs/2405.10589v1)|null|
|**2024-05-17**|**RDRec: Rationale Distillation for LLM-based Recommendation**|Xinfeng Wang et.al.|[2405.10587v1](http://arxiv.org/abs/2405.10587v1)|[link](https://github.com/wangxfng/rdrec)|
|**2024-05-17**|**A Hybrid Deep Learning Framework for Stock Price Prediction Considering the Investor Sentiment of Online Forum Enhanced by Popularity**|Huiyu Li et.al.|[2405.10584v1](http://arxiv.org/abs/2405.10584v1)|null|
|**2024-05-17**|**Future Aware Safe Active Learning of Time Varying Systems using Gaussian Processes**|Markus Lange-Hegermann et.al.|[2405.10581v1](http://arxiv.org/abs/2405.10581v1)|null|
|**2024-05-17**|**A Hard Nut to Crack: Idiom Detection with Conversational Large Language Models**|Francesca De Luca Fornaciari et.al.|[2405.10579v1](http://arxiv.org/abs/2405.10579v1)|null|
|**2024-05-17**|**Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks**|Anwoy Chatterjee et.al.|[2405.10548v1](http://arxiv.org/abs/2405.10548v1)|null|
|**2024-05-17**|**Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset**|Jie Zhu et.al.|[2405.10542v1](http://arxiv.org/abs/2405.10542v1)|[link](https://github.com/aliyun/cflue)|
|**2024-05-17**|**Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors**|Jiachen Sun et.al.|[2405.10529v1](http://arxiv.org/abs/2405.10529v1)|null|
|**2024-05-17**|**Smart Expert System: Large Language Models as Text Classifiers**|Zhiqiang Wang et.al.|[2405.10523v1](http://arxiv.org/abs/2405.10523v1)|[link](https://github.com/yeyimilk/llm-zero-shot-classifiers)|
|**2024-05-17**|**Towards Better Question Generation in QA-Based Event Extraction**|Zijin Hong et.al.|[2405.10517v1](http://arxiv.org/abs/2405.10517v1)|null|
|**2024-05-17**|**Language Models can Evaluate Themselves via Probability Discrepancy**|Tingyu Xia et.al.|[2405.10516v1](http://arxiv.org/abs/2405.10516v1)|[link](https://github.com/xiatingyu/probdiff)|
|**2024-05-17**|**SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge**|Bo Wu et.al.|[2405.10497v1](http://arxiv.org/abs/2405.10497v1)|null|
|**2024-05-17**|**Automatic News Generation and Fact-Checking System Based on Language Processing**|Xirui Peng et.al.|[2405.10492v1](http://arxiv.org/abs/2405.10492v1)|null|
|**2024-05-17**|**CNER: A tool Classifier of Named-Entity Relationships**|Jefferson A. Peña Torres et.al.|[2405.10485v1](http://arxiv.org/abs/2405.10485v1)|null|
|**2024-05-17**|**Multi-Evidence based Fact Verification via A Confidential Graph Neural Network**|Yuqing Lan et.al.|[2405.10481v1](http://arxiv.org/abs/2405.10481v1)|null|
|**2024-05-17**|**Analysis, Modeling and Design of Personalized Digital Learning Environment**|Sanjaya Khanal et.al.|[2405.10476v1](http://arxiv.org/abs/2405.10476v1)|[link](https://github.com/pli-research-d/secure-ml-with-bert)|
|**2024-05-17**|**Rethinking ChatGPT's Success: Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs' Prompting**|Xinzhe Li et.al.|[2405.10474v1](http://arxiv.org/abs/2405.10474v1)|null|
|**2024-05-16**|**Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents**|Yue Liu et.al.|[2405.10467v1](http://arxiv.org/abs/2405.10467v1)|null|
|**2024-05-16**|**Navigating Public Sentiment in the Circular Economy through Topic Modelling and Hyperparameter Optimisation**|Junhao Song et.al.|[2405.10452v1](http://arxiv.org/abs/2405.10452v1)|null|
|**2024-05-16**|**Dynamic In-context Learning with Conversational Models for Data Extraction and Materials Property Prediction**|Chinedu Ekuma et.al.|[2405.10448v1](http://arxiv.org/abs/2405.10448v1)|[link](https://github.com/gmp007/propertyextractor)|
|**2024-05-16**|**Tell me more: Intent Fulfilment Framework for Enhancing User Experiences in Conversational XAI**|Anjana Wijekoon et.al.|[2405.10446v1](http://arxiv.org/abs/2405.10446v1)|null|
|**2024-05-16**|**Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation**|Matthew Raffel et.al.|[2405.10443v1](http://arxiv.org/abs/2405.10443v1)|null|
|**2024-05-16**|**Retrieving and Refining: A Hybrid Framework with Large Language Models for Rare Disease Identification**|Jinge Wu et.al.|[2405.10440v1](http://arxiv.org/abs/2405.10440v1)|null|
|**2024-05-16**|**Positional encoding is not the same as context: A study on positional encoding for Sequential recommendation**|Alejo Lopez-Avila et.al.|[2405.10436v1](http://arxiv.org/abs/2405.10436v1)|null|
|**2024-05-16**|**Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models**|Shaz Furniturewala et.al.|[2405.10431v1](http://arxiv.org/abs/2405.10431v1)|null|
|**2024-05-16**|**Memory-efficient Energy-adaptive Inference of Pre-Trained Models on Batteryless Embedded Systems**|Pietro Farina et.al.|[2405.10426v1](http://arxiv.org/abs/2405.10426v1)|null|
|**2024-05-16**|**Vision Transformers for End-to-End Vision-Based Quadrotor Obstacle Avoidance**|Anish Bhattacharya et.al.|[2405.10391v1](http://arxiv.org/abs/2405.10391v1)|null|
|**2024-05-16**|**AmazUtah_NLP at SemEval-2024 Task 9: A MultiChoice Question Answering System for Commonsense Defying Reasoning**|Mina Ghashami et.al.|[2405.10385v1](http://arxiv.org/abs/2405.10385v1)|null|
|**2024-05-16**|**Dealing Doubt: Unveiling Threat Models in Gradient Inversion Attacks under Federated Learning, A Survey and Taxonomy**|Yichuan Shi et.al.|[2405.10376v1](http://arxiv.org/abs/2405.10376v1)|null|
|**2024-05-16**|**4D Panoptic Scene Graph Generation**|Jingkang Yang et.al.|[2405.10305v1](http://arxiv.org/abs/2405.10305v1)|[link](https://github.com/jingkang50/psg4d)|
|**2024-05-16**|**Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees**|Yu Gui et.al.|[2405.10301v1](http://arxiv.org/abs/2405.10301v1)|null|
|**2024-05-16**|**HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models**|Rhea Sanjay Sukthanker et.al.|[2405.10299v1](http://arxiv.org/abs/2405.10299v1)|[link](https://github.com/automl/hw-aware-llm-bench)|
|**2024-05-16**|**Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning**|Yuexiang Zhai et.al.|[2405.10292v2](http://arxiv.org/abs/2405.10292v2)|null|
|**2024-05-16**|**Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction**|Jianhao Chen et.al.|[2405.10288v1](http://arxiv.org/abs/2405.10288v1)|null|
|**2024-05-16**|**FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models**|Adrian Bulat et.al.|[2405.10286v1](http://arxiv.org/abs/2405.10286v1)|null|
|**2024-05-16**|**Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers**|Tuo Zhang et.al.|[2405.10276v1](http://arxiv.org/abs/2405.10276v1)|null|
|**2024-05-16**|**Faces that Speak: Jointly Synthesising Talking Face and Speech from Text**|Youngjoon Jang et.al.|[2405.10272v1](http://arxiv.org/abs/2405.10272v1)|null|
|**2024-05-16**|**Automated Federated Learning via Informed Pruning**|Christian Internò et.al.|[2405.10271v1](http://arxiv.org/abs/2405.10271v1)|[link](https://github.com/christianinterno/autoflip)|
|**2024-05-16**|**A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision**|Charles Raude et.al.|[2405.10266v1](http://arxiv.org/abs/2405.10266v1)|null|
|**2024-05-16**|**Keep It Private: Unsupervised Privatization of Online Text**|Calvin Bao et.al.|[2405.10260v1](http://arxiv.org/abs/2405.10260v1)|[link](https://github.com/csbao/kip-privatization)|
|**2024-05-16**|**A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks**|Xuanfan Ni et.al.|[2405.10251v1](http://arxiv.org/abs/2405.10251v1)|null|
|**2024-05-16**|**ENADPool: The Edge-Node Attention-based Differentiable Pooling for Graph Neural Networks**|Zhehan Zhao et.al.|[2405.10218v1](http://arxiv.org/abs/2405.10218v1)|null|
|**2024-05-16**|**Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting**|Divij Gupta et.al.|[2405.10216v1](http://arxiv.org/abs/2405.10216v1)|null|
|**2024-05-16**|**SMLP: Symbolic Machine Learning Prover (User Manual)**|Franz Brauße et.al.|[2405.10215v1](http://arxiv.org/abs/2405.10215v1)|[link](https://github.com/fbrausse/smlp)|
|**2024-05-16**|**CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations**|Jiahao Zhao et.al.|[2405.10212v1](http://arxiv.org/abs/2405.10212v1)|null|
|**2024-05-16**|**Building a Luganda Text-to-Speech Model From Crowdsourced Data**|Sulaiman Kagumire et.al.|[2405.10211v1](http://arxiv.org/abs/2405.10211v1)|null|
|**2024-05-16**|**Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level**|Chenlong Zhao et.al.|[2405.10202v1](http://arxiv.org/abs/2405.10202v1)|[link](https://github.com/molichenxi/haesum)|
|**2024-05-16**|**LFED: A Literary Fiction Evaluation Dataset for Large Language Models**|Linhao Yu et.al.|[2405.10166v1](http://arxiv.org/abs/2405.10166v1)|[link](https://github.com/tjunlp-lab/lfed)|
|**2024-05-16**|**PIR: Remote Sensing Image-Text Retrieval with Prior Instruction Representation Learning**|Jiancheng Pan et.al.|[2405.10160v1](http://arxiv.org/abs/2405.10160v1)|[link](https://github.com/jaychempan/pir-clip)|
|**2024-05-16**|**Speaker Verification in Agent-Generated Conversations**|Yizhe Yang et.al.|[2405.10150v1](http://arxiv.org/abs/2405.10150v1)|null|
|**2024-05-16**|**PL-MTEB: Polish Massive Text Embedding Benchmark**|Rafał Poświata et.al.|[2405.10138v1](http://arxiv.org/abs/2405.10138v1)|[link](https://github.com/rafalposwiata/pl-mteb)|
|**2024-05-16**|**Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language**|Togay Yazar et.al.|[2405.10133v1](http://arxiv.org/abs/2405.10133v1)|null|
|**2024-05-16**|**StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis**|Chidimma Opara et.al.|[2405.10129v1](http://arxiv.org/abs/2405.10129v1)|null|
|**2024-05-16**|**Red Teaming Language Models for Contradictory Dialogues**|Xiaofei Wen et.al.|[2405.10128v2](http://arxiv.org/abs/2405.10128v2)|null|
|**2024-05-16**|**Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource Dialogue Generation**|Bo Zhang et.al.|[2405.10121v1](http://arxiv.org/abs/2405.10121v1)|null|
|**2024-05-16**|**A novel Reservoir Architecture for Periodic Time Series Prediction**|Zhongju Yuan et.al.|[2405.10102v1](http://arxiv.org/abs/2405.10102v1)|null|

#### Abstracts
##### **DINO as a von Mises-Fisher mixture model**
2405.10939v1 by Hariprasath Govindarajan, Per Sidén, Jacob Roll, Fredrik Lindsten

Self-distillation methods using Siamese networks are popular for
self-supervised pre-training. DINO is one such method based on a cross-entropy
loss between $K$-dimensional probability vectors, obtained by applying a
softmax function to the dot product between representations and learnt
prototypes. Given the fact that the learned representations are
$L^2$-normalized, we show that DINO and its derivatives, such as iBOT, can be
interpreted as a mixture model of von Mises-Fisher components. With this
interpretation, DINO assumes equal precision for all components when the
prototypes are also $L^2$-normalized. Using this insight we propose DINO-vMF,
that adds appropriate normalization constants when computing the cluster
assignment probabilities. Unlike DINO, DINO-vMF is stable also for the larger
ViT-Base model with unnormalized prototypes. We show that the added flexibility
of the mixture model is beneficial in terms of better image representations.
The DINO-vMF pre-trained model consistently performs better than DINO on a
range of downstream tasks. We obtain similar improvements for iBOT-vMF vs iBOT
and thereby show the relevance of our proposed modification also for other
methods derived from DINO.

摘要：使用 Siamese 网络的自蒸馏方法在自我监督预训练中很流行。DINO 是一种基于 $K$ 维概率向量之间的交叉熵损失的方法，该向量是通过对表示和学习原型之间的点积应用 softmax 函数获得的。鉴于学习到的表示是 $L^2$ 归一化的，我们表明 DINO 及其派生产品，如 iBOT，可以解释为 von Mises-Fisher 分量的混合模型。通过这种解释，当原型也经过 $L^2$ 归一化时，DINO 假设所有分量的精度相等。利用这一见解，我们提出了 DINO-vMF，它在计算聚类分配概率时增加了适当的归一化常数。与 DINO 不同，DINO-vMF 对于具有未归一化原型的较大 ViT-Base 模型也稳定。我们表明，混合模型增加的灵活性在更好的图像表示方面是有益的。DINO-vMF 预训练模型在各种下游任务中始终优于 DINO。我们为 iBOT-vMF 与 iBOT 获得了类似的改进，从而表明我们提出的修改也与其他源自 DINO 的方法相关。

##### **Observational Scaling Laws and the Predictability of Language Model Performance**
2405.10938v1 by Yangjun Ruan, Chris J. Maddison, Tatsunori Hashimoto

Understanding how language model performance varies with scale is critical to
benchmark and algorithm development. Scaling laws are one approach to building
this understanding, but the requirement of training models across many
different scales has limited their use. We propose an alternative,
observational approach that bypasses model training and instead builds scaling
laws from ~80 publically available models. Building a single scaling law from
multiple model families is challenging due to large variations in their
training compute efficiencies and capabilities. However, we show that these
variations are consistent with a simple, generalized scaling law where language
model performance is a function of a low-dimensional capability space, and
model families only vary in their efficiency in converting training compute to
capabilities. Using this approach, we show the surprising predictability of
complex scaling phenomena: we show that several emergent phenomena follow a
smooth, sigmoidal behavior and are predictable from small models; we show that
the agent performance of models such as GPT-4 can be precisely predicted from
simpler non-agentic benchmarks; and we show how to predict the impact of
post-training interventions like Chain-of-Thought and Self-Consistency as
language model capabilities continue to improve.

摘要：了解语言模型性能如何随着规模而变化对于基准和算法开发至关重要。缩放定律是建立这种理解的一种方法，但跨许多不同规模训练模型的要求限制了它们的使用。我们提出了一种替代性的观察方法，它绕过了模型训练，而是从约 80 个公开可用的模型中构建缩放定律。由于训练计算效率和能力的差异很大，因此很难从多个模型系列构建一个单一的缩放定律。然而，我们表明这些变化与一个简单的、通用的缩放定律是一致的，其中语言模型性能是低维能力空间的函数，而模型系列仅在将训练计算转换为能力方面的效率上有所不同。使用这种方法，我们展示了复杂缩放现象的惊人可预测性：我们表明，几个新兴现象遵循平滑的 S 形行为，并且可以从小型模型中预测；我们表明，GPT-4 等模型的代理性能可以从更简单的非代理基准中准确预测；我们展示了如何预测像思想链和自洽性这样的后训练干预的影响，因为语言模型能力不断提高。

##### **A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers**
2405.10936v1 by Kaiyu Huang, Fengran Mo, Hongliang Li, You Li, Yuanchi Zhang, Weijian Yi, Yulong Mao, Jinchen Liu, Yuzhuang Xu, Jinan Xu, Jian-Yun Nie, Yang Liu

The rapid development of Large Language Models (LLMs) demonstrates remarkable
multilingual capabilities in natural language processing, attracting global
attention in both academia and industry. To mitigate potential discrimination
and enhance the overall usability and accessibility for diverse language user
groups, it is important for the development of language-fair technology.
Despite the breakthroughs of LLMs, the investigation into the multilingual
scenario remains insufficient, where a comprehensive survey to summarize recent
approaches, developments, limitations, and potential solutions is desirable. To
this end, we provide a survey with multiple perspectives on the utilization of
LLMs in the multilingual scenario. We first rethink the transitions between
previous and current research on pre-trained language models. Then we introduce
several perspectives on the multilingualism of LLMs, including training and
inference methods, model security, multi-domain with language culture, and
usage of datasets. We also discuss the major challenges that arise in these
aspects, along with possible solutions. Besides, we highlight future research
directions that aim at further enhancing LLMs with multilingualism. The survey
aims to help the research community address multilingual problems and provide a
comprehensive understanding of the core concepts, key techniques, and latest
developments in multilingual natural language processing based on LLMs.

摘要：大型語言模型 (LLM) 的快速發展展示了自然語言處理中顯著的多語言能力，吸引了學術界和產業界的全球關注。為了減輕潛在的歧視並增強不同語言使用者群體的整體可用性和可及性，語言公平技術的發展非常重要。儘管 LLM 取得了突破，但對多語言場景的研究仍然不足，需要進行全面的調查來總結最近的方法、發展、限制和潛在的解決方案。為此，我們提供了一項調查，對 LLM 在多語言場景中的利用提出了多種觀點。我們首先重新思考預訓練語言模型之前和當前研究之間的轉變。然後，我們介紹了 LLM 多語言的幾個觀點，包括訓練和推理方法、模型安全性、具有語言文化的多領域以及資料集的使用。我們還討論了這些方面出現的主要挑戰以及可能的解決方案。此外，我們重點介紹了旨在進一步增強具有多語言能力的 LLM 的未來研究方向。該調查旨在幫助研究社群解決多語言問題，並提供基於 LLM 的多語言自然語言處理的核心概念、關鍵技術和最新發展的全面理解。

##### **High-dimensional multiple imputation (HDMI) for partially observed confounders including natural language processing-derived auxiliary covariates**
2405.10925v1 by Janick Weberpals, Pamela A. Shaw, Kueiyu Joshua Lin, Richard Wyss, Joseph M Plasek, Li Zhou, Kerry Ngan, Thomas DeRamus, Sudha R. Raman, Bradley G. Hammill, Hana Lee, Sengwee Toh, John G. Connolly, Kimberly J. Dandreo, Fang Tian, Wei Liu, Jie Li, José J. Hernández-Muñoz, Sebastian Schneeweiss, Rishi J. Desai

Multiple imputation (MI) models can be improved by including auxiliary
covariates (AC), but their performance in high-dimensional data is not well
understood. We aimed to develop and compare high-dimensional MI (HDMI)
approaches using structured and natural language processing (NLP)-derived AC in
studies with partially observed confounders. We conducted a plasmode simulation
study using data from opioid vs. non-steroidal anti-inflammatory drug (NSAID)
initiators (X) with observed serum creatinine labs (Z2) and time-to-acute
kidney injury as outcome. We simulated 100 cohorts with a null treatment
effect, including X, Z2, atrial fibrillation (U), and 13 other
investigator-derived confounders (Z1) in the outcome generation. We then
imposed missingness (MZ2) on 50% of Z2 measurements as a function of Z2 and U
and created different HDMI candidate AC using structured and NLP-derived
features. We mimicked scenarios where U was unobserved by omitting it from all
AC candidate sets. Using LASSO, we data-adaptively selected HDMI covariates
associated with Z2 and MZ2 for MI, and with U to include in propensity score
models. The treatment effect was estimated following propensity score matching
in MI datasets and we benchmarked HDMI approaches against a baseline imputation
and complete case analysis with Z1 only. HDMI using claims data showed the
lowest bias (0.072). Combining claims and sentence embeddings led to an
improvement in the efficiency displaying the lowest root-mean-squared-error
(0.173) and coverage (94%). NLP-derived AC alone did not perform better than
baseline MI. HDMI approaches may decrease bias in studies with partially
observed confounders where missingness depends on unobserved factors.

摘要：多重插補 (MI) 模型可透過納入輔助共變量 (AC) 來改善，但其在高維度資料中的表現尚未充分了解。我們旨在開發和比較高維度 MI (HDMI) 方法，在部分觀察到的混淆因子研究中使用結構化和自然語言處理 (NLP) 衍生的 AC。我們進行了一項類模式模擬研究，使用類鴉片藥物與非類固醇消炎藥 (NSAID) 引發者 (X) 的資料，其中觀察到血清肌酐實驗室 (Z2) 和急性腎臟損傷的時間作為結果。我們模擬了 100 個具有空值處理效果的群組，包括 X、Z2、心房顫動 (U) 和結果產生中的 13 個其他研究人員衍生的混淆因子 (Z1)。然後，我們對 50% 的 Z2 測量施加缺失 (MZ2) 作為 Z2 和 U 的函數，並使用結構化和 NLP 衍生的特徵建立不同的 HDMI 候選 AC。我們模擬了 U 未被觀察到的場景，方法是從所有 AC 候選集中省略它。使用 LASSO，我們資料自適應地選擇了與 Z2 和 MZ2 相關的 HDMI 共變量，用於 MI，並使用 U 納入傾向得分模型。在 MI 資料集中進行傾向得分匹配後估計處理效果，並將 HDMI 方法與僅使用 Z1 的基線插補和完整案例分析進行比較。使用索賠資料的 HDMI 顯示出最低偏差 (0.072)。結合索賠和句子嵌入會提高效率，顯示出最低的均方根誤差 (0.173) 和覆蓋率 (94%)。單獨的 NLP 衍生 AC 的表現並未優於基線 MI。在缺失取決於未觀察到的因素的部分觀察到的混淆因子研究中，HDMI 方法可能會降低偏差。

##### **GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value Identification**
2405.10918v1 by D. Subhalingam, Keshav Kolluru, Mausam, Saurabh Singal

In the e-commerce domain, the accurate extraction of attribute-value pairs
from product listings (e.g., Brand: Apple) is crucial for enhancing search and
recommendation systems. The automation of this extraction process is
challenging due to the vast diversity of product categories and their
respective attributes, compounded by the lack of extensive, accurately
annotated training datasets and the demand for low latency to meet the
real-time needs of e-commerce platforms. To address these challenges, we
introduce GenToC, a novel two-stage model for extracting attribute-value pairs
from product titles. GenToC is designed to train with partially-labeled data,
leveraging incomplete attribute-value pairs and obviating the need for a fully
annotated dataset. Moreover, we introduce a bootstrapping method that enables
GenToC to progressively refine and expand its training dataset. This
enhancement substantially improves the quality of data available for training
other neural network models that are typically faster but are inherently less
capable than GenToC in terms of their capacity to handle partially-labeled
data. By supplying an enriched dataset for training, GenToC significantly
advances the performance of these alternative models, making them more suitable
for real-time deployment. Our results highlight the unique capability of GenToC
to learn from a limited set of labeled data and to contribute to the training
of more efficient models, marking a significant leap forward in the automated
extraction of attribute-value pairs from product titles. GenToC has been
successfully integrated into India's largest B2B e-commerce platform,
IndiaMART.com, achieving a significant increase of 21.1% in recall over the
existing deployed system while maintaining a high precision of 89.5% in this
challenging task.

摘要：在電子商務領域中，從產品清單中準確提取屬性-值對（例如，品牌：Apple）對於增強搜尋和推薦系統至關重要。由於產品類別及其各自屬性的種類繁多，加上缺乏廣泛且準確標註的訓練資料集，以及滿足電子商務平台的即時需求而對低延遲性的要求，使得此提取程序的自動化面臨挑戰。為了應對這些挑戰，我們引入了 GenToC，這是一個用於從產品標題中提取屬性-值對的新穎兩階段模型。GenToC 旨在使用部分標記的資料進行訓練，利用不完整的屬性-值對，並消除了對完全標註資料集的需求。此外，我們引入了一種自舉法，使 GenToC 能夠逐步優化和擴展其訓練資料集。此增強功能大幅提升了可用於訓練其他神經網路模型的資料品質，這些模型通常較快，但就其處理部分標記資料的能力而言，本質上不如 GenToC。透過提供豐富的資料集進行訓練，GenToC 大幅提升了這些替代模型的效能，使其更適合於即時部署。我們的結果突顯了 GenToC 從有限的標記資料集中學習並有助於訓練更有效率的模型的獨特能力，標誌著從產品標題中自動提取屬性-值對向前邁出了一大步。GenToC 已成功整合到印度最大的 B2B 電子商務平台 IndiaMART.com 中，在保持此項艱鉅任務中 89.5% 的高精度下，召回率比現有已部署系統大幅提升了 21.1%。

##### **COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain**
2405.10893v1 by Dimitrios P. Panagoulias, Persephone Papatheodosiou, Anastasios P. Palamidas, Mattheos Sanoudos, Evridiki Tsoureli-Nikita, Maria Virvou, George A. Tsihrintzis

Large Language Models (LLMs) constitute a breakthrough state-of-the-art
Artificial Intelligence (AI) technology which is rapidly evolving and promises
to aid in medical diagnosis either by assisting doctors or by simulating a
doctor's workflow in more advanced and complex implementations. In this
technical paper, we outline Cognitive Network Evaluation Toolkit for Medical
Domains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in
the medical domain. Specifically, we propose a scoring-framework with increased
difficulty to assess the ability of LLMs in interpreting medical text. The
proposed framework is accompanied with a database of Multiple Choice Quizzes
(MCQs). To ensure alignment with current medical trends and enhance safety,
usefulness, and applicability, these MCQs have been constructed in
collaboration with several associated medical experts in various medical
domains and are characterized by varying degrees of difficulty. The current
(first) version of the database includes the medical domains of Psychiatry,
Dentistry, Pulmonology, Dermatology and Endocrinology, but it will be
continuously extended and expanded to include additional medical domains.

摘要：大型語言模型 (LLM) 構成了一項突破性的尖端人工智能 (AI) 技術，它正在迅速發展，並承諾通過協助醫生或在更先進和複雜的實施中模擬醫生的工作流程來幫助進行醫療診斷。在本文中，我們概述了醫療領域的認知網路評估工具包 (COGNET-MD)，它構成了一個 LLM 評估在醫療領域的新基準。具體來說，我們提出了一個評分框架，難度增加，以評估 LLM 解釋醫療文本的能力。所提出的框架附帶了一個多選題測驗 (MCQ) 資料庫。為了確保與當前醫療趨勢保持一致並增強安全性、實用性和適用性，這些 MCQ 已與多個相關醫療領域的幾位醫療專家合作構建，並且難度各不相同。資料庫的當前（第一）版本包括精神病學、牙科、肺科學、皮膚病學和內分泌學的醫療領域，但它將不斷擴充和擴展以包括其他醫療領域。

##### **A Versatile Framework for Analyzing Galaxy Image Data by Implanting Human-in-the-loop on a Large Vision Model**
2405.10890v1 by Mingxiang Fu, Yu Song, Jiameng Lv, Liang Cao, Peng Jia, Nan Li, Xiangru Li, Jifeng Liu, A-Li Luo, Bo Qiu, Shiyin Shen, Liangping Tu, Lili Wang, Shoulin Wei, Haifeng Yang, Zhenping Yi, Zhiqiang Zou

The exponential growth of astronomical datasets provides an unprecedented
opportunity for humans to gain insight into the Universe. However, effectively
analyzing this vast amount of data poses a significant challenge. Astronomers
are turning to deep learning techniques to address this, but the methods are
limited by their specific training sets, leading to considerable duplicate
workloads too. Hence, as an example to present how to overcome the issue, we
built a framework for general analysis of galaxy images, based on a large
vision model (LVM) plus downstream tasks (DST), including galaxy morphological
classification, image restoration, object detection, parameter extraction, and
more. Considering the low signal-to-noise ratio of galaxy images and the
imbalanced distribution of galaxy categories, we have incorporated a
Human-in-the-loop (HITL) module into our large vision model, which leverages
human knowledge to enhance the reliability and interpretability of processing
galaxy images interactively. The proposed framework exhibits notable few-shot
learning capabilities and versatile adaptability to all the abovementioned
tasks on galaxy images in the DESI legacy imaging surveys. Expressly, for
object detection, trained by 1000 data points, our DST upon the LVM achieves an
accuracy of 96.7%, while ResNet50 plus Mask R-CNN gives an accuracy of 93.1%;
for morphology classification, to obtain AUC ~0.9, LVM plus DST and HITL only
requests 1/50 training sets compared to ResNet18. Expectedly, multimodal data
can be integrated similarly, which opens up possibilities for conducting joint
analyses with datasets spanning diverse domains in the era of multi-message
astronomy.

摘要：天文資料的指數成長，為人類深入了解宇宙提供了前所未有的機會。然而，有效分析這些海量資料是一項重大挑戰。天文學家正轉向深度學習技術來解決這個問題，但這些方法受到其特定訓練集的限制，也導致大量重複的工作。因此，我們以銀河影像的一般分析框架為例，說明如何克服這個問題，這個框架基於大型視覺模型 (LVM) 加上下游任務 (DST)，包括銀河形態分類、影像修復、物體偵測、參數萃取等等。考量到銀河影像的訊噪比低，以及銀河類別分佈不平衡，我們將人類在迴圈 (HITL) 模組整合到我們的大型視覺模型中，利用人類知識來增強處理銀河影像的可靠度和可解釋性。所提出的框架展現出顯著的少樣本學習能力，以及對 DESI 傳統影像調查中所有上述銀河影像任務的多功能適應性。特別是對於物體偵測，我們的 DST 在 LVM 上訓練了 1000 個資料點，達到了 96.7% 的精確度，而 ResNet50 加上 Mask R-CNN 的精確度為 93.1%；對於形態分類，為了獲得 AUC ~0.9，LVM 加上 DST 和 HITL 只需要 1/50 的訓練集，與 ResNet18 相比。預期多模態資料可以類似地整合，這為在多訊息天文學時代跨越不同領域的資料集進行聯合分析開啟了可能性。

##### **Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review**
2405.10883v1 by Hongyi Yang, Fangyuan Chang, Dian Zhu, Muroi Fumie, Zhao Liu

This review aims to systematically assess the current status and prospects of
artificial intelligence (AI) in the rehabilitation management of patients with
schizophrenia and their impact on the rehabilitation process. We selected 70
studies from 2012 to the present, focusing on application, technology
categories, products, and data types of machine learning, deep learning,
reinforcement learning, and other technologies in mental health interventions
and management. The results indicate that AI can be widely used in symptom
monitoring, relapse risk prediction, and rehabilitation treatment by analyzing
ecological momentary assessment, behavioral, and speech data. This review
further explores the potential challenges and future directions of emerging
products, technologies, and analytical methods based on AI, such as social
media analysis, serious games, and large language models in rehabilitation. In
summary, this study systematically reviews the application status of AI in
schizophrenia rehabilitation management and provides valuable insights and
recommendations for future research paths.

摘要：本綜述旨在系統性評估人工智慧 (AI) 在精神分裂症患者復健管理中的現況與前景，以及其對復健歷程的影響。我們從 2012 年至今選取了 70 篇研究，重點關注機器學習、深度學習、強化學習和其他技術在心理健康介入和管理中的應用、技術類別、產品和資料類型。結果顯示，AI 可廣泛應用於症狀監控、復發風險預測和復健治療，方法是分析生態瞬時評估、行為和言語資料。本綜述進一步探討了基於 AI 的新興產品、技術和分析方法的潛在挑戰和未來方向，例如復健中的社群媒體分析、嚴肅遊戲和大語言模型。總之，本研究系統性地回顧了 AI 在精神分裂症復健管理中的應用現況，並為未來的研究路徑提供了有價值的見解和建議。

##### **WEITS: A Wavelet-enhanced residual framework for interpretable time series forecasting**
2405.10877v1 by Ziyou Guo, Yan Sun, Tieru Wu

Time series (TS) forecasting has been an unprecedentedly popular problem in
recent years, with ubiquitous applications in both scientific and business
fields. Various approaches have been introduced to time series analysis,
including both statistical approaches and deep neural networks. Although neural
network approaches have illustrated stronger ability of representation than
statistical methods, they struggle to provide sufficient interpretablility, and
can be too complicated to optimize. In this paper, we present WEITS, a
frequency-aware deep learning framework that is highly interpretable and
computationally efficient. Through multi-level wavelet decomposition, WEITS
novelly infuses frequency analysis into a highly deep learning framework.
Combined with a forward-backward residual architecture, it enjoys both high
representation capability and statistical interpretability. Extensive
experiments on real-world datasets have demonstrated competitive performance of
our model, along with its additional advantage of high computation efficiency.
Furthermore, WEITS provides a general framework that can always seamlessly
integrate with state-of-the-art approaches for time series forecast.

摘要：時序 (TS) 預測近年來一直是一個空前受歡迎的問題，在科學和商業領域都有廣泛的應用。已針對時序分析引入了各種方法，包括統計方法和深度神經網路。儘管神經網路方法已說明其比統計方法具有更強的表示能力，但它們難以提供足夠的可解釋性，且優化起來可能過於複雜。在本文中，我們提出 WEITS，這是一個高度可解釋且計算效率高的頻率感知深度學習架構。透過多層級小波分解，WEITS 將頻率分析新穎地融入一個高度深度學習架構中。結合前向後向殘差架構，它同時具備高表示能力和統計可解釋性。在真實世界資料集上的大量實驗已證明我們模型的競爭力，以及它在高計算效率方面的額外優勢。此外，WEITS 提供了一個通用架構，它始終可以與時序預測的最新方法無縫整合。

##### **Tailoring Vaccine Messaging with Common-Ground Opinions**
2405.10861v1 by Rickard Stureborg, Sanxing Chen, Ruoyu Xie, Aayushi Patel, Christopher Li, Chloe Qinyu Zhu, Tingnan Hu, Jun Yang, Bhuwan Dhingra

One way to personalize chatbot interactions is by establishing common ground
with the intended reader. A domain where establishing mutual understanding
could be particularly impactful is vaccine concerns and misinformation. Vaccine
interventions are forms of messaging which aim to answer concerns expressed
about vaccination. Tailoring responses in this domain is difficult, since
opinions often have seemingly little ideological overlap. We define the task of
tailoring vaccine interventions to a Common-Ground Opinion (CGO). Tailoring
responses to a CGO involves meaningfully improving the answer by relating it to
an opinion or belief the reader holds. In this paper we introduce TAILOR-CGO, a
dataset for evaluating how well responses are tailored to provided CGOs. We
benchmark several major LLMs on this task; finding GPT-4-Turbo performs
significantly better than others. We also build automatic evaluation metrics,
including an efficient and accurate BERT model that outperforms finetuned LLMs,
investigate how to successfully tailor vaccine messaging to CGOs, and provide
actionable recommendations from this investigation.
  Code and model weights: https://github.com/rickardstureborg/tailor-cgo
Dataset: https://huggingface.co/datasets/DukeNLP/tailor-cgo

摘要：一種使聊天機器人互動個人化的方式是與目標讀者建立共識。建立共識特別有影響力的領域是疫苗疑慮和錯誤資訊。疫苗干預是訊息傳遞的形式，旨在回答對疫苗接種表達的疑慮。在這個領域中，調整回應很困難，因為意見通常看似幾乎沒有意識形態重疊。我們定義了將疫苗干預調整為共同意見（CGO）的任務。針對 CGO 調整回應涉及透過將其與讀者持有的意見或信念相關聯來有意義地改善答案。在本文中，我們介紹了 TAILOR-CGO，一個用於評估回應與提供的 CGO 的調整程度的資料集。我們針對這項任務對幾個主要的 LLM 進行基準測試；發現 GPT-4-Turbo 的表現明顯優於其他 LLM。我們還建立了自動評估指標，包括一個表現優於微調 LLM 的高效且準確的 BERT 模型，探討如何成功地將疫苗訊息調整為 CGO，並從這項調查中提供可行的建議。
程式碼和模型權重：https://github.com/rickardstureborg/tailor-cgo
資料集：https://huggingface.co/datasets/DukeNLP/tailor-cgo

##### **ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains**
2405.10860v1 by Zhaopei Huang, Jinming Zhao, Qin Jin

Understanding the process of emotion generation is crucial for analyzing the
causes behind emotions. Causal Emotion Entailment (CEE), an
emotion-understanding task, aims to identify the causal utterances in a
conversation that stimulate the emotions expressed in a target utterance.
However, current works in CEE mainly focus on modeling semantic and emotional
interactions in conversations, neglecting the exploration of the
emotion-generation process. This hinders the models from deeply understanding
emotions, restricting their ability to produce explainable predictions. In this
work, inspired by the emotion generation process of
"stimulus-appraisal-emotion" in the cognitive appraisal theory, we introduce a
step-by-step reasoning method, Emotion-Cause Reasoning Chain (ECR-Chain), to
infer the stimulus from the target emotional expressions in conversations.
Specifically, we first introduce the ECR-Chain to ChatGPT via few-shot
prompting, which significantly improves its performance on the CEE task. We
further propose an automated construction process to utilize ChatGPT in
building an ECR-Chain set, which can enhance the reasoning abilities of smaller
models through supervised training and assist the Vicuna-7B model in achieving
state-of-the-art CEE performance. Moreover, our methods can enable these
generative language models to effectively perform emotion-cause reasoning in an
explainable manner. Our code, data and more details are at
https://github.com/hzp3517/ECR-Chain.

摘要：<paragraph>了解情緒產生的過程對於分析情緒背後的原因至關重要。因果情緒蘊含 (CEE) 是一種情緒理解任務，旨在識別對話中引發目標話語中表達的情緒的因果話語。然而，目前 CEE 的工作主要集中於對話中語義和情緒交互的建模，而忽略了對情緒產生過程的探索。這阻礙了模型對情緒的深入理解，限制了它們產生可解釋預測的能力。在這項工作中，受認知評估理論中「刺激-評估-情緒」的情緒產生過程啟發，我們引入了一個循序漸進的推理方法，情緒原因推理鏈 (ECR-Chain)，從對話中的目標情緒表達中推斷出刺激。具體來說，我們首先通過少次提示將 ECR-Chain 引入 ChatGPT，這顯著提高了其在 CEE 任務上的表現。我們進一步提出了一個自動化構建過程，利用 ChatGPT 構建 ECR-Chain 集合，這可以通過監督訓練增強較小模型的推理能力，並幫助 Vicuna-7B 模型實現最先進的 CEE 性能。此外，我們的這些方法可以使這些生成語言模型以可解釋的方式有效地執行情緒原因推理。我們的程式碼、資料和更多詳細資訊請參閱 https://github.com/hzp3517/ECR-Chain。</paragraph>

##### **The Future of Large Language Model Pre-training is Federated**
2405.10853v1 by Lorenzo Sani, Alex Iacob, Zeyu Cao, Bill Marino, Yan Gao, Tomas Paulik, Wanru Zhao, William F. Shen, Preslav Aleksandrov, Xinchi Qiu, Nicholas D. Lane

Generative pre-trained large language models (LLMs) have demonstrated
impressive performance over a wide range of tasks, thanks to the unprecedented
amount of data they have been trained on. As established scaling laws indicate,
LLMs' future performance improvement depends on the amount of computing and
data sources we can leverage for pre-training. Federated learning (FL) has the
potential to unleash the majority of the planet's data and computational
resources, which are underutilized by the data-center-focused training
methodology of current LLM practice. Our work presents a robust, flexible,
reproducible FL approach that enables large-scale collaboration across
institutions to train LLMs. This would mobilize more computational and data
resources while matching or potentially exceeding centralized performance. We
further show the effectiveness of the federated training scales with model size
and present our approach for training a billion-scale federated LLM using
limited resources. This will help data-rich actors to become the protagonists
of LLMs pre-training instead of leaving the stage to compute-rich actors alone.

摘要：生成式预训练大型语言模型 (LLM) 已在广泛的任务中展示出令人印象深刻的性能，这要归功于它们接受过前所未有的数据训练。正如既定的缩放定律所表明的，LLM 未来性能的提升取决于我们可用于预训练的计算量和数据源。联邦学习 (FL) 有可能释放地球上大部分数据和计算资源，而这些资源目前并未得到以数据中心为中心的当前 LLM 实践训练方法的充分利用。我们的工作提出了一种稳健、灵活、可复制的 FL 方法，该方法支持跨机构进行大规模协作以训练 LLM。这将调动更多计算和数据资源，同时匹配或可能超过集中式性能。我们进一步展示了联邦训练规模与模型大小的有效性，并提出了我们使用有限资源训练十亿级联邦 LLM 的方法。这将帮助数据丰富的参与者成为 LLM 预训练的主角，而不是将舞台留给仅有的计算丰富的参与者。

##### **KernelSHAP-IQ: Weighted Least-Square Optimization for Shapley Interactions**
2405.10852v1 by Fabian Fumagalli, Maximilian Muschalik, Patrick Kolpaczki, Eyke Hüllermeier, Barbara Hammer

The Shapley value (SV) is a prevalent approach of allocating credit to
machine learning (ML) entities to understand black box ML models. Enriching
such interpretations with higher-order interactions is inevitable for complex
systems, where the Shapley Interaction Index (SII) is a direct axiomatic
extension of the SV. While it is well-known that the SV yields an optimal
approximation of any game via a weighted least square (WLS) objective, an
extension of this result to SII has been a long-standing open problem, which
even led to the proposal of an alternative index. In this work, we characterize
higher-order SII as a solution to a WLS problem, which constructs an optimal
approximation via SII and $k$-Shapley values ($k$-SII). We prove this
representation for the SV and pairwise SII and give empirically validated
conjectures for higher orders. As a result, we propose KernelSHAP-IQ, a direct
extension of KernelSHAP for SII, and demonstrate state-of-the-art performance
for feature interactions.

摘要：Shapley 值 (SV) 是一種普遍用於將信用分配給機器學習 (ML) 實體的方法，以了解黑盒 ML 模型。對於複雜系統，以高階互動豐富此類解釋是不可避免的，其中 Shapley 互動指數 (SII) 是 SV 的直接公理延伸。雖然眾所周知，SV 通過加權最小二乘 (WLS) 目標產生任何遊戲的最佳近似，但將此結果擴展到 SII 一直是一個長期存在的開放問題，甚至導致提出替代指數。在這項工作中，我們將高階 SII 描述為 WLS 問題的解，該問題通過 SII 和 $k$-Shapley 值 ($k$-SII) 構建最佳近似。我們證明了 SV 和成對 SII 的這個表示，並給出經驗驗證的高階猜想。因此，我們提出了 KernelSHAP-IQ，這是 KernelSHAP 的直接擴展，用於 SII，並展示了特徵互動的最新性能。

##### **ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios**
2405.10808v1 by Markus Bayer, Christian Reuter

Active learning is designed to minimize annotation efforts by prioritizing
instances that most enhance learning. However, many active learning strategies
struggle with a 'cold start' problem, needing substantial initial data to be
effective. This limitation often reduces their utility for pre-trained models,
which already perform well in few-shot scenarios. To address this, we introduce
ActiveLLM, a novel active learning approach that leverages large language
models such as GPT-4, Llama 3, and Mistral Large for selecting instances. We
demonstrate that ActiveLLM significantly enhances the classification
performance of BERT classifiers in few-shot scenarios, outperforming both
traditional active learning methods and the few-shot learning method SetFit.
Additionally, ActiveLLM can be extended to non-few-shot scenarios, allowing for
iterative selections. In this way, ActiveLLM can even help other active
learning strategies to overcome their cold start problem. Our results suggest
that ActiveLLM offers a promising solution for improving model performance
across various learning setups.

摘要：主动学习旨在通过优先考虑最能促进学习的实例来最大程度地减少标注工作。然而，许多主动学习策略都面临着“冷启动”问题，需要大量初始数据才能有效。此限制通常会降低其对预训练模型的效用，而预训练模型在小样本场景中已经表现良好。为了解决这个问题，我们引入了 ActiveLLM，这是一种新颖的主动学习方法，它利用大型语言模型（例如 GPT-4、Llama 3 和 Mistral Large）来选择实例。我们证明 ActiveLLM 在小样本场景中显著增强了 BERT 分类器的分类性能，优于传统主动学习方法和少量样本学习方法 SetFit。此外，ActiveLLM 可以扩展到非小样本场景，允许进行迭代选择。通过这种方式，ActiveLLM 甚至可以帮助其他主动学习策略克服其冷启动问题。我们的结果表明，ActiveLLM 为改善各种学习设置中的模型性能提供了一种有希望的解决方案。

##### **What should be observed for optimal reward in POMDPs?**
2405.10768v1 by Alyzia-Maria Konsta, Alberto Lluch Lafuente, Christoph Matheja

Partially observable Markov Decision Processes (POMDPs) are a standard model
for agents making decisions in uncertain environments. Most work on POMDPs
focuses on synthesizing strategies based on the available capabilities.
However, system designers can often control an agent's observation
capabilities, e.g. by placing or selecting sensors. This raises the question of
how one should select an agent's sensors cost-effectively such that it achieves
the desired goals. In this paper, we study the novel optimal observability
problem OOP: Given a POMDP M, how should one change M's observation
capabilities within a fixed budget such that its (minimal) expected reward
remains below a given threshold? We show that the problem is undecidable in
general and decidable when considering positional strategies only. We present
two algorithms for a decidable fragment of the OOP: one based on optimal
strategies of M's underlying Markov decision process and one based on parameter
synthesis with SMT. We report promising results for variants of typical
examples from the POMDP literature.

摘要：部分可觀察馬可夫決策過程 (POMDP) 是在不確定環境中做出決策的代理標準模型。大多數關於 POMDP 的工作都專注於根據可用功能綜合策略。然而，系統設計人員通常可以控制代理的觀察能力，例如放置或選擇感測器。這引發了一個問題，即如何以具有成本效益的方式選擇代理的感測器，以便實現預期的目標。在本文中，我們研究了新穎的最佳可觀察性問題 OOP：給定 POMDP M，如何在固定預算內改變 M 的觀察能力，使其（最小）預期回報保持在給定閾值以下？我們表明，這個問題在一般情況下是不可判定的，而在僅考慮位置策略時是可以判定的。我們為 OOP 的可判別片段提供兩種演算法：一種基於 M 的底層馬可夫決策過程的最佳策略，另一種基於帶 SMT 的參數合成。我們報告了 POMDP 文獻中典型範例變體的有希望的結果。

##### **Evaluating Saliency Explanations in NLP by Crowdsourcing**
2405.10767v1 by Xiaotian Lu, Jiyi Li, Zhen Wan, Xiaofeng Lin, Koh Takeuchi, Hisashi Kashima

Deep learning models have performed well on many NLP tasks. However, their
internal mechanisms are typically difficult for humans to understand. The
development of methods to explain models has become a key issue in the
reliability of deep learning models in many important applications. Various
saliency explanation methods, which give each feature of input a score
proportional to the contribution of output, have been proposed to determine the
part of the input which a model values most. Despite a considerable body of
work on the evaluation of saliency methods, whether the results of various
evaluation metrics agree with human cognition remains an open question. In this
study, we propose a new human-based method to evaluate saliency methods in NLP
by crowdsourcing. We recruited 800 crowd workers and empirically evaluated
seven saliency methods on two datasets with the proposed method. We analyzed
the performance of saliency methods, compared our results with existing
automated evaluation methods, and identified notable differences between NLP
and computer vision (CV) fields when using saliency methods. The instance-level
data of our crowdsourced experiments and the code to reproduce the explanations
are available at https://github.com/xtlu/lreccoling_evaluation.

摘要：深度學習模型在許多 NLP 任務上表現良好。然而，人類通常難以理解其內部機制。在許多重要應用中，開發解釋模型的方法已成為深度學習模型可靠性的關鍵問題。已經提出各種顯著性解釋方法，這些方法為輸入的每個特徵賦予一個與輸出貢獻成正比的分數，以確定模型最重視輸入的哪一部分。儘管在顯著性方法的評估方面有大量的工作，但各種評估指標的結果是否與人類認知一致仍然是一個開放的問題。在本研究中，我們提出了一種基於人類的新方法，通過眾包來評估 NLP 中的顯著性方法。我們招募了 800 名群眾工作者，並使用所提出的方法在兩個數據集上對七種顯著性方法進行了經驗評估。我們分析了顯著性方法的性能，將我們的結果與現有的自動評估方法進行了比較，並在使用顯著性方法時發現了 NLP 和計算機視覺 (CV) 領域之間的顯著差異。我們眾包實驗的實例級別數據和重現解釋的代碼可在 https://github.com/xtlu/lreccoling_evaluation 中獲得。

##### **Research on Credit Risk Early Warning Model of Commercial Banks Based on Neural Network Algorithm**
2405.10762v1 by Yu Cheng, Qin Yang, Liyang Wang, Ao Xiang, Jingyu Zhang

In the realm of globalized financial markets, commercial banks are confronted
with an escalating magnitude of credit risk, thereby imposing heightened
requisites upon the security of bank assets and financial stability. This study
harnesses advanced neural network techniques, notably the Backpropagation (BP)
neural network, to pioneer a novel model for preempting credit risk in
commercial banks. The discourse initially scrutinizes conventional financial
risk preemptive models, such as ARMA, ARCH, and Logistic regression models,
critically analyzing their real-world applications. Subsequently, the
exposition elaborates on the construction process of the BP neural network
model, encompassing network architecture design, activation function selection,
parameter initialization, and objective function construction. Through
comparative analysis, the superiority of neural network models in preempting
credit risk in commercial banks is elucidated. The experimental segment selects
specific bank data, validating the model's predictive accuracy and
practicality. Research findings evince that this model efficaciously enhances
the foresight and precision of credit risk management.

摘要：在全球化金融市場的領域中，商業銀行面臨著信貸風險不斷升高的問題，從而對銀行資產的安全性和金融穩定性提出了更高的要求。本研究利用先進的神經網路技術，特別是反向傳播 (BP) 神經網路，開創了一種預防商業銀行信貸風險的新模型。本文首先審視了傳統的金融風險預防模型，例如 ARMA、ARCH 和邏輯迴歸模型，並批判性地分析了它們在實際中的應用。隨後，本文詳細闡述了 BP 神經網路模型的構建過程，包括網路架構設計、激活函數選擇、參數初始化和目標函數構建。通過比較分析，闡明了神經網路模型在預防商業銀行信貸風險方面的優越性。實驗部分選擇了具體的銀行資料，驗證了該模型的預測準確性和實用性。研究結果表明，該模型有效地提高了信貸風險管理的前瞻性和準確性。

##### **Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings**
2405.10745v1 by Albert Sawczyn, Jakub Binkowski, Piotr Bielak, Tomasz Kajdanowicz

Knowledge-intensive tasks pose a significant challenge for Machine Learning
(ML) techniques. Commonly adopted methods, such as Large Language Models
(LLMs), often exhibit limitations when applied to such tasks. Nevertheless,
there have been notable endeavours to mitigate these challenges, with a
significant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While
KGs provide many advantages for representing knowledge, their development costs
can deter extensive research and applications. Addressing this limitation, we
introduce a framework for enriching embeddings of small-scale domain-specific
Knowledge Graphs with well-established general-purpose KGs. Adopting our
method, a modest domain-specific KG can benefit from a performance boost in
downstream tasks when linked to a substantial general-purpose KG. Experimental
evaluations demonstrate a notable enhancement, with up to a 44% increase
observed in the Hits@10 metric. This relatively unexplored research direction
can catalyze more frequent incorporation of KGs in knowledge-intensive tasks,
resulting in more robust, reliable ML implementations, which hallucinates less
than prevalent LLM solutions.
  Keywords: knowledge graph, knowledge graph completion, entity alignment,
representation learning, machine learning

摘要：知識密集型任務對機器學習 (ML) 技術構成重大挑戰。常見採用的方法，例如大型語言模型 (LLM)，在應用於此類任務時，通常會表現出限制。儘管如此，已經有顯著的努力來減輕這些挑戰，重點在於透過知識圖譜 (KG) 來擴充 LLM。雖然 KG 在表示知識方面提供了許多優點，但其開發成本可能會阻礙廣泛的研究和應用。為了解決這個限制，我們引入了一個架構，用完善的通用 KG 來豐富小規模特定領域知識圖譜的嵌入。採用我們的這個方法，一個適度的特定領域 KG 可以從與一個大量的通用 KG 連結時，在下游任務中受益於效能提升。實驗評估證明了顯著的改進，在 Hits@10 指標中觀察到高達 44% 的提升。這個相對未開發的研究方向可以催化在知識密集型任務中更頻繁地納入 KG，從而產生更強大、更可靠的 ML 實作，其產生的幻覺少於普遍的 LLM 解决方案。
關鍵字：知識圖譜、知識圖譜完成功能、實體對齊、表示學習、機器學習

##### **SBAAM! Eliminating Transcript Dependency in Automatic Subtitling**
2405.10741v1 by Marco Gaido, Sara Papi, Matteo Negri, Mauro Cettolo, Luisa Bentivogli

Subtitling plays a crucial role in enhancing the accessibility of audiovisual
content and encompasses three primary subtasks: translating spoken dialogue,
segmenting translations into concise textual units, and estimating timestamps
that govern their on-screen duration. Past attempts to automate this process
rely, to varying degrees, on automatic transcripts, employed diversely for the
three subtasks. In response to the acknowledged limitations associated with
this reliance on transcripts, recent research has shifted towards
transcription-free solutions for translation and segmentation, leaving the
direct generation of timestamps as uncharted territory. To fill this gap, we
introduce the first direct model capable of producing automatic subtitles,
entirely eliminating any dependence on intermediate transcripts also for
timestamp prediction. Experimental results, backed by manual evaluation,
showcase our solution's new state-of-the-art performance across multiple
language pairs and diverse conditions.

摘要：字幕對於提升視聽內容的可近性扮演著至關重要的角色，並包含了三個主要的子任務：翻譯口語對話、將翻譯內容區隔成簡潔的文字單位，以及估計其在螢幕上顯示時間的戳記。過去自動化此流程的嘗試在不同程度上依賴於自動轉錄，並廣泛用於三個子任務。為了回應與依賴轉錄相關的已知限制，最近的研究已轉向無轉錄的翻譯和區隔解決方案，將時間戳記的直接產生視為未知領域。為了填補此空白，我們引進了第一個能夠產生自動字幕的直接模型，完全消除了對中間轉錄的任何依賴，也包括時間戳記預測。由人工評估支持的實驗結果展示了我們的解決方案在多個語言配對和各種條件下的最新技術表現。

##### **Efficient Multimodal Large Language Models: A Survey**
2405.10739v1 by Yizhang Jin, Jian Li, Yexin Liu, Tianjun Gu, Kai Wu, Zhengkai Jiang, Muyang He, Bo Zhao, Xin Tan, Zhenye Gan, Yabiao Wang, Chengjie Wang, Lizhuang Ma

In the past year, Multimodal Large Language Models (MLLMs) have demonstrated
remarkable performance in tasks such as visual question answering, visual
understanding and reasoning. However, the extensive model size and high
training and inference costs have hindered the widespread application of MLLMs
in academia and industry. Thus, studying efficient and lightweight MLLMs has
enormous potential, especially in edge computing scenarios. In this survey, we
provide a comprehensive and systematic review of the current state of efficient
MLLMs. Specifically, we summarize the timeline of representative efficient
MLLMs, research state of efficient structures and strategies, and the
applications. Finally, we discuss the limitations of current efficient MLLM
research and promising future directions. Please refer to our GitHub repository
for more details:
https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.

摘要：在過去一年中，多模態大型語言模型 (MLLM) 在視覺問題解答、視覺理解和推理等任務中展現了卓越的表現。然而，龐大的模型規模和高昂的訓練和推論成本阻礙了 MLLM 在學術界和產業中的廣泛應用。因此，研究高效且輕量的 MLLM 具有巨大的潛力，特別是在邊緣運算場景中。在這項調查中，我們全面且系統地回顧了當前高效 MLLM 的現狀。具體而言，我們總結了代表性高效 MLLM 的時間表、高效結構和策略的研究現狀，以及應用。最後，我們討論了當前高效 MLLM 研究的局限性以及未來有前景的方向。有關更多詳細資訊，請參閱我們的 GitHub 儲存庫：
https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey。

##### **Feature-Adaptive and Data-Scalable In-Context Learning**
2405.10738v1 by Jiahao Li, Quan Wang, Licheng Zhang, Guoqing Jin, Zhendong Mao

In-context learning (ICL), which promotes inference with several
demonstrations, has become a widespread paradigm to stimulate LLM capabilities
for downstream tasks. Due to context length constraints, it cannot be further
improved in spite of more training data, and general features directly from
LLMs in ICL are not adaptive to the specific downstream task. In this paper, we
propose a feature-adaptive and data-scalable in-context learning framework
(FADS-ICL), which can leverage task-adaptive features to promote inference on
the downstream task, with the supervision of beyond-context samples.
Specifically, it first extracts general features of beyond-context samples via
the LLM with ICL input form one by one, and introduces a task-specific
modulator to perform feature refinement and prediction after fitting a specific
downstream task. We conduct extensive experiments on FADS-ICL under varying
data settings (4$\sim$128 shots) and LLM scale (0.8$\sim$70B) settings.
Experimental results show that FADS-ICL consistently outperforms previous
state-of-the-art methods by a significant margin under all settings, verifying
the effectiveness and superiority of FADS-ICL. For example, under the 1.5B and
32 shots setting, FADS-ICL can achieve \textbf{+14.3} average accuracy from
feature adaptation over vanilla ICL on 10 datasets, with \textbf{+6.2} average
accuracy over the previous state-of-the-art method, and the performance can
further improve with increasing training data. Code and data are publicly
available at \url{https://github.com/jiahaozhenbang/FADS-ICL}.

摘要：<paragraph>情境學習 (ICL) 透過多個示範促進推論，已成為一個廣泛的範例，用於刺激 LLM 在下游任務中的能力。由於情境長度限制，儘管有更多訓練資料，但它無法進一步改善，而 ICL 中直接來自 LLM 的一般特徵並無法適應特定下游任務。在本文中，我們提出一個特徵適應且資料可擴充的情境學習架構 (FADS-ICL)，它可以利用任務適應特徵來促進對下游任務的推論，並監督情境外範例。具體來說，它首先透過 ICL 輸入表單逐一提取情境外範例的一般特徵，並引入一個任務特定調製器，在擬合特定下游任務後執行特徵優化和預測。我們對 FADS-ICL 在不同的資料設定 (4$\sim$128 個鏡頭) 和 LLM 規模 (0.8$\sim$70B) 設定下進行了廣泛的實驗。實驗結果表明，在所有設定下，FADS-ICL 持續優於先前的最先進方法，驗證了 FADS-ICL 的有效性和優越性。例如，在 1.5B 和 32 個鏡頭的設定下，FADS-ICL 可以透過從香草 ICL 到 10 個資料集的特徵適應來實現\textbf{+14.3} 的平均準確度，比先前的最先進方法高出\textbf{+6.2} 的平均準確度，而且隨著訓練資料的增加，效能可以進一步提升。程式碼和資料已公開於\url{https://github.com/jiahaozhenbang/FADS-ICL}。</paragraph>

##### **INDUS: Effective and Efficient Language Models for Scientific Applications**
2405.10725v1 by Bishwaranjan Bhattacharjee, Aashka Trivedi, Masayasu Muraoka, Muthukumaran Ramasubramanian, Takuma Udagawa, Iksha Gurung, Rong Zhang, Bharath Dandala, Rahul Ramachandran, Manil Maskey, Kayleen Bugbee, Mike Little, Elizabeth Fancher, Lauren Sanders, Sylvain Costes, Sergi Blanco-Cuaresma, Kelly Lockhart, Thomas Allen, Felix Grazes, Megan Ansdel, Alberto Accomazzi, Yousef El-Kurdi, Davis Wertheimer, Birgit Pfitzmann, Cesar Berrospi Ramis, Michele Dolfi, Rafael Teixeira de Lima, Panos Vegenas, S. Karthik Mukkavilli, Peter Staar, Sanaz Vahidinia, Ryan McGranaghan, Armin Mehrabian, Tsendgar Lee

Large language models (LLMs) trained on general domain corpora showed
remarkable results on natural language processing (NLP) tasks. However,
previous research demonstrated LLMs trained using domain-focused corpora
perform better on specialized tasks. Inspired by this pivotal insight, we
developed INDUS, a comprehensive suite of LLMs tailored for the Earth science,
biology, physics, heliophysics, planetary sciences and astrophysics domains and
trained using curated scientific corpora drawn from diverse data sources. The
suite of models include: (1) an encoder model trained using domain-specific
vocabulary and corpora to address natural language understanding tasks, (2) a
contrastive-learning-based general text embedding model trained using a diverse
set of datasets drawn from multiple sources to address information retrieval
tasks and (3) smaller versions of these models created using knowledge
distillation techniques to address applications which have latency or resource
constraints. We also created three new scientific benchmark datasets namely,
CLIMATE-CHANGE-NER (entity-recognition), NASA-QA (extractive QA) and NASA-IR
(IR) to accelerate research in these multi-disciplinary fields. Finally, we
show that our models outperform both general-purpose encoders (RoBERTa) and
existing domain-specific encoders (SciBERT) on these new tasks as well as
existing benchmark tasks in the domains of interest.

摘要：大型語言模型 (LLM) 在一般領域語料庫上訓練，顯示出自然語言處理 (NLP) 任務的顯著成果。然而，先前的研究表明，使用領域聚焦語料庫訓練的 LLM 在特殊任務上的表現更好。受到這項關鍵見解的啟發，我們開發了 INDUS，這是一套針對地球科學、生物學、物理學、太陽物理學、行星科學和天體物理學領域量身打造的 LLM，並使用從各種數據來源中提取的精選科學語料庫進行訓練。這套模型包括：(1) 使用特定領域詞彙和語料庫訓練的編碼器模型，以解決自然語言理解任務，(2) 使用從多個來源中提取的各種資料集訓練的對比學習基礎一般文字嵌入模型，以解決資訊檢索任務，以及 (3) 使用知識蒸餾技術建立的這些模型的較小版本，以解決有延遲或資源限制的應用程式。我們還建立了三個新的科學基準資料集，即 CLIMATE-CHANGE-NER (實體識別)、NASA-QA (萃取式問答) 和 NASA-IR (IR)，以加速這些多學科領域的研究。最後，我們展示我們的模型在這些新任務以及感興趣領域中的現有基準任務上，都優於通用編碼器 (RoBERTa) 和現有的特定領域編碼器 (SciBERT)。

##### **SignLLM: Sign Languages Production Large Language Models**
2405.10718v1 by Sen Fang, Lei Wang, Ce Zheng, Yapeng Tian, Chen Chen

In this paper, we introduce the first comprehensive multilingual sign
language dataset named Prompt2Sign, which builds from public data including
American Sign Language (ASL) and seven others. Our dataset transforms a vast
array of videos into a streamlined, model-friendly format, optimized for
training with translation models like seq2seq and text2text. Building on this
new dataset, we propose SignLLM, the first multilingual Sign Language
Production (SLP) model, which includes two novel multilingual SLP modes that
allow for the generation of sign language gestures from input text or prompt.
Both of the modes can use a new loss and a module based on reinforcement
learning, which accelerates the training by enhancing the model's capability to
autonomously sample high-quality data. We present benchmark results of SignLLM,
which demonstrate that our model achieves state-of-the-art performance on SLP
tasks across eight sign languages.

摘要：在本文中，我們介紹第一個全面的多語言手語資料集，名為 Prompt2Sign，它建立在包括美國手語 (ASL) 和其他七種語言的公開資料之上。我們的資料集將大量影片轉換成簡化的、模型友善的格式，針對使用序列到序列和文字到文字等翻譯模型進行訓練進行最佳化。建立在這個新資料集上，我們提出 SignLLM，第一個多語言手語製作 (SLP) 模型，它包含兩種新穎的多語言 SLP 模式，允許從輸入文字或提示產生手語手勢。這兩種模式都可以使用新的損失和基於強化學習的模組，透過增強模型自主取樣高品質資料的能力來加速訓練。我們提出 SignLLM 的基準測試結果，證明我們的模型在八種手語的 SLP 任務上達到最先進的效能。

##### **Persian Pronoun Resolution: Leveraging Neural Networks and Language Models**
2405.10714v1 by Hassan Haji Mohammadi, Alireza Talebpour, Ahmad Mahmoudi Aznaveh, Samaneh Yazdani

Coreference resolution, critical for identifying textual entities referencing
the same entity, faces challenges in pronoun resolution, particularly
identifying pronoun antecedents. Existing methods often treat pronoun
resolution as a separate task from mention detection, potentially missing
valuable information. This study proposes the first end-to-end neural network
system for Persian pronoun resolution, leveraging pre-trained Transformer
models like ParsBERT. Our system jointly optimizes both mention detection and
antecedent linking, achieving a 3.37 F1 score improvement over the previous
state-of-the-art system (which relied on rule-based and statistical methods) on
the Mehr corpus. This significant improvement demonstrates the effectiveness of
combining neural networks with linguistic models, potentially marking a
significant advancement in Persian pronoun resolution and paving the way for
further research in this under-explored area.

摘要：核心指代消解對於識別文本實體引用相同實體至關重要，在代名詞消解中面臨挑戰，特別是識別代名詞先行詞。現有方法通常將代名詞消解視為與提及偵測分開的任務，可能會遺漏有價值的資訊。本研究提出了第一個波斯語代名詞消解端到端神經網路系統，利用預先訓練的 Transformer 模型，例如 ParsBERT。我們的系統同時最佳化提及偵測和先行詞連結，在 Mehr 語料庫中比以前最先進的系統（依賴基於規則和統計的方法）提升了 3.37 的 F1 分數。這個顯著的改善證明了將神經網路與語言模型結合的有效性，可能會標誌著波斯語代名詞消解的重大進展，並為這個探索不足的領域的進一步研究鋪路。

##### **Development of Semantics-Based Distributed Middleware for Heterogeneous Data Integration and its Application for Drought**
2405.10713v1 by A Akanbi

Drought is a complex environmental phenomenon that affects millions of people
and communities all over the globe and is too elusive to be accurately
predicted. This is mostly due to the scalability and variability of the web of
environmental parameters that directly/indirectly causes the onset of different
categories of drought. Since the dawn of man, efforts have been made to
uniquely understand the natural indicators that provide signs of likely
environmental events. These indicators/signs in the form of indigenous
knowledge system have been used for generations. The intricate complexity of
drought has, however, always been a major stumbling block for accurate drought
prediction and forecasting systems. Recently, scientists in the field of
agriculture and environmental monitoring have been discussing the integration
of indigenous knowledge and scientific knowledge for a more accurate
environmental forecasting system in order to incorporate diverse environmental
information for a reliable drought forecast. Hence, in this research, the core
objective is the development of a semantics-based data integration middleware
that encompasses and integrates heterogeneous data models of local indigenous
knowledge and sensor data towards an accurate drought forecasting system for
the study areas. The local indigenous knowledge on drought gathered from the
domain experts is transformed into rules to be used for performing deductive
inference in conjunction with sensors data for determining the onset of drought
through an automated inference generation module of the middleware. The
semantic middleware incorporates, inter alia, a distributed architecture that
consists of a streaming data processing engine based on Apache Kafka for
real-time stream processing; a rule-based reasoning module; an ontology module
for semantic representation of the knowledge bases.

摘要：<paragraph>乾旱是一種複雜的環境現象，影響全球數百萬人及社區，且難以準確預測。這主要是由於直接/間接導致不同類別乾旱發生的環境參數網路的可擴充性和變異性。自人類誕生以來，人們一直努力獨特地理解提供可能環境事件跡象的自然指標。這些以原住民知識系統形式存在的指標/跡象已被使用了好幾代。然而，乾旱的複雜性一直是準確乾旱預測和預報系統的主要障礙。最近，農業和環境監測領域的科學家一直在討論整合原住民知識和科學知識，以建立更準確的環境預測系統，以便納入多樣化的環境資訊以進行可靠的乾旱預測。因此，本研究的核心目標是開發一個基於語義的資料整合中介軟體，該軟體涵蓋並整合了當地原住民知識和感測器資料的異質資料模型，以建立研究區域的準確乾旱預測系統。從領域專家收集的當地原住民乾旱知識轉換為規則，用於執行演繹推理，並結合感測器資料，透過中介軟體的自動化推理產生模組來確定乾旱的發生。語義中介軟體整合了分布式架構，其中包括基於 Apache Kafka 的串流資料處理引擎，用於即時串流處理；基於規則的推理模組；用於知識庫語義表示的本体模組。</paragraph>

##### **Empowering Prior to Court Legal Analysis: A Transparent and Accessible Dataset for Defensive Statement Classification and Interpretation**
2405.10702v1 by Yannis Spyridis, Jean-Paul, Haneen Deeb, Vasileios Argyriou

The classification of statements provided by individuals during police
interviews is a complex and significant task within the domain of natural
language processing (NLP) and legal informatics. The lack of extensive
domain-specific datasets raises challenges to the advancement of NLP methods in
the field. This paper aims to address some of the present challenges by
introducing a novel dataset tailored for classification of statements made
during police interviews, prior to court proceedings. Utilising the curated
dataset for training and evaluation, we introduce a fine-tuned DistilBERT model
that achieves state-of-the-art performance in distinguishing truthful from
deceptive statements. To enhance interpretability, we employ explainable
artificial intelligence (XAI) methods to offer explainability through saliency
maps, that interpret the model's decision-making process. Lastly, we present an
XAI interface that empowers both legal professionals and non-specialists to
interact with and benefit from our system. Our model achieves an accuracy of
86%, and is shown to outperform a custom transformer architecture in a
comparative study. This holistic approach advances the accessibility,
transparency, and effectiveness of statement analysis, with promising
implications for both legal practice and research.

摘要：在警察訪談中，由個人所提供的陳述分類，是自然語言處理（NLP）和法律資訊學領域中一項複雜且重要的任務。缺乏廣泛的特定領域資料集，對 NLP 方法在該領域的進步提出了挑戰。本文旨在透過引入一個新穎的資料集來解決一些當前挑戰，該資料集專門用於對警察訪談中所作的陳述進行分類，並在法庭程序之前進行分類。利用策展的資料集進行訓練和評估，我們引入了一個經過微調的 DistilBERT 模型，該模型在區分真實陳述和虛假陳述方面取得了最先進的效能。為了增強可解釋性，我們採用可解釋的人工智慧（XAI）方法，透過顯著性圖提供可解釋性，以詮釋模型的決策制定過程。最後，我們提出了一個 XAI 介面，讓法律專業人士和非專業人士都能與我們的系統互動並從中受益。我們的模型達到了 86% 的準確度，並且在比較研究中被證明優於自訂的轉換器架構。這種整體方法提升了陳述分析的可及性、透明度和有效性，對法律實務和研究都有著有希望的影響。

##### **SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks**
2405.10700v1 by Michael Shliselberg, Ashkan Kazemi, Scott A. Hale, Shiri Dori-Hacohen

Diaspora communities are disproportionately impacted by off-the-radar
misinformation and often neglected by mainstream fact-checking efforts,
creating a critical need to scale-up efforts of nascent fact-checking
initiatives. In this paper we present SynDy, a framework for Synthetic Dynamic
Dataset Generation to leverage the capabilities of the largest frontier Large
Language Models (LLMs) to train local, specialized language models. To the best
of our knowledge, SynDy is the first paper utilizing LLMs to create
fine-grained synthetic labels for tasks of direct relevance to misinformation
mitigation, namely Claim Matching, Topical Clustering, and Claim Relationship
Classification. SynDy utilizes LLMs and social media queries to automatically
generate distantly-supervised, topically-focused datasets with synthetic labels
on these three tasks, providing essential tools to scale up human-led
fact-checking at a fraction of the cost of human-annotated data. Training on
SynDy's generated labels shows improvement over a standard baseline and is not
significantly worse compared to training on human labels (which may be
infeasible to acquire). SynDy is being integrated into Meedan's chatbot
tiplines that are used by over 50 organizations, serve over 230K users
annually, and automatically distribute human-written fact-checks via messaging
apps such as WhatsApp. SynDy will also be integrated into our deployed
Co-Insights toolkit, enabling low-resource organizations to launch tiplines for
their communities. Finally, we envision SynDy enabling additional fact-checking
tools such as matching new misinformation claims to high-quality explainers on
common misinformation topics.

摘要：離散社群受到雷達外錯誤資訊的不成比例影響，且通常被主流查核事實的努力所忽略，這造成了擴大新興查核事實計畫的關鍵需求。在本文中，我們提出 SynDy，一個用於合成動態資料集生成的架構，以利用最大的前沿大型語言模型 (LLM) 的能力來訓練在地的、專業的語言模型。就我們所知，SynDy 是第一個利用 LLM 來為與錯誤資訊緩解直接相關的任務建立細緻的合成標籤的論文，也就是宣稱比對、主題分類和宣稱關係分類。SynDy 利用 LLM 和社群媒體查詢，自動產生遠程監督、主題為焦點的資料集，以及這三個任務的合成標籤，提供必要的工具，以人類標註資料的成本，來擴大由人主導的查核事實。在 SynDy 生成的標籤上訓練，顯示出比標準基準線有進步，並且與在人類標籤上訓練相比，並未顯著惡化（這可能是難以取得的）。SynDy 正整合到 Meedan 的聊天機器人提示熱線中，由超過 50 個組織使用，每年服務超過 23 萬名使用者，並透過 WhatsApp 等訊息應用程式自動散佈由人撰寫的事實查核。SynDy 也將整合到我們已部署的共同見解工具組中，讓資源不足的組織能夠為他們的社群啟動提示熱線。最後，我們預想 SynDy 能夠啟用其他查核事實工具，例如將新的錯誤資訊宣稱與常見錯誤資訊主題的高品質說明相匹配。

##### **Revolutionizing Process Mining: A Novel Architecture for ChatGPT Integration and Enhanced User Experience through Optimized Prompt Engineering**
2405.10689v1 by Mehrdad Agha Mohammad Ali Kermani, Hamid Reza Seddighi, Mehrdad Maghsoudi

In the rapidly evolving field of business process management, there is a
growing need for analytical tools that can transform complex data into
actionable insights. This research introduces a novel approach by integrating
Large Language Models (LLMs), such as ChatGPT, into process mining tools,
making process analytics more accessible to a wider audience. The study aims to
investigate how ChatGPT enhances analytical capabilities, improves user
experience, increases accessibility, and optimizes the architectural frameworks
of process mining tools. The key innovation of this research lies in developing
a tailored prompt engineering strategy for each process mining submodule,
ensuring that the AI-generated outputs are accurate and relevant to the
context. The integration architecture follows an Extract, Transform, Load (ETL)
process, which includes various process mining engine modules and utilizes
zero-shot and optimized prompt engineering techniques. ChatGPT is connected via
APIs and receives structured outputs from the process mining modules, enabling
conversational interactions. To validate the effectiveness of this approach,
the researchers used data from 17 companies that employ BehfaLab's Process
Mining Tool. The results showed significant improvements in user experience,
with an expert panel rating 72% of the results as "Good". This research
contributes to the advancement of business process analysis methodologies by
combining process mining with artificial intelligence. Future research
directions include further optimization of prompt engineering, exploration of
integration with other AI technologies, and assessment of scalability across
various business environments. This study paves the way for continuous
innovation at the intersection of process mining and artificial intelligence,
promising to revolutionize the way businesses analyze and optimize their
processes.

摘要：<paragraph>在快速发展的商業流程管理領域中，對於分析工具的需求日益增加，這些工具可以將複雜的資料轉換為可操作的見解。本研究透過將大型語言模型 (LLM)，例如 ChatGPT，整合到流程探勘工具中，提出了一種創新的方法，讓流程分析更容易為更廣泛的受眾所使用。本研究旨在探討 ChatGPT 如何增強分析能力、改善使用者體驗、提高可及性，以及最佳化流程探勘工具的架構。本研究的主要創新在於為每個流程探勘子模組開發量身打造的提示工程策略，確保 AI 生成的輸出結果準確且與脈絡相關。整合架構遵循萃取、轉換、載入 (ETL) 流程，其中包括各種流程探勘引擎模組，並利用零次學習和最佳化的提示工程技術。ChatGPT 透過 API 連接，並從流程探勘模組接收結構化的輸出，進而實現對話式互動。為了驗證此方法的有效性，研究人員使用了採用 BehfaLab 流程探勘工具的 17 家公司的資料。結果顯示使用者體驗有顯著的改善，專家小組將 72% 的結果評為「良好」。本研究透過結合流程探勘與人工智慧，為商業流程分析方法的進步做出貢獻。未來的研究方向包括進一步最佳化提示工程、探索與其他 AI 技術的整合，以及評估在各種商業環境中的可擴充性。本研究為流程探勘與人工智慧的交會點鋪路，持續創新，有望革新企業分析和最佳化其流程的方式。</paragraph>

##### **Off-the-Shelf Neural Network Architectures for Forex Time Series Prediction come at a Cost**
2405.10679v1 by Theodoros Zafeiriou, Dimitris Kalles

Our study focuses on comparing the performance and resource requirements
between different Long Short-Term Memory (LSTM) neural network architectures
and an ANN specialized architecture for forex market prediction. We analyze the
execution time of the models as well as the resources consumed, such as memory
and computational power. Our aim is to demonstrate that the specialized
architecture not only achieves better results in forex market prediction but
also executes using fewer resources and in a shorter time frame compared to
LSTM architectures. This comparative analysis will provide significant insights
into the suitability of these two types of architectures for time series
prediction in the forex market environment.

摘要：我們的研究專注於比較不同長短期記憶 (LSTM) 神經網路架構與專門用於外匯市場預測的人工神經網路 (ANN) 架構之間的效能和資源需求。我們分析模型的執行時間以及消耗的資源，例如記憶體和運算能力。我們的目標是證明專門的架構不僅在外匯市場預測中獲得更好的結果，而且與 LSTM 架構相比，還使用更少的資源並在更短的時間內執行。這種比較分析將提供重要的見解，了解這兩種架構類型在適合外匯市場環境中的時間序列預測。

##### **Realistic Evaluation of Toxicity in Large Language Models**
2405.10659v1 by Tinh Son Luong, Thanh-Thien Le, Linh Ngo Van, Thien Huu Nguyen

Large language models (LLMs) have become integral to our professional
workflows and daily lives. Nevertheless, these machine companions of ours have
a critical flaw: the huge amount of data which endows them with vast and
diverse knowledge, also exposes them to the inevitable toxicity and bias. While
most LLMs incorporate defense mechanisms to prevent the generation of harmful
content, these safeguards can be easily bypassed with minimal prompt
engineering. In this paper, we introduce the new Thoroughly Engineered Toxicity
(TET) dataset, comprising manually crafted prompts designed to nullify the
protective layers of such models. Through extensive evaluations, we demonstrate
the pivotal role of TET in providing a rigorous benchmark for evaluation of
toxicity awareness in several popular LLMs: it highlights the toxicity in the
LLMs that might remain hidden when using normal prompts, thus revealing subtler
issues in their behavior.

摘要：大型語言模型 (LLM) 已成為我們專業工作流程和日常生活不可或缺的一部分。儘管如此，這些機器伴侶有一個嚴重的缺陷：賦予它們廣泛且多樣化知識的龐大數據，也讓它們面臨不可避免的毒性和偏見。雖然大多數 LLM 都包含防禦機制以防止產生有害內容，但這些防護措施可以用最小的提示工程輕鬆繞過。在本文中，我們介紹了新的徹底設計的毒性 (TET) 數據集，其中包含手動製作的提示，旨在消除此類模型的保護層。透過廣泛的評估，我們展示了 TET 在提供嚴格基準以評估多個流行 LLM 中的毒性意識方面的關鍵作用：它突出了 LLM 中的毒性，這些毒性在使用正常提示時可能仍然隱藏，從而揭示了它們行為中更微妙的問題。

##### **SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation**
2405.10650v1 by Ziyao Xu, Houfeng Wang

Compositional generalization is an important ability of language models and
has many different manifestations. For data-to-text generation, previous
research on this ability is limited to a single manifestation called
Systematicity and lacks consideration of large language models (LLMs), which
cannot fully cover practical application scenarios. In this work, we propose
SPOR, a comprehensive and practical evaluation method for compositional
generalization in data-to-text generation. SPOR includes four aspects of
manifestations (Systematicity, Productivity, Order invariance, and Rule
learnability) and allows high-quality evaluation without additional manual
annotations based on existing datasets. We demonstrate SPOR on two different
datasets and evaluate some existing language models including LLMs. We find
that the models are deficient in various aspects of the evaluation and need
further improvement. Our work shows the necessity for comprehensive research on
different manifestations of compositional generalization in data-to-text
generation and provides a framework for evaluation.

摘要：組合式概化是語言模型的一項重要能力，並有許多不同的表現形式。對於資料到文字的生成，先前對此能力的研究僅限於稱為系統性的單一表現形式，且缺乏對大型語言模型 (LLM) 的考量，而大型語言模型無法完全涵蓋實際應用場景。在這項工作中，我們提出 SPOR，一種針對資料到文字生成中的組合式概化進行全面且實用的評估方法。SPOR 包含四個面向的表現形式（系統性、生產力、順序不變性，以及規則可學習性），並允許在現有資料集的基礎上進行高品質的評估，而無需額外的標記。我們在兩個不同的資料集上展示 SPOR，並評估一些現有的語言模型，包括大型語言模型。我們發現這些模型在評估的各個面向都有所不足，需要進一步改進。我們的研究顯示出有必要對資料到文字生成中組合式概化的不同表現形式進行全面研究，並提供一個評估架構。

##### **Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting in Serial Federated Learning**
2405.10647v1 by Haoyue Song, Jiacheng Wang, Liansheng Wang

Federated Learning (FL) has gained attention for addressing data scarcity and
privacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable
performance, they face challenges in scenarios with diverse network speeds and
concerns about centralized control, especially in multi-institutional
collaborations like the medical domain. Serial FL presents an alternative
solution, circumventing these challenges by transferring model updates serially
between devices in a cyclical manner. Nevertheless, it is deemed inferior to
parallel FL in that (1) its performance shows undesirable fluctuations, and (2)
it converges to a lower plateau, particularly when dealing with non-IID data.
The observed phenomenon is attributed to catastrophic forgetting due to
knowledge loss from previous sites. In this paper, to overcome fluctuation and
low efficiency in the iterative learning and forgetting process, we introduce
cyclical weight consolidation (CWC), a straightforward yet potent approach
specifically tailored for serial FL. CWC employs a consolidation matrix to
regulate local optimization. This matrix tracks the significance of each
parameter on the overall federation throughout the entire training trajectory,
preventing abrupt changes in significant weights. During revisitation, to
maintain adaptability, old memory undergoes decay to incorporate new
information. Our comprehensive evaluations demonstrate that in various non-IID
settings, CWC mitigates the fluctuation behavior of the original serial FL
approach and enhances the converged performance consistently and significantly.
The improved performance is either comparable to or better than the parallel
vanilla.

摘要：联邦学习 (FL) 因解决数据稀缺和隐私问题而受到关注。虽然 FedAvg 等并行 FL 算法表现出色，但它们在网络速度多样化和集中控制的场景中面临挑战，尤其是在医疗领域等多机构协作中。串行 FL 提出了一种替代解决方案，通过循环方式在设备之间串行传输模型更新来规避这些挑战。然而，它被认为不如并行 FL，原因在于 (1) 它的性能表现出不希望的波动，(2) 它收敛到较低的平台，特别是在处理非 IID 数据时。观察到的现象归因于由于先前站点知识丢失而导致的灾难性遗忘。在本文中，为了克服迭代学习和遗忘过程中的波动和低效率，我们引入了循环权重合并 (CWC)，这是一种专门针对串行 FL 量身定制的简单而有效的方法。CWC 使用合并矩阵来调节局部优化。该矩阵跟踪整个训练轨迹中每个参数对整个联合的重要性，防止重要权重的突然变化。在重新访问期间，为了保持适应性，旧记忆会衰减以纳入新信息。我们的综合评估表明，在各种非 IID 设置中，CWC 减轻了原始串行 FL 方法的波动行为，并持续且显着地提高了收敛性能。改进后的性能与并行香草相当或更好。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Layer-Condensed KV Cache for Efficient Inference of Large Language Models**
2405.10637v1 by Haoyi Wu, Kewei Tu

Huge memory consumption has been a major bottleneck for deploying
high-throughput large language models in real-world applications. In addition
to the large number of parameters, the key-value (KV) cache for the attention
mechanism in the transformer architecture consumes a significant amount of
memory, especially when the number of layers is large for deep language models.
In this paper, we propose a novel method that only computes and caches the KVs
of a small number of layers, thus significantly saving memory consumption and
improving inference throughput. Our experiments on large language models show
that our method achieves up to 26$\times$ higher throughput than standard
transformers and competitive performance in language modeling and downstream
tasks. In addition, our method is orthogonal to existing transformer
memory-saving techniques, so it is straightforward to integrate them with our
model, achieving further improvement in inference efficiency. Our code is
available at https://github.com/whyNLP/LCKV.

摘要：龐大的記憶體消耗一直是部署高吞吐量大型語言模型於實際應用中的一大瓶頸。除了大量的參數外，Transformer架構中注意力機制的鍵值 (KV) 快取會消耗大量的記憶體，特別是在深度語言模型中層數龐大的情況下。在本文中，我們提出了一種新穎的方法，僅計算並快取少數層的 KV，從而顯著節省記憶體消耗並提高推論吞吐量。我們在大型語言模型上的實驗表明，與標準Transformer相比，我們的模型可實現高達 26 倍的吞吐量，且在語言建模和下游任務中具有競爭力。此外，我們的模型與現有的Transformer省記憶體技術正交，因此可以輕鬆地將它們與我們的模型整合，進一步提高推論效率。我們的程式碼可在 https://github.com/whyNLP/LCKV 取得。

##### **Beyond static AI evaluations: advancing human interaction evaluations for LLM harms and risks**
2405.10632v1 by Lujain Ibrahim, Saffron Huang, Lama Ahmad, Markus Anderljung

Model evaluations are central to understanding the safety, risks, and
societal impacts of AI systems. While most real-world AI applications involve
human-AI interaction, most current evaluations (e.g., common benchmarks) of AI
models do not. Instead, they incorporate human factors in limited ways,
assessing the safety of models in isolation, thereby falling short of capturing
the complexity of human-model interactions. In this paper, we discuss and
operationalize a definition of an emerging category of evaluations -- "human
interaction evaluations" (HIEs) -- which focus on the assessment of human-model
interactions or the process and the outcomes of humans using models. First, we
argue that HIEs can be used to increase the validity of safety evaluations,
assess direct human impact and interaction-specific harms, and guide future
assessments of models' societal impact. Second, we propose a safety-focused HIE
design framework -- containing a human-LLM interaction taxonomy -- with three
stages: (1) identifying the risk or harm area, (2) characterizing the use
context, and (3) choosing the evaluation parameters. Third, we apply our
framework to two potential evaluations for overreliance and persuasion risks.
Finally, we conclude with tangible recommendations for addressing concerns over
costs, replicability, and unrepresentativeness of HIEs.

摘要：模型評估對於了解 AI 系統的安全性、風險和社會影響至關重要。雖然大多數真實世界的 AI 應用程式都涉及人類與 AI 的互動，但目前大多數的 AI 模型評估（例如常見基準）並非如此。相反地，它們以有限的方式納入人類因素，孤立地評估模型的安全性，因此無法捕捉人機互動的複雜性。在本文中，我們討論並制定了一個新興評估類別的定義——「人機互動評估」（HIE），其重點在於評估人機互動或人類使用模型的過程和結果。首先，我們主張 HIE 可用於提高安全評估的效度，評估直接的人類影響和特定互動的危害，並指導未來對模型社會影響的評估。其次，我們提出一個以安全性為重點的 HIE 設計架構——包含人機 LLM 互動分類法——分為三個階段：(1) 識別風險或危害區域，(2) 描述使用情境，以及 (3) 選擇評估參數。第三，我們將我們的架構應用於過度依賴和說服風險的兩個潛在評估。最後，我們提出具體建議來解決對 HIE 成本、可複製性和非代表性的疑慮。

##### **Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges**
2405.10630v1 by Xiaoming Shi, Zeming Liu, Li Du, Yuxuan Wang, Hongru Wang, Yuhang Guo, Tong Ruan, Jie Xu, Shaoting Zhang

This paper surveys and organizes research works on medical dialog systems,
which is an important yet challenging task. Although these systems have been
surveyed in the medical community from an application perspective, a systematic
review from a rigorous technical perspective has to date remained noticeably
absent. As a result, an overview of the categories, methods, and evaluation of
medical dialogue systems remain limited and underspecified, hindering the
further improvement of this area. To fill this gap, we investigate an initial
pool of 325 papers from well-known computer science, and natural language
processing conferences and journals, and make an overview. Recently, large
language models have shown strong model capacity on downstream tasks, which
also reshaped medical dialog systems' foundation. Despite the alluring
practical application value, current medical dialogue systems still suffer from
problems. To this end, this paper lists the grand challenges of medical dialog
systems, especially of large language models.

摘要：這篇論文調查並整理了醫療對話系統的研究工作，這是一項重要且具有挑戰性的任務。儘管這些系統已從應用角度在醫療界進行調查，但迄今為止仍明顯缺乏從嚴謹技術角度進行的系統性回顧。因此，對醫療對話系統的類別、方法和評估的概述仍然有限且未指定，阻礙了該領域的進一步改進。為了填補這一空白，我們研究了來自知名計算機科學、自然語言處理會議和期刊的 325 篇論文的初始庫，並進行了概述。最近，大型語言模型在下游任務上表現出強大的模型能力，這也重塑了醫療對話系統的基礎。儘管具有誘人的實際應用價值，但當前的醫療對話系統仍然存在問題。為此，本文列出了醫療對話系統的重大挑戰，尤其是大型語言模型的挑戰。

##### **Dynamic data sampler for cross-language transfer learning in large language models**
2405.10626v1 by Yudong Li, Yuhao Feng, Wen Zhou, Zhe Zhao, Linlin Shen, Cheng Hou, Xianxu Hou

Large Language Models (LLMs) have gained significant attention in the field
of natural language processing (NLP) due to their wide range of applications.
However, training LLMs for languages other than English poses significant
challenges, due to the difficulty in acquiring large-scale corpus and the
requisite computing resources. In this paper, we propose ChatFlow, a
cross-language transfer-based LLM, to address these challenges and train large
Chinese language models in a cost-effective manner. We employ a mix of Chinese,
English, and parallel corpus to continuously train the LLaMA2 model, aiming to
align cross-language representations and facilitate the knowledge transfer
specifically to the Chinese language model. In addition, we use a dynamic data
sampler to progressively transition the model from unsupervised pre-training to
supervised fine-tuning. Experimental results demonstrate that our approach
accelerates model convergence and achieves superior performance. We evaluate
ChatFlow on popular Chinese and English benchmarks, the results indicate that
it outperforms other Chinese models post-trained on LLaMA-2-7B.

摘要：大型語言模型 (LLM) 因其廣泛的應用而在自然語言處理 (NLP) 領域備受關注。然而，訓練非英語語言的 LLM 具有重大挑戰，因為難以獲取大規模語料庫和必要的運算資源。在本文中，我們提出 ChatFlow，一個基於跨語言轉移的 LLM，以解決這些挑戰並以經濟有效的方式訓練大型中文語言模型。我們採用中文、英文和平行語料庫的組合來持續訓練 LLaMA2 模型，旨在對齊跨語言表示並促進知識轉移，特別是轉移到中文語言模型。此外，我們使用動態數據採樣器逐步將模型從無監督預訓練轉換為監督微調。實驗結果表明，我們的做法加速了模型收斂並實現了卓越的性能。我們在流行的中英文基準上評估 ChatFlow，結果表明，它優於在 LLaMA-2-7B 上進行後訓練的其他中文模型。

##### **Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction**
2405.10625v1 by Jiayun Pang, Ivan Vulić

Transformer-based encoder-decoder models have demonstrated impressive results
in chemical reaction prediction tasks. However, these models typically rely on
pretraining using tens of millions of unlabelled molecules, which can be
time-consuming and GPU-intensive. One of the central questions we aim to answer
in this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained
solely on language data, be effectively specialised for organic reaction
prediction through task-specific fine-tuning? We conduct a systematic empirical
study on several key issues of the process, including tokenisation, the impact
of (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding
algorithms at inference. Our key findings indicate that although being
pretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation
to fine-tune for reaction prediction, and thus become `chemistry domain
compatible' in the process. This suggests that GPU-intensive and expensive
pretraining on a large dataset of unlabelled molecules may be useful yet not
essential to leverage the power of language models for chemistry. All our
models achieve comparable Top-1 and Top-5 accuracy although some variation
across different models does exist. Notably, tokenisation and vocabulary
trimming slightly affect final performance but can speed up training and
inference; The most efficient greedy decoding strategy is very competitive
while only marginal gains can be achieved from more sophisticated decoding
algorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions
and benchmark their impact on organic reaction prediction, which may guide more
effective use of these state-of-the-art language models for chemistry-related
tasks in the future.

摘要：<paragraph>基於 Transformer 的編碼器-解碼器模型已在化學反應預測任務中展現令人印象深刻的成果。然而，這些模型通常依賴於使用數千萬個未標記分子的預訓練，這會耗時且耗費 GPU 資源。我們在這項工作中旨在回答的中心問題之一是：僅在語言資料上預訓練的編碼器-解碼器模型 FlanT5 和 ByT5，是否能透過特定任務的微調，有效地專門用於有機反應預測？我們對這個過程的幾個關鍵問題進行了系統性的實證研究，包括標記化、（面向 SMILES 的）預訓練、微調樣本效率和推理中的解碼演算法。我們的關鍵發現表明，儘管僅在語言任務上預訓練，FlanT5 和 ByT5 為反應預測的微調提供了穩固的基礎，因此在這個過程中變得「相容於化學領域」。這表明在大量的未標記分子資料集上進行耗費 GPU 資源且昂貴的預訓練可能很有用，但對於發揮語言模型在化學上的能力並非必要。儘管不同模型之間確實存在一些差異，但我們所有的模型都達到了相當的 Top-1 和 Top-5 準確率。值得注意的是，標記化和詞彙修剪會輕微影響最終效能，但可以加速訓練和推理；最有效率的貪婪解碼策略極具競爭力，而更精密的解碼演算法只能獲得邊際收益。總之，我們在幾個面向評估 FlanT5 和 ByT5，並評估它們對有機反應預測的影響，這可能有助於在未來更有效地使用這些最先進的語言模型來執行與化學相關的任務。</paragraph>

##### **Historically Relevant Event Structuring for Temporal Knowledge Graph Reasoning**
2405.10621v1 by Jinchuan Zhang, Bei Hui, Chong Mu, Ming Sun, Ling Tian

Temporal Knowledge Graph (TKG) reasoning focuses on predicting events through
historical information within snapshots distributed on a timeline. Existing
studies mainly concentrate on two perspectives of leveraging the history of
TKGs, including capturing evolution of each recent snapshot or correlations
among global historical facts. Despite the achieved significant
accomplishments, these models still fall short of (1) investigating the
influences of multi-granularity interactions across recent snapshots and (2)
harnessing the expressive semantics of significant links accorded with queries
throughout the entire history, especially events exerting a profound impact on
the future. These inadequacies restrict representation ability to reflect
historical dependencies and future trends thoroughly. To overcome these
drawbacks, we propose an innovative TKG reasoning approach towards
\textbf{His}torically \textbf{R}elevant \textbf{E}vents \textbf{S}tructuring
($\mathsf{HisRES}$). Concretely, $\mathsf{HisRES}$ comprises two distinctive
modules excelling in structuring historically relevant events within TKGs,
including a multi-granularity evolutionary encoder that captures structural and
temporal dependencies of the most recent snapshots, and a global relevance
encoder that concentrates on crucial correlations among events relevant to
queries from the entire history. Furthermore, $\mathsf{HisRES}$ incorporates a
self-gating mechanism for adaptively merging multi-granularity recent and
historically relevant structuring representations. Extensive experiments on
four event-based benchmarks demonstrate the state-of-the-art performance of
$\mathsf{HisRES}$ and indicate the superiority and effectiveness of structuring
historical relevance for TKG reasoning.

摘要：時序知識圖譜 (TKG) 推理專注於透過時序上分佈於快照中的歷史資訊來預測事件。現有研究主要集中於利用 TKG 歷史的兩個觀點，包括捕捉每個最近快照的演化或全局歷史事實之間的關聯性。儘管已取得顯著成就，但這些模型仍不足以 (1) 調查跨最近快照的多粒度互動影響，以及 (2) 利用與整個歷史中查詢相符的重要連結的表達語義，特別是對未來產生深遠影響的事件。這些不足限制了表示能力，無法徹底反映歷史依賴性和未來趨勢。為了克服這些缺點，我們提出了一個創新的 TKG 推理方法，朝向\textbf{歷}史\textbf{相}關\textbf{事}件\textbf{結}構（$\mathsf{HisRES}$）。具體來說，$\mathsf{HisRES}$ 包含兩個獨特的模組，擅長於建構 TKG 中歷史相關事件，包括一個多粒度演化編碼器，用於捕捉最近快照的結構和時間依賴性，以及一個全局相關編碼器，用於專注於與查詢相關的事件在整個歷史中的關鍵關聯性。此外，$\mathsf{HisRES}$ 結合了一個自門控機制，用於自適應地合併多粒度最近和歷史相關的建構表示。在四個基於事件的基準上進行的廣泛實驗證明了 $\mathsf{HisRES}$ 的最先進效能，並表明建構歷史相關性對於 TKG 推理的優越性和有效性。

##### **MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains**
2405.10620v1 by Zhaohuan Zhan, Lisha Yu, Sijie Yu, Guang Tan

In the Vision-and-Language Navigation (VLN) task, the agent is required to
navigate to a destination following a natural language instruction. While
learning-based approaches have been a major solution to the task, they suffer
from high training costs and lack of interpretability. Recently, Large Language
Models (LLMs) have emerged as a promising tool for VLN due to their strong
generalization capabilities. However, existing LLM-based methods face
limitations in memory construction and diversity of navigation strategies. To
address these challenges, we propose a suite of techniques. Firstly, we
introduce a method to maintain a topological map that stores navigation
history, retaining information about viewpoints, objects, and their spatial
relationships. This map also serves as a global action space. Additionally, we
present a Navigation Chain of Thoughts module, leveraging human navigation
examples to enrich navigation strategy diversity. Finally, we establish a
pipeline that integrates navigational memory and strategies with perception and
action prediction modules. Experimental results on the REVERIE and R2R datasets
show that our method effectively enhances the navigation ability of the LLM and
improves the interpretability of navigation reasoning.

摘要：在視覺與語言導航 (VLN) 任務中，代理必須遵循自然語言指令導航至目的地。雖然基於學習的方法一直是此任務的主要解決方案，但它們存在訓練成本高和缺乏可解釋性的問題。最近，大型語言模型 (LLM) 由於其強大的泛化能力而成為 VLN 的一個有前途的工具。然而，現有的基於 LLM 的方法在記憶體建構和導航策略的多樣性方面面臨限制。為了應對這些挑戰，我們提出了一系列技術。首先，我們介紹了一種維護拓撲地圖的方法，該地圖儲存導航歷史，保留有關視點、物件及其空間關係的資訊。此地圖還可用作全局動作空間。此外，我們展示了一個導航思維鏈模組，利用人類導航範例來豐富導航策略的多樣性。最後，我們建立了一個將導航記憶體和策略與感知和動作預測模組整合的管道。在 REVERIE 和 R2R 資料集上的實驗結果表明，我們的模型有效地增強了 LLM 的導航能力，並提高了導航推理的可解釋性。

##### **Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization**
2405.10616v1 by Yixin Ji, Yang Xiang, Juntao Li, Wei Chen, Zhongyi Liu, Kehai Chen, Min Zhang

In recent years, large language models (LLMs) have driven advances in natural
language processing. Still, their growing scale has increased the computational
burden, necessitating a balance between efficiency and performance. Low-rank
compression, a promising technique, reduces non-essential parameters by
decomposing weight matrices into products of two low-rank matrices. Yet, its
application in LLMs has not been extensively studied. The key to low-rank
compression lies in low-rank factorization and low-rank dimensions allocation.
To address the challenges of low-rank compression in LLMs, we conduct empirical
research on the low-rank characteristics of large models. We propose a low-rank
compression method suitable for LLMs. This approach involves precise estimation
of feature distributions through pooled covariance matrices and a Bayesian
optimization strategy for allocating low-rank dimensions. Experiments on the
LLaMA-2 models demonstrate that our method outperforms existing strong
structured pruning and low-rank compression techniques in maintaining model
performance at the same compression ratio.

摘要：近年來，大型語言模型 (LLM) 推動了自然語言處理的進展。然而，它們不斷擴大的規模增加了運算負擔，因此必須在效率和效能之間取得平衡。低秩壓縮是一種很有前景的技術，它透過將權重矩陣分解為兩個低秩矩陣的乘積來減少非必要的參數。然而，它在 LLM 中的應用尚未廣泛研究。低秩壓縮的關鍵在於低秩分解和低秩維度分配。為了應對 LLM 中低秩壓縮的挑戰，我們對大型模型的低秩特徵進行了實證研究。我們提出了一種適用於 LLM 的低秩壓縮方法。此方法涉及透過合併的共變異數矩陣精確估計特徵分佈，以及一種用於分配低秩維度的貝氏最佳化策略。在 LLaMA-2 模型上的實驗證明，我們的模型在相同的壓縮比下，優於現有的強結構剪枝和低秩壓縮技術，同時維持模型效能。

##### **A Certified Proof Checker for Deep Neural Network Verification**
2405.10611v1 by Remi Desmartin, Omri Isac, Ekaterina Komendantskaya, Kathrin Stark, Grant Passmore, Guy Katz

Recent advances in the verification of deep neural networks (DNNs) have
opened the way for broader usage of DNN verification technology in many
application areas, including safety-critical ones. DNN verifiers are themselves
complex programs that have been shown to be susceptible to errors and
imprecisions; this in turn has raised the question of trust in DNN verifiers.
One prominent attempt to address this issue is enhancing DNN verifiers with the
capability of producing proofs of their results that are subject to independent
algorithmic certification (proof checking). Formulations of proof production
and proof checking already exist on top of the state-of-the-art Marabou DNN
verifier. The native implementation of the proof checking algorithm for Marabou
was done in C++ and itself raised the question of trust in the code (e.g., in
the precision of floating point calculations or guarantees for implementation
soundness). Here, we present an alternative implementation of the Marabou proof
checking algorithm in Imandra -- an industrial functional programming language
and prover -- that allows us to obtain an implementation with formal
guarantees, including proofs of mathematical results underlying the algorithm,
such as the use of the Farkas lemma.

摘要：深度神经网络 (DNN) 验证的最新进展为在许多应用领域（包括安全关键领域）更广泛地使用 DNN 验证技术开辟了道路。DNN 验证器本身就是复杂的程序，已被证明容易出现错误和不精确；这反过来又引发了对 DNN 验证器的信任问题。解决此问题的突出尝试之一是增强 DNN 验证器生成其结果证明的能力，这些证明受独立算法认证（证明检查）。证明生成和证明检查的公式已经存在于最先进的 Marabou DNN 验证器之上。Marabou 的证明检查算法的本机实现是用 C++ 完成的，它本身引发了对代码信任的问题（例如，在浮点计算的精度或实现健全性的保证中）。在此，我们提出了 Marabou 证明检查算法在 Imandra 中的替代实现——一种工业函数式编程语言和证明器——它允许我们获得具有正式保证的实现，包括算法底层数学结果的证明，例如 Farkas 引理的使用。

##### **ECATS: Explainable-by-design concept-based anomaly detection for time series**
2405.10608v1 by Irene Ferfoglia, Gaia Saveri, Laura Nenzi, Luca Bortolussi

Deep learning methods for time series have already reached excellent
performances in both prediction and classification tasks, including anomaly
detection. However, the complexity inherent in Cyber Physical Systems (CPS)
creates a challenge when it comes to explainability methods. To overcome this
inherent lack of interpretability, we propose ECATS, a concept-based
neuro-symbolic architecture where concepts are represented as Signal Temporal
Logic (STL) formulae. Leveraging kernel-based methods for STL, concept
embeddings are learnt in an unsupervised manner through a cross-attention
mechanism. The network makes class predictions through these concept
embeddings, allowing for a meaningful explanation to be naturally extracted for
each input. Our preliminary experiments with a simple CPS-based dataset show
that our model is able to achieve great classification performance while
ensuring local interpretability.

摘要：深度學習方法在時間序列預測和分類任務中已經取得了極好的表現，包括異常偵測。然而，網路物理系統 (CPS) 固有的複雜性在可解釋性方法方面產生了挑戰。為了克服這種固有的不可解釋性，我們提出了 ECATS，一種基於概念的神經符號架構，其中概念表示為信號時序邏輯 (STL) 公式。利用基於核心的 STL 方法，概念嵌入是透過交叉注意機制以無監督的方式學習的。網路透過這些概念嵌入進行類別預測，允許為每個輸入自然地提取有意義的解釋。我們使用一個簡單的基於 CPS 的資料集進行的初步實驗表明，我們的模型能夠在確保局部可解釋性的同時實現良好的分類效能。

##### **UniCL: A Universal Contrastive Learning Framework for Large Time Series Models**
2405.10597v1 by Jiawei Li, Jingshu Peng, Haoyang Li, Lei Chen

Time-series analysis plays a pivotal role across a range of critical
applications, from finance to healthcare, which involves various tasks, such as
forecasting and classification. To handle the inherent complexities of
time-series data, such as high dimensionality and noise, traditional supervised
learning methods first annotate extensive labels for time-series data in each
task, which is very costly and impractical in real-world applications. In
contrast, pre-trained foundation models offer a promising alternative by
leveraging unlabeled data to capture general time series patterns, which can
then be fine-tuned for specific tasks. However, existing approaches to
pre-training such models typically suffer from high-bias and low-generality
issues due to the use of predefined and rigid augmentation operations and
domain-specific data training. To overcome these limitations, this paper
introduces UniCL, a universal and scalable contrastive learning framework
designed for pretraining time-series foundation models across cross-domain
datasets. Specifically, we propose a unified and trainable time-series
augmentation operation to generate pattern-preserved, diverse, and low-bias
time-series data by leveraging spectral information. Besides, we introduce a
scalable augmentation algorithm capable of handling datasets with varying
lengths, facilitating cross-domain pretraining. Extensive experiments on two
benchmark datasets across eleven domains validate the effectiveness of UniCL,
demonstrating its high generalization on time-series analysis across various
fields.

摘要：時間序列分析在從金融到醫療保健等一系列關鍵應用中發揮著舉足輕重的作用，其中涉及預測和分類等各種任務。為了處理時間序列資料固有的複雜性，例如高維度和雜訊，傳統的監督式學習方法首先為每個任務中的時間序列資料標註廣泛的標籤，這在實際應用中非常昂貴且不切實際。相比之下，預先訓練好的基礎模型提供了一個有希望的替代方案，通過利用未標籤的資料來捕捉一般時間序列模式，然後可以針對特定任務進行微調。然而，現有的預訓練此類模型的方法通常由於使用預定義和僵化的擴充操作以及特定領域的資料訓練而存在高偏差和低通用性的問題。為了克服這些限制，本文介紹了 UniCL，這是一個通用且可擴充的對比學習框架，旨在針對跨領域資料集預訓練時間序列基礎模型。具體來說，我們提出了一個統一且可訓練的時間序列擴充操作，通過利用光譜資訊生成模式保留、多樣且低偏差的時間序列資料。此外，我們引入了一個可擴充的擴充演算法，能夠處理長度不同的資料集，促進跨領域預訓練。在 11 個領域的兩個基準資料集上進行的廣泛實驗驗證了 UniCL 的有效性，證明了其在各種領域的時間序列分析中的高泛化性。

##### **Improving Point-based Crowd Counting and Localization Based on Auxiliary Point Guidance**
2405.10589v1 by I-Hsiang Chen, Wei-Ting Chen, Yu-Wei Liu, Ming-Hsuan Yang, Sy-Yen Kuo

Crowd counting and localization have become increasingly important in
computer vision due to their wide-ranging applications. While point-based
strategies have been widely used in crowd counting methods, they face a
significant challenge, i.e., the lack of an effective learning strategy to
guide the matching process. This deficiency leads to instability in matching
point proposals to target points, adversely affecting overall performance. To
address this issue, we introduce an effective approach to stabilize the
proposal-target matching in point-based methods. We propose Auxiliary Point
Guidance (APG) to provide clear and effective guidance for proposal selection
and optimization, addressing the core issue of matching uncertainty.
Additionally, we develop Implicit Feature Interpolation (IFI) to enable
adaptive feature extraction in diverse crowd scenarios, further enhancing the
model's robustness and accuracy. Extensive experiments demonstrate the
effectiveness of our approach, showing significant improvements in crowd
counting and localization performance, particularly under challenging
conditions. The source codes and trained models will be made publicly
available.

摘要：群眾計算和定位由於其廣泛的應用，在電腦視覺中變得越來越重要。雖然基於點的策略已廣泛用於群眾計算方法中，但它們面臨著一個重大的挑戰，即缺乏一個有效的學習策略來指導匹配過程。這種缺陷導致了匹配點建議與目標點的不穩定性，對整體效能產生了不利影響。為了解決這個問題，我們引入了一種有效的方法來穩定基於點的方法中的建議目標匹配。我們提出了輔助點指導 (APG) 來為建議選擇和最佳化提供清晰且有效的指導，解決了匹配不確定性的核心問題。此外，我們開發了隱式特徵插值 (IFI) 以在不同的群眾場景中實現自適應特徵提取，進一步增強了模型的穩健性和準確性。大量的實驗證明了我們方法的有效性，顯示出在群眾計算和定位效能方面有顯著的改進，特別是在具有挑戰性的條件下。原始碼和訓練好的模型將公開提供。

##### **RDRec: Rationale Distillation for LLM-based Recommendation**
2405.10587v1 by Xinfeng Wang, Jin Cui, Yoshimi Suzuki, Fumiyo Fukumoto

Large language model (LLM)-based recommender models that bridge users and
items through textual prompts for effective semantic reasoning have gained
considerable attention. However, few methods consider the underlying rationales
behind interactions, such as user preferences and item attributes, limiting the
reasoning capability of LLMs for recommendations. This paper proposes a
rationale distillation recommender (RDRec), a compact model designed to learn
rationales generated by a larger language model (LM). By leveraging rationales
from reviews related to users and items, RDRec remarkably specifies their
profiles for recommendations. Experiments show that RDRec achieves
state-of-the-art (SOTA) performance in both top-N and sequential
recommendations. Our source code is released at
https://github.com/WangXFng/RDRec.

摘要：基於大型語言模型 (LLM) 的推薦模型，透過文字提示橋接使用者和商品以進行有效的語義推理，已獲得相當多的關注。然而，很少有方法考量互動背後的根本道理，例如使用者偏好和商品屬性，這會限制 LLM 在推薦方面的推理能力。這篇論文提出了一個道理萃取推薦器 (RDRec)，這是一個緊湊的模型，旨在學習由較大的語言模型 (LM) 生成的道理。透過利用與使用者和商品相關的評論中的道理，RDRec 顯著地指定了他們用於推薦的個人資料。實驗顯示，RDRec 在前 N 名和順序推薦中都達到了最先進 (SOTA) 的效能。我們的原始程式碼可在 https://github.com/WangXFng/RDRec 取得。

##### **A Hybrid Deep Learning Framework for Stock Price Prediction Considering the Investor Sentiment of Online Forum Enhanced by Popularity**
2405.10584v1 by Huiyu Li, Junhua Hu

Stock price prediction has always been a difficult task for forecasters.
Using cutting-edge deep learning techniques, stock price prediction based on
investor sentiment extracted from online forums has become feasible. We propose
a novel hybrid deep learning framework for predicting stock prices. The
framework leverages the XLNET model to analyze the sentiment conveyed in user
posts on online forums, combines these sentiments with the post popularity
factor to compute daily group sentiments, and integrates this information with
stock technical indicators into an improved BiLSTM-highway model for stock
price prediction. Through a series of comparative experiments involving four
stocks on the Chinese stock market, it is demonstrated that the hybrid
framework effectively predicts stock prices. This study reveals the necessity
of analyzing investors' textual views for stock price prediction.

摘要：股票價格預測一直是預測者的一項艱鉅任務。
使用尖端的深度學習技術，從網上論壇中提取投資者情緒的股票價格預測已變得可行。我們提出了一個新穎的混合深度學習框架來預測股票價格。該框架利用 XLNET 模型來分析網上論壇中用戶帖子傳達的情緒，將這些情緒與帖子流行度因素相結合來計算每日群組情緒，並將這些資訊與股票技術指標整合到一個改進的 BiLSTM-highway 模型中，用於股票價格預測。通過一連串涉及中國股市上四檔股票的比較實驗，證明了混合框架有效地預測了股票價格。本研究揭示了分析投資者對股票價格預測的文字觀點的必要性。

##### **Future Aware Safe Active Learning of Time Varying Systems using Gaussian Processes**
2405.10581v1 by Markus Lange-Hegermann, Christoph Zimmer

Experimental exploration of high-cost systems with safety constraints, common
in engineering applications, is a challenging endeavor. Data-driven models
offer a promising solution, but acquiring the requisite data remains expensive
and is potentially unsafe. Safe active learning techniques prove essential,
enabling the learning of high-quality models with minimal expensive data points
and high safety. This paper introduces a safe active learning framework
tailored for time-varying systems, addressing drift, seasonal changes, and
complexities due to dynamic behavior. The proposed Time-aware Integrated Mean
Squared Prediction Error (T-IMSPE) method minimizes posterior variance over
current and future states, optimizing information gathering also in the time
domain. Empirical results highlight T-IMSPE's advantages in model quality
through toy and real-world examples. State of the art Gaussian processes are
compatible with T-IMSPE. Our theoretical contributions include a clear
delineation which Gaussian process kernels, domains, and weighting measures are
suitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE.

摘要：在工程应用中常見的具有安全約束的高成本系統的實驗探索是一項艱鉅的任務。數據驅動模型提供了一個有希望的解決方案，但獲取必要的數據仍然昂貴且潛在不安全。安全的主動學習技術被證明是必不可少的，它能用最少的昂貴數據點和高安全性來學習高質量的模型。本文介紹了一個針對時變系統的安全主動學習框架，解決了漂移、季節性變化以及由於動態行為導致的複雜性。所提出的時間感知綜合均方預測誤差 (T-IMSPE) 方法最小化了當前和未來狀態的後驗方差，並在時間域中優化信息收集。經驗結果通過玩具和真實世界的例子突出了 T-IMSPE 在模型質量方面的優勢。最先進的高斯過程與 T-IMSPE 兼容。我們的理論貢獻包括明確描述哪些高斯過程核、域和加權測量適合 T-IMSPE，甚至超越其非時間感知前身 IMSPE。

##### **A Hard Nut to Crack: Idiom Detection with Conversational Large Language Models**
2405.10579v1 by Francesca De Luca Fornaciari, Begoña Altuna, Itziar Gonzalez-Dios, Maite Melero

In this work, we explore idiomatic language processing with Large Language
Models (LLMs). We introduce the Idiomatic language Test Suite IdioTS, a new
dataset of difficult examples specifically designed by language experts to
assess the capabilities of LLMs to process figurative language at sentence
level. We propose a comprehensive evaluation methodology based on an idiom
detection task, where LLMs are prompted with detecting an idiomatic expression
in a given English sentence. We present a thorough automatic and manual
evaluation of the results and an extensive error analysis.

摘要：在這項工作中，我們探索使用大型語言模型 (LLM) 處理慣用語。我們介紹了慣用語測試套件 IdioTS，這是一個由語言專家特別設計的新困難範例資料集，用於評估 LLM 在句子層級處理比喻語言的能力。我們提出了一個基於慣用語偵測任務的綜合評估方法，其中 LLM 會被提示在給定的英文句子中偵測慣用語。我們對結果進行了徹底的自動和手動評估，並進行了廣泛的錯誤分析。

##### **Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks**
2405.10548v1 by Anwoy Chatterjee, Eshaan Tanwar, Subhabrata Dutta, Tanmoy Chakraborty

Large Language Models (LLMs) have transformed NLP with their remarkable
In-context Learning (ICL) capabilities. Automated assistants based on LLMs are
gaining popularity; however, adapting them to novel tasks is still challenging.
While colossal models excel in zero-shot performance, their computational
demands limit widespread use, and smaller language models struggle without
context. This paper investigates whether LLMs can generalize from labeled
examples of predefined tasks to novel tasks. Drawing inspiration from
biological neurons and the mechanistic interpretation of the Transformer
architecture, we explore the potential for information sharing across tasks. We
design a cross-task prompting setup with three LLMs and show that LLMs achieve
significant performance improvements despite no examples from the target task
in the context. Cross-task prompting leads to a remarkable performance boost of
107% for LLaMA-2 7B, 18.6% for LLaMA-2 13B, and 3.2% for GPT 3.5 on average
over zero-shot prompting, and performs comparable to standard in-context
learning. The effectiveness of generating pseudo-labels for in-task examples is
demonstrated, and our analyses reveal a strong correlation between the effect
of cross-task examples and model activation similarities in source and target
input tokens. This paper offers a first-of-its-kind exploration of LLMs'
ability to solve novel tasks based on contextual signals from different task
examples.

摘要：大型語言模型 (LLM) 以其卓越的語境學習 (ICL) 能力轉變了自然語言處理。基於 LLM 的自動化助理正變得越來越流行；然而，將它們適應到新任務仍然具有挑戰性。儘管大型模型在零次學習表現中表現出色，但它們的計算需求限制了廣泛使用，而較小的語言模型在沒有語境的情況下會遇到困難。本文探討了 LLM 是否可以從預定義任務的標記範例推廣到新任務。從生物神經元和 Transformer 架構的機械解釋中汲取靈感，我們探索了跨任務資訊共享的可能性。我們使用三個 LLM 設計了一個跨任務提示設定，並表明儘管語境中沒有目標任務的範例，但 LLM 仍可實現顯著的效能提升。跨任務提示會顯著提升效能，平均而言，LLaMA-2 7B 提升了 107%，LLaMA-2 13B 提升了 18.6%，GPT 3.5 提升了 3.2%，優於零次提示，並與標準語境學習表現相當。證明了為任務內範例產生偽標籤的有效性，我們的分析揭示了跨任務範例的效果與來源和目標輸入標記中模型激活相似性之間的強相關性。本文首次探討了 LLM 基於不同任務範例的語境信號解決新任務的能力。

##### **Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset**
2405.10542v1 by Jie Zhu, Junhui Li, Yalong Wen, Lifan Guo

In light of recent breakthroughs in large language models (LLMs) that have
revolutionized natural language processing (NLP), there is an urgent need for
new benchmarks to keep pace with the fast development of LLMs. In this paper,
we propose CFLUE, the Chinese Financial Language Understanding Evaluation
benchmark, designed to assess the capability of LLMs across various dimensions.
Specifically, CFLUE provides datasets tailored for both knowledge assessment
and application assessment. In knowledge assessment, it consists of 38K+
multiple-choice questions with associated solution explanations. These
questions serve dual purposes: answer prediction and question reasoning. In
application assessment, CFLUE features 16K+ test instances across distinct
groups of NLP tasks such as text classification, machine translation, relation
extraction, reading comprehension, and text generation. Upon CFLUE, we conduct
a thorough evaluation of representative LLMs. The results reveal that only
GPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\% in answer prediction
for knowledge assessment, suggesting that there is still substantial room for
improvement in current LLMs. In application assessment, although GPT-4 and
GPT-4-turbo are the top two performers, their considerable advantage over
lightweight LLMs is noticeably diminished. The datasets and scripts associated
with CFLUE are openly accessible at https://github.com/aliyun/cflue.

摘要：鑑於大型語言模型 (LLM) 的近期突破已徹底改變自然語言處理 (NLP)，因此迫切需要新的基準來跟上 LLM 的快速發展。在本文中，我們提出 CFLUE，即中文金融語言理解評估基準，旨在評估 LLM 在各個面向的能力。具體來說，CFLUE 提供了專門針對知識評估和應用評估而設計的資料集。在知識評估中，它包含 38K+ 個選擇題，並附有解決方案說明。這些問題有兩個目的：答案預測和問題推理。在應用評估中，CFLUE 在不同的 NLP 任務組中提供了 16K+ 個測試實例，例如文字分類、機器翻譯、關係抽取、閱讀理解和文字生成。在 CFLUE 上，我們對代表性 LLM 進行了徹底的評估。結果表明，只有 GPT-4 和 GPT-4-turbo 在知識評估的答案預測中達到 60% 以上的準確度，這表明當前 LLM 仍有很大的改進空間。在應用評估中，儘管 GPT-4 和 GPT-4-turbo 是表現最好的兩個，但它們相較於輕量級 LLM 的顯著優勢已明顯降低。與 CFLUE 相關的資料集和腳本可在 https://github.com/aliyun/cflue 公開取得。

##### **Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors**
2405.10529v1 by Jiachen Sun, Changsheng Wang, Jiongxiao Wang, Yiwei Zhang, Chaowei Xiao

Large language models have become increasingly prominent, also signaling a
shift towards multimodality as the next frontier in artificial intelligence,
where their embeddings are harnessed as prompts to generate textual content.
Vision-language models (VLMs) stand at the forefront of this advancement,
offering innovative ways to combine visual and textual data for enhanced
understanding and interaction. However, this integration also enlarges the
attack surface. Patch-based adversarial attack is considered the most realistic
threat model in physical vision applications, as demonstrated in many existing
literature. In this paper, we propose to address patched visual prompt
injection, where adversaries exploit adversarial patches to generate target
content in VLMs. Our investigation reveals that patched adversarial prompts
exhibit sensitivity to pixel-wise randomization, a trait that remains robust
even against adaptive attacks designed to counteract such defenses. Leveraging
this insight, we introduce SmoothVLM, a defense mechanism rooted in smoothing
techniques, specifically tailored to protect VLMs from the threat of patched
visual prompt injectors. Our framework significantly lowers the attack success
rate to a range between 0% and 5.0% on two leading VLMs, while achieving around
67.3% to 95.0% context recovery of the benign images, demonstrating a balance
between security and usability.

摘要：大型語言模型變得越來越重要，也標誌著人工智慧的下一前沿將轉向多模態，其中其嵌入被利用為提示來產生文字內容。視覺語言模型 (VLM) 站在這項進展的最前線，提供創新的方式來結合視覺和文字資料，以增強理解和互動。然而，這種整合也擴大了攻擊面。基於貼片的對抗性攻擊被認為是物理視覺應用中最逼真的威脅模型，如許多現有文獻中所展示的那樣。在本文中，我們提議解決貼片視覺提示注入的問題，其中對手利用對抗性貼片在 VLM 中產生目標內容。我們的調查顯示，貼片的對抗性提示對逐像素隨機化表現出敏感性，即使針對旨在對抗此類防禦的適應性攻擊，這種特徵仍然很強大。利用這一見解，我們引入了 SmoothVLM，這是一種根植於平滑技術的防禦機制，專門用於保護 VLM 免受貼片視覺提示注入器的威脅。我們的框架將攻擊成功率顯著降低到兩個領先的 VLM 上的 0% 到 5.0% 之間，同時實現了良性圖像的 67.3% 到 95.0% 的內容恢復，展示了安全性與可用性之間的平衡。

##### **Smart Expert System: Large Language Models as Text Classifiers**
2405.10523v1 by Zhiqiang Wang, Yiran Pang, Yanbin Lin

Text classification is a fundamental task in Natural Language Processing
(NLP), and the advent of Large Language Models (LLMs) has revolutionized the
field. This paper introduces the Smart Expert System, a novel approach that
leverages LLMs as text classifiers. The system simplifies the traditional text
classification workflow, eliminating the need for extensive preprocessing and
domain expertise. The performance of several LLMs, machine learning (ML)
algorithms, and neural network (NN) based structures is evaluated on four
datasets. Results demonstrate that certain LLMs surpass traditional methods in
sentiment analysis, spam SMS detection and multi-label classification.
Furthermore, it is shown that the system's performance can be further enhanced
through few-shot or fine-tuning strategies, making the fine-tuned model the top
performer across all datasets. Source code and datasets are available in this
GitHub repository: https://github.com/yeyimilk/llm-zero-shot-classifiers.

摘要：文本分類是自然語言處理 (NLP) 中的一項基本任務，而大型語言模型 (LLM) 的出現已經徹底改變了這個領域。本文介紹了智慧專家系統，這是一種新穎的方法，它利用 LLM 作為文本分類器。該系統簡化了傳統的文本分類工作流程，消除了對廣泛預處理和領域專業知識的需求。在四個資料集上評估了幾個 LLM、機器學習 (ML) 演算法和基於神經網路 (NN) 的結構的效能。結果表明，某些 LLM 在情緒分析、垃圾簡訊偵測和多標籤分類中優於傳統方法。此外，結果顯示，該系統的效能可以透過少量樣本學習或微調策略進一步增強，使微調模型在所有資料集中的表現都最佳。原始碼和資料集可在這個 GitHub 儲存庫中取得：https://github.com/yeyimilk/llm-zero-shot-classifiers。

##### **Towards Better Question Generation in QA-Based Event Extraction**
2405.10517v1 by Zijin Hong, Jian Liu

Event Extraction (EE) is an essential information extraction task that aims
to extract event-related information from unstructured texts. The paradigm of
this task has shifted from conventional classification-based methods to more
contemporary question-answering (QA)-based approaches. However, in QA-based EE,
the questions' quality dramatically affects the extraction accuracy, and how to
generate high-quality questions for QA-based EE still remains a challenge. In
this work, to tackle this challenge, we suggest four criteria to evaluate the
quality of a question and propose a reinforcement learning method for QA-Based
EE that can generate fluent, generalizable, and context-dependent questions and
provides clear guidance to QA models. The extensive experiments conducted on
ACE and RAMS datasets have strongly validated our approach's effectiveness,
which also demonstrates its robustness in scenarios with limited training data.

摘要：事件萃取 (EE) 是項重要的資訊萃取任務，旨在從非結構化文字中擷取與事件相關的資訊。此任務的典範已從傳統的基於分類的方法轉變為更現代的基於問答 (QA) 的方法。然而，在基於 QA 的 EE 中，問題的品質會大幅影響萃取的準確度，而如何為基於 QA 的 EE 產生高品質的問題仍然是一項挑戰。在這項工作中，為了應對此挑戰，我們建議四項準則來評估問題的品質，並提出一個基於 QA 的 EE 的強化學習方法，該方法可以產生流暢、可概括且依賴於脈絡的問題，並為 QA 模型提供明確的指導。在 ACE 和 RAMS 資料集上進行的廣泛實驗強烈驗證了我們方法的有效性，這也證明了它在訓練資料有限的情況下的穩健性。

##### **Language Models can Evaluate Themselves via Probability Discrepancy**
2405.10516v1 by Tingyu Xia, Bowen Yu, Yuan Wu, Yi Chang, Chang Zhou

In this paper, we initiate our discussion by demonstrating how Large Language
Models (LLMs), when tasked with responding to queries, display a more even
probability distribution in their answers if they are more adept, as opposed to
their less skilled counterparts. Expanding on this foundational insight, we
propose a new self-evaluation method ProbDiff for assessing the efficacy of
various LLMs. This approach obviates the necessity for an additional evaluation
model or the dependence on external, proprietary models like GPT-4 for
judgment. It uniquely utilizes the LLMs being tested to compute the probability
discrepancy between the initial response and its revised versions. A higher
discrepancy for a given query between two LLMs indicates a relatively weaker
capability. Our findings reveal that ProbDiff achieves results on par with
those obtained from evaluations based on GPT-4, spanning a range of scenarios
that include natural language generation (NLG) tasks such as translation,
summarization, and our proposed Xiaohongshu blog writing task, and benchmarks
for LLM evaluation like AlignBench, MT-Bench, and AlpacaEval, across LLMs of
varying magnitudes.

摘要：在本文中，我們透過展示大型語言模型 (LLM) 在回答查詢時，如果它們更熟練，則其答案的機率分佈會更平均，與技能較差的模型相反，來開啟我們的討論。在這個基礎見解的基礎上，我們提出一個新的自我評估方法 ProbDiff，用於評估各種 LLM 的效能。這種方法消除了對額外評估模型或依賴於 GPT-4 等外部、專有模型進行判斷的必要性。它獨特地利用受測的 LLM 來計算初始回應及其修訂版本之間的機率差異。對於給定的查詢，兩個 LLM 之間的差異越大，表示能力相對較弱。我們的研究結果顯示，ProbDiff 達到了與基於 GPT-4 的評估所獲得的結果相當的結果，涵蓋了各種情境，包括自然語言生成 (NLG) 任務，例如翻譯、摘要和我們提出的 Xiaohongshu 部落格寫作任務，以及跨越不同規模 LLM 的 LLM 評估基準，例如 AlignBench、MT-Bench 和 AlpacaEval。

##### **SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge**
2405.10497v1 by Bo Wu, Peiye Liu, Wen-Huang Cheng, Bei Liu, Zhaoyang Zeng, Jia Wang, Qiushi Huang, Jiebo Luo

Social Media Popularity Prediction (SMPP) is a crucial task that involves
automatically predicting future popularity values of online posts, leveraging
vast amounts of multimodal data available on social media platforms. Studying
and investigating social media popularity becomes central to various online
applications and requires novel methods of comprehensive analysis, multimodal
comprehension, and accurate prediction.
  SMP Challenge is an annual research activity that has spurred academic
exploration in this area. This paper summarizes the challenging task, data, and
research progress. As a critical resource for evaluating and benchmarking
predictive models, we have released a large-scale SMPD benchmark encompassing
approximately half a million posts authored by around 70K users. The research
progress analysis provides an overall analysis of the solutions and trends in
recent years. The SMP Challenge website (www.smp-challenge.com) provides the
latest information and news.

摘要：社群媒體熱門度預測 (SMPP) 是一項重要的任務，涉及自動預測社群媒體平台上線上貼文的未來熱門度數值，並利用社群媒體平台上大量的多模態資料。研究和調查社群媒體熱門度對於各種線上應用程式變得至關重要，並需要全面的分析、多模態理解和準確預測的新方法。
SMP Challenge 是一項年度研究活動，激勵了這個領域的學術探索。本文總結了具有挑戰性的任務、資料和研究進度。作為評估和基準化預測模型的重要資源，我們發布了一個大型 SMPD 基準，其中包含大約 70K 使用者撰寫的約 50 萬篇貼文。研究進度分析提供了對近年來解決方案和趨勢的整體分析。SMP Challenge 網站 (www.smp-challenge.com) 提供最新資訊和新聞。

##### **Automatic News Generation and Fact-Checking System Based on Language Processing**
2405.10492v1 by Xirui Peng, Qiming Xu, Zheng Feng, Haopeng Zhao, Lianghao Tan, Yan Zhou, Zecheng Zhang, Chenwei Gong, Yingqiao Zheng

This paper explores an automatic news generation and fact-checking system
based on language processing, aimed at enhancing the efficiency and quality of
news production while ensuring the authenticity and reliability of the news
content. With the rapid development of Natural Language Processing (NLP) and
deep learning technologies, automatic news generation systems are capable of
extracting key information from massive data and generating well-structured,
fluent news articles. Meanwhile, by integrating fact-checking technology, the
system can effectively prevent the spread of false news and improve the
accuracy and credibility of news. This study details the key technologies
involved in automatic news generation and factchecking, including text
generation, information extraction, and the application of knowledge graphs,
and validates the effectiveness of these technologies through experiments.
Additionally, the paper discusses the future development directions of
automatic news generation and fact-checking systems, emphasizing the importance
of further integration and innovation of technologies. The results show that
with continuous technological optimization and practical application, these
systems will play an increasingly important role in the future news industry,
providing more efficient and reliable news services.

摘要：本文探討了一種基於語言處理的自動新聞生成和事實查核系統，旨在提高新聞製作的效率和品質，同時確保新聞內容的真實性和可靠性。隨著自然語言處理 (NLP) 和深度學習技術的快速發展，自動新聞生成系統能夠從海量數據中提取關鍵資訊，並生成結構良好、流暢的新聞文章。同時，透過整合事實查核技術，該系統可以有效防止假新聞的傳播，提高新聞的準確性和可信度。本研究詳細說明了自動新聞生成和事實查核所涉及的關鍵技術，包括文本生成、資訊抽取和知識圖譜的應用，並透過實驗驗證了這些技術的有效性。此外，本文探討了自動新聞生成和事實查核系統的未來發展方向，強調進一步整合和創新技術的重要性。結果顯示，隨著技術的持續優化和實際應用，這些系統將在未來的新聞產業中發揮越來越重要的作用，提供更有效率和可靠的新聞服務。

##### **CNER: A tool Classifier of Named-Entity Relationships**
2405.10485v1 by Jefferson A. Peña Torres, Raúl E. Gutiérrez De Piñerez

We introduce CNER, an ensemble of capable tools for extraction of semantic
relationships between named entities in Spanish language. Built upon a
container-based architecture, CNER integrates different Named entity
recognition and relation extraction tools with a user-friendly interface that
allows users to input free text or files effortlessly, facilitating streamlined
analysis. Developed as a prototype version for the Natural Language Processing
(NLP) Group at Universidad del Valle, CNER serves as a practical educational
resource, illustrating how machine learning techniques can effectively tackle
diverse NLP tasks in Spanish. Our preliminary results reveal the promising
potential of CNER in advancing the understanding and development of NLP tools,
particularly within Spanish-language contexts.

摘要：我們介紹 CNER，一個能夠萃取西班牙語命名實體間語意關係的強大工具組。建構於一個基於容器的架構上，CNER 整合了不同的命名實體辨識與關係萃取工具，並配備一個使用者友善的介面，讓使用者可以輕鬆地輸入自由文字或檔案，進而促進簡化的分析。作為巴耶大學自然語言處理 (NLP) 小組的原型版本，CNER 是一個實用的教育資源，說明機器學習技術如何有效地處理西班牙語中的各種 NLP 任務。我們的初步結果顯示 CNER 在推進 NLP 工具的理解和發展方面具有潛力，特別是在西班牙語的語境中。

##### **Multi-Evidence based Fact Verification via A Confidential Graph Neural Network**
2405.10481v1 by Yuqing Lan, Zhenghao Liu, Yu Gu, Xiaoyuan Yi, Xiaohua Li, Liner Yang, Ge Yu

Fact verification tasks aim to identify the integrity of textual contents
according to the truthful corpus. Existing fact verification models usually
build a fully connected reasoning graph, which regards claim-evidence pairs as
nodes and connects them with edges. They employ the graph to propagate the
semantics of the nodes. Nevertheless, the noisy nodes usually propagate their
semantics via the edges of the reasoning graph, which misleads the semantic
representations of other nodes and amplifies the noise signals. To mitigate the
propagation of noisy semantic information, we introduce a Confidential Graph
Attention Network (CO-GAT), which proposes a node masking mechanism for
modeling the nodes. Specifically, CO-GAT calculates the node confidence score
by estimating the relevance between the claim and evidence pieces. Then, the
node masking mechanism uses the node confidence scores to control the noise
information flow from the vanilla node to the other graph nodes. CO-GAT
achieves a 73.59% FEVER score on the FEVER dataset and shows the generalization
ability by broadening the effectiveness to the science-specific domain.

摘要：事實驗證任務旨在根據真實語料庫識別文本內容的完整性。現有的事實驗證模型通常會建構一個完全連接的推理圖，將聲明證據對視為節點並用邊緣連接它們。它們使用圖表來傳播節點的語義。然而，有雜訊的節點通常會通過推理圖的邊緣傳播其語義，這會誤導其他節點的語義表示並放大雜訊信號。為了減輕有雜訊語義資訊的傳播，我們引入了一個機密圖注意力網路 (CO-GAT)，它提出了一個節點遮罩機制來對節點進行建模。具體來說，CO-GAT 透過估計聲明和證據片段之間的相關性來計算節點置信度分數。然後，節點遮罩機制使用節點置信度分數來控制從香草節點到其他圖節點的雜訊資訊流。CO-GAT 在 FEVER 資料集上獲得了 73.59% 的 FEVER 分數，並透過擴大對特定科學領域的有效性來展現其泛化能力。

##### **Analysis, Modeling and Design of Personalized Digital Learning Environment**
2405.10476v1 by Sanjaya Khanal, Shiva Raj Pokhrel

This research analyzes, models and develops a novel Digital Learning
Environment (DLE) fortified by the innovative Private Learning Intelligence
(PLI) framework. The proposed PLI framework leverages federated machine
learning (FL) techniques to autonomously construct and continuously refine
personalized learning models for individual learners, ensuring robust privacy
protection. Our approach is pivotal in advancing DLE capabilities, empowering
learners to actively participate in personalized real-time learning
experiences. The integration of PLI within a DLE also streamlines instructional
design and development demands for personalized teaching/learning. We seek ways
to establish a foundation for the seamless integration of FL into learning
systems, offering a transformative approach to personalized learning in digital
environments. Our implementation details and code are made public.

摘要：本研究分析、建模並開發了一個創新的私人學習智慧 (PLI) 框架所強化的數位學習環境 (DLE)。所提出的 PLI 框架利用聯邦機器學習 (FL) 技術，自主建構並持續優化個人化學習模型，以確保強大的隱私保護。我們的做法對於推進 DLE 能力至關重要，讓學習者能夠積極參與個人化的即時學習體驗。在 DLE 中整合 PLI 也簡化了個人化教學/學習的教學設計和開發需求。我們尋求方法，為將 FL 無縫整合到學習系統中建立基礎，提供數位環境中個人化學習的轉型方法。我們的實作詳細資訊和程式碼已公開。

##### **Rethinking ChatGPT's Success: Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs' Prompting**
2405.10474v1 by Xinzhe Li, Ming Liu

Over the last decade, a wide range of training and deployment strategies for
Large Language Models (LLMs) have emerged. Among these, the prompting paradigms
of Auto-regressive LLMs (AR-LLMs) have catalyzed a significant surge in
Artificial Intelligence (AI). This paper aims to emphasize the significance of
utilizing free-form modalities (forms of input and output) and verbal free-form
contexts as user-directed channels (methods for transforming modalities) for
downstream deployment. Specifically, we analyze the structure of modalities
within both two types of LLMs and six task-specific channels during deployment.
From the perspective of users, our analysis introduces and applies the
analytical metrics of task customizability, transparency, and complexity to
gauge their usability, highlighting the superior nature of AR-LLMs' prompting
paradigms. Moreover, we examine the stimulation of diverse cognitive behaviors
in LLMs through the adoption of free-form text and verbal contexts, mirroring
human linguistic expressions of such behaviors. We then detail four common
cognitive behaviors to underscore how AR-LLMs' prompting successfully imitate
human-like behaviors using this free-form modality and channel. Lastly, the
potential for improving LLM deployment, both as autonomous agents and within
multi-agent systems, is identified via cognitive behavior concepts and
principles.

摘要：在過去十年中，出現了各種訓練和部署策略，用於大型語言模型 (LLM)。其中，自迴歸 LLM (AR-LLM) 的提示範例已催化了人工智慧 (AI) 的顯著激增。本文旨在強調利用自由形式模態（輸入和輸出形式）和口頭自由形式上下文作為使用者導向通道（轉換模態的方法）對於下游部署的重要性。具體來說，我們分析了在部署期間兩種 LLM 和六個特定任務通道中的模態結構。從使用者的角度來看，我們的分析引入了任務可自訂性、透明度和複雜性的分析指標，並應用這些指標來評估它們的可用性，突出了 AR-LLM 提示範例的優越性。此外，我們透過採用自由形式文字和口頭語境來檢視 LLM 中各種認知行為的刺激，反映出人類對此類行為的語言表達。然後，我們詳細說明四種常見的認知行為，以強調 AR-LLM 的提示如何成功地使用這種自由形式模態和通道來模仿類人行為。最後，透過認知行為概念和原則，確定了改善 LLM 部署的潛力，無論是作為自主代理還是多代理系統。

##### **Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents**
2405.10467v1 by Yue Liu, Sin Kit Lo, Qinghua Lu, Liming Zhu, Dehai Zhao, Xiwei Xu, Stefan Harrer, Jon Whittle

Foundation model-enabled generative artificial intelligence facilitates the
development and implementation of agents, which can leverage distinguished
reasoning and language processing capabilities to takes a proactive, autonomous
role to pursue users' goals. Nevertheless, there is a lack of systematic
knowledge to guide practitioners in designing the agents considering challenges
of goal-seeking (including generating instrumental goals and plans), such as
hallucinations inherent in foundation models, explainability of reasoning
process, complex accountability, etc. To address this issue, we have performed
a systematic literature review to understand the state-of-the-art foundation
model-based agents and the broader ecosystem. In this paper, we present a
pattern catalogue consisting of 16 architectural patterns with analyses of the
context, forces, and trade-offs as the outcomes from the previous literature
review. The proposed catalogue can provide holistic guidance for the effective
use of patterns, and support the architecture design of foundation model-based
agents by facilitating goal-seeking and plan generation.

摘要：由基础模型支持的生成式人工智能促进了代理的开发和实施，代理可以利用杰出的推理和语言处理能力来采取主动、自主的角色来追求用户的目标。然而，缺乏系统化的知识来指导从业者在考虑目标寻求（包括生成工具性目标和计划）的挑战的情况下设计代理，例如基础模型中固有的幻觉、推理过程的可解释性、复杂的责任制等。为了解决这个问题，我们执行了一项系统的文献综述，以了解基于基础模型的最新代理和更广泛的生态系统。在本文中，我们提出了一个模式目录，其中包含 16 个架构模式，其中包含对上下文、力量和权衡的分析，作为先前文献综述的结果。提议的目录可以为模式的有效使用提供全面的指导，并通过促进目标寻求和计划生成来支持基于基础模型的代理的架构设计。

##### **Navigating Public Sentiment in the Circular Economy through Topic Modelling and Hyperparameter Optimisation**
2405.10452v1 by Junhao Song, Yingfang Yuan, Kaiwen Chang, Bing Xu, Jin Xuan, Wei Pang

To advance the circular economy (CE), it is crucial to gain insights into the
evolution of public sentiments, cognitive pathways of the masses concerning
circular products and digital technology, and recognise the primary concerns.
To achieve this, we collected data related to the CE from diverse platforms
including Twitter, Reddit, and The Guardian. This comprehensive data collection
spanned across three distinct strata of the public: the general public,
professionals, and official sources. Subsequently, we utilised three topic
models on the collected data. Topic modelling represents a type of data-driven
and machine learning approach for text mining, capable of automatically
categorising a large number of documents into distinct semantic groups.
Simultaneously, these groups are described by topics, and these topics can aid
in understanding the semantic content of documents at a high level. However,
the performance of topic modelling may vary depending on different
hyperparameter values. Therefore, in this study, we proposed a framework for
topic modelling with hyperparameter optimisation for CE and conducted a series
of systematic experiments to ensure that topic models are set with appropriate
hyperparameters and to gain insights into the correlations between the CE and
public opinion based on well-established models. The results of this study
indicate that concerns about sustainability and economic impact persist across
all three datasets. Official sources demonstrate a higher level of engagement
with the application and regulation of CE. To the best of our knowledge, this
study is pioneering in investigating various levels of public opinions
concerning CE through topic modelling with the exploration of hyperparameter
optimisation.

摘要：<paragraph>為了推動循環經濟 (CE)，深入了解大眾的情緒演變、大眾對循環產品和數位科技的認知途徑，並找出主要問題至關重要。為達成此目標，我們從 Twitter、Reddit 和 The Guardian 等不同平台收集了與 CE 相關的資料。這項全面的資料收集涵蓋了大眾的三個不同階層：一般大眾、專業人士和官方消息來源。接著，我們對收集到的資料使用三個主題模型。主題建模代表一種由資料驅動的機器學習方法，用於文字探勘，能夠自動將大量文件分類成不同的語意群組。同時，這些群組由主題描述，而這些主題有助於在高層級了解文件的語意內容。然而，主題建模的效能可能會因不同的超參數值而異。因此，在這項研究中，我們提出了具有超參數最佳化的主題建模架構，並進行了一系列的系統性實驗，以確保主題模型設定了適當的超參數，並根據完善的模型深入了解 CE 與輿論之間的關聯性。這項研究的結果顯示，對永續性和經濟影響的疑慮存在於所有三個資料集中。官方消息來源顯示出對 CE 的應用和法規有較高的參與度。據我們所知，這項研究是透過主題建模，並探討超參數最佳化，來調查大眾對 CE 的不同意見層級的先驅。</paragraph>

##### **Dynamic In-context Learning with Conversational Models for Data Extraction and Materials Property Prediction**
2405.10448v1 by Chinedu Ekuma

The advent of natural language processing and large language models (LLMs)
has revolutionized the extraction of data from unstructured scholarly papers.
However, ensuring data trustworthiness remains a significant challenge. In this
paper, we introduce PropertyExtractor, an open-source tool that leverages
advanced conversational LLMs like Google Gemini-Pro and OpenAI GPT-4, blends
zero-shot with few-shot in-context learning, and employs engineered prompts for
the dynamic refinement of structured information hierarchies, enabling
autonomous, efficient, scalable, and accurate identification, extraction, and
verification of material property data. Our tests on material data demonstrate
precision and recall exceeding 93% with an error rate of approximately 10%,
highlighting the effectiveness and versatility of the toolkit. We apply
PropertyExtractor to generate a database of 2D material thicknesses, a critical
parameter for device integration. The rapid evolution of the field has outpaced
both experimental measurements and computational methods, creating a
significant data gap. Our work addresses this gap and showcases the potential
of PropertyExtractor as a reliable and efficient tool for the autonomous
generation of diverse material property databases, advancing the field.

摘要：自然語言處理和大型語言模型 (LLM) 的出現徹底改變了從非結構化學術論文中提取數據的方式。然而，確保數據可信度仍然是一項重大挑戰。在本文中，我們介紹了 PropertyExtractor，這是一個開源工具，它利用了 Google Gemini-Pro 和 OpenAI GPT-4 等先進的對話式 LLM，將零次學習與少次學習情境學習相結合，並採用工程提示來動態優化結構化信息層次結構，從而實現材料屬性數據的自主、高效、可擴展且準確的識別、提取和驗證。我們對材料數據的測試表明，精度和召回率超過 93%，錯誤率約為 10%，突顯了該工具包的有效性和多功能性。我們應用 PropertyExtractor 生成了 2D 材料厚度的數據庫，這是設備集成的關鍵參數。該領域的快速發展已經超過了實驗測量和計算方法，從而產生了重大的數據差距。我們的研究解決了這一差距，並展示了 PropertyExtractor 作為一個可靠且高效的工具的潛力，用於自主生成多樣化的材料屬性數據庫，從而推動該領域的發展。

##### **Tell me more: Intent Fulfilment Framework for Enhancing User Experiences in Conversational XAI**
2405.10446v1 by Anjana Wijekoon, David Corsar, Nirmalie Wiratunga, Kyle Martin, Pedram Salimi

The evolution of Explainable Artificial Intelligence (XAI) has emphasised the
significance of meeting diverse user needs. The approaches to identifying and
addressing these needs must also advance, recognising that explanation
experiences are subjective, user-centred processes that interact with users
towards a better understanding of AI decision-making. This paper delves into
the interrelations in multi-faceted XAI and examines how different types of
explanations collaboratively meet users' XAI needs. We introduce the Intent
Fulfilment Framework (IFF) for creating explanation experiences. The novelty of
this paper lies in recognising the importance of "follow-up" on explanations
for obtaining clarity, verification and/or substitution. Moreover, the
Explanation Experience Dialogue Model integrates the IFF and "Explanation
Followups" to provide users with a conversational interface for exploring their
explanation needs, thereby creating explanation experiences. Quantitative and
qualitative findings from our comparative user study demonstrate the impact of
the IFF in improving user engagement, the utility of the AI system and the
overall user experience. Overall, we reinforce the principle that "one
explanation does not fit all" to create explanation experiences that guide the
complex interaction through conversation.

摘要：可解釋人工智慧 (XAI) 的演進強調滿足多元使用者需求的重要性。辨識及滿足這些需求的方法也必須進步，認知到解釋體驗是主觀、以使用者為中心的流程，與使用者互動以期更了解 AI 決策制定。本文探討多面向 XAI 中的相互關係，並探討不同類型的解釋如何協作滿足使用者的 XAI 需求。我們介紹意圖滿足架構 (IFF)，用於建立解釋體驗。本文的新穎性在於認知到「後續」對解釋的重要性，以獲得清晰度、驗證和/或替換。此外，解釋體驗對話模式整合 IFF 和「解釋後續」，為使用者提供對話介面以探索其解釋需求，進而建立解釋體驗。我們比較使用者研究中的量化和質化發現，證明 IFF 在改善使用者參與度、AI 系統的效用和整體使用者體驗方面的影響。總體而言，我們強化「一種解釋無法適用所有」的原則，以建立解釋體驗，透過對話引導複雜的互動。

##### **Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation**
2405.10443v1 by Matthew Raffel, Victor Agostinelli, Lizhong Chen

Large language models (LLMs) have achieved state-of-the-art performance in
various language processing tasks, motivating their adoption in simultaneous
translation. Current fine-tuning methods to adapt LLMs for simultaneous
translation focus on prompting optimization strategies using either data
augmentation or prompt structure modifications. However, these methods suffer
from several issues, such as an unnecessarily expanded training set,
computational inefficiency from dumping the KV cache, increased prompt sizes,
or restriction to a single decision policy. To eliminate these issues, we
propose a new paradigm in fine-tuning LLMs for simultaneous translation, called
SimulMask. It utilizes a novel attention mask technique that models
simultaneous translation during fine-tuning by masking attention connections
under a desired decision policy. Applying the proposed SimulMask on a Falcon
LLM for the IWSLT 2017 dataset, we have observed a significant translation
quality improvement compared to state-of-the-art prompting optimization
strategies on three language pairs when averaged across four different latency
regimes while reducing the computational cost.

摘要：大型語言模型 (LLM) 在各種語言處理任務中都達到了最先進的效能，促使它們被採用在即時翻譯中。目前用於調整 LLM 以適應即時翻譯的微調方法，著重於使用資料擴充或提示結構修改的提示最佳化策略。然而，這些方法會產生幾個問題，例如訓練集不必要地擴充、清除 KV 快取的運算效率低、提示大小增加，或限制於單一決策政策。為了消除這些問題，我們提出了一種微調 LLM 以適應即時翻譯的新模式，稱為 SimulMask。它利用一種新穎的注意力遮罩技術，透過在所需決策政策下遮罩注意力連接，在微調期間對即時翻譯進行建模。將建議的 SimulMask 應用於 IWSLT 2017 資料集的 Falcon LLM，我們觀察到與最先進的提示最佳化策略相比，在四種不同的延遲模式下取平均值時，三種語言對的翻譯品質有顯著的提升，同時降低了運算成本。

##### **Retrieving and Refining: A Hybrid Framework with Large Language Models for Rare Disease Identification**
2405.10440v1 by Jinge Wu, Hang Dong, Zexi Li, Arijit Patra, Honghan Wu

The infrequency and heterogeneity of clinical presentations in rare diseases
often lead to underdiagnosis and their exclusion from structured datasets. This
necessitates the utilization of unstructured text data for comprehensive
analysis. However, the manual identification from clinical reports is an
arduous and intrinsically subjective task. This study proposes a novel hybrid
approach that synergistically combines a traditional dictionary-based natural
language processing (NLP) tool with the powerful capabilities of large language
models (LLMs) to enhance the identification of rare diseases from unstructured
clinical notes. We comprehensively evaluate various prompting strategies on six
large language models (LLMs) of varying sizes and domains (general and
medical). This evaluation encompasses zero-shot, few-shot, and
retrieval-augmented generation (RAG) techniques to enhance the LLMs' ability to
reason about and understand contextual information in patient reports. The
results demonstrate effectiveness in rare disease identification, highlighting
the potential for identifying underdiagnosed patients from clinical notes.

摘要：罕見疾病的臨床表現不頻繁且異質，這常常導致診斷不足，且無法納入結構化資料集。這使得必須利用非結構化文字資料進行全面分析。然而，從臨床報告中進行手動辨識是一項艱鉅且本質上主觀的任務。本研究提出了一種新穎的混合方法，該方法協同結合了傳統的基於詞典的自然語言處理 (NLP) 工具與大型語言模型 (LLM) 的強大功能，以增強從非結構化臨床筆記中辨識罕見疾病的能力。我們對六個不同大小和領域（一般和醫療）的大型語言模型 (LLM) 進行了各種提示策略的全面評估。此評估包含零次學習、少量學習和檢索增強生成 (RAG) 技術，以增強 LLM 推論和了解患者報告中背景資訊的能力。結果證明了罕見疾病辨識的有效性，突顯了從臨床筆記中辨識診斷不足患者的潛力。

##### **Positional encoding is not the same as context: A study on positional encoding for Sequential recommendation**
2405.10436v1 by Alejo Lopez-Avila, Jinhua Du, Abbas Shimary, Ze Li

The expansion of streaming media and e-commerce has led to a boom in
recommendation systems, including Sequential recommendation systems, which
consider the user's previous interactions with items. In recent years, research
has focused on architectural improvements such as transformer blocks and
feature extraction that can augment model information. Among these features are
context and attributes. Of particular importance is the temporal footprint,
which is often considered part of the context and seen in previous publications
as interchangeable with positional information. Other publications use
positional encodings with little attention to them. In this paper, we analyse
positional encodings, showing that they provide relative information between
items that are not inferable from the temporal footprint. Furthermore, we
evaluate different encodings and how they affect metrics and stability using
Amazon datasets. We added some new encodings to help with these problems along
the way. We found that we can reach new state-of-the-art results by finding the
correct positional encoding, but more importantly, certain encodings stabilise
the training.

摘要：串流媒體和電子商務的擴張導致推薦系統的蓬勃發展，包括順序推薦系統，它會考量使用者先前與商品的互動。近年來，研究專注於架構的改善，例如Transformer區塊和可以擴充模型資訊的特徵萃取。這些特徵包括脈絡和屬性。其中特別重要的是時間足跡，它通常被視為脈絡的一部分，在先前的出版物中被視為與位置資訊可以互換。其他出版物使用位置編碼，但鮮少關注它們。在本文中，我們分析位置編碼，證明它們提供了商品之間的相對資訊，而時間足跡無法推論出這些資訊。此外，我們評估不同的編碼以及它們如何影響指標和穩定性，並使用 Amazon 資料集。在此過程中，我們新增了一些新的編碼來協助解決這些問題。我們發現，透過找出正確的位置編碼，我們可以達到新的最先進結果，但更重要的是，某些編碼可以穩定訓練。

##### **Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models**
2405.10431v1 by Shaz Furniturewala, Surgan Jandial, Abhinav Java, Pragyan Banerjee, Simra Shahid, Sumit Bhatia, Kokil Jaidka

Existing debiasing techniques are typically training-based or require access
to the model's internals and output distributions, so they are inaccessible to
end-users looking to adapt LLM outputs for their particular needs. In this
study, we examine whether structured prompting techniques can offer
opportunities for fair text generation. We evaluate a comprehensive
end-user-focused iterative framework of debiasing that applies System 2
thinking processes for prompts to induce logical, reflective, and critical text
generation, with single, multi-step, instruction, and role-based variants. By
systematically evaluating many LLMs across many datasets and different
prompting strategies, we show that the more complex System 2-based Implicative
Prompts significantly improve over other techniques demonstrating lower mean
bias in the outputs with competitive performance on the downstream tasks. Our
work offers research directions for the design and the potential of
end-user-focused evaluative frameworks for LLM use.

摘要：現有的去偏見技術通常是基於訓練或需要存取模型的內部結構和輸出分佈，因此對於尋求調整 LLM 輸出以符合其特定需求的最終使用者而言，這些技術是無法存取的。在本研究中，我們探討結構化提示技術是否能為公平的文字生成提供機會。我們評估了一個全面的、以最終使用者為中心的去偏見迭代架構，該架構應用系統 2 思考程序來提示，以引發邏輯的、反思的和批判性的文字生成，並採用單一、多步驟、指令和基於角色的變體。透過系統性地評估許多 LLM、跨越許多資料集和不同的提示策略，我們表明更複雜的基於系統 2 的暗示提示顯著優於其他技術，在輸出中展現較低的平均偏差，且在下游任務中具有競爭力。我們的研究為 LLM 使用的設計和最終使用者為中心的評估架構的潛力提供了研究方向。

##### **Memory-efficient Energy-adaptive Inference of Pre-Trained Models on Batteryless Embedded Systems**
2405.10426v1 by Pietro Farina, Subrata Biswas, Eren Yıldız, Khakim Akhunov, Saad Ahmed, Bashima Islam, Kasım Sinan Yıldırım

Batteryless systems frequently face power failures, requiring extra runtime
buffers to maintain inference progress and leaving only a memory space for
storing ultra-tiny deep neural networks (DNNs). Besides, making these models
responsive to stochastic energy harvesting dynamics during inference requires a
balance between inference accuracy, latency, and energy overhead. Recent works
on compression mostly focus on time and memory, but often ignore energy
dynamics or significantly reduce the accuracy of pre-trained DNNs. Existing
energy-adaptive inference works modify the architecture of pre-trained models
and have significant memory overhead. Thus, energy-adaptive and accurate
inference of pre-trained DNNs on batteryless devices with extreme memory
constraints is more challenging than traditional microcontrollers. We combat
these issues by proposing FreeML, a framework to optimize pre-trained DNN
models for memory-efficient and energy-adaptive inference on batteryless
systems. FreeML comprises (1) a novel compression technique to reduce the model
footprint and runtime memory requirements simultaneously, making them
executable on extremely memory-constrained batteryless platforms; and (2) the
first early exit mechanism that uses a single exit branch for all exit points
to terminate inference at any time, making models energy-adaptive with minimal
memory overhead. Our experiments showed that FreeML reduces the model sizes by
up to $95 \times$, supports adaptive inference with a $2.03-19.65 \times$ less
memory overhead, and provides significant time and energy benefits with only a
negligible accuracy drop compared to the state-of-the-art.

摘要：<paragraph>無電池系統經常面臨電力故障，需要額外的執行時間緩衝區來維持推論進度，並且只留下記憶體空間來儲存極小的深度神經網路 (DNN)。此外，讓這些模型在推論期間對隨機能量收集動態做出反應，需要在推論準確度、延遲和能源開銷之間取得平衡。最近關於壓縮的研究大多集中在時間和記憶體上，但經常忽略能源動態或顯著降低預訓練 DNN 的準確度。現有的能源自適應推論工作會修改預訓練模型的架構，並且有顯著的記憶體開銷。因此，在記憶體限制極大的無電池裝置上進行預訓練 DNN 的能源自適應和準確推論，比傳統的微控制器更具挑戰性。我們透過提出 FreeML 來解決這些問題，這是一個用於最佳化預訓練 DNN 模型，以在無電池系統上進行記憶體高效且能源自適應推論的框架。FreeML 包含：(1) 一種新穎的壓縮技術，可同時減少模型佔用空間和執行時間記憶體需求，使其可以在記憶體限制極大的無電池平台上執行；以及 (2) 第一個早期退出機制，它對所有退出點使用單一退出分支來隨時終止推論，讓模型在最小的記憶體開銷下具有能源自適應性。我們的實驗顯示，與最先進的技術相比，FreeML 將模型大小減少了 $95 \times$，支援自適應推論，記憶體開銷減少了 $2.03-19.65 \times$，並且僅有微小的準確度下降，即可提供顯著的時間和能源效益。</paragraph>

##### **Vision Transformers for End-to-End Vision-Based Quadrotor Obstacle Avoidance**
2405.10391v1 by Anish Bhattacharya, Nishanth Rao, Dhruv Parikh, Pratik Kunapuli, Nikolai Matni, Vijay Kumar

We demonstrate the capabilities of an attention-based end-to-end approach for
high-speed quadrotor obstacle avoidance in dense, cluttered environments, with
comparison to various state-of-the-art architectures. Quadrotor unmanned aerial
vehicles (UAVs) have tremendous maneuverability when flown fast; however, as
flight speed increases, traditional vision-based navigation via independent
mapping, planning, and control modules breaks down due to increased sensor
noise, compounding errors, and increased processing latency. Thus,
learning-based, end-to-end planning and control networks have shown to be
effective for online control of these fast robots through cluttered
environments. We train and compare convolutional, U-Net, and recurrent
architectures against vision transformer models for depth-based end-to-end
control, in a photorealistic, high-physics-fidelity simulator as well as in
hardware, and observe that the attention-based models are more effective as
quadrotor speeds increase, while recurrent models with many layers provide
smoother commands at lower speeds. To the best of our knowledge, this is the
first work to utilize vision transformers for end-to-end vision-based quadrotor
control.

摘要：我們展示了基於注意力的端對端方法在密集、混亂環境中高速四旋翼障礙物避障的能力，並與各種最先進的架構進行了比較。四旋翼無人機 (UAV) 在快速飛行時具有極大的機動性；然而，隨著飛行速度的增加，由於傳感器噪聲增加、誤差累積和處理延遲增加，基於傳統視覺的導航通過獨立的映射、規劃和控制模塊會崩潰。因此，基於學習的端到端規劃和控制網路已被證明可以有效地對這些快速機器人在混亂的環境中進行線上控制。我們針對深度端到端控制訓練並比較了卷積、U-Net 和遞迴架構與視覺Transformer模型，在逼真的高物理保真度模擬器和硬體中，並觀察到基於注意力的模型在四旋翼速度增加時更有效，而具有多層的遞迴模型在較低速度下提供更平滑的指令。據我們所知，這是第一個利用視覺Transformer進行端到端基於視覺的四旋翼控制的工作。

##### **AmazUtah_NLP at SemEval-2024 Task 9: A MultiChoice Question Answering System for Commonsense Defying Reasoning**
2405.10385v1 by Mina Ghashami, Soumya Smruti Mishra

The SemEval 2024 BRAINTEASER task represents a pioneering venture in Natural
Language Processing (NLP) by focusing on lateral thinking, a dimension of
cognitive reasoning that is often overlooked in traditional linguistic
analyses. This challenge comprises of Sentence Puzzle and Word Puzzle subtasks
and aims to test language models' capacity for divergent thinking.
  In this paper, we present our approach to the BRAINTEASER task. We employ a
holistic strategy by leveraging cutting-edge pre-trained models in multiple
choice architecture, and diversify the training data with Sentence and Word
Puzzle datasets. To gain further improvement, we fine-tuned the model with
synthetic humor/jokes dataset and the RiddleSense dataset which helped
augmenting the model's lateral thinking abilities. Empirical results show that
our approach achieve 92.5\% accuracy in Sentence Puzzle subtask and 80.2\%
accuracy in Word Puzzle subtask.

摘要：SemEval 2024 BRAINTEASER 任務代表了自然語言處理 (NLP) 的開創性嘗試，重點在於橫向思考，這是一個在傳統語言分析中經常被忽略的認知推理層面。此挑戰包含句子謎題和單字謎題子任務，旨在測試語言模型發散性思考的能力。
在本文中，我們提出我們對 BRAINTEASER 任務的方法。我們採用整體策略，利用多選架構中的尖端預訓練模型，並使用句子和單字謎題資料集來分散訓練資料。為了進一步改進，我們使用合成幽默/笑話資料集和 RiddleSense 資料集微調模型，這有助於擴充模型的橫向思考能力。經驗結果顯示，我們的方法在句子謎題子任務中達到 92.5% 的準確度，在單字謎題子任務中達到 80.2% 的準確度。

##### **Dealing Doubt: Unveiling Threat Models in Gradient Inversion Attacks under Federated Learning, A Survey and Taxonomy**
2405.10376v1 by Yichuan Shi, Olivera Kotevska, Viktor Reshniak, Abhishek Singh, Ramesh Raskar

Federated Learning (FL) has emerged as a leading paradigm for decentralized,
privacy preserving machine learning training. However, recent research on
gradient inversion attacks (GIAs) have shown that gradient updates in FL can
leak information on private training samples. While existing surveys on GIAs
have focused on the honest-but-curious server threat model, there is a dearth
of research categorizing attacks under the realistic and far more
privacy-infringing cases of malicious servers and clients. In this paper, we
present a survey and novel taxonomy of GIAs that emphasize FL threat models,
particularly that of malicious servers and clients. We first formally define
GIAs and contrast conventional attacks with the malicious attacker. We then
summarize existing honest-but-curious attack strategies, corresponding
defenses, and evaluation metrics. Critically, we dive into attacks with
malicious servers and clients to highlight how they break existing FL defenses,
focusing specifically on reconstruction methods, target model architectures,
target data, and evaluation metrics. Lastly, we discuss open problems and
future research directions.

摘要：聯邦學習 (FL) 已成為分散式、隱私保護機器學習訓練的領先範例。然而，最近對梯度反轉攻擊 (GIA) 的研究表明，FL 中的梯度更新可能會洩露私人訓練樣本的資訊。雖然現有的 GIA 調查著重於誠實但好奇的伺服器威脅模型，但對於惡意伺服器和客戶端這種更具現實性和更侵犯隱私的情況下的攻擊分類，卻缺乏研究。在本文中，我們提出了一項強調 FL 威脅模型（特別是惡意伺服器和客戶端）的 GIA 調查和新分類法。我們首先正式定義 GIA，並將傳統攻擊與惡意攻擊者進行對比。然後，我們總結現有的誠實但好奇的攻擊策略、相應的防禦措施和評估指標。至關重要的是，我們深入探討惡意伺服器和客戶端的攻擊，以強調它們如何突破現有的 FL 防禦措施，特別關注重建方法、目標模型架構、目標資料和評估指標。最後，我們討論了開放問題和未來的研究方向。

##### **4D Panoptic Scene Graph Generation**
2405.10305v1 by Jingkang Yang, Jun Cen, Wenxuan Peng, Shuai Liu, Fangzhou Hong, Xiangtai Li, Kaiyang Zhou, Qifeng Chen, Ziwei Liu

We are living in a three-dimensional space while moving forward through a
fourth dimension: time. To allow artificial intelligence to develop a
comprehensive understanding of such a 4D environment, we introduce 4D Panoptic
Scene Graph (PSG-4D), a new representation that bridges the raw visual data
perceived in a dynamic 4D world and high-level visual understanding.
Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent
entities with precise location and status information, and edges, which capture
the temporal relations. To facilitate research in this new area, we build a
richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of
1M frames, each of which is labeled with 4D panoptic segmentation masks as well
as fine-grained, dynamic scene graphs. To solve PSG-4D, we propose PSG4DFormer,
a Transformer-based model that can predict panoptic segmentation masks, track
masks along the time axis, and generate the corresponding scene graphs via a
relation component. Extensive experiments on the new dataset show that our
method can serve as a strong baseline for future research on PSG-4D. In the
end, we provide a real-world application example to demonstrate how we can
achieve dynamic scene understanding by integrating a large language model into
our PSG-4D system.

摘要：我們生活在三維空間中，同時在第四維度：時間中前進。為了讓人工智慧發展對這種 4D 環境的全面理解，我們引入了 4D 全景場景圖 (PSG-4D)，這是一種新的表示方式，它彌合了在動態 4D 世界中感知到的原始視覺數據和高層級視覺理解。具體來說，PSG-4D 將豐富的 4D 感測數據抽象為節點，這些節點表示具有精確位置和狀態信息的實體，以及邊緣，這些邊緣捕獲時間關係。為了促進這一新領域的研究，我們構建了一個豐富註釋的 PSG-4D 數據集，其中包含 3K RGB-D 視頻，總共 1M 幀，每個幀都標記有 4D 全景分割蒙版以及細粒度、動態場景圖。為了解決 PSG-4D，我們提出了 PSG4DFormer，這是一個基於 Transformer 的模型，它可以預測全景分割蒙版、沿時間軸追蹤蒙版，並通過關係組成產生對應的場景圖。在新的數據集上進行的廣泛實驗表明，我們的模型可以用作未來 PSG-4D 研究的強大基線。最後，我們提供了一個真實世界的應用範例，以展示如何通過將大型語言模型整合到我們的 PSG-4D 系統中來實現動態場景理解。

##### **Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees**
2405.10301v1 by Yu Gui, Ying Jin, Zhimei Ren

Before deploying outputs from foundation models in high-stakes tasks, it is
imperative to ensure that they align with human values. For instance, in
radiology report generation, reports generated by a vision-language model must
align with human evaluations before their use in medical decision-making. This
paper presents Conformal Alignment, a general framework for identifying units
whose outputs meet a user-specified alignment criterion. It is guaranteed that
on average, a prescribed fraction of selected units indeed meet the alignment
criterion, regardless of the foundation model or the data distribution. Given
any pre-trained model and new units with model-generated outputs, Conformal
Alignment leverages a set of reference data with ground-truth alignment status
to train an alignment predictor. It then selects new units whose predicted
alignment scores surpass a data-dependent threshold, certifying their
corresponding outputs as trustworthy. Through applications to question
answering and radiology report generation, we demonstrate that our method is
able to accurately identify units with trustworthy outputs via lightweight
training over a moderate amount of reference data. En route, we investigate the
informativeness of various features in alignment prediction and combine them
with standard models to construct the alignment predictor.

摘要：在將基礎模型的輸出部署到高風險任務之前，必須確保它們與人類價值觀保持一致。例如，在放射學報告生成中，在將視覺語言模型生成的報告用於醫療決策之前，必須與人類評估保持一致。本文提出了共形校準，這是一個用於識別輸出符合使用者指定校準準則的單元的通用框架。無論基礎模型或資料分佈如何，平均而言，一定比例的選定單元確實符合校準準則。給定任何預先訓練的模型和具有模型生成輸出的新單元，共形校準利用一組具有真實校準狀態的參考資料來訓練校準預測器。然後，它選擇預測校準分數超過資料依賴性閾值的單元，並將其對應的輸出認證為可信賴的。透過應用於問題解答和放射學報告生成，我們證明了我們的方法能夠透過對適量的參考資料進行輕量化訓練，準確地識別具有可信賴輸出的單元。在途中，我們研究了校準預測中各種特徵的信息量，並將它們與標準模型結合起來，以構建校準預測器。

##### **HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models**
2405.10299v1 by Rhea Sanjay Sukthanker, Arber Zela, Benedikt Staffler, Jorg K. H. Franke, Frank Hutter

The expanding size of language models has created the necessity for a
comprehensive examination across various dimensions that reflect the desiderata
with respect to the tradeoffs between various hardware metrics, such as
latency, energy consumption, GPU memory usage, and performance. There is a
growing interest in establishing Pareto frontiers for different language model
configurations to identify optimal models with specified hardware constraints.
Notably, architectures that excel in latency on one device may not perform
optimally on another. However, exhaustive training and evaluation of numerous
architectures across diverse hardware configurations is computationally
prohibitive. To this end, we propose HW-GPT-Bench, a hardware-aware language
model surrogate benchmark, where we leverage weight-sharing techniques from
Neural Architecture Search (NAS) to efficiently train a supernet proxy,
encompassing language models of varying scales in a single model. We conduct
profiling of these models across 13 devices, considering 5 hardware metrics and
3 distinct model scales. Finally, we showcase the usability of HW-GPT-Bench
using 8 different multi-objective NAS algorithms and evaluate the quality of
the resultant Pareto fronts. Through this benchmark, our objective is to propel
and expedite research in the advancement of multi-objective methods for NAS and
structural pruning in large language models.

摘要：<paragraph>語言模型的規模擴大，讓人有必要從各種面向進行全面檢視，這些面向反映了在各種硬體指標（例如延遲、能源消耗、GPU 記憶體使用量和效能）之間的折衷考量。對於建立不同語言模型組態的 Pareto 前緣，以找出符合特定硬體限制的最佳模型，人們的興趣與日俱增。值得注意的是，在一個裝置上延遲表現優異的架構，在另一個裝置上可能無法達到最佳效能。然而，在各種硬體組態中對眾多架構進行窮舉式訓練和評估，在運算上是禁止的。為此，我們提出了 HW-GPT-Bench，這是一個硬體感知語言模型替代基準，我們在其中利用神經架構搜尋 (NAS) 的權重共用技術，有效率地訓練一個超級網路代理，在單一模型中涵蓋各種規模的語言模型。我們在 13 個裝置上對這些模型進行分析，考量 5 個硬體指標和 3 個不同的模型規模。最後，我們展示了 HW-GPT-Bench 的可用性，使用了 8 種不同的多目標 NAS 演算法，並評估所得 Pareto 前緣的品質。透過這個基準，我們的目標是推動和加速在 NAS 和大型語言模型結構化剪枝的多目標方法的進展。</paragraph>

##### **Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning**
2405.10292v2 by Yuexiang Zhai, Hao Bai, Zipeng Lin, Jiayi Pan, Shengbang Tong, Yifei Zhou, Alane Suhr, Saining Xie, Yann LeCun, Yi Ma, Sergey Levine

Large vision-language models (VLMs) fine-tuned on specialized visual
instruction-following data have exhibited impressive language reasoning
capabilities across various scenarios. However, this fine-tuning paradigm may
not be able to efficiently learn optimal decision-making agents in multi-step
goal-directed tasks from interactive environments. To address this challenge,
we propose an algorithmic framework that fine-tunes VLMs with reinforcement
learning (RL). Specifically, our framework provides a task description and then
prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM
to efficiently explore intermediate reasoning steps that lead to the final
text-based action. Next, the open-ended text output is parsed into an
executable action to interact with the environment to obtain goal-directed task
rewards. Finally, our framework uses these task rewards to fine-tune the entire
VLM with RL. Empirically, we demonstrate that our proposed framework enhances
the decision-making capabilities of VLM agents across various tasks, enabling
7b models to outperform commercial models such as GPT4-V or Gemini.
Furthermore, we find that CoT reasoning is a crucial component for performance
improvement, as removing the CoT reasoning results in a significant decrease in
the overall performance of our method.

摘要：大型视觉语言模型 (VLM) 针对专门的视觉指令遵循数据进行了微调，在各种场景中展示了令人印象深刻的语言推理能力。然而，这种微调范例可能无法从交互式环境中有效地学习多步骤目标导向任务中的最优决策制定代理。为了应对这一挑战，我们提出了一种算法框架，该框架使用强化学习 (RL) 对 VLM 进行微调。具体来说，我们的框架提供了一个任务描述，然后提示 VLM 生成思维链 (CoT) 推理，使 VLM 能够有效地探索导致最终基于文本的动作的中间推理步骤。接下来，将开放式文本输出解析为可执行动作，以与环境交互以获得目标导向任务奖励。最后，我们的框架使用这些任务奖励对整个 VLM 进行 RL 微调。根据经验，我们证明我们提出的框架增强了 VLM 代理在各种任务中的决策能力，使 7b 模型能够优于 GPT4-V 或 Gemini 等商业模型。此外，我们发现 CoT 推理是提高性能的关键组成部分，因为移除 CoT 推理会导致我们方法的整体性能显着下降。

##### **Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction**
2405.10288v1 by Jianhao Chen, Haoyuan Ouyang, Junyang Ren, Wentao Ding, Wei Hu, Yuzhong Qu

Facts extraction is pivotal for constructing knowledge graphs. Recently, the
increasing demand for temporal facts in downstream tasks has led to the
emergence of the task of temporal fact extraction. In this paper, we
specifically address the extraction of temporal facts from natural language
text. Previous studies fail to handle the challenge of establishing
time-to-fact correspondences in complex sentences. To overcome this hurdle, we
propose a timeline-based sentence decomposition strategy using large language
models (LLMs) with in-context learning, ensuring a fine-grained understanding
of the timeline associated with various facts. In addition, we evaluate the
performance of LLMs for direct temporal fact extraction and get unsatisfactory
results. To this end, we introduce TSDRE, a method that incorporates the
decomposition capabilities of LLMs into the traditional fine-tuning of smaller
pre-trained language models (PLMs). To support the evaluation, we construct
ComplexTRED, a complex temporal fact extraction dataset. Our experiments show
that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and
ComplexTRED datasets.

摘要：事實抽取對於建構知識圖譜至關重要。最近，下游任務對時間事實的需求增加，導致了時間事實抽取任務的出現。在本文中，我們特別探討從自然語言文本中抽取時間事實。先前的研究無法處理在複雜句子中建立時間到事實對應的挑戰。為了克服這個障礙，我們提出了一個基於時間軸的句子分解策略，使用具備上下文學習功能的大語言模型 (LLM)，確保對與各種事實相關的時間軸進行細粒度的理解。此外，我們評估了 LLM 直接時間事實抽取的效能，並獲得了不令人滿意的結果。為此，我們引入了 TSDRE，一種將 LLM 的分解能力整合到較小預訓練語言模型 (PLM) 的傳統微調中的方法。為了支援評估，我們構建了 ComplexTRED，一個複雜的時間事實抽取資料集。我們的實驗表明，TSDRE 在 HyperRED-Temporal 和 ComplexTRED 資料集上都達到了最先進的結果。

##### **FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models**
2405.10286v1 by Adrian Bulat, Yassine Ouali, Georgios Tzimiropoulos

Despite noise and caption quality having been acknowledged as important
factors impacting vision-language contrastive pre-training, in this paper, we
show that the full potential of improving the training process by addressing
such issues is yet to be realized. Specifically, we firstly study and analyze
two issues affecting training: incorrect assignment of negative pairs, and low
caption quality and diversity. Then, we devise effective solutions for
addressing both problems, which essentially require training with multiple true
positive pairs. Finally, we propose training with sigmoid loss to address such
a requirement. We show very large gains over the current state-of-the-art for
both image recognition ($\sim +6\%$ on average over 11 datasets) and image
retrieval ($\sim +19\%$ on Flickr30k and $\sim +15\%$ on MSCOCO).

摘要：儘管噪音和標題品質已被確認為影響視覺語言對比預訓練的重要因素，在本文中，我們表明透過解決此類問題來改善訓練流程的全部潛力尚未實現。具體來說，我們首先研究和分析影響訓練的兩個問題：負對的錯誤分配，以及標題品質和多樣性低。然後，我們為解決這兩個問題設計了有效的解決方案，這本質上需要使用多個真實正對進行訓練。最後，我們提出使用 sigmoid 損失進行訓練以滿足這樣的要求。我們展示了在當前最先進的技術中，無論是影像辨識（在 11 個資料集上平均高出約 +6%）還是影像檢索（在 Flickr30k 上高出約 +19%，在 MSCOCO 上高出約 +15%）都獲得了非常大的收益。

##### **Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers**
2405.10276v1 by Tuo Zhang, Jinyue Yuan, Salman Avestimehr

Numerous recent works aim to enhance the efficacy of Large Language Models
(LLMs) through strategic prompting. In particular, the Optimization by
PROmpting (OPRO) approach provides state-of-the-art performance by leveraging
LLMs as optimizers where the optimization task is to find instructions that
maximize the task accuracy. In this paper, we revisit OPRO for automated
prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral
7B. Our investigation reveals that OPRO shows limited effectiveness in
small-scale LLMs, with limited inference capabilities constraining optimization
ability. We suggest future automatic prompting engineering to consider both
model capabilities and computational costs. Additionally, for small-scale LLMs,
we recommend direct instructions that clearly outline objectives and
methodologies as robust prompt baselines, ensuring efficient and effective
prompt engineering in ongoing research.

摘要：許多最近的研究旨在透過策略性提示來增強大型語言模型 (LLM) 的效能。特別是，透過最佳化提示 (OPRO) 方法，可將 LLM 作為最佳化器，而最佳化任務是找出可最大化任務精確度的指令，進而提供最先進的效能。在本文中，我們重新檢視 OPRO，以自動提示相對小規模的 LLM，例如 LLaMa-2 系列和 Mistral 7B。我們的調查顯示，OPRO 在小規模 LLM 中展現的效能有限，原因是有限的推論能力限制了最佳化能力。我們建議未來的自動提示工程應考量模型能力和運算成本。此外，對於小規模 LLM，我們建議直接提供明確說明目標和方法的指令，作為穩健的提示基準，以確保持續研究中的提示工程能有效率且有效。

##### **Faces that Speak: Jointly Synthesising Talking Face and Speech from Text**
2405.10272v1 by Youngjoon Jang, Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Hong-Sun Yang, Yoon-Cheol Ju, Il-Hwan Kim, Byeong-Yeol Kim, Joon Son Chung

The goal of this work is to simultaneously generate natural talking faces and
speech outputs from text. We achieve this by integrating Talking Face
Generation (TFG) and Text-to-Speech (TTS) systems into a unified framework. We
address the main challenges of each task: (1) generating a range of head poses
representative of real-world scenarios, and (2) ensuring voice consistency
despite variations in facial motion for the same identity. To tackle these
issues, we introduce a motion sampler based on conditional flow matching, which
is capable of high-quality motion code generation in an efficient way.
Moreover, we introduce a novel conditioning method for the TTS system, which
utilises motion-removed features from the TFG model to yield uniform speech
outputs. Our extensive experiments demonstrate that our method effectively
creates natural-looking talking faces and speech that accurately match the
input text. To our knowledge, this is the first effort to build a multimodal
synthesis system that can generalise to unseen identities.

摘要：本研究的目标是同时从文本生成自然对话人脸和语音输出。我们通过将Talking Face Generation (TFG) 和 Text-to-Speech (TTS) 系统整合到一个统一的框架中来实现这一目标。我们解决了每项任务的主要挑战：(1) 生成一系列代表真实场景的头部姿势，以及 (2) 确保语音一致性，尽管同一身份的面部动作有所不同。为了解决这些问题，我们引入了一个基于条件流匹配的运动采样器，它能够高效地生成高质量的运动代码。此外，我们为 TTS 系统引入了一种新颖的条件化方法，它利用 TFG 模型中去除运动的特征来产生统一的语音输出。我们广泛的实验表明，我们的方法有效地创建了自然逼真的对话人脸和与输入文本准确匹配的语音。据我们所知，这是构建多模态合成系统的首次尝试，该系统可以推广到看不见的身份。

##### **Automated Federated Learning via Informed Pruning**
2405.10271v1 by Christian Internò, Elena Raponi, Niki van Stein, Thomas Bäck, Markus Olhofer, Yaochu Jin, Barbara Hammer

Federated learning (FL) represents a pivotal shift in machine learning (ML)
as it enables collaborative training of local ML models coordinated by a
central aggregator, all without the need to exchange local data. However, its
application on edge devices is hindered by limited computational capabilities
and data communication challenges, compounded by the inherent complexity of
Deep Learning (DL) models. Model pruning is identified as a key technique for
compressing DL models on devices with limited resources. Nonetheless,
conventional pruning techniques typically rely on manually crafted heuristics
and demand human expertise to achieve a balance between model size, speed, and
accuracy, often resulting in sub-optimal solutions.
  In this study, we introduce an automated federated learning approach
utilizing informed pruning, called AutoFLIP, which dynamically prunes and
compresses DL models within both the local clients and the global server. It
leverages a federated loss exploration phase to investigate model gradient
behavior across diverse datasets and losses, providing insights into parameter
significance. Our experiments showcase notable enhancements in scenarios with
strong non-IID data, underscoring AutoFLIP's capacity to tackle computational
constraints and achieve superior global convergence.

摘要：聯邦學習 (FL) 代表機器學習 (ML) 的關鍵轉變，因為它能讓由中央聚合器協調的本地 ML 模型進行協作訓練，而無需交換本地數據。然而，其在邊緣裝置上的應用受到有限的運算能力和資料傳輸挑戰的阻礙，而深度學習 (DL) 模型的內在複雜性更讓問題雪上加霜。模型剪枝被視為在資源有限的裝置上壓縮 DL 模型的一項關鍵技術。儘管如此，傳統的剪枝技術通常依賴於人工製作的啟發法，並需要人類專家才能在模型大小、速度和準確性之間取得平衡，這常常導致次優的解決方案。
在本研究中，我們引入一種自動化的聯邦學習方法，利用稱為 AutoFLIP 的知情剪枝，它會動態剪枝並壓縮本地用戶端和全球伺服器中的 DL 模型。它利用聯邦損失探索階段來探討各種資料集和損失中的模型梯度行為，提供對參數重要性的見解。我們的實驗展示了在具有強非 IID 資料的情況下顯著的改進，突顯了 AutoFLIP 處理運算限制和實現優越的整體收斂的能力。

##### **A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision**
2405.10266v1 by Charles Raude, K R Prajwal, Liliane Momeni, Hannah Bull, Samuel Albanie, Andrew Zisserman, Gül Varol

In this work, our goals are two fold: large-vocabulary continuous sign
language recognition (CSLR), and sign language retrieval. To this end, we
introduce a multi-task Transformer model, CSLR2, that is able to ingest a
signing sequence and output in a joint embedding space between signed language
and spoken language text. To enable CSLR evaluation in the large-vocabulary
setting, we introduce new dataset annotations that have been manually
collected. These provide continuous sign-level annotations for six hours of
test videos, and will be made publicly available. We demonstrate that by a
careful choice of loss functions, training the model for both the CSLR and
retrieval tasks is mutually beneficial in terms of performance -- retrieval
improves CSLR performance by providing context, while CSLR improves retrieval
with more fine-grained supervision. We further show the benefits of leveraging
weak and noisy supervision from large-vocabulary datasets such as BOBSL, namely
sign-level pseudo-labels, and English subtitles. Our model significantly
outperforms the previous state of the art on both tasks.

摘要：在這項工作中，我們的目標有兩個：大詞彙量連續手語辨識 (CSLR) 和手語檢索。為此，我們提出了一個多任務 Transformer 模型 CSLR2，它能夠攝取手語序列並在手語和口語文本之間的聯合嵌入空間中輸出。為了在大量詞彙的設定中啟用 CSLR 評估，我們引入了已手動收集的新資料集註解。這些註解為六小時的測試影片提供了連續的手語級別註解，並將公開提供。我們證明，透過仔細選擇損失函數，針對 CSLR 和檢索任務訓練模型在效能方面是互利的——檢索透過提供上下文來改善 CSLR 效能，而 CSLR 則透過更細緻的監督來改善檢索。我們進一步展示了利用來自大詞彙量資料集（例如 BOBSL）的弱監督和雜訊監督的好處，即手語級別的偽標籤和英文字幕。我們的模型在兩個任務上都顯著優於先前的技術水準。

##### **Keep It Private: Unsupervised Privatization of Online Text**
2405.10260v1 by Calvin Bao, Marine Carpuat

Authorship obfuscation techniques hold the promise of helping people protect
their privacy in online communications by automatically rewriting text to hide
the identity of the original author. However, obfuscation has been evaluated in
narrow settings in the NLP literature and has primarily been addressed with
superficial edit operations that can lead to unnatural outputs. In this work,
we introduce an automatic text privatization framework that fine-tunes a large
language model via reinforcement learning to produce rewrites that balance
soundness, sense, and privacy. We evaluate it extensively on a large-scale test
set of English Reddit posts by 68k authors composed of short-medium length
texts. We study how the performance changes among evaluative conditions
including authorial profile length and authorship detection strategy. Our
method maintains high text quality according to both automated metrics and
human evaluation, and successfully evades several automated authorship attacks.

摘要：作者模糊化技术有望帮助人们通过自动改写文本来隐藏原始作者的身份，从而保护他们在网络通信中的隐私。然而，在 NLP 文献中，混淆已在狭窄的环境中得到评估，并且主要通过表面编辑操作来解决，这可能导致不自然的结果。在这项工作中，我们引入了一个自动文本私有化框架，该框架通过强化学习对大型语言模型进行微调，以生成平衡健全性、意义和隐私性的改写。我们对由 68k 位作者撰写的英语 Reddit 帖子的大规模测试集进行了广泛的评估，该测试集由中短篇文本组成。我们研究了在评估条件（包括作者个人资料长度和作者身份检测策略）之间性能如何变化。我们的方法根据自动指标和人工评估保持了较高的文本质量，并成功规避了几次自动作者攻击。

##### **A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks**
2405.10251v1 by Xuanfan Ni, Piji Li

Recent efforts have evaluated large language models (LLMs) in areas such as
commonsense reasoning, mathematical reasoning, and code generation. However, to
the best of our knowledge, no work has specifically investigated the
performance of LLMs in natural language generation (NLG) tasks, a pivotal
criterion for determining model excellence. Thus, this paper conducts a
comprehensive evaluation of well-known and high-performing LLMs, namely
ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models,
in the context of NLG tasks. We select English and Chinese datasets
encompassing Dialogue Generation and Text Summarization. Moreover, we propose a
common evaluation setting that incorporates input templates and post-processing
strategies. Our study reports both automatic results, accompanied by a detailed
analysis.

摘要：近期的研究已評估大型語言模型 (LLM) 在常識推理、數學推理和程式碼生成等領域的表現。然而，據我們所知，目前尚未有研究特別探討 LLM 在自然語言生成 (NLG) 任務中的表現，而這項任務是評量模型優異性的關鍵標準。因此，本論文針對廣為人知且表現優異的 LLM 進行全面的評估，包括 ChatGPT、ChatGLM、基於 T5 的模型、基於 LLaMA 的模型和基於 Pythia 的模型，並以 NLG 任務為背景。我們選擇涵蓋對話生成和文字摘要的英文和中文資料集。此外，我們提出一個通用的評估設定，其中包含輸入範本和後處理策略。我們的研究報告了自動化結果，並附有詳細的分析。

##### **ENADPool: The Edge-Node Attention-based Differentiable Pooling for Graph Neural Networks**
2405.10218v1 by Zhehan Zhao, Lu Bai, Lixin Cui, Ming Li, Yue Wang, Lixiang Xu, Edwin R. Hancock

Graph Neural Networks (GNNs) are powerful tools for graph classification. One
important operation for GNNs is the downsampling or pooling that can learn
effective embeddings from the node representations. In this paper, we propose a
new hierarchical pooling operation, namely the Edge-Node Attention-based
Differentiable Pooling (ENADPool), for GNNs to learn effective graph
representations. Unlike the classical hierarchical pooling operation that is
based on the unclear node assignment and simply computes the averaged feature
over the nodes of each cluster, the proposed ENADPool not only employs a hard
clustering strategy to assign each node into an unique cluster, but also
compress the node features as well as their edge connectivity strengths into
the resulting hierarchical structure based on the attention mechanism after
each pooling step. As a result, the proposed ENADPool simultaneously identifies
the importance of different nodes within each separated cluster and edges
between corresponding clusters, that significantly addresses the shortcomings
of the uniform edge-node based structure information aggregation arising in the
classical hierarchical pooling operation. Moreover, to mitigate the
over-smoothing problem arising in existing GNNs, we propose a Multi-distance
GNN (MD-GNN) model associated with the proposed ENADPool operation, allowing
the nodes to actively and directly receive the feature information from
neighbors at different random walk steps. Experiments demonstrate the
effectiveness of the MD-GNN associated with the proposed ENADPool.

摘要：圖形神經網路 (GNN) 是用於圖形分類的強大工具。GNN 的一個重要操作是降採樣或池化，它可以從節點表示中學習有效的嵌入。在本文中，我們提出了一個新的分層池化操作，即基於邊緣節點注意力的可微池化 (ENADPool)，供 GNN 學習有效的圖形表示。與基於不明確節點分配並僅計算每個群集節點的平均特徵的經典分層池化操作不同，所提出的 ENADPool 不僅採用硬群集策略將每個節點分配到一個唯一的群集，而且還將節點特徵及其邊緣連接強度壓縮到在每個池化步驟之後基於注意力機制的結果分層結構中。因此，所提出的 ENADPool 同時識別了每個分隔群集內不同節點的重要性以及對應群集之間的邊緣，這顯著地解決了經典分層池化操作中出現的基於均勻邊緣節點的結構信息聚合的缺點。此外，為了減輕現有 GNN 中出現的過度平滑問題，我們提出了一個與所提出的 ENADPool 操作相關的多距離 GNN (MD-GNN) 模型，允許節點主動直接接收來自不同隨機遊走步驟的鄰居的特徵信息。實驗證明了與所提出的 ENADPool 相關的 MD-GNN 的有效性。

##### **Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting**
2405.10216v1 by Divij Gupta, Anubhav Bhatti, Suraj Parmar, Chen Dan, Yuwei Liu, Bingjie Shen, San Lee

Low-Rank Adaptation (LoRA) is a widely used technique for fine-tuning large
pre-trained or foundational models across different modalities and tasks.
However, its application to time series data, particularly within foundational
models, remains underexplored. This paper examines the impact of LoRA on
contemporary time series foundational models: Lag-Llama, MOIRAI, and Chronos.
We demonstrate LoRA's fine-tuning potential for forecasting the vital signs of
sepsis patients in intensive care units (ICUs), emphasizing the models'
adaptability to previously unseen, out-of-domain modalities. Integrating LoRA
aims to enhance forecasting performance while reducing inefficiencies
associated with fine-tuning large models on limited domain-specific data. Our
experiments show that LoRA fine-tuning of time series foundational models
significantly improves forecasting, achieving results comparable to
state-of-the-art models trained from scratch on similar modalities. We conduct
comprehensive ablation studies to demonstrate the trade-offs between the number
of tunable parameters and forecasting performance and assess the impact of
varying LoRA matrix ranks on model performance.

摘要：低秩適應 (LoRA) 是一種廣泛用於微調不同模態和任務的大型預訓練或基礎模型的技術。
然而，它在時間序列數據中的應用，特別是在基礎模型中，仍然處於探索不足的階段。本文探討了 LoRA 對當代時間序列基礎模型的影響：Lag-Llama、MOIRAI 和 Chronos。
我們展示了 LoRA 在預測重症監護病房 (ICU) 中敗血症患者生命體徵方面的微調潛力，強調了模型對以前未見的、超出領域模式的適應性。
整合 LoRA 旨在增強預測性能，同時減少與在有限的特定領域數據上微調大型模型相關的低效率。我們的實驗表明，時間序列基礎模型的 LoRA 微調顯著改善了預測，實現了與從類似模式中從頭訓練的最新模型相當的結果。我們進行了全面的消融研究，以展示可調參數數量和預測性能之間的權衡，並評估不同 LoRA 矩陣秩對模型性能的影響。

##### **SMLP: Symbolic Machine Learning Prover (User Manual)**
2405.10215v1 by Franz Brauße, Zurab Khasidashvili, Konstantin Korovin

SMLP: Symbolic Machine Learning Prover an open source tool for exploration
and optimization of systems represented by machine learning models. SMLP uses
symbolic reasoning for ML model exploration and optimization under verification
and stability constraints, based on SMT, constraint and NN solvers. In addition
its exploration methods are guided by probabilistic and statistical methods.
SMLP is a general purpose tool that requires only data suitable for ML
modelling in the csv format (usually samples of the system's input/output).
SMLP has been applied at Intel for analyzing and optimizing hardware designs at
the analog level. Currently SMLP supports NNs, polynomial and tree models, and
uses SMT solvers for reasoning and optimization at the backend, integration of
specialized NN solvers is in progress.

摘要：SMLP：符號機器學習證明器，一個用於探索和最佳化機器學習模型所表示系統的開源工具。SMLP 使用符號推理來探索和最佳化 ML 模型，在驗證和穩定性約束下，基於 SMT、約束和 NN 求解器。此外，它的探索方法由機率和統計方法引導。SMLP 是通用目的工具，僅需要適合以 csv 格式進行 ML 建模的資料（通常是系統輸入/輸出的範例）。SMLP 已應用於英特爾，用於分析和最佳化類比層級的硬體設計。目前 SMLP 支援 NN、多項式和樹狀模型，並使用 SMT 求解器進行後端的推理和最佳化，目前正在整合專門的 NN 求解器。

##### **CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations**
2405.10212v1 by Jiahao Zhao, Jingwei Zhu, Minghuan Tan, Min Yang, Di Yang, Chenhao Zhang, Guancheng Ye, Chengming Li, Xiping Hu

In this paper, we introduce a novel psychological benchmark, CPsyExam,
constructed from questions sourced from Chinese language examinations. CPsyExam
is designed to prioritize psychological knowledge and case analysis separately,
recognizing the significance of applying psychological knowledge to real-world
scenarios. From the pool of 22k questions, we utilize 4k to create the
benchmark that offers balanced coverage of subjects and incorporates a diverse
range of case analysis techniques.Furthermore, we evaluate a range of existing
large language models~(LLMs), spanning from open-sourced to API-based models.
Our experiments and analysis demonstrate that CPsyExam serves as an effective
benchmark for enhancing the understanding of psychology within LLMs and enables
the comparison of LLMs across various granularities.

摘要：在本文中，我們介紹了一個新穎的心理基准 CPsyExam，
它是從中文考試中提取的問題構成的。CPsyExam
旨在優先考慮心理知識和案例分析，
認識到將心理知識應用於現實世界
場景的重要性。從 22k 個問題中，我們利用 4k 來創建
基準，提供平衡的主題涵蓋範圍，並結合各種
案例分析技術。此外，我們評估了一系列現有的
大型語言模型 (LLM)，從開源模型到基於 API 的模型。
我們的實驗和分析表明，CPsyExam 是一個有效的
基準，用於增強 LLM 中對心理學的理解，並允許
比較 LLM 跨各種粒度。

##### **Building a Luganda Text-to-Speech Model From Crowdsourced Data**
2405.10211v1 by Sulaiman Kagumire, Andrew Katumba, Joyce Nakatumba-Nabende, John Quinn

Text-to-speech (TTS) development for African languages such as Luganda is
still limited, primarily due to the scarcity of high-quality, single-speaker
recordings essential for training TTS models. Prior work has focused on
utilizing the Luganda Common Voice recordings of multiple speakers aged between
20-49. Although the generated speech is intelligible, it is still of lower
quality than the model trained on studio-grade recordings. This is due to the
insufficient data preprocessing methods applied to improve the quality of the
Common Voice recordings. Furthermore, speech convergence is more difficult to
achieve due to varying intonations, as well as background noise. In this paper,
we show that the quality of Luganda TTS from Common Voice can improve by
training on multiple speakers of close intonation in addition to further
preprocessing of the training data. Specifically, we selected six female
speakers with close intonation determined by subjectively listening and
comparing their voice recordings. In addition to trimming out silent portions
from the beginning and end of the recordings, we applied a pre-trained speech
enhancement model to reduce background noise and enhance audio quality. We also
utilized a pre-trained, non-intrusive, self-supervised Mean Opinion Score (MOS)
estimation model to filter recordings with an estimated MOS over 3.5,
indicating high perceived quality. Subjective MOS evaluations from nine native
Luganda speakers demonstrate that our TTS model achieves a significantly better
MOS of 3.55 compared to the reported 2.5 MOS of the existing model. Moreover,
for a fair comparison, our model trained on six speakers outperforms models
trained on a single-speaker (3.13 MOS) or two speakers (3.22 MOS). This
showcases the effectiveness of compensating for the lack of data from one
speaker with data from multiple speakers of close intonation to improve TTS
quality.

摘要：盧干達語等非洲語言的文字轉語音 (TTS) 開發仍受限，主要是因為缺乏訓練 TTS 模型不可或缺的高品質單一講者錄音。先前研究專注於利用多位 20 至 49 歲講者的盧干達語 Common Voice 錄音。儘管產生的語音可以理解，但品質仍低於使用錄音室等級錄音訓練的模型。這是因為應用於提升 Common Voice 錄音品質的資料前處理方法不足。此外，由於語調變化和背景噪音，更難達成語音收斂。在本文中，我們展示透過訓練語調接近的多位講者，以及進一步前處理訓練資料，可以提升 Common Voice 的盧干達語 TTS 品質。具體來說，我們根據主觀聆聽和比較他們的語音錄音，選出六位語調接近的女性講者。除了修剪錄音開頭和結尾的靜音部分，我們還應用預先訓練的語音增強模型，以降低背景噪音和提升音訊品質。我們還利用預先訓練的、非侵入式、自我監督平均意見分數 (MOS) 估計模型，過濾估計 MOS 超過 3.5 的錄音，這表示感知品質高。九位盧干達語母語人士的主觀 MOS 評估顯示，我們的 TTS 模型達到了顯著更好的 MOS 3.55，而現有模型的報告 MOS 為 2.5。此外，為了公平比較，我們訓練於六位講者的模型優於訓練於單一講者 (3.13 MOS) 或兩位講者 (3.22 MOS) 的模型。這展示了透過使用語調接近的多位講者的資料來彌補單一講者資料不足，進而提升 TTS 品質的有效性。

##### **Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level**
2405.10202v1 by Chenlong Zhao, Xiwen Zhou, Xiaopeng Xie, Yong Zhang

Scientific document summarization has been a challenging task due to the long
structure of the input text. The long input hinders the simultaneous effective
modeling of both global high-order relations between sentences and local
intra-sentence relations which is the most critical step in extractive
summarization. However, existing methods mostly focus on one type of relation,
neglecting the simultaneous effective modeling of both relations, which can
lead to insufficient learning of semantic representations. In this paper, we
propose HAESum, a novel approach utilizing graph neural networks to locally and
globally model documents based on their hierarchical discourse structure.
First, intra-sentence relations are learned using a local heterogeneous graph.
Subsequently, a novel hypergraph self-attention layer is introduced to further
enhance the characterization of high-order inter-sentence relations. We
validate our approach on two benchmark datasets, and the experimental results
demonstrate the effectiveness of HAESum and the importance of considering
hierarchical structures in modeling long scientific documents. Our code will be
available at \url{https://github.com/MoLICHENXI/HAESum}

摘要：<paragraph>科學文件摘要一直是一項具有挑戰性的任務，因為輸入文字的結構很長。長的輸入會阻礙同時有效地對句子之間的整體高階關係和句子內部的局部關係進行建模，這是萃取式摘要中最關鍵的步驟。然而，現有的方法大多只關注一種關係，忽視了對兩種關係的同時有效建模，這可能會導致語義表示的學習不足。在本文中，我們提出了 HAESum，這是一種利用圖神經網路在局部和整體上根據其層次化話語結構對文件進行建模的新方法。首先，使用局部異質圖學習句子內部關係。隨後，引入了一個新穎的超圖自注意力層，以進一步增強高階句子間關係的表徵。我們在兩個基準資料集上驗證了我們的做法，實驗結果證明了 HAESum 的有效性，以及在對長科學文件進行建模時考慮層次結構的重要性。我們的程式碼將可以在 \url{https://github.com/MoLICHENXI/HAESum} 取得</paragraph>

##### **LFED: A Literary Fiction Evaluation Dataset for Large Language Models**
2405.10166v1 by Linhao Yu, Qun Liu, Deyi Xiong

The rapid evolution of large language models (LLMs) has ushered in the need
for comprehensive assessments of their performance across various dimensions.
In this paper, we propose LFED, a Literary Fiction Evaluation Dataset, which
aims to evaluate the capability of LLMs on the long fiction comprehension and
reasoning. We collect 95 literary fictions that are either originally written
in Chinese or translated into Chinese, covering a wide range of topics across
several centuries. We define a question taxonomy with 8 question categories to
guide the creation of 1,304 questions. Additionally, we conduct an in-depth
analysis to ascertain how specific attributes of literary fictions (e.g., novel
types, character numbers, the year of publication) impact LLM performance in
evaluations. Through a series of experiments with various state-of-the-art
LLMs, we demonstrate that these models face considerable challenges in
effectively addressing questions related to literary fictions, with ChatGPT
reaching only 57.08% under the zero-shot setting. The dataset will be publicly
available at https://github.com/tjunlp-lab/LFED.git

摘要：大型語言模型 (LLM) 的快速發展，讓評估其在各方面表現的全面性需求應運而生。在本文中，我們提出了一個文學小說評估資料集 (LFED)，旨在評估 LLM 在長篇小說理解和推理的能力。我們收集了 95 部文學小說，這些小說原本以中文寫成或翻譯成中文，涵蓋了幾個世紀以來廣泛的主題。我們定義了一個包含 8 個問題類別的問題分類法，以指導 1,304 個問題的建立。此外，我們進行了深入分析，以確定文學小說的特定屬性（例如，小說類型、角色數量、出版年份）如何影響 LLM 在評估中的表現。透過一系列使用各種最先進 LLM 進行的實驗，我們證明了這些模型在有效回答與文學小說相關的問題時面臨相當大的挑戰，其中 ChatGPT 在零次學習設定下僅達到 57.08%。該資料集將在 https://github.com/tjunlp-lab/LFED.git 公開。

##### **PIR: Remote Sensing Image-Text Retrieval with Prior Instruction Representation Learning**
2405.10160v1 by Jiancheng Pan, Muyuan Ma, Qing Ma, Cong Bai, Shengyong Chen

Remote sensing image-text retrieval constitutes a foundational aspect of
remote sensing interpretation tasks, facilitating the alignment of vision and
language representations. This paper introduces a prior instruction
representation (PIR) learning paradigm that draws on prior knowledge to
instruct adaptive learning of vision and text representations. Based on PIR, a
domain-adapted remote sensing image-text retrieval framework PIR-ITR is
designed to address semantic noise issues in vision-language understanding
tasks. However, with massive additional data for pre-training the
vision-language foundation model, remote sensing image-text retrieval is
further developed into an open-domain retrieval task. Continuing with the
above, we propose PIR-CLIP, a domain-specific CLIP-based framework for remote
sensing image-text retrieval, to address semantic noise in remote sensing
vision-language representations and further improve open-domain retrieval
performance. In vision representation, Vision Instruction Representation (VIR)
based on Spatial-PAE utilizes the prior-guided knowledge of the remote sensing
scene recognition by building a belief matrix to select key features for
reducing the impact of semantic noise. In text representation, Language Cycle
Attention (LCA) based on Temporal-PAE uses the previous time step to cyclically
activate the current time step to enhance text representation capability. A
cluster-wise Affiliation Loss (AL) is proposed to constrain the inter-classes
and to reduce the semantic confusion zones in the common subspace.
Comprehensive experiments demonstrate that PIR could enhance vision and text
representations and outperform the state-of-the-art methods of closed-domain
and open-domain retrieval on two benchmark datasets, RSICD and RSITMD.

摘要：遙感影像文字檢索構成遙感解譯任務的基礎層面，促進視覺與語言表徵的一致性。本文介紹一種事前指令表徵 (PIR) 學習範例，利用事前知識指導視覺與文字表徵的自適應學習。根據 PIR，設計了一個領域適應的遙感影像文字檢索架構 PIR-ITR，用於解決視覺語言理解任務中的語義雜訊問題。然而，隨著預訓練視覺語言基礎模型的大量額外資料，遙感影像文字檢索進一步發展成開放領域檢索任務。延續上述，我們提出 PIR-CLIP，一個基於領域特定 CLIP 的遙感影像文字檢索架構，用於解決遙感視覺語言表徵中的語義雜訊，並進一步提升開放領域檢索效能。在視覺表徵中，基於空間 PAE 的視覺指令表徵 (VIR) 透過建立一個信念矩陣，利用遙感場景辨識的事前引導知識，來選擇關鍵特徵，以降低語義雜訊的影響。在文字表徵中，基於時間 PAE 的語言循環注意力 (LCA) 使用前一個時間步驟，以循環方式啟動當前時間步驟，以增強文字表徵能力。提出一個群集式關聯損失 (AL)，用於約束類間，並減少共同子空間中的語義混淆區域。全面的實驗證明，PIR 可以增強視覺和文字表徵，並在兩個基準資料集 RSICD 和 RSITMD 上優於封閉領域和開放領域檢索的最新方法。

##### **Speaker Verification in Agent-Generated Conversations**
2405.10150v1 by Yizhe Yang, Heyan Huang, Palakorn Achananuparp, Jing Jiang, Ee-Peng Lim

The recent success of large language models (LLMs) has attracted widespread
interest to develop role-playing conversational agents personalized to the
characteristics and styles of different speakers to enhance their abilities to
perform both general and special purpose dialogue tasks. However, the ability
to personalize the generated utterances to speakers, whether conducted by human
or LLM, has not been well studied. To bridge this gap, our study introduces a
novel evaluation challenge: speaker verification in agent-generated
conversations, which aimed to verify whether two sets of utterances originate
from the same speaker. To this end, we assemble a large dataset collection
encompassing thousands of speakers and their utterances. We also develop and
evaluate speaker verification models under experiment setups. We further
utilize the speaker verification models to evaluate the personalization
abilities of LLM-based role-playing models. Comprehensive experiments suggest
that the current role-playing models fail in accurately mimicking speakers,
primarily due to their inherent linguistic characteristics.

摘要：大型語言模型 (LLM) 近期的成功，吸引了廣泛的興趣，以開發角色扮演對話代理，針對不同說話者的特徵和風格進行個人化，以增強他們執行一般和特殊目的對話任務的能力。然而，無論是由人類或 LLM 進行，將生成的對話個人化為說話者的能力尚未得到很好的研究。為了彌補這個差距，我們的研究引入了一個新的評估挑戰：代理生成對話中的說話者驗證，旨在驗證兩組對話是否來自同一個說話者。為此，我們彙編了一個大型的資料集，包含數千名說話者及其對話。我們還開發並評估了實驗設置下的說話者驗證模型。我們進一步利用說話者驗證模型來評估基於 LLM 的角色扮演模型的個人化能力。綜合實驗表明，目前的扮演模型無法準確地模仿說話者，主要是由於其固有的語言特徵。

##### **PL-MTEB: Polish Massive Text Embedding Benchmark**
2405.10138v1 by Rafał Poświata, Sławomir Dadas, Michał Perełkiewicz

In this paper, we introduce the Polish Massive Text Embedding Benchmark
(PL-MTEB), a comprehensive benchmark for text embeddings in Polish. The PL-MTEB
consists of 28 diverse NLP tasks from 5 task types. We adapted the tasks based
on previously used datasets by the Polish NLP community. In addition, we
created a new PLSC (Polish Library of Science Corpus) dataset consisting of
titles and abstracts of scientific publications in Polish, which was used as
the basis for two novel clustering tasks. We evaluated 15 publicly available
models for text embedding, including Polish and multilingual ones, and
collected detailed results for individual tasks and aggregated results for each
task type and the entire benchmark. PL-MTEB comes with open-source code at
https://github.com/rafalposwiata/pl-mteb.

摘要：在本文中，我們介紹了波蘭語大規模文本嵌入基準 (PL-MTEB)，這是一個針對波蘭語文本嵌入的全面基準。PL-MTEB 包含來自 5 種任務類型的 28 項不同的 NLP 任務。我們根據波蘭 NLP 社群先前使用的資料集調整了任務。此外，我們建立了一個新的 PLSC (波蘭科學語料庫) 資料集，其中包含波蘭語科學出版品的標題和摘要，並將其用作兩個新分群任務的基礎。我們評估了 15 個公開的文本嵌入模型，包括波蘭語和多語言模型，並收集了各個任務的詳細結果，以及每個任務類型和整個基準的彙總結果。PL-MTEB 附帶開源程式碼，網址為 https://github.com/rafalposwiata/pl-mteb。

##### **Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language**
2405.10133v1 by Togay Yazar, Mucahid Kutlu, İsa Kerem Bayırlı

Over the past century, the Turkish language has undergone substantial
changes, primarily driven by governmental interventions. In this work, our goal
is to investigate the evolution of the Turkish language since the establishment
of T\"urkiye in 1923. Thus, we first introduce Turkronicles which is a
diachronic corpus for Turkish derived from the Official Gazette of T\"urkiye.
Turkronicles contains 45,375 documents, detailing governmental actions, making
it a pivotal resource for analyzing the linguistic evolution influenced by the
state policies. In addition, we expand an existing diachronic Turkish corpus
which consists of the records of the Grand National Assembly of T\"urkiye by
covering additional years. Next, combining these two diachronic corpora, we
seek answers for two main research questions: How have the Turkish vocabulary
and the writing conventions changed since the 1920s? Our analysis reveals that
the vocabularies of two different time periods diverge more as the time between
them increases, and newly coined Turkish words take the place of their old
counterparts. We also observe changes in writing conventions. In particular,
the use of circumflex noticeably decreases and words ending with the letters
"-b" and "-d" are successively replaced with "-p" and "-t" letters,
respectively. Overall, this study quantitatively highlights the dramatic
changes in Turkish from various aspects of the language in a diachronic
perspective.

摘要：<paragraph>在過去一個世紀以來，土耳其語經歷了重大的變化，主要是受到政府干預的影響。在這項研究中，我們的目標是探討自 1923 年土耳其共和國成立以來土耳其語的演變。因此，我們首先介紹 Turkronicles，這是一個源自土耳其共和國官方公報的土耳其語歷時語料庫。Turkronicles 包含 45,375 份文件，詳述政府行動，使其成為分析受國家政策影響的語言演變的關鍵資源。此外，我們擴展了一個現有的歷時土耳其語語料庫，其中包含土耳其共和國大國民議會的記錄，涵蓋了額外的年份。接下來，結合這兩個歷時語料庫，我們尋求回答兩個主要的研究問題：自 1920 年代以來，土耳其語的詞彙和書寫慣例發生了怎樣的變化？我們的分析表明，兩個不同時期的詞彙隨著它們之間時間的增加而出現更多分歧，新創造的土耳其語詞彙取代了它們舊的對應詞。我們還觀察到書寫慣例的變化。特別是，抑揚符的使用明顯減少，以字母“-b”和“-d”結尾的詞分別被“-p”和“-t”字母取代。總的來說，這項研究從語言的各個方面定量地突出了土耳其語在歷時觀點下的巨大變化。</paragraph>

##### **StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis**
2405.10129v1 by Chidimma Opara

The emergence of large language models (LLMs) capable of generating realistic
texts and images has sparked ethical concerns across various sectors. In
response, researchers in academia and industry are actively exploring methods
to distinguish AI-generated content from human-authored material. However, a
crucial question remains: What are the unique characteristics of AI-generated
text? Addressing this gap, this study proposes StyloAI, a data-driven model
that uses 31 stylometric features to identify AI-generated texts by applying a
Random Forest classifier on two multi-domain datasets. StyloAI achieves
accuracy rates of 81% and 98% on the test set of the AuTextification dataset
and the Education dataset, respectively. This approach surpasses the
performance of existing state-of-the-art models and provides valuable insights
into the differences between AI-generated and human-authored texts.

摘要：隨著能夠產生逼真文本和圖像的大語言模型 (LLM) 的出現，在各個領域中引起了道德問題。作為回應，學術界和產業中的研究人員正在積極探索區分 AI 生成的內容和人類編寫的材料的方法。然而，一個關鍵問題仍然存在：AI 生成的文本有哪些獨特特徵？為了解決這個差距，本研究提出了 StyloAI，這是一個數據驅動的模型，它使用 31 個文體特徵來識別 AI 生成的文本，方法是在兩個多領域數據集上應用隨機森林分類器。StyloAI 在 AuTextification 數據集和 Education 數據集的測試集上分別達到了 81% 和 98% 的準確率。這種方法超越了現有最先進模型的性能，並提供了對 AI 生成的文本和人類編寫的文本之間差異的寶貴見解。

##### **Red Teaming Language Models for Contradictory Dialogues**
2405.10128v2 by Xiaofei Wen, Bangzheng Li, Tenghao Huang, Muhao Chen

Most language models currently available are prone to self-contradiction
during dialogues. To mitigate this issue, this study explores a novel
contradictory dialogue processing task that aims to detect and modify
contradictory statements in a conversation. This task is inspired by research
on context faithfulness and dialogue comprehension, which have demonstrated
that the detection and understanding of contradictions often necessitate
detailed explanations. We develop a dataset comprising contradictory dialogues,
in which one side of the conversation contradicts itself. Each dialogue is
accompanied by an explanatory label that highlights the location and details of
the contradiction. With this dataset, we present a Red Teaming framework for
contradictory dialogue processing. The framework detects and attempts to
explain the dialogue, then modifies the existing contradictory content using
the explanation. Our experiments demonstrate that the framework improves the
ability to detect contradictory dialogues and provides valid explanations.
Additionally, it showcases distinct capabilities for modifying such dialogues.
Our study highlights the importance of the logical inconsistency problem in
conversational AI.

摘要：目前多數的語言模型在對話中容易出現自我矛盾。為了緩解這個問題，本研究探討了一項新穎的矛盾對話處理任務，旨在偵測和修改對話中的矛盾陳述。此任務的靈感來自於對脈絡忠實度和對話理解的研究，這些研究表明，矛盾的偵測和理解通常需要詳細的解釋。我們開發了一個包含矛盾對話的資料集，其中對話的一方與自己產生矛盾。每個對話都附有說明標籤，標籤中突出了矛盾的位置和細節。有了這個資料集，我們提出了紅隊架構來處理矛盾對話。此架構會偵測對話並嘗試解釋對話，然後使用解釋修改現有的矛盾內容。我們的實驗證明，此架構改善了偵測矛盾對話的能力，並提供了有效的解釋。此外，它展示了修改此類對話的獨特功能。我們的研究突出了對話式 AI 中邏輯不一致問題的重要性。

##### **Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource Dialogue Generation**
2405.10121v1 by Bo Zhang, Hui Ma, Jian Ding, Jian Wang, Bo Xu, Hongfei Lin

Integrating multimodal knowledge into large language models (LLMs) represents
a significant advancement in dialogue generation capabilities. However, the
effective incorporation of such knowledge in zero-resource scenarios remains a
substantial challenge due to the scarcity of diverse, high-quality dialogue
datasets. To address this, we propose the Visual Implicit Knowledge
Distillation Framework (VIKDF), an innovative approach aimed at enhancing LLMs
for enriched dialogue generation in zero-resource contexts by leveraging
implicit multimodal knowledge. VIKDF comprises two main stages: knowledge
distillation, using an Implicit Query Transformer to extract and encode visual
implicit knowledge from image-text pairs into knowledge vectors; and knowledge
integration, employing a novel Bidirectional Variational Information Fusion
technique to seamlessly integrate these distilled vectors into LLMs. This
enables the LLMs to generate dialogues that are not only coherent and engaging
but also exhibit a deep understanding of the context through implicit
multimodal cues, effectively overcoming the limitations of zero-resource
scenarios. Our extensive experimentation across two dialogue datasets shows
that VIKDF outperforms existing state-of-the-art models in generating
high-quality dialogues. The code will be publicly available following
acceptance.

摘要：將多模式知識整合到大型語言模型 (LLM) 中，代表對話產生能力的重大進展。然而，由於缺乏多樣化、高品質的對話資料集，在零資源場景中有效整合此類知識仍然是一項重大挑戰。為了解決這個問題，我們提出了視覺隱含知識蒸餾框架 (VIKDF)，這是一種創新的方法，旨在通過利用隱含的多模式知識，增強 LLM 在零資源場景中的豐富對話產生。VIKDF 包含兩個主要階段：知識蒸餾，使用隱含查詢轉換器從影像文字對中萃取和編碼視覺隱含知識成知識向量；以及知識整合，採用新穎的雙向變異資訊融合技術，將這些蒸餾向量無縫整合到 LLM 中。這使 LLM 能夠產生不僅連貫且引人入勝的對話，而且還能透過隱含的多模式提示，對脈絡有深入的理解，有效克服零資源場景的限制。我們在兩個對話資料集上進行的廣泛實驗表明，VIKDF 在產生高品質對話方面優於現有的最先進模型。在接受後，程式碼將公開提供。

##### **A novel Reservoir Architecture for Periodic Time Series Prediction**
2405.10102v1 by Zhongju Yuan, Geraint Wiggins, Dick Botteldooren

This paper introduces a novel approach to predicting periodic time series
using reservoir computing. The model is tailored to deliver precise forecasts
of rhythms, a crucial aspect for tasks such as generating musical rhythm.
Leveraging reservoir computing, our proposed method is ultimately oriented
towards predicting human perception of rhythm. Our network accurately predicts
rhythmic signals within the human frequency perception range. The model
architecture incorporates primary and intermediate neurons tasked with
capturing and transmitting rhythmic information. Two parameter matrices,
denoted as c and k, regulate the reservoir's overall dynamics. We propose a
loss function to adapt c post-training and introduce a dynamic selection (DS)
mechanism that adjusts $k$ to focus on areas with outstanding contributions.
Experimental results on a diverse test set showcase accurate predictions,
further improved through real-time tuning of the reservoir via c and k.
Comparative assessments highlight its superior performance compared to
conventional models.

摘要：本文介紹了一種使用儲存器運算預測週期性時間序列的新穎方法。此模型經過量身打造，可提供節奏的精準預測，這是產生音樂節奏等任務的關鍵面向。我們的建議方法利用儲存器運算，最終目標是預測人類對節奏的感知。我們的網路準確預測人類頻率感知範圍內的節奏訊號。模型架構包含負責擷取和傳遞節奏資訊的主要神經元和中間神經元。兩個參數矩陣，表示為 c 和 k，用來調節儲存器的整體動態。我們提出一個損失函數來調整 c 後訓練，並引入一個動態選擇 (DS) 機制，調整 k 以專注於有傑出貢獻的區域。在多樣化測試集上的實驗結果展示了準確的預測，透過 c 和 k 即時調整儲存器後進一步改進。比較評估突顯其與傳統模型相比的卓越效能。

