{"2407.17879": {"publish_time": "2024-07-25", "title": "HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline", "paper_summary": "Vision Transformer (ViT) acceleration with field programmable gate array\n(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators\nmainly rely on temporal architectures, which process different operators by\nreusing the same hardware blocks and suffer from extensive memory access\noverhead. Pipelined architectures, either coarse-grained or fine-grained,\nunroll the ViT computation spatially for memory access efficiency. However,\nthey usually suffer from significant hardware resource constraints and pipeline\nbubbles induced by the global computation dependency of ViT. In this paper, we\nintroduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and\nlow-latency ViT processing. HG-PIPE features a hybrid-grained pipeline\narchitecture to reduce on-chip buffer cost and couples the computation dataflow\nand parallelism design to eliminate the pipeline bubbles. HG-PIPE further\nintroduces careful approximations to implement both linear and non-linear\noperators with abundant Lookup Tables (LUTs), thus alleviating resource\nconstraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput\nand 2.52 times better resource efficiency than the prior-art accelerators,\ne.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT\nacceleration on a single device and achieves 7118 images/s, which is 2.81 times\nfaster than a V100 GPU.", "paper_summary_zh": "\u8996\u89ba\u8f49\u63db\u5668 (ViT) \u8207\u73fe\u5834\u53ef\u7de8\u7a0b\u9598\u9663\u5217 (FPGA) \u7684\u52a0\u901f\u5f88\u6709\u524d\u666f\uff0c\u4f46\u4e5f\u5145\u6eff\u6311\u6230\u3002\u73fe\u6709\u7684\u57fa\u65bc FPGA \u7684 ViT \u52a0\u901f\u5668\u4e3b\u8981\u4f9d\u8cf4\u65bc\u66ab\u614b\u67b6\u69cb\uff0c\u5b83\u900f\u904e\u91cd\u8907\u4f7f\u7528\u76f8\u540c\u7684\u786c\u9ad4\u5340\u584a\u4f86\u8655\u7406\u4e0d\u540c\u7684\u904b\u7b97\u5b50\uff0c\u4e26\u627f\u53d7\u5927\u91cf\u7684\u8a18\u61b6\u9ad4\u5b58\u53d6\u958b\u92b7\u3002\u7ba1\u7dda\u67b6\u69cb\uff08\u7121\u8ad6\u662f\u7c97\u7c92\u5ea6\u6216\u7d30\u7c92\u5ea6\uff09\u5728\u7a7a\u9593\u4e0a\u5c55\u958b ViT \u8a08\u7b97\u4ee5\u63d0\u9ad8\u8a18\u61b6\u9ad4\u5b58\u53d6\u6548\u7387\u3002\u7136\u800c\uff0c\u5b83\u5011\u901a\u5e38\u6703\u53d7\u5230\u986f\u8457\u7684\u786c\u9ad4\u8cc7\u6e90\u9650\u5236\u548c\u7531 ViT \u7684\u5168\u5c40\u8a08\u7b97\u4f9d\u8cf4\u6027\u6240\u5f15\u767c\u7684\u7ba1\u7dda\u6c23\u6ce1\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 HG-PIPE\uff0c\u9019\u662f\u4e00\u7a2e\u7528\u65bc\u9ad8\u901a\u91cf\u548c\u4f4e\u5ef6\u9072 ViT \u8655\u7406\u7684\u7ba1\u7dda\u5f0f FPGA \u52a0\u901f\u5668\u3002HG-PIPE \u63a1\u7528\u6df7\u5408\u7c92\u5ea6\u7ba1\u7dda\u67b6\u69cb\u4f86\u964d\u4f4e\u6676\u7247\u7de9\u885d\u6210\u672c\uff0c\u4e26\u7d50\u5408\u8a08\u7b97\u8cc7\u6599\u6d41\u548c\u4e26\u884c\u8a2d\u8a08\u4ee5\u6d88\u9664\u7ba1\u7dda\u6c23\u6ce1\u3002HG-PIPE \u9032\u4e00\u6b65\u5f15\u5165\u4e86\u4ed4\u7d30\u7684\u8fd1\u4f3c\u503c\uff0c\u4ee5\u4f7f\u7528\u8c50\u5bcc\u7684\u67e5\u627e\u8868 (LUT) \u4f86\u5be6\u4f5c\u7dda\u6027\u548c\u975e\u7dda\u6027\u904b\u7b97\u5b50\uff0c\u5f9e\u800c\u6e1b\u8f15\u8cc7\u6e90\u9650\u5236\u3002\u5728 ZCU102 FPGA \u4e0a\uff0cHG-PIPE \u7684\u541e\u5410\u91cf\u6bd4\u5148\u9032\u7684\u52a0\u901f\u5668\uff08\u4f8b\u5982 AutoViTAcc\uff09\u9ad8\u51fa 2.78 \u500d\uff0c\u8cc7\u6e90\u6548\u7387\u9ad8\u51fa 2.52 \u500d\u3002\u4f7f\u7528 VCK190 FPGA\uff0cHG-PIPE \u5728\u55ae\u4e00\u88dd\u7f6e\u4e0a\u5be6\u73fe\u7aef\u5230\u7aef\u7684 ViT \u52a0\u901f\uff0c\u4e26\u9054\u5230\u6bcf\u79d2 7118 \u5f35\u5f71\u50cf\uff0c\u6bd4 V100 GPU \u5feb 2.81 \u500d\u3002", "author": "Qingyu Guo et.al.", "authors": "Qingyu Guo, Jiayong Wan, Songqiang Xu, Meng Li, Yuan Wang", "id": "2407.17879v1", "paper_url": "http://arxiv.org/abs/2407.17879v1", "repo": "null"}}