{"2407.02791": {"publish_time": "2024-07-03", "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps", "paper_summary": "The flourishing ecosystem centered around voice personal assistants (VPA),\nsuch as Amazon Alexa, has led to the booming of VPA apps. The largest app\nmarket Amazon skills store, for example, hosts over 200,000 apps. Despite their\npopularity, the open nature of app release and the easy accessibility of apps\nalso raise significant concerns regarding security, privacy and quality.\nConsequently, various testing approaches have been proposed to systematically\nexamine VPA app behaviors. To tackle the inherent lack of a visible user\ninterface in the VPA app, two strategies are employed during testing, i.e.,\nchatbot-style testing and model-based testing. The former often lacks effective\nguidance for expanding its search space, while the latter falls short in\ninterpreting the semantics of conversations to construct precise and\ncomprehensive behavior models for apps. In this work, we introduce Elevate, a\nmodel-enhanced large language model (LLM)-driven VUI testing framework. Elevate\nleverages LLMs' strong capability in natural language processing to compensate\nfor semantic information loss during model-based VUI testing. It operates by\nprompting LLMs to extract states from VPA apps' outputs and generate\ncontext-related inputs. During the automatic interactions with the app, it\nincrementally constructs the behavior model, which facilitates the LLM in\ngenerating inputs that are highly likely to discover new states. Elevate\nbridges the LLM and the behavior model with innovative techniques such as\nencoding behavior model into prompts and selecting LLM-generated inputs based\non the context relevance. Elevate is benchmarked on 4,000 real-world Alexa\nskills, against the state-of-the-art tester Vitas. It achieves 15% higher state\nspace coverage compared to Vitas on all types of apps, and exhibits significant\nadvancement in efficiency.", "paper_summary_zh": "\u4ee5\u8bed\u97f3\u500b\u4eba\u52a9\u7406 (VPA) \u70ba\u4e2d\u5fc3\u7684\u84ec\u52c3\u751f\u614b\u7cfb\u7d71\uff0c\u4f8b\u5982 Amazon Alexa\uff0c\u5df2\u5c0e\u81f4 VPA \u61c9\u7528\u7a0b\u5f0f\u84ec\u52c3\u767c\u5c55\u3002\u4f8b\u5982\uff0c\u6700\u5927\u7684\u61c9\u7528\u7a0b\u5f0f\u5e02\u5834 Amazon \u6280\u80fd\u5546\u5e97\uff0c\u64c1\u6709\u8d85\u904e 200,000 \u500b\u61c9\u7528\u7a0b\u5f0f\u3002\u5118\u7ba1\u5b83\u5011\u5f88\u53d7\u6b61\u8fce\uff0c\u4f46\u61c9\u7528\u7a0b\u5f0f\u767c\u5e03\u7684\u958b\u653e\u6027\u8cea\u548c\u61c9\u7528\u7a0b\u5f0f\u7684\u6613\u65bc\u5b58\u53d6\u6027\u4e5f\u5c0d\u5b89\u5168\u6027\u3001\u96b1\u79c1\u6b0a\u548c\u54c1\u8cea\u63d0\u51fa\u4e86\u91cd\u5927\u7684\u7591\u616e\u3002\u56e0\u6b64\uff0c\u5df2\u63d0\u51fa\u5404\u7a2e\u6e2c\u8a66\u65b9\u6cd5\u4f86\u7cfb\u7d71\u5316\u5730\u6aa2\u67e5 VPA \u61c9\u7528\u7a0b\u5f0f\u884c\u70ba\u3002\u70ba\u4e86\u89e3\u6c7a VPA \u61c9\u7528\u7a0b\u5f0f\u4e2d\u7f3a\u4e4f\u53ef\u898b\u4f7f\u7528\u8005\u4ecb\u9762\u7684\u554f\u984c\uff0c\u5728\u6e2c\u8a66\u671f\u9593\u63a1\u7528\u4e86\u5169\u7a2e\u7b56\u7565\uff0c\u5373\u804a\u5929\u6a5f\u5668\u4eba\u5f0f\u6e2c\u8a66\u548c\u57fa\u65bc\u6a21\u578b\u7684\u6e2c\u8a66\u3002\u524d\u8005\u5e38\u5e38\u7f3a\u4e4f\u6709\u6548\u7684\u6307\u5c0e\u4f86\u64f4\u5c55\u5176\u641c\u5c0b\u7a7a\u9593\uff0c\u800c\u5f8c\u8005\u5247\u7121\u6cd5\u89e3\u91cb\u5c0d\u8a71\u7684\u8a9e\u7fa9\u4f86\u5efa\u69cb\u61c9\u7528\u7a0b\u5f0f\u7684\u7cbe\u78ba\u4e14\u5168\u9762\u7684\u884c\u70ba\u6a21\u578b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 Elevate\uff0c\u4e00\u500b\u7531\u6a21\u578b\u589e\u5f37\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u9a45\u52d5\u7684 VUI \u6e2c\u8a66\u67b6\u69cb\u3002Elevate \u5145\u5206\u5229\u7528 LLM \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u65b9\u9762\u7684\u5f37\u5927\u529f\u80fd\uff0c\u4ee5\u5f4c\u88dc\u57fa\u65bc\u6a21\u578b\u7684 VUI \u6e2c\u8a66\u671f\u9593\u7684\u8a9e\u7fa9\u8cc7\u8a0a\u907a\u5931\u3002\u5b83\u7684\u904b\u4f5c\u65b9\u5f0f\u662f\u63d0\u793a LLM \u5f9e VPA \u61c9\u7528\u7a0b\u5f0f\u7684\u8f38\u51fa\u4e2d\u63d0\u53d6\u72c0\u614b\uff0c\u4e26\u7522\u751f\u8207\u5167\u5bb9\u76f8\u95dc\u7684\u8f38\u5165\u3002\u5728\u8207\u61c9\u7528\u7a0b\u5f0f\u7684\u81ea\u52d5\u4e92\u52d5\u671f\u9593\uff0c\u5b83\u6703\u9010\u6b65\u5efa\u69cb\u884c\u70ba\u6a21\u578b\uff0c\u9019\u6709\u52a9\u65bc LLM \u7522\u751f\u6975\u6709\u53ef\u80fd\u767c\u73fe\u65b0\u72c0\u614b\u7684\u8f38\u5165\u3002Elevate \u4f7f\u7528\u5275\u65b0\u7684\u6280\u8853\u5c07 LLM \u548c\u884c\u70ba\u6a21\u578b\u806f\u7e6b\u8d77\u4f86\uff0c\u4f8b\u5982\u5c07\u884c\u70ba\u6a21\u578b\u7de8\u78bc\u6210\u63d0\u793a\uff0c\u4e26\u6839\u64da\u5167\u5bb9\u76f8\u95dc\u6027\u9078\u64c7 LLM \u751f\u6210\u7684\u8f38\u5165\u3002Elevate \u4ee5 4,000 \u500b\u771f\u5be6\u4e16\u754c\u7684 Alexa \u6280\u80fd\u70ba\u57fa\u6e96\uff0c\u4e26\u91dd\u5c0d\u6700\u5148\u9032\u7684\u6e2c\u8a66\u54e1 Vitas \u9032\u884c\u8a55\u91cf\u3002\u8207 Vitas \u76f8\u6bd4\uff0c\u5b83\u5728\u6240\u6709\u985e\u578b\u7684\u61c9\u7528\u7a0b\u5f0f\u4e0a\u5be6\u73fe\u4e86 15% \u7684\u66f4\u9ad8\u72c0\u614b\u7a7a\u9593\u6db5\u84cb\u7387\uff0c\u4e26\u5c55\u73fe\u51fa\u986f\u8457\u7684\u6548\u7387\u63d0\u5347\u3002", "author": "Suwan Li et.al.", "authors": "Suwan Li, Lei Bu, Guangdong Bai, Fuman Xie, Kai Chen, Chang Yue", "id": "2407.02791v1", "paper_url": "http://arxiv.org/abs/2407.02791v1", "repo": "null"}}