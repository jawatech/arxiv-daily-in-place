{"2406.16356": {"publish_time": "2024-06-24", "title": "Evaluation of Instruction-Following Ability for Large Language Models on Story-Ending Generation", "paper_summary": "Instruction-tuned Large Language Models (LLMs) have achieved remarkable\nperformance across various benchmark tasks. While providing instructions to\nLLMs for guiding their generations is user-friendly, assessing their\ninstruction-following capabilities is still unclarified due to a lack of\nevaluation metrics. In this paper, we focus on evaluating the\ninstruction-following ability of LLMs in the context of story-ending\ngeneration, which requires diverse and context-specific instructions. We\npropose an automatic evaluation pipeline that utilizes a machine reading\ncomprehension (MRC) model to determine whether the generated story-ending\nreflects instruction. Our findings demonstrate that our proposed metric aligns\nwith human evaluation. Furthermore, our experiments confirm that recent\nopen-source LLMs can achieve instruction-following performance close to\nGPT-3.5, as assessed through automatic evaluation.", "paper_summary_zh": "\u6307\u4ee4\u8abf\u6574\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u57fa\u6e96\u4efb\u52d9\u4e2d\u53d6\u5f97\u986f\u8457\u7684\u8868\u73fe\u3002\u96d6\u7136\u5411 LLM \u63d0\u4f9b\u6307\u4ee4\u4ee5\u6307\u5c0e\u5176\u751f\u6210\u5c0d\u4f7f\u7528\u8005\u4f86\u8aaa\u5f88\u53cb\u5584\uff0c\u4f46\u7531\u65bc\u7f3a\u4e4f\u8a55\u4f30\u6307\u6a19\uff0c\u8a55\u4f30\u5176\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u4ecd\u7136\u4e0d\u660e\u78ba\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u8a55\u4f30 LLM \u5728\u6545\u4e8b\u7d50\u5c3e\u751f\u6210\u60c5\u5883\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u9019\u9700\u8981\u591a\u6a23\u5316\u4e14\u7279\u5b9a\u65bc\u60c5\u5883\u7684\u6307\u4ee4\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u81ea\u52d5\u8a55\u4f30\u7ba1\u9053\uff0c\u5229\u7528\u6a5f\u5668\u95b1\u8b80\u7406\u89e3 (MRC) \u6a21\u578b\u4f86\u78ba\u5b9a\u751f\u6210\u7684\u6545\u4e8b\u60c5\u7bc0\u662f\u5426\u53cd\u6620\u6307\u4ee4\u3002\u6211\u5011\u7684\u767c\u73fe\u8b49\u660e\u6211\u5011\u63d0\u51fa\u7684\u6307\u6a19\u8207\u4eba\u985e\u8a55\u4f30\u4e00\u81f4\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u5be6\u9a57\u78ba\u8a8d\u6700\u8fd1\u7684\u958b\u6e90 LLM \u53ef\u4ee5\u5be6\u73fe\u63a5\u8fd1 GPT-3.5 \u7684\u6307\u4ee4\u9075\u5faa\u6548\u80fd\uff0c\u9019\u662f\u900f\u904e\u81ea\u52d5\u8a55\u4f30\u4f86\u8a55\u4f30\u7684\u3002", "author": "Rem Hida et.al.", "authors": "Rem Hida, Junki Ohmura, Toshiyuki Sekiya", "id": "2406.16356v1", "paper_url": "http://arxiv.org/abs/2406.16356v1", "repo": "null"}}