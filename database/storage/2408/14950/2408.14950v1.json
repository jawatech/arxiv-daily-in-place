{"2408.14950": {"publish_time": "2024-08-27", "title": "NeuralOOD: Improving Out-of-Distribution Generalization Performance with Brain-machine Fusion Learning Framework", "paper_summary": "Deep Neural Networks (DNNs) have demonstrated exceptional recognition\ncapabilities in traditional computer vision (CV) tasks. However, existing CV\nmodels often suffer a significant decrease in accuracy when confronted with\nout-of-distribution (OOD) data. In contrast to these DNN models, human can\nmaintain a consistently low error rate when facing OOD scenes, partly\nattributed to the rich prior cognitive knowledge stored in the human brain.\nPrevious OOD generalization researches only focus on the single modal,\noverlooking the advantages of multimodal learning method. In this paper, we\nutilize the multimodal learning method to improve the OOD generalization and\npropose a novel Brain-machine Fusion Learning (BMFL) framework. We adopt the\ncross-attention mechanism to fuse the visual knowledge from CV model and prior\ncognitive knowledge from the human brain. Specially, we employ a pre-trained\nvisual neural encoding model to predict the functional Magnetic Resonance\nImaging (fMRI) from visual features which eliminates the need for the fMRI data\ncollection and pre-processing, effectively reduces the workload associated with\nconventional BMFL methods. Furthermore, we construct a brain transformer to\nfacilitate the extraction of knowledge inside the fMRI data. Moreover, we\nintroduce the Pearson correlation coefficient maximization regularization\nmethod into the training process, which improves the fusion capability with\nbetter constrains. Our model outperforms the DINOv2 and baseline models on the\nImageNet-1k validation dataset as well as six curated OOD datasets, showcasing\nits superior performance in diverse scenarios.", "paper_summary_zh": "\u6df1\u5ea6\u795e\u7ecf\u7db2\u8def (DNN) \u5df2\u5728\u50b3\u7d71\u96fb\u8166\u8996\u89ba (CV) \u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u8fa8\u8b58\u80fd\u529b\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 CV \u6a21\u578b\u5728\u9762\u5c0d\u5206\u5e03\u5916 (OOD) \u8cc7\u6599\u6642\uff0c\u5176\u6e96\u78ba\u5ea6\u901a\u5e38\u6703\u5927\u5e45\u964d\u4f4e\u3002\u8207\u9019\u4e9b DNN \u6a21\u578b\u76f8\u53cd\u7684\u662f\uff0c\u4eba\u985e\u5728\u9762\u5c0d OOD \u5834\u666f\u6642\uff0c\u53ef\u4ee5\u7dad\u6301\u6301\u7e8c\u4f4e\u932f\u8aa4\u7387\uff0c\u9019\u90e8\u5206\u6b78\u529f\u65bc\u5132\u5b58\u5728\u4eba\u8166\u4e2d\u7684\u8c50\u5bcc\u5148\u9a57\u8a8d\u77e5\u77e5\u8b58\u3002\u5148\u524d\u7684 OOD \u6cdb\u5316\u7814\u7a76\u50c5\u5c08\u6ce8\u65bc\u55ae\u4e00\u6a21\u5f0f\uff0c\u800c\u5ffd\u7565\u4e86\u591a\u6a21\u614b\u5b78\u7fd2\u65b9\u6cd5\u7684\u512a\u9ede\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5229\u7528\u591a\u6a21\u614b\u5b78\u7fd2\u65b9\u6cd5\u4f86\u6539\u5584 OOD \u6cdb\u5316\uff0c\u4e26\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u5927\u8166\u6a5f\u5668\u878d\u5408\u5b78\u7fd2 (BMFL) \u67b6\u69cb\u3002\u6211\u5011\u63a1\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u6a5f\u5236\uff0c\u878d\u5408\u4f86\u81ea CV \u6a21\u578b\u7684\u8996\u89ba\u77e5\u8b58\u548c\u4f86\u81ea\u4eba\u8166\u7684\u5148\u9a57\u8a8d\u77e5\u77e5\u8b58\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u63a1\u7528\u9810\u5148\u8a13\u7df4\u597d\u7684\u8996\u89ba\u795e\u7d93\u7de8\u78bc\u6a21\u578b\uff0c\u5f9e\u8996\u89ba\u7279\u5fb5\u9810\u6e2c\u529f\u80fd\u6027\u78c1\u632f\u9020\u5f71 (fMRI)\uff0c\u9019\u6d88\u9664\u4e86\u5c0d fMRI \u8cc7\u6599\u6536\u96c6\u548c\u9810\u8655\u7406\u7684\u9700\u6c42\uff0c\u6709\u6548\u5730\u6e1b\u5c11\u4e86\u8207\u50b3\u7d71 BMFL \u65b9\u6cd5\u76f8\u95dc\u7684\u5de5\u4f5c\u8ca0\u64d4\u3002\u6b64\u5916\uff0c\u6211\u5011\u5efa\u69cb\u4e86\u4e00\u500b\u5927\u8166\u8f49\u63db\u5668\uff0c\u4ee5\u5229\u65bc\u5f9e fMRI \u8cc7\u6599\u4e2d\u8403\u53d6\u77e5\u8b58\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c07\u76ae\u723e\u68ee\u76f8\u95dc\u4fc2\u6578\u6700\u5927\u5316\u6b63\u5247\u5316\u65b9\u6cd5\u5f15\u5165\u8a13\u7df4\u904e\u7a0b\u4e2d\uff0c\u9019\u900f\u904e\u66f4\u597d\u7684\u7d04\u675f\u6539\u5584\u4e86\u878d\u5408\u80fd\u529b\u3002\u6211\u5011\u7684\u6a21\u578b\u5728 ImageNet-1k \u9a57\u8b49\u8cc7\u6599\u96c6\u4ee5\u53ca\u516d\u500b\u7b56\u5c55\u7684 OOD \u8cc7\u6599\u96c6\u4e0a\u512a\u65bc DINOv2 \u548c\u57fa\u7dda\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u540c\u5834\u666f\u4e2d\u7684\u512a\u7570\u6548\u80fd\u3002", "author": "Shuangchen Zhao et.al.", "authors": "Shuangchen Zhao, Changde Du, Hui Li, Huiguang He", "id": "2408.14950v1", "paper_url": "http://arxiv.org/abs/2408.14950v1", "repo": "null"}}