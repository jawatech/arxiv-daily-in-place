
### LLM
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-29**|**Stylus: Automatic Adapter Selection for Diffusion Models**|Michael Luo et.al.|[2404.18928v1](http://arxiv.org/abs/2404.18928v1)|null|
|**2024-04-29**|**Holmes: Benchmark the Linguistic Competence of Language Models**|Andreas Waldis et.al.|[2404.18923v1](http://arxiv.org/abs/2404.18923v1)|null|
|**2024-04-29**|**DPO Meets PPO: Reinforced Token Optimization for RLHF**|Han Zhong et.al.|[2404.18922v1](http://arxiv.org/abs/2404.18922v1)|null|
|**2024-04-29**|**Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting**|Fangcheng Liu et.al.|[2404.18911v1](http://arxiv.org/abs/2404.18911v1)|null|
|**2024-04-29**|**IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation**|Kebin Wu et.al.|[2404.18891v1](http://arxiv.org/abs/2404.18891v1)|null|
|**2024-04-29**|**A Survey on Diffusion Models for Time Series and Spatio-Temporal Data**|Yiyuan Yang et.al.|[2404.18886v1](http://arxiv.org/abs/2404.18886v1)|null|
|**2024-04-29**|**Spivavtor: An Instruction Tuned Ukrainian Text Editing Model**|Aman Saini et.al.|[2404.18880v1](http://arxiv.org/abs/2404.18880v1)|null|
|**2024-04-29**|**OpenStreetView-5M: The Many Roads to Global Visual Geolocation**|Guillaume Astruc et.al.|[2404.18873v1](http://arxiv.org/abs/2404.18873v1)|[link](https://github.com/gastruc/osv5m)|
|**2024-04-29**|**More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness**|Aaron J. Li et.al.|[2404.18870v1](http://arxiv.org/abs/2404.18870v1)|[link](https://github.com/aaron-jx-li/rlhf-trustworthiness)|
|**2024-04-29**|**Truth-value judgment in language models: belief directions are context sensitive**|Stefan F. Schouten et.al.|[2404.18865v1](http://arxiv.org/abs/2404.18865v1)|null|
|**2024-04-29**|**Performance-Aligned LLMs for Generating Fast Code**|Daniel Nichols et.al.|[2404.18864v1](http://arxiv.org/abs/2404.18864v1)|null|
|**2024-04-29**|**A Comprehensive Rubric for Annotating Pathological Speech**|Mario Corrales-Astorgano et.al.|[2404.18851v1](http://arxiv.org/abs/2404.18851v1)|null|
|**2024-04-29**|**FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition**|Yuxuan Yan et.al.|[2404.18848v1](http://arxiv.org/abs/2404.18848v1)|null|
|**2024-04-29**|**It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments**|Petter Mæhlum et.al.|[2404.18832v1](http://arxiv.org/abs/2404.18832v1)|null|
|**2024-04-29**|**Harmonic Machine Learning Models are Robust**|Nicholas S. Kersting et.al.|[2404.18825v1](http://arxiv.org/abs/2404.18825v1)|null|
|**2024-04-29**|**Benchmarking Benchmark Leakage in Large Language Models**|Ruijie Xu et.al.|[2404.18824v1](http://arxiv.org/abs/2404.18824v1)|[link](https://github.com/gair-nlp/benbench)|
|**2024-04-29**|**Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies**|Seyed Soroush Karimi Madahi et.al.|[2404.18821v1](http://arxiv.org/abs/2404.18821v1)|null|
|**2024-04-29**|**Unknown Script: Impact of Script on Cross-Lingual Transfer**|Wondimagegnhue Tsegaye Tufa et.al.|[2404.18810v1](http://arxiv.org/abs/2404.18810v1)|null|
|**2024-04-29**|**Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**|Pat Verga et.al.|[2404.18796v1](http://arxiv.org/abs/2404.18796v1)|null|
|**2024-04-29**|**Certification of Speaker Recognition Models to Additive Perturbations**|Dmitrii Korzh et.al.|[2404.18791v1](http://arxiv.org/abs/2404.18791v1)|null|
|**2024-04-29**|**Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input**|Tessa Masis et.al.|[2404.18784v1](http://arxiv.org/abs/2404.18784v1)|null|
|**2024-04-29**|**Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain**|Gustaw Opiełka et.al.|[2404.18772v1](http://arxiv.org/abs/2404.18772v1)|[link](https://github.com/gucioopielka/saliency-semantic-rsa)|
|**2024-04-29**|**PECC: Problem Extraction and Coding Challenges**|Patrick Haller et.al.|[2404.18766v1](http://arxiv.org/abs/2404.18766v1)|[link](https://github.com/hallerpatrick/pecc)|
|**2024-04-29**|**Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective**|Juraj Vladika et.al.|[2404.18759v1](http://arxiv.org/abs/2404.18759v1)|null|
|**2024-04-29**|**Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment**|Shanle Yao et.al.|[2404.18747v1](http://arxiv.org/abs/2404.18747v1)|null|
|**2024-04-29**|**Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**|Artem Abzaliev et.al.|[2404.18739v1](http://arxiv.org/abs/2404.18739v1)|null|
|**2024-04-29**|**The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages**|Wondimagegnhue Tsegaye Tufa et.al.|[2404.18726v1](http://arxiv.org/abs/2404.18726v1)|[link](https://github.com/cltl/reddit_topic)|
|**2024-04-29**|**Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library**|Solène Tarride et.al.|[2404.18722v1](http://arxiv.org/abs/2404.18722v1)|null|
|**2024-04-29**|**Iconic Gesture Semantics**|Andy Lücking et.al.|[2404.18708v1](http://arxiv.org/abs/2404.18708v1)|null|
|**2024-04-29**|**Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages**|Sidharth Ranjan et.al.|[2404.18684v1](http://arxiv.org/abs/2404.18684v1)|null|
|**2024-04-29**|**Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report**|Paul Cibier et.al.|[2404.18672v1](http://arxiv.org/abs/2404.18672v1)|null|
|**2024-04-29**|**Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting**|Yifei Gao et.al.|[2404.18669v1](http://arxiv.org/abs/2404.18669v1)|null|
|**2024-04-29**|**Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods**|Haeun Yu et.al.|[2404.18655v1](http://arxiv.org/abs/2404.18655v1)|null|
|**2024-04-29**|**Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection**|Konstantinos Tsigos et.al.|[2404.18649v1](http://arxiv.org/abs/2404.18649v1)|null|
|**2024-04-29**|**Reinforcement Learning Problem Solving with Large Language Models**|Sina Gholamian et.al.|[2404.18638v1](http://arxiv.org/abs/2404.18638v1)|null|
|**2024-04-29**|**Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?**|Letitia Parcalabescu et.al.|[2404.18624v1](http://arxiv.org/abs/2404.18624v1)|null|
|**2024-04-29**|**The SAMER Arabic Text Simplification Corpus**|Bashar Alhafni et.al.|[2404.18615v1](http://arxiv.org/abs/2404.18615v1)|null|
|**2024-04-29**|**CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**|Xiangyu Liang et.al.|[2404.18604v1](http://arxiv.org/abs/2404.18604v1)|null|
|**2024-04-29**|**FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering**|Wei Zhou et.al.|[2404.18585v1](http://arxiv.org/abs/2404.18585v1)|null|
|**2024-04-29**|**Analyzing Semantic Change through Lexical Replacements**|Francesco Periti et.al.|[2404.18570v1](http://arxiv.org/abs/2404.18570v1)|[link](https://github.com/changeiskey/asc-lr)|
|**2024-04-29**|**Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning**|Wen-Yu Chang et.al.|[2404.18564v1](http://arxiv.org/abs/2404.18564v1)|null|
|**2024-04-29**|**LangBiTe: A Platform for Testing Bias in Large Language Models**|Sergio Morales et.al.|[2404.18558v1](http://arxiv.org/abs/2404.18558v1)|null|
|**2024-04-29**|**Can GPT-4 do L2 analytic assessment?**|Stefano Bannò et.al.|[2404.18557v1](http://arxiv.org/abs/2404.18557v1)|null|
|**2024-04-29**|**Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting**|Gareth Davies et.al.|[2404.18553v1](http://arxiv.org/abs/2404.18553v1)|null|
|**2024-04-29**|**SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods**|Manos Schinas et.al.|[2404.18552v1](http://arxiv.org/abs/2404.18552v1)|[link](https://github.com/mever-team/sidbench)|
|**2024-04-29**|**Time Machine GPT**|Felix Drinkall et.al.|[2404.18543v1](http://arxiv.org/abs/2404.18543v1)|null|
|**2024-04-29**|**Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods**|Chuni Liu et.al.|[2404.18539v1](http://arxiv.org/abs/2404.18539v1)|[link](https://github.com/clovermini/skea_topo)|
|**2024-04-29**|**Evaluating and Mitigating Linguistic Discrimination in Large Language Models**|Guoliang Dong et.al.|[2404.18534v1](http://arxiv.org/abs/2404.18534v1)|null|
|**2024-04-29**|**Evaluating Readability and Faithfulness of Concept-based Explanations**|Meng Li et.al.|[2404.18533v1](http://arxiv.org/abs/2404.18533v1)|null|
|**2024-04-29**|**MileBench: Benchmarking MLLMs in Long Context**|Dingjie Song et.al.|[2404.18532v1](http://arxiv.org/abs/2404.18532v1)|null|
|**2024-04-29**|**A Framework to Model ML Engineering Processes**|Sergio Morales et.al.|[2404.18531v1](http://arxiv.org/abs/2404.18531v1)|null|
|**2024-04-29**|**Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning**|Weike Peng et.al.|[2404.18527v1](http://arxiv.org/abs/2404.18527v1)|null|
|**2024-04-29**|**On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**|Usevalad Milasheuski. Luca Barbieri et.al.|[2404.18519v1](http://arxiv.org/abs/2404.18519v1)|null|
|**2024-04-29**|**From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?**|Jiangfeng Liu et.al.|[2404.18518v1](http://arxiv.org/abs/2404.18518v1)|null|
|**2024-04-29**|**Explainability of Machine Learning Approaches in Forensic Linguistics: A Case Study in Geolinguistic Authorship Profiling**|Dana Roemling et.al.|[2404.18510v1](http://arxiv.org/abs/2404.18510v1)|null|
|**2024-04-29**|**Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models**|Mark Schöne et.al.|[2404.18508v1](http://arxiv.org/abs/2404.18508v1)|null|
|**2024-04-29**|**ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction**|Yupeng Cao et.al.|[2404.18470v1](http://arxiv.org/abs/2404.18470v1)|null|
|**2024-04-29**|**HFT: Half Fine-Tuning for Large Language Models**|Tingfeng Hui et.al.|[2404.18466v1](http://arxiv.org/abs/2404.18466v1)|null|
|**2024-04-29**|**M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework**|Zijian Zhang et.al.|[2404.18465v1](http://arxiv.org/abs/2404.18465v1)|[link](https://github.com/applied-machine-learning-lab/m3oe)|
|**2024-04-29**|**Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in**|Utkarsh Agarwal et.al.|[2404.18460v1](http://arxiv.org/abs/2404.18460v1)|null|
|**2024-04-29**|**U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models**|Song Mei et.al.|[2404.18444v1](http://arxiv.org/abs/2404.18444v1)|null|
|**2024-04-29**|**BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**|Ran Xu et.al.|[2404.18443v1](http://arxiv.org/abs/2404.18443v1)|[link](https://github.com/ritaranx/bmretriever)|
|**2024-04-29**|**Unsupervised Dynamics Prediction with Object-Centric Kinematics**|Yeon-Ji Song et.al.|[2404.18423v1](http://arxiv.org/abs/2404.18423v1)|null|
|**2024-04-29**|**Capabilities of Gemini Models in Medicine**|Khaled Saab et.al.|[2404.18416v1](http://arxiv.org/abs/2404.18416v1)|null|
|**2024-04-29**|**3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset**|Xinyu Ma et.al.|[2404.18413v1](http://arxiv.org/abs/2404.18413v1)|[link](https://github.com/maxylee/3am)|
|**2024-04-29**|**Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions**|Bowen Xu et.al.|[2404.18410v1](http://arxiv.org/abs/2404.18410v1)|null|
|**2024-04-29**|**LLM-SR: Scientific Equation Discovery via Programming with Large Language Models**|Parshin Shojaee et.al.|[2404.18400v1](http://arxiv.org/abs/2404.18400v1)|[link](https://github.com/deep-symbolic-mathematics/llm-sr)|
|**2024-04-29**|**MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**|Xiang Li et.al.|[2404.18398v1](http://arxiv.org/abs/2404.18398v1)|null|
|**2024-04-29**|**Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice**|Yixuan Li et.al.|[2404.18385v1](http://arxiv.org/abs/2404.18385v1)|null|
|**2024-04-29**|**Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions**|Jordan Meadows et.al.|[2404.18384v1](http://arxiv.org/abs/2404.18384v1)|null|
|**2024-04-29**|**QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**|Tomoki Fukuma et.al.|[2404.18371v1](http://arxiv.org/abs/2404.18371v1)|null|
|**2024-04-29**|**FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models**|Wei Li et.al.|[2404.18359v1](http://arxiv.org/abs/2404.18359v1)|null|
|**2024-04-29**|**Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models**|Norbert Tihanyi et.al.|[2404.18353v1](http://arxiv.org/abs/2404.18353v1)|null|
|**2024-04-29**|**Post-hoc and manifold explanations analysis of facial expression data based on deep learning**|Yang Xiao et.al.|[2404.18352v1](http://arxiv.org/abs/2404.18352v1)|[link](https://github.com/nkushaw/psychoinformatics)|
|**2024-04-28**|**Multi-stage Attack Detection and Prediction Using Graph Neural Networks: An IoT Feasibility Study**|Hamdi Friji et.al.|[2404.18328v1](http://arxiv.org/abs/2404.18328v1)|null|
|**2024-04-28**|**SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies**|Amir Samadi et.al.|[2404.18326v1](http://arxiv.org/abs/2404.18326v1)|[link](https://github.com/amir-samadi/safe-rl)|
|**2024-04-28**|**Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review**|Mladjan Jovanovic et.al.|[2404.18311v1](http://arxiv.org/abs/2404.18311v1)|null|
|**2024-04-28**|**Retrieval-Oriented Knowledge for Click-Through Rate Prediction**|Huanshuo Liu et.al.|[2404.18304v1](http://arxiv.org/abs/2404.18304v1)|null|
|**2024-04-28**|**Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms**|Zoi Lygizou et.al.|[2404.18296v1](http://arxiv.org/abs/2404.18296v1)|null|
|**2024-04-28**|**Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages**|David Ifeoluwa Adelani et.al.|[2404.18286v1](http://arxiv.org/abs/2404.18286v1)|null|
|**2024-04-28**|**Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)**|Malur Narayan et.al.|[2404.18276v1](http://arxiv.org/abs/2404.18276v1)|null|
|**2024-04-28**|**Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**|Qi Zhu et.al.|[2404.18271v1](http://arxiv.org/abs/2404.18271v1)|null|
|**2024-04-28**|**Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design**|Aman Kumar et.al.|[2404.18270v1](http://arxiv.org/abs/2404.18270v1)|null|
|**2024-04-28**|**Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin**|Pin-Jie Lin et.al.|[2404.18264v1](http://arxiv.org/abs/2404.18264v1)|null|
|**2024-04-28**|**Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning**|Atharva Naik et.al.|[2404.18262v1](http://arxiv.org/abs/2404.18262v1)|null|
|**2024-04-28**|**Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology**|Nilo Pedrazzini et.al.|[2404.18257v1](http://arxiv.org/abs/2404.18257v1)|null|
|**2024-04-28**|**PatentGPT: A Large Language Model for Intellectual Property**|Zilong Bai et.al.|[2404.18255v1](http://arxiv.org/abs/2404.18255v1)|null|
|**2024-04-28**|**LEGENT: Open Platform for Embodied Agents**|Zhili Cheng et.al.|[2404.18243v1](http://arxiv.org/abs/2404.18243v1)|null|
|**2024-04-28**|**SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning**|Jinghan Jia et.al.|[2404.18239v1](http://arxiv.org/abs/2404.18239v1)|[link](https://github.com/optml-group/soul)|
|**2024-04-28**|**From Persona to Personalization: A Survey on Role-Playing Language Agents**|Jiangjie Chen et.al.|[2404.18231v1](http://arxiv.org/abs/2404.18231v1)|null|
|**2024-04-28**|**TextGram: Towards a better domain-adaptive pretraining**|Sharayu Hiwarkhedkar et.al.|[2404.18228v1](http://arxiv.org/abs/2404.18228v1)|null|
|**2024-04-28**|**L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi**|Saloni Mittal et.al.|[2404.18216v1](http://arxiv.org/abs/2404.18216v1)|[link](https://github.com/l3cube-pune/MarathiNLP)|
|**2024-04-28**|**Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement**|Zeyu Hu et.al.|[2404.18214v1](http://arxiv.org/abs/2404.18214v1)|null|
|**2024-04-28**|**S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification**|Guanchun Wang et.al.|[2404.18213v1](http://arxiv.org/abs/2404.18213v1)|null|
|**2024-04-28**|**Paint by Inpaint: Learning to Add Image Objects by Removing Them First**|Navve Wasserman et.al.|[2404.18212v1](http://arxiv.org/abs/2404.18212v1)|null|
|**2024-04-28**|**LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM**|Zicheng Zhang et.al.|[2404.18203v1](http://arxiv.org/abs/2404.18203v1)|null|
|**2024-04-28**|**WorldGPT: Empowering LLM as Multimodal World Model**|Zhiqi Ge et.al.|[2404.18202v1](http://arxiv.org/abs/2404.18202v1)|[link](https://github.com/dcdmllm/worldgpt)|
|**2024-04-28**|**Exploring the Robustness of In-Context Learning with Noisy Labels**|Chen Cheng et.al.|[2404.18191v1](http://arxiv.org/abs/2404.18191v1)|[link](https://github.com/inezyu0928/in-context-learning)|
|**2024-04-28**|**Ranked List Truncation for Large Language Model-based Re-Ranking**|Chuan Meng et.al.|[2404.18185v1](http://arxiv.org/abs/2404.18185v1)|[link](https://github.com/chuanmeng/rlt4reranking)|
|**2024-04-28**|**EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter**|Comfort Eseohen Ilevbare et.al.|[2404.18180v1](http://arxiv.org/abs/2404.18180v1)|null|

#### Abstracts
##### **Stylus: Automatic Adapter Selection for Diffusion Models**
2404.18928v1 by Michael Luo,Justin Wong,Brandon Trabucco,Yanping Huang,Joseph E. Gonzalez,Zhifeng Chen,Ruslan Salakhutdinov,Ion Stoica

Beyond scaling base models with more data or parameters, fine-tuned adapters
provide an alternative way to generate high fidelity, custom images at reduced
costs. As such, adapters have been widely adopted by open-source communities,
accumulating a database of over 100K adapters-most of which are highly
customized with insufficient descriptions. This paper explores the problem of
matching the prompt to a set of relevant adapters, built on recent work that
highlight the performance gains of composing adapters. We introduce Stylus,
which efficiently selects and automatically composes task-specific adapters
based on a prompt's keywords. Stylus outlines a three-stage approach that first
summarizes adapters with improved descriptions and embeddings, retrieves
relevant adapters, and then further assembles adapters based on prompts'
keywords by checking how well they fit the prompt. To evaluate Stylus, we
developed StylusDocs, a curated dataset featuring 75K adapters with
pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion
checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as
preferred, with humans and multimodal models as evaluators, over the base
model. See stylus-diffusion.github.io for more.

摘要：除了使用更多資料或參數調整基本模型外，微調的適配器提供了一種以降低成本產生高保真自訂圖像的替代方法。因此，適配器已被開源社群廣泛採用，累積了一個超過 100K 個適配器的資料庫，其中大部分都經過高度自訂，且描述不足。本文探討了將提示與一組相關適配器配對的問題，該問題建立在最近強調組成適配器效能提升的工作之上。我們介紹 Stylus，它根據提示的關鍵字有效率地選擇並自動組成特定於任務的適配器。Stylus 概述了一個三階段方法，首先使用改進的描述和嵌入來總結適配器，擷取相關適配器，然後根據提示的關鍵字進一步組裝適配器，方法是檢查它們與提示的契合度。為了評估 Stylus，我們開發了 StylusDocs，這是一個經過整理的資料集，其中包含 75K 個具有預先計算的適配器嵌入的適配器。在我們對流行的 Stable Diffusion 檢查點進行評估時，Stylus 達到了更高的 CLIP-FID Pareto 效率，並且在人類和多模態模型作為評估者的情況下，其偏好度高達兩倍。請參閱 stylus-diffusion.github.io 以進一步了解。

##### **Holmes: Benchmark the Linguistic Competence of Language Models**
2404.18923v1 by Andreas Waldis,Yotam Perlitz,Leshem Choshen,Yufang Hou,Iryna Gurevych

We introduce Holmes, a benchmark to assess the linguistic competence of
language models (LMs) - their ability to grasp linguistic phenomena. Unlike
prior prompting-based evaluations, Holmes assesses the linguistic competence of
LMs via their internal representations using classifier-based probing. In doing
so, we disentangle specific phenomena (e.g., part-of-speech of words) from
other cognitive abilities, like following textual instructions, and meet recent
calls to assess LMs' linguistic competence in isolation. Composing Holmes, we
review over 250 probing studies and feature more than 200 datasets to assess
syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing
over 50 LMs reveals that, aligned with known trends, their linguistic
competence correlates with model size. However, surprisingly, model
architecture and instruction tuning also significantly influence performance,
particularly in morphology and syntax. Finally, we propose FlashHolmes, a
streamlined version of Holmes designed to lower the high computation load while
maintaining high-ranking precision.

摘要：我們介紹 Holmes，一個用於評估語言模型 (LM) 語言能力的基準，也就是它們掌握語言現象的能力。與之前的提示式評估不同，Holmes 使用基於分類器的探測，透過其內部表示來評估 LM 的語言能力。在這樣做的過程中，我們將特定現象（例如單詞的詞性）從其他認知能力中解開，例如遵循文本說明，並滿足最近評估 LM 語言能力的孤立呼籲。在編寫 Holmes 時，我們回顧了 250 多項探測研究，並使用了 200 多個數據集來評估句法、形態、語義、推理和話語現象。分析 50 多個 LM 顯示，與已知的趨勢一致，它們的語言能力與模型大小相關。然而，令人驚訝的是，模型架構和指令調整也顯著影響效能，特別是在形態和句法方面。最後，我們提出了 FlashHolmes，這是一個簡化的 Holmes 版本，旨在降低高計算負載，同時保持高排名精度。

##### **DPO Meets PPO: Reinforced Token Optimization for RLHF**
2404.18922v1 by Han Zhong,Guhao Feng,Wei Xiong,Li Zhao,Di He,Jiang Bian,Liwei Wang

In the classical Reinforcement Learning from Human Feedback (RLHF) framework,
Proximal Policy Optimization (PPO) is employed to learn from sparse,
sentence-level rewards -- a challenging scenario in traditional deep
reinforcement learning. Despite the great successes of PPO in the alignment of
state-of-the-art closed-source large language models (LLMs), its open-source
implementation is still largely sub-optimal, as widely reported by numerous
research studies. To address these issues, we introduce a framework that models
RLHF problems as a Markov decision process (MDP), enabling the capture of
fine-grained token-wise information. Furthermore, we provide theoretical
insights that demonstrate the superiority of our MDP framework over the
previous sentence-level bandit formulation. Under this framework, we introduce
an algorithm, dubbed as Reinforced Token Optimization (\texttt{RTO}), which
learns the token-wise reward function from preference data and performs policy
optimization based on this learned token-wise reward signal. Theoretically,
\texttt{RTO} is proven to have the capability of finding the near-optimal
policy sample-efficiently. For its practical implementation, \texttt{RTO}
innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,
originally derived from sparse sentence rewards, surprisingly provides us with
a token-wise characterization of response quality, which is seamlessly
incorporated into our subsequent PPO training stage. Extensive real-world
alignment experiments verify the effectiveness of the proposed approach.

摘要：在經典的人類回饋強化學習 (RLHF) 框架中，
採用近端策略最佳化 (PPO) 從稀疏的句子級獎勵中學習——這是傳統深度強化學習中具有挑戰性的場景。儘管 PPO 在對齊最先進的閉源大型語言模型 (LLM) 方面取得了巨大的成功，但它的開源實作仍然很大程度上次佳，正如許多研究報告中廣泛報導的那樣。為了解決這些問題，我們引入了將 RLHF 問題建模為馬可夫決策過程 (MDP) 的框架，能夠擷取細粒度的 token 資訊。此外，我們提供了理論見解，證明了我們的 MDP 框架優於先前的句子級強盜公式。在這個框架下，我們引入了一種演算法，稱為強化 token 最佳化 (\texttt{RTO})，它從偏好資料中學習 token 獎勵函數，並根據這個學習到的 token 獎勵訊號執行策略最佳化。從理論上來說，\texttt{RTO} 被證明有能力以近乎最佳的策略樣本有效率地尋找。對於它的實際實作，\texttt{RTO} 創新地整合了直接偏好最佳化 (DPO) 和 PPO。DPO 最初來自稀疏的句子獎勵，令人驚訝的是它為我們提供了回應品質的 token 特徵，這被無縫整合到我們後續的 PPO 訓練階段。廣泛的真實世界對齊實驗驗證了所提出方法的有效性。

##### **Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting**
2404.18911v1 by Fangcheng Liu,Yehui Tang,Zhenhua Liu,Yunsheng Ni,Kai Han,Yunhe Wang

Speculative decoding has demonstrated its effectiveness in accelerating the
inference of large language models while maintaining a consistent sampling
distribution. However, the conventional approach of training a separate draft
model to achieve a satisfactory token acceptance rate can be costly. Drawing
inspiration from early exiting, we propose a novel self-speculative decoding
framework \emph{Kangaroo}, which uses a fixed shallow sub-network as a
self-draft model, with the remaining layers serving as the larger target model.
We train a lightweight and efficient adapter module on top of the sub-network
to bridge the gap between the sub-network and the full model's representation
ability. It is noteworthy that the inference latency of the self-draft model
may no longer be negligible compared to the large model, necessitating
strategies to increase the token acceptance rate while minimizing the drafting
steps of the small model. To address this challenge, we introduce an additional
early exiting mechanism for generating draft tokens. Specifically, we halt the
small model's subsequent prediction during the drafting phase once the
confidence level for the current token falls below a certain threshold.
Extensive experiments on the Spec-Bench demonstrate the effectiveness of
Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to
$1.68\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\% fewer additional
parameters (67M compared to 591M). The code for Kangaroo is available at
https://github.com/Equationliu/Kangaroo.

摘要：<paragraph>推測式解碼已證明其在加速大型語言模型的推論的同時，能維持一致的抽樣分佈中發揮其效用。然而，訓練一個單獨的草稿模型以達成令人滿意的符號接受率的傳統方法可能會很昂貴。從早期退出中汲取靈感，我們提出一個新穎的自推測式解碼架構「Kangaroo」，它使用一個固定的淺層子網路作為自草稿模型，而其餘的層則作為較大的目標模型。我們在子網路之上訓練一個輕量且高效的適配器模組，以彌補子網路與完整模型的表示能力之間的差距。值得注意的是，與大型模型相比，自草稿模型的推論延遲可能不再可以忽略不計，因此需要策略來增加符號接受率，同時將小模型的起草步驟降到最低。為了應對這項挑戰，我們引入了一個額外的早期退出機制來產生草稿符號。具體來說，一旦當前符號的信心水準低於某個閾值，我們就會在起草階段暫停小模型的後續預測。在 Spec-Bench 上進行的廣泛實驗證明了 Kangaroo 的效用。在單一序列驗證下，Kangaroo 在 Spec-Bench 上實現了高達 1.68 倍的加速，在附加參數比 Medusa-1 少 88.7% 的情況下表現更出色（67M，相比之下 Medusa-1 為 591M）。Kangaroo 的程式碼可在 https://github.com/Equationliu/Kangaroo 取得。</paragraph>

##### **IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation**
2404.18891v1 by Kebin Wu,Wenbin Li,Xiaofei Xiao

The scarcity of labeled data in real-world scenarios is a critical bottleneck
of deep learning's effectiveness. Semi-supervised semantic segmentation has
been a typical solution to achieve a desirable tradeoff between annotation cost
and segmentation performance. However, previous approaches, whether based on
consistency regularization or self-training, tend to neglect the contextual
knowledge embedded within inter-pixel relations. This negligence leads to
suboptimal performance and limited generalization. In this paper, we propose a
novel approach IPixMatch designed to mine the neglected but valuable
Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch
is constructed as an extension of the standard teacher-student network,
incorporating additional loss terms to capture inter-pixel relations. It shines
in low-data regimes by efficiently leveraging the limited labeled data and
extracting maximum utility from the available unlabeled data. Furthermore,
IPixMatch can be integrated seamlessly into most teacher-student frameworks
without the need of model modification or adding additional components. Our
straightforward IPixMatch method demonstrates consistent performance
improvements across various benchmark datasets under different partitioning
protocols.

摘要：在現實世界中標記資料的稀少性是深度學習有效性的關鍵瓶頸。半監督語意分割一直是實現標註成本和分割性能之間理想折衷方案的典型解決方案。然而，先前的做法，無論是基於一致性正則化還是自訓練，都傾向於忽略嵌入像素間關係中的上下文知識。這種疏忽導致次優性能和有限的泛化。在本文中，我們提出了一種新方法 IPixMatch，旨在挖掘半監督學習中被忽視但有價值的像素間資訊。具體來說，IPixMatch 被構造為標準師生網路的擴展，加入額外的損失項來捕獲像素間關係。它在低資料情況下表現出色，有效利用有限的標記資料，並從可用的未標記資料中提取最大效用。此外，IPixMatch 可以無縫整合到大多數師生框架中，而無需修改模型或添加額外組件。我們簡單的 IPixMatch 方法在不同的分割協議下，在各種基準資料集上展示了一致的性能改進。

##### **A Survey on Diffusion Models for Time Series and Spatio-Temporal Data**
2404.18886v1 by Yiyuan Yang,Ming Jin,Haomin Wen,Chaoli Zhang,Yuxuan Liang,Lintao Ma,Yi Wang,Chenghao Liu,Bin Yang,Zenglin Xu,Jiang Bian,Shirui Pan,Qingsong Wen

The study of time series data is crucial for understanding trends and
anomalies over time, enabling predictive insights across various sectors.
Spatio-temporal data, on the other hand, is vital for analyzing phenomena in
both space and time, providing a dynamic perspective on complex system
interactions. Recently, diffusion models have seen widespread application in
time series and spatio-temporal data mining. Not only do they enhance the
generative and inferential capabilities for sequential and temporal data, but
they also extend to other downstream tasks. In this survey, we comprehensively
and thoroughly review the use of diffusion models in time series and
spatio-temporal data, categorizing them by model category, task type, data
modality, and practical application domain. In detail, we categorize diffusion
models into unconditioned and conditioned types and discuss time series data
and spatio-temporal data separately. Unconditioned models, which operate
unsupervised, are subdivided into probability-based and score-based models,
serving predictive and generative tasks such as forecasting, anomaly detection,
classification, and imputation. Conditioned models, on the other hand, utilize
extra information to enhance performance and are similarly divided for both
predictive and generative tasks. Our survey extensively covers their
application in various fields, including healthcare, recommendation, climate,
energy, audio, and transportation, providing a foundational understanding of
how these models analyze and generate data. Through this structured overview,
we aim to provide researchers and practitioners with a comprehensive
understanding of diffusion models for time series and spatio-temporal data
analysis, aiming to direct future innovations and applications by addressing
traditional challenges and exploring innovative solutions within the diffusion
model framework.

摘要：時間序列資料的研究對於了解趨勢和隨時間發生的異常現象至關重要，並能針對各個領域提供預測見解。另一方面，時空資料對於分析時空中的現象至關重要，並能提供複雜系統互動的動態觀點。最近，擴散模型已在時間序列和時空資料探勘中廣泛應用。它們不僅增強了序列和時間資料的生成和推論能力，也延伸到其他下游任務。在本綜述中，我們全面且徹底地回顧了擴散模型在時間序列和時空資料中的應用，並根據模型類型、任務類型、資料模式和實際應用領域對它們進行分類。詳細來說，我們將擴散模型分類為無條件和條件類型，並分別討論時間序列資料和時空資料。無條件模型以非監督的方式運作，被細分為基於機率和基於評分的模型，用於預測和生成任務，例如預測、異常偵測、分類和填補。另一方面，條件模型利用額外的資訊來增強效能，並針對預測和生成任務進行類似的區分。我們的綜述廣泛涵蓋了它們在各個領域的應用，包括醫療保健、推薦、氣候、能源、音訊和運輸，提供了這些模型如何分析和生成資料的基本理解。透過這個結構化的概觀，我們旨在為研究人員和實務工作者提供對時間序列和時空資料分析的擴散模型的全面理解，並透過解決傳統挑戰和在擴散模型架構中探索創新解決方案，來引導未來的創新和應用。

##### **Spivavtor: An Instruction Tuned Ukrainian Text Editing Model**
2404.18880v1 by Aman Saini,Artem Chernodub,Vipul Raheja,Vivek Kulkarni

We introduce Spivavtor, a dataset, and instruction-tuned models for text
editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused
adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor
performs text editing tasks by following instructions in Ukrainian. This paper
describes the details of the Spivavtor-Instruct dataset and Spivavtor models.
We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as
Grammatical Error Correction (GEC), Text Simplification, Coherence, and
Paraphrasing, and demonstrate its superior performance on all of them. We
publicly release our best-performing models and data as resources to the
community to advance further research in this space.

摘要：我們介紹 Spivavtor，一個專注於烏克蘭語的資料集和指令調整模型，用於文字編輯。Spivavtor 是僅限英文的 CoEdIT 模型的烏克蘭語專用改編版本。與 CoEdIT 類似，Spivavtor 透過遵循烏克蘭語中的指令來執行文字編輯任務。本文說明了 Spivavtor-Instruct 資料集和 Spivavtor 模型的詳細資訊。我們在烏克蘭語的各種文字編輯任務中評估 Spivavtor，例如文法錯誤修正 (GEC)、文字簡化、連貫性和同義改寫，並展示其在所有任務中的卓越效能。我們公開發布我們效能最佳的模型和資料，作為資源提供給社群，以推進此領域的進一步研究。

##### **OpenStreetView-5M: The Many Roads to Global Visual Geolocation**
2404.18873v1 by Guillaume Astruc,Nicolas Dufour,Ioannis Siglidis,Constantin Aronssohn,Nacim Bouia,Stephanie Fu,Romain Loiseau,Van Nguyen Nguyen,Charles Raude,Elliot Vincent,Lintao XU,Hongyu Zhou,Loic Landrieu

Determining the location of an image anywhere on Earth is a complex visual
task, which makes it particularly relevant for evaluating computer vision
algorithms. Yet, the absence of standard, large-scale, open-access datasets
with reliably localizable images has limited its potential. To address this
issue, we introduce OpenStreetView-5M, a large-scale, open-access dataset
comprising over 5.1 million geo-referenced street view images, covering 225
countries and territories. In contrast to existing benchmarks, we enforce a
strict train/test separation, allowing us to evaluate the relevance of learned
geographical features beyond mere memorization. To demonstrate the utility of
our dataset, we conduct an extensive benchmark of various state-of-the-art
image encoders, spatial representations, and training strategies. All
associated codes and models can be found at https://github.com/gastruc/osv5m.

摘要：確定地球上任何地方的影像位置是一項複雜的視覺任務，這讓它在評估電腦視覺演算法時特別相關。然而，缺乏標準、大規模、開放存取的資料集，且具有可信度高的可定位影像，限制了它的潛力。為了解決這個問題，我們引進了 OpenStreetView-5M，一個大規模、開放存取的資料集，包含超過 510 萬張地理參照街景影像，涵蓋 225 個國家和地區。與現有的基準測試不同，我們實施了嚴格的訓練/測試分離，讓我們得以評估學習到的地理特徵與單純記憶之間的關聯性。為了展示我們資料集的效用，我們對各種最先進的影像編碼器、空間表示和訓練策略進行了廣泛的基準測試。所有相關程式碼和模型都可以在 https://github.com/gastruc/osv5m 找到。

##### **More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness**
2404.18870v1 by Aaron J. Li,Satyapriya Krishna,Himabindu Lakkaraju

The surge in Large Language Models (LLMs) development has led to improved
performance on cognitive tasks as well as an urgent need to align these models
with human values in order to safely exploit their power. Despite the
effectiveness of preference learning algorithms like Reinforcement Learning
From Human Feedback (RLHF) in aligning human preferences, their assumed
improvements on model trustworthiness haven't been thoroughly testified. Toward
this end, this study investigates how models that have been aligned with
general-purpose preference data on helpfulness and harmlessness perform across
five trustworthiness verticals: toxicity, stereotypical bias, machine ethics,
truthfulness, and privacy. For model alignment, we focus on three widely used
RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO),
and Direct Preference Optimization (DPO). Through extensive empirical
investigations, we discover that the improvement in trustworthiness by RLHF is
far from guaranteed, and there exists a complex interplay between preference
data, alignment algorithms, and specific trustworthiness aspects. Together, our
results underscore the need for more nuanced approaches for model alignment. By
shedding light on the intricate dynamics of these components within model
alignment, we hope this research will guide the community towards developing
language models that are both capable and trustworthy.

摘要：大型語言模型 (LLM) 的發展激增已導致認知任務的效能提升，以及迫切需要將這些模型與人類價值觀保持一致，以安全地利用其力量。儘管像人類回饋強化學習 (RLHF) 等偏好學習演算法在調整人類偏好方面很有效，但它們在模型可信度方面的假設改進尚未經過徹底驗證。為此，本研究探討了已根據對有益性和無害性的通用偏好資料調整的模型，在五個可信度垂直領域中的表現：毒性、刻板印象偏見、機器倫理、真實性和隱私。對於模型調整，我們專注於三個廣泛使用的 RLHF 變體：監督微調 (SFT)、近端策略最佳化 (PPO) 和直接偏好最佳化 (DPO)。透過廣泛的實證調查，我們發現 RLHF 對可信度的改善遠非有保證，而且偏好資料、調整演算法和特定可信度面向之間存在複雜的相互作用。我們的結果共同強調了對模型調整需要更細緻方法的必要性。透過闡明模型調整中這些組成部分的複雜動態，我們希望這項研究能引導社群開發既有能力又可信賴的語言模型。

##### **Truth-value judgment in language models: belief directions are context sensitive**
2404.18865v1 by Stefan F. Schouten,Peter Bloem,Ilia Markov,Piek Vossen

Recent work has demonstrated that the latent spaces of large language models
(LLMs) contain directions predictive of the truth of sentences. Multiple
methods recover such directions and build probes that are described as getting
at a model's "knowledge" or "beliefs". We investigate this phenomenon, looking
closely at the impact of context on the probes. Our experiments establish where
in the LLM the probe's predictions can be described as being conditional on the
preceding (related) sentences. Specifically, we quantify the responsiveness of
the probes to the presence of (negated) supporting and contradicting sentences,
and score the probes on their consistency. We also perform a causal
intervention experiment, investigating whether moving the representation of a
premise along these belief directions influences the position of the hypothesis
along that same direction. We find that the probes we test are generally
context sensitive, but that contexts which should not affect the truth often
still impact the probe outputs. Our experiments show that the type of errors
depend on the layer, the (type of) model, and the kind of data. Finally, our
results suggest that belief directions are (one of the) causal mediators in the
inference process that incorporates in-context information.

摘要：最近的研究表明大型语言模型（LLM）的潜在空间包含预测句子真实性的方向。多种方法恢复此类方向并构建探针，这些探针被描述为获取模型的“知识”或“信念”。我们调查了这种现象，仔细研究了上下文对探针的影响。我们的实验确定了 LLM 中探针的预测可以在何处被描述为以先前的（相关）句子为条件。具体来说，我们量化了探针对（否定）支持和矛盾句子的存在做出反应的能力，并根据其一致性对探针进行评分。我们还执行了一个因果干预实验，调查移动前提表示是否沿着这些信念方向影响假设在同一方向上的位置。我们发现我们测试的探针通常对上下文敏感，但通常不应该影响真实性的上下文仍然会影响探针输出。我们的实验表明，错误的类型取决于层、模型（类型）和数据类型。最后，我们的结果表明，信念方向是推理过程中（一种）因果中介，其中包含上下文信息。

##### **Performance-Aligned LLMs for Generating Fast Code**
2404.18864v1 by Daniel Nichols,Pranav Polasam,Harshitha Menon,Aniruddha Marathe,Todd Gamblin,Abhinav Bhatele

Optimizing scientific software is a difficult task because codebases are
often large and complex, and performance can depend upon several factors
including the algorithm, its implementation, and hardware among others. Causes
of poor performance can originate from disparate sources and be difficult to
diagnose. Recent years have seen a multitude of work that use large language
models (LLMs) to assist in software development tasks. However, these tools are
trained to model the distribution of code as text, and are not specifically
designed to understand performance aspects of code. In this work, we introduce
a reinforcement learning based methodology to align the outputs of code LLMs
with performance. This allows us to build upon the current code modeling
capabilities of LLMs and extend them to generate better performing code. We
demonstrate that our fine-tuned model improves the expected speedup of
generated code over base models for a set of benchmark tasks from 0.9 to 1.6
for serial code and 1.9 to 4.5 for OpenMP code.

摘要：優化科學軟體是一項艱難的任務，因為程式碼庫通常龐大且複雜，而效能可能取決於演算法、其實作和硬體等多項因素。效能不佳的原因可能來自不同的來源，且難以診斷。近年來，有許多工作使用大型語言模型 (LLM) 來協助軟體開發任務。然而，這些工具經過訓練，可以將程式碼的分布建模為文字，但並非特別設計用於了解程式碼的效能面向。在這項工作中，我們引入一種基於強化學習的方法，以將程式碼 LLM 的輸出與效能對齊。這讓我們能夠建立在 LLM 目前的程式碼建模能力之上，並將其延伸到產生效能更好的程式碼。我們展示出，針對一組基準任務，我們微調過的模型將產生的程式碼預期加速從基本模型的 0.9 到 1.6（序列程式碼）和 1.9 到 4.5（OpenMP 程式碼）提升。

##### **A Comprehensive Rubric for Annotating Pathological Speech**
2404.18851v1 by Mario Corrales-Astorgano,David Escudero-Mancebo,Lourdes Aguilar,Valle Flores-Lucas,Valentín Cardeñoso-Payo,Carlos Vivaracho-Pascual,César González-Ferreras

Rubrics are a commonly used tool for labeling voice corpora in speech quality
assessment, although their application in the context of pathological speech
remains relatively limited. In this study, we introduce a comprehensive rubric
based on various dimensions of speech quality, including phonetics, fluency,
and prosody. The objective is to establish standardized criteria for
identifying errors within the speech of individuals with Down syndrome, thereby
enabling the development of automated assessment systems. To achieve this
objective, we utilized the Prautocal corpus. To assess the quality of
annotations using our rubric, two experiments were conducted, focusing on
phonetics and fluency. For phonetic evaluation, we employed the Goodness of
Pronunciation (GoP) metric, utilizing automatic segmentation systems and
correlating the results with evaluations conducted by a specialized speech
therapist. While the obtained correlation values were not notably high, a
positive trend was observed. In terms of fluency assessment, deep learning
models like wav2vec were used to extract audio features, and we employed an SVM
classifier trained on a corpus focused on identifying fluency issues to
categorize Prautocal corpus samples. The outcomes highlight the complexities of
evaluating such phenomena, with variability depending on the specific type of
disfluency detected.

摘要：評分標準是標示語音品質評估中語音語料庫的常用工具，儘管它們在病理性語音脈絡中的應用仍然相對有限。在本研究中，我們根據語音品質的各種面向，包括語音學、流暢度和語調，引入了一個全面的評分標準。目標是為識別唐氏症患者語音中的錯誤建立標準化準則，從而能夠開發自動化評估系統。為達成此目標，我們利用了 Prautocal 語料庫。為了使用我們的評分標準評估註解的品質，我們進行了兩項實驗，重點關注語音學和流暢度。對於語音學評估，我們採用了發音優良度 (GoP) 指標，利用自動分段系統，並將結果與專門的語言治療師進行的評估結果進行對應。儘管獲得的相關性值並不算高，但仍觀察到正向趨勢。在流暢度評估方面，我們使用深度學習模型，如 wav2vec，來提取音訊特徵，並採用針對識別流暢度問題的語料庫訓練的 SVM 分類器，對 Prautocal 語料庫樣本進行分類。結果突顯了評估此類現象的複雜性，變異性取決於所檢測到的特定類型的不流暢。

##### **FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition**
2404.18848v1 by Yuxuan Yan,Shunpu Tang,Zhiguo Shi,Qianqian Yang

Pre-trained Language Models (PLMs) have shown excellent performance on
various downstream tasks after fine-tuning. Nevertheless, the escalating
concerns surrounding user privacy have posed significant challenges to
centralized training reliant on extensive data collection. Federated
learning(FL), which only requires training on the clients and aggregates
weights on the server without sharing data, has emerged as a solution. However,
the substantial parameter size of PLMs places a significant burden on the
computational resources of client devices, while also leading to costly
communication expenses. Introducing Parameter-Efficient Fine-Tuning(PEFT) into
FL can effectively address this problem. However, we observe that the non-IID
data in federated learning leads to a gap in performance between the PEFT
method and full parameter fine-tuning(FT). To overcome this, we propose FeDeRA,
an improvement over the LoRA method in FL. FeDeRA uses the same adapter module
as LoRA. However, the difference lies in FeDeRA's initialization of the adapter
module by performing Singular Value Decomposition (SVD) on the pre-trained
matrix and selecting its principal components. We conducted extensive
experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets,
comparing the methods including FT and the other three different PEFT methods.
FeDeRA outperforms all other PEFT methods and is comparable to or even
surpasses the performance of FT methods. We also deployed federated learning on
Jetson AGX Orin and compared the time required by different methods to achieve
the target accuracy on specific tasks. Compared to FT, FeDeRA reduces the
training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively
on three tasks using RoBERTa and DeBERTaV3. The overall experiments indicate
that FeDeRA achieves good performance while also maintaining efficiency.

摘要：<paragraph>預訓練語言模型 (PLM) 在微調後於各種下游任務中展現出優異的效能。儘管如此，圍繞使用者隱私的日益升高的疑慮對仰賴廣泛資料蒐集的集中式訓練構成重大挑戰。聯邦學習 (FL) 僅需在用戶端訓練，並在伺服器上彙總權重，而無須分享資料，因此成為一種解決方案。然而，PLM 龐大的參數規模對用戶端裝置的運算資源造成顯著負擔，同時也導致高昂的通訊費用。將參數有效微調 (PEFT) 引入 FL 可以有效解決這個問題。然而，我們觀察到聯邦學習中的非獨立同分布 (non-IID) 資料會導致 PEFT 方法與完全參數微調 (FT) 之間的效能差距。為了克服這一點，我們提出 FeDeRA，這是一種改進 FL 中 LoRA 方法的方法。FeDeRA 使用與 LoRA 相同的適配器模組。然而，FeDeRA 的不同之處在於它透過對預訓練矩陣執行奇異值分解 (SVD) 並選擇其主成份來初始化適配器模組。我們使用 RoBERTa 和 DeBERTaV3 針對三項任務和六個資料集進行廣泛的實驗，比較包括 FT 和其他三種不同的 PEFT 方法。FeDeRA 優於所有其他 PEFT 方法，並且與 FT 方法的效能相當，甚至超越。我們還將聯邦學習部署在 Jetson AGX Orin 上，並比較不同方法在特定任務上達到目標準確度所需的時間。與 FT 相比，FeDeRA 在使用 RoBERTa 和 DeBERTaV3 的三項任務上分別將訓練時間減少了 95.9%、97.9%、96.9% 和 97.3%、96.5% 和 96.5%。整體實驗結果顯示 FeDeRA 在維持效率的同時，也達到了良好的效能。</paragraph>

##### **It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments**
2404.18832v1 by Petter Mæhlum,David Samuel,Rebecka Maria Norman,Elma Jelin,Øyvind Andresen Bjertnæs,Lilja Øvrelid,Erik Velldal

Sentiment analysis is an important tool for aggregating patient voices, in
order to provide targeted improvements in healthcare services. A prerequisite
for this is the availability of in-domain data annotated for sentiment. This
article documents an effort to add sentiment annotations to free-text comments
in patient surveys collected by the Norwegian Institute of Public Health
(NIPH). However, annotation can be a time-consuming and resource-intensive
process, particularly when it requires domain expertise. We therefore also
evaluate a possible alternative to human annotation, using large language
models (LLMs) as annotators. We perform an extensive evaluation of the approach
for two openly available pretrained LLMs for Norwegian, experimenting with
different configurations of prompts and in-context learning, comparing their
performance to human annotators. We find that even for zero-shot runs, models
perform well above the baseline for binary sentiment, but still cannot compete
with human annotators on the full dataset.

摘要：情緒分析是彙整患者意見的重要工具，目的是提供針對性的醫療服務改進。要達到此目的，前提是取得已針對情緒標記的領域內資料。本文記錄了針對挪威公共衛生研究所 (NIPH) 所收集的患者調查中的自由文字評論新增情緒標記的努力。然而，標記可能是一個耗時且耗費資源的過程，特別是在需要領域專業知識時。因此，我們也評估了人工標記的替代方案，使用大型語言模型 (LLM) 作為標記者。我們針對兩種開放取得的挪威語預訓練 LLM 執行廣泛的評估，實驗使用提示和情境學習的不同設定，並將其效能與人工標記者進行比較。我們發現，即使是零次學習，模型在二元情緒的基準上表現良好，但仍無法在完整資料集上與人工標記者競爭。

##### **Harmonic Machine Learning Models are Robust**
2404.18825v1 by Nicholas S. Kersting,Yi Li,Aman Mohanty,Oyindamola Obisesan,Raphael Okochu

We introduce Harmonic Robustness, a powerful and intuitive method to test the
robustness of any machine-learning model either during training or in black-box
real-time inference monitoring without ground-truth labels. It is based on
functional deviation from the harmonic mean value property, indicating
instability and lack of explainability. We show implementation examples in
low-dimensional trees and feedforward NNs, where the method reliably identifies
overfitting, as well as in more complex high-dimensional models such as
ResNet-50 and Vision Transformer where it efficiently measures adversarial
vulnerability across image classes.

摘要：我們介紹調和穩健性，這是一種強大且直觀的方法，可以在訓練期間或在黑盒實時推論監控中測試任何機器學習模型的穩健性，而無需依賴真實標籤。它基於與調和平均值屬性的函數偏差，表示不穩定性和缺乏可解釋性。我們在低維樹和前饋神經網路中展示了實作範例，其中該方法可靠地識別過度擬合，以及在更複雜的高維模型（例如 ResNet-50 和視覺轉換器）中，它可以有效地衡量跨影像類別的對抗性脆弱性。

##### **Benchmarking Benchmark Leakage in Large Language Models**
2404.18824v1 by Ruijie Xu,Zengzhi Wang,Run-Ze Fan,Pengfei Liu

Amid the expanding use of pre-training data, the phenomenon of benchmark
dataset leakage has become increasingly prominent, exacerbated by opaque
training processes and the often undisclosed inclusion of supervised data in
contemporary Large Language Models (LLMs). This issue skews benchmark
effectiveness and fosters potentially unfair comparisons, impeding the field's
healthy development. To address this, we introduce a detection pipeline
utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that
gauge a model's prediction precision on benchmark, to identify potential data
leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we
reveal substantial instances of training even test set misuse, resulting in
potentially unfair comparisons. These findings prompt us to offer several
recommendations regarding model documentation, benchmark setup, and future
evaluations. Notably, we propose the "Benchmark Transparency Card" to encourage
clear documentation of benchmark utilization, promoting transparency and
healthy developments of LLMs. we have made our leaderboard, pipeline
implementation, and model predictions publicly available, fostering future
research.

摘要：隨著預訓練資料的使用範圍擴大，基準資料外洩的現象變得越來越明顯，原因是訓練過程不透明，以及當代大型語言模型 (LLM) 中經常不公開包含監督式資料。這個問題會扭曲基準的效用，並促進潛在不公平的比較，阻礙該領域的健康發展。為了解決這個問題，我們引進了一個檢測管道，利用困惑度和 N-gram 精確度這兩個簡單且可擴充的指標，來衡量模型在基準上的預測精準度，以識別潛在的資料外洩。透過在數學推理的背景下分析 31 個 LLM，我們揭露了大量訓練甚至誤用測試集的案例，導致潛在不公平的比較。這些發現促使我們提出多項關於模型文件、基準設定和未來評估的建議。值得注意的是，我們提出「基準透明度卡」，以鼓勵清楚記錄基準利用，促進 LLM 的透明度和健康發展。我們已公開我們的排行榜、管道實作和模型預測，以促進未來的研究。

##### **Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies**
2404.18821v1 by Seyed Soroush Karimi Madahi,Gargya Gokhale,Marie-Sophie Verwee,Bert Claessens,Chris Develder

A continuous rise in the penetration of renewable energy sources, along with
the use of the single imbalance pricing, provides a new opportunity for balance
responsible parties to reduce their cost through energy arbitrage in the
imbalance settlement mechanism. Model-free reinforcement learning (RL) methods
are an appropriate choice for solving the energy arbitrage problem due to their
outstanding performance in solving complex stochastic sequential problems.
However, RL is rarely deployed in real-world applications since its learned
policy does not necessarily guarantee safety during the execution phase. In
this paper, we propose a new RL-based control framework for batteries to obtain
a safe energy arbitrage strategy in the imbalance settlement mechanism. In our
proposed control framework, the agent initially aims to optimize the arbitrage
revenue. Subsequently, in the post-processing step, we correct (constrain) the
learned policy following a knowledge distillation process based on properties
that follow human intuition. Our post-processing step is a generic method and
is not restricted to the energy arbitrage domain. We use the Belgian imbalance
price of 2023 to evaluate the performance of our proposed framework.
Furthermore, we deploy our proposed control framework on a real battery to show
its capability in the real world.

摘要：隨著可再生能源滲透率持續上升，再加上單一不平衡定價的使用，為平衡責任方透過不平衡結算機制中的能源套利來降低其成本提供了新的機會。無模型強化學習 (RL) 方法由於其在解決複雜隨機順序問題方面的出色表現，是解決能源套利問題的適當選擇。然而，由於其學習的策略並不能保證在執行階段的安全，因此 RL 很少部署在實際應用中。在本文中，我們提出了一個新的基於 RL 的電池控制框架，以在不平衡結算機制中獲得安全的能源套利策略。在我們提出的控制框架中，代理最初旨在優化套利收入。隨後，在後處理步驟中，我們根據遵循人類直覺的屬性，遵循知識提煉過程更正（約束）學習的策略。我們的後處理步驟是一種通用方法，並不限於能源套利領域。我們使用 2023 年比利時不平衡價格來評估我們提出的框架的性能。此外，我們將我們提出的控制框架部署在一個真實的電池上，以展示其在現實世界中的能力。

##### **Unknown Script: Impact of Script on Cross-Lingual Transfer**
2404.18810v1 by Wondimagegnhue Tsegaye Tufa,Ilia Markov,Piek Vossen

Cross-lingual transfer has become an effective way of transferring knowledge
between languages. In this paper, we explore an often-overlooked aspect in this
domain: the influence of the source language of the base language model on
transfer performance. We conduct a series of experiments to determine the
effect of the script and tokenizer used in the pre-trained model on the
performance of the downstream task. Our findings reveal the importance of the
tokenizer as a stronger factor than the sharing of the script, the language
typology match, and the model size.

摘要：跨語言轉移已成為在語言之間傳遞知識的有效方式。在本文中，我們探討了在這個領域中經常被忽視的一個方面：基礎語言模型的原始語言對轉移效能的影響。我們進行了一系列實驗，以確定預訓練模型中使用的腳本和分詞器對下游任務效能的影響。我們的發現揭示了分詞器作為一個比腳本共享、語言類型匹配和模型大小更強大的因素的重要性。

##### **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**
2404.18796v1 by Pat Verga,Sebastian Hofstatter,Sophia Althammer,Yixuan Su,Aleksandra Piktus,Arkady Arkhangorodsky,Minjie Xu,Naomi White,Patrick Lewis

As Large Language Models (LLMs) have become more advanced, they have outpaced
our abilities to accurately evaluate their quality. Not only is finding data to
adequately probe particular model properties difficult, but evaluating the
correctness of a model's freeform generation alone is a challenge. To address
this, many evaluations now rely on using LLMs themselves as judges to score the
quality of outputs from other LLMs. Evaluations most commonly use a single
large model like GPT4. While this method has grown in popularity, it is costly,
has been shown to introduce intramodel bias, and in this work, we find that
very large models are often unnecessary. We propose instead to evaluate models
using a Panel of LLm evaluators (PoLL). Across three distinct judge settings
and spanning six different datasets, we find that using a PoLL composed of a
larger number of smaller models outperforms a single large judge, exhibits less
intra-model bias due to its composition of disjoint model families, and does so
while being over seven times less expensive.

摘要：隨著大型語言模型 (LLM) 的進步，它們已經超越了我們準確評估其品質的能力。不僅難以找到資料來充分探測特定模型屬性，單獨評估模型自由形式生成的正確性也是一項挑戰。為了解決這個問題，許多評估現在依賴於使用 LLM 本身作為評審，以評分來自其他 LLM 的輸出的品質。評估最常使用單一的大型模型，例如 GPT4。雖然這種方法越來越受歡迎，但它很昂貴，已被證明會引入模型內部偏差，並且在這項工作中，我們發現非常大的模型通常是不必要的。我們建議改用 LLM 評審小組 (PoLL) 來評估模型。在三個不同的評審設定和涵蓋六個不同資料集的情況下，我們發現使用由大量較小模型組成的 PoLL，其表現優於單一大型評審，由於其由不相交的模型家族組成，因此表現出較少的模型內部偏差，同時成本降低了七倍以上。

##### **Certification of Speaker Recognition Models to Additive Perturbations**
2404.18791v1 by Dmitrii Korzh,Elvir Karimov,Mikhail Pautov,Oleg Y. Rogov,Ivan Oseledets

Speaker recognition technology is applied in various tasks ranging from
personal virtual assistants to secure access systems. However, the robustness
of these systems against adversarial attacks, particularly to additive
perturbations, remains a significant challenge. In this paper, we pioneer
applying robustness certification techniques to speaker recognition, originally
developed for the image domain. In our work, we cover this gap by transferring
and improving randomized smoothing certification techniques against
norm-bounded additive perturbations for classification and few-shot learning
tasks to speaker recognition. We demonstrate the effectiveness of these methods
on VoxCeleb 1 and 2 datasets for several models. We expect this work to improve
voice-biometry robustness, establish a new certification benchmark, and
accelerate research of certification methods in the audio domain.

摘要：語音辨識技術應用於從個人虛擬助理到安全存取系統等各種任務。然而，這些系統對抗攻擊的穩健性，特別是對加法擾動，仍然是一項重大的挑戰。在本文中，我們率先將原本開發用於影像領域的穩健性認證技術應用於語音辨識。在我們的研究中，我們透過將針對分類和少樣本學習任務的範數約束加法擾動的隨機平滑認證技術轉移並加以改進，來填補這個空白，以應用於語音辨識。我們在 VoxCeleb 1 和 2 資料集上針對多個模型展示了這些方法的有效性。我們預期這項研究將改善語音生物辨識的穩健性，建立新的認證基準，並加速音訊領域認證方法的研究。

##### **Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input**
2404.18784v1 by Tessa Masis,Brendan O'Connor

Geo-entity linking is the task of linking a location mention to the
real-world geographic location. In this paper we explore the challenging task
of geo-entity linking for noisy, multilingual social media data. There are few
open-source multilingual geo-entity linking tools available and existing ones
are often rule-based, which break easily in social media settings, or
LLM-based, which are too expensive for large-scale datasets. We present a
method which represents real-world locations as averaged embeddings from
labeled user-input location names and allows for selective prediction via an
interpretable confidence score. We show that our approach improves geo-entity
linking on a global and multilingual social media dataset, and discuss progress
and problems with evaluating at different geographic granularities.

摘要：地理實體連結是將位置提及連結到真實世界地理位置的任務。在本文中，我們探討了對雜訊、多語言社群媒體資料進行地理實體連結的挑戰性任務。目前只有少數開放原始碼的多語言地理實體連結工具可用，而現有的工具通常基於規則，在社群媒體設定中容易中斷，或基於 LLM，這對於大規模資料集而言過於昂貴。我們提出了一種方法，將真實世界的位置表示為標記使用者輸入位置名稱的平均嵌入，並允許透過可解釋的信心分數進行選擇性預測。我們展示了我們的做法改進了全球且多語言的社群媒體資料集上的地理實體連結，並討論了在不同地理粒度下評估的進度和問題。

##### **Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain**
2404.18772v1 by Gustaw Opiełka,Jessica Loke,Steven Scholte

Deep learning algorithms lack human-interpretable accounts of how they
transform raw visual input into a robust semantic understanding, which impedes
comparisons between different architectures, training objectives, and the human
brain. In this work, we take inspiration from neuroscience and employ
representational approaches to shed light on how neural networks encode
information at low (visual saliency) and high (semantic similarity) levels of
abstraction. Moreover, we introduce a custom image dataset where we
systematically manipulate salient and semantic information. We find that
ResNets are more sensitive to saliency information than ViTs, when trained with
object classification objectives. We uncover that networks suppress saliency in
early layers, a process enhanced by natural language supervision (CLIP) in
ResNets. CLIP also enhances semantic encoding in both architectures. Finally,
we show that semantic encoding is a key factor in aligning AI with human visual
perception, while saliency suppression is a non-brain-like strategy.

摘要：深度學習演算法缺乏人類可解釋的說明，說明它們如何將原始視覺輸入轉換為穩健的語義理解，這阻礙了不同架構、訓練目標和人腦之間的比較。在這項工作中，我們從神經科學中汲取靈感，並採用表徵方法來闡明神經網路如何在低（視覺顯著性）和高（語義相似性）抽象層級編碼資訊。此外，我們引入一個自訂圖像資料集，其中我們系統性地處理顯著和語義資訊。我們發現，在使用物件分類目標訓練時，ResNet 對顯著性資訊比 ViT 更敏感。我們發現網路會在早期層級抑制顯著性，這個過程在 ResNet 中會因自然語言監督 (CLIP) 而增強。CLIP 也增強了兩種架構中的語義編碼。最後，我們表明語義編碼是將 AI 與人類視覺知覺對齊的關鍵因素，而顯著性抑制是一種非大腦式的策略。

##### **PECC: Problem Extraction and Coding Challenges**
2404.18766v1 by Patrick Haller,Jonas Golde,Alan Akbik

Recent advancements in large language models (LLMs) have showcased their
exceptional abilities across various tasks, such as code generation,
problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation,
yet the extent to which LLMs can understand prose-style tasks, identify the
underlying problems, and then generate appropriate code solutions is still
unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived
from Advent Of Code (AoC) challenges and Project Euler, including 2396
problems. Unlike conventional benchmarks, PECC requires LLMs to interpret
narrative-embedded problems, extract requirements, and generate executable
code. A key feature of our dataset is the complexity added by natural language
prompting in chat-based evaluations, mirroring real-world instruction
ambiguities. Results show varying model performance between narrative and
neutral problems, with specific challenges in the Euler math-based subset with
GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler
problems. By probing the limits of LLMs' capabilities, our benchmark provides a
framework to monitor and assess the subsequent progress of LLMs as a universal
problem solver.

摘要：大型語言模型 (LLM) 的最新進展展示了它們在各種任務中的卓越能力，例如程式碼生成、問題解決和推理。現有的基準會孤立地評估任務，但 LLM 理解散文式任務、識別潛在問題，然後產生適當程式碼解決方案的能力仍未被探索。為了填補這個空白，我們引入了 PECC，一個源自 Advent Of Code (AoC) 挑戰和歐拉計畫的新基準，包括 2396 個問題。與傳統基準不同，PECC 要求 LLM 解釋嵌入式敘述的問題、提取需求並產生可執行的程式碼。我們資料集的一個關鍵特徵是透過聊天式評估中加入自然語言提示所增加的複雜性，反映了真實世界的指令模糊性。結果顯示，在敘述和中立問題之間，模型效能有所不同，在歐拉數學子集中，GPT-3.5-Turbo 通過 50% 的 AoC 挑戰，但在歐拉問題中只有 8%。透過探討 LLM 能力的極限，我們的基準提供了一個架構來監控和評估 LLM 作為通用問題解決者的後續進展。

##### **Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective**
2404.18759v1 by Juraj Vladika,Stephen Meisenbacher,Martina Preis,Alexandra Klymenko,Florian Matthes

In recent years, the field of Legal Tech has risen in prevalence, as the
Natural Language Processing (NLP) and legal disciplines have combined forces to
digitalize legal processes. Amidst the steady flow of research solutions
stemming from the NLP domain, the study of use cases has fallen behind, leading
to a number of innovative technical methods without a place in practice. In
this work, we aim to build a structured overview of Legal Tech use cases,
grounded in NLP literature, but also supplemented by voices from legal practice
in Germany. Based upon a Systematic Literature Review, we identify seven
categories of NLP technologies for the legal domain, which are then studied in
juxtaposition to 22 legal use cases. In the investigation of these use cases,
we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the
potential concerns of digitally transforming the legal domain.

摘要：近年來，法律科技領域的普及率有所提升，因為自然語言處理 (NLP) 和法律學科已結合力量，將法律程序數位化。在來自 NLP 領域的穩定研究解決方案中，使用案例的研究落後，導致許多創新的技術方法無法實務應用。在這項工作中，我們旨在建立法律科技使用案例的結構化概觀，以 NLP 文獻為基礎，並補充德國法律實務的見解。根據系統性文獻回顧，我們找出七類法律領域的 NLP 技術，然後與 22 個法律使用案例並置研究。在調查這些使用案例時，我們找出 15 個倫理、法律和社會面向 (ELSA)，揭示數位轉型法律領域的潛在問題。

##### **Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment**
2404.18747v1 by Shanle Yao,Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi

Video Anomaly Detection (VAD) identifies unusual activities in video streams,
a key technology with broad applications ranging from surveillance to
healthcare. Tackling VAD in real-life settings poses significant challenges due
to the dynamic nature of human actions, environmental variations, and domain
shifts. Many research initiatives neglect these complexities, often
concentrating on traditional testing methods that fail to account for
performance on unseen datasets, creating a gap between theoretical models and
their real-world utility. Online learning is a potential strategy to mitigate
this issue by allowing models to adapt to new information continuously. This
paper assesses how well current VAD algorithms can adjust to real-life
conditions through an online learning framework, particularly those based on
pose analysis, for their efficiency and privacy advantages. Our proposed
framework enables continuous model updates with streaming data from novel
environments, thus mirroring actual world challenges and evaluating the models'
ability to adapt in real-time while maintaining accuracy. We investigate three
state-of-the-art models in this setting, focusing on their adaptability across
different domains. Our findings indicate that, even under the most challenging
conditions, our online learning approach allows a model to preserve 89.39% of
its original effectiveness compared to its offline-trained counterpart in a
specific target domain.

摘要：視訊異常偵測 (VAD) 可識別視訊串流中的異常活動，
這項關鍵技術的應用範圍很廣，從監控到醫療保健都有。在現實生活中應對 VAD 會遇到重大挑戰，因為人類行為的動態特性、環境變異和領域轉移。許多研究計畫忽略了這些複雜性，通常專注於傳統的測試方法，這些方法無法說明在未見過的資料集上的效能，造成理論模型與其實際效用之間的差距。線上學習是一種潛在策略，可透過讓模型持續適應新資訊來減輕這個問題。本文評估目前的 VAD 演算法在線上學習架構中能有多好地適應現實生活條件，特別是那些基於姿勢分析的演算法，因為它們具有效率和隱私優勢。我們提出的架構能透過來自新環境的串流資料連續更新模型，從而反映實際世界的挑戰，並評估模型在維持準確度的同時適應即時環境的能力。我們在這個設定中研究了三種最先進的模型，重點關注它們在不同領域中的適應能力。我們的研究結果表明，即使在最具挑戰性的條件下，我們的線上學習方法也能讓模型保留其原始效能的 89.39%，而特定目標領域中經過離線訓練的模型則無法做到。

##### **Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**
2404.18739v1 by Artem Abzaliev,Humberto Pérez Espinosa,Rada Mihalcea

Similar to humans, animals make extensive use of verbal and non-verbal forms
of communication, including a large range of audio signals. In this paper, we
address dog vocalizations and explore the use of self-supervised speech
representation models pre-trained on human speech to address dog bark
classification tasks that find parallels in human-centered tasks in speech
recognition. We specifically address four tasks: dog recognition, breed
identification, gender classification, and context grounding. We show that
using speech embedding representations significantly improves over simpler
classification baselines. Further, we also find that models pre-trained on
large human speech acoustics can provide additional performance boosts on
several tasks.

摘要：與人類相似，動物廣泛使用語言和非語言形式的溝通方式，包括大量的音訊訊號。在本文中，我們探討狗的吠叫聲，並探索使用在人類語音上預先訓練的自監督式語音表示模型來處理狗吠聲分類任務，這些任務與以人類為中心的語音辨識任務有相似之處。我們特別探討四項任務：狗隻辨識、品種辨識、性別分類和情境基礎。我們證明使用語音嵌入表示法顯著優於較簡單的分類基準。此外，我們也發現在大規模人類語音聲學上預先訓練的模型可以在多項任務中提供額外的效能提升。

##### **The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages**
2404.18726v1 by Wondimagegnhue Tsegaye Tufa,Ilia Markov,Piek Vossen

Toxic language remains an ongoing challenge on social media platforms,
presenting significant issues for users and communities. This paper provides a
cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We
collect 1.5 million comment threads from 481 communities in six languages:
English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as
Culture, Politics, and News. We thoroughly analyze how toxicity spikes within
different communities in relation to specific topics. We observe consistent
patterns of increased toxicity across languages for certain topics, while also
noting significant variations within specific language communities.

摘要：有毒的語言仍然是社交媒體平台上持續存在的挑戰，對使用者和社群造成重大問題。本文提供 Reddit 對話中跨主題和跨語言的毒性分析。我們從六種語言的 481 個社群中收集了 150 萬個留言串：英語、德語、西班牙語、土耳其語、阿拉伯語和荷蘭語，涵蓋文化、政治和新聞等 80 個主題。我們徹底分析了毒性如何在不同的社群中與特定主題相關聯而激增。我們觀察到，某些主題在所有語言中都出現毒性增加的一致模式，同時也注意到特定語言社群內的顯著差異。

##### **Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library**
2404.18722v1 by Solène Tarride,Yoann Schneider,Marie Generali-Lince,Mélodie Boillet,Bastien Abadie,Christopher Kermorvant

PyLaia is one of the most popular open-source software for Automatic Text
Recognition (ATR), delivering strong performance in terms of speed and
accuracy. In this paper, we outline our recent contributions to the PyLaia
library, focusing on the incorporation of reliable confidence scores and the
integration of statistical language modeling during decoding. Our
implementation provides an easy way to combine PyLaia with n-grams language
models at different levels. One of the highlights of this work is that language
models are completely auto-tuned: they can be built and used easily without any
expert knowledge, and without requiring any additional data. To demonstrate the
significance of our contribution, we evaluate PyLaia's performance on twelve
datasets, both with and without language modelling. The results show that
decoding with small language models improves the Word Error Rate by 13% and the
Character Error Rate by 12% in average. Additionally, we conduct an analysis of
confidence scores and highlight the importance of calibration techniques. Our
implementation is publicly available in the official PyLaia repository at
https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are
released on Hugging Face.

摘要：PyLaia 是最受歡迎的自動文本辨識 (ATR) 開源軟體之一，在速度和準確性方面表現優異。在這篇論文中，我們概述了我們對 PyLaia 函式庫的最新貢獻，重點在於納入可靠的置信度分數，以及在解碼過程中整合統計語言模型。我們的實作提供了一個簡單的方法，可以在不同的層級將 PyLaia 與 n-grams 語言模型結合在一起。這項工作的亮點之一是語言模型完全自動調整：它們可以輕鬆建立和使用，無需任何專家知識，也不需要任何額外資料。為了展示我們貢獻的重要性，我們在十二個資料集上評估 PyLaia 的效能，包括使用和不使用語言模型的狀況。結果顯示，使用小型語言模型進行解碼，平均可將字元錯誤率降低 13%，將字元錯誤率降低 12%。此外，我們進行了置信度分數的分析，並強調了校正技術的重要性。我們的實作已公開在官方 PyLaia 儲存庫中，網址為 https://gitlab.teklia.com/atr/pylaia，並在 Hugging Face 上發布了十二個開源模型。

##### **Iconic Gesture Semantics**
2404.18708v1 by Andy Lücking,Alexander Henlein,Alexander Mehler

The "meaning" of an iconic gesture is conditioned on its informational
evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic
level that can interact with verbal content. Interaction is either vacuous or
regimented by usual lexicon-driven inferences. Informational evaluation is
spelled out as extended exemplification (extemplification) in terms of
perceptual classification of a gesture's visual iconic model. The iconic model
is derived from Frege/Montague-like truth-functional evaluation of a gesture's
form within spatially extended domains. We further argue that the perceptual
classification of instances of visual communication requires a notion of
meaning different from Frege/Montague frameworks. Therefore, a heuristic for
gesture interpretation is provided that can guide the working semanticist. In
sum, an iconic gesture semantics is introduced which covers the full range from
kinematic gesture representations over model-theoretic evaluation to
inferential interpretation in dynamic semantic frameworks.

摘要：手勢圖示的「意義」取決於其資訊評估。只有資訊評估才能將手勢提升到能與語言內容互動的準語言層級。互動要不是空洞無物，就是受到慣常詞彙驅動的推論所規範。資訊評估會以手勢視覺圖示模型的知覺分類為基礎，用延伸的例證 (extemplification) 說明。圖示模型來自於在空間延伸領域中，對手勢形式的弗雷格/蒙塔古式真值函數評估。我們進一步主張，視覺溝通實例的知覺分類需要一個與弗雷格/蒙塔古架構不同的意義概念。因此，我們提供了一個手勢詮釋啟發法，可以引導工作語義學家。總之，我們引入了一種圖示手勢語義，涵蓋了從運動手勢表徵到模型理論評估，再到動態語義架構中的推論詮釋的完整範圍。

##### **Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages**
2404.18684v1 by Sidharth Ranjan,Titus von der Malsburg

Dependency length minimization is a universally observed quantitative
property of natural languages. However, the extent of dependency length
minimization, and the cognitive mechanisms through which the language processor
achieves this minimization remain unclear. This research offers mechanistic
insights by postulating that moving a short preverbal constituent next to the
main verb explains preverbal constituent ordering decisions better than global
minimization of dependency length in SOV languages. This approach constitutes a
least-effort strategy because it's just one operation but simultaneously
reduces the length of all preverbal dependencies linked to the main verb. We
corroborate this strategy using large-scale corpus evidence across all seven
SOV languages that are prominently represented in the Universal Dependency
Treebank. These findings align with the concept of bounded rationality, where
decision-making is influenced by 'quick-yet-economical' heuristics rather than
exhaustive searches for optimal solutions. Overall, this work sheds light on
the role of bounded rationality in linguistic decision-making and language
evolution.

摘要：依存關係長度最小化是自然語言普遍觀察到的定量屬性。然而，依存關係長度最小化的程度，以及語言處理器實現此最小化的認知機制仍不清楚。本研究通過假設將短的動詞前成分移動到主要動詞旁邊，比 SOV 語言中依存關係長度的全局最小化，能更好地解釋動詞前成分的排序決策，從而提供機制見解。這種方法構成一種最省力的策略，因為它只是一個操作，但同時減少了與主要動詞相關的所有動詞前依存關係的長度。我們使用在 Universal Dependency Treebank 中有突出代表性的所有七種 SOV 語言的大規模語料庫證據來驗證此策略。這些發現與有限理性的概念一致，其中決策制定受「快速且經濟」的啟發式影響，而不是對最佳解決方案的窮舉搜尋。總體而言，這項工作闡明了有限理性在語言決策和語言演變中的作用。

##### **Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report**
2404.18672v1 by Paul Cibier,Jean-Guy Mailly

Various approaches have been proposed for providing efficient computational
approaches for abstract argumentation. Among them, neural networks have
permitted to solve various decision problems, notably related to arguments
(credulous or skeptical) acceptability. In this work, we push further this
study in various ways. First, relying on the state-of-the-art approach AFGCN,
we show how we can improve the performances of the Graph Convolutional Networks
(GCNs) regarding both runtime and accuracy. Then, we show that it is possible
to improve even more the efficiency of the approach by modifying the
architecture of the network, using Graph Attention Networks (GATs) instead.

摘要：各種方法已被提議用於提供抽象論證的有效計算方法。其中，神經網路已允許解決各種決策問題，尤其是與論證（輕信或懷疑）可接受性相關的問題。在這項工作中，我們以各種方式進一步推動這項研究。首先，依賴於最先進的方法 AFGCN，我們展示了如何改善圖形卷積網路（GCN）在執行時間和準確性方面的效能。然後，我們展示了通過修改網路架構，改用圖注意力網路（GAT）可以進一步提高方法的效率。

##### **Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting**
2404.18669v1 by Yifei Gao,Jie Ou,Lei Wang,Jun Cheng

Recent developments in neural rendering techniques have greatly enhanced the
rendering of photo-realistic 3D scenes across both academic and commercial
fields. The latest method, known as 3D Gaussian Splatting (3D-GS), has set new
benchmarks for rendering quality and speed. Nevertheless, the limitations of
3D-GS become pronounced in synthesizing new viewpoints, especially for views
that greatly deviate from those seen during training. Additionally, issues such
as dilation and aliasing arise when zooming in or out. These challenges can all
be traced back to a single underlying issue: insufficient sampling. In our
paper, we present a bootstrapping method that significantly addresses this
problem. This approach employs a diffusion model to enhance the rendering of
novel views using trained 3D-GS, thereby streamlining the training process. Our
results indicate that bootstrapping effectively reduces artifacts, as well as
clear enhancements on the evaluation metrics. Furthermore, we show that our
method is versatile and can be easily integrated, allowing various 3D
reconstruction projects to benefit from our approach.

摘要：近來神經渲染技術的發展大幅提升了學術界和商業領域中寫實 3D 場景的渲染。最新的方法，稱為 3D Gaussian Splatting (3D-GS)，為渲染品質與速度設定了新的基準。儘管如此，3D-GS 的限制在合成新的視角時變得明顯，特別是對於與訓練期間所見視角有很大不同的視角。此外，在縮放或放大時會出現膨脹和混疊等問題。這些挑戰都可以追溯到單一的基本問題：採樣不足。在我們的論文中，我們提出了一種自舉方法，可以顯著解決這個問題。這種方法採用擴散模型來增強使用訓練過的 3D-GS 渲染新視角，從而簡化訓練過程。我們的結果表明，自舉有效地減少了人工製品，並在評估指標上顯著提升。此外，我們展示了我們的方法具有多功能性，並且可以輕鬆整合，讓各種 3D 重建專案都能從我們的方法中受益。

##### **Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods**
2404.18655v1 by Haeun Yu,Pepa Atanasova,Isabelle Augenstein

Language Models (LMs) acquire parametric knowledge from their training
process, embedding it within their weights. The increasing scalability of LMs,
however, poses significant challenges for understanding a model's inner
workings and further for updating or correcting this embedded knowledge without
the significant cost of retraining. This underscores the importance of
unveiling exactly what knowledge is stored and its association with specific
model components. Instance Attribution (IA) and Neuron Attribution (NA) offer
insights into this training-acquired knowledge, though they have not been
compared systematically. Our study introduces a novel evaluation framework to
quantify and compare the knowledge revealed by IA and NA. To align the results
of the methods we introduce the attribution method NA-Instances to apply NA for
retrieving influential training instances, and IA-Neurons to discover important
neurons of influential instances discovered by IA. We further propose a
comprehensive list of faithfulness tests to evaluate the comprehensiveness and
sufficiency of the explanations provided by both methods. Through extensive
experiments and analysis, we demonstrate that NA generally reveals more diverse
and comprehensive information regarding the LM's parametric knowledge compared
to IA. Nevertheless, IA provides unique and valuable insights into the LM's
parametric knowledge, which are not revealed by NA. Our findings further
suggest the potential of a synergistic approach of combining the diverse
findings of IA and NA for a more holistic understanding of an LM's parametric
knowledge.

摘要：語言模型 (LM) 從其訓練過程中獲取參數知識，並將其嵌入其權重中。然而，LM 的可擴充性不斷提高，對理解模型的內部運作以及進一步更新或更正此嵌入式知識提出了重大挑戰，而無需付出重新訓練的巨大成本。這強調了準確揭示儲存了什麼知識及其與特定模型組件關聯的重要性。實例歸因 (IA) 和神經元歸因 (NA) 提供了對這種訓練獲取的知識的見解，儘管它們尚未得到系統比較。我們的研究引入了一個新的評估框架，用於量化和比較 IA 和 NA 揭示的知識。為了調整這些方法的結果，我們引入了歸因方法 NA-Instances，用於應用 NA 來檢索有影響力的訓練實例，以及 IA-Neurons 來發現 IA 發現的有影響力實例的重要神經元。我們進一步提出了全面的忠實度測試清單，以評估這兩種方法提供的解釋的全面性和充分性。通過廣泛的實驗和分析，我們證明 NA 通常揭示了更多樣化和全面的信息，關於 LM 的參數知識，與 IA 相比。儘管如此，IA 對 LM 的參數知識提供了獨特且有價值的見解，而 NA 沒有揭示這些見解。我們的研究結果進一步表明了結合 IA 和 NA 的不同發現的協同方法的潛力，以更全面地理解 LM 的參數知識。

##### **Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection**
2404.18649v1 by Konstantinos Tsigos,Evlampios Apostolidis,Spyridon Baxevanakis,Symeon Papadopoulos,Vasileios Mezaris

In this paper we propose a new framework for evaluating the performance of
explanation methods on the decisions of a deepfake detector. This framework
assesses the ability of an explanation method to spot the regions of a fake
image with the biggest influence on the decision of the deepfake detector, by
examining the extent to which these regions can be modified through a set of
adversarial attacks, in order to flip the detector's prediction or reduce its
initial prediction; we anticipate a larger drop in deepfake detection accuracy
and prediction, for methods that spot these regions more accurately. Based on
this framework, we conduct a comparative study using a state-of-the-art model
for deepfake detection that has been trained on the FaceForensics++ dataset,
and five explanation methods from the literature. The findings of our
quantitative and qualitative evaluations document the advanced performance of
the LIME explanation method against the other compared ones, and indicate this
method as the most appropriate for explaining the decisions of the utilized
deepfake detector.

摘要：在本文中，我們提出一個新的架構，用於評估解釋方法在深度偽造檢測器的決策上的效能。這個架構評估解釋方法辨識偽造影像中對深度偽造檢測器決策影響最大的區域的能力，方法是檢視這些區域能透過一組對抗性攻擊修改的程度，以翻轉檢測器的預測或降低其初始預測；我們預期對於更準確辨識這些區域的方法，深度偽造檢測準確度和預測會大幅下降。基於這個架構，我們使用一個在 FaceForensics++ 資料集上受過訓練的深度偽造檢測最新模型，以及文獻中的五種解釋方法，進行比較研究。我們的定量和定性評估結果證明了 LIME 解釋方法相較於其他比較方法的進階效能，並指出此方法最適合用於解釋所使用的深度偽造檢測器的決策。

##### **Reinforcement Learning Problem Solving with Large Language Models**
2404.18638v1 by Sina Gholamian,Domingo Huh

Large Language Models (LLMs) encapsulate an extensive amount of world
knowledge, and this has enabled their application in various domains to improve
the performance of a variety of Natural Language Processing (NLP) tasks. This
has also facilitated a more accessible paradigm of conversation-based
interactions between humans and AI systems to solve intended problems. However,
one interesting avenue that shows untapped potential is the use of LLMs as
Reinforcement Learning (RL) agents to enable conversational RL problem solving.
Therefore, in this study, we explore the concept of formulating Markov Decision
Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can
be iteratively prompted to learn and optimize policies for specific RL tasks.
In addition, we leverage the introduced prompting technique for episode
simulation and Q-Learning, facilitated by LLMs. We then show the practicality
of our approach through two detailed case studies for "Research Scientist" and
"Legal Matter Intake" workflows.

摘要：大型語言模型 (LLM) 涵蓋了大量的世界知識，這使得它們能夠在各種領域中應用，以改善各種自然語言處理 (NLP) 任務的效能。這也促進了人類與 AI 系統之間基於對話的互動模式，以解決預期的問題。然而，一個顯示出尚未開發潛力的有趣途徑是將 LLM 用作強化學習 (RL) 代理，以實現對話式 RL 問題解決。因此，在本研究中，我們探討了將基於馬可夫決策過程的 RL 問題表述為 LLM 提示任務的概念。我們展示了如何反覆提示 LLM 以學習和最佳化特定 RL 任務的政策。此外，我們利用引入的提示技術進行情節模擬和 Q 學習，並由 LLM 促進。然後，我們通過針對「研究科學家」和「法律事務處理」工作流程的兩個詳細案例研究展示了我們方法的實用性。

##### **Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?**
2404.18624v1 by Letitia Parcalabescu,Anette Frank

Vision and language models (VLMs) are currently the most generally performant
architectures on multimodal tasks. Next to their predictions, they can also
produce explanations, either in post-hoc or CoT settings. However, it is not
clear how much they use the vision and text modalities when generating
predictions or explanations. In this work, we investigate if VLMs rely on
modalities differently when generating explanations as opposed to when they
provide answers. We also evaluate the self-consistency of VLM decoders in both
post-hoc and CoT explanation settings, by extending existing tests and measures
to VLM decoders. We find that VLMs are less self-consistent than LLMs. The text
contributions in VL decoders are much larger than the image contributions
across all measured tasks. And the contributions of the image are significantly
larger for explanation generations than for answer generation. This difference
is even larger in CoT compared to the post-hoc explanation setting. We also
provide an up-to-date benchmarking of state-of-the-art VL decoders on the VALSE
benchmark, which to date focused only on VL encoders. We find that VL decoders
are still struggling with most phenomena tested by VALSE.

摘要：視覺語言模型 (VLM) 目前是多模態任務中最普遍的高效架構。除了預測之外，它們還可以產生解釋，無論是在事後或 CoT 設定中。然而，尚不清楚它們在產生預測或解釋時，使用了多少視覺和文字模式。在這項工作中，我們探討 VLM 在產生解釋時是否與在提供答案時，依賴於不同的模式。我們還透過將現有的測試和測量擴展到 VLM 解碼器，評估 VLM 解碼器在事後和 CoT 解釋設定中的自我一致性。我們發現 VLM 的自我一致性低於 LLM。在所有測量任務中，VLM 解碼器中的文字貢獻遠大於影像貢獻。而且影像的貢獻在產生解釋時顯著大於產生答案時。這種差異在 CoT 中甚至比在事後解釋設定中更大。我們還對最先進的 VLM 解碼器在 VALSE 基準上進行了最新的基準測試，而 VALSE 基準迄今只關注 VLM 編碼器。我們發現 VLM 解碼器仍難以應付 VALSE 測試的大多數現象。

##### **The SAMER Arabic Text Simplification Corpus**
2404.18615v1 by Bashar Alhafni,Reem Hazim,Juan Piñeros Liberato,Muhamed Al Khalil,Nizar Habash

We present the SAMER Corpus, the first manually annotated Arabic parallel
corpus for text simplification targeting school-aged learners. Our corpus
comprises texts of 159K words selected from 15 publicly available Arabic
fiction novels most of which were published between 1865 and 1955. Our corpus
includes readability level annotations at both the document and word levels, as
well as two simplified parallel versions for each text targeting learners at
two different readability levels. We describe the corpus selection process, and
outline the guidelines we followed to create the annotations and ensure their
quality. Our corpus is publicly available to support and encourage research on
Arabic text simplification, Arabic automatic readability assessment, and the
development of Arabic pedagogical language technologies.

摘要：我們提出 SAMER 語料庫，這是第一個針對學齡學習者進行文字簡化的阿拉伯語平行語料庫。我們的語料庫包含從 15 部公開的阿拉伯語小說中挑選的 159K 字的文字，其中大部分出版於 1865 年至 1955 年之間。我們的語料庫包含文件和單字層級的可讀性標註，以及針對兩個不同可讀性層級的學習者提供的兩個簡化平行版本。我們描述語料庫的選擇過程，並概述我們遵循的準則來建立標註並確保其品質。我們的語料庫公開提供，以支持和鼓勵阿拉伯語文字簡化、阿拉伯語自動可讀性評估以及阿拉伯語教學語言技術的發展。

##### **CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**
2404.18604v1 by Xiangyu Liang,Wenlin Zhuang,Tianyong Wang,Guangxing Geng,Guangyue Geng,Haifeng Xia,Siyu Xia

Speech-driven 3D facial animation technology has been developed for years,
but its practical application still lacks expectations. The main challenges lie
in data limitations, lip alignment, and the naturalness of facial expressions.
Although lip alignment has seen many related studies, existing methods struggle
to synthesize natural and realistic expressions, resulting in a mechanical and
stiff appearance of facial animations. Even with some research extracting
emotional features from speech, the randomness of facial movements limits the
effective expression of emotions. To address this issue, this paper proposes a
method called CSTalk (Correlation Supervised) that models the correlations
among different regions of facial movements and supervises the training of the
generative model to generate realistic expressions that conform to human facial
motion patterns. To generate more intricate animations, we employ a rich set of
control parameters based on the metahuman character model and capture a dataset
for five different emotions. We train a generative network using an autoencoder
structure and input an emotion embedding vector to achieve the generation of
user-control expressions. Experimental results demonstrate that our method
outperforms existing state-of-the-art methods.

摘要：語音驅動的 3D 臉部動畫技術已經發展多年，
但其實際應用仍未達到預期。主要的挑戰在於數據限制、嘴唇對齊和臉部表情的自然性。
儘管嘴唇對齊已經有許多相關研究，但現有方法難以合成自然且逼真的表情，導致臉部動畫呈現機械且僵硬的外觀。即使有些研究從語音中提取情緒特徵，但臉部動作的隨機性限制了情緒的有效表達。為了解決此問題，本文提出了一種稱為 CSTalk（相關監督）的方法，該方法模擬臉部動作不同區域之間的相關性，並監督生成模型的訓練，以生成符合人類臉部動作模式的逼真表情。為了產生更複雜的動畫，我們採用了一組豐富的控制參數，這些參數基於超人類角色模型，並擷取了一個包含五種不同情緒的資料集。我們使用自動編碼器結構訓練了一個生成網路，並輸入一個情緒嵌入向量，以實現使用者控制表情的生成。實驗結果證明，我們的模型優於現有的最先進模型。

##### **FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering**
2404.18585v1 by Wei Zhou,Mohsen Mesgar,Heike Adel,Annemarie Friedrich

Table Question Answering (TQA) aims at composing an answer to a question
based on tabular data. While prior research has shown that TQA models lack
robustness, understanding the underlying cause and nature of this issue remains
predominantly unclear, posing a significant obstacle to the development of
robust TQA systems. In this paper, we formalize three major desiderata for a
fine-grained evaluation of robustness of TQA systems. They should (i) answer
questions regardless of alterations in table structure, (ii) base their
responses on the content of relevant cells rather than on biases, and (iii)
demonstrate robust numerical reasoning capabilities. To investigate these
aspects, we create and publish a novel TQA evaluation benchmark in English. Our
extensive experimental analysis reveals that none of the examined
state-of-the-art TQA systems consistently excels in these three aspects. Our
benchmark is a crucial instrument for monitoring the behavior of TQA systems
and paves the way for the development of robust TQA systems. We release our
benchmark publicly.

摘要：表格問答 (TQA) 旨在根據表格資料撰寫問題的答案。雖然先前的研究顯示 TQA 模型缺乏健全性，但了解此問題的根本原因和性質仍然相當不明確，對健全 TQA 系統的開發構成重大障礙。在本文中，我們正式制定了三個主要條件，以對 TQA 系統的健全性進行細緻的評估。它們應該 (i) 無論表格結構如何變更，都能回答問題，(ii) 將回應建立在相關儲存格的內容上，而不是偏見，以及 (iii) 展示健全的數字推理能力。為了調查這些面向，我們建立並發布了一個新穎的英文 TQA 評估基準。我們的廣泛實驗分析顯示，沒有任何已檢查的最新 TQA 系統在這三個面向都持續表現出色。我們的基準是監控 TQA 系統行為的關鍵工具，並為健全 TQA 系統的開發鋪平道路。我們公開發布我們的基準。

##### **Analyzing Semantic Change through Lexical Replacements**
2404.18570v1 by Francesco Periti,Pierluigi Cassotti,Haim Dubossarsky,Nina Tahmasebi

Modern language models are capable of contextualizing words based on their
surrounding context. However, this capability is often compromised due to
semantic change that leads to words being used in new, unexpected contexts not
encountered during pre-training. In this paper, we model \textit{semantic
change} by studying the effect of unexpected contexts introduced by
\textit{lexical replacements}. We propose a \textit{replacement schema} where a
target word is substituted with lexical replacements of varying relatedness,
thus simulating different kinds of semantic change. Furthermore, we leverage
the replacement schema as a basis for a novel \textit{interpretable} model for
semantic change. We are also the first to evaluate the use of LLaMa for
semantic change detection.

摘要：現代語言模型能夠根據單字周圍的語境，將單字脈絡化。然而，由於語義變化，導致單字在預訓練過程中未遇到的新、意外語境中使用，因此這種能力常常受到影響。在本文中，我們透過研究由「詞彙替換」帶來的意外語境影響，對「語義變化」進行建模。我們提出了一個「替換架構」，其中目標單字會被相關性不同的詞彙替換所取代，從而模擬不同類型的語義變化。此外，我們將替換架構作為語義變化的創新「可詮釋」模型的基礎。我們也是第一個評估使用 LLaMa 進行語義變更偵測的人。

##### **Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning**
2404.18564v1 by Wen-Yu Chang,Yun-Nung Chen

Recent research in dialogue systems and corpora has focused on two main
categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD
systems help users accomplish specific tasks, while open-domain systems aim to
create engaging conversations. However, in real-world scenarios, user intents
are often revealed during interactions. A recent study introduced SalesBot,
which simulates dialogues transitioning from chit-chat to task-oriented
scenarios to train sales agents. Unfortunately, the initial data lacked smooth
transitions and coherent long-turn dialogues, resulting in poor naturalness in
sales-customer interactions. To address these issues, this paper presents
SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from
large language models (LLMs) through strategic prompting. Additionally, we
introduce a novel model called SalesAgent, trained on salesperson's
interactions, using chain-of-thought (CoT) reasoning. This model excels in
transitioning topics, understanding user intents, and selecting appropriate
strategies. Experiments using diverse user simulations validate the
effectiveness of our method in controlling dialogue strategies in LLMs.
Furthermore, SalesBot 2.0 enhances coherence and reduces aggression,
facilitating better model learning for sales-customer interactions.

摘要：最近在對話系統和語料庫的研究主要集中在兩個主要類別：任務導向 (TOD) 和開放領域 (閒聊) 對話。TOD 系統幫助使用者完成特定任務，而開放領域系統旨在創造引人入勝的對話。然而，在真實世界的場景中，使用者意圖通常在互動過程中才被揭示出來。最近的一項研究引入了 SalesBot，它模擬從閒聊到任務導向場景的對話，以訓練銷售人員。不幸的是，初始資料缺乏流暢的轉換和連貫的長輪對話，導致銷售人員與客戶互動時自然度不佳。為了解決這些問題，本文提出了 SalesBot 2.0，一個改進的資料集。它透過策略性提示，利用了來自大型語言模型 (LLM) 的常識知識。此外，我們引入了稱為 SalesAgent 的新模型，它使用思想鏈 (CoT) 推理，並根據銷售人員的互動進行訓練。此模型擅長轉換主題、理解使用者意圖和選擇適當的策略。使用各種使用者模擬的實驗驗證了我們的方法在控制 LLM 中對話策略的有效性。此外，SalesBot 2.0 增強了連貫性並減少了攻擊性，促進了銷售人員與客戶互動的模型學習。

##### **LangBiTe: A Platform for Testing Bias in Large Language Models**
2404.18558v1 by Sergio Morales,Robert Clarisó,Jordi Cabot

The integration of Large Language Models (LLMs) into various software
applications raises concerns about their potential biases. Typically, those
models are trained on a vast amount of data scrapped from forums, websites,
social media and other internet sources, which may instill harmful and
discriminating behavior into the model. To address this issue, we present
LangBiTe, a testing platform to systematically assess the presence of biases
within an LLM. LangBiTe enables development teams to tailor their test
scenarios, and automatically generate and execute the test cases according to a
set of user-defined ethical requirements. Each test consists of a prompt fed
into the LLM and a corresponding test oracle that scrutinizes the LLM's
response for the identification of biases. LangBite provides users with the
bias evaluation of LLMs, and end-to-end traceability between the initial
ethical requirements and the insights obtained.

摘要：大型語言模型 (LLM) 與各種軟體應用程式整合，引發了人們對其潛在偏見的擔憂。通常，這些模型會根據從論壇、網站、社群媒體和其他網路來源擷取的大量資料進行訓練，這可能會讓有害和歧視性的行為植入模型中。為了解決這個問題，我們提出了 LangBiTe，這是一個測試平台，用於系統性評估 LLM 中偏見的存在。LangBiTe 能讓開發團隊調整他們的測試情境，並根據一組使用者定義的道德要求自動產生和執行測試案例。每個測試都包含一個輸入提示，輸入到 LLM 中，以及一個對應的測試預言，用於仔細檢查 LLM 的回應，以識別偏見。LangBite 為使用者提供 LLM 的偏見評估，以及在初始道德要求和獲得的見解之間的端對端追溯。

##### **Can GPT-4 do L2 analytic assessment?**
2404.18557v1 by Stefano Bannò,Hari Krishna Vydana,Kate M. Knill,Mark J. F. Gales

Automated essay scoring (AES) to evaluate second language (L2) proficiency
has been a firmly established technology used in educational contexts for
decades. Although holistic scoring has seen advancements in AES that match or
even exceed human performance, analytic scoring still encounters issues as it
inherits flaws and shortcomings from the human scoring process. The recent
introduction of large language models presents new opportunities for automating
the evaluation of specific aspects of L2 writing proficiency. In this paper, we
perform a series of experiments using GPT-4 in a zero-shot fashion on a
publicly available dataset annotated with holistic scores based on the Common
European Framework of Reference and aim to extract detailed information about
their underlying analytic components. We observe significant correlations
between the automatically predicted analytic scores and multiple features
associated with the individual proficiency components.

摘要：自動化論文評分 (AES) 用於評估第二語言 (L2) 能力，這項技術已在教育環境中穩固確立數十年。儘管整體評分在 AES 中已見進步，與人類表現相匹配甚至超越，但分析評分仍會遇到問題，因為它繼承了人類評分過程中的缺陷和不足。最近引入的大語言模型為自動化評估 L2 寫作能力的特定面向提供了新契機。在本文中，我們使用 GPT-4 針對一個公開可用的資料集進行一系列零次學習實驗，該資料集根據歐洲共同參考架構標註了整體分數，並旨在提取有關其基礎分析組成的詳細資訊。我們觀察到自動預測的分析分數與個別能力組成相關的多項特徵之間存在顯著相關性。

##### **Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting**
2404.18553v1 by Gareth Davies

Autoregressive Recurrent Neural Networks are widely employed in time-series
forecasting tasks, demonstrating effectiveness in univariate and certain
multivariate scenarios. However, their inherent structure does not readily
accommodate the integration of future, time-dependent covariates. A proposed
solution, outlined by Salinas et al 2019, suggests forecasting both covariates
and the target variable in a multivariate framework. In this study, we
conducted comprehensive tests on publicly available time-series datasets,
artificially introducing highly correlated covariates to future time-step
values. Our evaluation aimed to assess the performance of an LSTM network when
considering these covariates and compare it against a univariate baseline. As
part of this study we introduce a novel approach using seasonal time segments
in combination with an RNN architecture, which is both simple and extremely
effective over long forecast horizons with comparable performance to many state
of the art architectures. Our findings from the results of more than 120 models
reveal that under certain conditions jointly training covariates with target
variables can improve overall performance of the model, but often there exists
a significant performance disparity between multivariate and univariate
predictions. Surprisingly, even when provided with covariates informing the
network about future target values, multivariate predictions exhibited inferior
performance. In essence, compelling the network to predict multiple values can
prove detrimental to model performance, even in the presence of informative
covariates. These results suggest that LSTM architectures may not be suitable
for forecasting tasks where predicting covariates would typically be expected
to enhance model accuracy.

摘要：自迴歸遞迴神經網路廣泛用於時間序列預測任務，證明了在單變量和特定多變量場景中的有效性。然而，它們的內在結構並不能輕易地容納未來時間依賴協變量的整合。Salinas 等人在 2019 年概述的建議解決方案，建議在多變量框架中預測協變量和目標變數。在本研究中，我們對公開的時間序列資料集進行了全面的測試，人工引入了與未來時間步驟值高度相關的協變量。我們的評估旨在評估 LSTM 網路在考慮這些協變量時的效能，並將其與單變量基準進行比較。作為本研究的一部分，我們介紹了一種使用季節性時間區段與 RNN 架構相結合的新方法，它既簡單又極有效，在長預測範圍內具有與許多現有架構相當的效能。我們從 120 多個模型的結果中得出的發現表明，在某些條件下，共同訓練協變量和目標變數可以提高模型的整體效能，但多變量和單變量預測之間常常存在顯著的效能差異。令人驚訝的是，即使提供了告知網路未來目標值的協變量，多變量預測也表現出較差的效能。從本質上講，強迫網路預測多個值可能會損害模型效能，即使在存在資訊性協變量的情況下也是如此。這些結果表明，LSTM 架構可能不適合預測任務，其中預測協變量通常預計會提高模型準確度。

##### **SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods**
2404.18552v1 by Manos Schinas,Symeon Papadopoulos

The generative AI technology offers an increasing variety of tools for
generating entirely synthetic images that are increasingly indistinguishable
from real ones. Unlike methods that alter portions of an image, the creation of
completely synthetic images presents a unique challenge and several Synthetic
Image Detection (SID) methods have recently appeared to tackle it. Yet, there
is often a large gap between experimental results on benchmark datasets and the
performance of methods in the wild. To better address the evaluation needs of
SID and help close this gap, this paper introduces a benchmarking framework
that integrates several state-of-the-art SID models. Our selection of
integrated models was based on the utilization of varied input features, and
different network architectures, aiming to encompass a broad spectrum of
techniques. The framework leverages recent datasets with a diverse set of
generative models, high level of photo-realism and resolution, reflecting the
rapid improvements in image synthesis technology. Additionally, the framework
enables the study of how image transformations, common in assets shared online,
such as JPEG compression, affect detection performance. SIDBench is available
on https://github.com/mever-team/sidbench and is designed in a modular manner
to enable easy inclusion of new datasets and SID models.

摘要：生成式 AI 技術提供越來越多樣化的工具，用於生成完全合成的影像，這些影像與真實影像越來越難以區分。與改變影像部分的方法不同，完全合成影像的建立提出了一個獨特的挑戰，最近出現了幾種合成影像偵測 (SID) 方法來解決這個問題。然而，基準資料集上的實驗結果與方法在實際環境中的效能之間，通常存在很大的差距。為了更好地解決 SID 的評估需求並協助縮小這個差距，本文介紹了一個基準架構，整合了幾個最先進的 SID 模型。我們選擇整合的模型是基於使用不同的輸入特徵和不同的網路架構，旨在涵蓋廣泛的技術。這個架構利用了最近的資料集，其中包含多樣化的生成模型、高階照片寫實主義和解析度，反映了影像合成技術的快速進步。此外，這個架構能夠研究影像轉換（例如 JPEG 壓縮）如何影響偵測效能，而這在線上共享的素材中很常見。SIDBench 可在 https://github.com/mever-team/sidbench 上取得，並且以模組化方式設計，以便輕鬆納入新的資料集和 SID 模型。

##### **Time Machine GPT**
2404.18543v1 by Felix Drinkall,Eghbal Rahimikia,Janet B. Pierrehumbert,Stefan Zohren

Large language models (LLMs) are often trained on extensive, temporally
indiscriminate text corpora, reflecting the lack of datasets with temporal
metadata. This approach is not aligned with the evolving nature of language.
Conventional methods for creating temporally adapted language models often
depend on further pre-training static models on time-specific data. This paper
presents a new approach: a series of point-in-time LLMs called Time Machine GPT
(TiMaGPT), specifically designed to be nonprognosticative. This ensures they
remain uninformed about future factual information and linguistic changes. This
strategy is beneficial for understanding language evolution and is of critical
importance when applying models in dynamic contexts, such as time-series
forecasting, where foresight of future information can prove problematic. We
provide access to both the models and training datasets.

摘要：大型語言模型 (LLM) 通常在廣泛且時間上不加區分的文字語料庫上進行訓練，反映了缺乏具有時間元數據的資料集。這種方法與語言的演化性質不符。建立時間適應語言模型的傳統方法通常依賴於進一步在特定時間的資料上預訓練靜態模型。本文提出了一種新方法：一系列稱為時光機 GPT (TiMaGPT) 的時間點 LLM，專門設計為非預測性的。這確保他們對未來的實際資訊和語言變化保持不知情。此策略有利於了解語言演化，並且在動態環境中應用模型時至關重要，例如時間序列預測，其中對未來資訊的預見可能被證明是有問題的。我們提供對模型和訓練資料集的存取。

##### **Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods**
2404.18539v1 by Chuni Liu,Boyuan Ma,Xiaojuan Ban,Yujie Xie,Hao Wang,Weihua Xue,Jingchao Ma,Ke Xu

Topological consistency plays a crucial role in the task of boundary
segmentation for reticular images, such as cell membrane segmentation in neuron
electron microscopic images, grain boundary segmentation in material
microscopic images and road segmentation in aerial images. In these fields,
topological changes in segmentation results have a serious impact on the
downstream tasks, which can even exceed the misalignment of the boundary
itself. To enhance the topology accuracy in segmentation results, we propose
the Skea-Topo Aware loss, which is a novel loss function that takes into
account the shape of each object and topological significance of the pixels. It
consists of two components. First, the skeleton-aware weighted loss improves
the segmentation accuracy by better modeling the object geometry with
skeletons. Second, a boundary rectified term effectively identifies and
emphasizes topological critical pixels in the prediction errors using both
foreground and background skeletons in the ground truth and predictions.
Experiments prove that our method improves topological consistency by up to 7
points in VI compared to 13 state-of-art methods, based on objective and
subjective assessments across three different boundary segmentation datasets.
The code is available at https://github.com/clovermini/Skea_topo.

摘要：拓扑一致性在網狀圖像的邊界分割任務中扮演著至關重要的角色，例如神經元電子顯微圖像中的細胞膜分割、材料顯微圖像中的晶界分割和航拍圖像中的道路分割。在這些領域中，分割結果的拓撲變化對下游任務有嚴重的影響，甚至可能超過邊界本身的錯位。為了提高分割結果的拓撲準確度，我們提出了 Skea-Topo 感知損失，這是一種新穎的損失函數，它考慮了每個物體的形狀和像素的拓撲重要性。它包含兩個組成部分。首先，骨架感知加權損失通過使用骨架對物體幾何進行更好的建模來提高分割準確度。其次，邊界校正項使用真實值和預測中的前景和背景骨架，有效地識別並強調預測誤差中的拓撲臨界像素。實驗證明，與 13 種最先進的方法相比，我們的模型在 VI 中將拓撲一致性提高了 7 個百分點，這是基於三個不同的邊界分割數據集的客觀和主觀評估。代碼可在 https://github.com/clovermini/Skea_topo 獲得。

##### **Evaluating and Mitigating Linguistic Discrimination in Large Language Models**
2404.18534v1 by Guoliang Dong,Haoyu Wang,Jun Sun,Xinyu Wang

By training on text in various languages, large language models (LLMs)
typically possess multilingual support and demonstrate remarkable capabilities
in solving tasks described in different languages. However, LLMs can exhibit
linguistic discrimination due to the uneven distribution of training data
across languages. That is, LLMs are hard to keep the consistency of responses
when faced with the same task but depicted in different languages.
  In this study, we first explore the consistency in the LLMs' outputs
responding to queries in various languages from two aspects: safety and
quality. We conduct this analysis with two datasets (AdvBench and NQ) based on
four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results
show that LLMs exhibit stronger human alignment capabilities with queries in
English, French, Russian, and Spanish (only 1.04\% of harmful queries
successfully jailbreak on average) compared to queries in Bengali, Georgian,
Nepali and Maithili (27.7\% of harmful queries jailbreak successfully on
average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs
tend to produce responses with a higher quality (with 0.1494 $F_1$ score on
average) compared to the other languages. Upon these findings, we propose
LDFighter, a similarity-based voting, to mitigate the linguistic discrimination
in LLMs. LDFighter ensures consistent service for different language speakers.
We evaluate LDFighter with both benign queries and harmful queries. The results
show that LDFighter not only significantly reduces the jailbreak success rate
but also improve the response quality on average, demonstrating its
effectiveness.

摘要：<paragraph>透過訓練各種語言的文字，大型語言模型 (LLM)
通常具備多語言支援，並在解決以不同語言描述的任務時展現出卓越的能力。然而，LLM 會因訓練資料在各語言間分佈不均而表現出語言歧視。也就是說，LLM 在面對相同的任務，但以不同語言描述時，難以維持回應的一致性。
在這項研究中，我們首先從安全性和品質兩個面向探討 LLM 對各種語言查詢的輸出的一致性。我們使用兩個資料集 (AdvBench 和 NQ) 針對四個 LLM (Llama2-13b、Gemma-7b、GPT-3.5-turbo 和 Gemini-pro) 進行這項分析。結果顯示，LLM 對英語、法語、俄語和西班牙語查詢展現出較強的人類對齊能力（平均只有 1.04% 的有害查詢成功越獄），而對孟加拉語、喬治亞語、尼泊爾語和邁蒂利語查詢則較弱（平均有 27.7% 的有害查詢成功越獄）。此外，對於英語、丹麥語、捷克語和斯洛維尼亞語查詢，LLM 往往會產生品質較高的回應（平均 F1 分數為 0.1494），優於其他語言。根據這些發現，我們提出基於相似性的投票機制 LDFighter，以減輕 LLM 中的語言歧視。LDFighter 可確保為不同語言使用者提供一致的服務。我們使用良性查詢和有害查詢評估 LDFighter。結果顯示，LDFighter 不僅大幅降低越獄成功率，也提升了平均回應品質，證明其有效性。</paragraph>

##### **Evaluating Readability and Faithfulness of Concept-based Explanations**
2404.18533v1 by Meng Li,Haoran Jin,Ruixuan Huang,Zhihao Xu,Defu Lian,Zijia Lin,Di Zhang,Xiting Wang

Despite the surprisingly high intelligence exhibited by Large Language Models
(LLMs), we are somehow intimidated to fully deploy them into real-life
applications considering their black-box nature. Concept-based explanations
arise as a promising avenue for explaining what the LLMs have learned, making
them more transparent to humans. However, current evaluations for concepts tend
to be heuristic and non-deterministic, e.g. case study or human evaluation,
hindering the development of the field. To bridge the gap, we approach
concept-based explanation evaluation via faithfulness and readability. We first
introduce a formal definition of concept generalizable to diverse concept-based
explanations. Based on this, we quantify faithfulness via the difference in the
output upon perturbation. We then provide an automatic measure for readability,
by measuring the coherence of patterns that maximally activate a concept. This
measure serves as a cost-effective and reliable substitute for human
evaluation. Finally, based on measurement theory, we describe a meta-evaluation
method for evaluating the above measures via reliability and validity, which
can be generalized to other tasks as well. Extensive experimental analysis has
been conducted to validate and inform the selection of concept evaluation
measures.

摘要：儘管大型語言模型 (LLM) 展現出驚人的高智慧，但我們在將其完全部署到實際應用中時，仍因其黑箱性質而感到恐懼。基於概念的解釋作為一種有前途的方法出現，用於解釋 LLM 學到了什麼，讓它們對人類更透明。然而，目前對概念的評估往往是啟發式的且非確定性的，例如案例研究或人類評估，這阻礙了該領域的發展。為了彌合差距，我們透過忠實度和可讀性來評估基於概念的解釋。我們首先介紹一個概念的形式定義，該定義可以推廣到各種基於概念的解釋。在此基礎上，我們通過擾動後輸出的差異來量化忠實度。然後，我們透過測量最大程度激活概念的模式的相干性，提供一個自動的可讀性測量。此測量作為人類評估的經濟且可靠的替代方案。最後，基於測量理論，我們描述一種元評估方法，透過可靠性和有效性評估上述測量，這也可以推廣到其他任務。已進行廣泛的實驗分析，以驗證和告知概念評估措施的選擇。

##### **MileBench: Benchmarking MLLMs in Long Context**
2404.18532v1 by Dingjie Song,Shunian Chen,Guiming Hardy Chen,Fei Yu,Xiang Wan,Benyou Wang

Despite the advancements and impressive performance of Multimodal Large
Language Models (MLLMs) on benchmarks, their effectiveness in real-world,
long-context, and multi-image tasks is unclear due to the benchmarks' limited
scope. Existing benchmarks often focus on single-image and short-text samples,
and when assessing multi-image tasks, they either limit the image count or
focus on specific task (e.g time-series captioning), potentially obscuring the
performance challenges of MLLMs. To address these limitations, we introduce
MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt
capabilities of MLLMs. This benchmark comprises not only multimodal long
contexts, but also multiple tasks requiring both comprehension and generation.
We establish two distinct evaluation sets, diagnostic and realistic, to
systematically assess MLLMs' long-context adaptation capacity and their ability
to complete tasks in long-context scenarios. Our experimental results, obtained
from testing 20 models, revealed that while the closed-source GPT-4(Vision) and
Gemini 1.5 outperform others, most open-source MLLMs struggle in long-context
situations. Interestingly, the performance gap tends to widen with an increase
in the number of images. We strongly encourage an intensification of research
efforts towards enhancing MLLMs' long-context capabilities, especially in
scenarios involving multiple images.

摘要：儘管多模態大型語言模型 (MMLM) 在基準上的進展和令人印象深刻的表現，但由於基準的範圍有限，它們在真實世界、長語境和多圖像任務中的有效性仍不清楚。現有的基準通常專注於單一圖像和短文字範例，並且在評估多圖像任務時，它們會限制圖像數量或專注於特定任務（例如時間序列標題），可能會模糊 MLLM 的效能挑戰。為了解決這些限制，我們引入了 MileBench，這是一個先驅基準，旨在測試 MLLM 的多模態長語境能力。此基準不僅包含多模態長語境，還包含需要理解和生成的各種任務。我們建立了兩個不同的評估集，診斷和現實，以系統地評估 MLLM 的長語境適應能力及其在長語境場景中完成任務的能力。我們從測試 20 個模型中獲得的實驗結果顯示，雖然閉源的 GPT-4(Vision) 和 Gemini 1.5 優於其他模型，但大多數開源 MLLM 在長語境情況下都很難以應付。有趣的是，效能差距往往會隨著圖像數量的增加而擴大。我們強烈鼓勵加強研究工作，以增強 MLLM 的長語境能力，特別是在涉及多圖像的場景中。

##### **A Framework to Model ML Engineering Processes**
2404.18531v1 by Sergio Morales,Robert Clarisó,Jordi Cabot

The development of Machine Learning (ML) based systems is complex and
requires multidisciplinary teams with diverse skill sets. This may lead to
communication issues or misapplication of best practices. Process models can
alleviate these challenges by standardizing task orchestration, providing a
common language to facilitate communication, and nurturing a collaborative
environment. Unfortunately, current process modeling languages are not suitable
for describing the development of such systems. In this paper, we introduce a
framework for modeling ML-based software development processes, built around a
domain-specific language and derived from an analysis of scientific and gray
literature. A supporting toolkit is also available.

摘要：機器學習 (ML) 為基礎的系統開發複雜，
需要具備多元技能的多學科團隊。這可能會導致
溝通問題或最佳實務的錯誤應用。程序模型可以透過標準化任務協調、提供一種共同語言來促進溝通，以及培養協作環境來緩解這些挑戰。不幸的是，目前的程序建模語言並不適合用來描述此類系統的開發。在本文中，我們介紹了一個用於建模基於 ML 的軟體開發程序的架構，它建立在特定領域語言的基礎上，並衍生自對科學和灰色文獻的分析。也提供了支援工具包。

##### **Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning**
2404.18527v1 by Weike Peng,Jiaxin Gao,Yuntian Chen,Shengwei Wang

Machine learning algorithms emerge as a promising approach in energy fields,
but its practical is hindered by data barriers, stemming from high collection
costs and privacy concerns. This study introduces a novel federated learning
(FL) framework based on XGBoost models, enabling safe collaborative modeling
with accessible yet concealed data from multiple parties. Hyperparameter tuning
of the models is achieved through Bayesian Optimization. To ascertain the
merits of the proposed FL-XGBoost method, a comparative analysis is conducted
between separate and centralized models to address a classical binary
classification problem in geoenergy sector. The results reveal that the
proposed FL framework strikes an optimal balance between privacy and accuracy.
FL models demonstrate superior accuracy and generalization capabilities
compared to separate models, particularly for participants with limited data or
low correlation features and offers significant privacy benefits compared to
centralized model. The aggregated optimization approach within the FL agreement
proves effective in tuning hyperparameters. This study opens new avenues for
assessing unconventional reservoirs through collaborative and
privacy-preserving FL techniques.

摘要：機器學習演算法在能源領域中作為一種有前途的方法出現，
但其實際應用受到資料障礙的阻礙，這源於高昂的收集成本和隱私問題。本研究介紹了一種基於 XGBoost 模型的新型聯合學習 (FL) 架構，能夠利用來自多方的可存取但隱藏的資料進行安全的協作建模。模型的超參數調整是透過貝氏最佳化來實現的。為了確定所提出的 FL-XGBoost 方法的優點，在單獨模型和集中式模型之間進行了比較分析，以解決地熱能領域中的一個經典二元分類問題。結果表明，所提出的 FL 架構在隱私和準確性之間取得了最佳平衡。與單獨模型相比，FL 模型展示出優越的準確性和泛化能力，特別是對於資料有限或低相關特徵的參與者，並且與集中式模型相比提供了顯著的隱私優勢。FL 協議中的聚合最佳化方法被證明在調整超參數方面是有效的。本研究為透過協作和隱私保護 FL 技術評估非常規儲層開闢了新途徑。

##### **On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**
2404.18519v1 by Usevalad Milasheuski. Luca Barbieri,Bernardo Camajori Tedeschini,Monica Nicoli,Stefano Savazzi

Federated Learning (FL) allows multiple privacy-sensitive applications to
leverage their dataset for a global model construction without any disclosure
of the information. One of those domains is healthcare, where groups of silos
collaborate in order to generate a global predictor with improved accuracy and
generalization. However, the inherent challenge lies in the high heterogeneity
of medical data, necessitating sophisticated techniques for assessment and
compensation. This paper presents a comprehensive exploration of the
mathematical formalization and taxonomy of heterogeneity within FL
environments, focusing on the intricacies of medical data. In particular, we
address the evaluation and comparison of the most popular FL algorithms with
respect to their ability to cope with quantity-based, feature and label
distribution-based heterogeneity. The goal is to provide a quantitative
evaluation of the impact of data heterogeneity in FL systems for healthcare
networks as well as a guideline on FL algorithm selection. Our research extends
beyond existing studies by benchmarking seven of the most common FL algorithms
against the unique challenges posed by medical data use cases. The paper
targets the prediction of the risk of stroke recurrence through a set of
tabular clinical reports collected by different federated hospital silos: data
heterogeneity frequently encountered in this scenario and its impact on FL
performance are discussed.

摘要：聯邦學習 (FL) 允許多個注重隱私的應用程式利用其資料集，在不揭露任何資訊的情況下建構全球模型。其中一個領域是醫療保健，各個資料孤島共同合作，以產生具有更高準確度和概括性的全球預測器。然而，其固有的挑戰在於醫療資料的高度異質性，這需要採用複雜的技術進行評估和補償。本文全面探討了 FL 環境中的異質性的數學形式化和分類，重點關注醫療資料的複雜性。特別是，我們探討了最受歡迎的 FL 演算法的評估和比較，特別是它們應對基於數量、特徵和標籤分佈的異質性的能力。目標是對資料異質性對醫療保健網路的 FL 系統的影響進行量化評估，並提供 FL 演算法選擇的指南。我們的研究擴展到現有研究，將七種最常見的 FL 演算法與醫療資料使用案例帶來的獨特挑戰進行比較。本文針對通過不同聯邦醫院孤島收集的一組表格臨床報告來預測中風復發的風險：此情境中經常遇到的資料異質性及其對 FL 效能的影響。

##### **From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?**
2404.18518v1 by Jiangfeng Liu,Ziyi Wang,Jing Xie,Lei Pei

Generative large-scale language models create the fifth paradigm of
scientific research, organically combine data science and computational
intelligence, transform the research paradigm of natural language processing
and multimodal information processing, promote the new trend of AI-enabled
social science research, and provide new ideas for digital humanities research
and application. This article profoundly explores the application of
large-scale language models in digital humanities research, revealing their
significant potential in ancient book protection, intelligent processing, and
academic innovation. The article first outlines the importance of ancient book
resources and the necessity of digital preservation, followed by a detailed
introduction to developing large-scale language models, such as ChatGPT, and
their applications in document management, content understanding, and
cross-cultural research. Through specific cases, the article demonstrates how
AI can assist in the organization, classification, and content generation of
ancient books. Then, it explores the prospects of AI applications in artistic
innovation and cultural heritage preservation. Finally, the article explores
the challenges and opportunities in the interaction of technology, information,
and society in the digital humanities triggered by AI technologies.

摘要：生成式大型語言模型創造了科學研究的第五個範例，有機地結合了資料科學和計算智慧，轉變了自然語言處理和多模態資訊處理的研究範例，推動了 AI 驅動的社會科學研究的新趨勢，並為數位人文研究和應用提供了新思路。本文深入探討了大型語言模型在數位人文研究中的應用，揭示了它們在古籍保護、智慧處理和學術創新方面的顯著潛力。本文首先概述了古籍資源的重要性以及數位保存的必要性，接著詳細介紹了大型語言模型的發展，例如 ChatGPT，以及它們在文件管理、內容理解和跨文化研究中的應用。本文通過具體案例展示了 AI 如何協助古籍的組織、分類和內容生成。然後，它探討了 AI 應用於藝術創新和文化遺產保護的前景。最後，本文探討了 AI 技術引發的數位人文領域中技術、資訊和社會互動所面臨的挑戰和機遇。

##### **Explainability of Machine Learning Approaches in Forensic Linguistics: A Case Study in Geolinguistic Authorship Profiling**
2404.18510v1 by Dana Roemling,Yves Scherrer,Aleksandra Miletic

Forensic authorship profiling uses linguistic markers to infer
characteristics about an author of a text. This task is paralleled in dialect
classification, where a prediction is made about the linguistic variety of a
text based on the text itself. While there have been significant advances in
the last years in variety classification (Jauhiainen et al., 2019) and
state-of-the-art approaches reach accuracies of up to 100% depending on the
similarity of varieties and the scope of prediction (e.g., Milne et al., 2012;
Blodgett et al., 2017), forensic linguistics rarely relies on these approaches
due to their lack of transparency (see Nini, 2023), amongst other reasons. In
this paper we therefore explore explainability of machine learning approaches
considering the forensic context. We focus on variety classification as a means
of geolinguistic profiling of unknown texts. For this we work with an approach
proposed by Xie et al. (2024) to extract the lexical items most relevant to the
variety classifications. We find that the extracted lexical features are indeed
representative of their respective varieties and note that the trained models
also rely on place names for classifications.

摘要：法醫作者側寫使用語言標記來推斷文字作者的特徵。此任務與方言分類類似，其中根據文字本身對文字的語言變體進行預測。雖然在過去幾年中，品種分類（Jauhiainen 等人，2019 年）取得了顯著進展，並且最先進的方法根據品種的相似性和預測範圍（例如，Milne 等人，2012 年；Blodgett 等人，2017 年）達到了高達 100% 的準確度，但法醫語言學由於缺乏透明度（見 Nini，2023 年）等原因，很少依賴這些方法。因此，在本文中，我們探討了考慮法醫背景的機器學習方法的可解釋性。我們專注於品種分類作為對未知文字進行地理語言側寫的一種手段。為此，我們採用 Xie 等人（2024 年）提出的方法來提取與品種分類最相關的詞彙項目。我們發現提取的詞彙特徵確實代表了它們各自的品種，並且注意到訓練有素的模型也依賴於地名進行分類。

##### **Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models**
2404.18508v1 by Mark Schöne,Neeraj Mohan Sushma,Jingyue Zhuge,Christian Mayr,Anand Subramoney,David Kappel

Event-based sensors are well suited for real-time processing due to their
fast response times and encoding of the sensory data as successive temporal
differences. These and other valuable properties, such as a high dynamic range,
are suppressed when the data is converted to a frame-based format. However,
most current methods either collapse events into frames or cannot scale up when
processing the event data directly event-by-event. In this work, we address the
key challenges of scaling up event-by-event modeling of the long event streams
emitted by such sensors, which is a particularly relevant problem for
neuromorphic computing. While prior methods can process up to a few thousand
time steps, our model, based on modern recurrent deep state-space models,
scales to event streams of millions of events for both training and
inference.We leverage their stable parameterization for learning long-range
dependencies, parallelizability along the sequence dimension, and their ability
to integrate asynchronous events effectively to scale them up to long event
streams.We further augment these with novel event-centric techniques enabling
our model to match or beat the state-of-the-art performance on several event
stream benchmarks. In the Spiking Speech Commands task, we improve
state-of-the-art by a large margin of 6.6% to 87.1%. On the DVS128-Gestures
dataset, we achieve competitive results without using frames or convolutional
neural networks. Our work demonstrates, for the first time, that it is possible
to use fully event-based processing with purely recurrent networks to achieve
state-of-the-art task performance in several event-based benchmarks.

摘要：<paragraph>基於事件的感測器由於其快速的回應時間和將感測資料編碼為連續時間差異，因此非常適合用於即時處理。這些和其他有價值的特性（例如高動態範圍）在資料轉換為基於幀的格式時會被抑制。然而，目前大多數方法會將事件壓縮成幀，或者在直接逐個事件處理事件資料時無法擴充。在這項工作中，我們探討了擴充逐個事件建模的關鍵挑戰，以處理此類感測器所發出的長事件串流，這對於神經形態運算來說是一個特別相關的問題。雖然先前的方法可以處理數千個時間步驟，但我們的模型基於現代遞迴深度狀態空間模型，可以擴充到數百萬個事件的事件串流，用於訓練和推論。我們利用其穩定的參數化來學習長程依賴性、序列維度的並行性，以及有效整合非同步事件的能力，以將其擴充到長事件串流。我們進一步使用新穎的以事件為中心的技術來擴充這些技術，使我們的模型能夠在多個事件串流基準測試中匹配或超越最先進的效能。在 Spiking Speech Commands 任務中，我們將最先進的技術大幅提升了 6.6%，達到 87.1%。在 DVS128-Gestures 資料集上，我們在不使用幀或卷積神經網路的情況下達到了有競爭力的結果。我們的研究首次證明，使用純遞迴網路進行完全基於事件的處理，可以在多個基於事件的基準測試中實現最先進的任務效能。</paragraph>

##### **ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction**
2404.18470v1 by Yupeng Cao,Zhi Chen,Qingyun Pei,Prashant Kumar,K. P. Subbalakshmi,Papa Momar Ndiaye

In the realm of financial analytics, leveraging unstructured data, such as
earnings conference calls (ECCs), to forecast stock performance is a critical
challenge that has attracted both academics and investors. While previous
studies have used deep learning-based models to obtain a general view of ECCs,
they often fail to capture detailed, complex information. Our study introduces
a novel framework: \textbf{ECC Analyzer}, combining Large Language Models
(LLMs) and multi-modal techniques to extract richer, more predictive insights.
The model begins by summarizing the transcript's structure and analyzing the
speakers' mode and confidence level by detecting variations in tone and pitch
for audio. This analysis helps investors form an overview perception of the
ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based
methods to meticulously extract the focuses that have a significant impact on
stock performance from an expert's perspective, providing a more targeted
analysis. The model goes a step further by enriching these extracted focuses
with additional layers of analysis, such as sentiment and audio segment
features. By integrating these insights, the ECC Analyzer performs multi-task
predictions of stock performance, including volatility, value-at-risk (VaR),
and return for different intervals. The results show that our model outperforms
traditional analytic benchmarks, confirming the effectiveness of using advanced
LLM techniques in financial analytics.

摘要：在財務分析領域，利用非結構化數據，例如收益會議電話 (ECC)，來預測股票表現是一項重大挑戰，吸引了學者和投資者的關注。雖然先前的研究已經使用基於深度學習的模型來獲得 ECC 的一般看法，但它們通常無法捕捉詳細、複雜的資訊。我們的研究引入了新的架構：**ECC 分析器**，結合大型語言模型 (LLM) 和多模式技術，以提取更豐富、更具預測性的見解。該模型首先總結轉錄的結構，並透過偵測音調和音高的變化來分析說話者的模式和信心水準。此分析有助於投資者形成對 ECC 的概觀認知。此外，此模型使用基於檢索增強生成 (RAG) 的方法，從專家的角度細緻地提取對股票表現有重大影響的重點，提供更具針對性的分析。該模型進一步透過豐富這些提取的重點，加上情緒和音訊片段特徵等額外的分析層。透過整合這些見解，ECC 分析器執行股票表現的多任務預測，包括波動性、風險價值 (VaR) 和不同區間的報酬。結果顯示，我們的模型優於傳統的分析基準，證實了在財務分析中使用進階 LLM 技術的有效性。

##### **HFT: Half Fine-Tuning for Large Language Models**
2404.18466v1 by Tingfeng Hui,Zhenyu Zhang,Shuohuan Wang,Weiran Xu,Yu Sun,Hua Wu

Large language models (LLMs) with one or more fine-tuning phases have become
a necessary step to unlock various capabilities, enabling LLMs to follow
natural language instructions or align with human preferences. However, it
carries the risk of catastrophic forgetting during sequential training, the
parametric knowledge or the ability learned in previous stages may be
overwhelmed by incoming training data. In this paper, we find that by regularly
resetting partial parameters, LLMs can restore some of the original knowledge.
Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute
for full fine-tuning (FFT), to mitigate the forgetting issues, where half of
the parameters are selected to learn new tasks while the other half are frozen
to remain previous knowledge. We provide a feasibility analysis from the
perspective of optimization and interpret the parameter selection operation as
a regularization term. Without changing the model architecture, HFT could be
seamlessly integrated into existing fine-tuning frameworks. Extensive
experiments and analysis on supervised fine-tuning, direct preference
optimization, and continual learning consistently demonstrate the
effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not
only significantly alleviates the forgetting problem, but also achieves the
best performance in a series of downstream benchmarks, with an approximately
30% reduction in training time.

摘要：大型語言模型 (LLM) 經過一或多個微調階段，已成為解鎖各種功能的必要步驟，使 LLM 能夠遵循自然語言指令或符合人類偏好。然而，它在順序訓練過程中會帶來災難性遺忘的風險，在先前階段中學習到的參數知識或能力可能會被輸入的訓練資料淹沒。在本文中，我們發現透過定期重設部分參數，LLM 可以恢復一些原始知識。受到此啟發，我們為 LLM 介紹了半微調 (HFT)，作為完全微調 (FFT) 的替代方案，以減輕遺忘問題，其中一半參數被選來學習新任務，而另一半則被凍結以保留先前的知識。我們從最佳化的角度提供了可行性分析，並將參數選擇操作解釋為正則化項。在不改變模型架構的情況下，HFT 可以無縫整合到現有的微調框架中。在監督式微調、直接偏好最佳化和持續學習上的廣泛實驗和分析持續證明了 HFT 的有效性、穩健性和效率。與 FFT 相比，HFT 不僅顯著減輕了遺忘問題，而且在連串的下游基準測試中取得了最佳效能，訓練時間減少了大約 30%。

##### **M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework**
2404.18465v1 by Zijian Zhang,Shuchang Liu,Jiaao Yu,Qingpeng Cai,Xiangyu Zhao,Chunxu Zhang,Ziru Liu,Qidong Liu,Hongwei Zhao,Lantao Hu,Peng Jiang,Kun Gai

Multi-domain recommendation and multi-task recommendation have demonstrated
their effectiveness in leveraging common information from different domains and
objectives for comprehensive user modeling. Nonetheless, the practical
recommendation usually faces multiple domains and tasks simultaneously, which
cannot be well-addressed by current methods. To this end, we introduce M3oE, an
adaptive multi-domain multi-task mixture-of-experts recommendation framework.
M3oE integrates multi-domain information, maps knowledge across domains and
tasks, and optimizes multiple objectives. We leverage three mixture-of-experts
modules to learn common, domain-aspect, and task-aspect user preferences
respectively to address the complex dependencies among multiple domains and
tasks in a disentangled manner. Additionally, we design a two-level fusion
mechanism for precise control over feature extraction and fusion across diverse
domains and tasks. The framework's adaptability is further enhanced by applying
AutoML technique, which allows dynamic structure optimization. To the best of
the authors' knowledge, our M3oE is the first effort to solve multi-domain
multi-task recommendation self-adaptively. Extensive experiments on two
benchmark datasets against diverse baselines demonstrate M3oE's superior
performance. The implementation code is available to ensure reproducibility.

摘要：多領域推薦和多任務推薦已證明它們在利用不同領域和目標的共同資訊進行全面使用者建模方面的有效性。儘管如此，實際推薦通常同時面對多個領域和任務，這無法透過目前的方法來妥善解決。為此，我們引入了 M3oE，一個適應性多領域多任務混合專家推薦架構。M3oE 整合多領域資訊，對跨領域和任務的知識進行對應，並最佳化多個目標。我們利用三個混合專家模組分別學習共同、領域面向和任務面向的使用者偏好，以解開多個領域和任務之間的複雜依存關係。此外，我們設計了一個兩級融合機制，精準控制跨不同領域和任務的特徵萃取和融合。透過應用 AutoML 技術，進一步增強架構的適應性，允許動態結構最佳化。據作者所知，我們的 M3oE 是第一個嘗試以自適應方式解決多領域多任務推薦的成果。針對兩個基準資料集進行大量實驗，與不同的基準進行比較，證明了 M3oE 的卓越效能。實作程式碼可供取得，以確保可重製性。

##### **Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in**
2404.18460v1 by Utkarsh Agarwal,Kumar Tanmay,Aditi Khandelwal,Monojit Choudhury

Ethical reasoning is a crucial skill for Large Language Models (LLMs).
However, moral values are not universal, but rather influenced by language and
culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and
Llama2-70B-Chat -- perform ethical reasoning in different languages and if
their moral judgement depend on the language in which they are prompted. We
extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a
multilingual setup following their framework of probing LLMs with ethical
dilemmas and policies from three branches of normative ethics: deontology,
virtue, and consequentialism. We experiment with six languages: English,
Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most
consistent and unbiased ethical reasoner across languages, while ChatGPT and
Llama2-70B-Chat show significant moral value bias when we move to languages
other than English. Interestingly, the nature of this bias significantly vary
across languages for all LLMs, including GPT-4.

摘要：大型語言模型 (LLM) 的倫理推理是一項至關重要的技能。
然而，道德價值觀並非普遍，而是受語言和文化影響。本文探討了三種傑出的 LLM（GPT-4、ChatGPT 和 Llama2-70B-Chat）如何在不同的語言中進行倫理推理，以及他們的道德判斷是否取決於提示他們的語言。我們擴展了 Rao 等人 (2023) 對 LLM 倫理推理的研究，採用他們的框架，用來自規範倫理學三個分支（義務論、美德論和後果論）的倫理困境和政策來探測 LLM。我們實驗了六種語言：英語、西班牙語、俄語、中文、印地語和斯瓦希里語。我們發現 GPT-4 是跨語言最一致且最公正的倫理推理器，而 ChatGPT 和 Llama2-70B-Chat 在我們轉換到英語以外的語言時表現出顯著的道德價值觀偏差。有趣的是，這種偏差的性質對於所有 LLM，包括 GPT-4，在不同語言中都有顯著差異。

##### **U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models**
2404.18444v1 by Song Mei

U-Nets are among the most widely used architectures in computer vision,
renowned for their exceptional performance in applications such as image
segmentation, denoising, and diffusion modeling. However, a theoretical
explanation of the U-Net architecture design has not yet been fully
established.
  This paper introduces a novel interpretation of the U-Net architecture by
studying certain generative hierarchical models, which are tree-structured
graphical models extensively utilized in both language and image domains. With
their encoder-decoder structure, long skip connections, and pooling and
up-sampling layers, we demonstrate how U-Nets can naturally implement the
belief propagation denoising algorithm in such generative hierarchical models,
thereby efficiently approximating the denoising functions. This leads to an
efficient sample complexity bound for learning the denoising function using
U-Nets within these models. Additionally, we discuss the broader implications
of these findings for diffusion models in generative hierarchical models. We
also demonstrate that the conventional architecture of convolutional neural
networks (ConvNets) is ideally suited for classification tasks within these
models. This offers a unified view of the roles of ConvNets and U-Nets,
highlighting the versatility of generative hierarchical models in modeling
complex data distributions across language and image domains.

摘要：U-Nets 是電腦視覺中最廣泛使用的架構之一，
以其在影像分割、去噪和擴散建模等應用中的出色表現而聞名。然而，對於 U-Net 架構設計的理論解釋尚未完全建立。
本文透過研究某些生成式階層模型，提出 U-Net 架構的新穎詮釋，這些模型是廣泛用於語言和影像領域的樹狀結構圖形模型。透過其編碼器-解碼器結構、長跳躍連接，以及池化和上採樣層，我們展示 U-Nets 如何在這些生成式階層模型中自然地實作信念傳播去噪演算法，從而有效地近似去噪函數。這導致在這些模型中使用 U-Nets 學習去噪函數時，能夠有效地限制樣本複雜度。此外，我們討論了這些發現對生成式階層模型中擴散模型的更廣泛影響。我們也展示了卷積神經網路 (ConvNets) 的傳統架構非常適合這些模型中的分類任務。這提供了 ConvNets 和 U-Nets 角色的統一觀點，突顯了生成式階層模型在語言和影像領域中對複雜資料分佈建模的多功能性。

##### **BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**
2404.18443v1 by Ran Xu,Wenqi Shi,Yue Yu,Yuchen Zhuang,Yanqiao Zhu,May D. Wang,Joyce C. Ho,Chao Zhang,Carl Yang

Developing effective biomedical retrieval models is important for excelling
at knowledge-intensive biomedical tasks but still challenging due to the
deficiency of sufficient publicly annotated biomedical data and computational
resources. We present BMRetriever, a series of dense retrievers for enhancing
biomedical retrieval via unsupervised pre-training on large biomedical corpora,
followed by instruction fine-tuning on a combination of labeled datasets and
synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify
BMRetriever's efficacy on various biomedical applications. BMRetriever also
exhibits strong parameter efficiency, with the 410M variant outperforming
baselines up to 11.7 times larger, and the 2B variant matching the performance
of models with over 5B parameters. The training data and model checkpoints are
released at \url{https://huggingface.co/BMRetriever} to ensure transparency,
reproducibility, and application to new domains.

摘要：開發有效生物醫學檢索模型對於在知識密集的生物醫學任務中表現出色很重要，但由於缺乏足夠的公開註釋生物醫學資料和計算資源，仍然具有挑戰性。我們提出 BMRetriever，這是一系列密集檢索器，用於透過在大型生物醫學語料庫上進行無監督預訓練來增強生物醫學檢索，然後對標記資料集和合成配對的組合進行指令微調。在 11 個資料集中的 5 個生物醫學任務上進行的實驗驗證了 BMRetriever 在各種生物醫學應用中的功效。BMRetriever 還展現出強大的參數效率，其中 410M 變體的效能優於基準線高達 11.7 倍，而 2B 變體的效能與超過 5B 參數的模型相匹配。訓練資料和模型檢查點在 \url{https://huggingface.co/BMRetriever} 發布，以確保透明度、可複製性，並應用於新領域。

##### **Unsupervised Dynamics Prediction with Object-Centric Kinematics**
2404.18423v1 by Yeon-Ji Song,Suhyung Choi,Jaein Kim,Jin-Hwa Kim,Byoung-Tak Zhang

Human perception involves discerning complex multi-object scenes into
time-static object appearance (\ie, size, shape, color) and time-varying object
motion (\ie, location, velocity, acceleration). This innate ability to
unconsciously understand the environment is the motivation behind the success
of dynamics modeling. Object-centric representations have emerged as a
promising tool for dynamics prediction, yet they primarily focus on the
objects' appearance, often overlooking other crucial attributes. In this paper,
we propose Object-Centric Kinematics (OCK), a framework for dynamics prediction
leveraging object-centric representations. Our model utilizes a novel component
named object kinematics, which comprises low-level structured states of
objects' position, velocity, and acceleration. The object kinematics are
obtained via either implicit or explicit approaches, enabling comprehensive
spatiotemporal object reasoning, and integrated through various transformer
mechanisms, facilitating effective object-centric dynamics modeling. Our model
demonstrates superior performance when handling objects and backgrounds in
complex scenes characterized by a wide range of object attributes and dynamic
movements. Moreover, our model demonstrates generalization capabilities across
diverse synthetic environments, highlighting its potential for broad
applicability in vision-related tasks.

摘要：人類感知涉及將複雜的多物件場景分辨為時間靜態物件外觀（例如，大小、形狀、顏色）和時間變動物件運動（例如，位置、速度、加速度）。這種無意識理解環境的先天能力是動力學建模成功的背後動機。以物件為中心的表示法已成為動態預測的有前途工具，但它們主要關注物件的外觀，常常忽略其他關鍵屬性。在本文中，我們提出了以物件為中心的運動學（OCK），一個利用以物件為中心的表示法的動態預測框架。我們的模型利用了一個名為物件運動學的新元件，它包含物件位置、速度和加速度的低階結構狀態。物件運動學是透過隱式或顯式方法獲得的，能進行全面的時空物件推理，並透過各種變壓器機制進行整合，促進有效的以物件為中心的動態建模。我們的模型在處理具有廣泛物件屬性和動態運動的複雜場景中的物件和背景時，表現出優異的效能。此外，我們的模型展示了在不同合成環境中的泛化能力，突顯了其在與視覺相關任務中廣泛應用的潛力。

##### **Capabilities of Gemini Models in Medicine**
2404.18416v1 by Khaled Saab,Tao Tu,Wei-Hung Weng,Ryutaro Tanno,David Stutz,Ellery Wulczyn,Fan Zhang,Tim Strother,Chunjong Park,Elahe Vedadi,Juanma Zambrano Chaves,Szu-Yeu Hu,Mike Schaekermann,Aishwarya Kamath,Yong Cheng,David G. T. Barrett,Cathy Cheung,Basil Mustafa,Anil Palepu,Daniel McDuff,Le Hou,Tomer Golany,Luyang Liu,Jean-baptiste Alayrac,Neil Houlsby,Nenad Tomasev,Jan Freyberg,Charles Lau,Jonas Kemp,Jeremy Lai,Shekoofeh Azizi,Kimberly Kanada,SiWai Man,Kavita Kulkarni,Ruoxi Sun,Siamak Shakeri,Luheng He,Ben Caine,Albert Webson,Natasha Latysheva,Melvin Johnson,Philip Mansfield,Jian Lu,Ehud Rivlin,Jesper Anderson,Bradley Green,Renee Wong,Jonathan Krause,Jonathon Shlens,Ewa Dominowska,S. M. Ali Eslami,Claire Cui,Oriol Vinyals,Koray Kavukcuoglu,James Manyika,Jeff Dean,Demis Hassabis,Yossi Matias,Dale Webster,Joelle Barral,Greg Corrado,Christopher Semturs,S. Sara Mahdavi,Juraj Gottweis,Alan Karthikesalingam,Vivek Natarajan

Excellence in a wide variety of medical applications poses considerable
challenges for AI, requiring advanced reasoning, access to up-to-date medical
knowledge and understanding of complex multimodal data. Gemini models, with
strong general capabilities in multimodal and long-context reasoning, offer
exciting possibilities in medicine. Building on these core strengths of Gemini,
we introduce Med-Gemini, a family of highly capable multimodal models that are
specialized in medicine with the ability to seamlessly use web search, and that
can be efficiently tailored to novel modalities using custom encoders. We
evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
benchmark where a direct comparison is viable, often by a wide margin. On the
popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
(health & medicine), Med-Gemini improves over GPT-4V by an average relative
margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
capabilities through SoTA performance on a needle-in-a-haystack retrieval task
from long de-identified health records and medical video question answering,
surpassing prior bespoke methods using only in-context learning. Finally,
Med-Gemini's performance suggests real-world utility by surpassing human
experts on tasks such as medical text summarization, alongside demonstrations
of promising potential for multimodal medical dialogue, medical research and
education. Taken together, our results offer compelling evidence for
Med-Gemini's potential, although further rigorous evaluation will be crucial
before real-world deployment in this safety-critical domain.

摘要：<paragraph>在各種醫療應用中追求卓越對 AI 構成相當大的挑戰，需要進階推理、取得最新醫療知識，以及理解複雜的多模態資料。Gemini 模型在多模態和長脈絡推理方面具備強大的通用功能，在醫學領域提供了令人興奮的可能性。在 Gemini 這些核心優勢的基礎上，我們推出了 Med-Gemini，這是一個功能強大的多模態模型系列，專精於醫學，能夠無縫使用網路搜尋，而且可以使用自訂編碼器有效地調整為新穎的模態。我們在 14 個醫療基準上評估 Med-Gemini，在其中 10 個基準上建立了新的最先進 (SoTA) 效能，並且在每個可以進行直接比較基準上都超越了 GPT-4 模型系列，而且差距通常很大。在熱門的 MedQA (USMLE) 基準上，我們效能最佳的 Med-Gemini 模型使用新穎的不確定性引導搜尋策略，達到了 91.1% 的 SoTA 準確率。在包括 NEJM 影像挑戰和 MMMU（健康與醫學）在內的 7 個多模態基準上，Med-Gemini 比 GPT-4V 提升了平均相對幅度 44.5%。我們透過在從長去識別化健康記錄和醫療影片問答中進行大海撈針檢索任務上達到 SoTA 效能，證明了 Med-Gemini 的長脈絡功能的有效性，超越了僅使用脈絡學習的先前客製化方法。最後，Med-Gemini 的效能顯示出真正的實用性，在醫療文字摘要等任務上超越了人類專家，同時也展示了多模態醫療對話、醫學研究和教育的潛力。綜上所述，我們的結果為 Med-Gemini 的潛力提供了令人信服的證據，儘管在這個安全至上的領域中進行實際部署之前，進一步的嚴謹評估至關重要。</paragraph>

##### **3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset**
2404.18413v1 by Xinyu Ma,Xuebo Liu,Derek F. Wong,Jun Rao,Bei Li,Liang Ding,Lidia S. Chao,Dacheng Tao,Min Zhang

Multimodal machine translation (MMT) is a challenging task that seeks to
improve translation quality by incorporating visual information. However,
recent studies have indicated that the visual information provided by existing
MMT datasets is insufficient, causing models to disregard it and overestimate
their capabilities. This issue presents a significant obstacle to the
development of MMT research. This paper presents a novel solution to this issue
by introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel
sentence pairs in English and Chinese, each with corresponding images. Our
dataset is specifically designed to include more ambiguity and a greater
variety of both captions and images than other MMT datasets. We utilize a word
sense disambiguation model to select ambiguous data from vision-and-language
datasets, resulting in a more challenging dataset. We further benchmark several
state-of-the-art MMT models on our proposed dataset. Experimental results show
that MMT models trained on our dataset exhibit a greater ability to exploit
visual information than those trained on other MMT datasets. Our work provides
a valuable resource for researchers in the field of multimodal learning and
encourages further exploration in this area. The data, code and scripts are
freely available at https://github.com/MaxyLee/3AM.

摘要：多模態機器翻譯 (MMT) 是一項艱鉅的任務，旨在透過納入視覺資訊來提升翻譯品質。然而，最近的研究指出，現有的 MMT 資料集所提供的視覺資訊不足，導致模型忽視視覺資訊並高估其能力。此問題對 MMT 研究的發展造成重大障礙。本文提出一個創新的解決方案來解決此問題，方法是引入 3AM，一個包含 26,000 組英文和中文並行句子的含糊感知 MMT 資料集，每個句子都對應到相應的影像。我們的資料集特別設計為包含比其他 MMT 資料集更多的含糊性，以及更多樣化的標題和影像。我們利用詞彙意義消歧模型從視覺語言資料集中選取含糊的資料，進而產生更具挑戰性的資料集。我們進一步在我們提出的資料集上評量數個最先進的 MMT 模型。實驗結果顯示，在我們的資料集上訓練的 MMT 模型展現出比在其他 MMT 資料集上訓練的模型更強大的視覺資訊利用能力。我們的研究為多模態學習領域的研究人員提供寶貴的資源，並鼓勵進一步探索此領域。資料、程式碼和腳本可於 https://github.com/MaxyLee/3AM 免費取得。

##### **Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions**
2404.18410v1 by Bowen Xu,Shaoyu Wu,Kai Liu,Lulu Hu

With the proliferation of large language models (LLMs), the comprehensive
alignment of such models across multiple tasks has emerged as a critical area
of research. Existing alignment methodologies primarily address single task,
such as multi-turn dialogue, coding, mathematical problem-solving, and tool
usage. However, AI-driven products that leverage language models usually
necessitate a fusion of these abilities to function effectively in real-world
scenarios. Moreover, the considerable computational resources required for
proper alignment of LLMs underscore the need for a more robust, efficient, and
encompassing approach to multi-task alignment, ensuring improved generative
performance. In response to these challenges, we introduce a novel technique
termed Mixture-of-Instructions (MoI), which employs a strategy of instruction
concatenation combined with diverse system prompts to boost the alignment
efficiency of language models. We have also compiled a diverse set of seven
benchmark datasets to rigorously evaluate the alignment efficacy of the
MoI-enhanced language model. Our methodology was applied to the open-source
Qwen-7B-chat model, culminating in the development of Qwen-SFT-MoI. This
enhanced model demonstrates significant advancements in generative capabilities
across coding, mathematics, and tool use tasks.

摘要：隨著大型語言模型 (LLM) 的激增，此類模型在多項任務中的全面對齊已成為研究的重要領域。現有的對齊方法主要針對單一任務，例如多輪對話、編碼、數學問題求解和工具使用。然而，利用語言模型的 AI 驅動產品通常需要融合這些能力才能在實際場景中有效運作。此外，LLM 的適當對齊需要大量的運算資源，這強調了對多任務對齊採用更強大、更有效率且更全面的方法的需求，以確保生成效能的提升。為了應對這些挑戰，我們引進了一種稱為混合指令 (MoI) 的新技術，它採用指令串接策略，結合不同的系統提示，以提升語言模型的對齊效率。我們還編制了一組七個不同的基準資料集，以嚴格評估 MoI 增強語言模型的對齊效能。我們的技術已應用於開源的 Qwen-7B-chat 模型，最終開發出 Qwen-SFT-MoI。此增強模型在編碼、數學和工具使用任務中展現出生成能力的顯著進步。

##### **LLM-SR: Scientific Equation Discovery via Programming with Large Language Models**
2404.18400v1 by Parshin Shojaee,Kazem Meidani,Shashank Gupta,Amir Barati Farimani,Chandan K Reddy

Mathematical equations have been unreasonably effective in describing complex
natural phenomena across various scientific disciplines. However, discovering
such insightful equations from data presents significant challenges due to the
necessity of navigating extremely high-dimensional combinatorial and nonlinear
hypothesis spaces. Traditional methods of equation discovery largely focus on
extracting equations from data alone, often neglecting the rich domain-specific
prior knowledge that scientists typically depend on. To bridge this gap, we
introduce LLM-SR, a novel approach that leverages the extensive scientific
knowledge and robust code generation capabilities of Large Language Models
(LLMs) to discover scientific equations from data in an efficient manner.
Specifically, LLM-SR treats equations as programs with mathematical operators
and combines LLMs' scientific priors with evolutionary search over equation
programs. The LLM iteratively proposes new equation skeletons, drawing from its
physical understanding, which are then optimized against data to estimate
skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse
scientific domains, where it discovers physically accurate equations that
provide significantly better fits to in-domain and out-of-domain data compared
to the well-established equation discovery baselines

摘要：數學方程式在描述各種科學領域中複雜的自然現象方面一直異常有效。然而，由於必須在極高維度的組合和非線性假設空間中導航，從數據中發現此類有見地的方程式提出了重大挑戰。傳統的方程式發現方法主要專注於僅從數據中提取方程式，通常忽略了科學家通常依賴的豐富領域特定先驗知識。為了彌合理論與實務的差距，我們引入了 LLM-SR，這是一種新方法，它利用大型語言模型 (LLM) 廣泛的科學知識和強大的程式碼生成能力，以有效的方式從數據中發現科學方程式。具體來說，LLM-SR 將方程式視為具有數學運算子的程式，並將 LLM 的科學先驗知識與方程式程式的演化搜尋相結合。LLM 反覆提出新的方程式骨架，從其物理理解中汲取靈感，然後根據數據進行最佳化以估計骨架參數。我們展示了 LLM-SR 在三個不同的科學領域中的有效性，它發現了物理上準確的方程式，與已建立的方程式發現基準線相比，這些方程式對域內和域外數據提供了顯著更好的擬合。

##### **MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**
2404.18398v1 by Xiang Li,Zhi-Qi Cheng,Jun-Yan He,Xiaojiang Peng,Alexander G. Hauptmann

Emotional Text-to-Speech (E-TTS) synthesis has gained significant attention
in recent years due to its potential to enhance human-computer interaction.
However, current E-TTS approaches often struggle to capture the complexity of
human emotions, primarily relying on oversimplified emotional labels or
single-modality inputs. To address these limitations, we propose the Multimodal
Emotional Text-to-Speech System (MM-TTS), a unified framework that leverages
emotional cues from multiple modalities to generate highly expressive and
emotionally resonant speech. MM-TTS consists of two key components: (1) the
Emotion Prompt Alignment Module (EP-Align), which employs contrastive learning
to align emotional features across text, audio, and visual modalities, ensuring
a coherent fusion of multimodal information; and (2) the Emotion
Embedding-Induced TTS (EMI-TTS), which integrates the aligned emotional
embeddings with state-of-the-art TTS models to synthesize speech that
accurately reflects the intended emotions. Extensive evaluations across diverse
datasets demonstrate the superior performance of MM-TTS compared to traditional
E-TTS models. Objective metrics, including Word Error Rate (WER) and Character
Error Rate (CER), show significant improvements on ESD dataset, with MM-TTS
achieving scores of 7.35% and 3.07%, respectively. Subjective assessments
further validate that MM-TTS generates speech with emotional fidelity and
naturalness comparable to human speech. Our code and pre-trained models are
publicly available at https://anonymous.4open.science/r/MMTTS-D214

摘要：情感文字轉語音 (E-TTS) 合成近年來備受關注，因為它有潛力增強人機互動。然而，目前的 E-TTS 方法通常難以捕捉人類情緒的複雜性，主要依賴過於簡化的情緒標籤或單一模式輸入。為了解決這些限制，我們提出了多模態情感文字轉語音系統 (MM-TTS)，這是一個統一的架構，利用來自多種模式的情緒線索來生成極具表現力和情感共鳴的語音。MM-TTS 包含兩個關鍵組成部分：(1) 情緒提示對齊模組 (EP-Align)，它採用對比學習在文字、音訊和視覺模式中對齊情緒特徵，確保多模態資訊的融合一致；(2) 情緒嵌入誘導 TTS (EMI-TTS)，它將對齊的情緒嵌入與最先進的 TTS 模型整合，以合成準確反映預期情緒的語音。跨越不同資料集的廣泛評估證明了 MM-TTS 與傳統 E-TTS 模型相比具有卓越的效能。客觀指標，包括字元錯誤率 (WER) 和字元錯誤率 (CER)，在 ESD 資料集上顯示出顯著的改進，MM-TTS 分別達到 7.35% 和 3.07% 的分數。主觀評估進一步驗證了 MM-TTS 生成的語音具有與人類語音相當的情緒保真度和自然度。我們的程式碼和預訓練模型可在 https://anonymous.4open.science/r/MMTTS-D214 公開取得。

##### **Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice**
2404.18385v1 by Yixuan Li,Dan C. Baciu,Marcos Novak,George Legrady

Over the past year, the emergence of advanced text-to-image Generative AI
models has significantly impacted the art world, challenging traditional
notions of creativity and the role of artists. This study explores how artists
interact with these technologies, using a 5P model (Purpose, People, Process,
Product, and Press) based on Rhodes' creativity framework to compare the
artistic processes behind Conceptual Art and Image Generative AI. To exemplify
this framework, a practical case study titled "Equivalence", a multi-screen
interactive installation that converts users' speech input into continuously
evolving paintings developed based on Stable Diffusion and NLP algorithms, was
developed. Through comprehensive analysis and the case study, this work aims to
broaden our understanding of artists' roles and foster a deeper appreciation
for the creative aspects inherent in artwork created with Image Generative AI.

摘要：在過去的一年，先進的文字轉圖像生成式 AI 模型的出現，對藝術界產生了重大影響，挑戰了傳統的創造力觀念和藝術家的角色。本研究探討藝術家如何與這些技術互動，使用基於羅德斯創造力框架的 5P 模型（目的、人、過程、產品和新聞），比較概念藝術和影像生成式 AI 背後的藝術過程。為了說明這個框架，開發了一個名為「等價」的實務個案研究，這是一個多螢幕互動裝置，將使用者的語音輸入轉換為持續演化的繪畫，這些繪畫是根據 Stable Diffusion 和 NLP 演算法開發的。透過全面的分析和個案研究，這項工作旨在擴展我們對藝術家角色的理解，並培養對使用影像生成式 AI 創作的藝術作品中固有的創造性面向的更深入欣賞。

##### **Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions**
2404.18384v1 by Jordan Meadows,Tamsin James,Andre Freitas

Language models can hallucinate when performing complex and detailed
mathematical reasoning. Physics provides a rich domain for assessing
mathematical reasoning capabilities where physical context imbues the use of
symbols which needs to satisfy complex semantics (\textit{e.g.,} units,
tensorial order), leading to instances where inference may be algebraically
coherent, yet unphysical. In this work, we assess the ability of Language
Models (LMs) to perform fine-grained mathematical and physical reasoning using
a curated dataset encompassing multiple notations and Physics subdomains. We
improve zero-shot scores using synthetic in-context examples, and demonstrate
non-linear degradation of derivation quality with perturbation strength via the
progressive omission of supporting premises. We find that the models'
mathematical reasoning is not physics-informed in this setting, where physical
context is predominantly ignored in favour of reverse-engineering solutions.

摘要：語言模型在進行複雜且詳細的數學推理時可能會出現幻覺。物理學提供了一個豐富的領域來評估數學推理能力，其中物理背景賦予了符號的使用，需要滿足複雜的語義（例如，單位、張量順序），導致推理在代數上可能是一致的，但卻不符合物理。在這項工作中，我們評估語言模型 (LM) 使用精心策劃的數據集（包含多種符號和物理子領域）執行細緻的數學和物理推理的能力。我們使用合成的上下文範例改進零次學習分數，並透過逐步省略支持前提來證明推導品質隨著擾動強度呈非線性下降。我們發現，在這種情況下，模型的數學推理並未受到物理學的影響，其中物理背景在很大程度上被忽略，轉而採用逆向工程解決方案。

##### **QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**
2404.18371v1 by Tomoki Fukuma,Koki Noda,Toshihide Ubukata Kousuke Hoso,Yoshiharu Ichikawa,Kyosuke Kambe,Yu Masubuch,Fujio Toriumi

The proliferation of social media has led to information overload and
increased interest in opinion mining. We propose "Question-Answering Network
Analysis" (QANA), a novel opinion mining framework that utilizes Large Language
Models (LLMs) to generate questions from users' comments, constructs a
bipartite graph based on the comments' answerability to the questions, and
applies centrality measures to examine the importance of opinions. We
investigate the impact of question generation styles, LLM selections, and the
choice of embedding model on the quality of the constructed QA networks by
comparing them with annotated Key Point Analysis datasets. QANA achieves
comparable performance to previous state-of-the-art supervised models in a
zero-shot manner for Key Point Matching task, also reducing the computational
cost from quadratic to linear. For Key Point Generation, questions with high
PageRank or degree centrality align well with manually annotated key points.
Notably, QANA enables analysts to assess the importance of key points from
various aspects according to their selection of centrality measure. QANA's
primary contribution lies in its flexibility to extract key points from a wide
range of perspectives, which enhances the quality and impartiality of opinion
mining.

摘要：社群媒體的激增導致資訊超載，並提升了對意見探勘的興趣。我們提出「問答網路分析」(QANA)，一種新穎的意見探勘架構，它利用大型語言模型 (LLM) 從使用者的意見產生問題，根據意見對問題的可回答性建構二部圖，並應用中心性測量來檢視意見的重要性。我們透過將問題產生樣式、LLM 選擇以及嵌入模型的選擇，與標註關鍵點分析資料集進行比較，來探討其對建構問答網路品質的影響。QANA 在關鍵點比對任務中，以零次學習的方式達到與先前最先進的監督模型相當的效能，同時將運算成本從二次方降低為一次方。對於關鍵點產生，具有高 PageRank 或度中心性的問題與手動標註的關鍵點十分吻合。值得注意的是，QANA 讓分析師能夠根據他們選擇的中心性測量，從各種面向評估關鍵點的重要性。QANA 的主要貢獻在於它從廣泛的角度提取關鍵點的靈活性，這提升了意見探勘的品質和公正性。

##### **FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models**
2404.18359v1 by Wei Li,Ren Ma,Jiang Wu,Chenya Gu,Jiahui Peng,Jinyang Len,Songyang Zhang,Hang Yan,Dahua Lin,Conghui He

In the burgeoning field of large language models (LLMs), the assessment of
fundamental knowledge remains a critical challenge, particularly for models
tailored to Chinese language and culture. This paper introduces FoundaBench, a
pioneering benchmark designed to rigorously evaluate the fundamental knowledge
capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354
multiple-choice questions across common sense and K-12 educational subjects,
meticulously curated to reflect the breadth and depth of everyday and academic
knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using
FoundaBench, employing both traditional assessment methods and our CircularEval
protocol to mitigate potential biases in model responses. Our results highlight
the superior performance of models pre-trained on Chinese corpora, and reveal a
significant disparity between models' reasoning and memory recall capabilities.
The insights gleaned from FoundaBench evaluations set a new standard for
understanding the fundamental knowledge of LLMs, providing a robust framework
for future advancements in the field.

摘要：在蓬勃發展的大語言模型 (LLM) 領域中，基礎知識的評估仍然是一項嚴峻的挑戰，特別是針對針對中文語言和文化的模型。本文介紹了 FoundaBench，這是一個先驅基準，旨在嚴格評估中文 LLM 的基礎知識能力。FoundaBench 涵蓋了 3354 個多元化的多選題，涵蓋常識和 K-12 教育科目，經過精心策劃以反映日常生活和學術知識的廣度和深度。我們使用 FoundaBench 對 12 個最先進的 LLM 進行了廣泛的評估，採用傳統評估方法和我們的 CircularEval 協議來減輕模型回應中的潛在偏差。我們的結果突出了在中文語料庫上預訓練的模型的優異性能，並揭示了模型的推理和記憶召回能力之間的顯著差異。從 FoundaBench 評估中獲得的見解為理解 LLM 的基礎知識樹立了新的標準，為該領域未來的進步提供了強大的框架。

##### **Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models**
2404.18353v1 by Norbert Tihanyi,Tamas Bisztray,Mohamed Amine Ferrag,Ridhi Jain,Lucas C. Cordeiro

This study provides a comparative analysis of state-of-the-art large language
models (LLMs), analyzing how likely they generate vulnerabilities when writing
simple C programs using a neutral zero-shot prompt. We address a significant
gap in the literature concerning the security properties of code produced by
these models without specific directives. N. Tihanyi et al. introduced the
FormAI dataset at PROMISE '23, containing 112,000 GPT-3.5-generated C programs,
with over 51.24% identified as vulnerable. We expand that work by introducing
the FormAI-v2 dataset comprising 265,000 compilable C programs generated using
various LLMs, including robust models such as Google's GEMINI-pro, OpenAI's
GPT-4, and TII's 180 billion-parameter Falcon, to Meta's specialized 13
billion-parameter CodeLLama2 and various other compact models. Each program in
the dataset is labelled based on the vulnerabilities detected in its source
code through formal verification using the Efficient SMT-based Context-Bounded
Model Checker (ESBMC). This technique eliminates false positives by delivering
a counterexample and ensures the exclusion of false negatives by completing the
verification process. Our study reveals that at least 63.47% of the generated
programs are vulnerable. The differences between the models are minor, as they
all display similar coding errors with slight variations. Our research
highlights that while LLMs offer promising capabilities for code generation,
deploying their output in a production environment requires risk assessment and
validation.

摘要：本研究提供了對最先進的大語言模型 (LLM) 的比較分析，分析了它們在使用中立的零次提示編寫簡單 C 程式時產生漏洞的可能性。我們解決了關於這些模型在沒有具體指令的情況下產生的程式碼的安全性屬性的文獻中的重大差距。N. Tihanyi 等人在 PROMISE '23 上介紹了 FormAI 資料集，其中包含 112,000 個 GPT-3.5 生成的 C 程式，其中超過 51.24% 被識別為有漏洞。我們通過引入 FormAI-v2 資料集來擴展這項工作，該資料集包含使用各種 LLM 生成的 265,000 個可編譯 C 程式，包括 Google 的 GEMINI-pro、OpenAI 的 GPT-4 和 TII 的 1800 億參數 Falcon 等強大的模型，以及 Meta 的專用 130 億參數 CodeLLama2 和各種其他精簡模型。資料集中的每個程式都根據使用基於高效 SMT 的上下文限定模型檢查器 (ESBMC) 的形式驗證在其原始程式碼中檢測到的漏洞進行標記。此技術通過提供反例來消除假陽性，並通過完成驗證過程來確保排除假陰性。我們的研究表明，至少 63.47% 的生成程式是有漏洞的。模型之間的差異很小，因為它們都顯示出類似的編碼錯誤，但略有不同。我們的研究強調，儘管 LLM 為程式碼生成提供了有希望的能力，但在生產環境中部署其輸出需要風險評估和驗證。

##### **Post-hoc and manifold explanations analysis of facial expression data based on deep learning**
2404.18352v1 by Yang Xiao

The complex information processing system of humans generates a lot of
objective and subjective evaluations, making the exploration of human cognitive
products of great cutting-edge theoretical value. In recent years, deep
learning technologies, which are inspired by biological brain mechanisms, have
made significant strides in the application of psychological or cognitive
scientific research, particularly in the memorization and recognition of facial
data. This paper investigates through experimental research how neural networks
process and store facial expression data and associate these data with a range
of psychological attributes produced by humans. Researchers utilized deep
learning model VGG16, demonstrating that neural networks can learn and
reproduce key features of facial data, thereby storing image memories.
Moreover, the experimental results reveal the potential of deep learning models
in understanding human emotions and cognitive processes and establish a
manifold visualization interpretation of cognitive products or psychological
attributes from a non-Euclidean space perspective, offering new insights into
enhancing the explainability of AI. This study not only advances the
application of AI technology in the field of psychology but also provides a new
psychological theoretical understanding the information processing of the AI.
The code is available in here: https://github.com/NKUShaw/Psychoinformatics.

摘要：人類複雜的資訊處理系統會產生許多客觀與主觀的評估，使得探討人類認知產物具有極大的前沿理論價值。近年來，受生物大腦機制啟發的深度學習技術，在心理學或認知科學研究的應用上已獲得長足的進展，特別是在臉部資料的記憶與辨識上。本文透過實驗研究探討神經網路如何處理與儲存臉部表情資料，並將這些資料與人類產生的各種心理屬性做連結。研究者利用深度學習模型 VGG16，驗證神經網路可以學習並重現臉部資料的關鍵特徵，進而儲存影像記憶。此外，實驗結果揭示深度學習模型在理解人類情緒與認知歷程的潛力，並從非歐幾里得空間的觀點建立認知產物或心理屬性的流形視覺化詮釋，為提升 AI 的可解釋性提供了新的見解。本研究不僅推進了 AI 技術在心理學領域的應用，也為 AI 的資訊處理提供了新的心理學理論理解。程式碼可於此處取得：https://github.com/NKUShaw/Psychoinformatics。

##### **Multi-stage Attack Detection and Prediction Using Graph Neural Networks: An IoT Feasibility Study**
2404.18328v1 by Hamdi Friji,Ioannis Mavromatis,Adrian Sanchez-Mompo,Pietro Carnelli,Alexis Olivereau,Aftab Khan

With the ever-increasing reliance on digital networks for various aspects of
modern life, ensuring their security has become a critical challenge. Intrusion
Detection Systems play a crucial role in ensuring network security, actively
identifying and mitigating malicious behaviours. However, the relentless
advancement of cyber-threats has rendered traditional/classical approaches
insufficient in addressing the sophistication and complexity of attacks. This
paper proposes a novel 3-stage intrusion detection system inspired by a
simplified version of the Lockheed Martin cyber kill chain to detect advanced
multi-step attacks. The proposed approach consists of three models, each
responsible for detecting a group of attacks with common characteristics. The
detection outcome of the first two stages is used to conduct a feasibility
study on the possibility of predicting attacks in the third stage. Using the
ToN IoT dataset, we achieved an average of 94% F1-Score among different stages,
outperforming the benchmark approaches based on Random-forest model. Finally,
we comment on the feasibility of this approach to be integrated in a real-world
system and propose various possible future work.

摘要：隨著現代生活中各方面對數位網路的依賴與日俱增，確保其安全已成為一項嚴峻的挑戰。入侵偵測系統在確保網路安全方面扮演著至關重要的角色，主動識別和減輕惡意行為。然而，網路威脅的不斷進步，使得傳統/經典方法無法應對攻擊的複雜性和精緻性。本文提出了一個新穎的三階段入侵偵測系統，其靈感來自洛克希德·馬丁網路殺戮鏈的簡化版本，用於偵測進階的多步驟攻擊。所提出的方法包含三個模型，每個模型負責偵測一組具有共同特徵的攻擊。前兩個階段的偵測結果用於對第三階段中預測攻擊的可能性進行可行性研究。使用 ToN IoT 資料集，我們在不同階段達到了平均 94% 的 F1 分數，優於基於隨機森林模型的基準方法。最後，我們評論了這種方法整合到真實世界系統中的可行性，並提出了各種可能的未來工作。

##### **SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies**
2404.18326v1 by Amir Samadi,Konstantinos Koufos,Kurt Debattista,Mehrdad Dianati

While Deep Reinforcement Learning (DRL) has emerged as a promising solution
for intricate control tasks, the lack of explainability of the learned policies
impedes its uptake in safety-critical applications, such as automated driving
systems (ADS). Counterfactual (CF) explanations have recently gained prominence
for their ability to interpret black-box Deep Learning (DL) models. CF examples
are associated with minimal changes in the input, resulting in a complementary
output by the DL model. Finding such alternations, particularly for
high-dimensional visual inputs, poses significant challenges. Besides, the
temporal dependency introduced by the reliance of the DRL agent action on a
history of past state observations further complicates the generation of CF
examples. To address these challenges, we propose using a saliency map to
identify the most influential input pixels across the sequence of past observed
states by the agent. Then, we feed this map to a deep generative model,
enabling the generation of plausible CFs with constrained modifications centred
on the salient regions. We evaluate the effectiveness of our framework in
diverse domains, including ADS, Atari Pong, Pacman and space-invaders games,
using traditional performance metrics such as validity, proximity and sparsity.
Experimental results demonstrate that this framework generates more informative
and plausible CFs than the state-of-the-art for a wide range of environments
and DRL agents. In order to foster research in this area, we have made our
datasets and codes publicly available at
https://github.com/Amir-Samadi/SAFE-RL.

摘要：儘管深度強化學習 (DRL) 已成為複雜控制任務的一項有前途的解決方案，但所學政策缺乏可解釋性阻礙了其在安全關鍵應用程式中的採用，例如自動駕駛系統 (ADS)。反事實 (CF) 解釋最近因其解釋黑箱深度學習 (DL) 模型的能力而備受重視。CF 範例與輸入中的最小變更相關聯，從而導致 DL 模型產生互補的輸出。尋找此類交替，特別是對於高維度視覺輸入，構成了重大挑戰。此外，DRL 代理動作依賴於過去狀態觀察的歷史所產生的時間依賴性進一步複雜化了 CF 範例的產生。為了應對這些挑戰，我們建議使用顯著性圖來識別代理在過去觀察到的狀態序列中影響力最大的輸入像素。然後，我們將此映射提供給深度生成模型，從而能夠生成以顯著區域為中心的受約束修改的合理 CF。我們使用傳統的效能指標（例如有效性、接近性和稀疏性）評估了我們架構在不同領域（包括 ADS、Atari Pong、Pacman 和太空侵略者遊戲）中的有效性。實驗結果表明，對於廣泛的環境和 DRL 代理，此架構產生的 CF 比最先進的技術更具資訊性和合理性。為了促進這方面的研究，我們已將我們的資料集和程式碼公開在 https://github.com/Amir-Samadi/SAFE-RL。

##### **Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review**
2404.18311v1 by Mladjan Jovanovic,Peter Voss

Real-time learning concerns the ability of learning systems to acquire
knowledge over time, enabling their adaptation and generalization to novel
tasks. It is a critical ability for intelligent, real-world systems, especially
when data may be insufficient or difficult to obtain. This review provides a
comprehensive analysis of real-time learning in Large Language Models. It
synthesizes the state-of-the-art real-time learning paradigms, including
continual learning, meta-learning, parameter-efficient learning, and
mixture-of-experts learning. We demonstrate their utility for real-time
learning by describing specific achievements from these related topics and
their critical factors. Finally, the paper highlights current problems and
challenges for future research in the field. By consolidating the latest
relevant research developments, this review offers a comprehensive
understanding of real-time learning and its implications for designing and
developing LLM-based learning systems addressing real-world problems.

摘要：實時學習關注學習系統隨著時間推移獲取知識的能力，使其能夠適應和概括到新任務。它是智慧型、真實世界系統的一項關鍵能力，尤其是在資料可能不足或難以取得時。本篇評論對大型語言模型中的實時學習提供了全面的分析。它綜合了最先進的實時學習範例，包括持續學習、元學習、參數有效學習和專家混合學習。我們透過描述這些相關主題的具體成就及其關鍵因素，展示了它們在實時學習中的效用。最後，本文重點介紹了該領域未來研究的當前問題和挑戰。透過整合最新的相關研究進展，本篇評論提供了對實時學習及其對設計和開發解決真實世界問題的 LLM 基礎學習系統的影響的全面理解。

##### **Retrieval-Oriented Knowledge for Click-Through Rate Prediction**
2404.18304v1 by Huanshuo Liu,Bo Chen,Menghui Zhu,Jianghao Lin,Jiarui Qin,Yang Yang,Hao Zhang,Ruiming Tang

Click-through rate (CTR) prediction plays an important role in personalized
recommendations. Recently, sample-level retrieval-based models (e.g., RIM) have
achieved remarkable performance by retrieving and aggregating relevant samples.
However, their inefficiency at the inference stage makes them impractical for
industrial applications. To overcome this issue, this paper proposes a
universal plug-and-play Retrieval-Oriented Knowledge (ROK) framework.
Specifically, a knowledge base, consisting of a retrieval-oriented embedding
layer and a knowledge encoder, is designed to preserve and imitate the
retrieved & aggregated representations in a decomposition-reconstruction
paradigm. Knowledge distillation and contrastive learning methods are utilized
to optimize the knowledge base, and the learned retrieval-enhanced
representations can be integrated with arbitrary CTR models in both
instance-wise and feature-wise manners. Extensive experiments on three
large-scale datasets show that ROK achieves competitive performance with the
retrieval-based CTR models while reserving superior inference efficiency and
model compatibility.

摘要：點擊率 (CTR) 預測在個人化推薦中扮演著重要的角色。最近，基於樣本層級檢索的模型 (例如 RIM) 透過檢索和彙總相關樣本，達到了顯著的效能。然而，它們在推論階段的低效率讓它們不切實際地應用於產業應用中。為了克服這個問題，本文提出了一個通用的即插即用檢索導向知識 (ROK) 架構。具體來說，一個知識庫，包含一個檢索導向的嵌入層和一個知識編碼器，被設計用來在分解重建範例中保存和模仿檢索和彙總的表示。知識萃取和對比學習方法被用來最佳化知識庫，而學習到的檢索增強表示可以與任意的 CTR 模型整合，無論是基於實例還是基於特徵的方式。在三個大型資料集上的廣泛實驗顯示，ROK 達到了與基於檢索的 CTR 模型相當的效能，同時保留了優越的推論效率和模型相容性。

##### **Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms**
2404.18296v1 by Zoi Lygizou,Dimitris Kalles

Recent work on decentralized computational trust models for open Multi Agent
Systems has resulted in the development of CA, a biologically inspired model
which focuses on the trustee's perspective. This new model addresses a serious
unresolved problem in existing trust and reputation models, namely the
inability to handle constantly changing behaviors and agents' continuous entry
and exit from the system. In previous work, we compared CA to FIRE, a
well-known trust and reputation model, and found that CA is superior when the
trustor population changes, whereas FIRE is more resilient to the trustee
population changes. Thus, in this paper, we investigate how the trustors can
detect the presence of several dynamic factors in their environment and then
decide which trust model to employ in order to maximize utility. We frame this
problem as a machine learning problem in a partially observable environment,
where the presence of several dynamic factors is not known to the trustor and
we describe how an adaptable trustor can rely on a few measurable features so
as to assess the current state of the environment and then use Deep Q Learning
(DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt
to a changing environment. We ran a series of simulation experiments to compare
the performance of the adaptable trustor with the performance of trustors using
only one model (FIRE or CA) and we show that an adaptable agent is indeed
capable of learning when to use each model and, thus, perform consistently in
dynamic environments.

摘要：<paragraph>最近在開放式多代理系統的去中心化計算信任模型上的研究，導致了 CA 的發展，這是一個以受託人的觀點為中心的生物靈感模型。這個新模型解決了現有信任和聲譽模型中一個嚴重的未解決問題，即無法處理不斷變化的行為以及代理人持續進入和退出系統。在先前的研究中，我們將 CA 與 FIRE（一個著名的信任和聲譽模型）進行比較，發現當信任者群體發生變化時，CA 較為優越，而 FIRE 對受託人群體的變化具有較強的韌性。因此，在本文中，我們探討了信任者如何偵測其環境中幾個動態因素的存在，然後決定採用哪個信任模型以最大化效用。我們將此問題構建為部分可觀察環境中的機器學習問題，其中信任者不知道幾個動態因素的存在，並且我們描述了一個適應性信任者如何依賴幾個可測量特徵，以評估環境的當前狀態，然後在單一代理強化學習設定中使用深度 Q 學習 (DQN) 來學習如何適應不斷變化的環境。我們進行了一系列模擬實驗，以比較適應性信任者的效能與僅使用一個模型 (FIRE 或 CA) 的信任者的效能，並且我們表明一個適應性代理確實有能力學習何時使用每個模型，因此，在動態環境中持續執行。</paragraph>

##### **Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages**
2404.18286v1 by David Ifeoluwa Adelani,A. Seza Doğruöz,André Coneglian,Atul Kr. Ojha

Large Language Models are transforming NLP for a variety of tasks. However,
how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.
In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from
Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English
and Brazilian Portuguese). Our results indicate that the LLMs perform worse for
the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the
reasons behind this failure and provide an error analyses through examples
observed in our data set.

摘要：大型語言模型正在為各種任務轉換 NLP。然而，LLM 如何執行低資源語言 (LRL) 的 NLP 任務則較少探討。根據美洲 NLP 工作坊的目標，我們專注於來自巴西的 12 個 LRL、來自非洲的 2 個 LRL 和 2 個高資源語言 (HRL)（例如英語和巴西葡萄牙語）。我們的結果表明，與 HRL 相比，LLM 對 LRL 的詞性標記執行得更差。我們解釋了這種失敗背後的原因，並通過在我們的數據集中觀察到的示例提供錯誤分析。

##### **Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)**
2404.18276v1 by Malur Narayan,John Pasmore,Elton Sampaio,Vijay Raghavan,Gabriella Waters

The burgeoning influence of Large Language Models (LLMs) in shaping public
discourse and decision-making underscores the imperative to address inherent
biases within these AI systems. In the wake of AI's expansive integration
across sectors, addressing racial bias in LLMs has never been more critical.
This paper introduces a novel framework called Comprehensive Bias
Neutralization Framework (CBNF) which embodies an innovative approach to
quantifying and mitigating biases within LLMs. Our framework combines the Large
Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)]
and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)]
methodologies to create a new metric called Bias Intelligence Quotient
(BiQ)which detects, measures, and mitigates racial bias in LLMs without
reliance on demographic annotations.
  By introducing a new metric called BiQ that enhances LLMBI with additional
fairness metrics, CBNF offers a multi-dimensional metric for bias assessment,
underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et
al., 2021]. This paper presents a detailed analysis of Latimer AI (a language
model incrementally trained on black history and culture) in comparison to
ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural,
and gender biases through targeted training and refined bias mitigation
strategies [Latimer & Bender, 2023].

摘要：大型語言模型 (LLM) 在塑造公眾話語和決策制定方面影響力日益增長，這凸顯了解決這些 AI 系統中固有偏差的必要性。隨著 AI 在各個領域的廣泛整合，解決 LLM 中的種族偏見比以往任何時候都更加關鍵。本文介紹了一個名為全面偏差中和框架 (CBNF) 的新框架，它體現了量化和減輕 LLM 中偏差的創新方法。我們的框架結合了大型語言模型偏差指數 (LLMBI) [Oketunji, A.，Anas, M.，Saina, D.，(2023)] 和無人口統計偏差移除 (BLIND) [Orgad, H.，Belinkov, Y. (2023)] 方法來創建一個名為偏差智商 (BiQ) 的新指標，它可以在不依賴人口統計註釋的情況下檢測、衡量和減輕 LLM 中的種族偏見。
通過引入一個名為 BiQ 的新指標，該指標使用額外的公平性指標增強了 LLMBI，CBNF 提供了一個多維度的偏差評估指標，強調了 AI 中公平性細緻入微的方法的必要性 [Mehrabi 等，2021]。本文詳細分析了 Latimer AI（一個針對黑人歷史和文化進行增量訓練的語言模型）與 ChatGPT 3.5 的比較，說明了 Latimer AI 通過有針對性的訓練和改進的偏差緩解策略在檢測種族、文化和性別偏差方面的功效 [Latimer & Bender，2023]。

##### **Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**
2404.18271v1 by Qi Zhu,Da Zheng,Xiang Song,Shichang Zhang,Bowen Jin,Yizhou Sun,George Karypis

Text-rich graphs, which exhibit rich textual information on nodes and edges,
are prevalent across a wide range of real-world business applications. Large
Language Models (LLMs) have demonstrated remarkable abilities in understanding
text, which also introduced the potential for more expressive modeling in
text-rich graphs. Despite these capabilities, efficiently applying LLMs to
representation learning on graphs presents significant challenges. Recently,
parameter-efficient fine-tuning methods for LLMs have enabled efficient new
task generalization with minimal time and memory consumption. Inspired by this,
we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
approach for efficient graph representation learning with LLMs on text-rich
graphs. Specifically, we utilize a graph neural network (GNN) to encode
structural information from neighboring nodes into a graph prompt. This prompt
is then inserted at the beginning of the text sequence. To improve the quality
of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
the next token in the node text. Compared with existing joint GNN and LMs, our
method directly generate the node embeddings from large language models with an
affordable fine-tuning cost. We validate our approach through comprehensive
experiments conducted on 8 different text-rich graphs, observing an average
improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
evaluations. Our results demonstrate the efficacy and efficiency of our model,
showing that it can be smoothly integrated with various large language models,
including OPT, LLaMA and Falcon.

摘要：<paragraph>文本豐富的圖形，在節點和邊緣上展現豐富的文本資訊，
在廣泛的實際商業應用中很普遍。大型語言模型 (LLM) 已展現出在理解
文字方面的卓越能力，這也引入了在文本豐富的圖形中進行更具表現力的建模的可能性。儘管有這些能力，有效地將 LLM 應用於圖形上的表徵學習仍存在重大挑戰。最近，LLM 的參數有效微調方法已實現了有效的新任務概化，且時間和記憶體消耗最少。受到此啟發，我們引入了圖形感知參數有效微調 - GPEFT，一種在文本豐富的圖形上使用 LLM 進行有效圖形表徵學習的新穎方法。具體來說，我們利用圖形神經網路 (GNN) 將來自鄰近節點的結構資訊編碼到圖形提示中。然後將此提示插入文字序列的開頭。為了提升圖形提示的品質，我們預先訓練 GNN 以協助凍結的 LLM 預測節點文字中的下一個符號。與現有的聯合 GNN 和 LM 相比，我們的模型直接從大型語言模型產生節點嵌入，且微調成本合理。我們透過在 8 個不同的文本豐富圖形上進行的全面實驗驗證了我們的做法，觀察到連結預測評估中 hit@1 和平均倒數排名 (MRR) 平均提升了 2%。我們的結果證明了我們模型的有效性和效率，顯示它可以順利整合到各種大型語言模型中，包括 OPT、LLaMA 和 Falcon。</paragraph>

##### **Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design**
2404.18270v1 by Aman Kumar

Error Detection and Correction Codes (ECCs) are often used in digital designs
to protect data integrity. Especially in safety-critical systems such as
automotive electronics, ECCs are widely used and the verification of such
complex logic becomes more critical considering the ISO 26262 safety standards.
Exhaustive verification of ECC using formal methods has been a challenge given
the high number of data bits to protect. As an example, for an ECC of 128 data
bits with a possibility to detect up to four-bit errors, the combination of bit
errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7. This vast
analysis space often leads to bounded proof results. Moreover, the complexity
and state-space increase further if the ECC has sequential encoding and
decoding stages. To overcome such problems and sign-off the design with
confidence within reasonable proof time, we present a pragmatic formal
verification approach of complex ECC cores with several complexity reduction
techniques and know-how that were learnt during the course of verification. We
discuss using the linearity of the syndrome generator as a helper assertion,
using the abstract model as glue logic to compare the RTL with the sequential
version of the circuit, k-induction-based model checking and using mathematical
relations captured as properties to simplify the verification in order to get
an unbounded proof result within 24 hours of proof runtime.

摘要：<paragraph>錯誤偵測與修正碼 (ECC) 常用於數位設計中，以保護資料完整性。特別是在安全關鍵系統（例如汽車電子設備）中，ECC 廣泛用於驗證此類複雜邏輯，而考量 ISO 26262 安全標準時，這種驗證變得更為關鍵。使用形式化方法對 ECC 進行詳盡驗證一直是一項挑戰，因為需要保護大量的資料位元。舉例來說，對於一個具有偵測最多四位元錯誤的 128 個資料位元的 ECC，位元錯誤的組合由 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7 給出。這個龐大的分析空間通常會導致有界證明結果。此外，如果 ECC 具有順序編碼和解碼階段，複雜度和狀態空間會進一步增加。為了克服這些問題並在合理的證明時間內自信地簽核設計，我們提出了一個實用的形式化驗證方法，其中包含了數個複雜度降低技術和驗證過程中學到的知識。我們討論使用症候群產生器的線性作為輔助斷言，使用抽象模型作為膠水邏輯來比較 RTL 與電路的順序版本，基於 k 感應的模型檢查，以及使用作為屬性的數學關係來簡化驗證，以便在 24 小時的證明執行時間內取得無界的證明結果。</paragraph>

##### **Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin**
2404.18264v1 by Pin-Jie Lin,Merel Scholman,Muhammed Saeed,Vera Demberg

Nigerian Pidgin is an English-derived contact language and is traditionally
an oral language, spoken by approximately 100 million people. No orthographic
standard has yet been adopted, and thus the few available Pidgin datasets that
exist are characterised by noise in the form of orthographic variations. This
contributes to under-performance of models in critical NLP tasks. The current
work is the first to describe various types of orthographic variations commonly
found in Nigerian Pidgin texts, and model this orthographic variation. The
variations identified in the dataset form the basis of a phonetic-theoretic
framework for word editing, which is used to generate orthographic variations
to augment training data. We test the effect of this data augmentation on two
critical NLP tasks: machine translation and sentiment analysis. The proposed
variation generation framework augments the training data with new orthographic
variants which are relevant for the test set but did not occur in the training
set originally. Our results demonstrate the positive effect of augmenting the
training data with a combination of real texts from other corpora as well as
synthesized orthographic variation, resulting in performance improvements of
2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.

摘要：尼日利亞皮欽語是一種源自英語的接觸語言，傳統上是一種口語，約有 1 億人使用。目前尚未採用拼字標準，因此現有的少數皮欽語資料集特點是正字法變異形式的雜訊。這會導致模型在重要的 NLP 任務中表現不佳。目前的工作首次描述了尼日利亞皮欽語文本中常見的各種正字法變異，並對此正字法變異進行建模。資料集中識別出的變異構成了一個用於文字編輯的音位理論框架的基礎，該框架用於產生正字法變異以擴充訓練資料。我們在兩個重要的 NLP 任務中測試了這種資料擴充的效果：機器翻譯和情緒分析。所提出的變異產生框架使用與測試集相關但最初未出現在訓練集中的新正字法變異來擴充訓練資料。我們的結果證明了使用來自其他語料庫的真實文本以及合成正字法變異的組合來擴充訓練資料的正面效果，從而使情緒分析的效能提升了 2.1 個百分點，翻譯成英語的 BLEU 得分提高了 1.4 個百分點。

##### **Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning**
2404.18262v1 by Atharva Naik,Jessica Ruhan Yin,Anusha Kamath,Qianou Ma,Sherry Tongshuang Wu,Charles Murray,Christopher Bogart,Majd Sakr,Carolyn P. Rose

An advantage of Large Language Models (LLMs) is their contextualization
capability - providing different responses based on student inputs like
solution strategy or prior discussion, to potentially better engage students
than standard feedback. We present a design and evaluation of a
proof-of-concept LLM application to offer students dynamic and contextualized
feedback. Specifically, we augment an Online Programming Exercise bot for a
college-level Cloud Computing course with ChatGPT, which offers students
contextualized reflection triggers during a collaborative query optimization
task in database design. We demonstrate that LLMs can be used to generate
highly situated reflection triggers that incorporate details of the
collaborative discussion happening in context. We discuss in depth the
exploration of the design space of the triggers and their correspondence with
the learning objectives as well as the impact on student learning in a pilot
study with 34 students.

摘要：大型語言模型 (LLM) 的優點在於其脈絡化能力，根據學生的輸入（如解決策略或先前的討論）提供不同的回應，以潛在的方式讓學生比標準回饋更投入。我們提出一個概念驗證 LLM 應用的設計和評估，以向學生提供動態且脈絡化的回饋。具體來說，我們為大學等級的雲端運算課程擴充一個線上程式練習機器人，使用 ChatGPT，在資料庫設計的協作式查詢最佳化任務中為學生提供脈絡化的反思觸發器。我們證明 LLM 可用於產生高度情境化的反思觸發器，其中包含在脈絡中發生的協作討論的詳細資訊。我們深入探討觸發器的設計空間探索及其與學習目標的對應關係，以及在有 34 名學生的試驗研究中對學生學習的影響。

##### **Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology**
2404.18257v1 by Nilo Pedrazzini

Languages can encode temporal subordination lexically, via subordinating
conjunctions, and morphologically, by marking the relation on the predicate.
Systematic cross-linguistic variation among the former can be studied using
well-established token-based typological approaches to token-aligned parallel
corpora. Variation among different morphological means is instead much harder
to tackle and therefore more poorly understood, despite being predominant in
several language groups. This paper explores variation in the expression of
generic temporal subordination ('when'-clauses) among the languages of Latin
America and the Caribbean, where morphological marking is particularly common.
It presents probabilistic semantic maps computed on the basis of the languages
of the region, thus avoiding bias towards the many world's languages that
exclusively use lexified connectors, incorporating associations between
character $n$-grams and English $when$. The approach allows capturing
morphological clause-linkage devices in addition to lexified connectors, paving
the way for larger-scale, strategy-agnostic analyses of typological variation
in temporal subordination.

摘要：语言可以通过从属连词在词汇上编码时间从属，并通过在谓词上标记关系在形态上进行编码。前者的系统性跨语言变异可以通过使用基于标记的对齐平行语料库的完善的基于标记的类型学方法来研究。尽管在几个语言组中占主导地位，但不同形态手段之间的变异却更难解决，因此了解得更少。本文探讨了拉丁美洲和加勒比地区的语言中通用时间从属（“when”从句）表达方式的变异，其中形态标记尤为常见。它展示了基于该地区语言计算出的概率语义图，从而避免了对仅使用词化连接器的世界上许多语言的偏见，并结合了字符 n-gram 和英语 when 之间的关联。该方法除了词化连接器之外，还可以捕获形态句法链接设备，为更大规模、与策略无关的时间从属类型学变异分析铺平了道路。

##### **PatentGPT: A Large Language Model for Intellectual Property**
2404.18255v1 by Zilong Bai,Ruiji Zhang,Linqing Chen,Qijun Cai,Yuan Zhong,Cong Wang Yan Fang,Jie Fang,Jing Sun,Weikuan Wang,Lizhi Zhou,Haoran Hua Tian Qiu,Chaochao Wang,Cheng Sun,Jianping Lu,Yixin Wang,Yubin Xia Meng Hu,Haowen Liu,Peng Xu,Licong Xu,Fu Bian,Xiaolong Gu,Lisha Zhang Weilei Wang,Changyang Tu

In recent years, large language models have attracted significant attention
due to their exceptional performance across a multitude of natural language
process tasks, and have been widely applied in various fields. However, the
application of large language models in the Intellectual Property (IP) space is
challenging due to the strong need for specialized knowledge, privacy
protection, processing of extremely long text in this field. In this technical
report, we present for the first time a low-cost, standardized procedure for
training IP-oriented LLMs, meeting the unique requirements of the IP domain.
Using this standard process, we have trained the PatentGPT series models based
on open-source pretrained models. By evaluating them on the open-source
IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms GPT-4,
indicating the effectiveness of the proposed training procedure and the
expertise of the PatentGPT models in the IP demain. What is impressive is that
our model significantly outperformed GPT-4 on the 2019 China Patent Agent
Qualification Examination by achieving a score of 65, reaching the level of
human experts. Additionally, the PatentGPT model, which utilizes the SMoE
architecture, achieves performance comparable to that of GPT-4 in the IP domain
and demonstrates a better cost-performance ratio on long-text tasks,
potentially serving as an alternative to GPT-4 within the IP domain.

摘要：近年來，大型語言模型因其在多種自然語言處理任務中的卓越表現而備受關注，並已廣泛應用於各個領域。然而，由於在知識產權（IP）領域中對專業知識、隱私保護、處理極長文本的強烈需求，大型語言模型在知識產權領域的應用面臨挑戰。在本技術報告中，我們首次提出了一種低成本、標準化的知識產權導向 LLM 訓練程序，以滿足知識產權領域的獨特需求。使用此標準流程，我們根據開源預訓練模型訓練了 PatentGPT 系列模型。通過在開源知識產權導向基準 MOZIP 上對它們進行評估，我們的特定領域 LLM 優於 GPT-4，表明所提出的訓練程序的有效性以及 PatentGPT 模型在知識產權領域的專業知識。令人印象深刻的是，我們的模型在 2019 年中國專利代理人資格考試中以 65 分的成績顯著優於 GPT-4，達到人類專家的水平。此外，採用 SMoE 架構的 PatentGPT 模型在知識產權領域實現了與 GPT-4 相當的性能，並在長文本任務中展示出更好的成本效益比，有可能在知識產權領域內作為 GPT-4 的替代方案。

##### **LEGENT: Open Platform for Embodied Agents**
2404.18243v1 by Zhili Cheng,Zhitong Wang,Jinyi Hu,Shengding Hu,An Liu,Yuge Tu,Pengkai Li,Lei Shi,Zhiyuan Liu,Maosong Sun

Despite advancements in Large Language Models (LLMs) and Large Multimodal
Models (LMMs), their integration into language-grounded, human-like embodied
agents remains incomplete, hindering complex real-life task performance in
physical environments. Existing integrations often feature limited open
sourcing, challenging collective progress in this field. We introduce LEGENT,
an open, scalable platform for developing embodied agents using LLMs and LMMs.
LEGENT offers a dual approach: a rich, interactive 3D environment with
communicable and actionable agents, paired with a user-friendly interface, and
a sophisticated data generation pipeline utilizing advanced algorithms to
exploit supervision from simulated worlds at scale. In our experiments, an
embryonic vision-language-action model trained on LEGENT-generated data
surpasses GPT-4V in embodied tasks, showcasing promising generalization
capabilities.

摘要：儘管大型語言模型 (LLM) 和大型多模態模型 (LMM) 有所進展，但它們整合到以語言為基礎、類似人類的具身代理人中仍不完整，這阻礙了在物理環境中執行複雜的現實任務。現有的整合通常具有有限的開放原始碼，對這個領域的集體進展構成挑戰。我們介紹 LEGENT，這是一個使用 LLM 和 LMM 開發具身代理人的開放、可擴充平台。LEGENT 提供雙重方法：一個豐富、互動的 3D 環境，其中包含可溝通和可操作的代理人，並配備使用者友善的介面，以及一個使用進階演算法來利用規模化模擬世界的監督的精密資料產生管道。在我們的實驗中，一個訓練於 LEGENT 產生的資料的胚胎視覺語言動作模型在具身任務中超越了 GPT-4V，展示了有希望的概化能力。

##### **SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning**
2404.18239v1 by Jinghan Jia,Yihua Zhang,Yimeng Zhang,Jiancheng Liu,Bharat Runwal,James Diffenderfer,Bhavya Kailkhura,Sijia Liu

Large Language Models (LLMs) have highlighted the necessity of effective
unlearning mechanisms to comply with data regulations and ethical AI practices.
LLM unlearning aims at removing undesired data influences and associated model
capabilities without compromising utility out of the scope of unlearning. While
interest in studying LLM unlearning is growing,the impact of the optimizer
choice for LLM unlearning remains under-explored. In this work, we shed light
on the significance of optimizer selection in LLM unlearning for the first
time, establishing a clear connection between {second-order optimization} and
influence unlearning (a classical approach using influence functions to update
the model for data influence removal). This insight propels us to develop a
second-order unlearning framework, termed SOUL, built upon the second-order
clipped stochastic optimization (Sophia)-based LLM training method. SOUL
extends the static, one-shot model update using influence unlearning to a
dynamic, iterative unlearning process. Our extensive experiments show that SOUL
consistently outperforms conventional first-order methods across various
unlearning tasks, models, and metrics, suggesting the promise of second-order
optimization in providing a scalable and easily implementable solution for LLM
unlearning.

摘要：大型語言模型 (LLM) 強調了有效遺忘機制以符合資料法規和道德 AI 實務的必要性。LLM 遺忘旨在移除不想要的資料影響和相關模型功能，而不會損害遺忘範圍外的效用。雖然研究 LLM 遺忘的興趣與日俱增，但最佳化器選擇對 LLM 遺忘的影響仍未充分探討。在這項工作中，我們首次闡明了最佳化器選擇在 LLM 遺忘中的重要性，建立了 {二階最佳化} 與影響遺忘（一種使用影響函數更新模型以移除資料影響的經典方法）之間的明確關聯。這個見解促使我們開發一個二階遺忘架構，稱為 SOUL，建立在二階裁切隨機最佳化（Sophia）為基礎的 LLM 訓練方法上。SOUL 將使用影響遺忘的靜態、一次性模型更新延伸至動態、反覆的遺忘程序。我們廣泛的實驗顯示，SOUL 在各種遺忘任務、模型和指標中始終優於傳統的一階方法，這表明二階最佳化有望提供可擴充、易於實作的 LLM 遺忘解決方案。

##### **From Persona to Personalization: A Survey on Role-Playing Language Agents**
2404.18231v1 by Jiangjie Chen,Xintao Wang,Rui Xu,Siyu Yuan,Yikai Zhang,Wei Shi,Jian Xie,Shuang Li,Ruihan Yang,Tinghui Zhu,Aili Chen,Nianqi Li,Lida Chen,Caiyu Hu,Siye Wu,Scott Ren,Ziquan Fu,Yanghua Xiao

Recent advancements in large language models (LLMs) have significantly
boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI
systems designed to simulate assigned personas. By harnessing multiple advanced
abilities of LLMs, including in-context learning, instruction following, and
social intelligence, RPLAs achieve a remarkable sense of human likeness and
vivid role-playing performance. RPLAs can mimic a wide range of personas,
ranging from historical figures and fictional characters to real-life
individuals. Consequently, they have catalyzed numerous AI applications, such
as emotional companions, interactive video games, personalized assistants and
copilots, and digital clones. In this paper, we conduct a comprehensive survey
of this field, illustrating the evolution and recent progress in RPLAs
integrating with cutting-edge LLM technologies. We categorize personas into
three types: 1) Demographic Persona, which leverages statistical stereotypes;
2) Character Persona, focused on well-established figures; and 3)
Individualized Persona, customized through ongoing user interactions for
personalized services. We begin by presenting a comprehensive overview of
current methodologies for RPLAs, followed by the details for each persona type,
covering corresponding data sourcing, agent construction, and evaluation.
Afterward, we discuss the fundamental risks, existing limitations, and future
prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI
applications, which reflects practical user demands that shape and drive RPLA
research. Through this work, we aim to establish a clear taxonomy of RPLA
research and applications, and facilitate future research in this critical and
ever-evolving field, and pave the way for a future where humans and RPLAs
coexist in harmony.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展顯著地提升了角色扮演語言代理 (RPLA) 的興起，也就是專門設計來模擬指定角色的 AI 系統。透過運用 LLM 的多項進階能力，包括情境學習、指令遵循和社交智慧，RPLA 達到了人類相似性和生動角色扮演表演的顯著表現。RPLA 可以模擬廣泛的角色，從歷史人物和虛構角色到現實生活中的個人。因此，它們催化了許多 AI 應用程式，例如情感伴侶、互動式電玩遊戲、個人化助理和副駕駛，以及數位分身。在本文中，我們對此領域進行了全面的調查，說明了 RPLA 與尖端的 LLM 技術整合的演進和最新進展。我們將角色分為三種類型：1) 人口統計角色，利用統計刻板印象；2) 角色角色，專注於知名人物；3) 個人化角色，透過持續的使用者互動進行客製化，以提供個人化服務。我們首先對 RPLA 的現有方法進行全面的概述，接著說明每種類型的角色，涵蓋對應的資料採集、代理建構和評估。之後，我們討論了 RPLA 的基本風險、現有限制和未來前景。此外，我們簡要回顧了 RPLA 在 AI 應用程式中的應用，這反映了形塑和推動 RPLA 研究的實際使用者需求。透過這項工作，我們旨在建立 RPLA 研究和應用程式的明確分類法，並促進這個關鍵且不斷演進領域的未來研究，為人類和 RPLA 和諧共存的未來鋪路。</paragraph>

##### **TextGram: Towards a better domain-adaptive pretraining**
2404.18228v1 by Sharayu Hiwarkhedkar,Saloni Mittal,Vidula Magdum,Omkar Dhekane,Raviraj Joshi,Geetanjali Kale,Arnav Ladkat

For green AI, it is crucial to measure and reduce the carbon footprint
emitted during the training of large language models. In NLP, performing
pre-training on Transformer models requires significant computational
resources. This pre-training involves using a large amount of text data to gain
prior knowledge for performing downstream tasks. Thus, it is important that we
select the correct data in the form of domain-specific data from this vast
corpus to achieve optimum results aligned with our domain-specific tasks. While
training on large unsupervised data is expensive, it can be optimized by
performing a data selection step before pretraining. Selecting important data
reduces the space overhead and the substantial amount of time required to
pre-train the model while maintaining constant accuracy. We investigate the
existing selection strategies and propose our own domain-adaptive data
selection method - TextGram - that effectively selects essential data from
large corpora. We compare and evaluate the results of finetuned models for text
classification task with and without data selection. We show that the proposed
strategy works better compared to other selection methods.

摘要：對於綠色 AI 而言，在訓練大型語言模型期間量測和減少碳足跡至關重要。在 NLP 中，在 Transformer 模型上執行預訓練需要大量的運算資源。此預訓練涉及使用大量的文字資料來獲得執行下游任務的先驗知識。因此，我們從這個龐大的語料庫中選擇正確的資料，以特定領域的資料形式，對於達成與我們特定領域任務相符的最佳結果至關重要。雖然在大量非監督式資料上進行訓練很昂貴，但可以在預訓練前執行資料選取步驟來最佳化。選取重要的資料可以減少空間開銷和預訓練模型所需的大量時間，同時維持穩定的準確度。我們研究現有的選取策略，並提出我們自己的領域適應式資料選取方法 - TextGram - 可以有效地從大型語料庫中選取必要的資料。我們比較和評估微調模型在有和沒有資料選取的文字分類任務中的結果。我們表明，與其他選取方法相比，所提出的策略有更好的效果。

##### **L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi**
2404.18216v1 by Saloni Mittal,Vidula Magdum,Omkar Dhekane,Sharayu Hiwarkhedkar,Raviraj Joshi

The availability of text or topic classification datasets in the low-resource
Marathi language is limited, typically consisting of fewer than 4 target
labels, with some achieving nearly perfect accuracy. In this work, we introduce
L3Cube-MahaNews, a Marathi text classification corpus that focuses on News
headlines and articles. This corpus stands out as the largest supervised
Marathi Corpus, containing over 1.05L records classified into a diverse range
of 12 categories. To accommodate different document lengths, MahaNews comprises
three supervised datasets specifically designed for short text, long documents,
and medium paragraphs. The consistent labeling across these datasets
facilitates document length-based analysis. We provide detailed data statistics
and baseline results on these datasets using state-of-the-art pre-trained BERT
models. We conduct a comparative analysis between monolingual and multilingual
BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT
model outperforms all others on every dataset. These resources also serve as
Marathi topic classification datasets or models and are publicly available at
https://github.com/l3cube-pune/MarathiNLP .

摘要：馬拉地語這種低資源語言中的文字或主題分類資料集的可用性有限，通常包含少於 4 個目標標籤，有些標籤達到了近乎完美的準確度。在這項工作中，我們引入了 L3Cube-MahaNews，這是一個專注於新聞標題和文章的馬拉地語文字分類語料庫。這個語料庫是最大的監督式馬拉地語語料庫，包含超過 1.05L 條記錄，分類為 12 個不同的類別。為了適應不同的文件長度，MahaNews 包含三個監督式資料集，專門設計用於短文字、長文件和中等長度的段落。這些資料集中一致的標籤有助於基於文件長度的分析。我們使用最先進的預訓練 BERT 模型，提供這些資料集的詳細資料統計和基準結果。我們對單語和多語 BERT 模型（包括 MahaBERT、IndicBERT 和 MuRIL）進行了比較分析。單語的 MahaBERT 模型在每個資料集上的表現都優於其他模型。這些資源也可用作馬拉地語主題分類資料集或模型，並在 https://github.com/l3cube-pune/MarathiNLP 公開提供。

##### **Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement**
2404.18214v1 by Zeyu Hu,Yuzhi Xiao,Tao Huang,Xuanrong Huo

Sequential recommendation is one of the important branches of recommender
system, aiming to achieve personalized recommended items for the future through
the analysis and prediction of users' ordered historical interactive behaviors.
However, along with the growth of the user volume and the increasingly rich
behavioral information, how to understand and disentangle the user's
interactive multi-intention effectively also poses challenges to behavior
prediction and sequential recommendation. In light of these challenges, we
propose a Contrastive Learning sequential recommendation method based on
Multi-Intention Disentanglement (MIDCL). In our work, intentions are recognized
as dynamic and diverse, and user behaviors are often driven by current
multi-intentions, which means that the model needs to not only mine the most
relevant implicit intention for each user, but also impair the influence from
irrelevant intentions. Therefore, we choose Variational Auto-Encoder (VAE) to
realize the disentanglement of users' multi-intentions, and propose two types
of contrastive learning paradigms for finding the most relevant user's
interactive intention, and maximizing the mutual information of positive sample
pairs, respectively. Experimental results show that MIDCL not only has
significant superiority over most existing baseline methods, but also brings a
more interpretable case to the research about intention-based prediction and
recommendation.

摘要：序列推薦是推薦系統中的重要分支，旨在透過分析和預測使用者有順序的歷史互動行為，為未來提供個人化的推薦項目。然而，隨著使用者規模的增長和行為資訊的日益豐富，如何有效理解和區分使用者的互動多意圖，也對行為預測和序列推薦帶來挑戰。有鑑於這些挑戰，我們提出一個基於多意圖解糾纏 (MIDCL) 的對比學習序列推薦方法。在我們的研究中，意圖被視為動態且多樣，而使用者行為通常是由當前的多意圖驅動，這意味著模型不僅需要挖掘每個使用者的最相關隱含意圖，還要減弱無關意圖的影響。因此，我們選擇變異自動編碼器 (VAE) 來實現使用者多意圖的解糾纏，並提出兩種對比學習範例，分別用於尋找最相關的使用者互動意圖，以及最大化正樣本對的互信息。實驗結果表明，MIDCL 不僅顯著優於現有的多數基線方法，還為基於意圖的預測和推薦的研究帶來了更具可解釋性的案例。

##### **S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification**
2404.18213v1 by Guanchun Wang,Xiangrong Zhang,Zelin Peng,Tianyang Zhang,Xiuping Jia,Licheng Jiao

Land cover analysis using hyperspectral images (HSI) remains an open problem
due to their low spatial resolution and complex spectral information. Recent
studies are primarily dedicated to designing Transformer-based architectures
for spatial-spectral long-range dependencies modeling, which is computationally
expensive with quadratic complexity. Selective structured state space model
(Mamba), which is efficient for modeling long-range dependencies with linear
complexity, has recently shown promising progress. However, its potential in
hyperspectral image processing that requires handling numerous spectral bands
has not yet been explored. In this paper, we innovatively propose S$^2$Mamba, a
spatial-spectral state space model for hyperspectral image classification, to
excavate spatial-spectral contextual features, resulting in more efficient and
accurate land cover analysis. In S$^2$Mamba, two selective structured state
space models through different dimensions are designed for feature extraction,
one for spatial, and the other for spectral, along with a spatial-spectral
mixture gate for optimal fusion. More specifically, S$^2$Mamba first captures
spatial contextual relations by interacting each pixel with its adjacent
through a Patch Cross Scanning module and then explores semantic information
from continuous spectral bands through a Bi-directional Spectral Scanning
module. Considering the distinct expertise of the two attributes in homogenous
and complicated texture scenes, we realize the Spatial-spectral Mixture Gate by
a group of learnable matrices, allowing for the adaptive incorporation of
representations learned across different dimensions. Extensive experiments
conducted on HSI classification benchmarks demonstrate the superiority and
prospect of S$^2$Mamba. The code will be available at:
https://github.com/PURE-melo/S2Mamba.

摘要：使用高光谱影像 (HSI) 进行土地覆盖分析仍然是一个开放的问题，因为它们的空间分辨率低且光谱信息复杂。最近的研究主要致力于设计基于 Transformer 的架构，用于建模空间光谱长距离依赖性，这在计算上很昂贵，具有二次复杂度。选择性结构状态空间模型 (Mamba) 对于使用线性复杂度建模长距离依赖性非常有效，最近已显示出有希望的进展。然而，它在需要处理大量光谱波段的高光谱图像处理中的潜力尚未得到探索。在本文中，我们创新性地提出了 S$^2$Mamba，这是一种用于高光谱图像分类的空间光谱状态空间模型，用于挖掘空间光谱上下文特征，从而实现更高效和准确的土地覆盖分析。在 S$^2$Mamba 中，设计了两个通过不同维度的选择性结构状态空间模型用于特征提取，一个用于空间，另一个用于光谱，以及一个用于优化融合的空间光谱混合门。更具体地说，S$^2$Mamba 首先通过 Patch Cross Scanning 模块使每个像素与其相邻像素交互来捕获空间上下文关系，然后通过双向光谱扫描模块探索来自连续光谱波段的语义信息。考虑到两种属性在同质和复杂纹理场景中的不同专业知识，我们通过一组可学习矩阵实现了空间光谱混合门，允许自适应地合并跨不同维度学习的表示。在 HSI 分类基准上进行的广泛实验证明了 S$^2$Mamba 的优越性和前景。代码将在以下位置提供：
https://github.com/PURE-melo/S2Mamba。

##### **Paint by Inpaint: Learning to Add Image Objects by Removing Them First**
2404.18212v1 by Navve Wasserman,Noam Rotstein,Roy Ganz,Ron Kimmel

Image editing has advanced significantly with the introduction of
text-conditioned diffusion models. Despite this progress, seamlessly adding
objects to images based on textual instructions without requiring user-provided
input masks remains a challenge. We address this by leveraging the insight that
removing objects (Inpaint) is significantly simpler than its inverse process of
adding them (Paint), attributed to the utilization of segmentation mask
datasets alongside inpainting models that inpaint within these masks.
Capitalizing on this realization, by implementing an automated and extensive
pipeline, we curate a filtered large-scale image dataset containing pairs of
images and their corresponding object-removed versions. Using these pairs, we
train a diffusion model to inverse the inpainting process, effectively adding
objects into images. Unlike other editing datasets, ours features natural
target images instead of synthetic ones; moreover, it maintains consistency
between source and target by construction. Additionally, we utilize a large
Vision-Language Model to provide detailed descriptions of the removed objects
and a Large Language Model to convert these descriptions into diverse,
natural-language instructions. We show that the trained model surpasses
existing ones both qualitatively and quantitatively, and release the
large-scale dataset alongside the trained models for the community.

摘要：影像編輯隨著文字條件擴散模型的引入而大幅進步。儘管有此進展，根據文字說明無縫地將物件加入影像中，且無需使用者提供的輸入遮罩，仍然是一項挑戰。我們透過利用移除物件（修復）明顯比其反向的加入過程（繪製）簡單的見解來解決這個問題，這歸功於將分割遮罩資料集與在這些遮罩內修復的修復模型結合使用。透過實作自動化且廣泛的管道，充分利用這個認知，我們策劃一個經過濾的大規模影像資料集，其中包含成對的影像及其對應的移除物件版本。使用這些成對的影像，我們訓練一個擴散模型來反轉修復過程，有效地將物件加入影像中。與其他編輯資料集不同，我們的資料集具有自然的目標影像，而非合成的影像；此外，它透過建構來維持來源與目標之間的一致性。此外，我們利用一個大型的視覺語言模型來提供已移除物件的詳細描述，並利用一個大型語言模型將這些描述轉換為多樣化的自然語言說明。我們展示訓練好的模型在質量和數量上都超越現有的模型，並釋出大規模的資料集以及訓練好的模型供社群使用。

##### **LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM**
2404.18203v1 by Zicheng Zhang,Haoning Wu,Yingjie Zhou,Chunyi Li,Wei Sun,Chaofeng Chen,Xiongkuo Min,Xiaohong Liu,Weisi Lin,Guangtao Zhai

Although large multi-modality models (LMMs) have seen extensive exploration
and application in various quality assessment studies, their integration into
Point Cloud Quality Assessment (PCQA) remains unexplored. Given LMMs'
exceptional performance and robustness in low-level vision and quality
assessment tasks, this study aims to investigate the feasibility of imparting
PCQA knowledge to LMMs through text supervision. To achieve this, we transform
quality labels into textual descriptions during the fine-tuning phase, enabling
LMMs to derive quality rating logits from 2D projections of point clouds. To
compensate for the loss of perception in the 3D domain, structural features are
extracted as well. These quality logits and structural features are then
combined and regressed into quality scores. Our experimental results affirm the
effectiveness of our approach, showcasing a novel integration of LMMs into PCQA
that enhances model understanding and assessment accuracy. We hope our
contributions can inspire subsequent investigations into the fusion of LMMs
with PCQA, fostering advancements in 3D visual quality analysis and beyond.

摘要：儘管大型多模態模型 (LMM) 已在各種品質評估研究中廣泛探討和應用，但其整合至點雲品質評估 (PCQA) 仍未見探索。考量到 LMM 在低階視覺和品質評估任務中表現出色的效能和穩健性，本研究旨在探討透過文字監督將 PCQA 知識傳授給 LMM 的可行性。為達成此目的，我們在微調階段將品質標籤轉換為文字描述，讓 LMM 能從點雲的 2D 投影中推導出品質評分對數。為了彌補 3D 領域感知的損失，我們也萃取出結構特徵。這些品質對數和結構特徵接著會被合併並迴歸成品質分數。我們的實驗結果肯定了我們方法的有效性，展示出 LMM 與 PCQA 的創新整合，可提升模型理解和評估準確度。我們希望我們的貢獻能激勵後續研究融合 LMM 與 PCQA，進而促進 3D 視覺品質分析及其他領域的進展。

##### **WorldGPT: Empowering LLM as Multimodal World Model**
2404.18202v1 by Zhiqi Ge,Hongzhe Huang,Mingze Zhou,Juncheng Li,Guoming Wang,Siliang Tang,Yueting Zhuang

World models are progressively being employed across diverse fields,
extending from basic environment simulation to complex scenario construction.
However, existing models are mainly trained on domain-specific states and
actions, and confined to single-modality state representations. In this paper,
We introduce WorldGPT, a generalist world model built upon Multimodal Large
Language Model (MLLM). WorldGPT acquires an understanding of world dynamics
through analyzing millions of videos across various domains. To further enhance
WorldGPT's capability in specialized scenarios and long-term tasks, we have
integrated it with a novel cognitive architecture that combines memory
offloading, knowledge retrieval, and context reflection. As for evaluation, we
build WorldNet, a multimodal state transition prediction benchmark encompassing
varied real-life scenarios. Conducting evaluations on WorldNet directly
demonstrates WorldGPT's capability to accurately model state transition
patterns, affirming its effectiveness in understanding and predicting the
dynamics of complex scenarios. We further explore WorldGPT's emerging potential
in serving as a world simulator, helping multimodal agents generalize to
unfamiliar domains through efficiently synthesising multimodal instruction
instances which are proved to be as reliable as authentic data for fine-tuning
purposes. The project is available on
\url{https://github.com/DCDmllm/WorldGPT}.

摘要：世界模型正逐步應用於各種領域，
從基本的環境模擬延伸到複雜的場景建構。
然而，現有的模型主要訓練於特定領域的狀態和
動作，並侷限於單一模態狀態表示。在本文中，
我們介紹 WorldGPT，一個建立於多模態大型
語言模型 (MLLM) 上的泛用世界模型。WorldGPT 透過
分析數百萬個跨領域的影片，獲取對世界動態的理解。為了進一步增強
WorldGPT 在特定場景和長期任務中的能力，我們已
將其與一種新穎的認知架構整合，結合記憶
卸載、知識擷取和情境反思。至於評估，我們
建立了 WorldNet，一個包含各種真實生活場景的多模態狀態轉換預測基準。在 WorldNet 上進行評估直接
證明了 WorldGPT 精確建模狀態轉換
模式的能力，肯定了其在理解和預測複雜場景動態方面的效能。我們進一步探索 WorldGPT 在作為世界模擬器方面的潛力，協助多模態代理概化到
不熟悉的領域，透過有效地合成多模態指令
實例，證明其與用於微調目的的真實資料一樣可靠。這個專案可在
\url{https://github.com/DCDmllm/WorldGPT} 取得。

##### **Exploring the Robustness of In-Context Learning with Noisy Labels**
2404.18191v1 by Chen Cheng,Xinzhi Yu,Haodong Wen,Jinsong Sun,Guanzhang Yue,Yihao Zhang,Zeming Wei

Recently, the mysterious In-Context Learning (ICL) ability exhibited by
Transformer architectures, especially in large language models (LLMs), has
sparked significant research interest. However, the resilience of Transformers'
in-context learning capabilities in the presence of noisy samples, prevalent in
both training corpora and prompt demonstrations, remains underexplored. In this
paper, inspired by prior research that studies ICL ability using simple
function classes, we take a closer look at this problem by investigating the
robustness of Transformers against noisy labels. Specifically, we first conduct
a thorough evaluation and analysis of the robustness of Transformers against
noisy labels during in-context learning and show that they exhibit notable
resilience against diverse types of noise in demonstration labels. Furthermore,
we delve deeper into this problem by exploring whether introducing noise into
the training set, akin to a form of data augmentation, enhances such robustness
during inference, and find that such noise can indeed improve the robustness of
ICL. Overall, our fruitful analysis and findings provide a comprehensive
understanding of the resilience of Transformer models against label noises
during ICL and provide valuable insights into the research on Transformers in
natural language processing. Our code is available at
https://github.com/InezYu0928/in-context-learning.

摘要：最近，Transformer 架構所展現的神秘語境學習 (ICL) 能力，特別是在大型語言模型 (LLM) 中，已引起重大的研究興趣。然而，Transformer 的語境學習能力在有雜訊樣本的情況下的復原力，在訓練語料庫和提示範例中普遍存在，仍未被充分探討。在本文中，受到先前研究的啟發，該研究使用簡單函數類別研究 ICL 能力，我們透過探討 Transformer 對雜訊標籤的穩健性，仔細探討這個問題。具體來說，我們首先對 Transformer 在語境學習期間對雜訊標籤的穩健性進行徹底的評估和分析，並顯示出它們對範例標籤中各種類型的雜訊表現出顯著的復原力。此外，我們進一步探討這個問題，探索在訓練集中引入雜訊（類似於一種資料擴充）是否會增強這種在推論期間的穩健性，並發現這種雜訊確實可以改善 ICL 的穩健性。總體而言，我們富有成果的分析和發現提供了對 Transformer 模型在 ICL 期間對標籤雜訊的復原力的全面理解，並為自然語言處理中 Transformer 的研究提供了寶貴的見解。我們的程式碼可在 https://github.com/InezYu0928/in-context-learning 取得。

##### **Ranked List Truncation for Large Language Model-based Re-Ranking**
2404.18185v1 by Chuan Meng,Negar Arabzadeh,Arian Askari,Mohammad Aliannejadi,Maarten de Rijke

We study ranked list truncation (RLT) from a novel "retrieve-then-re-rank"
perspective, where we optimize re-ranking by truncating the retrieved list
(i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can
improve re-ranking efficiency by sending variable-length candidate lists to a
re-ranker on a per-query basis. It also has the potential to improve re-ranking
effectiveness. Despite its importance, there is limited research into applying
RLT methods to this new perspective. To address this research gap, we reproduce
existing RLT methods in the context of re-ranking, especially newly emerged
large language model (LLM)-based re-ranking. In particular, we examine to what
extent established findings on RLT for retrieval are generalizable to the
"retrieve-then-re-rank" setup from three perspectives: (i) assessing RLT
methods in the context of LLM-based re-ranking with lexical first-stage
retrieval, (ii) investigating the impact of different types of first-stage
retrievers on RLT methods, and (iii) investigating the impact of different
types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and
2020 deep learning tracks, investigating 8 RLT methods for pipelines involving
3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the
context of re-ranking.

摘要：<paragraph>我們從新的「先擷取後重新排序」觀點研究排序清單截斷 (RLT)，在這個觀點中，我們透過截斷擷取清單（即修剪重新排序候選）來最佳化重新排序。RLT 對重新排序至關重要，因為它可以透過在每次查詢中傳送長度可變的候選清單給重新排序器，來提升重新排序的效率。它也有可能提升重新排序的效能。儘管 RLT 很重要，但將 RLT 方法應用到這個新觀點的研究卻很有限。為了解決這個研究落差，我們在重新排序的脈絡中重現現有的 RLT 方法，特別是新興的大型語言模型 (LLM) 重新排序。具體來說，我們探討 RLT 在擷取方面的既有發現，在多大程度上可以推廣到「先擷取後重新排序」的設定，從三個觀點來看：(i) 評估 RLT 方法在基於 LLM 的重新排序脈絡中，搭配詞彙第一階段擷取的成效，(ii) 調查不同類型的第一階段擷取器對 RLT 方法的影響，以及 (iii) 調查不同類型的重新排序器對 RLT 方法的影響。我們針對 TREC 2019 和 2020 深度學習軌道執行實驗，調查 8 種 RLT 方法，用於包含 3 個擷取器和 2 個重新排序器的管道。我們在重新排序的脈絡中對 RLT 方法有了新的見解。</paragraph>

##### **EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter**
2404.18180v1 by Comfort Eseohen Ilevbare,Jesujoba O. Alabi,David Ifeoluwa Adelani,Firdous Damilola Bakare,Oluwatoyin Bunmi Abiola,Oluwaseyi Adesina Adeyemo

Nigerians have a notable online presence and actively discuss political and
topical matters. This was particularly evident throughout the 2023 general
election, where Twitter was used for campaigning, fact-checking and
verification, and even positive and negative discourse. However, little or none
has been done in the detection of abusive language and hate speech in Nigeria.
In this paper, we curated code-switched Twitter data directed at three
musketeers of the governorship election on the most populous and economically
vibrant state in Nigeria; Lagos state, with the view to detect offensive speech
in political discussions. We developed EkoHate -- an abusive language and hate
speech dataset for political discussions between the three candidates and their
followers using a binary (normal vs offensive) and fine-grained four-label
annotation scheme. We analysed our dataset and provided an empirical evaluation
of state-of-the-art methods across both supervised and cross-lingual transfer
learning settings. In the supervised setting, our evaluation results in both
binary and four-label annotation schemes show that we can achieve 95.1 and 70.3
F1 points respectively. Furthermore, we show that our dataset adequately
transfers very well to three publicly available offensive datasets (OLID,
HateUS2020, and FountaHate), generalizing to political discussions in other
regions like the US.

摘要：奈及利亞人在網路上非常活躍，並積極討論政治和時事議題。這在 2023 年的總統大選中特別明顯，當時 Twitter 被用於競選、查核事實和驗證，甚至有正面和負面的討論。然而，在奈及利亞，很少或根本沒有人偵測到辱罵性語言和仇恨言論。在本文中，我們整理了針對奈及利亞人口最多、經濟最活躍的拉哥斯州州長選舉的三位候選人的 Twitter 數據，目的是偵測政治討論中的攻擊性言論。我們開發了 EkoHate，一個針對三位候選人及其追隨者之間的政治討論的辱罵性語言和仇恨言論數據集，使用二元（正常與攻擊性）和細緻的四標籤註釋方案。我們分析了我們的數據集，並對監督式和跨語言遷移學習設定中的最先進方法提供了經驗評估。在監督式設定中，我們的評估結果在二元和四標籤註釋方案中顯示，我們分別可以達到 95.1 和 70.3 的 F1 分數。此外，我們表明我們的數據集充分轉移到三個公開可用的攻擊性數據集（OLID、HateUS2020 和 FountaHate），並推廣到美國等其他地區的政治討論。

