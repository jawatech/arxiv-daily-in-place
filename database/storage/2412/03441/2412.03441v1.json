{"2412.03441": {"publish_time": "2024-12-04", "title": "PBP: Post-training Backdoor Purification for Malware Classifiers", "paper_summary": "In recent years, the rise of machine learning (ML) in cybersecurity has\nbrought new challenges, including the increasing threat of backdoor poisoning\nattacks on ML malware classifiers. For instance, adversaries could inject\nmalicious samples into public malware repositories, contaminating the training\ndata and potentially misclassifying malware by the ML model. Current\ncountermeasures predominantly focus on detecting poisoned samples by leveraging\ndisagreements within the outputs of a diverse set of ensemble models on\ntraining data points. However, these methods are not suitable for scenarios\nwhere Machine Learning-as-a-Service (MLaaS) is used or when users aim to remove\nbackdoors from a model after it has been trained. Addressing this scenario, we\nintroduce PBP, a post-training defense for malware classifiers that mitigates\nvarious types of backdoor embeddings without assuming any specific backdoor\nembedding mechanism. Our method exploits the influence of backdoor attacks on\nthe activation distribution of neural networks, independent of the\ntrigger-embedding method. In the presence of a backdoor attack, the activation\ndistribution of each layer is distorted into a mixture of distributions. By\nregulating the statistics of the batch normalization layers, we can guide a\nbackdoored model to perform similarly to a clean one. Our method demonstrates\nsubstantial advantages over several state-of-the-art methods, as evidenced by\nexperiments on two datasets, two types of backdoor methods, and various attack\nconfigurations. Notably, our approach requires only a small portion of the\ntraining data -- only 1\\% -- to purify the backdoor and reduce the attack\nsuccess rate from 100\\% to almost 0\\%, a 100-fold improvement over the baseline\nmethods. Our code is available at\n\\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}.", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u6a5f\u5668\u5b78\u7fd2 (ML) \u5728\u7db2\u8def\u5b89\u5168\u7684\u5d1b\u8d77\u5e36\u4f86\u4e86\u65b0\u7684\u6311\u6230\uff0c\u5305\u62ec\u91dd\u5c0d ML \u60e1\u610f\u8edf\u9ad4\u5206\u985e\u5668\u8d8a\u4f86\u8d8a\u56b4\u91cd\u7684\u5f8c\u9580\u6295\u6bd2\u653b\u64ca\u5a01\u8105\u3002\u4f8b\u5982\uff0c\u653b\u64ca\u8005\u53ef\u4ee5\u5c07\u60e1\u610f\u6a23\u672c\u6ce8\u5165\u516c\u5171\u60e1\u610f\u8edf\u9ad4\u5132\u5b58\u5eab\uff0c\u6c61\u67d3\u8a13\u7df4\u8cc7\u6599\uff0c\u4e26\u53ef\u80fd\u5c0e\u81f4 ML \u6a21\u578b\u932f\u8aa4\u5206\u985e\u60e1\u610f\u8edf\u9ad4\u3002\u76ee\u524d\u7684\u5c0d\u7b56\u4e3b\u8981\u96c6\u4e2d\u65bc\u900f\u904e\u5229\u7528\u4e00\u7d44\u591a\u5143\u96c6\u6210\u6a21\u578b\u5728\u8a13\u7df4\u8cc7\u6599\u9ede\u4e0a\u8f38\u51fa\u7684\u5206\u6b67\u4f86\u5075\u6e2c\u4e2d\u6bd2\u6a23\u672c\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u4e0d\u9069\u7528\u65bc\u4f7f\u7528\u6a5f\u5668\u5b78\u7fd2\u5373\u670d\u52d9 (MLaaS) \u6216\u4f7f\u7528\u8005\u5728\u8a13\u7df4\u6a21\u578b\u5f8c\u5e0c\u671b\u5f9e\u6a21\u578b\u4e2d\u79fb\u9664\u5f8c\u9580\u7684\u5834\u666f\u3002\u70ba\u4e86\u8655\u7406\u9019\u7a2e\u5834\u666f\uff0c\u6211\u5011\u5f15\u5165\u4e86 PBP\uff0c\u9019\u662f\u4e00\u7a2e\u91dd\u5c0d\u60e1\u610f\u8edf\u9ad4\u5206\u985e\u5668\u7684\u8a13\u7df4\u5f8c\u9632\u79a6\u6a5f\u5236\uff0c\u5b83\u80fd\u6e1b\u8f15\u5404\u7a2e\u985e\u578b\u7684\u5f8c\u9580\u5d4c\u5165\uff0c\u800c\u7121\u9700\u5047\u8a2d\u4efb\u4f55\u7279\u5b9a\u5f8c\u9580\u5d4c\u5165\u6a5f\u5236\u3002\u6211\u5011\u7684\u65b9\u6cd5\u5229\u7528\u5f8c\u9580\u653b\u64ca\u5c0d\u795e\u7d93\u7db2\u8def\u555f\u7528\u5206\u4f48\u7684\u5f71\u97ff\uff0c\u8207\u89f8\u767c\u5d4c\u5165\u65b9\u6cd5\u7121\u95dc\u3002\u5728\u5f8c\u9580\u653b\u64ca\u7684\u60c5\u6cc1\u4e0b\uff0c\u6bcf\u4e00\u5c64\u7684\u555f\u7528\u5206\u4f48\u6703\u626d\u66f2\u6210\u6df7\u5408\u5206\u4f48\u3002\u900f\u904e\u8abf\u7bc0\u6279\u6b21\u6a19\u6e96\u5316\u5c64\u7684\u7d71\u8a08\u8cc7\u6599\uff0c\u6211\u5011\u53ef\u4ee5\u5f15\u5c0e\u5f8c\u9580\u6a21\u578b\u57f7\u884c\u985e\u4f3c\u65bc\u4e7e\u6de8\u6a21\u578b\u7684\u4efb\u52d9\u3002\u6211\u5011\u7684\u6a21\u578b\u5c55\u73fe\u51fa\u512a\u65bc\u591a\u7a2e\u6700\u5148\u9032\u65b9\u6cd5\u7684\u986f\u8457\u512a\u52e2\uff0c\u9019\u5728\u5169\u500b\u8cc7\u6599\u96c6\u3001\u5169\u7a2e\u5f8c\u9580\u65b9\u6cd5\u548c\u5404\u7a2e\u653b\u64ca\u914d\u7f6e\u7684\u5be6\u9a57\u4e2d\u5f97\u5230\u8b49\u660e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u6a21\u578b\u50c5\u9700\u8981\u4e00\u5c0f\u90e8\u5206\u8a13\u7df4\u8cc7\u6599 (\u50c5 1%) \u5c31\u80fd\u6de8\u5316\u5f8c\u9580\uff0c\u4e26\u5c07\u653b\u64ca\u6210\u529f\u7387\u5f9e 100% \u964d\u4f4e\u5230\u5e7e\u4e4e 0%\uff0c\u6bd4\u57fa\u6e96\u65b9\u6cd5\u63d0\u5347\u4e86 100 \u500d\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u65bc\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1a\\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}\u3002", "author": "Dung Thuy Nguyen et.al.", "authors": "Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach", "id": "2412.03441v1", "paper_url": "http://arxiv.org/abs/2412.03441v1", "repo": "https://github.com/judydnguyen/pbp-backdoor-purification-official"}}