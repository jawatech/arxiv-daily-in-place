{"2406.07222": {"publish_time": "2024-06-11", "title": "Improving Autoformalization using Type Checking", "paper_summary": "Large language models show promise for autoformalization, the task of\nautomatically translating natural language into formal languages. However,\ncurrent autoformalization methods remain limited. The last reported\nstate-of-the-art performance on the ProofNet formalization benchmark for the\nLean proof assistant, achieved using Codex for Lean 3, only showed successful\nformalization of 16.1% of informal statements. Similarly, our evaluation of\nGPT-4o for Lean 4 only produces successful translations 34.9% of the time. Our\nanalysis shows that the performance of these models is largely limited by their\ninability to generate formal statements that successfully type-check (i.e., are\nsyntactically correct and consistent with types) - with a whopping 86.6% of\nGPT-4o errors starting from a type-check failure. In this work, we propose a\nmethod to fix this issue through decoding with type-check filtering, where we\ninitially sample a diverse set of candidate formalizations for an informal\nstatement, then use the Lean proof assistant to filter out candidates that do\nnot type-check. Using GPT-4o as a base model, and combining our method with\nself-consistency, we obtain a +18.3% absolute increase in formalization\naccuracy, and achieve a new state-of-the-art of 53.2% on ProofNet with Lean 4.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u663e\u793a\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u524d\u666f\uff0c\u5373\u81ea\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u7ffb\u8bd1\u6210\u5f62\u5f0f\u8bed\u8a00\u7684\u4efb\u52a1\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u4ecd\u7136\u6709\u9650\u3002\u5728\u4f7f\u7528 Codex for Lean 3 \u9488\u5bf9 Lean \u8bc1\u660e\u52a9\u624b\u5b9e\u73b0\u7684 ProofNet \u5f62\u5f0f\u5316\u57fa\u51c6\u4e0a\u62a5\u544a\u7684\u6700\u65b0\u6027\u80fd\uff0c\u4ec5\u663e\u793a\u6210\u529f\u5f62\u5f0f\u5316\u4e86 16.1% \u7684\u975e\u6b63\u5f0f\u9648\u8ff0\u3002\u7c7b\u4f3c\u5730\uff0c\u6211\u4eec\u5bf9 Lean 4 \u7684 GPT-4o \u7684\u8bc4\u4f30\u4ec5\u5728 34.9% \u7684\u65f6\u95f4\u5185\u4ea7\u751f\u4e86\u6210\u529f\u7684\u7ffb\u8bd1\u3002\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u6027\u80fd\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d7\u5230\u5b83\u4eec\u751f\u6210\u6210\u529f\u7c7b\u578b\u68c0\u67e5\uff08\u5373\u8bed\u6cd5\u6b63\u786e\u4e14\u4e0e\u7c7b\u578b\u4e00\u81f4\uff09\u7684\u6b63\u5f0f\u9648\u8ff0\u7684\u80fd\u529b\u7684\u9650\u5236\u2014\u201486.6% \u7684 GPT-4o \u9519\u8bef\u4ece\u7c7b\u578b\u68c0\u67e5\u5931\u8d25\u5f00\u59cb\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4f7f\u7528\u7c7b\u578b\u68c0\u67e5\u8fc7\u6ee4\u8fdb\u884c\u89e3\u7801\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d\u6211\u4eec\u6700\u521d\u4e3a\u975e\u6b63\u5f0f\u9648\u8ff0\u62bd\u53d6\u4e00\u7ec4\u4e0d\u540c\u7684\u5019\u9009\u5f62\u5f0f\u5316\uff0c\u7136\u540e\u4f7f\u7528 Lean \u8bc1\u660e\u52a9\u624b\u6765\u8fc7\u6ee4\u6389\u672a\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\u7684\u5019\u9009\u9879\u3002\u4f7f\u7528 GPT-4o \u4f5c\u4e3a\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u5c06\u6211\u4eec\u7684\u65b9\u6cd5\u4e0e\u81ea\u6d3d\u6027\u76f8\u7ed3\u5408\uff0c\u6211\u4eec\u5728\u5f62\u5f0f\u5316\u51c6\u786e\u6027\u4e0a\u83b7\u5f97\u4e86 +18.3% \u7684\u7edd\u5bf9\u63d0\u5347\uff0c\u5e76\u5728 Lean 4 \u4e0a\u7684 ProofNet \u4e0a\u5b9e\u73b0\u4e86 53.2% \u7684\u65b0\u6280\u672f\u6c34\u5e73\u3002", "author": "Auguste Poiroux et.al.", "authors": "Auguste Poiroux, Gail Weiss, Viktor Kun\u010dak, Antoine Bosselut", "id": "2406.07222v1", "paper_url": "http://arxiv.org/abs/2406.07222v1", "repo": "null"}}