{"2411.16495": {"publish_time": "2024-11-25", "title": "AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning", "paper_summary": "Recent advancements in large language models (LLMs) have led to significant\nimprovements in various natural language processing tasks, but it is still\nchallenging for LLMs to perform knowledge-intensive complex question answering\ndue to LLMs' inefficacy in reasoning planning and the hallucination problem. A\ntypical solution is to employ retrieval-augmented generation (RAG) coupled with\nchain-of-thought (CoT) reasoning, which decomposes complex questions into\nchain-like sub-questions and applies iterative RAG at each sub-question.\nHowever, prior works exhibit sub-optimal reasoning planning and overlook\ndynamic knowledge retrieval from heterogeneous sources. In this paper, we\npropose AtomR, a novel heterogeneous knowledge reasoning framework that\nconducts multi-source reasoning at the atomic level. Drawing inspiration from\nthe graph modeling of knowledge, AtomR leverages large language models (LLMs)\nto decompose complex questions into combinations of three atomic knowledge\noperators, significantly enhancing the reasoning process at both the planning\nand execution stages. We also introduce BlendQA, a novel evaluation benchmark\ntailored to assess complex heterogeneous knowledge reasoning. Experiments show\nthat AtomR significantly outperforms state-of-the-art baselines across three\nsingle-source and two multi-source reasoning benchmarks, with notable\nperformance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u5df2\u5927\u5e45\u63d0\u5347\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u7684\u8868\u73fe\uff0c\u4f46 LLM \u4ecd\u96e3\u4ee5\u57f7\u884c\u77e5\u8b58\u5bc6\u96c6\u578b\u8907\u96dc\u554f\u984c\u89e3\u7b54\uff0c\u539f\u56e0\u5728\u65bc LLM \u5728\u63a8\u7406\u898f\u5283\u548c\u5e7b\u89ba\u554f\u984c\u65b9\u9762\u6548\u7387\u4e0d\u5f70\u3002\u5178\u578b\u7684\u89e3\u6c7a\u65b9\u6848\u662f\u63a1\u7528\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u642d\u914d\u601d\u7dad\u93c8 (CoT) \u63a8\u7406\uff0c\u5c07\u8907\u96dc\u554f\u984c\u5206\u89e3\u6210\u93c8\u72c0\u5b50\u554f\u984c\uff0c\u4e26\u5728\u6bcf\u500b\u5b50\u554f\u984c\u5957\u7528\u53cd\u8986 RAG\u3002\u7136\u800c\uff0c\u5148\u524d\u7684\u7814\u7a76\u5c55\u73fe\u51fa\u6b21\u4f73\u63a8\u7406\u898f\u5283\uff0c\u4e26\u5ffd\u7565\u5f9e\u7570\u8cea\u4f86\u6e90\u9032\u884c\u52d5\u614b\u77e5\u8b58\u6aa2\u7d22\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa AtomR\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u7570\u8cea\u77e5\u8b58\u63a8\u7406\u67b6\u69cb\uff0c\u5728\u539f\u5b50\u5c64\u7d1a\u9032\u884c\u591a\u4f86\u6e90\u63a8\u7406\u3002AtomR \u5f9e\u77e5\u8b58\u7684\u5716\u5f62\u5efa\u6a21\u4e2d\u6c72\u53d6\u9748\u611f\uff0c\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c07\u8907\u96dc\u554f\u984c\u5206\u89e3\u6210\u4e09\u7a2e\u539f\u5b50\u77e5\u8b58\u904b\u7b97\u5b50\u7684\u7d44\u5408\uff0c\u5927\u5e45\u63d0\u5347\u898f\u5283\u548c\u57f7\u884c\u968e\u6bb5\u7684\u63a8\u7406\u7a0b\u5e8f\u3002\u6211\u5011\u4e5f\u5f15\u9032 BlendQA\uff0c\u4e00\u500b\u65b0\u7a4e\u7684\u8a55\u91cf\u57fa\u6e96\uff0c\u5c08\u9580\u7528\u65bc\u8a55\u4f30\u8907\u96dc\u7570\u8cea\u77e5\u8b58\u63a8\u7406\u3002\u5be6\u9a57\u986f\u793a\uff0cAtomR \u5728\u4e09\u500b\u55ae\u4e00\u4f86\u6e90\u548c\u5169\u500b\u591a\u4f86\u6e90\u63a8\u7406\u57fa\u6e96\u4e2d\uff0c\u8868\u73fe\u986f\u8457\u512a\u65bc\u73fe\u6709\u6280\u8853\u57fa\u7dda\uff0c\u5728 2WikiMultihop \u4e0a\u7372\u5f97 9.4% \u7684\u986f\u8457\u6548\u80fd\u63d0\u5347\uff0c\u5728 BlendQA \u4e0a\u7372\u5f97 9.5% \u7684\u63d0\u5347\u3002", "author": "Amy Xin et.al.", "authors": "Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li", "id": "2411.16495v2", "paper_url": "http://arxiv.org/abs/2411.16495v2", "repo": "https://github.com/THU-KEG/AtomR"}}