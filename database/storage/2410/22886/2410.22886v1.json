{"2410.22886": {"publish_time": "2024-10-30", "title": "Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies", "paper_summary": "Curriculum Learning has been a popular strategy to improve the cognitive\nplausibility of Small-Scale Language Models (SSLMs) in the BabyLM Challenge.\nHowever, it has not led to considerable improvements over non-curriculum\nmodels. We assess whether theoretical linguistic acquisition theories can be\nused to specify more fine-grained curriculum learning strategies, creating\nage-ordered corpora of Child-Directed Speech for four typologically distant\nlanguage families to implement SSLMs and acquisition-inspired curricula\ncross-lingually. Comparing the success of three objective curricula (Growing,\nInwards and MMM) that precisely replicate the predictions of acquisition\ntheories on a standard SSLM architecture, we find fine-grained\nacquisition-inspired curricula can outperform non-curriculum baselines and\nperformance benefits of curricula strategies in SSLMs can be derived by\nspecifying fine-grained language-specific curricula that precisely replicate\nlanguage acquisition theories.", "paper_summary_zh": "\u8ab2\u7a0b\u5b78\u7fd2\u4e00\u76f4\u662f\u63d0\u9ad8 BabyLM \u6311\u6230\u4e2d\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b (SSLMs) \u7684\u8a8d\u77e5\u5408\u7406\u6027\u7684\u71b1\u9580\u7b56\u7565\u3002\n\u7136\u800c\uff0c\u5b83\u4e26\u672a\u5c0e\u81f4\u975e\u8ab2\u7a0b\u6a21\u578b\u6709\u986f\u8457\u7684\u6539\u9032\u3002\u6211\u5011\u8a55\u4f30\u7406\u8ad6\u8a9e\u8a00\u7fd2\u5f97\u7406\u8ad6\u662f\u5426\u53ef\u7528\u65bc\u6307\u5b9a\u66f4\u7d30\u7dfb\u7684\u8ab2\u7a0b\u5b78\u7fd2\u7b56\u7565\uff0c\u70ba\u56db\u500b\u985e\u578b\u5b78\u4e0a\u76f8\u8ddd\u751a\u9060\u7684\u8a9e\u8a00\u5bb6\u65cf\u5efa\u7acb\u5152\u7ae5\u5c0e\u5411\u8a00\u8a9e\u7684\u5e74\u9f61\u9806\u5e8f\u8a9e\u6599\u5eab\uff0c\u4ee5\u8de8\u8a9e\u8a00\u5730\u5be6\u65bd SSLM \u548c\u7fd2\u5f97\u555f\u767c\u8ab2\u7a0b\u3002\u6bd4\u8f03\u4e09\u500b\u5ba2\u89c0\u8ab2\u7a0b\uff08Growing\u3001Inwards \u548c MMM\uff09\u7684\u6210\u529f\uff0c\u9019\u4e9b\u8ab2\u7a0b\u7cbe\u78ba\u5730\u8907\u88fd\u4e86\u6a19\u6e96 SSLM \u67b6\u69cb\u4e0a\u7684\u7fd2\u5f97\u7406\u8ad6\u9810\u6e2c\uff0c\u6211\u5011\u767c\u73fe\u7d30\u7dfb\u7684\u7fd2\u5f97\u555f\u767c\u8ab2\u7a0b\u53ef\u4ee5\u512a\u65bc\u975e\u8ab2\u7a0b\u57fa\u6e96\uff0c\u4e26\u4e14 SSLM \u4e2d\u8ab2\u7a0b\u7b56\u7565\u7684\u6548\u80fd\u512a\u52e2\u53ef\u4ee5\u900f\u904e\u6307\u5b9a\u7cbe\u78ba\u8907\u88fd\u8a9e\u8a00\u7fd2\u5f97\u7406\u8ad6\u7684\u7d30\u7dfb\u8a9e\u8a00\u7279\u5b9a\u8ab2\u7a0b\u4f86\u7372\u5f97\u3002", "author": "Suchir Salhan et.al.", "authors": "Suchir Salhan, Richard Diehl Martinez, Z\u00e9bulon Goriely, Paula Buttery", "id": "2410.22886v1", "paper_url": "http://arxiv.org/abs/2410.22886v1", "repo": "https://github.com/suchirsalhan/mao-climb"}}