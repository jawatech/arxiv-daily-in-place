{"2409.11704": {"publish_time": "2024-09-18", "title": "From Lists to Emojis: How Format Bias Affects Model Alignment", "paper_summary": "In this paper, we study format biases in reinforcement learning from human\nfeedback (RLHF). We observe that many widely-used preference models, including\nhuman evaluators, GPT-4, and top-ranking models on the RewardBench benchmark,\nexhibit strong biases towards specific format patterns, such as lists, links,\nbold text, and emojis. Furthermore, large language models (LLMs) can exploit\nthese biases to achieve higher rankings on popular benchmarks like AlpacaEval\nand LMSYS Chatbot Arena. One notable example of this is verbosity bias, where\ncurrent preference models favor longer responses that appear more\ncomprehensive, even when their quality is equal to or lower than shorter,\ncompeting responses. However, format biases beyond verbosity remain largely\nunderexplored in the literature. In this work, we extend the study of biases in\npreference learning beyond the commonly recognized length bias, offering a\ncomprehensive analysis of a wider range of format biases. Additionally, we show\nthat with a small amount of biased data (less than 1%), we can inject\nsignificant bias into the reward model. Moreover, these format biases can also\nbe easily exploited by downstream alignment algorithms, such as best-of-n\nsampling and online iterative DPO, as it is usually easier to manipulate the\nformat than to improve the quality of responses. Our findings emphasize the\nneed to disentangle format and content both for designing alignment algorithms\nand evaluating models.", "paper_summary_zh": "<paragraph>\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86\u4eba\u985e\u56de\u994b (RLHF) \u4e2d\u5f37\u5316\u5b78\u7fd2\u7684\u683c\u5f0f\u504f\u5dee\u3002\u6211\u5011\u89c0\u5bdf\u5230\u8a31\u591a\u5ee3\u6cdb\u4f7f\u7528\u7684\u504f\u597d\u6a21\u578b\uff0c\u5305\u62ec\u4eba\u985e\u8a55\u4f30\u54e1\u3001GPT-4 \u548c RewardBench \u57fa\u6e96\u4e0a\u7684\u6392\u540d\u6700\u9ad8\u6a21\u578b\uff0c\u5c0d\u7279\u5b9a\u683c\u5f0f\u6a21\u5f0f\uff08\u4f8b\u5982\u6e05\u55ae\u3001\u9023\u7d50\u3001\u7c97\u9ad4\u6587\u5b57\u548c\u8868\u60c5\u7b26\u865f\uff09\u8868\u73fe\u51fa\u5f37\u70c8\u7684\u504f\u898b\u3002\u6b64\u5916\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u53ef\u4ee5\u5229\u7528\u9019\u4e9b\u504f\u898b\u5728 AlpacaEval \u548c LMSYS Chatbot Arena \u7b49\u71b1\u9580\u57fa\u6e96\u4e0a\u7372\u5f97\u66f4\u9ad8\u7684\u6392\u540d\u3002\u4e00\u500b\u986f\u8457\u7684\u4f8b\u5b50\u662f\u5197\u9577\u504f\u898b\uff0c\u5176\u4e2d\u7576\u524d\u7684\u504f\u597d\u6a21\u578b\u504f\u597d\u770b\u8d77\u4f86\u66f4\u5168\u9762\u7684\u8f03\u9577\u56de\u61c9\uff0c\u5373\u4f7f\u5b83\u5011\u7684\u54c1\u8cea\u7b49\u65bc\u6216\u4f4e\u65bc\u8f03\u77ed\u7684\u7af6\u722d\u56de\u61c9\u3002\u7136\u800c\uff0c\u9664\u4e86\u5197\u9577\u4e4b\u5916\u7684\u683c\u5f0f\u504f\u5dee\u5728\u6587\u737b\u4e2d\u4ecd\u7136\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u63a2\u7d22\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c07\u504f\u597d\u5b78\u7fd2\u4e2d\u504f\u5dee\u7684\u7814\u7a76\u5ef6\u4f38\u5230\u5e38\u898b\u7684\u9577\u5ea6\u504f\u5dee\u4e4b\u5916\uff0c\u63d0\u4f9b\u5c0d\u66f4\u5ee3\u6cdb\u7684\u683c\u5f0f\u504f\u5dee\u7684\u5168\u9762\u5206\u6790\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e\uff0c\u53ea\u8981\u6709\u5c11\u91cf\u7684\u504f\u5dee\u8cc7\u6599\uff08\u5c0f\u65bc 1%\uff09\uff0c\u6211\u5011\u5c31\u53ef\u4ee5\u5c07\u986f\u8457\u7684\u504f\u5dee\u6ce8\u5165\u734e\u52f5\u6a21\u578b\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u683c\u5f0f\u504f\u5dee\u4e5f\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u88ab\u4e0b\u6e38\u5c0d\u9f4a\u6f14\u7b97\u6cd5\uff08\u4f8b\u5982\u6700\u4f73 n \u63a1\u6a23\u548c\u7dda\u4e0a\u53cd\u8986 DPO\uff09\u5229\u7528\uff0c\u56e0\u70ba\u64cd\u7e31\u683c\u5f0f\u901a\u5e38\u6bd4\u63d0\u9ad8\u56de\u61c9\u54c1\u8cea\u66f4\u5bb9\u6613\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\u4e86\u5728\u8a2d\u8a08\u5c0d\u9f4a\u6f14\u7b97\u6cd5\u548c\u8a55\u4f30\u6a21\u578b\u6642\u89e3\u958b\u683c\u5f0f\u548c\u5167\u5bb9\u7684\u5fc5\u8981\u6027\u3002</paragraph>", "author": "Xuanchang Zhang et.al.", "authors": "Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang", "id": "2409.11704v1", "paper_url": "http://arxiv.org/abs/2409.11704v1", "repo": "null"}}