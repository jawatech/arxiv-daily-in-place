{"2308.08407": {"publish_time": "2023-08-16", "title": "Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities", "paper_summary": "Recent advancements in AI applications to healthcare have shown incredible\npromise in surpassing human performance in diagnosis and disease prognosis.\nWith the increasing complexity of AI models, however, concerns regarding their\nopacity, potential biases, and the need for interpretability. To ensure trust\nand reliability in AI systems, especially in clinical risk prediction models,\nexplainability becomes crucial. Explainability is usually referred to as an AI\nsystem's ability to provide a robust interpretation of its decision-making\nlogic or the decisions themselves to human stakeholders. In clinical risk\nprediction, other aspects of explainability like fairness, bias, trust, and\ntransparency also represent important concepts beyond just interpretability. In\nthis review, we address the relationship between these concepts as they are\noften used together or interchangeably. This review also discusses recent\nprogress in developing explainable models for clinical risk prediction,\nhighlighting the importance of quantitative and clinical evaluation and\nvalidation across multiple common modalities in clinical practice. It\nemphasizes the need for external validation and the combination of diverse\ninterpretability methods to enhance trust and fairness. Adopting rigorous\ntesting, such as using synthetic datasets with known generative factors, can\nfurther improve the reliability of explainability methods. Open access and\ncode-sharing resources are essential for transparency and reproducibility,\nenabling the growth and trustworthiness of explainable research. While\nchallenges exist, an end-to-end approach to explainability in clinical risk\nprediction, incorporating stakeholders from clinicians to developers, is\nessential for success.", "paper_summary_zh": "\u6700\u8fd1\u5728\u91ab\u7642\u4fdd\u5065\u4e2d\u7684\u4eba\u5de5\u667a\u6167\u61c9\u7528\u9032\u5c55\u986f\u793a\u51fa\u4ee4\u4eba\u96e3\u4ee5\u7f6e\u4fe1\u7684\u627f\u8afe\uff0c\u5728\u8a3a\u65b7\u548c\u75be\u75c5\u9810\u5f8c\u65b9\u9762\u8d85\u8d8a\u4eba\u985e\u8868\u73fe\u3002\u7136\u800c\uff0c\u96a8\u8457\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u7684\u65e5\u76ca\u8907\u96dc\uff0c\u4eba\u5011\u5c0d\u5176\u4e0d\u900f\u660e\u6027\u3001\u6f5b\u5728\u504f\u5dee\u548c\u5c0d\u53ef\u89e3\u91cb\u6027\u7684\u9700\u6c42\u611f\u5230\u64d4\u6182\u3002\u70ba\u4e86\u78ba\u4fdd\u4eba\u5de5\u667a\u80fd\u7cfb\u7d71\u7684\u4fe1\u4efb\u548c\u53ef\u9760\u6027\uff0c\u5c24\u5176\u662f\u5728\u81e8\u5e8a\u98a8\u96aa\u9810\u6e2c\u6a21\u578b\u4e2d\uff0c\u53ef\u89e3\u91cb\u6027\u8b8a\u5f97\u81f3\u95dc\u91cd\u8981\u3002\u53ef\u89e3\u91cb\u6027\u901a\u5e38\u88ab\u7a31\u70ba\u4eba\u5de5\u667a\u80fd\u7cfb\u7d71\u63d0\u4f9b\u5176\u6c7a\u7b56\u908f\u8f2f\u6216\u6c7a\u7b56\u672c\u8eab\u5c0d\u4eba\u985e\u5229\u76ca\u76f8\u95dc\u8005\u7684\u5f37\u6709\u529b\u89e3\u91cb\u7684\u80fd\u529b\u3002\u5728\u81e8\u5e8a\u98a8\u96aa\u9810\u6e2c\u4e2d\uff0c\u53ef\u89e3\u91cb\u6027\u7684\u5176\u4ed6\u65b9\u9762\uff0c\u5982\u516c\u5e73\u6027\u3001\u504f\u898b\u3001\u4fe1\u4efb\u548c\u900f\u660e\u5ea6\uff0c\u4e5f\u4ee3\u8868\u4e86\u8d85\u8d8a\u53ef\u89e3\u91cb\u6027\u7684\u91cd\u8981\u6982\u5ff5\u3002\u5728\u672c\u6b21\u5be9\u67e5\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u9019\u4e9b\u6982\u5ff5\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u56e0\u70ba\u5b83\u5011\u7d93\u5e38\u4e00\u8d77\u6216\u4e92\u63db\u4f7f\u7528\u3002\u672c\u5be9\u67e5\u9084\u8a0e\u8ad6\u4e86\u70ba\u81e8\u5e8a\u98a8\u96aa\u9810\u6e2c\u958b\u767c\u53ef\u89e3\u91cb\u6a21\u578b\u7684\u6700\u65b0\u9032\u5c55\uff0c\u5f37\u8abf\u4e86\u5728\u81e8\u5e8a\u5be6\u8e10\u4e2d\u5c0d\u591a\u7a2e\u5e38\u898b\u6a21\u5f0f\u9032\u884c\u5b9a\u91cf\u548c\u81e8\u5e8a\u8a55\u4f30\u548c\u9a57\u8b49\u7684\u91cd\u8981\u6027\u3002\u5b83\u5f37\u8abf\u4e86\u5916\u90e8\u9a57\u8b49\u548c\u591a\u6a23\u5316\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u76f8\u7d50\u5408\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u589e\u5f37\u4fe1\u4efb\u548c\u516c\u5e73\u6027\u3002\u63a1\u7528\u56b4\u683c\u7684\u6e2c\u8a66\uff0c\u4f8b\u5982\u4f7f\u7528\u5177\u6709\u5df2\u77e5\u751f\u6210\u56e0\u7d20\u7684\u5408\u6210\u6578\u64da\u96c6\uff0c\u53ef\u4ee5\u9032\u4e00\u6b65\u63d0\u9ad8\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002\u958b\u653e\u7372\u53d6\u548c\u4ee3\u78bc\u5171\u4eab\u8cc7\u6e90\u5c0d\u65bc\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u8907\u6027\u81f3\u95dc\u91cd\u8981\uff0c\u5f9e\u800c\u4fc3\u9032\u53ef\u89e3\u91cb\u7814\u7a76\u7684\u589e\u9577\u548c\u53ef\u4fe1\u5ea6\u3002\u5118\u7ba1\u5b58\u5728\u6311\u6230\uff0c\u4f46\u5f9e\u81e8\u5e8a\u91ab\u751f\u5230\u958b\u767c\u4eba\u54e1\uff0c\u63a1\u7528\u7aef\u5230\u7aef\u7684\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u5c0d\u65bc\u81e8\u5e8a\u98a8\u96aa\u9810\u6e2c\u7684\u6210\u529f\u81f3\u95dc\u91cd\u8981\u3002", "author": "Munib Mesinovic et.al.", "authors": "Munib Mesinovic, Peter Watkinson, Tingting Zhu", "id": "2308.08407v1", "paper_url": "http://arxiv.org/abs/2308.08407v1", "repo": "null"}}