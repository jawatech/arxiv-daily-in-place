{"2410.08085": {"publish_time": "2024-10-10", "title": "Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering", "paper_summary": "Recent works integrating Knowledge Graphs (KGs) have led to promising\nimprovements in enhancing reasoning accuracy of Large Language Models (LLMs).\nHowever, current benchmarks mainly focus on closed tasks, leaving a gap in the\nassessment of more complex, real-world scenarios. This gap has also obscured\nthe evaluation of KGs' potential to mitigate the problem of hallucination in\nLLMs. To fill the gap, we introduce OKGQA, a new benchmark specifically\ndesigned to assess LLMs enhanced with KGs under open-ended, real-world question\nanswering scenarios. OKGQA is designed to closely reflect the complexities of\npractical applications using questions from different types, and incorporates\nspecific metrics to measure both the reduction in hallucinations and the\nenhancement in reasoning capabilities. To consider the scenario in which KGs\nmay have varying levels of mistakes, we further propose another experiment\nsetting OKGQA-P to assess model performance when the semantics and structure of\nKGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore\nwhether KGs can make LLMs more trustworthy in an open-ended setting, and (2)\nconduct a comparative analysis to shed light on methods and future directions\nfor leveraging KGs to reduce LLMs' hallucination. We believe that this study\ncan facilitate a more complete performance comparison and encourage continuous\nimprovement in integrating KGs with LLMs.", "paper_summary_zh": "\u8fd1\u671f\u7684\u77e5\u8bc6\u56fe\u8c31 (KG) \u6574\u5408\u7814\u7a76\uff0c\u5df2\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u63a8\u7406\u51c6\u786e\u5ea6\u7684\u8868\u73b0\u3002\n\u7136\u800c\uff0c\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u7740\u91cd\u4e8e\u5c01\u95ed\u5f0f\u4efb\u52a1\uff0c\u5728\u8bc4\u4f30\u66f4\u590d\u6742\u3001\u66f4\u5b9e\u9645\u7684\u573a\u666f\u65f6\u5b58\u5728\u7f3a\u53e3\u3002\u6b64\u7f3a\u53e3\u4e5f\u6a21\u7cca\u4e86\u77e5\u8bc6\u56fe\u8c31\u5728\u51cf\u8f7b LLM \u5e7b\u89c9\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\u8bc4\u4f30\u3002\u4e3a\u4e86\u586b\u8865\u6b64\u7f3a\u53e3\uff0c\u6211\u4eec\u5f15\u5165\u4e86 OKGQA\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7528\u6765\u8bc4\u4f30\u5728\u5f00\u653e\u5f0f\u3001\u5b9e\u9645\u95ee\u7b54\u573a\u666f\u4e2d\uff0c\u589e\u5f3a\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684 LLM \u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u3002OKGQA \u65e8\u5728\u7d27\u5bc6\u53cd\u6620\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u590d\u6742\u6027\uff0c\u4f7f\u7528\u4e0d\u540c\u7c7b\u578b\u7684\u9898\u76ee\uff0c\u5e76\u7eb3\u5165\u7279\u5b9a\u6307\u6807\u6765\u8861\u91cf\u5e7b\u89c9\u7684\u51cf\u5c11\u548c\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\u3002\u4e3a\u4e86\u8003\u8651\u77e5\u8bc6\u56fe\u8c31\u53ef\u80fd\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u9519\u8bef\u7684\u573a\u666f\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u53e6\u4e00\u4e2a\u5b9e\u9a8c\u8bbe\u7f6e OKGQA-P\uff0c\u4ee5\u8bc4\u4f30\u5f53\u77e5\u8bc6\u56fe\u8c31\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u88ab\u6545\u610f\u6270\u52a8\u548c\u6c61\u67d3\u65f6\u7684\u6a21\u578b\u6027\u80fd\u3002OKGQA \u65e8\u5728 (1) \u63a2\u7d22\u77e5\u8bc6\u56fe\u8c31\u662f\u5426\u80fd\u4f7f LLM \u5728\u5f00\u653e\u5f0f\u8bbe\u7f6e\u4e2d\u66f4\u503c\u5f97\u4fe1\u8d56\uff0c\u4ee5\u53ca (2) \u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u4ee5\u9610\u660e\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u6765\u51cf\u5c11 LLM \u5e7b\u89c9\u7684\u65b9\u6cd5\u548c\u672a\u6765\u65b9\u5411\u3002\u6211\u4eec\u76f8\u4fe1\u8fd9\u9879\u7814\u7a76\u53ef\u4ee5\u4fc3\u8fdb\u66f4\u5b8c\u6574\u7684\u6027\u80fd\u6bd4\u8f83\uff0c\u5e76\u9f13\u52b1\u6301\u7eed\u6539\u8fdb\u77e5\u8bc6\u56fe\u8c31\u4e0e LLM \u7684\u6574\u5408\u3002", "author": "Yuan Sui et.al.", "authors": "Yuan Sui, Bryan Hooi", "id": "2410.08085v1", "paper_url": "http://arxiv.org/abs/2410.08085v1", "repo": "null"}}