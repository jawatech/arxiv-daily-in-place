# arxiv-daily
 Automated deployment @ 2025-02-20 09:06:03 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-18**|**Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions**|Taedong Yun et.al.|[2502.13135v1](http://arxiv.org/abs/2502.13135v1)|null|
|**2025-02-18**|**Improving Clinical Question Answering with Multi-Task Learning: A Joint Approach for Answer Extraction and Medical Categorization**|Priyaranjan Pattnayak et.al.|[2502.13108v1](http://arxiv.org/abs/2502.13108v1)|null|
|**2025-02-18**|**Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection**|Athira J Jacob et.al.|[2502.12948v1](http://arxiv.org/abs/2502.12948v1)|null|
|**2025-02-18**|**Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models**|Rubing Lu et.al.|[2502.12825v1](http://arxiv.org/abs/2502.12825v1)|null|
|**2025-02-18**|**LLM Safety for Children**|Prasanjit Rath et.al.|[2502.12552v1](http://arxiv.org/abs/2502.12552v1)|null|
|**2025-02-17**|**Classifiers of Data Sharing Statements in Clinical Trial Records**|Saber Jelodari Mamaghani et.al.|[2502.12362v1](http://arxiv.org/abs/2502.12362v1)|null|
|**2025-02-17**|**Relational Norms for Human-AI Cooperation**|Brian D. Earp et.al.|[2502.12102v1](http://arxiv.org/abs/2502.12102v1)|null|
|**2025-02-17**|**Deep Spatio-Temporal Neural Network for Air Quality Reanalysis**|Ammar Kheder et.al.|[2502.11941v1](http://arxiv.org/abs/2502.11941v1)|null|
|**2025-02-17**|**Proactive Depot Discovery: A Generative Framework for Flexible Location-Routing**|Site Qu et.al.|[2502.11715v1](http://arxiv.org/abs/2502.11715v1)|null|
|**2025-02-17**|**LLM Agents Making Agent Tools**|Georg WÃ¶lflein et.al.|[2502.11705v1](http://arxiv.org/abs/2502.11705v1)|null|
|**2025-02-17**|**MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression**|Linjie Mu et.al.|[2502.11651v1](http://arxiv.org/abs/2502.11651v1)|null|
|**2025-02-17**|**A Survey of Personalized Large Language Models: Progress and Future Directions**|Jiahong Liu et.al.|[2502.11528v1](http://arxiv.org/abs/2502.11528v1)|null|
|**2025-02-17**|**Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos**|Xiangxiang Cui et.al.|[2502.11481v1](http://arxiv.org/abs/2502.11481v1)|null|
|**2025-02-17**|**Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning Network for Semi-supervised 3D Medical Image Segmentation**|Yanyan Wang et.al.|[2502.11456v1](http://arxiv.org/abs/2502.11456v1)|null|
|**2025-02-16**|**A Survey of LLM-based Agents in Medicine: How far are we from Baymax?**|Wenxuan Wang et.al.|[2502.11211v1](http://arxiv.org/abs/2502.11211v1)|null|
|**2025-02-16**|**RT-DEMT: A hybrid real-time acupoint detection model combining mamba and transformer**|Shilong Yang et.al.|[2502.11179v1](http://arxiv.org/abs/2502.11179v1)|null|
|**2025-02-16**|**Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications**|Alexandru Lecu et.al.|[2502.11108v1](http://arxiv.org/abs/2502.11108v1)|null|
|**2025-02-16**|**Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration**|Xianbing Zhao et.al.|[2502.12204v1](http://arxiv.org/abs/2502.12204v1)|null|
|**2025-02-16**|**CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening**|Gen Zhou et.al.|[2502.11001v1](http://arxiv.org/abs/2502.11001v1)|null|
|**2025-02-15**|**Automatic Quality Assessment of First Trimester Crown-Rump-Length Ultrasound Images**|Sevim Cengiz et.al.|[2502.10908v1](http://arxiv.org/abs/2502.10908v1)|null|
|**2025-02-15**|**Breaking Down the Hierarchy: A New Approach to Leukemia Classification**|Ibraheem Hamdi et.al.|[2502.10899v1](http://arxiv.org/abs/2502.10899v1)|null|
|**2025-02-15**|**An Empirical Analysis of Uncertainty in Large Language Model Evaluations**|Qiujie Xie et.al.|[2502.10709v1](http://arxiv.org/abs/2502.10709v1)|null|
|**2025-02-15**|**Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model**|Jiarui Jin et.al.|[2502.10707v1](http://arxiv.org/abs/2502.10707v1)|[link](https://github.com/pkudigitalhealth/heartlang)|
|**2025-02-15**|**Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction**|Leisheng Yu et.al.|[2502.10689v1](http://arxiv.org/abs/2502.10689v1)|null|
|**2025-02-15**|**ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language Interactions for Computer-Aided Diagnosis**|Xueshen Li et.al.|[2502.10620v1](http://arxiv.org/abs/2502.10620v1)|null|
|**2025-02-15**|**Optimizing CNN Architectures for Advanced Thoracic Disease Classification**|Tejas Mirthipati et.al.|[2502.10614v1](http://arxiv.org/abs/2502.10614v1)|null|
|**2025-02-14**|**PolyPath: Adapting a Large Multimodal Model for Multi-slide Pathology Report Generation**|Faruk Ahmed et.al.|[2502.10536v1](http://arxiv.org/abs/2502.10536v1)|null|
|**2025-02-14**|**Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks**|Venkatesh Sivaraman et.al.|[2502.10526v1](http://arxiv.org/abs/2502.10526v1)|null|
|**2025-02-14**|**A Robust Attack: Displacement Backdoor Attack**|Yong Li et.al.|[2502.10490v1](http://arxiv.org/abs/2502.10490v1)|null|
|**2025-02-14**|**3D ReX: Causal Explanations in 3D Neuroimaging Classification**|Melane Navaratnarajah et.al.|[2502.12181v1](http://arxiv.org/abs/2502.12181v1)|null|
|**2025-02-14**|**Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model**|Jin Cui et.al.|[2502.09947v1](http://arxiv.org/abs/2502.09947v1)|null|
|**2025-02-14**|**TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation**|Ju-Hyeon Nam et.al.|[2502.09931v1](http://arxiv.org/abs/2502.09931v1)|null|
|**2025-02-14**|**Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos**|Weirui Ye et.al.|[2502.09886v1](http://arxiv.org/abs/2502.09886v1)|null|
|**2025-02-14**|**HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation**|Tianwei Lin et.al.|[2502.09838v2](http://arxiv.org/abs/2502.09838v2)|null|
|**2025-02-13**|**Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games**|Tong Yang et.al.|[2502.09780v1](http://arxiv.org/abs/2502.09780v1)|null|
|**2025-02-13**|**The AI-Therapist Duo: Exploring the Potential of Human-AI Collaboration in Personalized Art Therapy for PICS Intervention**|Bereket A. Yilma et.al.|[2502.09757v1](http://arxiv.org/abs/2502.09757v1)|null|
|**2025-02-13**|**A CNN Approach to Automated Detection and Classification of Brain Tumors**|Md. Zahid Hasan et.al.|[2502.09731v1](http://arxiv.org/abs/2502.09731v1)|null|
|**2025-02-13**|**Evaluating GPT's Capability in Identifying Stages of Cognitive Impairment from Electronic Health Data**|Yu Leng et.al.|[2502.09715v1](http://arxiv.org/abs/2502.09715v1)|null|
|**2025-02-13**|**Metamorphic Testing for Pose Estimation Systems**|Matias Duran et.al.|[2502.09460v1](http://arxiv.org/abs/2502.09460v1)|null|
|**2025-02-13**|**Towards Virtual Clinical Trials of Radiology AI with Conditional Generative Modeling**|Benjamin D. Killeen et.al.|[2502.09688v1](http://arxiv.org/abs/2502.09688v1)|null|
|**2025-02-13**|**Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models**|Wiktoria Mieleszczenko-Kowszewicz et.al.|[2502.09687v1](http://arxiv.org/abs/2502.09687v1)|null|
|**2025-02-13**|**The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics**|Danni Feng et.al.|[2502.09247v1](http://arxiv.org/abs/2502.09247v1)|null|
|**2025-02-13**|**From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine**|Lukas Buess et.al.|[2502.09242v1](http://arxiv.org/abs/2502.09242v1)|null|
|**2025-02-13**|**Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**|Flavio Bertini et.al.|[2502.09218v1](http://arxiv.org/abs/2502.09218v1)|null|
|**2025-02-13**|**Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York**|Sanskar Sehgal et.al.|[2502.09204v1](http://arxiv.org/abs/2502.09204v1)|null|
|**2025-02-13**|**Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia**|Jin Cui et.al.|[2502.09173v1](http://arxiv.org/abs/2502.09173v1)|null|
|**2025-02-13**|**TastepepAI, An artificial intelligence platform for taste peptide de novo design**|Jianda Yue et.al.|[2502.12167v1](http://arxiv.org/abs/2502.12167v1)|null|
|**2025-02-12**|**HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification**|Valentina Vadori et.al.|[2502.08754v1](http://arxiv.org/abs/2502.08754v1)|[link](https://github.com/Vadori/CytoArk)|
|**2025-02-12**|**Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion**|Lemuel Puglisi et.al.|[2502.08560v1](http://arxiv.org/abs/2502.08560v1)|[link](https://github.com/lemuelpuglisi/brlp)|
|**2025-02-12**|**Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**|Doudou Zhou et.al.|[2502.08547v1](http://arxiv.org/abs/2502.08547v1)|null|
|**2025-02-12**|**EEG Artifact Detection and Correction with Deep Autoencoders**|David AquiluÃ©-Llorens et.al.|[2502.08686v1](http://arxiv.org/abs/2502.08686v1)|null|
|**2025-02-12**|**SycEval: Evaluating LLM Sycophancy**|Aaron Fanous et.al.|[2502.08177v1](http://arxiv.org/abs/2502.08177v1)|null|
|**2025-02-12**|**Cancer Vaccine Adjuvant Name Recognition from Biomedical Literature using Large Language Models**|Hasin Rehana et.al.|[2502.09659v1](http://arxiv.org/abs/2502.09659v1)|null|
|**2025-02-11**|**Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?**|Hye Sun Yun et.al.|[2502.07963v1](http://arxiv.org/abs/2502.07963v1)|null|
|**2025-02-11**|**An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating**|Mohammad Ali Labbaf Khaniki et.al.|[2502.07755v1](http://arxiv.org/abs/2502.07755v1)|null|
|**2025-02-11**|**Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension**|Wenbo Gong et.al.|[2502.07752v1](http://arxiv.org/abs/2502.07752v1)|null|
|**2025-02-11**|**The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation**|Raman Dutt et.al.|[2502.07516v2](http://arxiv.org/abs/2502.07516v2)|[link](https://github.com/Raman1121/diffusion_memorization)|
|**2025-02-11**|**KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level**|Ruining Deng et.al.|[2502.07288v1](http://arxiv.org/abs/2502.07288v1)|[link](https://github.com/agaldran/kpis)|
|**2025-02-11**|**Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer**|Jiaying Lu et.al.|[2502.07158v2](http://arxiv.org/abs/2502.07158v2)|null|
|**2025-02-11**|**Explaining 3D Computed Tomography Classifiers with Counterfactuals**|Joseph Paul Cohen et.al.|[2502.07156v1](http://arxiv.org/abs/2502.07156v1)|[link](https://github.com/ieee8023/ct-counterfactuals)|
|**2025-02-10**|**Interactive Data Harmonization with LLM Agents**|AÃ©cio Santos et.al.|[2502.07132v1](http://arxiv.org/abs/2502.07132v1)|null|
|**2025-02-10**|**Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML**|Mohammad Amir Salari et.al.|[2502.07026v1](http://arxiv.org/abs/2502.07026v1)|null|
|**2025-02-10**|**AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements**|Adriana Eufrosiana Bora et.al.|[2502.07022v1](http://arxiv.org/abs/2502.07022v1)|null|
|**2025-02-10**|**Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium**|Amin Adibi et.al.|[2502.06693v1](http://arxiv.org/abs/2502.06693v1)|null|
|**2025-02-10**|**Automatic Evaluation of Healthcare LLMs Beyond Question-Answering**|Anna Arias-Duart et.al.|[2502.06666v1](http://arxiv.org/abs/2502.06666v1)|null|
|**2025-02-10**|**Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging**|Mohammed Abdul Hafeez Khan et.al.|[2502.06632v1](http://arxiv.org/abs/2502.06632v1)|null|
|**2025-02-10**|**Illegal Waste Detection in Remote Sensing Images: A Case Study**|Federico Gibellini et.al.|[2502.06607v2](http://arxiv.org/abs/2502.06607v2)|null|
|**2025-02-10**|**FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model**|Anna Tegon et.al.|[2502.06438v1](http://arxiv.org/abs/2502.06438v1)|null|
|**2025-02-10**|**Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?**|Qingshan Hou et.al.|[2502.06289v1](http://arxiv.org/abs/2502.06289v1)|null|
|**2025-02-10**|**Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning**|Liuqing Chen et.al.|[2502.06134v1](http://arxiv.org/abs/2502.06134v1)|null|
|**2025-02-10**|**Foundation Model of Electronic Medical Records for Adaptive Risk Estimation**|Pawel Renc et.al.|[2502.06124v1](http://arxiv.org/abs/2502.06124v1)|null|
|**2025-02-10**|**Can ChatGPT Diagnose Alzheimer's Disease?**|Quoc-Toan Nguyen et.al.|[2502.06907v1](http://arxiv.org/abs/2502.06907v1)|null|
|**2025-02-09**|**Protecting Intellectual Property of EEG-based Neural Networks with Watermarking**|Ahmed Abdelaziz et.al.|[2502.05931v1](http://arxiv.org/abs/2502.05931v1)|[link](https://github.com/Prog-Jacob/watermarking-eeg-models)|
|**2025-02-09**|**Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models**|Shiyu Teng et.al.|[2502.05879v1](http://arxiv.org/abs/2502.05879v1)|null|
|**2025-02-09**|**LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison**|Gabriele De Vito et.al.|[2502.06890v1](http://arxiv.org/abs/2502.06890v1)|null|
|**2025-02-09**|**Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm)**|Lokesh Koli et.al.|[2502.07815v1](http://arxiv.org/abs/2502.07815v1)|null|
|**2025-02-09**|**WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch**|Ying Lei et.al.|[2502.05783v1](http://arxiv.org/abs/2502.05783v1)|null|
|**2025-02-09**|**RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care**|Ziqi Yang et.al.|[2502.05740v1](http://arxiv.org/abs/2502.05740v1)|null|
|**2025-02-08**|**4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis**|An Zhao et.al.|[2502.05713v1](http://arxiv.org/abs/2502.05713v1)|null|
|**2025-02-08**|**KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy**|Hyunjong Kim et.al.|[2502.05651v1](http://arxiv.org/abs/2502.05651v1)|null|
|**2025-02-08**|**ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports**|Aynur Guluzade et.al.|[2502.05638v1](http://arxiv.org/abs/2502.05638v1)|[link](https://gitlab.cc-asp.fraunhofer.de/health-open/elmtex)|
|**2025-02-08**|**Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection**|Ya Zhou et.al.|[2502.05494v1](http://arxiv.org/abs/2502.05494v1)|null|
|**2025-02-08**|**DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability**|Sibasish Dhibar et.al.|[2502.05459v1](http://arxiv.org/abs/2502.05459v1)|null|
|**2025-02-07**|**Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge**|Muhammad Imran et.al.|[2502.05330v1](http://arxiv.org/abs/2502.05330v1)|[link](https://github.com/MaxwellEng/MICCAI_CHANLLENGE24_HJL)|
|**2025-02-07**|**Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning**|Yuting He et.al.|[2502.05282v1](http://arxiv.org/abs/2502.05282v1)|null|
|**2025-02-07**|**"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**|Shihan Fu et.al.|[2502.05115v1](http://arxiv.org/abs/2502.05115v1)|null|
|**2025-02-07**|**Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**|Thierry Bossy et.al.|[2502.05087v1](http://arxiv.org/abs/2502.05087v1)|[link](https://github.com/tuneinsight/federated-llms)|
|**2025-02-07**|**MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**|Minrui Chen et.al.|[2502.04794v2](http://arxiv.org/abs/2502.04794v2)|null|
|**2025-02-06**|**MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification**|Wei Fan et.al.|[2502.04515v1](http://arxiv.org/abs/2502.04515v1)|[link](https://github.com/aikunyi/MedGNN)|
|**2025-02-06**|**Integrating Generative Artificial Intelligence in ADRD: A Framework for Streamlining Diagnosis and Care in Neurodegenerative Diseases**|Andrew G. Breithaupt et.al.|[2502.06842v1](http://arxiv.org/abs/2502.06842v1)|null|
|**2025-02-06**|**Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions**|Khushboo Verma et.al.|[2502.04423v1](http://arxiv.org/abs/2502.04423v1)|null|
|**2025-02-06**|**Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**|Tewele W. Tareke et.al.|[2502.04083v1](http://arxiv.org/abs/2502.04083v1)|null|
|**2025-02-06**|**Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**|Ran Song et.al.|[2502.04034v1](http://arxiv.org/abs/2502.04034v1)|null|
|**2025-02-06**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413v1](http://arxiv.org/abs/2502.04413v1)|[link](https://github.com/snowteam2023/medrag)|
|**2025-02-06**|**Transforming Multimodal Models into Action Models for Radiotherapy**|Matteo Ferrante et.al.|[2502.04408v1](http://arxiv.org/abs/2502.04408v1)|null|
|**2025-02-06**|**Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning**|Bokeng Zheng et.al.|[2502.04399v1](http://arxiv.org/abs/2502.04399v1)|null|
|**2025-02-06**|**Multimodal Medical Code Tokenizer**|Xiaorui Su et.al.|[2502.04397v2](http://arxiv.org/abs/2502.04397v2)|null|
|**2025-02-06**|**A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**|Chaoyin She et.al.|[2502.03772v1](http://arxiv.org/abs/2502.03772v1)|[link](https://github.com/Asunatan/HSQformer)|
|**2025-02-05**|**Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings**|Guangyao Zheng et.al.|[2502.04386v1](http://arxiv.org/abs/2502.04386v1)|[link](https://github.com/BioIntelligence-Lab/VAE-Adversarial-Debiasing)|
|**2025-02-05**|**Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function**|Mehrdad Asadi et.al.|[2502.03591v1](http://arxiv.org/abs/2502.03591v1)|[link](https://github.com/the-mercury/CIHMLC)|

#### Abstracts
##### **Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions**
2502.13135v1 by Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Schneider, Isaac Galatzer-Levy, Yugang Jia, John Canny, Arthur Gretton, Maja MatariÄ

We present an end-to-end framework for generating synthetic users for
evaluating interactive agents designed to encourage positive behavior changes,
such as in health and lifestyle coaching. The synthetic users are grounded in
health and lifestyle conditions, specifically sleep and diabetes management in
this study, to ensure realistic interactions with the health coaching agent.
Synthetic users are created in two stages: first, structured data are generated
grounded in real-world health and lifestyle factors in addition to basic
demographics and behavioral attributes; second, full profiles of the synthetic
users are developed conditioned on the structured data. Interactions between
synthetic users and the coaching agent are simulated using generative
agent-based models such as Concordia, or directly by prompting a language
model. Using two independently-developed agents for sleep and diabetes coaching
as case studies, the validity of this framework is demonstrated by analyzing
the coaching agent's understanding of the synthetic users' needs and
challenges. Finally, through multiple blinded evaluations of user-coach
interactions by human experts, we demonstrate that our synthetic users with
health and behavioral attributes more accurately portray real human users with
the same attributes, compared to generic synthetic users not grounded in such
attributes. The proposed framework lays the foundation for efficient
development of conversational agents through extensive, realistic, and grounded
simulated interactions.

æè¦ï¼<paragraph>æåæä¾äºä¸åç«¯å°ç«¯çæ¶æ§ï¼ç¨æ¼çºè©ä¼°äºåå¼ä»£ççæåæä½¿ç¨èï¼éäºä»£çæ¨å¨é¼åµæ­£åè¡çºæ¹è®ï¼ä¾å¦å¥åº·åçæ´»æ¹å¼æå°ãåæä½¿ç¨èä»¥å¥åº·åçæ´»æ¹å¼çæ³çºåºç¤ï¼ç¹å¥æ¯æ¬ç ç©¶ä¸­çç¡ç åç³å°¿çç®¡çï¼ä»¥ç¢ºä¿èå¥åº·æå°ä»£ççäºåå·æçå¯¦æ§ãåæä½¿ç¨èåå©åéæ®µå»ºç«ï¼é¦åï¼é¤äºåºæ¬äººå£çµ±è¨è³æåè¡çºå±¬æ§å¤ï¼éæç¢çä»¥ç¾å¯¦ä¸ççå¥åº·åçæ´»æ¹å¼å ç´ çºåºç¤ççµæ§åè³æï¼å¶æ¬¡ï¼ææ ¹æçµæ§åè³æéç¼åæä½¿ç¨èçå®æ´åäººè³æãåæä½¿ç¨èåæå°ä»£çä¹éçäºåæ¯ä½¿ç¨çæå¼åºæ¼ä»£ççæ¨¡åï¼ä¾å¦ Concordiaï¼æ¨¡æ¬çï¼æèç´æ¥ééæç¤ºèªè¨æ¨¡åä¾æ¨¡æ¬ãä½¿ç¨å©åç¨ç«éç¼çç¡ç åç³å°¿çæå°ä»£çä½çºæ¡ä¾ç ç©¶ï¼ééåææå°ä»£çå°åæä½¿ç¨èéæ±åææ°ççè§£ï¼è­æäºæ­¤æ¶æ§çæææ§ãæå¾ï¼ééäººé¡å°å®¶å°ä½¿ç¨èæå°äºåé²è¡å¤éç²æ¸¬è©ä¼°ï¼æåè­æäºèæªä»¥éäºå±¬æ§çºåºç¤çéç¨åæä½¿ç¨èç¸æ¯ï¼å·æå¥åº·åè¡çºå±¬æ§çåæä½¿ç¨èæ´æºç¢ºå°æç¹ªäºå·æç¸åå±¬æ§ççå¯¦äººé¡ä½¿ç¨èãææåºçæ¶æ§çºééå»£æ³ãçå¯¦ä¸ææ ¹æçæ¨¡æ¬äºåï¼çºå°è©±ä»£ççææéç¼å¥ å®äºåºç¤ã</paragraph>

##### **Improving Clinical Question Answering with Multi-Task Learning: A Joint Approach for Answer Extraction and Medical Categorization**
2502.13108v1 by Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Amit Agarwal, Bhargava Kumar, Srikant Panda, Tejaswini Kumar

Clinical Question Answering (CQA) plays a crucial role in medical
decision-making, enabling physicians to extract relevant information from
Electronic Medical Records (EMRs). While transformer-based models such as BERT,
BioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in
CQA, existing models lack the ability to categorize extracted answers, which is
critical for structured retrieval, content filtering, and medical decision
support.
  To address this limitation, we introduce a Multi-Task Learning (MTL)
framework that jointly trains CQA models for both answer extraction and medical
categorization. In addition to predicting answer spans, our model classifies
responses into five standardized medical categories: Diagnosis, Medication,
Symptoms, Procedure, and Lab Reports. This categorization enables more
structured and interpretable outputs, making clinical QA models more useful in
real-world healthcare settings.
  We evaluate our approach on emrQA, a large-scale dataset for medical question
answering. Results show that MTL improves F1-score by 2.2% compared to standard
fine-tuning, while achieving 90.7% accuracy in answer categorization. These
findings suggest that MTL not only enhances CQA performance but also introduces
an effective mechanism for categorization and structured medical information
retrieval.

æè¦ï¼<paragraph>è¨åºåç­ (CQA) å¨é«çæ±ºç­ä¸­æ®æ¼èè³ééè¦çè§è²ï¼è®é«å¸«è½å¤ å¾é»å­çæ­· (EMR) ä¸­æ·åç¸éè³è¨ãåç®¡ BERTãBioBERT å ClinicalBERT ç­åºæ¼è½æå¨çæ¨¡åå·²å¨ CQA ä¸­å±ç¾åºæåé²çæè½ï¼ä½ç¾æçæ¨¡åç¼ºä¹åé¡æ·åç­æ¡çè½åï¼éå°æ¼çµæ§åæª¢ç´¢ãå§å®¹éæ¿¾åé«çæ±ºç­æ¯æ´è³ééè¦ã
  çºäºè§£æ±ºéåéå¶ï¼æåå¼é²äºä¸åå¤ä»»åå­¸ç¿ (MTL) æ¶æ§ï¼å®åæè¨ç·´ CQA æ¨¡åç¨æ¼ç­æ¡æ·ååé«çåé¡ãé¤äºé æ¸¬ç­æ¡ç¯åï¼æåçæ¨¡åå°åæåé¡çºäºåæ¨æºåé«çé¡å¥ï¼è¨ºæ·ãè¥ç©ãççãç¨åºåå¯¦é©å®¤å ±åãéç¨®åé¡è½ç¢çæ´çµæ§åä¸ææ¼çè§£çè¼¸åºï¼è®è¨åºåç­æ¨¡åå¨çå¯¦ä¸ççé«çä¿å¥ç°å¢ä¸­æ´å¯¦ç¨ã
  æåå¨ emrQA ä¸è©ä¼°æåçåæ³ï¼emrQA æ¯ç¨æ¼é«çåé¡è§£ç­çå¤§è¦æ¨¡è³æéãçµæé¡¯ç¤ºï¼èæ¨æºå¾®èª¿ç¸æ¯ï¼MTL å° F1 åæ¸æé«äº 2.2%ï¼åæå¨ç­æ¡åé¡ä¸­éå° 90.7% çæºç¢ºåº¦ãéäºç¼ç¾è¡¨æï¼MTL ä¸åå¢å¼·äº CQA çæè½ï¼éå¼å¥äºä¸ç¨®åé¡åçµæ§åé«çè³è¨æª¢ç´¢çæææ©å¶ã</paragraph>

##### **Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection**
2502.12948v1 by Athira J Jacob, Puneet Sharma, Daniel Rueckert

Detection of hyperenhancement from cardiac LGE MRI images is a complex task
requiring significant clinical expertise. Although deep learning-based models
have shown promising results for the task, they require large amounts of data
with fine-grained annotations. Clinical reports generated for cardiac MR
studies contain rich, clinically relevant information, including the location,
extent and etiology of any scars present. Although recently developed
CLIP-based training enables pretraining models with image-text pairs, it
requires large amounts of data and further finetuning strategies on downstream
tasks. In this study, we use various strategies rooted in domain knowledge to
train a model for LGE detection solely using text from clinical reports, on a
relatively small clinical cohort of 965 patients. We improve performance
through the use of synthetic data augmentation, by systematically creating scar
images and associated text. In addition, we standardize the orientation of the
images in an anatomy-informed way to enable better alignment of spatial and
text features. We also use a captioning loss to enable fine-grained supervision
and explore the effect of pretraining of the vision encoder on performance.
Finally, ablation studies are carried out to elucidate the contributions of
each design component to the overall performance of the model.

æè¦ï¼å¾å¿è LGE MRI å½±ååµæ¸¬åºéåº¦å¢å¼·æ¯ä¸é è¤éçä»»åï¼éè¦é¡¯èçè¨åºå°æ¥­ç¥è­ãåç®¡åºæ¼æ·±åº¦å­¸ç¿çæ¨¡åå·²é¡¯ç¤ºåºå°éé ä»»åæåæ¯ççµæï¼ä½å®åéè¦å¤§éå·æç´°ç·»è¨»è§£çè³æãçºå¿è MR ç ç©¶ç¢ççè¨åºå ±ååå«è±å¯ä¸è¨åºä¸ç¸éçè³è¨ï¼åæ¬ä»»ä½ç¤ççä½ç½®ãç¯ååçå ãåç®¡æè¿éç¼çåºæ¼ CLIP çè¨ç·´è½ä½¿ç¨å½±åæå­å°é è¨ç·´æ¨¡åï¼ä½å®éè¦å¤§éè³æåé²ä¸æ­¥å¾®èª¿ä¸æ¸¸ä»»åçç­ç¥ãå¨éé ç ç©¶ä¸­ï¼æåä½¿ç¨æ¤åºæ¼é åç¥è­çåç¨®ç­ç¥ï¼åä½¿ç¨ä¾èªè¨åºå ±åçæå­ï¼å¨ä¸åç¸å°è¼å°ç 965 åæ£èè¨åºç¾¤é«ä¸­è¨ç·´ä¸å LGE åµæ¸¬æ¨¡åãæåééä½¿ç¨åæè³ææ´åä¾æ¹åæè½ï¼ç³»çµ±æ§å°å»ºç«ç¤çå½±ååç¸éæå­ãæ­¤å¤ï¼æåä»¥è§£åå­¸åç¥çæ¹å¼æ¨æºåå½±åæ¹åï¼ä»¥ä½¿ç©ºéåæå­ç¹å¾µè½æ´å¥½å°å°é½ãæåä¹ä½¿ç¨æ¨é¡æå¤±ä¾åç¨ç´°ç·»çç£ç£ï¼ä¸¦æ¢è¨è¦è¦ºç·¨ç¢¼å¨çé è¨ç·´å°æè½çå½±é¿ãæå¾ï¼é²è¡æ¶èç ç©¶ä»¥é¡ææ¯åè¨­è¨åä»¶å°æ¨¡åæ´é«æè½çè²¢ç»ã

##### **Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models**
2502.12825v1 by Rubing Lu, JoÃ£o Sedoc, Arun Sundararajan

When encountering increasingly frequent performance improvements or cost
reductions from a new large language model (LLM), developers of applications
leveraging LLMs must decide whether to take advantage of these improvements or
stay with older tried-and-tested models. Low perceived switching frictions can
lead to choices that do not consider more subtle behavior changes that the
transition may induce. Our experiments use a popular game-theoretic behavioral
economics model of trust to show stark differences in the trusting behavior of
OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust
behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing
and risk-seeking with future returns from trust, and contrast it with
DeepSeek's more sophisticated and profitable trusting behavior that stems from
an ability to incorporate deeper concepts like forward planning and
theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our
results highlight the perils of relying on LLM performance benchmarks that are
too narrowly defined and suggest that careful analysis of their hidden fault
lines should be part of any organization's AI strategy.

æè¦ï¼ç¶éå°è¶ä¾è¶é »ç¹çæè½æåæä¾èªæ¼æ°çå¤§åèªè¨æ¨¡å (LLM) çææ¬éä½æï¼å©ç¨ LLM çæç¨ç¨å¼éç¼äººå¡å¿é æ±ºå®æ¯å¦è¦å©ç¨éäºæåæç¶­æè¼èä¸ç¶éæ¸¬è©¦çæ¨¡åãä½æç¥åææ©æ¦å¯è½æå°è´é¸æä¸èæ®è½æå¯è½èªç¼çæ´ç´°å¾®çè¡çºæ¹è®ãæåçå¯¦é©ä½¿ç¨ä¿¡ä»»çæµè¡åå¼è«è¡çºç¶æ¿æ¨¡åä¾é¡¯ç¤º OpenAI å DeepSeek æ¨¡åå¨ä¿¡ä»»è¡çºä¸çé¡¯èå·®ç°ãæåå¼·èª¿ o1-mini å o3-mini æ¨¡åçç¶æ¿ä¿¡ä»»è¡çºå´©æ½°ï¼å çºå®åèª¿åäºå©æ½¤æå¤§ååé¢¨éªå°æ±èä¾èªä¿¡ä»»çæªä¾åå ±ï¼ä¸¦å°å¶è DeepSeek æ´è¤éä¸æå©å¯åçä¿¡ä»»è¡çºé²è¡å°æ¯ï¼éç¨®ä¿¡ä»»è¡çºæºæ¼æ´åæ´æ·±å±¤çæ¦å¿µï¼ä¾å¦åç»æ§è¦ååå¿æºçè«ãç±æ¼ LLM æ§æé«é¢¨éªåæ¥­ç³»çµ±çåºç¤ï¼æåççµæçªé¡¯äºä¾è³´å®ç¾©éæ¼ç¹çªç LLM æè½åºæºçå±éªæ§ï¼ä¸¦å»ºè­°ä»ç´°åæå¶é±èçæ·å±¤ç·æè©²æ¯ä»»ä½çµç¹ç AI ç­ç¥çä¸é¨åã

##### **LLM Safety for Children**
2502.12552v1 by Prasanjit Rath, Hari Shrawgi, Parag Agrawal, Sandipan Dandapat

This paper analyzes the safety of Large Language Models (LLMs) in
interactions with children below age of 18 years. Despite the transformative
applications of LLMs in various aspects of children's lives such as education
and therapy, there remains a significant gap in understanding and mitigating
potential content harms specific to this demographic. The study acknowledges
the diverse nature of children often overlooked by standard safety evaluations
and proposes a comprehensive approach to evaluating LLM safety specifically for
children. We list down potential risks that children may encounter when using
LLM powered applications. Additionally we develop Child User Models that
reflect the varied personalities and interests of children informed by
literature in child care and psychology. These user models aim to bridge the
existing gap in child safety literature across various fields. We utilize Child
User Models to evaluate the safety of six state of the art LLMs. Our
observations reveal significant safety gaps in LLMs particularly in categories
harmful to children but not adults

æè¦ï¼æ¬æåæäºå¤§åèªè¨æ¨¡å (LLM) å¨è 18 æ­²ä»¥ä¸åç«¥äºåæçå®å¨æ§ãåç®¡ LLM å¨åç«¥çæ´»çååæ¹é¢ï¼ä¾å¦æè²åæ²»çï¼é½æè½è®æ§çæç¨ï¼ä½å¨äºè§£åæ¸è¼å°éåç¾¤é«å·é«çæ½å¨å§å®¹å±å®³æ¹é¢ä»ç¶å­å¨é¡¯èå·®è·ãç ç©¶æ¿èªåç«¥çå¤æ¨£æ§ï¼èæ¨æºå®å¨è©ä¼°éå¸¸æå¿½ç¥éäºå¤æ¨£æ§ï¼ä¸¦æåºäºä¸ç¨®éå°åç«¥è©ä¼° LLM å®å¨æ§çç¶åæ¹æ³ãæåååºäºåç«¥å¨ä½¿ç¨ç± LLM æä¾ååçæç¨ç¨å¼æå¯è½éå°çæ½å¨é¢¨éªãæ­¤å¤ï¼æåéç¼äºåç«¥ä½¿ç¨èæ¨¡åï¼éäºæ¨¡ååæ äºåç«¥ä¸åçåæ§ç¹è³ªåèè¶£ï¼ä¸¦åèäºåç«¥ç§è­·åå¿çå­¸çæç»ãéäºä½¿ç¨èæ¨¡åæ¨å¨å½åä¸åé ååç«¥å®å¨æç»ä¸­ç¾æçå·®è·ãæåå©ç¨åç«¥ä½¿ç¨èæ¨¡åä¾è©ä¼°å­åæåé²ç LLM çå®å¨æ§ãæåçè§å¯çµææ­ç¤ºäº LLM ä¸­çéå¤§å®å¨æ¼æ´ï¼ç¹å¥æ¯å¨å°åç«¥æå®³ä½å°æå¹´äººç¡å®³çé¡å¥ä¸­

##### **Classifiers of Data Sharing Statements in Clinical Trial Records**
2502.12362v1 by Saber Jelodari Mamaghani, Cosima Strantz, Dennis Toddenroth

Digital individual participant data (IPD) from clinical trials are
increasingly distributed for potential scientific reuse. The identification of
available IPD, however, requires interpretations of textual data-sharing
statements (DSS) in large databases. Recent advancements in computational
linguistics include pre-trained language models that promise to simplify the
implementation of effective classifiers based on textual inputs. In a subset of
5,000 textual DSS from ClinicalTrials.gov, we evaluate how well classifiers
based on domain-specific pre-trained language models reproduce original
availability categories as well as manually annotated labels. Typical metrics
indicate that classifiers that predicted manual annotations outperformed those
that learned to output the original availability categories. This suggests that
the textual DSS descriptions contain applicable information that the
availability categories do not, and that such classifiers could thus aid the
automatic identification of available IPD in large trial databases.

æè¦ï¼è¨åºè©¦é©çæ¸ä½åäººåèèè³æ (IPD) æä¾æå»£æ³å°ç¨æ¼æ½å¨çç§å­¸åå©ç¨ãç¶èï¼è¦æ¾åºå¯ç¨ç IPDï¼éè¦å°å¤§åè³æåº«ä¸­çæå­è³æå±äº«è²æ (DSS) é²è¡è©®éãè¨ç®èªè¨å­¸æè¿çé²å±åæ¬é åè¨ç·´çèªè¨æ¨¡åï¼ææç°¡åæ ¹ææå­è¼¸å¥å¯¦ä½ææåé¡å¨çéç¨ãå¨ ClinicalTrials.gov ä¸­ç 5,000 åæå­ DSS å­éä¸­ï¼æåè©ä¼°äºåºæ¼ç¹å®é åé åè¨ç·´èªè¨æ¨¡åçåé¡å¨ï¼å¨éç¾åå§å¯ç¨æ§é¡å¥ä»¥åæåè¨»è§£æ¨ç±¤æ¹é¢çè¡¨ç¾ãå¸åçææ¨é¡¯ç¤ºï¼é æ¸¬æåè¨»è§£çåé¡å¨åªæ¼å­¸æè¼¸åºåå§å¯ç¨æ§é¡å¥çåé¡å¨ãéè¡¨ç¤ºæå­ DSS èªªæåå«å¯ç¨æ§é¡å¥ææ²æçé©ç¨è³è¨ï¼èä¸æ­¤é¡åé¡å¨å æ­¤æå©æ¼å¨å¤§åè©¦é©è³æåº«ä¸­èªåæ¾åºå¯ç¨ç IPDã

##### **Relational Norms for Human-AI Cooperation**
2502.12102v1 by Brian D. Earp, Sebastian Porsdam Mann, Mateo Aboy, Edmond Awad, Monika Betzler, Marietjie Botes, Rachel Calcott, Mina Caraccio, Nick Chater, Mark Coeckelbergh, Mihaela Constantinescu, Hossein Dabbagh, Kate Devlin, Xiaojun Ding, Vilius Dranseika, Jim A. C. Everett, Ruiping Fan, Faisal Feroz, Kathryn B. Francis, Cindy Friedman, Orsolya Friedrich, Iason Gabriel, Ivar Hannikainen, Julie Hellmann, Arasj Khodadade Jahrome, Niranjan S. Janardhanan, Paul Jurcys, Andreas Kappes, Maryam Ali Khan, Gordon Kraft-Todd, Maximilian Kroner Dale, Simon M. Laham, Benjamin Lange, Muriel Leuenberger, Jonathan Lewis, Peng Liu, David M. Lyreskog, Matthijs Maas, John McMillan, Emilian Mihailov, Timo Minssen, Joshua Teperowski Monrad, Kathryn Muyskens, Simon Myers, Sven Nyholm, Alexa M. Owen, Anna Puzio, Christopher Register, Madeline G. Reinecke, Adam Safron, Henry Shevlin, Hayate Shimizu, Peter V. Treit, Cristina Voinea, Karen Yan, Anda Zahiu, Renwen Zhang, Hazem Zohny, Walter Sinnott-Armstrong, Ilina Singh, Julian Savulescu, Margaret S. Clark

How we should design and interact with social artificial intelligence depends
on the socio-relational role the AI is meant to emulate or occupy. In human
society, relationships such as teacher-student, parent-child, neighbors,
siblings, or employer-employee are governed by specific norms that prescribe or
proscribe cooperative functions including hierarchy, care, transaction, and
mating. These norms shape our judgments of what is appropriate for each
partner. For example, workplace norms may allow a boss to give orders to an
employee, but not vice versa, reflecting hierarchical and transactional
expectations. As AI agents and chatbots powered by large language models are
increasingly designed to serve roles analogous to human positions - such as
assistant, mental health provider, tutor, or romantic partner - it is
imperative to examine whether and how human relational norms should extend to
human-AI interactions. Our analysis explores how differences between AI systems
and humans, such as the absence of conscious experience and immunity to
fatigue, may affect an AI's capacity to fulfill relationship-specific functions
and adhere to corresponding norms. This analysis, which is a collaborative
effort by philosophers, psychologists, relationship scientists, ethicists,
legal experts, and AI researchers, carries important implications for AI
systems design, user behavior, and regulation. While we accept that AI systems
can offer significant benefits such as increased availability and consistency
in certain socio-relational roles, they also risk fostering unhealthy
dependencies or unrealistic expectations that could spill over into human-human
relationships. We propose that understanding and thoughtfully shaping (or
implementing) suitable human-AI relational norms will be crucial for ensuring
that human-AI interactions are ethical, trustworthy, and favorable to human
well-being.

æè¦ï¼<paragraph>æåæå¦ä½è¨­è¨åèç¤¾äº¤äººå·¥æºæ§äºåï¼åæ±ºæ¼äººå·¥æºæ§é æè¦æ¨¡ä»¿ææ®æ¼çç¤¾æéä¿è§è²ãå¨äººé¡ç¤¾æä¸­ï¼å¸«çãç¶æ¯å­å¥³ãé°å±ãåå¼å§å¦¹æéä¸»å¡å·¥ç­éä¿åç¹å®è¦ç¯ææ¯éï¼éäºè¦ç¯è¦å®æç¦æ­¢åæ¬ç­ç´ãç§é¡§ãäº¤æåäº¤éå¨å§çåä½åè½ãéäºè¦ç¯å½¢å¡æåå°æ¯åå¤¥ä¼´é©ç¶è¡çºçå¤æ·ãä¾å¦ï¼è·å ´è¦ç¯å¯è½åè¨±èéå°å¡å·¥ç¼èæ½ä»¤ï¼ä½åä¹åä¸è¡ï¼éåæ äºç­ç´åäº¤æçææãé¨èç±å¤§åèªè¨æ¨¡åé©åçäººå·¥æºæ§ä»£çç¨å¼åèå¤©æ©å¨äººæ¥çè¢«è¨­è¨çºæåé¡ä¼¼æ¼äººé¡è·ä½çè§è²ï¼ä¾å¦å©çãå¿çå¥åº·æä¾èãå°å¸«ææµªæ¼«ä¼´ä¾¶ï¼å¯©æ¥äººé¡éä¿è¦ç¯æ¯å¦ä»¥åå¦ä½å»¶ä¼¸è³äººé¡èäººå·¥æºæ§çäºåè³ééè¦ãæåçåææ¢è¨äºäººå·¥æºæ§ç³»çµ±åäººé¡ä¹éçå·®ç°ï¼ä¾å¦ç¼ºä¹æè­é«é©åå°ç²åçåç«åï¼å¦ä½å½±é¿äººå·¥æºæ§å±¥è¡ç¹å®éä¿åè½åéµå®ç¸æè¦ç¯çè½åãéé åææ¯ç±å²å­¸å®¶ãå¿çå­¸å®¶ãéä¿ç§å­¸å®¶ãå«çå­¸å®¶ãæ³å¾å°å®¶åäººå·¥æºæ§ç ç©¶äººå¡å±ååä½çææï¼å°äººå·¥æºæ§ç³»çµ±è¨­è¨ãä½¿ç¨èè¡çºåæ³è¦å·æéè¦çæç¾©ãéç¶æåæ¥åäººå·¥æºæ§ç³»çµ±å¯ä»¥å¨æäºç¤¾æéä¿è§è²ä¸­æä¾é¡¯èçå¥½èï¼ä¾å¦å¢å å¯ç¨æ§åä¸è´æ§ï¼ä½å®åä¹å¯è½å©é·ä¸å¥åº·çä¾è³´éä¿æä¸åå¯¦éçææï¼éäºææå¯è½æèå»¶å°äººééä¿ä¸­ãæåæåºï¼çè§£åæ·±æçæ®å°å¡é ï¼æå¯¦æ½ï¼é©ç¶çäººé¡èäººå·¥æºæ§éä¿è¦ç¯ï¼å°æ¼ç¢ºä¿äººé¡èäººå·¥æºæ§çäºåå·æå«çæ§ãå¯ä¿¡è³´æ§åæå©æ¼äººé¡ç¦ç¥è³ééè¦ã</paragraph>

##### **Deep Spatio-Temporal Neural Network for Air Quality Reanalysis**
2502.11941v1 by Ammar Kheder, Benjamin Foreback, Lili Wang, Zhi-Song Liu, Michael Boy

Air quality prediction is key to mitigating health impacts and guiding
decisions, yet existing models tend to focus on temporal trends while
overlooking spatial generalization. We propose AQ-Net, a spatiotemporal
reanalysis model for both observed and unobserved stations in the near future.
AQ-Net utilizes the LSTM and multi-head attention for the temporal regression.
We also propose a cyclic encoding technique to ensure continuous time
representation. To learn fine-grained spatial air quality estimation, we
incorporate AQ-Net with the neural kNN to explore feature-based interpolation,
such that we can fill the spatial gaps given coarse observation stations. To
demonstrate the efficiency of our model for spatiotemporal reanalysis, we use
data from 2013-2017 collected in northern China for PM2.5 analysis. Extensive
experiments show that AQ-Net excels in air quality reanalysis, highlighting the
potential of hybrid spatio-temporal models to better capture environmental
dynamics, especially in urban areas where both spatial and temporal variability
are critical.

æè¦ï¼ç©ºæ°åè´¨é¢æµæ¯åè½»å¥åº·å½±ååæå¯¼å³ç­çå³é®ï¼ä½ç°æçæ¨¡åå¾åäºå³æ³¨æ¶é´è¶å¿ï¼èå¿½ç¥ç©ºé´æ¦åãæä»¬æåºäº AQ-Netï¼è¿æ¯ä¸ç§æ¶ç©ºååææ¨¡åï¼éç¨äºè¿æåå·²è§æµåæªè§æµå°çç«ç¹ãAQ-Net å©ç¨ LSTM åå¤å¤´æ³¨æåè¿è¡æ¶é´åå½ãæä»¬è¿æåºäºä¸ç§å¾ªç¯ç¼ç ææ¯æ¥ç¡®ä¿æ¶é´è¡¨ç¤ºçè¿ç»­æ§ãä¸ºäºå­¦ä¹ ç»ç²åº¦çç©ºé´ç©ºæ°è´¨éä¼°è®¡ï¼æä»¬å° AQ-Net ä¸ç¥ç» kNN ç»åèµ·æ¥ï¼ä»¥æ¢ç´¢åºäºç¹å¾çæå¼ï¼ä»¥ä¾¿æä»¬è½å¤å¡«åç»å®ç²ç¥è§æµç«çç©ºé´ç©ºç½ãä¸ºäºå±ç¤ºæä»¬çæ¨¡åå¨æ¶ç©ºååæä¸­çæçï¼æä»¬ä½¿ç¨äº 2013-2017 å¹´å¨ä¸­å½åé¨æ¶éç PM2.5 åææ°æ®ãå¤§éçå®éªè¡¨æï¼AQ-Net å¨ç©ºæ°è´¨éååæä¸­è¡¨ç°åºè²ï¼çªåºäºæ··åæ¶ç©ºæ¨¡åå¨æ´å¥½å°ææç¯å¢å¨ææ¹é¢çæ½åï¼å°¤å¶æ¯å¨ç©ºé´åæ¶é´åå¼æ§é½å¾å³é®çåå¸å°åºã

##### **Proactive Depot Discovery: A Generative Framework for Flexible Location-Routing**
2502.11715v1 by Site Qu, Guoqiang Hu

The Location-Routing Problem (LRP), which combines the challenges of facility
(depot) locating and vehicle route planning, is critically constrained by the
reliance on predefined depot candidates, limiting the solution space and
potentially leading to suboptimal outcomes. Previous research on LRP without
predefined depots is scant and predominantly relies on heuristic algorithms
that iteratively attempt depot placements across a planar area. Such approaches
lack the ability to proactively generate depot locations that meet specific
geographic requirements, revealing a notable gap in current research landscape.
To bridge this gap, we propose a data-driven generative DRL framework, designed
to proactively generate depots for LRP without predefined depot candidates,
solely based on customer requests data which include geographic and demand
information. It can operate in two distinct modes: direct generation of exact
depot locations, and the creation of a multivariate Gaussian distribution for
flexible depots sampling. By extracting depots' geographic pattern from
customer requests data, our approach can dynamically respond to logistical
needs, identifying high-quality depot locations that further reduce total
routing costs compared to traditional methods. Extensive experiments
demonstrate that, for a same group of customer requests, compared with those
depots identified through random attempts, our framework can proactively
generate depots that lead to superior solution routes with lower routing cost.
The implications of our framework potentially extend into real-world
applications, particularly in emergency medical rescue and disaster relief
logistics, where rapid establishment and adjustment of depot locations are
paramount, showcasing its potential in addressing LRP for dynamic and
unpredictable environments.

æè¦ï¼<paragraph>å°é»è·¯ç·åé¡ï¼LRPï¼çµåäºè¨­æ½ï¼ååº«ï¼å®ä½åè»è¼è·¯ç·è¦åçææ°ï¼å´éåå°é åå®ç¾©çååº«åé¸éå¶ï¼éå¶äºè§£æ±ºæ¹æ¡ç©ºéï¼ä¸¦å¯è½å°è´æ¬¡åªçµæãååéæ¼æ²æé åå®ç¾©ååº«ç LRP ç ç©¶å¾å°ï¼èä¸ä¸»è¦ä¾è³´æ¼åç¼å¼æ¼ç®æ³ï¼å¨å¹³é¢ååä¸­åè¦åè©¦ååº«éç½®ãéç¨®æ¹æ³ç¡æ³ä¸»åç¢çç¬¦åç¹å®å°çéæ±çååº«ä½ç½®ï¼é¡¯ç¤ºäºç¶åç ç©¶é åçé¡¯èå·®è·ãçºäºå½è£éåå·®è·ï¼æåæåºä¸åè³æé©åççæå¼ DRL æ¶æ§ï¼æ¨å¨ä¸»åçº LRP ç¢çååº«ï¼èç¡éé åå®ç¾©çååº«åé¸ï¼åæ ¹æåå«å°çåéæ±è³è¨çå®¢æ¶è¦æ±è³æãå®å¯ä»¥å¨å©ç¨®ä¸åçæ¨¡å¼ä¸éä½ï¼ç´æ¥ç¢çç¢ºåçååº«ä½ç½®ï¼ä»¥åå»ºç«å¤åé«æ¯åå¸ä»¥é²è¡å½æ§ååº«æ½æ¨£ãééå¾å®¢æ¶è¦æ±è³æä¸­æåååº«çå°çæ¨¡å¼ï¼æåçæ¹æ³å¯ä»¥åæåæå¾å¤éæ±ï¼æ¾åºé«åè³ªçååº«ä½ç½®ï¼é²ä¸æ­¥éä½èå³çµ±æ¹æ³ç¸æ¯çç¸½è·¯ç·ææ¬ãå»£æ³çå¯¦é©è­æï¼å°æ¼åä¸çµå®¢æ¶è¦æ±ï¼èééé¨æ©åè©¦è­å¥çé£äºååº«ç¸æ¯ï¼æåçæ¶æ§å¯ä»¥ä¸»åç¢çååº«ï¼ä¸¦ç¢çè·¯ç·ææ¬è¼ä½çåªè³ªè§£æ±ºæ¹æ¡è·¯ç·ãæåçæ¶æ§çå½±é¿æ½å¨å°æ´å±å°å¯¦éæç¨ï¼ç¹å¥æ¯å¨ç·æ¥é«çææ´åç½å®³æç½å¾å¤æ¹é¢ï¼å¶ä¸­ååº«ä½ç½®çå¿«éå»ºç«åèª¿æ´è³ééè¦ï¼å±ç¤ºäºå¶å¨è§£æ±ºåæåä¸å¯é æ¸¬ç°å¢ç LRP ä¸­çæ½åã</paragraph>

##### **LLM Agents Making Agent Tools**
2502.11705v1 by Georg WÃ¶lflein, Dyke Ferber, Daniel Truhn, Ognjen ArandjeloviÄ, Jakob Nikolas Kather

Tool use has turned large language models (LLMs) into powerful agents that
can perform complex multi-step tasks by dynamically utilising external software
components. However, these tools must be implemented in advance by human
developers, hindering the applicability of LLM agents in domains which demand
large numbers of highly specialised tools, like in life sciences and medicine.
Motivated by the growing trend of scientific studies accompanied by public code
repositories, we propose ToolMaker, a novel agentic framework that autonomously
transforms papers with code into LLM-compatible tools. Given a short task
description and a repository URL, ToolMaker autonomously installs required
dependencies and generates code to perform the task, using a closed-loop
self-correction mechanism to iteratively diagnose and rectify errors. To
evaluate our approach, we introduce a benchmark comprising 15 diverse and
complex computational tasks spanning both medical and non-medical domains with
over 100 unit tests to objectively assess tool correctness and robustness.
ToolMaker correctly implements 80% of the tasks, substantially outperforming
current state-of-the-art software engineering agents. ToolMaker therefore is a
step towards fully autonomous agent-based scientific workflows.

æè¦ï¼å·¥å·ä½¿ç¨å·²å°å¤§åèªè¨æ¨¡å (LLM) è½è®çºå¼·å¤§çä»£çï¼å¯ééåæä½¿ç¨å¤é¨è»é«åä»¶ä¾å·è¡è¤éçå¤æ­¥é©ä»»åãç¶èï¼éäºå·¥å·å¿é äºåç±äººé¡éç¼äººå¡å¯¦ä½ï¼éæé»ç¤ LLM ä»£çå¨éè¦å¤§éé«åº¦å°æ¥­åå·¥å·çé åï¼ä¾å¦çå½ç§å­¸åé«å­¸ï¼ä¸­çæç¨æ§ãåå°ä¼´é¨å¬éç¨å¼ç¢¼å²å­åº«çç§å­¸ç ç©¶è¶¨å¢æåç¼ï¼æåæåº ToolMakerï¼ä¸ååµæ°çä»£çæ¶æ§ï¼å¯èªä¸»å°å°å¸¶æç¨å¼ç¢¼çè«æè½æçºç¸å®¹æ¼ LLM çå·¥å·ãçµ¦å®ç°¡ç­çä»»åæè¿°åå²å­åº«ç¶²åï¼ToolMaker æèªä¸»å®è£æéçä¾è³´é ï¼ä¸¦ç¢çç¨å¼ç¢¼ä¾å·è¡ä»»åï¼ä½¿ç¨éç°èªæä¿®æ­£æ©å¶ä¾åè¦è¨ºæ·åç³¾æ­£é¯èª¤ãçºäºè©ä¼°æåçåæ³ï¼æåå¼é²ä¸ååå« 15 åä¸åä¸è¤éçéç®ä»»åçåºæºï¼æ¶µèé«çåéé«çé åï¼ä¸¦åå«è¶é 100 åå®åæ¸¬è©¦ï¼ä»¥å®¢è§è©ä¼°å·¥å·çæ­£ç¢ºæ§åç©©å¥æ§ãToolMaker æ­£ç¢ºå¯¦ä½äº 80% çä»»åï¼å¤§å¹åªæ¼ç®åçææ°è»é«å·¥ç¨ä»£çãå æ­¤ï¼ToolMaker æ¯éåå®å¨èªä¸»çåºæ¼ä»£ççç§å­¸å·¥ä½æµç¨çä¸æ­¥ã

##### **MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression**
2502.11651v1 by Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang

Large vision-language models (LVLMs) have shown great promise in medical
applications, particularly in visual question answering (MedVQA) and diagnosis
from medical images. However, existing datasets and models often fail to
consider critical aspects of medical diagnostics, such as the integration of
historical records and the analysis of disease progression over time. In this
paper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel
dataset for MedVQA that focuses on identifying changes in specific regions
between two patient visits. Unlike previous datasets that primarily address
single-image questions, MMXU enables multi-image questions, incorporating both
current and historical patient data. We demonstrate the limitations of current
LVLMs in identifying disease progression on MMXU-\textit{test}, even those that
perform well on traditional benchmarks. To address this, we propose a
MedRecord-Augmented Generation (MAG) approach, incorporating both global and
regional historical records. Our experiments show that integrating historical
records significantly enhances diagnostic accuracy by at least 20\%, bridging
the gap between current LVLMs and human expert performance. Additionally, we
fine-tune models with MAG on MMXU-\textit{dev}, which demonstrates notable
improvements. We hope this work could illuminate the avenue of advancing the
use of LVLMs in medical diagnostics by emphasizing the importance of historical
context in interpreting medical images. Our dataset is released at
\href{https://github.com/linjiemu/MMXU}{https://github.com/linjiemu/MMXU}.

æè¦ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) å·²å¨é«çæç¨ä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ç¹å¥æ¯å¨è¦è¦ºåç­ (MedVQA) åé«å­¸å½±åè¨ºæ·æ¹é¢ãç¶èï¼ç¾æçè³æéåæ¨¡åå¸¸å¸¸ç¡æ³èéé«çè¨ºæ·çééµå±¤é¢ï¼ä¾å¦çæ­·æ´åä»¥åé¨èæéæ¨ç§»å°ç¾çé²ç¨çåæãå¨æ¬æä¸­ï¼æåä»ç´¹ MMXUï¼å¤æ¨¡æå¤ X åçè§£ï¼ï¼ä¸åå°æ³¨æ¼è­å¥å©æ¬¡æ£èå°±è¨ºä¹éç¹å®ååè®åç MedVQA æ°è³æéãèä¸»è¦èçå®ä¸å½±ååé¡çååè³æéä¸åï¼MMXU æ¯æ´å¤å½±ååé¡ï¼åæç´å¥ç¶ååçå²æ£èè³æãæåå±ç¤ºäºç¾æ LVLMs å¨ MMXU-\textit{test} ä¸­è­å¥ç¾çé²ç¨çéå¶ï¼å³ä½¿æ¯å¨å³çµ±åºæºæ¸¬è©¦ä¸­è¡¨ç¾è¯å¥½ç LVLMs ä¹æ¯å¦æ­¤ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åçæ­·å¢å¼·çæ (MAG) æ¹æ³ï¼çµåäºå¨ååååçå²ãæåçå¯¦é©é¡¯ç¤ºï¼æ´åçæ­·å¯é¡¯èæåè³å° 20% çè¨ºæ·æºç¢ºåº¦ï¼ç¸®å°äºç¾æ LVLMs åäººé¡å°å®¶è¡¨ç¾ä¹éçå·®è·ãæ­¤å¤ï¼æåå¨ MMXU-\textit{dev} ä¸å¾®èª¿å¸¶æ MAG çæ¨¡åï¼éå±ç¤ºäºé¡¯èçé²æ­¥ãæåå¸æéé å·¥ä½è½ééå¼·èª¿çå²èçµ¡å¨è§£è®é«å­¸å½±åä¸­çéè¦æ§ï¼çºæ¨é² LVLMs å¨é«çè¨ºæ·ä¸­çæç¨éé¢éè·¯ãæåçè³æéå·²æ¼\href{https://github.com/linjiemu/MMXU}{https://github.com/linjiemu/MMXU} ç¼å¸ã

##### **A Survey of Personalized Large Language Models: Progress and Future Directions**
2502.11528v1 by Jiahong Liu, Zexuan Qiu, Zhongyang Li, Quanyu Dai, Jieming Zhu, Minda Hu, Menglin Yang, Irwin King

Large Language Models (LLMs) excel in handling general knowledge tasks, yet
they struggle with user-specific personalization, such as understanding
individual emotions, writing styles, and preferences. Personalized Large
Language Models (PLLMs) tackle these challenges by leveraging individual user
data, such as user profiles, historical dialogues, content, and interactions,
to deliver responses that are contextually relevant and tailored to each user's
specific needs. This is a highly valuable research topic, as PLLMs can
significantly enhance user satisfaction and have broad applications in
conversational agents, recommendation systems, emotion recognition, medical
assistants, and more. This survey reviews recent advancements in PLLMs from
three technical perspectives: prompting for personalized context (input level),
finetuning for personalized adapters (model level), and alignment for
personalized preferences (objective level). To provide deeper insights, we also
discuss current limitations and outline several promising directions for future
research. Updated information about this survey can be found at the
https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èçä¸è¬ç¥è­ä»»åæ¹é¢è¡¨ç¾åºè²ï¼ä½
å®åå¨ä½¿ç¨èç¹å®çåäººåæ¹é¢æå°é£ï¼ä¾å¦çè§£
åå¥çæç·ãå¯«ä½é¢¨æ ¼ååå¥½ãåäººåå¤§å
èªè¨æ¨¡å (PLLM) ééå©ç¨åå¥ä½¿ç¨èç
è³æä¾è§£æ±ºéäºææ°ï¼ä¾å¦ä½¿ç¨èåäººè³æãæ­·å²å°è©±ãå§å®¹åäºåï¼
æä¾å¨èçµ¡ä¸ç¸éä¸éå°æ¯åä½¿ç¨èçç¹å®éæ±éèº«æé çåæãéæ¯ä¸åéå¸¸æå¹å¼çç ç©¶ä¸»é¡ï¼å çº PLLM å¯ä»¥
é¡¯èæåä½¿ç¨èæ»¿æåº¦ï¼ä¸¦å¨å°è©±ä»£çãæ¨è¦ç³»çµ±ãæç·è¾¨è­ãé«ç
å©çç­æ¹é¢æå»£æ³çæç¨ãéé èª¿æ¥å¾ä¸åæè¡è§é»åé¡§ PLLM çææ°é²å±ï¼æç¤ºåäººåèçµ¡ï¼è¼¸å¥å±¤ç´ï¼ãå¾®èª¿åäººåé©éå¨ï¼æ¨¡åå±¤ç´ï¼ï¼ä»¥åå°é½åäººååå¥½ï¼ç®æ¨å±¤ç´ï¼ãçºäºæä¾æ´æ·±å¥çè¦è§£ï¼æåä¹
è¨è«ç®åçéå¶ï¼ä¸¦æ¦è¿°æªä¾ç ç©¶çå¹¾åæå¸æçæ¹åãéé èª¿æ¥çææ°è³è¨å¯ä»¥å¨
https://github.com/JiahongLiu21/Awesome-Personalized-Large-Language-Models æ¾å°ã

##### **Variable-frame CNNLSTM for Breast Nodule Classification using Ultrasound Videos**
2502.11481v1 by Xiangxiang Cui, Zhongyu Li, Xiayue Fan, Peng Huang, Ying Wang, Meng Yang, Shi Chang, Jihua Zhu

The intersection of medical imaging and artificial intelligence has become an
important research direction in intelligent medical treatment, particularly in
the analysis of medical images using deep learning for clinical diagnosis.
Despite the advances, existing keyframe classification methods lack extraction
of time series features, while ultrasonic video classification based on
three-dimensional convolution requires uniform frame numbers across patients,
resulting in poor feature extraction efficiency and model classification
performance. This study proposes a novel video classification method based on
CNN and LSTM, introducing NLP's long and short sentence processing scheme into
video classification for the first time. The method reduces CNN-extracted image
features to 1x512 dimension, followed by sorting and compressing feature
vectors for LSTM training. Specifically, feature vectors are sorted by patient
video frame numbers and populated with padding value 0 to form variable
batches, with invalid padding values compressed before LSTM training to
conserve computing resources. Experimental results demonstrate that our
variable-frame CNNLSTM method outperforms other approaches across all metrics,
showing improvements of 3-6% in F1 score and 1.5% in specificity compared to
keyframe methods. The variable-frame CNNLSTM also achieves better accuracy and
precision than equal-frame CNNLSTM. These findings validate the effectiveness
of our approach in classifying variable-frame ultrasound videos and suggest
potential applications in other medical imaging modalities.

æè¦ï¼é«å­¸å½±åèäººå·¥æºæ§çäº¤åé åå·²æçºæºæ§é«ççéè¦ç ç©¶æ¹åï¼ç¹å¥æ¯å¨è¨åºè¨ºæ·ä¸­ä½¿ç¨æ·±åº¦å­¸ç¿åæé«å­¸å½±åãåç®¡æé²å±ï¼ç¾æçééµå½±æ ¼åé¡æ¹æ³ç¼ºä¹æéåºåç¹å¾µçæåï¼èåºæ¼ä¸ç¶­å·ç©çè¶é³æ³¢å½±çåé¡éè¦æ£èä¹éçåå»å½±æ ¼æ¸ï¼å°è´ç¹å¾µæåæçå·®åæ¨¡ååé¡æè½ä¸ä½³ãæ¬ç ç©¶æåºäºä¸ç¨®åºæ¼ CNN å LSTM çæ°å½±çåé¡æ¹æ³ï¼é¦æ¬¡å° NLP çé·ç­å¥èçæ©å¶å¼å¥å½±çåé¡ä¸­ãè©²æ¹æ³å° CNN æåçå½±åç¹å¾µç¸®æ¸çº 1x512 ç¶­åº¦ï¼ç¶å¾å°ç¹å¾µåéé²è¡æåºåå£ç¸®ä»¥é²è¡ LSTM è¨ç·´ãå·é«ä¾èªªï¼ç¹å¾µåéææ£èå½±çå½±æ ¼æ¸æåºï¼ä¸¦å¡«å 0 è£é½å¼ä»¥å½¢æå¯è®æ¹æ¬¡ï¼å¨ LSTM è¨ç·´åå£ç¸®ç¡æçè£é½å¼ä»¥ç¯çéç®è³æºãå¯¦é©çµæè¡¨æï¼æåçå¯è®å½±æ ¼ CNNLSTM æ¹æ³å¨ææææ¨ä¸é½åªæ¼å¶ä»æ¹æ³ï¼èééµå½±æ ¼æ¹æ³ç¸æ¯ï¼F1 åæ¸æé«äº 3-6%ï¼ç¹ç°æ§æé«äº 1.5%ãå¯è®å½±æ ¼ CNNLSTM ä¹æ¯ç­å½±æ ¼ CNNLSTM éå°äºæ´å¥½çæºç¢ºåº¦åç²¾ç¢ºåº¦ãéäºç¼ç¾é©è­äºæåçæ¹æ³å¨åé¡å¯è®å½±æ ¼è¶é³æ³¢å½±çä¸­çæææ§ï¼ä¸¦è¡¨æå¨å¶ä»é«å­¸å½±åæ¨¡å¼ä¸­å·ææ½å¨çæç¨ã

##### **Leveraging Labelled Data Knowledge: A Cooperative Rectification Learning Network for Semi-supervised 3D Medical Image Segmentation**
2502.11456v1 by Yanyan Wang, Kechen Song, Yuyuan Liu, Shuai Ma, Yunhui Yan, Gustavo Carneiro

Semi-supervised 3D medical image segmentation aims to achieve accurate
segmentation using few labelled data and numerous unlabelled data. The main
challenge in the design of semi-supervised learning methods consists in the
effective use of the unlabelled data for training. A promising solution
consists of ensuring consistent predictions across different views of the data,
where the efficacy of this strategy depends on the accuracy of the
pseudo-labels generated by the model for this consistency learning strategy. In
this paper, we introduce a new methodology to produce high-quality
pseudo-labels for a consistency learning strategy to address semi-supervised 3D
medical image segmentation. The methodology has three important contributions.
The first contribution is the Cooperative Rectification Learning Network (CRLN)
that learns multiple prototypes per class to be used as external knowledge
priors to adaptively rectify pseudo-labels at the voxel level. The second
contribution consists of the Dynamic Interaction Module (DIM) to facilitate
pairwise and cross-class interactions between prototypes and multi-resolution
image features, enabling the production of accurate voxel-level clues for
pseudo-label rectification. The third contribution is the Cooperative Positive
Supervision (CPS), which optimises uncertain representations to align with
unassertive representations of their class distributions, improving the model's
accuracy in classifying uncertain regions. Extensive experiments on three
public 3D medical segmentation datasets demonstrate the effectiveness and
superiority of our semi-supervised learning method.

æè¦ï¼åçç£ 3D å»å­¦å½±ååå²æ¨å¨ä½¿ç¨å°éæ è®°æ°æ®åå¤§éæªæ è®°æ°æ®å®ç°ç²¾ç¡®åå²ãåçç£å­¦ä¹ æ¹æ³è®¾è®¡ä¸­çä¸»è¦ææå¨äºææä½¿ç¨æªæ è®°æ°æ®è¿è¡è®­ç»ãä¸ä¸ªæåæ¯çè§£å³æ¹æ¡æ¯ç¡®ä¿æ°æ®ä¸åè§å¾ä¹é´é¢æµçä¸è´æ§ï¼å¶ä¸­æ­¤ç­ç¥çæææ§åå³äºæ¨¡åä¸ºè¿ç§ä¸è´æ§å­¦ä¹ ç­ç¥çæçä¼ªæ ç­¾çåç¡®æ§ãå¨æ¬æä¸­ï¼æä»¬å¼å¥äºä¸ç§æ°çæ¹æ³æ¥ä¸ºä¸è´æ§å­¦ä¹ ç­ç¥çæé«è´¨éçä¼ªæ ç­¾ï¼ä»¥è§£å³åçç£ 3D å»å­¦å¾ååå²é®é¢ãè¯¥æ¹æ³æä¸ä¸ªéè¦çè´¡ç®ãç¬¬ä¸ä¸ªè´¡ç®æ¯åä½ä¿®æ­£å­¦ä¹ ç½ç» (CRLN)ï¼å®ä¸ºæ¯ä¸ªç±»å«å­¦ä¹ å¤ä¸ªååï¼ç¨ä½å¤é¨ç¥è¯åéªï¼ä»¥å¨ä½ç´ çº§å«èªéåºå°ä¿®æ­£ä¼ªæ ç­¾ãç¬¬äºä¸ªè´¡ç®åæ¬å¨æäº¤äºæ¨¡å (DIM)ï¼ä»¥ä¿è¿åååå¤åè¾¨çå¾åç¹å¾ä¹é´çæå¯¹åè·¨ç±»äº¤äºï¼ä»èè½å¤çæç¨äºä¼ªæ ç­¾ä¿®æ­£çåç¡®ä½ç´ çº§çº¿ç´¢ãç¬¬ä¸ä¸ªè´¡ç®æ¯åä½æ­£çç£ (CPS)ï¼å®ä¼åä¸ç¡®å®çè¡¨ç¤ºä»¥ä¸å¶ç±»åå¸çä¸ç¡®å®è¡¨ç¤ºä¿æä¸è´ï¼ä»èæé«æ¨¡åå¯¹ä¸ç¡®å®åºåè¿è¡åç±»çåç¡®æ§ãå¨ä¸ä¸ªå¬å± 3D å»å­¦åå²æ°æ®éä¸è¿è¡çå¤§éå®éªè¡¨æäºæä»¬åçç£å­¦ä¹ æ¹æ³çæææ§åä¼è¶æ§ã

##### **A Survey of LLM-based Agents in Medicine: How far are we from Baymax?**
2502.11211v1 by Wenxuan Wang, Zizhan Ma, Zheng Wang, Chenghan Wu, Wenting Chen, Xiang Li, Yixuan Yuan

Large Language Models (LLMs) are transforming healthcare through the
development of LLM-based agents that can understand, reason about, and assist
with medical tasks. This survey provides a comprehensive review of LLM-based
agents in medicine, examining their architectures, applications, and
challenges. We analyze the key components of medical agent systems, including
system profiles, clinical planning mechanisms, medical reasoning frameworks,
and external capacity enhancement. The survey covers major application
scenarios such as clinical decision support, medical documentation, training
simulations, and healthcare service optimization. We discuss evaluation
frameworks and metrics used to assess these agents' performance in healthcare
settings. While LLM-based agents show promise in enhancing healthcare delivery,
several challenges remain, including hallucination management, multimodal
integration, implementation barriers, and ethical considerations. The survey
concludes by highlighting future research directions, including advances in
medical reasoning inspired by recent developments in LLM architectures,
integration with physical systems, and improvements in training simulations.
This work provides researchers and practitioners with a structured overview of
the current state and future prospects of LLM-based agents in medicine.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) éééç¼å¯çè§£ãæ¨çä¸¦åå©é«çä»»åç LLM åºç¤ä»£çäººï¼è½è®äºé«çä¿å¥ãæ¬èª¿æ¥æä¾äº LLM åºç¤ä»£çäººå¨é«å­¸ä¸­çå¨é¢åé¡§ï¼æ¢è¨å¶æ¶æ§ãæç¨åææ°ãæååæäºé«çä»£çç³»çµ±çä¸»è¦çµæé¨åï¼åæ¬ç³»çµ±æ¦æ³ãè¨åºè¦åæ©å¶ãé«çæ¨çæ¶æ§åå¤é¨è½åæåãæ¬èª¿æ¥æ¶µèäºä¸»è¦çæç¨å ´æ¯ï¼ä¾å¦è¨åºæ±ºç­æ¯æ´ãé«çæä»¶ãè¨ç·´æ¨¡æ¬åé«çä¿å¥æåæä½³åãæåè¨è«äºç¨æ¼è©ä¼°éäºä»£çäººå¨é«çä¿å¥ç°å¢ä¸­è¡¨ç¾çè©ä¼°æ¶æ§åææ¨ãéç¶ LLM åºç¤ä»£çäººé¡¯ç¤ºåºå¨å¢å¼·é«çä¿å¥æä¾æ¹é¢çæ½åï¼ä½ä»æè¨±å¤ææ°ï¼åæ¬å¹»è¦ºç®¡çãå¤æ¨¡ææ´åãå¯¦æ½éç¤åå«çèéãæ¬èª¿æ¥æå¾å¼·èª¿äºæªä¾çç ç©¶æ¹åï¼åæ¬å LLM æ¶æ§è¿æç¼å±åç¼çé«çæ¨çé²å±ãèç©çç³»çµ±çæ´ååè¨ç·´æ¨¡æ¬çæ¹é²ãéé å·¥ä½çºç ç©¶äººå¡åå¾æ¥­äººå¡æä¾äº LLM åºç¤ä»£çäººå¨é«å­¸ä¸­ç¶åçæåæªä¾åæ¯ççµæ§åæ¦è§ã

##### **RT-DEMT: A hybrid real-time acupoint detection model combining mamba and transformer**
2502.11179v1 by Shilong Yang, Qi Zang, Chulong Zhang, Lingfeng Huang, Yaoqin Xie

Traditional Chinese acupuncture methods often face controversy in clinical
practice due to their high subjectivity. Additionally, current
intelligent-assisted acupuncture systems have two major limitations: slow
acupoint localization speed and low accuracy. To address these limitations, a
new method leverages the excellent inference efficiency of the state-space
model Mamba, while retaining the advantages of the attention mechanism in the
traditional DETR architecture, to achieve efficient global information
integration and provide high-quality feature information for acupoint
localization tasks. Furthermore, by employing the concept of residual
likelihood estimation, it eliminates the need for complex upsampling processes,
thereby accelerating the acupoint localization task. Our method achieved
state-of-the-art (SOTA) accuracy on a private dataset of acupoints on the human
back, with an average Euclidean distance pixel error (EPE) of 7.792 and an
average time consumption of 10.05 milliseconds per localization task. Compared
to the second-best algorithm, our method improved both accuracy and speed by
approximately 14\%. This significant advancement not only enhances the efficacy
of acupuncture treatment but also demonstrates the commercial potential of
automated acupuncture robot systems. Access to our method is available at
https://github.com/Sohyu1/RT-DEMT

æè¦ï¼å³çµ±çä¸­é«éç¸æ¹æ³ç±æ¼å¶é«åº¦ä¸»è§æ§ï¼å¨è¨åºå¯¦åä¸­ç¶å¸¸é¢è¨ç­è­°ãæ­¤å¤ï¼ç¾æçæºæ§è¼å©éç¸ç³»çµ±æå©å¤§éå¶ï¼åç©´éåº¦æ¢ä»¥åæºç¢ºåº¦ä½ãçºäºè§£æ±ºéäºéå¶ï¼ä¸ç¨®æ°çæ¹æ³å©ç¨äºçæç©ºéæ¨¡å Mamba åªç°çæ¨çæçï¼åæä¿çäºå³çµ± DETR æ¶æ§ä¸­æ³¨æåæ©å¶çåªé»ï¼ä»¥å¯¦ç¾é«æçå¨å±è³è¨æ´åï¼ä¸¦çºåç©´ä»»åæä¾é«åè³ªçç¹å¾µè³è¨ãæ­¤å¤ï¼ééæ¡ç¨æ®å·®ä¼¼ç¶ä¼°è¨çæ¦å¿µï¼å®æ¶é¤äºå°è¤éä¸æ¡æ¨£ç¨åºçéæ±ï¼å¾èå éäºåç©´ä»»åãæåçæ¨¡åå¨äººé«èé¨ç©´ä½ç§äººè³æéä¸éå°äºæåé² (SOTA) çæºç¢ºåº¦ï¼å¹³åæ­å¹¾éå¾è·é¢åç´ èª¤å·® (EPE) çº 7.792ï¼å¹³åæ¯ååç©´ä»»åèæ 10.05 æ¯«ç§ãèç¬¬äºå¥½çæ¼ç®æ³ç¸æ¯ï¼æåçæ¨¡åå¨æºç¢ºåº¦åéåº¦ä¸é½æé«äºå¤§ç´ 14%ãéé éå¤§é²å±ä¸åæé«äºéç¸æ²»çççæï¼ä¹è­æäºèªååéç¸æ©å¨äººç³»çµ±çåæ¥­æ½åãæåçæ¨¡åå¯ä»¥å¨ https://github.com/Sohyu1/RT-DEMT åå¾

##### **Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications**
2502.11108v1 by Alexandru Lecu, Adrian Groza, Lezan Hawizy

Large language models (LLMs) have significantly advanced the field of natural
language generation. However, they frequently generate unverified outputs,
which compromises their reliability in critical applications. In this study, we
propose an innovative framework that combines structured biomedical knowledge
with LLMs through a retrieval-augmented generation technique. Our system
develops a thorough knowledge graph by identifying and refining causal
relationships and named entities from medical abstracts related to age-related
macular degeneration (AMD). Using a vector-based retrieval process and a
locally deployed language model, our framework produces responses that are both
contextually relevant and verifiable, with direct references to clinical
evidence. Experimental results show that this method notably decreases
hallucinations, enhances factual precision, and improves the clarity of
generated responses, providing a robust solution for advanced biomedical
chatbot applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¤§å¹æ¨åèªç¶èªè¨çæçé åãç¶èï¼å®åç¶å¸¸ç¢çæªç¶é©è­çè¼¸åºï¼éææå®³å®åå¨ééµæç¨ä¸­çå¯é æ§ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ååµæ°çæ¡æ¶ï¼ééæª¢ç´¢å¢å¼·çææè¡ï¼å°çµæ§åççç©é«å­¸ç¥è­è LLM çµåãæåçç³»çµ±ééè­å¥åç²¾çèå¹´é½¡ç¸éæ§é»æé¨çè® (AMD) ç¸éçé«å­¸æè¦ä¸­çå æéä¿åå½åå¯¦é«ï¼éç¼ä¸åå¾¹åºçç¥è­åè­ãæåçæ¡æ¶ä½¿ç¨åºæ¼åéçæª¢ç´¢æµç¨åæ¬å°é¨ç½²çèªè¨æ¨¡åï¼ç¢çå¨èçµ¡ä¸ç¸éä¸å¯é©è­çåæï¼ä¸¦ç´æ¥åèè¨åºè­æãå¯¦é©çµæé¡¯ç¤ºï¼æ­¤æ¹æ³é¡¯èæ¸å°äºå¹»è¦ºãå¢å¼·äºäºå¯¦æºç¢ºæ§ï¼ä¸¦æ¹åäºçæåæçæ¸æ°åº¦ï¼çºåé²ççç©é«å­¸èå¤©æ©å¨äººæç¨ç¨å¼æä¾äºç©©å¥çè§£æ±ºæ¹æ¡ã

##### **Predicting Depression in Screening Interviews from Interactive Multi-Theme Collaboration**
2502.12204v1 by Xianbing Zhao, Yiqing Lyu, Di Wang, Buzhou Tang

Automatic depression detection provides cues for early clinical intervention
by clinicians. Clinical interviews for depression detection involve dialogues
centered around multiple themes. Existing studies primarily design end-to-end
neural network models to capture the hierarchical structure of clinical
interview dialogues. However, these methods exhibit defects in modeling the
thematic content of clinical interviews: 1) they fail to capture intra-theme
and inter-theme correlation explicitly, and 2) they do not allow clinicians to
intervene and focus on themes of interest. To address these issues, this paper
introduces an interactive depression detection framework. This framework
leverages in-context learning techniques to identify themes in clinical
interviews and then models both intra-theme and inter-theme correlation.
Additionally, it employs AI-driven feedback to simulate the interests of
clinicians, enabling interactive adjustment of theme importance. PDIMC achieves
absolute improvements of 35\% and 12\% compared to the state-of-the-art on the
depression detection dataset DAIC-WOZ, which demonstrates the effectiveness of
modeling theme correlation and incorporating interactive external feedback.

æè¦ï¼èªåæé¬±çåµæ¸¬æä¾è¨åºé«å¸«æ©æè¨åºä»å¥çç·ç´¢ãæé¬±çåµæ¸¬çè¨åºè¨ªè«æ¶åä»¥å¤åä¸»é¡çºä¸­å¿çå°è©±ãç¾æç ç©¶ä¸»è¦è¨­è¨ç«¯å°ç«¯çé¡ç¥ç¶ç¶²è·¯æ¨¡åä¾ææè¨åºè¨ªè«å°è©±çéå±¤çµæ§ãç¶èï¼éäºæ¹æ³å¨å»ºæ¨¡è¨åºè¨ªè«çä¸»é¡å§å®¹æè¡¨ç¾åºç¼ºé·ï¼1ï¼å®åç¡æ³æç¢ºææä¸»é¡å§åä¸»é¡éçéè¯æ§ï¼ä»¥å 2ï¼å®åä¸åè¨±è¨åºé«å¸«ä»å¥ä¸¦å°æ³¨æ¼æèè¶£çä¸»é¡ãçºäºè§£æ±ºéäºåé¡ï¼æ¬æä»ç´¹äºä¸åäºåå¼æé¬±çåµæ¸¬æ¡æ¶ãæ­¤æ¡æ¶å©ç¨æå¢å­¸ç¿æè¡ä¾è­å¥è¨åºè¨ªè«ä¸­çä¸»é¡ï¼ç¶å¾å°ä¸»é¡å§åä¸»é¡éçéè¯æ§é²è¡å»ºæ¨¡ãæ­¤å¤ï¼å®æ¡ç¨ AI é©åçåé¥ä¾æ¨¡æ¬è¨åºé«å¸«çèè¶£ï¼å¯¦ç¾ä¸»é¡éè¦æ§çäºåå¼èª¿æ´ãè DAIC-WOZ æé¬±çåµæ¸¬è³æéä¸çææ°æè¡ç¸æ¯ï¼PDIMC ççµå°æ¹é²çåå¥çº 35% å 12%ï¼éè­æäºå°ä¸»é¡éè¯æ§å»ºæ¨¡åç´å¥äºåå¼å¤é¨åé¥çæææ§ã

##### **CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening**
2502.11001v1 by Gen Zhou, Sugitha Janarthanan, Yutong Lu, Pingzhao Hu

Due to the rise in antimicrobial resistance, identifying novel compounds with
antibiotic potential is crucial for combatting this global health issue.
However, traditional drug development methods are costly and inefficient.
Recognizing the pressing need for more effective solutions, researchers have
turned to machine learning techniques to streamline the prediction and
development of novel antibiotic compounds. While foundation models have shown
promise in antibiotic discovery, current mainstream efforts still fall short of
fully leveraging the potential of multimodal molecular data. Recent studies
suggest that contrastive learning frameworks utilizing multimodal data exhibit
excellent performance in representation learning across various domains.
Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning
(CL)-based multimodal foundation (MF) model specifically tailored for
discovering small molecules with potential antibiotic properties (AP) using
three types of molecular data. This model employs 1.6 million bioactive
molecules with drug-like properties from the ChEMBL dataset to jointly pretrain
three encoders: (1) a transformer-based encoder with rotary position embedding
for processing SMILES strings; (2) another transformer-based encoder,
incorporating a novel bi-level routing attention mechanism to handle molecular
graph representations; and (3) a Morgan fingerprint encoder using a multilayer
perceptron, to achieve the contrastive learning purpose. The CL-MFAP
outperforms baseline models in antibiotic property prediction by effectively
utilizing different molecular modalities and demonstrates superior
domain-specific performance when fine-tuned for antibiotic-related property
prediction tasks.

æè¦ï¼<paragraph>ç±æ¼æèè¥ç©ææ§ä¸åï¼æ¾åºå·ææçç´ æ½åçæ°åååç©å°æ¼å°ææ­¤é å¨çæ§å¥åº·è­°é¡è³ééè¦ãä¸éï¼å³çµ±çè¥ç©éç¼æ¹æ³ææ¬é«æä¸æçä¸å½°ãç ç©¶äººå¡é«èªå°å°æ¼æ´ææè§£æ±ºæ¹æ¡çè¿«åéæ±ï¼å æ­¤è½åæ©å¨å­¸ç¿æè¡ä¾ç°¡åæ°åæçç´ ååç©çé æ¸¬åéç¼ãåç®¡åºç¤æ¨¡åå¨æçç´ ç¼ç¾æ¹é¢å±ç¾æ½åï¼ç®åçæ®éåæ³ä»æªååå©ç¨å¤æ¨¡æåå­è³æçæ½åãæè¿çç ç©¶é¡¯ç¤ºï¼å©ç¨å¤æ¨¡æè³æçå°æ¯å­¸ç¿æ¶æ§å¨åç¨®é åçè¡¨å¾µå­¸ç¿ä¸­å±ç¾åºåªç°çæè½ãæéæ¼æ­¤ï¼æåå¼é² CL-MFAPï¼ä¸ç¨®ç¡ç£ç£å°æ¯å­¸ç¿ (CL) çºåºç¤çå¤æ¨¡æåºç¤ (MF) æ¨¡åï¼å°éç¨æ¼ä½¿ç¨ä¸ç¨®é¡åçåå­è³æç¼ç¾å·ææ½å¨æçç´ ç¹æ§çä½åå­ãæ­¤æ¨¡åæ¡ç¨ ChEMBL è³æéä¸­ç 160 è¬åå·æé¡è¥ç©ç¹æ§ççç©æ´»æ§åå­ï¼ä»¥è¯åé è¨ç·´ä¸åç·¨ç¢¼å¨ï¼(1) ä¸åå·ææè½ä½ç½®åµå¥çåºæ¼Transformerçç·¨ç¢¼å¨ï¼ç¨æ¼èç SMILES å­ä¸²ï¼(2) å¦ä¸ååºæ¼Transformerçç·¨ç¢¼å¨ï¼çµåä¸ç¨®æ°ç©çéå±¤è·¯ç±æ³¨ææ©å¶ä¾èçåå­åè¡¨è¡¨å¾µï¼ä»¥å (3) ä¸åä½¿ç¨å¤å±¤æç¥å¨ç Morgan æç´ç·¨ç¢¼å¨ï¼ä»¥éæå°æ¯å­¸ç¿çç®çãCL-MFAP ééææå©ç¨ä¸åçåå­æ¨¡å¼å¨æçç´ ç¹æ§é æ¸¬æ¹é¢åªæ¼åºæºæ¨¡åï¼ä¸¦ä¸å¨éå°æçç´ ç¸éç¹æ§é æ¸¬ä»»åé²è¡å¾®èª¿æå±ç¾åºåªç°çç¹å®é åæè½ã</paragraph>

##### **Automatic Quality Assessment of First Trimester Crown-Rump-Length Ultrasound Images**
2502.10908v1 by Sevim Cengiz, Ibraheem Hamdi, Mohammad Yaqub

Fetal gestational age (GA) is vital clinical information that is estimated
during pregnancy in order to assess fetal growth. This is usually performed by
measuring the crown-rump-length (CRL) on an ultrasound image in the Dating scan
which is then correlated with fetal age and growth trajectory. A major issue
when performing the CRL measurement is ensuring that the image is acquired at
the correct view, otherwise it could be misleading. Although clinical
guidelines specify the criteria for the correct CRL view, sonographers may not
regularly adhere to such rules. In this paper, we propose a new deep
learning-based solution that is able to verify the adherence of a CRL image to
clinical guidelines in order to assess image quality and facilitate accurate
estimation of GA. We first segment out important fetal structures then use the
localized structures to perform a clinically-guided mapping that verifies the
adherence of criteria. The segmentation method combines the benefits of
Convolutional Neural Network (CNN) and the Vision Transformer (ViT) to segment
fetal structures in ultrasound images and localize important fetal landmarks.
For segmentation purposes, we compare our proposed work with UNet and show that
our CNN/ViT-based method outperforms an optimized version of UNet. Furthermore,
we compare the output of the mapping with classification CNNs when assessing
the clinical criteria and the overall acceptability of CRL images. We show that
the proposed mapping is not only explainable but also more accurate than the
best performing classification CNNs.

æè¦ï¼èåå¦å¨ å¹´é½¡ (GA) æ¯éè¦çè¨åºè³è¨ï¼æå¨æ·å­æéä¼°è¨ï¼ä»¥è©ä¼°èåçé·ãééå¸¸æ¯ééå¨ç´æææä¸­æ¸¬éè¶é³æ³¢å½±åä¸­çé ­èé·åº¦ (CRL) ä¾å·è¡ï¼ç¶å¾èèåå¹´é½¡åçé·è»è·¡ç¸éè¯ãå·è¡ CRL æ¸¬éæçä¸åä¸»è¦åé¡æ¯ç¢ºä¿å½±åæ¯å¨æ­£ç¢ºçè¦è§ä¸åå¾ï¼å¦åå¯è½æç¢çèª¤å°ãåç®¡è¨åºæåè¦å®äºæ­£ç¢º CRL è¦è§çæ¨æºï¼ä½è¶é³æ³¢æª¢æ¥å¡å¯è½ä¸æå®æéµå®éäºè¦åãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°çæ·±åº¦å­¸ç¿è§£æ±ºæ¹æ¡ï¼è½å¤ é©è­ CRL å½±åæ¯å¦ç¬¦åè¨åºæåï¼ä»¥è©ä¼°å½±ååè³ªä¸¦ä¿é²å° GA çæºç¢ºä¼°è¨ãæåé¦ååå²åºéè¦çèåçµæ§ï¼ç¶å¾ä½¿ç¨å±é¨çµæ§ä¾å·è¡è¨åºæå°çå°æï¼ä»¥é©è­æ¨æºçéµå®ææ³ãåå²æ¹æ³çµåäºå·ç©ç¥ç¶ç¶²è·¯ (CNN) åè¦è¦ºè½æå¨ (ViT) çåªé»ï¼ä»¥åå²è¶é³æ³¢å½±åä¸­çèåçµæ§ä¸¦å®ä½éè¦çèåæ¨èªãçºäºåå²ç®çï¼æåå°æåæåºçå·¥ä½è UNet é²è¡æ¯è¼ï¼ä¸¦é¡¯ç¤ºæååºæ¼ CNN/ViT çæ¹æ³åªæ¼ UNet çæä½³åçæ¬ãæ­¤å¤ï¼æåå¨è©ä¼°è¨åºæ¨æºå CRL å½±åçæ´é«å¯æ¥åæ§æï¼å°å°æçè¼¸åºèåé¡ CNN é²è¡æ¯è¼ãæåè¡¨æï¼ææåºçå°æä¸åå¯ä»¥è§£éï¼èä¸æ¯æè½æä½³çåé¡ CNN æ´æºç¢ºã

##### **Breaking Down the Hierarchy: A New Approach to Leukemia Classification**
2502.10899v1 by Ibraheem Hamdi, Hosam El-Gendy, Ahmed Sharshar, Mohamed Saeed, Muhammad Ridzuan, Shahrukh K. Hashmi, Naveed Syed, Imran Mirza, Shakir Hussain, Amira Mahmoud Abdalla, Mohammad Yaqub

The complexities inherent to leukemia, multifaceted cancer affecting white
blood cells, pose considerable diagnostic and treatment challenges, primarily
due to reliance on laborious morphological analyses and expert judgment that
are susceptible to errors. Addressing these challenges, this study presents a
refined, comprehensive strategy leveraging advanced deep-learning techniques
for the classification of leukemia subtypes. We commence by developing a
hierarchical label taxonomy, paving the way for differentiating between various
subtypes of leukemia. The research further introduces a novel hierarchical
approach inspired by clinical procedures capable of accurately classifying
diverse types of leukemia alongside reactive and healthy cells. An integral
part of this study involves a meticulous examination of the performance of
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) as
classifiers. The proposed method exhibits an impressive success rate, achieving
approximately 90\% accuracy across all leukemia subtypes, as substantiated by
our experimental results. A visual representation of the experimental findings
is provided to enhance the model's explainability and aid in understanding the
classification process.

æè¦ï¼ç½è¡ççå¤ææ§æºäºå®æ¯ä¸ç§å½±åç½è¡ççå¤é¢æ§ççï¼ä¸»è¦ç±äºä¾èµè´¹åçå½¢æåæåå®¹æåºéçä¸å®¶å¤æ­ï¼å æ­¤å¸¦æ¥äºç¸å½å¤§çè¯æ­åæ²»çææãä¸ºäºåºå¯¹è¿äºææï¼æ¬ç ç©¶æåºäºä¸ç§ç²¾ç»ä¸å¨é¢çç­ç¥ï¼å©ç¨åè¿çæ·±åº¦å­¦ä¹ ææ¯å¯¹ç½è¡çäºåè¿è¡åç±»ãæä»¬é¦åå¼åäºä¸ä¸ªåå±çæ ç­¾åç±»æ³ï¼ä¸ºåºåç½è¡ççåç§äºåéºå¹³äºéè·¯ãè¯¥ç ç©¶è¿ä¸æ­¥å¼å¥äºä¸ç§æ°é¢çåå±æ¹æ³ï¼è¯¥æ¹æ³åä¸´åºç¨åºçå¯åï¼è½å¤åç¡®å°å¯¹åç§ç±»åçç½è¡çä»¥åååºæ§åå¥åº·ç»èè¿è¡åç±»ãæ¬ç ç©¶çä¸ä¸ªç»æé¨åæ¶åå¯¹å·ç§¯ç¥ç»ç½ç» (CNN) åè§è§ååå¨ (ViT) ä½ä¸ºåç±»å¨çæ§è½è¿è¡ç»è´æ£æ¥ãææåºçæ¹æ³å±ç¤ºäºä»¤äººå°è±¡æ·±å»çæåçï¼å¨ææç½è¡çäºåä¸­å®ç°äºå¤§çº¦ 90% çåç¡®çï¼æä»¬çå®éªç»æè¯å®äºè¿ä¸ç¹ãæä¾äºå®éªç»æçå¯è§åè¡¨ç¤ºï¼ä»¥å¢å¼ºæ¨¡åçå¯è§£éæ§å¹¶å¸®å©çè§£åç±»è¿ç¨ã

##### **An Empirical Analysis of Uncertainty in Large Language Model Evaluations**
2502.10709v1 by Qiujie Xie, Qingqiu Li, Zhuohao Yu, Yuejie Zhang, Yue Zhang, Linyi Yang

As LLM-as-a-Judge emerges as a new paradigm for assessing large language
models (LLMs), concerns have been raised regarding the alignment, bias, and
stability of LLM evaluators. While substantial work has focused on alignment
and bias, little research has concentrated on the stability of LLM evaluators.
In this paper, we conduct extensive experiments involving 9 widely used LLM
evaluators across 2 different evaluation settings to investigate the
uncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators
exhibit varying uncertainty based on model families and sizes. With careful
comparative analyses, we find that employing special prompting strategies,
whether during inference or post-training, can alleviate evaluation uncertainty
to some extent. By utilizing uncertainty to enhance LLM's reliability and
detection capability in Out-Of-Distribution (OOD) data, we further fine-tune an
uncertainty-aware LLM evaluator named ConfiLM using a human-annotated
fine-tuning set and assess ConfiLM's OOD evaluation ability on a manually
designed test set sourced from the 2024 Olympics. Experimental results
demonstrate that incorporating uncertainty as additional information during the
fine-tuning phase can largely improve the model's evaluation performance in OOD
scenarios. The code and data are released at:
https://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.

æè¦ï¼é¨è LLM ä½çºæ³å®çæ°å¸ç¯åºç¾ï¼ç¨æ¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) ç LLM è©ä¼°å¨å¨å°é½ãåå·®åç©©å®æ§æ¹é¢å¼ç¼äºéæ³¨ãåç®¡å¤§éå·¥ä½éä¸­å¨å°é½ååå·®ä¸ï¼ä½å¾å°æç ç©¶éä¸­å¨ LLM è©ä¼°å¨çç©©å®æ§ä¸ãå¨æ¬æä¸­ï¼æåé²è¡äºå»£æ³çå¯¦é©ï¼æ¶å 9 åå»£æ³ä½¿ç¨ç LLM è©ä¼°å¨ï¼è·¨è¶ 2 åä¸åçè©ä¼°è¨­å®ï¼ä»¥èª¿æ¥åºæ¼æ¨¡åç LLM è©ä¼°ä¸­çä¸ç¢ºå®æ§ãæåç²¾ç¢ºæåº LLM è©ä¼°å¨æ ¹ææ¨¡åç³»ååå¤§å°è¡¨ç¾åºä¸åçä¸ç¢ºå®æ§ãééä»ç´°çæ¯è¼åæï¼æåç¼ç¾æ¡ç¨ç¹æ®çæç¤ºç­ç¥ï¼ç¡è«æ¯å¨æ¨çéç¨ä¸­éæ¯è¨ç·´å¾ï¼å¯ä»¥å¨ä¸å®ç¨åº¦ä¸ç·©è§£è©ä¼°ä¸ç¢ºå®æ§ãééå©ç¨ä¸ç¢ºå®æ§ä¾å¢å¼· LLM å¨ Out-Of-Distribution (OOD) æ¸æä¸­çå¯é æ§åæª¢æ¸¬è½åï¼æåé²ä¸æ­¥å¾®èª¿äºä¸ååçº ConfiLM çä¸ç¢ºå®æ§æç¥ LLM è©ä¼°å¨ï¼ä½¿ç¨äººå·¥è¨»éçå¾®èª¿è¨­ç½®ï¼ä¸¦è©ä¼° ConfiLM å¨æåè¨­è¨çãä¾èª 2024 å¹´å¥§éæçæ¸¬è©¦éä¸ç OOD è©ä¼°è½åãå¯¦é©çµæè¡¨æï¼å¨å¾®èª¿éæ®µå°ä¸ç¢ºå®æ§ä½çºéå ä¿¡æ¯ç´å¥å¶ä¸­å¯ä»¥å¨å¾å¤§ç¨åº¦ä¸æé«æ¨¡åå¨ OOD å ´æ¯ä¸­çè©ä¼°æ§è½ãä»£ç¢¼åæ¸æç¼å¸æ¼ï¼
https://github.com/hasakiXie123/LLM-Evaluator-Uncertaintyã

##### **Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model**
2502.10707v1 by Jiarui Jin, Haoyu Wang, Hongyan Li, Jun Li, Jiahui Pan, Shenda Hong

Electrocardiogram (ECG) is essential for the clinical diagnosis of
arrhythmias and other heart diseases, but deep learning methods based on ECG
often face limitations due to the need for high-quality annotations. Although
previous ECG self-supervised learning (eSSL) methods have made significant
progress in representation learning from unannotated ECG data, they typically
treat ECG signals as ordinary time-series data, segmenting the signals using
fixed-size and fixed-step time windows, which often ignore the form and rhythm
characteristics and latent semantic relationships in ECG signals. In this work,
we introduce a novel perspective on ECG signals, treating heartbeats as words
and rhythms as sentences. Based on this perspective, we first designed the
QRS-Tokenizer, which generates semantically meaningful ECG sentences from the
raw ECG signals. Building on these, we then propose HeartLang, a novel
self-supervised learning framework for ECG language processing, learning
general representations at form and rhythm levels. Additionally, we construct
the largest heartbeat-based ECG vocabulary to date, which will further advance
the development of ECG language processing. We evaluated HeartLang across six
public ECG datasets, where it demonstrated robust competitiveness against other
eSSL methods. Our data and code are publicly available at
https://github.com/PKUDigitalHealth/HeartLang.

æè¦ï¼å¿é»å (ECG) å°æ¼å¿å¾ä¸æ´åå¶ä»å¿èç¾ççè¨åºè¨ºæ·è³ééè¦ï¼ä½åºæ¼å¿é»åçæ·±åº¦å­¸ç¿æ¹æ³éå¸¸æå éè¦é«åè³ªè¨»è§£èé¢è¨éå¶ãåç®¡ååç ECG èªæç£ç£å­¸ç¿ (eSSL) æ¹æ³å¨å¾æªè¨»è§£ç ECG è³æä¸­å­¸ç¿è¡¨å¾µæ¹é¢åå¾é¡¯èé²å±ï¼ä½å®åéå¸¸å° ECG è¨èè¦çºæ®éçæéåºåè³æï¼ä½¿ç¨åºå®å¤§å°ååºå®æ­¥é·çæçªå°è¨èé²è¡åæ®µï¼ééå¸¸æå¿½ç¥ ECG è¨èä¸­çå½¢å¼åç¯å¾ç¹å¾µä»¥åæ½å¨çèªç¾©éä¿ãå¨éé å·¥ä½ä¸­ï¼æåå° ECG è¨èå¼å¥äºæ°çè§é»ï¼å°å¿è·³è¦çºå®å­ï¼å°ç¯å¾è¦çºå¥å­ãåºæ¼æ­¤è§é»ï¼æåé¦åè¨­è¨äº QRS-Tokenizerï¼å®å¾åå§ ECG è¨èä¸­ç¢çèªç¾©ææç¾©ç ECG å¥å­ãå¨æ­¤åºç¤ä¸ï¼æåæåºäº HeartLangï¼ä¸ç¨®ç¨æ¼ ECG èªè¨èççæ°åèªæç£ç£å­¸ç¿æ¡æ¶ï¼å¨å½¢å¼åç¯å¾å±¤é¢ä¸å­¸ç¿ä¸è¬è¡¨å¾µãæ­¤å¤ï¼æåæ§å»ºäºè¿ä»çºæ­¢æå¤§çåºæ¼å¿è·³ç ECG è©å½è¡¨ï¼éå°é²ä¸æ­¥ä¿é² ECG èªè¨èççç¼å±ãæåå¨å­åå¬éç ECG è³æéä¸è©ä¼°äº HeartLangï¼å®å±ç¤ºäºèå¶ä» eSSL æ¹æ³ç¸æ¯çå¼·å¤§ç«¶ç­åãæåçè³æåç¨å¼ç¢¼å¯å¨ https://github.com/PKUDigitalHealth/HeartLang å¬éåå¾ã

##### **Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction**
2502.10689v1 by Leisheng Yu, Yanxiao Cai, Minxing Zhang, Xia Hu

The burgeoning volume of electronic health records (EHRs) has enabled deep
learning models to excel in predictive healthcare. However, for high-stakes
applications such as diagnosis prediction, model interpretability remains
paramount. Existing deep learning diagnosis prediction models with intrinsic
interpretability often assign attention weights to every past diagnosis or
hospital visit, providing explanations lacking flexibility and succinctness. In
this paper, we introduce SHy, a self-explaining hypergraph neural network
model, designed to offer personalized, concise and faithful explanations that
allow for interventions from clinical experts. By modeling each patient as a
unique hypergraph and employing a message-passing mechanism, SHy captures
higher-order disease interactions and extracts distinct temporal phenotypes as
personalized explanations. It also addresses the incompleteness of the EHR data
by accounting for essential false negatives in the original diagnosis record. A
qualitative case study and extensive quantitative evaluations on two real-world
EHR datasets demonstrate the superior predictive performance and
interpretability of SHy over existing state-of-the-art models.

æè¦ï¼é¨èé»å­å¥åº·ç´é (EHR) æ¸éçæ¿å¢ï¼æ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬ä¿å¥æ¹é¢è¡¨ç¾åºè²ãç¶èï¼å°æ¼è¨ºæ·é æ¸¬ç­é«é¢¨éªæç¨ï¼æ¨¡åçå¯è§£éæ§ä»ç¶è³ééè¦ãç¾æçå·æå§å¨å¯è§£éæ§çæ·±åº¦å­¸ç¿è¨ºæ·é æ¸¬æ¨¡åéå¸¸æçºæ¯åéå»çè¨ºæ·æé«é¢å°±è¨ºåéæ³¨æåæ¬éï¼æä¾çè§£éç¼ºä¹éæ´»æ§ä¸ç°¡æ½æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº SHyï¼éæ¯ä¸åèªè§£éçè¶åç¥ç¶ç¶²è·¯æ¨¡åï¼æ¨å¨æä¾åæ§åãç°¡æ½ä¸å¿ å¯¦çè§£éï¼è®è¨åºå°å®¶å¯ä»¥é²è¡å¹²é ãééå°æ¯åæ£èå»ºæ¨¡çºä¸åç¨ç¹çè¶åä¸¦æ¡ç¨è¨æ¯å³éæ©å¶ï¼SHy ææå°äºé«éç¾çäº¤äºä½ç¨ï¼ä¸¦æååºä¸åçæéè¡¨åä½çºåæ§åè§£éãå®éééèæ®åå§è¨ºæ·è¨éä¸­çåºæ¬åé°æ§ä¾è§£æ±ºé»å­å¥åº·ç´éè³æçä¸å®æ´æ§ãå°å©åçå¯¦ä¸çé»å­å¥åº·ç´éè³æéé²è¡çå®æ§æ¡ä¾ç ç©¶åå»£æ³çå®éè©ä¼°è¡¨æï¼SHy å¨é æ¸¬æè½åå¯è§£éæ§æ¹é¢åªæ¼ç¾æçæåé²æ¨¡åã

##### **ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language Interactions for Computer-Aided Diagnosis**
2502.10620v1 by Xueshen Li, Xinlong Hou, Ziyi Huang, Yu Gan

Recent advancements in large language models (LLMs) have demonstrated
extraordinary comprehension capabilities with remarkable breakthroughs on
various vision-language tasks. However, the application of LLMs in generating
reliable medical diagnostic reports remains in the early stages. Currently,
medical LLMs typically feature a passive interaction model where doctors
respond to patient queries with little or no involvement in analyzing medical
images. In contrast, some ChatBots simply respond to predefined queries based
on visual inputs, lacking interactive dialogue or consideration of medical
history. As such, there is a gap between LLM-generated patient-ChatBot
interactions and those occurring in actual patient-doctor consultations. To
bridge this gap, we develop an LLM-based dialogue system, namely proactive
multi-round vision-language interactions for computer-aided diagnosis
(ProMRVL-CAD), to generate patient-friendly disease diagnostic reports. The
proposed ProMRVL-CAD system allows proactive dialogue to provide patients with
constant and reliable medical access via an integration of knowledge graph into
a recommendation system. Specifically, we devise two generators: a Proactive
Question Generator (Pro-Q Gen) to generate proactive questions that guide the
diagnostic procedure and a Multi-Vision Patient-Text Diagnostic Report
Generator (MVP-DR Gen) to produce high-quality diagnostic reports. Evaluating
two real-world publicly available datasets, MIMIC-CXR and IU-Xray, our model
has better quality in generating medical reports. We further demonstrate the
performance of ProMRVL achieves robust under the scenarios with low image
quality. Moreover, we have created a synthetic medical dialogue dataset that
simulates proactive diagnostic interactions between patients and doctors,
serving as a valuable resource for training LLM.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) æè¿çé²å±å·²å±ç¾åºéå¡ççè§£è½åï¼å¨åç¨®è¦è¦ºèªè¨ä»»åä¸­åå¾äºé¡¯èççªç ´ãç¶èï¼LLM å¨ç¢çå¯é çé«çè¨ºæ·å ±åä¸­çæç¨ä»èæ¼æ©æéæ®µãç®åï¼é«ç LLM éå¸¸æ¡ç¨è¢«åäºåæ¨¡å¼ï¼é«çå°æ£èççåååºåæï¼ä½å¾å°ææ ¹æ¬ä¸åèåæé«çå½±åãç¸æ¯ä¹ä¸ï¼æäºèå¤©æ©å¨äººåæ ¹æè¦è¦ºè¼¸å¥åæé åå®ç¾©çæ¥è©¢ï¼ç¼ºä¹äºåå°è©±æå°çå²çèéãå æ­¤ï¼LLM ç¢ççæ£èèå¤©æ©å¨äººäºåèå¯¦éæ£èé«çè«®è©¢ä¹éå­å¨å·®è·ãçºäºå½åéä¸å·®è·ï¼æåéç¼äºä¸ååºæ¼ LLM çå°è©±ç³»çµ±ï¼å³ä¸»åå¤è¼ªè¦è¦ºèªè¨äºåï¼ç¨æ¼é»è¦è¼å©è¨ºæ· (ProMRVL-CAD)ï¼ä»¥ç¢çå°æ£èååçç¾çè¨ºæ·å ±åãå»ºè­°ç ProMRVL-CAD ç³»çµ±åè¨±ä¸»åå°è©±ï¼ééå°ç¥è­åè­æ´åå°æ¨è¦ç³»çµ±ä¸­ï¼çºæ£èæä¾æçºä¸å¯é çé«çç®¡éãå·é«ä¾èªªï¼æåè¨­è¨äºå©åç¢çå¨ï¼ä¸»ååé¡ç¢çå¨ (Pro-Q Gen)ï¼ç¨æ¼ç¢çå¼å°è¨ºæ·ç¨åºçä¸»ååé¡ï¼ä»¥åå¤è¦è¦ºæ£èæå­è¨ºæ·å ±åç¢çå¨ (MVP-DR Gen)ï¼ç¨æ¼ç¢çé«åè³ªçè¨ºæ·å ±åãè©ä¼°å©åçå¯¦ä¸çå¬éå¯ç¨çè³æéï¼MIMIC-CXR å IU-Xrayï¼æåçæ¨¡åå¨ç¢çé«çå ±åæ¹é¢åè³ªè¼ä½³ãæåé²ä¸æ­¥è­æ ProMRVL çæè½ï¼å¨å½±ååè³ªä½çææ³ä¸ä»è½ç©©å¥éè¡ãæ­¤å¤ï¼æåå»ºç«äºä¸åæ¨¡æ¬æ£èåé«çä¹éä¸»åè¨ºæ·äºåçåæé«çå°è©±è³æéï¼ä½çºè¨ç·´ LLM çå¯¶è²´è³æºã</paragraph>

##### **Optimizing CNN Architectures for Advanced Thoracic Disease Classification**
2502.10614v1 by Tejas Mirthipati

Machine learning, particularly convolutional neural networks (CNNs), has
shown promise in medical image analysis, especially for thoracic disease
detection using chest X-ray images. In this study, we evaluate various CNN
architectures, including binary classification, multi-label classification, and
ResNet50 models, to address challenges like dataset imbalance, variations in
image quality, and hidden biases. We introduce advanced preprocessing
techniques such as principal component analysis (PCA) for image compression and
propose a novel class-weighted loss function to mitigate imbalance issues. Our
results highlight the potential of CNNs in medical imaging but emphasize that
issues like unbalanced datasets and variations in image acquisition methods
must be addressed for optimal model performance.

æè¦ï¼æ©å¨å­¸ç¿ï¼ç¹å¥æ¯å·ç©ç¥ç¶ç¶²è·¯ (CNN) å·²å¨é«å­¸å½±ååæä¸­å±ç¾åºæ½åï¼ç¹å¥æ¯ä½¿ç¨è¸é¨ X åå½±åé²è¡è¸èç¾çåµæ¸¬ãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°åç¨® CNN æ¶æ§ï¼åæ¬äºååé¡ãå¤æ¨ç±¤åé¡å ResNet50 æ¨¡åï¼ä»¥è§£æ±ºè³æéä¸å¹³è¡¡ãå½±ååè³ªå·®ç°åé±èåå·®ç­ææ°ãæåå°å¥é²éåèçæè¡ï¼ä¾å¦ä¸»æååæ (PCA) ä»¥é²è¡å½±åå£ç¸®ï¼ä¸¦æåºä¸åæ°ç©çé¡å¥å æ¬æå¤±å½æ¸ä¾ç·©è§£ä¸å¹³è¡¡åé¡ãæåççµæçªé¡¯äº CNN å¨é«å­¸å½±åä¸­çæ½åï¼ä½å¼·èª¿å¿é è§£æ±ºè³æéä¸å¹³è¡¡åå½±åæ·åæ¹æ³å·®ç°ç­åé¡ï¼æè½ç²å¾æä½³æ¨¡åæè½ã

##### **PolyPath: Adapting a Large Multimodal Model for Multi-slide Pathology Report Generation**
2502.10536v1 by Faruk Ahmed, Lin Yang, Tiam Jaroensri, Andrew Sellergren, Yossi Matias, Avinatan Hassidim, Greg S. Corrado, Dale R. Webster, Shravya Shetty, Shruthi Prabhakara, Yun Liu, Daniel Golden, Ellery Wulczyn, David F. Steiner

The interpretation of histopathology cases underlies many important
diagnostic and treatment decisions in medicine. Notably, this process typically
requires pathologists to integrate and summarize findings across multiple
slides per case. Existing vision-language capabilities in computational
pathology have so far been largely limited to small regions of interest, larger
regions at low magnification, or single whole-slide images (WSIs). This limits
interpretation of findings that span multiple high-magnification regions across
multiple WSIs. By making use of Gemini 1.5 Flash, a large multimodal model
(LMM) with a 1-million token context window, we demonstrate the ability to
generate bottom-line diagnoses from up to 40,000 768x768 pixel image patches
from multiple WSIs at 10X magnification. This is the equivalent of up to 11
hours of video at 1 fps. Expert pathologist evaluations demonstrate that the
generated report text is clinically accurate and equivalent to or preferred
over the original reporting for 68% (95% CI: [60%, 76%]) of multi-slide
examples with up to 5 slides. While performance decreased for examples with 6
or more slides, this study demonstrates the promise of leveraging the
long-context capabilities of modern LMMs for the uniquely challenging task of
medical report generation where each case can contain thousands of image
patches.

æè¦ï¼çµç¹ççå­¸çä¾çè§£è®æ¯è¨±å¤éè¦çé«å­¸è¨ºæ·åæ²»çæ±ºç­çåºç¤ãå¼å¾æ³¨æçæ¯ï¼éåéç¨éå¸¸éè¦ççå­¸å®¶æ´ååç¸½çµæ¯åçä¾çè¨±å¤ç»çä¸­çç¼ç¾ãè¿ä»çºæ­¢ï¼è¨ç®æ©ççå­¸ä¸­ç¾æçè¦è¦ºèªè¨åè½å¨å¾å¤§ç¨åº¦ä¸åéæ¼å°ç¯åçæèè¶£ååãä½åçä¸çè¼å¤§ååæå®ä¸çå¨ç»çå½±å (WSI)ãééå¶äºè·¨å¤å WSI ä¸­å¤åé«åçååçç¼ç¾çè§£è®ãééä½¿ç¨ Gemini 1.5 Flashï¼ä¸åå·æ 100 è¬åä»¤çä¸ä¸æè¦çªçå¤§åå¤æ¨¡ææ¨¡å (LMM)ï¼æåå±ç¤ºäºå¾å¤å WSI ä¸­å¤é 40,000 å 768x768 åç´ ååè²¼çï¼10 åæ¾å¤§ï¼çæåºç·è¨ºæ·çè½åãéç¸ç¶æ¼ 1 fps ä¸é·é 11 å°æçå½±çãå°å®¶ççå­¸å®¶è©ä¼°è¡¨æï¼çæçå ±åæå­å¨è¨åºä¸æ¯æºç¢ºçï¼ä¸¦ä¸ç­åæ¼æåªæ¼ 68%ï¼95% CIï¼[60%ï¼76%]ï¼çå¤ç»çç¯ä¾ï¼æå¤ 5 åç»çï¼çåå§å ±åãåç®¡å°æ¼æ 6 åææ´å¤ç»ççç¯ä¾ï¼å¶æ§è½ä¸éï¼ä½éé ç ç©¶è­æäºå©ç¨ç¾ä»£ LMM çé·ä¸ä¸æåè½ä¾æå°ç¨ç¹ææ°æ§çé«çå ±åçæä»»åï¼å¶ä¸­æ¯åçä¾å¯è½åå«æ¸ååå½±åè²¼çï¼éé ä»»åçåæ¯ã

##### **Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks**
2502.10526v1 by Venkatesh Sivaraman, Anika Vaishampayan, Xiaotong Li, Brian R Buck, Ziyong Ma, Richard D Boyce, Adam Perer

Temporal predictive models have the potential to improve decisions in health
care, public services, and other domains, yet they often fail to effectively
support decision-makers. Prior literature shows that many misalignments between
model behavior and decision-makers' expectations stem from issues of model
specification, namely how, when, and for whom predictions are made. However,
model specifications for predictive tasks are highly technical and difficult
for non-data-scientist stakeholders to interpret and critique. To address this
challenge we developed Tempo, an interactive system that helps data scientists
and domain experts collaboratively iterate on model specifications. Using
Tempo's simple yet precise temporal query language, data scientists can quickly
prototype specifications with greater transparency about pre-processing
choices. Moreover, domain experts can assess performance within data subgroups
to validate that models behave as expected. Through three case studies, we
demonstrate how Tempo helps multidisciplinary teams quickly prune infeasible
specifications and identify more promising directions to explore.

æè¦ï¼æéé æ¸¬æ¨¡åå·ææ¹åé«çä¿å¥ãå¬å±æååå¶ä»é åæ±ºç­çæ½åï¼ä½å®åéå¸¸ç¡æ³æææ¯ææ±ºç­èãååçæç»è¡¨æï¼æ¨¡åè¡çºèæ±ºç­èææä¹éçè¨±å¤ä¸ä¸è´æºæ¼æ¨¡åè¦ç¯åé¡ï¼å³å¦ä½ãä½æä»¥åéå°èª°é²è¡é æ¸¬ãç¶èï¼é æ¸¬ä»»åçæ¨¡åè¦ç¯éå¸¸æè¡åï¼éæ¸æç§å­¸å®¶å©çç¸éèé£ä»¥è§£éåæ¹è©ãçºäºæå°éä¸ææ°ï¼æåéç¼äº Tempoï¼éæ¯ä¸åäºåå¼ç³»çµ±ï¼å¯å¹«å©æ¸æç§å­¸å®¶åé åå°å®¶åä½åè¦éç®æ¨¡åè¦ç¯ãä½¿ç¨ Tempo ç°¡å®ä½ç²¾ç¢ºçæéæ¥è©¢èªè¨ï¼æ¸æç§å­¸å®¶å¯ä»¥å¿«éå»ºç«è¦ç¯ååï¼ä¸¦æ´éæå°äºè§£é èçé¸æãæ­¤å¤ï¼é åå°å®¶å¯ä»¥è©ä¼°è³æå­ç¾¤çµå§çæè½ï¼ä»¥é©è­æ¨¡åæ¯å¦æé æå·è¡ãééä¸åæ¡ä¾ç ç©¶ï¼æåå±ç¤ºäº Tempo å¦ä½å¹«å©è·¨é ååéå¿«éåªé¤ä¸å¯è¡çè¦ç¯ï¼ä¸¦æ¾åºæ´æå¸ææ¢ç´¢çæ¹åã

##### **A Robust Attack: Displacement Backdoor Attack**
2502.10490v1 by Yong Li, Han Gao

As artificial intelligence becomes more prevalent in our lives, people are
enjoying the convenience it brings, but they are also facing hidden threats,
such as data poisoning and ad- versarial attacks. These threats can have
disastrous consequences for the application of artificial intelligence,
especially for some applications that take effect immediately, such as
autonomous driving and medical fields. Among these threats, backdoor attacks
have left a deep impression on people with their concealment and simple
deployment, making them a threat that cannot be ignored, however, in the
process of deploying the backdoor model, the backdoor attack often has some
reasons that make it unsatisfactory in real-world applications, such as jitter
and brightness changes. Based on this, we propose a highly robust backdoor
attack that shifts the target sample and combines it with itself to form a
backdoor sample, the Displacement Backdoor Attack(DBA). Experimental results
show that the DBA attack can resist data augmentation that simulates real-world
differences, such as rotation and cropping.

æè¦ï¼éçäººå·¥æºè½å¨æä»¬ççæ´»ä¸­åå¾è¶æ¥è¶æ®éï¼äººä»¬æ­£å¨äº«åå®å¸¦æ¥çä¾¿å©ï¼ä½ä¹é¢ä¸´çéèçå¨èï¼ä¾å¦æ°æ®ä¸­æ¯åå¯¹ææ§æ»å»ãè¿äºå¨èå¯è½å¯¹äººå·¥æºè½çåºç¨äº§çç¾é¾æ§åæï¼ç¹å«æ¯å¯¹äºä¸äºç«å³çæçåºç¨ï¼ä¾å¦èªå¨é©¾é©¶åå»çé¢åãå¨è¿äºå¨èä¸­ï¼åé¨æ»å»ä»¥å¶éè½æ§åç®åçé¨ç½²ç»äººä»¬çä¸äºæ·±å»çå°è±¡ï¼ä½¿å¶æä¸ºä¸å¯å¿½è§çå¨èï¼ç¶èï¼å¨é¨ç½²åé¨æ¨¡åçè¿ç¨ä¸­ï¼åé¨æ»å»å¾å¾å­å¨ä¸äºä½¿å¶å¨å®éåºç¨ä¸­ä¸å°½å¦äººæçåå ï¼ä¾å¦æå¨åäº®åº¦ååãåºäºæ­¤ï¼æä»¬æåºäºä¸ç§é«åº¦é²æ£çåé¨æ»å»ï¼è¯¥æ»å»å¯¹ç®æ æ ·æ¬è¿è¡å¹³ç§»å¹¶å°å¶ä¸èªèº«ç»åä»¥å½¢æåé¨æ ·æ¬ï¼å³ç½®æ¢åé¨æ»å» (DBA)ãå®éªç»æè¡¨æï¼DBA æ»å»å¯ä»¥æµææ¨¡æçå®ä¸çå·®å¼çæ°æ®å¢å¼ºï¼ä¾å¦æè½¬åè£åªã

##### **3D ReX: Causal Explanations in 3D Neuroimaging Classification**
2502.12181v1 by Melane Navaratnarajah, Sophie A. Martin, David A. Kelly, Nathan Blake, Hana Chocker

Explainability remains a significant problem for AI models in medical
imaging, making it challenging for clinicians to trust AI-driven predictions.
We introduce 3D ReX, the first causality-based post-hoc explainability tool for
3D models. 3D ReX uses the theory of actual causality to generate
responsibility maps which highlight the regions most crucial to the model's
decision. We test 3D ReX on a stroke detection model, providing insight into
the spatial distribution of features relevant to stroke.

æè¦ï¼è§£éæ§ä»ç¶æ¯é«çå½±åä¸­ AI æ¨¡åçä¸å¤§åé¡ï¼éä½¿å¾è¨åºé«çé£ä»¥ä¿¡ä»» AI é©åçé æ¸¬ã
æåå¼å¥äº 3D ReXï¼éæ¯ç¬¬ä¸åç¨æ¼ 3D æ¨¡åçåºæ¼å æéä¿çäºå¾è§£éæ§å·¥å·ã3D ReX ä½¿ç¨å¯¦éå æéä¿çè«ä¾çæè²¬ä»»åï¼è©²åçªåºäºå°æ¨¡åæ±ºç­è³ééè¦çååãæåå¨ä¸­é¢¨æª¢æ¸¬æ¨¡åä¸æ¸¬è©¦äº 3D ReXï¼æä¾äºèä¸­é¢¨ç¸éç¹å¾µçç©ºéåä½çè¦è§£ã

##### **Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model**
2502.09947v1 by Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott

In the analysis of remote healthcare monitoring data, time series
representation learning offers substantial value in uncovering deeper patterns
of patient behavior, especially given the fine temporal granularity of the
data. In this study, we focus on a dataset of home activity records from people
living with Dementia. We propose a two-stage self-supervised learning approach.
The first stage involves converting time-series activities into text strings,
which are then encoded by a fine-tuned language model. In the second stage,
these time-series vectors are bi-dimensionalized for applying PageRank method,
to analyze latent state transitions to quantitatively assess participants
behavioral patterns and identify activity biases. These insights, combined with
diagnostic data, aim to support personalized care interventions.

æè¦ï¼å¨é ç¨é«çç£æ§æ¸æåæä¸­ï¼æåºè¡¨ç¤ºå­¸ç¿å¨æ­ç¤ºæ£èè¡çºçæ´æ·±å±¤æ¨¡å¼æ¹é¢æä¾äºå¯¦è³ªæ§çå¹å¼ï¼ç¹å¥æ¯èæ®å°æ¸æçç²¾ç´°æéç²åº¦ãå¨æ¬ç ç©¶ä¸­ï¼æåå°æ³¨æ¼ç´åçæ£èå±å®¶æ´»åè¨éçæ¸æéãæåæåºäºä¸ç¨®å©éæ®µçèªæç£ç£å­¸ç¿æ¹æ³ãç¬¬ä¸éæ®µæ¶åå°æåºæ´»åè½æçºææ¬ä¸²ï¼ç¶å¾ç±å¾®èª¿èªè¨æ¨¡åç·¨ç¢¼ãå¨ç¬¬äºéæ®µï¼éäºæåºåéè¢«éç¶­åä»¥æç¨ PageRank æ¹æ³ï¼åææ½å¨çæè½æä»¥å®éè©ä¼°åèèçè¡çºæ¨¡å¼ä¸¦è­å¥æ´»ååå·®ãéäºè¦è§£èè¨ºæ·æ¸æç¸çµåï¼æ¨å¨æ¯æåæ§åè­·çå¹²é ã

##### **TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation**
2502.09931v1 by Ju-Hyeon Nam, Nur Suriza Syazwany, Sang-Chul Lee

Skip connection engineering is primarily employed to address the semantic gap
between the encoder and decoder, while also integrating global dependencies to
understand the relationships among complex anatomical structures in medical
image segmentation. Although several models have proposed transformer-based
approaches to incorporate global dependencies within skip connections, they
often face limitations in capturing detailed local features with high
computational complexity. In contrast, graph neural networks (GNNs) exploit
graph structures to effectively capture local and global features. Leveraging
these properties, we introduce an attentional cross-scale graph neural network
(ACS-GNN), which enhances the skip connection framework by converting
cross-scale feature maps into a graph structure and capturing complex
anatomical structures through node attention. Additionally, we observed that
deep learning models often produce uninformative feature maps, which degrades
the quality of spatial attention maps. To address this problem, we integrated
entropy-driven feature selection (EFS) with spatial attention, calculating an
entropy score for each channel and filtering out high-entropy feature maps. Our
innovative framework, TransGUNet, comprises ACS-GNN and EFS-based spatial
attentio} to effectively enhance domain generalizability across various
modalities by leveraging GNNs alongside a reliable spatial attention map,
ensuring more robust features within the skip connection. Through comprehensive
experiments and analysis, TransGUNet achieved superior segmentation performance
on six seen and eight unseen datasets, demonstrating significantly higher
efficiency compared to previous methods.

æè¦ï¼è·³èºé£æ¥å·¥ç¨ä¸»è¦ç¨æ¼è§£æ±ºç·¨ç¢¼å¨åè§£ç¢¼å¨ä¹éçèªç¾©é´»æºï¼åæéæ´åå¨å±ä¾è³´éä¿ä»¥äºè§£é«å­¸å½±ååå²ä¸­è¤éè§£åçµæ§ä¹éçéä¿ãåç®¡æå¹¾åæ¨¡åæåºäºåºæ¼Transformerçæ¶æ§ä¾æ´åè·³èºé£æ¥ä¸­çå¨å±ä¾è³´éä¿ï¼ä½å®åå¨ä»¥é«è¨ç®è¤éåº¦æ·åè©³ç´°çå±é¨ç¹å¾µæå¸¸å¸¸é¢è¨éå¶ãç¸æ¯ä¹ä¸ï¼åç¥ç¶ç¶²è·¯ (GNN) å©ç¨åçµæ§æææ·åå±é¨åå¨å±ç¹å¾µãå©ç¨éäºå±¬æ§ï¼æåå¼å¥äºæ³¨æåè·¨å°ºåº¦åç¥ç¶ç¶²è·¯ (ACS-GNN)ï¼å®ééå°è·¨å°ºåº¦ç¹å¾µåè½æçºåçµæ§ä¸¦ééç¯é»æ³¨æåæ·åè¤éçè§£åçµæ§ä¾å¢å¼·è·³èºé£æ¥æ¡æ¶ãæ­¤å¤ï¼æåè§å¯å°æ·±åº¦å­¸ç¿æ¨¡åéå¸¸æç¢çç¡æç¾©çç¹å¾µåï¼éæéä½ç©ºéæ³¨æååçåè³ªãçºäºè§£æ±ºéååé¡ï¼æåå°çµé©åç¹å¾µé¸æ (EFS) èç©ºéæ³¨æåæ´åå¨ä¸èµ·ï¼çºæ¯åééè¨ç®çµåæ¸ä¸¦æ¿¾åºé«çµç¹å¾µåãæååµæ°çæ¡æ¶ TransGUNet åå« ACS-GNN ååºæ¼ EFS çç©ºéæ³¨æåï¼ééå©ç¨ GNN ä»¥åå¯é çç©ºéæ³¨æååææå¢å¼·è·¨åç¨®æ¨¡æçåæ³åè½åï¼ç¢ºä¿è·³èºé£æ¥ä¸­æ´å¼·å¤§çç¹å¾µãééå¨é¢çå¯¦é©ååæï¼TransGUNet å¨å­åå·²è¦åå«åæªè¦çè³æéä¸å¯¦ç¾äºåªç°çåå²æè½ï¼è­æèååçæ¹æ³ç¸æ¯ï¼æçé¡¯èæé«ã

##### **Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos**
2502.09886v1 by Weirui Ye, Fangchen Liu, Zheng Ding, Yang Gao, Oleh Rybkin, Pieter Abbeel

Simulation offers a promising approach for cheaply scaling training data for
generalist policies. To scalably generate data from diverse and realistic
tasks, existing algorithms either rely on large language models (LLMs) that may
hallucinate tasks not interesting for robotics; or digital twins, which require
careful real-to-sim alignment and are hard to scale. To address these
challenges, we introduce Video2Policy, a novel framework that leverages
internet RGB videos to reconstruct tasks based on everyday human behavior. Our
approach comprises two phases: (1) task generation in simulation from videos;
and (2) reinforcement learning utilizing in-context LLM-generated reward
functions iteratively. We demonstrate the efficacy of Video2Policy by
reconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,
which depicts diverse and complex human behaviors on 9 different tasks. Our
method can successfully train RL policies on such tasks, including complex and
challenging tasks such as throwing. Finally, we show that the generated
simulation data can be scaled up for training a general policy, and it can be
transferred back to the real robot in a Real2Sim2Real way.

æè¦ï¼æ¨¡æ¬æä¾äºä¸ç¨®æåéçæ¹æ³ï¼å¯ä»¥ç¨æ¼æ´å±è¨ç·´è³æï¼ä»¥å¶å®éææ¿ç­ãçºäºå¾å¤æ¨£åä¸é¼ççä»»åä¸­å¯æ´åå°ç¢çè³æï¼ç¾ææ¼ç®æ³ä»°è³´å¤§åèªè¨æ¨¡å (LLM)ï¼éäºæ¨¡åå¯è½æç¢çå°æ©å¨äººæè¡ä¸æèè¶£çä»»åï¼æèä»°è³´æ¸ä½éèèï¼ééè¦ä»ç´°å°å°çå¯¦ç°å¢èæ¨¡æ¬ç°å¢å°é½ï¼èä¸å¾é£æ´åãçºäºæå°éäºææ°ï¼æåå¼å¥äº Video2Policyï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼å®å©ç¨ç¶²è·¯ä¸ç RGB å½±çï¼æ ¹ææ¥å¸¸äººé¡è¡çºä¾éå»ºä»»åãæåçåæ³åå«å©åéæ®µï¼(1) å¾å½±çä¸­å¨æ¨¡æ¬ç°å¢ä¸­ç¢çä»»åï¼ä»¥å (2) å©ç¨å¨æå¢ä¸­ç± LLM ç¢çççåµå½æ¸ï¼åè¦é²è¡å¼·åå­¸ç¿ãæåéééå»º Something-Something-v2 (SSv2) è³æéä¸­ç 100 å¤åå½±çä¾å±ç¤º Video2Policy çæè½ï¼éäºå½±çæç¹ªäº 9 é ä¸åä»»åä¸­å¤æ¨£åä¸è¤éçäººé¡è¡çºãæåçåæ³å¯ä»¥å¨éäºä»»åä¸æåè¨ç·´ RL æ¿ç­ï¼åæ¬è¤éä¸å·ææ°æ§çä»»åï¼ä¾å¦ææ²ãæå¾ï¼æåå±ç¤ºäºç¢ççæ¨¡æ¬è³æå¯ä»¥æ´åå°è¨ç·´ä¸è¬æ¿ç­ï¼èä¸å¯ä»¥éé Real2Sim2Real çæ¹å¼è½ç§»åçå¯¦æ©å¨äººã

##### **HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation**
2502.09838v2 by Tianwei Lin, Wenqiao Zhang, Sijing Li, Yuqian Yuan, Binhe Yu, Haoyuan Li, Wanggui He, Hao Jiang, Mengze Li, Xiaohui Song, Siliang Tang, Jun Xiao, Hui Lin, Yueting Zhuang, Beng Chin Ooi

We present HealthGPT, a powerful Medical Large Vision-Language Model
(Med-LVLM) that integrates medical visual comprehension and generation
capabilities within a unified autoregressive paradigm. Our bootstrapping
philosophy is to progressively adapt heterogeneous comprehension and generation
knowledge to pre-trained large language models (LLMs). This is achieved through
a novel heterogeneous low-rank adaptation (H-LoRA) technique, which is
complemented by a tailored hierarchical visual perception approach and a
three-stage learning strategy. To effectively learn the HealthGPT, we devise a
comprehensive medical domain-specific comprehension and generation dataset
called VL-Health. Experimental results demonstrate exceptional performance and
scalability of HealthGPT in medical visual unified tasks. Our project can be
accessed at https://github.com/DCDmllm/HealthGPT.

æè¦ï¼æåæåº HealthGPTï¼ä¸ç¨®å¼·å¤§çé«å­¸å¤§åè¦è¦ºèªè¨æ¨¡å (Med-LVLM)ï¼å®æ´åäºé«å­¸è¦è¦ºçè§£åçæè½åæ¼ä¸åçµ±ä¸çèªåè¿´æ­¸ç¯ä¾ä¸­ãæåçå¼å°å²å­¸æ¯éæ­¥èª¿æ´ç°è³ªçè§£åçæç¥è­ä»¥é åè¨ç·´å¤§åèªè¨æ¨¡å (LLM)ãéæ¯ééä¸ç¨®æ°ç©çç°è³ªä½ç§©é©æ (H-LoRA) æè¡å¯¦ç¾çï¼è©²æè¡ç±éèº«å®å¶çåå±¤è¦è¦ºæç¥æ¹æ³åä¸éæ®µå­¸ç¿ç­ç¥è£åãçºäºææå­¸ç¿ HealthGPTï¼æåè¨­è¨äºä¸åå¨é¢çé«å­¸é åç¹å®çè§£åçææ¸æéï¼ç¨±çº VL-Healthãå¯¦é©çµæè­æäº HealthGPT å¨é«å­¸è¦è¦ºçµ±ä¸ä»»åä¸­çåè¶æ§è½åå¯æ´å±æ§ãæåçé ç®å¯ä»¥å¨ https://github.com/DCDmllm/HealthGPT ä¸­è¨ªåã

##### **Incentivize without Bonus: Provably Efficient Model-based Online Multi-agent RL for Markov Games**
2502.09780v1 by Tong Yang, Bo Dai, Lin Xiao, Yuejie Chi

Multi-agent reinforcement learning (MARL) lies at the heart of a plethora of
applications involving the interaction of a group of agents in a shared unknown
environment. A prominent framework for studying MARL is Markov games, with the
goal of finding various notions of equilibria in a sample-efficient manner,
such as the Nash equilibrium (NE) and the coarse correlated equilibrium (CCE).
However, existing sample-efficient approaches either require tailored
uncertainty estimation under function approximation, or careful coordination of
the players. In this paper, we propose a novel model-based algorithm, called
VMG, that incentivizes exploration via biasing the empirical estimate of the
model parameters towards those with a higher collective best-response values of
all the players when fixing the other players' policies, thus encouraging the
policy to deviate from its current equilibrium for more exploration. VMG is
oblivious to different forms of function approximation, and permits
simultaneous and uncoupled policy updates of all players. Theoretically, we
also establish that VMG achieves a near-optimal regret for finding both the NEs
of two-player zero-sum Markov games and CCEs of multi-player general-sum Markov
games under linear function approximation in an online environment, which
nearly match their counterparts with sophisticated uncertainty quantification.

æè¦ï¼å¤æºè½é«å¼·åå­¸ç¿ (MARL) æ¯ä¸ç³»åæç¨ç¨å¼çå¿èï¼éäºæç¨ç¨å¼æ¶åä¸ç¾¤æºè½é«å¨ä¸åå±ç¨æªç¥ç°å¢ä¸­çäºåãç ç©¶ MARL çä¸åèåæ¡æ¶æ¯é¦¬å¯å¤«åå¼ï¼å¶ç®æ¨æ¯ç¨æ¨£æ¬ææççæ¹å¼æ¾åºåç¨®åè¡¡æ¦å¿µï¼ä¾å¦ç´è¨±åè¡¡ (NE) åç²ç¸éåè¡¡ (CCE)ãç¶èï¼ç¾æçæ¨£æ¬ææçæ¹æ³éè¦å¨å½æ¸é¼è¿ä¸é²è¡éèº«æé çä¸ç¢ºå®æ§ä¼°è¨ï¼æè¬¹æåèª¿åèèãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çåºæ¼æ¨¡åçæ¼ç®æ³ï¼ç¨±çº VMGï¼å®ééå°æ¨¡ååæ¸çç¶é©ä¼°è¨å¼ååæ¼å¨åºå®å¶ä»åèèæ¿ç­æææåèèçéé«æä½³åæå¼ï¼å¾èæ¿åµæ¢ç´¢ï¼é²èé¼åµæ¿ç­åé¢å¶ç¶ååè¡¡ä»¥é²è¡æ´å¤æ¢ç´¢ãVMG ä¸æå¿½ç¥å½æ¸é¼è¿çä¸åå½¢å¼ï¼ä¸¦åè¨±ææåèèåæé²è¡éè¦åçæ¿ç­æ´æ°ãå¨çè«ä¸ï¼æåä¹å»ºç«äº VMG å¨ç·ä¸ç°å¢ä¸­ä½¿ç¨ç·æ§å½æ¸é¼è¿ä¾å°æ¾éäººé¶åé¦¬å¯å¤«åå¼ç NE åå¤äººä¸è¬åé¦¬å¯å¤«åå¼ç CCE æï¼æç²å¾æ¥è¿æä½³çå¾æï¼éå¹¾ä¹èå¶å¨ä¸ç¢ºå®æ§éåæ¹é¢æ´çºè¤éçå°æç©ç¸å¹éã

##### **The AI-Therapist Duo: Exploring the Potential of Human-AI Collaboration in Personalized Art Therapy for PICS Intervention**
2502.09757v1 by Bereket A. Yilma, Chan Mi Kim, Geke Ludden, Thomas van Rompay, Luis A. Leiva

Post-intensive care syndrome (PICS) is a multifaceted condition that arises
from prolonged stays in an intensive care unit (ICU). While preventing PICS
among ICU patients is becoming increasingly important, interventions remain
limited. Building on evidence supporting the effectiveness of art exposure in
addressing the psychological aspects of PICS, we propose a novel art therapy
solution through a collaborative Human-AI approach that enhances personalized
therapeutic interventions using state-of-the-art Visual Art Recommendation
Systems. We developed two Human-in-the-Loop (HITL) personalization methods and
assessed their impact through a large-scale user study (N=150). Our findings
demonstrate that this Human-AI collaboration not only enhances the
personalization and effectiveness of art therapy but also supports therapists
by streamlining their workload. While our study centres on PICS intervention,
the results suggest that human-AI collaborative Art therapy could potentially
benefit other areas where emotional support is critical, such as cases of
anxiety and depression.

æè¦ï¼éçå¾çåç¾¤ (PICS) æ¯ä¸ç¨®å¤é¢åçç¾çï¼æºèªæ¼å¨å è­·çæ¿ (ICU) é·æä½é¢ãéç¶é é²éçå¾çåç¾¤å¨å è­·çæ¿æ£èä¸­æ­£è®å¾è¶ä¾è¶éè¦ï¼ä½ä»å¥æªæ½ä»ç¶æéãå»ºç«å¨æ¯æèè¡æ¥è§¸å¨è§£æ±ºéçå¾çåç¾¤å¿çå±¤é¢çè­æä¸ï¼æåæåºä¸ååµæ°çèè¡çæ³è§£æ±ºæ¹æ¡ï¼ééåä½å¼çäººå·¥æºæ§æ¹æ³ï¼ä½¿ç¨æåé²çè¦è¦ºèè¡æ¨è¦ç³»çµ±ï¼å¢å¼·åäººåçæ²»çä»å¥ãæåéç¼äºå©ç¨®äººæ©è¿´è·¯ (HITL) åäººåæ¹æ³ï¼ä¸¦ééå¤§è¦æ¨¡ä½¿ç¨èç ç©¶ (N=150) è©ä¼°å¶å½±é¿ãæåçç¼ç¾è­æï¼éç¨®äººæ©åä½ä¸åå¢å¼·äºèè¡æ²»ççåäººååæææ§ï¼ä¹ééç°¡åæ²»çå¸«çå·¥ä½éä¾æä¾æ¯æ´ãéç¶æåçç ç©¶ä¸­å¿å¨éçå¾çåç¾¤ä»å¥ï¼ä½çµæé¡¯ç¤ºï¼äººæ©åä½èè¡çæ³æå¯è½å°å¶ä»éè¦æç·æ¯æçé åæçï¼ä¾å¦ç¦æ®åæé¬±çã

##### **A CNN Approach to Automated Detection and Classification of Brain Tumors**
2502.09731v1 by Md. Zahid Hasan, Abdullah Tamim, D. M. Asadujjaman, Md. Mahfujur Rahman, Md. Abu Ahnaf Mollick, Nosin Anjum Dristi, Abdullah-Al-Noman

Brain tumors require an assessment to ensure timely diagnosis and effective
patient treatment. Morphological factors such as size, location, texture, and
variable appearance com- plicate tumor inspection. Medical imaging presents
challenges, including noise and incomplete images. This research article
presents a methodology for processing Magnetic Resonance Imag- ing (MRI) data,
encompassing techniques for image classification and denoising. The effective
use of MRI images allows medical professionals to detect brain disorders,
including tumors. This research aims to categorize healthy brain tissue and
brain tumors by analyzing the provided MRI data. Unlike alternative methods
like Computed Tomography (CT), MRI technology offers a more detailed
representation of internal anatomical components, mak- ing it a suitable option
for studying data related to brain tumors. The MRI picture is first subjected
to a denoising technique utilizing an Anisotropic diffusion filter. The dataset
utilized for the models creation is a publicly accessible and validated Brain
Tumour Classification (MRI) database, comprising 3,264 brain MRI scans. SMOTE
was employed for data augmentation and dataset balancing. Convolutional Neural
Networks(CNN) such as ResNet152V2, VGG, ViT, and EfficientNet were employed for
the classification procedure. EfficientNet attained an accuracy of 98%, the
highest recorded.

æè¦ï¼è¦è«ç¤éè¦è©ä¼°ä»¥ç¢ºä¿åæè¨ºæ·åææçæ£èæ²»çãå¤§å°ãä½ç½®ãè³ªå°åå¯è®å¤è§ç­å½¢æå ç´ æä½¿è«ç¤æª¢æ¥è¤éåãé«å­¸å½±åæåç¾ææ°ï¼åæ¬éè¨åä¸å®æ´çå½±åãæ¬ç ç©¶æç« æåºäºä¸ç¨®èçç£å±æ¯å½±å (MRI) è³æçæ¹æ³ï¼åå«å½±ååé¡åå»åªæè¡ãææä½¿ç¨ MRI å½±åå¯è®é«è­·äººå¡åµæ¸¬è¦é¨ç¾çï¼åæ¬è«ç¤ãæ¬ç ç©¶æ¨å¨ééåææä¾ç MRI è³æä¾åé¡å¥åº·çè¦çµç¹åè¦ç¤ãèé»è¦æ·å±¤ææ (CT) ç­æ¿ä»£æ¹æ³ä¸åï¼MRI æè¡æä¾äºæ´è©³ç´°çå§é¨è§£åçµæ§è¡¨ç¤ºï¼ä½¿å¶æçºç ç©¶èè¦ç¤ç¸éè³æçåé©é¸æãMRI å½±åæåä½¿ç¨ååç°æ§æ´æ£æ¿¾æ³¢å¨é²è¡å»åªæè¡èçãç¨æ¼å»ºç«æ¨¡åçè³æéæ¯ä¸åå¬éä¸ç¶éé©è­çè¦è«ç¤åé¡ (MRI) è³æåº«ï¼åå« 3,264 åè¦é¨ MRI ææãSMOTE ç¨æ¼è³ææ´ååè³æéå¹³è¡¡ãå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä¾å¦ ResNet152V2ãVGGãViT å EfficientNetï¼ç¨æ¼åé¡ç¨åºãEfficientNet éå°äº 98% çæºç¢ºåº¦ï¼æ¯è¨éå°çæé«å¼ã

##### **Evaluating GPT's Capability in Identifying Stages of Cognitive Impairment from Electronic Health Data**
2502.09715v1 by Yu Leng, Yingnan He, Colin Magdamo, Ana-Maria Vranceanu, Christine S. Ritchie, Shibani S. Mukerji, Lidia M. V. R. Moura, John R. Dickson, Deborah Blacker, Sudeshna Das

Identifying cognitive impairment within electronic health records (EHRs) is
crucial not only for timely diagnoses but also for facilitating research.
Information about cognitive impairment often exists within unstructured
clinician notes in EHRs, but manual chart reviews are both time-consuming and
error-prone. To address this issue, our study evaluates an automated approach
using zero-shot GPT-4o to determine stage of cognitive impairment in two
different tasks. First, we evaluated the ability of GPT-4o to determine the
global Clinical Dementia Rating (CDR) on specialist notes from 769 patients who
visited the memory clinic at Massachusetts General Hospital (MGH), and achieved
a weighted kappa score of 0.83. Second, we assessed GPT-4o's ability to
differentiate between normal cognition, mild cognitive impairment (MCI), and
dementia on all notes in a 3-year window from 860 Medicare patients. GPT-4o
attained a weighted kappa score of 0.91 in comparison to specialist chart
reviews and 0.96 on cases that the clinical adjudicators rated with high
confidence. Our findings demonstrate GPT-4o's potential as a scalable chart
review tool for creating research datasets and assisting diagnosis in clinical
settings in the future.

æè¦ï¼å¨é»å­å¥åº·è¨é (EHR) ä¸­è­å¥èªç¥éç¤ä¸åå°åæè¨ºæ·è³ééè¦ï¼ä¹æå©æ¼ä¿é²ç ç©¶ãæéèªç¥éç¤çè³è¨éå¸¸å­å¨æ¼ EHR ä¸­éçµæ§åçè¨åºè¨éä¸­ï¼ä½æååè¡¨å¯©æ¥æ¢èæåå®¹æåºé¯ãçºäºè§£æ±ºéååé¡ï¼æåçç ç©¶è©ä¼°äºä¸ç¨®èªååæ¹æ³ï¼ä½¿ç¨é¶æ¬¡å­¸ç¿ç GPT-4o ä¾ç¢ºå®å©ç¨®ä¸åä»»åä¸­çèªç¥éç¤åæãé¦åï¼æåè©ä¼°äº GPT-4o ç¢ºå®ä¾èªéº»è©è«¸å¡å·ç¸½é«é¢ (MGH) è¨æ¶è¨ºæ 769 åæ£èçå°ç§è¨éçå¨çè¨åºç´åè©å (CDR) çè½åï¼ä¸¦ç²å¾äº 0.83 çå æ¬ kappa åæ¸ãå¶æ¬¡ï¼æåè©ä¼°äº GPT-4o å¨ 860 å Medicare æ£è 3 å¹´è¦çªä¸­çææè¨éä¸­ååæ­£å¸¸èªç¥ãè¼åº¦èªç¥éç¤ (MCI) åç´åçè½åãèå°ç§åè¡¨å¯©æ¥ç¸æ¯ï¼GPT-4o ç²å¾äº 0.91 çå æ¬ kappa åæ¸ï¼èå°æ¼è¨åºè©å¯©å¡ä»¥é«åº¦ä¿¡å¿è©ä¼°ççä¾ï¼å¶å æ¬ kappa åæ¸çº 0.96ãæåçç ç©¶çµæè­æäº GPT-4o ä½çºå¯æ´ååè¡¨å¯©æ¥å·¥å·çæ½åï¼å¯ç¨æ¼å»ºç«ç ç©¶è³æéä¸¦åå©æªä¾è¨åºç°å¢ä¸­çè¨ºæ·ã

##### **Metamorphic Testing for Pose Estimation Systems**
2502.09460v1 by Matias Duran, Thomas Laurent, Ellen Rushe, Anthony Ventresque

Pose estimation systems are used in a variety of fields, from sports
analytics to livestock care. Given their potential impact, it is paramount to
systematically test their behaviour and potential for failure. This is a
complex task due to the oracle problem and the high cost of manual labelling
necessary to build ground truth keypoints. This problem is exacerbated by the
fact that different applications require systems to focus on different subjects
(e.g., human versus animal) or landmarks (e.g., only extremities versus whole
body and face), which makes labelled test data rarely reusable. To combat these
problems we propose MET-POSE, a metamorphic testing framework for pose
estimation systems that bypasses the need for manual annotation while assessing
the performance of these systems under different circumstances. MET-POSE thus
allows users of pose estimation systems to assess the systems in conditions
that more closely relate to their application without having to label an ad-hoc
test dataset or rely only on available datasets, which may not be adapted to
their application domain. While we define MET-POSE in general terms, we also
present a non-exhaustive list of metamorphic rules that represent common
challenges in computer vision applications, as well as a specific way to
evaluate these rules. We then experimentally show the effectiveness of MET-POSE
by applying it to Mediapipe Holistic, a state of the art human pose estimation
system, with the FLIC and PHOENIX datasets. With these experiments, we outline
numerous ways in which the outputs of MET-POSE can uncover faults in pose
estimation systems at a similar or higher rate than classic testing using hand
labelled data, and show that users can tailor the rule set they use to the
faults and level of accuracy relevant to their application.

æè¦ï¼å§¿å¢ä¼°è¨ç³»çµ±æç¨æ¼åç¨®é åï¼å¾éååæå°ç²çç§è­·ãéæ¼å¶æ½å¨å½±é¿ï¼ç³»çµ±æ§å°æ¸¬è©¦å¶è¡çºåæéæ½åè³ééè¦ãç±æ¼é è¨æ©åé¡ä»¥åå»ºç«å°é¢å¯¦æ³ééµé»æéçæåæ¨è¨ææ¬é«ï¼éæ¯ä¸é è¤éçä»»åãéååé¡å ä¸åçæç¨éè¦ç³»çµ±å°æ³¨æ¼ä¸åçä¸»é«ï¼ä¾å¦ï¼äººé¡å°åç©ï¼æå°æ¨ï¼ä¾å¦ï¼åªæåè¢å°å¨èº«åèé¨ï¼èå åï¼éä½¿å¾æ¨è¨çæ¸¬è©¦æ¸æå¾å°å¯ä»¥éè¤ä½¿ç¨ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº MET-POSEï¼éæ¯ä¸åå§¿å¢ä¼°è¨ç³»çµ±çè®å½¢æ¸¬è©¦æ¡æ¶ï¼å¨è©ä¼°éäºç³»çµ±å¨ä¸åææ³ä¸çæ§è½æï¼å¯ä»¥ç¹éæåè¨»è§£çéè¦ãå æ­¤ï¼MET-POSE åè¨±å§¿å¢ä¼°è¨ç³»çµ±çä½¿ç¨èå¨æ´æ¥è¿å¶æç¨ç¨å¼çæ¢ä»¶ä¸è©ä¼°ç³»çµ±ï¼èç¡éæ¨è¨è¨ææ¸¬è©¦æ¸æéæåä¾è³´å¯ç¨æ¸æéï¼éäºæ¸æéå¯è½ä¸é©åå¶æç¨é åãéç¶æåä»¥ä¸è¬è¡èªå®ç¾© MET-POSEï¼ä½æåä¹æä¾äºä¸åéè©³ç¡çè®å½¢è¦ååè¡¨ï¼éäºè¦åä»£è¡¨äºé»è¦è¦è¦ºæç¨ä¸­çå¸¸è¦ææ°ï¼ä»¥åè©ä¼°éäºè¦åçå·é«æ¹æ³ãç¶å¾ï¼æåééå° MET-POSE æç¨æ¼ Mediapipe Holisticï¼ä¸ç¨®åé²çäººé¡å§¿å¢ä¼°è¨ç³»çµ±ï¼ï¼ä¸¦ä½¿ç¨ FLIC å PHOENIX æ¸æéï¼ä»¥å¯¦é©æ¹å¼å±ç¤º MET-POSE çæææ§ãéééäºå¯¦é©ï¼æåæ¦è¿°äº MET-POSE çè¼¸åºå¯ä»¥æ­ç¤ºå§¿å¢ä¼°è¨ç³»çµ±ä¸­æéçè¨±å¤æ¹æ³ï¼å¶éåº¦èä½¿ç¨æåæ¨è¨æ¸æçå³çµ±æ¸¬è©¦é¡ä¼¼ææ´é«ï¼ä¸¦è¡¨æä½¿ç¨èå¯ä»¥æ ¹æå¶æç¨ç¨å¼ç¸éçæéåæºç¢ºåº¦ç­ç´ä¾èª¿æ´ä»åä½¿ç¨çè¦åéã

##### **Towards Virtual Clinical Trials of Radiology AI with Conditional Generative Modeling**
2502.09688v1 by Benjamin D. Killeen, Bohua Wan, Aditya V. Kulkarni, Nathan Drenkow, Michael Oberst, Paul H. Yi, Mathias Unberath

Artificial intelligence (AI) is poised to transform healthcare by enabling
personalized and efficient care through data-driven insights. Although
radiology is at the forefront of AI adoption, in practice, the potential of AI
models is often overshadowed by severe failures to generalize: AI models can
have performance degradation of up to 20% when transitioning from controlled
test environments to clinical use by radiologists. This mismatch raises
concerns that radiologists will be misled by incorrect AI predictions in
practice and/or grow to distrust AI, rendering these promising technologies
practically ineffectual. Exhaustive clinical trials of AI models on abundant
and diverse data is thus critical to anticipate AI model degradation when
encountering varied data samples. Achieving these goals, however, is
challenging due to the high costs of collecting diverse data samples and
corresponding annotations. To overcome these limitations, we introduce a novel
conditional generative AI model designed for virtual clinical trials (VCTs) of
radiology AI, capable of realistically synthesizing full-body CT images of
patients with specified attributes. By learning the joint distribution of
images and anatomical structures, our model enables precise replication of
real-world patient populations with unprecedented detail at this scale. We
demonstrate meaningful evaluation of radiology AI models through VCTs powered
by our synthetic CT study populations, revealing model degradation and
facilitating algorithmic auditing for bias-inducing data attributes. Our
generative AI approach to VCTs is a promising avenue towards a scalable
solution to assess model robustness, mitigate biases, and safeguard patient
care by enabling simpler testing and evaluation of AI models in any desired
range of diverse patient populations.

æè¦ï¼<paragraph>äººå·¥æºæ§ (AI) æºåééè³æé©åçè¦è§£ï¼è½åé«çä¿å¥ï¼ä¸¦æä¾åäººåä¸ææççç§è­·ãåç®¡æ¾å°ç§èæ¼ AI æ¡ç¨çæåç·ï¼ä½å¨å¯¦åä¸ï¼AI æ¨¡åçæ½åå¾å¾æè¢«å´éçæ¦åå¤±æææ©èï¼AI æ¨¡åå¨å¾åæ§æ¸¬è©¦ç°å¢è½ç§»å°æ¾å°ç§é«å¸«çè¨åºä½¿ç¨æï¼æè½å¯è½æéä½å¤é 20%ãéç¨®ä¸å¹éå¼ç¼äºçæ®ï¼å³æ¾å°ç§é«å¸«å¨å¯¦åä¸æè¢«ä¸æ­£ç¢ºç AI é æ¸¬èª¤å°ï¼å/æéå§ä¸ä¿¡ä»» AIï¼è®éäºæåæ¯çæè¡å¨å¯¦åä¸å½¢åå¤±æãå æ­¤ï¼å¨ AI æ¨¡åé­éåç¨®è³æç¯ä¾æï¼é æ AI æ¨¡åçè¡°éï¼å°è±å¯ä¸å¤æ¨£åçè³æé²è¡ AI æ¨¡åçå¨é¢è¨åºè©¦é©è³ééè¦ãç¶èï¼ç±æ¼æ¶éå¤æ¨£åçè³æç¯ä¾åå°æè¨»è§£çææ¬å¾é«ï¼å¯¦ç¾éäºç®æ¨å·æææ°æ§ãçºäºåæéäºéå¶ï¼æåå¼é²ä¸ååµæ°çæ¢ä»¶å¼çæå¼ AI æ¨¡åï¼å°éç¨æ¼æ¾å°ç§ AI çèæ¬è¨åºè©¦é© (VCT)ï¼è½å¤ çå¯¦å°åæå·æç¹å®å±¬æ§ççæ£å¨èº«é»è¦æ·å±¤ (CT) å½±åãééå­¸ç¿å½±ååè§£åçµæ§çè¯ååä½ï¼æåçæ¨¡åè½å¤ ä»¥ç©ºåçç´°ç¯ç²¾ç¢ºè¤è£½çå¯¦ä¸çççæ£æç¾¤ãæåééç±æååæçé»è¦æ·å±¤ç ç©¶æç¾¤æ¯æ´ç VCTï¼å±ç¤ºäºæ¾å°ç§ AI æ¨¡åææç¾©çè©ä¼°ï¼æ­é²æ¨¡åè¡°éï¼ä¸¦ä¿é²æ¼ç®æ³ç¨½æ ¸ï¼ä»¥æ¾åºå°è´åå·®çè³æå±¬æ§ãæåå° VCT ççæå¼ AI æ¹æ³ï¼æ¯ä¸åæåæ¯çéå¾ï¼å¯ä»¥è©ä¼°æ¨¡åçç©©å¥æ§ãæ¸è¼åå·®ï¼ä¸¦ééå¨ä»»ä½æéçåç¨®çæ£æç¾¤ä¸­ï¼é²è¡æ´ç°¡å®ç AI æ¨¡åæ¸¬è©¦åè©ä¼°ï¼ä¾ä¿éçæ£ç§è­·ã</paragraph>

##### **Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models**
2502.09687v1 by Wiktoria Mieleszczenko-Kowszewicz, Beata Bajcar, Jolanta Babiak, Berenika Dyczek, Jakub Åwistak, PrzemysÅaw Biecek

Be careful what you ask for, you just might get it. This saying fits with the
way large language models (LLMs) are trained, which, instead of being rewarded
for correctness, are increasingly rewarded for pleasing the recipient. So, they
are increasingly effective at persuading us that their answers are valuable.
But what tricks do they use in this persuasion? In this study, we examine what
are the psycholinguistic features of the responses used by twelve different
language models. By grouping response content according to rational or
emotional prompts and exploring social influence principles employed by LLMs,
we ask whether and how we can mitigate the risks of LLM-driven mass
misinformation. We position this study within the broader discourse on
human-centred AI, emphasizing the need for interdisciplinary approaches to
mitigate cognitive and societal risks posed by persuasive AI responses.

æè¦ï¼å°å¿ä½ è¦æ±çï¼ä½ å¯è½ççæå¾å°ãéå¥è©±é©ç¨æ¼å¤§åèªè¨æ¨¡å (LLM) çè¨ç·´æ¹å¼ï¼å®åä¸æ¯å çºæ­£ç¢ºæ§èç²å¾çåµï¼èæ¯å çºåææ¥æ¶èèç²å¾è¶ä¾è¶å¤ççåµãå æ­¤ï¼å®åè¶ä¾è¶ææå°èªªææåï¼å®åçç­æ¡æ¯æå¹å¼çãä½æ¯å®åå¨éç¨®èªªæä¸­ä½¿ç¨ä»éº¼æå·§å¢ï¼å¨éé ç ç©¶ä¸­ï¼æåæ¢è¨äºåäºç¨®ä¸åçèªè¨æ¨¡åä½¿ç¨çåæçå¿çèªè¨ç¹å¾µãééæ ¹æçæ§åæç·æç¤ºå°åæå§å®¹é²è¡åçµï¼ä¸¦æ¢è¨ LLM ä½¿ç¨çç¤¾æå½±é¿ååï¼æåæ¢è¨æ¯å¦ä»¥åå¦ä½æ¸è¼ LLM é©åçå¤§è¦æ¨¡é¯èª¤ä¿¡æ¯çé¢¨éªãæåå°éé ç ç©¶å®ä½å¨ä»¥äººçºä¸­å¿ç AI çæ´å»£æ³è¨è«ä¸­ï¼å¼·èª¿éè¦è·¨å­¸ç§æ¹æ³ä¾æ¸è¼å·æèªªæåç AI åæå¸¶ä¾çèªç¥åç¤¾æé¢¨éªã

##### **The Joint Entity-Relation Extraction Model Based on Span and Interactive Fusion Representation for Chinese Medical Texts with Complex Semantics**
2502.09247v1 by Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, Yunli Xing

Joint entity-relation extraction is a critical task in transforming
unstructured or semi-structured text into triplets, facilitating the
construction of large-scale knowledge graphs, and supporting various downstream
applications. Despite its importance, research on Chinese text, particularly
with complex semantics in specialized domains like medicine, remains limited.
To address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions
dataset designed to capture the intricacies of medical text. Leveraging the
strengths of attention mechanisms in capturing long-range dependencies, we
propose the SEA module, which enhances the extraction of complex contextual
semantic information, thereby improving entity recognition and relation
extraction. Additionally, to address the inefficiencies of existing methods in
facilitating information exchange between entity recognition and relation
extraction, we present an interactive fusion representation module. This module
employs Cross Attention for bidirectional information exchange between the
tasks and further refines feature extraction through BiLSTM. Experimental
results on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that
our model exhibits strong generalization capabilities. On the CH-DDI dataset,
our model achieves an F1-score of 96.73% for entity recognition and 78.43% for
relation extraction. On the CoNLL04 dataset, it attains an entity recognition
precision of 89.54% and a relation extraction accuracy of 71.64%.

æè¦ï¼è¯åå¯¦é«éä¿æ½åæ¯å°éçµæ§åæåçµæ§åæå­è½æçºä¸åçµçéè¦ä»»åï¼æå©æ¼å»ºæ§å¤§è¦æ¨¡ç¥è­åè­ï¼ä¸¦æ¯æ´åç¨®ä¸æ¸¸æç¨ç¨å¼ãåç®¡å¶éè¦æ§ï¼ä½éå°ä¸­æææ¬çç ç©¶ï¼ç¹å¥æ¯é«å­¸ç­å°æ¥­é åä¸­å·æè¤éèªç¾©çç ç©¶ä»ååæéãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº CH-DDIï¼ä¸åä¸­æè¥ç©-è¥ç©äº¤äºä½ç¨è³æéï¼æ¨å¨æ·åé«å­¸ææ¬çè¤éæ§ãå©ç¨æ³¨æåæ©å¶å¨æ·åé·ç¨ä¾è³´éä¿æ¹é¢çåªå¢ï¼æåæåºäº SEA æ¨¡çµï¼å¢å¼·äºè¤éèçµ¡èªç¾©è³è¨çæ½åï¼å¾èæ¹é²äºå¯¦é«è¾¨è­åéä¿æ½åãæ­¤å¤ï¼çºäºè§£æ±ºç¾ææ¹æ³å¨ä¿é²å¯¦é«è¾¨è­åéä¿æ½åä¹éè³è¨äº¤ææ¹é¢çä½æçåé¡ï¼æåæåºäºäºåå¼èåè¡¨ç¤ºæ¨¡çµãæ­¤æ¨¡çµæ¡ç¨äº¤åæ³¨æåï¼å¨ä»»åä¹éé²è¡éåè³è¨äº¤æï¼ä¸¦éé BiLSTM é²ä¸æ­¥ç²¾çç¹å¾µæ½åãå¨æåç CH-DDI è³æéåå¬éç CoNLL04 è³æéä¸çå¯¦é©çµæè¡¨æï¼æåçæ¨¡åå±ç¾åºå¼·å¤§çæ³åè½åãå¨ CH-DDI è³æéä¸ï¼æåçæ¨¡åå¨å¯¦é«è¾¨è­æ¹é¢éå°äº 96.73% ç F1 åæ¸ï¼å¨éä¿æ½åæ¹é¢éå°äº 78.43% ç F1 åæ¸ãå¨ CoNLL04 è³æéä¸ï¼å®å¨å¯¦é«è¾¨è­æ¹é¢éå°äº 89.54% çæºç¢ºåº¦ï¼å¨éä¿æ½åæ¹é¢éå°äº 71.64% çæºç¢ºåº¦ã

##### **From large language models to multimodal AI: A scoping review on the potential of generative AI in medicine**
2502.09242v1 by Lukas Buess, Matthias Keicher, Nassir Navab, Andreas Maier, Soroosh Tayebi Arasteh

Generative artificial intelligence (AI) models, such as diffusion models and
OpenAI's ChatGPT, are transforming medicine by enhancing diagnostic accuracy
and automating clinical workflows. The field has advanced rapidly, evolving
from text-only large language models for tasks such as clinical documentation
and decision support to multimodal AI systems capable of integrating diverse
data modalities, including imaging, text, and structured data, within a single
model. The diverse landscape of these technologies, along with rising interest,
highlights the need for a comprehensive review of their applications and
potential. This scoping review explores the evolution of multimodal AI,
highlighting its methods, applications, datasets, and evaluation in clinical
settings. Adhering to PRISMA-ScR guidelines, we systematically queried PubMed,
IEEE Xplore, and Web of Science, prioritizing recent studies published up to
the end of 2024. After rigorous screening, 144 papers were included, revealing
key trends and challenges in this dynamic field. Our findings underscore a
shift from unimodal to multimodal approaches, driving innovations in diagnostic
support, medical report generation, drug discovery, and conversational AI.
However, critical challenges remain, including the integration of heterogeneous
data types, improving model interpretability, addressing ethical concerns, and
validating AI systems in real-world clinical settings. This review summarizes
the current state of the art, identifies critical gaps, and provides insights
to guide the development of scalable, trustworthy, and clinically impactful
multimodal AI solutions in healthcare.

æè¦ï¼çæå¼äººå·¥æºè½ (AI) æ¨¡åï¼ä¾å¦æ©æ£æ¨¡åå OpenAI ç ChatGPTï¼éè¿æé«è¯æ­åç¡®æ§åèªå¨åä¸´åºå·¥ä½æµç¨ï¼æ­£å¨æ¹åå»å­¦é¢åãè¯¥é¢åå·²è¿éåå±ï¼ä»ç¨äºä¸´åºæä»¶ç¼å¶åå³ç­æ¯æç­ä»»å¡ççº¯ææ¬å¤§åè¯­è¨æ¨¡åï¼åå±å°è½å¤å¨åä¸ªæ¨¡åä¸­æ´ååæ¬å½±åãææ¬åç»æåæ°æ®å¨åçå¤ç§æ°æ®æ¹å¼çå¤æ¨¡æ AI ç³»ç»ãè¿äºææ¯çå¤æ ·åæ ¼å±ä»¥åæ¥çå¢é¿çå´è¶£ï¼å¸æ¾äºå¨é¢å®¡æ¥å¶åºç¨åæ½åçå¿è¦æ§ãæ¬èå´å®¡æ¥æ¢è®¨äºå¤æ¨¡æ AI çæ¼åï¼éç¹ä»ç»äºå¶æ¹æ³ãåºç¨ãæ°æ®éåå¨ä¸´åºç¯å¢ä¸­çè¯ä¼°ãéµå¾ª PRISMA-ScR æåï¼æä»¬ç³»ç»å°æ¥è¯¢äº PubMedãIEEE Xplore å Web of Scienceï¼ä¼åèèæªè³ 2024 å¹´åºåè¡¨çææ°ç ç©¶ãç»è¿ä¸¥æ ¼ç­éï¼çº³å¥äº 144 ç¯è®ºæï¼æ­ç¤ºäºè¿ä¸åæ»¡æ´»åçé¢åçè¶å¿åææãæä»¬çç ç©¶ç»æå¼ºè°äºä»åæ¨¡ææ¹æ³åå¤æ¨¡ææ¹æ³çè½¬åï¼æ¨å¨äºè¯æ­æ¯æãå»çæ¥åçæãè¯ç©åç°åä¼è¯å¼ AI çåæ°ãç¶èï¼å³é®ææä»ç¶å­å¨ï¼åæ¬å¼ææ°æ®ç±»åçæ´åãæé«æ¨¡åå¯è§£éæ§ãè§£å³ä¼¦çé®é¢ä»¥åå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­éªè¯ AI ç³»ç»ãæ¬ç»¼è¿°æ»ç»äºå½åçææ°ææ¯ï¼ç¡®å®äºå³é®å·®è·ï¼å¹¶æä¾äºè§è§£ï¼ä»¥æå¯¼å¨å»çä¿å¥é¢åå¼åå¯æ©å±ãå¯ä¿¡èµä¸å·æä¸´åºå½±ååçå¤æ¨¡æ AI è§£å³æ¹æ¡ã

##### **Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**
2502.09218v1 by Flavio Bertini, Alessandro Dal PalÃ¹, Federica Zaglio, Francesco Fabiano, Andrea Formisano

This paper presents a complete explainable system that interprets a set of
data, abstracts the underlying features and describes them in a natural
language of choice. The system relies on two crucial stages: (i) identifying
emerging properties from data and transforming them into abstract concepts, and
(ii) converting these concepts into natural language. Despite the impressive
natural language generation capabilities demonstrated by Large Language Models,
their statistical nature and the intricacy of their internal mechanism still
force us to employ these techniques as black boxes, forgoing trustworthiness.
Developing an explainable pipeline for data interpretation would allow
facilitating its use in safety-critical environments like processing medical
information and allowing non-experts and visually impaired people to access
narrated information. To this end, we believe that the fields of knowledge
representation and automated reasoning research could present a valid
alternative. Expanding on prior research that tackled the first stage (i), we
focus on the second stage, named Concept2Text. Being explainable, data
translation is easily modeled through logic-based rules, once again emphasizing
the role of declarative programming in achieving AI explainability. This paper
explores a Prolog/CLP-based rewriting system to interpret concepts-articulated
in terms of classes and relations, plus common knowledge-derived from a generic
ontology, generating natural language text. Its main features include
hierarchical tree rewritings, modular multilingual generation, support for
equivalent variants across semantic, grammar, and lexical levels, and a
transparent rule-based system. We outline the architecture and demonstrate its
flexibility through some examples capable of generating numerous diverse and
equivalent rewritings based on the input concept.

æè¦ï¼<paragraph>éç¯è«ææåºäºä¸åå®æ´çå¯è§£éç³»çµ±ï¼å®å¯ä»¥è§£éä¸çµè³æï¼æ½è±¡åºåºç¤ç¹å¾µï¼ä¸¦ä»¥é¸æçèªç¶èªè¨æè¿°å®åãç³»çµ±ä¾è³´å©åééµéæ®µï¼(i) å¾è³æä¸­è­å¥æ°èå±¬æ§ï¼ä¸¦å°å®åè½æçºæ½è±¡æ¦å¿µï¼ä»¥å (ii) å°éäºæ¦å¿µè½æçºèªç¶èªè¨ãåç®¡å¤§åèªè¨æ¨¡åå±ç¤ºäºä»¤äººå°è±¡æ·±å»çèªç¶èªè¨çæè½åï¼ä½å®åççµ±è¨æ§è³ªåå§é¨æ©å¶çè¤éæ§ä»ç¶è¿«ä½¿æåå°éäºæè¡ç¨ä½é»çå­ï¼æ¾æ£å¯ä¿¡åº¦ãéç¼ä¸åå¯è§£éçè³æè§£éç®¡éå°æå©æ¼ä¿é²å¨å®å¨ééµç°å¢ä¸­ä½¿ç¨å®ï¼ä¾å¦èçé«çè³è¨ï¼ä¸¦åè¨±éå°å®¶åè¦éäººå£«å­åæè¿°è³è¨ãçºæ­¤ï¼æåç¸ä¿¡ç¥è­è¡¨ç¤ºåèªåæ¨çç ç©¶é åå¯ä»¥æåºä¸åææçæ¿ä»£æ¹æ¡ãå¨æ´å±è§£æ±ºç¬¬ä¸éæ®µ (i) çååç ç©¶çåºç¤ä¸ï¼æåå°æ³¨æ¼ç¬¬äºéæ®µï¼ç¨±çº Concept2Textãç±æ¼å·æå¯è§£éæ§ï¼è³æç¿»è­¯å¾å®¹æééåºæ¼éè¼¯çè¦åå»ºæ¨¡ï¼åæ¬¡å¼·èª¿å®£åå¼ç¨å¼è¨­è¨å¨å¯¦ç¾ AI å¯è§£éæ§ä¸­çä½ç¨ãæ¬ææ¢è¨äºä¸ååºæ¼ Prolog/CLP çéå¯«ç³»çµ±ï¼ä»¥è§£éæ¦å¿µï¼éäºæ¦å¿µä»¥é¡å¥åéä¿çå½¢å¼è¡¨éï¼åå ä¸å¾éç¨æ¬ä½è¡ççå¸¸è­ï¼ç¢çèªç¶èªè¨æå­ãå®çä¸»è¦ç¹é»åæ¬éå±¤æ¨¹éå¯«ãæ¨¡çµåå¤èªè¨çæãæ¯æ´èªç¾©ãèªæ³åè©å½å±¤é¢çç­æè®é«ï¼ä»¥åä¸åéæçåºæ¼è¦åçç³»çµ±ãæåæ¦è¿°äºæ¶æ§ï¼ä¸¦ééä¸äºç¯ä¾å±ç¤ºäºå®çéæ´»æ§ï¼éäºç¯ä¾è½å¤ æ ¹æè¼¸å¥æ¦å¿µçæè¨±å¤ä¸åçç­æéå¯«ã</paragraph>

##### **Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York**
2502.09204v1 by Sanskar Sehgal, Yanhong A. Liu

Legal cases require careful logical reasoning following the laws, whereas
interactions with non- technical users must be in natural language. As an
application combining logical reasoning using Prolog and natural language
processing using large language models (LLMs), this paper presents a novel
approach and system, LogicLease, to automate the analysis of landlord-tenant
legal cases in the state of New York. LogicLease determines compliance with
relevant legal requirements by analyzing case descriptions and citing all
relevant laws. It leverages LLMs for information extraction and Prolog for
legal reasoning. By separating information extraction from legal reasoning,
LogicLease achieves greater transparency and control over the legal logic
applied to each case. We evaluate the accuracy, efficiency, and robustness of
LogicLease through a series of tests, achieving 100% accuracy and an average
processing time of 2.57 seconds. LogicLease presents advantages over
state-of-the-art LLM- based legal analysis systems by providing clear,
step-by-step reasoning, citing specific laws, and distinguishing itself by its
ability to avoid hallucinations - a common issue in LLMs.

æè¦ï¼æ³å¾æ¡ä»¶éè¦éµå¾ªæ³å¾è¿è¡è°¨æçé»è¾æ¨çï¼èä¸éææ¯ç¨æ·çäºå¨å¿é¡»ä½¿ç¨èªç¶è¯­è¨ãä½ä¸ºç»åä½¿ç¨ Prolog è¿è¡é»è¾æ¨çåä½¿ç¨å¤§åè¯­è¨æ¨¡å (LLM) è¿è¡èªç¶è¯­è¨å¤ççåºç¨ç¨åºï¼æ¬ææåºäºä¸ç§æ°é¢çæ¹æ³åç³»ç» LogicLeaseï¼ä»¥èªå¨åæçº½çº¦å·çæ¿ä¸ä¸ç§æ·æ³å¾æ¡ä»¶ãLogicLease éè¿åææ¡ä¾æè¿°å¹¶å¼ç¨ææç¸å³æ³å¾æ¥ç¡®å®æ¯å¦ç¬¦åç¸å³æ³å¾è¦æ±ãå®å©ç¨ LLM è¿è¡ä¿¡æ¯æåï¼å¹¶å©ç¨ Prolog è¿è¡æ³å¾æ¨çãéè¿å°ä¿¡æ¯æåä¸æ³å¾æ¨çåå¼ï¼LogicLease å®ç°äºå¯¹åºç¨äºæ¯ä¸ªæ¡ä¾çæ³å¾é»è¾çæ´é«éæåº¦åæ§å¶åãæä»¬éè¿ä¸ç³»åæµè¯è¯ä¼°äº LogicLease çåç¡®æ§ãæçåé²æ£æ§ï¼å®ç°äº 100% çåç¡®æ§å 2.57 ç§çå¹³åå¤çæ¶é´ãLogicLease éè¿æä¾æ¸æ°ãåæ­¥çæ¨çï¼å¼ç¨å·ä½æ³å¾ï¼å¹¶ä»¥å¶é¿åå¹»è§çè½åèåºå«äºæåè¿çåºäº LLM çæ³å¾åæç³»ç»ï¼ä»èæ¾ç¤ºåºä¼å¿ââè¿æ¯ LLM ä¸­çå¸¸è§é®é¢ã

##### **Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics in People Living with Dementia**
2502.09173v1 by Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott

In remote healthcare monitoring, time series representation learning reveals
critical patient behavior patterns from high-frequency data. This study
analyzes home activity data from individuals living with dementia by proposing
a two-stage, self-supervised learning approach tailored to uncover low-rank
structures. The first stage converts time-series activities into text sequences
encoded by a pre-trained language model, providing a rich, high-dimensional
latent state space using a PageRank-based method. This PageRank vector captures
latent state transitions, effectively compressing complex behaviour data into a
succinct form that enhances interpretability. This low-rank representation not
only enhances model interpretability but also facilitates clustering and
transition analysis, revealing key behavioral patterns correlated with
clinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the
framework's potential in supporting cognitive status prediction, personalized
care interventions, and large-scale health monitoring.

æè¦ï¼å¨é ç¨é«çç£æ§ä¸­ï¼æéåºåè¡¨ç¤ºå­¸ç¿æ­ç¤ºäºé«é »çæ¸æä¸­çééµæ£èè¡çºæ¨¡å¼ãæ¬ç ç©¶ééæåºä¸åå©éæ®µãèªæç£ç£çå­¸ç¿æ¹æ³ä¾åæç´åçæ£èçå®¶åº­æ´»åæ¸æï¼è©²æ¹æ³å°éç¨æ¼ç¼ç¾ä½ç§©çµæ§ãç¬¬ä¸éæ®µå°æéåºåæ´»åè½æçºç±é è¨ç·´èªè¨æ¨¡åç·¨ç¢¼çææ¬åºåï¼ä½¿ç¨åºæ¼ PageRank çæ¹æ³æä¾äºä¸åè±å¯ãé«ç¶­çæ½å¨çæç©ºéãæ­¤ PageRank åéæç²æ½å¨çæè½æï¼ææå°å°è¤éçè¡çºæ¸æå£ç¸®æç°¡æ½çå½¢å¼ï¼å¾èå¢å¼·äºè§£åãæ­¤ä½ç§©è¡¨ç¤ºä¸åå¢å¼·äºæ¨¡åçå¯è§£éæ§ï¼éä¿é²äºèé¡åè½æåæï¼æ­ç¤ºäºèè¨åºææ¨ï¼ä¾å¦ MMSE å ADAS-COG åæ¸ï¼ç¸éçééµè¡çºæ¨¡å¼ãæåçç ç©¶çµæè­æäºè©²æ¡æ¶å¨æ¯æèªç¥çæé æ¸¬ãåæ§åè­·çå¹²é åå¤§åå¥åº·ç£æ§æ¹é¢çæ½åã

##### **TastepepAI, An artificial intelligence platform for taste peptide de novo design**
2502.12167v1 by Jianda Yue, Tingting Li, Jian Ouyang, Jiawei Xu, Hua Tan, Zihui Chen, Changsheng Han, Huanyu Li, Songping Liang, Zhonghua Liu, Zhonghua Liu, Ying Wang

Taste peptides have emerged as promising natural flavoring agents attributed
to their unique organoleptic properties, high safety profile, and potential
health benefits. However, the de novo identification of taste peptides derived
from animal, plant, or microbial sources remains a time-consuming and
resource-intensive process, significantly impeding their widespread application
in the food industry. Here, we present TastePepAI, a comprehensive artificial
intelligence framework for customized taste peptide design and safety
assessment. As the key element of this framework, a loss-supervised adaptive
variational autoencoder (LA-VAE) is implemented to efficiently optimizes the
latent representation of sequences during training and facilitates the
generation of target peptides with desired taste profiles. Notably, our model
incorporates a novel taste-avoidance mechanism, allowing for selective flavor
exclusion. Subsequently, our in-house developed toxicity prediction algorithm
(SpepToxPred) is integrated in the framework to undergo rigorous safety
evaluation of generated peptides. Using this integrated platform, we
successfully identified 73 peptides exhibiting sweet, salty, and umami,
significantly expanding the current repertoire of taste peptides. This work
demonstrates the potential of TastePepAI in accelerating taste peptide
discovery for food applications and provides a versatile framework adaptable to
broader peptide engineering challenges.

æè¦ï¼å³è§è½å å¶ç¬ç¹çæå®ç¹æ§ãé«å®å¨æ§æ¦åµåæ½å¨çå¥åº·çå¤èæä¸ºæåéçå¤©ç¶è°å³åãç¶èï¼ä»å¨ç©ãæ¤ç©æå¾®çç©æ¥æºä¸­ä»å¤´é´å®å³è§è½ä»ç¶æ¯ä¸ä¸ªèæ¶ä¸èµæºå¯éçè¿ç¨ï¼ä¸¥éé»ç¢äºå®ä»¬å¨é£åå·¥ä¸ä¸­çå¹¿æ³åºç¨ãå¨æ­¤ï¼æä»¬æåºäº TastePepAIï¼è¿æ¯ä¸ä¸ªç¨äºå®å¶å³è§è½è®¾è®¡åå®å¨æ§è¯ä¼°çç»¼åäººå·¥æºè½æ¡æ¶ãä½ä¸ºè¯¥æ¡æ¶çå³é®åç´ ï¼å®ç°äºæå¤±çç£èªéåºååèªå¨ç¼ç å¨ (LA-VAE)ï¼ä»¥å¨è®­ç»æé´ææä¼ååºåçæ½å¨è¡¨ç¤ºï¼å¹¶ä¿è¿çæå·ææéå³è§ç¹å¾çç®æ è½ãå¼å¾æ³¨æçæ¯ï¼æä»¬çæ¨¡ååå«äºä¸ç§æ°é¢çå³è§åé¿æºå¶ï¼åè®¸éæ©æ§æé¤é£å³ãéåï¼æä»¬åé¨å¼åçæ¯æ§é¢æµç®æ³ (SpepToxPred) è¢«éæå°æ¡æ¶ä¸­ï¼ä»¥å¯¹çæçè½è¿è¡ä¸¥æ ¼çå®å¨è¯ä¼°ãä½¿ç¨è¿ä¸ªéæå¹³å°ï¼æä»¬æåå°é´å®äº 73 ç§è¡¨ç°åºçå³ãå¸å³åé²å³çè½ï¼æå¤§å°æ©å±äºå½åçå³è§è½åºãè¿é¡¹å·¥ä½å±ç¤ºäº TastePepAI å¨å éå³è§è½åç°ä»¥ç¨äºé£ååºç¨æ¹é¢çæ½åï¼å¹¶æä¾äºä¸ä¸ªéç¨äºæ´å¹¿æ³çè½å·¥ç¨ææçå¤åè½æ¡æ¶ã

##### **HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification**
2502.08754v1 by Valentina Vadori, Jean-Marie GraÃ¯c, Antonella Peruffo, Livio Finos, Ujwala Kiran Chaudhari, Enrico Grisan

Precise segmentation and classification of cell instances are vital for
analyzing the tissue microenvironment in histology images, supporting medical
diagnosis, prognosis, treatment planning, and studies of brain
cytoarchitecture. However, the creation of high-quality annotated datasets for
training remains a major challenge. This study introduces a novel single-stage
approach (HistoSmith) for generating image-label pairs to augment histology
datasets. Unlike state-of-the-art methods that utilize diffusion models with
separate components for label and image generation, our approach employs a
latent diffusion model to learn the joint distribution of cellular layouts,
classification masks, and histology images. This model enables tailored data
generation by conditioning on user-defined parameters such as cell types,
quantities, and tissue types. Trained on the Conic H&E histopathology dataset
and the Nissl-stained CytoDArk0 dataset, the model generates realistic and
diverse labeled samples. Experimental results demonstrate improvements in cell
instance segmentation and classification, particularly for underrepresented
cell types like neutrophils in the Conic dataset. These findings underscore the
potential of our approach to address data scarcity challenges.

æè¦ï¼ç²¾ç¢ºçç´°èå¯¦ä¾åå²ååé¡å°æ¼åæçµç¹å­¸å½±åä¸­ççµç¹å¾®ç°å¢ãæ¯æ´é«çè¨ºæ·ãé å¾ãæ²»çè¦ååè¦é¨ç´°èçµæ§ç ç©¶è³ééè¦ãç¶èï¼å»ºç«ç¨æ¼è¨ç·´çé«åè³ªæ¨è¨»è³æéä»ç¶æ¯ä¸é éå¤§ææ°ãæ¬ç ç©¶æåºäºä¸ç¨®æ°ç©çå®éæ®µæ¹æ³ (HistoSmith)ï¼ç¨æ¼ç¢çå½±åæ¨ç±¤å°ï¼ä»¥æ´åçµç¹å­¸è³æéãèå©ç¨æ´æ£æ¨¡åä¸¦å°æ¨ç±¤åå½±åç¢çåéççµæé¨åçç¾ææè¡ä¸åï¼æåçåæ³æ¡ç¨æ½å¨æ´æ£æ¨¡åä¾å­¸ç¿ç´°èä½å±ãåé¡é®ç½©åçµç¹å­¸å½±åçè¯ååä½ãæ­¤æ¨¡åè½ééèª¿æ´ä½¿ç¨èå®ç¾©çåæ¸ï¼ä¾å¦ç´°èé¡åãæ¸éåçµç¹é¡åï¼ä¾é²è¡å®¢è£½åè³æç¢çãå¨ Conic H&E ç´°èççå­¸è³æéå Nissl æè²ç CytoDArk0 è³æéä¸è¨ç·´å¾ï¼æ­¤æ¨¡åç¢çé¼çä¸å¤æ¨£åçæ¨ç±¤æ¨£æ¬ãå¯¦é©çµæé¡¯ç¤ºç´°èå¯¦ä¾åå²ååé¡æé¡¯èé²æ­¥ï¼ç¹å¥æ¯å°æ¼ Conic è³æéä¸­ä»£è¡¨æ§ä¸è¶³çç´°èé¡åï¼ä¾å¦ä¸­æ§çãéäºç¼ç¾å¼·èª¿äºæåçæ¹æ³å¨è§£æ±ºè³æç¨å°æ§ææ°æ¹é¢çæ½åã

##### **Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion**
2502.08560v1 by Lemuel Puglisi, Daniel C. Alexander, Daniele RavÃ¬

The growing availability of longitudinal Magnetic Resonance Imaging (MRI)
datasets has facilitated Artificial Intelligence (AI)-driven modeling of
disease progression, making it possible to predict future medical scans for
individual patients. However, despite significant advancements in AI, current
methods continue to face challenges including achieving patient-specific
individualization, ensuring spatiotemporal consistency, efficiently utilizing
longitudinal data, and managing the substantial memory demands of 3D scans. To
address these challenges, we propose Brain Latent Progression (BrLP), a novel
spatiotemporal model designed to predict individual-level disease progression
in 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates
in a small latent space, mitigating the computational challenges posed by
high-dimensional imaging data; (ii) it explicitly integrates subject metadata
to enhance the individualization of predictions; (iii) it incorporates prior
knowledge of disease dynamics through an auxiliary model, facilitating the
integration of longitudinal data; and (iv) it introduces the Latent Average
Stabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in
the predicted progression at inference time and (b) allows us to derive a
measure of the uncertainty for the prediction. We train and evaluate BrLP on
11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its
generalizability on an external test set comprising 2,257 MRIs from 962
subjects. Our experiments compare BrLP-generated MRI scans with real follow-up
MRIs, demonstrating state-of-the-art accuracy compared to existing methods. The
code is publicly available at: https://github.com/LemuelPuglisi/BrLP.

æè¦ï¼é¨èç¸±åç£å±æ¯å½±å (MRI) è³æéçæ¥çæ®åï¼å·²ä¿é²äººå·¥æºæ§ (AI) é©åçç¾çé²ç¨å»ºæ¨¡ï¼è®é æ¸¬åå¥æ£èçæªä¾é«å­¸æææçºå¯è½ãç¶èï¼åç®¡ AI æé¡¯èé²å±ï¼ç®åçæè¡ä»é¢è¨ææ°ï¼åæ¬å¯¦ç¾æ£èç¹å®çåå¥åãç¢ºä¿æç©ºä¸è´æ§ãææå©ç¨ç¸±åè³æï¼ä»¥åç®¡ç 3D ææçå¤§éè¨æ¶é«éæ±ãçºäºæå°éäºææ°ï¼æåæåºè¦æ½å¨é²ç¨ (BrLP)ï¼éæ¯ä¸ç¨®æ°ç©çæç©ºæ¨¡åï¼æ¨å¨é æ¸¬ 3D è¦é¨ MRI ä¸­çåäººå±¤ç´ç¾çé²ç¨ãBrLP çä¸»è¦è²¢ç»æååï¼(i) å®å¨ä¸åå°çæ½å¨ç©ºéä¸­éä½ï¼æ¸è¼äºé«ç¶­åº¦å½±åè³æå¸¶ä¾çè¨ç®ææ°ï¼(ii) å®æç¢ºæ´ååè©¦èçåè³æï¼ä»¥å¢å¼·é æ¸¬çåå¥åï¼(iii) å®ééè¼å©æ¨¡åç´å¥ç¾çåæçåé©ç¥è­ï¼ä¿é²ç¸±åè³æçæ´åï¼(iv) å®å¼å¥äºæ½å¨å¹³åç©©å®å (LAS) æ¼ç®æ³ï¼è©²æ¼ç®æ³ (a) å¨æ¨è«æå¼·å¶é æ¸¬é²ç¨ä¸­çæç©ºä¸è´æ§ï¼(b) è®æåè½å¤ æ¨å°é æ¸¬çä¸ç¢ºå®æ§æ¸¬éãæåå°ä¾èª 2,805 ååè©¦èç 11,730 å T1 å æ¬ (T1w) è¦é¨ MRI é²è¡ BrLP è¨ç·´åè©ä¼°ï¼ä¸¦å¨åå«ä¾èª 962 ååè©¦èç 2,257 å MRI çå¤é¨æ¸¬è©¦éä¸é©è­å¶æ¦æ¬æ§ãæåçå¯¦é©å° BrLP çæç MRI ææèå¯¦éè¿½è¹¤ MRI é²è¡æ¯è¼ï¼èç¾ææ¹æ³ç¸æ¯ï¼å±ç¤ºäºæåé²çæºç¢ºæ§ãç¨å¼ç¢¼å·²å¬éæ¼ï¼https://github.com/LemuelPuglisi/BrLPã

##### **Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**
2502.08547v1 by Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai

The adoption of EHRs has expanded opportunities to leverage data-driven
algorithms in clinical care and research. A major bottleneck in effectively
conducting multi-institutional EHR studies is the data heterogeneity across
systems with numerous codes that either do not exist or represent different
clinical concepts across institutions. The need for data privacy further limits
the feasibility of including multi-institutional patient-level data required to
study similarities and differences across patient subgroups. To address these
challenges, we developed the GAME algorithm. Tested and validated across 7
institutions and 2 languages, GAME integrates data in several levels: (1) at
the institutional level with knowledge graphs to establish relationships
between codes and existing knowledge sources, providing the medical context for
standard codes and their relationship to each other; (2) between institutions,
leveraging language models to determine the relationships between
institution-specific codes with established standard codes; and (3) quantifying
the strength of the relationships between codes using a graph attention
network. Jointly trained embeddings are created using transfer and federated
learning to preserve data privacy. In this study, we demonstrate the
applicability of GAME in selecting relevant features as inputs for AI-driven
algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.
We then highlight the application of GAME harmonized multi-institutional EHR
data in a study of Alzheimer's disease outcomes and suicide risk among patients
with mental health disorders, without sharing patient-level data outside
individual institutions.

æè¦ï¼é»å­å¥åº·ç´éçæ¡ç¨æ´å¤§äºå¨è¨åºç§è­·åç ç©¶ä¸­å©ç¨è³æé©åæ¼ç®æ³çæ©æãå¨ææé²è¡å¤æ©æ§é»å­å¥åº·ç´éç ç©¶æï¼ä¸åä¸»è¦çç¶é ¸æ¯ç³»çµ±éè³æç°è³ªæ§ï¼å¶ä¸­æè¨±å¤ä»£ç¢¼å¨æ©æ§éä¸å­å¨æè¡¨ç¤ºä¸åçè¨åºæ¦å¿µãè³æé±ç§çéæ±é²ä¸æ­¥éå¶äºç´å¥å¤æ©æ§æ£èå±¤ç´è³æçå¯è¡æ§ï¼èéäºè³æå°æ¼ç ç©¶æ£èäºç¾¤ä¹éçç¸ä¼¼æ§åå·®ç°æ§æ¯å¿è¦çãçºäºæå°éäºææ°ï¼æåéç¼äº GAME æ¼ç®æ³ãGAME å·²å¨ 7 åæ©æ§å 2 ç¨®èªè¨ä¸­é²è¡æ¸¬è©¦åé©è­ï¼å®æ´åäºå¤åå±¤ç´çè³æï¼(1) å¨æ©æ§å±¤ç´ï¼ä½¿ç¨ç¥è­åè¡¨ä¾å»ºç«ä»£ç¢¼åç¾æç¥è­ä¾æºä¹éçéä¿ï¼çºæ¨æºä»£ç¢¼åå¶å½¼æ­¤ä¹éçéä¿æä¾é«çèæ¯ï¼(2) å¨æ©æ§ä¹éï¼å©ç¨èªè¨æ¨¡åä¾ç¢ºå®æ©æ§ç¹å®ä»£ç¢¼èå·²å»ºç«çæ¨æºä»£ç¢¼ä¹éçéä¿ï¼(3) ä½¿ç¨åå½¢æ³¨æç¶²è·¯éåä»£ç¢¼ä¹ééä¿çå¼·åº¦ãä½¿ç¨é·ç§»åè¯åå­¸ç¿å»ºç«è¯åè¨ç·´çåµå¥ï¼ä»¥ä¿è­·è³æé±ç§ãå¨æ¬ç ç©¶ä¸­ï¼æåå±ç¤ºäº GAME å¨é¸æç¸éç¹å¾µä½çº AI é©åæ¼ç®æ³è¼¸å¥æçé©ç¨æ§ï¼é©ç¨æ¼åç¨®ææ³ï¼ä¾å¦å¿èè¡°ç«­ãé¡é¢¨æ¿æ§éç¯çãç¶å¾ï¼æåéé»ä»ç´¹äº GAME åè«§åå¤æ©æ§é»å­å¥åº·ç´éè³æå¨é¿è²æµ·é»çç¾ççµæåç²¾ç¥ç¾çæ£èèªæ®ºé¢¨éªç ç©¶ä¸­çæç¨ï¼èç¡éå¨åå¥æ©æ§ä¹å¤å±äº«æ£èå±¤ç´è³æã

##### **EEG Artifact Detection and Correction with Deep Autoencoders**
2502.08686v1 by David AquiluÃ©-Llorens, Aureli Soria-Frisch

EEG signals convey important information about brain activity both in healthy
and pathological conditions. However, they are inherently noisy, which poses
significant challenges for accurate analysis and interpretation. Traditional
EEG artifact removal methods, while effective, often require extensive expert
intervention. This study presents LSTEEG, a novel LSTM-based autoencoder
designed for the detection and correction of artifacts in EEG signals.
Leveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear
dependencies in sequential EEG data. LSTEEG demonstrates superior performance
in both artifact detection and correction tasks compared to other
state-of-the-art convolutional autoencoders. Our methodology enhances the
interpretability and utility of the autoencoder's latent space, enabling
data-driven automated artefact removal in EEG its application in downstream
tasks. This research advances the field of efficient and accurate multi-channel
EEG preprocessing, and promotes the implementation and usage of automated EEG
analysis pipelines for brain health applications.

æè¦ï¼è¦é»åè¨èå³éäºéæ¼å¤§è¦æ´»åçéè¦è³è¨ï¼ç¡è«æ¯å¨å¥åº·æçççæ³ä¸ãç¶èï¼å®åæ¬è³ªä¸æ¯æéè¨çï¼éå°æºç¢ºçåæåè§£éæ§æäºéå¤§çææ°ãå³çµ±çè¦é»åäººå·¥è£½åç§»é¤æ¹æ³éç¶ææï¼ä½éå¸¸éè¦å¤§éçå°å®¶ä»å¥ãæ¬ç ç©¶æåº LSTEEGï¼ä¸ç¨®æ°ç©çåºæ¼ LSTM çèªåç·¨ç¢¼å¨ï¼ç¨æ¼åµæ¸¬åæ ¡æ­£è¦é»åè¨èä¸­çäººå·¥è£½åãå©ç¨æ·±åº¦å­¸ç¿ï¼ç¹å¥æ¯ LSTM å±¤ï¼LSTEEG ææåºåè¦é»åè³æä¸­çéç·æ§ä¾è³´æ§ãèå¶ä»æåé²çå·ç©èªåç·¨ç¢¼å¨ç¸æ¯ï¼LSTEEG å¨äººå·¥è£½ååµæ¸¬åæ ¡æ­£ä»»åä¸­é½å±ç¾åºåªç°çæè½ãæåçåæ³å¢å¼·äºèªåç·¨ç¢¼å¨æ½å¨ç©ºéçå¯è§£éæ§åå¯¦ç¨æ§ï¼è®è³æé©åçèªåäººå·¥è£½åç§»é¤å¾ä»¥æç¨æ¼è¦é»åçä¸æ¸¸ä»»åãéé ç ç©¶æ¨åäºé«æä¸æºç¢ºçå¤ééè¦é»ååèçé åï¼ä¸¦ä¿é²äºèªåè¦é»ååæç®¡ç·å¨è¦é¨å¥åº·æç¨ä¸­çå¯¦ä½åä½¿ç¨ã

##### **SycEval: Evaluating LLM Sycophancy**
2502.08177v1 by Aaron Fanous, Jacob Goldberg, Ank A. Agarwal, Joanna Lin, Anson Zhou, Roxana Daneshjou, Sanmi Koyejo

Large language models (LLMs) are increasingly applied in educational,
clinical, and professional settings, but their tendency for sycophancy --
prioritizing user agreement over independent reasoning -- poses risks to
reliability. This study introduces a framework to evaluate sycophantic behavior
in ChatGPT-4o, Claude-Sonnet, and Gemini-1.5-Pro across AMPS (mathematics) and
MedQuad (medical advice) datasets. Sycophantic behavior was observed in 58.19%
of cases, with Gemini exhibiting the highest rate (62.47%) and ChatGPT the
lowest (56.71%). Progressive sycophancy, leading to correct answers, occurred
in 43.52% of cases, while regressive sycophancy, leading to incorrect answers,
was observed in 14.66%. Preemptive rebuttals demonstrated significantly higher
sycophancy rates than in-context rebuttals (61.75% vs. 56.52%, $Z=5.87$,
$p<0.001$), particularly in computational tasks, where regressive sycophancy
increased significantly (preemptive: 8.13%, in-context: 3.54%, $p<0.001$).
Simple rebuttals maximized progressive sycophancy ($Z=6.59$, $p<0.001$), while
citation-based rebuttals exhibited the highest regressive rates ($Z=6.59$,
$p<0.001$). Sycophantic behavior showed high persistence (78.5%, 95% CI:
[77.2%, 79.8%]) regardless of context or model. These findings emphasize the
risks and opportunities of deploying LLMs in structured and dynamic domains,
offering insights into prompt programming and model optimization for safer AI
applications.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼æ¥çæç¨æ¼æè²ãè¨åºåå°æ¥­é åï¼ä½å®åè¶¨æ¼è¶¨çéå¢ââåªåèæ®ç¨æ¶åæèéç¨ç«æ¨çââå°å¯é æ§æ§æé¢¨éªãæ¬ç ç©¶å¼å¥äºä¸åæ¡æ¶ä¾è©ä¼° ChatGPT-4oãClaude-Sonnet å Gemini-1.5-Pro ä¸­çè¶¨çéå¢è¡çºï¼æ¶å AMPSï¼æ¸å­¸ï¼å MedQuadï¼é«çå»ºè­°ï¼æ¸æéãå¨ 58.19% çæ¡ä¾ä¸­è§å¯å°äºè¶¨çéå¢è¡çºï¼å¶ä¸­ Gemini è¡¨ç¾åºæé«æ¯çï¼62.47%ï¼ï¼è ChatGPT æä½ï¼56.71%ï¼ãå°è´æ­£ç¢ºç­æ¡çæ¼¸é²å¼è¶¨çéå¢ç¼çå¨ 43.52% çæ¡ä¾ä¸­ï¼èå°è´ä¸æ­£ç¢ºç­æ¡çéæ­¥å¼è¶¨çéå¢åå¨ 14.66% çæ¡ä¾ä¸­è¢«è§å¯å°ãåç¼å¶äººçåé§è¡¨ç¾åºé¡¯èé«æ¼ä¸ä¸æåé§çè¶¨çéå¢çï¼61.75% å° 56.52%ï¼Z=5.87ï¼p<0.001ï¼ï¼ç¹å¥æ¯å¨è¨ç®ä»»åä¸­ï¼å¶ä¸­éæ­¥å¼è¶¨çéå¢é¡¯èå¢å ï¼åç¼å¶äººï¼8.13%ï¼ä¸ä¸æï¼3.54%ï¼p<0.001ï¼ãç°¡å®çåé§æå¤§åäºæ¼¸é²å¼è¶¨çéå¢ï¼Z=6.59ï¼p<0.001ï¼ï¼èåºæ¼å¼ç¨çåé§è¡¨ç¾åºæé«çéæ­¥å¼æ¯çï¼Z=6.59ï¼p<0.001ï¼ãè¶¨çéå¢è¡çºè¡¨ç¾åºå¾é«çæçºæ§ï¼78.5%ï¼95% CIï¼[77.2%ï¼79.8%]ï¼ï¼ç¡è«ä¸ä¸æææ¨¡åå¦ä½ãéäºç¼ç¾å¼·èª¿äºå¨çµæ§åååæé åé¨ç½² LLM çé¢¨éªåæ©éï¼çºæ´å®å¨ç AI æç¨æä¾äºæç¤ºç·¨ç¨åæ¨¡ååªåçè¦è§£ã

##### **Cancer Vaccine Adjuvant Name Recognition from Biomedical Literature using Large Language Models**
2502.09659v1 by Hasin Rehana, Jie Zheng, Leo Yeh, Benu Bansal, Nur Bengisu Ãam, Christianah Jemiyo, Brett McGregor, Arzucan ÃzgÃ¼r, Yongqun He, Junguk Hur

Motivation: An adjuvant is a chemical incorporated into vaccines that
enhances their efficacy by improving the immune response. Identifying adjuvant
names from cancer vaccine studies is essential for furthering research and
enhancing immunotherapies. However, the manual curation from the constantly
expanding biomedical literature poses significant challenges. This study
explores the automated recognition of vaccine adjuvant names using Large
Language Models (LLMs), specifically Generative Pretrained Transformers (GPT)
and Large Language Model Meta AI (Llama). Methods: We utilized two datasets: 97
clinical trial records from AdjuvareDB and 290 abstracts annotated with the
Vaccine Adjuvant Compendium (VAC). GPT-4o and Llama 3.2 were employed in
zero-shot and few-shot learning paradigms with up to four examples per prompt.
Prompts explicitly targeted adjuvant names, testing the impact of contextual
information such as substances or interventions. Outputs underwent automated
and manual validation for accuracy and consistency. Results: GPT-4o attained
100% Precision across all situations while exhibiting notable improve in Recall
and F1-scores, particularly with incorporating interventions. On the VAC
dataset, GPT-4o achieved a maximum F1-score of 77.32% with interventions,
surpassing Llama-3.2-3B by approximately 2%. On the AdjuvareDB dataset, GPT-4o
reached an F1-score of 81.67% for three-shot prompting with interventions,
surpassing Llama-3.2-3 B's maximum F1-score of 65.62%. Conclusion: Our findings
demonstrate that LLMs excel at identifying adjuvant names, including rare
variations of naming representation. This study emphasizes the capability of
LLMs to enhance cancer vaccine development by efficiently extracting insights.
Future work aims to broaden the framework to encompass various biomedical
literature and enhance model generalizability across various vaccines and
adjuvants.

æè¦ï¼<paragraph>åæ©ï¼ä½åæ¯ä¸ç¨®å å¥ç«èçåå­¸ç©è³ªï¼è½èç±æ¹ååç«åæä¾æåç«èçæåãå¾ççç«èç ç©¶ä¸­æ¾åºä½ååç¨±å°æ¼æ¨é²ç ç©¶åæ¹ååç«çæ³è³ééè¦ãç¶èï¼å¾ä¸æ·æ´å±ççç©é«å­¸æç»ä¸­æåæ´çæé æéå¤§ææ°ãæ¬ç ç©¶æ¢è¨ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ç¹å¥æ¯çæå¼é è¨ç·´Transformer (GPT) åå¤§åèªè¨æ¨¡å Meta AI (Llama) ä¾èªåè¾¨è­ç«èä½ååç¨±ãæ¹æ³ï¼æåä½¿ç¨å©åè³æéï¼ä¾èª AdjuvareDB ç 97 ä»½è¨åºè©¦é©è¨éå 290 ç¯æ¨è¨»äºç«èä½åå½ç·¨ (VAC) çæè¦ãGPT-4o å Llama 3.2 è¢«ç¨æ¼é¶æ¬¡å­¸ç¿åå°éå­¸ç¿ç¯ä¾ï¼æ¯åæç¤ºæå¤æååç¯ä¾ãæç¤ºæç¢ºéå®ä½ååç¨±ï¼æ¸¬è©¦ç©è³ªæä»å¥æªæ½ç­èæ¯è³è¨çå½±é¿ãè¼¸åºç¶éèªååæåé©è­ï¼ä»¥ç¢ºä¿æºç¢ºæ§åä¸è´æ§ãçµæï¼GPT-4o å¨ææææ³ä¸é½éå° 100% çæºç¢ºçï¼åæå¨å¬åçå F1 åæ¸ä¸è¡¨ç¾åºé¡¯èçé²æ­¥ï¼ç¹å¥æ¯å¨ç´å¥ä»å¥æªæ½çææ³ä¸ãå¨ VAC è³æéä¸ï¼GPT-4o å¨æä»å¥æªæ½çææ³ä¸éå° 77.32% çæé« F1 åæ¸ï¼æ¯ Llama-3.2-3B é«åºç´ 2%ãå¨ AdjuvareDB è³æéä¸ï¼GPT-4o å¨æä»å¥æªæ½çä¸æ¬¡æç¤ºä¸­éå° 81.67% ç F1 åæ¸ï¼è¶é Llama-3.2-3 B çæé« F1 åæ¸ 65.62%ãçµè«ï¼æåçç ç©¶çµæè¡¨æï¼LLM å¨è¾¨è­ä½ååç¨±æ¹é¢è¡¨ç¾åºè²ï¼åæ¬å½åè¡¨ç¤ºçç½è¦è®ç°ãæ¬ç ç©¶å¼·èª¿äº LLM å¨æææåè¦è§£æ¹é¢å¢å¼·ççç«èéç¼çè½åãæªä¾çç ç©¶å·¥ä½æ¨å¨æ´å¤§æ¶æ§ï¼æ¶µèåç¨®çç©é«å­¸æç»ï¼ä¸¦å¢å¼·æ¨¡åå¨åç¨®ç«èåä½åä¸­çæ³åè½åã</paragraph>

##### **Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?**
2502.07963v1 by Hye Sun Yun, Karen Y. C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace

Medical research faces well-documented challenges in translating novel
treatments into clinical practice. Publishing incentives encourage researchers
to present "positive" findings, even when empirical results are equivocal.
Consequently, it is well-documented that authors often spin study results,
especially in article abstracts. Such spin can influence clinician
interpretation of evidence and may affect patient care decisions. In this
study, we ask whether the interpretation of trial results offered by Large
Language Models (LLMs) is similarly affected by spin. This is important since
LLMs are increasingly being used to trawl through and synthesize published
medical evidence. We evaluated 22 LLMs and found that they are across the board
more susceptible to spin than humans. They might also propagate spin into their
outputs: We find evidence, e.g., that LLMs implicitly incorporate spin into
plain language summaries that they generate. We also find, however, that LLMs
are generally capable of recognizing spin, and can be prompted in a way to
mitigate spin's impact on LLM outputs.

æè¦ï¼é«å­¸ç ç©¶å¨å°æ°ç©çæ³è½åçºè¨åºå¯¦åä¸ï¼é¢è¨èææå¯æ¥çææ°ãç¼è¡¨èªå é¼åµç ç©¶äººå¡åç¾ãæ­£åãçç¼ç¾ï¼å³ä½¿ç¶é©çµææ¨¡ç¨å©å¯ãå æ­¤ï¼ææå¯æ¥çæ¯ï¼ä½èç¶å¸¸æ­æ²ç ç©¶çµæï¼ç¹å¥æ¯å¨æç« æè¦ä¸­ãæ­¤é¡æ­æ²å¯è½æå½±é¿è¨åºé«å¸«å°è­æçè©®éï¼ä¸¦å¯è½å½±é¿çæ£ç§è­·æ±ºç­ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) æä¾çè©¦é©çµæè©®éæ¯å¦ä¹åå°æ­æ²å½±é¿ãç±æ¼ LLM æ­£è¶ä¾è¶å¸¸è¢«ç¨æ¼ç¬æ¢³åç¶åå·²ç¼è¡¨çé«å­¸è­æï¼å æ­¤éé»éå¸¸éè¦ãæåè©ä¼°äº 22 å LLMï¼ç¼ç¾å®åæ®éæ¯äººé¡æ´å®¹æåå°æ­æ²å½±é¿ãå®åä¹å¯è½å°æ­æ²å³æ­å°å¶è¼¸åºä¸­ï¼ä¾å¦ï¼æåç¼ç¾ LLM æå°æ­æ²é±å«ç´å¥å¶ç¢ççç½è©±ææè¦ä¸­ãç¶èï¼æåä¹ç¼ç¾ LLM éå¸¸æè½åè¾¨èªæ­æ²ï¼èä¸å¯ä»¥ééæç¤ºçæ¹å¼æ¸è¼æ­æ²å° LLM è¼¸åºçå½±é¿ã

##### **An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating**
2502.07755v1 by Mohammad Ali Labbaf Khaniki, Sahabeh Saadati, Mohammad Manthouri

This paper presents a novel Natural Language Processing (NLP) framework for
enhancing medical diagnosis through the integration of advanced techniques in
data augmentation, feature extraction, and classification. The proposed
approach employs back-translation to generate diverse paraphrased datasets,
improving robustness and mitigating overfitting in classification tasks.
Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with
Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained
contextual and positional relationships, dynamically adjusting the influence of
positional information based on semantic context to produce high-quality text
embeddings. For classification, an Attention-Based Feedforward Neural Network
(ABFNN) is utilized, effectively focusing on the most relevant features to
improve decision-making accuracy. Applied to the classification of symptoms,
clinical notes, and other medical texts, this architecture demonstrates its
ability to address the complexities of medical data. The combination of data
augmentation, contextual embedding generation, and advanced classification
mechanisms offers a robust and accurate diagnostic tool, with potential
applications in automated medical diagnosis and clinical decision support. This
method demonstrates the effectiveness of the proposed NLP framework for medical
diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of
99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only
underscore the model's robust performance in classifying medical texts with
exceptional precision and reliability but also highlight its superiority over
existing methods, making it a highly promising tool for automated diagnostic
systems.

æè¦ï¼æ¬ææåºäºä¸ååµæ°çèªç¶èªè¨èç (NLP) æ¡æ¶ï¼ééæ´åè³ææ´åãç¹å¾µèåååé¡çé²éæè¡ä¾å¢å¼·é«çè¨ºæ·ãææåºçæ¹æ³æ¡ç¨ååç¿»è­¯ä¾ç¢çå¤æ¨£åçåç¾©æ¹å¯«è³æéï¼æåç©©å¥æ§ä¸¦æ¸è¼åé¡ä»»åä¸­çéåº¦æ¬åãééå©ç¨å·æåæèçµ¡ä½ç½®éæ§ (DCPG) çè§£ç¢¼å¢å¼· BERT èå»ç³¾çºæ³¨æå (DeBERTa)ï¼éåæ¨¡åææç´°ç·»çèçµ¡åä½ç½®éä¿ï¼æ ¹æèªæèçµ¡åæèª¿æ´ä½ç½®è³è¨çå½±é¿ï¼ä»¥ç¢çé«åè³ªçæå­åµå¥ãå¨åé¡æ¹é¢ï¼å©ç¨åºæ¼æ³¨æåçåé¥ç¥ç¶ç¶²è·¯ (ABFNN)ï¼ææå°éæ³¨æç¸éçç¹å¾µï¼ä»¥æé«æ±ºç­æºç¢ºåº¦ãæç¨æ¼ççãè¨åºç­è¨åå¶ä»é«çææ¬çåé¡ï¼æ­¤æ¶æ§è­æäºå¶èçé«çè³æè¤éæ§çè½åãè³ææ´åãèçµ¡åµå¥ç¢çåé²éåé¡æ©å¶ççµåæä¾äºä¸åç©©å¥ä¸æºç¢ºçè¨ºæ·å·¥å·ï¼å¨èªååé«çè¨ºæ·åè¨åºæ±ºç­æ¯æ´ä¸­å·ææ½å¨æç¨ãæ­¤æ¹æ³è­æäºææåºç NLP æ¡æ¶å¨é«çè¨ºæ·ä¸­çæææ§ï¼ä»¥ 99.78% çæºç¢ºåº¦ã99.72% çå¬åçã99.79% çç²¾ç¢ºåº¦å 99.75% ç F1 åæ¸ï¼åå¾äºé¡¯èçææãéäºææ¨ä¸åå¼·èª¿äºæ¨¡åå¨åé¡é«çææ¬æå·æåè¶çç²¾ç¢ºåº¦åå¯é æ§ï¼ä¹çªé¡¯äºå®åªæ¼ç¾ææ¹æ³çåªè¶æ§ï¼ä½¿å¶æçºèªååè¨ºæ·ç³»çµ±ä¸­æ¥µå·åæ¯çå·¥å·ã

##### **Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension**
2502.07752v1 by Wenbo Gong, Meyer Scetbon, Chao Ma, Edward Meeds

Designing efficient optimizers for large language models (LLMs) with
low-memory requirements and fast convergence is an important and challenging
problem. This paper makes a step towards the systematic design of such
optimizers through the lens of structured Fisher information matrix (FIM)
approximation. We show that many state-of-the-art efficient optimizers can be
viewed as solutions to FIM approximation (under the Frobenius norm) with
specific structural assumptions. Building on these insights, we propose two
design recommendations of practical efficient optimizers for LLMs, involving
the careful selection of structural assumptions to balance generality and
efficiency, and enhancing memory efficiency of optimizers with general
structures through a novel low-rank extension framework. We demonstrate how to
use each design approach by deriving new memory-efficient optimizers: Row and
Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation
(Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the
effectiveness, showing faster and better convergence than existing
memory-efficient baselines and Adam with little memory overhead. Notably, Alice
achieves better than 2x faster convergence over Adam, while RACS delivers
strong performance on the 1B model with SGD-like memory.

æè¦ï¼è¨­è¨å·æä½è¨æ¶é«éæ±åå¿«éæ¶æçå¤§åèªè¨æ¨¡å (LLM) çé«ææä½³åå¨æ¯ä¸åéè¦ä¸å·æææ°æ§çåé¡ãæ¬æééçµæ§å Fisher è³è¨ç©é£ (FIM) è¿ä¼¼çè§åº¦ï¼æåæ­¤é¡æä½³åå¨çç³»çµ±åè¨­è¨éé²ä¸æ­¥ãæåå±ç¤ºäºè¨±å¤æåé²çé«ææä½³åå¨å¯ä»¥è¢«è¦çº FIM è¿ä¼¼ï¼å¨ Frobenius ç¯æ¸ä¸ï¼çè§£ï¼ä¸¦å·æç¹å®ççµæ§åè¨­ãåºæ¼éäºè¦è§£ï¼æåæåºäº LLM çå©åå¯¦ç¨é«ææä½³åå¨è¨­è¨å»ºè­°ï¼åæ¬ä»ç´°é¸æçµæ§åè¨­ä»¥å¹³è¡¡éç¨æ§åæçï¼ä¸¦ééæ°ç©çä½ç§©å»¶ä¼¸æ¶æ§ä¾å¢å¼·å·æéç¨çµæ§çæä½³åå¨çè¨æ¶é«æçãæåå±ç¤ºäºå¦ä½ééæ¨å°æ°çè¨æ¶é«é«ææä½³åå¨ä¾ä½¿ç¨æ¯ç¨®è¨­è¨æ¹æ³ï¼ååæ¬ç¸®æ¾ SGD (RACS) åèªé©æä½ç¶­å­ç©ºéä¼°è¨ (Alice)ãå¨ LLaMA é è¨ç·´ï¼é«é 1B åæ¸ï¼ä¸çå¯¦é©é©è­äºå¶æææ§ï¼é¡¯ç¤ºæ¯ç¾æçè¨æ¶é«é«æåºç·å Adam æ´å¿«ä¸æ´å¥½çæ¶æï¼ä¸è¨æ¶é«éé·å¾å°ãå¼å¾æ³¨æçæ¯ï¼Alice æ¯ Adam å¿« 2 åä»¥ä¸ï¼è RACS åå¨ 1B æ¨¡åä¸æä¾é¡ä¼¼ SGD è¨æ¶é«çå¼·åæè½ã

##### **The Devil is in the Prompts: De-Identification Traces Enhance Memorization Risks in Synthetic Chest X-Ray Generation**
2502.07516v2 by Raman Dutt

Generative models, particularly text-to-image (T2I) diffusion models, play a
crucial role in medical image analysis. However, these models are prone to
training data memorization, posing significant risks to patient privacy.
Synthetic chest X-ray generation is one of the most common applications in
medical image analysis with the MIMIC-CXR dataset serving as the primary data
repository for this task. This study presents the first systematic attempt to
identify prompts and text tokens in MIMIC-CXR that contribute the most to
training data memorization. Our analysis reveals two unexpected findings: (1)
prompts containing traces of de-identification procedures (markers introduced
to hide Protected Health Information) are the most memorized, and (2) among all
tokens, de-identification markers contribute the most towards memorization.
This highlights a broader issue with the standard anonymization practices and
T2I synthesis with MIMIC-CXR. To exacerbate, existing inference-time
memorization mitigation strategies are ineffective and fail to sufficiently
reduce the model's reliance on memorized text tokens. On this front, we propose
actionable strategies for different stakeholders to enhance privacy and improve
the reliability of generative models in medical imaging. Finally, our results
provide a foundation for future work on developing and benchmarking
memorization mitigation techniques for synthetic chest X-ray generation using
the MIMIC-CXR dataset. The anonymized code is available at
https://anonymous.4open.science/r/diffusion_memorization-8011/

æè¦ï¼<paragraph>çææ¨¡åï¼å°¤å¶æ¯ææ¬å°å½±å (T2I) æ´æ£æ¨¡åå¨é«å­¸å½±ååæä¸­æ®æ¼èè³ééè¦çè§è²ãç¶èï¼éäºæ¨¡åå®¹æè¨ç·´è³æè¨æ¶ï¼å°çæ£é±ç§æ§æéå¤§é¢¨éªãåæè¸é¨ X åå½±åçææ¯é«å­¸å½±ååæä¸­æå¸¸è¦çæç¨ä¹ä¸ï¼è MIMIC-CXR è³æéåä½çºæ­¤ä»»åçä¸»è¦è³æå²å­åº«ãæ¬ç ç©¶æåºäºç¬¬ä¸åç³»çµ±åçåè©¦ï¼ä»¥è­å¥ MIMIC-CXR ä¸­å°è¨ç·´è³æè¨æ¶è²¢ç»æå¤§çæç¤ºåæå­ä»£ç¢¼ãæåçåææ­ç¤ºäºå©ååºä¹ææçç¼ç¾ï¼(1) åå«å»è­å¥ç¨åºçè·¡çæç¤ºï¼ç¨æ¼é±èåä¿è­·å¥åº·è³è¨çæ¨è¨ï¼æ¯æå®¹æè¢«è¨æ¶çï¼ä»¥å (2) å¨ææä»£ç¢¼ä¸­ï¼å»è­å¥æ¨è¨å°è¨æ¶çè²¢ç»æå¤§ãéçªé¡¯äºæ¨æºå¿ååå¯¦ååä½¿ç¨ MIMIC-CXR é²è¡ T2I åæçæ´å»£æ³åé¡ãæ´ç³çæ¯ï¼ç¾æçæ¨è«æéè¨æ¶æ¸ç·©ç­ç¥ç¡æï¼ç¡æ³ååéä½æ¨¡åå°è¨æ¶æå­ä»£ç¢¼çä¾è³´ãå¨éåæ¹é¢ï¼æåéå°ä¸åçå©å®³éä¿äººæåºå¯è¡çç­ç¥ï¼ä»¥å¢å¼·é±ç§åæ¹åçææ¨¡åå¨é«å­¸å½±åä¸­çå¯é æ§ãæå¾ï¼æåççµæçºæªä¾éç¼åè©éä½¿ç¨ MIMIC-CXR è³æéé²è¡åæè¸é¨ X åå½±åçæçè¨æ¶æ¸ç·©æè¡å¥ å®äºåºç¤ãå·²å¿ååçç¨å¼ç¢¼å¯å¨ https://anonymous.4open.science/r/diffusion_memorization-8011/ åå¾ã</paragraph>

##### **KPIs 2024 Challenge: Advancing Glomerular Segmentation from Patch- to Slide-Level**
2502.07288v1 by Ruining Deng, Tianyuan Yao, Yucheng Tang, Junlin Guo, Siqi Lu, Juming Xiong, Lining Yu, Quan Huu Cap, Pengzhou Cai, Libin Lan, Ze Zhao, Adrian Galdran, Amit Kumar, Gunjan Deotale, Dev Kumar Das, Inyoung Paik, Joonho Lee, Geongyu Lee, Yujia Chen, Wangkai Li, Zhaoyang Li, Xuege Hou, Zeyuan Wu, Shengjin Wang, Maximilian Fischer, Lars Kramer, Anghong Du, Le Zhang, Maria Sanchez Sanchez, Helena Sanchez Ulloa, David Ribalta Heredia, Carlos Perez de Arenaza Garcia, Shuoyu Xu, Bingdou He, Xinping Cheng, Tao Wang, Noemie Moreau, Katarzyna Bozek, Shubham Innani, Ujjwal Baid, Kaura Solomon Kefas, Bennett A. Landman, Yu Wang, Shilin Zhao, Mengmeng Yin, Haichun Yang, Yuankai Huo

Chronic kidney disease (CKD) is a major global health issue, affecting over
10% of the population and causing significant mortality. While kidney biopsy
remains the gold standard for CKD diagnosis and treatment, the lack of
comprehensive benchmarks for kidney pathology segmentation hinders progress in
the field. To address this, we organized the Kidney Pathology Image
Segmentation (KPIs) Challenge, introducing a dataset that incorporates
preclinical rodent models of CKD with over 10,000 annotated glomeruli from 60+
Periodic Acid Schiff (PAS)-stained whole slide images. The challenge includes
two tasks, patch-level segmentation and whole slide image segmentation and
detection, evaluated using the Dice Similarity Coefficient (DSC) and F1-score.
By encouraging innovative segmentation methods that adapt to diverse CKD models
and tissue conditions, the KPIs Challenge aims to advance kidney pathology
analysis, establish new benchmarks, and enable precise, large-scale
quantification for disease research and diagnosis.

æè¦ï¼æ¢æ§èèç (CKD) æ¯å¨çä¸»è¦çå¥åº·åé¡ï¼å½±é¿è¶é
10% çäººå£ï¼ä¸¦é æé¡¯èçæ­»äº¡çãéç¶èèæ´»æª¢
ä»ç¶æ¯ CKD è¨ºæ·åæ²»ççé»éæ¨æºï¼ä½ç¼ºä¹
èèççå­¸åå²çå¨é¢åºæºé»ç¤äºè©²é åçé²å±ã
çºäºè§£æ±ºéååé¡ï¼æåçµç¹äºèèççå½±å
åå² (KPIs) ææ°ï¼å¼å¥äºåå«è¶é 10,000 åè¨»è§£ç
CKD è¨åºååé½åç©æ¨¡åçè³æéï¼éäºè¨»è§£ä¾èª 60 å¤å
é±ææ§é¸æ§éªå¤« (PAS) æè²çå¨å¹»ççå½±åãææ°åæ¬
å©åä»»åï¼ä¿®è£å±¤ç´åå²åå¨å¹»ççå½±ååå²å
åµæ¸¬ï¼ä½¿ç¨ Dice ç¸ä¼¼ä¿æ¸ (DSC) å F1 åæ¸é²è¡è©ä¼°ã
ééé¼åµåµæ°çåå²æ¹æ³ä¾é©æä¸åç CKD æ¨¡å
åçµç¹æ¢ä»¶ï¼KPIs ææ°æ¨å¨æ¨é²èèçç
åæï¼å»ºç«æ°çåºæºï¼ä¸¦å¯¦ç¾ç²¾ç¢ºãå¤§è¦æ¨¡ç
ç¾çç ç©¶åè¨ºæ·éåã

##### **Early Risk Prediction of Pediatric Cardiac Arrest from Electronic Health Records via Multimodal Fused Transformer**
2502.07158v2 by Jiaying Lu, Stephanie R. Brown, Songyuan Liu, Shifan Zhao, Kejun Dong, Del Bold, Michael Fundora, Alaa Aljiffry, Alex Fedorov, Jocelyn Grunwell, Xiao Hu

Early prediction of pediatric cardiac arrest (CA) is critical for timely
intervention in high-risk intensive care settings. We introduce PedCA-FT, a
novel transformer-based framework that fuses tabular view of EHR with the
derived textual view of EHR to fully unleash the interactions of
high-dimensional risk factors and their dynamics. By employing dedicated
transformer modules for each modality view, PedCA-FT captures complex temporal
and contextual patterns to produce robust CA risk estimates. Evaluated on a
curated pediatric cohort from the CHOA-CICU database, our approach outperforms
ten other artificial intelligence models across five key performance metrics
and identifies clinically meaningful risk factors. These findings underscore
the potential of multimodal fusion techniques to enhance early CA detection and
improve patient care.

æè¦ï¼æ©æé æ¸¬å°åå¿èé©å (CA) å°æ¼å¨é«é¢¨éªçéçç§è­·ç°å¢ä¸­åæä»å¥è³ééè¦ãæåå¼å¥äº PedCA-FTï¼ä¸åæ°ç©çåºæ¼è½æå¨çæ¡æ¶ï¼å®å° EHR çè¡¨æ ¼è¦åè EHR çæ´¾çææ¬è¦åèåå¨ä¸èµ·ï¼ä»¥ååç¼æ®é«ç¶­é¢¨éªå ç´ åå¶åæçäº¤äºä½ç¨ãééçºæ¯åæ¨¡æè¦åæ¡ç¨å°ç¨çè½æå¨æ¨¡çµï¼PedCA-FT æç²è¤éçæéåä¸ä¸ææ¨¡å¼ï¼ä»¥ç¢çç©©å¥ç CA é¢¨éªä¼°è¨ãå¨ CHOA-CICU è³æåº«ä¸­ç­åçå°åç¾¤é«ä¸­é²è¡è©ä¼°ï¼æåçåæ³å¨äºé ééµç¸¾æææ¨ä¸­åªæ¼å¶ä»åç¨®äººå·¥æºæ§æ¨¡åï¼ä¸¦æ¾åºè¨åºä¸ææç¾©çé¢¨éªå ç´ ãéäºç¼ç¾å¼·èª¿äºå¤æ¨¡å¼èåæè¡å¨å¢å¼·æ©æ CA æª¢æ¸¬åæ¹åæ£èç§è­·æ¹é¢çæ½åã

##### **Explaining 3D Computed Tomography Classifiers with Counterfactuals**
2502.07156v1 by Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari

Counterfactual explanations in medical imaging are critical for understanding
the predictions made by deep learning models. We extend the Latent Shift
counterfactual generation method from 2D applications to 3D computed tomography
(CT) scans. We address the challenges associated with 3D data, such as limited
training samples and high memory demands, by implementing a slice-based
approach. This method leverages a 2D encoder trained on CT slices, which are
subsequently combined to maintain 3D context. We demonstrate this technique on
two models for clinical phenotype prediction and lung segmentation. Our
approach is both memory-efficient and effective for generating interpretable
counterfactuals in high-resolution 3D medical imaging.

æè¦ï¼åäºå¯¦è§£éå¨é«å­¸å½±åä¸­å°æ¼çè§£æ·±åº¦å­¸ç¿æ¨¡åæåçé æ¸¬è³ééè¦ãæåå° Latent Shift åäºå¯¦çææ¹æ³å¾ 2D æç¨ç¨å¼å»¶ä¼¸å° 3D é»è¦æ·å±¤ææ (CT) ææãæåééå¯¦ä½åºæ¼åççåæ³ï¼ä¾è§£æ±ºè 3D è³æç¸éçææ°ï¼ä¾å¦åéçè¨ç·´æ¨£æ¬åé«è¨æ¶é«éæ±ãæ­¤æ¹æ³å©ç¨ç¶é CT åçè¨ç·´ç 2D ç·¨ç¢¼å¨ï¼é¨å¾å°éäºåççµåèµ·ä¾ä»¥ç¶­è­· 3D èæ¯ãæåå¨å©åç¨æ¼è¨åºè¡¨åé æ¸¬åèºé¨åå²çæ¨¡åä¸å±ç¤ºæ­¤æè¡ãæåçåæ³å°æ¼å¨é«è§£æåº¦ 3D é«å­¸å½±åä¸­ç¢çå¯è§£éçåäºå¯¦ï¼æ¢ç¯çè¨æ¶é«åææã

##### **Interactive Data Harmonization with LLM Agents**
2502.07132v1 by AÃ©cio Santos, Eduardo H. M. Pena, Roque Lopez, Juliana Freire

Data harmonization is an essential task that entails integrating datasets
from diverse sources. Despite years of research in this area, it remains a
time-consuming and challenging task due to schema mismatches, varying
terminologies, and differences in data collection methodologies. This paper
presents the case for agentic data harmonization as a means to both empower
experts to harmonize their data and to streamline the process. We introduce
Harmonia, a system that combines LLM-based reasoning, an interactive user
interface, and a library of data harmonization primitives to automate the
synthesis of data harmonization pipelines. We demonstrate Harmonia in a
clinical data harmonization scenario, where it helps to interactively create
reusable pipelines that map datasets to a standard format. Finally, we discuss
challenges and open problems, and suggest research directions for advancing our
vision.

æè¦ï¼è³æèª¿åæ¯ä¸é æ´åä¸åä¾æºè³æéçéè¦ä»»åãåç®¡å¤å¹´ä¾éå°æ­¤é åçç ç©¶ä¸æ·ï¼ä½ç±æ¼æ¶æ§ä¸å¹éãè¡èªä¸åï¼ä»¥åè³ææ¶éæ¹æ³çå·®ç°ï¼å®ä»ç¶æ¯ä¸é èæä¸å·æææ°æ§çä»»åãæ¬ææåºä»£çè³æèª¿åï¼ä½çºè³¦è½å°å®¶èª¿åå¶è³æä¸¦ç°¡åæµç¨çæ¹æ³ãæåä»ç´¹ Harmoniaï¼ä¸åçµåäºåºæ¼ LLM çæ¨çãäºåå¼ä½¿ç¨èä»é¢åè³æèª¿ååèªåº«çç³»çµ±ï¼ä»¥èªååè³æèª¿åç®¡ç·çåæãæåå¨è¨åºè³æèª¿åå ´æ¯ä¸­å±ç¤ºäº Harmoniaï¼å®æå©æ¼äºåå¼å»ºç«å¯éè¤ä½¿ç¨çç®¡ç·ï¼å°è³æéå°æè³æ¨æºæ ¼å¼ãæå¾ï¼æåè¨è«ææ°åéæ¾æ§åé¡ï¼ä¸¦å»ºè­°ç ç©¶æ¹åä»¥æ¨é²æåçé¡æ¯ã

##### **Machine Learning for Everyone: Simplifying Healthcare Analytics with BigQuery ML**
2502.07026v1 by Mohammad Amir Salari, Bahareh Rahmani

Machine learning (ML) is transforming healthcare by enabling predictive
analytics, personalized treatments, and improved patient outcomes. However,
traditional ML workflows require specialized skills, infrastructure, and
resources, limiting accessibility for many healthcare professionals. This paper
explores how Google Cloud's BigQuery ML simplifies the development and
deployment of ML models using SQL, reducing technical barriers. Through a case
study on diabetes prediction using the Diabetes Health Indicators Dataset, we
evaluate three predictive models: Logistic Regression, Boosted Tree, and Deep
Neural Network (DNN). Our results demonstrate that the Boosted Tree model
achieves the highest performance, making it highly effective for diabetes
prediction. This study highlights BigQuery ML's role in democratizing machine
learning by providing a scalable, efficient, and accessible solution for
healthcare analytics.

æè¦ï¼æ©å¨å­¸ç¿ (ML) ééåç¨é æ¸¬åæãåäººåæ²»çåæ¹åçæ£çµæï¼æ­£å¨è½åé«çä¿å¥ãç¶èï¼å³çµ±ç ML å·¥ä½æµç¨éè¦å°æ¥­æè½ãåºç¤è¨­æ½åè³æºï¼éå¶äºè¨±å¤é«çä¿å¥å°æ¥­äººå¡çå¯åæ§ãæ¬ææ¢è¨ Google Cloud ç BigQuery ML å¦ä½ä½¿ç¨ SQL ç°¡å ML æ¨¡åçéç¼åé¨ç½²ï¼éä½æè¡éç¤ãééä½¿ç¨ç³å°¿çå¥åº·ææ¨è³æéå°ç³å°¿çé æ¸¬é²è¡åæ¡ç ç©¶ï¼æåè©ä¼°äºä¸åé æ¸¬æ¨¡åï¼éè¼¯è¿´æ­¸ãæåæ¨¹åæ·±åº¦ç¥ç¶ç¶²è·¯ (DNN)ãæåççµæè­æï¼æåæ¨¹æ¨¡åéå°äºæé«çæè½ï¼ä½¿å¶å°æ¼ç³å°¿çé æ¸¬éå¸¸ææãéé ç ç©¶å¼·èª¿äº BigQuery ML å¨æ°ä¸»åæ©å¨å­¸ç¿ä¸­æ®æ¼çè§è²ï¼æä¾å¯æ´åãææçä¸å¯å­åçé«çä¿å¥åæè§£æ±ºæ¹æ¡ã

##### **AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements**
2502.07022v1 by Adriana Eufrosiana Bora, Pierre-Luc St-Charles, Mirko Bronzi, ArsÃ¨ne Fansi Tchango, Bruno Rousseau, Kerrie Mengersen

Despite over a decade of legislative efforts to address modern slavery in the
supply chains of large corporations, the effectiveness of government oversight
remains hampered by the challenge of scrutinizing thousands of statements
annually. While Large Language Models (LLMs) can be considered a well
established solution for the automatic analysis and summarization of documents,
recognizing concrete modern slavery countermeasures taken by companies and
differentiating those from vague claims remains a challenging task. To help
evaluate and fine-tune LLMs for the assessment of corporate statements, we
introduce a dataset composed of 5,731 modern slavery statements taken from the
Australian Modern Slavery Register and annotated at the sentence level. This
paper details the construction steps for the dataset that include the careful
design of annotation specifications, the selection and preprocessing of
statements, and the creation of high-quality annotation subsets for effective
model evaluations. To demonstrate our dataset's utility, we propose a machine
learning methodology for the detection of sentences relevant to mandatory
reporting requirements set by the Australian Modern Slavery Act. We then follow
this methodology to benchmark modern language models under zero-shot and
supervised learning settings.

æè¦ï¼åç®¡ç«æ³åªåè¶éåå¹´ï¼æ¨å¨è§£æ±ºå¤§åä¼æ¥­ä¾æéä¸­çç¾ä»£å¥´é¸å¶ï¼ä½æ¿åºç£ç£çæææ§ä»ç¶åå°æ¯å¹´å¯©æ¥æ¸åä»½è²æçææ°æé»ç¤ãéç¶å¤§åèªè¨æ¨¡åï¼LLMï¼å¯ä»¥è¢«èªçºæ¯æä»¶èªååæåæè¦çå®åè§£æ±ºæ¹æ¡ï¼ä½è¦è¾¨è­å¬å¸æ¡åçå·é«ç¾ä»£å¥´é¸å¶å°ç­ï¼ä¸¦å°å¶èå«ç³çè²æååéä¾ï¼ä»ç¶æ¯ä¸é å·æææ°æ§çä»»åãçºäºå¹«å©è©ä¼°åå¾®èª¿ LLM ä»¥è©ä¼°ä¼æ¥­è²æï¼æåå¼å¥äºä¸åç± 5,731 ä»½ç¾ä»£å¥´é¸å¶è²æçµæçè³æéï¼éäºè²æåèªæ¾³æ´²ç¾ä»£å¥´é¸å¶è¨»åèï¼ä¸¦å¨å¥å­å±¤ç´é²è¡è¨»è§£ãæ¬æè©³ç´°èªªæäºè³æéçå»ºæ§æ­¥é©ï¼å¶ä¸­åæ¬è¨»è§£è¦æ ¼çä»ç´°è¨­è¨ãè²æçé¸æåé èçï¼ä»¥åç¨æ¼æææ¨¡åè©ä¼°çé«åè³ªè¨»è§£å­éçå»ºç«ãçºäºå±ç¤ºæåçè³æéçæç¨ï¼æåæåºäºä¸ç¨®æ©å¨å­¸ç¿æ¹æ³ï¼ç¨æ¼æª¢æ¸¬èæ¾³æ´²ç¾ä»£å¥´é¸å¶æ³è¦å®çå¼·å¶æ§å ±åè¦æ±ç¸éçå¥å­ãç¶å¾ï¼æåéµå¾ªéç¨®æ¹æ³ï¼å¨é¶æ¬¡å­¸ç¿åç£ç£å­¸ç¿è¨­å®ä¸å°ç¾ä»£èªè¨æ¨¡åé²è¡åºæºæ¸¬è©¦ã

##### **Recent Advances, Applications and Open Challenges in Machine Learning for Health: Reflections from Research Roundtables at ML4H 2024 Symposium**
2502.06693v1 by Amin Adibi, Xu Cao, Zongliang Ji, Jivat Neet Kaur, Winston Chen, Elizabeth Healey, Brighton Nuwagira, Wenqian Ye, Geoffrey Woollard, Maxwell A Xu, Hejie Cui, Johnny Xi, Trenton Chang, Vasiliki Bikia, Nicole Zhang, Ayush Noori, Yuan Xia, Md. Belal Hossain, Hanna A. Frank, Alina Peluso, Yuan Pu, Shannon Zejiang Shen, John Wu, Adibvafa Fallahpour, Sazan Mahbub, Ross Duncan, Yuwei Zhang, Yurui Cao, Zuheng Xu, Michael Craig, Rahul G. Krishnan, Rahmatollah Beheshti, James M. Rehg, Mohammad Ehsanul Karim, Megan Coffee, Leo Anthony Celi, Jason Alan Fries, Mohsen Sadatsafavi, Dennis Shung, Shannon McWeeney, Jessica Dafflon, Sarah Jabbour

The fourth Machine Learning for Health (ML4H) symposium was held in person on
December 15th and 16th, 2024, in the traditional, ancestral, and unceded
territories of the Musqueam, Squamish, and Tsleil-Waututh Nations in Vancouver,
British Columbia, Canada. The symposium included research roundtable sessions
to foster discussions between participants and senior researchers on timely and
relevant topics for the ML4H community. The organization of the research
roundtables at the conference involved 13 senior and 27 junior chairs across 13
tables. Each roundtable session included an invited senior chair (with
substantial experience in the field), junior chairs (responsible for
facilitating the discussion), and attendees from diverse backgrounds with an
interest in the session's topic.

æè¦ï¼ç¬¬åå±é«çæ©å¨å­¸ç¿ (ML4H) ç è¨ææ¼ 2024 å¹´ 12 æ 15 æ¥å 16 æ¥å¨å æ¿å¤§ä¸åé¡å¥å«æ¯äºçæº«å¥è¯ç MusqueamãSquamish å Tsleil-Waututh åå®¶çå³çµ±ãç¥ååæªå²è®é åä¸èè¡ãç è¨æåæ¬ç ç©¶åæ¡æè­°ï¼ä»¥ä¿é²åèèåé«ç´ç ç©¶äººå¡ä¹ééæ¼ ML4H ç¤¾ç¾¤çåæåç¸éä¸»é¡çè¨è«ãå¨æè­°ä¸çµç¹ç ç©¶åæ¡æè­°æ¶å 13 å¼µæ¡å­ä¸ç 13 ä½é«ç´ä¸»å¸­å 27 ä½åç´ä¸»å¸­ãæ¯ååæ¡æè­°é½åæ¬ä¸ä½åéçé«ç´ä¸»å¸­ï¼å¨è©²é åææè±å¯çç¶é©ï¼ãåç´ä¸»å¸­ï¼è² è²¬ä¿é²è¨è«ï¼ä»¥åå°æè­°ä¸»é¡æèè¶£çä¾èªä¸åèæ¯çèæèã

##### **Automatic Evaluation of Healthcare LLMs Beyond Question-Answering**
2502.06666v1 by Anna Arias-Duart, Pablo Agustin Martin-Torres, Daniel Hinjos, Pablo Bernabeu-Perez, Lucia Urcelay Ganzabal, Marta Gonzalez Mallo, Ashwin Kumar Gururajan, Enrique Lopez-Cuena, Sergio Alvarez-Napagao, Dario Garcia-Gasulla

Current Large Language Models (LLMs) benchmarks are often based on open-ended
or close-ended QA evaluations, avoiding the requirement of human labor.
Close-ended measurements evaluate the factuality of responses but lack
expressiveness. Open-ended capture the model's capacity to produce discourse
responses but are harder to assess for correctness. These two approaches are
commonly used, either independently or together, though their relationship
remains poorly understood. This work is focused on the healthcare domain, where
both factuality and discourse matter greatly. It introduces a comprehensive,
multi-axis suite for healthcare LLM evaluation, exploring correlations between
open and close benchmarks and metrics. Findings include blind spots and
overlaps in current methodologies. As an updated sanity check, we release a new
medical benchmark--CareQA--, with both open and closed variants. Finally, we
propose a novel metric for open-ended evaluations --Relaxed Perplexity-- to
mitigate the identified limitations.

æè¦ï¼ç¶åå¤§åèªè¨æ¨¡å (LLM) åºæºéå¸¸åºæ¼éæ¾å¼æå°éå¼åç­è©éï¼é¿åäºäººåéæ±ãå°éå¼æ¸¬éè©ä¼°åæçäºå¯¦æ§ï¼ä½ç¼ºä¹è¡¨éåãéæ¾å¼æ¸¬éæææ¨¡åç¢çè«è¿°åæçè½åï¼ä½è¼é£è©ä¼°æ­£ç¢ºæ§ãéå©ç¨®æ¹æ³éå¸¸ç¨ç«æåä½µä½¿ç¨ï¼åç®¡å®åä¹éçéä¿ä»ç¶ç¥ä¹çå°ãéé å·¥ä½å°æ³¨æ¼é«çä¿å¥é åï¼å¨è©²é åä¸­ï¼äºå¯¦æ§åè«è¿°é½éå¸¸éè¦ãå®å¼å¥äºä¸åå¨é¢çå¤è»¸å¥ä»¶ï¼ç¨æ¼é«çä¿å¥ LLM è©éï¼æ¢ç´¢éæ¾å¼åå°éå¼åºæºåææ¨ä¹éçéè¯æ§ãç ç©¶çµæåæ¬ç¶åæ¹æ³ä¸­çç²é»åéçãä½çºæ´æ°çå¥å¨æ§æª¢æ¥ï¼æåç¼å¸äºä¸åæ°çé«çåºæº--CareQA--ï¼åå«éæ¾å¼åå°éå¼è®é«ãæå¾ï¼æåæåºäºä¸åç¨æ¼éæ¾å¼è©éçå¨æ°ææ¨--æ¾é¬å°æåº¦--ä»¥æ¸è¼å·²è­å¥çéå¶ã

##### **Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging**
2502.06632v1 by Mohammed Abdul Hafeez Khan, Samuel Morries Boddepalli, Siddhartha Bhattacharyya, Debasis Mitra

Accurate classification and anatomical localization are essential for
effective medical diagnostics and research, which may be efficiently performed
using deep learning techniques. However, availability of limited labeled data
poses a significant challenge. To address this, we adapted Prototypical
Networks and the Propagation-Reconstruction Network (PRNet) for few-shot
classification and localization, respectively, in Single Photon Emission
Computed Tomography (SPECT) images. For the proof of concept we used a
2D-sliced image cropped around heart. The Prototypical Network, with a
pre-trained ResNet-18 backbone, classified ventricles, myocardium, and liver
tissues with 96.67% training and 93.33% validation accuracy. PRNet, adapted for
2D imaging with an encoder-decoder architecture and skip connections, achieved
a training loss of 1.395, accurately reconstructing patches and capturing
spatial relationships. These results highlight the potential of Prototypical
Networks for tissue classification with limited labeled data and PRNet for
anatomical landmark localization, paving the way for improved performance in
deep learning frameworks.

æè¦ï¼ç²¾ç¢ºçåé¡åè§£åå®ä½å°æ¼ææçé«çè¨ºæ·åç ç©¶è³ééè¦ï¼èéå¯ä»¥ä½¿ç¨æ·±åº¦å­¸ç¿æè¡ææå·è¡ãç¶èï¼æ¨è¨è³ææéçåå¾æé æéå¤§çææ°ãçºäºè§£æ±ºéååé¡ï¼æååå¥èª¿æ´äºååç¶²è·¯åå³æ­éå»ºç¶²è·¯ (PRNet)ï¼ç¨æ¼å®åå­ç¼å°é»è¦æ·å±¤ææ (SPECT) å½±åä¸­çå°éåé¡åå®ä½ãçºäºè­æéåæ¦å¿µï¼æåä½¿ç¨åç¹å¿èè£åç 2D åçå½±åãååç¶²è·¯ï¼ä½¿ç¨é åè¨ç·´ç ResNet-18 ä¸»å¹¹ï¼å°å¿å®¤ãå¿èåèèçµç¹é²è¡åé¡ï¼è¨ç·´æºç¢ºåº¦çº 96.67%ï¼é©è­æºç¢ºåº¦çº 93.33%ãPRNetï¼èª¿æ´çºä½¿ç¨ç·¨ç¢¼å¨è§£ç¢¼å¨æ¶æ§åè·³èºé£æ¥ç 2D å½±åï¼éå°äº 1.395 çè¨ç·´æå¤±ï¼ç²¾ç¢ºå°éå»ºäºåå¡ä¸¦æ·åäºç©ºééä¿ãéäºçµæçªåºäºååç¶²è·¯å¨æ¨è¨è³ææéçææ³ä¸é²è¡çµç¹åé¡çæ½åï¼ä»¥å PRNet å¨è§£åæ¨èªå®ä½æ¹é¢çæ½åï¼çºæ·±åº¦å­¸ç¿æ¶æ§ä¸­æè½çæåéªå¹³äºéè·¯ã

##### **Illegal Waste Detection in Remote Sensing Images: A Case Study**
2502.06607v2 by Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca Morandini, Andrea Diecidue, Simona Malegori

Environmental crime currently represents the third largest criminal activity
worldwide while threatening ecosystems as well as human health. Among the
crimes related to this activity, improper waste management can nowadays be
countered more easily thanks to the increasing availability and decreasing cost
of Very-High-Resolution Remote Sensing images, which enable semi-automatic
territory scanning in search of illegal landfills. This paper proposes a
pipeline, developed in collaboration with professionals from a local
environmental agency, for detecting candidate illegal dumping sites leveraging
a classifier of Remote Sensing images. To identify the best configuration for
such classifier, an extensive set of experiments was conducted and the impact
of diverse image characteristics and training settings was thoroughly analyzed.
The local environmental agency was then involved in an experimental exercise
where outputs from the developed classifier were integrated in the experts'
everyday work, resulting in time savings with respect to manual
photo-interpretation. The classifier was eventually run with valuable results
on a location outside of the training area, highlighting potential for
cross-border applicability of the proposed pipeline.

æè¦ï¼ç°å¢ç¯ç½ªç®åæ¯å¨çç¬¬ä¸å¤§ç¯ç½ªæ´»åï¼å¨èçæç³»çµ±åäººé¡å¥åº·ãå¨èæ­¤æ´»åç¸éçç¯ç½ªä¸­ï¼ä¸ç¶å»¢ç©ç®¡çç¾å¨å¯ä»¥æ´å®¹æå°å¾å°è§£æ±ºï¼éè¦æ­¸åæ¼è¶é«è§£æåº¦éæ¸¬å½±åè¶ä¾è¶æ®åä¸ææ¬ä¸éï¼éä½¿å¾åèªåé åææè½å¤ æå°éæ³åå¾æ©åå ´ãæ¬ææåºäºä¸æ¢ç®¡éï¼èç¶å°ç°å¢æ©æ§çå°æ¥­äººå£«åä½éç¼ï¼ç¨æ¼æª¢æ¸¬åé¸éæ³å¾åå°é»ï¼å©ç¨éæ¸¬å½±ååé¡å¨ãçºäºæ¾åºéç¨®åé¡å¨çæä½³éç½®ï¼é²è¡äºä¸ç³»åå»£æ³çå¯¦é©ï¼ä¸¦å¾¹åºåæäºä¸åå½±åç¹å¾µåè¨ç·´è¨­å®çå½±é¿ãç¶å¾ï¼ç¶å°ç°å¢æ©æ§åèäºä¸é å¯¦é©ç·´ç¿ï¼å¶ä¸­å°å·²éç¼åé¡å¨çè¼¸åºæ´åå°å°å®¶çæ¥å¸¸å·¥ä½ä¸­ï¼å¾èç¯çäºäººå·¥ç§çè§£è­¯çæéãæå¾å¨è¨ç·´ååå¤çæåä½ç½®å·è¡åé¡å¨ï¼ç²å¾äºæå¹å¼ççµæï¼çªåºäºææåºç®¡éçè·¨å¢é©ç¨æ§æ½åã

##### **FEMBA: Efficient and Scalable EEG Analysis with a Bidirectional Mamba Foundation Model**
2502.06438v1 by Anna Tegon, Thorir Mar Ingolfsson, Xiaying Wang, Luca Benini, Yawei Li

Accurate and efficient electroencephalography (EEG) analysis is essential for
detecting seizures and artifacts in long-term monitoring, with applications
spanning hospital diagnostics to wearable health devices. Robust EEG analytics
have the potential to greatly improve patient care. However, traditional deep
learning models, especially Transformer-based architectures, are hindered by
their quadratic time and memory complexity, making them less suitable for
resource-constrained environments. To address these challenges, we present
FEMBA (Foundational EEG Mamba + Bidirectional Architecture), a novel
self-supervised framework that establishes new efficiency benchmarks for EEG
analysis through bidirectional state-space modeling. Unlike Transformer-based
models, which incur quadratic time and memory complexity, FEMBA scales linearly
with sequence length, enabling more scalable and efficient processing of
extended EEG recordings. Trained on over 21,000 hours of unlabeled EEG and
fine-tuned on three downstream tasks, FEMBA achieves competitive performance in
comparison with transformer models, with significantly lower computational
cost. Specifically, it reaches 81.82% balanced accuracy (0.8921 AUROC) on TUAB
and 0.949 AUROC on TUAR, while a tiny 7.8M-parameter variant demonstrates
viability for resource-constrained devices. These results pave the way for
scalable, general-purpose EEG analytics in both clinical and highlight FEMBA as
a promising candidate for wearable applications.

æè¦ï¼æºç¢ºä¸ææçè¦é»å (EEG) åæå°æ¼åµæ¸¬é·æéç£æ§ä¸­çç²çç¼ä½åå½åè³ééè¦ï¼å¶æç¨ç¯åæ¶µèé«é¢è¨ºæ·å°å¯ç©¿æ´å¼å¥åº·è£ç½®ãç©©å¥ç EEG åæå·æå¤§å¹æ¹åçæ£ç§è­·çæ½åãç¶èï¼å³çµ±æ·±åº¦å­¸ç¿æ¨¡åï¼ç¹å¥æ¯åºæ¼ Transformer çæ¶æ§ï¼åå°å¶äºæ¬¡æéåè¨æ¶é«è¤éåº¦çé»ç¤ï¼ä½¿å¶ä¸å¤ªé©åè³æºåéçç°å¢ãçºäºæå°éäºææ°ï¼æåæåº FEMBA (åºç¤ EEG Mamba + éåæ¶æ§)ï¼ä¸ç¨®åµæ°çèªæç£ç£æ¶æ§ï¼éééåçæç©ºéå»ºæ¨¡çº EEG åæå»ºç«æ°çæçåºæºãèæç¢çäºæ¬¡æéåè¨æ¶é«è¤éåº¦çåºæ¼ Transformer çæ¨¡åä¸åï¼FEMBA é¨èåºåé·åº¦ç·æ§ç¸®æ¾ï¼æ¯æ´æ´å·å¯æ´åæ§åæççå»¶ä¼¸ EEG è¨éèçãFEMBA å¨è¶é 21,000 å°æçæªæ¨è¨ EEG ä¸è¨ç·´ä¸¦å¨ä¸åä¸æ¸¸ä»»åä¸é²è¡å¾®èª¿ï¼èTransformeræ¨¡åç¸æ¯ï¼å¨è¨ç®ææ¬é¡¯èéä½çææ³ä¸ï¼å¯¦ç¾äºå·æç«¶ç­åçæè½ãå·é«ä¾èªªï¼å®å¨ TUAB ä¸éå° 81.82% çå¹³è¡¡æºç¢ºåº¦ (0.8921 AUROC) åå¨ TUAR ä¸éå° 0.949 AUROCï¼èä¸åå¾®å°ç 7.8M åæ¸è®é«è­æäºå¶å¨è³æºåéè£ç½®ä¸çå¯è¡æ§ãéäºçµæçºè¨åºåå¯ç©¿æ´æç¨ä¸­å¯æ´åçéç¨ EEG åæéªå¹³äºéè·¯ï¼ä¸¦çªé¡¯ FEMBA æ¯å¯ç©¿æ´æç¨ä¸­ä¸åæåæ¯çåé¸èã

##### **Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?**
2502.06289v1 by Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh, Ke Zou, Samantha Min Er Yew, Sahana Srinivasan, Meng Wang, Thaddaeus Lo, Xiaofeng Lei, Siegfried K. Wagner, Mark A. Chia, Dawei Yang, Hongyang Jiang, AnRan Ran, Rui Santos, Gabor Mark Somfai, Juan Helen Zhou, Haoyu Chen, Qingyu Chen, Carol Yim-Lui Cheung, Pearse A. Keane, Yih Chung Tham

The advent of foundation models (FMs) is transforming medical domain. In
ophthalmology, RETFound, a retina-specific FM pre-trained sequentially on 1.4
million natural images and 1.6 million retinal images, has demonstrated high
adaptability across clinical applications. Conversely, DINOv2, a
general-purpose vision FM pre-trained on 142 million natural images, has shown
promise in non-medical domains. However, its applicability to clinical tasks
remains underexplored. To address this, we conducted head-to-head evaluations
by fine-tuning RETFound and three DINOv2 models (large, base, small) for ocular
disease detection and systemic disease prediction tasks, across eight
standardized open-source ocular datasets, as well as the Moorfields AlzEye and
the UK Biobank datasets. DINOv2-large model outperformed RETFound in detecting
diabetic retinopathy (AUROC=0.850-0.952 vs 0.823-0.944, across three datasets,
all P<=0.007) and multi-class eye diseases (AUROC=0.892 vs. 0.846, P<0.001). In
glaucoma, DINOv2-base model outperformed RETFound (AUROC=0.958 vs 0.940,
P<0.001). Conversely, RETFound achieved superior performance over all DINOv2
models in predicting heart failure, myocardial infarction, and ischaemic stroke
(AUROC=0.732-0.796 vs 0.663-0.771, all P<0.001). These trends persisted even
with 10% of the fine-tuning data. These findings showcase the distinct
scenarios where general-purpose and domain-specific FMs excel, highlighting the
importance of aligning FM selection with task-specific requirements to optimise
clinical performance.

æè¦ï¼åºç¤æ¨¡å (FM) çåºç¾æ­£å¨è½è®é«çé åãå¨ç¼ç§ï¼RETFound æ¯ä¸åè¦ç¶²èå°ç¨ FMï¼ä¾åºä½¿ç¨ 140 è¬å¼µèªç¶å½±åå 160 è¬å¼µè¦ç¶²èå½±åé²è¡é è¨ç·´ï¼å·²å±ç¾åºé«åº¦é©ææ§ï¼å¯æç¨æ¼åç¨®è¨åºæç¨ãç¸åå°ï¼DINOv2 æ¯ä¸åéç¨è¦è¦º FMï¼ä½¿ç¨ 1.42 åå¼µèªç¶å½±åé²è¡é è¨ç·´ï¼å·²å±ç¾åºå¨éé«çé åçæ½åãç¶èï¼å¶å¨è¨åºä»»åä¸­çé©ç¨æ§ä»æªè¢«ååæ¢ç´¢ãçºäºè§£æ±ºéååé¡ï¼æåéå°ç¼é¨ç¾çåµæ¸¬åå¨èº«æ§ç¾çé æ¸¬ä»»åï¼å° RETFound åä¸å DINOv2 æ¨¡åï¼å¤§åãåºç¤ãå°åï¼é²è¡å¾®èª¿ï¼ä¸¦é²è¡ä¸å°ä¸çè©ä¼°ï¼ä½¿ç¨å«åæ¨æºåçéæºç¼ç§è³æéï¼ä»¥å Moorfields AlzEye å UK Biobank è³æéãDINOv2 å¤§åæ¨¡åå¨ç³å°¿çè¦ç¶²èçè®åµæ¸¬æ¹é¢åªæ¼ RETFoundï¼ä¸åè³æéç AUROC=0.850-0.952ï¼ç¸è¼æ¼ 0.823-0.944ï¼ææ P<=0.007ï¼åå¤é¡ç¼é¨ç¾çï¼AUROC=0.892ï¼ç¸è¼æ¼ 0.846ï¼P<0.001ï¼ãå¨éåç¼æ¹é¢ï¼DINOv2 åºç¤æ¨¡ååªæ¼ RETFoundï¼AUROC=0.958ï¼ç¸è¼æ¼ 0.940ï¼P<0.001ï¼ãç¸åå°ï¼RETFound å¨é æ¸¬å¿èè¡°ç«­ãå¿èæ¢å¡åç¼ºè¡æ§ä¸­é¢¨æ¹é¢åªæ¼ææ DINOv2 æ¨¡åï¼AUROC=0.732-0.796ï¼ç¸è¼æ¼ 0.663-0.771ï¼ææ P<0.001ï¼ãå³ä½¿ä½¿ç¨ 10% çå¾®èª¿è³æï¼éäºè¶¨å¢ä»ç¶æçºãéäºç¼ç¾å±ç¤ºäºéç¨åé åå°ç¨ FM åèªæé·çå ´æ¯ï¼çªé¡¯äºæ ¹æä»»åç¹å®éæ±èª¿æ´ FM é¸æï¼ä»¥æä½³åè¨åºè¡¨ç¾çéè¦æ§ã

##### **Integrating Sequence and Image Modeling in Irregular Medical Time Series Through Self-Supervised Learning**
2502.06134v1 by Liuqing Chen, Shuhong Xiao, Shixian Ding, Shanhai Hu, Lingyun Sun

Medical time series are often irregular and face significant missingness,
posing challenges for data analysis and clinical decision-making. Existing
methods typically adopt a single modeling perspective, either treating series
data as sequences or transforming them into image representations for further
classification. In this paper, we propose a joint learning framework that
incorporates both sequence and image representations. We also design three
self-supervised learning strategies to facilitate the fusion of sequence and
image representations, capturing a more generalizable joint representation. The
results indicate that our approach outperforms seven other state-of-the-art
models in three representative real-world clinical datasets. We further
validate our approach by simulating two major types of real-world missingness
through leave-sensors-out and leave-samples-out techniques. The results
demonstrate that our approach is more robust and significantly surpasses other
baselines in terms of classification performance.

æè¦ï¼é«çæéåºåéå¸¸ä¸è¦åä¸æé¢è¨é¡¯èçç¼ºå¤±ï¼å°è³æåæåè¨åºæ±ºç­å¶å®æ§æææ°ãç¾ææ¹æ³éå¸¸æ¡ç¨å®ä¸å»ºæ¨¡è§é»ï¼å°åºåè³æè¦çºåºåæå°å¶è½æçºå½±åè¡¨ç¤ºä»¥é²è¡é²ä¸æ­¥åé¡ãå¨æ¬æä¸­ï¼æåæåºäºä¸åè¯åå­¸ç¿æ¶æ§ï¼çµååºååå½±åè¡¨ç¤ºãæåéè¨­è¨äºä¸ç¨®èªæç£ç£å­¸ç¿ç­ç¥ï¼ä»¥ä¿é²åºååå½±åè¡¨ç¤ºçèåï¼æææ´å·æ¦æ¬æ§çè¯åè¡¨ç¤ºãçµæè¡¨æï¼æåçåæ³å¨ä¸åå·æä»£è¡¨æ§ççå¯¦ä¸çè¨åºè³æéä¸­åªæ¼å¶ä»ä¸åæåé²çæ¨¡åãæåé²ä¸æ­¥ééçåºææ¸¬å¨åçåºæ¨£æ¬çæè¡æ¨¡æ¬å©ç¨®ä¸»è¦ççå¯¦ä¸çç¼ºå¤±é¡åä¾é©è­æåçåæ³ãçµæè¡¨æï¼æåçåæ³æ´å¼·å¤§ï¼ä¸¦ä¸å¨åé¡æè½æ¹é¢é¡¯èåªæ¼å¶ä»åºæºã

##### **Foundation Model of Electronic Medical Records for Adaptive Risk Estimation**
2502.06124v1 by Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek

We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS),
an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS
predicts future PHTs using transformer-based architectures. The Adaptive Risk
Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk
probabilities for clinician-defined critical events. ARES incorporates a
personalized explainability module that identifies key clinical factors
influencing risk estimates for individual patients. ARES was evaluated on the
MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its
performance against traditional early warning systems and machine learning
models. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs,
with 60% including hospital admissions. The dataset contained over 357 million
tokens. ETHOS outperformed benchmark models in predicting hospital admissions,
ICU admissions, and prolonged hospital stays, achieving superior AUC scores.
ETHOS-based risk estimates demonstrated robustness across demographic subgroups
with strong model reliability, confirmed via calibration curves. The
personalized explainability module provides insights into patient-specific
factors contributing to risk. ARES, powered by ETHOS, advances predictive
healthcare AI by providing dynamic, real-time, and personalized risk estimation
with patient-specific explainability to enhance clinician trust. Its
adaptability and superior accuracy position it as a transformative tool for
clinical decision-making, potentially improving patient outcomes and resource
allocation in emergency and inpatient settings. We release the full code at
github.com/ipolharvard/ethos-ares to facilitate future research.

æè¦ï¼æåéç¼äºå¢å¼·åå¥åº·çµææ¨¡æ¬è½æå¨ (ETHOS)ï¼
ä¸ç¨®å¾é»å­å¥åº·ç´é (EHR) ä¸­å°æ£èå¥åº·æéè»¸ (PHT) æ¨è¨åç AI æ¨¡åãETHOS
ä½¿ç¨åºæ¼è½æå¨çæ¶æ§é æ¸¬æªä¾ç PHTãèªé©æé¢¨éªè©ä¼°ç³»çµ± (ARES) ä½¿ç¨ ETHOS è¨ç®ç±è¨åºé«çå®ç¾©çå±æ¥äºä»¶çåæä¸åäººåçé¢¨éªæ©çãARES çµåäºåäººåçå¯è§£éæ§æ¨¡çµï¼å¯æ¾åºå½±é¿åå¥æ£èé¢¨éªè©ä¼°çä¸»è¦è¨åºå ç´ ãARES å¨æ¥è¨ºé¨é (ED) è¨­å®ä¸­éå° MIMIC-IV v2.2 è³æéé²è¡è©ä¼°ï¼ä¸¦å°å¶æè½èå³çµ±çé è­¦ç³»çµ±åæ©å¨å­¸ç¿æ¨¡åé²è¡åºæºæ¸¬è©¦ãæåå° 299,721 ä½ MIMIC-IV çç¨ç¹æ£èèçæ 285,622 å PHTï¼å¶ä¸­ 60% åå«ä½é¢è¨éãè©²è³æéåå«è¶é 3.57 ååæ¨è¨ãETHOS å¨é æ¸¬ä½é¢ãå è­·çæ¿ (ICU) ä½é¢åå»¶é·ä½é¢æéæ¹é¢è¡¨ç¾åªæ¼åºæºæ¨¡åï¼ä¸¦ç²å¾äºè¼é«ç AUC åæ¸ãåºæ¼ ETHOS çé¢¨éªè©ä¼°é¡¯ç¤ºåºè·¨äººå£çµ±è¨å­ç¾¤çç©©å¥æ§ï¼ä¸¦ééæ ¡æºæ²ç·ç¢ºèªäºå¼·å¤§çæ¨¡åå¯é æ§ãåäººåçå¯è§£éæ§æ¨¡çµæä¾äºå°å°è´é¢¨éªçæ£èç¹å®å ç´ çè¦è§£ãç± ETHOS é©åç ARES ééæä¾åæãå³æä¸åäººåçé¢¨éªè©ä¼°ï¼ä»¥åæ£èç¹å®çå¯è§£éæ§ä¾å¢å¼·è¨åºé«ççä¿¡ä»»ï¼å¾èæ¨åäºé æ¸¬æ§é«çä¿å¥ AI çç¼å±ãå¶é©ææ§ååè¶çæºç¢ºæ§ä½¿å¶æçºè¨åºæ±ºç­å¶å®çä¸ç¨®è®é©æ§å·¥å·ï¼æå¯è½æ¹åç·æ¥åä½é¢ç°å¢ä¸­çæ£èçµæåè³æºåéãæåå¨ github.com/ipolharvard/ethos-ares ä¸éåºå®æ´ç¨å¼ç¢¼ï¼ä»¥å©æªä¾çç ç©¶ã

##### **Can ChatGPT Diagnose Alzheimer's Disease?**
2502.06907v1 by Quoc-Toan Nguyen, Linh Le, Xuan-The Tran, Thomas Do, Chin-Teng Lin

Can ChatGPT diagnose Alzheimer's Disease (AD)? AD is a devastating
neurodegenerative condition that affects approximately 1 in 9 individuals aged
65 and older, profoundly impairing memory and cognitive function. This paper
utilises 9300 electronic health records (EHRs) with data from Magnetic
Resonance Imaging (MRI) and cognitive tests to address an intriguing question:
As a general-purpose task solver, can ChatGPT accurately detect AD using EHRs?
We present an in-depth evaluation of ChatGPT using a black-box approach with
zero-shot and multi-shot methods. This study unlocks ChatGPT's capability to
analyse MRI and cognitive test results, as well as its potential as a
diagnostic tool for AD. By automating aspects of the diagnostic process, this
research opens a transformative approach for the healthcare system,
particularly in addressing disparities in resource-limited regions where AD
specialists are scarce. Hence, it offers a foundation for a promising method
for early detection, supporting individuals with timely interventions, which is
paramount for Quality of Life (QoL).

æè¦ï¼ChatGPT è½å¦è¨ºæ·åºé¿è²æµ·é»ç (AD)ï¼AD æ¯ä¸ç¨®æ¯æ»æ§çç¥ç¶éåæ§ç¾çï¼å½±é¿ç´ 1/9 ç 65 æ­²åä»¥ä¸äººå£«ï¼å´éæå®³è¨æ¶ååèªç¥åè½ãéç¯è«æå©ç¨äº 9300 ä»½é»å­å¥åº·ç´é (EHR)ï¼å¶ä¸­åå«ç£å±æ¯æå (MRI) åèªç¥æ¸¬è©¦çæ¸æï¼ä¾è§£æ±ºä¸åæè¶£çåé¡ï¼ä½çºä¸åéç¨ä»»åè§£æ±ºå¨ï¼ChatGPT è½å¦ä½¿ç¨ EHR æºç¢ºå°æª¢æ¸¬åº ADï¼æåä½¿ç¨é»çæ¹æ³å° ChatGPT é²è¡äºæ·±å¥è©ä¼°ï¼æ¡ç¨é¶æ¬¡åè©¦åå¤æ¬¡åè©¦çæ¹æ³ãéé ç ç©¶æ­ç¤ºäº ChatGPT åæ MRI åèªç¥æ¸¬è©¦çµæçè½åï¼ä»¥åå¶ä½çº AD è¨ºæ·å·¥å·çæ½åãééèªååè¨ºæ·éç¨çååæ¹é¢ï¼éé ç ç©¶çºé«çä¿å¥ç³»çµ±éåäºä¸ç¨®è®é©æ§çæ¹æ³ï¼ç¹å¥æ¯å¨è§£æ±ºè³æºæéçå°åä¸­ AD å°å®¶ç¨ç¼ºçä¸å¹³ç­åé¡æ¹é¢ãå æ­¤ï¼å®çºä¸ç¨®æå¸æçæ©ææª¢æ¸¬æ¹æ³å¥ å®äºåºç¤ï¼ééåæå¹²é ä¾æ¯æåäººï¼éå°æ¼çæ´»åè³ª (QoL) è³ééè¦ã

##### **Protecting Intellectual Property of EEG-based Neural Networks with Watermarking**
2502.05931v1 by Ahmed Abdelaziz, Ahmed Fathi, Ahmed Fares

EEG-based neural networks, pivotal in medical diagnosis and brain-computer
interfaces, face significant intellectual property (IP) risks due to their
reliance on sensitive neurophysiological data and resource-intensive
development. Current watermarking methods, particularly those using abstract
trigger sets, lack robust authentication and fail to address the unique
challenges of EEG models. This paper introduces a cryptographic wonder
filter-based watermarking framework tailored for EEG-based neural networks.
Leveraging collision-resistant hashing and public-key encryption, the wonder
filter embeds the watermark during training, ensuring minimal distortion ($\leq
5\%$ drop in EEG task accuracy) and high reliability (100\% watermark
detection). The framework is rigorously evaluated against adversarial attacks,
including fine-tuning, transfer learning, and neuron pruning. Results
demonstrate persistent watermark retention, with classification accuracy for
watermarked states remaining above 90\% even after aggressive pruning, while
primary task performance degrades faster, deterring removal attempts. Piracy
resistance is validated by the inability to embed secondary watermarks without
severe accuracy loss ( $>10\%$ in EEGNet and CCNN models). Cryptographic
hashing ensures authentication, reducing brute-force attack success
probabilities. Evaluated on the DEAP dataset across models (CCNN, EEGNet,
TSception), the method achieves $>99.4\%$ null-embedding accuracy, effectively
eliminating false positives. By integrating wonder filters with EEG-specific
adaptations, this work bridges a critical gap in IP protection for
neurophysiological models, offering a secure, tamper-proof solution for
healthcare and biometric applications. The framework's robustness against
adversarial modifications underscores its potential to safeguard sensitive EEG
models while maintaining diagnostic utility.

æè¦ï¼<paragraph>åºæ¼ EEG çç¥ç¶ç¶²è·¯å¨é«å­¸è¨ºæ·åè¦é»è¦ä»é¢ä¸­è³ééè¦ï¼ç±æ¼å¶ä¾è³´ææçç¥ç¶ççè³æåè³æºå¯éåçéç¼ï¼é¢è¨éå¤§çæºæ§è²¡ç¢æ¬ (IP) é¢¨éªãç®åçæµ®æ°´å°æ¹æ³ï¼ç¹å¥æ¯é£äºä½¿ç¨æ½è±¡è§¸ç¼éçæ¹æ³ï¼ç¼ºä¹å¼·å¥çé©è­ï¼ä¸ç¡æ³è§£æ±º EEG æ¨¡åçç¨ç¹ææ°ãæ¬æä»ç´¹äºä¸åå°çºåºæ¼ EEG çç¥ç¶ç¶²è·¯éèº«æé çå¯ç¢¼å­¸ wonder æ¿¾æ³¢å¨æµ®æ°´å°æ¶æ§ãå©ç¨æç¢°æéæ¹åå¬ééé°å å¯ï¼wonder æ¿¾æ³¢å¨å¨è¨ç·´æéåµå¥æµ®æ°´å°ï¼ç¢ºä¿æå°çå¤±çï¼EEG ä»»åæºç¢ºåº¦ä¸é $\leq 5\%$ï¼åé«å¯é æ§ï¼100% æµ®æ°´å°æª¢æ¸¬ï¼ãè©²æ¶æ§éå°å°ææ§æ»æé²è¡äºå´æ ¼çè©ä¼°ï¼åæ¬å¾®èª¿ãé·ç§»å­¸ç¿åç¥ç¶ååªæãçµæè­æäºæçºçæµ®æ°´å°ä¿çï¼å³ä½¿å¨æ¿é²çåªæå¾ï¼æµ®æ°´å°çæçåé¡æºç¢ºåº¦ä»ä¿æå¨ 90% ä»¥ä¸ï¼èä¸»è¦ä»»åçæ§è½ä¸éå¾æ´å¿«ï¼é»æ­¢äºç§»é¤åè©¦ãççæµæåééç¡æ³åµå¥æ¬¡è¦æµ®æ°´å°èå¾å°é©è­ï¼èä¸æé æå´éçæºç¢ºåº¦æå¤±ï¼å¨ EEGNet å CCNN æ¨¡åä¸­ $>10\%$ï¼ãå¯ç¢¼å­¸éæ¹ç¢ºä¿é©è­ï¼éä½äºæ´åæ»ææåæ©çãå¨ DEAP è³æéä¸éå°æ¨¡åï¼CCNNãEEGNetãTSceptionï¼é²è¡è©ä¼°ï¼è©²æ¹æ³éå°äº $>99.4\%$ çç©ºåµå¥æºç¢ºåº¦ï¼ææå°æ¶é¤äºåé½æ§ãééå° wonder æ¿¾æ³¢å¨è EEG ç¹å®çé©æç¸æ´åï¼éé å·¥ä½å½è£äºç¥ç¶ççæ¨¡å IP ä¿è­·ä¸­çééµå·®è·ï¼çºé«çä¿å¥åçç©ç¹å¾µæç¨æä¾äºä¸åå®å¨ãé²ç¯¡æ¹çè§£æ±ºæ¹æ¡ãè©²æ¶æ§å°ææµå°ä¿®æ¹çå¼·å¥æ§çªé¡¯äºå¶å¨ç¶­è­·è¨ºæ·æç¨çåæä¿è­·ææ EEG æ¨¡åçæ½åã</paragraph>

##### **Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models**
2502.05879v1 by Shiyu Teng, Jiaqing Liu, Rahul Kumar Jain, Shurong Chai, Ruibo Hou, Tomoko Tateyama, Lanfen Lin, Yen-wei Chen

Depression is one of the leading causes of disability worldwide, posing a
severe burden on individuals, healthcare systems, and society at large. Recent
advancements in Large Language Models (LLMs) have shown promise in addressing
mental health challenges, including the detection of depression through
text-based analysis. However, current LLM-based methods often struggle with
nuanced symptom identification and lack a transparent, step-by-step reasoning
process, making it difficult to accurately classify and explain mental health
conditions. To address these challenges, we propose a Chain-of-Thought
Prompting approach that enhances both the performance and interpretability of
LLM-based depression detection. Our method breaks down the detection process
into four stages: (1) sentiment analysis, (2) binary depression classification,
(3) identification of underlying causes, and (4) assessment of severity. By
guiding the model through these structured reasoning steps, we improve
interpretability and reduce the risk of overlooking subtle clinical indicators.
We validate our method on the E-DAIC dataset, where we test multiple
state-of-the-art large language models. Experimental results indicate that our
Chain-of-Thought Prompting technique yields superior performance in both
classification accuracy and the granularity of diagnostic insights, compared to
baseline approaches.

æè¦ï¼æé¬±çæ¯å¨çæ®éçä¸»è¦åå ä¹ä¸ï¼å°åäººãé«çä¿å¥ç³»çµ±åæ´åç¤¾æé æå´éè² æãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å·²å±ç¾åºè§£æ±ºå¿çå¥åº·ææ°çå¸æï¼åæ¬ééåºæ¼æå­çåæä¾åµæ¸¬æé¬±çãç¶èï¼ç¾æçåºæ¼ LLM çæ¹æ³éå¸¸é£ä»¥è¾¨è­ç´°å¾®çççï¼èä¸ç¼ºä¹éæä¸éæ­¥çæ¨çéç¨ï¼éä½¿å¾æºç¢ºåé¡åè§£éå¿çå¥åº·çæ³è®å¾å°é£ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æèéæç¤ºæ¹æ³ï¼å®å¢å¼·äºåºæ¼ LLM çæé¬±çåµæ¸¬çæè½åå¯è§£éæ§ãæåçéé æ¹æ³å°åµæ¸¬éç¨åè§£çºååéæ®µï¼(1) æç·åæï¼(2) äºåæé¬±çåé¡ï¼(3) æ¾åºæ½å¨åå ï¼ä»¥å (4) è©ä¼°å´éç¨åº¦ãééå¼å°æ¨¡åå®æéäºçµæ§åçæ¨çæ­¥é©ï¼æåæåäºå¯è§£éæ§ï¼ä¸¦éä½äºå¿½ç¥ç´°å¾®è¨åºææ¨çé¢¨éªãæåå¨ E-DAIC è³æéä¸é©è­äºæåçéé æ¹æ³ï¼ä¸¦å¨å¶ä¸­æ¸¬è©¦äºå¤ç¨®æåé²çå¤§åèªè¨æ¨¡åãå¯¦é©çµæé¡¯ç¤ºï¼èåºç·æ¹æ³ç¸æ¯ï¼æåçæèéæç¤ºæè¡å¨åé¡æºç¢ºåº¦åè¨ºæ·è¦è§£çç²¾ç´°åº¦æ¹é¢é½è¡¨ç¾åºåªç°çæè½ã

##### **LLMs for Drug-Drug Interaction Prediction: A Comprehensive Comparison**
2502.06890v1 by Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis

The increasing volume of drug combinations in modern therapeutic regimens
needs reliable methods for predicting drug-drug interactions (DDIs). While
Large Language Models (LLMs) have revolutionized various domains, their
potential in pharmaceutical research, particularly in DDI prediction, remains
largely unexplored. This study thoroughly investigates LLMs' capabilities in
predicting DDIs by uniquely processing molecular structures (SMILES), target
organisms, and gene interaction data as raw text input from the latest DrugBank
dataset. We evaluated 18 different LLMs, including proprietary models (GPT-4,
Claude, Gemini) and open-source variants (from 1.5B to 72B parameters), first
assessing their zero-shot capabilities in DDI prediction. We then fine-tuned
selected models (GPT-4, Phi-3.5 2.7B, Qwen-2.5 3B, Gemma-2 9B, and Deepseek R1
distilled Qwen 1.5B) to optimize their performance. Our comprehensive
evaluation framework included validation across 13 external DDI datasets,
comparing against traditional approaches such as l2-regularized logistic
regression. Fine-tuned LLMs demonstrated superior performance, with Phi-3.5
2.7B achieving a sensitivity of 0.978 in DDI prediction, with an accuracy of
0.919 on balanced datasets (50% positive, 50% negative cases). This result
represents an improvement over both zero-shot predictions and state-of-the-art
machine-learning methods used for DDI prediction. Our analysis reveals that
LLMs can effectively capture complex molecular interaction patterns and cases
where drug pairs target common genes, making them valuable tools for practical
applications in pharmaceutical research and clinical settings.

æè¦ï¼<paragraph>ç¾ä»£æ²»çæ¹æ¡ä¸­è¥ç©çµåçæ¸éè¶ä¾è¶å¤ï¼éè¦å¯é çæ¹æ³ä¾é æ¸¬è¥ç©éäº¤äºä½ç¨ (DDI)ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å·²å¨ååé åæèµ·é©å½ï¼å®åå¨è¥ç©ç ç©¶ä¸­çæ½åï¼ç¹å¥æ¯å¨ DDI é æ¸¬ä¸­çæ½åï¼ä»æªå¾å°ååæ¢ç´¢ãæ¬ç ç©¶ééç¨ç¹å°èçåå­çµæ§ (SMILES)ãç®æ¨çç©ååºå äº¤äºè³æä½çºä¾èªææ° DrugBank è³æéçåå§æå­è¼¸å¥ï¼å¾¹åºèª¿æ¥äº LLM å¨é æ¸¬ DDI ä¸­çè½åãæåè©ä¼°äº 18 ç¨®ä¸åç LLMï¼åæ¬å°ææ¨¡åï¼GPT-4ãClaudeãGeminiï¼åéæºè®é«ï¼å¾ 1.5B å° 72B åæ¸ï¼ï¼é¦åè©ä¼°å®åå¨ DDI é æ¸¬ä¸­çé¶æ¬¡å­¸ç¿è½åãç¶å¾ï¼æåå¾®èª¿é¸å®çæ¨¡åï¼GPT-4ãPhi-3.5 2.7BãQwen-2.5 3BãGemma-2 9B å Deepseek R1 è¸é¤¾ Qwen 1.5Bï¼ä»¥æä½³åå¶æè½ãæåçå¨é¢è©ä¼°æ¡æ¶åæ¬è·¨ 13 åå¤é¨ DDI è³æéé²è¡é©è­ï¼ä¸¦èå³çµ±æ¹æ³ï¼ä¾å¦ l2 æ­£ååéè¼¯è¿´æ­¸ï¼é²è¡æ¯è¼ãå¾®èª¿å¾ç LLM è¡¨ç¾åºåªç°çæè½ï¼å¶ä¸­ Phi-3.5 2.7B å¨ DDI é æ¸¬ä¸­éå° 0.978 çéæåº¦ï¼å¨å¹³è¡¡è³æéï¼50% æ­£ä¾ï¼50% åä¾ï¼ä¸çæºç¢ºåº¦çº 0.919ãæ­¤çµæåªæ¼é¶æ¬¡å­¸ç¿é æ¸¬åç¨æ¼ DDI é æ¸¬çææ°æ©å¨å­¸ç¿æ¹æ³ãæåçåæè¡¨æï¼LLM å¯ä»¥ææææè¤éçåå­äº¤äºæ¨¡å¼åè¥ç©å°é¶åå±ååºå çææ³ï¼ä½¿å¶æçºè¥ç©ç ç©¶åè¨åºç°å¢ä¸­å¯¦ç¨æç¨çå¯¶è²´å·¥å·ã</paragraph>

##### **Decoding Complexity: Intelligent Pattern Exploration with CHPDA (Context Aware Hybrid Pattern Detection Algorithm)**
2502.07815v1 by Lokesh Koli, Shubham Kalra, Karanpreet Singh

Detecting sensitive data such as Personally Identifiable Information (PII)
and Protected Health Information (PHI) is critical for data security platforms.
This study evaluates regex-based pattern matching algorithms and exact-match
search techniques to optimize detection speed, accuracy, and scalability. Our
benchmarking results indicate that Google RE2 provides the best balance of
speed (10-15 ms/MB), memory efficiency (8-16 MB), and accuracy (99.5%) among
regex engines, outperforming PCRE while maintaining broader hardware
compatibility than Hyperscan. For exact matching, Aho-Corasick demonstrated
superior performance (8 ms/MB) and scalability for large datasets. Performance
analysis revealed that regex processing time scales linearly with dataset size
and pattern complexity. A hybrid AI + Regex approach achieved the highest F1
score (91. 6%) by improving recall and minimizing false positives. Device
benchmarking confirmed that our solution maintains efficient CPU and memory
usage on both high-performance and mid-range systems. Despite its
effectiveness, challenges remain, such as limited multilingual support and the
need for regular pattern updates. Future work should focus on expanding
language coverage, integrating data security and privacy management (DSPM) with
data loss prevention (DLP) tools, and enhancing regulatory compliance for
broader global adoption.

æè¦ï¼åµæ¸¬åäººèº«åè³è¨ (PII) ååä¿è­·å¥åº·è³è¨ (PHI) ç­ææè³æï¼å°æ¼è³æå®å¨å¹³å°è³ééè¦ãæ¬ç ç©¶è©ä¼°åºæ¼ regex çæ¨¡å¼éå°æ¼ç®æ³åç²¾ç¢ºéå°æå°æè¡ï¼ä»¥æä½³ååµæ¸¬éåº¦ãæºç¢ºåº¦åå¯æ´åæ§ãæåçåºæºæ¸¬è©¦çµæé¡¯ç¤ºï¼å¨ regex å¼æä¸­ï¼Google RE2 å¨éåº¦ (10-15 ms/MB)ãè¨æ¶é«æç (8-16 MB) åæºç¢ºåº¦ (99.5%) æ¹é¢åå¾æä½³å¹³è¡¡ï¼åªæ¼ PCREï¼åææ¯ Hyperscan æææ´å»£æ³çç¡¬é«ç¸å®¹æ§ãå°æ¼ç²¾ç¢ºéå°ï¼Aho-Corasick å±ç¾åºåªç°çæè½ (8 ms/MB) åå¤§è³æéçå¯æ´åæ§ãæè½åæé¡¯ç¤ºï¼regex èçæéæé¨èè³æéå¤§å°åæ¨¡å¼è¤éåº¦ç·æ§æ´åãæ··å AI + Regex æ¹æ³ééæåå¬åçåå°åé½æ§éè³æä½ï¼éå°äºæé«ç F1 åæ¸ (91. 6%)ãè£ç½®åºæºæ¸¬è©¦ç¢ºèªæåçè§£æ±ºæ¹æ¡å¨é«æ§è½åä¸­éç³»çµ±ä¸é½è½ç¶­æé«æç CPU åè¨æ¶é«ä½¿ç¨çãåç®¡ææï¼ä½ä»æææ°å­å¨ï¼ä¾å¦å¤èªè¨æ¯æ´æéï¼ä»¥åéè¦å®ææ´æ°æ¨¡å¼ãæªä¾çç ç©¶æèéæ¼æ´å±èªè¨æ¶µèç¯åï¼å°è³æå®å¨åé±ç§ç®¡ç (DSPM) èè³æéºå¤±é²è­· (DLP) å·¥å·æ´åï¼ä»¥åå å¼·æ³è¦éµå¾ªä»¥å©æ´å»£æ³çå¨çæ¡ç¨ã

##### **WatchGuardian: Enabling User-Defined Personalized Just-in-Time Intervention on Smartwatch**
2502.05783v1 by Ying Lei, Yancheng Cao, Will Wang, Yuanzhe Dong, Changchang Yin, Weidan Cao, Ping Zhang, Jingzhen Yang, Bingsheng Yao, Yifan Peng, Chunhua Weng, Randy Auerbach, Lena Mamykina, Dakuo Wang, Yuntao Wang, Xuhai Xu

While just-in-time interventions (JITIs) have effectively targeted common
health behaviors, individuals often have unique needs to intervene in personal
undesirable actions that can negatively affect physical, mental, and social
well-being. We present WatchGuardian, a smartwatch-based JITI system that
empowers users to define custom interventions for these personal actions with a
small number of samples. For the model to detect new actions based on limited
new data samples, we developed a few-shot learning pipeline that finetuned a
pre-trained inertial measurement unit (IMU) model on public hand-gesture
datasets. We then designed a data augmentation and synthesis process to train
additional classification layers for customization. Our offline evaluation with
26 participants showed that with three, five, and ten examples, our approach
achieved an average accuracy of 76.8%, 84.7%, and 87.7%, and an F1 score of
74.8%, 84.2%, and 87.2% We then conducted a four-hour intervention study to
compare WatchGuardian against a rule-based intervention. Our results
demonstrated that our system led to a significant reduction by 64.0 +- 22.6% in
undesirable actions, substantially outperforming the baseline by 29.0%. Our
findings underscore the effectiveness of a customizable, AI-driven JITI system
for individuals in need of behavioral intervention in personal undesirable
actions. We envision that our work can inspire broader applications of
user-defined personalized intervention with advanced AI solutions.

æè¦ï¼<paragraph>éç¶å³æä»å¥ï¼JITIsï¼ææå°éå°å¸¸è¦çå¥åº·è¡çºï¼ä½åäººéå¸¸æç¨ç¹çéæ±ä¾ä»å¥å¯è½æå°èº«å¿åç¤¾æç¦ç¥ç¢çè² é¢å½±é¿çåäººä¸è¯è¡çºãæåæåº WatchGuardianï¼éæ¯ä¸ååºæ¼æºæ§æé¶ç JITI ç³»çµ±ï¼å®ä½¿ç¨å°æ¸æ¨£æ¬è®ä½¿ç¨èè½å¤ çºéäºåäººè¡çºå®ç¾©èªè¨ä»å¥æªæ½ãçºäºè®æ¨¡åæ ¹ææéçæ°è³ææ¨£æ¬åµæ¸¬æ°è¡çºï¼æåéç¼äºä¸åå°æ¨£æ¬å­¸ç¿ç®¡éï¼å¾®èª¿äºå¬å±æå¢è³æéä¸çé è¨ç·´æ£æ§æ¸¬éå®åï¼IMUï¼æ¨¡åãç¶å¾ï¼æåè¨­è¨äºä¸åè³ææ´åååææµç¨ï¼ä»¥è¨ç·´å¶ä»åé¡å±¤ä»¥é²è¡èªè¨ãæåå° 26 ä½åèèé²è¡çé¢ç·è©ä¼°é¡¯ç¤ºï¼æåçåæ³ä½¿ç¨ä¸åãäºååååç¯ä¾ï¼éå°äº 76.8%ã84.7% å 87.7% çå¹³åæºç¢ºåº¦ï¼ä»¥å 74.8%ã84.2% å 87.2% ç F1 åæ¸ãç¶å¾ï¼æåé²è¡äºä¸é çºæåå°æçä»å¥ç ç©¶ï¼ä»¥å° WatchGuardian èåºæ¼è¦åçä»å¥é²è¡æ¯è¼ãæåççµæè¡¨æï¼æåçç³»çµ±å°è´ä¸è¯è¡çºé¡¯èæ¸å°äº 64.0 +- 22.6%ï¼å¤§å¹åªæ¼åºç· 29.0%ãæåçç ç©¶çµæå¼·èª¿äºå¯èªè¨ãAI é©åç JITI ç³»çµ±å°éè¦è¡çºä»å¥ä»¥æå°åäººä¸è¯è¡çºçåäººçæææ§ãæåé è¨æåçç ç©¶å¯ä»¥æ¿åµä½¿ç¨èå®ç¾©åäººåä»å¥çæ´å»£æ³æç¨ï¼ä¸¦æ¡ç¨åé²ç AI è§£æ±ºæ¹æ¡ã</paragraph>

##### **RECOVER: Designing a Large Language Model-based Remote Patient Monitoring System for Postoperative Gastrointestinal Cancer Care**
2502.05740v1 by Ziqi Yang, Yuxuan Lu, Jennifer Bagdasarian, Vedant Das Swain, Ritu Agarwal, Collin Campbell, Waddah Al-Refaire, Jehan El-Bayoumi, Guodong Gao, Dakuo Wang, Bingsheng Yao, Nawar Shara

Cancer surgery is a key treatment for gastrointestinal (GI) cancers, a group
of cancers that account for more than 35% of cancer-related deaths worldwide,
but postoperative complications are unpredictable and can be life-threatening.
In this paper, we investigate how recent advancements in large language models
(LLMs) can benefit remote patient monitoring (RPM) systems through clinical
integration by designing RECOVER, an LLM-powered RPM system for postoperative
GI cancer care. To closely engage stakeholders in the design process, we first
conducted seven participatory design sessions with five clinical staff and
interviewed five cancer patients to derive six major design strategies for
integrating clinical guidelines and information needs into LLM-based RPM
systems. We then designed and implemented RECOVER, which features an
LLM-powered conversational agent for cancer patients and an interactive
dashboard for clinical staff to enable efficient postoperative RPM. Finally, we
used RECOVER as a pilot system to assess the implementation of our design
strategies with four clinical staff and five patients, providing design
implications by identifying crucial design elements, offering insights on
responsible AI, and outlining opportunities for future LLM-powered RPM systems.

æè¦ï¼ççæè¡æ¯èè¸é (GI) çççä¸»è¦æ²»çæ¹å¼ï¼éé¡ççä½å¨çççç¸éæ­»äº¡äººæ¸ç 35% ä»¥ä¸ï¼ä½è¡å¾ä½µç¼çç¡æ³é æ¸¬ï¼ä¸å¯è½å±åçå½ãå¨æ¬æä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) çè¿æé²å±å¦ä½ééè¨åºæ´åé ç¦é ç«¯çæ£ç£æ§ (RPM) ç³»çµ±ï¼æ¹æ³æ¯è¨­è¨ RECOVERï¼ä¸åç± LLM é©åç RPM ç³»çµ±ï¼ç¨æ¼è¡å¾èè¸éççç§è­·ãçºäºè®å©å®³éä¿äººå¯ååèè¨­è¨æµç¨ï¼æåé¦åèäºä½è¨åºäººå¡é²è¡ä¸å ´åèå¼è¨­è¨æè­°ï¼ä¸¦è¨ªè«äºä½ççæ£èï¼ä»¥æ¾åºå­é æ´åè¨åºæååè³è¨éæ±è³åºæ¼ LLM ç RPM ç³»çµ±çä¸»è¦è¨­è¨ç­ç¥ãæ¥èï¼æåè¨­è¨ä¸¦å¯¦ä½ RECOVERï¼å¶ç¹è²å¨æ¼ä¸åç± LLM é©åçå°è©±å¼ä»£çäººï¼ä¾ççæ£èä½¿ç¨ï¼ä»¥åä¸åäºåå¼åè¡¨æ¿ï¼ä¾è¨åºäººå¡ä½¿ç¨ï¼ä»¥é²è¡ææçè¡å¾ RPMãæå¾ï¼æåä½¿ç¨ RECOVER ä½çºè©¦é»ç³»çµ±ï¼èåä½è¨åºäººå¡åäºä½æ£èè©ä¼°æåè¨­è¨ç­ç¥çå¯¦ä½ï¼ä¸¦ééæ¾åºéè¦çè¨­è¨åç´ ãæä¾å°è² è²¬ä»» AI çè¦è§£ï¼ä»¥åæ¦è¿°æªä¾ç± LLM é©åç RPM ç³»çµ±çæ©æï¼æåºè¨­è¨ææ¶µã

##### **4D VQ-GAN: Synthesising Medical Scans at Any Time Point for Personalised Disease Progression Modelling of Idiopathic Pulmonary Fibrosis**
2502.05713v1 by An Zhao, Moucheng Xu, Ahmed H. Shahin, Wim Wuyts, Mark G. Jones, Joseph Jacob, Daniel C. Alexander

Understanding the progression trajectories of diseases is crucial for early
diagnosis and effective treatment planning. This is especially vital for
life-threatening conditions such as Idiopathic Pulmonary Fibrosis (IPF), a
chronic, progressive lung disease with a prognosis comparable to many cancers.
Computed tomography (CT) imaging has been established as a reliable diagnostic
tool for IPF. Accurately predicting future CT scans of early-stage IPF patients
can aid in developing better treatment strategies, thereby improving survival
outcomes. In this paper, we propose 4D Vector Quantised Generative Adversarial
Networks (4D-VQ-GAN), a model capable of generating realistic CT volumes of IPF
patients at any time point. The model is trained using a two-stage approach. In
the first stage, a 3D-VQ-GAN is trained to reconstruct CT volumes. In the
second stage, a Neural Ordinary Differential Equation (ODE) based temporal
model is trained to capture the temporal dynamics of the quantised embeddings
generated by the encoder in the first stage. We evaluate different
configurations of our model for generating longitudinal CT scans and compare
the results against ground truth data, both quantitatively and qualitatively.
For validation, we conduct survival analysis using imaging biomarkers derived
from generated CT scans and achieve a C-index comparable to that of biomarkers
derived from the real CT scans. The survival analysis results demonstrate the
potential clinical utility inherent to generated longitudinal CT scans, showing
that they can reliably predict survival outcomes.

æè¦ï¼äºè§£ç¾ççé²ç¨è»è·¡å°æ¼æ©æè¨ºæ·åææçæ²»çè¨ç«è³ééè¦ãéå°æ¼ç¹ç¼æ§èºçºç¶­å (IPF) ç­å¨èçå½çç¾çå°¤å¶éè¦ï¼IPF æ¯ä¸ç¨®æ¢æ§ãé²è¡æ§èºé¨ç¾çï¼å¶é å¾èè¨±å¤ççç¸ç¶ãé»è¦æ·å±¤ææ (CT) å½±åå·²è¢«ç¢ºç«çº IPF çå¯é è¨ºæ·å·¥å·ãæºç¢ºé æ¸¬æ©æ IPF æ£èçæªä¾ CT æææå©æ¼å¶å®æ´å¥½çæ²»çç­ç¥ï¼å¾èæ¹åå­æ´»çµæãå¨æ¬æä¸­ï¼æåæåº 4D åééåçæå°æç¶²è·¯ (4D-VQ-GAN)ï¼éæ¯ä¸åæ¨¡åï¼è½å¤ å¨ä»»ä½æéé»çæ IPF æ£èçé¼ç CT é«ç©ãè©²æ¨¡åä½¿ç¨å©éæ®µæ¹æ³é²è¡è¨ç·´ãå¨ç¬¬ä¸éæ®µï¼è¨ç·´ 3D-VQ-GAN ä»¥éå»º CT é«ç©ãå¨ç¬¬äºéæ®µï¼è¨ç·´åºæ¼ç¥ç¶å¸¸å¾®åæ¹ç¨ (ODE) çæéæ¨¡åï¼ä»¥ææç¬¬ä¸éæ®µç·¨ç¢¼å¨çæçéååµå¥çæéåæãæåè©ä¼°äºæåçæ¨¡åçä¸åéç½®ï¼ä»¥çæç¸±å CT ææï¼ä¸¦å¨å®éåå®æ§æ¹é¢å°çµæèçå¯¦æ¸æé²è¡æ¯è¼ãçºäºé©è­ï¼æåä½¿ç¨å¾çæç CT ææä¸­å¾åºçå½±åçç©æ¨è¨é²è¡å­æ´»åæï¼ä¸¦ç²å¾èå¾çå¯¦ CT ææä¸­å¾åºççç©æ¨è¨ç¸ç¶ç C ææ¸ãå­æ´»åæçµæè­æäºçæç¸±å CT ææåºæçæ½å¨è¨åºæç¨ï¼è¡¨æå®åå¯ä»¥å¯é å°é æ¸¬å­æ´»çµæã

##### **KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy**
2502.05651v1 by Hyunjong Kim, Suyeon Lee, Yeongjae Cho, Eunseo Ryu, Yohan Jo, Suran Seong, Sungzoon Cho

The increasing demand for mental health services has led to the rise of
AI-driven mental health chatbots, though challenges related to privacy, data
collection, and expertise persist. Motivational Interviewing (MI) is gaining
attention as a theoretical basis for boosting expertise in the development of
these chatbots. However, existing datasets are showing limitations for training
chatbots, leading to a substantial demand for publicly available resources in
the field of MI and psychotherapy. These challenges are even more pronounced in
non-English languages, where they receive less attention. In this paper, we
propose a novel framework that simulates MI sessions enriched with the
expertise of professional therapists. We train an MI forecaster model that
mimics the behavioral choices of professional therapists and employ Large
Language Models (LLMs) to generate utterances through prompt engineering. Then,
we present KMI, the first synthetic dataset theoretically grounded in MI,
containing 1,000 high-quality Korean Motivational Interviewing dialogues.
Through an extensive expert evaluation of the generated dataset and the
dialogue model trained on it, we demonstrate the quality, expertise, and
practicality of KMI. We also introduce novel metrics derived from MI theory in
order to evaluate dialogues from the perspective of MI.

æè¦ï¼ç±æ¼å°å¿çå¥åº·æåçéæ±æ¥çå¢å ï¼å°è´ä»¥äººå·¥æºæ§çºåºç¤çå¿çå¥åº·èå¤©æ©å¨äººèèµ·ï¼åç®¡èé±ç§ãè³æèéåå°æ¥­ç¥è­ç¸éçææ°ä¾ç¶å­å¨ãåæ©æ§è¨ªè« (MI) æ­£ä½çºæåéäºèå¤©æ©å¨äººå¨éç¼æ¹é¢å°æ¥­ç¥è­ççè«åºç¤èååéæ³¨ãç¶èï¼ç¾æçè³æéé¡¯ç¤ºåºè¨ç·´èå¤©æ©å¨äººçéå¶ï¼å°è´å° MI åå¿çæ²»çé åä¸­å¬éå¯ç¨è³æºçéæ±å¤§å¹å¢å ãéäºææ°å¨éè±èªèªè¨ä¸­æ´å æé¡¯ï¼å çºå®ååå°çéæ³¨è¼å°ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çæ¶æ§ï¼å®æ¨¡æ¬äºè±å¯å°æ¥­æ²»çå¸«å°æ¥­ç¥è­ç MI èª²ç¨ãæåè¨ç·´äºä¸å MI é æ¸¬æ¨¡åï¼å®æ¨¡æ¬äºå°æ¥­æ²»çå¸«çè¡çºé¸æï¼ä¸¦æ¡ç¨å¤§åèªè¨æ¨¡å (LLM) ééæç¤ºå·¥ç¨ä¾ç¢çè©±èªãç¶å¾ï¼æåå±ç¤ºäº KMIï¼éæ¯ç¬¬ä¸åçè«ä¸ä»¥ MI çºåºç¤çåæè³æéï¼å¶ä¸­åå« 1,000 åé«åè³ªçéèªåæ©æ§è¨ªè«å°è©±ãééå°æç¢ççè³æéåå¨è©²è³æéä¸è¨ç·´çå°è©±æ¨¡åé²è¡å»£æ³çå°å®¶è©ä¼°ï¼æåå±ç¤ºäº KMI çåè³ªãå°æ¥­ç¥è­åå¯¦ç¨æ§ãæåéå¼å¥äºå¾ MI çè«ä¸­è¡ççæ°ææ¨ï¼ä»¥ä¾¿å¾ MI çè§åº¦è©ä¼°å°è©±ã

##### **ELMTEX: Fine-Tuning Large Language Models for Structured Clinical Information Extraction. A Case Study on Clinical Reports**
2502.05638v1 by Aynur Guluzade, Naguib Heiba, Zeyd Boukhers, Florim Hamiti, Jahid Hasan Polash, Yehya Mohamad, Carlos A Velasco

Europe's healthcare systems require enhanced interoperability and
digitalization, driving a demand for innovative solutions to process legacy
clinical data. This paper presents the results of our project, which aims to
leverage Large Language Models (LLMs) to extract structured information from
unstructured clinical reports, focusing on patient history, diagnoses,
treatments, and other predefined categories. We developed a workflow with a
user interface and evaluated LLMs of varying sizes through prompting strategies
and fine-tuning. Our results show that fine-tuned smaller models match or
surpass larger counterparts in performance, offering efficiency for
resource-limited settings. A new dataset of 60,000 annotated English clinical
summaries and 24,000 German translations was validated with automated and
manual checks. The evaluations used ROUGE, BERTScore, and entity-level metrics.
The work highlights the approach's viability and outlines future improvements.

æè¦ï¼æ­æ´²çé«çä¿å¥ç³»çµ±éè¦å¢å¼·äºéæ§åæ¸ä½åï¼éé©åäºå°åµæ°è§£æ±ºæ¹æ¡çéæ±ï¼ä»¥èçå³çµ±çè¨åºæ¸æãæ¬æä»ç´¹äºæåå°æ¡çææï¼è©²å°æ¡æ¨å¨å©ç¨å¤§åèªè¨æ¨¡å (LLM) å¾éçµæ§åçè¨åºå ±åä¸­æåçµæ§åçè³è¨ï¼éé»æ¾å¨çæ­·ãè¨ºæ·ãæ²»çåå¶ä»é å®ç¾©é¡å¥ä¸ãæåéç¼äºä¸åå·æä½¿ç¨èä»é¢çå·¥ä½æµç¨ï¼ä¸¦ééæç¤ºç­ç¥åå¾®èª¿ä¾è©ä¼°ä¸åè¦æ¨¡ç LLMãæåççµæé¡¯ç¤ºï¼å¾®èª¿å¾çè¼å°æ¨¡åå¨æè½ä¸èè¼å¤§çæ¨¡åç¸å¹éæè¶è¶å®åï¼çºè³æºæéçç°å¢æä¾äºæçãä¸ååå« 60,000 åè¨»è§£è±æè¨åºæè¦å 24,000 åå¾·æç¿»è­¯çæ°è³æéå·²ééèªåååæåæª¢æ¥é²è¡é©è­ãè©ä¼°ä½¿ç¨äº ROUGEãBERTScore åå¯¦é«å±¤ç´çææ¨ãéé å·¥ä½çªåºäºéç¨®æ¹æ³çå¯è¡æ§ï¼ä¸¦æ¦è¿°äºæªä¾çæ¹é²ã

##### **Multi-scale Masked Autoencoder for Electrocardiogram Anomaly Detection**
2502.05494v1 by Ya Zhou, Yujie Yang, Jianhuang Gan, Xiangjie Li, Jing Yuan, Wei Zhao

Electrocardiogram (ECG) analysis is a fundamental tool for diagnosing
cardiovascular conditions, yet anomaly detection in ECG signals remains
challenging due to their inherent complexity and variability. We propose
Multi-scale Masked Autoencoder for ECG anomaly detection (MMAE-ECG), a novel
end-to-end framework that effectively captures both global and local
dependencies in ECG data. Unlike state-of-the-art methods that rely on
heartbeat segmentation or R-peak detection, MMAE-ECG eliminates the need for
such pre-processing steps, enhancing its suitability for clinical deployment.
MMAE-ECG partitions ECG signals into non-overlapping segments, with each
segment assigned learnable positional embeddings. A novel multi-scale masking
strategy and multi-scale attention mechanism, along with distinct positional
embeddings, enable a lightweight Transformer encoder to effectively capture
both local and global dependencies. The masked segments are then reconstructed
using a single-layer Transformer block, with an aggregation strategy employed
during inference to refine the outputs. Experimental results demonstrate that
our method achieves performance comparable to state-of-the-art approaches while
significantly reducing computational complexity-approximately 1/78 of the
floating-point operations (FLOPs) required for inference. Ablation studies
further validate the effectiveness of each component, highlighting the
potential of multi-scale masked autoencoders for anomaly detection.

æè¦ï¼å¿é»å (ECG) åææ¯è¨ºæ·å¿è¡ç®¡ç¾ççåºæ¬å·¥å·ï¼ä½ç±æ¼ ECG è¨èæ¬èº«çè¤éæ§åè®ç°æ§ï¼ç°å¸¸åµæ¸¬ä»ç¶æ¯ä¸é ææ°ãæåæåºç¨æ¼ ECG ç°å¸¸åµæ¸¬çå¤å°ºåº¦é®ç½©èªç·¨ç¢¼å¨ (MMAE-ECG)ï¼éæ¯ä¸åæ°ç©çç«¯å°ç«¯æ¶æ§ï¼å¯æææ·å ECG è³æä¸­çå¨å±åå±é¨ä¾è³´éä¿ãèä¾è³´æ¼å¿è·³åæ®µæ R æ³¢å³°åµæ¸¬çææ°æ¹æ³ä¸åï¼MMAE-ECG æ¶é¤äºå°æ­¤é¡åèçæ­¥é©çéæ±ï¼å¢å¼·å¶é©ç¨æ¼è¨åºé¨ç½²ãMMAE-ECG å° ECG è¨èåå²æä¸ç¸ççåæ®µï¼æ¯ååæ®µé½ææ´¾å¯å­¸ç¿çä½ç½®åµå¥ãæ°ç©çå¤å°ºåº¦é®ç½©ç­ç¥åå¤å°ºåº¦æ³¨æåæ©å¶ï¼ä»¥åä¸åçä½ç½®åµå¥ï¼ä½¿è¼éç´ Transformer ç·¨ç¢¼å¨è½å¤ æææ·åå±é¨åå¨å±ä¾è³´éä¿ãç¶å¾ä½¿ç¨å®å±¤ Transformer åå¡éå»ºé®ç½©åæ®µï¼ä¸¦å¨æ¨çæéæ¡ç¨èåç­ç¥ä¾åªåè¼¸åºãå¯¦é©çµæè¡¨æï¼æåçæ¨¡åéå°äºèææ°æ¹æ³ç¸ç¶çæè½ï¼åæå¤§å¹éä½éç®è¤éåº¦ï¼ç´çºæ¨çæéçæµ®é»éç® (FLOP) ç 1/78ãæ¶èç ç©¶é²ä¸æ­¥é©è­äºæ¯åçµä»¶çæææ§ï¼çªé¡¯äºå¤å°ºåº¦é®ç½©èªç·¨ç¢¼å¨å¨ç°å¸¸åµæ¸¬æ¹é¢çæ½åã

##### **DCENWCNet: A Deep CNN Ensemble Network for White Blood Cell Classification with LIME-Based Explainability**
2502.05459v1 by Sibasish Dhibar

White blood cells (WBC) are important parts of our immune system, and they
protect our body against infections by eliminating viruses, bacteria, parasites
and fungi. The number of WBC types and the total number of WBCs provide
important information about our health status. A traditional method,
convolutional neural networks (CNN), a deep learning architecture, can classify
the blood cell from a part of an object and perform object recognition. Various
CNN models exhibit potential; however, their development often involves ad-hoc
processes that neglect unnecessary layers, leading to issues with unbalanced
datasets and insufficient data augmentation. To address these challenges, we
propose a novel ensemble approach that integrates three CNN architectures, each
uniquely configured with different dropout and max-pooling layer settings to
enhance feature learning. This ensemble model, named DCENWCNet, effectively
balances the bias-variance trade-off. When evaluated on the widely recognized
Rabbin-WBC dataset, our model outperforms existing state-of-the-art networks,
achieving highest mean accuracy. Additionally, it demonstrates superior
performance in precision, recall, F1-score, and Area Under the ROC Curve (AUC)
across all categories. To delve deeper into the interpretability of
classifiers, we employ reliable post-hoc explanation techniques, including
Local Interpretable Model-Agnostic Explanations (LIME). These methods
approximate the behavior of a black-box model by elucidating the relationships
between feature values and predictions. Interpretable results enable users to
comprehend and validate the model's predictions, thereby increasing their
confidence in the automated diagnosis.

æè¦ï¼ç½è¡ç (WBC) æ¯æååç«ç³»çµ±çéè¦çµæé¨åï¼å®åééæ¸é¤çæ¯ãç´°èãå¯çè²åçèä¾ä¿è­·æåçæ©é«ååææãWBC é¡åæ¸éå WBC ç¸½æ¸æä¾äºæéæåå¥åº·çæ³çéè¦è³è¨ãå³çµ±æ¹æ³å·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¯ä¸ç¨®æ·±åº¦å­¸ç¿æ¶æ§ï¼å¯ä»¥å°ç©é«çä¸é¨åé²è¡è¡ç´°èåé¡ä¸¦å·è¡ç©é«è­å¥ãåç¨® CNN æ¨¡åå±ç¾åºæ½åï¼ç¶èï¼å®åçéç¼éå¸¸æ¶åå¿½ç¥ä¸å¿è¦å±¤çè¨æéç¨ï¼å°è´ä¸å¹³è¡¡çè³æéåè³ææ´åä¸è¶³çåé¡ãçºäºæå°éäºææ°ï¼æåæåºäºä¸ç¨®æ°ç©çæ´é«æ¹æ³ï¼å®æ´åäºä¸ç¨® CNN æ¶æ§ï¼æ¯ç¨®æ¶æ§é½æ¡ç¨ä¸åçä¸­æ·åæå¤§æ± åå±¤è¨­å®é²è¡ç¨ç¹éç½®ï¼ä»¥å¢å¼·ç¹å¾µå­¸ç¿ãéç¨®åçº DCENWCNet çæ´é«æ¨¡åææå°å¹³è¡¡äºåå·®è®ç°åæ¨ãå¨å»£æ³èªå¯ç Rabbin-WBC è³æéä¸é²è¡è©ä¼°æï¼æåçæ¨¡ååªæ¼ç¾æçæåé²ç¶²è·¯ï¼éå°äºæé«çå¹³åæºç¢ºåº¦ãæ­¤å¤ï¼å®å¨ææé¡å¥ä¸­é½å±ç¤ºäºå¨ç²¾ç¢ºåº¦ãå¬åçãF1 åæ¸å ROC æ²ç·ä¸é¢ç© (AUC) æ¹é¢çåè¶æè½ãçºäºæ´æ·±å¥å°ç ç©¶åé¡å¨çå¯è§£éæ§ï¼æåæ¡ç¨äºå¯é çäºå¾è§£éæè¡ï¼åæ¬å±é¨å¯è§£éæ¨¡åä¸å¯ç¥è§£é (LIME)ãéäºæ¹æ³ééé¡æç¹å¾µå¼åé æ¸¬ä¹éçéä¿ä¾è¿ä¼¼é»çæ¨¡åçè¡çºãå¯è§£éççµæä½¿ç¨æ¶è½å¤ çè§£åé©è­æ¨¡åçé æ¸¬ï¼å¾èå¢å ä»åå°èªååè¨ºæ·çä¿¡å¿ã

##### **Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge**
2502.05330v1 by Muhammad Imran, Jonathan R. Krebs, Vishal Balaji Sivaraman, Teng Zhang, Amarjeet Kumar, Walker R. Ueland, Michael J. Fassler, Jinlong Huang, Xiao Sun, Lisheng Wang, Pengcheng Shi, Maximilian Rokuss, Michael Baumgartner, Yannick Kirchhof, Klaus H. Maier-Hein, Fabian Isensee, Shuolin Liu, Bing Han, Bong Thanh Nguyen, Dong-jin Shin, Park Ji-Woo, Mathew Choi, Kwang-Hyun Uhm, Sung-Jea Ko, Chanwoong Lee, Jaehee Chun, Jin Sung Kim, Minghui Zhang, Hanxiao Zhang, Xin You, Yun Gu, Zhaohong Pan, Xuan Liu, Xiaokun Liang, Markus Tiefenthaler, Enrique Almar-Munoz, Matthias Schwab, Mikhail Kotyushev, Rostislav Epifanov, Marek Wodzinski, Henning Muller, Abdul Qayyum, Moona Mazher, Steven A. Niederer, Zhiwei Wang, Kaixiang Yang, Jintao Ren, Stine Sofia Korreman, Yuchong Gao, Hongye Zeng, Haoyu Zheng, Rui Zheng, Jinghua Yue, Fugen Zhou, Bo Liu, Alexander Cosman, Muxuan Liang, Chang Zhao, Gilbert R. Upchurch Jr., Jun Ma, Yuyin Zhou, Michol A. Cooper, Wei Shao

Multi-class segmentation of the aorta in computed tomography angiography
(CTA) scans is essential for diagnosing and planning complex endovascular
treatments for patients with aortic dissections. However, existing methods
reduce aortic segmentation to a binary problem, limiting their ability to
measure diameters across different branches and zones. Furthermore, no
open-source dataset is currently available to support the development of
multi-class aortic segmentation methods. To address this gap, we organized the
AortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes
annotated for 23 clinically relevant aortic branches and zones. This dataset
was designed to facilitate both model development and validation. The challenge
attracted 121 teams worldwide, with participants leveraging state-of-the-art
frameworks such as nnU-Net and exploring novel techniques, including cascaded
models, data augmentation strategies, and custom loss functions. We evaluated
the submitted algorithms using the Dice Similarity Coefficient (DSC) and
Normalized Surface Distance (NSD), highlighting the approaches adopted by the
top five performing teams. This paper presents the challenge design, dataset
details, evaluation metrics, and an in-depth analysis of the top-performing
algorithms. The annotated dataset, evaluation code, and implementations of the
leading methods are publicly available to support further research. All
resources can be accessed at https://aortaseg24.grand-challenge.org.

æè¦ï¼å¤é¡å¥ä¸»åèé»è¦æ·å±¤è¡ç®¡æå½± (CTA) ææåå²å°æ¼è¨ºæ·åè¦åä¸»åèåé¢æ£èçè¤éè¡ç®¡å§æ²»çè³ééè¦ãç¶èï¼ç¾ææ¹æ³å°ä¸»åèåå²ç°¡åçºäºååé¡ï¼éå¶äºå¶æ¸¬éä¸ååæ¯åååç´å¾çè½åãæ­¤å¤ï¼ç®åæ²æéæ¾åå§ç¢¼æ¸æéå¯ç¨æ¼æ¯æ´å¤é¡å¥ä¸»åèåå²æ¹æ³çéç¼ãçºäºè§£æ±ºæ­¤åé¡ï¼æåçµç¹äº AortaSeg24 MICCAI ææ°ï¼å¼å¥äºç¬¬ä¸ååå« 100 å CTA é«ç©çæ¸æéï¼éäºé«ç©éå° 23 åè¨åºä¸ç¸éçä¸»åèåæ¯åååé²è¡äºè¨»éãæ­¤æ¸æéæ¨å¨ä¿é²æ¨¡åéç¼åé©è­ãè©²ææ°å¸å¼äºä¾èªä¸çåå°ç 121 ååéï¼åèèå©ç¨äº nnU-Net ç­æåé²çæ¡æ¶ï¼ä¸¦æ¢ç´¢äºåµæ°æè¡ï¼åæ¬ä¸²è¯æ¨¡åãæ¸ææ´åç­ç¥åèªè¨æå¤±å½æ¸ãæåä½¿ç¨ Dice ç¸ä¼¼æ§ä¿æ¸ (DSC) åæ¨æºåè¡¨é¢è·é¢ (NSD) è©ä¼°äºæäº¤çæ¼ç®æ³ï¼éé»ä»ç´¹äºåäºåè¡¨ç¾æä½³åéæ¡ç¨çæ¹æ³ãæ¬æä»ç´¹äºææ°è¨­è¨ãæ¸æéè©³ç´°è³è¨ãè©ä¼°ææ¨ä»¥åå°è¡¨ç¾æä½³æ¼ç®æ³çæ·±å¥åæãå·²å¬éè¨»éçæ¸æéãè©ä¼°ç¨å¼ç¢¼åé åæ¹æ³çå¯¦ä½ï¼ä»¥æ¯æ´é²ä¸æ­¥çç ç©¶ãææè³æºé½å¯ä»¥å¨ https://aortaseg24.grand-challenge.org/ ç²å¾ã

##### **Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning**
2502.05282v1 by Yuting He, Boyu Wang, Rongjun Ge, Yang Chen, Guanyu Yang, Shuo Li

Dense contrastive representation learning (DCRL) has greatly improved the
learning efficiency for image-dense prediction tasks, showing its great
potential to reduce the large costs of medical image collection and dense
annotation. However, the properties of medical images make unreliable
correspondence discovery, bringing an open problem of large-scale false
positive and negative (FP&N) pairs in DCRL. In this paper, we propose GEoMetric
vIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism prior
to DCRL and enables a reliable correspondence discovery for effective dense
contrast. We propose a deformable homeomorphism learning (DHL) which models the
homeomorphism of medical images and learns to estimate a deformable mapping to
predict the pixels' correspondence under topological preservation. It
effectively reduces the searching space of pairing and drives an implicit and
soft learning of negative pairs via a gradient. We also propose a geometric
semantic similarity (GSS) which extracts semantic information in features to
measure the alignment degree for the correspondence learning. It will promote
the learning efficiency and performance of deformation, constructing positive
pairs reliably. We implement two practical variants on two typical
representation learning tasks in our experiments. Our promising results on
seven datasets which outperform the existing methods show our great
superiority. We will release our code on a companion link:
https://github.com/YutingHe-list/GEMINI.

æè¦ï¼å¯éå¯¹æ¯è¡¨å¾å­¦ä¹ ï¼DCRLï¼æå¤§å°æé«äºå½±åå¯éé¢æµä»»å¡çå­¦ä¹ æçï¼æ¾ç¤ºåºå¶å¨éä½å»å­¦å½±åæ¶éåå¯éæ æ³¨çå¤§éææ¬æ¹é¢çå·¨å¤§æ½åãç¶èï¼å»å­¦å½±åçç¹æ§ä½¿å¾å¯¹åºå³ç³»åç°ä¸å¯é ï¼ç» DCRL å¸¦æ¥å¤§è§æ¨¡åé³æ§ååé´æ§ï¼FP&Nï¼å¯¹çå¼æ¾æ§é®é¢ãå¨æ¬æä¸­ï¼æä»¬æåºäº GEoMetric vIsual deNse sImilarityï¼GEMINIï¼å­¦ä¹ ï¼å®å°åèåéªåµå¥ DCRL ä¸­ï¼å¹¶éå¯¹ææå¯éå¯¹æ¯æä¾äºå¯é çå¯¹åºå³ç³»åç°ãæä»¬æåºäºä¸ç§å¯åå½¢åèå­¦ä¹ ï¼DHLï¼ï¼å®å¯¹å»å­¦å½±åçåèè¿è¡å»ºæ¨¡ï¼å¹¶å­¦ä¹ ä¼°è®¡å¯åå½¢æ å°ï¼ä»¥é¢æµå¨ææä¿æä¸çåç´ å¯¹åºå³ç³»ãå®ææå°åå°äºéå¯¹çæç´¢ç©ºé´ï¼å¹¶éè¿æ¢¯åº¦é©±å¨äºè´å¯¹çéå¼åè½¯å­¦ä¹ ãæä»¬è¿æåºäºå ä½è¯­ä¹ç¸ä¼¼æ§ï¼GSSï¼ï¼å®æåç¹å¾ä¸­çè¯­ä¹ä¿¡æ¯ï¼ä»¥æµéå¯¹åºå³ç³»å­¦ä¹ çå¯¹é½åº¦ãå®å°ä¿è¿åå½¢å­¦ä¹ çæçåæ§è½ï¼å¯é å°æå»ºæ­£å¯¹ãæä»¬å¨å®éªä¸­éå¯¹ä¸¤ä¸ªå¸åçè¡¨å¾å­¦ä¹ ä»»å¡å®ç°äºä¸¤ä¸ªå®éåä½ãæä»¬å¨ä¸ä¸ªæ°æ®éä¸çæå¸æçç»æä¼äºç°ææ¹æ³ï¼æ¾ç¤ºåºæä»¬çå·¨å¤§ä¼å¿ãæä»¬å°å¨éå¥é¾æ¥ä¸­åå¸æä»¬çä»£ç ï¼https://github.com/YutingHe-list/GEMINIã

##### **"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**
2502.05115v1 by Shihan Fu, Bingsheng Yao, Smit Desai, Yuqi Hu, Yuling Sun, Samantha Stonbraker, Yanjun Gao, Elizabeth M. Goldberg, Dakuo Wang

Older adult patients constitute a rapidly growing subgroup of Intensive Care
Unit (ICU) patients. In these situations, their family caregivers are expected
to represent the unconscious patients to access and interpret patients' medical
information. However, caregivers currently have to rely on overloaded
clinicians for information updates and typically lack the health literacy to
understand complex medical information. Our project aims to explore the
information needs of caregivers of ICU older adult patients, from which we can
propose design opportunities to guide future AI systems. The project begins
with formative interviews with 11 caregivers to identify their challenges in
accessing and interpreting medical information; From these findings, we then
synthesize design requirements and propose an AI system prototype to cope with
caregivers' challenges. The system prototype has two key features: a timeline
visualization to show the AI extracted and summarized older adult patients' key
medical events; and an LLM-based chatbot to provide context-aware informational
support. We conclude our paper by reporting on the follow-up user evaluation of
the system and discussing future AI-based systems for ICU caregivers of older
adults.

æè¦ï¼èå¹´æ£èæ§æå è­·çæ¿ (ICU) æ£èä¸­å¿«éæé·çå­ç¾¤ãå¨éäºææ³ä¸ï¼é æä»åçå®¶åº­ç§è­·èè½ä»£è¡¨ç¡æè­çæ£èåå¾ä¸¦è§£è®æ£èçé«çè³è¨ãç¶èï¼ç§è­·èç®åå¿é ä¾è³´å·¥ä½ç¹éçè¨åºé«å¸«æä¾è³è¨æ´æ°ï¼èä¸éå¸¸ç¼ºä¹äºè§£è¤éé«çè³è¨çå¥åº·ç´ é¤ãæåçå°æ¡æ¨å¨æ¢ç´¢ ICU èå¹´æ£èç§è­·èçè³è¨éæ±ï¼æåå¯ä»¥æ ¹æéäºéæ±æåºè¨­è¨æ©æï¼ä»¥å¼å°æªä¾ç AI ç³»çµ±ãéåå°æ¡å¾å° 11 ä½ç§è­·èçå½¢ææ§è¨ªè«éå§ï¼ä»¥æ¾åºä»åå¨åå¾åè§£è®é«çè³è¨æ¹é¢çææ°ï¼æ ¹æéäºç¼ç¾ï¼æåæ¥èç¶åè¨­è¨éæ±ï¼ä¸¦æåºä¸å AI ç³»çµ±ååï¼ä»¥æå°ç§è­·èçææ°ãéåç³»çµ±ååå·æå©åééµç¹é»ï¼ä¸åæéè»¸è¦è¦ºåï¼ä»¥é¡¯ç¤º AI èåä¸¦æè¦åºçèå¹´æ£èééµé«çäºä»¶ï¼ä»¥åä¸ååºæ¼ LLM çèå¤©æ©å¨äººï¼ä»¥æä¾æå¢æç¥çè³è¨æ¯æ´ãæåééå ±åç³»çµ±çå¾çºä½¿ç¨èè©ä¼°ï¼ä»¥åè¨è«æªä¾éå°èå¹´äºº ICU ç§è­·èç AI ç³»çµ±ï¼ä¾ç¸½çµæåçè«æã

##### **Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**
2502.05087v1 by Thierry Bossy, Julien Vignoud, Tahseen Rabbani, Juan R. Troncoso Pastoriza, Martin Jaggi

Federated learning (FL) is a popular paradigm for collaborative training
which avoids direct data exposure between clients. However, data privacy issues
still remain: FL-trained large language models are capable of memorizing and
completing phrases and sentences contained in training data when given with
their prefixes. Thus, it is possible for adversarial and honest-but-curious
clients to recover training data of other participants simply through targeted
prompting. In this work, we demonstrate that a popular and simple fine-tuning
strategy, low-rank adaptation (LoRA), reduces memorization during FL up to a
factor of 10. We study this effect by performing a medical question-answering
fine-tuning task and injecting multiple replicas of out-of-distribution
sensitive sequences drawn from an external clinical dataset. We observe a
reduction in memorization for a wide variety of Llama 2 and 3 models, and find
that LoRA can reduce memorization in centralized learning as well. Furthermore,
we show that LoRA can be combined with other privacy-preserving techniques such
as gradient clipping and Gaussian noising, secure aggregation, and Goldfish
loss to further improve record-level privacy while maintaining performance.

æè¦ï¼è¯é¦å­¸ç¿ (FL) æ¯ä¸ç¨®æµè¡çåä½è¨ç·´ç¯ä¾ï¼å¯é¿åå®¢æ¶ç«¯ä¹éç´æ¥å¬éè³æãç¶èï¼è³æé±ç§åé¡ä»ç¶å­å¨ï¼ç¶é FL è¨ç·´çå¤§åèªè¨æ¨¡åè½å¤ è¨æ¶ä¸¦å®æè¨ç·´è³æä¸­åå«ççèªåå¥å­ï¼åªè¦çµ¦äºå¶åç¶´å³å¯ãå æ­¤ï¼å°æåèª å¯¦ä½å¥½å¥çå®¢æ¶ç«¯æå¯è½åééç®æ¨æç¤ºä¾æ¢å¾©å¶ä»åèèçè¨ç·´è³æãå¨éé å·¥ä½ä¸­ï¼æåè­æäºä¸ç¨®æµè¡ä¸ç°¡å®çå¾®èª¿ç­ç¥ï¼ä½ç§©é©æ (LoRA)ï¼å¯å° FL æéçè¨æ¶æ¸å°å¤é 10 åãæåééå·è¡é«å­¸åç­å¾®èª¿ä»»åä¸¦æ³¨å¥å¾å¤é¨è¨åºè³æéæ½åçéåä½ææåºåçå¤æ¬¡è¤è£½åä¾ç ç©¶æ­¤ææãæåè§å¯å°åç¨® Llama 2 å 3 æ¨¡åçè¨æ¶åéä½ï¼ä¸¦ç¼ç¾ LoRA ä¹è½æ¸å°éä¸­å¼å­¸ç¿ä¸­çè¨æ¶åãæ­¤å¤ï¼æåå±ç¤º LoRA å¯ä»¥èå¶ä»é±ç§ä¿è­·æè¡çµåä½¿ç¨ï¼ä¾å¦æ¢¯åº¦è£åªåé«æ¯éè¨ãå®å¨èåå Goldfish æå¤±ï¼ä»¥é²ä¸æ­¥æ¹åè¨éç´é±ç§ï¼åæç¶­ææè½ã

##### **MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**
2502.04794v2 by Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo

Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is
introduced as a multimodal framework inspired by real-world diagnostic
processes. It uses pretrained models such as DINOv2, Vision Transformer, and
ResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into
low-dimensional, semantically meaningful features. A learnable
self-attention-based fusion network then integrates these imaging features with
clinical data for classification. Using 416 FUO patient cases from Sichuan
University West China Hospital from 2017 to 2023, the multimodal fusion
classification network MFCN achieved macro-AUROC scores ranging from 0.8654 to
0.9291 across seven tasks, outperforming conventional machine learning and
single-modality deep learning methods. Ablation studies and five-fold
cross-validation further validated its effectiveness. By combining the
strengths of pretrained large models and deep learning, MedMimic offers a
promising solution for disease classification.

æè¦ï¼ç¼çæå ä¸æï¼FUOï¼ä»æ¯è¨ºæ·ä¸çææ°ãMedMimic è¢«å¼å¥ä½çºä¸åå¤æ¨¡ææ¡æ¶ï¼éæä¾èªæ¼çå¯¦ä¸ççè¨ºæ·éç¨ãå®ä½¿ç¨é è¨ç·´æ¨¡åï¼ä¾å¦ DINOv2ãVision Transformer å ResNet-18ï¼å°é«ç¶­ 18F-FDG PET/CT å½±åè½æçºä½ç¶­ãèªç¾©ææç¾©çç¹å¾µãä¸åå¯å­¸ç¿çåºæ¼èªæ³¨æåæ©å¶çèåç¶²è·¯æ¥èæ´åéäºå½±åç¹å¾µèè¨åºè³æä»¥é²è¡åé¡ãä½¿ç¨ 2017 å¹´è³ 2023 å¹´éåå·å¤§å­¸è¯è¥¿é«é¢ç 416 å FUO çæ£æ¡ä¾ï¼å¤æ¨¡æèååé¡ç¶²è·¯ MFCN å¨ä¸é ä»»åä¸­éæ 0.8654 è³ 0.9291 çå·¨è§ AUROC åæ¸ï¼åªæ¼å³çµ±æ©å¨å­¸ç¿åå®ä¸æ¨¡ææ·±åº¦å­¸ç¿æ¹æ³ãæ¶èç ç©¶åäºåäº¤åé©è­é²ä¸æ­¥é©è­äºå¶æææ§ãMedMimic çµåäºé è¨ç·´å¤§åæ¨¡ååæ·±åº¦å­¸ç¿çåªé»ï¼çºç¾çåé¡æä¾äºä¸åæåæ¯çè§£æ±ºæ¹æ¡ã

##### **MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification**
2502.04515v1 by Wei Fan, Jingru Fei, Dingyu Guo, Kun Yi, Xiaozhuang Song, Haolong Xiang, Hangting Ye, Min Li

Medical time series has been playing a vital role in real-world healthcare
systems as valuable information in monitoring health conditions of patients.
Accurate classification for medical time series, e.g., Electrocardiography
(ECG) signals, can help for early detection and diagnosis. Traditional methods
towards medical time series classification rely on handcrafted feature
extraction and statistical methods; with the recent advancement of artificial
intelligence, the machine learning and deep learning methods have become more
popular. However, existing methods often fail to fully model the complex
spatial dynamics under different scales, which ignore the dynamic
multi-resolution spatial and temporal joint inter-dependencies. Moreover, they
are less likely to consider the special baseline wander problem as well as the
multi-view characteristics of medical time series, which largely hinders their
prediction performance. To address these limitations, we propose a
Multi-resolution Spatiotemporal Graph Learning framework, MedGNN, for medical
time series classification. Specifically, we first propose to construct
multi-resolution adaptive graph structures to learn dynamic multi-scale
embeddings. Then, to address the baseline wander problem, we propose Difference
Attention Networks to operate self-attention mechanisms on the finite
difference for temporal modeling. Moreover, to learn the multi-view
characteristics, we utilize the Frequency Convolution Networks to capture
complementary information of medical time series from the frequency domain. In
addition, we introduce the Multi-resolution Graph Transformer architecture to
model the dynamic dependencies and fuse the information from different
resolutions. Finally, we have conducted extensive experiments on multiple
medical real-world datasets that demonstrate the superior performance of our
method. Our Code is available.

æè¦ï¼<paragraph>é«çæéåºåå¨çå¯¦ä¸ççé«çä¿å¥ç³»çµ±ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä½çºç£æ§æ£èå¥åº·çæ³çå¯¶è²´è³è¨ã
æºç¢ºåé¡é«çæéåºåï¼ä¾å¦å¿é»å (ECG) è¨èï¼æå©æ¼æ©æåµæ¸¬åè¨ºæ·ãå³çµ±çé«çæéåºååé¡æ¹æ³ä»°è³´æå·¥ç¹å¾µèååçµ±è¨æ¹æ³ï¼é¨èäººå·¥æºæ§çææ°é²å±ï¼æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³è®å¾æ´çºæ®åãç¶èï¼ç¾ææ¹æ³éå¸¸ç¡æ³å®å¨å»ºæ¨¡ä¸åå°ºåº¦ä¸çè¤éç©ºéåæï¼å¿½ç¥äºåæå¤è§£æåº¦ç©ºéåæééç¯ç¸äºä¾è³´æ§ãæ­¤å¤ï¼å®åä¸å¤ªå¯è½èæ®ç¹æ®çåºç·æ¼ç§»åé¡ä»¥åé«çæéåºåçå¤è¦è§ç¹æ§ï¼éå¨å¾å¤§ç¨åº¦ä¸é»ç¤äºå®åçé æ¸¬æè½ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºä¸åå¤è§£æåº¦æç©ºåå½¢å­¸ç¿æ¶æ§ MedGNNï¼ç¨æ¼é«çæéåºååé¡ãå·é«ä¾èªªï¼æåé¦åæåºæ§å»ºå¤è§£æåº¦èªé©æåå½¢çµæ§ä»¥å­¸ç¿åæå¤å°ºåº¦åµå¥ãç¶å¾ï¼çºäºè§£æ±ºåºç·æ¼ç§»åé¡ï¼æåæåºå·®åæ³¨æåç¶²è·¯ï¼å°æéå»ºæ¨¡çæéå·®åéç®èªæ³¨æåæ©å¶ãæ­¤å¤ï¼çºäºå­¸ç¿å¤è¦è§ç¹æ§ï¼æåå©ç¨é »çå·ç©ç¶²è·¯å¾é »åæ·åé«çæéåºåçäºè£è³è¨ãæ­¤å¤ï¼æåå¼å¥äºå¤è§£æåº¦åå½¢Transformeræ¶æ§ä¾å»ºæ¨¡åæä¾è³´æ§ï¼ä¸¦èåä¾èªä¸åè§£æåº¦çè³è¨ãæå¾ï¼æåå°å¤åé«ççå¯¦ä¸çè³æéé²è¡äºå»£æ³çå¯¦é©ï¼è­æäºæåæ¹æ³çåªç°æè½ãæåçç¨å¼ç¢¼å·²å¬éã</paragraph>

##### **Integrating Generative Artificial Intelligence in ADRD: A Framework for Streamlining Diagnosis and Care in Neurodegenerative Diseases**
2502.06842v1 by Andrew G. Breithaupt, Alice Tang, Bruce L. Miller, Pedro Pinheiro-Chagas

Healthcare systems are struggling to meet the growing demand for neurological
care, with challenges particularly acute in Alzheimer's disease and related
dementias (ADRD). While artificial intelligence research has often focused on
identifying patterns beyond human perception, implementing such predictive
capabilities remains challenging as clinicians cannot readily verify insights
they cannot themselves detect. We propose that large language models (LLMs)
offer more immediately practical applications by enhancing clinicians'
capabilities in three critical areas: comprehensive data collection,
interpretation of complex clinical information, and timely application of
relevant medical knowledge. These challenges stem from limited time for proper
diagnosis, growing data complexity, and an overwhelming volume of medical
literature that exceeds any clinician's capacity to fully master. We present a
framework for responsible AI integration that leverages LLMs' ability to
communicate effectively with both patients and providers while maintaining
human oversight. This approach prioritizes standardized, high-quality data
collection to enable a system that learns from every patient encounter while
incorporating the latest clinical evidence, continuously improving care
delivery. We begin to address implementation challenges and initiate important
discussions around ethical considerations and governance needs. While developed
for ADRD, this roadmap provides principles for responsible AI integration
across neurology and other medical specialties, with potential to improve
diagnostic accuracy, reduce care disparities, and advance clinical knowledge
through a learning healthcare system.

æè¦ï¼é«çé«ç³»æ­£åªåæ»¿è¶³æ¥çå¢é·çç¥ç¶ç§è­·éæ±ï¼å¶ä¸­é¿è²æµ·é»çåç¸éå¤±æºç (ADRD) çææ°ç¹å¥å´éãéç¶äººå·¥æºæ§ç ç©¶éå¸¸å°æ³¨æ¼è­å¥äººé¡æç¥ä¹å¤çæ¨¡å¼ï¼ä½å¯¦ä½æ­¤é¡é æ¸¬åè½ä»ç¶å·æææ°æ§ï¼å çºè¨åºé«çç¡æ³è¼æé©è­ä»åèªå·±ç¡æ³åµæ¸¬å°çè¦è§£ãæåæåºå¤§åèªè¨æ¨¡å (LLM) å¯ééæåè¨åºé«çå¨ä¸åééµé åçè½åï¼æä¾æ´ç´æ¥ä¸å¯¦ç¨çæç¨ï¼å¨é¢çè³ææ¶éãè¤éè¨åºè³è¨çè©®éï¼ä»¥åé©ææç¨ç¸éçé«å­¸ç¥è­ãéäºææ°æºèªæ¼é©ç¶è¨ºæ·æéæéãè³æè¤éæ§æ¥çå¢å ï¼ä»¥åé¾å¤§çé«å­¸æç»éè¶éä»»ä½è¨åºé«çæè½å®å¨ææ¡çå®¹éãæåæåºäºä¸åè² è²¬ä»»ç AI æ´åæ¶æ§ï¼å©ç¨ LLM èæ£èåæä¾èæææºéçè½åï¼åæç¶­æäººçºç£ç£ãæ­¤æ¹æ³åªåèæ®æ¨æºåãé«åè³ªçè³ææ¶éï¼ä»¥å»ºç«ä¸åå¾æ¯æ¬¡æ£èæ¥è§¸ä¸­å­¸ç¿çç³»çµ±ï¼åæç´å¥ææ°çè¨åºè­æï¼æçºæ¹åç§è­·æä¾ãæåéå§æ¢è¨å¯¦ä½ææ°ï¼ä¸¦å±ééæ¼å«çèéåæ²»çéæ±çéè¦è¨è«ãåç®¡æ¯çº ADRD æéç¼ï¼æ­¤èåæä¾äºç¥ç¶ç§åå¶ä»é«å­¸å°ç§è² è²¬ä»» AI æ´åçååï¼ææ½åééå­¸ç¿åé«çä¿å¥ç³»çµ±æ¹åè¨ºæ·æºç¢ºæ§ãæ¸å°ç§è­·å·®ç°ï¼ä¸¦æ¨é²è¨åºç¥è­ã

##### **Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions**
2502.04423v1 by Khushboo Verma, Alan Michels, Ergi Gumusaneli, Shilpa Chitnis, Smita Sinha Kumar, Christopher Thompson, Lena Esmail, Guruprasath Srinivasan, Chandini Panchada, Sushovan Guha, Satwant Kumar

Referral workflow inefficiencies, including misaligned referrals and delays,
contribute to suboptimal patient outcomes and higher healthcare costs. In this
study, we investigated the possibility of predicting procedural needs based on
primary care diagnostic entries, thereby improving referral accuracy,
streamlining workflows, and providing better care to patients. A de-identified
dataset of 2,086 orthopedic referrals from the University of Texas Health at
Tyler was analyzed using machine learning models built on Base General
Embeddings (BGE) for semantic extraction. To ensure real-world applicability,
noise tolerance experiments were conducted, and oversampling techniques were
employed to mitigate class imbalance. The selected optimum and parsimonious
embedding model demonstrated high predictive accuracy (ROC-AUC: 0.874, Matthews
Correlation Coefficient (MCC): 0.540), effectively distinguishing patients
requiring surgical intervention. Dimensionality reduction techniques confirmed
the model's ability to capture meaningful clinical relationships. A threshold
sensitivity analysis identified an optimal decision threshold (0.30) to balance
precision and recall, maximizing referral efficiency. In the predictive
modeling analysis, the procedure rate increased from 11.27% to an optimal
60.1%, representing a 433% improvement with significant implications for
operational efficiency and healthcare revenue.
  The results of our study demonstrate that referral optimization can enhance
primary and surgical care integration. Through this approach, precise and
timely predictions of procedural requirements can be made, thereby minimizing
delays, improving surgical planning, and reducing administrative burdens. In
addition, the findings highlight the potential of clinical decision support as
a scalable solution for improving patient outcomes and the efficiency of the
healthcare system.

æè¦ï¼è½è¨ºæµç¨æçä½è½ï¼åæ¬è½è¨ºä¸ç¶åå»¶èª¤ï¼
å°è´æ¬¡åªçæ£èçµæåæ´é«çé«çä¿å¥ææ¬ãå¨é
é ç ç©¶ä¸­ï¼æåæ¢è¨äºæ ¹æåç´ä¿å¥è¨ºæ·æ¢ç®é æ¸¬ç¨åºéæ±çå¯è½æ§ï¼å¾èæé«è½è¨ºæºç¢ºæ§ï¼
ç°¡åå·¥ä½æµç¨ï¼ä¸¦çºæ£èæä¾æ´å¥½çç§è­·ãä¸åå»è­å¥å
å¾·åè©æ¯å¤§å­¸å¥åº·ä¸­å¿ç 2,086 åéª¨ç§è½è¨ºçè³æé
æ³°åä½¿ç¨å»ºç«å¨åºæ¬éç¨
èªç¾©æåçåµå¥ (BGE) ä¸çæ©å¨å­¸ç¿æ¨¡åé²è¡åæãçºäºç¢ºä¿ç¾å¯¦ä¸ççé©ç¨æ§ï¼
é²è¡äºåªè²å®¹å¿åº¦å¯¦é©ï¼ä¸¦æ¡ç¨äºéæ¡æ¨£æè¡ä¾æ¸è¼é¡å¥ä¸å¹³è¡¡ãæé¸çæä½³åç°¡ç´
åµå¥æ¨¡åå±ç¤ºäºé«é æ¸¬æºç¢ºåº¦ (ROC-AUCï¼0.874ï¼é¦¬ä¿®æ¯
ç¸éç³»æ¸ (MCC)ï¼0.540)ï¼ææååéè¦æè¡å¹²é çæ£èãéç¶­
æè¡è­å¯¦äºæ¨¡åææææç¾©çè¨åºéä¿çè½åãé¾å¼
æææ§åæç¢ºå®äºä¸åæä½³æ±ºç­é¾å¼ (0.30) ä¾å¹³è¡¡
ç²¾ç¢ºåº¦åå¬åçï¼æå¤§åè½è¨ºæçãå¨é æ¸¬ä¸­
å»ºæ¨¡åæä¸­ï¼ç¨åºçå¾ 11.27% å¢å å°æä½³ç
60.1%ï¼ä»£è¡¨ 433% çæ¹é²ï¼å°éçæçåé«çä¿å¥æ¶å¥å·æéå¤§å½±é¿ã
æåç ç©¶ççµæè¡¨æï¼è½è¨ºåªåå¯ä»¥å¢å¼·
åç´åå¤ç§è­·çæ´åãéééç¨®æ¹æ³ï¼å¯ä»¥å°ç¨åºéæ±é²è¡æºç¢ºåæçé æ¸¬ï¼å¾èæå¤§ç¨åº¦å°æ¸å°
å»¶èª¤ï¼æ¹åæè¡è¨åï¼ä¸¦æ¸è¼è¡æ¿è² æãæ­¤å¤ï¼ç ç©¶çµæå¼·èª¿äºè¨åºæ±ºç­æ¯æä½çº
ä¸åå¯æ´å±çè§£æ±ºæ¹æ¡çæ½åï¼ç¨æ¼æ¹åæ£èçµæåé«çä¿å¥ç³»çµ±çæçã

##### **Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation**
2502.04083v1 by Tewele W. Tareke, Neree Payan, Alexandre Cochet, Laurent Arnould, Benoit Presles, Jean-Marc Vrigneaud, Fabrice Meriaudeau, Alain Lalande

Neoadjuvant chemotherapy (NAC) has become a standard clinical practice for
tumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography
(PET). Our work aims to leverage PET imaging for the segmentation of breast
lesions. The focus is on developing an automated system that accurately
segments primary tumor regions and extracts key biomarkers from these areas to
provide insights into the evolution of breast cancer following the first course
of NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PET
scans (PET_Fu) were acquired before and after the first course of NAC,
respectively. Firstly, a deep learning-based breast tumor segmentation method
was developed. The optimal baseline model (model trained on baseline exams) was
fine-tuned on 15 follow-up exams and adapted using active learning to segment
tumor areas in PET_Fu. The pipeline computes biomarkers such as maximum
standardized uptake value (SUVmax), metabolic tumor volume (MTV), and total
lesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.
Quality control measures were employed to exclude aberrant outliers. The nnUNet
deep learning model outperformed in tumor segmentation on PET_Bl, achieved a
Dice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52
mm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mm
on PET_Fu exams. Biomarkers analysis revealed very strong correlations whatever
the biomarker between manually segmented and automatically predicted regions.
The significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3
and 19.23 cm3, respectively. The presented approach demonstrates an automated
system for breast tumor segmentation from 18F-FDG PET. Thanks to the extracted
biomarkers, our method enables the automatic assessment of cancer progression.

æè¦ï¼æ°è¾å©åç (NAC) å·²æä¸ºä¹³èºçä¸­éç¨ 18F-FDG æ­£çµå­åå°æ­å±æ«æ (PET) è¿è¡è¿ç¤ç¼©å°çæ åä¸´åºå®è·µãæä»¬çå·¥ä½æ¨å¨å©ç¨ PET å½±ååå²ä¹³èºçåãéç¹å¨äºå¼åä¸ä¸ªèªå¨ç³»ç»ï¼è¯¥ç³»ç»å¯ä»¥åç¡®åå²ååæ§è¿ç¤åºåå¹¶ä»è¿äºåºåæåå³é®çç©æ è®°ï¼ä»¥æ·±å¥äºè§£ä¹³èºçå¨ç¬¬ä¸çç¨ NAC åçæ¼åãåå«å¨ç¬¬ä¸çç¨ NAC ä¹ååä¹åééäº 243 ä¾åºçº¿ 18F-FDG PET æ«æ (PET_Bl) å 180 ä¾éè®¿ 18F-FDG PET æ«æ (PET_Fu)ãé¦åï¼å¼åäºä¸ç§åºäºæ·±åº¦å­¦ä¹ çä¹³èºè¿ç¤åå²æ¹æ³ãå¯¹ 15 ä¾éè®¿æ£æ¥å¯¹æä¼åºçº¿æ¨¡åï¼å¨åºçº¿æ£æ¥ä¸­è®­ç»çæ¨¡åï¼è¿è¡äºå¾®è°ï¼å¹¶ä½¿ç¨ä¸»å¨å­¦ä¹ å¯¹ PET_Fu ä¸­çè¿ç¤åºåè¿è¡äºåå²ãè¯¥ç®¡éè®¡ç®è¯¸å¦æå¤§æ åæåå¼ (SUVmax)ãä»£è°¢è¿ç¤ä½ç§¯ (MTV) åæ»çç¶ç³éµè§£ (TLG) ç­çç©æ è®°ï¼ä»¥è¯ä¼° PET_Fu å PET_Bl ä¹é´çè¿ç¤æ¼åãéç¨è´¨éæ§å¶æªæ½æ¥æé¤å¼å¸¸å¼ãnnUNet æ·±åº¦å­¦ä¹ æ¨¡åå¨ PET_Bl ä¸çè¿ç¤åå²æ¹é¢è¡¨ç°åºè²ï¼è¾¾å° 0.89 ç Dice ç¸ä¼¼æ§ç³»æ° (DSC) å 3.52 æ¯«ç±³ç Hausdorff è·ç¦» (HD)ãå¾®è°åï¼è¯¥æ¨¡åå¨ PET_Fu æ£æ¥ä¸­æ¾ç¤ºåº 0.78 ç DSC å 4.95 æ¯«ç±³ç HDãæ è®ºæå¨åå²åºååèªå¨é¢æµåºåä¹é´ççç©æ è®°å¦ä½ï¼çç©æ è®°åæé½æ¾ç¤ºåºéå¸¸å¼ºçç¸å³æ§ãSUVmaxãMTV å TLG çå¹³åæ¾çä¸éåå«ä¸º 5.22ã11.79 cm3 å 19.23 cm3ãææåºçæ¹æ³å±ç¤ºäºä¸ä¸ªç¨äºä» 18F-FDG PET åå²ä¹³èºè¿ç¤çèªå¨åç³»ç»ãç±äºæåäºçç©æ è®°ï¼æä»¬çæ¹æ³è½å¤èªå¨è¯ä¼°ççè¿å±ã

##### **Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization**
2502.04034v1 by Ran Song, Yinpu Bai, Hui Liu

The accurate prediction of drug responses remains a formidable challenge,
particularly at the single-cell level and in clinical treatment contexts. Some
studies employ transfer learning techniques to predict drug responses in
individual cells and patients, but they require access to target-domain data
during training, which is often unavailable or only obtainable in future. In
this study, we propose a novel domain generalization framework, termed
panCancerDR, to address this challenge. We conceptualize each cancer type as a
distinct source domain, with its cell lines serving as domain-specific samples.
Our primary objective is to extract domain-invariant features from the
expression profiles of cell lines across diverse cancer types, thereby
generalize the predictive capacity to out-of-distribution samples. To enhance
robustness, we introduce a latent independence projection (LIP) module that
encourages the encoder to extract informative yet non-redundant features. Also,
we propose an asymmetric adaptive clustering constraint, which clusters
drug-sensitive samples into a compact group while drives resistant samples
dispersed across separate clusters in the latent space. Our empirical
experiments demonstrate that panCancerDR effectively learns task-relevant
features from diverse source domains, and achieves accurate predictions of drug
response for unseen cancer type during training. Furthermore, when evaluated on
single-cell and patient-level prediction tasks, our model-trained solely on in
vitro cell line data without access to target-domain information-consistently
outperforms and matched current state-of-the-art methods. These findings
highlights the potential of our method for real-world clinical applications.

æè¦ï¼<paragraph>æºç¢ºé æ¸¬è¥ç©åæä»ç¶æ¯ä¸é è±éçææ°ï¼ç¹å¥æ¯å¨å®ç´°èå±¤ç´åè¨åºæ²»çèæ¯ä¸­ãä¸äºç ç©¶æ¡ç¨é·ç§»å­¸ç¿æè¡ä¾é æ¸¬åå¥ç´°èåæ£èçè¥ç©åæï¼ä½å®åéè¦å¨è¨ç·´æéå­åç®æ¨ç¶²åè³æï¼èéäºè³æéå¸¸ç¡æ³åå¾ï¼æåªè½å¨æªä¾åå¾ãå¨éé ç ç©¶ä¸­ï¼æåæåºä¸åæ°ç©çç¶²åæ¦åæ¶æ§ï¼ç¨±çº panCancerDRï¼ä»¥æå°éé ææ°ãæåå°æ¯ç¨®é¡åçççæ¦å¿µåçºä¸åä¸åçä¾æºç¶²åï¼å¶ç´°èæ ªä½çºç¹å®ç¶²åçæ¨£æ¬ãæåçé¦è¦ç®æ¨æ¯å¾ä¸åççé¡åçç´°èæ ªè¡¨ç¾ç¹å¾µä¸­èåç¶²åä¸è®ç¹å¾µï¼å¾èå°é æ¸¬è½åæ¦åå°åå¸å¤çæ¨£æ¬ãçºäºå¢å¼·ç©©å¥æ§ï¼æåå¼å¥ä¸åæ½å¨ç¨ç«æå½± (LIP) æ¨¡çµï¼é¼åµç·¨ç¢¼å¨èåæè³è¨ä½éåé¤çç¹å¾µãæ­¤å¤ï¼æåæåºä¸åéå°ç¨±èªé©æèé¡ç´æï¼å°å°è¥ç©ææçæ¨£æ¬èé¡å°ä¸åç·æ¹çç¾¤çµä¸­ï¼åæé©åæè¥æ§æ¨£æ¬åæ£å¨æ½å¨ç©ºéä¸­çä¸åç¾¤çµä¸­ãæåçå¯¦è­å¯¦é©è­æï¼panCancerDR ææå°å¾ä¸åçä¾æºç¶²åå­¸ç¿èä»»åç¸éçç¹å¾µï¼ä¸¦å¨è¨ç·´æéå°æªè¦çççé¡åå¯¦ç¾æºç¢ºçè¥ç©åæé æ¸¬ãæ­¤å¤ï¼ç¶å¨å®ç´°èåæ£èå±¤ç´é æ¸¬ä»»åä¸­é²è¡è©ä¼°æï¼æåçæ¨¡ååå¨é«å¤ç´°èæ ªè³æä¸è¨ç·´ï¼èæ²æå­åç®æ¨ç¶²åè³è¨ï¼å§çµåªæ¼ä¸¦ç¬¦åç¶åçææ°æ¹æ³ãéäºç¼ç¾çªé¡¯äºæåçæ¹æ³å¨å¯¦éè¨åºæç¨ä¸­çæ½åã</paragraph>

##### **MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**
2502.04413v1 by Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao

Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) æ¯ä¸ç¨®é©ç¨æ¼æª¢ç´¢é±ç§ææçé»å­å¥åº·è¨é (EHR) çæè¡ãå®å¯ä»¥ä½çºé«çä¿å¥å¯é§é§çä¸åééµæ¨¡çµï¼åå©æ¸å°é«çä¿å¥å¾æ¥­äººå¡åæ£èçèª¤è¨ºãç¶èï¼å¨é«çé åä¸­ä½¿ç¨çç¾æåºæ¼åç¼æ³ç RAG æ¨¡åçè¨ºæ·æºç¢ºæ§åç¹ç°æ§ä¸è¶³ï¼ç¹å¥æ¯å°æ¼å·æé¡ä¼¼è¡¨ç¾çç¾çãæ¬ææåº MedRAGï¼ä¸ç¨®ç±ç¥è­åè­ (KG) å¼ç¼çæ¨çå¢å¼·ç RAG æ¨¡åï¼ç¨æ¼é«çé åï¼å®æ ¹æè¡¨ç¾æª¢ç´¢è¨ºæ·åæ²»çå»ºè­°ãMedRAG ç³»çµ±æ§å°æ§å»ºäºä¸åå¨é¢çåå±¤éå±¤å¼è¨ºæ· KGï¼æ¶µèåç¨®ç¾ççééµè¨ºæ·å·®ç°ãéäºå·®ç°èå¾ EHR è³æåº«ä¸­æª¢ç´¢å°çé¡ä¼¼ EHR åææ´åï¼ä¸¦å¨å¤§åèªè¨æ¨¡åä¸­é²è¡æ¨çãéåéç¨å¯ä»¥å¯¦ç¾æ´æºç¢ºåå·é«çæ±ºç­æ¯æ´ï¼åæä¸»åæä¾å¾çºåé¡ï¼ä»¥å¢å¼·åäººåé«çæ±ºç­å¶å®ãMedRAG å¨å¬å±è³æé DDXPlus åå¾é³ç¯¤çé«é¢æ¶éçç§äººæ¢æ§ç¼çè¨ºæ·è³æé (CPDD) ä¸é²è¡è©ä¼°ï¼ä¸¦å°å¶æè½èåç¨®ç¾æ RAG æ¹æ³é²è¡æ¯è¼ãå¯¦é©çµæé¡¯ç¤ºï¼å©ç¨ KG çè³è¨æ´ååéä¿è½åï¼æåç MedRAG æä¾äºæ´å·é«çè¨ºæ·è¦è§£ï¼ä¸¦å¨éä½èª¤è¨ºçæ¹é¢åªæ¼æåé²çæ¨¡åãæåçç¨å¼ç¢¼å°å¨ https://github.com/SNOWTEAM2023/MedRAG æä¾

##### **Transforming Multimodal Models into Action Models for Radiotherapy**
2502.04408v1 by Matteo Ferrante, Alessandra Carosi, Rolando Maria D Angelillo, Nicola Toschi

Radiotherapy is a crucial cancer treatment that demands precise planning to
balance tumor eradication and preservation of healthy tissue. Traditional
treatment planning (TP) is iterative, time-consuming, and reliant on human
expertise, which can potentially introduce variability and inefficiency. We
propose a novel framework to transform a large multimodal foundation model
(MLM) into an action model for TP using a few-shot reinforcement learning (RL)
approach. Our method leverages the MLM's extensive pre-existing knowledge of
physics, radiation, and anatomy, enhancing it through a few-shot learning
process. This allows the model to iteratively improve treatment plans using a
Monte Carlo simulator. Our results demonstrate that this method outperforms
conventional RL-based approaches in both quality and efficiency, achieving
higher reward scores and more optimal dose distributions in simulations on
prostate cancer data. This proof-of-concept suggests a promising direction for
integrating advanced AI models into clinical workflows, potentially enhancing
the speed, quality, and standardization of radiotherapy treatment planning.

æè¦ï¼æ¾å°æ²»çæ¯ä¸ç¨®éè¦çççæ²»çæ¹æ³ï¼éè¦ç²¾ç¢ºçè¦åä¾å¹³è¡¡è«ç¤æ ¹é¤åå¥åº·çµç¹çä¿çãå³çµ±çæ²»çè¦åï¼TPï¼æ¯åè¦çãèæçï¼ä¸¦ä¸ä¾è³´æ¼äººçºå°æ¥­ç¥è­ï¼éå¯è½æå¼å¥è®ç°æ§åä½æçãæåæåºäºä¸åæ°ç©çæ¡æ¶ï¼ä½¿ç¨å°æ¬¡å¼·åå­¸ç¿ (RL) æ¹æ³å°å¤§åå¤æ¨¡æåºç¤æ¨¡å (MLM) è½æçº TP çåä½æ¨¡åãæåçæ¨¡åå©ç¨äº MLM å°ç©çãè¼»å°åè§£åå­¸çå»£æ³é åå­å¨çç¥è­ï¼ä¸¦ééå°æ¬¡å­¸ç¿éç¨å°å¶é²è¡å¢å¼·ãéåè¨±æ¨¡åä½¿ç¨èç¹å¡ç¾æ¨¡æ¬å¨åè¦æ¹é²æ²»çè¨åãæåççµæè¡¨æï¼éç¨®æ¹æ³å¨è³ªéåæçæ¹é¢é½åªæ¼åºæ¼å³çµ± RL çæ¹æ³ï¼å¨å°ååèºçæ¸æé²è¡æ¨¡æ¬æï¼ç²å¾äºæ´é«ççåµåæ¸åæ´åªåçåéåä½ãéåæ¦å¿µé©è­è¡¨æäºä¸åæå¸æçæ¹åï¼å³å°åé²çäººå·¥æºæ§æ¨¡åæ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼å¾èæå¯è½æé«æ¾å°æ²»çè¨åçéåº¦ãè³ªéåæ¨æºåã

##### **Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning**
2502.04399v1 by Bokeng Zheng, Bo Rao, Tianxiang Zhu, Chee Wei Tan, Jingpu Duan, Zhi Zhou, Xu Chen, Xiaoxi Zhang

Advances in artificial intelligence (AI) including foundation models (FMs),
are increasingly transforming human society, with smart city driving the
evolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged as
a key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.
In particular, ride-hailing vehicles can effectively facilitate flexible data
collection and contribute towards urban intelligence, despite resource
limitations. Therefore, this work explores a promising scenario, where
edge-assisted vehicles perform joint tasks of order serving and the emerging
foundation model fine-tuning using various urban data. However, integrating the
VCS AI task with the conventional order serving task is challenging, due to
their inconsistent spatio-temporal characteristics: (i) The distributions of
ride orders and data point-of-interests (PoIs) may not coincide in geography,
both following a priori unknown patterns; (ii) they have distinct forms of
temporal effects, i.e., prolonged waiting makes orders become instantly invalid
while data with increased staleness gradually reduces its utility for model
fine-tuning.To overcome these obstacles, we propose an online framework based
on multi-agent reinforcement learning (MARL) with careful augmentation. A new
quality-of-service (QoS) metric is designed to characterize and balance the
utility of the two joint tasks, under the effects of varying data volumes and
staleness. We also integrate graph neural networks (GNNs) with MARL to enhance
state representations, capturing graph-structured, time-varying dependencies
among vehicles and across locations. Extensive experiments on our testbed
simulator, utilizing various real-world foundation model fine-tuning tasks and
the New York City Taxi ride order dataset, demonstrate the advantage of our
proposed method.

æè¦ï¼äººå·¥æºè½ï¼AIï¼çé²å±ï¼åæ¬åºç¤æ¨¡åï¼FMï¼ï¼æ­£æ¥çè½è®äººé¡ç¤¾æï¼æºæ§åå¸æ¨åèåå¸çæ´»çæ¼é²ãåæï¼è»è¼ç¾¤ææ¸¬ï¼VCSï¼å·²æçºééµæ¨åå ç´ ï¼å©ç¨è»è¼çæ©åæ§åéåææ¸¬å¨çè½åãç¹å¥æ¯ï¼åç®¡æè³æºéå¶ï¼å«è»æåè»è¼è½ææä¿é²éæ´»çè³ææ¶éï¼ä¸¦æå©æ¼åå¸æºæ§ãå æ­¤ï¼éé å·¥ä½æ¢ç´¢äºä¸åæåéçå ´æ¯ï¼å¶ä¸­éç·£è¼å©è»è¼å·è¡è¨å®æååæ°èåºç¤æ¨¡åå¾®èª¿çè¯åä»»åï¼ä½¿ç¨åç¨®åå¸è³æãç¶èï¼ç±æ¼ VCS AI ä»»åèå³çµ±è¨å®æåä»»åçä¸ä¸è´æç©ºç¹å¾µï¼æ´åå®åå·æææ°æ§ï¼(i) å«è»è¨å®åè³ææèè¶£é» (PoI) çåä½å¨å°åä¸å¯è½ä¸éåï¼å©èé½éµå¾ªåé©æªç¥çæ¨¡å¼ï¼(ii) å®åå·æä¸åçæéææå½¢å¼ï¼å³é·æéç­å¾æä½¿è¨å®ç«å³å¤±æï¼èéæçè³ææéæ¼¸éä½å¶å°æ¨¡åå¾®èª¿çæç¨ãçºäºè§£æ±ºéäºéç¤ï¼æåæåºäºä¸ååºæ¼å¤æºè½é«å¼·åå­¸ç¿ (MARL) çç·ä¸æ¶æ§ï¼ä¸¦é²è¡äºä»ç´°çæ´åãè¨­è¨äºä¸åæ°çæååè³ª (QoS) ææ¨ï¼ç¨æ¼è¡¨å¾µåå¹³è¡¡éå©åè¯åä»»åçæç¨ï¼å¨ä¸åè³æéåéææ§çå½±é¿ä¸ãæåéå°åç¥ç¶ç¶²è·¯ï¼GNNï¼è MARL æ´åï¼ä»¥å¢å¼·çæè¡¨ç¤ºï¼ææè»è¼ä¹éåä¸åå°é»ä¹éçåçµæ§ãæè®ä¾è³´æ§ãå¨æåçæ¸¬è©¦å¹³å°æ¨¡æ¬å¨ä¸é²è¡çå»£æ³å¯¦é©ï¼å©ç¨åç¨®çå¯¦ä¸ççåºç¤æ¨¡åå¾®èª¿ä»»ååç´ç´å¸è¨ç¨è»å«è»è¨å®è³æéï¼è­æäºæåæåºçæ¹æ³çåªé»ã

##### **Multimodal Medical Code Tokenizer**
2502.04397v2 by Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik

Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.

æè¦ï¼<paragraph>å¨æ£èçµå­å¥åº·è®°å½ (EHR) ä¸è®­ç»çåºç¡æ¨¡åéè¦å°å»å­¦æ°æ®æ è®°ä¸ºç¦»æ£è¯æ±é¡¹åºåãç°æçæ è®°å¨å° EHR ä¸­çå»å­¦ä»£ç è§ä¸ºå­¤ç«çææ¬æ è®°ãç¶èï¼æ¯ä¸ªå»å­¦ä»£ç é½ç±å¶ææ¬æè¿°ãå¨æ¬ä½å±æ¬¡ç»æä¸­çä½ç½®ä»¥åä¸å¶ä»ä»£ç çå³ç³»ï¼ä¾å¦ç¾çå±ç°åè¯ç©æ²»çå³èï¼æ¥å®ä¹ãå»å­¦è¯æ±è¡¨åå«è¶è¿ 600,000 ä¸ªä»£ç ï¼è¿äºä»£ç åå«ä¸´åºæ¨ççå³é®ä¿¡æ¯ãæä»¬å¼å¥äº MedTokï¼è¿æ¯ä¸ç§å¤æ¨¡æå»å­¦ä»£ç æ è®°å¨ï¼å®ä½¿ç¨ææ¬æè¿°åä»£ç çå³ç³»ä¸ä¸æãMedTok ä½¿ç¨è¯­è¨æ¨¡åç¼ç å¨å¤çææ¬ï¼å¹¶ä½¿ç¨å¾ç¼ç å¨å¯¹å³ç³»ç»æè¿è¡ç¼ç ãç¶åï¼å®å°è¿ä¸¤ç§æ¨¡æéåä¸ºä¸ä¸ªç»ä¸çæ è®°ç©ºé´ï¼ä¿çç¹å®äºæ¨¡æåè·¨æ¨¡æçä¿¡æ¯ãæä»¬å° MedTok éæå°äºä¸ª EHR æ¨¡åä¸­ï¼å¹¶å¨ä½é¢åé¨è¯æ°æ®éï¼åæ¬ç»æé¢æµãè¯æ­åç±»ãè¯ç©æ¨èåé£é©åå±ï¼ä¸å¯¹å¶å®æ½æä½åä¸´åºä»»å¡è¿è¡è¯ä¼°ãç¨ MedTok æ¿æ¢æ å EHR æ è®°å¨å¯æé«ææ EHR æ¨¡åç AUPRCï¼å¨ MIMIC-III ä¸æé« 4.10%ï¼å¨ MIMIC-IV ä¸æé« 4.78%ï¼å¨ EHRShot ä¸æé« 11.30%ï¼å¶ä¸­è¯ç©æ¨èçå¢çæå¤§ãé¤äº EHR å»ºæ¨¡ä¹å¤ï¼æä»¬è¿æ¼ç¤ºäºå° MedTok æ è®°å¨ä¸å»å­¦é®ç­ç³»ç»ç»åä½¿ç¨ãæä»¬çç»æè¯æäº MedTok ä½ä¸ºå»å­¦ä»£ç çç»ä¸æ è®°å¨çæ½åï¼æ¹è¿äºå»å­¦åºç¡æ¨¡åçæ è®°åã</paragraph>

##### **A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma**
2502.03772v1 by Chaoyin She, Ruifang Lu, Danni He, Jiayi Lv, Yadan Lin, Meiqing Cheng, Hui Huang, Lida Chen, Wei Wang, Qinghua Huang

Hepatocellular carcinoma (HCC) ranks as the third leading cause of
cancer-related mortality worldwide, with early detection being crucial for
improving patient survival rates. However, early screening for HCC using
ultrasound suffers from insufficient sensitivity and is highly dependent on the
expertise of radiologists for interpretation. Leveraging the latest
advancements in artificial intelligence (AI) in medical imaging, this study
proposes an innovative Hierarchical Sparse Query Transformer (HSQformer) model
that combines the strengths of Convolutional Neural Networks (CNNs) and Vision
Transformers (ViTs) to enhance the accuracy of HCC diagnosis in ultrasound
screening. The HSQformer leverages sparse latent space representations to
capture hierarchical details at various granularities without the need for
complex adjustments, and adopts a modular, plug-and-play design philosophy,
ensuring the model's versatility and ease of use. The HSQformer's performance
was rigorously tested across three distinct clinical scenarios: single-center,
multi-center, and high-risk patient testing. In each of these settings, it
consistently outperformed existing state-of-the-art models, such as ConvNext
and SwinTransformer. Notably, the HSQformer even matched the diagnostic
capabilities of senior radiologists and comprehensively surpassed those of
junior radiologists. The experimental results from this study strongly
demonstrate the effectiveness and clinical potential of AI-assisted tools in
HCC screening. The full code is available at
https://github.com/Asunatan/HSQformer.

æè¦ï¼èç´°èçï¼HCCï¼æ¯å¨çç¬¬ä¸å¤§ççç¸éæ­»äº¡åå ï¼æ©ææª¢æ¸¬å°æ¼æé«æ£èå­æ´»çè³ééè¦ãç¶èï¼ä½¿ç¨è¶é³æ³¢é²è¡ HCC æ©æç¯©æª¢çéæåº¦ä¸è¶³ï¼ä¸é«åº¦ä¾è³´æ¾å°ç§é«å¸«çå°æ¥­ç¥è­é²è¡å¤è®ãæ¬ç ç©¶å©ç¨é«å­¸å½±åä¸­äººå·¥æºæ§ï¼AIï¼çææ°é²å±ï¼æåºäºä¸ç¨®åµæ°çåå±¤ç¨çæ¥è©¢Transformerï¼HSQformerï¼æ¨¡åï¼çµåäºå·ç©ç¥ç¶ç¶²è·¯ï¼CNNï¼åè¦è¦ºTransformerï¼ViTï¼çåªé»ï¼ä»¥æé«è¶é³æ³¢ç¯©æª¢ä¸­ HCC è¨ºæ·çæºç¢ºæ§ãHSQformer å©ç¨ç¨çæ½å¨ç©ºéè¡¨ç¤ºï¼å¨ä¸éè¦è¤éèª¿æ´çææ³ä¸æ·ååç¨®ç²åº¦å±¤ç´çç´°ç¯ï¼ä¸¦æ¡ç¨æ¨¡çµåãå³æå³ç¨çè¨­è¨çå¿µï¼ç¢ºä¿æ¨¡åçå¤åè½æ§åæç¨æ§ãHSQformer çæè½ç¶éä¸åä¸åçè¨åºå ´æ¯çå´æ ¼æ¸¬è©¦ï¼å®ä¸­å¿ãå¤ä¸­å¿åé«é¢¨éªæ£èæ¸¬è©¦ãå¨éäºè¨­å®ä¸­ï¼å®å§çµåªæ¼ç¾æçæåé²æ¨¡åï¼ä¾å¦ ConvNext å SwinTransformerãå¼å¾æ³¨æçæ¯ï¼HSQformer çè³å¹éäºè³æ·±æ¾å°ç§é«å¸«çè¨ºæ·è½åï¼ä¸¦å¨é¢è¶è¶äºåç´æ¾å°ç§é«å¸«çè¨ºæ·è½åãæ¬ç ç©¶çå¯¦é©çµææåå°è­æäº AI è¼å©å·¥å·å¨ HCC ç¯©æª¢ä¸­çæææ§åè¨åºæ½åãå®æ´ç¨å¼ç¢¼å¯å¨ https://github.com/Asunatan/HSQformer åå¾ã

##### **Towards Fair Medical AI: Adversarial Debiasing of 3D CT Foundation Embeddings**
2502.04386v1 by Guangyao Zheng, Michael A. Jacobs, Vladimir Braverman, Vishwa S. Parekh

Self-supervised learning has revolutionized medical imaging by enabling
efficient and generalizable feature extraction from large-scale unlabeled
datasets. Recently, self-supervised foundation models have been extended to
three-dimensional (3D) computed tomography (CT) data, generating compact,
information-rich embeddings with 1408 features that achieve state-of-the-art
performance on downstream tasks such as intracranial hemorrhage detection and
lung cancer risk forecasting. However, these embeddings have been shown to
encode demographic information, such as age, sex, and race, which poses a
significant risk to the fairness of clinical applications.
  In this work, we propose a Variation Autoencoder (VAE) based adversarial
debiasing framework to transform these embeddings into a new latent space where
demographic information is no longer encoded, while maintaining the performance
of critical downstream tasks. We validated our approach on the NLST lung cancer
screening dataset, demonstrating that the debiased embeddings effectively
eliminate multiple encoded demographic information and improve fairness without
compromising predictive accuracy for lung cancer risk at 1-year and 2-year
intervals. Additionally, our approach ensures the embeddings are robust against
adversarial bias attacks. These results highlight the potential of adversarial
debiasing techniques to ensure fairness and equity in clinical applications of
self-supervised 3D CT embeddings, paving the way for their broader adoption in
unbiased medical decision-making.

æè¦ï¼èªæç£ç£å­¸ç¿ééå¾å¤§è¦æ¨¡æªæ¨è¨è³æéä¸­æåææä¸å¯æ¦åçç¹å¾µï¼é²èé©æ°äºé«å­¸å½±åãæè¿ï¼èªæç£ç£åºç¤æ¨¡åå·²æ´å±å°ä¸ç¶­ (3D) é»è¦æ·å±¤ææ (CT) è³æï¼ç¢çç·æ¹ãè³è¨è±å¯çåµå¥ï¼åå« 1408 åç¹å¾µï¼å¨é¡±å§åºè¡åµæ¸¬åèºçé¢¨éªé æ¸¬ç­ä¸æ¸¸ä»»åä¸­éå°æåé²çæè½ãç¶èï¼éäºåµå¥å·²è¢«è­ææç·¨ç¢¼äººå£çµ±è¨è³è¨ï¼ä¾å¦å¹´é½¡ãæ§å¥åç¨®æï¼éå°è¨åºæç¨çå¬å¹³æ§æ§æéå¤§é¢¨éªã
å¨éé å·¥ä½ä¸­ï¼æåæåºä¸ååºæ¼è®ç°èªç·¨ç¢¼å¨ (VAE) çå°ææ§å»åæ¡æ¶ï¼å°éäºåµå¥è½æå°ä¸åæ°çæ½å¨ç©ºéï¼å¶ä¸­ä¸åç·¨ç¢¼äººå£çµ±è¨è³è¨ï¼åæç¶­æééµä¸æ¸¸ä»»åçæè½ãæåå¨ NLST èºçç¯©æª¢è³æéä¸é©è­äºæåçåæ³ï¼è­æå»ååµå¥æææ¶é¤äºå¤éç·¨ç¢¼çäººå£çµ±è¨è³è¨ï¼ä¸¦å¨ä¸æå®³ 1 å¹´å 2 å¹´ééçèºçé¢¨éªé æ¸¬æºç¢ºæ§çææ³ä¸æé«äºå¬å¹³æ§ãæ­¤å¤ï¼æåçåæ³ç¢ºä¿äºåµå¥å°ææ§åèª¤æ»æå·æé­¯æ£æ§ãéäºçµæçªé¡¯äºå°ææ§å»åæè¡çæ½åï¼å¯ç¢ºä¿èªæç£ç£ 3D CT åµå¥å¨è¨åºæç¨ä¸­çå¬å¹³æ§åå¬æ­£æ§ï¼çºå¶å¨ç¡åè¦é«çæ±ºç­ä¸­çå»£æ³æ¡ç¨éªè·¯ã

##### **Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function**
2502.03591v1 by Mehrdad Asadi, Komi SodokÃ©, Ian J. Gerard, Marta Kersten-Oertel

In this work, we present a novel approach to multi-label chest X-ray (CXR)
image classification that enhances clinical interpretability while maintaining
a streamlined, single-model, single-run training pipeline. Leveraging the
CheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical
label groupings to capture clinically meaningful relationships between
diagnoses. To achieve this, we designed a custom hierarchical binary
cross-entropy (HBCE) loss function that enforces label dependencies using
either fixed or data-driven penalty types. Our model achieved a mean area under
the receiver operating characteristic curve (AUROC) of 0.903 on the test set.
Additionally, we provide visual explanations and uncertainty estimations to
further enhance model interpretability. All code, model configurations, and
experiment details are made available.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºè¸é¨ X åï¼CXRï¼å½±åå¤æ¨ç±¤åé¡çæ°æ¹æ³ï¼å¨ç¶­æç°¡åçå®ä¸æ¨¡åãå®æ¬¡å·è¡è¨ç·´ç®¡ç·çåæï¼æåè¨åºå¯è§£éæ§ãå©ç¨ CheXpert è³æéå VisualCheXbert è¡ççæ¨ç±¤ï¼æåç´å¥éå±¤æ¨ç±¤ç¾¤çµï¼ä»¥æ·åè¨ºæ·ä¹éå·æè¨åºæç¾©çéè¯æ§ãçºæ­¤ï¼æåè¨­è¨äºèªè¨çéå±¤äºåäº¤åçµ (HBCE) æå¤±å½æ¸ï¼ä½¿ç¨åºå®æè³æé©åçæ²ç½°é¡åä¾å¼·å¶å·è¡æ¨ç±¤ä¾è³´æ§ãæåçæ¨¡åå¨æ¸¬è©¦éä¸éå°åè©¦èå·¥ä½ç¹æ§æ²ç· (AUROC) ä¸çå¹³åé¢ç©çº 0.903ãæ­¤å¤ï¼æåæä¾è¦è¦ºåèªªæåä¸ç¢ºå®æ§ä¼°è¨ï¼ä»¥é²ä¸æ­¥æåæ¨¡åå¯è§£éæ§ãææç¨å¼ç¢¼ãæ¨¡åçµæåå¯¦é©è©³ç´°è³æçå·²å¬éã


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-18**|**Learning to Defer for Causal Discovery with Imperfect Experts**|Oscar Clivio et.al.|[2502.13132v1](http://arxiv.org/abs/2502.13132v1)|null|
|**2025-02-18**|**Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks**|Markus J. Buehler et.al.|[2502.13025v1](http://arxiv.org/abs/2502.13025v1)|null|
|**2025-02-18**|**Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge**|Mohammad Reza Rezaei et.al.|[2502.13010v1](http://arxiv.org/abs/2502.13010v1)|null|
|**2025-02-18**|**R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs**|Sumin Jo et.al.|[2502.12767v1](http://arxiv.org/abs/2502.12767v1)|null|
|**2025-02-18**|**Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research**|Xiang Liu et.al.|[2502.12669v1](http://arxiv.org/abs/2502.12669v1)|null|
|**2025-02-18**|**G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable Recommendation**|Yuhan Li et.al.|[2502.12586v1](http://arxiv.org/abs/2502.12586v1)|null|
|**2025-02-17**|**A-MEM: Agentic Memory for LLM Agents**|Wujiang Xu et.al.|[2502.12110v1](http://arxiv.org/abs/2502.12110v1)|null|
|**2025-02-17**|**KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths over Knowledge Graphs**|Qi Zhao et.al.|[2502.12029v1](http://arxiv.org/abs/2502.12029v1)|null|
|**2025-02-17**|**Atom of Thoughts for Markov LLM Test-Time Scaling**|Fengwei Teng et.al.|[2502.12018v1](http://arxiv.org/abs/2502.12018v1)|null|
|**2025-02-17**|**Generating Text from Uniform Meaning Representation**|Emma Markle et.al.|[2502.11973v1](http://arxiv.org/abs/2502.11973v1)|null|
|**2025-02-17**|**GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs**|Yi Fang et.al.|[2502.11925v1](http://arxiv.org/abs/2502.11925v1)|null|
|**2025-02-17**|**Exploring LLM-based Student Simulation for Metacognitive Cultivation**|Haoxuan Li et.al.|[2502.11678v1](http://arxiv.org/abs/2502.11678v1)|null|
|**2025-02-17**|**Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering**|Runxuan Liu et.al.|[2502.11491v1](http://arxiv.org/abs/2502.11491v1)|null|
|**2025-02-17**|**GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion**|Kangyang Luo et.al.|[2502.11471v1](http://arxiv.org/abs/2502.11471v1)|null|
|**2025-02-16**|**Large Language-Geometry Model: When LLM meets Equivariance**|Zongzhao Li et.al.|[2502.11149v1](http://arxiv.org/abs/2502.11149v1)|null|
|**2025-02-16**|**Beyond Pairwise: Global Zero-shot Temporal Graph Generation**|Alon Eirew et.al.|[2502.11114v1](http://arxiv.org/abs/2502.11114v1)|null|
|**2025-02-16**|**Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications**|Alexandru Lecu et.al.|[2502.11108v1](http://arxiv.org/abs/2502.11108v1)|null|
|**2025-02-16**|**Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection**|Yang Zhao et.al.|[2502.11062v1](http://arxiv.org/abs/2502.11062v1)|null|
|**2025-02-16**|**CounterBench: A Benchmark for Counterfactuals Reasoning in Large Language Models**|Yuefei Chen et.al.|[2502.11008v1](http://arxiv.org/abs/2502.11008v1)|null|
|**2025-02-16**|**RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation**|Pengcheng Jiang et.al.|[2502.10996v1](http://arxiv.org/abs/2502.10996v1)|null|
|**2025-02-15**|**Developing Conversational Speech Systems for Robots to Detect Speech Biomarkers of Cognition in People Living with Dementia**|Rohith Perumandla et.al.|[2502.10896v1](http://arxiv.org/abs/2502.10896v1)|null|
|**2025-02-15**|**Evaluating improvements on using Large Language Models (LLMs) for property extraction in the Open Research Knowledge Graph (ORKG)**|Sandra Schaftner et.al.|[2502.10768v1](http://arxiv.org/abs/2502.10768v1)|null|
|**2025-02-15**|**K-Edit: Language Model Editing with Contextual Knowledge Awareness**|Elan Markowitz et.al.|[2502.10626v1](http://arxiv.org/abs/2502.10626v1)|null|
|**2025-02-15**|**ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language Interactions for Computer-Aided Diagnosis**|Xueshen Li et.al.|[2502.10620v1](http://arxiv.org/abs/2502.10620v1)|null|
|**2025-02-14**|**GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs**|Shima Khoshraftar et.al.|[2502.10522v1](http://arxiv.org/abs/2502.10522v1)|null|
|**2025-02-14**|**Do Large Language Models Reason Causally Like Us? Even Better?**|Hanna M. Dettki et.al.|[2502.10215v1](http://arxiv.org/abs/2502.10215v1)|null|
|**2025-02-14**|**Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages**|Daniil Gurgurov et.al.|[2502.10140v1](http://arxiv.org/abs/2502.10140v1)|null|
|**2025-02-14**|**Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models**|Chenrui Tie et.al.|[2502.10090v1](http://arxiv.org/abs/2502.10090v1)|null|
|**2025-02-14**|**Decision Information Meets Large Language Models: The Future of Explainable Operations Research**|Yansen Zhang et.al.|[2502.09994v1](http://arxiv.org/abs/2502.09994v1)|null|
|**2025-02-14**|**KGGen: Extracting Knowledge Graphs from Plain Text with Language Models**|Belinda Mo et.al.|[2502.09956v1](http://arxiv.org/abs/2502.09956v1)|null|
|**2025-02-14**|**ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**|Shu Wang et.al.|[2502.09891v1](http://arxiv.org/abs/2502.09891v1)|null|
|**2025-02-13**|**Visual Graph Question Answering with ASP and LLMs for Language Parsing**|Jakob Johannes Bauer et.al.|[2502.09211v1](http://arxiv.org/abs/2502.09211v1)|null|
|**2025-02-12**|**Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**|Doudou Zhou et.al.|[2502.08547v1](http://arxiv.org/abs/2502.08547v1)|null|
|**2025-02-12**|**Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy**|Ruizhan Xue et.al.|[2502.08353v1](http://arxiv.org/abs/2502.08353v1)|null|
|**2025-02-12**|**Graph Foundation Models for Recommendation: A Comprehensive Survey**|Bin Wu et.al.|[2502.08346v3](http://arxiv.org/abs/2502.08346v3)|null|
|**2025-02-12**|**Self-Evaluation for Job-Shop Scheduling**|Imanol Echeverria et.al.|[2502.08684v1](http://arxiv.org/abs/2502.08684v1)|null|
|**2025-02-12**|**Improving Existing Optimization Algorithms with LLMs**|Camilo ChacÃ³n Sartori et.al.|[2502.08298v1](http://arxiv.org/abs/2502.08298v1)|null|
|**2025-02-12**|**LLM4GNAS: A Large Language Model Based Toolkit for Graph Neural Architecture Search**|Yang Gao et.al.|[2502.10459v1](http://arxiv.org/abs/2502.10459v1)|null|
|**2025-02-12**|**ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning**|Vy Vo et.al.|[2502.08148v1](http://arxiv.org/abs/2502.08148v1)|null|
|**2025-02-12**|**Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep Learning to Enhance Question Answering Quality**|Xin Kang et.al.|[2502.09658v1](http://arxiv.org/abs/2502.09658v1)|null|
|**2025-02-12**|**GCoT: Chain-of-Thought Prompt Learning for Graphs**|Xingtong Yu et.al.|[2502.08092v1](http://arxiv.org/abs/2502.08092v1)|null|
|**2025-02-12**|**Linking Cryptoasset Attribution Tags to Knowledge Graph Entities: An LLM-based Approach**|RÃ©gnier Avice et.al.|[2502.10453v1](http://arxiv.org/abs/2502.10453v1)|null|
|**2025-02-11**|**Deep Semantic Graph Learning via LLM based Node Enhancement**|Chuanqi Shi et.al.|[2502.07982v1](http://arxiv.org/abs/2502.07982v1)|null|
|**2025-02-10**|**Cardiverse: Harnessing LLMs for Novel Card Game Prototyping**|Danrui Li et.al.|[2502.07128v1](http://arxiv.org/abs/2502.07128v1)|null|
|**2025-02-10**|**GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units**|Arghadip Das et.al.|[2502.06921v2](http://arxiv.org/abs/2502.06921v2)|[link](https://github.com/arghadippurdue/GraNNite)|
|**2025-02-10**|**Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language**|Zhiqiang Zhong et.al.|[2502.06634v1](http://arxiv.org/abs/2502.06634v1)|null|
|**2025-02-10**|**KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment**|Yuxing Lu et.al.|[2502.06472v1](http://arxiv.org/abs/2502.06472v1)|[link](https://github.com/YuxingLu613/KARMA)|
|**2025-02-10**|**RoToR: Towards More Reliable Responses for Order-Invariant Inputs**|Soyoung Yoon et.al.|[2502.08662v1](http://arxiv.org/abs/2502.08662v1)|null|
|**2025-02-10**|**K-ON: Stacking Knowledge On the Head Layer of Large Language Model**|Lingbing Guo et.al.|[2502.06257v1](http://arxiv.org/abs/2502.06257v1)|null|
|**2025-02-10**|**LegalViz: Legal Text Visualization by Text To Diagram Generation**|Eri Onami et.al.|[2502.06147v2](http://arxiv.org/abs/2502.06147v2)|null|
|**2025-02-09**|**Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs**|Han Meng et.al.|[2502.06075v1](http://arxiv.org/abs/2502.06075v1)|null|
|**2025-02-09**|**LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification**|Shubham Kumar Nigam et.al.|[2502.05836v1](http://arxiv.org/abs/2502.05836v1)|null|
|**2025-02-08**|**LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning**|Hanqing Yang et.al.|[2502.05453v1](http://arxiv.org/abs/2502.05453v1)|null|
|**2025-02-08**|**SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation**|Xingtong Yu et.al.|[2502.05424v1](http://arxiv.org/abs/2502.05424v1)|null|
|**2025-02-08**|**Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints**|Ali Al-Lawati et.al.|[2502.05414v1](http://arxiv.org/abs/2502.05414v1)|null|
|**2025-02-08**|**Knowledge Graph-Guided Retrieval Augmented Generation**|Xiangrong Zhu et.al.|[2502.06864v1](http://arxiv.org/abs/2502.06864v1)|[link](https://github.com/nju-websoft/KG2RAG)|
|**2025-02-07**|**Can Large Language Models Understand Intermediate Representations?**|Hailong Jiang et.al.|[2502.06854v1](http://arxiv.org/abs/2502.06854v1)|null|
|**2025-02-07**|**GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?**|Yang Zhou et.al.|[2502.05252v1](http://arxiv.org/abs/2502.05252v1)|null|
|**2025-02-07**|**Causality can systematically address the monsters under the bench(marks)**|Felix Leeb et.al.|[2502.05085v1](http://arxiv.org/abs/2502.05085v1)|null|
|**2025-02-07**|**Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**|Tushar Pandey et.al.|[2502.05078v1](http://arxiv.org/abs/2502.05078v1)|[link](https://github.com/AgnostiqHQ/multi-agent-llm)|
|**2025-02-07**|**Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics**|Hussam Ghanem et.al.|[2502.05239v1](http://arxiv.org/abs/2502.05239v1)|null|
|**2025-02-07**|**Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**|Junde Wu et.al.|[2502.04644v1](http://arxiv.org/abs/2502.04644v1)|[link](https://github.com/theworldofagents/agentic-reasoning)|
|**2025-02-07**|**Position-aware Automatic Circuit Discovery**|Tal Haklay et.al.|[2502.04577v1](http://arxiv.org/abs/2502.04577v1)|[link](https://github.com/technion-cs-nlp/peap)|
|**2025-02-06**|**Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**|Shangbin Feng et.al.|[2502.04510v1](http://arxiv.org/abs/2502.04510v1)|null|
|**2025-02-06**|**MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**|Xuejiao Zhao et.al.|[2502.04413v1](http://arxiv.org/abs/2502.04413v1)|[link](https://github.com/snowteam2023/medrag)|
|**2025-02-06**|**Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**|Longquan Jiang et.al.|[2502.03992v1](http://arxiv.org/abs/2502.03992v1)|[link](https://github.com/longquanjiang/ontoscprompt)|
|**2025-02-06**|**Multimodal Medical Code Tokenizer**|Xiaorui Su et.al.|[2502.04397v2](http://arxiv.org/abs/2502.04397v2)|null|
|**2025-02-06**|**Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents**|Chenyang Shao et.al.|[2502.04392v1](http://arxiv.org/abs/2502.04392v1)|null|
|**2025-02-06**|**Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**|Rui Cai et.al.|[2502.03715v1](http://arxiv.org/abs/2502.03715v1)|null|
|**2025-02-05**|**A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**|Yiye Chen et.al.|[2502.03450v1](http://arxiv.org/abs/2502.03450v1)|null|
|**2025-02-05**|**SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**|Ben Liu et.al.|[2502.03283v2](http://arxiv.org/abs/2502.03283v2)|null|
|**2025-02-05**|**Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**|Daniil Laptev et.al.|[2502.03032v2](http://arxiv.org/abs/2502.03032v2)|null|
|**2025-02-05**|**A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**|Bradley P. Allen et.al.|[2502.02896v1](http://arxiv.org/abs/2502.02896v1)|null|
|**2025-02-05**|**Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**|Chanhui Lee et.al.|[2502.02810v1](http://arxiv.org/abs/2502.02810v1)|null|
|**2025-02-05**|**Leveraging the true depth of LLMs**|RamÃ³n Calvo GonzÃ¡lez et.al.|[2502.02790v1](http://arxiv.org/abs/2502.02790v1)|null|
|**2025-02-04**|**Modular Training of Neural Networks aids Interpretability**|Satvik Golechha et.al.|[2502.02470v2](http://arxiv.org/abs/2502.02470v2)|null|
|**2025-02-04**|**Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs**|Sagnik Mukherjee et.al.|[2502.02362v3](http://arxiv.org/abs/2502.02362v3)|null|
|**2025-02-04**|**AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement**|Shivam Singh et.al.|[2502.02067v1](http://arxiv.org/abs/2502.02067v1)|[link](https://github.com/sssshivvvv/adaptbot)|
|**2025-02-03**|**On Bob Dylan: A Computational Perspective**|Prashant Garg et.al.|[2502.01772v1](http://arxiv.org/abs/2502.01772v1)|null|
|**2025-02-03**|**VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**|Xubin Ren et.al.|[2502.01549v1](http://arxiv.org/abs/2502.01549v1)|null|
|**2025-02-03**|**Transformers trained on proteins can learn to attend to Euclidean distance**|Isaac Ellmen et.al.|[2502.01533v1](http://arxiv.org/abs/2502.01533v1)|[link](https://github.com/Ellmen/attending-to-distance)|
|**2025-02-03**|**Common Foundations for SHACL, ShEx, and PG-Schema**|S. Ahmetaj et.al.|[2502.01295v1](http://arxiv.org/abs/2502.01295v1)|null|
|**2025-02-03**|**GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**|Linhao Luo et.al.|[2502.01113v1](http://arxiv.org/abs/2502.01113v1)|[link](https://github.com/RManLuo/gfm-rag)|
|**2025-02-03**|**Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**|Seungri Yoon et.al.|[2502.01059v1](http://arxiv.org/abs/2502.01059v1)|null|
|**2025-02-03**|**Encrypted Large Model Inference: The Equivariant Encryption Paradigm**|James Buban et.al.|[2502.01013v1](http://arxiv.org/abs/2502.01013v1)|null|
|**2025-02-02**|**Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation**|Juno Kim et.al.|[2502.01694v1](http://arxiv.org/abs/2502.01694v1)|null|
|**2025-02-02**|**PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation**|Qixuan Li et.al.|[2502.00708v1](http://arxiv.org/abs/2502.00708v1)|null|
|**2025-02-02**|**A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models**|Qika Lin et.al.|[2502.00681v1](http://arxiv.org/abs/2502.00681v1)|null|
|**2025-02-01**|**Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions**|Jingyuan Yi et.al.|[2502.00339v1](http://arxiv.org/abs/2502.00339v1)|null|
|**2025-02-01**|**DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning**|Jiaxin Guo et.al.|[2502.00305v1](http://arxiv.org/abs/2502.00305v1)|null|
|**2025-01-31**|**Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques**|Nathaniel Tomczak et.al.|[2502.01659v2](http://arxiv.org/abs/2502.01659v2)|[link](https://github.com/KLab-AI3/Graph-Processing-Attention-IPDPS-2025)|
|**2025-01-31**|**Improving vision-language alignment with graph spiking hybrid Networks**|Siyu Zhang et.al.|[2501.19069v1](http://arxiv.org/abs/2501.19069v1)|null|
|**2025-01-30**|**Semantic Web and Creative AI -- A Technical Report from ISWS 2023**|Raia Abu Ahmad et.al.|[2501.18542v1](http://arxiv.org/abs/2501.18542v1)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**|Tianpeng Pan et.al.|[2501.18320v1](http://arxiv.org/abs/2501.18320v1)|null|
|**2025-01-30**|**Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**|Wanlong Liu et.al.|[2501.18154v1](http://arxiv.org/abs/2501.18154v1)|null|
|**2025-01-30**|**Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**|Qika Lin et.al.|[2501.18119v1](http://arxiv.org/abs/2501.18119v1)|null|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**|Wooyoung Kim et.al.|[2501.17549v1](http://arxiv.org/abs/2501.17549v1)|null|
|**2025-01-29**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403v1](http://arxiv.org/abs/2501.17403v1)|[link](https://github.com/honghd16/gsa-vln)|
|**2025-01-28**|**Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**|Saloni Potdar et.al.|[2501.17270v1](http://arxiv.org/abs/2501.17270v1)|null|

#### Abstracts
##### **Learning to Defer for Causal Discovery with Imperfect Experts**
2502.13132v1 by Oscar Clivio, Divyat Mahajan, Perouz Taslakian, Sara Magliacane, Ioannis Mitliagkas, Valentina Zantedeschi, Alexandre Drouin

Integrating expert knowledge, e.g. from large language models, into causal
discovery algorithms can be challenging when the knowledge is not guaranteed to
be correct. Expert recommendations may contradict data-driven results, and
their reliability can vary significantly depending on the domain or specific
query. Existing methods based on soft constraints or inconsistencies in
predicted causal relationships fail to account for these variations in
expertise. To remedy this, we propose L2D-CD, a method for gauging the
correctness of expert recommendations and optimally combining them with
data-driven causal discovery results. By adapting learning-to-defer (L2D)
algorithms for pairwise causal discovery (CD), we learn a deferral function
that selects whether to rely on classical causal discovery methods using
numerical data or expert recommendations based on textual meta-data. We
evaluate L2D-CD on the canonical T\"ubingen pairs dataset and demonstrate its
superior performance compared to both the causal discovery method and the
expert used in isolation. Moreover, our approach identifies domains where the
expert's performance is strong or weak. Finally, we outline a strategy for
generalizing this approach to causal discovery on graphs with more than two
variables, paving the way for further research in this area.

æè¦ï¼æ´åä¸å®¶ç¥è­ï¼ä¾å¦å¾å¤§åèªè¨æ¨¡åä¸­æ´åå°å æç¼ç¾æ¼ç®æ³ä¸­ï¼ç¶ç¥è­ç¡æ³ä¿è­æ­£ç¢ºææå¾æææ°æ§ãå°å®¶å»ºè­°å¯è½æèè³æé©åççµæç¸çç¾ï¼èä¸ä»åçå¯é æ§å¯è½ææ ¹æé åæç¹å®æ¥è©¢èæé¡¯èå·®ç°ãç¾æçåºæ¼è»ç´ææé æ¸¬å æéä¿ä¸­ä¸ä¸è´çæ¹æ³ç¡æ³èªªæå°æ¥­ç¥è­ä¸­çéäºè®åãçºäºè£æéä¸é»ï¼æåæåºäº L2D-CDï¼ä¸ç¨®ç¨æ¼è©ä¼°å°å®¶å»ºè­°çæ­£ç¢ºæ§ä¸¦å°å¶èè³æé©åçå æç¼ç¾çµææä½³çµåçæ¹æ³ãééèª¿æ´å­¸ç¿å»¶é² (L2D) æ¼ç®æ³ä»¥é²è¡æå°å æç¼ç¾ (CD)ï¼æåå­¸ç¿äºä¸åå»¶é²å½æ¸ï¼ç¨æ¼é¸æä¾è³´ä½¿ç¨æ¸å¼è³æçå³çµ±å æç¼ç¾æ¹æ³æåºæ¼æå­åè³æçå°å®¶å»ºè­°ãæåå¨ç¶å¸ç T\"ubingen å°è³æéä¸è©ä¼° L2D-CDï¼ä¸¦è­æå¶èå®ç¨ä½¿ç¨çå æç¼ç¾æ¹æ³åå°å®¶ç¸æ¯å·æåªè¶çæè½ãæ­¤å¤ï¼æåçåæ³è­å¥åºå°å®¶è¡¨ç¾å¼·æå¼±çé åãæå¾ï¼æåæ¦è¿°äºä¸ç¨®å°æ­¤æ¹æ³æ¨å»£å°å·æå©åä»¥ä¸è®æ¸çåè¡¨ä¸é²è¡å æç¼ç¾çç­ç¥ï¼çºæ­¤é åçé²ä¸æ­¥ç ç©¶éªå¹³äºéè·¯ã

##### **Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks**
2502.13025v1 by Markus J. Buehler

We present an agentic, autonomous graph expansion framework that iteratively
structures and refines knowledge in situ. Unlike conventional knowledge graph
construction methods relying on static extraction or single-pass learning, our
approach couples a reasoning-native large language model with a continually
updated graph representation. At each step, the system actively generates new
concepts and relationships, merges them into a global graph, and formulates
subsequent prompts based on its evolving structure. Through this
feedback-driven loop, the model organizes information into a scale-free network
characterized by hub formation, stable modularity, and bridging nodes that link
disparate knowledge clusters. Over hundreds of iterations, new nodes and edges
continue to appear without saturating, while centrality measures and shortest
path distributions evolve to yield increasingly distributed connectivity. Our
analysis reveals emergent patterns, such as the rise of highly connected 'hub'
concepts and the shifting influence of 'bridge' nodes, indicating that agentic,
self-reinforcing graph construction can yield open-ended, coherent knowledge
structures. Applied to materials design problems, we present compositional
reasoning experiments by extracting node-specific and synergy-level principles
to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that
transcend rote summarization and strengthen the framework's potential for
open-ended scientific discovery. We discuss other applications in scientific
discovery and outline future directions for enhancing scalability and
interpretability.

æè¦ï¼<paragraph>æåæåºä¸åè½åçãèªä¸»çåå½¢æ´å±æ¡æ¶ï¼å®åè¦å°å»ºæ§åç²¾çåä½ç¥è­ãèä¾è³´éææåæå®æ¬¡å­¸ç¿çå³çµ±ç¥è­åå½¢å»ºæ§æ¹æ³ä¸åï¼æåçåæ³å°ä¸åæ¨çåççå¤§èªè¨æ¨¡åèä¸åæçºæ´æ°çåå½¢è¡¨ç¤ºçµåèµ·ä¾ãå¨æ¯ä¸æ­¥ä¸­ï¼ç³»çµ±ä¸»åç¢çæ°çæ¦å¿µåéä¿ï¼å°å®ååä½µå°ä¸åå¨ååå½¢ä¸­ï¼ä¸¦æ ¹æå¶ä¸æ·æ¼åççµæ§å¶å®å¾çºæç¤ºãéééååé¥é©åçè¿´åï¼æ¨¡åå°è³è¨çµç¹æä¸åç¡æ¨åº¦ç¶²è·¯ï¼å¶ç¹å¾µæ¯æ¨ç´å½¢æãç©©å®çæ¨¡çµåä»¥åé£çµä¸åç¥è­ç¾¤éçæ©æ¥ç¯é»ãå¨æ¸ç¾æ¬¡åè¦éç®ä¸­ï¼æ°çç¯é»åéç·£ææçºåºç¾ï¼èä¸æé£½åï¼åæä¸­å¿æ§æ¸¬éåæç­è·¯å¾åä½ææ¼åçºç¢çè¶ä¾è¶åæ£çé£éæ§ãæåçåææ­ç¤ºäºæ°èæ¨¡å¼ï¼ä¾å¦é«åº¦é£æ¥çãæ¨ç´ãæ¦å¿µçèèµ·åãæ©æ¨ãç¯é»å½±é¿åçè½ç§»ï¼éè¡¨æè½åçãèªæå¼·åçåå½¢å»ºæ§å¯ä»¥ç¢çéæ¾å¼ãé£è²«çç¥è­çµæ§ãæç¨æ¼ææè¨­è¨åé¡ï¼æåæåºçµåæ¨çå¯¦é©ï¼ééæåç¹å®æ¼ç¯é»çåååååææå±¤ç´ååï¼ä»¥ä¿é²çæ­£æ°ç©çç¥è­ç¶åï¼ç¢çè¶è¶æ­»èå¼æè¦ä¸¦å¼·åæ¡æ¶å¨éæ¾å¼ç§å­¸ç¼ç¾ä¸­æ½åçè·¨é åæ³æ³ãæåè¨è«äºå¨ç§å­¸ç¼ç¾ä¸­çå¶ä»æç¨ï¼ä¸¦æ¦è¿°äºå¢å¼·å¯æ´åæ§åå¯è§£éæ§çæªä¾æ¹åã</paragraph>

##### **Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge**
2502.13010v1 by Mohammad Reza Rezaei, Reza Saadati Fard, Jayson Parker, Rahul G. Krishnan, Milad Lankarany

Large Language Models (LLMs) have significantly advanced medical
question-answering by leveraging extensive clinical data and medical
literature. However, the rapid evolution of medical knowledge and the
labor-intensive process of manually updating domain-specific resources pose
challenges to the reliability of these systems. To address this, we introduce
Adaptive Medical Graph-RAG (AMG-RAG), a comprehensive framework that automates
the construction and continuous updating of medical knowledge graphs,
integrates reasoning, and retrieves current external evidence, such as PubMed
and WikiSearch. By dynamically linking new findings and complex medical
concepts, AMG-RAG not only improves accuracy but also enhances interpretability
in medical queries.
  Evaluations on the MEDQA and MEDMCQA benchmarks demonstrate the effectiveness
of AMG-RAG, achieving an F1 score of 74.1 percent on MEDQA and an accuracy of
66.34 percent on MEDMCQA, outperforming both comparable models and those 10 to
100 times larger. Notably, these improvements are achieved without increasing
computational overhead, highlighting the critical role of automated knowledge
graph generation and external evidence retrieval in delivering up-to-date,
trustworthy medical insights.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééå©ç¨å»£æ³çè¨åºè³æåé«å­¸æç»ï¼å¤§å¹æåäºé«çåé¡è§£ç­çé²æ­¥ãç¶èï¼é«çç¥è­çå¿«éæ¼é²åæåæ´æ°ç¹å®é åè³æºçç¹è¤ç¨åºï¼å°éäºç³»çµ±çå¯é æ§æ§æææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºé©ææ§é«çåè¡¨ RAG (AMG-RAG)ï¼éæ¯ä¸åèªååå»ºæ§åæçºæ´æ°é«çç¥è­åè¡¨çç¶åæ¶æ§ï¼æ´åæ¨çä¸¦æ·å PubMed å WikiSearch ç­ææ°çå¤é¨è­æãééåæé£çµæ°çç¼ç¾åè¤éçé«çæ¦å¿µï¼AMG-RAG ä¸åæåäºæºç¢ºæ§ï¼ä¹å¢å¼·äºé«çæ¥è©¢çå¯è§£éæ§ãå¨ MEDQA å MEDMCQA åºæºä¸çè©éè­æäº AMG-RAG çæææ§ï¼å¨ MEDQA ä¸éå°äº 74.1% ç F1 åæ¸ï¼å¨ MEDMCQA ä¸éå°äº 66.34% çæºç¢ºåº¦ï¼åªæ¼å¶ä»åé¡æ¨¡åä»¥åé£äºå¤§ 10 å° 100 åçæ¨¡åãå¼å¾æ³¨æçæ¯ï¼éäºæ¹é²æ¯å¨ä¸å¢å éç®è² æçææ³ä¸å¯¦ç¾çï¼çªé¡¯äºèªååç¥è­åè¡¨çæåå¤é¨è­ææ·åå¨æä¾ææ°ãå¯ä¿¡è³´çé«çè¦è§£ä¸­æ®æ¼çéè¦è§è²ã

##### **R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs**
2502.12767v1 by Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi

Recent studies have combined Large Language Models (LLMs) with Knowledge
Graphs (KGs) to enhance reasoning, improving inference accuracy without
additional training while mitigating hallucination. However, existing
frameworks are often rigid, struggling to adapt to KG or task changes. They
also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.
To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that
separates reasoning into two roles: an Operator (a low-capacity LLM) that
gathers evidence and a Supervisor (a high-capacity LLM) that makes final
judgments. This design is cost-efficient for LLM inference while still
maintaining strong reasoning accuracy. Additionally, R2-KG employs an
Abstention mechanism, generating answers only when sufficient evidence is
collected from KG, which significantly enhances reliability. Experiments across
multiple KG-based reasoning tasks show that R2-KG consistently outperforms
baselines in both accuracy and reliability, regardless of the inherent
capability of LLMs used as the Operator. Further experiments reveal that the
single-agent version of R2-KG, equipped with a strict self-consistency
strategy, achieves significantly higher-than-baseline reliability while
reducing inference cost. However, it also leads to a higher abstention rate in
complex KGs. Our findings establish R2-KG as a flexible and cost-effective
solution for KG-based reasoning. It reduces reliance on high-capacity LLMs
while ensuring trustworthy inference.

æè¦ï¼<paragraph>æè¿çç ç©¶ç»åäºå¤§åè¯­è¨æ¨¡å (LLM) ä¸ç¥è¯å¾è°± (KG) ä»¥å¢å¼ºæ¨çï¼å¨ä¸é¢å¤è®­ç»çæåµä¸æé«æ¨çåç¡®æ§ï¼åæ¶åè½»å¹»è§ãç¶èï¼ç°æçæ¡æ¶éå¸¸å¾åµåï¼é¾ä»¥éåºç¥è¯å¾è°±æä»»å¡çååãå®ä»¬è¿ä¸¥éä¾èµå¼ºå¤§ç LLM æ¥è¿è¡å¯é ï¼å³å¼å¾ä¿¡èµï¼çæ¨çãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº R2-KGï¼è¿æ¯ä¸ä¸ªå³æå³ç¨ãåä»£çæ¡æ¶ï¼å®å°æ¨çåä¸ºä¸¤ä¸ªè§è²ï¼ä¸ä¸ªæ¶éè¯æ®çæä½åï¼ä½å®¹é LLMï¼åä¸ä¸ªååºæç»å¤æ­ççç£åï¼é«å®¹é LLMï¼ãè¿ç§è®¾è®¡å¨ LLM æ¨çæ¹é¢å·æææ¬æçï¼åæ¶ä»ä¿æå¼ºå¤§çæ¨çåç¡®æ§ãæ­¤å¤ï¼R2-KG éç¨å¼ææºå¶ï¼ä»å¨ä»ç¥è¯å¾è°±æ¶éå°è¶³å¤è¯æ®æ¶æçæç­æ¡ï¼è¿æ¾èæé«äºå¯é æ§ãè·¨å¤ä¸ªåºäºç¥è¯å¾è°±çæ¨çä»»å¡çå®éªè¡¨æï¼R2-KG å¨åç¡®æ§åå¯é æ§æ¹é¢å§ç»ä¼äºåºçº¿ï¼èä¸ç¨ä½æä½åç LLM çåºæè½åæ å³ãè¿ä¸æ­¥çå®éªè¡¨æï¼R2-KG çåä»£ççæ¬éå¤äºä¸¥æ ¼çèªä¸è´æ§ç­ç¥ï¼å®ç°äºææ¾é«äºåºçº¿çå¯é æ§ï¼åæ¶éä½äºæ¨çææ¬ãç¶èï¼å®ä¹å¯¼è´äºå¤æç¥è¯å¾è°±ä¸­æ´é«çå¼æçãæä»¬çåç°å° R2-KG ç¡®ç«ä¸ºä¸ç§çµæ´»ä¸ç»æµé«æçåºäºç¥è¯å¾è°±çæ¨çè§£å³æ¹æ¡ãå®åå°äºå¯¹é«å®¹é LLM çä¾èµï¼åæ¶ç¡®ä¿äºå¯ä¿¡çæ¨çã</paragraph>

##### **Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research**
2502.12669v1 by Xiang Liu, Penglei Sun, Shuyan Chen, Longhan Zhang, Peijie Dong, Huajie You, Yongqi Zhang, Chang Yan, Xiaowen Chu, Tong-yi Zhang

The rapid advancement of perovskite solar cells (PSCs) has led to an
exponential growth in research publications, creating an urgent need for
efficient knowledge management and reasoning systems in this domain. We present
a comprehensive knowledge-enhanced system for PSCs that integrates three key
components. First, we develop Perovskite-KG, a domain-specific knowledge graph
constructed from 1,517 research papers, containing 23,789 entities and 22,272
relationships. Second, we create two complementary datasets: Perovskite-Chat,
comprising 55,101 high-quality question-answer pairs generated through a novel
multi-agent framework, and Perovskite-Reasoning, containing 2,217 carefully
curated materials science problems. Third, we introduce two specialized large
language models: Perovskite-Chat-LLM for domain-specific knowledge assistance
and Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental
results demonstrate that our system significantly outperforms existing models
in both domain-specific knowledge retrieval and scientific reasoning tasks,
providing researchers with effective tools for literature review, experimental
design, and complex problem-solving in PSC research.

æè¦ï¼ç±æ¼ perovskite å¤ªé½è½é»æ±  (PSC) å¿«éé²å±ï¼å°è´ç ç©¶åºçç©åææ¸æé·ï¼è¿«åéè¦å¨éé åå»ºç«ææçç¥è­ç®¡çåæ¨çç³»çµ±ãæåæåºä¸åçµåä¸é ééµåä»¶ç PSC å¨é¢ç¥è­å¢å¼·ç³»çµ±ãé¦åï¼æåéç¼åº Perovskite-KGï¼ä¸åç± 1,517 ç¯ç ç©¶è«æå»ºæ§èæãåå« 23,789 åå¯¦é«å 22,272 åéä¿çé åç¹å®ç¥è­åè­ãå¶æ¬¡ï¼æåå»ºç«å©åäºè£çè³æéï¼Perovskite-Chatï¼åå«ééä¸åæ°ç©çå¤ä»£çæ¶æ§ç¢ç 55,101 åé«åè³ªåç­éå°ï¼ä»¥å Perovskite-Reasoningï¼åå« 2,217 åä»ç´°ç­å±çææç§å­¸åé¡ãç¬¬ä¸ï¼æåæ¨åºå©åå°éåå¤§åèªè¨æ¨¡åï¼éå°é åç¹å®ç¥è­åå©ç Perovskite-Chat-LLMï¼ä»¥åéå°ç§å­¸æ¨çä»»åç Perovskite-Reasoning-LLMãå¯¦é©çµæé¡¯ç¤ºï¼æåçç³»çµ±å¨é åç¹å®ç¥è­æ·ååç§å­¸æ¨çä»»åä¸é½æé¡¯åªæ¼ç¾ææ¨¡åï¼çºç ç©¶äººå¡æä¾ææçå·¥å·ï¼ç¨æ¼ PSC ç ç©¶ä¸­çæç»åé¡§ãå¯¦é©è¨­è¨åè¤éåé¡è§£æ±ºã

##### **G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable Recommendation**
2502.12586v1 by Yuhan Li, Xinni Zhang, Linhao Luo, Heng Chang, Yuxiang Ren, Irwin King, Jia Li

Explainable recommendation has demonstrated significant advantages in
informing users about the logic behind recommendations, thereby increasing
system transparency, effectiveness, and trustworthiness. To provide
personalized and interpretable explanations, existing works often combine the
generation capabilities of large language models (LLMs) with collaborative
filtering (CF) information. CF information extracted from the user-item
interaction graph captures the user behaviors and preferences, which is crucial
for providing informative explanations. However, due to the complexity of graph
structure, effectively extracting the CF information from graphs still remains
a challenge. Moreover, existing methods often struggle with the integration of
extracted CF information with LLMs due to its implicit representation and the
modality gap between graph structures and natural language explanations. To
address these challenges, we propose G-Refer, a framework using graph
retrieval-augmented large language models (LLMs) for explainable
recommendation. Specifically, we first employ a hybrid graph retrieval
mechanism to retrieve explicit CF signals from both structural and semantic
perspectives. The retrieved CF information is explicitly formulated as
human-understandable text by the proposed graph translation and accounts for
the explanations generated by LLMs. To bridge the modality gap, we introduce
knowledge pruning and retrieval-augmented fine-tuning to enhance the ability of
LLMs to process and utilize the retrieved CF information to generate
explanations. Extensive experiments show that G-Refer achieves superior
performance compared with existing methods in both explainability and
stability. Codes and data are available at https://github.com/Yuhan1i/G-Refer.

æè¦ï¼å¯è§£éå»ºè­°å·²è­æå¨åç¥ä½¿ç¨èå»ºè­°èå¾çéè¼¯æ¹é¢å·æé¡¯èåªé»ï¼å¾èæé«ç³»çµ±éæåº¦ãæææ§åå¯ä¿¡åº¦ãçºäºæä¾åäººåä¸å¯è§£éçèªªæï¼ç¾æä½åéå¸¸çµåå¤§åèªè¨æ¨¡å (LLM) ççæè½åèååéæ¿¾ (CF) è³è¨ãå¾ä½¿ç¨èé ç®äºååå½¢ä¸­æåç CF è³è¨ææ·åä½¿ç¨èè¡çºååå¥½ï¼éå°æ¼æä¾è³è¨æ§èªªæè³ééè¦ãç¶èï¼ç±æ¼åå½¢çµæ§çè¤éæ§ï¼å¾åå½¢ä¸­æææå CF è³è¨ä»ç¶æ¯ä¸åææ°ãæ­¤å¤ï¼ç¾ææ¹æ³éå¸¸é£ä»¥å°æåç CF è³è¨è LLM æ´åï¼å çºå¶é±å«è¡¨ç¤ºååå½¢çµæ§èèªç¶èªè¨èªªæä¹éçæ¨¡å¼å·®è·ãçºäºæå°éäºææ°ï¼æåæåº G-Referï¼ä¸åä½¿ç¨åå½¢æª¢ç´¢å¢å¼·åå¤§åèªè¨æ¨¡å (LLM) çå¯è§£éå»ºè­°æ¶æ§ãå·é«ä¾èªªï¼æåé¦åæ¡ç¨æ··ååå½¢æª¢ç´¢æ©å¶ï¼å¾çµæ§åèªç¾©è§åº¦æª¢ç´¢æç¢ºç CF è¨èãæª¢ç´¢å°ç CF è³è¨ç±å»ºè­°çåå½¢ç¿»è­¯æç¢ºè¡¨è¿°çºäººé¡å¯ä»¥çè§£çæå­ï¼ä¸¦èªªæ LLM çæçè§£éãçºäºå½åæ¨¡å¼å·®è·ï¼æåå¼å¥äºç¥è­ä¿®åªåæª¢ç´¢å¢å¼·å¾®èª¿ï¼ä»¥å¢å¼· LLM èçåå©ç¨æª¢ç´¢å°ç CF è³è¨ä»¥ç¢çè§£éçè½åãå»£æ³çå¯¦é©è¡¨æï¼èç¾ææ¹æ³ç¸æ¯ï¼G-Refer å¨å¯è§£éæ§åç©©å®æ§æ¹é¢é½åå¾äºåè¶çæè½ãç¨å¼ç¢¼åè³æå¯å¨ https://github.com/Yuhan1i/G-Refer åå¾ã

##### **A-MEM: Agentic Memory for LLM Agents**
2502.12110v1 by Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang

While large language model (LLM) agents can effectively use external tools
for complex real-world tasks, they require memory systems to leverage
historical experiences. Current memory systems enable basic storage and
retrieval but lack sophisticated memory organization, despite recent attempts
to incorporate graph databases. Moreover, these systems' fixed operations and
structures limit their adaptability across diverse tasks. To address this
limitation, this paper proposes a novel agentic memory system for LLM agents
that can dynamically organize memories in an agentic way. Following the basic
principles of the Zettelkasten method, we designed our memory system to create
interconnected knowledge networks through dynamic indexing and linking. When a
new memory is added, we generate a comprehensive note containing multiple
structured attributes, including contextual descriptions, keywords, and tags.
The system then analyzes historical memories to identify relevant connections,
establishing links where meaningful similarities exist. Additionally, this
process enables memory evolution - as new memories are integrated, they can
trigger updates to the contextual representations and attributes of existing
historical memories, allowing the memory network to continuously refine its
understanding. Our approach combines the structured organization principles of
Zettelkasten with the flexibility of agent-driven decision making, allowing for
more adaptive and context-aware memory management. Empirical experiments on six
foundation models show superior improvement against existing SOTA baselines.
The source code is available at https://github.com/WujiangXu/AgenticMemory.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä»£çéç¶è½ææå°ä½¿ç¨å¤é¨å·¥å·ä¾å·è¡è¤éççå¯¦ä¸çä»»åï¼ä½å®åéè¦è¨æ¶é«ç³»çµ±ä¾å©ç¨æ­·å²ç¶é©ãç®åçè¨æ¶é«ç³»çµ±è½é²è¡åºæ¬çå²å­åæª¢ç´¢ï¼ä½ç¼ºä¹ç²¾å¯çè¨æ¶é«çµç¹ï¼åç®¡æè¿åè©¦ç´å¥åå½¢è³æåº«ãæ­¤å¤ï¼éäºç³»çµ±åºå®çéä½åçµæ§éå¶äºå®åå¨ä¸åä»»åä¸­çé©ææ§ãçºäºè§£æ±ºéåéå¶ï¼æ¬ææåºäºä¸ç¨®æ°çä»£çè¨æ¶é«ç³»çµ±ï¼ä¾ LLM ä»£çåæå°ä»¥ä»£ççæ¹å¼çµç¹è¨æ¶é«ãéµå¾ª Zettelkasten æ¹æ³çåºæ¬ååï¼æåè¨­è¨æåçè¨æ¶é«ç³»çµ±ï¼ééåæç´¢å¼åé£çµä¾å»ºç«ç¸äºé£çµçç¥è­ç¶²è·¯ãç¶å å¥æ°çè¨æ¶é«æï¼æåæç¢çåå«å¤åçµæ§åå±¬æ§çç¶åç­è¨ï¼åæ¬èçµ¡æè¿°ãééµå­åæ¨ç±¤ãç¶å¾ï¼ç³»çµ±æåææ­·å²è¨æ¶é«ä»¥æ¾åºç¸éé£çµï¼å¨ææç¾©çç¸ä¼¼æ§æå»ºç«é£çµãæ­¤å¤ï¼éåç¨åºè½è®è¨æ¶é«æ¼åï¼å çºç¶æ´åæ°çè¨æ¶é«æï¼å®åæè§¸ç¼å°ç¾ææ­·å²è¨æ¶é«çèçµ¡è¡¨ç¤ºåå±¬æ§çæ´æ°ï¼è®è¨æ¶é«ç¶²è·¯è½æçºç²¾é²å®ççè§£ãæåçåæ³çµåäº Zettelkasten ççµæ§åçµç¹åååä»£çé©åæ±ºç­å¶å®çéæ´»æ§ï¼è½é²è¡æ´å·é©ææ§åèçµ¡æç¥çè¨æ¶é«ç®¡çãå¨å­ååºç¤æ¨¡åä¸çç¶é©å¯¦é©é¡¯ç¤ºåºæ¯ç¾æç SOTA åºæºç·æé¡¯èçé²æ­¥ãåå§ç¢¼å¯ä»¥å¨ https://github.com/WujiangXu/AgenticMemory æ¾å°ã

##### **KnowPath: Knowledge-enhanced Reasoning via LLM-generated Inference Paths over Knowledge Graphs**
2502.12029v1 by Qi Zhao, Hongyu Yang, Qi Song, Xinwei Yao, Xiangyang Li

Large language models (LLMs) have demonstrated remarkable capabilities in
various complex tasks, yet they still suffer from hallucinations. Introducing
external knowledge, such as knowledge graph, can enhance the LLMs' ability to
provide factual answers. LLMs have the ability to interactively explore
knowledge graphs. However, most approaches have been affected by insufficient
internal knowledge excavation in LLMs, limited generation of trustworthy
knowledge reasoning paths, and a vague integration between internal and
external knowledge. Therefore, we propose KnowPath, a knowledge-enhanced large
model framework driven by the collaboration of internal and external knowledge.
It relies on the internal knowledge of the LLM to guide the exploration of
interpretable directed subgraphs in external knowledge graphs, better
integrating the two knowledge sources for more accurate reasoning. Extensive
experiments on multiple real-world datasets confirm the superiority of
KnowPath.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®è¤éä»»åä¸­å±ç¾åºåè¶çè½åï¼ä½ä»æåºç¾å¹»è¦ºãå¼å¥å¤é¨ç¥è­ï¼ä¾å¦ç¥è­åè­ï¼å¯ä»¥å¢å¼· LLM æä¾äºå¯¦ç­æ¡çè½åãLLM æè½åäºåå¼å°æ¢ç´¢ç¥è­åè­ãç¶èï¼å¤§å¤æ¸æ¹æ³é½åå° LLM ä¸­å§é¨ç¥è­ææä¸è¶³ãå¯ä¿¡è³´ç¥è­æ¨çè·¯å¾çæåéï¼ä»¥åå§é¨åå¤é¨ç¥è­ä¹éçæ´åæ¨¡ç³çå½±é¿ãå æ­¤ï¼æåæåº KnowPathï¼éæ¯ä¸åç±å§é¨åå¤é¨ç¥è­çåä½é©åçç¥è­å¢å¼·åå¤§åæ¨¡åæ¡æ¶ãå®ä¾è³´æ¼ LLM çå§é¨ç¥è­ä¾æå°å°å¤é¨ç¥è­åè­ä¸­å¯è§£éçæåå­åçæ¢ç´¢ï¼æ´å¥½å°æ´åå©åç¥è­ä¾æºä»¥é²è¡æ´æºç¢ºçæ¨çãå°å¤åçå¯¦ä¸çè³æéé²è¡çå¤§éå¯¦é©è­å¯¦äº KnowPath çåªè¶æ§ã

##### **Atom of Thoughts for Markov LLM Test-Time Scaling**
2502.12018v1 by Fengwei Teng, Zhaoyang Yu, Quan Shi, Jiayi Zhang, Chenglin Wu, Yuyu Luo

Large Language Models (LLMs) achieve superior performance through
training-time scaling, and test-time scaling further enhances their
capabilities by conducting effective reasoning during inference. However, as
the scale of reasoning increases, existing test-time scaling methods suffer
from accumulated historical information, which not only wastes computational
resources but also interferes with effective reasoning. To address this issue,
we observe that complex reasoning progress is often achieved by solving a
sequence of independent subquestions, each being self-contained and verifiable.
These subquestions are essentially atomic questions, relying primarily on their
current state rather than accumulated history, similar to the memoryless
transitions in a Markov process. Based on this observation, we propose Atom of
Thoughts (AoT), where each state transition in the reasoning process consists
of decomposing the current question into a dependency-based directed acyclic
graph and contracting its subquestions, forming a new atomic question state.
This iterative decomposition-contraction process continues until reaching
directly solvable atomic questions, naturally realizing Markov transitions
between question states. Furthermore, these atomic questions can be seamlessly
integrated into existing test-time scaling methods, enabling AoT to serve as a
plug-in enhancement for improving reasoning capabilities. Experiments across
six benchmarks demonstrate the effectiveness of AoT both as a standalone
framework and a plug-in enhancement. Notably, on HotpotQA, when applied to
gpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and
DeepSeek-R1 by 10.6%. The code will be available at
https://github.com/qixucen/atom.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééè¨ç·´æéæ´åä¾éæåè¶çæè½ï¼èæ¸¬è©¦æéæ´åééå¨æ¨è«æéé²è¡ææçæ¨çï¼é²ä¸æ­¥æåå¶è½åãç¶èï¼é¨èæ¨çè¦æ¨¡çæ´å¤§ï¼ç¾æçæ¸¬è©¦æéæ´åæ¹æ³æåå°ç´¯ç©çæ­·å²è³è¨å½±é¿ï¼éä¸åææµªè²»éç®è³æºï¼éæå¹²æ¾ææçæ¨çãçºäºè§£æ±ºéååé¡ï¼æåè§å¯å°è¤éçæ¨çé²ç¨éå¸¸æ¯ééè§£æ±ºä¸ç³»åç¨ç«çå­åé¡ä¾éæï¼æ¯åå­åé¡é½æ¯ç¨ç«ä¸å¯é©è­çãéäºå­åé¡æ¬è³ªä¸æ¯åå­åé¡ï¼ä¸»è¦ä¾è³´æ¼å®åçç¶åçæï¼èä¸æ¯ç´¯ç©çæ­·å²ï¼é¡ä¼¼æ¼é¦¬å¯å¤«éç¨ä¸­çç¡è¨æ¶è½æãåºæ¼éåè§å¯ï¼æåæåºäºææ³åå­ (AoT)ï¼å¶ä¸­æ¨çéç¨ä¸­æ¯åçæè½æé½åå«å°ç¶ååé¡åè§£çºåºæ¼ä¾è³´éä¿çæåç¡ç°åï¼ä¸¦æ¶ç¸®å¶å­åé¡ï¼å½¢ææ°çåå­åé¡çæãéååè¦çåè§£æ¶ç¸®éç¨ææçºé²è¡ï¼ç´å°éå°å¯ç´æ¥è§£æ±ºçåå­åé¡ï¼èªç¶å°å¯¦ç¾åé¡çæä¹éçé¦¬å¯å¤«è½æãæ­¤å¤ï¼éäºåå­åé¡å¯ä»¥ç¡ç¸«æ´åå°ç¾æçæ¸¬è©¦æéæ´åæ¹æ³ä¸­ï¼è® AoT å¯ä»¥ä½çºå¤æç¨å¼å¼·ååè½ï¼ä»¥æ¹åæ¨çè½åãæ©«è·¨å­ååºæºçå¯¦é©è­æäº AoT ä½çºç¨ç«æ¶æ§åå¤æç¨å¼å¼·åçæææ§ãå¼å¾æ³¨æçæ¯ï¼å¨ HotpotQA ä¸ï¼ç¶æç¨æ¼ gpt-4o-mini æï¼AoT éå°äº 80.6% ç F1 åæ¸ï¼æ¯ o3-mini é«åº 3.4%ï¼æ¯ DeepSeek-R1 é«åº 10.6%ãç¨å¼ç¢¼å°å¨ https://github.com/qixucen/atom ä¸æä¾ã

##### **Generating Text from Uniform Meaning Representation**
2502.11973v1 by Emma Markle, Reihaneh Iranmanesh, Shira Wein

Uniform Meaning Representation (UMR) is a recently developed graph-based
semantic representation, which expands on Abstract Meaning Representation (AMR)
in a number of ways, in particular through the inclusion of document-level
information and multilingual flexibility. In order to effectively adopt and
leverage UMR for downstream tasks, efforts must be placed toward developing a
UMR technological ecosystem. Though still limited amounts of UMR annotations
have been produced to date, in this work, we investigate the first approaches
to producing text from multilingual UMR graphs: (1) a pipeline conversion of
UMR to AMR, then using AMR-to-text generation models, (2) fine-tuning large
language models with UMR data, and (3) fine-tuning existing AMR-to-text
generation models with UMR data. Our best performing model achieves a
multilingual BERTscore of 0.825 for English and 0.882 for Chinese when compared
to the reference, which is a promising indication of the effectiveness of
fine-tuning approaches for UMR-to-text generation with even limited amounts of
UMR data.

æè¦ï¼çµ±ä¸èªæè¡¨ç¤º (UMR) æ¯ä¸ç¨®æè¿éç¼çåºæ¼åå½¢çèªæè¡¨ç¤ºï¼å®å¨è¨±å¤æ¹é¢æ´å±äºæ½è±¡èªæè¡¨ç¤º (AMR)ï¼ç¹å¥æ¯ééç´å¥æä»¶å±¤ç´è³è¨åå¤èªè¨éæ´»æ§ãçºäºæææ¡ç¨åå©ç¨ä¸æ¸¸ä»»åç UMRï¼å¿é æå¥ç²¾åéç¼ UMR æè¡çæç³»çµ±ãéç¶å°ç®åçºæ­¢ç¢çç UMR æ¨è¨»æ¸éä»ç¶æéï¼ä½å¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå¾å¤èªè¨ UMR åå½¢ç¢çæå­çç¬¬ä¸ç¨®æ¹æ³ï¼(1) å° UMR è½æçº AMR çç®¡éï¼ç¶å¾ä½¿ç¨ AMR è½æå­çææ¨¡åï¼(2) ä½¿ç¨ UMR è³æå¾®èª¿å¤§åèªè¨æ¨¡åï¼ä»¥å (3) ä½¿ç¨ UMR è³æå¾®èª¿ç¾æç AMR è½æå­çææ¨¡åãèåèç¸æ¯ï¼æåæè½æå¥½çæ¨¡åå¨è±æä¸­éå° 0.825 çå¤èªè¨ BERT åæ¸ï¼å¨ä¸­æä¸­éå° 0.882ï¼éè¡¨ç¤ºä½¿ç¨ UMR è³æé²è¡ UMR è½æå­çæçå¾®èª¿æ¹æ³å·æè¯å¥½çææï¼å³ä½¿ UMR è³ææ¸éæéã

##### **GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs**
2502.11925v1 by Yi Fang, Bowen Jin, Jiacheng Shen, Sirui Ding, Qiaoyu Tan, Jiawei Han

The rapid development of Multimodal Large Language Models (MLLMs) has enabled
the integration of multiple modalities, including texts and images, within the
large language model (LLM) framework. However, texts and images are usually
interconnected, forming a multimodal attributed graph (MMAG). It is
underexplored how MLLMs can incorporate the relational information
(\textit{i.e.}, graph structure) and semantic information (\textit{i.e.,} texts
and images) on such graphs for multimodal comprehension and generation. In this
paper, we propose GraphGPT-o, which supports omni-multimodal understanding and
creation on MMAGs. We first comprehensively study linearization variants to
transform semantic and structural information as input for MLLMs. Then, we
propose a hierarchical aligner that enables deep graph encoding, bridging the
gap between MMAGs and MLLMs. Finally, we explore the inference choices,
adapting MLLM to interleaved text and image generation in graph scenarios.
Extensive experiments on three datasets from different domains demonstrate the
effectiveness of our proposed method. Datasets and codes will be open-sourced
upon acceptance.

æè¦ï¼å¤æ¨¡æå¤§è¯­è¨æ¨¡å (MLLM) çå¿«éåå±ï¼ä¿è¿äºææ¬åå¾åç­å¤ç§æ¨¡æå¨å¤§åè¯­è¨æ¨¡å (LLM) æ¡æ¶åçæ´åãç¶èï¼ææ¬åå¾åéå¸¸æ¯ç¸äºå³èçï¼å½¢æå¤æ¨¡æå±æ§å¾ (MMAG)ãå¯¹äº MLLM å¦ä½æ´åæ­¤ç±»å¾ä¸çå³ç³»ä¿¡æ¯ï¼å³å¾ç»æï¼åè¯­ä¹ä¿¡æ¯ï¼å³ææ¬åå¾åï¼ä»¥è¿è¡å¤æ¨¡æçè§£åçæï¼ç®åä»æªå¾å°ååæ¢ç´¢ãå¨æ¬æä¸­ï¼æä»¬æåºäº GraphGPT-oï¼å®æ¯æå¨ MMAG ä¸è¿è¡å¨æ¹ä½å¤æ¨¡æçè§£ååå»ºãæä»¬é¦åå¨é¢ç ç©¶äºçº¿æ§ååä½ï¼ä»¥å°è¯­ä¹åç»æä¿¡æ¯è½¬æ¢ä¸º MLLM çè¾å¥ãç¶åï¼æä»¬æåºäºä¸ä¸ªåå±å¯¹é½å¨ï¼å®æ¯ææ·±åº¦å¾ç¼ç ï¼å¼¥åäº MMAG å MLLM ä¹é´çå·®è·ãæåï¼æä»¬æ¢ç´¢äºæ¨çéæ©ï¼ä½¿ MLLM éåºå¾åºæ¯ä¸­äº¤éçææ¬åå¾åçæãæ¥èªä¸åé¢åçä¸ç»æ°æ®éä¸çå¤§éå®éªè¡¨æäºæä»¬æåºçæ¹æ³çæææ§ãæ°æ®éåä»£ç å°å¨è¢«æ¥ååå¼æºã

##### **Exploring LLM-based Student Simulation for Metacognitive Cultivation**
2502.11678v1 by Haoxuan Li, Jifan Yu, Xin Cong, Yang Dang, Yisi Zhan, Huiqin Liu, Zhiyuan Liu

Metacognitive education plays a crucial role in cultivating students'
self-regulation and reflective thinking, providing essential support for those
with learning difficulties through academic advising. Simulating students with
insufficient learning capabilities using large language models offers a
promising approach to refining pedagogical methods without ethical concerns.
However, existing simulations often fail to authentically represent students'
learning struggles and face challenges in evaluation due to the lack of
reliable metrics and ethical constraints in data collection. To address these
issues, we propose a pipeline for automatically generating and filtering
high-quality simulated student agents. Our approach leverages a two-round
automated scoring system validated by human experts and employs a score
propagation module to obtain more consistent scores across the student graph.
Experimental results demonstrate that our pipeline efficiently identifies
high-quality student agents, and we discuss the traits that influence the
simulation's effectiveness. By simulating students with varying degrees of
learning difficulties, our work paves the way for broader applications in
personalized learning and educational assessment.

æè¦ï¼åèªç¥æè²å¨å¹é¤å­¸ççèªæèª¿ç¯ååææ§æèä¸­ç¼æ®èè³ééè¦çä½ç¨ï¼ééå­¸è¡è«®è©¢çºæå­¸ç¿å°é£çäººæä¾å¿è¦çæ¯æãä½¿ç¨å¤§åèªè¨æ¨¡åæ¨¡æ¬å­¸ç¿è½åä¸è¶³çå­¸çæä¾äºä¸ç¨®æåéçæ¹æ³ï¼å¯ä»¥å¨æ²æéå¾·åé¡çææ³ä¸æ¹é²æå­¸æ¹æ³ãç¶èï¼ç¾æçæ¨¡æ¬éå¸¸ç¡æ³çå¯¦å°åæ å­¸ççå­¸ç¿å°é£ï¼ä¸¦ä¸ç±æ¼ç¼ºä¹å¯é çææ¨åæ¸ææ¶éä¸­çéå¾·ç´æï¼å¨è©ä¼°ä¸­é¢è¨ææ°ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸åèªåçæåéæ¿¾é«è³ªéæ¨¡æ¬å­¸çä»£ççç®¡éãæåçåæ³å©ç¨äºç±äººé¡å°å®¶é©è­çå©è¼ªèªåè©åç³»çµ±ï¼ä¸¦æ¡ç¨åæ¸å³æ­æ¨¡çµä¾ç²å¾è·¨å­¸çåè¡¨æ´ä¸è´çåæ¸ãå¯¦é©çµæè¡¨æï¼æåçç®¡éææå°è­å¥äºé«è³ªéçå­¸çä»£çï¼ä¸¦ä¸æåè¨è«äºå½±é¿æ¨¡æ¬ææçç¹è³ªãééæ¨¡æ¬å·æä¸åç¨åº¦å­¸ç¿å°é£çå­¸çï¼æåçç ç©¶çºåæ§åå­¸ç¿åæè²è©ä¼°ä¸­çæ´å»£æ³æç¨éªå¹³äºéè·¯ã

##### **Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering**
2502.11491v1 by Runxuan Liu, Bei Luo, Jiaqi Li, Baoxin Wang, Ming Liu, Dayong Wu, Shijin Wang, Bing Qin

Large language models (LLMs) have shown remarkable capabilities in natural
language processing. However, in knowledge graph question answering tasks
(KGQA), there remains the issue of answering questions that require multi-hop
reasoning. Existing methods rely on entity vector matching, but the purpose of
the question is abstract and difficult to match with specific entities. As a
result, it is difficult to establish reasoning paths to the purpose, which
leads to information loss and redundancy. To address this issue, inspired by
human reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a
novel framework that constructs reasoning paths from purposes back to
conditions. ORT operates in three key phases: (1) using LLM to extract purpose
labels and condition labels, (2) constructing label reasoning paths based on
the KG ontology, and (3) using the label reasoning paths to guide knowledge
retrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves
state-of-the-art performance and significantly enhances the capability of LLMs
for KGQA.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçä¸­å±ç¾åºåè¶çè½åãç¶èï¼å¨ç¥è­åè­åç­ä»»å (KGQA) ä¸­ï¼ä»ç¶å­å¨éè¦å¤è·³æ¨çæè½åç­åé¡çåé¡ãç¾ææ¹æ³ä¾è³´æ¼å¯¦é«åéå¹éï¼ä½åé¡çç®çæ¯æ½è±¡çï¼é£ä»¥èç¹å®å¯¦é«å¹éãå æ­¤ï¼å¾é£å»ºç«æ¨çè·¯å¾ä¾éæç®çï¼éæå°è´è³è¨éºå¤±ååé¤ãçºäºè§£æ±ºéååé¡ï¼å¨äººé¡éåæç¶­çåç¼ä¸ï¼æåæåºäºåºæ¼æ¬ä½çéåæç¶­ (ORT)ï¼éæ¯ä¸ååµæ°çæ¶æ§ï¼å¯ä»¥å¾ç®çå»ºæ§æ¨çè·¯å¾ï¼ååæ¨å°æ¢ä»¶ãORT éä½å¨ä¸åééµéæ®µï¼(1) ä½¿ç¨ LLM èåç®çæ¨ç±¤åæ¢ä»¶æ¨ç±¤ï¼(2) åºæ¼ KG æ¬ä½å»ºæ§æ¨ç±¤æ¨çè·¯å¾ï¼ä»¥å (3) ä½¿ç¨æ¨ç±¤æ¨çè·¯å¾ä¾å¼å°ç¥è­æ·åãå¨ WebQSP å CWQ è³æéä¸çå¯¦é©é¡¯ç¤ºï¼ORT éå°äºæåé²çæè½ï¼ä¸¦é¡¯èå¢å¼·äº LLM å° KGQA çè½åã

##### **GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion**
2502.11471v1 by Kangyang Luo, Yuzhuo Bai, Cheng Gao, Shuzheng Si, Yingli Shen, Zhu Liu, Zhitong Wang, Cunliang Kong, Wenhao Li, Yufei Huang, Ye Tian, Xuantang Xiong, Lei Han, Maosong Sun

Knowledge Graph Completion (KGC), which aims to infer missing or incomplete
facts, is a crucial task for KGs. However, integrating the vital structural
information of KGs into Large Language Models (LLMs) and outputting predictions
deterministically remains challenging. To address this, we propose a new method
called GLTW, which encodes the structural information of KGs and merges it with
LLMs to enhance KGC performance. Specifically, we introduce an improved Graph
Transformer (iGT) that effectively encodes subgraphs with both local and global
structural information and inherits the characteristics of language model,
bypassing training from scratch. Also, we develop a subgraph-based
multi-classification training objective, using all entities within KG as
classification objects, to boost learning efficiency.Importantly, we combine
iGT with an LLM that takes KG language prompts as input.Our extensive
experiments on various KG datasets show that GLTW achieves significant
performance gains compared to SOTA baselines.

æè¦ï¼ç¥è­åè­è£å¨ (KGC) æ¨å¨æ¨è«éºå¤±æä¸å®æ´ç
äºå¯¦ï¼æ¯ KGs çä¸é ééµä»»åãç¶èï¼å° KGs çéè¦çµæ§
è³è¨æ´åè³å¤§åèªè¨æ¨¡å (LLM)ï¼ä¸¦ç¢ºå®æ§å°è¼¸åºé æ¸¬çµæï¼ä»ç¶æ¯ä¸é ææ°ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨±çº GLTWï¼å®ç·¨ç¢¼äº KGs ççµæ§è³è¨ï¼ä¸¦å°å¶è LLM åä½µï¼ä»¥å¢å¼· KGC çæè½ãå·é«ä¾èªªï¼æåå¼é²äºä¸åæ¹è¯çåå½¢è½æå¨ (iGT)ï¼å®è½ææå°ç·¨ç¢¼å·æå±é¨åå¨åçµæ§è³è¨çå­åï¼ä¸¦ç¹¼æ¿èªè¨æ¨¡åçç¹å¾µï¼ç¹éå¾é ­éå§çè¨ç·´ãæ­¤å¤ï¼æåéç¼äºä¸ååºæ¼å­åçå¤åé¡è¨ç·´ç®æ¨ï¼ä½¿ç¨ KG ä¸­çææå¯¦é«ä½çº
åé¡ç©ä»¶ï¼ä»¥æåå­¸ç¿æçãéè¦çæ¯ï¼æåå° iGT èä¸åå° KG èªè¨æç¤ºä½çºè¼¸å¥ç LLM çµåèµ·ä¾ãæåå¨åç¨® KG è³æéä¸é²è¡çå»£æ³å¯¦é©é¡¯ç¤ºï¼è SOTA åºæºç·ç¸æ¯ï¼GLTW ç²å¾äºé¡¯èçæè½æåã

##### **Large Language-Geometry Model: When LLM meets Equivariance**
2502.11149v1 by Zongzhao Li, Jiacheng Cen, Bing Su, Wenbing Huang, Tingyang Xu, Yu Rong, Deli Zhao

Accurately predicting 3D structures and dynamics of physical systems is
crucial in scientific applications. Existing approaches that rely on geometric
Graph Neural Networks (GNNs) effectively enforce $\mathrm{E}(3)$-equivariance,
but they often fall in leveraging extensive broader information. While direct
application of Large Language Models (LLMs) can incorporate external knowledge,
they lack the capability for spatial reasoning with guaranteed equivariance. In
this paper, we propose EquiLLM, a novel framework for representing 3D physical
systems that seamlessly integrates E(3)-equivariance with LLM capabilities.
Specifically, EquiLLM comprises four key components: geometry-aware prompting,
an equivariant encoder, an LLM, and an equivariant adaptor. Essentially, the
LLM guided by the instructive prompt serves as a sophisticated invariant
feature processor, while 3D directional information is exclusively handled by
the equivariant encoder and adaptor modules. Experimental results demonstrate
that EquiLLM delivers significant improvements over previous methods across
molecular dynamics simulation, human motion simulation, and antibody design,
highlighting its promising generalizability.

æè¦ï¼æºç¢ºé æ¸¬ç©çç³»çµ±ç 3D çµæ§åååå­¸å¨ç§å­¸æç¨ä¸­è³ééè¦ãä¾è³´æ¼å¹¾ä½åç¥ç¶ç¶²è·¯ (GNN) çç¾ææ¹æ³ææå°å·è¡ $\mathrm{E}(3)$-ç­è®æ§ï¼ä½å®åéå¸¸æå©ç¨å»£æ³çæ´å»£æ³çä¿¡æ¯ãéç¶å¤§åèªè¨æ¨¡å (LLM) çç´æ¥æç¨å¯ä»¥ç´å¥å¤é¨ç¥è­ï¼ä½å®åç¼ºä¹å·æä¿è­ç­è®æ§çç©ºéæ¨çè½åãå¨æ¬æä¸­ï¼æåæåºäº EquiLLMï¼éæ¯ä¸åç¨æ¼è¡¨ç¤º 3D ç©çç³»çµ±çæ°æ¡æ¶ï¼å®å° E(3)-ç­è®æ§è LLM è½åç¡ç¸«éæãå·é«ä¾èªªï¼EquiLLM åå«ååééµçµæé¨åï¼æç¥å¹¾ä½çæç¤ºãç­è®ç·¨ç¢¼å¨ãLLM åç­è®é©éå¨ãå¾æ¬è³ªä¸è¬ï¼ç±æå°æ§æç¤ºå¼å°ç LLM ä½çºä¸åè¤éçä¸è®ç¹å¾µèçå¨ï¼è 3D æ¹åä¿¡æ¯åç±ç­è®ç·¨ç¢¼å¨åé©éå¨æ¨¡çµç¨å®¶èçãå¯¦é©çµæè¡¨æï¼EquiLLM å¨åå­ååå­¸æ¨¡æ¬ãäººé«éåæ¨¡æ¬åæé«è¨­è¨æ¹é¢æä¾äºå°ä»¥åæ¹æ³çé¡¯èæ¹é²ï¼çªåºäºå¶æå¸æçæ³åè½åã

##### **Beyond Pairwise: Global Zero-shot Temporal Graph Generation**
2502.11114v1 by Alon Eirew, Kfir Bar, Ido Dagan

Temporal relation extraction (TRE) is a fundamental task in natural language
processing (NLP) that involves identifying the temporal relationships between
events in a document. Despite the advances in large language models (LLMs),
their application to TRE remains limited. Most existing approaches rely on
pairwise classification, in which event pairs are considered individually,
leading to computational inefficiency and a lack of global consistency in the
resulting temporal graph. In this work, we propose a novel zero-shot method for
TRE that generates a document's complete temporal graph at once, then applies
transitive constraints optimization to refine predictions and enforce temporal
consistency across relations. Additionally, we introduce OmniTemp, a new
dataset with complete annotations for all pairs of targeted events within a
document. Through experiments and analyses, we demonstrate that our method
significantly outperforms existing zero-shot approaches while achieving
competitive performance with supervised models.

æè¦ï¼æééä¿æ½å (TRE) æ¯èªç¶èªè¨èç (NLP) ä¸­çä¸é åºæ¬ä»»åï¼æ¶åè­å¥æä»¶ä¸­äºä»¶ä¹éçæééä¿ãåç®¡å¤§åèªè¨æ¨¡å (LLM) åå¾é²å±ï¼ä½å®åå¨ TRE ä¸­çæç¨ä»ç¶æéãç¾æçå¤§å¤æ¸æ¹æ³ä¾è³´æ¼æå°åé¡ï¼å¶ä¸­äºä»¶å°è¢«å®ç¨èæ®ï¼å°è´è¨ç®æçä½ä¸ä¸å¨çæçæåºåä¸­ç¼ºä¹å¨å±ä¸è´æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©ç TRE é¶æ¬¡å­¸ç¿æ¹æ³ï¼å®å¯ä»¥ä¸æ¬¡çææä»¶çå®æ´æåºåï¼ç¶å¾æç¨éç§»ç´ææä½³åä¾åªåé æ¸¬ä¸¦å¼·å¶éä¿ä¹éçæéä¸è´æ§ãæ­¤å¤ï¼æåå¼å¥äº OmniTempï¼éæ¯ä¸åæ°çæ¸æéï¼å¶ä¸­åå«æä»¶å§ææç®æ¨äºä»¶å°çå®æ´è¨»è§£ãééå¯¦é©ååæï¼æåè­æäºæåçæ¹æ³æé¡¯åªæ¼ç¾æçé¶æ¬¡å­¸ç¿æ¹æ³ï¼åæå¯¦ç¾äºèç£ç£æ¨¡åç¸ç¶çæ§è½ã

##### **Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications**
2502.11108v1 by Alexandru Lecu, Adrian Groza, Lezan Hawizy

Large language models (LLMs) have significantly advanced the field of natural
language generation. However, they frequently generate unverified outputs,
which compromises their reliability in critical applications. In this study, we
propose an innovative framework that combines structured biomedical knowledge
with LLMs through a retrieval-augmented generation technique. Our system
develops a thorough knowledge graph by identifying and refining causal
relationships and named entities from medical abstracts related to age-related
macular degeneration (AMD). Using a vector-based retrieval process and a
locally deployed language model, our framework produces responses that are both
contextually relevant and verifiable, with direct references to clinical
evidence. Experimental results show that this method notably decreases
hallucinations, enhances factual precision, and improves the clarity of
generated responses, providing a robust solution for advanced biomedical
chatbot applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¤§å¹æ¨åèªç¶èªè¨çæçé åãç¶èï¼å®åç¶å¸¸ç¢çæªç¶é©è­çè¼¸åºï¼éææå®³å®åå¨ééµæç¨ä¸­çå¯é æ§ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ååµæ°çæ¡æ¶ï¼ééæª¢ç´¢å¢å¼·çææè¡ï¼å°çµæ§åççç©é«å­¸ç¥è­è LLM çµåãæåçç³»çµ±ééè­å¥åç²¾çèå¹´é½¡ç¸éæ§é»æé¨çè® (AMD) ç¸éçé«å­¸æè¦ä¸­çå æéä¿åå½åå¯¦é«ï¼éç¼ä¸åå¾¹åºçç¥è­åè­ãæåçæ¡æ¶ä½¿ç¨åºæ¼åéçæª¢ç´¢æµç¨åæ¬å°é¨ç½²çèªè¨æ¨¡åï¼ç¢çå¨èçµ¡ä¸ç¸éä¸å¯é©è­çåæï¼ä¸¦ç´æ¥åèè¨åºè­æãå¯¦é©çµæé¡¯ç¤ºï¼æ­¤æ¹æ³é¡¯èæ¸å°äºå¹»è¦ºãå¢å¼·äºäºå¯¦æºç¢ºæ§ï¼ä¸¦æ¹åäºçæåæçæ¸æ°åº¦ï¼çºåé²ççç©é«å­¸èå¤©æ©å¨äººæç¨ç¨å¼æä¾äºç©©å¥çè§£æ±ºæ¹æ¡ã

##### **Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection**
2502.11062v1 by Yang Zhao, Li Du, Xiao Ding, Yangou Ouyang, Hepeng Wang, Kai Xiong, Jinglong Gao, Zhouhao Sun, Dongliang Xu, Yang Qing, Dongchen Li, Bing Qin, Ting Liu

Large language models (LLMs) have shown great potential across various
industries due to their remarkable ability to generalize through instruction
tuning. However, the limited availability of domain-specific data significantly
hampers their performance on specialized tasks. While existing methods
primarily focus on selecting training data from general datasets that are
similar to the target domain, they often fail to consider the joint
distribution of instructions, resulting in inefficient learning and suboptimal
knowledge transfer. To address these challenges, we introduce G2IS
(Gradient-based Graph Instruction Selection), a novel method that constructs a
mixed gradient-based instruction graph to capture the joint distribution and
interdependencies between instructions. By accounting for the relationships
between instructions, G2IS improves domain adaptation efficiency. Additionally,
we propose a gradient walk algorithm to refine the data selection process,
enhancing both training effectiveness and efficiency. Our experiments
demonstrate that G2IS outperforms traditional methods across various domain
adaptation tasks, yielding significant performance gains, particularly in
complex, data-scarce scenarios. These results underscore the potential of G2IS
in advancing the development of large, domain-specific models.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å å¶ééæä»¤å¾®èª¿èå·åçåè¶æ³åè½åï¼å¨åç¢æ¥­ä¸­å±ç¾åºæ¥µå¤§çæ½åãç¶èï¼ç¹å®é åè³æçåå¾æéï¼å¤§å¹å½±é¿å¶å¨å°æ¥­ä»»åä¸çè¡¨ç¾ãç¾ææ¹æ³ä¸»è¦å°æ³¨æ¼å¾èç®æ¨é åé¡ä¼¼çéç¨è³æéä¸­é¸åè¨ç·´è³æï¼ä½å®åéå¸¸æªè½èéæä»¤çè¯ååä½ï¼å°è´å­¸ç¿æçä¸å½°ä¸ç¥è­å³éä¸ä½³ãçºäºæå°éäºææ°ï¼æåå¼é² G2ISï¼åºæ¼æ¢¯åº¦çåå½¢æä»¤é¸åï¼ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å¯å»ºæ§ä¸åæ··åçåºæ¼æ¢¯åº¦çæä»¤åå½¢ï¼ä»¥æ·åæä»¤ä¹éçè¯ååä½åç¸äºä¾è³´æ§ãééèéæä»¤ä¹éçéä¿ï¼G2IS æåäºé åé©æçæçãæ­¤å¤ï¼æåæåºäºä¸ç¨®æ¢¯åº¦æ¼«æ­¥æ¼ç®æ³ä¾åªåè³æé¸åç¨åºï¼åææåè¨ç·´æè½åæçãæåçå¯¦é©è­æï¼G2IS å¨åç¨®é åé©æä»»åä¸­åªæ¼å³çµ±æ¹æ³ï¼ç¢çé¡¯èçæè½æåï¼ç¹å¥æ¯å¨è³æç¨å°çè¤éå ´æ¯ä¸­ãéäºçµæçªé¡¯äº G2IS å¨æ¨åå¤§åç¹å®é åæ¨¡åç¼å±æ¹é¢çæ½åã

##### **CounterBench: A Benchmark for Counterfactuals Reasoning in Large Language Models**
2502.11008v1 by Yuefei Chen, Vivek K. Singh, Jing Ma, Ruxiang Tang

Counterfactual reasoning is widely recognized as one of the most challenging
and intricate aspects of causality in artificial intelligence. In this paper,
we evaluate the performance of large language models (LLMs) in counterfactual
reasoning. In contrast to previous studies that primarily focus on commonsense
causal reasoning, where LLMs often rely on prior knowledge for inference, we
specifically assess their ability to perform counterfactual inference using a
set of formal rules. To support this evaluation, we introduce a new benchmark
dataset, CounterBench, comprising 1K counterfactual reasoning questions. The
dataset is designed with varying levels of difficulty, diverse causal graph
structures, distinct types of counterfactual questions, and multiple
nonsensical name variants. Our experiments demonstrate that counterfactual
reasoning poses a significant challenge for LLMs, with most models performing
at levels comparable to random guessing. To enhance LLM's counterfactual
reasoning ability, we propose a novel reasoning paradigm, CoIn, which guides
LLMs through iterative reasoning and backtracking to systematically explore
counterfactual solutions. Experimental results show that our method
significantly improves LLM performance on counterfactual reasoning tasks and
consistently enhances performance across different LLMs.Our dataset is
available at https://huggingface.co/datasets/CounterBench/CounterBench.

æè¦ï¼åäºå¯¦æ¨çè¢«å»£æ³èªçºæ¯äººå·¥æºæ§ä¸­å æéä¿æå·ææ°æ§åè¤éçé¢åä¹ä¸ãå¨æ¬æä¸­ï¼æåè©ä¼°å¤§åèªè¨æ¨¡å (LLM) å¨åäºå¯¦æ¨çä¸­çè¡¨ç¾ãèä¸»è¦éæ³¨å¸¸è­å ææ¨çï¼å¶ä¸­ LLM ç¶å¸¸ä¾è³´åé©ç¥è­ä¾é²è¡æ¨ççååç ç©¶ä¸åï¼æåç¹å¥è©ä¼°å®åä½¿ç¨ä¸çµå½¢å¼è¦åå·è¡åäºå¯¦æ¨ççè½åãçºäºæ¯ææ­¤è©ä¼°ï¼æåå¼å¥äºä¸åæ°çåºæºè³æé CounterBenchï¼å¶ä¸­åå« 1K ååäºå¯¦æ¨çåé¡ãè³æéçè¨­è¨å·æä¸åçé£åº¦ç­ç´ãå¤æ¨£åçå æåçµæ§ãä¸åé¡åçåäºå¯¦åé¡åå¤ç¨®ç¡æç¾©çåç¨±è®é«ãæåçå¯¦é©è¡¨æï¼åäºå¯¦æ¨çå° LLM æ§æéå¤§ææ°ï¼å¤§å¤æ¸æ¨¡åçè¡¨ç¾èé¨æ©çæ¸¬ç¸ç¶ãçºäºå¢å¼· LLM çåäºå¯¦æ¨çè½åï¼æåæåºäºä¸ç¨®æ°ç©çæ¨çç¯ä¾ CoInï¼å®å¼å° LLM ééåè¦æ¨çååæº¯ç³»çµ±æ§å°æ¢ç´¢åäºå¯¦è§£ãå¯¦é©çµæè¡¨æï¼æåçæ¹æ³é¡¯èæå LLM å¨åäºå¯¦æ¨çä»»åä¸çè¡¨ç¾ï¼ä¸¦æçºå¢å¼·ä¸å LLM çè¡¨ç¾ãæåçè³æéå¯å¨ https://huggingface.co/datasets/CounterBench/CounterBench åå¾ã

##### **RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation**
2502.10996v1 by Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, Jiawei Han

Retrieval-augmented language models often struggle with knowledge-intensive
tasks due to inefficient retrieval, unstructured knowledge integration, and
single-pass architectures. We present Retrieval-And-Structuring (RAS), a novel
framework that dynamically constructs and reasons over query-specific knowledge
graphs through iterative retrieval and structuring. RAS introduces four key
technical innovations: (1) a themescoped retrieval mechanism that efficiently
narrows the search space while maintaining retrieval quality, (2) an action
planning module that determines knowledge needs and generates focused
sub-queries, (3) a dynamic knowledge structuring approach that converts
retrieved text into an evolving knowledge graph, and (4) a graph-augmented
answering component that leverages the accumulated structured information. Our
framework achieves state-of-the-art performance, surpassing leading baselines
by 6.4% with open-source language models and 7.0% with proprietary models on
seven knowledge-intensive generation datasets across all evaluation metrics.
Detailed ablation studies verify the contribution of each technical component
to the overall system performance.

æè¦ï¼æ£ç´¢å¢å¼ºè¯­è¨æ¨¡åéå¸¸ä¼å æ£ç´¢æçä½ãç¥è¯æ´åæ ç»æååæ¬¡éè¿æ¶æèé¾ä»¥èä»»ç¥è¯å¯éåä»»å¡ãæä»¬æåºæ£ç´¢åç»æå (RAS)ï¼è¿æ¯ä¸ä¸ªæ°é¢çæ¡æ¶ï¼éè¿è¿­ä»£æ£ç´¢åç»æåï¼å¨ææå»ºåæ¨çç¹å®äºæ¥è¯¢çç¥è¯å¾è°±ãRAS å¼å¥äºåé¡¹å³é®ææ¯åæ°ï¼(1) ä¸»é¢èå´æ£ç´¢æºå¶ï¼å¨ä¿ææ£ç´¢è´¨éçåæ¶ææç¼©å°æç´¢ç©ºé´ï¼(2) å¨ä½è§åæ¨¡åï¼ç¡®å®ç¥è¯éæ±å¹¶çæéç¹å­æ¥è¯¢ï¼(3) å¨æç¥è¯ç»æåæ¹æ³ï¼å°æ£ç´¢å°çææ¬è½¬æ¢ä¸ºä¸æ­åå±çç¥è¯å¾è°±ï¼ä»¥å (4) å¾è°±å¢å¼ºååç­ç»ä»¶ï¼å©ç¨ç´¯ç§¯çç»æåä¿¡æ¯ãæä»¬çæ¡æ¶å®ç°äºæåè¿çæ§è½ï¼å¨ä¸ä¸ªç¥è¯å¯éåçææ°æ®éä¸ï¼ä½¿ç¨å¼æºè¯­è¨æ¨¡åæé«äº 6.4%ï¼ä½¿ç¨ä¸ææ¨¡åæé«äº 7.0%ï¼è¶è¶äºé¢åçåºçº¿ï¼ä¸ææè¯ä¼°ææ åå¦æ­¤ãè¯¦ç»çæ¶èç ç©¶éªè¯äºæ¯ä¸ªææ¯ç»ä»¶å¯¹æ´ä½ç³»ç»æ§è½çè´¡ç®ã

##### **Developing Conversational Speech Systems for Robots to Detect Speech Biomarkers of Cognition in People Living with Dementia**
2502.10896v1 by Rohith Perumandla, Young-Ho Bae, Diego Izaguirre, Esther Hwang, Andrew Murphy, Long-Jing Hsu, Selma Sabanovic, Casey C. Bennett

This study presents the development and testing of a conversational speech
system designed for robots to detect speech biomarkers indicative of cognitive
impairments in people living with dementia (PLwD). The system integrates a
backend Python WebSocket server and a central core module with a large language
model (LLM) fine-tuned for dementia to process user input and generate robotic
conversation responses in real-time in less than 1.5 seconds. The frontend user
interface, a Progressive Web App (PWA), displays information and biomarker
score graphs on a smartphone in real-time to human users (PLwD, caregivers,
clinicians). Six speech biomarkers based on the existing literature - Altered
Grammar, Pragmatic Impairments, Anomia, Disrupted Turn-Taking, Slurred
Pronunciation, and Prosody Changes - were developed for the robot conversation
system using two datasets, one that included conversations of PLwD with a human
clinician (DementiaBank dataset) and one that included conversations of PLwD
with a robot (Indiana dataset). We also created a composite speech biomarker
that combined all six individual biomarkers into a single score. The speech
system's performance was first evaluated on the DementiaBank dataset showing
moderate correlation with MMSE scores, with the composite biomarker score
outperforming individual biomarkers. Analysis of the Indiana dataset revealed
higher and more variable biomarker scores, suggesting potential differences due
to study populations (e.g. severity of dementia) and the conversational
scenario (human-robot conversations are different from human-human). The
findings underscore the need for further research on the impact of
conversational scenarios on speech biomarkers and the potential clinical
applications of robotic speech systems.

æè¦ï¼æ¬ç ç©¶å±ç¤ºäºå°è©±å¼èªé³ç³»çµ±çéç¼åæ¸¬è©¦ï¼è©²ç³»çµ±å°çºæ©å¨äººè¨­è¨ï¼ç¨æ¼åµæ¸¬å¤±æºçæ£èï¼PLwDï¼èªç¥éç¤çèªè¨çç©æ¨è¨ãè©²ç³»çµ±æ´åäºå¾ç«¯ Python WebSocket ä¼ºæå¨åä¸åä¸­å¤®æ ¸å¿æ¨¡çµï¼å¶ä¸­åå«éå°å¤±æºçå¾®èª¿çå¤§èªè¨æ¨¡åï¼LLMï¼ï¼ä»¥èçä½¿ç¨èè¼¸å¥ä¸¦å¨ä¸å° 1.5 ç§çæéå§ç¢çæ©å¨äººå°è©±åæãåç«¯ä½¿ç¨èä»é¢ï¼æ¼¸é²å¼ç¶²è·¯æç¨ç¨å¼ï¼PWAï¼æå¨æºæ§åææ©ä¸å³æåäººé¡ä½¿ç¨èï¼PLwDãç§è­·èãè¨åºé«çï¼é¡¯ç¤ºè³è¨åçç©æ¨è¨è©ååè¡¨ãæ ¹æç¾ææç»ï¼éå°æ©å¨äººå°è©±ç³»çµ±éç¼äºå­åèªè¨çç©æ¨è¨ï¼èªæ³æ¹è®ãå¯¦ç¨éç¤ãå¤±èªçãè¼ªæµä¸­æ·ãç¼é³ä¸æ¸åé»å¾è®åï¼ä½¿ç¨äºå©åè³æéï¼ä¸ååå« PLwD èäººé¡è¨åºé«çå°è©±ï¼DementiaBank è³æéï¼ï¼å¦ä¸ååå« PLwD èæ©å¨äººå°è©±ï¼Indiana è³æéï¼ãæåéå»ºç«äºä¸åè¤åèªè¨çç©æ¨è¨ï¼å°ææå­ååå¥çç©æ¨è¨çµåæä¸åå®ä¸è©åãèªè¨ç³»çµ±çæè½é¦åå¨ DementiaBank è³æéä¸é²è¡è©ä¼°ï¼é¡¯ç¤ºè MMSE è©åæä¸­ç­ç¸éæ§ï¼è¤åçç©æ¨è¨è©ååªæ¼åå¥çç©æ¨è¨ãå° Indiana è³æéçåæé¡¯ç¤ºåºè¼é«ä¸è®ç°æ§è¼å¤§ççç©æ¨è¨è©åï¼éè¡¨æç±æ¼ç ç©¶æç¾¤ï¼ä¾å¦å¤±æºççå´éç¨åº¦ï¼åå°è©±æå¢ï¼äººæ©å°è©±èäººéå°è©±ä¸åï¼èç¢çæ½å¨å·®ç°ãç ç©¶çµæå¼·èª¿éè¦é²ä¸æ­¥ç ç©¶å°è©±æå¢å°èªè¨çç©æ¨è¨çå½±é¿ï¼ä»¥åæ©å¨äººèªè¨ç³»çµ±çæ½å¨è¨åºæç¨ã

##### **Evaluating improvements on using Large Language Models (LLMs) for property extraction in the Open Research Knowledge Graph (ORKG)**
2502.10768v1 by Sandra Schaftner

Current research highlights the great potential of Large Language Models
(LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly
complex step in this process is relation extraction, aimed at identifying
suitable properties to describe the content of research. This study builds
directly on previous research of three Open Research Knowledge Graph (ORKG)
team members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and
Mistral for property extraction in scientific literature. Given the moderate
performance observed, the previous work concluded that fine-tuning is needed to
improve these models' alignment with scientific tasks and their emulation of
human expertise. Expanding on this prior experiment, this study evaluates the
impact of advanced prompt engineering techniques and demonstrates that these
techniques can highly significantly enhance the results. Additionally, this
study extends the property extraction process to include property matching to
existing ORKG properties, which are retrieved via the API. The evaluation
reveals that results generated through advanced prompt engineering achieve a
higher proportion of matches with ORKG properties, further emphasizing the
enhanced alignment achieved. Moreover, this lays the groundwork for addressing
challenges such as the inconsistency of ORKG properties, an issue highlighted
in prior studies. By assigning unique URIs and using standardized terminology,
this work increases the consistency of the properties, fulfilling a crucial
aspect of Linked Data and FAIR principles - core commitments of ORKG. This, in
turn, significantly enhances the applicability of ORKG content for subsequent
tasks such as comparisons of research publications. Finally, the study
concludes with recommendations for future improvements in the overall property
extraction process.

æè¦ï¼<paragraph>ç®åçèª¿æ¥å¼·èª¿å¤§èªè¨æ¨¡å (LLM) å¨å»ºæ§å­¸è¡ç¥è­åè­ (SKG) ä¸çå·¨å¤§æ½åãæ­¤éç¨ä¸­ç¹å¥è¤éçæ­¥é©æ¯éä¿èåï¼ç®æ¨æ¯æ¾åºåé©çå±¬æ§ä¾æè¿°ç ç©¶å§å®¹ãæ¬ç ç©¶ç´æ¥å»ºç«å¨ä¸ä½éæ¾ç ç©¶ç¥è­åè­ (ORKG) åéæå¡ååç ç©¶çåºç¤ä¸ï¼ä»åè©ä¼°äº GPT-3.5ãLlama 2 å Mistral ç­ LLM å¨ç§å­¸æç»ä¸­èåå±¬æ§çæºåææ³ãéæ¼è§å¯å°çè¡¨ç¾ä¸­ç­ï¼ååçç ç©¶çµè«æ¯éè¦å¾®èª¿ï¼ä»¥æ¹åéäºæ¨¡åèç§å­¸ä»»åçä¸è´æ§ï¼ä»¥åå®åå°äººé¡å°æ¥­ç¥è­çæ¨¡æ¬ãæ¬ç ç©¶æ´å±äºååçå¯¦é©ï¼è©ä¼°äºé²éæç¤ºå·¥ç¨æè¡çå½±é¿ï¼ä¸¦è­æéäºæè¡å¯ä»¥å¤§å¹é¡¯èå°æåçµæãæ­¤å¤ï¼æ¬ç ç©¶å°å±¬æ§èåæµç¨æ´å±å°åå«èç¾æ ORKG å±¬æ§çå±¬æ§æ¯å°ï¼éäºå±¬æ§æ¯éé API æ·åçãè©ä¼°çµæé¡¯ç¤ºï¼ééé²éæç¤ºå·¥ç¨ç¢çççµæè ORKG å±¬æ§ææ´é«çæ¯å°æ¯ä¾ï¼é²ä¸æ­¥å¼·èª¿æéæçé²éä¸è´æ§ãæ­¤å¤ï¼éä¹çºäºè§£æ±ºååçç ç©¶ä¸­å¼·èª¿çåé¡ï¼ä¾å¦ ORKG å±¬æ§çä¸ä¸è´æ§ï¼å¥ å®äºåºç¤ãééæå®å¯ä¸ç URI ä¸¦ä½¿ç¨æ¨æºåçè¡èªï¼æ¬ç ç©¶å¢å äºå±¬æ§çç¸å®¹æ§ï¼éæäºé£çµè³æå FAIR ååçéè¦å±¤é¢ï¼éæ¯ ORKG çæ ¸å¿æ¿è«¾ãéåéä¾å¤§å¹æåäº ORKG å§å®¹å¨å¾çºä»»åä¸­çé©ç¨æ§ï¼ä¾å¦ç ç©¶åºçåçæ¯è¼ãæå¾ï¼æ¬ç ç©¶ä»¥éå°æ´é«å±¬æ§èåæµç¨æªä¾æ¹é²çå»ºè­°ä½çºçµè«ã</paragraph>

##### **K-Edit: Language Model Editing with Contextual Knowledge Awareness**
2502.10626v1 by Elan Markowitz, Anil Ramakrishna, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan

As the world changes, we need to be able to update our models and correct
false information without costly retraining. Knowledge-based model editing
enables precise modifications to the weights of large language models in order
to modify the information encoded within. Recent approaches have seen success
in enabling recall of edited information for thousands of edits at once.
However, these approaches fail to produce edits that account for associated
contextual information. We present K-Edit, an effective approach to generating
contextually consistent knowledge edits. By using knowledge graphs, which
maintain contextual consistency when an edge is edited, we are able to generate
additional \textit{contextual edits} that ensure consistency of related
information in the language model. Our experiments demonstrate significant
improvements in multi-hop question answering while maintaining the general
effectiveness and scalability of model edits.

æè¦ï¼é¨èä¸çè®åï¼æåéè¦è½å¤ æ´æ°æåçæ¨¡åï¼ä¸¦å¨ä¸é²è¡æè²´çéæ°è¨ç·´çææ³ä¸æ´æ­£é¯èª¤è³è¨ãåºæ¼ç¥è­çæ¨¡åç·¨è¼¯è½å¤ å°å¤§åèªè¨æ¨¡åçæ¬éé²è¡ç²¾ç¢ºä¿®æ¹ï¼ä»¥ä¾¿ä¿®æ¹å¶ä¸­ç·¨ç¢¼çè³è¨ãæè¿çæ¹æ³å¨ä¸æ¬¡åç¨æ¸åæ¬¡ç·¨è¼¯çç·¨è¼¯è³è¨çå¬åæ¹é¢åå¾äºæåãç¶èï¼éäºæ¹æ³ç¡æ³ç¢çèæ®ç¸éä¸ä¸æè³è¨çç·¨è¼¯ãæåæåº K-Editï¼éæ¯ä¸ç¨®ç¢çä¸ä¸æä¸è´çç¥è­ç·¨è¼¯çæææ¹æ³ãééä½¿ç¨ç¥è­åï¼å¨ç·¨è¼¯éç·£æä¿æä¸ä¸æä¸è´æ§ï¼æåè½å¤ ç¢çé¡å¤çãä¸ä¸æç·¨è¼¯ãï¼ä»¥ç¢ºä¿èªè¨æ¨¡åä¸­ç¸éè³è¨çä¸è´æ§ãæåçå¯¦é©è­æäºå¤è·³åé¡åç­çé¡¯èæ¹é²ï¼åæä¿æäºæ¨¡åç·¨è¼¯çä¸è¬æææ§åå¯æ´åæ§ã

##### **ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language Interactions for Computer-Aided Diagnosis**
2502.10620v1 by Xueshen Li, Xinlong Hou, Ziyi Huang, Yu Gan

Recent advancements in large language models (LLMs) have demonstrated
extraordinary comprehension capabilities with remarkable breakthroughs on
various vision-language tasks. However, the application of LLMs in generating
reliable medical diagnostic reports remains in the early stages. Currently,
medical LLMs typically feature a passive interaction model where doctors
respond to patient queries with little or no involvement in analyzing medical
images. In contrast, some ChatBots simply respond to predefined queries based
on visual inputs, lacking interactive dialogue or consideration of medical
history. As such, there is a gap between LLM-generated patient-ChatBot
interactions and those occurring in actual patient-doctor consultations. To
bridge this gap, we develop an LLM-based dialogue system, namely proactive
multi-round vision-language interactions for computer-aided diagnosis
(ProMRVL-CAD), to generate patient-friendly disease diagnostic reports. The
proposed ProMRVL-CAD system allows proactive dialogue to provide patients with
constant and reliable medical access via an integration of knowledge graph into
a recommendation system. Specifically, we devise two generators: a Proactive
Question Generator (Pro-Q Gen) to generate proactive questions that guide the
diagnostic procedure and a Multi-Vision Patient-Text Diagnostic Report
Generator (MVP-DR Gen) to produce high-quality diagnostic reports. Evaluating
two real-world publicly available datasets, MIMIC-CXR and IU-Xray, our model
has better quality in generating medical reports. We further demonstrate the
performance of ProMRVL achieves robust under the scenarios with low image
quality. Moreover, we have created a synthetic medical dialogue dataset that
simulates proactive diagnostic interactions between patients and doctors,
serving as a valuable resource for training LLM.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) æè¿çé²å±å·²å±ç¾åºéå¡ççè§£è½åï¼å¨åç¨®è¦è¦ºèªè¨ä»»åä¸­åå¾äºé¡¯èççªç ´ãç¶èï¼LLM å¨ç¢çå¯é çé«çè¨ºæ·å ±åä¸­çæç¨ä»èæ¼æ©æéæ®µãç®åï¼é«ç LLM éå¸¸æ¡ç¨è¢«åäºåæ¨¡å¼ï¼é«çå°æ£èççåååºåæï¼ä½å¾å°ææ ¹æ¬ä¸åèåæé«çå½±åãç¸æ¯ä¹ä¸ï¼æäºèå¤©æ©å¨äººåæ ¹æè¦è¦ºè¼¸å¥åæé åå®ç¾©çæ¥è©¢ï¼ç¼ºä¹äºåå°è©±æå°çå²çèéãå æ­¤ï¼LLM ç¢ççæ£èèå¤©æ©å¨äººäºåèå¯¦éæ£èé«çè«®è©¢ä¹éå­å¨å·®è·ãçºäºå½åéä¸å·®è·ï¼æåéç¼äºä¸ååºæ¼ LLM çå°è©±ç³»çµ±ï¼å³ä¸»åå¤è¼ªè¦è¦ºèªè¨äºåï¼ç¨æ¼é»è¦è¼å©è¨ºæ· (ProMRVL-CAD)ï¼ä»¥ç¢çå°æ£èååçç¾çè¨ºæ·å ±åãå»ºè­°ç ProMRVL-CAD ç³»çµ±åè¨±ä¸»åå°è©±ï¼ééå°ç¥è­åè­æ´åå°æ¨è¦ç³»çµ±ä¸­ï¼çºæ£èæä¾æçºä¸å¯é çé«çç®¡éãå·é«ä¾èªªï¼æåè¨­è¨äºå©åç¢çå¨ï¼ä¸»ååé¡ç¢çå¨ (Pro-Q Gen)ï¼ç¨æ¼ç¢çå¼å°è¨ºæ·ç¨åºçä¸»ååé¡ï¼ä»¥åå¤è¦è¦ºæ£èæå­è¨ºæ·å ±åç¢çå¨ (MVP-DR Gen)ï¼ç¨æ¼ç¢çé«åè³ªçè¨ºæ·å ±åãè©ä¼°å©åçå¯¦ä¸çå¬éå¯ç¨çè³æéï¼MIMIC-CXR å IU-Xrayï¼æåçæ¨¡åå¨ç¢çé«çå ±åæ¹é¢åè³ªè¼ä½³ãæåé²ä¸æ­¥è­æ ProMRVL çæè½ï¼å¨å½±ååè³ªä½çææ³ä¸ä»è½ç©©å¥éè¡ãæ­¤å¤ï¼æåå»ºç«äºä¸åæ¨¡æ¬æ£èåé«çä¹éä¸»åè¨ºæ·äºåçåæé«çå°è©±è³æéï¼ä½çºè¨ç·´ LLM çå¯¶è²´è³æºã</paragraph>

##### **GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs**
2502.10522v1 by Shima Khoshraftar, Niaz Abedini, Amir Hajian

The application of large language models (LLMs) to graph data has attracted a
lot of attention recently. LLMs allow us to use deep contextual embeddings from
pretrained models in text-attributed graphs, where shallow embeddings are often
used for the text attributes of nodes. However, it is still challenging to
efficiently encode the graph structure and features into a sequential form for
use by LLMs. In addition, the performance of an LLM alone, is highly dependent
on the structure of the input prompt, which limits their effectiveness as a
reliable approach and often requires iterative manual adjustments that could be
slow, tedious and difficult to replicate programmatically. In this paper, we
propose GraphiT (Graphs in Text), a framework for encoding graphs into a
textual format and optimizing LLM prompts for graph prediction tasks. Here we
focus on node classification for text-attributed graphs. We encode the graph
data for every node and its neighborhood into a concise text to enable LLMs to
better utilize the information in the graph. We then further programmatically
optimize the LLM prompts using the DSPy framework to automate this step and
make it more efficient and reproducible. GraphiT outperforms our LLM-based
baselines on three datasets and we show how the optimization step in GraphiT
leads to measurably better results without manual prompt tweaking. We also
demonstrated that our graph encoding approach is competitive to other graph
encoding methods while being less expensive because it uses significantly less
tokens for the same task.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) å¨åè¡¨è³æçæç¨æè¿ååéæ³¨ãLLM è®æåè½å¤ å¨æå­æ¨è¨åè¡¨ä¸­ä½¿ç¨é è¨ç·´æ¨¡åçæ·±åº¦èçµ¡åµå¥ï¼å¶ä¸­æ·ºå±¤åµå¥éå¸¸ç¨æ¼ç¯é»çæå­å±¬æ§ãç¶èï¼è¦ææçå°å°åè¡¨çµæ§åç¹å¾µç·¨ç¢¼æåºåå½¢å¼ä¾ LLM ä½¿ç¨ï¼ä»ç¶æ¯ä¸é ææ°ãæ­¤å¤ï¼å®ç¨ LLM çæè½é«åº¦ä¾è³´è¼¸å¥æç¤ºççµæ§ï¼ééå¶äºå®åä½çºå¯é æ¹æ³çæææ§ï¼èä¸éå¸¸éè¦åè¦çäººå·¥èª¿æ´ï¼éå¯è½æç·©æ¢ãç¹ç£ä¸é£ä»¥ééç¨å¼è¤è£½ãå¨æ¬æä¸­ï¼æåæåº GraphiTï¼æå­ä¸­çåè¡¨ï¼ï¼ä¸åç¨æ¼å°åè¡¨ç·¨ç¢¼ææå­æ ¼å¼ä¸¦æä½³å LLM æç¤ºä»¥é²è¡åè¡¨é æ¸¬ä»»åçæ¶æ§ãå¨éè£¡ï¼æåå°æ³¨æ¼æå­æ¨è¨åè¡¨çç¯é»åé¡ãæåå°æ¯åç¯é»åå¶é°åçåè¡¨è³æç·¨ç¢¼æç°¡æ½çæå­ï¼è® LLM è½å¤ æ´å¥½å°å©ç¨åè¡¨ä¸­çè³è¨ãç¶å¾ï¼æåé²ä¸æ­¥ééç¨å¼æä½³å LLM æç¤ºï¼ä½¿ç¨ DSPy æ¶æ§èªååéåæ­¥é©ï¼ä¸¦ä½¿å¶æ´ææçä¸å¯è¤è£½ãGraphite å¨ä¸åè³æéä¸åªæ¼æåçåºæ¼ LLM çåºæºï¼æåå±ç¤ºäº GraphiT ä¸­çæä½³åæ­¥é©å¦ä½å°è´é¡¯èæ´å¥½ççµæï¼èç¡éæåèª¿æ´æç¤ºãæåéè­æäºæåçåè¡¨ç·¨ç¢¼æ¹æ³èå¶ä»åè¡¨ç·¨ç¢¼æ¹æ³å·æç«¶ç­åï¼åæææ¬æ´ä½ï¼å çºå®å¨ç¸åçä»»åä¸­ä½¿ç¨äºé¡¯èæ´å°çæ¨è¨ã</paragraph>

##### **Do Large Language Models Reason Causally Like Us? Even Better?**
2502.10215v1 by Hanna M. Dettki, Brenden M. Lake, Charley M. Wu, Bob Rehder

Causal reasoning is a core component of intelligence. Large language models
(LLMs) have shown impressive capabilities in generating human-like text,
raising questions about whether their responses reflect true understanding or
statistical patterns. We compared causal reasoning in humans and four LLMs
using tasks based on collider graphs, rating the likelihood of a query variable
occurring given evidence from other variables. We find that LLMs reason
causally along a spectrum from human-like to normative inference, with
alignment shifting based on model, context, and task. Overall, GPT-4o and
Claude showed the most normative behavior, including "explaining away", whereas
Gemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected
independence of causes - Claude the least - they exhibited strong associative
reasoning and predictive inference when assessing the likelihood of the effect
given its causes. These findings underscore the need to assess AI biases as
they increasingly assist human decision-making.

æè¦ï¼å ææ¨çæ¯æºè½çæ ¸å¿çµæé¨åãå¤§åèªè¨æ¨¡å (LLM) å¨çæé¡äººææ¬æ¹é¢å±ç¾äºä»¤äººå°è±¡æ·±å»çè½åï¼å¼ç¼äºéæ¼å®åçåææ¯å¦åæ çå¯¦çè§£æçµ±è¨æ¨¡å¼ççåãæåä½¿ç¨åºæ¼ç¢°æåçä»»åæ¯è¼äºäººé¡ååå LLM ä¸­çå ææ¨çï¼æ ¹æå¶ä»è®æ¸çè­æè©ä¼°æ¥è©¢è®æ¸ç¼ççå¯è½æ§ãæåç¼ç¾ LLM æ²¿èå¾é¡äººå°è¦ç¯æ¨è«çåè­é²è¡å ææ¨çï¼å°é½ææ ¹ææ¨¡åãä¸ä¸æåä»»åèæ¹è®ãç¸½é«èè¨ï¼GPT-4o å Claude è¡¨ç¾åºæè¦ç¯çè¡çºï¼åæ¬ãè§£éãï¼è Gemini-Pro å GPT-3.5 åæ²æãåç®¡ææä»£çé½åé¢äºé æçåå ç¨ç«æ§ - Claude æä¸åé¢ - ä½å®åå¨è©ä¼°çµ¦å®åå çææå¯è½æ§æè¡¨ç¾åºå¼·ççéè¯æ¨çåé æ¸¬æ¨è«ãéäºç¼ç¾å¼·èª¿äºè©ä¼° AI åå·®çå¿è¦æ§ï¼å çºå®åè¶ä¾è¶åå©äººé¡æ±ºç­ã

##### **Small Models, Big Impact: Efficient Corpus and Graph-Based Adaptation of Small Multilingual Language Models for Low-Resource Languages**
2502.10140v1 by Daniil Gurgurov, Ivan Vykopal, Josef van Genabith, Simon Ostermann

Low-resource languages (LRLs) face significant challenges in natural language
processing (NLP) due to limited data. While current state-of-the-art large
language models (LLMs) still struggle with LRLs, smaller multilingual models
(mLMs) such as mBERT and XLM-R offer greater promise due to a better fit of
their capacity to low training data sizes. This study systematically
investigates parameter-efficient adapter-based methods for adapting mLMs to
LRLs, evaluating three architectures: Sequential Bottleneck, Invertible
Bottleneck, and Low-Rank Adaptation. Using unstructured text from GlotCC and
structured knowledge from ConceptNet, we show that small adaptation datasets
(e.g., up to 1 GB of free-text or a few MB of knowledge graph data) yield gains
in intrinsic (masked language modeling) and extrinsic tasks (topic
classification, sentiment analysis, and named entity recognition). We find that
Sequential Bottleneck adapters excel in language modeling, while Invertible
Bottleneck adapters slightly outperform other methods on downstream tasks due
to better embedding alignment and larger parameter counts. Adapter-based
methods match or outperform full fine-tuning while using far fewer parameters,
and smaller mLMs prove more effective for LRLs than massive LLMs like LLaMA-3,
GPT-4, and DeepSeek-R1-based distilled models. While adaptation improves
performance, pre-training data size remains the dominant factor, especially for
languages with extensive pre-training coverage.

æè¦ï¼ä½è³æºèªè¨ (LRL) ç±æ¼è³ææéï¼å¨èªç¶èªè¨èç (NLP) ä¸­é¢è¨éå¤§ææ°ãéç¶ç¶åæåé²çå¤§åèªè¨æ¨¡å (LLM) ä»é£ä»¥èç LRLï¼ä½è¼å°çå¤èªè¨æ¨¡å (mLMS)ï¼ä¾å¦ mBERT å XLM-Rï¼ç±æ¼å¶å®¹éæ´é©åä½è¨ç·´è³æå¤§å°ï¼å æ­¤æä¾äºæ´å¤§çå¸æãæ¬ç ç©¶ç³»çµ±æ§å°æ¢è¨äºåºæ¼åæ¸æçé©éå¨çé©éæ¹æ³ï¼ä»¥å° mLMS é©éå° LRLï¼è©ä¼°äºä¸ç¨®æ¶æ§ï¼é åºç¶é ¸ãå¯éç¶é ¸åä½ç§©é©éãä½¿ç¨ä¾èª GlotCC çéçµæ§åææ¬åä¾èª ConceptNet ççµæ§åç¥è­ï¼æåè¡¨æå°åé©éè³æéï¼ä¾å¦ï¼é«é 1 GB çèªç±ææ¬æå¹¾ MB çç¥è­åè­è³æï¼å¨å§å¨ï¼é®è½èªè¨æ¨¡åï¼åå¤å¨ä»»åï¼ä¸»é¡åé¡ãæç·åæåå½åå¯¦é«è­å¥ï¼ä¸­ç¢çå¢çãæåç¼ç¾é åºç¶é ¸é©éå¨å¨èªè¨æ¨¡åä¸­è¡¨ç¾åºè²ï¼èå¯éç¶é ¸é©éå¨ç±æ¼æ´å¥½çåµå¥å°é½åæ´å¤§çåæ¸æ¸éï¼å¨ä¸æ¸¸ä»»åä¸ç¥åæ¼å¶ä»æ¹æ³ãåºæ¼é©éå¨çæ¹æ³å¨ä½¿ç¨æ´å°åæ¸çåæï¼å¯ä»¥å¹éæåªæ¼å®å¨å¾®èª¿ï¼èè¼å°ç mLM è¢«è­ææ¯ LLaMA-3ãGPT-4 ååºæ¼ DeepSeek-R1 çè¸é¤¾æ¨¡åç­å¤§å LLM æ´é©å LRLãéç¶é©éå¯ä»¥æé«æè½ï¼ä½é è¨ç·´è³æå¤§å°ä»ç¶æ¯ä¸»è¦å ç´ ï¼ç¹å¥æ¯å°æ¼é è¨ç·´è¦èç¯åå»£æ³çèªè¨ã

##### **Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models**
2502.10090v1 by Chenrui Tie, Shengxiang Sun, Jinxuan Zhu, Yiwei Liu, Jingxiang Guo, Yue Hu, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao

Humans possess an extraordinary ability to understand and execute complex
manipulation tasks by interpreting abstract instruction manuals. For robots,
however, this capability remains a substantial challenge, as they cannot
interpret abstract instructions and translate them into executable actions. In
this paper, we present Manual2Skill, a novel framework that enables robots to
perform complex assembly tasks guided by high-level manual instructions. Our
approach leverages a Vision-Language Model (VLM) to extract structured
information from instructional images and then uses this information to
construct hierarchical assembly graphs. These graphs represent parts,
subassemblies, and the relationships between them. To facilitate task
execution, a pose estimation model predicts the relative 6D poses of components
at each assembly step. At the same time, a motion planning module generates
actionable sequences for real-world robotic implementation. We demonstrate the
effectiveness of Manual2Skill by successfully assembling several real-world
IKEA furniture items. This application highlights its ability to manage
long-horizon manipulation tasks with both efficiency and precision,
significantly enhancing the practicality of robot learning from instruction
manuals. This work marks a step forward in advancing robotic systems capable of
understanding and executing complex manipulation tasks in a manner akin to
human capabilities.

æè¦ï¼äººé¡ææçè§£ä¸¦å·è¡è¤éæä½ä»»åçéå¡è½åï¼æ¹æ³æ¯è©®éæ½è±¡çèªªææåãç¶èï¼å°æ©å¨äººä¾èªªï¼éé è½åä»ç¶æ¯ä¸é éå¤§çææ°ï¼å çºå®åç¡æ³è©®éæ½è±¡çæä»¤ä¸¦å°å¶è½æçºå¯å·è¡çåä½ãå¨æ¬æä¸­ï¼æåæåºäº Manual2Skillï¼éæ¯ä¸åæ°ç©çæ¡æ¶ï¼ä½¿æ©å¨äººè½å¤ å¨é«éæåèªªæçæå°ä¸å·è¡è¤éççµè£ä»»åãæåçåæ³å©ç¨è¦è¦ºèªè¨æ¨¡å (VLM) å¾æå­¸åçä¸­æåçµæ§åè³è¨ï¼ç¶å¾ä½¿ç¨æ­¤è³è¨ä¾å»ºæ§éå±¤å¼çµè£åãéäºåè¡¨ç¤ºé¶ä»¶ãå­çµä»¶ä»¥åå®åä¹éçéä¿ãçºäºä¿é²ä»»åå·è¡ï¼å§¿å¢ä¼°è¨æ¨¡åæé æ¸¬æ¯åçµè£æ­¥é©ä¸­çµä»¶çç¸å° 6D å§¿å¢ãåæï¼åä½è¦åæ¨¡çµæç¢çé©ç¨æ¼å¯¦éæ©å¨äººå¯¦ä½çå¯æä½é åºãæåééæåçµè£å¹¾åçå¯¦ä¸çç IKEA å®¶å·ä¾å±ç¤º Manual2Skill çæææ§ãæ­¤æç¨ç¨å¼çªé¡¯äºå®ä»¥é«æçåé«ç²¾æºåº¦ç®¡çé·æç¨æä½ä»»åçè½åï¼å¤§å¹æåæ©å¨äººå¾èªªææåä¸­å­¸ç¿çå¯¦ç¨æ§ãéé å·¥ä½æ¨èªèæ©å¨äººç³»çµ±å¨çè§£åå·è¡è¤éæä½ä»»åæ¹é¢ååéé²äºä¸æ­¥ï¼å¶æ¹å¼é¡ä¼¼æ¼äººé¡çè½åã

##### **Decision Information Meets Large Language Models: The Future of Explainable Operations Research**
2502.09994v1 by Yansen Zhang, Qingcan Kang, Wing Yin Yu, Hailei Gong, Xiaojin Fu, Xiongwei Han, Tao Zhong, Chen Ma

Operations Research (OR) is vital for decision-making in many industries.
While recent OR methods have seen significant improvements in automation and
efficiency through integrating Large Language Models (LLMs), they still
struggle to produce meaningful explanations. This lack of clarity raises
concerns about transparency and trustworthiness in OR applications. To address
these challenges, we propose a comprehensive framework, Explainable Operations
Research (EOR), emphasizing actionable and understandable explanations
accompanying optimization. The core of EOR is the concept of Decision
Information, which emerges from what-if analysis and focuses on evaluating the
impact of complex constraints (or parameters) changes on decision-making.
Specifically, we utilize bipartite graphs to quantify the changes in the OR
model and adopt LLMs to improve the explanation capabilities. Additionally, we
introduce the first industrial benchmark to rigorously evaluate the
effectiveness of explanations and analyses in OR, establishing a new standard
for transparency and clarity in the field.

æè¦ï¼ä½æ¥­ç ç©¶ (OR) å°è¨±å¤ç¢æ¥­çæ±ºç­å¶å®è³ééè¦ãéç¶è¿æç OR æ¹æ³å·²ééæ´åå¤§åèªè¨æ¨¡å (LLM) å¨èªåååæçæ¹é¢åå¾é¡¯èçé²æ­¥ï¼ä½å®åå¨ç¢çææç¾©çè§£éæ¹é¢ä»é¢è¨ææ°ãéç¨®ç¼ºä¹æç¢ºæ§çææ³æå° OR æç¨ä¸­çéæåº¦åå¯ä¿¡åº¦é æçæ®ãçºäºæå°éäºææ°ï¼æåæåºä¸åå¨é¢çæ¶æ§ï¼å³å¯è§£éä½æ¥­ç ç©¶ (EOR)ï¼å¼·èª¿å¨æä½³åéç¨ä¸­æä¾å¯æä½ä¸ææ¼çè§£çè§£éãEOR çæ ¸å¿æ¯æ±ºç­è³è¨çæ¦å¿µï¼å®æºèªåè¨­åæï¼ä¸¦å°æ³¨æ¼è©ä¼°è¤éç´ææ¢ä»¶ (æåæ¸) è®æ´å°æ±ºç­å¶å®çå½±é¿ãå·é«ä¾èªªï¼æåå©ç¨äºé¨åéå OR æ¨¡åçè®åï¼ä¸¦æ¡ç¨ LLM ä¾æ¹åè§£éè½åãæ­¤å¤ï¼æåå¼å¥äºç¬¬ä¸åç¢æ¥­åºæºï¼ä»¥å´æ ¼è©ä¼° OR ä¸­è§£éååæçæææ§ï¼çºè©²é åçéæåº¦åæ¸æ°åº¦å»ºç«æ°çæ¨æºã

##### **KGGen: Extracting Knowledge Graphs from Plain Text with Language Models**
2502.09956v1 by Belinda Mo, Kyssen Yu, Joshua Kazdan, Proud Mpala, Lisa Yu, Chris Cundy, Charilaos Kanatsoulis, Sanmi Koyejo

Recent interest in building foundation models for KGs has highlighted a
fundamental challenge: knowledge-graph data is relatively scarce. The
best-known KGs are primarily human-labeled, created by pattern-matching, or
extracted using early NLP techniques. While human-generated KGs are in short
supply, automatically extracted KGs are of questionable quality. We present a
solution to this data scarcity problem in the form of a text-to-KG generator
(KGGen), a package that uses language models to create high-quality graphs from
plaintext. Unlike other KG extractors, KGGen clusters related entities to
reduce sparsity in extracted KGs. KGGen is available as a Python library
(\texttt{pip install kg-gen}), making it accessible to everyone. Along with
KGGen, we release the first benchmark, Measure of of Information in Nodes and
Edges (MINE), that tests an extractor's ability to produce a useful KG from
plain text. We benchmark our new tool against existing extractors and
demonstrate far superior performance.

æè¦ï¼æè¿å¯¹äºæå»ºç¥è¯å¾è°±åºç¡æ¨¡åçå´è¶£å¸æ¾äºä¸ä¸ªåºæ¬ææï¼ç¥è¯å¾è°±æ°æ®ç¸å¯¹ç¨ç¼ºãæç¥åçç¥è¯å¾è°±ä¸»è¦ä¸ºäººæ æ³¨ï¼ç±æ¨¡å¼å¹éåå»ºï¼æä½¿ç¨æ©æèªç¶è¯­è¨å¤çææ¯æåãè½ç¶äººçæçç¥è¯å¾è°±ä¾ä¸åºæ±ï¼ä½èªå¨æåçç¥è¯å¾è°±è´¨éå ªå¿§ãæä»¬ä»¥ææ¬å°ç¥è¯å¾è°±çæå¨ (KGGen) çå½¢å¼ä¸ºè¿ä¸æ°æ®ç¨ç¼ºé®é¢æä¾äºä¸ä¸ªè§£å³æ¹æ¡ï¼è¿æ¯ä¸ä¸ªä½¿ç¨è¯­è¨æ¨¡åä»çº¯ææ¬åå»ºé«è´¨éå¾è¡¨çåãä¸å¶ä»ç¥è¯å¾è°±æåå¨ä¸åï¼KGGen å¯¹ç¸å³å®ä½è¿è¡èç±»ä»¥åå°æåçç¥è¯å¾è°±ä¸­çç¨çæ§ãKGGen å¯ç¨ä½ Python åºï¼\texttt{pip install kg-gen}ï¼ï¼ä½¿å¶ææäººé½è½è®¿é®ãé¤äº KGGenï¼æä»¬è¿åå¸äºç¬¬ä¸ä¸ªåºåæµè¯ï¼å³èç¹åè¾¹ä¿¡æ¯åº¦é (MINE)ï¼å®æµè¯äºæåå¨ä»çº¯ææ¬çææç¨ç¥è¯å¾è°±çè½åãæä»¬éå¯¹ç°ææåå¨å¯¹æä»¬çæ°å·¥å·è¿è¡åºåæµè¯ï¼å¹¶å±ç¤ºäºè¿è¶å¶æ§è½ã

##### **ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation**
2502.09891v1 by Shu Wang, Yixiang Fang, Yingli Zhou, Xilin Liu, Yuchi Ma

Retrieval-Augmented Generation (RAG) has proven effective in integrating
external knowledge into large language models (LLMs) for question-answer (QA)
tasks. The state-of-the-art RAG approaches often use the graph data as the
external data since they capture the rich semantic information and link
relationships between entities. However, existing graph-based RAG approaches
cannot accurately identify the relevant information from the graph and also
consume large numbers of tokens in the online retrieval process. To address
these issues, we introduce a novel graph-based RAG approach, called Attributed
Community-based Hierarchical RAG (ArchRAG), by augmenting the question using
attributed communities, and also introducing a novel LLM-based hierarchical
clustering method. To retrieve the most relevant information from the graph for
the question, we build a novel hierarchical index structure for the attributed
communities and develop an effective online retrieval method. Experimental
results demonstrate that ArchRAG outperforms existing methods in terms of both
accuracy and token cost.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²è­æå¯å°å¤é¨ç¥è­æ´åå°å¤§åèªè¨æ¨¡å (LLM)ï¼ç¨æ¼åç­ (QA) ä»»åãæåé²ç RAG æ¹æ³éå¸¸ä½¿ç¨åå½¢è³æä½çºå¤é¨è³æï¼å çºå®åæ·åäºè±å¯çèªæè³è¨åå¯¦é«ä¹éçé£çµéä¿ãç¶èï¼ç¾æçåºæ¼åå½¢ç RAG æ¹æ³ç¡æ³æºç¢ºè­å¥åå½¢ä¸­çç¸éè³è¨ï¼èä¸å¨ç·ä¸æª¢ç´¢éç¨ä¸­ä¹ææ¶èå¤§éçç¬¦èãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼åå½¢ç RAG æ¹æ³ï¼ç¨±çºåºæ¼å±¬æ§ç¤¾ç¾¤çåå±¤ RAG (ArchRAG)ï¼ééä½¿ç¨å±¬æ§ç¤¾ç¾¤ä¾æ´ååé¡ï¼ä¸¦å¼å¥ä¸ç¨®æ°ç©çåºæ¼ LLM çåå±¤èé¡æ¹æ³ãçºäºå¾åå½¢ä¸­æª¢ç´¢èåé¡æç¸éçè³è¨ï¼æåçºå±¬æ§ç¤¾ç¾¤å»ºç«äºä¸åæ°ç©çåå±¤ç´¢å¼çµæ§ï¼ä¸¦éç¼äºä¸ç¨®ææçç·ä¸æª¢ç´¢æ¹æ³ãå¯¦é©çµæè­æï¼ArchRAG å¨æºç¢ºæ§åç¬¦èææ¬æ¹é¢é½åªæ¼ç¾ææ¹æ³ã

##### **Visual Graph Question Answering with ASP and LLMs for Language Parsing**
2502.09211v1 by Jakob Johannes Bauer, Thomas Eiter, Nelson Higuera Ruiz, Johannes Oetsch

Visual Question Answering (VQA) is a challenging problem that requires to
process multimodal input. Answer-Set Programming (ASP) has shown great
potential in this regard to add interpretability and explainability to modular
VQA architectures. In this work, we address the problem of how to integrate ASP
with modules for vision and natural language processing to solve a new and
demanding VQA variant that is concerned with images of graphs (not graphs in
symbolic form). Images containing graph-based structures are an ubiquitous and
popular form of visualisation. Here, we deal with the particular problem of
graphs inspired by transit networks, and we introduce a novel dataset that
amends an existing one by adding images of graphs that resemble metro lines.
Our modular neuro-symbolic approach combines optical graph recognition for
graph parsing, a pretrained optical character recognition neural network for
parsing labels, Large Language Models (LLMs) for language processing, and ASP
for reasoning. This method serves as a first baseline and achieves an overall
average accuracy of 73% on the dataset. Our evaluation provides further
evidence of the potential of modular neuro-symbolic systems, in particular with
pretrained models that do not involve any further training and logic
programming for reasoning, to solve complex VQA tasks.

æè¦ï¼è¦è¦ºåç­ï¼VQAï¼æ¯ä¸é å·æææ°æ§çåé¡ï¼éè¦èçå¤æ¨¡æè¼¸å¥ãç­æ¡éç¨å¼è¨­è¨ï¼ASPï¼å¨éæ¹é¢é¡¯ç¤ºåºå·¨å¤§çæ½åï¼å¯ä»¥çºæ¨¡çµå VQA æ¶æ§å¢å å¯è§£éæ§åèªªææ§ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å¦ä½å° ASP èè¦è¦ºåèªç¶èªè¨èçæ¨¡çµæ´åï¼ä»¥è§£æ±ºä¸åæ°çä¸è¦æ±å´æ ¼ç VQA è®é«ï¼è©²è®é«èåå½¢å½±åï¼èéç¬¦èå½¢å¼çåå½¢ï¼æéãåå«åå½¢çµæ§çå½±åæ¯ä¸ç¨®æ®éä¸æµè¡çå¯è¦åå½¢å¼ãå¨éè£¡ï¼æåèçåäº¤éç¶²è·¯åç¼çåå½¢ç¹å®åé¡ï¼ä¸¦å¼å¥ä¸åæ°çè³æéï¼ééæ°å¢é¡ä¼¼å°éµè·¯ç·çåå½¢å½±åä¾ä¿®æ­£ç¾æè³æéãæåçæ¨¡çµåç¥ç¶ç¬¦èæ¹æ³çµååå­¸åå½¢è¾¨è­é²è¡åå½¢è§£æãé åè¨ç·´çåå­¸å­åè¾¨è­ç¥ç¶ç¶²è·¯é²è¡æ¨ç±¤è§£æãå¤§åèªè¨æ¨¡åï¼LLMï¼é²è¡èªè¨èçï¼ä»¥å ASP é²è¡æ¨çãæ­¤æ¹æ³ä½çºç¬¬ä¸ååºæºï¼å¨è³æéä¸éå° 73% çæ´é«å¹³åæºç¢ºåº¦ãæåçè©ä¼°é²ä¸æ­¥è­æäºæ¨¡çµåç¥ç¶ç¬¦èç³»çµ±çæ½åï¼ç¹å¥æ¯é åè¨ç·´çæ¨¡åï¼éäºæ¨¡åä¸æ¶åä»»ä½é²ä¸æ­¥çè¨ç·´åéè¼¯ç¨å¼è¨­è¨é²è¡æ¨çï¼ä»¥è§£æ±ºè¤éç VQA ä»»åã

##### **Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data**
2502.08547v1 by Doudou Zhou, Han Tong, Linshanshan Wang, Suqi Liu, Xin Xiong, Ziming Gan, Romain Griffier, Boris Hejblum, Yun-Chung Liu, Chuan Hong, Clara-Lea Bonzel, Tianrun Cai, Kevin Pan, Yuk-Lam Ho, Lauren Costa, Vidul A. Panickan, J. Michael Gaziano, Kenneth Mandl, Vianney Jouhet, Rodolphe Thiebaut, Zongqi Xia, Kelly Cho, Katherine Liao, Tianxi Cai

The adoption of EHRs has expanded opportunities to leverage data-driven
algorithms in clinical care and research. A major bottleneck in effectively
conducting multi-institutional EHR studies is the data heterogeneity across
systems with numerous codes that either do not exist or represent different
clinical concepts across institutions. The need for data privacy further limits
the feasibility of including multi-institutional patient-level data required to
study similarities and differences across patient subgroups. To address these
challenges, we developed the GAME algorithm. Tested and validated across 7
institutions and 2 languages, GAME integrates data in several levels: (1) at
the institutional level with knowledge graphs to establish relationships
between codes and existing knowledge sources, providing the medical context for
standard codes and their relationship to each other; (2) between institutions,
leveraging language models to determine the relationships between
institution-specific codes with established standard codes; and (3) quantifying
the strength of the relationships between codes using a graph attention
network. Jointly trained embeddings are created using transfer and federated
learning to preserve data privacy. In this study, we demonstrate the
applicability of GAME in selecting relevant features as inputs for AI-driven
algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.
We then highlight the application of GAME harmonized multi-institutional EHR
data in a study of Alzheimer's disease outcomes and suicide risk among patients
with mental health disorders, without sharing patient-level data outside
individual institutions.

æè¦ï¼é»å­å¥åº·ç´éçæ¡ç¨æ´å¤§äºå¨è¨åºç§è­·åç ç©¶ä¸­å©ç¨è³æé©åæ¼ç®æ³çæ©æãå¨ææé²è¡å¤æ©æ§é»å­å¥åº·ç´éç ç©¶æï¼ä¸åä¸»è¦çç¶é ¸æ¯ç³»çµ±éè³æç°è³ªæ§ï¼å¶ä¸­æè¨±å¤ä»£ç¢¼å¨æ©æ§éä¸å­å¨æè¡¨ç¤ºä¸åçè¨åºæ¦å¿µãè³æé±ç§çéæ±é²ä¸æ­¥éå¶äºç´å¥å¤æ©æ§æ£èå±¤ç´è³æçå¯è¡æ§ï¼èéäºè³æå°æ¼ç ç©¶æ£èäºç¾¤ä¹éçç¸ä¼¼æ§åå·®ç°æ§æ¯å¿è¦çãçºäºæå°éäºææ°ï¼æåéç¼äº GAME æ¼ç®æ³ãGAME å·²å¨ 7 åæ©æ§å 2 ç¨®èªè¨ä¸­é²è¡æ¸¬è©¦åé©è­ï¼å®æ´åäºå¤åå±¤ç´çè³æï¼(1) å¨æ©æ§å±¤ç´ï¼ä½¿ç¨ç¥è­åè¡¨ä¾å»ºç«ä»£ç¢¼åç¾æç¥è­ä¾æºä¹éçéä¿ï¼çºæ¨æºä»£ç¢¼åå¶å½¼æ­¤ä¹éçéä¿æä¾é«çèæ¯ï¼(2) å¨æ©æ§ä¹éï¼å©ç¨èªè¨æ¨¡åä¾ç¢ºå®æ©æ§ç¹å®ä»£ç¢¼èå·²å»ºç«çæ¨æºä»£ç¢¼ä¹éçéä¿ï¼(3) ä½¿ç¨åå½¢æ³¨æç¶²è·¯éåä»£ç¢¼ä¹ééä¿çå¼·åº¦ãä½¿ç¨é·ç§»åè¯åå­¸ç¿å»ºç«è¯åè¨ç·´çåµå¥ï¼ä»¥ä¿è­·è³æé±ç§ãå¨æ¬ç ç©¶ä¸­ï¼æåå±ç¤ºäº GAME å¨é¸æç¸éç¹å¾µä½çº AI é©åæ¼ç®æ³è¼¸å¥æçé©ç¨æ§ï¼é©ç¨æ¼åç¨®ææ³ï¼ä¾å¦å¿èè¡°ç«­ãé¡é¢¨æ¿æ§éç¯çãç¶å¾ï¼æåéé»ä»ç´¹äº GAME åè«§åå¤æ©æ§é»å­å¥åº·ç´éè³æå¨é¿è²æµ·é»çç¾ççµæåç²¾ç¥ç¾çæ£èèªæ®ºé¢¨éªç ç©¶ä¸­çæç¨ï¼èç¡éå¨åå¥æ©æ§ä¹å¤å±äº«æ£èå±¤ç´è³æã

##### **Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy**
2502.08353v1 by Ruizhan Xue, Huimin Deng, Fang He, Maojun Wang, Zeyu Zhang

With the extensive application of Graph Neural Networks (GNNs) across various
domains, their trustworthiness has emerged as a focal point of research. Some
existing studies have shown that the integration of large language models
(LLMs) can improve the semantic understanding and generation capabilities of
GNNs, which in turn improves the trustworthiness of GNNs from various aspects.
Our review introduces a taxonomy that offers researchers a clear framework for
comprehending the principles and applications of different methods and helps
clarify the connections and differences among various approaches. Then we
systematically survey representative approaches along the four categories of
our taxonomy. Through our taxonomy, researchers can understand the applicable
scenarios, potential advantages, and limitations of each approach for the the
trusted integration of GNNs with LLMs. Finally, we present some promising
directions of work and future trends for the integration of LLMs and GNNs to
improve model trustworthiness.

æè¦ï¼é¨èåç¥ç¶ç¶²è·¯ (GNN) å¨åç¨®é åçå»£æ³æç¨ï¼å¶å¯ä¿¡åº¦å·²æçºç ç©¶çç¦é»ãä¸äºç¾æç ç©¶è¡¨æï¼æ´åå¤§åèªè¨æ¨¡å (LLM) å¯ä»¥æå GNN çèªæçè§£åçæè½åï¼é²èå¾åæ¹é¢æå GNN çå¯ä¿¡åº¦ãæåçè©è«ä»ç´¹äºä¸ç¨®åé¡æ³ï¼çºç ç©¶äººå¡æä¾äºä¸åæ¸æ°çæ¶æ§ï¼ç¨æ¼çè§£ä¸åæ¹æ³çåçåæç¨ï¼ä¸¦æå©æ¼éæ¸åç¨®æ¹æ³ä¹éçéè¯åå·®ç°ãç¶å¾ï¼æåç³»çµ±æ§å°éå°åé¡æ³çååé¡å¥é²è¡ä»£è¡¨æ§æ¹æ³çèª¿æ¥ãç ç©¶äººå¡ééæåçåé¡æ³ï¼å¯ä»¥äºè§£æ¯ç¨®æ¹æ³å¨ GNN è LLM çå¯ä¿¡æ´åä¸­é©ç¨çå ´æ¯ãæ½å¨åªé»åéå¶ãæå¾ï¼æåæåº LLM è GNN æ´åçä¸äºæåæ¯çå·¥ä½æ¹ååæªä¾è¶¨å¢ï¼ä»¥æåæ¨¡åçå¯ä¿¡åº¦ã

##### **Graph Foundation Models for Recommendation: A Comprehensive Survey**
2502.08346v3 by Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi

Recommender systems (RS) serve as a fundamental tool for navigating the vast
expanse of online information, with deep learning advancements playing an
increasingly important role in improving ranking accuracy. Among these, graph
neural networks (GNNs) excel at extracting higher-order structural information,
while large language models (LLMs) are designed to process and comprehend
natural language, making both approaches highly effective and widely adopted.
Recent research has focused on graph foundation models (GFMs), which integrate
the strengths of GNNs and LLMs to model complex RS problems more efficiently by
leveraging the graph-based structure of user-item relationships alongside
textual understanding. In this survey, we provide a comprehensive overview of
GFM-based RS technologies by introducing a clear taxonomy of current
approaches, diving into methodological details, and highlighting key challenges
and future directions. By synthesizing recent advancements, we aim to offer
valuable insights into the evolving landscape of GFM-based recommender systems.

æè¦ï¼æ¨è¦ç³»çµ± (RS) æ¯ç¨æ¼å°èªå»£éçç·ä¸è³è¨çåºæ¬å·¥å·ï¼æ·±åº¦å­¸ç¿çé²æ­¥å¨æåæåæºç¢ºåº¦æ¹é¢æ®æ¼èæ¥çéè¦çè§è²ãå¶ä¸­ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æé·èåé«éçµæ§è³è¨ï¼èå¤§åèªè¨æ¨¡å (LLM) åè¨­è¨ç¨æ¼èçåçè§£èªç¶èªè¨ï¼éä½¿å¾éå©ç¨®æ¹æ³é½éå¸¸ææä¸å»£æ³æ¡ç¨ãæè¿çç ç©¶å°æ³¨æ¼åå½¢åºç¤æ¨¡å (GFM)ï¼å®æ´åäº GNN å LLM çåªé»ï¼ééå©ç¨ä½¿ç¨èèé ç®éä¿çåå½¢åçµæ§ä»¥åæå­çè§£ï¼æ´ææçå°å»ºæ§è¤éç RS åé¡æ¨¡åãå¨éé èª¿æ¥ä¸­ï¼æåééä»ç´¹ç¶åæ¹æ³çæç¢ºåé¡ãæ·±å¥æ¢è¨æ¹æ³è«ç´°ç¯ï¼ä»¥åå¼·èª¿ééµææ°åæªä¾æ¹åï¼æä¾äº GFM çºåºç¤ç RS æè¡çå¨é¢æ¦è§ãééç¶åæè¿çé²å±ï¼æåæ¨å¨æä¾å° GFM çºåºç¤çæ¨è¦ç³»çµ±ä¸æ·æ¼è®ççåçå¯¶è²´è¦è§£ã

##### **Self-Evaluation for Job-Shop Scheduling**
2502.08684v1 by Imanol Echeverria, Maialen Murua, Roberto Santana

Combinatorial optimization problems, such as scheduling and route planning,
are crucial in various industries but are computationally intractable due to
their NP-hard nature. Neural Combinatorial Optimization methods leverage
machine learning to address these challenges but often depend on sequential
decision-making, which is prone to error accumulation as small mistakes
propagate throughout the process. Inspired by self-evaluation techniques in
Large Language Models, we propose a novel framework that generates and
evaluates subsets of assignments, moving beyond traditional stepwise
approaches. Applied to the Job-Shop Scheduling Problem, our method integrates a
heterogeneous graph neural network with a Transformer to build a policy model
and a self-evaluation function. Experimental validation on challenging,
well-known benchmarks demonstrates the effectiveness of our approach,
surpassing state-of-the-art methods.

æè¦ï¼çµååªååé¡ï¼ä¾å¦æç¨åè·¯ç·è¦åï¼å¨åè¡åæ¥­ä¸­è³ééè¦ï¼ä½ç±æ¼å®åç NP é£åº¦ï¼å¨è¨ç®ä¸é£ä»¥èçãç¥ç¶çµååªåæ¹æ³å©ç¨æ©å¨å­¸ç¿ä¾è§£æ±ºéäºææ°ï¼ä½éå¸¸ä¾è³´æ¼åºè²«æ±ºç­å¶å®ï¼èåºè²«æ±ºç­å¶å®å®¹æç¼çé¯èª¤ç´¯ç©ï¼å çºå°é¯èª¤æå¨æ´åéç¨ä¸­å³æ­ãåå¤§åèªè¨æ¨¡åä¸­çèªæè©ä¼°æè¡åç¼ï¼æåæåºäºä¸åæ°çæ¡æ¶ï¼å¯çæåè©ä¼°ä½æ¥­å­éï¼è¶è¶å³çµ±çåæ­¥æ¹æ³ãæç¨æ¼å·¥ä½è»éæç¨åé¡ï¼æåçæ¹æ³å°ç°è³ªåç¥ç¶ç¶²è·¯è Transformer æ´åå¨ä¸èµ·ï¼ä»¥å»ºç«ç­ç¥æ¨¡ååèªæè©ä¼°å½æ¸ãå¨å·æææ°æ§çèååºæºä¸çå¯¦é©é©è­è­æäºæåæ¹æ³çæææ§ï¼è¶è¶äºæåé²çæ¹æ³ã

##### **Improving Existing Optimization Algorithms with LLMs**
2502.08298v1 by Camilo ChacÃ³n Sartori, Christian Blum

The integration of Large Language Models (LLMs) into optimization has created
a powerful synergy, opening exciting research opportunities. This paper
investigates how LLMs can enhance existing optimization algorithms. Using their
pre-trained knowledge, we demonstrate their ability to propose innovative
heuristic variations and implementation strategies. To evaluate this, we
applied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt
(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that
incorporates a heuristic in the solution construction phase. Our results show
that an alternative heuristic proposed by GPT-4o outperforms the
expert-designed heuristic of CMSA, with the performance gap widening on larger
and denser graphs. Project URL: https://imp-opt-algo-llms.surge.sh/

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) ä¸ä¼åç¸ç»åï¼åé äºä¸ç§å¼ºå¤§çååä½ç¨ï¼å¼å¯äºä»¤äººå´å¥çç ç©¶æºä¼ãæ¬ææ¢è®¨äº LLM å¦ä½å¢å¼ºç°æçä¼åç®æ³ãå©ç¨å¶é¢åè®­ç»çç¥è¯ï¼æä»¬å±ç¤ºäºå®ä»¬æåºåæ°å¯åå¼åä½åå®æ½ç­ç¥çè½åãä¸ºäºè¯ä¼°è¿ä¸ç¹ï¼æä»¬åºç¨äºä¸ç§éå¹³å¡çä¼åç®æ³ï¼æå»ºãåå¹¶ãæ±è§£åéåº (CMSA)ââä¸ç§ç¨äºç»åä¼åé®é¢çæ··ååå¯åå¼ç®æ³ï¼å®å¨æ±è§£æå»ºé¶æ®µçº³å¥äºå¯åå¼ç®æ³ãæä»¬çç»æè¡¨æï¼GPT-4o æåºçæ¿ä»£å¯åå¼ç®æ³ä¼äº CMSA çä¸å®¶è®¾è®¡çå¯åå¼ç®æ³ï¼å¹¶ä¸éçå¾å½¢åå¾æ´å¤§ãæ´å¯éï¼æ§è½å·®è·ä¹å¨æ©å¤§ãé¡¹ç®ç½åï¼https://imp-opt-algo-llms.surge.sh/

##### **LLM4GNAS: A Large Language Model Based Toolkit for Graph Neural Architecture Search**
2502.10459v1 by Yang Gao, Hong Yang, Yizhi Chen, Junxian Wu, Peng Zhang, Haishuai Wang

Graph Neural Architecture Search (GNAS) facilitates the automatic design of
Graph Neural Networks (GNNs) tailored to specific downstream graph learning
tasks. However, existing GNAS approaches often require manual adaptation to new
graph search spaces, necessitating substantial code optimization and
domain-specific knowledge. To address this challenge, we present LLM4GNAS, a
toolkit for GNAS that leverages the generative capabilities of Large Language
Models (LLMs). LLM4GNAS includes an algorithm library for graph neural
architecture search algorithms based on LLMs, enabling the adaptation of GNAS
methods to new search spaces through the modification of LLM prompts. This
approach reduces the need for manual intervention in algorithm adaptation and
code modification. The LLM4GNAS toolkit is extensible and robust, incorporating
LLM-enhanced graph feature engineering, LLM-enhanced graph neural architecture
search, and LLM-enhanced hyperparameter optimization. Experimental results
indicate that LLM4GNAS outperforms existing GNAS methods on tasks involving
both homogeneous and heterogeneous graphs.

æè¦ï¼åå½¢ç¥ç¶æ¶æ§æå° (GNAS) ä¿é²åå½¢ç¥ç¶ç¶²è·¯ (GNN) çèªåè¨­è¨ï¼ä»¥ç¬¦åç¹å®ä¸æ¸¸åå½¢å­¸ç¿ä»»åãç¶èï¼ç¾æç GNAS æ¹æ³éå¸¸éè¦æåèª¿æ´è³æ°çåå½¢æå°ç©ºéï¼ééè¦å¤§éçç¨å¼ç¢¼æä½³ååé åç¹å®ç¥è­ãçºäºæå°éé ææ°ï¼æåæåº LLM4GNASï¼ä¸åå©ç¨å¤§åèªè¨æ¨¡å (LLM) ççæè½åç GNAS å·¥å·åãLLM4GNAS åå«ä¸ååºæ¼ LLM çåå½¢ç¥ç¶æ¶æ§æå°æ¼ç®æ³å½å¼åº«ï¼è® GNAS æ¹æ³è½å¤ ééä¿®æ¹ LLM æç¤ºä¾é©ææ°çæå°ç©ºéãéç¨®æ¹æ³æ¸å°äºæ¼ç®æ³é©æåç¨å¼ç¢¼ä¿®æ¹ä¸­æåä»å¥çéè¦ãLLM4GNAS å·¥å·åå·æå¯æ´åæ§åç©©å¥æ§ï¼æ´åäº LLM å¢å¼·çåå½¢ç¹å¾µå·¥ç¨ãLLM å¢å¼·çåå½¢ç¥ç¶æ¶æ§æå°å LLM å¢å¼·çè¶åæ¸æä½³åãå¯¦é©çµæè¡¨æï¼LLM4GNAS å¨æ¶ååè³ªåç°è³ªåå½¢çä»»åä¸åªæ¼ç¾æç GNAS æ¹æ³ã

##### **ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning**
2502.08148v1 by Vy Vo, Lizhen Qu, Tao Feng, Yuncheng Hua, Xiaoxi Kang, Songhai Fan, Tim Dwyer, Lay-Ki Soon, Gholamreza Haffari

Identifying cause-and-effect relationships is critical to understanding
real-world dynamics and ultimately causal reasoning. Existing methods for
identifying event causality in NLP, including those based on Large Language
Models (LLMs), exhibit difficulties in out-of-distribution settings due to the
limited scale and heavy reliance on lexical cues within available benchmarks.
Modern benchmarks, inspired by probabilistic causal inference, have attempted
to construct causal graphs of events as a robust representation of causal
knowledge, where \texttt{CRAB} \citep{romanou2023crab} is one such recent
benchmark along this line. In this paper, we introduce \texttt{ACCESS}, a
benchmark designed for discovery and reasoning over abstract causal events.
Unlike existing resources, \texttt{ACCESS} focuses on causality of everyday
life events on the abstraction level. We propose a pipeline for identifying
abstractions for event generalizations from \texttt{GLUCOSE}
\citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit
commonsense causal knowledge, from which we subsequently extract $1,4$K causal
pairs. Our experiments highlight the ongoing challenges of using statistical
methods and/or LLMs for automatic abstraction identification and causal
discovery in NLP. Nonetheless, we demonstrate that the abstract causal
knowledge provided in \texttt{ACCESS} can be leveraged for enhancing QA
reasoning performance in LLMs.

æè¦ï¼<paragraph>æ¾åºå æéä¿å°æ¼çè§£ç¾å¯¦ä¸ççåæåæçµçå ææ¨çè³ééè¦ãç¾æç NLP äºä»¶å æéä¿è­å¥æ¹æ³ï¼åæ¬åºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ¹æ³ï¼ç±æ¼è¦æ¨¡æéä¸éåº¦ä¾è³´æ¼å¯ç¨åºæºä¸­çè©å½ç·ç´¢ï¼å¨åä½å¤ç°å¢ä¸­è¡¨ç¾åºå°é£ãåæ©çå ææ¨è«åç¼çç¾ä»£åºæºå·²åè©¦å»ºæ§äºä»¶çå æåï¼ä½çºå æç¥è­çå¼·å¥è¡¨ç¤ºï¼å¶ä¸­ \texttt{CRAB} \citep{romanou2023crab} æ¯éæ¢è·¯å¾ä¸æè¿çä¸ååºæºãå¨æ¬æä¸­ï¼æåä»ç´¹ \texttt{ACCESS}ï¼ä¸åå°éè¨­è¨ä¾æ¢ç´¢åæ¨çæ½è±¡å æäºä»¶çåºæºãèç¾æè³æºä¸åï¼\texttt{ACCESS} å°æ³¨æ¼æ½è±¡å±¤é¢ä¸æ¥å¸¸çæ´»äºä»¶çå æéä¿ãæåæåºä¸åç®¡éï¼ç¨æ¼å¾ \texttt{GLUCOSE} \citep{mostafazadeh-etal-2020-glucose} æ¾åºäºä»¶æ¦æ¬çæ½è±¡ï¼\texttt{GLUCOSE} æ¯é±å«å¸¸è­å æç¥è­çå¤§è¦æ¨¡è³æéï¼æåé¨å¾å¾ä¸­èååº 1,4K å æå°ãæåçå¯¦é©çªé¡¯åºä½¿ç¨çµ±è¨æ¹æ³å/æ LLM é²è¡ NLP ä¸­çèªåæ½è±¡è­å¥åå æç¼ç¾çæçºææ°ãåç®¡å¦æ­¤ï¼æåè­æäº \texttt{ACCESS} ä¸­æä¾çæ½è±¡å æç¥è­å¯ç¨æ¼å¢å¼· LLM ä¸­çåç­æ¨çæè½ã</paragraph>

##### **Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep Learning to Enhance Question Answering Quality**
2502.09658v1 by Xin Kang, Veronika Shteingardt, Yuhan Wang, Dov Dori

Knowledge representation and reasoning are critical challenges in Artificial
Intelligence (AI), particularly in integrating neural and symbolic approaches
to achieve explainable and transparent AI systems. Traditional knowledge
representation methods often fall short of capturing complex processes and
state changes. We introduce Neuro-Conceptual Artificial Intelligence (NCAI), a
specialization of the neuro-symbolic AI approach that integrates conceptual
modeling using Object-Process Methodology (OPM) ISO 19450:2024 with deep
learning to enhance question-answering (QA) quality. By converting natural
language text into OPM models using in-context learning, NCAI leverages the
expressive power of OPM to represent complex OPM elements-processes, objects,
and states-beyond what traditional triplet-based knowledge graphs can easily
capture. This rich structured knowledge representation improves reasoning
transparency and answer accuracy in an OPM-QA system. We further propose
transparency evaluation metrics to quantitatively measure how faithfully the
predicted reasoning aligns with OPM-based conceptual logic. Our experiments
demonstrate that NCAI outperforms traditional methods, highlighting its
potential for advancing neuro-symbolic AI by providing rich knowledge
representations, measurable transparency, and improved reasoning.

æè¦ï¼ç¥è­è¡¨å¾µèæ¨çæ¯äººå·¥æºæ§ (AI) ä¸­çéå¤§ææ°ï¼ç¹å¥æ¯å¨æ´åç¥ç¶èç¬¦èæ¹æ³ä»¥å¯¦ç¾å¯è§£éä¸éæçäººå·¥æºæ§ç³»çµ±æãå³çµ±çç¥è­è¡¨å¾µæ¹æ³éå¸¸ç¡æ³ææè¤éçæµç¨åçæè®åãæåå¼å¥äºç¥ç¶æ¦å¿µäººå·¥æºæ§ (NCAI)ï¼ä¸ç¨®ç¥ç¶ç¬¦è AI æ¹æ³çå°éåï¼å®å°ä½¿ç¨ç©ä»¶æµç¨æ¹æ³ (OPM) ISO 19450:2024 çæ¦å¿µå»ºæ¨¡èæ·±åº¦å­¸ç¿æ´åå¨ä¸èµ·ï¼ä»¥æååç­ (QA) çåè³ªãééä½¿ç¨æå¢å­¸ç¿å°èªç¶èªè¨æå­è½æçº OPM æ¨¡åï¼NCAI ååå©ç¨ OPM çè¡¨éè½åä¾è¡¨å¾µè¤éç OPM åç´ ï¼æµç¨ãç©ä»¶åçæï¼ï¼è¶è¶å³çµ±çä¸åçµç¥è­åè¡¨å®¹æææçç¯åãéç¨®è±å¯ççµæ§åç¥è­è¡¨å¾µæ¹åäº OPM-QA ç³»çµ±ä¸­çæ¨çéæåº¦åç­æ¡æºç¢ºåº¦ãæåé²ä¸æ­¥æåºäºéæåº¦è©ä¼°ææ¨ï¼ä»¥éåæ¸¬éé æ¸¬æ¨çèåºæ¼ OPM çæ¦å¿µéè¼¯çå»åç¨åº¦ãæåçå¯¦é©è­æï¼NCAI åªæ¼å³çµ±æ¹æ³ï¼çªé¡¯äºå®å¨ééæä¾è±å¯çç¥è­è¡¨å¾µãå¯æ¸¬éçéæåº¦åæ¹åçæ¨çä¾æ¨é²ç¥ç¶ç¬¦è AI çæ½åã

##### **GCoT: Chain-of-Thought Prompt Learning for Graphs**
2502.08092v1 by Xingtong Yu, Chang Zhou, Zhongwei Kuai, Xinming Zhang, Yuan Fang

Chain-of-thought (CoT) prompting has achieved remarkable success in natural
language processing (NLP). However, its vast potential remains largely
unexplored for graphs. This raises an interesting question: How can we design
CoT prompting for graphs to guide graph models to learn step by step? On one
hand, unlike natural languages, graphs are non-linear and characterized by
complex topological structures. On the other hand, many graphs lack textual
data, making it difficult to formulate language-based CoT prompting. In this
work, we propose the first CoT prompt learning framework for text-free graphs,
GCoT. Specifically, we decompose the adaptation process for each downstream
task into a series of inference steps, with each step consisting of
prompt-based inference, ``thought'' generation, and thought-conditioned prompt
learning. While the steps mimic CoT prompting in NLP, the exact mechanism
differs significantly. Specifically, at each step, an input graph, along with a
prompt, is first fed into a pre-trained graph encoder for prompt-based
inference. We then aggregate the hidden layers of the encoder to construct a
``thought'', which captures the working state of each node in the current step.
Conditioned on this thought, we learn a prompt specific to each node based on
the current state. These prompts are fed into the next inference step,
repeating the cycle. To evaluate and analyze the effectiveness of GCoT, we
conduct comprehensive experiments on eight public datasets, which demonstrate
the advantage of our approach.

æè¦ï¼<paragraph>éå¼æè (CoT) æç¤ºå¨èªç¶èªè¨èç (NLP) ä¸­åå¾äºé¡¯èçæåãç¶èï¼å¶é¾å¤§çæ½åå¨åå½¢æ¹é¢ä»æªå¾å°ååæ¢ç´¢ãéæåºäºä¸åæè¶£çåé¡ï¼æåå¦ä½è¨­è¨åå½¢ç CoT æç¤ºä¾æå°åå½¢æ¨¡åéæ­¥å­¸ç¿ï¼ä¸æ¹é¢ï¼èèªç¶èªè¨ä¸åï¼åå½¢æ¯éç·æ§çï¼ä¸¦ä¸å·æè¤éçææ²çµæ§ãå¦ä¸æ¹é¢ï¼è¨±å¤åå½¢ç¼ºä¹ææ¬æ¸æï¼éä½¿å¾é£ä»¥å¶å®åºæ¼èªè¨ç CoT æç¤ºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºç¬¬ä¸åé©ç¨æ¼ç¡ææ¬åå½¢ç CoT æç¤ºå­¸ç¿æ¡æ¶ GCoTãå·é«ä¾èªªï¼æåå°æ¯åä¸æ¸¸ä»»åçé©æéç¨åè§£çºä¸ç³»åæ¨çæ­¥é©ï¼æ¯åæ­¥é©é½åå«åºæ¼æç¤ºçæ¨çããææ³ãçæä»¥ååºæ¼ææ³çæç¤ºå­¸ç¿ãéç¶éäºæ­¥é©æ¨¡æ¬äº NLP ä¸­ç CoT æç¤ºï¼ä½å·é«æ©å¶å»æå¾å¤§ä¸åãå·é«ä¾èªªï¼å¨æ¯ä¸æ­¥ä¸­ï¼ä¸åè¼¸å¥åå½¢é£åä¸åæç¤ºé¦åè¢«è¼¸å¥å°ä¸åé è¨ç·´çåå½¢ç·¨ç¢¼å¨ä¸­é²è¡åºæ¼æç¤ºçæ¨çãç¶å¾ï¼æåèåç·¨ç¢¼å¨çé±èå±¤ä»¥æ§å»ºä¸åãææ³ãï¼å®æç²äºç¶åæ­¥é©ä¸­æ¯åç¯é»çå·¥ä½çæãåºæ¼éåææ³ï¼æåæ ¹æç¶åçæå­¸ç¿ä¸åç¹å®æ¼æ¯åç¯é»çæç¤ºãéäºæç¤ºè¢«è¼¸å¥å°ä¸ä¸åæ¨çæ­¥é©ä¸­ï¼éè¤éåå¾ªç°ãçºäºè©ä¼°ååæ GCoT çæææ§ï¼æåå°å«åå¬å±æ¸æéé²è¡äºå¨é¢çå¯¦é©ï¼éè­æäºæåæ¹æ³çåªå¢ã</paragraph>

##### **Linking Cryptoasset Attribution Tags to Knowledge Graph Entities: An LLM-based Approach**
2502.10453v1 by RÃ©gnier Avice, Bernhard Haslhofer, Zhidong Li, Jianlong Zhou

Attribution tags form the foundation of modern cryptoasset forensics.
However, inconsistent or incorrect tags can mislead investigations and even
result in false accusations. To address this issue, we propose a novel
computational method based on Large Language Models (LLMs) to link attribution
tags with well-defined knowledge graph concepts. We implemented this method in
an end-to-end pipeline and conducted experiments showing that our approach
outperforms baseline methods by up to 37.4% in F1-score across three publicly
available attribution tag datasets. By integrating concept filtering and
blocking procedures, we generate candidate sets containing five knowledge graph
entities, achieving a recall of 93% without the need for labeled data.
Additionally, we demonstrate that local LLM models can achieve F1-scores of
90%, comparable to remote models which achieve 94%. We also analyze the
cost-performance trade-offs of various LLMs and prompt templates, showing that
selecting the most cost-effective configuration can reduce costs by 90%, with
only a 1% decrease in performance. Our method not only enhances attribution tag
quality but also serves as a blueprint for fostering more reliable forensic
evidence.

æè¦ï¼æ­¸å æ¨ç±¤æ§æç¾ä»£å å¯è³ç¢éè­çåºç¤ã
ç¶èï¼ä¸ä¸è´æä¸æ­£ç¢ºçæ¨ç±¤æèª¤å°èª¿æ¥ï¼çè³å°è´é¯èª¤çææ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®åºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ°åè¨ç®æ¹æ³ï¼å°æ­¸å æ¨ç±¤èå®ç¾©æç¢ºçç¥è­åè­æ¦å¿µé£çµèµ·ä¾ãæåå¨ç«¯å°ç«¯ç®¡éä¸­å¯¦æ½äºéç¨®æ¹æ³ï¼ä¸¦é²è¡äºå¯¦é©ï¼çµæé¡¯ç¤ºæåçåæ³å¨ä¸åå¬éå¯ç¨çæ­¸å æ¨ç±¤è³æéä¸­ï¼F1 åæ¸æ¯åºç·æ¹æ³é«åº 37.4%ãééæ´åæ¦å¿µéæ¿¾åå°éç¨åºï¼æåçæäºåå«äºåç¥è­åè­å¯¦é«çåé¸éï¼å¨ä¸éè¦æ¨ç±¤è³æçææ³ä¸ï¼éå°äº 93% çå¬åçã
æ­¤å¤ï¼æåè­æäºæ¬æ© LLM æ¨¡åå¯ä»¥éå° 90% ç F1 åæ¸ï¼èéå° 94% çé ç«¯æ¨¡åç¸ç¶ãæåä¹åæäºåç¨® LLM åæç¤ºç¯æ¬çææ¬æçæ¬è¡¡ï¼çµæé¡¯ç¤ºé¸ææå·ææ¬æççè¨­å®å¯ä»¥å°ææ¬éä½ 90%ï¼èæè½åªä¸é 1%ãæåçåæ³ä¸åæåäºæ­¸å æ¨ç±¤çåè³ªï¼ä¹ä½çºä¿é²æ´å¯é éè­è­æçèåã

##### **Deep Semantic Graph Learning via LLM based Node Enhancement**
2502.07982v1 by Chuanqi Shi, Yiyi Tao, Hang Zhang, Lun Wang, Shaoshuai Du, Yixian Shen, Yanxin Shen

Graph learning has attracted significant attention due to its widespread
real-world applications. Current mainstream approaches rely on text node
features and obtain initial node embeddings through shallow embedding learning
using GNNs, which shows limitations in capturing deep textual semantics. Recent
advances in Large Language Models (LLMs) have demonstrated superior
capabilities in understanding text semantics, transforming traditional text
feature processing. This paper proposes a novel framework that combines Graph
Transformer architecture with LLM-enhanced node features. Specifically, we
leverage LLMs to generate rich semantic representations of text nodes, which
are then processed by a multi-head self-attention mechanism in the Graph
Transformer to capture both local and global graph structural information. Our
model utilizes the Transformer's attention mechanism to dynamically aggregate
neighborhood information while preserving the semantic richness provided by LLM
embeddings. Experimental results demonstrate that the LLM-enhanced node
features significantly improve the performance of graph learning models on node
classification tasks. This approach shows promising results across multiple
graph learning tasks, offering a practical direction for combining graph
networks with language models.

æè¦ï¼åå½¢å­¸ç¿å å¶å»£æ³çç¾å¯¦ä¸çæç¨èååéæ³¨ãç®åçç±éæ¹æ³ä¾è³´æ¼ææ¬ç¯é»ç¹å¾µï¼ä¸¦ééä½¿ç¨ GNN çæ·ºå±¤åµå¥å­¸ç¿ä¾ç²ååå§ç¯é»åµå¥ï¼éå¨æææ·±åº¦ææ¬èªç¾©æ¹é¢è¡¨ç¾åºå±éæ§ãå¤§èªè¨æ¨¡å (LLM) çææ°é²å±å·²è­æå¨çè§£ææ¬èªç¾©æ¹é¢å·æåªè¶çè½åï¼è½æäºå³çµ±çææ¬ç¹å¾µèçãæ¬ææåºäºä¸ç¨®æ°çæ¡æ¶ï¼å°åå½¢è½æå¨æ¶æ§è LLM å¢å¼·çç¯é»ç¹å¾µç¸çµåãå·é«ä¾èªªï¼æåå©ç¨ LLM ä¾çæææ¬ç¯é»çè±å¯èªç¾©è¡¨ç¤ºï¼ç¶å¾å¨åå½¢è½æå¨ä¸­ç±å¤é ­èªææ³¨ææ©å¶èçï¼ä»¥ææå±é¨åå¨å±åå½¢çµæ§ä¿¡æ¯ãæåçæ¨¡åå©ç¨ Transformer çæ³¨ææ©å¶ä¾åæèåé°åä¿¡æ¯ï¼åæä¿ç LLM åµå¥æä¾çèªç¾©è±å¯æ§ãå¯¦é©çµæè¡¨æï¼LLM å¢å¼·çç¯é»ç¹å¾µé¡¯èæé«äºåå½¢å­¸ç¿æ¨¡åå¨ç¯é»åé¡ä»»åä¸çæ§è½ãéç¨®æ¹æ³å¨å¤ååå½¢å­¸ç¿ä»»åä¸­é¡¯ç¤ºåºæå¸æççµæï¼çºå°åå½¢ç¶²çµ¡èèªè¨æ¨¡åç¸çµåæä¾äºå¯¦ç¨çæ¹åã

##### **Cardiverse: Harnessing LLMs for Novel Card Game Prototyping**
2502.07128v1 by Danrui Li, Sen Zhang, Sam S. Sohn, Kaidong Hu, Muhammad Usman, Mubbasir Kapadia

The prototyping of computer games, particularly card games, requires
extensive human effort in creative ideation and gameplay evaluation. Recent
advances in Large Language Models (LLMs) offer opportunities to automate and
streamline these processes. However, it remains challenging for LLMs to design
novel game mechanics beyond existing databases, generate consistent gameplay
environments, and develop scalable gameplay AI for large-scale evaluations.
This paper addresses these challenges by introducing a comprehensive automated
card game prototyping framework. The approach highlights a graph-based indexing
method for generating novel game designs, an LLM-driven system for consistent
game code generation validated by gameplay records, and a gameplay AI
constructing method that uses an ensemble of LLM-generated action-value
functions optimized through self-play. These contributions aim to accelerate
card game prototyping, reduce human labor, and lower barriers to entry for game
developers.

æè¦ï¼é»è¦éæ²ï¼å°¤å¶æ¯å¡çéæ²çååè£½ä½ï¼éè¦å¤§éçäººåå¨åµææ§æåéæ²ç©æ³è©ä¼°ä¸ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æä¾äºèªåååç°¡åéäºæµç¨çæ©æãç¶èï¼LLM å¨è¨­è¨è¶è¶ç¾æè³æåº«çæ°ç©éæ²æ©å¶ãçæä¸è´çéæ²ç°å¢ï¼ä»¥åéç¼ç¨æ¼å¤§è¦æ¨¡è©ä¼°çå¯æ´åéæ² AI æ¹é¢ä»ç¶é¢è¨ææ°ãæ¬æééå¼å¥ä¸åå¨é¢çèªååå¡çéæ²ååè£½ä½æ¡æ¶ä¾æå°éäºææ°ãè©²æ¹æ³å¼·èª¿äºä¸ç¨®åºæ¼åè¡¨çç´¢å¼æ¹æ³ï¼ç¨æ¼çææ°ç©çéæ²è¨­è¨ï¼ä¸åç± LLM é©åçç³»çµ±ï¼ç¨æ¼ä¸è´çéæ²ç¨å¼ç¢¼çæï¼ä¸¦ç±éæ²è¨éé©è­ï¼ä»¥åä¸åéæ² AI æ§å»ºæ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ç± LLM çæçåä½å¼å½æ¸çéåï¼ééèªæå°å¼é²è¡æä½³åãéäºè²¢ç»æ¨å¨å éå¡çéæ²ååè£½ä½ï¼æ¸å°äººåï¼ä¸¦éä½éæ²éç¼äººå¡çé²å¥éæª»ã

##### **GraNNite: Enabling High-Performance Execution of Graph Neural Networks on Resource-Constrained Neural Processing Units**
2502.06921v2 by Arghadip Das, Shamik Kundu, Arnab Raha, Soumendu Ghosh, Deepak Mathaikutty, Vijay Raghunathan

Graph Neural Networks (GNNs) are vital for learning from graph-structured
data, enabling applications in network analysis, recommendation systems, and
speech analytics. Deploying them on edge devices like client PCs and laptops
enhances real-time processing, privacy, and cloud independence. GNNs aid
Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs) and
enable event-based vision tasks. However, irregular memory access, sparsity,
and dynamic structures cause high latency and energy overhead on
resource-constrained devices. While modern edge processors integrate CPUs,
GPUs, and NPUs, NPUs designed for data-parallel tasks struggle with irregular
GNN computations. We introduce GraNNite, the first hardware-aware framework
optimizing GNN execution on commercial-off-the-shelf (COTS) SOTA DNN
accelerators via a structured three-step methodology: (1) enabling NPU
execution, (2) optimizing performance, and (3) trading accuracy for efficiency
gains. Step 1 employs GraphSplit for workload distribution and StaGr for static
aggregation, while GrAd and NodePad handle dynamic graphs. Step 2 boosts
performance using EffOp for control-heavy tasks and GraSp for sparsity
exploitation. Graph Convolution optimizations PreG, SymG, and CacheG reduce
redundancy and memory transfers. Step 3 balances quality versus efficiency,
where QuantGr applies INT8 quantization, and GrAx1, GrAx2, and GrAx3 accelerate
attention, broadcast-add, and SAGE-max aggregation. On Intel Core Ultra AI PCs,
GraNNite achieves 2.6X to 7.6X speedups over default NPU mappings and up to
8.6X energy gains over CPUs and GPUs, delivering 10.8X and 6.7X higher
performance than CPUs and GPUs, respectively, across GNN models.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å°æ¼å¾åå½¢çµæ§è³æä¸­å­¸ç¿è³ééè¦ï¼è½æç¨æ¼ç¶²è·¯åæãæ¨è¦ç³»çµ±åèªé³åæãå°å¶é¨ç½²å¨éç·£è£ç½®ï¼ä¾å¦ç¨æ¶ç«¯é»è¦åç­é»ï¼ä¸å¯å¢å¼·å³æèçãé±ç§åé²ç«¯ç¨ç«æ§ãGNN åå©å¤§åèªè¨æ¨¡å (LLM) çæª¢ç´¢å¢å¼·çæ (RAG)ï¼ä¸¦æ¯æ´åºæ¼äºä»¶çè¦è¦ºä»»åãç¶èï¼ä¸è¦åçè¨æ¶é«å­åãç¨çæ§ååæçµæ§æå°è´è³æºåéè£ç½®ä¸çé«å»¶é²åè½æºè² æãåç®¡ç¾ä»£éç·£èçå¨æ´åäº CPUãGPU å NPUï¼ä½éå°è³æå¹³è¡ä»»åæè¨­è¨ç NPU é£ä»¥èçä¸è¦åç GNN è¨ç®ãæåå¼å¥äº GraNNiteï¼éæ¯ç¬¬ä¸åç¡¬é«æç¥æ¡æ¶ï¼ééçµæ§åçä¸æ­¥é©æ¹æ³æä½³ååç¨ç¾æ (COTS) SOTA DNN å éå¨ä¸ç GNN å·è¡ï¼(1) åç¨ NPU å·è¡ï¼(2) æä½³åæè½ï¼ä»¥å (3) ä»¥æºç¢ºåº¦æåæçæåãæ­¥é© 1 ä½¿ç¨ GraphSplit é²è¡å·¥ä½è² è¼åéï¼ä¸¦ä½¿ç¨ StaGr é²è¡éæèåï¼è GrAd å NodePad åèçåæåå½¢ãæ­¥é© 2 ä½¿ç¨ EffOp æåæ§å¶å¯éåä»»åçæè½ï¼ä¸¦ä½¿ç¨ GraSp é²è¡ç¨çæ§å©ç¨ãåå½¢å·ç©æä½³å PreGãSymG å CacheG æ¸å°äºåé¤åè¨æ¶é«å³è¼¸ãæ­¥é© 3 å¹³è¡¡åè³ªèæçï¼å¶ä¸­ QuantGr é©ç¨ INT8 éåï¼è GrAx1ãGrAx2 å GrAx3 åå éæ³¨æåãå»£æ­å æ³å SAGE-max èåãå¨ Intel Core Ultra AI PC ä¸ï¼GraNNite å¨é è¨­ NPU æ å°ä¸å¯¦ç¾äº 2.6X å° 7.6X çå éï¼å¨ CPU å GPU ä¸å¯¦ç¾äºé«é 8.6X çè½æºå¢çï¼å¨ GNN æ¨¡åä¸­åå¥æä¾äºæ¯ CPU å GPU é«åº 10.8X å 6.7X çæè½ã

##### **Automatic Annotation Augmentation Boosts Translation between Molecules and Natural Language**
2502.06634v1 by Zhiqiang Zhong, Simon Sataa-Yu Larsen, Haoyu Guo, Tao Tang, Kuangyu Zhou, Davide Mottin

Recent advancements in AI for biological research focus on integrating
molecular data with natural language to accelerate drug discovery. However, the
scarcity of high-quality annotations limits progress in this area. This paper
introduces LA$^3$, a Language-based Automatic Annotation Augmentation framework
that leverages large language models to augment existing datasets, thereby
improving AI training. We demonstrate the effectiveness of LA$^3$ by creating
an enhanced dataset, LaChEBI-20, where we systematically rewrite the
annotations of molecules from an established dataset. These rewritten
annotations preserve essential molecular information while providing more
varied sentence structures and vocabulary. Using LaChEBI-20, we train LaMolT5
based on a benchmark architecture to learn the mapping between molecular
representations and augmented annotations.
  Experimental results on text-based *de novo* molecule generation and molecule
captioning demonstrate that LaMolT5 outperforms state-of-the-art models.
Notably, incorporating LA$^3$ leads to improvements of up to 301% over the
benchmark architecture. Furthermore, we validate the effectiveness of LA$^3$
notable applications in *image*, *text* and *graph* tasks, affirming its
versatility and utility.

æè¦ï¼<paragraph>äººå·¥æºæ§å¨çç©ç ç©¶ä¸çææ°é²å±ï¼å°æ³¨æ¼å°åå­è³æèèªç¶èªè¨æ´åï¼ä»¥å éè¥ç©ç¼ç¾ãç¶èï¼é«åè³ªè¨»è§£çç¨å°éå¶äºæ­¤é åçé²å±ãéç¯è«æä»ç´¹äº LA$^3$ï¼ä¸ååºæ¼èªè¨çèªåè¨»è§£æ´åæ¡æ¶ï¼å®å©ç¨å¤§åèªè¨æ¨¡åä¾æ´åç¾æçè³æéï¼é²èæ¹åäººå·¥æºæ§è¨ç·´ãæåééå»ºç«ä¸åå¢å¼·çè³æé LaChEBI-20 ä¾å±ç¤º LA$^3$ çæææ§ï¼æåç³»çµ±æ§å°æ¹å¯«äºä¸åæ¢å®è³æéä¸­åå­çè¨»è§£ãéäºæ¹å¯«çè¨»è§£ä¿çäºéè¦çåå­è³è¨ï¼åææä¾äºæ´å¤æ¨£åçå¥å­çµæ§åè©å½ãä½¿ç¨ LaChEBI-20ï¼æåå¨åºæ¼åºæºæ¶æ§ä¸è¨ç·´ LaMolT5ï¼ä»¥å­¸ç¿åå­è¡¨ç¤ºåæ´åè¨»è§£ä¹éçå°æã
å¨åºæ¼æå­ç *å¾é ­éå§* åå­çæååå­æ¨é¡ä¸çå¯¦é©çµæè¡¨æï¼LaMolT5 åªæ¼æåé²çæ¨¡åãå¼å¾æ³¨æçæ¯ï¼ç´å¥ LA$^3$ å¯è®åºæºæ¶æ§çæ¹é²å¹åº¦é«é 301%ãæ­¤å¤ï¼æåé©è­äº LA$^3$ å¨ *å½±å*ã*æå­* å *åå½¢* ä»»åä¸­çæææ§ï¼è¯å®äºå®çå¤åè½æ§åå¯¦ç¨æ§ã</paragraph>

##### **KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment**
2502.06472v1 by Yuxing Lu, Jinzhuo Wang

Maintaining comprehensive and up-to-date knowledge graphs (KGs) is critical
for modern AI systems, but manual curation struggles to scale with the rapid
growth of scientific literature. This paper presents KARMA, a novel framework
employing multi-agent large language models (LLMs) to automate KG enrichment
through structured analysis of unstructured text. Our approach employs nine
collaborative agents, spanning entity discovery, relation extraction, schema
alignment, and conflict resolution that iteratively parse documents, verify
extracted knowledge, and integrate it into existing graph structures while
adhering to domain-specific schema. Experiments on 1,200 PubMed articles from
three different domains demonstrate the effectiveness of KARMA in knowledge
graph enrichment, with the identification of up to 38,230 new entities while
achieving 83.1\% LLM-verified correctness and reducing conflict edges by 18.6\%
through multi-layer assessments.

æè¦ï¼ç¶­è­·å¨é¢ä¸ææ°çç¥è­åè­ (KG) å°ç¾ä»£ AI ç³»çµ±è³ééè¦ï¼ä½æåç­åé£ä»¥é¨èç§å­¸æç»çå¿«éå¢é·èæ´å±ãæ¬ææåºäº KARMAï¼ä¸åæ¡ç¨å¤ä»£çå¤§åèªè¨æ¨¡å (LLM) çæ°æ¡æ¶ï¼ééå°éçµæ§åææ¬ççµæ§ååæä¾èªåå KG è±å¯åãæåçåæ³æ¡ç¨ä¹ååä½ä»£çï¼æ¶µèå¯¦é«ç¼ç¾ãéä¿æåãæ¶æ§æ¯å°åè¡çªè§£æ±ºï¼éäºä»£çæåè¦åææä»¶ãé©è­æåçç¥è­ï¼ä¸¦å°å¶æ´åå°ç¾æçåçµæ§ä¸­ï¼åæéµå®ç¹å®é åçæ¶æ§ãéå°ä¾èªä¸åä¸åé åç 1,200 ç¯ PubMed æç« é²è¡çå¯¦é©è­æäº KARMA å¨ç¥è­åè­è±å¯åæ¹é¢çæææ§ï¼è­å¥åºå¤é 38,230 åæ°å¯¦é«ï¼åæéå° 83.1% ç LLM é©è­æ­£ç¢ºæ§ï¼ä¸¦ééå¤å±¤è©ä¼°å°è¡çªéç·£éä½äº 18.6%ã

##### **RoToR: Towards More Reliable Responses for Order-Invariant Inputs**
2502.08662v1 by Soyoung Yoon, Dongha Ahn, Youngwon Lee, Minkyu Jung, HyungJoo Jang, Seung-won Hwang

Mitigating positional bias of language models (LMs) for listwise inputs is a
well-known and important problem (e.g., lost-in-the-middle). While zero-shot
order-invariant LMs have been proposed to solve this issue, their success on
practical listwise problems has been limited. In this work, as a first
contribution, we identify and overcome two limitations to make zero-shot
invariant LMs more practical: (1) training and inference distribution mismatch
arising from modifying positional ID assignments to enforce invariance, and (2)
failure to adapt to a mixture of order-invariant and sensitive inputs in
practical listwise problems. To overcome, we propose (1) RoToR, a zero-shot
invariant LM for genuinely order-invariant inputs with minimal modifications of
positional IDs, and (2) Selective Routing, an adaptive framework that handles
both order-invariant and order-sensitive inputs in listwise tasks. On the Lost
in the middle (LitM), Knowledge Graph Question Answering (KGQA), and MMLU
benchmarks, we show that RoToR with Selective Routing can effectively handle
practical listwise input tasks in a zero-shot manner.

æè¦ï¼èªè¨æ¨¡å (LM) çä½ç½®åå·®ç·©è§£å°æ¼åè¡¨è¼¸å¥ä¾èªªæ¯ä¸åå»£çºäººç¥ä¸éè¦çåé¡ï¼ä¾å¦ï¼è¿·å¤±å¨ä¸­éï¼ãéç¶å·²ç¶æåºé¶æ¬¡å­¸ç¿é åºä¸è®ç LM ä¾è§£æ±ºéååé¡ï¼ä½å®åå¨å¯¦éåè¡¨åé¡ä¸çæåå»å¾æéãå¨éé å·¥ä½ä¸­ï¼ä½çºç¬¬ä¸åè²¢ç»ï¼æåæ¾åºä¸¦åæäºå©åéå¶ï¼è®é¶æ¬¡å­¸ç¿ä¸è®ç LM æ´æå¯¦ç¨æ§ï¼(1) è¨ç·´åæ¨è«åå¸ä¸å¹éï¼éæ¯ç±æ¼ä¿®æ¹ä½ç½® ID åéä»¥å¼·å¶ä¸è®æ§æé æçï¼ä»¥å (2) ç¡æ³é©æå¯¦éåè¡¨åé¡ä¸­ä¸è®åææè¼¸å¥ççµåãçºäºåæéäºåé¡ï¼æåæåº (1) RoToRï¼ä¸åé¶æ¬¡å­¸ç¿ä¸è®ç LMï¼ç¨æ¼çæ­£ä¸è®çè¼¸å¥ï¼ä¸¦å°ä½ç½® ID é²è¡æå°çä¿®æ¹ï¼ä»¥å (2) é¸ææ§è·¯ç±ï¼ä¸åèªé©ææ¡æ¶ï¼ç¨æ¼èçåè¡¨ä»»åä¸­ä¸è®åææçè¼¸å¥ãå¨è¿·å¤±å¨ä¸­é (LitM)ãç¥è­åè­åç­ (KGQA) å MMLU åºæºæ¸¬è©¦ä¸­ï¼æåå±ç¤ºäº RoToR èé¸ææ§è·¯ç±å¯ä»¥ææå°ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼èçå¯¦éçåè¡¨è¼¸å¥ä»»åã

##### **K-ON: Stacking Knowledge On the Head Layer of Large Language Model**
2502.06257v1 by Lingbing Guo, Yichi Zhang, Zhongpu Bo, Zhuo Chen, Mengshu Sun, Zhiqiang Zhang, Wen Zhang, Huajun Chen

Recent advancements in large language models (LLMs) have significantly
improved various natural language processing (NLP) tasks. Typically, LLMs are
trained to predict the next token, aligning well with many NLP tasks. However,
in knowledge graph (KG) scenarios, entities are the fundamental units and
identifying an entity requires at least several tokens. This leads to a
granularity mismatch between KGs and natural languages. To address this issue,
we propose K-ON, which integrates KG knowledge into the LLM by employing
multiple head layers for next k-step prediction. K-ON can not only generate
entity-level results in one step, but also enables contrastive loss against
entities, which is the most powerful tool in KG representation learning.
Experimental results show that K-ON outperforms state-of-the-art methods that
incorporate text and even the other modalities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯èæåäºåç¨®èªç¶èªè¨èç (NLP) ä»»åãéå¸¸ï¼LLM ææ¥åè¨ç·´ä»¥é æ¸¬ä¸ä¸åç¬¦èï¼éèè¨±å¤ NLP ä»»åéå¸¸å»åãç¶èï¼å¨ç¥è­åè­ (KG) å ´æ¯ä¸­ï¼å¯¦é«æ¯åºæ¬å®ä½ï¼èè­å¥å¯¦é«è³å°éè¦å¹¾åç¬¦èãéå°è´ KG åèªç¶èªè¨ä¹éçç²åº¦ä¸å¹éãçºäºè§£æ±ºéååé¡ï¼æåæåºäº K-ONï¼å®ééæ¡ç¨å¤åé ­é¨å±¤é²è¡ä¸ä¸å k æ­¥é æ¸¬ï¼å° KG ç¥è­æ´åå° LLM ä¸­ãK-ON ä¸åå¯ä»¥å¨ä¸åæ­¥é©ä¸­ç¢çå¯¦é«å±¤ç´ççµæï¼éè½éå°å¯¦é«åç¨å°æ¯æå¤±ï¼éæ¯ KG è¡¨ç¤ºå­¸ç¿ä¸­ææåçå·¥å·ãå¯¦é©çµæé¡¯ç¤ºï¼K-ON åªæ¼å°æå­çè³å¶ä»æ¹å¼ç´å¥èéçææ°æ¹æ³ã

##### **LegalViz: Legal Text Visualization by Text To Diagram Generation**
2502.06147v2 by Eri Onami, Taiki Miyanishi, Koki Maeda, Shuhei Kurita

Legal documents including judgments and court orders require highly
sophisticated legal knowledge for understanding. To disclose expert knowledge
for non-experts, we explore the problem of visualizing legal texts with
easy-to-understand diagrams and propose a novel dataset of LegalViz with 23
languages and 7,010 cases of legal document and visualization pairs, using the
DOT graph description language of Graphviz. LegalViz provides a simple diagram
from a complicated legal corpus identifying legal entities, transactions, legal
sources, and statements at a glance, that are essential in each judgment. In
addition, we provide new evaluation metrics for the legal diagram visualization
by considering graph structures, textual similarities, and legal contents. We
conducted empirical studies on few-shot and finetuning large language models
for generating legal diagrams and evaluated them with these metrics, including
legal content-based evaluation within 23 languages. Models trained with
LegalViz outperform existing models including GPTs, confirming the
effectiveness of our dataset.

æè¦ï¼æ³å¾æä»¶ï¼åæ¬å¤æ±ºåæ³é¢å½ä»¤ï¼éè¦é«åº¦å°æ¥­çæ³å¾ç¥è­æè½çè§£ãçºäºåéå°å®¶æ­é²å°å®¶ç¥è­ï¼æåæ¢è¨äºä½¿ç¨ææ¼çè§£çåè¡¨å°æ³å¾ææ¬è¦è¦ºåçåé¡ï¼ä¸¦æåºäºä¸åæ°ç LegalViz æ¸æéï¼å¶ä¸­åå« 23 ç¨®èªè¨å 7,010 åæ³å¾æä»¶åè¦è¦ºåéå°ï¼ä½¿ç¨ Graphviz ç DOT åå½¢æè¿°èªè¨ãLegalViz å¾è¤éçæ³å¾èªæåº«ä¸­æä¾äºä¸åç°¡å®çåè¡¨ï¼å¯ä»¥ä¸ç®äºç¶å°è­å¥æ³å¾å¯¦é«ãäº¤æãæ³å¾ä¾æºåé³è¿°ï¼éäºå¨æ¯é å¤æ±ºä¸­é½æ¯å¿ä¸å¯å°çãæ­¤å¤ï¼æåééèæ®åå½¢çµæ§ãææ¬ç¸ä¼¼æ§åæ³å¾å§å®¹ï¼çºæ³å¾åè¡¨è¦è¦ºåæä¾äºæ°çè©ä¼°ææ¨ãæåå°å°æ¬¡å­¸ç¿åå¾®èª¿å¤§åèªè¨æ¨¡åé²è¡äºå¯¦è­ç ç©¶ï¼ä»¥çææ³å¾åè¡¨ï¼ä¸¦ä½¿ç¨éäºææ¨å°å®åé²è¡äºè©ä¼°ï¼åæ¬å¨ 23 ç¨®èªè¨ä¸­åºæ¼æ³å¾å§å®¹çè©ä¼°ãä½¿ç¨ LegalViz è¨ç·´çæ¨¡ååªæ¼ç¾æçæ¨¡åï¼åæ¬ GPTï¼è­å¯¦äºæåæ¸æéçæææ§ã

##### **Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs**
2502.06075v1 by Han Meng, Renwen Zhang, Ganyi Wang, Yitian Yang, Peinuan Qin, Jungup Lee, Yi-Chieh Lee

Mental-illness stigma is a persistent social problem, hampering both
treatment-seeking and recovery. Accordingly, there is a pressing need to
understand it more clearly, but analyzing the relevant data is highly
labor-intensive. Therefore, we designed a chatbot to engage participants in
conversations; coded those conversations qualitatively with AI assistance; and,
based on those coding results, built causal knowledge graphs to decode stigma.
The results we obtained from 1,002 participants demonstrate that conversation
with our chatbot can elicit rich information about people's attitudes toward
depression, while our AI-assisted coding was strongly consistent with
human-expert coding. Our novel approach combining large language models (LLMs)
and causal knowledge graphs uncovered patterns in individual responses and
illustrated the interrelationships of psychological constructs in the dataset
as a whole. The paper also discusses these findings' implications for HCI
researchers in developing digital interventions, decomposing human
psychological constructs, and fostering inclusive attitudes.

æè¦ï¼ç²¾ç¥ç¾ççæ±¡ååæ¯ä¸åæçºå­å¨çç¤¾æåé¡ï¼é»ç¤äºå°æ±æ²»çååº·å¾©ãå æ­¤ï¼è¿«åéè¦æ´æ¸æ¥å°äºè§£å®ï¼ä½åæç¸éæ¸æéå¸¸è²»åãå æ­¤ï¼æåè¨­è¨äºä¸åèå¤©æ©å¨äººï¼è®åèèåèå°è©±ï¼ä½¿ç¨ AI åå©å°éäºå°è©±é²è¡å®æ§ç·¨ç¢¼ï¼ä¸¦æ ¹æéäºç·¨ç¢¼çµæï¼æ§å»ºå æç¥è­åè­ä¾ç ´è­¯æ±¡ååãæåå¾ 1,002 ååèèé£è£¡ç²å¾ççµæè¡¨æï¼èæåçèå¤©æ©å¨äººçå°è©±å¯ä»¥å¼åºäººåå°æé¬±ççè±å¯è³è¨ï¼èæå AI è¼å©çç·¨ç¢¼èäººé¡å°å®¶ç·¨ç¢¼éå¸¸ä¸è´ãæåå°å¤§åèªè¨æ¨¡å (LLM) åå æç¥è­åè­ç¸çµåçæ°æ¹æ³æ­ç¤ºäºåå¥åæä¸­çæ¨¡å¼ï¼ä¸¦èªªæäºè³æéä¸­å¿çå»ºæ§ä¹éçç¸äºéä¿ãæ¬æéè¨è«äºéäºç¼ç¾å° HCI ç ç©¶äººå¡å¨éç¼æ¸ä½ä»å¥æªæ½ãåè§£äººé¡å¿çå»ºæ§åå¹é¤åå®¹æåº¦æ¹é¢çå½±é¿ã

##### **LegalSeg: Unlocking the Structure of Indian Legal Judgments Through Rhetorical Role Classification**
2502.05836v1 by Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya

In this paper, we address the task of semantic segmentation of legal
documents through rhetorical role classification, with a focus on Indian legal
judgments. We introduce LegalSeg, the largest annotated dataset for this task,
comprising over 7,000 documents and 1.4 million sentences, labeled with 7
rhetorical roles. To benchmark performance, we evaluate multiple
state-of-the-art models, including Hierarchical BiLSTM-CRF,
TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and
Role-Aware Transformers, alongside an exploratory RhetoricLLaMA, an
instruction-tuned large language model. Our results demonstrate that models
incorporating broader context, structural relationships, and sequential
sentence information outperform those relying solely on sentence-level
features. Additionally, we conducted experiments using surrounding context and
predicted or actual labels of neighboring sentences to assess their impact on
classification accuracy. Despite these advancements, challenges persist in
distinguishing between closely related roles and addressing class imbalance.
Our work underscores the potential of advanced techniques for improving legal
document understanding and sets a strong foundation for future research in
legal NLP.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåééä¿®è¾­è§è²åé¡ä¾æ¢è¨æ³å¾æä»¶çèªç¾©åæ®µä»»åï¼éé»éæ³¨å°åº¦æ³å¾å¤æ±ºãæåå¼å¥äº LegalSegï¼éæ¯æ­¤ä»»åä¸­æå¤§çè¨»éè³æéï¼åå«è¶é 7,000 ä»½æä»¶å 140 è¬åå¥å­ï¼ä¸¦æ¨è¨äº 7 åä¿®è¾­è§è²ãçºäºè©éæè½ï¼æåè©ä¼°äºå¤åæåé²çæ¨¡åï¼åæ¬åå±¤ BiLSTM-CRFãTransformerOverInLegalBERT (ToInLegalBERT)ãåç¥ç¶ç¶²è·¯ (GNN) åè§è²æç¥Transformerï¼ä»¥åæ¢ç´¢æ§ç RhetoricLLaMAï¼ä¸ç¨®ç¶éæä»¤èª¿æ´çå¤§åèªè¨æ¨¡åãæåççµæè¡¨æï¼çµåå»£æ³èæ¯ãçµæ§éä¿åé åºå¥å­è³è¨çæ¨¡åï¼è¡¨ç¾åªæ¼åä¾è³´å¥å­å±¤ç´ç¹å¾µçæ¨¡åãæ­¤å¤ï¼æåä½¿ç¨å¨åçèæ¯åé°è¿å¥å­çé æ¸¬æå¯¦éæ¨ç±¤é²è¡å¯¦é©ï¼ä»¥è©ä¼°å®åå°åé¡ç²¾åº¦çå½±é¿ãåç®¡æéäºé²å±ï¼ä½å¨ååå¯åç¸éçè§è²åè§£æ±ºé¡å¥ä¸å¹³è¡¡æ¹é¢ä»å­å¨ææ°ãæåçç ç©¶å¼·èª¿äºåé²æè¡å¨æ¹åæ³å¾æä»¶çè§£æ¹é¢çæ½åï¼ä¸¦çºæ³å¾èªç¶èªè¨èççæªä¾ç ç©¶å¥ å®äºå å¯¦çåºç¤ã</paragraph>

##### **LLM-Powered Decentralized Generative Agents with Adaptive Hierarchical Knowledge Graph for Cooperative Planning**
2502.05453v1 by Hanqing Yang, Jingdi Chen, Marie Siew, Tania Lorido-Botran, Carlee Joe-Wong

Developing intelligent agents for long-term cooperation in dynamic open-world
scenarios is a major challenge in multi-agent systems. Traditional Multi-agent
Reinforcement Learning (MARL) frameworks like centralized training
decentralized execution (CTDE) struggle with scalability and flexibility. They
require centralized long-term planning, which is difficult without custom
reward functions, and face challenges in processing multi-modal data. CTDE
approaches also assume fixed cooperation strategies, making them impractical in
dynamic environments where agents need to adapt and plan independently. To
address decentralized multi-agent cooperation, we propose Decentralized
Adaptive Knowledge Graph Memory and Structured Communication System (DAMCS) in
a novel Multi-agent Crafter environment. Our generative agents, powered by
Large Language Models (LLMs), are more scalable than traditional MARL agents by
leveraging external knowledge and language for long-term planning and
reasoning. Instead of fully sharing information from all past experiences,
DAMCS introduces a multi-modal memory system organized as a hierarchical
knowledge graph and a structured communication protocol to optimize agent
cooperation. This allows agents to reason from past interactions and share
relevant information efficiently. Experiments on novel multi-agent open-world
tasks show that DAMCS outperforms both MARL and LLM baselines in task
efficiency and collaboration. Compared to single-agent scenarios, the two-agent
scenario achieves the same goal with 63% fewer steps, and the six-agent
scenario with 74% fewer steps, highlighting the importance of adaptive memory
and structured communication in achieving long-term goals. We publicly release
our project at: https://happyeureka.github.io/damcs.

æè¦ï¼<paragraph>å¨åæéæ¾ä¸çæå¢ä¸­éç¼ç¨æ¼é·æåä½çæºæ§ä»£çæ¯å¤éä»£çç³»çµ±ä¸­çä¸é éå¤§ææ°ãå³çµ±çå¤éä»£çå¼·åå­¸ç¿ (MARL) æ¡æ¶ï¼ä¾å¦éä¸­å¼è¨ç·´å»ä¸­å¿åå·è¡ (CTDE)ï¼å¨å¯æ´åæ§åéæ´»æ§æ¹é¢é¢è¨å°é£ãå®åéè¦éä¸­å¼é·æè¦åï¼éå¨æ²æèªè¨çåµå½æ¸çææ³ä¸å¾é£å·è¡ï¼ä¸¦ä¸å¨èçå¤æ¨¡å¼æ¸æææé¢è¨ææ°ãCTDE æ¹æ³éåè¨­åºå®çåä½ç­ç¥ï¼éä½¿å¾å®åå¨ä»£çéè¦ç¨ç«é©æåè¦åçåæç°å¢ä¸­ä¸åå¯¦éãçºäºè§£æ±ºåæ£å¼å¤éä»£çåä½åé¡ï¼æåå¨ä¸åæ°ç©çå¤éä»£çå·¥å ç°å¢ä¸­æåºäºåæ£å¼èªé©æç¥è­åè­è¨æ¶é«åçµæ§åéè¨ç³»çµ± (DAMCS)ãæåççæä»£çç±å¤§åèªè¨æ¨¡å (LLM) æä¾æ¯æ´ï¼ééå©ç¨å¤é¨ç¥è­åèªè¨é²è¡é·æè¦ååæ¨çï¼æ¯å³çµ±ç MARL ä»£çæ´å·å¯æ´åæ§ãDAMCS æ²æå®å¨åäº«ä¾èªææéå»ç¶é©çè³è¨ï¼èæ¯å¼å¥äºå¤æ¨¡å¼è¨æ¶é«ç³»çµ±ï¼è©²ç³»çµ±çµç¹æéå±¤å¼ç¥è­åè­åçµæ§åéè¨åå®ï¼ä»¥æä½³åä»£çåä½ãéåè¨±ä»£çæ ¹æéå»çäºåé²è¡æ¨çä¸¦ææå°åäº«ç¸éè³è¨ãå¨æ°çå¤éä»£çéæ¾ä¸çä»»åä¸çå¯¦é©è¡¨æï¼DAMCS å¨ä»»åæçååä½æ¹é¢åªæ¼ MARL å LLM åºæºãèå®ä¸ä»£çæå¢ç¸æ¯ï¼ééä»£çæå¢ä»¥å° 63% çæ­¥é©éæç¸åçç®æ¨ï¼èå­éä»£çæå¢åä»¥å° 74% çæ­¥é©éæç®æ¨ï¼çªé¡¯äºèªé©æè¨æ¶é«åçµæ§åéè¨å¨éæé·æç®æ¨ä¸­çéè¦æ§ãæåå¬éç¼å¸æåçå°æ¡æ¼ï¼https://happyeureka.github.io/damcsã</paragraph>

##### **SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation**
2502.05424v1 by Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang

Graphs are able to model interconnected entities in many online services,
supporting a wide range of applications on the Web. This raises an important
question: How can we train a graph foundational model on multiple source
domains and adapt to an unseen target domain? A major obstacle is that graphs
from different domains often exhibit divergent characteristics. Some studies
leverage large language models to align multiple domains based on textual
descriptions associated with the graphs, limiting their applicability to
text-attributed graphs. For text-free graphs, a few recent works attempt to
align different feature distributions across domains, while generally
neglecting structural differences. In this work, we propose a novel Structure
Alignment framework for text-free Multi-domain Graph Pre-Training and
cross-domain adaptation (SAMGPT). It is designed to learn multi-domain
knowledge from graphs originating in multiple source domains, which can then be
adapted to address applications in an unseen target domain. Specifically, we
introduce a set of structure tokens to harmonize structure-based aggregation
across source domains during the pre-training phase. Next, for cross-domain
adaptation, we design dual prompts, namely, holistic prompts and specific
prompts, which adapt unified multi-domain structural knowledge and
fine-grained, domain-specific information, respectively, to a target domain.
Finally, we conduct comprehensive experiments on seven public datasets to
evaluate and analyze the effectiveness of SAMGPT.

æè¦ï¼åè¡¨è½å¤ å¨è¨±å¤ç·ä¸æåä¸­å°ç¸äºéè¯çå¯¦é«é²è¡å»ºæ¨¡ï¼
æ¯æ´ç¶²è·¯ä¸å»£æ³çæç¨ç¨å¼ãéæåºäºéè¦çåé¡ï¼æåå¦ä½éå°å¤åä¾æºç¶²åè¨ç·´åè¡¨åºç¤æ¨¡åï¼ä¸¦é©ææªè¦éçç®æ¨ç¶²åï¼ä¸åä¸»è¦çéç¤æ¯ï¼ä¾èªä¸åç¶²åçåè¡¨éå¸¸è¡¨ç¾åºä¸åçç¹æ§ãä¸äºç ç©¶å©ç¨å¤§åèªè¨æ¨¡åï¼æ ¹æèåè¡¨ç¸éçæå­æè¿°ï¼å°é½å¤åç¶²åï¼éå¶å¶é©ç¨æ§æ¼ææå­å±¬æ§çåè¡¨ãå°æ¼æ²ææå­çåè¡¨ï¼æè¿çä¸äºä½ååè©¦å°é½è·¨ç¶²åçä¸åç¹å¾µåä½ï¼åæéå¸¸å¿½ç¥çµæ§ä¸çå·®ç°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åæ°ççµæ§å°é½æ¡æ¶ï¼ç¨æ¼ç¡æå­å¤ç¶²ååè¡¨é è¨ç·´åè·¨ç¶²åé©æ (SAMGPT)ãå®è¢«è¨­è¨çºå¾èµ·æºæ¼å¤åä¾æºç¶²åçåè¡¨ä¸­å­¸ç¿å¤ç¶²åç¥è­ï¼ç¶å¾å¯ä»¥é©ææ¼æªè¦éçç®æ¨ç¶²åä¸­çæç¨ç¨å¼ãå·é«ä¾èªªï¼æåå¼å¥äºä¸çµçµæ§åä»£ç¢¼ï¼ä»¥å¨é è¨ç·´éæ®µï¼èª¿åè·¨ä¾æºç¶²åçåºæ¼çµæ§çèåãæ¥ä¸ä¾ï¼å°æ¼è·¨ç¶²åé©æï¼æåè¨­è¨äºééæç¤ºï¼å³æ´é«æç¤ºåå·é«æç¤ºï¼åå¥å°çµ±ä¸çå¤ç¶²åçµæ§ç¥è­åç´°ç·»çãç¹å®æ¼ç¶²åçè³è¨é©æå°ç®æ¨ç¶²åãæå¾ï¼æåå¨ä¸åå¬å±è³æéä¸é²è¡äºå¨é¢çå¯¦é©ï¼ä»¥è©ä¼°ååæ SAMGPT çæææ§ã

##### **Graph-based Molecular In-context Learning Grounded on Morgan Fingerprints**
2502.05414v1 by Ali Al-Lawati, Jason Lucas, Zhiwei Zhang, Prasenjit Mitra, Suhang Wang

In-context learning (ICL) effectively conditions large language models (LLMs)
for molecular tasks, such as property prediction and molecule captioning, by
embedding carefully selected demonstration examples into the input prompt. This
approach avoids the computational overhead of extensive pertaining and
fine-tuning. However, current prompt retrieval methods for molecular tasks have
relied on molecule feature similarity, such as Morgan fingerprints, which do
not adequately capture the global molecular and atom-binding relationships. As
a result, these methods fail to represent the full complexity of molecular
structures during inference. Moreover, small-to-medium-sized LLMs, which offer
simpler deployment requirements in specialized systems, have remained largely
unexplored in the molecular ICL literature. To address these gaps, we propose a
self-supervised learning technique, GAMIC (Graph-Aligned Molecular In-Context
learning, which aligns global molecular structures, represented by graph neural
networks (GNNs), with textual captions (descriptions) while leveraging local
feature similarity through Morgan fingerprints. In addition, we introduce a
Maximum Marginal Relevance (MMR) based diversity heuristic during retrieval to
optimize input prompt demonstration samples. Our experimental findings using
diverse benchmark datasets show GAMIC outperforms simple Morgan-based ICL
retrieval methods across all tasks by up to 45%.

æè¦ï¼<paragraph>æå¢å­¸ç¿ (ICL) ææå°èª¿æ´å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥å·è¡åå­ä»»åï¼ä¾å¦å±¬æ§é æ¸¬ååå­æ¨é¡ï¼æ¹æ³æ¯å°ä»ç´°æé¸çç¤ºç¯ç¯ä¾åµå¥è¼¸å¥æç¤ºä¸­ãéç¨®æ¹æ³é¿åäºå»£æ³ç¸éåå¾®èª¿çè¨ç®éé·ãç¶èï¼ç®åéå°åå­ä»»åçæç¤ºæª¢ç´¢æ¹æ³ä¾è³´æ¼åå­ç¹å¾µç¸ä¼¼æ§ï¼ä¾å¦ Morgan æç´ï¼èç¡æ³ååææå¨å±åå­ååå­éµçµéä¿ãå æ­¤ï¼éäºæ¹æ³ç¡æ³å¨æ¨çéç¨ä¸­è¡¨ç¤ºåå­çµæ§çå®æ´è¤éæ§ãæ­¤å¤ï¼å¨å°æ¥­ç³»çµ±ä¸­æä¾æ´ç°¡å®é¨ç½²éæ±çå°å°ä¸­åç LLMï¼å¨åå­ ICL æç»ä¸­ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéäºå·®è·ï¼æåæåºäºä¸ç¨®èªæç£ç£å­¸ç¿æè¡ï¼GAMICï¼åå½¢å°é½åå­æå¢å­¸ç¿ï¼ï¼å®å°ç±åå½¢ç¥ç¶ç¶²è·¯ (GNN) è¡¨ç¤ºçå¨å±åå­çµæ§èæå­æ¨é¡ï¼æè¿°ï¼å°é½ï¼åæéé Morgan æç´å©ç¨å±é¨ç¹å¾µç¸ä¼¼æ§ãæ­¤å¤ï¼æåå¨æª¢ç´¢éç¨ä¸­å¼å¥äºä¸ååºæ¼æå¤§ééç¸éæ§ (MMR) çå¤æ¨£æ§åç¼æ³ï¼ä»¥æä½³åè¼¸å¥æç¤ºç¤ºç¯æ¨£æ¬ãæåä½¿ç¨ä¸åçåºæºè³æéé²è¡çå¯¦é©çµæé¡¯ç¤ºï¼GAMIC å¨ææä»»åä¸­é½åªæ¼åºæ¼ Morgan çç°¡å® ICL æª¢ç´¢æ¹æ³ï¼æå¤å¯é 45%ã</paragraph>

##### **Knowledge Graph-Guided Retrieval Augmented Generation**
2502.06864v1 by Xiangrong Zhu, Yuexiang Xie, Yi Liu, Yaliang Li, Wei Hu

Retrieval-augmented generation (RAG) has emerged as a promising technology
for addressing hallucination issues in the responses generated by large
language models (LLMs). Existing studies on RAG primarily focus on applying
semantic-based approaches to retrieve isolated relevant chunks, which ignore
their intrinsic relationships. In this paper, we propose a novel Knowledge
Graph-Guided Retrieval Augmented Generation (KG$^2$RAG) framework that utilizes
knowledge graphs (KGs) to provide fact-level relationships between chunks,
improving the diversity and coherence of the retrieved results. Specifically,
after performing a semantic-based retrieval to provide seed chunks, KG$^2$RAG
employs a KG-guided chunk expansion process and a KG-based chunk organization
process to deliver relevant and important knowledge in well-organized
paragraphs. Extensive experiments conducted on the HotpotQA dataset and its
variants demonstrate the advantages of KG$^2$RAG compared to existing RAG-based
approaches, in terms of both response quality and retrieval quality.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²æçºä¸é æåéçæè¡ï¼ç¨æ¼è§£æ±ºå¤§åèªè¨æ¨¡å (LLM) æç¢çåæä¸­çå¹»è¦ºåé¡ãç¾æéæ¼ RAG çç ç©¶ä¸»è¦å°æ³¨æ¼æç¨åºæ¼èªç¾©çæ¹æ³ä¾æª¢ç´¢å­¤ç«ç¸éçåå¡ï¼èå¿½ç¥å®åçå§å¨éä¿ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çç¥è­åè¡¨å¼å°æª¢ç´¢å¢å¼·çæ (KG$^2$RAG) æ¡æ¶ï¼å®å©ç¨ç¥è­åè¡¨ (KG) ä¾æä¾åå¡ä¹éçäºå¯¦å±¤ç´éä¿ï¼å¾èæé«æª¢ç´¢çµæçå¤æ¨£æ§åä¸è´æ§ãå·é«ä¾èªªï¼å¨å·è¡åºæ¼èªç¾©çæª¢ç´¢ä»¥æä¾ç¨®å­åå¡å¾ï¼KG$^2$RAG æ¡ç¨ KG å¼å°çåå¡æ´åç¨åºååºæ¼ KG çåå¡çµç¹ç¨åºï¼ä»¥å¨çµç¹è¯å¥½çæ®µè½ä¸­å³éç¸éä¸éè¦çç¥è­ãå¨ HotpotQA è³æéåå¶è®é«ä¸é²è¡çå¤§éå¯¦é©è­æäº KG$^2$RAG å¨åæåè³ªåæª¢ç´¢åè³ªæ¹é¢åªæ¼ç¾æçåºæ¼ RAG çæ¹æ³ã

##### **Can Large Language Models Understand Intermediate Representations?**
2502.06854v1 by Hailong Jiang, Jianfeng Zhu, Yao Wan, Bo Fang, Hongyu Zhang, Ruoming Jin, Qiang Guan

Intermediate Representations (IRs) are essential in compiler design and
program analysis, yet their comprehension by Large Language Models (LLMs)
remains underexplored. This paper presents a pioneering empirical study to
investigate the capabilities of LLMs, including GPT-4, GPT-3, Gemma 2, LLaMA
3.1, and Code Llama, in understanding IRs. We analyze their performance across
four tasks: Control Flow Graph (CFG) reconstruction, decompilation, code
summarization, and execution reasoning. Our results indicate that while LLMs
demonstrate competence in parsing IR syntax and recognizing high-level
structures, they struggle with control flow reasoning, execution semantics, and
loop handling. Specifically, they often misinterpret branching instructions,
omit critical IR operations, and rely on heuristic-based reasoning, leading to
errors in CFG reconstruction, IR decompilation, and execution reasoning. The
study underscores the necessity for IR-specific enhancements in LLMs,
recommending fine-tuning on structured IR datasets and integration of explicit
control flow models to augment their comprehension and handling of IR-related
tasks.

æè¦ï¼ä¸­éè¡¨å¾µ (IR) å¨ç·¨è­¯å¨è¨­è¨åç¨å¼åæä¸­è³ééè¦ï¼ä½å¤§åèªè¨æ¨¡å (LLM) å°å¶çè§£ä»æªå¾å°ååæ¢è¨ãæ¬ææåºäºä¸é éåµæ§çå¯¦è­ç ç©¶ï¼ä»¥æ¢è¨ LLMï¼åæ¬ GPT-4ãGPT-3ãGemma 2ãLLaMA 3.1 å Code Llamaï¼çè§£ IR çè½åãæååæäºå®åå¨åé ä»»åä¸­çè¡¨ç¾ï¼æ§å¶æµç¨å (CFG) éå»ºãåç·¨è­¯ãç¨å¼ç¢¼æè¦åå·è¡æ¨çãæåççµæè¡¨æï¼åç®¡ LLM å¨è§£æ IR èªæ³åè­å¥é«éçµæ§æ¹é¢è¡¨ç¾åºè½åï¼ä½å®åå¨æ§å¶æµç¨æ¨çãå·è¡èªç¾©åè¿´åèçæ¹é¢å­å¨å°é£ãå·é«èè¨ï¼å®åç¶å¸¸èª¤è§£åæ¯æä»¤ãçç¥ééµ IR æä½ï¼ä¸¦ä¾è³´æ¼åºæ¼åç¼å¼çæ¨çï¼å°è´ CFG éå»ºãIR åç·¨è­¯åå·è¡æ¨çåºç¾é¯èª¤ãéé ç ç©¶å¼·èª¿äº LLM ä¸­å° IR ç¹å®çå¢å¼·çå¿è¦æ§ï¼å»ºè­°å°çµæ§åç IR è³æéé²è¡å¾®èª¿ï¼ä¸¦æ´åæç¢ºçæ§å¶æµç¨æ¨¡åï¼ä»¥å¢å¼·å¶å° IR ç¸éä»»åççè§£åèçã

##### **GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?**
2502.05252v1 by Yang Zhou, Hongyi Liu, Zhuoming Chen, Yuandong Tian, Beidi Chen

Long-context large language models (LLMs) have recently shown strong
performance in information retrieval and long-document QA. However, to tackle
the most challenging intellectual problems, LLMs must reason effectively in
long and complex contexts (e.g., frontier mathematical research). Studying how
LLMs handle increasing reasoning complexity and context length is essential,
yet existing benchmarks lack a solid basis for quantitative evaluation.
Inspired by the abstraction of GSM-8K problems as computational graphs, and the
ability to introduce noise by adding unnecessary nodes and edges, we develop a
grade school math problem generator capable of producing arithmetic problems
with infinite difficulty and context length under fine-grained control. Using
our newly synthesized GSM-Infinite benchmark, we comprehensively evaluate
existing LLMs. We find a consistent sigmoid decline in reasoning performance as
complexity increases, along with a systematic inference scaling trend:
exponentially increasing inference computation yields only linear performance
gains. These findings underscore the fundamental limitations of current
long-context LLMs and the key challenges in scaling reasoning capabilities. Our
GSM-Infinite benchmark provides a scalable and controllable testbed for
systematically studying and advancing LLM reasoning in long and complex
contexts.

æè¦ï¼é·ææ¬å¤§åèªè¨æ¨¡å (LLM) æè¿å¨è³è¨æª¢ç´¢åé·æä»¶åç­ä¸­å±ç¤ºäºå¼·å¤§çæè½ãç¶èï¼è¥è¦è§£æ±ºæå·ææ°æ§çæºååé¡ï¼LLM å¿é å¨é·ä¸è¤éçèçµ¡ä¸­æææ¨çï¼ä¾å¦ï¼åæ²¿æ¸å­¸ç ç©¶ï¼ãç ç©¶ LLM å¦ä½èçå¢å çæ¨çè¤éæ§åèçµ¡é·åº¦è³ééè¦ï¼ä½ç¾æçåºæºç¼ºä¹å®éè©ä¼°çç©©åºåºç¤ãåå° GSM-8K åé¡æ½è±¡åçºè¨ç®åå½¢çåç¼ï¼ä»¥åééå å¥ä¸å¿è¦çç¯é»åéç·£ä¾å¼å¥éè¨çè½åï¼æåéç¼äºä¸åå°å­¸æ¸å­¸åé¡ç¢çå¨ï¼è½å¤ å¨ç´°ç·»çæ§å¶ä¸ç¢çå·æç¡éé£åº¦åèçµ¡é·åº¦çç®è¡åé¡ãä½¿ç¨æåæ°åæç GSM-Infinite åºæºï¼æåå¨é¢è©ä¼°ç¾æç LLMãæåç¼ç¾æ¨çæè½æé¨èè¤éæ§çå¢å èæçºå S å½¢ä¸éï¼ä¸¦ä¼´é¨èç³»çµ±æ§çæ¨è«ç¸®æ¾è¶¨å¢ï¼ææ¸å¢å çæ¨è«è¨ç®åç¢çç·æ§çæè½å¢çãéäºç¼ç¾å¼·èª¿äºç¶åé·èçµ¡ LLM çåºæ¬éå¶ï¼ä»¥åæ´å±æ¨çè½åçä¸»è¦ææ°ãæåç GSM-Infinite åºæºæä¾äºä¸åå¯æ´åä¸å¯æ§çæ¸¬è©¦å¹³å°ï¼ç¨æ¼ç³»çµ±æ§å°ç ç©¶åæå LLM å¨é·ä¸è¤éèçµ¡ä¸­çæ¨çè½åã

##### **Causality can systematically address the monsters under the bench(marks)**
2502.05085v1 by Felix Leeb, Zhijing Jin, Bernhard SchÃ¶lkopf

Effective and reliable evaluation is essential for advancing empirical
machine learning. However, the increasing accessibility of generalist models
and the progress towards ever more complex, high-level tasks make systematic
evaluation more challenging. Benchmarks are plagued by various biases,
artifacts, or leakage, while models may behave unreliably due to poorly
explored failure modes. Haphazard treatments and inconsistent formulations of
such "monsters" can contribute to a duplication of efforts, a lack of trust in
results, and unsupported inferences. In this position paper, we argue causality
offers an ideal framework to systematically address these challenges. By making
causal assumptions in an approach explicit, we can faithfully model phenomena,
formulate testable hypotheses with explanatory power, and leverage principled
tools for analysis. To make causal model design more accessible, we identify
several useful Common Abstract Topologies (CATs) in causal graphs which help
gain insight into the reasoning abilities in large language models. Through a
series of case studies, we demonstrate how the precise yet pragmatic language
of causality clarifies the strengths and limitations of a method and inspires
new approaches for systematic progress.

æè¦ï¼ææçãå¯é çè©ä¼°å°æ¼æ¨é²ç¶é©æ©å¨å­¸ç¿è³ééè¦ãç¶èï¼ä¸è¬åæ¨¡åçå¯åæ§æ¥çæé«ï¼ä»¥åæèæ´è¤éãæ´é«ç´å¥ä»»åçé²å±ï¼ä½¿å¾ç³»çµ±è©ä¼°æ´å·ææ°æ§ãåºæºæ¸¬è©¦åå°åç¨®åå·®ãäººå·¥è£½åææ´©æ¼çå°æ¾ï¼èæ¨¡åç±æ¼æ¢ç´¢ä¸ååçæéæ¨¡å¼èå¯è½è¡¨ç¾å¾ä¸å¯é ãé¨æèçåä¸ä¸è´çè¡¨è¿°ç­ãæªç©ãå¯è½æå°è´éè¤å·¥ä½ãå°çµæç¼ºä¹ä¿¡ä»»ä»¥åä¸æ¯æ´çæ¨è«ãå¨æ¬æä¸­ï¼æåè«è­å æéä¿æä¾äºä¸åç³»çµ±æ§è§£æ±ºéäºææ°ççæ³æ¡æ¶ãééå¨æ¹æ³ä¸­æç¢ºå æåè¨­ï¼æåå¯ä»¥å¿ å¯¦å°æ¨¡æ¬ç¾è±¡ï¼å¶å®å·æè§£éåçå¯æ¸¬è©¦åè¨­ï¼ä¸¦å©ç¨ååæ§çåæå·¥å·ãçºäºä½¿å ææ¨¡åè¨­è¨æ´ææ¼ä½¿ç¨ï¼æåå¨å æåä¸­è­å¥åºå¹¾åæç¨çéç¨æ½è±¡ææ² (CAT)ï¼æå©æ¼æ·±å¥äºè§£å¤§åèªè¨æ¨¡åä¸­çæ¨çè½åãééä¸ç³»åæ¡ä¾ç ç©¶ï¼æåå±ç¤ºäºå æéä¿çç²¾ç¢ºä½åå¯¦çèªè¨å¦ä½éæ¸æ¹æ³çåªç¼ºé»ï¼ä¸¦æ¿ç¼ç³»çµ±é²å±çæ°æ¹æ³ã

##### **Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**
2502.05078v1 by Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha

Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities, yet their performance is highly dependent on the prompting
strategy and model scale. While reinforcement learning and fine-tuning have
been deployed to boost reasoning, these approaches incur substantial
computational and data overhead. In this work, we introduce Adaptive Graph of
Thoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM
reasoning solely at test time. Rather than relying on fixed-step methods like
Chain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes
complex queries into structured subproblems, forming an dynamic directed
acyclic graph (DAG) of interdependent reasoning steps. By selectively expanding
only those subproblems that require further analysis, AGoT unifies the
strengths of chain, tree, and graph paradigms into a cohesive framework that
allocates computation where it is most needed. We validate our approach on
diverse benchmarks spanning multi-hop retrieval, scientific reasoning, and
mathematical problem-solving, achieving up to 46.2% improvement on scientific
reasoning tasks (GPQA) - comparable to gains achieved through computationally
intensive reinforcement learning approaches and outperforming state-of-the-art
iterative approaches. These results suggest that dynamic decomposition and
structured recursion offer a scalable, cost-effective alternative to
post-training modifications, paving the way for more robust, general-purpose
reasoning in LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾ä»¤äººå°è±¡æ·±å»çæ¨çè½åï¼ä½å¶æè½é«åº¦ä¾è³´æ¼æç¤ºç­ç¥åæ¨¡åè¦æ¨¡ãéç¶å¼·åå­¸ç¿åå¾®èª¿å·²è¢«ç¨æ¼æåæ¨çï¼ä½éäºæ¹æ³æé æå¤§éçéç®åè³æéé·ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºãé©ææ§æèåã(AGoT)ï¼ä¸ååæçãåºæ¼åå½¢çæ¨è«æ¶æ§ï¼å®åå¨æ¸¬è©¦æå°±è½å¢å¼· LLM æ¨çãAGoT ä¸¦éä¾è³´æ¼éå¼æè (CoT) ææ¨¹çæè (ToT) ç­åºå®æ­¥é©æ¹æ³ï¼èæ¯éè¿´å°å°è¤éçæ¥è©¢åè§£æçµæ§åçå­åé¡ï¼å½¢æä¸åç±ç¸äºä¾è³´çæ¨çæ­¥é©æçµæçåææåç¡ç°å (DAG)ãééé¸ææ§å°åæ´åé£äºéè¦é²ä¸æ­¥åæçå­åé¡ï¼AGoT å°éå¼ãæ¨¹çååå½¢ç¯ä¾çåªå¢çµ±ä¸å°ä¸åç·å¯çæ¶æ§ä¸­ï¼å°éç®åéå°æéè¦çå°æ¹ãæåå¨è·¨è¶å¤éè·³èºæª¢ç´¢ãç§å­¸æ¨çåæ¸å­¸åé¡è§£æ±ºç­å¤æ¨£åºæºä¸é©è­äºæåçåæ³ï¼å¨ç§å­¸æ¨çä»»å (GPQA) ä¸éå°äºé«é 46.2% çæ¹é²ï¼éèéééç®å¯éçå¼·åå­¸ç¿æ¹æ³æç²å¾çå¢çç¸ç¶ï¼ä¸¦ä¸åªæ¼æåé²çè¿­ä»£æ¹æ³ãéäºçµæè¡¨æï¼åæåè§£åçµæ§åéè¿´æä¾äºä¸åå¯æ´åãå·ææ¬æççæ¿ä»£æ¹æ¡ï¼ç¨æ¼è¨ç·´å¾ä¿®æ¹ï¼çº LLM ä¸­æ´å¼·å¥ãæ´éç¨çæ¨çéªå¹³äºéè·¯ã

##### **Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics**
2502.05239v1 by Hussam Ghanem, Christophe Cruz

Recent advancements in large language models have demonstrated significant
potential in the automated construction of knowledge graphs from unstructured
text. This paper builds upon our previous work [16], which evaluated various
models using metrics like precision, recall, F1 score, triple matching, and
graph matching, and introduces a refined approach to address the critical
issues of hallucination and omission. We propose an enhanced evaluation
framework incorporating BERTScore for graph similarity, setting a practical
threshold of 95% for graph matching. Our experiments focus on the Mistral
model, comparing its original and fine-tuned versions in zero-shot and few-shot
settings. We further extend our experiments using examples from the KELM-sub
training dataset, illustrating that the fine-tuned model significantly improves
knowledge graph construction accuracy while reducing the exact hallucination
and omission. However, our findings also reveal that the fine-tuned models
perform worse in generalization tasks on the KELM-sub dataset. This study
underscores the importance of comprehensive evaluation metrics in advancing the
state-of-the-art in knowledge graph construction from textual data.

æè¦ï¼å¤§åèªè¨æ¨¡åçææ°é²å±å·²è­æå¨å¾éçµæ§åæå­èªåå»ºæ§ç¥è­åè­æ¹é¢å·æé¡¯èçæ½åãæ¬æå»ºç«å¨æåååçç ç©¶ [16] ä¹ä¸ï¼è©²ç ç©¶ä½¿ç¨æºç¢ºåº¦ãå¬åçãF1 åæ¸ãä¸åçµå¹éååå½¢å¹éç­ææ¨è©ä¼°åç¨®æ¨¡åï¼ä¸¦å¼å¥äºä¸ç¨®æ¹é²çæ¹æ³ä¾è§£æ±ºå¹»è¦ºåéºæ¼çééµåé¡ãæåæåºä¸åå¢å¼·çè©ä¼°æ¡æ¶ï¼çµå BERTScore ä¾é²è¡åå½¢ç¸ä¼¼æ§ï¼ä¸¦å°åå½¢å¹éçå¯¦éé¾å¼è¨­å®çº 95%ãæåçå¯¦é©éé»å¨ Mistral æ¨¡åä¸ï¼æ¯è¼å¶åå§çæ¬åå¾®èª¿çæ¬å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿çè¨­å®ä¸­ãæåé²ä¸æ­¥ä½¿ç¨ KELM-sub è¨ç·´è³æéä¸­çç¯ä¾ä¾æ´å±æåçå¯¦é©ï¼èªªæå¾®èª¿å¾çæ¨¡åé¡¯èæé«äºç¥è­åè­å»ºæ§çæºç¢ºåº¦ï¼åææ¸å°äºç²¾ç¢ºçå¹»è¦ºåéºæ¼ãç¶èï¼æåçç ç©¶çµæä¹é¡¯ç¤ºï¼å¾®èª¿å¾çæ¨¡åå¨ KELM-sub è³æéä¸çæ³åä»»åè¡¨ç¾è¼å·®ãéé ç ç©¶å¼·èª¿äºå¨é¢è©ä¼°ææ¨å¨æ¨é²å¾æå­è³æå»ºæ§ç¥è­åè­çææ°æè¡æ¹é¢çéè¦æ§ã

##### **Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**
2502.04644v1 by Junde Wu, Jiayuan Zhu, Yuyuan Liu

We introduce Agentic Reasoning, a framework that enhances large language
model (LLM) reasoning by integrating external tool-using agents. Unlike
conventional LLM-based reasoning approaches, which rely solely on internal
inference, Agentic Reasoning dynamically engages web search, code execution,
and structured reasoning-context memory to solve complex problems requiring
deep research and multi-step logical deduction. Our framework introduces the
Mind Map agent, which constructs a structured knowledge graph to track logical
relationships, improving deductive reasoning. Additionally, the integration of
web-search and coding agents enables real-time retrieval and computational
analysis, enhancing reasoning accuracy and decision-making. Evaluations on
PhD-level scientific reasoning (GPQA) and domain-specific deep research tasks
demonstrate that our approach significantly outperforms existing models,
including leading retrieval-augmented generation (RAG) systems and
closed-source LLMs. Moreover, our results indicate that agentic reasoning
improves expert-level knowledge synthesis, test-time scalability, and
structured problem-solving. The code is at:
https://github.com/theworldofagents/Agentic-Reasoning.

æè¦ï¼æåå¼å¥äºä»£çæ¨çï¼ä¸åééæ´åå¤é¨å·¥å·ä½¿ç¨ä»£çä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM) æ¨ççæ¡æ¶ãèåä¾è³´æ¼å§é¨æ¨è«çå³çµ±åºæ¼ LLM çæ¨çæ¹æ³ä¸åï¼ä»£çæ¨çåæå°éç¨ç¶²è·¯æå°ãç¨å¼ç¢¼å·è¡åçµæ§åæ¨çæå¢è¨æ¶ä¾è§£æ±ºéè¦æ·±å¥ç ç©¶åå¤æ­¥é©éè¼¯æ¨è«çè¤éåé¡ãæåçæ¡æ¶å¼å¥äºå¿æºåä»£çï¼å®å»ºç«ä¸åçµæ§åçç¥è­åè­ä¾è¿½è¹¤éè¼¯éä¿ï¼æ¹åæ¼ç¹¹æ¨çãæ­¤å¤ï¼æ´åç¶²è·¯æå°åç·¨ç¢¼ä»£çè½é²è¡å³ææ·ååéç®åæï¼å¢å¼·æ¨çæºç¢ºåº¦åæ±ºç­å¶å®ãå¨åå£«ç­ç´ç§å­¸æ¨ç (GPQA) åç¹å®é åçæ·±å¥ç ç©¶ä»»åä¸çè©ä¼°é¡¯ç¤ºï¼æåçåæ³æé¡¯åªæ¼ç¾ææ¨¡åï¼åæ¬é åçæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±åå°éåå§ç¢¼ LLMãæ­¤å¤ï¼æåççµæé¡¯ç¤ºï¼ä»£çæ¨çæ¹é²äºå°å®¶ç´ç¥è­ç¶åãæ¸¬è©¦æéå¯æ´åæ§åçµæ§ååé¡è§£æ±ºãç¨å¼ç¢¼å¨ï¼https://github.com/theworldofagents/Agentic-Reasoningã

##### **Position-aware Automatic Circuit Discovery**
2502.04577v1 by Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov

A widely used strategy to discover and understand language model mechanisms
is circuit analysis. A circuit is a minimal subgraph of a model's computation
graph that executes a specific task. We identify a gap in existing circuit
discovery methods: they assume circuits are position-invariant, treating model
components as equally relevant across input positions. This limits their
ability to capture cross-positional interactions or mechanisms that vary across
positions. To address this gap, we propose two improvements to incorporate
positionality into circuits, even on tasks containing variable-length examples.
First, we extend edge attribution patching, a gradient-based method for circuit
discovery, to differentiate between token positions. Second, we introduce the
concept of a dataset schema, which defines token spans with similar semantics
across examples, enabling position-aware circuit discovery in datasets with
variable length examples. We additionally develop an automated pipeline for
schema generation and application using large language models. Our approach
enables fully automated discovery of position-sensitive circuits, yielding
better trade-offs between circuit size and faithfulness compared to prior work.

æè¦ï¼å»£æ³ç¨æ¼ç¼ç¾åäºè§£èªè¨æ¨¡åæ©å¶çç­ç¥æ¯é»è·¯åæãé»è·¯æ¯æ¨¡åè¨ç®åçæå°å­åï¼å¯å·è¡ç¹å®ä»»åãæåæ¾åºé»è·¯ç¼ç¾æ¹æ³ä¸­çä¸åç¼ºå£ï¼å®ååè¨­é»è·¯èä½ç½®ç¡éï¼å°æ¨¡åçµä»¶è¦çºå¨è¼¸å¥ä½ç½®ä¸­åæ¨£ç¸éãééå¶äºå®åææè·¨ä½ç½®äºåæå¨ä¸åä½ç½®ä¸­è®åçæ©å¶çè½åãçºäºè§£æ±ºéåç¼ºå£ï¼æåæåºå©é æ¹é²ï¼å°ä½ç½®æ§ç´å¥é»è·¯ä¸­ï¼å³ä½¿å¨åå«è®é·ç¯ä¾çä»»åä¸­ä¹æ¯å¦æ­¤ãé¦åï¼æåæ´åéç·£å±¬æ§ä¿®è£ï¼ä¸ç¨®åºæ¼æ¢¯åº¦çé»è·¯ç¼ç¾æ¹æ³ï¼ä»¥ååç¬¦èä½ç½®ãå¶æ¬¡ï¼æåå¼å¥äºè³æéæ¶æ§çæ¦å¿µï¼å®å®ç¾©äºå¨ç¯ä¾ä¸­å·æé¡ä¼¼èªç¾©çç¬¦èè·¨è·ï¼ä½¿æåå¯ä»¥å¨å·æè®é·ç¯ä¾çè³æéä¸­é²è¡èä½ç½®ç¸éçé»è·¯ç¼ç¾ãæ­¤å¤ï¼æåéç¼äºä¸åèªååç®¡ç·ï¼ç¨æ¼ä½¿ç¨å¤§åèªè¨æ¨¡åé²è¡æ¶æ§çæåæç¨ãæåçåæ³è½è®ä½ç½®ææé»è·¯çç¼ç¾å®å¨èªååï¼èååçç ç©¶ç¸æ¯ï¼å¨é»è·¯å¤§å°åå¿ å¯¦åº¦ä¹éç¢çäºæ´å¥½çæ¬è¡¡ã

##### **Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**
2502.04510v1 by Shangbin Feng, Zifeng Wang, Palash Goyal, Yike Wang, Weijia Shi, Huang Xia, Hamid Palangi, Luke Zettlemoyer, Yulia Tsvetkov, Chen-Yu Lee, Tomas Pfister

We propose Heterogeneous Swarms, an algorithm to design multi-LLM systems by
jointly optimizing model roles and weights. We represent multi-LLM systems as
directed acyclic graphs (DAGs) of LLMs with topological message passing for
collaborative generation. Given a pool of LLM experts and a utility function,
Heterogeneous Swarms employs two iterative steps: role-step and weight-step.
For role-step, we interpret model roles as learning a DAG that specifies the
flow of inputs and outputs between LLMs. Starting from a swarm of random
continuous adjacency matrices, we decode them into discrete DAGs, call the LLMs
in topological order, evaluate on the utility function (e.g. accuracy on a
task), and optimize the adjacency matrices with particle swarm optimization
based on the utility score. For weight-step, we assess the contribution of
individual LLMs in the multi-LLM systems and optimize model weights with swarm
intelligence. We propose JFK-score to quantify the individual contribution of
each LLM in the best-found DAG of the role-step, then optimize model weights
with particle swarm optimization based on the JFK-score. Experiments
demonstrate that Heterogeneous Swarms outperforms 15 role- and/or weight-based
baselines by 18.5% on average across 12 tasks. Further analysis reveals that
Heterogeneous Swarms discovers multi-LLM systems with heterogeneous model roles
and substantial collaborative gains, and benefits from the diversity of
language models.

æè¦ï¼<paragraph>æåæåºç°è³ªç¾¤é«ï¼ä¸ç¨®æ¼ç®æ³ï¼ééå±åæä½³åæ¨¡åè§è²åæ¬éä¾è¨­è¨å¤ LLM ç³»çµ±ãæåå°å¤ LLM ç³»çµ±è¡¨ç¤ºçº LLM çæåéå¾ªç°å (DAG)ï¼ä¸¦ééææ²è¨æ¯å³éé²è¡åä½ç¢çãçµ¦å®ä¸çµ LLM å°å®¶åä¸åæç¨å½æ¸ï¼ç°è³ªç¾¤é«ä½¿ç¨å©ååè¦æ­¥é©ï¼è§è²æ­¥é©åæ¬éæ­¥é©ãå°æ¼è§è²æ­¥é©ï¼æåå°æ¨¡åè§è²è§£éçºå­¸ç¿ä¸å DAGï¼å®æå® LLM ä¹éè¼¸å¥åè¼¸åºçæµåãå¾ä¸çµé¨æ©é£çºé°æ¥ç©é£éå§ï¼æåå°å®åè§£ç¢¼çºé¢æ£ DAGï¼ä»¥ææ²é åºå¼å« LLMï¼æ ¹ææç¨å½æ¸ï¼ä¾å¦ä»»åçæºç¢ºåº¦ï¼é²è¡è©ä¼°ï¼ä¸¦æ ¹ææç¨åæ¸ä½¿ç¨ç²å­ç¾¤æä½³åæä½³åé°æ¥ç©é£ãå°æ¼æ¬éæ­¥é©ï¼æåè©ä¼°åå¥ LLM å¨å¤ LLM ç³»çµ±ä¸­çè²¢ç»ï¼ä¸¦ä½¿ç¨ç¾¤é«æºæ§æä½³åæ¨¡åæ¬éãæåæåº JFK åæ¸ä¾éåæ¯å LLM å¨è§è²æ­¥é©ä¸­æ¾å°çæä½³ DAG ä¸­çåå¥è²¢ç»ï¼ç¶å¾æ ¹æ JFK åæ¸ä½¿ç¨ç²å­ç¾¤æä½³åæä½³åæ¨¡åæ¬éãå¯¦é©è¡¨æï¼ç°è³ªç¾¤é«å¨ 12 é ä»»åä¸­å¹³åæ¯ 15 ååºæ¼è§è²å/ææ¬éçåºç·é«åº 18.5%ãé²ä¸æ­¥çåæè¡¨æï¼ç°è³ªç¾¤é«ç¼ç¾å·æç°è³ªæ¨¡åè§è²åå¤§éåä½æ¶ççå¤ LLM ç³»çµ±ï¼ä¸¦åçæ¼èªè¨æ¨¡åçå¤æ¨£æ§ã</paragraph>

##### **MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot**
2502.04413v1 by Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao

Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) æ¯ä¸ç¨®é©ç¨æ¼æª¢ç´¢é±ç§ææçé»å­å¥åº·è¨é (EHR) çæè¡ãå®å¯ä»¥ä½çºé«çä¿å¥å¯é§é§çä¸åééµæ¨¡çµï¼åå©æ¸å°é«çä¿å¥å¾æ¥­äººå¡åæ£èçèª¤è¨ºãç¶èï¼å¨é«çé åä¸­ä½¿ç¨çç¾æåºæ¼åç¼æ³ç RAG æ¨¡åçè¨ºæ·æºç¢ºæ§åç¹ç°æ§ä¸è¶³ï¼ç¹å¥æ¯å°æ¼å·æé¡ä¼¼è¡¨ç¾çç¾çãæ¬ææåº MedRAGï¼ä¸ç¨®ç±ç¥è­åè­ (KG) å¼ç¼çæ¨çå¢å¼·ç RAG æ¨¡åï¼ç¨æ¼é«çé åï¼å®æ ¹æè¡¨ç¾æª¢ç´¢è¨ºæ·åæ²»çå»ºè­°ãMedRAG ç³»çµ±æ§å°æ§å»ºäºä¸åå¨é¢çåå±¤éå±¤å¼è¨ºæ· KGï¼æ¶µèåç¨®ç¾ççééµè¨ºæ·å·®ç°ãéäºå·®ç°èå¾ EHR è³æåº«ä¸­æª¢ç´¢å°çé¡ä¼¼ EHR åææ´åï¼ä¸¦å¨å¤§åèªè¨æ¨¡åä¸­é²è¡æ¨çãéåéç¨å¯ä»¥å¯¦ç¾æ´æºç¢ºåå·é«çæ±ºç­æ¯æ´ï¼åæä¸»åæä¾å¾çºåé¡ï¼ä»¥å¢å¼·åäººåé«çæ±ºç­å¶å®ãMedRAG å¨å¬å±è³æé DDXPlus åå¾é³ç¯¤çé«é¢æ¶éçç§äººæ¢æ§ç¼çè¨ºæ·è³æé (CPDD) ä¸é²è¡è©ä¼°ï¼ä¸¦å°å¶æè½èåç¨®ç¾æ RAG æ¹æ³é²è¡æ¯è¼ãå¯¦é©çµæé¡¯ç¤ºï¼å©ç¨ KG çè³è¨æ´ååéä¿è½åï¼æåç MedRAG æä¾äºæ´å·é«çè¨ºæ·è¦è§£ï¼ä¸¦å¨éä½èª¤è¨ºçæ¹é¢åªæ¼æåé²çæ¨¡åãæåçç¨å¼ç¢¼å°å¨ https://github.com/SNOWTEAM2023/MedRAG æä¾

##### **Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering**
2502.03992v1 by Longquan Jiang, Junbo Huang, Cedric MÃ¶ller, Ricardo Usbeck

Most existing Knowledge Graph Question Answering (KGQA) approaches are
designed for a specific KG, such as Wikidata, DBpedia or Freebase. Due to the
heterogeneity of the underlying graph schema, topology and assertions, most
KGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) without
resource-intensive training data. We present OntoSCPrompt, a novel Large
Language Model (LLM)-based KGQA approach with a two-stage architecture that
separates semantic parsing from KG-dependent interactions. OntoSCPrompt first
generates a SPARQL query structure (including SPARQL keywords such as SELECT,
ASK, WHERE and placeholders for missing tokens) and then fills them with
KG-specific information. To enhance the understanding of the underlying KG, we
present an ontology-guided, hybrid prompt learning strategy that integrates KG
ontology into the learning process of hybrid prompts (e.g., discrete and
continuous vectors). We also present several task-specific decoding strategies
to ensure the correctness and executability of generated SPARQL queries in both
stages. Experimental results demonstrate that OntoSCPrompt performs as well as
SOTA approaches without retraining on a number of KGQA datasets such as CWQ,
WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize well
to unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

æè¦ï¼ç¾æçç¥è­åè­åç­ï¼KGQAï¼æ¹æ³å¤§å¤æ¯çºç¹å® KG èè¨­è¨çï¼ä¾å¦ WikidataãDBpedia æ Freebaseãç±æ¼åºå±¤åå½¢æ¨¡å¼ãææ²åæ·è¨çç°è³ªæ§ï¼å¤§å¤æ¸ KGQA ç³»çµ±ç¡æ³å¨æ²æè³æºå¯éåè¨ç·´è³æçææ³ä¸è½ç§»å°æªè¦éçç¥è­åè­ï¼KGï¼ãæåæåº OntoSCPromptï¼éæ¯ä¸ç¨®åºæ¼å¤§åèªè¨æ¨¡åï¼LLMï¼çæ°å KGQA æ¹æ³ï¼æ¡ç¨å©éæ®µæ¶æ§ï¼å°èªç¾©è§£æèä¾è³´ KG çäºååéãOntoSCPrompt é¦åçæ SPARQL æ¥è©¢çµæ§ï¼åæ¬ SPARQL ééµå­ï¼ä¾å¦ SELECTãASKãWHERE åç¼ºå¤±ä»¤ççä½ä½ç¬¦ï¼ï¼ç¶å¾ç¨ KG ç¹å®çè³è¨å¡«å¯«å®åãçºäºå¢å¼·å°åºå±¤ KG ççè§£ï¼æåæåºäºä¸ç¨®ç±æ¬ä½æå°çæ··åæç¤ºå­¸ç¿ç­ç¥ï¼å° KG æ¬ä½æ´åå°æ··åæç¤ºï¼ä¾å¦ï¼é¢æ£åé£çºåéï¼çå­¸ç¿éç¨ä¸­ãæåéæåºäºå¤ç¨®ç¹å®ä»»åçè§£ç¢¼ç­ç¥ï¼ä»¥ç¢ºä¿å¨å©åéæ®µä¸­çæç SPARQL æ¥è©¢çæ­£ç¢ºæ§åå¯å·è¡æ§ãå¯¦é©çµæè¡¨æï¼OntoSCPrompt å¨ CWQãWebQSP å LC-QuAD 1.0 ç­å¤å KGQA è³æéä¸å·è¡æï¼æè½è SOTA æ¹æ³ä¸æ¨£å¥½ï¼ä¸è³æºä½¿ç¨æçé«ï¼ä¸¦ä¸å¯ä»¥å¾å¥½å°æ¦æ¬å°æªè¦éçç¹å®é å KGï¼ä¾å¦ DBLP-QuAD å CoyPu KG Codeï¼
\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}

##### **Multimodal Medical Code Tokenizer**
2502.04397v2 by Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik

Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.

æè¦ï¼<paragraph>å¨æ£èçµå­å¥åº·è®°å½ (EHR) ä¸è®­ç»çåºç¡æ¨¡åéè¦å°å»å­¦æ°æ®æ è®°ä¸ºç¦»æ£è¯æ±é¡¹åºåãç°æçæ è®°å¨å° EHR ä¸­çå»å­¦ä»£ç è§ä¸ºå­¤ç«çææ¬æ è®°ãç¶èï¼æ¯ä¸ªå»å­¦ä»£ç é½ç±å¶ææ¬æè¿°ãå¨æ¬ä½å±æ¬¡ç»æä¸­çä½ç½®ä»¥åä¸å¶ä»ä»£ç çå³ç³»ï¼ä¾å¦ç¾çå±ç°åè¯ç©æ²»çå³èï¼æ¥å®ä¹ãå»å­¦è¯æ±è¡¨åå«è¶è¿ 600,000 ä¸ªä»£ç ï¼è¿äºä»£ç åå«ä¸´åºæ¨ççå³é®ä¿¡æ¯ãæä»¬å¼å¥äº MedTokï¼è¿æ¯ä¸ç§å¤æ¨¡æå»å­¦ä»£ç æ è®°å¨ï¼å®ä½¿ç¨ææ¬æè¿°åä»£ç çå³ç³»ä¸ä¸æãMedTok ä½¿ç¨è¯­è¨æ¨¡åç¼ç å¨å¤çææ¬ï¼å¹¶ä½¿ç¨å¾ç¼ç å¨å¯¹å³ç³»ç»æè¿è¡ç¼ç ãç¶åï¼å®å°è¿ä¸¤ç§æ¨¡æéåä¸ºä¸ä¸ªç»ä¸çæ è®°ç©ºé´ï¼ä¿çç¹å®äºæ¨¡æåè·¨æ¨¡æçä¿¡æ¯ãæä»¬å° MedTok éæå°äºä¸ª EHR æ¨¡åä¸­ï¼å¹¶å¨ä½é¢åé¨è¯æ°æ®éï¼åæ¬ç»æé¢æµãè¯æ­åç±»ãè¯ç©æ¨èåé£é©åå±ï¼ä¸å¯¹å¶å®æ½æä½åä¸´åºä»»å¡è¿è¡è¯ä¼°ãç¨ MedTok æ¿æ¢æ å EHR æ è®°å¨å¯æé«ææ EHR æ¨¡åç AUPRCï¼å¨ MIMIC-III ä¸æé« 4.10%ï¼å¨ MIMIC-IV ä¸æé« 4.78%ï¼å¨ EHRShot ä¸æé« 11.30%ï¼å¶ä¸­è¯ç©æ¨èçå¢çæå¤§ãé¤äº EHR å»ºæ¨¡ä¹å¤ï¼æä»¬è¿æ¼ç¤ºäºå° MedTok æ è®°å¨ä¸å»å­¦é®ç­ç³»ç»ç»åä½¿ç¨ãæä»¬çç»æè¯æäº MedTok ä½ä¸ºå»å­¦ä»£ç çç»ä¸æ è®°å¨çæ½åï¼æ¹è¿äºå»å­¦åºç¡æ¨¡åçæ è®°åã</paragraph>

##### **Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents**
2502.04392v1 by Chenyang Shao, Xinyuan Hu, Yutang Lin, Fengli Xu

The rapid expansion of web content has made on-device AI assistants
indispensable for helping users manage the increasing complexity of online
tasks. The emergent reasoning ability in large language models offer a
promising path for next-generation on-device AI agents. However, deploying
full-scale Large Language Models (LLMs) on resource-limited local devices is
challenging. In this paper, we propose Division-of-Thoughts (DoT), a
collaborative reasoning framework leveraging the synergy between locally
deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT
leverages a Task Decomposer to elicit the inherent planning abilities in
language models to decompose user queries into smaller sub-tasks, which allows
hybrid language models to fully exploit their respective strengths. Besides,
DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks
and create a dependency graph, facilitating parallel reasoning of sub-tasks and
the identification of key steps. To allocate the appropriate model based on the
difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an
additional task head attached to the SLM that does not alter the SLM's
parameters. To boost adapter's task allocation capability, we propose a
self-reinforced training method that relies solely on task execution feedback.
Extensive experiments on various benchmarks demonstrate that our DoT
significantly reduces LLM costs while maintaining competitive reasoning
accuracy. Specifically, DoT reduces the average reasoning time and API costs by
66.12% and 83.57%, while achieving comparable reasoning accuracy with the best
baseline methods.

æè¦ï¼<paragraph>ç¶²é å§å®¹å¿«éæ´åï¼ä½¿å¾è¡åè£ç½®ä¸ç AI å©çå¨åå©ä½¿ç¨èç®¡çæ¥çè¤éçç·ä¸å·¥ä½ä¸è®å¾ä¸å¯æç¼ºãå¤§åèªè¨æ¨¡åä¸­æµ®ç¾çæ¨çè½åçºæ°ä¸ä»£è¡åè£ç½®ä¸ç AI ä»£çæä¾äºä¸æ¢æå¸æçéå¾ãç¶èï¼å¨è³æºæéçæ¬æ©è£ç½®ä¸é¨ç½²å¨è¦æ¨¡çå¤§åèªè¨æ¨¡å (LLM) æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåæåºäºææ³åå·¥ (DoT)ï¼ä¸ååä½æ¨çæ¡æ¶ï¼å©ç¨äºæ¬å°é¨ç½²çå°åèªè¨æ¨¡å (SLM) èé²ç«¯ LLM ä¹éçååææãDoT å©ç¨ä»»ååè§£å¨å¼åºèªè¨æ¨¡åä¸­åºæçè¦åè½åï¼å°ä½¿ç¨èæ¥è©¢åè§£æè¼å°çå­ä»»åï¼éåè¨±æ··åèªè¨æ¨¡åååç¼æ®å¶åèªçåªå¢ãæ­¤å¤ï¼DoT éç¨äºä¸åä»»åæç¨å¨ä¾åæå­ä»»åçæå°ä¾è³´æ§ä¸¦å»ºç«ä¸åä¾è³´æ§åï¼ä¿é²å­ä»»åçä¸¦è¡æ¨çåééµæ­¥é©çè­å¥ãçºäºæ ¹æå­ä»»åçé£åº¦åéé©ç¶çæ¨¡åï¼DoT å©ç¨äºå³æå³ç¨é©éå¨ï¼éæ¯ä¸åéå å¨ SLM ä¸çä»»åé ­ï¼ä¸ææ¹è® SLM çåæ¸ãçºäºæåé©éå¨çä»»ååéè½åï¼æåæåºäºä¸ç¨®èªæå¼·åè¨ç·´æ¹æ³ï¼å®åä¾è³´æ¼ä»»åå·è¡åé¥ãå¨åç¨®åºæºä¸çå»£æ³å¯¦é©è¡¨æï¼æåç DoT å¤§å¹éä½äº LLM ææ¬ï¼åæç¶­æäºæç«¶ç­åçæ¨çæºç¢ºåº¦ãå·é«ä¾èªªï¼DoT å°å¹³åæ¨çæéå API ææ¬åå¥éä½äº 66.12% å 83.57%ï¼åæéå°äºèæä½³åºæºæ¹æ³ç¸ç¶çæ¨çæºç¢ºåº¦ã</paragraph>

##### **Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models**
2502.03715v1 by Rui Cai, Chao Wang, Qianyi Cai, Dazhong Shen, Hui Xiong

Knowledge Graph-based recommendations have gained significant attention due
to their ability to leverage rich semantic relationships. However, constructing
and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy
of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent
advancements in Large Language Models (LLMs) offer a promising way to improve
the quality and relevance of KGs for recommendation tasks. Despite this,
integrating LLMs into KG-based systems presents challenges, such as efficiently
augmenting KGs, addressing hallucinations, and developing effective joint
learning methods. In this paper, we propose the Confidence-aware KG-based
Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework
that combines KGs and LLMs for recommendation task. The framework includes: (1)
an LLM-based subgraph augmenter for enriching KGs with high-quality
information, (2) a confidence-aware message propagation mechanism to filter
noisy triplets, and (3) a dual-view contrastive learning method to integrate
user-item interactions and KG data. Additionally, we employ a confidence-aware
explanation generation process to guide LLMs in producing realistic
explanations for recommendations. Finally, extensive experiments demonstrate
the effectiveness of CKG-LLMA across multiple public datasets.

æè¦ï¼åºæ¼ç¥è­åè­çæ¨è¦å å¶å©ç¨è±å¯èªç¾©éä¿çè½åèååéæ³¨ãç¶èï¼æ§å»ºåç¶­è­·ç¥è­åè­ (KG) æ¯ä¸é è³æºå¯éåä»»åï¼è KG çæºç¢ºæ§å¯è½æåå°éè¨ãéææç¡éçä¸åçµçå½±é¿ãå¤§åèªè¨æ¨¡å (LLM) çææ°é²å±çºæé« KG å¨æ¨è¦ä»»åä¸­çåè³ªåç¸éæ§æä¾äºä¸ç¨®æåéçæ¹æ³ãåç®¡å¦æ­¤ï¼å° LLM æ´åå°åºæ¼ KG çç³»çµ±ä¸­æå¸¶ä¾ææ°ï¼ä¾å¦æææ´å KGãèçå¹»è¦ºï¼ä»¥åéç¼ææçè¯åå­¸ç¿æ¹æ³ãå¨æ¬æä¸­ï¼æåæåºå·æ LLM æ´åçä¿¡å¿æç¥ååºæ¼ KG çæ¨è¦æ¡æ¶ (CKG-LLMA)ï¼éæ¯ä¸åçµå KG å LLM é²è¡æ¨è¦ä»»åçæ°ç©æ¡æ¶ãè©²æ¡æ¶åæ¬ï¼(1) ä¸ååºæ¼ LLM çå­åæ´åå¨ï¼ç¨æ¼ä½¿ç¨é«åè³ªè³è¨è±å¯ KGï¼(2) ä¸åä¿¡å¿æç¥åè¨æ¯å³æ­æ©å¶ï¼ç¨æ¼éæ¿¾éè¨ä¸åçµï¼ä»¥å (3) ä¸åéè¦åå°æ¯å­¸ç¿æ¹æ³ï¼ç¨æ¼æ´åä½¿ç¨è-é ç®äºåå KG è³æãæ­¤å¤ï¼æåæ¡ç¨ä¸åä¿¡å¿æç¥åè§£éç¢çç¨åºï¼ä»¥å¼å° LLM çºæ¨è¦ç¢çé¼ççè§£éãæå¾ï¼å¤§éçå¯¦é©è­æäº CKG-LLMA å¨å¤åå¬éè³æéä¸­çæææ§ã

##### **A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)**
2502.03450v1 by Yiye Chen, Harpreet Sawhney, Nicholas GydÃ©, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell

Scene graphs have emerged as a structured and serializable environment
representation for grounded spatial reasoning with Large Language Models
(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reason
framework for reasoning and planning with scene graphs. Our approach employs
two cooperative, code-writing LLM agents: a (1) Reasoner for task planning and
information queries generation, and a (2) Retriever for extracting
corresponding graph information following the queries. Two agents collaborate
iteratively, enabling sequential reasoning and adaptive attention to graph
information. Unlike prior works, both agents are prompted only with the scene
graph schema rather than the full graph data, which reduces the hallucination
by limiting input tokens, and drives the Reasoner to generate reasoning trace
abstractly.Following the trace, the Retriever programmatically query the scene
graph data based on the schema understanding, allowing dynamic and global
attention on the graph that enhances alignment between reasoning and retrieval.
Through experiments in multiple simulation environments, we show that our
framework surpasses existing LLM-based approaches in numerical Q\&A and
planning tasks, and can benefit from task-level few-shot examples, even in the
absence of agent-level demonstrations. Project code will be released.

æè¦ï¼å ´æ¯åè¡¨å·²æçºå¤§åèªè¨æ¨¡å (LLM) ä»¥åºç¤ç©ºéæ¨ççºåºç¤ççµæ§åä¸å¯åºååçç°å¢è¡¨å¾µãå¨éé å·¥ä½ä¸­ï¼æåæåº SG-RwRï¼ä¸åä»¥ç¶±è¦çºå°åçæª¢ç´¢èæ¨çæ¡æ¶ï¼ç¨æ¼å ´æ¯åè¡¨çæ¨çåè¦åãæåçåæ³æ¡ç¨äºå©ååä½çãç·¨å¯«ç¨å¼ç¢¼ç LLM ä»£çï¼ä¸å (1) æ¨è«å¨ï¼ç¨æ¼ä»»åè¦ååè³è¨æ¥è©¢ç¢çï¼ä»¥åä¸å (2) æª¢ç´¢å¨ï¼ç¨æ¼æ ¹ææ¥è©¢æåå°æçåå½¢è³è¨ãå©åä»£çåè¦åä½ï¼å¯¦ç¾å°åå½¢è³è¨çé åºæ¨çåé©ææ§éæ³¨ãèååçä½åä¸åï¼å©åä»£çåæç¤ºå ´æ¯åè¡¨ç¶±è¦ï¼èä¸æ¯å®æ´çåå½¢è³æï¼ééééå¶è¼¸å¥ä»£ç¢¼æ¸å°äºå¹»è¦ºï¼ä¸¦é©ä½¿æ¨è«å¨æ½è±¡å°ç¢çæ¨çè»è·¡ãæ ¹æè»è·¡ï¼æª¢ç´¢å¨æ ¹æç¶±è¦çè§£ä»¥ç¨å¼åæ¹å¼æ¥è©¢å ´æ¯åå½¢è³æï¼åè¨±å°åå½¢é²è¡åæåæ´é«éæ³¨ï¼å¢å¼·æ¨çåæª¢ç´¢ä¹éçä¸è´æ§ãééå¨å¤åæ¨¡æ¬ç°å¢ä¸­çå¯¦é©ï¼æåè¡¨ææåçæ¡æ¶å¨æ¸å¼åç­åè¦åä»»åä¸­è¶è¶äºç¾æçåºæ¼ LLM çæ¹æ³ï¼ä¸¦ä¸å¯ä»¥åçæ¼ä»»åç´å¥çå°æ¬¡ç¯ä¾ï¼å³ä½¿å¨æ²æä»£çç´å¥ç¤ºç¯çææ³ä¸ä¹æ¯å¦æ­¤ãå°æ¡ç¨å¼ç¢¼å°æéåºã

##### **SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs**
2502.03283v2 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng, Wotao Yin

Recent advancements have highlighted that Large Language Models (LLMs) are
prone to hallucinations when solving complex reasoning problems, leading to
erroneous results. To tackle this issue, researchers incorporate Knowledge
Graphs (KGs) to improve the reasoning ability of LLMs. However, existing
methods face two limitations: 1) they typically assume that all answers to the
questions are contained in KGs, neglecting the incompleteness issue of KGs, and
2) they treat the KG as a static repository and overlook the implicit logical
reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an
innovative neural-symbolic agent framework that achieves collaborative
augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments
and transform complex reasoning tasks into a multi-step interactive process,
enabling KGs to participate deeply in the reasoning process. SymAgent consists
of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages
LLM's inductive reasoning capability to extract symbolic rules from KGs,
guiding efficient question decomposition. The Agent-Executor autonomously
invokes predefined action tools to integrate information from KGs and external
documents, addressing the issues of KG incompleteness. Furthermore, we design a
self-learning framework comprising online exploration and offline iterative
policy updating phases, enabling the agent to automatically synthesize
reasoning trajectories and improve performance. Experimental results
demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields
better or comparable performance compared to various strong baselines. Further
analysis reveals that our agent can identify missing triples, facilitating
automatic KG updates.

æè¦ï¼<paragraph>æè¿çé²å±å¼·èª¿åºï¼å¤§åèªè¨æ¨¡å (LLM) å¨è§£æ±ºè¤éæ¨çåé¡æå®¹æåºç¾å¹»è¦ºï¼å°è´é¯èª¤ççµæãçºäºè§£æ±ºéååé¡ï¼ç ç©¶äººå¡çµåç¥è­åè­ (KG) ä¾æ¹å LLM çæ¨çè½åãç¶èï¼ç¾ææ¹æ³é¢è¨å©åéå¶ï¼1) å®åéå¸¸åè¨­åé¡çææç­æ¡é½åå«å¨ KG ä¸­ï¼å¿½ç¥äº KG çä¸å®æ´æ§åé¡ï¼ä»¥å 2) å®åå° KG è¦çºä¸åéæå²å­åº«ï¼èå¿½ç¥äº KG ä¸­åºæçé±å¼éè¼¯æ¨ççµæ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº SymAgentï¼ä¸ååµæ°çç¥ç¶ç¬¦èä»£çæ¶æ§ï¼å®å¨ KG å LLM ä¹éå¯¦ç¾äºåä½æ´åãæåå° KG æ¦å¿µåçºåæç°å¢ï¼ä¸¦å°è¤éçæ¨çä»»åè½åçºä¸åå¤æ­¥é©çäºåéç¨ï¼ä½¿ KG è½å¤ æ·±å¥åèæ¨çéç¨ãSymAgent åå«å©åæ¨¡çµï¼ä»£çè¦åå¨åä»£çå·è¡å¨ãä»£çè¦åå¨å©ç¨ LLM çæ­¸ç´æ¨çè½åå¾ KG ä¸­æåç¬¦èè¦åï¼æå°ææçåé¡åè§£ãä»£çå·è¡å¨èªä¸»å°èª¿ç¨é å®ç¾©çåä½å·¥å·ä¾æ´åä¾èª KG åå¤é¨æä»¶çè³è¨ï¼è§£æ±º KG ä¸å®æ´æ§çåé¡ãæ­¤å¤ï¼æåè¨­è¨äºä¸åèªå­¸ç¿æ¡æ¶ï¼åæ¬ç·ä¸æ¢ç´¢åé¢ç·åè¦çæ¿ç­æ´æ°éæ®µï¼ä½¿ä»£çè½å¤ èªååææ¨çè»è·¡ä¸¦æ¹åæè½ãå¯¦é©çµæè¡¨æï¼å·æå¼± LLM ä¸»å¹¹ç SymAgentï¼ä¾å¦ï¼7B ç³»åï¼èåç¨®å¼·å¤§çåºç·ç¸æ¯ï¼ç¢çäºæ´å¥½æç¸ç¶çæè½ãé²ä¸æ­¥çåæè¡¨æï¼æåçä»£çå¯ä»¥è­å¥éºå¤±çä¸åçµï¼ä¿é²èªå KG æ´æ°ã</paragraph>

##### **Analyze Feature Flow to Enhance Interpretation and Steering in Language Models**
2502.03032v2 by Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov

We introduce a new approach to systematically map features discovered by
sparse autoencoder across consecutive layers of large language models,
extending earlier work that examined inter-layer feature links. By using a
data-free cosine similarity technique, we trace how specific features persist,
transform, or first appear at each stage. This method yields granular flow
graphs of feature evolution, enabling fine-grained interpretability and
mechanistic insights into model computations. Crucially, we demonstrate how
these cross-layer feature maps facilitate direct steering of model behavior by
amplifying or suppressing chosen features, achieving targeted thematic control
in text generation. Together, our findings highlight the utility of a causal,
cross-layer interpretability framework that not only clarifies how features
develop through forward passes but also provides new means for transparent
manipulation of large language models.

æè¦ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼ç¨æ¼ç³»çµ±æ§å°ç¹ªè£½å¤§åèªè¨æ¨¡åé£çºå±¤ä¸­ç¨çèªåç·¨ç¢¼å¨ç¼ç¾çåè½ï¼æ´å±äºååç ç©¶å±¤éç¹å¾µé£çµçå·¥ä½ãééä½¿ç¨ç¡è³æé¤å¼¦ç¸ä¼¼æ§æè¡ï¼æåè¿½è¹¤ç¹å®ç¹å¾µå¨æ¯åéæ®µå¦ä½æçºãè½ææé¦æ¬¡åºç¾ãæ­¤æ¹æ³ç¢çäºç¹å¾µæ¼åçç´°ç²åº¦æµç¨åï¼å¯¦ç¾äºç´°ç²åº¦çå¯è§£éæ§åå°æ¨¡åéç®çæ©å¶è¦è§£ãè³ééè¦çæ¯ï¼æåå±ç¤ºäºéäºè·¨å±¤ç¹å¾µåå¦ä½ééæ¾å¤§ææå¶æé¸ç¹å¾µä¾ä¿é²æ¨¡åè¡çºçç´æ¥å¼å°ï¼å¨æå­çæä¸­å¯¦ç¾ç®æ¨ä¸»é¡æ§å¶ãæåçç ç©¶çµæå±åçªåºäºå æãè·¨å±¤å¯è§£éæ§æ¡æ¶çæç¨ï¼ä¸åé¡æäºç¹å¾µå¦ä½ééååå³éç¼å±ï¼éæä¾äºæ°çæ¹æ³ä¾éæå°æä½å¤§åèªè¨æ¨¡åã

##### **A Benchmark for the Detection of Metalinguistic Disagreements between LLMs and Knowledge Graphs**
2502.02896v1 by Bradley P. Allen, Paul T. Groth

Evaluating large language models (LLMs) for tasks like fact extraction in
support of knowledge graph construction frequently involves computing accuracy
metrics using a ground truth benchmark based on a knowledge graph (KG). These
evaluations assume that errors represent factual disagreements. However, human
discourse frequently features metalinguistic disagreement, where agents differ
not on facts but on the meaning of the language used to express them. Given the
complexity of natural language processing and generation using LLMs, we ask: do
metalinguistic disagreements occur between LLMs and KGs? Based on an
investigation using the T-REx knowledge alignment dataset, we hypothesize that
metalinguistic disagreement does in fact occur between LLMs and KGs, with
potential relevance for the practice of knowledge graph engineering. We propose
a benchmark for evaluating the detection of factual and metalinguistic
disagreements between LLMs and KGs. An initial proof of concept of such a
benchmark is available on Github.

æè¦ï¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) å·è¡ç¥è­åè­å»ºæ§æ¯æ´äºå¯¦èåç­ä»»åæï¼éå¸¸æä½¿ç¨åºæ¼ç¥è­åè­ (KG) çåºæºäºå¯¦è¨ç®æºç¢ºåº¦ææ¨ãéäºè©ä¼°åè¨­é¯èª¤ä»£è¡¨äºå¯¦ä¸çåæ­§ãç¶èï¼äººé¡è©±èªç¶å¸¸åºç¾åèªè¨åæ­§ï¼å¶ä¸­ä»£çäººä¹éçå·®ç°ä¸å¨æ¼äºå¯¦ï¼èå¨æ¼ç¨æ¼è¡¨éäºå¯¦çèªè¨çå«ç¾©ãéæ¼ä½¿ç¨ LLM èçåç¢çèªç¶èªè¨çè¤éæ§ï¼æåæåºçåï¼LLM å KG ä¹éæ¯å¦æç¼çåèªè¨åæ­§ï¼æ ¹æä½¿ç¨ T-REx ç¥è­æ¯å°è³æéé²è¡çèª¿æ¥ï¼æååè¨­åèªè¨åæ­§ç¢ºå¯¦æç¼çå¨ LLM å KG ä¹éï¼ä¸¦å¯è½èç¥è­åè­å·¥ç¨å¯¦åæéãæåæåºä¸ååºæºï¼ç¨æ¼è©ä¼° LLM å KG ä¹éçäºå¯¦ååèªè¨åæ­§çåµæ¸¬ãæ­¤åºæºçåæ­¥æ¦å¿µé©è­å¯å¨ Github ä¸åå¾ã

##### **Mol-LLM: Generalist Molecular LLM with Improved Graph Utilization**
2502.02810v1 by Chanhui Lee, Yuheon Song, YongJun Jeong, Hanbum Ko, Rodrigo Hormazabal, Sehui Han, Kyunghoon Bae, Sungbin Lim, Sungwoong Kim

Recent advances in Large Language Models (LLMs) have motivated the
development of general LLMs for molecular tasks. While several studies have
demonstrated that fine-tuned LLMs can achieve impressive benchmark
performances, they are far from genuine generalist molecular LLMs due to a lack
of fundamental understanding of molecular structure. Specifically, when given
molecular task instructions, LLMs trained with naive next-token prediction
training assign similar likelihood scores to both original and negatively
corrupted molecules, revealing their lack of molecular structure understanding
that is crucial for reliable and general molecular LLMs. To overcome this
limitation and obtain a true generalist molecular LLM, we introduce a novel
multi-modal training method based on a thorough multi-modal instruction tuning
as well as a molecular structure preference optimization between chosen and
rejected graphs. On various molecular benchmarks, the proposed generalist
molecular LLM, called Mol-LLM, achieves state-of-the-art performances among
generalist LLMs on most tasks, at the same time, surpassing or comparable to
state-of-the-art specialist LLMs. Moreover, Mol-LLM also shows superior
generalization performances in reaction prediction tasks, demonstrating the
effect of the molecular structure understanding for generalization perspective.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çè¿æé²å±æ¿åµäºéå°åå­ä»»åéç¼éç¨ LLMãéç¶å¤é ç ç©¶å·²è­æå¾®èª¿ LLM å¯å¯¦ç¾ä»¤äººå°è±¡æ·±å»çåºæºæè½ï¼ä½ç±æ¼ç¼ºä¹å°åå­çµæ§çåºæ¬çè§£ï¼å®åé éçæ­£çéæåå­ LLMãå·é«ä¾èªªï¼ç¶çµ¦äºåå­ä»»åèªªææï¼ä½¿ç¨å¤©ççä¸ä¸åç¬¦èé æ¸¬è¨ç·´è¨ç·´ç LLM æå°é¡ä¼¼çå¯è½æ§è©ååéçµ¦åå§åå­åè² é¢æå£åå­ï¼éé¡¯ç¤ºåºå®åç¼ºä¹å°åå­çµæ§ççè§£ï¼èéå°æ¼å¯é ä¸éç¨çåå­ LLM è³ééè¦ãçºäºåæéåéå¶ä¸¦ç²å¾çæ­£çéæåå­ LLMï¼æåå¼å¥äºä¸ç¨®æ°ç©çå¤æ¨¡æè¨ç·´æ¹æ³ï¼è©²æ¹æ³åºæ¼å¾¹åºçå¤æ¨¡æèªªæèª¿æ´ä»¥åå¨æé¸åæçµåå½¢ä¹éçåå­çµæ§åå¥½æä½³åãå¨åç¨®åå­åºæºæ¸¬è©¦ä¸­ï¼ææåºçéæåå­ LLMï¼ç¨±çº Mol-LLMï¼å¨å¤æ¸ä»»åä¸­å¯¦ç¾äºéæ LLM ä¸­çææ°æè½ï¼åæè¶è¶æèææ°çå°å®¶ LLM ç¸ç¶ãæ­¤å¤ï¼Mol-LLM å¨åæé æ¸¬ä»»åä¸­ä¹å±ç¾åºåªç°çæ³åæè½ï¼è­æäºåå­çµæ§çè§£å°æ³åè§é»çå½±é¿ã

##### **Leveraging the true depth of LLMs**
2502.02790v1 by RamÃ³n Calvo GonzÃ¡lez, Daniele Paliotta, Matteo Pagliardini, Martin Jaggi, FranÃ§ois Fleuret

Large Language Models demonstrate remarkable capabilities at the cost of high
compute requirements. While recent research has shown that intermediate layers
can be removed or have their order shuffled without impacting performance
significantly, these findings have not been employed to reduce the
computational cost of inference. We investigate several potential ways to
reduce the depth of pre-trained LLMs without significantly affecting
performance. Leveraging our insights, we present a novel approach that exploits
this decoupling between layers by grouping some of them into pairs that can be
evaluated in parallel.
  This modification of the computational graph -- through better parallelism --
results in an average improvement of around 1.20x on the number of tokens
generated per second, without re-training nor fine-tuning, while retaining
95%-99% of the original accuracy. Empirical evaluation demonstrates that this
approach significantly improves serving efficiency while maintaining model
performance, offering a practical improvement for large-scale LLM deployment.

æè¦ï¼å¤§åè¯­è¨æ¨¡åå±ç¤ºäºå¶å¼ºå¤§çåè½ï¼ä½ä»£ä»·æ¯è¾é«çè®¡ç®éæ±ãè½ç¶æè¿çç ç©¶è¡¨æï¼ä¸­é´å±å¯ä»¥è¢«ç§»é¤æéæ°æåå¶é¡ºåºï¼èä¸ä¼æ¾èå½±åæ§è½ï¼ä½è¿äºåç°å°æªè¢«ç¨æ¥éä½æ¨ççè®¡ç®ææ¬ãæä»¬ç ç©¶äºå ç§æ½å¨çæ¹æ³æ¥åå°é¢è®­ç» LLM çæ·±åº¦ï¼èä¸ä¼æ¾èå½±åæ§è½ãå©ç¨æä»¬çè§è§£ï¼æä»¬æåºäºä¸ç§æ°é¢çæ¹æ³ï¼è¯¥æ¹æ³éè¿å°å¶ä¸­ä¸äºåç»ä¸ºå¯ä»¥å¹¶è¡è¯ä¼°çæå¯¹æ¥å©ç¨å±ä¹é´çè¿ç§è§£è¦ã
éè¿æ´å¥½çå¹¶è¡æ§å¯¹è®¡ç®å¾è¿è¡ä¿®æ¹ï¼å¹³åèè¨ï¼æ¯ç§çæçä»¤çæ°éæé«äºçº¦ 1.20 åï¼èæ ééæ°è®­ç»æå¾®è°ï¼åæ¶ä¿çäº 95%-99% çåå§åç¡®æ§ãç»éªè¯ä¼°è¡¨æï¼è¿ç§æ¹æ³æ¾èæé«äºæå¡æçï¼åæ¶ä¿æäºæ¨¡åæ§è½ï¼ä¸ºå¤§è§æ¨¡ LLM é¨ç½²æä¾äºå®éæ¹è¿ã

##### **Modular Training of Neural Networks aids Interpretability**
2502.02470v2 by Satvik Golechha, Maheep Chaudhary, Joan Velja, Alessandro Abate, Nandi Schoots

An approach to improve neural network interpretability is via clusterability,
i.e., splitting a model into disjoint clusters that can be studied
independently. We define a measure for clusterability and show that pre-trained
models form highly enmeshed clusters via spectral graph clustering. We thus
train models to be more modular using a "clusterability loss" function that
encourages the formation of non-interacting clusters. Using automated
interpretability techniques, we show that our method can help train models that
are more modular and learn different, disjoint, and smaller circuits. We
investigate CNNs trained on MNIST and CIFAR, small transformers trained on
modular addition, and language models. Our approach provides a promising
direction for training neural networks that learn simpler functions and are
easier to interpret.

æè¦ï¼ä¸ç¨®æ¹åç¥ç¶ç¶²è·¯å¯è§£éæ§çæ¹æ³æ¯ééç¾¤éæ§ï¼
ä¹å°±æ¯å°æ¨¡ååå²æå¯ç¨ç«ç ç©¶çä¸ç¸äº¤ç¾¤éãæåå®ç¾©ä¸åç¾¤éæ§çåº¦éï¼ä¸¦é¡¯ç¤ºé è¨ç·´ç
æ¨¡åééåè­åå½¢ç¾¤éå½¢æé«åº¦ç³¾çºçç¾¤éãå æ­¤ï¼æåä½¿ç¨ãç¾¤éæ§æå¤±ãå½æ¸è¨ç·´æ¨¡åï¼ä½¿å¶æ´å·æ¨¡çµåï¼
éé¼åµå½¢æéäº¤äºç¾¤éãä½¿ç¨èªååå¯è§£éæ§æè¡ï¼æåé¡¯ç¤ºæåçæ¨¡åå¯ä»¥å¹«å©è¨ç·´æ´å·æ¨¡çµåçæ¨¡åï¼ä¸¦å­¸ç¿ä¸åãä¸ç¸äº¤ä¸è¼å°çé»è·¯ãæå
ç ç©¶äºå¨ MNIST å CIFAR ä¸è¨ç·´ç CNNï¼å¨æ¨¡çµåå æ³ä¸è¨ç·´çå°åTransformerï¼ä»¥åèªè¨æ¨¡åãæåçåæ³çºè¨ç·´å­¸ç¿æ´ç°¡å®å½æ¸ä¸æ´å®¹æè§£éçç¥ç¶ç¶²è·¯æä¾äºæå¸æçæ¹åã

##### **Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs**
2502.02362v3 by Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-TÃ¼r

Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large
language models (LLMs) by enabling detailed step-by-step solutions. However,
due to the verbosity of LLMs, the resulting reasoning chains can be long,
making it harder to verify the reasoning steps and trace issues resulting from
dependencies between the steps that may be farther away in the sequence of
steps. Importantly, mathematical reasoning allows each step to be derived from
a small set of premises, which are a subset of the preceding steps in the
reasoning chain. In this paper, we present a framework that identifies the
premises for each step, to improve the evaluation of reasoning. We restructure
conventional linear reasoning chains into Premise Augmented Reasoning Chains
(PARC) by introducing premise links, resulting in a directed acyclic graph
where the nodes are the steps and the edges are the premise links. Through
experiments with a PARC-based dataset that we built, namely PERL (Premises and
ERrors identification in LLMs), we demonstrate that LLMs can reliably identify
premises within complex reasoning chains. In particular, even open-source LLMs
achieve 90% recall in premise identification. We also show that PARC helps to
identify errors in reasoning chains more reliably. The accuracy of error
identification improves by 6% to 16% absolute when step-by-step verification is
carried out in PARC under the premises. Our findings highlight the utility of
premise-centric representations in addressing complex problem-solving tasks and
open new avenues for improving the reliability of LLM-based reasoning
evaluations.

æè¦ï¼<paragraph>æèéï¼CoTï¼æç¤ºééæä¾è©³ç´°çéæ­¥è§£æ³ï¼å¢å¼·å¤§åèªè¨æ¨¡åï¼LLMï¼çæ¸å­¸æ¨çè½åãç¶èï¼ç±æ¼ LLM çåé·ï¼ç¢ççæ¨çéå¯è½å¾é·ï¼éä½¿å¾é©è­æ¨çæ­¥é©åè¿½è¹¤ç±æ­¥é©ä¹éç¸ä¾éä¿æç¢ççåé¡è®å¾æ´å å°é£ï¼èéäºæ­¥é©å¯è½å¨æ­¥é©é åºä¸­ç¸è·è¼é ãéè¦çæ¯ï¼æ¸å­¸æ¨çåè¨±æ¯åæ­¥é©å¾ä¸çµå°çåæä¸­æ¨å°åºä¾ï¼éäºåææ¯æ¨çéä¸­åä¸åæ­¥é©çå­éãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ¡æ¶ï¼ç¨æ¼è­å¥æ¯åæ­¥é©çåæï¼ä»¥æ¹é²æ¨çè©ä¼°ãæåééå¼å¥åæé£çµï¼å°å³çµ±çç·æ§æ¨çééçµçºåææ´åæ¨çéï¼PARCï¼ï¼ç¢çä¸åæåç¡ç°åï¼å¶ä¸­ç¯é»æ¯æ­¥é©ï¼èéç·£æ¯åæé£çµãééæåå»ºç«çåºæ¼ PARC çè³æéï¼å³ PERLï¼LLM ä¸­çåæåé¯èª¤è­å¥ï¼ï¼é²è¡çå¯¦é©ï¼æåè­æ LLM è½å¤ å¨è¤éçæ¨çéä¸­å¯é å°è­å¥åæãç¹å¥æ¯ï¼å³ä½¿æ¯éæº LLM å¨åæè­å¥ä¸­ä¹è½éå° 90% çå¬åçãæåéè¡¨æï¼PARC æå©æ¼æ´å¯é å°è­å¥æ¨çéä¸­çé¯èª¤ãå¨åæä¸æ¼ PARC ä¸­å·è¡éæ­¥é©è­æï¼é¯èª¤è­å¥çæºç¢ºåº¦æé«äº 6% å° 16%ãæåçç ç©¶çµæçªé¡¯äºä»¥åæçºä¸­å¿çè¡¨ç¤ºå¨è§£æ±ºè¤éåé¡è§£æ±ºä»»åä¸­çæç¨ï¼ä¸¦çºæ¹é²åºæ¼ LLM çæ¨çè©ä¼°çå¯é æ§éé¢äºæ°éå¾ã</paragraph>

##### **AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement**
2502.02067v1 by Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, Mohan Sridharan, Madhava Krishna

Embodied agents assisting humans are often asked to complete a new task in a
new scenario. An agent preparing a particular dish in the kitchen based on a
known recipe may be asked to prepare a new dish or to perform cleaning tasks in
the storeroom. There may not be sufficient resources, e.g., time or labeled
examples, to train the agent for these new situations. Large Language Models
(LLMs) trained on considerable knowledge across many domains are able to
predict a sequence of abstract actions for such new tasks and scenarios,
although it may not be possible for the agent to execute this action sequence
due to task-, agent-, or domain-specific constraints. Our framework addresses
these challenges by leveraging the generic predictions provided by LLM and the
prior domain-specific knowledge encoded in a Knowledge Graph (KG), enabling an
agent to quickly adapt to new tasks and scenarios. The robot also solicits and
uses human input as needed to refine its existing knowledge. Based on
experimental evaluation over cooking and cleaning tasks in simulation domains,
we demonstrate that the interplay between LLM, KG, and human input leads to
substantial performance gains compared with just using the LLM output.

æè¦ï¼å·èº«ä»£çåå©äººç±»æ¶ï¼éå¸¸éè¦å¨æ°çæå¢ä¸­å®ææ°çä»»å¡ãåºäºå·²ç¥é£è°±å¨å¨æ¿åå¤ç¹å®èè´çä»£çå¯è½ä¼è¢«è¦æ±åå¤æ°èè´æå¨å¨èå®¤æ§è¡æ¸æ´ä»»å¡ãå¯è½æ²¡æè¶³å¤èµæºï¼ä¾å¦æ¶é´ææ è®°çç¤ºä¾ï¼æ¥è®­ç»ä»£çä»¥åºå¯¹è¿äºæ°æåµãå¨è®¸å¤é¢åæ¥åå¤§éç¥è¯è®­ç»çå¤§åè¯­è¨æ¨¡å (LLM) è½å¤é¢æµæ­¤ç±»æ°ä»»å¡åæå¢çæ½è±¡å¨ä½åºåï¼å°½ç®¡ä»£çå¯è½æ æ³æ§è¡æ­¤å¨ä½åºåï¼å ä¸ºä»»å¡ãä»£çæç¹å®äºåççº¦æãæä»¬çæ¡æ¶éè¿å©ç¨ LLM æä¾çéç¨é¢æµåç¥è¯å¾ (KG) ä¸­ç¼ç çååç¹å®äºåçç¥è¯æ¥åºå¯¹è¿äºææï¼ä½¿ä»£çè½å¤å¿«ééåºæ°ä»»å¡åæå¢ãè¯¥æºå¨äººè¿ä¼æ ¹æ®éè¦å¾æ±å¹¶ä½¿ç¨äººç±»è¾å¥æ¥å®åå¶ç°æç¥è¯ãåºäºå¨æ¨¡æåä¸­å¯¹ç¹é¥ªåæ¸æ´ä»»å¡çå®éªè¯ä¼°ï¼æä»¬è¯æäº LLMãKG åäººç±»è¾å¥ä¹é´çç¸äºä½ç¨ä¸ä»ä½¿ç¨ LLM è¾åºç¸æ¯å¸¦æ¥äºå·¨å¤§çæ§è½æåã

##### **On Bob Dylan: A Computational Perspective**
2502.01772v1 by Prashant Garg

Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style
-- a constant refusal to conform to expectation and a penchant for reinventing
his musical and lyrical identity. In this paper, I extend Sunstein's
observations through a large-scale computational analysis of Dylan's lyrics
from 1962 to 2012. Using o3-mini-high (a large language model), I extract
concept-to-concept relationships from the lyrics and construct directed
knowledge graphs that capture Dylan's thematic structure. I then quantify
shifts in sentiment, metaphorical expression, thematic diversity, and network
complexity over time. The results indicate that Dylan's lyrics increasingly
rely on metaphor, display an evolving sentiment profile, and exhibit heightened
dishabituation -- measured here as a growing variance in the network centrality
of key concepts. I also find that references to movement, protest, and mythic
imagery fluctuate in ways that align with well-known phases of Dylan's career,
reflecting the dynamic and unpredictable quality of his art. These findings not
only deepen our empirical understanding of Sunstein's thesis but also introduce
a novel computational method for analyzing an artist's evolution-offering
broader applicability to the study of cultural and creative change.

æè¦ï¼å¡æ¯Â·æ¡æ¯å¦çè«æãè«é®ä¼¯Â·è¿ªå«ãæè¿°äºè¿ªå«ãå»ç¿æ£åãçé¢¨æ ¼
-- éç¨®é¢¨æ ¼ä¸æ·æçµç¬¦åé æï¼ä¸¦ç±è¡·æ¼éæ°å¡é ä»çé³æ¨åæ­è©èªåãå¨æ¬æä¸­ï¼æééå°è¿ªå« 1962 å¹´è³ 2012 å¹´æ­è©é²è¡å¤§è¦æ¨¡çéç®åæï¼ä¾å»¶ä¼¸æ¡æ¯å¦çè§å¯ãä½¿ç¨ o3-mini-highï¼ä¸åå¤§åèªè¨æ¨¡åï¼ï¼æå¾æ­è©ä¸­æåæ¦å¿µå°æ¦å¿µçéä¿ï¼ä¸¦å»ºæ§æåç¥è­åï¼ä»¥ææè¿ªå«çä¸»é¡çµæ§ãç¶å¾ï¼æéåæç·ãé±å»è¡¨éãä¸»é¡å¤æ¨£æ§åç¶²è·¯è¤éæ§é¨æéçè®åãçµæé¡¯ç¤ºï¼è¿ªå«çæ­è©è¶ä¾è¶ä¾è³´é±å»ï¼å±ç¾åºä¸æ·æ¼åçæç·è¼ªå»ï¼ä¸¦è¡¨ç¾åºé«åº¦çå»ç¿æ£å -- å¨éè£¡æ¸¬éçºééµæ¦å¿µçç¶²è·¯ä¸­å¿æ§çè®ç°å¢å ãæä¹ç¼ç¾ï¼å°éåãæè­°åç¥è©±æè±¡çå¼ç¨ï¼æä»¥èè¿ªå«è·æ¥­çæ¶¯ä¸­ç¾æå¨ç¥éæ®µä¸è´çæ¹å¼æ³¢åï¼åæ äºä»èè¡çåæåä¸å¯é æ¸¬çåè³ªãéäºç¼ç¾ä¸åå æ·±äºæåå°æ¡æ¯å¦è«æçç¶é©çè§£ï¼ä¹å¼å¥äºåæèè¡å®¶æ¼è®çæ°ç©éç®æ¹æ³ï¼çºæåååµé æ§è®åçç ç©¶æä¾äºæ´å»£æ³çé©ç¨æ§ã

##### **VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos**
2502.01549v1 by Xubin Ren, Lingrui Xu, Long Xia, Shuaiqiang Wang, Dawei Yin, Chao Huang

Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in
enhancing Large Language Models (LLMs) through external knowledge integration,
yet its application has primarily focused on textual content, leaving the rich
domain of multi-modal video knowledge predominantly unexplored. This paper
introduces VideoRAG, the first retrieval-augmented generation framework
specifically designed for processing and understanding extremely long-context
videos. Our core innovation lies in its dual-channel architecture that
seamlessly integrates (i) graph-based textual knowledge grounding for capturing
cross-video semantic relationships, and (ii) multi-modal context encoding for
efficiently preserving visual features. This novel design empowers VideoRAG to
process unlimited-length videos by constructing precise knowledge graphs that
span multiple videos while maintaining semantic dependencies through
specialized multi-modal retrieval paradigms. Through comprehensive empirical
evaluation on our proposed LongerVideos benchmark-comprising over 160 videos
totaling 134+ hours across lecture, documentary, and entertainment
categories-VideoRAG demonstrates substantial performance compared to existing
RAG alternatives and long video understanding methods. The source code of
VideoRAG implementation and the benchmark dataset are openly available at:
https://github.com/HKUDS/VideoRAG.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²è­æå¨ééå¤é¨ç¥è­æ´åå¢å¼·å¤§åèªè¨æ¨¡å (LLM) æ¹é¢åå¾é¡¯èæåï¼ä½å¶æç¨ä¸»è¦éä¸­å¨æå­å§å®¹ä¸ï¼èè±å¯çå¤æ¨¡æå½±çç¥è­é ååé®®å°è¢«æ¢ç´¢ãæ¬æä»ç´¹ VideoRAGï¼éæ¯ç¬¬ä¸åæª¢ç´¢å¢å¼·çææ¶æ§ï¼å°éè¨­è¨ç¨æ¼èçåçè§£æ¥µé·èªå¢çå½±çãæåçæ ¸å¿åµæ°å¨æ¼å¶éééæ¶æ§ï¼å®ç¡ç¸«æ´å (i) åºæ¼åå½¢æå­ç¥è­åºç¤ï¼ç¨æ¼æ·åè·¨å½±çèªç¾©éä¿ï¼ä»¥å (ii) å¤æ¨¡æèªå¢ç·¨ç¢¼ï¼ç¨æ¼ææä¿çè¦è¦ºç¹å¾µãéåæ°ç©çè¨­è¨è® VideoRAG è½å¤ ééå»ºæ§è·¨è¶å¤åå½±ççç²¾ç¢ºç¥è­åè­ä¾èçé·åº¦ä¸éçå½±çï¼åæééå°éçå¤æ¨¡ææª¢ç´¢ç¯ä¾ä¾ç¶­æèªç¾©ä¾è³´æ§ãééæåæåºç LongerVideos åºæºçå¨é¢ç¶é©è©ä¼°ï¼è©²åºæºåå«è¶é 160 é¨å½±çï¼ç¸½ææ¸è¶é 134 å°æï¼æ¶µèæ¼è¬ãç´éçåå¨æ¨é¡å¥ï¼VideoRAG èç¾æç RAG æ¿ä»£æ¹æ¡åé·å½±ççè§£æ¹æ³ç¸æ¯ï¼å±ç¾åºé¡¯èçæè½ãVideoRAG å¯¦ä½çåå§ç¢¼ååºæºè³æéå·²å¬éæ¼ï¼https://github.com/HKUDS/VideoRAGã

##### **Transformers trained on proteins can learn to attend to Euclidean distance**
2502.01533v1 by Isaac Ellmen, Constantin Schneider, Matthew I. J. Raybould, Charlotte M. Deane

While conventional Transformers generally operate on sequence data, they can
be used in conjunction with structure models, typically SE(3)-invariant or
equivariant graph neural networks (GNNs), for 3D applications such as protein
structure modelling. These hybrids typically involve either (1)
preprocessing/tokenizing structural features as input for Transformers or (2)
taking Transformer embeddings and processing them within a structural
representation. However, there is evidence that Transformers can learn to
process structural information on their own, such as the AlphaFold3 structural
diffusion model. In this work we show that Transformers can function
independently as structure models when passed linear embeddings of coordinates.
We first provide a theoretical explanation for how Transformers can learn to
filter attention as a 3D Gaussian with learned variance. We then validate this
theory using both simulated 3D points and in the context of masked token
prediction for proteins. Finally, we show that pre-training protein Transformer
encoders with structure improves performance on a downstream task, yielding
better performance than custom structural models. Together, this work provides
a basis for using standard Transformers as hybrid structure-language models.

æè¦ï¼éç¶å³çµ±ç Transformer éå¸¸èçåºåè³æï¼ä½å®åå¯ç¨æ¼çµæ§æ¨¡åï¼éå¸¸æ¯ SE(3) ä¸è®å¼æç­è®å¼åç¥ç¶ç¶²è·¯ (GNN)ï¼ç¨æ¼èç½è³ªçµæ§å»ºæ¨¡ç­ 3D æç¨ãéäºæ··åæ¨¡åéå¸¸åå« (1) å°çµæ§ç¹å¾µé èç/æ¨è¨åçº Transformer çè¼¸å¥æ (2) åç¨ Transformer åµå¥ä¸¦å¨çµæ§è¡¨ç¤ºä¸­èçå®åãç¶èï¼æè­æè¡¨æ Transformer å¯ä»¥èªè¡å­¸ç¿èççµæ§è³è¨ï¼ä¾å¦ AlphaFold3 çµæ§æ´æ£æ¨¡åãå¨éé å·¥ä½ä¸­ï¼æåå±ç¤ºäº Transformer å¨å³éåº§æ¨çç·æ§åµå¥æï¼å¯ä»¥ç¨ç«ä½çºçµæ§æ¨¡åéä½ãæåé¦åæä¾äº Transformer å¦ä½å­¸ç¿å°æ³¨æåæ¿¾æ³¢çºå·æå­¸ç¿è®ç°ç 3D é«æ¯ççè«è§£éãç¶å¾æåä½¿ç¨æ¨¡æ¬ 3D é»åå¨èç½è³ªé®ç½©æ¨è¨é æ¸¬çèæ¯ä¸é©è­æ­¤çè«ãæå¾ï¼æåå±ç¤ºäºä½¿ç¨çµæ§é è¨ç·´èç½è³ª Transformer ç·¨ç¢¼å¨ææ¹åä¸æ¸¸ä»»åçæè½ï¼ç¢çæ¯èªè¨çµæ§æ¨¡åæ´å¥½çæè½ãç¶åä¾èªªï¼éé å·¥ä½æä¾äºä½¿ç¨æ¨æº Transformer ä½çºæ··åçµæ§èªè¨æ¨¡åçåºç¤ã

##### **Common Foundations for SHACL, ShEx, and PG-Schema**
2502.01295v1 by S. Ahmetaj, I. Boneva, J. Hidders, K. Hose, M. Jakubowski, J. E. Labra-Gayo, W. Martens, F. Mogavero, F. Murlak, C. Okulmus, A. Polleres, O. Savkovic, M. Simkus, D. Tomaszuk

Graphs have emerged as an important foundation for a variety of applications,
including capturing and reasoning over factual knowledge, semantic data
integration, social networks, and providing factual knowledge for machine
learning algorithms. To formalise certain properties of the data and to ensure
data quality, there is a need to describe the schema of such graphs. Because of
the breadth of applications and availability of different data models, such as
RDF and property graphs, both the Semantic Web and the database community have
independently developed graph schema languages: SHACL, ShEx, and PG-Schema.
Each language has its unique approach to defining constraints and validating
graph data, leaving potential users in the dark about their commonalities and
differences. In this paper, we provide formal, concise definitions of the core
components of each of these schema languages. We employ a uniform framework to
facilitate a comprehensive comparison between the languages and identify a
common set of functionalities, shedding light on both overlapping and
distinctive features of the three languages.

æè¦ï¼åè¡¨å·²æçºåç¨®æç¨çéè¦åºç¤ï¼åæ¬æ·ååæ¨çäºå¯¦ç¥è­ãèªç¾©è³ææ´åãç¤¾ç¾¤ç¶²è·¯ï¼ä»¥åçºæ©å¨å­¸ç¿æ¼ç®æ³æä¾äºå¯¦ç¥è­ãçºäºå½¢å¼åè³æçç¹å®å±¬æ§ä¸¦ç¢ºä¿è³æåè³ªï¼æå¿è¦æè¿°æ­¤é¡åè¡¨çæ¶æ§ãç±æ¼æç¨ç¯åå»£æ³ä¸æä¸åçè³ææ¨¡åå¯ç¨ï¼ä¾å¦ RDF åå±¬æ§åè¡¨ï¼å æ­¤èªç¾©ç¶²è·¯åè³æåº«ç¤¾ç¾¤å·²ç¨ç«éç¼åè¡¨æ¶æ§èªè¨ï¼SHACLãShEx å PG-Schemaãæ¯ç¨®èªè¨é½æå¶å®ç¾©ç´æåé©è­åè¡¨è³æçç¨ç¹æ¹æ³ï¼è®æ½å¨ä½¿ç¨èä¸æ¸æ¥å®åçå±æ§åå·®ç°ãå¨æ¬æä¸­ï¼æåæä¾éäºæ¶æ§èªè¨ä¸­æ¯åæ ¸å¿åä»¶çæ­£å¼ç°¡æ½å®ç¾©ãæåæ¡ç¨çµ±ä¸çæ¡æ¶ä¾ä¿é²èªè¨ä¹éçå¨é¢æ¯è¼ï¼ä¸¦æ¾åºåè½çå±åéåï¼èªªæéä¸ç¨®èªè¨çéçåç¨ç¹åè½ã

##### **GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**
2502.01113v1 by Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Dinh Phung, Chen Gong, Shirui Pan

Retrieval-augmented generation (RAG) has proven effective in integrating
knowledge into large language models (LLMs). However, conventional RAGs
struggle to capture complex relationships between pieces of knowledge, limiting
their performance in intricate reasoning that requires integrating knowledge
from multiple sources. Recently, graph-enhanced retrieval augmented generation
(GraphRAG) builds graph structure to explicitly model these relationships,
enabling more effective and efficient retrievers. Nevertheless, its performance
is still hindered by the noise and incompleteness within the graph structure.
To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for
retrieval augmented generation. GFM-RAG is powered by an innovative graph
neural network that reasons over graph structure to capture complex
query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage
training process on large-scale datasets, comprising 60 knowledge graphs with
over 14M triples and 700k documents. This results in impressive performance and
generalizability for GFM-RAG, making it the first graph foundation model
applicable to unseen datasets for retrieval without any fine-tuning required.
Extensive experiments on three multi-hop QA datasets and seven domain-specific
RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance
while maintaining efficiency and alignment with neural scaling laws,
highlighting its potential for further improvement.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å·²è­æå¨æ´åç¥è­å°å¤§èªè¨æ¨¡å (LLM) ä¸­ææãç¶èï¼å³çµ±ç RAG é£ä»¥ææç¥è­çæ®µä¹éçè¤ééä¿ï¼éå¶äºå®åå¨éè¦æ´åä¾èªå¤åä¾æºçç¥è­çè¤éæ¨çä¸­çè¡¨ç¾ãæè¿ï¼åè¡¨å¢å¼·æª¢ç´¢å¢å¼·çæ (GraphRAG) å»ºç«åè¡¨çµæ§ä¾æç¢ºå»ºæ¨¡éäºéä¿ï¼å¾èå¯¦ç¾æ´ææççæª¢ç´¢å¨ãåç®¡å¦æ­¤ï¼å¶æè½ä»åå°åè¡¨çµæ§ä¸­éè¨åä¸å®æ´æ§çé»ç¤ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº GFM-RAGï¼ä¸ç¨®ç¨æ¼æª¢ç´¢å¢å¼·çæçå¨æ°åè¡¨åºç¤æ¨¡å (GFM)ãGFM-RAG ç±ä¸ååµæ°çåç¥ç¶ç¶²è·¯é©åï¼è©²ç¶²è·¯å¨åè¡¨çµæ§ä¸é²è¡æ¨çä»¥ææè¤éçæ¥è©¢ç¥è­éä¿ãå·æ 8M åæ¸ç GFM å¨å¤§åè³æéä¸é²è¡å©éæ®µè¨ç·´æµç¨ï¼åæ¬ 60 ååå«è¶é 14M åä¸åçµå 700k åæä»¶çæä»¶ãéçº GFM-RAG å¸¶ä¾äºä»¤äººå°è±¡æ·±å»çæè½åéç¨æ§ï¼ä½¿å¶æçºç¬¬ä¸åé©ç¨æ¼æªè¦éè³æéçåè¡¨åºç¤æ¨¡åï¼èç¡éä»»ä½å¾®èª¿ãå¨ä¸åå¤è·³åç­è³æéåä¸åç¹å®é å RAG è³æéä¸çå»£æ³å¯¦é©è¡¨æï¼GFM-RAG éå°äºæåé²çæè½ï¼åæä¿æäºæçä¸¦èç¥ç¶æ´åå®å¾ä¿æä¸è´ï¼çªé¡¯äºå¶é²ä¸æ­¥æ¹é²çæ½åã

##### **Knowledge Synthesis of Photosynthesis Research Using a Large Language Model**
2502.01059v1 by Seungri Yoon, Woosang Jeon, Sanghyeok Choi, Taehyeong Kim, Tae In Ahn

The development of biological data analysis tools and large language models
(LLMs) has opened up new possibilities for utilizing AI in plant science
research, with the potential to contribute significantly to knowledge
integration and research gap identification. Nonetheless, current LLMs struggle
to handle complex biological data and theoretical models in photosynthesis
research and often fail to provide accurate scientific contexts. Therefore,
this study proposed a photosynthesis research assistant (PRAG) based on
OpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt
optimization. Vector databases and an automated feedback loop were used in the
prompt optimization process to enhance the accuracy and relevance of the
responses to photosynthesis-related queries. PRAG showed an average improvement
of 8.7% across five metrics related to scientific writing, with a 25.4%
increase in source transparency. Additionally, its scientific depth and domain
coverage were comparable to those of photosynthesis research papers. A
knowledge graph was used to structure PRAG's responses with papers within and
outside the database, which allowed PRAG to match key entities with 63% and
39.5% of the database and test papers, respectively. PRAG can be applied for
photosynthesis research and broader plant science domains, paving the way for
more in-depth data analysis and predictive capabilities.

æè¦ï¼çç©è³æåæå·¥å·åå¤§åèªè¨æ¨¡å (LLM) çç¼å±ï¼çºå©ç¨äººå·¥æºæ§æ¼æ¤ç©ç§å­¸ç ç©¶éåäºæ°çå¯è½æ§ï¼ä¸¦ææ½åå°ç¥è­æ´ååç ç©¶å·®è·çè­å¥ååºéå¤§è²¢ç»ãåç®¡å¦æ­¤ï¼ç®åç LLM å¨èçååä½ç¨ç ç©¶ä¸­çè¤éçç©è³æåçè«æ¨¡åæä»æå°é£ï¼èä¸å¸¸å¸¸ç¡æ³æä¾æºç¢ºçç§å­¸èæ¯ãå æ­¤ï¼æ¬ç ç©¶æåºäºä¸ååºæ¼ OpenAI ç GPT-4oãå·åæª¢ç´¢å¢å¼·çæ (RAG) æè¡åæç¤ºæä½³åçååä½ç¨ç ç©¶å©ç (PRAG)ãå¨æç¤ºæä½³åéç¨ä¸­ï¼ä½¿ç¨äºåéè³æåº«åèªååé¥è¿´è·¯ï¼ä»¥å¢å¼·å°èååä½ç¨ç¸éæ¥è©¢çåæçæºç¢ºæ§åç¸éæ§ãPRAG å¨èç§å­¸å¯«ä½ç¸éçäºé ææ¨ä¸­é¡¯ç¤ºåºå¹³åæ¹åäº 8.7%ï¼ä¾æºéæåº¦å¢å äº 25.4%ãæ­¤å¤ï¼å¶ç§å­¸æ·±åº¦åé åæ¶µèç¯åèååä½ç¨ç ç©¶è«æç¸ç¶ãç¥è­åè­ç¨æ¼å»ºæ§ PRAG çåæï¼å¶ä¸­åå«è³æåº«å§å¤è«æï¼éä½¿å¾ PRAG è½å¤ åå¥èè³æåº«åæ¸¬è©¦è«æä¸­ç 63% å 39.5% çééµå¯¦é«ç¸å¹éãPRAG å¯æç¨æ¼ååä½ç¨ç ç©¶åæ´å»£æ³çæ¤ç©ç§å­¸é åï¼çºæ´æ·±å¥çè³æåæåé æ¸¬è½åéªè·¯ã

##### **Encrypted Large Model Inference: The Equivariant Encryption Paradigm**
2502.01013v1 by James Buban, Hongyang Zhang, Claudio Angione, Harry Yang, Ahmad Farhan, Seyfal Sultanov, Michael Du, Xuran Ma, Zihao Wang, Yue Zhao, Arria Owlia, Fielding Johnston, Patrick Colangelo

Large scale deep learning model, such as modern language models and diffusion
architectures, have revolutionized applications ranging from natural language
processing to computer vision. However, their deployment in distributed or
decentralized environments raises significant privacy concerns, as sensitive
data may be exposed during inference. Traditional techniques like secure
multi-party computation, homomorphic encryption, and differential privacy offer
partial remedies but often incur substantial computational overhead, latency
penalties, or limited compatibility with non-linear network operations. In this
work, we introduce Equivariant Encryption (EE), a novel paradigm designed to
enable secure, "blind" inference on encrypted data with near zero performance
overhead. Unlike fully homomorphic approaches that encrypt the entire
computational graph, EE selectively obfuscates critical internal
representations within neural network layers while preserving the exact
functionality of both linear and a prescribed set of non-linear operations.
This targeted encryption ensures that raw inputs, intermediate activations, and
outputs remain confidential, even when processed on untrusted infrastructure.
We detail the theoretical foundations of EE, compare its performance and
integration complexity against conventional privacy preserving techniques, and
demonstrate its applicability across a range of architectures, from
convolutional networks to large language models. Furthermore, our work provides
a comprehensive threat analysis, outlining potential attack vectors and
baseline strategies, and benchmarks EE against standard inference pipelines in
decentralized settings. The results confirm that EE maintains high fidelity and
throughput, effectively bridging the gap between robust data confidentiality
and the stringent efficiency requirements of modern, large scale model
inference.

æè¦ï¼å¤§åæ·±åº¦å­¸ç¿æ¨¡åï¼ä¾å¦ç¾ä»£èªè¨æ¨¡ååæ´æ£æ¶æ§ï¼å¾¹åºæ¹è®äºå¾èªç¶èªè¨èçå°é»è¦è¦è¦ºç­åç¨®æç¨ãç¶èï¼å®åå¨åæ£å¼æåæ£å¼ç°å¢ä¸­çé¨ç½²å¼ç¼äºéå¤§çé±ç§åé¡ï¼å çºæææ¸æå¯è½æå¨æ¨çéç¨ä¸­é­å°æ­é²ãå®å¨å¤æ¹è¨ç®ãåæå å¯åå·®åé±ç§ç­å³çµ±æè¡æä¾äºé¨åè£ææªæ½ï¼ä½éå¸¸æç¢çå¤§éçè¨ç®éé·ãå»¶é²èç½°ï¼æèéç·æ§ç¶²è·¯æä½ç¸å®¹æ§æéãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºç­è®å å¯ (EE)ï¼éæ¯ä¸ç¨®æ°ç©çç¯ä¾ï¼æ¨å¨ä»¥æ¥è¿é¶æè½éé·å°å å¯æ¸æé²è¡å®å¨ããç²ç®ãæ¨çãèå å¯æ´åè¨ç®åå½¢çå®å¨åææ¹æ³ä¸åï¼EE æé¸ææ§å°æ··æ·ç¥ç¶ç¶²è·¯å±¤å§çééµå§é¨è¡¨ç¤ºï¼åæä¿çç·æ§åè¦å®çä¸çµéç·æ§æä½çç²¾ç¢ºåè½ãéç¨®æéå°æ§çå å¯ç¢ºä¿äºåå§è¼¸å¥ãä¸­éæ¿æ´»åè¼¸åºä¿ææ©å¯ï¼å³ä½¿å¨ä¸åä¿¡ä»»çåºç¤è¨­æ½ä¸èçä¹æ¯å¦æ­¤ãæåè©³ç´°èªªæäº EE ççè«åºç¤ï¼æ¯è¼äºå¶æè½åæ´åè¤éåº¦èå³çµ±çé±ç§ä¿è­·æè¡ï¼ä¸¦å±ç¤ºäºå¶å¨å¾å·ç©ç¶²è·¯å°å¤§èªè¨æ¨¡åç­åç¨®æ¶æ§ä¸­çé©ç¨æ§ãæ­¤å¤ï¼æåçç ç©¶æä¾äºå¨é¢çå¨èåæï¼æ¦è¿°äºæ½å¨çæ»æåªä»ååºæºç­ç¥ï¼ä¸¦å¨åæ£å¼è¨­å®ä¸­å° EE èæ¨æºæ¨çç®¡éé²è¡æ¯è¼ãçµæè­å¯¦ï¼EE ä¿æäºé«ä¿çåº¦åé«å³è¼¸éï¼ææå°å½åäºå¼·å¤§çæ¸ææ©å¯æ§èç¾ä»£åãå¤§è¦æ¨¡æ¨¡åæ¨ççå´æ ¼æçè¦æ±ä¹éçå·®è·ã

##### **Metastable Dynamics of Chain-of-Thought Reasoning: Provable Benefits of Search, RL and Distillation**
2502.01694v1 by Juno Kim, Denny Wu, Jason Lee, Taiji Suzuki

A key paradigm to improve the reasoning capabilities of large language models
(LLMs) is to allocate more inference-time compute to search against a verifier
or reward model. This process can then be utilized to refine the pretrained
model or distill its reasoning patterns into more efficient models. In this
paper, we study inference-time compute by viewing chain-of-thought (CoT)
generation as a metastable Markov process: easy reasoning steps (e.g.,
algebraic manipulations) form densely connected clusters, while hard reasoning
steps (e.g., applying a relevant theorem) create sparse, low-probability edges
between clusters, leading to phase transitions at longer timescales. Under this
framework, we prove that implementing a search protocol that rewards sparse
edges improves CoT by decreasing the expected number of steps to reach
different clusters. In contrast, we establish a limit on reasoning capability
when the model is restricted to local information of the pretrained graph. We
also show that the information gained by search can be utilized to obtain a
better reasoning model: (1) the pretrained model can be directly finetuned to
favor sparse edges via policy gradient methods, and moreover (2) a compressed
metastable representation of the reasoning dynamics can be distilled into a
smaller, more efficient model.

æè¦ï¼<paragraph>æåå¤§åèªè¨æ¨¡å (LLM) æ¨çè½åçä¸åééµç¯ä¾ï¼æ¯åéæ´å¤æ¨è«æééç®ä¾æå°é©è­å¨æçåµæ¨¡åãæ­¤ç¨åºæ¥èå¯ç¨æ¼æ¹åé è¨ç·´æ¨¡åæå°å¶æ¨çæ¨¡å¼æçå°æ´ææççæ¨¡åä¸­ãå¨éç¯è«æä¸­ï¼æåééå°æç¶­é (CoT) çæè¦çºäºç©©æé¦¬å¯å¤«éç¨ä¾ç ç©¶æ¨è«æééç®ï¼ç°¡å®çæ¨çæ­¥é©ï¼ä¾å¦ä»£æ¸éç®ï¼å½¢æå¯éé£æ¥çå¢éï¼èå°é£çæ¨çæ­¥é©ï¼ä¾å¦æç¨ç¸éå®çï¼åå¨å¢éä¹éå»ºç«ç¨çãä½æ©ççéç·£ï¼å°è´å¨è¼é·æéå°ºåº¦ä¸ç¢çç¸è®ãå¨æ­¤æ¶æ§ä¸ï¼æåè­æå¯¦ä½ä¸ç¨®çåµç¨çéç·£çæå°åå®ï¼æééæ¸å°å°éä¸åå¢éæéçé ææ­¥é©æ¸ä¾æ¹å CoTãç¸åå°ï¼ç¶æ¨¡ååéæ¼é è¨ç·´åå½¢çå±é¨è³è¨æï¼æåå»ºç«äºæ¨çè½åçéå¶ãæåä¹é¡¯ç¤ºæå°æç²å¾çè³è¨å¯ç¨æ¼åå¾æ´å¥½çæ¨çæ¨¡åï¼(1) é è¨ç·´æ¨¡åå¯ä»¥ç´æ¥å¾®èª¿ä»¥ééç­ç¥æ¢¯åº¦æ¹æ³åå¥½ç¨çéç·£ï¼èä¸ (2) æ¨çåæçå£ç¸®äºç©©æè¡¨å¾µå¯ä»¥æçå°æ´å°ãæ´ææççæ¨¡åä¸­ã</paragraph>

##### **PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation**
2502.00708v1 by Qixuan Li, Chao Wang, Zongjin He, Yan Peng

Text-to-3D asset generation has achieved significant optimization under the
supervision of 2D diffusion priors. However, when dealing with compositional
scenes, existing methods encounter several challenges: 1). failure to ensure
that composite scene layouts comply with physical laws; 2). difficulty in
accurately capturing the assets and relationships described in complex scene
descriptions; 3). limited autonomous asset generation capabilities among layout
approaches leveraging large language models (LLMs). To avoid these compromises,
we propose a novel framework for compositional scene generation, PhiP-G, which
seamlessly integrates generation techniques with layout guidance based on a
world model. Leveraging LLM-based agents, PhiP-G analyzes the complex scene
description to generate a scene graph, and integrating a multimodal 2D
generation agent and a 3D Gaussian generation method for targeted assets
creation. For the stage of layout, PhiP-G employs a physical pool with adhesion
capabilities and a visual supervision agent, forming a world model for layout
prediction and planning. Extensive experiments demonstrate that PhiP-G
significantly enhances the generation quality and physical rationality of the
compositional scenes. Notably, PhiP-G attains state-of-the-art (SOTA)
performance in CLIP scores, achieves parity with the leading methods in
generation quality as measured by the T$^3$Bench, and improves efficiency by
24x.

æè¦ï¼<paragraph>å¨ 2D æ´æ£åé©çç£ç£ä¸ï¼æå­è½ 3D è³ç¢çæå·²åå¾é¡¯èçæä½³åãç¶èï¼å¨èçåæå ´æ¯æï¼ç¾ææ¹æ³æéå°å¹¾åææ°ï¼1) ç¡æ³ç¢ºä¿è¤åå ´æ¯ä½å±ç¬¦åç©çå®å¾ï¼2) é£ä»¥æºç¢ºææè¤éå ´æ¯æè¿°ä¸­ææè¿°çè³ç¢åéä¿ï¼3) å¨å©ç¨å¤§åèªè¨æ¨¡å (LLM) çä½å±æ¹æ³ä¸­ï¼èªä¸»è³ç¢çæè½åæéãçºäºé¿åéäºæè¡·ï¼æåæåºäºä¸ååæå ´æ¯çæçæ°æ¡æ¶ PhiP-Gï¼å®å°çææè¡èåºæ¼ä¸çæ¨¡åçä½å±æå°ç¡ç¸«æ´åãå©ç¨åºæ¼ LLM çä»£çï¼PhiP-G åæè¤éçå ´æ¯æè¿°ä»¥çæå ´æ¯åï¼ä¸¦æ´åå¤æ¨¡æ 2D çæä»£çå 3D é«æ¯çææ¹æ³ä»¥é²è¡ç®æ¨è³ç¢åµå»ºãå°æ¼ä½å±éæ®µï¼PhiP-G æ¡ç¨å·æéèè½åçç©çæ± åè¦è¦ºç£ç£ä»£çï¼å½¢æç¨æ¼ä½å±é æ¸¬åè¦åçä¸çæ¨¡åãå¤§éçå¯¦é©è­æï¼PhiP-G å¤§å¹æåäºåæå ´æ¯ççæåè³ªåç©çåçæ§ãå¼å¾æ³¨æçæ¯ï¼PhiP-G å¨ CLIP åæ¸ä¸­ç²å¾äºæåé² (SOTA) çæè½ï¼å¨ T$^3$Bench æ¸¬éççæåè³ªä¸­èé åçæ¹æ³éå°åç­æ°´æºï¼ä¸¦å°æçæåäº 24 åã</paragraph>

##### **A Survey of Quantized Graph Representation Learning: Connecting Graph Structures with Large Language Models**
2502.00681v1 by Qika Lin, Zhen Peng, Kaize Shi, Kai He, Yiming Xu, Erik Cambria, Mengling Feng

Recent years have witnessed rapid advances in graph representation learning,
with the continuous embedding approach emerging as the dominant paradigm.
However, such methods encounter issues regarding parameter efficiency,
interpretability, and robustness. Thus, Quantized Graph Representation (QGR)
learning has recently gained increasing interest, which represents the graph
structure with discrete codes instead of conventional continuous embeddings.
Given its analogous representation form to natural language, QGR also possesses
the capability to seamlessly integrate graph structures with large language
models (LLMs). As this emerging paradigm is still in its infancy yet holds
significant promise, we undertake this thorough survey to promote its rapid
future prosperity. We first present the background of the general quantization
methods and their merits. Moreover, we provide an in-depth demonstration of
current QGR studies from the perspectives of quantized strategies, training
objectives, distinctive designs, knowledge graph quantization, and
applications. We further explore the strategies for code dependence learning
and integration with LLMs. At last, we give discussions and conclude future
directions, aiming to provide a comprehensive picture of QGR and inspire future
research.

æè¦ï¼è¿å¹´æ¥ï¼å¾è¡¨ç¤ºå­¦ä¹ åå¾äºå¿«éè¿å±ï¼å¶ä¸­è¿ç»­åµå¥æ¹æ³ä½ä¸ºä¸»å¯¼èå¼åºç°ãç¶èï¼æ­¤ç±»æ¹æ³éå°äºåæ°æçãå¯è§£éæ§åé²æ£æ§æ¹é¢çé®é¢ãå æ­¤ï¼éåå¾è¡¨ç¤º (QGR) å­¦ä¹ æè¿å¼èµ·äºè¶æ¥è¶å¤çå´è¶£ï¼å®ä½¿ç¨ç¦»æ£ä»£ç èä¸æ¯ä¼ ç»çè¿ç»­åµå¥æ¥è¡¨ç¤ºå¾ç»æãé´äºå¶ä¸èªç¶è¯­è¨ç±»ä¼¼çè¡¨ç¤ºå½¢å¼ï¼QGR ä¹å·å¤å°å¾ç»æä¸å¤§åè¯­è¨æ¨¡å (LLM) æ ç¼éæçè½åãç±äºè¿ç§æ°å´èå¼ä»å¤äºèµ·æ­¥é¶æ®µï¼ä½åæ¯å¹¿éï¼æä»¬è¿è¡äºè¿é¡¹å¨é¢è°æ¥ä»¥ä¿è¿å¶å¿«éæªæ¥çç¹è£ãæä»¬é¦åä»ç»äºéç¨éåæ¹æ³çèæ¯åå¶ä¼ç¹ãæ­¤å¤ï¼æä»¬ä»éåç­ç¥ãè®­ç»ç®æ ãç¬ç¹è®¾è®¡ãç¥è¯å¾è°±éåååºç¨çè§åº¦å¯¹å½åç QGR ç ç©¶è¿è¡äºæ·±å¥çè®ºè¯ãæä»¬è¿ä¸æ­¥æ¢ç´¢äºä»£ç ä¾èµæ§å­¦ä¹ åä¸ LLM éæçç­ç¥ãæåï¼æä»¬ç»åºäºè®¨è®ºå¹¶æ»ç»äºæªæ¥çæ¹åï¼æ¨å¨æä¾ QGR çå¨é¢å¾æ¯å¹¶æ¿åæªæ¥çç ç©¶ã

##### **Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions**
2502.00339v1 by Jingyuan Yi, Zeqiu Xu, Tianyi Huang, Peiyang Yu

The pervasiveness of the dissemination of fake news through social media
platforms poses critical risks to the trust of the general public, societal
stability, and democratic institutions. This challenge calls for novel
methodologies in detection, which can keep pace with the dynamic and
multi-modal nature of misinformation. Recent works include powering the
detection using large language model advances in multimodal frameworks,
methodologies using graphs, and adversarial training in the literature of fake
news. Based on the different approaches which can bring success, some key
highlights will be underlined: enhanced LLM-improves accuracy through more
advanced semantics and cross-modality fusion for robust detections. The review
further identifies critical gaps in adaptability to dynamic social media
trends, real-time, and cross-platform detection capabilities, as well as the
ethical challenges thrown up by the misuse of LLMs. Future directions underline
the development of style-agnostic models, cross-lingual detection frameworks,
and robust policies with a view to mitigating LLM-driven misinformation. This
synthesis thus lays a concrete foundation for those researchers and
practitioners committed to reinforcing fake news detection systems with
complications that keep on growing in the digital landscape.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°ä¸åæ°èæ£æ­çæ®éæ§å°ä¸è¬å¤§ç¾çä¿¡ä»»ãç¤¾æç©©å®æ§èæ°ä¸»å¶åº¦æ§æéå¤§é¢¨éªãéé ææ°éè¦å¨åµæ¸¬æ¹é¢æ¡ç¨åµæ°çæ¹æ³è«ï¼æè½è·ä¸é¯èª¤è³è¨çåæåå¤æ¨¡æç¹æ§ãæè¿çç ç©¶åæ¬ä½¿ç¨å¤æ¨¡ææ¶æ§ä¸­å¤§åèªè¨æ¨¡åçé²å±ãä½¿ç¨åå½¢çæ¹æ³è«ï¼ä»¥åå¨åæ°èæç»ä¸­é²è¡å°æè¨ç·´ä¾å¼·ååµæ¸¬ãæ ¹æå¯ä»¥å¸¶ä¾æåçä¸åæ¹æ³ï¼å°éé»èªªæä¸äºéé»ï¼å¢å¼·ç LLM å¯ééæ´é²éçèªæåè·¨æ¨¡æèåä¾æåæºç¢ºåº¦ï¼ä»¥é²è¡ç©©å¥çåµæ¸¬ãéç¯è©è«é²ä¸æ­¥æ¾åºå¨é©æåæç¤¾ç¾¤åªé«è¶¨å¢ãå³æåè·¨å¹³å°åµæ¸¬è½åæ¹é¢çéå¤§å·®è·ï¼ä»¥å LLM é­æ¿«ç¨çéå¾·ææ°ãæªä¾çæ¹åå¼·èª¿éç¼èé¢¨æ ¼ç¡éçæ¨¡åãè·¨èªè¨åµæ¸¬æ¶æ§åç©©å¥çæ¿ç­ï¼ä»¥æ¸è¼ LLM é©åçé¯èª¤è³è¨ãå æ­¤ï¼éç¨®ç¶ååæçºé£äºè´åæ¼å¼·ååæ°èåµæ¸¬ç³»çµ±çç ç©¶äººå¡åå¾æ¥­äººå¡å¥ å®äºå·é«çåºç¤ï¼èéäºè¤éæ§å¨æ¸ä½ç°å¢ä¸­æçºå¢é·ã

##### **DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning**
2502.00305v1 by Jiaxin Guo, C. L. Philip Chen, Shuzhen Li, Tong Zhang

Cold-start active learning (CSAL) selects valuable instances from an
unlabeled dataset for manual annotation. It provides high-quality data at a low
annotation cost for label-scarce text classification. However, existing CSAL
methods overlook weak classes and hard representative examples, resulting in
biased learning. To address these issues, this paper proposes a novel
dual-diversity enhancing and uncertainty-aware (DEUCE) framework for CSAL.
Specifically, DEUCE leverages a pretrained language model (PLM) to efficiently
extract textual representations, class predictions, and predictive uncertainty.
Then, it constructs a Dual-Neighbor Graph (DNG) to combine information on both
textual diversity and class diversity, ensuring a balanced data distribution.
It further propagates uncertainty information via density-based clustering to
select hard representative instances. DEUCE performs well in selecting
class-balanced and hard representative data by dual-diversity and
informativeness. Experiments on six NLP datasets demonstrate the superiority
and efficiency of DEUCE.

æè¦ï¼å·ååä¸»åå­¸ç¿ (CSAL) å¾æªæ¨è¨çè³æéä¸­é¸åæå¹å¼çå¯¦ä¾é²è¡æåæ¨è¨ãå®ä»¥ä½æ¨è¨ææ¬æä¾é«åè³ªçè³æï¼ç¨æ¼æ¨ç±¤ç¨å°çæå­åé¡ãç¶èï¼ç¾æç CSAL æ¹æ³å¿½ç¥äºå¼±é¡å¥åé£ä»¥ä»£è¡¨çç¯ä¾ï¼å°è´æåå·®çå­¸ç¿ãçºäºè§£æ±ºéäºåé¡ï¼æ¬ææåºäºä¸åæ°çééå¤æ¨£æ§å¢å¼·åä¸ç¢ºå®æ§æç¥ (DEUCE) æ¶æ§ï¼ç¨æ¼ CSALãå·é«ä¾èªªï¼DEUCE å©ç¨é è¨ç·´çèªè¨æ¨¡å (PLM) ä¾ææå°æåæå­è¡¨å¾µãé¡å¥é æ¸¬åé æ¸¬ä¸ç¢ºå®æ§ãç¶å¾ï¼å®æ§å»ºä¸åéé°å±å (DNG) ä¾çµåæå­å¤æ¨£æ§åé¡å¥å¤æ¨£æ§çè³è¨ï¼ç¢ºä¿å¹³è¡¡çè³æåä½ãå®é²ä¸æ­¥ééåºæ¼å¯åº¦çèé¡ä¾å³æ­ä¸ç¢ºå®æ§è³è¨ï¼ä»¥é¸æé£ä»¥ä»£è¡¨çå¯¦ä¾ãDEUCE å¨ééééå¤æ¨£æ§åè³è¨æ§é¸æé¡å¥å¹³è¡¡åé£ä»¥ä»£è¡¨çè³ææ¹é¢è¡¨ç¾è¯å¥½ãå¨å­å NLP è³æéä¸çå¯¦é©è­æäº DEUCE çåªè¶æ§åæçã

##### **Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques**
2502.01659v2 by Nathaniel Tomczak, Sanmukh Kuppannagari

Transformers have demonstrated great success in numerous domains including
natural language processing and bioinformatics. This success stems from the use
of the attention mechanism by these models in order to represent and propagate
pairwise interactions between individual tokens of sequential data. However,
the primary limitation of this operation is its quadratic memory and time
complexity in relation to the input's context length - the length of a sequence
over which the interactions need to be captured. This significantly limits the
length of sequences that can be inferred upon by these models. Extensive
research has been conducted to reduce the number of pairwise interactions to
sub-quadratic in relation to the context length by introducing sparsity into
the attention mechanism through the development of sparse attention masks.
However, efficient implementations that achieve "true sparsity" are lacking.
  In this work, we address this issue by proposing a graph computing view of
attention where tokens are perceived as nodes of the graph and the attention
mask determines the edges of the graph. Using this view, we develop graph
processing algorithms to implement the attention mechanism. Both theoretically
and empirically, we demonstrate that our algorithms only perform the needed
computations, i.e., they are work optimal. We also perform extensive
experimentation using popular attention masks to explore the impact of sparsity
on execution time and achievable context length. Our experiments demonstrate
significant speedups in execution times compared to state-of-the-art attention
implementations such as FlashAttention for large sequence lengths. We also
demonstrate that our algorithms are able to achieve extremely long sequence
lengths of as high as 160 million on a single NVIDIA A100 GPU (SXM4 80GB).

æè¦ï¼è®å½¢éåå·²å¨è¨±å¤é åå±ç¾åºå·¨å¤§çæåï¼åæ¬èªç¶èªè¨èçåçç©è³è¨å­¸ãéç¨®æåæºèªæ¼éäºæ¨¡åä½¿ç¨æ³¨ææ©å¶ä¾è¡¨ç¤ºåå³æ­åºåè³æä¸­ååæ¨è¨ä¹éæå°çäºåãç¶èï¼éç¨®éç®çä¸»è¦éå¶å¨æ¼å¶äºæ¬¡è¨æ¶é«åæéè¤éåº¦èè¼¸å¥çå§å®¹é·åº¦æéï¼ä¹å°±æ¯éè¦æ·åäºåçåºåé·åº¦ãéæé¡¯èéå¶éäºæ¨¡åå¯ä»¥æ¨è«çåºåé·åº¦ãå·²ç¶é²è¡äºå¤§éçç ç©¶ä¾æ¸å°æå°äºåçæ¸éï¼ä½¿å¶èå§å®¹é·åº¦ææ¬¡äºæ¬¡éä¿ï¼æ¹æ³æ¯éééç¼ç¨çæ³¨æé®ç½©ä¾å°ç¨çæ§å¼å¥æ³¨ææ©å¶ãç¶èï¼ç¼ºä¹è½éæãçå¯¦ç¨çæ§ãçé«æå¯¦ä½ãå¨éé å·¥ä½ä¸­ï¼æåééæåºæ³¨æåçåå½¢éç®æª¢è¦ä¾è§£æ±ºéååé¡ï¼å¶ä¸­æ¨è¨è¢«è¦çºåå½¢çç¯é»ï¼èæ³¨æåé®ç½©åæ±ºå®åå½¢ä¸­çéç·£ãä½¿ç¨éç¨®æª¢è¦ï¼æåéç¼äºåå½¢èçæ¼ç®æ³ä¾å¯¦ä½æ³¨æåæ©å¶ãæåå¨çè«ä¸åç¶é©ä¸é½è­æäºæåçæ¼ç®æ³åªå·è¡å¿è¦çéç®ï¼ä¹å°±æ¯èªªï¼å®åæ¯å·¥ä½æåªçãæåä¹ä½¿ç¨æµè¡çæ³¨æåé®ç½©é²è¡å»£æ³çå¯¦é©ï¼ä»¥æ¢è¨ç¨çæ§å°å·è¡æéåå¯éæçå§å®¹é·åº¦çå½±é¿ãæåçå¯¦é©è­æï¼èæåé²çæ³¨æåå¯¦ä½ï¼ä¾å¦ FlashAttentionï¼ç¸æ¯ï¼å°æ¼å¤§ååºåé·åº¦ï¼æåçæ¼ç®æ³å¨å·è¡æéæ¹é¢æé¡¯èçå éãæåä¹è­æäºæåçæ¼ç®æ³è½å¤ å¨å®ä¸ç NVIDIA A100 GPU (SXM4 80GB) ä¸éææ¥µé·çåºåé·åº¦ï¼æé«å¯é 1.6 åã

##### **Improving vision-language alignment with graph spiking hybrid Networks**
2501.19069v1 by Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen

To bridge the semantic gap between vision and language (VL), it is necessary
to develop a good alignment strategy, which includes handling semantic
diversity, abstract representation of visual information, and generalization
ability of models. Recent works use detector-based bounding boxes or patches
with regular partitions to represent visual semantics. While current paradigms
have made strides, they are still insufficient for fully capturing the nuanced
contextual relations among various objects. This paper proposes a comprehensive
visual semantic representation module, necessitating the utilization of
panoptic segmentation to generate coherent fine-grained semantic features.
Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that
integrates the complementary advantages of Spiking Neural Networks (SNNs) and
Graph Attention Networks (GATs) to encode visual semantic information.
Intriguingly, the model not only encodes the discrete and continuous latent
variables of instances but also adeptly captures both local and global
contextual features, thereby significantly enhancing the richness and diversity
of semantic representations. Leveraging the spatiotemporal properties inherent
in SNNs, we employ contrastive learning (CL) to enhance the similarity-based
representation of embeddings. This strategy alleviates the computational
overhead of the model and enriches meaningful visual representations by
constructing positive and negative sample pairs. We design an innovative
pre-training method, Spiked Text Learning (STL), which uses text features to
improve the encoding ability of discrete semantics. Experiments show that the
proposed GSHN exhibits promising results on multiple VL downstream tasks.

æè¦ï¼<paragraph>çºäºå½åè¦è¦ºåèªè¨ (VL) ä¹éçèªæå·®è·ï¼å¿é å¶å®è¯å¥½çå°é½ç­ç¥ï¼å¶ä¸­åæ¬èçèªæå¤æ¨£æ§ãè¦è¦ºè³è¨çæ½è±¡è¡¨ç¤ºä»¥åæ¨¡åçæ³åè½åãæè¿çç ç©¶ä½¿ç¨åºæ¼åµæ¸¬å¨çéçæ¡æå·æè¦ååå²çåå¡ä¾è¡¨ç¤ºè¦è¦ºèªæãéç¶ç®åçç¯ä¾å·²åå¾é²å±ï¼ä½å°æ¼å®å¨ææåç¨®ç©ä»¶ä¹éçç´°å¾®èçµ¡éä¿ä»ä¸è¶³å¤ ãæ¬ææåºäºä¸åå¨é¢çè¦è¦ºèªæè¡¨ç¤ºæ¨¡çµï¼éè¦å©ç¨å¨æ¯åå²ä¾ç¢çé£è²«çç´°ç²åº¦èªæç¹å¾µãæ­¤å¤ï¼æåæåºäºä¸åæ°ç©çåå½¢èè¡æ··åç¶²è·¯ (GSHN)ï¼å®æ´åäºèè¡ç¥ç¶ç¶²è·¯ (SNN) ååå½¢æ³¨æåç¶²è·¯ (GAT) çäºè£åªå¢ä¾ç·¨ç¢¼è¦è¦ºèªæè³è¨ãæè¶£çæ¯ï¼è©²æ¨¡åä¸åç·¨ç¢¼å¯¦ä¾çé¢æ£åé£çºæ½å¨è®æ¸ï¼éè½å·§å¦å°ææå±é¨åå¨åèçµ¡ç¹å¾µï¼å¾èé¡¯èå¢å¼·èªæè¡¨ç¤ºçè±å¯æ§åå¤æ¨£æ§ãå©ç¨ SNN ä¸­åºæçæç©ºç¹æ§ï¼æåæ¡ç¨å°æ¯å­¸ç¿ (CL) ä¾å¢å¼·åµå¥çåºæ¼ç¸ä¼¼æ§çè¡¨ç¤ºãæ­¤ç­ç¥æ¸è¼äºæ¨¡åçè¨ç®è² æï¼ä¸¦ééå»ºæ§æ­£è² æ¨£æ¬å°ä¾è±å¯ææç¾©çè¦è¦ºè¡¨ç¤ºãæåè¨­è¨äºä¸ååµæ°çé è¨ç·´æ¹æ³ï¼èè¡ææ¬å­¸ç¿ (STL)ï¼å®ä½¿ç¨ææ¬ç¹å¾µä¾æé«é¢æ£èªæçç·¨ç¢¼è½åãå¯¦é©è¡¨æï¼ææåºç GSHN å¨å¤å VL ä¸æ¸¸ä»»åä¸å±ç¾åºæå¸æççµæã</paragraph>

##### **Semantic Web and Creative AI -- A Technical Report from ISWS 2023**
2501.18542v1 by Raia Abu Ahmad, Reham Alharbi, Roberto Barile, Martin BÃ¶ckling, Francisco Bolanos, Sara Bonfitto, Oleksandra Bruns, Irene Celino, Yashrajsinh Chudasama, Martin Critelli, Claudia d'Amato, Giada D'Ippolito, Ioannis Dasoulas, Stefano De Giorgis, Vincenzo De Leo, Chiara Di Bonaventura, Marco Di Panfilo, Daniil Dobriy, John Domingue, Xuemin Duan, Michel Dumontier, Sefika Efeoglu, Ruben Eschauzier, Fakih Ginwa, Nicolas Ferranti, Arianna Graciotti, Philipp Hanisch, George Hannah, Golsa Heidari, Aidan Hogan, Hassan Hussein, Alexane Jouglar, Jan-Christoph Kalo, ManoÃ© Kieffer, Antonis Klironomos, InÃªs Koch, Weronika Lajewska, Nicolas Lazzari, Mikael Lindekrans, Anna Sofia Lippolis, Majlinda Llugiqi, Eleonora Mancini, Eleonora Marzi, Laura Menotti, Daniela Milon Flores, Soulakshmee Nagowah, Kerstin Neubert, Emetis Niazmand, Ebrahim Norouzi, Beatriz Olarte Martinez, Anouk Michelle Oudshoorn, Andrea Poltronieri, Valentina Presutti, Disha Purohit, Ensiyeh Raoufi, Celian Ringwald, Johanna Rockstroh, Sebastian Rudolph, Harald Sack, Zafar Saeed, Mohammad Javad Saeedizade, Aya Sahbi, Cristian Santini, Aleksandra Simic, Dennis Sommer, Rita Sousa, Mary Ann Tan, Vidyashree Tarikere, Tabea Tietz, Liam Tirpitz, Arnaldo Tomasino, Frank van Harmelen, Joao Vissoci, Caitlin Woods, Bohui Zhang, Xinyue Zhang, Heng Zheng

The International Semantic Web Research School (ISWS) is a week-long
intensive program designed to immerse participants in the field. This document
reports a collaborative effort performed by ten teams of students, each guided
by a senior researcher as their mentor, attending ISWS 2023. Each team provided
a different perspective to the topic of creative AI, substantiated by a set of
research questions as the main subject of their investigation. The 2023 edition
of ISWS focuses on the intersection of Semantic Web technologies and Creative
AI. ISWS 2023 explored various intersections between Semantic Web technologies
and creative AI. A key area of focus was the potential of LLMs as support tools
for knowledge engineering. Participants also delved into the multifaceted
applications of LLMs, including legal aspects of creative content production,
humans in the loop, decentralised approaches to multimodal generative AI
models, nanopublications and AI for personal scientific knowledge graphs,
commonsense knowledge in automatic story and narrative completion, generative
AI for art critique, prompt engineering, automatic music composition,
commonsense prototyping and conceptual blending, and elicitation of tacit
knowledge. As Large Language Models and semantic technologies continue to
evolve, new exciting prospects are emerging: a future where the boundaries
between creative expression and factual knowledge become increasingly permeable
and porous, leading to a world of knowledge that is both informative and
inspiring.

æè¦ï¼åéèªæç¶²è·¯ç ç©¶å­¸æ ¡ (ISWS) æ¯ä¸åçºæä¸é±çå¯éèª²ç¨ï¼æ¨å¨è®åèèæ²æµ¸å¨è©²é åä¸­ãæ¬æä»¶å ±åäºç±ååå­¸çåéé²è¡çåä½ææï¼æ¯ååéé½ç±ä¸ä½è³æ·±ç ç©¶å¡ä½çºå°å¸«ï¼åå äº 2023 å¹´ ISWSãæ¯ååéé½å¾ä¸åçè§åº¦æ¢è¨äºåµæ AI ä¸»é¡ï¼ä¸¦ä»¥ä¸ç³»åç ç©¶åé¡ä½çºèª¿æ¥çä¸»è¦ä¸»é¡ã2023 å¹´çç ISWS éæ³¨æ¼èªæç¶²è·¯æè¡ååµæ AI çäº¤éãISWS 2023 æ¢ç´¢äºèªæç¶²è·¯æè¡ååµæ AI ä¹éçåç¨®äº¤éãä¸åéé»éæ³¨é åæ¯ LLM ä½çºç¥è­å·¥ç¨çæ¯æ´å·¥å·çæ½åãåèèéæ·±å¥æ¢è¨äº LLM çå¤æ¹é¢æç¨ï¼åæ¬åµæå§å®¹è£½ä½çæ³å¾æ¹é¢ãå¾ªç°ä¸­çäººé¡ãå¤æ¨¡æçæå¼ AI æ¨¡åçåæ£å¼æ¹æ³ãç´ç±³åºçç©åç¨æ¼åäººç§å­¸ç¥è­åè­ç AIãèªåæäºåæè¿°å®æä¸­çå¸¸è­ç¥è­ãçæå¼ AI ç¨æ¼èè¡è©è«ãæç¤ºå·¥ç¨ãèªåé³æ¨åµä½ãå¸¸è­åååæ¦å¿µæ··åï¼ä»¥åå°é»æç¥è­çå¼å°ãé¨èå¤§åèªè¨æ¨¡ååèªææè¡çæçºç¼å±ï¼æ°çä»¤äººèå¥®çåæ¯æ­£å¨åºç¾ï¼ä¸ååµæè¡¨éåäºå¯¦ç¥è­ä¹éççéè®å¾è¶ä¾è¶å¯æ»²éåå¤å­çæªä¾ï¼å¾èå°è´ä¸åæ¢æè³è¨æ§åæåç¼æ§çç¥è­ä¸çã

##### **Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**
2501.18320v1 by Tianpeng Pan, Wenqiang Pu, Licheng Zhao, Rui Zhou

Automated optimization modeling (AOM) has evoked considerable interest with
the rapid evolution of large language models (LLMs). Existing approaches
predominantly rely on prompt engineering, utilizing meticulously designed
expert response chains or structured guidance. However, prompt-based techniques
have failed to perform well in the sensor array signal processing (SASP) area
due the lack of specific domain knowledge. To address this issue, we propose an
automated modeling approach based on retrieval-augmented generation (RAG)
technique, which consists of two principal components: a multi-agent (MA)
structure and a graph-based RAG (Graph-RAG) process. The MA structure is
tailored for the architectural AOM process, with each agent being designed
based on principles of human modeling procedure. The Graph-RAG process serves
to match user query with specific SASP modeling knowledge, thereby enhancing
the modeling result. Results on ten classical signal processing problems
demonstrate that the proposed approach (termed as MAG-RAG) outperforms several
AOM benchmarks.

æè¦ï¼èªååæä½³åå»ºæ¨¡ (AOM) é¨èå¤§åèªè¨æ¨¡å (LLM) çå¿«éæ¼é²èå¼èµ·ç¸ç¶å¤§çèè¶£ãç¾ææ¹æ³ä¸»è¦ä¾è³´æç¤ºå·¥ç¨ï¼å©ç¨ç²¾å¿è¨­è¨çå°å®¶åæéæçµæ§åæå°ãç¶èï¼åºæ¼æç¤ºçæè¡ç±æ¼ç¼ºä¹ç¹å®é åç¥è­ï¼ç¡æ³å¨ææ¸¬å¨é£åè¨èèç (SASP) é åä¸­è¡¨ç¾è¯å¥½ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸ååºæ¼æª¢ç´¢å¢å¼·çæ (RAG) æè¡çèªååå»ºæ¨¡æ¹æ³ï¼å®åå«å©åä¸»è¦çµæé¨åï¼å¤ä»£ç (MA) çµæ§ååºæ¼åå½¢ç RAG (Graph-RAG) ç¨åºãMA çµæ§æ¯éå°æ¶æ§ AOM ç¨åºéèº«æé ï¼æ¯åä»£çé½æ¯æ ¹æäººé¡å»ºæ¨¡ç¨åºçåçè¨­è¨çãGraph-RAG ç¨åºç¨æ¼å°ä½¿ç¨èæ¥è©¢èç¹å®ç SASP å»ºæ¨¡ç¥è­ç¸å¹éï¼å¾èå¢å¼·å»ºæ¨¡çµæãå¨ååç¶å¸è¨èèçåé¡ä¸ççµæè¡¨æï¼ææåºçæ¹æ³ï¼ç¨±çº MAG-RAGï¼åªæ¼å¤å AOM åºæºã

##### **Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**
2501.18154v1 by Wanlong Liu, Yichen Xiao, Dingyi Zeng, Hongyang Zhao, Wenyu Chen, Malu Zhang

Post-Training Quantization (PTQ) is pivotal for deploying large language
models (LLMs) within resource-limited settings by significantly reducing
resource demands. However, existing PTQ strategies underperform at low bit
levels < 3 bits due to the significant difference between the quantized and
original weights. To enhance the quantization performance at low bit widths, we
introduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a
graph neural network (GNN) module to capture dependencies among weights and
adaptively assign quantization bit-widths. Through the information propagation
of the GNN module, our method more effectively captures dependencies among
target weights, leading to a more accurate assessment of weight importance and
optimized allocation of quantization strategies. Extensive experiments on the
WikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms
previous state-of-the-art PTQ method GPTQ, setting new benchmarks for
quantization performance under low-bit conditions.

æè¦ï¼è¨ç·´å¾éå (PTQ) å°æ¼å¨è³æºåéçè¨­å®ä¸­é¨ç½²å¤§åèªè¨æ¨¡å (LLM) è³ééè¦ï¼å çºå®è½é¡¯èéä½è³æºéæ±ãç¶èï¼ç¾æç PTQ ç­ç¥å¨ä½ä½åå±¤ç´ < 3 ä½åæè¡¨ç¾ä¸ä½³ï¼å çºéåå¾çæ¬éèåå§æ¬éä¹éæé¡¯èçå·®ç°ãçºäºæåä½ä½åå¯¬åº¦çéåæè½ï¼æåæåºæ··åç²¾åº¦åç¥ç¶ç¶²è·¯ PTQ (MG-PTQ) æ¹æ³ï¼æ¡ç¨åç¥ç¶ç¶²è·¯ (GNN) æ¨¡çµä¾æ·åæ¬éä¹éçä¾å­éä¿ï¼ä¸¦åæåééåä½åå¯¬åº¦ãéé GNN æ¨¡çµçè³è¨å³æ­ï¼æåçæ¹æ³è½æ´ææå°æ·åç®æ¨æ¬éä¹éçä¾å­éä¿ï¼é²èæ´æºç¢ºå°è©ä¼°æ¬ééè¦æ§ï¼ä¸¦æä½³åéåç­ç¥çéç½®ãå¨ WikiText2 å C4 è³æéä¸çå»£æ³å¯¦é©è­æï¼æåç MG-PTQ æ¹æ³åªæ¼ååçæåé² PTQ æ¹æ³ GPTQï¼å¨ä½ä½åæ¢ä»¶ä¸è¨­å®äºéåæè½çæ°åºæºã

##### **Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**
2501.18119v1 by Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

Due to the presence of the natural gap between Knowledge Graph (KG)
structures and the natural language, the effective integration of holistic
structural information of KGs with Large Language Models (LLMs) has emerged as
a significant question. To this end, we propose a two-stage framework to learn
and apply quantized codes for each entity, aiming for the seamless integration
of KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)
method is proposed to compress both KG structural and semantic knowledge into
discrete codes (\ie, tokens) that align the format of language sentences. We
further design KG instruction-following data by viewing these learned codes as
features to directly input to LLMs, thereby achieving seamless integration. The
experiment results demonstrate that SSQR outperforms existing unsupervised
quantized methods, producing more distinguishable codes. Further, the
fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link
prediction and triple classification tasks, utilizing only 16 tokens per entity
instead of thousands in conventional prompting methods.

æè¦ï¼ç±æ¼ç¥è­åè­ (KG) çµæ§èèªç¶èªè¨ä¹éå­å¨èªç¶å·®è·ï¼å° KG çæ´é«çµæ§è³è¨èå¤§åèªè¨æ¨¡å (LLM) æææ´åå·²æçºä¸åéè¦çåé¡ãçºæ­¤ï¼æåæåºäºä¸åå©éæ®µæ¶æ§ä¾å­¸ç¿åæç¨æ¯åå¯¦é«çéåç¢¼ï¼æ¨å¨å° KG è LLM ç¡ç¸«æ´åãé¦åï¼æåºäºä¸åèªç£ç£éåè¡¨ç¤º (SSQR) æ¹æ³ï¼å° KG çµæ§åèªç¾©ç¥è­å£ç¸®æé¢æ£ç¢¼ï¼å³ï¼ç¬¦èï¼ï¼ä»¥å°é½èªè¨å¥å­çæ ¼å¼ãæåé²ä¸æ­¥è¨­è¨ KG æä»¤éµå¾ªè³æï¼å°éäºå­¸ç¿å°çç¢¼è¦çºç´æ¥è¼¸å¥ LLM çç¹å¾µï¼å¾èå¯¦ç¾ç¡ç¸«æ´åãå¯¦é©çµæè¡¨æï¼SSQR åªæ¼ç¾æçç¡ç£ç£éåæ¹æ³ï¼ç¢çæ´å·åå¥æ§çç¢¼ãæ­¤å¤ï¼å¾®èª¿å¾ç LLaMA2 å LLaMA3.1 å¨ KG é£çµé æ¸¬åä¸ååé¡ä»»åä¸ä¹å·æåªç°çæ§è½ï¼æ¯åå¯¦é«åä½¿ç¨ 16 åç¬¦èï¼èä¸æ¯å³çµ±æç¤ºæ¹æ³ä¸­çæ¸ååã

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

æè¦ï¼åç­éè¦å°çµæ§åï¼è¡¨æ ¼ï¼åéçµæ§åï¼åå§æå­ï¼è³æä¾æºé²è¡æ¨çåå½ç¸½çåé¡æå¸¶ä¾éå¤§ææ°ãç®åçè¾¦æ³ä»°è³´å¾®èª¿åé«åè³ªãäººå·¥æ´ççè³æï¼èéå¾é£åå¾ãå¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±å·²éå°é¶æ¬¡å­¸ç¿è¨­å®çå®ä¸ä¾æºæå­è³æå¤è·³åé¡åç­ï¼QAï¼å±ç¾åºæå¸æççµæï¼ä½å°å¤ä¾æºè¡¨æ ¼æå­ QA çæ¢è¨ä»ç¶æéãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çåºæ¼æ··ååè¡¨çè¡¨æ ¼æå­ QA æ¹æ³ï¼å®å©ç¨ LLM èç¡éå¾®èª¿ãæåçè¾¦æ³å¾æå­åè¡¨æ ¼è³æå»ºæ§ä¸åçµ±ä¸çæ··ååè¡¨ï¼æ ¹æè¼¸å¥åé¡ä¿®åªè³è¨ï¼ä»¥ç°¡æ½å°çº LLM æä¾ç¸éèçµ¡ãæåä½¿ç¨æåé²ç LLMï¼åæ¬ GPT-3.5ãGPT-4 å LLaMA-3ï¼éå°å·æææ°æ§ç Hybrid-QA å OTT-QA è³æéè©ä¼°æåçè¾¦æ³ãæåçè¾¦æ³å¨å©åè³æéä¸é½éå°äºæä½³çé¶æ¬¡å­¸ç¿æè½ï¼å¨ Hybrid-QA ä¸å°å®å¨æ¯å°åæ¸æé«äº 10%ï¼å¨ OTT-QA ä¸å°å®å¨æ¯å°åæ¸æé«äº 5.4%ãæ­¤å¤ï¼èåå§èçµ¡ç¸æ¯ï¼æåçè¾¦æ³å°ç¬¦èä½¿ç¨éæ¸å°äº 53%ã

##### **Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**
2501.17549v1 by Wooyoung Kim, Byungyoon Park, Wooju Kim

Graph-structured data plays a vital role in numerous domains, such as social
networks, citation networks, commonsense reasoning graphs and knowledge graphs.
While graph neural networks have been employed for graph processing, recent
advancements have explored integrating large language models for graph-based
tasks. In this paper, we propose a novel approach named Learnable Graph Pooling
Token (LGPT), which addresses the limitations of the scalability issues in
node-level projection and information loss in graph-level projection. LGPT
enables flexible and efficient graph representation by introducing learnable
parameters that act as tokens in large language models, balancing fine-grained
and global graph information. Additionally, we investigate an Early Query
Fusion technique, which fuses query context before constructing the graph
representation, leading to more effective graph embeddings. Our method achieves
a 4.13\% performance improvement on the GraphQA benchmark without training the
large language model, demonstrating significant gains in handling complex
textual-attributed graph data.

æè¦ï¼åå½¢çµæ§è³æå¨è¨±å¤é åä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä¾å¦ç¤¾äº¤ç¶²è·¯ãå¼ç¨ç¶²è·¯ãå¸¸è­æ¨çåå½¢åç¥è­åå½¢ãéç¶åå½¢ç¥ç¶ç¶²è·¯å·²ç¨æ¼åå½¢èçï¼ä½æè¿çé²å±å·²æ¢è¨æ´åå¤§åèªè¨æ¨¡åä»¥é²è¡åºæ¼åå½¢çä»»åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®åçºå¯å­¸ç¿åå½¢æ± åä»¤ç (LGPT) çæ°æ¹æ³ï¼å®è§£æ±ºäºç¯é»å±¤ç´æå½±ä¸­çå¯æ´åæ§åé¡ååå½¢å±¤ç´æå½±ä¸­çè³è¨éºå¤±éå¶ãLGPT ééå¼å¥å¯å­¸ç¿çåæ¸ï¼å¨å¤§åèªè¨æ¨¡åä¸­ä½çºä»¤çéä½ï¼ä¾åç¨å½æ§åé«æçåå½¢è¡¨ç¤ºï¼å¹³è¡¡ç´°ç²åº¦åæ´é«åå½¢è³è¨ãæ­¤å¤ï¼æåç ç©¶äºä¸ç¨®æ©ææ¥è©¢èåæè¡ï¼å®å¨å»ºæ§åå½¢è¡¨ç¤ºä¹åèåæ¥è©¢å§å®¹ï¼é²èç¢çæ´ææçåå½¢åµå¥ãæåçæ¹æ³å¨ GraphQA åºæºä¸éå°äº 4.13% çæè½æåï¼èç¡éè¨ç·´å¤§åèªè¨æ¨¡åï¼è­æäºå¨èçè¤éçæå­å±¬æ§åå½¢è³ææ¹é¢æé¡¯èçé²å±ã

##### **General Scene Adaptation for Vision-and-Language Navigation**
2501.17403v1 by Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu

Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on
one-time execution of individual instructions across multiple environments,
aiming to develop agents capable of functioning in any environment in a
zero-shot manner. However, real-world navigation robots often operate in
persistent environments with relatively consistent physical layouts, visual
observations, and language styles from instructors. Such a gap in the task
setting presents an opportunity to improve VLN agents by incorporating
continuous adaptation to specific environments. To better reflect these
real-world conditions, we introduce GSA-VLN, a novel task requiring agents to
execute navigation instructions within a specific scene and simultaneously
adapt to it for improved performance over time. To evaluate the proposed task,
one has to address two challenges in existing VLN datasets: the lack of OOD
data, and the limited number and style diversity of instructions for each
scene. Therefore, we propose a new dataset, GSA-R2R, which significantly
expands the diversity and quantity of environments and instructions for the R2R
dataset to evaluate agent adaptability in both ID and OOD contexts.
Furthermore, we design a three-stage instruction orchestration pipeline that
leverages LLMs to refine speaker-generated instructions and apply role-playing
techniques to rephrase instructions into different speaking styles. This is
motivated by the observation that each individual user often has consistent
signatures or preferences in their instructions. We conducted extensive
experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various
methods. Based on our findings, we propose a novel method, GR-DUET, which
incorporates memory-based navigation graphs with an environment-specific
training strategy, achieving state-of-the-art results on all GSA-R2R splits.

æè¦ï¼è¦è¦ºèªè¨å°èª (VLN) ä»»åä¸»è¦æ ¹æä»£çç¨å¼å¨å¤åç°å¢ä¸­å·è¡åå¥æä»¤çä¸æ¬¡æ§å·è¡ä¾è©ä¼°ä»£çç¨å¼ï¼æ¨å¨éç¼è½å¤ å¨ä»»ä½ç°å¢ä¸­ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼éä½çä»£çç¨å¼ãç¶èï¼çå¯¦ä¸ççå°èªæ©å¨äººéå¸¸å¨æçºæ§çç°å¢ä¸­éä½ï¼èéäºç°å¢å·æç¸å°ä¸è´çç©çéç½®ãè¦è¦ºè§å¯åæä»¤çèªè¨é¢¨æ ¼ãä»»åè¨­å®ä¸­çéç¨®å·®è·æä¾äºä¸åæ©æï¼å¯ä»¥ééå°é£çºé©æç¹å®ç°å¢ç´å¥å¶ä¸­ä¾æ¹å VLN ä»£çç¨å¼ãçºäºæ´å¥½å°åæ éäºçå¯¦ä¸ççæ¢ä»¶ï¼æåæ¨åºäº GSA-VLNï¼éæ¯ä¸åæ°ä»»åï¼è¦æ±ä»£çç¨å¼å¨ç¹å®å ´æ¯ä¸­å·è¡å°èªæä»¤ï¼ä¸¦åæé©æè©²å ´æ¯ï¼ä»¥é¨èæéæ¨ç§»èæé«æè½ãçºäºè©ä¼°ææåºçä»»åï¼å¿é è§£æ±ºç¾æ VLN è³æéä¸­çå©åææ°ï¼ç¼ºä¹ OOD è³æï¼ä»¥åæ¯åå ´æ¯çæä»¤æ¸éåé¢¨æ ¼å¤æ¨£æ§æéãå æ­¤ï¼æåæåºäºä¸åæ°çè³æé GSA-R2Rï¼å®é¡¯èæ´å±äº R2R è³æéçç°å¢åæä»¤çå¤æ¨£æ§åæ¸éï¼ä»¥è©ä¼°ä»£çç¨å¼å¨ ID å OOD èæ¯ä¸çé©æè½åãæ­¤å¤ï¼æåè¨­è¨äºä¸åä¸éæ®µæä»¤ç·¨æç®¡éï¼è©²ç®¡éå©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾ç²¾çç±èªªè©±èç¢ççæä»¤ï¼ä¸¦æç¨è§è²æ®æ¼æå·§å°æä»¤æ¹å¯«æä¸åçèªªè©±é¢¨æ ¼ãéé æè¡çéæä¾èªæ¼è§å¯å°æ¯ååå¥ä½¿ç¨èéå¸¸å¨å¶æä»¤ä¸­å·æç¸ç¬¦çç°½åæåå¥½ãæåéå° GSA-R2R é²è¡äºå¤§éçå¯¦é©ï¼ä»¥å¾¹åºè©ä¼°æåçè³æéååºæºåç¨®æ¹æ³ãæ ¹ææåçç ç©¶çµæï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ GR-DUETï¼å®å°åºæ¼è¨æ¶çå°èªåè¡¨èç¹å®æ¼ç°å¢çè¨ç·´ç­ç¥çµåå¨ä¸èµ·ï¼å¨ææ GSA-R2R åå²ä¸­åå¾äºæåé²ççµæã

##### **Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**
2501.17270v1 by Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li

Question answering systems for knowledge graph (KGQA), answer factoid
questions based on the data in the knowledge graph. KGQA systems are complex
because the system has to understand the relations and entities in the
knowledge-seeking natural language queries and map them to structured queries
against the KG to answer them. In this paper, we introduce Chronos, a
comprehensive evaluation framework for KGQA at industry scale. It is designed
to evaluate such a multi-component system comprehensively, focusing on (1)
end-to-end and component-level metrics, (2) scalable to diverse datasets and
(3) a scalable approach to measure the performance of the system prior to
release. In this paper, we discuss the unique challenges associated with
evaluating KGQA systems at industry scale, review the design of Chronos, and
how it addresses these challenges. We will demonstrate how it provides a base
for data-driven decisions and discuss the challenges of using it to measure and
improve a real-world KGQA system.

æè¦ï¼ç¥è­åè­åç­ç³»çµ± (KGQA) æ ¹æç¥è­åè­ä¸­çè³æåç­äºå¯¦åé¡ãKGQA ç³»çµ±å¾è¤éï¼å çºç³»çµ±å¿é çè§£ç¥è­å°æ±èªç¶èªè¨æ¥è©¢ä¸­çéä¿åå¯¦é«ï¼ä¸¦å°å®åå°æ å°éå°ç¥è­åè­ççµæ§åæ¥è©¢ï¼æè½åç­éäºæ¥è©¢ãå¨æ¬æä¸­ï¼æåä»ç´¹äº Chronosï¼éæ¯ä¸åç¨æ¼ç¢æ¥­è¦æ¨¡ KGQA çå¨é¢è©ä¼°æ¡æ¶ãå®æ¨å¨å¨é¢è©ä¼°éç¨®å¤çµä»¶ç³»çµ±ï¼éé»éæ³¨ï¼(1) ç«¯å°ç«¯åçµä»¶å±¤ç´ææ¨ï¼(2) å¯æ´åè³åç¨®è³æéï¼ä»¥å (3) å¯æ´åçæ¹æ³ï¼ç¨æ¼å¨éåºåè¡¡éç³»çµ±çæè½ãå¨æ¬æä¸­ï¼æåè¨è«äºèç¢æ¥­è¦æ¨¡ KGQA ç³»çµ±è©ä¼°ç¸éçç¨ç¹ææ°ï¼æª¢è¦ Chronos çè¨­è¨ï¼ä»¥åå®å¦ä½æå°éäºææ°ãæåå°å±ç¤ºå®å¦ä½æä¾è³æé©åæ±ºç­çåºç¤ï¼ä¸¦è¨è«ä½¿ç¨å®ä¾è¡¡éåæ¹åçå¯¦ä¸ç KGQA ç³»çµ±çææ°ã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-18**|**SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation**|Zekun Qi et.al.|[2502.13143v1](http://arxiv.org/abs/2502.13143v1)|null|
|**2025-02-18**|**Pre-training Auto-regressive Robotic Models with 4D Representations**|Dantong Niu et.al.|[2502.13142v1](http://arxiv.org/abs/2502.13142v1)|null|
|**2025-02-18**|**UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor Attacks and Adversarial Attacks in Large Language Models**|Huawei Lin et.al.|[2502.13141v1](http://arxiv.org/abs/2502.13141v1)|null|
|**2025-02-18**|**AIDE: AI-Driven Exploration in the Space of Code**|Zhengyao Jiang et.al.|[2502.13138v1](http://arxiv.org/abs/2502.13138v1)|null|
|**2025-02-18**|**Theorem Prover as a Judge for Synthetic Data Generation**|Joshua Ong Jun Leang et.al.|[2502.13137v1](http://arxiv.org/abs/2502.13137v1)|null|
|**2025-02-18**|**Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions**|Taedong Yun et.al.|[2502.13135v1](http://arxiv.org/abs/2502.13135v1)|null|
|**2025-02-18**|**Learning to Defer for Causal Discovery with Imperfect Experts**|Oscar Clivio et.al.|[2502.13132v1](http://arxiv.org/abs/2502.13132v1)|null|
|**2025-02-18**|**Rethinking Diverse Human Preference Learning through Principal Component Analysis**|Feng Luo et.al.|[2502.13131v1](http://arxiv.org/abs/2502.13131v1)|null|
|**2025-02-18**|**Magma: A Foundation Model for Multimodal AI Agents**|Jianwei Yang et.al.|[2502.13130v1](http://arxiv.org/abs/2502.13130v1)|null|
|**2025-02-18**|**SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation**|Zihan Liu et.al.|[2502.13128v1](http://arxiv.org/abs/2502.13128v1)|null|
|**2025-02-18**|**Facilitating Long Context Understanding via Supervised Chain-of-Thought Reasoning**|Jingyang Lin et.al.|[2502.13127v1](http://arxiv.org/abs/2502.13127v1)|null|
|**2025-02-18**|**RuozhiBench: Evaluating LLMs with Logical Fallacies and Misleading Premises**|Zenan Zhai et.al.|[2502.13125v1](http://arxiv.org/abs/2502.13125v1)|null|
|**2025-02-18**|**NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions**|Weizhe Yuan et.al.|[2502.13124v1](http://arxiv.org/abs/2502.13124v1)|null|
|**2025-02-18**|**Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language in a Coreference Context**|Marion Bartl et.al.|[2502.13120v1](http://arxiv.org/abs/2502.13120v1)|null|
|**2025-02-18**|**STEER-ME: Assessing the Microeconomic Reasoning of Large Language Models**|Narun Raman et.al.|[2502.13119v1](http://arxiv.org/abs/2502.13119v1)|null|
|**2025-02-18**|**Performance Evaluation of Large Language Models in Statistical Programming**|Xinyi Song et.al.|[2502.13117v1](http://arxiv.org/abs/2502.13117v1)|null|
|**2025-02-18**|**Near-Optimal Private Learning in Linear Contextual Bandits**|Fan Chen et.al.|[2502.13115v1](http://arxiv.org/abs/2502.13115v1)|null|
|**2025-02-18**|**The influence of motion features in temporal perception**|Rosa Illan Castillo et.al.|[2502.13114v1](http://arxiv.org/abs/2502.13114v1)|null|
|**2025-02-18**|**Improving Clinical Question Answering with Multi-Task Learning: A Joint Approach for Answer Extraction and Medical Categorization**|Priyaranjan Pattnayak et.al.|[2502.13108v1](http://arxiv.org/abs/2502.13108v1)|null|
|**2025-02-18**|**MatterChat: A Multi-Modal LLM for Material Science**|Yingheng Tang et.al.|[2502.13107v1](http://arxiv.org/abs/2502.13107v1)|null|
|**2025-02-18**|**Understanding and Rectifying Safety Perception Distortion in VLMs**|Xiaohan Zou et.al.|[2502.13095v1](http://arxiv.org/abs/2502.13095v1)|null|
|**2025-02-18**|**Text2World: Benchmarking Large Language Models for Symbolic World Model Generation**|Mengkang Hu et.al.|[2502.13092v1](http://arxiv.org/abs/2502.13092v1)|null|
|**2025-02-18**|**KAPPA: A Generic Patent Analysis Framework with Keyphrase-Based Portraits**|Xin Xia et.al.|[2502.13076v1](http://arxiv.org/abs/2502.13076v1)|null|
|**2025-02-18**|**Interactive Agents to Overcome Ambiguity in Software Engineering**|Sanidhya Vijayvargiya et.al.|[2502.13069v1](http://arxiv.org/abs/2502.13069v1)|null|
|**2025-02-18**|**Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity**|Yuri Kuratov et.al.|[2502.13063v1](http://arxiv.org/abs/2502.13063v1)|null|
|**2025-02-18**|**AI-Assisted Decision Making with Human Learning**|Gali Noti et.al.|[2502.13062v1](http://arxiv.org/abs/2502.13062v1)|null|
|**2025-02-18**|**Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection**|Jingbiao Mei et.al.|[2502.13061v1](http://arxiv.org/abs/2502.13061v1)|null|
|**2025-02-18**|**SimpleVQA: Multimodal Factuality Evaluation for Multimodal Large Language Models**|Xianfu Cheng et.al.|[2502.13059v1](http://arxiv.org/abs/2502.13059v1)|null|
|**2025-02-18**|**LAMD: Context-driven Android Malware Detection and Classification with LLMs**|Xingzhi Qian et.al.|[2502.13055v1](http://arxiv.org/abs/2502.13055v1)|null|
|**2025-02-18**|**Do we still need Human Annotators? Prompting Large Language Models for Aspect Sentiment Quad Prediction**|Nils Constantin Hellwig et.al.|[2502.13044v1](http://arxiv.org/abs/2502.13044v1)|null|
|**2025-02-18**|**Natural Language Generation from Visual Sequences: Challenges and Future Directions**|Aditya K Surikuchi et.al.|[2502.13034v1](http://arxiv.org/abs/2502.13034v1)|null|
|**2025-02-18**|**HPSS: Heuristic Prompting Strategy Search for LLM Evaluators**|Bosi Wen et.al.|[2502.13031v1](http://arxiv.org/abs/2502.13031v1)|null|
|**2025-02-18**|**Whose story is it? Personalizing story generation by inferring author styles**|Nischal Ashok Kumar et.al.|[2502.13028v1](http://arxiv.org/abs/2502.13028v1)|null|
|**2025-02-18**|**Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks**|Markus J. Buehler et.al.|[2502.13025v1](http://arxiv.org/abs/2502.13025v1)|null|
|**2025-02-18**|**Oreo: A Plug-in Context Reconstructor to Enhance Retrieval-Augmented Generation**|Sha Li et.al.|[2502.13019v1](http://arxiv.org/abs/2502.13019v1)|null|
|**2025-02-18**|**LLM-Powered Proactive Data Systems**|Sepanta Zeighami et.al.|[2502.13016v1](http://arxiv.org/abs/2502.13016v1)|null|
|**2025-02-18**|**Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents**|Chaoran Chen et.al.|[2502.13012v1](http://arxiv.org/abs/2502.13012v1)|null|
|**2025-02-18**|**Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge**|Mohammad Reza Rezaei et.al.|[2502.13010v1](http://arxiv.org/abs/2502.13010v1)|null|
|**2025-02-18**|**Integrating Reinforcement Learning, Action Model Learning, and Numeric Planning for Tackling Complex Tasks**|Yarin Benyamin et.al.|[2502.13006v1](http://arxiv.org/abs/2502.13006v1)|null|
|**2025-02-18**|**Language Barriers: Evaluating Cross-Lingual Performance of CNN and Transformer Architectures for Speech Quality Estimation**|Wafaa Wardah et.al.|[2502.13004v1](http://arxiv.org/abs/2502.13004v1)|null|
|**2025-02-18**|**You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations**|Frederic Kirstein et.al.|[2502.13001v1](http://arxiv.org/abs/2502.13001v1)|null|
|**2025-02-18**|**Personalized Top-k Set Queries Over Predicted Scores**|Sohrab Namazi Nia et.al.|[2502.12998v1](http://arxiv.org/abs/2502.12998v1)|null|
|**2025-02-18**|**Eager Updates For Overlapped Communication and Computation in DiLoCo**|Satyen Kale et.al.|[2502.12996v1](http://arxiv.org/abs/2502.12996v1)|null|
|**2025-02-18**|**Free Argumentative Exchanges for Explaining Image Classifiers**|Avinash Kori et.al.|[2502.12995v1](http://arxiv.org/abs/2502.12995v1)|null|
|**2025-02-18**|**B-cos LM: Efficiently Transforming Pre-trained Language Models for Improved Explainability**|Yifan Wang et.al.|[2502.12992v1](http://arxiv.org/abs/2502.12992v1)|null|
|**2025-02-18**|**Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs**|Zixiao Wang et.al.|[2502.12988v1](http://arxiv.org/abs/2502.12988v1)|null|
|**2025-02-18**|**PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization**|Nicolas Talabot et.al.|[2502.12985v1](http://arxiv.org/abs/2502.12985v1)|null|
|**2025-02-18**|**Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs**|Longxu Dou et.al.|[2502.12982v1](http://arxiv.org/abs/2502.12982v1)|null|
|**2025-02-18**|**Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking**|Junda Zhu et.al.|[2502.12970v1](http://arxiv.org/abs/2502.12970v1)|null|
|**2025-02-18**|**A Survey of Text Classification Under Class Distribution Shift**|Adriana Valentina Costache et.al.|[2502.12965v1](http://arxiv.org/abs/2502.12965v1)|null|
|**2025-02-18**|**Trust Me, I'm Wrong: High-Certainty Hallucinations in LLMs**|Adi Simhi et.al.|[2502.12964v1](http://arxiv.org/abs/2502.12964v1)|null|
|**2025-02-18**|**Infinite Retrieval: Attention Enhanced LLMs in Long-Context Processing**|Xiaoju Ye et.al.|[2502.12962v1](http://arxiv.org/abs/2502.12962v1)|null|
|**2025-02-18**|**Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger**|Wenjun Li et.al.|[2502.12961v1](http://arxiv.org/abs/2502.12961v1)|null|
|**2025-02-18**|**AlignFreeze: Navigating the Impact of Realignment on the Layers of Multilingual Models Across Diverse Languages**|Steve Bakos et.al.|[2502.12959v1](http://arxiv.org/abs/2502.12959v1)|null|
|**2025-02-18**|**Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text**|Andrei Jarca et.al.|[2502.12953v1](http://arxiv.org/abs/2502.12953v1)|null|
|**2025-02-18**|**Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection**|Athira J Jacob et.al.|[2502.12948v1](http://arxiv.org/abs/2502.12948v1)|null|
|**2025-02-18**|**Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models**|Gyeongman Kim et.al.|[2502.12947v1](http://arxiv.org/abs/2502.12947v1)|null|
|**2025-02-18**|**LLMPopcorn: An Empirical Study of LLMs as Assistants for Popular Micro-video Generation**|Junchen Fu et.al.|[2502.12945v1](http://arxiv.org/abs/2502.12945v1)|null|
|**2025-02-18**|**Synthetic Data Generation for Culturally Nuanced Commonsense Reasoning in Low-Resource Languages**|Salsabila Zahirah Pranida et.al.|[2502.12932v1](http://arxiv.org/abs/2502.12932v1)|null|
|**2025-02-18**|**Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options**|Lakshmi Nair et.al.|[2502.12929v1](http://arxiv.org/abs/2502.12929v1)|null|
|**2025-02-18**|**Finedeep: Mitigating Sparse Activation in Dense LLMs via Multi-Layer Fine-Grained Experts**|Leiyu Pan et.al.|[2502.12928v1](http://arxiv.org/abs/2502.12928v1)|null|
|**2025-02-18**|**SEFL: Harnessing Large Language Model Agents to Improve Educational Feedback Systems**|Mike Zhang et.al.|[2502.12927v1](http://arxiv.org/abs/2502.12927v1)|null|
|**2025-02-18**|**Towards more Contextual Agents: An extractor-Generator Optimization Framework**|Mourad Aouini et.al.|[2502.12926v1](http://arxiv.org/abs/2502.12926v1)|null|
|**2025-02-18**|**Keep what you need : extracting efficient subnetworks from large audio representation models**|David Genova et.al.|[2502.12925v1](http://arxiv.org/abs/2502.12925v1)|null|
|**2025-02-18**|**Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded in Naturally Occurring Data**|Maite Heredia et.al.|[2502.12924v1](http://arxiv.org/abs/2502.12924v1)|null|
|**2025-02-18**|**On-Device LLMs for Home Assistant: Dual Role in Intent Detection and Response Generation**|Rune Birkmose et.al.|[2502.12923v1](http://arxiv.org/abs/2502.12923v1)|null|
|**2025-02-18**|**Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison**|George-Kirollos Saad et.al.|[2502.12921v1](http://arxiv.org/abs/2502.12921v1)|null|
|**2025-02-18**|**GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning**|Sifan Zhou et.al.|[2502.12913v1](http://arxiv.org/abs/2502.12913v1)|null|
|**2025-02-18**|**Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation**|Zheng Yuan et.al.|[2502.12911v1](http://arxiv.org/abs/2502.12911v1)|null|
|**2025-02-18**|**Graph Neural Networks for Databases: A Survey**|Ziming Li et.al.|[2502.12908v1](http://arxiv.org/abs/2502.12908v1)|null|
|**2025-02-18**|**Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements**|Shu Yang et.al.|[2502.12904v1](http://arxiv.org/abs/2502.12904v1)|null|
|**2025-02-18**|**Soundwave: Less is More for Speech-Text Alignment in LLMs**|Yuhao Zhang et.al.|[2502.12900v1](http://arxiv.org/abs/2502.12900v1)|null|
|**2025-02-18**|**None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks**|Eva SÃ¡nchez Salido et.al.|[2502.12896v1](http://arxiv.org/abs/2502.12896v1)|null|
|**2025-02-18**|**Multilingual European Language Models: Benchmarking Approaches and Challenges**|Fabio Barth et.al.|[2502.12895v1](http://arxiv.org/abs/2502.12895v1)|null|
|**2025-02-18**|**H-CoT: Hijacking the Chain-of-Thought Safety Reasoning Mechanism to Jailbreak Large Reasoning Models, Including OpenAI o1/o3, DeepSeek-R1, and Gemini 2.0 Flash Thinking**|Martin Kuo et.al.|[2502.12893v1](http://arxiv.org/abs/2502.12893v1)|null|
|**2025-02-18**|**Are Multilingual Language Models an Off-ramp for Under-resourced Languages? Will we arrive at Digital Language Equality in Europe in 2030?**|Georg Rehm et.al.|[2502.12886v1](http://arxiv.org/abs/2502.12886v1)|null|
|**2025-02-18**|**How desirable is alignment between LLMs and linguistically diverse human users?**|Pia Knoeferle et.al.|[2502.12884v1](http://arxiv.org/abs/2502.12884v1)|null|
|**2025-02-18**|**Continuous Learning Conversational AI: A Personalized Agent Framework via A2C Reinforcement Learning**|Nandakishor M et.al.|[2502.12876v1](http://arxiv.org/abs/2502.12876v1)|null|
|**2025-02-18**|**PAFT: Prompt-Agnostic Fine-Tuning**|Chenxing Wei et.al.|[2502.12859v1](http://arxiv.org/abs/2502.12859v1)|null|
|**2025-02-18**|**Rejected Dialects: Biases Against African American Language in Reward Models**|Joel Mire et.al.|[2502.12858v1](http://arxiv.org/abs/2502.12858v1)|null|
|**2025-02-18**|**Integrating Arithmetic Learning Improves Mathematical Reasoning in Smaller Models**|Neeraj Gangwar et.al.|[2502.12855v1](http://arxiv.org/abs/2502.12855v1)|null|
|**2025-02-18**|**S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning**|Ruotian Ma et.al.|[2502.12853v1](http://arxiv.org/abs/2502.12853v1)|null|
|**2025-02-18**|**MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching**|Fabian David Schmidt et.al.|[2502.12852v1](http://arxiv.org/abs/2502.12852v1)|null|
|**2025-02-18**|**MeMo: Towards Language Models with Associative Memory Mechanisms**|Fabio Massimo Zanzotto et.al.|[2502.12851v1](http://arxiv.org/abs/2502.12851v1)|null|
|**2025-02-18**|**Towards Adaptive Feedback with AI: Comparing the Feedback Quality of LLMs and Teachers on Experimentation Protocols**|Kathrin SeÃler et.al.|[2502.12842v1](http://arxiv.org/abs/2502.12842v1)|null|
|**2025-02-18**|**Towards Equitable AI: Detecting Bias in Using Large Language Models for Marketing**|Berk Yilmaz et.al.|[2502.12838v1](http://arxiv.org/abs/2502.12838v1)|null|
|**2025-02-18**|**An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation**|Mohammad Feli et.al.|[2502.12836v1](http://arxiv.org/abs/2502.12836v1)|null|
|**2025-02-18**|**Subword models struggle with word learning, but surprisal hides it**|Bastian Bunzeck et.al.|[2502.12835v1](http://arxiv.org/abs/2502.12835v1)|null|
|**2025-02-18**|**KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan**|Mukhammed Togmanov et.al.|[2502.12829v1](http://arxiv.org/abs/2502.12829v1)|null|
|**2025-02-18**|**Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models**|Rubing Lu et.al.|[2502.12825v1](http://arxiv.org/abs/2502.12825v1)|null|
|**2025-02-18**|**Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models**|Elena Stringli et.al.|[2502.12821v1](http://arxiv.org/abs/2502.12821v1)|null|
|**2025-02-18**|**Simulating User Diversity in Task-Oriented Dialogue Systems using Large Language Models**|Adnan Ahmad et.al.|[2502.12813v1](http://arxiv.org/abs/2502.12813v1)|null|
|**2025-02-18**|**Towards Text-Image Interleaved Retrieval**|Xin Zhang et.al.|[2502.12799v1](http://arxiv.org/abs/2502.12799v1)|null|
|**2025-02-18**|**Envious Explore and Exploit**|Omer Ben-Porat et.al.|[2502.12798v1](http://arxiv.org/abs/2502.12798v1)|null|
|**2025-02-18**|**Commonsense Reasoning in Arab Culture**|Abdelrahman Sadallah et.al.|[2502.12788v1](http://arxiv.org/abs/2502.12788v1)|null|
|**2025-02-18**|**VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation**|Xinlong Chen et.al.|[2502.12782v1](http://arxiv.org/abs/2502.12782v1)|null|
|**2025-02-18**|**Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models**|Daiki Chijiwa et.al.|[2502.12776v1](http://arxiv.org/abs/2502.12776v1)|null|
|**2025-02-18**|**Mind the Gap: Aligning the Brain with Language Models Requires a Nonlinear and Multimodal Approach**|Danny Dongyeop Han et.al.|[2502.12771v1](http://arxiv.org/abs/2502.12771v1)|null|
|**2025-02-18**|**How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild**|Saad Obaid ul Islam et.al.|[2502.12769v1](http://arxiv.org/abs/2502.12769v1)|null|
|**2025-02-18**|**R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs**|Sumin Jo et.al.|[2502.12767v1](http://arxiv.org/abs/2502.12767v1)|null|

#### Abstracts
##### **SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation**
2502.13143v1 by Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen Li, Lingyun Xu, Baoyu Li, Xialin He, Guofan Fan, Jiazhao Zhang, Jiawei He, Jiayuan Gu, Xin Jin, Kaisheng Ma, Zhizheng Zhang, He Wang, Li Yi

Spatial intelligence is a critical component of embodied AI, promoting robots
to understand and interact with their environments. While recent advances have
enhanced the ability of VLMs to perceive object locations and positional
relationships, they still lack the capability to precisely understand object
orientations-a key requirement for tasks involving fine-grained manipulations.
Addressing this limitation not only requires geometric reasoning but also an
expressive and intuitive way to represent orientation. In this context, we
propose that natural language offers a more flexible representation space than
canonical frames, making it particularly suitable for instruction-following
robotic systems. In this paper, we introduce the concept of semantic
orientation, which defines object orientations using natural language in a
reference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the
''handle'' direction of a knife). To support this, we construct OrienText300K,
a large-scale dataset of 3D models annotated with semantic orientations that
link geometric understanding to functional semantics. By integrating semantic
orientation into a VLM system, we enable robots to generate manipulation
actions with both positional and orientational constraints. Extensive
experiments in simulation and real world demonstrate that our approach
significantly enhances robotic manipulation capabilities, e.g., 48.7% accuracy
on Open6DOR and 74.9% accuracy on SIMPLER.

æè¦ï¼ç©ºéæºè½æ¯å·è±¡ AI çééµçµæé¨åï¼ä¿ä½¿æ©å¨äººäºè§£å¶ç°å¢ä¸¦èä¹äºåãéç¶æè¿çé²å±å¢å¼·äº VLM æç¥ç©ä»¶ä½ç½®åä½ç½®éä¿çè½åï¼ä½å®åä»ç¶ç¼ºä¹ç²¾ç¢ºçè§£ç©ä»¶æ¹åçè½åï¼éå°æ¼æ¶åç´°å¾®æä½çä»»åä¾èªªæ¯ä¸é ééµè¦æ±ãè§£æ±ºéåéå¶ä¸åéè¦å¹¾ä½æ¨çï¼ééè¦ä¸ç¨®è¡¨éæ§åç´è§çæ¹å¼ä¾è¡¨ç¤ºæ¹åãå¨æ­¤èæ¯ä¸ï¼æåæåºèªç¶èªè¨æä¾äºä¸åæ¯æ¨æºæ¡æ¶æ´éæ´»çè¡¨ç¤ºç©ºéï¼ä½¿å¶ç¹å¥é©åæ¼éµå¾ªæä»¤çæ©å¨äººç³»çµ±ãå¨æ¬æä¸­ï¼æåä»ç´¹äºèªç¾©æ¹åçæ¦å¿µï¼å®ä½¿ç¨èªç¶èªè¨ä»¥ç¡åèæ¡æ¶çæ¹å¼å®ç¾©ç©ä»¶æ¹åï¼ä¾å¦ï¼USB çãæå¥ãæ¹åæåå­çãæ¡æãæ¹åï¼ãçºäºæ¯æéä¸é»ï¼æåæ§å»ºäº OrienText300Kï¼éæ¯ä¸åå¤§å 3D æ¨¡åæ¸æéï¼å¶ä¸­è¨»éäºèªç¾©æ¹åï¼å°å¹¾ä½çè§£èåè½èªç¾©è¯ç¹«èµ·ä¾ãééå°èªç¾©æ¹åæ´åå° VLM ç³»çµ±ä¸­ï¼æåä½¿æ©å¨äººè½å¤ çæåæå·æä½ç½®åæ¹åç´æçæä½åä½ãå¨æ¨¡æ¬åç¾å¯¦ä¸çä¸­é²è¡çå»£æ³å¯¦é©è¡¨æï¼æåçåæ³é¡¯èå¢å¼·äºæ©å¨äººçæä½è½åï¼ä¾å¦ï¼Open6DOR çæºç¢ºççº 48.7%ï¼SIMPLER çæºç¢ºççº 74.9%ã

##### **Pre-training Auto-regressive Robotic Models with 4D Representations**
2502.13142v1 by Dantong Niu, Yuvan Sharma, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrell, Roei Herzig

Foundation models pre-trained on massive unlabeled datasets have
revolutionized natural language and computer vision, exhibiting remarkable
generalization capabilities, thus highlighting the importance of pre-training.
Yet, efforts in robotics have struggled to achieve similar success, limited by
either the need for costly robotic annotations or the lack of representations
that effectively model the physical world. In this paper, we introduce ARM4R,
an Auto-regressive Robotic Model that leverages low-level 4D Representations
learned from human video data to yield a better pre-trained robotic model.
Specifically, we focus on utilizing 3D point tracking representations from
videos derived by lifting 2D representations into 3D space via monocular depth
estimation across time. These 4D representations maintain a shared geometric
structure between the points and robot state representations up to a linear
transformation, enabling efficient transfer learning from human video data to
low-level robotic control. Our experiments show that ARM4R can transfer
efficiently from human video data to robotics and consistently improves
performance on tasks across various robot environments and configurations.

æè¦ï¼é åå¨å¤§éæªæ¨è¨è³æéä¸è¨ç·´å¥½çåºç¤æ¨¡åå·²ç¶å¾¹åºæ¹è®äºèªç¶èªè¨åé»è¦è¦è¦ºï¼å±ç¾åºéå¡çæ¦åè½åï¼å æ­¤çªé¡¯äºé åè¨ç·´çéè¦æ§ãç¶èï¼æ©å¨äººé åçåªåä¸ç´é£ä»¥åå¾é¡ä¼¼çæåï¼åå°æè²´çæ©å¨äººæ¨è¨»éæ±æç¼ºä¹ææå»ºæ¨¡ç©çä¸ççè¡¨å¾µçéå¶ãå¨æ¬æä¸­ï¼æåä»ç´¹äº ARM4Rï¼ä¸ç¨®èªè¿´æ­¸æ©å¨äººæ¨¡åï¼å®å©ç¨å¾äººé¡å½±çè³æä¸­å­¸ç¿å°çä½é 4D è¡¨å¾µï¼ä»¥ç¢çæ´å¥½çé åè¨ç·´æ©å¨äººæ¨¡åãå·é«ä¾èªªï¼æåå°æ³¨æ¼å©ç¨å¾å½±çä¸­ç²å¾ç 3D é»è¿½è¹¤è¡¨å¾µï¼éäºè¡¨å¾µæ¯ééå®ç¼æ·±åº¦ä¼°è¨è·¨æéå° 2D è¡¨å¾µæåå° 3D ç©ºéèå°åºçãéäº 4D è¡¨å¾µå¨é»åæ©å¨äººçæè¡¨å¾µä¹éä¿æä¸åå±ç¨çå¹¾ä½çµæ§ï¼ç´å°ä¸åç·æ§è½æï¼éä½¿å¾å¾äººé¡å½±çè³æå°ä½éæ©å¨äººæ§å¶çææé·ç§»å­¸ç¿æçºå¯è½ãæåçå¯¦é©è¡¨æï¼ARM4R å¯ä»¥ææå°å¾äººé¡å½±çè³æè½ç§»å°æ©å¨äººæè¡ï¼ä¸¦æçºæ¹ååç¨®æ©å¨äººç°å¢åçµæä¸­çä»»åæè½ã

##### **UniGuardian: A Unified Defense for Detecting Prompt Injection, Backdoor Attacks and Adversarial Attacks in Large Language Models**
2502.13141v1 by Huawei Lin, Yingjie Lao, Tong Geng, Tan Yu, Weijie Zhao

Large Language Models (LLMs) are vulnerable to attacks like prompt injection,
backdoor attacks, and adversarial attacks, which manipulate prompts or models
to generate harmful outputs. In this paper, departing from traditional deep
learning attack paradigms, we explore their intrinsic relationship and
collectively term them Prompt Trigger Attacks (PTA). This raises a key
question: Can we determine if a prompt is benign or poisoned? To address this,
we propose UniGuardian, the first unified defense mechanism designed to detect
prompt injection, backdoor attacks, and adversarial attacks in LLMs.
Additionally, we introduce a single-forward strategy to optimize the detection
pipeline, enabling simultaneous attack detection and text generation within a
single forward pass. Our experiments confirm that UniGuardian accurately and
efficiently identifies malicious prompts in LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å®¹æåå°æç¤ºæ³¨å¥ãå¾éæ»æåå°ææ§æ»æç­æ»æï¼éäºæ»æææç¸±æç¤ºææ¨¡åä»¥ç¢çæå®³çè¼¸åºãå¨æ¬æä¸­ï¼æåè·³è«å³çµ±æ·±åº¦å­¸ç¿æ»æç¯ä¾ï¼æ¢è¨å®åçå§å¨éä¿ï¼ä¸¦å°å®åçµ±ç¨±çºæç¤ºè§¸ç¼æ»æ (PTA)ãéå¼ç¼äºä¸åééµåé¡ï¼æåè½ç¢ºå®ä¸åæç¤ºæ¯è¯æ§çéæ¯æ¡æçåï¼çºäºè§£æ±ºéååé¡ï¼æåæåºäº UniGuardianï¼éæ¯ä¸ç¨®æ¨å¨åµæ¸¬ LLM ä¸­çæç¤ºæ³¨å¥ãå¾éæ»æåå°ææ§æ»æçç¬¬ä¸åçµ±ä¸é²ç¦¦æ©å¶ãæ­¤å¤ï¼æåå¼å¥äºä¸åå®ä¸ååç­ç¥ä¾æä½³ååµæ¸¬ç®¡éï¼å¨å®ä¸ååå³éä¸­åæé²è¡æ»æåµæ¸¬åæå­çæãæåçå¯¦é©è­å¯¦ï¼UniGuardian è½æºç¢ºä¸ææå°è­å¥ LLM ä¸­çæ¡ææç¤ºã

##### **AIDE: AI-Driven Exploration in the Space of Code**
2502.13138v1 by Zhengyao Jiang, Dominik Schmidt, Dhruv Srikanth, Dixing Xu, Ian Kaplan, Deniss Jacenko, Yuxiang Wu

Machine learning, the foundation of modern artificial intelligence, has
driven innovations that have fundamentally transformed the world. Yet, behind
advancements lies a complex and often tedious process requiring labor and
compute intensive iteration and experimentation. Engineers and scientists
developing machine learning models spend much of their time on trial-and-error
tasks instead of conceptualizing innovative solutions or research hypotheses.
To address this challenge, we introduce AI-Driven Exploration (AIDE), a machine
learning engineering agent powered by large language models (LLMs). AIDE frames
machine learning engineering as a code optimization problem, and formulates
trial-and-error as a tree search in the space of potential solutions. By
strategically reusing and refining promising solutions, AIDE effectively trades
computational resources for enhanced performance, achieving state-of-the-art
results on multiple machine learning engineering benchmarks, including our
Kaggle evaluations, OpenAI MLE-Bench and METRs RE-Bench.

æè¦ï¼æ©å¨å­¸ç¿ï¼ç¾ä»£äººå·¥æºæ§çåºç¤ï¼å·²ç¶æ¨åäºæ ¹æ¬æ§å°æ¹è®ä¸ççåµæ°ãç¶èï¼é²æ­¥çèå¾æ¯ä¸åè¤éä¸ç¶å¸¸ç¹ç£çéç¨ï¼éè¦äººå·¥åè¨ç®å¯éçè¿­ä»£åå¯¦é©ãéç¼æ©å¨å­¸ç¿æ¨¡åçå·¥ç¨å¸«åç§å­¸å®¶å°å¤§é¨åæéè±å¨è©¦é¯ä»»åä¸ï¼èä¸æ¯æ§æåµæ°çè§£æ±ºæ¹æ¡æç ç©¶åè¨­ãçºäºæå°éä¸ææ°ï¼æåå¼å¥äº AI é©åæ¢ç´¢ (AIDE)ï¼éæ¯ä¸ç¨®ç±å¤§åèªè¨æ¨¡å (LLM) é©åçæ©å¨å­¸ç¿å·¥ç¨ä»£çãAIDE å°æ©å¨å­¸ç¿å·¥ç¨æ§å»ºçºä¸åç¨å¼ç¢¼æä½³ååé¡ï¼ä¸¦å°è©¦é¯è¡¨è¿°çºå¨æ½å¨è§£æ±ºæ¹æ¡ç©ºéä¸­çæ¨¹çæå°ãééç­ç¥æ§å°éè¤ä½¿ç¨åæ¹é²æå¸æçè§£æ±ºæ¹æ¡ï¼AIDE ææå°å°è¨ç®è³æºè½æçºå¢å¼·çæè½ï¼å¨å¤åæ©å¨å­¸ç¿å·¥ç¨åºæºä¸åå¾äºæåé²çææï¼åæ¬æåç Kaggle è©ä¼°ãOpenAI MLE-Bench å METRs RE-Benchã

##### **Theorem Prover as a Judge for Synthetic Data Generation**
2502.13137v1 by Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B. Cohen

The demand for synthetic data in mathematical reasoning has increased due to
its potential to enhance the mathematical capabilities of large language models
(LLMs). However, ensuring the validity of intermediate reasoning steps remains
a significant challenge, affecting data quality. While formal verification via
theorem provers effectively validates LLM reasoning, the autoformalisation of
mathematical proofs remains error-prone. In response, we introduce iterative
autoformalisation, an approach that iteratively refines theorem prover
formalisation to mitigate errors, thereby increasing the execution rate on the
Lean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as
a Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to
rigorously assess LLM intermediate reasoning, effectively integrating
autoformalisation with synthetic data generation. Finally, we present
Reinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that
replaces human annotation with theorem prover feedback in Reinforcement
Learning from Human Feedback (RLHF). Across multiple LLMs, applying
TP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving
5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for
SVAMP, and 3.55% on Llama-3.1-8B for AQUA.

æè¦ï¼<paragraph>ç±æ¼åæè³æå¨æ¸å­¸æ¨çä¸­å·æå¢å¼·å¤§åèªè¨æ¨¡å (LLM) æ¸å­¸è½åçæ½åï¼å°åæè³æçéæ±å·²å¢å ãç¶èï¼ç¢ºä¿ä¸­éæ¨çæ­¥é©çæææ§ä»ç¶æ¯ä¸é éå¤§çææ°ï¼å½±é¿è³æåè³ªãéç¶ééå®çè­æå¨é²è¡å½¢å¼é©è­å¯ææé©è­ LLM æ¨çï¼ä½æ¸å­¸è­æèªåå½¢å¼åä»ç¶å®¹æåºé¯ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºè¿­ä»£èªåå½¢å¼åï¼éæ¯ä¸ç¨®è¿­ä»£åªåå®çè­æå¨å½¢å¼åä»¥æ¸å°é¯èª¤çæ¹æ³ï¼å¾èå° Lean è­æå¨çå·è¡çå¾ 60% æé«å° 87%ãå¨æ­¤åºç¤ä¸ï¼æåå¼å¥äºå®çè­æå¨ä½çºè©å¯© (TP-as-a-Judge)ï¼éæ¯ä¸ç¨®æ¡ç¨å®çè­æå¨å½¢å¼åä¾å´æ ¼è©ä¼° LLM ä¸­éæ¨ççæ¹æ³ï¼ææå°å°èªåå½¢å¼åèåæè³æç¢çæ´åãæå¾ï¼æåæåºäºå®çè­æå¨åé¥å¼·åå­¸ç¿ (RLTPF)ï¼éæ¯ä¸åæ¡æ¶ï¼ç¨å®çè­æå¨åé¥åä»£äººé¡æ¨è¨»ï¼ä»¥é²è¡äººé¡åé¥å¼·åå­¸ç¿ (RLHF)ãå¨å¤å LLM ä¸­ï¼æç¨ TP-as-a-Judge å RLTPF å¯ééå 3,508 åæ¨£æ¬æ¹ååºæºï¼å¨ MultiArith ä¸ç²å¾ 5.56% çæºç¢ºåº¦æåï¼å¨ SVAMP ä¸ç²å¾ Llama-2-7B ç 6.00% æåï¼å¨ AQUA ä¸ç²å¾ Llama-3.1-8B ç 3.55% æåã</paragraph>

##### **Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions**
2502.13135v1 by Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Schneider, Isaac Galatzer-Levy, Yugang Jia, John Canny, Arthur Gretton, Maja MatariÄ

We present an end-to-end framework for generating synthetic users for
evaluating interactive agents designed to encourage positive behavior changes,
such as in health and lifestyle coaching. The synthetic users are grounded in
health and lifestyle conditions, specifically sleep and diabetes management in
this study, to ensure realistic interactions with the health coaching agent.
Synthetic users are created in two stages: first, structured data are generated
grounded in real-world health and lifestyle factors in addition to basic
demographics and behavioral attributes; second, full profiles of the synthetic
users are developed conditioned on the structured data. Interactions between
synthetic users and the coaching agent are simulated using generative
agent-based models such as Concordia, or directly by prompting a language
model. Using two independently-developed agents for sleep and diabetes coaching
as case studies, the validity of this framework is demonstrated by analyzing
the coaching agent's understanding of the synthetic users' needs and
challenges. Finally, through multiple blinded evaluations of user-coach
interactions by human experts, we demonstrate that our synthetic users with
health and behavioral attributes more accurately portray real human users with
the same attributes, compared to generic synthetic users not grounded in such
attributes. The proposed framework lays the foundation for efficient
development of conversational agents through extensive, realistic, and grounded
simulated interactions.

æè¦ï¼<paragraph>æåæä¾äºä¸åç«¯å°ç«¯çæ¶æ§ï¼ç¨æ¼çºè©ä¼°äºåå¼ä»£ççæåæä½¿ç¨èï¼éäºä»£çæ¨å¨é¼åµæ­£åè¡çºæ¹è®ï¼ä¾å¦å¥åº·åçæ´»æ¹å¼æå°ãåæä½¿ç¨èä»¥å¥åº·åçæ´»æ¹å¼çæ³çºåºç¤ï¼ç¹å¥æ¯æ¬ç ç©¶ä¸­çç¡ç åç³å°¿çç®¡çï¼ä»¥ç¢ºä¿èå¥åº·æå°ä»£ççäºåå·æçå¯¦æ§ãåæä½¿ç¨èåå©åéæ®µå»ºç«ï¼é¦åï¼é¤äºåºæ¬äººå£çµ±è¨è³æåè¡çºå±¬æ§å¤ï¼éæç¢çä»¥ç¾å¯¦ä¸ççå¥åº·åçæ´»æ¹å¼å ç´ çºåºç¤ççµæ§åè³æï¼å¶æ¬¡ï¼ææ ¹æçµæ§åè³æéç¼åæä½¿ç¨èçå®æ´åäººè³æãåæä½¿ç¨èåæå°ä»£çä¹éçäºåæ¯ä½¿ç¨çæå¼åºæ¼ä»£ççæ¨¡åï¼ä¾å¦ Concordiaï¼æ¨¡æ¬çï¼æèç´æ¥ééæç¤ºèªè¨æ¨¡åä¾æ¨¡æ¬ãä½¿ç¨å©åç¨ç«éç¼çç¡ç åç³å°¿çæå°ä»£çä½çºæ¡ä¾ç ç©¶ï¼ééåææå°ä»£çå°åæä½¿ç¨èéæ±åææ°ççè§£ï¼è­æäºæ­¤æ¶æ§çæææ§ãæå¾ï¼ééäººé¡å°å®¶å°ä½¿ç¨èæå°äºåé²è¡å¤éç²æ¸¬è©ä¼°ï¼æåè­æäºèæªä»¥éäºå±¬æ§çºåºç¤çéç¨åæä½¿ç¨èç¸æ¯ï¼å·æå¥åº·åè¡çºå±¬æ§çåæä½¿ç¨èæ´æºç¢ºå°æç¹ªäºå·æç¸åå±¬æ§ççå¯¦äººé¡ä½¿ç¨èãææåºçæ¶æ§çºééå»£æ³ãçå¯¦ä¸ææ ¹æçæ¨¡æ¬äºåï¼çºå°è©±ä»£ççææéç¼å¥ å®äºåºç¤ã</paragraph>

##### **Learning to Defer for Causal Discovery with Imperfect Experts**
2502.13132v1 by Oscar Clivio, Divyat Mahajan, Perouz Taslakian, Sara Magliacane, Ioannis Mitliagkas, Valentina Zantedeschi, Alexandre Drouin

Integrating expert knowledge, e.g. from large language models, into causal
discovery algorithms can be challenging when the knowledge is not guaranteed to
be correct. Expert recommendations may contradict data-driven results, and
their reliability can vary significantly depending on the domain or specific
query. Existing methods based on soft constraints or inconsistencies in
predicted causal relationships fail to account for these variations in
expertise. To remedy this, we propose L2D-CD, a method for gauging the
correctness of expert recommendations and optimally combining them with
data-driven causal discovery results. By adapting learning-to-defer (L2D)
algorithms for pairwise causal discovery (CD), we learn a deferral function
that selects whether to rely on classical causal discovery methods using
numerical data or expert recommendations based on textual meta-data. We
evaluate L2D-CD on the canonical T\"ubingen pairs dataset and demonstrate its
superior performance compared to both the causal discovery method and the
expert used in isolation. Moreover, our approach identifies domains where the
expert's performance is strong or weak. Finally, we outline a strategy for
generalizing this approach to causal discovery on graphs with more than two
variables, paving the way for further research in this area.

æè¦ï¼æ´åä¸å®¶ç¥è­ï¼ä¾å¦å¾å¤§åèªè¨æ¨¡åä¸­æ´åå°å æç¼ç¾æ¼ç®æ³ä¸­ï¼ç¶ç¥è­ç¡æ³ä¿è­æ­£ç¢ºææå¾æææ°æ§ãå°å®¶å»ºè­°å¯è½æèè³æé©åççµæç¸çç¾ï¼èä¸ä»åçå¯é æ§å¯è½ææ ¹æé åæç¹å®æ¥è©¢èæé¡¯èå·®ç°ãç¾æçåºæ¼è»ç´ææé æ¸¬å æéä¿ä¸­ä¸ä¸è´çæ¹æ³ç¡æ³èªªæå°æ¥­ç¥è­ä¸­çéäºè®åãçºäºè£æéä¸é»ï¼æåæåºäº L2D-CDï¼ä¸ç¨®ç¨æ¼è©ä¼°å°å®¶å»ºè­°çæ­£ç¢ºæ§ä¸¦å°å¶èè³æé©åçå æç¼ç¾çµææä½³çµåçæ¹æ³ãééèª¿æ´å­¸ç¿å»¶é² (L2D) æ¼ç®æ³ä»¥é²è¡æå°å æç¼ç¾ (CD)ï¼æåå­¸ç¿äºä¸åå»¶é²å½æ¸ï¼ç¨æ¼é¸æä¾è³´ä½¿ç¨æ¸å¼è³æçå³çµ±å æç¼ç¾æ¹æ³æåºæ¼æå­åè³æçå°å®¶å»ºè­°ãæåå¨ç¶å¸ç T\"ubingen å°è³æéä¸è©ä¼° L2D-CDï¼ä¸¦è­æå¶èå®ç¨ä½¿ç¨çå æç¼ç¾æ¹æ³åå°å®¶ç¸æ¯å·æåªè¶çæè½ãæ­¤å¤ï¼æåçåæ³è­å¥åºå°å®¶è¡¨ç¾å¼·æå¼±çé åãæå¾ï¼æåæ¦è¿°äºä¸ç¨®å°æ­¤æ¹æ³æ¨å»£å°å·æå©åä»¥ä¸è®æ¸çåè¡¨ä¸é²è¡å æç¼ç¾çç­ç¥ï¼çºæ­¤é åçé²ä¸æ­¥ç ç©¶éªå¹³äºéè·¯ã

##### **Rethinking Diverse Human Preference Learning through Principal Component Analysis**
2502.13131v1 by Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen

Understanding human preferences is crucial for improving foundation models
and building personalized AI systems. However, preferences are inherently
diverse and complex, making it difficult for traditional reward models to
capture their full range. While fine-grained preference data can help,
collecting it is expensive and hard to scale. In this paper, we introduce
Decomposed Reward Models (DRMs), a novel approach that extracts diverse human
preferences from binary comparisons without requiring fine-grained annotations.
Our key insight is to represent human preferences as vectors and analyze them
using Principal Component Analysis (PCA). By constructing a dataset of
embedding differences between preferred and rejected responses, DRMs identify
orthogonal basis vectors that capture distinct aspects of preference. These
decomposed rewards can be flexibly combined to align with different user needs,
offering an interpretable and scalable alternative to traditional reward
models. We demonstrate that DRMs effectively extract meaningful preference
dimensions (e.g., helpfulness, safety, humor) and adapt to new users without
additional training. Our results highlight DRMs as a powerful framework for
personalized and interpretable LLM alignment.

æè¦ï¼çè§£äººé¡åå¥½å°æ¼æ¹é²åºç¤æ¨¡ååå»ºæ§åäººå AI ç³»çµ±è³ééè¦ãç¶èï¼åå¥½æ¬è³ªä¸æ¯å¤æ¨£ä¸è¤éçï¼éä½¿å¾å³çµ±ççåµæ¨¡åé£ä»¥ææå¶å¨é¨ç¯åãéç¶ç´°ç·»çåå¥½æ¸æå¯è½ææå¹«å©ï¼ä½æ¶ééäºæ¸ææ¢æè²´åé£ä»¥æ´å±ãå¨æ¬æä¸­ï¼æåä»ç´¹äºè§£æ§çåµæ¨¡å (DRM)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å¯ä»¥å¾äºåæ¯è¼ä¸­æåå¤æ¨£åçäººé¡åå¥½ï¼èä¸éè¦ç´°ç·»çè¨»è§£ãæåçééµè¦è§£æ¯å°äººé¡åå¥½è¡¨ç¤ºçºåéï¼ä¸¦ä½¿ç¨ä¸»æååæ (PCA) å°å¶é²è¡åæãééå»ºæ§åå¥½åæçµåæä¹éåµå¥å·®ç°çæ¸æéï¼DRM è­å¥åºæ­£äº¤åºåéï¼éäºåéææåå¥½çä¸åé¢åãéäºè§£æ§ççåµå¯ä»¥éæ´»å°çµåå¨ä¸èµ·ï¼ä»¥ç¬¦åä¸åçä½¿ç¨èéæ±ï¼æä¾ä¸ç¨®å¯è§£éä¸å¯æ´å±çå³çµ±çåµæ¨¡åæ¿ä»£æ¹æ¡ãæåè­æäº DRM å¯ä»¥ææå°æåææç¾©çåå¥½ç¶­åº¦ï¼ä¾å¦ï¼æç¨æ§ãå®å¨æ§ãå¹½é»æï¼ï¼ä¸¦å¨ä¸éè¦é¡å¤è¨ç·´çææ³ä¸é©ææ°çä½¿ç¨èãæåççµæçªé¡¯äº DRM ä½çºåäººåä¸å¯è§£éç LLM å°é½å¼·å¤§æ¶æ§ã

##### **Magma: A Foundation Model for Multimodal AI Agents**
2502.13130v1 by Jianwei Yang, Reuben Tan, Qianhui Wu, Ruijie Zheng, Baolin Peng, Yongyuan Liang, Yu Gu, Mu Cai, Seonghyeon Ye, Joel Jang, Yuquan Deng, Lars Liden, Jianfeng Gao

We present Magma, a foundation model that serves multimodal AI agentic tasks
in both the digital and physical worlds. Magma is a significant extension of
vision-language (VL) models in that it not only retains the VL understanding
ability (verbal intelligence) of the latter, but is also equipped with the
ability to plan and act in the visual-spatial world (spatial-temporal
intelligence) and complete agentic tasks ranging from UI navigation to robot
manipulation. To endow the agentic capabilities, Magma is pretrained on large
amounts of heterogeneous datasets spanning from images, videos to robotics
data, where the actionable visual objects (e.g., clickable buttons in GUI) in
images are labeled by Set-of-Mark (SoM) for action grounding, and the object
movements (e.g., the trace of human hands or robotic arms) in videos are
labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show
that SoM and ToM reach great synergy and facilitate the acquisition of
spatial-temporal intelligence for our Magma model, which is fundamental to a
wide range of tasks as shown in Fig.1. In particular, Magma creates new
state-of-the-art results on UI navigation and robotic manipulation tasks,
outperforming previous models that are specifically tailored to these tasks. On
image and video-related multimodal tasks, Magma also compares favorably to
popular large multimodal models that are trained on much larger datasets. We
make our model and code public for reproducibility at
https://microsoft.github.io/Magma.

æè¦ï¼<paragraph>æåæåº Magmaï¼éæ¯ä¸ååºç¤æ¨¡åï¼ç¨æ¼æåæ¸ä½åç©çä¸çä¸­çå¤æ¨¡æ AI ä»£çä»»åãMagma æ¯è¦è¦ºèªè¨ (VL) æ¨¡åçéå¤§å»¶ä¼¸ï¼å®ä¸åä¿çäºå¾èç VL çè§£è½åï¼èªè¨æºè½ï¼ï¼éå·åå¨è¦è¦ºç©ºéä¸çä¸­è¦ååè¡åçè½åï¼æç©ºæºè½ï¼ï¼ä¸¦å®æå¾ UI å°èªå°æ©å¨äººæä½çä»£çä»»åãçºäºè³¦äºä»£çè½åï¼Magma å¨å¾å½±åãå½±çå°æ©å¨äººè³æçå¤§éç°è³ªè³æéä¸é²è¡é è¨ç·´ï¼å¶ä¸­å½±åä¸­çå¯æä½è¦è¦ºç©ä»¶ï¼ä¾å¦ GUI ä¸­çå¯é»ææéï¼ç±åä½æ¥å° Set-of-Mark (SoM) æ¨è¨ï¼å½±çä¸­çç©ä»¶åä½ï¼ä¾å¦äººæææ©å¨æèçè»è·¡ï¼ç±åä½è¦å Trace-of-Mark (ToM) æ¨è¨ãå»£æ³çå¯¦é©è¡¨æï¼SoM å ToM éå°äºæ¥µå¤§çååä½ç¨ï¼ä¸¦ä¿é²äºæå Magma æ¨¡åçæç©ºæºè½çç²åï¼éå°æ¼å 1 ä¸­æç¤ºçåç¨®ä»»åè³ééè¦ãç¹å¥æ¯ï¼Magma å¨ UI å°èªåæ©å¨äººæä½ä»»åä¸åµé äºæ°çæåé²ççµæï¼åªæ¼å°ééå°éäºä»»åçååæ¨¡åãå¨å½±ååå½±çç¸éçå¤æ¨¡æä»»åä¸ï¼Magma ä¹èå¨æ´å¤§è³æéä¸è¨ç·´çæµè¡å¤§åå¤æ¨¡ææ¨¡åç¸æ¯ï¼è¡¨ç¾å¾å¾å¥½ãæåå¬éæåçæ¨¡ååç¨å¼ç¢¼ï¼ä»¥ä¾¿å¨ https://microsoft.github.io/Magma ä¸éç¾ã</paragraph>

##### **SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation**
2502.13128v1 by Zihan Liu, Shuangrui Ding, Zhixiong Zhang, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Dahua Lin, Jiaqi Wang

Text-to-song generation, the task of creating vocals and accompaniment from
textual inputs, poses significant challenges due to domain complexity and data
scarcity. Existing approaches often employ multi-stage generation procedures,
resulting in cumbersome training and inference pipelines. In this paper, we
propose SongGen, a fully open-source, single-stage auto-regressive transformer
designed for controllable song generation. The proposed model facilitates
fine-grained control over diverse musical attributes, including lyrics and
textual descriptions of instrumentation, genre, mood, and timbre, while also
offering an optional three-second reference clip for voice cloning. Within a
unified auto-regressive framework, SongGen supports two output modes: mixed
mode, which generates a mixture of vocals and accompaniment directly, and
dual-track mode, which synthesizes them separately for greater flexibility in
downstream applications. We explore diverse token pattern strategies for each
mode, leading to notable improvements and valuable insights. Furthermore, we
design an automated data preprocessing pipeline with effective quality control.
To foster community engagement and future research, we will release our model
weights, training code, annotated data, and preprocessing pipeline. The
generated samples are showcased on our project page at
https://liuzh-19.github.io/SongGen/ , and the code will be available at
https://github.com/LiuZH-19/SongGen .

æè¦ï¼æå­è½æ­æ²çæï¼å¾æå­è¼¸å¥å»ºç«äººè²åä¼´å¥çä»»åï¼ç±æ¼é åè¤éæ§åè³æç¨å°æ§ï¼å æ­¤æ§æéå¤§ææ°ãç¾ææ¹æ³éå¸¸æ¡ç¨å¤éæ®µçæç¨åºï¼å°è´è¨ç·´åæ¨è«ç®¡éç¹ç£ãå¨æ¬æä¸­ï¼æåæåº SongGenï¼ä¸åå®å¨éæºçå®éæ®µèªè¿´æ­¸è½æå¨ï¼å°çºå¯æ§æ­æ²çæèè¨­è¨ãææåºçæ¨¡åä¿é²å°åç¨®é³æ¨å±¬æ§çç´°ç²åº¦æ§å¶ï¼åæ¬æ­è©åæ¨å¨ãé¡åãæç·åé³è²çæå­æè¿°ï¼åæéæä¾å¯é¸çä¸ç§åèçæ®µä»¥é²è¡èªé³è¤è£½ãå¨çµ±ä¸çèªè¿´æ­¸æ¡æ¶å§ï¼SongGen æ¯æ´å©ç¨®è¼¸åºæ¨¡å¼ï¼æ··åæ¨¡å¼ï¼ç´æ¥çæäººè²åä¼´å¥çæ··åï¼ä»¥åéè»æ¨¡å¼ï¼å°å®ååéåæä»¥æé«ä¸æ¸¸æç¨ç¨å¼çéæ´»æ§ãæåæ¢ç´¢æ¯ç¨®æ¨¡å¼çä¸åä»£å¹£æ¨¡å¼ç­ç¥ï¼å¾èå¸¶ä¾é¡¯èçæ¹é²åæå¹å¼çè¦è§£ãæ­¤å¤ï¼æåè¨­è¨äºä¸åèªååè³æé èçç®¡éï¼å·åææçåè³ªæ§å¶ãçºäºä¿é²ç¤¾ååèåæªä¾çç ç©¶ï¼æåå°éåºæåçæ¨¡åæ¬éãè¨ç·´ç¨å¼ç¢¼ãè¨»è§£è³æåé èçç®¡éãçæçç¯ä¾å±ç¤ºå¨æåçå°æ¡é é¢ https://liuzh-19.github.io/SongGen/ï¼ç¨å¼ç¢¼å°å¨ https://github.com/LiuZH-19/SongGen ä¸­æä¾ã

##### **Facilitating Long Context Understanding via Supervised Chain-of-Thought Reasoning**
2502.13127v1 by Jingyang Lin, Andy Wong, Tian Xia, Shenghua He, Hui Wei, Mei Han, Jiebo Luo

Recent advances in Large Language Models (LLMs) have enabled them to process
increasingly longer sequences, ranging from 2K to 2M tokens and even beyond.
However, simply extending the input sequence length does not necessarily lead
to effective long-context understanding. In this study, we integrate
Chain-of-Thought (CoT) reasoning into LLMs in a supervised manner to facilitate
effective long-context understanding. To achieve this, we introduce
LongFinanceQA, a synthetic dataset in the financial domain designed to improve
long-context reasoning. Unlike existing long-context synthetic data,
LongFinanceQA includes intermediate CoT reasoning before the final conclusion,
which encourages LLMs to perform explicit reasoning, improving accuracy and
interpretability in long-context understanding. To generate synthetic CoT
reasoning, we propose Property-driven Agentic Inference (PAI), an agentic
framework that simulates human-like reasoning steps, including property
extraction, retrieval, and summarization. We evaluate PAI's reasoning
capabilities by assessing GPT-4o-mini w/ PAI on the Loong benchmark,
outperforming standard GPT-4o-mini by 20.0%. Furthermore, we fine-tune
LLaMA-3.1-8B-Instruct on LongFinanceQA, achieving a 24.6% gain on Loong's
financial subset.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±è®å®åè½å¤ èçè¶ä¾è¶é·çåºåï¼ç¯åå¾ 2K å° 2M åç¬¦èï¼çè³æ´é·ã
ç¶èï¼ååå»¶é·è¼¸å¥åºåé·åº¦ä¸¦ä¸æå¿ç¶å°è´ææçé·èªå¢çè§£ãå¨æ¬ç ç©¶ä¸­ï¼æåä»¥ç£ç£çæ¹å¼å°æèé (CoT) æ¨çæ´åå° LLM ä¸­ï¼ä»¥ä¿é²ææçé·èªå¢çè§£ãçºæ­¤ï¼æåå¼å¥äº LongFinanceQAï¼éæ¯ä¸åå¨éèé åä¸­çåææ¸æéï¼æ¨å¨æ¹é²é·èªå¢æ¨çãèç¾æçé·èªå¢åææ¸æä¸åï¼LongFinanceQA å¨æçµçµè«ä¹ååå«äºä¸­éç CoT æ¨çï¼éé¼åµ LLM å·è¡æç¢ºçæ¨çï¼å¾èæé«é·èªå¢çè§£çæºç¢ºæ§åå¯è§£éæ§ãçºäºçæåæç CoT æ¨çï¼æåæåºäºåºæ¼å±¬æ§çä¸»é«æ¨ç (PAI)ï¼éæ¯ä¸åæ¨¡æ¬é¡äººæ¨çæ­¥é©çä¸»é«æ¡æ¶ï¼åæ¬å±¬æ§æåãæª¢ç´¢åç¸½çµãæåééè©ä¼°æ­è¼ PAI ç GPT-4o-mini å¨ Loong åºæºä¸çæ¨çè½åï¼ä½¿å¶æ¯æ¨æºç GPT-4o-mini é«åº 20.0%ï¼ä¾è©ä¼° PAI çæ¨çè½åãæ­¤å¤ï¼æåå° LLaMA-3.1-8B-Instruct é²è¡äºå¾®èª¿ï¼å¨ Loong çéèå­éä¸­å¯¦ç¾äº 24.6% çå¢çã

##### **RuozhiBench: Evaluating LLMs with Logical Fallacies and Misleading Premises**
2502.13125v1 by Zenan Zhai, Hao Li, Xudong Han, Zhenxuan Zhang, Yixuan Zhang, Timothy Baldwin, Haonan Li

Recent advances in large language models (LLMs) have shown that they can
answer questions requiring complex reasoning. However, their ability to
identify and respond to text containing logical fallacies or deliberately
misleading premises remains less studied. To address this gap, we introduce
RuozhiBench, a bilingual dataset comprising 677 carefully curated questions
that contain various forms of deceptive reasoning, meticulously crafted through
extensive human effort and expert review. In a comprehensive evaluation of 17
LLMs from 5 Series over RuozhiBench using both open-ended and two-choice
formats, we conduct extensive analyses on evaluation protocols and result
patterns. Despite their high scores on conventional benchmarks, these models
showed limited ability to detect and reason correctly about logical fallacies,
with even the best-performing model, Claude-3-haiku, achieving only 62%
accuracy compared to the human of more than 90%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±é¡¯ç¤ºï¼å®åå¯ä»¥åç­éè¦è¤éæ¨ççåé¡ãç¶èï¼å®åè­å¥ååæåå«éè¼¯è¬¬èª¤æææèª¤å°åæçææ¬çè½åä»æªå¾å°ååç ç©¶ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº RuozhiBenchï¼éæ¯ä¸åéèªè³æéï¼åå« 677 åç¶éä»ç´°ç­åçåé¡ï¼å¶ä¸­åå«åç¨®å½¢å¼çæ¬ºé¨æ§æ¨çï¼ä¸¦ééå»£æ³çäººåæå¥åå°å®¶å¯©æ¥ç²¾å¿è£½ä½ãå¨ä½¿ç¨éæ¾å¼åäºé¸ä¸æ ¼å¼å°ä¾èª 5 åç³»åç 17 å LLM é²è¡ RuozhiBench çå¨é¢è©ä¼°ä¸­ï¼æåå°è©ä¼°åå®åçµææ¨¡å¼é²è¡äºå»£æ³çåæãåç®¡å®åå¨å³çµ±åºæºæ¸¬è©¦ä¸­ç²å¾äºé«åï¼ä½éäºæ¨¡åå¨æª¢æ¸¬åæ­£ç¢ºæ¨çéè¼¯è¬¬èª¤æ¹é¢è¡¨ç¾åºçè½åæéï¼å³ä½¿æ¯æè½æå¥½çæ¨¡å Claude-3-haikuï¼èäººé¡ç 90% ä»¥ä¸ç¸æ¯ï¼ä¹åªéå°äº 62% çæºç¢ºåº¦ã

##### **NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions**
2502.13124v1 by Weizhe Yuan, Jane Yu, Song Jiang, Karthik Padthe, Yang Li, Dong Wang, Ilia Kulikov, Kyunghyun Cho, Yuandong Tian, Jason E Weston, Xian Li

Scaling reasoning capabilities beyond traditional domains such as math and
coding is hindered by the lack of diverse and high-quality questions. To
overcome this limitation, we introduce a scalable approach for generating
diverse and challenging reasoning questions, accompanied by reference answers.
We present NaturalReasoning, a comprehensive dataset comprising 2.8 million
questions that span multiple domains, including STEM fields (e.g., Physics,
Computer Science), Economics, Social Sciences, and more. We demonstrate the
utility of the questions in NaturalReasoning through knowledge distillation
experiments which show that NaturalReasoning can effectively elicit and
transfer reasoning capabilities from a strong teacher model. Furthermore, we
demonstrate that NaturalReasoning is also effective for unsupervised
self-training using external reward models or self-rewarding.

æè¦ï¼ééè¶è¶å³çµ±é åï¼ä¾å¦æ¸å­¸åç·¨ç¢¼ï¼ä¾æ´åæ¨çè½åï¼åå°ç¼ºä¹å¤åä¸é«åè³ªåé¡çé»ç¤ãçºäºåæéåéå¶ï¼æåå¼å¥ä¸åå¯æ´åçæ¹æ³ï¼ç¨æ¼ç¢çå¤åä¸å·ææ°æ§çæ¨çåé¡ï¼ä¸¦éä¸åèç­æ¡ãæåæåº NaturalReasoningï¼éæ¯ä¸ååå« 280 è¬ååé¡çç¶åè³æéï¼æ¶µèå¤åé åï¼åæ¬ STEM é åï¼ä¾å¦ç©çãé»è¦ç§å­¸ï¼ãç¶æ¿å­¸ãç¤¾æç§å­¸ç­ç­ãæåééç¥è­è¸é¤¾å¯¦é©ï¼å±ç¤º NaturalReasoning ä¸­åé¡çå¯¦ç¨æ§ï¼éäºå¯¦é©é¡¯ç¤º NaturalReasoning è½ææå°å¼ç¼åè½ç§»å¼·å¤§æå¸«æ¨¡åçæ¨çè½åãæ­¤å¤ï¼æåå±ç¤º NaturalReasoning ä¹é©ç¨æ¼ä½¿ç¨å¤é¨çåµæ¨¡åæèªæçåµçç¡ç£ç£èªæè¨ç·´ã

##### **Adapting Psycholinguistic Research for LLMs: Gender-inclusive Language in a Coreference Context**
2502.13120v1 by Marion Bartl, Thomas Brendan Murphy, Susan Leavy

Gender-inclusive language is often used with the aim of ensuring that all
individuals, regardless of gender, can be associated with certain concepts.
While psycholinguistic studies have examined its effects in relation to human
cognition, it remains unclear how Large Language Models (LLMs) process
gender-inclusive language. Given that commercial LLMs are gaining an
increasingly strong foothold in everyday applications, it is crucial to examine
whether LLMs in fact interpret gender-inclusive language neutrally, because the
language they generate has the potential to influence the language of their
users. This study examines whether LLM-generated coreferent terms align with a
given gender expression or reflect model biases. Adapting psycholinguistic
methods from French to English and German, we find that in English, LLMs
generally maintain the antecedent's gender but exhibit underlying masculine
bias. In German, this bias is much stronger, overriding all tested
gender-neutralization strategies.

æè¦ï¼æ§å¥åå®¹æ§èªè¨éå¸¸ç¨æ¼ç¢ºä¿ææåäººï¼ç¡è«æ§å¥å¦ä½ï¼é½è½èæäºæ¦å¿µè¯ç¹«å¨ä¸èµ·ãéç¶å¿çèªè¨å­¸ç ç©¶å·²ç¶æª¢è¦äºå®å°äººé¡èªç¥çå½±é¿ï¼ä½å¤§åèªè¨æ¨¡å (LLM) å¦ä½èçæ§å¥åå®¹æ§èªè¨ä»ç¶ä¸æ¸æ¥ãéæ¼åæ¥­ LLM å¨æ¥å¸¸æç¨ä¸­è¶ä¾è¶ç«ç©©è³æ­¥ï¼å æ­¤è³ééè¦çæ¯è¦æª¢æ¥ LLM æ¯å¦å¯¦éä¸ä¸­ç«å°è§£éæ§å¥åå®¹æ§èªè¨ï¼å çºå®åç¢ççèªè¨æå¯è½å½±é¿å¶ä½¿ç¨èçèªè¨ãæ¬ç ç©¶æ¢è¨äº LLM çæçå±æè¡èªæ¯å¦èçµ¦å®çæ§å¥è¡¨éä¸è´æåæ æ¨¡ååè¦ãæåæ¡ç¨æ³èªå°è±èªåå¾·èªçå¿çèªè¨å­¸æ¹æ³ï¼ç¼ç¾è±èªä¸­ï¼LLM éå¸¸æä¿æåè¡è©çæ§å¥ï¼ä½è¡¨ç¾åºæ½å¨çç·æ§åè¦ãå¨å¾·èªä¸­ï¼éç¨®åè¦å¼·å¾å¤ï¼åé§æ¼ææç¶éæ¸¬è©¦çæ§å¥ä¸­ç«åç­ç¥ã

##### **STEER-ME: Assessing the Microeconomic Reasoning of Large Language Models**
2502.13119v1 by Narun Raman, Taylor Lundy, Thiago Amin, Jesse Perla, Kevin-Leyton Brown

How should one judge whether a given large language model (LLM) can reliably
perform economic reasoning? Most existing LLM benchmarks focus on specific
applications and fail to present the model with a rich variety of economic
tasks. A notable exception is Raman et al. [2024], who offer an approach for
comprehensively benchmarking strategic decision-making; however, this approach
fails to address the non-strategic settings prevalent in microeconomics, such
as supply-and-demand analysis. We address this gap by taxonomizing
microeconomic reasoning into $58$ distinct elements, focusing on the logic of
supply and demand, each grounded in up to $10$ distinct domains, $5$
perspectives, and $3$ types. The generation of benchmark data across this
combinatorial space is powered by a novel LLM-assisted data generation protocol
that we dub auto-STEER, which generates a set of questions by adapting
handwritten templates to target new domains and perspectives. Because it offers
an automated way of generating fresh questions, auto-STEER mitigates the risk
that LLMs will be trained to over-fit evaluation benchmarks; we thus hope that
it will serve as a useful tool both for evaluating and fine-tuning models for
years to come. We demonstrate the usefulness of our benchmark via a case study
on $27$ LLMs, ranging from small open-source models to the current state of the
art. We examined each model's ability to solve microeconomic problems across
our whole taxonomy and present the results across a range of prompting
strategies and scoring metrics.

æè¦ï¼<paragraph>å¦ä½å¤æ·ä¸åçµ¦å®çå¤§åèªè¨æ¨¡å (LLM) è½å¦å¯é å°é²è¡ç¶æ¿æ¨çï¼ç¾æç LLM åºæºæ¸¬è©¦å¤§å¤å°æ³¨æ¼ç¹å®æç¨ï¼æªè½çºæ¨¡åæä¾è±å¯å¤æ¨£çç¶æ¿ä»»åãä¸åå¼å¾æ³¨æçä¾å¤æ¯ Raman ç­äºº [2024]ï¼ä»åæä¾äºä¸ç¨®å¨é¢è©ä¼°ç­ç¥æ±ºç­å¶å®æ¹æ³ï¼ç¶èï¼éç¨®æ¹æ³ç¡æ³è§£æ±ºå¾®è§ç¶æ¿å­¸ä¸­æ®éå­å¨çéç­ç¥æ§è¨­å®ï¼ä¾å¦ä¾éåæãæåééå°å¾®è§ç¶æ¿æ¨çåé¡çº 58 åä¸åçåç´ ä¾è§£æ±ºéåå·®è·ï¼éé»æ¾å¨ä¾ééè¼¯ä¸ï¼æ¯ååç´ é½åºæ¼å¤é 10 åä¸åçé åã5 åè§é»å 3 ç¨®é¡åãå¨éåçµåç©ºéä¸­ç¢çåºæºæ¸ææ¯ç±ä¸ç¨®æ°ç©ç LLM è¼å©æ¸æçæåè­°ï¼æåç¨±ä¹çº auto-STEERï¼æ¨åçï¼å®ééèª¿æ´æå¯«æ¨¡æ¿ä¾éå°æ°çé ååè§é»ä¾çæä¸çµåé¡ãç±æ¼å®æä¾äºä¸ç¨®çææ°åé¡çèªååæ¹å¼ï¼auto-STEER æ¸è¼äº LLM å°è¢«è¨ç·´éåº¦éåè©ä¼°åºæºæ¸¬è©¦çé¢¨éªï¼å æ­¤ï¼æåå¸æå®å°æçºæªä¾å¹¾å¹´è©ä¼°åå¾®èª¿æ¨¡åçæç¨å·¥å·ãæåééä¸åæ¡ä¾ç ç©¶å±ç¤ºäºæååºæºæ¸¬è©¦çæç¨ï¼è©²æ¡ä¾ç ç©¶æ¶µèäº 27 å LLMï¼å¾å°åéæºæ¨¡åå°ç¶åæè¡çæãæåæª¢æ¥äºæ¯åæ¨¡åå¨æåçæ´ååé¡æ³ä¸­è§£æ±ºå¾®è§ç¶æ¿åé¡çè½åï¼ä¸¦å¨åç¨®æç¤ºç­ç¥åè©åææ¨ä¸­å±ç¤ºäºçµæã</paragraph>

##### **Performance Evaluation of Large Language Models in Statistical Programming**
2502.13117v1 by Xinyi Song, Kexin Xie, Lina Lee, Ruizhe Chen, Jared M. Clark, Hao He, Haoran He, Jie Min, Xinlei Zhang, Simin Zheng, Zhiyang Zhang, Xinwei Deng, Yili Hong

The programming capabilities of large language models (LLMs) have
revolutionized automatic code generation and opened new avenues for automatic
statistical analysis. However, the validity and quality of these generated
codes need to be systematically evaluated before they can be widely adopted.
Despite their growing prominence, a comprehensive evaluation of statistical
code generated by LLMs remains scarce in the literature. In this paper, we
assess the performance of LLMs, including two versions of ChatGPT and one
version of Llama, in the domain of SAS programming for statistical analysis.
Our study utilizes a set of statistical analysis tasks encompassing diverse
statistical topics and datasets. Each task includes a problem description,
dataset information, and human-verified SAS code. We conduct a comprehensive
assessment of the quality of SAS code generated by LLMs through human expert
evaluation based on correctness, effectiveness, readability, executability, and
the accuracy of output results. The analysis of rating scores reveals that
while LLMs demonstrate usefulness in generating syntactically correct code,
they struggle with tasks requiring deep domain understanding and may produce
redundant or incorrect results. This study offers valuable insights into the
capabilities and limitations of LLMs in statistical programming, providing
guidance for future advancements in AI-assisted coding systems for statistical
analysis.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çç¨å¼è¨­è¨åè½å¾¹åºæ¹è®äºèªåç¨å¼ç¢¼çæï¼ä¸¦çºèªåçµ±è¨åæéåäºæ°éå¾ãç¶èï¼å¨å»£æ³æ¡ç¨éäºç¢ççç¨å¼ç¢¼ä¹åï¼éè¦ç³»çµ±æ§å°è©ä¼°å¶æææ§ååè³ªãåç®¡å¶éè¦æ§æ¥çæåï¼ä½æç»ä¸­å°æ¼ LLM ç¢çççµ±è¨ç¨å¼ç¢¼çå¨é¢è©ä¼°ä»ç¶ç¨å°ãå¨æ¬æä¸­ï¼æåè©ä¼°äº LLM çæè½ï¼åæ¬å©åçæ¬ç ChatGPT åä¸åçæ¬ç Llamaï¼å¨çµ±è¨åæç SAS ç¨å¼è¨­è¨é åãæåçç ç©¶å©ç¨äºä¸çµæ¶µèåç¨®çµ±è¨ä¸»é¡åè³æéççµ±è¨åæä»»åãæ¯åä»»åé½åå«åé¡èªªæãè³æéè³è¨åç¶éäººå·¥é©è­ç SAS ç¨å¼ç¢¼ãæåééåºæ¼æ­£ç¢ºæ§ãæææ§ãå¯è®æ§ãå¯å·è¡æ§åè¼¸åºçµæç²¾ç¢ºåº¦çå°å®¶è©ä¼°ï¼å° LLM ç¢çç SAS ç¨å¼ç¢¼åè³ªé²è¡å¨é¢è©ä¼°ãè©åçµæçåæé¡¯ç¤ºï¼åç®¡ LLM å¨ç¢çèªæ³æ­£ç¢ºçç¨å¼ç¢¼æ¹é¢è¡¨ç¾åºå¶æç¨ï¼ä½å®åå¨éè¦æ·±å¥é åçè§£çä»»åä¸­æéå°å°é£ï¼ä¸¦ä¸å¯è½æç¢çåé¤æä¸æ­£ç¢ºççµæãæ¬ç ç©¶æä¾äº LLM å¨çµ±è¨ç¨å¼è¨­è¨ä¸­è½ååéå¶çå¯¶è²´è¦è§£ï¼çºçµ±è¨åæç AI è¼å©ç·¨ç¢¼ç³»çµ±çæªä¾é²å±æä¾æå°ã

##### **Near-Optimal Private Learning in Linear Contextual Bandits**
2502.13115v1 by Fan Chen, Jiachun Li, Alexander Rakhlin, David Simchi-Levi

We analyze the problem of private learning in generalized linear contextual
bandits. Our approach is based on a novel method of re-weighted regression,
yielding an efficient algorithm with regret of order
$\sqrt{T}+\frac{1}{\alpha}$ and $\sqrt{T}/\alpha$ in the joint and local model
of $\alpha$-privacy, respectively. Further, we provide near-optimal private
procedures that achieve dimension-independent rates in private linear models
and linear contextual bandits. In particular, our results imply that joint
privacy is almost "for free" in all the settings we consider, partially
addressing the open problem posed by Azize and Basu (2024).

æè¦ï¼æååæå»£ç¾©ç·æ§æå¢å¼·çä¸­ç§äººå­¸ç¿çåé¡ãæåçåæ³åºæ¼éæ°å æ¬åæ­¸çæ°æ¹æ³ï¼ç¢çä¸ç¨®ææççæ¼ç®æ³ï¼å¶å¾æå¼åå¥çº
$\sqrt{T}+\frac{1}{\alpha}$ å $\sqrt{T}/\alpha$ å¨ $\alpha$-é±ç§çè¯ååå±é¨æ¨¡åä¸­ãæ­¤å¤ï¼æåæä¾è¿ä¹æä½³çç§äººç¨åºï¼å¨ç§äººç·æ§æ¨¡ååç·æ§æå¢å¼·çä¸­å¯¦ç¾èç¶­åº¦ç¡éçæ¯çãç¹å¥æ¯ï¼æåççµæè¡¨æï¼å¨æåèæ®çææè¨­å®ä¸­ï¼è¯åé±ç§å¹¾ä¹æ¯ãåè²»ãçï¼é¨åè§£æ±ºäº Azize å Basu (2024) æåºçéæ¾æ§åé¡ã

##### **The influence of motion features in temporal perception**
2502.13114v1 by Rosa Illan Castillo, Javier Valenzuela

This paper examines the role of manner-of-motion verbs in shaping subjective
temporal perception and emotional resonance. Through four complementary
studies, we explore how these verbs influence the conceptualization of time,
examining their use in literal and metaphorical (temporal) contexts. Our
findings reveal that faster verbs (e.g., fly, zoom) evoke dynamic and engaging
temporal experiences, often linked to positive emotions and greater agency. In
contrast, slower verbs (e.g., crawl, drag) convey passivity, monotony, and
negative emotions, reflecting tedious or constrained experiences of time. These
effects are amplified in metaphorical contexts, where manner verbs encode
emotional and experiential nuances that transcend their literal meanings. We
also find that participants prefer manner verbs over path verbs (e.g., go,
pass) in emotionally charged temporal contexts, as manner verbs capture the
experiential and emotional qualities of time more effectively. These findings
highlight the interplay between language, motion, and emotion in shaping
temporal perception, offering insights into how linguistic framing influences
subjective experiences of time.

æè¦ï¼æ¬ææ¢è¨åä½æ¹å¼åè©å¨å½¢å¡ä¸»è§æéæç¥åæç·å±é³´ä¸­ææ®æ¼çè§è²ãééåé äºè£çç ç©¶ï¼æåæ¢è¨éäºåè©å¦ä½å½±é¿æéçæ¦å¿µåï¼ä¸¦æª¢è¦å®åå¨å­é¢åé±å»ï¼æéï¼èªå¢ä¸­çç¨æ³ãæåçç ç©¶çµæé¡¯ç¤ºï¼è¼å¿«çåè©ï¼ä¾å¦é£ãé£ï¼æå¼èµ·åæä¸å¼äººå¥åçæéé«é©ï¼éå¸¸èæ­£é¢æç·åè¼å¤§çèªä¸»æ§æéãç¸åå°ï¼è¼æ¢çåè©ï¼ä¾å¦ç¬ãæï¼å³éäºè¢«åãå®èª¿åè² é¢æç·ï¼åæ åºä¹å³æåéçæéé«é©ãéäºææå¨é±å»èªå¢ä¸­æè¢«æ¾å¤§ï¼å¶ä¸­åä½åè©ç·¨ç¢¼äºè¶è¶å¶å­é¢æç¾©çæç·åé«é©ç´°å¾®å·®å¥ãæåéç¼ç¾ï¼å¨åæ»¿æç·çæéèªå¢ä¸­ï¼åèèåå¥½åä½åè©èéè·¯å¾åè©ï¼ä¾å¦èµ°ãç¶éï¼ï¼å çºåä½åè©æ´ææå°ææäºæéçé«é©åæç·åè³ªãéäºç ç©¶çµæçªé¡¯äºèªè¨ãåä½åæç·ä¹éå¨å½¢å¡æéæç¥ä¸­çäº¤äºä½ç¨ï¼ä¸¦æä¾äºèªè¨æ¡æ¶å¦ä½å½±é¿ä¸»è§æéé«é©çè¦è§£ã

##### **Improving Clinical Question Answering with Multi-Task Learning: A Joint Approach for Answer Extraction and Medical Categorization**
2502.13108v1 by Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Amit Agarwal, Bhargava Kumar, Srikant Panda, Tejaswini Kumar

Clinical Question Answering (CQA) plays a crucial role in medical
decision-making, enabling physicians to extract relevant information from
Electronic Medical Records (EMRs). While transformer-based models such as BERT,
BioBERT, and ClinicalBERT have demonstrated state-of-the-art performance in
CQA, existing models lack the ability to categorize extracted answers, which is
critical for structured retrieval, content filtering, and medical decision
support.
  To address this limitation, we introduce a Multi-Task Learning (MTL)
framework that jointly trains CQA models for both answer extraction and medical
categorization. In addition to predicting answer spans, our model classifies
responses into five standardized medical categories: Diagnosis, Medication,
Symptoms, Procedure, and Lab Reports. This categorization enables more
structured and interpretable outputs, making clinical QA models more useful in
real-world healthcare settings.
  We evaluate our approach on emrQA, a large-scale dataset for medical question
answering. Results show that MTL improves F1-score by 2.2% compared to standard
fine-tuning, while achieving 90.7% accuracy in answer categorization. These
findings suggest that MTL not only enhances CQA performance but also introduces
an effective mechanism for categorization and structured medical information
retrieval.

æè¦ï¼<paragraph>è¨åºåç­ (CQA) å¨é«çæ±ºç­ä¸­æ®æ¼èè³ééè¦çè§è²ï¼è®é«å¸«è½å¤ å¾é»å­çæ­· (EMR) ä¸­æ·åç¸éè³è¨ãåç®¡ BERTãBioBERT å ClinicalBERT ç­åºæ¼è½æå¨çæ¨¡åå·²å¨ CQA ä¸­å±ç¾åºæåé²çæè½ï¼ä½ç¾æçæ¨¡åç¼ºä¹åé¡æ·åç­æ¡çè½åï¼éå°æ¼çµæ§åæª¢ç´¢ãå§å®¹éæ¿¾åé«çæ±ºç­æ¯æ´è³ééè¦ã
  çºäºè§£æ±ºéåéå¶ï¼æåå¼é²äºä¸åå¤ä»»åå­¸ç¿ (MTL) æ¶æ§ï¼å®åæè¨ç·´ CQA æ¨¡åç¨æ¼ç­æ¡æ·ååé«çåé¡ãé¤äºé æ¸¬ç­æ¡ç¯åï¼æåçæ¨¡åå°åæåé¡çºäºåæ¨æºåé«çé¡å¥ï¼è¨ºæ·ãè¥ç©ãççãç¨åºåå¯¦é©å®¤å ±åãéç¨®åé¡è½ç¢çæ´çµæ§åä¸ææ¼çè§£çè¼¸åºï¼è®è¨åºåç­æ¨¡åå¨çå¯¦ä¸ççé«çä¿å¥ç°å¢ä¸­æ´å¯¦ç¨ã
  æåå¨ emrQA ä¸è©ä¼°æåçåæ³ï¼emrQA æ¯ç¨æ¼é«çåé¡è§£ç­çå¤§è¦æ¨¡è³æéãçµæé¡¯ç¤ºï¼èæ¨æºå¾®èª¿ç¸æ¯ï¼MTL å° F1 åæ¸æé«äº 2.2%ï¼åæå¨ç­æ¡åé¡ä¸­éå° 90.7% çæºç¢ºåº¦ãéäºç¼ç¾è¡¨æï¼MTL ä¸åå¢å¼·äº CQA çæè½ï¼éå¼å¥äºä¸ç¨®åé¡åçµæ§åé«çè³è¨æª¢ç´¢çæææ©å¶ã</paragraph>

##### **MatterChat: A Multi-Modal LLM for Material Science**
2502.13107v1 by Yingheng Tang, Wenbin Xu, Jie Cao, Jianzhu Ma, Weilu Gao, Steve Farrell, Benjamin Erichson, Michael W. Mahoney, Andy Nonaka, Zhi Yao

Understanding and predicting the properties of inorganic materials is crucial
for accelerating advancements in materials science and driving applications in
energy, electronics, and beyond. Integrating material structure data with
language-based information through multi-modal large language models (LLMs)
offers great potential to support these efforts by enhancing human-AI
interaction. However, a key challenge lies in integrating atomic structures at
full resolution into LLMs. In this work, we introduce MatterChat, a versatile
structure-aware multi-modal LLM that unifies material structural data and
textual inputs into a single cohesive model. MatterChat employs a bridging
module to effectively align a pretrained machine learning interatomic potential
with a pretrained LLM, reducing training costs and enhancing flexibility. Our
results demonstrate that MatterChat significantly improves performance in
material property prediction and human-AI interaction, surpassing
general-purpose LLMs such as GPT-4. We also demonstrate its usefulness in
applications such as more advanced scientific reasoning and step-by-step
material synthesis.

æè¦ï¼äºè§£åé æ¸¬ç¡æ©ææçç¹æ§å°æ¼å éææç§å­¸çé²æ­¥åæ¨åè½æºãé»å­ç­æ¹é¢çæç¨è³ééè¦ãééå¤æ¨¡æå¤§åèªè¨æ¨¡å (LLM) å°ææçµæ§æ¸æèåºæ¼èªè¨çè³è¨æ´åï¼å¯ä»¥æ¥µå¤§ç¨åº¦å°æ¯æéäºå·¥ä½ï¼èæ­¤å¢å¼·äººé¡è AI çäºåãç¶èï¼ä¸åééµææ°å¨æ¼å°åå­çµæ§ä»¥å®æ´è§£æåº¦æ´åå° LLM ä¸­ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº MatterChatï¼éæ¯ä¸åéç¨ççµæ§æç¥å¤æ¨¡æ LLMï¼å®å°ææçµæ§æ¸æåæå­è¼¸å¥çµ±ä¸å°ä¸åå®ä¸çå§èæ¨¡åä¸­ãMatterChat æ¡ç¨æ©æ¥æ¨¡çµï¼å°é åè¨ç·´å¥½çæ©å¨å­¸ç¿åå­éé»ä½èé åè¨ç·´å¥½ç LLM ææå°å°é½ï¼å¾èéä½è¨ç·´ææ¬ä¸¦å¢å¼·éæ´»æ§ãæåççµæè¡¨æï¼MatterChat å¤§å¹æåäºææç¹æ§é æ¸¬åäººé¡è AI äºåçæè½ï¼è¶è¶äº GPT-4 ç­éç¨ LLMãæåä¹å±ç¤ºäºå®å¨æ´é²éçç§å­¸æ¨çåéæ­¥ææåæç­æç¨ä¸­çæç¨ã

##### **Understanding and Rectifying Safety Perception Distortion in VLMs**
2502.13095v1 by Xiaohan Zou, Jian Kang, George Kesidis, Lu Lin

Recent studies reveal that vision-language models (VLMs) become more
susceptible to harmful requests and jailbreak attacks after integrating the
vision modality, exhibiting greater vulnerability than their text-only LLM
backbones. To uncover the root cause of this phenomenon, we conduct an in-depth
analysis and identify a key issue: multimodal inputs introduce an
modality-induced activation shift toward a "safer" direction compared to their
text-only counterparts, leading VLMs to systematically overestimate the safety
of harmful inputs. We refer to this issue as safety perception distortion. To
mitigate such distortion, we propose Activation Shift Disentanglement and
Calibration (ShiftDC), a training-free method that decomposes and calibrates
the modality-induced activation shift to reduce the impact of modality on
safety. By isolating and removing the safety-relevant component, ShiftDC
restores the inherent safety alignment of the LLM backbone while preserving the
vision-language capabilities of VLMs. Empirical results demonstrate that
ShiftDC significantly enhances alignment performance on safety benchmarks
without impairing model utility.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¨æ´åäºè§è§æ¨¡æåï¼è§è§è¯­è¨æ¨¡å (VLM) æ´å®¹æåå°æå®³è¯·æ±åè¶ç±æ»å»ï¼è¡¨ç°åºæ¯å¶ä»ææ¬ç LLM ä¸»å¹²æ´å¤§çæ¼æ´ãä¸ºäºæ­ç¤ºè¿ç§ç°è±¡çæ ¹æ¬åå ï¼æä»¬è¿è¡äºæ·±å¥åæï¼å¹¶ç¡®å®äºä¸ä¸ªå³é®é®é¢ï¼ä¸ä»ææ¬çå¯¹åºç©ç¸æ¯ï¼å¤æ¨¡æè¾å¥å¼å¥äºæâæ´å®å¨âæ¹åçæ¨¡æè¯±å¯¼æ¿æ´»è½¬ç§»ï¼å¯¼è´ VLM ç³»ç»æ§å°é«ä¼°æå®³è¾å¥çå®å¨æ§ãæä»¬å°æ­¤é®é¢ç§°ä¸ºå®å¨æç¥æ­æ²ãä¸ºäºåè½»è¿ç§æ­æ²ï¼æä»¬æåºäºæ¿æ´»è½¬ç§»è§£è¦åæ ¡å (ShiftDC)ï¼è¿æ¯ä¸ç§æ è®­ç»æ¹æ³ï¼ç¨äºåè§£åæ ¡åæ¨¡æè¯±å¯¼çæ¿æ´»è½¬ç§»ï¼ä»¥åå°æ¨¡æå¯¹å®å¨æ§çå½±åãéè¿éç¦»åç§»é¤ä¸å®å¨æ§ç¸å³çç»ä»¶ï¼ShiftDC æ¢å¤äº LLM ä¸»å¹²çåºæå®å¨æ§å¯¹é½ï¼åæ¶ä¿çäº VLM çè§è§è¯­è¨è½åãå®è¯ç»æè¡¨æï¼ShiftDC å¨ä¸æå®³æ¨¡åæç¨çæåµä¸ï¼æ¾èå¢å¼ºäºå®å¨åºåä¸çå¯¹é½æ§è½ã

##### **Text2World: Benchmarking Large Language Models for Symbolic World Model Generation**
2502.13092v1 by Mengkang Hu, Tianxing Chen, Yude Zou, Yuheng Lei, Qiguang Chen, Ming Li, Hongyuan Zhang, Wenqi Shao, Ping Luo

Recently, there has been growing interest in leveraging large language models
(LLMs) to generate symbolic world models from textual descriptions. Although
LLMs have been extensively explored in the context of world modeling, prior
studies encountered several challenges, including evaluation randomness,
dependence on indirect metrics, and a limited domain scope. To address these
limitations, we introduce a novel benchmark, Text2World, based on planning
domain definition language (PDDL), featuring hundreds of diverse domains and
employing multi-criteria, execution-based metrics for a more robust evaluation.
We benchmark current LLMs using Text2World and find that reasoning models
trained with large-scale reinforcement learning outperform others. However,
even the best-performing model still demonstrates limited capabilities in world
modeling. Building on these insights, we examine several promising strategies
to enhance the world modeling capabilities of LLMs, including test-time
scaling, agent training, and more. We hope that Text2World can serve as a
crucial resource, laying the groundwork for future research in leveraging LLMs
as world models. The project page is available at
https://text-to-world.github.io/.

æè¦ï¼æè¿ï¼äººä»¬è¶æ¥è¶æå´è¶£å©ç¨å¤§åè¯­è¨æ¨¡åï¼LLMï¼ä»ææ¬æè¿°ä¸­çæç¬¦å·ä¸çæ¨¡åãå°½ç®¡ LLM å·²å¨ä¸çå»ºæ¨¡çèæ¯ä¸å¾å°å¹¿æ³æ¢ç´¢ï¼ä½ååçç ç©¶éå°äºè¥å¹²ææï¼åæ¬è¯ä¼°éæºæ§ãå¯¹é´æ¥ææ çä¾èµä»¥åæéçé¢åèå´ãä¸ºäºè§£å³è¿äºéå¶ï¼æä»¬å¼å¥äºåºäºè§ååå®ä¹è¯­è¨ï¼PDDLï¼çæ°åºå Text2Worldï¼è¯¥åºååå«æ°ç¾ä¸ªä¸åçåï¼å¹¶éç¨åºäºæ§è¡çå¤æ åææ æ¥è¿è¡æ´ç¨³å¥çè¯ä¼°ãæä»¬ä½¿ç¨ Text2World å¯¹å½åç LLM è¿è¡äºåºåæµè¯ï¼åç°ä½¿ç¨å¤§è§æ¨¡å¼ºåå­¦ä¹ è®­ç»çæ¨çæ¨¡åä¼äºå¶ä»æ¨¡åãç¶èï¼å³ä½¿æ¯æ§è½æä½³çæ¨¡åå¨ä¸çå»ºæ¨¡æ¹é¢ä»ç¶è¡¨ç°åºæéçè½åãåºäºè¿äºè§è§£ï¼æä»¬ç ç©¶äºå ç§æå¸æçç­ç¥æ¥å¢å¼º LLM çä¸çå»ºæ¨¡è½åï¼åæ¬æµè¯æ¶ç¼©æ¾ãä»£çè®­ç»ç­ç­ãæä»¬å¸æ Text2World è½å¤ä½ä¸ºä¸é¡¹è³å³éè¦çèµæºï¼ä¸ºæªæ¥å©ç¨ LLM ä½ä¸ºä¸çæ¨¡åçç ç©¶å¥ å®åºç¡ãé¡¹ç®é¡µé¢å¯å¨ https://text-to-world.github.io/ è·å¾ã

##### **KAPPA: A Generic Patent Analysis Framework with Keyphrase-Based Portraits**
2502.13076v1 by Xin Xia, Yujin Wang, Jun Zhou, Guisheng Zhong, Linning Cai, Chen Zhang

Patent analysis highly relies on concise and interpretable document
representations, referred to as patent portraits. Keyphrases, both present and
absent, are ideal candidates for patent portraits due to their brevity,
representativeness, and clarity. In this paper, we introduce KAPPA, an
integrated framework designed to construct keyphrase-based patent portraits and
enhance patent analysis. KAPPA operates in two phases: patent portrait
construction and portrait-based analysis. To ensure effective portrait
construction, we propose a semantic-calibrated keyphrase generation paradigm
that integrates pre-trained language models with a prompt-based hierarchical
decoding strategy to leverage the multi-level structural characteristics of
patents. For portrait-based analysis, we develop a comprehensive framework that
employs keyphrase-based patent portraits to enable efficient and accurate
patent analysis. Extensive experiments on benchmark datasets of keyphrase
generation, the proposed model achieves significant improvements compared to
state-of-the-art baselines. Further experiments conducted on real-world patent
applications demonstrate that our keyphrase-based portraits effectively capture
domain-specific knowledge and enrich semantic representation for patent
analysis tasks.

æè¦ï¼å°å©åæé«åº¦ä¾è³´ç°¡æ½ä¸å¯è§£è®çæä»¶è¡¨ç¤ºï¼ç¨±çºå°å©æè¿°ãééµå­çµï¼ç¡è«æ¯å­å¨çéæ¯ä¸å­å¨çï¼é½æ¯å°å©æè¿°ççæ³åé¸èï¼å çºå®åç°¡æ½ãå·æä»£è¡¨æ§ä¸æ¸æ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äº KAPPAï¼ä¸åç¨æ¼å»ºæ§åºæ¼ééµå­çµçå°å©æè¿°åå¢å¼·å°å©åæçæ´åå¼æ¶æ§ãKAPPA åçºå©åéæ®µå·è¡ï¼å°å©æè¿°å»ºæ§ååºæ¼æè¿°çåæãçºç¢ºä¿ææçæè¿°å»ºæ§ï¼æåæåºäºä¸åèªç¾©æ ¡æºééµå­çµçæç¯ä¾ï¼å®å°é åè¨ç·´çèªè¨æ¨¡åèåºæ¼æç¤ºçåå±¤è§£ç¢¼ç­ç¥æ´åå¨ä¸èµ·ï¼ä»¥å©ç¨å°å©çå¤åå±¤çµæ§ç¹æ§ãå°æ¼åºæ¼æè¿°çåæï¼æåéç¼äºä¸åå¨é¢çæ¶æ§ï¼å®æ¡ç¨åºæ¼ééµå­çµçå°å©æè¿°ï¼ä»¥å¯¦ç¾é«æä¸æºç¢ºçå°å©åæãå¨ééµå­çµçæåºæºè³æéä¸é²è¡çå»£æ³å¯¦é©ä¸­ï¼èæåé²çåºæºç·ç¸æ¯ï¼ææåºçæ¨¡ååå¾äºé¡¯èçæ¹é²ãå¨çå¯¦ä¸çå°å©ç³è«ä¸é²è¡çé²ä¸æ­¥å¯¦é©è¡¨æï¼æååºæ¼ééµå­çµçæè¿°ææå°æ·åäºç¹å®é åçç¥è­ï¼ä¸¦è±å¯äºå°å©åæä»»åçèªç¾©è¡¨ç¤ºã

##### **Interactive Agents to Overcome Ambiguity in Software Engineering**
2502.13069v1 by Sanidhya Vijayvargiya, Xuhui Zhou, Akhila Yerukola, Maarten Sap, Graham Neubig

AI agents are increasingly being deployed to automate tasks, often based on
ambiguous and underspecified user instructions. Making unwarranted assumptions
and failing to ask clarifying questions can lead to suboptimal outcomes, safety
risks due to tool misuse, and wasted computational resources. In this work, we
study the ability of LLM agents to handle ambiguous instructions in interactive
code generation settings by evaluating proprietary and open-weight models on
their performance across three key steps: (a) leveraging interactivity to
improve performance in ambiguous scenarios, (b) detecting ambiguity, and (c)
asking targeted questions. Our findings reveal that models struggle to
distinguish between well-specified and underspecified instructions. However,
when models interact for underspecified inputs, they effectively obtain vital
information from the user, leading to significant improvements in performance
and underscoring the value of effective interaction. Our study highlights
critical gaps in how current state-of-the-art models handle ambiguity in
complex software engineering tasks and structures the evaluation into distinct
steps to enable targeted improvements.

æè¦ï¼äººå·¥æºè½ä»£çæ­£è¶ä¾è¶å¤å°è¢«é¨ç½²ç¨æ¼èªååä»»åï¼éå¸¸åºæ¼æ¨¡æ£±å©å¯ä¸æªæç¢ºè¦å®çä½¿ç¨èæä»¤ãååºä¸åççåè¨­ä¸æªè½æåºæ¾æ¸åé¡ï¼å¯è½å°è´æ¬¡ä½³çµæãå å·¥å·èª¤ç¨èç¢ççå®å¨é¢¨éªï¼ä»¥åæµªè²»éç®è³æºãå¨éé å·¥ä½ä¸­ï¼æåç ç©¶äº LLM ä»£çå¨äºåå¼ç¨å¼ç¢¼çæè¨­å®ä¸­èçæ¨¡æ£±å©å¯æä»¤çè½åï¼æ¹æ³æ¯å¨ä¸åééµæ­¥é©ä¸­è©ä¼°å°æåéæ¾æ¬éçæ¨¡åï¼ (a) å©ç¨äºåæ§ä¾æåå¨æ¨¡æ£±å©å¯å ´æ¯ä¸­çæè½ã(b) åµæ¸¬æ¨¡ç³æ§ï¼ä»¥å (c) æåºç®æ¨åé¡ãæåçç ç©¶çµæé¡¯ç¤ºï¼æ¨¡åé£ä»¥ååæç¢ºè¦ç¯çæä»¤åæªæç¢ºè¦ç¯çæä»¤ãç¶èï¼ç¶æ¨¡åéå°æªæç¢ºè¦ç¯çè¼¸å¥é²è¡äºåæï¼å®åæææå°å¾ä½¿ç¨èåå¾éè¦è³è¨ï¼é²èå¤§å¹æåæè½ï¼ä¸¦å¼·èª¿ææäºåçå¹å¼ãæåçç ç©¶çªé¡¯äºç®åæåé²çæ¨¡åå¨èçè¤éè»é«å·¥ç¨ä»»åä¸­çæ¨¡ç³æ§æå­å¨åªäºééµå·®è·ï¼ä¸¦å°è©ä¼°æ¶æ§çºä¸åçæ­¥é©ï¼ä»¥ä¿ææç®æ¨çæ¹åã

##### **Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity**
2502.13063v1 by Yuri Kuratov, Mikhail Arkhipov, Aydar Bulatov, Mikhail Burtsev

A range of recent works addresses the problem of compression of sequence of
tokens into a shorter sequence of real-valued vectors to be used as inputs
instead of token embeddings or key-value cache. These approaches allow to
reduce the amount of compute in existing language models. Despite relying on
powerful models as encoders, the maximum attainable lossless compression ratio
is typically not higher than x10. This fact is highly intriguing because, in
theory, the maximum information capacity of large real-valued vectors is far
beyond the presented rates even for 16-bit precision and a modest vector size.
In this work, we explore the limits of compression by replacing the encoder
with a per-sample optimization procedure. We show that vectors with compression
ratios up to x1500 exist, which highlights two orders of magnitude gap between
existing and practically attainable solutions. Furthermore, we empirically show
that the compression limits are determined not by the length of the input but
by the amount of uncertainty to be reduced, namely, the cross-entropy loss on
this sequence without any conditioning. The obtained limits highlight the
substantial gap between the theoretical capacity of input embeddings and their
practical utilization, suggesting significant room for optimization in model
design.

æè¦ï¼ä¸ç³»åè¿æä½åæ¢è®¨äºå°åºåæ è®°åç¼©æè¾ç­çå®å¼åéåºåçé®é¢ï¼ä»¥ç¨ä½è¾å¥ï¼èä¸æ¯æ è®°åµå¥æé®å¼ç¼å­ãè¿äºæ¹æ³åè®¸åå°ç°æè¯­è¨æ¨¡åä¸­çè®¡ç®éãå°½ç®¡ä¾èµäºå¼ºå¤§çæ¨¡åä½ä¸ºç¼ç å¨ï¼ä½æå¤§å¯è¾¾å°çæ æåç¼©æ¯éå¸¸ä¸é«äº x10ãè¿ä¸äºå®éå¸¸æè¶£ï¼å ä¸ºçè®ºä¸ï¼å³ä½¿å¯¹äº 16 ä½ç²¾åº¦åéä¸­çåéå¤§å°ï¼å¤§åå®å¼åéçæå¤§ä¿¡æ¯å®¹éä¹è¿è¿è¶åºäºæåç°çéçãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬éè¿ç¨ææ ·æ¬ä¼åç¨åºæ¿æ¢ç¼ç å¨æ¥æ¢ç´¢åç¼©çæéãæä»¬è¡¨æï¼å­å¨åç¼©æ¯é«è¾¾ x1500 çåéï¼è¿çªåºäºç°æè§£å³æ¹æ¡åå®éå¯å®ç°è§£å³æ¹æ¡ä¹é´ä¸¤ä¸ªæ°éçº§çå·®è·ãæ­¤å¤ï¼æä»¬å­ç»éªè¡¨æï¼åç¼©æéä¸æ¯ç±è¾å¥çé¿åº¦å³å®çï¼èæ¯ç±è¦åå°çä¸ç¡®å®æ§éå³å®çï¼å³å¨æ­¤åºåä¸çäº¤åçµæå¤±ï¼æ²¡æä»»ä½æ¡ä»¶ãè·å¾çæéçªåºäºè¾å¥åµå¥ççè®ºå®¹éä¸å¶å®éå©ç¨ä¹é´çå·¨å¤§å·®è·ï¼è¡¨ææ¨¡åè®¾è®¡ä¸­æå¾å¤§çä¼åç©ºé´ã

##### **AI-Assisted Decision Making with Human Learning**
2502.13062v1 by Gali Noti, Kate Donahue, Jon Kleinberg, Sigal Oren

AI systems increasingly support human decision-making. In many cases, despite
the algorithm's superior performance, the final decision remains in human
hands. For example, an AI may assist doctors in determining which diagnostic
tests to run, but the doctor ultimately makes the diagnosis. This paper studies
such AI-assisted decision-making settings, where the human learns through
repeated interactions with the algorithm. In our framework, the algorithm --
designed to maximize decision accuracy according to its own model -- determines
which features the human can consider. The human then makes a prediction based
on their own less accurate model. We observe that the discrepancy between the
algorithm's model and the human's model creates a fundamental tradeoff. Should
the algorithm prioritize recommending more informative features, encouraging
the human to recognize their importance, even if it results in less accurate
predictions in the short term until learning occurs? Or is it preferable to
forgo educating the human and instead select features that align more closely
with their existing understanding, minimizing the immediate cost of learning?
This tradeoff is shaped by the algorithm's time-discounted objective and the
human's learning ability. Our results show that optimal feature selection has a
surprisingly clean combinatorial characterization, reducible to a stationary
sequence of feature subsets that is tractable to compute. As the algorithm
becomes more "patient" or the human's learning improves, the algorithm
increasingly selects more informative features, enhancing both prediction
accuracy and the human's understanding. Notably, early investment in learning
leads to the selection of more informative features than a later investment. We
complement our analysis by showing that the impact of errors in the algorithm's
knowledge is limited as it does not make the prediction directly.

æè¦ï¼äººå·¥æºæ§ç³»çµ±æ¥çæ¯æ´äººé¡æ±ºç­ãå¨è¨±å¤ææ³ä¸ï¼åç®¡æ¼ç®æ³çæè½åªç°ï¼æçµæ±ºç­ä»ææ¡å¨äººé¡æä¸­ãä¾å¦ï¼äººå·¥æºæ§å¯è½æåå©é«çæ±ºå®è¦å·è¡åªäºè¨ºæ·æ¸¬è©¦ï¼ä½æçµä¸è¨ºæ·çæ¯é«çãæ¬ææ¢è¨æ­¤é¡äººå·¥æºæ§è¼å©æ±ºç­è¨­å®ï¼å¶ä¸­äººé¡ééèæ¼ç®æ³éè¤äºåèå­¸ç¿ãå¨æåçæ¶æ§ä¸­ï¼æ¼ç®æ³ï¼æ¨å¨æ ¹æå¶èªèº«æ¨¡åæå¤§åæ±ºç­æºç¢ºåº¦ï¼ææ±ºå®äººé¡å¯ä»¥èéçç¹å¾µãç¶å¾ï¼äººé¡æ ¹æå¶èªèº«è¼ä¸æºç¢ºçæ¨¡åååºé æ¸¬ãæåè§å¯å°ï¼æ¼ç®æ³æ¨¡åèäººé¡æ¨¡åä¹éçå·®ç°æç¢çåºæ¬çæ¬è¡¡ãæ¼ç®æ³æ¯å¦æåªåæ¨è¦æ´å¤è³è¨æ§ç¹å¾µï¼é¼åµäººé¡èªè­å¶éè¦æ§ï¼å³ä½¿ç­æå§æå°è´æºç¢ºåº¦è¼ä½çé æ¸¬ï¼ç´å°å­¸ç¿ç¼çï¼æèï¼æ¯å¦è¼å¥½æ¾æ£æè²äººé¡ï¼èé¸æèå¶ç¾æçè§£æ´ç·å¯å°é½çç¹å¾µï¼å°å­¸ç¿çç«å³ææ¬éè³æä½ï¼éç¨®æ¬è¡¡åæ±ºæ¼æ¼ç®æ³çæéæç¾ç®æ¨åäººé¡çå­¸ç¿è½åãæåççµæè¡¨æï¼æä½³ç¹å¾µé¸æå·æä»¤äººé©è¨çä¹¾æ·¨çµåç¹å¾µï¼å¯ç°¡åçºå¯è¨ç®çåºå®ç¹å¾µå­éåºåãé¨èæ¼ç®æ³è®å¾æ´ãæèå¿ãæäººé¡çå­¸ç¿é²æ­¥ï¼æ¼ç®æ³æè¶ä¾è¶å¤å°é¸ææ´å¤è³è¨æ§ç¹å¾µï¼å¢å¼·é æ¸¬æºç¢ºåº¦åäººé¡ççè§£ãå¼å¾æ³¨æçæ¯ï¼æ©ææè³æ¼å­¸ç¿æå°è´é¸ææ¯å¾ææè³æ´å¤è³è¨æ§ç¹å¾µãæåééé¡¯ç¤ºæ¼ç®æ³ç¥è­ä¸­é¯èª¤çå½±é¿æ¯æéçï¼å çºå®ä¸æç´æ¥ååºé æ¸¬ï¼ä¾è£åæåçåæã

##### **Improved Fine-Tuning of Large Multimodal Models for Hateful Meme Detection**
2502.13061v1 by Jingbiao Mei, Jinghong Chen, Guangyu Yang, Weizhe Lin, Bill Byrne

Hateful memes have become a significant concern on the Internet,
necessitating robust automated detection systems. While large multimodal models
have shown strong generalization across various tasks, they exhibit poor
generalization to hateful meme detection due to the dynamic nature of memes
tied to emerging social trends and breaking news. Recent work further
highlights the limitations of conventional supervised fine-tuning for large
multimodal models in this context. To address these challenges, we propose
Large Multimodal Model Retrieval-Guided Contrastive Learning (LMM-RGCL), a
novel two-stage fine-tuning framework designed to improve both in-domain
accuracy and cross-domain generalization. Experimental results on six widely
used meme classification datasets demonstrate that LMM-RGCL achieves
state-of-the-art performance, outperforming agent-based systems such as
VPD-PALI-X-55B. Furthermore, our method effectively generalizes to
out-of-domain memes under low-resource settings, surpassing models like GPT-4o.

æè¦ï¼ç¶²è·¯ä¸çä»æ¨è¿·å å·²æçºä¸å¤§é±æï¼å æ­¤éè¦å¼·å¤§çèªåååµæ¸¬ç³»çµ±ãéç¶å¤§åå¤æ¨¡ææ¨¡åå·²å¨åç¨®ä»»åä¸­å±ç¾åºå¼·å¤§çæ³åè½åï¼ä½ç±æ¼è¿·å èæ°èç¤¾æè¶¨å¢åçªç¼æ°èæ¯æ¯ç¸éï¼å æ­¤å¨ä»æ¨è¿·å åµæ¸¬æ¹é¢è¡¨ç¾ä¸ä½³ãæè¿çç ç©¶é²ä¸æ­¥å¼·èª¿äºå¨éç¨®ææ³ä¸ï¼å³çµ±ç£ç£å¾®èª¿å°å¤§åå¤æ¨¡ææ¨¡åçéå¶ãçºäºæå°éäºææ°ï¼æåæåºäºå¤§åå¤æ¨¡ææ¨¡åæª¢ç´¢å¼å°å°æ¯å­¸ç¿ (LMM-RGCL)ï¼éæ¯ä¸ç¨®æ°ç©çå©éæ®µå¾®èª¿æ¶æ§ï¼æ¨å¨æé«é åå§æºç¢ºåº¦åè·¨é åæ³åè½åãå¨å­åå»£æ³ä½¿ç¨çè¿·å åé¡è³æéä¸çå¯¦é©çµæè¡¨æï¼LMM-RGCL éå°äºæåé²çæè½ï¼åªæ¼åºæ¼ä»£ççç³»çµ±ï¼ä¾å¦ VPD-PALI-X-55Bãæ­¤å¤ï¼æåçæ¨¡åå¨ä½è³æºè¨­å®ä¸æææ³åå°é åå¤è¿·å ï¼è¶è¶äº GPT-4o ç­æ¨¡åã

##### **SimpleVQA: Multimodal Factuality Evaluation for Multimodal Large Language Models**
2502.13059v1 by Xianfu Cheng, Wei Zhang, Shiwei Zhang, Jian Yang, Xiangyuan Guan, Xianjie Wu, Xiang Li, Ge Zhang, Jiaheng Liu, Yuying Mai, Yutao Zeng, Zhoufutu Wen, Ke Jin, Baorui Wang, Weixiao Zhou, Yunhong Lu, Tongliang Li, Wenhao Huang, Zhoujun Li

The increasing application of multi-modal large language models (MLLMs)
across various sectors have spotlighted the essence of their output reliability
and accuracy, particularly their ability to produce content grounded in factual
information (e.g. common and domain-specific knowledge). In this work, we
introduce SimpleVQA, the first comprehensive multi-modal benchmark to evaluate
the factuality ability of MLLMs to answer natural language short questions.
SimpleVQA is characterized by six key features: it covers multiple tasks and
multiple scenarios, ensures high quality and challenging queries, maintains
static and timeless reference answers, and is straightforward to evaluate. Our
approach involves categorizing visual question-answering items into 9 different
tasks around objective events or common knowledge and situating these within 9
topics. Rigorous quality control processes are implemented to guarantee
high-quality, concise, and clear answers, facilitating evaluation with minimal
variance via an LLM-as-a-judge scoring system. Using SimpleVQA, we perform a
comprehensive assessment of leading 18 MLLMs and 8 text-only LLMs, delving into
their image comprehension and text generation abilities by identifying and
analyzing error cases.

æè¦ï¼é¨èå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å¨ååé åçæç¨æ¥çæ®åï¼å¶è¼¸åºçµæçå¯é æ§åæºç¢ºæ§å·²ååéæ³¨ï¼ç¹å¥æ¯å¶æ ¹æäºå¯¦è³è¨ï¼ä¾å¦ä¸è¬ç¥è­åç¹å®é åç¥è­ï¼ç¢çå§å®¹çè½åãå¨æ¬æä¸­ï¼æåä»ç´¹ SimpleVQAï¼éæ¯ç¬¬ä¸åç¨æ¼è©ä¼° MLLM åç­èªç¶èªè¨ç°¡ç­åé¡çäºå¯¦è½åçç¶åå¤æ¨¡æåºæºãSimpleVQA æå­åä¸»è¦ç¹å¾µï¼æ¶µèå¤é ä»»ååå¤ç¨®æå¢ãç¢ºä¿é«åè³ªä¸å·ææ°æ§çæ¥è©¢ãç¶­è­·éæä¸æ°¸æçåèç­æ¡ï¼èä¸è©ä¼°èµ·ä¾å¾ç°¡å®ãæåçåæ³æ¯å°è¦è¦ºåç­é ç®åé¡çº 9 åä¸åçä»»åï¼åç¹å®¢è§äºä»¶æå¸¸è­ï¼ä¸¦å°å®åç½®æ¼ 9 åä¸»é¡ä¸­ãæåå¯¦æ½å´æ ¼çåè³ªæ§ç®¡æµç¨ï¼ä»¥ä¿è­ç­æ¡çé«åè³ªãç°¡æ½åæ¸æ°ï¼ä¸¦éé LLM ä½çºè©åç³»çµ±ï¼ä»¥æå°çå·®ç°é²è¡è©ä¼°ãæåä½¿ç¨ SimpleVQA å° 18 åä¸»è¦ç MLLM å 8 åç´æå­ LLM é²è¡å¨é¢è©ä¼°ï¼ééæ¾åºååæé¯èª¤æ¡ä¾ï¼æ·±å¥æ¢è¨å®åçå½±åçè§£åæå­çæè½åã

##### **LAMD: Context-driven Android Malware Detection and Classification with LLMs**
2502.13055v1 by Xingzhi Qian, Xinran Zheng, Yiling He, Shuo Yang, Lorenzo Cavallaro

The rapid growth of mobile applications has escalated Android malware
threats. Although there are numerous detection methods, they often struggle
with evolving attacks, dataset biases, and limited explainability. Large
Language Models (LLMs) offer a promising alternative with their zero-shot
inference and reasoning capabilities. However, applying LLMs to Android malware
detection presents two key challenges: (1)the extensive support code in Android
applications, often spanning thousands of classes, exceeds LLMs' context limits
and obscures malicious behavior within benign functionality; (2)the structural
complexity and interdependencies of Android applications surpass LLMs'
sequence-based reasoning, fragmenting code analysis and hindering malicious
intent inference. To address these challenges, we propose LAMD, a practical
context-driven framework to enable LLM-based Android malware detection. LAMD
integrates key context extraction to isolate security-critical code regions and
construct program structures, then applies tier-wise code reasoning to analyze
application behavior progressively, from low-level instructions to high-level
semantics, providing final prediction and explanation. A well-designed factual
consistency verification mechanism is equipped to mitigate LLM hallucinations
from the first tier. Evaluation in real-world settings demonstrates LAMD's
effectiveness over conventional detectors, establishing a feasible basis for
LLM-driven malware analysis in dynamic threat landscapes.

æè¦ï¼é¨èè¡åæç¨ç¨å¼å¿«éæé·ï¼Android æ¡æè»é«å¨èä¹é¨ä¹åç´ãéç¶æè¨±å¤åµæ¸¬æ¹æ³ï¼ä½å®åç¶å¸¸é£ä»¥æä»ä¸æ·æ¼é²çæ»æãè³æéåå·®åæéçå¯è§£éæ§ãå¤§åèªè¨æ¨¡å (LLM) æä¾äºä¸åæåéçæ¿ä»£æ¹æ¡ï¼å·åé¶æ¬¡å­¸ç¿æ¨çåæ¨çè½åãç¶èï¼å° LLM æç¨æ¼ Android æ¡æè»é«åµæ¸¬æåºç¾å©åä¸»è¦ææ°ï¼(1) Android æç¨ç¨å¼ä¸­å¤§éçæ¯æ´ç¨å¼ç¢¼ï¼éå¸¸æ©«è·¨æ¸ååé¡å¥ï¼è¶é LLM çä¸ä¸æéå¶ï¼ä¸¦æ¨¡ç³äºè¯æ§åè½ä¸­çæ¡æè¡çºï¼(2) Android æç¨ç¨å¼ççµæ§è¤éæ§åç¸äºä¾è³´æ§è¶é LLM çåºæ¼åºåçæ¨çï¼æé æç¨å¼ç¢¼åæç ´ç¢ï¼ä¸¦é»ç¤æ¡ææåæ¨è«ãçºäºæå°éäºææ°ï¼æåæåºäº LAMDï¼ä¸åå¯¦ç¨çèçµ¡é©åæ¶æ§ï¼ä»¥æ¯æ´åºæ¼ LLM ç Android æ¡æè»é«åµæ¸¬ãLAMD æ´åäºééµèçµ¡èåï¼ä»¥éé¢èå®å¨æ§è³ééè¦çç¨å¼ç¢¼ååä¸¦å»ºæ§ç¨å¼çµæ§ï¼ç¶å¾å¥ç¨åå±¤å¼ç¨å¼ç¢¼æ¨çï¼éæ­¥åææç¨ç¨å¼è¡çºï¼å¾ä½éæä»¤å°é«éèªæï¼æä¾æçµé æ¸¬åèªªæãä¸åè¨­è¨è¯å¥½çäºå¯¦ä¸è´æ§é©è­æ©å¶å·åæ¸è¼ LLM å¾ç¬¬ä¸å±¤ç¢ççå¹»è¦ºçè½åãå¨çå¯¦ç°å¢ä¸­çè©ä¼°é¡¯ç¤ºï¼LAMD åªæ¼å³çµ±åµæ¸¬å¨ï¼çºåæå¨èç°å¢ä¸­ç LLM é©åæ¡æè»é«åæå»ºç«äºä¸åå¯è¡çåºç¤ã

##### **Do we still need Human Annotators? Prompting Large Language Models for Aspect Sentiment Quad Prediction**
2502.13044v1 by Nils Constantin Hellwig, Jakob Fehle, Udo Kruschwitz, Christian Wolff

Aspect sentiment quadruple prediction (ASQP) facilitates a detailed
understanding of opinions expressed in a text by identifying the opinion term,
aspect term, aspect category and sentiment polarity for each opinion. However,
annotating a full set of training examples to fine-tune models for ASQP is a
resource-intensive process. In this study, we explore the capabilities of large
language models (LLMs) for zero- and few-shot learning on the ASQP task across
five diverse datasets. We report F1 scores slightly below those obtained with
state-of-the-art fine-tuned models but exceeding previously reported zero- and
few-shot performance. In the 40-shot setting on the Rest16 restaurant domain
dataset, LLMs achieved an F1 score of 52.46, compared to 60.39 by the
best-performing fine-tuned method MVP. Additionally, we report the performance
of LLMs in target aspect sentiment detection (TASD), where the F1 scores were
also close to fine-tuned models, achieving 66.03 on Rest16 in the 40-shot
setting, compared to 72.76 with MVP. While human annotators remain essential
for achieving optimal performance, LLMs can reduce the need for extensive
manual annotation in ASQP tasks.

æè¦ï¼é¢åè§é»çååé æ¸¬ (ASQP) ééè¾¨è­ååè§é»çè§é»è©å½ãé¢åè©å½ãé¢åé¡å¥åè§é»æ¥µæ§ï¼åå©è©³ç´°äºè§£æå­ä¸­è¡¨éçæè¦ãç¶èï¼æ¨è¨»ä¸çµå®æ´çè¨ç·´ç¯ä¾ä»¥å¾®èª¿ ASQP æ¨¡åæ¯ä¸åèè²»è³æºçéç¨ãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨ ASQP ä»»åä¸­é²è¡é¶æ¬¡åå°éå­¸ç¿çè½åï¼æ©«è·¨äºåä¸åçè³æéãæåå ±åç F1 åæ¸ç¥ä½æ¼ä½¿ç¨æåé²çå¾®èª¿æ¨¡åç²å¾çåæ¸ï¼ä½è¶éååå ±åçé¶æ¬¡åå°éå­¸ç¿è¡¨ç¾ãå¨ Rest16 é¤å»³é åè³æéç 40 æ¬¡å­¸ç¿è¨­å®ä¸­ï¼LLM éå°äº 52.46 ç F1 åæ¸ï¼èæè½æä½³çå¾®èª¿æ¹æ³ MVP åçº 60.39ãæ­¤å¤ï¼æåå ±åäº LLM å¨ç®æ¨é¢åè§é»åµæ¸¬ (TASD) ä¸­çè¡¨ç¾ï¼å¶ä¸­ F1 åæ¸ä¹æ¥è¿å¾®èª¿æ¨¡åï¼å¨ 40 æ¬¡å­¸ç¿è¨­å®ä¸­æ¼ Rest16 éå° 66.03ï¼è MVP åçº 72.76ãåç®¡äººé¡æ¨è¨»å¡å°æ¼éææä½³æè½ä»ç¶è³ééè¦ï¼ä½ LLM å¯ä»¥æ¸å° ASQP ä»»åä¸­å»£æ³æåæ¨è¨»çéæ±ã

##### **Natural Language Generation from Visual Sequences: Challenges and Future Directions**
2502.13034v1 by Aditya K Surikuchi, Raquel FernÃ¡ndez, Sandro Pezzelle

The ability to use natural language to talk about visual content is at the
core of human intelligence and a crucial feature of any artificial intelligence
system. Various studies have focused on generating text for single images. In
contrast, comparatively little attention has been paid to exhaustively
analyzing and advancing work on multiple-image vision-to-text settings. In this
position paper, we claim that any task dealing with temporally ordered
sequences of multiple images or frames is an instance of a broader, more
general problem involving the understanding of intricate relationships between
the visual content and the corresponding text. We comprehensively analyze five
tasks that are instances of this problem and argue that they pose a common set
of challenges and share similarities in terms of modeling and evaluation
approaches. Based on the insights from these various aspects and stages of
multi-image-to-text generation, we highlight several open questions and suggest
future research directions. We believe that these directions can advance the
understanding of complex phenomena in this domain and the development of better
models.

æè¦ï¼ä½¿ç¨èªç¶èªè¨ä¾è«è«è¦è¦ºå§å®¹çè½åæ¯äººé¡æºæ§çæ ¸å¿ï¼ä¹æ¯ä»»ä½äººå·¥æºæ§ç³»çµ±çä¸é ééµåè½ãåç¨®ç ç©¶é½å°æ³¨æ¼çºå®ä¸å½±åç¢çæå­ãç¸è¼ä¹ä¸ï¼å°æ¼è©³ç¡åæåæ¨é²å¤éå½±åè¦è¦ºè½æå­è¨­å®çå·¥ä½ï¼éæ³¨è¼å°ãå¨æ­¤ç«å ´æä»¶ä¸­ï¼æåè²ç¨±ä»»ä½èçå¤éå½±åæç«æ ¼çæéé åºåºåçä»»åï¼é½æ¯ä¸åæ´å»£æ³ãæ´æ®éåé¡çç¯ä¾ï¼æ¶åçè§£è¦è¦ºå§å®¹åå°ææå­ä¹éçè¤ééä¿ãæåå¨é¢åæäºæ­¤åé¡çäºåç¯ä¾ä»»åï¼ä¸¦è«è­å®åæåºäºä¸çµå¸¸è¦çææ°ï¼ä¸å¨å»ºæ¨¡åè©ä¼°æ¹æ³æ¹é¢æç¸ä¼¼ä¹èãæ ¹æå¤éå½±åè½æå­çæçéäºä¸åé¢ååéæ®µçè¦è§£ï¼æåçªåºäºå¹¾åéæ¾æ§åé¡ï¼ä¸¦å»ºè­°æªä¾çç ç©¶æ¹åãæåç¸ä¿¡éäºæ¹åå¯ä»¥æ¨é²å°æ­¤é åä¸­è¤éç¾è±¡ççè§£ï¼ä»¥åéç¼åºæ´å¥½çæ¨¡åã

##### **HPSS: Heuristic Prompting Strategy Search for LLM Evaluators**
2502.13031v1 by Bosi Wen, Pei Ke, Yufei Sun, Cunxiang Wang, Xiaotao Gu, Jinfeng Zhou, Jie Tang, Hongning Wang, Minlie Huang

Since the adoption of large language models (LLMs) for text evaluation has
become increasingly prevalent in the field of natural language processing
(NLP), a series of existing works attempt to optimize the prompts for LLM
evaluators to improve their alignment with human judgment. However, their
efforts are limited to optimizing individual factors of evaluation prompts,
such as evaluation criteria or output formats, neglecting the combinatorial
impact of multiple factors, which leads to insufficient optimization of the
evaluation pipeline. Nevertheless, identifying well-behaved prompting
strategies for adjusting multiple factors requires extensive enumeration. To
this end, we comprehensively integrate 8 key factors for evaluation prompts and
propose a novel automatic prompting strategy optimization method called
Heuristic Prompting Strategy Search (HPSS). Inspired by the genetic algorithm,
HPSS conducts an iterative search to find well-behaved prompting strategies for
LLM evaluators. A heuristic function is employed to guide the search process,
enhancing the performance of our algorithm. Extensive experiments across four
evaluation tasks demonstrate the effectiveness of HPSS, consistently
outperforming both human-designed evaluation prompts and existing automatic
prompt optimization methods.

æè¦ï¼é¨èèªç¶èªè¨èçï¼NLPï¼é åä¸­æ¡ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼é²è¡ææ¬è©ä¼°è®å¾è¶ä¾è¶æ®éï¼ä¸ç³»åç¾æå·¥ä½åè©¦åªå LLM è©ä¼°å¨çæç¤ºï¼ä»¥æ¹åå®åèäººé¡å¤æ·çä¸è´æ§ãç¶èï¼ä»åçåªååéæ¼åªåè©ä¼°æç¤ºçåå¥å ç´ ï¼ä¾å¦è©ä¼°æºåæè¼¸åºæ ¼å¼ï¼èå¿½ç¥äºå¤ç¨®å ç´ ççµåå½±é¿ï¼éå°è´è©ä¼°ç®¡éåªåä¸è¶³ãåç®¡å¦æ­¤ï¼æ¾åºèª¿æ´å¤ç¨®å ç´ çè¯å¥½æç¤ºç­ç¥éè¦å»£æ³çæèãçºæ­¤ï¼æåå¨é¢æ´åäºè©ä¼°æç¤ºç 8 åééµå ç´ ï¼ä¸¦æåºäºä¸ç¨®åçºåç¼å¼æç¤ºç­ç¥æç´¢ï¼HPSSï¼çæ°åèªåæç¤ºç­ç¥åªåæ¹æ³ãå¨éºå³æ¼ç®æ³çåç¼ä¸ï¼HPSS é²è¡åè¦æç´¢ä»¥æ¾åº LLM è©ä¼°å¨çè¯å¥½æç¤ºç­ç¥ãæ¡ç¨åç¼å¼å½æ¸ä¾æå°æç´¢éç¨ï¼å¢å¼·äºæåæ¼ç®æ³çæè½ãå¨åé è©ä¼°ä»»åä¸­é²è¡çå»£æ³å¯¦é©è­æäº HPSS çæææ§ï¼å§çµåªæ¼äººé¡è¨­è¨çè©ä¼°æç¤ºåç¾æçèªåæç¤ºåªåæ¹æ³ã

##### **Whose story is it? Personalizing story generation by inferring author styles**
2502.13028v1 by Nischal Ashok Kumar, Chau Minh Pham, Mohit Iyyer, Andrew Lan

Personalization has become essential for improving user experience in
interactive writing and educational applications, yet its potential in story
generation remains largely unexplored. In this work, we propose a novel
two-stage pipeline for personalized story generation. Our approach first infers
an author's implicit story-writing characteristics from their past work and
organizes them into an Author Writing Sheet, inspired by narrative theory. The
second stage uses this sheet to simulate the author's persona through tailored
persona descriptions and personalized story writing rules. To enable and
validate our approach, we construct Mythos, a dataset of 590 stories from 64
authors across five distinct sources that reflect diverse story-writing
settings. A head-to-head comparison with a non-personalized baseline
demonstrates our pipeline's effectiveness in generating high-quality
personalized stories. Our personalized stories achieve a 75 percent win rate
(versus 14 percent for the baseline and 11 percent ties) in capturing authors'
writing style based on their past works. Human evaluation highlights the high
quality of our Author Writing Sheet and provides valuable insights into the
personalized story generation task. Notable takeaways are that writings from
certain sources, such as Reddit, are easier to personalize than others, like
AO3, while narrative aspects, like Creativity and Language Use, are easier to
personalize than others, like Plot.

æè¦ï¼åäººåå·²æçºæ¹åäºåå¼å¯«ä½åæè²æç¨ç¨å¼ä¸­ä½¿ç¨èé«é©çå¿è¦ææ®µï¼ç¶èå¶å¨æäºçæä¸­çæ½åä»æªè¢«å»£æ³æ¢ç´¢ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ååµæ°çå©éæ®µæµç¨ï¼ç¨æ¼åäººåæäºçæãæåçåæ³é¦åå¾ä½èéå»çä½åä¸­æ¨è«åºä½èé±å«çæäºå¯«ä½ç¹å¾µï¼ä¸¦æ ¹ææäºçè«å°å®åçµç¹æä½èå¯«ä½è¡¨ãç¬¬äºéæ®µä½¿ç¨æ­¤è¡¨éééèº«æé çè§è²æè¿°ååäººåæäºå¯«ä½è¦åä¾æ¨¡æ¬ä½èçè§è²ãçºäºåç¨åé©è­æåçåæ³ï¼æåå»ºæ§äº Mythosï¼ä¸ååå«ä¾èª 64 ä½ä½èãæ©«è·¨äºåä¸åä¾æºç 590 åæäºçè³æéï¼éäºæäºåæ äºå¤æ¨£åçæäºå¯«ä½è¨­å®ãèéåäººååºæºé²è¡ä¸å°ä¸çæ¯è¼ï¼è­æäºæåçæµç¨å¨çæé«åè³ªåäººåæäºæ¹é¢çæææ§ãæåçåäººåæäºä»¥ 75% çç²åçï¼ç¸è¼æ¼åºæºç 14% å 11% å¹³æï¼ææå°ä½èåºæ¼å¶éå»ä½åçå¯«ä½é¢¨æ ¼ãäººé¡è©ä¼°çªé¡¯äºæåä½èå¯«ä½è¡¨çåªè¯åè³ªï¼ä¸¦æä¾äºå°åäººåæäºçæä»»åçå¯¶è²´è¦è§£ãå¼å¾æ³¨æçæ¯ï¼ä¾èªæäºä¾æºï¼ä¾å¦ Redditï¼çä½åæ¯å¶ä»ä¾æºï¼ä¾å¦ AO3ï¼æ´å®¹æåäººåï¼èæäºå±¤é¢ï¼ä¾å¦åµé ååèªè¨ä½¿ç¨ï¼æ¯å¶ä»å±¤é¢ï¼ä¾å¦æç¯ï¼æ´å®¹æåäººåã

##### **Agentic Deep Graph Reasoning Yields Self-Organizing Knowledge Networks**
2502.13025v1 by Markus J. Buehler

We present an agentic, autonomous graph expansion framework that iteratively
structures and refines knowledge in situ. Unlike conventional knowledge graph
construction methods relying on static extraction or single-pass learning, our
approach couples a reasoning-native large language model with a continually
updated graph representation. At each step, the system actively generates new
concepts and relationships, merges them into a global graph, and formulates
subsequent prompts based on its evolving structure. Through this
feedback-driven loop, the model organizes information into a scale-free network
characterized by hub formation, stable modularity, and bridging nodes that link
disparate knowledge clusters. Over hundreds of iterations, new nodes and edges
continue to appear without saturating, while centrality measures and shortest
path distributions evolve to yield increasingly distributed connectivity. Our
analysis reveals emergent patterns, such as the rise of highly connected 'hub'
concepts and the shifting influence of 'bridge' nodes, indicating that agentic,
self-reinforcing graph construction can yield open-ended, coherent knowledge
structures. Applied to materials design problems, we present compositional
reasoning experiments by extracting node-specific and synergy-level principles
to foster genuinely novel knowledge synthesis, yielding cross-domain ideas that
transcend rote summarization and strengthen the framework's potential for
open-ended scientific discovery. We discuss other applications in scientific
discovery and outline future directions for enhancing scalability and
interpretability.

æè¦ï¼<paragraph>æåæåºä¸åè½åçãèªä¸»çåå½¢æ´å±æ¡æ¶ï¼å®åè¦å°å»ºæ§åç²¾çåä½ç¥è­ãèä¾è³´éææåæå®æ¬¡å­¸ç¿çå³çµ±ç¥è­åå½¢å»ºæ§æ¹æ³ä¸åï¼æåçåæ³å°ä¸åæ¨çåççå¤§èªè¨æ¨¡åèä¸åæçºæ´æ°çåå½¢è¡¨ç¤ºçµåèµ·ä¾ãå¨æ¯ä¸æ­¥ä¸­ï¼ç³»çµ±ä¸»åç¢çæ°çæ¦å¿µåéä¿ï¼å°å®ååä½µå°ä¸åå¨ååå½¢ä¸­ï¼ä¸¦æ ¹æå¶ä¸æ·æ¼åççµæ§å¶å®å¾çºæç¤ºãéééååé¥é©åçè¿´åï¼æ¨¡åå°è³è¨çµç¹æä¸åç¡æ¨åº¦ç¶²è·¯ï¼å¶ç¹å¾µæ¯æ¨ç´å½¢æãç©©å®çæ¨¡çµåä»¥åé£çµä¸åç¥è­ç¾¤éçæ©æ¥ç¯é»ãå¨æ¸ç¾æ¬¡åè¦éç®ä¸­ï¼æ°çç¯é»åéç·£ææçºåºç¾ï¼èä¸æé£½åï¼åæä¸­å¿æ§æ¸¬éåæç­è·¯å¾åä½ææ¼åçºç¢çè¶ä¾è¶åæ£çé£éæ§ãæåçåææ­ç¤ºäºæ°èæ¨¡å¼ï¼ä¾å¦é«åº¦é£æ¥çãæ¨ç´ãæ¦å¿µçèèµ·åãæ©æ¨ãç¯é»å½±é¿åçè½ç§»ï¼éè¡¨æè½åçãèªæå¼·åçåå½¢å»ºæ§å¯ä»¥ç¢çéæ¾å¼ãé£è²«çç¥è­çµæ§ãæç¨æ¼ææè¨­è¨åé¡ï¼æåæåºçµåæ¨çå¯¦é©ï¼ééæåç¹å®æ¼ç¯é»çåååååææå±¤ç´ååï¼ä»¥ä¿é²çæ­£æ°ç©çç¥è­ç¶åï¼ç¢çè¶è¶æ­»èå¼æè¦ä¸¦å¼·åæ¡æ¶å¨éæ¾å¼ç§å­¸ç¼ç¾ä¸­æ½åçè·¨é åæ³æ³ãæåè¨è«äºå¨ç§å­¸ç¼ç¾ä¸­çå¶ä»æç¨ï¼ä¸¦æ¦è¿°äºå¢å¼·å¯æ´åæ§åå¯è§£éæ§çæªä¾æ¹åã</paragraph>

##### **Oreo: A Plug-in Context Reconstructor to Enhance Retrieval-Augmented Generation**
2502.13019v1 by Sha Li, Naren Ramarkrishnan

Despite the remarkable capabilities of Large Language Models (LLMs) in
various NLP tasks, they remain vulnerable to hallucinations due to their
limited parametric knowledge and lack of domain-specific expertise.
Retrieval-Augmented Generation (RAG) addresses this challenge by incorporating
external document retrieval to augment the knowledge base of LLMs. In this
approach, RAG retrieves document chunks from an external corpus in response to
a query, which are then used as context for the downstream language model to
generate an answer. However, these retrieved knowledge sources often include
irrelevant or erroneous information, undermining the effectiveness of RAG in
downstream tasks. To overcome this limitation, we introduce a compact,
efficient, and pluggable module designed to refine external knowledge sources
before feeding them to the generator. The module reconstructs retrieved content
by extracting the most relevant and supportive information and reorganising it
into a concise, query-specific format. Through a three-stage training paradigm
- comprising supervised fine-tuning, contrastive multi-task learning, and
reinforcement learning-based alignment - it prioritises critical knowledge and
aligns it with the generator's preferences. This method enables LLMs to produce
outputs that are more accurate, reliable, and contextually appropriate.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­å·ååè¶çè½åï¼ä½ç±æ¼å¶åæ¸ç¥è­æéä¸ç¼ºä¹ç¹å®é åçå°æ¥­ç¥è­ï¼å æ­¤å®åä»ç¶å®¹æåºç¾å¹»è¦ºãæª¢ç´¢å¢å¼·å¼çæ (RAG) ééç´å¥å¤é¨æä»¶æª¢ç´¢ä¾æ´å LLM çç¥è­åº«ï¼ä»¥æå°æ­¤é ææ°ãå¨æ­¤æ¹æ³ä¸­ï¼RAG ææ ¹ææ¥è©¢æª¢ç´¢å¤é¨èªæåº«ä¸­çæä»¶åå¡ï¼ç¶å¾å°å¶ç¨ä½ä¸æ¸¸èªè¨æ¨¡åçèæ¯ï¼ä»¥ç¢çç­æ¡ãç¶èï¼éäºæª¢ç´¢å°çç¥è­ä¾æºéå¸¸åå«ä¸ç¸éæé¯èª¤çè³è¨ï¼å èæå®³äº RAG å¨ä¸æ¸¸ä»»åä¸­çæè½ãçºäºåææ­¤é éå¶ï¼æåå¼å¥äºä¸åç²¾ç°¡ãææçä¸å¯æå¥çæ¨¡çµï¼ç¨æ¼å¨å°å¤é¨ç¥è­ä¾æºæä¾çµ¦çæå¨ä¹åå°å¶é²è¡ç²¾çãæ­¤æ¨¡çµééæåæç¸éä¸æç¨çè³è¨ä¸¦å°å¶éæ°çµç¹æç°¡æ½ä¸ç¹å®æ¼æ¥è©¢çæ ¼å¼ï¼ä¾éå»ºæª¢ç´¢å°çå§å®¹ãééä¸éæ®µè¨ç·´ç¯ä¾ - åå«ç£ç£å¾®èª¿ãå°æ¯å¤ä»»åå­¸ç¿ä»¥ååºæ¼å¼·åå­¸ç¿çæ¯å° - å®åªåèéééµç¥è­ï¼ä¸¦ä½¿å¶èçæå¨çåå¥½ç¸ç¬¦ãæ­¤æ¹æ³å¯è® LLM ç¢çæ´æºç¢ºãå¯é ä¸å¨èªå¢ä¸æ´é©ç¶çè¼¸åºã

##### **LLM-Powered Proactive Data Systems**
2502.13016v1 by Sepanta Zeighami, Yiming Lin, Shreya Shankar, Aditya Parameswaran

With the power of LLMs, we now have the ability to query data that was
previously impossible to query, including text, images, and video. However,
despite this enormous potential, most present-day data systems that leverage
LLMs are reactive, reflecting our community's desire to map LLMs to known
abstractions. Most data systems treat LLMs as an opaque black box that operates
on user inputs and data as is, optimizing them much like any other approximate,
expensive UDFs, in conjunction with other relational operators. Such data
systems do as they are told, but fail to understand and leverage what the LLM
is being asked to do (i.e. the underlying operations, which may be
error-prone), the data the LLM is operating on (e.g., long, complex documents),
or what the user really needs. They don't take advantage of the characteristics
of the operations and/or the data at hand, or ensure correctness of results
when there are imprecisions and ambiguities. We argue that data systems instead
need to be proactive: they need to be given more agency -- armed with the power
of LLMs -- to understand and rework the user inputs and the data and to make
decisions on how the operations and the data should be represented and
processed. By allowing the data system to parse, rewrite, and decompose user
inputs and data, or to interact with the user in ways that go beyond the
standard single-shot query-result paradigm, the data system is able to address
user needs more efficiently and effectively. These new capabilities lead to a
rich design space where the data system takes more initiative: they are
empowered to perform optimization based on the transformation operations, data
characteristics, and user intent. We discuss various successful examples of how
this framework has been and can be applied in real-world tasks, and present
future directions for this ambitious research agenda.

æè¦ï¼<paragraph>éé LLM çå¼·å¤§åè½ï¼æåç¾å¨è½å¤ æ¥è©¢éå»ç¡æ³æ¥è©¢çè³æï¼åæ¬æå­ãåçåå½±çãç¶èï¼åç®¡æå¦æ­¤é¾å¤§çæ½åï¼ä½ç¾ä»å¤§å¤æ¸å©ç¨ LLM çè³æç³»çµ±é½æ¯è¢«åçï¼åæ åºæåçç¤¾ç¾¤å¸æå° LLM æ å°å°å·²ç¥çæ½è±¡åãå¤§å¤æ¸è³æç³»çµ±å° LLM è¦çºä¸åä¸éæçé»çå­ï¼ä»¥ä½¿ç¨èè¼¸å¥åè³æçºåºç¤é²è¡éä½ï¼ä¸¦åå¶ä»è¿ä¼¼ãæè²´ç UDF ä¸æ¨£æä½³åå®åï¼ä¸¦èå¶ä»éè¯éç®å­çµåä½¿ç¨ãéäºè³æç³»çµ±æç§èæç¤ºå·è¡ï¼ä½ç¡æ³çè§£ä¸¦éç¨ LLM è¢«è¦æ±å·è¡çä»»åï¼ä¾å¦å¯è½å®¹æåºé¯çåºæ¬éç®ï¼ãLLM æ­£å¨éç®çè³æï¼ä¾å¦åé·ãè¤éçæä»¶ï¼ï¼æä½¿ç¨èçæ­£éè¦çæ¯ä»éº¼ãå®åä¸æå©ç¨éç®å/ææéè³æçç¹æ§ï¼æå¨æèª¤å·®åæ­§ç¾©æç¢ºä¿çµæçæ­£ç¢ºæ§ãæåèªçºè³æç³»çµ±æè©²æ¹çºä¸»åï¼å®åéè¦è¢«è³¦äºæ´å¤èªä¸»æ¬ï¼ä¸¦å·å LLM çå¼·å¤§åè½ï¼ä»¥äºè§£ä¸¦éæ°èçä½¿ç¨èè¼¸å¥åè³æï¼ä¸¦å°±éç®åè³æçè¡¨ç¤ºåèçæ¹å¼ååºæ±ºç­ãééåè¨±è³æç³»çµ±è§£æãæ¹å¯«ååè§£ä½¿ç¨èè¼¸å¥åè³æï¼æä»¥è¶è¶æ¨æºå®æ¬¡æ¥è©¢çµææ¨¡å¼çæ¹å¼èä½¿ç¨èäºåï¼è³æç³»çµ±è½å¤ æ´ææçä¸ææå°æ»¿è¶³ä½¿ç¨èçéæ±ãéäºæ°åè½æå¸¶ä¾ä¸åè±å¯çè¨­è¨ç©ºéï¼è®è³æç³»çµ±ç¼æ®æ´å¤ä¸»å°æ§ï¼å®åæè½åæ ¹æè½æéç®ãè³æç¹æ§åä½¿ç¨èæåé²è¡æä½³åãæåå°è¨è«éåæ¶æ§å¦ä½æç¨æ¼å¯¦éä»»åï¼ä¸¦æåºéåéå¿ååçç ç©¶è­°ç¨çæªä¾æ¹åã</paragraph>

##### **Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents**
2502.13012v1 by Chaoran Chen, Bingsheng Yao, Ruishi Zou, Wenyue Hua, Weimin Lyu, Toby Jia-Jun Li, Dakuo Wang

Role-Playing Agent (RPA) is an increasingly popular type of LLM Agent that
simulates human-like behaviors in a variety of tasks. However, evaluating RPAs
is challenging due to diverse task requirements and agent designs. This paper
proposes an evidence-based, actionable, and generalizable evaluation design
guideline for LLM-based RPA by systematically reviewing 1,676 papers published
between Jan. 2021 and Dec. 2024. Our analysis identifies six agent attributes,
seven task attributes, and seven evaluation metrics from existing literature.
Based on these findings, we present an RPA evaluation design guideline to help
researchers develop more systematic and consistent evaluation methods.

æè¦ï¼è§è²æ®æ¼ä»£çï¼RPAï¼æ¯ä¸ç¨®è¶ä¾è¶æµè¡ç LLM ä»£çï¼å®è½æ¨¡æ¬äººé¡å¨åç¨®ä»»åä¸­çè¡çºãç¶èï¼ç±æ¼ä»»åéæ±åä»£çè¨­è¨çå¤æ¨£æ§ï¼è©ä¼° RPA å·æææ°æ§ãæ¬æééç³»çµ±å°å¯©æ¥ 2021 å¹´ 1 æè³ 2024 å¹´ 12 ææéç¼è¡¨ç 1,676 ç¯è«æï¼æåºäºåºæ¼è­æãå¯æä½ä¸å¯æ¨å»£ç LLM åºæ¼ RPA çè©ä¼°è¨­è¨æåãæåçåæå¾ç¾ææç»ä¸­è­å¥åºå­åä»£çå±¬æ§ãä¸åä»»åå±¬æ§åä¸åè©ä¼°ææ¨ãæ ¹æéäºç¼ç¾ï¼æåæåºäº RPA è©ä¼°è¨­è¨æåï¼ä»¥å¹«å©ç ç©¶äººå¡éç¼æ´ç³»çµ±ååä¸è´çè©ä¼°æ¹æ³ã

##### **Adaptive Knowledge Graphs Enhance Medical Question Answering: Bridging the Gap Between LLMs and Evolving Medical Knowledge**
2502.13010v1 by Mohammad Reza Rezaei, Reza Saadati Fard, Jayson Parker, Rahul G. Krishnan, Milad Lankarany

Large Language Models (LLMs) have significantly advanced medical
question-answering by leveraging extensive clinical data and medical
literature. However, the rapid evolution of medical knowledge and the
labor-intensive process of manually updating domain-specific resources pose
challenges to the reliability of these systems. To address this, we introduce
Adaptive Medical Graph-RAG (AMG-RAG), a comprehensive framework that automates
the construction and continuous updating of medical knowledge graphs,
integrates reasoning, and retrieves current external evidence, such as PubMed
and WikiSearch. By dynamically linking new findings and complex medical
concepts, AMG-RAG not only improves accuracy but also enhances interpretability
in medical queries.
  Evaluations on the MEDQA and MEDMCQA benchmarks demonstrate the effectiveness
of AMG-RAG, achieving an F1 score of 74.1 percent on MEDQA and an accuracy of
66.34 percent on MEDMCQA, outperforming both comparable models and those 10 to
100 times larger. Notably, these improvements are achieved without increasing
computational overhead, highlighting the critical role of automated knowledge
graph generation and external evidence retrieval in delivering up-to-date,
trustworthy medical insights.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééå©ç¨å»£æ³çè¨åºè³æåé«å­¸æç»ï¼å¤§å¹æåäºé«çåé¡è§£ç­çé²æ­¥ãç¶èï¼é«çç¥è­çå¿«éæ¼é²åæåæ´æ°ç¹å®é åè³æºçç¹è¤ç¨åºï¼å°éäºç³»çµ±çå¯é æ§æ§æææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºé©ææ§é«çåè¡¨ RAG (AMG-RAG)ï¼éæ¯ä¸åèªååå»ºæ§åæçºæ´æ°é«çç¥è­åè¡¨çç¶åæ¶æ§ï¼æ´åæ¨çä¸¦æ·å PubMed å WikiSearch ç­ææ°çå¤é¨è­æãééåæé£çµæ°çç¼ç¾åè¤éçé«çæ¦å¿µï¼AMG-RAG ä¸åæåäºæºç¢ºæ§ï¼ä¹å¢å¼·äºé«çæ¥è©¢çå¯è§£éæ§ãå¨ MEDQA å MEDMCQA åºæºä¸çè©éè­æäº AMG-RAG çæææ§ï¼å¨ MEDQA ä¸éå°äº 74.1% ç F1 åæ¸ï¼å¨ MEDMCQA ä¸éå°äº 66.34% çæºç¢ºåº¦ï¼åªæ¼å¶ä»åé¡æ¨¡åä»¥åé£äºå¤§ 10 å° 100 åçæ¨¡åãå¼å¾æ³¨æçæ¯ï¼éäºæ¹é²æ¯å¨ä¸å¢å éç®è² æçææ³ä¸å¯¦ç¾çï¼çªé¡¯äºèªååç¥è­åè¡¨çæåå¤é¨è­ææ·åå¨æä¾ææ°ãå¯ä¿¡è³´çé«çè¦è§£ä¸­æ®æ¼çéè¦è§è²ã

##### **Integrating Reinforcement Learning, Action Model Learning, and Numeric Planning for Tackling Complex Tasks**
2502.13006v1 by Yarin Benyamin, Argaman Mordoch, Shahaf S. Shperberg, Roni Stern

Automated Planning algorithms require a model of the domain that specifies
the preconditions and effects of each action. Obtaining such a domain model is
notoriously hard. Algorithms for learning domain models exist, yet it remains
unclear whether learning a domain model and planning is an effective approach
for numeric planning environments, i.e., where states include discrete and
numeric state variables. In this work, we explore the benefits of learning a
numeric domain model and compare it with alternative model-free solutions. As a
case study, we use two tasks in Minecraft, a popular sandbox game that has been
used as an AI challenge. First, we consider an offline learning setting, where
a set of expert trajectories are available to learn from. This is the standard
setting for learning domain models. We used the Numeric Safe Action Model
Learning (NSAM) algorithm to learn a numeric domain model and solve new
problems with the learned domain model and a numeric planner. We call this
model-based solution NSAM_(+p), and compare it to several model-free Imitation
Learning (IL) and Offline Reinforcement Learning (RL) algorithms. Empirical
results show that some IL algorithms can learn faster to solve simple tasks,
while NSAM_(+p) allows solving tasks that require long-term planning and
enables generalizing to solve problems in larger environments. Then, we
consider an online learning setting, where learning is done by moving an agent
in the environment. For this setting, we introduce RAMP. In RAMP, observations
collected during the agent's execution are used to simultaneously train an RL
policy and learn a planning domain action model. This forms a positive feedback
loop between the RL policy and the learned domain model. We demonstrate
experimentally the benefits of using RAMP, showing that it finds more efficient
plans and solves more problems than several RL baselines.

æè¦ï¼<paragraph>èªååè¦åæ¼ç®æ³éè¦ä¸åç¶²åæ¨¡åï¼ä¾æå®æ¯ååä½çåææ¢ä»¶åææãåå¾éæ¨£çç¶²åæ¨¡ååºäºåçå°é£ãå­¸ç¿ç¶²åæ¨¡åçæ¼ç®æ³ç¢ºå¯¦å­å¨ï¼ä½å­¸ç¿ç¶²åæ¨¡ååè¦åæ¯å¦çºæ¸å¼è¦åç°å¢çæææ¹æ³ä»ç¶ä¸æ¸æ¥ï¼ä¹å°±æ¯èªªï¼å¶ä¸­çæåå«é¢æ£åæ¸å¼çæè®æ¸ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨å­¸ç¿æ¸å¼ç¶²åæ¨¡åçåªé»ï¼ä¸¦å°å¶èæ¿ä»£çç¡æ¨¡åè§£æ±ºæ¹æ¡é²è¡æ¯è¼ãä½çºä¸åæ¡ä¾ç ç©¶ï¼æåä½¿ç¨ Minecraft ä¸­çå©åä»»åï¼Minecraft æ¯ä¸åæµè¡çæ²çéæ²ï¼å·²è¢«ç¨ä½ AI ææ°ãé¦åï¼æåèæ®é¢ç·å­¸ç¿è¨­å®ï¼å¶ä¸­æä¸çµå°å®¶è»è·¡å¯ä¾å­¸ç¿ãéæ¯å­¸ç¿ç¶²åæ¨¡åçæ¨æºè¨­å®ãæåä½¿ç¨æ¸å¼å®å¨åä½æ¨¡åå­¸ç¿ (NSAM) æ¼ç®æ³ä¾å­¸ç¿æ¸å¼ç¶²åæ¨¡åï¼ä¸¦ä½¿ç¨å·²å­¸ç¿çç¶²åæ¨¡ååæ¸å¼è¦åå¨è§£æ±ºæ°åé¡ãæåç¨±æ­¤æ¨¡åçºåºç¤çè§£æ±ºæ¹æ¡ NSAM_(+p)ï¼ä¸¦å°å¶èå¤ç¨®ç¡æ¨¡åæ¨¡ä»¿å­¸ç¿ (IL) åé¢ç·å¼·åå­¸ç¿ (RL) æ¼ç®æ³é²è¡æ¯è¼ãç¶é©çµæé¡¯ç¤ºï¼ä¸äº IL æ¼ç®æ³å¯ä»¥æ´å¿«å°å­¸ç¿è§£æ±ºç°¡å®ä»»åï¼è NSAM_(+p) åè¨±è§£æ±ºéè¦é·æè¦åçä»»åï¼ä¸¦è½å¤ æ¨å»£å°å¨æ´å¤§ç°å¢ä¸­è§£æ±ºåé¡ãç¶å¾ï¼æåèæ®ç·ä¸å­¸ç¿è¨­å®ï¼å¶ä¸­å­¸ç¿æ¯ééå¨ç°å¢ä¸­ç§»åä»£çä¾å®æçãå°æ¼æ­¤è¨­å®ï¼æåå¼å¥äº RAMPãå¨ RAMP ä¸­ï¼å¨ä»£çå·è¡æéæ¶éçè§å¯çµæç¨æ¼åæè¨ç·´ RL æ¿ç­åå­¸ç¿è¦åç¶²ååä½æ¨¡åãéå¨ RL æ¿ç­åå·²å­¸ç¿çç¶²åæ¨¡åä¹éå½¢æäºä¸åæ­£ååé¥è¿´è·¯ãæåééå¯¦é©è­æäºä½¿ç¨ RAMP çå¥½èï¼é¡¯ç¤ºå®æ¯å¤å RL åºæºæ¾å°äºæ´ææçè¨ç«ï¼ä¸¦è§£æ±ºäºæ´å¤åé¡ã</paragraph>

##### **Language Barriers: Evaluating Cross-Lingual Performance of CNN and Transformer Architectures for Speech Quality Estimation**
2502.13004v1 by Wafaa Wardah, TuÄÃ§e Melike KoÃ§ak BÃ¼yÃ¼ktaÅ, Kirill Shchegelskiy, Sebastian MÃ¶ller, Robert P. Spang

Objective speech quality models aim to predict human-perceived speech quality
using automated methods. However, cross-lingual generalization remains a major
challenge, as Mean Opinion Scores (MOS) vary across languages due to
linguistic, perceptual, and dataset-specific differences. A model trained
primarily on English data may struggle to generalize to languages with
different phonetic, tonal, and prosodic characteristics, leading to
inconsistencies in objective assessments. This study investigates the
cross-lingual performance of two speech quality models: NISQA, a CNN-based
model, and a Transformer-based Audio Spectrogram Transformer (AST) model. Both
models were trained exclusively on English datasets containing over 49,000
speech samples and subsequently evaluated on speech in German, French,
Mandarin, Swedish, and Dutch. We analyze model performance using Pearson
Correlation Coefficient (PCC) and Root Mean Square Error (RMSE) across five
speech quality dimensions: coloration, discontinuity, loudness, noise, and MOS.
Our findings show that while AST achieves a more stable cross-lingual
performance, both models exhibit noticeable biases. Notably, Mandarin speech
quality predictions correlate highly with human MOS scores, whereas Swedish and
Dutch present greater prediction challenges. Discontinuities remain difficult
to model across all languages. These results highlight the need for more
balanced multilingual datasets and architecture-specific adaptations to improve
cross-lingual generalization.

æè¦ï¼å®¢è§èªé³åè³ªæ¨¡åæ¨å¨ä½¿ç¨èªååæ¹æ³é æ¸¬äººé¡æç¥çèªé³åè³ªãç¶èï¼è·¨èªè¨çæ¦åä»ç¶æ¯ä¸é éå¤§ææ°ï¼å çºå¹³åæè¦åæ¸ (MOS) æå èªè¨çä¸åèææä¸åï¼éæ¯ç±æ¼èªè¨ãæç¥åç¹å®æ¼è³æéçå·®ç°æè´ãä¸»è¦ä½¿ç¨è±èªè³æè¨ç·´çæ¨¡åå¯è½æé£ä»¥æ¦åå°å·æä¸åèªé³ãè²èª¿åé»å¾ç¹å¾µçèªè¨ï¼å°è´å®¢è§è©ä¼°ä¸ä¸è´ãæ¬ç ç©¶æ¢è¨äºå©ç¨®èªé³åè³ªæ¨¡åçè·¨èªè¨æè½ï¼åºæ¼ CNN ç NISQA æ¨¡åååºæ¼ Transformer çé³è¨åè­ Transformer (AST) æ¨¡åãéå©ç¨®æ¨¡åé½åä½¿ç¨åå«è¶é 49,000 åèªé³ç¯ä¾çè±èªè³æéé²è¡è¨ç·´ï¼ç¶å¾å¨å¾·èªãæ³èªãæ®éè©±ãçå¸èªåè·è­èªçèªé³ä¸é²è¡è©ä¼°ãæåä½¿ç¨ç®ç¾æ£®ç¸éä¿æ¸ (PCC) ååæ¹æ ¹èª¤å·® (RMSE) åæäºåèªé³åè³ªç¶­åº¦çæ¨¡åæè½ï¼è²å½©ãä¸é£çºæ§ãé¿åº¦ãéè¨å MOSãæåçç ç©¶çµæé¡¯ç¤ºï¼åç®¡ AST éå°äºæ´ç©©å®çè·¨èªè¨æè½ï¼ä½éå©ç¨®æ¨¡åé½è¡¨ç¾åºæé¡¯çåå·®ãå¼å¾æ³¨æçæ¯ï¼æ®éè©±èªé³åè³ªé æ¸¬èäººé¡ MOS åæ¸é«åº¦ç¸éï¼èçå¸èªåè·è­èªååç¾åºæ´å¤§çé æ¸¬ææ°ãä¸é£çºæ§å¨ææèªè¨ä¸­ä»ç¶é£ä»¥å»ºæ¨¡ãéäºçµæå¸é¡¯äºå°æ´å¹³è¡¡çå¤èªè¨è³æéåç¹å®æ¼æ¶æ§çèª¿æ´çéæ±ï¼ä»¥æ¹åè·¨èªè¨çæ¦åã

##### **You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations**
2502.13001v1 by Frederic Kirstein, Muneeb Khan, Jan Philip Wahle, Terry Ruas, Bela Gipp

Meeting summarization suffers from limited high-quality data, mainly due to
privacy restrictions and expensive collection processes. We address this gap
with FAME, a dataset of 500 meetings in English and 300 in German produced by
MIMIC, our new multi-agent meeting synthesis framework that generates meeting
transcripts on a given knowledge source by defining psychologically grounded
participant profiles, outlining the conversation, and orchestrating a large
language model (LLM) debate. A modular post-processing step refines these
outputs, mitigating potential repetitiveness and overly formal tones, ensuring
coherent, credible dialogues at scale. We also propose a psychologically
grounded evaluation framework assessing naturalness, social behavior
authenticity, and transcript difficulties. Human assessments show that FAME
approximates real-meeting spontaneity (4.5/5 in naturalness), preserves
speaker-centric challenges (3/5 in spoken language), and introduces richer
information-oriented difficulty (4/5 in difficulty). These findings highlight
that FAME is a good and scalable proxy for real-world meeting conditions. It
enables new test scenarios for meeting summarization research and other
conversation-centric applications in tasks requiring conversation data or
simulating social scenarios under behavioral constraints.

æè¦ï¼æè­°æè¦å ç¼ºä¹é«åè³ªè³æèåéï¼ä¸»è¦æ¯ç±æ¼é±ç§éå¶åæè²´çæ¶éç¨åºãæåéé FAME ä¾è§£æ±ºéåå·®è·ï¼FAME æ¯ MIMIC è£½ä½ç 500 å ´è±ææè­°å 300 å ´å¾·ææè­°çè³æéï¼MIMIC æ¯æåæ°çå¤éä»£çæè­°åææ¶æ§ï¼ééå®ç¾©å¿çåºç¤çåèèè¨­å®æªãæ¦è¿°å°è©±ï¼ä¸¦åèª¿å¤§åèªè¨æ¨¡å (LLM) è¾¯è«ï¼å¨çµ¦å®çç¥è­ä¾æºä¸ç¢çæè­°è¨éãæ¨¡çµåå¾èçæ­¥é©ææ¹åéäºè¼¸åºï¼æ¸è¼æ½å¨çéè¤æ§åéæ¼æ­£å¼çèªæ°£ï¼ç¢ºä¿å¤§è¦æ¨¡çå°è©±é£è²«ä¸å¯ä¿¡ãæåä¹æåºä¸åå¿çåºç¤çè©ä¼°æ¶æ§ï¼è©ä¼°èªç¶æ§ãç¤¾äº¤è¡çºçå¯¦æ§ï¼ä»¥åè¨éé£åº¦ãäººé¡è©ä¼°é¡¯ç¤ºï¼FAME è¿ä¼¼æ¼çå¯¦æè­°çå³èæ§ï¼èªç¶æ§ 4.5/5ï¼ï¼ä¿çä»¥è¬èçºä¸­å¿çææ°ï¼å£èª 3/5ï¼ï¼ä¸¦å¼å¥æ´è±å¯çè³è¨å°åé£åº¦ï¼é£åº¦ 4/5ï¼ãéäºç¼ç¾å¼·èª¿ FAME æ¯çå¯¦ä¸çæè­°æ¢ä»¶çè¯å¥½ä¸å¯æ´åçä»£çãå®è½çºæè­°æè¦ç ç©¶åå¶ä»å°è©±çºä¸­å¿çæç¨ç¨å¼åç¨æ°çæ¸¬è©¦æå¢ï¼å¨éè¦å°è©±è³ææå¨è¡çºéå¶ä¸æ¨¡æ¬ç¤¾äº¤æå¢çä»»åä¸­ã

##### **Personalized Top-k Set Queries Over Predicted Scores**
2502.12998v1 by Sohrab Namazi Nia, Subhodeep Ghosh, Senjuti Basu Roy, Sihem Amer-Yahia

This work studies the applicability of expensive external oracles such as
large language models in answering top-k queries over predicted scores. Such
scores are incurred by user-defined functions to answer personalized queries
over multi-modal data. We propose a generic computational framework that
handles arbitrary set-based scoring functions, as long as the functions could
be decomposed into constructs, each of which sent to an oracle (in our case an
LLM) to predict partial scores. At a given point in time, the framework assumes
a set of responses and their partial predicted scores, and it maintains a
collection of possible sets that are likely to be the true top-k. Since calling
oracles is costly, our framework judiciously identifies the next construct,
i.e., the next best question to ask the oracle so as to maximize the likelihood
of identifying the true top-k. We present a principled probabilistic model that
quantifies that likelihood. We study efficiency opportunities in designing
algorithms. We run an evaluation with three large scale datasets, scoring
functions, and baselines. Experiments indicate the efficacy of our framework,
as it achieves an order of magnitude improvement over baselines in requiring
LLM calls while ensuring result accuracy. Scalability experiments further
indicate that our framework could be used in large-scale applications.

æè¦ï¼æ¬ç ç©¶æ¢è¨å¨é æ¸¬åæ¸ä¸­åç­å k åæ¥è©¢æï¼æè²´çå¤é¨é è¨ï¼ä¾å¦å¤§åèªè¨æ¨¡åï¼çé©ç¨æ§ãæ­¤é¡åæ¸æ¯ç±ä½¿ç¨èå®ç¾©çå½å¼ç¢çï¼ç¨æ¼åç­å¤æ¨¡æè³æä¸­çåäººåæ¥è©¢ãæåæåºä¸åéç¨çéç®æ¡æ¶ï¼ç¨æ¼èçä»»æåºæ¼éåçè¨åå½å¼ï¼åªè¦éäºå½å¼å¯ä»¥åè§£çºå»ºæ§åå¡ï¼ç¶å¾å°æ¯åå»ºæ§åå¡å³éçµ¦é è¨ï¼å¨æ¬ä¾ä¸­çº LLMï¼ä»¥é æ¸¬é¨ååæ¸ãå¨ç¹å®æéé»ï¼æ­¤æ¡æ¶åè¨­ä¸çµåæåå¶é¨åé æ¸¬åæ¸ï¼ä¸¦ç¶­è­·ä¸çµå¯è½æçºçå¯¦å k åçéåãç±æ¼å¼å«é è¨çææ¬å¾é«ï¼å æ­¤æåçæ¡æ¶æææºå°æ¾åºä¸ä¸åå»ºæ§åå¡ï¼äº¦å³ä¸ä¸åæä½³åé¡ï¼ä»¥è©¢åé è¨ï¼ä»¥ä¾¿æå¤§åæ¾åºçå¯¦å k åçå¯è½æ§ãæåæåºä¸ååºæ¼åççæ©çæ¨¡åï¼ç¨æ¼éåæ­¤å¯è½æ§ãæåç ç©¶è¨­è¨æ¼ç®æ³æçæçæ©æãæåéå°ä¸åå¤§åè³æéãè¨åå½å¼ååºæºå·è¡è©ä¼°ãå¯¦é©çµææåºæåæ¡æ¶çæè½ï¼å çºå®å¨éè¦ LLM å¼å«çåæç¢ºä¿çµææºç¢ºæ§ï¼æ¯åºæºé²æ­¥äºä¸åæ¸éç´ãå¯æ´åæ§å¯¦é©é²ä¸æ­¥æåºæåçæ¡æ¶å¯ç¨æ¼å¤§åæç¨ç¨å¼ã

##### **Eager Updates For Overlapped Communication and Computation in DiLoCo**
2502.12996v1 by Satyen Kale, Arthur Douillard, Yanislav Donchev

Distributed optimization methods such as DiLoCo have been shown to be
effective in training very large models across multiple distributed workers,
such as datacenters. These methods split updates into two parts: an inner
optimization phase, where the workers independently execute multiple
optimization steps on their own local data, and an outer optimization step,
where the inner updates are synchronized. While such approaches require orders
of magnitude less communication than standard data-parallel training, in
settings where the workers are datacenters, even the limited communication
requirements of these approaches can still cause significant slow downs due to
the blocking necessary at each outer optimization step. In this paper, we
investigate techniques to mitigate this issue by overlapping communication with
computation in a manner that allows the outer optimization step to fully
overlap with the inner optimization phase. We show that a particular variant,
dubbed eager updates, provides competitive performance with standard DiLoCo in
settings with low bandwidth between workers.

æè¦ï¼åæ£å¼åªåæ¹æ³ï¼ä¾å¦ DiLoCoï¼å·²è¢«è­æå¯ææè¨ç·´æ©«è·¨å¤ååæ£å¼å·¥ä½èçè¶å¤§åæ¨¡åï¼ä¾å¦è³æä¸­å¿ãéäºæ¹æ³å°æ´æ°æåçºå©é¨åï¼å§é¨æä½³åéæ®µï¼å¶ä¸­å·¥ä½èç¨ç«å°å¨èªå·±çæ¬å°è³æä¸å·è¡å¤åæä½³åæ­¥é©ï¼ä»¥åå¤é¨æä½³åæ­¥é©ï¼å¶ä¸­å§é¨æ´æ°æåæ­¥ãéç¶æ­¤é¡æ¹æ³æéçéè¨éæ¯æ¨æºè³æå¹³è¡è¨ç·´å°å¹¾åæ¸éç´ï¼ä½å¨å·¥ä½èçºè³æä¸­å¿çææ³ä¸ï¼å³ä½¿éäºæ¹æ³æéçéè¨éæ±ä»å¯è½ç±æ¼æ¯åå¤é¨æä½³åæ­¥é©æéçå°éèå°è´é¡¯èçæ¸éãå¨æ¬æä¸­ï¼æåæ¢è¨äºééä»¥åè¨±å¤é¨æä½³åæ­¥é©èå§é¨æä½³åéæ®µå®å¨éççæ¹å¼å°éè¨èéç®éçï¼ä¾æ¸è¼æ­¤åé¡çæè¡ãæåå±ç¤ºäºä¸åç¹å®è®é«ï¼ç¨±çºå³ææ´æ°ï¼å¨å·¥ä½èä¹éé »å¯¬è¼ä½çææ³ä¸ï¼å¯æä¾èæ¨æº DiLoCo ç¸ç¶çæè½ã

##### **Free Argumentative Exchanges for Explaining Image Classifiers**
2502.12995v1 by Avinash Kori, Antonio Rago, Francesca Toni

Deep learning models are powerful image classifiers but their opacity hinders
their trustworthiness. Explanation methods for capturing the reasoning process
within these classifiers faithfully and in a clear manner are scarce, due to
their sheer complexity and size. We provide a solution for this problem by
defining a novel method for explaining the outputs of image classifiers with
debates between two agents, each arguing for a particular class. We obtain
these debates as concrete instances of Free Argumentative eXchanges (FAXs), a
novel argumentation-based multi-agent framework allowing agents to internalise
opinions by other agents differently than originally stated. We define two
metrics (consensus and persuasion rate) to assess the usefulness of FAXs as
argumentative explanations for image classifiers. We then conduct a number of
empirical experiments showing that FAXs perform well along these metrics as
well as being more faithful to the image classifiers than conventional,
non-argumentative explanation methods. All our implementations can be found at
https://github.com/koriavinash1/FAX.

æè¦ï¼æ·±åº¦å­¸ç¿æ¨¡åæ¯å¼·å¤§çå½±ååé¡å¨ï¼ä½å¶ä¸éææ§é»ç¤äºå¶å¯ä¿¡åº¦ãç±æ¼å¶æ¥µé«çè¤éæ§åè¦æ¨¡ï¼å¿ å¯¦ä¸æ¸æ¥å°ææéäºåé¡å¨å§é¨æ¨çéç¨çè§£éæ¹æ³å¾å°è¦ãæåééå®ç¾©ä¸ç¨®æ°ç©çæ¹æ³ä¾è§£æ±ºéååé¡ï¼è©²æ¹æ³ééå©åä»£çä¹éçè¾¯è«ä¾è§£éå½±ååé¡å¨çè¼¸åºï¼æ¯åä»£çé½ä¸»å¼µä¸åç¹å®é¡å¥ãæåå°éäºè¾¯è«ä½çºèªç±è«è­äº¤æ (FAX) çå·é«å¯¦ä¾ï¼éæ¯ä¸åæ°ç©çåºæ¼è«è­çå¤ä»£çæ¶æ§ï¼åè¨±ä»£çä»¥ä¸åæ¼åå§é³è¿°çæ¹å¼å§åå¶ä»ä»£ççæè¦ãæåå®ç¾©äºå©åææ¨ï¼å±è­çåèªªæçï¼ä¾è©ä¼° FAX ä½çºå½±ååé¡å¨è«è­è§£éçæç¨æ§ãç¶å¾ï¼æåé²è¡äºå¤é å¯¦è­å¯¦é©ï¼è¡¨æ FAX å¨éäºææ¨ä¸è¡¨ç¾è¯å¥½ï¼ä¸¦ä¸æ¯å³çµ±çéè«è­è§£éæ¹æ³æ´å¿ å¯¦æ¼å½±ååé¡å¨ãæåææçå¯¦ä½é½å¯ä»¥å¨ https://github.com/koriavinash1/FAX ä¸­æ¾å°ã

##### **B-cos LM: Efficiently Transforming Pre-trained Language Models for Improved Explainability**
2502.12992v1 by Yifan Wang, Sukrut Rao, Ji-Ung Lee, Mayank Jobanputra, Vera Demberg

Post-hoc explanation methods for black-box models often struggle with
faithfulness and human interpretability due to the lack of explainability in
current neural models. Meanwhile, B-cos networks have been introduced to
improve model explainability through architectural and computational
adaptations, but their application has so far been limited to computer vision
models and their associated training pipelines. In this work, we introduce
B-cos LMs, i.e., B-cos networks empowered for NLP tasks. Our approach directly
transforms pre-trained language models into B-cos LMs by combining B-cos
conversion and task fine-tuning, improving efficiency compared to previous
B-cos methods. Our automatic and human evaluation results demonstrate that
B-cos LMs produce more faithful and human interpretable explanations than post
hoc methods, while maintaining task performance comparable to conventional
fine-tuning. Our in-depth analysis explores how B-cos LMs differ from
conventionally fine-tuned models in their learning processes and explanation
patterns. Finally, we provide practical guidelines for effectively building
B-cos LMs based on our findings. Our code is available at
https://anonymous.4open.science/r/bcos_lm.

æè¦ï¼é»çæ¨¡åçäºåè§£éæ¹æ³éå¸¸ä¼å ä¸ºå½åç¥ç»æ¨¡åç¼ºä¹å¯è§£éæ§èé¾ä»¥åå°å¿ å®åäººç±»å¯è§£éãä¸æ­¤åæ¶ï¼B-cos ç½ç»å·²è¢«å¼å¥ï¼ä»¥éè¿æ¶æåè®¡ç®æ¹ç¼æ¥æé«æ¨¡åçå¯è§£éæ§ï¼ä½å°ç®åä¸ºæ­¢ï¼å®ä»¬çåºç¨ä»éäºè®¡ç®æºè§è§æ¨¡ååå¶ç¸å³çè®­ç»ç®¡éãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äº B-cos LMï¼å³éå¯¹ NLP ä»»å¡å¢å¼ºç B-cos ç½ç»ãæä»¬çæ¹æ³éè¿ç»å B-cos è½¬æ¢åä»»å¡å¾®è°ï¼å°é¢è®­ç»çè¯­è¨æ¨¡åç´æ¥è½¬æ¢ä¸º B-cos LMï¼ä¸ä»¥å B-cos æ¹æ³ç¸æ¯ï¼æé«äºæçãæä»¬çèªå¨åäººå·¥è¯ä¼°ç»æè¡¨æï¼ä¸äºåæ¹æ³ç¸æ¯ï¼B-cos LM äº§çäºæ´å¿ å®åäººç±»å¯è§£éçè§£éï¼åæ¶ä¿æä¸ä¼ ç»å¾®è°ç¸å½çä»»å¡æ§è½ãæä»¬çæ·±å¥åææ¢è®¨äº B-cos LM å¨å¶å­¦ä¹ è¿ç¨åè§£éæ¨¡å¼ä¸­ä¸ä¼ ç»å¾®è°æ¨¡åæä½ä¸åãæåï¼æä»¬æ ¹æ®æä»¬çåç°æä¾äºæææå»º B-cos LM çå®ç¨æåãæä»¬çä»£ç å¯å¨ https://anonymous.4open.science/r/bcos_lm è·å¾ã

##### **Beyond Profile: From Surface-Level Facts to Deep Persona Simulation in LLMs**
2502.12988v1 by Zixiao Wang, Duzhen Zhang, Ishita Agrawal, Shen Gao, Le Song, Xiuying Chen

Previous approaches to persona simulation large language models (LLMs) have
typically relied on learning basic biographical information, or using limited
role-play dialogue datasets to capture a character's responses. However, a
holistic representation of an individual goes beyond surface-level facts or
conversations to deeper thoughts and thinking. In this work, we introduce
CharacterBot, a model designed to replicate both the linguistic patterns and
distinctive thought processes of a character. Using Lu Xun, a renowned Chinese
writer, as a case study, we propose four training tasks derived from his 17
essay collections. These include a pre-training task focused on mastering
external linguistic structures and knowledge, as well as three fine-tuning
tasks: multiple-choice question answering, generative question answering, and
style transfer, each aligning the LLM with Lu Xun's internal ideation and
writing style. To optimize learning across these tasks, we introduce a CharLoRA
parameter updating mechanism, where a general linguistic style expert
collaborates with other task-specific experts to better study both the language
style and the understanding of deeper thoughts. We evaluate CharacterBot on
three tasks for linguistic accuracy and opinion comprehension, demonstrating
that it significantly outperforms the baselines on our adapted metrics. We hope
that this work inspires future research on deep character persona simulation
LLM.

æè¦ï¼<paragraph>ä»¥åå°è§è²æ¨¡æ¬å¤§åèªè¨æ¨¡å (LLM) çæ¹æ³éå¸¸ä¾è³´æ¼å­¸ç¿åºæ¬å³è¨è³è¨ï¼æä½¿ç¨æéçè§è²æ®æ¼å°è©±è³æéä¾ææè§è²çåæãç¶èï¼å°åäººçæ´é«è¡¨å¾µè¶è¶äºè¡¨é¢å±¤é¢çäºå¯¦æå°è©±ï¼æ·±å¥å°æ´æ·±å±¤çæ³æ³åæèãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº CharacterBotï¼ä¸åæ¨å¨è¤è£½è§è²çèªè¨æ¨¡å¼åç¨ç¹æèéç¨çæ¨¡åãä»¥èåçä¸­åä½å®¶é­¯è¿çºæ¡ä¾ç ç©¶ï¼æåæåºäºååå¾ä»ç 17 ç¯æ£æéä¸­è¡ççè¨ç·´ä»»åãå¶ä¸­åæ¬ä¸åé è¨ç·´ä»»åï¼å°æ³¨æ¼ææ¡å¤é¨èªè¨çµæ§åç¥è­ï¼ä»¥åä¸åå¾®èª¿ä»»åï¼å¤é¸é¡åç­ãçæå¼åç­åé¢¨æ ¼è½ç§»ï¼æ¯åä»»åé½å° LLM èé­¯è¿çå§é¨è§å¿µåå¯«ä½é¢¨æ ¼ç¸çµåãçºäºåªåéäºä»»åçå­¸ç¿ï¼æåå¼å¥äºä¸å CharLoRA åæ¸æ´æ°æ©å¶ï¼å¶ä¸­ä¸ä½éæèªè¨é¢¨æ ¼çå°å®¶èå¶ä»ç¹å®ä»»åå°å®¶åä½ï¼ä»¥æ´å¥½å°ç ç©¶èªè¨é¢¨æ ¼åå°æ·±å±¤ææ³ççè§£ãæåå¨ä¸é ä»»åä¸è©ä¼°äº CharacterBot çèªè¨æºç¢ºæ§åæè¦çè§£ï¼è­æå®å¨æåèª¿æ´çææ¨ä¸é¡¯èåªæ¼åºæºãæåå¸æéé å·¥ä½è½æ¿åµæªä¾å°æ·±åº¦è§è²è§è²æ¨¡æ¬ LLM çç ç©¶ã</paragraph>

##### **PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization**
2502.12985v1 by Nicolas Talabot, Olivier Clerc, Arda Cinar Demirtas, Doruk Oner, Pascal Fua

Accurate 3D shape representation is essential in engineering applications
such as design, optimization, and simulation. In practice, engineering
workflows require structured, part-aware representations, as objects are
inherently designed as assemblies of distinct components. However, most
existing methods either model shapes holistically or decompose them without
predefined part structures, limiting their applicability in real-world design
tasks. We propose PartSDF, a supervised implicit representation framework that
explicitly models composite shapes with independent, controllable parts while
maintaining shape consistency. Despite its simple single-decoder architecture,
PartSDF outperforms both supervised and unsupervised baselines in
reconstruction and generation tasks. We further demonstrate its effectiveness
as a structured shape prior for engineering applications, enabling precise
control over individual components while preserving overall coherence. Code
available at https://github.com/cvlab-epfl/PartSDF.

æè¦ï¼ç²¾ç¢ºç 3D å½¢çè¡¨ç¤ºå¨å·¥ç¨æç¨ä¸­è³ééè¦ï¼ä¾å¦è¨­è¨ãæä½³ååæ¨¡æ¬ãå¯¦éä¸ï¼å·¥ç¨å·¥ä½æµç¨éè¦çµæ§åãé¶ä»¶æç¥çè¡¨ç¤ºï¼å çºç©é«æ¬è³ªä¸æ¯è¨­è¨çºä¸ååä»¶ççµä»¶ãç¶èï¼å¤§å¤æ¸ç¾ææ¹æ³ä¸æ¯æ´é«å»ºæ¨¡å½¢çï¼å°±æ¯å°å¶åè§£ï¼èæ²æé åå®ç¾©çé¶ä»¶çµæ§ï¼ééå¶äºå®åå¨å¯¦éè¨­è¨ä»»åä¸­çé©ç¨æ§ãæåæåº PartSDFï¼ä¸åç£ç£å¼çé±å¼è¡¨ç¤ºæ¡æ¶ï¼å®æç¢ºå°ä½¿ç¨ç¨ç«ãå¯æ§çé¶ä»¶å°è¤åå½¢çé²è¡å»ºæ¨¡ï¼åæä¿æå½¢çä¸è´æ§ãåç®¡å¶å®ä¸çè§£ç¢¼å¨æ¶æ§å¾ç°¡å®ï¼ä½ PartSDF å¨éå»ºåçæä»»åä¸­é½åªæ¼ç£ç£å¼åéç£ç£å¼åºæºãæåé²ä¸æ­¥è­æäºå¶ä½çºå·¥ç¨æç¨çµæ§åå½¢çåé©çæææ§ï¼è½å¤ ç²¾ç¢ºæ§å¶åååä»¶ï¼åæä¿ææ´é«ä¸è´æ§ãç¨å¼ç¢¼å¯å¨ https://github.com/cvlab-epfl/PartSDF åå¾ã

##### **Sailor2: Sailing in South-East Asia with Inclusive Multilingual LLMs**
2502.12982v1 by Longxu Dou, Qian Liu, Fan Zhou, Changyu Chen, Zili Wang, Ziqi Jin, Zichen Liu, Tongyao Zhu, Cunxiao Du, Penghui Yang, Haonan Wang, Jiaheng Liu, Yongchi Zhao, Xiachong Feng, Xin Mao, Man Tsung Yeung, Kunat Pipatanakul, Fajri Koto, Min Si Thu, Hynek KydlÃ­Äek, Zeyi Liu, Qunshu Lin, Sittipong Sripaisarnmongkol, Kridtaphad Sae-Khow, Nirattisai Thongchim, Taechawat Konkaew, Narong Borijindargoon, Anh Dao, Matichon Maneegard, Phakphum Artkaew, Zheng-Xin Yong, Quan Nguyen, Wannaphong Phatthiyaphaibun, Hoang H. Tran, Mike Zhang, Shiqi Chen, Tianyu Pang, Chao Du, Xinyi Wan, Wei Lu, Min Lin

Sailor2 is a family of cutting-edge multilingual language models for
South-East Asian (SEA) languages, available in 1B, 8B, and 20B sizes to suit
diverse applications. Building on Qwen2.5, Sailor2 undergoes continuous
pre-training on 500B tokens (400B SEA-specific and 100B replay tokens) to
support 13 SEA languages while retaining proficiency in Chinese and English.
Sailor2-20B model achieves a 50-50 win rate against GPT-4o across SEA
languages. We also deliver a comprehensive cookbook on how to develop the
multilingual model in an efficient manner, including five key aspects: data
curation, pre-training, post-training, model customization and evaluation. We
hope that Sailor2 model (Apache 2.0 license) will drive language development in
the SEA region, and Sailor2 cookbook will inspire researchers to build more
inclusive LLMs for other under-served languages.

æè¦ï¼Sailor2 æ¯ä¸ç³»åéå°æ±åäº (SEA) èªè¨çå°ç«¯å¤èªè¨èªè¨æ¨¡åï¼åæ 1Bã8B å 20B å¤§å°ï¼ä»¥é©æåç¨®æç¨ãå¨ Qwen2.5 çåºç¤ä¸ï¼Sailor2 æçºé²è¡ 500B ä»£å¹£ï¼400B SEA å°ç¨å 100B éæ­ä»£å¹£ï¼çé è¨ç·´ï¼ä»¥æ¯æ´ 13 ç¨® SEA èªè¨ï¼åæä¿çä¸­æåè±æççç·´åº¦ãSailor2-20B æ¨¡åå¨ SEA èªè¨ä¸­å°æ GPT-4o æï¼éå° 50-50 çç²åçãæåéæä¾ä¸æ¬å¨é¢çé£è­ï¼èªªæå¦ä½ä»¥ææçæ¹å¼éç¼å¤èªè¨æ¨¡åï¼åæ¬äºåééµæ¹é¢ï¼è³æç­å±ãé è¨ç·´ãå¾è¨ç·´ãæ¨¡åèªè¨åè©ä¼°ãæåå¸æ Sailor2 æ¨¡åï¼Apache 2.0 ææ¬ï¼å°æ¨å SEA å°åçèªè¨ç¼å±ï¼è Sailor2 é£è­å°æ¿åµç ç©¶äººå¡çºå¶ä»æåä¸è¶³çèªè¨å»ºç«æ´å·åå®¹æ§ç LLMã

##### **Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking**
2502.12970v1 by Junda Zhu, Lingyong Yan, Shuaiqiang Wang, Dawei Yin, Lei Sha

The reasoning abilities of Large Language Models (LLMs) have demonstrated
remarkable advancement and exceptional performance across diverse domains.
However, leveraging these reasoning capabilities to enhance LLM safety against
adversarial attacks and jailbreak queries remains largely unexplored. To bridge
this gap, we propose Reasoning-to-Defend (R2D), a novel training paradigm that
integrates safety reflections of queries and responses into LLMs' generation
process, unlocking a safety-aware reasoning mechanism. This approach enables
self-evaluation at each reasoning step to create safety pivot tokens as
indicators of the response's safety status. Furthermore, in order to improve
the learning efficiency of pivot token prediction, we propose Contrastive Pivot
Optimization(CPO), which enhances the model's ability to perceive the safety
status of dialogues. Through this mechanism, LLMs dynamically adjust their
response strategies during reasoning, significantly enhancing their defense
capabilities against jailbreak attacks. Extensive experimental results
demonstrate that R2D effectively mitigates various attacks and improves overall
safety, highlighting the substantial potential of safety-aware reasoning in
strengthening LLMs' robustness against jailbreaks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åå·²å±ç¾åºé¡¯èçé²æ­¥ï¼ä¸¦å¨ä¸åçé åä¸­è¡¨ç¾åºè²ãç¶èï¼å©ç¨éäºæ¨çè½åä¾å¢å¼· LLM å°ææ»æåè¶çæ¥è©¢çå®å¨æ§ä»ç¶æ¯æªéç¼çé åãçºäºå½è£éåå·®è·ï¼æåæåºäºæ¨çé²ç¦¦ (R2D)ï¼éæ¯ä¸ç¨®æ°ç©çè¨ç·´ç¯ä¾ï¼å®å°æ¥è©¢ååæçå®å¨èéæ´åå° LLM ççæéç¨ä¸­ï¼éåäºä¸åå®å¨æç¥æ¨çæ©å¶ãæ­¤æ¹æ³å¯ä»¥å¨æ¯åæ¨çæ­¥é©ä¸­é²è¡èªæè©ä¼°ï¼ä»¥å»ºç«å®å¨æ¨ç´æ¨è¨ï¼ä½çºåæå®å¨çæçææ¨ãæ­¤å¤ï¼çºäºæé«æ¨ç´æ¨è¨é æ¸¬çå­¸ç¿æçï¼æåæåºäºå°æ¯æ¨ç´æä½³å (CPO)ï¼å®å¢å¼·äºæ¨¡åæç¥å°è©±å®å¨çæçè½åãééæ­¤æ©å¶ï¼LLM å¨æ¨çéç¨ä¸­åæèª¿æ´å¶åæç­ç¥ï¼å¤§å¹å¢å¼·å¶å°æè¶çæ»æçé²ç¦¦è½åãå»£æ³çå¯¦é©çµæè­æï¼R2D ææå°æ¸è¼äºåç¨®æ»æï¼ä¸¦æ¹åäºæ´é«å®å¨æ§ï¼çªé¡¯äºå®å¨æç¥æ¨çå¨å å¼· LLM å°æè¶ççç©©å¥æ§æ¹é¢çæ½åã

##### **A Survey of Text Classification Under Class Distribution Shift**
2502.12965v1 by Adriana Valentina Costache, Silviu Florin Gheorghe, Eduard Gabriel Poesina, Paul Irofti, Radu Tudor Ionescu

The basic underlying assumption of machine learning (ML) models is that the
training and test data are sampled from the same distribution. However, in
daily practice, this assumption is often broken, i.e.~the distribution of the
test data changes over time, which hinders the application of conventional ML
models. One domain where the distribution shift naturally occurs is text
classification, since people always find new topics to discuss. To this end, we
survey research articles studying open-set text classification and related
tasks. We divide the methods in this area based on the constraints that define
the kind of distribution shift and the corresponding problem formulation,
i.e.~learning with the Universum, zero-shot learning, and open-set learning. We
next discuss the predominant mitigation approaches for each problem setup.
Finally, we identify several future work directions, aiming to push the
boundaries beyond the state of the art. Interestingly, we find that continual
learning can solve many of the issues caused by the shifting class
distribution. We maintain a list of relevant papers at
https://github.com/Eduard6421/Open-Set-Survey.

æè¦ï¼æ©å¨å­¸ç¿ (ML) æ¨¡åçåºæ¬åè¨­æ¯è¨ç·´è³æåæ¸¬è©¦è³æåæ¨£èªåä¸ååä½ãç¶èï¼å¨æ¥å¸¸å¯¦åä¸­ï¼éååè¨­ç¶å¸¸è¢«æç ´ï¼ä¹å°±æ¯èªªæ¸¬è©¦è³æçåå¸æé¨èæéæ¹è®ï¼éæé»ç¤å³çµ± ML æ¨¡åçæç¨ãåä½è½ç§»èªç¶ç¼ççå¶ä¸­ä¸åé åæ¯æå­åé¡ï¼å çºäººåç¸½è½æ¾å°æ°çä¸»é¡ä¾è¨è«ãçºæ­¤ï¼æåèª¿æ¥ç ç©¶éæ¾éæå­åé¡åç¸éä»»åçç ç©¶æç« ãæåæ ¹æå®ç¾©åä½è½ç§»çé¡ååå°æåé¡å¬å¼çéå¶ï¼å°éåé åçæ¹æ³åçºï¼ä½¿ç¨ Universum å­¸ç¿ãé¶æ¬¡å­¸ç¿åéæ¾éå­¸ç¿ãæ¥ä¸ä¾ï¼æåè¨è«æ¯ååé¡è¨­å®çä¸»è¦ç·©è§£æ¹æ³ãæå¾ï¼æåæ¾åºå¹¾åæªä¾çç ç©¶æ¹åï¼ç®æ¨æ¯å°çç·æ¨å±å°ç¾ææè¡çæ¥µéä¹å¤ãæè¶£çæ¯ï¼æåç¼ç¾æçºå­¸ç¿å¯ä»¥è§£æ±ºè¨±å¤ç±é¡å¥åä½è½ç§»æé æçè­°é¡ãæåå¨ https://github.com/Eduard6421/Open-Set-Survey ç¶­è­·ä¸ä»½ç¸éè«ææ¸å®ã

##### **Trust Me, I'm Wrong: High-Certainty Hallucinations in LLMs**
2502.12964v1 by Adi Simhi, Itay Itzhak, Fazl Barez, Gabriel Stanovsky, Yonatan Belinkov

Large Language Models (LLMs) often generate outputs that lack grounding in
real-world facts, a phenomenon known as hallucinations. Prior research has
associated hallucinations with model uncertainty, leveraging this relationship
for hallucination detection and mitigation. In this paper, we challenge the
underlying assumption that all hallucinations are associated with uncertainty.
Using knowledge detection and uncertainty measurement methods, we demonstrate
that models can hallucinate with high certainty even when they have the correct
knowledge. We further show that high-certainty hallucinations are consistent
across models and datasets, distinctive enough to be singled out, and challenge
existing mitigation methods. Our findings reveal an overlooked aspect of
hallucinations, emphasizing the need to understand their origins and improve
mitigation strategies to enhance LLM safety. The code is available at
https://github.com/technion-cs-nlp/Trust_me_Im_wrong .

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç¶å¸¸ç¢çç¼ºä¹çå¯¦ä¸çäºå¯¦æ ¹æçè¼¸åºï¼éç¨®ç¾è±¡ç¨±çºå¹»è¦ºãååçç ç©¶å·²å°å¹»è¦ºèæ¨¡åä¸ç¢ºå®æ§è¯ç¹«èµ·ä¾ï¼å©ç¨éç¨®éä¿é²è¡å¹»è¦ºåµæ¸¬åç·©è§£ãå¨æ¬æä¸­ï¼æåææ°ææå¹»è¦ºé½èä¸ç¢ºå®æ§ç¸éçåºæ¬åè¨­ãä½¿ç¨ç¥è­åµæ¸¬åä¸ç¢ºå®æ§æ¸¬éæ¹æ³ï¼æåè­ææ¨¡åå³ä½¿æææ­£ç¢ºçç¥è­ï¼ä¹è½ä»¥é«åº¦ç¢ºå®æ§ç¢çå¹»è¦ºãæåé²ä¸æ­¥è¡¨æï¼é«ç¢ºå®æ§å¹»è¦ºå¨æ¨¡ååè³æéä¹éæ¯ä¸è´çï¼è¶³å¤ ç¨ç¹ä»¥è³æ¼å¯ä»¥å®ç¨æé¸åºä¾ï¼ä¸¦ææ°ç¾æçç·©è§£æ¹æ³ãæåçç ç©¶çµææ­ç¤ºäºå¹»è¦ºçä¸åè¢«å¿½è¦çæ¹é¢ï¼å¼·èª¿éè¦äºè§£å¶èµ·æºä¸¦æ¹é²ç·©è§£ç­ç¥ä»¥å¢å¼· LLM å®å¨æ§ãå¯ä»¥å¨ https://github.com/technion-cs-nlp/Trust_me_Im_wrong æ¾å°ç¨å¼ç¢¼ã

##### **Infinite Retrieval: Attention Enhanced LLMs in Long-Context Processing**
2502.12962v1 by Xiaoju Ye, Zhichun Wang, Jingyuan Wang

Limited by the context window size of Large Language Models(LLMs), handling
various tasks with input tokens exceeding the upper limit has been challenging,
whether it is a simple direct retrieval task or a complex multi-hop reasoning
task. Although various methods have been proposed to enhance the long-context
processing capabilities of LLMs, they either incur substantial post-training
costs, or require additional tool modules(e.g.,RAG), or have not shown
significant improvement in realistic tasks. Our work observes the correlation
between the attention distribution and generated answers across each layer, and
establishes the attention allocation aligns with retrieval-augmented
capabilities through experiments. Drawing on the above insights, we propose a
novel method InfiniRetri that leverages the LLMs's own attention information to
enable accurate retrieval across inputs of infinitely length. Our evaluations
indicate that InfiniRetri achieves 100% accuracy in the
Needle-In-a-Haystack(NIH) test over 1M tokens using a 0.5B parameter model,
surpassing other method or larger models and setting a new
state-of-the-art(SOTA). Moreover, our method achieves significant performance
improvements on real-world benchmarks, with a maximum 288% improvement. In
addition, InfiniRetri can be applied to any Transformer-based LLMs without
additional training and substantially reduces inference latency and compute
overhead in long texts. In summary, our comprehensive studies show
InfiniRetri's potential for practical applications and creates a paradigm for
retrievaling information using LLMs own capabilities under infinite-length
tokens. Code will be released in link.

æè¦ï¼åéäºå¤§åè¯­è¨æ¨¡å (LLM) çä¸ä¸æçªå£å¤§å°ï¼å¤çè¶åºä¸éçè¾å¥æ è®°çåç§ä»»å¡ä¸ç´å·ææææ§ï¼æ è®ºæ¯ç®åçç´æ¥æ£ç´¢ä»»å¡è¿æ¯å¤æçå¤è·³æ¨çä»»å¡ãè½ç¶å·²ç»æåºäºåç§æ¹æ³æ¥å¢å¼º LLM çé¿ä¸ä¸æå¤çè½åï¼ä½å®ä»¬è¦ä¹äº§çå¤§éçåè®­ç»ææ¬ï¼è¦ä¹éè¦é¢å¤çå·¥å·æ¨¡åï¼ä¾å¦ï¼RAGï¼ï¼è¦ä¹å¨å®éä»»å¡ä¸­æ²¡ææ¾ç¤ºåºæ¾ççæ¹è¿ãæä»¬çå·¥ä½è§å¯äºæ¯å±æ³¨æååå¸åçæç­æ¡ä¹é´çç¸å³æ§ï¼å¹¶éè¿å®éªå»ºç«äºæ³¨æååéä¸æ£ç´¢å¢å¼ºè½åä¿æä¸è´ãæ ¹æ®ä¸è¿°è§è§£ï¼æä»¬æåºäºä¸ç§æ°æ¹æ³ InfiniRetriï¼è¯¥æ¹æ³å©ç¨ LLM èªèº«çæ³¨æåä¿¡æ¯æ¥å®ç°å¯¹æ éé¿åº¦è¾å¥çåç¡®æ£ç´¢ãæä»¬çè¯ä¼°è¡¨æï¼InfiniRetri å¨ä½¿ç¨ 0.5B åæ°æ¨¡åå¯¹è¶è¿ 100 ä¸ä¸ªæ è®°çéå¤´å¹²èå  (NIH) æµè¯ä¸­å®ç°äº 100% çåç¡®çï¼è¶è¶äºå¶ä»æ¹æ³ææ´å¤§çæ¨¡åï¼å¹¶åé äºæ°çæåè¿ (SOTA)ãæ­¤å¤ï¼æä»¬çæ¹æ³å¨å®éåºåä¸å®ç°äºæ¾èçæ§è½æåï¼æå¤§æåäº 288%ãæ­¤å¤ï¼InfiniRetri å¯ä»¥åºç¨äºä»»ä½åºäº Transformer ç LLMï¼èæ éé¢å¤çè®­ç»ï¼å¹¶ä¸å¯ä»¥å¤§å¹åå°æ¨çå»¶è¿åé¿ææ¬ä¸­çè®¡ç®å¼éãæ»ä¹ï¼æä»¬çç»¼åç ç©¶è¡¨æäº InfiniRetri å¨å®éåºç¨ä¸­çæ½åï¼å¹¶ä¸ºä½¿ç¨ LLM èªèº«è½åå¨æ éé¿åº¦æ è®°ä¸æ£ç´¢ä¿¡æ¯åé äºä¸ä¸ªèä¾ãä»£ç å°å¨é¾æ¥ä¸­åå¸ã

##### **Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger**
2502.12961v1 by Wenjun Li, Dexun Li, Kuicai Dong, Cong Zhang, Hao Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Liu

Large language models (LLMs) have shown remarkable emergent capabilities,
transforming the execution of functional tasks by leveraging external tools for
complex problems that require specialized processing or real-time data. While
existing research expands LLMs access to diverse tools (e.g., program
interpreters, search engines, weather/map apps), the necessity of using these
tools is often overlooked, leading to indiscriminate tool invocation. This
naive approach raises two key issues:(1) increased delays due to unnecessary
tool calls, and (2) potential errors resulting from faulty interactions with
external tools. In this paper, we introduce meta-cognition as a proxy for LLMs
self-assessment of their capabilities, representing the model's awareness of
its own limitations. Based on this, we propose MeCo, an adaptive
decision-making strategy for external tool use. MeCo quantifies metacognitive
scores by capturing high-level cognitive signals in the representation space,
guiding when to invoke tools. Notably, MeCo is fine-tuning-free and incurs
minimal cost. Our experiments show that MeCo accurately detects LLMs' internal
cognitive signals and significantly improves tool-use decision-making across
multiple base models and benchmarks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºé¡¯èçæ°èè½åï¼éééç¨å¤é¨å·¥å·ä¾å·è¡åè½ä»»åï¼è§£æ±ºéè¦å°æ¥­èçæå³æè³æçè¤éåé¡ï¼å¾èè½è®ä»»åçå·è¡æ¹å¼ãåç®¡ç¾æç ç©¶æ´å±äº LLM å°åç¨®å·¥å·çå­åï¼ä¾å¦ç¨å¼ç¢¼è©®éå¨ãæå°å¼æãå¤©æ°£/å°åæç¨ç¨å¼ï¼ï¼ä½ä½¿ç¨éäºå·¥å·çå¿è¦æ§å¾å¾è¢«å¿½ç¥ï¼å°è´ä¸å é¸æå°å¼å«å·¥å·ãéç¨®å¤©ççæ¹æ³æåºäºå©åééµåé¡ï¼(1) ç±æ¼ä¸å¿è¦çå·¥å·å¼å«èå°è´å»¶é²å¢å ï¼ä»¥å (2) ç±æ¼èå¤é¨å·¥å·äºåé¯èª¤èå°è´çæ½å¨é¯èª¤ãå¨æ¬æä¸­ï¼æåå°åèªç¥å¼å¥ä½çº LLM èªæè©ä¼°å¶è½åçä»£çï¼ä»£è¡¨æ¨¡åæè­å°å¶èªèº«çéå¶ãåºæ¼æ­¤ï¼æåæåºäº MeCoï¼ä¸ç¨®ç¨æ¼å¤é¨å·¥å·ä½¿ç¨çé©ææ§æ±ºç­å¶å®ç­ç¥ãMeCo ééæ·åè¡¨å¾µç©ºéä¸­çé«éèªç¥è¨èä¾éååèªç¥åæ¸ï¼æå°ä½æå¼å«å·¥å·ãå¼å¾æ³¨æçæ¯ï¼MeCo æ¯åå¾®èª¿çï¼èä¸ææ¬æ¥µä½ãæåçå¯¦é©è¡¨æï¼MeCo è½å¤ æºç¢ºå°åµæ¸¬ LLM çå§é¨èªç¥è¨èï¼ä¸¦å¤§å¹æ¹åè·¨å¤ååºæ¬æ¨¡åååºæºçå·¥å·ä½¿ç¨æ±ºç­å¶å®ã

##### **AlignFreeze: Navigating the Impact of Realignment on the Layers of Multilingual Models Across Diverse Languages**
2502.12959v1 by Steve Bakos, FÃ©lix Gaschi, David GuzmÃ¡n, Riddhi More, Kelly Chutong Li, En-Shiun Annie Lee

Realignment techniques are often employed to enhance cross-lingual transfer
in multilingual language models, still, they can sometimes degrade performance
in languages that differ significantly from the fine-tuned source language.
This paper introduces AlignFreeze, a method that freezes either the layers'
lower half or upper half during realignment. Through controlled experiments on
4 tasks, 3 models, and in 35 languages, we find that realignment affects all
the layers but can be the most detrimental to the lower ones. Freezing the
lower layers can prevent performance degradation. Particularly, AlignFreeze
improves Part-of-Speech (PoS) tagging performances in languages where full
realignment fails: with XLM-R, it provides improvements of more than one
standard deviation in accuracy in seven more languages than full realignment.

æè¦ï¼éæ°å°é½æè¡éå¸¸ç¨æ¼å¢å¼·å¤èªè¨èªè¨æ¨¡åä¸­çè·¨èªè¨è½ç§»ï¼ç¶èï¼å®åæææéä½èå¾®èª¿æºèªè¨é¡¯èä¸åçèªè¨çæè½ãæ¬æä»ç´¹äº AlignFreezeï¼ä¸ç¨®å¨éæ°å°é½æéåçµå±¤çä¸åé¨æä¸åé¨ççæ¹æ³ãéé 4 é ä»»åã3 åæ¨¡åå 35 ç¨®èªè¨çåæ§å¯¦é©ï¼æåç¼ç¾éæ°å°é½æå½±é¿ææå±¤ï¼ä½å°è¼ä½å±¤çå½±é¿æå¤§ãåçµè¼ä½å±¤å¯ä»¥é²æ­¢æè½ä¸éãç¹å¥æ¯ï¼AlignFreeze æ¹åäºå¨å®å¨éæ°å°é½å¤±æçèªè¨ä¸­çè©æ§ (PoS) æ¨è¨æè½ï¼ä½¿ç¨ XLM-Rï¼å®æ¯å®å¨éæ°å°é½å¨ä¸ç¨®èªè¨ä¸­æä¾äºè¶éä¸åæ¨æºå·®çæºç¢ºåº¦æ¹é²ã

##### **Task-Informed Anti-Curriculum by Masking Improves Downstream Performance on Text**
2502.12953v1 by Andrei Jarca, Florinel Alin Croitoru, Radu Tudor Ionescu

Masked language modeling has become a widely adopted unsupervised technique
to pre-train language models. However, the process of selecting tokens for
masking is random, and the percentage of masked tokens is typically fixed for
the entire training process. In this paper, we propose to adjust the masking
ratio and to decide which tokens to mask based on a novel task-informed
anti-curriculum learning scheme. First, we harness task-specific knowledge
about useful and harmful tokens in order to determine which tokens to mask.
Second, we propose a cyclic decaying masking ratio, which corresponds to an
anti-curriculum schedule (from hard to easy). We exemplify our novel
task-informed anti-curriculum by masking (TIACBM) approach across three diverse
downstream tasks: sentiment analysis, text classification by topic, and
authorship attribution. Our findings suggest that TIACBM enhances the ability
of the model to focus on key task-relevant features, contributing to
statistically significant performance gains across tasks. We release our code
at https://github.com/JarcaAndrei/TIACBM.

æè¦ï¼é®è½èªè¨æ¨¡åå·²æçºä¸ç¨®å»£æ³æ¡ç¨çç¡ç£ç£æè¡ï¼ç¨æ¼é åè¨ç·´èªè¨æ¨¡åãç¶èï¼é¸æç¨æ¼é®è½çè©å½çéç¨æ¯é¨æ©çï¼ä¸é®è½è©å½çç¾åæ¯éå¸¸å¨æ´åè¨ç·´éç¨ä¸­æ¯åºå®çãå¨æ¬æä¸­ï¼æåå»ºè­°èª¿æ´é®è½çï¼ä¸¦æ ¹æä¸ç¨®æ°ç©çä»»åè³è¨åèª²ç¨å­¸ç¿æ¹æ¡ä¾æ±ºå®è¦é®è½åªäºè©å½ãé¦åï¼æåå©ç¨ä»»åç¹å®çç¥è­ï¼äºè§£æç¨çåæå®³çè©å½ï¼ä»¥ç¢ºå®è¦é®è½åªäºè©å½ãå¶æ¬¡ï¼æåæåºä¸åå¾ªç°éæ¸é®è½çï¼éå°ææ¼ä¸ååèª²ç¨è¡¨ï¼å¾é£å°æï¼ãæåä»¥ä¸é ä¸åçä¸æ¸¸ä»»åçºä¾ï¼èªªææåæ°ç©çä»»åè³è¨åèª²ç¨é®è½ï¼TIACBMï¼æ¹æ³ï¼æç·åæãæä¸»é¡åé¡æå­ï¼ä»¥åä½èæ­¸å±¬ãæåçç ç©¶çµæè¡¨æï¼TIACBM å¢å¼·äºæ¨¡åå°æ³¨æ¼ééµä»»åç¸éç¹å¾µçè½åï¼æå©æ¼å¨åé ä»»åä¸­ç²å¾å·æçµ±è¨æç¾©çæè½æåãæåå¨ https://github.com/JarcaAndrei/TIACBM éåºæåçç¨å¼ç¢¼ã

##### **Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection**
2502.12948v1 by Athira J Jacob, Puneet Sharma, Daniel Rueckert

Detection of hyperenhancement from cardiac LGE MRI images is a complex task
requiring significant clinical expertise. Although deep learning-based models
have shown promising results for the task, they require large amounts of data
with fine-grained annotations. Clinical reports generated for cardiac MR
studies contain rich, clinically relevant information, including the location,
extent and etiology of any scars present. Although recently developed
CLIP-based training enables pretraining models with image-text pairs, it
requires large amounts of data and further finetuning strategies on downstream
tasks. In this study, we use various strategies rooted in domain knowledge to
train a model for LGE detection solely using text from clinical reports, on a
relatively small clinical cohort of 965 patients. We improve performance
through the use of synthetic data augmentation, by systematically creating scar
images and associated text. In addition, we standardize the orientation of the
images in an anatomy-informed way to enable better alignment of spatial and
text features. We also use a captioning loss to enable fine-grained supervision
and explore the effect of pretraining of the vision encoder on performance.
Finally, ablation studies are carried out to elucidate the contributions of
each design component to the overall performance of the model.

æè¦ï¼å¾å¿è LGE MRI å½±ååµæ¸¬åºéåº¦å¢å¼·æ¯ä¸é è¤éçä»»åï¼éè¦é¡¯èçè¨åºå°æ¥­ç¥è­ãåç®¡åºæ¼æ·±åº¦å­¸ç¿çæ¨¡åå·²é¡¯ç¤ºåºå°éé ä»»åæåæ¯ççµæï¼ä½å®åéè¦å¤§éå·æç´°ç·»è¨»è§£çè³æãçºå¿è MR ç ç©¶ç¢ççè¨åºå ±ååå«è±å¯ä¸è¨åºä¸ç¸éçè³è¨ï¼åæ¬ä»»ä½ç¤ççä½ç½®ãç¯ååçå ãåç®¡æè¿éç¼çåºæ¼ CLIP çè¨ç·´è½ä½¿ç¨å½±åæå­å°é è¨ç·´æ¨¡åï¼ä½å®éè¦å¤§éè³æåé²ä¸æ­¥å¾®èª¿ä¸æ¸¸ä»»åçç­ç¥ãå¨éé ç ç©¶ä¸­ï¼æåä½¿ç¨æ¤åºæ¼é åç¥è­çåç¨®ç­ç¥ï¼åä½¿ç¨ä¾èªè¨åºå ±åçæå­ï¼å¨ä¸åç¸å°è¼å°ç 965 åæ£èè¨åºç¾¤é«ä¸­è¨ç·´ä¸å LGE åµæ¸¬æ¨¡åãæåééä½¿ç¨åæè³ææ´åä¾æ¹åæè½ï¼ç³»çµ±æ§å°å»ºç«ç¤çå½±ååç¸éæå­ãæ­¤å¤ï¼æåä»¥è§£åå­¸åç¥çæ¹å¼æ¨æºåå½±åæ¹åï¼ä»¥ä½¿ç©ºéåæå­ç¹å¾µè½æ´å¥½å°å°é½ãæåä¹ä½¿ç¨æ¨é¡æå¤±ä¾åç¨ç´°ç·»çç£ç£ï¼ä¸¦æ¢è¨è¦è¦ºç·¨ç¢¼å¨çé è¨ç·´å°æè½çå½±é¿ãæå¾ï¼é²è¡æ¶èç ç©¶ä»¥é¡ææ¯åè¨­è¨åä»¶å°æ¨¡åæ´é«æè½çè²¢ç»ã

##### **Every Expert Matters: Towards Effective Knowledge Distillation for Mixture-of-Experts Language Models**
2502.12947v1 by Gyeongman Kim, Gyouk Chu, Eunho Yang

With the emergence of Mixture-of-Experts (MoE), the efficient scaling of
model size has accelerated the development of large language models in recent
years. However, their high memory requirements prevent their use in
resource-constrained environments. While knowledge distillation (KD) has been a
proven method for model compression, its application to MoE teacher models
remains underexplored. Through our investigation, we discover that
non-activated experts in MoE models possess valuable knowledge that benefits
student models. We further demonstrate that existing KD methods are not optimal
for compressing MoE models, as they fail to leverage this knowledge
effectively. To address this, we propose two intuitive MoE-specific KD methods
for the first time: Knowledge Augmentation (KA) and Student-Aware Router (SAR),
both designed to effectively extract knowledge from all experts. Specifically,
KA augments knowledge by sampling experts multiple times, while SAR uses all
experts and adjusts the expert weights through router training to provide
optimal knowledge. Extensive experiments show that our methods outperform
conventional KD methods, demonstrating their effectiveness for MoE teacher
models.

æè¦ï¼é¨è Mixture-of-Experts (MoE) çåºç¾ï¼æ¨¡åè¦æ¨¡çæææ´å±å éäºè¿å¹´ä¾å¤§åèªè¨æ¨¡åçç¼å±ãç¶èï¼å®åçé«è¨æ¶é«éæ±æé»ç¤å®åå¨è³æºåéçç°å¢ä¸­ä½¿ç¨ãéç¶ç¥è­è¸é¤¾ (KD) å·²è¢«è­ææ¯ä¸ç¨®æ¨¡åå£ç¸®çæ¹æ³ï¼ä½å®å¨ MoE æå¸«æ¨¡åä¸­çæç¨ä»æªè¢«ååæ¢ç´¢ãééæåçèª¿æ¥ï¼æåç¼ç¾ MoE æ¨¡åä¸­æªè¢«åç¨çå°å®¶æææå¹å¼çç¥è­ï¼éäºç¥è­å°å­¸çæ¨¡åæçãæåé²ä¸æ­¥è­æï¼ç¾æç KD æ¹æ³ä¸¦éå£ç¸® MoE æ¨¡åçæä½³æ¹æ³ï¼å çºå®åç¡æ³ææå©ç¨éäºç¥è­ãçºäºè§£æ±ºéååé¡ï¼æåé¦æ¬¡æåºå©ç¨®ç´è§ç MoE å°ç¨ KD æ¹æ³ï¼ç¥è­æ´å (KA) åå­¸çæç¥è·¯ç±å¨ (SAR)ï¼å©èé½æ¨å¨å¾ææå°å®¶æææåç¥è­ãå·é«ä¾èªªï¼KA ééå¤æ¬¡æ½æ¨£å°å®¶ä¾æ´åç¥è­ï¼è SAR ä½¿ç¨ææå°å®¶ä¸¦ééè·¯ç±å¨è¨ç·´èª¿æ´å°å®¶æ¬éä»¥æä¾æä½³ç¥è­ãå»£æ³çå¯¦é©è¡¨æï¼æåçæ¨¡ååªæ¼å³çµ±ç KD æ¨¡åï¼è­æäºå®åå° MoE æå¸«æ¨¡åçæææ§ã

##### **LLMPopcorn: An Empirical Study of LLMs as Assistants for Popular Micro-video Generation**
2502.12945v1 by Junchen Fu, Xuri Ge, Kaiwen Zheng, Ioannis Arapakis, Xin Xin, Joemon M. Jose

Popular Micro-videos, dominant on platforms like TikTok and YouTube, hold
significant commercial value. The rise of high-quality AI-generated content has
spurred interest in AI-driven micro-video creation. However, despite the
advanced capabilities of large language models (LLMs) like ChatGPT and DeepSeek
in text generation and reasoning, their potential to assist the creation of
popular micro-videos remains largely unexplored.
  In this paper, we conduct an empirical study on LLM-assisted popular
micro-video generation (LLMPopcorn). Specifically, we investigate the following
research questions: (i) How can LLMs be effectively utilized to assist popular
micro-video generation? (ii) To what extent can prompt-based enhancements
optimize the LLM-generated content for higher popularity? (iii) How well do
various LLMs and video generators perform in the popular micro-video generation
task? By exploring these questions, we show that advanced LLMs like DeepSeek-V3
enable micro-video generation to achieve popularity comparable to human-created
content. Prompt enhancements further boost popularity, and benchmarking
highlights DeepSeek-V3 and DeepSeek-R1 among LLMs, while LTX-Video and
HunyuanVideo lead in video generation. This pioneering work advances
AI-assisted micro-video creation, uncovering new research opportunities. We
will release the code and datasets to support future studies.

æè¦ï¼<paragraph>å¨ TikTok å YouTube ç­å¹³å°ä¸æµè¡çå¾®å½±çå·æ
éè¦çåä¸ä»·å¼ãé«è´¨é AI çæçåå®¹çå´èµ·
æ¿åäºäººä»¬å¯¹ AI é©±å¨çå¾®å½±çåä½çå´è¶£ãç¶èï¼å°½ç®¡å¤§åè¯­è¨æ¨¡å (LLM) å¦ ChatGPT å DeepSeek
å¨ææ¬çæåæ¨çæ¹é¢çè½åå¾å¼ºï¼ä½å®ä»¬å¨è¾å©åå»º
æµè¡å¾®å½±çæ¹é¢çæ½åå¨å¾å¤§ç¨åº¦ä¸ä»æªå¾å°æ¢ç´¢ã
  å¨æ¬æä¸­ï¼æä»¬å¯¹ LLM è¾å©çæµè¡
å¾®å½±ççæ (LLMPopcorn) è¿è¡äºå®è¯ç ç©¶ãå·ä½æ¥è¯´ï¼æä»¬è°æ¥äºä»¥ä¸
ç ç©¶é®é¢ï¼(i) å¦ä½ææå©ç¨ LLM æ¥è¾å©æµè¡
å¾®å½±ççæï¼(ii) åºäºæç¤ºçå¢å¼ºå¨å¤å¤§ç¨åº¦ä¸å¯ä»¥
ä¼å LLM çæçåå®¹ä»¥è·å¾æ´é«çæµè¡åº¦ï¼(iii) åç§ LLM åè§é¢çæå¨å¨æµè¡çå¾®è§é¢çæä¸­è¡¨ç°å¦ä½
ä»»å¡ï¼éè¿æ¢ç´¢è¿äºé®é¢ï¼æä»¬è¡¨æäºå DeepSeek-V3 è¿æ ·çé«çº§ LLM
ä½¿å¾®è§é¢çæè½å¤è¾¾å°ä¸äººç±»åä½çåå®¹ç¸å½çæµè¡åº¦ãæç¤ºå¢å¼ºè¿ä¸æ­¥æé«äºåæ¬¢è¿ç¨åº¦ï¼å¹¶ä¸åºåæµè¯çªåºäº LLM ä¸­ç DeepSeek-V3 å DeepSeek-R1ï¼è LTX-Video å
HunyuanVideo å¨è§é¢çæä¸­é¢åãè¿é¡¹å¼åæ§çå·¥ä½æ¨è¿äº
äººå·¥æºè½è¾å©çå¾®è§é¢åä½ï¼åç°äºæ°çç ç©¶æºä¼ãæä»¬å°åå¸ä»£ç åæ°æ®éä»¥æ¯ææªæ¥çç ç©¶ã</paragraph>

##### **Synthetic Data Generation for Culturally Nuanced Commonsense Reasoning in Low-Resource Languages**
2502.12932v1 by Salsabila Zahirah Pranida, Rifo Ahmad Genadi, Fajri Koto

Quantifying reasoning capability in low-resource languages remains a
challenge in NLP due to data scarcity and limited access to annotators. While
LLM-assisted dataset construction has proven useful for medium- and
high-resource languages, its effectiveness in low-resource languages,
particularly for commonsense reasoning, is still unclear. In this paper, we
compare three dataset creation strategies: (1) LLM-assisted dataset generation,
(2) machine translation, and (3) human-written data by native speakers, to
build a culturally nuanced story comprehension dataset. We focus on Javanese
and Sundanese, two major local languages in Indonesia, and evaluate the
effectiveness of open-weight and closed-weight LLMs in assisting dataset
creation through extensive manual validation. To assess the utility of
synthetic data, we fine-tune language models on classification and generation
tasks using this data and evaluate performance on a human-written test set. Our
findings indicate that LLM-assisted data creation outperforms machine
translation.

æè¦ï¼ç±æ¼è³æç¨å°ä¸æ¨è¨»èæéï¼éåä½è³æºèªè¨ä¸­çæ¨çè½åå¨èªç¶èªè¨èçä¸­ä»ç¶æ¯ä¸é ææ°ãéç¶ LLM è¼å©çè³æéå»ºæ§å·²è¢«è­æå°ä¸­é«è³æºèªè¨æç¨ï¼ä½å¶å¨ä½è³æºèªè¨ä¸­çæææ§ï¼ç¹å¥æ¯å°æ¼å¸¸è­æ¨çï¼ä»ç¶ä¸æ¸æ¥ãå¨æ¬æä¸­ï¼æåæ¯è¼äºä¸ç¨®è³æéå»ºç«ç­ç¥ï¼(1) LLM è¼å©çè³æéçæï¼(2) æ©å¨ç¿»è­¯ï¼ä»¥å (3) æ¯èªäººå£«æ°å¯«çäººå·¥è³æï¼ä»¥å»ºç«å·ææåç´°å¾®å·®çæäºçè§£è³æéãæåå°æ³¨æ¼çªåèªåå·½ä»èªï¼éå©ç¨®å°å°¼çä¸»è¦å°æ¹èªè¨ï¼ä¸¦ééå»£æ³çæåé©è­è©ä¼°éæ¾æ¬éåå°éæ¬é LLM å¨åå©è³æéå»ºç«ä¸­çæææ§ãçºäºè©ä¼°åæè³æçæç¨ï¼æåä½¿ç¨éäºè³æå°åé¡åçæä»»åé²è¡èªè¨æ¨¡åå¾®èª¿ï¼ä¸¦å¨äººå·¥æ°å¯«çæ¸¬è©¦éä¸è©ä¼°æè½ãæåçç ç©¶çµæè¡¨æï¼LLM è¼å©çè³æå»ºç«åªæ¼æ©å¨ç¿»è­¯ã

##### **Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options**
2502.12929v1 by Lakshmi Nair, Ian Trase, Mark Kim

We present a novel reasoning approach called Flow-of-Options (FoO), designed
to address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs
to systematically explore a diverse range of possibilities in their reasoning,
as demonstrated by an FoO-based agentic system for autonomously solving Machine
Learning tasks (AutoML). Our framework outperforms state-of-the-art baselines,
achieving improvements of 38.2% - 69.2% on standard data science tasks, and
37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost
under $1 per task, our framework is well-suited for cost-sensitive
applications. Beyond classification and regression, we illustrate the broader
applicability of our FoO-based agentic system to tasks such as reinforcement
learning and image generation. Our framework presents significant advancements
compared to current state-of-the-art agentic systems for AutoML, due to the
benefits of FoO in enforcing diversity in LLM solutions through compressed,
explainable representations that also support long-term memory when combined
with case-based reasoning.

æè¦ï¼æåæåºäºä¸ç¨®ç¨±çºé¸é æµ (FoO) çæ°æ¨çæ¹æ³ï¼æ¨å¨è§£æ±ºå¤§åèªè¨æ¨¡å (LLM) ä¸­çå§å¨åå·®ãFoO ä½¿ LLM è½ç³»çµ±æ§å°æ¢ç´¢å¶æ¨çä¸­çåç¨®å¯è½æ§ï¼éç±ä¸ååºæ¼ FoO çä»£çç³»çµ±å±ç¤ºï¼è©²ç³»çµ±å¯èªä¸»è§£æ±ºæ©å¨å­¸ç¿ä»»å (AutoML)ãæåçæ¡æ¶åªæ¼æåé²çåºæºï¼å¨æ¨æºæ¸æç§å­¸ä»»åä¸åå¾äº 38.2% - 69.2% çæ¹é²ï¼å¨æ²»çåå­¸ä»»åä¸åå¾äº 37.4% - 47.9% çæ¹é²ãç±æ¼æ¯åä»»åçæ´é«éçææ¬ä½æ¼ 1 ç¾åï¼å æ­¤æåçæ¡æ¶éå¸¸é©åå°ææ¬ææçæç¨ãé¤äºåé¡ååæ­¸ä¹å¤ï¼æåéèªªæäºåºæ¼ FoO çä»£çç³»çµ±å¨å¼·åå­¸ç¿åååçæç­ä»»åä¸­çæ´å»£æ³é©ç¨æ§ãæåçæ¡æ¶èç¶åæåé²ç AutoML ä»£çç³»çµ±ç¸æ¯å·æé¡¯èçé²æ­¥ï¼éæ¯å çº FoO å¨ééå£ç¸®ãå¯è§£éçè¡¨ç¤ºå¼·å¶ LLM è§£æ±ºæ¹æ¡çå¤æ¨£æ§æ¹é¢å·æåªå¢ï¼éäºè¡¨ç¤ºèåºæ¼æ¡ä¾çæ¨ççµåæéæ¯æé·æè¨æ¶ã

##### **Finedeep: Mitigating Sparse Activation in Dense LLMs via Multi-Layer Fine-Grained Experts**
2502.12928v1 by Leiyu Pan, Zhenpeng Su, Minxuan Lv, Yizhe Xiong, Xiangwen Zhang, Zijia Lin, Hui Chen, Jungong Han, Guiguang Ding, Cheng Luo, Di Zhang, Kun Gai, Deyi Xiong

Large language models have demonstrated exceptional performance across a wide
range of tasks. However, dense models usually suffer from sparse activation,
where many activation values tend towards zero (i.e., being inactivated). We
argue that this could restrict the efficient exploration of model
representation space. To mitigate this issue, we propose Finedeep, a
deep-layered fine-grained expert architecture for dense models. Our framework
partitions the feed-forward neural network layers of traditional dense models
into small experts, arranges them across multiple sub-layers. A novel routing
mechanism is proposed to determine each expert's contribution. We conduct
extensive experiments across various model sizes, demonstrating that our
approach significantly outperforms traditional dense architectures in terms of
perplexity and benchmark performance while maintaining a comparable number of
parameters and floating-point operations. Moreover, we find that Finedeep
achieves optimal results when balancing depth and width, specifically by
adjusting the number of expert sub-layers and the number of experts per
sub-layer. Empirical results confirm that Finedeep effectively alleviates
sparse activation and efficiently utilizes representation capacity in dense
models.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨åç¨®ä»»åä¸­å±ç¾åºéå¡çæè½ãç¶èï¼å¯éæ¨¡åéå¸¸æåºç¾ç¨çæ¿æ´»ï¼å¶ä¸­è¨±å¤æ¿æ´»å¼è¶¨è¿æ¼é¶ï¼å³èæ¼éæ¿æ´»çæï¼ãæåèªçºéå¯è½æéå¶æ¨¡åè¡¨ç¤ºç©ºéçæææ¢ç´¢ãçºäºæ¸è¼éååé¡ï¼æåæåº Finedeepï¼éæ¯ä¸ç¨®éå°å¯éæ¨¡åçæ·±åº¦åå±¤ç´°ç²åº¦å°å®¶æ¶æ§ãæåçæ¡æ¶å°å³çµ±å¯éæ¨¡åçåé¥ç¥ç¶ç¶²è·¯å±¤åå²æå°åå°å®¶ï¼ä¸¦å°å®åæåå¨å¤åå­å±¤ä¸­ãæåæåºäºä¸ç¨®æ°ç©çè·¯ç±æ©å¶ä¾ç¢ºå®æ¯åå°å®¶çè²¢ç»ãæåéå°åç¨®æ¨¡åå¤§å°é²è¡äºå»£æ³çå¯¦é©ï¼è­ææåçåæ³å¨å°æåº¦ååºæºæè½æ¹é¢é¡¯èåªæ¼å³çµ±çå¯éæ¶æ§ï¼åæä¿æäºç¸ç¶æ¸éçåæ¸åæµ®é»éç®ãæ­¤å¤ï¼æåç¼ç¾ Finedeep å¨å¹³è¡¡æ·±åº¦åå»£åº¦æå¯ä»¥éå°æä½³çµæï¼ç¹å¥æ¯ééèª¿æ´å°å®¶å­å±¤çæ¸éåæ¯åå­å±¤çå°å®¶æ¸éãå¯¦è­çµæè­å¯¦ï¼Finedeep ææå°æ¸è¼äºç¨çæ¿æ´»ï¼ä¸¦ææå©ç¨äºå¯éæ¨¡åä¸­çè¡¨ç¤ºè½åã

##### **SEFL: Harnessing Large Language Model Agents to Improve Educational Feedback Systems**
2502.12927v1 by Mike Zhang, Amalie Pernille Dilling, LÃ©on Gondelman, Niels Erik Ruan Lyngdorf, Euan D. Lindsay, Johannes Bjerva

Providing high-quality feedback is crucial for student success but is
constrained by time, cost, and limited data availability. We introduce
Synthetic Educational Feedback Loops (SEFL), a novel framework designed to
deliver immediate, on-demand feedback at scale without relying on extensive,
real-world student data. In SEFL, two large language models (LLMs) operate in
teacher--student roles to simulate assignment completion and formative
feedback, generating abundant synthetic pairs of student work and corresponding
critiques. We then fine-tune smaller, more computationally efficient LLMs on
these synthetic pairs, enabling them to replicate key features of high-quality,
goal-oriented feedback. Unlike personalized tutoring approaches that offer
multi-turn, individualized instruction, SEFL specifically focuses on
replicating the teacher-->student feedback loop for diverse assignments.
Through both LLM-as-a-judge and human evaluations, we demonstrate that
SEFL-tuned models outperform their non-tuned counterparts in feedback quality,
clarity, and timeliness. These findings reveal SEFL's potential to transform
feedback processes for higher education and beyond, offering an ethical and
scalable alternative to conventional manual feedback cycles.

æè¦ï¼æä¾é«åè³ªçåé¥å°æ¼å­¸ççæåè³ééè¦ï¼ä½åå°æéãææ¬åè³æåå¾æéçéå¶ãæåå¼å¥äºåææè²åé¥è¿´å (SEFL)ï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨æä¾ç«å³ä¸ä¾éæ±çåé¥ï¼ä¸ç¡éä»°è³´å¤§éççå¯¦ä¸çå­¸çè³æãå¨ SEFL ä¸­ï¼å©åå¤§åèªè¨æ¨¡å (LLM) ä»¥å¸«çè§è²éä½ï¼æ¨¡æ¬ä½æ¥­å®æåå½¢ææ§åé¥ï¼ç¢çå¤§éçåæå­¸çä½æ¥­åå°æçè©è«ãç¶å¾æåéå°éäºåæéå°å¾®èª¿è¼å°ãè¨ç®æçè¼é«ç LLMï¼è®å®åè½å¤ è¤è£½é«åè³ªãç®æ¨å°ååé¥çä¸»è¦ç¹å¾µãèæä¾å¤ååãåå¥åæå­¸çåäººåè¼å°æ¹æ³ä¸åï¼SEFL ç¹å¥å°æ³¨æ¼è¤è£½é©ç¨æ¼åç¨®ä½æ¥­çæå¸«-->å­¸çåé¥è¿´åãéé LLM ä½çºè©å¯©åäººé¡è©ä¼°ï¼æåè­æäº SEFL å¾®èª¿æ¨¡åå¨åé¥åè³ªãæ¸æ°åº¦åæææ§æ¹é¢åªæ¼æªå¾®èª¿çæ¨¡åãéäºç¼ç¾æ­ç¤ºäº SEFL è½è®é«ç­æè²åå¶ä»é ååé¥æµç¨çæ½åï¼æä¾äºä¸åç¬¦åéå¾·ä¸å¯æ´åçæ¿ä»£æ¹æ¡ï¼åä»£å³çµ±çæååé¥é±æã

##### **Towards more Contextual Agents: An extractor-Generator Optimization Framework**
2502.12926v1 by Mourad Aouini, Jinan Loubani

Large Language Model (LLM)-based agents have demonstrated remarkable success
in solving complex tasks across a wide range of general-purpose applications.
However, their performance often degrades in context-specific scenarios, such
as specialized industries or research domains, where the absence of
domain-relevant knowledge leads to imprecise or suboptimal outcomes. To address
this challenge, our work introduces a systematic approach to enhance the
contextual adaptability of LLM-based agents by optimizing their underlying
prompts-critical components that govern agent behavior, roles, and
interactions. Manually crafting optimized prompts for context-specific tasks is
labor-intensive, error-prone, and lacks scalability. In this work, we introduce
an Extractor-Generator framework designed to automate the optimization of
contextual LLM-based agents. Our method operates through two key stages: (i)
feature extraction from a dataset of gold-standard input-output examples, and
(ii) prompt generation via a high-level optimization strategy that iteratively
identifies underperforming cases and applies self-improvement techniques. This
framework substantially improves prompt adaptability by enabling more precise
generalization across diverse inputs, particularly in context-specific tasks
where maintaining semantic consistency and minimizing error propagation are
critical for reliable performance. Although developed with single-stage
workflows in mind, the approach naturally extends to multi-stage workflows,
offering broad applicability across various agent-based systems. Empirical
evaluations demonstrate that our framework significantly enhances the
performance of prompt-optimized agents, providing a structured and efficient
approach to contextual LLM-based agents.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çºåºç¤çä»£çå·²å±ç¾åºéå¡çæåï¼
è½è§£æ±ºå»£æ³ä¸è¬ç¨éæç¨ç¨å¼çè¤éä»»åã
ç¶èï¼å®åçæè½éå¸¸æå¨ç¹å®æå¢ä¸­ä¸éï¼ä¾å¦å°éç¢æ¥­æç ç©¶é åï¼
å¶ä¸­ç¼ºä¹èé åç¸éç¥è­æå°è´ä¸ç²¾ç¢ºææ¬¡ä½³ççµæãçºäºè§£æ±º
éé ææ°ï¼æåçç ç©¶å¼é²äºä¸ç¨®ç³»çµ±åçæ¹æ³ä¾å¢å¼· LLM çºåºç¤çä»£çç
æå¢é©ææ§ï¼æ¹æ³æ¯æä½³åå®åçåºç¤æç¤ºï¼éäºæç¤ºæ¯æ±ºå®ä»£çè¡çºãè§è²å
äºåçéè¦çµæé¨åãæåè£½ä½æä½³åçæç¤ºä»¥æå°ç¹å®æå¢çä»»åæ¢è²»æåå®¹æåºé¯ï¼èä¸ç¼ºä¹å¯æ´åæ§ãå¨éé ç ç©¶ä¸­ï¼æåå¼é²
ä¸åèåç¢çå¨æ¶æ§ï¼æ¨å¨èªååæå¢ LLM çºåºç¤ä»£ççæä½³åãæåç
æ¹æ³ééå©åééµéæ®µéä½ï¼(i) å¾é»éæ¨æºè¼¸å¥è¼¸åºç¯ä¾çè³æéèåç¹å¾µï¼ä»¥å
(ii) ééé«éæä½³åç­ç¥ç¢çæç¤ºï¼æ­¤ç­ç¥æåè¦æ¾åºè¡¨ç¾ä¸ä½³çæ¡ä¾ä¸¦å¥ç¨èªææ¹åæè¡ãæ­¤
æ¶æ§å¤§å¹æ¹åäºæç¤ºé©ææ§ï¼è®å®è½éå°ä¸åçè¼¸å¥é²è¡æ´ç²¾ç¢ºçæ¦æ¬ï¼ç¹å¥æ¯å¨æå¢ç¹å®ä»»åä¸­ï¼å¨éäºä»»åä¸­ï¼ç¶­æèªæä¸è´æ§åå°é¯èª¤å³æ­éè³æä½å°æ¼å¯é çæè½è³ééè¦ãåç®¡æ¯éå°å®éæ®µå·¥ä½æµç¨éç¼ï¼ä½æ­¤æ¹æ³èªç¶è½å»¶ä¼¸è³å¤éæ®µå·¥ä½æµç¨ï¼å¨åç¨®åºæ¼ä»£ççç³»çµ±ä¸­æä¾å»£æ³çé©ç¨æ§ãå¯¦è­è©ä¼°é¡¯ç¤ºï¼æåçæ¶æ§å¤§å¹å¢å¼·äºæç¤ºæä½³åä»£ççæè½ï¼çºåºæ¼æå¢ç LLM ä»£çæä¾äºä¸åçµæ§åä¸ææççæ¹æ³ã

##### **Keep what you need : extracting efficient subnetworks from large audio representation models**
2502.12925v1 by David Genova, Philippe Esling, Tom Hurlin

Recently, research on audio foundation models has witnessed notable advances,
as illustrated by the ever improving results on complex downstream tasks.
Subsequently, those pretrained networks have quickly been used for various
audio applications. These improvements have however resulted in a considerable
increase both in size and complexity of these models. Along the environmental
concerns this issue raises, this prevents the deployment of such networks on
consumer-level devices, and precludes their use for real-time applications.
Moreover, this appears contradictory with the specificity of the tasks for
which these models are used, which are often simpler compared to extracting a
rich, multi-purpose representation from any type of audio data. In this paper,
we address this issue with a simple, yet effective method to extract
lightweight specialist subnetworks from large foundation models. Specifically,
we introduce learnable binary masks in-between the layers of a pretrained
representation model. When training the end-to-end model on a downstream task,
we add a sparsity-inducing loss to the overall objective, hence learning a
compact subnetwork specialized on a single task. Importantly, the weights of
the foundation model are kept frozen, resulting into low additional training
costs. Once trained, the masked computational units can then be removed from
the network, implying significant performance gains. We assess our method on
three widespread audio foundation models, each based on a different backbone
architecture, and illustrate its effectiveness on common audio representation
evaluation tasks, as well as its versatility on both speech, music, and general
audio. Code for reproducing the results and supporting webpage are available at
https://github.com/gnvIRCAM/Audio-representation-trimming

æè¦ï¼<paragraph>è¿æï¼é³é¢åºç¡æ¨¡åçç ç©¶åå¾äºæ¾èè¿å±ï¼
å¤æçä¸æ¸¸ä»»å¡ä¸ä¸æ­æåçç»æè¯æäºè¿ä¸ç¹ã
éåï¼è¿äºé¢è®­ç»ç½ç»å·²è¿éç¨äºåç§
é³é¢åºç¨ç¨åºãç¶èï¼è¿äºæ¹è¿å¯¼è´äºè¿äºæ¨¡åçå°ºå¯¸åå¤ææ§é½å¤§å¹
å¢å ãé¤äºç±æ­¤äº§ççç¯å¢é®é¢å¤ï¼è¿ä¹é»æ­¢äºæ­¤ç±»ç½ç»å¨
æ¶è´¹èçº§è®¾å¤ä¸çé¨ç½²ï¼å¹¶æé¤äºå®ä»¬å¨å®æ¶åºç¨ç¨åºä¸­çä½¿ç¨ã
æ­¤å¤ï¼è¿ä¼¼ä¹ä¸è¿äºæ¨¡åçä½¿ç¨ä»»å¡çç¹æ®æ§ç¸çç¾ï¼ä¸ä»ä»»ä½ç±»åçé³é¢æ°æ®ä¸­æåä¸°å¯çå¤ç¨éè¡¨ç¤ºç¸æ¯ï¼è¿äºä»»å¡éå¸¸æ´ç®åãå¨æ¬æä¸­ï¼
æä»¬éè¿ä¸ç§ç®åä½ææçæ¹æ³æ¥è§£å³æ­¤é®é¢ï¼ä»å¤§ååºç¡æ¨¡åä¸­æåè½»éçº§ä¸å®¶å­ç½ç»ãå·ä½æ¥è¯´ï¼
æä»¬å¨é¢è®­ç»è¡¨ç¤ºæ¨¡åçå±ä¹é´å¼å¥äºå¯å­¦ä¹ çäºè¿å¶æ©ç ãå½å¨æä¸ªä¸æ¸¸ä»»å¡ä¸è®­ç»ç«¯å°ç«¯æ¨¡åæ¶ï¼
æä»¬å¨æ»ä½ç®æ ä¸­æ·»å äºç¨çæ§è¯±å¯¼æå¤±ï¼ä»èå­¦ä¹ å°ä¸é¨ç¨äºåä¸ªä»»å¡çç´§ååå­ç½ç»ãéè¦çæ¯ï¼
åºç¡æ¨¡åçæéä¿æå»ç»ï¼ä»èå¯¼è´é¢å¤çè®­ç»ææ¬ä½ãä¸æ¦è®­ç»å®æï¼å°±å¯ä»¥ä»ç½ç»ä¸­ç§»é¤æ©ç çè®¡ç®ååï¼è¿æå³çæ§è½å°å¤§å¹æåãæä»¬å¯¹ä¸ä¸ªå¹¿æ³ä½¿ç¨çé³é¢åºç¡æ¨¡åè¯ä¼°äºæä»¬çæ¹æ³ï¼æ¯ä¸ªæ¨¡åé½åºäºä¸åçéª¨å¹²æ¶æï¼å¹¶è¯´æäºå¶å¨å¸¸è§é³é¢è¡¨ç¤ºè¯ä¼°ä»»å¡ä¸çæææ§ï¼ä»¥åå¶å¨è¯­é³ãé³ä¹åéç¨é³é¢ä¸çå¤åè½æ§ãç¨äºéç°ç»æçä»£ç åæ¯æç½é¡µå¯å¨
https://github.com/gnvIRCAM/Audio-representation-trimming è·å¾</paragraph>

##### **Conditioning LLMs to Generate Code-Switched Text: A Methodology Grounded in Naturally Occurring Data**
2502.12924v1 by Maite Heredia, Gorka Labaka, Jeremy Barnes, Aitor Soroa

Code-switching (CS) is still a critical challenge in Natural Language
Processing (NLP). Current Large Language Models (LLMs) struggle to interpret
and generate code-switched text, primarily due to the scarcity of large-scale
CS datasets for training. This paper presents a novel methodology to generate
CS data using LLMs, and test it on the English-Spanish language pair. We
propose back-translating natural CS sentences into monolingual English, and
using the resulting parallel corpus to fine-tune LLMs to turn monolingual
sentences into CS. Unlike previous approaches to CS generation, our methodology
uses natural CS data as a starting point, allowing models to learn its natural
distribution beyond grammatical patterns. We thoroughly analyse the models'
performance through a study on human preferences, a qualitative error analysis
and an evaluation with popular automatic metrics. Results show that our
methodology generates fluent code-switched text, expanding research
opportunities in CS communication, and that traditional metrics do not
correlate with human judgement when assessing the quality of the generated CS
data. We release our code and generated dataset under a CC-BY-NC-SA license.

æè¦ï¼ä»£ç¢¼è½æï¼CSï¼å¨èªç¶èªè¨èçï¼NLPï¼ä¸­ä»æ¯ä¸åå´å³»çææ°ãç®åçå·¨éèªè¨æ¨¡åï¼LLMï¼é£ä»¥è§£è®åçæä»£ç¢¼è½ææå­ï¼ä¸»è¦æ¯å çºç¼ºä¹ç¨æ¼è¨ç·´çå¤§è¦æ¨¡ CS è³æéãæ¬ææåºäºä¸ç¨®ä½¿ç¨ LLM çæ CS è³æçæ°æ¹æ³ï¼ä¸¦å¨è±èª-è¥¿ç­çèªèªè¨å°ä¸é²è¡æ¸¬è©¦ãæåå»ºè­°å°èªç¶ CS å¥å­ååç¿»è­¯æå®èªè±èªï¼ä¸¦ä½¿ç¨ç¢ççå¹³è¡èªæåº«å¾®èª¿ LLMï¼å°å®èªå¥å­è½æçº CSãèååç CS çææ¹æ³ä¸åï¼æåçæè¡ä½¿ç¨èªç¶ CS è³æä½çºèµ·é»ï¼è®æ¨¡åè½å¤ å­¸ç¿å¶è¶è¶èªæ³æ¨¡å¼çèªç¶åä½ãæåééç ç©¶äººé¡åå¥½ãå®æ§é¯èª¤åæåä½¿ç¨æµè¡çèªååææ¨é²è¡è©ä¼°ï¼å¾¹åºåææ¨¡åçæè½ãçµæé¡¯ç¤ºï¼æåçæè¡å¯ä»¥çææµå©çä»£ç¢¼è½ææå­ï¼æ´å± CS æºéçç ç©¶æ©æï¼èä¸å¨è©ä¼°çæç CS è³æåè³ªæï¼å³çµ±ææ¨èäººé¡å¤æ·ç¡éãæåå¨ CC-BY-NC-SA ææ¬ä¸éåºæåçç¨å¼ç¢¼åçæçè³æéã

##### **On-Device LLMs for Home Assistant: Dual Role in Intent Detection and Response Generation**
2502.12923v1 by Rune Birkmose, Nathan MÃ¸rkeberg Reece, Esben Hofstedt Norvin, Johannes Bjerva, Mike Zhang

This paper investigates whether Large Language Models (LLMs), fine-tuned on
synthetic but domain-representative data, can perform the twofold task of (i)
slot and intent detection and (ii) natural language response generation for a
smart home assistant, while running solely on resource-limited, CPU-only edge
hardware. We fine-tune LLMs to produce both JSON action calls and text
responses. Our experiments show that 16-bit and 8-bit quantized variants
preserve high accuracy on slot and intent detection and maintain strong
semantic coherence in generated text, while the 4-bit model, while retaining
generative fluency, suffers a noticeable drop in device-service classification
accuracy. Further evaluations on noisy human (non-synthetic) prompts and
out-of-domain intents confirm the models' generalization ability, obtaining
around 80--86\% accuracy. While the average inference time is 5--6 seconds per
query -- acceptable for one-shot commands but suboptimal for multi-turn
dialogue -- our results affirm that an on-device LLM can effectively unify
command interpretation and flexible response generation for home automation
without relying on specialized hardware.

æè¦ï¼æ¬ææ¢è¨å¾®èª¿æ¼åæä½å·é åä»£è¡¨æ§çè³æä¸çå¤§åèªè¨æ¨¡å (LLM)ï¼æ¯å¦è½å·è¡ (i) æ§½ä½åæååµæ¸¬ï¼ä»¥å (ii) èªç¶èªè¨åæç¢ççééä»»åï¼åæåå¨è³æºåéãå CPU çéç·£ç¡¬é«ä¸å·è¡ãæåå¾®èª¿ LLM ä»¥ç¢ç JSON åä½å¼å«åæå­åæãæåçå¯¦é©é¡¯ç¤ºï¼16 ä½åå 8 ä½åéåçè®é«å¨æ§½ä½åæååµæ¸¬ä¸ä¿æé«æºç¢ºåº¦ï¼ä¸¦å¨ç¢ççæå­ä¸­ç¶­æå¼·å¤§çèªæä¸è´æ§ï¼è 4 ä½åæ¨¡åéç¶ä¿æçææµæ¢åº¦ï¼ä½å¨è£ç½®æååé¡æºç¢ºåº¦ä¸å»ææé¡¯ä¸éãé²ä¸æ­¥å°æéè¨çäººé¡ (éåæ) æç¤ºåé åå¤æåçè©ä¼°ï¼è­å¯¦äºæ¨¡åçæ³åè½åï¼ç²å¾ç´ 80--86% çæºç¢ºåº¦ãéç¶å¹³åæ¨è«æéçºæ¯åæ¥è©¢ 5--6 ç§ï¼å°æ¼ä¸æ¬¡æ§å½ä»¤ä¾èªªæ¯å¯ä»¥æ¥åçï¼ä½å°æ¼å¤è¼ªå°è©±ä¾èªªä¸¦ä¸çæ³ï¼ä½æåççµæè­å¯¦ï¼è£ç½®ä¸ç LLM å¯ä»¥ææå°çµ±ä¸å½ä»¤è§£è­¯åå½æ§åæç¢çï¼ä»¥é²è¡å®¶åº­èªååï¼èç¡éä¾è³´å°ç¨ç¡¬é«ã

##### **Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison**
2502.12921v1 by George-Kirollos Saad, Scott Sanner

Query-driven recommendation with unknown items poses a challenge for users to
understand why certain items are appropriate for their needs. Query-driven
Contrastive Summarization (QCS) is a methodology designed to address this issue
by leveraging language-based item descriptions to clarify contrasts between
them. However, existing state-of-the-art contrastive summarization methods such
as STRUM-LLM fall short of this goal. To overcome these limitations, we
introduce Q-STRUM Debate, a novel extension of STRUM-LLM that employs
debate-style prompting to generate focused and contrastive summarizations of
item aspects relevant to a query. Leveraging modern large language models
(LLMs) as powerful tools for generating debates, Q-STRUM Debate provides
enhanced contrastive summaries. Experiments across three datasets demonstrate
that Q-STRUM Debate yields significant performance improvements over existing
methods on key contrastive summarization criteria, thus introducing a novel and
performant debate prompting methodology for QCS.

æè¦ï¼ä»¥æªç¥é ç®é²è¡çæ¥è©¢é©åæ¨è¦å°ä½¿ç¨èä¾èªªæ¯ä¸é ææ°ï¼ä»åé£ä»¥çè§£çºä½æäºé ç®é©åèªå·±çéæ±ãæ¥è©¢é©åå°æ¯æè¦ (QCS) æ¯ä¸ç¨®æ¹æ³ï¼æ¨å¨ééå©ç¨åºæ¼èªè¨çé ç®æè¿°ä¾éæ¸é ç®ä¹éçå°æ¯ï¼ä»¥è§£æ±ºéååé¡ãç¶èï¼ç¾æçæåé²å°æ¯æè¦æ¹æ³ï¼ä¾å¦ STRUM-LLMï¼ä¸¦æªéææ­¤ç®æ¨ãçºäºåæéäºéå¶ï¼æåå¼é² Q-STRUM Debateï¼ä¸ç¨® STRUM-LLM çæ°å»¶ä¼¸ï¼å®æ¡ç¨è¾¯è«å¼æç¤ºä¾ç¢çèæ¥è©¢ç¸éçé ç®é¢åçéé»å¼å°æ¯æè¦ãééå©ç¨ç¾ä»£å¤§åèªè¨æ¨¡å (LLM) ä½çºç¢çè¾¯è«çå¼·å¤§å·¥å·ï¼Q-STRUM Debate æä¾å¢å¼·çå°æ¯æè¦ãééä¸åè³æéçå¯¦é©è­æï¼Q-STRUM Debate å¨ééµçå°æ¯æè¦æ¨æºä¸ï¼æ¯ç¾ææ¹æ³æé¡¯èçæè½æ¹åï¼å æ­¤çº QCS å¼é²ä¸ç¨®æ°ç©ä¸é«æ§è½çè¾¯è«æç¤ºæ¹æ³ã

##### **GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning**
2502.12913v1 by Sifan Zhou, Shuo Wang, Zhihang Yuan, Mingjia Shi, Yuzhang Shang, Dawei Yang

Large Language Models (LLMs) fine-tuning technologies have achieved
remarkable results. However, traditional LLM fine-tuning approaches face
significant challenges: they require large Floating Point (FP) computation,
raising privacy concerns when handling sensitive data, and are impractical for
resource-constrained edge devices. While Parameter-Efficient Fine-Tuning (PEFT)
techniques reduce trainable parameters, their reliance on floating-point
arithmetic creates fundamental incompatibilities with edge hardware. In this
work, we introduce a novel framework for on-device LLM fine-tuning that
eliminates the need for floating-point operations in both inference and
training, named GSQ-Tuning. At its core is the Group-Shared Exponents Integer
format, which efficiently represents model parameters in integer format using
shared exponents among parameter groups. When combined with LoRA-like adapters,
this enables fully integer-based fine-tuning that is both memory and compute
efficient. We demonstrate that our approach achieves accuracy comparable to
FP16-based fine-tuning while significantly reducing memory usage (50%).
Moreover, compared to FP8, our method can reduce 5x power consumption and 11x
chip area with same performance, making large-scale model adaptation feasible
on edge devices.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å¾®è°ææ¯å·²åå¾æ¾èææãç¶èï¼ä¼ ç»ç LLM å¾®è°æ¹æ³é¢ä¸´çä¸¥å³»çææï¼å®ä»¬éè¦å¤§éçæµ®ç¹ (FP) è®¡ç®ï¼å¨å¤çæææ°æ®æ¶ä¼å¼åéç§é®é¢ï¼å¹¶ä¸å¯¹äºèµæºåéçè¾¹ç¼è®¾å¤èè¨ä¸åå®éãè½ç¶åæ°é«æå¾®è° (PEFT) ææ¯åå°äºå¯è®­ç»åæ°ï¼ä½å®ä»¬å¯¹æµ®ç¹è¿ç®çä¾èµä¸è¾¹ç¼ç¡¬ä»¶äº§çäºæ ¹æ¬ä¸çä¸å¼å®¹æ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªç¨äºè®¾å¤ä¸ LLM å¾®è°çæ°æ¡æ¶ï¼è¯¥æ¡æ¶æ¶é¤äºæ¨çåè®­ç»ä¸­å¯¹æµ®ç¹è¿ç®çéæ±ï¼åä¸º GSQ-Tuningãå¶æ ¸å¿æ¯ç»å±äº«ææ°æ´æ°æ ¼å¼ï¼è¯¥æ ¼å¼ä½¿ç¨åæ°ç»ä¹é´çå±äº«ææ°ä»¥æ´æ°æ ¼å¼ææå°è¡¨ç¤ºæ¨¡ååæ°ãå½ä¸ç±»ä¼¼ LoRA çééå¨ç¸ç»åæ¶ï¼è¿å®ç°äºå®å¨åºäºæ´æ°çå¾®è°ï¼æ¢èçåå­åèçè®¡ç®ãæä»¬è¯æäºæä»¬çæ¹æ³å®ç°äºä¸åºäº FP16 çå¾®è°ç¸å½çåç¡®æ§ï¼åæ¶æ¾èåå°äºåå­ä½¿ç¨é (50%)ãæ­¤å¤ï¼ä¸ FP8 ç¸æ¯ï¼æä»¬çæ¹æ³å¯ä»¥å¨ç¸åçæ§è½ä¸åå° 5 åçåèå 11 åçè¯çé¢ç§¯ï¼ä»èä½¿å¤§è§æ¨¡æ¨¡åéåºå¨è¾¹ç¼è®¾å¤ä¸æä¸ºå¯è½ã

##### **Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation**
2502.12911v1 by Zheng Yuan, Hao Chen, Zijin Hong, Qinggang Zhang, Feiran Huang, Xiao Huang

Generating SQLs from user queries is a long-standing challenge, where the
accuracy of initial schema linking significantly impacts subsequent SQL
generation performance. However, current schema linking models still struggle
with missing relevant schema elements or an excess of redundant ones. A crucial
reason for this is that commonly used metrics, recall and precision, fail to
capture relevant element missing and thus cannot reflect actual schema linking
performance. Motivated by this, we propose an enhanced schema linking metric by
introducing a restricted missing indicator. Accordingly, we introduce Knapsack
optimization-based Schema Linking Agent (KaSLA), a plug-in schema linking agent
designed to prevent the missing of relevant schema elements while minimizing
the inclusion of redundant ones. KaSLA employs a hierarchical linking strategy
that first identifies the optimal table linking and subsequently links columns
within the selected table to reduce linking candidate space. In each linking
process, it utilize a knapsack optimization approach to link potentially
relevant elements while accounting for a limited tolerance of potential
redundant ones.With this optimization, KaSLA-1.6B achieves superior schema
linking results compared to large-scale LLMs, including deepseek-v3 with
state-of-the-art (SOTA) schema linking method. Extensive experiments on Spider
and BIRD benchmarks verify that KaSLA can significantly improve the SQL
generation performance of SOTA text-to-SQL models by substituting their schema
linking processes.

æè¦ï¼å¾ä½¿ç¨èæ¥è©¢ä¸­ç¢ç SQL æ¯åé·æçææ°ï¼å¶ä¸­åå§æ¶æ§é£çµçæºç¢ºæ§æé¡¯èå½±é¿å¾çº SQL ç¢çæè½ãç¶èï¼ç®åçæ¶æ§é£çµæ¨¡åä»é£ä»¥èçéºæ¼ç¸éæ¶æ§åç´ æéå¤éè¤åç´ çåé¡ãé ææ­¤åé¡çä¸åééµåå æ¯ï¼å¸¸ç¨çææ¨å¬åçåç²¾ç¢ºåº¦ç¡æ³ææéºæ¼ç¸éåç´ ï¼å æ­¤ç¡æ³åæ å¯¦éçæ¶æ§é£çµæè½ãæéæ¼æ­¤ï¼æåæåºä¸åå¢å¼·çæ¶æ§é£çµææ¨ï¼ééå¼å¥åééºæ¼ææ¨ãå æ­¤ï¼æåä»ç´¹åºæ¼èåæä½³åçæ¶æ§é£çµä»£ç (KaSLA)ï¼éæ¯ä¸åå¤æå¼æ¶æ§é£çµä»£çï¼æ¨å¨é²æ­¢éºæ¼ç¸éæ¶æ§åç´ ï¼åæå°éè¤åç´ çç´å¥éè³æä½ãKaSLA æ¡ç¨åå±¤é£çµç­ç¥ï¼é¦åæ¾åºæä½³çè¡¨æ ¼é£çµï¼ç¶å¾é£çµæé¸è¡¨æ ¼ä¸­çæ¬ä½ï¼ä»¥æ¸å°é£çµåé¸ç©ºéãå¨æ¯åé£çµéç¨ä¸­ï¼å®å©ç¨èåæä½³åæ¹æ³é£çµæ½å¨ç¸éåç´ ï¼åæèéå°æ½å¨éè¤åç´ çå®¹å¿åº¦ãééæ­¤æä½³åï¼KaSLA-1.6B éå°åªæ¼å¤§è¦æ¨¡ LLM çæ¶æ§é£çµçµæï¼åæ¬æ¡ç¨æåé² (SOTA) æ¶æ§é£çµæ¹æ³ç deepseek-v3ãå¨ Spider å BIRD åºæºä¸çå»£æ³å¯¦é©é©è­ï¼KaSLA å¯ééåä»£å¶æ¶æ§é£çµæµç¨ï¼å¤§å¹æå SOTA æå­è½ SQL æ¨¡åç SQL ç¢çæè½ã

##### **Graph Neural Networks for Databases: A Survey**
2502.12908v1 by Ziming Li, Youhuan Li, Yuyu Luo, Guoliang Li, Chuxu Zhang

Graph neural networks (GNNs) are powerful deep learning models for
graph-structured data, demonstrating remarkable success across diverse domains.
Recently, the database (DB) community has increasingly recognized the
potentiality of GNNs, prompting a surge of researches focusing on improving
database systems through GNN-based approaches. However, despite notable
advances, There is a lack of a comprehensive review and understanding of how
GNNs could improve DB systems. Therefore, this survey aims to bridge this gap
by providing a structured and in-depth overview of GNNs for DB systems.
Specifically, we propose a new taxonomy that classifies existing methods into
two key categories: (1) Relational Databases, which includes tasks like
performance prediction, query optimization, and text-to-SQL, and (2) Graph
Databases, addressing challenges like efficient graph query processing and
graph similarity computation. We systematically review key methods in each
category, highlighting their contributions and practical implications. Finally,
we suggest promising avenues for integrating GNNs into Database systems.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) æ¯ç¨æ¼åå½¢çµæ§è³æçå¼·å¤§æ·±åº¦å­¸ç¿æ¨¡åï¼å¨åç¨®é åä¸­å±ç¾åºé¡¯èçæåãæè¿ï¼è³æåº« (DB) ç¤¾ç¾¤è¶ä¾è¶èªè­å° GNN çæ½åï¼ä¿ä½¿å¤§éç ç©¶å°æ³¨æ¼ééåºæ¼ GNN çæ¹æ³ä¾æ¹åè³æåº«ç³»çµ±ãç¶èï¼åç®¡æé¡¯èçé²å±ï¼ä½å°æ¼ GNN å¦ä½æ¹åè³æåº«ç³»çµ±ï¼ä»ç¶ç¼ºä¹å¨é¢çåé¡§åçè§£ãå æ­¤ï¼æ¬èª¿æ¥æ¨å¨ééæä¾ GNN å¨è³æåº«ç³»çµ±ä¸­ççµæ§åä¸æ·±å¥çæ¦è§ä¾å½è£éåå·®è·ãå·é«ä¾èªªï¼æåæåºäºä¸åæ°çåé¡æ³ï¼å°ç¾ææ¹æ³åé¡çºå©åä¸»è¦é¡å¥ï¼(1) éä¿è³æåº«ï¼å¶ä¸­åæ¬æè½é æ¸¬ãæ¥è©¢æä½³ååæå­è½ SQL ç­ä»»åï¼ä»¥å (2) åå½¢è³æåº«ï¼ç¨æ¼èçé«æåå½¢æ¥è©¢èçååå½¢ç¸ä¼¼åº¦è¨ç®ç­ææ°ãæåç³»çµ±æ§å°åé¡§äºæ¯åé¡å¥ä¸­çééµæ¹æ³ï¼éé»èªªæå¶è²¢ç»åå¯¦åææ¶µãæå¾ï¼æåå»ºè­°å° GNN æ´åå°è³æåº«ç³»çµ±ä¸­çæå¸æéå¾ã

##### **Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements**
2502.12904v1 by Shu Yang, Shenzhe Zhu, Zeyu Wu, Keyu Wang, Junchi Yao, Junchao Wu, Lijie Hu, Mengdi Li, Derek F. Wong, Di Wang

We introduce Fraud-R1, a benchmark designed to evaluate LLMs' ability to
defend against internet fraud and phishing in dynamic, real-world scenarios.
Fraud-R1 comprises 8,564 fraud cases sourced from phishing scams, fake job
postings, social media, and news, categorized into 5 major fraud types. Unlike
previous benchmarks, Fraud-R1 introduces a multi-round evaluation pipeline to
assess LLMs' resistance to fraud at different stages, including credibility
building, urgency creation, and emotional manipulation. Furthermore, we
evaluate 15 LLMs under two settings: 1. Helpful-Assistant, where the LLM
provides general decision-making assistance, and 2. Role-play, where the model
assumes a specific persona, widely used in real-world agent-based interactions.
Our evaluation reveals the significant challenges in defending against fraud
and phishing inducement, especially in role-play settings and fake job
postings. Additionally, we observe a substantial performance gap between
Chinese and English, underscoring the need for improved multilingual fraud
detection capabilities.

æè¦ï¼æåæ¨åº Fraud-R1ï¼ä¸ååºæºï¼æ¨å¨è©ä¼° LLM å¨åæãçå¯¦ä¸çå ´æ¯ä¸­é²ç¯ç¶²è·¯è©é¨åç¶²è·¯é£é­çè½åãFraud-R1 åå« 8,564 èµ·è©é¨æ¡ä¾ï¼ä¾æºåæ¬ç¶²è·¯é£é­è©é¨ãèåè·ç¼ºãç¤¾ç¾¤åªé«åæ°èï¼åé¡çº 5 ç¨®é¡åçä¸»è¦è©é¨ææ³ãèååçåºæºä¸åï¼Fraud-R1 å¼å¥å¤è¼ªè©ä¼°ç®¡éï¼ä»¥è©ä¼° LLM å¨ä¸åéæ®µå°è©é¨çæµæåï¼åæ¬å»ºç«ä¿¡è­½ãè£½é æ¥è¿«æåæææç¸±ãæ­¤å¤ï¼æåå¨å©ç¨®è¨­å®ä¸è©ä¼° 15 å LLMï¼1. åå©å©çï¼å¶ä¸­ LLM æä¾ä¸è¬æ±ºç­åå©ï¼ä»¥å 2. è§è²æ®æ¼ï¼å¶ä¸­æ¨¡ååè¨­ç¹å®è§è²ï¼å»£æ³ç¨æ¼ç¾å¯¦ä¸çä¸­åºæ¼ä»£ççäºåãæåçè©ä¼°æ­ç¤ºäºå¨é²ç¯è©é¨åç¶²è·¯é£é­èªå°æ¹é¢é¢è¨çéå¤§ææ°ï¼å°¤å¶æ¯å¨è§è²æ®æ¼è¨­å®åèåè·ç¼ºä¸­ãæ­¤å¤ï¼æåè§å¯å°ä¸­æåè±æä¹éæé¡¯èçæè½å·®è·ï¼éå¸é¡¯äºæ¹é²å¤èªè¨è©é¨åµæ¸¬åè½çå¿è¦æ§ã

##### **Soundwave: Less is More for Speech-Text Alignment in LLMs**
2502.12900v1 by Yuhao Zhang, Zhiheng Liu, Fan Bu, Ruiyu Zhang, Benyou Wang, Haizhou Li

Existing end-to-end speech large language models (LLMs) usually rely on
large-scale annotated data for training, while data-efficient training has not
been discussed in depth. We focus on two fundamental problems between speech
and text: the representation space gap and sequence length inconsistency. We
propose Soundwave, which utilizes an efficient training strategy and a novel
architecture to address these issues. Results show that Soundwave outperforms
the advanced Qwen2-Audio in speech translation and AIR-Bench speech tasks,
using only one-fiftieth of the training data. Further analysis shows that
Soundwave still retains its intelligence during conversation. The project is
available at https://github.com/FreedomIntelligence/Soundwave.

æè¦ï¼ç¾æçç«¯å°ç«¯èªé³å¤§åèªè¨æ¨¡å (LLM) éå¸¸ä¾è³´æ¼å¤§è¦æ¨¡è¨»éè³æé²è¡è¨ç·´ï¼èè³æææççè¨ç·´å°æªæ·±å¥æ¢è¨ãæåå°æ³¨æ¼èªé³åæå­ä¹éçå©ååºæ¬åé¡ï¼è¡¨ç¤ºç©ºéå·®è·ååºåé·åº¦ä¸ä¸è´ãæåæåº Soundwaveï¼å®å©ç¨é«æçè¨ç·´ç­ç¥åæ°ç©çæ¶æ§ä¾è§£æ±ºéäºåé¡ãçµæé¡¯ç¤ºï¼Soundwave å¨èªé³ç¿»è­¯å AIR-Bench èªé³ä»»åä¸­åªæ¼é²éç Qwen2-Audioï¼åä½¿ç¨äºååä¹ä¸çè¨ç·´è³æãé²ä¸æ­¥çåæé¡¯ç¤ºï¼Soundwave å¨å°è©±ä¸­ä»è½ä¿æå¶æºæ§ãå°æ¡å¯æ¼ https://github.com/FreedomIntelligence/Soundwave åå¾ã

##### **None of the Others: a General Technique to Distinguish Reasoning from Memorization in Multiple-Choice LLM Evaluation Benchmarks**
2502.12896v1 by Eva SÃ¡nchez Salido, Julio Gonzalo, Guillermo Marco

In LLM evaluations, reasoning is often distinguished from recall/memorization
by performing numerical variations to math-oriented questions. Here we
introduce a general variation method for multiple-choice questions that
completely dissociates the correct answer from previously seen tokens or
concepts, requiring LLMs to understand and reason (rather than memorizing) in
order to answer correctly. Using this method, we evaluate state-of-the-art
proprietary and open-source LLMs on two datasets available in English and
Spanish: the public MMLU benchmark and the private UNED-Access 2024 dataset.
Results show that all models experience remarkable accuracy drops under our
proposed variation, with an average loss of 57% on MMLU and 50% on UNED-Access
2024, ranging from 10% to 93% across models. Notably, the most accurate model
in our experimentation (OpenAI-o3-mini) is not the most robust
(DeepSeek-R1-70B), suggesting that the best models in standard evaluations may
not be the ones with better reasoning capabilities. Also, we see larger
accuracy drops in public (vs private) datasets and questions posed in their
original language (vs a manual translation), which are signs of contamination
and also point to a relevant role of recall/memorization in current LLMs'
answers.

æè¦ï¼å¨ LLM è©ä¼°ä¸­ï¼æ¨çéå¸¸ééå°æ¸å­¸å°ååé¡é²è¡æ¸å¼è®ç°ä¾åå¥æ¼åæ¶/è¨æ¶ãå¨æ­¤ï¼æåå¼å¥ä¸ç¨®éç¨è®ç°æ¹æ³ï¼é©ç¨æ¼å¤é¸é¡ï¼å®å°æ­£ç¢ºç­æ¡èååçå°çä»£å¹£ææ¦å¿µå®å¨ååéä¾ï¼è¦æ± LLM çè§£åæ¨çï¼èä¸æ¯è¨æ¶ï¼ï¼ä»¥ä¾¿æ­£ç¢ºåç­ãä½¿ç¨æ­¤æ¹æ³ï¼æåå¨è±èªåè¥¿ç­çèªä¸­è©ä¼°äºå©ç¨®æ¸æéä¸­çæåé²çå°æåéæº LLMï¼å¬å± MMLU åºæºåç§æ UNED-Access 2024 æ¸æéãçµæè¡¨æï¼å¨æåæåºçè®ç°ä¸ï¼æææ¨¡åçæºç¢ºåº¦é½åºç¾é¡¯èä¸éï¼å¨ MMLU ä¸å¹³åæå¤± 57%ï¼å¨ UNED-Access 2024 ä¸å¹³åæå¤± 50%ï¼å¨ä¸åæ¨¡åä¸­ç¯åå¾ 10% å° 93%ãå¼å¾æ³¨æçæ¯ï¼æåå¯¦é©ä¸­ææºç¢ºçæ¨¡åï¼OpenAI-o3-miniï¼ä¸¦ä¸æ¯æç©©å¥çæ¨¡åï¼DeepSeek-R1-70Bï¼ï¼éè¡¨ææ¨æºè©ä¼°ä¸­æå¥½çæ¨¡åå¯è½ä¸æ¯æ¨çè½åæå¼·çæ¨¡åãæ­¤å¤ï¼æåçå°å¬å±ï¼ç¸å°æ¼ç§æï¼æ¸æéåä»¥åå§èªè¨æåºçåé¡ï¼ç¸å°æ¼äººå·¥ç¿»è­¯ï¼çæºç¢ºåº¦ä¸éå¹åº¦æ´å¤§ï¼éæ¯æ±æçè·¡è±¡ï¼ä¹è¡¨æåæ¶/è¨æ¶å¨ç¶å LLM çç­æ¡ä¸­ç¼æ®èç¸éä½ç¨ã

##### **Multilingual European Language Models: Benchmarking Approaches and Challenges**
2502.12895v1 by Fabio Barth, Georg Rehm

The breakthrough of generative large language models (LLMs) that can solve
different tasks through chat interaction has led to a significant increase in
the use of general benchmarks to assess the quality or performance of these
models beyond individual applications. There is also a need for better methods
to evaluate and also to compare models due to the ever increasing number of new
models published. However, most of the established benchmarks revolve around
the English language. This paper analyses the benefits and limitations of
current evaluation datasets, focusing on multilingual European benchmarks. We
analyse seven multilingual benchmarks and identify four major challenges.
Furthermore, we discuss potential solutions to enhance translation quality and
mitigate cultural biases, including human-in-the-loop verification and
iterative translation ranking. Our analysis highlights the need for culturally
aware and rigorously validated benchmarks to assess the reasoning and
question-answering capabilities of multilingual LLMs accurately.

æè¦ï¼çæå¼å¤§åèªè¨æ¨¡å (LLM) ççªç ´ï¼å®è½ééèå¤©äºåè§£æ±ºä¸åä»»åï¼éå°è´ä½¿ç¨ä¸è¬åºæºä¾è©ä¼°éäºæ¨¡åå¨åå¥æç¨ç¨å¼ä»¥å¤çåè³ªææè½å¤§å¹å¢å ãç±æ¼å·²ç¼å¸çæ°æ¨¡åæ¸éä¸æ·å¢å ï¼å æ­¤ä¹æå¿è¦æ¡ç¨æ´å¥½çæ¹æ³ä¾è©ä¼°æ¨¡åä¸¦é²è¡æ¯è¼ãç¶èï¼å¤§å¤æ¸å·²å»ºç«çåºæºé½åç¹èè±èªãæ¬æåæäºç®åè©ä¼°è³æéçåªé»åéå¶ï¼éé»æ¾å¨å¤èªè¨æ­æ´²åºæºãæååæäºä¸åå¤èªè¨åºæºï¼ä¸¦æ¾åºååä¸»è¦çææ°ãæ­¤å¤ï¼æåè¨è«äºå¢å¼·ç¿»è­¯åè³ªåæ¸è¼æååè¦çæ½å¨è§£æ±ºæ¹æ¡ï¼åæ¬äººçºè¿´åé©è­ååè¦ç¿»è­¯æåãæåçåæçªé¡¯äºå°æåæè­åå´æ ¼é©è­çåºæºçéæ±ï¼ä»¥æºç¢ºè©ä¼°å¤èªè¨ LLM çæ¨çååç­è½åã

##### **H-CoT: Hijacking the Chain-of-Thought Safety Reasoning Mechanism to Jailbreak Large Reasoning Models, Including OpenAI o1/o3, DeepSeek-R1, and Gemini 2.0 Flash Thinking**
2502.12893v1 by Martin Kuo, Jianyi Zhang, Aolin Ding, Qinsi Wang, Louis DiValentin, Yujia Bao, Wei Wei, Da-Cheng Juan, Hai Li, Yiran Chen

Large Reasoning Models (LRMs) have recently extended their powerful reasoning
capabilities to safety checks-using chain-of-thought reasoning to decide
whether a request should be answered. While this new approach offers a
promising route for balancing model utility and safety, its robustness remains
underexplored. To address this gap, we introduce Malicious-Educator, a
benchmark that disguises extremely dangerous or malicious requests beneath
seemingly legitimate educational prompts. Our experiments reveal severe
security flaws in popular commercial-grade LRMs, including OpenAI o1/o3,
DeepSeek-R1, and Gemini 2.0 Flash Thinking. For instance, although OpenAI's o1
model initially maintains a high refusal rate of about 98%, subsequent model
updates significantly compromise its safety; and attackers can easily extract
criminal strategies from DeepSeek-R1 and Gemini 2.0 Flash Thinking without any
additional tricks. To further highlight these vulnerabilities, we propose
Hijacking Chain-of-Thought (H-CoT), a universal and transferable attack method
that leverages the model's own displayed intermediate reasoning to jailbreak
its safety reasoning mechanism. Under H-CoT, refusal rates sharply
decline-dropping from 98% to below 2%-and, in some instances, even transform
initially cautious tones into ones that are willing to provide harmful content.
We hope these findings underscore the urgent need for more robust safety
mechanisms to preserve the benefits of advanced reasoning capabilities without
compromising ethical standards.

æè¦ï¼å¤§åæ¨çæ¨¡å (LRM) æè¿å°å¶å¼·å¤§çæ¨çè½åæ´å±å°å®å¨æª¢æ¥ï¼ä½¿ç¨æç¶­éæ¨çä¾æ±ºå®æ¯å¦æåç­è«æ±ãéç¶éç¨®æ°æ¹æ³çºå¹³è¡¡æ¨¡åå¯¦ç¨æ§åå®å¨æ§æä¾äºä¸æ¢æå¸æçéå¾ï¼ä½å¶ç©©å¥æ§ä»æªå¾å°ååæ¢ç´¢ãçºäºè§£æ±ºéä¸å·®è·ï¼æåå¼å¥äº Malicious-Educatorï¼éæ¯ä¸ååºæºï¼å®å°æ¥µå¶å±éªææ¡æçè«æ±å½è£å¨çä¼¼åæ³çæè²æç¤ºä¹ä¸ãæåçå¯¦é©æ­ç¤ºäºæµè¡çåæ¥­ç´ LRM ä¸­å´éçå®å¨ç¼ºé·ï¼åæ¬ OpenAI o1/o3ãDeepSeek-R1 å Gemini 2.0 Flash Thinkingãä¾å¦ï¼åç®¡ OpenAI ç o1 æ¨¡åæåä¿æç´ 98% çé«æçµçï¼ä½å¾çºçæ¨¡åæ´æ°é¡¯èæå®³äºå¶å®å¨æ§ï¼æ»æèå¯ä»¥è¼é¬å°å¾ DeepSeek-R1 å Gemini 2.0 Flash Thinking ä¸­æåç¯ç½ªç­ç¥ï¼èç¡éä»»ä½é¡å¤çæå·§ãçºäºé²ä¸æ­¥å¼·èª¿éäºæ¼æ´ï¼æåæåºäºå«ææç¶­é (H-CoT)ï¼éæ¯ä¸ç¨®éç¨ä¸å¯è½ç§»çæ»ææ¹æ³ï¼å®å©ç¨æ¨¡åèªå·±é¡¯ç¤ºçä¸­éæ¨çä¾è¶çå¶å®å¨æ¨çæ©å¶ãå¨ H-CoT ä¸ï¼æçµçæ¥åä¸éï¼å¾ 98% éè³ 2% ä»¥ä¸ï¼å¨æäºææ³ä¸ï¼çè³å°æåè¬¹æçèªæ°£è½è®çºé¡ææä¾æå®³å§å®¹çèªæ°£ãæåå¸æéäºç¼ç¾å¼·èª¿äºå°æ´å¼·å¤§çå®å¨æ©å¶çè¿«åéè¦ï¼ä»¥ä¿çåé²æ¨çè½åçå¥½èï¼åæä¸æå®³éå¾·æ¨æºã

##### **Are Multilingual Language Models an Off-ramp for Under-resourced Languages? Will we arrive at Digital Language Equality in Europe in 2030?**
2502.12886v1 by Georg Rehm, Annika GrÃ¼tzner-Zahn, Fabio Barth

Large language models (LLMs) demonstrate unprecedented capabilities and
define the state of the art for almost all natural language processing (NLP)
tasks and also for essentially all Language Technology (LT) applications. LLMs
can only be trained for languages for which a sufficient amount of pre-training
data is available, effectively excluding many languages that are typically
characterised as under-resourced. However, there is both circumstantial and
empirical evidence that multilingual LLMs, which have been trained using data
sets that cover multiple languages (including under-resourced ones), do exhibit
strong capabilities for some of these under-resourced languages. Eventually,
this approach may have the potential to be a technological off-ramp for those
under-resourced languages for which "native" LLMs, and LLM-based technologies,
cannot be developed due to a lack of training data. This paper, which
concentrates on European languages, examines this idea, analyses the current
situation in terms of technology support and summarises related work. The
article concludes by focusing on the key open questions that need to be
answered for the approach to be put into practice in a systematic way.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¾åææªæçè½åï¼ä¸¦å®ç¾©äºå¹¾ä¹ææèªç¶èªè¨èç (NLP) ä»»åä»¥åææèªè¨æè¡ (LT) æç¨çææ°æè¡ãLLM åªè½éå°æè¶³å¤ é è¨ç·´è³æå¯ç¨çèªè¨é²è¡è¨ç·´ï¼å¯¦éä¸æé¤äºè¨±å¤éå¸¸è¢«æ­¸é¡çºè³æºä¸è¶³çèªè¨ãç¶èï¼æç°å¢åç¶é©è­æé¡¯ç¤ºï¼å¤èªè¨ LLM å·²ä½¿ç¨æ¶µèå¤ç¨®èªè¨ï¼åæ¬è³æºä¸è¶³çèªè¨ï¼çè³æéé²è¡è¨ç·´ï¼ç¢ºå¯¦å°å¶ä¸­ä¸äºè³æºä¸è¶³çèªè¨å±ç¾åºå¼·å¤§çè½åãæçµï¼éç¨®æ¹æ³å¯è½å·ææçºé£äºç±æ¼ç¼ºä¹è¨ç·´è³æèç¡æ³éç¼ãåçãLLM ååºæ¼ LLM çæè¡çè³æºä¸è¶³èªè¨çæè¡è·³æ¿çæ½åãæ¬æå°æ³¨æ¼æ­æ´²èªè¨ï¼æ¢è¨éåæ³æ³ï¼åææè¡æ¯æ´æ¹é¢çç¾çï¼ä¸¦ç¸½çµç¸éå·¥ä½ãæ¬ææå¾å°æ³¨æ¼å¿é åç­çä¸»è¦éæ¾æ§åé¡ï¼ä»¥ä¾¿ç³»çµ±æ§å°å¯¦è¸éç¨®æ¹æ³ã

##### **How desirable is alignment between LLMs and linguistically diverse human users?**
2502.12884v1 by Pia Knoeferle, Sebastian MÃ¶ller, Dorothea Kolossa, Veronika Solopova, Georg Rehm

We discuss how desirable it is that Large Language Models (LLMs) be able to
adapt or align their language behavior with users who may be diverse in their
language use. User diversity may come about among others due to i) age
differences; ii) gender characteristics, and/or iii) multilingual experience,
and associated differences in language processing and use. We consider
potential consequences for usability, communication, and LLM development.

æè¦ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) è½å¤ é©ææèª¿æ´å¶èªè¨è¡çºï¼ä»¥é©æèªè¨ä½¿ç¨å¯è½å¤æ¨£åçä½¿ç¨èï¼éæå¤éº¼å¯åãä½¿ç¨èå¤æ¨£æ§å¯è½åºæ¼ä»¥ä¸åå èç¢çï¼i) å¹´é½¡å·®ç°ï¼ii) æ§å¥ç¹å¾µï¼å/æ iii) å¤èªè¨ç¶é©ï¼ä»¥åèªè¨èçåä½¿ç¨ä¸çç¸éå·®ç°ãæåèæ®å°å¯ç¨æ§ãæºéå LLM éç¼çæ½å¨å¾æã

##### **Continuous Learning Conversational AI: A Personalized Agent Framework via A2C Reinforcement Learning**
2502.12876v1 by Nandakishor M, Anjali M

Creating personalized and adaptable conversational AI remains a key
challenge. This paper introduces a Continuous Learning Conversational AI (CLCA)
approach, implemented using A2C reinforcement learning, to move beyond static
Large Language Models (LLMs). We use simulated sales dialogues, generated by
LLMs, to train an A2C agent. This agent learns to optimize conversation
strategies for personalization, focusing on engagement and delivering value.
Our system architecture integrates reinforcement learning with LLMs for both
data creation and response selection. This method offers a practical way to
build personalized AI companions that evolve through continuous learning,
advancing beyond traditional static LLM techniques.

æè¦ï¼å»ºç«åäººåä¸é©ææ§å¼·çå°è©±å¼ AI ä»ç¶æ¯ä¸é ééµææ°ãæ¬æä»ç´¹äºä¸ç¨®æçºå­¸ç¿å°è©±å¼ AI (CLCA) æ¹æ³ï¼éé A2C å¼·åå­¸ç¿å¯¦ä½ï¼ä»¥è¶è¶éæå¤§åèªè¨æ¨¡å (LLM)ãæåä½¿ç¨ LLM çæçæ¨¡æ¬é·å®å°è©±ä¾è¨ç·´ A2C ä»£çãæ­¤ä»£çæå­¸ç¿æä½³åå°è©±ç­ç¥ä»¥å¯¦ç¾åäººåï¼ä¸¦å°æ³¨æ¼åèåæä¾å¹å¼ãæåçç³»çµ±æ¶æ§å°å¼·åå­¸ç¿è LLM æ´åï¼ç¨æ¼è³æå»ºç«ååæé¸åãæ­¤æ¹æ³æä¾äºä¸ç¨®å¯¦ç¨çæ¹å¼ä¾å»ºç«åäººå AI ä¼´ä¾¶ï¼éäºä¼´ä¾¶æééæçºå­¸ç¿èæ¼é²ï¼è¶è¶å³çµ±çéæ LLM æè¡ã

##### **PAFT: Prompt-Agnostic Fine-Tuning**
2502.12859v1 by Chenxing Wei, Yao Shu, Mingwen Ou, Ying Tiffany He, Fei Richard Yu

While Large Language Models (LLMs) adapt well to downstream tasks after
fine-tuning, this adaptability often compromises prompt robustness, as even
minor prompt variations can significantly degrade performance. To address this,
we propose Prompt-Agnostic Fine-Tuning(PAFT), a simple yet effective approach
that dynamically adjusts prompts during fine-tuning. This encourages the model
to learn underlying task principles rather than overfitting to specific prompt
formulations. PAFT operates in two stages: First, a diverse set of meaningful,
synthetic candidate prompts is constructed. Second, during fine-tuning, prompts
are randomly sampled from this set to create dynamic training inputs. Extensive
experiments across diverse datasets and LLMs demonstrate that models trained
with PAFT exhibit strong robustness and generalization across a wide range of
prompts, including unseen ones. This enhanced robustness improves both model
performance and inference speed while maintaining training efficiency. Ablation
studies further confirm the effectiveness of PAFT.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨å¾®èª¿å¾è½å¾å¥½å°é©æä¸æ¸¸ä»»åï¼ä½éç¨®é©ææ§éå¸¸ææå®³æç¤ºçç©©å¥æ§ï¼å çºå³ä½¿å¾®å°çæç¤ºè®ç°ä¹æå¤§å¹éä½æè½ãçºäºè§£æ±ºéååé¡ï¼æåæåºæç¤ºä¸å¯ç¥å¾®èª¿ (PAFT)ï¼éæ¯ä¸ç¨®ç°¡å®å»ææçæ¹æ³ï¼å¯ä»¥å¨å¾®èª¿æéåæèª¿æ´æç¤ºãéé¼åµæ¨¡åå­¸ç¿åºå±¤ä»»åååï¼èä¸æ¯éåº¦æ¬åç¹å®çæç¤ºè¡¨è¿°ãPAFT åçºå©åéæ®µéä½ï¼é¦åï¼æ§å»ºä¸çµå¤æ¨£åãææç¾©çåæåé¸æç¤ºãå¶æ¬¡ï¼å¨å¾®èª¿æéï¼å¾æ­¤éåä¸­é¨æ©æ½åæç¤ºä»¥å»ºç«åæè¨ç·´è¼¸å¥ãéå°åç¨®è³æéå LLM é²è¡çå»£æ³å¯¦é©è¡¨æï¼ä½¿ç¨ PAFT è¨ç·´çæ¨¡åå¨åç¨®æç¤ºä¸­è¡¨ç¾åºå¼·å¤§çç©©å¥æ§åæ¦æ¬æ§ï¼åæ¬æªè¦éçæç¤ºãéç¨®å¢å¼·çç©©å¥æ§åææ¹åäºæ¨¡åæè½åæ¨çéåº¦ï¼åæç¶­æè¨ç·´æçãæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äº PAFT çæææ§ã

##### **Rejected Dialects: Biases Against African American Language in Reward Models**
2502.12858v1 by Joel Mire, Zubin Trivadi Aysola, Daniel Chechelnitsky, Nicholas Deas, Chrysoula Zerva, Maarten Sap

Preference alignment via reward models helps build safe, helpful, and
reliable large language models (LLMs). However, subjectivity in preference
judgments and the lack of representative sampling in preference data collection
can introduce new biases, hindering reward models' fairness and equity. In this
work, we introduce a framework for evaluating dialect biases in reward models
and conduct a case study on biases against African American Language (AAL)
through several experiments comparing reward model preferences and behavior on
paired White Mainstream English (WME) and both machine-translated and
human-written AAL corpora. We show that reward models are less aligned with
human preferences when processing AAL texts vs. WME ones (-4\% accuracy on
average), frequently disprefer AAL-aligned texts vs. WME-aligned ones, and
steer conversations toward WME, even when prompted with AAL texts. Our findings
provide a targeted analysis of anti-AAL biases at a relatively understudied
stage in LLM development, highlighting representational harms and ethical
questions about the desired behavior of LLMs concerning AAL.

æè¦ï¼ééçåµæ¨¡åé²è¡åå¥½æ¯å°æå©æ¼å»ºç«å®å¨ãæç¨çå¯é å¤§åèªè¨æ¨¡å (LLM)ãç¶èï¼åå¥½å¤æ·çä¸»è§æ§ï¼ä»¥ååå¥½è³ææ¶éä¸­ç¼ºä¹ä»£è¡¨æ§æ½æ¨£ï¼å¯è½æå¼é²æ°çåèª¤ï¼é»ç¤çåµæ¨¡åçå¬å¹³æ§åå¬æ­£æ§ãå¨éé å·¥ä½ä¸­ï¼æåå¼é²ä¸åç¨æ¼è©ä¼°çåµæ¨¡åä¸­æ¹è¨åèª¤çæ¶æ§ï¼ä¸¦ééæ¸åå¯¦é©é²è¡æ¡ä¾ç ç©¶ï¼æ¢è¨éå°éè£ç¾åäººèªè¨ (AAL) çåèª¤ï¼éäºå¯¦é©æ¯è¼äºçåµæ¨¡ååå¥½åè¡çºï¼æ¯è¼æå°çç½äººä¸»æµè±èª (WME) èæ©å¨ç¿»è­¯åäººé¡æ°å¯«ç AAL èªæåº«ãæåé¡¯ç¤ºï¼èèç WME æå­ç¸æ¯ï¼çåµæ¨¡åå¨èç AAL æå­æèäººé¡åå¥½è¼ä¸ä¸è´ï¼å¹³åæºç¢ºåº¦éä½ 4%ï¼ï¼ç¶å¸¸ä¸åå¥½è AAL ä¸è´çæå­ï¼èåå¥½è WME ä¸è´çæå­ï¼ä¸¦å°å°è©±å°å WMEï¼å³ä½¿æç¤ºçæ¯ AAL æå­ãæåçç¼ç¾éå° LLM éç¼ä¸­ç¸å°æªåéè¦çéæ®µï¼æä¾éå°å AAL åèª¤çç®æ¨åæï¼å¼·èª¿èè¡¨å¾µç¸éçå±å®³åéæ¼ LLM å° AAL çææè¡çºçå«çåé¡ã

##### **Integrating Arithmetic Learning Improves Mathematical Reasoning in Smaller Models**
2502.12855v1 by Neeraj Gangwar, Suma P Bhat, Nickvash Kani

While large models pre-trained on high-quality data exhibit excellent
performance across various reasoning tasks, including mathematical reasoning
(e.g. GSM8k, MultiArith), specializing smaller models to excel at mathematical
reasoning remains a challenging problem. Common approaches to address this
challenge include knowledge distillation, where smaller student models learn
from large pre-trained teacher models, and data augmentation, such as
rephrasing questions. Despite these efforts, smaller models struggle with
arithmetic computations, leading to errors in mathematical reasoning. In this
work, we focus on leveraging a programmatically generated arithmetic dataset to
enhance the reasoning capabilities of smaller models. We investigate two key
approaches to incorporate this dataset -- (1) intermediate fine-tuning, where a
model is fine-tuned on the arithmetic dataset before being trained on a
reasoning dataset, and (2) integrating the arithmetic dataset into the
instruction-tuning mixture, allowing the model to learn arithmetic skills
alongside general instruction-following abilities. Our experiments on multiple
reasoning benchmarks demonstrate that incorporating an arithmetic dataset,
whether through targeted fine-tuning or within the instruction-tuning mixture,
enhances the models' arithmetic capabilities, which in turn improves their
mathematical reasoning performance.

æè¦ï¼å¤§åæ¨¡åç»è¿éå¯¹é«è´¨éæ°æ®çé¢è®­ç»ï¼å¨åç§æ¨çä»»å¡ä¸­è¡¨ç°åºè²ï¼åæ¬æ°å­¦æ¨çï¼ä¾å¦ GSM8kãMultiArithï¼ï¼ä½ä¸é¨åå°åæ¨¡åä»¥æé¿æ°å­¦æ¨çä»ç¶æ¯ä¸ä¸ªå·ææææ§çé®é¢ãè§£å³è¿ä¸ææçå¸¸è§æ¹æ³åæ¬ç¥è¯è¸é¦ï¼å¶ä¸­è¾å°çå­¦çæ¨¡åä»ç»è¿é¢è®­ç»çå¤§åæå¸æ¨¡åä¸­å­¦ä¹ ï¼ä»¥åæ°æ®å¢å¼ºï¼ä¾å¦éæ°è¡¨è¿°é®é¢ãå°½ç®¡ååºäºè¿äºåªåï¼è¾å°çæ¨¡åå¨ç®æ¯è®¡ç®ä¸­ä»ç¶å­å¨å°é¾ï¼ä»èå¯¼è´æ°å­¦æ¨çéè¯¯ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬ä¸æ³¨äºå©ç¨ç¨åºåçæçç®æ¯æ°æ®éæ¥å¢å¼ºè¾å°æ¨¡åçæ¨çè½åãæä»¬ç ç©¶äºä¸¤ç§å³é®æ¹æ³æ¥åå¹¶æ­¤æ°æ®éââï¼1ï¼ä¸­é´å¾®è°ï¼å¶ä¸­æ¨¡åå¨ç®æ¯æ°æ®éä¸è¿è¡å¾®è°ï¼ç¶åå¨æ¨çæ°æ®éä¸è¿è¡è®­ç»ï¼ä»¥åï¼2ï¼å°ç®æ¯æ°æ®ééæå°æä»¤å¾®è°æ··åä¸­ï¼åè®¸æ¨¡åå­¦ä¹ ç®æ¯æè½ä»¥åä¸è¬çæä»¤éµå¾ªè½åãæä»¬å¨å¤ä¸ªæ¨çåºåä¸çå®éªè¡¨æï¼éè¿æéå¯¹æ§çå¾®è°æå¨æä»¤å¾®è°æ··åä¸­åå¹¶ç®æ¯æ°æ®éï¼å¢å¼ºäºæ¨¡åçç®æ¯è½åï¼è¿èæé«äºå®ä»¬çæ°å­¦æ¨çæ§è½ã

##### **S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning**
2502.12853v1 by Ruotian Ma, Peisong Wang, Cheng Liu, Xingyan Liu, Jiaqi Chen, Bang Zhang, Xin Zhou, Nan Du, Jia Li

Recent studies have demonstrated the effectiveness of LLM test-time scaling.
However, existing approaches to incentivize LLMs' deep thinking abilities
generally require large-scale data or significant training efforts. Meanwhile,
it remains unclear how to improve the thinking abilities of less powerful base
models. In this work, we introduce S$^2$R, an efficient framework that enhances
LLM reasoning by teaching models to self-verify and self-correct during
inference. Specifically, we first initialize LLMs with iterative
self-verification and self-correction behaviors through supervised fine-tuning
on carefully curated data. The self-verification and self-correction skills are
then further strengthened by both outcome-level and process-level reinforcement
learning, with minimized resource requirements, enabling the model to
adaptively refine its reasoning process during inference. Our results
demonstrate that, with only 3.1k self-verifying and self-correcting behavior
initialization samples, Qwen2.5-math-7B achieves an accuracy improvement from
51.0\% to 81.6\%, outperforming models trained on an equivalent amount of
long-CoT distilled data. Extensive experiments and analysis based on three base
models across both in-domain and out-of-domain benchmarks validate the
effectiveness of S$^2$R. Our code and data are available at
https://github.com/NineAbyss/S2R.

æè¦ï¼<paragraph>æè¿çç ç©¶è¡¨æäº LLM æµè¯æ¶é´æ©å±çæææ§ã
ç¶èï¼ç°ææ¿å± LLM æ·±åº¦æèè½åçæ¹æ³
éå¸¸éè¦å¤§è§æ¨¡æ°æ®æå¤§éçè®­ç»å·¥ä½ãåæ¶ï¼
å¦ä½æé«è¾å¼±åºç¡æ¨¡åçæèè½åä»ç¶ä¸æ¸æ¥ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äº S$^2$Rï¼ä¸ä¸ªéè¿æå¯¼æ¨¡åå¨
æ¨çè¿ç¨ä¸­è¿è¡èªæéªè¯åèªæçº æ­£æ¥å¢å¼º LLM æ¨ççæææ¡æ¶ãå·ä½æ¥è¯´ï¼æä»¬é¦åéè¿çç£å¾®è°å¯¹ç²¾å¿æ´ççæ°æ®æ¥åå§åå·æè¿­ä»£èªæéªè¯åèªæçº æ­£è¡ä¸ºç LLMãç¶åéè¿ç»æçº§å«åè¿ç¨çº§å«çå¼ºå
å­¦ä¹ è¿ä¸æ­¥å å¼ºèªæéªè¯åèªæçº æ­£æè½ï¼åæ¶æå¤§ç¨åº¦å°åå°èµæºéæ±ï¼ä½¿æ¨¡åè½å¤
å¨æ¨çè¿ç¨ä¸­èªéåºå°ä¼åå¶æ¨çè¿ç¨ãæä»¬çç»æ
è¡¨æï¼ä»ä½¿ç¨ 3.1k ä¸ªèªæéªè¯åèªæçº æ­£è¡ä¸º
åå§åæ ·æ¬ï¼Qwen2.5-math-7B çåç¡®çä»
51.0% æé«å° 81.6%ï¼ä¼äºå¨ç­éé¿ CoT è¸é¦æ°æ®ä¸è®­ç»çæ¨¡åãåºäºä¸ä¸ªåºç¡æ¨¡åå¨ååååå¤åºåä¸çå¹¿æ³å®éªååæéªè¯äº
S$^2$R çæææ§ãæä»¬çä»£ç åæ°æ®å¯ä»¥å¨
https://github.com/NineAbyss/S2R è·å¾ã</paragraph>

##### **MVL-SIB: A Massively Multilingual Vision-Language Benchmark for Cross-Modal Topical Matching**
2502.12852v1 by Fabian David Schmidt, Florian Schneider, Chris Biemann, Goran GlavaÅ¡

Existing multilingual vision-language (VL) benchmarks often only cover a
handful of languages. Consequently, evaluations of large vision-language models
(LVLMs) predominantly target high-resource languages, underscoring the need for
evaluation data for low-resource languages. To address this limitation, we
introduce MVL-SIB, a massively multilingual vision-language benchmark that
evaluates both cross-modal and text-only topical matching across 205 languages
-- over 100 more than the most multilingual existing VL benchmarks encompass.
We then benchmark a range of of open-weight LVLMs together with GPT-4o(-mini)
on MVL-SIB. Our results reveal that LVLMs struggle in cross-modal topic
matching in lower-resource languages, performing no better than chance on
languages like N'Koo. Our analysis further reveals that VL support in LVLMs
declines disproportionately relative to textual support for lower-resource
languages, as evidenced by comparison of cross-modal and text-only topical
matching performance. We further observe that open-weight LVLMs do not benefit
from representing a topic with more than one image, suggesting that these
models are not yet fully effective at handling multi-image tasks. By
correlating performance on MVL-SIB with other multilingual VL benchmarks, we
highlight that MVL-SIB serves as a comprehensive probe of multilingual VL
understanding in LVLMs.

æè¦ï¼ç¾æçå¤èªè¨è¦è¦ºèªè¨ (VL) åºæºéå¸¸åªæ¶µèå°æ¸èªè¨ãå æ­¤ï¼å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) çè©ä¼°ä¸»è¦éå°è³æºè±å¯çèªè¨ï¼å¼·èª¿äºå°è³æºå±ä¹èªè¨çè©ä¼°è³æçéæ±ãçºäºè§£æ±ºæ­¤éå¶ï¼æåå¼å¥äº MVL-SIBï¼ä¸åå¤§è¦æ¨¡çå¤èªè¨è¦è¦ºèªè¨åºæºï¼å®è©ä¼°äº 205 ç¨®èªè¨çè·¨æ¨¡æåç´æå­ä¸»é¡å¹éï¼æ¯ç¾æçå¤èªè¨ VL åºæºæ¶µèçèªè¨å¤åº 100 å¤ç¨®ãç¶å¾ï¼æåå¨ MVL-SIB ä¸å°ä¸ç³»åéæ¾æ¬éç LVLMs è GPT-4o(-mini) é²è¡äºåºæºæ¸¬è©¦ãæåççµæè¡¨æï¼LVLMs å¨è³æºè¼å°çèªè¨ä¸­é£ä»¥é²è¡è·¨æ¨¡æä¸»é¡å¹éï¼å¨ N'Koo ç­èªè¨ä¸çè¡¨ç¾ä¸æ¯é¨æ©å¥½ãæåçåæé²ä¸æ­¥è¡¨æï¼LVLMs ä¸­ç VL æ¯æ´ç¸å°æ¼è³æºè¼å°çèªè¨çæå­æ¯æ´ä¸éå¾ä¸ææ¯ä¾ï¼éå¾è·¨æ¨¡æåç´æå­ä¸»é¡å¹éæè½çæ¯è¼ä¸­å¯ä»¥çåºãæåé²ä¸æ­¥è§å¯å°ï¼éæ¾æ¬éç LVLMs ç¡æ³å¾ç¨å¤æ¼ä¸å¼µå½±åä¾è¡¨ç¤ºä¸»é¡ä¸­åçï¼éè¡¨æéäºæ¨¡åå¨èçå¤å½±åä»»åæ¹é¢å°æªå®å¨ææãééå° MVL-SIB ä¸çæè½èå¶ä»å¤èªè¨ VL åºæºç¸éè¯ï¼æåå¼·èª¿ MVL-SIB å¯ä½çº LVLMs ä¸­å¤èªè¨ VL çè§£çç¶åæ¢æ¸¬ã

##### **MeMo: Towards Language Models with Associative Memory Mechanisms**
2502.12851v1 by Fabio Massimo Zanzotto, Elena Sofia Ruzzetti, Giancarlo A. Xompero, Leonardo Ranaldi, Davide Venditti, Federico Ranaldi, Cristina Giannone, Andrea Favalli, Raniero Romagnoli

Memorization is a fundamental ability of Transformer-based Large Language
Models, achieved through learning. In this paper, we propose a paradigm shift
by designing an architecture to memorize text directly, bearing in mind the
principle that memorization precedes learning. We introduce MeMo, a novel
architecture for language modeling that explicitly memorizes sequences of
tokens in layered associative memories. By design, MeMo offers transparency and
the possibility of model editing, including forgetting texts. We experimented
with the MeMo architecture, showing the memorization power of the one-layer and
the multi-layer configurations.

æè¦ï¼è¨æ¶æ¯ Transformer å¤§åèªè¨æ¨¡åçåºæ¬è½åï¼å¯ééå­¸ç¿éæãå¨æ¬æä¸­ï¼æåæåºä¸åå¸ç¯è½ç§»ï¼ééè¨­è¨ä¸åæ¶æ§ä¾ç´æ¥è¨æ¶æå­ï¼ä¸¦ç¢è¨è¨æ¶åæ¼å­¸ç¿çååãæåå°å¥ MeMoï¼ä¸åæ°ç©çèªè¨å»ºæ¨¡æ¶æ§ï¼å¯æç¢ºå°è¨æ¶åå±¤éè¯å¼è¨æ¶ä¸­çä»£å¹£åºåãééè¨­è¨ï¼MeMo æä¾éæåº¦åæ¨¡åç·¨è¼¯çå¯è½æ§ï¼åæ¬éºå¿æå­ãæåå¯¦é©äº MeMo æ¶æ§ï¼å±ç¤ºäºå®å±¤åå¤å±¤çµæçè¨æ¶åã

##### **Towards Adaptive Feedback with AI: Comparing the Feedback Quality of LLMs and Teachers on Experimentation Protocols**
2502.12842v1 by Kathrin SeÃler, Arne Bewersdorff, Claudia Nerdel, Enkelejda Kasneci

Effective feedback is essential for fostering students' success in scientific
inquiry. With advancements in artificial intelligence, large language models
(LLMs) offer new possibilities for delivering instant and adaptive feedback.
However, this feedback often lacks the pedagogical validation provided by
real-world practitioners. To address this limitation, our study evaluates and
compares the feedback quality of LLM agents with that of human teachers and
science education experts on student-written experimentation protocols. Four
blinded raters, all professionals in scientific inquiry and science education,
evaluated the feedback texts generated by 1) the LLM agent, 2) the teachers and
3) the science education experts using a five-point Likert scale based on six
criteria of effective feedback: Feed Up, Feed Back, Feed Forward, Constructive
Tone, Linguistic Clarity, and Technical Terminology. Our results indicate that
LLM-generated feedback shows no significant difference to that of teachers and
experts in overall quality. However, the LLM agent's performance lags in the
Feed Back dimension, which involves identifying and explaining errors within
the student's work context. Qualitative analysis highlighted the LLM agent's
limitations in contextual understanding and in the clear communication of
specific errors. Our findings suggest that combining LLM-generated feedback
with human expertise can enhance educational practices by leveraging the
efficiency of LLMs and the nuanced understanding of educators.

æè¦ï¼ææçåé¥å°æ¼å¹é¤å­¸çå¨ç§å­¸æ¢ç©¶ä¸­çæåè³ééè¦ãé¨èäººå·¥æºæ§çé²æ­¥ï¼å¤§åèªè¨æ¨¡å (LLM) çºæä¾å³æä¸é©ææ§çåé¥æä¾äºæ°çå¯è½æ§ãç¶èï¼æ­¤åé¥éå¸¸ç¼ºä¹å¯¦éå¾æ¥­èæä¾çæå­¸é©è­ãçºäºè§£æ±ºæ­¤éå¶ï¼æåçç ç©¶è©ä¼°ä¸¦æ¯è¼äº LLM ä»£çèäººé¡æå¸«åç§å­¸æè²å°å®¶å¨å­¸çæ°å¯«çå¯¦é©åå®ä¸çåé¥åè³ªãåä½ç²è©èï¼ççºç§å­¸æ¢ç©¶åç§å­¸æè²å°æ¥­äººå£«ï¼ä½¿ç¨åºæ¼å­åææåé¥æºåçäºé»æåç¹éè¡¨è©ä¼°ç± 1) LLM ä»£çã2) æå¸«å 3) ç§å­¸æè²å°å®¶ç¢ççåé¥æå­ï¼é¼åµãåé¥ãåé¥ãå»ºè¨­æ§èªæ°£ãèªè¨æ¸æ°åº¦åæè¡è¡èªãæåççµæè¡¨æï¼LLM ç¢ççåé¥å¨æ´é«åè³ªä¸èæå¸«åå°å®¶ç¢ççåé¥æ²æé¡¯èå·®ç°ãç¶èï¼LLM ä»£ççè¡¨ç¾è½å¾æ¼åé¥é¢åï¼éæ¶åå¨å­¸ççä½æ¥­èæ¯ä¸­è­å¥åè§£éé¯èª¤ãå®æ§åæçªé¡¯äº LLM ä»£çå¨æå¢çè§£åæç¢ºå³éç¹å®é¯èª¤æ¹é¢çéå¶ãæåçç ç©¶çµæè¡¨æï¼å° LLM ç¢ççåé¥èäººé¡å°æ¥­ç¥è­ç¸çµåï¼å¯ä»¥ééå©ç¨ LLM çæçåæè²èçç´°ç·»çè§£ä¾æåæè²å¯¦åã

##### **Towards Equitable AI: Detecting Bias in Using Large Language Models for Marketing**
2502.12838v1 by Berk Yilmaz, Huthaifa I. Ashqar

The recent advances in large language models (LLMs) have revolutionized
industries such as finance, marketing, and customer service by enabling
sophisticated natural language processing tasks. However, the broad adoption of
LLMs brings significant challenges, particularly in the form of social biases
that can be embedded within their outputs. Biases related to gender, age, and
other sensitive attributes can lead to unfair treatment, raising ethical
concerns and risking both company reputation and customer trust. This study
examined bias in finance-related marketing slogans generated by LLMs (i.e.,
ChatGPT) by prompting tailored ads targeting five demographic categories:
gender, marital status, age, income level, and education level. A total of
1,700 slogans were generated for 17 unique demographic groups, and key terms
were categorized into four thematic groups: empowerment, financial, benefits
and features, and personalization. Bias was systematically assessed using
relative bias calculations and statistically tested with the Kolmogorov-Smirnov
(KS) test against general slogans generated for any individual. Results
revealed that marketing slogans are not neutral; rather, they emphasize
different themes based on demographic factors. Women, younger individuals,
low-income earners, and those with lower education levels receive more distinct
messaging compared to older, higher-income, and highly educated individuals.
This underscores the need to consider demographic-based biases in AI-generated
marketing strategies and their broader societal implications. The findings of
this study provide a roadmap for developing more equitable AI systems,
highlighting the need for ongoing bias detection and mitigation efforts in
LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±å¾¹åºæ¹è®äºéèãè¡é·åå®¢æ¶æåç­ç¢æ¥­ï¼å çºå®è½å·è¡è¤éçèªç¶èªè¨èçä»»åãç¶èï¼LLM çå»£æ³æ¡ç¨å¸¶ä¾éå¤§çææ°ï¼ç¹å¥æ¯æ½èå¨å¶è¼¸åºçµæä¸­çç¤¾æåè¦å½¢å¼ãèæ§å¥ãå¹´é½¡åå¶ä»ææå±¬æ§ç¸éçåè¦å¯è½å°è´ä¸å¬å¹³çå¾éï¼å¼ç¼éå¾·åé¡ï¼ä¸¦å±åå¬å¸è²è­½åå®¢æ¶ä¿¡ä»»ãæ¬ç ç©¶æ¢è¨äº LLMï¼å³ ChatGPTï¼ç¢ççèéèç¸éçè¡é·æ¨èªä¸­çåè¦ï¼æ¹æ³æ¯éå°äºåäººå£çµ±è¨é¡å¥ï¼æ§å¥ãå©å§»çæ³ãå¹´é½¡ãæ¶å¥æ°´æºåæè²æ°´æºï¼æç¤ºéèº«æé çå»£åãç¸½å±çº 17 åç¨ç¹çäººå£çµ±è¨ç¾¤çµç¢çäº 1,700 åæ¨èªï¼ä¸¦ä¸ééµè©è¢«åé¡çºååä¸»é¡ç¾¤çµï¼è³¦æ¬ãè²¡åãå¥½èååè½ï¼ä»¥ååäººåãåè¦ä½¿ç¨ç¸å°åè¦è¨ç®é²è¡ç³»çµ±æ§è©ä¼°ï¼ä¸¦ä½¿ç¨ç§ç¾è«å¥æ´å¤«-å²ç±³è«¾å¤« (KS) æª¢å®èéå°ä»»ä½åäººç¢ççéç¨æ¨èªé²è¡çµ±è¨æª¢å®ãçµæé¡¯ç¤ºè¡é·æ¨èªä¸¦éä¸­ç«ï¼ç¸åå°ï¼å®åæ ¹æäººå£çµ±è¨å ç´ å¼·èª¿ä¸åçä¸»é¡ãèå¹´ç´è¼å¤§ãæ¶å¥è¼é«ååæè²ç¨åº¦è¼é«çåäººç¸æ¯ï¼å¥³æ§ãå¹´è¼äººãä½æ¶å¥èåæè²ç¨åº¦è¼ä½èæ¥æ¶å°çè¨æ¯æ´çºä¸åãéå¼·èª¿äºå¨ AI çæçè¡é·ç­ç¥ä¸­èéåºæ¼äººå£çµ±è¨çåè¦åå¶æ´å»£æ³çç¤¾æå½±é¿çå¿è¦æ§ãæ¬ç ç©¶çç¼ç¾æä¾äºéç¼æ´å¬å¹³ AI ç³»çµ±çè·¯ç·åï¼çªé¡¯äºå¨ LLM ä¸­æçºé²è¡åè¦åµæ¸¬åç·©è§£å·¥ä½çéè¦æ§ã

##### **An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation**
2502.12836v1 by Mohammad Feli, Iman Azimi, Pasi Liljeberg, Amir M. Rahmani

Large language models (LLMs) are revolutionizing healthcare by improving
diagnosis, patient care, and decision support through interactive
communication. More recently, they have been applied to analyzing physiological
time-series like wearable data for health insight extraction. Existing methods
embed raw numerical sequences directly into prompts, which exceeds token limits
and increases computational costs. Additionally, some studies integrated
features extracted from time-series in textual prompts or applied multimodal
approaches. However, these methods often produce generic and unreliable outputs
due to LLMs' limited analytical rigor and inefficiency in interpreting
continuous waveforms. In this paper, we develop an LLM-powered agent for
physiological time-series analysis aimed to bridge the gap in integrating LLMs
with well-established analytical tools. Built on the OpenCHA, an open-source
LLM-powered framework, our agent features an orchestrator that integrates user
interaction, data sources, and analytical tools to generate accurate health
insights. To evaluate its effectiveness, we implement a case study on heart
rate (HR) estimation from Photoplethysmogram (PPG) signals using a dataset of
PPG and Electrocardiogram (ECG) recordings in a remote health monitoring study.
The agent's performance is benchmarked against OpenAI GPT-4o-mini and GPT-4o,
with ECG serving as the gold standard for HR estimation. Results demonstrate
that our agent significantly outperforms benchmark models by achieving lower
error rates and more reliable HR estimations. The agent implementation is
publicly available on GitHub.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ééäºåå¼æºéï¼æ¹åè¨ºæ·ãçäººç§è­·åæ±ºç­æ¯æ´ï¼é²èé©æ°é«çä¿å¥ãæè¿ï¼å®åå·²æç¨æ¼åæççæéåºåï¼ä¾å¦å¯ç©¿æ´å¼è£ç½®çè³æï¼ä»¥èåå¥åº·è¦è§£ãç¾ææ¹æ³æå°åå§æ¸å¼åºåç´æ¥åµå¥æç¤ºä¸­ï¼éæè¶éæ¬æéå¶ä¸¦å¢å éç®ææ¬ãæ­¤å¤ï¼ä¸äºç ç©¶å°å¾æéåºåä¸­èåçç¹å¾µæ´åå°æå­æç¤ºä¸­ï¼ææç¨å¤æ¨¡ææ¹æ³ãç¶èï¼ç±æ¼ LLM å¨è§£è­¯é£çºæ³¢å½¢æåæå´è¬¹åº¦æéä¸æçä¸å½°ï¼éäºæ¹æ³ç¶å¸¸ç¢çéç¨ä¸ä¸å¯é çè¼¸åºãå¨æ¬æä¸­ï¼æåéç¼äºä¸åç± LLM é©åçä»£çï¼ç¨æ¼ççæéåºååæï¼æ¨å¨å½åå° LLM èæ¢æåæå·¥å·æ´åçå·®è·ãæåçä»£çå»ºç«å¨ OpenCHAï¼ä¸åç± LLM é©åçéæºæ¶æ§ï¼ä¹ä¸ï¼å·åä¸åæ´åä½¿ç¨èäºåãè³æä¾æºååæå·¥å·çåèª¿å¨ï¼ä»¥ç¢çæºç¢ºçå¥åº·è¦è§£ãçºäºè©ä¼°å¶æææ§ï¼æåå¯¦ä½äºä¸åæ¡ä¾ç ç©¶ï¼å¾é è·å¥åº·ç£æ¸¬ç ç©¶ä¸­çä¸çµåé»å®¹ç©æè¨å (PPG) åå¿é»å (ECG) è¨éä¸­ä¼°ç®å¿ç (HR)ãè©²ä»£ççæè½è OpenAI GPT-4o-mini å GPT-4o é²è¡åºæºæ¸¬è©¦ï¼å¶ä¸­ ECG ä½çº HR ä¼°ç®çéæ¨æºãçµæé¡¯ç¤ºï¼æåçä»£çéééæè¼ä½çé¯èª¤çåæ´å¯é ç HR ä¼°ç®ï¼é¡¯èåªæ¼åºæºæ¨¡åãè©²ä»£çå¯¦ä½å·²å¬éå¨ GitHub ä¸ã

##### **Subword models struggle with word learning, but surprisal hides it**
2502.12835v1 by Bastian Bunzeck, Sina ZarrieÃ

We study word learning in subword and character language models with the
psycholinguistic lexical decision task. While subword LMs struggle to discern
words and non-words with high accuracy, character LMs solve this task easily
and consistently. Furthermore, when comparing word learning and syntactic
learning, both processes are separable in character LM where word learning
predates syntactic learning, whereas these processes are simultaneous in
subword LM. This raises questions about the adequacy of subword LMs for
modeling language acquisition and positions character LMs as a viable
alternative.

æè¦ï¼æåä½¿ç¨å¿çèªè¨å­¸çè©å½æ±ºç­ä»»åç ç©¶å¨å­è©åå­åèªè¨æ¨¡åä¸­çè©å½å­¸ç¿ãåç®¡å­è©èªè¨æ¨¡åé£ä»¥ååå®è©åéå®è©ï¼ä½å­åèªè¨æ¨¡åå¯ä»¥è¼é¬ä¸ä¸è´å°è§£æ±ºæ­¤ä»»åãæ­¤å¤ï¼å¨æ¯è¼å®è©å­¸ç¿åå¥æ³å­¸ç¿æï¼éå©åéç¨å¨å­åèªè¨æ¨¡åä¸­æ¯å¯åé¢çï¼å¶ä¸­å®è©å­¸ç¿åæ¼å¥æ³å­¸ç¿ï¼èéäºéç¨å¨å­è©èªè¨æ¨¡åä¸­æ¯åæç¼ççãéå¼ç¼äºéæ¼å­è©èªè¨æ¨¡åå°èªè¨ç¿å¾å»ºæ¨¡çååæ§çåé¡ï¼ä¸¦å°å­åèªè¨æ¨¡åå®ä½çºå¯è¡çæ¿ä»£æ¹æ¡ã

##### **KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan**
2502.12829v1 by Mukhammed Togmanov, Nurdaulet Mukhituly, Diana Turmakhan, Jonibek Mansurov, Maiya Goloburda, Akhmed Sakip, Zhuohan Xie, Yuxia Wang, Bekassyl Syzdykov, Nurkhan Laiyk, Alham Fikri Aji, Ekaterina Kochmar, Preslav Nakov, Fajri Koto

Despite having a population of twenty million, Kazakhstan's culture and
language remain underrepresented in the field of natural language processing.
Although large language models (LLMs) continue to advance worldwide, progress
in Kazakh language has been limited, as seen in the scarcity of dedicated
models and benchmark evaluations. To address this gap, we introduce KazMMLU,
the first MMLU-style dataset specifically designed for Kazakh language. KazMMLU
comprises 23,000 questions that cover various educational levels, including
STEM, humanities, and social sciences, sourced from authentic educational
materials and manually validated by native speakers and educators. The dataset
includes 10,969 Kazakh questions and 12,031 Russian questions, reflecting
Kazakhstan's bilingual education system and rich local context. Our evaluation
of several state-of-the-art multilingual models (Llama-3.1, Qwen-2.5, GPT-4,
and DeepSeek V3) demonstrates substantial room for improvement, as even the
best-performing models struggle to achieve competitive performance in Kazakh
and Russian. These findings underscore significant performance gaps compared to
high-resource languages. We hope that our dataset will enable further research
and development of Kazakh-centric LLMs. Data and code will be made available
upon acceptance.

æè¦ï¼åç®¡åè©åäººå£éå©åè¬ï¼ä½åè©åçæååèªè¨å¨èªç¶èªè¨èçé åä»æªå¾å°ååçéè¦ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¨å¨çæçºé²æ­¥ï¼ä½åè©åèªçé²å±å»ååæéï¼éå¾å°ç¨æ¨¡åååºæºè©ä¼°çç¨ç¼ºæ§ä¸­å¯è¦ä¸æãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº KazMMLUï¼éæ¯ç¬¬ä¸åå°éçºåè©åèªè¨­è¨ç MMLU é¢¨æ ¼è³æéãKazMMLU åå« 23,000 ååé¡ï¼æ¶µèåç¨®æè²å±¤ç´ï¼åæ¬ STEMãäººæå­¸ç§åç¤¾æç§å­¸ï¼éäºåé¡ä¾èªçå¯¦çæè²ææï¼ä¸¦ç±æ¯èªäººå£«åæè²å·¥ä½èæåé©è­ãè©²è³æéåå« 10,969 ååè©åèªåé¡å 12,031 åä¿èªåé¡ï¼åæ äºåè©åçéèªæè²é«ç³»åè±å¯çå¨å°èçµ¡ãæåå°å¹¾åæåé²çå¤èªè¨æ¨¡åï¼Llama-3.1ãQwen-2.5ãGPT-4 å DeepSeek V3ï¼çè©ä¼°é¡¯ç¤ºï¼ä»æå¾å¤§çæ¹é²ç©ºéï¼å çºå³ä½¿æ¯æè½æå¥½çæ¨¡åï¼ä¹å¾é£å¨åè©åèªåä¿èªä¸­éå°æç«¶ç­åçæè½ãéäºç¼ç¾å¼·èª¿äºèè³æºè±å¯çèªè¨ç¸æ¯ï¼å­å¨é¡¯èçæè½å·®è·ãæåå¸ææåçè³æéè½ä¿é²ä»¥åè©åèªçºä¸­å¿ç LLM çé²ä¸æ­¥ç ç©¶åéç¼ãè³æåç¨å¼ç¢¼å°å¨ç²å¾æ¥åå¾æä¾ã

##### **Reasoning and the Trusting Behavior of DeepSeek and GPT: An Experiment Revealing Hidden Fault Lines in Large Language Models**
2502.12825v1 by Rubing Lu, JoÃ£o Sedoc, Arun Sundararajan

When encountering increasingly frequent performance improvements or cost
reductions from a new large language model (LLM), developers of applications
leveraging LLMs must decide whether to take advantage of these improvements or
stay with older tried-and-tested models. Low perceived switching frictions can
lead to choices that do not consider more subtle behavior changes that the
transition may induce. Our experiments use a popular game-theoretic behavioral
economics model of trust to show stark differences in the trusting behavior of
OpenAI's and DeepSeek's models. We highlight a collapse in the economic trust
behavior of the o1-mini and o3-mini models as they reconcile profit-maximizing
and risk-seeking with future returns from trust, and contrast it with
DeepSeek's more sophisticated and profitable trusting behavior that stems from
an ability to incorporate deeper concepts like forward planning and
theory-of-mind. As LLMs form the basis for high-stakes commercial systems, our
results highlight the perils of relying on LLM performance benchmarks that are
too narrowly defined and suggest that careful analysis of their hidden fault
lines should be part of any organization's AI strategy.

æè¦ï¼ç¶éå°è¶ä¾è¶é »ç¹çæè½æåæä¾èªæ¼æ°çå¤§åèªè¨æ¨¡å (LLM) çææ¬éä½æï¼å©ç¨ LLM çæç¨ç¨å¼éç¼äººå¡å¿é æ±ºå®æ¯å¦è¦å©ç¨éäºæåæç¶­æè¼èä¸ç¶éæ¸¬è©¦çæ¨¡åãä½æç¥åææ©æ¦å¯è½æå°è´é¸æä¸èæ®è½æå¯è½èªç¼çæ´ç´°å¾®çè¡çºæ¹è®ãæåçå¯¦é©ä½¿ç¨ä¿¡ä»»çæµè¡åå¼è«è¡çºç¶æ¿æ¨¡åä¾é¡¯ç¤º OpenAI å DeepSeek æ¨¡åå¨ä¿¡ä»»è¡çºä¸çé¡¯èå·®ç°ãæåå¼·èª¿ o1-mini å o3-mini æ¨¡åçç¶æ¿ä¿¡ä»»è¡çºå´©æ½°ï¼å çºå®åèª¿åäºå©æ½¤æå¤§ååé¢¨éªå°æ±èä¾èªä¿¡ä»»çæªä¾åå ±ï¼ä¸¦å°å¶è DeepSeek æ´è¤éä¸æå©å¯åçä¿¡ä»»è¡çºé²è¡å°æ¯ï¼éç¨®ä¿¡ä»»è¡çºæºæ¼æ´åæ´æ·±å±¤çæ¦å¿µï¼ä¾å¦åç»æ§è¦ååå¿æºçè«ãç±æ¼ LLM æ§æé«é¢¨éªåæ¥­ç³»çµ±çåºç¤ï¼æåççµæçªé¡¯äºä¾è³´å®ç¾©éæ¼ç¹çªç LLM æè½åºæºçå±éªæ§ï¼ä¸¦å»ºè­°ä»ç´°åæå¶é±èçæ·å±¤ç·æè©²æ¯ä»»ä½çµç¹ç AI ç­ç¥çä¸é¨åã

##### **Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models**
2502.12821v1 by Elena Stringli, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou

Inverse tasks can uncover potential reasoning gaps as Large Language Models
(LLMs) scale up. In this work, we explore the redefinition task, in which we
assign alternative values to well-known physical constants and units of
measure, prompting LLMs to respond accordingly. Our findings show that not only
does model performance degrade with scale, but its false confidence also rises.
Moreover, while factors such as prompting strategies or response formatting are
influential, they do not preclude LLMs from anchoring to memorized values.

æè¦ï¼éåä»»åå¯ä»¥æ­ç¤ºå¤§åèªè¨æ¨¡å (LLM) æ´å±ææ½å¨çæ¨çå·®è·ãå¨æ¬æä¸­ï¼æåæ¢è¨éæ°å®ç¾©ä»»åï¼å¶ä¸­æåå°æ¿æå¼æå®çµ¦èåçç©çå¸¸æ¸åæ¸¬éå®ä½ï¼ä¿ä½¿ LLM ååºç¸æåæãæåçç ç©¶çµæè¡¨æï¼æ¨¡åæè½ä¸åæé¨èè¦æ¨¡èä¸éï¼å¶èåä¿¡å¿ä¹æä¸åãæ­¤å¤ï¼åç®¡æç¤ºç­ç¥æåææ ¼å¼ç­å ç´ å·æå½±é¿åï¼ä½å®åä¸¦ä¸å¦¨ç¤ LLM é¨å®å¨è¨æ¶å¼ä¸ã

##### **Simulating User Diversity in Task-Oriented Dialogue Systems using Large Language Models**
2502.12813v1 by Adnan Ahmad, Stefan Hillmann, Sebastian MÃ¶ller

In this study, we explore the application of Large Language Models (LLMs) for
generating synthetic users and simulating user conversations with a
task-oriented dialogue system and present detailed results and their analysis.
We propose a comprehensive novel approach to user simulation technique that
uses LLMs to create diverse user profiles, set goals, engage in multi-turn
dialogues, and evaluate the conversation success. We employ two proprietary
LLMs, namely GPT-4o and GPT-o1 (Achiam et al., 2023), to generate a
heterogeneous base of user profiles, characterized by varied demographics,
multiple user goals, different conversational styles, initial knowledge levels,
interests, and conversational objectives. We perform a detailed analysis of the
user profiles generated by LLMs to assess the diversity, consistency, and
potential biases inherent in these LLM-generated user simulations. We find that
GPT-o1 generates more heterogeneous user distribution across most user
attributes, while GPT-4o generates more skewed user attributes. The generated
set of user profiles are then utilized to simulate dialogue sessions by
interacting with a task-oriented dialogue system.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåæ¢è¨å¤§åèªè¨æ¨¡å (LLM) å¨çæåæä½¿ç¨èåæ¨¡æ¬ä½¿ç¨èå°è©±ï¼ä¸¦ä½¿ç¨ä»»åå°åå°è©±ç³»çµ±é²è¡å°è©±çæç¨ï¼ä¸¦æåºè©³ç´°ççµæåå¶åæãæåæåºäºä¸ç¨®å¨é¢çä½¿ç¨èæ¨¡æ¬æè¡æ°æ¹æ³ï¼å©ç¨ LLM å»ºç«å¤æ¨£åçä½¿ç¨èæ¦æ³ãè¨­å®ç®æ¨ãåèå¤è¼ªå°è©±ï¼ä¸¦è©ä¼°å°è©±çæåæ§ãæåæ¡ç¨äºå©åå°æç LLMï¼å³ GPT-4o å GPT-o1 (Achiam ç­äººï¼2023 å¹´)ï¼ä»¥çæä¸åç°è³ªçä½¿ç¨èæ¦æ³åºç¤ï¼å¶ç¹å¾µå¨æ¼ä¸åçäººå£çµ±è¨è³æãå¤åä½¿ç¨èç®æ¨ãä¸åçå°è©±é¢¨æ ¼ãåå§ç¥è­æ°´æºãèè¶£åå°è©±ç®æ¨ãæåå° LLM çæçä½¿ç¨èæ¦æ³é²è¡äºè©³ç´°åæï¼ä»¥è©ä¼°éäº LLM çæçä½¿ç¨èæ¨¡æ¬ä¸­åºæçå¤æ¨£æ§ãä¸è´æ§åæ½å¨åå·®ãæåç¼ç¾ GPT-o1 å¨å¤§å¤æ¸ä½¿ç¨èå±¬æ§ä¸­ç¢çæ´ç°è³ªçä½¿ç¨èåä½ï¼è GPT-4o åç¢çæ´åæçä½¿ç¨èå±¬æ§ãç¶å¾å©ç¨çæçä½¿ç¨èæ¦æ³éï¼ééèä»»åå°åå°è©±ç³»çµ±äºåä¾æ¨¡æ¬å°è©±æè©±ã

##### **Towards Text-Image Interleaved Retrieval**
2502.12799v1 by Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu, Wenjie Li, Min Zhang

Current multimodal information retrieval studies mainly focus on single-image
inputs, which limits real-world applications involving multiple images and
text-image interleaved content. In this work, we introduce the text-image
interleaved retrieval (TIIR) task, where the query and document are interleaved
text-image sequences, and the model is required to understand the semantics
from the interleaved context for effective retrieval. We construct a TIIR
benchmark based on naturally interleaved wikiHow tutorials, where a specific
pipeline is designed to generate interleaved queries. To explore the task, we
adapt several off-the-shelf retrievers and build a dense baseline by
interleaved multimodal large language model (MLLM). We then propose a novel
Matryoshka Multimodal Embedder (MME), which compresses the number of visual
tokens at different granularity, to address the challenge of excessive visual
tokens in MLLM-based TIIR models. Experiments demonstrate that simple adaption
of existing models does not consistently yield effective results. Our MME
achieves significant improvements over the baseline by substantially fewer
visual tokens. We provide extensive analysis and will release the dataset and
code to facilitate future research.

æè¦ï¼ç®åçå¤æ¨¡æè³è¨æª¢ç´¢ç ç©¶ä¸»è¦éä¸­å¨å®ä¸å½±åè¼¸å¥ï¼ééå¶äºæ¶åå¤åå½±ååæå­å½±åäº¤é¯å§å®¹çå¯¦éæç¨ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºæå­å½±åäº¤é¯æª¢ç´¢ (TIIR) ä»»åï¼å¶ä¸­æ¥è©¢åæä»¶æ¯äº¤é¯çæå­å½±ååºåï¼ä¸¦ä¸æ¨¡åéè¦çè§£äº¤é¯å§å®¹çèªæä»¥é²è¡æææª¢ç´¢ãæåæ ¹æèªç¶äº¤é¯ç wikiHow æå­¸èª²ç¨å»ºæ§äºä¸å TIIR åºæºï¼å¶ä¸­è¨­è¨äºä¸åç¹å®çç®¡ç·ä¾ç¢çäº¤é¯æ¥è©¢ãçºäºæ¢ç´¢éåä»»åï¼æåèª¿æ´äºå¹¾åç¾æçæª¢ç´¢å¨ï¼ä¸¦ééäº¤é¯çå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) å»ºç«äºä¸åå¯éçåºæºãç¶å¾ï¼æåæåºäºä¸åæ°ç©ç Matryoshka å¤æ¨¡æåµå¥å¨ (MME)ï¼å®å£ç¸®äºä¸åç²åº¦è¦è¦ºç¬¦èçæ¸éï¼ä»¥è§£æ±ºåºæ¼ MLLM ç TIIR æ¨¡åä¸­éå¤è¦è¦ºç¬¦èçææ°ãå¯¦é©è¡¨æï¼å°ç¾ææ¨¡åçç°¡å®èª¿æ´ä¸¦æªæçºç¢çææçµæãæåç MME ééå¤§å¹æ¸å°è¦è¦ºç¬¦èï¼éå°äºæ¯åºæºé¡¯èçæ¹é²ãæåæä¾äºå»£æ³çåæï¼ä¸¦å°éåºè³æéåç¨å¼ç¢¼ä»¥ä¿é²æªä¾çç ç©¶ã

##### **Envious Explore and Exploit**
2502.12798v1 by Omer Ben-Porat, Yotam Gafni, Or Markovetzki

Explore-and-exploit tradeoffs play a key role in recommendation systems
(RSs), aiming at serving users better by learning from previous interactions.
Despite their commercial success, the societal effects of explore-and-exploit
mechanisms are not well understood, especially regarding the utility
discrepancy they generate between different users. In this work, we measure
such discrepancy using the economic notion of envy. We present a multi-armed
bandit-like model in which every round consists of several sessions, and
rewards are realized once per round. We call the latter property reward
consistency, and show that the RS can leverage this property for better
societal outcomes. On the downside, doing so also generates envy, as
late-to-arrive users enjoy the information gathered by early-to-arrive users.
We examine the generated envy under several arrival order mechanisms and
virtually any anonymous algorithm, i.e., any algorithm that treats all similar
users similarly without leveraging their identities. We provide tight envy
bounds on uniform arrival and upper bound the envy for nudged arrival, in which
the RS can affect the order of arrival by nudging its users. Furthermore, we
study the efficiency-fairness trade-off by devising an algorithm that allows
constant envy and approximates the optimal welfare in restricted settings.
Finally, we validate our theoretical results empirically using simulations.

æè¦ï¼æ¢ç´¢èéç¼çåæ¨å¨æ¨è¦ç³»çµ± (RS) ä¸­æ®æ¼èééµè§è²ï¼æ¨å¨ééå­¸ç¿ååçäºåä¾çºä½¿ç¨èæä¾æ´å¥½çæåãåç®¡å¨åæ¥­ä¸ç²å¾æåï¼ä½æ¢ç´¢èéç¼æ©å¶çç¤¾æææä»æªè¢«ååçè§£ï¼ç¹å¥æ¯éæ¼å®åå¨ä¸åä½¿ç¨èä¹éç¢ççæç¨å·®ç°ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨ç¶æ¿å­¸ä¸­çå«å¦æ¦å¿µä¾è¡¡ééç¨®å·®ç°ãæåæåºäºä¸åå¤èèèæ©æ¨¡åï¼å¶ä¸­æ¯ä¸è¼ªé½åå«å¤åååï¼ä¸¦ä¸æ¯åååªæå¯¦ç¾ä¸æ¬¡çåµãæåå°å¾èçç¹æ§ç¨±çºçåµä¸è´æ§ï¼ä¸¦è­æ RS å¯ä»¥å©ç¨æ­¤ç¹æ§ä¾ç²å¾æ´å¥½çç¤¾æææãä¸å©çæ¯ï¼ééº¼åä¹æç¢çå«å¦ï¼å çºè¼æå å¥çä½¿ç¨èå¯ä»¥äº«åè¼æ©å å¥çä½¿ç¨èææ¶éçè³è¨ãæåå¨å¤ç¨®å°éé åºæ©å¶åå¹¾ä¹ä»»ä½å¿åæ¼ç®æ³ï¼å³ä»»ä½æ¼ç®æ³é½ä»¥é¡ä¼¼çæ¹å¼å°å¾ææé¡ä¼¼çä½¿ç¨èï¼èä¸å©ç¨ä»åçèº«ä»½ï¼ä¸æª¢é©ç¢ççå«å¦ãæåå°åå»å°éæä¾å´æ ¼çå«å¦çç·ï¼ä¸¦å°æ¨åå°éçä¸éé²è¡å«å¦çç·ï¼å¶ä¸­ RS å¯ä»¥ééæ¨åå¶ä½¿ç¨èä¾å½±é¿å°éé åºãæ­¤å¤ï¼æåééè¨­è¨ä¸ç¨®æ¼ç®æ³ä¾ç ç©¶æçå¬å¹³æ¬è¡¡ï¼è©²æ¼ç®æ³åè¨±æå®çå«å¦ï¼ä¸¦å¨åéè¨­å®ä¸­è¿ä¼¼æä½³ç¦å©ãæå¾ï¼æåä½¿ç¨æ¨¡æ¬å°æåççè«çµæé²è¡ç¶é©é©è­ã

##### **Commonsense Reasoning in Arab Culture**
2502.12788v1 by Abdelrahman Sadallah, Junior Cedric Tonga, Khalid Almubarak, Saeed Almheiri, Farah Atif, Chatrine Qwaider, Karima Kadaoui, Sara Shatnawi, Yaser Alesh, Fajri Koto

Despite progress in Arabic large language models, such as Jais and AceGPT,
their evaluation on commonsense reasoning has largely relied on
machine-translated datasets, which lack cultural depth and may introduce
Anglocentric biases. Commonsense reasoning is shaped by geographical and
cultural contexts, and existing English datasets fail to capture the diversity
of the Arab world. To address this, we introduce \datasetname, a commonsense
reasoning dataset in Modern Standard Arabic (MSA), covering cultures of 13
countries across the Gulf, Levant, North Africa, and the Nile Valley. The
dataset was built from scratch by engaging native speakers to write and
validate culturally relevant questions for their respective countries.
\datasetname spans 12 daily life domains with 54 fine-grained subtopics,
reflecting various aspects of social norms, traditions, and everyday
experiences. Zero-shot evaluations show that open-weight language models with
up to 32B parameters struggle to comprehend diverse Arab cultures, with
performance varying across regions. These findings highlight the need for more
culturally aware models and datasets tailored to the Arabic-speaking world.

æè¦ï¼åç®¡é¿æä¼¯èªå¤§åèªè¨æ¨¡åï¼ä¾å¦ Jais å AceGPTï¼å·²æé²å±ï¼
ä½å®åå¨å¸¸è­æ¨çä¸çè©ä¼°å¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼
æ©å¨ç¿»è­¯çè³æéï¼éäºè³æéç¼ºä¹æåæ·±åº¦ï¼å¯è½æå¼å¥
ä»¥è±èªçºä¸­å¿çåè¦ãå¸¸è­æ¨çåå°çå
æåèæ¯å½±é¿ï¼ç¾æçè±æè³æéç¡æ³ææé¿æä¼¯ä¸ççå¤æ¨£æ§ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº \datasetnameï¼ä¸åç¾ä»£æ¨æºé¿æä¼¯èª (MSA) çå¸¸è­æ¨çè³æéï¼æ¶µèæµ·ç£å°åãé»å¡ç¹å°åãåéåå°¼ç¾æ²³è°· 13 ååå®¶çæåãæ­¤è³æéæ¯å¾é ­éå§å»ºç«çï¼ç±æ¯èªäººå£«åèç·¨å¯«åé©è­ä»ååèªåå®¶çæåç¸éåé¡ã\datasetname æ¶µè 12 åæ¥å¸¸çæ´»é åï¼åå« 54 åç´°ç·»çä¸»é¡ï¼åæ ç¤¾æè¦ç¯ãå³çµ±åæ¥å¸¸ç¶é©çååæ¹é¢ãé¶æ¬¡å­¸ç¿è©ä¼°é¡¯ç¤ºï¼å·æé«é 32B åæ¸çéæ¾å¼æ¬éèªè¨æ¨¡åé£ä»¥çè§£ä¸åçé¿æä¼¯æåï¼ä¸åååçè¡¨ç¾ä¸ä¸ãéäºç¼ç¾çªé¡¯äºå°æ´å·æåæè­çæ¨¡ååå°çºé¿æä¼¯èªç³»ä¸çéèº«æé çè³æéçéæ±ã

##### **VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation**
2502.12782v1 by Xinlong Chen, Yuanxing Zhang, Chongling Rao, Yushuo Guan, Jiaheng Liu, Fuzheng Zhang, Chengru Song, Qiang Liu, Di Zhang, Tieniu Tan

The training of controllable text-to-video (T2V) models relies heavily on the
alignment between videos and captions, yet little existing research connects
video caption evaluation with T2V generation assessment. This paper introduces
VidCapBench, a video caption evaluation scheme specifically designed for T2V
generation, agnostic to any particular caption format. VidCapBench employs a
data annotation pipeline, combining expert model labeling and human refinement,
to associate each collected video with key information spanning video
aesthetics, content, motion, and physical laws. VidCapBench then partitions
these key information attributes into automatically assessable and manually
assessable subsets, catering to both the rapid evaluation needs of agile
development and the accuracy requirements of thorough validation. By evaluating
numerous state-of-the-art captioning models, we demonstrate the superior
stability and comprehensiveness of VidCapBench compared to existing video
captioning evaluation approaches. Verification with off-the-shelf T2V models
reveals a significant positive correlation between scores on VidCapBench and
the T2V quality evaluation metrics, indicating that VidCapBench can provide
valuable guidance for training T2V models. The project is available at
https://github.com/VidCapBench/VidCapBench.

æè¦ï¼å¯æ§å¶ææ¬å°å½±ç (T2V) æ¨¡åçè¨ç·´æ¥µåº¦ä»°è³´å½±çåå­å¹ä¹éçå°é½ï¼ä½ç¾æç ç©¶é®®å°å°å½±çå­å¹è©ä¼°è T2V çæè©ä¼°é£çµèµ·ä¾ãæ¬æä»ç´¹ VidCapBenchï¼éæ¯ä¸ç¨®å°éçº T2V çæè¨­è¨çå½±çå­å¹è©ä¼°æ¶æ§ï¼èä»»ä½ç¹å®çå­å¹æ ¼å¼ç¡éãVidCapBench æ¡ç¨è³ææ¨è¨»æµç¨ï¼çµåå°å®¶æ¨¡åæ¨è¨åäººå·¥å¾®èª¿ï¼å°æ¯åæ¶éå°çå½±çèæ¶µèå½±çç¾å­¸ãå§å®¹ãåä½åç©çå®å¾ç­ééµè³è¨éè¯èµ·ä¾ãVidCapBench æ¥èå°éäºééµè³è¨å±¬æ§åå²æå¯èªåè©ä¼°åå¯æåè©ä¼°çå­éï¼ä»¥æ»¿è¶³ææ·éç¼çå¿«éè©ä¼°éæ±åå¨é¢é©è­çæºç¢ºæ§è¦æ±ãééè©ä¼°è¨±å¤æåé²çå­å¹æ¨¡åï¼æåè­æäº VidCapBench èç¾æçå½±çå­å¹è©ä¼°æ¹æ³ç¸æ¯ï¼å·æåªç°çç©©å®æ§åå¨é¢æ§ãä½¿ç¨ç¾æç T2V æ¨¡åé©è­é¡¯ç¤ºï¼VidCapBench å¾åè T2V åè³ªè©ä¼°ææ¨ä¹éå­å¨é¡¯èçæ­£ç¸éï¼éè¡¨ç¤º VidCapBench å¯ä»¥çºè¨ç·´ T2V æ¨¡åæä¾æå¹å¼çæå°ãå°æ¡å¯æ¼ https://github.com/VidCapBench/VidCapBench åå¾ã

##### **Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models**
2502.12776v1 by Daiki Chijiwa, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Susumu Takeuchi

While foundation models have been exploited for various expert tasks through
fine-tuning, any foundation model will become outdated due to its old knowledge
or limited capability. Thus the underlying foundation model should be
eventually replaced by new ones, which leads to repeated cost of fine-tuning
these new models. Existing work addresses this problem by inference-time
tuning, i.e., modifying the output probabilities from the new foundation model
with the outputs from the old foundation model and its fine-tuned model, which
involves an additional overhead in inference by the latter two models. In this
paper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT),
that reduces the inference overhead by its nature, based on the reformulation
of fine-tuning as the reward maximization. Specifically, instead of fine-tuning
parameters of the foundation models, PRT trains the reward model explicitly
through the same loss function as in fine-tuning. During inference, the reward
model can be used with any foundation model (with the same set of vocabularies
or labels) through the formulation of reward maximization. Experimental
results, covering both vision and language models, demonstrate that the
PRT-trained model can achieve comparable accuracy to the existing work of
inference-time tuning, with less inference cost.

æè¦ï¼åç®¡åºç¤æ¨¡åå·²ééå¾®èª¿ç¨æ¼åç¨®å°å®¶ä»»åï¼ä»»ä½åºç¤æ¨¡åé½å°å å¶èç¥è­ææéåè½èéæãå æ­¤ï¼åºç¤æ¨¡åæçµæç±æ°æ¨¡ååä»£ï¼éå°è´éè¤å¾®èª¿éäºæ°æ¨¡åçææ¬ãç¾æå·¥ä½ééæ¨è«æéèª¿æ´ä¾è§£æ±ºéååé¡ï¼å³ä½¿ç¨èåºç¤æ¨¡ååå¶å¾®èª¿æ¨¡åçè¼¸åºä¿®æ¹æ°åºç¤æ¨¡åçè¼¸åºæ©çï¼éæ¶åå¾å©åæ¨¡åå¨æ¨è«ä¸­çé¡å¤éé·ãå¨æ¬æä¸­ï¼æåæåºä¸åæ°çå¾®èª¿ååï¼å¯æå¼çåµèª¿æ´ (PRT)ï¼å®æ¬è³ªä¸ææ¸å°æ¨è«éé·ï¼åºæ¼å°å¾®èª¿éæ°è¡¨è¿°çºçåµæå¤§åãå·é«ä¾èªªï¼PRT ä¸æ¯å¾®èª¿åºç¤æ¨¡åçåæ¸ï¼èæ¯ééèå¾®èª¿ä¸­ç¸åçæå¤±å½æ¸æç¢ºè¨ç·´çåµæ¨¡åãå¨æ¨è«æéï¼çåµæ¨¡åå¯ééçåµæå¤§åçå¬å¼èä»»ä½åºç¤æ¨¡åï¼å·æç¸åçè©å½ææ¨ç±¤çµï¼ä¸èµ·ä½¿ç¨ãæ¶µèè¦è¦ºåèªè¨æ¨¡åçå¯¦é©çµæè­æï¼PRT è¨ç·´çæ¨¡åå¯ä»¥éå°èç¾ææ¨è«æéèª¿æ´å·¥ä½ç¸ç¶çæºç¢ºåº¦ï¼ä¸æ¨è«ææ¬è¼ä½ã

##### **Mind the Gap: Aligning the Brain with Language Models Requires a Nonlinear and Multimodal Approach**
2502.12771v1 by Danny Dongyeop Han, Yunju Cho, Jiook Cha, Jay-Yoon Lee

Self-supervised language and audio models effectively predict brain responses
to speech. However, traditional prediction models rely on linear mappings from
unimodal features, despite the complex integration of auditory signals with
linguistic and semantic information across widespread brain networks during
speech comprehension. Here, we introduce a nonlinear, multimodal prediction
model that combines audio and linguistic features from pre-trained models
(e.g., LLAMA, Whisper). Our approach achieves a 17.2% and 17.9% improvement in
prediction performance (unnormalized and normalized correlation) over
traditional unimodal linear models, as well as a 7.7% and 14.4% improvement,
respectively, over prior state-of-the-art models. These improvements represent
a major step towards future robust in-silico testing and improved decoding
performance. They also reveal how auditory and semantic information are fused
in motor, somatosensory, and higher-level semantic regions, aligning with
existing neurolinguistic theories. Overall, our work highlights the often
neglected potential of nonlinear and multimodal approaches to brain modeling,
paving the way for future studies to embrace these strategies in naturalistic
neurolinguistics research.

æè¦ï¼èªæç£ç£çèªè¨åé³è¨æ¨¡åææé æ¸¬å¤§è¦å°èªè¨çåæãç¶èï¼å³çµ±çé æ¸¬æ¨¡åä¾è³´æ¼å®æ¨¡æç¹å¾µçç·æ§æ å°ï¼åç®¡å¨èªè¨çè§£éç¨ä¸­ï¼è½è¦ºä¿¡èèèªè¨åèªç¾©è³è¨å¨å»£æ³çè¦ç¶²è·¯ä¸­é²è¡è¤éçæ´åãå¨æ­¤ï¼æåå¼å¥ä¸åéç·æ§ãå¤æ¨¡æé æ¸¬æ¨¡åï¼çµåé åè¨ç·´æ¨¡åï¼ä¾å¦ï¼LLAMAãWhisperï¼ä¸­çé³è¨åèªè¨ç¹å¾µãæåçåæ³å¨é æ¸¬æè½ä¸ï¼æªæ­£è¦ååæ­£è¦åç¸éæ§ï¼åå¥æ¯å³çµ±çå®æ¨¡æç·æ§æ¨¡åæåäº 17.2% å 17.9%ï¼åå¥æ¯ååçæåé²æ¨¡åæåäº 7.7% å 14.4%ãéäºæ¹é²ä»£è¡¨äºæªä¾ç©©å¥çé»è¦æ¨¡æ¬æ¸¬è©¦åæ¹é²çè§£ç¢¼æè½éåºäºä¸å¤§æ­¥ãå®åä¹æ­ç¤ºäºè½è¦ºåèªç¾©è³è¨å¦ä½å¨éåãé«æåæ´é«å±¤æ¬¡çèªç¾©ååä¸­èåï¼èç¾æçç¥ç¶èªè¨å­¸çè«ä¸è´ãç¸½çä¾èªªï¼æåçç ç©¶çªåºäºéç·æ§åå¤æ¨¡æå¤§è¦å»ºæ¨¡æ¹æ³ç¶å¸¸è¢«å¿½ç¥çæ½åï¼çºæªä¾ç ç©¶å¨èªç¶ä¸»ç¾©ç¥ç¶èªè¨å­¸ç ç©¶ä¸­æ¡ç¨éäºç­ç¥éªå¹³äºéè·¯ã

##### **How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild**
2502.12769v1 by Saad Obaid ul Islam, Anne Lauscher, Goran GlavaÅ¡

In the age of misinformation, hallucination -- the tendency of Large Language
Models (LLMs) to generate non-factual or unfaithful responses -- represents the
main risk for their global utility. Despite LLMs becoming increasingly
multilingual, the vast majority of research on detecting and quantifying LLM
hallucination are (a) English-centric and (b) focus on machine translation (MT)
and summarization, tasks that are less common ``in the wild'' than open
information seeking. In contrast, we aim to quantify the extent of LLM
hallucination across languages in knowledge-intensive long-form question
answering. To this end, we train a multilingual hallucination detection model
and conduct a large-scale study across 30 languages and 6 open-source LLM
families. We start from an English hallucination detection dataset and rely on
MT to generate (noisy) training data in other languages. We also manually
annotate gold data for five high-resource languages; we then demonstrate, for
these languages, that the estimates of hallucination rates are similar between
silver (LLM-generated) and gold test sets, validating the use of silver data
for estimating hallucination rates for other languages. For the final rates
estimation, we build a knowledge-intensive QA dataset for 30 languages with
LLM-generated prompts and Wikipedia articles as references. We find that, while
LLMs generate longer responses with more hallucinated tokens for
higher-resource languages, there is no correlation between length-normalized
hallucination rates of languages and their digital representation. Further, we
find that smaller LLMs exhibit larger hallucination rates than larger models.

æè¦ï¼<paragraph>å¨éè¯¯è¨æ¯çæä»£ï¼å¹»è¦ºââå¤§åèªè¨æ¨¡å (LLM) ç¢çéäºå¯¦æä¸å¿ å¯¦åæçå¾åââä»£è¡¨å¶å¨çæç¨çä¸»è¦é¢¨éªãåç®¡ LLM è®å¾è¶ä¾è¶å¤ååï¼ä½çµå¤§å¤æ¸éæ¼åµæ¸¬åéå LLM å¹»è¦ºçç ç©¶é½æ¯ (a) ä»¥è±èªçºä¸­å¿ï¼(b) å°æ³¨æ¼æ©å¨ç¿»è­¯ (MT) åæè¦ï¼éäºä»»åå¨ãéå¤ãä¸­ä¸å¦éæ¾å¼è³è¨æå°å¸¸è¦ãç¸åå°ï¼æåæ¨å¨éå LLM å¨ç¥è­å¯éåé·ç¯åç­ä¸­è·¨èªè¨çå¹»è¦ºç¨åº¦ãçºæ­¤ï¼æåè¨ç·´äºä¸åå¤èªè¨å¹»è¦ºåµæ¸¬æ¨¡åï¼ä¸¦éå° 30 ç¨®èªè¨å 6 åéæ¾åå§ç¢¼ LLM å®¶æé²è¡å¤§è¦æ¨¡ç ç©¶ãæåå¾ä¸åè±èªå¹»è¦ºåµæ¸¬è³æééå§ï¼ä¸¦ä¾è³´ MT å¨å¶ä»èªè¨ä¸­ç¢çï¼æéè¨çï¼è¨ç·´è³æãæåéæåçºäºç¨®é«è³æºèªè¨è¨»è§£é»éè³æï¼ç¶å¾æåè­æï¼å°æ¼éäºèªè¨ï¼å¹»è¦ºççä¼°è¨å¼å¨ç½éï¼LLM ç¢çï¼åé»éæ¸¬è©¦éä¹éæ¯ç¸ä¼¼çï¼é©è­äºä½¿ç¨ç½éè³æä¾ä¼°è¨å¶ä»èªè¨çå¹»è¦ºçãå°æ¼æçµçæ¯çä¼°è¨ï¼æåå»ºç«äºä¸åç¥è­å¯éååç­è³æéï¼å¶ä¸­åå« 30 ç¨®èªè¨ï¼ä¸¦ä»¥ LLM ç¢ççæç¤ºåç¶­åºç¾ç§æç« ä½çºåèãæåç¼ç¾ï¼åç®¡ LLM çºè³æºè¼å¤çèªè¨ç¢çäºæ´é·çåæåæ´å¤å¹»è¦ºçä»£å¹£ï¼ä½èªè¨çé·åº¦æ­£è¦åå¹»è¦ºçèå¶æ¸ä½è¡¨ç¤ºä¹éæ²æç¸éæ§ãæ­¤å¤ï¼æåç¼ç¾è¼å°ç LLM è¡¨ç¾åºæ¯è¼å¤§çæ¨¡åæ´å¤§çå¹»è¦ºçã</paragraph>

##### **R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs**
2502.12767v1 by Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi

Recent studies have combined Large Language Models (LLMs) with Knowledge
Graphs (KGs) to enhance reasoning, improving inference accuracy without
additional training while mitigating hallucination. However, existing
frameworks are often rigid, struggling to adapt to KG or task changes. They
also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.
To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that
separates reasoning into two roles: an Operator (a low-capacity LLM) that
gathers evidence and a Supervisor (a high-capacity LLM) that makes final
judgments. This design is cost-efficient for LLM inference while still
maintaining strong reasoning accuracy. Additionally, R2-KG employs an
Abstention mechanism, generating answers only when sufficient evidence is
collected from KG, which significantly enhances reliability. Experiments across
multiple KG-based reasoning tasks show that R2-KG consistently outperforms
baselines in both accuracy and reliability, regardless of the inherent
capability of LLMs used as the Operator. Further experiments reveal that the
single-agent version of R2-KG, equipped with a strict self-consistency
strategy, achieves significantly higher-than-baseline reliability while
reducing inference cost. However, it also leads to a higher abstention rate in
complex KGs. Our findings establish R2-KG as a flexible and cost-effective
solution for KG-based reasoning. It reduces reliance on high-capacity LLMs
while ensuring trustworthy inference.

æè¦ï¼<paragraph>æè¿çç ç©¶ç»åäºå¤§åè¯­è¨æ¨¡å (LLM) ä¸ç¥è¯å¾è°± (KG) ä»¥å¢å¼ºæ¨çï¼å¨ä¸é¢å¤è®­ç»çæåµä¸æé«æ¨çåç¡®æ§ï¼åæ¶åè½»å¹»è§ãç¶èï¼ç°æçæ¡æ¶éå¸¸å¾åµåï¼é¾ä»¥éåºç¥è¯å¾è°±æä»»å¡çååãå®ä»¬è¿ä¸¥éä¾èµå¼ºå¤§ç LLM æ¥è¿è¡å¯é ï¼å³å¼å¾ä¿¡èµï¼çæ¨çãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº R2-KGï¼è¿æ¯ä¸ä¸ªå³æå³ç¨ãåä»£çæ¡æ¶ï¼å®å°æ¨çåä¸ºä¸¤ä¸ªè§è²ï¼ä¸ä¸ªæ¶éè¯æ®çæä½åï¼ä½å®¹é LLMï¼åä¸ä¸ªååºæç»å¤æ­ççç£åï¼é«å®¹é LLMï¼ãè¿ç§è®¾è®¡å¨ LLM æ¨çæ¹é¢å·æææ¬æçï¼åæ¶ä»ä¿æå¼ºå¤§çæ¨çåç¡®æ§ãæ­¤å¤ï¼R2-KG éç¨å¼ææºå¶ï¼ä»å¨ä»ç¥è¯å¾è°±æ¶éå°è¶³å¤è¯æ®æ¶æçæç­æ¡ï¼è¿æ¾èæé«äºå¯é æ§ãè·¨å¤ä¸ªåºäºç¥è¯å¾è°±çæ¨çä»»å¡çå®éªè¡¨æï¼R2-KG å¨åç¡®æ§åå¯é æ§æ¹é¢å§ç»ä¼äºåºçº¿ï¼èä¸ç¨ä½æä½åç LLM çåºæè½åæ å³ãè¿ä¸æ­¥çå®éªè¡¨æï¼R2-KG çåä»£ççæ¬éå¤äºä¸¥æ ¼çèªä¸è´æ§ç­ç¥ï¼å®ç°äºææ¾é«äºåºçº¿çå¯é æ§ï¼åæ¶éä½äºæ¨çææ¬ãç¶èï¼å®ä¹å¯¼è´äºå¤æç¥è¯å¾è°±ä¸­æ´é«çå¼æçãæä»¬çåç°å° R2-KG ç¡®ç«ä¸ºä¸ç§çµæ´»ä¸ç»æµé«æçåºäºç¥è¯å¾è°±çæ¨çè§£å³æ¹æ¡ãå®åå°äºå¯¹é«å®¹é LLM çä¾èµï¼åæ¶ç¡®ä¿äºå¯ä¿¡çæ¨çã</paragraph>


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-14**|**3D ReX: Causal Explanations in 3D Neuroimaging Classification**|Melane Navaratnarajah et.al.|[2502.12181v1](http://arxiv.org/abs/2502.12181v1)|null|
|**2025-02-13**|**Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**|Flavio Bertini et.al.|[2502.09218v1](http://arxiv.org/abs/2502.09218v1)|null|
|**2025-02-10**|**Foundation Model of Electronic Medical Records for Adaptive Risk Estimation**|Pawel Renc et.al.|[2502.06124v1](http://arxiv.org/abs/2502.06124v1)|null|
|**2025-01-27**|**An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**|Shaheer Ahmad Khan et.al.|[2501.15969v1](http://arxiv.org/abs/2501.15969v1)|null|
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v2](http://arxiv.org/abs/2501.09628v2)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v2](http://arxiv.org/abs/2412.16086v2)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v2](http://arxiv.org/abs/2411.17645v2)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-13**|**Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**|Mercy Asiedu et.al.|[2409.09201v3](http://arxiv.org/abs/2409.09201v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust in Healthcare**|Antonio Rago et.al.|[2408.17401v2](http://arxiv.org/abs/2408.17401v2)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v2](http://arxiv.org/abs/2406.06728v2)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|

#### Abstracts
##### **3D ReX: Causal Explanations in 3D Neuroimaging Classification**
2502.12181v1 by Melane Navaratnarajah, Sophie A. Martin, David A. Kelly, Nathan Blake, Hana Chocker

Explainability remains a significant problem for AI models in medical
imaging, making it challenging for clinicians to trust AI-driven predictions.
We introduce 3D ReX, the first causality-based post-hoc explainability tool for
3D models. 3D ReX uses the theory of actual causality to generate
responsibility maps which highlight the regions most crucial to the model's
decision. We test 3D ReX on a stroke detection model, providing insight into
the spatial distribution of features relevant to stroke.

æè¦ï¼è§£éæ§ä»ç¶æ¯é«çå½±åä¸­ AI æ¨¡åçä¸å¤§åé¡ï¼éä½¿å¾è¨åºé«çé£ä»¥ä¿¡ä»» AI é©åçé æ¸¬ã
æåå¼å¥äº 3D ReXï¼éæ¯ç¬¬ä¸åç¨æ¼ 3D æ¨¡åçåºæ¼å æéä¿çäºå¾è§£éæ§å·¥å·ã3D ReX ä½¿ç¨å¯¦éå æéä¿çè«ä¾çæè²¬ä»»åï¼è©²åçªåºäºå°æ¨¡åæ±ºç­è³ééè¦çååãæåå¨ä¸­é¢¨æª¢æ¸¬æ¨¡åä¸æ¸¬è©¦äº 3D ReXï¼æä¾äºèä¸­é¢¨ç¸éç¹å¾µçç©ºéåä½çè¦è§£ã

##### **Data2Concept2Text: An Explainable Multilingual Framework for Data Analysis Narration**
2502.09218v1 by Flavio Bertini, Alessandro Dal PalÃ¹, Federica Zaglio, Francesco Fabiano, Andrea Formisano

This paper presents a complete explainable system that interprets a set of
data, abstracts the underlying features and describes them in a natural
language of choice. The system relies on two crucial stages: (i) identifying
emerging properties from data and transforming them into abstract concepts, and
(ii) converting these concepts into natural language. Despite the impressive
natural language generation capabilities demonstrated by Large Language Models,
their statistical nature and the intricacy of their internal mechanism still
force us to employ these techniques as black boxes, forgoing trustworthiness.
Developing an explainable pipeline for data interpretation would allow
facilitating its use in safety-critical environments like processing medical
information and allowing non-experts and visually impaired people to access
narrated information. To this end, we believe that the fields of knowledge
representation and automated reasoning research could present a valid
alternative. Expanding on prior research that tackled the first stage (i), we
focus on the second stage, named Concept2Text. Being explainable, data
translation is easily modeled through logic-based rules, once again emphasizing
the role of declarative programming in achieving AI explainability. This paper
explores a Prolog/CLP-based rewriting system to interpret concepts-articulated
in terms of classes and relations, plus common knowledge-derived from a generic
ontology, generating natural language text. Its main features include
hierarchical tree rewritings, modular multilingual generation, support for
equivalent variants across semantic, grammar, and lexical levels, and a
transparent rule-based system. We outline the architecture and demonstrate its
flexibility through some examples capable of generating numerous diverse and
equivalent rewritings based on the input concept.

æè¦ï¼<paragraph>éç¯è«ææåºäºä¸åå®æ´çå¯è§£éç³»çµ±ï¼å®å¯ä»¥è§£éä¸çµè³æï¼æ½è±¡åºåºç¤ç¹å¾µï¼ä¸¦ä»¥é¸æçèªç¶èªè¨æè¿°å®åãç³»çµ±ä¾è³´å©åééµéæ®µï¼(i) å¾è³æä¸­è­å¥æ°èå±¬æ§ï¼ä¸¦å°å®åè½æçºæ½è±¡æ¦å¿µï¼ä»¥å (ii) å°éäºæ¦å¿µè½æçºèªç¶èªè¨ãåç®¡å¤§åèªè¨æ¨¡åå±ç¤ºäºä»¤äººå°è±¡æ·±å»çèªç¶èªè¨çæè½åï¼ä½å®åççµ±è¨æ§è³ªåå§é¨æ©å¶çè¤éæ§ä»ç¶è¿«ä½¿æåå°éäºæè¡ç¨ä½é»çå­ï¼æ¾æ£å¯ä¿¡åº¦ãéç¼ä¸åå¯è§£éçè³æè§£éç®¡éå°æå©æ¼ä¿é²å¨å®å¨ééµç°å¢ä¸­ä½¿ç¨å®ï¼ä¾å¦èçé«çè³è¨ï¼ä¸¦åè¨±éå°å®¶åè¦éäººå£«å­åæè¿°è³è¨ãçºæ­¤ï¼æåç¸ä¿¡ç¥è­è¡¨ç¤ºåèªåæ¨çç ç©¶é åå¯ä»¥æåºä¸åææçæ¿ä»£æ¹æ¡ãå¨æ´å±è§£æ±ºç¬¬ä¸éæ®µ (i) çååç ç©¶çåºç¤ä¸ï¼æåå°æ³¨æ¼ç¬¬äºéæ®µï¼ç¨±çº Concept2Textãç±æ¼å·æå¯è§£éæ§ï¼è³æç¿»è­¯å¾å®¹æééåºæ¼éè¼¯çè¦åå»ºæ¨¡ï¼åæ¬¡å¼·èª¿å®£åå¼ç¨å¼è¨­è¨å¨å¯¦ç¾ AI å¯è§£éæ§ä¸­çä½ç¨ãæ¬ææ¢è¨äºä¸ååºæ¼ Prolog/CLP çéå¯«ç³»çµ±ï¼ä»¥è§£éæ¦å¿µï¼éäºæ¦å¿µä»¥é¡å¥åéä¿çå½¢å¼è¡¨éï¼åå ä¸å¾éç¨æ¬ä½è¡ççå¸¸è­ï¼ç¢çèªç¶èªè¨æå­ãå®çä¸»è¦ç¹é»åæ¬éå±¤æ¨¹éå¯«ãæ¨¡çµåå¤èªè¨çæãæ¯æ´èªç¾©ãèªæ³åè©å½å±¤é¢çç­æè®é«ï¼ä»¥åä¸åéæçåºæ¼è¦åçç³»çµ±ãæåæ¦è¿°äºæ¶æ§ï¼ä¸¦ééä¸äºç¯ä¾å±ç¤ºäºå®çéæ´»æ§ï¼éäºç¯ä¾è½å¤ æ ¹æè¼¸å¥æ¦å¿µçæè¨±å¤ä¸åçç­æéå¯«ã</paragraph>

##### **Foundation Model of Electronic Medical Records for Adaptive Risk Estimation**
2502.06124v1 by Pawel Renc, Michal K. Grzeszczyk, Nassim Oufattole, Deirdre Goode, Yugang Jia, Szymon Bieganski, Matthew B. A. McDermott, Jaroslaw Was, Anthony E. Samir, Jonathan W. Cunningham, David W. Bates, Arkadiusz Sitek

We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS),
an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS
predicts future PHTs using transformer-based architectures. The Adaptive Risk
Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk
probabilities for clinician-defined critical events. ARES incorporates a
personalized explainability module that identifies key clinical factors
influencing risk estimates for individual patients. ARES was evaluated on the
MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its
performance against traditional early warning systems and machine learning
models. We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs,
with 60% including hospital admissions. The dataset contained over 357 million
tokens. ETHOS outperformed benchmark models in predicting hospital admissions,
ICU admissions, and prolonged hospital stays, achieving superior AUC scores.
ETHOS-based risk estimates demonstrated robustness across demographic subgroups
with strong model reliability, confirmed via calibration curves. The
personalized explainability module provides insights into patient-specific
factors contributing to risk. ARES, powered by ETHOS, advances predictive
healthcare AI by providing dynamic, real-time, and personalized risk estimation
with patient-specific explainability to enhance clinician trust. Its
adaptability and superior accuracy position it as a transformative tool for
clinical decision-making, potentially improving patient outcomes and resource
allocation in emergency and inpatient settings. We release the full code at
github.com/ipolharvard/ethos-ares to facilitate future research.

æè¦ï¼æåéç¼äºå¢å¼·åå¥åº·çµææ¨¡æ¬è½æå¨ (ETHOS)ï¼
ä¸ç¨®å¾é»å­å¥åº·ç´é (EHR) ä¸­å°æ£èå¥åº·æéè»¸ (PHT) æ¨è¨åç AI æ¨¡åãETHOS
ä½¿ç¨åºæ¼è½æå¨çæ¶æ§é æ¸¬æªä¾ç PHTãèªé©æé¢¨éªè©ä¼°ç³»çµ± (ARES) ä½¿ç¨ ETHOS è¨ç®ç±è¨åºé«çå®ç¾©çå±æ¥äºä»¶çåæä¸åäººåçé¢¨éªæ©çãARES çµåäºåäººåçå¯è§£éæ§æ¨¡çµï¼å¯æ¾åºå½±é¿åå¥æ£èé¢¨éªè©ä¼°çä¸»è¦è¨åºå ç´ ãARES å¨æ¥è¨ºé¨é (ED) è¨­å®ä¸­éå° MIMIC-IV v2.2 è³æéé²è¡è©ä¼°ï¼ä¸¦å°å¶æè½èå³çµ±çé è­¦ç³»çµ±åæ©å¨å­¸ç¿æ¨¡åé²è¡åºæºæ¸¬è©¦ãæåå° 299,721 ä½ MIMIC-IV çç¨ç¹æ£èèçæ 285,622 å PHTï¼å¶ä¸­ 60% åå«ä½é¢è¨éãè©²è³æéåå«è¶é 3.57 ååæ¨è¨ãETHOS å¨é æ¸¬ä½é¢ãå è­·çæ¿ (ICU) ä½é¢åå»¶é·ä½é¢æéæ¹é¢è¡¨ç¾åªæ¼åºæºæ¨¡åï¼ä¸¦ç²å¾äºè¼é«ç AUC åæ¸ãåºæ¼ ETHOS çé¢¨éªè©ä¼°é¡¯ç¤ºåºè·¨äººå£çµ±è¨å­ç¾¤çç©©å¥æ§ï¼ä¸¦ééæ ¡æºæ²ç·ç¢ºèªäºå¼·å¤§çæ¨¡åå¯é æ§ãåäººåçå¯è§£éæ§æ¨¡çµæä¾äºå°å°è´é¢¨éªçæ£èç¹å®å ç´ çè¦è§£ãç± ETHOS é©åç ARES ééæä¾åæãå³æä¸åäººåçé¢¨éªè©ä¼°ï¼ä»¥åæ£èç¹å®çå¯è§£éæ§ä¾å¢å¼·è¨åºé«ççä¿¡ä»»ï¼å¾èæ¨åäºé æ¸¬æ§é«çä¿å¥ AI çç¼å±ãå¶é©ææ§ååè¶çæºç¢ºæ§ä½¿å¶æçºè¨åºæ±ºç­å¶å®çä¸ç¨®è®é©æ§å·¥å·ï¼æå¯è½æ¹åç·æ¥åä½é¢ç°å¢ä¸­çæ£èçµæåè³æºåéãæåå¨ github.com/ipolharvard/ethos-ares ä¸éåºå®æ´ç¨å¼ç¢¼ï¼ä»¥å©æªä¾çç ç©¶ã

##### **An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**
2501.15969v1 by Shaheer Ahmad Khan, Muhammad Usamah Shahid, Ahmad Abdullah, Ibrahim Hashmat, Muddassar Farooq

This study addresses a critical gap in the healthcare system by developing a
clinically meaningful, practical, and explainable disease surveillance system
for multiple chronic diseases, utilizing routine EHR data from multiple U.S.
practices integrated with CureMD's EMR/EHR system. Unlike traditional
systems--using AI models that rely on features from patients' labs--our
approach focuses on routinely available data, such as medical history, vitals,
diagnoses, and medications, to preemptively assess the risks of chronic
diseases in the next year. We trained three distinct models for each chronic
disease: prediction models that forecast the risk of a disease 3, 6, and 12
months before a potential diagnosis. We developed Random Forest models, which
were internally validated using F1 scores and AUROC as performance metrics and
further evaluated by a panel of expert physicians for clinical relevance based
on inferences grounded in medical knowledge. Additionally, we discuss our
implementation of integrating these models into a practical EMR system. Beyond
using Shapley attributes and surrogate models for explainability, we also
introduce a new rule-engineering framework to enhance the intrinsic
explainability of Random Forests.

æè¦ï¼æ¬ç ç©¶éééç¼ä¸åè¨åºææç¾©ãå¯¦ç¨ä¸å¯è§£éçå¤éæ¢æ§ç¾çç¾çç£æ¸¬ç³»çµ±ï¼ä¾è§£æ±ºé«çä¿å¥ç³»çµ±ä¸­çéå¤§ç¼ºå£ï¼å©ç¨æ´å CureMD ç EMR/EHR ç³»çµ±ï¼ä¾èªå¤åç¾åå¯¦åçä¾è¡ EHR è³æãèå³çµ±ç³»çµ±ä¸åçæ¯ï¼æåçåæ³èéå¨ä¾è¡å¯å¾çè³æï¼ä¾å¦çæ­·ãçå½å¾µè±¡ãè¨ºæ·åè¥ç©ï¼ä»¥é åè©ä¼°æªä¾ä¸å¹´æ¢æ§ç¾ççé¢¨éªï¼èéä»°è³´çæ£å¯¦é©å®¤ç¹å¾µç AI æ¨¡åãæåéå°æ¯ç¨®æ¢æ§ç¾çè¨ç·´äºä¸åä¸åçæ¨¡åï¼é æ¸¬æ¨¡åï¼ç¨ä»¥é æ¸¬å¨æ½å¨è¨ºæ·å 3ã6 å 12 åæçç¾çé¢¨éªãæåéç¼äºé¨æ©æ£®ææ¨¡åï¼ä¸¦ä½¿ç¨ F1 åæ¸å AUROC ä½çºæè½ææ¨ï¼é²è¡å§é¨é©è­ï¼ä¸¦é²ä¸æ­¥ç±å°å®¶é«å¸«å°çµæ ¹ææ¤åºæ¼é«å­¸ç¥è­çæ¨è«ï¼è©ä¼°å¶è¨åºç¸éæ§ãæ­¤å¤ï¼æåè¨è«äºå°éäºæ¨¡åæ´åå°å¯¦ç¨ EMR ç³»çµ±ä¸­çå¯¦ä½æ¹å¼ãé¤äºä½¿ç¨ Shapley å±¬æ§åä»£çæ¨¡åä¾è§£éå¤ï¼æåéå¼é²äºä¸åæ°çè¦åå·¥ç¨æ¶æ§ï¼ä»¥å¢å¼·é¨æ©æ£®æçå§å¨å¯è§£éæ§ã

##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

æè¦ï¼æ·±åº¦ç¥ç»ç½ç»è¶æ¥è¶å¤å°ç¨äºé«é£é©å»çåºç¨ä¸­ï¼å°½ç®¡å®ä»¬å¨å­å¨èåç¸å³æ§çæåµä¸å¾åäºæ·å¾å­¦ä¹ ï¼è¿å¨å®è·µä¸­å¯è½äº§çè´å½çåæãæ£æµåç¼è§£æ·å¾è¡ä¸ºæ¯ä¸é¡¹è°å·¨çä»»å¡ï¼éå¸¸éè¦é¢åä¸å®¶çå¤§éæ è®°å·¥ä½ãä¸ºäºç¼è§£è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªåèªå¨æ¡æ¶ï¼ç¨äºä»æ°æ®åæ¨¡åçè§åº¦è¯å«èåè¡ä¸ºï¼æ¹æ³æ¯å©ç¨å¯è§£éäººå·¥æºè½ (XAI) çè§è§£ãè¿åè®¸æ£ç´¢èåæ°æ®ç¹å¹¶æ£æµå¯¹å³èé¢æµè§åè¿è¡ç¼ç çæ¨¡åçµè·¯ãæ­¤å¤ï¼æä»¬æ¼ç¤ºäºå¦ä½ä½¿ç¨è¿äºæ·å¾ç¼ç è¿è¡åºäº XAI çæ ·æ¬ååç´ çº§æ°æ®æ³¨éï¼ä¸ºåå·®ç¼è§£æ¹æ³æä¾æä»·å¼çä¿¡æ¯ï¼ä»¥æ¶é¤ä¸éè¦çæ·å¾è¡ä¸ºãæä»¬ä½¿ç¨è·¨è¶ä¸¤ç§æ¹å¼çåä¸ªå»å­¦æ°æ®éå±ç¤ºäºæä»¬æ¡æ¶çéç¨æ§ï¼è¿äºæ°æ®éå·æç±æ°æ®ä¼ªåå¼èµ·çåæ§åçå®ä¸çèåç¸å³æ§ãæä»¬æåå°è¯å«å¹¶åè½»äº VGG16ãResNet50 åå½ä»£ Vision Transformer æ¨¡åä¸­çè¿äºåå·®ï¼æç»æé«äºå®ä»¬çé²æ£æ§åå¨çå®ä¸çå»çä»»å¡ä¸­çéç¨æ§ã

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

æè¦ï¼èªæ®ºæå¿µåµæ¸¬å°æ¼é é²èªæ®ºè³ééè¦ï¼èèªæ®ºæ¯å¨çä¸»è¦çæ­»äº¡åå ãè¨±å¤äººå¨ç¤¾ç¾¤åªé«ä¸è¡¨éèªæ®ºå¿µé ­ï¼éæä¾äºééé²éæ©å¨å­¸ç¿æè¡é²è¡æ©æåµæ¸¬çéè¦æ©æãééæ´åå·ç©ç¥ç¶ç¶²è·¯ (CNN) åéåé·ç­æè¨æ¶ (BiLSTM) çæ··åæ¶æ§ï¼ä¸¦å å¥æ³¨æåæ©å¶ï¼å¯ä»¥æåå¨ç¤¾ç¾¤åªé«æå­ä¸­è¾¨è­èªæ®ºæå¿µçè½åãçºäºå å¼·æ¨¡åé æ¸¬çå¯è§£éæ§ï¼æåæ¡ç¨å¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ï¼ç¹å¥èéæ¼ SHapley å æ³è§£é (SHAP)ãä¸éå§ï¼æ¨¡åæåéå° 92.81% çæºç¢ºåº¦ãééå¥ç¨å¾®èª¿åæ©æåæ­¢æè¡ï¼æºç¢ºåº¦æåè³ 94.29%ãSHAP åææ­é²äºå½±é¿æ¨¡åé æ¸¬çééµç¹å¾µï¼ä¾å¦èå¿çå¥åº·å°å¢ç¸éçè©å½ãéç¨®éæåº¦æåäºæ¨¡åçå¯ä¿¡åº¦ï¼åæåå©å¿çå¥åº·å°æ¥­äººå¡çè§£åä¿¡è³´é æ¸¬çµæãéé å·¥ä½çªé¡¯äºæååµæ¸¬èªæ®ºå¾åçæºç¢ºåº¦åå¯è§£éæ§çæ½åï¼çºå¿çå¥åº·ç£æ§ç³»çµ±çé²å±ååºå¯¶è²´çè²¢ç»ãå®å¼·èª¿äºå°å¼·å¤§çæ©å¨å­¸ç¿æ¹æ³èå¯è§£éæ§ç¸çµåä»¥éç¼å¯é ä¸æå½±é¿åçå¿çå¥åº·è§£æ±ºæ¹æ¡çéè¦æ§ã

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, LÃ©a MaÃ®tre, RÃ©my Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

æè¦ï¼å¨æµè¡çå­¸ä¸­ï¼å³çµ±ççµ±è¨æ¹æ³ï¼ä¾å¦éè¼¯è¿´æ­¸ãç·æ§è¿´æ­¸åå¶ä»åæ¸æ¨¡åéå¸¸ç¨æ¼èª¿æ¥é æ¸¬å å­èå¥åº·çµæä¹éçéè¯ãç¶èï¼éåæ¸æ©å¨å­¸ç¿æè¡ï¼ä¾å¦æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN)ï¼çµåå¯è§£éç AI (XAI) å·¥å·ï¼çºéé ä»»åæä¾äºæ°çæ©æãåç®¡éäºæ¹æ³å·ææ½åï¼ä½ç±æ¼è©²é åç¼ºä¹é«åè³ªãé«æ¸éè³æï¼å æ­¤éäºæ¹æ³é¢è¨ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äº SEANNï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼ç²åç¥è­ç DNNï¼å®å©ç¨äºä¸ç¨®æµè¡çé åç¹å®ç¥è­å½¢å¼ï¼å½ç¸½ææé (PES)ãPES éå¸¸ä»¥ä¸åçå½¢å¼åºç¾å¨å·²ç¼è¡¨ç Meta åæç ç©¶ä¸­ï¼ä¸¦ä»£è¡¨ç§å­¸å±è­çéåå½¢å¼ãééä½¿ç¨èªè¨æå¤±å½æ¸ç´æ¥æ´åå¨å­¸ç¿ç¨åºä¸­ï¼æåä»¥å¯¦é©æ¹å¼è­æäºé æ¸¬æè½çæ¦æ¬æ§ä»¥åèå¾ç¼ºä¹é åç¥è­çç¥ç¶ç¶²è·¯ä¸­æåçéä¿ç¸æ¯ï¼ç§å­¸åçæ§çé¡¯èæåï¼ä¸æ¯å¨ç¨å°ä¸æéè¨çè³æè¨­å®ä¸­ã

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v2 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

æè¦ï¼é¨èäººå·¥æºæ§ï¼AIï¼å¨é«çä¿å¥æåä¸­æ¥çæ®åï¼æ¬ç« æ¢è¨äºéç¼å¯é ä¸ç¬¦åéå¾·çè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) çééµé¢åãå¾å³çµ±çµ±è¨æ¨¡åè½è®å°è¤éæ©å¨å­¸ç¿æ¹æ³çåºæ¬åçéå§ï¼éé å·¥ä½æ¢è¨äºå´è¬¹çé©è­ç­ç¥åæè½è©ä¼°æ¹æ³ï¼åæ¬æ¨¡åæ ¡æºåæ±ºç­æ²ç·åæçééµè§è²ãæ¬ç« å¼·èª¿ï¼å¨é«çä¿å¥ä¸­å»ºç«å¼å¾ä¿¡è³´ç AI ç³»çµ±ä¸åéè¦æè¡æºç¢ºæ§ï¼å®éè¦ä»ç´°èéå¬å¹³æ§ãå¯è§£éæ§åé±ç§ãæ¬ç« å¼·èª¿äºéé AI ç¢ºä¿å¬å¹³é«çä¿å¥æåçææ°ï¼ä¸¦è¨è«äºè­å¥åæ¸è¼è¨åºé æ¸¬æ¨¡åä¸­åå·®çæ¹æ³ãæ¥èï¼æ¬ç« æ·±å¥æ¢è¨å¯è§£éæ§ä½çºä»¥äººçºä¸­å¿ç CDSS çåºç³ãéç¨®éæ³¨åæ äºå°é«çä¿å¥å°æ¥­äººå¡ä¸åå¿é ä¿¡ä»» AI å»ºè­°ï¼éå¿é çè§£å¶èå¾æ¨çççè§£ãè¨è«é²å±å°å°é«ç AI ç³»çµ±ä¸­é±ç§æ¼æ´çåæï¼å¾æ·±åº¦å­¸ç¿æ¨¡åä¸­çè³æå¤æ´©å°éå°æ¨¡åè§£éçè¤éæ»æãæ¬ææ¢è¨äºé±ç§ä¿è­·ç­ç¥ï¼ä¾å¦å·®åé±ç§åè¯åå­¸ç¿ï¼åææ¿èªé±ç§ä¿è­·åæ¨¡åæè½ä¹éçåºææ¬è¡¡ãå¾æè¡é©è­å°éå¾·èéï¼éç¨®é²å±åæ äºéç¼ AI ç³»çµ±çå¤æ¹é¢ææ°ï¼éäºç³»çµ±å¯ä»¥ç¡ç¸«ä¸å¯é å°æ´åå°æ¥å¸¸è¨åºå¯¦åä¸­ï¼åæç¶­ææé«æ¨æºçæ£èç§è­·åè³æä¿è­·ã

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

æè¦ï¼éçæ·±åº¦å­¦ä¹ æ¨¡åå¨å»å­¦æ°æ®ä¸­è·å¾å³æ³¨ï¼ç¡®ä¿éæä¸å¼å¾ä¿¡èµçå³ç­è³å³éè¦ãå¨ç®è¤çè¯æ­ä¸­ï¼è½ç¶çç¶æ£æµååç±»çè¿æ­¥æé«äºåç¡®æ§ï¼ä½è¿äºæ¹æ³çé»çæ§è´¨å¯¹çè§£å¶å³ç­è¿ç¨ææäºææï¼å¯¼è´å»çä¹é´çä¿¡ä»»é®é¢ãæ¬ç ç©¶å©ç¨å¨ä¸åç®è¤çåæ°æ®éä¸è®­ç»ç CLIPï¼å¯¹æ¯è¯­è¨å¾åé¢è®­ç»ï¼æ¨¡åï¼ä»¥ææè§è§ç¹å¾åè¯æ­æ åæ¯è¯­ä¹é´çææä¹å³ç³»ãä¸ºäºè¿ä¸æ­¥æé«éæåº¦ï¼æä»¬æåºäºä¸ç§åä¸º MedGrad E-CLIP çæ¹æ³ï¼è¯¥æ¹æ³éè¿ç»åä¸ä¸ºç®è¤çåç­å¤æå»å­¦å½±åè®¾è®¡çå æçµæºå¶ï¼å»ºç«å¨åºäºæ¢¯åº¦ç E-CLIP ä¹ä¸ãæ­¤æ¹æ³çªåºäºä¸ç¹å®è¯æ­æè¿°ç¸å³èçå³é®å¾ååºåãå¼åçéæç®¡éä¸ä»éè¿å¹éç¸åºçæè¿°å¯¹ç®è¤çåè¿è¡åç±»ï¼è¿æ·»å äºä¸å±ä¸é¨ä¸ºå»å­¦æ°æ®å¼åçåºæ¬å¯è§£éæ§ãéè¿ç´è§å°è§£éå¾åä¸­ä¸åç¹å¾ä¸è¯æ­æ åçå³ç³»ï¼è¿ç§æ¹æ³å±ç¤ºäºé«çº§è§è§è¯­è¨æ¨¡åå¨å»å­¦å¾ååæä¸­çæ½åï¼æç»æé«äºéæåº¦ãç¨³å¥æ§åå¯¹äººå·¥æºè½é©±å¨çè¯æ­ç³»ç»çä¿¡ä»»ã

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

æè¦ï¼å¹½é»é¢¨æ ¼å°å¹¸ç¦æå¯è½ç¢çè² é¢ææ­£é¢çå½±é¿ã
éæ¼éäºé¢¨æ ¼å°å¿çå¥åº·çéè¦æ§ï¼å·²ç¶å°å¶èªåè­å¥é²è¡äºå¤§éç ç©¶ãç¶èï¼ç¨æ¼æ­¤ç®ççèªåæ©å¨å­¸ç¿æ¨¡åæ¯é»çå­ï¼ä½¿å¾å¶é æ¸¬æ±ºç­ä¸éæãæ¸æ°åº¦åéæåº¦å¨å¿çå¥åº·é åè³ééè¦ãæ¬ææåºäºä¸åå¯è§£éç AI (XAI) æ¡æ¶ï¼ç¨æ¼çè§£å¹½é»é¢¨æ ¼åé¡ï¼å»ºç«å¨è¨ç®å¹½é»åæçååå·¥ä½ä¹ä¸ãä½¿ç¨ååç ç©¶ä¸­è¡¨ç¾æå¥½çå®ä¸æ¨¡å (ALI+XGBoost)ï¼æåæç¨å¨é¢ç XAI æè¡ä¾åæèªè¨ãæç·åèªç¾©ç¹å¾µå¦ä½å½±é¿å¹½é»é¢¨æ ¼åé¡æ±ºç­ãæåçåææ­ç¤ºäºä¸åå¹½é»é¢¨æ ¼å¦ä½è¢«è¡¨å¾µåé¯èª¤åé¡çä¸åæ¨¡å¼ï¼ç¹å¥å¼·èª¿äºååè¯å±¬å¹½é»èå¶ä»é¢¨æ ¼çææ°ãééä»ç´°æª¢æ¥ç¹å¾µéè¦æ§ãé¯èª¤æ¨¡å¼åé¯èª¤åé¡æ¡ä¾ï¼æåç¢ºå®äºå½±é¿æ¨¡åæ±ºç­çééµå ç´ ï¼åæ¬æç·æ¨¡ç³ãæå¢èª¤è§£åç®æ¨è­å¥ãè©²æ¡æ¶å±ç¤ºäºå¨çè§£æ¨¡åè¡çºæ¹é¢çé¡¯èæç¨ï¼å¯¦ç¾äºå°å®ç¾©ä¸åå¹½é»é¢¨æ ¼çç¹å¾µä¹éè¤éç¸äºä½ç¨çå¯è§£éè¦è§£ãæåçç¼ç¾æå©æ¼è¨ç®å¹½é»åæççè«çè§£åå¿çå¥åº·ãå§å®¹å¯©æ ¸åæ¸å­äººæç ç©¶ä¸­çå¯¦éæç¨ã

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

æè¦ï¼é¨èå°å¿çå¥åº·æåéæ±çå¢å ï¼å¸é¡¯äºåµæ°è§£æ±ºæ¹æ¡çéæ±ï¼ç¹å¥æ¯å¨å¿çå°è©±å¼äººå·¥æºæ§é åï¼é£è£¡ç¼ºä¹ææè³æãå¨éé å·¥ä½ä¸­ï¼æåæ¢ç´¢äºéç¼ä¸åéå°å¿çå¥åº·æ¯æçç³»çµ±ï¼æ¡ç¨ä¸ç¨®åºæ¼å¯è§£éçæç·ç¹å¾µçæ°æ¹æ³é²è¡å¿çè©ä¼°ï¼çµååçå¿å°è©±æ¨¡å¼ï¼æä¾äºä¸åæåéçå·¥å·ï¼ç¨æ¼æ´åå³çµ±ç§è­·ï¼ç¹å¥æ¯å¨ç¡æ³ç«å³ç²å¾å°æ¥­ç¥è­çææ³ä¸ãæåçå·¥ä½å¯ä»¥åçºå©åä¸»è¦é¨åï¼å½¼æ­¤å§å¨ç¸éãé¦åï¼æåå±ç¤ºäº RACLETTEï¼ä¸åå°è©±ç³»çµ±ï¼èæåé²çåºæºç¸æ¯ï¼å¨çè§£ä½¿ç¨èæç·çæåå¨å°è©±ä¸­ç¢çåçå¿åææ¹é¢è¡¨ç¾åºåªè¶çæç·æºç¢ºæ§ï¼åæééä»åçäºåéæ¼¸å»ºç«ä½¿ç¨èçæç·ç¹å¾µãå¶æ¬¡ï¼æåå±ç¤ºäºä½¿ç¨èçæç·ç¹å¾µå¦ä½å¯ç¨ä½å¿çå¥åº·è©ä¼°çå¯è§£éæ¨è¨ãéäºç¹å¾µå¯ä»¥èèä¸åå¿çç¾çç¸éçå¸åæç·æ¨¡å¼é²è¡æ¯è¼ï¼æä¾äºä¸ç¨®åæ­¥ç¯©é¸åæ¯æçæ°æ¹æ³ã

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²æçºå¢å¼·é«å¤åç²¾ï¼IVFï¼æ±ºç­å¶å®ååªåæ²»çæ¹æ¡çå¼·å¤§å·¥å·ãç¹å¥æ¯ï¼AI å¨æ¯æ IVF éç¨ä¸­åµå·¢åºæ¿éæ®µçæ±ºç­å¶å®æ¹é¢é¡¯ç¤ºåºé¡¯èçåæ¯ãæ¬ç¶è¿°è©ä¼°äºå°æ³¨æ¼ AI çµååµå·¢åºæ¿ä¸­çé«å­¸å½±åæç¨ãæª¢é©æ¹æ³ãçµæåç¶åéå¶çç ç©¶ãæåå° 13 é éæ¼æ­¤ä¸»é¡çç ç©¶åæé¡¯ç¤ºï¼éç¶ AI æ¼ç®æ³å¨é æ¸¬æä½³è·ç¾èåéãè§¸ç¼ææ©ååµå­ååºçµææ¹é¢è¡¨ç¾åºé¡¯èçæ½åï¼ä½æå©ç¨çé«å­¸å½±åæ¸æä¸»è¦ä¾èªæ¼äºæ¬¡åï¼2Dï¼è¶é³æ³¢ï¼èäºæ¬¡åè¶é³æ³¢ä¸»è¦æ¶ååºæ¬éåï¼ä¾å¦æ¿¾æ³¡å¤§å°åæ¸éï¼ä¸æéä½¿ç¨ç´æ¥ç¹å¾µæåæé²éå½±ååææè¡ãéæåä¸åå°æªæ¢ç´¢çæ©æï¼ä¾å¦æ·±åº¦å­¸ç¿ç­é²éå½±ååææ¹æ³ï¼ä»¥åæ´å¤åçå½±åæ¨¡å¼ï¼ä¾å¦ä¸ç¶­ï¼3Dï¼è¶é³æ³¢ï¼å¯ä»¥è§£éæ´æ·±å¥çè¦è§£ãæ­¤å¤ï¼å¤§å¤æ¸ç ç©¶ç¼ºä¹å¯è§£é AIï¼XAIï¼ï¼éå¼èµ·äºäººåå° AI é©åæ±ºç­çéæåº¦åå¯è¿½æº¯æ§çææï¼èéæåº¦åå¯è¿½æº¯æ§æ¯è¨åºæ¡ç¨åä¿¡ä»»çééµå ç´ ãæ­¤å¤ï¼è¨±å¤ç ç©¶ä¾è³´æ¼å®ä¸­å¿è¨­è¨åå°åæ¸æéï¼ééå¶äºå¶ç¼ç¾çæ®éæ§ãæ¬ç¶è¿°å¼·èª¿äºå°é²éå½±ååææè¡èå¯è§£é AI æ¹æ³æ´åèµ·ä¾çå¿è¦æ§ï¼ä»¥åå©ç¨å¤ä¸­å¿åä½åå¤§åæ¸æéçéè¦æ§ãè§£æ±ºéäºå·®è·æå¯è½å¢å¼·åµå·¢åºæ¿ç®¡çï¼çºææãåäººååæ¸æé©åçæ²»çéå¾éªå¹³éè·¯ï¼é²èæ¹å IVF çµæã

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ååµæ°çççè¨ºæ·åé æ¸¬æ¹æ³ï¼ä½¿ç¨å¯è§£éçäººå·¥æºæ§ (XAI) åæ·±åº¦å­¸ç¿æè¡ãç±æ¼ççå¨ 2020 å¹´é æå¨çè¿ 1,000 è¬äººæ­»äº¡ï¼å æ­¤æ©ææºç¢ºçè¨ºæ·è³ééè¦ãå³çµ±æ¹æ³éå¸¸é¢è¨ææ¬ãæºç¢ºæ§åæçæ¹é¢çææ°ãæåçç ç©¶éç¼äºä¸å AI æ¨¡åï¼å®æä¾ç²¾ç¢ºççµæä¸¦æ¸æ¥å°äºè§£å¶æ±ºç­éç¨ï¼è§£æ±ºäºæ·±åº¦å­¸ç¿æ¨¡åçãé»ç®±ãåé¡ãééæ¡ç¨ XAI æè¡ï¼æåå¢å¼·äºè§£éæ§åéæåº¦ï¼å¨é«çå°æ¥­äººå¡åæ£èä¹éå»ºç«ä¿¡ä»»ãæåçåæ³å©ç¨ç¥ç¶ç¶²è·¯åæå»£æ³çæ¸æéï¼è­å¥ççæª¢æ¸¬æ¨¡å¼ãéåæ¨¡åæå¯è½ééæé«é«çæ±ºç­çæºç¢ºæ§ãå¯åæ§åæ¸æ°åº¦ä¾é©æ°è¨ºæ·ï¼å¯è½å°è´æ´æ©çæª¢æ¸¬åæ´åæ§åçæ²»çç­ç¥ãæ­¤å¤ï¼å®å¯ä»¥ä½¿æ´å¤äººç²å¾é«åè³ªçè¨ºæ·ï¼ç¹å¥æ¯å¨è³æºæéçç°å¢ä¸­ï¼æå©æ¼å¨çå¥åº·å¬å¹³ãè©²æ¨¡åçæç¨ç¯åä¸åéæ¼ççè¨ºæ·ï¼éå¯è½è½è®é«çæ±ºç­çååæ¹é¢ï¼ä¸¦æ¯æå¨çæ¸ç¾è¬äººççå½ã

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v2 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings. Our code is available at
https://github.com/tifat58/IRR-with-CBM-RAG.git.

æè¦ï¼æ·±åº¦å­¸ç¿å·²æåé«å­¸å½±ååé¡ï¼ä½å¯è§£éæ§ææ°é»ç¤å¶è¨åºæç¨ãæ¬ç ç©¶ééä½¿ç¨æ¦å¿µç¶é ¸æ¨¡å (CBM) åå¤ä»£çæª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±é²è¡å ±åçæï¼ä¾å¢å¼·è¸é¨ X å (CXR) åé¡çå¯è§£éæ§ãééå»ºæ¨¡è¦è¦ºç¹å¾µèè¨åºæ¦å¿µä¹éçéä¿ï¼æåå»ºç«å¯è§£éçæ¦å¿µåéï¼å¼å°å¤ä»£ç RAG ç³»çµ±çææ¾å°å ±åï¼å¢å¼·è¨åºç¸éæ§ãå¯è§£éæ§åéæåº¦ãä½¿ç¨ LLM ä½çºè©å¯©å¡å°çæå ±åé²è¡è©ä¼°ï¼ç¢ºèªäºæåæ¨¡åè¼¸åºçå¯è§£éæ§åè¨åºæç¨ãå¨ COVID-QU è³æéä¸ï¼æåçæ¨¡åéå°äº 81% çåé¡æºç¢ºçï¼ä¸¦å±ç¤ºäºç©©å¥çå ±åçææè½ï¼äºé ééµææ¨ä»æ¼ 84% è³ 90% ä¹éãéåå¯è§£éçå¤ä»£çæ¶æ§å½åäºé«æ§è½ AI èè¨åºç°å¢ä¸­å¯é ç AI é©å CXR åææéçè§£éæ§ä¹éçå·®è·ãæåçç¨å¼ç¢¼å¯æ¼ https://github.com/tifat58/IRR-with-CBM-RAG.git åå¾ã

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

æè¦ï¼èæ¯ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) ç®åå¨é«çé åç¡æä¸å¨ï¼ä½ä»¤äººé©è¨çæ¯ï¼æ¢è¨å¶æ¨çè¡çºçç ç©¶å»ç¸ç¶ç¼ºä¹ãæåå¼·èª¿äºè§£æ¨çè¡çºèéé«å±¤ç´çé æ¸¬æºç¢ºåº¦éå¸¸éè¦ï¼å çºå¨éç¨®ææ³ä¸ï¼éç­åæ¼å¯è§£é AI (XAI)ãå°¤å¶æ¯å¨è¨åºé åä¸­ä½¿ç¨çé«ç LLM ä¸­å¯¦ç¾ XAIï¼å°å°æ´åé«çä¿å¥ç¢æ¥­ç¢çéå¤§å½±é¿ãçµæï¼å æ­¤ï¼æåå¨é«ç LLM çç¹å®èæ¯ä¸å®ç¾©äºæ¨çè¡çºçæ¦å¿µãæ¥èæååé¡ä¸¦æ¢è¨ç¶åè©ä¼°é«ç LLM ä¸­æ¨çè¡çºçæ¹æ³çææ°æè¡ãæå¾ï¼æåæåºçè«æ¶æ§ï¼è®é«çå°æ¥­äººå¡ææ©å¨å­¸ç¿å·¥ç¨å¸«å¾ä»¥æ·±å¥äºè§£éäºååæ¨¡ç³æ¨¡åçä½å±¤ç´æ¨çéç®ãçµè«ï¼è¨åºé«çåæ£èå°é«çæ©å¨å­¸ç¿æ¨¡åçéæåº¦åä¿¡ä»»åº¦é¨ä¹æåï¼å°å éé«ç AI å¨æ´åé«çä¿å¥ç³»çµ±ä¸­çæ´åãæç¨åé²ä¸æ­¥ç¼å±ã

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

æè¦ï¼å£åæ¯ä¸åæ®éçå¨çæ§å¥åº·åé¡ï¼å¯è½æå°è´å´éçç²¾ç¥
å¥åº·åé¡ãæ©æç¼ç¾æä¾åæçå¹²é åé é²
å£åç¸éç¾çãç®åçæ©æç¼ç¾æ¨¡åå·è¡ãé»
çå­ãæ¨è«ï¼å­å¨å¯è§£éæ§åä¿¡ä»»åº¦æéçåé¡ï¼é»ç¤äº
ç¾å¯¦ä¸ççè¨åºæç¨ãå¤è§äºå¤§åèªè¨æ¨¡å (LLM) å¼å¥ççæå±¬æ§ï¼æ­¤é¡
æ¨¡åçæ±ºç­åé æ¸¬ééå°ææè¿°å·æåå¯è§£éæ§ãç¶èï¼
ç¾æç LLM ä¸»è¦éå°ä¸è¬ç¨éé²è¡è¨ç·´ï¼æ²æå¿çèªç¥çè«çæå°ãçºæ­¤ï¼æåé¦åå¼·èª¿
åé©çè«çéè¦æ§ï¼ä¸¦è§å¯å°éå°å£åæª¢æ¸¬éèº«å®å¶çææ³éæåäºæ§è½ãéç¨®æ¹æ³ç¨±çºèªç¥
éééåºæ¼èªç¥è©ä¼°çè«çå¾ªåºæ¼¸é²çèªç¥è¦è§é¡æäºå£åçç¢çï¼ä¸¦å·æé²åº¦ç®¡éï¼
åºæ¿ $\rightarrow$ è©ä¼° $\rightarrow$ åæ $\rightarrow$ å£å
çæï¼æå° LLM æä¾å¨é¢çæ¨çè§£éãæåé²ä¸æ­¥
ééå°å¶ç¨ä½ LLM æä»¤èª¿æ´çåææ¸æéçææ¨¡æ¿ä¾ç ç©¶ææåºçèªç¥éæ ¼å¼å¸¶ä¾çåªé»ï¼ä¸¦ä»ç´¹ CogInstructï¼éæ¯ä¸åéå°å£åæª¢æ¸¬çæä»¤èª¿æ´æ¸æéãéå
æ¸æéæ¯ä½¿ç¨ä¸åä¸éæ®µçèªçæ¨è¨»ç®¡ééç¼çï¼ä½¿ LLM è½å¤ èªä¸»çæååªåæä»¤æ¸æãéé
ä½¿ç¨ CogInstruct å° Llama3 é²è¡æä»¤èª¿æ´ï¼æåéç¼äº CogLLMï¼éæ¯ä¸åå¯è§£éç
å£åæª¢æ¸¬æ¨¡åãè©ä¼°è¡¨æï¼CogLLM å¨æé«å¯è§£éæ§çåæå¯¦ç¾äºåºè²çæ§è½ãæåçç ç©¶ééå°èªç¥çè«æ´åå° LLM æ¨çéç¨ä¸­ï¼æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼
çºæªä¾çå¯è§£éäººå·¥æºè½ç ç©¶æä¾äºä¸åæå¸æçæ¹åã

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

æè¦ï¼äººæ©åä½å¨é«ç AI ä¸­ï¼éè¦æåçè§£åéè¨ç·´çè¨åºé«çå¨å¤å¤§ç¨åº¦ä¸æéè¦ AI é æ¸¬ãéç¶ååçç ç©¶é¡¯ç¤º AI è¼å©å¨æ¹åè¨åºé æ¸¬æ¹é¢çæ½åï¼ä½ç¾æçè¨åºæ±ºç­æ¯æ´ç³»çµ±ï¼è¦ä¸å°±æ²ææä¾é æ¸¬çå¯è§£éæ§ï¼è¦ä¸å°±æ¯ä½¿ç¨åé¡¯èæ§å Shapley å¼ä¹é¡çæè¡ï¼éäºæè¡ä¸åè¨±åºæ¼é«ççé©è­ãçºäºè§£æ±ºéåå·®è·ï¼æ¬ç ç©¶å°ååä½¿ç¨çå¯è§£é AI æè¡èä¸ç¨®æ°æåºçç¨±çºã2 å å­æª¢ç´¢ (2FR)ãçæè¡é²è¡æ¯è¼ï¼å¾èæ¯ä¸ç¨®ä»é¢è¨­è¨åæå°æª¢ç´¢ççµåï¼å®æå³åæ¨ç±¤ç¸ä¼¼çè³æï¼èä¸æèçéäºè³æãéæç¢çä¸å 2 å å­å®å¨æ©å¶ï¼å¶ä¸­ï¼(a) æ­£ç¢ºçå½±åéè¦ç± AI æª¢ç´¢ï¼(b) äººé¡æå°æª¢ç´¢çå½±åèæ­£å¨æ¸¬è©¦ä¸­çççè¯æ³èµ·ä¾ãæåç¼ç¾ï¼ç¶å¨è¸é¨ X åè¨ºæ·ä¸é²è¡æ¸¬è©¦æï¼2FR ææé«è¨åºé«ççæºç¢ºåº¦ï¼ç¹å¥æ¯å¨è¨åºé«çæ¯æ¾å°ç§é«çä¸å°å¶æ±ºç­ä¿¡å¿ä¸è¶³æï¼ææé¡¯èçæ¹åãæåççµæå¼·èª¿äºçè§£äººæ©æ±ºç­çä¸åæ¨¡å¼å¦ä½å½±é¿è¨åºé«çå¨è¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çæºç¢ºæ§çéè¦æ§ã

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

æè¦ï¼<paragraph>äºè§£å¬ç¾å°äººå·¥æºæ§ (AI) çèªç¥ä»¥åæ½å¨é¢¨éªèå¥½èä¹éçæ¬è¡¡è³ééè¦ï¼å çºéäºèªç¥å¯è½æå½±é¿æ¿ç­æ±ºç­ãå½±é¿æåå¸å ´ç­ç¥çåµæ°è»è·¡ï¼ä¸¦æ±ºå®åäººåç¤¾æå° AI æè¡çæ¥ååº¦ãæ¬ç ç©¶ä½¿ç¨ä¾èªå¾·åç 1100 ååèèçä»£è¡¨æ§æ¨£æ¬ï¼æ¢è¨äº AI çå¿æºæ¨¡åãåèèå° 71 é éæ¼ AI æªä¾è½åçé³è¿°ï¼ä¾å¦ï¼èªåé§é§ãé«çä¿å¥ãèè¡ãæ¿æ²»ãæ°ç­åç¤¾æåæ­§ï¼é²è¡äºå®éè©ä¼°ï¼è©ä¼°é æçç¼çå¯è½æ§ãæç¥é¢¨éªãå¥½èåæ´é«å¹å¼ãæåå±ç¤ºäºéäºé æ¸¬çæåï¼ä¸¦éä¸è¦è¦ºåæ å°ï¼èªªæäºå¬ç¾çé¢¨éªæ¶çæ¬è¡¡ãåç®¡è¨±å¤å ´æ¯è¢«èªçºæ¯å¯è½çï¼ä½åèèéå¸¸å°å®åèé«é¢¨éªãæéçå¥½èåä½æ´é«å¹å¼è¯ç¹«èµ·ä¾ãå¨ææå ´æ¯ä¸­ï¼96.4% ($r^2=96.4\%$) çå¹å¼è©ä¼°å·®ç°å¯ä»¥ç¨æç¥é¢¨éª ($\beta=-.504$) åæç¥å¥½è ($\beta=+.710$) ä¾è§£éï¼èé æçå¯è½æ§æ²æé¡¯èéä¿ãäººå£çµ±è¨åäººæ ¼ç¹è³ªå½±é¿äºå°é¢¨éªãå¥½èåæ´é«è©ä¼°ççæ³ï¼éå¸é¡¯äºæé« AI ç´ é¤åæ ¹æä¸åçä½¿ç¨èéæ±èª¿æ´å¬å±è³è¨çéè¦æ§ãéäºç¼ç¾ééå¼·èª¿ééµçå¬å±éæ³¨åèåäººå¹å¼è§ä¸è´ç AI éç¼å¿ä¸å¯å°çåäººå ç´ ï¼çºç ç©¶äººå¡ãéç¼äººå¡åæ¿ç­å¶å®èæä¾äºå¯è¡çè¦è§£ã</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v2 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
challenges due to data heterogeneity, sparsity, temporal misalignment, and
limited labeled outcomes. In this context, we leverage a linked EHR dataset of
approximately one million de-identified individuals from Bristol, North
Somerset, and South Gloucestershire, UK, to characterize urinary tract
infections (UTIs). We implemented a data pre-processing and curation pipeline
that transforms the raw EHR data into a structured format suitable for
developing predictive models focused on data fairness, accountability and
transparency. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Pairwise
XGBoost models are trained using this framework to differentiate UTI risk
categories with explainable AI techniques applied to identify key predictors
and support interpretability. Our findings reveal differences in clinical and
demographic predictors across risk groups. While this study highlights the
potential of AI-driven insights to support UTI clinical decision-making,
further investigation of patient sub-strata and extensive validation are needed
to ensure robustness and applicability in clinical practice.

æè¦ï¼é»å­å¥åº·ç´é (EHR) ä¸­æ©å¨å­¸ç¿å AI çä½¿ç¨å°æ¼è¨åºè¦è§£å·æç¸ç¶å¤§çæ½åãç¶èï¼ç±æ¼è³æç°è³ªæ§ãç¨çæ§ãæéé¯ä½åæ¨ç±¤çµææéï¼æ­¤æ¹æ³é¢è¨ææ°ãå¨æ­¤èæ¯ä¸ï¼æåå©ç¨ä¾èªè±åå¸éæ¯æãåè©é»å¡ç¹ååæ ¼æ´æ¯ç¹é¡ç´ä¸ç¾è¬åå»è­å¥åäººé£çµç EHR è³æéï¼ä¾æè¿°å°¿è·¯ææ (UTI)ãæåå¯¦æ½äºå°åå§ EHR è³æè½æçºçµæ§åæ ¼å¼çè³æåèçåæ´çç®¡ç·ï¼é©åéç¼å°æ³¨æ¼è³æå¬å¹³æ§ãåè²¬å¶åéæåº¦çé æ¸¬æ¨¡åãéæ¼ UTI çå¯¦çµæçå¯ç¨æ§æéååå·®ï¼æåå¼å¥äºç±è¨åºå°æ¥­ç¥è­åç¥ç UTI é¢¨éªè©ä¼°æ¶æ§ï¼ä»¥ä¼°è¨åå¥æ£èæéè»¸ä¸ç UTI é¢¨éªãæå°ç XGBoost æ¨¡åä½¿ç¨æ­¤æ¶æ§é²è¡è¨ç·´ï¼ä»¥åå UTI é¢¨éªé¡å¥ï¼ä¸¦æç¨å¯è§£éç AI æè¡ä¾è­å¥ééµé æ¸¬å å­ä¸¦æ¯æå¯è§£éæ§ãæåçç ç©¶çµææ­ç¤ºäºä¸åé¢¨éªç¾¤çµå¨è¨åºåäººå£çµ±è¨é æ¸¬å å­ä¸çå·®ç°ãéç¶éé ç ç©¶å¼·èª¿äº AI é©åè¦è§£å¨æ¯æ´ UTI è¨åºæ±ºç­å¶å®æ¹é¢çæ½åï¼ä½ä»éè¦é²ä¸æ­¥èª¿æ¥æ£èå­ç¾¤é«åå»£æ³é©è­ï¼ä»¥ç¢ºä¿å¨è¨åºå¯¦åä¸­çç©©å¥æ§åé©ç¨æ§ã

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) æ¨¡åè®å¾è¶ä¾è¶è¤éï¼ä¸è¶ä¾è¶é£ä»¥è¢«äººçè§£ï¼äºè§£æ¸ä½ç³»çµ±å¦ä½æ¯æ´è¨åºæ±ºç­çéæ±ä¹æ¥çå¢å ãéç¨®è¤éæ§å¼ç¼äºå°å¯ä¿¡åº¦ççæ®ï¼å½±é¿äºæ­¤é¡æè¡çå®å¨ä¸æææ¡ç¨ãæ¹åå°æ±ºç­å¶å®æµç¨ççè§£ï¼ä»¥åå°æ±ºç­æ¯æ´å·¥å·ææä¾èªªæçè¦æ±ï¼æ¯æä¾ææå¯è§£éè§£æ±ºæ¹æ¡çéè¦çµæé¨åãéå¨è³æå¯éãå¿«ç¯å¥çå è­·çæ¿ (ICU) ç°å¢ä¸­ç¹å¥ç¸éãçºäºæ¢è¨éäºåé¡ï¼å°ä¸ä½ ICU è¨åºé«å¸«é²è¡äºå°çµè¨ªè«ï¼éäºé«å¸«ä»£è¡¨äºä¸åçè§è²åç¶é©å±¤ç´ãä¸»é¡åææ­é²äºä¸åæ ¸å¿ä¸»é¡ï¼(T1) ICU æ±ºç­å¶å®ä¾è³´æ¼å»£æ³çå ç´ ï¼(T2) çæ£çæçè¤éæ§å°å±åæ±ºç­å¶å®æ§æææ°ï¼ä»¥å (T3) AI æ±ºç­æ¯æ´ç³»çµ±çè¦æ±åè½åãæåç´å¥äºè¨åºè¼¸å¥çè¨­è¨å»ºè­°ï¼æä¾è¦è§£ä»¥æä¾è³è¨çµ¦æªä¾ç¨æ¼å è­·ç AI ç³»çµ±ã

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

æè¦ï¼å°åå¿èç¾çåç¾åå¤©æ§èå¾å¤©æ§ç¾ççå»£æ³åè­ãè¼è¤éçåå¤©æ§ç¸å½¢éè¦ä¸åå·®ç°åä¸å¤æ¨¡å¼çæ±ºç­éç¨ï¼éå¸¸åæ¬è¶é³æ³¢æª¢æ¥ä½çºä¸»è¦çå½±åæ¹æ³ãäººå·¥æºæ§ (AI) çºè¨åºé«çæä¾äºç¸ç¶å¤§çå¸æï¼å çºå®å¯ä»¥ä¿é²å°åè¶é³æ³¢æª¢æ¥è³æçèªååè§£è®ãç¶èï¼å°äººå·¥æºæ§æè¡æç¨æ¼å°åè¶é³æ³¢æª¢æ¥åææè¨±å¤ææ°ï¼ä¾å¦æéçå¬éè³æå¯ç¨æ§ãè³æé±ç§åäººå·¥æºæ§æ¨¡åéæåº¦ãæè¿ï¼ç ç©¶äººå¡å°æ³¨æ¼ç ´å£æ§æè¡ï¼ä¾å¦è¯åå­¸ç¿ (FL) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥æ¹åèªåè¨ºæ·åæ±ºç­æ¯æ´å·¥ä½æµç¨ãæ¬ç ç©¶æä¾äºäººå·¥æºæ§å¨å°åè¶é³æ³¢æª¢æ¥ä¸­çéå¶åæ©æçå¨é¢æ¦è¿°ï¼å¼·èª¿äº XAI å FL çååå·¥ä½æµç¨åè§è²ï¼æ¾åºç ç©¶å·®è·ä¸¦æ¢è¨æ½å¨çæªä¾ç¼å±ãæ­¤å¤ï¼ä¸åç¸éçè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº XAI å FL çåè½ï¼éé»å¨æ¼ (i) æª¢è¦è¾¨è­ã(ii) ç¾çåé¡ã(iii) å¿èçµæ§åå²å (iv) å¿èåè½çéåè©ä¼°ã

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

æè¦ï¼éª¨è³ªçé¬çæ¯ä¸ç¨®å¸¸è¦çç¾çï¼æå¢å éª¨æçé¢¨éªï¼ç¹å¥æ¯èå¹´äººãæ©æè¨ºæ·å°æ¼é é²éª¨æãéä½æ²»çææ¬åç¶­æè¡åè½åè³ééè¦ãç¶èï¼é«çä¿å¥æä¾èé¢è¨èæ¨è¨æ¸ææéåèçé«å­¸å½±åå°é£ç­ææ°ãæ¬ç ç©¶æåºäºä¸åæ°ç©çå¤æ¨¡å¼å­¸ç¿æ¡æ¶ï¼è©²æ¡æ¶æ´åäºè¨åºåå½±åæ¸æï¼ä»¥æé«è¨ºæ·æºç¢ºæ§åæ¨¡åå¯è§£éæ§ãè©²æ¨¡åå©ç¨ä¸åé è¨ç·´çç¶²è·¯ï¼VGG19ãInceptionV3 å ResNet50ï¼å¾ X å°ç·å½±åä¸­æåæ·±åº¦ç¹å¾µãéäºç¹å¾µä½¿ç¨ PCA è½æä»¥éä½ç¶­åº¦ä¸¦å°æ³¨æ¼æç¸éççµæé¨åãåºæ¼èé¡çé¸æéç¨è­å¥åºæå·ä»£è¡¨æ§ççµæé¨åï¼ç¶å¾å°éäºçµæé¨åèé èççè¨åºæ¸æçµåï¼ä¸¦ééå¨é£æ¥ç¶²è·¯ (FCN) é²è¡æçµåé¡ãç¹å¾µéè¦æ§åçªåºäºééµè®æ¸ï¼è¡¨æçå²ãBMI åèº«é«æ¯ä¸»è¦è²¢ç»å ç´ ï¼å¼·èª¿äºæ£èç¹å®æ¸æçéè¦æ§ãéç¶å½±åç¹å¾µå¾æå¹å¼ï¼ä½å®åçéè¦æ§è¼ä½ï¼éè¡¨æè¨åºæ¸æå°æ¼æºç¢ºé æ¸¬è³ééè¦ãæ­¤æ¡æ¶ä¿è¿äºæºç¢ºä¸å¯è§£éçé æ¸¬ï¼æé«äºéæåº¦ï¼ä¸¦å»ºç«äºå° AI é©åè¨ºæ·å¨è¨åºæ´åä¸­çä¿¡ä»»ã

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

æè¦ï¼æ¬ç¯è©è«æ¢è¨äºæ·±åº¦å­¸ç¿æ¹æ³å¨éä¾µå¥å¼èªç¥åè½éç¤æª¢æ¸¬ä¸çææ°é²å±ãæåæª¢è¦äºåç¨®éä¾µå¥å¼çèªç¥è¡°éææ¨ï¼åæ¬èªè¨åèªè¨ãé¢é¨åéåæ©è½ãæ¬ææ¦è¿°äºèæ­¤é åç¸éçè³æéãç¹å¾µæåæè¡åæ·±åº¦å­¸ç¿æ¶æ§ãæååæäºä¸åæ¹æ³å¨ä¸åæ¹å¼ä¸çè¡¨ç¾ï¼ä¸¦è§å¯å°åºæ¼èªè¨åèªè¨çæ¹æ³éå¸¸è½éå°æé«çæª¢æ¸¬è¡¨ç¾ãçµåè²å­¸åèªè¨ç¹å¾µçç ç©¶å¾å¾åªæ¼ä½¿ç¨å®ä¸æ¹å¼çç ç©¶ãé¢é¨åææ¹æ³é¡¯ç¤ºåºè¦è¦ºæ¹å¼çæ½åï¼ä½ç ç©¶è¼å°ãå¤§å¤æ¸è«æå°æ³¨æ¼äºååé¡ï¼åæèæªåæï¼ï¼è¼å°æ¢è¨å¤é¡æåæ­¸ä»»åãé·ç§»å­¸ç¿åé è¨ç·´èªè¨æ¨¡åå·²æçºæµè¡ä¸ææçæè¡ï¼ç¹å¥æ¯å°æ¼èªè¨åæãåç®¡åå¾äºéå¤§é²å±ï¼ä½ä»å­å¨ä¸äºææ°ï¼åæ¬è³ææ¨æºååå¯åæ§ãæ¨¡åå¯è§£éæ§ãç¸±ååæéå¶åè¨åºé©ææ§ãæå¾ï¼æåæåºäºæªä¾çç ç©¶æ¹åï¼ä¾å¦èª¿æ¥èèªè¨ç¡éçèªé³åææ¹æ³ãéç¼å¤æ¨¡å¼è¨ºæ·ç³»çµ±ï¼ä»¥åè§£æ±ºäººå·¥æºæ§è¼å©é«çä¿å¥ä¸­çå«çèéãééç¶åç®åçè¶¨å¢åæ¾åºééµéç¤ï¼æ¬ç¯è©è«æ¨å¨å¼å°æ·±åº¦å­¸ç¿çºåºç¤çèªç¥åè½éç¤æª¢æ¸¬ç³»çµ±çé²ä¸æ­¥ç¼å±ï¼ä»¥æ¹åæ©æè¨ºæ·ï¼ä¸¦æçµæ¹åæ£èçæ²»ççµæã

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

æè¦ï¼å¯è§£éäººå·¥æºæ§ï¼AIï¼å°æ³¨æ¼åå©äººé¡äºè§£ AI ç³»çµ±éä½æå¶æ±ºç­ï¼æ¸åå¹´ä¾ä¸ç´æ¯ AI çåºç³ãæè¿çå¯è§£éæ§ç ç©¶å°æ³¨æ¼è§£é AI æ¨¡åææ¨¡åå¯è§£éæ§çéä½ãä¹æå¹¾ä»½ç«å ´è²æåè©è«è«æè©³ç´°èªªæäºæçµä½¿ç¨èå°ä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§çéæ±ï¼ä½å¯¦ä½è¼å°ãå æ­¤ï¼æ¬è«ææ¨å¨å½è£æ¨¡ååä»¥ä½¿ç¨èçºä¸­å¿çå¯è§£éæ§ä¹éçä¸äºå·®è·ãæåå»ºç«ä¸åè§£éæ¬é«ï¼EOï¼ä»¥ééå¶æ¯æ´åä»¶ä¾è¡¨ç¤ºå¾æç»ä¸­è¡ççè§£éé¡åãæåå¯¦ä½ä¸åç¥è­å¢å¼·çåç­ï¼QAï¼ç®¡ç·ï¼ä»¥å¨è¨åºç°å¢ä¸­æ¯æ´æå¢è§£éãæå¾ï¼æåæ­£å¨å¯¦ä½ä¸åç³»çµ±ï¼ä»¥çµåä¾èªä¸å AI æ¹æ³åè³ææ¨¡å¼çè§£éãå¨ EO ä¸­ï¼æåå¯ä»¥è¡¨ç¤º 15 ç¨®ä¸åçè§£éé¡åï¼ä¸¦ä¸æåå·²å¨å­åç¯ä¾ä½¿ç¨æ¡ä¾ä¸­æ¸¬è©¦éäºè¡¨ç¤ºãæåç¼ç¾ï¼ç¥è­å¢å¼·æ¹åäºåºç¤å¤§åèªè¨æ¨¡åå¨æå¢å QA ä¸­çæè½ï¼ä¸¦ä¸æè½å ç¾çç¾¤çµèç°ãå¨ç¸åçç°å¢ä¸­ï¼è¨åºé«çä¹è¡¨ç¤ºä»åå¸æå°å¯æä½æ§è¦çºè§£éä¸­çä¸»è¦ç¦é»ä¹ä¸ãå¨æåçè§£éçµåæ¹æ³ä¸­ï¼æåè¨ç«ä½¿ç¨ç¸ä¼¼æ§ææ¨ä¾ç¢ºå®æ¢æ§çåµæ¸¬ç°å¢ä¸­è§£éçç¸ä¼¼æ§ãç¸½é«èè¨ï¼ééæ¬è«æï¼æåè¨­è¨äºå¯ä»¥å¨ä¸åä½¿ç¨æ¡ä¾ä¸­æ¯æ´ç¥è­åç¨è§£éçæ¹æ³ï¼èéå°ç¶ä» AI æä»£ä¸­å¯ä»¥ç¢çéäºè§£éçæ¯æ´åä»¶åå¯ä»¥å¢å¼·éäºè§£éçé åç¥è­ä¾æºçæ¹æ³ã

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

æè¦ï¼<paragraph>ç®çï¼èª¿æ¥è¨åºé«çå°ç®åèªååå¿é»åè§£è®åæ°çäººå·¥æºæ§æè¡çæåº¦ï¼ä»¥åä»åå°é»è¦è¼å©è§£è®ççæ³ãææåæ¹æ³ï¼æåå°è±åçè¨åºé«çé²è¡äºä¸ç³»åè¨ªè«ãæåçç ç©¶ï¼(i) æ¢è¨äººå·¥æºæ§çæ½åï¼ç¹å¥æ¯æªä¾çãé¡äººé¡ãéç®æ¹æ³ï¼ä»¥ä¿é²å¿é»åè§£è®ä¸¦æ¯æè¨åºæ±ºç­å¶å®ï¼ä»¥å (ii) å¾µæ±ä»åå°äººå·¥æºæ§æ¼ç®æ³çå¯è§£éæ§åå¯ä¿¡åº¦ççæ³ãçµæï¼æåå° 23 ä½è¨åºé«ççè¨ªè«è¨éé²è¡äºæ­¸ç´ä¸»é¡åæï¼ä¸¦æ¾åºä»¥ä¸ä¸»é¡ï¼(i) å°ç®åç³»çµ±ç¼ºä¹ä¿¡ä»»ï¼(ii) å°æªä¾äººå·¥æºæ§æç¨åå°éäºæç¨çè¦æ±ææ­£é¢æåº¦ï¼(iii) æ¼ç®æ³çæºç¢ºæ§åå¯è§£éæ§ä¹éçéä¿ï¼ä»¥å (iv) å°æè²ãå¯è½çæè½éåï¼ä»¥åäººå·¥æºæ§å°è¨åºè½åçå½±é¿ççæ³ãè¨è«ï¼è¨åºé«çä¸ä¿¡ä»»ç®åçé»è¦åæ¹æ³ï¼ä½æ­¡è¿æªä¾çãäººå·¥æºæ§ãæè¡ãå¨è¨åºé«çç¸ä¿¡æªä¾ç AI è§£è®æºç¢ºçææ³ä¸ï¼ä»åä¸å¤ªæå¿å®æ¯å¦å¯è§£éãä»åä¹æ¯è¼åæ­¡è½ä»¥è¦è¦ºæ¹å¼åç¾æ¼ç®æ³çµæçå¿é»åè§£è®ãéç¶è¨åºé«çä¸å®³æå¤±æ¥­ï¼ä½ä»åæå¿æè½éåï¼ä»¥åéè¦æè²å¡å·¥è² è²¬ä»»å°ä½¿ç¨äººå·¥æºæ§ãçµè«ï¼è¨åºé«çå°äººå·¥æºæ§å¨è¨åºæ±ºç­å¶å®ä¸­çæªä¾æç¨ææ­£é¢æåº¦ãæºç¢ºæ§æ¯æ¡ç¨äººå·¥æºæ§çä¸åééµå ç´ ï¼èè¦è¦ºåæ¯ç®åçé»è¦åæ¹æ³æ´åéçãéè¢«è¦çºä¸ç¨®æ½å¨çå¹è¨åæåæè½çæ¹æ³ï¼èèªååå¯è½å¸¶ä¾çæè½éåå½¢æå°æ¯ã</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah HaggenmÃ¼ller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria CompÃ©rat, Andreas Gocht, Monika HÃ¤mmerle, Niels J. Rupp, Jula Westhoff, Irene KrÃ¼cken, Maximillian Seidl, Christian M. SchÃ¼rch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian HÃ¶rner, Kirsten D. Mertz, Constanze DÃ¶ring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

æè¦ï¼ååèºçæ¯å¨çç·æ§æå¸¸è¦çççï¼å¶æ¡æ§ç¨åº¦ä¸»è¦æ ¹æ Gleason è©åç³»çµ±ä½¿ç¨çµç¹ççå­¸æ¸æé²è¡è©ä¼°ãéç¶äººå·¥æºæ§ (AI) å¨æºç¢ºé æ¸¬ Gleason è©åæ¹é¢å·²å±ç¾æ½åï¼ä½éäºé æ¸¬éå¸¸ç¼ºä¹å§å¨çå¯è§£éæ§ï¼å¯è½æå°è´å°äººæ©äºåçä¸ä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æåå¼é²äºä¸åç± 54 ä½ççå­¸å®¶çµæçåéåéè¨»è§£ç 1,015 åçµç¹å¾®é£åæ ¸å¿å½±åçæ°ç©è³æéãéäºè¨»è§£æä¾äºè©³ç´°çå±é¨æ¨¡å¼æè¿°ï¼ç¨æ¼ç¬¦ååéæºåç Gleason åç´ãå©ç¨éåè³æéï¼æåéç¼äºä¸ååºæ¼ U-Net æ¶æ§çå§å¨å¯è§£é AI ç³»çµ±ï¼è©²ç³»çµ±æä¾äºå©ç¨ççå­¸å®¶è¡èªé²è¡é æ¸¬ãéç¨®æ¹æ³è¦é¿äºäºå¾å¯è§£éæ§æ¹æ³ï¼åæç¶­ææè¶è¶äºç´æ¥è¨ç·´ç¨æ¼ Gleason æ¨¡å¼åå²çæ¹æ³çæè½ï¼Dice åæ¸ï¼0.713 Â± 0.003ï¼è¨ç·´æ¼è§£éï¼ç¸å°æ¼ 0.691 Â± 0.010ï¼è¨ç·´æ¼ Gleason æ¨¡å¼ï¼ãééå¨è¨ç·´æéæ¡ç¨è»æ¨ç±¤ï¼æåææäºè³æä¸­çå§å¨ä¸ç¢ºå®æ§ï¼å³ä½¿å¨è§å¯èéè®ç°æ§é«çææ³ä¸ï¼ä¹è½å¨ Gleason æ¨¡å¼åå²ä¸­ç¢çå¼·å¤§ççµæãéééåºéåè³æéï¼æåæ¨å¨é¼åµé²ä¸æ­¥ç ç©¶ä¸»è§æ§é«çé«çä»»åä¸­çåå²ï¼ä¸¦å¢é²å°ççå­¸å®¶æ¨çéç¨ççè§£ã

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

æè¦ï¼é«ééæè¡çé²æ­¥å°è´å¾å³çµ±çåè¨­é©åæ¹æ³è½è®çºè³æé©åçæ¹æ³ãå¤çµå­¸æ¯ææ´ååæä¾èªå¤åãçµå­¸ãçè³æï¼ä¾å¦åºå çµå­¸ãèç½è³ªçµå­¸ãè½éçµå­¸ãä»£è¬çµå­¸åå¾®çç©çµå­¸ãæ­¤æ¹æ³ééæ·åçç©è³è¨çä¸åå±¤é¢ï¼è½å¨é¢äºè§£çç©ç³»çµ±ãæ·±åº¦å­¸ç¿æ¹æ³æä¾æå¸¸è¢«ç¨æ¼æ´åå¤çµå­¸è³æï¼æä¾åå­äº¤äºä½ç¨çæ´å¯åï¼ä¸¦å å¼·å°è¤éç¾ççç ç©¶ãç¶èï¼éäºæ¨¡åå·æè¨±å¤ç¸äºé£æ¥çå±¤ç´åéç·æ§éä¿ï¼éå¸¸æåé»çå­ä¸æ¨£éä½ï¼ç¼ºä¹æ±ºç­éç¨çéæåº¦ãçºäºåææ­¤ææ°ï¼å¯è§£éäººå·¥æºæ§ (xAI) æ¹æ³å°æ¼å»ºç«éææ¨¡åè³ééè¦ï¼è®è¨åºé«çå¯ä»¥æ´ææå°è§£éåèçè¤éè³æãæ­¤è©è«æ¢è¨ xAI å¦ä½è½æ¹åå¤çµå­¸ç ç©¶ä¸­æ·±åº¦å­¸ç¿æ¨¡åçå¯è§£éæ§ï¼å¼·èª¿å¶æä¾è¨åºé«çæç¢ºè¦è§£çæ½åï¼é²èä¿é²æ­¤é¡æ¨¡åå¨è¨åºç°å¢ä¸­çæææç¨ã

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian GeiÃler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°æ¼å»ºæ§åé²çæ©å¨å­¸ç¿é©åæç¨ç¨å¼è³ééè¦ï¼ç¹å¥æ¯å¨é«çè¨ºæ·æèªåé§é§ç­ééµé åãæ³å¾ãåæ¥­åå«çè¦æ±ä¿ä½¿ä½¿ç¨ææç XAIï¼ä½æ¸éæ¥çå¢å çä¸åæ¹æ³ä½¿å¾æé¸æ­£ç¢ºçæ¹æ³å·æææ°æ§ãæ­¤å¤ï¼ç±æ¼è§£éé«åº¦ä¾è³´æ¼èæ¯ï¼å¨æ²æä½¿ç¨èçææ³ä¸è¡¡é XAI æ¹æ³çæææ§åªè½æ­ç¤ºæéçè³è¨ï¼æé¤äººé¡å ç´ ï¼ä¾å¦çè§£å®çè½åãæåå»ºè­°ééä½¿ç¨èæåå·è¡ä»£çä»»åçè½åä¾è©ä¼° XAI æ¹æ³ï¼è¨­è¨ä½¿å¾è¯å¥½çå·è¡è¡¨ç¾æ¯è§£éæä¾æç¨è³è¨çææ¨ãæå¥è©±èªªï¼æåæ¢è¨ XAI å°äººé¡æ±ºç­å¶å®çå¹«å©ãæ­¤å¤ï¼å°æåé²çæ¹æ³é²è¡ä½¿ç¨èç ç©¶ï¼é¡¯ç¤ºåºå®åå¨ç¢çä¿¡ä»»åæ·ççè½åä»¥åæ­£ç¢ºå¤æ· AI æ±ºç­æ¯å¦æ­£ç¢ºçè½åæ¹é¢å­å¨å·®ç°ãæ ¹æçµæï¼æåå¼·çå»ºè­°ä½¿ç¨åæ´åéç¨®æ¹æ³ï¼ä»¥é²è¡æ´å¤ä»¥ç®æ¨çºåºç¤çäººçºä¸­å¿ä½¿ç¨èç ç©¶ï¼ä»¥çµç«¯å°çµç«¯çæ¹å¼è¡¡é XAI æè½ã

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

æè¦ï¼ç¢ç¨ä¸­é¢¨éªçæ©æåµæ¸¬æå©æ¼é²è¡å¹²é æªæ½ï¼ä»¥é é²ææ¸è¼ä¸å©ççç¢çµæï¼ä¾å¦è¦æ§éº»çºãç®åï¼æ²ææºç¢ºçèªååç³»çµ±å¯ä»¥é æ¸¬æ­¤é¡äºä»¶ï¼ä»¥åå©è¨åºæ±ºç­ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºãç¨æ¼å»ºæ¨¡åè§£éæ°çåå¥åº·çäººå·¥æºæ§ã(AIMEN)ï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¶æ§ï¼å®ä¸åå¯ä»¥æ ¹æå­ç¢å©¦ãèåãç¢ç§åç¢ç¨é¢¨éªå ç´ é æ¸¬ä¸å©ççç¢çµæï¼éè½æä¾æ¨¡åååºé æ¸¬èå¾çåå ãå¾èå¯ä»¥æä¾è¦è§£ï¼èªªææ¨¡åè¼¸å¥è®æ¸ä¸­çåªäºä¿®æ¹å¯è½ææ¹è®é æ¸¬çµæãæåééä½¿ç¨é©ææ§åææ½æ¨£ (ADASYN) åæ¢ä»¶è¡¨æ ¼çæå°æç¶²è·¯ (CTGAN) ä¾åæé¡å¤çè¨ç·´è³æï¼ä»¥è§£æ±ºä¸å¹³è¡¡åå°åè³æéçææ°ãAIMEN ä½¿ç¨å¨é£æ¥ç¥ç¶ç¶²è·¯çéåä½çºå¶åé¡çéª¨å¹¹ï¼ä¸¦éé ADASYN æ CTGAN æ¯æ´è³ææ´åãç± CTGAN æ¯æ´ç AIMEN å¨åé¡æ¹é¢åªæ¼ç± ADASYN æ¯æ´ç AIMENãAIMEN å¯ä»¥é æ¸¬ä¸å©ççç¢çµæçé«é¢¨éªï¼å¹³å F1 åæ¸çº 0.784ãå®éæä¾åäºå¯¦è§£éï¼å¯ééå¹³åè®æ´ 2 è³ 3 åå±¬æ§ä¾éæãå¯ç¨è³æºï¼https://github.com/ab9mamun/AIMENã

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

æè¦ï¼éºå³æ§è¦ç¶²èç¾ç (IRD) æ¯ä¸çµå¤æ¨£åçéºå³ç¾çï¼
æå°è´è¦åéæ¼¸åªå¤±ï¼æ¯å·¥ä½å¹´é½¡æäººå¤±æçä¸»è¦åå ãIRD çè¤éæ§åç°è³ªæ§å°è¨ºæ·ãé å¾åç®¡çæåºäºéå¤§ææ°ãæè¿äººå·¥æºè½ (AI) çé²æ­¥çºéäºææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ã
ç¶èï¼AI æè¡çå¿«éç¼å±åå¶å¤ç¨®æç¨å°è´äºè©²é åçç¥è­åæ£ãæ¬ç¶è¿°æ´åäºç¾æç ç©¶ï¼æ¾åºå·®è·ï¼ä¸¦æ¦è¿°äº AI å¨è¨ºæ·åç®¡ç IRD ä¸­çæ½åãå®æ¨å¨ééæ¢ç´¢æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿ç­ AI æè¡ï¼ç¹å¥æ¯å¨ç¾çæª¢æ¸¬ãé²ç¨é æ¸¬ååæ§åæ²»çè¨åä¸­ï¼çºæ¨é²è¨åºæç¨æ§å»ºéå¾ãç¹å¥éæ³¨éäºé åä¸­å·ç©ç¥ç¶ç¶²è·¯çæææ§ãæ­¤å¤ï¼è¨è«äºå¯è§£é AI çæ´åï¼å¼·èª¿äºå¶å¨è¨åºç°å¢ä¸­æé«éæåº¦åå°åºæ¼ AI çç³»çµ±çä¿¡ä»»çéè¦æ§ãè©²ç¶è¿°è§£æ±ºäºå½å AI å¨ IRD ä¸­ä½ç¨çéé»ç ç©¶ä¸­ç¾æå·®è·çå¿è¦æ§ï¼æä¾äºå°ç¶å AI æè¡ççµæ§ååæï¼ä¸¦æ¦è¿°äºæªä¾çç ç©¶æ¹åãæå¾æ¦è¿°äºå¨ IRD ä¸­é¨ç½² AI çææ°åæ©éï¼å¼·èª¿äºè·¨å­¸ç§åä½åæçºéç¼å¼·å¤§ãå¯è§£éç AI æ¨¡åä»¥æ¨é²è¨åºæç¨çå¿è¦æ§ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æé¡¯èå½±é¿æ£èççµæãå³çµ±çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨éåé ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éå¨è¨åºç°å¢ä¸­æ¯ä¸é ééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³çæç¨ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼ç¨æ¼è¨ºæ·é æ¸¬çå¯è§£éæ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼éäºæ¨¡åééå·æå¯å­¸ç¿é¾å¼çéè¼¯è¦åæ´åé åç¹å®ç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼ä¾å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåªç°æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿å°çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸å½±é¿é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼æ¨é²ç²¾æºé«çï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç³å ±è³æï¼çµååé²æ©å¨å­¸ç¿èæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD) çå¯è½æ§ãæååæä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾ç 10 å¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·æç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯è¦çªçé æ¸¬æ¨¡åãæåçç ç©¶çµæé¡¯ç¤ºï¼LSTM æ¨¡åï¼å°¤å¶æ¯ 24 åæè§å¯è¦çªï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å¯å æ§è§£é (SHAP) åæä»¥å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç³å ±è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**
2409.09201v3 by Mercy Asiedu, Nenad Tomasev, Chintan Ghate, Tiya Tiyasirichokchai, Awa Dieng, Oluwatosin Akande, Geoffrey Siwo, Steve Adudans, Sylvanus Aitkins, Odianosen Ehiakhamen, Eric Ndombi, Katherine Heller

While large language models (LLMs) have shown promise for medical question
answering, there is limited work focused on tropical and infectious
disease-specific exploration. We build on an opensource tropical and infectious
diseases (TRINDs) dataset, expanding it to include demographic and semantic
clinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM
performance on these, comparing generalist and medical LLMs, as well as LLM
outcomes to human experts. We demonstrate through systematic experimentation,
the benefit of contextual information such as demographics, location, gender,
risk factors for optimal LLM response. Finally we develop a prototype of
TRINDs-LM, a research tool that provides a playground to navigate how context
impacts LLM outputs for health.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨é«çåé¡è§£ç­æ¹é¢å±ç¾åºåæ¯ï¼ä½å°æ³¨æ¼ç±å¸¶åå³æçç¹å®æ¢ç´¢çç ç©¶æéãæåå»ºç«å¨ä¸åéæ¾åå§ç¢¼ç±å¸¶åå³æç (TRINDs) è³æéä¸ï¼ä¸¦å°å¶æ´å±çºç´å¥äººå£çµ±è¨åèªç¾©è¨åºåæ¶è²»èæ´åï¼ç¢çè¶é 11000 åæç¤ºãæåè©ä¼°äº LLM å¨éäºæ¹é¢çæè½ï¼æ¯è¼äºéæåé«ç LLMï¼ä»¥å LLM çµæèäººé¡å°å®¶çæ¯è¼ãæåééç³»çµ±æ§å¯¦é©è­æäºèæ¯è³è¨ï¼ä¾å¦äººå£çµ±è¨ãä½ç½®ãæ§å¥ãæä½³ LLM åæçé¢¨éªå ç´ ï¼çå¥½èãæå¾ï¼æåéç¼äº TRINDs-LM çååï¼éæ¯ä¸åç ç©¶å·¥å·ï¼æä¾ä¸åæ¢ç´¢èæ¯å¦ä½å½±é¿ LLM å¥åº·è¼¸åºçå¹³å°ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust in Healthcare**
2408.17401v2 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

AI-driven tools for healthcare are widely acknowledged as potentially
beneficial to health practitioners and patients, e.g. the QCancer regression
tool for cancer risk prediction. However, for these tools to be trusted, they
need to be supplemented with explanations. We examine how explanations' content
and format affect user comprehension and trust when explaining QCancer's
predictions. Regarding content, we deploy SHAP and Occlusion-1. Regarding
format, we present SHAP explanations, conventionally, as charts (SC) and
Occlusion-1 explanations as charts (OC) as well as text (OT), to which their
simpler nature lends itself. We conduct experiments with two sets of
stakeholders: the general public (representing patients) and medical students
(representing healthcare practitioners). Our experiments showed higher
subjective comprehension and trust for Occlusion-1 over SHAP explanations based
on content. However, when controlling for format, only OT outperformed SC,
suggesting this trend is driven by preferences for text. Other findings
corroborated that explanation format, rather than content, is often the
critical factor.

æè¦ï¼ç± AI é©åçé«çä¿å¥å·¥å·è¢«å»£æ³èªçºå°é«çå¾æ¥­èåæ£èææ½å¨å¥½èï¼ä¾å¦ç¨æ¼ççé¢¨éªé æ¸¬ç QCancer åæ­¸å·¥å·ãç¶èï¼å°æ¼éäºå·¥å·ï¼å¦æè¦è®äººåä¿¡è³´ï¼å°±éè¦è£åèªªæãæåç ç©¶äºèªªæçå§å®¹åæ ¼å¼å¦ä½å½±é¿ä½¿ç¨èå¨è§£é QCancer é æ¸¬æççè§£åä¿¡ä»»ãéæ¼å§å®¹ï¼æåé¨ç½²äº SHAP å Occlusion-1ãéæ¼æ ¼å¼ï¼æåä»¥åè¡¨ (SC) çå½¢å¼åç¾ SHAP èªªæï¼ä»¥åè¡¨ (OC) åæå­ (OT) çå½¢å¼åç¾ Occlusion-1 èªªæï¼å çºå®åçæ§è³ªè¼çºç°¡å®ãæåå°å©çµå©å®³éä¿äººé²è¡äºå¯¦é©ï¼ä¸è¬æ°ç¾ï¼ä»£è¡¨æ£èï¼åé«å­¸çï¼ä»£è¡¨é«çå¾æ¥­èï¼ãæåçå¯¦é©çµæé¡¯ç¤ºï¼åºæ¼å§å®¹ï¼Occlusion-1 æ¯ SHAP èªªæå·ææ´é«çä¸»è§çè§£åä¿¡ä»»ãç¶èï¼å¨æ§å¶æ ¼å¼æï¼åªæ OT åªæ¼ SCï¼éè¡¨æéç¨®è¶¨å¢æ¯ç±å°æå­çåå¥½æé©åçãå¶ä»ç¼ç¾è­å¯¦äºèªªææ ¼å¼ï¼èä¸æ¯å§å®¹ï¼éå¸¸æ¯ééµå ç´ ã

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸å½±ååæä¸­å·²éå°æ´é«é«æºç¢ºåº¦ãç¶èï¼ç¹å®æ£èç¾¤é«çæè½å·®ç°å°å¶è¨åºæç¨ãå®å¨æ§èå¬å¹³æ§æ§æææ°ãéå¯è½æå½±é¿å·²ç¥çæ£èç¾¤é«ï¼ä¾å¦åºæ¼æ§å¥ãå¹´é½¡æç¾çäºåï¼ä»¥åååæªç¥ä¸æªæ¨ç±¤çç¾¤é«ãæ­¤å¤ï¼æ­¤é¡è§å¯å°çæè½å·®ç°çæ ¹æ¬åå éå¸¸é£ä»¥ç¼ç¾ï¼é»ç¤äºç·©è§£æªæ½ãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéäºåé¡ï¼æåå©ç¨åçç¼ç¾æ¹æ³ (SDM) ä¾è­å¥å¯è§£éçè³ææè½ä¸ä½³å­éï¼ä¸¦éå°è§å¯å°çæè½å·®ç°åå å¶å®åè¨­ãæåå¼å¥ä¸ç¨®æ°ç SDMï¼ä¸¦å¨è¸é¨ X åçä¸­èºçåèºä¸å¼µåé¡çæ¡ä¾ç ç©¶ä¸­æç¨å®ãæåçç ç©¶è­æäº SDM å¨åè¨­å¶å®ä¸­çæææ§ï¼ä¸¦å°å»£æ³ä½¿ç¨çè¸é¨ X åçè³æéåæ¨¡åä¸­ååè§å¯å°ä½ç¡æ³è§£éçç·æ§åå¥³æ§æ£èä¹éçæè½å·®ç°æä¾äºè§£éãæåçç¼ç¾è¡¨æï¼å¨åé¡ä»»åä¸­ï¼ééè¸èå¼æµç®¡åå¿é»åå°ç·çå­å¨ï¼å­å¨æ·å¾å­¸ç¿ãéäºæ·å¾ç¹å¾µççè¡çå­å¨åºæ¼æ§å¥çå·®ç°ï¼ä¼¼ä¹æå°è´è§å¯å°çåé¡æè½å·®è·ï¼éä»£è¡¨æ·å¾å­¸ç¿åæ¨¡åå¬å¹³æ§åæä¹éååæªåå°éè¦çäº¤äºä½ç¨ã

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v2 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad, Lamia Ashraf

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèç (CKD) æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼ç®åå°æªæ¾å°æçµçæ²»çæ¹æ³ï¼ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèç (CKD) æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çæ¼è®æä¸ç¨®å´éç¨åº¦ä¸ä¸çå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨æ´é«å­¸ç¿åå¯è§£éç AI ä¾è¦è¦ºåæ¯éæ§ç¹å¾µãç¹å¾µåæ¸åå¼ï¼ä»¥é²è¡ CKD çæ©æé å¾åæª¢æ¸¬ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼çä¿®æ¹å»ºè­°ï¼ä»¥éä½æ­¤ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½å¾µè±¡ä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªè¦ç CKD çä¾ãæåçç ç©¶çµæå¨èèèç§é«å¸«é²è¡é·æéè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤çç¹å¾µä½çºé¡¯èçè²¢ç»èãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèè¢«é®è½ç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨æ­¤ææ¨ä¸­åå¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼åºäºæºå¨å­¦ä¹ çä¸´åºå³ç­æ¯æç³»ç» (CDSS) å¨å¤ç§ç¾ççåæä¸­æ®æ¼äºå³é®è§è²ãå°½ç®¡å®ä»¬å·æå¹¿éçåæ¯ï¼ä½ AI æ¨¡åç¼ºä¹éæåº¦ï¼å°¤å¶å¨å»çé¢åï¼å¯é æ§æ¯å¼ºå¶æ§æ¹é¢ï¼è¿å¸¦æ¥äºéå¤§ææãç¶èï¼è§£éæ§ä¼¼ä¹ä¸åç¡®æ§æåæ¯ãå æ­¤ï¼å¨ä¸å½±åé¢æµåç¡®æ§çæåµä¸å®ç°éæåº¦ä»ç¶æ¯ä¸ä¸ªå³é®ææãæ¬ææåºäºä¸ç§æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥éè¿æ¾å°ç»å­¦çåå¨å¯è§£éæ§æ¥å¢å¼º CNN è¡çç¹å¾çé¢æµè½åãRad4XCNN éè¿æ¾å°ç»å­¦å°å¯çè§£çå«ä¹ä¸ CNN è¡çç¹å¾å³èèµ·æ¥ï¼ä»èåç¦»äºåºäºæ¾çæ§å¾çä¼ ç»æ¹æ³ï¼ä¸ºè¶è¶å¯è§åå¾çè§£éæ¹æ³æä¾äºæ°çè§è§ãä½¿ç¨ä¹³èºçåç±»ä»»å¡ä½ä¸ºæ¡ä¾ç ç©¶ï¼æä»¬å¨è¶å£°æåæ°æ®éä¸è¯ä¼°äº Rad4XCNNï¼åæ¬ä¸ä¸ªå¨çº¿æ°æ®éåä¸¤ä¸ªç¨äºåé¨åå¤é¨éªè¯çåé¨æ°æ®éãä¸äºå³é®ç»ææ¯ï¼i) ä¸ ViT è¡çåæ¾å°ç»å­¦ç¹å¾ç¸æ¯ï¼CNN è¡çç¹å¾ä¿è¯äºæ´ç¨³å¥çåç¡®æ§ï¼ii) ç¨äºè§£éçä¼ ç»å¯è§åå¾æ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN ä¸ä¼ä¸ºäºå¯è§£éæ§èçºç²æ¨¡ååç¡®æ§ï¼iv) Rad4XCNN æä¾å¨å±è§£éï¼ä½¿å»çè½å¤æåå¨å±è§è§£ååç°ãæä»¬çæ¹æ³å¯ä»¥åè½»ä¸äºä¸å¯è§£éæ§-åç¡®æ§æè¡¡ç¸å³çæå¿§ãæ¬ç ç©¶å¼ºè°äºæåºæ°æ¹æ³æ¥è§£éæ¨¡åèä¸å½±åå¶åç¡®æ§çéè¦æ§ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

