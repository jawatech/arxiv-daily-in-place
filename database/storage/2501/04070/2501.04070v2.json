{"2501.04070": {"publish_time": "2025-01-07", "title": "More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives", "paper_summary": "Large language models (LLMs) excel at few-shot in-context learning (ICL)\nwithout requiring parameter updates. However, as the number of ICL\ndemonstrations increases from a few to many, performance tends to plateau and\neventually decline. We identify two primary causes for this trend: the\nsuboptimal negative log-likelihood (NLL) optimization objective and the\nincremental data noise. To address these issues, we introduce DrICL, a novel\noptimization method that enhances model performance through Differentiated\nLearning and advantage-based Reweighting objectives. Globally, DrICL utilizes\ndifferentiated learning to optimize the NLL objective, ensuring that many-shot\nperformance surpasses zero-shot levels. Locally, it dynamically adjusts the\nweighting of many-shot demonstrations by leveraging cumulative advantages\ninspired by reinforcement learning, thereby improving generalization. This\napproach allows the model to handle varying numbers of shots effectively,\nmitigating the impact of noisy data. Recognizing the lack of multi-task\ndatasets with diverse many-shot distributions, we develop the Many-Shot ICL\nBenchmark (ICL-50)-a large-scale benchmark of 50 tasks that cover shot numbers\nfrom 1 to 350 within sequences of up to 8,000 tokens-for fine-tuning purposes.\nICL-50 facilitates the evaluation of many-shot ICL strategies across seven\nprominent NLP tasks and 50 distinct datasets. Experimental results demonstrate\nthat LLMs enhanced with DrICL achieve significant improvements in many-shot\nsetups across various tasks, including both in-domain and out-of-domain\nscenarios. We release the code and benchmark dataset hoping to facilitate\nfurther research in many-shot ICL.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u50c5\u9700\u5c11\u91cf\u7bc4\u4f8b\u7684\u8108\u7d61\u5b78\u7fd2 (ICL) \u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u800c\u7121\u9700\u66f4\u65b0\u53c3\u6578\u3002\u7136\u800c\uff0c\u96a8\u8457 ICL \u793a\u7bc4\u7684\u6578\u91cf\u5f9e\u5c11\u6578\u589e\u52a0\u5230\u591a\u6578\uff0c\u6548\u80fd\u5f80\u5f80\u6703\u9054\u5230\u5e73\u7a69\u671f\uff0c\u4e26\u6700\u7d42\u4e0b\u964d\u3002\u6211\u5011\u627e\u51fa\u6b64\u8da8\u52e2\u7684\u5169\u500b\u4e3b\u8981\u539f\u56e0\uff1a\u6b21\u4f73\u8ca0\u5c0d\u6578\u4f3c\u7136 (NLL) \u6700\u4f73\u5316\u76ee\u6a19\u548c\u905e\u589e\u8cc7\u6599\u96dc\u8a0a\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86 DrICL\uff0c\u4e00\u7a2e\u900f\u904e\u5dee\u7570\u5316\u5b78\u7fd2\u548c\u57fa\u65bc\u512a\u52e2\u7684\u91cd\u65b0\u52a0\u6b0a\u76ee\u6a19\u4f86\u589e\u5f37\u6a21\u578b\u6548\u80fd\u7684\u65b0\u578b\u6700\u4f73\u5316\u65b9\u6cd5\u3002\u5728\u5168\u7403\u5c64\u9762\u4e0a\uff0cDrICL \u5229\u7528\u5dee\u7570\u5316\u5b78\u7fd2\u4f86\u6700\u4f73\u5316 NLL \u76ee\u6a19\uff0c\u78ba\u4fdd\u591a\u7bc4\u4f8b\u6548\u80fd\u8d85\u8d8a\u96f6\u7bc4\u4f8b\u7b49\u7d1a\u3002\u5728\u5c40\u90e8\u5c64\u9762\u4e0a\uff0c\u5b83\u900f\u904e\u5229\u7528\u53d7\u5f37\u5316\u5b78\u7fd2\u555f\u767c\u7684\u7d2f\u7a4d\u512a\u52e2\uff0c\u52d5\u614b\u8abf\u6574\u591a\u7bc4\u4f8b\u793a\u7bc4\u7684\u52a0\u6b0a\uff0c\u5f9e\u800c\u6539\u5584\u6cdb\u5316\u80fd\u529b\u3002\u9019\u7a2e\u65b9\u6cd5\u8b93\u6a21\u578b\u80fd\u5920\u6709\u6548\u8655\u7406\u4e0d\u540c\u6578\u91cf\u7684\u7bc4\u4f8b\uff0c\u6e1b\u8f15\u96dc\u8a0a\u8cc7\u6599\u7684\u5f71\u97ff\u3002\u7531\u65bc\u7f3a\u4e4f\u5177\u6709\u591a\u6a23\u5316\u591a\u7bc4\u4f8b\u5206\u4f48\u7684\u591a\u4efb\u52d9\u8cc7\u6599\u96c6\uff0c\u6211\u5011\u958b\u767c\u4e86\u591a\u7bc4\u4f8b ICL \u57fa\u6e96 (ICL-50) - \u4e00\u500b\u5305\u542b 50 \u9805\u4efb\u52d9\u7684\u5927\u898f\u6a21\u57fa\u6e96\uff0c\u6db5\u84cb\u5f9e 1 \u5230 350 \u7684\u7bc4\u4f8b\u6578\u91cf\uff0c\u5e8f\u5217\u9577\u5ea6\u6700\u9577\u70ba 8,000 \u500b\u7b26\u865f\uff0c\u7528\u65bc\u5fae\u8abf\u76ee\u7684\u3002ICL-50 \u4fc3\u9032\u4e86\u8de8\u8d8a\u4e03\u9805\u986f\u8457\u7684 NLP \u4efb\u52d9\u548c 50 \u500b\u4e0d\u540c\u8cc7\u6599\u96c6\u7684\u591a\u7bc4\u4f8b ICL \u7b56\u7565\u7684\u8a55\u4f30\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u900f\u904e DrICL \u589e\u5f37\u7684 LLM \u5728\u5404\u7a2e\u4efb\u52d9\u7684\u591a\u7bc4\u4f8b\u8a2d\u5b9a\u4e2d\u7372\u5f97\u986f\u8457\u6539\u5584\uff0c\u5305\u62ec\u9818\u57df\u5167\u548c\u9818\u57df\u5916\u5834\u666f\u3002\u6211\u5011\u91cb\u51fa\u7a0b\u5f0f\u78bc\u548c\u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u5e0c\u671b\u80fd\u4fc3\u9032\u591a\u7bc4\u4f8b ICL \u7684\u9032\u4e00\u6b65\u7814\u7a76\u3002", "author": "Xiaoqing Zhang et.al.", "authors": "Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Shuo Shang, Xiuying Chen, Rui Yan", "id": "2501.04070v2", "paper_url": "http://arxiv.org/abs/2501.04070v2", "repo": "https://github.com/xiaoqzhwhu/dr-icl"}}