{"2410.01469": {"publish_time": "2024-10-02", "title": "TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation", "paper_summary": "In recent years, much speech separation research has focused primarily on\nimproving model performance. However, for low-latency speech processing\nsystems, high efficiency is equally important. Therefore, we propose a speech\nseparation model with significantly reduced parameters and computational costs:\nTime-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).\nTIGER leverages prior knowledge to divide frequency bands and compresses\nfrequency information. We employ a multi-scale selective attention module to\nextract contextual features, while introducing a full-frequency-frame attention\nmodule to capture both temporal and frequency contextual information.\nAdditionally, to more realistically evaluate the performance of speech\nseparation models in complex acoustic environments, we introduce a dataset\ncalled EchoSet. This dataset includes noise and more realistic reverberation\n(e.g., considering object occlusions and material properties), with speech from\ntwo speakers overlapping at random proportions. Experimental results showed\nthat models trained on EchoSet had better generalization ability than those\ntrained on other datasets to the data collected in the physical world, which\nvalidated the practical value of the EchoSet. On EchoSet and real-world data,\nTIGER significantly reduces the number of parameters by 94.3% and the MACs by\n95.3% while achieving performance surpassing state-of-the-art (SOTA) model\nTF-GridNet. This is the first speech separation model with fewer than 1 million\nparameters that achieves performance comparable to the SOTA model.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u8bb8\u591a\u8bed\u97f3\u5206\u79bb\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u4e0a\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u4f4e\u5ef6\u8fdf\u8bed\u97f3\u5904\u7406\u7cfb\u7edf\u800c\u8a00\uff0c\u9ad8\u6548\u7387\u540c\u6837\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u53c2\u6570\u548c\u8ba1\u7b97\u6210\u672c\u660e\u663e\u964d\u4f4e\u7684\u8bed\u97f3\u5206\u79bb\u6a21\u578b\uff1a\u65f6\u9891\u4ea4\u9519\u589e\u76ca\u63d0\u53d6\u548c\u91cd\u5efa\u7f51\u7edc\uff08TIGER\uff09\u3002TIGER \u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u6765\u5212\u5206\u9891\u6bb5\u5e76\u538b\u7f29\u9891\u7387\u4fe1\u606f\u3002\u6211\u4eec\u91c7\u7528\u591a\u5c3a\u5ea6\u9009\u62e9\u6027\u6ce8\u610f\u6a21\u5757\u6765\u63d0\u53d6\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u540c\u65f6\u5f15\u5165\u5168\u9891\u5e27\u6ce8\u610f\u6a21\u5757\u6765\u6355\u83b7\u65f6\u95f4\u548c\u9891\u7387\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u66f4\u771f\u5b9e\u5730\u8bc4\u4f30\u8bed\u97f3\u5206\u79bb\u6a21\u578b\u5728\u590d\u6742\u58f0\u5b66\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3a EchoSet \u7684\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c6\u5305\u62ec\u566a\u58f0\u548c\u66f4\u771f\u5b9e\u7684\u6df7\u54cd\uff08\u4f8b\u5982\uff0c\u8003\u8651\u7269\u4f53\u906e\u6321\u548c\u6750\u6599\u7279\u6027\uff09\uff0c\u5176\u4e2d\u6765\u81ea\u4e24\u4e2a\u8bf4\u8bdd\u8005\u7684\u8bed\u97f3\u4ee5\u968f\u673a\u6bd4\u4f8b\u91cd\u53e0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728 EchoSet \u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u6bd4\u5728\u5176\u4ed6\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5bf9\u7269\u7406\u4e16\u754c\u4e2d\u6536\u96c6\u7684\u6570\u636e\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u9a8c\u8bc1\u4e86 EchoSet \u7684\u5b9e\u9645\u4ef7\u503c\u3002\u5728 EchoSet \u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\uff0cTIGER \u5c06\u53c2\u6570\u6570\u91cf\u663e\u7740\u51cf\u5c11\u4e86 94.3%\uff0c\u5c06 MAC \u51cf\u5c11\u4e86 95.3%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u8d85\u8d8a\u6700\u5148\u8fdb (SOTA) \u6a21\u578b TF-GridNet \u7684\u6027\u80fd\u3002\u8fd9\u662f\u7b2c\u4e00\u4e2a\u53c2\u6570\u5c11\u4e8e 100 \u4e07\u4e14\u6027\u80fd\u4e0e SOTA \u6a21\u578b\u76f8\u5f53\u7684\u8bed\u97f3\u5206\u79bb\u6a21\u578b\u3002", "author": "Mohan Xu et.al.", "authors": "Mohan Xu, Kai Li, Guo Chen, Xiaolin Hu", "id": "2410.01469v1", "paper_url": "http://arxiv.org/abs/2410.01469v1", "repo": "null"}}