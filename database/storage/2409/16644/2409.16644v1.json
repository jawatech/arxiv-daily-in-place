{"2409.16644": {"publish_time": "2024-09-25", "title": "Enabling Auditory Large Language Models for Automatic Speech Quality Evaluation", "paper_summary": "Speech quality assessment typically requires evaluating audio from multiple\naspects, such as mean opinion score (MOS) and speaker similarity (SIM) etc.,\nwhich can be challenging to cover using one small model designed for a single\ntask. In this paper, we propose leveraging recently introduced auditory large\nlanguage models (LLMs) for automatic speech quality assessment. By employing\ntask-specific prompts, auditory LLMs are finetuned to predict MOS, SIM and A/B\ntesting results, which are commonly used for evaluating text-to-speech systems.\nAdditionally, the finetuned auditory LLM is able to generate natural language\ndescriptions assessing aspects like noisiness, distortion, discontinuity, and\noverall quality, providing more interpretable outputs. Extensive experiments\nhave been performed on the NISQA, BVCC, SOMOS and VoxSim speech quality\ndatasets, using open-source auditory LLMs such as SALMONN, Qwen-Audio, and\nQwen2-Audio. For the natural language descriptions task, a commercial model\nGoogle Gemini 1.5 Pro is also evaluated. The results demonstrate that auditory\nLLMs achieve competitive performance compared to state-of-the-art task-specific\nsmall models in predicting MOS and SIM, while also delivering promising results\nin A/B testing and natural language descriptions. Our data processing scripts\nand finetuned model checkpoints will be released upon acceptance.", "paper_summary_zh": "\u8a9e\u97f3\u54c1\u8cea\u8a55\u4f30\u901a\u5e38\u9700\u8981\u5f9e\u591a\u500b\u9762\u5411\u8a55\u4f30\u97f3\u8a0a\uff0c\u4f8b\u5982\u5e73\u5747\u610f\u898b\u5206\u6578 (MOS) \u548c\u8aaa\u8a71\u8005\u76f8\u4f3c\u5ea6 (SIM) \u7b49\uff0c\u800c\u4f7f\u7528\u91dd\u5c0d\u55ae\u4e00\u4efb\u52d9\u8a2d\u8a08\u7684\u5c0f\u578b\u6a21\u578b\u4f86\u6db5\u84cb\u9019\u4e9b\u9762\u5411\u53ef\u80fd\u6703\u662f\u4e00\u9805\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u8b70\u5229\u7528\u6700\u8fd1\u63a8\u51fa\u7684\u807d\u89ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u9032\u884c\u81ea\u52d5\u8a9e\u97f3\u54c1\u8cea\u8a55\u4f30\u3002\u900f\u904e\u63a1\u7528\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u63d0\u793a\uff0c\u807d\u89ba LLM \u6703\u7d93\u904e\u5fae\u8abf\uff0c\u4ee5\u9810\u6e2c MOS\u3001SIM \u548c A/B \u6e2c\u8a66\u7d50\u679c\uff0c\u9019\u4e9b\u7d50\u679c\u901a\u5e38\u7528\u65bc\u8a55\u4f30\u6587\u5b57\u8f49\u8a9e\u97f3\u7cfb\u7d71\u3002\u6b64\u5916\uff0c\u7d93\u904e\u5fae\u8abf\u7684\u807d\u89ba LLM \u80fd\u5920\u7522\u751f\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\uff0c\u8a55\u4f30\u96dc\u8a0a\u3001\u5931\u771f\u3001\u4e0d\u9023\u7e8c\u6027\u4ee5\u53ca\u6574\u9ad4\u54c1\u8cea\u7b49\u9762\u5411\uff0c\u63d0\u4f9b\u66f4\u6613\u65bc\u7406\u89e3\u7684\u8f38\u51fa\u3002\u6211\u5011\u5df2\u7d93\u5728 NISQA\u3001BVCC\u3001SOMOS \u548c VoxSim \u8a9e\u97f3\u54c1\u8cea\u8cc7\u6599\u96c6\u4e0a\u57f7\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4f7f\u7528 SALMONN\u3001Qwen-Audio \u548c Qwen2-Audio \u7b49\u958b\u6e90\u807d\u89ba LLM\u3002\u5c0d\u65bc\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u4efb\u52d9\uff0c\u6211\u5011\u4e5f\u8a55\u4f30\u4e86\u5546\u7528\u6a21\u578b Google Gemini 1.5 Pro\u3002\u7d50\u679c\u986f\u793a\uff0c\u8207\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u7684\u6700\u65b0\u5c0f\u578b\u6a21\u578b\u76f8\u6bd4\uff0c\u807d\u89ba LLM \u5728\u9810\u6e2c MOS \u548c SIM \u6642\u9054\u5230\u4e86\u6709\u7af6\u722d\u529b\u7684\u6548\u80fd\uff0c\u540c\u6642\u5728 A/B \u6e2c\u8a66\u548c\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u4e2d\u4e5f\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u7d50\u679c\u3002\u6211\u5011\u7684\u8cc7\u6599\u8655\u7406\u8173\u672c\u548c\u7d93\u904e\u5fae\u8abf\u7684\u6a21\u578b\u6aa2\u67e5\u9ede\u5c07\u5728\u7372\u5f97\u63a5\u53d7\u5f8c\u91cb\u51fa\u3002", "author": "Siyin Wang et.al.", "authors": "Siyin Wang, Wenyi Yu, Yudong Yang, Changli Tang, Yixuan Li, Jimin Zhuang, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Guangzhi Sun, Lu Lu, Chao Zhang", "id": "2409.16644v1", "paper_url": "http://arxiv.org/abs/2409.16644v1", "repo": "null"}}