{"2411.05897": {"publish_time": "2024-11-08", "title": "Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators", "paper_summary": "Although large language models (LLMs) have been assessed for general medical\nknowledge using medical licensing exams, their ability to effectively support\nclinical decision-making tasks, such as selecting and using medical\ncalculators, remains uncertain. Here, we evaluate the capability of both\nmedical trainees and LLMs to recommend medical calculators in response to\nvarious multiple-choice clinical scenarios such as risk stratification,\nprognosis, and disease diagnosis. We assessed eight LLMs, including\nopen-source, proprietary, and domain-specific models, with 1,009\nquestion-answer pairs across 35 clinical calculators and measured human\nperformance on a subset of 100 questions. While the highest-performing LLM,\nGPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human\nannotators, on average, outperformed LLMs with an accuracy of 79.5% (CI:\n73.5-85.0%). With error analysis showing that the highest-performing LLMs\ncontinue to make mistakes in comprehension (56.6%) and calculator knowledge\n(8.1%), our findings emphasize that humans continue to surpass LLMs on complex\nclinical tasks such as calculator recommendation.", "paper_summary_zh": "\u5118\u7ba1\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u4f7f\u7528\u91ab\u5b78\u57f7\u7167\u8003\u8a66\u8a55\u4f30\u5176\u4e00\u822c\u91ab\u5b78\u77e5\u8b58\uff0c\u4f46\u5b83\u5011\u6709\u6548\u652f\u63f4\u81e8\u5e8a\u6c7a\u7b56\u4efb\u52d9\uff08\u4f8b\u5982\u9078\u64c7\u548c\u4f7f\u7528\u91ab\u5b78\u8a08\u7b97\u5668\uff09\u7684\u80fd\u529b\u4ecd\u4e0d\u78ba\u5b9a\u3002\u5728\u6b64\uff0c\u6211\u5011\u8a55\u4f30\u91ab\u5b78\u53d7\u8a13\u8005\u548c LLM \u63a8\u85a6\u91ab\u5b78\u8a08\u7b97\u5668\u7684\u80fd\u529b\uff0c\u4ee5\u56de\u61c9\u5404\u7a2e\u591a\u9078\u984c\u81e8\u5e8a\u60c5\u5883\uff0c\u4f8b\u5982\u98a8\u96aa\u5206\u5c64\u3001\u9810\u5f8c\u548c\u75be\u75c5\u8a3a\u65b7\u3002\u6211\u5011\u8a55\u4f30\u4e86\u516b\u500b LLM\uff0c\u5305\u62ec\u958b\u6e90\u3001\u5c08\u6709\u548c\u7279\u5b9a\u9818\u57df\u7684\u6a21\u578b\uff0c\u5176\u4e2d\u5305\u542b 35 \u500b\u81e8\u5e8a\u8a08\u7b97\u5668\u7684 1,009 \u500b\u554f\u7b54\u5c0d\uff0c\u4e26\u6e2c\u91cf\u4e86\u4eba\u985e\u5728 100 \u500b\u554f\u984c\u5b50\u96c6\u4e0a\u7684\u8868\u73fe\u3002\u8868\u73fe\u6700\u4f73\u7684 LLM GPT-4o \u63d0\u4f9b\u4e86 74.3% \u7684\u56de\u7b54\u6e96\u78ba\u5ea6 (CI\uff1a71.5-76.9%)\uff0c\u800c\u4eba\u985e\u8a3b\u89e3\u8005\u5e73\u5747\u8868\u73fe\u512a\u65bc LLM\uff0c\u6e96\u78ba\u5ea6\u70ba 79.5% (CI\uff1a73.5-85.0%)\u3002\u932f\u8aa4\u5206\u6790\u986f\u793a\uff0c\u8868\u73fe\u6700\u4f73\u7684 LLM \u5728\u7406\u89e3 (56.6%) \u548c\u8a08\u7b97\u5668\u77e5\u8b58 (8.1%) \u65b9\u9762\u4ecd\u6703\u72af\u932f\uff0c\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u5f37\u8abf\uff0c\u4eba\u985e\u5728\u8a08\u7b97\u5668\u63a8\u85a6\u7b49\u8907\u96dc\u81e8\u5e8a\u4efb\u52d9\u4e0a\u4ecd\u7136\u512a\u65bc LLM\u3002", "author": "Nicholas Wan et.al.", "authors": "Nicholas Wan, Qiao Jin, Joey Chan, Guangzhi Xiong, Serina Applebaum, Aidan Gilson, Reid McMurry, R. Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu", "id": "2411.05897v1", "paper_url": "http://arxiv.org/abs/2411.05897v1", "repo": "null"}}