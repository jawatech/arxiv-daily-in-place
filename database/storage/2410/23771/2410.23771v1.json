{"2410.23771": {"publish_time": "2024-10-31", "title": "What is Wrong with Perplexity for Long-context Language Modeling?", "paper_summary": "Handling long-context inputs is crucial for large language models (LLMs) in\ntasks such as extended conversations, document summarization, and many-shot\nin-context learning. While recent approaches have extended the context windows\nof LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has\nproven unreliable for assessing long-context capabilities. The underlying cause\nof this limitation has remained unclear. In this work, we provide a\ncomprehensive explanation for this issue. We find that PPL overlooks key\ntokens, which are essential for long-context understanding, by averaging across\nall tokens and thereby obscuring the true performance of models in long-context\nscenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that\nfocuses on key tokens by employing a long-short context contrastive method to\nidentify them. Our experiments demonstrate that LongPPL strongly correlates\nwith performance on various long-context benchmarks (e.g., Pearson correlation\nof -0.96), significantly outperforming traditional PPL in predictive accuracy.\nAdditionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a\nre-weighting strategy for fine-tuning that prioritizes key tokens, leading to\nconsistent improvements across diverse benchmarks. In summary, these\ncontributions offer deeper insights into the limitations of PPL and present\neffective solutions for accurately evaluating and enhancing the long-context\ncapabilities of LLMs. Code is available at https://github.com/PKU-ML/LongPPL.", "paper_summary_zh": "<paragraph>\u8655\u7406\u9577\u8a9e\u5883\u8f38\u5165\u5c0d\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u81f3\u95dc\u91cd\u8981\uff0c\u5176\u4efb\u52d9\u5305\u62ec\u5ef6\u4f38\u5c0d\u8a71\u3001\u6587\u4ef6\u6458\u8981\u548c\u591a\u767c\u5b78\u7fd2\u3002\u5118\u7ba1\u8fd1\u671f\u65b9\u6cd5\u5df2\u5ef6\u4f38 LLM \u7684\u8a9e\u5883\u7a97\u53e3\uff0c\u4e26\u63a1\u7528\u56f0\u60d1\u5ea6 (PPL) \u4f5c\u70ba\u6a19\u6e96\u8a55\u91cf\u6307\u6a19\uff0c\u4f46 PPL \u5df2\u88ab\u8b49\u5be6\u7121\u6cd5\u53ef\u9760\u8a55\u91cf\u9577\u8a9e\u5883\u80fd\u529b\u3002\u9019\u7a2e\u9650\u5236\u7684\u6839\u672c\u539f\u56e0\u4ecd\u4e0d\u660e\u78ba\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5c0d\u9019\u500b\u554f\u984c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u89e3\u91cb\u3002\u6211\u5011\u767c\u73fe PPL \u6703\u5ffd\u7565\u95dc\u9375\u8a5e\u5f59\uff0c\u800c\u95dc\u9375\u8a5e\u5f59\u5c0d\u65bc\u9577\u8a9e\u5883\u7406\u89e3\u81f3\u95dc\u91cd\u8981\uff0c\u56e0\u70ba PPL \u6703\u5e73\u5747\u6240\u6709\u8a5e\u5f59\uff0c\u56e0\u800c\u6a21\u7cca\u4e86\u6a21\u578b\u5728\u9577\u8a9e\u5883\u60c5\u5883\u4e2d\u7684\u771f\u5be6\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa \\textbf{LongPPL}\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u6307\u6a19\uff0c\u900f\u904e\u63a1\u7528\u9577\u77ed\u8a9e\u5883\u5c0d\u6bd4\u65b9\u6cd5\u4f86\u627e\u51fa\u95dc\u9375\u8a5e\u5f59\uff0c\u9032\u800c\u5c08\u6ce8\u65bc\u9019\u4e9b\u95dc\u9375\u8a5e\u5f59\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0cLongPPL \u8207\u5404\u7a2e\u9577\u8a9e\u5883\u57fa\u6e96\u7684\u6548\u80fd\u9ad8\u5ea6\u76f8\u95dc\uff08\u4f8b\u5982\uff0c\u76ae\u723e\u68ee\u76f8\u95dc\u4fc2\u6578\u70ba -0.96\uff09\uff0c\u5728\u9810\u6e2c\u6e96\u78ba\u5ea6\u65b9\u9762\u660e\u986f\u512a\u65bc\u50b3\u7d71 PPL\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86 \\textbf{LongCE}\uff08\u9577\u8a9e\u5883\u4ea4\u53c9\u71b5\uff09\u640d\u5931\uff0c\u9019\u662f\u4e00\u7a2e\u91cd\u65b0\u52a0\u6b0a\u7b56\u7565\uff0c\u7528\u65bc\u5fae\u8abf\uff0c\u4e26\u512a\u5148\u8003\u616e\u95dc\u9375\u8a5e\u5f59\uff0c\u9032\u800c\u63d0\u5347\u5404\u7a2e\u57fa\u6e96\u7684\u8868\u73fe\u3002\u7e3d\u800c\u8a00\u4e4b\uff0c\u9019\u4e9b\u8ca2\u737b\u63d0\u4f9b\u4e86\u5c0d PPL \u9650\u5236\u7684\u66f4\u6df1\u5165\u898b\u89e3\uff0c\u4e26\u63d0\u51fa\u4e86\u6709\u6548\u89e3\u6c7a\u65b9\u6848\uff0c\u7528\u65bc\u6e96\u78ba\u8a55\u4f30\u548c\u63d0\u5347 LLM \u7684\u9577\u8a9e\u5883\u80fd\u529b\u3002\u7a0b\u5f0f\u78bc\u53ef\u65bc https://github.com/PKU-ML/LongPPL \u53d6\u5f97\u3002</paragraph>", "author": "Lizhe Fang et.al.", "authors": "Lizhe Fang, Yifei Wang, Zhaoyang Liu, Chenheng Zhang, Stefanie Jegelka, Jinyang Gao, Bolin Ding, Yisen Wang", "id": "2410.23771v1", "paper_url": "http://arxiv.org/abs/2410.23771v1", "repo": "https://github.com/pku-ml/longppl"}}