{"2412.04300": {"publish_time": "2024-12-05", "title": "T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts", "paper_summary": "Evaluating the quality of synthesized images remains a significant challenge\nin the development of text-to-image (T2I) generation. Most existing studies in\nthis area primarily focus on evaluating text-image alignment, image quality,\nand object composition capabilities, with comparatively fewer studies\naddressing the evaluation of the factuality of T2I models, particularly when\nthe concepts involved are knowledge-intensive. To mitigate this gap, we present\nT2I-FactualBench in this work - the largest benchmark to date in terms of the\nnumber of concepts and prompts specifically designed to evaluate the factuality\nof knowledge-intensive concept generation. T2I-FactualBench consists of a\nthree-tiered knowledge-intensive text-to-image generation framework, ranging\nfrom the basic memorization of individual knowledge concepts to the more\ncomplex composition of multiple knowledge concepts. We further introduce a\nmulti-round visual question answering (VQA) based evaluation framework to\nassess the factuality of three-tiered knowledge-intensive text-to-image\ngeneration tasks. Experiments on T2I-FactualBench indicate that current\nstate-of-the-art (SOTA) T2I models still leave significant room for\nimprovement.", "paper_summary_zh": "\u8a55\u4f30\u5408\u6210\u5f71\u50cf\u54c1\u8cea\u5728\u6587\u5b57\u8f49\u5f71\u50cf (T2I) \u751f\u6210\u767c\u5c55\u4e2d\u4ecd\u662f\u4e00\u9805\u91cd\u5927\u6311\u6230\u3002\u73fe\u6709\u5927\u591a\u6578\u7814\u7a76\u4e3b\u8981\u5c08\u6ce8\u65bc\u8a55\u4f30\u6587\u5b57\u5f71\u50cf\u5c0d\u9f4a\u3001\u5f71\u50cf\u54c1\u8cea\u548c\u7269\u9ad4\u7d44\u6210\u80fd\u529b\uff0c\u8f03\u5c11\u7814\u7a76\u63a2\u8a0e T2I \u6a21\u578b\u7684\u4e8b\u5be6\u6027\u8a55\u4f30\uff0c\u7279\u5225\u662f\u5728\u6240\u6d89\u53ca\u6982\u5ff5\u9700\u8981\u5927\u91cf\u77e5\u8b58\u6642\u3002\u70ba\u4e86\u5f4c\u88dc\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\u63d0\u51fa T2I-FactualBench\uff0c\u9019\u662f\u76ee\u524d\u5728\u6982\u5ff5\u548c\u63d0\u793a\u6578\u91cf\u65b9\u9762\u6700\u5927\u7684\u57fa\u6e96\uff0c\u5c08\u9580\u7528\u65bc\u8a55\u4f30\u77e5\u8b58\u5bc6\u96c6\u578b\u6982\u5ff5\u751f\u6210\u7684\u771f\u5be6\u6027\u3002T2I-FactualBench \u5305\u542b\u4e00\u500b\u4e09\u5c64\u7d1a\u7684\u77e5\u8b58\u5bc6\u96c6\u578b\u6587\u5b57\u8f49\u5f71\u50cf\u751f\u6210\u67b6\u69cb\uff0c\u5f9e\u57fa\u672c\u8a18\u61b6\u500b\u5225\u77e5\u8b58\u6982\u5ff5\u5230\u66f4\u8907\u96dc\u7684\u591a\u500b\u77e5\u8b58\u6982\u5ff5\u7d44\u6210\u3002\u6211\u5011\u9032\u4e00\u6b65\u5f15\u5165\u4e00\u500b\u57fa\u65bc\u591a\u8f2a\u8996\u89ba\u554f\u7b54 (VQA) \u7684\u8a55\u4f30\u67b6\u69cb\uff0c\u4ee5\u8a55\u4f30\u4e09\u5c64\u7d1a\u77e5\u8b58\u5bc6\u96c6\u578b\u6587\u5b57\u8f49\u5f71\u50cf\u751f\u6210\u4efb\u52d9\u7684\u4e8b\u5be6\u6027\u3002\u5728 T2I-FactualBench \u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0c\u76ee\u524d\u7684\u6700\u65b0\u6280\u8853 (SOTA) T2I \u6a21\u578b\u4ecd\u6709\u5f88\u5927\u7684\u6539\u9032\u7a7a\u9593\u3002", "author": "Ziwei Huang et.al.", "authors": "Ziwei Huang, Wanggui He, Quanyu Long, Yandi Wang, Haoyuan Li, Zhelun Yu, Fangxun Shu, Long Chen, Hao Jiang, Leilei Gan", "id": "2412.04300v1", "paper_url": "http://arxiv.org/abs/2412.04300v1", "repo": "null"}}