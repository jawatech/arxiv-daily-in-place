{"2408.00106": {"publish_time": "2024-07-31", "title": "WAS: Dataset and Methods for Artistic Text Segmentation", "paper_summary": "Accurate text segmentation results are crucial for text-related generative\ntasks, such as text image generation, text editing, text removal, and text\nstyle transfer. Recently, some scene text segmentation methods have made\nsignificant progress in segmenting regular text. However, these methods perform\npoorly in scenarios containing artistic text. Therefore, this paper focuses on\nthe more challenging task of artistic text segmentation and constructs a real\nartistic text segmentation dataset. One challenge of the task is that the local\nstroke shapes of artistic text are changeable with diversity and complexity. We\npropose a decoder with the layer-wise momentum query to prevent the model from\nignoring stroke regions of special shapes. Another challenge is the complexity\nof the global topological structure. We further design a skeleton-assisted head\nto guide the model to focus on the global structure. Additionally, to enhance\nthe generalization performance of the text segmentation model, we propose a\nstrategy for training data synthesis, based on the large multi-modal model and\nthe diffusion model. Experimental results show that our proposed method and\nsynthetic dataset can significantly enhance the performance of artistic text\nsegmentation and achieve state-of-the-art results on other public datasets.", "paper_summary_zh": "\u6e96\u78ba\u7684\u6587\u5b57\u5206\u5272\u7d50\u679c\u5c0d\u65bc\u6587\u5b57\u76f8\u95dc\u7684\u751f\u6210\u4efb\u52d9\u81f3\u95dc\u91cd\u8981\uff0c\u4f8b\u5982\u6587\u5b57\u5f71\u50cf\u751f\u6210\u3001\u6587\u5b57\u7de8\u8f2f\u3001\u6587\u5b57\u79fb\u9664\u548c\u6587\u5b57\u6a23\u5f0f\u8f49\u79fb\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u5834\u666f\u6587\u5b57\u5206\u5272\u65b9\u6cd5\u5728\u5206\u5272\u898f\u5247\u6587\u5b57\u65b9\u9762\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\u3002\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u5728\u5305\u542b\u85dd\u8853\u6587\u5b57\u7684\u5834\u666f\u4e2d\u8868\u73fe\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u672c\u6587\u91cd\u9ede\u95dc\u6ce8\u66f4\u5177\u6311\u6230\u6027\u7684\u85dd\u8853\u6587\u5b57\u5206\u5272\u4efb\u52d9\uff0c\u4e26\u69cb\u5efa\u4e86\u4e00\u500b\u771f\u5be6\u7684\u85dd\u8853\u6587\u5b57\u5206\u5272\u8cc7\u6599\u96c6\u3002\u8a72\u4efb\u52d9\u7684\u4e00\u500b\u6311\u6230\u662f\u85dd\u8853\u6587\u5b57\u7684\u5c40\u90e8\u7b46\u756b\u5f62\u72c0\u6703\u96a8\u8457\u591a\u6a23\u6027\u548c\u8907\u96dc\u6027\u800c\u6539\u8b8a\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5177\u6709\u9010\u5c64\u52d5\u91cf\u67e5\u8a62\u7684\u89e3\u78bc\u5668\uff0c\u4ee5\u9632\u6b62\u6a21\u578b\u5ffd\u7565\u7279\u6b8a\u5f62\u72c0\u7684\u7b46\u756b\u5340\u57df\u3002\u53e6\u4e00\u500b\u6311\u6230\u662f\u5168\u5c40\u62d3\u64b2\u7d50\u69cb\u7684\u8907\u96dc\u6027\u3002\u6211\u5011\u9032\u4e00\u6b65\u8a2d\u8a08\u4e86\u4e00\u500b\u9aa8\u67b6\u8f14\u52a9\u982d\u90e8\uff0c\u4ee5\u5f15\u5c0e\u6a21\u578b\u95dc\u6ce8\u5168\u5c40\u7d50\u69cb\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u589e\u5f37\u6587\u5b57\u5206\u5272\u6a21\u578b\u7684\u6cdb\u5316\u6548\u80fd\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b\u548c\u64f4\u6563\u6a21\u578b\u7684\u8a13\u7df4\u8cc7\u6599\u5408\u6210\u7b56\u7565\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u5408\u6210\u8cc7\u6599\u96c6\u53ef\u4ee5\u986f\u8457\u589e\u5f37\u85dd\u8853\u6587\u5b57\u5206\u5272\u7684\u6548\u80fd\uff0c\u4e26\u5728\u5176\u4ed6\u516c\u958b\u8cc7\u6599\u96c6\u4e0a\u53d6\u5f97\u6700\u5148\u9032\u7684\u7d50\u679c\u3002", "author": "Xudong Xie et.al.", "authors": "Xudong Xie, Yuzhe Li, Yang Liu, Zhifei Zhang, Zhaowen Wang, Wei Xiong, Xiang Bai", "id": "2408.00106v1", "paper_url": "http://arxiv.org/abs/2408.00106v1", "repo": "null"}}