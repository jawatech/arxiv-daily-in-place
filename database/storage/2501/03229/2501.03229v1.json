{"2501.03229": {"publish_time": "2025-01-06", "title": "Gaussian Masked Autoencoders", "paper_summary": "This paper explores Masked Autoencoders (MAE) with Gaussian Splatting. While\nreconstructive self-supervised learning frameworks such as MAE learns good\nsemantic abstractions, it is not trained for explicit spatial awareness. Our\napproach, named Gaussian Masked Autoencoder, or GMAE, aims to learn semantic\nabstractions and spatial understanding jointly. Like MAE, it reconstructs the\nimage end-to-end in the pixel space, but beyond MAE, it also introduces an\nintermediate, 3D Gaussian-based representation and renders images via\nsplatting. We show that GMAE can enable various zero-shot learning capabilities\nof spatial understanding (e.g., figure-ground segmentation, image layering,\nedge detection, etc.) while preserving the high-level semantics of\nself-supervised representation quality from MAE. To our knowledge, we are the\nfirst to employ Gaussian primitives in an image representation learning\nframework beyond optimization-based single-scene reconstructions. We believe\nGMAE will inspire further research in this direction and contribute to\ndeveloping next-generation techniques for modeling high-fidelity visual data.\nMore details at https://brjathu.github.io/gmae", "paper_summary_zh": "\u9019\u7bc7\u8ad6\u6587\u63a2\u8a0e\u4e86\u5177\u6709\u9ad8\u65af\u6f51\u9ede\u7684\u906e\u7f69\u5f0f\u81ea\u52d5\u7de8\u78bc\u5668 (MAE)\u3002\u96d6\u7136\u50cf MAE \u9019\u6a23\u7684\u91cd\u5efa\u5f0f\u81ea\u6211\u76e3\u7763\u5b78\u7fd2\u67b6\u69cb\u5b78\u7fd2\u4e86\u826f\u597d\u7684\u8a9e\u7fa9\u62bd\u8c61\uff0c\u4f46\u5b83\u4e26\u672a\u91dd\u5c0d\u660e\u78ba\u7684\u7a7a\u9593\u611f\u77e5\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u7684\u65b9\u6cd5\u7a31\u70ba\u9ad8\u65af\u906e\u7f69\u5f0f\u81ea\u52d5\u7de8\u78bc\u5668\u6216 GMAE\uff0c\u65e8\u5728\u5171\u540c\u5b78\u7fd2\u8a9e\u7fa9\u62bd\u8c61\u548c\u7a7a\u9593\u7406\u89e3\u3002\u5b83\u8207 MAE \u4e00\u6a23\uff0c\u5728\u50cf\u7d20\u7a7a\u9593\u4e2d\u7aef\u5c0d\u7aef\u91cd\u5efa\u5f71\u50cf\uff0c\u4f46\u9664\u6b64\u4e4b\u5916\uff0c\u5b83\u9084\u5f15\u5165\u4e86\u4e2d\u9593\u7684 3D \u9ad8\u65af\u8868\u793a\uff0c\u4e26\u900f\u904e\u6f51\u9ede\u6e32\u67d3\u5f71\u50cf\u3002\u6211\u5011\u5c55\u793a\u4e86 GMAE \u80fd\u5920\u555f\u7528\u5404\u7a2e\u7a7a\u9593\u7406\u89e3\u7684\u96f6\u6b21\u5b78\u7fd2\u80fd\u529b\uff08\u4f8b\u5982\uff0c\u5716\u5f62\u5206\u5272\u3001\u5f71\u50cf\u5206\u5c64\u3001\u908a\u7de3\u6aa2\u6e2c\u7b49\uff09\uff0c\u540c\u6642\u4fdd\u7559 MAE \u81ea\u6211\u76e3\u7763\u8868\u793a\u54c1\u8cea\u7684\u9ad8\u968e\u8a9e\u7fa9\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u6211\u5011\u662f\u7b2c\u4e00\u500b\u5728\u5f71\u50cf\u8868\u793a\u5b78\u7fd2\u67b6\u69cb\u4e2d\u63a1\u7528\u9ad8\u65af\u57fa\u5143\uff0c\u800c\u9019\u8d85\u8d8a\u4e86\u57fa\u65bc\u6700\u4f73\u5316\u7684\u55ae\u4e00\u5834\u666f\u91cd\u5efa\u3002\u6211\u5011\u76f8\u4fe1 GMAE \u5c07\u6fc0\u52f5\u6b64\u65b9\u5411\u7684\u9032\u4e00\u6b65\u7814\u7a76\uff0c\u4e26\u6709\u52a9\u65bc\u958b\u767c\u65b0\u4e00\u4ee3\u7684\u9ad8\u4fdd\u771f\u8996\u89ba\u8cc7\u6599\u5efa\u6a21\u6280\u8853\u3002\u66f4\u591a\u8a73\u60c5\u8acb\u898b https://brjathu.github.io/gmae", "author": "Jathushan Rajasegaran et.al.", "authors": "Jathushan Rajasegaran, Xinlei Chen, Rulilong Li, Christoph Feichtenhofer, Jitendra Malik, Shiry Ginosar", "id": "2501.03229v1", "paper_url": "http://arxiv.org/abs/2501.03229v1", "repo": "null"}}