{"2406.18922": {"publish_time": "2024-06-27", "title": "Time Matters: Scaling Laws for Any Budget", "paper_summary": "A primary cost driver for training large models is wall-clock training time.\nWe show that popular time estimates based on FLOPs are poor estimates, and\nconstruct a more accurate proxy based on memory copies. We show that with some\nsimple accounting, we can estimate the training speed of a transformer model\nfrom its hyperparameters. Combined with a scaling law curve like Chinchilla,\nthis lets us estimate the final loss of the model. We fit our estimate to real\ndata with a linear regression, and apply the result to rewrite Chinchilla in\nterms of a model's estimated training time as opposed to the amount of training\ndata. This gives an expression for the loss in terms of the model's\nhyperparameters alone. We show that this expression is accurate across a wide\nrange of model hyperparameter values, enabling us to analytically make\narchitectural decisions and train models more efficiently.", "paper_summary_zh": "\u5927\u578b\u6a21\u578b\u8a13\u7df4\u7684\u4e3b\u8981\u6210\u672c\u9a45\u52d5\u56e0\u7d20\u662f\u5be6\u969b\u8a13\u7df4\u6642\u9593\u3002\n\u6211\u5011\u986f\u793a\u57fa\u65bc FLOP \u7684\u71b1\u9580\u6642\u9593\u4f30\u8a08\u503c\u662f\u8f03\u5dee\u7684\u4f30\u8a08\u503c\uff0c\n\u4e26\u6839\u64da\u8a18\u61b6\u9ad4\u8907\u88fd\u5efa\u69cb\u66f4\u6e96\u78ba\u7684\u4ee3\u7406\u3002\u6211\u5011\u986f\u793a\uff0c\u900f\u904e\u4e00\u4e9b\n\u7c21\u55ae\u7684\u8a08\u7b97\uff0c\u6211\u5011\u53ef\u4ee5\u5f9e\u5176\u8d85\u53c3\u6578\u4f30\u8a08Transformer\u6a21\u578b\u7684\u8a13\u7df4\u901f\u5ea6\u3002\u7d50\u5408\u985e\u4f3c Chinchilla \u7684\u6bd4\u4f8b\u5b9a\u5f8b\u66f2\u7dda\uff0c\n\u9019\u8b93\u6211\u5011\u53ef\u4ee5\u4f30\u8a08\u6a21\u578b\u7684\u6700\u7d42\u640d\u5931\u3002\u6211\u5011\u4f7f\u7528\u7dda\u6027\u56de\u6b78\u5c07\u6211\u5011\u7684\u4f30\u8a08\u503c\u5957\u7528\u5230\u771f\u5be6\n\u8cc7\u6599\uff0c\u4e26\u5c07\u7d50\u679c\u5957\u7528\u5728 Chinchilla \u4e2d\uff0c\u4ee5\u6a21\u578b\u7684\u9810\u4f30\u8a13\u7df4\u6642\u9593\u91cd\u5beb\uff0c\u800c\u4e0d\u662f\u8a13\u7df4\n\u8cc7\u6599\u91cf\u3002\u9019\u7d66\u51fa\u4e86\u50c5\u6839\u64da\u6a21\u578b\u8d85\u53c3\u6578\u7684\u640d\u5931\u8868\u9054\u5f0f\u3002\u6211\u5011\u986f\u793a\u6b64\u8868\u9054\u5f0f\u5728\u5ee3\u6cdb\n\u7684\u6a21\u578b\u8d85\u53c3\u6578\u503c\u7bc4\u570d\u5167\u662f\u6e96\u78ba\u7684\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u5206\u6790\u6027\u5730\u505a\u51fa\n\u67b6\u69cb\u6c7a\u7b56\u4e26\u66f4\u6709\u6548\u7387\u5730\u8a13\u7df4\u6a21\u578b\u3002", "author": "Itay Inbar et.al.", "authors": "Itay Inbar, Luke Sernau", "id": "2406.18922v1", "paper_url": "http://arxiv.org/abs/2406.18922v1", "repo": "null"}}