{"2410.11772": {"publish_time": "2024-10-15", "title": "Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models", "paper_summary": "Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant\npopularity for adapting pre-trained Large Language Models (LLMs) to downstream\ntasks, primarily due to their potential to significantly reduce memory and\ncomputational overheads. However, a common limitation in most PEFT approaches\nis their application of a uniform architectural design across all layers. This\nuniformity involves identical trainable modules and ignores the varying\nimportance of each layer, leading to sub-optimal fine-tuning results. To\novercome the above limitation and obtain better performance, we develop a novel\napproach, Importance-aware Sparse Tuning (IST), to fully utilize the inherent\nsparsity and select the most important subset of full layers with effective\nlayer-wise importance scoring. The proposed IST is a versatile and\nplug-and-play technique compatible with various PEFT methods that operate on a\nper-layer basis. By leveraging the estimated importance scores, IST dynamically\nupdates these selected layers in PEFT modules, leading to reduced memory\ndemands. We further provide theoretical proof of convergence and empirical\nevidence of superior performance to demonstrate the advantages of IST over\nuniform updating strategies. Extensive experiments on a range of LLMs, PEFTs,\nand downstream tasks substantiate the effectiveness of our proposed method,\nshowcasing IST's capacity to enhance existing layer-based PEFT methods. Our\ncode is available at https://github.com/Kaiseem/IST.", "paper_summary_zh": "\u53c3\u6578\u9ad8\u6548\u5fae\u8abf (PEFT) \u65b9\u6cd5\u56e0\u5176\u5c07\u9810\u5148\u8a13\u7df4\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9069\u61c9\u81f3\u4e0b\u6e38\u4efb\u52d9\u800c\u7372\u5f97\u986f\u8457\u7684\u666e\u53ca\uff0c\u9019\u4e3b\u8981\u6b78\u529f\u65bc\u5b83\u5011\u5927\u5e45\u6e1b\u5c11\u8a18\u61b6\u9ad4\u548c\u904b\u7b97\u8ca0\u64d4\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u5927\u591a\u6578 PEFT \u65b9\u6cd5\u7684\u5e38\u898b\u9650\u5236\u662f\u5b83\u5011\u5728\u6240\u6709\u5c64\u4e2d\u5957\u7528\u7d71\u4e00\u7684\u67b6\u69cb\u8a2d\u8a08\u3002\u9019\u7a2e\u7d71\u4e00\u6027\u5305\u542b\u76f8\u540c\u7684\u53ef\u8a13\u7df4\u6a21\u7d44\uff0c\u4e26\u5ffd\u7565\u6bcf\u500b\u5c64\u4e0d\u540c\u7684\u91cd\u8981\u6027\uff0c\u5c0e\u81f4\u6b21\u4f73\u7684\u5fae\u8abf\u7d50\u679c\u3002\u70ba\u4e86\u514b\u670d\u4e0a\u8ff0\u9650\u5236\u4e26\u7372\u5f97\u66f4\u597d\u7684\u6548\u80fd\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5373\u91cd\u8996\u7a00\u758f\u8abf\u6574 (IST)\uff0c\u4ee5\u5145\u5206\u5229\u7528\u5167\u5728\u7684\u7a00\u758f\u6027\uff0c\u4e26\u900f\u904e\u6709\u6548\u7684\u9010\u5c64\u91cd\u8981\u6027\u8a55\u5206\u4f86\u9078\u64c7\u6700\u91cd\u8981\u7684\u5b8c\u6574\u5c64\u5b50\u96c6\u3002\u6240\u63d0\u51fa\u7684 IST \u662f\u4e00\u7a2e\u901a\u7528\u4e14\u5373\u63d2\u5373\u7528\u7684\u6280\u8853\uff0c\u8207\u5404\u7a2e\u57fa\u65bc\u9010\u5c64\u904b\u4f5c\u7684 PEFT \u65b9\u6cd5\u76f8\u5bb9\u3002\u900f\u904e\u5229\u7528\u4f30\u8a08\u7684\u91cd\u8981\u6027\u5206\u6578\uff0cIST \u52d5\u614b\u66f4\u65b0 PEFT \u6a21\u7d44\u4e2d\u9019\u4e9b\u9078\u5b9a\u7684\u5c64\uff0c\u5f9e\u800c\u6e1b\u5c11\u8a18\u61b6\u9ad4\u9700\u6c42\u3002\u6211\u5011\u9032\u4e00\u6b65\u63d0\u4f9b\u4e86\u6536\u6582\u7684\u7406\u8ad6\u8b49\u660e\u548c\u512a\u7570\u6548\u80fd\u7684\u5be6\u8b49\u8b49\u64da\uff0c\u4ee5\u8b49\u660e IST \u512a\u65bc\u7d71\u4e00\u66f4\u65b0\u7b56\u7565\u7684\u512a\u9ede\u3002\u91dd\u5c0d\u5404\u7a2e LLM\u3001PEFT \u548c\u4e0b\u6e38\u4efb\u52d9\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u5be6\u4e86\u6211\u5011\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86 IST \u589e\u5f37\u73fe\u6709\u57fa\u65bc\u5c64\u7684 PEFT \u65b9\u6cd5\u7684\u80fd\u529b\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/Kaiseem/IST \u53d6\u5f97\u3002", "author": "Kai Yao et.al.", "authors": "Kai Yao, Penlei Gao, Lichun Li, Yuan Zhao, Xiaofeng Wang, Wei Wang, Jianke Zhu", "id": "2410.11772v1", "paper_url": "http://arxiv.org/abs/2410.11772v1", "repo": "https://github.com/kaiseem/ist"}}