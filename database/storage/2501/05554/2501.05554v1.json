{"2501.05554": {"publish_time": "2025-01-09", "title": "LLMQuoter: Enhancing RAG Capabilities Through Efficient Quote Extraction From Large Contexts", "paper_summary": "We introduce LLMQuoter, a lightweight, distillation-based model designed to\nenhance Retrieval Augmented Generation (RAG) by extracting the most relevant\ntextual evidence for downstream reasoning tasks. Built on the LLaMA-3B\narchitecture and fine-tuned with Low-Rank Adaptation (LoRA) on a 15,000-sample\nsubset of HotpotQA, LLMQuoter adopts a \"quote-first-then-answer\" strategy,\nefficiently identifying key quotes before passing curated snippets to reasoning\nmodels. This workflow reduces cognitive overhead and outperforms full-context\napproaches like Retrieval-Augmented Fine-Tuning (RAFT), achieving over 20-point\naccuracy gains across both small and large language models. By leveraging\nknowledge distillation from a high-performing teacher model, LLMQuoter achieves\ncompetitive results in a resource-efficient fine-tuning setup. It democratizes\nadvanced RAG capabilities, delivering significant performance improvements\nwithout requiring extensive model retraining. Our results highlight the\npotential of distilled quote-based reasoning to streamline complex workflows,\noffering a scalable and practical solution for researchers and practitioners\nalike.", "paper_summary_zh": "\u6211\u5011\u63a8\u51fa LLMQuoter\uff0c\u9019\u662f\u4e00\u500b\u8f15\u91cf\u7d1a\u7684\u3001\u57fa\u65bc\u84b8\u993e\u7684\u6a21\u578b\uff0c\u65e8\u5728\u900f\u904e\u64f7\u53d6\u8207\u4e0b\u6e38\u63a8\u7406\u4efb\u52d9\u6700\u76f8\u95dc\u7684\u6587\u5b57\u8b49\u64da\u4f86\u589e\u5f37\u6aa2\u7d22\u64f4\u589e\u751f\u6210 (RAG)\u3002LLMQuoter \u5efa\u7acb\u5728 LLaMA-3B \u67b6\u69cb\u4e0a\uff0c\u4e26\u4f7f\u7528\u4f4e\u79e9\u9069\u61c9 (LoRA) \u5728 HotpotQA \u7684 15,000 \u500b\u6a23\u672c\u5b50\u96c6\u4e0a\u9032\u884c\u5fae\u8abf\uff0c\u63a1\u7528\u300c\u5148\u5f15\u7528\u518d\u56de\u7b54\u300d\u7b56\u7565\uff0c\u5728\u5c07\u7cbe\u9078\u7247\u6bb5\u50b3\u905e\u7d66\u63a8\u7406\u6a21\u578b\u4e4b\u524d\uff0c\u6709\u6548\u8b58\u5225\u95dc\u9375\u5f15\u7528\u3002\u9019\u500b\u5de5\u4f5c\u6d41\u7a0b\u6e1b\u5c11\u4e86\u8a8d\u77e5\u8ca0\u64d4\uff0c\u4e26\u4e14\u512a\u65bc\u5168\u5167\u5bb9\u65b9\u6cd5\uff0c\u4f8b\u5982\u6aa2\u7d22\u64f4\u589e\u5fae\u8abf (RAFT)\uff0c\u5728\u5c0f\u578b\u548c\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d\u90fd\u7372\u5f97\u8d85\u904e 20 \u9ede\u7684\u6e96\u78ba\u5ea6\u63d0\u5347\u3002\u900f\u904e\u5229\u7528\u9ad8\u6027\u80fd\u6559\u5e2b\u6a21\u578b\u7684\u77e5\u8b58\u84b8\u993e\uff0cLLMQuoter \u5728\u8cc7\u6e90\u6548\u7387\u5fae\u8abf\u8a2d\u5b9a\u4e2d\u53d6\u5f97\u4e86\u7af6\u722d\u529b\u7684\u7d50\u679c\u3002\u5b83\u6c11\u4e3b\u5316\u4e86\u9032\u968e RAG \u529f\u80fd\uff0c\u5728\u4e0d\u9700\u8981\u5ee3\u6cdb\u6a21\u578b\u91cd\u65b0\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\uff0c\u63d0\u4f9b\u4e86\u986f\u8457\u7684\u6027\u80fd\u6539\u9032\u3002\u6211\u5011\u7684\u7d50\u679c\u7a81\u986f\u4e86\u57fa\u65bc\u5f15\u7528\u7684\u84b8\u993e\u63a8\u7406\u5728\u7c21\u5316\u8907\u96dc\u5de5\u4f5c\u6d41\u7a0b\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u70ba\u7814\u7a76\u4eba\u54e1\u548c\u5f9e\u696d\u4eba\u54e1\u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u64f4\u5145\u4e14\u5be6\u7528\u7684\u89e3\u6c7a\u65b9\u6848\u3002", "author": "Yuri Facanha Bezerra et.al.", "authors": "Yuri Facanha Bezerra, Li Weigang", "id": "2501.05554v1", "paper_url": "http://arxiv.org/abs/2501.05554v1", "repo": "https://github.com/yurifacanha/llmquoter"}}