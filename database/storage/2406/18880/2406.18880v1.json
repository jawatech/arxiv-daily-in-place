{"2406.18880": {"publish_time": "2024-06-27", "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models", "paper_summary": "Recently, very large language models (LLMs) have shown exceptional\nperformance on several English NLP tasks with just in-context learning (ICL),\nbut their utility in other languages is still underexplored. We investigate\ntheir effectiveness for NLP tasks in low-resource languages (LRLs), especially\nin the setting of zero-labelled cross-lingual transfer (0-CLT), where no\nlabelled training data for the target language is available -- however training\ndata from one or more related medium-resource languages (MRLs) is utilized,\nalongside the available unlabeled test data for a target language. We introduce\nSelf-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT\nsetting.\n  SSP is based on the key observation that LLMs output more accurate labels if\nin-context exemplars are from the target language (even if their labels are\nslightly noisy). To operationalize this, since target language training data is\nnot available in 0-CLT, SSP operates in two stages. In Stage I, using source\nMRL training data, target language's test data is noisily labeled. In Stage II,\nthese noisy test data points are used as exemplars in ICL for further improved\nlabelling. Additionally, our implementation of SSP uses a novel Integer Linear\nProgramming (ILP)-based exemplar selection that balances similarity, prediction\nconfidence (when available) and label coverage. Experiments on three tasks and\neleven LRLs (from three regions) demonstrate that SSP strongly outperforms\nexisting SOTA fine-tuned and prompting-based baselines in 0-CLT setup.", "paper_summary_zh": "\u6700\u8fd1\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5728\u4ec5\u4f7f\u7528\u8bed\u5883\u5b66\u4e60 (ICL) \u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u591a\u9879\u82f1\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u5176\u4ed6\u8bed\u8a00\u4e2d\u7684\u6548\u7528\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u6211\u4eec\u8c03\u67e5\u4e86\u5b83\u4eec\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00 (LRL) \u4e2d\u6267\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u96f6\u6807\u8bb0\u8de8\u8bed\u8a00\u8fc1\u79fb (0-CLT) \u7684\u8bbe\u7f6e\u4e2d\uff0c\u5176\u4e2d\u6ca1\u6709\u76ee\u6807\u8bed\u8a00\u7684\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u53ef\u7528\u2014\u2014\u4f46\u6765\u81ea\u4e00\u4e2a\u6216\u591a\u4e2a\u76f8\u5173\u7684\u4e2d\u7b49\u8d44\u6e90\u8bed\u8a00 (MRL) \u7684\u8bad\u7ec3\u6570\u636e\u88ab\u5229\u7528\uff0c\u4ee5\u53ca\u76ee\u6807\u8bed\u8a00\u7684\u53ef\u7528\u672a\u6807\u8bb0\u6d4b\u8bd5\u6570\u636e\u3002\u6211\u4eec\u5f15\u5165\u4e86\u81ea\u76d1\u7763\u63d0\u793a (SSP)\uff0c\u8fd9\u662f\u4e00\u79cd\u9488\u5bf9 0-CLT \u8bbe\u7f6e\u91cf\u8eab\u5b9a\u5236\u7684\u65b0\u578b ICL \u65b9\u6cd5\u3002\nSSP \u57fa\u4e8e\u4e00\u4e2a\u5173\u952e\u89c2\u5bdf\uff0c\u5373\u5982\u679c\u8bed\u5883\u793a\u4f8b\u6765\u81ea\u76ee\u6807\u8bed\u8a00\uff08\u5373\u4f7f\u5b83\u4eec\u7684\u6807\u7b7e\u6709\u70b9\u5608\u6742\uff09\uff0cLLM \u8f93\u51fa\u7684\u6807\u7b7e\u4f1a\u66f4\u51c6\u786e\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u7531\u4e8e\u5728 0-CLT \u4e2d\u6ca1\u6709\u76ee\u6807\u8bed\u8a00\u8bad\u7ec3\u6570\u636e\uff0cSSP \u5206\u4e24\u4e2a\u9636\u6bb5\u64cd\u4f5c\u3002\u5728\u7b2c\u4e00\u9636\u6bb5\uff0c\u4f7f\u7528\u6e90 MRL \u8bad\u7ec3\u6570\u636e\uff0c\u5bf9\u76ee\u6807\u8bed\u8a00\u7684\u6d4b\u8bd5\u6570\u636e\u8fdb\u884c\u566a\u58f0\u6807\u8bb0\u3002\u5728\u7b2c\u4e8c\u9636\u6bb5\uff0c\u8fd9\u4e9b\u5608\u6742\u7684\u6d4b\u8bd5\u6570\u636e\u70b9\u88ab\u7528\u4f5c ICL \u4e2d\u7684\u793a\u4f8b\uff0c\u4ee5\u8fdb\u4e00\u6b65\u6539\u8fdb\u6807\u8bb0\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5bf9 SSP \u7684\u5b9e\u73b0\u4f7f\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212 (ILP) \u7684\u793a\u4f8b\u9009\u62e9\uff0c\u5b83\u5e73\u8861\u4e86\u76f8\u4f3c\u6027\u3001\u9884\u6d4b\u7f6e\u4fe1\u5ea6\uff08\u5982\u679c\u53ef\u7528\uff09\u548c\u6807\u7b7e\u8986\u76d6\u7387\u3002\u5bf9\u4e09\u4e2a\u4efb\u52a1\u548c\u5341\u4e00\u4e2a LRL\uff08\u6765\u81ea\u4e09\u4e2a\u533a\u57df\uff09\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSSP \u5728 0-CLT \u8bbe\u7f6e\u4e2d\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u7684 SOTA \u5fae\u8c03\u548c\u57fa\u4e8e\u63d0\u793a\u7684\u57fa\u51c6\u3002", "author": "Vipul Rathore et.al.", "authors": "Vipul Rathore, Aniruddha Deb, Ankish Chandresh, Parag Singla, Mausam", "id": "2406.18880v1", "paper_url": "http://arxiv.org/abs/2406.18880v1", "repo": "https://github.com/dair-iitd/SSP"}}