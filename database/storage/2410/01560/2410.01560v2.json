{"2410.01560": {"publish_time": "2024-10-02", "title": "OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data", "paper_summary": "Mathematical reasoning continues to be a critical challenge in large language\nmodel (LLM) development with significant interest. However, most of the\ncutting-edge progress in mathematical reasoning with LLMs has become\n\\emph{closed-source} due to lack of access to training data. This lack of data\naccess limits researchers from understanding the impact of different choices\nfor synthesizing and utilizing the data. With the goal of creating a\nhigh-quality finetuning (SFT) dataset for math reasoning, we conduct careful\nablation experiments on data synthesis using the recently released\n\\texttt{Llama3.1} family of models. Our experiments show that: (a) solution\nformat matters, with excessively verbose solutions proving detrimental to SFT\nperformance, (b) data generated by a strong teacher outperforms equally-sized\ndata generated by a weak student model, (c) SFT is robust to low-quality\nsolutions, allowing for imprecise data filtering, and (d) question diversity is\ncrucial for achieving data scaling gains. Based on these insights, we create\nthe OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs\n($\\approx$ 600K unique questions), making it nearly eight times larger than the\nprevious largest open-source math reasoning dataset. Finetuning the\n\\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms\n\\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\\% (51.9\\%\n$\\rightarrow$ 67.8\\%). Finally, to accelerate the open-source efforts, we\nrelease the code, the finetuned models, and the OpenMathInstruct-2 dataset\nunder a commercially permissive license.", "paper_summary_zh": "<paragraph>\u6578\u5b78\u63a8\u7406\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u767c\u5c55\u4e2d\u6301\u7e8c\u6210\u70ba\u4e00\u9805\u95dc\u9375\u6311\u6230\uff0c\u4e26\u5f15\u8d77\u6975\u5927\u7684\u8208\u8da3\u3002\u7136\u800c\uff0c\u7531\u65bc\u7f3a\u4e4f\u8a13\u7df4\u8cc7\u6599\u7684\u5b58\u53d6\uff0c\u5927\u591a\u6578 LLM \u5728\u6578\u5b78\u63a8\u7406\u65b9\u9762\u7684\u5c16\u7aef\u9032\u5c55\u5df2\u6210\u70ba\u300c\u5c01\u9589\u539f\u59cb\u78bc\u300d\u3002\u9019\u7a2e\u8cc7\u6599\u5b58\u53d6\u7684\u7f3a\u4e4f\u9650\u5236\u4e86\u7814\u7a76\u4eba\u54e1\u4e86\u89e3\u4e0d\u540c\u9078\u64c7\u5c0d\u7d9c\u5408\u548c\u5229\u7528\u8cc7\u6599\u7684\u5f71\u97ff\u3002\u70ba\u4e86\u5efa\u7acb\u4e00\u500b\u7528\u65bc\u6578\u5b78\u63a8\u7406\u7684\u9ad8\u54c1\u8cea\u5fae\u8abf (SFT) \u8cc7\u6599\u96c6\uff0c\u6211\u5011\u4f7f\u7528\u6700\u8fd1\u767c\u5e03\u7684 \\texttt{Llama3.1} \u6a21\u578b\u7cfb\u5217\u5c0d\u8cc7\u6599\u5408\u6210\u9032\u884c\u4e86\u4ed4\u7d30\u7684\u6d88\u878d\u5be6\u9a57\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff1a(a) \u89e3\u7b54\u683c\u5f0f\u5f88\u91cd\u8981\uff0c\u904e\u65bc\u5197\u9577\u7684\u89e3\u7b54\u6703\u5c0d SFT \u6548\u80fd\u9020\u6210\u640d\u5bb3\uff0c(b) \u7531\u5f37\u8001\u5e2b\u7522\u751f\u7684\u8cc7\u6599\u512a\u65bc\u7531\u5f31\u5b78\u751f\u6a21\u578b\u7522\u751f\u7684\u76f8\u540c\u5927\u5c0f\u8cc7\u6599\uff0c(c) SFT \u5c0d\u4f4e\u54c1\u8cea\u89e3\u7b54\u5177\u6709\u9b6f\u68d2\u6027\uff0c\u5141\u8a31\u9032\u884c\u4e0d\u7cbe\u78ba\u7684\u8cc7\u6599\u904e\u6ffe\uff0c\u4ee5\u53ca (d) \u554f\u984c\u7684\u591a\u6a23\u6027\u5c0d\u65bc\u5be6\u73fe\u8cc7\u6599\u64f4\u5145\u589e\u76ca\u81f3\u95dc\u91cd\u8981\u3002\u6839\u64da\u9019\u4e9b\u898b\u89e3\uff0c\u6211\u5011\u5efa\u7acb\u4e86 OpenMathInstruct-2 \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 1400 \u842c\u500b\u554f\u984c\u89e3\u7b54\u5c0d\uff08\u7d04 60 \u842c\u500b\u7368\u7279\u554f\u984c\uff09\uff0c\u4f7f\u5176\u898f\u6a21\u5e7e\u4e4e\u662f\u4e4b\u524d\u6700\u5927\u7684\u958b\u6e90\u6578\u5b78\u63a8\u7406\u8cc7\u6599\u96c6\u7684\u516b\u500d\u3002\u4f7f\u7528 OpenMathInstruct-2 \u5fae\u8abf \\texttt{Llama-3.1-8B-Base} \u5728 MATH \u4e0a\u7684\u8868\u73fe\u512a\u65bc \\texttt{Llama3.1-8B-Instruct}\uff0c\u7d55\u5c0d\u512a\u52e2 15.9%\uff0851.9% \u2192 67.8%\uff09\u3002\u6700\u5f8c\uff0c\u70ba\u4e86\u52a0\u901f\u958b\u6e90\u5de5\u4f5c\uff0c\u6211\u5011\u5728\u5546\u696d\u8a31\u53ef\u4e0b\u767c\u5e03\u4e86\u7a0b\u5f0f\u78bc\u3001\u5fae\u8abf\u6a21\u578b\u548c OpenMathInstruct-2 \u8cc7\u6599\u96c6\u3002</paragraph>", "author": "Shubham Toshniwal et.al.", "authors": "Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman", "id": "2410.01560v2", "paper_url": "http://arxiv.org/abs/2410.01560v2", "repo": "https://github.com/kipok/nemo-skills"}}