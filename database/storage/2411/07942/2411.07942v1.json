{"2411.07942": {"publish_time": "2024-11-12", "title": "Towards Low-bit Communication for Tensor Parallel LLM Inference", "paper_summary": "Tensor parallelism provides an effective way to increase server large\nlanguage model (LLM) inference efficiency despite adding an additional\ncommunication cost. However, as server LLMs continue to scale in size, they\nwill need to be distributed across more devices, magnifying the communication\ncost. One way to approach this problem is with quantization, but current\nmethods for LLMs tend to avoid quantizing the features that tensor parallelism\nneeds to communicate. Taking advantage of consistent outliers in communicated\nfeatures, we introduce a quantization method that reduces communicated values\non average from 16 bits to 4.2 bits while preserving nearly all of the original\nperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma\n2 27B's and Llama 2 13B's original performance, respectively, averaged across\nall tasks we evaluated on.", "paper_summary_zh": "\u5f35\u91cf\u4e26\u884c\u63d0\u4f9b\u4e86\u589e\u52a0\u4f3a\u670d\u5668\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u63a8\u8ad6\u6548\u7387\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5118\u7ba1\u589e\u52a0\u4e86\u984d\u5916\u7684\u901a\u8a0a\u6210\u672c\u3002\u7136\u800c\uff0c\u7531\u65bc\u4f3a\u670d\u5668 LLM \u6301\u7e8c\u64f4\u5927\u898f\u6a21\uff0c\u5b83\u5011\u9700\u8981\u5206\u4f48\u5728\u66f4\u591a\u88dd\u7f6e\u4e0a\uff0c\u9019\u6703\u653e\u5927\u901a\u8a0a\u6210\u672c\u3002\u89e3\u6c7a\u6b64\u554f\u984c\u7684\u4e00\u7a2e\u65b9\u6cd5\u662f\u91cf\u5316\uff0c\u4f46 LLM \u7684\u7576\u524d\u65b9\u6cd5\u50be\u5411\u65bc\u907f\u514d\u91cf\u5316\u5f35\u91cf\u4e26\u884c\u9700\u8981\u901a\u8a0a\u7684\u529f\u80fd\u3002\u6211\u5011\u5229\u7528\u901a\u8a0a\u529f\u80fd\u4e2d\u7684\u4e00\u81f4\u7570\u5e38\u503c\uff0c\u5f15\u5165\u4e00\u7a2e\u91cf\u5316\u65b9\u6cd5\uff0c\u53ef\u5c07\u901a\u8a0a\u503c\u5e73\u5747\u5f9e 16 \u4f4d\u5143\u6e1b\u5c11\u5230 4.2 \u4f4d\u5143\uff0c\u540c\u6642\u4fdd\u7559\u5e7e\u4e4e\u6240\u6709\u539f\u59cb\u6548\u80fd\u3002\u4f8b\u5982\uff0c\u6211\u5011\u7684\u6a21\u578b\u5206\u5225\u7dad\u6301\u4e86 Gemma 2 27B \u548c Llama 2 13B \u7684\u7d04 98.0% \u548c 99.5% \u539f\u59cb\u6548\u80fd\uff0c\u5e73\u5747\u5728\u6211\u5011\u8a55\u4f30\u7684\u6240\u6709\u4efb\u52d9\u4e2d\u3002", "author": "Harry Dong et.al.", "authors": "Harry Dong, Tyler Johnson, Minsik Cho, Emad Soroush", "id": "2411.07942v1", "paper_url": "http://arxiv.org/abs/2411.07942v1", "repo": "null"}}