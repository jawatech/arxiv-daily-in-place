{"2405.16836": {"publish_time": "2024-05-27", "title": "Enhancing Fast Feed Forward Networks with Load Balancing and a Master Leaf Node", "paper_summary": "Fast feedforward networks (FFFs) are a class of neural networks that exploit\nthe observation that different regions of the input space activate distinct\nsubsets of neurons in wide networks. FFFs partition the input space into\nseparate sections using a differentiable binary tree of neurons and during\ninference descend the binary tree in order to improve computational efficiency.\nInspired by Mixture of Experts (MoE) research, we propose the incorporation of\nload balancing and Master Leaf techniques into the FFF architecture to improve\nperformance and simplify the training process. We reproduce experiments found\nin literature and present results on FFF models enhanced using these\ntechniques. The proposed architecture and training recipe achieves up to 16.3%\nand 3% absolute classification accuracy increase in training and test accuracy,\nrespectively, compared to the original FFF architecture. Additionally, we\nobserve a smaller variance in the results compared to those reported in prior\nresearch. These findings demonstrate the potential of integrating MoE-inspired\ntechniques into FFFs for developing more accurate and efficient models.", "paper_summary_zh": "\u5feb\u901f\u524d\u9988\u7f51\u7edc (FFF) \u662f\u4e00\u7c7b\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u5229\u7528\u4e86\u8f93\u5165\u7a7a\u95f4\u7684\u4e0d\u540c\u533a\u57df\u6fc0\u6d3b\u5bbd\u7f51\u7edc\u4e2d\u4e0d\u540c\u795e\u7ecf\u5143\u5b50\u96c6\u7684\u89c2\u5bdf\u7ed3\u679c\u3002FFF \u4f7f\u7528\u53ef\u5fae\u4e8c\u53c9\u6811\u795e\u7ecf\u5143\u5c06\u8f93\u5165\u7a7a\u95f4\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u90e8\u5206\uff0c\u5e76\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e0b\u964d\u4e8c\u53c9\u6811\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002\u53d7\u5230\u4e13\u5bb6\u6df7\u5408 (MoE) \u7814\u7a76\u7684\u542f\u53d1\uff0c\u6211\u4eec\u5efa\u8bae\u5c06\u8d1f\u8f7d\u5e73\u8861\u548c\u4e3b\u53f6\u6280\u672f\u7eb3\u5165 FFF \u67b6\u6784\uff0c\u4ee5\u63d0\u9ad8\u6027\u80fd\u5e76\u7b80\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002\u6211\u4eec\u91cd\u73b0\u4e86\u6587\u732e\u4e2d\u53d1\u73b0\u7684\u5b9e\u9a8c\uff0c\u5e76\u5c55\u793a\u4e86\u4f7f\u7528\u8fd9\u4e9b\u6280\u672f\u589e\u5f3a\u7684 FFF \u6a21\u578b\u7684\u7ed3\u679c\u3002\u4e0e\u539f\u59cb FFF \u67b6\u6784\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u67b6\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\u5206\u522b\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u51c6\u786e\u6027\u65b9\u9762\u5b9e\u73b0\u4e86\u9ad8\u8fbe 16.3% \u548c 3% \u7684\u7edd\u5bf9\u5206\u7c7b\u51c6\u786e\u6027\u63d0\u5347\u3002\u6b64\u5916\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u4e0e\u5148\u524d\u7814\u7a76\u62a5\u544a\u7684\u7ed3\u679c\u76f8\u6bd4\uff0c\u7ed3\u679c\u7684\u5dee\u5f02\u8f83\u5c0f\u3002\u8fd9\u4e9b\u53d1\u73b0\u8bc1\u660e\u4e86\u5c06\u53d7 MoE \u542f\u53d1\u7684\u6280\u672f\u96c6\u6210\u5230 FFF \u4e2d\u4ee5\u5f00\u53d1\u66f4\u51c6\u786e\u3001\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u7684\u6f5c\u529b\u3002", "author": "Andreas Charalampopoulos et.al.", "authors": "Andreas Charalampopoulos, Nikolas Chatzis, Foivos Ntoulas-Panagiotopoulos, Charilaos Papaioannou, Alexandros Potamianos", "id": "2405.16836v1", "paper_url": "http://arxiv.org/abs/2405.16836v1", "repo": "null"}}