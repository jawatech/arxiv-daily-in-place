{"2406.10057": {"publish_time": "2024-06-14", "title": "First Multi-Dimensional Evaluation of Flowchart Comprehension for Multimodal Large Language Models", "paper_summary": "With the development of multimodal large language models (MLLMs) technology,\nits general capabilities are increasingly powerful. To evaluate the various\nabilities of MLLMs, numerous evaluation systems have emerged. But now there is\nstill a lack of a comprehensive method to evaluate MLLMs in the tasks related\nto flowcharts, which are very important in daily life and work. We propose the\nfirst comprehensive method, FlowCE, to assess MLLMs across various dimensions\nfor tasks related to flowcharts. It encompasses evaluating MLLMs' abilities in\nReasoning, Localization Recognition, Information Extraction, Logical\nVerification, and Summarization on flowcharts. However, we find that even the\nGPT4o model achieves only a score of 56.63. Among open-source models,\nPhi-3-Vision obtained the highest score of 49.97. We hope that FlowCE can\ncontribute to future research on multimodal large language models (MLLMs) for\ntasks based on flowcharts. We are open-sourcing this project:\n\\url{https://github.com/360AILAB-NLP/FlowCE}", "paper_summary_zh": "\u96a8\u8457\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08MLLM\uff09\u6280\u8853\u7684\u767c\u5c55\uff0c\u5176\u7d9c\u5408\u80fd\u529b\u8d8a\u4f86\u8d8a\u5f37\u5927\u3002\u70ba\u4e86\u8a55\u4f30 MLLM \u7684\u5404\u7a2e\u80fd\u529b\uff0c\u5df2\u7d93\u51fa\u73fe\u4e86\u8a31\u591a\u8a55\u4f30\u7cfb\u7d71\u3002\u4f46\u76ee\u524d\u4ecd\u7136\u7f3a\u4e4f\u4e00\u7a2e\u7d9c\u5408\u7684\u65b9\u6cd5\u4f86\u8a55\u4f30 MLLM \u5728\u8207\u6d41\u7a0b\u5716\u76f8\u95dc\u7684\u4efb\u52d9\u4e2d\uff0c\u9019\u5728\u65e5\u5e38\u751f\u6d3b\u548c\u5de5\u4f5c\u4e2d\u975e\u5e38\u91cd\u8981\u3002\u6211\u5011\u63d0\u51fa\u4e86\u7b2c\u4e00\u500b\u7d9c\u5408\u6027\u65b9\u6cd5 FlowCE\uff0c\u7528\u65bc\u8a55\u4f30 MLLM \u5728\u8207\u6d41\u7a0b\u5716\u76f8\u95dc\u7684\u4efb\u52d9\u7684\u5404\u500b\u7dad\u5ea6\u3002\u5b83\u5305\u62ec\u8a55\u4f30 MLLM \u5728\u6d41\u7a0b\u5716\u4e0a\u7684\u63a8\u7406\u3001\u5b9a\u4f4d\u8b58\u5225\u3001\u8cc7\u8a0a\u8403\u53d6\u3001\u908f\u8f2f\u9a57\u8b49\u548c\u6458\u8981\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u6211\u5011\u767c\u73fe\u5373\u4f7f\u662f GPT4o \u6a21\u578b\u4e5f\u53ea\u7372\u5f97\u4e86 56.63 \u7684\u5206\u6578\u3002\u5728\u958b\u6e90\u6a21\u578b\u4e2d\uff0cPhi-3-Vision \u7372\u5f97\u4e86 49.97 \u7684\u6700\u9ad8\u5206\u3002\u6211\u5011\u5e0c\u671b FlowCE \u80fd\u5920\u70ba\u57fa\u65bc\u6d41\u7a0b\u5716\u4efb\u52d9\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u672a\u4f86\u7814\u7a76\u505a\u51fa\u8ca2\u737b\u3002\u6211\u5011\u958b\u653e\u4e86\u9019\u500b\u5c08\u6848\uff1a\\url{https://github.com/360AILAB-NLP/FlowCE}", "author": "Enming Zhang et.al.", "authors": "Enming Zhang, Ruobing Yao, Huanyong Liu, Junhui Yu, Jiale Wang", "id": "2406.10057v1", "paper_url": "http://arxiv.org/abs/2406.10057v1", "repo": "null"}}