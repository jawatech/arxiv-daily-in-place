{"2406.09981": {"publish_time": "2024-06-14", "title": "Challenges in explaining deep learning models for data with biological variation", "paper_summary": "Much machine learning research progress is based on developing models and\nevaluating them on a benchmark dataset (e.g., ImageNet for images). However,\napplying such benchmark-successful methods to real-world data often does not\nwork as expected. This is particularly the case for biological data where we\nexpect variability at multiple time and spatial scales. In this work, we are\nusing grain data and the goal is to detect diseases and damages. Pink fusarium,\nskinned grains, and other diseases and damages are key factors in setting the\nprice of grains or excluding dangerous grains from food production. Apart from\nchallenges stemming from differences of the data from the standard toy\ndatasets, we also present challenges that need to be overcome when explaining\ndeep learning models. For example, explainability methods have many\nhyperparameters that can give different results, and the ones published in the\npapers do not work on dissimilar images. Other challenges are more general:\nproblems with visualization of the explanations and their comparison since the\nmagnitudes of their values differ from method to method. An open fundamental\nquestion also is: How to evaluate explanations? It is a non-trivial task\nbecause the \"ground truth\" is usually missing or ill-defined. Also, human\nannotators may create what they think is an explanation of the task at hand,\nyet the machine learning model might solve it in a different and perhaps\ncounter-intuitive way. We discuss several of these challenges and evaluate\nvarious post-hoc explainability methods on grain data. We focus on robustness,\nquality of explanations, and similarity to particular \"ground truth\"\nannotations made by experts. The goal is to find the methods that overall\nperform well and could be used in this challenging task. We hope the proposed\npipeline will be used as a framework for evaluating explainability methods in\nspecific use cases.", "paper_summary_zh": "\u8a31\u591a\u6a5f\u5668\u5b78\u7fd2\u7814\u7a76\u9032\u5c55\u90fd\u662f\u5efa\u7acb\u5728\u958b\u767c\u6a21\u578b\uff0c\u4e26\u5728\u57fa\u6e96\u8cc7\u6599\u96c6\uff08\u4f8b\u5982\uff0c\u7528\u65bc\u5f71\u50cf\u7684 ImageNet\uff09\u4e0a\u8a55\u4f30\u6a21\u578b\u3002\u7136\u800c\uff0c\u5c07\u9019\u4e9b\u57fa\u6e96\u6210\u529f\u7684\u6a21\u578b\u61c9\u7528\u65bc\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u6642\uff0c\u901a\u5e38\u7121\u6cd5\u5982\u9810\u671f\u822c\u904b\u4f5c\u3002\u9019\u7279\u5225\u9069\u7528\u65bc\u751f\u7269\u8cc7\u6599\uff0c\u56e0\u70ba\u6211\u5011\u9810\u671f\u6703\u5728\u591a\u91cd\u6642\u9593\u548c\u7a7a\u9593\u5c3a\u5ea6\u4e2d\u51fa\u73fe\u8b8a\u7570\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4f7f\u7528\u7a40\u7269\u8cc7\u6599\uff0c\u76ee\u6a19\u662f\u5075\u6e2c\u75be\u75c5\u548c\u640d\u5bb3\u3002\u7c89\u7d05\u9ef4\u83cc\u3001\u525d\u76ae\u7a40\u7269\u548c\u5176\u4ed6\u75be\u75c5\u548c\u640d\u5bb3\u662f\u8a2d\u5b9a\u7a40\u7269\u50f9\u683c\u6216\u6392\u9664\u5371\u96aa\u7a40\u7269\u65bc\u98df\u54c1\u751f\u7522\u4e2d\u7684\u95dc\u9375\u56e0\u7d20\u3002\u9664\u4e86\u6e90\u81ea\u8cc7\u6599\u8207\u6a19\u6e96\u73a9\u5177\u8cc7\u6599\u96c6\u5dee\u7570\u7684\u6311\u6230\u5916\uff0c\u6211\u5011\u4e5f\u63d0\u51fa\u5728\u89e3\u91cb\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u6642\u9700\u8981\u514b\u670d\u7684\u6311\u6230\u3002\u4f8b\u5982\uff0c\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u6709\u8a31\u591a\u8d85\u53c3\u6578\uff0c\u53ef\u80fd\u6703\u7522\u751f\u4e0d\u540c\u7684\u7d50\u679c\uff0c\u4e14\u767c\u8868\u5728\u8ad6\u6587\u4e2d\u7684\u65b9\u6cd5\u7121\u6cd5\u7528\u65bc\u76f8\u7570\u7684\u5f71\u50cf\u3002\u5176\u4ed6\u6311\u6230\u8f03\u70ba\u666e\u904d\uff1a\u89e3\u91cb\u7684\u8996\u89ba\u5316\u548c\u6bd4\u8f03\u6709\u554f\u984c\uff0c\u56e0\u70ba\u5b83\u5011\u6578\u503c\u7684\u5927\u5c0f\u56e0\u65b9\u6cd5\u800c\u7570\u3002\u4e00\u500b\u958b\u653e\u7684\u57fa\u672c\u554f\u984c\u662f\uff1a\u5982\u4f55\u8a55\u4f30\u89e3\u91cb\uff1f\u9019\u9805\u4efb\u52d9\u4e26\u4e0d\u5bb9\u6613\uff0c\u56e0\u70ba\u300c\u57fa\u672c\u4e8b\u5be6\u300d\u901a\u5e38\u4e0d\u5b58\u5728\u6216\u5b9a\u7fa9\u4e0d\u660e\u78ba\u3002\u6b64\u5916\uff0c\u4eba\u985e\u8a3b\u89e3\u8005\u53ef\u80fd\u6703\u5efa\u7acb\u4ed6\u5011\u8a8d\u70ba\u662f\u624b\u908a\u4efb\u52d9\u89e3\u91cb\u7684\u5167\u5bb9\uff0c\u4f46\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u53ef\u80fd\u6703\u4ee5\u4e0d\u540c\u4e14\u53ef\u80fd\u9055\u53cd\u76f4\u89ba\u7684\u65b9\u5f0f\u89e3\u6c7a\u4efb\u52d9\u3002\u6211\u5011\u8a0e\u8ad6\u4e86\u5176\u4e2d\u5e7e\u500b\u6311\u6230\uff0c\u4e26\u5728\u7a40\u7269\u8cc7\u6599\u4e0a\u8a55\u4f30\u5404\u7a2e\u4e8b\u5f8c\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u3002\u6211\u5011\u5c08\u6ce8\u65bc\u7a69\u5065\u6027\u3001\u89e3\u91cb\u7684\u54c1\u8cea\uff0c\u4ee5\u53ca\u8207\u5c08\u5bb6\u6240\u505a\u7684\u7279\u5b9a\u300c\u57fa\u672c\u4e8b\u5be6\u300d\u8a3b\u89e3\u7684\u76f8\u4f3c\u6027\u3002\u76ee\u6a19\u662f\u627e\u51fa\u6574\u9ad4\u8868\u73fe\u826f\u597d\u7684\u65b9\u6cd5\uff0c\u4e26\u80fd\u7528\u65bc\u9019\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\u3002\u6211\u5011\u5e0c\u671b\u6240\u63d0\u51fa\u7684\u6d41\u7a0b\u5c07\u88ab\u7528\u4f5c\u5728\u7279\u5b9a\u4f7f\u7528\u6848\u4f8b\u4e2d\u8a55\u4f30\u53ef\u89e3\u91cb\u6027\u65b9\u6cd5\u7684\u67b6\u69cb\u3002", "author": "Lenka T\u011btkov\u00e1 et.al.", "authors": "Lenka T\u011btkov\u00e1, Erik Schou Dreier, Robin Malm, Lars Kai Hansen", "id": "2406.09981v1", "paper_url": "http://arxiv.org/abs/2406.09981v1", "repo": "null"}}