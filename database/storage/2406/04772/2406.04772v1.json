{"2406.04772": {"publish_time": "2024-06-07", "title": "REP: Resource-Efficient Prompting for On-device Continual Learning", "paper_summary": "On-device continual learning (CL) requires the co-optimization of model\naccuracy and resource efficiency to be practical. This is extremely challenging\nbecause it must preserve accuracy while learning new tasks with continuously\ndrifting data and maintain both high energy and memory efficiency to be\ndeployable on real-world devices. Typically, a CL method leverages one of two\ntypes of backbone networks: CNN or ViT. It is commonly believed that CNN-based\nCL excels in resource efficiency, whereas ViT-based CL is superior in model\nperformance, making each option attractive only for a single aspect. In this\npaper, we revisit this comparison while embracing powerful pre-trained ViT\nmodels of various sizes, including ViT-Ti (5.8M parameters). Our detailed\nanalysis reveals that many practical options exist today for making ViT-based\nmethods more suitable for on-device CL, even when accuracy, energy, and memory\nare all considered. To further expand this impact, we introduce REP, which\nimproves resource efficiency specifically targeting prompt-based rehearsal-free\nmethods. Our key focus is on avoiding catastrophic trade-offs with accuracy\nwhile trimming computational and memory costs throughout the training process.\nWe achieve this by exploiting swift prompt selection that enhances input data\nusing a carefully provisioned model, and by developing two novel\nalgorithms-adaptive token merging (AToM) and adaptive layer dropping (ALD)-that\noptimize the prompt updating stage. In particular, AToM and ALD perform\nselective skipping across the data and model-layer dimensions without\ncompromising task-specific features in vision transformer models. Extensive\nexperiments on three image classification datasets validate REP's superior\nresource efficiency over current state-of-the-art methods.", "paper_summary_zh": "<paragraph>\u88dd\u7f6e\u5167\u9023\u7e8c\u5b78\u7fd2 (CL) \u9700\u8981\u6a21\u578b\u7cbe\u78ba\u5ea6\u8207\u8cc7\u6e90\u6548\u7387\u7684\u5171\u540c\u6700\u4f73\u5316\uff0c\u624d\u80fd\u5be6\u7528\u3002\u9019\u6975\u5177\u6311\u6230\u6027\uff0c\u56e0\u70ba\u5b83\u5fc5\u9808\u5728\u5b78\u7fd2\u65b0\u4efb\u52d9\u7684\u540c\u6642\uff0c\u4fdd\u6301\u6e96\u78ba\u6027\uff0c\u4e26\u6301\u7e8c\u8abf\u6574\u8cc7\u6599\uff0c\u540c\u6642\u7dad\u6301\u9ad8\u80fd\u6e90\u548c\u8a18\u61b6\u9ad4\u6548\u7387\uff0c\u624d\u80fd\u90e8\u7f72\u5728\u771f\u5be6\u4e16\u754c\u7684\u88dd\u7f6e\u4e0a\u3002\u901a\u5e38\uff0cCL \u65b9\u6cd5\u6703\u5229\u7528\u5169\u7a2e\u4e3b\u5e79\u7db2\u8def\u4e4b\u4e00\uff1aCNN \u6216 ViT\u3002\u4e00\u822c\u8a8d\u70ba\uff0c\u57fa\u65bc CNN \u7684 CL \u5728\u8cc7\u6e90\u6548\u7387\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u800c\u57fa\u65bc ViT \u7684 CL \u5728\u6a21\u578b\u6548\u80fd\u65b9\u9762\u5247\u66f4\u52dd\u4e00\u7c4c\uff0c\u9019\u4f7f\u5f97\u6bcf\u500b\u9078\u9805\u53ea\u5c0d\u55ae\u4e00\u5c64\u9762\u5177\u6709\u5438\u5f15\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u91cd\u65b0\u63a2\u8a0e\u9019\u500b\u6bd4\u8f03\uff0c\u540c\u6642\u63a1\u7528\u5404\u7a2e\u5c3a\u5bf8\u7684\u5f37\u5927\u9810\u5148\u8a13\u7df4\u7684 ViT \u6a21\u578b\uff0c\u5305\u62ec ViT-Ti\uff085.8M \u53c3\u6578\uff09\u3002\u6211\u5011\u7684\u8a73\u7d30\u5206\u6790\u986f\u793a\uff0c\u76ee\u524d\u6709\u8a31\u591a\u5be6\u7528\u7684\u9078\u9805\u53ef\u4ee5\u8b93\u57fa\u65bc ViT \u7684\u65b9\u6cd5\u66f4\u9069\u5408\u88dd\u7f6e\u5167 CL\uff0c\u5373\u4f7f\u5728\u8003\u616e\u7cbe\u78ba\u5ea6\u3001\u80fd\u6e90\u548c\u8a18\u61b6\u9ad4\u7684\u60c5\u6cc1\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u64f4\u5927\u9019\u500b\u5f71\u97ff\uff0c\u6211\u5011\u5f15\u5165\u4e86 REP\uff0c\u5b83\u7279\u5225\u91dd\u5c0d\u57fa\u65bc\u63d0\u793a\u7684\u7121\u5f69\u6392\u65b9\u6cd5\u6539\u9032\u8cc7\u6e90\u6548\u7387\u3002\u6211\u5011\u7684\u91cd\u9ede\u5728\u65bc\u907f\u514d\u5728\u6574\u500b\u8a13\u7df4\u904e\u7a0b\u4e2d\u6e1b\u5c11\u904b\u7b97\u548c\u8a18\u61b6\u9ad4\u6210\u672c\u6642\uff0c\u51fa\u73fe\u7cbe\u78ba\u5ea6\u7684\u707d\u96e3\u6027\u6b0a\u8861\u3002\u6211\u5011\u900f\u904e\u5229\u7528\u589e\u5f37\u8f38\u5165\u8cc7\u6599\u7684\u5feb\u901f\u63d0\u793a\u9078\u53d6\uff0c\u4e26\u900f\u904e\u958b\u767c\u5169\u7a2e\u65b0\u7684\u6f14\u7b97\u6cd5\u2014\u2014\u81ea\u9069\u61c9\u4ee3\u865f\u5408\u4f75 (AToM) \u548c\u81ea\u9069\u61c9\u5c64\u6368\u68c4 (ALD)\u2014\u2014\u4f86\u9054\u6210\u6b64\u76ee\u6a19\uff0c\u9019\u4e9b\u6f14\u7b97\u6cd5\u6700\u4f73\u5316\u4e86\u63d0\u793a\u66f4\u65b0\u968e\u6bb5\u3002\u7279\u5225\u662f\uff0cAToM \u548c ALD \u5728\u8cc7\u6599\u548c\u6a21\u578b\u5c64\u7dad\u5ea6\u4e0a\u57f7\u884c\u9078\u64c7\u6027\u8df3\u8e8d\uff0c\u800c\u4e0d\u6703\u640d\u5bb3\u8996\u89ba\u8f49\u63db\u5668\u6a21\u578b\u4e2d\u7684\u7279\u5b9a\u4efb\u52d9\u529f\u80fd\u3002\u5728\u4e09\u500b\u5f71\u50cf\u5206\u985e\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u9a57\u8b49\u4e86 REP \u512a\u65bc\u76ee\u524d\u6700\u5148\u9032\u65b9\u6cd5\u7684\u8cc7\u6e90\u6548\u7387\u3002</paragraph>", "author": "Sungho Jeon et.al.", "authors": "Sungho Jeon, Xinyue Ma, Kwang In Kim, Myeongjae Jeon", "id": "2406.04772v1", "paper_url": "http://arxiv.org/abs/2406.04772v1", "repo": "null"}}