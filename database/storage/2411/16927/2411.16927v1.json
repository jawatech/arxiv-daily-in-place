{"2411.16927": {"publish_time": "2024-11-25", "title": "ASSERTIFY: Utilizing Large Language Models to Generate Assertions for Production Code", "paper_summary": "Production assertions are statements embedded in the code to help developers\nvalidate their assumptions about the code. They assist developers in debugging,\nprovide valuable documentation, and enhance code comprehension. Current\nresearch in this area primarily focuses on assertion generation for unit tests\nusing techniques, such as static analysis and deep learning. While these\ntechniques have shown promise, they fall short when it comes to generating\nproduction assertions, which serve a different purpose.\n  This preprint addresses the gap by introducing Assertify, an automated\nend-to-end tool that leverages Large Language Models (LLMs) and prompt\nengineering with few-shot learning to generate production assertions. By\ncreating context-rich prompts, the tool emulates the approach developers take\nwhen creating production assertions for their code. To evaluate our approach,\nwe compiled a dataset of 2,810 methods by scraping 22 mature Java repositories\nfrom GitHub. Our experiments demonstrate the effectiveness of few-shot learning\nby producing assertions with an average ROUGE-L score of 0.526, indicating\nreasonably high structural similarity with the assertions written by\ndevelopers. This research demonstrates the potential of LLMs in automating the\ngeneration of production assertions that resemble the original assertions.", "paper_summary_zh": "\u751f\u7522\u65b7\u8a00\u662f\u5d4c\u5165\u5728\u7a0b\u5f0f\u78bc\u4e2d\u7684\u9673\u8ff0\uff0c\u7528\u65bc\u5354\u52a9\u958b\u767c\u4eba\u54e1\u9a57\u8b49\u4ed6\u5011\u5c0d\u7a0b\u5f0f\u78bc\u7684\u5047\u8a2d\u3002\u5b83\u5011\u5354\u52a9\u958b\u767c\u4eba\u54e1\u9032\u884c\u9664\u932f\u3001\u63d0\u4f9b\u6709\u50f9\u503c\u7684\u6587\u4ef6\uff0c\u4e26\u589e\u5f37\u7a0b\u5f0f\u78bc\u7406\u89e3\u3002\u76ee\u524d\u9019\u65b9\u9762\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u65bc\u4f7f\u7528\u975c\u614b\u5206\u6790\u548c\u6df1\u5ea6\u5b78\u7fd2\u7b49\u6280\u8853\u91dd\u5c0d\u55ae\u5143\u6e2c\u8a66\u7522\u751f\u65b7\u8a00\u3002\u96d6\u7136\u9019\u4e9b\u6280\u8853\u5df2\u5c55\u73fe\u51fa\u524d\u666f\uff0c\u4f46\u5728\u7522\u751f\u751f\u7522\u65b7\u8a00\u6642\u537b\u6709\u6240\u4e0d\u8db3\uff0c\u56e0\u70ba\u751f\u7522\u65b7\u8a00\u670d\u52d9\u65bc\u4e0d\u540c\u7684\u76ee\u7684\u3002\n  \u672c\u9810\u5370\u672c\u900f\u904e\u5f15\u5165 Assertify \u4f86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0cAssertify \u662f\u4e00\u500b\u81ea\u52d5\u5316\u7aef\u5230\u7aef\u5de5\u5177\uff0c\u5b83\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u4e26\u900f\u904e\u5c11\u91cf\u5b78\u7fd2\u4f86\u7522\u751f\u751f\u7522\u65b7\u8a00\u3002\u900f\u904e\u5efa\u7acb\u8c50\u5bcc\u7684\u63d0\u793a\uff0c\u6b64\u5de5\u5177\u6a21\u64ec\u958b\u767c\u4eba\u54e1\u5728\u70ba\u5176\u7a0b\u5f0f\u78bc\u5efa\u7acb\u751f\u7522\u65b7\u8a00\u6642\u63a1\u53d6\u7684\u65b9\u6cd5\u3002\u70ba\u4e86\u8a55\u4f30\u6211\u5011\u7684\u505a\u6cd5\uff0c\u6211\u5011\u900f\u904e\u5f9e GitHub \u4e2d\u64f7\u53d6 22 \u500b\u6210\u719f\u7684 Java \u5132\u5b58\u5eab\uff0c\u7de8\u8b6f\u4e86\u4e00\u500b\u5305\u542b 2,810 \u500b\u65b9\u6cd5\u7684\u8cc7\u6599\u96c6\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\u4e86\u5c11\u91cf\u5b78\u7fd2\u7684\u6709\u6548\u6027\uff0c\u5b83\u7522\u751f\u65b7\u8a00\u7684\u5e73\u5747 ROUGE-L \u5206\u6578\u70ba 0.526\uff0c\u8868\u793a\u8207\u958b\u767c\u4eba\u54e1\u7de8\u5beb\u7684\u65b7\u8a00\u5177\u6709\u76f8\u7576\u9ad8\u7684\u7d50\u69cb\u76f8\u4f3c\u6027\u3002\u9019\u9805\u7814\u7a76\u5c55\u793a\u4e86 LLM \u5728\u81ea\u52d5\u5316\u7522\u751f\u985e\u4f3c\u539f\u59cb\u65b7\u8a00\u7684\u751f\u7522\u65b7\u8a00\u65b9\u9762\u7684\u6f5b\u529b\u3002", "author": "Mohammad Jalili Torkamani et.al.", "authors": "Mohammad Jalili Torkamani, Abhinav Sharma, Nikita Mehrotra, Rahul Purandare", "id": "2411.16927v1", "paper_url": "http://arxiv.org/abs/2411.16927v1", "repo": "null"}}