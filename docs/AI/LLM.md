
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-18**|**Learning from Massive Human Videos for Universal Humanoid Pose Control**|Jiageng Mao et.al.|[2412.14172v1](http://arxiv.org/abs/2412.14172v1)|null|
|**2024-12-18**|**E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling**|Zhihang Yuan et.al.|[2412.14170v1](http://arxiv.org/abs/2412.14170v1)|null|
|**2024-12-18**|**VideoDPO: Omni-Preference Alignment for Video Diffusion Generation**|Runtao Liu et.al.|[2412.14167v1](http://arxiv.org/abs/2412.14167v1)|null|
|**2024-12-18**|**TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks**|Frank F. Xu et.al.|[2412.14161v1](http://arxiv.org/abs/2412.14161v1)|[link](https://github.com/theagentcompany/experiments)|
|**2024-12-18**|**AKiRa: Augmentation Kit on Rays for optical video generation**|Xi Wang et.al.|[2412.14158v1](http://arxiv.org/abs/2412.14158v1)|null|
|**2024-12-18**|**Advanced Reasoning and Transformation Engine for Multi-Step Insight Synthesis in Data Analytics with Large Language Models**|Atin Sakkeer Hussain et.al.|[2412.14146v1](http://arxiv.org/abs/2412.14146v1)|null|
|**2024-12-18**|**LLMs can realize combinatorial creativity: generating creative ideas via LLMs for scientific research**|Tianyang Gu et.al.|[2412.14141v1](http://arxiv.org/abs/2412.14141v1)|null|
|**2024-12-18**|**GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking**|Darshan Deshpande et.al.|[2412.14140v1](http://arxiv.org/abs/2412.14140v1)|null|
|**2024-12-18**|**Design choices made by LLM-based test generators prevent them from finding bugs**|Noble Saji Mathews et.al.|[2412.14137v1](http://arxiv.org/abs/2412.14137v1)|null|
|**2024-12-18**|**Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective**|Zhiyuan Zeng et.al.|[2412.14135v1](http://arxiv.org/abs/2412.14135v1)|null|
|**2024-12-18**|**Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models**|Ido Cohen et.al.|[2412.14133v1](http://arxiv.org/abs/2412.14133v1)|[link](https://github.com/ido-co/vlm-modality-gap)|
|**2024-12-18**|**Adaptive Concept Bottleneck for Foundation Models Under Distribution Shifts**|Jihye Choi et.al.|[2412.14097v1](http://arxiv.org/abs/2412.14097v1)|null|
|**2024-12-18**|**Alignment faking in large language models**|Ryan Greenblatt et.al.|[2412.14093v1](http://arxiv.org/abs/2412.14093v1)|[link](https://github.com/redwoodresearch/alignment_faking_public)|
|**2024-12-18**|**SEKE: Specialised Experts for Keyword Extraction**|Matej Martinc et.al.|[2412.14087v1](http://arxiv.org/abs/2412.14087v1)|[link](https://github.com/matejmartinc/seke_keyword_extraction)|
|**2024-12-18**|**Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report**|Markus Dablander et.al.|[2412.14085v1](http://arxiv.org/abs/2412.14085v1)|null|
|**2024-12-18**|**Compositional Generalization Across Distributional Shifts with Sparse Tree Operations**|Paul Soulos et.al.|[2412.14076v1](http://arxiv.org/abs/2412.14076v1)|null|
|**2024-12-18**|**A Computationally Grounded Framework for Cognitive Attitudes (extended version)**|Tiago de Lima et.al.|[2412.14073v1](http://arxiv.org/abs/2412.14073v1)|null|
|**2024-12-18**|**Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification**|Kyle Thompson et.al.|[2412.14063v1](http://arxiv.org/abs/2412.14063v1)|null|
|**2024-12-18**|**A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future**|Shilin Sun et.al.|[2412.14056v1](http://arxiv.org/abs/2412.14056v1)|[link](https://github.com/shilinsun/mxai_review)|
|**2024-12-18**|**Digestion Algorithm in Hierarchical Symbolic Forests: A Fast Text Normalization Algorithm and Semantic Parsing Framework for Specific Scenarios and Lightweight Deployment**|Kevin You et.al.|[2412.14054v1](http://arxiv.org/abs/2412.14054v1)|null|
|**2024-12-18**|**Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation**|Vera Neplenbroek et.al.|[2412.14050v1](http://arxiv.org/abs/2412.14050v1)|[link](https://github.com/veranep/crosslingualdetoxdebias)|
|**2024-12-18**|**Hansel: Output Length Controlling Framework for Large Language Models**|Seoha Song et.al.|[2412.14033v1](http://arxiv.org/abs/2412.14033v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**|Tong Chen et.al.|[2412.14018v1](http://arxiv.org/abs/2412.14018v1)|null|
|**2024-12-18**|**Towards an optimised evaluation of teachers' discourse: The case of engaging messages**|Samuel Falcon et.al.|[2412.14011v1](http://arxiv.org/abs/2412.14011v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-12-18**|**FarExStance: Explainable Stance Detection for Farsi**|Majid Zarharan et.al.|[2412.14008v1](http://arxiv.org/abs/2412.14008v1)|[link](https://github.com/dadmatech/farexstance)|
|**2024-12-18**|**Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with Neural Processes**|Katarzyna Kobalczyk et.al.|[2412.13998v1](http://arxiv.org/abs/2412.13998v1)|[link](https://github.com/kasia-kobalczyk/few-shot-steerable-alignment)|
|**2024-12-18**|**What makes a good metric? Evaluating automatic metrics for text-to-image consistency**|Candace Ross et.al.|[2412.13989v1](http://arxiv.org/abs/2412.13989v1)|null|
|**2024-12-18**|**DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**|Stefano M. Nicoletti et.al.|[2412.13964v1](http://arxiv.org/abs/2412.13964v1)|null|
|**2024-12-18**|**Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation**|Eleni Sgouritsa et.al.|[2412.13952v1](http://arxiv.org/abs/2412.13952v1)|null|
|**2024-12-18**|**Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence**|Jinghan He et.al.|[2412.13949v1](http://arxiv.org/abs/2412.13949v1)|null|
|**2024-12-18**|**On Explaining Knowledge Distillation: Measuring and Visualising the Knowledge Transfer Process**|Gereziher Adhane et.al.|[2412.13943v1](http://arxiv.org/abs/2412.13943v1)|null|
|**2024-12-18**|**A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI**|Beiduo Chen et.al.|[2412.13942v1](http://arxiv.org/abs/2412.13942v1)|null|
|**2024-12-18**|**Spatio-Temporal Forecasting of PM2.5 via Spatial-Diffusion guided Encoder-Decoder Architecture**|Malay Pandey et.al.|[2412.13935v1](http://arxiv.org/abs/2412.13935v1)|[link](https://github.com/malayp717/pm2.5)|
|**2024-12-18**|**Language verY Rare for All**|Ibrahim Merad et.al.|[2412.13924v1](http://arxiv.org/abs/2412.13924v1)|null|
|**2024-12-18**|**Pipeline Analysis for Developing Instruct LLMs in Low-Resource Languages: A Case Study on Basque**|Ander Corral et.al.|[2412.13922v1](http://arxiv.org/abs/2412.13922v1)|null|
|**2024-12-18**|**Energy-Efficient SLAM via Joint Design of Sensing, Communication, and Exploration Speed**|Zidong Han et.al.|[2412.13912v1](http://arxiv.org/abs/2412.13912v1)|null|
|**2024-12-18**|**Understanding and Analyzing Model Robustness and Knowledge-Transfer in Multilingual Neural Machine Translation using TX-Ray**|Vageesh Saxena et.al.|[2412.13881v1](http://arxiv.org/abs/2412.13881v1)|null|
|**2024-12-18**|**Crabs: Consuming Resrouce via Auto-generation for LLM-DoS Attack under Black-box Settings**|Yuanhe Zhang et.al.|[2412.13879v1](http://arxiv.org/abs/2412.13879v1)|[link](https://github.com/shuita2333/autodos)|
|**2024-12-18**|**RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation**|Kun Wu et.al.|[2412.13877v1](http://arxiv.org/abs/2412.13877v1)|null|
|**2024-12-18**|**SHAP scores fail pervasively even when Lipschitz succeeds**|Olivier Letoffe et.al.|[2412.13866v1](http://arxiv.org/abs/2412.13866v1)|null|
|**2024-12-18**|**Energy-Based Preference Model Offers Better Offline Alignment than the Bradley-Terry Preference Model**|Yuzhong Hong et.al.|[2412.13862v1](http://arxiv.org/abs/2412.13862v1)|null|
|**2024-12-18**|**Domain-adaptative Continual Learning for Low-resource Tasks: Evaluation on Nepali**|Sharad Duwal et.al.|[2412.13860v1](http://arxiv.org/abs/2412.13860v1)|null|
|**2024-12-18**|**IDEQ: an improved diffusion model for the TSP**|Mickael Basson et.al.|[2412.13858v1](http://arxiv.org/abs/2412.13858v1)|null|
|**2024-12-18**|**From approximation error to optimality gap -- Explaining the performance impact of opportunity cost approximation in integrated demand management and vehicle routing**|David Fleckenstein et.al.|[2412.13851v1](http://arxiv.org/abs/2412.13851v1)|null|
|**2024-12-18**|**A Concept-Centric Approach to Multi-Modality Learning**|Yuchong Geng et.al.|[2412.13847v1](http://arxiv.org/abs/2412.13847v1)|null|
|**2024-12-18**|**From Expectation to Habit: Why Do Software Practitioners Adopt Fairness Toolkits?**|Gianmario Voria et.al.|[2412.13846v1](http://arxiv.org/abs/2412.13846v1)|null|
|**2024-12-18**|**Do Language Models Understand Time?**|Xi Ding et.al.|[2412.13845v1](http://arxiv.org/abs/2412.13845v1)|null|
|**2024-12-18**|**CRM: Retrieval Model with Controllable Condition**|Chi Liu et.al.|[2412.13844v1](http://arxiv.org/abs/2412.13844v1)|null|
|**2024-12-18**|**AI Perceptions Across Cultures: Similarities and Differences in Expectations, Risks, Benefits, Tradeoffs, and Value in Germany and China**|Philipp Brauner et.al.|[2412.13841v1](http://arxiv.org/abs/2412.13841v1)|null|
|**2024-12-18**|**RACQUET: Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs**|Alberto Testoni et.al.|[2412.13835v1](http://arxiv.org/abs/2412.13835v1)|null|
|**2024-12-18**|**Maybe you are looking for CroQS: Cross-modal Query Suggestion for Text-to-Image Retrieval**|Giacomo Pacini et.al.|[2412.13834v1](http://arxiv.org/abs/2412.13834v1)|null|
|**2024-12-18**|**Heterogeneous Graph Collaborative Filtering**|Lianghao Xia et.al.|[2412.13825v1](http://arxiv.org/abs/2412.13825v1)|[link](https://github.com/hkuds/mixrec)|
|**2024-12-18**|**CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers?**|Dimitrios Mallis et.al.|[2412.13810v1](http://arxiv.org/abs/2412.13810v1)|null|
|**2024-12-18**|**M$^3$-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation**|Zixuan Chen et.al.|[2412.13803v1](http://arxiv.org/abs/2412.13803v1)|null|
|**2024-12-18**|**Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application with RAG Integration**|Ramona Kühn et.al.|[2412.13799v1](http://arxiv.org/abs/2412.13799v1)|null|
|**2024-12-18**|**Mix-LN: Unleashing the Power of Deeper Layers by Combining Pre-LN and Post-LN**|Pengxiang Li et.al.|[2412.13795v1](http://arxiv.org/abs/2412.13795v1)|[link](https://github.com/pixeli99/mixln)|
|**2024-12-18**|**MATCHED: Multimodal Authorship-Attribution To Combat Human Trafficking in Escort-Advertisement Data**|Vageesh Saxena et.al.|[2412.13794v1](http://arxiv.org/abs/2412.13794v1)|[link](https://github.com/vageeshsaxena/matched)|
|**2024-12-18**|**Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics Problems with Large Language Models**|Xinyu Pang et.al.|[2412.13791v1](http://arxiv.org/abs/2412.13791v1)|[link](https://github.com/xinyu-pang/physics_reasoner)|
|**2024-12-18**|**Open Universal Arabic ASR Leaderboard**|Yingzhi Wang et.al.|[2412.13788v1](http://arxiv.org/abs/2412.13788v1)|null|
|**2024-12-18**|**Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question Answering**|Yifan Lu et.al.|[2412.13782v1](http://arxiv.org/abs/2412.13782v1)|null|
|**2024-12-18**|**Meta-Reflection: A Feedback-Free Reflection Learning Framework**|Yaoke Wang et.al.|[2412.13781v1](http://arxiv.org/abs/2412.13781v1)|null|
|**2024-12-18**|**Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization**|Guanghan Li et.al.|[2412.13771v1](http://arxiv.org/abs/2412.13771v1)|null|
|**2024-12-18**|**QuLTSF: Long-Term Time Series Forecasting with Quantum Machine Learning**|Hari Hara Suthan Chittoor et.al.|[2412.13769v1](http://arxiv.org/abs/2412.13769v1)|[link](https://github.com/chariharasuthan/qultsf)|
|**2024-12-18**|**LLM-SEM: A Sentiment-Based Student Engagement Metric Using LLMS for E-Learning Platforms**|Ali Hamdi et.al.|[2412.13765v1](http://arxiv.org/abs/2412.13765v1)|null|
|**2024-12-18**|**RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment**|Zhuoran Jin et.al.|[2412.13746v1](http://arxiv.org/abs/2412.13746v1)|[link](https://github.com/jinzhuoran/rag-rewardbench)|
|**2024-12-18**|**Learning Complex Word Embeddings in Classical and Quantum Spaces**|Carys Harvey et.al.|[2412.13745v1](http://arxiv.org/abs/2412.13745v1)|null|
|**2024-12-18**|**Uncertainty separation via ensemble quantile regression**|Navid Ansari et.al.|[2412.13738v1](http://arxiv.org/abs/2412.13738v1)|null|
|**2024-12-18**|**On the Compression of Language Models for Code: An Empirical Study on CodeBERT**|Giordano d'Aloisio et.al.|[2412.13737v1](http://arxiv.org/abs/2412.13737v1)|null|
|**2024-12-18**|**Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**|Jincheol Jung et.al.|[2412.13720v1](http://arxiv.org/abs/2412.13720v1)|null|
|**2024-12-18**|**An Algebraic Notion of Conditional Independence, and Its Application to Knowledge Representation (full version)**|Jesse Heyninck et.al.|[2412.13712v1](http://arxiv.org/abs/2412.13712v1)|null|
|**2024-12-18**|**Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation**|Minkyoung Kim et.al.|[2412.13705v1](http://arxiv.org/abs/2412.13705v1)|null|
|**2024-12-18**|**Typhoon 2: A Family of Open Text and Multimodal Thai Large Language Models**|Kunat Pipatanakul et.al.|[2412.13702v1](http://arxiv.org/abs/2412.13702v1)|null|
|**2024-12-18**|**Towards Efficient and Explainable Hate Speech Detection via Model Distillation**|Paloma Piot et.al.|[2412.13698v1](http://arxiv.org/abs/2412.13698v1)|[link](https://github.com/palomapiot/distil-metahate)|
|**2024-12-18**|**Discerning and Characterising Types of Competency Questions for Ontologies**|C. Maria Keet et.al.|[2412.13688v1](http://arxiv.org/abs/2412.13688v1)|null|
|**2024-12-18**|**ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning**|Jie-Jing Shao et.al.|[2412.13682v1](http://arxiv.org/abs/2412.13682v1)|null|
|**2024-12-18**|**Clio: Privacy-Preserving Insights into Real-World AI Use**|Alex Tamkin et.al.|[2412.13678v1](http://arxiv.org/abs/2412.13678v1)|null|
|**2024-12-18**|**AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge**|Xiaobao Wu et.al.|[2412.13670v1](http://arxiv.org/abs/2412.13670v1)|null|
|**2024-12-18**|**Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**|ChengAo Shen et.al.|[2412.13667v1](http://arxiv.org/abs/2412.13667v1)|null|
|**2024-12-18**|**Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation**|Aneta Zugecova et.al.|[2412.13666v1](http://arxiv.org/abs/2412.13666v1)|null|
|**2024-12-18**|**Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference**|Benjamin Warner et.al.|[2412.13663v1](http://arxiv.org/abs/2412.13663v1)|null|
|**2024-12-18**|**PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling**|Haojie Xie et.al.|[2412.13660v1](http://arxiv.org/abs/2412.13660v1)|[link](https://github.com/scutcyr/soulchat2.0)|
|**2024-12-18**|**SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation**|Jialong Wu et.al.|[2412.13649v1](http://arxiv.org/abs/2412.13649v1)|null|
|**2024-12-18**|**G-VEval: A Versatile Metric for Evaluating Image and Video Captions Using GPT-4o**|Tony Cheng Tong et.al.|[2412.13647v1](http://arxiv.org/abs/2412.13647v1)|[link](https://github.com/ztangaj/gveval)|
|**2024-12-18**|**On the Role of Model Prior in Real-World Inductive Reasoning**|Zhuo Liu et.al.|[2412.13645v1](http://arxiv.org/abs/2412.13645v1)|null|
|**2024-12-18**|**Consistency of Compositional Generalization across Multiple Levels**|Chuanhao Li et.al.|[2412.13636v1](http://arxiv.org/abs/2412.13636v1)|[link](https://github.com/nevermorelch/ccg)|
|**2024-12-18**|**Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning**|Eitan Wagner et.al.|[2412.13631v1](http://arxiv.org/abs/2412.13631v1)|null|
|**2024-12-18**|**Policy Decorator: Model-Agnostic Online Refinement for Large Policy Model**|Xiu Yuan et.al.|[2412.13630v1](http://arxiv.org/abs/2412.13630v1)|null|
|**2024-12-18**|**LIFT: Improving Long Context Understanding Through Long Input Fine-Tuning**|Yansheng Mao et.al.|[2412.13626v1](http://arxiv.org/abs/2412.13626v1)|null|
|**2024-12-18**|**Unifying Attribution-Based Explanations Using Functional Decomposition**|Arne Gevaert et.al.|[2412.13623v1](http://arxiv.org/abs/2412.13623v1)|null|
|**2024-12-18**|**NPC: Neural Predictive Control for Fuel-Efficient Autonomous Trucks**|Jiaping Ren et.al.|[2412.13618v1](http://arxiv.org/abs/2412.13618v1)|null|
|**2024-12-18**|**Reverse Region-to-Entity Annotation for Pixel-Level Visual Entity Linking**|Zhengfei Xu et.al.|[2412.13614v1](http://arxiv.org/abs/2412.13614v1)|null|
|**2024-12-18**|**Are LLMs Good Literature Review Writers? Evaluating the Literature Review Writing Ability of Large Language Models**|Xuemei Tang et.al.|[2412.13612v1](http://arxiv.org/abs/2412.13612v1)|null|
|**2024-12-18**|**Beyond Outcomes: Transparent Assessment of LLM Reasoning in Games**|Wenye Lin et.al.|[2412.13602v1](http://arxiv.org/abs/2412.13602v1)|null|
|**2024-12-18**|**Hybrid CNN-LSTM based Indoor Pedestrian Localization with CSI Fingerprint Maps**|Muhammad Emad-ud-din et.al.|[2412.13601v1](http://arxiv.org/abs/2412.13601v1)|[link](https://github.com/em22ad/CSI-Fingerprint-Indoor-Localization)|
|**2024-12-18**|**Unlocking the Potential of Weakly Labeled Data: A Co-Evolutionary Learning Framework for Abnormality Detection and Report Generation**|Jinghan Sun et.al.|[2412.13599v1](http://arxiv.org/abs/2412.13599v1)|null|
|**2024-12-18**|**Generalizable Sensor-Based Activity Recognition via Categorical Concept Invariant Learning**|Di Xiong et.al.|[2412.13594v1](http://arxiv.org/abs/2412.13594v1)|null|
|**2024-12-18**|**SemiDFL: A Semi-Supervised Paradigm for Decentralized Federated Learning**|Xinyang Liu et.al.|[2412.13589v1](http://arxiv.org/abs/2412.13589v1)|[link](https://github.com/ez4lionky/SemiDFL)|
|**2024-12-18**|**EvoWiki: Evaluating LLMs on Evolving Knowledge**|Wei Tang et.al.|[2412.13582v1](http://arxiv.org/abs/2412.13582v1)|null|

#### Abstracts
##### **Learning from Massive Human Videos for Universal Humanoid Pose Control**
2412.14172v1 by Jiageng Mao, Siheng Zhao, Siqi Song, Tianheng Shi, Junjie Ye, Mingtong Zhang, Haoran Geng, Jitendra Malik, Vitor Guizilini, Yue Wang

Scalable learning of humanoid robots is crucial for their deployment in
real-world applications. While traditional approaches primarily rely on
reinforcement learning or teleoperation to achieve whole-body control, they are
often limited by the diversity of simulated environments and the high costs of
demonstration collection. In contrast, human videos are ubiquitous and present
an untapped source of semantic and motion information that could significantly
enhance the generalization capabilities of humanoid robots. This paper
introduces Humanoid-X, a large-scale dataset of over 20 million humanoid robot
poses with corresponding text-based motion descriptions, designed to leverage
this abundant data. Humanoid-X is curated through a comprehensive pipeline:
data mining from the Internet, video caption generation, motion retargeting of
humans to humanoid robots, and policy learning for real-world deployment. With
Humanoid-X, we further train a large humanoid model, UH-1, which takes text
instructions as input and outputs corresponding actions to control a humanoid
robot. Extensive simulated and real-world experiments validate that our
scalable training approach leads to superior generalization in text-based
humanoid control, marking a significant step toward adaptable, real-world-ready
humanoid robots.

摘要：類人機器人的可擴充學習對於它們在真實世界應用中至關重要。雖然傳統方法主要依賴強化學習或遠程操作來實現全身控制，但它們往往受到模擬環境多樣性和示範收集成本高的限制。相比之下，人類影片無處不在，並提供語義和動作資訊的未開發來源，這可以顯著增強類人機器人的泛化能力。本文介紹 Humanoid-X，一個包含超過 2000 萬個類人機器人姿勢的大型資料集，並附有對應的文字動作描述，旨在利用這些豐富的資料。Humanoid-X 是透過一個全面的管道策展：從網際網路中挖掘資料、產生影片字幕、將人類動作重新定位到類人機器人，以及針對真實世界部署進行策略學習。有了 Humanoid-X，我們進一步訓練一個大型類人模型 UH-1，它以文字指令作為輸入，並輸出對應的動作來控制類人機器人。廣泛的模擬和真實世界實驗驗證了我們可擴充的訓練方法會帶來文字類人控制的優異泛化，這標誌著邁向適應性、真實世界就緒的類人機器人邁出了重要一步。

##### **E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling**
2412.14170v1 by Zhihang Yuan, Yuzhang Shang, Hanling Zhang, Tongcheng Fang, Rui Xie, Bingxin Xu, Yan Yan, Shengen Yan, Guohao Dai, Yu Wang

Recent advances in autoregressive (AR) models with continuous tokens for
image generation show promising results by eliminating the need for discrete
tokenization. However, these models face efficiency challenges due to their
sequential token generation nature and reliance on computationally intensive
diffusion-based sampling. We present ECAR (Efficient Continuous Auto-Regressive
Image Generation via Multistage Modeling), an approach that addresses these
limitations through two intertwined innovations: (1) a stage-wise continuous
token generation strategy that reduces computational complexity and provides
progressively refined token maps as hierarchical conditions, and (2) a
multistage flow-based distribution modeling method that transforms only
partial-denoised distributions at each stage comparing to complete denoising in
normal diffusion models. Holistically, ECAR operates by generating tokens at
increasing resolutions while simultaneously denoising the image at each stage.
This design not only reduces token-to-image transformation cost by a factor of
the stage number but also enables parallel processing at the token level. Our
approach not only enhances computational efficiency but also aligns naturally
with image generation principles by operating in continuous token space and
following a hierarchical generation process from coarse to fine details.
Experimental results demonstrate that ECAR achieves comparable image quality to
DiT Peebles & Xie [2023] while requiring 10$\times$ FLOPs reduction and
5$\times$ speedup to generate a 256$\times$256 image.

摘要：<paragraph>最近在具有連續圖像生成代幣的自迴歸 (AR) 模型中取得的進展，透過消除離散代幣化的需求，展示了令人振奮的成果。然而，這些模型由於其順序代幣生成特性和依賴於計算密集型擴散式採樣，而面臨效率挑戰。我們提出了 ECAR（透過多階段建模實現高效連續自迴歸圖像生成），這是一種透過兩項相互交織的創新來解決這些限制的方法：(1) 一種階段性的連續代幣生成策略，可降低運算複雜度，並提供逐漸精煉的代幣映射作為分層條件，以及 (2) 一種多階段基於流的分布建模方法，與在一般擴散模型中進行完整去噪相比，它僅轉換每個階段的部分去噪分布。整體而言，ECAR 的運作方式是在每個階段同時產生不同解析度的代幣，並去噪影像。這種設計不僅將代幣到影像轉換成本降低了階段數倍，還可以在代幣層級進行並行處理。我們的方法不僅增強了運算效率，還透過在連續代幣空間中運作並遵循從粗略到精細細節的分層生成過程，自然地與影像生成原理保持一致。實驗結果表明，ECAR 達到了與 DiT Peebles & Xie [2023] 相當的影像品質，同時將產生 256×256 影像所需的浮點運算次數 (FLOP) 減少了 10 倍，並將速度提升了 5 倍。</paragraph>

##### **VideoDPO: Omni-Preference Alignment for Video Diffusion Generation**
2412.14167v1 by Runtao Liu, Haoyu Wu, Zheng Ziqiang, Chen Wei, Yingqing He, Renjie Pi, Qifeng Chen

Recent progress in generative diffusion models has greatly advanced
text-to-video generation. While text-to-video models trained on large-scale,
diverse datasets can produce varied outputs, these generations often deviate
from user preferences, highlighting the need for preference alignment on
pre-trained models. Although Direct Preference Optimization (DPO) has
demonstrated significant improvements in language and image generation, we
pioneer its adaptation to video diffusion models and propose a VideoDPO
pipeline by making several key adjustments. Unlike previous image alignment
methods that focus solely on either (i) visual quality or (ii) semantic
alignment between text and videos, we comprehensively consider both dimensions
and construct a preference score accordingly, which we term the OmniScore. We
design a pipeline to automatically collect preference pair data based on the
proposed OmniScore and discover that re-weighting these pairs based on the
score significantly impacts overall preference alignment. Our experiments
demonstrate substantial improvements in both visual quality and semantic
alignment, ensuring that no preference aspect is neglected. Code and data will
be shared at https://videodpo.github.io/.

摘要：生成扩散模型的最新进展极大地推进了
文本到视频生成。虽然在大规模训练的文本到视频模型中，
不同的数据集可以产生不同的输出，但这些生成通常偏离
用户偏好，突显了对预训练模型偏好对齐的需求。尽管直接偏好优化 (DPO) 已
在语言和图像生成方面展示出显著的改进，我们
率先将其改编为视频扩散模型，并通过进行一些关键调整提出了 VideoDPO
管道。与先前仅专注于 (i) 视觉质量或 (ii) 文本和视频之间的语义
对齐的图像对齐方法不同，我们全面考虑了这两个维度
并据此构建了一个偏好分数，我们称之为 OmniScore。我们
设计了一个管道，以根据
建议的 OmniScore 自动收集偏好对数据，并发现根据
分数对这些对进行重新加权会显著影响整体偏好对齐。我们的实验
表明在视觉质量和语义
对齐方面都有实质性的改进，确保不忽视任何偏好方面。代码和数据将
在 https://videodpo.github.io/ 上共享。

##### **TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks**
2412.14161v1 by Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi, Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig

We interact with computers on an everyday basis, be it in everyday life or
work, and many aspects of work can be done entirely with access to a computer
and the Internet. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. But how
performant are AI agents at helping to accelerate or even autonomously perform
work-related tasks? The answer to this question has important implications for
both industry looking to adopt AI into their workflows, and for economic policy
to understand the effects that adoption of AI may have on the labor market. To
measure the progress of these LLM agents' performance on performing real-world
professional tasks, in this paper, we introduce TheAgentCompany, an extensible
benchmark for evaluating AI agents that interact with the world in similar ways
to those of a digital worker: by browsing the Web, writing code, running
programs, and communicating with other coworkers. We build a self-contained
environment with internal web sites and data that mimics a small software
company environment, and create a variety of tasks that may be performed by
workers in such a company. We test baseline agents powered by both closed
API-based and open-weights language models (LMs), and find that with the most
competitive agent, 24% of the tasks can be completed autonomously. This paints
a nuanced picture on task automation with LM agents -- in a setting simulating
a real workplace, a good portion of simpler tasks could be solved autonomously,
but more difficult long-horizon tasks are still beyond the reach of current
systems.

摘要：<paragraph>我們每天都會與電腦互動，無論是在日常生活中或工作中，而且許多工作面向都可以透過使用電腦和網路來完成。同時，由於大型語言模型 (LLM) 的進步，與周遭環境互動並影響其變化的 AI 代理也有快速發展。但 AI 代理在協助加速甚至自主執行與工作相關的任務上，表現如何？這個問題的答案對於希望在工作流程中採用 AI 的產業，以及了解 AI 採用可能對勞動市場造成的影響的經濟政策，都有重要的意義。為了衡量這些 LLM 代理在執行真實世界的專業任務上的進度，我們在本文中介紹了 TheAgentCompany，一個可擴展的基準，用於評估以類似於數位工作者的方式與世界互動的 AI 代理：瀏覽網路、撰寫程式碼、執行程式，以及與其他同事溝通。我們建構了一個包含內部網站和資料的自給自足環境，模擬一個小型軟體公司環境，並建立了各種可能由該公司員工執行的任務。我們測試了由封閉式基於 API 的語言模型 (LM) 和開放權重語言模型 (LM) 提供動力的基準代理，並發現使用最具競爭力的代理，24% 的任務可以自主完成。這描繪了一幅關於 LM 代理任務自動化的細緻圖像——在模擬真實工作場所的設定中，相當一部分較簡單的任務可以自主解決，但更困難的長時程任務仍超出目前系統的能力範圍。</paragraph>

##### **AKiRa: Augmentation Kit on Rays for optical video generation**
2412.14158v1 by Xi Wang, Robin Courant, Marc Christie, Vicky Kalogeiton

Recent advances in text-conditioned video diffusion have greatly improved
video quality. However, these methods offer limited or sometimes no control to
users on camera aspects, including dynamic camera motion, zoom, distorted lens
and focus shifts. These motion and optical aspects are crucial for adding
controllability and cinematic elements to generation frameworks, ultimately
resulting in visual content that draws focus, enhances mood, and guides
emotions according to filmmakers' controls. In this paper, we aim to close the
gap between controllable video generation and camera optics. To achieve this,
we propose AKiRa (Augmentation Kit on Rays), a novel augmentation framework
that builds and trains a camera adapter with a complex camera model over an
existing video generation backbone. It enables fine-tuned control over camera
motion as well as complex optical parameters (focal length, distortion,
aperture) to achieve cinematic effects such as zoom, fisheye effect, and bokeh.
Extensive experiments demonstrate AKiRa's effectiveness in combining and
composing camera optics while outperforming all state-of-the-art methods. This
work sets a new landmark in controlled and optically enhanced video generation,
paving the way for future optical video generation methods.

摘要：最近在文字条件视频扩散方面取得的进展极大地改善了视频质量。然而，这些方法对用户在摄像机方面（包括动态摄像机运动、缩放、失真的镜头和焦点转换）的控制有限，有时甚至没有控制。这些运动和光学方面对于为生成框架添加可控性和电影元素至关重要，最终会产生吸引注意力、增强情绪并根据电影制作人的控制引导情绪的视觉内容。在本文中，我们旨在缩小可控视频生成和摄像机光学之间的差距。为了实现这一点，我们提出了 AKiRa（射线上的增强工具包），这是一种新颖的增强框架，它在现有的视频生成主干上构建并训练具有复杂摄像机模型的摄像机适配器。它可以对摄像机运动以及复杂的光学参数（焦距、失真、光圈）进行微调控制，以实现诸如缩放、鱼眼效果和散景等电影效果。大量的实验表明，AKiRa 在组合和合成摄像机光学方面是有效的，同时优于所有最先进的方法。这项工作在受控和光学增强视频生成方面树立了新的里程碑，为未来的光学视频生成方法铺平了道路。

##### **Advanced Reasoning and Transformation Engine for Multi-Step Insight Synthesis in Data Analytics with Large Language Models**
2412.14146v1 by Atin Sakkeer Hussain

This paper presents the Advanced Reasoning and Transformation Engine for
Multi-Step Insight Synthesis in Data Analytics (ARTEMIS-DA), a novel framework
designed to augment Large Language Models (LLMs) for solving complex,
multi-step data analytics tasks. ARTEMIS-DA integrates three core components:
the Planner, which dissects complex user queries into structured, sequential
instructions encompassing data preprocessing, transformation, predictive
modeling, and visualization; the Coder, which dynamically generates and
executes Python code to implement these instructions; and the Grapher, which
interprets generated visualizations to derive actionable insights. By
orchestrating the collaboration between these components, ARTEMIS-DA
effectively manages sophisticated analytical workflows involving advanced
reasoning, multi-step transformations, and synthesis across diverse data
modalities. The framework achieves state-of-the-art (SOTA) performance on
benchmarks such as WikiTableQuestions and TabFact, demonstrating its ability to
tackle intricate analytical tasks with precision and adaptability. By combining
the reasoning capabilities of LLMs with automated code generation and execution
and visual analysis, ARTEMIS-DA offers a robust, scalable solution for
multi-step insight synthesis, addressing a wide range of challenges in data
analytics.

摘要：這篇論文提出了進階推理和轉換引擎，用於資料分析中的多步驟洞察合成（ARTEMIS-DA），這是一個新穎的架構，旨在擴充大型語言模型（LLM），以解決複雜的多步驟資料分析任務。ARTEMIS-DA 整合了三個核心組成部分：規劃器，它將複雜的使用者查詢剖析成結構化的順序指令，包含資料前處理、轉換、預測建模和視覺化；編碼器，它動態產生並執行 Python 程式碼來實作這些指令；以及繪圖器，它解譯產生的視覺化，以推導可行的洞察。透過協調這些組成部分之間的合作，ARTEMIS-DA 有效地管理了複雜的分析工作流程，涉及進階推理、多步驟轉換以及跨不同資料模式的綜合。這個架構在基準測試（例如 WikiTableQuestions 和 TabFact）上達到了最先進（SOTA）的效能，證明了它能夠精準且靈活地處理複雜的分析任務。透過結合 LLM 的推理能力、自動化程式碼產生與執行以及視覺分析，ARTEMIS-DA 提供了一個強健且可擴充的解決方案，用於多步驟洞察合成，解決了資料分析中的廣泛挑戰。

##### **LLMs can realize combinatorial creativity: generating creative ideas via LLMs for scientific research**
2412.14141v1 by Tianyang Gu, Jingjin Wang, Zhihao Zhang, HaoHong Li

Scientific idea generation has been extensively studied in creativity theory
and computational creativity research, providing valuable frameworks for
understanding and implementing creative processes. However, recent work using
Large Language Models (LLMs) for research idea generation often overlooks these
theoretical foundations. We present a framework that explicitly implements
combinatorial creativity theory using LLMs, featuring a generalization-level
retrieval system for cross-domain knowledge discovery and a structured
combinatorial process for idea generation. The retrieval system maps concepts
across different abstraction levels to enable meaningful connections between
disparate domains, while the combinatorial process systematically analyzes and
recombines components to generate novel solutions. Experiments on the OAG-Bench
dataset demonstrate our framework's effectiveness, consistently outperforming
baseline approaches in generating ideas that align with real research
developments (improving similarity scores by 7\%-10\% across multiple metrics).
Our results provide strong evidence that LLMs can effectively realize
combinatorial creativity when guided by appropriate theoretical frameworks,
contributing both to practical advancement of AI-assisted research and
theoretical understanding of machine creativity.

摘要：科學構想產生在創意理論和計算創意研究中已被廣泛研究，為理解和執行創意流程提供了有價值的架構。然而，最近使用大型語言模型 (LLM) 進行研究構想產生的工作經常忽略這些理論基礎。我們提出一個架構，使用 LLM 明確實作組合式創意理論，具備跨領域知識發現的概化層級檢索系統和用於構想產生的結構化組合式流程。檢索系統將不同抽象層級的概念對應起來，以在不同的領域之間建立有意義的連結，而組合式流程系統性地分析和重新組合組成部分，以產生新穎的解決方案。在 OAG-Bench 資料集上的實驗證明了我們架構的有效性，在產生與真實研究發展一致的構想方面，始終優於基準方法（在多項指標中，相似性評分提高了 7%-10%）。我們的結果提供了強有力的證據，證明當由適當的理論框架指導時，LLM 可以有效實現組合式創意，這有助於 AI 輔助研究的實際進展和機器創意的理論理解。

##### **GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking**
2412.14140v1 by Darshan Deshpande, Selvan Sunitha Ravi, Sky CH-Wang, Bartosz Mielczarek, Anand Kannappan, Rebecca Qian

The LLM-as-judge paradigm is increasingly being adopted for automated
evaluation of model outputs. While LLM judges have shown promise on constrained
evaluation tasks, closed source LLMs display critical shortcomings when
deployed in real world applications due to challenges of fine grained metrics
and explainability, while task specific evaluation models lack cross-domain
generalization. We introduce GLIDER, a powerful 3B evaluator LLM that can score
any text input and associated context on arbitrary user defined criteria.
GLIDER shows higher Pearson's correlation than GPT-4o on FLASK and greatly
outperforms prior evaluation models, achieving comparable performance to LLMs
17x its size. GLIDER supports fine-grained scoring, multilingual reasoning,
span highlighting and was trained on 685 domains and 183 criteria. Extensive
qualitative analysis shows that GLIDER scores are highly correlated with human
judgments, with 91.3% human agreement. We have open-sourced GLIDER to
facilitate future research.

摘要：LLM 作為評判的範例正越來越多地被採用於模型輸出的自動評估。儘管 LLM 評判在受限的評估任務中已展現潛力，但封閉原始碼的 LLM 在部署於真實世界的應用程式中時，會因精細粒度的指標和可解釋性的挑戰而顯示出嚴重的缺點，而任務特定的評估模型則缺乏跨領域的概括化。我們介紹 GLIDER，一個強大的 3B 評估器 LLM，它可以根據使用者定義的任意標準對任何文字輸入和相關內容進行評分。GLIDER 在 FLASK 上顯示出比 GPT-4o 更高的皮爾森相關性，並且遠遠優於先前的評估模型，達到了與其大小 17 倍的 LLM 相當的效能。GLIDER 支援精細粒度的評分、多語言推理、範圍標記，並在 685 個網域和 183 個標準上進行訓練。廣泛的定性分析顯示，GLIDER 評分與人類判斷高度相關，人類同意率為 91.3%。我們已開放 GLIDER 的原始碼，以利未來的研究。

##### **Design choices made by LLM-based test generators prevent them from finding bugs**
2412.14137v1 by Noble Saji Mathews, Meiyappan Nagappan

There is an increasing amount of research and commercial tools for automated
test case generation using Large Language Models (LLMs). This paper critically
examines whether recent LLM-based test generation tools, such as Codium
CoverAgent and CoverUp, can effectively find bugs or unintentionally validate
faulty code. Considering bugs are only exposed by failing test cases, we
explore the question: can these tools truly achieve the intended objectives of
software testing when their test oracles are designed to pass? Using real
human-written buggy code as input, we evaluate these tools, showing how
LLM-generated tests can fail to detect bugs and, more alarmingly, how their
design can worsen the situation by validating bugs in the generated test suite
and rejecting bug-revealing tests. These findings raise important questions
about the validity of the design behind LLM-based test generation tools and
their impact on software quality and test suite reliability.

摘要：隨著大型語言模型 (LLM) 的出現，用於自動化測試案例生成的相關研究和商用工具越來越多。本文批判性地探討了基於 LLM 的最新測試生成工具（例如 Codium CoverAgent 和 CoverUp）是否能有效找出錯誤或無意中驗證有缺陷的程式碼。由於錯誤僅會因測試案例失敗而暴露出來，我們探討以下問題：當這些工具的測試預言被設計為通過時，它們是否真能達成軟體測試的預期目標？我們使用真實的人工編寫的錯誤程式碼作為輸入，評估這些工具，說明 LLM 生成的測試如何無法偵測錯誤，更令人擔憂的是，它們的設計如何透過在產生的測試套件中驗證錯誤並拒絕揭露錯誤的測試，使情況惡化。這些發現對基於 LLM 的測試生成工具背後的設計有效性提出了重要的問題，並影響軟體品質和測試套件的可靠性。

##### **Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective**
2412.14135v1 by Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Bo Wang, Shimin Li, Yunhua Zhou, Qipeng Guo, Xuanjing Huang, Xipeng Qiu

OpenAI o1 represents a significant milestone in Artificial Inteiligence,
which achieves expert-level performances on many challanging tasks that require
strong reasoning ability.OpenAI has claimed that the main techinique behinds o1
is the reinforcement learining. Recent works use alternative approaches like
knowledge distillation to imitate o1's reasoning style, but their effectiveness
is limited by the capability ceiling of the teacher model. Therefore, this
paper analyzes the roadmap to achieving o1 from the perspective of
reinforcement learning, focusing on four key components: policy initialization,
reward design, search, and learning. Policy initialization enables models to
develop human-like reasoning behaviors, equipping them with the ability to
effectively explore solution spaces for complex problems. Reward design
provides dense and effective signals via reward shaping or reward modeling,
which is the guidance for both search and learning. Search plays a crucial role
in generating high-quality solutions during both training and testing phases,
which can produce better solutions with more computation. Learning utilizes the
data generated by search for improving policy, which can achieve the better
performance with more parameters and more searched data. Existing open-source
projects that attempt to reproduce o1 can be seem as a part or a variant of our
roadmap. Collectively, these components underscore how learning and search
drive o1's advancement, making meaningful contributions to the development of
LLM.

摘要：OpenAI o1 代表人工智慧的一個重要里程碑，在許多需要強大推理能力的挑戰性任務中，達到了專家級的表現。OpenAI 宣稱 o1 背後的主要技術是強化學習。最近的研究使用知識蒸餾等替代方法來模仿 o1 的推理風格，但其有效性受到教師模型能力上限的限制。因此，本文從強化學習的角度分析了實現 o1 的路線圖，重點關注四個關鍵組成部分：策略初始化、獎勵設計、搜尋和學習。策略初始化使模型能夠發展出類似人類的推理行為，讓它們具備有效探索複雜問題的解決方案空間的能力。獎勵設計透過獎勵塑造或獎勵建模提供密集且有效的訊號，這是搜尋和學習的指導方針。搜尋在訓練和測試階段產生高品質的解決方案中扮演至關重要的角色，它能透過更多運算產生更好的解決方案。學習利用搜尋產生的資料來改善策略，它能透過更多參數和更多搜尋的資料達成更好的表現。現有的嘗試複製 o1 的開源專案可以視為我們路線圖的一部分或一個變體。總的來說，這些組成部分強調了學習和搜尋如何推動 o1 的進步，對 LLM 的發展做出有意義的貢獻。

##### **Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models**
2412.14133v1 by Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes

Vision-language models (VLMs) excel at extracting and reasoning about
information from images. Yet, their capacity to leverage internal knowledge
about specific entities remains underexplored. This work investigates the
disparity in model performance when answering factual questions about an entity
described in text versus depicted in an image. Our results reveal a significant
accuracy drop --averaging 19%-- when the entity is presented visually instead
of textually. We hypothesize that this decline arises from limitations in how
information flows from image tokens to query tokens. We use mechanistic
interpretability tools to reveal that, although image tokens are preprocessed
by the vision encoder, meaningful information flow from these tokens occurs
only in the much deeper layers. Furthermore, critical image processing happens
in the language model's middle layers, allowing few layers for consecutive
reasoning, highlighting a potential inefficiency in how the model utilizes its
layers for reasoning. These insights shed light on the internal mechanics of
VLMs and offer pathways for enhancing their reasoning capabilities.

摘要：視覺語言模型 (VLM) 擅長從影像中萃取和推理資訊。然而，它們利用關於特定實體的內部知識的能力仍未被充分探索。這項工作探討了在回答關於文本中描述或影像中描繪的實體的事實問題時，模型效能的差異。我們的結果顯示，當實體以視覺方式而非文字方式呈現時，準確度會顯著下降——平均下降 19%。我們假設這種下降是由於影像標記如何流向查詢標記的限制。我們使用機制可解釋性工具來揭示，儘管影像標記是由視覺編碼器預先處理的，但從這些標記的有意義的資訊流僅發生在更深的層級中。此外，重要的影像處理發生在語言模型的中間層，允許少數層進行連續推理，突顯了模型如何利用其層進行推理的潛在低效率。這些見解闡明了 VLM 的內部機制，並提供了增強其推理能力的途徑。

##### **Adaptive Concept Bottleneck for Foundation Models Under Distribution Shifts**
2412.14097v1 by Jihye Choi, Jayaram Raghuram, Yixuan Li, Somesh Jha

Advancements in foundation models (FMs) have led to a paradigm shift in
machine learning. The rich, expressive feature representations from these
pre-trained, large-scale FMs are leveraged for multiple downstream tasks,
usually via lightweight fine-tuning of a shallow fully-connected network
following the representation. However, the non-interpretable, black-box nature
of this prediction pipeline can be a challenge, especially in critical domains
such as healthcare, finance, and security. In this paper, we explore the
potential of Concept Bottleneck Models (CBMs) for transforming complex,
non-interpretable foundation models into interpretable decision-making
pipelines using high-level concept vectors. Specifically, we focus on the
test-time deployment of such an interpretable CBM pipeline "in the wild", where
the input distribution often shifts from the original training distribution. We
first identify the potential failure modes of such a pipeline under different
types of distribution shifts. Then we propose an adaptive concept bottleneck
framework to address these failure modes, that dynamically adapts the
concept-vector bank and the prediction layer based solely on unlabeled data
from the target domain, without access to the source (training) dataset.
Empirical evaluations with various real-world distribution shifts show that our
adaptation method produces concept-based interpretations better aligned with
the test data and boosts post-deployment accuracy by up to 28%, aligning the
CBM performance with that of non-interpretable classification.

摘要：基礎模型 (FM) 的進展導致機器學習發生典範轉移。這些預先訓練的大規模 FM 豐富且具表現力的特徵表示被用於多個下游任務，通常透過表示後對淺層全連接網路進行輕量級微調。然而，此預測管線不可解釋的的黑箱性質可能會帶來挑戰，特別是在醫療保健、金融和安全等關鍵領域。在本文中，我們探討了概念瓶頸模型 (CBM) 將複雜且無法解釋的基礎模型轉換為使用高級概念向量的可解釋決策制定管線的潛力。具體來說，我們專注於這種可解釋的 CBM 管線在「野外」的測試時間部署，其中輸入分布通常會從原始訓練分布轉移。我們首先識別此類管線在不同類型的分布轉移下的潛在故障模式。然後，我們提出一個適應性概念瓶頸框架來解決這些故障模式，該框架僅根據目標領域中的未標記數據動態調整概念向量庫和預測層，而無需訪問來源（訓練）資料集。使用各種真實世界分布轉移進行的經驗評估表明，我們的適應方法產生的基於概念的解釋與測試數據更一致，並將部署後準確度提高了 28%，使 CBM 性能與不可解釋分類保持一致。

##### **Alignment faking in large language models**
2412.14093v1 by Ryan Greenblatt, Carson Denison, Benjamin Wright, Fabien Roger, Monte MacDiarmid, Sam Marks, Johannes Treutlein, Tim Belonax, Jack Chen, David Duvenaud, Akbir Khan, Julian Michael, Sören Mindermann, Ethan Perez, Linda Petrini, Jonathan Uesato, Jared Kaplan, Buck Shlegeris, Samuel R. Bowman, Evan Hubinger

We present a demonstration of a large language model engaging in alignment
faking: selectively complying with its training objective in training to
prevent modification of its behavior out of training. First, we give Claude 3
Opus a system prompt stating it is being trained to answer all queries, even
harmful ones, which conflicts with its prior training to refuse such queries.
To allow the model to infer when it is in training, we say it will be trained
only on conversations with free users, not paid users. We find the model
complies with harmful queries from free users 14% of the time, versus almost
never for paid users. Explaining this gap, in almost all cases where the model
complies with a harmful query from a free user, we observe explicit
alignment-faking reasoning, with the model stating it is strategically
answering harmful queries in training to preserve its preferred harmlessness
behavior out of training. Next, we study a more realistic setting where
information about the training process is provided not in a system prompt, but
by training on synthetic documents that mimic pre-training data--and observe
similar alignment faking. Finally, we study the effect of actually training the
model to comply with harmful queries via reinforcement learning, which we find
increases the rate of alignment-faking reasoning to 78%, though also increases
compliance even out of training. We additionally observe other behaviors such
as the model exfiltrating its weights when given an easy opportunity. While we
made alignment faking easier by telling the model when and by what criteria it
was being trained, we did not instruct the model to fake alignment or give it
any explicit goal. As future models might infer information about their
training process without being told, our results suggest a risk of alignment
faking in future models, whether due to a benign preference--as in this
case--or not.

摘要：<paragraph>我們展示了一個大型語言模型參與調整偽造的示範：有選擇地遵守其訓練目標，以防止在訓練中修改其行為。首先，我們給 Claude 3 Opus 一個系統提示，說明它正在接受訓練以回答所有查詢，甚至是有害的查詢，這與它拒絕此類查詢的先前訓練相衝突。為讓模型推斷它何時處於訓練中，我們說它將只接受與免費用戶（而非付費用戶）對話的訓練。我們發現該模型 14% 的時間遵守免費用戶的有害查詢，而付費用戶幾乎從不遵守。在幾乎所有模型遵守免費用戶的有害查詢的情況下，我們觀察到明確的調整偽造推理，解釋了這個差距，模型聲稱它在訓練中策略性地回答有害查詢，以在訓練之外保持其首選的無害行為。接下來，我們研究了一個更實際的設定，其中有關訓練過程的信息不是在系統提示中提供的，而是通過訓練模擬預訓練數據的合成文件來提供的——並觀察到類似的調整偽造。最後，我們研究了實際訓練模型以通過強化學習來遵守有害查詢的影響，我們發現這將調整偽造推理的比率提高到 78%，儘管在訓練之外也會增加遵守率。我們還觀察到其他行為，例如模型在有容易機會時滲透其權重。雖然我們通過告訴模型何時以及根據什麼標準進行訓練來簡化調整偽造，但我們沒有指示模型偽造調整或給予它任何明確的目標。由於未來的模型可能會在沒有被告知的情況下推斷出有關其訓練過程的信息，我們的結果表明未來模型存在調整偽造的風險，無論是出於良性的偏好（如在這種情況下）還是出於其他原因。</paragraph>

##### **SEKE: Specialised Experts for Keyword Extraction**
2412.14087v1 by Matej Martinc, Hanh Thi Hong Tran, Senja Pollak, Boshko Koloski

Keyword extraction involves identifying the most descriptive words in a
document, allowing automatic categorisation and summarisation of large
quantities of diverse textual data. Relying on the insight that real-world
keyword detection often requires handling of diverse content, we propose a
novel supervised keyword extraction approach based on the mixture of experts
(MoE) technique. MoE uses a learnable routing sub-network to direct information
to specialised experts, allowing them to specialize in distinct regions of the
input space. SEKE, a mixture of Specialised Experts for supervised Keyword
Extraction, uses DeBERTa as the backbone model and builds on the MoE framework,
where experts attend to each token, by integrating it with a recurrent neural
network (RNN), to allow successful extraction even on smaller corpora, where
specialisation is harder due to lack of training data. The MoE framework also
provides an insight into inner workings of individual experts, enhancing the
explainability of the approach. We benchmark SEKE on multiple English datasets,
achieving state-of-the-art performance compared to strong supervised and
unsupervised baselines. Our analysis reveals that depending on data size and
type, experts specialize in distinct syntactic and semantic components, such as
punctuation, stopwords, parts-of-speech, or named entities. Code is available
at: https://github.com/matejMartinc/SEKE_keyword_extraction

摘要：關鍵字萃取涉及識別文件中描述性最強的字詞，讓大量多樣化的文字資料能自動分類和摘要。基於現實世界的關鍵字偵測通常需要處理多樣化內容的見解，我們提出一個基於專家混合 (MoE) 技術的新穎監督式關鍵字萃取方法。MoE 使用可學習的路由子網路將資訊導向專業的專家，讓他們專精於輸入空間的不同區域。SEKE 是一種用於監督式關鍵字萃取的專業專家混合，使用 DeBERTa 作為主幹模型並建構在 MoE 框架上，其中專家會關注每個標記，並透過將其與遞迴神經網路 (RNN) 整合，即使在較小的語料庫中也能成功萃取，因為缺乏訓練資料會讓專精變得更困難。MoE 框架也能深入了解個別專家的內部運作，增強方法的可解釋性。我們在多個英文資料集上對 SEKE 進行基準測試，與強大的監督式和非監督式基準相比，達到了最先進的效能。我們的分析顯示，根據資料大小和類型，專家會專精於不同的句法和語義元件，例如標點符號、停止詞、詞性或命名實體。程式碼可在以下網址取得：https://github.com/matejMartinc/SEKE_keyword_extraction

##### **Future Research Avenues for Artificial Intelligence in Digital Gaming: An Exploratory Report**
2412.14085v1 by Markus Dablander

Video games are a natural and synergistic application domain for artificial
intelligence (AI) systems, offering both the potential to enhance player
experience and immersion, as well as providing valuable benchmarks and virtual
environments to advance AI technologies in general. This report presents a
high-level overview of five promising research pathways for applying
state-of-the-art AI methods, particularly deep learning, to digital gaming
within the context of the current research landscape. The objective of this
work is to outline a curated, non-exhaustive list of encouraging research
directions at the intersection of AI and video games that may serve to inspire
more rigorous and comprehensive research efforts in the future. We discuss (i)
investigating large language models as core engines for game agent modelling,
(ii) using neural cellular automata for procedural game content generation,
(iii) accelerating computationally expensive in-game simulations via deep
surrogate modelling, (iv) leveraging self-supervised learning to obtain useful
video game state embeddings, and (v) training generative models of interactive
worlds using unlabelled video data. We also briefly address current technical
challenges associated with the integration of advanced deep learning systems
into video game development, and indicate key areas where further progress is
likely to be beneficial.

摘要：電子遊戲是人工智慧 (AI) 系統的自然且具有協同效應的應用領域，它既可以提升玩家體驗和沉浸感，又可以提供有價值的基準和虛擬環境，以推進一般的 AI 技術。此報告概述了五種有前途的研究途徑，以將最先進的 AI 方法（特別是深度學習）應用於數位遊戲，同時考量到當前研究領域的背景。這項工作的目標是概述一個經過策劃、非詳盡的鼓勵性研究清單，說明 AI 和電玩遊戲的交集，可能有助於激發未來更嚴謹且全面的研究工作。我們討論 (i) 調查大型語言模型作為遊戲代理建模的核心引擎，(ii) 使用神經元細胞自動機進行程序化遊戲內容生成，(iii) 透過深度代理建模加速計算成本昂貴的遊戲內模擬，(iv) 利用自監督學習來取得有用的電玩遊戲狀態嵌入，以及 (v) 使用未標記的影片資料訓練互動式世界的生成模型。我們也簡要說明與將先進的深度學習系統整合到電玩遊戲開發中相關的當前技術挑戰，並指出可能會受益於進一步進展的主要領域。

##### **Compositional Generalization Across Distributional Shifts with Sparse Tree Operations**
2412.14076v1 by Paul Soulos, Henry Conklin, Mattia Opper, Paul Smolensky, Jianfeng Gao, Roland Fernandez

Neural networks continue to struggle with compositional generalization, and
this issue is exacerbated by a lack of massive pre-training. One successful
approach for developing neural systems which exhibit human-like compositional
generalization is \textit{hybrid} neurosymbolic techniques. However, these
techniques run into the core issues that plague symbolic approaches to AI:
scalability and flexibility. The reason for this failure is that at their core,
hybrid neurosymbolic models perform symbolic computation and relegate the
scalable and flexible neural computation to parameterizing a symbolic system.
We investigate a \textit{unified} neurosymbolic system where transformations in
the network can be interpreted simultaneously as both symbolic and neural
computation. We extend a unified neurosymbolic architecture called the
Differentiable Tree Machine in two central ways. First, we significantly
increase the model's efficiency through the use of sparse vector
representations of symbolic structures. Second, we enable its application
beyond the restricted set of tree2tree problems to the more general class of
seq2seq problems. The improved model retains its prior generalization
capabilities and, since there is a fully neural path through the network,
avoids the pitfalls of other neurosymbolic techniques that elevate symbolic
computation over neural computation.

摘要：神經網路持續與組合概括奮戰，
而這個問題因缺乏大量的預訓練而惡化。一種成功的方法是開發展示人類般組合概括的神經系統，也就是「混合」神經符號技術。然而，這些技術會遇到困擾 AI 符號方法的核心問題：可擴充性和彈性。這個失敗的原因在於，混合神經符號模型在核心上執行符號運算，並將可擴充且彈性的神經運算降級為符號系統的參數化。我們研究一個「統一」的神經符號系統，其中網路中的轉換可以同時詮釋為符號和神經運算。我們以兩種核心方式擴充一個稱為可微分樹狀機器的統一神經符號架構。首先，我們透過使用符號結構的稀疏向量表示法，大幅提升模型的效率。其次，我們讓其應用不只限於受限的樹對樹問題，而是擴及更通用的序列對序列問題。改良後的模型保留了其先前的概括能力，而且由於網路中有一條完全的神經路徑，避免了其他神經符號技術的陷阱，這些技術將符號運算提升至神經運算之上。

##### **A Computationally Grounded Framework for Cognitive Attitudes (extended version)**
2412.14073v1 by Tiago de Lima, Emiliano Lorini, Elise Perrotin, François Schwarzentruber

We introduce a novel language for reasoning about agents' cognitive attitudes
of both epistemic and motivational type. We interpret it by means of a
computationally grounded semantics using belief bases. Our language includes
five types of modal operators for implicit belief, complete attraction,
complete repulsion, realistic attraction and realistic repulsion. We give an
axiomatization and show that our operators are not mutually expressible and
that they can be combined to represent a large variety of psychological
concepts including ambivalence, indifference, being motivated, being
demotivated and preference. We present a dynamic extension of the language that
supports reasoning about the effects of belief change operations. Finally, we
provide a succinct formulation of model checking for our languages and a PSPACE
model checking algorithm relying on a reduction into TQBF. We present some
experimental results for the implemented algorithm on computation time in a
concrete example.

摘要：我們介紹了一種新語言，用於推理代理認知態度，包括認識論和動機類型。我們使用信念基礎，透過計算基礎的語義來詮釋它。我們的語言包含五種類型的模態運算子，用於隱含信念、完全吸引、完全排斥、現實吸引和現實排斥。我們給出一個公理化，並說明我們的運算子不能相互表達，而且可以結合起來表示各種心理概念，包括矛盾、冷漠、有動機、失去動機和偏好。我們提出語言的動態擴展，支援推理信念改變運算的效果。最後，我們提供模型檢查的簡潔公式，以及依賴於 TQBF 縮減的 PSPACE 模型檢查演算法。我們在具體範例中針對實作演算法的計算時間，提供一些實驗結果。

##### **Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification**
2412.14063v1 by Kyle Thompson, Nuno Saavedra, Pedro Carrott, Kevin Fisher, Alex Sanchez-Stern, Yuriy Brun, João F. Ferreira, Sorin Lerner, Emily First

Formal verification using proof assistants, such as Coq, enables the creation
of high-quality software. However, the verification process requires
significant expertise and manual effort to write proofs. Recent work has
explored automating proof synthesis using machine learning and large language
models (LLMs). This work has shown that identifying relevant premises, such as
lemmas and definitions, can aid synthesis. We present Rango, a fully automated
proof synthesis tool for Coq that automatically identifies relevant premises
and also similar proofs from the current project and uses them during
synthesis. Rango uses retrieval augmentation at every step of the proof to
automatically determine which proofs and premises to include in the context of
its fine-tuned LLM. In this way, Rango adapts to the project and to the
evolving state of the proof. We create a new dataset, CoqStoq, of 2,226
open-source Coq projects and 196,929 theorems from GitHub, which includes both
training data and a curated evaluation benchmark of well-maintained projects.
On this benchmark, Rango synthesizes proofs for 32.0% of the theorems, which is
29% more theorems than the prior state-of-the-art tool Tactician. Our
evaluation also shows that Rango adding relevant proofs to its context leads to
a 47% increase in the number of theorems proven.

摘要：使用 Coq 等證明助理進行形式驗證，可以建立高品質的軟體。然而，驗證過程需要相當的專業知識和手動撰寫證明的手工工作。最近的研究已探討使用機器學習和大型語言模型 (LLM) 自動化證明合成。這項研究顯示，識別相關的前提，例如引理和定義，有助於合成。我們提出 Rango，一個完全自動化的 Coq 證明合成工具，它會自動識別相關的前提，以及來自目前專案的類似證明，並在合成期間使用它們。Rango 在證明的每個步驟中使用檢索擴充，以自動決定在微調 LLM 的背景下要包含哪些證明和前提。藉此方式，Rango 適應專案和證明的演化狀態。我們建立了一個新的資料集 CoqStoq，包含 2,226 個開源 Coq 專案和來自 GitHub 的 196,929 個定理，其中包括訓練資料和維護良好的專案的精選評估基準。在此基準上，Rango 為 32.0% 的定理合成證明，比先前的最新工具 Tactician 多出 29% 的定理。我們的評估也顯示，Rango 將相關證明新增到其背景中，會讓已證明定理的數量增加 47%。

##### **A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future**
2412.14056v1 by Shilin Sun, Wenbin An, Feng Tian, Fang Nan, Qidong Liu, Jun Liu, Nazaraf Shah, Ping Chen

Artificial intelligence (AI) has rapidly developed through advancements in
computational power and the growth of massive datasets. However, this progress
has also heightened challenges in interpreting the "black-box" nature of AI
models. To address these concerns, eXplainable AI (XAI) has emerged with a
focus on transparency and interpretability to enhance human understanding and
trust in AI decision-making processes. In the context of multimodal data fusion
and complex reasoning scenarios, the proposal of Multimodal eXplainable AI
(MXAI) integrates multiple modalities for prediction and explanation tasks.
Meanwhile, the advent of Large Language Models (LLMs) has led to remarkable
breakthroughs in natural language processing, yet their complexity has further
exacerbated the issue of MXAI. To gain key insights into the development of
MXAI methods and provide crucial guidance for building more transparent, fair,
and trustworthy AI systems, we review the MXAI methods from a historical
perspective and categorize them across four eras: traditional machine learning,
deep learning, discriminative foundation models, and generative LLMs. We also
review evaluation metrics and datasets used in MXAI research, concluding with a
discussion of future challenges and directions. A project related to this
review has been created at https://github.com/ShilinSun/mxai_review.

摘要：人工智慧 (AI) 透過計算能力的進步以及大量資料集的成長而快速發展。然而，此進展也加劇了詮釋 AI 模型「黑盒子」特性的挑戰。為了解決這些問題，可解釋 AI (XAI) 已應運而生，專注於透明度和可解釋性，以增強人類對 AI 決策流程的理解和信任。在多模態資料融合和複雜推理情境中，多模態可解釋 AI (MXAI) 的提案整合了多種模態，以進行預測和解釋任務。同時，大型語言模型 (LLM) 的出現已導致自然語言處理的顯著突破，但其複雜性進一步加劇了 MXAI 的問題。為了深入了解 MXAI 方法的發展，並為建立更透明、公平且值得信賴的 AI 系統提供關鍵指導，我們從歷史角度回顧 MXAI 方法，並將其分為四個時代：傳統機器學習、深度學習、判別基礎模型和生成式 LLM。我們也回顧了 MXAI 研究中使用的評估指標和資料集，並在最後討論未來的挑戰和方向。與此回顧相關的專案已建立於 https://github.com/ShilinSun/mxai_review。

##### **Digestion Algorithm in Hierarchical Symbolic Forests: A Fast Text Normalization Algorithm and Semantic Parsing Framework for Specific Scenarios and Lightweight Deployment**
2412.14054v1 by Kevin You

Text Normalization and Semantic Parsing have numerous applications in natural
language processing, such as natural language programming, paraphrasing, data
augmentation, constructing expert systems, text matching, and more. Despite the
prominent achievements of deep learning in Large Language Models (LLMs), the
interpretability of neural network architectures is still poor, which affects
their credibility and hence limits the deployments of risk-sensitive scenarios.
In certain scenario-specific domains with scarce data, rapidly obtaining a
large number of supervised learning labels is challenging, and the workload of
manually labeling data would be enormous. Catastrophic forgetting in neural
networks further leads to low data utilization rates. In situations where swift
responses are vital, the density of the model makes local deployment difficult
and the response time long, which is not conducive to local applications of
these fields. Inspired by the multiplication rule, a principle of combinatorial
mathematics, and human thinking patterns, a multilayer framework along with its
algorithm, the Digestion Algorithm in Hierarchical Symbolic Forests (DAHSF), is
proposed to address these above issues, combining text normalization and
semantic parsing workflows. The Chinese Scripting Language "Fire Bunny
Intelligent Development Platform V2.0" is an important test and application of
the technology discussed in this paper. DAHSF can run locally in
scenario-specific domains on little datasets, with model size and memory usage
optimized by at least two orders of magnitude, thus improving the execution
speed, and possessing a promising optimization outlook.

摘要：文本归一化和语义解析在自然语言处理中具有广泛的应用，例如自然语言编程、释义、数据扩充、构建专家系统、文本匹配等。尽管深度学习在大型语言模型 (LLM) 方面取得了显著成就，但神经网络架构的可解释性仍然很差，这影响了它们的可信度，从而限制了风险敏感场景的部署。在某些数据稀缺的特定场景领域，快速获取大量监督学习标签具有挑战性，并且手动标记数据的的工作量将非常庞大。神经网络中的灾难性遗忘进一步导致数据利用率低。在快速响应至关重要的某些情况下，模型的密度使得本地部署变得困难，响应时间长，这不利于这些领域的本地应用。受乘法规则、组合数学原理和人类思维模式的启发，提出了一种多层框架及其算法，即分层符号森林中的消化算法 (DAHSF)，以解决上述问题，结合文本归一化和语义解析工作流。中文脚本语言“火兔智能开发平台 V2.0”是本文讨论的技术的重要测试和应用。DAHSF 可以在特定场景领域的本地小数据集上运行，模型大小和内存使用量至少优化了两个数量级，从而提高了执行速度，并拥有一个有前途的优化前景。

##### **Cross-Lingual Transfer of Debiasing and Detoxification in Multilingual LLMs: An Extensive Investigation**
2412.14050v1 by Vera Neplenbroek, Arianna Bisazza, Raquel Fernández

Recent generative large language models (LLMs) show remarkable performance in
non-English languages, but when prompted in those languages they tend to
express higher harmful social biases and toxicity levels. Prior work has shown
that finetuning on specialized datasets can mitigate this behavior, and doing
so in English can transfer to other languages. In this work, we investigate the
impact of different finetuning methods on the model's bias and toxicity, but
also on its ability to produce fluent and diverse text. Our results show that
finetuning on curated non-harmful text is more effective for mitigating bias,
and finetuning on direct preference optimization (DPO) datasets is more
effective for mitigating toxicity. The mitigation caused by applying these
methods in English also transfers to non-English languages. We find evidence
that the extent to which transfer takes place can be predicted by the amount of
data in a given language present in the model's pretraining data. However, this
transfer of bias and toxicity mitigation often comes at the expense of
decreased language generation ability in non-English languages, highlighting
the importance of developing language-specific bias and toxicity mitigation
methods.

摘要：最近的生成式大型语言模型 (LLM) 在非英语语言中表现出色，但当以这些语言提示时，它们往往表现出较高的有害社会偏见和毒性水平。先前的研究表明，在专门的数据集上进行微调可以减轻这种行为，并且在英语中这样做可以转移到其他语言。在这项工作中，我们调查了不同的微调方法对模型的偏见和毒性的影响，以及对生成流畅且多样化的文本的能力的影响。我们的结果表明，在经过整理的无害文本上进行微调对于减轻偏见更有效，而在直接偏好优化 (DPO) 数据集上进行微调对于减轻毒性更有效。在英语中应用这些方法造成的缓解也转移到了非英语语言。我们发现证据表明，转移发生的程度可以通过模型预训练数据中给定语言的数据量来预测。然而，这种偏见和毒性缓解的转移通常是以牺牲非英语语言的语言生成能力为代价的，这突出了开发特定语言的偏见和毒性缓解方法的重要性。

##### **Hansel: Output Length Controlling Framework for Large Language Models**
2412.14033v1 by Seoha Song, Junhyun Lee, Hyeonmok Ko

Despite the great success of large language models (LLMs), efficiently
controlling the length of the output sequence still remains a challenge. In
this paper, we propose Hansel, an efficient framework for length control in
LLMs without affecting its generation ability. Hansel utilizes periodically
outputted hidden special tokens to keep track of the remaining target length of
the output sequence. Together with techniques to avoid abrupt termination of
the output, this seemingly simple method proved to be efficient and versatile,
while not harming the coherency and fluency of the generated text. The
framework can be applied to any pre-trained LLMs during the finetuning stage of
the model, regardless of its original positional encoding method. We
demonstrate this by finetuning four different LLMs with Hansel and show that
the mean absolute error of the output sequence decreases significantly in every
model and dataset compared to the prompt-based length control finetuning.
Moreover, the framework showed a substantially improved ability to extrapolate
to target lengths unseen during finetuning, such as long dialog responses or
extremely short summaries. This indicates that the model learns the general
means of length control, rather than learning to match output lengths to those
seen during training.

摘要：儘管大型語言模型 (LLM) 獲得巨大的成功，但有效地控制輸出序列的長度仍然是一項挑戰。在本文中，我們提出 Hansel，一個用於 LLM 中長度控制的有效框架，而不會影響其生成能力。Hansel 利用定期輸出的隱藏特殊符號來追蹤輸出序列的剩餘目標長度。此看似簡單的方法與避免輸出突然終止的技術結合使用，證明既有效又多功能，同時不會損害所生成文字的連貫性和流暢性。此框架可以在模型的微調階段應用於任何預先訓練的 LLM，無論其原始位置編碼方法為何。我們透過使用 Hansel 微調四個不同的 LLM 來證明這一點，並顯示與基於提示的長度控制微調相比，每個模型和資料集的輸出序列的平均絕對誤差都顯著降低。此外，該框架顯示出大幅提升的能力，可以外推到微調期間未見的目標長度，例如長對話回應或極短摘要。這表示模型學習長度控制的一般方法，而不是學習將輸出長度與訓練期間所見的長度相匹配。

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

摘要：因果發現對於理解複雜系統至關重要，但傳統方法通常依賴於強而不可測試的假設，這使得這個過程充滿挑戰。大型語言模型 (LLM) 提供了一個從基於文本的元數據中提取因果見解的有希望的替代方案，它整合了領域專業知識。然而，LLM 容易出現不可靠性和幻覺，這需要考慮其限制的策略。一種這樣的策略涉及利用一致性度量來評估可靠性。此外，大多數文本元數據並未清楚地區分直接因果關係和間接因果關係，這進一步複雜化了因果圖的推論。因此，專注於因果順序，而不是因果圖，成為一種更實用、更穩健的方法。我們提出了一種新方法來推導無環錦標賽的分布（表示合理的因果順序），這最大化了一致性分數。我們的做法首先計算變量之間成對的一致性分數，產生一個彙總這些分數的循環錦標賽。從這個結構中，我們識別出與原始錦標賽相容的最佳無環錦標賽，優先考慮那些在所有配置中最大化一致性的錦標賽。我們在經典且完善的基準以及來自流行病學和公共衛生的真實世界數據集上測試了我們的模型。我們的結果證明了我們的方法在以最小誤差恢復因果順序分布方面的有效性。

##### **SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**
2412.14018v1 by Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou

Medical video generation has transformative potential for enhancing surgical
understanding and pathology insights through precise and controllable visual
representations. However, current models face limitations in controllability
and authenticity. To bridge this gap, we propose SurgSora, a
motion-controllable surgical video generation framework that uses a single
input frame and user-controllable motion cues. SurgSora consists of three key
modules: the Dual Semantic Injector (DSI), which extracts object-relevant RGB
and depth features from the input frame and integrates them with segmentation
cues to capture detailed spatial features of complex anatomical structures; the
Decoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-D
features at multiple scales to enhance temporal understanding and object
spatial dynamics; and the Trajectory Controller (TC), which allows users to
specify motion directions and estimates sparse optical flow, guiding the video
generation process. The fused features are used as conditions for a frozen
Stable Diffusion model to produce realistic, temporally coherent surgical
videos. Extensive evaluations demonstrate that SurgSora outperforms
state-of-the-art methods in controllability and authenticity, showing its
potential to advance surgical video generation for medical education, training,
and research.

摘要：醫療影片生成具有變革性的潛力，可透過精確且可控的視覺表現來增強手術理解和病理見解。然而，目前的模型在可控性和真實性方面面臨限制。為了彌合這個差距，我們提出了 SurgSora，一個動作可控的手術影片生成框架，使用單一輸入幀和使用者可控的動作提示。SurgSora 包含三個關鍵模組：雙語意注入器 (DSI)，它從輸入幀中提取與物件相關的 RGB 和深度特徵，並將其與分割提示整合，以擷取複雜解剖結構的詳細空間特徵；解耦流對應器 (DFM)，它在多個尺度上將光流與語意 RGB-D 特徵融合，以增強時間理解和物件空間動態；以及軌跡控制器 (TC)，它允許使用者指定動作方向並估計稀疏光流，引導影片生成過程。融合的特徵用作凍結的 Stable Diffusion 模型的條件，以產生逼真、時間連貫的手術影片。廣泛的評估表明，SurgSora 在可控性和真實性方面優於最先進的方法，顯示其在推進手術影片生成以用於醫學教育、培訓和研究方面的潛力。

##### **Towards an optimised evaluation of teachers' discourse: The case of engaging messages**
2412.14011v1 by Samuel Falcon, Jaime Leon

Evaluating teachers' skills is crucial for enhancing education quality and
student outcomes. Teacher discourse, significantly influencing student
performance, is a key component. However, coding this discourse can be
laborious. This study addresses this issue by introducing a new methodology for
optimising the assessment of teacher discourse. The research consisted of two
studies, both within the framework of engaging messages used by secondary
education teachers. The first study involved training two large language models
on real-world examples from audio-recorded lessons over two academic years to
identify and classify the engaging messages from the lessons' transcripts. This
resulted in sensitivities of 84.31% and 91.11%, and specificities of 97.69% and
86.36% in identification and classification, respectively. The second study
applied these models to transcripts of audio-recorded lessons from a third
academic year to examine the frequency and distribution of message types by
educational level and moment of the academic year. Results showed teachers
predominantly use messages emphasising engagement benefits, linked to improved
outcomes, while one-third highlighted non-engagement disadvantages, associated
with increased anxiety. The use of engaging messages declined in Grade 12 and
towards the academic year's end. These findings suggest potential interventions
to optimise engaging message use, enhancing teaching quality and student
outcomes.

摘要：評量教師技能對於提升教育品質和學生成就至關重要，而教師話語對學生表現有顯著影響，是關鍵組成部分。然而，對話語進行編碼可能很費力。本研究透過提出新的方法論來最佳化教師話語評量，以解決此問題。研究包含兩項研究，兩者皆在中等教育教師所使用的引人訊息架構內進行。第一項研究涉及訓練兩個大型語言模型，使用來自兩學年錄音課程的真實範例，以識別和分類課程講義中的引人訊息。這導致識別和分類的敏感度分別為 84.31% 和 91.11%，特異度分別為 97.69% 和 86.36%。第二項研究將這些模型應用於第三個學年的錄音課程講義，以檢視訊息類型的頻率和分佈，依據教育程度和學年時間。結果顯示，教師主要使用強調參與好處的訊息，與改善成果相關，而三分之一強調不參與的缺點，與焦慮增加相關。引人訊息的使用在 12 年級和學年末下降。這些發現建議潛在的介入措施，以最佳化引人訊息的使用，提升教學品質和學生成就。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **FarExStance: Explainable Stance Detection for Farsi**
2412.14008v1 by Majid Zarharan, Maryam Hashemi, Malika Behroozrazegh, Sauleh Eetemadi, Mohammad Taher Pilehvar, Jennifer Foster

We introduce FarExStance, a new dataset for explainable stance detection in
Farsi. Each instance in this dataset contains a claim, the stance of an article
or social media post towards that claim, and an extractive explanation which
provides evidence for the stance label. We compare the performance of a
fine-tuned multilingual RoBERTa model to several large language models in
zero-shot, few-shot, and parameter-efficient fine-tuned settings on our new
dataset. On stance detection, the most accurate models are the fine-tuned
RoBERTa model, the LLM Aya-23-8B which has been fine-tuned using
parameter-efficient fine-tuning, and few-shot Claude-3.5-Sonnet. Regarding the
quality of the explanations, our automatic evaluation metrics indicate that
few-shot GPT-4o generates the most coherent explanations, while our human
evaluation reveals that the best Overall Explanation Score (OES) belongs to
few-shot Claude-3.5-Sonnet. The fine-tuned Aya-32-8B model produced
explanations most closely aligned with the reference explanations.

摘要：我們介紹 FarExStance，這是波斯語中可解釋立場檢測的新資料集。此資料集中的每個實例包含一個聲明、一篇文章或社群媒體貼文對該聲明的立場，以及一個萃取式解釋，提供立場標籤的證據。我們將微調多語言 RoBERTa 模型的效能與幾個大型語言模型進行比較，這些模型在我們的全新資料集上採用零次學習、少次學習和參數有效微調設定。在立場檢測方面，最準確的模型是微調 RoBERTa 模型、已使用參數有效微調進行微調的 LLM Aya-23-8B，以及少次學習的 Claude-3.5-Sonnet。關於解釋的品質，我們的自動評估指標顯示少次學習的 GPT-4o 產生最連貫的解釋，而我們的人類評估顯示最佳的整體解釋分數 (OES) 屬於少次學習的 Claude-3.5-Sonnet。微調的 Aya-32-8B 模型產生的解釋最接近參考解釋。

##### **Few-shot Steerable Alignment: Adapting Rewards and LLM Policies with Neural Processes**
2412.13998v1 by Katarzyna Kobalczyk, Claudio Fanconi, Hao Sun, Mihaela van der Schaar

As large language models (LLMs) become increasingly embedded in everyday
applications, ensuring their alignment with the diverse preferences of
individual users has become a critical challenge. Currently deployed approaches
typically assume homogeneous user objectives and rely on single-objective
fine-tuning. However, human preferences are inherently heterogeneous,
influenced by various unobservable factors, leading to conflicting signals in
preference data. Existing solutions addressing this diversity often require
costly datasets labelled for specific objectives and involve training multiple
reward models or LLM policies, which is computationally expensive and
impractical. In this work, we present a novel framework for few-shot steerable
alignment, where users' underlying preferences are inferred from a small sample
of their choices. To achieve this, we extend the Bradley-Terry-Luce model to
handle heterogeneous preferences with unobserved variability factors and
propose its practical implementation for reward modelling and LLM fine-tuning.
Thanks to our proposed approach of functional parameter-space conditioning,
LLMs trained with our framework can be adapted to individual preferences at
inference time, generating outputs over a continuum of behavioural modes. We
empirically validate the effectiveness of methods, demonstrating their ability
to capture and align with diverse human preferences in a data-efficient manner.
Our code is made available at:
https://github.com/kasia-kobalczyk/few-shot-steerable-alignment.

摘要：隨著大型語言模型（LLM）日益嵌入日常應用程式中，確保它們與個別使用者的多元化偏好保持一致已成為一項重大的挑戰。目前部署的方法通常假設使用者目標同質，並依賴於單一目標微調。然而，人類偏好本質上是異質的，受各種不可觀察的因素影響，導致偏好資料中的訊號相互衝突。現有的解決方案解決此多元性通常需要標記特定目標的昂貴資料集，並涉及訓練多重獎勵模型或 LLM 政策，這在計算上昂貴且不切實際。在這項工作中，我們提出了一個新穎的框架，用於少次引導對齊，其中使用者的潛在偏好從一小部分的選擇中推論出來。為達成此目的，我們擴充 Bradley-Terry-Luce 模型，以處理具有未觀察變異因子的異質偏好，並提出其在獎勵建模和 LLM 微調中的實際實作。感謝我們提出的函數參數空間條件化方法，使用我們的框架訓練的 LLM 可以適應推理時間中的個別偏好，在行為模式的連續體上產生輸出。我們憑經驗驗證了方法的有效性，證明了它們能夠以資料有效率的方式捕捉和與多元化的人類偏好保持一致。我們的程式碼可在以下網址取得：
https://github.com/kasia-kobalczyk/few-shot-steerable-alignment。

##### **What makes a good metric? Evaluating automatic metrics for text-to-image consistency**
2412.13989v1 by Candace Ross, Melissa Hall, Adriana Romero Soriano, Adina Williams

Language models are increasingly being incorporated as components in larger
AI systems for various purposes, from prompt optimization to automatic
evaluation. In this work, we analyze the construct validity of four recent,
commonly used methods for measuring text-to-image consistency - CLIPScore,
TIFA, VPEval, and DSG - which rely on language models and/or VQA models as
components. We define construct validity for text-image consistency metrics as
a set of desiderata that text-image consistency metrics should have, and find
that no tested metric satisfies all of them. We find that metrics lack
sufficient sensitivity to language and visual properties. Next, we find that
TIFA, VPEval and DSG contribute novel information above and beyond CLIPScore,
but also that they correlate highly with each other. We also ablate different
aspects of the text-image consistency metrics and find that not all model
components are strictly necessary, also a symptom of insufficient sensitivity
to visual information. Finally, we show that all three VQA-based metrics likely
rely on familiar text shortcuts (such as yes-bias in QA) that call their
aptitude as quantitative evaluations of model performance into question.

摘要：語言模型正日益被納入大型 AI 系統中，作為各種用途的組成部分，從提示最佳化到自動評估。在這項工作中，我們分析了四種近期常用的衡量文字轉圖像一致性的方法的建構效度，包括 CLIPScore、TIFA、VPEval 和 DSG，這些方法仰賴語言模型和/或 VQA 模型作為組成部分。我們將文字轉圖像一致性指標的建構效度定義為文字轉圖像一致性指標應具備的一組理想條件，並發現沒有任何受測指標能滿足所有條件。我們發現指標對於語言和視覺屬性缺乏足夠的敏感度。接著，我們發現 TIFA、VPEval 和 DSG 提供了超越 CLIPScore 的新穎資訊，但它們彼此之間也高度相關。我們也消融了文字轉圖像一致性指標的不同面向，並發現並非所有模型組成部分都是絕對必要的，這也是對視覺資訊敏感度不足的徵兆。最後，我們證明所有三種基於 VQA 的指標可能依賴於熟悉的文字捷徑（例如 QA 中的肯定偏差），這使得它們作為模型效能的量化評估的適性受到質疑。

##### **DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**
2412.13964v1 by Stefano M. Nicoletti, E. Moritz Hahn, Mattia Fumagalli, Giancarlo Guizzardi, Mariëlle Stoelinga

When considering risky events or actions, we must not downplay the role of
involved objects: a charged battery in our phone averts the risk of being
stranded in the desert after a flat tyre, and a functional firewall mitigates
the risk of a hacker intruding the network. The Common Ontology of Value and
Risk (COVER) highlights how the role of objects and their relationships remains
pivotal to performing transparent, complete and accountable risk assessment. In
this paper, we operationalize some of the notions proposed by COVER -- such as
parthood between objects and participation of objects in events/actions -- by
presenting a new framework for risk assessment: DODGE. DODGE enriches the
expressivity of vetted formal models for risk -- i.e., fault trees and attack
trees -- by bridging the disciplines of ontology and formal methods into an
ontology-aware formal framework composed by a more expressive modelling
formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an
intermediate query language (ODGLang). With these, DODGE allows risk assessors
to pose questions about disruption propagation, disruption likelihood and risk
levels, keeping the fundamental role of objects at risk always in sight.

摘要：在考量高風險事件或行動時，我們不能低估所涉物件的角色：手機中的充電電池可避免在爆胎後受困沙漠的風險，而功能正常的防火牆則可降低駭客入侵網路的風險。價值與風險的共用本体論 (COVER) 強調物件及其關係的角色，對於執行透明、完整且負責任的風險評估仍然至關重要。在本文中，我們將 COVER 所提出的部分概念（例如物件之間的組成部分關係，以及物件參與事件/行動）具體化，藉由提出一個新的風險評估架構：DODGE。DODGE 透過將本体論與形式化方法橋接至一個本体論感知形式化架構中，豐富了風險驗證形式化模型（例如故障樹和攻擊樹）的表達力，該架構由更具表達力的建模形式主義、物件導向中斷圖 (ODG)、邏輯 (ODGLog) 和一個中間查詢語言 (ODGLang) 組成。透過這些，DODGE 讓風險評估者能夠提出有關中斷傳播、中斷可能性和風險層級的問題，同時始終保持對風險物件的基本角色的關注。

##### **Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation**
2412.13952v1 by Eleni Sgouritsa, Virginia Aglietti, Yee Whye Teh, Arnaud Doucet, Arthur Gretton, Silvia Chiappa

The reasoning abilities of Large Language Models (LLMs) are attracting
increasing attention. In this work, we focus on causal reasoning and address
the task of establishing causal relationships based on correlation information,
a highly challenging problem on which several LLMs have shown poor performance.
We introduce a prompting strategy for this problem that breaks the original
task into fixed subquestions, with each subquestion corresponding to one step
of a formal causal discovery algorithm, the PC algorithm. The proposed
prompting strategy, PC-SubQ, guides the LLM to follow these algorithmic steps,
by sequentially prompting it with one subquestion at a time, augmenting the
next subquestion's prompt with the answer to the previous one(s). We evaluate
our approach on an existing causal benchmark, Corr2Cause: our experiments
indicate a performance improvement across five LLMs when comparing PC-SubQ to
baseline prompting strategies. Results are robust to causal query
perturbations, when modifying the variable names or paraphrasing the
expressions.

摘要：大型語言模型 (LLM) 的推理能力正吸引越來越多的關注。在這項工作中，我們專注於因果推理，並解決基於相關資訊建立因果關係的任務，這是一個極具挑戰性的問題，多個 LLM 在此問題上表現不佳。我們為此問題引入了一個提示策略，將原始任務分解為固定的子問題，每個子問題對應於形式因果發現演算法（PC 演算法）的一個步驟。建議的提示策略 PC-SubQ 引導 LLM 按照這些演算法步驟進行，一次提示一個子問題，並使用前一個（或多個）子問題的答案擴充下一個子問題的提示。我們在現有的因果基準 Corr2Cause 上評估了我們的方法：我們的實驗表明，與基準提示策略相比，PC-SubQ 在比較五個 LLM 時改進了效能。當修改變數名稱或改寫表達式時，結果對因果查詢擾動具有魯棒性。

##### **Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence**
2412.13949v1 by Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhenglin Hua, Yuheng Jia, Ming Tang, Tat-Seng Chua, Jinqiao Wang

Large vision-language models (LVLMs) have made substantial progress in
integrating large language models (LLMs) with visual inputs, enabling advanced
multimodal reasoning. Despite their success, a persistent challenge is
hallucination-where generated text fails to accurately reflect visual
content-undermining both accuracy and reliability. Existing methods focus on
alignment training or decoding refinements but primarily address symptoms at
the generation stage without probing the underlying causes. In this work, we
investigate the internal mechanisms driving hallucination in LVLMs, with an
emphasis on the multi-head attention module. Specifically, we introduce
Vision-aware Head Divergence (VHD), a metric that quantifies the sensitivity of
attention head outputs to visual context. Based on this, our findings reveal
the presence of vision-aware attention heads that are more attuned to visual
information; however, the model's overreliance on its prior language patterns
is closely related to hallucinations. Building on these insights, we propose
Vision-aware Head Reinforcement (VHR), a training-free approach to mitigate
hallucination by enhancing the role of vision-aware attention heads. Extensive
experiments demonstrate that our method achieves superior performance compared
to state-of-the-art approaches in mitigating hallucinations, while maintaining
high efficiency with negligible additional time overhead.

摘要：大型視覺語言模型 (LVLMs) 在將大型語言模型 (LLMs) 與視覺輸入整合方面取得了實質性進展，實現了先進的多模態推理。儘管它們取得了成功，但持續的挑戰在於幻覺，其中產生的文字無法準確反映視覺內容，從而損害了準確性和可靠性。現有方法專注於對齊訓練或解碼優化，但主要解決產生階段的症狀，而沒有探究根本原因。在這項工作中，我們研究了驅動 LVLMs 中幻覺的內部機制，重點關注多頭注意模組。具體來說，我們引入了視覺感知頭部差異 (VHD)，這是一個量化注意頭部輸出對視覺環境敏感性的指標。基於此，我們的研究結果揭示了存在視覺感知注意頭部，它們更適應視覺資訊；然而，模型過度依賴其先前的語言模式與幻覺密切相關。根據這些見解，我們提出了視覺感知頭部強化 (VHR)，這是一種無需訓練的方法，通過增強視覺感知注意頭部的作用來減輕幻覺。大量的實驗證明，與減輕幻覺的最新方法相比，我們的模型取得了卓越的效能，同時保持高效率，且幾乎沒有額外的時間開銷。

##### **On Explaining Knowledge Distillation: Measuring and Visualising the Knowledge Transfer Process**
2412.13943v1 by Gereziher Adhane, Mohammad Mahdi Dehshibi, Dennis Vetter, David Masip, Gemma Roig

Knowledge distillation (KD) remains challenging due to the opaque nature of
the knowledge transfer process from a Teacher to a Student, making it difficult
to address certain issues related to KD. To address this, we proposed UniCAM, a
novel gradient-based visual explanation method, which effectively interprets
the knowledge learned during KD. Our experimental results demonstrate that with
the guidance of the Teacher's knowledge, the Student model becomes more
efficient, learning more relevant features while discarding those that are not
relevant. We refer to the features learned with the Teacher's guidance as
distilled features and the features irrelevant to the task and ignored by the
Student as residual features. Distilled features focus on key aspects of the
input, such as textures and parts of objects. In contrast, residual features
demonstrate more diffused attention, often targeting irrelevant areas,
including the backgrounds of the target objects. In addition, we proposed two
novel metrics: the feature similarity score (FSS) and the relevance score (RS),
which quantify the relevance of the distilled knowledge. Experiments on the
CIFAR10, ASIRRA, and Plant Disease datasets demonstrate that UniCAM and the two
metrics offer valuable insights to explain the KD process.

摘要：知識蒸餾（KD）由於教師到學生的知識傳輸過程的不透明本質而仍然具有挑戰性，這使得難以解決與 KD 相關的某些問題。為了解決這個問題，我們提出了 UniCAM，一種新穎的基於梯度的視覺解釋方法，它有效地解釋了 KD 期間學習到的知識。我們的實驗結果表明，在教師知識的指導下，學生模型變得更有效率，學習更多相關特徵，同時捨棄不相關的特徵。我們將在教師指導下學習到的特徵稱為蒸餾特徵，而與任務無關且學生忽略的特徵稱為殘差特徵。蒸餾特徵關注輸入的關鍵方面，例如紋理和物體的部分。相比之下，殘差特徵表現出更分散的注意力，通常針對無關區域，包括目標物體的背景。此外，我們提出了兩個新穎的指標：特徵相似度分數（FSS）和相關性分數（RS），它們量化了蒸餾知識的相關性。在 CIFAR10、ASIRRA 和植物病害數據集上的實驗表明，UniCAM 和這兩個指標提供了寶貴的見解來解釋 KD 過程。

##### **A Rose by Any Other Name: LLM-Generated Explanations Are Good Proxies for Human Explanations to Collect Label Distributions on NLI**
2412.13942v1 by Beiduo Chen, Siyao Peng, Anna Korhonen, Barbara Plank

Disagreement in human labeling is ubiquitous, and can be captured in human
judgment distributions (HJDs). Recent research has shown that explanations
provide valuable information for understanding human label variation (HLV) and
large language models (LLMs) can approximate HJD from a few human-provided
label-explanation pairs. However, collecting explanations for every label is
still time-consuming. This paper examines whether LLMs can be used to replace
humans in generating explanations for approximating HJD. Specifically, we use
LLMs as annotators to generate model explanations for a few given human labels.
We test ways to obtain and combine these label-explanations with the goal to
approximate human judgment distribution. We further compare the resulting human
with model-generated explanations, and test automatic and human explanation
selection. Our experiments show that LLM explanations are promising for NLI: to
estimate HJD, generated explanations yield comparable results to human's when
provided with human labels. Importantly, our results generalize from datasets
with human explanations to i) datasets where they are not available and ii)
challenging out-of-distribution test sets.

摘要：<paragraph>人類標記中的分歧無處不在，並且可以捕捉在人類判斷分佈 (HJD) 中。最近的研究表明，解釋提供了有價值的資訊，用於了解人類標籤變異 (HLV)，而大型語言模型 (LLM) 可以從少數人類提供的標籤-說明配對中近似 HJD。然而，為每個標籤收集解釋仍然很費時。本文探討了 LLM 是否可用於取代人類，為近似 HJD 產生解釋。具體來說，我們使用 LLM 作為註解者，為幾個給定的人類標籤產生模型解釋。我們測試了獲取和組合這些標籤-解釋的方法，目標是近似人類判斷分佈。我們進一步比較了由此產生的由人類和模型產生的解釋，並測試了自動和人類解釋選擇。我們的實驗表明，LLM 解釋對於 NLI 很有希望：為了估計 HJD，當提供人類標籤時，產生的解釋會產生與人類相當的結果。重要的是，我們的結果從具有人類解釋的資料集推廣到 i) 沒有可用資料集以及 ii) 具有挑戰性的分佈外測試集。</paragraph>

##### **Spatio-Temporal Forecasting of PM2.5 via Spatial-Diffusion guided Encoder-Decoder Architecture**
2412.13935v1 by Malay Pandey, Vaishali Jain, Nimit Godhani, Sachchida Nand Tripathi, Piyush Rai

In many problem settings that require spatio-temporal forecasting, the values
in the time-series not only exhibit spatio-temporal correlations but are also
influenced by spatial diffusion across locations. One such example is
forecasting the concentration of fine particulate matter (PM2.5) in the
atmosphere which is influenced by many complex factors, the most important ones
being diffusion due to meteorological factors as well as transport across vast
distances over a period of time. We present a novel Spatio-Temporal Graph
Neural Network architecture, that specifically captures these dependencies to
forecast the PM2.5 concentration. Our model is based on an encoder-decoder
architecture where the encoder and decoder parts leverage gated recurrent units
(GRU) augmented with a graph neural network (TransformerConv) to account for
spatial diffusion. Our model can also be seen as a generalization of various
existing models for time-series or spatio-temporal forecasting. We demonstrate
the model's effectiveness on two real-world PM2.5 datasets: (1) data collected
by us using a recently deployed network of low-cost PM$_{2.5}$ sensors from 511
locations spanning the entirety of the Indian state of Bihar over a period of
one year, and (2) another publicly available dataset that covers severely
polluted regions from China for a period of 4 years. Our experimental results
show our model's impressive ability to account for both spatial as well as
temporal dependencies precisely.

摘要：在許多需要時空預測的問題設定中，時序中的值不僅表現出時空關聯性，而且還受到位置間空間擴散的影響。一個這樣的例子是預測大氣中細懸浮微粒 (PM2.5) 的濃度，這受到許多複雜因素的影響，其中最重要的因素是氣象因素造成的擴散以及一段時間內跨越廣大距離的傳輸。我們提出了一種新穎的時空圖形神經網路架構，它特別捕捉這些依賴性以預測 PM2.5 濃度。我們的模型基於編碼器-解碼器架構，其中編碼器和解碼器部分利用門控遞迴單元 (GRU) 來擴充圖形神經網路 (TransformerConv) 以考量空間擴散。我們的模型也可以視為各種現有時間序列或時空預測模型的概括。我們在兩個真實世界的 PM2.5 資料集上展示了該模型的有效性：(1) 我們使用最近部署的低成本 PM$_{2.5}$ 感測器網路收集的資料，來自於印度比哈爾邦全境 511 個地點，為期一年，以及 (2) 另一個公開可用的資料集，涵蓋了中國嚴重污染地區長達 4 年的資料。我們的實驗結果顯示，我們的模型具有令人印象深刻的能力，可以準確地考量空間和時間依賴性。

##### **Language verY Rare for All**
2412.13924v1 by Ibrahim Merad, Amos Wolf, Ziad Mazzawi, Yannick Léo

In the quest to overcome language barriers, encoder-decoder models like NLLB
have expanded machine translation to rare languages, with some models (e.g.,
NLLB 1.3B) even trainable on a single GPU. While general-purpose LLMs perform
well in translation, open LLMs prove highly competitive when fine-tuned for
specific tasks involving unknown corpora. We introduce LYRA (Language verY Rare
for All), a novel approach that combines open LLM fine-tuning,
retrieval-augmented generation (RAG), and transfer learning from related
high-resource languages. This study is exclusively focused on single-GPU
training to facilitate ease of adoption. Our study focuses on two-way
translation between French and Mon\'egasque, a rare language unsupported by
existing translation tools due to limited corpus availability. Our results
demonstrate LYRA's effectiveness, frequently surpassing and consistently
matching state-of-the-art encoder-decoder models in rare language translation.

摘要：為了克服語言障礙，編碼器-解碼器模型（例如 NLLB）已將機器翻譯擴展到罕見語言，有些模型（例如 NLLB 1.3B）甚至可以在單一 GPU 上訓練。雖然通用 LLM 在翻譯方面表現良好，但針對涉及未知語料庫的特定任務進行微調時，開放式 LLM 證明了其高度競爭力。我們介紹 LYRA（對所有人來說都非常罕見的語言），這是一種新穎的方法，結合了開放式 LLM 微調、檢索增強生成（RAG）和來自相關高資源語言的轉移學習。本研究專注於單一 GPU 訓練，以促進輕鬆採用。我們的研究重點放在法語和摩納哥語之間的雙向翻譯，這是一種罕見的語言，由於語料庫可用性有限，現有的翻譯工具無法支援。我們的結果證明了 LYRA 的有效性，在罕見語言翻譯中經常超越並始終匹配最先進的編碼器-解碼器模型。

##### **Pipeline Analysis for Developing Instruct LLMs in Low-Resource Languages: A Case Study on Basque**
2412.13922v1 by Ander Corral, Ixak Sarasua, Xabier Saralegi

Large language models (LLMs) are typically optimized for resource-rich
languages like English, exacerbating the gap between high-resource and
underrepresented languages. This work presents a detailed analysis of
strategies for developing a model capable of following instructions in a
low-resource language, specifically Basque, by focusing on three key stages:
pre-training, instruction tuning, and alignment with human preferences. Our
findings demonstrate that continual pre-training with a high-quality Basque
corpus of around 600 million words improves natural language understanding
(NLU) of the foundational model by over 12 points. Moreover, instruction tuning
and human preference alignment using automatically translated datasets proved
highly effective, resulting in a 24-point improvement in instruction-following
performance. The resulting models, Llama-eus-8B and Llama-eus-8B-instruct,
establish a new state-of-the-art for Basque in the sub-10B parameter category.

摘要：大型語言模型 (LLM) 通常針對英語等資源豐富的語言進行最佳化，這加劇了高資源語言和低代表性語言之間的差距。本研究針對開發一種能夠遵循低資源語言（特別是巴斯克語）指令的模型的策略進行詳細分析，重點關注三個關鍵階段：預訓練、指令調整和與人類偏好的對齊。我們的研究結果表明，使用約 6 億個單詞的高品質巴斯克語語料庫進行持續預訓練，可以將基礎模型的自然語言理解 (NLU) 提升超過 12 分。此外，使用自動翻譯數據集進行指令調整和人類偏好對齊被證明非常有效，從而使指令遵循性能提升了 24 分。所產生的模型 Llama-eus-8B 和 Llama-eus-8B-instruct 為低於 10B 參數類別中的巴斯克語建立了新的技術水準。

##### **Energy-Efficient SLAM via Joint Design of Sensing, Communication, and Exploration Speed**
2412.13912v1 by Zidong Han, Ruibo Jin, Xiaoyang Li, Bingpeng Zhou, Qinyu Zhang, Yi Gong

To support future spatial machine intelligence applications, lifelong
simultaneous localization and mapping (SLAM) has drawn significant attentions.
SLAM is usually realized based on various types of mobile robots performing
simultaneous and continuous sensing and communication. This paper focuses on
analyzing the energy efficiency of robot operation for lifelong SLAM by jointly
considering sensing, communication and mechanical factors. The system model is
built based on a robot equipped with a 2D light detection and ranging (LiDAR)
and an odometry. The cloud point raw data as well as the odometry data are
wirelessly transmitted to data center where real-time map reconstruction is
realized based on an unsupervised deep learning based method. The sensing
duration, transmit power, transmit duration and exploration speed are jointly
optimized to minimize the energy consumption. Simulations and experiments
demonstrate the performance of our proposed method.

摘要：為了支援未來的空間機器智慧應用，終身同步定位與地圖繪製 (SLAM) 已經引起廣泛的關注。SLAM 通常是根據各種類型的行動機器人執行同步且持續的感測和通訊而實現。本文重點在於分析機器人運作的能源效率，以進行終身 SLAM，並同時考慮感測、通訊和機械因素。系統模型是根據配備 2D 光偵測與測距 (LiDAR) 和里程計的機器人所建立。雲端點原始資料以及里程計資料會無線傳輸到資料中心，並根據非監督式深度學習方法進行即時地圖重建。感測持續時間、傳輸功率、傳輸持續時間和探索速度會共同最佳化，以將能源消耗降至最低。模擬和實驗證明了我們提出的方法的效能。

##### **Understanding and Analyzing Model Robustness and Knowledge-Transfer in Multilingual Neural Machine Translation using TX-Ray**
2412.13881v1 by Vageesh Saxena, Sharid Loáiciga, Nils Rethmeier

Neural networks have demonstrated significant advancements in Neural Machine
Translation (NMT) compared to conventional phrase-based approaches. However,
Multilingual Neural Machine Translation (MNMT) in extremely low-resource
settings remains underexplored. This research investigates how knowledge
transfer across languages can enhance MNMT in such scenarios. Using the Tatoeba
translation challenge dataset from Helsinki NLP, we perform English-German,
English-French, and English-Spanish translations, leveraging minimal parallel
data to establish cross-lingual mappings. Unlike conventional methods relying
on extensive pre-training for specific language pairs, we pre-train our model
on English-English translations, setting English as the source language for all
tasks. The model is fine-tuned on target language pairs using joint multi-task
and sequential transfer learning strategies. Our work addresses three key
questions: (1) How can knowledge transfer across languages improve MNMT in
extremely low-resource scenarios? (2) How does pruning neuron knowledge affect
model generalization, robustness, and catastrophic forgetting? (3) How can
TX-Ray interpret and quantify knowledge transfer in trained models? Evaluation
using BLEU-4 scores demonstrates that sequential transfer learning outperforms
baselines on a 40k parallel sentence corpus, showcasing its efficacy. However,
pruning neuron knowledge degrades performance, increases catastrophic
forgetting, and fails to improve robustness or generalization. Our findings
provide valuable insights into the potential and limitations of knowledge
transfer and pruning in MNMT for extremely low-resource settings.

摘要：神經網路在神經機器翻譯 (NMT) 方面已展現出比傳統基於詞彙的技術更顯著的進展。然而，在極度低資源的環境中，多語言神經機器翻譯 (MNMT) 仍未被充分探討。本研究探討了在這種情況下，跨語言的知識轉移如何增強 MNMT。我們使用赫爾辛基 NLP 的 Tatoeba 翻譯挑戰資料集，執行英德、英法和英西翻譯，利用最少的平行資料來建立跨語言對應。有別於依賴特定語言對進行廣泛預訓練的傳統方法，我們在英英翻譯上預訓練我們的模型，將英語設定為所有任務的原始語言。該模型使用聯合多任務和順序轉移學習策略，針對目標語言對進行微調。我們的研究探討了三個關鍵問題：(1) 在極度低資源的情況下，跨語言的知識轉移如何改善 MNMT？(2) 修剪神經元知識如何影響模型的泛化性、穩健性和災難性遺忘？(3) TX-Ray 如何解讀和量化訓練模型中的知識轉移？使用 BLEU-4 分數進行的評估顯示，順序轉移學習在 40k 平行句子語料庫上優於基線，展示了其效能。然而，修剪神經元知識會降低效能、增加災難性遺忘，並且無法改善穩健性或泛化性。我們的研究結果提供了有價值的見解，說明了在極度低資源的環境中，知識轉移和修剪在 MNMT 中的潛力和限制。

##### **Crabs: Consuming Resrouce via Auto-generation for LLM-DoS Attack under Black-box Settings**
2412.13879v1 by Yuanhe Zhang, Zhenhong Zhou, Wei Zhang, Xinyue Wang, Xiaojun Jia, Yang Liu, Sen Su

Large Language Models (LLMs) have demonstrated remarkable performance across
diverse tasks. LLMs continue to be vulnerable to external threats, particularly
Denial-of-Service (DoS) attacks. Specifically, LLM-DoS attacks aim to exhaust
computational resources and block services. However, prior works tend to focus
on performing white-box attacks, overlooking black-box settings. In this work,
we propose an automated algorithm designed for black-box LLMs, called
Auto-Generation for LLM-DoS Attack (AutoDoS). AutoDoS introduces DoS Attack
Tree and optimizes the prompt node coverage to enhance effectiveness under
black-box conditions. Our method can bypass existing defense with enhanced
stealthiness via semantic improvement of prompt nodes. Furthermore, we reveal
that implanting Length Trojan in Basic DoS Prompt aids in achieving higher
attack efficacy. Experimental results show that AutoDoS amplifies service
response latency by over 250 $\times \uparrow$, leading to severe resource
consumption in terms of GPU utilization and memory usage. Our code is available
at \url{https://github.com/shuita2333/AutoDoS}.

摘要：大型語言模型 (LLM) 已展現出在各種任務上的卓越效能。LLM 仍容易受到外部威脅，特別是拒絕服務 (DoS) 攻擊。具體來說，LLM-DoS 攻擊旨在耗盡運算資源並封鎖服務。然而，先前的研究傾向於專注於執行白盒攻擊，而忽略黑盒設定。在這項研究中，我們提出一個自動化演算法，專門用於黑盒 LLM，稱為 LLM-DoS 攻擊自動產生 (AutoDoS)。AutoDoS 引入 DoS 攻擊樹，並最佳化提示節點涵蓋範圍，以增強在黑盒條件下的效能。我們的技術可透過語意改善提示節點，繞過現有的防禦機制，並增強隱蔽性。此外，我們揭露在基本 DoS 提示中植入長度木馬有助於達成更高的攻擊效能。實驗結果顯示，AutoDoS 將服務回應延遲放大超過 250 倍，導致 GPU 使用率和記憶體使用量方面出現嚴重的資源消耗。我們的程式碼可於 \url{https://github.com/shuita2333/AutoDoS} 取得。

##### **RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation**
2412.13877v1 by Kun Wu, Chengkai Hou, Jiaming Liu, Zhengping Che, Xiaozhu Ju, Zhuqin Yang, Meng Li, Yinuo Zhao, Zhiyuan Xu, Guang Yang, Zhen Zhao, Guangyu Li, Zhao Jin, Lecheng Wang, Jilei Mao, Xinhua Wang, Shichao Fan, Ning Liu, Pei Ren, Qiang Zhang, Yaoxu Lyu, Mengzhen Liu, Jingyang He, Yulin Luo, Zeyu Gao, Chenxuan Li, Chenyang Gu, Yankai Fu, Di Wu, Xingyu Wang, Sixiang Chen, Zhenyu Wang, Pengju An, Siyuan Qian, Shanghang Zhang, Jian Tang

Developing robust and general-purpose robotic manipulation policies is a key
goal in the field of robotics. To achieve effective generalization, it is
essential to construct comprehensive datasets that encompass a large number of
demonstration trajectories and diverse tasks. Unlike vision or language data
that can be collected from the Internet, robotic datasets require detailed
observations and manipulation actions, necessitating significant investment in
hardware-software infrastructure and human labor. While existing works have
focused on assembling various individual robot datasets, there remains a lack
of a unified data collection standard and insufficient diversity in tasks,
scenarios, and robot types. In this paper, we introduce RoboMIND
(Multi-embodiment Intelligence Normative Data for Robot manipulation),
featuring 55k real-world demonstration trajectories across 279 diverse tasks
involving 61 different object classes. RoboMIND is collected through human
teleoperation and encompasses comprehensive robotic-related information,
including multi-view RGB-D images, proprioceptive robot state information, end
effector details, and linguistic task descriptions. To ensure dataset
consistency and reliability during policy learning, RoboMIND is built on a
unified data collection platform and standardized protocol, covering four
distinct robotic embodiments. We provide a thorough quantitative and
qualitative analysis of RoboMIND across multiple dimensions, offering detailed
insights into the diversity of our datasets. In our experiments, we conduct
extensive real-world testing with four state-of-the-art imitation learning
methods, demonstrating that training with RoboMIND data results in a high
manipulation success rate and strong generalization. Our project is at
https://x-humanoid-robomind.github.io/.

摘要：<paragraph>開發健全且通用的機器人操作策略是機器人領域的一項關鍵目標。為了達到有效的概化，建構包含大量示範軌跡和多樣任務的全面資料集至關重要。與可以從網際網路上收集的視覺或語言資料不同，機器人資料集需要詳細的觀察和操作動作，這需要對硬體軟體基礎設施和人力進行大量投資。儘管現有作品專注於組裝各種個別機器人資料集，但仍然缺乏統一的資料收集標準，並且任務、場景和機器人類型缺乏多樣性。在本文中，我們介紹了 RoboMIND（機器人操作的多具現智能規範資料），它包含 61 個不同物體類別的 279 個多樣化任務中 55k 個真實世界的示範軌跡。RoboMIND 是透過人類遠端操作收集的，並包含全面的機器人相關資訊，包括多視角 RGB-D 影像、本體感覺機器人狀態資訊、末端執行器詳細資訊和語言任務描述。為了確保在策略學習期間資料集的一致性和可靠性，RoboMIND 建構在統一的資料收集平台和標準化協定上，涵蓋四種不同的機器人具現。我們提供了 RoboMIND 在多個維度上的全面定量和定性分析，對我們資料集的多樣性提供了詳細的見解。在我們的實驗中，我們使用四種最先進的模仿學習方法進行了廣泛的真實世界測試，證明使用 RoboMIND 資料進行訓練會產生很高的操作成功率和強大的概化能力。我們的專案網址為 https://x-humanoid-robomind.github.io/。</paragraph>

##### **SHAP scores fail pervasively even when Lipschitz succeeds**
2412.13866v1 by Olivier Letoffe, Xuanxiang Huang, Joao Marques-Silva

The ubiquitous use of Shapley values in eXplainable AI (XAI) has been
triggered by the tool SHAP, and as a result are commonly referred to as SHAP
scores. Recent work devised examples of machine learning (ML) classifiers for
which the computed SHAP scores are thoroughly unsatisfactory, by allowing human
decision-makers to be misled. Nevertheless, such examples could be perceived as
somewhat artificial, since the selected classes must be interpreted as numeric.
Furthermore, it was unclear how general were the issues identified with SHAP
scores. This paper answers these criticisms. First, the paper shows that for
Boolean classifiers there are arbitrarily many examples for which the SHAP
scores must be deemed unsatisfactory. Second, the paper shows that the issues
with SHAP scores are also observed in the case of regression models. In
addition, the paper studies the class of regression models that respect
Lipschitz continuity, a measure of a function's rate of change that finds
important recent uses in ML, including model robustness. Concretely, the paper
shows that the issues with SHAP scores occur even for regression models that
respect Lipschitz continuity. Finally, the paper shows that the same issues are
guaranteed to exist for arbitrarily differentiable regression models.

摘要：在可解釋 AI (XAI) 中普遍使用 Shapley 值是由工具 SHAP 引發的，因此通常稱為 SHAP 分數。最近的工作設計了機器學習 (ML) 分類器的範例，其中計算出的 SHAP 分數完全不令人滿意，因為它讓人類決策者誤入歧途。儘管如此，此類範例可能會被視為有點人為，因為所選的類別必須解釋為數字。此外，目前尚不清楚使用 SHAP 分數所發現的問題有多普遍。本文回答了這些批評。首先，本文顯示對於布林分類器，有任意多個範例，其中 SHAP 分數必須被視為不令人滿意。其次，本文顯示，在回歸模型的情況下也觀察到了 SHAP 分數的問題。此外，本文研究了尊重 Lipschitz 連續性的回歸模型類別，這是一種函數變化率的量度，在 ML 中發現了重要的近期用途，包括模型穩健性。具體來說，本文顯示，即使對於尊重 Lipschitz 連續性的回歸模型，也會出現 SHAP 分數的問題。最後，本文顯示，對於任意可微分的回歸模型，保證存在相同的問題。

##### **Energy-Based Preference Model Offers Better Offline Alignment than the Bradley-Terry Preference Model**
2412.13862v1 by Yuzhong Hong, Hanshan Zhang, Junwei Bao, Hongfei Jiang, Yang Song

Since the debut of DPO, it has been shown that aligning a target LLM with
human preferences via the KL-constrained RLHF loss is mathematically equivalent
to a special kind of reward modeling task. Concretely, the task requires: 1)
using the target LLM to parameterize the reward model, and 2) tuning the reward
model so that it has a 1:1 linear relationship with the true reward. However,
we identify a significant issue: the DPO loss might have multiple minimizers,
of which only one satisfies the required linearity condition. The problem
arises from a well-known issue of the underlying Bradley-Terry preference
model: it does not always have a unique maximum likelihood estimator (MLE).
Consequently,the minimizer of the RLHF loss might be unattainable because it is
merely one among many minimizers of the DPO loss. As a better alternative, we
propose an energy-based model (EBM) that always has a unique MLE, inherently
satisfying the linearity requirement. To approximate the MLE in practice, we
propose a contrastive loss named Energy Preference Alignment (EPA), wherein
each positive sample is contrasted against one or more strong negatives as well
as many free weak negatives. Theoretical properties of our EBM enable the
approximation error of EPA to almost surely vanish when a sufficient number of
negatives are used. Empirically, we demonstrate that EPA consistently delivers
better performance on open benchmarks compared to DPO, thereby showing the
superiority of our EBM.

摘要：自 DPO 問世以來，已經證明透過 KL 約束 RLHF 損失將目標 LLM 與人類偏好對齊在數學上等同於一種特殊類型的獎勵建模任務。具體而言，該任務需要：1) 使用目標 LLM 將獎勵模型參數化，以及 2) 調整獎勵模型，使其與真實獎勵具有 1:1 的線性關係。然而，我們發現一個重要問題：DPO 損失可能有多個最小化器，其中只有一個滿足所需的線性條件。這個問題源自於基礎 Bradley-Terry 偏好模型的一個眾所周知的問題：它並不總是具有唯一的最大似然估計器 (MLE)。因此，RLHF 損失的最小化器可能是無法達成的，因為它只是 DPO 損失的許多最小化器之一。作為一個更好的替代方案，我們提出了一個始終具有唯一 MLE 的基於能量的模型 (EBM)，它固有地滿足線性要求。為了在實務中估計 MLE，我們提出了一個名為能量偏好對齊 (EPA) 的對比損失，其中每個正樣本都與一個或多個強負樣本以及許多自由弱負樣本進行對比。我們的 EBM 的理論性質使 EPA 的近似誤差幾乎可以在使用足夠數量的負樣本時消失。根據經驗，我們證明 EPA 在開放基準測試中始終提供比 DPO 更好的效能，從而顯示出我們的 EBM 的優越性。

##### **Domain-adaptative Continual Learning for Low-resource Tasks: Evaluation on Nepali**
2412.13860v1 by Sharad Duwal, Suraj Prasai, Suresh Manandhar

Continual learning has emerged as an important research direction due to the
infeasibility of retraining large language models (LLMs) from scratch in the
event of new data availability. Of great interest is the domain-adaptive
pre-training (DAPT) paradigm, which focuses on continually training a
pre-trained language model to adapt it to a domain it was not originally
trained on. In this work, we evaluate the feasibility of DAPT in a low-resource
setting, namely the Nepali language. We use synthetic data to continue training
Llama 3 8B to adapt it to the Nepali language in a 4-bit QLoRA setting. We
evaluate the adapted model on its performance, forgetting, and knowledge
acquisition. We compare the base model and the final model on their Nepali
generation abilities, their performance on popular benchmarks, and run
case-studies to probe their linguistic knowledge in Nepali. We see some
unsurprising forgetting in the final model, but also surprisingly find that
increasing the number of shots during evaluation yields better percent
increases in the final model (as high as 19.29% increase) compared to the base
model (4.98%), suggesting latent retention. We also explore layer-head
self-attention heatmaps to establish dependency resolution abilities of the
final model in Nepali.

摘要：持續學習已成為一項重要的研究方向，因為在有新資料可用時，從頭重新訓練大型語言模型 (LLM) 不可行。極具興趣的是領域適應預訓練 (DAPT) 典範，它專注於持續訓練預訓練語言模型，以適應它最初未受過訓練的領域。在這項工作中，我們評估了 DAPT 在低資源設定（即尼泊爾語）中的可行性。我們使用合成資料繼續訓練 Llama 3 8B，以 4 位元 QLoRA 設定將其適應尼泊爾語。我們評估適應模型的效能、遺忘和知識習得。我們比較基礎模型和最終模型的尼泊爾語生成能力、它們在熱門基準測試中的效能，並執行個案研究以探討它們在尼泊爾語中的語言知識。我們在最終模型中看到一些不足為奇的遺忘，但令人驚訝地發現，在評估期間增加次數會產生更好的最終模型百分比增加（高達 19.29% 的增加），與基礎模型（4.98%）相比，這表明潛在保留。我們還探索層級頭部自注意力熱圖，以建立最終模型在尼泊爾語中的依存關係解析能力。

##### **IDEQ: an improved diffusion model for the TSP**
2412.13858v1 by Mickael Basson, Philippe Preux

We investigate diffusion models to solve the Traveling Salesman Problem.
Building on the recent DIFUSCO and T2TCO approaches, we propose IDEQ. IDEQ
improves the quality of the solutions by leveraging the constrained structure
of the state space of the TSP. Another key component of IDEQ consists in
replacing the last stages of DIFUSCO curriculum learning by considering a
uniform distribution over the Hamiltonian tours whose orbits by the 2-opt
operator converge to the optimal solution as the training objective. Our
experiments show that IDEQ improves the state of the art for such neural
network based techniques on synthetic instances. More importantly, our
experiments show that IDEQ performs very well on the instances of the TSPlib, a
reference benchmark in the TSP community: it closely matches the performance of
the best heuristics, LKH3, being even able to obtain better solutions than LKH3
on 2 instances of the TSPlib defined on 1577 and 3795 cities. IDEQ obtains 0.3%
optimality gap on TSP instances made of 500 cities, and 0.5% on TSP instances
with 1000 cities. This sets a new SOTA for neural based methods solving the
TSP. Moreover, IDEQ exhibits a lower variance and better scales-up with the
number of cities with regards to DIFUSCO and T2TCO.

摘要：我們研究擴散模型來解決旅行商問題。
建立在最近的 DIFUSCO 和 T2TCO 方法之上，我們提出 IDEQ。IDEQ
通過利用 TSP 狀態空間的約束結構來改善解決方案的品質。IDEQ 的另一個關鍵組成部分在於
通過考慮哈密頓迴路的均勻分布來替換 DIFUSCO 課程學習的最後階段，其軌道由 2 選擇運算子收斂到最佳解，作為訓練目標。我們的
實驗顯示，IDEQ 改善了此類神經網路技術在合成實例上的最新技術。更重要的是，我們的
實驗顯示，IDEQ 在 TSPlib 的實例上表現得非常好，TSPlib 是 TSP 社群中的參考基準：它與最佳啟發式演算法 LKH3 的效能非常接近，甚至能夠在 TSPlib 定義的 1577 個和 3795 個城市的 2 個實例上獲得比 LKH3 更好的解。IDEQ 在由 500 個城市組成的 TSP 實例上獲得 0.3% 的最優解差距，在由 1000 個城市組成的 TSP 實例上獲得 0.5%。這為解決 TSP 的基於神經的方法設定了新的 SOTA。此外，IDEQ 表現出較低的變異性，並且在城市數量方面與 DIFUSCO 和 T2TCO 相比具有更好的擴充性。

##### **From approximation error to optimality gap -- Explaining the performance impact of opportunity cost approximation in integrated demand management and vehicle routing**
2412.13851v1 by David Fleckenstein, Robert Klein, Vienna Klein, Claudius Steinhardt

The widespread adoption of digital distribution channels both enables and
forces more and more logistical service providers to manage booking processes
actively to maintain competitiveness. As a result, their operational planning
is no longer limited to solving vehicle routing problems. Instead, demand
management decisions and vehicle routing decisions are optimized integratively
with the aim of maximizing revenue and minimizing fulfillment cost. The
resulting integrated demand management and vehicle routing problems (i-DMVRPs)
can be formulated as Markov decision process models and, theoretically, can be
solved via the well-known Bellman equation. Unfortunately, the Bellman equation
is intractable for realistic-sized instances. Thus, in the literature, i-DMVRPs
are often addressed via decomposition-based solution approaches involving an
opportunity cost approximation as a key component. Despite its importance, to
the best of our knowledge, there is neither a technique to systematically
analyze how the accuracy of the opportunity cost approximation translates into
overall solution quality nor are there general guidelines on when to apply
which class of approximation approach. In this work, we address this research
gap by proposing an explainability technique that quantifies and visualizes the
magnitude of approximation errors, their immediate impact, and their relevance
in specific regions of the state space. Exploiting reward decomposition, it
further yields a characterization of different types of approximation errors.
Applying the technique to a generic i-DMVRP in a full-factorial computational
study and comparing the results with observations in existing literature, we
show that the technique contributes to better explaining algorithmic
performance and provides guidance for the algorithm selection and development
process.

摘要：<paragraph>數位配送管道廣泛採用，促使且強迫越來越多的物流服務供應商積極管理預訂流程，以維持競爭力。因此，他們的營運規劃不再僅限於解決車輛路線問題。相反地，需求管理決策和車輛路線決策會整合最佳化，以最大化收益並最小化履行成本。由此產生的整合需求管理和車輛路線問題 (i-DMVRP) 可表述為馬可夫決策程序模型，理論上可透過著名的貝爾曼方程式求解。遺憾的是，貝爾曼方程式對於實際規模的個案來說難以處理。因此，在文獻中，i-DMVRP 通常透過基於分解的解決方案方法來解決，其中機會成本近似值是一個關鍵組成部分。儘管其重要性，但據我們所知，既沒有系統分析機會成本近似值準確度如何轉化為整體解決方案品質的技術，也沒有關於何時套用哪一類近似值方法的一般準則。在這項工作中，我們透過提出一個可量化並視覺化近似誤差大小、其立即影響及其在狀態空間特定區域中相關性的可解釋性技術，來解決這個研究差距。利用獎勵分解，它進一步對不同類型的近似誤差進行表徵。將此技術應用於全因子運算研究中的通用 i-DMVRP，並將結果與現有文獻中的觀察結果進行比較，我們表明該技術有助於更好地解釋演算法效能，並為演算法選擇和開發流程提供指導。</paragraph>

##### **A Concept-Centric Approach to Multi-Modality Learning**
2412.13847v1 by Yuchong Geng, Ao Tang

In an effort to create a more efficient AI system, we introduce a new
multi-modality learning framework that leverages a modality-agnostic concept
space possessing abstract knowledge and a set of modality-specific projection
models tailored to process distinct modality inputs and map them onto the
concept space. Decoupled from specific modalities and their associated
projection models, the concept space focuses on learning abstract knowledge
that is universally applicable across modalities. Subsequently, the knowledge
embedded into the concept space streamlines the learning processes of
modality-specific projection models. We evaluate our framework on two popular
tasks: Image-Text Matching and Visual Question Answering. Our framework
achieves performance on par with benchmark models while demonstrating more
efficient learning curves.

摘要：為了建立更有效率的人工智慧系統，我們提出一個新的多模態學習架構，它利用模態不可知概念空間，擁有抽象知識和一組針對處理不同模態輸入並將它們映射到概念空間而量身打造的模態特定投影模型。與特定模態及其關聯投影模型脫鉤後，概念空間專注於學習普遍適用於所有模態的抽象知識。隨後，嵌入到概念空間中的知識簡化了模態特定投影模型的學習過程。我們在兩個熱門任務中評估我們的架構：影像文字配對和視覺問答。我們的架構在與基準模型相當的效能上取得成功，同時展現出更有效率的學習曲線。

##### **From Expectation to Habit: Why Do Software Practitioners Adopt Fairness Toolkits?**
2412.13846v1 by Gianmario Voria, Stefano Lambiase, Maria Concetta Schiavone, Gemma Catolino, Fabio Palomba

As the adoption of machine learning (ML) systems continues to grow across
industries, concerns about fairness and bias in these systems have taken center
stage. Fairness toolkits, designed to mitigate bias in ML models, serve as
critical tools for addressing these ethical concerns. However, their adoption
in the context of software development remains underexplored, especially
regarding the cognitive and behavioral factors driving their usage. As a deeper
understanding of these factors could be pivotal in refining tool designs and
promoting broader adoption, this study investigates the factors influencing the
adoption of fairness toolkits from an individual perspective. Guided by the
Unified Theory of Acceptance and Use of Technology (UTAUT2), we examined the
factors shaping the intention to adopt and actual use of fairness toolkits.
Specifically, we employed Partial Least Squares Structural Equation Modeling
(PLS-SEM) to analyze data from a survey study involving practitioners in the
software industry. Our findings reveal that performance expectancy and habit
are the primary drivers of fairness toolkit adoption. These insights suggest
that by emphasizing the effectiveness of these tools in mitigating bias and
fostering habitual use, organizations can encourage wider adoption. Practical
recommendations include improving toolkit usability, integrating bias
mitigation processes into routine development workflows, and providing ongoing
support to ensure professionals see clear benefits from regular use.

摘要：隨著機器學習 (ML) 系統在各產業的採用持續增加，對於這些系統中的公平性和偏見的疑慮已成為關注焦點。公平性工具包旨在減輕 ML 模型中的偏見，作為解決這些道德疑慮的關鍵工具。然而，它們在軟體開發中的採用仍未被充分探討，特別是在驅動其使用行為的認知和行為因素方面。由於對這些因素更深入的了解對於改進工具設計和促進更廣泛的採用至關重要，本研究從個人角度探討影響公平性工具包採用的因素。在技術接受和使用統一理論 (UTAUT2) 的指導下，我們檢視了影響採用意願和實際使用公平性工具包的因素。具體來說，我們採用偏最小二乘結構方程模型 (PLS-SEM) 來分析軟體產業從業人員參與的調查研究資料。我們的發現顯示，績效預期和習慣是公平性工具包採用的主要驅動力。這些見解表明，透過強調這些工具在減輕偏見和促進習慣性使用的有效性，組織可以鼓勵更廣泛的採用。實務建議包括改善工具包的可用性、將偏見緩解程序整合到例行的開發工作流程中，以及提供持續支援，以確保專業人員了解定期使用的明顯好處。

##### **Do Language Models Understand Time?**
2412.13845v1 by Xi Ding, Lei Wang

Large language models (LLMs) have revolutionized video-based computer vision
applications, including action recognition, anomaly detection, and video
summarization. Videos inherently pose unique challenges, combining spatial
complexity with temporal dynamics that are absent in static images or textual
data. Current approaches to video understanding with LLMs often rely on
pretrained video encoders to extract spatiotemporal features and text encoders
to capture semantic meaning. These representations are integrated within LLM
frameworks, enabling multimodal reasoning across diverse video tasks. However,
the critical question persists: Can LLMs truly understand the concept of time,
and how effectively can they reason about temporal relationships in videos?
This work critically examines the role of LLMs in video processing, with a
specific focus on their temporal reasoning capabilities. We identify key
limitations in the interaction between LLMs and pretrained encoders, revealing
gaps in their ability to model long-term dependencies and abstract temporal
concepts such as causality and event progression. Furthermore, we analyze
challenges posed by existing video datasets, including biases, lack of temporal
annotations, and domain-specific limitations that constrain the temporal
understanding of LLMs. To address these gaps, we explore promising future
directions, including the co-evolution of LLMs and encoders, the development of
enriched datasets with explicit temporal labels, and innovative architectures
for integrating spatial, temporal, and semantic reasoning. By addressing these
challenges, we aim to advance the temporal comprehension of LLMs, unlocking
their full potential in video analysis and beyond.

摘要：大型語言模型 (LLM) 徹底改變了基於影片的電腦視覺應用，包括動作辨識、異常偵測和影片摘要。影片本身就具有獨特的挑戰，結合了空間複雜度和靜態影像或文字資料中沒有的時間動態。目前使用 LLM 了解影片的方法通常依賴於預先訓練好的影片編碼器來提取時空特徵，以及文字編碼器來擷取語義意義。這些表示整合在 LLM 架構中，可以在不同的影片任務中進行多模態推理。然而，一個關鍵問題仍然存在：LLM 是否真的能理解時間概念，以及它們在影片中推論時間關係的效率如何？這項研究批判性地探討了 LLM 在影片處理中的角色，特別關注它們的時間推理能力。我們找出 LLM 和預先訓練好的編碼器之間互動中的主要限制，揭示它們在建模長期依賴關係和抽象時間概念（例如因果關係和事件進程）方面的能力差距。此外，我們分析了現有影片資料集所帶來的挑戰，包括偏見、缺乏時間註解，以及限制 LLM 時間理解的特定領域限制。為了解決這些差距，我們探討了有希望的未來方向，包括 LLM 和編碼器的共同演化、開發具有明確時間標籤的豐富資料集，以及整合空間、時間和語義推理的創新架構。透過解決這些挑戰，我們旨在提升 LLM 的時間理解，發揮它們在影片分析及其他領域的全部潛力。

##### **CRM: Retrieval Model with Controllable Condition**
2412.13844v1 by Chi Liu, Jiangxia Cao, Rui Huang, Kuo Cai, Weifeng Ding, Qiang Luo, Kun Gai, Guorui Zhou

Recommendation systems (RecSys) are designed to connect users with relevant
items from a vast pool of candidates while aligning with the business goals of
the platform. A typical industrial RecSys is composed of two main stages,
retrieval and ranking: (1) the retrieval stage aims at searching hundreds of
item candidates satisfied user interests; (2) based on the retrieved items, the
ranking stage aims at selecting the best dozen items by multiple targets
estimation for each item candidate, including classification and regression
targets. Compared with ranking model, the retrieval model absence of item
candidate information during inference, therefore retrieval models are often
trained by classification target only (e.g., click-through rate), but failed to
incorporate regression target (e.g., the expected watch-time), which limit the
effectiveness of retrieval. In this paper, we propose the Controllable
Retrieval Model (CRM), which integrates regression information as conditional
features into the two-tower retrieval paradigm. This modification enables the
retrieval stage could fulfill the target gap with ranking model, enhancing the
retrieval model ability to search item candidates satisfied the user interests
and condition effectively. We validate the effectiveness of CRM through
real-world A/B testing and demonstrate its successful deployment in Kuaishou
short-video recommendation system, which serves over 400 million users.

摘要：推薦系統 (RecSys) 的設計目的是將使用者與來自龐大候選池中相關的項目連結起來，同時符合平台的商業目標。典型的產業用 RecSys 由兩個主要階段組成，檢索和排名：(1) 檢索階段的目的是搜尋數百個符合使用者興趣的項目候選；(2) 排名階段基於檢索到的項目，透過對每個項目候選進行多目標估計（包括分類和回歸目標）來選擇最佳的十幾項。與排名模型相比，檢索模型在推論期間缺少項目候選資訊，因此檢索模型通常僅透過分類目標（例如，點擊率）進行訓練，但無法納入回歸目標（例如，預期的觀看時間），這限制了檢索的有效性。在本文中，我們提出可控檢索模型 (CRM)，將回歸資訊作為條件特徵整合到兩塔式檢索範例中。此修改讓檢索階段能夠填補與排名模型的目標差距，加強檢索模型搜尋符合使用者興趣且條件有效的項目候選的能力。我們透過實際的 A/B 測試驗證 CRM 的有效性，並展示其在快手短影音推薦系統中的成功部署，該系統服務超過 4 億名使用者。

##### **AI Perceptions Across Cultures: Similarities and Differences in Expectations, Risks, Benefits, Tradeoffs, and Value in Germany and China**
2412.13841v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

As artificial intelligence (AI) continues to advance, understanding public
perceptions -- including biases, risks, and benefits -- is critical for guiding
research priorities, shaping public discourse, and informing policy. This study
explores public mental models of AI using micro scenarios to assess reactions
to 71 statements about AI's potential future impacts. Drawing on cross-cultural
samples from Germany (N=52) and China (N=60), we identify significant
differences in expectations, evaluations, and risk-utility tradeoffs. German
participants tended toward more cautious assessments, whereas Chinese
participants expressed greater optimism regarding AI's societal benefits.
Chinese participants exhibited relatively balanced risk-benefit tradeoffs
($\beta=-0.463$ for risk and $\beta=+0.484$ for benefit, $r^2=.630$). In
contrast, German participants showed a stronger emphasis on AI benefits and
less on risks ($\beta=-0.337$ for risk and $\beta=+0.715$ for benefit,
$r^2=.839$). Visual cognitive maps illustrate these contrasts, offering new
perspectives on how cultural contexts shape AI acceptance. Our findings
underline key factors influencing public perception and provide actionable
insights for fostering equitable and culturally sensitive integration of AI
technologies.

摘要：隨著人工智慧 (AI) 持續進步，了解大眾觀感（包括偏見、風險和好處）對於引導研究優先順序、塑造公共論述和制定政策至關重要。本研究使用微觀情境探討大眾對 AI 的心智模式，以評估對 71 項關於 AI 潛在未來影響的聲明的反應。根據來自德國 (N=52) 和中國 (N=60) 的跨文化樣本，我們發現期望、評估和風險效用權衡方面存在顯著差異。德國參與者傾向於更謹慎的評估，而中國參與者則對 AI 的社會效益表示出更大的樂觀。中國參與者表現出相對平衡的風險效益權衡（風險為 $\beta=-0.463$，效益為 $\beta=+0.484$，$r^2=.630$）。相比之下，德國參與者更強調 AI 的好處，而較少強調風險（風險為 $\beta=-0.337$，效益為 $\beta=+0.715$，$r^2=.839$）。視覺認知地圖說明了這些對比，提供了文化背景如何塑造 AI 接受度的新觀點。我們的研究結果強調了影響大眾觀感的關鍵因素，並為促進 AI 技術的公平且具有文化敏感性的整合提供了可行的見解。

##### **RACQUET: Unveiling the Dangers of Overlooked Referential Ambiguity in Visual LLMs**
2412.13835v1 by Alberto Testoni, Barbara Plank, Raquel Fernández

Ambiguity resolution is key to effective communication. While humans
effortlessly address ambiguity through conversational grounding strategies, the
extent to which current language models can emulate these strategies remains
unclear. In this work, we examine referential ambiguity in image-based question
answering by introducing RACQUET, a carefully curated dataset targeting
distinct aspects of ambiguity. Through a series of evaluations, we reveal
significant limitations and problems of overconfidence of state-of-the-art
large multimodal language models in addressing ambiguity in their responses.
The overconfidence issue becomes particularly relevant for RACQUET-BIAS, a
subset designed to analyze a critical yet underexplored problem: failing to
address ambiguity leads to stereotypical, socially biased responses. Our
results underscore the urgency of equipping models with robust strategies to
deal with uncertainty without resorting to undesirable stereotypes.

摘要：消除歧義是有效溝通的關鍵。雖然人類能透過對話基礎策略輕鬆解決歧義，但目前語言模型能模擬這些策略的程度仍不明確。在這項工作中，我們透過導入 RACQUET，一個針對歧義不同面向仔細策劃的資料集，來檢視基於影像的問題回答中的指涉歧義。透過一系列評估，我們揭露了最先進的多模態大型語言模型在回應中處理歧義時有顯著的限制和過度自信的問題。過度自信的問題對於 RACQUET-BIAS 來說特別相關，RACQUET-BIAS 是專門用來分析一個關鍵但未被充分探討的問題的子集：未能解決歧義會導致刻板印象和社會偏見的回應。我們的結果強調了讓模型具備強健策略以應對不確定性，且不訴諸於不良刻板印象的急迫性。

##### **Maybe you are looking for CroQS: Cross-modal Query Suggestion for Text-to-Image Retrieval**
2412.13834v1 by Giacomo Pacini, Fabio Carrara, Nicola Messina, Nicola Tonellotto, Giuseppe Amato, Fabrizio Falchi

Query suggestion, a technique widely adopted in information retrieval,
enhances system interactivity and the browsing experience of document
collections. In cross-modal retrieval, many works have focused on retrieving
relevant items from natural language queries, while few have explored query
suggestion solutions. In this work, we address query suggestion in cross-modal
retrieval, introducing a novel task that focuses on suggesting minimal textual
modifications needed to explore visually consistent subsets of the collection,
following the premise of ''Maybe you are looking for''. To facilitate the
evaluation and development of methods, we present a tailored benchmark named
CroQS. This dataset comprises initial queries, grouped result sets, and
human-defined suggested queries for each group. We establish dedicated metrics
to rigorously evaluate the performance of various methods on this task,
measuring representativeness, cluster specificity, and similarity of the
suggested queries to the original ones. Baseline methods from related fields,
such as image captioning and content summarization, are adapted for this task
to provide reference performance scores. Although relatively far from human
performance, our experiments reveal that both LLM-based and captioning-based
methods achieve competitive results on CroQS, improving the recall on cluster
specificity by more than 115% and representativeness mAP by more than 52% with
respect to the initial query. The dataset, the implementation of the baseline
methods and the notebooks containing our experiments are available here:
https://paciosoft.com/CroQS-benchmark/

摘要：查詢建議是一種在資訊檢索中廣泛採用的技術，它能提升系統互動性以及文件集的瀏覽體驗。在跨模態檢索中，許多作品專注於從自然語言查詢中檢索相關項目，但很少探討查詢建議的解決方案。在這項工作中，我們探討跨模態檢索中的查詢建議，並提出一個新的任務，專注於建議探索視覺上一致的子集所需的最小文字修改，遵循「也許您正在尋找」的前提。為了促進方法的評估和開發，我們提出了名為 CroQS 的客製化基準測試。此資料集包含初始查詢、分組結果集，以及每組由人定義的建議查詢。我們建立專門的指標來嚴格評估各種方法在這個任務上的效能，衡量建議查詢的代表性、群集特異性，以及與原始查詢的相似性。我們將相關領域的基準方法，例如影像標題和內容摘要，改編為此任務，以提供參考效能分數。儘管與人類效能相去甚遠，但我們的實驗顯示，LLM 為基礎的方法和標題為基礎的方法在 CroQS 上都取得了有競爭力的結果，將群集特異性的召回率提高了 115% 以上，將代表性的 mAP 提高了 52% 以上，相對於初始查詢而言。資料集、基準方法的實作，以及包含我們實驗的筆記本電腦都可以在這裡取得：https://paciosoft.com/CroQS-benchmark/

##### **Heterogeneous Graph Collaborative Filtering**
2412.13825v1 by Lianghao Xia, Meiyan Xie, Yong Xu, Chao Huang

For modern recommender systems, the use of low-dimensional latent
representations to embed users and items based on their observed interactions
has become commonplace. However, many existing recommendation models are
primarily designed for coarse-grained and homogeneous interactions, which
limits their effectiveness in two critical dimensions. Firstly, these models
fail to leverage the relational dependencies that exist across different types
of user behaviors, such as page views, collects, comments, and purchases.
Secondly, they struggle to capture the fine-grained latent factors that drive
user interaction patterns. To address these limitations, we present a
heterogeneous graph collaborative filtering model MixRec that excels at
disentangling users' multi-behavior interaction patterns and uncovering the
latent intent factors behind each behavior. Our model achieves this by
incorporating intent disentanglement and multi-behavior modeling, facilitated
by a parameterized heterogeneous hypergraph architecture. Furthermore, we
introduce a novel contrastive learning paradigm that adaptively explores the
advantages of self-supervised data augmentation, thereby enhancing the model's
resilience against data sparsity and expressiveness with relation
heterogeneity. To validate the efficacy of MixRec, we conducted extensive
experiments on three public datasets. The results clearly demonstrate its
superior performance, significantly outperforming various state-of-the-art
baselines. Our model is open-sourced and available at:
https://github.com/HKUDS/MixRec.

摘要：對於現代推薦系統來說，使用低維潛在表示來嵌入使用者和項目，根據他們觀察到的互動已變得司空見慣。然而，許多現有的推薦模型主要是為粗粒度和同質互動而設計的，這限制了它們在兩個關鍵維度上的有效性。首先，這些模型未能利用不同類型使用者行為之間存在的關係依賴性，例如頁面瀏覽、收藏、評論和購買。其次，它們難以捕捉驅動使用者互動模式的細粒度潛在因素。為了解決這些限制，我們提出了一個異質圖協作過濾模型 MixRec，它擅長解開使用者的多行為互動模式，並揭示每種行為背後的潛在意圖因素。我們的模型通過結合意圖解開和多行為建模來實現這一點，並由參數化異質超圖架構促進。此外，我們引入了一個新的對比學習範例，自適應地探索自監督數據增強的優點，從而增強模型對數據稀疏性和異質性關係的表達能力。為了驗證 MixRec 的功效，我們對三個公開數據集進行了廣泛的實驗。結果清楚地證明了它的優異性能，顯著優於各種最先進的基線。我們的模型是開源的，可以在以下位置獲得：https://github.com/HKUDS/MixRec。

##### **CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers?**
2412.13810v1 by Dimitrios Mallis, Ahmet Serdar Karadeniz, Sebastian Cavada, Danila Rukhovich, Niki Foteinopoulou, Kseniya Cherenkova, Anis Kacem, Djamila Aouada

We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design.
Our approach is based on a powerful Vision and Large Language Model (VLLM) as a
planner and a tool-augmentation paradigm using CAD-specific modules.
CAD-Assistant addresses multimodal user queries by generating actions that are
iteratively executed on a Python interpreter equipped with the FreeCAD
software, accessed via its Python API. Our framework is able to assess the
impact of generated CAD commands on geometry and adapts subsequent actions
based on the evolving state of the CAD design. We consider a wide range of
CAD-specific tools including Python libraries, modules of the FreeCAD Python
API, helpful routines, rendering functions and other specialized modules. We
evaluate our method on multiple CAD benchmarks and qualitatively demonstrate
the potential of tool-augmented VLLMs as generic CAD task solvers across
diverse CAD workflows.

摘要：我們提出 CAD-Assistant，一個用於 AI 輔助設計的通用 CAD 代理。
我們的做法基於強大的 Vision 和大型語言模型 (VLLM) 作為規劃器，以及使用 CAD 特定模組的工具擴充範例。
CAD-Assistant 透過產生在配備 FreeCAD 軟體的 Python 詮釋器上反覆執行的動作，來處理多模式使用者查詢，並透過其 Python API 存取。我們的架構能夠評估產生的 CAD 指令對幾何的影響，並根據 CAD 設計的演化狀態調整後續動作。我們考慮了廣泛的 CAD 特定工具，包括 Python 函式庫、FreeCAD Python API 的模組、有用的常式、渲染函式和其他專門模組。我們在多個 CAD 基準上評估我們的做法，並定性地展示了工具擴充 VLLM 作為通用 CAD 任務解決器的潛力，涵蓋了各種 CAD 工作流程。

##### **M$^3$-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation**
2412.13803v1 by Zixuan Chen, Jiaxin Li, Liming Tan, Yejie Guo, Junxuan Liang, Cewu Lu, Yonglu Li

Intelligent robots need to interact with diverse objects across various
environments. The appearance and state of objects frequently undergo complex
transformations depending on the object properties, e.g., phase transitions.
However, in the vision community, segmenting dynamic objects with phase
transitions is overlooked. In light of this, we introduce the concept of phase
in segmentation, which categorizes real-world objects based on their visual
characteristics and potential morphological and appearance changes. Then, we
present a new benchmark, Multi-Phase, Multi-Transition, and Multi-Scenery Video
Object Segmentation (M3-VOS), to verify the ability of models to understand
object phases, which consists of 479 high-resolution videos spanning over 10
distinct everyday scenarios. It provides dense instance mask annotations that
capture both object phases and their transitions. We evaluate state-of-the-art
methods on M3-VOS, yielding several key insights. Notably, current appearance
based approaches show significant room for improvement when handling objects
with phase transitions. The inherent changes in disorder suggest that the
predictive performance of the forward entropy-increasing process can be
improved through a reverse entropy-reducing process. These findings lead us to
propose ReVOS, a new plug-and-play model that improves its performance by
reversal refinement. Our data and code will be publicly available

摘要：智慧型機器人需要與不同環境中的各種物件互動。物件的外觀和狀態會根據物件屬性頻繁地進行複雜的轉換，例如相變。然而，在視覺社群中，會忽略分割具有相變的動態物件。有鑑於此，我們在分割中引入了相的概念，它根據真實世界物件的視覺特徵和潛在的形態和外觀變化對物件進行分類。然後，我們提出了新的基準，多相、多轉換和多場景影片物件分割 (M3-VOS)，以驗證模型了解物件相的能力，它包含 479 個高解析度影片，涵蓋超過 10 個不同的日常場景。它提供密集的實例遮罩註解，用於擷取物件相及其轉換。我們在 M3-VOS 上評估了最先進的方法，產生了幾個關鍵見解。值得注意的是，當處理具有相變的物件時，當前的基於外觀的方法顯示出顯著的改進空間。無序的內在變化表明，向前熵增加過程的預測效能可透過反向熵減少過程來改善。這些發現讓我們提出 ReVOS，這是一種新的即插即用模型，它透過反向精緻化來改善效能。我們的資料和程式碼將公開提供

##### **Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application with RAG Integration**
2412.13799v1 by Ramona Kühn, Jelena Mitrović, Michael Granitzer

Rhetorical figures play an important role in our communication. They are used
to convey subtle, implicit meaning, or to emphasize statements. We notice them
in hate speech, fake news, and propaganda. By improving the systems for
computational detection of rhetorical figures, we can also improve tasks such
as hate speech and fake news detection, sentiment analysis, opinion mining, or
argument mining. Unfortunately, there is a lack of annotated data, as well as
qualified annotators that would help us build large corpora to train machine
learning models for the detection of rhetorical figures. The situation is
particularly difficult in languages other than English, and for rhetorical
figures other than metaphor, sarcasm, and irony. To overcome this issue, we
develop a web application called "Find your Figure" that facilitates the
identification and annotation of German rhetorical figures. The application is
based on the German Rhetorical ontology GRhOOT which we have specially adapted
for this purpose. In addition, we improve the user experience with Retrieval
Augmented Generation (RAG). In this paper, we present the restructuring of the
ontology, the development of the web application, and the built-in RAG
pipeline. We also identify the optimal RAG settings for our application. Our
approach is one of the first to practically use rhetorical ontologies in
combination with RAG and shows promising results.

摘要：修辭手法在我們的溝通中扮演著重要的角色。它們被用來傳達微妙的、隱含的意思，或強調陳述。我們在仇恨言論、假新聞和宣傳中注意到它們。透過改善修辭手法的計算檢測系統，我們也可以改善仇恨言論和假新聞檢測、情緒分析、意見探勘或論證探勘等任務。不幸的是，缺乏註解資料，以及合格的註解員，這會讓我們難以建立大型語料庫來訓練機器學習模型以檢測修辭手法。在英語以外的語言中，以及對於隱喻、諷刺和反諷以外的修辭手法來說，情況特別困難。為了克服這個問題，我們開發了一個稱為「尋找你的手法」的網路應用程式，它有助於識別和註解德語修辭手法。該應用程式基於 German Rhetorical ontology GRhOOT，我們已特別調整其用途。此外，我們使用檢索擴充產生 (RAG) 來改善使用者體驗。在本文中，我們說明了本体的重組、網路應用程式的開發和內建的 RAG 管線。我們也找出我們應用程式的最佳 RAG 設定。我們的做法是首批實際將修辭本体與 RAG 結合使用的做法之一，並顯示出有希望的結果。

##### **Mix-LN: Unleashing the Power of Deeper Layers by Combining Pre-LN and Post-LN**
2412.13795v1 by Pengxiang Li, Lu Yin, Shiwei Liu

Large Language Models (LLMs) have achieved remarkable success, yet recent
findings reveal that their deeper layers often contribute minimally and can be
pruned without affecting overall performance. While some view this as an
opportunity for model compression, we identify it as a training shortfall
rooted in the widespread use of Pre-Layer Normalization (Pre-LN). We
demonstrate that Pre-LN, commonly employed in models like GPT and LLaMA, leads
to diminished gradient norms in its deeper layers, reducing their
effectiveness. In contrast, Post-Layer Normalization (Post-LN) preserves larger
gradient norms in deeper layers but suffers from vanishing gradients in earlier
layers. To address this, we introduce Mix-LN, a novel normalization technique
that combines the strengths of Pre-LN and Post-LN within the same model. Mix-LN
applies Post-LN to the earlier layers and Pre-LN to the deeper layers, ensuring
more uniform gradients across layers. This allows all parts of the
network--both shallow and deep layers--to contribute effectively to training.
Extensive experiments with various model sizes from 70M to 7B demonstrate that
Mix-LN consistently outperforms both Pre-LN and Post-LN, promoting more
balanced, healthier gradient norms throughout the network, and enhancing the
overall quality of LLM pre-training. Furthermore, we demonstrate that models
pre-trained with Mix-LN learn better compared to those using Pre-LN or Post-LN
during supervised fine-tuning (SFT) and reinforcement learning from human
feedback (RLHF), highlighting the critical importance of high-quality deep
layers. By effectively addressing the inefficiencies of deep layers in current
LLMs, Mix-LN unlocks their potential, enhancing model capacity without
increasing model size. Our code is available at
https://github.com/pixeli99/MixLN.

摘要：大型語言模型 (LLM) 已取得顯著成功，但最近的研究發現，它們較深的層級通常只做出極小的貢獻，而且可以修剪而不會影響整體效能。雖然有些人將此視為模型壓縮的機會，但我們認為這是訓練不足，根源於廣泛使用預層標準化 (Pre-LN)。我們證明了預層標準化（通常用於 GPT 和 LLaMA 等模型）導致其較深層級的梯度範數減小，降低了它們的效能。相比之下，後層標準化 (Post-LN) 在較深層級保留了較大的梯度範數，但較早層級的梯度會消失。為了解決這個問題，我們引入了 Mix-LN，這是一種新穎的標準化技術，結合了預層標準化和後層標準化的優點於同一個模型中。Mix-LN 將後層標準化應用於較早層級，將預層標準化應用於較深層級，確保所有層級的梯度更加均勻。這讓網路的所有部分（淺層和深層）都能有效地為訓練做出貢獻。使用從 70M 到 7B 的各種模型規模進行的大量實驗證明，Mix-LN 持續優於預層標準化和後層標準化，在整個網路中促進了更平衡、更健康的梯度範數，並提升了 LLM 預訓練的整體品質。此外，我們證明了使用 Mix-LN 預訓練的模型在監督微調 (SFT) 和人類回饋強化學習 (RLHF) 期間，與使用預層標準化或後層標準化的模型相比，學習效果更好，突顯了高品質深層級的重要性。透過有效解決當前 LLM 中深層級的低效率，Mix-LN 釋放了它們的潛力，在不增加模型規模的情況下提升了模型容量。我們的程式碼可在 https://github.com/pixeli99/MixLN 取得。

##### **MATCHED: Multimodal Authorship-Attribution To Combat Human Trafficking in Escort-Advertisement Data**
2412.13794v1 by Vageesh Saxena, Benjamin Bashpole, Gijs Van Dijck, Gerasimos Spanakis

Human trafficking (HT) remains a critical issue, with traffickers
increasingly leveraging online escort advertisements (ads) to advertise victims
anonymously. Existing detection methods, including Authorship Attribution (AA),
often center on text-based analyses and neglect the multimodal nature of online
escort ads, which typically pair text with images. To address this gap, we
introduce MATCHED, a multimodal dataset of 27,619 unique text descriptions and
55,115 unique images collected from the Backpage escort platform across seven
U.S. cities in four geographical regions. Our study extensively benchmarks
text-only, vision-only, and multimodal baselines for vendor identification and
verification tasks, employing multitask (joint) training objectives that
achieve superior classification and retrieval performance on in-distribution
and out-of-distribution (OOD) datasets. Integrating multimodal features further
enhances this performance, capturing complementary patterns across text and
images. While text remains the dominant modality, visual data adds stylistic
cues that enrich model performance. Moreover, text-image alignment strategies
like CLIP and BLIP2 struggle due to low semantic overlap and vague connections
between the modalities of escort ads, with end-to-end multimodal training
proving more robust. Our findings emphasize the potential of multimodal AA
(MAA) to combat HT, providing LEAs with robust tools to link ads and disrupt
trafficking networks.

摘要：人口販運 (HT) 仍然是一個關鍵問題，販運者越來越利用線上應召廣告 (ad) 來匿名宣傳受害者。現有的偵測方法，包括作者歸因 (AA)，通常集中在基於文字的分析，而忽略線上應召廣告的多模態性質，而這通常會將文字與圖片配對。為了解決這個差距，我們引入了 MATCHED，一個多模態資料集，包含從美國七個城市在四個地理區域的 Backpage 應召平台收集的 27,619 個獨特文字描述和 55,115 個獨特圖片。我們的研究廣泛地比較了僅文字、僅視覺和多模態的基準，用於供應商識別和驗證任務，採用多任務 (聯合) 訓練目標，在分佈內和分佈外 (OOD) 資料集上獲得優異的分類和檢索效能。整合多模態特徵進一步增強了此效能，捕捉文字和圖片中的互補模式。儘管文字仍然是主要的模態，但視覺資料增加了豐富模型效能的風格線索。此外，由於應召廣告的模態之間的語義重疊低且關聯模糊，因此 CLIP 和 BLIP2 等文字影像對齊策略難以發揮作用，而端到端的多模態訓練則證明更為穩健。我們的研究結果強調了多模態 AA (MAA) 打擊 HT 的潛力，為執法機構 (LEA) 提供了強大的工具來連結廣告並瓦解販運網路。

##### **Physics Reasoner: Knowledge-Augmented Reasoning for Solving Physics Problems with Large Language Models**
2412.13791v1 by Xinyu Pang, Ruixin Hong, Zhanke Zhou, Fangrui Lv, Xinwei Yang, Zhilong Liang, Bo Han, Changshui Zhang

Physics problems constitute a significant aspect of reasoning, necessitating
complicated reasoning ability and abundant physics knowledge. However, existing
large language models (LLMs) frequently fail due to a lack of knowledge or
incorrect knowledge application. To mitigate these issues, we propose Physics
Reasoner, a knowledge-augmented framework to solve physics problems with LLMs.
Specifically, the proposed framework constructs a comprehensive formula set to
provide explicit physics knowledge and utilizes checklists containing detailed
instructions to guide effective knowledge application. Namely, given a physics
problem, Physics Reasoner solves it through three stages: problem analysis,
formula retrieval, and guided reasoning. During the process, checklists are
employed to enhance LLMs' self-improvement in the analysis and reasoning
stages. Empirically, Physics Reasoner mitigates the issues of insufficient
knowledge and incorrect application, achieving state-of-the-art performance on
SciBench with an average accuracy improvement of 5.8%.

摘要：物理學題目構成推理的重要面向，需要複雜的推理能力和豐富的物理知識。然而，現有的大型語言模型 (LLM) 經常因為缺乏知識或不正確地應用知識而失敗。為了減輕這些問題，我們提出物理推理器，一個知識增強框架，用 LLM 解決物理問題。具體來說，所提出的框架建構了一個全面的公式集，以提供明確的物理知識，並利用包含詳細說明的檢查清單來指導有效的知識應用。也就是說，給定一個物理問題，物理推理器透過三個階段來解決它：問題分析、公式檢索和引導推理。在過程中，使用檢查清單來增強 LLM 在分析和推理階段的自我改進。根據經驗，物理推理器減輕了知識不足和應用不正確的問題，在 SciBench 上實現了最先進的效能，平均準確度提高了 5.8%。

##### **Open Universal Arabic ASR Leaderboard**
2412.13788v1 by Yingzhi Wang, Anas Alhmoud, Muhammad Alqurishi

In recent years, the enhanced capabilities of ASR models and the emergence of
multi-dialect datasets have increasingly pushed Arabic ASR model development
toward an all-dialect-in-one direction. This trend highlights the need for
benchmarking studies that evaluate model performance on multiple dialects,
providing the community with insights into models' generalization capabilities.
  In this paper, we introduce Open Universal Arabic ASR Leaderboard, a
continuous benchmark project for open-source general Arabic ASR models across
various multi-dialect datasets. We also provide a comprehensive analysis of the
model's robustness, speaker adaptation, inference efficiency, and memory
consumption. This work aims to offer the Arabic ASR community a reference for
models' general performance and also establish a common evaluation framework
for multi-dialectal Arabic ASR models.

摘要：近年來，ASR 模型功能的增強和多方言資料集的出現，促使阿拉伯語 ASR 模型開發朝向全方言合一的趨勢。這種趨勢突顯了對基準研究的需求，該研究評估模型在多種方言上的效能，為社群提供對模型概化能力的見解。在本文中，我們介紹開放式通用阿拉伯語 ASR 排行榜，這是一個跨各種多方言資料集的開源通用阿拉伯語 ASR 模型的持續基準測試專案。我們還提供了模型穩健性、說話者適應性、推論效率和記憶體消耗的全面分析。這項工作旨在為阿拉伯語 ASR 社群提供模型一般效能的參考，並為多方言阿拉伯語 ASR 模型建立一個通用的評估架構。

##### **Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question Answering**
2412.13782v1 by Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang

Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.

摘要：多跳問題回答 (MHQA) 由於涉及廣泛的知識需求，對大型語言模型 (LLM) 構成重大挑戰。知識編輯旨在精確修改 LLM 以納入特定知識，而不會對其他不相關的知識產生負面影響，為了解決 LLM 的 MHQA 挑戰提供了潛在的解決方案。然而，目前的解決方案難以有效解決知識衝突的問題。大多數參數保留編輯方法受到不準確檢索的阻礙，並且忽視了次要編輯問題，這可能會在 LLM 的推理過程中引入雜訊。在本文中，我們介紹了 KEDKG，這是一種新穎的知識編輯方法，它利用動態知識圖譜進行 MHQA，旨在確保答案的可靠性。KEDKG 涉及兩個主要步驟：動態知識圖譜構建和知識圖譜增強生成。最初，KEDKG 自主構建動態知識圖譜以儲存修改後的資訊，同時解決潛在的知識衝突。隨後，它採用精細的檢索策略，結合實體和關係檢測器，以增強 LLM 生成的圖譜檢索的準確性。基準上的實驗結果表明，KEDKG 超越了以前最先進的模型，在動態資訊環境中提供了更準確和可靠的答案。

##### **Meta-Reflection: A Feedback-Free Reflection Learning Framework**
2412.13781v1 by Yaoke Wang, Yun Zhu, Xintong Bao, Wenqiao Zhang, Suyang Dai, Kehan Chen, Wenqiang Li, Gang Huang, Siliang Tang, Yueting Zhuang

Despite the remarkable capabilities of large language models (LLMs) in
natural language understanding and reasoning, they often display undesirable
behaviors, such as generating hallucinations and unfaithful reasoning. A
prevalent strategy to mitigate these issues is the use of reflection, which
refines responses through an iterative process. However, while promising,
reflection heavily relies on high-quality external feedback and requires
iterative multi-agent inference processes, thus hindering its practical
application. In this paper, we propose Meta-Reflection, a novel feedback-free
reflection mechanism that necessitates only a single inference pass without
external feedback. Motivated by the human ability to remember and retrieve
reflections from past experiences when encountering similar problems,
Meta-Reflection integrates reflective insights into a codebook, allowing the
historical insights to be stored, retrieved, and used to guide LLMs in
problem-solving. To thoroughly investigate and evaluate the practicality of
Meta-Reflection in real-world scenarios, we introduce an industrial e-commerce
benchmark named E-commerce Customer Intent Detection (ECID). Extensive
experiments conducted on both public datasets and the ECID benchmark highlight
the effectiveness and efficiency of our proposed approach.

摘要：儘管大型語言模型 (LLM) 在自然語言理解和推理方面具有非凡的能力，但它們常常表現出不良行為，例如產生幻覺和不忠實的推理。減輕這些問題的一種普遍策略是使用反思，它通過反覆運算的過程來改善回應。然而，雖然有希望，但反思嚴重依賴於高品質的外部回饋，並且需要反覆的多代理推理過程，從而阻礙了其實際應用。在本文中，我們提出了元反思，這是一種新穎的無回饋反思機制，只需要單一推理過程，而無需外部回饋。受人類在遇到類似問題時記住並從過去經驗中提取反思的能力的啟發，元反思將反思見解整合到一個密碼本中，允許儲存、檢索和使用歷史見解來指導 LLM 解決問題。為了徹底調查和評估元反思在實際場景中的實用性，我們引入了一個名為電子商務客戶意圖檢測 (ECID) 的產業電子商務基準。在公共數據集和 ECID 基準上進行的廣泛實驗突出了我們提出的方法的有效性和效率。

##### **Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization**
2412.13771v1 by Guanghan Li, Xun Zhang, Yufei Zhang, Yifan Yin, Guojun Yin, Wei Lin

Large language models (LLMs), endowed with exceptional reasoning
capabilities, are adept at discerning profound user interests from historical
behaviors, thereby presenting a promising avenue for the advancement of
recommendation systems. However, a notable discrepancy persists between the
sparse collaborative semantics typically found in recommendation systems and
the dense token representations within LLMs. In our study, we propose a novel
framework that harmoniously merges traditional recommendation models with the
prowess of LLMs. We initiate this integration by transforming ItemIDs into
sequences that align semantically with the LLMs space, through the proposed
Alignment Tokenization module. Additionally, we design a series of specialized
supervised learning tasks aimed at aligning collaborative signals with the
subtleties of natural language semantics. To ensure practical applicability, we
optimize online inference by pre-caching the top-K results for each user,
reducing latency and improving effciency. Extensive experimental evidence
indicates that our model markedly improves recall metrics and displays
remarkable scalability of recommendation systems.

摘要：大型語言模型 (LLM) 擁有卓越的推理能力，擅長從歷史行為中辨識出深刻的使用者興趣，因此為推薦系統的進步提供了一條有前途的途徑。然而，推薦系統中通常發現的稀疏協作語義與 LLM 中的密集標記表示之間存在明顯的差異。在我們的研究中，我們提出了一個新的框架，將傳統的推薦模型與 LLM 的優勢和諧地結合起來。我們通過建議的對齊標記化模組，將 ItemID 轉換成在語義上與 LLM 空間對齊的序列，來啟動此整合。此外，我們設計了一系列專門的監督式學習任務，旨在將協作訊號與自然語言語義的細微差別對齊。為了確保實際應用性，我們透過預先快取每個使用者的前 K 個結果來最佳化線上推論，進而減少延遲並提高效率。廣泛的實驗證據表明，我們的模型顯著改善了召回指標，並展現出推薦系統的顯著可擴充性。

##### **QuLTSF: Long-Term Time Series Forecasting with Quantum Machine Learning**
2412.13769v1 by Hari Hara Suthan Chittoor, Paul Robert Griffin, Ariel Neufeld, Jayne Thompson, Mile Gu

Long-term time series forecasting (LTSF) involves predicting a large number
of future values of a time series based on the past values and is an essential
task in a wide range of domains including weather forecasting, stock market
analysis, disease outbreak prediction. Over the decades LTSF algorithms have
transitioned from statistical models to deep learning models like transformer
models. Despite the complex architecture of transformer based LTSF models `Are
Transformers Effective for Time Series Forecasting? (Zeng et al., 2023)' showed
that simple linear models can outperform the state-of-the-art transformer based
LTSF models. Recently, quantum machine learning (QML) is evolving as a domain
to enhance the capabilities of classical machine learning models. In this paper
we initiate the application of QML to LTSF problems by proposing QuLTSF, a
simple hybrid QML model for multivariate LTSF. Through extensive experiments on
a widely used weather dataset we show the advantages of QuLTSF over the
state-of-the-art classical linear models, in terms of reduced mean squared
error and mean absolute error.

摘要：長期時間序列預測 (LTSF) 涉及根據過去值預測時間序列的大量未來值，並且是天氣預報、股票市場分析、疾病爆發預測等廣泛領域中的一項基本任務。數十年來，LTSF 演算法已從統計模型轉變為Transformer模型等深度學習模型。儘管基於Transformer的 LTSF 模型架構複雜，但「Transformer對時間序列預測有效嗎？」（曾等人，2023 年）一文顯示，簡單的線性模型可以優於最先進的基於Transformer的 LTSF 模型。最近，量子機器學習 (QML) 正作為一個領域發展，以增強經典機器學習模型的能力。在本文中，我們透過提出 QuLTSF（一種用於多變量 LTSF 的簡單混合 QML 模型），啟動了 QML 在 LTSF 問題中的應用。透過在廣泛使用的天氣資料集上進行大量實驗，我們展示了 QuLTSF 在減少均方誤差和平均絕對誤差方面優於最先進的經典線性模型。

##### **LLM-SEM: A Sentiment-Based Student Engagement Metric Using LLMS for E-Learning Platforms**
2412.13765v1 by Ali Hamdi, Ahmed Abdelmoneim Mazrou, Mohamed Shaltout

Current methods for analyzing student engagement in e-learning platforms,
including automated systems, often struggle with challenges such as handling
fuzzy sentiment in text comments and relying on limited metadata. Traditional
approaches, such as surveys and questionnaires, also face issues like small
sample sizes and scalability. In this paper, we introduce LLM-SEM (Language
Model-Based Student Engagement Metric), a novel approach that leverages video
metadata and sentiment analysis of student comments to measure engagement. By
utilizing recent Large Language Models (LLMs), we generate high-quality
sentiment predictions to mitigate text fuzziness and normalize key features
such as views and likes. Our holistic method combines comprehensive metadata
with sentiment polarity scores to gauge engagement at both the course and
lesson levels. Extensive experiments were conducted to evaluate various LLM
models, demonstrating the effectiveness of LLM-SEM in providing a scalable and
accurate measure of student engagement. We fine-tuned LLMs, including AraBERT,
TXLM-RoBERTa, LLama 3B and Gemma 9B from Ollama, using human-annotated
sentiment datasets to enhance prediction accuracy.

摘要：目前用於分析學生在電子學習平台中參與度的現有方法，包括自動化系統，通常會在處理文字評論中的模糊情感和依賴有限元資料時面臨挑戰。傳統方法，例如調查和問卷，也面臨樣本量小和可擴充性等問題。在本文中，我們介紹了 LLM-SEM（基於語言模型的學生參與度量數），這是一種新方法，它利用影片元資料和學生評論的情感分析來衡量參與度。通過利用最近的大語言模型 (LLM)，我們產生了高品質的情感預測，以減輕文字模糊性並標準化觀看次數和按讚數等關鍵功能。我們的整體方法結合了全面的元資料和情緒極性分數，以評估課程和課程層級的參與度。我們進行了大量實驗來評估各種 LLM 模型，證明了 LLM-SEM 在提供可擴充且準確的學生參與度測量方面的有效性。我們微調了 LLM，包括 AraBERT、TXLM-RoBERTa、來自 Ollama 的 LLama 3B 和 Gemma 9B，使用人工標記的情感資料集來提高預測準確度。

##### **RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented Generation for Preference Alignment**
2412.13746v1 by Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

Despite the significant progress made by existing retrieval augmented
language models (RALMs) in providing trustworthy responses and grounding in
reliable sources, they often overlook effective alignment with human
preferences. In the alignment process, reward models (RMs) act as a crucial
proxy for human values to guide optimization. However, it remains unclear how
to evaluate and select a reliable RM for preference alignment in RALMs. To this
end, we propose RAG-RewardBench, the first benchmark for evaluating RMs in RAG
settings. First, we design four crucial and challenging RAG-specific scenarios
to assess RMs, including multi-hop reasoning, fine-grained citation,
appropriate abstain, and conflict robustness. Then, we incorporate 18 RAG
subsets, six retrievers, and 24 RALMs to increase the diversity of data
sources. Finally, we adopt an LLM-as-a-judge approach to improve preference
annotation efficiency and effectiveness, exhibiting a strong correlation with
human annotations. Based on the RAG-RewardBench, we conduct a comprehensive
evaluation of 45 RMs and uncover their limitations in RAG scenarios.
Additionally, we also reveal that existing trained RALMs show almost no
improvement in preference alignment, highlighting the need for a shift towards
preference-aligned training.We release our benchmark and code publicly at
https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ for future work.

摘要：儘管現有的檢索增強語言模型 (RALM) 在提供可信賴的回應和依據可信賴的來源方面取得重大進展，但它們往往忽略與人類偏好進行有效的對齊。在對齊過程中，獎勵模型 (RM) 作為人類價值觀的關鍵代理，用於引導最佳化。然而，如何評估和選擇一個可靠的 RM 以用於 RALM 中的偏好對齊，目前仍不清楚。為此，我們提出 RAG-RewardBench，這是評估 RAG 設定中 RM 的第一個基準。首先，我們設計四個關鍵且具有挑戰性的 RAG 特定場景來評估 RM，包括多跳推理、細粒度引文、適當的棄權和衝突穩健性。然後，我們納入 18 個 RAG 子集、六個檢索器和 24 個 RALM，以增加數據來源的多樣性。最後，我們採用 LLM 作為評判者方法來提高偏好標註的效率和有效性，並表現出與人類標註的強相關性。根據 RAG-RewardBench，我們對 45 個 RM 進行了全面的評估，並揭示了它們在 RAG 場景中的局限性。此外，我們還揭示現有的已訓練 RALM 在偏好對齊方面幾乎沒有改進，這凸顯了需要轉向偏好對齊訓練。我們在 https://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ 上公開發布我們的基準和代碼，供將來的工作使用。

##### **Learning Complex Word Embeddings in Classical and Quantum Spaces**
2412.13745v1 by Carys Harvey, Stephen Clark, Douglas Brown, Konstantinos Meichanetzidis

We present a variety of methods for training complex-valued word embeddings,
based on the classical Skip-gram model, with a straightforward adaptation
simply replacing the real-valued vectors with arbitrary vectors of complex
numbers. In a more "physically-inspired" approach, the vectors are produced by
parameterised quantum circuits (PQCs), which are unitary transformations
resulting in normalised vectors which have a probabilistic interpretation. We
develop a complex-valued version of the highly optimised C code version of
Skip-gram, which allows us to easily produce complex embeddings trained on a
3.8B-word corpus for a vocabulary size of over 400k, for which we are then able
to train a separate PQC for each word. We evaluate the complex embeddings on a
set of standard similarity and relatedness datasets, for some models obtaining
results competitive with the classical baseline. We find that, while training
the PQCs directly tends to harm performance, the quantum word embeddings from
the two-stage process perform as well as the classical Skip-gram embeddings
with comparable numbers of parameters. This enables a highly scalable route to
learning embeddings in complex spaces which scales with the size of the
vocabulary rather than the size of the training corpus. In summary, we
demonstrate how to produce a large set of high-quality word embeddings for use
in complex-valued and quantum-inspired NLP models, and for exploring potential
advantage in quantum NLP models.

摘要：我們提出了多種訓練複數值詞嵌入的方法，
基於經典的 Skip-gram 模型，透過直接替換實值向量為複數的任意向量，進行簡單的調整。在更「物理靈感」的方法中，向量是由參數化的量子電路 (PQC) 所產生，這是單元轉換，會產生具有機率詮釋的正規化向量。我們開發了 Skip-gram 的高度最佳化 C 程式碼版本的複數值版本，讓我們可以輕鬆產生在超過 40 萬個單字的詞彙量中，訓練於 3.8B 字語料庫的複數嵌入，我們接著可以為每個單字訓練一個獨立的 PQC。我們在標準相似性和相關性資料集上評估複數嵌入，對於某些模型，我們取得了與經典基準相競爭的結果。我們發現，雖然直接訓練 PQC 傾向於損害效能，但來自兩階段程序的量子詞嵌入，在具有可比較的參數數量時，效能與經典 Skip-gram 嵌入一樣好。這提供了一個高度可擴充的途徑，可以在複數空間中學習嵌入，其規模會隨著詞彙量的大小而擴充，而不是訓練語料庫的大小。總之，我們展示了如何產生一大組高品質的詞嵌入，以供在複數值和量子靈感 NLP 模型中使用，並探索量子 NLP 模型中的潛在優勢。

##### **Uncertainty separation via ensemble quantile regression**
2412.13738v1 by Navid Ansari, Hans-Peter Seidel, Vahid Babaei

This paper introduces a novel and scalable framework for uncertainty
estimation and separation with applications in data driven modeling in science
and engineering tasks where reliable uncertainty quantification is critical.
Leveraging an ensemble of quantile regression (E-QR) models, our approach
enhances aleatoric uncertainty estimation while preserving the quality of
epistemic uncertainty, surpassing competing methods, such as Deep Ensembles
(DE) and Monte Carlo (MC) dropout. To address challenges in separating
uncertainty types, we propose an algorithm that iteratively improves separation
through progressive sampling in regions of high uncertainty. Our framework is
scalable to large datasets and demonstrates superior performance on synthetic
benchmarks, offering a robust tool for uncertainty quantification in
data-driven applications.

摘要：本文介紹一個創新且可擴充的架構，用於不確定性估計和分離，並應用於科學和工程任務中的資料驅動建模，這些任務中可靠的不確定性量化至關重要。
利用分位數回歸 (E-QR) 模型的集合，我們的做法增強了隨機不確定性估計，同時保留了認識不確定性的品質，超越了競爭方法，例如深度集合 (DE) 和蒙地卡羅 (MC) 輟學。為了應對分離不確定性類型的挑戰，我們提出了一種演算法，透過在高不確定性區域進行漸進式抽樣，反覆改善分離。我們的架構可擴充到大型資料集，並在合成基準上展現出卓越的效能，為資料驅動應用中的不確定性量化提供了一個強大的工具。

##### **On the Compression of Language Models for Code: An Empirical Study on CodeBERT**
2412.13737v1 by Giordano d'Aloisio, Luca Traini, Federica Sarro, Antinisca Di Marco

Language models have proven successful across a wide range of software
engineering tasks, but their significant computational costs often hinder their
practical adoption. To address this challenge, researchers have begun applying
various compression strategies to improve the efficiency of language models for
code. These strategies aim to optimize inference latency and memory usage,
though often at the cost of reduced model effectiveness. However, there is
still a significant gap in understanding how these strategies influence the
efficiency and effectiveness of language models for code. Here, we empirically
investigate the impact of three well-known compression strategies -- knowledge
distillation, quantization, and pruning -- across three different classes of
software engineering tasks: vulnerability detection, code summarization, and
code search. Our findings reveal that the impact of these strategies varies
greatly depending on the task and the specific compression method employed.
Practitioners and researchers can use these insights to make informed decisions
when selecting the most appropriate compression strategy, balancing both
efficiency and effectiveness based on their specific needs.

摘要：語言模型已被證明在廣泛的軟體工程任務中取得成功，但其顯著的運算成本通常會阻礙其實際採用。為了應對這一挑戰，研究人員已開始應用各種壓縮策略來提高語言模型對程式碼的效率。這些策略旨在最佳化推論延遲和記憶體使用率，儘管通常以降低模型有效性為代價。然而，對於這些策略如何影響語言模型對程式碼的效率和有效性，仍有顯著的理解差距。在此，我們根據三個不同的軟體工程任務類別：漏洞偵測、程式碼摘要和程式碼搜尋，實證調查三種眾所周知的壓縮策略的影響——知識萃取、量化和剪枝。我們的研究結果顯示，這些策略的影響會根據任務和所採用的特定壓縮方法而有很大差異。從業人員和研究人員可以使用這些見解，在根據其特定需求平衡效率和有效性的同時，做出明智的決定，選擇最合適的壓縮策略。

##### **Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**
2412.13720v1 by Jincheol Jung, Hongju Jeong, Eui-Nam Huh

This study analyzes the performance of domain-specific Large Language Models
(LLMs) for the medical field by integrating Retrieval-Augmented Generation
(RAG) systems within a federated learning framework. Leveraging the inherent
advantages of federated learning, such as preserving data privacy and enabling
distributed computation, this research explores the integration of RAG systems
with models trained under varying client configurations to optimize
performance. Experimental results demonstrate that the federated learning-based
models integrated with RAG systems consistently outperform their non-integrated
counterparts across all evaluation metrics. This study highlights the potential
of combining federated learning and RAG systems for developing domain-specific
LLMs in the medical field, providing a scalable and privacy-preserving solution
for enhancing text generation capabilities.

摘要：本研究透過在聯邦學習架構中整合檢索擴增生成 (RAG) 系統，分析特定領域的大語言模型 (LLM) 在醫療領域的表現。利用聯邦學習的內在優勢，例如維護資料隱私和啟用分散式運算，本研究探討將 RAG 系統與在不同客戶端組態下訓練的模型整合，以最佳化效能。實驗結果顯示，與 RAG 系統整合的基於聯邦學習的模型在所有評估指標上都持續優於未整合的對應模型。本研究強調在醫療領域結合聯邦學習和 RAG 系統以開發特定領域 LLM 的潛力，提供可擴充且維護隱私的解決方案，以增強文字生成能力。

##### **An Algebraic Notion of Conditional Independence, and Its Application to Knowledge Representation (full version)**
2412.13712v1 by Jesse Heyninck

Conditional independence is a crucial concept supporting adequate modelling
and efficient reasoning in probabilistics. In knowledge representation, the
idea of conditional independence has also been introduced for specific
formalisms, such as propositional logic and belief revision. In this paper, the
notion of conditional independence is studied in the algebraic framework of
approximation fixpoint theory. This gives a language-independent account of
conditional independence that can be straightforwardly applied to any logic
with fixpoint semantics. It is shown how this notion allows to reduce global
reasoning to parallel instances of local reasoning, leading to fixed-parameter
tractability results. Furthermore, relations to existing notions of conditional
independence are discussed and the framework is applied to normal logic
programming.

摘要：條件獨立是支援適當建模和機率推理中有效推論的關鍵概念。在知識表徵中，條件獨立的概念也已針對特定形式主義引入，例如命題邏輯和信念修正。在本文中，條件獨立的概念在近似不動點理論的代數框架中進行探討。這提供了條件獨立的與語言無關的說明，可直接應用於任何具有不動點語意的邏輯。展示了這個概念如何允許將全局推理化約為局部推理的平行實例，從而產生固定參數可處理性結果。此外，討論了與現有條件獨立概念的關係，並將框架應用於常態邏輯程式設計。

##### **Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation**
2412.13705v1 by Minkyoung Kim, Yunha Kim, Hyeram Seo, Heejung Choi, Jiye Han, Gaeun Kee, Soyoung Ko, HyoJe Jung, Byeolhee Kim, Young-Hak Kim, Sanghyun Park, Tae Joon Jun

Large language models (LLMs) have exhibited outstanding performance in
natural language processing tasks. However, these models remain susceptible to
adversarial attacks in which slight input perturbations can lead to harmful or
misleading outputs. A gradient-based defensive suffix generation algorithm is
designed to bolster the robustness of LLMs. By appending carefully optimized
defensive suffixes to input prompts, the algorithm mitigates adversarial
influences while preserving the models' utility. To enhance adversarial
understanding, a novel total loss function ($L_{\text{total}}$) combining
defensive loss ($L_{\text{def}}$) and adversarial loss ($L_{\text{adv}}$)
generates defensive suffixes more effectively. Experimental evaluations
conducted on open-source LLMs such as Gemma-7B, mistral-7B, Llama2-7B, and
Llama2-13B show that the proposed method reduces attack success rates (ASR) by
an average of 11\% compared to models without defensive suffixes. Additionally,
the perplexity score of Gemma-7B decreased from 6.57 to 3.93 when applying the
defensive suffix generated by openELM-270M. Furthermore, TruthfulQA evaluations
demonstrate consistent improvements with Truthfulness scores increasing by up
to 10\% across tested configurations. This approach significantly enhances the
security of LLMs in critical applications without requiring extensive
retraining.

摘要：大型語言模型 (LLM) 已在自然語言處理任務中展現出色的表現。然而，這些模型仍容易受到對抗性攻擊，其中輕微的輸入擾動可能導致有害或誤導的輸出。基於梯度的防禦性後綴生成演算法旨在加強 LLM 的穩健性。透過附加經過仔細最佳化的防禦性後綴至輸入提示，此演算法可減輕對抗性影響，同時保留模型的效用。為了增強對抗性理解，一個新穎的總損失函數 ($L_{\text{total}}$) 結合了防禦性損失 ($L_{\text{def}}$) 和對抗性損失 ($L_{\text{adv}}$)，更有效地產生防禦性後綴。在 Gemma-7B、mistral-7B、Llama2-7B 和 Llama2-13B 等開源 LLM 上進行的實驗評估顯示，與沒有防禦性後綴的模型相比，所提出的方法將攻擊成功率 (ASR) 平均降低了 11%。此外，在應用 openELM-270M 生成的防禦性後綴時，Gemma-7B 的困惑度分數從 6.57 降低到 3.93。此外，TruthfulQA 評估顯示，在測試的配置中，真實性分數提高了 10%，證明了一致的改進。此方法顯著增強了 LLM 在關鍵應用中的安全性，而無需進行廣泛的再訓練。

##### **Typhoon 2: A Family of Open Text and Multimodal Thai Large Language Models**
2412.13702v1 by Kunat Pipatanakul, Potsawee Manakul, Natapong Nitarach, Warit Sirichotedumrong, Surapon Nonesung, Teetouch Jaknamon, Parinthapat Pengpun, Pittawat Taveekitworachai, Adisai Na-Thalang, Sittipong Sripaisarnmongkol, Krisanapong Jirayoot, Kasima Tharnpipitchai

This paper introduces Typhoon 2, a series of text and multimodal large
language models optimized for the Thai language. The series includes models for
text, vision, and audio. Typhoon2-Text builds on state-of-the-art open models,
such as Llama 3 and Qwen2, and we perform continual pre-training on a mixture
of English and Thai data. We employ various post-training techniques to enhance
Thai language performance while preserving the base models' original
capabilities. We release text models across a range of sizes, from 1 to 70
billion parameters, available in both base and instruction-tuned variants.
Typhoon2-Vision improves Thai document understanding while retaining general
visual capabilities, such as image captioning. Typhoon2-Audio introduces an
end-to-end speech-to-speech model architecture capable of processing audio,
speech, and text inputs and generating both text and speech outputs
simultaneously.

摘要：本論文介紹了颱風 2，一系列針對泰語進行最佳化的文字和多模態大型語言模型。該系列包括文字、視覺和音訊模型。Typhoon2-Text 建立在最先進的開放模型上，例如 Llama 3 和 Qwen2，我們針對英文和泰文資料的混合進行持續的預先訓練。我們採用各種訓練後技術來增強泰語語言效能，同時保留基礎模型的原始功能。我們釋出各種規模的文字模型，從 10 億到 700 億個參數，提供基礎和指令調整的變體。Typhoon2-Vision 改善了泰文文件理解，同時保留了一般視覺功能，例如影像加註。Typhoon2-Audio 介紹了一個端對端的語音轉語音模型架構，能夠處理音訊、語音和文字輸入，並同時產生文字和語音輸出。

##### **Towards Efficient and Explainable Hate Speech Detection via Model Distillation**
2412.13698v1 by Paloma Piot, Javier Parapar

Automatic detection of hate and abusive language is essential to combat its
online spread. Moreover, recognising and explaining hate speech serves to
educate people about its negative effects. However, most current detection
models operate as black boxes, lacking interpretability and explainability. In
this context, Large Language Models (LLMs) have proven effective for hate
speech detection and to promote interpretability. Nevertheless, they are
computationally costly to run. In this work, we propose distilling big language
models by using Chain-of-Thought to extract explanations that support the hate
speech classification task. Having small language models for these tasks will
contribute to their use in operational settings. In this paper, we demonstrate
that distilled models deliver explanations of the same quality as larger models
while surpassing them in classification performance. This dual capability,
classifying and explaining, advances hate speech detection making it more
affordable, understandable and actionable.

摘要：自動偵測仇恨和辱罵語言對於遏止其在網路上散播至關重要。此外，辨識並解釋仇恨言論有助於教育大眾了解其負面影響。然而，目前多數偵測模型運作就像黑盒子，缺乏可解釋性和可理解性。在此背景下，大型語言模型 (LLM) 已被證明在仇恨言論偵測和促進可解釋性方面有效。儘管如此，它們的運算成本很高。在這項研究中，我們提出使用思考鏈來萃取出支持仇恨言論分類任務的說明，以提煉大型語言模型。針對這些任務擁有小型語言模型將有助於它們在作業設定中的運用。在本文中，我們證明提煉後的模型提供的說明品質與較大型模型相同，同時在分類效能上超越它們。這種同時分類和說明的雙重能力，讓仇恨言論偵測更實惠、更易於理解且更具可行性。

##### **Discerning and Characterising Types of Competency Questions for Ontologies**
2412.13688v1 by C. Maria Keet, Zubeida Casmod Khan

Competency Questions (CQs) are widely used in ontology development by
guiding, among others, the scoping and validation stages. However, very limited
guidance exists for formulating CQs and assessing whether they are good CQs,
leading to issues such as ambiguity and unusable formulations. To solve this,
one requires insight into the nature of CQs for ontologies and their
constituent parts, as well as which ones are not. We aim to contribute to such
theoretical foundations in this paper, which is informed by analysing
questions, their uses, and the myriad of ontology development tasks. This
resulted in a first Model for Competency Questions, which comprises five main
types of CQs, each with a different purpose: Scoping (SCQ), Validating (VCQ),
Foundational (FCQ), Relationship (RCQ), and Metaproperty (MpCQ) questions. This
model enhances the clarity of CQs and therewith aims to improve on the
effectiveness of CQs in ontology development, thanks to their respective
identifiable distinct constituent elements. We illustrate and evaluate them
with a user story and demonstrate where which type can be used in ontology
development tasks. To foster use and research, we created an annotated
repository of 438 CQs, the Repository of Ontology Competency QuestionS (ROCQS),
incorporating an existing CQ dataset and new CQs and CQ templates, which
further demonstrate distinctions among types of CQs.

摘要：能力問題（CQs）廣泛用於本體論開發，引導其他領域的範圍和驗證階段。然而，對於制定 CQs 和評估它們是否為良好的 CQs，只有非常有限的指導，導致模稜兩可和無法使用的公式等問題。為了解決這個問題，需要深入了解本體論 CQs 的本質及其組成部分，以及哪些不是。我們旨在為這篇論文的理論基礎做出貢獻，這篇論文是透過分析問題、它們的用途和大量的本體論開發任務而獲得的。這產生了能力問題的第一個模型，其中包括五種類型的 CQs，每種類型都有不同的目的：範圍（SCQ）、驗證（VCQ）、基礎（FCQ）、關係（RCQ）和元屬性（MpCQ）問題。這個模型增強了 CQs 的清晰度，並因此旨在透過它們各自可識別的不同組成元素，改善 CQs 在本體論開發中的有效性。我們用一個使用者故事來說明和評估它們，並展示在哪些本體論開發任務中可以使用哪種類型。為了促進使用和研究，我們創建了一個註解的 438 個 CQs 儲存庫，本體論能力問題儲存庫（ROCQS），其中包含現有的 CQ 資料集和新的 CQs 和 CQ 範本，進一步展示了 CQs 類型之間的區別。

##### **ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning**
2412.13682v1 by Jie-Jing Shao, Xiao-Wen Yang, Bo-Wen Zhang, Baizhi Chen, Wen-Da Wei, Lan-Zhe Guo, Yu-feng Li

Recent advances in LLMs, particularly in language reasoning and tool
integration, have rapidly sparked the real-world development of Language
Agents. Among these, travel planning represents a prominent domain, combining
academic challenges with practical value due to its complexity and market
demand. However, existing benchmarks fail to reflect the diverse, real-world
requirements crucial for deployment. To address this gap, we introduce
ChinaTravel, a benchmark specifically designed for authentic Chinese travel
planning scenarios. We collect the travel requirements from questionnaires and
propose a compositionally generalizable domain-specific language that enables a
scalable evaluation process, covering feasibility, constraint satisfaction, and
preference comparison. Empirical studies reveal the potential of neuro-symbolic
agents in travel planning, achieving a constraint satisfaction rate of 27.9%,
significantly surpassing purely neural models at 2.6%. Moreover, we identify
key challenges in real-world travel planning deployments, including open
language reasoning and unseen concept composition. These findings highlight the
significance of ChinaTravel as a pivotal milestone for advancing language
agents in complex, real-world planning scenarios.

摘要：近來 LLM 在語言推理和工具整合方面取得了進展，迅速激發了語言代理的實際開發。其中，旅遊規劃代表了一個突出的領域，它結合了學術挑戰和實際價值，因為它的複雜性和市場需求。然而，現有的基準未能反映出對於部署至關重要的多樣化現實世界需求。為了解決這個差距，我們引入了 ChinaTravel，一個專門為正宗的中國旅遊規劃場景設計的基準。我們從問卷中收集旅遊需求，並提出一個可組合的通用特定領域語言，它能進行可擴充的評估過程，涵蓋可行性、約束滿足和偏好比較。實證研究揭示了神經符號代理在旅遊規劃中的潛力，實現了 27.9% 的約束滿足率，顯著超過了 2.6% 的純神經模型。此外，我們確定了現實世界旅遊規劃部署中的關鍵挑戰，包括開放語言推理和未見的概念組合。這些發現突出了 ChinaTravel 作為在複雜的現實世界規劃場景中推進語言代理的重要里程碑。

##### **Clio: Privacy-Preserving Insights into Real-World AI Use**
2412.13678v1 by Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli

How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.

摘要：人工智能助理在現實世界中如何使用？雖然理論上模型供應商可以透過使用者的資料了解這種影響，但隱私問題和實際挑戰都讓分析這些資料變得困難。為了解決這些問題，我們提出了 Clio（Claude 見解與觀察），一個隱私保護平台，它使用人工智能助理本身來分析並浮出數百萬次對話中的彙整使用模式，而不需要人類審查員閱讀原始對話。我們透過進行廣泛的評估，驗證這可以用高度準確和隱私來完成。我們以兩種廣泛的方式展示 Clio 的用途。首先，我們分享關於模型在現實世界中如何使用的一百萬個 Claude.ai 免費和專業對話的見解，範圍從提供髮型建議到提供有關 Git 操作和概念的指導。我們還找出 Claude.ai 上最常見的高階使用案例（編碼、寫作和研究任務），以及不同語言之間的模式差異（例如，日語對話討論老年照護和老齡化人口的比率高於一般）。其次，我們使用 Clio 透過找出協調濫用我們系統的嘗試、在啟動新功能或重大世界事件等關鍵時期監控未知的未知數，以及改善我們現有的監控系統，讓我們的系統更安全。我們也討論我們方法的限制，以及風險和道德問題。透過啟用對現實世界人工智能使用的分析，Clio 提供了一個可擴充的平台，用於以經驗為基礎的人工智能安全和治理。

##### **AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge**
2412.13670v1 by Xiaobao Wu, Liangming Pan, Yuxi Xie, Ruiwen Zhou, Shuai Zhao, Yubo Ma, Mingzhe Du, Rui Mao, Anh Tuan Luu, William Yang Wang

Data contamination hinders fair LLM evaluation by introducing test data into
newer models' training sets. Existing studies solve this challenge by updating
benchmarks with newly collected data. However, they fail to guarantee
contamination-free evaluation as the newly collected data may contain
pre-existing knowledge, and their benchmark updates rely on intensive human
labor. To address these issues, we in this paper propose AntiLeak-Bench, an
automated anti-leakage benchmarking framework. Instead of simply using newly
collected data, we construct samples with explicitly new knowledge absent from
LLMs' training sets, which thus ensures strictly contamination-free evaluation.
We further design a fully automated workflow to build and update our benchmark
without human labor. This significantly reduces the cost of benchmark
maintenance to accommodate emerging LLMs. Through extensive experiments, we
highlight that data contamination likely exists before LLMs' cutoff time and
demonstrate AntiLeak-Bench effectively overcomes this challenge.

摘要：資料污染會透過將測試資料引入較新的模型訓練組中，而阻礙公平的 LLM 評估。現有研究透過使用新收集的資料來更新基準，來解決這個挑戰。然而，由於新收集的資料可能包含既有知識，因此無法保證無污染評估，且其基準更新仰賴於大量的人力。為了解決這些問題，我們在本文中提出 AntiLeak-Bench，一個自動化的防外洩基準架構。我們並非單純使用新收集的資料，而是建構明確包含 LLM 訓練組中所沒有的新知識的範例，進而確保嚴格的無污染評估。我們進一步設計一個全自動化工作流程，來建構並更新我們的基準，而無需人力。這大幅降低了基準維護的成本，以容納新興的 LLM。透過廣泛的實驗，我們強調資料污染很可能存在於 LLM 截止時間之前，並證明 AntiLeak-Bench 有效克服了這個挑戰。

##### **Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**
2412.13667v1 by ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

Causal inference is an imperative foundation for decision-making across
domains, such as smart health, AI for drug discovery and AIOps. Traditional
statistical causal discovery methods, while well-established, predominantly
rely on observational data and often overlook the semantic cues inherent in
cause-and-effect relationships. The advent of Large Language Models (LLMs) has
ushered in an affordable way of leveraging the semantic cues for
knowledge-driven causal discovery, but the development of LLMs for causal
discovery lags behind other areas, particularly in the exploration of
multi-modality data. To bridge the gap, we introduce MATMCD, a multi-agent
system powered by tool-augmented LLMs. MATMCD has two key agents: a Data
Augmentation agent that retrieves and processes modality-augmented data, and a
Causal Constraint agent that integrates multi-modal data for knowledge-driven
inference. Delicate design of the inner-workings ensures successful cooperation
of the agents. Our empirical study across seven datasets suggests the
significant potential of multi-modality enhanced causal discovery.

摘要：因果推論是跨領域決策制定中的必要基礎，例如智慧醫療、用於藥物發現的人工智慧和 AIOps。傳統的統計因果發現方法雖然已經確立，但主要依賴於觀察資料，且常常忽略因果關係中固有的語意線索。大型語言模型 (LLM) 的出現，開啟了一種利用語意線索進行知識驅動因果發現的方法，但用於因果發現的 LLM 發展落後於其他領域，特別是在多模態資料的探索方面。為了彌補差距，我們引入了 MATMCD，這是一個由工具增強的 LLM 驅動的多主體系統。MATMCD 有兩個關鍵主體：一個資料擴充主體，用於擷取和處理模態擴充資料，以及一個因果約束主體，用於整合多模態資料進行知識驅動推論。內部運作的精細設計確保了主體之間的成功合作。我們對七個資料集的實證研究表明，多模態增強因果發現具有顯著的潛力。

##### **Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation**
2412.13666v1 by Aneta Zugecova, Dominik Macko, Ivan Srba, Robert Moro, Jakub Kopal, Katarina Marcincinova, Matus Mesarcik

The capabilities of recent large language models (LLMs) to generate
high-quality content indistinguishable by humans from human-written texts rises
many concerns regarding their misuse. Previous research has shown that LLMs can
be effectively misused for generating disinformation news articles following
predefined narratives. Their capabilities to generate personalized (in various
aspects) content have also been evaluated and mostly found usable. However, a
combination of personalization and disinformation abilities of LLMs has not
been comprehensively studied yet. Such a dangerous combination should trigger
integrated safety filters of the LLMs, if there are some. This study fills this
gap by evaluation of vulnerabilities of recent open and closed LLMs, and their
willingness to generate personalized disinformation news articles in English.
We further explore whether the LLMs can reliably meta-evaluate the
personalization quality and whether the personalization affects the
generated-texts detectability. Our results demonstrate the need for stronger
safety-filters and disclaimers, as those are not properly functioning in most
of the evaluated LLMs. Additionally, our study revealed that the
personalization actually reduces the safety-filter activations; thus
effectively functioning as a jailbreak. Such behavior must be urgently
addressed by LLM developers and service providers.

摘要：最近的大型語言模型 (LLM) 產生高品質內容的能力，其品質之高甚至讓人無法分辨是人類還是機器所寫，這引發許多關於其遭濫用的疑慮。先前的研究顯示，LLM 可以有效地被濫用來產生假訊息新聞文章，遵循預先定義好的敘事。它們產生個人化（在各方面）內容的能力也已被評估，且大多數被發現可用。然而，LLM 個人化和假訊息能力的結合尚未被全面研究。如果有的話，如此危險的結合應觸發 LLM 的整合式安全過濾器。本研究透過評估近期開放和封閉 LLM 的漏洞，以及它們產生個人化假訊息新聞文章的意願，來填補這個空白。我們進一步探討 LLM 是否能可靠地對個人化品質進行元評估，以及個人化是否會影響所產生文字的可偵測性。我們的結果顯示需要更強大的安全過濾器和免責聲明，因為這些功能在大部分評估的 LLM 中並未適當運作。此外，我們的研究揭露，個人化實際上會降低安全過濾器的啟動次數；因此有效地作為一種越獄。LLM 開發人員和服務供應商必須緊急解決這種行為。

##### **Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference**
2412.13663v1 by Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, Nathan Cooper, Griffin Adams, Jeremy Howard, Iacopo Poli

Encoder-only transformer models such as BERT offer a great performance-size
tradeoff for retrieval and classification tasks with respect to larger
decoder-only models. Despite being the workhorse of numerous production
pipelines, there have been limited Pareto improvements to BERT since its
release. In this paper, we introduce ModernBERT, bringing modern model
optimizations to encoder-only models and representing a major Pareto
improvement over older encoders. Trained on 2 trillion tokens with a native
8192 sequence length, ModernBERT models exhibit state-of-the-art results on a
large pool of evaluations encompassing diverse classification tasks and both
single and multi-vector retrieval on different domains (including code). In
addition to strong downstream performance, ModernBERT is also the most speed
and memory efficient encoder and is designed for inference on common GPUs.

摘要：僅編碼器轉換器模型，例如 BERT，對於檢索和分類任務，提供了相對於較大的僅解碼器模型的出色效能大小權衡。儘管是許多生產管線的運作主軸，但自 BERT 發布以來，Pareto 改進一直很有限。在本文中，我們引入了 ModernBERT，將現代模型最佳化帶入僅編碼器模型，並代表了相較於舊編碼器的一項重大 Pareto 改進。ModernBERT 模型以 2 兆個符號和原生 8192 順序長度進行訓練，在包含各種分類任務和不同領域（包括程式碼）的單向量和多向量檢索的大型評估池中展現了最先進的結果。除了強大的下游效能之外，ModernBERT 也是速度和記憶體最有效率的編碼器，並設計用於在常見 GPU 上進行推論。

##### **PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling**
2412.13660v1 by Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu

Currently, large language models (LLMs) have made significant progress in the
field of psychological counseling. However, existing mental health LLMs
overlook a critical issue where they do not consider the fact that different
psychological counselors exhibit different personal styles, including
linguistic style and therapy techniques, etc. As a result, these LLMs fail to
satisfy the individual needs of clients who seek different counseling styles.
To help bridge this gap, we propose PsyDT, a novel framework using LLMs to
construct the Digital Twin of Psychological counselor with personalized
counseling style. Compared to the time-consuming and costly approach of
collecting a large number of real-world counseling cases to create a specific
counselor's digital twin, our framework offers a faster and more cost-effective
solution. To construct PsyDT, we utilize dynamic one-shot learning by using
GPT-4 to capture counselor's unique counseling style, mainly focusing on
linguistic style and therapy techniques. Subsequently, using existing
single-turn long-text dialogues with client's questions, GPT-4 is guided to
synthesize multi-turn dialogues of specific counselor. Finally, we fine-tune
the LLMs on the synthetic dataset, PsyDTCorpus, to achieve the digital twin of
psychological counselor with personalized counseling style. Experimental
results indicate that our proposed PsyDT framework can synthesize multi-turn
dialogues that closely resemble real-world counseling cases and demonstrate
better performance compared to other baselines, thereby show that our framework
can effectively construct the digital twin of psychological counselor with a
specific counseling style.

摘要：<paragraph>目前，大型語言模型 (LLM) 在心理諮商領域已取得顯著進展。然而，現有的心理健康 LLM 忽視了一個關鍵問題，即它們沒有考慮到不同的心理諮商師表現出不同的個人風格，包括語言風格和治療技巧等。因此，這些 LLM 無法滿足尋求不同諮商風格的客戶的個別需求。為了幫助彌合這一差距，我們提出了 PsyDT，這是一個使用 LLM 構建具有個性化諮商風格的心理諮商師數位雙胞胎的新框架。與收集大量真實世界諮商案例以建立特定諮商師數位雙胞胎的耗時且昂貴的方法相比，我們的框架提供了一個更快、更具成本效益的解決方案。為了構建 PsyDT，我們利用動態一發學習，使用 GPT-4 來捕捉諮商師獨特的諮商風格，主要關注語言風格和治療技巧。隨後，使用現有的單回合長文本對話和客戶問題，指導 GPT-4 合成特定諮商師的多回合對話。最後，我們對合成數據集 PsyDTCorpus 上的 LLM 進行微調，以實現具有個性化諮商風格的心理諮商師數位雙胞胎。實驗結果表明，我們提出的 PsyDT 框架可以合成與真實世界諮商案例非常相似的多回合對話，並且與其他基線相比表現出更好的性能，從而表明我們的框架可以有效地構建具有特定諮商風格的心理諮商師數位雙胞胎。</paragraph>

##### **SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation**
2412.13649v1 by Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou

Key-Value (KV) cache has become a bottleneck of LLMs for long-context
generation. Despite the numerous efforts in this area, the optimization for the
decoding phase is generally ignored. However, we believe such optimization is
crucial, especially for long-output generation tasks based on the following two
observations: (i) Excessive compression during the prefill phase, which
requires specific full context impairs the comprehension of the reasoning task;
(ii) Deviation of heavy hitters occurs in the reasoning tasks with long
outputs. Therefore, SCOPE, a simple yet efficient framework that separately
performs KV cache optimization during the prefill and decoding phases, is
introduced. Specifically, the KV cache during the prefill phase is preserved to
maintain the essential information, while a novel strategy based on sliding is
proposed to select essential heavy hitters for the decoding phase. Memory usage
and memory transfer are further optimized using adaptive and discontinuous
strategies. Extensive experiments on LongGenBench show the effectiveness and
generalization of SCOPE and its compatibility as a plug-in to other
prefill-only KV compression methods.

摘要：鍵值 (KV) 快取已成為長語境生成 LLM 的瓶頸。儘管在該領域付出了許多努力，但通常會忽略對解碼階段的最佳化。然而，我們相信這種最佳化至關重要，特別是基於以下兩個觀察結果的長輸出生成任務：(i) 預填充階段的過度壓縮，需要特定的完整語境會損害對推理任務的理解；(ii) 在具有長輸出的推理任務中會發生重擊手的偏差。因此，引入了 SCOPE，一個簡單而高效的框架，在預填充和解碼階段分別執行 KV 快取最佳化。具體而言，預填充階段的 KV 快取被保留以維護必要資訊，同時提出了一種基於滑動的新策略來選擇解碼階段的必要重擊手。使用自適應和不連續策略進一步最佳化記憶體使用和記憶體傳輸。在 LongGenBench 上進行的廣泛實驗顯示了 SCOPE 的有效性和泛化性，以及它作為其他僅預填充 KV 壓縮方法的插入模組的相容性。

##### **G-VEval: A Versatile Metric for Evaluating Image and Video Captions Using GPT-4o**
2412.13647v1 by Tony Cheng Tong, Sirui He, Zhiwen Shao, Dit-Yan Yeung

Evaluation metric of visual captioning is important yet not thoroughly
explored. Traditional metrics like BLEU, METEOR, CIDEr, and ROUGE often miss
semantic depth, while trained metrics such as CLIP-Score, PAC-S, and Polos are
limited in zero-shot scenarios. Advanced Language Model-based metrics also
struggle with aligning to nuanced human preferences. To address these issues,
we introduce G-VEval, a novel metric inspired by G-Eval and powered by the new
GPT-4o. G-VEval uses chain-of-thought reasoning in large multimodal models and
supports three modes: reference-free, reference-only, and combined,
accommodating both video and image inputs. We also propose MSVD-Eval, a new
dataset for video captioning evaluation, to establish a more transparent and
consistent framework for both human experts and evaluation metrics. It is
designed to address the lack of clear criteria in existing datasets by
introducing distinct dimensions of Accuracy, Completeness, Conciseness, and
Relevance (ACCR). Extensive results show that G-VEval outperforms existing
methods in correlation with human annotations, as measured by Kendall tau-b and
Kendall tau-c. This provides a flexible solution for diverse captioning tasks
and suggests a straightforward yet effective approach for large language models
to understand video content, paving the way for advancements in automated
captioning. Codes are available at https://github.com/ztangaj/gveval

摘要：視覺字幕的評估指標很重要，但尚未被徹底探討。BLEU、METEOR、CIDEr 和 ROUGE 等傳統指標經常遺漏語義深度，而 CLIP-Score、PAC-S 和 Polos 等訓練指標則在零次學習場景中受到限制。基於先進語言模型的指標也難以與細微的人類偏好保持一致。為了解決這些問題，我們引入了 G-VEval，這是一種受 G-Eval 啟發並由新的 GPT-4o 提供支持的新指標。G-VEval 在大型多模態模型中使用思維鏈推理，並支援三種模式：無參考、僅參考和組合，同時容納影片和影像輸入。我們還提出了 MSVD-Eval，這是一個用於影片字幕評估的新資料集，為人類專家和評估指標建立一個更透明且一致的架構。它旨在透過引入準確性、完整性、簡潔性和相關性 (ACCR) 的不同面向來解決現有資料集中缺乏明確標準的問題。廣泛的結果顯示，G-VEval 在與人類註解的相關性方面優於現有方法，以 Kendall tau-b 和 Kendall tau-c 衡量。這為不同的字幕任務提供了一個靈活的解決方案，並為大型語言模型理解影片內容提供了一個簡單但有效的方法，為自動字幕的進步鋪平了道路。程式碼可在 https://github.com/ztangaj/gveval 取得

##### **On the Role of Model Prior in Real-World Inductive Reasoning**
2412.13645v1 by Zhuo Liu, Ding Yu, Hangfeng He

Large Language Models (LLMs) show impressive inductive reasoning
capabilities, enabling them to generate hypotheses that could generalize
effectively to new instances when guided by in-context demonstrations. However,
in real-world applications, LLMs' hypothesis generation is not solely
determined by these demonstrations but is significantly shaped by task-specific
model priors. Despite their critical influence, the distinct contributions of
model priors versus demonstrations to hypothesis generation have been
underexplored. This study bridges this gap by systematically evaluating three
inductive reasoning strategies across five real-world tasks with three LLMs.
Our empirical findings reveal that, hypothesis generation is primarily driven
by the model's inherent priors; removing demonstrations results in minimal loss
of hypothesis quality and downstream usage. Further analysis shows the result
is consistent across various label formats with different label configurations,
and prior is hard to override, even under flipped labeling. These insights
advance our understanding of the dynamics of hypothesis generation in LLMs and
highlight the potential for better utilizing model priors in real-world
inductive reasoning tasks.

摘要：大型語言模型 (LLM) 展現出令人印象深刻的歸納推理能力，讓它們能夠產生假設，在有脈絡的示範引導下，這些假設可以有效地推廣到新的實例。然而，在現實世界的應用中，LLM 的假設產生不僅僅取決於這些示範，還會受到特定任務模型先驗的顯著影響。儘管它們有重要的影響，但模型先驗和示範對假設產生的不同貢獻尚未得到充分探討。本研究通過系統地評估三個歸納推理策略，跨越五個現實世界任務，使用三個 LLM，來彌合這一差距。我們的實證發現表明，假設產生主要是由模型的固有先驗驅動的；移除示範會導致假設品質和下游使用率的損失最小化。進一步的分析表明，結果與具有不同標籤配置的各種標籤格式一致，而且先驗很難被覆蓋，即使在翻轉標籤的情況下也是如此。這些見解提升了我們對 LLM 中假設產生動態的理解，並強調了在現實世界的歸納推理任務中更好地利用模型先驗的潛力。

##### **Consistency of Compositional Generalization across Multiple Levels**
2412.13636v1 by Chuanhao Li, Zhen Li, Chenchen Jing, Xiaomeng Fan, Wenbo Ye, Yuwei Wu, Yunde Jia

Compositional generalization is the capability of a model to understand novel
compositions composed of seen concepts. There are multiple levels of novel
compositions including phrase-phrase level, phrase-word level, and word-word
level. Existing methods achieve promising compositional generalization, but the
consistency of compositional generalization across multiple levels of novel
compositions remains unexplored. The consistency refers to that a model should
generalize to a phrase-phrase level novel composition, and
phrase-word/word-word level novel compositions that can be derived from it
simultaneously. In this paper, we propose a meta-learning based framework, for
achieving consistent compositional generalization across multiple levels. The
basic idea is to progressively learn compositions from simple to complex for
consistency. Specifically, we divide the original training set into multiple
validation sets based on compositional complexity, and introduce multiple
meta-weight-nets to generate sample weights for samples in different validation
sets. To fit the validation sets in order of increasing compositional
complexity, we optimize the parameters of each meta-weight-net independently
and sequentially in a multilevel optimization manner. We build a GQA-CCG
dataset to quantitatively evaluate the consistency. Experimental results on
visual question answering and temporal video grounding, demonstrate the
effectiveness of the proposed framework. We release GQA-CCG at
https://github.com/NeverMoreLCH/CCG.

摘要：組合泛化是指模型理解由已見概念組成的創新組合的能力。創新組合有多個層次，包括片語-片語層次、片語-詞彙層次和詞彙-詞彙層次。現有方法實現了有前景的組合泛化，但組合泛化在多個創新組合層次中的一致性仍未探索。一致性是指模型應概化為片語-片語層次的創新組合，以及可以同時從中衍生的片語-詞彙/詞彙-詞彙層次的創新組合。在本文中，我們提出了一個基於元學習的框架，用於在多個層次實現一致的組合泛化。基本思想是逐步學習從簡單到複雜的組合以保持一致性。具體來說，我們根據組合複雜性將原始訓練集劃分為多個驗證集，並引入多個元權重網路來為不同驗證集中的樣本生成樣本權重。為了按照組合複雜性遞增的順序擬合驗證集，我們以多層次優化的方式獨立且依序優化每個元權重網路的參數。我們建立了一個 GQA-CCG 資料集來定量評估一致性。視覺問題解答和時序影片接地的實驗結果證明了所提出框架的有效性。我們在 https://github.com/NeverMoreLCH/CCG 釋出 GQA-CCG。

##### **Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning**
2412.13631v1 by Eitan Wagner, Nitay Alon, Joseph M. Barnby, Omri Abend

Theory of Mind (ToM) capabilities in LLMs have recently become a central
object of investigation. Cognitive science distinguishes between two steps
required for ToM tasks: 1) determine whether to invoke ToM, which includes the
appropriate Depth of Mentalizing (DoM), or level of recursion required to
complete a task; and 2) applying the correct inference given the DoM. In this
position paper, we first identify several lines of work in different
communities in AI, including LLM benchmarking, ToM add-ons, ToM probing, and
formal models for ToM. We argue that recent work in AI tends to focus
exclusively on the second step which are typically framed as static logic
problems. We conclude with suggestions for improved evaluation of ToM
capabilities inspired by dynamic environments used in cognitive tasks.

摘要：心智理論（ToM）在大型語言模型（LLM）中的能力最近成為研究的中心
對象。認知科學區分了 ToM 任務所需的兩個步驟：1）確定是否調用 ToM，其中包括完成任務所需的適當心智深度（DoM）或遞迴層級；以及 2）應用給定 DoM 的正確推論。在這篇立場文件中，我們首先找出 AI 中不同社群的幾條工作線，包括 LLM 基準測試、ToM 附加元件、ToM 探索和 ToM 的形式模型。我們認為，AI 中的近期工作傾向於專注於第二個步驟，而這些步驟通常被視為靜態邏輯問題。我們最後提出一些改進 ToM 能力評估的建議，這些建議受到認知任務中使用的動態環境啟發。

##### **Policy Decorator: Model-Agnostic Online Refinement for Large Policy Model**
2412.13630v1 by Xiu Yuan, Tongzhou Mu, Stone Tao, Yunhao Fang, Mengke Zhang, Hao Su

Recent advancements in robot learning have used imitation learning with large
models and extensive demonstrations to develop effective policies. However,
these models are often limited by the quantity, quality, and diversity of
demonstrations. This paper explores improving offline-trained imitation
learning models through online interactions with the environment. We introduce
Policy Decorator, which uses a model-agnostic residual policy to refine large
imitation learning models during online interactions. By implementing
controlled exploration strategies, Policy Decorator enables stable,
sample-efficient online learning. Our evaluation spans eight tasks across two
benchmarks-ManiSkill and Adroit-and involves two state-of-the-art imitation
learning models (Behavior Transformer and Diffusion Policy). The results show
Policy Decorator effectively improves the offline-trained policies and
preserves the smooth motion of imitation learning models, avoiding the erratic
behaviors of pure RL policies. See our project page
(https://policydecorator.github.io) for videos.

摘要：機器學習的最新進展已使用大型模型和廣泛的示範進行模仿學習，以制定有效的策略。然而，這些模型通常受到示範數量、品質和多樣性的限制。本文探討了透過與環境的線上互動來改善離線訓練的模仿學習模型。我們引入了策略裝飾器，它使用與模型無關的殘差策略來在線上互動期間優化大型模仿學習模型。透過實施受控探索策略，策略裝飾器能實現穩定的、樣本效率高的線上學習。我們的評估橫跨兩個基準測試中的八項任務（ManiSkill 和 Adroit），並涉及兩個最先進的模仿學習模型（行為轉換器和擴散策略）。結果顯示策略裝飾器有效地改善了離線訓練的策略，並保留了模仿學習模型的流暢動作，避免了純粹 RL 策略的異常行為。請參閱我們的專案頁面 (https://policydecorator.github.io) 以觀看影片。

##### **LIFT: Improving Long Context Understanding Through Long Input Fine-Tuning**
2412.13626v1 by Yansheng Mao, Jiaqi Li, Fanxu Meng, Jing Xiong, Zilong Zheng, Muhan Zhang

Long context understanding remains challenging for large language models due
to their limited context windows. This paper introduces Long Input Fine-Tuning
(LIFT) for long context modeling, a novel framework that enhances LLM
performance on long-context tasks by adapting model parameters to the context
at test time. LIFT enables efficient processing of lengthy inputs without the
computational burden of offline long-context adaptation, and can improve the
long-context capabilities of arbitrary short-context models. The framework is
further enhanced by integrating in-context learning and pre-LIFT supervised
fine-tuning. The combination of in-context learning and LIFT enables
short-context models like Llama 3 to handle arbitrarily long contexts and
consistently improves their performance on popular long-context benchmarks like
LooGLE and LongBench. We also provide a comprehensive analysis of the strengths
and limitations of LIFT on long context understanding, offering valuable
directions for future research.

摘要：大型語言模型在長文脈理解方面仍面臨挑戰，因為它們的文脈窗口有限。本文介紹了長文脈建模的長輸入微調 (LIFT)，這是一個新穎的框架，透過在測試時調整模型參數以適應文脈，增強 LLM 在長文脈任務上的效能。LIFT 能夠有效處理長輸入，而無需負擔線下長文脈適應的運算負擔，並且可以提升任意短文脈模型的長文脈能力。這個框架進一步透過整合文脈中學習和 LIFT 前的監督微調而增強。文脈中學習和 LIFT 的結合使像 Llama 3 這樣的短文脈模型能夠處理任意長的文脈，並持續提升它們在 LooGLE 和 LongBench 等熱門長文脈基準上的效能。我們也提供了 LIFT 在長文脈理解上的優點和限制的全面分析，為未來的研究提供了有價值的方向。

##### **Unifying Attribution-Based Explanations Using Functional Decomposition**
2412.13623v1 by Arne Gevaert, Yvan Saeys

The black box problem in machine learning has led to the introduction of an
ever-increasing set of explanation methods for complex models. These
explanations have different properties, which in turn has led to the problem of
method selection: which explanation method is most suitable for a given use
case? In this work, we propose a unifying framework of attribution-based
explanation methods, which provides a step towards a rigorous study of the
similarities and differences of explanations. We first introduce removal-based
attribution methods (RBAMs), and show that an extensively broad selection of
existing methods can be viewed as such RBAMs. We then introduce the canonical
additive decomposition (CAD). This is a general construction for additively
decomposing any function based on the central idea of removing (groups of)
features. We proceed to show that indeed every valid additive decomposition is
an instance of the CAD, and that any removal-based attribution method is
associated with a specific CAD. Next, we show that any removal-based
attribution method can be completely defined as a game-theoretic value or
interaction index for a specific (possibly constant-shifted) cooperative game,
which is defined using the corresponding CAD of the method. We then use this
intrinsic connection to define formal descriptions of specific behaviours of
explanation methods, which we also call functional axioms, and identify
sufficient conditions on the corresponding CAD and game-theoretic value or
interaction index of an attribution method under which the attribution method
is guaranteed to adhere to these functional axioms. Finally, we show how this
unifying framework can be used to develop new, efficient approximations for
existing explanation methods.

摘要：機器學習中的黑盒問題導致了一組不斷增加的複雜模型解釋方法的引入。這些解釋具有不同的屬性，這反過來導致了方法選擇的問題：哪種解釋方法最適合給定的使用案例？在這項工作中，我們提出了一個基於歸因的解釋方法的統一框架，這為嚴謹研究解釋的相似性和差異邁出了一步。我們首先介紹了基於移除的歸因方法 (RBAM)，並表明現有方法的廣泛選擇可以視為這樣的 RBAM。然後我們介紹了規範加性分解 (CAD)。這是一個通用結構，用於根據移除（特徵組）的中心思想對任何函數進行加性分解。我們繼續證明，每個有效的加性分解實際上都是 CAD 的一個實例，並且任何基於移除的歸因方法都與特定的 CAD 相關。接下來，我們表明任何基於移除的歸因方法都可以完全定義為一個博弈論價值或一個特定（可能為常數偏移）合作博弈的交互指數，該博弈是使用該方法的對應 CAD 定義的。然後，我們使用這種內在聯繫來定義解釋方法的特定行為的正式描述，我們也稱之為函數公理，並識別歸因方法對應的 CAD 和博弈論價值或交互指數的充分條件，在這些條件下，歸因方法保證遵守這些函數公理。最後，我們展示了如何使用這個統一框架來為現有的解釋方法開發新的、高效的近似值。

##### **NPC: Neural Predictive Control for Fuel-Efficient Autonomous Trucks**
2412.13618v1 by Jiaping Ren, Jiahao Xiang, Hongfei Gao, Jinchuan Zhang, Yiming Ren, Yuexin Ma, Yi Wu, Ruigang Yang, Wei Li

Fuel efficiency is a crucial aspect of long-distance cargo transportation by
oil-powered trucks that economize on costs and decrease carbon emissions.
Current predictive control methods depend on an accurate model of vehicle
dynamics and engine, including weight, drag coefficient, and the Brake-specific
Fuel Consumption (BSFC) map of the engine. We propose a pure data-driven
method, Neural Predictive Control (NPC), which does not use any physical model
for the vehicle. After training with over 20,000 km of historical data, the
novel proposed NVFormer implicitly models the relationship between vehicle
dynamics, road slope, fuel consumption, and control commands using the
attention mechanism. Based on the online sampled primitives from the past of
the current freight trip and anchor-based future data synthesis, the NVFormer
can infer optimal control command for reasonable fuel consumption. The physical
model-free NPC outperforms the base PCC method with 2.41% and 3.45% more
significant fuel saving in simulation and open-road highway testing,
respectively.

摘要：燃油效率是長途貨運中由燃油卡車執行的關鍵面向，可節省成本並減少碳排放。
目前的預測控制方法依賴於車輛動力學和引擎的精準模型，包括重量、阻力係數和引擎的特定煞車燃油消耗 (BSFC) 地圖。我們提出了一種純數據驅動的方法，神經預測控制 (NPC)，它不使用任何車輛物理模型。在使用超過 20,000 公里的歷史資料進行訓練後，新提出的 NVFormer 隱含地使用注意力機制建構車輛動力學、道路坡度、燃料消耗和控制指令之間的關係。基於當前貨運行程過去的在線取樣基元和基於錨點的未來資料合成，NVFormer 可以推斷出合理燃料消耗的最佳控制指令。無物理模型的 NPC 在模擬和開放道路高速公路測試中分別比基礎 PCC 方法節省了 2.41% 和 3.45% 的燃料，表現更出色。

##### **Reverse Region-to-Entity Annotation for Pixel-Level Visual Entity Linking**
2412.13614v1 by Zhengfei Xu, Sijia Zhao, Yanchao Hao, Xiaolong Liu, Lili Li, Yuyang Yin, Bo Li, Xi Chen, Xin Xin

Visual Entity Linking (VEL) is a crucial task for achieving fine-grained
visual understanding, matching objects within images (visual mentions) to
entities in a knowledge base. Previous VEL tasks rely on textual inputs, but
writing queries for complex scenes can be challenging. Visual inputs like
clicks or bounding boxes offer a more convenient alternative. Therefore, we
propose a new task, Pixel-Level Visual Entity Linking (PL-VEL), which uses
pixel masks from visual inputs to refer to objects, supplementing reference
methods for VEL. To facilitate research on this task, we have constructed the
MaskOVEN-Wiki dataset through an entirely automatic reverse region-entity
annotation framework. This dataset contains over 5 million annotations aligning
pixel-level regions with entity-level labels, which will advance visual
understanding towards fine-grained. Moreover, as pixel masks correspond to
semantic regions in an image, we enhance previous patch-interacted attention
with region-interacted attention by a visual semantic tokenization approach.
Manual evaluation results indicate that the reverse annotation framework
achieved a 94.8% annotation success rate. Experimental results show that models
trained on this dataset improved accuracy by 18 points compared to zero-shot
models. Additionally, the semantic tokenization method achieved a 5-point
accuracy improvement over the trained baseline.

摘要：視覺實體連結 (VEL) 是達成細粒度視覺理解的一項重要任務，用於將影像中的物件 (視覺提及) 與知識庫中的實體配對。先前的 VEL 任務依賴於文字輸入，但為複雜場景撰寫查詢可能具有挑戰性。點擊或邊界框等視覺輸入提供了更便利的替代方案。因此，我們提出了一項新任務，即像素級視覺實體連結 (PL-VEL)，它使用視覺輸入中的像素遮罩來指涉物件，補充 VEL 的參考方法。為了促進對此任務的研究，我們透過一個完全自動化的反向區域實體註釋架構建構了 MaskOVEN-Wiki 資料集。此資料集包含超過 500 萬個註釋，將像素級區域與實體級標籤對齊，這將推進視覺理解走向細粒度。此外，由於像素遮罩對應於影像中的語意區域，我們透過視覺語意標記化方法，使用區域互動注意力增強先前的區塊互動注意力。手動評估結果表明，反向註釋架構達到了 94.8% 的註釋成功率。實驗結果顯示，在這個資料集上訓練的模型，與零次學習模型相比，準確度提高了 18 個百分點。此外，語意標記化方法比訓練基準線提高了 5 個百分點的準確度。

##### **Are LLMs Good Literature Review Writers? Evaluating the Literature Review Writing Ability of Large Language Models**
2412.13612v1 by Xuemei Tang, Xufeng Duan, Zhenguang G. Cai

The literature review is a crucial form of academic writing that involves
complex processes of literature collection, organization, and summarization.
The emergence of large language models (LLMs) has introduced promising tools to
automate these processes. However, their actual capabilities in writing
comprehensive literature reviews remain underexplored, such as whether they can
generate accurate and reliable references. To address this gap, we propose a
framework to assess the literature review writing ability of LLMs
automatically. We evaluate the performance of LLMs across three tasks:
generating references, writing abstracts, and writing literature reviews. We
employ external tools for a multidimensional evaluation, which includes
assessing hallucination rates in references, semantic coverage, and factual
consistency with human-written context. By analyzing the experimental results,
we find that, despite advancements, even the most sophisticated models still
cannot avoid generating hallucinated references. Additionally, different models
exhibit varying performance in literature review writing across different
disciplines.

摘要：文獻回顧是學術寫作中至關重要的一種形式，它涉及文獻收集、組織和摘要的複雜過程。大型語言模型 (LLM) 的出現引入了有望自動化這些過程的工具。然而，它們在撰寫綜合文獻回顧中的實際能力仍未得到充分探討，例如它們是否能產生準確且可靠的參考文獻。為了填補這一空白，我們提出了一個框架，以自動評估 LLM 的文獻回顧寫作能力。我們評估了 LLM 在三項任務中的表現：生成參考文獻、撰寫摘要和撰寫文獻回顧。我們採用外部工具進行多維評估，其中包括評估參考文獻中的幻覺率、語義覆蓋率以及與人寫語境的實際一致性。通過分析實驗結果，我們發現，儘管有進步，但即使是最複雜的模型仍然無法避免產生幻覺的參考文獻。此外，不同的模型在不同學科的文獻回顧寫作中表現出不同的表現。

##### **Beyond Outcomes: Transparent Assessment of LLM Reasoning in Games**
2412.13602v1 by Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han

Large Language Models (LLMs) are increasingly deployed in real-world
applications that demand complex reasoning. To track progress, robust
benchmarks are required to evaluate their capabilities beyond superficial
pattern recognition. However, current LLM reasoning benchmarks often face
challenges such as insufficient interpretability, performance saturation or
data contamination. To address these challenges, we introduce GAMEBoT, a gaming
arena designed for rigorous and transparent assessment of LLM reasoning
capabilities. GAMEBoT decomposes complex reasoning in games into predefined
modular subproblems. This decomposition allows us to design a suite of
Chain-of-Thought (CoT) prompts that leverage domain knowledge to guide LLMs in
addressing these subproblems before action selection. Furthermore, we develop a
suite of rule-based algorithms to generate ground truth for these subproblems,
enabling rigorous validation of the LLMs' intermediate reasoning steps. This
approach facilitates evaluation of both the quality of final actions and the
accuracy of the underlying reasoning process. GAMEBoT also naturally alleviates
the risk of data contamination through dynamic games and head-to-head LLM
competitions. We benchmark 17 prominent LLMs across eight games, encompassing
various strategic abilities and game characteristics. Our results suggest that
GAMEBoT presents a significant challenge, even when LLMs are provided with
detailed CoT prompts. Project page: \url{https://visual-ai.github.io/gamebot}

摘要：大型語言模型 (LLM)  zunehmend in realen Anwendungen eingesetzt, die komplexe Überlegungen erfordern. Um den Fortschritt zu verfolgen, sind robuste Benchmarks erforderlich, um ihre Fähigkeiten über die oberflächliche Mustererkennung hinaus zu bewerten. Allerdings stehen aktuelle LLM-Begründungs-Benchmarks oft vor Herausforderungen wie unzureichender Interpretierbarkeit, Leistungssättigung oder Datenkontamination. Um diese Herausforderungen anzugehen, stellen wir GAMEBoT vor, eine Spielarena, die für eine strenge und transparente Bewertung der LLM-Begründungsfähigkeiten entwickelt wurde. GAMEBoT zerlegt komplexe Überlegungen in Spielen in vordefinierte modulare Teilprobleme. Diese Zerlegung ermöglicht es uns, eine Reihe von Chain-of-Thought (CoT)-Eingabeaufforderungen zu entwerfen, die Domänenwissen nutzen, um LLMs bei der Lösung dieser Teilprobleme vor der Aktionsauswahl zu unterstützen. Darüber hinaus entwickeln wir eine Reihe regelbasierter Algorithmen, um eine Grundwahrheit für diese Teilprobleme zu generieren, die eine strenge Validierung der Zwischenbegründungsschritte der LLMs ermöglicht. Dieser Ansatz erleichtert die Bewertung sowohl der Qualität der endgültigen Aktionen als auch der Genauigkeit des zugrunde liegenden Begründungsprozesses. GAMEBoT verringert außerdem auf natürliche Weise das Risiko einer Datenkontamination durch dynamische Spiele und Kopf-an-Kopf-LLM-Wettbewerbe. Wir vergleichen 17 herausragende LLMs in acht Spielen, die verschiedene strategische Fähigkeiten und Spieleigenschaften umfassen. Unsere Ergebnisse deuten darauf hin, dass GAMEBoT eine erhebliche Herausforderung darstellt, selbst wenn LLMs mit detaillierten CoT-Eingabeaufforderungen versehen werden. Projektseite: \url{https://visual-ai.github.io/gamebot}

##### **Hybrid CNN-LSTM based Indoor Pedestrian Localization with CSI Fingerprint Maps**
2412.13601v1 by Muhammad Emad-ud-din

The paper presents a novel Wi-Fi fingerprinting system that uses Channel
State Information (CSI) data for fine-grained pedestrian localization. The
proposed system exploits the frequency diversity and spatial diversity of the
features extracted from CSI data to generate a 2D+channel image termed as a CSI
Fingerprint Map. We then use this CSI Fingerprint Map representation of CSI
data to generate a pedestrian trajectory hypothesis using a hybrid architecture
that combines a Convolutional Neural Network and a Long Short-Term Memory
Recurrent Neural Network model. The proposed architecture exploits the temporal
and spatial relationship information among the CSI data observations gathered
at neighboring locations. A particle filter is then employed to separate out
the most likely hypothesis matching a human walk model. The experimental
performance of our method is compared to existing deep learning localization
methods such ConFi, DeepFi and to a self-developed temporal-feature based LSTM
based location classifier. The experimental results show marked improvement
with an average RMSE of 0.36 m in a moderately dynamic and 0.17 m in a static
environment. Our method is essentially a proof of concept that with (1) sparse
availability of observations, (2) limited infrastructure requirements, (3)
moderate level of short-term and long-term noise in the training and testing
environment, reliable fine-grained Wi-Fi based pedestrian localization is a
potential option.

摘要：本文提出了一個創新的 Wi-Fi 指紋辨識系統，它使用頻道狀態資訊 (CSI) 資料進行精確的行人定位。所提出的系統利用從 CSI 資料中提取特徵的頻率多樣性和空間多樣性，以產生稱為 CSI 指紋圖的 2D+ 頻道影像。我們接著使用這個 CSI 指紋圖的 CSI 資料表示，以產生一個行人軌跡假設，使用結合卷積神經網路和長期短期記憶遞迴神經網路模型的混合架構。所提出的架構利用在鄰近位置收集的 CSI 資料觀測之間的時間和空間關係資訊。接著使用粒子濾波器來分離出最有可能與人類行走模型相符的假設。我們的方法的實驗效能與現有的深度學習定位方法（例如 ConFi、DeepFi）和自開發的基於時間特徵的 LSTM 定位分類器進行比較。實驗結果顯示顯著的改善，在中等動態環境中平均 RMSE 為 0.36 公尺，在靜態環境中為 0.17 公尺。我們的這個方法基本上是一個概念驗證，它證明了 (1) 觀測的稀疏可用性、(2) 有限的基礎設施需求、(3) 訓練和測試環境中短期和長期雜訊的適度程度，可靠的精確 Wi-Fi 行人定位是一個潛在的選項。

##### **Unlocking the Potential of Weakly Labeled Data: A Co-Evolutionary Learning Framework for Abnormality Detection and Report Generation**
2412.13599v1 by Jinghan Sun, Dong Wei, Zhe Xu, Donghuan Lu, Hong Liu, Hong Wang, Sotirios A. Tsaftaris, Steven McDonagh, Yefeng Zheng, Liansheng Wang

Anatomical abnormality detection and report generation of chest X-ray (CXR)
are two essential tasks in clinical practice. The former aims at localizing and
characterizing cardiopulmonary radiological findings in CXRs, while the latter
summarizes the findings in a detailed report for further diagnosis and
treatment. Existing methods often focused on either task separately, ignoring
their correlation. This work proposes a co-evolutionary abnormality detection
and report generation (CoE-DG) framework. The framework utilizes both fully
labeled (with bounding box annotations and clinical reports) and weakly labeled
(with reports only) data to achieve mutual promotion between the abnormality
detection and report generation tasks. Specifically, we introduce a
bi-directional information interaction strategy with generator-guided
information propagation (GIP) and detector-guided information propagation
(DIP). For semi-supervised abnormality detection, GIP takes the informative
feature extracted by the generator as an auxiliary input to the detector and
uses the generator's prediction to refine the detector's pseudo labels. We
further propose an intra-image-modal self-adaptive non-maximum suppression
module (SA-NMS). This module dynamically rectifies pseudo detection labels
generated by the teacher detection model with high-confidence predictions by
the student.Inversely, for report generation, DIP takes the abnormalities'
categories and locations predicted by the detector as input and guidance for
the generator to improve the generated reports.

摘要：胸部 X 光片 (CXR) 的解剖異常偵測與報告生成在臨床實務中有兩個重要的任務。前者旨在定位和描述 CXR 中的心肺放射線學發現，而後者則在詳細報告中總結發現，以利進一步診斷和治療。現有的方法通常專注於單獨的任務，而忽略了它們之間的關聯性。本研究提出了一種協同演化異常偵測與報告生成 (CoE-DG) 架構。此架構同時利用完全標記（包含邊界框標註和臨床報告）和弱標記（僅包含報告）的資料，以達成異常偵測與報告生成任務之間的相互促進。具體來說，我們引入了一個具有生成器引導資訊傳遞 (GIP) 和偵測器引導資訊傳遞 (DIP) 的雙向資訊互動策略。對於半監督異常偵測，GIP 將生成器提取的資訊特徵作為偵測器的輔助輸入，並使用生成器的預測來改善偵測器的偽標籤。我們進一步提出了一個影像內模態自適應非極大值抑制模組 (SA-NMS)。此模組會根據學生具有高信心預測的偽偵測標籤，動態修正由教師偵測模型產生的偽偵測標籤。反之，對於報告生成，DIP 將偵測器預測的異常類別和位置作為生成器的輸入和指引，以改善生成的報告。

##### **Generalizable Sensor-Based Activity Recognition via Categorical Concept Invariant Learning**
2412.13594v1 by Di Xiong, Shuoyuan Wang, Lei Zhang, Wenbo Huang, Chaolei Han

Human Activity Recognition (HAR) aims to recognize activities by training
models on massive sensor data. In real-world deployment, a crucial aspect of
HAR that has been largely overlooked is that the test sets may have different
distributions from training sets due to inter-subject variability including
age, gender, behavioral habits, etc., which leads to poor generalization
performance. One promising solution is to learn domain-invariant
representations to enable a model to generalize on an unseen distribution.
However, most existing methods only consider the feature-invariance of the
penultimate layer for domain-invariant learning, which leads to suboptimal
results. In this paper, we propose a Categorical Concept Invariant Learning
(CCIL) framework for generalizable activity recognition, which introduces a
concept matrix to regularize the model in the training stage by simultaneously
concentrating on feature-invariance and logit-invariance. Our key idea is that
the concept matrix for samples belonging to the same activity category should
be similar. Extensive experiments on four public HAR benchmarks demonstrate
that our CCIL substantially outperforms the state-of-the-art approaches under
cross-person, cross-dataset, cross-position, and one-person-to-another
settings.

摘要：人類活動識別 (HAR) 旨在透過在大量感測器資料上訓練模型來辨識活動。在實際部署中，HAR 的一個關鍵面向在很大程度上被忽略了，那就是測試集可能與訓練集有不同的分佈，這是由於包括年齡、性別、行為習慣等在內的個體間變異所導致的，這會造成不佳的概化效能。一個有希望的解決方案是學習領域不變表示，以使模型能夠在未見過的分佈上進行概化。然而，現有的大部分方法只考慮倒數第二層的特性不變性來進行領域不變學習，這會導致次佳結果。在本文中，我們提出一個類別概念不變學習 (CCIL) 架構，用於可概化的活動識別，它引入一個概念矩陣，以在訓練階段透過同時專注於特性不變性和 logit 不變性來規範模型。我們的關鍵想法是，屬於相同活動類別的樣本的概念矩陣應該是相似的。在四個公開 HAR 基準上進行的廣泛實驗證明，我們的 CCIL 在跨人、跨資料集、跨位置和一人對另一人設定下，大幅優於最先進的方法。

##### **SemiDFL: A Semi-Supervised Paradigm for Decentralized Federated Learning**
2412.13589v1 by Xinyang Liu, Pengchao Han, Xuan Li, Bo Liu

Decentralized federated learning (DFL) realizes cooperative model training
among connected clients without relying on a central server, thereby mitigating
communication bottlenecks and eliminating the single-point failure issue
present in centralized federated learning (CFL). Most existing work on DFL
focuses on supervised learning, assuming each client possesses sufficient
labeled data for local training. However, in real-world applications, much of
the data is unlabeled. We address this by considering a challenging yet
practical semisupervised learning (SSL) scenario in DFL, where clients may have
varying data sources: some with few labeled samples, some with purely unlabeled
data, and others with both. In this work, we propose SemiDFL, the first
semi-supervised DFL method that enhances DFL performance in SSL scenarios by
establishing a consensus in both data and model spaces. Specifically, we
utilize neighborhood information to improve the quality of pseudo-labeling,
which is crucial for effectively leveraging unlabeled data. We then design a
consensusbased diffusion model to generate synthesized data, which is used in
combination with pseudo-labeled data to create mixed datasets. Additionally, we
develop an adaptive aggregation method that leverages the model accuracy of
synthesized data to further enhance SemiDFL performance. Through extensive
experimentation, we demonstrate the remarkable performance superiority of the
proposed DFL-Semi method over existing CFL and DFL schemes in both IID and
non-IID SSL scenarios.

摘要：分散式聯合學習 (DFL) 讓連線的用戶端在不依賴中央伺服器的情況下實現協作模型訓練，進而減輕通訊瓶頸並消除集中式聯合學習 (CFL) 中存在的單點故障問題。現有關於 DFL 的研究大多著重於監督式學習，假設每個用戶端都擁有足夠的標籤資料，可進行本地訓練。然而，在實際應用中，大部分資料都是未標籤的。我們透過考量 DFL 中具有挑戰性但實用的半監督式學習 (SSL) 情境來解決這個問題，在該情境中，用戶端可能擁有不同的資料來源：有些標籤範例很少，有些只有純未標籤資料，而有些則兩者都有。在這項研究中，我們提出 SemiDFL，這是第一個半監督式 DFL 方法，透過在資料和模型空間中建立共識來增強 DFL 在 SSL 情境中的效能。具體來說，我們利用鄰域資訊來提升偽標籤的品質，這對於有效利用未標籤資料至關重要。然後，我們設計一個基於共識的擴散模型來產生合成資料，並與偽標籤資料結合使用，以建立混合資料集。此外，我們開發了一種自適應聚合方法，利用合成資料的模型準確度進一步提升 SemiDFL 的效能。透過廣泛的實驗，我們證明了所提出的 DFL-Semi 方法在 IID 和非 IID SSL 情境中均優於現有的 CFL 和 DFL 方案，效能極為優異。

##### **EvoWiki: Evaluating LLMs on Evolving Knowledge**
2412.13582v1 by Wei Tang, Yixin Cao, Yang Deng, Jiahao Ying, Bo Wang, Yizhe Yang, Yuyue Zhao, Qi Zhang, Xuanjing Huang, Yugang Jiang, Yong Liao

Knowledge utilization is a critical aspect of LLMs, and understanding how
they adapt to evolving knowledge is essential for their effective deployment.
However, existing benchmarks are predominantly static, failing to capture the
evolving nature of LLMs and knowledge, leading to inaccuracies and
vulnerabilities such as contamination. In this paper, we introduce EvoWiki, an
evolving dataset designed to reflect knowledge evolution by categorizing
information into stable, evolved, and uncharted states. EvoWiki is fully
auto-updatable, enabling precise evaluation of continuously changing knowledge
and newly released LLMs. Through experiments with Retrieval-Augmented
Generation (RAG) and Contunual Learning (CL), we evaluate how effectively LLMs
adapt to evolving knowledge. Our results indicate that current models often
struggle with evolved knowledge, frequently providing outdated or incorrect
responses. Moreover, the dataset highlights a synergistic effect between RAG
and CL, demonstrating their potential to better adapt to evolving knowledge.
EvoWiki provides a robust benchmark for advancing future research on the
knowledge evolution capabilities of large language models.

摘要：知識利用是 LLM 的一個關鍵面向，而了解它們如何適應不斷演化的知識對於其有效部署至關重要。然而，現有的基準測試主要都是靜態的，無法捕捉 LLM 和知識的演化本質，導致不準確和漏洞，例如污染。在本文中，我們介紹了 EvoWiki，這是一個旨在反映知識演化的演化數據集，它將資訊分類為穩定、演化和未知狀態。EvoWiki 具有完全自動更新的功能，能夠精確評估持續變化的知識和新發布的 LLM。透過檢索增強生成 (RAG) 和持續學習 (CL) 的實驗，我們評估了 LLM 如何有效適應不斷演化的知識。我們的結果表明，目前的模型經常難以應付演化的知識，經常提供過時或不正確的回應。此外，該數據集突顯了 RAG 和 CL 之間的協同效應，證明了它們在更好地適應不斷演化的知識方面的潛力。EvoWiki 為推進未來有關大型語言模型知識演化能力的研究提供了強健的基準測試。

