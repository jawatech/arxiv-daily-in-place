{"2409.05076": {"publish_time": "2024-09-08", "title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions", "paper_summary": "Large Vision-Language Models (LVLMs) have demonstrated their powerful\nmultimodal capabilities. However, they also face serious safety problems, as\nadversaries can induce robustness issues in LVLMs through the use of\nwell-designed adversarial examples. Therefore, LVLMs are in urgent need of\ndetection tools for adversarial examples to prevent incorrect responses. In\nthis work, we first discover that LVLMs exhibit regular attention patterns for\nclean images when presented with probe questions. We propose an unconventional\nmethod named PIP, which utilizes the attention patterns of one randomly\nselected irrelevant probe question (e.g., \"Is there a clock?\") to distinguish\nadversarial examples from clean examples. Regardless of the image to be tested\nand its corresponding question, PIP only needs to perform one additional\ninference of the image to be tested and the probe question, and then achieves\nsuccessful detection of adversarial examples. Even under black-box attacks and\nopen dataset scenarios, our PIP, coupled with a simple SVM, still achieves more\nthan 98% recall and a precision of over 90%. Our PIP is the first attempt to\ndetect adversarial attacks on LVLMs via simple irrelevant probe questions,\nshedding light on deeper understanding and introspection within LVLMs. The code\nis available at https://github.com/btzyd/pip.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5df2\u5c55\u73fe\u5176\u5f37\u5927\u7684\u591a\u6a21\u614b\u80fd\u529b\u3002\u7136\u800c\uff0c\u5b83\u5011\u4e5f\u9762\u81e8\u56b4\u91cd\u7684\u5b89\u5168\u554f\u984c\uff0c\u56e0\u70ba\u5c0d\u624b\u53ef\u4ee5\u900f\u904e\u4f7f\u7528\u7cbe\u5fc3\u8a2d\u8a08\u7684\u5c0d\u6297\u7bc4\u4f8b\uff0c\u5728 LVLMs \u4e2d\u5f15\u767c\u5065\u5168\u6027\u554f\u984c\u3002\u56e0\u6b64\uff0cLVLMs \u8feb\u5207\u9700\u8981\u5c0d\u6297\u7bc4\u4f8b\u7684\u5075\u6e2c\u5de5\u5177\uff0c\u4ee5\u9632\u6b62\u4e0d\u6b63\u78ba\u7684\u56de\u61c9\u3002\u5728\u6b64\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u9996\u5148\u767c\u73fe\u7576 LVLMs \u9762\u5c0d\u63a2\u6e2c\u554f\u984c\u6642\uff0c\u5b83\u5011\u6703\u5c0d\u4e7e\u6de8\u7684\u5f71\u50cf\u5c55\u73fe\u898f\u5f8b\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u540d\u70ba PIP \u7684\u975e\u5e38\u898f\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u4e00\u500b\u96a8\u6a5f\u9078\u64c7\u7684\u4e0d\u76f8\u95dc\u63a2\u6e2c\u554f\u984c\uff08\u4f8b\u5982\u300c\u90a3\u88e1\u6709\u9418\u55ce\uff1f\u300d\uff09\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u4f86\u5340\u5206\u5c0d\u6297\u7bc4\u4f8b\u8207\u4e7e\u6de8\u7bc4\u4f8b\u3002\u7121\u8ad6\u8981\u6e2c\u8a66\u7684\u5f71\u50cf\u53ca\u5176\u5c0d\u61c9\u554f\u984c\u70ba\u4f55\uff0cPIP \u53ea\u9700\u8981\u5c0d\u8981\u6e2c\u8a66\u7684\u5f71\u50cf\u548c\u63a2\u6e2c\u554f\u984c\u57f7\u884c\u4e00\u6b21\u984d\u5916\u7684\u63a8\u8ad6\uff0c\u7136\u5f8c\u5c31\u80fd\u6210\u529f\u5075\u6e2c\u5c0d\u6297\u7bc4\u4f8b\u3002\u5373\u4f7f\u5728\u9ed1\u76d2\u653b\u64ca\u548c\u958b\u653e\u8cc7\u6599\u96c6\u5834\u666f\u4e0b\uff0c\u6211\u5011\u7684 PIP \u7d50\u5408\u4e00\u500b\u7c21\u55ae\u7684 SVM\uff0c\u4ecd\u53ef\u9054\u5230\u8d85\u904e 98% \u7684\u53ec\u56de\u7387\u548c\u8d85\u904e 90% \u7684\u7cbe\u78ba\u5ea6\u3002\u6211\u5011\u7684 PIP \u662f\u7b2c\u4e00\u500b\u5617\u8a66\u900f\u904e\u7c21\u55ae\u7684\u4e0d\u76f8\u95dc\u63a2\u6e2c\u554f\u984c\u4f86\u5075\u6e2c LVLMs \u4e0a\u7684\u5c0d\u6297\u653b\u64ca\uff0c\u70ba LVLMs \u4e2d\u66f4\u6df1\u5165\u7684\u7406\u89e3\u548c\u5167\u7701\u63d0\u4f9b\u4e86\u555f\u767c\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/btzyd/pip \u53d6\u5f97\u3002", "author": "Yudong Zhang et.al.", "authors": "Yudong Zhang, Ruobing Xie, Jiansheng Chen, Xingwu Sun, Yu Wang", "id": "2409.05076v1", "paper_url": "http://arxiv.org/abs/2409.05076v1", "repo": "null"}}