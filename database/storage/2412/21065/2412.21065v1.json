{"2412.21065": {"publish_time": "2024-12-30", "title": "Efficient Multi-Task Inferencing with a Shared Backbone and Lightweight Task-Specific Adapters for Automatic Scoring", "paper_summary": "The integration of Artificial Intelligence (AI) in education requires\nscalable and efficient frameworks that balance performance, adaptability, and\ncost. This paper addresses these needs by proposing a shared backbone model\narchitecture enhanced with lightweight LoRA adapters for task-specific\nfine-tuning, targeting the automated scoring of student responses across 27\nmutually exclusive tasks. By achieving competitive performance (average QWK of\n0.848 compared to 0.888 for fully fine-tuned models) while reducing GPU memory\nconsumption by 60% and inference latency by 40%, the framework demonstrates\nsignificant efficiency gains. This approach aligns with the workshops' focus on\nimproving language models for educational tasks, creating responsible\ninnovations for cost-sensitive deployment, and supporting educators by\nstreamlining assessment workflows. The findings underscore the potential of\nscalable AI to enhance learning outcomes while maintaining fairness and\ntransparency in automated scoring systems.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167\uff08AI\uff09\u5728\u6559\u80b2\u4e2d\u7684\u6574\u5408\u9700\u8981\u53ef\u64f4\u5145\u4e14\u6709\u6548\u7387\u7684\u67b6\u69cb\uff0c\u4ee5\u5e73\u8861\u6548\u80fd\u3001\u9069\u61c9\u6027\u548c\u6210\u672c\u3002\u672c\u6587\u900f\u904e\u63d0\u51fa\u4e00\u500b\u5171\u540c\u7684\u9aa8\u5e79\u6a21\u578b\u67b6\u69cb\u4f86\u89e3\u6c7a\u9019\u4e9b\u9700\u6c42\uff0c\u4e26\u900f\u904e\u8f15\u91cf\u5316\u7684 LoRA \u9069\u914d\u5668\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u9032\u884c\u5fae\u8abf\uff0c\u76ee\u6a19\u662f\u81ea\u52d5\u8a55\u5206\u5b78\u751f\u5728 27 \u500b\u76f8\u4e92\u6392\u65a5\u7684\u4efb\u52d9\u4e2d\u7684\u56de\u61c9\u3002\u900f\u904e\u9054\u6210\u5177\u7af6\u722d\u529b\u7684\u6548\u80fd\uff08\u8207\u7d93\u904e\u5b8c\u5168\u5fae\u8abf\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u5e73\u5747 QWK \u70ba 0.848\uff0c\u800c\u5f8c\u8005\u70ba 0.888\uff09\uff0c\u540c\u6642\u5c07 GPU \u8a18\u61b6\u9ad4\u6d88\u8017\u6e1b\u5c11 60%\uff0c\u4e26\u5c07\u63a8\u8ad6\u5ef6\u9072\u6e1b\u5c11 40%\uff0c\u6b64\u67b6\u69cb\u5c55\u793a\u4e86\u986f\u8457\u7684\u6548\u7387\u63d0\u5347\u3002\u9019\u7a2e\u65b9\u6cd5\u7b26\u5408\u5de5\u4f5c\u574a\u7684\u91cd\u9ede\uff0c\u5373\u6539\u5584\u6559\u80b2\u4efb\u52d9\u7684\u8a9e\u8a00\u6a21\u578b\u3001\u70ba\u6210\u672c\u654f\u611f\u7684\u90e8\u7f72\u5275\u9020\u8ca0\u8cac\u4efb\u7684\u5275\u65b0\uff0c\u4ee5\u53ca\u900f\u904e\u7c21\u5316\u8a55\u91cf\u5de5\u4f5c\u6d41\u7a0b\u4f86\u652f\u63f4\u6559\u80b2\u5de5\u4f5c\u8005\u3002\u9019\u4e9b\u767c\u73fe\u5f37\u8abf\u4e86\u53ef\u64f4\u5145 AI \u5728\u63d0\u5347\u5b78\u7fd2\u6210\u679c\u65b9\u9762\u7684\u6f5b\u529b\uff0c\u540c\u6642\u5728\u81ea\u52d5\u8a55\u5206\u7cfb\u7d71\u4e2d\u7dad\u6301\u516c\u5e73\u6027\u548c\u900f\u660e\u5ea6\u3002", "author": "Ehsan Latif et.al.", "authors": "Ehsan Latif, Xiaoming Zhai", "id": "2412.21065v1", "paper_url": "http://arxiv.org/abs/2412.21065v1", "repo": "null"}}