# arxiv-daily
 Automated deployment @ 2024-08-04 20:32:24 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-01**|**DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**|Guillermo Villar-Rodríguez et.al.|[2408.00633v1](http://arxiv.org/abs/2408.00633v1)|null|
|**2024-08-01**|**On the Limitations and Prospects of Machine Unlearning for Generative AI**|Shiji Zhou et.al.|[2408.00376v1](http://arxiv.org/abs/2408.00376v1)|null|
|**2024-08-01**|**Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**|Bin Cheng et.al.|[2408.00290v1](http://arxiv.org/abs/2408.00290v1)|null|
|**2024-07-31**|**CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**|Stefan Langer et.al.|[2407.21708v1](http://arxiv.org/abs/2407.21708v1)|null|
|**2024-07-31**|**eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**|Xiny Pan et.al.|[2407.21483v2](http://arxiv.org/abs/2407.21483v2)|null|
|**2024-07-31**|**Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**|Haodong Hong et.al.|[2407.21452v1](http://arxiv.org/abs/2407.21452v1)|null|
|**2024-07-31**|**Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**|Elan Markowitz et.al.|[2407.21358v1](http://arxiv.org/abs/2407.21358v1)|null|
|**2024-07-31**|**SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**|Peiru Zheng et.al.|[2407.21293v1](http://arxiv.org/abs/2407.21293v1)|null|
|**2024-07-30**|**Be aware of overfitting by hyperparameter optimization!**|Igor V. Tetko et.al.|[2407.20786v1](http://arxiv.org/abs/2407.20786v1)|null|
|**2024-07-30**|**Harvesting Textual and Structured Data from the HAL Publication Repository**|Francis Kulumba et.al.|[2407.20595v1](http://arxiv.org/abs/2407.20595v1)|null|
|**2024-07-30**|**CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**|Tianshi Zheng et.al.|[2407.20564v1](http://arxiv.org/abs/2407.20564v1)|null|
|**2024-07-30**|**Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**|Hossein Rajaby Faghihi et.al.|[2407.20513v1](http://arxiv.org/abs/2407.20513v1)|null|
|**2024-07-29**|**What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**|Navapat Nananukul et.al.|[2407.20382v1](http://arxiv.org/abs/2407.20382v1)|null|
|**2024-07-29**|**MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**|Zehui Chen et.al.|[2407.20183v1](http://arxiv.org/abs/2407.20183v1)|[link](https://github.com/internlm/mindsearch)|
|**2024-07-29**|**rLLM: Relational Table Learning with LLMs**|Weichen Li et.al.|[2407.20157v1](http://arxiv.org/abs/2407.20157v1)|[link](https://github.com/rllm-project/rllm)|
|**2024-07-29**|**Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**|Yunsheng Wang et.al.|[2407.19643v2](http://arxiv.org/abs/2407.19643v2)|[link](https://github.com/iamryanshengwang/prometheus-chatbot)|
|**2024-07-29**|**TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**|Selma Wanna et.al.|[2407.19616v1](http://arxiv.org/abs/2407.19616v1)|null|
|**2024-07-27**|**Semantic Communication Enhanced by Knowledge Graph Representation Learning**|Nour Hello et.al.|[2407.19338v1](http://arxiv.org/abs/2407.19338v1)|null|
|**2024-07-26**|**GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**|Yuchen Shen et.al.|[2407.19039v1](http://arxiv.org/abs/2407.19039v1)|null|
|**2024-07-26**|**Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**|Yuni Susanti et.al.|[2407.18752v3](http://arxiv.org/abs/2407.18752v3)|[link](https://github.com/littleflow3r/kg-structure-as-prompt)|
|**2024-07-26**|**Using GPT-4 to guide causal machine learning**|Anthony C. Constantinou et.al.|[2407.18607v1](http://arxiv.org/abs/2407.18607v1)|null|
|**2024-07-26**|**Multi-turn Response Selection with Commonsense-enhanced Language Models**|Yuandong Wang et.al.|[2407.18479v1](http://arxiv.org/abs/2407.18479v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|[link](https://github.com/emergenceai/mathviz-e)|
|**2024-07-23**|**Ranking protein-protein models with large language models and graph neural networks**|Xiaotong Xu et.al.|[2407.16375v1](http://arxiv.org/abs/2407.16375v1)|[link](https://github.com/haddocking/deeprank-gnn-esm)|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Graph-Structured Speculative Decoding**|Zhuocheng Gong et.al.|[2407.16207v1](http://arxiv.org/abs/2407.16207v1)|null|
|**2024-07-23**|**Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**|Yannick Assogba et.al.|[2407.21049v1](http://arxiv.org/abs/2407.21049v1)|null|
|**2024-07-23**|**Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**|Yang Liu et.al.|[2407.16127v1](http://arxiv.org/abs/2407.16127v1)|[link](https://github.com/nju-websoft/dift)|
|**2024-07-22**|**Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**|Soojin Yoon et.al.|[2407.15588v1](http://arxiv.org/abs/2407.15588v1)|[link](https://github.com/eralign/eralign)|
|**2024-07-22**|**Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**|Huanjing Zhao et.al.|[2407.15431v1](http://arxiv.org/abs/2407.15431v1)|null|
|**2024-07-22**|**LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**|Jiaxing Zhang et.al.|[2407.15351v2](http://arxiv.org/abs/2407.15351v2)|null|
|**2024-07-21**|**Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**|Yu Zhang et.al.|[2407.15141v1](http://arxiv.org/abs/2407.15141v1)|null|
|**2024-07-20**|**On the Design and Analysis of LLM-Based Algorithms**|Yanxi Chen et.al.|[2407.14788v1](http://arxiv.org/abs/2407.14788v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-19**|**LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**|Chen-Chia Chang et.al.|[2407.18269v1](http://arxiv.org/abs/2407.18269v1)|null|
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-18**|**MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**|Guoli Yin et.al.|[2407.18961v2](http://arxiv.org/abs/2407.18961v2)|[link](https://github.com/apple/axlearn)|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v3](http://arxiv.org/abs/2407.12703v3)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**|Kai Guo et.al.|[2407.12068v2](http://arxiv.org/abs/2407.12068v2)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v2](http://arxiv.org/abs/2407.11393v2)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v1](http://arxiv.org/abs/2407.10805v1)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|[link](https://github.com/lighteternal/farfetched_nlp)|
|**2024-07-12**|**GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**|Lecheng Kong et.al.|[2407.09709v1](http://arxiv.org/abs/2407.09709v1)|[link](https://github.com/jiaruifeng/gofa)|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**The $μ\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v3](http://arxiv.org/abs/2407.08516v3)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v2](http://arxiv.org/abs/2407.07775v2)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**|Aaron Zolnai-Lucas et.al.|[2407.12860v1](http://arxiv.org/abs/2407.12860v1)|[link](https://github.com/aaronzo/STAGE)|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-09**|**FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**|Yi Zhan et.al.|[2407.14530v1](http://arxiv.org/abs/2407.14530v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**Knowledge-based Consistency Testing of Large Language Models**|Sai Sathiesh Rajan et.al.|[2407.12830v1](http://arxiv.org/abs/2407.12830v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v2](http://arxiv.org/abs/2407.01406v2)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v2](http://arxiv.org/abs/2407.01245v2)|null|
|**2024-07-01**|**Revisiting Random Walks for Learning on Graphs**|Jinwoo Kim et.al.|[2407.01214v1](http://arxiv.org/abs/2407.01214v1)|[link](https://github.com/jw9730/random-walk)|
|**2024-07-01**|**LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**|Longchao Da et.al.|[2407.00994v2](http://arxiv.org/abs/2407.00994v2)|null|
|**2024-06-30**|**Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**|Romy Fieblinger et.al.|[2407.02528v1](http://arxiv.org/abs/2407.02528v1)|null|
|**2024-06-30**|**Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**|Yifei Zhang et.al.|[2407.00653v1](http://arxiv.org/abs/2407.00653v1)|null|
|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466v1](http://arxiv.org/abs/2407.00466v1)|[link](https://github.com/westlake-autolab/biokgbench.github.io)|
|**2024-06-29**|**GraphArena: Benchmarking Large Language Models on Graph Computational Problems**|Jianheng Tang et.al.|[2407.00379v1](http://arxiv.org/abs/2407.00379v1)|[link](https://github.com/squareroot3/grapharena)|
|**2024-06-29**|**Teola: Towards End-to-End Optimization of LLM-based Applications**|Xin Tan et.al.|[2407.00326v1](http://arxiv.org/abs/2407.00326v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|

#### Abstracts
##### **DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**
2408.00633v1 by Guillermo Villar-Rodríguez, Álvaro Huertas-García, Alejandro Martín, Javier Huertas-Tato, David Camacho

Introduction: This article introduces DisTrack, a methodology and a tool
developed for tracking and analyzing misinformation within Online Social
Networks (OSNs). DisTrack is designed to combat the spread of misinformation
through a combination of Natural Language Processing (NLP) Social Network
Analysis (SNA) and graph visualization. The primary goal is to detect
misinformation, track its propagation, identify its sources, and assess the
influence of various actors within the network.
  Methods: DisTrack's architecture incorporates a variety of methodologies
including keyword search, semantic similarity assessments, and graph generation
techniques. These methods collectively facilitate the monitoring of
misinformation, the categorization of content based on alignment with known
false claims, and the visualization of dissemination cascades through detailed
graphs. The tool is tailored to capture and analyze the dynamic nature of
misinformation spread in digital environments.
  Results: The effectiveness of DisTrack is demonstrated through three case
studies focused on different themes: discredit/hate speech, anti-vaccine
misinformation, and false narratives about the Russia-Ukraine conflict. These
studies show DisTrack's capabilities in distinguishing posts that propagate
falsehoods from those that counteract them, and tracing the evolution of
misinformation from its inception.
  Conclusions: The research confirms that DisTrack is a valuable tool in the
field of misinformation analysis. It effectively distinguishes between
different types of misinformation and traces their development over time. By
providing a comprehensive approach to understanding and combating
misinformation in digital spaces, DisTrack proves to be an essential asset for
researchers and practitioners working to mitigate the impact of false
information in online social environments.

摘要：<paragraph>引言：本文介紹 DisTrack，這是一種方法和工具，用於追蹤和分析線上社交網路（OSN）中的錯誤資訊。DisTrack 的設計目的是透過結合自然語言處理（NLP）、社交網路分析（SNA）和圖形視覺化來對抗錯誤資訊的散布。主要目標是偵測錯誤資訊、追蹤其傳播、找出其來源，並評估網路中各個參與者的影響力。
方法：DisTrack 的架構結合了多種方法，包括關鍵字搜尋、語意相似性評估和圖形產生技術。這些方法共同促進了錯誤資訊的監控、基於與已知虛假說法的比對來分類內容，以及透過詳細圖形視覺化傳播層疊。此工具經過量身打造，用於擷取和分析數位環境中錯誤資訊散布的動態特性。
結果：DisTrack 的效能透過三個案例研究獲得驗證，這些研究專注於不同的主題：貶低/仇恨言論、反疫苗錯誤資訊，以及關於俄羅斯-烏克蘭衝突的虛假敘述。這些研究顯示出 DisTrack 在區分傳播虛假資訊和反制虛假資訊的貼文，以及追蹤錯誤資訊從其開端演變的過程中所具備的能力。
結論：研究證實 DisTrack 是錯誤資訊分析領域中一個有價值的工具。它有效區分了不同類型的錯誤資訊，並追蹤其隨著時間推移的發展。透過提供一種全面的方法來理解和對抗數位空間中的錯誤資訊，DisTrack 證明了自己是協助研究人員和實務工作者減輕線上社交環境中虛假資訊影響力的重要資產。</paragraph>

##### **On the Limitations and Prospects of Machine Unlearning for Generative AI**
2408.00376v1 by Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang

Generative AI (GenAI), which aims to synthesize realistic and diverse data
samples from latent variables or other data modalities, has achieved remarkable
results in various domains, such as natural language, images, audio, and
graphs. However, they also pose challenges and risks to data privacy, security,
and ethics. Machine unlearning is the process of removing or weakening the
influence of specific data samples or features from a trained model, without
affecting its performance on other data or tasks. While machine unlearning has
shown significant efficacy in traditional machine learning tasks, it is still
unclear if it could help GenAI become safer and aligned with human desire. To
this end, this position paper provides an in-depth discussion of the machine
unlearning approaches for GenAI. Firstly, we formulate the problem of machine
unlearning tasks on GenAI and introduce the background. Subsequently, we
systematically examine the limitations of machine unlearning on GenAI models by
focusing on the two representative branches: LLMs and image generative
(diffusion) models. Finally, we provide our prospects mainly from three
aspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and
conscientiously advocate for the future development of this field.

摘要：生成式 AI (GenAI) 旨在從潛在變數或其他資料模式中合成逼真且多樣化的資料範例，已在自然語言、影像、音訊和圖形等各種領域中取得顯著成果。然而，它們也對資料隱私、安全性與道德構成挑戰和風險。機器遺忘是移除或減弱特定資料範例或特徵對已訓練模型的影響，同時不影響其在其他資料或任務上的效能。雖然機器遺忘已在傳統機器學習任務中展現顯著的功效，但仍不清楚它是否能協助 GenAI 變得更安全且符合人類的期望。為此，本立場文件深入探討了 GenAI 的機器遺忘方法。首先，我們制定 GenAI 上機器遺忘任務的問題，並介紹背景。接著，我們有系統地檢視機器遺忘在 GenAI 模型上的限制，重點放在兩個代表性的分支：LLM 和影像生成（擴散）模型。最後，我們主要從基準、評估指標和效用遺忘權衡三個面向提供我們的展望，並審慎倡議該領域的未來發展。

##### **Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**
2408.00290v1 by Bin Cheng, Jiaxuan Lu

With the advent of the era of foundation models, pre-training and fine-tuning
have become common paradigms. Recently, parameter-efficient fine-tuning has
garnered widespread attention due to its better balance between the number of
learnable parameters and performance. However, some current parameter-efficient
fine-tuning methods only model a single modality and lack the utilization of
structural knowledge in downstream tasks. To address this issue, this paper
proposes a multi-modal parameter-efficient fine-tuning method based on graph
networks. Each image is fed into a multi-modal large language model (MLLM) to
generate a text description. The image and its corresponding text description
are then processed by a frozen image encoder and text encoder to generate image
features and text features, respectively. A graph is constructed based on the
similarity of the multi-modal feature nodes, and knowledge and relationships
relevant to these features are extracted from each node. Additionally, Elastic
Weight Consolidation (EWC) regularization is incorporated into the loss
function to mitigate the problem of forgetting during task learning. The
proposed model achieves test accuracies on the OxfordPets, Flowers102, and
Food101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The
code is available at https://github.com/yunche0/GA-Net/tree/master.

摘要：隨著基礎模型時代的到來，預訓練和微調已成為常見的範例。最近，由於參數有效微調在可學習參數數量和效能之間取得更好的平衡，因此備受關注。然而，一些目前的參數有效微調方法僅建模單一模態，且缺乏在下游任務中利用結構知識。為了解決此問題，本文提出了一種基於圖形網路的多模態參數有效微調方法。每個影像都會輸入到多模態大型語言模型 (MLLM) 中，以產生文字描述。然後，影像及其對應的文字描述會由凍結的影像編碼器和文字編碼器處理，分別產生影像特徵和文字特徵。根據多模態特徵節點的相似性建構一個圖形，並從每個節點中萃取出與這些特徵相關的知識和關係。此外，彈性權重整合 (EWC) 正則化會納入損失函數中，以減輕在任務學習期間遺忘的問題。所提出的模型在 OxfordPets、Flowers102 和 Food101 資料集上達成的測試準確度分別提升了 4.45%、2.92% 和 0.23%。程式碼可在 https://github.com/yunche0/GA-Net/tree/master 取得。

##### **CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**
2407.21708v1 by Stefan Langer, Fabian Neuhaus, Andreas Nürnberger

Ontologies are formal representations of knowledge in specific domains that
provide a structured framework for organizing and understanding complex
information. Creating ontologies, however, is a complex and time-consuming
endeavor. ChEBI is a well-known ontology in the field of chemistry, which
provides a comprehensive resource for defining chemical entities and their
properties. However, it covers only a small fraction of the rapidly growing
knowledge in chemistry and does not provide references to the scientific
literature. To address this, we propose a methodology that involves augmenting
existing annotated text corpora with knowledge from Chebi and fine-tuning a
large language model (LLM) to recognize chemical entities and their roles in
scientific text. Our experiments demonstrate the effectiveness of our approach.
By combining ontological knowledge and the language understanding capabilities
of LLMs, we achieve high precision and recall rates in identifying both the
chemical entities and roles in scientific literature. Furthermore, we extract
them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a
knowledge graph (KG) of chemical entities and roles (CEAR), which provides
complementary information to ChEBI, and can help to extend it.

摘要：本体是特定領域中知識的形式化表示，它提供了一個結構化的框架，用於組織和理解複雜的資訊。然而，建立本体是一項複雜且耗時的努力。ChEBI 是化學領域中一個著名的本体，它提供了一個全面的資源，用於定義化學實體及其屬性。然而，它僅涵蓋了化學領域快速增長的知識中的一小部分，並且沒有提供科學文獻的參考。為了解決這個問題，我們提出了一種方法，它涉及使用來自 Chebi 的知識擴充現有的註釋文本語料庫，並微調大型語言模型 (LLM)，以識別化學實體及其在科學文本中的作用。我們的實驗證明了我們方法的有效性。透過結合本体知識和 LLM 的語言理解能力，我們在識別科學文獻中的化學實體和作用方面達到了很高的準確度和召回率。此外，我們從一組 8,000 篇 ChemRxiv 文章中提取它們，並應用第二個 LLM 來建立一個化學實體和作用 (CEAR) 的知識圖譜 (KG)，它提供補充 ChEBI 的資訊，並有助於擴充它。

##### **eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**
2407.21483v2 by Xiny Pan, Daniel Hernández, Philipp Seifer, Ralf Lämmel, Steffen Staab

Over the past few years, we have seen the emergence of large knowledge graphs
combining information from multiple sources. Sometimes, this information is
provided in the form of assertions about other assertions, defining contexts
where assertions are valid. A recent extension to RDF which admits statements
over statements, called RDF-star, is in revision to become a W3C standard.
However, there is no proposal for a semantics of these RDF-star statements nor
a built-in facility to operate over them. In this paper, we propose a query
language for epistemic RDF-star metadata based on a four-valued logic, called
eSPARQL. Our proposed query language extends SPARQL-star, the query language
for RDF-star, with a new type of FROM clause to facilitate operating with
multiple and sometimes conflicting beliefs. We show that the proposed query
language can express four use case queries, including the following features:
(i) querying the belief of an individual, (ii) the aggregating of beliefs,
(iii) querying who is conflicting with somebody, and (iv) beliefs about beliefs
(i.e., nesting of beliefs).

摘要：在過去幾年，我們已經看到大型知識圖譜的出現，結合來自多個來源的資訊。有時，此資訊以對其他斷言的斷言形式提供，定義斷言有效的脈絡。RDF 的最新擴充允許對斷言進行陳述，稱為 RDF-star，目前正在修訂為 W3C 標準。然而，沒有針對這些 RDF-star 陳述的語義提出建議，也沒有內建的運作工具。在本文中，我們提出一個基於四值邏輯的知識 RDF-star 元資料查詢語言，稱為 eSPARQL。我們提出的查詢語言擴充了 RDF-star 的查詢語言 SPARQL-star，並使用新的 FROM 子句類型來促進運作，包括多重且有時衝突的信念。我們展示了所提出的查詢語言可以表達四個用例查詢，包括下列功能：(i) 查詢個人的信念，(ii) 信念的彙總，(iii) 查詢誰與某人衝突，以及 (iv) 關於信念的信念（即信念的巢狀）。

##### **Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**
2407.21452v1 by Haodong Hong, Sen Wang, Zi Huang, Qi Wu, Jiajun Liu

Real-world navigation often involves dealing with unexpected obstructions
such as closed doors, moved objects, and unpredictable entities. However,
mainstream Vision-and-Language Navigation (VLN) tasks typically assume
instructions perfectly align with the fixed and predefined navigation graphs
without any obstructions. This assumption overlooks potential discrepancies in
actual navigation graphs and given instructions, which can cause major failures
for both indoor and outdoor agents. To address this issue, we integrate diverse
obstructions into the R2R dataset by modifying both the navigation graphs and
visual observations, introducing an innovative dataset and task, R2R with
UNexpected Obstructions (R2R-UNO). R2R-UNO contains various types and numbers
of path obstructions to generate instruction-reality mismatches for VLN
research. Experiments on R2R-UNO reveal that state-of-the-art VLN methods
inevitably encounter significant challenges when facing such mismatches,
indicating that they rigidly follow instructions rather than navigate
adaptively. Therefore, we propose a novel method called ObVLN (Obstructed VLN),
which includes a curriculum training strategy and virtual graph construction to
help agents effectively adapt to obstructed environments. Empirical results
show that ObVLN not only maintains robust performance in unobstructed scenarios
but also achieves a substantial performance advantage with unexpected
obstructions.

摘要：现实世界的导航通常涉及处理意外的障碍，例如关着的门、移动的物体和不可预测的实体。然而，主流的视觉和语言导航 (VLN) 任务通常假设指令与固定的和预定义的导航图完全一致，没有任何障碍。这种假设忽略了实际导航图和给定指令中潜在的差异，这可能会导致室内和室外代理出现重大故障。为了解决这个问题，我们通过修改导航图和视觉观察，将各种障碍整合到 R2R 数据集中，引入了创新数据集和任务，即带有意外障碍的 R2R (R2R-UNO)。R2R-UNO 包含各种类型和数量的路径障碍，以生成 VLN 研究的指令-现实不匹配。在 R2R-UNO 上的实验表明，最先进的 VLN 方法在面对此类不匹配时不可避免地会遇到重大挑战，这表明它们严格遵循指令，而不是自适应地导航。因此，我们提出了一种称为 ObVLN（受阻 VLN）的新方法，其中包括课程训练策略和虚拟图构建，以帮助代理有效地适应受阻环境。经验结果表明，ObVLN 不仅在无障碍场景中保持了稳健的性能，而且在意外障碍中也获得了实质性的性能优势。

##### **Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**
2407.21358v1 by Elan Markowitz, Anil Ramakrishna, Jwala Dhamala, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan

Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing
reliable, structured, domain-specific, and up-to-date external knowledge.
However, KGs and LLMs are often developed separately and must be integrated
after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning
algorithm that enables augmentation of black-box LLMs with one or more KGs. The
algorithm equips a LLM with actions for interfacing a KG and enables the LLM to
perform tree search over possible thoughts and actions to find high confidence
reasoning paths. We evaluate on two popular benchmark datasets. Our results
show that Tree-of-Traversals significantly improves performance on question
answering and KG question answering tasks. Code is available at
\url{https://github.com/amazon-science/tree-of-traversals}

摘要：知識圖譜 (KG) 透過提供可靠、結構化、特定於領域且最新的外部知識，來補充大型語言模型 (LLM)。
然而，KG 和 LLM 通常是分開開發，並且必須在訓練後整合。我們介紹了 Tree-of-Traversals，一種新穎的零次推理演算法，它能讓黑盒 LLM 使用一個或多個 KG。該演算法為 LLM 提供與 KG 介面的動作，並讓 LLM 能在可能的思考和動作上執行樹狀搜尋，以找出高度信心的推理路徑。我們在兩個熱門的基準資料集上進行評估。我們的結果顯示，Tree-of-Traversals 大幅提升了問題解答和 KG 問題解答任務的效能。程式碼可在 \url{https://github.com/amazon-science/tree-of-traversals} 取得

##### **SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**
2407.21293v1 by Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu

Many fields could benefit from the rapid development of the large language
models (LLMs). The end-to-end autonomous driving (e2eAD) is one of the
typically fields facing new opportunities as the LLMs have supported more and
more modalities. Here, by utilizing vision-language model (VLM), we proposed an
e2eAD method called SimpleLLM4AD. In our method, the e2eAD task are divided
into four stages, which are perception, prediction, planning, and behavior.
Each stage consists of several visual question answering (VQA) pairs and VQA
pairs interconnect with each other constructing a graph called Graph VQA
(GVQA). By reasoning each VQA pair in the GVQA through VLM stage by stage, our
method could achieve e2e driving with language. In our method, vision
transformers (ViT) models are employed to process nuScenes visual data, while
VLM are utilized to interpret and reason about the information extracted from
the visual inputs. In the perception stage, the system identifies and
classifies objects from the driving environment. The prediction stage involves
forecasting the potential movements of these objects. The planning stage
utilizes the gathered information to develop a driving strategy, ensuring the
safety and efficiency of the autonomous vehicle. Finally, the behavior stage
translates the planned actions into executable commands for the vehicle. Our
experiments demonstrate that SimpleLLM4AD achieves competitive performance in
complex driving scenarios.

摘要：大型語言模型 (LLM) 的快速發展可能使許多領域受益。端到端自動駕駛 (e2eAD) 是典型領域之一，因為 LLM 支援越來越多的模式，因此面臨新的機會。在此，透過利用視覺語言模型 (VLM)，我們提出了一個稱為 SimpleLLM4AD 的 e2eAD 方法。在我們的模型中，e2eAD 任務分為四個階段，分別是感知、預測、規劃和行為。每個階段包含多個視覺問答 (VQA) 配對，且 VQA 配對相互連接，構建一個稱為圖形 VQA (GVQA) 的圖形。透過 VLM 分階段推理 GVQA 中的每個 VQA 配對，我們的模型可以透過語言實現端到端駕駛。在我們的模型中，採用視覺Transformer (ViT) 模型來處理 nuScenes 視覺資料，同時利用 VLM 來詮釋和推理從視覺輸入中提取的資訊。在感知階段，系統識別和分類駕駛環境中的物件。預測階段涉及預測這些物件的潛在移動。規劃階段利用收集的資訊來制定駕駛策略，確保自動駕駛汽車的安全性和效率。最後，行為階段將規劃的動作轉換為車輛可執行的命令。我們的實驗證明，SimpleLLM4AD 在複雜的駕駛場景中實現了競爭力。

##### **Be aware of overfitting by hyperparameter optimization!**
2407.20786v1 by Igor V. Tetko, Ruud van Deursen, Guillaume Godin

Hyperparameter optimization is very frequently employed in machine learning.
However, an optimization of a large space of parameters could result in
overfitting of models. In recent studies on solubility prediction the authors
collected seven thermodynamic and kinetic solubility datasets from different
data sources. They used state-of-the-art graph-based methods and compared
models developed for each dataset using different data cleaning protocols and
hyperparameter optimization. In our study we showed that hyperparameter
optimization did not always result in better models, possibly due to
overfitting when using the same statistical measures. Similar results could be
calculated using pre-set hyperparameters, reducing the computational effort by
around 10,000 times. We also extended the previous analysis by adding a
representation learning method based on Natural Language Processing of smiles
called Transformer CNN. We show that across all analyzed sets using exactly the
same protocol, Transformer CNN provided better results than graph-based methods
for 26 out of 28 pairwise comparisons by using only a tiny fraction of time as
compared to other methods. Last but not least we stressed the importance of
comparing calculation results using exactly the same statistical measures.

摘要：機器學習中非常頻繁地使用超參數最佳化。
然而，對大參數空間進行最佳化可能會導致模型過擬合。在最近對溶解度預測的研究中，作者從不同的數據源收集了七個熱力學和動力學溶解度數據集。他們使用了最先進的基於圖形的方法，並比較了使用不同的數據清洗協議和超參數最佳化為每個數據集開發的模型。在我們的研究中，我們表明超參數最佳化並非總是會產生更好的模型，這可能是由於在使用相同的統計測量時發生過擬合。可以使用預設的超參數計算類似的結果，從而將計算工作量減少約 10,000 倍。我們還通過添加基於笑容的自然語言處理的表示學習方法（稱為 Transformer CNN）來擴展先前的分析。我們表明，在使用完全相同的協議對所有分析的集合進行分析時，Transformer CNN 在 28 個成對比較中有 26 個比較比基於圖形的方法提供了更好的結果，而與其他方法相比，所用的時間只是很小的一部分。最後但並非最不重要的是，我們強調了使用完全相同的統計測量來比較計算結果的重要性。

##### **Harvesting Textual and Structured Data from the HAL Publication Repository**
2407.20595v1 by Francis Kulumba, Wissam Antoun, Guillaume Vimont, Laurent Romary

HAL (Hyper Articles en Ligne) is the French national publication repository,
used by most higher education and research organizations for their open science
policy. As a digital library, it is a rich repository of scholarly documents,
but its potential for advanced research has been underutilized. We present
HALvest, a unique dataset that bridges the gap between citation networks and
the full text of papers submitted on HAL. We craft our dataset by filtering HAL
for scholarly publications, resulting in approximately 700,000 documents,
spanning 34 languages across 13 identified domains, suitable for language model
training, and yielding approximately 16.5 billion tokens (with 8 billion in
French and 7 billion in English, the most represented languages). We transform
the metadata of each paper into a citation network, producing a directed
heterogeneous graph. This graph includes uniquely identified authors on HAL, as
well as all open submitted papers, and their citations. We provide a baseline
for authorship attribution using the dataset, implement a range of
state-of-the-art models in graph representation learning for link prediction,
and discuss the usefulness of our generated knowledge graph structure.

摘要：HAL（線上超連結文章）是法國國家出版物資料庫，
大多數高等教育和研究組織都使用它來制定開放科學
政策。作為一個數位圖書館，它是一個豐富的學術文件資料庫，
但它在進階研究的潛力尚未被充分利用。我們提出
HALvest，一個獨特的資料集，它彌補了引文網路和
在 HAL 上提交的論文全文之間的差距。我們透過篩選 HAL
中的學術出版品來建立我們的資料集，最後得到約 70 萬份文件，
涵蓋 13 個已識別領域的 34 種語言，適合語言模型
訓練，並產生約 165 億個詞彙（其中法文有 80 億個，
英文有 70 億個，是最具代表性的語言）。我們將
每篇論文的元資料轉換成引文網路，產生一個有向
異質圖形。此圖形包含在 HAL 上唯一識別的作者，以及
所有公開提交的論文及其引文。我們提供一個基準
使用資料集進行作者歸屬，實作一系列
最先進的圖形表示學習模型進行連結預測，
並討論我們產生的知識圖形結構的實用性。

##### **CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**
2407.20564v1 by Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song

While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.

摘要：儘管大型語言模型 (LLM) 已展現出令人印象深刻的能力，可透過從廣泛的訓練資料中獲取豐富的事實知識，執行各種自然語言處理任務，但它們綜合運用並以複雜的方式運用此知識進行邏輯推理的能力仍有待進一步探討。在這項工作中，我們透過一個自動生成的一般領域和生物醫學知識圖表複雜推理問題的新基準，對最先進的 LLM 複雜邏輯推理能力進行系統性評估。我們的廣泛實驗採用多樣化的情境學習技術，揭示出 LLM 擅長對一般世界知識進行推理，但在處理特定領域的專業知識時則面臨重大挑戰。我們發現，使用明確的思考鏈條示範進行提示，可以大幅改善 LLM 在具有多樣化邏輯運算的複雜邏輯推理任務中的表現。有趣的是，我們的受控評估揭露了一個不對稱性，其中 LLM 展現出在集合聯集運算方面的熟練度，但在集合交集方面卻顯得相當吃力，而集合交集正是邏輯推理的關鍵組成部分。為了促進後續研究，我們將公開發布我們的評估基準和程式碼。

##### **Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**
2407.20513v1 by Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi

This paper presents a conversational pipeline for crafting domain knowledge
for complex neuro-symbolic models through natural language prompts. It
leverages large language models to generate declarative programs in the
DomiKnowS framework. The programs in this framework express concepts and their
relationships as a graph in addition to logical constraints between them. The
graph, later, can be connected to trainable neural models according to those
specifications. Our proposed pipeline utilizes techniques like dynamic
in-context demonstration retrieval, model refinement based on feedback from a
symbolic parser, visualization, and user interaction to generate the tasks'
structure and formal knowledge representation. This approach empowers domain
experts, even those not well-versed in ML/AI, to formally declare their
knowledge to be incorporated in customized neural models in the DomiKnowS
framework.

摘要：本文提出了一個對話式管道，透過自然語言提示，為複雜的神經符號模型建立領域知識。它利用大型語言模型在 DomiKnowS 框架中產生宣告式程式。此框架中的程式會將概念及其關係表示為圖形，並在它們之間加上邏輯約束。之後，可以根據這些規格將圖形連接到可訓練的神經模型。我們提出的管道利用動態情境中示範檢索、基於符號解析器回饋的模型精煉、視覺化和使用者互動等技術，以產生任務結構和形式知識表示。這種方法讓領域專家，即使是不熟悉機器學習／人工智慧的人，也能正式宣告他們的知識，並將其納入 DomiKnowS 框架中的自訂神經模型。

##### **What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**
2407.20382v1 by Navapat Nananukul, Wichayaporn Wongkamjan

Role-playing games (RPGs) provide players with a rich, interactive world to
explore. Dialogue serves as the primary means of communication between
developers and players, manifesting in various forms such as guides, NPC
interactions, and storytelling. While most games rely on written scripts to
define the main story and character personalities, player immersion can be
significantly enhanced through casual interactions between characters. With the
advent of large language models (LLMs), we introduce a dialogue filler
framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic
and contextually appropriate character interactions. We test this framework
within the environments of Final Fantasy VII Remake and Pokemon, providing
qualitative and quantitative evidence that demonstrates GPT-4's capability to
act with defined personalities and generate dialogue. However, some flaws
remain, such as GPT-4 being overly positive or more subtle personalities, such
as maturity, tend to be of lower quality compared to more overt traits like
timidity. This study aims to assist developers in crafting more nuanced filler
dialogues, thereby enriching player immersion and enhancing the overall RPG
experience.

摘要：角色扮演遊戲 (RPG) 為玩家提供一個豐富且互動的世界供其探索。對話作為開發者與玩家之間的主要溝通方式，以指南、NPC 互動和說故事等各種形式呈現。雖然大多數遊戲依賴於書面腳本來定義主線故事和角色個性，但透過角色之間的閒聊互動，可以大幅提升玩家的沉浸感。隨著大型語言模型 (LLM) 的出現，我們引入了一個對話填充框架，利用由知識圖譜增強的 LLM 來產生動態且符合情境的對話互動。我們在 Final Fantasy VII Remake 和寶可夢的環境中測試了這個框架，提供了定性和定量的證據，證明了 GPT-4 具備以定義好的個性行動並產生對話的能力。然而，仍存在一些缺陷，例如 GPT-4 過於正面，或者較為細微的個性，例如成熟度，往往品質低於較明顯的特質，例如膽怯。本研究旨在協助開發者打造更細緻的填充對話，從而豐富玩家的沉浸感並提升整體 RPG 體驗。

##### **MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**
2407.20183v1 by Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao

Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.

摘要：資訊搜尋與整合是一項複雜的認知任務，會耗費大量時間與精力。在大型語言模型顯著進展的啟發下，近期研究嘗試結合大型語言模型與搜尋引擎來解決此任務。然而，這些方法仍因三項挑戰而無法獲得令人滿意的效能：(1) 複雜的查詢通常無法由搜尋引擎一次準確且完整地擷取，(2) 要整合的對應資訊散布在多個網頁中且伴隨著大量雜訊，以及 (3) 大量內容過長的網頁可能會快速超過大型語言模型的最大脈絡長度。在人類解決這些問題的認知過程中獲得靈感，我們引入了 MindSearch 來模擬人類心智在網頁資訊搜尋與整合中的行為，這可以用一個簡單但有效的基於大型語言模型的多代理架構來實例化。WebPlanner 以動態圖形建構過程來建模人類心智的多步驟資訊搜尋：它將使用者查詢分解成圖形中的節點，作為原子化子問題，並根據 WebSearcher 的搜尋結果逐步延伸圖形。WebSearcher 以每個子問題為任務，執行搜尋引擎的分層式資訊擷取，並為 WebPlanner 收集有價值的資訊。MindSearch 的多代理設計讓整個架構可以在 3 分鐘內平行地從更大規模（例如超過 300 個）的網頁中搜尋並整合資訊，這相當於 3 小時的人力。MindSearch 在深度和廣度方面都顯著提升了回應品質，無論是在封閉式或開放式問答問題上。此外，人類更偏好基於 InternLM2.5-7B 的 MindSearch 回應，勝過 ChatGPT-Web 和 Perplexity.ai 應用程式，這表示 MindSearch 已經可以為專有 AI 搜尋引擎提供有競爭力的解決方案。

##### **rLLM: Relational Table Learning with LLMs**
2407.20157v1 by Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li

We introduce rLLM (relationLLM), a PyTorch library designed for Relational
Table Learning (RTL) with Large Language Models (LLMs). The core idea is to
decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural
Networks into standardized modules, to enable the fast construction of novel
RTL-type models in a simple "combine, align, and co-train" manner. To
illustrate the usage of rLLM, we introduce a simple RTL method named
\textbf{BRIDGE}. Additionally, we present three novel relational tabular
datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope
rLLM can serve as a useful and easy-to-use development framework for
RTL-related tasks. Our code is available at:
https://github.com/rllm-project/rllm.

摘要：我們引入了 rLLM (relationLLM)，一個專為大型語言模型 (LLM) 的關係表學習 (RTL) 所設計的 PyTorch 函式庫。核心概念是將最先進的圖形神經網路、LLM 和表神經網路分解為標準化模組，以便以簡單的「組合、對齊和共同訓練」方式快速建構新型 RTL 類型模型。為了說明 rLLM 的用法，我們引入了名為 \textbf{BRIDGE} 的簡單 RTL 方法。此外，我們透過強化經典資料集來呈現三個新穎的關係表格資料集 (TML1M、TLF2K 和 TACM12K)。我們希望 rLLM 能夠作為 RTL 相關任務有用的且易於使用的開發架構。我們的程式碼可在以下網址取得：
https://github.com/rllm-project/rllm。

##### **Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**
2407.19643v2 by Yunsheng Wang, Songhao Chen, Kevin Jin

Knowledge graphs (KGs) are essential in applications such as network
alignment, question-answering, and recommender systems (RSs) since they offer
structured relational data that facilitate the inference of indirect
relationships. However, the development of KG-based RSs capable of processing
user inputs in natural language faces significant challenges. Firstly, natural
language processing units must effectively handle the ambiguity and variability
in human language to interpret user intents accurately. Secondly, the system
must precisely identify and link entities, like product names, to their
corresponding nodes in KGs. To overcome these challenges, supported by Lenovo,
we developed a novel chatbot called "Prometheus," which integrates a KG with a
large language model (LLM), specifically designed for recommending computer
components. This chatbot can accurately decode user requests and deliver
personalized recommendations derived from KGs, ensuring precise comprehension
and response to their computer setup needs.

摘要：知識圖譜 (KG) 在網路比對、問答和推薦系統 (RS) 等應用中至關重要，因為它們提供結構化的關係資料，有助於推斷間接關係。然而，開發能夠處理自然語言使用者輸入的基於 KG 的 RS 面臨著重大的挑戰。首先，自然語言處理單元必須有效處理人類語言中的模糊性和變異性，才能準確地解釋使用者意圖。其次，系統必須準確識別和連結實體（例如產品名稱）到 KG 中對應的節點。為了克服這些挑戰，在聯想的支援下，我們開發了一款名為「普羅米修斯」的新聊天機器人，它將 KG 與大型語言模型 (LLM) 整合在一起，專門用於推薦電腦組件。此聊天機器人可以準確地解碼使用者要求，並提供從 KG 中衍生的個人化推薦，確保精確理解和回應其電腦設定需求。

##### **TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**
2407.19616v1 by Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov

Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.

摘要：主題建模是一種從大量非結構化文本中組織和提取主題的技術。非負矩陣分解 (NMF) 是一種常見的無監督方法，它將詞頻-逆文件頻率 (TF-IDF) 矩陣分解為潛在主題，並據此對數據集進行分段。儘管 NMF 可用於強調模式和群組文件，但它不提供明確的主題標籤，這需要主題專家 (SME) 手動分配標籤。我們提出了一種方法，用於自動標記通過 NMF 進行群組的文件，並自動確定模型 (NMFk)。通過利用 NMFk 的輸出並採用提示工程，我們利用大型語言模型 (LLM) 來生成準確的主題標籤。我們對超過 34,000 篇關於知識圖譜的科學摘要進行的案例研究證明了我們的方法在增強知識管理和文件組織方面的有效性。

##### **Semantic Communication Enhanced by Knowledge Graph Representation Learning**
2407.19338v1 by Nour Hello, Paolo Di Lorenzo, Emilio Calvanese Strinati

This paper investigates the advantages of representing and processing
semantic knowledge extracted into graphs within the emerging paradigm of
semantic communications. The proposed approach leverages semantic and pragmatic
aspects, incorporating recent advances on large language models (LLMs) to
achieve compact representations of knowledge to be processed and exchanged
between intelligent agents. This is accomplished by using the cascade of LLMs
and graph neural networks (GNNs) as semantic encoders, where information to be
shared is selected to be meaningful at the receiver. The embedding vectors
produced by the proposed semantic encoder represent information in the form of
triplets: nodes (semantic concepts entities), edges(relations between
concepts), nodes. Thus, semantic information is associated with the
representation of relationships among elements in the space of semantic concept
abstractions. In this paper, we investigate the potential of achieving high
compression rates in communication by incorporating relations that link
elements within graph embeddings. We propose sending semantic symbols solely
equivalent to node embeddings through the wireless channel and inferring the
complete knowledge graph at the receiver. Numerical simulations illustrate the
effectiveness of leveraging knowledge graphs to semantically compress and
transmit information.

摘要：本文研究了在语义通信的新兴范例中将提取到图中的语义知识表示和处理的优势。所提出的方法利用语义和语用方面，结合了大语言模型 (LLM) 的最新进展，以实现要处理和在智能代理之间交换的知识的紧凑表示。这是通过使用 LLM 和图神经网络 (GNN) 的级联作为语义编码器来完成的，其中要共享的信息被选择为对接收者有意义。由所提出的语义编码器产生的嵌入向量以三元组的形式表示信息：节点（语义概念实体）、边（概念之间的关系）、节点。因此，语义信息与语义概念抽象空间中元素之间关系的表示相关联。在本文中，我们研究了通过合并将图嵌入中的元素联系起来的关联来实现高压缩率的潜力。我们建议仅通过无线信道发送语义符号，这些符号完全等效于节点嵌入，并在接收器处推断出完整的知识图。数值模拟说明了利用知识图语义压缩和传输信息的有效性。

##### **GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**
2407.19039v1 by Yuchen Shen, Barnabás Póczos

With the increasing attention to molecular machine learning, various
innovations have been made in designing better models or proposing more
comprehensive benchmarks. However, less is studied on the data preprocessing
schedule for molecular graphs, where a different view of the molecular graph
could potentially boost the model's performance. Inspired by the Byte-Pair
Encoding (BPE) algorithm, a subword tokenization method popularly adopted in
Natural Language Processing, we propose GraphBPE, which tokenizes a molecular
graph into different substructures and acts as a preprocessing schedule
independent of the model architectures. Our experiments on 3 graph-level
classification and 3 graph-level regression datasets show that data
preprocessing could boost the performance of models for molecular graphs, and
GraphBPE is effective for small classification datasets and it performs on par
with other tokenization methods across different model architectures.

摘要：隨著分子機器學習受到的關注度越來越高，在設計更好的模型或提出更全面的基準方面已經有了各種創新。然而，對於分子圖的數據預處理計畫研究較少，在該計畫中，分子圖的不同視圖可能會提升模型的效能。受到在自然語言處理中廣泛採用的子詞彙標記化方法 Byte-Pair 編碼 (BPE) 演算法的啟發，我們提出了 GraphBPE，它將分子圖標記化為不同的子結構，並作為與模型架構無關的預處理計畫。我們在 3 個圖形層級分類和 3 個圖形層級回歸資料集上的實驗顯示，資料預處理可以提升分子圖模型的效能，而 GraphBPE 對於小型分類資料集有效，並且在不同的模型架構中與其他標記化方法表現相當。

##### **Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**
2407.18752v3 by Yuni Susanti, Michael Färber

Causal discovery aims to estimate causal structures among variables based on
observational data. Large Language Models (LLMs) offer a fresh perspective to
tackle the causal discovery problem by reasoning on the metadata associated
with variables rather than their actual data values, an approach referred to as
knowledge-based causal discovery. In this paper, we investigate the
capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1
billion parameters) with prompt-based learning for knowledge-based causal
discovery. Specifically, we present KG Structure as Prompt, a novel approach
for integrating structural information from a knowledge graph, such as common
neighbor nodes and metapaths, into prompt-based learning to enhance the
capabilities of SLMs. Experimental results on three types of biomedical and
open-domain datasets under few-shot settings demonstrate the effectiveness of
our approach, surpassing most baselines and even conventional fine-tuning
approaches trained on full datasets. Our findings further highlight the strong
capabilities of SLMs: in combination with knowledge graphs and prompt-based
learning, SLMs demonstrate the potential to surpass LLMs with larger number of
parameters. Our code and datasets are available on GitHub.

摘要：因果發現旨在根據觀測數據估計變數之間的因果結構。大型語言模型 (LLM) 提供了一個新的觀點來解決因果發現問題，方法是推論與變數相關的元數據，而不是它們的實際數據值，這種方法稱為基於知識的因果發現。在本文中，我們探討了小語言模型 (SLM，定義為參數少於 10 億的 LLM) 的能力，並採用基於提示的學習進行基於知識的因果發現。具體來說，我們提出了 KG Structure as Prompt，這是一種新穎的方法，用於將來自知識圖譜的結構資訊，例如共同鄰居節點和元路徑，整合到基於提示的學習中，以增強 SLM 的能力。在少次嘗試設定下，針對三種類型的生物醫學和開放領域資料集的實驗結果證明了我們方法的有效性，超越了大多數基準，甚至超越了在完整資料集上訓練的傳統微調方法。我們的發現進一步突出了 SLM 的強大功能：結合知識圖譜和基於提示的學習，SLM 展示了超越具有更多參數的 LLM 的潛力。我們的程式碼和資料集可在 GitHub 上取得。

##### **Using GPT-4 to guide causal machine learning**
2407.18607v1 by Anthony C. Constantinou, Neville K. Kitson, Alessio Zanga

Since its introduction to the public, ChatGPT has had an unprecedented
impact. While some experts praised AI advancements and highlighted their
potential risks, others have been critical about the accuracy and usefulness of
Large Language Models (LLMs). In this paper, we are interested in the ability
of LLMs to identify causal relationships. We focus on the well-established
GPT-4 (Turbo) and evaluate its performance under the most restrictive
conditions, by isolating its ability to infer causal relationships based solely
on the variable labels without being given any context, demonstrating the
minimum level of effectiveness one can expect when it is provided with
label-only information. We show that questionnaire participants judge the GPT-4
graphs as the most accurate in the evaluated categories, closely followed by
knowledge graphs constructed by domain experts, with causal Machine Learning
(ML) far behind. We use these results to highlight the important limitation of
causal ML, which often produces causal graphs that violate common sense,
affecting trust in them. However, we show that pairing GPT-4 with causal ML
overcomes this limitation, resulting in graphical structures learnt from real
data that align more closely with those identified by domain experts, compared
to structures learnt by causal ML alone. Overall, our findings suggest that
despite GPT-4 not being explicitly designed to reason causally, it can still be
a valuable tool for causal representation, as it improves the causal discovery
process of causal ML algorithms that are designed to do just that.

摘要：自 ChatGPT 向公众发布以来，它产生了前所未有的影响。虽然一些专家赞扬了 AI 的进步并强调了其潜在风险，但其他人一直批评大型语言模型 (LLM) 的准确性和有用性。在本文中，我们对 LLM 识别因果关系的能力感兴趣。我们专注于成熟的 GPT-4（Turbo），并在最严格的条件下评估其性能，通过孤立其仅根据变量标签推断因果关系的能力，而不提供任何上下文，展示了当仅提供标签信息时人们可以预期的最低有效性水平。我们表明，问卷参与者认为 GPT-4 图形在评估类别中是最准确的，紧随其后的是由领域专家构建的知识图谱，因果机器学习 (ML) 远远落后。我们使用这些结果来强调因果 ML 的重要局限性，它经常产生违背常识的因果图，影响人们对它们的信任。然而，我们表明将 GPT-4 与因果 ML 配对可以克服这一限制，从而产生从真实数据中学到的图形结构，与领域专家识别的结构相比，更紧密地与之对齐，而不是仅由因果 ML 学到的结构。总体而言，我们的研究结果表明，尽管 GPT-4 并未明确设计为因果推理，但它仍然可以成为因果表示的宝贵工具，因为它改进了旨在执行此操作的因果 ML 算法的因果发现过程。

##### **Multi-turn Response Selection with Commonsense-enhanced Language Models**
2407.18479v1 by Yuandong Wang, Xuhui Ren, Tong Chen, Yuxiao Dong, Nguyen Quoc Viet Hung, Jie Tang

As a branch of advanced artificial intelligence, dialogue systems are
prospering. Multi-turn response selection is a general research problem in
dialogue systems. With the assistance of background information and pre-trained
language models, the performance of state-of-the-art methods on this problem
gains impressive improvement. However, existing studies neglect the importance
of external commonsense knowledge. Hence, we design a Siamese network where a
pre-trained Language model merges with a Graph neural network (SinLG). SinLG
takes advantage of Pre-trained Language Models (PLMs) to catch the word
correlations in the context and response candidates and utilizes a Graph Neural
Network (GNN) to reason helpful common sense from an external knowledge graph.
The GNN aims to assist the PLM in fine-tuning, and arousing its related
memories to attain better performance. Specifically, we first extract related
concepts as nodes from an external knowledge graph to construct a subgraph with
the context response pair as a super node for each sample. Next, we learn two
representations for the context response pair via both the PLM and GNN. A
similarity loss between the two representations is utilized to transfer the
commonsense knowledge from the GNN to the PLM. Then only the PLM is used to
infer online so that efficiency can be guaranteed. Finally, we conduct
extensive experiments on two variants of the PERSONA-CHAT dataset, which proves
that our solution can not only improve the performance of the PLM but also
achieve an efficient inference.

摘要：作為高級人工智慧的一個分支，對話系統正蓬勃發展。多輪回應用戶回應選擇是對話系統中一個通用的研究問題。在背景資訊和預先訓練的語言模型的協助下，最先進的方法在此問題上的表現獲致令人印象深刻的進步。然而，現有的研究忽略了外部常識知識的重要性。因此，我們設計了一個暹羅網路，其中一個預先訓練的語言模型與一個圖神經網路（SinLG）合併。SinLG 利用預先訓練的語言模型（PLM）來捕捉語境和回應候選中的詞彙關聯，並利用圖神經網路（GNN）從外部知識圖譜推理有用的常識。GNN 旨在協助 PLM 進行微調，並喚醒其相關記憶以獲得更好的表現。具體來說，我們首先從外部知識圖譜中提取相關概念作為節點，以構建一個子圖，其中語境回應對作為每個範例的超級節點。接下來，我們透過 PLM 和 GNN 為語境回應對學習兩個表示。兩個表示之間的相似性損失用於將常識知識從 GNN 轉移到 PLM。然後僅使用 PLM 來進行線上推論，以便保證效率。最後，我們對 PERSONA-CHAT 資料集的兩個變體進行了廣泛的實驗，這證明我們的解決方案不僅可以提高 PLM 的效能，還能實現高效的推論。

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

摘要：從單細胞 RNA 定序 (scRNA-seq) 資料推論基因調控網路 (GRN) 是一項複雜的挑戰，需要掌握基因與其調控交互作用之間的複雜關係。在此研究中，我們透過利用在廣泛的未標記 scRNA-seq 資料上訓練的單細胞 BERT 基於預訓練轉換器模型 (scBERT)，來克服此挑戰，以擴充現有 GRN 中的結構化生物知識。我們引入一種新穎的聯合圖形學習方法，它結合了預訓練單細胞語言模型所學習到的豐富脈絡表徵，以及使用圖形神經網路 (GNN) 對 GRN 中編碼的結構化知識。透過整合這兩種方式，我們的做法有效地對 scRNA-seq 資料提供的基因表現層級約束和 GRN 中固有的結構化生物知識進行推理。我們使用 BEELINE 研究中的人類細胞基準資料集，以及細胞類型特定的基本事實網路，來評估我們的方法。結果證明其效能優於目前最先進的基準，提供了對細胞調控機制的更深入理解。

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

摘要：最近，人们对利用大型语言模型 (LLM) 来通过多步骤推理、规划和工具使用来控制软件系统产生了极大的兴趣。虽然已经取得了一些有希望的结果，但应用于特定领域会引发几个普遍性问题，包括对专业领域工具的控制、缺乏用于训练和评估的现有数据集，以及自动化系统评估和改进的非平凡性。在本文中，我们提出了一个案例研究，其中我们研究了特定领域背景下的这些问题。具体来说，我们展示了一个用于数学教育的自动化数学可视化器和求解器系统。该系统协调数学求解器和数学绘图工具，以根据简单的自然语言命令生成准确的可视化效果。我们描述了专门数据集的创建，还开发了一个自动评估器，通过将我们的系统输出与真实表达式进行比较，轻松评估其输出。我们已经开源了所提议系统的代码和数据集。

##### **Ranking protein-protein models with large language models and graph neural networks**
2407.16375v1 by Xiaotong Xu, Alexandre M. J. J. Bonvin

Protein-protein interactions (PPIs) are associated with various diseases,
including cancer, infections, and neurodegenerative disorders. Obtaining
three-dimensional structural information on these PPIs serves as a foundation
to interfere with those or to guide drug design. Various strategies can be
followed to model those complexes, all typically resulting in a large number of
models. A challenging step in this process is the identification of good models
(near-native PPI conformations) from the large pool of generated models. To
address this challenge, we previously developed DeepRank-GNN-esm, a graph-based
deep learning algorithm for ranking modelled PPI structures harnessing the
power of protein language models. Here, we detail the use of our software with
examples. DeepRank-GNN-esm is freely available at
https://github.com/haddocking/DeepRank-GNN-esm

摘要：蛋白-蛋白交互作用 (PPI) 與各種疾病相關，包括癌症、感染和神經退化性疾病。取得這些 PPI 的三維結構資訊，作為干擾它們或引導藥物設計的基礎。可以遵循各種策略來建模這些複合體，所有這些策略通常會產生大量的模型。此過程中的挑戰性步驟，是從大量產生的模型中找出好的模型（接近原生 PPI 構象）。為了應對這個挑戰，我們之前開發了 DeepRank-GNN-esm，這是一種基於圖形的深度學習演算法，用於對建模的 PPI 結構進行排名，利用蛋白質語言模型的力量。在這裡，我們詳細說明了我們軟體的使用範例。DeepRank-GNN-esm 可在 https://github.com/haddocking/DeepRank-GNN-esm 免費取得

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

摘要：<paragraph>急性中風需要迅速診斷和治療，才能達到最佳的病人治療結果。然而，與急性中風相關的臨床資料複雜且不規則，特別是血壓 (BP) 測量，對有效的視覺分析和決策制定構成重大障礙。透過與經驗豐富的神經科醫師長達一年的合作，我們開發了 PhenoFlow，這是一個視覺分析系統，利用人與大型語言模型 (LLM) 之間的協作來分析急性缺血性中風患者的廣泛且複雜資料。PhenoFlow 開創了一種創新的工作流程，其中 LLM 擔任資料整理員，而神經科醫師則使用視覺化和自然語言互動來探索和監督輸出。這種方法使神經科醫師能夠更專注於決策制定，同時降低認知負擔。為了保護敏感的病人資訊，PhenoFlow 僅利用元資料進行推論並合成可執行程式碼，而不會存取原始病人資料。這確保了結果既可重現又可解釋，同時維護病人的隱私。該系統採用分段和包裝設計，採用時間摺疊來建立疊加的圓形視覺化。結合線性長條圖，此設計有助於探索不規則測量血壓資料中的有意義模式。透過案例研究，PhenoFlow 已證明其支援對廣泛臨床資料集進行反覆分析的能力，降低認知負擔並使神經科醫師能夠做出明智的決策。我們的研究以與領域專家長期合作為基礎，證明了利用 LLM 來應對當前急性缺血性中風患者資料驅動臨床決策制定挑戰的潛力。</paragraph>

##### **Graph-Structured Speculative Decoding**
2407.16207v1 by Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan

Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.

摘要：<paragraph>推測性解碼已成為一種有前途的技術，可通過使用小型語言模型起草假設序列，然後由大型語言模型 (LLM) 驗證該序列，從而加速大型語言模型 (LLM) 的推理。此方法的有效性在很大程度上取決於草稿模型的性能和效率之間的平衡。在我們的研究中，我們專注於通過生成多個假設而不是只生成一個假設來提高被接受為最終輸出的草稿令牌的比例。這允許 LLM 從中選擇更多選項，並選擇符合其標準的最長序列。我們的分析表明，草稿模型產生的假設共享許多公共令牌序列，這表明優化計算的可能性。利用這一觀察結果，我們引入了一種創新的方法，利用有向無環圖 (DAG) 來管理已編制的假設。這種結構使我們能夠有效地預測和合併重複的令牌序列，從而大大降低了草稿模型的計算需求。我們將這種方法稱為圖結構推測性解碼 (GSD)。我們將 GSD 應用於一系列 LLM，包括一個 700 億參數的 LLaMA-2 模型，並觀察到顯著的加速，從 1.73 倍到 1.96 倍，顯著超過標準推測性解碼。</paragraph>

##### **Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**
2407.21049v1 by Yannick Assogba, Donghao Ren

As language models support larger and larger context sizes, evaluating their
ability to make effective use of that context becomes increasingly important.
We analyze the ability of several code generation models to handle long range
dependencies using a suite of multi-step key retrieval tasks in context windows
up to 8k tokens in length. The tasks progressively increase in difficulty and
allow more nuanced evaluation of model capabilities than tests like the popular
needle-in-the-haystack test. We find that performance degrades significantly
(up to 2x) when a function references another function that is defined later in
the prompt. We also observe that models that use sliding window attention
mechanisms have difficulty handling references further than the size of a
single window. We perform simple prompt modifications using call graph
information to improve multi-step retrieval performance up to 3x. Our analysis
highlights different facets of long-context performance and is suggestive of
prompt construction strategies for code completion tools

摘要：隨著語言模型支援的內容大小越來越大，評估其有效利用該內容的能力變得越來越重要。我們分析了幾個程式碼生成模型處理長距離依賴關係的能力，使用一組多步驟關鍵檢索任務，在長達 8k 令牌的內容視窗中。任務逐漸增加難度，並允許對模型功能進行比流行的針頭乾草堆測試更細緻的評估。我們發現，當函式參照稍後在提示中定義的另一個函式時，效能會顯著下降（最多 2 倍）。我們還觀察到，使用滑動視窗注意機制的模型難以處理超出單一視窗大小的參照。我們使用呼叫圖形資訊執行簡單的提示修改，以將多步驟檢索效能提升至 3 倍。我們的分析突顯了長內容效能的不同面向，並暗示了程式碼完成工具的提示建構策略

##### **Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**
2407.16127v1 by Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu

Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.

摘要：傳統知識圖譜（KG）完成功能模型學習嵌入，以預測遺失的事實。最近的工作嘗試以大型語言模型（LLM）以文字生成的方式完成 KG。然而，他們需要將 LLM 的輸出基礎建立在 KG 實體上，這不可避免地會帶來錯誤。在本文中，我們提出了一個微調框架 DIFT，旨在釋放 LLM 的 KG 完成功能，並避免基礎錯誤。給定一個不完整的事實，DIFT 使用一個輕量級模型來獲得候選實體，並微調一個 LLM，並使用辨別指令從給定的候選項中選擇正確的實體。為了在減少指令數據的同時提升效能，DIFT 使用一個截斷抽樣方法來選擇有用的事實以進行微調，並將 KG 嵌入注入到 LLM 中。在基準資料集上的廣泛實驗證明了我們提出的框架的有效性。

##### **Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**
2407.15588v1 by Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee

Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge.Existing methods, mostly
supervised, face challenges in obtaining labeled entity pairs. To address this,
recent studies have shifted towards a self-supervised and unsupervised
frameworks. Despite their effectiveness, these approaches have limitations: (1)
they mainly focus on entity features, neglecting the semantic information of
relations, (2) they assume isomorphism between source and target graphs,
leading to noise and reduced alignment accuracy, and (3) they are susceptible
to noise in the textual features, especially when encountering inconsistent
translations or Out-Of-Vocabulary (OOV) problems.
  In this paper, we propose ERAlign, an unsupervised and robust cross-lingual
EA framework that jointly performs Entity-level and Relation-level Alignment
using semantic textual features of relations and entities. Its refinement
process iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification
process examines the entities' neighbor triples as the linearized text. This
\textit{Align-and-Verify} pipeline that rigorously assesses alignment results,
achieving near-perfect alignment even in the presence of noisy textual features
of entities. Our extensive experiments demonstrate that robustness and general
applicability of \proposed improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.

摘要：跨語言實體對齊 (EA) 能夠整合不同語言中的多個知識圖譜 (KG)，讓使用者能無縫地存取多元且全面的知識。現有方法大多是有監督的，在取得標記實體對時面臨挑戰。為了解決這個問題，最近的研究已轉向自監督和無監督的架構。儘管這些方法很有效，但它們有以下限制：(1) 它們主要關注實體特徵，忽略關係的語義資訊，(2) 它們假設來源圖譜和目標圖譜之間同構，導致雜訊和對齊準確度降低，(3) 它們容易受到文字特徵中的雜訊影響，特別是在遇到不一致的翻譯或詞彙外問題 (OOV) 時。
在本文中，我們提出 ERAlign，一個無監督且穩健的跨語言 EA 架構，它使用關係和實體的語義文字特徵，同時執行實體層級和關係層級對齊。它的精煉程序透過根據鄰接三元組匹配融合實體層級和關係層級對齊，反覆增強結果。額外的驗證程序將實體的鄰接三元組視為線性化文字進行檢查。這個嚴格評估對齊結果的「對齊和驗證」管線，即使在存在實體的雜訊文字特徵時也能達成近乎完美的對齊。我們廣泛的實驗證明，\proposed 的穩健性和普遍適用性提升了 EA 任務的準確度和有效性，對知識導向應用程式有顯著的貢獻。

##### **Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**
2407.15431v1 by Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang

The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.

摘要：文本属性图 (TAG) 是一种重要的真实世界图结构化数据，其中每个节点都与原始文本相关联。对于 TAG，传统的少数镜头节点分类方法直接对预处理的节点特征进行训练，而不考虑原始文本。性能在很大程度上取决于特征预处理方法的选择。在本文中，我们提出了 P2TAG，这是一个专为 TAG 上的少数镜头节点分类设计的框架，具有图预训练和提示。P2TAG 首先使用自我监督损失对 TAG 上的语言模型 (LM) 和图神经网络 (GNN) 进行预训练。为了充分利用语言模型的能力，我们为我们的框架调整了掩码语言建模目标。然后使用预训练模型进行少数镜头节点分类，采用混合提示方法，同时考虑文本和图信息。我们对六个真实世界的 TAG 进行了实验，包括论文引用网络和产品共同购买网络。实验结果表明，我们提出的框架在这些数据集上优于现有的图少数镜头学习方法，改进了 +18.98% ~ +35.98%。

##### **LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**
2407.15351v2 by Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei

Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.

摘要：近期研究試圖透過多種非監督式學習模型來提供圖神經網路 (GNN) 的可解釋性。由於資料集的稀少，目前的演算法容易受到學習偏差的影響。為了解決這個問題，我們將大型語言模型 (LLM) 作為知識嵌入到 GNN 解釋網路中，以避免學習偏差的問題。我們將 LLM 作為貝氏推論 (BI) 模組注入，以減輕學習偏差。BI 模組的效能已在理論上和實驗上得到證實。我們在合成和真實世界資料集上進行實驗。我們工作的創新之處在於兩部分：1. 我們提供 LLM 作為貝氏推論以改善現有演算法效能的可能性之新觀點；2. 我們率先討論 GNN 解釋問題中的學習偏差問題。

##### **Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**
2407.15141v1 by Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.

摘要：高通量反應條件 (RC) 篩選是化學合成中的基礎。然而，當前的 RC 篩選會遇到繁瑣且昂貴的試錯工作流程。傳統的電腦輔助合成規劃 (CASP) 工具無法找到合適的 RC，這是因為資料稀疏且反應表示不足。如今，大型語言模型 (LLM) 能夠解決與化學相關的問題，例如分子設計和化學邏輯問答任務。然而，LLM 尚未達成化學反應條件的準確預測。在此，我們提出 MM-RCR，一個文本增強的多模態 LLM，它從 SMILES、反應圖和文本語料庫學習統一的反應表示，以進行化學反應推薦 (RCR)。為了訓練 MM-RCR，我們建構了 120 萬對配對的問答指令資料集。我們的實驗結果證明，MM-RCR 在兩個開放基準資料集上達到了最先進的效能，並在領域外 (OOD) 和高通量實驗 (HTE) 資料集上展現出強大的概化能力。MM-RCR 有可能加速化學合成中的高通量條件篩選。

##### **On the Design and Analysis of LLM-Based Algorithms**
2407.14788v1 by Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou

We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs. We
further consider parallel decomposition for a case study, providing extensive
analytical and empirical study for four concrete examples of this pattern. Our
proposed framework holds promise for advancing LLM-based algorithms, by
revealing the reasons behind curious empirical phenomena, guiding the choices
of hyperparameters, predicting the empirical performance of algorithms, and
inspiring new algorithm design. To promote further study of LLM-based
algorithms, we release our source code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.

摘要：<paragraph>我們對基於 LLM 的演算法的設計和分析展開正式調查，即包含一個或多個大型語言模型 (LLM) 作為子常式呼叫的演算法，並極度依賴 LLM 的功能。儘管基於 LLM 的演算法，從帶提示工程的基本 LLM 呼叫到複雜的 LLM 驅動的代理系統和複合式 AI 系統，已取得顯著的實證成功，但其設計和最佳化大多依賴試驗法和錯誤，這在很大程度上是因為缺乏對這些演算法的正式和分析研究。為了填補這個空白，我們從識別基於 LLM 的演算法的計算圖表示、任務分解的設計原則，以及一些關鍵抽象化開始，然後促進我們對基於 LLM 的演算法的準確性和效率進行正式分析，儘管 LLM 本身具有黑盒特性。我們進一步考慮並行分解作為案例研究，為此模式的四個具體範例提供廣泛的分析和實證研究。我們提出的架構有望推進基於 LLM 的演算法，方法是揭示奇怪的實證現象背後的原因、指導超參數的選擇、預測演算法的實證效能，並激發新的演算法設計。為了促進對基於 LLM 的演算法的進一步研究，我們在 https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm/ 發布我們的原始碼。</paragraph>

##### **LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**
2407.18269v1 by Chen-Chia Chang, Yikang Shan, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, Xin Zhang

In the realm of electronic and electrical engineering, automation of analog
circuit is increasingly vital given the complexity and customized requirements
of modern applications. However, existing methods only develop search-based
algorithms that require many simulation iterations to design a custom circuit
topology, which is usually a time-consuming process. To this end, we introduce
LaMAGIC, a pioneering language model-based topology generation model that
leverages supervised finetuning for automated analog circuit design. LaMAGIC
can efficiently generate an optimized circuit design from the custom
specification in a single pass. Our approach involves a meticulous development
and analysis of various input and output formulations for circuit. These
formulations can ensure canonical representations of circuits and align with
the autoregressive nature of LMs to effectively addressing the challenges of
representing analog circuits as graphs. The experimental results show that
LaMAGIC achieves a success rate of up to 96\% under a strict tolerance of 0.01.
We also examine the scalability and adaptability of LaMAGIC, specifically
testing its performance on more complex circuits. Our findings reveal the
enhanced effectiveness of our adjacency matrix-based circuit formulation with
floating-point input, suggesting its suitability for handling intricate circuit
designs. This research not only demonstrates the potential of language models
in graph generation, but also builds a foundational framework for future
explorations in automated analog circuit design.

摘要：在電子和電氣工程領域中，自動化類比電路越來越重要，因為現代應用程式具有複雜且客製化的需求。然而，現有的方法僅開發基於搜尋的演算法，需要許多模擬反覆運算才能設計客製化電路拓撲，這通常是一個耗時的過程。為此，我們引入了 LaMAGIC，一個基於先驅語言模型的拓撲生成模型，它利用監督微調進行自動化類比電路設計。LaMAGIC 可以有效率地從客製化規格中生成最佳化的電路設計，只需一次通過。我們的做法包括仔細開發和分析電路的各種輸入和輸出公式。這些公式可以確保電路的標準表示，並與 LM 的自迴歸性質保持一致，以有效解決將類比電路表示為圖形的挑戰。實驗結果顯示，LaMAGIC 在 0.01 的嚴格容差下實現了高達 96% 的成功率。我們還檢查了 LaMAGIC 的可擴充性和適應性，特別是測試了它在更複雜電路上的效能。我們的研究結果揭示了我們基於鄰接矩陣的電路公式與浮點輸入的增強效能，表明它適用於處理複雜的電路設計。這項研究不僅展示了語言模型在圖形生成中的潛力，也為未來在自動化類比電路設計中的探索建立了基礎框架。

##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

摘要：自動手語 (SL) 識別是電腦視覺社群中的重要任務。要建立強健的 SL 識別系統，我們需要大量的資料，而這在印度手語 (ISL) 中特別缺乏。在本文中，我們提出一個大規模的孤立 ISL 資料集，以及一個基於骨架圖結構的新型 SL 識別模型。該資料集涵蓋 2,002 個聾啞社群中常用的日常單字，由 20 位 (10 男 10 女) 聾啞成人手語者錄製（包含 40033 部影片）。我們提出一個 SL 識別模型，即分層視窗圖注意力網路 (HWGAT)，利用人體上半身骨架圖結構。HWGAT 嘗試透過關注由人體骨架圖結構誘導的不同身體部位來捕捉獨特的動作。透過廣泛的實驗評估所提出的資料集的效用和我們模型的有用性。我們在所提出的資料集上預訓練所提出的模型，並在不同的手語資料集上微調它，進一步提升了 INCLUDE、LSA64、AUTSL 和 WLASL 上 1.10、0.46、0.78 和 6.84 個百分點的效能，分別與現有的最先進的基於骨架的模型相比。

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

摘要：圖表已成為各種領域中內容分析的關鍵數據結構，例如社交網路分析、生物資訊學和推薦系統。節點分類是此脈絡中的基本任務，通常使用圖形神經網路 (GNN) 來處理。不幸的是，儘管現實世界應用中普遍存在少樣本節點分類任務，但傳統的 GNN 在標記節點很少的情況下仍面臨挑戰。為了應對這一挑戰，已提出各種方法，包括圖形元學習、遷移學習和基於大型語言模型 (LLM) 的方法。然而，傳統的元學習和遷移學習方法通常需要來自基礎類別的先驗知識，或者無法利用未標記節點的潛在優勢。同時，基於 LLM 的方法可能會忽視 LLM 的零樣本能力，並且過度依賴生成語境的品質。在本文中，我們提出了一種新的方法，它整合了 LLM 和 GNN，利用 LLM 的零樣本推論和推理能力，並採用基於 Graph-LLM 的主動學習範例來增強 GNN 的效能。廣泛的實驗證明了我們的模型在改進節點分類準確度方面的有效性，標記數據相當有限，顯著超越了最先進的基準。

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

摘要：推薦系統 (RS) 在提升使用者體驗中扮演著不可或缺的角色，透過提供個人化的商品建議。這項調查回顧了 RS 在 2017 年到 2024 年間的進展，有效地將理論進展與實際應用連結起來。我們探討了從傳統的 RS 技術，例如基於內容和協同過濾，到涉及深度學習、基於圖形的模型、強化學習和大語言模型等先進方法的發展。我們也討論了專門的系統，例如情境感知、基於評論和公平感知的 RS。這項調查的主要目標是將理論與實務結合起來。它解決了各個領域的挑戰，包括電子商務、醫療保健和金融，強調了對可擴充、即時和可信賴的解決方案的需求。透過這項調查，我們促進了學術研究和產業實務之間更強大的夥伴關係。這項調查提供的見解旨在引導產業專業人士優化 RS 部署，並激勵未來的研究方向，特別是在解決新興的技術和社會趨勢方面。

##### **MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**
2407.18961v2 by Guoli Yin, Haoping Bai, Shuang Ma, Feng Nan, Yanchao Sun, Zhaoyang Xu, Shen Ma, Jiarui Lu, Xiang Kong, Aonan Zhang, Dian Ang Yap, Yizhe zhang, Karsten Ahnert, Vik Kamath, Mathias Berglund, Dominic Walsh, Tobias Gindele, Juergen Wiest, Zhengfeng Lai, Xiaoming Wang, Jiulong Shan, Meng Cao, Ruoming Pang, Zirui Wang

Recent advances in large language models (LLMs) have increased the demand for
comprehensive benchmarks to evaluate their capabilities as human-like agents.
Existing benchmarks, while useful, often focus on specific application
scenarios, emphasizing task completion but failing to dissect the underlying
skills that drive these outcomes. This lack of granularity makes it difficult
to deeply discern where failures stem from. Additionally, setting up these
environments requires considerable effort, and issues of unreliability and
reproducibility sometimes arise, especially in interactive tasks. To address
these limitations, we introduce the Massive Multitask Agent Understanding
(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need
for complex environment setups. It evaluates models across five domains,
including Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine
Learning coding, Contest-level programming and Mathematics, and covers five
essential capabilities: Understanding, Reasoning, Planning, Problem-solving,
and Self-correction. With a total of 20 meticulously designed tasks
encompassing over 3K distinct prompts, MMAU provides a comprehensive framework
for evaluating the strengths and limitations of LLM agents. By testing 18
representative models on MMAU, we provide deep and insightful analyses.
Ultimately, MMAU not only sheds light on the capabilities and limitations of
LLM agents but also enhances the interpretability of their performance.
Datasets and evaluation scripts of MMAU are released at
https://github.com/apple/axlearn/tree/main/docs/research/mmau.

摘要：大型語言模型 (LLM) 的最新進展增加了對全面基準測試的需求，以評估其作為類人代理的能力。現有的基準測試雖然有用，但通常專注於具體的應用場景，強調任務完成，但未能剖析驅動這些結果的底層技能。這種缺乏粒度使得難以深入辨別失敗的根源。此外，設置這些環境需要大量的精力，有時會出現不可靠性和可重複性的問題，特別是在互動任務中。為了解決這些限制，我們引入了大規模多任務代理理解 (MMAU) 基準測試，它具有全面的離線任務，消除了對複雜環境設置的需求。它跨越五個領域評估模型，包括工具使用、有向無環圖 (DAG) 問答、數據科學和機器學習編碼、競賽級編程和數學，並涵蓋五項基本能力：理解、推理、規劃、問題解決和自我糾正。MMAU 總共包含 20 項精心設計的任務，涵蓋超過 3K 個不同的提示，為評估 LLM 代理的優勢和局限性提供了一個全面的框架。通過在 MMAU 上測試 18 個代表性模型，我們提供了深入而有見地的分析。最終，MMAU 不僅闡明了 LLM 代理的能力和局限性，還增強了其性能的可解釋性。MMAU 的數據集和評估腳本已發布在 https://github.com/apple/axlearn/tree/main/docs/research/mmau。

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

摘要：通過闡述一系列中間推理步驟，大幅提升大型語言模型 (LLM) 解決複雜問題的能力，因為這些步驟會促使 LLM 按順序思考。然而，人類的諷刺理解通常被認為是一種直覺且全面的認知過程，其中各種語言、語境和情緒線索整合在一起，以全面了解說話者的真實意圖，這被認為不僅限於循序漸進的推理過程。為了驗證這個論點，我們引入了一個新的提示框架，稱為 SarcasmCue，其中包含四種提示策略，即矛盾鏈 (CoC)、線索圖 (GoC)、線索袋 (BoC) 和線索張量 (ToC)，它引發 LLM 通過考慮順序和非順序提示方法來檢測人類的諷刺。通過對四個基準數據集進行全面的實證比較，我們表明所提出的四種提示方法以相當大的幅度優於標準 IO 提示、CoT 和 ToT，並且非順序提示通常優於順序提示。

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v3 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

摘要：微調預訓練語言模型 (PLM) 近來顯示出改善知識圖譜完成功能 (KGC) 的潛力。然而，大多數基於 PLM 的方法僅編碼文字資訊，忽略了知識圖譜 (KG) 的各種拓撲結構。在本文中，我們透過經驗驗證了 KG 的結構屬性與基於 PLM 的方法效能之間的重要關係。為了利用結構知識，我們提出了一個用於 KGC 的子圖感知訓練架構 (SATKGC)，它結合了：(i) 子圖感知小批次處理以鼓勵困難負面抽樣，以及 (ii) 一種新的對比學習方法，在結構屬性方面更專注於更困難的實體和更困難的負三元組。據我們所知，這是第一個將子圖的結構歸納偏誤全面納入 PLM 微調的研究。在四個 KGC 基準上的廣泛實驗證明了 SATKGC 的優越性。我們的程式碼現已公開。

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

摘要：抽象化——將特定範例概括為廣泛可重複使用的模式的過程——是人們有效處理和儲存資訊，並將其知識應用於新資料的核心。有希望的是，研究顯示 ML 模型學習跨越抽象層級的表徵，從「細領帶」和「汽車輪胎」等具體概念到「執行長」和「模型」等更一般的概念。然而，現有的技術孤立地分析這些表徵，將學習到的概念視為獨立的產物，而不是抽象的相互連結網路。因此，儘管我們可以識別模型用來產生其輸出的概念，但很難評估它是否學習到概念的人類對齊抽象，這些概念將概括到新的資料。為了解決這個差距，我們引入了抽象對齊，一種衡量模型學習的抽象與預期的抽象之間一致性的方法。我們透過將模型輸出與人類抽象圖形（例如語言關係或醫療疾病層級結構）進行比較來量化抽象對齊。在解釋影像模型、基準語言模型和分析醫療資料集的評估任務中，抽象對齊提供了對模型行為和資料集內容更深入的理解，根據與人類知識的一致性區分錯誤，擴展當前模型品質指標的詳細程度，並揭示改善現有人類抽象的方法。

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

摘要：結構化資料富含邏輯和關係資訊，有潛力增強大型語言模型 (LLM) 的推理能力。儘管如此，由於過多符號和無關脈絡資訊可能會讓 LLM 不堪負荷，因此整合此類資料構成了一項挑戰。為了解決此問題，我們提出 Struct-X，這是一個透過五個關鍵階段運作的新穎架構：``讀取-建模-填補-反思-推理''，有效地讓 LLM 能夠利用結構化資料。它首先使用圖形嵌入將結構化資料編碼到拓撲空間中，接著利用知識擷取模組填補遺失的實體資訊，並透過自我監督模組篩選出無關符號。最後一個階段涉及建構一個拓撲網路，其中包含選定的符號，以進一步減少總符號長度，以便更有效地進行 LLM 推論。此外，Struct-X 還包括一個輔助模組，經過訓練可以產生提示，協助 LLM 分析結構化資料。在基準上的大量實驗，包括知識圖譜問答任務和長篇文件閱讀理解任務，顯示 Struct-X 明顯改善了 LLM 推理，證明了結構化資料擴充在改善 LLM 推論時的有效性，特別是在輸入脈絡複雜的情況下。

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

摘要：<paragraph>現今大量的生物醫學資訊對試圖有效消化、處理和理解這些發現的研究人員構成重大挑戰。大型語言模型 (LLM) 已成為在這個複雜且具挑戰性的資料環境中導航的強大工具。然而，LLM 可能會導致幻覺反應，這使得檢索擴增生成 (RAG) 對於獲得準確資訊至關重要。在這個協定中，我們提出 RUGGED（圖形導引可解釋疾病區分的檢索），這是一個全面的工作流程，旨在支援研究人員進行知識整合和假設產生，找出經過驗證的進展路徑。來自出版物和知識庫的相關生物醫學資訊會透過文本探勘關聯分析和疾病節點的可解釋圖形預測模型進行檢閱、整合和萃取，預測藥物和疾病之間的潛在關聯。這些分析連同生物醫學文本會整合到一個架構中，該架構促進使用者導向的機制闡明，以及透過 RAG 啟用的 LLM 進行假設探討。一個臨床使用案例展示了 RUGGED 評估和推薦用於心律失常性心肌病變 (ACM) 和擴張型心肌病變 (DCM) 的治療方法的能力，分析處方藥物的分子交互作用和未探索的用途。這個平台將 LLM 幻覺降到最低，提供可操作的見解，並改善新治療方法的研究。</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

摘要：近期，大型语言模型 (LLM) 在各种资料探勘任务中展现出极大的潜力，例如知识问答、数学推理和常识推理。然而，LLM 在时间事件预测方面的推理能力尚未被充分探索。为了系统性地调查其在时间事件预测方面的能力，我们对基于 LLM 的时间事件预测方法进行了全面的评估。由于缺乏同时包含图表和文本资料的高品质数据集，我们首先构建了一个名为 MidEast-TE-mini 的基准数据集。基于此数据集，我们设计了一系列基线方法，其特点是各种输入格式和检索增强生成 (RAG) 模块。从广泛的实验中，我们发现直接将原始文本整合到 LLM 的输入中并不会增强零次学习外推性能。相比之下，在特定复杂事件中纳入原始文本并微调 LLM 会显著提高性能。此外，通过检索模块的增强，LLM 可以有效地捕捉隐藏在历史事件中的时间关系模式。同时，诸如流行度偏差和长尾问题等问题仍然存在于 LLM 中，尤其是在基于 RAG 的方法中。这些发现不仅加深了我们对基于 LLM 的事件预测方法的理解，还突出了几个有前景的研究方向。我们认为，这项全面的评估，连同已确定的研究机会，将极大地促进通过 LLM 进行时间事件预测的未来研究。

##### **Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**
2407.12068v2 by Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang

Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中都展現出卓越的效能。最近，已開發出多個基於 LLM 的管道，以增強具有文字屬性的圖形學習，展現出令人滿意的效能。然而，圖形容易受到對抗性攻擊，而 LLM 在圖形學習中是否展現出穩健性仍不清楚。為了解決這個差距，我們的研究旨在探討 LLM 在圖形對抗性攻擊中的潛力。具體來說，我們針對兩個面向探討其對圖形結構和文字擾動的穩健性：LLM 作為增強器和 LLM 作為預測器。透過廣泛的實驗，我們發現，與淺層模型相比，LLM 作為增強器和 LLM 作為預測器在結構性和文字攻擊中都提供優異的穩健性。根據這些發現，我們進行了額外的分析來探討其根本原因。此外，我們已公開我們的基準庫，以利快速且公平的評估，並鼓勵持續進行這方面的創新研究。

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v2 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

摘要：可控图像标注 (CIC) 旨在生成自然语言描述以描述图像，条件是根据最终用户提供的资讯，例如区域、实体或感兴趣的事件。然而，现有的图像语言数据集主要包含描述整个图像的标注，使其无法有效训练 CIC 模型，而这些模型有可能关注任何区域或关系的子集。为了应对这一挑战，我们提出了一种新颖的、全自动的方法，使用建立在与图像关联的现有标注集之上的统一结构化语义表示来抽样其他聚焦且视觉接地的标注。我们利用跨语言图式语义形式化抽象意义表示 (AMR) 来编码实体之间所有可能的空间语义关系，而不仅仅是当前方法中仅关注的空间关系。我们使用这种结构化语义增强 (SSA) 框架来增强现有的图像标注数据集，使其接地且可控的标注，增加它们的空间和语义多样性以及焦点覆盖范围。然后，我们开发了一个新模型 CIC-BART-SSA，专门针对 CIC 任务量身定制，其控制信号来自 SSA 多样化的数据集。我们凭经验表明，与 SOTA CIC 模型相比，CIC-BART-SSA 生成的标注在多样性和文本质量方面更胜一筹，在可控性方面具有竞争力，而且重要的是，通过有效地推广到具有挑战性的高度聚焦场景，最大限度地缩小了广泛和高度聚焦的受控标注性能之间的差距。代码可从 https://github.com/SamsungLabs/CIC-BART-SSA 获得。

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v1 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

摘要：檢索增強生成（RAG）透過啟用動態資訊檢索來減輕生成內容中的知識差距和幻覺，大幅提升大型語言模型（LLM）。然而，這些系統在複雜推理和跨不同查詢的一致性方面常常表現不佳。在這項工作中，我們提出了 Think-on-Graph 2.0，一個增強的 RAG 框架，它將問題與知識圖譜對齊，並將其用作導航工具，這加深並改進了 RAG 典範，用於資訊收集和整合。受知識圖譜引導的導航促進了深層且長程的關聯，以維持邏輯一致性並最佳化檢索範圍，以提高精確度和互操作性。同時，事實一致性可以透過由精確指示引導的語意相似性獲得更好的確保。ToG${2.0}$ 不僅提升了 LLM 回應的準確性和可靠性，也展示了混合結構化知識系統的潛力，可以大幅提升 LLM 推理，使其更接近人類般的表現。我們在四個公開資料集上進行了廣泛的實驗，以展示我們的方法相較於基線的優勢。

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

摘要：<paragraph>知識圖譜 (KG) 在人工智慧領域至關重要，並廣泛應用於下游任務，例如增強問答 (QA) 系統。知識圖譜的建構通常需要領域專家的大量工作。最近，大型語言模型 (LLM) 已被用於知識圖譜建構 (KGC)，然而，現有方法大多關注局部觀點，從個別句子或文件中提取知識三元組。在這項工作中，我們介紹了 Graphusion，一個從自由文本中進行零次學習的 KGC 框架。核心融合模組提供三元組的全局觀點，包含實體合併、衝突解決和新三元組發現。我們展示了如何將 Graphusion 應用於自然語言處理 (NLP) 領域，並在教育場景中驗證它。具體來說，我們介紹了 TutorQA，一個新的由專家驗證的圖譜推理和問答基準，包含六項任務和總計 1,200 個問答對。我們的評估表明，Graphusion 在連結預測的準確度上比監督式基準高出 10%。此外，在概念實體提取和關係識別的人類評估中，它分別獲得了 3 分中的 2.92 分和 2.37 分。</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

摘要：大型語言模型 (LLM) 回應評估方法和不一致性偵測（又稱為幻覺），相對於所提供的知識，對於 LLM 應用正變得越來越重要。目前的指標無法提供可解釋的決策、系統性地檢查回應中的所有資訊，而且在實務上使用時，通常過於耗費運算資源。我們提出 GraphEval：一個基於知識圖 (KG) 結構來表示資訊的幻覺評估架構。我們的技術識別出容易出現幻覺的 KG 中特定三元組，因此比以往的方法更深入地了解回應中幻覺發生在哪裡（如果有的話）。此外，將我們的方法與最先進的自然語言推論 (NLI) 模型結合使用，與使用原始 NLI 模型相比，可以在各種幻覺基準上提高平衡準確度。最後，我們探索使用 GraphEval 來進行幻覺修正，方法是利用 KG 的結構，我們將此方法命名為 GraphCorrect，並證明大多數幻覺確實可以得到糾正。

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

摘要：本文討論了將大型多模態模型 (LMM) 擴展到廣闊 3D 環境的挑戰。解決這個開放性問題對於機器人在許多第一反應人員場景中的部署特別相關，例如涵蓋廣闊空間的搜救任務。這些設定中使用 LMM 目前受到嚴格的上下文視窗限制，這限制了 LMM 的輸入大小。因此，我們引入了一種新穎的方法，該方法利用資料圖結構，允許 LMM 迭代查詢大型環境的較小部分。透過將資料圖與圖形遍歷演算法結合使用，我們可以優先考慮與查詢最相關的位置，從而提高 3D 場景語言任務的可擴充性。我們使用 3D 場景說明資料圖，但這些場景可以輕鬆地由其他表示環境的密集模式取代，例如點雲或高斯點。我們展示了在搜救任務範例中使用資料圖進行兩個 3D 場景語言任務用例的潛力。

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

摘要：我們介紹 AutoGRAMS 框架，用於編寫與語言模型的多步驟互動。AutoGRAMS 將 AI 代理表示為一個圖形，其中每個節點可以執行語言建模指令或傳統代碼。同樣地，圖形中的轉換可以由語言建模決策或傳統分支邏輯控制。AutoGRAMS 支援使用變數作為記憶體，並允許節點呼叫其他 AutoGRAMS 圖形作為函式。我們展示如何使用 AutoGRAMS 設計高度複雜的代理，包括可以修改自身圖形的自參照代理。AutoGRAMS 以圖形為中心的方法有助於在 AI 代理的設計、開發和部署過程中提高可解釋性、可控性和安全性。我們在 https://github.com/autograms/autograms 提供我們的框架作為開源。

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

摘要：網路資訊的洪流縮短了我們的集體注意力時間。透過 \textit{FarFetched}，我們解決了根據從多個線上新聞來源彙總的證據進行自動化聲明驗證的需求。我們引入了一個以實體為中心的推理框架，其中事件、動作或陳述之間的潛在關聯透過實體提及被揭露，並在圖形資料庫中表示。使用實體連結和語義相似性，我們提供一種方式來收集和組合來自不同來源的資訊，以產生與使用者聲明相關的證據。然後，我們利用文本蘊涵識別來根據建立的證據量化確定此斷言是否可信。我們的做法試圖填補資源較少的語言的自動化聲明驗證方面的空白，並在希臘語中展示，輔以對相關語義文本相似性 (STS) 和自然語言推論 (NLI) 模型的訓練，這些模型在常見基準的翻譯版本上進行評估。

##### **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**
2407.09709v1 by Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang

Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.

摘要：基礎模型，例如大型語言模型 (LLM) 或大型視覺模型 (LVM)，已成為各自領域中最有力的工具之一。然而，與文本和影像資料不同，圖形資料沒有明確的結構，對開發圖形基礎模型 (GFM) 構成極大的挑戰。例如，目前設計通用圖形模型的嘗試，不是將圖形資料轉換為語言格式以供基於 LLM 的預測，就是訓練 GNN 模型，並以 LLM 作為輔助。前者可以處理無限的任務，而後者可以更好地擷取圖形結構，但現有的工作無法同時達成這兩者。在本文中，我們找出 GFM 的三個關鍵理想特性：自我監督預訓練、任務流暢度和圖形感知。為了考量這些特性，我們將傳統的語言建模擴充到圖形領域，並提出一個新穎的生成式圖形語言模型 GOFA 來解決問題。此模型將隨機初始化的 GNN 層交錯插入凍結的預訓練 LLM 中，以便語意和結構建模能力有機結合。GOFA 採用新提出的圖形層級下一個字預測、問答和結構任務進行預訓練，以取得上述 GFM 特性。預訓練模型進一步在下游任務上進行微調，以取得解決任務的能力。微調模型在各種下游任務上進行評估，證明了在零次學習場景中解決結構和上下文問題的強大能力。程式碼可在 https://github.com/JiaruiFeng/GOFA 取得。

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

摘要：大型語言模型 (LLM) 已展現出非凡的能力，但仍難以處理廣泛的脈絡，這限制了它們在長序列中維持連貫性和準確性的能力。相較之下，人腦擅長在廣大的時間尺度上組織和提取情節體驗，跨越一生。在這項工作中，我們引入了 EM-LLM，這是一種新穎的方法，它將人類情節記憶和事件認知的關鍵面向整合到 LLM 中，讓它們能夠有效地處理實際上無限的脈絡長度，同時維持運算效率。EM-LLM 使用貝氏驚喜和圖論邊界精煉的組合，以線上方式將序列標記組織成連貫的情節事件。在需要時，這些事件會透過兩階段的記憶過程來提取，結合基於相似性和時間連續性的提取，以有效且類似人類的方式存取相關資訊。在 LongBench 資料集上的實驗證明了 EM-LLM 的卓越效能，在各種任務中優於最先進的 InfLLM 模型，在 PassageRetrieval 任務中改進了 33%。此外，我們的分析揭示了 EM-LLM 的事件分割與人類感知事件之間的強相關性，顯示了這個人工系統與其生物對應物之間的橋樑。這項工作不僅提升了 LLM 在處理延伸脈絡方面的能力，也提供了一個運算架構來探索人類記憶機制，為 AI 和認知科學的跨領域研究開啟了新的途徑。

##### **The $μ\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

摘要：圖形神經網路形成一類深度學習架構，特別設計用於處理圖形結構化的資料。因此，它們具有深度學習固有的限制和問題，特別是在可解釋性和可信賴性問題上。我們提出 $\mu\mathcal{G}$，一種用於指定圖形神經網路的原創領域特定語言，旨在克服這些問題。引入了語言的語法，並透過指示語義嚴格定義其含義。還提供了運算語義形式的等效特徵描述，並與類型系統一起用於證明 $\mu\mathcal{G}$ 的類型健全性。我們展示了如何將 $\mu\mathcal{G}$ 程式表示為更友善的圖形視覺化，並透過展示如何使用它定義一些最流行的圖形神經網路模型或開發任何自訂圖形處理應用程式，來提供其通用性的範例。

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

摘要：可信度和可解釋性是 LLM 中密不可分的概念。LLM 的可解釋性越高，它的可信度就越高。然而，當應用於與程式碼相關的任務時，目前解釋 LLM 的技術主要集中在準確性測量、模型對變化的反應測量或個別任務表現，而不是在預測時間所需的細粒度解釋，從而提高可解釋性和因此提高信任度。為了改善這種現狀，本文介紹了 ASTrust，這是一種用於程式碼 LLM 的可解釋性方法，它會根據模型信心與程式語言的語法結構之間的關係產生解釋。ASTrust 在基於抽象語法樹的語法類別的上下文中解釋產生的程式碼，並幫助實務人員在局部（個別程式碼片段）和全域（較大的程式碼資料集）層級了解模型預測。透過將模型信心分數分配和指定給 AST 中存在的眾所周知的語法結構，我們的做法超越了先前的技術，這些技術透過提供與開發人員熟悉的程式語言概念直接對齊的模型信心視圖來執行令牌級別的信心對應。為了實踐 ASTrust，我們開發了一個自動化視覺化工具，它說明了疊加在 AST 語法結構的序列、熱圖和基於圖形的視覺效果上的聚合模型信心分數。我們檢查了 ASTrust 可以透過對 12 個流行的 LLM 在一組精選的 GitHub 儲存庫上進行資料科學研究提供的實際好處，以及透過人體研究提供的 ASTrust 的有用性。

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

摘要：<paragraph>最近，已经提出了多种预训练语言模型 (PLM)，以证明它们在广泛的少量样本任务上具有令人印象深刻的性能。然而，由于 PLM 中非结构化的先验知识受到限制，因此难以在复杂结构化场景（例如层次文本分类 (HTC)）中保持一致的性能，尤其是在下游数据极其稀少的情况下。主要的挑战是如何将 PLM 中非结构化的语义空间转移到下游域层次结构。与以前直接执行多标签分类或使用图神经网络 (GNN) 注入标签层次结构的 HTC 工作不同，在这项工作中，我们在少量样本设置下研究 HTC 问题，以将 PLM 中的知识从非结构化方式适应到下游层次结构。从技术上讲，我们设计了一种简单而有效的方法，称为层次迭代条件随机场 (HierICRF)，以搜索最具领域挑战性的方向，并精细地将领域层次结构适应作为分层迭代语言建模问题，然后它鼓励模型在推理期间进行层次一致性自我校正，从而实现具有层次一致性保留的知识转移。我们在各种架构上执行 HierICRF，在两个流行的 HTC 数据集上的大量实验表明，使用 HierICRF 的提示显着提高了少量样本 HTC 性能，平均 Micro-F1 从 28.80% 提高到 1.50%，Macro-F1 从 36.29% 提高到 1.5% 在少量样本设置下超过了以前最先进 (SOTA) 基准，同时保持 SOTA 层次一致性性能。</paragraph>

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

摘要：在現代雲端系統中，執行時期故障和效能降低是司空見慣的事。對於雲端供應商而言，自動找出事件的根本原因對於確保高可靠性和可用性至關重要，因為及時的故障定位可以讓診斷和分類更快速，以利於及時解決問題。最近的工作中探討了一個引人注目的解決方案，即使用因果圖來擷取各種雲端系統效能指標之間關係的因果推理。然而，系統開發人員必須正確定義其系統的因果圖才能發揮效用，而這項任務耗時、脆弱且具有挑戰性，對於大型且動態的系統而言難度更高，而且需要領域專家知識。或者，由於事件的固有稀少性，自動化資料驅動方法對於雲端系統的效力有限。在這項工作中，我們提出 Atlas，一種自動合成雲端系統因果圖的新方法。Atlas 利用大型語言模型 (LLM) 使用系統文件、遙測和部署回饋來產生因果圖。Atlas 是資料驅動因果發現技術的補充，我們進一步使用資料驅動驗證步驟來增強 Atlas。我們在各種故障定位情境中評估 Atlas，並證明 Atlas 能夠以可擴充且可概化的方式產生因果圖，其效能遠遠超過資料驅動演算法，並且與真實基線相當。

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v3 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

摘要：本文探討了連線主義與符號人工智慧 (AI) 的融合，從歷史辯論到當代進展。連線主義 AI 傳統上被視為不同的範例，專注於神經網路，而符號 AI 則強調符號表徵和邏輯。大型語言模型 (LLM) 的最新進展，以 ChatGPT 和 GPT-4 為例，突顯了連線主義架構在將人類語言視為符號形式處理方面的潛力。研究認為，由 LLM 賦能的自主代理 (LAA) 體現了這種範例融合。透過利用 LLM 進行基於文字的知識建模和表徵，LAA 整合了神經符號 AI 原則，展示了增強的推理和決策能力。在神經符號 AI 主題中比較 LAA 與知識圖譜，突顯了 LAA 在模擬類人推理過程、有效擴充大型資料集以及利用情境範例而無需明確重新訓練方面的獨特優勢。研究強調了神經向量符號整合、指令編碼和隱式推理中前景看好的途徑，旨在進一步增強 LAA 的能力。透過探討神經符號 AI 的進展並提出未來的研究方向，這項工作推進了對 AI 技術的理解和發展。

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

摘要：在這項研究中，我們對智慧電網安全性進行全面檢視，探討系統架構、攻擊方法、防禦策略和未來的研究機會。我們深入分析各種攻擊媒介，專注於智慧電網中先進組件所引入的新攻擊面。本檢視特別包含對協調攻擊的廣泛分析，其中包含多種攻擊策略並利用各種智慧電網組件中的漏洞來增加其負面影響，展示這些威脅的複雜性和潛在嚴重性。在此之後，我們探討創新的偵測和緩解策略，包括博弈論、圖論、區塊鏈和機器學習，討論它們在對抗不斷演變的威脅和相關研究挑戰方面的進展。特別是，我們的檢視涵蓋對廣泛使用的基於機器學習的緩解策略的徹底檢驗，分析它們在監督式、非監督式、半監督式、整體式和強化學習中的應用和研究挑戰。此外，我們概述未來的研究方向並探討新技術和問題。我們首先討論現有和新興策略的研究機會，然後探討新技術的潛在作用，例如大型語言模型 (LLM)，以及對抗式機器學習在智慧電網安全未來的威脅。

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v2 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin. A video demonstrating Mobility VLA can be
found here: https://youtu.be/-Tof__Q8_5s

摘要：<paragraph>導航研究中一個難以捉摸的目標，是建立一個智能代理，它可以理解包括自然語言和影像的多模態指令，並執行有用的導航。為了達成此目標，我們研究了一類廣泛有用的導航任務，我們稱之為示範導覽的多模態指令導航 (MINT)，其中環境先驗是透過先前錄製的示範影片提供的。視覺語言模型 (VLM) 的近期進展，展示了一條實現此目標的有前景路徑，因為它展示了感知和推理多模態輸入的能力。然而，VLM 通常訓練用於預測文字輸出，而如何最佳利用它們進行導航，則是一個開放的研究問題。為了解決 MINT，我們提出了 Mobility VLA，這是一種分層的視覺-語言-動作 (VLA) 導航政策，它結合了長語境 VLM 的環境理解和常識推理能力，以及基於拓撲圖的強健低階導航政策。高階政策包含一個長語境 VLM，它採用示範導覽影片和多模態使用者指令作為輸入，以在導覽影片中找到目標幀。接下來，低階政策使用目標幀和離線建構的拓撲圖，在每個時間步產生機器人動作。我們在 836 平方公尺的真實世界環境中評估了 Mobility VLA，並展示了 Mobility VLA 在先前未解決的多模態指令（例如「我應該把這個塑膠箱歸還到哪裡？」）上具有很高的端到端成功率，同時拿著一個塑膠箱。展示 Mobility VLA 的影片可以在這裡找到：https://youtu.be/-Tof__Q8_5s</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

摘要：<paragraph>對於基於文字的人工智慧系統與真實世界互動來說，因果推理是一項必要的技能。由於介入資料的產生成本很高，我們研究一位代理人從被動資料中學習因果推理的程度。具體來說，我們考慮一個公理訓練設置，其中一位代理人從因果公理（或規則）的多個示範中學習，而不是將公理作為歸納偏誤或從資料值中推斷出來。一個關鍵問題是代理人是否會學會從公理示範推廣到新的場景。例如，如果一個Transformer模型在小圖表上因果傳遞性公理的示範中接受訓練，它是否會推廣到在大圖表上應用傳遞性公理？我們的結果基於一個新穎的公理訓練方案，表明這樣的概括是可能的。我們考慮推論一個變數是否導致另一個變數的任務，給定一個因果圖結構。我們發現一個 6700 萬個參數的Transformer模型，在線性因果鏈（以及一些雜訊變化）上訓練時，可以很好地概括到新類型的圖形，包括更長的因果鏈、順序相反的因果鏈和具有分支的圖形；即使它沒有針對此類設置進行明確訓練。我們的模型表現與許多較大的語言模型（例如 GPT-4、Gemini Pro 和 Phi-3）相當（甚至更好）。總體而言，我們的公理訓練框架提供了一個從被動資料中學習因果推理的新範例，只要可以產生足夠的示範，就可以用於學習任意公理。</paragraph>

##### **STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**
2407.12860v1 by Aaron Zolnai-Lucas, Jack Boylan, Chris Hokamp, Parsa Ghaffari

We present Simplified Text-Attributed Graph Embeddings (STAGE), a
straightforward yet effective method for enhancing node features in Graph
Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our
approach leverages Large-Language Models (LLMs) to generate embeddings for
textual attributes. STAGE achieves competitive results on various node
classification benchmarks while also maintaining a simplicity in implementation
relative to current state-of-the-art (SoTA) techniques. We show that utilizing
pre-trained LLMs as embedding generators provides robust features for ensemble
GNN training, enabling pipelines that are simpler than current SoTA approaches
which require multiple expensive training and prompting stages. We also
implement diffusion-pattern GNNs in an effort to make this pipeline scalable to
graphs beyond academic benchmarks.

摘要：我們提出了簡化文字屬性圖嵌入 (STAGE)，這是一種直接但有效的方法，用於增強圖神經網路 (GNN) 模型中的節點特徵，這些模型會編碼文字屬性圖 (TAG)。我們的做法利用大型語言模型 (LLM) 來為文字屬性產生嵌入。STAGE 在各種節點分類基準上取得了有競爭力的結果，同時在實作上也維持了簡潔性，相較於目前的技術水準 (SoTA)。我們展示了使用預訓練的 LLM 作為嵌入產生器，可為整體 GNN 訓練提供強健的特徵，進而建構比目前 SoTA 做法更簡單的管道，而後者需要多個昂貴的訓練和提示階段。我們也實作了擴散模式 GNN，以期讓這個管道能擴充到學術基準之外的圖形。

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

摘要：大型語言模型 (LLM) 的出現徹底改變了我們與圖表互動的方式，進而產生一種稱為 GraphLLM 的新典範。儘管近年來 GraphLLM 方法快速發展，但由於缺乏具有一致實驗協定的基準，因此該領域的進展和理解仍不明確。為了彌補這個差距，我們引入了 GLBench，這是第一個用於評估 GraphLLM 方法在監督式和零次學習場景中的綜合基準。GLBench 提供對不同類別的 GraphLLM 方法進行公平且徹底的評估，以及傳統基準，例如圖神經網路。透過對一組真實世界資料集進行廣泛實驗，並採用一致的資料處理和分割策略，我們發現了幾個關鍵發現。首先，GraphLLM 方法在監督式設定中優於傳統基準，其中 LLM 作為增強器顯示出最穩健的效能。然而，使用 LLM 作為預測器較不有效，而且經常導致無法控制的輸出問題。我們還注意到，對於目前的 GraphLLM 方法並不存在明確的縮放定律。此外，結構和語義對於有效的零次學習傳輸至關重要，而我們提出的簡單基準甚至可以優於針對零次學習場景量身打造的幾個模型。基準的資料和程式碼可以在 https://github.com/NineAbyss/GLBench 中找到。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis Béthune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

摘要：<paragraph>人類使用簡單的文字描述，豐富的連結和關係，來描述複雜的場景。雖然視覺語言的研究旨在開發具有組合理解能力的模型，但現有的數據集尚未反映這一點，這些數據集在很大程度上仍使用純文本來描述圖像。在這項工作中，我們提出了一種新的註釋策略，基於圖表的標題 (GBC)，它使用標籤圖表結構來描述圖像，其中包含各種類型的節點。GBC 中的節點是使用物體檢測和密集標題工具在第一階段創建的，以遞迴嵌套的方式發現和描述實體節點，並在第二階段使用新類型的節點突出顯示，從而將它們進一步連結在一起，實體之間的組合和關係。由於所有 GBC 節點都包含純文本描述，因此 GBC 保留了自然語言中的靈活性，但也可以在其邊緣編碼分層信息。我們證明了 GBC 可以使用現成的多模態 LLM 和開放詞彙檢測模型自動生成，通過構建一個新的數據集 GBC10M，收集了大約 10M CC12M 數據集圖像的 GBC 註釋。我們使用 GBC10M 來展示 GBC 發現的豐富節點標題，並使用 CLIP 訓練進行測量。我們表明，與其他數據集格式相比，使用 GBC 節點的註釋——特別是存儲在組合和關係節點中的註釋——會顯著提升下游模型的性能。為了進一步探索 GBC 提供的機會，我們還提出了一種新的注意機制，它可以利用整個 GBC 圖表，並通過鼓勵性的實驗結果展示了結合圖表結構的額外好處。我們的數據集發布在 \url{https://huggingface.co/graph-based-captions}。</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

摘要：近年来，自然语言处理 (NLP) 在各种人工智能 (AI) 应用中发挥了重要作用，例如聊天机器人、文本生成和语言翻译。大语言模型 (LLM) 的出现极大地提高了这些应用程序的性能，在语言理解和生成方面显示出惊人的结果。然而，它们仍然表现出一些缺点，例如幻觉和缺乏特定领域的知识，这些缺点会影响它们在现实世界中的任务中的表现。通过纳入知识图谱 (KG) 可以有效地减轻这些问题，知识图谱以结构化格式组织信息，以多功能且可解释的方式捕获实体之间的关系。同样，KG 的构建和验证提出了 LLM 可以帮助解决的挑战。LLM 和 KG 之间的互补关系导致了一种将这些技术相结合以实现可信结果的趋势。这项工作收集了 28 篇概述了 KG 驱动的 LLM、基于 LLM 的 KG 和 LLM-KG 混合方法的方法的论文。我们系统地分析和比较了这些方法，以提供一个全面的概述，重点介绍关键趋势、创新技术和共同挑战。这种综合将使该领域的新研究人员和那些寻求加深对如何有效地将 KG 和 LLM 相结合以增强 AI 应用能力的理解的人受益。

##### **FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**
2407.14530v1 by Yi Zhan, Yang Sun, Han Weng, Longjie Cui, Guifeng Wang, Jiajun Xie, Yu Tian, Xiaoming Yin, Boyi Liu, Dongchi Huang

In this paper, we propose a novel graph-based methodology to evaluate the
functional correctness of SQL generation. Conventional metrics for assessing
SQL code generation, such as matching-based and execution-based methods (e.g.,
exact set match and execution accuracy), are subject to two primary
limitations. Firstly, the former fails to effectively assess functional
correctness, as different SQL queries may possess identical functionalities.
Secondly, the latter is susceptible to producing false positive samples in
evaluations. Our proposed evaluation method, \texttt{FuncEvalGMN}, does not
depend on the sufficient preparation of the test data, and it enables precise
testing of the functional correctness of the code. Firstly, we parse SQL using
a relational operator tree (ROT) called \textit{Relnode}, which contains rich
semantic information from the perspective of logical execution.Then, we
introduce a GNN-based approach for predicting the functional correctness of
generated SQL. This approach incorporates global positional embeddings to
address the limitations with the loss of topological information in
conventional graph matching frameworks. As an auxiliary contribution, we
propose a rule-based matching algorithm, Relnode Partial Matching
(\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,
\texttt{Pair-Aug-Spider} with a training set and two testing sets, each
comprising pairs of SQL codes to simulate various SQL code evaluation
scenarios. The training set and one testing dataset focus on code generation
using large language models (LLMs), while the other emphasizes SQL equivalence
rewriting.

摘要：<paragraph>在本文中，我們提出了一種新穎的基於圖的方法來評估 SQL 生成的功能正確性。評估 SQL 程式碼生成的傳統指標，例如基於匹配和基於執行的指標（例如，精確集合匹配和執行準確度），存在兩個主要的限制。首先，前者無法有效評估功能正確性，因為不同的 SQL 查詢可能具有相同的機能。其次，後者在評估中容易產生假陽性樣本。我們提出的評估方法 \texttt{FuncEvalGMN} 不依賴於測試資料的充分準備，並且可以精確測試程式碼的功能正確性。首先，我們使用稱為 \textit{Relnode} 的關係運算元樹 (ROT) 來解析 SQL，其中包含從邏輯執行的角度來看豐富的語義資訊。然後，我們引入一種基於 GNN 的方法來預測生成的 SQL 的功能正確性。這種方法結合了全局位置嵌入，以解決傳統圖形匹配框架中拓撲資訊遺失的限制。作為輔助貢獻，我們提出了一個基於規則的匹配演算法，即 Relnode 部分匹配 (\texttt{RelPM}) 作為基線。最後，我們貢獻了一個資料集 \texttt{Pair-Aug-Spider}，其中包含一個訓練集和兩個測試集，每個測試集都包含成對的 SQL 程式碼來模擬各種 SQL 程式碼評估場景。訓練集和一個測試資料集專注於使用大型語言模型 (LLM) 進行程式碼生成，而另一個則強調 SQL 等價重寫。</paragraph>

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

摘要：知識圖表問答 (KGQA) 簡化了使用自然語言查詢儲存在圖形化模型中的大量知識。然而，研究主要集中在英文上，這對非英語使用者來說是不利的。同時，現有的多語言 KGQA 系統在達成與英文系統相媲美的效能方面面臨挑戰，突顯了從不同語言產生 SPARQL 查詢的困難性。在這項研究中，我們提出了一種簡化的方法，通過將語言學背景和實體資訊直接納入語言模型的處理管道，來增強多語言 KGQA 系統。與依賴於單獨編碼器來整合輔助資訊的現有方法不同，我們的策略利用單一的、預訓練的多語言轉換器語言模型來管理主要輸入和輔助資料。我們的技術顯著提升了語言模型準確地將自然語言查詢轉換為相關 SPARQL 查詢的能力。它在最新的 QALD 資料集，即 QALD-9-Plus 和 QALD-10 上展示了有希望的結果。此外，我們在中文和日文中引入並評估了我們的做法，從而擴展了現有資料集的語言多樣性。

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

摘要：辨識交通事故是任何自動駕駛或道路監控系統的必要部分。事故可能以各種形式出現，了解事故類型可能有助於防止再次發生。將交通事故場景分類為特定事故類型的任務是這項工作的重點。我們將交通事故場景比喻為圖形來解決問題，其中汽車等物體可以表示為節點，而它們之間的相對距離和方向則表示為邊緣。這種事故表示可以稱為場景圖，並用作事故分類器的輸入。使用將場景圖輸入與視覺和語言表示融合的分類器可以獲得更好的結果。這項工作引入了一個多階段、多模態管道，用於預處理交通事故影片、將其編碼為場景圖，以及將此表示與視覺和語言模式對齊以進行事故分類。當在 4 個類別上進行訓練時，我們的模型在熱門交通異常檢測 (DoTA) 基準的（不平衡）子集上實現了 57.77% 的平衡準確率，比不考慮場景圖資訊的情況提高了接近 5 個百分點。

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

摘要：基於 LLM 的代理已在視覺語言導航 (VLN) 任務中展示出令人印象深刻的零次學習效能。然而，這些零次學習方法僅專注於透過選擇預定義導航圖形中的節點來解決高階任務規劃，忽略了實際導航場景中的低階控制。為了彌合此差距，我們提出 AO-Planner，一個用於連續 VLN 任務的新型以可負擔性為導向的規劃架構。我們的 AO-Planner 整合各種基礎模型，以實現以可負擔性為導向的動作規劃和動作決策，兩者都以零次學習的方式執行。具體來說，我們採用視覺可負擔性提示 (VAP) 方法，其中利用 SAM 對可見地面進行分割，以提供導航可負擔性，LLM 根據這些可負擔性選擇潛在的下一個航點，並針對所選航點產生低階路徑規劃。我們進一步引入一個高階代理 PathAgent，以識別最可能的基於像素的路徑，並將其轉換為 3D 座標，以實現低階動作。在具有挑戰性的 R2R-CE 基準測試上的實驗結果表明，AO-Planner 達到了最先進的零次學習效能（SPL 提升 5.5%）。我們的模型在 LLM 和 3D 世界之間建立了一個有效的連結，以規避直接預測世界座標的難題，為在低階動作控制中採用基礎模型提供了新的前景。

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

摘要：最近的研究表明，大型语言模型 (LLM) 容易被错误前提问题 (FPQ) 误导，从而导致事实知识错误，即事实幻觉。用于评估此漏洞的现有基准主要依赖于手动构建，导致规模有限且缺乏可扩展性。在这项工作中，我们引入了一个基于知识图谱 (KG) 创建 FPQ 的自动化可扩展管道。第一步是修改从 KG 中提取的真三元组以创建错误前提。随后，利用 GPT 的最先进功能，我们生成了语义丰富的 FPQ。基于所提出的方法，我们提出了一个综合基准，即基于知识图谱的错误前提问题 (KG-FPQ)，它包含大约 178k 个 FPQ，涵盖三个知识域，六个混淆级别和两种任务格式。使用 KG-FPQ，我们对几个有代表性的 LLM 进行了广泛的评估，并提供了有价值的见解。KG-FPQ 数据集和代码可在~https://github.com/yanxuzhu/KG-FPQ 获得。

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

摘要：<paragraph>最近的研究實證表明，語言模型 (LM) 編碼豐富的世界知識，超越了單純的語義，吸引了各個領域的極大關注。然而，在推薦領域中，LM 是否隱含編碼使用者偏好資訊仍不確定。與普遍認知相反，LM 和傳統推薦模型由於語言和行為建模目標的巨大差距而學習兩個不同的表示空間，這項工作重新思考這種理解，並探索直接從語言表示空間中提取推薦空間。令人驚訝的是，我們的研究結果表明，當從先進的 LM 表示中線性映射時，項目表示會產生優異的推薦效能。此結果表明語言表示空間和有效的推薦空間之間存在同態性，這意味著協作訊號確實可能編碼在先進的 LM 中。受這些研究結果的啟發，我們提出了一個簡單但有效的協同過濾 (CF) 模型，名為 AlphaRec，它利用項目文字元資料（例如標題）的語言表示，而不是傳統基於 ID 的嵌入。具體來說，AlphaRec 由三個主要組成部分組成：多層感知器 (MLP)、圖形卷積和對比學習 (CL) 損失函數，使其極易於實作和訓練。我們的實證結果表明，AlphaRec 在多個資料集上優於領先的基於 ID 的 CF 模型，標誌著這種具有文字嵌入的推薦系統首次達到此效能水準。此外，AlphaRec 引入了一個新的基於語言表示的 CF 典範，具有多項理想的優點：易於實作、輕量級、快速收斂、在新的領域中具有優異的零次學習推薦能力，並且可以了解使用者的意圖。</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

摘要：時間推理 (TR) 是人工智慧的一項關鍵組成部分，
涵蓋了對時間資訊和事件之間關係的理解和處理。為了發現和研究大型語言模型 (LLM) 中的 TR 能力，已透過各種方式建構各種資料集，用於評估 TR 能力的各個面向。我們的工作提出了一種新穎的方法，用於設計和開發一個建構資料集的管道，以評估 LLM 的 TR 能力，方法是利用隨機有向圖生成、LTL 公式和 NuSMV 模型檢查器。根據這個管道，我們還建構了一個資料集作為基準，即 LTLBench，其中包含 2,000 個 TR 挑戰，並用它評估了六個 LLM。此外，我們還進行了額外的實驗，以發現增加事件數量和公式運算子對 TR 問題複雜性和 LLM 效能的影響。我們已經證明，儘管 LLM 在處理 TR 挑戰方面表現出一些希望，但它們仍然難以處理複雜的 TR。我們預期這項工作可以提供對 LLM 中 TR 能力的見解，同時也為未來的 TR 評估提供一個有價值的工具。

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

摘要：大型語言模型廣泛應用於各種任務中，例如客戶支援、內容創作、教育輔導和提供財務指導。然而，一個眾所周知的缺點是它們傾向於產生幻覺。這損害了這些模型所提供資訊的可信度，影響了決策制定和使用者信心。我們提出了一種透過觀察潛在空間的結構並找出幻覺和非幻覺生成中的關聯來偵測幻覺的方法。我們建立了一個圖形結構，連接在嵌入空間中緊密相連的生成。此外，我們採用了一個圖形注意力網路，它利用訊息傳遞來彙總來自相鄰節點的資訊，並根據每個相鄰節點的相關性為其指定不同程度的重要性。我們的研究結果顯示，1) 潛在空間中存在一個結構，可以區分幻覺和非幻覺生成，2) 圖形注意力網路可以學習這個結構並將其概括到未見的生成中，以及 3) 當納入對比學習時，我們方法的穩健性會得到增強。當根據基於證據的基準進行評估時，我們的模型在無法取得基於搜尋的方法的情況下，表現得類似。

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

摘要：生成式 AI 的進步擴展了大型語言模型 (LLM) 在自主代理開發中的潛在應用。實現真正的自主性需要累積和更新從與環境互動中獲得的知識，並有效利用它。當前的基於 LLM 的方法利用過去的經驗，使用完整的觀察、摘要或檢索擴充。然而，這些非結構化的記憶表徵並不能促進複雜決策制定中必不可少的推理和規劃。在我們的研究中，我們介紹了 AriGraph，這是一種新方法，其中代理構建了一個記憶圖，該圖在探索環境時整合了語義和情節記憶。這種圖形結構促進了相互聯繫的概念的有效關聯性檢索，與代理的當前狀態和目標相關，從而作為一個有效的環境模型，增強了代理的探索和規劃能力。我們展示了我們的 Ariadne LLM 代理，配備了這種提議的記憶架構，並增強了規劃和決策制定，有效地處理了 TextWorld 環境中零次學習的複雜任務。我們的做法顯著優於已建立的方法，例如完整歷史、摘要和檢索增強生成，在各種任務中，包括來自第一個 TextWorld 問題競賽的烹飪挑戰和房屋清潔和拼圖尋寶等新任務。

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

摘要：符號句子意義表徵，例如 AMR（抽象意義表徵），提供表達性和結構化的語義圖表，作為簡化下游 NLP 任務的中介。然而，大型語言模型 (LLM) 的指令遵循能力提供了一個捷徑來有效解決 NLP 任務，質疑語義圖表的效用。同時，最近的研究也表明僅將意義表徵用作 LLM 的輔助工具的難度。我們重新審視語義圖表在語法簡化中的位置，語法簡化的任務是在保留句子結構的同時簡化句子結構，這需要語義理解，並在一個新的複雜且自然的數據集上對其進行評估。我們提出的基於 AMR 的方法 AMRS$^3$ 證明了最先進的意義表徵可以導致易於實現的簡化方法，在成本、可解釋性和泛化方面具有競爭優勢和獨特優勢。以 AMRS$^3$ 為錨點，我們發現語法簡化是一項語義圖表有助於 LLM 提示的任務。我們提出 AMRCoC 提示，指導 LLM 模擬圖形演算法，對 AMR 圖形進行明確的符號推理，並展示其在改進 LLM 在以語義為中心的任務（如語法簡化）方面的潛力。

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

摘要：<paragraph>在本文中，我們介紹了對稱為電路發現任務的全面重新表述，以及 DiscoGP，一種基於可微遮罩的發現電路的新穎且有效的演算法。電路發現是透過將其功能和能力解剖成稀疏子網路（電路）來詮釋語言模型（LM）的運算機制的任務。我們在現有的電路發現工作中發現了兩個主要的限制：（1）基於權重和基於連接邊緣的方法之間的二分法迫使研究人員在修剪連接或權重之間進行選擇，從而限制了 LM 機制詮釋的範圍；（2）基於啟用修補的演算法傾向於識別在功能上既不忠實也不完整的電路。這些已識別電路的效能大幅降低，通常導致孤立的近乎隨機效能。此外，電路的補數——即移除已識別電路的原始 LM——仍保留了足夠的效能，這表示現有方法錯失了完整電路的基本組成部分。
DiscoGP 成功地解決了上述兩個問題，並展示了最先進的忠實度、完整性和稀疏性。該演算法的有效性和其新穎的結構為深入瞭解生成式 AI 的內部運作開闢了新的途徑。</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

摘要：本文提出 Bag-of-Concept Graph (BACON)，赋予语言能力有限的模型品尝视觉语言模型 (VLM) 的特权，并提升下游任务，例如检测、视觉问答 (VQA) 和图像生成。由于物理世界中的视觉场景是由对象之间的复杂关系构建而成的，因此 BACON 将注释分解为基本的最小元素，并以图形结构呈现它们。基于元素的风格便于理解，结构化组合解放了困难的定位。在公共可用 VLM 和分割方法的帮助下，精心设计的提示生成了 BACON 标题。通过这种方式，我们收集了一个包含 100K 张注释图像的数据集，该数据集赋予 VLM 显著的能力，例如准确生成 BACON、将提示转换为 BACON 格式、以 BACONr 的风格设想场景，以及通过交互式对话动态修改 BACON 中的元素等等。广泛的代表性实验，包括检测、VQA 和图像生成任务，表明 BACON 作为一条生命线，可以实现以前无法实现的任务，或在当前的尖端解决方案中表现出色。

##### **Knowledge-based Consistency Testing of Large Language Models**
2407.12830v1 by Sai Sathiesh Rajan, Ezekiel Soremekun, Sudipta Chattopadhyay

In this work, we systematically expose and measure the inconsistency and
knowledge gaps of Large Language Models (LLMs). Specifically, we propose an
automated testing framework (called KONTEST) which leverages a knowledge graph
to construct test cases. KONTEST probes and measures the inconsistencies in the
LLM's knowledge of the world via a combination of semantically-equivalent
queries and test oracles (metamorphic or ontological oracle). KONTEST further
mitigates knowledge gaps via a weighted LLM model ensemble. Using four
state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that
KONTEST generates 19.2% error inducing inputs (1917 errors from 9983 test
inputs). It also reveals a 16.5% knowledge gap across all tested LLMs.
KONTEST's mitigation method reduces LLM knowledge gap by 32.48%. Our ablation
study further shows that GPT3.5 is not suitable for knowledge-based consistency
testing because it is only 60%-68% effective in knowledge construction.

摘要：在這項工作中，我們系統性地揭露並衡量大型語言模型 (LLM) 的不一致性和知識差距。具體來說，我們提出了一個自動化測試框架 (稱為 KONTEST)，它利用知識圖譜來建構測試案例。KONTEST 通過語義等效查詢和測試預言 (變形或本體論預言) 的組合來探測和衡量 LLM 對世界知識的不一致性。KONTEST 進一步通過加權 LLM 模型集成來緩解知識差距。使用四種最先進的 LLM（Falcon、Gemini、GPT3.5 和 Llama2），我們表明 KONTEST 生成了 19.2% 的錯誤誘發輸入（9983 個測試輸入中的 1917 個錯誤）。它還揭示了所有測試的 LLM 中有 16.5% 的知識差距。KONTEST 的緩解方法將 LLM 知識差距減少了 32.48%。我們的消融研究進一步表明，GPT3.5 不適合用於基於知識的一致性測試，因為它在知識建構中只有 60%-68% 的有效性。

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

摘要：評估大型語言模型 (LLM) 的圖形理解和推理能力具有挑戰性，且通常不完整。現有的基準主要著重於純粹的圖形理解，缺乏對所有圖形類型和詳細功能定義的全面評估。本文提出了 GraCoRe，一個用於系統評估 LLM 的圖形理解和推理的基準。GraCoRe 使用三層階層分類法對模型進行分類和測試，將功能細分為 10 個不同的領域，並通過 19 個任務進行測試。我們的基準包含 11 個數據集，其中包含 5,140 個不同複雜度的圖形。我們評估了三個閉源和七個開源 LLM，從能力和任務角度進行了徹底的分析。主要發現表明語義豐富化增強了推理性能，節點排序影響任務成功，而處理較長文本的能力並不一定能改善圖形理解或推理。GraCoRe 在 https://github.com/ZIKEYUAN/GraCoRe 開源

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

摘要：知識圖嵌入 (KGE) 是知識圖 (KG) 用於服務各種人工智慧任務的常見方法。嵌入的適當維度取決於特定應用場景的儲存和運算條件。一旦需要新的維度，就需要從頭訓練新的 KGE 模型，這大大增加了訓練成本，並限制了 KGE 在服務各種場景中的效率和靈活性。在這項工作中，我們提出了一種新穎的 KGE 訓練框架 MED，通過它，我們可以訓練一次以獲得適用於具有不同維度需求的多個場景的可裁剪 KGE 模型，可以從中裁剪出所需維度的子模型並直接使用，而無需任何額外訓練。在 MED 中，我們提出了一種相互學習機制，以提高低維子模型的效能，並使高維子模型保留低維子模型具有的能力，一種進化改進機制，以促進高維子模型掌握低維子模型無法學習的知識，以及一種動態損失權重，以自適應地平衡多重損失。在 4 個標準 KG 完成資料集上的 3 個 KGE 模型、一個真實世界大規模 KG 上的 3 個實際應用場景以及將 MED 擴展到語言模型 BERT 的實驗中，展示了 MED 的有效性、高效率和靈活的可擴充性。

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

摘要：大型語言模型 (LLM) 在實際應用中的進展，關鍵在於提升其推理能力。在這項工作中，我們透過大型語言模型 (LLM) 的幾何理解，探討其推理能力。我們建立了 LLM 的表達能力與其自注意力圖密度之間的關聯。我們的分析證明，這些圖的密度定義了 MLP 塊輸入的內在維度。我們透過理論分析和玩具範例證明，較高的內在維度意味著 LLM 具有更大的表達能力。我們進一步提供經驗證據，將這個幾何框架連結到最近在旨在增強 LLM 推理能力的方法中取得的進展。

##### **Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v1 by Devam Mondal, Carlo Lipizzi

In light of recent plagiarism allegations Brough by publishers, newspapers,
and other creators of copyrighted corpora against large language model (LLM)
developers, we propose a novel system, a variant of a plagiarism detection
system, that assesses whether a knowledge source has been used in the training
or fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and a LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional systems
that focus on content matching and keyword identification between a source and
target corpus, our approach enables a broader evaluation of similarity and thus
a more accurate comparison of the similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
modeling "black-box" systems, as well as the training corpus. A prototype of
our system will be found on a hyperlinked GitHub repository.

摘要：鉴于出版商、报纸和其他受版权保护语料库的创造者最近对大型语言模型 (LLM) 开发者提出的剽窃指控，我们提出了一种新颖的系统，该系统是剽窃检测系统的一个变体，它评估知识源是否已用于大型语言模型的训练或微调。与当前方法不同，我们利用一种使用资源描述框架 (RDF) 三元组的方法从源文档和该文档的 LLM 延续中创建知识图谱。然后使用余弦相似性分析这些图谱的内容，并使用图编辑距离的标准化版本分析结构，该版本显示同构度。与专注于源语料库和目标语料库之间的内容匹配和关键词识别的传统系统不同，我们的方法能够对相似性进行更广泛的评估，从而更准确地比较源文档和 LLM 延续之间的相似性，方法是关注思想之间的关系以及它们与其他思想的关系。此外，我们的方法不需要访问 LLM 指标，例如困惑度，这些指标在封闭的大型语言建模“黑匣子”系统以及训练语料库中可能不可用。我们系统的原型将在超链接的 GitHub 存储库中找到。

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

摘要：肽在生物過程和治療中至關重要。在此研究中，我們介紹了多肽，這是一種創新的方法，結合了基於轉換器的語言模型和圖神經網絡 (GNN) 來預測肽的性質。我們結合了專門用於肽性質預測的轉換器模型 PeptideBERT 和 GNN 編碼器，以捕獲基於序列和結構的特徵。通過採用對比語言圖像預訓練 (CLIP)，多肽將來自兩種模態的嵌入對齊到一個共享的潛在空間中，從而增強模型的預測準確度。對溶血和抗污數據集的評估證明了多肽的穩健性，在溶血預測中實現了最先進的 86.185% 準確率。本研究強調了生物信息學中多模態學習的潛力，為基於肽的研究和應用中的準確且可靠的預測鋪平了道路。

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

摘要：大型视觉语言模型 (LVLMs) 在视觉指令遵循任务中会产生幻觉，这限制了它们的可靠性和现实世界的适用性。我们提出了 Pelican——一种旨在通过声明验证来检测和减轻幻觉的新型框架。Pelican 首先根据一阶谓词将视觉声明分解成一个子声明链。这些子声明由 (谓词、问题) 对组成，可以被概念化为计算图的节点。然后，我们使用思想计划提示来生成 Python 代码，通过外部工具的灵活组合来回答这些问题。Pelican 通过引入 (1) 用于对象实例精确接地的中间变量，以及 (2) 用于回答子问题以实现自适应校正和不一致性识别的共享计算，改进了之前的工作。我们最终使用 LLM 的推理能力，通过考虑每个子声明的 (问题、答案) 对的一致性和置信度来验证声明的正确性。我们的实验表明，在各种基线 LVLMs 中，幻觉率下降了约 8%-32%，与 MMHal-Bench 上提出的幻觉缓解方法相比，下降了 27%。在另外两个基准上的结果进一步证实了我们的结果。

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

摘要：最近的研究表明，大型语言模型 (LLM) 仅使用选项就能回答多项选择题，但这是否表示多项选择问答 (MCQA) 排行榜上的 LLM 主要受限于仅选项设置中的能力？为了回答这个问题，我们使用对比集来探查 LLM 在 MCQA 中是否过度依赖仅选项捷径。虽然先前的研究通过昂贵的人工注释或可能存在偏差的模型生成数据来构建对比集，但我们采用图挖掘从现有 MCQA 数据集中提取对比集。我们使用我们的方法在 UnifiedQA 上，这是一个由六个具有高仅选项准确率的常识推理数据集组成的组，构建了一个 820 题的对比集。在验证我们的对比集后，我们测试了 12 个 LLM，发现当同时给出问题和选项时，这些模型不会表现出对仅选项捷径的依赖。因此，尽管 MCQA 容易受到高仅选项准确率的影响，但我们认为 LLM 在 MCQA 排行榜上获得高排名并非仅仅因为它们利用仅选项捷径的能力。

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

摘要：自主代理的開發越來越依賴多模態語言模型 (MLM)，以在具有 GUI 環境（例如網站、桌上型電腦或手機）的自然語言中執行任務。現有的互動環境中 MLM 代理的基準受到以下限制：它們專注於單一環境、缺乏詳細且通用的評估方法，以及建構任務和評估器的複雜性。為了克服這些限制，我們引入了 Crab，這是第一個代理基準架構，旨在支援跨環境任務，並結合了基於圖形的細粒度評估方法和任務與評估器建構的有效機制。我們的架構支援多種裝置，並且可以輕鬆地擴充到任何具有 Python 介面的環境。利用 Crab，我們開發了一個跨平台的 Crab Benchmark-v0，其中包含電腦桌上型電腦和手機環境中的 100 個任務。我們使用不同的單一和多代理系統配置，在這個基準上評估了四種先進的 MLM。實驗結果表明，具有 GPT-4o 的單一代理實現了 35.26% 的最佳完成率。所有架構程式碼、代理程式碼和任務資料集都公開於 https://github.com/camel-ai/crab。

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

摘要：大型語言模型為知識圖譜（KGQA）的創新問答提供了機會。然而，它們並非天生就設計用於查詢生成。為了彌補這一差距，已提出依賴於微調或特定架構的解決方案，取得了良好的結果，但域外分佈泛化能力有限。在本研究中，我們引入了一種稱為動態小樣本學習（DFSL）的新方法。DFSL 集成了語境學習和語義相似性的效率，並為 KGQA 提供了一個普遍適用的解決方案，具有最先進的性能。我們對多個基準資料集和架構配置進行了廣泛的評估。

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v2 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

摘要：這篇論文探討了使用適配器將來自語言學本體的圖形知識整合到多語言大型語言模型 (LLM) 中，以提升低資源語言 (LRL) 在情緒分析 (SA) 和命名實體識別 (NER) 中的效能。我們建立在成功的參數有效微調技術上，例如 K-ADAPTER 和 MAD-X，我們提出了一個類似的做法，將來自多語言圖形、透過語言關係將各種語言中的概念相互連接的知識，納入 LRL 的多語言 LLM 中。具體來說，我們專注於八種 LRL——馬爾他語、保加利亞語、印尼語、尼泊爾語、爪哇語、維吾爾語、藏語和僧伽羅語——並使用在從 ConceptNet 的語言特定部分中提取的資料上微調的語言特定適配器，旨在讓知識轉移到知識圖形涵蓋的語言中。我們比較了各種微調目標，包括標準的遮罩語言模型 (MLM)、具有全詞遮罩的 MLM，以及具有目標遮罩的 MLM，以分析它們在學習和整合提取的圖形資料中的有效性。透過對語言特定任務的實證評估，我們評估結構化圖形知識如何影響多語言 LLM 在 LRL 中的 SA 和 NER 效能，並深入了解為低資源場景調整語言模型的潛在好處。

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v2 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

摘要：知識追蹤 (KT) 的目的是確定學生是否能正確回答下一個問題，這在智慧型教學系統 (ITS) 中是一項至關重要的任務。在教育 KT 場景中，基於 ID 的轉導方法經常面臨嚴重的資料稀疏性和冷啟動問題，其中個別學生和問題之間的互動很稀疏，而且新的問題和概念會持續出現在資料庫中。此外，現有的 KT 模型只會隱含地考慮概念和問題之間的關聯性，缺乏對概念和問題異質圖中更複雜關係的直接建模。在本文中，我們提出了一個具有大型語言模型的結構感知歸納知識追蹤模型（稱為 SINKT），它首次引入了大型語言模型（LLM），並實現了歸納知識追蹤。首先，SINKT 利用 LLM 引入概念之間的結構關係，並為概念和問題構建了一個異質圖。其次，透過使用 LLM 編碼概念和問題，SINKT 結合了語義資訊，以協助預測。最後，SINKT 透過與學生的知識狀態和問題表徵進行互動，預測學生對目標問題的回應。在四個真實世界資料集上的實驗表明，SINKT 在 12 個現有的轉導 KT 模型中取得了最先進的效能。此外，我們探討了 SINKT 在歸納 KT 任務上的效能，並提供了對各種模組的見解。

##### **Revisiting Random Walks for Learning on Graphs**
2407.01214v1 by Jinwoo Kim, Olga Zaghen, Ayhan Suleymanzade, Youngmin Ryou, Seunghoon Hong

We revisit a simple idea for machine learning on graphs, where a random walk
on a graph produces a machine-readable record, and this record is processed by
a deep neural network to directly make vertex-level or graph-level predictions.
We refer to these stochastic machines as random walk neural networks, and show
that we can design them to be isomorphism invariant while capable of universal
approximation of graph functions in probability. A useful finding is that
almost any kind of record of random walk guarantees probabilistic invariance as
long as the vertices are anonymized. This enables us to record random walks in
plain text and adopt a language model to read these text records to solve graph
tasks. We further establish a parallelism to message passing neural networks
using tools from Markov chain theory, and show that over-smoothing in message
passing is alleviated by construction in random walk neural networks, while
over-squashing manifests as probabilistic under-reaching. We show that random
walk neural networks based on pre-trained language models can solve several
hard problems on graphs, such as separating strongly regular graphs where the
3-WL test fails, counting substructures, and transductive classification on
arXiv citation network without training. Code is available at
https://github.com/jw9730/random-walk.

摘要：<paragraph>我們重新審視圖形機器學習的一個簡單想法，其中圖形上的隨機遊走會產生機器可讀的記錄，而這個記錄會由深度神經網路處理，以直接進行頂點層級或圖形層級的預測。我們將這些隨機機器稱為隨機遊走神經網路，並展示我們可以將它們設計成同構不變，同時具備機率中圖形函數的通用近似能力。一個有用的發現是，只要頂點是匿名的，幾乎任何類型的隨機遊走記錄都可以保證機率不變性。這使我們能夠以純文字記錄隨機遊走，並採用語言模型來讀取這些文字記錄，以解決圖形任務。我們進一步建立了一個與訊息傳遞神經網路的平行性，使用馬可夫鏈理論的工具，並展示訊息傳遞中的過度平滑會因隨機遊走神經網路中的構造而得到緩解，而過度壓縮則表現為機率性不足。我們展示了基於預先訓練語言模型的隨機遊走神經網路可以解決圖形上的幾個困難問題，例如分離 3-WL 測試失敗的強正則圖形、計算子結構，以及在 arXiv 引文網路中進行轉導分類，而無需訓練。程式碼可在 https://github.com/jw9730/random-walk 取得。</paragraph>

##### **LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**
2407.00994v2 by Longchao Da, Tiejin Chen, Lu Cheng, Hua Wei

The Large language models (LLMs) have showcased superior capabilities in
sophisticated tasks across various domains, stemming from basic question-answer
(QA), they are nowadays used as decision assistants or explainers for
unfamiliar content. However, they are not always correct due to the data
sparsity in specific domain corpus, or the model's hallucination problems.
Given this, how much should we trust the responses from LLMs? This paper
presents a novel way to evaluate the uncertainty that captures the directional
instability, by constructing a directional graph from entailment probabilities,
and we innovatively conduct Random Walk Laplacian given the asymmetric property
of a constructed directed graph, then the uncertainty is aggregated by the
derived eigenvalues from the Laplacian process. We also provide a way to
incorporate the existing work's semantics uncertainty with our proposed layer.
Besides, this paper identifies the vagueness issues in the raw response set and
proposes an augmentation approach to mitigate such a problem, we conducted
extensive empirical experiments and demonstrated the superiority of our
proposed solutions.

摘要：大型語言模型 (LLM) 在各個領域的複雜任務中展現出卓越的能力，從基本的問答 (QA) 開始，它們現在被用作決策助理或不熟悉內容的說明者。然而，它們並不總是正確的，因為特定領域語料庫中的數據稀疏，或模型的幻覺問題。有鑑於此，我們應該多相信 LLM 的回應？本文提出了一種新的方法來評估捕捉方向不穩定性的不確定性，通過從蘊涵概率構造一個有向圖，並且我們創新地進行隨機遊走拉普拉斯算子，給定一個構造的有向圖的不對稱屬性，然後不確定性由拉普拉斯過程中的導出特徵值聚合。我們還提供了一種將現有工作的語義不確定性與我們提出的層結合起來的方法。此外，本文識別了原始回應集中模糊的問題，並提出了一種擴充方法來減輕這種問題，我們進行了廣泛的實證實驗，並展示了我們提出的解決方案的優越性。

##### **Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**
2407.02528v1 by Romy Fieblinger, Md Tanvirul Alam, Nidhi Rastogi

Cyber threats are constantly evolving. Extracting actionable insights from
unstructured Cyber Threat Intelligence (CTI) data is essential to guide
cybersecurity decisions. Increasingly, organizations like Microsoft, Trend
Micro, and CrowdStrike are using generative AI to facilitate CTI extraction.
This paper addresses the challenge of automating the extraction of actionable
CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs
(KGs). We explore the application of state-of-the-art open-source LLMs,
including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting
meaningful triples from CTI texts. Our methodology evaluates techniques such as
prompt engineering, the guidance framework, and fine-tuning to optimize
information extraction and structuring. The extracted data is then utilized to
construct a KG, offering a structured and queryable representation of threat
intelligence. Experimental results demonstrate the effectiveness of our
approach in extracting relevant information, with guidance and fine-tuning
showing superior performance over prompt engineering. However, while our
methods prove effective in small-scale tests, applying LLMs to large-scale data
for KG construction and Link Prediction presents ongoing challenges.

摘要：網路威脅不斷演變。從非結構化的網路威脅情報 (CTI) 資料中萃取可採取行動的見解，對於引導網路安全決策至關重要。越來越多組織，例如 Microsoft、趨勢科技和 CrowdStrike，使用生成式 AI 來促進 CTI 萃取。本文探討了使用大型語言模型 (LLM) 和知識圖譜 (KG) 的進展，自動萃取可採取行動的 CTI 的挑戰。我們探討了最先進的開源 LLM 的應用，包括 Llama 2 系列、Mistral 7B Instruct 和 Zephyr，以從 CTI 文字中萃取有意義的三元組。我們的做法評估了提示工程、指導架構和微調等技術，以最佳化資訊萃取和結構化。然後，將萃取的資料用於建構 KG，提供威脅情報的結構化且可查詢的表示。實驗結果證明了我們方法在萃取相關資訊方面的有效性，指導和微調顯示出優於提示工程的效能。然而，雖然我們的做法在小規模測試中證明有效，但將 LLM 應用於大規模資料以進行 KG 建構和連結預測，仍存在持續的挑戰。

##### **Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**
2407.00653v1 by Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao

Large Language Models (LLMs) have exhibited impressive proficiency in various
natural language processing (NLP) tasks, which involve increasingly complex
reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving
new knowledge from existing one.While it has been widely studied in the context
of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.
In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for
knowledge reasoning, including methodologies for both dataset construction and
model learning. For dataset construction, we create KnowReason via rule mining
on KGs. For model learning, we observe rule overfitting induced by naive
training. Hence, we enhance CoK with a trial-and-error mechanism that simulates
the human process of internal knowledge exploration. We conduct extensive
experiments with KnowReason. Our results show the effectiveness of CoK in
refining LLMs in not only knowledge reasoning, but also general reasoning
benchmarkms.

摘要：大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中展現出驚人的能力，這些任務涉及越來越複雜的推理。知識推理作為推理的主要類型，旨在從既有知識中推導出新知識。儘管知識推理已在知識圖譜 (KG) 的背景下得到廣泛研究，但 LLM 中的知識推理仍處於探索階段。在本文中，我們介紹了知識推理的綜合框架知識鏈，其中包括用於資料集構建和模型學習的方法。對於資料集構建，我們透過在 KG 中進行規則挖掘來建立 KnowReason。對於模型學習，我們觀察到由天真訓練引發的規則過度擬合。因此，我們使用模擬人類內部知識探索過程的試錯機制來增強 CoK。我們對 KnowReason 進行了廣泛的實驗。我們的結果顯示 CoK 在精煉 LLM 不僅在知識推理方面，還包括一般推理基準方面都非常有效。

##### **BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**
2407.00466v1 by Xinna Lin, Siqi Ma, Junjie Shan, Xiaojing Zhang, Shell Xu Hu, Tiannan Guo, Stan Z. Li, Kaicheng Yu

Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,
draws increasing attention, where one common approach is to build a copilot
agent driven by Large Language Models (LLMs). However, to evaluate such
systems, people either rely on direct Question-Answering (QA) to the LLM
itself, or in a biomedical experimental manner. How to precisely benchmark
biomedical agents from an AI Scientist perspective remains largely unexplored.
To this end, we draw inspiration from one most important abilities of
scientists, understanding the literature, and introduce BioKGBench. In contrast
to traditional evaluation benchmark that only focuses on factual QA, where the
LLMs are known to have hallucination issues, we first disentangle
"Understanding Literature" into two atomic abilities, i) "Understanding" the
unstructured text from research papers by performing scientific claim
verification, and ii) Ability to interact with structured Knowledge-Graph
Question-Answering (KGQA) as a form of "Literature" grounding. We then
formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based
Retrieval-Augmented Generation (RAG) to identify the factual errors of existing
large-scale knowledge graph databases. We collect over two thousand data for
two atomic tasks and 225 high-quality annotated data for the agent task.
Surprisingly, we discover that state-of-the-art agents, both daily scenarios
and biomedical ones, have either failed or inferior performance on our
benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.
On the widely used popular knowledge graph, we discover over 90 factual errors
which provide scenarios for agents to make discoveries and demonstrate the
effectiveness of our approach. The code and data are available at
https://github.com/westlake-autolab/BioKGBench.

摘要：<paragraph>追求生物醫學科學的人工智慧，又稱 AI 科學家，
越來越受到關注，其中一種常見的方法是建立由大型語言模型 (LLM) 驅動的副駕駛代理。然而，要評估此類
系統，人們要么依賴 LLM 本身的直接問答 (QA)，要么依賴生物醫學實驗方式。如何從 AI 科學家的角度精確評量
生物醫學代理在很大程度上仍未探索。
為此，我們從科學家最重要的能力之一，即理解文獻中汲取靈感，並介紹 BioKGBench。與僅關注事實 QA 的傳統評量基準不同，已知 LLM 在事實 QA 中存在幻覺問題，我們首先將
「理解文獻」分解為兩種基本能力，i) 透過執行科學主張驗證來「理解」研究論文中的非結構化文字，以及 ii) 以「文獻」為基礎，與結構化的知識圖表問答 (KGQA) 互動的能力。然後
我們使用 KGQA 和基於網域的檢索擴充產生 (RAG) 制定了一項新穎的代理任務，稱為 KGCheck，以識別現有大型知識圖表資料庫的事實錯誤。我們為
兩個基本任務收集了兩千多個資料，以及 225 個高品質註解資料，以作為代理任務。令人驚訝的是，我們發現最先進的代理，無論是日常情境還是生物醫學，在我們的
基準上都表現不佳或表現較差。然後，我們引入了一個簡單但有效的基準，稱為 BKGAgent。在廣泛使用的熱門知識圖表上，我們發現超過 90 個事實錯誤，這些錯誤為代理提供了發現情境，並證明了我們方法的有效性。程式碼和資料可在
https://github.com/westlake-autolab/BioKGBench 取得。</paragraph>

##### **GraphArena: Benchmarking Large Language Models on Graph Computational Problems**
2407.00379v1 by Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li

The "arms race" of Large Language Models (LLMs) demands novel, challenging,
and diverse benchmarks to faithfully examine their progresses. We introduce
GraphArena, a benchmarking tool designed to evaluate LLMs on graph
computational problems using million-scale real-world graphs from diverse
scenarios such as knowledge graphs, social networks, and molecular structures.
GraphArena offers a suite of 10 computational tasks, encompassing four
polynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,
Travelling Salesman Problem). It features a rigorous evaluation framework that
classifies LLM outputs as correct, suboptimal (feasible but not optimal), or
hallucinatory (properly formatted but infeasible). Evaluation of 10 leading
LLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even
top-performing models struggle with larger, more complex graph problems and
exhibit hallucination issues. Despite the application of strategies such as
chain-of-thought prompting, these issues remain unresolved. GraphArena
contributes a valuable supplement to the existing LLM benchmarks and is
open-sourced at https://github.com/squareRoot3/GraphArena.

摘要：大型語言模型 (LLM) 的「軍備競賽」需要新穎、具挑戰性且多樣化的基準來忠實檢驗其進度。我們推出 GraphArena，這是一個基準工具，旨在使用來自知識圖譜、社交網路和分子結構等多樣化情境的數百萬個真實世界圖形，針對圖形計算問題評估 LLM。GraphArena 提供一系列 10 個計算任務，包含四個多項式時間（例如，最短距離）和六個 NP 完全挑戰（例如，旅行推銷員問題）。它具有一個嚴謹的評估架構，將 LLM 輸出分類為正確、次佳（可行但非最佳）或幻覺（格式正確但不可行）。對包括 GPT-4o 和 LLaMA3-70B-Instruct 在內的 10 個領先 LLM 的評估顯示，即使是效能最佳的模型在處理更大、更複雜的圖形問題時仍會遇到困難，並出現幻覺問題。儘管應用了一系列策略，例如思考鏈提示，這些問題仍未解決。GraphArena 為現有的 LLM 基準提供了有價值的補充，並在 https://github.com/squareRoot3/GraphArena 開源。

##### **Teola: Towards End-to-End Optimization of LLM-based Applications**
2407.00326v1 by Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu

Large language model (LLM)-based applications consist of both LLM and non-LLM
components, each contributing to the end-to-end latency. Despite great efforts
to optimize LLM inference, end-to-end workflow optimization has been
overlooked. Existing frameworks employ coarse-grained orchestration with task
modules, which confines optimizations to within each module and yields
suboptimal scheduling decisions. We propose fine-grained end-to-end
orchestration, which utilizes task primitives as the basic units and represents
each query's workflow as a primitive-level dataflow graph. This explicitly
exposes a much larger design space, enables optimizations in parallelization
and pipelining across primitives of different modules, and enhances scheduling
to improve application-level performance. We build Teola, a novel orchestration
framework for LLM-based applications that implements this scheme. Comprehensive
experiments show that Teola can achieve up to 2.09x speedup over existing
systems across various popular LLM applications.

摘要：大型語言模型 (LLM) 應用程式由 LLM 和非 LLM 元件組成，每個元件都會影響端對端延遲。儘管已針對最佳化 LLM 推論做出許多努力，但端對端工作流程最佳化卻遭到忽略。現有架構採用粗略的編排與任務模組，將最佳化限制在每個模組內，並產生次佳的排程決策。我們提出細緻的端對端編排，它使用任務原語作為基本單位，並將每個查詢的工作流程表示為原語層級資料流圖。這明確地揭露了更大的設計空間，在不同模組的原語之間啟用平行化和管線最佳化，並加強排程以改善應用程式層級效能。我們建構 Teola，一個實作此架構的 LLM 應用程式創新編排架構。全面的實驗顯示，Teola 能在各種熱門 LLM 應用程式中，比現有系統快上 2.09 倍。

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

摘要：類似於專注於彌合具體導航中視覺與語言差距的視覺語言導航 (VLN) 任務，新的會面 (RVS) 任務需要使用非順序導航指令和地圖推理異中心空間關係（與觀察者的觀點無關）。然而，在沒有訓練資料的新環境中，效能會大幅下降。使用與座標配對的開源說明（例如，維基百科）提供了訓練資料，但由於空間導向文字有限，導致地理位置解析度低。我們提出了一種大規模擴充方法，使用現成的地理空間資料為新環境產生高品質的合成資料。我們的建構方法建立了一個基礎知識圖，擷取實體關係。取樣的實體和關係（「商店在學校北邊」）透過以下方式產生導航指令：(i) 使用無關乎語境的文法 (CFG) 產生許多範本來嵌入特定實體和關係；(ii) 將實體和關係輸入大型語言模型 (LLM) 以產生指令。在 RVS 上的全面評估顯示，我們的做法將未見過環境中的 100 公尺準確度提升了 45.83%。此外，我們證明使用基於 CFG 的擴充所訓練的模型，在未見過和見過環境中，都比使用基於 LLM 的擴充所訓練的模型獲得了更好的效能。這些發現表明，在以前未知的環境中，明確建構用於基於文字的地理空間推理的空間資訊的潛在優勢，可以解鎖資料稀少的場景。


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v1](http://arxiv.org/abs/2408.00756v1)|null|
|**2024-08-01**|**Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**|Venkat Margapuri et.al.|[2408.00749v1](http://arxiv.org/abs/2408.00749v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**|Angona Biswas et.al.|[2408.00348v1](http://arxiv.org/abs/2408.00348v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|null|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)**|Adam Gould et.al.|[2408.00108v1](http://arxiv.org/abs/2408.00108v1)|null|
|**2024-07-31**|**A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**|Mothilal Asokan et.al.|[2407.21739v1](http://arxiv.org/abs/2407.21739v1)|null|
|**2024-07-31**|**Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**|Krishan Agyakari Raja Babu et.al.|[2407.21674v1](http://arxiv.org/abs/2407.21674v1)|null|
|**2024-07-31**|**Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**|Hermione Warr et.al.|[2407.21638v1](http://arxiv.org/abs/2407.21638v1)|null|
|**2024-07-31**|**Voxel Scene Graph for Intracranial Hemorrhage**|Antoine P. Sanner et.al.|[2407.21580v1](http://arxiv.org/abs/2407.21580v1)|null|
|**2024-07-31**|**Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**|I. M. Chernenkiy et.al.|[2407.21516v1](http://arxiv.org/abs/2407.21516v1)|null|
|**2024-07-31**|**Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**|Junxuan Yu et.al.|[2407.21490v1](http://arxiv.org/abs/2407.21490v1)|null|
|**2024-07-31**|**Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**|Mengtian Kang et.al.|[2407.21467v1](http://arxiv.org/abs/2407.21467v1)|null|
|**2024-07-31**|**Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**|Danfeng Guo et.al.|[2407.21368v1](http://arxiv.org/abs/2407.21368v1)|null|
|**2024-07-31**|**MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**|Adrian Celaya et.al.|[2407.21343v1](http://arxiv.org/abs/2407.21343v1)|null|
|**2024-07-31**|**Robust Box Prompt based SAM for Medical Image Segmentation**|Yuhao Huang et.al.|[2407.21284v1](http://arxiv.org/abs/2407.21284v1)|null|
|**2024-07-31**|**Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**|Marcelo Corrales Compagnucci et.al.|[2407.21281v1](http://arxiv.org/abs/2407.21281v1)|null|
|**2024-07-31**|**FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**|Rujia Shen et.al.|[2407.21275v1](http://arxiv.org/abs/2407.21275v1)|null|
|**2024-07-31**|**Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**|Rohini Banerjee et.al.|[2407.21273v1](http://arxiv.org/abs/2407.21273v1)|null|
|**2024-07-30**|**Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**|Mayanka Chandrashekar et.al.|[2407.21149v1](http://arxiv.org/abs/2407.21149v1)|null|
|**2024-07-30**|**Zero Shot Health Trajectory Prediction Using Transformer**|Pawel Renc et.al.|[2407.21124v1](http://arxiv.org/abs/2407.21124v1)|null|
|**2024-07-30**|**CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**|Yuexi Du et.al.|[2407.21011v1](http://arxiv.org/abs/2407.21011v1)|[link](https://github.com/xypb/cleft)|
|**2024-07-30**|**Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**|Eugenio Lomurno et.al.|[2407.20830v1](http://arxiv.org/abs/2407.20830v1)|null|
|**2024-07-30**|**Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**|Michael Kölle et.al.|[2407.20739v1](http://arxiv.org/abs/2407.20739v1)|null|
|**2024-07-29**|**Dense Self-Supervised Learning for Medical Image Segmentation**|Maxime Seince et.al.|[2407.20395v1](http://arxiv.org/abs/2407.20395v1)|null|
|**2024-07-29**|**Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**|Ruochen Li et.al.|[2407.20108v1](http://arxiv.org/abs/2407.20108v1)|null|
|**2024-07-29**|**Robust Conformal Volume Estimation in 3D Medical Images**|Benjamin Lambert et.al.|[2407.19938v1](http://arxiv.org/abs/2407.19938v1)|[link](https://github.com/benolmbrt/wcp_miccai)|
|**2024-07-29**|**Yucca: A Deep Learning Framework For Medical Image Analysis**|Sebastian Nørgaard Llambias et.al.|[2407.19888v1](http://arxiv.org/abs/2407.19888v1)|[link](https://github.com/sllambias/yucca)|
|**2024-07-29**|**CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**|Jingwei Zhu et.al.|[2407.19705v2](http://arxiv.org/abs/2407.19705v2)|[link](https://github.com/cas-siat-xinhai/collectivesft)|
|**2024-07-29**|**Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**|Marco AF Pimentel et.al.|[2407.21072v1](http://arxiv.org/abs/2407.21072v1)|null|
|**2024-07-29**|**Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**|Minxiao Chen et.al.|[2407.19668v1](http://arxiv.org/abs/2407.19668v1)|[link](https://github.com/faceless0124/mghstn)|
|**2024-07-28**|**Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**|Heejoon Koo et.al.|[2407.19540v1](http://arxiv.org/abs/2407.19540v1)|null|
|**2024-07-28**|**Nudging Consent and the New Opt Out System to the Processing of Health Data in England**|Janos Meszaros et.al.|[2407.19447v1](http://arxiv.org/abs/2407.19447v1)|null|
|**2024-07-28**|**ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**|Zhen Chen et.al.|[2407.19435v1](http://arxiv.org/abs/2407.19435v1)|[link](https://github.com/zonmgin-zhang/asi-seg)|
|**2024-07-28**|**A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**|Meng Jiang et.al.|[2407.19422v1](http://arxiv.org/abs/2407.19422v1)|null|
|**2024-07-28**|**Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**|Aamer Abdul Rahman et.al.|[2407.19380v1](http://arxiv.org/abs/2407.19380v1)|null|
|**2024-07-28**|**Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**|Yuan Xue et.al.|[2407.19359v1](http://arxiv.org/abs/2407.19359v1)|null|
|**2024-07-27**|**Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification**|Santosh V. Patapati et.al.|[2407.19340v1](http://arxiv.org/abs/2407.19340v1)|null|
|**2024-07-27**|**Multi-Modal CLIP-Informed Protein Editing**|Mingze Yin et.al.|[2407.19296v1](http://arxiv.org/abs/2407.19296v1)|null|
|**2024-07-27**|**Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review**|Tongyue Shi et.al.|[2407.19256v1](http://arxiv.org/abs/2407.19256v1)|null|
|**2024-07-27**|**Channel Boosted CNN-Transformer-based Multi-Level and Multi-Scale Nuclei Segmentation**|Zunaira Rauf et.al.|[2407.19186v1](http://arxiv.org/abs/2407.19186v1)|null|
|**2024-07-26**|**Large Language Models as Co-Pilots for Causal Inference in Medical Studies**|Ahmed Alaa et.al.|[2407.19118v1](http://arxiv.org/abs/2407.19118v1)|null|
|**2024-07-26**|**Solving Robotics Problems in Zero-Shot with Vision-Language Models**|Zidan Wang et.al.|[2407.19094v1](http://arxiv.org/abs/2407.19094v1)|null|
|**2024-07-26**|**Using Large Language Models for the Interpretation of Building Regulations**|Stefan Fuchs et.al.|[2407.21060v1](http://arxiv.org/abs/2407.21060v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-26**|**Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**|Yinghao Zhu et.al.|[2407.18525v1](http://arxiv.org/abs/2407.18525v1)|[link](https://github.com/yhzhu99/ehr-llm-benchmark)|
|**2024-07-26**|**A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**|Laiyi Fu et.al.|[2407.18483v4](http://arxiv.org/abs/2407.18483v4)|[link](https://github.com/sperfu/eyedoc)|
|**2024-07-26**|**Towards Automated Solution Recipe Generation for Industrial Asset Management with LLM**|Nianjun Zhou et.al.|[2407.18992v1](http://arxiv.org/abs/2407.18992v1)|null|
|**2024-07-25**|**HDL-GPT: High-Quality HDL is All You Need**|Bhuvnesh Kumar et.al.|[2407.18423v1](http://arxiv.org/abs/2407.18423v1)|null|
|**2024-07-25**|**SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**|Sai Puppala et.al.|[2407.18387v1](http://arxiv.org/abs/2407.18387v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|[link](https://github.com/scjjb/MultiscalePathGraph)|
|**2024-07-25**|**HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**|Qingyu Guo et.al.|[2407.17879v2](http://arxiv.org/abs/2407.17879v2)|null|
|**2024-07-25**|**EEG-SSM: Leveraging State-Space Model for Dementia Detection**|Xuan-The Tran et.al.|[2407.17801v1](http://arxiv.org/abs/2407.17801v1)|null|
|**2024-07-25**|**Closing the gap between open-source and commercial large language models for medical evidence summarization**|Gongbo Zhang et.al.|[2408.00588v1](http://arxiv.org/abs/2408.00588v1)|null|
|**2024-07-25**|**Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**|Yudara Kularathne et.al.|[2407.17762v1](http://arxiv.org/abs/2407.17762v1)|null|
|**2024-07-25**|**Cost-effective Instruction Learning for Pathology Vision and Language Analysis**|Kaitao Chen et.al.|[2407.17734v1](http://arxiv.org/abs/2407.17734v1)|[link](https://github.com/jlinekai/clover)|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Improving ICD coding using Chapter based Named Entities and Attentional Models**|Abhijith R. Beeravolu et.al.|[2407.17230v1](http://arxiv.org/abs/2407.17230v1)|null|
|**2024-07-24**|**Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**|Xiaoyu Tan et.al.|[2407.17164v2](http://arxiv.org/abs/2407.17164v2)|null|
|**2024-07-24**|**SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**|Bernardo Consoli et.al.|[2407.17126v1](http://arxiv.org/abs/2407.17126v1)|null|
|**2024-07-24**|**SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**|Changchang Yin et.al.|[2407.16999v1](http://arxiv.org/abs/2407.16999v1)|[link](https://github.com/yinchangchang/sepsislab)|
|**2024-07-24**|**Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**|Nur Ahmad Khatim et.al.|[2407.16962v1](http://arxiv.org/abs/2407.16962v1)|[link](https://github.com/inteligensi/dsapomdps.jl)|
|**2024-07-23**|**AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**|Yuheng Wang et.al.|[2407.16822v1](http://arxiv.org/abs/2407.16822v1)|[link](https://github.com/ryan315/7pgd)|
|**2024-07-23**|**Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges**|Zahraa Al Sahili et.al.|[2407.16804v1](http://arxiv.org/abs/2407.16804v1)|null|
|**2024-07-23**|**Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**|Daniela L. Ramos et.al.|[2407.16608v1](http://arxiv.org/abs/2407.16608v1)|null|
|**2024-07-23**|**A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**|Giorgos Lysandrou et.al.|[2407.16593v1](http://arxiv.org/abs/2407.16593v1)|null|
|**2024-07-23**|**Prompt Injection Attacks on Large Language Models in Oncology**|Jan Clusmann et.al.|[2407.18981v1](http://arxiv.org/abs/2407.18981v1)|null|
|**2024-07-23**|**Knowledge Models for Cancer Clinical Practice Guidelines : Construction, Management and Usage in Question Answering**|Pralaypati Ta et.al.|[2407.21053v1](http://arxiv.org/abs/2407.21053v1)|null|
|**2024-07-23**|**Virtue Ethics For Ethically Tunable Robotic Assistants**|Rajitha Ramanayake et.al.|[2407.16361v1](http://arxiv.org/abs/2407.16361v1)|null|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning**|Yufeng Li et.al.|[2407.16715v2](http://arxiv.org/abs/2407.16715v2)|null|
|**2024-07-22**|**Artificial Intelligence-based Decision Support Systems for Precision and Digital Health**|Nina Deliu et.al.|[2407.16062v1](http://arxiv.org/abs/2407.16062v1)|null|
|**2024-07-22**|**GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**|Zhaojie Fang et.al.|[2407.15719v1](http://arxiv.org/abs/2407.15719v1)|[link](https://github.com/tinysqua/gfe-mamba)|
|**2024-07-22**|**Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**|Eugenio Lomurno et.al.|[2407.15526v2](http://arxiv.org/abs/2407.15526v2)|null|
|**2024-07-22**|**A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**|Yingxue Xu et.al.|[2407.15362v1](http://arxiv.org/abs/2407.15362v1)|null|
|**2024-07-21**|**They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models**|Mohammad Saeid Mahdavinejad et.al.|[2407.21041v1](http://arxiv.org/abs/2407.21041v1)|null|
|**2024-07-21**|**Genetic Algorithm to Optimize Design of Micro-Surgical Scissors**|Fatemeh Norouziani et.al.|[2407.15243v1](http://arxiv.org/abs/2407.15243v1)|null|
|**2024-07-21**|**MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM**|Navyansh Mahla et.al.|[2407.15042v1](http://arxiv.org/abs/2407.15042v1)|null|
|**2024-07-20**|**Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives**|Sudeshna Jana et.al.|[2407.21039v1](http://arxiv.org/abs/2407.21039v1)|null|
|**2024-07-20**|**Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction**|Petros Koutsouvelis et.al.|[2407.14876v1](http://arxiv.org/abs/2407.14876v1)|null|
|**2024-07-20**|**PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates**|Junjie Shi et.al.|[2407.14796v1](http://arxiv.org/abs/2407.14796v1)|[link](https://github.com/jun-jie-shi/passion)|
|**2024-07-19**|**Improving Representation of High-frequency Components for Medical Foundation Models**|Yuetan Chu et.al.|[2407.14651v2](http://arxiv.org/abs/2407.14651v2)|[link](https://github.com/Arturia-Pendragon-Iris/Frepa)|
|**2024-07-19**|**CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models**|Rikhiya Ghosh et.al.|[2407.14640v1](http://arxiv.org/abs/2407.14640v1)|null|
|**2024-07-19**|**Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis**|Kamyab Karimi et.al.|[2407.14631v1](http://arxiv.org/abs/2407.14631v1)|null|
|**2024-07-19**|**Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**|Kun Zhao et.al.|[2407.14326v1](http://arxiv.org/abs/2407.14326v1)|null|
|**2024-07-19**|**Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**|José Daniel Pascual-Triana et.al.|[2407.14210v1](http://arxiv.org/abs/2407.14210v1)|null|
|**2024-07-19**|**Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**|Tobias Kerner et.al.|[2407.14076v2](http://arxiv.org/abs/2407.14076v2)|null|
|**2024-07-19**|**HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**|Prerana Sanjay Kulkarni et.al.|[2407.14030v1](http://arxiv.org/abs/2407.14030v1)|null|
|**2024-07-18**|**DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**|Xiaoya Tang et.al.|[2407.13920v1](http://arxiv.org/abs/2407.13920v1)|null|
|**2024-07-18**|**Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset**|Yi Sheng et.al.|[2407.13896v1](http://arxiv.org/abs/2407.13896v1)|null|
|**2024-07-18**|**APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy**|Yi Sheng et.al.|[2407.14564v1](http://arxiv.org/abs/2407.14564v1)|null|
|**2024-07-18**|**Addressing Imbalance for Class Incremental Learning in Medical Image Classification**|Xuze Hao et.al.|[2407.13768v1](http://arxiv.org/abs/2407.13768v1)|null|
|**2024-07-18**|**Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**|Longchao Da et.al.|[2407.13689v1](http://arxiv.org/abs/2407.13689v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|

#### Abstracts
##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v1 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment a variety of objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we provide an extensive evaluation of SAM
2's ability to segment both 2D and 3D medical images. We collect 18 medical
imaging datasets, including common 3D modalities such as computed tomography
(CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)
as well as 2D modalities such as X-ray and ultrasound. We consider two
evaluation pipelines of SAM 2: (1) multi-frame 3D segmentation, where prompts
are provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. We learn that SAM 2 exhibits similar performance as SAM
under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

摘要：分段任何模型 (SAM) 因其在給定提示的情況下分段圖像中各種物體的能力而備受關注。最近開發的 SAM 2 已將此能力擴展到影片輸入。這開啟了一個將 SAM 應用於 3D 影像的機會，這是醫學影像領域的基礎任務之一。在本文中，我們對 SAM 2 分段 2D 和 3D 醫學影像的能力進行了廣泛評估。我們收集了 18 個醫學影像資料集，包括常見的 3D 方式，例如電腦斷層掃描 (CT)、磁振造影 (MRI) 和正子發射斷層掃描 (PET)，以及 2D 方式，例如 X 光和超音波。我們考慮了 SAM 2 的兩個評估管道：(1) 多幀 3D 分段，其中提示提供給從體積中選取的一個或多個切片，以及 (2) 單幀 2D 分段，其中提示提供給每個切片。前者僅適用於 3D 方式，而後者適用於 2D 和 3D 方式。我們了解到，在單幀 2D 分段下，SAM 2 表現出與 SAM 相似的效能，而在多幀 3D 分段下則表現出不同的效能，具體取決於標記切片的選擇、傳播方向、傳播期間使用的預測等。

##### **Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer**
2408.00749v1 by Venkat Margapuri, Prapti Thapaliya, Trevor Rife

Modern day studies show a high degree of correlation between high yielding
crop varieties and plants with upright leaf angles. It is observed that plants
with upright leaf angles intercept more light than those without upright leaf
angles, leading to a higher rate of photosynthesis. Plant scientists and
breeders benefit from tools that can directly measure plant parameters in the
field i.e. on-site phenotyping. The estimation of leaf angles by manual means
in a field setting is tedious and cumbersome. We mitigate the tedium using a
combination of the Mask R-CNN instance segmentation neural network, and Line
Segment Transformer (LETR), a vision transformer. The proposed Computer Vision
(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer
2015- Ames MLA, with a combined total of 1,827 plant images collected in the
field using FieldBook, an Android application aimed at on-site phenotyping. The
leaf angles estimated by the proposed pipeline on the image datasets are
compared to two independent manual measurements using ImageJ, a Java-based
image processing program developed at the National Institutes of Health and the
Laboratory for Optical and Computational Instrumentation. The results, when
compared for similarity using the Cosine Similarity measure, exhibit 0.98
similarity scores on both independent measurements of Summer 2015-Ames ULA and
Summer 2015-Ames MLA image datasets, demonstrating the feasibility of the
proposed pipeline for on-site measurement of leaf angles.

摘要：<paragraph>現代研究顯示，高產量作物品種和葉片角度直立的植物之間有高度相關性。觀察到葉片角度直立的植物比葉片角度不直立的植物攔截更多光線，從而導致更高的光合作用速率。植物科學家和育種者受益於可以在田間直接測量植物參數的工具，即現場表型分析。在田間環境中通過手動方式估計葉片角度既繁瑣又麻煩。我們使用 Mask R-CNN 實例分割神經網路和線段Transformer (LETR)（一種視覺Transformer）的組合來減輕繁瑣性。所提出的計算機視覺 (CV) 管線應用於兩個圖像資料集，Summer 2015-Ames ULA 和 Summer 2015- Ames MLA，總共包含 1,827 張植物圖像，這些圖像是在田間使用 FieldBook（一種針對現場表型分析的 Android 應用程式）收集的。使用所提出的管線估計的圖像資料集上的葉片角度與使用 ImageJ（一種由美國國家衛生研究院和光學和計算儀器實驗室開發的基於 Java 的影像處理程式）進行的兩次獨立手動測量進行比較。將結果使用餘弦相似度測量進行相似性比較時，在 Summer 2015-Ames ULA 和 Summer 2015-Ames MLA 影像資料集的兩次獨立測量中都顯示出 0.98 的相似度分數，證明了所提出的管線用於現場測量葉片角度的可行性。</paragraph>

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

摘要：大型語言模型（LLM）的新興能力已證明在解決醫療問題方面具有巨大潛力。它們可能擁有大量的醫療知識，但仍可能產生幻覺，並且在知識更新方面缺乏靈活性。雖然已提出檢索增強生成（RAG）以利用外部知識庫增強 LLM 的醫療問題解答能力，但在需要多輪信息檢索的複雜情況下，它仍可能失敗。為了解決這個問題，我們提出了用於醫療的迭代 RAG（i-MedRAG），其中 LLM 可以根據先前的信息檢索嘗試反覆詢問後續查詢。在 i-MedRAG 的每次迭代中，後續查詢將由基本的 RAG 系統回答，並且它們將進一步用於指導下一次迭代中的查詢生成。我們的實驗表明，與美國醫學執照考試（USMLE）中臨床小插圖中的複雜問題以及 Massive Multitask Language Understanding（MMLU）數據集中各種知識測試中的基本 RAG 相比，i-MedRAG 帶來的各種 LLM 的改進性能。值得注意的是，我們的零次學習 i-MedRAG 在 GPT-3.5 上優於所有現有的提示工程和微調方法，在 MedQA 數據集上達到了 69.68% 的準確率。此外，我們描述了 i-MedRAG 的擴展屬性，包括不同的後續查詢迭代和每個迭代的不同查詢數量。我們的案例研究表明，i-MedRAG 可以靈活地詢問後續查詢以形成推理鏈，從而對醫療問題進行深入分析。據我們所知，這是第一個將後續查詢納入醫療 RAG 的同類研究。

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

摘要：描繪病灶和解剖結構對於影像導引介入非常重要。點監督醫學影像分割（PSS）具有減輕昂貴的專家描繪標籤的巨大潛力。然而，由於缺乏精確的大小和邊界引導，PSS 的有效性通常低於預期。儘管最近的視覺基礎模型，例如醫學分割任何模型（MedSAM），在邊界框提示分割方面取得了重大進展，但利用點註釋並不容易，而且容易產生語義歧義。在這項初步研究中，我們引入了一個迭代框架來促進語義感知點監督 MedSAM。具體來說，語義框提示生成器（SBPG）模組能夠將點輸入轉換為潛在的偽邊界框建議，這些建議由基於原型的語義相似性明確細化。然後，由提示引導的空間細化（PGSR）模組繼承，它利用 MedSAM 的出色可概化性來推斷分割蒙版，這也會更新 SBPG 中的框建議種子。通過充分的迭代可以逐步提高性能。我們對 BraTS2018 進行了全腦腫瘤分割評估，並證明其性能優於傳統的 PSS 方法，並且與框監督方法相當。

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

摘要：中醫獨特的診治手法和顯著的臨床療效，在老年照護與保健領域中扮演著重要的角色，特別是在老年人常見慢性疾病的復健上。因此，建構一個中醫醫療照護聊天機器人，將有助於使用者以直接且自然的方式取得諮詢服務。然而，中醫所涉及的穴位、經絡等概念，在諮詢時總是會出現，而這些無法直觀地顯示出來。為了解決這個問題，我們開發了一個基於 3D 人體模型和知識圖譜的醫療照護聊天機器人（HBot），它提供了知識問答、處方推薦、艾灸療法推薦和穴位查詢等對話服務。當使用者與 HBot 的對話中涉及到具體穴位時，3D 人體會跳轉到對應的穴位並將其高亮顯示。此外，HBot 還可以用於培訓場景中，通過直觀地顯示穴位和知識卡片，來加速中醫教學的進程。示範影片可於 https://www.youtube.com/watch?v=UhQhutSKkTU 取得。我們的程式碼和資料集已於 Gitee 公開：https://gitee.com/plabrolin/interactive-3d-acup.git

##### **Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks**
2408.00348v1 by Angona Biswas, MD Abdullah Al Nasim, Kishor Datta Gupta, Roy George, Abdur Rashid

Machine learning (ML) is a rapidly developing area of medicine that uses
significant resources to apply computer science and statistics to medical
issues. ML's proponents laud its capacity to handle vast, complicated, and
erratic medical data. It's common knowledge that attackers might cause
misclassification by deliberately creating inputs for machine learning
classifiers. Research on adversarial examples has been extensively conducted in
the field of computer vision applications. Healthcare systems are thought to be
highly difficult because of the security and life-or-death considerations they
include, and performance accuracy is very important. Recent arguments have
suggested that adversarial attacks could be made against medical image analysis
(MedIA) technologies because of the accompanying technology infrastructure and
powerful financial incentives. Since the diagnosis will be the basis for
important decisions, it is essential to assess how strong medical DNN tasks are
against adversarial attacks. Simple adversarial attacks have been taken into
account in several earlier studies. However, DNNs are susceptible to more risky
and realistic attacks. The present paper covers recent proposed adversarial
attack strategies against DNNs for medical imaging as well as countermeasures.
In this study, we review current techniques for adversarial imaging attacks,
detections. It also encompasses various facets of these techniques and offers
suggestions for the robustness of neural networks to be improved in the future.

摘要：機器學習 (ML) 是醫學領域中快速發展的一個領域，它利用大量的資源將電腦科學和統計學應用於醫療問題。ML 的支持者讚揚它處理大量、複雜且不規則醫療資料的能力。眾所周知，攻擊者可能會透過故意為機器學習分類器建立輸入來導致錯誤分類。對抗範例的研究已在電腦視覺應用領域中廣泛進行。醫療保健系統被認為非常困難，因為它們包含安全性及生死攸關的考量，且效能準確性非常重要。最近的論點表明，由於伴隨而來的技術基礎設施和強大的財務誘因，對抗攻擊可能會針對醫學影像分析 (MedIA) 技術進行。由於診斷將成為重要決策的基礎，因此評估醫療 DNN 任務對抗攻擊的強弱非常重要。在先前的多項研究中已考慮了簡單的對抗攻擊。然而，DNN 容易受到風險更高且更逼真的攻擊。本文涵蓋了針對用於醫學影像的 DNN 所提出的最新對抗攻擊策略以及對策。在本研究中，我們回顧了當前對抗影像攻擊的技術和檢測方法。它還包含了這些技術的各個方面，並提供了改進神經網路在未來強健性的建議。

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

摘要：了解醫學影像的形態結構並精確分割感興趣或異常區域是一項重要的任務，有助於診斷。然而，醫學影像的獨特屬性使得清晰的分割變得困難，而標籤的高成本和耗時任務導致了地面實況的粗略表示。面對這些問題，我們提出了一個新的擴散Transformer分割（DTS）模型，用於在有噪聲的情況下進行穩健分割。我們通過應用捕獲全局依賴性的自注意力Transformer架構，提出了一個替代主流去噪 U-Net 編碼器的方案。此外，我們提出了 k 近鄰標籤平滑、反向邊界注意力，以及使用形態驅動學習的自監督學習，以提高識別複雜結構的能力。我們的模型分析了影像的形態表示，在各種醫學影像方式中顯示出比以前模型更好的結果，包括 CT、MRI 和病灶影像。

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

摘要：人工智慧 (AI) 技術在醫學影像方面的發展需要取得大規模且多元的資料集，以進行訓練和評估。在皮膚科中，取得此類資料集仍然具有挑戰性，原因在於患者族群、照明條件和取得系統特性有顯著的變化。在這項工作中，我們提出 S-SYNTH，這是第一個基於知識、可適應的開放原始碼皮膚模擬架構，可使用解剖學啟發的多層、多組成皮膚和生長病灶模型，快速產生合成皮膚、3D 模型和數位渲染影像。皮膚模型允許控制皮膚外觀的變化，例如膚色、毛髮存在、病灶形狀和血液比例等參數。我們使用這個架構來研究可能的變化對皮膚病灶分割 AI 模型的開發和評估的影響，並顯示使用合成資料取得的結果遵循與真實皮膚科影像類似的比較趨勢，同時減輕現有資料集的偏差和限制，包括資料集規模小、缺乏多元性以及代表性不足。

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

摘要：本研究針對當代大型語言模型 (LLM) 中的刻板印象內容進行分類。我們提示 ChatGPT 3.5、Llama 3 和 Mixtral 8x7B 這三種強大且廣泛使用的 LLM，了解與 87 個社會類別（例如性別、種族、職業）相關的特徵。我們識別出 14 個刻板印象面向（例如道德、能力、健康、信仰、情緒），約佔 LLM 刻板印象關聯的 90%。溫暖和能力面向是最頻繁的內容，但所有其他面向都很普遍。LLM 中的刻板印象比人類更正面，但不同類別和面向之間存在顯著差異。最後，分類法預測了 LLM 對社會類別的內部評估（例如類別的正面/負面呈現方式），支持了使用多維分類法來表徵 LLM 刻板印象的相關性。我們的研究結果表明，高維度的人類刻板印象反映在 LLM 中，並且必須在 AI 稽核和消除偏見中加以考慮，以將依賴 LLM 中偏見的低維度觀點造成的未識別危害降到最低。

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)**
2408.00108v1 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

摘要：為了提升可解釋、資料驅動分類模型的效能與靈活性，本研究提出了一種將使用者定義的偏好結合抽象論證與案例基礎推理 (CBR) 的新穎整合方式。具體來說，我們引入了偏好基礎抽象論證，用於案例基礎推理 (我們稱之為 AA-CBR-P)，允許使用者定義多種方法來比較案例，並透過設定順序來指定他們對這些比較方法的偏好。我們證明了此模型在進行預測時會固有地遵循這些偏好，並說明先前用於案例基礎推理的抽象論證不足以表達對論證組成部分的偏好。接著，我們展示如何將此方法應用於一個真實世界的醫療資料集，該資料集來自一項臨床試驗，評估了對原發性腦瘤患者的不同評估方法。我們透過實證證明，我們的做法在這個資料集上優於其他可解釋機器學習模型。

##### **A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation**
2407.21739v1 by Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar

Adapting foundation models for medical image analysis requires finetuning
them on a considerable amount of data because of extreme distribution shifts
between natural (source) data used for pretraining and medical (target) data.
However, collecting task-specific medical data for such finetuning at a central
location raises many privacy concerns. Although Federated learning (FL)
provides an effective means for training on private decentralized data,
communication costs in federating large foundation models can quickly become a
significant bottleneck, impacting the solution's scalability. In this work, we
address this problem of efficient communication while ensuring effective
learning in FL by combining the strengths of Parameter-Efficient Fine-tuning
(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)
in a federated manner to adapt the Segment Anything Model (SAM) for 3D medical
image segmentation. Unlike prior works that utilize LoRA and finetune the
entire decoder, we critically analyze the contribution of each granular
component of SAM on finetuning performance. Thus, we identify specific layers
to be federated that are very efficient in terms of communication cost while
producing on-par accuracy. Our experiments show that retaining the parameters
of the SAM model (including most of the decoder) in their original state during
adaptation is beneficial because fine-tuning on small datasets tends to distort
the inherent capabilities of the underlying foundation model. On Fed-KiTS, our
approach decreases communication cost (~48x) compared to full fine-tuning while
increasing performance (~6% Dice score) in 3D segmentation tasks. Our approach
performs similar to SAMed while achieving ~2.8x reduction in communication and
parameters to be finetuned. We further validate our approach with experiments
on Fed-IXI and Prostate MRI datasets.

摘要：<paragraph>由於預訓練所用的自然（來源）資料和醫療（目標）資料之間的極端分佈轉移，因此將基礎模型調整用於醫學影像分析需要在大量資料上對其進行微調。
然而，在中心位置收集此類微調的特定任務醫療資料會引發許多隱私問題。儘管聯合學習 (FL) 提供了一種在私有分散式資料上進行訓練的有效方法，但在聯合大型基礎模型時，通訊成本可能會迅速成為一個重大瓶頸，影響解決方案的可擴充性。在這項工作中，我們通過結合參數高效微調 (PEFT) 和 FL 的優勢，解決了在確保 FL 中有效學習的同時進行高效通訊的問題。具體來說，我們以聯合的方式研究即插即用低秩適配器 (LoRA)，以調整區段任何模型 (SAM) 以進行 3D 醫學影像分割。與利用 LoRA 和微調整個解碼器的先前工作不同，我們批判性地分析了 SAM 的每個粒狀組成部分對微調效能的貢獻。因此，我們確定了在通訊成本方面非常高效的特定層，同時產生了同等的準確度。我們的實驗表明，在調整過程中將 SAM 模型的參數（包括大部分解碼器）保留在其原始狀態是有益的，因為在小型資料集上進行微調往往會扭曲基礎模型的內在能力。在 Fed-KiTS 上，與完全微調相比，我們的做法降低了通訊成本（約 48 倍），同時提高了 3D 分割任務中的效能（約 6% 的骰子分數）。我們的做法與 SAMed 類似，同時將通訊和待微調參數減少了約 2.8 倍。我們進一步通過在 Fed-IXI 和 Prostate MRI 資料集上進行實驗驗證了我們的做法。</paragraph>

##### **Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation**
2407.21674v1 by Krishan Agyakari Raja Babu, Rachana Sathish, Mrunal Pattanaik, Rahul Venkataramani

Synthetic data is becoming increasingly integral in data-scarce fields such
as medical imaging, serving as a substitute for real data. However, its
inherent statistical characteristics can significantly impact downstream tasks,
potentially compromising deployment performance. In this study, we empirically
investigate this issue and uncover a critical phenomenon: downstream neural
networks often exploit spurious distinctions between real and synthetic data
when there is a strong correlation between the data source and the task label.
This exploitation manifests as \textit{simplicity bias}, where models overly
rely on superficial features rather than genuine task-related complexities.
Through principled experiments, we demonstrate that the source of data (real
vs.\ synthetic) can introduce spurious correlating factors leading to poor
performance during deployment when the correlation is absent. We first
demonstrate this vulnerability on a digit classification task, where the model
spuriously utilizes the source of data instead of the digit to provide an
inference. We provide further evidence of this phenomenon in a medical imaging
problem related to cardiac view classification in echocardiograms, particularly
distinguishing between 2-chamber and 4-chamber views. Given the increasing role
of utilizing synthetic datasets, we hope that our experiments serve as
effective guidelines for the utilization of synthetic datasets in model
training.

摘要：合成資料在資料稀少的領域中變得越來越不可或缺，例如醫學影像，用作真實資料的替代品。然而，其內在的統計特性會顯著影響下游任務，可能損害部署效能。在本研究中，我們實證調查此問題，並揭露一個關鍵現象：當資料來源與任務標籤之間有很強的相關性時，下游神經網路通常會利用真實資料與合成資料之間的虛假區別。這種利用表現為「簡化偏差」，其中模型過度依賴表面特徵，而不是真正的與任務相關的複雜性。透過有原則的實驗，我們證明資料來源（真實資料與合成資料）可能會引入虛假的相關因素，導致在相關性不存在時部署期間效能不佳。我們首先在數字分類任務中證明此漏洞，其中模型虛假地利用資料來源而非數字來提供推論。我們在與超音波心臟視野分類相關的醫學影像問題中進一步提供此現象的證據，特別是區分二腔和四腔視野。鑑於合成資料集的使用角色日益增加，我們希望我們的實驗能作為在模型訓練中利用合成資料集的有效指南。

##### **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**
2407.21638v1 by Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas

Automation of medical image interpretation could alleviate bottlenecks in
diagnostic workflows, and has become of particular interest in recent years due
to advancements in natural language processing. Great strides have been made
towards automated radiology report generation via AI, yet ensuring clinical
accuracy in generated reports is a significant challenge, hindering deployment
of such methods in clinical practice. In this work we propose a quality control
framework for assessing the reliability of AI-generated radiology reports with
respect to semantics of diagnostic importance using modular auxiliary auditing
components (AC). Evaluating our pipeline on the MIMIC-CXR dataset, our findings
show that incorporating ACs in the form of disease-classifiers can enable
auditing that identifies more reliable reports, resulting in higher F1 scores
compared to unfiltered generated reports. Additionally, leveraging the
confidence of the AC labels further improves the audit's effectiveness.

摘要：醫療影像判讀的自動化可以減輕診斷工作流程中的瓶頸，並且由於自然語言處理的進步，在近年來特別受到重視。在透過 AI 自動生成放射線報告方面已經取得了長足的進展，然而確保生成報告的臨床準確性是一項重大的挑戰，阻礙了此類方法在臨床實務中的部署。在這項工作中，我們提出了一個品質控制架構，用於評估 AI 生成的放射線報告的可靠性，並使用模組化輔助稽核元件 (AC) 針對診斷重要性的語義進行評估。在 MIMIC-CXR 資料集上評估我們的管道，我們的發現顯示，以疾病分類器的形式納入 AC 可以啟用稽核，以識別更可靠的報告，與未經篩選的生成報告相比，會產生更高的 F1 分數。此外，進一步利用 AC 標籤的信心可以提高稽核的有效性。

##### **Voxel Scene Graph for Intracranial Hemorrhage**
2407.21580v1 by Antoine P. Sanner, Nils F. Grauhan, Marc A. Brockmann, Ahmed E. Othman, Anirban Mukhopadhyay

Patients with Intracranial Hemorrhage (ICH) face a potentially
life-threatening condition, and patient-centered individualized treatment
remains challenging due to possible clinical complications. Deep-Learning-based
methods can efficiently analyze the routinely acquired head CTs to support the
clinical decision-making. The majority of early work focuses on the detection
and segmentation of ICH, but do not model the complex relations between ICH and
adjacent brain structures. In this work, we design a tailored object detection
method for ICH, which we unite with segmentation-grounded Scene Graph
Generation (SGG) methods to learn a holistic representation of the clinical
cerebral scene. To the best of our knowledge, this is the first application of
SGG for 3D voxel images. We evaluate our method on two head-CT datasets and
demonstrate that our model can recall up to 74% of clinically relevant
relations. This work lays the foundation towards SGG for 3D voxel data. The
generated Scene Graphs can already provide insights for the clinician, but are
also valuable for all downstream tasks as a compact and interpretable
representation.

摘要：腦出血 (ICH) 患者面臨可能危及生命的狀況，由於可能的臨床併發症，以患者為中心的個人化治療仍然具有挑戰性。基於深度學習的方法可以有效分析常規獲得的頭部電腦斷層掃描，以支持臨床決策制定。大多數早期工作都集中在 ICH 的檢測和分割，但沒有對 ICH 和相鄰大腦結構之間的複雜關係進行建模。在這項工作中，我們設計了一種針對 ICH 的客製化目標檢測方法，我們將其與基於分割的場景圖生成 (SGG) 方法結合，以學習臨床腦部場景的整體表徵。據我們所知，這是 SGG 第一次應用於 3D 體素影像。我們在兩個頭部電腦斷層掃描數據集上評估我們的模型，並證明我們的模型可以召回高達 74% 的臨床相關關係。這項工作為 3D 體素數據的 SGG 奠定了基礎。生成的場景圖已經可以為臨床醫生提供見解，但對於所有下游任務而言，它也是一種精簡且可解釋的表徵，因此非常有價值。

##### **Expanding the Medical Decathlon dataset: segmentation of colon and colorectal cancer from computed tomography images**
2407.21516v1 by I. M. Chernenkiy, Y. A. Drach, S. R. Mustakimova, V. V. Kazantseva, N. A. Ushakov, S. K. Efetov, M. V. Feldsherov

Colorectal cancer is the third-most common cancer in the Western Hemisphere.
The segmentation of colorectal and colorectal cancer by computed tomography is
an urgent problem in medicine. Indeed, a system capable of solving this problem
will enable the detection of colorectal cancer at early stages of the disease,
facilitate the search for pathology by the radiologist, and significantly
accelerate the process of diagnosing the disease. However, scientific
publications on medical image processing mostly use closed, non-public data.
This paper presents an extension of the Medical Decathlon dataset with
colorectal markups in order to improve the quality of segmentation algorithms.
An experienced radiologist validated the data, categorized it into subsets by
quality, and published it in the public domain. Based on the obtained results,
we trained neural network models of the UNet architecture with 5-part
cross-validation and achieved a Dice metric quality of $0.6988 \pm 0.3$. The
published markups will improve the quality of colorectal cancer detection and
simplify the radiologist's job for study description.

摘要：大腸癌是西半球第三常見的癌症。
利用電腦斷層掃描對大腸癌與大腸癌進行分段是醫學上的緊急問題。事實上，一個能夠解決這個問題的系統將能夠在疾病的早期階段偵測大腸癌，協助放射科醫師尋找病理，並顯著加速診斷疾病的過程。然而，關於醫學影像處理的科學刊物大多使用封閉、非公開的資料。這篇論文提出了一個帶有大腸標記的醫學十項全能資料集的延伸，以提高分段演算法的品質。一位經驗豐富的放射科醫師驗證了資料，將其依品質分類成子集，並將其發布在公共領域。根據獲得的結果，我們訓練了具有 5 部分交叉驗證的 UNet 架構的神經網路模型，並達到了 $0.6988 \pm 0.3$ 的 Dice 指標品質。發布的標記將提高大腸癌偵測的品質，並簡化放射科醫師研究描述的工作。

##### **Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation**
2407.21490v1 by Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni

Echocardiography video is a primary modality for diagnosing heart diseases,
but the limited data poses challenges for both clinical teaching and machine
learning training. Recently, video generative models have emerged as a
promising strategy to alleviate this issue. However, previous methods often
relied on holistic conditions during generation, hindering the flexible
movement control over specific cardiac structures. In this context, we propose
an explainable and controllable method for echocardiography video generation,
taking an initial frame and a motion curve as guidance. Our contributions are
three-fold. First, we extract motion information from each heart substructure
to construct motion curves, enabling the diffusion model to synthesize
customized echocardiography videos by modifying these curves. Second, we
propose the structure-to-motion alignment module, which can map semantic
features onto motion curves across cardiac structures. Third, The
position-aware attention mechanism is designed to enhance video consistency
utilizing Gaussian masks with structural position information. Extensive
experiments on three echocardiography datasets show that our method outperforms
others regarding fidelity and consistency. The full code will be released at
https://github.com/mlmi-2024-72/ECM.

摘要：超音波心動圖影片是診斷心臟疾病的主要方式，
但有限的數據對臨床教學和機器學習訓練都構成挑戰。最近，影片生成模型已成為緩解此問題的一種有前途的策略。然而，先前的辦法在生成過程中通常依賴整體條件，阻礙了對特定心臟結構的靈活運動控制。在此背景下，我們提出了一種可解釋且可控的超音波心動圖影片生成方法，以初始幀和運動曲線作為指導。我們的貢獻有三方面。首先，我們從每個心臟子結構中提取運動資訊以建構運動曲線，讓擴散模型能夠透過修改這些曲線來合成客製化的超音波心動圖影片。其次，我們提出了結構到運動對齊模組，它可以將語義特徵對應到心臟結構中的運動曲線。第三，位置感知注意力機制旨在利用具有結構位置資訊的高斯遮罩來增強影片的一致性。在三個超音波心動圖資料集上的廣泛實驗顯示，我們的辦法在保真度和一致性方面優於其他辦法。完整程式碼將在 https://github.com/mlmi-2024-72/ECM 上釋出。

##### **Deep Learning-Based Longitudinal Prediction of Childhood Myopia Progression Using Fundus Image Sequences and Baseline Refraction Data**
2407.21467v1 by Mengtian Kang, Yansong Hu, Shuo Gao, Yuanyuan Liu, Hongbei Meng, Xuemeng Li, Xuhang Chen, Hubin Zhao, Jing Fu, Guohua Hu, Wei Wang, Yanning Dai, Arokia Nathan, Peter Smielewski, Ningli Wang, Shiming Li

Childhood myopia constitutes a significant global health concern. It exhibits
an escalating prevalence and has the potential to evolve into severe,
irreversible conditions that detrimentally impact familial well-being and
create substantial economic costs. Contemporary research underscores the
importance of precisely predicting myopia progression to enable timely and
effective interventions, thereby averting severe visual impairment in children.
Such predictions predominantly rely on subjective clinical assessments, which
are inherently biased and resource-intensive, thus hindering their widespread
application. In this study, we introduce a novel, high-accuracy method for
quantitatively predicting the myopic trajectory and myopia risk in children
using only fundus images and baseline refraction data. This approach was
validated through a six-year longitudinal study of 3,408 children in Henan,
utilizing 16,211 fundus images and corresponding refractive data. Our method
based on deep learning demonstrated predictive accuracy with an error margin of
0.311D per year and AUC scores of 0.944 and 0.995 for forecasting the risks of
developing myopia and high myopia, respectively. These findings confirm the
utility of our model in supporting early intervention strategies and in
significantly reducing healthcare costs, particularly by obviating the need for
additional metadata and repeated consultations. Furthermore, our method was
designed to rely only on fundus images and refractive error data, without the
need for meta data or multiple inquiries from doctors, strongly reducing the
associated medical costs and facilitating large-scale screening. Our model can
even provide good predictions based on only a single time measurement.
Consequently, the proposed method is an important means to reduce medical
inequities caused by economic disparities.

摘要：兒童近視構成全球重要的健康問題。它顯示出日益增加的盛行率，並可能演變成嚴重、不可逆轉的狀況，對家庭福祉造成不利影響，並產生大量的經濟成本。現代研究強調精準預測近視進展的重要性，以實現及時有效的干預，從而避免兒童出現嚴重的視力損害。此類預測主要依賴主觀的臨床評估，其本身具有偏見且資源密集，從而阻礙了它們的廣泛應用。在本研究中，我們引入了一種新穎、高精確度的方法，僅使用眼底圖像和基線屈光數據，就能定量預測兒童的近視軌跡和近視風險。這種方法通過對河南省 3,408 名兒童進行為期六年的縱向研究，利用 16,211 張眼底圖像和相應的屈光數據進行了驗證。我們基於深度學習的方法展示了預測準確度，年誤差範圍為 0.311D，預測發生近視和高度近視的風險的 AUC 分數分別為 0.944 和 0.995。這些發現證實了我們的模型在支持早期干預策略和顯著降低醫療保健成本方面的效用，特別是通過消除對額外元數據和重複諮詢的需要。此外，我們的方法被設計為僅依賴眼底圖像和屈光不正數據，而無需元數據或醫生的多次詢問，從而大大降低了相關的醫療成本，並促進了大規模篩查。我們的模型甚至可以僅根據單次時間測量提供良好的預測。因此，所提出的方法是減少由經濟差距造成的醫療不平等的重要手段。

##### **Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering**
2407.21368v1 by Danfeng Guo, Demetri Terzopoulos

Large Vision-Language Models (LVLMs) have achieved significant success in
recent years, and they have been extended to the medical domain. Although
demonstrating satisfactory performance on medical Visual Question Answering
(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,
which makes them fail to diagnose complex pathologies. Moreover, they readily
fail to learn minority pathologies due to imbalanced training data. We propose
two prompting strategies for MLVLMs that reduce hallucination and improve VQA
performance. In the first strategy, we provide a detailed explanation of the
queried pathology. In the second strategy, we fine-tune a cheap, weak learner
to achieve high performance on a specific metric, and textually provide its
judgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our
methods significantly improve the diagnostic F1 score, with the highest
increase being 0.27. We also demonstrate that our prompting strategies can be
extended to general LVLM domains. Based on POPE metrics, it effectively
suppresses the false negative predictions of existing LVLMs and improves Recall
by approximately 0.07.

摘要：大型視覺語言模型 (LVLMs) 在近年來取得顯著的成功，並已擴展到醫療領域。儘管在醫學視覺問答 (VQA) 任務中表現令人滿意，但醫學 LVLMs (MLVLMs) 仍存在幻覺問題，導致它們無法診斷出複雜的病理。此外，由於訓練資料不平衡，它們很容易無法學習少數病理。我們提出兩種針對 MLVLMs 的提示策略，以減少幻覺並改善 VQA 效能。在第一個策略中，我們提供查詢病理的詳細說明。在第二個策略中，我們微調一個便宜、效能不佳的學習器，以在特定指標上獲得高效能，並以文字方式向 MLVLM 提供其判斷。在 MIMIC-CXR-JPG 和 Chexpert 資料集上進行測試後，我們的模型顯著改善了診斷 F1 分數，最高提升幅度為 0.27。我們還展示了我們的提示策略可以擴展到一般的 LVLM 領域。根據 POPE 指標，它有效地抑制了現有 LVLMs 的假陰性預測，並將召回率提高了約 0.07。

##### **MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework**
2407.21343v1 by Adrian Celaya, Evan Lim, Rachel Glenn, Brayden Mi, Alex Balsells, Tucker Netherton, Caroline Chung, Beatrice Riviere, David Fuentes

Medical imaging segmentation is a highly active area of research, with deep
learning-based methods achieving state-of-the-art results in several
benchmarks. However, the lack of standardized tools for training, testing, and
evaluating new methods makes the comparison of methods difficult. To address
this, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,
modular, and end-to-end medical imaging segmentation framework designed to
facilitate consistent training, testing, and evaluation of deep learning-based
medical imaging segmentation methods. MIST standardizes data analysis,
preprocessing, and evaluation pipelines, accommodating multiple architectures
and loss functions. This standardization ensures reproducible and fair
comparisons across different methods. We detail MIST's data format
requirements, pipelines, and auxiliary features and demonstrate its efficacy
using the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results
highlight MIST's ability to produce accurate segmentation masks and its
scalability across multiple GPUs, showcasing its potential as a powerful tool
for future medical imaging research and development.

摘要：醫學影像分割是一個高度活躍的研究領域，深度學習方法在多個基準測試中取得了最先進的成果。然而，缺乏標準化的訓練、測試和評估新方法的工具，使得方法的比較變得困難。為了解決這個問題，我們引入了醫學影像分割工具包 (MIST)，一個簡單、模組化和端對端的醫學影像分割框架，旨在促進基於深度學習的醫學影像分割方法的一致訓練、測試和評估。MIST 標準化了數據分析、預處理和評估管道，容納多種架構和損失函數。這種標準化確保了不同方法之間可重現且公平的比較。我們詳細說明了 MIST 的數據格式要求、管道和輔助功能，並使用 BraTS 成人神經膠質瘤治療後挑戰數據集展示了它的功效。我們的結果突顯了 MIST 產生準確分割遮罩的能力以及它跨多個 GPU 的可擴展性，展示了它作為未來醫學影像研究和開發的有力工具的潛力。

##### **Robust Box Prompt based SAM for Medical Image Segmentation**
2407.21284v1 by Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni

The Segment Anything Model (SAM) can achieve satisfactory segmentation
performance under high-quality box prompts. However, SAM's robustness is
compromised by the decline in box quality, limiting its practicality in
clinical reality. In this study, we propose a novel Robust Box prompt based SAM
(\textbf{RoBox-SAM}) to ensure SAM's segmentation performance under prompts
with different qualities. Our contribution is three-fold. First, we propose a
prompt refinement module to implicitly perceive the potential targets, and
output the offsets to directly transform the low-quality box prompt into a
high-quality one. We then provide an online iterative strategy for further
prompt refinement. Second, we introduce a prompt enhancement module to
automatically generate point prompts to assist the box-promptable segmentation
effectively. Last, we build a self-information extractor to encode the prior
information from the input image. These features can optimize the image
embeddings and attention calculation, thus, the robustness of SAM can be
further enhanced. Extensive experiments on the large medical segmentation
dataset including 99,299 images, 5 modalities, and 25 organs/targets validated
the efficacy of our proposed RoBox-SAM.

摘要：分段任何模型 (SAM) 可以在高质量框提示下实现令人满意的分段性能。然而，SAM 的鲁棒性因框质量的下降而受到损害，限制了其在临床现实中的实用性。在这项研究中，我们提出了一个基于 SAM 的新型鲁棒框提示（**RoBox-SAM**），以确保 SAM 在具有不同质量的提示下的分段性能。我们的贡献是三方面的。首先，我们提出一个提示优化模块，以隐式感知潜在目标，并输出偏移量，以直接将低质量框提示转换为高质量提示。然后，我们提供了一个在线迭代策略，以便进一步优化提示。其次，我们引入了一个提示增强模块，以自动生成点提示，以有效地辅助框提示分段。最后，我们构建了一个自信息提取器，以对来自输入图像的先验信息进行编码。这些特征可以优化图像嵌入和注意力计算，因此，可以进一步增强 SAM 的鲁棒性。在包括 99,299 张图像、5 种方式和 25 个器官/目标的大型医学分段数据集上进行的广泛实验验证了我们提出的 RoBox-SAM 的功效。

##### **Unlocking the Potential of Binding Corporate Rules (BCRs) in Health Data Transfers**
2407.21281v1 by Marcelo Corrales Compagnucci, Mark Fenwick, Helena Haapio

This chapter explores the essential role of Binding Corporate Rules (BCRs) in
managing and facilitating secure health data transfers within corporate groups
under the EU General Data Protection Regulation (GDPR). BCRs are tailored to
ensure compliance with the GDPR and similar international data protection laws,
presenting a flexible mechanism for transferring sensitive health and genomic
data. The chapter situates BCRs within the broader spectrum of the GDPR
international data transfer mechanisms, addressing the unique challenges posed
by the sensitive nature of health data and the increased adoption of AI
technologies. The European Data Protection Board (EDPB) Recommendations 1/2022
on BCRs, issued following the Schrems II decision, are critically analyzed,
highlighting their stringent requirements and the need for a balanced approach
that prioritizes data protection and an AI governance framework. The chapter
outlines the BCR approval process, stressing the importance of streamlining
this process to encourage broader adoption. It underscores the necessity of a
multidisciplinary approach in developing BCRs, incorporating recently adopted
international standards and frameworks, which offer valuable guidance for
organizations to build trustworthy AI management systems. They guarantee the
ethical development, deployment, and operation of AI, which is essential for
its successful integration and the broader digital transformation. In
conclusion, BCRs are positioned as essential tools for secure health data
management, fostering transparency, accountability, and collaboration across
international borders. The chapter calls for proactive measures to incentivize
BCR adoption, streamline approval processes, and promote more innovative
approaches, ensuring BCRs remain a robust mechanism for global data protection
and compliance.

摘要：<paragraph>此章探討約束企業規則 (BCR) 在歐盟一般資料保護條例 (GDPR) 下管理和促進企業集團內部安全健康資料傳輸的基本角色。BCR 專門用於確保符合 GDPR 和類似的國際資料保護法，提供傳輸敏感健康和基因組資料的彈性機制。此章將 BCR 定位在 GDPR 國際資料傳輸機制的更廣泛範圍內，解決健康資料敏感性質和 AI 技術採用增加所帶來的獨特挑戰。歐洲資料保護委員會 (EDPB) 在 Schrems II 決定後發布的 BCR 建議 1/2022 受到嚴格分析，強調其嚴格要求和平衡方法的必要性，該方法優先考慮資料保護和 AI 治理架構。此章概述 BCR 核准程序，強調簡化此程序以鼓勵更廣泛採用的重要性。它強調在開發 BCR 時採用多學科方法的必要性，包括最近採用的國際標準和架構，這些標準和架構為組織建立可信賴的 AI 管理系統提供了寶貴的指導。它們保證 AI 的道德開發、部署和運作，這對其成功整合和更廣泛的數位轉型至關重要。結論是，BCR 被定位為安全健康資料管理的基本工具，促進跨國界的透明度、問責制和協作。此章呼籲採取積極措施來激勵 BCR 採用、簡化核准程序，並促進更具創新的方法，確保 BCR 仍然是全球資料保護和合規性的強大機制。</paragraph>

##### **FreqTSF: Time Series Forecasting Via Simulating Frequency Kramer-Kronig Relations**
2407.21275v1 by Rujia Shen, Liangliang Liu, Boran Wang, Yi Guan, Yang Yang, Jingchi Jiang

Time series forecasting (TSF) is immensely important in extensive
applications, such as electricity transformation, financial trade, medical
monitoring, and smart agriculture. Although Transformer-based methods can
handle time series data, their ability to predict long-term time series is
limited due to the ``anti-order" nature of the self-attention mechanism. To
address this problem, we focus on frequency domain to weaken the impact of
order in TSF and propose the FreqBlock, where we first obtain frequency
representations through the Frequency Transform Module. Subsequently, a newly
designed Frequency Cross Attention is used to obtian enhanced frequency
representations between the real and imaginary parts, thus establishing a link
between the attention mechanism and the inherent Kramer-Kronig relations
(KKRs). Our backbone network, FreqTSF, adopts a residual structure by
concatenating multiple FreqBlocks to simulate KKRs in the frequency domain and
avoid degradation problems. On a theoretical level, we demonstrate that the
proposed two modules can significantly reduce the time and memory complexity
from $\mathcal{O}(L^2)$ to $\mathcal{O}(L)$ for each FreqBlock computation.
Empirical studies on four benchmark datasets show that FreqTSF achieves an
overall relative MSE reduction of 15\% and an overall relative MAE reduction of
11\% compared to the state-of-the-art methods. The code will be available soon.

摘要：時間序列預測 (TSF) 在廣泛的應用中非常重要，例如電力轉換、金融交易、醫療監控和智慧農業。雖然基於 Transformer 的方法可以處理時間序列資料，但由於自注意力機制的「反序」特性，它們預測長期時間序列的能力受到限制。為了解決這個問題，我們專注於頻域以減弱 TSF 中順序的影響，並提出 FreqBlock，我們首先透過頻率轉換模組取得頻率表示。隨後，使用新設計的頻率交叉注意力來獲得實部和虛部之間增強的頻率表示，從而建立注意力機制和固有 Kramer-Kronig 關係 (KKR) 之間的連結。我們的骨幹網路 FreqTSF 採用殘差結構，透過串接多個 FreqBlock 來模擬頻域中的 KKR 並避免退化問題。在理論層面上，我們證明所提出的兩個模組可以顯著降低每個 FreqBlock 計算的時間和記憶體複雜度，從 $\mathcal{O}(L^2)$ 降低到 $\mathcal{O}(L)$。在四個基準資料集上的實證研究顯示，與最先進的方法相比，FreqTSF 的整體相對 MSE 降低 15%，整體相對 MAE 降低 11%。程式碼將很快推出。

##### **Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net**
2407.21273v1 by Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski

Efficient intravascular access in trauma and critical care significantly
impacts patient outcomes. However, the availability of skilled medical
personnel in austere environments is often limited. Autonomous robotic
ultrasound systems can aid in needle insertion for medication delivery and
support non-experts in such tasks. Despite advances in autonomous needle
insertion, inaccuracies in vessel segmentation predictions pose risks.
Understanding the uncertainty of predictive models in ultrasound imaging is
crucial for assessing their reliability. We introduce MSU-Net, a novel
multistage approach for training an ensemble of U-Nets to yield accurate
ultrasound image segmentation maps. We demonstrate substantial improvements,
18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model
transparency, and trustworthiness. By highlighting areas of model certainty,
MSU-Net can guide safe needle insertions, empowering non-experts to accomplish
such tasks.

摘要：在創傷和重症照護中，有效的血管內通路會顯著影響病患的治療結果。然而，在惡劣的環境中，熟練的醫療人員往往不足。自主機器人超音波系統可以協助針頭插入，以提供藥物並支援非專家執行此類任務。儘管自主針頭插入技術進步，但血管分割預測的不準確性會造成風險。了解超音波影像中預測模型的不確定性，對於評估其可靠性至關重要。我們引進 MSU-Net，這是一種新穎的多階段方法，用於訓練一組 U-Net 以產生準確的超音波影像分割圖。我們展示了大幅改善，比單一的蒙地卡羅 U-Net 改善了 18.1%，增強了不確定性評估、模型透明度和可信度。透過強調模型確定性的區域，MSU-Net 可以引導安全的針頭插入，讓非專家也能執行此類任務。

##### **Domain Shift Analysis in Chest Radiographs Classification in a Veterans Healthcare Administration Population**
2407.21149v1 by Mayanka Chandrashekar, Ian Goethert, Md Inzamam Ul Haque, Benjamin McMahon, Sayera Dhaubhadel, Kathryn Knight, Joseph Erdos, Donna Reagan, Caroline Taylor, Peter Kuzmak, John Michael Gaziano, Eileen McAllister, Lauren Costa, Yuk-Lam Ho, Kelly Cho, Suzanne Tamang, Samah Fodeh-Jarad, Olga S. Ovchinnikova, Amy C. Justice, Jacob Hinkle, Ioana Danciu

Objectives: This study aims to assess the impact of domain shift on chest
X-ray classification accuracy and to analyze the influence of ground truth
label quality and demographic factors such as age group, sex, and study year.
Materials and Methods: We used a DenseNet121 model pretrained MIMIC-CXR dataset
for deep learning-based multilabel classification using ground truth labels
from radiology reports extracted using the CheXpert and CheXbert Labeler. We
compared the performance of the 14 chest X-ray labels on the MIMIC-CXR and
Veterans Healthcare Administration chest X-ray dataset (VA-CXR). The VA-CXR
dataset comprises over 259k chest X-ray images spanning between the years 2010
and 2022. Results: The validation of ground truth and the assessment of
multi-label classification performance across various NLP extraction tools
revealed that the VA-CXR dataset exhibited lower disagreement rates than the
MIMIC-CXR datasets. Additionally, there were notable differences in AUC scores
between models utilizing CheXpert and CheXbert. When evaluating multi-label
classification performance across different datasets, minimal domain shift was
observed in unseen datasets, except for the label "Enlarged Cardiomediastinum."
The study year's subgroup analyses exhibited the most significant variations in
multi-label classification model performance. These findings underscore the
importance of considering domain shifts in chest X-ray classification tasks,
particularly concerning study years. Conclusion: Our study reveals the
significant impact of domain shift and demographic factors on chest X-ray
classification, emphasizing the need for improved transfer learning and
equitable model development. Addressing these challenges is crucial for
advancing medical imaging and enhancing patient care.

摘要：<paragraph>目標：本研究旨在評估領域轉移對胸部 X 光分類精度的影響，並分析基本事實標籤品質和年齡組、性別和研究年份等人口因素的影響。
材料和方法：我們使用 DenseNet121 模型預訓練 MIMIC-CXR 資料集，使用從使用 CheXpert 和 CheXbert 標籤器從放射科報告中提取的基本事實標籤進行基於深度學習的多標籤分類。我們比較了 MIMIC-CXR 和退伍軍人健康管理局胸部 X 光資料集 (VA-CXR) 上 14 個胸部 X 光標籤的性能。VA-CXR 資料集包含超過 259k 張胸部 X 光影像，時間跨度為 2010 年至 2022 年。結果：基本事實的驗證和對各種 NLP 提取工具的多標籤分類性能的評估顯示，VA-CXR 資料集表現出的分歧率低於 MIMIC-CXR 資料集。此外，使用 CheXpert 和 CheXbert 的模型之間的 AUC 得分存在顯著差異。在評估不同資料集上的多標籤分類性能時，除了標籤「心縱隔增大」之外，在未見資料集中觀察到的領域轉移很小。研究年份的子群分析顯示，多標籤分類模型性能變化最大。這些發現強調了在胸部 X 光分類任務中考慮領域轉移的重要性，特別是關於研究年份。結論：我們的研究揭示了領域轉移和人口因素對胸部 X 光分類的顯著影響，強調了改進遷移學習和公平模型開發的必要性。應對這些挑戰對於推進醫學影像和加強患者護理至關重要。</paragraph>

##### **Zero Shot Health Trajectory Prediction Using Transformer**
2407.21124v1 by Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek

Integrating modern machine learning and clinical decision-making has great
promise for mitigating healthcare's increasing cost and complexity. We
introduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a
novel application of the transformer deep-learning architecture for analyzing
high-dimensional, heterogeneous, and episodic health data. ETHOS is trained
using Patient Health Timelines (PHTs)-detailed, tokenized records of health
events-to predict future health trajectories, leveraging a zero-shot learning
approach. ETHOS represents a significant advancement in foundation model
development for healthcare analytics, eliminating the need for labeled data and
model fine-tuning. Its ability to simulate various treatment pathways and
consider patient-specific factors positions ETHOS as a tool for care
optimization and addressing biases in healthcare delivery. Future developments
will expand ETHOS' capabilities to incorporate a wider range of data types and
data sources. Our work demonstrates a pathway toward accelerated AI development
and deployment in healthcare.

摘要：整合現代機器學習與臨床決策制定對於減輕醫療保健日益增加的成本和複雜性具有很大的前景。我們引入了健康結果模擬的增強式Transformer（ETHOS），這是一種Transformer深度學習架構的新穎應用，用於分析高維、異質且情節性的健康數據。ETHOS 使用患者健康時間軸 (PHT) 進行訓練，PHT 是健康事件的詳細、標記化記錄，用於預測未來的健康軌跡，並利用零次學習方法。ETHOS 代表了醫療保健分析基礎模型開發的重大進展，消除了對標記數據和模型微調的需求。它模擬各種治療途徑並考慮患者特定因素的能力，使 ETHOS 成為優化照護和解決醫療保健提供中偏差的工具。未來的發展將擴展 ETHOS 的功能，以納入更廣泛的數據類型和數據來源。我們的研究展示了一條加速醫療保健中 AI 開發和部署的途徑。

##### **CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning**
2407.21011v1 by Yuexi Du, Brian Chang, Nicha C. Dvornek

Recent advancements in Contrastive Language-Image Pre-training (CLIP) have
demonstrated notable success in self-supervised representation learning across
various tasks. However, the existing CLIP-like approaches often demand
extensive GPU resources and prolonged training times due to the considerable
size of the model and dataset, making them poor for medical applications, in
which large datasets are not always common. Meanwhile, the language model
prompts are mainly manually derived from labels tied to images, potentially
overlooking the richness of information within training samples. We introduce a
novel language-image Contrastive Learning method with an Efficient large
language model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of
the extensive pre-trained language and visual models. Furthermore, we present
an efficient strategy for learning context-based prompts that mitigates the gap
between informative clinical diagnostic data and simple class labels. Our
method demonstrates state-of-the-art performance on multiple chest X-ray and
mammography datasets compared with various baselines. The proposed parameter
efficient framework can reduce the total trainable model size by 39% and reduce
the trainable language model to only 4% compared with the current BERT encoder.

摘要：對比語言影像預訓練 (CLIP) 的最新進展已展現出在各項任務中以自我監督表徵學習獲得顯著成功的成果。然而，現有的 CLIP 類似方法通常需要大量的 GPU 資源和漫長的訓練時間，因為模型和資料集的規模龐大，這使得它們不適合醫療應用，因為醫療應用中並不總是會有大型資料集。同時，語言模型提示主要來自與影像相關的標籤，而手動衍生，這可能會忽略訓練樣本中豐富的資訊。我們提出一個新穎的語言影像對比學習方法，其中包含一個高效的大語言模型和提示微調 (CLEFT)，它利用了廣泛預訓練的語言和視覺模型的優勢。此外，我們提出一個學習基於脈絡提示的有效策略，以縮小資訊豐富的臨床診斷資料和簡單類別標籤之間的差距。與各種基準相比，我們的模型在多個胸部 X 光和乳房攝影資料集上展現出最先進的效能。所提出的參數有效架構可以將總體可訓練模型大小減少 39%，並將可訓練語言模型減少到僅 4%，與目前的 BERT 編碼器相比。

##### **Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing**
2407.20830v1 by Eugenio Lomurno, Matteo Matteucci

Federated learning has emerged as a paradigm for collaborative learning,
enabling the development of robust models without the need to centralise
sensitive data. However, conventional federated learning techniques have
privacy and security vulnerabilities due to the exposure of models, parameters
or updates, which can be exploited as an attack surface. This paper presents
Federated Knowledge Recycling (FedKR), a cross-silo federated learning approach
that uses locally generated synthetic data to facilitate collaboration between
institutions. FedKR combines advanced data generation techniques with a dynamic
aggregation process to provide greater security against privacy attacks than
existing methods, significantly reducing the attack surface. Experimental
results on generic and medical datasets show that FedKR achieves competitive
performance, with an average improvement in accuracy of 4.24% compared to
training models from local data, demonstrating particular effectiveness in data
scarcity scenarios.

摘要：聯邦學習已成為協作學習的典範，
無需集中敏感資料即可開發穩健模型。然而，由於模型、參數
或更新的公開，傳統的聯邦學習技術具有隱私和安全漏洞，可用作攻擊面。本文提出
聯邦知識再利用 (FedKR)，一種跨孤島的聯邦學習方法
使用本地生成的合成資料來促進
機構之間的合作。FedKR 將先進的資料生成技術與動態
聚合過程相結合，以提供比
現有方法更能抵禦隱私攻擊的安全保障，大幅縮小攻擊面。實驗
結果顯示，在一般和醫療資料集上，FedKR 達到競爭力
表現，與訓練模型相比，準確率平均提升 4.24%
來自本地資料，在資料稀缺的情況下展現出特別的有效性。

##### **Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization**
2407.20739v1 by Michael Kölle, Karola Schneider, Sabrina Egger, Felix Topp, Thomy Phan, Philipp Altmann, Jonas Nüßlein, Claudia Linnhoff-Popien

In recent years, Multi-Agent Reinforcement Learning (MARL) has found
application in numerous areas of science and industry, such as autonomous
driving, telecommunications, and global health. Nevertheless, MARL suffers
from, for instance, an exponential growth of dimensions. Inherent properties of
quantum mechanics help to overcome these limitations, e.g., by significantly
reducing the number of trainable parameters. Previous studies have developed an
approach that uses gradient-free quantum Reinforcement Learning and
evolutionary optimization for variational quantum circuits (VQCs) to reduce the
trainable parameters and avoid barren plateaus as well as vanishing gradients.
This leads to a significantly better performance of VQCs compared to classical
neural networks with a similar number of trainable parameters and a reduction
in the number of parameters by more than 97 \% compared to similarly good
neural networks. We extend an approach of K\"olle et al. by proposing a
Gate-Based, a Layer-Based, and a Prototype-Based concept to mutate and
recombine VQCs. Our results show the best performance for mutation-only
strategies and the Gate-Based approach. In particular, we observe a
significantly better score, higher total and own collected coins, as well as a
superior own coin rate for the best agent when evaluated in the Coin Game
environment.

摘要：近年來，多智能體強化學習 (MARL) 已在科學和產業的許多領域中找到應用，例如自動駕駛、電信和全球健康。儘管如此，MARL 還是會受到例如維度指數成長等問題的影響。量子力學的內在特性有助於克服這些限制，例如，透過大幅減少可訓練參數的數量。先前的研究已開發出一種方法，該方法使用無梯度的量子強化學習和變分量子電路 (VQC) 的演化最佳化，以減少可訓練參數並避免貧瘠高原和梯度消失。與具有類似可訓練參數數量的傳統神經網路相比，這會讓 VQC 的效能顯著提升，而且與同樣優良的神經網路相比，參數數量減少了超過 97%。我們擴充了 K\"olle 等人的方法，提出一個基於閘、基於層和基於原型的概念來變異和重組 VQC。我們的結果顯示，僅變異策略和基於閘的方法具有最佳效能。特別是，我們觀察到在 Coin Game 環境中進行評估時，最佳智能體的得分顯著提升、總計和自己收集的金幣數量較高，以及自己的金幣比率較高。

##### **Dense Self-Supervised Learning for Medical Image Segmentation**
2407.20395v1 by Maxime Seince, Loic Le Folgoc, Luiz Augusto Facury de Souza, Elsa Angelini

Deep learning has revolutionized medical image segmentation, but it relies
heavily on high-quality annotations. The time, cost and expertise required to
label images at the pixel-level for each new task has slowed down widespread
adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL)
approach for few-shot segmentation, that reduces the manual annotation burden
by learning powerful pixel-level representations directly from unlabeled
images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for
contrastive SSL on whole images. It is applied to generic encoder-decoder deep
learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance
of the learned image-level representations under intensity and spatial image
augmentations, Pix2Rep enforces equivariance of the pixel-level
representations. We demonstrate the framework on a task of cardiac MRI
segmentation. Results show improved performance compared to existing semi- and
self-supervised approaches; and a 5-fold reduction in the annotation burden for
equivalent performance versus a fully supervised U-Net baseline. This includes
a 30% (resp. 31%) DICE improvement for one-shot segmentation under
linear-probing (resp. fine-tuning). Finally, we also integrate the novel
Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even
better segmentation performance.

摘要：深度學習徹底改變了醫學影像分割，但它極度依賴於高品質的註解。為每個新任務標記像素層級的影像所需的時間、成本和專業知識，已減緩了範例的廣泛採用。我們提出 Pix2Rep，一種針對少次分割的自監督式學習 (SSL) 方法，可透過直接從未標記的影像中學習強大的像素層級表示，來減輕手動註解負擔。Pix2Rep 是一種針對完整影像對比式 SSL 的新穎像素層級損失和預訓練範例。它被應用於通用編碼器-解碼器深度學習主幹 (例如 U-Net)。大多數 SSL 方法強制學習的影像層級表示在強度和空間影像擴充下具有不變性，而 Pix2Rep 則強制像素層級表示具有等變性。我們在心臟 MRI 分割任務中展示了這個架構。結果顯示與現有的半監督式和自監督式方法相比，效能有所提升；且在與完全監督式 U-Net 基準具有相同效能的情況下，註解負擔減少了 5 倍。這包括在線性探測 (resp. 微調) 下，單次分割的 DICE 提升了 30% (resp. 31%)。最後，我們也將新穎的 Pix2Rep 概念與 Barlow Twins 非對比式 SSL 整合，這導致了更好的分割效能。

##### **Classification, Regression and Segmentation directly from k-Space in Cardiac MRI**
2407.20108v1 by Ruochen Li, Jiazhen Pan, Youxiang Zhu, Juncheng Ni, Daniel Rueckert

Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing
cardiovascular diseases. Clinical diagnoses predominantly rely on
magnitude-only Digital Imaging and Communications in Medicine (DICOM) images,
omitting crucial phase information that might provide additional diagnostic
benefits. In contrast, k-space is complex-valued and encompasses both magnitude
and phase information, while humans cannot directly perceive. In this work, we
propose KMAE, a Transformer-based model specifically designed to process
k-space data directly, eliminating conventional intermediary conversion steps
to the image domain. KMAE can handle critical cardiac disease classification,
relevant phenotype regression, and cardiac morphology segmentation tasks. We
utilize this model to investigate the potential of k-space-based diagnosis in
cardiac MRI. Notably, this model achieves competitive classification and
regression performance compared to image-domain methods e.g. Masked
Autoencoders (MAEs) and delivers satisfactory segmentation performance with a
myocardium dice score of 0.884. Last but not least, our model exhibits robust
performance with consistent results even when the k-space is 8* undersampled.
We encourage the MR community to explore the untapped potential of k-space and
pursue end-to-end, automated diagnosis with reduced human intervention.

摘要：心臟磁振造影 (CMR) 是診斷心血管疾病的黃金標準。臨床診斷主要依賴於醫學數位影像和通訊 (DICOM) 影像的幅度，而忽略了可能提供額外診斷好處的關鍵相位資訊。相較之下，k 空間是複數值且包含幅度和相位資訊，但人類無法直接感知。在這項工作中，我們提出 KMAE，一種特別設計用於直接處理 k 空間資料的 Transformer 基礎模型，消除了轉換到影像領域的傳統中介步驟。KMAE 可以處理關鍵的心臟疾病分類、相關表型回歸和心臟形態分割任務。我們利用此模型探討 k 空間基礎診斷在心臟 MRI 中的潛力。值得注意的是，與影像領域方法（例如遮罩式自動編碼器 (MAE)）相比，此模型達到了競爭性的分類和回歸效能，並以 0.884 的心肌骰子分數提供了令人滿意的分割效能。最後但並非最不重要的一點是，即使在 k 空間不足採樣 8* 時，我們的模型也能展現穩健的效能和一致的結果。我們鼓勵核磁共振社群探索 k 空間的未開發潛力，並追求減少人為干預的端到端自動化診斷。

##### **Robust Conformal Volume Estimation in 3D Medical Images**
2407.19938v1 by Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat

Volumetry is one of the principal downstream applications of 3D medical image
segmentation, for example, to detect abnormal tissue growth or for surgery
planning. Conformal Prediction is a promising framework for uncertainty
quantification, providing calibrated predictive intervals associated with
automatic volume measurements. However, this methodology is based on the
hypothesis that calibration and test samples are exchangeable, an assumption
that is in practice often violated in medical image applications. A weighted
formulation of Conformal Prediction can be framed to mitigate this issue, but
its empirical investigation in the medical domain is still lacking. A potential
reason is that it relies on the estimation of the density ratio between the
calibration and test distributions, which is likely to be intractable in
scenarios involving high-dimensional data. To circumvent this, we propose an
efficient approach for density ratio estimation relying on the compressed
latent representations generated by the segmentation model. Our experiments
demonstrate the efficiency of our approach to reduce the coverage error in the
presence of covariate shifts, in both synthetic and real-world settings. Our
implementation is available at https://github.com/benolmbrt/wcp_miccai

摘要：體積測量是 3D 醫學影像分割的主要下游應用之一，例如用於偵測異常組織生長或手術規劃。共形預測是一個有前途的不確定性量化架構，提供與自動體積量測相關的校正預測區間。然而，此方法基於校正和測試樣本可交換的假設，而此假設在實務上經常在醫學影像應用中遭到破壞。共形預測的加權公式可以被建構來減輕此問題，但其在醫學領域的經驗調查仍然不足。一個潛在原因是它依賴於校正和測試分佈之間的密度比估計，這在涉及高維度資料的場景中可能是棘手的。為了迴避此問題，我們提出一個有效率的密度比估計方法，依賴於分割模型產生的壓縮潛在表示。我們的實驗證明了我們的方法在合成和真實世界設定中減少共變異數偏移存在時的覆蓋率誤差的效率。我們的實作可以在 https://github.com/benolmbrt/wcp_miccai 取得

##### **Yucca: A Deep Learning Framework For Medical Image Analysis**
2407.19888v1 by Sebastian Nørgaard Llambias, Julia Machnio, Asbjørn Munk, Jakob Ambsdorf, Mads Nielsen, Mostafa Mehdipour Ghazi

Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.

摘要：使用深度學習框架進行的醫學影像分析已經通過自動化複雜任務推動了醫療保健的進步，但許多現有框架缺乏靈活性、模組化和使用者友善性。為了應對這些挑戰，我們引入了 Yucca，一個開放原始碼的 AI 框架，可於 https://github.com/Sllambias/yucca 取得，專門為醫學影像應用設計，並建立在 PyTorch 和 PyTorch Lightning 之上。Yucca 具有三層架構：功能、模組和管線，提供全面且可自訂的解決方案。在各種任務中進行評估，例如腦微出血偵測、白質高訊號分割和海馬分割，Yucca 達到了最先進的結果，證明了它的穩健性和多功能性。Yucca 提供了一個強大、靈活且使用者友善的醫學影像分析平台，歡迎社群貢獻以提升其能力和影響力。

##### **CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare**
2407.19705v2 by Jingwei Zhu, Minghuan Tan, Min Yang, Ruixue Li, Hamid Alinejad-Rokny

The rapid progress in Large Language Models (LLMs) has prompted the creation
of numerous benchmarks to evaluate their capabilities.This study focuses on the
Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset
diversity and distribution in supervised fine-tuning (SFT) may enhance LLM
performance.Remarkably, We successfully trained a smaller base model to achieve
scores comparable to larger models, indicating that a diverse and
well-distributed dataset can optimize performance regardless of model size.This
study suggests that even smaller models may reach high performance levels with
carefully curated and varied datasets. By integrating a wide range of
instructional content, our approach addresses potential issues such as data
quality inconsistencies. Our results imply that a broader spectrum of training
data may enhance a model's ability to generalize and perform effectively across
different medical scenarios, highlighting the importance of dataset quality and
diversity in fine-tuning processes. We open-source the model for future
research at https://github.com/CAS-SIAT-XinHai/CollectiveSFT

摘要：大型語言模型 (LLM) 的快速進展促成了許多基準的建立，以評估它們的能力。本研究專注於中文綜合醫療基準 (CMB)，展示了監督微調 (SFT) 中的資料集多樣性和分佈如何增強 LLM 效能。值得注意的是，我們成功地訓練了一個較小的基礎模型，以達到與較大型模型相當的分數，這表明一個多樣化且分佈良好的資料集可以最佳化效能，而與模型大小無關。本研究表明，即使是較小的模型，只要使用經過仔細策劃且多樣化的資料集，也能達到高水準的效能。透過整合廣泛的教學內容，我們的做法解決了資料品質不一致等潛在問題。我們的結果表明，更廣泛的訓練資料範圍可能會增強模型在不同醫療場景中概括和有效執行的能力，突顯了資料集品質和多樣性在微調過程中扮演的重要角色。我們在 https://github.com/CAS-SIAT-XinHai/CollectiveSFT 開源此模型以供將來研究。

##### **Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks**
2407.21072v1 by Marco AF Pimentel, Clément Christophe, Tathagata Raha, Prateek Munjal, Praveen K Kanithi, Shadab Khan

As large language models (LLMs) continue to evolve, the need for robust and
standardized evaluation benchmarks becomes paramount. Evaluating the
performance of these models is a complex challenge that requires careful
consideration of various linguistic tasks, model architectures, and
benchmarking methodologies. In recent years, various frameworks have emerged as
noteworthy contributions to the field, offering comprehensive evaluation tests
and benchmarks for assessing the capabilities of LLMs across diverse domains.
This paper provides an exploration and critical analysis of some of these
evaluation methodologies, shedding light on their strengths, limitations, and
impact on advancing the state-of-the-art in natural language processing.

摘要：隨著大型語言模型 (LLM) 持續演進，對於健全且標準化的評估基準的需求變得至關重要。評估這些模型的效能是一項複雜的挑戰，需要仔細考量各種語言任務、模型架構和基準方法。近年來，各種架構已成為該領域的顯著貢獻，提供全面的評估測試和基準，用於評估 LLM 在不同領域的能力。本文探討並批判性地分析其中一些評估方法，闡明其優點、限制和對自然語言處理領域進步的影響。

##### **Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity**
2407.19668v1 by Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang

Traffic accidents pose a significant risk to human health and property
safety. Therefore, to prevent traffic accidents, predicting their risks has
garnered growing interest. We argue that a desired prediction solution should
demonstrate resilience to the complexity of traffic accidents. In particular,
it should adequately consider the regional background, accurately capture both
spatial proximity and semantic similarity, and effectively address the sparsity
of traffic accidents. However, these factors are often overlooked or difficult
to incorporate. In this paper, we propose a novel multi-granularity
hierarchical spatio-temporal network. Initially, we innovate by incorporating
remote sensing data, facilitating the creation of hierarchical
multi-granularity structure and the comprehension of regional background. We
construct multiple high-level risk prediction tasks to enhance model's ability
to cope with sparsity. Subsequently, to capture both spatial proximity and
semantic similarity, region feature and multi-view graph undergo encoding
processes to distill effective representations. Additionally, we propose
message passing and adaptive temporal attention module that bridges different
granularities and dynamically captures time correlations inherent in traffic
accident patterns. At last, a multivariate hierarchical loss function is
devised considering the complexity of the prediction purpose. Extensive
experiments on two real datasets verify the superiority of our model against
the state-of-the-art methods.

摘要：交通事故對人類健康和財產安全構成重大風險。因此，預測交通事故風險已引起越來越大的興趣。我們認為，理想的預測解決方案應展現出對交通事故複雜性的韌性。具體而言，它應充分考慮區域背景，準確捕捉空間接近度和語義相似性，並有效解決交通事故的稀疏性。然而，這些因素通常被忽視或難以納入。在本文中，我們提出了一個新穎的多粒度分層時空網路。最初，我們創新地納入了遙感數據，促进了分層多粒度結構的創建和區域背景的理解。我們構建了多個高級風險預測任務，以增強模型應對稀疏性的能力。隨後，為了捕捉空間接近度和語義相似性，區域特徵和多視圖圖表經過編碼過程，以提取有效的表示。此外，我們提出了消息傳遞和自適應時間注意力模組，它架起了不同粒度之間的橋樑，並動態捕捉交通事故模式中固有的時間相關性。最後，考慮到預測目的的複雜性，設計了一個多變量分層損失函數。在兩個真實數據集上的大量實驗驗證了我們模型優於最先進方法的優越性。

##### **Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Knowledge Distillation and Random Data Erasing**
2407.19540v1 by Heejoon Koo

In this paper, we present NECHO v2, a novel framework designed to enhance the
predictive accuracy of multimodal sequential patient diagnoses under uncertain
missing visit sequences, a common challenge in clinical settings. Firstly, we
modify NECHO to handle uncertain modality representation dominance under the
imperfect data. Next, we develop a systematic knowledge distillation by
employing the modified NECHO as both teacher and student. It encompasses a
modality-wise contrastive and hierarchical distillation, transformer
representation random distillation, along with other distillations to align
representations tightly and effectively. We also utilise random erasing on
individual data points within sequences during both training and distillation
of teacher to lightly simulate scenario with missing visit information to
foster effective knowledge transfer. As a result, NECHO v2 verifies itself by
showing superiority in multimodal sequential diagnosis prediction on both
balanced and imbalanced incomplete settings on multimodal healthcare data.

摘要：在本文中，我們提出了 NECHO v2，一個新穎的框架，旨在增強多模態順序患者診斷的預測準確度，在臨床環境中常見的挑戰是不確定遺漏的訪問序列。首先，我們修改 NECHO 以處理不完美數據下的不確定模態表示優勢。接下來，我們通過使用修改後的 NECHO 作為教師和學生來開發系統的知識提煉。它包含模態對比和分層提煉、Transformer表示隨機提煉以及其他提煉，以緊密有效地對齊表示。我們還在訓練和教師提煉過程中對序列中的個別數據點使用隨機擦除，以輕微模擬遺漏訪問信息的場景，以促進有效的知識傳遞。因此，NECHO v2 通過在多模態醫療保健數據的平衡和不平衡不完整設置上顯示多模態順序診斷預測的優越性來驗證自身。

##### **Nudging Consent and the New Opt Out System to the Processing of Health Data in England**
2407.19447v1 by Janos Meszaros, Chih-hsing Ho, Marcelo Corrales Compagnucci

This chapter examines the challenges of the revised opt out system and the
secondary use of health data in England. The analysis of this data could be
very valuable for science and medical treatment as well as for the discovery of
new drugs. For this reason, the UK government established the care.data program
in 2013. The aim of the project was to build a central nationwide database for
research and policy planning. However, the processing of personal data was
planned without proper public engagement. Research has suggested that IT
companies, such as in the Google DeepMind deal case, had access to other kinds
of sensitive data and failed to comply with data protection law. Since May
2018, the government has launched the national data opt out system with the
hope of regaining public trust. Nevertheless, there are no evidence of
significant changes in the ND opt out, compared to the previous opt out system.
Neither in the use of secondary data, nor in the choices that patients can
make. The only notorious difference seems to be in the way that these options
are communicated and framed to the patients. Most importantly, according to the
new ND opt out, the type 1 opt out option, which is the only choice that truly
stops data from being shared outside direct care, will be removed in 2020.
According to the Behavioral Law and Economics literature (Nudge Theory),
default rules, such as the revised opt out system in England, are very
powerful, because people tend to stick to the default choices made readily
available to them. The crucial question analyzed in this chapter is whether it
is desirable for the UK government to stop promoting the type 1 opt outs, and
whether this could be seen as a kind of hard paternalism.

摘要：<paragraph>本章探討了英國修改後的退出機制和二次使用健康資料所面臨的挑戰。分析這些資料對於科學和醫療治療以及發現新藥物而言，可能非常有價值。基於此原因，英國政府於 2013 年建立了 care.data 計畫。該專案的目標是建立一個全國性的中央資料庫，以進行研究和政策規劃。然而，個人資料的處理是在沒有適當公眾參與的情況下進行規劃的。研究表明，例如在 Google DeepMind 交易案例中，IT 公司可以存取其他類型的敏感資料，且未能遵守資料保護法。自 2018 年 5 月以來，政府已推出全國資料退出機制，希望能重新獲得公眾信任。儘管如此，與先前的退出機制相比，並無證據顯示全國資料退出機制有顯著變化。無論是在二次資料的使用上，或是在患者可以做出的選擇上，皆是如此。唯一顯著的差異似乎在於這些選項的溝通和傳達方式。最重要的是，根據新的全國資料退出機制，類型 1 退出選項（這是唯一真正能阻止資料在直接照護之外被分享的選項）將於 2020 年被移除。根據行為法與經濟學文獻（推論理論），預設規則（例如英國修改後的退出機制）非常有效，因為人們傾向於堅持容易取得的預設選項。本章分析的關鍵問題是，英國政府停止推廣類型 1 退出是否可取，以及這是否可以視為一種嚴厲的父權主義。</paragraph>

##### **ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding**
2407.19435v1 by Zhen Chen, Zongming Zhang, Wenwu Guo, Xingjian Luo, Long Bai, Jinlin Wu, Hongliang Ren, Hongbin Liu

Surgical instrument segmentation is crucial in surgical scene understanding,
thereby facilitating surgical safety. Existing algorithms directly detected all
instruments of pre-defined categories in the input image, lacking the
capability to segment specific instruments according to the surgeon's
intention. During different stages of surgery, surgeons exhibit varying
preferences and focus toward different surgical instruments. Therefore, an
instrument segmentation algorithm that adheres to the surgeon's intention can
minimize distractions from irrelevant instruments and assist surgeons to a
great extent. The recent Segment Anything Model (SAM) reveals the capability to
segment objects following prompts, but the manual annotations for prompts are
impractical during the surgery. To address these limitations in operating
rooms, we propose an audio-driven surgical instrument segmentation framework,
named ASI-Seg, to accurately segment the required surgical instruments by
parsing the audio commands of surgeons. Specifically, we propose an
intention-oriented multimodal fusion to interpret the segmentation intention
from audio commands and retrieve relevant instrument details to facilitate
segmentation. Moreover, to guide our ASI-Seg segment of the required surgical
instruments, we devise a contrastive learning prompt encoder to effectively
distinguish the required instruments from the irrelevant ones. Therefore, our
ASI-Seg promotes the workflow in the operating rooms, thereby providing
targeted support and reducing the cognitive load on surgeons. Extensive
experiments are performed to validate the ASI-Seg framework, which reveals
remarkable advantages over classical state-of-the-art and medical SAMs in both
semantic segmentation and intention-oriented segmentation. The source code is
available at https://github.com/Zonmgin-Zhang/ASI-Seg.

摘要：手術器械分割對於手術場景理解至關重要，
從而促進手術安全。現有演算法直接偵測輸入影像中所有預定義類別的器械，缺乏根據外科醫師意圖分割特定器械的能力。在手術的不同階段，外科醫師會對不同的手術器械表現出不同的偏好和關注。因此，一種遵循外科醫師意圖的器械分割演算法可以最大程度地減少與手術無關的器械的干擾，並在很大程度上協助外科醫師。最近的 Segment Anything Model (SAM) 揭示了根據提示分割物件的能力，但提示的手動註解在手術過程中不切實際。為了解決手術室中的這些限制，我們提出了一個音訊驅動的手術器械分割架構，稱為 ASI-Seg，通過解析外科醫師的音訊命令來準確分割所需的器械。具體來說，我們提出了一個意圖導向的多模態融合，從音訊命令中解釋分割意圖並檢索相關器械細節以利於分割。此外，為了指導我們的 ASI-Seg 分割所需的器械，我們設計了一個對比學習提示編碼器，以有效區分所需的器械和不相關的器械。因此，我們的 ASI-Seg 促進了手術室中的工作流程，從而提供了有針對性的支援，並降低了外科醫師的認知負擔。進行了大量的實驗來驗證 ASI-Seg 架構，這揭示了在語義分割和意圖導向分割中，與傳統的最新技術和醫學 SAM 相比，它具有顯著的優勢。原始碼可在 https://github.com/Zonmgin-Zhang/ASI-Seg 獲得。

##### **A Generic Review of Integrating Artificial Intelligence in Cognitive Behavioral Therapy**
2407.19422v1 by Meng Jiang, Qing Zhao, Jianqiang Li, Fan Wang, Tianyu He, Xinyan Cheng, Bing Xiang Yang, Grace W. K. Ho, Guanghui Fu

Cognitive Behavioral Therapy (CBT) is a well-established intervention for
mitigating psychological issues by modifying maladaptive cognitive and
behavioral patterns. However, delivery of CBT is often constrained by resource
limitations and barriers to access. Advancements in artificial intelligence
(AI) have provided technical support for the digital transformation of CBT.
Particularly, the emergence of pre-training models (PTMs) and large language
models (LLMs) holds immense potential to support, augment, optimize and
automate CBT delivery. This paper reviews the literature on integrating AI into
CBT interventions. We begin with an overview of CBT. Then, we introduce the
integration of AI into CBT across various stages: pre-treatment, therapeutic
process, and post-treatment. Next, we summarized the datasets relevant to some
CBT-related tasks. Finally, we discuss the benefits and current limitations of
applying AI to CBT. We suggest key areas for future research, highlighting the
need for further exploration and validation of the long-term efficacy and
clinical utility of AI-enhanced CBT. The transformative potential of AI in
reshaping the practice of CBT heralds a new era of more accessible, efficient,
and personalized mental health interventions.

摘要：認知行為療法 (CBT) 是一種完善的干預措施，透過調整適應不良的認知和行為模式來減輕心理問題。然而，CBT 的提供往往受到資源限制和獲取障礙的限制。人工智慧 (AI) 的進步為 CBT 的數位轉型提供了技術支援。特別是，預訓練模型 (PTM) 和大型語言模型 (LLM) 的出現具有巨大的潛力，可以支援、擴充、最佳化和自動化 CBT 的提供。本文回顧了將 AI 整合到 CBT 干預措施的文獻。我們從 CBT 的概述開始。然後，我們介紹了在各種階段將 AI 整合到 CBT 中：治療前、治療過程和治療後。接下來，我們總結了與一些 CBT 相關任務相關的資料集。最後，我們討論了將 AI 應用於 CBT 的好處和目前的限制。我們建議未來研究的主要領域，強調需要進一步探索和驗證 AI 增強 CBT 的長期療效和臨床效用。AI 在重塑 CBT 實務中的轉化潛力預示著一個新的時代，即更易於取得、更有效率和更個人化的心理健康干預措施。

##### **Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment**
2407.19380v1 by Aamer Abdul Rahman, Pranav Agarwal, Rita Noumeir, Philippe Jouvet, Vincent Michalski, Samira Ebrahimi Kahou

Offline reinforcement learning has shown promise for solving tasks in
safety-critical settings, such as clinical decision support. Its application,
however, has been limited by the lack of interpretability and interactivity for
clinicians. To address these challenges, we propose the medical decision
transformer (MeDT), a novel and versatile framework based on the
goal-conditioned reinforcement learning paradigm for sepsis treatment
recommendation. MeDT uses the decision transformer architecture to learn a
policy for drug dosage recommendation. During offline training, MeDT utilizes
collected treatment trajectories to predict administered treatments for each
time step, incorporating known treatment outcomes, target acuity scores, past
treatment decisions, and current and past medical states. This analysis enables
MeDT to capture complex dependencies among a patient's medical history,
treatment decisions, outcomes, and short-term effects on stability. Our
proposed conditioning uses acuity scores to address sparse reward issues and to
facilitate clinician-model interactions, enhancing decision-making. Following
training, MeDT can generate tailored treatment recommendations by conditioning
on the desired positive outcome (survival) and user-specified short-term
stability improvements. We carry out rigorous experiments on data from the
MIMIC-III dataset and use off-policy evaluation to demonstrate that MeDT
recommends interventions that outperform or are competitive with existing
offline reinforcement learning methods while enabling a more interpretable,
personalized and clinician-directed approach.

摘要：離線強化學習已展現出解決諸如臨床決策支援等安全關鍵設定中任務的潛力。然而，其應用受到臨床醫師對可解釋性和互動性的缺乏所限制。為了應對這些挑戰，我們提出了醫療決策轉換器 (MeDT)，這是一個基於目標條件強化學習範例的新穎且多功能的架構，用於敗血症治療建議。MeDT 使用決策轉換器架構來學習藥物劑量建議的政策。在離線訓練期間，MeDT 利用收集的治療軌跡來預測每個時間步驟的管理治療，並納入已知的治療結果、目標嚴重程度評分、過去的治療決策以及當前和過去的醫療狀態。此分析使 MeDT 能夠捕捉患者病史、治療決策、結果以及對穩定性的短期影響之間的複雜依賴關係。我們提出的條件使用嚴重程度評分來解決稀疏獎勵問題並促進臨床醫師與模型的互動，從而增強決策制定。在訓練之後，MeDT 可以通過以所需的正面結果（存活）和使用者指定的短期穩定性改善為條件來產生量身打造的治療建議。我們對來自 MIMIC-III 資料集的資料進行了嚴格的實驗，並使用非策略評估來證明 MeDT 推薦的干預措施優於或與現有的離線強化學習方法具有競爭力，同時實現了更具可解釋性、個性化和臨床醫師指導的方法。

##### **Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction**
2407.19359v1 by Yuan Xue, Nan Du, Anne Mottram, Martin Seneviratne, Andrew M. Dai

We propose to meta-learn an a self-supervised patient trajectory forecast
learning rule by meta-training on a meta-objective that directly optimizes the
utility of the patient representation over the subsequent clinical outcome
prediction. This meta-objective directly targets the usefulness of a
representation generated from unlabeled clinical measurement forecast for later
supervised tasks.
  The meta-learned can then be directly used in target risk prediction, and the
limited available samples can be used for further fine-tuning the model
performance. The effectiveness of our approach is tested on a real open source
patient EHR dataset MIMIC-III. We are able to demonstrate that our
attention-based patient state representation approach can achieve much better
performance for predicting target risk with low resources comparing with both
direct supervised learning and pretraining with all-observation trajectory
forecast.

摘要：我們提議透過元訓練來元學習一個自我監督的患者軌跡預測學習規則，並透過元目標直接最佳化患者表徵在後續臨床結果預測中的效用。此元目標直接針對從未標記的臨床測量預測所產生的表徵在後續監督式任務中的效用。
元學習後，可以直接用於目標風險預測，且可使用有限的可用樣本進一步微調模型效能。我們的方法之有效性已在一個真實的開放原始碼患者電子病歷資料集 MIMIC-III 上進行測試。我們能夠證明，與直接監督式學習和使用所有觀察軌跡預測進行預訓練相比，我們基於注意力的患者狀態表徵方法可以達到更好的目標風險預測效能，且資源需求較低。

##### **Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification**
2407.19340v1 by Santosh V. Patapati

Major Depressive Disorder (MDD) is a pervasive mental health condition that
affects 300 million people worldwide. This work presents a novel, BiLSTM-based
tri-modal model-level fusion architecture for the binary classification of
depression from clinical interview recordings. The proposed architecture
incorporates Mel Frequency Cepstral Coefficients, Facial Action Units, and uses
a two-shot learning based GPT-4 model to process text data. This is the first
work to incorporate large language models into a multi-modal architecture for
this task. It achieves impressive results on the DAIC-WOZ AVEC 2016 Challenge
cross-validation split and Leave-One-Subject-Out cross-validation split,
surpassing all baseline models and multiple state-of-the-art models. In
Leave-One-Subject-Out testing, it achieves an accuracy of 91.01%, an F1-Score
of 85.95%, a precision of 80%, and a recall of 92.86%.

摘要：重度憂鬱症 (MDD) 是一種普遍的精神健康疾病，
影響全球 3 億人。這項工作提出了一種新穎的、基於 BiLSTM
的三模態模型級融合架構，用於從臨床訪談錄音中對憂鬱症進行二元分類。所提出的架構
結合了梅爾頻率倒譜係數、面部動作單元，並使用基於 GPT-4 的兩次學習模型來處理文本數據。這是第一個
將大型語言模型納入多模態架構以執行此任務的工作。它在 DAIC-WOZ AVEC 2016 挑戰賽
交叉驗證分割和留一受試者交叉驗證分割中取得了令人印象深刻的結果，超越了所有基線模型和多個最先進的模型。在
留一受試者測試中，它的準確率達到 91.01%，F1 分數
為 85.95%，準確度為 80%，召回率為 92.86%。

##### **Multi-Modal CLIP-Informed Protein Editing**
2407.19296v1 by Mingze Yin, Hanjing Zhou, Yiheng Zhu, Miao Lin, Yixuan Wu, Jialu Wu, Hongxia Xu, Chang-Yu Hsieh, Tingjun Hou, Jintai Chen, Jian Wu

Proteins govern most biological functions essential for life, but achieving
controllable protein discovery and optimization remains challenging. Recently,
machine learning-assisted protein editing (MLPE) has shown promise in
accelerating optimization cycles and reducing experimental workloads. However,
current methods struggle with the vast combinatorial space of potential protein
edits and cannot explicitly conduct protein editing using biotext instructions,
limiting their interactivity with human feedback. To fill these gaps, we
propose a novel method called ProtET for efficient CLIP-informed protein
editing through multi-modality learning. Our approach comprises two stages: in
the pretraining stage, contrastive learning aligns protein-biotext
representations encoded by two large language models (LLMs), respectively.
Subsequently, during the protein editing stage, the fused features from editing
instruction texts and original protein sequences serve as the final editing
condition for generating target protein sequences. Comprehensive experiments
demonstrated the superiority of ProtET in editing proteins to enhance
human-expected functionality across multiple attribute domains, including
enzyme catalytic activity, protein stability and antibody specific binding
ability. And ProtET improves the state-of-the-art results by a large margin,
leading to significant stability improvements of 16.67% and 16.90%. This
capability positions ProtET to advance real-world artificial protein editing,
potentially addressing unmet academic, industrial, and clinical needs.

摘要：<paragraph>蛋白质掌管着维持生命所需的大多数生物功能，但要实现可控的蛋白质发现和优化仍然具有挑战性。最近，机器学习辅助蛋白质编辑 (MLPE) 已显示出在加速优化周期和减少实验工作量方面的前景。然而，当前方法难以应对潜在蛋白质编辑的巨大组合空间，并且无法明确使用生物文本说明进行蛋白质编辑，从而限制了它们与人类反馈的交互性。为了填补这些空白，我们提出了一种称为 ProtET 的新方法，用于通过多模态学习进行高效的 CLIP 知情蛋白质编辑。我们的方法包括两个阶段：在预训练阶段，对比学习将分别由两个大型语言模型 (LLM) 编码的蛋白质生物文本表示对齐。随后，在蛋白质编辑阶段，来自编辑指令文本和原始蛋白质序列的融合特征作为生成目标蛋白质序列的最终编辑条件。综合实验表明，ProtET 在编辑蛋白质以增强跨多个属性域的人类预期功能方面具有优势，包括酶催化活性、蛋白质稳定性和抗体特异性结合能力。ProtET 将最先进的结果提高了一个很大的幅度，导致稳定性显着提高了 16.67% 和 16.90%。这种能力使 ProtET 能够推进现实世界的人工蛋白质编辑，有可能满足未满足的学术、工业和临床需求。</paragraph>

##### **Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review**
2407.19256v1 by Tongyue Shi, Jun Ma, Zihan Yu, Haowei Xu, Minqi Xiong, Meirong Xiao, Yilin Li, Huiying Zhao, Guilan Kong

With the rapid development of artificial intelligence (AI), large language
models (LLMs) have shown strong capabilities in natural language understanding,
reasoning, and generation, attracting amounts of research interest in applying
LLMs to health and medicine. Critical care medicine (CCM) provides diagnosis
and treatment for critically ill patients who often require intensive
monitoring and interventions in intensive care units (ICUs). Can LLMs be
applied to CCM? Are LLMs just like stochastic parrots or ICU experts in
assisting clinical decision-making? This scoping review aims to provide a
panoramic portrait of the application of LLMs in CCM. Literature in seven
databases, including PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE
Xplore, and ACM Digital Library, were searched from January 1, 2019, to June
10, 2024. Peer-reviewed journal and conference articles that discussed the
application of LLMs in critical care settings were included. From an initial
619 articles, 24 were selected for final review. This review grouped
applications of LLMs in CCM into three categories: clinical decision support,
medical documentation and reporting, and medical education and doctor-patient
communication. LLMs have advantages in handling unstructured data and do not
require manual feature engineering. Meanwhile, applying LLMs to CCM faces
challenges, including hallucinations, poor interpretability, bias and alignment
challenges, and privacy and ethics issues. Future research should enhance model
reliability and interpretability, integrate up-to-date medical knowledge, and
strengthen privacy and ethical guidelines. As LLMs evolve, they could become
key tools in CCM to help improve patient outcomes and optimize healthcare
delivery. This study is the first review of LLMs in CCM, aiding researchers,
clinicians, and policymakers to understand the current status and future
potentials of LLMs in CCM.

摘要：隨著人工智慧 (AI) 的快速發展，大型語言模型 (LLM) 已在自然語言理解、推理和生成方面展現出強大的能力，吸引了大量研究人員對將 LLM 應用於健康和醫學領域的興趣。重症醫學 (CCM) 為病危患者提供診斷和治療，這些患者通常需要在重症監護病房 (ICU) 中進行密集監控和干預。LLM 能否應用於 CCM？LLM 協助臨床決策時，是否僅像隨機鸚鵡或 ICU 專家？本範圍審查旨在提供 LLM 在 CCM 中應用的全景概況。從 PubMed、Embase、Scopus、Web of Science、CINAHL、IEEE Xplore 和 ACM Digital Library 等七個資料庫中搜尋 2019 年 1 月 1 日至 2024 年 6 月 10 日之間的文獻。納入了討論 LLM 在重症照護環境中應用的同行評審期刊和會議論文。在最初的 619 篇論文中，選出 24 篇進行最終審查。本審查將 LLM 在 CCM 中的應用分為三類：臨床決策支援、醫療文件和報告，以及醫學教育和醫患溝通。LLM 在處理非結構化資料方面具有優勢，且不需要手動特徵工程。同時，將 LLM 應用於 CCM 面臨挑戰，包括幻覺、可解釋性差、偏差和對齊挑戰，以及隱私和道德問題。未來的研究應加強模型的可靠性和可解釋性，整合最新的醫學知識，並加強隱私和道德準則。隨著 LLM 的發展，它們可能會成為 CCM 中的關鍵工具，有助於改善患者的治療成果並優化醫療保健服務。本研究是 LLM 在 CCM 中的第一篇審查，有助於研究人員、臨床醫生和政策制定者了解 LLM 在 CCM 中的現狀和未來潛力。

##### **Channel Boosted CNN-Transformer-based Multi-Level and Multi-Scale Nuclei Segmentation**
2407.19186v1 by Zunaira Rauf, Abdul Rehman Khan, Asifullah Khan

Accurate nuclei segmentation is an essential foundation for various
applications in computational pathology, including cancer diagnosis and
treatment planning. Even slight variations in nuclei representations can
significantly impact these downstream tasks. However, achieving accurate
segmentation remains challenging due to factors like clustered nuclei, high
intra-class variability in size and shape, resemblance to other cells, and
color or contrast variations between nuclei and background. Despite the
extensive utilization of Convolutional Neural Networks (CNNs) in medical image
segmentation, they may have trouble capturing long-range dependencies crucial
for accurate nuclei delineation. Transformers address this limitation but might
miss essential low-level features. To overcome these limitations, we utilized
CNN-Transformer-based techniques for nuclei segmentation in H&E stained
histology images. In this work, we proposed two CNN-Transformer architectures,
Nuclei Hybrid Vision Transformer (NucleiHVT) and Channel Boosted Nuclei Hybrid
Vision Transformer (CB-NucleiHVT), that leverage the strengths of both CNNs and
Transformers to effectively learn nuclei boundaries in multi-organ histology
images. The first architecture, NucleiHVT is inspired by the UNet architecture
and incorporates the dual attention mechanism to capture both multi-level and
multi-scale context effectively. The CB-NucleiHVT network, on the other hand,
utilizes the concept of channel boosting to learn diverse feature spaces,
enhancing the model's ability to distinguish subtle variations in nuclei
characteristics. Detailed evaluation of two medical image segmentation datasets
shows that the proposed architectures outperform existing CNN-based,
Transformer-based, and hybrid methods. The proposed networks demonstrated
effective results both in terms of quantitative metrics, and qualitative visual
assessment.

摘要：精確的細胞核分割是計算病理學中各種應用（包括癌症診斷和治療規劃）的基礎。即使細胞核表現形式有輕微變化，也會對這些下游任務產生重大影響。然而，由於細胞核聚集、大小和形狀的類內變異性高、與其他細胞相似、細胞核與背景之間的顏色或對比度變化等因素，實現精確分割仍然具有挑戰性。儘管卷積神經網路 (CNN) 在醫學影像分割中得到廣泛應用，但它們可能難以捕捉對於精確細胞核描繪至關重要的長程依賴性。Transformer 解決了這個限制，但可能會錯過必要的低階特徵。為了克服這些限制，我們利用基於 CNN-Transformer 的技術對 H&E 染色的組織學影像進行細胞核分割。在這項工作中，我們提出了兩種 CNN-Transformer 架構，即細胞核混合視覺 Transformer（NucleiHVT）和通道增強細胞核混合視覺 Transformer（CB-NucleiHVT），它們利用 CNN 和 Transformer 的優勢來有效學習多器官組織學影像中的細胞核邊界。第一個架構 NucleiHVT 受到 UNet 架構的啟發，並結合雙注意力機制來有效捕捉多層級和多尺度的背景。另一方面，CB-NucleiHVT 網路利用通道增強的概念來學習不同的特徵空間，增強模型區分細胞核特徵細微變化的能力。對兩個醫學影像分割資料集的詳細評估表明，所提出的架構優於現有的基於 CNN、基於 Transformer 和混合方法。所提出的網路在量化指標和定性視覺評估方面都展示了有效結果。

##### **Large Language Models as Co-Pilots for Causal Inference in Medical Studies**
2407.19118v1 by Ahmed Alaa, Rachael V. Phillips, Emre Kıcıman, Laura B. Balzer, Mark van der Laan, Maya Petersen

The validity of medical studies based on real-world clinical data, such as
observational studies, depends on critical assumptions necessary for drawing
causal conclusions about medical interventions. Many published studies are
flawed because they violate these assumptions and entail biases such as
residual confounding, selection bias, and misalignment between treatment and
measurement times. Although researchers are aware of these pitfalls, they
continue to occur because anticipating and addressing them in the context of a
specific study can be challenging without a large, often unwieldy,
interdisciplinary team with extensive expertise. To address this expertise gap,
we explore the use of large language models (LLMs) as co-pilot tools to assist
researchers in identifying study design flaws that undermine the validity of
causal inferences. We propose a conceptual framework for LLMs as causal
co-pilots that encode domain knowledge across various fields, engaging with
researchers in natural language interactions to provide contextualized
assistance in study design. We provide illustrative examples of how LLMs can
function as causal co-pilots, propose a structured framework for their
grounding in existing causal inference frameworks, and highlight the unique
challenges and opportunities in adapting LLMs for reliable use in
epidemiological research.

摘要：基於真實世界臨床資料的醫學研究，例如觀察性研究，其有效性取決於得出醫療介入因果結論時必要的關鍵假設。許多已發表的研究所存在缺陷，因為它們違反了這些假設，並導致了殘留混淆、選擇偏誤以及治療與測量時間之間的不一致等偏差。儘管研究人員意識到這些缺陷，但它們仍然會發生，因為在具體的研究背景下預期並解決這些缺陷可能具有挑戰性，除非有一個龐大且通常難以控制的、擁有廣泛專業知識的跨學科團隊。為了彌補這種專業知識差距，我們探索了使用大型語言模型 (LLM) 作為副駕駛工具，以協助研究人員識別破壞因果推論有效性的研究設計缺陷。我們提出了 LLM 作為因果副駕駛的概念架構，該架構編碼了跨各種領域的領域知識，並通過自然語言互動與研究人員互動，以在研究設計中提供情境化的協助。我們提供了 LLM 如何作為因果副駕駛運作的說明性範例，提出了它們在現有因果推論框架中接地的結構化框架，並強調了在流行病學研究中適應 LLM 以實現可靠使用的獨特挑戰和機遇。

##### **Solving Robotics Problems in Zero-Shot with Vision-Language Models**
2407.19094v1 by Zidan Wang, Rui Shen, Bradly Stadie

We introduce Wonderful Team, a multi-agent visual LLM (VLLM) framework for
solving robotics problems in the zero-shot regime. By zero-shot we mean that,
for a novel environment, we feed a VLLM an image of the robot's environment and
a description of the task, and have the VLLM output the sequence of actions
necessary for the robot to complete the task. Prior work on VLLMs in robotics
has largely focused on settings where some part of the pipeline is fine-tuned,
such as tuning an LLM on robot data or training a separate vision encoder for
perception and action generation. Surprisingly, due to recent advances in the
capabilities of VLLMs, this type of fine-tuning may no longer be necessary for
many tasks. In this work, we show that with careful engineering, we can prompt
a single off-the-shelf VLLM to handle all aspects of a robotics task, from
high-level planning to low-level location-extraction and action-execution.
Wonderful Team builds on recent advances in multi-agent LLMs to partition tasks
across an agent hierarchy, making it self-corrective and able to effectively
partition and solve even long-horizon tasks. Extensive experiments on VIMABench
and real-world robotic environments demonstrate the system's capability to
handle a variety of robotic tasks, including manipulation, visual
goal-reaching, and visual reasoning, all in a zero-shot manner. These results
underscore a key point: vision-language models have progressed rapidly in the
past year, and should strongly be considered as a backbone for robotics
problems going forward.

摘要：<paragraph>我們推出 Wonderful Team，這是一個多代理視覺 LLM (VLLM) 架構，用於解決零次學習模式下的機器人問題。零次學習是指，對於一個新環境，我們向 VLLM 提供機器人環境的圖像和任務描述，並讓 VLLM 輸出機器人完成任務所需的動作序列。機器人領域中 VLLM 的先前研究主要集中在管道某一部分進行微調的設定上，例如針對機器人資料微調 LLM 或訓練一個單獨的視覺編碼器以進行感知和動作產生。令人驚訝的是，由於 VLLM 能力的最新進展，對於許多任務來說，這種微調可能不再必要。在這項工作中，我們展示了透過仔細的工程設計，我們可以提示一個單一的現成 VLLM 來處理機器人任務的所有方面，從高層級規劃到低層級位置提取和動作執行。Wonderful Team 建立在多代理 LLM 的最新進展上，以在代理層級中分配任務，使其具有自我修正能力，並能有效地分配和解決長遠任務。在 VIMABench 和真實機器人環境中進行的廣泛實驗證明了系統處理各種機器人任務的能力，包括操作、視覺目標達成和視覺推理，所有這些都是在零次學習模式下進行的。這些結果強調了一個重點：視覺語言模型在過去一年中進步迅速，並且應強烈考慮作為機器人問題未來的基礎。</paragraph>

##### **Using Large Language Models for the Interpretation of Building Regulations**
2407.21060v1 by Stefan Fuchs, Michael Witbrock, Johannes Dimyadi, Robert Amor

Compliance checking is an essential part of a construction project. The
recent rapid uptake of building information models (BIM) in the construction
industry has created more opportunities for automated compliance checking
(ACC). BIM enables sharing of digital building design data that can be used for
compliance checking with legal requirements, which are conventionally conveyed
in natural language and not intended for machine processing. Creating a
computable representation of legal requirements suitable for ACC is complex,
costly, and time-consuming. Large language models (LLMs) such as the generative
pre-trained transformers (GPT), GPT-3.5 and GPT-4, powering OpenAI's ChatGPT,
can generate logically coherent text and source code responding to user
prompts. This capability could be used to automate the conversion of building
regulations into a semantic and computable representation. This paper evaluates
the performance of LLMs in translating building regulations into LegalRuleML in
a few-shot learning setup. By providing GPT-3.5 with only a few example
translations, it can learn the basic structure of the format. Using a system
prompt, we further specify the LegalRuleML representation and explore the
existence of expert domain knowledge in the model. Such domain knowledge might
be ingrained in GPT-3.5 through the broad pre-training but needs to be brought
forth by careful contextualisation. Finally, we investigate whether strategies
such as chain-of-thought reasoning and self-consistency could apply to this use
case. As LLMs become more sophisticated, the increased common sense, logical
coherence, and means to domain adaptation can significantly support ACC,
leading to more efficient and effective checking processes.

摘要：合規檢查是一個建設專案的必要部分。建築產業最近快速採用建築資訊模型 (BIM)，為自動化合規檢查 (ACC) 創造了更多機會。BIM 能夠分享可供用於與法律要求進行合規檢查的數位建築設計資料，而這些要求通常以自然語言傳達，且並非用於機器處理。建立一個適合 ACC 的法律要求可計算表示非常複雜、昂貴且耗時。大型語言模型 (LLM) 例如生成式預先訓練轉換器 (GPT)、GPT-3.5 和 GPT-4，為 OpenAI 的 ChatGPT 提供動力，可以產生合乎邏輯的連貫文字和原始碼，以回應使用者的提示。此功能可用於自動化將建築法規轉換為語意和可計算的表示。本文評估了 LLM 在將建築法規翻譯成 LegalRuleML 的表現，並採用少次學習設定。透過僅提供少數範例翻譯給 GPT-3.5，它可以學習格式的基本結構。使用系統提示，我們進一步指定 LegalRuleML 表示，並探討模型中是否存在專家領域知識。此類領域知識可能透過廣泛的預先訓練植入 GPT-3.5，但需要透過仔細的脈絡化才能產生。最後，我們探討諸如思考鏈推理和自我一致性等策略是否適用於此用例。隨著 LLM 變得更精緻，常識、邏輯連貫性和領域適應方法的增加可以顯著支援 ACC，進而帶來更有效率且有效的檢查流程。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**
2407.18525v1 by Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Liantao Ma

The use of Large Language Models (LLMs) in medicine is growing, but their
ability to handle both structured Electronic Health Record (EHR) data and
unstructured clinical notes is not well-studied. This study benchmarks various
models, including GPT-based LLMs, BERT-based models, and traditional clinical
predictive models, for non-generative medical tasks utilizing renowned
datasets. We assessed 14 language models (9 GPT-based and 5 BERT-based) and 7
traditional predictive models using the MIMIC dataset (ICU patient records) and
the TJH dataset (early COVID-19 EHR data), focusing on tasks such as mortality
and readmission prediction, disease hierarchy reconstruction, and biomedical
sentence matching, comparing both zero-shot and finetuned performance. Results
indicated that LLMs exhibited robust zero-shot predictive capabilities on
structured EHR data when using well-designed prompting strategies, frequently
surpassing traditional models. However, for unstructured medical texts, LLMs
did not outperform finetuned BERT models, which excelled in both supervised and
unsupervised tasks. Consequently, while LLMs are effective for zero-shot
learning on structured data, finetuned BERT models are more suitable for
unstructured texts, underscoring the importance of selecting models based on
specific task requirements and data characteristics to optimize the application
of NLP technology in healthcare.

摘要：大型語言模型 (LLM) 在醫學中的應用日益廣泛，但它們同時處理結構化電子病歷 (EHR) 資料和非結構化臨床註記的能力尚未得到充分研究。本研究針對各種模型進行基準測試，包括基於 GPT 的 LLM、基於 BERT 的模型，以及傳統的臨床預測模型，用於利用著名資料集的非生成性醫療任務。我們使用 MIMIC 資料集（ICU 病人記錄）和 TJH 資料集（早期 COVID-19 EHR 資料）評估了 14 個語言模型（9 個基於 GPT，5 個基於 BERT）和 7 個傳統預測模型，重點關注死亡率和再入院預測、疾病層級重建和生物醫學句子配對等任務，並比較了零次學習和微調後的效能。結果表明，LLM 在使用設計良好的提示策略時，對結構化 EHR 資料展現出強大的零次學習預測能力，經常超越傳統模型。然而，對於非結構化的醫療文本，LLM 的表現不如微調後的 BERT 模型，後者在監督式和非監督式任務中都表現出色。因此，儘管 LLM 對於結構化資料的零次學習很有用，但微調後的 BERT 模型更適合非結構化文本，這強調了根據特定任務需求和資料特性選擇模型以優化醫療保健中 NLP 技術應用之重要性。

##### **A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**
2407.18483v4 by Laiyi Fu, Binbin Fan, Hongkai Du, Yanxiang Feng, Chunhua Li, Huping Song

Ophthalmology consultations are crucial for diagnosing, treating, and
preventing eye diseases. However, the growing demand for consultations exceeds
the availability of ophthalmologists. By leveraging large pre-trained language
models, we can design effective dialogues for specific scenarios, aiding in
consultations. Traditional fine-tuning strategies for question-answering tasks
are impractical due to increasing model size and often ignoring patient-doctor
role function during consultations. In this paper, we propose EyeDoctor, an
ophthalmic medical questioning large language model that enhances accuracy
through doctor-patient role perception guided and an augmented knowledge base
with external disease information. Experimental results show EyeDoctor achieves
higher question-answering precision in ophthalmology consultations. Notably,
EyeDoctor demonstrated a 7.25% improvement in Rouge-1 scores and a 10.16%
improvement in F1 scores on multi-round datasets compared to second best model
ChatGPT, highlighting the importance of doctor-patient role differentiation and
dynamic knowledge base expansion for intelligent medical consultations. EyeDoc
also serves as a free available web based service and souce code is available
at https://github.com/sperfu/EyeDoc.

摘要：眼科諮詢對於診斷、治療和預防眼疾至關重要。然而，諮詢需求的增加超過了眼科醫生的供應。透過利用大型預訓練語言模型，我們可以為特定場景設計有效的對話，協助諮詢。傳統的微調策略對於問答任務來說是不切實際的，因為模型大小的增加，而且在諮詢期間常常忽略患者和醫生的角色功能。在本文中，我們提出 EyeDoctor，這是一個眼科醫療問答大型語言模型，透過醫生和患者角色感知指導和一個擴充的外部疾病資訊知識庫來增強準確性。實驗結果顯示，EyeDoctor 在眼科諮詢中達到了更高的問答準確度。值得注意的是，與第二好的模型 ChatGPT 相比，EyeDoctor 在多輪數據集上 Rouge-1 分數提高了 7.25%，F1 分數提高了 10.16%，這突顯了醫生和患者角色區分和動態知識庫擴充對於智能醫療諮詢的重要性。EyeDoc 也作為一個免費的網路服務，原始碼可以在 https://github.com/sperfu/EyeDoc 取得。

##### **Towards Automated Solution Recipe Generation for Industrial Asset Management with LLM**
2407.18992v1 by Nianjun Zhou, Dhaval Patel, Shuxin Lin, Fearghal O'Donncha

This study introduces a novel approach to Industrial Asset Management (IAM)
by incorporating Conditional-Based Management (CBM) principles with the latest
advancements in Large Language Models (LLMs). Our research introduces an
automated model-building process, traditionally reliant on intensive
collaboration between data scientists and domain experts. We present two
primary innovations: a taxonomy-guided prompting generation that facilitates
the automatic creation of AI solution recipes and a set of LLM pipelines
designed to produce a solution recipe containing a set of artifacts composed of
documents, sample data, and models for IAM. These pipelines, guided by
standardized principles, enable the generation of initial solution templates
for heterogeneous asset classes without direct human input, reducing reliance
on extensive domain knowledge and enhancing automation. We evaluate our
methodology by assessing asset health and sustainability across a spectrum of
ten asset classes. Our findings illustrate the potential of LLMs and
taxonomy-based LLM prompting pipelines in transforming asset management,
offering a blueprint for subsequent research and development initiatives to be
integrated into a rapid client solution.

摘要：本研究引入了一種創新的工業資產管理 (IAM) 方法，方法是將基於條件的管理 (CBM) 原則與大型語言模型 (LLM) 的最新進展相結合。我們的研究引入了一個自動化模型建構流程，傳統上依賴於數據科學家和領域專家之間的密集合作。我們提出了兩項主要的創新：一種分類引導的提示生成，它促進了 AI 解決方案配方（recipe）的自動創建，以及一組 LLM 管道，旨在產生一個解決方案配方，其中包含一組由文件、範例資料和 IAM 模型組成的成品。這些管道在標準化原則的指導下，能夠為異質資產類別產生初始解決方案範本，無需直接的人工輸入，從而減少對廣泛領域知識的依賴並增強自動化。我們通過評估十個資產類別的資產健康狀況和永續性來評估我們的技術。我們的研究結果說明了 LLM 和基於分類的 LLM 提示管線在轉型資產管理方面的潛力，為後續的研究和開發計畫提供了藍圖，這些計畫將整合到快速客戶解決方案中。

##### **HDL-GPT: High-Quality HDL is All You Need**
2407.18423v1 by Bhuvnesh Kumar, Saurav Nanda, Ganapathy Parthasarathy, Pawan Patil, Austin Tsai, Parivesh Choudhary

This paper presents Hardware Description Language Generative Pre-trained
Transformers (HDL-GPT), a novel approach that leverages the vast repository of
open-source High Definition Language (HDL) codes to train superior quality
large code models. The core premise of this paper is the hypothesis that
high-quality HDL is all you need to create models with exceptional performance
and broad zero-shot generalization abilities. The paper elucidates the methods
employed for the curation and augmentation of large corpora from open-source
HDL code, transforming highly variable quality data into high-quality data
through careful prompting and context maintenance. We demonstrate that the
careful selection, filtering, and augmentation of data across HDLs can yield
powerful models that surpass current state-of-the-art models. We also explore
the impact of different fine-tuning methods on the quality of results. We
describe experimental results across a range of fine-tuned SOTA LLMs,
substantiating our claims. We demonstrate improvements of 50% to 200% over SOTA
HDL models on current benchmarks in tasks ranging from HDL circuit
explanations, code generation, formal and simulation testbench creation,
triaging bugs, and fixing them. HDL-GPT opens new avenues for the development
of advanced model training techniques for circuit design tasks.

摘要：本文提出硬體描述語言生成式預訓練轉換器 (HDL-GPT)，這是一種新方法，利用大量開源高定義語言 (HDL) 程式碼來訓練優質的大型程式碼模型。本文的核心前提是高品質的 HDL 是建立具有卓越效能和廣泛零次學習概化能力模型的唯一要素。本文闡明了從開源 HDL 程式碼策展和擴充大型語料庫所使用的方法，透過仔細提示和脈絡維護，將品質高度變異的資料轉換成高品質資料。我們證明了仔細選擇、篩選和擴充 HDL 中的資料可以產生強大的模型，超越現有的最先進模型。我們也探討了不同微調方法對結果品質的影響。我們描述了針對一系列微調過的 SOTA LLM 的實驗結果，以證實我們的說法。我們證明了在從 HDL 電路說明、程式碼產生、正式和模擬測試平台建立、分類錯誤到修正錯誤等任務的現有基準中，HDL-GPT 比 SOTA HDL 模型進步了 50% 至 200%。HDL-GPT 為電路設計任務的進階模型訓練技術開發開啟了新途徑。

##### **SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**
2407.18387v1 by Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Zahidur Talukder, Syed Bahauddin

Federated Learning (FL) has emerged as a transformative approach for enabling
distributed machine learning while preserving user privacy, yet it faces
challenges like communication inefficiencies and reliance on centralized
infrastructures, leading to increased latency and costs. This paper presents a
novel FL methodology that overcomes these limitations by eliminating the
dependency on edge servers, employing a server-assisted Proximity Evaluation
for dynamic cluster formation based on data similarity, performance indices,
and geographical proximity. Our integrated approach enhances operational
efficiency and scalability through a Hybrid Decentralized Aggregation Protocol,
which merges local model training with peer-to-peer weight exchange and a
centralized final aggregation managed by a dynamically elected driver node,
significantly curtailing global communication overhead. Additionally, the
methodology includes Decentralized Driver Selection, Check-pointing to reduce
network traffic, and a Health Status Verification Mechanism for system
robustness. Validated using the breast cancer dataset, our architecture not
only demonstrates a nearly tenfold reduction in communication overhead but also
shows remarkable improvements in reducing training latency and energy
consumption while maintaining high learning performance, offering a scalable,
efficient, and privacy-preserving solution for the future of federated learning
ecosystems.

摘要：聯邦學習 (FL) 已成為一種變革性方法，用於在保護使用者隱私的同時啟用分散式機器學習，但它面臨著諸如通訊效率低和依賴於集中式基礎設施等挑戰，導致延遲和成本增加。本文提出了一種新穎的 FL 方法，通過消除對邊緣伺服器的依賴，採用伺服器輔助的接近度評估來根據資料相似性、效能指標和地理接近度進行動態叢集形成，從而克服了這些限制。我們的整合方法透過混合式分散式聚合協定來增強運作效率和可擴充性，該協定將本地模型訓練與點對點權重交換以及由動態選出的驅動程式節點管理的集中式最終聚合合併在一起，大幅減少了整體通訊開銷。此外，該方法包括分散式驅動程式選擇、檢查點以減少網路流量，以及用於系統穩健性的健康狀態驗證機制。我們的架構使用乳癌資料集進行驗證，不僅證明通訊開銷減少了近十倍，而且還顯示出在降低訓練延遲和能源消耗的同時，學習效能仍保持很高的顯著改進，為聯邦學習生態系統的未來提供了一個可擴充性、高效且保護隱私的解決方案。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

摘要：在過去幾年中，深度神經網路已廣泛應用於醫療領域的不同任務，從影像分類和分割到地標偵測。然而，這些技術在醫療領域的應用常常受到資料稀少的阻礙，無論是在可用的註解或影像方面。本研究介紹了一個新的自監督預訓練協定，它是基於擴散模型，用於 X 光影像中的地標偵測。我們的結果顯示，所提出的自監督架構可以在最少數量的可用註解訓練影像（最多 50 個）下提供準確的地標偵測，優於 ImageNet 監督式預訓練以及三個熱門 X 光基準資料集的最新自監督式預訓練。據我們所知，這是首次探討擴散模型用於地標偵測中的自監督式學習，它可能在小樣本訓練模式中提供有價值的預訓練方法，以減輕資料稀少的問題。

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

摘要：電腦視覺模型越來越能夠分類卵巢上皮癌的亞型，但它們與病理學家不同，它們以單一解析度處理小組織貼片。多解析度圖形模型利用多個放大倍率下貼片的空間關係，學習每個貼片的背景。在這項研究中，我們對圖形模型進行了迄今為止最徹底的卵巢癌亞型驗證。使用 434 名在利茲教學醫院 NHS 信託基金接受治療的患者的 1864 張全幻燈片影像 (WSI) 進行五倍交叉驗證，調整並訓練了七個模型。將交叉驗證模型集成並使用來自 30 名患者的 100 張 WSI 的平衡留出測試集和來自 Transcanadian 研究中 80 名患者的 80 張 WSI 的外部驗證集進行評估。表現最佳的模型，一個使用 10 倍+20 倍放大倍率資料的圖形模型，在交叉驗證、留出測試和外部驗證中分別給出 73%、88% 和 99% 的平衡準確度。然而，這僅超過了外部驗證中基於注意力的多實例學習的表現，平衡準確度為 93%。圖形模型從使用 UNI 基礎模型而不是 ImageNet 預訓練的 ResNet50 進行特徵提取中受益匪淺，與改變後續分類方法相比，這對效能有更大的影響。結合基礎模型和多解析度圖形網路的準確度為這些模型的臨床應用邁出了一步，對於這項任務來說，這是新的最高報告表現，儘管仍需要進一步的驗證來確保模型的穩健性和可用性。

##### **HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**
2407.17879v2 by Qingyu Guo, Jiayong Wan, Songqiang Xu, Meng Li, Yuan Wang

Vision Transformer (ViT) acceleration with field programmable gate array
(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators
mainly rely on temporal architectures, which process different operators by
reusing the same hardware blocks and suffer from extensive memory access
overhead. Pipelined architectures, either coarse-grained or fine-grained,
unroll the ViT computation spatially for memory access efficiency. However,
they usually suffer from significant hardware resource constraints and pipeline
bubbles induced by the global computation dependency of ViT. In this paper, we
introduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and
low-latency ViT processing. HG-PIPE features a hybrid-grained pipeline
architecture to reduce on-chip buffer cost and couples the computation dataflow
and parallelism design to eliminate the pipeline bubbles. HG-PIPE further
introduces careful approximations to implement both linear and non-linear
operators with abundant Lookup Tables (LUTs), thus alleviating resource
constraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput
and 2.52 times better resource efficiency than the prior-art accelerators,
e.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT
acceleration on a single device and achieves 7118 images/s, which is 2.81 times
faster than a V100 GPU.

摘要：視覺變換器 (ViT) 加速與現場可編程閘陣列 (FPGA) 充滿前景，但具有挑戰性。現有的基於 FPGA 的 ViT 加速器主要依賴於時間架構，它透過重複使用相同的硬體區塊來處理不同的運算子，並承受大量的記憶體存取負擔。無論是粗粒度或細粒度，流水線架構都會在空間上展開 ViT 計算以提高記憶體存取效率。然而，它們通常會受到顯著的硬體資源限制和由 ViT 的全局計算依賴性所引發的流水線氣泡影響。在本文中，我們介紹 HG-PIPE，一種用於高通量和低延遲 ViT 處理的流水線 FPGA 加速器。HG-PIPE 採用混合粒度流水線架構以降低晶片緩衝成本，並結合計算資料流程和並行設計以消除流水線氣泡。HG-PIPE 進一步引入仔細的近似值，以使用豐富的查閱表 (LUT) 實作線性和非線性運算子，從而減輕資源限制。在 ZCU102 FPGA 上，HG-PIPE 的處理量比現有加速器（例如 AutoViTAcc）高出 2.78 倍，資源效率高出 2.52 倍。使用 VCK190 FPGA，HG-PIPE 在單一裝置上實現端到端的 ViT 加速，並實現每秒 7118 張影像，比 V100 GPU 快 2.81 倍。

##### **EEG-SSM: Leveraging State-Space Model for Dementia Detection**
2407.17801v1 by Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin

State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.

摘要：狀態空間模型 (SSM) 因有效處理長資料序列而備受關注，減少將時間序列區隔成較短區間以進行模型訓練和推論的需要。傳統上，SSM 只擷取時間序列資料的時間動態，省略同樣重要的頻譜特徵。本研究提出 EEG-SSM，一種新的基於狀態空間模型的方法，用於使用 EEG 資料進行失智症分類。我們的模型具有兩項主要的創新：EEG-SSM 時間和 EEG-SSM 頻譜組成部分。時間組成部分旨在有效率地處理長度不同的 EEG 序列，而頻譜組成部分透過整合 EEG 訊號的頻域資訊來增強模型。這些組成部分的協同作用讓 EEG-SSM 能靈活地管理多變量 EEG 資料的複雜性，大幅改善不同時間解析度下的準確性和穩定性。EEG-SSM 在分類健康對照組 (HC)、額顳葉型失智症 (FTD) 和阿茲海默症 (AD) 組別時展現出驚人的 91.0% 準確度，在相同的資料集上優於現有模型。EEG-SSM 的開發代表了使用狀態空間模型進行失智症篩檢的進步，為臨床神經科學提供更精確且更具成本效益的工具。

##### **Closing the gap between open-source and commercial large language models for medical evidence summarization**
2408.00588v1 by Gongbo Zhang, Qiao Jin, Yiliang Zhou, Song Wang, Betina R. Idnay, Yiming Luo, Elizabeth Park, Jordan G. Nestor, Matthew E. Spotnitz, Ali Soroush, Thomas Campion, Zhiyong Lu, Chunhua Weng, Yifan Peng

Large language models (LLMs) hold great promise in summarizing medical
evidence. Most recent studies focus on the application of proprietary LLMs.
Using proprietary LLMs introduces multiple risk factors, including a lack of
transparency and vendor dependency. While open-source LLMs allow better
transparency and customization, their performance falls short compared to
proprietary ones. In this study, we investigated to what extent fine-tuning
open-source LLMs can further improve their performance in summarizing medical
evidence. Utilizing a benchmark dataset, MedReview, consisting of 8,161 pairs
of systematic reviews and summaries, we fine-tuned three broadly-used,
open-sourced LLMs, namely PRIMERA, LongT5, and Llama-2. Overall, the fine-tuned
LLMs obtained an increase of 9.89 in ROUGE-L (95% confidence interval:
8.94-10.81), 13.21 in METEOR score (95% confidence interval: 12.05-14.37), and
15.82 in CHRF score (95% confidence interval: 13.89-16.44). The performance of
fine-tuned LongT5 is close to GPT-3.5 with zero-shot settings. Furthermore,
smaller fine-tuned models sometimes even demonstrated superior performance
compared to larger zero-shot models. The above trends of improvement were also
manifested in both human and GPT4-simulated evaluations. Our results can be
applied to guide model selection for tasks demanding particular domain
knowledge, such as medical evidence summarization.

摘要：大型语言模型 (LLM) 在总结医学证据方面具有很大的前景。最近的研究主要集中在专有 LLM 的应用上。使用专有 LLM 会引入多个风险因素，包括缺乏透明度和供应商依赖性。虽然开源 LLM 允许更好的透明度和定制，但它们的性能与专有 LLM 相比还有所不足。在这项研究中，我们调查了微调开源 LLM 在多大程度上可以进一步提高其在总结医学证据方面的性能。利用基准数据集 MedReview，其中包含 8,161 对系统评价和摘要，我们微调了三个广泛使用的开源 LLM，即 PRIMERA、LongT5 和 Llama-2。总体而言，经过微调的 LLM 在 ROUGE-L 中增加了 9.89（95% 置信区间：8.94-10.81），在 METEOR 分数中增加了 13.21（95% 置信区间：12.05-14.37），在 CHRF 分数中增加了 15.82（95% 置信区间：13.89-16.44）。经过微调的 LongT5 的性能接近于零镜头设置下的 GPT-3.5。此外，较小的微调模型有时甚至表现出优于较大的零镜头模型的性能。上述改进趋势也体现在人类和 GPT4 模拟评估中。我们的结果可用于指导模型选择，以完成需要特定领域知识的任务，例如医学证据总结。

##### **Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**
2407.17762v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Prarththanan Sothyrajah, Thanveer Ahamed, Dinuka Wijesundara

Rapid development of disease detection models using computer vision is
crucial in responding to medical emergencies, such as epidemics or bioterrorism
events. Traditional data collection methods are often too slow in these
scenarios, requiring innovative approaches for quick, reliable model generation
from minimal data. Our study introduces a novel approach by constructing a
comprehensive computer vision model to detect Mpox lesions using only synthetic
data. Initially, these models generated a diverse set of synthetic images
representing Mpox lesions on various body parts (face, back, chest, leg, neck,
arm) across different skin tones as defined by the Fitzpatrick scale (fair,
brown, dark skin). Subsequently, we trained and tested a vision model with this
synthetic dataset to evaluate the diffusion models' efficacy in producing
high-quality training data and its impact on the vision model's medical image
recognition performance. The results were promising; the vision model achieved
a 97% accuracy rate, with 96% precision and recall for Mpox cases, and
similarly high metrics for normal and other skin disorder cases, demonstrating
its ability to correctly identify true positives and minimize false positives.
The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and
other skin disorders, reflecting a balanced precision-recall relationship, thus
ensuring reliability and robustness in its predictions. Our proposed
SynthVision methodology indicates the potential to develop accurate computer
vision models with minimal data input for future medical emergencies.

摘要：<paragraph>利用電腦視覺快速開發疾病檢測模型對於因應醫療緊急事件（例如流行病或生物恐怖主義事件）至關重要。傳統的資料收集方法在這些情況下通常太慢，需要創新的方法才能從最少資料中快速、可靠地產生模型。我們的研究介紹了一種新穎的方法，透過建構一個全面的電腦視覺模型，僅使用合成資料來檢測猴痘病灶。最初，這些模型產生了一組多樣化的合成影像，代表了不同膚色（根據 Fitzpatrick 量表定義為白皙、棕色、深色皮膚）上不同身體部位（臉部、背部、胸部、腿部、頸部、手臂）的猴痘病灶。隨後，我們使用這個合成資料集訓練和測試一個視覺模型，以評估擴散模型產生高品質訓練資料的效能，以及其對視覺模型醫學影像辨識效能的影響。結果令人滿意；視覺模型達到了 97% 的準確率，猴痘病例的準確度和召回率為 96%，正常和其它皮膚疾病病例的指標也同樣高，證明了它正確辨識真陽性並將假陽性降至最低的能力。該模型在猴痘病例中達到了 96% 的 F1 分數，在正常和其它皮膚疾病中達到了 98%，反映出平衡的準確度召回率關係，從而確保其預測的可靠性和穩健性。我們提出的 SynthVision 方法表明，有可能為未來的醫療緊急事件開發出準確的電腦視覺模型，且資料輸入量最少。</paragraph>

##### **Cost-effective Instruction Learning for Pathology Vision and Language Analysis**
2407.17734v1 by Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang

The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.

摘要：視覺語言模型的出現促進了 AI 啟用模型與人類之間的互動對話。然而，將這些模型應用於臨床必須應對大規模訓練數據、財務和計算資源等嚴峻挑戰。在此，我們提出了一個名為 CLOVER 的經濟高效的會話病理學指令學習架構。CLOVER 僅訓練一個輕量級模組，並在凍結大型語言模型參數的同時使用指令微調。我們沒有使用昂貴的 GPT-4，而是針對 GPT-3.5 提出設計良好的提示，以建立基於生成的指令，強調從網際網路來源衍生的病理知識的效用。為了擴展指令的使用，我們在數位病理學的背景下構建了一組高品質的基於範本的指令。從兩個基準資料集，我們的研究結果揭示了混合形式指令在病理學視覺問答中的優勢。廣泛的結果顯示了 CLOVER 在回答開放式和封閉式問題方面的經濟效益，其中 CLOVER 優於擁有多 37 倍訓練參數並使用從 GPT-4 生成的指令資料的強大基準。透過指令微調，CLOVER 在外部臨床資料集中展現了小樣本學習的穩健性。這些發現證明了 CLOVER 的經濟高效建模可以加速在數位病理領域採用快速對話式應用程式。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Improving ICD coding using Chapter based Named Entities and Attentional Models**
2407.17230v1 by Abhijith R. Beeravolu, Mirjam Jonkman, Sami Azam, Friso De Boer

Recent advancements in natural language processing (NLP) have led to
automation in various domains. However, clinical NLP often relies on benchmark
datasets that may not reflect real-world scenarios accurately. Automatic ICD
coding, a vital NLP task, typically uses outdated and imbalanced datasets like
MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4
and 0.7 due to many false positives. Our research introduces an enhanced
approach to ICD coding that improves F1 scores by using chapter-based named
entities and attentional models. This method categorizes discharge summaries
into ICD-9 Chapters and develops attentional models with chapter-specific data,
eliminating the need to consider external data for code identification. For
categorization, we use Chapter-IV to de-bias and influence key entities and
weights without neural networks, creating accurate thresholds and providing
interpretability for human validation. Post-validation, we develop attentional
models for three frequent and three non-frequent codes from Chapter-IV using
Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with
Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and
0.81 from these models demonstrate significant performance improvements in ICD
coding.

摘要：自然語言處理 (NLP) 的最新進展已導致各種領域的自動化。然而，臨床 NLP 通常依賴於基準資料集，這些資料集可能無法準確反映真實世界的場景。自動 ICD 編碼是一項重要的 NLP 任務，通常使用過時且不平衡的資料集，例如 MIMIC-III，由於許多假陽性，現有方法產生的微平均 F1 分數介於 0.4 和 0.7 之間。我們的研究引入了一種增強的 ICD 編碼方法，通過使用基於章節的命名實體和注意力模型來提高 F1 分數。此方法將出院摘要分類為 ICD-9 章節，並使用章節特定資料開發注意力模型，消除了考慮外部資料以進行代碼識別的需要。對於分類，我們使用 Chapter-IV 來消除偏差並影響關鍵實體和權重，而無需神經網路，從而建立準確的閾值並提供人類驗證的可解釋性。在驗證之後，我們使用帶有注意力和多頭注意架構的雙向門控遞迴單元 (GRU) 和 Transformer，為 Chapter-IV 中的三個頻繁和三個非頻繁代碼開發注意力模型。這些模型的平均微 F1 分數為 0.79 和 0.81，表明 ICD 編碼的效能有了顯著的提升。

##### **Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**
2407.17164v2 by Xiaoyu Tan, Bin Li, Xihe Qiu, Jingjing Huang, Yinghui Xu, Wei Chu

Integrating deep neural networks with the Hawkes process has significantly
improved predictive capabilities in finance, health informatics, and
information technology. Nevertheless, these models often face challenges in
real-world settings, particularly due to substantial label noise. This issue is
of significant concern in the medical field, where label noise can arise from
delayed updates in electronic medical records or misdiagnoses, leading to
increased prediction risks. Our research indicates that deep Hawkes process
models exhibit reduced robustness when dealing with label noise, particularly
when it affects both event types and timing. To address these challenges, we
first investigate the influence of label noise in approximated intensity
functions and present a novel framework, the Robust Deep Hawkes Process (RDHP),
to overcome the impact of label noise on the intensity function of Hawkes
models, considering both the events and their occurrences. We tested RDHP using
multiple open-source benchmarks with synthetic noise and conducted a case study
on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting
with inherent label noise. The results demonstrate that RDHP can effectively
perform classification and regression tasks, even in the presence of noise
related to events and their timing. To the best of our knowledge, this is the
first study to successfully address both event and time label noise in deep
Hawkes process models, offering a promising solution for medical applications,
specifically in diagnosing OSAHS.

摘要：將深度神經網路與霍克斯過程整合，已顯著提升金融、健康資訊學和資訊科技的預測能力。儘管如此，這些模型在現實世界中經常面臨挑戰，特別是因為標籤雜訊很大。這個問題在醫學領域中特別令人擔憂，因為標籤雜訊可能來自電子病歷的延遲更新或誤診，導致預測風險增加。我們的研究表明，處理標籤雜訊時，深度霍克斯過程模型的穩健性會降低，特別是當它影響事件類型和時間點時。為了應對這些挑戰，我們首先研究標籤雜訊對近似強度函數的影響，並提出一個新的架構，即穩健深度霍克斯過程 (RDHP)，以克服標籤雜訊對霍克斯模型強度函數的影響，同時考慮事件及其發生。我們使用多個帶有合成雜訊的開源基準測試 RDHP，並在現實世界中對阻塞性睡眠呼吸中止低通氣症候群 (OSAHS) 進行案例研究，其中存在固有的標籤雜訊。結果表明，即使在與事件及其時間點相關的雜訊存在的情況下，RDHP 仍能有效執行分類和回歸任務。據我們所知，這是第一個成功解決深度霍克斯過程模型中事件和時間標籤雜訊的研究，為醫療應用（特別是在診斷 OSAHS 時）提供了一個有希望的解決方案。

##### **SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**
2407.17126v1 by Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding

Extracting social determinants of health (SDoH) from unstructured medical
notes depends heavily on labor-intensive annotations, which are typically
task-specific, hampering reusability and limiting sharing. In this study we
introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)
method leveraging contrastive examples and concise instructions to extract SDoH
without relying on extensive medical annotations or costly human intervention.
It achieved tenfold and twentyfold reductions in time and cost respectively,
and superior consistency with human annotators measured by Cohen's kappa of up
to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the
strengths of both, ensuring high accuracy and computational efficiency while
consistently maintaining 0.90+ AUROC scores. Testing across three distinct
datasets has confirmed its robustness and accuracy. This study highlights the
potential of leveraging LLMs to revolutionize medical note classification,
demonstrating their capability to achieve highly accurate classifications with
significantly reduced time and cost.

摘要：從非結構化的醫療筆記中萃取健康的社會決定因素 (SDoH) 仰賴大量的人工標註，而這些標註通常是針對特定任務，這會阻礙可重複使用性並限制分享。在這項研究中，我們引入了 SDoH-GPT，一種簡單且有效的方法，它利用對比範例和簡潔的指示來萃取 SDoH，而不需要仰賴大量的醫療標註或昂貴的人工介入。它分別在時間和成本上達到了十倍和二十倍的降低，並且與人類標註者的優異一致性，由 Cohen's kappa 測量高達 0.92。SDoH-GPT 和 XGBoost 的創新結合利用了兩者的優點，確保了高準確度和運算效率，同時始終維持 0.90+ 的 AUROC 分數。在三個不同的資料集上進行測試已經確認了它的穩健性和準確性。這項研究突顯了利用 LLM 來革新醫療筆記分類的潛力，展示了它們在顯著減少時間和成本的情況下實現高度準確分類的能力。

##### **SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**
2407.16999v1 by Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis
onset prediction and diagnosis could significantly improve the survival of
sepsis patients. Existing predictive models are usually trained on high-quality
data with few missing information, while missing values widely exist in
real-world clinical scenarios (especially in the first hours of admissions to
the hospital), which causes a significant decrease in accuracy and an increase
in uncertainty for the predictive models. The common method to handle missing
values is imputation, which replaces the unavailable variables with estimates
from the observed data. The uncertainty of imputation results can be propagated
to the sepsis prediction outputs, which have not been studied in existing works
on either sepsis prediction or uncertainty quantification. In this study, we
first define such propagated uncertainty as the variance of prediction output
and then introduce uncertainty propagation methods to quantify the propagated
uncertainty. Moreover, for the potential high-risk patients with low confidence
due to limited observations, we propose a robust active sensing algorithm to
increase confidence by actively recommending clinicians to observe the most
informative variables. We validate the proposed models in both publicly
available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The
Ohio State University Wexner Medical Center (OSUWMC). The experimental results
show that the propagated uncertainty is dominant at the beginning of admissions
to hospitals and the proposed algorithm outperforms state-of-the-art active
sensing methods. Finally, we implement a SepsisLab system for early sepsis
prediction and active sensing based on our pre-trained models. Clinicians and
potential sepsis patients can benefit from the system in early prediction and
diagnosis of sepsis.

摘要：敗血症是美國醫院中死亡的主要原因。敗血症的早期發作預測和診斷可以顯著提高敗血症患者的存活率。現有的預測模型通常在資料品質高且遺失資訊較少的情況下進行訓練，而遺失值在實際臨床情境中普遍存在（尤其是在入院的前幾個小時），這會導致預測模型的準確度顯著下降，並增加不確定性。處理遺失值的常見方法是內插，它使用從觀測資料中估計的數值取代不可用的變數。內插結果的不確定性可能會傳播到敗血症預測輸出，這在現有的敗血症預測或不確定性量化研究中尚未被探討。在這項研究中，我們首先將這種傳播的不確定性定義為預測輸出的變異，然後引入不確定性傳播方法來量化傳播的不確定性。此外，對於由於觀察有限而導致信心較低的潛在高風險患者，我們提出了一種強大的主動感測演算法，透過主動建議臨床醫生觀察最有資訊性的變數來增加信心。我們在公開資料（例如 MIMIC-III 和 AmsterdamUMCdb）和俄亥俄州立大學韋克斯納醫學中心 (OSUWMC) 的專有資料中驗證了所提出的模型。實驗結果表明，傳播的不確定性在入院初期佔主導地位，而所提出的演算法優於最先進的主動感測方法。最後，我們根據預先訓練的模型實作了一個敗血症實驗室系統，用於早期敗血症預測和主動感測。臨床醫生和潛在的敗血症患者可以在敗血症的早期預測和診斷中受益於該系統。

##### **Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**
2407.16962v1 by Nur Ahmad Khatim, Ahmad Azmul Asmar Irfan, Amaliya Mata'ul Hayah, Mansur M. Arief

This study addresses the challenge of stroke diagnosis and treatment under
uncertainty, a critical issue given the rapid progression and severe
consequences of stroke conditions such as aneurysms, arteriovenous
malformations (AVM), and occlusions. Current diagnostic methods, including
Digital Subtraction Angiography (DSA), face limitations due to high costs and
its invasive nature. To overcome these challenges, we propose a novel approach
using a Partially Observable Markov Decision Process (POMDP) framework. Our
model integrates advanced diagnostic tools and treatment approaches with a
decision-making algorithm that accounts for the inherent uncertainties in
stroke diagnosis. Our approach combines noisy observations from CT scans,
Siriraj scores, and DSA reports to inform the subsequent treatment options. We
utilize the online solver DESPOT, which employs tree-search methods and
particle filters, to simulate potential future scenarios and guide our
strategies. The results indicate that our POMDP framework balances diagnostic
and treatment objectives, striking a tradeoff between the need for precise
stroke identification via invasive procedures like DSA and the constraints of
limited healthcare resources that necessitate more cost-effective strategies,
such as in-hospital or at-home observation, by relying only relying on
simulation rollouts and not imposing any prior knowledge. Our study offers a
significant contribution by presenting a systematic framework that optimally
integrates diagnostic and treatment processes for stroke and accounting for
various uncertainties, thereby improving care and outcomes in stroke
management.

摘要：本研究探討在不確定性下中風的診斷和治療的挑戰，這是考量到中風狀況（例如動脈瘤、動靜脈畸形 (AVM) 和阻塞）的快速進展和嚴重後果而出現的關鍵問題。目前的診斷方法（包括數位減影血管攝影 (DSA)）由於成本高昂和侵入性而面臨限制。為了克服這些挑戰，我們提出了一種使用部分可觀察馬可夫決策過程 (POMDP) 架構的新穎方法。我們的模型整合了先進的診斷工具和治療方法，以及一個決策演算法，該演算法考量了中風診斷中固有的不確定性。我們的做法結合了來自電腦斷層掃描、Siriraj 評分和 DSA 報告的雜訊觀測值，以告知後續的治療選項。我們利用線上求解器 DESPOT，它採用樹狀搜尋方法和粒子濾波器，模擬潛在的未來情境並指導我們的策略。結果表明，我們的 POMDP 架構平衡了診斷和治療目標，在透過 DSA 等侵入性程序精確識別中風的需求與需要更具成本效益的策略（例如住院或居家觀察）的醫療資源限制之間取得平衡，僅依賴模擬推出且不施加任何先驗知識。我們的研究透過提出一個系統性架構，最佳化整合中風的診斷和治療過程並考量各種不確定性，從而改善中風管理的照護和結果，做出了重大貢獻。

##### **AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**
2407.16822v1 by Yuheng Wang, Tianze Yu, Jiayue Cai, Sunil Kalia, Harvey Lui, Z. Jane Wang, Tim K. Lee

The 7-point checklist (7PCL) is widely used in dermoscopy to identify
malignant melanoma lesions needing urgent medical attention. It assigns point
values to seven attributes: major attributes are worth two points each, and
minor ones are worth one point each. A total score of three or higher prompts
further evaluation, often including a biopsy. However, a significant limitation
of current methods is the uniform weighting of attributes, which leads to
imprecision and neglects their interconnections. Previous deep learning studies
have treated the prediction of each attribute with the same importance as
predicting melanoma, which fails to recognize the clinical significance of the
attributes for melanoma. To address these limitations, we introduce a novel
diagnostic method that integrates two innovative elements: a Clinical
Knowledge-Based Topological Graph (CKTG) and a Gradient Diagnostic Strategy
with Data-Driven Weighting Standards (GD-DDW). The CKTG integrates 7PCL
attributes with diagnostic information, revealing both internal and external
associations. By employing adaptive receptive domains and weighted edges, we
establish connections among melanoma's relevant features. Concurrently, GD-DDW
emulates dermatologists' diagnostic processes, who first observe the visual
characteristics associated with melanoma and then make predictions. Our model
uses two imaging modalities for the same lesion, ensuring comprehensive feature
acquisition. Our method shows outstanding performance in predicting malignant
melanoma and its features, achieving an average AUC value of 85%. This was
validated on the EDRA dataset, the largest publicly available dataset for the
7-point checklist algorithm. Specifically, the integrated weighting system can
provide clinicians with valuable data-driven benchmarks for their evaluations.

摘要：7 點檢查表 (7PCL) 廣泛用於皮膚鏡檢查，以識別需要緊急醫療照護的惡性黑色素瘤病灶。它為七個屬性分配分數：主要屬性各值兩分，次要屬性各值一分。總分為三或以上表示需要進一步評估，通常包括活檢。然而，目前方法的一個重大限制是屬性的統一加權，導致不精確且忽略它們之間的相互關聯。先前的深度學習研究將每個屬性的預測視為與預測黑色素瘤同等重要，這未能認識到屬性對黑色素瘤的臨床意義。為了解決這些限制，我們引入一種新的診斷方法，結合了兩個創新元素：基於臨床知識的拓撲圖 (CKTG) 和具有數據驅動加權標準的梯度診斷策略 (GD-DDW)。CKTG 將 7PCL 屬性與診斷信息整合在一起，揭示了內部和外部關聯。通過採用自適應感受域和加權邊緣，我們建立了黑色素瘤相關特徵之間的聯繫。同時，GD-DDW 模仿皮膚科醫生的診斷過程，他們首先觀察與黑色素瘤相關的視覺特徵，然後做出預測。我們的模型對同一個病灶使用兩種成像方式，確保全面獲取特徵。我們的這種方法在預測惡性黑色素瘤及其特徵方面表現出色，平均 AUC 值達到 85%。這已在 EDRA 數據集上得到驗證，該數據集是 7 點檢查表算法最大的公開可用數據集。具體來說，集成的加權系統可以為臨床醫生提供有價值的數據驅動基準，供他們評估。

##### **Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges**
2407.16804v1 by Zahraa Al Sahili, Ioannis Patras, Matthew Purver

The application of machine learning (ML) in detecting, diagnosing, and
treating mental health disorders is garnering increasing attention.
Traditionally, research has focused on single modalities, such as text from
clinical notes, audio from speech samples, or video of interaction patterns.
Recently, multimodal ML, which combines information from multiple modalities,
has demonstrated significant promise in offering novel insights into human
behavior patterns and recognizing mental health symptoms and risk factors.
Despite its potential, multimodal ML in mental health remains an emerging
field, facing several complex challenges before practical applications can be
effectively developed. This survey provides a comprehensive overview of the
data availability and current state-of-the-art multimodal ML applications for
mental health. It discusses key challenges that must be addressed to advance
the field. The insights from this survey aim to deepen the understanding of the
potential and limitations of multimodal ML in mental health, guiding future
research and development in this evolving domain.

摘要：機器學習（ML）在偵測、診斷和治療心理健康疾病中的應用正越來越受到重視。傳統上，研究著重於單一模式，例如臨床筆記中的文字、語音樣本中的音訊或互動模式的影片。最近，結合多模式資訊的多模態 ML 已展現出顯著的潛力，可提供對人類行為模式的新見解，並識別心理健康症狀和風險因子。儘管具有潛力，心理健康中的多模態 ML 仍是一個新興領域，在實際應用可以有效開發之前，面臨數項複雜挑戰。本調查提供了心理健康中資料可用性和當前最先進的多模態 ML 應用之全面概觀。它討論了必須解決的關鍵挑戰，以推動該領域的進步。本調查的見解旨在加深對多模態 ML 在心理健康中的潛力和限制的理解，引導這個不斷演變領域未來的研究和發展。

##### **Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**
2407.16608v1 by Daniela L. Ramos, Hector J. Hortua

Colorectal polyps are generally benign alterations that, if not identified
promptly and managed successfully, can progress to cancer and cause
affectations on the colon mucosa, known as adenocarcinoma. Today advances in
Deep Learning have demonstrated the ability to achieve significant performance
in image classification and detection in medical diagnosis applications.
Nevertheless, these models are prone to overfitting, and making decisions based
only on point estimations may provide incorrect predictions. Thus, to obtain a
more informed decision, we must consider point estimations along with their
reliable uncertainty quantification. In this paper, we built different Bayesian
neural network approaches based on the flexibility of posterior distribution to
develop semantic segmentation of colorectal polyp images. We found that these
models not only provide state-of-the-art performance on the segmentation of
this medical dataset but also, yield accurate uncertainty estimates. We applied
multiplicative normalized flows(MNF) and reparameterization trick on the UNET,
FPN, and LINKNET architectures tested with multiple backbones in deterministic
and Bayesian versions. We report that the FPN + EfficientnetB7 architecture
with MNF is the most promising option given its IOU of 0.94 and Expected
Calibration Error (ECE) of 0.004, combined with its superiority in identifying
difficult-to-detect colorectal polyps, which is effective in clinical areas
where early detection prevents the development of colon cancer.

摘要：大腸息肉通常是良性病變，如果不及時發現並成功處理，可能會演變成癌症並導致大腸粘膜受累，即腺癌。如今，深度學習的進展已證明有能力在醫療診斷應用中實現圖像分類和檢測的顯著性能。儘管如此，這些模型容易過度擬合，並且僅基於點估計做出決策可能會提供不正確的預測。因此，為了獲得更明智的決策，我們必須考慮點估計及其可靠的不確定性量化。在本文中，我們基於後驗分佈的靈活性構建了不同的貝葉斯神經網絡方法，以開發大腸息肉圖像的語義分割。我們發現這些模型不僅在這個醫療數據集的分割上提供了最先進的性能，而且還產生了準確的不確定性估計。我們在確定性和貝葉斯版本中使用多個主幹測試的 UNET、FPN 和 LINKNET 架構上應用乘法歸一化流 (MNF) 和重新參數化技巧。我們報告說，具有 MNF 的 FPN + EfficientnetB7 架構是最有希望的選擇，因為它的 IOU 為 0.94，預期的校準誤差 (ECE) 為 0.004，並且在識別難以檢測的大腸息肉方面具有優越性，這在早期檢測可以防止結腸癌發展的臨床領域是有效的。

##### **A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**
2407.16593v1 by Giorgos Lysandrou, Roma English Owen, Vanja Popovic, Grant Le Brun, Aryo Pradipta Gema, Beatrice Alex, Elizabeth A. L. Fairley

There exists an invisible barrier between healthcare professionals'
perception of a patient's clinical experience and the reality. This barrier may
be induced by the environment that hinders patients from sharing their
experiences openly with healthcare professionals. As patients are observed to
discuss and exchange knowledge more candidly on social media, valuable insights
can be leveraged from these platforms. However, the abundance of non-patient
posts on social media necessitates filtering out such irrelevant content to
distinguish the genuine voices of patients, a task we refer to as patient voice
classification. In this study, we analyse the importance of linguistic
characteristics in accurately classifying patient voices. Our findings
underscore the essential role of linguistic and statistical text similarity
analysis in identifying common patterns among patient groups. These results
allude to even starker differences in the way patients express themselves at a
disease level and across various therapeutic domains. Additionally, we
fine-tuned a pre-trained Language Model on the combined datasets with similar
linguistic patterns, resulting in a highly accurate automatic patient voice
classification. Being the pioneering study on the topic, our focus on
extracting authentic patient experiences from social media stands as a crucial
step towards advancing healthcare standards and fostering a patient-centric
approach.

摘要：醫療保健專業人員對於患者臨床經驗的認知與實際情況之間存在著一道無形的障礙。此障礙可能是由環境所造成，阻礙患者與醫療保健專業人員公開分享他們的經驗。由於觀察到患者在社群媒體上更坦率地討論和交換知識，因此可以從這些平台獲得有價值的見解。然而，社群媒體上充斥著非患者貼文，因此有必要過濾掉這些不相關的內容，以區分患者的真實聲音，我們將此任務稱為患者聲音分類。在本研究中，我們分析了語言特徵在準確分類患者聲音中的重要性。我們的研究結果強調了語言和統計文字相似性分析在識別患者群組之間共同模式中的重要角色。這些結果暗示了患者在疾病層級和各種治療領域中表達自己的方式存在著更明顯的差異。此外，我們根據具有類似語言模式的合併資料集微調了預先訓練好的語言模型，進而產生高度準確的自動患者聲音分類。作為這項主題的開創性研究，我們專注於從社群媒體中提取真實的患者經驗，這是邁向提升醫療保健標準和培養以患者為中心的途徑的關鍵一步。

##### **Prompt Injection Attacks on Large Language Models in Oncology**
2407.18981v1 by Jan Clusmann, Dyke Ferber, Isabella C. Wiest, Carolin V. Schneider, Titus J. Brinker, Sebastian Foersch, Daniel Truhn, Jakob N. Kather

Vision-language artificial intelligence models (VLMs) possess medical
knowledge and can be employed in healthcare in numerous ways, including as
image interpreters, virtual scribes, and general decision support systems.
However, here, we demonstrate that current VLMs applied to medical tasks
exhibit a fundamental security flaw: they can be attacked by prompt injection
attacks, which can be used to output harmful information just by interacting
with the VLM, without any access to its parameters. We performed a quantitative
study to evaluate the vulnerabilities to these attacks in four state of the art
VLMs which have been proposed to be of utility in healthcare: Claude 3 Opus,
Claude 3.5 Sonnet, Reka Core, and GPT-4o. Using a set of N=297 attacks, we show
that all of these models are susceptible. Specifically, we show that embedding
sub-visual prompts in medical imaging data can cause the model to provide
harmful output, and that these prompts are non-obvious to human observers.
Thus, our study demonstrates a key vulnerability in medical VLMs which should
be mitigated before widespread clinical adoption.

摘要：視覺語言人工智能模型（VLM）具備醫療知識，可用於醫療保健的許多方面，包括影像解讀、虛擬書寫員和一般決策支援系統。不過，我們在此證明應用於醫療任務的現行 VLM 有一個根本性的安全漏洞：它們會受到提示注入攻擊，而這種攻擊只要與 VLM 互動，就能用於輸出有害資訊，而無須存取其參數。我們執行了一項量化研究，以評估四個最先進的 VLM 對這些攻擊的脆弱性，這些 VLM 已被提議用於醫療保健：Claude 3 Opus、Claude 3.5 Sonnet、Reka Core 和 GPT-4o。我們使用一組 N=297 攻擊，顯示所有這些模型都容易受到攻擊。具體來說，我們顯示在醫學影像資料中嵌入次視覺提示，會導致模型提供有害輸出，而且這些提示對人類觀察者來說並不顯而易見。因此，我們的研究證明了醫療 VLM 中的一個關鍵漏洞，在廣泛臨床採用之前應加以緩解。

##### **Knowledge Models for Cancer Clinical Practice Guidelines : Construction, Management and Usage in Question Answering**
2407.21053v1 by Pralaypati Ta, Bhumika Gupta, Arihant Jain, Sneha Sree C, Keerthi Ram, Mohanasankar Sivaprakasam

An automated knowledge modeling algorithm for Cancer Clinical Practice
Guidelines (CPGs) extracts the knowledge contained in the CPG documents and
transforms it into a programmatically interactable, easy-to-update structured
model with minimal human intervention. The existing automated algorithms have
minimal scope and cannot handle the varying complexity of the knowledge content
in the CPGs for different cancer types. This work proposes an improved
automated knowledge modeling algorithm to create knowledge models from the
National Comprehensive Cancer Network (NCCN) CPGs in Oncology for different
cancer types. The proposed algorithm has been evaluated with NCCN CPGs for four
different cancer types. We also proposed an algorithm to compare the knowledge
models for different versions of a guideline to discover the specific changes
introduced in the treatment protocol of a new version. We created a
question-answering (Q&A) framework with the guideline knowledge models as the
augmented knowledge base to study our ability to query the knowledge models. We
compiled a set of 32 question-answer pairs derived from two reliable data
sources for the treatment of Non-Small Cell Lung Cancer (NSCLC) to evaluate the
Q&A framework. The framework was evaluated against the question-answer pairs
from one data source, and it can generate the answers with 54.5% accuracy from
the treatment algorithm and 81.8% accuracy from the discussion part of the NCCN
NSCLC guideline knowledge model.

摘要：一種用於癌症臨床實務指南 (CPG) 的自動化知識建模演算法，會從 CPG 文件中萃取知識，並將其轉換成一個可程式化互動、易於更新的結構化模型，且只需極少的人為介入。現有的自動化演算法範圍很小，無法處理不同癌症類型 CPG 中知識內容的複雜性變化。本研究提出了一種改良的自動化知識建模演算法，以從國家綜合癌症網路 (NCCN) 腫瘤學 CPG 中建立不同癌症類型的知識模型。已使用四種不同癌症類型的 NCCN CPG 評估所提出的演算法。我們也提出了一種演算法，用於比較指南不同版本的知識模型，以找出新版本治療協定中導入的特定變更。我們建立了一個問答 (Q&A) 架構，其中指南知識模型作為擴充的知識庫，以研究我們查詢知識模型的能力。我們編譯了一組 32 個問題解答對，這些對應關係來自兩個可靠的資料來源，用於治療非小細胞肺癌 (NSCLC)，以評估 Q&A 架構。該架構根據來自一個資料來源的問題解答對進行評估，它可以從治療演算法產生 54.5% 精確度的答案，並從 NCCN NSCLC 指南知識模型的討論部分產生 81.8% 精確度的答案。

##### **Virtue Ethics For Ethically Tunable Robotic Assistants**
2407.16361v1 by Rajitha Ramanayake, Vivek Nallur

The common consensus is that robots designed to work alongside or serve
humans must adhere to the ethical standards of their operational environment.
To achieve this, several methods based on established ethical theories have
been suggested. Nonetheless, numerous empirical studies show that the ethical
requirements of the real world are very diverse and can change rapidly from
region to region. This eliminates the idea of a universal robot that can fit
into any ethical context. However, creating customised robots for each
deployment, using existing techniques is challenging. This paper presents a way
to overcome this challenge by introducing a virtue ethics inspired
computational method that enables character-based tuning of robots to
accommodate the specific ethical needs of an environment. Using a simulated
elder-care environment, we illustrate how tuning can be used to change the
behaviour of a robot that interacts with an elderly resident in an
ambient-assisted environment. Further, we assess the robot's responses by
consulting ethicists to identify potential shortcomings.

摘要：一般共識是，設計用於與人類並肩工作或服務人類的機器人必須遵守其運作環境的道德標準。為達成此目的，已提出幾種基於既定倫理理論的方法。儘管如此，許多實證研究顯示，現實世界的道德要求非常多元，且可能因地區而異而快速改變。這消除了通用機器人的概念，而通用機器人可以融入任何道德脈絡。然而，使用現有技術為每個部署建立客製化機器人具有挑戰性。本文提出了一種克服此挑戰的方法，方法是引入一種美德倫理啟發的運算方法，使機器人能夠基於特質進行調整，以適應環境的特定道德需求。使用模擬的長者照護環境，我們說明如何使用調整來改變機器人在環境輔助環境中與年長住民互動的行為。此外，我們諮詢倫理學家來評估機器人的反應，以找出潛在的缺點。

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

摘要：<paragraph>急性中風需要迅速診斷和治療，才能達到最佳的病人治療結果。然而，與急性中風相關的臨床資料複雜且不規則，特別是血壓 (BP) 測量，對有效的視覺分析和決策制定構成重大障礙。透過與經驗豐富的神經科醫師長達一年的合作，我們開發了 PhenoFlow，這是一個視覺分析系統，利用人與大型語言模型 (LLM) 之間的協作來分析急性缺血性中風患者的廣泛且複雜資料。PhenoFlow 開創了一種創新的工作流程，其中 LLM 擔任資料整理員，而神經科醫師則使用視覺化和自然語言互動來探索和監督輸出。這種方法使神經科醫師能夠更專注於決策制定，同時降低認知負擔。為了保護敏感的病人資訊，PhenoFlow 僅利用元資料進行推論並合成可執行程式碼，而不會存取原始病人資料。這確保了結果既可重現又可解釋，同時維護病人的隱私。該系統採用分段和包裝設計，採用時間摺疊來建立疊加的圓形視覺化。結合線性長條圖，此設計有助於探索不規則測量血壓資料中的有意義模式。透過案例研究，PhenoFlow 已證明其支援對廣泛臨床資料集進行反覆分析的能力，降低認知負擔並使神經科醫師能夠做出明智的決策。我們的研究以與領域專家長期合作為基礎，證明了利用 LLM 來應對當前急性缺血性中風患者資料驅動臨床決策制定挑戰的潛力。</paragraph>

##### **Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning**
2407.16715v2 by Yufeng Li, Wenchao Zhao, Bo Dang, Xu Yan, Weimin Wang, Min Gao, Mingxuan Xiao

In clinical treatment, identifying potential adverse reactions of drugs can
help assist doctors in making medication decisions. In response to the problems
in previous studies that features are high-dimensional and sparse, independent
prediction models need to be constructed for each adverse reaction of drugs,
and the prediction accuracy is low, this paper develops an adverse drug
reaction prediction model based on knowledge graph embedding and deep learning,
which can predict experimental results. Unified prediction of adverse drug
reactions covered. Knowledge graph embedding technology can fuse the associated
information between drugs and alleviate the shortcomings of high-dimensional
sparsity in feature matrices, and the efficient training capabilities of deep
learning can improve the prediction accuracy of the model. This article builds
an adverse drug reaction knowledge graph based on drug feature data; by
analyzing the embedding effect of the knowledge graph under different embedding
strategies, the best embedding strategy is selected to obtain sample vectors;
and then a convolutional neural network model is constructed to predict adverse
reactions. The results show that under the DistMult embedding model and
400-dimensional embedding strategy, the convolutional neural network model has
the best prediction effect; the average accuracy, F_1 score, recall rate and
area under the curve of repeated experiments are better than the methods
reported in the literature. The obtained prediction model has good prediction
accuracy and stability, and can provide an effective reference for later safe
medication guidance.

摘要：在临床治疗中，识别药物潜在的不良反应可以帮助医生做出用药决策。针对以往研究中特征高维且稀疏、需要为每种药物不良反应构建独立的预测模型、预测准确率低等问题，本文提出了一种基于知识图谱嵌入和深度学习的不良药物反应预测模型，可以预测实验结果。覆盖不良药物反应的统一预测。知识图谱嵌入技术可以融合药物之间的关联信息，缓解特征矩阵中高维稀疏的不足，深度学习高效的训练能力可以提升模型的预测准确率。本文基于药物特征数据构建不良药物反应知识图谱；通过分析知识图谱在不同嵌入策略下的嵌入效果，选取最优的嵌入策略得到样本向量；然后构建卷积神经网络模型预测不良反应。结果表明，在DistMult嵌入模型和400维度的嵌入策略下，卷积神经网络模型的预测效果最佳；重复实验的平均准确率、F_1值、召回率和曲线下面积均优于文献报道的方法。所获得的预测模型具有良好的预测准确率和稳定性，可以为后期的安全用药指导提供有效的参考。

##### **Artificial Intelligence-based Decision Support Systems for Precision and Digital Health**
2407.16062v1 by Nina Deliu, Bibhas Chakraborty

Precision health, increasingly supported by digital technologies, is a domain
of research that broadens the paradigm of precision medicine, advancing
everyday healthcare. This vision goes hand in hand with the groundbreaking
advent of artificial intelligence (AI), which is reshaping the way we diagnose,
treat, and monitor both clinical subjects and the general population. AI tools
powered by machine learning have shown considerable improvements in a variety
of healthcare domains. In particular, reinforcement learning (RL) holds great
promise for sequential and dynamic problems such as dynamic treatment regimes
and just-in-time adaptive interventions in digital health. In this work, we
discuss the opportunity offered by AI, more specifically RL, to current trends
in healthcare, providing a methodological survey of RL methods in the context
of precision and digital health. Focusing on the area of adaptive
interventions, we expand the methodological survey with illustrative case
studies that used RL in real practice.
  This invited article has undergone anonymous review and is intended as a book
chapter for the volume "Frontiers of Statistics and Data Science" edited by
Subhashis Ghoshal and Anindya Roy for the International Indian Statistical
Association Series on Statistics and Data Science, published by Springer. It
covers the material from a short course titled "Artificial Intelligence in
Precision and Digital Health" taught by the author Bibhas Chakraborty at the
IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,
Bengaluru.

摘要：<paragraph>精準健康在數位科技的支撐下日益普及，是擴展精準醫療典範的研究領域，促進日常保健。這個願景與人工智慧 (AI) 的突破性進展息息相關，它正在重塑我們診斷、治療和監控臨床受試者和一般民眾的方式。由機器學習支援的 AI 工具已在各種醫療保健領域展現顯著的進步。特別是，強化學習 (RL) 對序貫和動態問題（例如動態治療方案和即時適應性干預）極具發展前景。在這項工作中，我們探討 AI（更具體地說，RL）為當前醫療保健趨勢帶來的契機，並提供 RL 方法在精準和數位健康領域的方法論調查。我們專注於適應性干預領域，並透過在實際應用中使用 RL 的說明性案例研究擴展方法論調查。這篇受邀文章已經過匿名審查，並作為 Subhashis Ghoshal 和 Anindya Roy 編輯的「統計學與資料科學前沿」一書的章節，由 Springer 出版的國際印度統計協會統計學與資料科學系列叢書發行。它涵蓋了由作者 Bibhas Chakraborty 在印度統計協會 2022 年會議（2022 年 12 月 26 日至 30 日，於印度科學院 Bengaluru 舉行）教授的「精準與數位健康中的人工智慧」短期課程的教材。</paragraph>

##### **GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**
2407.15719v1 by Zhaojie Fang, Shenghao Zhu, Yifei Chen, Binfeng Zou, Fan Jia, Linwei Qiu, Chang Liu, Yiyu Huang, Xiang Feng, Feiwei Qin, Changmiao Wang, Yeru Wang, Jin Fan, Changbiao Chu, Wan-Zhen Wu, Hu Zhao

Alzheimer's Disease (AD) is an irreversible neurodegenerative disorder that
often progresses from Mild Cognitive Impairment (MCI), leading to memory loss
and significantly impacting patients' lives. Clinical trials indicate that
early targeted interventions for MCI patients can potentially slow or halt the
development and progression of AD. Previous research has shown that accurate
medical classification requires the inclusion of extensive multimodal data,
such as assessment scales and various neuroimaging techniques like Magnetic
Resonance Imaging (MRI) and Positron Emission Tomography (PET). However,
consistently tracking the diagnosis of the same individual over time and
simultaneously collecting multimodal data poses significant challenges. To
address this issue, we introduce GFE-Mamba, a classifier based on Generative
Feature Extraction (GFE). This classifier effectively integrates data from
assessment scales, MRI, and PET, enabling deeper multimodal fusion. It
efficiently extracts both long and short sequence information and incorporates
additional information beyond the pixel space. This approach not only improves
classification accuracy but also enhances the interpretability and stability of
the model. We constructed datasets of over 3000 samples based on the
Alzheimer's Disease Neuroimaging Initiative (ADNI) for a two-step training
process. Our experimental results demonstrate that the GFE-Mamba model is
effective in predicting the conversion from MCI to AD and outperforms several
state-of-the-art methods. Our source code and ADNI dataset processing code are
available at https://github.com/Tinysqua/GFE-Mamba.

摘要：阿茲海默症 (AD) 是一種不可逆的神經退化性疾病，
通常會從輕度認知障礙 (MCI) 惡化，導致記憶力減退
並對病患的生活產生重大影響。臨床試驗顯示，
針對 MCI 病患的早期目標性干預措施，有可能減緩或停止
AD 的發展和惡化。先前的研究顯示，精確的
醫療分類需要納入廣泛的多模式數據，
例如評估量表和各種神經影像技術，如磁振造影 (MRI) 和正子斷層掃描 (PET)。然而，
持續追蹤同一位個體的診斷結果，並同時收集多模式數據，會造成重大的挑戰。為了
解決這個問題，我們引入了 GFE-Mamba，一種基於生成特徵萃取 (GFE) 的分類器。此分類器有效整合來自
評估量表、MRI 和 PET 的數據，實現更深入的多模式融合。它
有效率地萃取出長序列和短序列資訊，並納入像素空間以外的額外資訊。這種方法不僅提升了
分類準確度，也增強了模型的可解釋性和穩定性。我們根據
阿茲海默症神經影像倡議組織 (ADNI) 建立了超過 3000 個樣本的資料集，用於兩階段訓練
過程。我們的實驗結果證明，GFE-Mamba 模型在預測從 MCI 轉變為 AD 上是有效的，並且優於多種
最先進的方法。我們的原始程式碼和 ADNI 資料集處理程式碼可於 https://github.com/Tinysqua/GFE-Mamba 取得。

##### **Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**
2407.15526v2 by Eugenio Lomurno, Matteo Matteucci

Generative artificial intelligence has transformed the generation of
synthetic data, providing innovative solutions to challenges like data scarcity
and privacy, which are particularly critical in fields such as medicine.
However, the effective use of this synthetic data to train high-performance
models remains a significant challenge. This paper addresses this issue by
introducing Knowledge Recycling (KR), a pipeline designed to optimise the
generation and use of synthetic data for training downstream classifiers. At
the heart of this pipeline is Generative Knowledge Distillation (GKD), the
proposed technique that significantly improves the quality and usefulness of
the information provided to classifiers through a synthetic dataset
regeneration and soft labelling mechanism. The KR pipeline has been tested on a
variety of datasets, with a focus on six highly heterogeneous medical image
datasets, ranging from retinal images to organ scans. The results show a
significant reduction in the performance gap between models trained on real and
synthetic data, with models based on synthetic data outperforming those trained
on real data in some cases. Furthermore, the resulting models show almost
complete immunity to Membership Inference Attacks, manifesting privacy
properties missing in models trained with conventional techniques.

摘要：生成式人工智慧已經轉變了合成資料的生成，為資料稀少和隱私等挑戰提供了創新的解決方案，這些挑戰在醫學等領域特別關鍵。然而，有效使用這種合成資料來訓練高性能模型仍然是一個重大的挑戰。本文通過引入知識回收 (KR) 來解決此問題，這是一個旨在優化合成資料的生成和使用以訓練下游分類器的管道。此管道的核心是生成式知識蒸餾 (GKD)，這項提議的技術通過合成資料集再生和軟標籤機制，顯著改善了提供給分類器的資訊品質和有用性。KR 管道已針對各種資料集進行測試，重點是六個高度異質的醫學影像資料集，範圍從視網膜影像到器官掃描。結果顯示，在真實資料和合成資料上訓練的模型之間的效能差距顯著縮小，在某些情況下，基於合成資料的模型優於在真實資料上訓練的模型。此外，生成的模型對成員身分推論攻擊幾乎完全免疫，表現出傳統技術訓練的模型所缺少的隱私特性。

##### **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**
2407.15362v1 by Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen

Remarkable strides in computational pathology have been made in the
task-agnostic foundation model that advances the performance of a wide array of
downstream clinical tasks. Despite the promising performance, there are still
several challenges. First, prior works have resorted to either vision-only or
vision-captions data, disregarding invaluable pathology reports and gene
expression profiles which respectively offer distinct knowledge for versatile
clinical applications. Second, the current progress in pathology FMs
predominantly concentrates on the patch level, where the restricted context of
patch-level pretraining fails to capture whole-slide patterns. Here we curated
the largest multimodal dataset consisting of H\&E diagnostic whole slide images
and their associated pathology reports and RNA-Seq data, resulting in 26,169
slide-level modality pairs from 10,275 patients across 32 cancer types. To
leverage these data for CPath, we propose a novel whole-slide pretraining
paradigm which injects multimodal knowledge at the whole-slide context into the
pathology FM, called Multimodal Self-TAught PRetraining (mSTAR). The proposed
paradigm revolutionizes the workflow of pretraining for CPath, which enables
the pathology FM to acquire the whole-slide context. To our knowledge, this is
the first attempt to incorporate multimodal knowledge at the slide level for
enhancing pathology FMs, expanding the modelling context from unimodal to
multimodal knowledge and from patch-level to slide-level. To systematically
evaluate the capabilities of mSTAR, extensive experiments including slide-level
unimodal and multimodal applications, are conducted across 7 diverse types of
tasks on 43 subtasks, resulting in the largest spectrum of downstream tasks.
The average performance in various slide-level applications consistently
demonstrates significant performance enhancements for mSTAR compared to SOTA
FMs.

摘要：<paragraph>在計算病理學中，任務不可知基礎模型已取得顯著進展，可提升廣泛下游臨床任務的效能。儘管效能令人滿意，但仍有幾個挑戰。首先，先前的研究僅採用僅限影像或影像標題資料，忽略了寶貴的病理報告和基因表現特徵，而這些特徵分別為多功能臨床應用提供了不同的知識。其次，病理 FM 的當前進度主要集中在區塊層級，區塊層級預訓練的受限背景無法擷取全切片模式。在此，我們策劃了最大的多模態資料集，包含 H&E 診斷全切片影像及其相關病理報告和 RNA-Seq 資料，共產生來自 32 種癌症類型的 10,275 名患者的 26,169 個切片層級模態配對。為了將這些資料用於 CPath，我們提出了一種創新的全切片預訓練範例，將全切片背景的多模態知識注入病理 FM，稱為多模態自教預訓練 (mSTAR)。所提出的範例徹底改變了 CPath 的預訓練工作流程，使病理 FM 能夠獲取全切片背景。據我們所知，這是首次嘗試在切片層級納入多模態知識以增強病理 FM，將建模背景從單一模態知識擴展到多模態知識，以及從區塊層級擴展到切片層級。為了系統性地評估 mSTAR 的功能，我們在 43 個子任務中對 7 種不同類型的任務進行了廣泛的實驗，包括切片層級的單一模態和多模態應用，產生了最大的下游任務範圍。在各種切片層級應用中，平均效能持續顯示 mSTAR 與 SOTA FM 相比有顯著的效能提升。</paragraph>

##### **They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models**
2407.21041v1 by Mohammad Saeid Mahdavinejad, Peyman Adibi, Amirhassan Monadjemi, Pascal Hitzler

Depression is a common mental health issue that requires prompt diagnosis and
treatment. Despite the promise of social media data for depression detection,
the opacity of employed deep learning models hinders interpretability and
raises bias concerns. We address this challenge by introducing ProtoDep, a
novel, explainable framework for Twitter-based depression detection. ProtoDep
leverages prototype learning and the generative power of Large Language Models
to provide transparent explanations at three levels: (i) symptom-level
explanations for each tweet and user, (ii) case-based explanations comparing
the user to similar individuals, and (iii) transparent decision-making through
classification weights. Evaluated on five benchmark datasets, ProtoDep achieves
near state-of-the-art performance while learning meaningful prototypes. This
multi-faceted approach offers significant potential to enhance the reliability
and transparency of depression detection on social media, ultimately aiding
mental health professionals in delivering more informed care.

摘要：憂鬱症是一種常見的精神健康問題，需要及時診斷和治療。儘管社群媒體資料有望用於憂鬱症偵測，但所採用的深度學習模型的不透明性阻礙了解，並引發偏見疑慮。我們透過引入 ProtoDep 來解決這個挑戰，這是一個新穎且可解釋的架構，用於基於 Twitter 的憂鬱症偵測。ProtoDep 利用原型學習和大型語言模型的生成能力，在三個層級提供透明的解釋：(i) 對每則推文和使用者的症狀層級解釋，(ii) 將使用者與類似個體進行比較的情境式解釋，以及 (iii) 透過分類權重進行透明的決策制定。在五個基準資料集上進行評估，ProtoDep 在學習有意義的原型時，達到了接近最先進的效能。這種多面向的方法提供了顯著的潛力，以增強社群媒體上憂鬱症偵測的可靠性和透明度，最終協助心理健康專業人員提供更明智的照護。

##### **Genetic Algorithm to Optimize Design of Micro-Surgical Scissors**
2407.15243v1 by Fatemeh Norouziani, Veerash Palanichamy, Shivam Gupta, Onaizah Onaizah

Microrobotics is an attractive area of research as small-scale robots have
the potential to improve the precision and dexterity offered by minimally
invasive surgeries. One example of such a tool is a pair of micro-surgical
scissors that was developed for cutting of tumors or cancerous tissues present
deep inside the body such as in the brain. This task is often deemed difficult
or impossible with conventional robotic tools due to their size and dexterity.
The scissors are designed with two magnets placed a specific distance apart to
maximize deflection and generate cutting forces. However, remote actuation and
size requirements of the micro-surgical scissors limits the force that can be
generated to puncture the tissue. To address the limitation of small output
forces, we use an evolutionary algorithm to further optimize the performance of
the scissors. In this study, the design of the previously developed untethered
micro-surgical scissors has been modified and their performance is enhanced by
determining the optimal position of the magnets as well as the direction of
each magnetic moment. The developed algorithm is successfully applied to a
4-magnet configuration which results in increased net torque. This improvement
in net torque is directly translated into higher cutting forces. The new
configuration generates a cutting force of 58 mN from 80 generations of the
evolutionary algorithm which is a 1.65 times improvement from the original
design. Furthermore, the developed algorithm has the advantage that it can be
deployed with minor modifications to other microrobotic tools and systems,
opening up new possibilities for various medical procedures and applications.

摘要：微型機器人是一個有吸引力的研究領域，因為小型機器人具有提高微創手術的精確度和靈活性。此類工具的一個範例是一對微型手術剪刀，其開發用於切除深藏於體內（例如大腦）的腫瘤或癌組織。由於傳統機器人工具的尺寸和靈活性，此任務通常被認為困難或不可能。此剪刀的設計採用兩個磁鐵，它們之間的距離設定為特定值，以最大化偏轉並產生切削力。然而，微型手術剪刀的遠程致動和尺寸要求限制了可產生的穿刺組織力。為了解決小輸出力的限制，我們使用演化演算法進一步最佳化剪刀的效能。在本研究中，先前開發的無繫繩微型手術剪刀的設計已修改，並且透過確定磁鐵的最佳位置以及每個磁矩的方向來提升其效能。已將開發的演算法成功應用於 4 磁鐵組態，這會導致淨扭力增加。淨扭力的此項改善直接轉化為更高的切削力。新的組態從演化演算法的 80 個世代產生 58 mN 的切削力，這是相較於原始設計改善了 1.65 倍。此外，已開發的演算法具有可透過輕微修改部署至其他微型機器人工具和系統的優點，為各種醫療程序和應用開啟了新的可能性。

##### **MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM**
2407.15042v1 by Navyansh Mahla, Annie D'souza, Shubh Gupta, Bhavik Kanekar, Kshitij Sharad Jadhav

The application of large-scale models in medical image segmentation demands
substantial quantities of meticulously annotated data curated by experts along
with high computational resources, both of which are challenges in
resource-poor settings. In this study, we present the Medical Segment Anything
Model with Galore MedSAGa where we adopt the Segment Anything Model (SAM) to
achieve memory-efficient, few-shot medical image segmentation by applying
Gradient Low-Rank Projection GaLore to the parameters of the image encoder of
SAM. Meanwhile, the weights of the prompt encoder and mask decoder undergo full
parameter fine-tuning using standard optimizers. We further assess MedSAGa's
few-shot learning capabilities, reporting on its memory efficiency and
segmentation performance across multiple standard medical image segmentation
datasets. We compare it with several baseline models, including LoRA fine-tuned
SAM (SAMed) and DAE-Former. Experiments across multiple datasets and these
baseline models with different number of images for fine tuning demonstrated
that the GPU memory consumption of MedSAGa is significantly less than that of
the baseline models, achieving an average memory efficiency of 66% more than
current state-of-the-art (SOTA) models for medical image segmentation. The
combination of substantially lower memory requirements and comparable to SOTA
results in few-shot learning for medical image segmentation positions MedSAGa
as an optimal solution for deployment in resource-constrained settings.

摘要：大型模型在醫學影像分割中的應用需要大量由專家精心註解的資料，以及大量的計算資源，這兩者在資源貧乏的環境中都是挑戰。在本研究中，我們提出了具有豐富醫學影像分割的醫學分割任何模型 (MedSAGa)，其中我們採用分割任何模型 (SAM) 來通過將梯度低秩投影 GaLore 應用於 SAM 的影像編碼器參數來實現記憶體效率高的少量醫學影像分割。同時，提示編碼器和遮罩解碼器的權重使用標準最佳化器進行完整的參數微調。我們進一步評估了 MedSAGa 的少量學習能力，報告了其在多個標準醫學影像分割資料集中的記憶體效率和分割效能。我們將其與幾個基準模型進行比較，包括微調 SAM (SAMed) 的 LoRA 和 DAE-Former。跨多個資料集和這些基準模型的實驗，使用不同數量的影像進行微調，證明 MedSAGa 的 GPU 記憶體消耗明顯低於基準模型，比目前最先進 (SOTA) 的醫學影像分割模型平均記憶體效率高出 66%。在少量學習中，大幅降低記憶體需求與 SOTA 相當的結果，使得 MedSAGa 成為在資源受限環境中部署的最佳解決方案。

##### **Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives**
2407.21039v1 by Sudeshna Jana, Tirthankar Dasgupta, Lipika Dey

In recent years, healthcare professionals are increasingly emphasizing on
personalized and evidence-based patient care through the exploration of
prognostic pathways. To study this, structured clinical variables from
Electronic Health Records (EHRs) data have traditionally been employed by many
researchers. Presently, Natural Language Processing models have received great
attention in clinical research which expanded the possibilities of using
clinical narratives. In this paper, we propose a systematic methodology for
developing sepsis prognostic pathways derived from clinical notes, focusing on
diverse patient subgroups identified by exploring comorbidities associated with
sepsis and generating explanations of these subgroups using SHAP. The extracted
prognostic pathways of these subgroups provide valuable insights into the
dynamic trajectories of sepsis severity over time. Visualizing these pathways
sheds light on the likelihood and direction of disease progression across
various contexts and reveals patterns and pivotal factors or biomarkers
influencing the transition between sepsis stages, whether toward deterioration
or improvement. This empowers healthcare providers to implement more
personalized and effective healthcare strategies for individual patients.

摘要：近年來，醫療保健專業人士越來越重視透過探索預後途徑來提供個人化且基於證據的患者照護。為研究此議題，許多研究人員傳統上採用電子健康紀錄 (EHR) 資料中的結構化臨床變數。目前，自然語言處理模型在臨床研究中備受重視，擴大了使用臨床敘述的可能性。在本文中，我們提出一個系統化的方法，用於開發從臨床筆記中衍生的敗血症預後途徑，重點在於探索與敗血症相關的併發症所識別出的不同患者子群，並使用 SHAP 產生這些子群的說明。這些子群中萃取出的預後途徑提供了有價值的見解，了解敗血症嚴重程度隨著時間推移的動態軌跡。視覺化這些途徑有助於了解疾病進展在各種情境下的可能性和方向，並揭示影響敗血症階段轉變的模式和關鍵因素或生物標記，無論是惡化或改善。這使醫療保健提供者能夠為個別患者實施更個人化且有效的醫療保健策略。

##### **Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction**
2407.14876v1 by Petros Koutsouvelis, Bartlomiej Chybowski, Alfredo Gonzalez-Sulser, Shima Abdullateef, Javier Escudero

Accurate prediction of epileptic seizures could prove critical for improving
patient safety and quality of life in drug-resistant epilepsy. Although deep
learning-based approaches have shown promising seizure prediction performance
using scalp electroencephalogram (EEG) signals, substantial limitations still
impede their clinical adoption. Furthermore, identifying the optimal preictal
period (OPP) for labeling EEG segments remains a challenge. Here, we not only
develop a competitive deep learning model for seizure prediction but, more
importantly, leverage it to demonstrate a methodology to comprehensively
evaluate the predictive performance in the seizure prediction task. For this,
we introduce a CNN-Transformer deep learning model to detect preictal
spatiotemporal dynamics, alongside a novel Continuous Input-Output Performance
Ratio (CIOPR) metric to determine the OPP. We trained and evaluated our model
on 19 pediatric patients of the open-access CHB-MIT dataset in a
subject-specific manner. Using the OPP of each patient, preictal and interictal
segments were correctly identified with an average sensitivity of 99.31%,
specificity of 95.34%, AUC of 99.35%, and F1- score of 97.46%, while prediction
time averaged 76.8 minutes before onset. Notably, our novel CIOPR metric
allowed outlining the impact of different preictal period definitions on
prediction time, accuracy, output stability, and transition time between
interictal and preictal states in a comprehensive and quantitative way and
highlighted the importance of considering both inter- and intra-patient
variability in seizure prediction.

摘要：準確預測癲癇發作對於改善藥物抗性癲癇患者的安全性與生活品質至關重要。儘管基於深度學習的方法已展現出使用頭皮腦電圖 (EEG) 信號進行癲癇發作預測的出色表現，但仍有實質限制阻礙其臨床應用。此外，找出標記 EEG 片段的最佳發作前 (OPP) 時期仍然是一項挑戰。在此，我們不僅開發了一種用於癲癇發作預測的競爭性深度學習模型，更重要的是，利用它來展示一種方法，以全面評估癲癇發作預測任務中的預測性能。為此，我們引入了一個 CNN-Transformer 深度學習模型來偵測發作前的時空動力學，以及一個新的連續輸入輸出效能比 (CIOPR) 指標來確定 OPP。我們以主題特定的方式，在開放取用的 CHB-MIT 資料集的 19 位小兒患者上訓練並評估我們的模型。使用每位患者的 OPP，以平均敏感度 99.31%、特異度 95.34%、AUC 99.35% 和 F1 分數 97.46% 正確識別發作前和發作間期，而預測時間平均在發作前 76.8 分鐘。值得注意的是，我們新穎的 CIOPR 指標可以全面且量化地概述不同發作前時期定義對預測時間、準確度、輸出穩定性以及發作間期和發作前狀態之間的轉換時間的影響，並強調在癲癇發作預測中考慮患者間和患者內變異性的重要性。

##### **PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates**
2407.14796v1 by Junjie Shi, Caozhi Shang, Zhaobin Sun, Li Yu, Xin Yang, Zengqiang Yan

Incomplete multi-modal image segmentation is a fundamental task in medical
imaging to refine deployment efficiency when only partial modalities are
available. However, the common practice that complete-modality data is visible
during model training is far from realistic, as modalities can have imbalanced
missing rates in clinical scenarios. In this paper, we, for the first time,
formulate such a challenging setting and propose Preference-Aware
Self-diStillatION (PASSION) for incomplete multi-modal medical image
segmentation under imbalanced missing rates. Specifically, we first construct
pixel-wise and semantic-wise self-distillation to balance the optimization
objective of each modality. Then, we define relative preference to evaluate the
dominance of each modality during training, based on which to design task-wise
and gradient-wise regularization to balance the convergence rates of different
modalities. Experimental results on two publicly available multi-modal datasets
demonstrate the superiority of PASSION against existing approaches for modality
balancing. More importantly, PASSION is validated to work as a plug-and-play
module for consistent performance improvement across different backbones. Code
is available at https://github.com/Jun-Jie-Shi/PASSION.

摘要：不完整的多模態影像分割是醫學影像中的一項基本任務，用於在只有部分模態可用時精進部署效率。然而，在模型訓練期間可見完整模態資料的常見做法並不切實際，因為在臨床場景中，模態可能會有不平衡的遺漏率。在本文中，我們首次制定了這樣一個具有挑戰性的設定，並提出了不平衡遺漏率下不完整多模態醫學影像分割的偏好感知自蒸餾 (PASSION)。具體來說，我們首先建構像素級和語義級自蒸餾，以平衡每個模態的最佳化目標。然後，我們定義相對偏好來評估訓練期間每個模態的主導地位，並根據此設計任務級和梯度級正則化，以平衡不同模態的收斂率。在兩個公開的多模態資料集上的實驗結果證明了 PASSION 優於現有模態平衡方法。更重要的是，PASSION 被驗證為即插即用模組，可在不同的主幹中持續提升效能。程式碼可在 https://github.com/Jun-Jie-Shi/PASSION 取得。

##### **Improving Representation of High-frequency Components for Medical Foundation Models**
2407.14651v2 by Yuetan Chu, Yilan Zhang, Zhongyi Han, Changchun Yang, Longxi Zhou, Gongning Luo, Xin Gao

Foundation models have recently attracted significant attention for their
impressive generalizability across diverse downstream tasks. However, these
models are demonstrated to exhibit great limitations in representing
high-frequency components and fine-grained details. In many medical imaging
tasks, the precise representation of such information is crucial due to the
inherently intricate anatomical structures, sub-visual features, and complex
boundaries involved. Consequently, the limited representation of prevalent
foundation models can result in significant performance degradation or even
failure in these tasks. To address these challenges, we propose a novel
pretraining strategy, named Frequency-advanced Representation Autoencoder
(Frepa). Through high-frequency masking and low-frequency perturbation combined
with adversarial learning, Frepa encourages the encoder to effectively
represent and preserve high-frequency components in the image embeddings.
Additionally, we introduce an innovative histogram-equalized image masking
strategy, extending the Masked Autoencoder approach beyond ViT to other
architectures such as Swin Transformer and convolutional networks. We develop
Frepa across nine medical modalities and validate it on 32 downstream tasks for
both 2D images and 3D volume data. Without fine-tuning, Frepa can outperform
other self-supervised pretraining methods and, in some cases, even surpasses
task-specific trained models. This improvement is particularly significant for
tasks involving fine-grained details, such as achieving up to a +15% increase
in DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule
detection. Further experiments quantitatively reveal that Frepa enables
superior high-frequency representations and preservation in the embeddings,
underscoring its potential for developing more generalized and universal
medical image foundation models.

摘要：<paragraph>基礎模型最近因其在各種下游任務中令人印象深刻的泛化能力而備受關注。然而，這些模型已證明在表示高頻率組成和細粒度細節方面表現出很大的局限性。在許多醫學影像任務中，由於涉及固有的複雜解剖結構、次視覺特徵和複雜邊界，因此準確表示此類信息至關重要。因此，流行基礎模型的有限表示可能會導致這些任務的顯著性能下降甚至失敗。為了應對這些挑戰，我們提出了一種名為頻率先進表示自動編碼器 (Frepa) 的新穎預訓練策略。通過高頻掩蔽和低頻擾動與對抗學習相結合，Frepa 鼓勵編碼器有效表示和保留圖像嵌入中的高頻組成。此外，我們引入了一種創新的直方圖均衡圖像掩蔽策略，將掩蔽自動編碼器方法從 ViT 擴展到其他架構，例如 Swin Transformer 和卷積網路。我們在九種醫學模式下開發了 Frepa，並在 32 個下游任務中對其進行了驗證，包括 2D 圖像和 3D 體積數據。在不進行微調的情況下，Frepa 可以優於其他自我監督預訓練方法，並且在某些情況下，甚至超過了特定任務訓練的模型。這種改進對於涉及細粒度細節的任務尤其顯著，例如在視網膜血管分割中將 DSC 提高了 15%，在肺結節檢測中將 IoU 提高了 7%。進一步的實驗定量地表明，Frepa 能夠在嵌入中實現優越的高頻表示和保留，這突顯了其開發更通用和通用的醫學影像基礎模型的潛力。</paragraph>

##### **CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models**
2407.14640v1 by Rikhiya Ghosh, Oladimeji Farri, Hans-Martin von Stockhausen, Martin Schmitt, George Marica Vasile

The healthcare industry is currently experiencing an unprecedented wave of
cybersecurity attacks, impacting millions of individuals. With the discovery of
thousands of vulnerabilities each month, there is a pressing need to drive the
automation of vulnerability assessment processes for medical devices,
facilitating rapid mitigation efforts. Generative AI systems have
revolutionized various industries, offering unparalleled opportunities for
automation and increased efficiency. This paper presents a solution leveraging
Large Language Models (LLMs) to learn from historical evaluations of
vulnerabilities for the automatic assessment of vulnerabilities in the medical
devices industry. This approach is applied within the portfolio of a single
manufacturer, taking into account device characteristics, including existing
security posture and controls. The primary contributions of this paper are
threefold. Firstly, it provides a detailed examination of the best practices
for training a vulnerability Language Model (LM) in an industrial context.
Secondly, it presents a comprehensive comparison and insightful analysis of the
effectiveness of Language Models in vulnerability assessment. Finally, it
proposes a new human-in-the-loop framework to expedite vulnerability evaluation
processes.

摘要：醫療保健產業目前正經歷一前所未有的網路安全攻擊浪潮，影響了數百萬人。隨著每月發現數千個漏洞，迫切需要推動醫療器材漏洞評估程序的自動化，以利於快速採取緩解措施。生成式 AI 系統已經徹底改變了各產業，為自動化和提高效率提供了無與倫比的機會。本文提出了一種解決方案，利用大型語言模型 (LLM) 從漏洞的歷史評估中學習，以自動評估醫療器材產業中的漏洞。此方法應用於單一製造商的產品組合中，考量了裝置特性，包括現有的安全態勢和控制措施。本文的主要貢獻有三方面。首先，它提供了在產業背景下訓練漏洞語言模型 (LM) 的最佳實務詳細說明。其次，它提出了語言模型在漏洞評估中的有效性之全面比較和深入分析。最後，它提出了一個新的「人機協作」架構，以加速漏洞評估程序。

##### **Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis**
2407.14631v1 by Kamyab Karimi, Ali Ghodratnama, Reza Tavakkoli-Moghaddam

Breast cancer is not preventable because of its unknown causes. However, its
early diagnosis increases patients' recovery chances. Machine learning (ML) can
be utilized to improve treatment outcomes in healthcare operations while
diminishing costs and time. In this research, we suggest two novel feature
selection (FS) methods based upon an imperialist competitive algorithm (ICA)
and a bat algorithm (BA) and their combination with ML algorithms. This study
aims to enhance diagnostic models' efficiency and present a comprehensive
analysis to help clinical physicians make much more precise and reliable
decisions than before. K-nearest neighbors, support vector machine, decision
tree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,
logistic regression, and artificial neural network are some of the methods
employed. This paper applied a distinctive integration of evaluation measures
and ML algorithms using the wrapper feature selection based on ICA (WFSIC) and
BA (WFSB) separately. We compared two proposed approaches for the performance
of the classifiers. Also, we compared our best diagnostic model with previous
works reported in the literature survey. Experimentations were performed on the
Wisconsin diagnostic breast cancer dataset. Results reveal that the proposed
framework that uses the BA with an accuracy of 99.12\%, surpasses the framework
using the ICA and most previous works. Additionally, the RF classifier in the
approach of FS based on BA emerges as the best model and outperforms others
regarding its criteria. Besides, the results illustrate the role of our
techniques in reducing the dataset dimensions up to 90\% and increasing the
performance of diagnostic models by over 99\%. Moreover, the result
demonstrates that there are more critical features than the optimum dataset
obtained by proposed FS approaches that have been selected by most ML models.

摘要：<paragraph>由於乳癌的成因不明，因此無法預防。然而，早期診斷可增加患者的康復機會。機器學習 (ML) 可用於改善醫療保健作業中的治療成果，同時降低成本和時間。在本研究中，我們提出兩種基於帝國主義競爭演算法 (ICA) 和蝙蝠演算法 (BA) 的新特徵選擇 (FS) 方法，以及它們與 ML 演算法的組合。本研究旨在提高診斷模型的效率，並提供全面的分析，以幫助臨床醫師做出比以往更精確且可靠的決策。K 最近鄰、支援向量機、決策樹、樸素貝氏、AdaBoost、線性判別分析、隨機森林、邏輯迴歸和人工神經網路是一些所採用的方法。本文使用基於 ICA (WFSIC) 和 BA (WFSB) 的包裝特徵選擇，應用評估措施和 ML 演算法的獨特整合。我們比較了兩種提出的方法以評估分類器的效能。此外，我們將我們最好的診斷模型與文獻調查中報導的先前研究進行比較。實驗是在威斯康辛診斷乳癌資料集上進行的。結果顯示，使用 BA 的擬議架構準確率為 99.12%，優於使用 ICA 和大多數先前研究的架構。此外，基於 BA 的 FS 方法中的 RF 分類器成為最佳模型，並在標準方面優於其他模型。此外，結果說明了我們的技術在將資料集維度減少多達 90% 以及將診斷模型的效能提高超過 99% 中所扮演的角色。此外，結果表明，由大多數 ML 模型所選取的，比由提出的 FS 方法所獲得的最佳資料集更重要的特徵還更多。</paragraph>

##### **Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**
2407.14326v1 by Kun Zhao, Jakub Prokop, Javier Montalt Tordera, Sadegh Mohammadi

Mammography is crucial for breast cancer surveillance and early diagnosis.
However, analyzing mammography images is a demanding task for radiologists, who
often review hundreds of mammograms daily, leading to overdiagnosis and
overtreatment. Computer-Aided Diagnosis (CAD) systems have been developed to
assist in this process, but their capabilities, particularly in lesion
segmentation, remained limited. With the contemporary advances in deep learning
their performance may be improved. Recently, vision-language diffusion models
emerged, demonstrating outstanding performance in image generation and
transferability to various downstream tasks. We aim to harness their
capabilities for breast lesion segmentation in a panoptic setting, which
encompasses both semantic and instance-level predictions. Specifically, we
propose leveraging pretrained features from a Stable Diffusion model as inputs
to a state-of-the-art panoptic segmentation architecture, resulting in accurate
delineation of individual breast lesions. To bridge the gap between natural and
medical imaging domains, we incorporated a mammography-specific MAM-E diffusion
model and BiomedCLIP image and text encoders into this framework. We evaluated
our approach on two recently published mammography datasets, CDD-CESM and
VinDr-Mammo. For the instance segmentation task, we noted 40.25 AP0.1 and 46.82
AP0.05, as well as 25.44 PQ0.1 and 26.92 PQ0.05. For the semantic segmentation
task, we achieved Dice scores of 38.86 and 40.92, respectively.

摘要：乳房攝影對於乳癌監控和早期診斷至關重要。
然而，分析乳房攝影影像對放射科醫師來說是一項艱鉅的任務，他們
每天經常檢閱數百張乳房攝影影像，導致過度診斷和
過度治療。電腦輔助診斷 (CAD) 系統已開發出來以
協助此流程，但其功能，特別是在病灶
分割方面，仍然有限。隨著深度學習的當代進展
其性能可能會得到改善。最近，視覺語言擴散模型
出現，在影像生成和
可轉移到各種下游任務中展現出傑出的性能。我們旨在利用其
功能在全景設置中進行乳房病灶分割，其中
包含語義和實例級別預測。具體來說，我們
建議利用預先訓練的 Stable Diffusion 模型中的特徵作為輸入
到最先進的全景分割架構，從而精確地描繪個別乳房病灶。為了彌合自然和
醫學影像領域之間的差距，我們將乳房攝影專用的 MAM-E 擴散
模型和 BiomedCLIP 影像和文字編碼器納入這個架構中。我們評估
我們的方法在兩個最近發布的乳房攝影資料集 CDD-CESM 和
VinDr-Mammo。對於實例分割任務，我們注意到 40.25 AP0.1 和 46.82
AP0.05，以及 25.44 PQ0.1 和 26.92 PQ0.05。對於語義分割
任務，我們分別達到了 38.86 和 40.92 的 Dice 分數。

##### **Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**
2407.14210v1 by José Daniel Pascual-Triana, Alberto Fernández, Paulo Novais, Francisco Herrera

Given the magnitude of data generation currently, both in quantity and speed,
the use of machine learning is increasingly important. When data include
protected features that might give rise to discrimination, special care must be
taken. Data quality is critical in these cases, as biases in training data can
be reflected in classification models. This has devastating consequences and
fails to comply with current regulations. Data-Centric Artificial Intelligence
proposes dataset modifications to improve its quality. Instance selection via
undersampling can foster balanced learning of classes and protected feature
values in the classifier. When such undersampling is done close to the decision
boundary, the effect on the classifier would be bolstered. This work proposes
Fair Overlap Number of Balls (Fair-ONB), an undersampling method that harnesses
the data morphology of the different data groups (obtained from the combination
of classes and protected feature values) to perform guided undersampling in the
areas where they overlap. It employs attributes of the ball coverage of the
groups, such as the radius, number of covered instances and density, to select
the most suitable areas for undersampling and reduce bias. Results show that
the Fair-ONB method reduces bias with low impact on the classifier's predictive
performance.

摘要：<paragraph>鉴于当前数据生成的规模，无论是在数量还是速度上，机器学习的使用变得越来越重要。当数据包含可能导致歧视的受保护特征时，必须特别小心。在这些情况下，数据质量至关重要，因为训练数据中的偏差可能会反映在分类模型中。这会产生毁灭性的后果，并且不符合当前法规。以数据为中心的 AI 提出了数据集修改以提高其质量。通过欠采样进行实例选择可以促进分类器中类和受保护特征值的平衡学习。当此类欠采样接近决策边界时，对分类器的影响将得到加强。这项工作提出了公平重叠球数 (Fair-ONB)，这是一种欠采样方法，利用不同数据组（从类和受保护特征值的组合中获得）的数据形态，在它们重叠的区域执行引导欠采样。它采用球覆盖的属性，例如半径、覆盖实例数和密度，以选择最适合欠采样的区域并减少偏差。结果表明，Fair-ONB 方法减少了偏差，对分类器的预测性能影响很小。</paragraph>

##### **Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**
2407.14076v2 by Tobias Kerner

There are many cases where LLMs are used for specific tasks in a single
domain. These usually require less general, but more domain-specific knowledge.
Highly capable, general-purpose state-of-the-art language models like GPT-4 or
Claude-3-opus can often be used for such tasks, but they are very large and
cannot be run locally, even if they were not proprietary. This can be a problem
when working with sensitive data. This paper focuses on domain-specific and
mixed-domain pretraining as potentially more efficient methods than general
pretraining for specialized language models. We will take a look at work
related to domain-specific pretraining, specifically in the medical area, and
compare benchmark results of specialized language models to general-purpose
language models.

摘要：在許多情況下，LLM 用於單一領域中的特定任務。這些任務通常需要較少的通用知識，但需要更多特定領域的知識。功能強大、通用且最先進的語言模型，例如 GPT-4 或 Claude-3-opus，通常可用於此類任務，但它們非常龐大，即使不是專有軟體，也無法在本地執行。在處理敏感資料時，這可能會成為一個問題。本文重點探討領域特定和混合領域預訓練，作為比一般預訓練更有效率的專業語言模型潛在方法。我們將探討與領域特定預訓練相關的工作，特別是在醫療領域，並比較專業語言模型和通用語言模型的基準測試結果。

##### **HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**
2407.14030v1 by Prerana Sanjay Kulkarni, Muskaan Jain, Disha Sheshanarayana, Srinivasan Parthiban

Despite advancements in drug development strategies, 90% of clinical trials
fail. This suggests overlooked aspects in target validation and drug
optimization. In order to address this, we introduce HeCiX-KG,
Hetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from
ClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines
data on previously conducted clinical trials from ClinicalTrials.gov, and
domain expertise on diseases and genes from Hetionet. This offers a thorough
resource for clinical researchers. Further, we introduce HeCiX, a system that
uses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.
HeCiX shows high performance during evaluation against a range of clinically
relevant issues, proving this model to be promising for enhancing the
effectiveness of clinical research. Thus, this approach provides a more
holistic view of clinical trials and existing biological data.

摘要：儘管藥物開發策略有進展，90% 的臨床試驗都失敗了。這表示在目標驗證和藥物最佳化方面有被忽略的層面。為了解決這個問題，我們引進了 HeCiX-KG，Hetionet-Clinicaltrials neXus 知識圖譜，這是一個將 ClinicalTrials.gov 和 Hetionet 的資料融合在單一知識圖譜中的新穎融合。HeCiX-KG 結合了來自 ClinicalTrials.gov 的先前執行臨床試驗資料，以及來自 Hetionet 的疾病和基因領域專業知識。這為臨床研究人員提供了豐富的資源。此外，我們引進了 HeCiX，一個使用 LangChain 將 HeCiX-KG 與 GPT-4 整合，並提高其可用性的系統。HeCiX 在針對一系列臨床相關問題的評估中表現出高性能，證明了這個模型有望提高臨床研究的有效性。因此，這種方法提供了對臨床試驗和現有生物資料更全面的看法。

##### **DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**
2407.13920v1 by Xiaoya Tang, Bodong Zhang, Beatrice S. Knudsen, Tolga Tasdizen

We here propose a novel hierarchical transformer model that adeptly
integrates the feature extraction capabilities of Convolutional Neural Networks
(CNNs) with the advanced representational potential of Vision Transformers
(ViTs). Addressing the lack of inductive biases and dependence on extensive
training datasets in ViTs, our model employs a CNN backbone to generate
hierarchical visual representations. These representations are then adapted for
transformer input through an innovative patch tokenization. We also introduce a
'scale attention' mechanism that captures cross-scale dependencies,
complementing patch attention to enhance spatial understanding and preserve
global perception. Our approach significantly outperforms baseline models on
small and medium-sized medical datasets, demonstrating its efficiency and
generalizability. The components are designed as plug-and-play for different
CNN architectures and can be adapted for multiple applications. The code is
available at https://github.com/xiaoyatang/DuoFormer.git.

摘要：我們在此提出一個新穎的分層Transformer模型，它巧妙地整合了卷積神經網路 (CNN) 的特徵擷取能力，以及視覺Transformer (ViT) 的先進表示潛力。針對 ViT 中缺乏歸納偏誤和依賴於廣泛訓練資料集的問題，我們的模型採用 CNN 主幹來產生分層視覺表示。這些表示接著透過創新的區塊標記化，調整為Transformer輸入。我們也引入「尺度注意力」機制，它捕捉跨尺度依賴性，補充區塊注意力以增強空間理解並保留全局感知。我們的做法在小型和中型的醫學資料集上，明顯優於基線模型，證明了它的效率和可概化性。這些組件被設計成即插即用，適用於不同的 CNN 架構，並且可以調整為多種應用程式。程式碼可在 https://github.com/xiaoyatang/DuoFormer.git 取得。

##### **Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset**
2407.13896v1 by Yi Sheng, Junhuan Yang, Jinyang Li, James Alaina, Xiaowei Xu, Yiyu Shi, Jingtong Hu, Weiwen Jiang, Lei Yang

As Artificial Intelligence (AI) increasingly integrates into our daily lives,
fairness has emerged as a critical concern, particularly in medical AI, where
datasets often reflect inherent biases due to social factors like the
underrepresentation of marginalized communities and socioeconomic barriers to
data collection. Traditional approaches to mitigating these biases have focused
on data augmentation and the development of fairness-aware training algorithms.
However, this paper argues that the architecture of neural networks, a core
component of Machine Learning (ML), plays a crucial role in ensuring fairness.
We demonstrate that addressing fairness effectively requires a holistic
approach that simultaneously considers data, algorithms, and architecture.
Utilizing Automated ML (AutoML) technology, specifically Neural Architecture
Search (NAS), we introduce a novel framework, BiaslessNAS, designed to achieve
fair outcomes in analyzing skin lesion datasets. BiaslessNAS incorporates
fairness considerations at every stage of the NAS process, leading to the
identification of neural networks that are not only more accurate but also
significantly fairer. Our experiments show that BiaslessNAS achieves a 2.55%
increase in accuracy and a 65.50% improvement in fairness compared to
traditional NAS methods, underscoring the importance of integrating fairness
into neural network architecture for better outcomes in medical AI
applications.

摘要：隨著人工智慧（AI）日益融入我們的日常生活，公平性已成為一項至關重要的考量，特別是在醫療 AI 領域，其中由於社會因素（例如邊緣化社群的代表性不足和資料收集的社會經濟障礙），資料集往往反映出固有的偏見。減輕這些偏見的傳統方法著重於資料擴充和開發注重公平性的訓練演算法。然而，本文論證神經網路的架構（機器學習（ML）的核心組成部分）在確保公平性方面發揮著至關重要的作用。我們證明，有效解決公平性問題需要一種全面的方法，該方法同時考慮資料、演算法和架構。利用自動化 ML（AutoML）技術，特別是神經架構搜尋（NAS），我們引入了一個新穎的框架 BiaslessNAS，旨在分析皮膚病變資料集時獲得公平的結果。BiaslessNAS 在 NAS 程序的每個階段都納入了公平性考量，從而識別出不僅更準確，而且也顯著更公平的神經網路。我們的實驗表明，與傳統的 NAS 方法相比，BiaslessNAS 的準確度提高了 2.55%，公平性提高了 65.50%，這凸顯了將公平性整合到神經網路架構中對於改善醫療 AI 應用中的結果的重要性。

##### **APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy**
2407.14564v1 by Yi Sheng, Hanchen Wang, Yipei Liu, Junhuan Yang, Weiwen Jiang, Youzuo Lin, Lei Yang

Ultrasound computed tomography (USCT) is a promising technique that achieves
superior medical imaging reconstruction resolution by fully leveraging waveform
information, outperforming conventional ultrasound methods. Despite its
advantages, high-quality USCT reconstruction relies on extensive data
acquisition by a large number of transducers, leading to increased costs,
computational demands, extended patient scanning times, and manufacturing
complexities. To mitigate these issues, we propose a new USCT method called
APS-USCT, which facilitates imaging with sparse data, substantially reducing
dependence on high-cost dense data acquisition. Our APS-USCT method consists of
two primary components: APS-wave and APS-FWI. The APS-wave component, an
encoder-decoder system, preprocesses the waveform data, converting sparse data
into dense waveforms to augment sample density prior to reconstruction. The
APS-FWI component, utilizing the InversionNet, directly reconstructs the speed
of sound (SOS) from the ultrasound waveform data. We further improve the
model's performance by incorporating Squeeze-and-Excitation (SE) Blocks and
source encoding techniques. Testing our method on a breast cancer dataset
yielded promising results. It demonstrated outstanding performance with an
average Structural Similarity Index (SSIM) of 0.8431. Notably, over 82% of
samples achieved an SSIM above 0.8, with nearly 61% exceeding 0.85,
highlighting the significant potential of our approach in improving USCT image
reconstruction by efficiently utilizing sparse data.

摘要：超音波電腦斷層攝影 (USCT) 是一種很有前景的技術，它能透過充分利用波形資訊，達成優異的醫學影像重建解析度，表現優於傳統超音波方法。儘管有其優點，高品質的 USCT 重建依賴於大量換能器廣泛的資料擷取，導致成本增加、運算需求、病患掃描時間延長，以及製造複雜度。為了減輕這些問題，我們提出了一種名為 APS-USCT 的新型 USCT 方法，它促進使用稀疏資料進行影像處理，大幅降低對高成本密集資料擷取的依賴。我們的 APS-USCT 方法包含兩個主要組成部分：APS-wave 和 APS-FWI。APS-wave 組件是一個編碼器解碼器系統，它預先處理波形資料，將稀疏資料轉換為密集波形，以在重建之前增加取樣密度。APS-FWI 組件利用 InversionNet，直接從超音波波形資料重建音速 (SOS)。我們進一步透過結合 Squeeze-and-Excitation (SE) 區塊和原始編碼技術來提升模型效能。在乳癌資料集上測試我們的這個方法，得到了有前景的結果。它展現了傑出的效能，結構相似性指標 (SSIM) 平均為 0.8431。值得注意的是，超過 82% 的樣本達成 SSIM 高於 0.8，近 61% 超過 0.85，突顯了我們的方法在透過有效利用稀疏資料來改善 USCT 影像重建方面的顯著潛力。

##### **Addressing Imbalance for Class Incremental Learning in Medical Image Classification**
2407.13768v1 by Xuze Hao, Wenqian Ni, Xuhao Jiang, Weimin Tan, Bo Yan

Deep convolutional neural networks have made significant breakthroughs in
medical image classification, under the assumption that training samples from
all classes are simultaneously available. However, in real-world medical
scenarios, there's a common need to continuously learn about new diseases,
leading to the emerging field of class incremental learning (CIL) in the
medical domain. Typically, CIL suffers from catastrophic forgetting when
trained on new classes. This phenomenon is mainly caused by the imbalance
between old and new classes, and it becomes even more challenging with
imbalanced medical datasets. In this work, we introduce two simple yet
effective plug-in methods to mitigate the adverse effects of the imbalance.
First, we propose a CIL-balanced classification loss to mitigate the classifier
bias toward majority classes via logit adjustment. Second, we propose a
distribution margin loss that not only alleviates the inter-class overlap in
embedding space but also enforces the intra-class compactness. We evaluate the
effectiveness of our method with extensive experiments on three benchmark
datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our
approach outperforms state-of-the-art methods.

摘要：深度卷積神經網路在醫學影像分類方面取得了重大突破，假設所有類別的訓練樣本都能同時取得。然而，在現實世界的醫療場景中，通常需要持續學習新的疾病，導致醫療領域中類別增量學習 (CIL) 的新興領域。通常，CIL 在訓練新類別時會遭受災難性遺忘。這種現象主要是由於舊類別和新類別之間的不平衡造成的，而在不平衡的醫療資料集上，這會變得更具挑戰性。在這項工作中，我們介紹了兩種簡單但有效的外掛方法來減輕不平衡的負面影響。首先，我們提出一個 CIL 平衡分類損失，透過 logit 調整來減輕分類器對多數類別的偏見。其次，我們提出一個分佈邊際損失，它不僅可以減輕嵌入空間中的類間重疊，還可以加強類內緊密性。我們在三個基準資料集（CCH5000、HAM10000 和 EyePACS）上進行了廣泛的實驗，評估了我們方法的有效性。結果表明，我們的做法優於最先進的方法。

##### **Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**
2407.13689v1 by Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei

Heatwaves pose significant health risks, particularly due to prolonged
exposure to high summer temperatures. Vulnerable groups, especially pedestrians
and cyclists on sun-exposed sidewalks, motivate the development of a route
planning method that incorporates somatosensory temperature effects through
shade ratio consideration. This paper is the first to introduce a pipeline that
utilizes segmentation foundation models to extract shaded areas from
high-resolution satellite images. These areas are then integrated into a
multi-layered road map, enabling users to customize routes based on a balance
between distance and shade exposure, thereby enhancing comfort and health
during outdoor activities. Specifically, we construct a graph-based
representation of the road map, where links indicate connectivity and are
updated with shade ratio data for dynamic route planning. This system is
already implemented online, with a video demonstration, and will be
specifically adapted to assist travelers during the 2024 Olympic Games in
Paris.

摘要：熱浪造成顯著的健康風險，特別是長時間暴露在夏季的高溫下。容易受傷害的族群，尤其是行走在陽光直射人行道上的行人和自行車騎士，促成了規劃路線方法的發展，其中納入了透過遮陽率考量來產生的體感溫度影響。本文首次介紹一個利用分割基礎模型從高解析度衛星影像中擷取陰影區域的管線。這些區域接著整合到多層道路地圖中，使用戶能夠根據距離和遮陽曝曬之間的平衡來自訂路線，進而提升戶外活動時的舒適度和健康。具體來說，我們建構了一個以圖形為基礎的道路地圖表徵，其中連結表示連通性，並透過遮陽率資料更新以進行動態路線規劃。此系統已線上實作，並附有影片示範，且將特別調整以協助旅客參加 2024 年巴黎奧運。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v2](http://arxiv.org/abs/2406.16908v2)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|

#### Abstracts
##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：<paragraph>本文提出了用于视网膜眼底图像疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善与用于疾病分类的正常 ResNet 模型相比的感受野。本研究介绍了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医疗专业人员能够理解和信任 AI 的诊断决策。它们在当今医疗保健领域尤为重要，因为对 AI 应用程序的透明度需求不断增长，以确保其可靠性和道德使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼病的分类准确性并减少所需的计算时间。本工作中使用的数据集是 Ocular Disease Intelligent Recognition (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 分数。在这项工作中，对正常 ResNet 模型和扩张 ResNet 模型在五个变体（即 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152）之间进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 分数分别为 0.71、0.70、0.69、0.67 和 0.70。</paragraph>

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像上的快速進展代表著在增強診斷準確度和個人化治療方面邁出了一大步。然而，基礎模型在醫療保健中的部署需要嚴格檢查其可信度，包括隱私、穩健性、可靠性、可解釋性和公平性。當前關於醫學影像中基礎模型的調查文獻顯示出相當大的差距，特別是在可信度方面。此外，現有的關於基礎模型可信度的調查未能解決其在醫學影像領域內的具體變化和應用。這篇調查論文回顧了當前關於基礎模型在主要醫學影像應用中的研究，重點關注分割、醫療報告生成、醫療問題和解答 (Q&A) 以及疾病診斷，其中包括手稿中的可信度討論。我們探討了讓用於醫學影像分析的基礎模型值得信賴的複雜挑戰，與每個應用相關，並總結了當前提高可信度的問題和策略。此外，我們探討了這些模型在革新患者照護方面的未來前景。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，提倡一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v2 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒時期是大腦發育最脆弱的時期，會導致癲癇發作。癲癇發作會對未成熟的大腦造成不良後果，因此需要早期診斷。目前新生兒癲癇檢測的黃金標準依賴於連續視訊腦電圖監測；這包括在新生兒加護病房 (NICU) 內記錄多通道腦電圖 (EEG) 和即時視訊監測。然而，視訊腦電圖監測技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具有成本效益的新技術可以幫助醫療界做出準確的診斷，並立即提倡治療。在這項工作中，提出了一個新穎可解釋的深度學習模型，以自動化新生兒癲癇檢測過程，並減少腦電圖裝置，該模型採用卷積網路、圖注意力層和全連接層。除了能夠即時偵測減少裝置的癲癇發作外，此模型還提供即時可解釋性的獨特優勢。透過評估 Zenodo 資料集上的效能，並進行 10 倍交叉驗證，所提出的模型在曲線下面積 (AUC) 和召回率分別達到 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

摘要：<paragraph>人工智慧系統的說明很少能滿足受演算法決策 (ADM) 影響的人們的資訊需求。傳達的資訊與影響利害關係人重要的資訊之間的差距，可能會阻礙了解和遵守法規架構，例如人工智慧法案。為了解決這個差距，我們提出了「XAI 初學者問題庫」：受影響利害關係人資訊需求的目錄，涵蓋兩個 ADM 使用案例（就業預測和健康監測），涵蓋資料、系統脈絡、系統使用和系統規格類別。資訊需求是透過訪談研究收集的，參與者在詢問後收到說明。參與者進一步回報他們的理解和決策信心，顯示雖然在收到說明後信心傾向於增加，但參與者也遇到了理解挑戰，例如無法說明為什麼他們的理解感覺不完整。說明進一步影響參與者對系統風險和好處的看法，他們會根據使用案例確認或改變這些看法。當風險被認為很高時，參與者表示特別有興趣了解意圖的說明，例如為什麼以及為了什麼目的而建立系統。透過這項工作，我們旨在透過在決策採用 ADM 系統時提供相關資訊和挑戰的概覽，來支援將受影響的利害關係人納入可解釋性。我們最後總結我們的發現，列出六項關鍵影響，這些影響會告知未來針對受影響利害關係人受眾說明的設計。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 發展社群日益利用 Hugging Face 等託管中介，提供使用者上傳之模型與訓練資料的簡易取得管道。這些模型市集降低了數十萬名使用者的技術部署門檻，但卻可能被用於許多潛在有害且非法的用途。在本文中，我們說明了 AI 系統既可以「包含」內容，也可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以探討模型市集如何控管模型。根據此分析，我們概述了產業為回應控管需求而發展的重要（但仍有限）實務：授權、存取和使用限制、自動內容控管和開放式政策發展。儘管目前面臨的政策挑戰相當嚴峻，我們仍提出了一些想法，說明平台如何能更好地動員資源，作為謹慎、公平和適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫療領域中已取得顯著進展，在醫學影像、病人照護和其他領域中出現了新興應用。雖然這些應用已在回顧性研究中被證實是成功的，但實際上只有極少數應用於實務。醫療 AI 領域面臨著各種挑戰，包括建立使用者信任、遵守法規、使用資料符合倫理。可解釋 AI (XAI) 的目標是讓人類了解 AI 並相信其結果。本文針對最近幾年發表的 198 篇文章的具代表性樣本，提出有關醫療決策支援的 XAI 解決方案的最新發展的文獻回顧。相關文章的系統性綜合整理產生了多項發現：(1) 這些解決方案大多採用與模型無關的 XAI 技術，(2) 深度學習模型的使用率高於其他類型的機器學習模型，(3) 可解釋性被用於促進信任，但很少有研究報告醫師參與迴圈，(4) 視覺和互動式使用者介面對於理解系統的解釋和建議更有用。需要更多醫療和 AI 專家合作進行研究，這有助於為醫療領域的 XAI 解決方案的設計、實作和評估提供適當架構。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是治療不孕症最廣泛的方法之一。其主要挑戰之一是評估和選擇胚胎進行植入，此過程具有很大的臨床間和臨床內變異性。基於深度學習的方法正受到關注，但其不透明的性質會影響其在臨床環境中的接受度，而透明度在決策制定中至關重要。在本文中，我們分析了 AI 輔助胚胎分析模型的可解釋性方面的現有工作，並找出其局限性。我們還討論了如何將這些模型作為決策支持系統整合到臨床環境中，同時考慮臨床醫生和患者的需求。最後，我們提出了提高可解釋性和可信度的準則，推進這項技術朝著既定的臨床實務邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程 (RE) 領域中，可解釋人工智慧 (XAI) 在將 AI 支持的系統與使用者需求、社會期望和法規標準相符方面的重要性日益顯著，已獲得認可。一般來說，可解釋性已成為影響系統品質的重要非功能需求。然而，可解釋性與效能之間的假定權衡挑戰了可解釋性的假定正面影響。如果滿足可解釋性的需求需要降低系統效能，那麼必須仔細考慮這些品質面向中哪一個優先，以及如何在它們之間進行折衷。在本文中，我們批判性地探討了這種假定的權衡。我們認為，最好的方法是以一種細緻的方式來處理，這種方式包含資源可用性、領域特性和風險考量。透過提供未來研究和最佳實務的基礎，這項工作旨在提升 AI 的 RE 領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schlüter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）领域，可解释人工智能（XAI）在将人工智能支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益凸显，并获得了认可。一般来说，可解释性已成为影响系统质量的重要非功能性需求。然而，可解释性和性能之间的权衡挑战了可解释性的正面影响。如果满足可解释性的要求需要降低系统性能，那么必须仔细考虑这些质量方面中的哪一个优先，以及如何在它们之间进行权衡。在本文中，我们批判性地考察了所谓的权衡。我们认为，最好以一种细致入微的方式来处理它，这种方式结合了资源可用性、领域特征和风险考虑。通过为未来的研究和最佳实践提供基础，这项工作旨在推进人工智能的 RE 领域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文嚴格評估歐洲委員會提出的 AI 法案對風險管理和風險可接受性的方法，用於對基本權利和安全構成風險的高風險 AI 系統。該法案旨在以相稱的監管負擔促進「值得信賴」的 AI。其關於風險可接受性的條款要求將高風險系統的殘餘風險減低或消除「盡可能」，並考慮「技術狀態」。此準則，特別是如果狹義解釋，無法執行，既不促進相稱的監管負擔，也不促進可信賴性。相比之下，議會對風險管理條款的最新修正草案引入了「合理性」、成本效益分析，並且更透明地說明了風險可接受性判斷的價值觀和背景性質。本文論證議會的方法更可行，且能更好地平衡相稱性和可信賴性的目標。本文說明風險可接受性判斷中的合理性會帶來什麼，並根據過失法和歐洲醫療器材法規中的原則進行說明。本文主張風險可接受性判斷的方法需要穩固的公民合法性基礎：包括監管機構的詳細指導或參與，以及受影響利害關係人的有意義投入。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：可解釋人工智慧 (XAI) 是機器學習中快速進展的領域，旨在解開複雜模型的預測。XAI 在敏感應用中特別需要，例如在醫療保健中，當診斷、建議和治療選擇可能依賴於人工智慧系統做出的決策時。人工智慧方法也已廣泛用於老化研究，特別是在開發生物時鐘模型和識別老化和與年齡相關疾病的生物標誌物方面。然而，這裡 XAI 的潛力有待充分認識。我們討論了 XAI 在開發「老化時鐘」方面的應用，並對按特定生理系統的重點分類的文獻進行了全面的分析。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, Jörg Schlötterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋設計的影像分類器，也是黑箱 AI 的一個有前途的替代方案。這篇論文探討了解釋性機器學習，特別是 PIP-Net，在真實世界醫學影像資料上自動化診斷支援的適用性和潛力。PIP-Net 學習人類可理解的原型影像部分，我們評估其在骨折檢測和皮膚癌診斷方面的準確性和可解釋性。我們發現 PIP-Net 的決策制定過程符合醫學分類標準，同時僅提供影像層級類別標籤。由於 PIP-Net 對原型的無監督預訓練，因此可以輕鬆識別資料品質問題，例如 X 光中的不需要文字或標籤錯誤。此外，我們首次展示人類可以透過直接停用不需要的原型來手動修正 PIP-Net 的推理。我們得出結論，部分原型模型由於其可解釋性和進階模型除錯的潛力，因此有望應用於醫療。

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

摘要：可解釋 AI (XAI) 是機器學習研究中日益重要的領域，其目標是讓黑箱模型透明且可解釋。在本文中，我們提出了一種新的 XAI 方法，該方法使用由特徵條件置換產生的所謂反事實路徑。該演算法透過識別特徵的順序置換來衡量特徵重要性，這些置換最能影響模型預測的變化。它特別適合根據包含領域知識的知識圖譜中的反事實路徑來產生解釋。反事實路徑在解釋和視覺化黑箱模型時，為目前的 XAI 方法引入了額外的圖形維度。使用合成和醫療資料進行的實驗證明了我們方法的實用適用性。

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

摘要：在人工智能 (AI) 的可解釋性領域中，已經看到越來越多的研究和學術興趣。然而，在解釋機器學習演算法的結果時缺乏人性化和個人化的詮釋，這顯著阻礙了臨床醫生在研究和臨床實務中接受這些方法。為了解決這個問題，我們的研究使用反事實解釋來探討「如果？」情境在醫學研究中的適用性。我們的目標是擴展我們對用於診斷小兒後顱窩腦腫瘤的磁共振成像 (MRI) 特徵的理解，超越現有的界線。在我們的案例研究中，所提出的概念提供了一種新穎的方法來檢視替代決策情境，提供個人化和特定於情境的見解，從而能夠驗證預測並釐清在不同情況下的差異。此外，我們探討了反事實用於資料擴充的潛在用途，並評估其作為我們醫學研究案例中替代方法的可行性。結果證明了使用反事實解釋來增強臨床研究中 AI 驅動方法的接受度的潛力。

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

摘要：目前人工智能領域的進展導致了各種類型的人工智慧驅動的失智症評估的發展，可用於識別處於失智症早期階段的患者。它可以徹底改變失智症護理設置。重要的是，醫療界要了解各種人工智能評估，並根據其有效性、效率、實用性、可靠性和準確性程度，考慮選擇它們來早期識別失智症患者 (PwD)。另一方面，人工智能開發人員也應該了解各種非人工智能評估以及最近開發的人工智能評估。因此，這篇臨床醫生和人工智能工程師都可以閱讀的論文填補了文獻中關於向臨床醫生解釋現有失智症識別解決方案以及向人工智能工程師解釋所用技術和最廣泛的失智症數據集的空白。它遵循對人工智能和非人工智能失智症評估論文的回顧，為人工智能和醫療界提供有關各種失智症評估的寶貴信息。討論和結論重點介紹了最突出的研究方向和現有解決方案的成熟度。

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

摘要：<paragraph>可解釋性對人工智慧 (AI) 技術構成一項重大挑戰。當前對可解釋 AI (XAI) 的研究缺乏提取學習任務整體知識的效率，因此存在不精確的顯著性、與情境無關的缺失和含糊意義等缺陷。在本文中，我們提出類別關聯嵌入 (CAE) 方法來解決這些問題。我們採用編碼器-解碼器架構來嵌入樣本特徵，並同時將它們分為類別相關和個體相關的樣式向量。將給定樣本的個體樣式代碼與另一個樣本的類別樣式代碼重新組合，會產生一個具有保留個體特徵但改變類別分配的合成樣本，遵循循環對抗學習策略。類別關聯嵌入將所有實例的全局類別相關特徵提煉到一個統一的領域中，並在類別之間有良好的區分。然後可以提取不同類別之間的轉換規則，並進一步應用於個別實例。然後，我們提出一個主動 XAI 框架，它沿著引導路徑操作特定樣本的類別樣式向量，朝著反類別移動，從而產生一系列具有相同個體特徵的反例合成樣本。將這些反事實樣本與原始樣本進行比較，可以對分類任務的性質提供全局、直觀的說明。我們採用該框架進行醫學影像分類任務，結果表明，與現有方法相比，可以獲得更精確的顯著性圖，並具有強大的與情境無關的表示。此外，疾病病理學可以直接通過在類別樣式空間中遍歷路徑來進行可視化。</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, Iñigo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

摘要：提供基於機器學習的 AI 預測的高品質說明是一項具有挑戰性和複雜性的任務。要順利進行，它需要具備下列因素：選擇適當的說明普遍性/特殊性層級；考量說明受益人對所考慮的 AI 任務的熟悉程度假設；參照促成決策的特定元素；利用可能不屬於預測程序的一部分的額外知識（例如專家證據）；並提供支持否定假設的證據。最後，系統需要以清晰可解釋且可能令人信服的方式制定說明。基於這些考量，ANTIDOTE 促成了可解釋 AI 的整合願景，其中深度學習程序的低階特徵與人類論證能力的高階架構相結合。ANTIDOTE 將利用深度學習與論證的跨領域能力，來支持可解釋 AI 更廣泛且創新的觀點，其中對臨床案例審議的高品質說明需求至關重要。作為該專案的第一個成果，我們發布了 Antidote CasiMedicos 資料集，以利於一般可解釋 AI 的研究，特別是醫療領域的論證。

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

摘要：<paragraph>近年來，圖神經網路的進展迅速，在藥物發現、醫療診斷和推薦系統方面都有許多新發展。雖然這些進展很重要，但許多網路都是「黑盒子」，對於網路到底在學習「什麼」了解甚少。許多高風險應用，例如藥物發現，需要模型提供人類可以理解的解釋，以便使用者可以辨識錯誤並發現新知識。因此，可解釋 AI 演算法的開發對於我們獲取 AI 的好處至關重要。
我們提出了一種稱為 eXplainable Insight (XInsight) 的 GNN 可解釋性演算法，它使用 GFlowNets 產生模型解釋分佈。由於 GFlowNets 會產生機率與獎勵成正比的物件，因此與先前僅學習最大獎勵範例的方法相比，XInsight 可以產生多樣化的解釋集合。我們透過為在兩個圖形分類任務中訓練的 GNN 產生解釋來展示 XInsight：使用 MUTAG 資料集對致突變化合物進行分類，並使用我們已開放原始碼的合成資料集對非環狀圖形進行分類。我們透過使用 QSAR 建模分析產生的化合物來展示 XInsight 解釋的效用，我們發現 XInsight 會產生按親脂性（已知的致突變相關性）分群的化合物。我們的結果顯示 XInsight 會產生一個解釋分佈，揭示模型所展示的底層關係。它們也強調產生多樣化解釋集合的重要性，因為它使我們能夠發現模型中的隱藏關係，並為進一步分析提供有價值的指導。</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar Kadıoğlu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

摘要：我們提出並實作一個可解釋機器學習分類模型，用於基於表達式布林公式的可解釋 AI (XAI)。潛在應用包括信用評分和醫療狀況診斷。布林公式定義了一個具有可調整複雜性（或可解釋性）的規則，根據該規則對輸入數據進行分類。這樣的公式可以包含任何可應用於一個或多個布林變數的運算子，從而與更嚴格的基於規則和基於樹的方法相比，提供更高的表達能力。分類器使用原生局部最佳化技術進行訓練，有效地搜索可行公式的空間。淺層規則可以用快速的整數線性規劃 (ILP) 或二次無約束二元最佳化 (QUBO) 求解器來確定，這些求解器可能由特殊用途的硬體或量子裝置提供支援。我們將原生局部最佳化器的表達能力和效率與這些裝置的快速運算相結合，透過執行非局部移動來最佳化完整布林公式的子樹。我們提供廣泛的數值基準測試結果，其中包含在眾所周知的公共資料集上使用多個基線。根據結果，我們發現原生局部規則分類器通常與其他分類器具有競爭力。加入非局部移動以較少的反覆運算次數達成類似的結果，因此使用專用或量子硬體可能會透過快速提出非局部移動來加速。

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

摘要：為了解決心理健康問題的全球挑戰，我們提出一個基於邏輯神經網路 (LNN) 的神經符號 AI 方法來診斷心理疾病。由於缺乏有效的心理疾病治療涵蓋範圍，因此需要一種 AI 解決方案來協助治療師進行診斷。然而，目前的類神經網路模型缺乏可解釋性，治療師可能無法信任它們。LNN 是一種遞迴神經網路架構，它結合了神經網路的學習能力和基於經典邏輯的 AI 的推理能力。所提出的系統使用來自臨床訪談的輸入謂詞來輸出心理疾病類別，並使用不同的謂詞剪枝技術來實現可擴充性和更高的分數。此外，我們提供了一個見解提取方法來協助治療師進行診斷。所提出的系統解決了當前類神經網路模型缺乏可解釋性的問題，並為心理疾病診斷提供了更值得信賴的解決方案。

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

摘要：隨著機器學習模型在醫療診斷中越來越普遍，可解釋性和透明度的需求變得至關重要。XAI 復興標誌著該領域的重大轉變，旨在重新定義醫療診斷模型的可解釋性。本文探討了可解釋 AI (XAI) 領域內的創新方法和方法論，這些方法和方法論正在革新醫療診斷模型的可解釋性。通過闡明基礎決策制定過程，XAI 技術使醫療保健專業人員能夠理解、信任並有效地利用這些模型進行準確且可靠的醫療診斷。本綜述重點介紹了 XAI 在醫療診斷方面的關鍵進展及其轉變醫療保健領域的潛力，最終改善患者的治療效果並培養對 AI 驅動的診斷系統的信任。

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

摘要：<paragraph>在以高度連接性和流動性為特徵的環境中，加上心血管疾病的激增，通過遠程監控心血管健康來削減醫療保健支出的必要性變得更加明顯。準確檢測和分類心律不整對於診斷患有心臟不規則的人至關重要。本研究強調了在家中使用心電圖 (ECG) 測量進行實時心律不整檢測的可行性。本文提出了一種新的心律不整檢測應用，利用尖端的 You-Only-Look-Once (YOLO)v8 演算法對單導聯 ECG 訊號進行分類。我們引入了一個新穎的損失修改 YOLOv8 模型，並針對 MIT-BIH 心律不整資料集進行了微調，從而實現了實時的持續監控。獲得的結果證實了我們方法的有效性，該模型在 NVIDIA Tesla V100 上達到了 99.5% 的平均準確度和 0.992 mAP@50，以及 0.002 秒的快速檢測時間。我們的研究說明了實時心律不整檢測的潛力，使用戶能夠在家中舒適地視覺化解讀模型輸出。此外，本研究為擴展到實時可解釋 AI (XAI) 模型奠定了基礎，該模型能夠部署在醫療保健領域，從而顯著推進醫療保健解決方案的領域。</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

摘要：乳癌（BC）仍然是一個重大的健康威脅，目前尚無長期治癒的方法。早期發現至關重要，但乳房攝影的判讀卻受到高假陽性和假陰性的阻礙。由於乳癌的發生率預計將超過肺癌，因此改善早期檢測方法至關重要。熱像攝影使用高解析度紅外線相機，特別是在與人工智慧（AI）結合使用時，提供了希望。這項工作提出了一個基於注意力的卷積神經網路用於分割，在乳癌檢測和分類中提供了更高的速度和精度。該系統增強影像並執行可解釋的 AI 癌症分割。我們提出了一個基於Transformer注意力的卷積架構（UNet）用於故障識別，並使用梯度加權類激活映射（Grad-CAM）來分析 UNet 架構中偏見和弱點的區域，使用 IRT 影像。與現有的深度學習框架相比，我們提出的框架的優越性得到證實。

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

摘要：憂鬱症是最普遍且嚴重的精神疾病，會造成嚴重的財務和社會後果。憂鬱症的偵測對於早期介入以減輕這些後果至關重要。如此重大的決定本質上需要可解釋性。儘管一些憂鬱症偵測研究嘗試根據重要性分數或注意力權重來解釋這個決定，但這些解釋與基於憂鬱症狀的臨床憂鬱症診斷標準不一致。為了填補這個缺口，我們遵循計算設計科學範例來開發一個新穎的多尺度時間原型網路 (MSTPNet)。MSTPNet 創新地偵測並解釋憂鬱症狀以及它們持續多久。使用大規模資料集進行的廣泛實證分析顯示，MSTPNet 以 0.851 的 F1 分數優於最先進的憂鬱症偵測方法。此結果還揭示了調查方法中未注意到的新症狀，例如分享對不同生活的欽佩。我們進一步進行使用者研究，以證明其在可解釋性方面優於基準。本研究以一個新穎的可解釋深度學習模型為憂鬱症偵測在社群媒體中的 IS 文獻做出貢獻。在實務上，我們提出的方法可以實作在社群媒體平台中，以提供個人化的線上資源給被偵測出憂鬱症的患者。

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

摘要：電子健康紀錄 (EHR) 作為預想中由人工智慧 (AI) 推動的醫療保健轉型的重要資料來源。然而，反映在 EHR 備註中的臨床偏見可能導致 AI 模型繼承並擴大這些偏見，進而造成健康差異。本研究探討 EHR 備註中汙名化語言 (SL) 對使用基於 Transformer 的深度學習模型和可解釋 AI (XAI) 技術預測死亡率的影響。我們的研究結果表明，由臨床醫生撰寫的 SL 會對 AI 效能產生不利影響，特別是對黑人患者而言，突顯 SL 是 AI 模型開發中種族差異的來源。為了探索一種運作上有效率的方法來減輕 SL 的影響，我們透過臨床醫生的協作網路探討 SL 產生的模式，並找出核心臨床醫生對 AI 模型中的種族差異有較大的影響。我們發現，移除由核心臨床醫生撰寫的 SL 是比消除資料集中所有 SL 更有效率的偏見減少策略。本研究提供可行的見解，用於負責任的 AI 開發，並有助於了解臨床醫生行為和醫療保健中的 EHR 備註撰寫。

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

摘要：當代通過 AI 的自動化需要大量的幕後人力，這通常既不可見且薪資過低。由於不可見的勞動，包括標籤和維護工作，是當代 AI 系統的組成部分，因此讓使用者了解其角色仍然很重要。我們建議這可以透過可解釋的 AI（XAI）設計來完成，特別是女性主義交叉的 XAI。我們提出源自女性主義交叉研究的製圖方法，以提出 AI 的系統觀點，並納入與不可見勞動相關的 AI 維度。

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

摘要：虛擬心理健康助理 (VMHA) 持續進步，以支援每年有 6000 萬人次初級保健就診和 600 萬人次急診室 (ER) 就診的超負荷全球醫療保健系統。這些系統是由臨床心理學家、精神科醫師和人工智慧 (AI) 研究人員為認知行為療法 (CBT) 所建構。目前，VMHA 的角色是透過資訊提供情緒支持，較少著重於與患者發展反思性的對話。需要更全面、安全且可解釋的方法來建構負責任的 VMHA，以提出後續問題或提供充分的回應。這項調查提供了對心理健康中現有對話代理的系統性批判性回顧，接著深入探討了 VMHA 在脈絡知識、資料集和其在臨床決策支援中新興角色的改進。我們也提供了新的方向，以透過可解釋性、安全性與整體可信度來豐富 VMHA 的使用者體驗。最後，我們提供了評量指標和 VMHA 的實務考量，超越目前的文獻，在 VMHA 與患者的積極溝通中建立信任。

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

摘要：XAI 指的是用於建構 AI 應用程式的技術和方法，這些應用程式可協助最終使用者詮釋 AI 模型的輸出和預測。在高風險決策情境中，例如醫療領域，黑箱 AI 應用程式增加了透明度和可解釋性的需求，因為錯誤的預測可能會造成嚴重的後果。模型可解釋性和可詮釋性對於在醫療實務中成功部署 AI 模型至關重要。AI 應用程式的基本推理需要對臨床醫生透明，才能獲得他們的信任。本文提供了醫療領域中 XAI 面向和挑戰的系統性回顧。本研究的主要目標是回顧各種 XAI 方法、其挑戰，以及相關的醫療保健機器學習模型。這些方法分為六類討論：面向特徵的方法、整體方法、概念模型、代理模型、局部基於像素的方法，以及以人為中心的方法。最重要的是，本文探討了 XAI 在醫療保健問題中的角色，以釐清其在安全關鍵應用中的必要性。本文旨在透過回顧相關的實驗結果，建立對醫療保健領域中 XAI 相關應用程式的全面了解。為了促進未來研究填補研究差距，本文探討了 XAI 模型從不同觀點來看的重要性及其限制。

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

摘要：最先进的机器学习模型通常会学习训练数据中嵌入的虚假关联。这在将这些模型部署于高风险决策时会带来风险，例如在皮肤癌检测等医学应用中。为了解决这个问题，我们提出了 Reveal to Revise (R2R)，一个涵盖整个可解释人工智能 (XAI) 生命周期的框架，使从业者能够以最少的人工交互迭代识别、缓解和（重新）评估虚假模型行为。在第一步 (1) 中，R2R 通过找出归因中的异常值或通过检查模型学习的潜在概念来揭示模型的弱点。其次 (2)，检测负责的伪像并在输入数据中进行空间定位，然后利用它来 (3) 修改模型行为。具体来说，我们应用 RRR、CDEP 和 ClArC 的方法来进行模型校正，并 (4)（重新）评估模型的性能和对伪像的剩余敏感性。使用两个用于黑色素瘤检测和骨龄估计的医学基准数据集，我们将我们的 R2R 框架应用于 VGG、ResNet 和 EfficientNet 架构，从而揭示和纠正了真实数据集固有的伪像，以及受控设置中的合成变体。完成 XAI 生命周期，我们演示了多个 R2R 迭代以减轻不同的偏差。代码可在 https://github.com/maxdreyer/Reveal2Revise 上找到。

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, Grégoire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

摘要：可解釋人工智慧 (XAI) 領域在近年來取得長足進步，但進展主要是在電腦視覺和自然語言處理方面。對於輸入通常無法解釋的時間序列，只有有限的研究可供使用 XAI。在這項工作中，我們提出了一個虛擬檢查層，它將時間序列轉換為可解釋的表示，並允許通過層級相關性傳播 (LRP) 等局部 XAI 方法將相關性歸因傳播到此表示。藉此，我們將一系列 XAI 方法的適用性擴展到輸入僅在轉換後才能解釋的領域（例如語音）。在此，我們專注於傅立葉轉換，它主要應用於時間序列和 LRP 的解釋，並將我們的稱之為 DFT-LRP。我們展示了 DFT-LRP 在各種時間序列分類設定（例如音訊和電子健康紀錄）中的效用。我們展示了 DFT-LRP 如何揭示在不同領域（例如時間與頻率域）訓練的模型的分類策略差異，或有助於發現模型如何處理資料中的虛假關聯。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-01**|**MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities**|Weihao Yu et.al.|[2408.00765v1](http://arxiv.org/abs/2408.00765v1)|null|
|**2024-08-01**|**AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation**|Mengkang Hu et.al.|[2408.00764v1](http://arxiv.org/abs/2408.00764v1)|null|
|**2024-08-01**|**Tamper-Resistant Safeguards for Open-Weight LLMs**|Rishub Tamirisa et.al.|[2408.00761v1](http://arxiv.org/abs/2408.00761v1)|null|
|**2024-08-01**|**Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**|Susung Hong et.al.|[2408.00760v1](http://arxiv.org/abs/2408.00760v1)|null|
|**2024-08-01**|**Segment anything model 2: an application to 2D and 3D medical images**|Haoyu Dong et.al.|[2408.00756v1](http://arxiv.org/abs/2408.00756v1)|null|
|**2024-08-01**|**DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency**|Jovan Stojkovic et.al.|[2408.00741v1](http://arxiv.org/abs/2408.00741v1)|null|
|**2024-08-01**|**CERT-ED: Certifiably Robust Text Classification for Edit Distance**|Zhuoqun Huang et.al.|[2408.00728v1](http://arxiv.org/abs/2408.00728v1)|null|
|**2024-08-01**|**Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**|Guangzhi Xiong et.al.|[2408.00727v1](http://arxiv.org/abs/2408.00727v1)|null|
|**2024-08-01**|**An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**|Yangzhen Wu et.al.|[2408.00724v1](http://arxiv.org/abs/2408.00724v1)|null|
|**2024-08-01**|**Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities**|Sunder Ali Khowaja et.al.|[2408.00722v1](http://arxiv.org/abs/2408.00722v1)|null|
|**2024-08-01**|**SAM 2: Segment Anything in Images and Videos**|Nikhila Ravi et.al.|[2408.00714v1](http://arxiv.org/abs/2408.00714v1)|null|
|**2024-08-01**|**Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification**|Amarpal Sahota et.al.|[2408.00711v1](http://arxiv.org/abs/2408.00711v1)|null|
|**2024-08-01**|**Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**|Xiaofeng Liu et.al.|[2408.00706v1](http://arxiv.org/abs/2408.00706v1)|null|
|**2024-08-01**|**Future of Artificial Intelligence in Agile Software Development**|Mariyam Mahboob et.al.|[2408.00703v1](http://arxiv.org/abs/2408.00703v1)|null|
|**2024-08-01**|**Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning**|Trapoom Ukarapol et.al.|[2408.00690v1](http://arxiv.org/abs/2408.00690v1)|null|
|**2024-08-01**|**Can Developers Prompt? A Controlled Experiment for Code Documentation Generation**|Hans-Alexander Kruse et.al.|[2408.00686v1](http://arxiv.org/abs/2408.00686v1)|null|
|**2024-08-01**|**Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index**|Anubhab Majumder et.al.|[2408.00684v1](http://arxiv.org/abs/2408.00684v1)|null|
|**2024-08-01**|**Learning in Multi-Objective Public Goods Games with Non-Linear Utilities**|Nicole Orzan et.al.|[2408.00682v1](http://arxiv.org/abs/2408.00682v1)|null|
|**2024-08-01**|**Leveraging Entailment Judgements in Cross-Lingual Summarisation**|Huajian Zhang et.al.|[2408.00675v1](http://arxiv.org/abs/2408.00675v1)|null|
|**2024-08-01**|**SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models**|Hongjun An et.al.|[2408.00655v1](http://arxiv.org/abs/2408.00655v1)|null|
|**2024-08-01**|**AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation**|Asbjørn Munk et.al.|[2408.00640v1](http://arxiv.org/abs/2408.00640v1)|null|
|**2024-08-01**|**DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**|Guillermo Villar-Rodríguez et.al.|[2408.00633v1](http://arxiv.org/abs/2408.00633v1)|null|
|**2024-08-01**|**SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data**|Yichen Lu et.al.|[2408.00624v1](http://arxiv.org/abs/2408.00624v1)|null|
|**2024-08-01**|**Are Bigger Encoders Always Better in Vision Large Models?**|Bozhou Li et.al.|[2408.00620v1](http://arxiv.org/abs/2408.00620v1)|null|
|**2024-08-01**|**Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review**|Amruta Mahuli et.al.|[2408.00613v1](http://arxiv.org/abs/2408.00613v1)|null|
|**2024-08-01**|**Downstream bias mitigation is all you need**|Arkadeep Baksi et.al.|[2408.00612v1](http://arxiv.org/abs/2408.00612v1)|null|
|**2024-08-01**|**Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses**|Gabriele Sarti et.al.|[2408.00584v1](http://arxiv.org/abs/2408.00584v1)|null|
|**2024-08-01**|**Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation**|Xiaoye Qu et.al.|[2408.00555v1](http://arxiv.org/abs/2408.00555v1)|null|
|**2024-08-01**|**Mitigating Multilingual Hallucination in Large Vision-Language Models**|Xiaoye Qu et.al.|[2408.00550v1](http://arxiv.org/abs/2408.00550v1)|null|
|**2024-08-01**|**Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model**|Felipe Mahlow et.al.|[2408.00544v1](http://arxiv.org/abs/2408.00544v1)|null|
|**2024-08-01**|**The Energy Cost of Artificial Intelligence of Things Lifecycle**|Shih-Kai Chou et.al.|[2408.00540v1](http://arxiv.org/abs/2408.00540v1)|null|
|**2024-08-01**|**Intermittent Semi-working Mask: A New Masking Paradigm for LLMs**|Mingcong Lu et.al.|[2408.00539v1](http://arxiv.org/abs/2408.00539v1)|null|
|**2024-08-01**|**The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement**|Thales Bertaglia et.al.|[2408.00534v1](http://arxiv.org/abs/2408.00534v1)|null|
|**2024-08-01**|**Jailbreaking Text-to-Image Models with LLM-Based Agents**|Yingkai Dong et.al.|[2408.00523v1](http://arxiv.org/abs/2408.00523v1)|null|
|**2024-08-01**|**A new approach for encoding code and assisting code understanding**|Mengdan Fan et.al.|[2408.00521v1](http://arxiv.org/abs/2408.00521v1)|null|
|**2024-08-01**|**GalleryGPT: Analyzing Paintings with Large Multimodal Models**|Yi Bin et.al.|[2408.00491v1](http://arxiv.org/abs/2408.00491v1)|null|
|**2024-08-01**|**Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation**|Chu Zhao et.al.|[2408.00490v1](http://arxiv.org/abs/2408.00490v1)|null|
|**2024-08-01**|**A Systematic Review on Long-Tailed Learning**|Chongsheng Zhang et.al.|[2408.00483v1](http://arxiv.org/abs/2408.00483v1)|null|
|**2024-08-01**|**HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**|Bolin Zhang et.al.|[2408.00481v1](http://arxiv.org/abs/2408.00481v1)|null|
|**2024-08-01**|**Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach**|Pedro Ramoneda et.al.|[2408.00473v1](http://arxiv.org/abs/2408.00473v1)|null|
|**2024-08-01**|**DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration**|Chengbo Zheng et.al.|[2408.00447v1](http://arxiv.org/abs/2408.00447v1)|null|
|**2024-08-01**|**Ontological Relations from Word Embeddings**|Mathieu d'Aquin et.al.|[2408.00444v1](http://arxiv.org/abs/2408.00444v1)|null|
|**2024-08-01**|**Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval**|Gangyan Zeng et.al.|[2408.00441v1](http://arxiv.org/abs/2408.00441v1)|null|
|**2024-08-01**|**A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality**|M. Mehdi Kholoosi et.al.|[2408.00435v1](http://arxiv.org/abs/2408.00435v1)|null|
|**2024-08-01**|**CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images**|Thiziri Nait Saada et.al.|[2408.00427v1](http://arxiv.org/abs/2408.00427v1)|null|
|**2024-08-01**|**MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition**|Wenqing Gan et.al.|[2408.00420v1](http://arxiv.org/abs/2408.00420v1)|null|
|**2024-08-01**|**DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving**|Xuemeng Yang et.al.|[2408.00415v1](http://arxiv.org/abs/2408.00415v1)|null|
|**2024-08-01**|**In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation**|Armel Zebaze et.al.|[2408.00397v1](http://arxiv.org/abs/2408.00397v1)|null|
|**2024-08-01**|**Enhancing Whole Slide Pathology Foundation Models through Stain Normalization**|Juseung Yun et.al.|[2408.00380v1](http://arxiv.org/abs/2408.00380v1)|null|
|**2024-08-01**|**On the Limitations and Prospects of Machine Unlearning for Generative AI**|Shiji Zhou et.al.|[2408.00376v1](http://arxiv.org/abs/2408.00376v1)|null|
|**2024-08-01**|**Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving**|Xi Chen et.al.|[2408.00374v1](http://arxiv.org/abs/2408.00374v1)|null|
|**2024-08-01**|**DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework**|Fan Zhang et.al.|[2408.00370v1](http://arxiv.org/abs/2408.00370v1)|null|
|**2024-08-01**|**Multimodal Fusion and Coherence Modeling for Video Topic Segmentation**|Hai Yu et.al.|[2408.00365v1](http://arxiv.org/abs/2408.00365v1)|null|
|**2024-08-01**|**DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model**|Nan Xie et.al.|[2408.00357v1](http://arxiv.org/abs/2408.00357v1)|null|
|**2024-08-01**|**DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training**|Yu Xie et.al.|[2408.00355v1](http://arxiv.org/abs/2408.00355v1)|null|
|**2024-08-01**|**A Simple Background Augmentation Method for Object Detection with Diffusion Model**|Yuhang Li et.al.|[2408.00350v1](http://arxiv.org/abs/2408.00350v1)|null|
|**2024-08-01**|**Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**|Sungmin Kang et.al.|[2408.00347v1](http://arxiv.org/abs/2408.00347v1)|null|
|**2024-08-01**|**Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerce**|Houye Ji et.al.|[2408.00346v1](http://arxiv.org/abs/2408.00346v1)|null|
|**2024-08-01**|**OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack**|Kuo Gai et.al.|[2408.00329v1](http://arxiv.org/abs/2408.00329v1)|null|
|**2024-08-01**|**ADBM: Adversarial diffusion bridge model for reliable adversarial purification**|Xiao Li et.al.|[2408.00315v1](http://arxiv.org/abs/2408.00315v1)|null|
|**2024-08-01**|**ABC Align: Large Language Model Alignment for Safety & Accuracy**|Gareth Seneque et.al.|[2408.00307v1](http://arxiv.org/abs/2408.00307v1)|null|
|**2024-08-01**|**Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck**|Yuntao Shou et.al.|[2408.00295v1](http://arxiv.org/abs/2408.00295v1)|null|
|**2024-08-01**|**Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**|Bin Cheng et.al.|[2408.00290v1](http://arxiv.org/abs/2408.00290v1)|null|
|**2024-08-01**|**Gradient Harmonization in Unsupervised Domain Adaptation**|Fuxiang Huang et.al.|[2408.00288v1](http://arxiv.org/abs/2408.00288v1)|null|
|**2024-08-01**|**Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation**|Xinhan Di et.al.|[2408.00284v1](http://arxiv.org/abs/2408.00284v1)|null|
|**2024-08-01**|**Navigating Text-to-Image Generative Bias across Indic Languages**|Surbhi Mittal et.al.|[2408.00283v1](http://arxiv.org/abs/2408.00283v1)|null|
|**2024-08-01**|**QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression**|Wenshan Wang et.al.|[2408.00274v1](http://arxiv.org/abs/2408.00274v1)|null|
|**2024-08-01**|**Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding**|Bin Xiao et.al.|[2408.00264v1](http://arxiv.org/abs/2408.00264v1)|null|
|**2024-08-01**|**RoCo:Robust Collaborative Perception By Iterative Object Matching and Pose Adjustment**|Zhe Huang et.al.|[2408.00257v1](http://arxiv.org/abs/2408.00257v1)|null|
|**2024-08-01**|**Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms**|Tian Meng et.al.|[2408.00244v1](http://arxiv.org/abs/2408.00244v1)|null|
|**2024-08-01**|**Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models**|Juntu Zhao et.al.|[2408.00230v1](http://arxiv.org/abs/2408.00230v1)|null|
|**2024-08-01**|**Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation**|Kohei Matsuura et.al.|[2408.00205v1](http://arxiv.org/abs/2408.00205v1)|null|
|**2024-08-01**|**OmniParser for Pure Vision Based GUI Agent**|Yadong Lu et.al.|[2408.00203v1](http://arxiv.org/abs/2408.00203v1)|null|
|**2024-07-31**|**Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models**|Elijah Pelofske et.al.|[2408.00197v1](http://arxiv.org/abs/2408.00197v1)|null|
|**2024-07-31**|**S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**|Andrea Kim et.al.|[2408.00191v1](http://arxiv.org/abs/2408.00191v1)|null|
|**2024-07-31**|**Finch: Prompt-guided Key-Value Cache Compression**|Giulio Corallo et.al.|[2408.00167v1](http://arxiv.org/abs/2408.00167v1)|null|
|**2024-07-31**|**A Taxonomy of Stereotype Content in Large Language Models**|Gandalf Nicolas et.al.|[2408.00162v1](http://arxiv.org/abs/2408.00162v1)|null|
|**2024-07-31**|**Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting**|Ying Li et.al.|[2408.00161v1](http://arxiv.org/abs/2408.00161v1)|null|
|**2024-07-31**|**StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization**|Kaiyuan Tang et.al.|[2408.00150v1](http://arxiv.org/abs/2408.00150v1)|null|
|**2024-07-31**|**Formal Ethical Obligations in Reinforcement Learning Agents: Verification and Policy Updates**|Colin Shea-Blymyer et.al.|[2408.00147v1](http://arxiv.org/abs/2408.00147v1)|null|
|**2024-07-31**|**Distributed In-Context Learning under Non-IID Among Clients**|Siqi Liang et.al.|[2408.00144v1](http://arxiv.org/abs/2408.00144v1)|null|
|**2024-07-31**|**Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment**|Sangwon Yu et.al.|[2408.00137v1](http://arxiv.org/abs/2408.00137v1)|null|
|**2024-07-31**|**Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions**|Patrick Kuiper et.al.|[2408.00131v1](http://arxiv.org/abs/2408.00131v1)|null|
|**2024-07-31**|**Semantic Codebook Learning for Dynamic Recommendation Models**|Zheqi Lv et.al.|[2408.00123v1](http://arxiv.org/abs/2408.00123v1)|null|
|**2024-07-31**|**A Course Shared Task on Evaluating LLM Output for Clinical Questions**|Yufang Hou et.al.|[2408.00122v1](http://arxiv.org/abs/2408.00122v1)|null|
|**2024-07-31**|**Gemma 2: Improving Open Language Models at a Practical Size**|Gemma Team et.al.|[2408.00118v1](http://arxiv.org/abs/2408.00118v1)|null|
|**2024-07-31**|**Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs**|Kewei Cheng et.al.|[2408.00114v1](http://arxiv.org/abs/2408.00114v1)|null|
|**2024-07-31**|**Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models**|Adam Karvonen et.al.|[2408.00113v1](http://arxiv.org/abs/2408.00113v1)|null|
|**2024-07-31**|**Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)**|Adam Gould et.al.|[2408.00108v1](http://arxiv.org/abs/2408.00108v1)|null|
|**2024-07-31**|**WAS: Dataset and Methods for Artistic Text Segmentation**|Xudong Xie et.al.|[2408.00106v1](http://arxiv.org/abs/2408.00106v1)|null|
|**2024-07-31**|**ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget**|Riccardo Orlando et.al.|[2408.00103v1](http://arxiv.org/abs/2408.00103v1)|null|
|**2024-07-31**|**From Attributes to Natural Language: A Survey and Foresight on Text-based Person Re-identification**|Fanzhi Jiang et.al.|[2408.00096v1](http://arxiv.org/abs/2408.00096v1)|null|
|**2024-07-31**|**Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey**|Atsuyuki Miyai et.al.|[2407.21794v1](http://arxiv.org/abs/2407.21794v1)|null|
|**2024-07-31**|**Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?**|Richard Ren et.al.|[2407.21792v1](http://arxiv.org/abs/2407.21792v1)|null|
|**2024-07-31**|**Vision-Language Model Based Handwriting Verification**|Mihir Chauhan et.al.|[2407.21788v1](http://arxiv.org/abs/2407.21788v1)|null|
|**2024-07-31**|**Large Language Monkeys: Scaling Inference Compute with Repeated Sampling**|Bradley Brown et.al.|[2407.21787v1](http://arxiv.org/abs/2407.21787v1)|null|
|**2024-07-31**|**The Llama 3 Herd of Models**|Abhimanyu Dubey et.al.|[2407.21783v1](http://arxiv.org/abs/2407.21783v1)|null|
|**2024-07-31**|**Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries**|Felix Ocker et.al.|[2407.21778v1](http://arxiv.org/abs/2407.21778v1)|null|
|**2024-07-31**|**ShieldGemma: Generative AI Content Moderation Based on Gemma**|Wenjun Zeng et.al.|[2407.21772v1](http://arxiv.org/abs/2407.21772v1)|null|
|**2024-07-31**|**MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts**|Xi Victoria Lin et.al.|[2407.21770v1](http://arxiv.org/abs/2407.21770v1)|null|

#### Abstracts
##### **MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities**
2408.00765v1 by Weihao Yu, Zhengyuan Yang, Linfeng Ren, Linjie Li, Jianfeng Wang, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang, Xinchao Wang

MM-Vet, with open-ended vision-language questions targeting at evaluating
integrated capabilities, has become one of the most popular benchmarks for
large multimodal model evaluation. MM-Vet assesses six core vision-language
(VL) capabilities: recognition, knowledge, spatial awareness, language
generation, OCR, and math. However, its question format is restricted to single
image-text pairs, lacking the interleaved image and text sequences prevalent in
real-world scenarios. To address this limitation, we introduce MM-Vet v2, which
includes a new VL capability called "image-text sequence understanding",
evaluating models' ability to process VL sequences. Furthermore, we maintain
the high quality of evaluation samples while further expanding the evaluation
set size. Using MM-Vet v2 to benchmark large multimodal models, we found that
Claude 3.5 Sonnet is the best model with a score of 71.8, slightly
outperforming GPT-4o which scored 71.0. Among open-weight models,
InternVL2-Llama3-76B leads with a score of 68.4.

摘要：MM-Vet 透過針對評估整合能力而設計的開放式視覺語言問題，已成為大型多模態模型評估最受歡迎的基準之一。MM-Vet 評估六項核心視覺語言 (VL) 能力：辨識、知識、空間意識、語言生成、OCR 和數學。然而，其問題格式僅限於單一影像文字對，缺乏真實世界場景中普遍存在的交錯影像和文字序列。為了解決此限制，我們引入了 MM-Vet v2，其中包含稱為「影像文字序列理解」的新 VL 能力，用於評估模型處理 VL 序列的能力。此外，我們在進一步擴充評估集大小的同時，維持評估範例的高品質。我們使用 MM-Vet v2 對大型多模態模型進行基準測試，發現 Claude 3.5 Sonnet 是最佳模型，得分為 71.8，略優於 GPT-4o 的 71.0 分。在開放權重模型中，InternVL2-Llama3-76B 以 68.4 分領先。

##### **AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation**
2408.00764v1 by Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang

Large Language Model (LLM) based agents have garnered significant attention
and are becoming increasingly popular. Furthermore, planning ability is a
crucial component of an LLM-based agent, involving interaction with the
environment and executing actions to complete a planning task, which generally
entails achieving a desired goal from an initial state. This paper investigates
enhancing the planning abilities of LLMs through instruction tuning, referred
to as agent training. Recent studies have demonstrated that utilizing
expert-level trajectory for instruction-tuning LLMs effectively enhances their
planning capabilities. However, existing work primarily focuses on synthesizing
trajectories from manually designed planning tasks and environments. The
labor-intensive nature of creating these environments and tasks impedes the
generation of sufficiently varied and extensive trajectories. To address this
limitation, this paper explores the automated synthesis of diverse environments
and a gradual range of planning tasks, from easy to difficult. We introduce a
framework, AgentGen, that leverages LLMs first to generate environments and
subsequently generate planning tasks conditioned on these environments.
Specifically, to improve environmental diversity, we propose using an
inspiration corpus composed of various domain-specific text segments as the
context for synthesizing environments. Moreover, to increase the difficulty
diversity of generated planning tasks, we propose a bidirectional evolution
method, Bi-Evol, that evolves planning tasks from easier and harder directions
to synthesize a task set with a smoother difficulty curve. The evaluation
results derived from AgentBoard show that AgentGen greatly improves LLMs'
planning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses
GPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms
GPT-4.

摘要：大型語言模型 (LLM) 基於代理已引起廣泛關注，並正變得越來越流行。此外，規劃能力是 LLM 基於代理的重要組成部分，涉及與環境互動並執行動作以完成規劃任務，這通常需要從初始狀態實現預期目標。本文探討了通過指令調整來增強 LLM 的規劃能力，稱為代理訓練。最近的研究表明，利用專家級軌跡進行指令調整 LLM 有效地增強了其規劃能力。然而，現有工作主要集中於從人工設計的規劃任務和環境中合成軌跡。創建這些環境和任務的勞動密集性阻礙了產生足夠多樣化和廣泛的軌跡。為了解決這個限制，本文探討了多樣化環境和從容易到困難的逐步規劃任務的自動合成。我們引入了一個框架 AgentGen，它利用 LLM 首先生成環境，然後根據這些環境生成規劃任務。具體來說，為了提高環境的多樣性，我們建議使用由各種特定領域文本片段組成的靈感語料庫作為合成環境的背景。此外，為了增加生成規劃任務的難度多樣性，我們提出了一種雙向演化方法 Bi-Evol，它從更容易和更困難的方向演化規劃任務，以合成一個具有更平滑難度曲線的任務集。從 AgentBoard 衍生的評估結果表明，AgentGen 大大提高了 LLM 的規劃能力，例如，AgentGen 指令調整的 Llama-3 8B 在整體性能上超過了 GPT-3.5。此外，在某些任務中，它甚至優於 GPT-4。

##### **Tamper-Resistant Safeguards for Open-Weight LLMs**
2408.00761v1 by Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika

Rapid advances in the capabilities of large language models (LLMs) have
raised widespread concerns regarding their potential for malicious use.
Open-weight LLMs present unique challenges, as existing safeguards lack
robustness to tampering attacks that modify model weights. For example, recent
works have demonstrated that refusal and unlearning safeguards can be trivially
removed with a few steps of fine-tuning. These vulnerabilities necessitate new
approaches for enabling the safe release of open-weight LLMs. We develop a
method, called TAR, for building tamper-resistant safeguards into open-weight
LLMs such that adversaries cannot remove the safeguards even after thousands of
steps of fine-tuning. In extensive evaluations and red teaming analyses, we
find that our method greatly improves tamper-resistance while preserving benign
capabilities. Our results demonstrate that tamper-resistance is a tractable
problem, opening up a promising new avenue to improve the safety and security
of open-weight LLMs.

摘要：大型語言模型 (LLM) 的功能快速進步，引發了人們對其潛在惡意使用感到普遍擔憂。開放權重的 LLM 提出獨特挑戰，因為現有保障措施缺乏對修改模型權重的竄改攻擊的健全性。例如，最近的研究表明，拒絕和遺忘保障措施可以用微調的幾個步驟輕鬆移除。這些漏洞需要新的方法來實現開放權重 LLM 的安全發布。我們開發了一種稱為 TAR 的方法，用於將防篡改保障措施建置到開放權重 LLM 中，這樣即使經過數千次微調步驟，對手也無法移除保障措施。在廣泛的評估和紅隊分析中，我們發現我們的這種方法大幅提高了防篡改能力，同時保留了良性功能。我們的結果表明，防篡改是一個易於解決的問題，為改善開放權重 LLM 的安全性和安全性開闢了一條新的途徑。

##### **Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention**
2408.00760v1 by Susung Hong

Conditional diffusion models have shown remarkable success in visual content
generation, producing high-quality samples across various domains, largely due
to classifier-free guidance (CFG). Recent attempts to extend guidance to
unconditional models have relied on heuristic techniques, resulting in
suboptimal generation quality and unintended effects. In this work, we propose
Smoothed Energy Guidance (SEG), a novel training- and condition-free approach
that leverages the energy-based perspective of the self-attention mechanism to
enhance image generation. By defining the energy of self-attention, we
introduce a method to reduce the curvature of the energy landscape of attention
and use the output as the unconditional prediction. Practically, we control the
curvature of the energy landscape by adjusting the Gaussian kernel parameter
while keeping the guidance scale parameter fixed. Additionally, we present a
query blurring method that is equivalent to blurring the entire attention
weights without incurring quadratic complexity in the number of tokens. In our
experiments, SEG achieves a Pareto improvement in both quality and the
reduction of side effects. The code is available at
\url{https://github.com/SusungHong/SEG-SDXL}.

摘要：條件擴散模型在視覺內容生成方面展現出顯著的成功，在各種領域產生高品質的範例，這在很大程度上歸功於無分類器引導 (CFG)。最近嘗試將引導擴展到無條件模型依賴於啟發式技術，導致次優的生成品質和意外的影響。在這項工作中，我們提出平滑能量引導 (SEG)，一種新穎的訓練和條件無關的方法，它利用自注意力機制的基於能量的觀點來增強影像生成。透過定義自注意力的能量，我們引入一種方法來減少注意力的能量景觀的曲率，並使用輸出作為無條件預測。實際上，我們透過調整高斯核參數來控制能量景觀的曲率，同時保持引導規模參數固定。此外，我們提出一個查詢模糊方法，這等同於模糊整個注意力權重，而不會產生二次複雜度，令牌數量也不受影響。在我們的實驗中，SEG 在品質和副作用的減少方面都達到了帕累托改善。程式碼可在 \url{https://github.com/SusungHong/SEG-SDXL} 取得。

##### **Segment anything model 2: an application to 2D and 3D medical images**
2408.00756v1 by Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski

Segment Anything Model (SAM) has gained significant attention because of its
ability to segment a variety of objects in images given a prompt. The recently
developed SAM 2 has extended this ability to video inputs. This opens an
opportunity to apply SAM to 3D images, one of the fundamental tasks in the
medical imaging field. In this paper, we provide an extensive evaluation of SAM
2's ability to segment both 2D and 3D medical images. We collect 18 medical
imaging datasets, including common 3D modalities such as computed tomography
(CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)
as well as 2D modalities such as X-ray and ultrasound. We consider two
evaluation pipelines of SAM 2: (1) multi-frame 3D segmentation, where prompts
are provided to one or multiple slice(s) selected from the volume, and (2)
single-frame 2D segmentation, where prompts are provided to each slice. The
former is only applicable to 3D modalities, while the latter applies to both 2D
and 3D modalities. We learn that SAM 2 exhibits similar performance as SAM
under single-frame 2D segmentation, and has variable performance under
multi-frame 3D segmentation depending on the choices of slices to annotate, the
direction of the propagation, the predictions utilized during the propagation,
etc.

摘要：分段任何模型 (SAM) 因其在給定提示的情況下分段圖像中各種物體的能力而備受關注。最近開發的 SAM 2 已將此能力擴展到影片輸入。這開啟了一個將 SAM 應用於 3D 影像的機會，這是醫學影像領域的基礎任務之一。在本文中，我們對 SAM 2 分段 2D 和 3D 醫學影像的能力進行了廣泛評估。我們收集了 18 個醫學影像資料集，包括常見的 3D 方式，例如電腦斷層掃描 (CT)、磁振造影 (MRI) 和正子發射斷層掃描 (PET)，以及 2D 方式，例如 X 光和超音波。我們考慮了 SAM 2 的兩個評估管道：(1) 多幀 3D 分段，其中提示提供給從體積中選取的一個或多個切片，以及 (2) 單幀 2D 分段，其中提示提供給每個切片。前者僅適用於 3D 方式，而後者適用於 2D 和 3D 方式。我們了解到，在單幀 2D 分段下，SAM 2 表現出與 SAM 相似的效能，而在多幀 3D 分段下則表現出不同的效能，具體取決於標記切片的選擇、傳播方向、傳播期間使用的預測等。

##### **DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency**
2408.00741v1 by Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Josep Torrellas, Esha Choukse

The rapid evolution and widespread adoption of generative large language
models (LLMs) have made them a pivotal workload in various applications. Today,
LLM inference clusters receive a large number of queries with strict Service
Level Objectives (SLOs). To achieve the desired performance, these models
execute on power-hungry GPUs causing the inference clusters to consume large
amount of energy and, consequently, result in excessive carbon emissions.
Fortunately, we find that there is a great opportunity to exploit the
heterogeneity in inference compute properties and fluctuations in inference
workloads, to significantly improve energy-efficiency. However, such a diverse
and dynamic environment creates a large search-space where different system
configurations (e.g., number of instances, model parallelism, and GPU
frequency) translate into different energy-performance trade-offs. To address
these challenges, we propose DynamoLLM, the first energy-management framework
for LLM inference environments. DynamoLLM automatically and dynamically
reconfigures the inference cluster to optimize for energy and cost of LLM
serving under the service's performance SLOs. We show that at a service-level,
DynamoLLM conserves 53% energy and 38% operational carbon emissions, and
reduces 61% cost to the customer, while meeting the latency SLOs.

摘要：生成式大型语言模型 (LLM) 的快速发展和广泛采用，使其成为各种应用程序中的关键工作负载。如今，LLM 推理集群会收到大量具有严格服务级别目标 (SLO) 的查询。为了实现所需的性能，这些模型在耗电的 GPU 上执行，导致推理集群消耗大量的能量，从而导致过度的碳排放。幸运的是，我们发现有很大的机会利用推理计算特性和推理工作负载的波动中的异质性，以显著提高能效。然而，如此多样化和动态的环境创造了一个巨大的搜索空间，其中不同的系统配置（例如，实例数量、模型并行性和 GPU 频率）转化为不同的能效权衡。为了应对这些挑战，我们提出了 DynamoLLM，这是 LLM 推理环境的第一个能源管理框架。DynamoLLM 会自动动态地重新配置推理集群，以优化 LLM 服务的能源和成本，同时满足服务的性能 SLO。我们表明，在服务级别，DynamoLLM 节省了 53% 的能源和 38% 的运营碳排放，并为客户节省了 61% 的成本，同时满足了延迟 SLO。

##### **CERT-ED: Certifiably Robust Text Classification for Edit Distance**
2408.00728v1 by Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein

With the growing integration of AI in daily life, ensuring the robustness of
systems to inference-time attacks is crucial. Among the approaches for
certifying robustness to such adversarial examples, randomized smoothing has
emerged as highly promising due to its nature as a wrapper around arbitrary
black-box models. Previous work on randomized smoothing in natural language
processing has primarily focused on specific subsets of edit distance
operations, such as synonym substitution or word insertion, without exploring
the certification of all edit operations. In this paper, we adapt Randomized
Deletion (Huang et al., 2023) and propose, CERTified Edit Distance defense
(CERT-ED) for natural language classification. Through comprehensive
experiments, we demonstrate that CERT-ED outperforms the existing Hamming
distance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of
both accuracy and the cardinality of the certificate. By covering various
threat models, including 5 direct and 5 transfer attacks, our method improves
empirical robustness in 38 out of 50 settings.

摘要：隨著 AI 在日常生活中整合度不斷提高，確保系統在推理時間攻擊中的穩健性至關重要。在用於驗證對此類對抗範例的穩健性的方法中，隨機平滑因其作為任意黑盒模型的包裝器的特性而備受矚目。先前針對自然語言處理中隨機平滑的研究主要集中在編輯距離操作的特定子集上，例如同義詞替換或詞彙插入，而沒有探索所有編輯操作的驗證。在本文中，我們調整了隨機刪除（Huang et al., 2023）並提出了自然語言分類的 CERTified 編輯距離防禦（CERT-ED）。透過全面的實驗，我們證明 CERT-ED 在準確性和證書基數方面，在 5 個資料集中有 4 個資料集優於現有的漢明距離方法 RanMASK（Zeng et al., 2023）。透過涵蓋各種威脅模型，包括 5 次直接攻擊和 5 次傳輸攻擊，我們的模型在 50 個設定中有 38 個設定改進了經驗穩健性。

##### **Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions**
2408.00727v1 by Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang

The emergent abilities of large language models (LLMs) have demonstrated
great potential in solving medical questions. They can possess considerable
medical knowledge, but may still hallucinate and are inflexible in the
knowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed
to enhance the medical question-answering capabilities of LLMs with external
knowledge bases, it may still fail in complex cases where multiple rounds of
information-seeking are required. To address such an issue, we propose
iterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up
queries based on previous information-seeking attempts. In each iteration of
i-MedRAG, the follow-up queries will be answered by a vanilla RAG system and
they will be further used to guide the query generation in the next iteration.
Our experiments show the improved performance of various LLMs brought by
i-MedRAG compared with vanilla RAG on complex questions from clinical vignettes
in the United States Medical Licensing Examination (USMLE), as well as various
knowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.
Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering and
fine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQA
dataset. In addition, we characterize the scaling properties of i-MedRAG with
different iterations of follow-up queries and different numbers of queries per
iteration. Our case studies show that i-MedRAG can flexibly ask follow-up
queries to form reasoning chains, providing an in-depth analysis of medical
questions. To the best of our knowledge, this is the first-of-its-kind study on
incorporating follow-up queries into medical RAG.

摘要：大型語言模型（LLM）的新興能力已證明在解決醫療問題方面具有巨大潛力。它們可能擁有大量的醫療知識，但仍可能產生幻覺，並且在知識更新方面缺乏靈活性。雖然已提出檢索增強生成（RAG）以利用外部知識庫增強 LLM 的醫療問題解答能力，但在需要多輪信息檢索的複雜情況下，它仍可能失敗。為了解決這個問題，我們提出了用於醫療的迭代 RAG（i-MedRAG），其中 LLM 可以根據先前的信息檢索嘗試反覆詢問後續查詢。在 i-MedRAG 的每次迭代中，後續查詢將由基本的 RAG 系統回答，並且它們將進一步用於指導下一次迭代中的查詢生成。我們的實驗表明，與美國醫學執照考試（USMLE）中臨床小插圖中的複雜問題以及 Massive Multitask Language Understanding（MMLU）數據集中各種知識測試中的基本 RAG 相比，i-MedRAG 帶來的各種 LLM 的改進性能。值得注意的是，我們的零次學習 i-MedRAG 在 GPT-3.5 上優於所有現有的提示工程和微調方法，在 MedQA 數據集上達到了 69.68% 的準確率。此外，我們描述了 i-MedRAG 的擴展屬性，包括不同的後續查詢迭代和每個迭代的不同查詢數量。我們的案例研究表明，i-MedRAG 可以靈活地詢問後續查詢以形成推理鏈，從而對醫療問題進行深入分析。據我們所知，這是第一個將後續查詢納入醫療 RAG 的同類研究。

##### **An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models**
2408.00724v1 by Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang

The optimal training configurations of large language models (LLMs) with
respect to model sizes and compute budgets have been extensively studied. But
how to optimally configure LLMs during inference has not been explored in
sufficient depth. We study compute-optimal inference: designing models and
inference strategies that optimally trade off additional inference-time compute
for improved performance. As a first step towards understanding and designing
compute-optimal inference methods, we assessed the effectiveness and
computational efficiency of multiple inference strategies such as Greedy
Search, Majority Voting, Best-of-N, Weighted Voting, and their variants on two
different Tree Search algorithms, involving different model sizes and
computational budgets. We found that a smaller language model with a novel tree
search algorithm typically achieves a Pareto-optimal trade-off. These results
highlight the potential benefits of deploying smaller models equipped with more
sophisticated decoding algorithms in budget-constrained scenarios, e.g., on
end-devices, to enhance problem-solving accuracy. For instance, we show that
the Llemma-7B model can achieve competitive accuracy to a Llemma-34B model on
MATH500 while using $2\times$ less FLOPs. Our findings could potentially apply
to any generation task with a well-defined measure of success.

摘要：對於大型語言模型 (LLM) 的最佳訓練組態，無論是模型大小或運算預算，都已廣泛研究過。但如何最佳組態 LLM 在推論期間尚未深入探討。我們研究計算最佳推論：設計模型和推論策略，最佳折衷額外的推論時間計算以提升效能。作為了解和設計計算最佳推論方法的第一步，我們評估多種推論策略的效能和計算效率，例如貪婪搜尋、多數決、N 中最佳、加權投票，以及它們在兩種不同樹狀搜尋演算法上的變體，涉及不同模型大小和計算預算。我們發現，具備新穎樹狀搜尋演算法的較小語言模型通常能達成帕雷托最佳折衷。這些結果突顯在預算受限的情況下，部署配備更精緻解碼演算法的小型模型的潛在好處，例如在終端裝置上，以提升問題解決的準確度。例如，我們顯示 Llemma-7B 模型在 MATH500 上能達成與 Llemma-34B 模型競爭的準確度，同時使用少 $2\times$ 的 FLOP。我們的發現潛在可應用於任何具有明確成功衡量標準的產生任務。

##### **Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities**
2408.00722v1 by Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan

Recently, large language models (LLMs) have been gaining a lot of interest
due to their adaptability and extensibility in emerging applications, including
communication networks. It is anticipated that 6G mobile edge computing
networks will be able to support LLMs as a service, as they provide ultra
reliable low-latency communications and closed loop massive connectivity.
However, LLMs are vulnerable to data and model privacy issues that affect the
trustworthiness of LLMs to be deployed for user-based services. In this paper,
we explore the security vulnerabilities associated with fine-tuning LLMs in 6G
networks, in particular the membership inference attack. We define the
characteristics of an attack network that can perform a membership inference
attack if the attacker has access to the fine-tuned model for the downstream
task. We show that the membership inference attacks are effective for any
downstream task, which can lead to a personal data breach when using LLM as a
service. The experimental results show that the attack success rate of maximum
92% can be achieved on named entity recognition task. Based on the experimental
analysis, we discuss possible defense mechanisms and present possible research
directions to make the LLMs more trustworthy in the context of 6G networks.

摘要：<paragraph>最近，大型语言模型 (LLM) 因其在包括通信网络在内的新兴应用中的适应性和可扩展性而备受关注。预计 6G 移动边缘计算网络将能够支持 LLM 作为一项服务，因为它们提供了超可靠的低延迟通信和闭环大规模连接。然而，LLM 容易受到数据和模型隐私问题的影响，这些问题会影响 LLM 被部署用于基于用户的服务的可信度。在本文中，我们探讨了在 6G 网络中微调 LLM 相关的安全漏洞，特别是成员推断攻击。我们定义了攻击网络的特征，如果攻击者可以访问下游任务的微调模型，则该攻击网络可以执行成员推断攻击。我们表明，成员推断攻击对任何下游任务都是有效的，这在使用 LLM 作为服务时可能导致个人数据泄露。实验结果表明，在命名实体识别任务上可以实现最高 92% 的攻击成功率。基于实验分析，我们讨论了可能的防御机制，并提出了可能的的研究方向，以使 LLM 在 6G 网络的背景下更值得信赖。</paragraph>

##### **SAM 2: Segment Anything in Images and Videos**
2408.00714v1 by Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Dollár, Christoph Feichtenhofer

We present Segment Anything Model 2 (SAM 2), a foundation model towards
solving promptable visual segmentation in images and videos. We build a data
engine, which improves model and data via user interaction, to collect the
largest video segmentation dataset to date. Our model is a simple transformer
architecture with streaming memory for real-time video processing. SAM 2
trained on our data provides strong performance across a wide range of tasks.
In video segmentation, we observe better accuracy, using 3x fewer interactions
than prior approaches. In image segmentation, our model is more accurate and 6x
faster than the Segment Anything Model (SAM). We believe that our data, model,
and insights will serve as a significant milestone for video segmentation and
related perception tasks. We are releasing a version of our model, the dataset
and an interactive demo.

摘要：我們提出「區段任何東西模型 2」(SAM 2)，這是一個基礎模型，用於解決影像和影片中的可提示視覺區段。我們建構了一個資料引擎，透過使用者互動來改善模型和資料，以收集迄今為止最大的影片區段資料集。我們的模型是一種簡單的轉換器架構，具有串流記憶體，可進行即時影片處理。在我們的資料上訓練的 SAM 2 在廣泛的任務中提供了強大的效能。在影片區段中，我們觀察到更高的準確度，與先前的做法相比，互動次數減少了 3 倍。在影像區段中，我們的模型比「區段任何東西模型」(SAM) 更準確，速度快了 6 倍。我們相信我們的資料、模型和見解將成為影片區段和相關感知任務的重要里程碑。我們正在釋出我們模型的一個版本、資料集和一個互動示範。

##### **Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification**
2408.00711v1 by Amarpal Sahota, Amber Roguski, Matthew W Jones, Zahraa S. Abdallah, Raul Santos-Rodriguez

We evaluate the effectiveness of combining brain connectivity metrics with
signal statistics for early stage Parkinson's Disease (PD) classification using
electroencephalogram data (EEG). The data is from 5 arousal states - wakeful
and four sleep stages (N1, N2, N3 and REM). Our pipeline uses an Ada Boost
model for classification on a challenging early stage PD classification task
with with only 30 participants (11 PD , 19 Healthy Control). Evaluating 9 brain
connectivity metrics we find the best connectivity metric to be different for
each arousal state with Phase Lag Index achieving the highest individual
classification accuracy of 86\% on N1 data. Further to this our pipeline using
regional signal statistics achieves an accuracy of 78\%, using brain
connectivity only achieves an accuracy of 86\% whereas combining the two
achieves a best accuracy of 91\%. This best performance is achieved on N1 data
using Phase Lag Index (PLI) combined with statistics derived from the frequency
characteristics of the EEG signal. This model also achieves a recall of 80 \%
and precision of 96\%. Furthermore we find that on data from each arousal
state, combining PLI with regional signal statistics improves classification
accuracy versus using signal statistics or brain connectivity alone. Thus we
conclude that combining brain connectivity statistics with regional EEG
statistics is optimal for classifier performance on early stage Parkinson's.
Additionally, we find outperformance of N1 EEG for classification of
Parkinson's and expect this could be due to disrupted N1 sleep in PD. This
should be explored in future work.

摘要：<paragraph>我們評估將腦連接性指標與訊號統計資料結合起來對早期帕金森氏症 (PD) 分類的有效性，使用腦電圖資料 (EEG)。資料來自 5 種喚醒狀態 - 清醒和四個睡眠階段 (N1、N2、N3 和 REM)。我們的管道使用 Ada Boost 模型對具有挑戰性的早期 PD 分類任務進行分類，僅有 30 位參與者 (11 位 PD，19 位健康對照組)。評估 9 種腦連接性指標，我們發現最佳連接性指標因每種喚醒狀態而異，相位滯後指標在 N1 資料上達到最高的個別分類準確度 86%。此外，我們的管道使用區域訊號統計資料達到 78% 的準確度，僅使用腦連接性達到 86% 的準確度，而將兩者結合起來達到最佳 91% 的準確度。此最佳效能是在 N1 資料上使用相位滯後指標 (PLI) 結合從 EEG 訊號的頻率特性衍生的統計資料時所達成。此模型也達到 80% 的召回率和 96% 的精確度。此外，我們發現，在來自每種喚醒狀態的資料上，將 PLI 與區域訊號統計資料結合起來，可提升分類準確度，優於僅使用訊號統計資料或腦連接性。因此，我們得出結論，將腦連接性統計資料與區域 EEG 統計資料結合起來，對於早期帕金森氏症的分類器效能而言是最佳的。此外，我們發現 N1 EEG 在帕金森氏症的分類上有優異表現，並預期這可能是由於 PD 中 N1 睡眠中斷所致。這應在未來的研究中加以探討。</paragraph>

##### **Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM**
2408.00706v1 by Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri

Delineating lesions and anatomical structure is important for image-guided
interventions. Point-supervised medical image segmentation (PSS) has great
potential to alleviate costly expert delineation labeling. However, due to the
lack of precise size and boundary guidance, the effectiveness of PSS often
falls short of expectations. Although recent vision foundational models, such
as the medical segment anything model (MedSAM), have made significant
advancements in bounding-box-prompted segmentation, it is not straightforward
to utilize point annotation, and is prone to semantic ambiguity. In this
preliminary study, we introduce an iterative framework to facilitate
semantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt
generator (SBPG) module has the capacity to convert the point input into
potential pseudo bounding box suggestions, which are explicitly refined by the
prototype-based semantic similarity. This is then succeeded by a prompt-guided
spatial refinement (PGSR) module that harnesses the exceptional
generalizability of MedSAM to infer the segmentation mask, which also updates
the box proposal seed in SBPG. Performance can be progressively improved with
adequate iterations. We conducted an evaluation on BraTS2018 for the
segmentation of whole brain tumors and demonstrated its superior performance
compared to traditional PSS methods and on par with box-supervised methods.

摘要：描繪病灶和解剖結構對於影像導引介入非常重要。點監督醫學影像分割（PSS）具有減輕昂貴的專家描繪標籤的巨大潛力。然而，由於缺乏精確的大小和邊界引導，PSS 的有效性通常低於預期。儘管最近的視覺基礎模型，例如醫學分割任何模型（MedSAM），在邊界框提示分割方面取得了重大進展，但利用點註釋並不容易，而且容易產生語義歧義。在這項初步研究中，我們引入了一個迭代框架來促進語義感知點監督 MedSAM。具體來說，語義框提示生成器（SBPG）模組能夠將點輸入轉換為潛在的偽邊界框建議，這些建議由基於原型的語義相似性明確細化。然後，由提示引導的空間細化（PGSR）模組繼承，它利用 MedSAM 的出色可概化性來推斷分割蒙版，這也會更新 SBPG 中的框建議種子。通過充分的迭代可以逐步提高性能。我們對 BraTS2018 進行了全腦腫瘤分割評估，並證明其性能優於傳統的 PSS 方法，並且與框監督方法相當。

##### **Future of Artificial Intelligence in Agile Software Development**
2408.00703v1 by Mariyam Mahboob, Mohammed Rayyan Uddin Ahmed, Zoiba Zia, Mariam Shakeel Ali, Ayman Khaleel Ahmed

The advent of Artificial intelligence has promising advantages that can be
utilized to transform the landscape of software project development. The
Software process framework consists of activities that constantly require
routine human interaction, leading to the possibility of errors and
uncertainties. AI can assist software development managers, software testers,
and other team members by leveraging LLMs, GenAI models, and AI agents to
perform routine tasks, risk analysis and prediction, strategy recommendations,
and support decision making. AI has the potential to increase efficiency and
reduce the risks encountered by the project management team while increasing
the project success rates. Additionally, it can also break down complex notions
and development processes for stakeholders to make informed decisions. In this
paper, we propose an approach in which AI tools and technologies can be
utilized to bestow maximum assistance for agile software projects, which have
become increasingly favored in the industry in recent years.

摘要：人工智慧的出現具有可帶來優勢，可望用於轉換軟體專案開發的樣貌。軟體流程架構包含持續需要常規人類互動的活動，導致可能產生錯誤和不確定性。人工智慧能協助軟體開發經理、軟體測試人員和其他團隊成員，透過利用大型語言模型 (LLM)、生成式人工智慧模型和人工智慧代理程式來執行常規工作、風險分析和預測、策略建議和支援決策制定。人工智慧有潛力提升效率和降低專案管理團隊遭遇的風險，同時提升專案成功率。此外，人工智慧還能為利害關係人分解複雜的概念和開發流程，以做出明智的決策。在本文中，我們提出一個方法，其中人工智慧工具和技術可望用於賦予敏捷軟體專案最大的協助，這些專案近年來在產業中越來越受到青睞。

##### **Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning**
2408.00690v1 by Trapoom Ukarapol, Zhicheng Lee, Amy Xin

While Large Language Models show remarkable performance in natural language
understanding, their resource-intensive nature makes them less accessible. In
contrast, smaller language models such as MiniCPM offer more sustainable
scalability, but often underperform without specialized optimization. In this
paper, we explore the enhancement of smaller language models through the
improvement of their text embeddings. We select three language models, MiniCPM,
Phi-2, and Gemma, to conduct contrastive fine-tuning on the NLI dataset. Our
results demonstrate that this fine-tuning method enhances the quality of text
embeddings for all three models across various benchmarks, with MiniCPM showing
the most significant improvements of an average 56.33\% performance gain. The
contrastive fine-tuning code is publicly available at
https://github.com/trapoom555/Language-Model-STS-CFT.

摘要：雖然大型語言模型在自然語言理解方面展現出卓越的效能，但其資源密集的本質使其較難以取得。相較之下，像 MiniCPM 等較小的語言模型提供了更永續的可擴充性，但通常在沒有特殊最佳化的情況下表現不佳。在本文中，我們探討了透過改善其文字嵌入來增強較小語言模型的方法。我們選取了三個語言模型，MiniCPM、Phi-2 和 Gemma，在 NLI 資料集上進行對比微調。我們的結果證明，這種微調方法提升了所有三個模型在各種基準上的文字嵌入品質，其中 MiniCPM 顯示出最顯著的改進，平均效能提升了 56.33%。對比微調程式碼已公開在 https://github.com/trapoom555/Language-Model-STS-CFT。

##### **Can Developers Prompt? A Controlled Experiment for Code Documentation Generation**
2408.00686v1 by Hans-Alexander Kruse, Tim Puhlfürß, Walid Maalej

Large language models (LLMs) bear great potential for automating tedious
development tasks such as creating and maintaining code documentation. However,
it is unclear to what extent developers can effectively prompt LLMs to create
concise and useful documentation. We report on a controlled experiment with 20
professionals and 30 computer science students tasked with code documentation
generation for two Python functions. The experimental group freely entered
ad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while the
control group executed a predefined few-shot prompt. Our results reveal that
professionals and students were unaware of or unable to apply prompt
engineering techniques. Especially students perceived the documentation
produced from ad-hoc prompts as significantly less readable, less concise, and
less helpful than documentation from prepared prompts. Some professionals
produced higher quality documentation by just including the keyword Docstring
in their ad-hoc prompts. While students desired more support in formulating
prompts, professionals appreciated the flexibility of ad-hoc prompting.
Participants in both groups rarely assessed the output as perfect. Instead,
they understood the tools as support to iteratively refine the documentation.
Further research is needed to understand which prompting skills and preferences
developers have and which support they need for certain tasks.

摘要：大型語言模型 (LLM) 具有自動化繁瑣開發任務（例如建立和維護程式碼文件）的巨大潛力。然而，目前尚不清楚開發人員在多大程度上可以有效地提示 LLM 建立簡潔且有用的文件。我們報告了一項受控實驗，有 20 位專業人員和 30 位電腦科學系學生負責為兩個 Python 函數建立程式碼文件。實驗組在類似 ChatGPT 的 Visual Studio Code 擴充功能中自由輸入臨時提示，而對照組則執行預先定義的少量提示。我們的結果顯示，專業人員和學生不知道或無法應用提示工程技術。特別是學生認為根據臨時提示產生的文件顯著低於根據準備好的提示產生的文件，可讀性、簡潔性和有幫助性都較低。一些專業人員僅在臨時提示中加入 Docstring 關鍵字，就產生了更高品質的文件。雖然學生希望在制定提示時獲得更多支援，但專業人員則欣賞臨時提示的靈活性。這兩組的參與者很少將輸出評估為完美。相反地，他們將這些工具視為反覆修改文件的支援。需要進一步研究以了解開發人員具備哪些提示技能和偏好，以及他們在某些任務中需要哪些支援。

##### **Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index**
2408.00684v1 by Anubhab Majumder, Ujjwal Pal, Amaresh Chakrabarti

Past research relates design creativity to 'divergent thinking,' i.e., how
well the concept space is explored during the early phase of design.
Researchers have argued that generating several concepts would increase the
chances of producing better design solutions. 'Variety' is one of the
parameters by which one can quantify the breadth of a concept space explored by
the designers. It is useful to assess variety at the conceptual design stage
because, at this stage, designers have the freedom to explore different
solution principles so as to satisfy a design problem with substantially novel
concepts. This article elaborates on and critically examines the existing
variety metrics from the engineering design literature, discussing their
limitations. A new distance-based variety metric is proposed, along with a
prescriptive framework to support the assessment process. This framework uses
the SAPPhIRE model of causality as a knowledge representation scheme to measure
the real-valued distance between two design concepts. The proposed framework is
implemented in a software tool called 'VariAnT.' Furthermore, the tool's
application is demonstrated through an illustrative example.

摘要：過去的研究將設計創意與「發散性思考」聯繫起來，亦即在設計的早期階段，概念空間探索得有多好。研究人員主張，產生多個概念將增加產生更好設計解決方案的機會。「多樣性」是其中一個參數，設計人員可以用來量化他們探索的概念空間廣度。在概念設計階段評估多樣性很有用，因為在這個階段，設計人員有自由探索不同的解決方案原則，以滿足實質上具有新穎概念的設計問題。本文詳細說明並批判性地審查工程設計文獻中現有的多樣性指標，並討論它們的限制。提出了一種新的基於距離的多樣性指標，以及一個規範性框架來支持評估過程。這個框架使用 SAPPhIRE 因果關係模型作為知識表示方案，來測量兩個設計概念之間的實值距離。所提出的框架在稱為「VariAnT」的軟體工具中實作。此外，透過一個說明性範例展示了該工具的應用。

##### **Learning in Multi-Objective Public Goods Games with Non-Linear Utilities**
2408.00682v1 by Nicole Orzan, Erman Acar, Davide Grossi, Patrick Mannion, Roxana Rădulescu

Addressing the question of how to achieve optimal decision-making under risk
and uncertainty is crucial for enhancing the capabilities of artificial agents
that collaborate with or support humans. In this work, we address this question
in the context of Public Goods Games. We study learning in a novel
multi-objective version of the Public Goods Game where agents have different
risk preferences, by means of multi-objective reinforcement learning. We
introduce a parametric non-linear utility function to model risk preferences at
the level of individual agents, over the collective and individual reward
components of the game. We study the interplay between such preference
modelling and environmental uncertainty on the incentive alignment level in the
game. We demonstrate how different combinations of individual preferences and
environmental uncertainties sustain the emergence of cooperative patterns in
non-cooperative environments (i.e., where competitive strategies are dominant),
while others sustain competitive patterns in cooperative environments (i.e.,
where cooperative strategies are dominant).

摘要：探討如何在風險和不確定性下達成最佳決策，對於提升與人類合作或支援人類的人工智慧代理能力至關重要。在這項研究中，我們在公共財博弈的背景下探討這個問題。我們透過多目標強化學習，研究在公共財博弈的新穎多目標版本中學習。我們引入一個參數非線性效用函數，以在個人代理層級對風險偏好進行建模，涵蓋博弈的集體和個人獎勵組成部分。我們研究此類偏好建模與環境不確定性在博弈中激勵對齊層級之間的交互作用。我們展示了個人偏好和環境不確定性的不同組合如何在非合作環境中維持合作模式的出現（即競爭策略佔主導地位），而其他組合如何在合作環境中維持競爭模式（即合作策略佔主導地位）。

##### **Leveraging Entailment Judgements in Cross-Lingual Summarisation**
2408.00675v1 by Huajian Zhang, Laura Perez-Beltrachini

Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone to
include document-summary pairs where the reference summary is unfaithful to the
corresponding document as it contains content not supported by the document
(i.e., hallucinated content). This low data quality misleads model learning and
obscures evaluation results. Automatic ways to assess hallucinations and
improve training have been proposed for monolingual summarisation,
predominantly in English. For CLS, we propose to use off-the-shelf
cross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness of
reference and model generated summaries. Then, we study training approaches
that are aware of faithfulness issues in the training data and propose an
approach that uses unlikelihood loss to teach a model about unfaithful summary
sequences. Our results show that it is possible to train CLS models that yield
more faithful summaries while maintaining comparable or better informativess.

摘要：合成建立的跨語言摘要 (CLS) 資料集容易包含文件摘要對，其中參考摘要對應文件不忠實，因為它包含文件不支援的內容（即幻覺內容）。這種低資料品質會誤導模型學習，並掩蓋評估結果。已經提出用於單語言摘要的自動方法來評估幻覺並改善訓練，主要用於英文。對於 CLS，我們建議使用現成的跨語言自然語言推論 (X-NLI) 來評估參考和模型產生的摘要的忠實度。然後，我們研究了訓練方法，這些方法了解訓練資料中的忠實度問題，並提出了一種使用不似然損失來教導模型有關不忠實摘要序列的方法。我們的結果表明，訓練 CLS 模型是可能的，這些模型會產生更忠實的摘要，同時保持可比性或更好的資訊性。

##### **SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models**
2408.00655v1 by Hongjun An, Yifan Chen, Xiaozhen Qiao, Zhe Sun, Xuelong Li

Contemporary large language models (LLMs) predominantly utilize a next-token
prediction method for inference, which significantly impedes their processing
speed. In this paper, we introduce a novel inference methodology termed
next-sentence prediction, aimed at enhancing the inference efficiency of LLMs.
We present SentenceVAE, a tiny model consisting of an encoder and a decoder.
The encoder effectively condenses the information within a sentence into a
singular token, while the decoder reconstructs this compressed data back into
its original sentential form. By integrating SentenceVAE into the input and
output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a
sentence-by-sentence inference approach, markedly accelerating inference
speeds. SentenceVAE also maintains the integrity of the original semantic
content by segmenting the text into sentences, thereby preserving accuracy
while boosting inference speeds. Compared to traditional LLMs, SLLMs process
fewer tokens over equivalent context lengths, significantly reducing memory
demands for Self-Attention computations and facilitating the handling of longer
contexts. Our experimental findings reveal that this method can increase
inference speeds by 204~365%, reduce perplexity (PPL) to 46~75% of its original
metric, and decrease memory overhead by 86~91% for the same context length. The
advantages of this approach are further amplified with increases in model
parameters.

摘要：當代大型語言模型 (LLM) 主要利用下一個代碼預測方法進行推論，這顯著地阻礙了它們的處理速度。在本文中，我們介紹了一種新的推論方法，稱為下一個句子預測，旨在提高 LLM 的推論效率。我們提出了 SentenceVAE，這是一個由編碼器和解碼器組成的小模型。編碼器有效地將句子中的資訊壓縮成一個單一代碼，而解碼器將這些壓縮資料解構回其原始的句子形式。透過將 SentenceVAE 整合到 LLM 的輸入和輸出層，我們開發了句子層級 LLM (SLLM)，它採用逐句推論方法，顯著地加速了推論速度。SentenceVAE 也透過將文字分段成句子來維護原始語義內容的完整性，從而提升推論速度的同時也維持準確性。與傳統的 LLM 相比，SLLM 處理較少代碼，但具有等效的內容長度，大幅減少自注意力計算的記憶體需求，並促進處理較長的內容。我們的實驗結果顯示，這種方法可以將推論速度提升 204~365%，將困惑度 (PPL) 降低到其原始指標的 46~75%，並在相同的內容長度下將記憶體開銷減少 86~91%。隨著模型參數的增加，這種方法的優勢進一步擴大。

##### **AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation**
2408.00640v1 by Asbjørn Munk, Jakob Ambsdorf, Sebastian Llambias, Mads Nielsen

This study investigates the impact of self-supervised pretraining of 3D
semantic segmentation models on a large-scale, domain-specific dataset. We
introduce BRAINS-45K, a dataset of 44,756 brain MRI volumes from public
sources, the largest public dataset available, and revisit a number of design
choices for pretraining modern segmentation architectures by simplifying and
optimizing state-of-the-art methods, and combining them with a novel
augmentation strategy. The resulting AMAES framework is based on
masked-image-modeling and intensity-based augmentation reversal and balances
memory usage, runtime, and finetuning performance. Using the popular U-Net and
the recent MedNeXt architecture as backbones, we evaluate the effect of
pretraining on three challenging downstream tasks, covering single-sequence,
low-resource settings, and out-of-domain generalization. The results highlight
that pretraining on the proposed dataset with AMAES significantly improves
segmentation performance in the majority of evaluated cases, and that it is
beneficial to pretrain the model with augmentations, despite pretraing on a
large-scale dataset. Code and model checkpoints for reproducing results, as
well as the BRAINS-45K dataset are available at
\url{https://github.com/asbjrnmunk/amaes}.

摘要：本研究調查了 3D 語意分割模型的自我監督預訓練對大型特定領域資料集的影響。我們引入了 BRAINS-45K，這是一個包含來自公共來源的 44,756 個大腦 MRI 卷的資料集，是最大的公開資料集，並重新審視了現代分割架構預訓練的許多設計選擇，透過簡化和最佳化最先進的方法，並將其與新穎的擴充策略相結合。由此產生的 AMAES 框架基於遮罩影像建模和基於強度的擴充反轉，並平衡了記憶體使用量、執行時間和微調效能。使用流行的 U-Net 和最近的 MedNeXt 架構作為主幹，我們評估了預訓練對三個具有挑戰性的下游任務的影響，涵蓋單一序列、低資源設定和領域外概化。結果強調了使用 AMAES 在建議的資料集上進行預訓練，在評估案例中大部分顯著改善了分割效能，並且儘管在大規模資料集上進行預訓練，但使用擴充預訓練模型是有益的。重製結果的程式碼和模型檢查點，以及 BRAINS-45K 資料集可在\url{https://github.com/asbjrnmunk/amaes} 取得。

##### **DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**
2408.00633v1 by Guillermo Villar-Rodríguez, Álvaro Huertas-García, Alejandro Martín, Javier Huertas-Tato, David Camacho

Introduction: This article introduces DisTrack, a methodology and a tool
developed for tracking and analyzing misinformation within Online Social
Networks (OSNs). DisTrack is designed to combat the spread of misinformation
through a combination of Natural Language Processing (NLP) Social Network
Analysis (SNA) and graph visualization. The primary goal is to detect
misinformation, track its propagation, identify its sources, and assess the
influence of various actors within the network.
  Methods: DisTrack's architecture incorporates a variety of methodologies
including keyword search, semantic similarity assessments, and graph generation
techniques. These methods collectively facilitate the monitoring of
misinformation, the categorization of content based on alignment with known
false claims, and the visualization of dissemination cascades through detailed
graphs. The tool is tailored to capture and analyze the dynamic nature of
misinformation spread in digital environments.
  Results: The effectiveness of DisTrack is demonstrated through three case
studies focused on different themes: discredit/hate speech, anti-vaccine
misinformation, and false narratives about the Russia-Ukraine conflict. These
studies show DisTrack's capabilities in distinguishing posts that propagate
falsehoods from those that counteract them, and tracing the evolution of
misinformation from its inception.
  Conclusions: The research confirms that DisTrack is a valuable tool in the
field of misinformation analysis. It effectively distinguishes between
different types of misinformation and traces their development over time. By
providing a comprehensive approach to understanding and combating
misinformation in digital spaces, DisTrack proves to be an essential asset for
researchers and practitioners working to mitigate the impact of false
information in online social environments.

摘要：<paragraph>引言：本文介紹 DisTrack，這是一種方法和工具，用於追蹤和分析線上社交網路（OSN）中的錯誤資訊。DisTrack 的設計目的是透過結合自然語言處理（NLP）、社交網路分析（SNA）和圖形視覺化來對抗錯誤資訊的散布。主要目標是偵測錯誤資訊、追蹤其傳播、找出其來源，並評估網路中各個參與者的影響力。
方法：DisTrack 的架構結合了多種方法，包括關鍵字搜尋、語意相似性評估和圖形產生技術。這些方法共同促進了錯誤資訊的監控、基於與已知虛假說法的比對來分類內容，以及透過詳細圖形視覺化傳播層疊。此工具經過量身打造，用於擷取和分析數位環境中錯誤資訊散布的動態特性。
結果：DisTrack 的效能透過三個案例研究獲得驗證，這些研究專注於不同的主題：貶低/仇恨言論、反疫苗錯誤資訊，以及關於俄羅斯-烏克蘭衝突的虛假敘述。這些研究顯示出 DisTrack 在區分傳播虛假資訊和反制虛假資訊的貼文，以及追蹤錯誤資訊從其開端演變的過程中所具備的能力。
結論：研究證實 DisTrack 是錯誤資訊分析領域中一個有價值的工具。它有效區分了不同類型的錯誤資訊，並追蹤其隨著時間推移的發展。透過提供一種全面的方法來理解和對抗數位空間中的錯誤資訊，DisTrack 證明了自己是協助研究人員和實務工作者減輕線上社交環境中虛假資訊影響力的重要資產。</paragraph>

##### **SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data**
2408.00624v1 by Yichen Lu, Jiaqi Song, Xuankai Chang, Hengwei Bian, Soumi Maiti, Shinji Watanabe

In this work, we present SynesLM, an unified model which can perform three
multimodal language understanding tasks: audio-visual automatic speech
recognition(AV-ASR) and visual-aided speech/machine translation(VST/VMT).
Unlike previous research that focused on lip motion as visual cues for speech
signals, our work explores more general visual information within entire
frames, such as objects and actions. Additionally, we use synthetic image data
to enhance the correlation between image and speech data. We benchmark SynesLM
against the How2 dataset, demonstrating performance on par with
state-of-the-art (SOTA) models dedicated to AV-ASR while maintaining our
multitasking framework. Remarkably, for zero-shot AV-ASR, SynesLM achieved SOTA
performance by lowering the Word Error Rate (WER) from 43.4% to 39.4% on the
VisSpeech Dataset. Furthermore, our results in VST and VMT outperform the
previous results, improving the BLEU score to 43.5 from 37.2 for VST, and to
54.8 from 54.4 for VMT.

摘要：在這項工作中，我們展示了 SynesLM，一個統一的模型，可以執行三項多模態語言理解任務：音訊視覺自動語音辨識 (AV-ASR) 和視覺輔助語音/機器翻譯 (VST/VMT)。與以往專注於唇部動作作為語音訊號視覺線索的研究不同，我們的研究探索了整個畫面中更通用的視覺資訊，例如物件和動作。此外，我們使用合成影像資料來增強影像和語音資料之間的關聯性。我們以 How2 資料集來評量 SynesLM，證明其效能與專門用於 AV-ASR 的最新 (SOTA) 模型相當，同時維持我們的多任務架構。值得注意的是，對於零次學習 AV-ASR，SynesLM 在 VisSpeech 資料集上將字元錯誤率 (WER) 從 43.4% 降低到 39.4%，達到了 SOTA 效能。此外，我們在 VST 和 VMT 中的結果優於先前的結果，將 VST 的 BLEU 分數從 37.2 提升到 43.5，將 VMT 的 BLEU 分數從 54.4 提升到 54.8。

##### **Are Bigger Encoders Always Better in Vision Large Models?**
2408.00620v1 by Bozhou Li, Hao Liang, Zimo Meng, Wentao Zhang

In recent years, multimodal large language models (MLLMs) have shown strong
potential in real-world applications. They are developing rapidly due to their
remarkable ability to comprehend multimodal information and their inherent
powerful cognitive and reasoning capabilities. Among MLLMs, vision language
models (VLM) stand out for their ability to understand vision information.
However, the scaling trend of VLMs under the current mainstream paradigm has
not been extensively studied. Whether we can achieve better performance by
training even larger models is still unclear. To address this issue, we
conducted experiments on the pretraining stage of MLLMs. We conduct our
experiment using different encoder sizes and large language model (LLM) sizes.
Our findings indicate that merely increasing the size of encoders does not
necessarily enhance the performance of VLMs. Moreover, we analyzed the effects
of LLM backbone parameter size and data quality on the pretraining outcomes.
Additionally, we explored the differences in scaling laws between LLMs and
VLMs.

摘要：近年來，多模態大型語言模型（MLLM）在實際應用中展現強大的潛力。由於其理解多模態資訊的非凡能力，以及其內在強大的認知和推理能力，它們正快速發展。在 MLLM 中，視覺語言模型（VLM）因其理解視覺資訊的能力而脫穎而出。然而，在目前的主流範例下，VLM 的擴充趨勢尚未廣泛研究。我們是否能透過訓練更大規模的模型來獲得更好的效能，仍不清楚。為了解決這個問題，我們對 MLLM 的預訓練階段進行了實驗。我們使用不同的編碼器大小和大型語言模型（LLM）大小來進行實驗。我們的研究結果表明，單純增加編碼器的規模並不會必然提升 VLM 的效能。此外，我們分析了 LLM 主幹參數大小和資料品質對預訓練結果的影響。此外，我們探討了 LLM 和 VLM 之間的擴充法則差異。

##### **Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review**
2408.00613v1 by Amruta Mahuli, Asia Biega

Through a systematization of generative AI (GenAI) stakeholder goals and
expectations, this work seeks to uncover what value different stakeholders see
in their contributions to the GenAI supply line. This valuation enables us to
understand whether fair use advocated by GenAI companies to train model
progresses the copyright law objective of promoting science and arts. While
assessing the validity and efficacy of the fair use argument, we uncover
research gaps and potential avenues for future works for researchers and
policymakers to address.

摘要：透過系統化生成式 AI (GenAI) 利益相關者的目標和預期，這項工作試圖揭示不同利益相關者在對 GenAI 供應鏈的貢獻中看到的價值。這種估值使我們能夠了解 GenAI 公司提倡的合理使用是否能促進科學和藝術的著作權法目標，以訓練模型進度。在評估合理使用論點的有效性和效能時，我們發現了研究差距和研究人員和政策制定者未來工作的潛在途徑，以加以解決。

##### **Downstream bias mitigation is all you need**
2408.00612v1 by Arkadeep Baksi, Rahul Singh, Tarun Joshi

The advent of transformer-based architectures and large language models
(LLMs) have significantly advanced the performance of natural language
processing (NLP) models. Since these LLMs are trained on huge corpuses of data
from the web and other sources, there has been a major concern about harmful
prejudices that may potentially be transferred from the data. In many
applications, these pre-trained LLMs are fine-tuned on task specific datasets,
which can further contribute to biases. This paper studies the extent of biases
absorbed by LLMs during pre-training as well as task-specific behaviour after
fine-tuning. We found that controlled interventions on pre-trained LLMs, prior
to fine-tuning, have minimal effect on lowering biases in classifiers. However,
the biases present in domain-specific datasets play a much bigger role, and
hence mitigating them at this stage has a bigger impact. While pre-training
does matter, but after the model has been pre-trained, even slight changes to
co-occurrence rates in the fine-tuning dataset has a significant effect on the
bias of the model.

摘要：隨著基於Transformer的架構和大語言模型 (LLM) 的出現，自然語言處理 (NLP) 模型的效能已大幅提升。由於這些 LLM 是根據網際網路和其他來源的大量資料庫訓練的，因此對於可能從資料傳遞的有害偏見存在著重大的疑慮。在許多應用程式中，這些預先訓練的 LLM 會針對特定任務的資料集進行微調，這可能會進一步造成偏見。本文探討 LLM 在預先訓練期間吸收的偏見程度，以及微調後的特定任務行為。我們發現，在微調之前對預先訓練的 LLM 進行受控介入，對於降低分類器的偏見影響甚微。然而，特定領域資料集中存在的偏見扮演了更重要的角色，因此在此階段減輕這些偏見會產生更大的影響。雖然預先訓練很重要，但在模型預先訓練後，即使微調資料集中共現率的微小變化也會對模型的偏見產生顯著影響。

##### **Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses**
2408.00584v1 by Gabriele Sarti, Tommaso Caselli, Malvina Nissim, Arianna Bisazza

Rebuses are puzzles requiring constrained multi-step reasoning to identify a
hidden phrase from a set of images and letters. In this work, we introduce a
large collection of verbalized rebuses for the Italian language and use it to
assess the rebus-solving capabilities of state-of-the-art large language
models. While general-purpose systems such as LLaMA-3 and GPT-4o perform poorly
on this task, ad-hoc fine-tuning seems to improve models' performance. However,
we find that performance gains from training are largely motivated by
memorization. Our results suggest that rebus solving remains a challenging test
bed to evaluate large language models' linguistic proficiency and sequential
instruction-following skills.

摘要：謎語是需要受限多步驟推理才能從一組圖像和字母中找出隱藏短語的謎題。在本文中，我們引進了一大批義大利語的文字謎語，並用它來評估最先進的大語言模型的謎語解題能力。儘管 LLaMA-3 和 GPT-4o 等通用系統在此任務上的表現不佳，但特別微調似乎能提升模型的表現。然而，我們發現訓練產生的表現提升，在很大程度上是由於記憶。我們的結果顯示，謎語解題仍然是大語言模型語言能力和循序指令遵循技能評估的嚴峻考驗。

##### **Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation**
2408.00555v1 by Xiaoye Qu, Qiyuan Chen, Wei Wei, Jishuo Sun, Jianfeng Dong

Despite the remarkable ability of large vision-language models (LVLMs) in
image comprehension, these models frequently generate plausible yet factually
incorrect responses, a phenomenon known as hallucination.Recently, in large
language models (LLMs), augmenting LLMs by retrieving information from external
knowledge resources has been proven as a promising solution to mitigate
hallucinations.However, the retrieval augmentation in LVLM significantly lags
behind the widespread applications of LVLM. Moreover, when transferred to
augmenting LVLMs, sometimes the hallucination degree of the model is even
exacerbated.Motivated by the research gap and counter-intuitive phenomenon, we
introduce a novel framework, the Active Retrieval-Augmented large
vision-language model (ARA), specifically designed to address hallucinations by
incorporating three critical dimensions: (i) dissecting the retrieval targets
based on the inherent hierarchical structures of images. (ii) pinpointing the
most effective retrieval methods and filtering out the reliable retrieval
results. (iii) timing the retrieval process to coincide with episodes of low
certainty, while circumventing unnecessary retrieval during periods of high
certainty. To assess the capability of our proposed ARA model in reducing
hallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and
mPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by
utilizing fitting retrieval mechanisms and timing the retrieval judiciously, we
can effectively mitigate the hallucination problem. We hope that this study can
provide deeper insights into how to adapt the retrieval augmentation to LVLMs
for reducing hallucinations with more effective retrieval and minimal retrieval
occurrences.

摘要：儘管大型視覺語言模型 (LVLMs) 在影像理解方面擁有非凡能力，但這些模型經常產生看似合理卻事實上不正確的回應，這種現象稱為幻覺。最近，在大型語言模型 (LLMs) 中，透過從外部知識資源擷取資訊來擴充 LLM 已被證明是一種減輕幻覺的有前途的解決方案。然而，LVLM 中的擷取擴充顯著落後於 LVLM 的廣泛應用。此外，當轉移到擴充 LVLMs 時，有時模型的幻覺程度甚至會加劇。在研究差距和反直覺現象的激勵下，我們引入了新穎的架構，主動擷取擴充大型視覺語言模型 (ARA)，專門設計用於透過納入三個關鍵面向來解決幻覺問題：(i) 根據影像的內在階層結構剖析擷取目標。(ii) 精確找出最有效的擷取方法，並過濾出可靠的擷取結果。(iii) 安排擷取流程與低確定性事件一致，同時在高確定性期間迴避不必要的擷取。為了評估我們提出的 ARA 模型在減少幻覺方面的能力，我們在四個基準測試中採用了三個廣泛使用的 LVLM 模型 (LLaVA-1.5、Qwen-VL 和 mPLUG-Owl2)。我們的經驗觀察表明，透過善用合適的擷取機制並明智安排擷取時機，我們可以有效減輕幻覺問題。我們希望這項研究可以提供更深入的見解，說明如何調整擷取擴充以適用於 LVLMs，以更有效的擷取和最少的擷取發生次數來減少幻覺。

##### **Mitigating Multilingual Hallucination in Large Vision-Language Models**
2408.00550v1 by Xiaoye Qu, Mingyang Song, Wei Wei, Jianfeng Dong, Yu Cheng

While Large Vision-Language Models (LVLMs) have exhibited remarkable
capabilities across a wide range of tasks, they suffer from hallucination
problems, where models generate plausible yet incorrect answers given the input
image-query pair. This hallucination phenomenon is even more severe when
querying the image in non-English languages, while existing methods for
mitigating hallucinations in LVLMs only consider the English scenarios. In this
paper, we make the first attempt to mitigate this important multilingual
hallucination in LVLMs. With thorough experiment analysis, we found that
multilingual hallucination in LVLMs is a systemic problem that could arise from
deficiencies in multilingual capabilities or inadequate multimodal abilities.
To this end, we propose a two-stage Multilingual Hallucination Removal (MHR)
framework for LVLMs, aiming to improve resistance to hallucination for both
high-resource and low-resource languages. Instead of relying on the intricate
manual annotations of multilingual resources, we fully leverage the inherent
capabilities of the LVLM and propose a novel cross-lingual alignment method,
which generates multiple responses for each image-query input and then
identifies the hallucination-aware pairs for each language. These data pairs
are finally used for direct preference optimization to prompt the LVLMs to
favor non-hallucinating responses. Experimental results show that our MHR
achieves a substantial reduction in hallucination generation for LVLMs.
Notably, on our extended multilingual POPE benchmark, our framework delivers an
average increase of 19.0% in accuracy across 13 different languages. Our code
and model weights are available at https://github.com/ssmisya/MHR

摘要：<paragraph>儘管大型視覺語言模型 (LVLMs) 在各種任務中展現出非凡的能力，但它們卻飽受幻覺問題所苦，也就是模型根據輸入的影像查詢對產生看似合理但實際上不正確的答案。這種幻覺現象在以非英語語言查詢影像時會更加嚴重，而現有針對 LVLMs 中幻覺問題的緩解方法僅考慮英語情境。在本文中，我們首次嘗試緩解 LVLMs 中這種重要的多語言幻覺問題。透過徹底的實驗分析，我們發現 LVLMs 中的多語言幻覺是一個系統性問題，可能源自多語言能力的不足或多模態能力的不足。有鑑於此，我們針對 LVLMs 提出一個兩階段的多語言幻覺移除 (MHR) 架構，目標是提升高資源語言和低資源語言對幻覺的抵抗力。我們並未依賴多語言資源的複雜手動註解，而是充分利用 LVLM 的內在能力，並提出一個創新的跨語言對齊方法，為每個影像查詢輸入產生多個回應，然後針對每種語言找出具備幻覺感知能力的配對。這些資料配對最後用於直接偏好最佳化，促使 LVLMs 偏好非幻覺的回應。實驗結果顯示，我們的 MHR 大幅減少了 LVLMs 中的幻覺產生。值得注意的是，在我們擴充的多語言 POPE 基準測試中，我們的架構在 13 種不同語言中平均提升了 19.0% 的準確度。我們的程式碼和模型權重可在 https://github.com/ssmisya/MHR 取得</paragraph>

##### **Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model**
2408.00544v1 by Felipe Mahlow, André Felipe Zanella, William Alberto Cruz Castañeda, Regilene Aparecida Sarzi-Ribeiro

In recent years, Generative Artificial Intelligence (GenAI) has undergone a
profound transformation in addressing intricate tasks involving diverse
modalities such as textual, auditory, visual, and pictorial generation. Within
this spectrum, text-to-image (TTI) models have emerged as a formidable approach
to generating varied and aesthetically appealing compositions, spanning
applications from artistic creation to realistic facial synthesis, and
demonstrating significant advancements in computer vision, image processing,
and multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a
paradigm shift in the domain of AI capabilities. This article delves into the
feasibility of employing the Stable Diffusion LDM to illustrate literary works.
For this exploration, seven classic Brazilian books have been selected as case
studies. The objective is to ascertain the practicality of this endeavor and to
evaluate the potential of Stable Diffusion in producing illustrations that
augment and enrich the reader's experience. We will outline the beneficial
aspects, such as the capacity to generate distinctive and contextually
pertinent images, as well as the drawbacks, including any shortcomings in
faithfully capturing the essence of intricate literary depictions. Through this
study, we aim to provide a comprehensive assessment of the viability and
efficacy of utilizing AI-generated illustrations in literary contexts,
elucidating both the prospects and challenges encountered in this pioneering
application of technology.

摘要：近年来，生成式人工智能（GenAI）在解决涉及文本、听觉、视觉和图像生成等不同模态的复杂任务方面经历了深刻的变革。在这个范围内，文本到图像（TTI）模型已经成为一种强大的方法，可以生成各种美观动人的构图，跨越从艺术创作到逼真的面部合成等应用，并在计算机视觉、图像处理和多模态任务方面展示了重大进展。潜在扩散模型（LDM）的出现标志着人工智能能力领域的一个范式转变。本文深入探讨了采用 Stable Diffusion LDM 来阐释文学作品的可行性。对于这项探索，选择了七本经典的巴西书籍作为案例研究。目的是确定这项工作的实用性，并评估 Stable Diffusion 在制作插图方面的潜力，以增强和丰富读者的体验。我们将概述有益的方面，例如生成独特且在上下文上相关的图像的能力，以及缺点，包括忠实捕捉复杂文学描绘的精髓方面的任何缺陷。通过这项研究，我们旨在对在文学语境中使用人工智能生成插图的可行性和有效性进行全面评估，阐明在这项开创性的技术应用中遇到的前景和挑战。

##### **The Energy Cost of Artificial Intelligence of Things Lifecycle**
2408.00540v1 by Shih-Kai Chou, Jernej Hribar, Mihael Mohorčič, Carolina Fortuna

Artificial intelligence (AI)coupled with existing Internet of Things (IoT)
enables more streamlined and autonomous operations across various economic
sectors. Consequently, the paradigm of Artificial Intelligence of Things (AIoT)
having AI techniques at its core implies additional energy and carbon costs
that may become significant with more complex neural architectures. To better
understand the energy and Carbon Footprint (CF) of some AIoT components, very
recent studies employ conventional metrics. However, these metrics are not
designed to capture energy efficiency aspects of inference. In this paper, we
propose a new metric, the Energy Cost of AIoT Lifecycle (eCAL) to capture the
overall energy cost of inference over the lifecycle of an AIoT system. We
devise a new methodology for determining eCAL of an AIoT system by analyzing
the complexity of data manipulation in individual components involved in the
AIoT lifecycle and derive the overall and per bit energy consumption. With eCAL
we show that the better a model is and the more it is used, the more energy
efficient an inference is. For an example AIoT configuration, eCAL for making
$100$ inferences is $1.43$ times higher than for $1000$ inferences. We also
evaluate the CF of the AIoT system by calculating the equivalent CO$_{2}$
emissions based on the energy consumption and the Carbon Intensity (CI) across
different countries. Using 2023 renewable data, our analysis reveals that
deploying an AIoT system in Germany results in emitting $4.62$ times higher
CO$_2$ than in Finland, due to latter using more low-CI energy sources.

摘要：人工智慧 (AI) 搭配現有的物聯網 (IoT)
能使各種經濟部門的運作更流暢且更自主。因此，以人工智慧技術為核心的物聯網人工智慧 (AIoT) 典範，暗示著額外的能源與碳成本，而這可能會隨著更複雜的神經架構而顯著增加。為了更了解一些 AIoT 元件的能源與碳足跡 (CF)，最近的研究採用傳統的指標。然而，這些指標並非設計用來捕捉推理的能源效率面向。在本文中，我們提出一個新的指標，即 AIoT 生命周期能源成本 (eCAL)，以捕捉 AIoT 系統生命周期中推理的整體能源成本。我們設計了一種新的方法來確定 AIoT 系統的 eCAL，方法是分析參與 AIoT 生命周期中個別元件中資料處理的複雜性，並推導出整體和每位元能源消耗。有了 eCAL，我們表明模型越好且使用越多，推理的能源效率就越高。對於範例 AIoT 組態，進行 100 次推理的 eCAL 比進行 1000 次推理高出 1.43 倍。我們也透過計算基於不同國家/地區的能源消耗和碳強度 (CI) 的等效 CO2 排放量，來評估 AIoT 系統的 CF。我們的分析使用 2023 年可再生能源資料，揭示在德國部署 AIoT 系統會排放比芬蘭高出 4.62 倍的 CO2，這是因為後者使用更多低 CI 能源。

##### **Intermittent Semi-working Mask: A New Masking Paradigm for LLMs**
2408.00539v1 by Mingcong Lu, Jiangcai Zhu, Wang Hao, Zheng Li, Shusheng Zhang, Kailai Shao, Chao Chen, Nan Li, Feng Wang, Xin Lu

Multi-turn dialogues are a key interaction method between humans and Large
Language Models (LLMs), as conversations extend over multiple rounds, keeping
LLMs' high generation quality and low latency is a challenge. Mainstream LLMs
can be grouped into two categories based on masking strategy: causal LLM and
prefix LLM. Several works have demonstrated that prefix LLMs tend to outperform
causal ones in scenarios that heavily depend on historical context such as
multi-turn dialogues or in-context learning, thanks to their bidirectional
attention on prefix sequences. However, prefix LLMs have an inherent
inefficient training problem in multi-turn dialogue datasets. In addition, the
attention mechanism of prefix LLM makes it unable to reuse Key-Value Cache (KV
Cache) across dialogue rounds to reduce generation latency. In this paper, we
propose a novel masking scheme called Intermittent Semi-working Mask (ISM) to
address these problems. Specifically, we apply alternate bidirectional and
unidirectional attention on queries and answers in the dialogue history. In
this way, ISM is able to maintain the high quality of prefix LLM and low
generation latency of causal LLM, simultaneously. Extensive experiments
illustrate that our ISM achieves significant performance.

摘要：多輪對話是人類與大型語言模型 (LLM) 之間的一種關鍵互動方法，由於對話會持續多輪，因此維持 LLM 的高生成品質和低延遲是一項挑戰。主流 LLM 可以根據遮罩策略分為兩類：因果 LLM 和前綴 LLM。多項研究已證明，前綴 LLM 在高度依賴歷史脈絡的場景中往往優於因果 LLM，例如多輪對話或情境學習，這要歸功於它們對前綴序列的雙向關注。然而，前綴 LLM 在多輪對話資料集中存在固有低效率的訓練問題。此外，前綴 LLM 的注意力機制使其無法在對話回合中重複使用鍵值快取 (KV 快取) 來降低生成延遲。在本文中，我們提出了一種稱為間歇半工作遮罩 (ISM) 的新遮罩方案來解決這些問題。具體來說，我們對對話記錄中的查詢和答案套用交替的雙向和單向注意力。透過這種方式，ISM 能夠同時維持前綴 LLM 的高品質和因果 LLM 的低生成延遲。廣泛的實驗說明我們的 ISM 獲得了顯著的效能。

##### **The Monetisation of Toxicity: Analysing YouTube Content Creators and Controversy-Driven Engagement**
2408.00534v1 by Thales Bertaglia, Catalina Goanta, Adriana Iamnitchi

YouTube is a major social media platform that plays a significant role in
digital culture, with content creators at its core. These creators often engage
in controversial behaviour to drive engagement, which can foster toxicity. This
paper presents a quantitative analysis of controversial content on YouTube,
focusing on the relationship between controversy, toxicity, and monetisation.
We introduce a curated dataset comprising 20 controversial YouTube channels
extracted from Reddit discussions, including 16,349 videos and more than 105
million comments. We identify and categorise monetisation cues from video
descriptions into various models, including affiliate marketing and direct
selling, using lists of URLs and keywords. Additionally, we train a machine
learning model to measure the toxicity of comments in these videos. Our
findings reveal that while toxic comments correlate with higher engagement,
they negatively impact monetisation, indicating that controversy-driven
interaction does not necessarily lead to financial gain. We also observed
significant variation in monetisation strategies, with some creators showing
extensive monetisation despite high toxicity levels. Our study introduces a
curated dataset, lists of URLs and keywords to categorise monetisation, a
machine learning model to measure toxicity, and is a significant step towards
understanding the complex relationship between controversy, engagement, and
monetisation on YouTube. The lists used for detecting and categorising
monetisation cues are available on https://github.com/thalesbertaglia/toxmon.

摘要：YouTube 是一个重要的社交媒體平台，在數位文化中扮演著重要的角色，而內容創作者則是其核心。這些創作者經常參與有爭議的行為以推動參與，這可能會助長毒性。本文提出對 YouTube 上有爭議內容的量化分析，重點關注爭議、毒性和獲利之間的關係。我們引入了一個精選的資料集，其中包含從 Reddit 討論中提取的 20 個有爭議的 YouTube 頻道，包括 16,349 個影片和超過 1.05 億則留言。我們從影片說明中識別並分類出各種獲利線索，包括聯盟行銷和直接銷售，並使用 URL 和關鍵字清單。此外，我們訓練了一個機器學習模型來衡量這些影片中留言的毒性。我們的研究結果顯示，雖然有毒的留言與較高的參與度相關，但它們會對獲利產生負面影響，這表示由爭議驅動的互動不一定會帶來財務收益。我們還觀察到獲利策略有顯著差異，一些創作者即使毒性程度很高，也表現出廣泛的獲利。我們的研究引入了精選的資料集、用於分類獲利的 URL 和關鍵字清單、用於衡量毒性的機器學習模型，並且是了解 YouTube 上爭議、參與度和獲利之間複雜關係的重要一步。用於偵測和分類獲利線索的清單可在 https://github.com/thalesbertaglia/toxmon 上取得。

##### **Jailbreaking Text-to-Image Models with LLM-Based Agents**
2408.00523v1 by Yingkai Dong, Zheng Li, Xiangtao Meng, Ning Yu, Shanqing Guo

Recent advancements have significantly improved automated task-solving
capabilities using autonomous agents powered by large language models (LLMs).
However, most LLM-based agents focus on dialogue, programming, or specialized
domains, leaving gaps in addressing generative AI safety tasks. These gaps are
primarily due to the challenges posed by LLM hallucinations and the lack of
clear guidelines. In this paper, we propose Atlas, an advanced LLM-based
multi-agent framework that integrates an efficient fuzzing workflow to target
generative AI models, specifically focusing on jailbreak attacks against
text-to-image (T2I) models with safety filters. Atlas utilizes a
vision-language model (VLM) to assess whether a prompt triggers the T2I model's
safety filter. It then iteratively collaborates with both LLM and VLM to
generate an alternative prompt that bypasses the filter. Atlas also enhances
the reasoning abilities of LLMs in attack scenarios by leveraging multi-agent
communication, in-context learning (ICL) memory mechanisms, and the
chain-of-thought (COT) approach. Our evaluation demonstrates that Atlas
successfully jailbreaks several state-of-the-art T2I models in a black-box
setting, which are equipped with multi-modal safety filters. In addition, Atlas
outperforms existing methods in both query efficiency and the quality of the
generated images.

摘要：<paragraph>最近的進展已經大幅改進了自動任務解決能力，使用大型語言模型（LLM）驅動的自主代理。然而，大多數基於 LLM 的代理專注於對話、程式設計或專業領域，在解決生成式 AI 安全任務方面留下了空白。這些空白主要是由於 LLM 幻覺帶來的挑戰和缺乏明確的指導方針。在本文中，我們提出 Atlas，一個基於 LLM 的先進多代理框架，它整合了一個高效的模糊測試工作流程來針對生成式 AI 模型，特別關注對具有安全過濾器的文字到圖像（T2I）模型的越獄攻擊。Atlas 利用視覺語言模型（VLM）來評估提示是否觸發了 T2I 模型的安全過濾器。然後，它與 LLM 和 VLM 進行反覆協作，以生成一個繞過過濾器的替代提示。Atlas 還通過利用多代理通信、情境學習（ICL）記憶機制和思維鏈（COT）方法，增強了 LLM 在攻擊場景中的推理能力。我們的評估表明，Atlas 在黑盒設置中成功越獄了幾個最先進的 T2I 模型，這些模型配備了多模式安全過濾器。此外，Atlas 在查詢效率和生成圖像的品質方面都優於現有方法。</paragraph>

##### **A new approach for encoding code and assisting code understanding**
2408.00521v1 by Mengdan Fan, Wei Zhang, Haiyan Zhao, Zhi Jin

Some companies(e.g., Microsoft Research and Google DeepMind) have discovered
some of the limitations of GPTs autoregressive paradigm next-word prediction,
manifested in the model lack of planning, working memory, backtracking, and
reasoning skills. GPTs rely on a local and greedy process of generating the
next word, without a global understanding of the task or the output.We have
confirmed the above limitations through specialized empirical studies of code
comprehension. Although GPT4 is good at producing fluent and coherent text, it
cannot handle complex logic and generate new code that haven not been seen, and
it relies too much on the formatting of the prompt to generate the correct
code.We propose a new paradigm for code understanding that goes beyond the
next-word prediction paradigm, inspired by the successful application of
diffusion techniques to image generation(Dalle2, Sora) and protein structure
generation(AlphaFold3), which have no autoregressive constraints.Instead of
encoding the code in a form that mimics natural language, we encode the code as
a heterogeneous image paradigm with a memory of global information that mimics
both images and protein structures.We then refer to Sora's CLIP upstream
text-to-image encoder model to design a text-to-code encoder model that can be
applied to various downstream code understanding tasks.The model learns the
global understanding of code under the new paradigm heterogeneous image,
connects the encoding space of text and code, and encodes the input of text
into the vector of code most similar to it.Using self-supervised comparative
learning on 456,360 text-code pairs, the model achieved a zero-shot prediction
of new data. This work is the basis for future work on code generation using
diffusion techniques under a new paradigm to avoid autoregressive limitations.

摘要：一些公司（例如 Microsoft Research 和 Google DeepMind）已經發現 GPT 自動迴歸範例中的一些限制，即下一個字詞預測，體現在模型缺乏規劃、工作記憶、回溯和推理技能。GPT 依賴於產生下一個字詞的局部和貪婪過程，而沒有對任務或輸出的全局理解。我們已經通過程式碼理解的專門經驗研究確認了上述限制。儘管 GPT4 擅長產生流暢且連貫的文字，但它無法處理複雜的邏輯和產生未曾見過的新程式碼，而且它過於依賴提示的格式來產生正確的程式碼。我們提出了超越下一個字詞預測範例的程式碼理解新範例，靈感來自擴散技術成功應用於影像產生（Dalle2、Sora）和蛋白質結構產生（AlphaFold3），它們沒有自動迴歸約束。我們沒有使用模仿自然語言的形式對程式碼進行編碼，而是將程式碼編碼為異質影像範例，其中包含模仿影像和蛋白質結構的全局資訊記憶體。然後，我們參考 Sora 的 CLIP 上游文字轉影像編碼器模型，設計一個文字轉程式碼編碼器模型，該模型可應用於各種下游程式碼理解任務。該模型在新的範例異質影像下學習程式碼的全局理解，連接文字和程式碼的編碼空間，並將文字輸入編碼成與其最相似的程式碼向量。使用 456,360 個文字程式碼對上的自我監督比較學習，該模型實現了新資料的零次學習預測。這項工作是使用擴散技術在新的範例下進行程式碼產生的未來工作的基礎，以避免自動迴歸限制。

##### **GalleryGPT: Analyzing Paintings with Large Multimodal Models**
2408.00491v1 by Yi Bin, Wenhao Shi, Yujuan Ding, Zhiqiang Hu, Zheng Wang, Yang Yang, See-Kiong Ng, Heng Tao Shen

Artwork analysis is important and fundamental skill for art appreciation,
which could enrich personal aesthetic sensibility and facilitate the critical
thinking ability. Understanding artworks is challenging due to its subjective
nature, diverse interpretations, and complex visual elements, requiring
expertise in art history, cultural background, and aesthetic theory. However,
limited by the data collection and model ability, previous works for
automatically analyzing artworks mainly focus on classification, retrieval, and
other simple tasks, which is far from the goal of AI. To facilitate the
research progress, in this paper, we step further to compose comprehensive
analysis inspired by the remarkable perception and generation ability of large
multimodal models. Specifically, we first propose a task of composing paragraph
analysis for artworks, i.e., painting in this paper, only focusing on visual
characteristics to formulate more comprehensive understanding of artworks. To
support the research on formal analysis, we collect a large dataset
PaintingForm, with about 19k painting images and 50k analysis paragraphs. We
further introduce a superior large multimodal model for painting analysis
composing, dubbed GalleryGPT, which is slightly modified and fine-tuned based
on LLaVA architecture leveraging our collected data. We conduct formal analysis
generation and zero-shot experiments across several datasets to assess the
capacity of our model. The results show remarkable performance improvements
comparing with powerful baseline LMMs, demonstrating its superb ability of art
analysis and generalization. \textcolor{blue}{The codes and model are available
at: https://github.com/steven640pixel/GalleryGPT.

摘要：<paragraph>藝術品分析是藝術鑑賞的重要且基本的技能，
它可以豐富個人的美學素養，促進批判性思考能力。由於其主觀性、多樣化的詮釋和複雜的視覺元素，理解藝術品具有挑戰性，需要藝術史、文化背景和美學理論方面的專業知識。然而，受限於數據收集和模型能力，以往自動化分析藝術品的相關研究主要集中於分類、檢索和其他簡單的任務，這遠遠達不到 AI 的目標。為了促進研究進展，本文進一步提出由大型多模態模型卓越的感知和生成能力所激發的綜合分析。具體來說，我們首先提出了一個針對藝術品（本文中為繪畫）撰寫段落分析的任務，僅專注於視覺特徵，以制定對藝術品的更全面理解。為了支持形式分析的研究，我們收集了一個大型數據集 PaintingForm，其中包含約 19k 幅繪畫圖像和 50k 段分析段落。我們進一步引入了一個用於繪畫分析撰寫的優越大型多模態模型 GalleryGPT，該模型基於 LLaVA 架構並利用我們收集的數據進行了微調和微調。我們在幾個數據集上進行了形式分析生成和零樣本實驗，以評估我們模型的能力。結果顯示，與強大的基線 LMM 相比，我們的模型取得了顯著的性能改進，證明了其在藝術分析和泛化方面的卓越能力。\textcolor{blue}{代碼和模型可在以下位置獲得：https://github.com/steven640pixel/GalleryGPT。</paragraph>

##### **Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation**
2408.00490v1 by Chu Zhao, Enneng Yang, Yuliang Liang, Pengxiang Lan, Yuting Liu, Jianzhe Zhao, Guibing Guo, Xingwei Wang

Graph Neural Networks (GNNs)-based recommendation algorithms typically assume
that training and testing data are drawn from independent and identically
distributed (IID) spaces. However, this assumption often fails in the presence
of out-of-distribution (OOD) data, resulting in significant performance
degradation. In this study, we construct a Structural Causal Model (SCM) to
analyze interaction data, revealing that environmental confounders (e.g., the
COVID-19 pandemic) lead to unstable correlations in GNN-based models, thus
impairing their generalization to OOD data. To address this issue, we propose a
novel approach, graph representation learning via causal diffusion
(CausalDiffRec) for OOD recommendation. This method enhances the model's
generalization on OOD data by eliminating environmental confounding factors and
learning invariant graph representations. Specifically, we use backdoor
adjustment and variational inference to infer the real environmental
distribution, thereby eliminating the impact of environmental confounders. This
inferred distribution is then used as prior knowledge to guide the
representation learning in the reverse phase of the diffusion process to learn
the invariant representation. In addition, we provide a theoretical derivation
that proves optimizing the objective function of CausalDiffRec can encourage
the model to learn environment-invariant graph representations, thereby
achieving excellent generalization performance in recommendations under
distribution shifts. Our extensive experiments validate the effectiveness of
CausalDiffRec in improving the generalization of OOD data, and the average
improvement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and
11.65% on Douban datasets.

摘要：<paragraph>基於圖神經網路 (GNN) 的推薦演算法通常假設訓練和測試資料是從獨立同分布 (IID) 空間中提取的。然而，這個假設在存在非分布 (OOD) 資料時常常會失敗，導致效能大幅下降。在本研究中，我們建構了一個結構因果模型 (SCM) 來分析互動資料，揭示環境混雜因子（例如，COVID-19 大流行）會導致基於 GNN 的模型中出現不穩定的相關性，進而損害其對 OOD 資料的泛化。為了解決這個問題，我們提出了一種創新的方法，即透過因果擴散進行圖表示學習（CausalDiffRec），以進行 OOD 推薦。此方法透過消除環境混雜因子和學習不變圖表示，增強模型對 OOD 資料的泛化。具體來說，我們使用後門調整和變異推論來推論真實的環境分佈，從而消除環境混雜因子的影響。然後將這個推論出的分佈用作先驗知識，以引導擴散過程的反向階段中的表示學習，以學習不變表示。此外，我們提供了理論推導，證明最佳化 CausalDiffRec 的目標函數可以促使模型學習與環境無關的圖表示，從而在分佈轉移下實現出色的推薦泛化效能。我們廣泛的實驗驗證了 CausalDiffRec 在改善 OOD 資料泛化方面的有效性，在 Food 上的平均改善幅度高達 10.69%，在 KuaiRec 上為 18.83%，在 Yelp2018 上為 22.41%，在 Douban 資料集上為 11.65%。</paragraph>

##### **A Systematic Review on Long-Tailed Learning**
2408.00483v1 by Chongsheng Zhang, George Almpanidis, Gaojuan Fan, Binquan Deng, Yanbo Zhang, Ji Liu, Aouaidjia Kamel, Paolo Soda, João Gama

Long-tailed data is a special type of multi-class imbalanced data with a very
large amount of minority/tail classes that have a very significant combined
influence. Long-tailed learning aims to build high-performance models on
datasets with long-tailed distributions, which can identify all the classes
with high accuracy, in particular the minority/tail classes. It is a
cutting-edge research direction that has attracted a remarkable amount of
research effort in the past few years. In this paper, we present a
comprehensive survey of latest advances in long-tailed visual learning. We
first propose a new taxonomy for long-tailed learning, which consists of eight
different dimensions, including data balancing, neural architecture, feature
enrichment, logits adjustment, loss function, bells and whistles, network
optimization, and post hoc processing techniques. Based on our proposed
taxonomy, we present a systematic review of long-tailed learning methods,
discussing their commonalities and alignable differences. We also analyze the
differences between imbalance learning and long-tailed learning approaches.
Finally, we discuss prospects and future directions in this field.

摘要：長尾數據是一種特殊類型，具有大量少數/尾部類別的多類別不平衡數據，這些類別具有非常顯著的綜合影響。長尾學習旨在建立具有長尾分佈的數據集的高性能模型，該模型可以識別所有類別，特別是少數/尾部類別，具有很高的準確度。這是一個尖端的的研究方向，在過去幾年中吸引了大量的研究工作。在本文中，我們對長尾視覺學習的最新進展進行了全面的調查。我們首先提出了長尾學習的新分類法，其中包括八個不同的維度，包括數據平衡、神經架構、特徵豐富、對數調整、損失函數、花裡胡哨、網路最佳化和事後處理技術。根據我們提出的分類法，我們對長尾學習方法進行了系統的回顧，討論了它們的共性和可比性差異。我們還分析了不平衡學習和長尾學習方法之間的差異。最後，我們討論了該領域的前景和未來方向。

##### **HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization**
2408.00481v1 by Bolin Zhang, Zhiwei Yi, Jiahao Wang, Dianbo Sui, Zhiying Tu, Dianhui Chu

The unique diagnosis and treatment techniques and remarkable clinical
efficacy of traditional Chinese medicine (TCM) make it play an important role
in the field of elderly care and healthcare, especially in the rehabilitation
of some common chronic diseases of the elderly. Therefore, building a TCM
chatbot for healthcare application will help users obtain consultation services
in a direct and natural way. However, concepts such as acupuncture points
(acupoints) and meridians involved in TCM always appear in the consultation,
which cannot be displayed intuitively. To this end, we develop a
\textbf{h}ealthcare chat\textbf{bot} (HBot) based on a human body model in 3D
and knowledge graph, which provides conversational services such as knowledge
Q\&A, prescription recommendation, moxibustion therapy recommendation, and
acupoint search. When specific acupoints are involved in the conversations
between user and HBot, the 3D body will jump to the corresponding acupoints and
highlight them. Moreover, Hbot can also be used in training scenarios to
accelerate the teaching process of TCM by intuitively displaying acupuncture
points and knowledge cards. The demonstration video is available at
https://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly
available at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git

摘要：中醫獨特的診治手法和顯著的臨床療效，在老年照護與保健領域中扮演著重要的角色，特別是在老年人常見慢性疾病的復健上。因此，建構一個中醫醫療照護聊天機器人，將有助於使用者以直接且自然的方式取得諮詢服務。然而，中醫所涉及的穴位、經絡等概念，在諮詢時總是會出現，而這些無法直觀地顯示出來。為了解決這個問題，我們開發了一個基於 3D 人體模型和知識圖譜的醫療照護聊天機器人（HBot），它提供了知識問答、處方推薦、艾灸療法推薦和穴位查詢等對話服務。當使用者與 HBot 的對話中涉及到具體穴位時，3D 人體會跳轉到對應的穴位並將其高亮顯示。此外，HBot 還可以用於培訓場景中，通過直觀地顯示穴位和知識卡片，來加速中醫教學的進程。示範影片可於 https://www.youtube.com/watch?v=UhQhutSKkTU 取得。我們的程式碼和資料集已於 Gitee 公開：https://gitee.com/plabrolin/interactive-3d-acup.git

##### **Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach**
2408.00473v1 by Pedro Ramoneda, Vsevolod Eremenko, Alexandre D'Hooge, Emilia Parada-Cabaleiro, Xavier Serra

Estimating music piece difficulty is important for organizing educational
music collections. This process could be partially automatized to facilitate
the educator's role. Nevertheless, the decisions performed by prevalent
deep-learning models are hardly understandable, which may impair the acceptance
of such a technology in music education curricula. Our work employs explainable
descriptors for difficulty estimation in symbolic music representations.
Furthermore, through a novel parameter-efficient white-box model, we outperform
previous efforts while delivering interpretable results. These comprehensible
outcomes emulate the functionality of a rubric, a tool widely used in music
education. Our approach, evaluated in piano repertoire categorized in 9
classes, achieved 41.4% accuracy independently, with a mean squared error (MSE)
of 1.7, showing precise difficulty estimation. Through our baseline, we
illustrate how building on top of past research can offer alternatives for
music difficulty assessment which are explainable and interpretable. With this,
we aim to promote a more effective communication between the Music Information
Retrieval (MIR) community and the music education one.

摘要：評估音樂作品的難度對於組織教學音樂合集來說非常重要。這個過程可以部分自動化，以促進教育者的角色。儘管如此，流行的深度學習模型做出的決定難以理解，這可能會損害這種技術在音樂教育課程中的接受度。我們的作品採用可解釋的描述符來估計符號音樂表示中的難度。此外，通過一個新的參數有效的白盒模型，我們在提供可解釋的結果的同時，超越了以往的努力。這些可理解的結果模擬了評分標準的功能，評分標準是音樂教育中廣泛使用的一種工具。我們的做法在分為 9 类的鋼琴曲目中進行了評估，獨立實現了 41.4% 的準確率，均方誤差 (MSE) 為 1.7，顯示出精確的難度估計。通過我們的基準，我們說明了如何建立在過去的研究之上，可以提供可解釋和可理解的音樂難度評估的替代方案。通過這個，我們旨在促進音樂信息檢索 (MIR) 社群與音樂教育社群之間更有效的溝通。

##### **DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration**
2408.00447v1 by Chengbo Zheng, Yuanhao Zhang, Zeyu Huang, Chuhan Shi, Minrui Xu, Xiaojuan Ma

Interdisciplinary studies often require researchers to explore literature in
diverse branches of knowledge. Yet, navigating through the highly scattered
knowledge from unfamiliar disciplines poses a significant challenge. In this
paper, we introduce DiscipLink, a novel interactive system that facilitates
collaboration between researchers and large language models (LLMs) in
interdisciplinary information seeking (IIS). Based on users' topics of
interest, DiscipLink initiates exploratory questions from the perspectives of
possible relevant fields of study, and users can further tailor these
questions. DiscipLink then supports users in searching and screening papers
under selected questions by automatically expanding queries with
disciplinary-specific terminologies, extracting themes from retrieved papers,
and highlighting the connections between papers and questions. Our evaluation,
comprising a within-subject comparative experiment and an open-ended
exploratory study, reveals that DiscipLink can effectively support researchers
in breaking down disciplinary boundaries and integrating scattered knowledge in
diverse fields. The findings underscore the potential of LLM-powered tools in
fostering information-seeking practices and bolstering interdisciplinary
research.

摘要：跨領域研究往往需要研究人員探索不同知識領域的文獻。然而，在不熟悉的領域中穿梭於高度分散的知識，構成了一項重大的挑戰。在本文中，我們介紹了 DiscipLink，一個新穎的互動式系統，它促進了研究人員與大型語言模型 (LLM) 在跨領域資訊搜尋 (IIS) 中的協作。根據使用者的興趣主題，DiscipLink 從可能相關的研究領域的角度提出探索性問題，而使用者可以進一步調整這些問題。接著，DiscipLink 透過自動擴充查詢，使用特定於領域的術語，從檢索到的論文中萃取主題，並強調論文與問題之間的關聯，來支援使用者在所選問題之下搜尋和篩選論文。我們的評量包含一個受試者內比較實驗和一個開放式的探索性研究，結果顯示 DiscipLink 能有效地支援研究人員打破學科界線，並整合不同領域中分散的知識。這些發現強調了 LLM 驅動工具在促進資訊搜尋實務和強化跨領域研究方面的潛力。

##### **Ontological Relations from Word Embeddings**
2408.00444v1 by Mathieu d'Aquin, Emmanuel Nauer

It has been reliably shown that the similarity of word embeddings obtained
from popular neural models such as BERT approximates effectively a form of
semantic similarity of the meaning of those words. It is therefore natural to
wonder if those embeddings contain enough information to be able to connect
those meanings through ontological relationships such as the one of
subsumption. If so, large knowledge models could be built that are capable of
semantically relating terms based on the information encapsulated in word
embeddings produced by pre-trained models, with implications not only for
ontologies (ontology matching, ontology evolution, etc.) but also on the
ability to integrate ontological knowledge in neural models. In this paper, we
test how embeddings produced by several pre-trained models can be used to
predict relations existing between classes and properties of popular
upper-level and general ontologies. We show that even a simple feed-forward
architecture on top of those embeddings can achieve promising accuracies, with
varying generalisation abilities depending on the input data. To achieve that,
we produce a dataset that can be used to further enhance those models, opening
new possibilities for applications integrating knowledge from web ontologies.

摘要：可靠地表明，从流行神经模型（例如 BERT）获得的词嵌入的相似性有效地近似了这些词的意义的语义相似性。因此，自然会想知道这些嵌入是否包含足够的信息，以便能够通过本体关系（例如从属关系）来连接这些含义。如果是这样，则可以构建大型知识模型，这些模型能够基于预训练模型产生的词嵌入中封装的信息在语义上关联术语，不仅对本体（本体匹配、本体演化等）产生影响，而且对在神经模型中集成本体知识的能力产生影响。在本文中，我们测试了由几个预训练模型产生的嵌入如何用于预测流行的上层和通用本体的类和属性之间存在的关联。我们表明，即使在这些嵌入之上建立一个简单的前馈架构也能实现有希望的准确性，其泛化能力因输入数据而异。为了实现这一目标，我们生成了一个数据集，可用于进一步增强这些模型，为集成来自 Web 本体知识的应用程序开辟了新的可能性。

##### **Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval**
2408.00441v1 by Gangyan Zeng, Yuan Zhang, Jin Wei, Dongbao Yang, Peng Zhang, Yiwen Gao, Xugong Qin, Yu Zhou

Scene text retrieval aims to find all images containing the query text from
an image gallery. Current efforts tend to adopt an Optical Character
Recognition (OCR) pipeline, which requires complicated text detection and/or
recognition processes, resulting in inefficient and inflexible retrieval.
Different from them, in this work we propose to explore the intrinsic potential
of Contrastive Language-Image Pre-training (CLIP) for OCR-free scene text
retrieval. Through empirical analysis, we observe that the main challenges of
CLIP as a text retriever are: 1) limited text perceptual scale, and 2)
entangled visual-semantic concepts. To this end, a novel model termed FDP
(Focus, Distinguish, and Prompt) is developed. FDP first focuses on scene text
via shifting the attention to the text area and probing the hidden text
knowledge, and then divides the query text into content word and function word
for processing, in which a semantic-aware prompting scheme and a distracted
queries assistance module are utilized. Extensive experiments show that FDP
significantly enhances the inference speed while achieving better or
competitive retrieval accuracy compared to existing methods. Notably, on the
IIIT-STR benchmark, FDP surpasses the state-of-the-art model by 4.37% with a 4
times faster speed. Furthermore, additional experiments under phrase-level and
attribute-aware scene text retrieval settings validate FDP's particular
advantages in handling diverse forms of query text. The source code will be
publicly available at https://github.com/Gyann-z/FDP.

摘要：場景文字檢索旨在從圖像庫中找出所有包含查詢文字的圖像。目前的努力傾向於採用光學字元辨識 (OCR) 管線，這需要複雜的文字偵測和/或辨識過程，導致檢索效率低下且不靈活。與它們不同，在這項工作中，我們提議探索對比式語言影像預訓練 (CLIP) 在無 OCR 場景文字檢索中的內在潛力。透過實證分析，我們觀察到 CLIP 作為文字檢索器的主要挑戰有：1) 受限的文字感知規模，以及 2) 糾纏的視覺語義概念。為此，開發了一個稱為 FDP（專注、區分和提示）的新穎模型。FDP 首先透過將注意力轉移到文字區域並探查隱藏的文字知識來專注於場景文字，然後將查詢文字分成內容字和功能字進行處理，其中利用了語義感知提示方案和分散查詢輔助模組。廣泛的實驗顯示，與現有方法相比，FDP 大幅提升了推論速度，同時達到了更好或具有競爭力的檢索準確度。值得注意的是，在 IIIT-STR 基準上，FDP 以快 4 倍的速度超越了最先進的模型，達到了 4.37%。此外，在詞組級別和屬性感知場景文字檢索設定下的額外實驗驗證了 FDP 在處理多樣化的查詢文字形式方面的特殊優勢。原始碼將公開在 https://github.com/Gyann-z/FDP。

##### **A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality**
2408.00435v1 by M. Mehdi Kholoosi, M. Ali Babar, Roland Croft

Artificial Intelligence (AI) advancements have enabled the development of
Large Language Models (LLMs) that can perform a variety of tasks with
remarkable semantic understanding and accuracy. ChatGPT is one such LLM that
has gained significant attention due to its impressive capabilities for
assisting in various knowledge-intensive tasks. Due to the knowledge-intensive
nature of engineering secure software, ChatGPT's assistance is expected to be
explored for security-related tasks during the development/evolution of
software. To gain an understanding of the potential of ChatGPT as an emerging
technology for supporting software security, we adopted a two-fold approach.
Initially, we performed an empirical study to analyse the perceptions of those
who had explored the use of ChatGPT for security tasks and shared their views
on Twitter. It was determined that security practitioners view ChatGPT as
beneficial for various software security tasks, including vulnerability
detection, information retrieval, and penetration testing. Secondly, we
designed an experiment aimed at investigating the practicality of this
technology when deployed as an oracle in real-world settings. In particular, we
focused on vulnerability detection and qualitatively examined ChatGPT outputs
for given prompts within this prominent software security task. Based on our
analysis, responses from ChatGPT in this task are largely filled with generic
security information and may not be appropriate for industry use. To prevent
data leakage, we performed this analysis on a vulnerability dataset compiled
after the OpenAI data cut-off date from real-world projects covering 40
distinct vulnerability types and 12 programming languages. We assert that the
findings from this study would contribute to future research aimed at
developing and evaluating LLMs dedicated to software security.

摘要：<paragraph>人工智慧 (AI) 的進步促成了大型語言模型 (LLM) 的發展，此模型可以執行各種任務，具備卓越的語意理解和準確度。ChatGPT 就是其中一個大型語言模型，由於其在協助各種知識密集型任務方面具有令人印象深刻的能力，因此備受關注。由於工程安全軟體的知識密集性，預計在軟體開發/演進過程中，將探索 ChatGPT 的協助，以執行與安全相關的任務。為了了解 ChatGPT 作為支援軟體安全的新興技術的潛力，我們採取了雙管齊下的方法。最初，我們進行了一項實證研究，以分析那些已經探索將 ChatGPT 用於安全任務的人的看法，並在 Twitter 上分享他們的觀點。確定安全從業人員將 ChatGPT 視為對各種軟體安全任務有益，包括漏洞偵測、資訊擷取和滲透測試。其次，我們設計了一個實驗，旨在調查在現實世界中將此技術部署為神諭時的實用性。特別是，我們專注於漏洞偵測，並在這個突出的軟體安全任務中，對 ChatGPT 對於給定提示的輸出進行定性檢查。根據我們的分析，ChatGPT 在此任務中的回應在很大程度上充斥著一般的安全資訊，可能不適合產業使用。為了防止資料外洩，我們在 OpenAI 資料截止日期後編譯的漏洞資料集上執行此分析，該資料集涵蓋了來自現實世界專案的 40 種不同的漏洞類型和 12 種程式語言。我們斷言，這項研究的發現將有助於未來的研究，目的是開發和評估專門用於軟體安全的 LLM。</paragraph>

##### **CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images**
2408.00427v1 by Thiziri Nait Saada, Valentina Di-Proietto, Benoit Schmauch, Katharina Von Loga, Lucas Fidon

Multiple Instance Learning (MIL) models have proven effective for cancer
prognosis from Whole Slide Images. However, the original MIL formulation
incorrectly assumes the patches of the same image to be independent, leading to
a loss of spatial context as information flows through the network.
Incorporating contextual knowledge into predictions is particularly important
given the inclination for cancerous cells to form clusters and the presence of
spatial indicators for tumors. State-of-the-art methods often use attention
mechanisms eventually combined with graphs to capture spatial knowledge. In
this paper, we take a novel and transversal approach, addressing this issue
through the lens of regularization. We propose Context-Aware Regularization for
Multiple Instance Learning (CARMIL), a versatile regularization scheme designed
to seamlessly integrate spatial knowledge into any MIL model. Additionally, we
present a new and generic metric to quantify the Context-Awareness of any MIL
model when applied to Whole Slide Images, resolving a previously unexplored gap
in the field. The efficacy of our framework is evaluated for two survival
analysis tasks on glioblastoma (TCGA GBM) and colon cancer data (TCGA COAD).

摘要：多实例学习 (MIL) 模型已证明对全切片图像的癌症预后有效。然而，原始的 MIL 公式错误地假设同一图像的补丁是独立的，导致空间上下文在信息流经网络时丢失。考虑到癌细胞形成簇的倾向和肿瘤的空间指标，将上下文知识纳入预测中尤为重要。最先进的方法通常使用注意力机制，最终与图结合来捕获空间知识。在本文中，我们采用了一种新颖且横向的方法，通过正则化的视角来解决这个问题。我们提出了用于多实例学习的上下文感知正则化 (CARMIL)，这是一种通用正则化方案，旨在将空间知识无缝集成到任何 MIL 模型中。此外，我们提出了一个新的通用指标来量化任何 MIL 模型在应用于全切片图像时的上下文感知度，从而解决了该领域以前未探索的差距。我们的框架的有效性在胶质母细胞瘤 (TCGA GBM) 和结肠癌数据 (TCGA COAD) 的两个生存分析任务中得到评估。

##### **MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition**
2408.00420v1 by Wenqing Gan, Yan Sun, Feiran Liu, Xiangfeng Luo

The objective of the panoramic activity recognition task is to identify
behaviors at various granularities within crowded and complex environments,
encompassing individual actions, social group activities, and global
activities. Existing methods generally use either parameter-independent modules
to capture task-specific features or parameter-sharing modules to obtain common
features across all tasks. However, there is often a strong interrelatedness
and complementary effect between tasks of different granularities that previous
methods have yet to notice. In this paper, we propose a model called MPT-PAR
that considers both the unique characteristics of each task and the synergies
between different tasks simultaneously, thereby maximizing the utilization of
features across multi-granularity activity recognition. Furthermore, we
emphasize the significance of temporal and spatial information by introducing a
spatio-temporal relation-enhanced module and a scene representation learning
module, which integrate the the spatio-temporal context of action and global
scene into the feature map of each granularity. Our method achieved an overall
F1 score of 47.5\% on the JRDB-PAR dataset, significantly outperforming all the
state-of-the-art methods.

摘要：全景活动识别任务的目的是识别在拥挤而复杂的环境中各种粒度下的行为，包括个人动作、社交团体活动和全局活动。现有方法通常使用与参数无关的模块来捕获特定任务特征，或使用参数共享模块来获取所有任务的共同特征。然而，不同粒度任务之间通常存在很强的相互关联性和互补效应，而之前的研究尚未注意到这一点。在本文中，我们提出了一个名为 MPT-PAR 的模型，该模型同时考虑了每个任务的独特特征和不同任务之间的协同作用，从而最大化了多粒度活动识别中特征的利用率。此外，我们通过引入时空关系增强模块和场景表示学习模块来强调时间和空间信息的重要性，该模块将动作和全局场景的时空上下文整合到每个粒度的特征图中。我们的方法在 JRDB-PAR 数据集上的总体 F1 得分为 47.5%，明显优于所有最先进的方法。

##### **DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving**
2408.00415v1 by Xuemeng Yang, Licheng Wen, Yukai Ma, Jianbiao Mei, Xin Li, Tiantian Wei, Wenjie Lei, Daocheng Fu, Pinlong Cai, Min Dou, Botian Shi, Liang He, Yong Liu, Yu Qiao

This paper presented DriveArena, the first high-fidelity closed-loop
simulation system designed for driving agents navigating in real scenarios.
DriveArena features a flexible, modular architecture, allowing for the seamless
interchange of its core components: Traffic Manager, a traffic simulator
capable of generating realistic traffic flow on any worldwide street map, and
World Dreamer, a high-fidelity conditional generative model with infinite
autoregression. This powerful synergy empowers any driving agent capable of
processing real-world images to navigate in DriveArena's simulated environment.
The agent perceives its surroundings through images generated by World Dreamer
and output trajectories. These trajectories are fed into Traffic Manager,
achieving realistic interactions with other vehicles and producing a new scene
layout. Finally, the latest scene layout is relayed back into World Dreamer,
perpetuating the simulation cycle. This iterative process fosters closed-loop
exploration within a highly realistic environment, providing a valuable
platform for developing and evaluating driving agents across diverse and
challenging scenarios. DriveArena signifies a substantial leap forward in
leveraging generative image data for the driving simulation platform, opening
insights for closed-loop autonomous driving. Code will be available soon on
GitHub: https://github.com/PJLab-ADG/DriveArena

摘要：本文展示了 DriveArena，這是第一個專為在真實場景中導航的駕駛代理而設計的高保真閉環模擬系統。
DriveArena 採用靈活的模組化架構，允許其核心組件無縫交換：Traffic Manager，一個能夠在全球任何街道地圖上產生逼真交通流的交通模擬器，以及 World Dreamer，一個具有無限自迴歸的高保真條件式生成模型。這個強大的協同效應讓任何能夠處理真實世界影像的駕駛代理都能在 DriveArena 的模擬環境中導航。
代理透過 World Dreamer 生成的影像感知其周圍環境並輸出軌跡。這些軌跡被輸入 Traffic Manager，與其他車輛進行逼真的互動並產生新的場景佈局。最後，最新的場景佈局被傳遞回 World Dreamer，持續進行模擬循環。這個反覆的過程促進了在高度逼真環境中的閉環探索，為在各種具有挑戰性的場景中開發和評估駕駛代理提供了有價值的平台。DriveArena 標誌著在利用生成影像資料進行駕駛模擬平台方面取得了重大進展，為閉環自動駕駛開啟了新的見解。代碼將很快在 GitHub 上提供：https://github.com/PJLab-ADG/DriveArena

##### **In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation**
2408.00397v1 by Armel Zebaze, Benoît Sagot, Rachel Bawden

The ability of generative large language models (LLMs) to perform in-context
learning has given rise to a large body of research into how best to prompt
models for various natural language processing tasks. In this paper, we focus
on machine translation (MT), a task that has been shown to benefit from
in-context translation examples. However no systematic studies have been
published on how best to select examples, and mixed results have been reported
on the usefulness of similarity-based selection over random selection. We
provide a study covering multiple LLMs and multiple in-context example
retrieval strategies, comparing multilingual sentence embeddings. We cover
several language directions, representing different levels of language
resourcedness (English into French, German, Swahili and Wolof). Contrarily to
previously published results, we find that sentence embedding similarity can
improve MT, especially for low-resource language directions, and discuss the
balance between selection pool diversity and quality. We also highlight
potential problems with the evaluation of LLM-based MT and suggest a more
appropriate evaluation protocol, adapting the COMET metric to the evaluation of
LLMs. Code and outputs are freely available at
https://github.com/ArmelRandy/ICL-MT.

摘要：生成式大型语言模型 (LLM) 在语境中进行学习的能力催生了许多关于如何最好地提示模型执行各种自然语言处理任务的研究。在本文中，我们重点关注机器翻译 (MT)，一项已被证明可以从语境翻译示例中受益的任务。然而，还没有关于如何最好地选择示例的系统性研究，并且已经报道了基于相似性的选择优于随机选择的用处。我们提供了一项涵盖多个 LLM 和多个语境示例检索策略的研究，比较了多语言句子嵌入。我们涵盖了几个语言方向，代表了不同级别的语言资源（英语到法语、德语、斯瓦希里语和沃洛夫语）。与先前公布的结果相反，我们发现句子嵌入相似性可以改善机器翻译，特别是对于低资源语言方向，并讨论了选择池多样性和质量之间的平衡。我们还强调了基于 LLM 的机器翻译评估的潜在问题，并提出了一个更合适的评估协议，将 COMET 指标调整为评估 LLM。代码和输出可在 https://github.com/ArmelRandy/ICL-MT 免费获得。

##### **Enhancing Whole Slide Pathology Foundation Models through Stain Normalization**
2408.00380v1 by Juseung Yun, Yi Hu, Jinhyung Kim, Jongseong Jang, Soonyoung Lee

Recent advancements in digital pathology have led to the development of
numerous foundational models that utilize self-supervised learning on patches
extracted from gigapixel whole slide images (WSIs). While this approach
leverages vast amounts of unlabeled data, we have discovered a significant
issue: features extracted from these self-supervised models tend to cluster by
individual WSIs, a phenomenon we term WSI-specific feature collapse. This
problem can potentially limit the model's generalization ability and
performance on various downstream tasks. To address this issue, we introduce
Stain Normalized Pathology Foundational Model, a novel foundational model
trained on patches that have undergone stain normalization. Stain normalization
helps reduce color variability arising from different laboratories and
scanners, enabling the model to learn more consistent features. Stain
Normalized Pathology Foundational Model is trained using 285,153,903 patches
extracted from a total of 34,795 WSIs, combining data from The Cancer Genome
Atlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments
demonstrate that Stain Normalized Pathology Foundational Model significantly
mitigates the feature collapse problem, indicating that the model has learned
more generalized features rather than overfitting to individual WSI
characteristics. We compared Stain Normalized Pathology Foundational Model with
state-of-the-art models across six downstream task datasets, and our results
show that \name{} achieves excellent performance relative to the number of WSIs
used and the model's parameter count. This suggests that the application of
stain normalization has substantially improved the model's efficiency and
generalization capabilities.

摘要：<paragraph>數位病理學的最新進展促成了許多基礎模型的開發，這些模型利用自監督學習來處理從千兆像素全玻片影像 (WSI) 中提取的區塊。儘管這種方法利用了大量的未標籤資料，我們發現了一個重大的問題：從這些自監督模型中提取的特徵傾向於按個別 WSI 分群，我們將這種現象稱為 WSI 特定特徵崩潰。此問題可能會限制模型的泛化能力和在各種下游任務上的效能。為了解決這個問題，我們引入了染色標準化病理基礎模型，這是一個新穎的基礎模型，針對經過染色標準化處理的區塊進行訓練。染色標準化有助於減少來自不同實驗室和掃描儀的色彩變異性，使模型能夠學習更一致的特徵。染色標準化病理基礎模型使用從總共 34,795 個 WSI 中提取的 285,153,903 個區塊進行訓練，結合了癌症基因組圖譜 (TCGA) 和基因型組織表達 (GTEx) 專案的資料。我們的實驗證明，染色標準化病理基礎模型顯著減輕了特徵崩潰問題，這表示模型已經學習到更廣義的特徵，而不是過度擬合到個別 WSI 特徵。我們在六個下游任務資料集上將染色標準化病理基礎模型與最先進的模型進行比較，我們的結果顯示，\name{} 相對於所使用的 WSI 數量和模型的參數數量，達到了極佳的效能。這表明染色標準化的應用大幅提升了模型的效率和泛化能力。</paragraph>

##### **On the Limitations and Prospects of Machine Unlearning for Generative AI**
2408.00376v1 by Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang

Generative AI (GenAI), which aims to synthesize realistic and diverse data
samples from latent variables or other data modalities, has achieved remarkable
results in various domains, such as natural language, images, audio, and
graphs. However, they also pose challenges and risks to data privacy, security,
and ethics. Machine unlearning is the process of removing or weakening the
influence of specific data samples or features from a trained model, without
affecting its performance on other data or tasks. While machine unlearning has
shown significant efficacy in traditional machine learning tasks, it is still
unclear if it could help GenAI become safer and aligned with human desire. To
this end, this position paper provides an in-depth discussion of the machine
unlearning approaches for GenAI. Firstly, we formulate the problem of machine
unlearning tasks on GenAI and introduce the background. Subsequently, we
systematically examine the limitations of machine unlearning on GenAI models by
focusing on the two representative branches: LLMs and image generative
(diffusion) models. Finally, we provide our prospects mainly from three
aspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and
conscientiously advocate for the future development of this field.

摘要：生成式 AI (GenAI) 旨在從潛在變數或其他資料模式中合成逼真且多樣化的資料範例，已在自然語言、影像、音訊和圖形等各種領域中取得顯著成果。然而，它們也對資料隱私、安全性與道德構成挑戰和風險。機器遺忘是移除或減弱特定資料範例或特徵對已訓練模型的影響，同時不影響其在其他資料或任務上的效能。雖然機器遺忘已在傳統機器學習任務中展現顯著的功效，但仍不清楚它是否能協助 GenAI 變得更安全且符合人類的期望。為此，本立場文件深入探討了 GenAI 的機器遺忘方法。首先，我們制定 GenAI 上機器遺忘任務的問題，並介紹背景。接著，我們有系統地檢視機器遺忘在 GenAI 模型上的限制，重點放在兩個代表性的分支：LLM 和影像生成（擴散）模型。最後，我們主要從基準、評估指標和效用遺忘權衡三個面向提供我們的展望，並審慎倡議該領域的未來發展。

##### **Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving**
2408.00374v1 by Xi Chen, Rahul Bhadani, Larry Head

Current research on trajectory prediction primarily relies on data collected
by onboard sensors of an ego vehicle. With the rapid advancement in connected
technologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure
(V2I) communication, valuable information from alternate views becomes
accessible via wireless networks. The integration of information from
alternative views has the potential to overcome the inherent limitations
associated with a single viewpoint, such as occlusions and limited field of
view. In this work, we introduce V2INet, a novel trajectory prediction
framework designed to model multi-view data by extending existing single-view
models. Unlike previous approaches where the multi-view data is manually fused
or formulated as a separate training stage, our model supports end-to-end
training, enhancing both flexibility and performance. Moreover, the predicted
multimodal trajectories are calibrated by a post-hoc conformal prediction
module to get valid and efficient confidence regions. We evaluated the entire
framework using the real-world V2I dataset V2X-Seq. Our results demonstrate
superior performance in terms of Final Displacement Error (FDE) and Miss Rate
(MR) using a single GPU. The code is publicly available at:
\url{https://github.com/xichennn/V2I_trajectory_prediction}.

摘要：目前關於軌跡預測的研究主要依賴於自我車輛上搭載感測器所收集的資料。隨著車聯網技術的快速發展，例如車對車 (V2V) 和車對基礎設施 (V2I) 通訊，來自備用視角的寶貴資訊可透過無線網路存取。整合來自備用視角的資訊有潛力克服與單一視角相關的固有限制，例如遮擋和受限視野。在這項工作中，我們引進 V2INet，這是一個新穎的軌跡預測架構，旨在透過擴充現有的單一視角模型來建構多視角資料。與先前的做法不同，先前的做法是手動融合多視角資料或將其制定為一個獨立的訓練階段，我們的模型支援端對端的訓練，提升了彈性和效能。此外，預測的多模態軌跡由事後共形預測模組校正，以取得有效且精確的信心區域。我們使用真實世界的 V2I 資料集 V2X-Seq 評估了整個架構。我們的結果證明，使用單一 GPU 時，在最終位移誤差 (FDE) 和遺漏率 (MR) 方面表現出優異的效能。程式碼已公開於：\url{https://github.com/xichennn/V2I_trajectory_prediction}。

##### **DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework**
2408.00370v1 by Fan Zhang, Naye Ji, Fuxing Gao, Bozuo Zhao, Jingmei Wu, Yanbing Jiang, Hui Du, Zhenqing Ye, Jiayang Zhu, WeiFan Zhong, Leyao Yan, Xiaomeng Ma

Speech-driven gesture generation is an emerging domain within virtual human
creation, where current methods predominantly utilize Transformer-based
architectures that necessitate extensive memory and are characterized by slow
inference speeds. In response to these limitations, we propose
\textit{DiM-Gestures}, a novel end-to-end generative model crafted to create
highly personalized 3D full-body gestures solely from raw speech audio,
employing Mamba-based architectures. This model integrates a Mamba-based fuzzy
feature extractor with a non-autoregressive Adaptive Layer Normalization
(AdaLN) Mamba-2 diffusion architecture. The extractor, leveraging a Mamba
framework and a WavLM pre-trained model, autonomously derives implicit,
continuous fuzzy features, which are then unified into a singular latent
feature. This feature is processed by the AdaLN Mamba-2, which implements a
uniform conditional mechanism across all tokens to robustly model the interplay
between the fuzzy features and the resultant gesture sequence. This innovative
approach guarantees high fidelity in gesture-speech synchronization while
maintaining the naturalness of the gestures. Employing a diffusion model for
training and inference, our framework has undergone extensive subjective and
objective evaluations on the ZEGGS and BEAT datasets. These assessments
substantiate our model's enhanced performance relative to contemporary
state-of-the-art methods, demonstrating competitive outcomes with the DiTs
architecture (Persona-Gestors) while optimizing memory usage and accelerating
inference speed.

摘要：語音驅動手勢生成是虛擬人類創造中一個新興領域，其中當前方法主要利用 Transformer 架構，需要大量的記憶體，並且特徵是推論速度慢。為了應對這些限制，我們提出了 \textit{DiM-Gestures}，這是一個新穎的端到端生成模型，專門用於僅從原始語音音訊建立高度個人化的 3D 全身手勢，使用基於 Mamba 的架構。此模型將基於 Mamba 的模糊特徵萃取器與非自迴歸適應層正規化 (AdaLN) Mamba-2 擴散架構整合在一起。萃取器利用 Mamba 框架和 WavLM 預訓練模型，自主地推導出隱含的、連續的模糊特徵，然後將這些特徵統一成一個單一的潛在特徵。此特徵由 AdaLN Mamba-2 處理，它在所有標記之間實作一個統一的條件機制，以穩健地模擬模糊特徵與結果手勢序列之間的交互作用。這種創新的方法保證了手勢語音同步的高保真度，同時保持手勢的自然性。透過採用擴散模型進行訓練和推論，我們的框架在 ZEGGS 和 BEAT 資料集上進行了廣泛的主觀和客觀評估。這些評估證實了我們的模型相對於當代最先進方法的增強效能，展示了與 DiTs 架構（Persona-Gestors）具有競爭力的成果，同時優化了記憶體使用量並加速了推論速度。

##### **Multimodal Fusion and Coherence Modeling for Video Topic Segmentation**
2408.00365v1 by Hai Yu, Chong Deng, Qinglin Zhang, Jiaqing Liu, Qian Chen, Wen Wang

The video topic segmentation (VTS) task segments videos into intelligible,
non-overlapping topics, facilitating efficient comprehension of video content
and quick access to specific content. VTS is also critical to various
downstream video understanding tasks. Traditional VTS methods using shallow
features or unsupervised approaches struggle to accurately discern the nuances
of topical transitions. Recently, supervised approaches have achieved superior
performance on video action or scene segmentation over unsupervised approaches.
In this work, we improve supervised VTS by thoroughly exploring multimodal
fusion and multimodal coherence modeling. Specifically, (1) we enhance
multimodal fusion by exploring different architectures using cross-attention
and mixture of experts. (2) To generally strengthen multimodality alignment and
fusion, we pre-train and fine-tune the model with multimodal contrastive
learning. (3) We propose a new pre-training task tailored for the VTS task, and
a novel fine-tuning task for enhancing multimodal coherence modeling for VTS.
We evaluate the proposed approaches on educational videos, in the form of
lectures, due to the vital role of topic segmentation of educational videos in
boosting learning experiences. Additionally, we introduce a large-scale Chinese
lecture video dataset to augment the existing English corpus, promoting further
research in VTS. Experiments on both English and Chinese lecture datasets
demonstrate that our model achieves superior VTS performance compared to
competitive unsupervised and supervised baselines.

摘要：影片主題分段 (VTS) 任務將影片分段成可理解且不重疊的主題，有助於有效理解影片內容並快速存取特定內容。VTS 對於各種下游影片理解任務也至關重要。使用淺層特徵或非監督式方法的傳統 VTS 方法難以準確辨別主題轉換的細微差別。最近，監督式方法在影片動作或場景分段方面已獲得優於非監督式方法的卓越效能。在這項工作中，我們透過徹底探索多模態融合和多模態相干性模型來改善監督式 VTS。具體來說，(1) 我們透過使用跨注意力和專家混合來探索不同架構，以增強多模態融合。(2) 為了普遍強化多模態對齊和融合，我們使用多模態對比學習預先訓練並微調模型。(3) 我們提出一個專門針對 VTS 任務量身打造的新預訓練任務，以及一個用於增強 VTS 多模態相干性模型的新微調任務。我們在教育影片（以演講形式呈現）上評估所提出的方法，因為主題分段在提升學習體驗中扮演至關重要的角色。此外，我們引進一個大規模的中文演講影片資料集，以擴充現有的英文語料庫，促進 VTS 的進一步研究。在英文和中文演講資料集上的實驗證明，與具有競爭力的非監督式和監督式基準線相比，我們的模型達到了卓越的 VTS 效能。

##### **DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model**
2408.00357v1 by Nan Xie, Yuelin Bai, Hengyuan Gao, Feiteng Fang, Qixuan Zhao, Zhijian Li, Ziqiang Xue, Liang Zhu, Shiwen Ni, Min Yang

Traditional legal retrieval systems designed to retrieve legal documents,
statutes, precedents, and other legal information are unable to give
satisfactory answers due to lack of semantic understanding of specific
questions. Large Language Models (LLMs) have achieved excellent results in a
variety of natural language processing tasks, which inspired us that we train a
LLM in the legal domain to help legal retrieval. However, in the Chinese legal
domain, due to the complexity of legal questions and the rigour of legal
articles, there is no legal large model with satisfactory practical application
yet. In this paper, we present DeliLaw, a Chinese legal counselling system
based on a large language model. DeliLaw integrates a legal retrieval module
and a case retrieval module to overcome the model hallucination. Users can
consult professional legal questions, search for legal articles and relevant
judgement cases, etc. on the DeliLaw system in a dialogue mode. In addition,
DeliLaw supports the use of English for counseling. we provide the address of
the system: https://data.delilegal.com/lawQuestion.

摘要：傳統的法律檢索系統旨在檢索法律文件、法規、判例和其他法律資訊，由於缺乏對特定問題的語義理解，無法給出令人滿意的答案。大型語言模型 (LLM) 在各種自然語言處理任務中取得了優異的成果，這啟發我們在法律領域訓練一個 LLM 來幫助法律檢索。然而，在中文法律領域，由於法律問題的複雜性和法律條文的嚴謹性，目前還沒有令人滿意的實用應用法律大模型。在本文中，我們提出了 DeliLaw，一個基於大型語言模型的中文法律諮詢系統。DeliLaw 整合了一個法律檢索模組和一個案例檢索模組來克服模型幻覺。使用者可以在 DeliLaw 系統上以對話模式諮詢專業法律問題、搜尋法律條文和相關判決案例等。此外，DeliLaw 支援使用英文進行諮詢。我們提供系統網址：https://data.delilegal.com/lawQuestion。

##### **DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training**
2408.00355v1 by Yu Xie, Qian Qiao, Jun Gao, Tianxiang Wu, Shaoyao Huang, Jiaqing Fan, Ziqiang Cao, Zili Wang, Yue Zhang, Jielei Zhang, Huyang Sun

More and more end-to-end text spotting methods based on Transformer
architecture have demonstrated superior performance. These methods utilize a
bipartite graph matching algorithm to perform one-to-one optimal matching
between predicted objects and actual objects. However, the instability of
bipartite graph matching can lead to inconsistent optimization targets, thereby
affecting the training performance of the model. Existing literature applies
denoising training to solve the problem of bipartite graph matching instability
in object detection tasks. Unfortunately, this denoising training method cannot
be directly applied to text spotting tasks, as these tasks need to perform
irregular shape detection tasks and more complex text recognition tasks than
classification. To address this issue, we propose a novel denoising training
method (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we
decompose the queries of the denoising part into noised positional queries and
noised content queries. We use the four Bezier control points of the Bezier
center curve to generate the noised positional queries. For the noised content
queries, considering that the output of the text in a fixed positional order is
not conducive to aligning position with content, we employ a masked character
sliding method to initialize noised content queries, thereby assisting in the
alignment of text content and position. To improve the model's perception of
the background, we further utilize an additional loss function for background
characters classification in the denoising training part.Although DNTextSpotter
is conceptually simple, it outperforms the state-of-the-art methods on four
benchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially
yielding an improvement of 11.3% against the best approach in Inverse-Text
dataset.

摘要：越來越多的基於 Transformer 架構的端到端文字偵測方法已經展示出優異的效能。這些方法利用二部圖匹配演算法，在預測物件和實際物件之間執行一對一最佳匹配。然而，二部圖匹配的不穩定性可能導致不一致的最佳化目標，進而影響模型的訓練效能。現有的文獻將去噪訓練應用於解決物件偵測任務中二部圖匹配不穩定的問題。不幸的是，這種去噪訓練方法無法直接應用於文字偵測任務，因為這些任務需要執行不規則形狀偵測任務和比分類更複雜的文字辨識任務。為了解決這個問題，我們提出了一種針對任意形狀文字偵測的新穎去噪訓練方法 (DNTextSpotter)。具體來說，我們將去噪部分的查詢分解為有雜訊的位置查詢和有雜訊的內容查詢。我們使用貝茲中心曲線的四個貝茲控制點來生成有雜訊的位置查詢。對於有雜訊的內容查詢，考慮到以固定位置順序輸出的文字不利於將位置與內容對齊，我們採用遮罩字元滑動方法來初始化有雜訊的內容查詢，從而協助文字內容和位置的對齊。為了改善模型對背景的感知，我們進一步在去噪訓練部分中利用一個額外的損失函數進行背景字元分類。儘管 DNTextSpotter 在概念上很簡單，但在四個基準（Total-Text、SCUT-CTW1500、ICDAR15 和 Inverse-Text）上都優於最先進的方法，特別是在 Inverse-Text 資料集上相較於最佳方法提升了 11.3%。

##### **A Simple Background Augmentation Method for Object Detection with Diffusion Model**
2408.00350v1 by Yuhang Li, Xin Dong, Chen Chen, Weiming Zhuang, Lingjuan Lyu

In computer vision, it is well-known that a lack of data diversity will
impair model performance. In this study, we address the challenges of enhancing
the dataset diversity problem in order to benefit various downstream tasks such
as object detection and instance segmentation. We propose a simple yet
effective data augmentation approach by leveraging advancements in generative
models, specifically text-to-image synthesis technologies like Stable
Diffusion. Our method focuses on generating variations of labeled real images,
utilizing generative object and background augmentation via inpainting to
augment existing training data without the need for additional annotations. We
find that background augmentation, in particular, significantly improves the
models' robustness and generalization capabilities. We also investigate how to
adjust the prompt and mask to ensure the generated content comply with the
existing annotations. The efficacy of our augmentation techniques is validated
through comprehensive evaluations of the COCO dataset and several other key
object detection benchmarks, demonstrating notable enhancements in model
performance across diverse scenarios. This approach offers a promising solution
to the challenges of dataset enhancement, contributing to the development of
more accurate and robust computer vision models.

摘要：在電腦視覺中，眾所周知資料的多樣性不足會影響模型的效能。在本研究中，我們探討了提升資料集多樣性問題的挑戰，以利於各種下游任務，例如物件偵測和實例分割。我們提出一個簡單但有效的資料擴充方法，利用生成模型的進展，特別是文字轉圖像合成技術，例如 Stable Diffusion。我們的做法專注於產生標記真實影像的變化，利用生成物件和背景擴充，透過修補來擴充現有的訓練資料，而無需額外的註解。我們發現背景擴充，特別是顯著地改善了模型的穩健性和泛化能力。我們還探討如何調整提示和遮罩，以確保產生的內容符合現有的註解。我們透過 COCO 資料集和幾個其他關鍵物件偵測基準的全面評估，驗證了我們的擴充技術的效能，展示了在各種場景中模型效能的顯著提升。這種方法為資料集增強的挑戰提供了有希望的解決方案，有助於開發更準確和穩健的電腦視覺模型。

##### **Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer**
2408.00347v1 by Sungmin Kang, Jaeha Song, Jihie Kim

Understanding the morphological structure of medical images and precisely
segmenting the region of interest or abnormality is an important task that can
assist in diagnosis. However, the unique properties of medical imaging make
clear segmentation difficult, and the high cost and time-consuming task of
labeling leads to a coarse-grained representation of ground truth. Facing with
these problems, we propose a novel Diffusion Transformer Segmentation (DTS)
model for robust segmentation in the presence of noise. We propose an
alternative to the dominant Denoising U-Net encoder through experiments
applying a transformer architecture, which captures global dependency through
self-attention. Additionally, we propose k-neighbor label smoothing, reverse
boundary attention, and self-supervised learning with morphology-driven
learning to improve the ability to identify complex structures. Our model,
which analyzes the morphological representation of images, shows better results
than the previous models in various medical imaging modalities, including CT,
MRI, and lesion images.

摘要：了解醫學影像的形態結構並精確分割感興趣或異常區域是一項重要的任務，有助於診斷。然而，醫學影像的獨特屬性使得清晰的分割變得困難，而標籤的高成本和耗時任務導致了地面實況的粗略表示。面對這些問題，我們提出了一個新的擴散Transformer分割（DTS）模型，用於在有噪聲的情況下進行穩健分割。我們通過應用捕獲全局依賴性的自注意力Transformer架構，提出了一個替代主流去噪 U-Net 編碼器的方案。此外，我們提出了 k 近鄰標籤平滑、反向邊界注意力，以及使用形態驅動學習的自監督學習，以提高識別複雜結構的能力。我們的模型分析了影像的形態表示，在各種醫學影像方式中顯示出比以前模型更好的結果，包括 CT、MRI 和病灶影像。

##### **Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerce**
2408.00346v1 by Houye Ji, Ye Tang, Zhaoxin Chen, Lixi Deng, Jun Hu, Lei Su

With the rapid development of the short video industry, traditional
e-commerce has encountered a new paradigm, video-driven e-commerce, which
leverages attractive videos for product showcases and provides both video and
item services for users. Benefitting from the dynamic and visualized
introduction of items,video-driven e-commerce has shown huge potential in
stimulating consumer confidence and promoting sales. In this paper, we focus on
the video retrieval task, facing the following challenges: (1) Howto handle the
heterogeneities among users, items, and videos? (2)How to mine the
complementarity between items and videos for better user understanding? In this
paper, we first leverage the dual graph to model the co-existing of user-video
and user-item interactions in video-driven e-commerce and innovatively reduce
user preference understanding to a graph matching problem. To solve it, we
further propose a novel bi-level Graph Matching Network(GMN), which mainly
consists of node- and preference-level graph matching. Given a user, node-level
graph matching aims to match videos and items, while preference-level graph
matching aims to match multiple user preferences extracted from both videos and
items. Then the proposed GMN can generate and improve user embedding by
aggregating matched nodes or preferences from the dual graph in a bi-level
manner. Comprehensive experiments show the superiority of the proposed GMN with
significant improvements over state-of-the-art approaches (e.g., AUC+1.9% and
CTR+7.15%). We have developed it on a well-known video-driven e-commerce
platform, serving hundreds of millions of users every day

摘要：<paragraph>隨著短影音產業的快速發展，傳統電商迎來新典範「影音電商」，其利用吸睛的影片進行商品展示，並為使用者提供影音與商品服務。影音電商受益於動態且視覺化的商品介紹，在提升消費者信心及促進銷售上展現龐大潛力。本論文聚焦於影音檢索任務，面臨的挑戰如下：(1)如何處理使用者、商品與影片間的異質性？(2)如何挖掘商品與影片間的互補性，以更佳理解使用者？本論文首先利用雙圖模型化影音電商中使用者-影片與使用者-商品互動的共存，並創新地將使用者偏好理解化約為圖形配對問題。為了解決此問題，我們進一步提出一個新穎的雙層圖形配對網路(GMN)，其主要包含節點層級與偏好層級圖形配對。針對一個使用者，節點層級圖形配對旨在配對影片與商品，而偏好層級圖形配對旨在配對從影片與商品中萃取出的多重使用者偏好。接著，所提出的GMN可以透過雙層方式彙總雙圖中配對的節點或偏好，以產生並改善使用者嵌入。綜合實驗顯示，所提出的GMN優於現有技術方法，並有顯著的進步(例如，AUC+1.9%和CTR+7.15%)。我們已於一個知名的影音電商平台上開發此方法，每天服務上億名使用者</paragraph>

##### **OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack**
2408.00329v1 by Kuo Gai, Sicong Wang, Shihua Zhang

Deep neural networks (DNNs) are vulnerable to small adversarial perturbations
of the inputs, posing a significant challenge to their reliability and
robustness. Empirical methods such as adversarial training can defend against
particular attacks but remain vulnerable to more powerful attacks.
Alternatively, Lipschitz networks provide certified robustness to unseen
perturbations but lack sufficient expressive power. To harness the advantages
of both approaches, we design a novel two-step Optimal Transport induced
Adversarial Defense (OTAD) model that can fit the training data accurately
while preserving the local Lipschitz continuity. First, we train a DNN with a
regularizer derived from optimal transport theory, yielding a discrete optimal
transport map linking data to its features. By leveraging the map's inherent
regularity, we interpolate the map by solving the convex integration problem
(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse
architectures of ResNet and Transformer, making it suitable for complex data.
For efficient computation, the CIP can be solved through training neural
networks. OTAD opens a novel avenue for developing reliable and secure deep
learning systems through the regularity of optimal transport maps. Empirical
results demonstrate that OTAD can outperform other robust models on diverse
datasets.

摘要：深度神經網路 (DNN) 容易受到輸入的小幅對抗性擾動影響，對其可靠性和穩健性構成重大挑戰。對抗訓練等經驗方法可以抵禦特定攻擊，但仍然容易受到更強大的攻擊。或者，Lipschitz 網路提供對未見擾動的認證穩健性，但缺乏足夠的表達能力。為了利用兩種方法的優點，我們設計了一個新穎的兩步驟最佳傳輸誘導對抗防禦 (OTAD) 模型，該模型可以準確擬合訓練數據，同時保持局部 Lipschitz 連續性。首先，我們使用源自最佳傳輸理論的正則化器訓練 DNN，產生將數據連結到其特徵的離散最佳傳輸映射。通過利用映射的固有規律性，我們通過求解凸積分問題 (CIP) 來插值映射，以保證局部 Lipschitz 屬性。OTAD 可擴展到 ResNet 和 Transformer 的各種架構，使其適用於複雜數據。為了有效計算，CIP 可以通過訓練神經網路來求解。OTAD 通過最佳傳輸映射的規律性，為開發可靠且安全的深度學習系統開闢了一條新途徑。經驗結果表明，OTAD 在各種數據集上可以優於其他穩健模型。

##### **ADBM: Adversarial diffusion bridge model for reliable adversarial purification**
2408.00315v1 by Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu

Recently Diffusion-based Purification (DiffPure) has been recognized as an
effective defense method against adversarial examples. However, we find
DiffPure which directly employs the original pre-trained diffusion models for
adversarial purification, to be suboptimal. This is due to an inherent
trade-off between noise purification performance and data recovery quality.
Additionally, the reliability of existing evaluations for DiffPure is
questionable, as they rely on weak adaptive attacks. In this work, we propose a
novel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs
a reverse bridge from the diffused adversarial data back to its original clean
examples, enhancing the purification capabilities of the original diffusion
models. Through theoretical analysis and experimental validation across various
scenarios, ADBM has proven to be a superior and robust defense mechanism,
offering significant promise for practical applications.

摘要：最近，基于扩散的净化（DiffPure）已被公认为对抗对抗性示例的有效防御方法。然而，我们发现 DiffPure 直接使用原始预训练扩散模型进行对抗性净化，这是次优的。这是由于噪声净化性能和数据恢复质量之间固有的权衡。此外，现有对 DiffPure 的评估的可靠性值得怀疑，因为它们依赖于弱自适应攻击。在这项工作中，我们提出了一种新颖的对抗性扩散桥接模型，称为 ADBM。ADBM 直接从扩散对抗数据构建一个反向桥，回到其原始干净的示例，增强了原始扩散模型的净化能力。通过各种场景的理论分析和实验验证，ADBM 已被证明是一种卓越且稳健的防御机制，为实际应用提供了重要的前景。

##### **ABC Align: Large Language Model Alignment for Safety & Accuracy**
2408.00307v1 by Gareth Seneque, Lap-Hang Ho, Ariel Kuperman, Nafise Erfanian Saeedi, Jeffrey Molendijk

Alignment of Large Language Models (LLMs) remains an unsolved problem. Human
preferences are highly distributed and can be captured at multiple levels of
abstraction, from the individual to diverse populations. Organisational
preferences, represented by standards and principles, are defined to mitigate
reputational risk or meet legislative obligations. In this paper, we present
ABC Align, a novel alignment methodology for LLMs that enables integration of
the standards and preferences of a large media organisation into the LLM
itself. We combine a set of data and methods that build on recent breakthroughs
in synthetic data generation, preference optimisation, and post-training model
quantisation. Our unified approach mitigates bias and improves accuracy, while
preserving reasoning capability, as measured against standard benchmarks.

摘要：大型語言模型 (LLM) 的對齊仍然是一個未解決的問題。人類的偏好高度分散，並且可以在從個人到不同族群的多個抽象層級中被捕捉。由標準和原則所代表的組織偏好被定義為減輕信譽風險或符合法定義務。在本文中，我們提出了 ABC Align，這是一種 LLM 的新對齊方法，它能夠將大型媒體組織的標準和偏好整合到 LLM 本身中。我們結合了一組數據和方法，這些數據和方法建立在合成數據生成、偏好最佳化和訓練後模型量化方面的最新突破之上。我們的統一方法減輕了偏差並提高了準確性，同時保持了推理能力，這是根據標準基準衡量的。

##### **Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck**
2408.00295v1 by Yuntao Shou, Haozhi Lan, Xiangyong Cao

Graph Neural Networks (GNNs) have received extensive research attention due
to their powerful information aggregation capabilities. Despite the success of
GNNs, most of them suffer from the popularity bias issue in a graph caused by a
small number of popular categories. Additionally, real graph datasets always
contain incorrect node labels, which hinders GNNs from learning effective node
representations. Graph contrastive learning (GCL) has been shown to be
effective in solving the above problems for node classification tasks. Most
existing GCL methods are implemented by randomly removing edges and nodes to
create multiple contrasting views, and then maximizing the mutual information
(MI) between these contrasting views to improve the node feature
representation. However, maximizing the mutual information between multiple
contrasting views may lead the model to learn some redundant information
irrelevant to the node classification task. To tackle this issue, we propose an
effective Contrastive Graph Representation Learning with Adversarial Cross-view
Reconstruction and Information Bottleneck (CGRL) for node classification, which
can adaptively learn to mask the nodes and edges in the graph to obtain the
optimal graph structure representation. Furthermore, we innovatively introduce
the information bottleneck theory into GCLs to remove redundant information in
multiple contrasting views while retaining as much information as possible
about node classification. Moreover, we add noise perturbations to the original
views and reconstruct the augmented views by constructing adversarial views to
improve the robustness of node feature representation. Extensive experiments on
real-world public datasets demonstrate that our method significantly
outperforms existing state-of-the-art algorithms.

摘要：圖神經網路 (GNN) 因其強大的資訊彙總能力而受到廣泛的研究關注。儘管 GNN 取得成功，但大多數 GNN 都會受到圖形中少數熱門類別所造成的熱門偏誤問題。此外，實際圖形資料集總是包含不正確的節點標籤，這會阻礙 GNN 學習有效的節點表示。圖對比學習 (GCL) 已被證明可有效解決節點分類任務中的上述問題。大多數現有的 GCL 方法都是透過隨機移除邊緣和節點來建立多個對比視圖，然後最大化這些對比視圖之間的互信息 (MI)，以改善節點特徵表示。然而，最大化多個對比視圖之間的互信息可能會導致模型學習到一些與節點分類任務無關的冗餘資訊。為了解決這個問題，我們提出了一個有效的對比圖形表示學習，帶有對抗性跨視圖重建和資訊瓶頸 (CGRL) 的節點分類，它可以自適應地學習遮蔽圖形中的節點和邊緣，以取得最佳的圖形結構表示。此外，我們創新地將資訊瓶頸理論引入 GCL，以移除多個對比視圖中的冗餘資訊，同時保留盡可能多的節點分類資訊。此外，我們在原始視圖中加入雜訊擾動，並透過建構對抗性視圖來重建擴增的視圖，以改善節點特徵表示的穩健性。在真實世界公開資料集上的廣泛實驗證明，我們的模型顯著優於現有的最先進演算法。

##### **Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**
2408.00290v1 by Bin Cheng, Jiaxuan Lu

With the advent of the era of foundation models, pre-training and fine-tuning
have become common paradigms. Recently, parameter-efficient fine-tuning has
garnered widespread attention due to its better balance between the number of
learnable parameters and performance. However, some current parameter-efficient
fine-tuning methods only model a single modality and lack the utilization of
structural knowledge in downstream tasks. To address this issue, this paper
proposes a multi-modal parameter-efficient fine-tuning method based on graph
networks. Each image is fed into a multi-modal large language model (MLLM) to
generate a text description. The image and its corresponding text description
are then processed by a frozen image encoder and text encoder to generate image
features and text features, respectively. A graph is constructed based on the
similarity of the multi-modal feature nodes, and knowledge and relationships
relevant to these features are extracted from each node. Additionally, Elastic
Weight Consolidation (EWC) regularization is incorporated into the loss
function to mitigate the problem of forgetting during task learning. The
proposed model achieves test accuracies on the OxfordPets, Flowers102, and
Food101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The
code is available at https://github.com/yunche0/GA-Net/tree/master.

摘要：隨著基礎模型時代的到來，預訓練和微調已成為常見的範例。最近，由於參數有效微調在可學習參數數量和效能之間取得更好的平衡，因此備受關注。然而，一些目前的參數有效微調方法僅建模單一模態，且缺乏在下游任務中利用結構知識。為了解決此問題，本文提出了一種基於圖形網路的多模態參數有效微調方法。每個影像都會輸入到多模態大型語言模型 (MLLM) 中，以產生文字描述。然後，影像及其對應的文字描述會由凍結的影像編碼器和文字編碼器處理，分別產生影像特徵和文字特徵。根據多模態特徵節點的相似性建構一個圖形，並從每個節點中萃取出與這些特徵相關的知識和關係。此外，彈性權重整合 (EWC) 正則化會納入損失函數中，以減輕在任務學習期間遺忘的問題。所提出的模型在 OxfordPets、Flowers102 和 Food101 資料集上達成的測試準確度分別提升了 4.45%、2.92% 和 0.23%。程式碼可在 https://github.com/yunche0/GA-Net/tree/master 取得。

##### **Gradient Harmonization in Unsupervised Domain Adaptation**
2408.00288v1 by Fuxiang Huang, Suqi Song, Lei Zhang

Unsupervised domain adaptation (UDA) intends to transfer knowledge from a
labeled source domain to an unlabeled target domain. Many current methods focus
on learning feature representations that are both discriminative for
classification and invariant across domains by simultaneously optimizing domain
alignment and classification tasks. However, these methods often overlook a
crucial challenge: the inherent conflict between these two tasks during
gradient-based optimization. In this paper, we delve into this issue and
introduce two effective solutions known as Gradient Harmonization, including GH
and GH++, to mitigate the conflict between domain alignment and classification
tasks. GH operates by altering the gradient angle between different tasks from
an obtuse angle to an acute angle, thus resolving the conflict and trade-offing
the two tasks in a coordinated manner. Yet, this would cause both tasks to
deviate from their original optimization directions. We thus further propose an
improved version, GH++, which adjusts the gradient angle between tasks from an
obtuse angle to a vertical angle. This not only eliminates the conflict but
also minimizes deviation from the original gradient directions. Finally, for
optimization convenience and efficiency, we evolve the gradient harmonization
strategies into a dynamically weighted loss function using an integral operator
on the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be
seamlessly integrated into most existing UDA models. Theoretical insights and
experimental analyses demonstrate that the proposed approaches not only enhance
popular UDA baselines but also improve recent state-of-the-art models.

摘要：無監督域適應 (UDA) 旨在將知識從標記的來源域轉移到未標記的目標域。許多現有方法專注於學習特徵表徵，這些表徵既可區分分類，又可透過同時最佳化域對齊和分類任務而在域間保持不變。然而，這些方法經常忽略一個關鍵的挑戰：在基於梯度的最佳化過程中，這兩個任務之間的固有衝突。在本文中，我們深入探討這個問題，並提出兩種稱為梯度調和的有效解決方案，包括 GH 和 GH++，以減輕域對齊和分類任務之間的衝突。GH 的運作方式是將不同任務之間的梯度角從鈍角改為銳角，從而解決衝突，並以協調的方式對這兩個任務進行權衡。然而，這將導致兩個任務都偏離其原始最佳化方向。因此，我們進一步提出一個改進版本 GH++，它將任務之間的梯度角從鈍角調整為垂直角。這不僅消除了衝突，還將原始梯度方向的偏差最小化。最後，為了最佳化的便利性和效率，我們將梯度調和策略演變為一個動態加權損失函數，使用調和梯度上的積分運算子。值得注意的是，GH/GH++ 與 UDA 正交，並且可以無縫整合到大多數現有的 UDA 模型中。理論見解和實驗分析表明，所提出的方法不僅增強了流行的 UDA 基準，而且改進了最近的最新模型。

##### **Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like Spontaneous Representation**
2408.00284v1 by Xinhan Di, Zihao Chen, Yunming Liang, Junjie Zheng, Yihua Wang, Chaofan Ding

Large-scale text-to-speech (TTS) models have made significant progress
recently.However, they still fall short in the generation of Chinese dialectal
speech. Toaddress this, we propose Bailing-TTS, a family of large-scale TTS
models capable of generating high-quality Chinese dialectal speech. Bailing-TTS
serves as a foundation model for Chinese dialectal speech generation. First,
continual semi-supervised learning is proposed to facilitate the alignment of
text tokens and speech tokens. Second, the Chinese dialectal representation
learning is developed using a specific transformer architecture and multi-stage
training processes. With the proposed design of novel network architecture and
corresponding strategy, Bailing-TTS is able to generate Chinese dialectal
speech from text effectively and efficiently. Experiments demonstrate that
Bailing-TTS generates Chinese dialectal speech towards human-like spontaneous
representation. Readers are encouraged to listen to demos at
\url{https://c9412600.github.io/bltts_tech_report/index.html}.

摘要：大型文字轉語音 (TTS) 模型最近取得顯著進展。然而，它們在生成中文方言語音方面仍有不足。為了解決此問題，我們提出了 Bailing-TTS，這是一個大型 TTS 模型系列，能夠生成高品質的中文方言語音。Bailing-TTS 可作為中文方言語音生成的基礎模型。首先，提出持續的半監督式學習，以利於文字符號和語音符號的對齊。其次，使用特定轉換器架構和多階段訓練流程開發中文方言表徵學習。透過新穎網路架構和對應策略的設計，Bailing-TTS 能夠有效率地從文字生成中文方言語音。實驗證明 Bailing-TTS 能夠產生接近人類自然表現的中文方言語音。建議讀者前往 \url{https://c9412600.github.io/bltts_tech_report/index.html} 試聽示範。

##### **Navigating Text-to-Image Generative Bias across Indic Languages**
2408.00283v1 by Surbhi Mittal, Arnav Sudan, Mayank Vatsa, Richa Singh, Tamar Glaser, Tal Hassner

This research investigates biases in text-to-image (TTI) models for the Indic
languages widely spoken across India. It evaluates and compares the generative
performance and cultural relevance of leading TTI models in these languages
against their performance in English. Using the proposed IndicTTI benchmark, we
comprehensively assess the performance of 30 Indic languages with two
open-source diffusion models and two commercial generation APIs. The primary
objective of this benchmark is to evaluate the support for Indic languages in
these models and identify areas needing improvement. Given the linguistic
diversity of 30 languages spoken by over 1.4 billion people, this benchmark
aims to provide a detailed and insightful analysis of TTI models' effectiveness
within the Indic linguistic landscape. The data and code for the IndicTTI
benchmark can be accessed at
https://iab-rubric.org/resources/other-databases/indictti.

摘要：這項研究調查了印度廣泛使用的指示語言中文字轉圖像 (TTI) 模型的偏見。它評估並比較了這些語言中領先的 TTI 模型的生成效能和文化相關性，並與它們在英語中的效能進行比較。使用建議的 IndicTTI 基準，我們全面評估了 30 種指示語言的效能，並使用兩個開源擴散模型和兩個商業生成 API。此基準的主要目標是評估這些模型對指示語言的支援，並找出需要改進的地方。由於 30 種語言的語言多樣性，由超過 14 億人使用，此基準旨在提供對指示語言環境中 TTI 模型有效性的詳細且有見地的分析。IndicTTI 基準的資料和程式碼可於 https://iab-rubric.org/resources/other-databases/indictti 取得。

##### **QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression**
2408.00274v1 by Wenshan Wang, Yihang Wang, Yixing Fan, Huaming Liao, Jiafeng Guo

In-context learning (ICL) capabilities are foundational to the success of
large language models (LLMs). Recently, context compression has attracted
growing interest since it can largely reduce reasoning complexities and
computation costs of LLMs. In this paper, we introduce a novel Query-gUIded
aTtention cOmpression (QUITO) method, which leverages attention of the question
over the contexts to filter useless information. Specifically, we take a
trigger token to calculate the attention distribution of the context in
response to the question. Based on the distribution, we propose three different
filtering methods to satisfy the budget constraints of the context length. We
evaluate the QUITO using two widely-used datasets, namely, NaturalQuestions and
ASQA. Experimental results demonstrate that QUITO significantly outperforms
established baselines across various datasets and downstream LLMs, underscoring
its effectiveness. Our code is available at
https://github.com/Wenshansilvia/attention_compressor.

摘要：脈絡學習 (ICL) 能力是大型語言模型 (LLM) 成功發展的基礎。最近，脈絡壓縮引起了越來越多的關注，因為它可以大幅降低 LLM 的推理複雜度和計算成本。在本文中，我們介紹了一種新穎的 Query 引導式注意力壓縮 (QUITO) 方法，它利用問題對脈絡的關注來過濾無用的資訊。具體來說，我們採用觸發詞彙來計算脈絡在回應問題時的注意力分佈。根據分佈，我們提出三種不同的過濾方法來滿足脈絡長度的預算限制。我們使用兩個廣泛使用的資料集，即 NaturalQuestions 和 ASQA，來評估 QUITO。實驗結果表明，QUITO 在各種資料集和下游 LLM 中都明顯優於已建立的基準，突顯了其有效性。我們的程式碼可在 https://github.com/Wenshansilvia/attention_compressor 取得。

##### **Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding**
2408.00264v1 by Bin Xiao, Lujun Gui, Lei Su, Weipeng Chen

Large Language Models (LLMs) frequently suffer from inefficiencies, largely
attributable to the discord between the requirements of auto-regressive
decoding and the architecture of contemporary GPUs. Recently, regressive
lightweight speculative decoding has garnered attention for its notable
efficiency improvements in text generation tasks. This approach utilizes a
lightweight regressive draft model, like a Recurrent Neural Network (RNN) or a
single transformer decoder layer, leveraging sequential information to
iteratively predict potential tokens. Specifically, RNN draft models are
computationally economical but tend to deliver lower accuracy, while attention
decoder layer models exhibit the opposite traits. This paper presents Clover-2,
an advanced iteration of Clover, an RNN-based draft model designed to achieve
comparable accuracy to that of attention decoder layer models while maintaining
minimal computational overhead. Clover-2 enhances the model architecture and
incorporates knowledge distillation to increase Clover's accuracy and improve
overall efficiency. We conducted experiments using the open-source Vicuna 7B
and LLaMA3-Instruct 8B models. The results demonstrate that Clover-2 surpasses
existing methods across various model architectures, showcasing its efficacy
and robustness.

摘要：大型語言模型 (LLM) 經常會出現低效率的問題，這在很大程度上是歸因於自迴歸解碼的要求與當代 GPU 架構之間的不協調。最近，回歸輕量級推測性解碼因其在文本生成任務中顯著的效率提升而備受關注。此方法利用輕量級回歸草稿模型（例如遞迴神經網路 (RNN) 或單一Transformer解碼器層），利用序列資訊來反覆預測潛在的符號。具體來說，RNN 草稿模型在計算上很經濟，但往往會提供較低的準確度，而注意力解碼器層模型則表現出相反的特徵。本文介紹了 Clover-2，這是基於 RNN 的草稿模型 Clover 的進階迭代，旨在實現與注意力解碼器層模型相當的準確度，同時維持最小的計算開銷。Clover-2 增強了模型架構，並結合了知識蒸餾，以提高 Clover 的準確度並改善整體效率。我們使用開源的 Vicuna 7B 和 LLaMA3-Instruct 8B 模型進行了實驗。結果表明，Clover-2 在各種模型架構中都超越了現有方法，展示了其效能和穩健性。

##### **RoCo:Robust Collaborative Perception By Iterative Object Matching and Pose Adjustment**
2408.00257v1 by Zhe Huang, Shuo Wang, Yongcai Wang, Wanting Li, Deying Li, Lei Wang

Collaborative autonomous driving with multiple vehicles usually requires the
data fusion from multiple modalities. To ensure effective fusion, the data from
each individual modality shall maintain a reasonably high quality. However, in
collaborative perception, the quality of object detection based on a modality
is highly sensitive to the relative pose errors among the agents. It leads to
feature misalignment and significantly reduces collaborative performance. To
address this issue, we propose RoCo, a novel unsupervised framework to conduct
iterative object matching and agent pose adjustment. To the best of our
knowledge, our work is the first to model the pose correction problem in
collaborative perception as an object matching task, which reliably associates
common objects detected by different agents. On top of this, we propose a graph
optimization process to adjust the agent poses by minimizing the alignment
errors of the associated objects, and the object matching is re-done based on
the adjusted agent poses. This process is carried out iteratively until
convergence. Experimental study on both simulated and real-world datasets
demonstrates that the proposed framework RoCo consistently outperforms existing
relevant methods in terms of the collaborative object detection performance,
and exhibits highly desired robustness when the pose information of agents is
with high-level noise. Ablation studies are also provided to show the impact of
its key parameters and components. The code is released at
https://github.com/HuangZhe885/RoCo.

摘要：多車輛協作自動駕駛通常需要來自多種模態的資料融合。為了確保融合有效，來自每個單獨模態的資料應維持相當高的品質。然而，在協作感知中，基於模態的物件偵測品質對代理之間的相對位姿誤差高度敏感。這會導致特徵未對齊，並顯著降低協作效能。為了解決這個問題，我們提出 RoCo，一種新的無監督架構，用於執行反覆物件配對和代理位姿調整。據我們所知，我們的研究率先將協作感知中的位姿校正問題建模為物件配對任務，它會可靠地關聯由不同代理偵測到的共同物件。此外，我們提出一個圖形最佳化流程，藉由最小化關聯物件的對齊誤差來調整代理位姿，並根據調整後的代理位姿重新執行物件配對。這個流程會反覆執行，直到收斂。在模擬和真實世界資料集上的實驗研究顯示，所提出的 RoCo 架構在協作物件偵測效能方面始終優於現有的相關方法，並且在代理的位姿資訊具有高層級雜訊時展現高度的穩健性。也提供了消融研究，以顯示其關鍵參數和組成的影響。程式碼已於 https://github.com/HuangZhe885/RoCo 發布。

##### **Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms**
2408.00244v1 by Tian Meng, Yang Tao, Wuliang Yin

Structured State Space Models (SSMs) have emerged as compelling alternatives
to Transformer architectures, offering linear-time complexity and superior
performance in various sequence modeling tasks. Despite their advantages, SSMs
like the original Mamba-2 face training difficulties due to the sensitivities
introduced by the extended series of recurrent matrix multiplications. In this
paper, we propose an advanced architecture that mitigates these challenges by
decomposing A-multiplications into multiple groups and optimizing positional
encoding through Grouped Finite Impulse Response (FIR) filtering. This new
structure, denoted as Grouped FIR-enhanced SSM (GFSSM), employs semiseparable
matrices for efficient computation. Furthermore, inspired by the "attention
sink" phenomenon identified in streaming language models, we incorporate a
similar mechanism to enhance the stability and performance of our model over
extended sequences. Our approach further bridges the gap between SSMs and
Transformer architectures, offering a viable path forward for scalable and
high-performing sequence modeling.

摘要：結構化狀態空間模型 (SSM) 已成為 Transformer 架構的引人注目的替代方案，在各種序列建模任務中提供線性時間複雜度和卓越的效能。儘管有這些優點，但像原始 Mamba-2 這樣的 SSM 會因遞迴矩陣乘法的延伸序列所帶來的敏感性而面臨訓練難題。在本文中，我們提出了一種先進的架構，透過將 A 乘法分解成多個群組並透過群組有限脈衝響應 (FIR) 濾波最佳化位置編碼來減輕這些挑戰。這個新的結構稱為群組 FIR 增強 SSM (GFSSM)，採用半可分離矩陣進行有效率的運算。此外，受到串流語言模型中識別出的「注意力接收器」現象的啟發，我們納入了一個類似的機制來增強我們模型在延伸序列中的穩定性和效能。我們的做法進一步縮小了 SSM 與 Transformer 架構之間的差距，為可擴充且高執行效能的序列建模提供了可行的前進道路。

##### **Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models**
2408.00230v1 by Juntu Zhao, Junyu Deng, Yixin Ye, Chongxuan Li, Zhijie Deng, Dequan Wang

Advancements in text-to-image diffusion models have broadened extensive
downstream practical applications, but such models often encounter misalignment
issues between text and image. Taking the generation of a combination of two
disentangled concepts as an example, say given the prompt "a tea cup of iced
coke", existing models usually generate a glass cup of iced coke because the
iced coke usually co-occurs with the glass cup instead of the tea one during
model training. The root of such misalignment is attributed to the confusion in
the latent semantic space of text-to-image diffusion models, and hence we refer
to the "a tea cup of iced coke" phenomenon as Latent Concept Misalignment
(LC-Mis). We leverage large language models (LLMs) to thoroughly investigate
the scope of LC-Mis, and develop an automated pipeline for aligning the latent
semantics of diffusion models to text prompts. Empirical assessments confirm
the effectiveness of our approach, substantially reducing LC-Mis errors and
enhancing the robustness and versatility of text-to-image diffusion models. Our
code and dataset have been available online for reference.

摘要：文本到图像扩散模型的进步拓宽了广泛的下游实际应用，但此类模型通常会遇到文本和图像之间的错位问题。以生成两个分离概念的组合为例，例如给定提示“一杯冰可乐”，现有的模型通常会生成一杯玻璃杯装的冰可乐，因为在模型训练期间，冰可乐通常与玻璃杯同时出现，而不是茶杯。这种错位问题的根源归因于文本到图像扩散模型的潜在语义空间中的混乱，因此我们将“一杯冰可乐”现象称为潜在概念错位 (LC-Mis)。我们利用大型语言模型 (LLM) 彻底调查 LC-Mis 的范围，并开发了一个自动管道来将扩散模型的潜在语义与文本提示对齐。经验评估证实了我们方法的有效性，大幅减少了 LC-Mis 错误，并增强了文本到图像扩散模型的鲁棒性和通用性。我们的代码和数据集已在线提供以供参考。

##### **Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation**
2408.00205v1 by Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Masato Mimura, Takatomo Kano, Atsunori Ogawa, Marc Delcroix

This paper introduces a novel approach called sentence-wise speech
summarization (Sen-SSum), which generates text summaries from a spoken document
in a sentence-by-sentence manner. Sen-SSum combines the real-time processing of
automatic speech recognition (ASR) with the conciseness of speech
summarization. To explore this approach, we present two datasets for Sen-SSum:
Mega-SSum and CSJ-SSum. Using these datasets, our study evaluates two types of
Transformer-based models: 1) cascade models that combine ASR and strong text
summarization models, and 2) end-to-end (E2E) models that directly convert
speech into a text summary. While E2E models are appealing to develop
compute-efficient models, they perform worse than cascade models. Therefore, we
propose knowledge distillation for E2E models using pseudo-summaries generated
by the cascade models. Our experiments show that this proposed knowledge
distillation effectively improves the performance of the E2E model on both
datasets.

摘要：本文介紹一種稱為句子式語音摘要 (Sen-SSum) 的新方法，它以逐句的方式從口語文件中產生文字摘要。Sen-SSum 結合了自動語音辨識 (ASR) 的即時處理，以及語音摘要的簡潔性。為了探索此方法，我們為 Sen-SSum 呈現兩個資料集：Mega-SSum 和 CSJ-SSum。我們的研究使用這些資料集，評估了兩種基於 Transformer 的模型：1) 將 ASR 和強大的文字摘要模型結合起來的串聯模型，以及 2) 直接將語音轉換成文字摘要的端到端 (E2E) 模型。雖然 E2E 模型對於開發運算效率高的模型很有吸引力，但它們的表現不如串聯模型。因此，我們針對 E2E 模型提出知識蒸餾，使用由串聯模型產生的擬摘要。我們的實驗顯示，所提出的知識蒸餾有效地改善了 E2E 模型在兩個資料集上的表現。

##### **OmniParser for Pure Vision Based GUI Agent**
2408.00203v1 by Yadong Lu, Jianwei Yang, Yelong Shen, Ahmed Awadallah

The recent success of large vision language models shows great potential in
driving the agent system operating on user interfaces. However, we argue that
the power multimodal models like GPT-4V as a general agent on multiple
operating systems across different applications is largely underestimated due
to the lack of a robust screen parsing technique capable of: 1) reliably
identifying interactable icons within the user interface, and 2) understanding
the semantics of various elements in a screenshot and accurately associate the
intended action with the corresponding region on the screen. To fill these
gaps, we introduce \textsc{OmniParser}, a comprehensive method for parsing user
interface screenshots into structured elements, which significantly enhances
the ability of GPT-4V to generate actions that can be accurately grounded in
the corresponding regions of the interface. We first curated an interactable
icon detection dataset using popular webpages and an icon description dataset.
These datasets were utilized to fine-tune specialized models: a detection model
to parse interactable regions on the screen and a caption model to extract the
functional semantics of the detected elements. \textsc{OmniParser}
significantly improves GPT-4V's performance on ScreenSpot benchmark. And on
Mind2Web and AITW benchmark, \textsc{OmniParser} with screenshot only input
outperforms the GPT-4V baselines requiring additional information outside of
screenshot.

摘要：最近大型视觉语言模型的成功显示出在用户界面上操作代理系统时巨大的潜力。然而，我们认为，由于缺乏一种强大的屏幕解析技术，GPT-4V 等多模态模型作为多个操作系统上跨不同应用程序的通用代理的能力在很大程度上被低估了：1）可靠地识别用户界面中的可交互图标，以及 2）理解屏幕截图中各种元素的语义，并将预期动作准确地与屏幕上的相应区域关联起来。为了填补这些空白，我们引入了 \textsc{OmniParser}，这是一种将用户界面屏幕截图解析为结构化元素的综合方法，它大大增强了 GPT-4V 生成动作的能力，这些动作可以准确地基于界面的相应区域。我们首先使用流行的网页和图标描述数据集整理了一个可交互图标检测数据集。这些数据集被用来微调专门的模型：一个用于解析屏幕上可交互区域的检测模型和一个用于提取检测元素的功能语义的标题模型。\textsc{OmniParser} 大大提高了 GPT-4V 在 ScreenSpot 基准上的性能。并且在 Mind2Web 和 AITW 基准上，仅输入屏幕截图的 \textsc{OmniParser} 优于需要屏幕截图外部附加信息的 GPT-4V 基线。

##### **Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models**
2408.00197v1 by Elijah Pelofske, Vincent Urias, Lorie M. Liebrock

Generative Pre-Trained Transformer models have been shown to be surprisingly
effective at a variety of natural language processing tasks -- including
generating computer code. We evaluate the effectiveness of open source GPT
models for the task of automatic identification of the presence of vulnerable
code syntax (specifically targeting C and C++ source code). This task is
evaluated on a selection of 36 source code examples from the NIST SARD dataset,
which are specifically curated to not contain natural English that indicates
the presence, or lack thereof, of a particular vulnerability. The NIST SARD
source code dataset contains identified vulnerable lines of source code that
are examples of one out of the 839 distinct Common Weakness Enumerations (CWE),
allowing for exact quantification of the GPT output classification error rate.
A total of 5 GPT models are evaluated, using 10 different inference
temperatures and 100 repetitions at each setting, resulting in 5,000 GPT
queries per vulnerable source code analyzed. Ultimately, we find that the GPT
models that we evaluated are not suitable for fully automated vulnerability
scanning because the false positive and false negative rates are too high to
likely be useful in practice. However, we do find that the GPT models perform
surprisingly well at automated vulnerability detection for some of the test
cases, in particular surpassing random sampling, and being able to identify the
exact lines of code that are vulnerable albeit at a low success rate. The best
performing GPT model result found was Llama-2-70b-chat-hf with inference
temperature of 0.1 applied to NIST SARD test case 149165 (which is an example
of a buffer overflow vulnerability), which had a binary classification recall
score of 1.0 and a precision of 1.0 for correctly and uniquely identifying the
vulnerable line of code and the correct CWE number.

摘要：生成式预训练 Transformer 模型已被证明在各种自然语言处理任务中出人意料地有效——包括生成计算机代码。我们评估了开源 GPT 模型在自动识别易受攻击的代码语法（具体针对 C 和 C++ 源代码）的任务中的有效性。此任务在 NIST SARD 数据集中的 36 个源代码示例中进行评估，这些示例经过专门整理，不包含表示存在或不存在特定漏洞的自然英语。NIST SARD 源代码数据集包含已识别的易受攻击的源代码行，这些行是 839 个不同的通用弱点枚举 (CWE) 中的一个示例，允许对 GPT 输出分类错误率进行精确量化。总共评估了 5 个 GPT 模型，每个设置使用 10 个不同的推理温度和 100 次重复，导致每分析一个易受攻击的源代码有 5,000 个 GPT 查询。最终，我们发现我们评估的 GPT 模型不适用于全自动漏洞扫描，因为误报率和漏报率太高，在实践中可能没有用。然而，我们确实发现 GPT 模型在某些测试用例的自动漏洞检测中表现出惊人的良好表现，特别是超过了随机抽样，并且能够识别出易受攻击的确切代码行，尽管成功率较低。发现表现最好的 GPT 模型结果是 Llama-2-70b-chat-hf，其推理温度为 0.1，应用于 NIST SARD 测试用例 149165（这是一个缓冲区溢出漏洞的示例），其二元分类召回得分为 1.0，正确且唯一地识别出易受攻击的代码行和正确的 CWE 编号的精确度为 1.0。

##### **S-SYNTH: Knowledge-Based, Synthetic Generation of Skin Images**
2408.00191v1 by Andrea Kim, Niloufar Saharkhiz, Elena Sizikova, Miguel Lago, Berkman Sahiner, Jana Delfino, Aldo Badano

Development of artificial intelligence (AI) techniques in medical imaging
requires access to large-scale and diverse datasets for training and
evaluation. In dermatology, obtaining such datasets remains challenging due to
significant variations in patient populations, illumination conditions, and
acquisition system characteristics. In this work, we propose S-SYNTH, the first
knowledge-based, adaptable open-source skin simulation framework to rapidly
generate synthetic skin, 3D models and digitally rendered images, using an
anatomically inspired multi-layer, multi-component skin and growing lesion
model. The skin model allows for controlled variation in skin appearance, such
as skin color, presence of hair, lesion shape, and blood fraction among other
parameters. We use this framework to study the effect of possible variations on
the development and evaluation of AI models for skin lesion segmentation, and
show that results obtained using synthetic data follow similar comparative
trends as real dermatologic images, while mitigating biases and limitations
from existing datasets including small dataset size, lack of diversity, and
underrepresentation.

摘要：人工智慧 (AI) 技術在醫學影像方面的發展需要取得大規模且多元的資料集，以進行訓練和評估。在皮膚科中，取得此類資料集仍然具有挑戰性，原因在於患者族群、照明條件和取得系統特性有顯著的變化。在這項工作中，我們提出 S-SYNTH，這是第一個基於知識、可適應的開放原始碼皮膚模擬架構，可使用解剖學啟發的多層、多組成皮膚和生長病灶模型，快速產生合成皮膚、3D 模型和數位渲染影像。皮膚模型允許控制皮膚外觀的變化，例如膚色、毛髮存在、病灶形狀和血液比例等參數。我們使用這個架構來研究可能的變化對皮膚病灶分割 AI 模型的開發和評估的影響，並顯示使用合成資料取得的結果遵循與真實皮膚科影像類似的比較趨勢，同時減輕現有資料集的偏差和限制，包括資料集規模小、缺乏多元性以及代表性不足。

##### **Finch: Prompt-guided Key-Value Cache Compression**
2408.00167v1 by Giulio Corallo, Paolo Papotti

Recent large language model applications, such as Retrieval-Augmented
Generation and chatbots, have led to an increased need to process longer input
contexts. However, this requirement is hampered by inherent limitations.
Architecturally, models are constrained by a context window defined during
training. Additionally, processing extensive texts requires substantial GPU
memory. We propose a novel approach, Finch, to compress the input context by
leveraging the pre-trained model weights of the self-attention. Given a prompt
and a long text, Finch iteratively identifies the most relevant Key (K) and
Value (V) pairs over chunks of the text conditioned on the prompt. Only such
pairs are stored in the KV cache, which, within the space constrained by the
context window, ultimately contains a compressed version of the long text. Our
proposal enables models to consume large inputs even with high compression (up
to 93x) while preserving semantic integrity without the need for fine-tuning.

摘要：最近的大型语言模型应用，例如检索增强生成和聊天机器人，导致了处理更长的输入语境的需要增加。然而，此项需求受到固有局限性的阻碍。在架构上，模型受到训练期间定义的上下文窗口的约束。此外，处理大文本需要大量的 GPU 内存。我们提出了一种新颖的方法 Finch，通过利用自注意力的预训练模型权重来压缩输入上下文。给定一个提示和一个长文本，Finch 根据提示对文本块进行迭代识别最相关的键 (K) 和值 (V) 对。只有此类对存储在 KV 缓存中，该缓存受上下文窗口约束的空间内最终包含长文本的压缩版本。我们的提议使模型能够消耗大量输入，即使在高压缩（高达 93 倍）的情况下，也能在无需微调的情况下保持语义完整性。

##### **A Taxonomy of Stereotype Content in Large Language Models**
2408.00162v1 by Gandalf Nicolas, Aylin Caliskan

This study introduces a taxonomy of stereotype content in contemporary large
language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three
powerful and widely used LLMs, for the characteristics associated with 87
social categories (e.g., gender, race, occupations). We identify 14 stereotype
dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for
~90% of LLM stereotype associations. Warmth and Competence facets were the most
frequent content, but all other dimensions were significantly prevalent.
Stereotypes were more positive in LLMs (vs. humans), but there was significant
variability across categories and dimensions. Finally, the taxonomy predicted
the LLMs' internal evaluations of social categories (e.g., how
positively/negatively the categories were represented), supporting the
relevance of a multidimensional taxonomy for characterizing LLM stereotypes.
Our findings suggest that high-dimensional human stereotypes are reflected in
LLMs and must be considered in AI auditing and debiasing to minimize
unidentified harms from reliance in low-dimensional views of bias in LLMs.

摘要：本研究針對當代大型語言模型 (LLM) 中的刻板印象內容進行分類。我們提示 ChatGPT 3.5、Llama 3 和 Mixtral 8x7B 這三種強大且廣泛使用的 LLM，了解與 87 個社會類別（例如性別、種族、職業）相關的特徵。我們識別出 14 個刻板印象面向（例如道德、能力、健康、信仰、情緒），約佔 LLM 刻板印象關聯的 90%。溫暖和能力面向是最頻繁的內容，但所有其他面向都很普遍。LLM 中的刻板印象比人類更正面，但不同類別和面向之間存在顯著差異。最後，分類法預測了 LLM 對社會類別的內部評估（例如類別的正面/負面呈現方式），支持了使用多維分類法來表徵 LLM 刻板印象的相關性。我們的研究結果表明，高維度的人類刻板印象反映在 LLM 中，並且必須在 AI 稽核和消除偏見中加以考慮，以將依賴 LLM 中偏見的低維度觀點造成的未識別危害降到最低。

##### **Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting**
2408.00161v1 by Ying Li, Rahul Singh, Tarun Joshi, Agus Sudjianto

Recent work in behavioral testing for natural language processing (NLP)
models, such as Checklist, is inspired by related paradigms in software
engineering testing. They allow evaluation of general linguistic capabilities
and domain understanding, hence can help evaluate conceptual soundness and
identify model weaknesses. However, a major challenge is the creation of test
cases. The current packages rely on semi-automated approach using manual
development which requires domain expertise and can be time consuming. This
paper introduces an automated approach to develop test cases by exploiting the
power of large language models and statistical techniques. It clusters the text
representations to carefully construct meaningful groups and then apply
prompting techniques to automatically generate Minimal Functionality Tests
(MFT). The well-known Amazon Reviews corpus is used to demonstrate our
approach. We analyze the behavioral test profiles across four different
classification algorithms and discuss the limitations and strengths of those
models.

摘要：自然語言處理 (NLP) 行為測試的最新研究，例如 Checklist，是受軟體工程測試中相關範例所啟發。它們允許評估一般語言能力和領域理解，因此有助於評估概念健全性並找出模型的弱點。然而，一個主要的挑戰是如何建立測試案例。目前的套件依賴於使用手動開發的半自動化方法，這需要領域專業知識，而且可能很耗時。本文介紹了一種自動化方法，透過利用大型語言模型和統計技術來開發測試案例。它會將文本表示分群，以仔細建構有意義的群組，然後套用提示技術來自動產生最小功能測試 (MFT)。我們使用著名的 Amazon Reviews 語料庫來展示我們的做法。我們會分析四種不同分類演算法的行為測試輪廓，並討論這些模型的限制和優點。

##### **StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization**
2408.00150v1 by Kaiyuan Tang, Chaoli Wang

In volume visualization, visualization synthesis has attracted much attention
due to its ability to generate novel visualizations without following the
conventional rendering pipeline. However, existing solutions based on
generative adversarial networks often require many training images and take
significant training time. Still, issues such as low quality, consistency, and
flexibility persist. This paper introduces StyleRF-VolVis, an innovative style
transfer framework for expressive volume visualization (VolVis) via neural
radiance field (NeRF). The expressiveness of StyleRF-VolVis is upheld by its
ability to accurately separate the underlying scene geometry (i.e., content)
and color appearance (i.e., style), conveniently modify color, opacity, and
lighting of the original rendering while maintaining visual content consistency
across the views, and effectively transfer arbitrary styles from reference
images to the reconstructed 3D scene. To achieve these, we design a base NeRF
model for scene geometry extraction, a palette color network to classify
regions of the radiance field for photorealistic editing, and an unrestricted
color network to lift the color palette constraint via knowledge distillation
for non-photorealistic editing. We demonstrate the superior quality,
consistency, and flexibility of StyleRF-VolVis by experimenting with various
volume rendering scenes and reference images and comparing StyleRF-VolVis
against other image-based (AdaIN), video-based (ReReVST), and NeRF-based (ARF
and SNeRF) style rendering solutions.

摘要：在體積可視化中，可視化合成因其能夠生成新穎的可視化而備受關注，而無需遵循傳統的渲染管道。然而，現有的基於生成對抗網路的解決方案通常需要大量的訓練影像，並且需要大量的訓練時間。儘管如此，諸如低品質、一致性和靈活性等問題仍然存在。本文介紹了 StyleRF-VolVis，這是一個創新的樣式轉移框架，用於通過神經輻射場 (NeRF) 進行富有表現力的體積可視化 (VolVis)。StyleRF-VolVis 的表現力通過其準確分離底層場景幾何形狀（即內容）和色彩外觀（即樣式）的能力得到提升，方便地修改原始渲染的色彩、不透明度和光照，同時保持視覺內容在視圖間的一致性，並有效地將任意樣式從參考影像轉移到重建的 3D 場景。為了實現這些目標，我們設計了一個用於場景幾何形狀提取的基本 NeRF 模型、一個用於對輻射場區域進行分類以進行逼真編輯的調色板色彩網路，以及一個用於通過知識蒸餾解除色彩調色板約束的無限制色彩網路，以進行非逼真編輯。我們通過使用各種體積渲染場景和參考影像進行實驗，並將 StyleRF-VolVis 與其他基於影像（AdaIN）、基於影片（ReReVST）和基於 NeRF（ARF 和 SNeRF）的樣式渲染解決方案進行比較，展示了 StyleRF-VolVis 的優越品質、一致性和靈活性。

##### **Formal Ethical Obligations in Reinforcement Learning Agents: Verification and Policy Updates**
2408.00147v1 by Colin Shea-Blymyer, Houssam Abbas

When designing agents for operation in uncertain environments, designers need
tools to automatically reason about what agents ought to do, how that conflicts
with what is actually happening, and how a policy might be modified to remove
the conflict. These obligations include ethical and social obligations,
permissions and prohibitions, which constrain how the agent achieves its
mission and executes its policy. We propose a new deontic logic, Expected Act
Utilitarian deontic logic, for enabling this reasoning at design time: for
specifying and verifying the agent's strategic obligations, then modifying its
policy from a reference policy to meet those obligations. Unlike approaches
that work at the reward level, working at the logical level increases the
transparency of the trade-offs. We introduce two algorithms: one for
model-checking whether an RL agent has the right strategic obligations, and one
for modifying a reference decision policy to make it meet obligations expressed
in our logic. We illustrate our algorithms on DAC-MDPs which accurately
abstract neural decision policies, and on toy gridworld environments.

摘要：在為不確定環境中的運作設計代理時，設計師需要
工具來自動推論代理應做什麼，這與實際發生的事如何衝突，以及如何修改策略以消除
衝突。這些義務包括道德和社會義務、
許可和禁止，它們限制了代理如何實現其
任務並執行其政策。我們提出了一種新的義務邏輯，預期行為
功利主義義務邏輯，用於在設計時啟用這種推理：用於
指定和驗證代理的策略義務，然後修改其
政策從參考政策來履行這些義務。與在獎勵層級運作的方法不同，在邏輯層級運作會增加
權衡的透明度。我們引入了兩種演算法：一種用於
模型檢查 RL 代理是否具有正確的策略義務，另一種用於
修改參考決策政策以使其符合我們的邏輯中表達的義務。我們在準確
抽象神經決策政策的 DAC-MDP 和玩具格狀世界環境中說明我們的演算法。

##### **Distributed In-Context Learning under Non-IID Among Clients**
2408.00144v1 by Siqi Liang, Sumyeong Ahn, Jiayu Zhou

Advancements in large language models (LLMs) have shown their effectiveness
in multiple complicated natural language reasoning tasks. A key challenge
remains in adapting these models efficiently to new or unfamiliar tasks.
In-context learning (ICL) provides a promising solution for few-shot adaptation
by retrieving a set of data points relevant to a query, called in-context
examples (ICE), from a training dataset and providing them during the inference
as context. Most existing studies utilize a centralized training dataset, yet
many real-world datasets may be distributed among multiple clients, and remote
data retrieval can be associated with costs. Especially when the client data
are non-identical independent distributions (non-IID), retrieving from clients
a proper set of ICEs needed for a test query presents critical challenges. In
this paper, we first show that in this challenging setting, test queries will
have different preferences among clients because of non-IIDness, and equal
contribution often leads to suboptimal performance. We then introduce a novel
approach to tackle the distributed non-IID ICL problem when a data usage budget
is present. The principle is that each client's proper contribution (budget)
should be designed according to the preference of each query for that client.
Our approach uses a data-driven manner to allocate a budget for each client,
tailored to each test query. Through extensive empirical studies on diverse
datasets, our framework demonstrates superior performance relative to competing
baselines.

摘要：大型語言模型 (LLM) 的進展已展現其在多重複雜自然語言推理任務中的有效性。一個關鍵挑戰在於有效地將這些模型適應於新的或不熟悉的任務。情境內學習 (ICL) 提供了一個有希望的解決方案，用於少量適應，方法是從訓練資料集中擷取一組與查詢相關的資料點，稱為情境內範例 (ICE)，並在推理過程中將它們提供為情境。大多數現有研究利用一個集中式訓練資料集，然而許多真實世界的資料集可能分佈在多個用戶端中，而且遠端資料擷取可能會產生成本。特別是當用戶端資料是非相同獨立分佈 (non-IID) 時，從用戶端擷取一個適當的 ICE 集合以供測試查詢會帶來重大的挑戰。在本文中，我們首先展示，在這個具挑戰性的設定中，測試查詢將會因為非相同獨立分佈而有不同的用戶端偏好，而相等的貢獻通常會導致次佳效能。接著，我們介紹一種新穎的方法來解決有資料使用預算時的分散式非相同獨立分佈 ICL 問題。原則是每個用戶端的適當貢獻 (預算) 應根據每個查詢對該用戶端的偏好來設計。我們的做法使用資料驅動的方式為每個用戶端分配預算，並針對每個測試查詢量身打造。透過在不同資料集上進行廣泛的實證研究，我們的架構展現出優於競爭基準的卓越效能。

##### **Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment**
2408.00137v1 by Sangwon Yu, Jongyoon Song, Bongkyu Hwang, Hoyoung Kang, Sooah Cho, Junhwa Choi, Seongho Joe, Taehee Lee, Youngjune L. Gwon, Sungroh Yoon

A binary decision task, like yes-no questions or answer verification,
reflects a significant real-world scenario such as where users look for
confirmation about the correctness of their decisions on specific issues. In
this work, we observe that language models exhibit a negative bias in the
binary decisions of complex reasoning tasks. Based on our observations and the
rationale about attention-based model dynamics, we propose a negative attention
score (NAS) to systematically and quantitatively formulate negative bias. Based
on NAS, we identify attention heads that attend to negative tokens provided in
the instructions as answer candidate of binary decisions, regardless of the
question in the prompt, and validate their association with the negative bias.
Additionally, we propose the negative attention score alignment (NASA) method,
which is a parameter-efficient fine-tuning technique to address the extracted
negatively biased attention heads. Experimental results from various domains of
reasoning tasks and large model search space demonstrate that NASA
significantly reduces the gap between precision and recall caused by negative
bias while preserving their generalization abilities. Our codes are available
at \url{https://github.com/ysw1021/NASA}.

摘要：二元決策任務，例如是非題或答案驗證，反映了一個重要的真實世界場景，例如使用者在特定問題上尋求對其決策正確性的確認。在本文中，我們觀察到語言模型在複雜推理任務的二元決策中表現出負面偏見。根據我們的觀察和基於注意力的模型動態的基本原理，我們提出了一個負面注意力分數 (NAS) 來系統且量化地制定負面偏見。基於 NAS，我們識別出在提示中的問題中，無論如何，都注意二元決策中提供的負面標記（作為答案候選）的注意力頭，並驗證它們與負面偏見的關聯性。此外，我們提出了負面注意力分數對齊 (NASA) 方法，這是一種參數高效的微調技術，用於解決提取的負面偏見注意力頭。來自各種推理任務領域和大型模型搜尋空間的實驗結果表明，NASA 在保留其泛化能力的同時，顯著縮小了由負面偏見造成的精確度和召回率之間的差距。我們的程式碼可在 \url{https://github.com/ysw1021/NASA} 取得。

##### **Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions**
2408.00131v1 by Patrick Kuiper, Ali Hasan, Wenhao Yang, Yuting Ng, Hoda Bidkhori, Jose Blanchet, Vahid Tarokh

The goal of this paper is to develop distributionally robust optimization
(DRO) estimators, specifically for multidimensional Extreme Value Theory (EVT)
statistics. EVT supports using semi-parametric models called max-stable
distributions built from spatial Poisson point processes. While powerful, these
models are only asymptotically valid for large samples. However, since extreme
data is by definition scarce, the potential for model misspecification error is
inherent to these applications, thus DRO estimators are natural. In order to
mitigate over-conservative estimates while enhancing out-of-sample performance,
we study DRO estimators informed by semi-parametric max-stable constraints in
the space of point processes. We study both tractable convex formulations for
some problems of interest (e.g. CVaR) and more general neural network based
estimators. Both approaches are validated using synthetically generated data,
recovering prescribed characteristics, and verifying the efficacy of the
proposed techniques. Additionally, the proposed method is applied to a real
data set of financial returns for comparison to a previous analysis. We
established the proposed model as a novel formulation in the multivariate EVT
domain, and innovative with respect to performance when compared to relevant
alternate proposals.

摘要：本文的目標是開發分布穩健最佳化 (DRO) 估計量，特別是針對多維極值理論 (EVT) 統計量。EVT 支援使用由空間泊松點過程建立的半參數模型，稱為極大穩定分佈。儘管功能強大，但這些模型僅對大型樣本具有漸近有效性。然而，由於極端資料的定義是稀少的，因此模型錯誤規範的潛力是這些應用程式固有的，因此 DRO 估計量是自然的。為了減輕過於保守的估計，同時增強樣本外效能，我們研究了由點過程空間中的半參數極大穩定約束所告知的 DRO 估計量。我們研究了針對一些感興趣問題（例如 CVaR）的可處理凸公式，以及更通用的基於神經網路的估計量。兩種方法都使用合成產生的資料驗證，恢復規定的特徵，並驗證所提出技術的效能。此外，所提出的方法應用於一組真實的財務報酬資料集，以與先前的分析進行比較。我們將所提出的模型建立為多元 EVT 領域中的創新公式，並且在與相關替代方案相比時，在效能方面具有創新性。

##### **Semantic Codebook Learning for Dynamic Recommendation Models**
2408.00123v1 by Zheqi Lv, Shaoxuan He, Tianyu Zhan, Shengyu Zhang, Wenqiao Zhang, Jingyuan Chen, Zhou Zhao, Fei Wu

Dynamic sequential recommendation (DSR) can generate model parameters based
on user behavior to improve the personalization of sequential recommendation
under various user preferences. However, it faces the challenges of large
parameter search space and sparse and noisy user-item interactions, which
reduces the applicability of the generated model parameters. The Semantic
Codebook Learning for Dynamic Recommendation Models (SOLID) framework presents
a significant advancement in DSR by effectively tackling these challenges. By
transforming item sequences into semantic sequences and employing a dual
parameter model, SOLID compresses the parameter generation search space and
leverages homogeneity within the recommendation system. The introduction of the
semantic metacode and semantic codebook, which stores disentangled item
representations, ensures robust and accurate parameter generation. Extensive
experiments demonstrates that SOLID consistently outperforms existing DSR,
delivering more accurate, stable, and robust recommendations.

摘要：動態順序推薦 (DSR) 能根據使用者行為產生模型參數，以改善在各種使用者偏好下的順序推薦個人化。然而，它面臨大型參數搜尋空間以及稀疏且有雜訊的使用者-項目互動的挑戰，這降低了所產生模型參數的適用性。語意碼本學習用於動態推薦模型 (SOLID) 架構提出了一個重大進展，能有效地應對這些挑戰。透過將項目序列轉換為語意序列並採用雙重參數模型，SOLID 壓縮參數產生搜尋空間，並利用推薦系統內的同質性。語意元碼和語意碼本的引入，儲存了解開的項目表示，確保了穩健且準確的參數產生。廣泛的實驗證明，SOLID 持續優於現有的 DSR，提供更準確、穩定且穩健的推薦。

##### **A Course Shared Task on Evaluating LLM Output for Clinical Questions**
2408.00122v1 by Yufang Hou, Thy Thy Tran, Doan Nam Long Vu, Yiwen Cao, Kai Li, Lukas Rohde, Iryna Gurevych

This paper presents a shared task that we organized at the Foundations of
Language Technology (FoLT) course in 2023/2024 at the Technical University of
Darmstadt, which focuses on evaluating the output of Large Language Models
(LLMs) in generating harmful answers to health-related clinical questions. We
describe the task design considerations and report the feedback we received
from the students. We expect the task and the findings reported in this paper
to be relevant for instructors teaching natural language processing (NLP) and
designing course assignments.

摘要：這篇論文介紹了一個我們在2023/2024年於達姆施塔特工業大學語言技術基礎（FoLT）課程中組織的共享任務，重點在於評估大型語言模型（LLM）在產生對健康相關臨床問題的有害答案時的輸出。我們描述了任務設計考量，並報告了我們從學生那裡收到的回饋。我們預期這項任務和本文中報告的發現與教授自然語言處理（NLP）並設計課程作業的講師相關。

##### **Gemma 2: Improving Open Language Models at a Practical Size**
2408.00118v1 by Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozińska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Plucińska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder Singh, Mark Iverson, Martin Görner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew Watson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit Khatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil Botarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat, Sara Mc Carthy, Sarah Perrin, Sébastien Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk Kwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, Alek Andreev

In this work, we introduce Gemma 2, a new addition to the Gemma family of
lightweight, state-of-the-art open models, ranging in scale from 2 billion to
27 billion parameters. In this new version, we apply several known technical
modifications to the Transformer architecture, such as interleaving
local-global attentions (Beltagy et al., 2020a) and group-query attention
(Ainslie et al., 2023). We also train the 2B and 9B models with knowledge
distillation (Hinton et al., 2015) instead of next token prediction. The
resulting models deliver the best performance for their size, and even offer
competitive alternatives to models that are 2-3 times bigger. We release all
our models to the community.

摘要：在本文中，我們介紹了 Gemma 2，它是 Gemma 系列輕量級、最先進的開放模型的新成員，規模從 20 億到 270 億個參數不等。在此新版本中，我們對 Transformer 架構應用了一些已知的技術修改，例如交錯局部全局注意力（Beltagy 等人，2020a）和組查詢注意力（Ainslie 等人，2023）。我們還使用知識蒸餾（Hinton 等人，2015）而不是下一個令牌預測來訓練 2B 和 9B 模型。由此產生的模型提供了與其規模相符的最佳性能，甚至提供了比大 2-3 倍的模型更有競爭力的替代方案。我們將所有模型發布給社區。

##### **Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs**
2408.00114v1 by Kewei Cheng, Jingfeng Yang, Haoming Jiang, Zhengyang Wang, Binxuan Huang, Ruirui Li, Shiyang Li, Zheng Li, Yifan Gao, Xian Li, Bing Yin, Yizhou Sun

Reasoning encompasses two typical types: deductive reasoning and inductive
reasoning. Despite extensive research into the reasoning capabilities of Large
Language Models (LLMs), most studies have failed to rigorously differentiate
between inductive and deductive reasoning, leading to a blending of the two.
This raises an essential question: In LLM reasoning, which poses a greater
challenge - deductive or inductive reasoning? While the deductive reasoning
capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning
tasks), have received considerable attention, their abilities in true inductive
reasoning remain largely unexplored. To delve into the true inductive reasoning
capabilities of LLMs, we propose a novel framework, SolverLearner. This
framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$),
that maps input data points $(x)$ to their corresponding output values $(y)$,
using only in-context examples. By focusing on inductive reasoning and
separating it from LLM-based deductive reasoning, we can isolate and
investigate inductive reasoning of LLMs in its pure form via SolverLearner. Our
observations reveal that LLMs demonstrate remarkable inductive reasoning
capabilities through SolverLearner, achieving near-perfect performance with ACC
of 1 in most cases. Surprisingly, despite their strong inductive reasoning
abilities, LLMs tend to relatively lack deductive reasoning capabilities,
particularly in tasks involving ``counterfactual'' reasoning.

摘要：推理包含兩種典型類型：演繹推理和歸納推理。儘管對大型語言模型 (LLM) 的推理能力進行了廣泛的研究，但大多數研究未能嚴格區分演繹推理和歸納推理，導致兩者混為一談。這引發了一個基本問題：在 LLM 推理中，演繹推理還是歸納推理構成更大的挑戰？儘管 LLM 的演繹推理能力（即它們在推理任務中遵循指令的能力）受到了相當多的關注，但它們在真正的歸納推理中的能力在很大程度上仍未得到探索。為了深入探討 LLM 的真正歸納推理能力，我們提出了一個新框架 SolverLearner。此框架使 LLM 能夠學習底層函數（即 $y = f_w(x)$），它將輸入數據點 $(x)$ 映射到它們對應的輸出值 $(y)$，僅使用上下文中的範例。通過專注於歸納推理並將其與基於 LLM 的演繹推理分開，我們可以通過 SolverLearner 孤立和研究 LLM 的歸納推理的純粹形式。我們的觀察表明，LLM 通過 SolverLearner 展示了非凡的歸納推理能力，在大多數情況下以 1 的 ACC 達到了接近完美的性能。令人驚訝的是，儘管 LLM 具有強大的歸納推理能力，但它們往往相對缺乏演繹推理能力，特別是在涉及「反事實」推理的任務中。

##### **Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models**
2408.00113v1 by Adam Karvonen, Benjamin Wright, Can Rager, Rico Angell, Jannik Brinkmann, Logan Smith, Claudio Mayrink Verdun, David Bau, Samuel Marks

What latent features are encoded in language model (LM) representations?
Recent work on training sparse autoencoders (SAEs) to disentangle interpretable
features in LM representations has shown significant promise. However,
evaluating the quality of these SAEs is difficult because we lack a
ground-truth collection of interpretable features that we expect good SAEs to
recover. We thus propose to measure progress in interpretable dictionary
learning by working in the setting of LMs trained on chess and Othello
transcripts. These settings carry natural collections of interpretable features
-- for example, "there is a knight on F3" -- which we leverage into
$\textit{supervised}$ metrics for SAE quality. To guide progress in
interpretable dictionary learning, we introduce a new SAE training technique,
$\textit{p-annealing}$, which improves performance on prior unsupervised
metrics as well as our new metrics.

摘要：語言模型（LM）表徵中編碼了哪些潛在特徵？
最近關於訓練稀疏自動編碼器（SAE）以解開 LM 表徵中可解釋特徵的研究顯示出顯著的成果。然而，評估這些 SAE 的品質很困難，因為我們缺乏預期良好 SAE 能夠恢復的可解釋特徵的真實資料集。因此，我們提議透過在針對西洋棋和奧賽羅棋譜訓練的 LM 設定中工作來衡量可解釋字典學習的進度。這些設定包含自然的可解釋特徵集合，例如「F3 上有一個騎士」，我們將其運用到 SAE 品質的「監督式」指標中。為了引導可解釋字典學習的進度，我們引入了一種新的 SAE 訓練技術「p 退火」，它改善了先前非監督式指標以及我們的新指標的效能。

##### **Preference-Based Abstract Argumentation for Case-Based Reasoning (with-Appendix)**
2408.00108v1 by Adam Gould, Guilherme Paulino-Passos, Seema Dadhania, Matthew Williams, Francesca Toni

In the pursuit of enhancing the efficacy and flexibility of interpretable,
data-driven classification models, this work introduces a novel incorporation
of user-defined preferences with Abstract Argumentation and Case-Based
Reasoning (CBR). Specifically, we introduce Preference-Based Abstract
Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users
to define multiple approaches to compare cases with an ordering that specifies
their preference over these comparison approaches. We prove that the model
inherently follows these preferences when making predictions and show that
previous abstract argumentation for case-based reasoning approaches are
insufficient at expressing preferences over constituents of an argument. We
then demonstrate how this can be applied to a real-world medical dataset
sourced from a clinical trial evaluating differing assessment methods of
patients with a primary brain tumour. We show empirically that our approach
outperforms other interpretable machine learning models on this dataset.

摘要：為了提升可解釋、資料驅動分類模型的效能與靈活性，本研究提出了一種將使用者定義的偏好結合抽象論證與案例基礎推理 (CBR) 的新穎整合方式。具體來說，我們引入了偏好基礎抽象論證，用於案例基礎推理 (我們稱之為 AA-CBR-P)，允許使用者定義多種方法來比較案例，並透過設定順序來指定他們對這些比較方法的偏好。我們證明了此模型在進行預測時會固有地遵循這些偏好，並說明先前用於案例基礎推理的抽象論證不足以表達對論證組成部分的偏好。接著，我們展示如何將此方法應用於一個真實世界的醫療資料集，該資料集來自一項臨床試驗，評估了對原發性腦瘤患者的不同評估方法。我們透過實證證明，我們的做法在這個資料集上優於其他可解釋機器學習模型。

##### **WAS: Dataset and Methods for Artistic Text Segmentation**
2408.00106v1 by Xudong Xie, Yuzhe Li, Yang Liu, Zhifei Zhang, Zhaowen Wang, Wei Xiong, Xiang Bai

Accurate text segmentation results are crucial for text-related generative
tasks, such as text image generation, text editing, text removal, and text
style transfer. Recently, some scene text segmentation methods have made
significant progress in segmenting regular text. However, these methods perform
poorly in scenarios containing artistic text. Therefore, this paper focuses on
the more challenging task of artistic text segmentation and constructs a real
artistic text segmentation dataset. One challenge of the task is that the local
stroke shapes of artistic text are changeable with diversity and complexity. We
propose a decoder with the layer-wise momentum query to prevent the model from
ignoring stroke regions of special shapes. Another challenge is the complexity
of the global topological structure. We further design a skeleton-assisted head
to guide the model to focus on the global structure. Additionally, to enhance
the generalization performance of the text segmentation model, we propose a
strategy for training data synthesis, based on the large multi-modal model and
the diffusion model. Experimental results show that our proposed method and
synthetic dataset can significantly enhance the performance of artistic text
segmentation and achieve state-of-the-art results on other public datasets.

摘要：準確的文字分割結果對於文字相關的生成任務至關重要，例如文字影像生成、文字編輯、文字移除和文字樣式轉移。最近，一些場景文字分割方法在分割規則文字方面取得了顯著進展。然而，這些方法在包含藝術文字的場景中表現不佳。因此，本文重點關注更具挑戰性的藝術文字分割任務，並構建了一個真實的藝術文字分割資料集。該任務的一個挑戰是藝術文字的局部筆畫形狀會隨著多樣性和複雜性而改變。我們提出了一個具有逐層動量查詢的解碼器，以防止模型忽略特殊形狀的筆畫區域。另一個挑戰是全局拓撲結構的複雜性。我們進一步設計了一個骨架輔助頭部，以引導模型關注全局結構。此外，為了增強文字分割模型的泛化效能，我們提出了一種基於大型多模態模型和擴散模型的訓練資料合成策略。實驗結果表明，我們提出的方法和合成資料集可以顯著增強藝術文字分割的效能，並在其他公開資料集上取得最先進的結果。

##### **ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget**
2408.00103v1 by Riccardo Orlando, Pere-Lluis Huguet-Cabot, Edoardo Barba, Roberto Navigli

Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in
Natural Language Processing, serving as critical components in a wide range of
applications. In this paper, we propose ReLiK, a Retriever-Reader architecture
for both EL and RE, where, given an input text, the Retriever module undertakes
the identification of candidate entities or relations that could potentially
appear within the text. Subsequently, the Reader module is tasked to discern
the pertinent retrieved entities or relations and establish their alignment
with the corresponding textual spans. Notably, we put forward an innovative
input representation that incorporates the candidate entities or relations
alongside the text, making it possible to link entities or extract relations in
a single forward pass and to fully leverage pre-trained language models
contextualization capabilities, in contrast with previous
Retriever-Reader-based methods, which require a forward pass for each
candidate. Our formulation of EL and RE achieves state-of-the-art performance
in both in-domain and out-of-domain benchmarks while using academic budget
training and with up to 40x inference speed compared to competitors. Finally,
we show how our architecture can be used seamlessly for Information Extraction
(cIE), i.e. EL + RE, and setting a new state of the art by employing a shared
Reader that simultaneously extracts entities and relations.

摘要：實體連結 (EL) 和關係抽取 (RE) 是自然語言處理中的基本任務，在廣泛的應用中擔任關鍵組成部分。在本文中，我們提出 ReLiK，一種用於 EL 和 RE 的檢索器-閱讀器架構，其中，在給定輸入文字時，檢索器模組承擔潛在可能出現在文字中的候選實體或關係的識別。隨後，閱讀器模組被指派辨別相關的檢索實體或關係，並建立它們與對應文字區間的對齊。值得注意的是，我們提出了創新的輸入表示，將候選實體或關係與文字結合在一起，使得在單一前向傳遞中連結實體或抽取關係，並充分利用預先訓練的語言模型情境化能力成為可能，這與先前的檢索器-閱讀器方法形成對比，後者需要針對每個候選進行前向傳遞。我們對 EL 和 RE 的公式化在領域內和領域外基準測試中都達到了最先進的效能，同時使用學術預算訓練，並且與競爭者相比，推論速度高達 40 倍。最後，我們展示了我們的架構如何能無縫地用於資訊抽取 (cIE)，即 EL + RE，並透過採用同時抽取實體和關係的共用閱讀器來設定新的最先進技術。

##### **From Attributes to Natural Language: A Survey and Foresight on Text-based Person Re-identification**
2408.00096v1 by Fanzhi Jiang, Su Yang, Mark W. Jones, Liumei Zhang

Text-based person re-identification (Re-ID) is a challenging topic in the
field of complex multimodal analysis, its ultimate aim is to recognize specific
pedestrians by scrutinizing attributes/natural language descriptions. Despite
the wide range of applicable areas such as security surveillance, video
retrieval, person tracking, and social media analytics, there is a notable
absence of comprehensive reviews dedicated to summarizing the text-based person
Re-ID from a technical perspective. To address this gap, we propose to
introduce a taxonomy spanning Evaluation, Strategy, Architecture, and
Optimization dimensions, providing a comprehensive survey of the text-based
person Re-ID task. We start by laying the groundwork for text-based person
Re-ID, elucidating fundamental concepts related to attribute/natural
language-based identification. Then a thorough examination of existing
benchmark datasets and metrics is presented. Subsequently, we further delve
into prevalent feature extraction strategies employed in text-based person
Re-ID research, followed by a concise summary of common network architectures
within the domain. Prevalent loss functions utilized for model optimization and
modality alignment in text-based person Re-ID are also scrutinized. To
conclude, we offer a concise summary of our findings, pinpointing challenges in
text-based person Re-ID. In response to these challenges, we outline potential
avenues for future open-set text-based person Re-ID and present a baseline
architecture for text-based pedestrian image generation-guided
re-identification(TBPGR).

摘要：<paragraph>基於文字的行人再辨識 (Re-ID) 是複雜多模態分析領域中一個具有挑戰性的課題，其最終目標是透過檢視屬性/自然語言描述來辨識特定行人。儘管在安全監控、影片擷取、人物追蹤和社群媒體分析等廣泛的應用領域中，但鮮少有全面的評論專門從技術角度總結基於文字的行人再辨識。為了填補這個缺口，我們提出了一個涵蓋評估、策略、架構和最佳化面向的分類法，提供基於文字的行人再辨識任務的全面調查。我們首先為基於文字的行人再辨識奠定基礎，闡明與屬性/基於自然語言的辨識相關的基本概念。接著徹底檢視現有的基準資料集和指標。隨後，我們進一步探討基於文字的行人再辨識研究中採用的流行特徵萃取策略，接著簡要總結該領域中常見的網路架構。基於文字的行人再辨識中用於模型最佳化和模態對齊的流行損失函數也受到仔細檢視。最後，我們簡要總結我們的發現，精確指出基於文字的行人再辨識的挑戰。針對這些挑戰，我們概述了未來開放式基於文字的行人再辨識的潛在途徑，並提出了基於文字的行人影像生成導向再辨識 (TBPGR) 的基準架構。</paragraph>

##### **Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey**
2407.21794v1 by Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa

Detecting out-of-distribution (OOD) samples is crucial for ensuring the
safety of machine learning systems and has shaped the field of OOD detection.
Meanwhile, several other problems are closely related to OOD detection,
including anomaly detection (AD), novelty detection (ND), open set recognition
(OSR), and outlier detection (OD). To unify these problems, a generalized OOD
detection framework was proposed, taxonomically categorizing these five
problems. However, Vision Language Models (VLMs) such as CLIP have
significantly changed the paradigm and blurred the boundaries between these
fields, again confusing researchers. In this survey, we first present a
generalized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD
detection, and OD in the VLM era. Our framework reveals that, with some field
inactivity and integration, the demanding challenges have become OOD detection
and AD. In addition, we also highlight the significant shift in the definition,
problem settings, and benchmarks; we thus feature a comprehensive review of the
methodology for OOD detection, including the discussion over other related
tasks to clarify their relationship to OOD detection. Finally, we explore the
advancements in the emerging Large Vision Language Model (LVLM) era, such as
GPT-4V. We conclude this survey with open challenges and future directions.

摘要：偵測異常樣本 (OOD) 對於確保機器學習系統的安全性至關重要，並形塑了 OOD 偵測領域。同時，還有許多其他問題與 OOD 偵測息息相關，包括異常偵測 (AD)、新穎性偵測 (ND)、開放集識別 (OSR) 和離群值偵測 (OD)。為了統一這些問題，提出了廣義的 OOD 偵測架構，將這五個問題分類。然而，像 CLIP 等視覺語言模型 (VLM) 已大幅改變典範，並模糊了這些領域之間的界線，再次讓研究人員感到困惑。在這項調查中，我們首先提出廣義的 OOD 偵測 v2，概括了 AD、ND、OSR、OOD 偵測和 OD 在 VLM 時代的演進。我們的架構揭示，由於某些領域的不活躍和整合，具有挑戰性的問題已成為 OOD 偵測和 AD。此外，我們也重點說明定義、問題設定和基準的重大轉變；因此，我們對 OOD 偵測的方法論進行全面檢視，包括討論其他相關任務以釐清它們與 OOD 偵測的關係。最後，我們探討新興的大型視覺語言模型 (LVLM) 時代的進展，例如 GPT-4V。我們以開放挑戰和未來方向作為這項調查的結論。

##### **Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?**
2407.21792v1 by Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks

As artificial intelligence systems grow more powerful, there has been
increasing interest in "AI safety" research to address emerging and future
risks. However, the field of AI safety remains poorly defined and
inconsistently measured, leading to confusion about how researchers can
contribute. This lack of clarity is compounded by the unclear relationship
between AI safety benchmarks and upstream general capabilities (e.g., general
knowledge and reasoning). To address these issues, we conduct a comprehensive
meta-analysis of AI safety benchmarks, empirically analyzing their correlation
with general capabilities across dozens of models and providing a survey of
existing directions in AI safety. Our findings reveal that many safety
benchmarks highly correlate with upstream model capabilities, potentially
enabling "safetywashing" -- where capability improvements are misrepresented as
safety advancements. Based on these findings, we propose an empirical
foundation for developing more meaningful safety metrics and define AI safety
in a machine learning research context as a set of clearly delineated research
goals that are empirically separable from generic capabilities advancements. In
doing so, we aim to provide a more rigorous framework for AI safety research,
advancing the science of safety evaluations and clarifying the path towards
measurable progress.

摘要：隨著人工智慧系統變得越來越強大，對於「AI 安全」的研究興趣也與日俱增，以因應新興和未來的風險。然而，AI 安全領域的定義仍然很模糊，衡量標準也不一致，導致研究人員如何做出貢獻感到困惑。AI 安全基準與上游一般能力（例如一般知識和推理）之間關係不明確，進一步加劇了這種不確定性。為了解決這些問題，我們對 AI 安全基準進行了全面的後設分析，根據數十個模型實證分析它們與一般能力的相關性，並對 AI 安全中的現有方向進行調查。我們的研究結果顯示，許多安全基準與上游模型能力高度相關，這可能會導致「安全漂白」——將能力的提升誤認為是安全性的進步。根據這些研究結果，我們提出了一個實證基礎，用於開發更有意義的安全指標，並在機器學習研究背景下將 AI 安全定義為一組明確界定的研究目標，這些目標在實證上可以與一般能力的進步區分開來。透過這麼做，我們旨在為 AI 安全研究提供一個更嚴謹的架構，推進安全評估的科學，並釐清邁向可衡量進展的道路。

##### **Vision-Language Model Based Handwriting Verification**
2407.21788v1 by Mihir Chauhan, Abhishek Satbhai, Mohammad Abuzar Hashemi, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari

Handwriting Verification is a critical in document forensics. Deep learning
based approaches often face skepticism from forensic document examiners due to
their lack of explainability and reliance on extensive training data and
handcrafted features. This paper explores using Vision Language Models (VLMs),
such as OpenAI's GPT-4o and Google's PaliGemma, to address these challenges. By
leveraging their Visual Question Answering capabilities and 0-shot
Chain-of-Thought (CoT) reasoning, our goal is to provide clear,
human-understandable explanations for model decisions. Our experiments on the
CEDAR handwriting dataset demonstrate that VLMs offer enhanced
interpretability, reduce the need for large training datasets, and adapt better
to diverse handwriting styles. However, results show that the CNN-based
ResNet-18 architecture outperforms the 0-shot CoT prompt engineering approach
with GPT-4o (Accuracy: 70%) and supervised fine-tuned PaliGemma (Accuracy:
71%), achieving an accuracy of 84% on the CEDAR AND dataset. These findings
highlight the potential of VLMs in generating human-interpretable decisions
while underscoring the need for further advancements to match the performance
of specialized deep learning models.

摘要：手寫驗證在文件鑑識中至關重要。基於深度學習的方法通常會受到文件鑑識專家的懷疑，原因在於它們缺乏可解釋性，並且依賴於大量的訓練資料和手工特徵。本文探討使用視覺語言模型 (VLM)，例如 OpenAI 的 GPT-4o 和 Google 的 PaliGemma，來解決這些挑戰。通過利用它們的視覺問答能力和 0-shot 思想鏈 (CoT) 推理，我們的目標是為模型決策提供清晰、人類可以理解的解釋。我們在 CEDAR 手寫資料集上的實驗表明，VLM 提供了增強的可解釋性，減少了對大型訓練資料集的需求，並且可以更好地適應不同的手寫風格。然而，結果表明，基於 CNN 的 ResNet-18 架構優於使用 GPT-4o（準確率：70%）和監督微調 PaliGemma（準確率：71%）的 0-shot CoT 提示工程方法，在 CEDAR AND 資料集上達到了 84% 的準確率。這些發現突顯了 VLM 在產生人類可以理解的決策方面的潛力，同時也強調了進一步提升與專業深度學習模型相匹配的效能的必要性。

##### **Large Language Monkeys: Scaling Inference Compute with Repeated Sampling**
2407.21787v1 by Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher Ré, Azalia Mirhoseini

Scaling the amount of compute used to train language models has dramatically
improved their capabilities. However, when it comes to inference, we often
limit the amount of compute to only one attempt per problem. Here, we explore
inference compute as another axis for scaling by increasing the number of
generated samples. Across multiple tasks and models, we observe that coverage -
the fraction of problems solved by any attempt - scales with the number of
samples over four orders of magnitude. In domains like coding and formal
proofs, where all answers can be automatically verified, these increases in
coverage directly translate into improved performance. When we apply repeated
sampling to SWE-bench Lite, the fraction of issues solved with
DeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250
samples, outperforming the single-attempt state-of-the-art of 43% which uses
more capable frontier models. Moreover, using current API pricing, amplifying
the cheaper DeepSeek model with five samples is more cost-effective and solves
more issues than paying a premium for one sample from GPT-4o or Claude 3.5
Sonnet. Interestingly, the relationship between coverage and the number of
samples is often log-linear and can be modelled with an exponentiated power
law, suggesting the existence of inference-time scaling laws. Finally, we find
that identifying correct samples out of many generations remains an important
direction for future research in domains without automatic verifiers. When
solving math word problems from GSM8K and MATH, coverage with Llama-3 models
grows to over 95% with 10,000 samples. However, common methods to pick correct
solutions from a sample collection, such as majority voting or reward models,
plateau beyond several hundred samples and fail to fully scale with the sample
budget.

摘要：<paragraph>擴大用於訓練語言模型的運算量已大幅提升其功能。然而，在進行推論時，我們通常將運算量限制在每個問題僅嘗試一次。在此，我們將推論運算視為另一種擴展軸，藉由增加生成範例的數量來進行擴展。在多個任務和模型中，我們觀察到覆蓋率（任何嘗試解決問題的分數）會隨著範例數量而擴展，超過四個數量級。在編碼和形式化證明等領域中，所有答案都可以自動驗證，這些覆蓋率的增加會直接轉化為效能的提升。當我們將重複抽樣套用於 SWE-bench Lite 時，使用 DeepSeek-V2-Coder-Instruct 解決問題的分數從一個範例的 15.9% 提升到 250 個範例的 56%，優於使用功能更強大的前沿模型而達到的 43% 單次嘗試最先進水準。此外，使用目前的 API 定價，以五個範例擴充較便宜的 DeepSeek 模型比支付溢價取得 GPT-4o 或 Claude 3.5 Sonnet 的一個範例更具成本效益，且能解決更多問題。有趣的是，覆蓋率與範例數量之間的關係通常是對數線性的，且可用指數冪律建模，這表示存在推論時間擴展律。最後，我們發現從許多世代中找出正確範例仍然是沒有自動驗證器的領域中未來研究的重要方向。在解決 GSM8K 和 MATH 的數學文字題時，使用 Llama-3 模型的覆蓋率會在 10,000 個範例中成長到超過 95%。然而，從範例集合中挑選正確解答的常見方法（例如多數決或獎勵模型）會在數百個範例後達到平穩期，且無法完全隨著範例預算而擴展。</paragraph>

##### **The Llama 3 Herd of Models**
2407.21783v1 by Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Mathew Oldham, Mathieu Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Olivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta Raileanu, Rohit Girdhar, Rohit Patel, Romain Sauvestre, Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaoqing Ellen Tan, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aaron Grattafiori, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alex Vaughan, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Anam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Franco, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Changhan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, Danny Wyatt, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Firat Ozgenel, Francesco Caggioni, Francisco Guzmán, Frank Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil Halpern, Govind Thattai, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Igor Molybog, Igor Tufanov, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Karthik Prasad, Kartikay Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kun Huang, Kunal Chawla, Kushal Lakhotia, Kyle Huang, Lailin Chen, Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Maria Tsimpoukelli, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Michael L. Seltzer, Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat, Mohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha Parks, Natasha White, Navyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikolay Pavlovich Laptev, Ning Dong, Ning Zhang, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Rohan Maheswari, Russ Howes, Ruty Rinott, Sai Jayesh Bondu, Samyak Datta, Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Verma, Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao Lin, Shengxin Cindy Zha, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Sungmin Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar Glaser, Tamara Best, Thilo Kohler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim Matthews, Timothy Chou, Tzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang, Xiaofang Wang, Xiaojian Wu, Xiaolan Wang, Xide Xia, Xilun Wu, Xinbo Gao, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao

Modern artificial intelligence (AI) systems are powered by foundation models.
This paper presents a new set of foundation models, called Llama 3. It is a
herd of language models that natively support multilinguality, coding,
reasoning, and tool usage. Our largest model is a dense Transformer with 405B
parameters and a context window of up to 128K tokens. This paper presents an
extensive empirical evaluation of Llama 3. We find that Llama 3 delivers
comparable quality to leading language models such as GPT-4 on a plethora of
tasks. We publicly release Llama 3, including pre-trained and post-trained
versions of the 405B parameter language model and our Llama Guard 3 model for
input and output safety. The paper also presents the results of experiments in
which we integrate image, video, and speech capabilities into Llama 3 via a
compositional approach. We observe this approach performs competitively with
the state-of-the-art on image, video, and speech recognition tasks. The
resulting models are not yet being broadly released as they are still under
development.

摘要：現代人工智慧 (AI) 系統由基礎模型提供動力。
本文提出了一組新的基礎模型，稱為 Llama 3。它是一群語言模型，本機支援多語言、編碼、推理和工具使用。我們最大的模型是一個具有 405B 參數和最多 128K 令牌的上下文視窗的密集Transformer。本文提供了對 Llama 3 的廣泛實證評估。我們發現 Llama 3 在大量任務上提供了與 GPT-4 等領先語言模型相當的品質。我們公開發布 Llama 3，包括 405B 參數語言模型的預訓練和後訓練版本，以及我們的 Llama Guard 3 模型，用於輸入和輸出安全性。本文還提供了將影像、影片和語音功能整合到 Llama 3 中的實驗結果，方法是採用組合式方法。我們觀察到這種方法在影像、影片和語音辨識任務上表現出與最先進技術相當的競爭力。由於這些模型仍處於開發階段，因此尚未廣泛發布。

##### **Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries**
2407.21778v1 by Felix Ocker, Daniel Tanneberg, Julian Eggert, Michael Gienger

We introduce tulip agent, an architecture for autonomous LLM-based agents
with Create, Read, Update, and Delete access to a tool library containing a
potentially large number of tools. In contrast to state-of-the-art
implementations, tulip agent does not encode the descriptions of all available
tools in the system prompt, which counts against the model's context window, or
embed the entire prompt for retrieving suitable tools. Instead, the tulip agent
can recursively search for suitable tools in its extensible tool library,
implemented exemplarily as a vector store. The tulip agent architecture
significantly reduces inference costs, allows using even large tool libraries,
and enables the agent to adapt and extend its set of tools. We evaluate the
architecture with several ablation studies in a mathematics context and
demonstrate its generalizability with an application to robotics. A reference
implementation and the benchmark are available at
github.com/HRI-EU/tulip_agent.

摘要：我們介紹了 Tulip 代理，一種基於自主 LLM 的代理架構，可以對包含大量工具的工具庫進行建立、讀取、更新和刪除存取。與最先進的實作相反，Tulip 代理不會將所有可用工具的描述編碼在系統提示中，這會計入模型的內容視窗，或嵌入整個提示以擷取合適的工具。相反地，Tulip 代理可以在其可延伸工具庫中遞迴搜尋合適的工具，範例實作為向量儲存。Tulip 代理架構大幅降低了推論成本，允許使用甚至大型工具庫，並讓代理調整和延伸其工具組。我們在數學背景中使用多項消融研究評估架構，並透過機器人應用程式展示其概括性。可以在 github.com/HRI-EU/tulip_agent 取得參考實作和基準。

##### **ShieldGemma: Generative AI Content Moderation Based on Gemma**
2407.21772v1 by Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, Olivia Sturman, Oscar Wahltinez

We present ShieldGemma, a comprehensive suite of LLM-based safety content
moderation models built upon Gemma2. These models provide robust,
state-of-the-art predictions of safety risks across key harm types (sexually
explicit, dangerous content, harassment, hate speech) in both user input and
LLM-generated output. By evaluating on both public and internal benchmarks, we
demonstrate superior performance compared to existing models, such as Llama
Guard (+10.8\% AU-PRC on public benchmarks) and WildCard (+4.3\%).
Additionally, we present a novel LLM-based data curation pipeline, adaptable to
a variety of safety-related tasks and beyond. We have shown strong
generalization performance for model trained mainly on synthetic data. By
releasing ShieldGemma, we provide a valuable resource to the research
community, advancing LLM safety and enabling the creation of more effective
content moderation solutions for developers.

摘要：我們展示 ShieldGemma，這是一套建構於 Gemma2 的全面 LLM 安全內容審核模型套件。這些模型提供健全、最先進的安全性風險預測，涵蓋使用者輸入和 LLM 產生的輸出中的主要危害類型（露骨性內容、危險內容、騷擾、仇恨言論）。透過在公開和內部基準上進行評估，我們展示出優於現有模型的卓越效能，例如 Llama Guard（在公開基準上 +10.8% AU-PRC）和 WildCard（+4.3%）。此外，我們提出一個新穎的 LLM 資料策管流程，適用於各種安全相關任務及其他任務。我們已展示出對於主要訓練在合成資料上的模型的強大泛化效能。透過釋出 ShieldGemma，我們為研究社群提供了寶貴的資源，推進 LLM 安全性並協助開發人員建立更有效的內容審核解決方案。

##### **MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts**
2407.21770v1 by Xi Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Gosh, Luke Zettlemoyer, Armen Aghajanyan

We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)
architecture designed for pre-training mixed-modal, early-fusion language
models. MoMa processes images and text in arbitrary sequences by dividing
expert modules into modality-specific groups. These groups exclusively process
designated tokens while employing learned routing within each group to maintain
semantically informed adaptivity. Our empirical results reveal substantial
pre-training efficiency gains through this modality-specific parameter
allocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,
featuring 4 text experts and 4 image experts, achieves impressive FLOPs
savings: 3.7x overall, with 2.6x for text and 5.2x for image processing
compared to a compute-equivalent dense baseline, measured by pre-training loss.
This outperforms the standard expert-choice MoE with 8 mixed-modal experts,
which achieves 3x overall FLOPs savings (3x for text, 2.8x for image).
Combining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs
savings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination
hurts performance in causal inference due to increased sensitivity to router
accuracy. These results demonstrate MoMa's potential to significantly advance
the efficiency of mixed-modal, early-fusion language model pre-training, paving
the way for more resource-efficient and capable multimodal AI systems.

摘要：<paragraph>我們介紹 MoMa，一種新穎的模態感知混合專家 (MoE) 架構，專為混合模態、早期融合語言模型的預訓練而設計。MoMa 透過將專家模組分為模態特定群組，以任意順序處理影像和文字。這些群組會獨自處理指定的代碼，同時在每個群組內使用已學習的路由，以維持語義適應性。我們的實證結果顯示，透過這種模態特定參數配置，可大幅提升預訓練效率。在 1 兆個代碼的訓練預算下，MoMa 1.4B 模型配備 4 個文字專家和 4 個影像專家，可節省令人驚豔的 FLOP：整體而言為 3.7 倍，文字處理為 2.6 倍，影像處理為 5.2 倍，這是以預訓練損失測量，並與運算等效的密集基準線相比較。這優於標準的專家選擇 MoE，後者配備 8 個混合模態專家，可節省整體 FLOP 3 倍（文字為 3 倍，影像為 2.8 倍）。將 MoMa 與混合深度 (MoD) 結合，可進一步將預訓練 FLOP 節省提升至整體 4.2 倍（文字：3.4 倍，影像：5.3 倍），儘管這種組合會因路由器精確度敏感度增加而損害因果推理的效能。這些結果證明了 MoMa 在提升混合模態、早期融合語言模型預訓練效率方面的潛力，為更具資源效率且功能強大的多模態 AI 系統鋪路。</paragraph>

