{"2405.04682": {"publish_time": "2024-05-07", "title": "TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation", "paper_summary": "Recent advances in diffusion-based generative modeling have led to the\ndevelopment of text-to-video (T2V) models that can generate high-quality videos\nconditioned on a text prompt. Most of these T2V models often produce\nsingle-scene video clips that depict an entity performing a particular action\n(e.g., `a red panda climbing a tree'). However, it is pertinent to generate\nmulti-scene videos since they are ubiquitous in the real-world (e.g., `a red\npanda climbing a tree' followed by `the red panda sleeps on the top of the\ntree'). To generate multi-scene videos from the pretrained T2V model, we\nintroduce Time-Aligned Captions (TALC) framework. Specifically, we enhance the\ntext-conditioning mechanism in the T2V architecture to recognize the temporal\nalignment between the video scenes and scene descriptions. For instance, we\ncondition the visual features of the earlier and later scenes of the generated\nvideo with the representations of the first scene description (e.g., `a red\npanda climbing a tree') and second scene description (e.g., `the red panda\nsleeps on the top of the tree'), respectively. As a result, we show that the\nT2V model can generate multi-scene videos that adhere to the multi-scene text\ndescriptions and be visually consistent (e.g., entity and background). Further,\nwe finetune the pretrained T2V model with multi-scene video-text data using the\nTALC framework. We show that the TALC-finetuned model outperforms the baseline\nmethods by 15.5 points in the overall score, which averages visual consistency\nand text adherence using human evaluation. The project website is\nhttps://talc-mst2v.github.io/.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u5728\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u5f0f\u5efa\u6a21\u65b9\u9762\u7684\u8fdb\u5c55\u5df2\u5bfc\u81f4\u5f00\u53d1\u51fa\u6587\u672c\u5230\u89c6\u9891 (T2V) \u6a21\u578b\uff0c\u8be5\u6a21\u578b\u53ef\u6839\u636e\u6587\u672c\u63d0\u793a\u751f\u6210\u9ad8\u8d28\u91cf\u89c6\u9891\u3002\u8fd9\u4e9b T2V \u6a21\u578b\u4e2d\u7684\u5927\u591a\u6570\u901a\u5e38\u4f1a\u751f\u6210\u63cf\u7ed8\u5b9e\u4f53\u6267\u884c\u7279\u5b9a\u52a8\u4f5c\u7684\u5355\u573a\u666f\u89c6\u9891\u7247\u6bb5\uff08\u4f8b\u5982\uff0c\u201c\u4e00\u53ea\u7ea2\u718a\u732b\u722c\u6811\u201d\uff09\u3002\u7136\u800c\uff0c\u751f\u6210\u591a\u573a\u666f\u89c6\u9891\u662f\u76f8\u5173\u7684\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u65e0\u5904\u4e0d\u5728\uff08\u4f8b\u5982\uff0c\u201c\u4e00\u53ea\u7ea2\u718a\u732b\u722c\u6811\u201d\uff0c\u7136\u540e\u201c\u7ea2\u718a\u732b\u7761\u5728\u6811\u9876\u201d\uff09\u3002\u4e3a\u4e86\u4ece\u9884\u8bad\u7ec3\u7684 T2V \u6a21\u578b\u751f\u6210\u591a\u573a\u666f\u89c6\u9891\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u65f6\u95f4\u5bf9\u9f50\u5b57\u5e55 (TALC) \u6846\u67b6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u589e\u5f3a\u4e86 T2V \u67b6\u6784\u4e2d\u7684\u6587\u672c\u8c03\u8282\u673a\u5236\uff0c\u4ee5\u8bc6\u522b\u89c6\u9891\u573a\u666f\u548c\u573a\u666f\u63cf\u8ff0\u4e4b\u95f4\u7684\u65f6\u6001\u5bf9\u9f50\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u4f7f\u7528\u7b2c\u4e00\u4e2a\u573a\u666f\u63cf\u8ff0\uff08\u4f8b\u5982\uff0c\u201c\u4e00\u53ea\u7ea2\u718a\u732b\u722c\u6811\u201d\uff09\u548c\u7b2c\u4e8c\u4e2a\u573a\u666f\u63cf\u8ff0\uff08\u4f8b\u5982\uff0c\u201c\u7ea2\u718a\u732b\u7761\u5728\u6811\u9876\u201d\uff09\u7684\u8868\u793a\uff0c\u5206\u522b\u8c03\u8282\u751f\u6210\u89c6\u9891\u7684\u65e9\u671f\u548c\u540e\u671f\u573a\u666f\u7684\u53ef\u89c6\u5316\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u8868\u660e T2V \u6a21\u578b\u53ef\u4ee5\u751f\u6210\u7b26\u5408\u591a\u573a\u666f\u6587\u672c\u63cf\u8ff0\u4e14\u5728\u89c6\u89c9\u4e0a\u4fdd\u6301\u4e00\u81f4\uff08\u4f8b\u5982\uff0c\u5b9e\u4f53\u548c\u80cc\u666f\uff09\u7684\u591a\u573a\u666f\u89c6\u9891\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4f7f\u7528 TALC \u6846\u67b6\u4f7f\u7528\u591a\u573a\u666f\u89c6\u9891\u6587\u672c\u6570\u636e\u5bf9\u9884\u8bad\u7ec3\u7684 T2V \u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u6211\u4eec\u8868\u660e\uff0cTALC \u5fae\u8c03\u6a21\u578b\u5728\u603b\u4f53\u5f97\u5206\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa 15.5 \u5206\uff0c\u8be5\u5f97\u5206\u4f7f\u7528\u4eba\u7c7b\u8bc4\u4f30\u5bf9\u89c6\u89c9\u4e00\u81f4\u6027\u548c\u6587\u672c\u4f9d\u4ece\u6027\u8fdb\u884c\u5e73\u5747\u3002\u9879\u76ee\u7f51\u7ad9\u662f https://talc-mst2v.github.io/\u3002</paragraph>", "author": "Hritik Bansal et.al.", "authors": "Hritik Bansal, Yonatan Bitton, Michal Yarom, Idan Szpektor, Aditya Grover, Kai-Wei Chang", "id": "2405.04682v1", "paper_url": "http://arxiv.org/abs/2405.04682v1", "repo": "null"}}