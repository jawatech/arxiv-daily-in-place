{"2502.14727": {"publish_time": "2025-02-20", "title": "WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models", "paper_summary": "Retrieval Augmented Generation (RAG) has gained widespread adoption owing to\nits capacity to empower large language models (LLMs) to integrate external\nknowledge. However, existing RAG frameworks are primarily designed for\ntext-based LLMs and rely on Automatic Speech Recognition to process speech\ninput, which discards crucial audio information, risks transcription errors,\nand increases computational overhead. Therefore, we introduce WavRAG, the first\nretrieval augmented generation framework with native, end-to-end audio support.\nWavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw\naudio for both embedding and retrieval. 2) WavRAG integrates audio and text\ninto a unified knowledge representation. Specifically, we propose the\nWavRetriever to facilitate the retrieval from a text-audio hybrid knowledge\nbase, and further enhance the in-context capabilities of spoken dialogue models\nthrough the integration of chain-of-thought reasoning. In comparison to\nstate-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval\nperformance while delivering a 10x acceleration. Furthermore, WavRAG's unique\ntext-audio hybrid retrieval capability extends the boundaries of RAG to the\naudio modality.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u56e0\u5176\u8ce6\u80fd\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6574\u5408\u5916\u90e8\u77e5\u8b58\u7684\u80fd\u529b\u800c\u7372\u5f97\u5ee3\u6cdb\u63a1\u7528\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 RAG \u6846\u67b6\u4e3b\u8981\u8a2d\u8a08\u7528\u65bc\u57fa\u65bc\u6587\u5b57\u7684 LLM\uff0c\u4e26\u4f9d\u8cf4\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58\u8655\u7406\u8a9e\u97f3\u8f38\u5165\uff0c\u9019\u6703\u6368\u68c4\u91cd\u8981\u7684\u97f3\u8a0a\u8cc7\u8a0a\u3001\u6709\u8f49\u9304\u932f\u8aa4\u7684\u98a8\u96aa\uff0c\u4e26\u589e\u52a0\u904b\u7b97\u8ca0\u64d4\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 WavRAG\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5177\u5099\u539f\u751f\u7aef\u5c0d\u7aef\u97f3\u8a0a\u652f\u63f4\u7684\u6aa2\u7d22\u589e\u5f37\u751f\u6210\u6846\u67b6\u3002WavRAG \u63d0\u4f9b\u5169\u500b\u4e3b\u8981\u529f\u80fd\uff1a1) \u7e5e\u904e ASR\uff0cWavRAG \u76f4\u63a5\u8655\u7406\u539f\u59cb\u97f3\u8a0a\u4ee5\u9032\u884c\u5d4c\u5165\u548c\u6aa2\u7d22\u30022) WavRAG \u5c07\u97f3\u8a0a\u548c\u6587\u5b57\u6574\u5408\u5230\u7d71\u4e00\u7684\u77e5\u8b58\u8868\u793a\u4e2d\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63d0\u51fa\u4e86 WavRetriever \u4ee5\u5229\u65bc\u5f9e\u6587\u5b57\u97f3\u8a0a\u6df7\u5408\u77e5\u8b58\u5eab\u4e2d\u9032\u884c\u6aa2\u7d22\uff0c\u4e26\u900f\u904e\u6574\u5408\u601d\u8003\u93c8\u63a8\u7406\u9032\u4e00\u6b65\u589e\u5f37\u5c0d\u8a71\u6a21\u578b\u7684\u8a9e\u5883\u80fd\u529b\u3002\u8207\u6700\u5148\u9032\u7684 ASR \u6587\u5b57 RAG \u7ba1\u7dda\u76f8\u6bd4\uff0cWavRAG \u9054\u5230\u4e86\u76f8\u7576\u7684\u6aa2\u7d22\u6548\u80fd\uff0c\u540c\u6642\u63d0\u4f9b\u4e86 10 \u500d\u7684\u52a0\u901f\u3002\u6b64\u5916\uff0cWavRAG \u7368\u7279\u7684\u6587\u5b57\u97f3\u8a0a\u6df7\u5408\u6aa2\u7d22\u80fd\u529b\u5c07 RAG \u7684\u754c\u7dda\u5ef6\u4f38\u5230\u97f3\u8a0a\u6a21\u5f0f\u3002", "author": "Yifu Chen et.al.", "authors": "Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao", "id": "2502.14727v1", "paper_url": "http://arxiv.org/abs/2502.14727v1", "repo": "null"}}