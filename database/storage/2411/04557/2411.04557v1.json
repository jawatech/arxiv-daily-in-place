{"2411.04557": {"publish_time": "2024-11-07", "title": "Pruning Literals for Highly Efficient Explainability at Word Level", "paper_summary": "Designing an explainable model becomes crucial now for Natural Language\nProcessing(NLP) since most of the state-of-the-art machine learning models\nprovide a limited explanation for the prediction. In the spectrum of an\nexplainable model, Tsetlin Machine(TM) is promising because of its capability\nof providing word-level explanation using proposition logic. However, concern\nrises over the elaborated combination of literals (propositional logic) in the\nclause that makes the model difficult for humans to comprehend, despite having\na transparent learning process. In this paper, we design a post-hoc pruning of\nclauses that eliminate the randomly placed literals in the clause thereby\nmaking the model more efficiently interpretable than the vanilla TM.\nExperiments on the publicly available YELP-HAT Dataset demonstrate that the\nproposed pruned TM's attention map aligns more with the human attention map\nthan the vanilla TM's attention map. In addition, the pairwise similarity\nmeasure also surpasses the attention map-based neural network models. In terms\nof accuracy, the proposed pruning method does not degrade the accuracy\nsignificantly but rather enhances the performance up to 4% to 9% in some test\ndata.", "paper_summary_zh": "<paragraph>\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\uff08NLP\uff09\u4e2d\uff0c\u8a2d\u8a08\u4e00\u500b\u53ef\u89e3\u91cb\u7684\u6a21\u578b\u73fe\u5728\u8b8a\u5f97\u81f3\u95dc\u91cd\u8981\uff0c\u56e0\u70ba\u5927\u591a\u6578\u6700\u5148\u9032\u7684\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u5c0d\u9810\u6e2c\u63d0\u4f9b\u7684\u89e3\u91cb\u6709\u9650\u3002\u5728\u53ef\u89e3\u91cb\u6a21\u578b\u7684\u7bc4\u7587\u4e2d\uff0cTsetlin \u6a5f\u5668\uff08TM\uff09\u56e0\u5176\u4f7f\u7528\u547d\u984c\u908f\u8f2f\u63d0\u4f9b\u5b57\u5143\u7b49\u7d1a\u89e3\u91cb\u7684\u80fd\u529b\u800c\u5f88\u6709\u524d\u666f\u3002\u7136\u800c\uff0c\u5118\u7ba1\u5b78\u7fd2\u904e\u7a0b\u900f\u660e\uff0c\u4f46\u5c0d\u5b50\u53e5\u4e2d\u7cbe\u7d30\u7684\u5b57\u9762\u91cf\uff08\u547d\u984c\u908f\u8f2f\uff09\u7d44\u5408\u7684\u95dc\u6ce8\u537b\u8b93\u4eba\u985e\u96e3\u4ee5\u7406\u89e3\u8a72\u6a21\u578b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5b50\u53e5\u7684\u5f8c\u8a2d\u526a\u679d\uff0c\u6d88\u9664\u4e86\u5b50\u53e5\u4e2d\u96a8\u6a5f\u653e\u7f6e\u7684\u5b57\u9762\u91cf\uff0c\u5f9e\u800c\u4f7f\u6a21\u578b\u6bd4\u9999\u8349 TM \u66f4\u5bb9\u6613\u89e3\u91cb\u3002\u5728\u516c\u958b\u7684 YELP-HAT \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u526a\u679d TM \u7684\u6ce8\u610f\u529b\u5716\u6bd4\u9999\u8349 TM \u7684\u6ce8\u610f\u529b\u5716\u66f4\u7b26\u5408\u4eba\u985e\u7684\u6ce8\u610f\u529b\u5716\u3002\u6b64\u5916\uff0c\u6210\u5c0d\u76f8\u4f3c\u6027\u6e2c\u91cf\u4e5f\u8d85\u8d8a\u4e86\u57fa\u65bc\u6ce8\u610f\u529b\u5716\u7684\u795e\u7d93\u7db2\u8def\u6a21\u578b\u3002\u5728\u6e96\u78ba\u6027\u65b9\u9762\uff0c\u6240\u63d0\u51fa\u7684\u526a\u679d\u65b9\u6cd5\u4e26\u672a\u986f\u8457\u964d\u4f4e\u6e96\u78ba\u6027\uff0c\u53cd\u800c\u5728\u67d0\u4e9b\u6e2c\u8a66\u8cc7\u6599\u4e2d\u5c07\u6548\u80fd\u63d0\u9ad8\u4e86 4% \u5230 9%\u3002</paragraph>", "author": "Rohan Kumar Yadav et.al.", "authors": "Rohan Kumar Yadav, Bimal Bhattarai, Abhik Jana, Lei Jiao, Seid Muhie Yimam", "id": "2411.04557v1", "paper_url": "http://arxiv.org/abs/2411.04557v1", "repo": "null"}}