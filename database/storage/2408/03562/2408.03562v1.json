{"2408.03562": {"publish_time": "2024-08-07", "title": "A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case", "paper_summary": "This research compares large language model (LLM) fine-tuning methods,\nincluding Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning\n(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally\ncompared LLM evaluation methods including End to End (E2E) benchmark method of\n\"Golden Answers\", traditional natural language processing (NLP) metrics, RAG\nAssessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,\nusing the travel chatbot use case. The travel dataset was sourced from the the\nReddit API by requesting posts from travel-related subreddits to get\ntravel-related conversation prompts and personalized travel experiences, and\naugmented for each fine-tuning method. We used two pretrained LLMs utilized for\nfine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to\nthe two pretrained models. The inferences from these models are extensively\nevaluated against the aforementioned metrics. The best model according to human\nevaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a\nReinforcement Learning from Human Feedback (RLHF) training pipeline, and\nultimately was evaluated as the best model. Our main findings are that: 1)\nquantitative and Ragas metrics do not align with human evaluation, 2) Open AI\nGPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep\nhumans in the loop for evaluation because, 4) traditional NLP metrics\ninsufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms\nQLoRA, but still needs postprocessing, 7) RLHF improves model performance\nsignificantly. Next steps include improving data quality, increasing data\nquantity, exploring RAG methods, and focusing data collection on a specific\ncity, which would improve data quality by narrowing the focus, while creating a\nuseful product.", "paper_summary_zh": "\u672c\u7814\u7a76\u6bd4\u8f03\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5fae\u8abf\u65b9\u6cd5\uff0c\u5305\u62ec\u91cf\u5316\u4f4e\u79e9\u9069\u914d\u5668 (QLoRA)\u3001\u6aa2\u7d22\u64f4\u589e\u5fae\u8abf (RAFT) \u548c\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF)\uff0c\u4e26\u984d\u5916\u6bd4\u8f03\u4e86 LLM \u8a55\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u300c\u9ec3\u91d1\u7b54\u6848\u300d\u7684\u7aef\u5c0d\u7aef (E2E) \u57fa\u6e96\u65b9\u6cd5\u3001\u50b3\u7d71\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u6307\u6a19\u3001RAG \u8a55\u4f30 (Ragas)\u3001OpenAI GPT-4 \u8a55\u4f30\u6307\u6a19\u548c\u4eba\u985e\u8a55\u4f30\uff0c\u4e26\u4f7f\u7528\u65c5\u904a\u804a\u5929\u6a5f\u5668\u4eba\u7528\u4f8b\u3002\u65c5\u904a\u8cc7\u6599\u96c6\u4f86\u81ea Reddit API\uff0c\u900f\u904e\u8981\u6c42\u65c5\u904a\u76f8\u95dc\u5b50\u7248\u584a\u7684\u8cbc\u6587\u4f86\u53d6\u5f97\u65c5\u904a\u76f8\u95dc\u5c0d\u8a71\u63d0\u793a\u548c\u500b\u4eba\u5316\u65c5\u904a\u9ad4\u9a57\uff0c\u4e26\u91dd\u5c0d\u6bcf\u7a2e\u5fae\u8abf\u65b9\u6cd5\u9032\u884c\u64f4\u5145\u3002\u6211\u5011\u4f7f\u7528\u4e86\u5169\u500b\u9810\u8a13\u7df4 LLM\uff0c\u7528\u65bc\u5fae\u8abf\u7814\u7a76\uff1aLLaMa 2 7B \u548c Mistral 7B\u3002QLoRA \u548c RAFT \u61c9\u7528\u65bc\u9019\u5169\u500b\u9810\u8a13\u7df4\u6a21\u578b\u3002\u5ee3\u6cdb\u8a55\u4f30\u9019\u4e9b\u6a21\u578b\u7684\u63a8\u8ad6\u7d50\u679c\uff0c\u4e26\u4f7f\u7528\u4e0a\u8ff0\u6307\u6a19\u3002\u6839\u64da\u4eba\u985e\u8a55\u4f30\u548c\u4e00\u4e9b GPT-4 \u6307\u6a19\uff0c\u6700\u597d\u7684\u6a21\u578b\u662f Mistral RAFT\uff0c\u56e0\u6b64\u5b83\u63a5\u53d7\u4e86\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF) \u8a13\u7df4\u6d41\u7a0b\uff0c\u4e26\u6700\u7d42\u88ab\u8a55\u70ba\u6700\u4f73\u6a21\u578b\u3002\u6211\u5011\u7684\u767c\u73fe\u4e3b\u8981\u6709\uff1a1) \u5b9a\u91cf\u548c Ragas \u6307\u6a19\u8207\u4eba\u985e\u8a55\u4f30\u4e0d\u4e00\u81f4\uff0c2) Open AI GPT-4 \u8a55\u4f30\u6700\u7b26\u5408\u4eba\u985e\u8a55\u4f30\uff0c3) \u5fc5\u9808\u8b93\u4eba\u985e\u53c3\u8207\u8a55\u4f30\uff0c\u56e0\u70ba 4) \u50b3\u7d71 NLP \u6307\u6a19\u4e0d\u8db3\uff0c5) Mistral \u901a\u5e38\u512a\u65bc LLaMa\uff0c6) RAFT \u512a\u65bc QLoRA\uff0c\u4f46\u4ecd\u9700\u8981\u5f8c\u8655\u7406\uff0c7) RLHF \u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u6548\u80fd\u3002\u5f8c\u7e8c\u6b65\u9a5f\u5305\u62ec\u63d0\u5347\u8cc7\u6599\u54c1\u8cea\u3001\u589e\u52a0\u8cc7\u6599\u6578\u91cf\u3001\u63a2\u7d22 RAG \u65b9\u6cd5\uff0c\u4ee5\u53ca\u5c08\u6ce8\u65bc\u7279\u5b9a\u57ce\u5e02\u7684\u8cc7\u6599\u6536\u96c6\uff0c\u9019\u5c07\u900f\u904e\u7e2e\u5c0f\u7126\u9ede\u4f86\u63d0\u5347\u8cc7\u6599\u54c1\u8cea\uff0c\u540c\u6642\u5275\u9020\u6709\u7528\u7684\u7522\u54c1\u3002", "author": "Sonia Meyer et.al.", "authors": "Sonia Meyer, Shreya Singh, Bertha Tam, Christopher Ton, Angel Ren", "id": "2408.03562v1", "paper_url": "http://arxiv.org/abs/2408.03562v1", "repo": "null"}}