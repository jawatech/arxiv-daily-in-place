{"2408.11785": {"publish_time": "2024-08-21", "title": "Timeline and Boundary Guided Diffusion Network for Video Shadow Detection", "paper_summary": "Video Shadow Detection (VSD) aims to detect the shadow masks with frame\nsequence. Existing works suffer from inefficient temporal learning. Moreover,\nfew works address the VSD problem by considering the characteristic (i.e.,\nboundary) of shadow. Motivated by this, we propose a Timeline and Boundary\nGuided Diffusion (TBGDiff) network for VSD where we take account of the\npast-future temporal guidance and boundary information jointly. In detail, we\ndesign a Dual Scale Aggregation (DSA) module for better temporal understanding\nby rethinking the affinity of the long-term and short-term frames for the\nclipped video. Next, we introduce Shadow Boundary Aware Attention (SBAA) to\nutilize the edge contexts for capturing the characteristics of shadows.\nMoreover, we are the first to introduce the Diffusion model for VSD in which we\nexplore a Space-Time Encoded Embedding (STEE) to inject the temporal guidance\nfor Diffusion to conduct shadow detection. Benefiting from these designs, our\nmodel can not only capture the temporal information but also the shadow\nproperty. Extensive experiments show that the performance of our approach\novertakes the state-of-the-art methods, verifying the effectiveness of our\ncomponents. We release the codes, weights, and results at\n\\url{https://github.com/haipengzhou856/TBGDiff}.", "paper_summary_zh": "\u5f71\u7247\u9670\u5f71\u5075\u6e2c\uff08VSD\uff09\u65e8\u5728\u5075\u6e2c\u5177\u6709\u5e8f\u5217\u756b\u683c\u7684\u9670\u5f71\u906e\u7f69\u3002\u73fe\u6709\u7684\u4f5c\u54c1\u5728\u6642\u9593\u5b78\u7fd2\u65b9\u9762\u6548\u7387\u4e0d\u5f70\u3002\u6b64\u5916\uff0c\u5f88\u5c11\u6709\u4f5c\u54c1\u900f\u904e\u8003\u91cf\u9670\u5f71\u7684\u7279\u5fb5\uff08\u4f8b\u5982\u908a\u754c\uff09\u4f86\u89e3\u6c7a VSD \u554f\u984c\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u6642\u9593\u8ef8\u548c\u908a\u754c\u5f15\u5c0e\u64f4\u6563\uff08TBGDiff\uff09\u7db2\u8def\u7528\u65bc VSD\uff0c\u5176\u4e2d\u6211\u5011\u540c\u6642\u8003\u91cf\u904e\u53bb\u548c\u672a\u4f86\u7684\u6642\u9593\u6307\u5f15\u548c\u908a\u754c\u8cc7\u8a0a\u3002\u8a73\u7d30\u4f86\u8aaa\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u96d9\u91cd\u5c3a\u5ea6\u805a\u5408\uff08DSA\uff09\u6a21\u7d44\uff0c\u900f\u904e\u91cd\u65b0\u601d\u8003\u9577\u671f\u548c\u77ed\u671f\u756b\u683c\u5c0d\u526a\u8f2f\u5f71\u7247\u7684\u95dc\u806f\u6027\uff0c\u4ee5\u7372\u5f97\u66f4\u597d\u7684\u6642\u9593\u7406\u89e3\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u5f15\u5165\u9670\u5f71\u908a\u754c\u611f\u77e5\u6ce8\u610f\u529b\uff08SBAA\uff09\u4f86\u5229\u7528\u908a\u7de3\u8108\u7d61\u4ee5\u64f7\u53d6\u9670\u5f71\u7684\u7279\u5fb5\u3002\u6b64\u5916\uff0c\u6211\u5011\u662f\u7b2c\u4e00\u500b\u5728 VSD \u4e2d\u5f15\u5165\u64f4\u6563\u6a21\u578b\u7684\u4eba\uff0c\u5176\u4e2d\u6211\u5011\u63a2\u8a0e\u4f7f\u7528\u6642\u7a7a\u7de8\u78bc\u5d4c\u5165\uff08STEE\uff09\u4f86\u6ce8\u5165\u6642\u9593\u6307\u5f15\uff0c\u4ee5\u8b93\u64f4\u6563\u57f7\u884c\u9670\u5f71\u5075\u6e2c\u3002\u53d7\u76ca\u65bc\u9019\u4e9b\u8a2d\u8a08\uff0c\u6211\u5011\u7684\u6a21\u578b\u4e0d\u50c5\u80fd\u64f7\u53d6\u6642\u9593\u8cc7\u8a0a\uff0c\u9084\u80fd\u64f7\u53d6\u9670\u5f71\u5c6c\u6027\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u65b9\u6cd5\u7684\u6548\u80fd\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u9a57\u8b49\u4e86\u6211\u5011\u5143\u4ef6\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u5728 \\url{https://github.com/haipengzhou856/TBGDiff} \u91cb\u51fa\u7a0b\u5f0f\u78bc\u3001\u6b0a\u91cd\u548c\u7d50\u679c\u3002", "author": "Haipeng Zhou et.al.", "authors": "Haipeng Zhou, Honqiu Wang, Tian Ye, Zhaohu Xing, Jun Ma, Ping Li, Qiong Wang, Lei Zhu", "id": "2408.11785v1", "paper_url": "http://arxiv.org/abs/2408.11785v1", "repo": "https://github.com/haipengzhou856/tbgdiff"}}