{"2410.18050": {"publish_time": "2024-10-23", "title": "LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering", "paper_summary": "Long-Context Question Answering (LCQA), a challenging task, aims to reason\nover long-context documents to yield accurate answers to questions. Existing\nlong-context Large Language Models (LLMs) for LCQA often struggle with the\n\"lost in the middle\" issue. Retrieval-Augmented Generation (RAG) mitigates this\nissue by providing external factual evidence. However, its chunking strategy\ndisrupts the global long-context information, and its low-quality retrieval in\nlong contexts hinders LLMs from identifying effective factual details due to\nsubstantial noise. To this end, we propose LongRAG, a general,\ndual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance\nRAG's understanding of complex long-context knowledge (i.e., global information\nand factual details). We design LongRAG as a plug-and-play paradigm,\nfacilitating adaptation to various domains and LLMs. Extensive experiments on\nthree multi-hop datasets demonstrate that LongRAG significantly outperforms\nlong-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG\n(up by 17.25%). Furthermore, we conduct quantitative ablation studies and\nmulti-dimensional analyses, highlighting the effectiveness of the system's\ncomponents and fine-tuning strategies. Data and code are available at\nhttps://github.com/QingFei1/LongRAG.", "paper_summary_zh": "\u9577\u6587\u672c\u554f\u7b54 (LCQA) \u662f\u4e00\u9805\u5177\u6709\u6311\u6230\u6027\u7684\u4efb\u52d9\uff0c\u65e8\u5728\u5c0d\u9577\u6587\u672c\u6587\u4ef6\u9032\u884c\u63a8\u7406\uff0c\u4ee5\u5c0d\u554f\u984c\u63d0\u4f9b\u6e96\u78ba\u7684\u7b54\u6848\u3002\u73fe\u6709\u7684\u9577\u6587\u672c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u65bc LCQA \u7d93\u5e38\u6703\u9047\u5230\u300c\u8ff7\u5931\u5728\u4e2d\u9593\u300d\u7684\u554f\u984c\u3002\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u53ef\u900f\u904e\u63d0\u4f9b\u5916\u90e8\u4e8b\u5be6\u8b49\u64da\u4f86\u7de9\u89e3\u6b64\u554f\u984c\u3002\u7136\u800c\uff0c\u5176\u5206\u584a\u7b56\u7565\u6703\u4e2d\u65b7\u5168\u5c40\u9577\u6587\u672c\u8cc7\u8a0a\uff0c\u4e14\u5176\u5728\u9577\u6587\u672c\u4e2d\u7684\u4f4e\u54c1\u8cea\u6aa2\u7d22\u6703\u56e0\u70ba\u5927\u91cf\u7684\u96dc\u8a0a\uff0c\u800c\u963b\u7919 LLM \u627e\u51fa\u6709\u6548\u7684\u5be6\u969b\u7d30\u7bc0\u3002\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa LongRAG\uff0c\u4e00\u500b\u91dd\u5c0d LCQA \u7684\u901a\u7528\u3001\u96d9\u91cd\u89c0\u9ede\u4e14\u5f37\u5065\u7684\u57fa\u65bc LLM \u7684 RAG \u7cfb\u7d71\u7bc4\u4f8b\uff0c\u4ee5\u589e\u5f37 RAG \u5c0d\u8907\u96dc\u9577\u6587\u672c\u77e5\u8b58\uff08\u4f8b\u5982\uff0c\u5168\u5c40\u8cc7\u8a0a\u548c\u5be6\u969b\u7d30\u7bc0\uff09\u7684\u7406\u89e3\u3002\u6211\u5011\u5c07 LongRAG \u8a2d\u8a08\u70ba\u4e00\u500b\u5373\u63d2\u5373\u7528\u7684\u7bc4\u4f8b\uff0c\u65b9\u4fbf\u8abf\u6574\u5230\u5404\u7a2e\u7db2\u57df\u548c LLM\u3002\u91dd\u5c0d\u4e09\u500b\u591a\u8df3\u8e8d\u8cc7\u6599\u96c6\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0cLongRAG \u660e\u986f\u512a\u65bc\u9577\u6587\u672c LLM\uff08\u63d0\u5347 6.94%\uff09\u3001\u9032\u968e RAG\uff08\u63d0\u5347 6.16%\uff09\u548c Vanilla RAG\uff08\u63d0\u5347 17.25%\uff09\u3002\u6b64\u5916\uff0c\u6211\u5011\u9032\u884c\u4e86\u5b9a\u91cf\u7684\u6d88\u878d\u7814\u7a76\u548c\u591a\u7dad\u5ea6\u5206\u6790\uff0c\u5f37\u8abf\u4e86\u7cfb\u7d71\u7d44\u6210\u548c\u5fae\u8abf\u7b56\u7565\u7684\u6709\u6548\u6027\u3002\u8cc7\u6599\u548c\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/QingFei1/LongRAG \u53d6\u5f97\u3002", "author": "Qingfei Zhao et.al.", "authors": "Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Yuxiao Dong, Jie Tang", "id": "2410.18050v1", "paper_url": "http://arxiv.org/abs/2410.18050v1", "repo": "https://github.com/qingfei1/longrag"}}