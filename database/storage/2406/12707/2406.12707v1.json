{"2406.12707": {"publish_time": "2024-06-18", "title": "Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction", "paper_summary": "Large Language Model (LLM)-enhanced agents become increasingly prevalent in\nHuman-AI communication, offering vast potential from entertainment to\nprofessional domains. However, current multi-modal dialogue systems overlook\nthe acoustic information present in speech, which is crucial for understanding\nhuman communication nuances. This oversight can lead to misinterpretations of\nspeakers' intentions, resulting in inconsistent or even contradictory responses\nwithin dialogues. To bridge this gap, in this paper, we propose\nPerceptiveAgent, an empathetic multi-modal dialogue system designed to discern\ndeeper or more subtle meanings beyond the literal interpretations of words\nthrough the integration of speech modality perception. Employing LLMs as a\ncognitive core, PerceptiveAgent perceives acoustic information from input\nspeech and generates empathetic responses based on speaking styles described in\nnatural language. Experimental results indicate that PerceptiveAgent excels in\ncontextual understanding by accurately discerning the speakers' true intentions\nin scenarios where the linguistic meaning is either contrary to or inconsistent\nwith the speaker's true feelings, producing more nuanced and expressive spoken\ndialogues. Code is publicly available at:\n\\url{https://github.com/Haoqiu-Yan/PerceptiveAgent}.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u589e\u5f37\u7684\u4ee3\u7406\u5728\u4eba\u6a5f\u6e9d\u901a\u4e2d\u65e5\u76ca\u666e\u904d\uff0c\u5728\u5a1b\u6a02\u5230\u5c08\u696d\u9818\u57df\u63d0\u4f9b\u5ee3\u6cdb\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u7576\u524d\u7684\u591a\u6a21\u614b\u5c0d\u8a71\u7cfb\u7d71\u5ffd\u8996\u4e86\u8a9e\u97f3\u4e2d\u5b58\u5728\u7684\u8072\u5b78\u8cc7\u8a0a\uff0c\u9019\u5c0d\u65bc\u7406\u89e3\u4eba\u985e\u6e9d\u901a\u7684\u7d30\u5fae\u5dee\u5225\u81f3\u95dc\u91cd\u8981\u3002\u9019\u7a2e\u758f\u5ffd\u53ef\u80fd\u6703\u5c0e\u81f4\u5c0d\u8aaa\u8a71\u8005\u610f\u5716\u7684\u8aa4\u89e3\uff0c\u5f9e\u800c\u5c0e\u81f4\u5c0d\u8a71\u4e2d\u51fa\u73fe\u4e0d\u4e00\u81f4\u751a\u81f3\u77db\u76fe\u7684\u56de\u61c9\u3002\u70ba\u4e86\u5f4c\u5408\u9019\u4e00\u5dee\u8ddd\uff0c\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 PerceptiveAgent\uff0c\u9019\u662f\u4e00\u500b\u540c\u7406\u5fc3\u591a\u6a21\u614b\u5c0d\u8a71\u7cfb\u7d71\uff0c\u65e8\u5728\u900f\u904e\u6574\u5408\u8a9e\u97f3\u6a21\u614b\u611f\u77e5\uff0c\u8fa8\u5225\u51fa\u6587\u5b57\u8868\u5c64\u8a6e\u91cb\u4e4b\u5916\u66f4\u6df1\u6216\u66f4\u5fae\u5999\u7684\u610f\u7fa9\u3002PerceptiveAgent \u4ee5 LLM \u4f5c\u70ba\u8a8d\u77e5\u6838\u5fc3\uff0c\u611f\u77e5\u8f38\u5165\u8a9e\u97f3\u4e2d\u7684\u8072\u5b78\u8cc7\u8a0a\uff0c\u4e26\u6839\u64da\u4ee5\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u7684\u8aaa\u8a71\u98a8\u683c\u7522\u751f\u540c\u7406\u5fc3\u7684\u56de\u61c9\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cPerceptiveAgent \u5728\u8108\u7d61\u7406\u89e3\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u5728\u8a9e\u8a00\u610f\u7fa9\u8207\u8aaa\u8a71\u8005\u7684\u771f\u5be6\u611f\u53d7\u76f8\u53cd\u6216\u4e0d\u4e00\u81f4\u7684\u60c5\u6cc1\u4e0b\uff0c\u6e96\u78ba\u5730\u8fa8\u5225\u51fa\u8aaa\u8a71\u8005\u7684\u771f\u5be6\u610f\u5716\uff0c\u7522\u751f\u66f4\u7d30\u7dfb\u4e14\u5bcc\u6709\u8868\u73fe\u529b\u7684\u53e3\u8a9e\u5c0d\u8a71\u3002\u7a0b\u5f0f\u78bc\u516c\u958b\u65bc\uff1a\\url{https://github.com/Haoqiu-Yan/PerceptiveAgent}\u3002", "author": "Haoqiu Yan et.al.", "authors": "Haoqiu Yan, Yongxin Zhu, Kai Zheng, Bing Liu, Haoyu Cao, Deqiang Jiang, Linli Xu", "id": "2406.12707v1", "paper_url": "http://arxiv.org/abs/2406.12707v1", "repo": "https://github.com/haoqiu-yan/perceptiveagent"}}