{"2406.08431": {"publish_time": "2024-06-12", "title": "Diffusion Soup: Model Merging for Text-to-Image Diffusion Models", "paper_summary": "We present Diffusion Soup, a compartmentalization method for Text-to-Image\nGeneration that averages the weights of diffusion models trained on sharded\ndata. By construction, our approach enables training-free continual learning\nand unlearning with no additional memory or inference costs, since models\ncorresponding to data shards can be added or removed by re-averaging. We show\nthat Diffusion Soup samples from a point in weight space that approximates the\ngeometric mean of the distributions of constituent datasets, which offers\nanti-memorization guarantees and enables zero-shot style mixing. Empirically,\nDiffusion Soup outperforms a paragon model trained on the union of all data\nshards and achieves a 30% improvement in Image Reward (.34 $\\to$ .44) on domain\nsharded data, and a 59% improvement in IR (.37 $\\to$ .59) on aesthetic data. In\nboth cases, souping also prevails in TIFA score (respectively, 85.5 $\\to$ 86.5\nand 85.6 $\\to$ 86.8). We demonstrate robust unlearning -- removing any\nindividual domain shard only lowers performance by 1% in IR (.45 $\\to$ .44) --\nand validate our theoretical insights on anti-memorization using real data.\nFinally, we showcase Diffusion Soup's ability to blend the distinct styles of\nmodels finetuned on different shards, resulting in the zero-shot generation of\nhybrid styles.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa Diffusion Soup\uff0c\u9019\u662f\u4e00\u7a2e\u91dd\u5c0d\u6587\u5b57\u8f49\u5716\u50cf\u751f\u6210\u7684\u5206\u5340\u65b9\u6cd5\uff0c\u5b83\u6703\u5c0d\u5728\u5206\u7247\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u64f4\u6563\u6a21\u578b\u6b0a\u91cd\u53d6\u5e73\u5747\u3002\u6839\u64da\u5efa\u69cb\uff0c\u6211\u5011\u7684\u505a\u6cd5\u80fd\u9032\u884c\u514d\u8a13\u7df4\u7684\u6301\u7e8c\u5b78\u7fd2\u548c\u53d6\u6d88\u5b78\u7fd2\uff0c\u800c\u7121\u9700\u984d\u5916\u8a18\u61b6\u9ad4\u6216\u63a8\u8ad6\u6210\u672c\uff0c\u56e0\u70ba\u5c0d\u61c9\u65bc\u8cc7\u6599\u5206\u7247\u7684\u6a21\u578b\u53ef\u4ee5\u900f\u904e\u91cd\u65b0\u53d6\u5e73\u5747\u4f86\u65b0\u589e\u6216\u79fb\u9664\u3002\u6211\u5011\u5c55\u793a Diffusion Soup \u5f9e\u6b0a\u91cd\u7a7a\u9593\u4e2d\u7684\u4e00\u500b\u9ede\u9032\u884c\u53d6\u6a23\uff0c\u6b64\u9ede\u8fd1\u4f3c\u65bc\u7d44\u6210\u8cc7\u6599\u96c6\u5206\u4f48\u7684\u5e7e\u4f55\u5e73\u5747\u503c\uff0c\u9019\u63d0\u4f9b\u4e86\u53cd\u8a18\u61b6\u4fdd\u8b49\u4e26\u80fd\u9032\u884c\u96f6\u6b21\u5b78\u7fd2\u98a8\u683c\u6df7\u5408\u3002\u6839\u64da\u7d93\u9a57\uff0cDiffusion Soup \u512a\u65bc\u5728\u6240\u6709\u8cc7\u6599\u5206\u7247\u7684\u806f\u96c6\u4e0a\u8a13\u7df4\u7684\u7bc4\u4f8b\u6a21\u578b\uff0c\u4e26\u4e14\u5728\u7db2\u57df\u5206\u7247\u8cc7\u6599\u4e0a\u5f71\u50cf\u734e\u52f5\u65b9\u9762\u63d0\u5347\u4e86 30%\uff08.34 $\\to$ .44\uff09\uff0c\u5728\u7f8e\u5b78\u8cc7\u6599\u4e0a IR \u63d0\u5347\u4e86 59%\uff08.37 $\\to$ .59\uff09\u3002\u5728\u5169\u7a2e\u60c5\u6cc1\u4e0b\uff0csouping \u4e5f\u5728 TIFA \u5206\u6578\u4e2d\u52dd\u51fa\uff08\u5206\u5225\u70ba 85.5 $\\to$ 86.5 \u548c 85.6 $\\to$ 86.8\uff09\u3002\u6211\u5011\u5c55\u793a\u4e86\u5f37\u5927\u7684\u53d6\u6d88\u5b78\u7fd2\u80fd\u529b\u2014\u2014\u79fb\u9664\u4efb\u4f55\u500b\u5225\u7db2\u57df\u5206\u7247\u53ea\u6703\u4f7f IR \u6548\u80fd\u964d\u4f4e 1%\uff08.45 $\\to$ .44\uff09\u2014\u2014\u4e26\u4f7f\u7528\u771f\u5be6\u8cc7\u6599\u9a57\u8b49\u4e86\u6211\u5011\u5728\u53cd\u8a18\u61b6\u65b9\u9762\u7684\u7406\u8ad6\u898b\u89e3\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u4e86 Diffusion Soup \u6df7\u5408\u5728\u4e0d\u540c\u5206\u7247\u4e0a\u5fae\u8abf\u7684\u6a21\u578b\u7684\u4e0d\u540c\u98a8\u683c\u7684\u80fd\u529b\uff0c\u7522\u751f\u4e86\u96f6\u6b21\u5b78\u7fd2\u7684\u6df7\u5408\u98a8\u683c\u3002</paragraph>", "author": "Benjamin Biggs et.al.", "authors": "Benjamin Biggs, Arjun Seshadri, Yang Zou, Achin Jain, Aditya Golatkar, Yusheng Xie, Alessandro Achille, Ashwin Swaminathan, Stefano Soatto", "id": "2406.08431v1", "paper_url": "http://arxiv.org/abs/2406.08431v1", "repo": "null"}}