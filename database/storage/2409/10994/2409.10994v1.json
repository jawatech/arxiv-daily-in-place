{"2409.10994": {"publish_time": "2024-09-17", "title": "Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs", "paper_summary": "The rapid advancement of Multimodal Large Language Models (MLLMs) has led to\nremarkable performances across various domains. However, this progress is\naccompanied by a substantial surge in the resource consumption of these models.\nWe address this pressing issue by introducing a new approach, Token Reduction\nusing CLIP Metric (TRIM), aimed at improving the efficiency of MLLMs without\nsacrificing their performance. Inspired by human attention patterns in Visual\nQuestion Answering (VQA) tasks, TRIM presents a fresh perspective on the\nselection and reduction of image tokens. The TRIM method has been extensively\ntested across 12 datasets, and the results demonstrate a significant reduction\nin computational overhead while maintaining a consistent level of performance.\nThis research marks a critical stride in efficient MLLM development, promoting\ngreater accessibility and sustainability of high-performing models.", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM) \u7684\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u4e86\u5728\u5404\u4e2a\u9886\u57df\u7684\u5353\u8d8a\u8868\u73b0\u3002\u7136\u800c\uff0c\u8fd9\u4e00\u8fdb\u5c55\u4f34\u968f\u7740\u8fd9\u4e9b\u6a21\u578b\u8d44\u6e90\u6d88\u8017\u7684\u5927\u5e45\u589e\u52a0\u3002\u6211\u4eec\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u7d27\u8feb\u95ee\u9898\uff0c\u5373\u4f7f\u7528 CLIP \u6307\u6807 (TRIM) \u8fdb\u884c\u6807\u8bb0\u51cf\u5c11\uff0c\u65e8\u5728\u63d0\u9ad8 MLLM \u7684\u6548\u7387\u800c\u4e0d\u727a\u7272\u5176\u6027\u80fd\u3002\u53d7\u89c6\u89c9\u95ee\u7b54 (VQA) \u4efb\u52a1\u4e2d\u4eba\u7c7b\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u542f\u53d1\uff0cTRIM \u63d0\u4f9b\u4e86\u5bf9\u56fe\u50cf\u6807\u8bb0\u9009\u62e9\u548c\u51cf\u5c11\u7684\u65b0\u89c6\u89d2\u3002TRIM \u65b9\u6cd5\u5df2\u5728 12 \u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660e\u5728\u4fdd\u6301\u4e00\u81f4\u6027\u80fd\u6c34\u5e73\u7684\u540c\u65f6\uff0c\u8ba1\u7b97\u5f00\u9500\u663e\u8457\u51cf\u5c11\u3002\u8fd9\u9879\u7814\u7a76\u6807\u5fd7\u7740\u9ad8\u6548 MLLM \u5f00\u53d1\u7684\u5173\u952e\u4e00\u6b65\uff0c\u4fc3\u8fdb\u4e86\u9ad8\u6027\u80fd\u6a21\u578b\u7684\u66f4\u5927\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002", "author": "Dingjie Song et.al.", "authors": "Dingjie Song, Wenjun Wang, Shunian Chen, Xidong Wang, Michael Guan, Benyou Wang", "id": "2409.10994v1", "paper_url": "http://arxiv.org/abs/2409.10994v1", "repo": "null"}}