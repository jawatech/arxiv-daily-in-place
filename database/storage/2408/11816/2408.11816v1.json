{"2408.11816": {"publish_time": "2024-08-21", "title": "Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction", "paper_summary": "In the face of difficult exploration problems in reinforcement learning, we\nstudy whether giving an agent an object-centric mapping (describing a set of\nitems and their attributes) allow for more efficient learning. We found this\nproblem is best solved hierarchically by modelling items at a higher level of\nstate abstraction to pixels, and attribute change at a higher level of temporal\nabstraction to primitive actions. This abstraction simplifies the transition\ndynamic by making specific future states easier to predict. We make use of this\nto propose a fully model-based algorithm that learns a discriminative world\nmodel, plans to explore efficiently with only a count-based intrinsic reward,\nand can subsequently plan to reach any discovered (abstract) states.\n  We demonstrate the model's ability to (i) efficiently solve single tasks,\n(ii) transfer zero-shot and few-shot across item types and environments, and\n(iii) plan across long horizons. Across a suite of 2D crafting and MiniHack\nenvironments, we empirically show our model significantly out-performs\nstate-of-the-art low-level methods (without abstraction), as well as performant\nmodel-free and model-based methods using the same abstraction. Finally, we show\nhow to reinforce learn low level object-perturbing policies, as well as\nsupervise learn the object mapping itself.", "paper_summary_zh": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u9762\u5bf9\u56f0\u96be\u7684\u63a2\u7d22\u95ee\u9898\u65f6\uff0c\u6211\u4eec\u7814\u7a76\u7ed9\u4e88\u4ee3\u7406\u4e00\u4e2a\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u6620\u5c04\uff08\u63cf\u8ff0\u4e00\u7ec4\u9879\u76ee\u53ca\u5176\u5c5e\u6027\uff09\u662f\u5426\u5141\u8bb8\u66f4\u6709\u6548\u7387\u7684\u5b66\u4e60\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u6b64\u95ee\u9898\u6700\u9002\u5408\u901a\u8fc7\u5728\u66f4\u9ad8\u5c42\u6b21\u7684\u72b6\u6001\u62bd\u8c61\u4e2d\u5c06\u9879\u76ee\u5efa\u6a21\u4e3a\u50cf\u7d20\uff0c\u5e76\u5c06\u5c5e\u6027\u66f4\u6539\u5efa\u6a21\u4e3a\u539f\u59cb\u52a8\u4f5c\u7684\u66f4\u9ad8\u5c42\u6b21\u7684\u65f6\u95f4\u62bd\u8c61\uff0c\u4ece\u800c\u5206\u5c42\u89e3\u51b3\u3002\u8fd9\u79cd\u62bd\u8c61\u901a\u8fc7\u4f7f\u7279\u5b9a\u7684\u672a\u6765\u72b6\u6001\u66f4\u5bb9\u6613\u9884\u6d4b\u6765\u7b80\u5316\u8f6c\u6362\u52a8\u6001\u3002\u6211\u4eec\u5229\u7528\u8fd9\u4e00\u70b9\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5b66\u4e60\u5224\u522b\u6027\u4e16\u754c\u6a21\u578b\uff0c\u8ba1\u5212\u4ec5\u4f7f\u7528\u57fa\u4e8e\u8ba1\u6570\u7684\u5185\u5728\u5956\u52b1\u6709\u6548\u5730\u8fdb\u884c\u63a2\u7d22\uff0c\u5e76\u968f\u540e\u8ba1\u5212\u8fbe\u5230\u4efb\u4f55\u53d1\u73b0\u7684\uff08\u62bd\u8c61\uff09\u72b6\u6001\u3002\u6211\u4eec\u5c55\u793a\u4e86\u8be5\u6a21\u578b\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a(i) \u6709\u6548\u5730\u89e3\u51b3\u5355\u4e00\u4efb\u52a1\uff0c(ii) \u5728\u9879\u76ee\u7c7b\u578b\u548c\u73af\u5883\u4e2d\u8f6c\u79fb\u96f6\u6b21\u548c\u5c11\u6b21\uff0c\u4ee5\u53ca (iii) \u5728\u8f83\u957f\u7684\u8303\u56f4\u5185\u8fdb\u884c\u8ba1\u5212\u3002\u5728 2D \u5236\u4f5c\u548c MiniHack \u73af\u5883\u5957\u4ef6\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u5b9e\u8bc1\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u660e\u663e\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u4f4e\u7ea7\u65b9\u6cd5\uff08\u6ca1\u6709\u62bd\u8c61\uff09\uff0c\u4ee5\u53ca\u4f7f\u7528\u76f8\u540c\u62bd\u8c61\u7684\u9ad8\u6027\u80fd\u65e0\u6a21\u578b\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u5f3a\u5316\u5b66\u4e60\u4f4e\u7ea7\u5bf9\u8c61\u6270\u52a8\u7b56\u7565\uff0c\u4ee5\u53ca\u76d1\u7763\u5b66\u4e60\u5bf9\u8c61\u6620\u5c04\u672c\u8eab\u3002", "author": "Anthony GX-Chen et.al.", "authors": "Anthony GX-Chen, Kenneth Marino, Rob Fergus", "id": "2408.11816v1", "paper_url": "http://arxiv.org/abs/2408.11816v1", "repo": "null"}}