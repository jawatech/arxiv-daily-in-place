{"2410.12388": {"publish_time": "2024-10-16", "title": "Prompt Compression for Large Language Models: A Survey", "paper_summary": "Leveraging large language models (LLMs) for complex natural language tasks\ntypically requires long-form prompts to convey detailed requirements and\ninformation, which results in increased memory usage and inference costs. To\nmitigate these challenges, multiple efficient methods have been proposed, with\nprompt compression gaining significant research interest. This survey provides\nan overview of prompt compression techniques, categorized into hard prompt\nmethods and soft prompt methods. First, the technical approaches of these\nmethods are compared, followed by an exploration of various ways to understand\ntheir mechanisms, including the perspectives of attention optimization,\nParameter-Efficient Fine-Tuning (PEFT), modality fusion, and new synthetic\nlanguage. We also examine the downstream adaptations of various prompt\ncompression techniques. Finally, the limitations of current prompt compression\nmethods are analyzed, and several future directions are outlined, such as\noptimizing the compression encoder, combining hard and soft prompts methods,\nand leveraging insights from multimodality.", "paper_summary_zh": "\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8655\u7406\u8907\u96dc\u7684\u81ea\u7136\u8a9e\u8a00\u4efb\u52d9\u901a\u5e38\u9700\u8981\u9577\u7bc7\u63d0\u793a\u4f86\u50b3\u9054\u8a73\u7d30\u7684\u8981\u6c42\u548c\u8cc7\u8a0a\uff0c\u9019\u6703\u589e\u52a0\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u548c\u63a8\u8ad6\u6210\u672c\u3002\u70ba\u4e86\u6e1b\u8f15\u9019\u4e9b\u6311\u6230\uff0c\u5df2\u63d0\u51fa\u591a\u7a2e\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d\u63d0\u793a\u58d3\u7e2e\u7372\u5f97\u4e86\u986f\u8457\u7684\u7814\u7a76\u8208\u8da3\u3002\u672c\u8abf\u67e5\u63d0\u4f9b\u4e86\u63d0\u793a\u58d3\u7e2e\u6280\u8853\u7684\u6982\u8ff0\uff0c\u5206\u70ba\u786c\u63d0\u793a\u65b9\u6cd5\u548c\u8edf\u63d0\u793a\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u6bd4\u8f03\u9019\u4e9b\u65b9\u6cd5\u7684\u6280\u8853\u65b9\u6cd5\uff0c\u7136\u5f8c\u63a2\u8a0e\u7406\u89e3\u5176\u6a5f\u5236\u7684\u5404\u7a2e\u65b9\u6cd5\uff0c\u5305\u62ec\u95dc\u6ce8\u6700\u4f73\u5316\u3001\u53c3\u6578\u6709\u6548\u5fae\u8abf (PEFT)\u3001\u6a21\u614b\u878d\u5408\u548c\u65b0\u7684\u5408\u6210\u8a9e\u8a00\u3002\u6211\u5011\u9084\u6aa2\u67e5\u4e86\u5404\u7a2e\u63d0\u793a\u58d3\u7e2e\u6280\u8853\u7684\u4e0b\u6e38\u9069\u61c9\u3002\u6700\u5f8c\uff0c\u5206\u6790\u4e86\u7576\u524d\u63d0\u793a\u58d3\u7e2e\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u4e26\u6982\u8ff0\u4e86\u5e7e\u500b\u672a\u4f86\u7684\u65b9\u5411\uff0c\u4f8b\u5982\u6700\u4f73\u5316\u58d3\u7e2e\u7de8\u78bc\u5668\u3001\u7d50\u5408\u786c\u63d0\u793a\u548c\u8edf\u63d0\u793a\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5229\u7528\u591a\u6a21\u614b\u7684\u898b\u89e3\u3002", "author": "Zongqian Li et.al.", "authors": "Zongqian Li, Yinhong Liu, Yixuan Su, Nigel Collier", "id": "2410.12388v1", "paper_url": "http://arxiv.org/abs/2410.12388v1", "repo": "null"}}