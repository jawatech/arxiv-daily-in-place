{"2408.12456": {"publish_time": "2024-08-22", "title": "Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing", "paper_summary": "Large language models (LLMs) face challenges with internal knowledge\ninaccuracies and outdated information. Knowledge editing has emerged as a\npivotal approach to mitigate these issues. Although current knowledge editing\ntechniques exhibit promising performance in single-hop reasoning tasks, they\nshow limitations when applied to multi-hop reasoning. Drawing on cognitive\nneuroscience and the operational mechanisms of LLMs, we hypothesize that the\nresidual single-hop knowledge after editing causes edited models to revert to\ntheir original answers when processing multi-hop questions, thereby undermining\ntheir performance in multihop reasoning tasks. To validate this hypothesis, we\nconduct a series of experiments that empirically confirm our assumptions.\nBuilding on the validated hypothesis, we propose a novel knowledge editing\nmethod that incorporates a Knowledge Erasure mechanism for Large language model\nEditing (KELE). Specifically, we design an erasure function for residual\nknowledge and an injection function for new knowledge. Through joint\noptimization, we derive the optimal recall vector, which is subsequently\nutilized within a rank-one editing framework to update the parameters of\ntargeted model layers. Extensive experiments on GPT-J and GPT-2 XL demonstrate\nthat KELE substantially enhances the multi-hop reasoning capability of edited\nLLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9762\u81e8\u8457\u5167\u90e8\u77e5\u8b58\u4e0d\u6e96\u78ba\u548c\u8cc7\u8a0a\u904e\u6642\u7684\u554f\u984c\u3002\u77e5\u8b58\u7de8\u8f2f\u5df2\u6210\u70ba\u7de9\u89e3\u9019\u4e9b\u554f\u984c\u7684\u95dc\u9375\u65b9\u6cd5\u3002\u5118\u7ba1\u76ee\u524d\u7684\u77e5\u8b58\u7de8\u8f2f\u6280\u8853\u5728\u55ae\u8df3\u63a8\u7406\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u826f\u597d\u7684\u6548\u80fd\uff0c\u4f46\u5728\u61c9\u7528\u65bc\u591a\u8df3\u63a8\u7406\u6642\u537b\u986f\u793a\u51fa\u5c40\u9650\u6027\u3002\u6839\u64da\u8a8d\u77e5\u795e\u7d93\u79d1\u5b78\u548c LLM \u7684\u904b\u4f5c\u6a5f\u5236\uff0c\u6211\u5011\u5047\u8a2d\u7de8\u8f2f\u5f8c\u7684\u6b98\u9918\u55ae\u8df3\u77e5\u8b58\u6703\u5c0e\u81f4\u7de8\u8f2f\u5f8c\u7684\u6a21\u578b\u5728\u8655\u7406\u591a\u8df3\u554f\u984c\u6642\u6062\u5fa9\u5230\u5b83\u5011\u7684\u539f\u59cb\u7b54\u6848\uff0c\u5f9e\u800c\u640d\u5bb3\u5b83\u5011\u5728\u591a\u8df3\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u6548\u80fd\u3002\u70ba\u4e86\u9a57\u8b49\u9019\u500b\u5047\u8a2d\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u7cfb\u5217\u5be6\u9a57\uff0c\u5be6\u8b49\u5730\u78ba\u8a8d\u4e86\u6211\u5011\u7684\u5047\u8a2d\u3002\u5efa\u7acb\u5728\u7d93\u904e\u9a57\u8b49\u7684\u5047\u8a2d\u4e4b\u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7684\u77e5\u8b58\u7de8\u8f2f\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u542b\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7de8\u8f2f\u7684\u77e5\u8b58\u522a\u9664\u6a5f\u5236 (KELE)\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u7528\u65bc\u6b98\u9918\u77e5\u8b58\u7684\u522a\u9664\u51fd\u6578\u548c\u4e00\u500b\u7528\u65bc\u65b0\u77e5\u8b58\u7684\u6ce8\u5165\u51fd\u6578\u3002\u900f\u904e\u806f\u5408\u6700\u4f73\u5316\uff0c\u6211\u5011\u63a8\u5c0e\u51fa\u6700\u4f73\u53ec\u56de\u5411\u91cf\uff0c\u96a8\u5f8c\u5728\u79e9\u4e00\u7de8\u8f2f\u67b6\u69cb\u4e2d\u4f7f\u7528\u5b83\u4f86\u66f4\u65b0\u76ee\u6a19\u6a21\u578b\u5c64\u7684\u53c3\u6578\u3002\u5728 GPT-J \u548c GPT-2 XL \u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0cKELE \u5927\u5927\u589e\u5f37\u4e86\u5df2\u7de8\u8f2f LLM \u7684\u591a\u8df3\u63a8\u7406\u80fd\u529b\u3002", "author": "Mengqi Zhang et.al.", "authors": "Mengqi Zhang, Bowen Fang, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen, Liang Wang", "id": "2408.12456v1", "paper_url": "http://arxiv.org/abs/2408.12456v1", "repo": "null"}}