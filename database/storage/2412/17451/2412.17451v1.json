{"2412.17451": {"publish_time": "2024-12-23", "title": "Diving into Self-Evolving Training for Multimodal Reasoning", "paper_summary": "Reasoning ability is essential for Large Multimodal Models (LMMs). In the\nabsence of multimodal chain-of-thought annotated data, self-evolving training,\nwhere the model learns from its own outputs, has emerged as an effective and\nscalable approach for enhancing reasoning abilities. Despite its growing usage,\na comprehensive understanding of self-evolving training, particularly in the\ncontext of multimodal reasoning, remains limited. In this paper, we delve into\nthe intricacies of self-evolving training for multimodal reasoning, pinpointing\nthree key factors: Training Method, Reward Model, and Prompt Variation. We\nsystematically examine each factor and explore how various configurations\naffect the training's effectiveness. Our analysis leads to a set of best\npractices for each factor, aimed at optimizing multimodal reasoning.\nFurthermore, we explore the Self-Evolution Dynamics during training and the\nimpact of automatic balancing mechanisms in boosting performance. After all the\ninvestigations, we present a final recipe for self-evolving training in\nmultimodal reasoning, encapsulating these design choices into a framework we\ncall MSTaR (Multimodal Self-evolving Training for Reasoning), which is\nuniversally effective for models with different sizes on various benchmarks,\ne.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning\nbenchmarks without using additional human annotations, as demonstrated on\nMiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this\nstudy fills a significant gap in the understanding of self-evolving training\nfor multimodal reasoning and offers a robust framework for future research. Our\npolicy and reward models, as well as the collected data, is released to\nfacilitate further investigation in multimodal reasoning.", "paper_summary_zh": "\u63a8\u7406\u80fd\u529b\u5bf9\u4e8e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b (LMM) \u81f3\u5173\u91cd\u8981\u3002\u5728\u7f3a\u4e4f\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u6ce8\u91ca\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\uff08\u6a21\u578b\u4ece\u5176\u81ea\u8eab\u7684\u8f93\u51fa\u4e2d\u5b66\u4e60\uff09\u5df2\u6210\u4e3a\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002\u5c3d\u7ba1\u4f7f\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4f46\u5bf9\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u7684\u5168\u9762\u7406\u89e3\uff0c\u5c24\u5176\u662f\u5728\u591a\u6a21\u6001\u63a8\u7406\u7684\u80cc\u666f\u4e0b\uff0c\u4ecd\u7136\u6709\u9650\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u6df1\u5165\u7814\u7a76\u4e86\u591a\u6a21\u6001\u63a8\u7406\u7684\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u7684\u590d\u6742\u6027\uff0c\u6307\u51fa\u4e86\u4e09\u4e2a\u5173\u952e\u56e0\u7d20\uff1a\u8bad\u7ec3\u65b9\u6cd5\u3001\u5956\u52b1\u6a21\u578b\u548c\u63d0\u793a\u53d8\u5316\u3002\u6211\u4eec\u7cfb\u7edf\u5730\u68c0\u67e5\u4e86\u6bcf\u4e2a\u56e0\u7d20\uff0c\u5e76\u63a2\u8ba8\u4e86\u5404\u79cd\u914d\u7f6e\u5982\u4f55\u5f71\u54cd\u8bad\u7ec3\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u7684\u5206\u6790\u9488\u5bf9\u6bcf\u4e2a\u56e0\u7d20\u5f97\u51fa\u4e86\u4e00\u7ec4\u6700\u4f73\u5b9e\u8df5\uff0c\u65e8\u5728\u4f18\u5316\u591a\u6a21\u6001\u63a8\u7406\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63a2\u8ba8\u4e86\u8bad\u7ec3\u671f\u95f4\u7684\u81ea\u6211\u8fdb\u5316\u52a8\u6001\u4ee5\u53ca\u81ea\u52a8\u5e73\u8861\u673a\u5236\u5bf9\u63d0\u5347\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5728\u6240\u6709\u8c03\u67e5\u4e4b\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u7684\u6700\u7ec8\u79d8\u8bc0\uff0c\u5c06\u8fd9\u4e9b\u8bbe\u8ba1\u9009\u62e9\u5c01\u88c5\u5230\u4e00\u4e2a\u6211\u4eec\u79f0\u4e4b\u4e3a MSTaR\uff08\u63a8\u7406\u591a\u6a21\u6001\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\uff09\u7684\u6846\u67b6\u4e2d\uff0c\u8be5\u6846\u67b6\u5bf9\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u5728\u5404\u79cd\u57fa\u51c6\u4e0a\u90fd\u5177\u6709\u666e\u904d\u7684\u6709\u6548\u6027\uff0c\u4f8b\u5982\uff0c\u5728 5 \u4e2a\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u4e0a\u660e\u663e\u8d85\u8d8a\u4e86\u9884\u5148\u8fdb\u5316\u7684\u6a21\u578b\uff0c\u800c\u65e0\u9700\u4f7f\u7528\u989d\u5916\u7684\u6ce8\u91ca\uff0c\u5982\u5728 MiniCPM-V-2.5 (8B)\u3001Phi-3.5-Vision (4B) \u548c InternVL2 (2B) \u4e0a\u6240\u5c55\u793a\u7684\u3002\u6211\u4eec\u76f8\u4fe1\uff0c\u8fd9\u9879\u7814\u7a76\u586b\u8865\u4e86\u5bf9\u591a\u6a21\u6001\u63a8\u7406\u7684\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u7406\u89e3\u65b9\u9762\u7684\u91cd\u5927\u7a7a\u767d\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6846\u67b6\u3002\u6211\u4eec\u7684\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\u4ee5\u53ca\u6536\u96c6\u7684\u6570\u636e\u5df2\u53d1\u5e03\uff0c\u4ee5\u4fc3\u8fdb\u5bf9\u591a\u6a21\u6001\u63a8\u7406\u7684\u8fdb\u4e00\u6b65\u8c03\u67e5\u3002", "author": "Wei Liu et.al.", "authors": "Wei Liu, Junlong Li, Xiwen Zhang, Fan Zhou, Yu Cheng, Junxian He", "id": "2412.17451v1", "paper_url": "http://arxiv.org/abs/2412.17451v1", "repo": "null"}}