{"2411.14215": {"publish_time": "2024-11-21", "title": "Evaluating the Robustness of Analogical Reasoning in Large Language Models", "paper_summary": "LLMs have performed well on several reasoning benchmarks, including ones that\ntest analogical reasoning abilities. However, there is debate on the extent to\nwhich they are performing general abstract reasoning versus employing\nnon-robust processes, e.g., that overly rely on similarity to pre-training\ndata. Here we investigate the robustness of analogy-making abilities previously\nclaimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu\n(2023): letter-string analogies, digit matrices, and story analogies. For each\ndomain we test humans and GPT models on robustness to variants of the original\nanalogy problems that test the same abstract reasoning abilities but are likely\ndissimilar from tasks in the pre-training data. The performance of a system\nthat uses robust abstract reasoning should not decline substantially on these\nvariants.\n  On simple letter-string analogies, we find that while the performance of\nhumans remains high for two types of variants we tested, the GPT models'\nperformance declines sharply. This pattern is less pronounced as the complexity\nof these problems is increased, as both humans and GPT models perform poorly on\nboth the original and variant problems requiring more complex analogies. On\ndigit-matrix problems, we find a similar pattern but only on one out of the two\ntypes of variants we tested. On story-based analogy problems, we find that,\nunlike humans, the performance of GPT models are susceptible to answer-order\neffects, and that GPT models also may be more sensitive than humans to\nparaphrasing.\n  This work provides evidence that LLMs often lack the robustness of zero-shot\nhuman analogy-making, exhibiting brittleness on most of the variations we\ntested. More generally, this work points to the importance of carefully\nevaluating AI systems not only for accuracy but also robustness when testing\ntheir cognitive capabilities.", "paper_summary_zh": "<paragraph>LLM \u5728\u8a31\u591a\u63a8\u7406\u57fa\u6e96\u4e0a\u8868\u73fe\u826f\u597d\uff0c\u5305\u62ec\u6e2c\u8a66\u985e\u6bd4\u63a8\u7406\u80fd\u529b\u7684\u57fa\u6e96\u3002\u7136\u800c\uff0c\u5c0d\u65bc\u5b83\u5011\u57f7\u884c\u4e00\u822c\u62bd\u8c61\u63a8\u7406\u7684\u7a0b\u5ea6\uff0c\u8207\u63a1\u7528\u975e\u7a69\u5065\u7684\u7a0b\u5e8f\uff08\u4f8b\u5982\u904e\u5ea6\u4f9d\u8cf4\u8207\u9810\u8a13\u7df4\u8cc7\u6599\u7684\u76f8\u4f3c\u6027\uff09\u4e4b\u9593\u7684\u722d\u8ad6\u4e0d\u4f11\u3002\u5728\u6b64\uff0c\u6211\u5011\u63a2\u8a0e\u4e86 Webb\u3001Holyoak \u548c Lu\uff082023 \u5e74\uff09\u7814\u7a76\u7684\u56db\u500b\u9818\u57df\u4e2d\uff0cLLM \u5148\u524d\u8072\u7a31\u7684\u985e\u6bd4\u5efa\u69cb\u80fd\u529b\u7684\u7a69\u5065\u6027\uff1a\u5b57\u6bcd\u4e32\u985e\u6bd4\u3001\u6578\u5b57\u77e9\u9663\u548c\u6545\u4e8b\u985e\u6bd4\u3002\u5c0d\u65bc\u6bcf\u500b\u9818\u57df\uff0c\u6211\u5011\u91dd\u5c0d\u4eba\u985e\u548c GPT \u6a21\u578b\u6e2c\u8a66\u5176\u5c0d\u539f\u59cb\u985e\u6bd4\u554f\u984c\u8b8a\u9ad4\u7684\u7a69\u5065\u6027\uff0c\u9019\u4e9b\u8b8a\u9ad4\u6e2c\u8a66\u4e86\u76f8\u540c\u7684\u62bd\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u53ef\u80fd\u8207\u9810\u8a13\u7df4\u8cc7\u6599\u4e2d\u7684\u4efb\u52d9\u4e0d\u540c\u3002\u4f7f\u7528\u7a69\u5065\u62bd\u8c61\u63a8\u7406\u7684\u7cfb\u7d71\uff0c\u5728\u9019\u4e9b\u8b8a\u9ad4\u4e0a\u7684\u8868\u73fe\u4e0d\u61c9\u5927\u5e45\u4e0b\u964d\u3002\n\u5728\u7c21\u55ae\u7684\u5b57\u6bcd\u4e32\u985e\u6bd4\u4e2d\uff0c\u6211\u5011\u767c\u73fe\u96d6\u7136\u4eba\u985e\u7684\u8868\u73fe\u5c0d\u65bc\u6211\u5011\u6e2c\u8a66\u7684\u5169\u7a2e\u8b8a\u9ad4\u985e\u578b\u4ecd\u7136\u5f88\u9ad8\uff0c\u4f46 GPT \u6a21\u578b\u7684\u8868\u73fe\u6025\u5287\u4e0b\u964d\u3002\u96a8\u8457\u9019\u4e9b\u554f\u984c\u7684\u8907\u96dc\u6027\u589e\u52a0\uff0c\u9019\u7a2e\u6a21\u5f0f\u4e0d\u592a\u660e\u986f\uff0c\u56e0\u70ba\u4eba\u985e\u548c GPT \u6a21\u578b\u5728\u9700\u8981\u66f4\u8907\u96dc\u985e\u6bd4\u7684\u539f\u59cb\u554f\u984c\u548c\u8b8a\u9ad4\u554f\u984c\u4e0a\u8868\u73fe\u90fd\u5f88\u5dee\u3002\u5728\u6578\u5b57\u77e9\u9663\u554f\u984c\u4e2d\uff0c\u6211\u5011\u767c\u73fe\u985e\u4f3c\u7684\u6a21\u5f0f\uff0c\u4f46\u50c5\u51fa\u73fe\u5728\u6211\u5011\u6e2c\u8a66\u7684\u5169\u7a2e\u8b8a\u9ad4\u985e\u578b\u4e2d\u7684\u4e00\u7a2e\u3002\u5728\u57fa\u65bc\u6545\u4e8b\u7684\u985e\u6bd4\u554f\u984c\u4e2d\uff0c\u6211\u5011\u767c\u73fe\u8207\u4eba\u985e\u4e0d\u540c\uff0cGPT \u6a21\u578b\u7684\u8868\u73fe\u5bb9\u6613\u53d7\u5230\u7b54\u6848\u9806\u5e8f\u6548\u61c9\u7684\u5f71\u97ff\uff0c\u800c\u4e14 GPT \u6a21\u578b\u4e5f\u53ef\u80fd\u6bd4\u4eba\u985e\u5c0d\u540c\u7fa9\u6539\u5beb\u66f4\u654f\u611f\u3002\n\u9019\u9805\u5de5\u4f5c\u63d0\u4f9b\u4e86\u8b49\u64da\uff0c\u8b49\u660e LLM \u901a\u5e38\u7f3a\u4e4f\u96f6\u6b21\u5b78\u7fd2\u4eba\u985e\u985e\u6bd4\u5efa\u69cb\u7684\u7a69\u5065\u6027\uff0c\u5728\u6211\u5011\u6e2c\u8a66\u7684\u5927\u591a\u6578\u8b8a\u9ad4\u4e0a\u8868\u73fe\u51fa\u8106\u5f31\u6027\u3002\u66f4\u4e00\u822c\u5730\u8aaa\uff0c\u9019\u9805\u5de5\u4f5c\u6307\u51fa\u5728\u6e2c\u8a66 AI \u7cfb\u7d71\u7684\u8a8d\u77e5\u80fd\u529b\u6642\uff0c\u4e0d\u50c5\u8981\u4ed4\u7d30\u8a55\u4f30\u5176\u6e96\u78ba\u6027\uff0c\u9084\u8981\u8a55\u4f30\u5176\u7a69\u5065\u6027\u7684\u91cd\u8981\u6027\u3002</paragraph>", "author": "Martha Lewis et.al.", "authors": "Martha Lewis, Melanie Mitchell", "id": "2411.14215v1", "paper_url": "http://arxiv.org/abs/2411.14215v1", "repo": "https://github.com/marthaflinderslewis/robust-analogy"}}