{"2409.03166": {"publish_time": "2024-09-05", "title": "Continual Skill and Task Learning via Dialogue", "paper_summary": "Continual and interactive robot learning is a challenging problem as the\nrobot is present with human users who expect the robot to learn novel skills to\nsolve novel tasks perpetually with sample efficiency. In this work we present a\nframework for robots to query and learn visuo-motor robot skills and task\nrelevant information via natural language dialog interactions with human users.\nPrevious approaches either focus on improving the performance of instruction\nfollowing agents, or passively learn novel skills or concepts. Instead, we used\ndialog combined with a language-skill grounding embedding to query or confirm\nskills and/or tasks requested by a user. To achieve this goal, we developed and\nintegrated three different components for our agent. Firstly, we propose a\nnovel visual-motor control policy ACT with Low Rank Adaptation (ACT-LoRA),\nwhich enables the existing SoTA ACT model to perform few-shot continual\nlearning. Secondly, we develop an alignment model that projects demonstrations\nacross skill embodiments into a shared embedding allowing us to know when to\nask questions and/or demonstrations from users. Finally, we integrated an\nexisting LLM to interact with a human user to perform grounded interactive\ncontinual skill learning to solve a task. Our ACT-LoRA model learns novel\nfine-tuned skills with a 100% accuracy when trained with only five\ndemonstrations for a novel skill while still maintaining a 74.75% accuracy on\npre-trained skills in the RLBench dataset where other models fall significantly\nshort. We also performed a human-subjects study with 8 subjects to demonstrate\nthe continual learning capabilities of our combined framework. We achieve a\nsuccess rate of 75% in the task of sandwich making with the real robot learning\nfrom participant data demonstrating that robots can learn novel skills or task\nknowledge from dialogue with non-expert users using our approach.", "paper_summary_zh": "\u6301\u7e8c\u4e14\u4e92\u52d5\u7684\u6a5f\u5668\u4eba\u5b78\u7fd2\u662f\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u7684\u554f\u984c\uff0c\u56e0\u70ba\u6a5f\u5668\u4eba\u8207\u4eba\u985e\u4f7f\u7528\u8005\u540c\u6642\u5b58\u5728\uff0c\u800c\u4eba\u985e\u4f7f\u7528\u8005\u671f\u671b\u6a5f\u5668\u4eba\u80fd\u5920\u5b78\u7fd2\u65b0\u6280\u80fd\uff0c\u4ee5\u6301\u7e8c\u89e3\u6c7a\u65b0\u4efb\u52d9\uff0c\u4e26\u5177\u6709\u7bc4\u4f8b\u6548\u7387\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u67b6\u69cb\uff0c\u8b93\u6a5f\u5668\u4eba\u900f\u904e\u8207\u4eba\u985e\u4f7f\u7528\u8005\u9032\u884c\u81ea\u7136\u8a9e\u8a00\u5c0d\u8a71\u4e92\u52d5\uff0c\u4f86\u67e5\u8a62\u548c\u5b78\u7fd2\u8996\u89ba\u904b\u52d5\u6a5f\u5668\u4eba\u6280\u80fd\u548c\u4efb\u52d9\u76f8\u95dc\u8cc7\u8a0a\u3002\u5148\u524d\u7684\u505a\u6cd5\u4e0d\u662f\u5c08\u6ce8\u65bc\u6539\u5584\u6307\u4ee4\u9075\u5faa\u4ee3\u7406\u4eba\u7684\u6548\u80fd\uff0c\u5c31\u662f\u88ab\u52d5\u5730\u5b78\u7fd2\u65b0\u6280\u80fd\u6216\u6982\u5ff5\u3002\u76f8\u53cd\u5730\uff0c\u6211\u5011\u4f7f\u7528\u5c0d\u8a71\u7d50\u5408\u8a9e\u8a00\u6280\u80fd\u57fa\u790e\u5d4c\u5165\uff0c\u4f86\u67e5\u8a62\u6216\u78ba\u8a8d\u4f7f\u7528\u8005\u8981\u6c42\u7684\u6280\u80fd\u548c/\u6216\u4efb\u52d9\u3002\u70ba\u4e86\u9054\u6210\u9019\u500b\u76ee\u6a19\uff0c\u6211\u5011\u70ba\u6211\u5011\u7684\u4ee3\u7406\u4eba\u958b\u767c\u4e26\u6574\u5408\u4e86\u4e09\u500b\u4e0d\u540c\u7684\u5143\u4ef6\u3002\u9996\u5148\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u8996\u89ba\u904b\u52d5\u63a7\u5236\u7b56\u7565 ACT\uff0c\u5177\u6709\u4f4e\u79e9\u9069\u61c9 (ACT-LoRA)\uff0c\u9019\u8b93\u73fe\u6709\u7684 SoTA ACT \u6a21\u578b\u80fd\u5920\u57f7\u884c\u5c0f\u6a23\u672c\u6301\u7e8c\u5b78\u7fd2\u3002\u5176\u6b21\uff0c\u6211\u5011\u958b\u767c\u4e00\u500b\u6bd4\u5c0d\u6a21\u578b\uff0c\u5c07\u4e0d\u540c\u6280\u80fd\u5177\u9ad4\u5be6\u4f8b\u4e2d\u7684\u793a\u7bc4\u6295\u5c04\u5230\u4e00\u500b\u5171\u7528\u5d4c\u5165\u4e2d\uff0c\u8b93\u6211\u5011\u77e5\u9053\u4f55\u6642\u5411\u4f7f\u7528\u8005\u8a62\u554f\u554f\u984c\u548c/\u6216\u793a\u7bc4\u3002\u6700\u5f8c\uff0c\u6211\u5011\u6574\u5408\u4e86\u4e00\u500b\u73fe\u6709\u7684 LLM\uff0c\u8207\u4eba\u985e\u4f7f\u7528\u8005\u4e92\u52d5\uff0c\u4ee5\u57f7\u884c\u57fa\u790e\u4e92\u52d5\u5f0f\u6301\u7e8c\u6280\u80fd\u5b78\u7fd2\uff0c\u4f86\u89e3\u6c7a\u4e00\u500b\u4efb\u52d9\u3002\u6211\u5011\u7684 ACT-LoRA \u6a21\u578b\u5728\u50c5\u4f7f\u7528\u4e94\u500b\u793a\u7bc4\u8a13\u7df4\u65b0\u6280\u80fd\u6642\uff0c\u5c31\u80fd\u5b78\u7fd2\u5230\u65b0\u7684\u5fae\u8abf\u6280\u80fd\uff0c\u6e96\u78ba\u7387\u9054\u5230 100%\uff0c\u540c\u6642\u5728 RLBench \u8cc7\u6599\u96c6\u4e2d\u9810\u5148\u8a13\u7df4\u7684\u6280\u80fd\u4e0a\u4ecd\u80fd\u7dad\u6301 74.75% \u7684\u6e96\u78ba\u7387\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u7684\u6e96\u78ba\u7387\u5247\u5927\u5e45\u4e0b\u964d\u3002\u6211\u5011\u9084\u9032\u884c\u4e86\u4e00\u9805\u5305\u542b 8 \u4f4d\u53d7\u8a66\u8005\u7684\u771f\u4eba\u7814\u7a76\uff0c\u4ee5\u5c55\u793a\u6211\u5011\u9019\u500b\u7d50\u5408\u6846\u67b6\u7684\u6301\u7e8c\u5b78\u7fd2\u80fd\u529b\u3002\u6211\u5011\u5728\u4e09\u660e\u6cbb\u88fd\u4f5c\u4efb\u52d9\u4e2d\u9054\u5230 75% \u7684\u6210\u529f\u7387\uff0c\u771f\u5be6\u6a5f\u5668\u4eba\u5f9e\u53c3\u8207\u8005\u7684\u8cc7\u6599\u4e2d\u5b78\u7fd2\uff0c\u8b49\u660e\u4e86\u6a5f\u5668\u4eba\u53ef\u4ee5\u4f7f\u7528\u6211\u5011\u7684\u65b9\u6cd5\uff0c\u5f9e\u975e\u5c08\u5bb6\u4f7f\u7528\u8005\u7684\u5c0d\u8a71\u4e2d\u5b78\u7fd2\u65b0\u7684\u6280\u80fd\u6216\u4efb\u52d9\u77e5\u8b58\u3002", "author": "Weiwei Gu et.al.", "authors": "Weiwei Gu, Suresh Kondepudi, Lixiao Huang, Nakul Gopalan", "id": "2409.03166v1", "paper_url": "http://arxiv.org/abs/2409.03166v1", "repo": "null"}}