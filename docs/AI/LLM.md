
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-10**|**LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts**|Anh-Quan Cao et.al.|[2410.08211v1](http://arxiv.org/abs/2410.08211v1)|null|
|**2024-10-10**|**PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection**|Botao Ren et.al.|[2410.08210v1](http://arxiv.org/abs/2410.08210v1)|null|
|**2024-10-10**|**Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision**|Shengcao Cao et.al.|[2410.08209v1](http://arxiv.org/abs/2410.08209v1)|null|
|**2024-10-10**|**SPA: 3D Spatial-Awareness Enables Effective Embodied Representation**|Haoyi Zhu et.al.|[2410.08208v1](http://arxiv.org/abs/2410.08208v1)|null|
|**2024-10-10**|**Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training**|Gen Luo et.al.|[2410.08202v1](http://arxiv.org/abs/2410.08202v1)|null|
|**2024-10-10**|**From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions**|Changle Qu et.al.|[2410.08197v1](http://arxiv.org/abs/2410.08197v1)|null|
|**2024-10-10**|**MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code**|Zimu Lu et.al.|[2410.08196v1](http://arxiv.org/abs/2410.08196v1)|[link](https://github.com/mathllm/mathcoder2)|
|**2024-10-10**|**GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment**|Yuancheng Xu et.al.|[2410.08193v1](http://arxiv.org/abs/2410.08193v1)|null|
|**2024-10-10**|**DifFRelight: Diffusion-Based Facial Performance Relighting**|Mingming He et.al.|[2410.08188v1](http://arxiv.org/abs/2410.08188v1)|null|
|**2024-10-10**|**MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models**|Wenbo Hu et.al.|[2410.08182v1](http://arxiv.org/abs/2410.08182v1)|null|
|**2024-10-10**|**Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models**|Qingni Wang et.al.|[2410.08174v1](http://arxiv.org/abs/2410.08174v1)|null|
|**2024-10-10**|**On the Evaluation of Generative Robotic Simulations**|Feng Chen et.al.|[2410.08172v1](http://arxiv.org/abs/2410.08172v1)|null|
|**2024-10-10**|**Agent S: An Open Agentic Framework that Uses Computers Like a Human**|Saaket Agashe et.al.|[2410.08164v1](http://arxiv.org/abs/2410.08164v1)|[link](https://github.com/simular-ai/agent-s)|
|**2024-10-10**|**The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading**|Keren Gruteke Klein et.al.|[2410.08162v1](http://arxiv.org/abs/2410.08162v1)|null|
|**2024-10-10**|**Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning**|Amrith Setlur et.al.|[2410.08146v1](http://arxiv.org/abs/2410.08146v1)|null|
|**2024-10-10**|**Insight Over Sight? Exploring the Vision-Knowledge Conflicts in Multimodal LLMs**|Xiaoyuan Liu et.al.|[2410.08145v1](http://arxiv.org/abs/2410.08145v1)|null|
|**2024-10-10**|**DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory**|Yutong Wang et.al.|[2410.08143v1](http://arxiv.org/abs/2410.08143v1)|[link](https://github.com/yutongwang1216/docmtagent)|
|**2024-10-10**|**Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction**|Jarrid Rector-Brooks et.al.|[2410.08134v1](http://arxiv.org/abs/2410.08134v1)|null|
|**2024-10-10**|**Assessing Episodic Memory in LLMs with Sequence Order Recall Tasks**|Mathis Pink et.al.|[2410.08133v1](http://arxiv.org/abs/2410.08133v1)|null|
|**2024-10-10**|**Think Beyond Size: Dynamic Prompting for More Effective Reasoning**|Kamesh R et.al.|[2410.08130v1](http://arxiv.org/abs/2410.08130v1)|null|
|**2024-10-10**|**Mars: Situated Inductive Reasoning in an Open-World Environment**|Xiaojuan Tang et.al.|[2410.08126v1](http://arxiv.org/abs/2410.08126v1)|null|
|**2024-10-10**|**Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection**|Moirangthem Tiken Singh et.al.|[2410.08121v1](http://arxiv.org/abs/2410.08121v1)|null|
|**2024-10-10**|**Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System**|Weize Chen et.al.|[2410.08115v1](http://arxiv.org/abs/2410.08115v1)|null|
|**2024-10-10**|**Robust AI-Generated Text Detection by Restricted Embeddings**|Kristian Kuznetsov et.al.|[2410.08113v1](http://arxiv.org/abs/2410.08113v1)|null|
|**2024-10-10**|**Active Fourier Auditor for Estimating Distributional Properties of ML Models**|Ayoub Ajarra et.al.|[2410.08111v1](http://arxiv.org/abs/2410.08111v1)|null|
|**2024-10-10**|**A Closer Look at Machine Unlearning for Large Language Models**|Xiaojian Yuan et.al.|[2410.08109v1](http://arxiv.org/abs/2410.08109v1)|[link](https://github.com/sail-sg/closer-look-llm-unlearning)|
|**2024-10-10**|**What Makes Large Language Models Reason in (Multi-Turn) Code Generation?**|Kunhao Zheng et.al.|[2410.08105v1](http://arxiv.org/abs/2410.08105v1)|null|
|**2024-10-10**|**Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining**|Tianyi Bai et.al.|[2410.08102v1](http://arxiv.org/abs/2410.08102v1)|null|
|**2024-10-10**|**A Generative AI Technique for Synthesizing a Digital Twin for U.S. Residential Solar Adoption and Generation**|Aparna Kishore et.al.|[2410.08098v1](http://arxiv.org/abs/2410.08098v1)|null|
|**2024-10-10**|**Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**|Yuan Sui et.al.|[2410.08085v1](http://arxiv.org/abs/2410.08085v1)|null|
|**2024-10-10**|**Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning**|Shuhe Wang et.al.|[2410.08081v1](http://arxiv.org/abs/2410.08081v1)|[link](https://github.com/shuhewang1998/packing-analysis)|
|**2024-10-10**|**Unlearning-based Neural Interpretations**|Ching Lam Choi et.al.|[2410.08069v1](http://arxiv.org/abs/2410.08069v1)|null|
|**2024-10-10**|**Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models**|Wenting Tan et.al.|[2410.08068v1](http://arxiv.org/abs/2410.08068v1)|[link](https://github.com/sallytan13/teaching-inspired-prompting)|
|**2024-10-10**|**Reward-Augmented Data Enhances Direct Preference Alignment of LLMs**|Shenao Zhang et.al.|[2410.08067v1](http://arxiv.org/abs/2410.08067v1)|[link](https://github.com/shenao-zhang/reward-augmented-preference)|
|**2024-10-10**|**Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions**|Inderjeet Nair et.al.|[2410.08058v1](http://arxiv.org/abs/2410.08058v1)|null|
|**2024-10-10**|**A Target-Aware Analysis of Data Augmentation for Hate Speech Detection**|Camilla Casula et.al.|[2410.08053v1](http://arxiv.org/abs/2410.08053v1)|null|
|**2024-10-10**|**VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers**|Jianing Qi et.al.|[2410.08048v1](http://arxiv.org/abs/2410.08048v1)|null|
|**2024-10-10**|**Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations**|Yiyuan Zhang et.al.|[2410.08049v1](http://arxiv.org/abs/2410.08049v1)|[link](https://github.com/ailab-cvc/unireplknet)|
|**2024-10-10**|**Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning**|Hyun Ryu et.al.|[2410.08047v1](http://arxiv.org/abs/2410.08047v1)|null|
|**2024-10-10**|**The Rise of AI-Generated Content in Wikipedia**|Creston Brooks et.al.|[2410.08044v1](http://arxiv.org/abs/2410.08044v1)|null|
|**2024-10-10**|**Strategic Classification With Externalities**|Yiling Chen et.al.|[2410.08032v1](http://arxiv.org/abs/2410.08032v1)|null|
|**2024-10-10**|**Private Language Models via Truncated Laplacian Mechanism**|Tianhao Huang et.al.|[2410.08027v1](http://arxiv.org/abs/2410.08027v1)|null|
|**2024-10-10**|**The Computational Complexity of Circuit Discovery for Inner Interpretability**|Federico Adolfi et.al.|[2410.08025v1](http://arxiv.org/abs/2410.08025v1)|null|
|**2024-10-10**|**Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling**|Alessio Fallani et.al.|[2410.08024v1](http://arxiv.org/abs/2410.08024v1)|null|
|**2024-10-10**|**GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder**|Junzhou Chen et.al.|[2410.08023v1](http://arxiv.org/abs/2410.08023v1)|null|
|**2024-10-10**|**Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs**|Jonas HÃ¼botter et.al.|[2410.08020v1](http://arxiv.org/abs/2410.08020v1)|null|
|**2024-10-10**|**LLM Cascade with Multi-Objective Optimal Consideration**|Kai Zhang et.al.|[2410.08014v1](http://arxiv.org/abs/2410.08014v1)|null|
|**2024-10-10**|**Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation**|Qingwen Bu et.al.|[2410.08001v1](http://arxiv.org/abs/2410.08001v1)|null|
|**2024-10-10**|**Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets**|Tommaso Giorgi et.al.|[2410.07991v1](http://arxiv.org/abs/2410.07991v1)|null|
|**2024-10-10**|**Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models**|Bofei Gao et.al.|[2410.07985v1](http://arxiv.org/abs/2410.07985v1)|null|
|**2024-10-10**|**MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning**|Andrei Manolache et.al.|[2410.07981v1](http://arxiv.org/abs/2410.07981v1)|null|
|**2024-10-10**|**Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling**|Yuanqi Du et.al.|[2410.07974v1](http://arxiv.org/abs/2410.07974v1)|null|
|**2024-10-10**|**Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation**|Tomas Bueno Momcilovic et.al.|[2410.07962v1](http://arxiv.org/abs/2410.07962v1)|null|
|**2024-10-10**|**COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act**|Philipp Guldimann et.al.|[2410.07959v1](http://arxiv.org/abs/2410.07959v1)|null|
|**2024-10-10**|**Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**|Kuleen Sasse et.al.|[2410.07951v1](http://arxiv.org/abs/2410.07951v1)|null|
|**2024-10-10**|**The Function-Representation Unification Framework**|Alfredo Ibias et.al.|[2410.07928v1](http://arxiv.org/abs/2410.07928v1)|null|
|**2024-10-10**|**InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions**|Xiang Zhuang et.al.|[2410.07919v1](http://arxiv.org/abs/2410.07919v1)|null|
|**2024-10-10**|**ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**|LÃ©o Machado et.al.|[2410.07908v1](http://arxiv.org/abs/2410.07908v1)|null|
|**2024-10-10**|**Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines**|Junyu Lai et.al.|[2410.07896v1](http://arxiv.org/abs/2410.07896v1)|null|
|**2024-10-10**|**Unsupervised Data Validation Methods for Efficient Model Training**|Yurii Paniv et.al.|[2410.07880v1](http://arxiv.org/abs/2410.07880v1)|null|
|**2024-10-10**|**Benchmarking Agentic Workflow Generation**|Shuofei Qiao et.al.|[2410.07869v1](http://arxiv.org/abs/2410.07869v1)|null|
|**2024-10-10**|**System-2 Reasoning via Generality and Adaptation**|Sejin Kim et.al.|[2410.07866v1](http://arxiv.org/abs/2410.07866v1)|null|
|**2024-10-10**|**RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation**|Songming Liu et.al.|[2410.07864v1](http://arxiv.org/abs/2410.07864v1)|null|
|**2024-10-10**|**From Logits to Hierarchies: Hierarchical Clustering made Simple**|Emanuele Palumbo et.al.|[2410.07858v1](http://arxiv.org/abs/2410.07858v1)|null|
|**2024-10-10**|**Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency**|Tim Knappe et.al.|[2410.07839v1](http://arxiv.org/abs/2410.07839v1)|null|
|**2024-10-10**|**MinorityPrompt: Text to Minority Image Generation via Prompt Optimization**|Soobin Um et.al.|[2410.07838v1](http://arxiv.org/abs/2410.07838v1)|null|
|**2024-10-10**|**Masked Generative Priors Improve World Models Sequence Modelling Capabilities**|Cristian Meo et.al.|[2410.07836v1](http://arxiv.org/abs/2410.07836v1)|null|
|**2024-10-10**|**NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models**|William Tan et.al.|[2410.07830v1](http://arxiv.org/abs/2410.07830v1)|null|
|**2024-10-10**|**Why do objects have many names? A study on word informativeness in language use and lexical systems**|Eleonora Gualdoni et.al.|[2410.07827v1](http://arxiv.org/abs/2410.07827v1)|null|
|**2024-10-10**|**Fine-Tuning Language Models for Ethical Ambiguity: A Comparative Study of Alignment with Human Responses**|Pranav Senthilkumar et.al.|[2410.07826v1](http://arxiv.org/abs/2410.07826v1)|null|
|**2024-10-10**|**Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models**|Zhipeng Chen et.al.|[2410.07825v1](http://arxiv.org/abs/2410.07825v1)|null|
|**2024-10-10**|**Mitigating Gender Bias in Code Large Language Models via Model Editing**|Zhanyue Qin et.al.|[2410.07820v1](http://arxiv.org/abs/2410.07820v1)|null|
|**2024-10-10**|**Uncovering Overfitting in Large Language Model Editing**|Mengqi Zhang et.al.|[2410.07819v1](http://arxiv.org/abs/2410.07819v1)|null|
|**2024-10-10**|**Temporal-Difference Variational Continual Learning**|Luckeciano C. Melo et.al.|[2410.07812v1](http://arxiv.org/abs/2410.07812v1)|null|
|**2024-10-10**|**Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?**|GÃ¼rkan Soykan et.al.|[2410.07809v1](http://arxiv.org/abs/2410.07809v1)|[link](https://github.com/gglab-ku/ling-informed-mit)|
|**2024-10-10**|**Rewriting Conversational Utterances with Instructed Large Language Models**|Elnara Galimzhanova et.al.|[2410.07797v1](http://arxiv.org/abs/2410.07797v1)|null|
|**2024-10-10**|**Do Current Language Models Support Code Intelligence for R Programming Language?**|ZiXiao Zhao et.al.|[2410.07793v1](http://arxiv.org/abs/2410.07793v1)|null|
|**2024-10-10**|**Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation**|Sweta Agrawal et.al.|[2410.07779v1](http://arxiv.org/abs/2410.07779v1)|null|
|**2024-10-10**|**Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models**|Adriana Fernandez-Lopez et.al.|[2410.07771v1](http://arxiv.org/abs/2410.07771v1)|null|
|**2024-10-10**|**Dialectical Behavior Therapy Approach to LLM Prompting**|Oxana Vitman et.al.|[2410.07768v1](http://arxiv.org/abs/2410.07768v1)|null|
|**2024-10-10**|**GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps**|Muhammad Umair Nasir et.al.|[2410.07765v1](http://arxiv.org/abs/2410.07765v1)|[link](https://github.com/umair-nasir14/game-traversal-benchmark)|
|**2024-10-10**|**HARIVO: Harnessing Text-to-Image Models for Video Generation**|Mingi Kwon et.al.|[2410.07763v1](http://arxiv.org/abs/2410.07763v1)|null|
|**2024-10-10**|**$\textit{Jump Your Steps}$: Optimizing Sampling Schedule of Discrete Diffusion Models**|Yong-Hyun Park et.al.|[2410.07761v1](http://arxiv.org/abs/2410.07761v1)|null|
|**2024-10-10**|**Learning Low-Level Causal Relations using a Simulated Robotic Arm**|Miroslav Cibula et.al.|[2410.07751v1](http://arxiv.org/abs/2410.07751v1)|null|
|**2024-10-10**|**StepTool: A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs**|Yuanqing Yu et.al.|[2410.07745v1](http://arxiv.org/abs/2410.07745v1)|[link](https://github.com/yuyq18/steptool)|
|**2024-10-10**|**SLIM: Let LLM Learn More and Forget Less with Soft LoRA and Identity Mixture**|Jiayi Han et.al.|[2410.07739v1](http://arxiv.org/abs/2410.07739v1)|null|
|**2024-10-10**|**Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning**|Jingyuan Zhang et.al.|[2410.07738v1](http://arxiv.org/abs/2410.07738v1)|null|
|**2024-10-10**|**On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models**|Gabriel Jarry et.al.|[2410.07717v1](http://arxiv.org/abs/2410.07717v1)|null|
|**2024-10-10**|**Learning Tree Pattern Transformations**|Daniel Neider et.al.|[2410.07708v1](http://arxiv.org/abs/2410.07708v1)|null|
|**2024-10-10**|**AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories**|Yifan Song et.al.|[2410.07706v1](http://arxiv.org/abs/2410.07706v1)|null|
|**2024-10-10**|**Multi-Facet Counterfactual Learning for Content Quality Evaluation**|Jiasheng Zheng et.al.|[2410.07693v1](http://arxiv.org/abs/2410.07693v1)|null|
|**2024-10-10**|**Smart Audit System Empowered by LLM**|Xu Yao et.al.|[2410.07677v1](http://arxiv.org/abs/2410.07677v1)|null|
|**2024-10-10**|**Adversarial Robustness Overestimation and Instability in TRADES**|Jonathan Weiping Li et.al.|[2410.07675v1](http://arxiv.org/abs/2410.07675v1)|null|
|**2024-10-10**|**Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference**|Jianxing Yu et.al.|[2410.07673v1](http://arxiv.org/abs/2410.07673v1)|null|
|**2024-10-10**|**MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization**|Yougang Lyu et.al.|[2410.07672v1](http://arxiv.org/abs/2410.07672v1)|null|
|**2024-10-10**|**DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation**|Xiaoshan Yu et.al.|[2410.07671v1](http://arxiv.org/abs/2410.07671v1)|null|
|**2024-10-10**|**StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models**|Minchan Kwon et.al.|[2410.07652v1](http://arxiv.org/abs/2410.07652v1)|null|
|**2024-10-10**|**Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits**|Yunlong Hou et.al.|[2410.07638v1](http://arxiv.org/abs/2410.07638v1)|null|
|**2024-10-10**|**Automatic Curriculum Expert Iteration for Reliable LLM Reasoning**|Zirui Zhao et.al.|[2410.07627v1](http://arxiv.org/abs/2410.07627v1)|null|
|**2024-10-10**|**Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation**|Kaiyuan Liu et.al.|[2410.07618v1](http://arxiv.org/abs/2410.07618v1)|null|

#### Abstracts
##### **LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts**
2410.08211v1 by Anh-Quan Cao, Maximilian Jaritz, Matthieu Guillaumin, Raoul de Charette, Loris Bazzani

Large-scale vision-language pre-trained (VLP) models (e.g., CLIP) are
renowned for their versatility, as they can be applied to diverse applications
in a zero-shot setup. However, when these models are used in specific domains,
their performance often falls short due to domain gaps or the
under-representation of these domains in the training data. While fine-tuning
VLP models on custom datasets with human-annotated labels can address this
issue, annotating even a small-scale dataset (e.g., 100k samples) can be an
expensive endeavor, often requiring expert annotators if the task is complex.
To address these challenges, we propose LatteCLIP, an unsupervised method for
fine-tuning CLIP models on classification with known class names in custom
domains, without relying on human annotations. Our method leverages Large
Multimodal Models (LMMs) to generate expressive textual descriptions for both
individual images and groups of images. These provide additional contextual
information to guide the fine-tuning process in the custom domains. Since
LMM-generated descriptions are prone to hallucination or missing details, we
introduce a novel strategy to distill only the useful information and stabilize
the training. Specifically, we learn rich per-class prototype representations
from noisy generated texts and dual pseudo-labels. Our experiments on 10
domain-specific datasets show that LatteCLIP outperforms pre-trained zero-shot
methods by an average improvement of +4.74 points in top-1 accuracy and other
state-of-the-art unsupervised methods by +3.45 points.

æè¦ï¼å¤§åè¦è¦ºèªè¨é è¨ç·´ (VLP) æ¨¡å (ä¾å¦ CLIP) ä»¥å¶å¤åè½æ§èèåï¼å çºå®åå¯ä»¥ç¨æ¼åç¨®æç¨ç¨å¼ä¸­ï¼èç¡éé²è¡ä»»ä½è¨­å®ãç¶èï¼ç¶éäºæ¨¡åç¨æ¼ç¹å®é åæï¼å®åçæè½éå¸¸æå é åå·®è·æè¨ç·´è³æä¸­éäºé åçä»£è¡¨æ§ä¸è¶³èä¸éãéç¶å¨å·æäººå·¥æ¨è¨æ¨ç±¤çå®¢è£½åè³æéä¸å¾®èª¿ VLP æ¨¡åå¯ä»¥è§£æ±ºéååé¡ï¼ä½å³ä½¿æ¯æ¨è¨å°è¦æ¨¡è³æé (ä¾å¦ 100k åæ¨£æ¬) ä¹å¯è½æ¯ä¸é æè²´çå·¥ä½ï¼å¦æä»»åå¾è¤éï¼éå¸¸éè¦å°å®¶æ¨è¨å¡ãçºäºæå°éäºææ°ï¼æåæåºäº LatteCLIPï¼éæ¯ä¸ç¨®ç¡ç£ç£æ¹æ³ï¼ç¨æ¼å¨å®¢è£½åé åä¸­å° CLIP æ¨¡åé²è¡å¾®èª¿ï¼ä»¥å°å·²ç¥çé¡å¥åç¨±é²è¡åé¡ï¼èä¸éè¦ä¾è³´äººå·¥æ¨è¨ãæåçæ¨¡åå©ç¨å¤§åå¤æ¨¡ææ¨¡å (LMM) çºåå¥å½±ååå½±åç¾¤çµç¢çå·è¡¨ç¾åçæå­æè¿°ãéäºæè¿°æä¾äºé¡å¤çèçµ¡è³è¨ï¼ä»¥æå°å®¢è£½åé åä¸­çå¾®èª¿éç¨ãç±æ¼ LMM çæçæè¿°å®¹æåºç¾å¹»è¦ºæéºæ¼ç´°ç¯ï¼å æ­¤æåå¼å¥äºä¸ç¨®æ°ç­ç¥ï¼åæåæç¨çè³è¨ä¸¦ç©©å®è¨ç·´ãå·é«ä¾èªªï¼æåå¾éè¨ç¢ççæå­åééå½æ¨ç±¤ä¸­å­¸ç¿è±å¯çæ¯åé¡å¥ååè¡¨ç¤ºãæåå¨ 10 åç¹å®é åçè³æéä¸é²è¡çå¯¦é©è¡¨æï¼LatteCLIP å¨å 1 åæºç¢ºçä¸æ¯é åè¨ç·´çé¶æ¬¡å­¸ç¿æ¹æ³å¹³åæé«äº +4.74 åç¾åé»ï¼æ¯å¶ä»æåé²çç¡ç£ç£æ¹æ³æé«äº +3.45 åç¾åé»ã

##### **PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection**
2410.08210v1 by Botao Ren, Xue Yang, Yi Yu, Junwei Luo, Zhidong Deng

Single point supervised oriented object detection has gained attention and
made initial progress within the community. Diverse from those approaches
relying on one-shot samples or powerful pretrained models (e.g. SAM), PointOBB
has shown promise due to its prior-free feature. In this paper, we propose
PointOBB-v2, a simpler, faster, and stronger method to generate pseudo rotated
boxes from points without relying on any other prior. Specifically, we first
generate a Class Probability Map (CPM) by training the network with non-uniform
positive and negative sampling. We show that the CPM is able to learn the
approximate object regions and their contours. Then, Principal Component
Analysis (PCA) is applied to accurately estimate the orientation and the
boundary of objects. By further incorporating a separation mechanism, we
resolve the confusion caused by the overlapping on the CPM, enabling its
operation in high-density scenarios. Extensive comparisons demonstrate that our
method achieves a training speed 15.58x faster and an accuracy improvement of
11.60%/25.15%/21.19% on the DOTA-v1.0/v1.5/v2.0 datasets compared to the
previous state-of-the-art, PointOBB. This significantly advances the cutting
edge of single point supervised oriented detection in the modular track.

æè¦ï¼å®é»ç£ç£å°åçç®æ¨åµæ¸¬å·²ç²å¾éæ³¨ï¼ä¸¦å¨ç¤¾ç¾¤ä¸­åå¾åæ­¥é²å±ãä¸åæ¼ä¾è³´å®æ¬¡æ¨£æ¬æå¼·å¤§é è¨ç·´æ¨¡åï¼ä¾å¦ SAMï¼çé£äºæ¹æ³ï¼PointOBB ç±æ¼å¶ç¡åé©ç¹å¾µèé¡¯ç¤ºåºåæ¯ãå¨æ¬æä¸­ï¼æåæåº PointOBB-v2ï¼éæ¯ä¸ç¨®æ´ç°¡å®ãæ´å¿«éä¸æ´å¼·å¤§çæ¹æ³ï¼ç¨æ¼å¨ä¸ä¾è³´ä»»ä½å¶ä»åé©çææ³ä¸å¾é»çæå½æè½æ¡ãå·é«ä¾èªªï¼æåé¦åééä½¿ç¨éåå»æ­£è² åæ¨£ä¾è¨ç·´ç¶²è·¯ï¼ä¾çæé¡å¥æ©çå (CPM)ãæåè¡¨æ CPM è½å¤ å­¸ç¿è¿ä¼¼çç©ä»¶åååå¶è¼ªå»ãç¶å¾ï¼æç¨ä¸»æååæ (PCA) ä¾æºç¢ºä¼°è¨ç©é«çæ¹ååéçãééé²ä¸æ­¥ç´å¥åé¢æ©å¶ï¼æåè§£æ±ºäº CPM ä¸éçæé æçæ··æ·ï¼ä½¿å¶è½å¤ å¨é«å¯åº¦å ´æ¯ä¸­æä½ãå»£æ³çæ¯è¼è¡¨æï¼èååçæè¡ PointOBB ç¸æ¯ï¼æåçæ¨¡åå¨ DOTA-v1.0/v1.5/v2.0 è³æéä¸å¯¦ç¾äºå¿« 15.58 åçè¨ç·´éåº¦ï¼ä»¥å 11.60%/25.15%/21.19% çæºç¢ºåº¦æåãéé¡¯èæåäºæ¨¡çµåè»éä¸­å®é»ç£ç£å°ååµæ¸¬çå°ç«¯æè¡ã

##### **Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision**
2410.08209v1 by Shengcao Cao, Liang-Yan Gui, Yu-Xiong Wang

Current large multimodal models (LMMs) face challenges in grounding, which
requires the model to relate language components to visual entities. Contrary
to the common practice that fine-tunes LMMs with additional grounding
supervision, we find that the grounding ability can in fact emerge in LMMs
trained without explicit grounding supervision. To reveal this emerging
grounding, we introduce an "attend-and-segment" method which leverages
attention maps from standard LMMs to perform pixel-level segmentation.
Furthermore, to enhance the grounding ability, we propose DIFFLMM, an LMM
utilizing a diffusion-based visual encoder, as opposed to the standard CLIP
visual encoder, and trained with the same weak supervision. Without being
constrained by the biases and limited scale of grounding-specific supervision
data, our approach is more generalizable and scalable. We achieve competitive
performance on both grounding-specific and general visual question answering
benchmarks, compared with grounding LMMs and generalist LMMs, respectively.
Notably, we achieve a 44.2 grounding mask recall on grounded conversation
generation without any grounding supervision, outperforming the extensively
supervised model GLaMM. Project page: https://groundLMM.github.io.

æè¦ï¼ç®åçå¤§åå¤æ¨¡ææ¨¡å (LMM) é¢è¨èåºç¤åé¡ï¼ééè¦æ¨¡åå°èªè¨çµæé¨åèè¦è¦ºå¯¦é«éè¯èµ·ä¾ãèä½¿ç¨é¡å¤çåºç¤ç£ç£å¾®èª¿ LMM çå¸¸è¦åæ³ç¸åï¼æåç¼ç¾åºç¤è½åå¯¦éä¸å¯ä»¥å¨æ²ææç¢ºåºç¤ç£ç£çææ³ä¸è¨ç·´ç LMM ä¸­åºç¾ãçºäºæ­ç¤ºéç¨®æ°èçåºç¤ï¼æåå¼å¥äºä¸åãéæ³¨ä¸¦åå²ãæ¹æ³ï¼è©²æ¹æ³å©ç¨æ¨æº LMM çæ³¨æååä¾å·è¡åç´ ç´åå²ãæ­¤å¤ï¼çºäºå¢å¼·åºç¤è½åï¼æåæåºäº DIFFLMMï¼éæ¯ä¸ç¨® LMMï¼å®ä½¿ç¨åºæ¼æ´æ£çè¦è¦ºç·¨ç¢¼å¨ï¼èä¸æ¯æ¨æº CLIP è¦è¦ºç·¨ç¢¼å¨ï¼ä¸¦ä½¿ç¨ç¸åçå¼±ç£ç£é²è¡è¨ç·´ãå¨ä¸ååºç¤ç¹å®ç£ç£æ¸æçåå·®åæéè¦æ¨¡çç´æä¸ï¼æåçåæ³æ´å·éç¨æ§åå¯æ´å±æ§ãèåºç¤ LMM åéæ LMM ç¸æ¯ï¼æåå¨åºç¤ç¹å®åä¸è¬è¦è¦ºåé¡è§£ç­åºæºä¸å¯¦ç¾äºç«¶ç­åãå¼å¾æ³¨æçæ¯ï¼æåå¨æ²æä»»ä½åºç¤ç£ç£çææ³ä¸ï¼å°åºç¤å°è©±çæå¯¦ç¾äº 44.2 çåºç¤é®ç½©å¬åçï¼åªæ¼å»£æ³ç£ç£çæ¨¡å GLaMMãå°æ¡é é¢ï¼https://groundLMM.github.ioã

##### **SPA: 3D Spatial-Awareness Enables Effective Embodied Representation**
2410.08208v1 by Haoyi Zhu, Honghui Yang, Yating Wang, Jiange Yang, Limin Wang, Tong He

In this paper, we introduce SPA, a novel representation learning framework
that emphasizes the importance of 3D spatial awareness in embodied AI. Our
approach leverages differentiable neural rendering on multi-view images to
endow a vanilla Vision Transformer (ViT) with intrinsic spatial understanding.
We present the most comprehensive evaluation of embodied representation
learning to date, covering 268 tasks across 8 simulators with diverse policies
in both single-task and language-conditioned multi-task scenarios. The results
are compelling: SPA consistently outperforms more than 10 state-of-the-art
representation methods, including those specifically designed for embodied AI,
vision-centric tasks, and multi-modal applications, while using less training
data. Furthermore, we conduct a series of real-world experiments to confirm its
effectiveness in practical scenarios. These results highlight the critical role
of 3D spatial awareness for embodied representation learning. Our strongest
model takes more than 6000 GPU hours to train and we are committed to
open-sourcing all code and model weights to foster future research in embodied
representation learning. Project Page: https://haoyizhu.github.io/spa/.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹ SPAï¼ä¸ç¨®æ°ç©çè¡¨å¾µå­¸ç¿æ¡æ¶ï¼å¼·èª¿äº 3D ç©ºéæç¥å¨å·èº« AI ä¸­çéè¦æ§ãæåçåæ³å©ç¨å¤è¦åå½±åä¸çå¯å¾®åç¥ç¶æ¸²æï¼è³¦äº vanilla è¦è¦º Transformer (ViT) å§å¨çç©ºéçè§£ãæåå±ç¤ºäºè¿ä»çºæ­¢æå¨é¢çå·èº«è¡¨å¾µå­¸ç¿è©ä¼°ï¼æ¶µèäº 8 åæ¨¡æ¬å¨ä¸­ç 268 åä»»åï¼å¨å®ä¸ä»»ååèªè¨æ¢ä»¶çå¤ä»»åå ´æ¯ä¸­æ¡ç¨ä¸åçç­ç¥ãçµæä»¤äººä¿¡æï¼SPA æçºåªæ¼ 10 ç¨®ä»¥ä¸çææ°è¡¨å¾µæ¹æ³ï¼åæ¬å°éçºå·èº« AIãä»¥è¦è¦ºçºä¸­å¿çä»»ååå¤æ¨¡ææç¨ç¨å¼è¨­è¨çæ¹æ³ï¼åæä½¿ç¨è¼å°çè¨ç·´è³æãæ­¤å¤ï¼æåé²è¡äºä¸ç³»åçå¯¦ä¸ççå¯¦é©ï¼ä»¥ç¢ºèªå¶å¨å¯¦éå ´æ¯ä¸­çæææ§ãéäºçµæçªåºäº 3D ç©ºéæç¥å°æ¼å·èº«è¡¨å¾µå­¸ç¿çééµä½ç¨ãæåæå¼·å¤§çæ¨¡åéè¦è¶é 6000 å GPU å°ææè½è¨ç·´ï¼æåè´åæ¼éæ¾åå§ç¢¼åæææ¨¡åæ¬éï¼ä»¥ä¿é²å·èº«è¡¨å¾µå­¸ç¿çæªä¾ç ç©¶ãå°æ¡é é¢ï¼https://haoyizhu.github.io/spa/ã</paragraph>

##### **Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training**
2410.08202v1 by Gen Luo, Xue Yang, Wenhan Dou, Zhaokai Wang, Jifeng Dai, Yu Qiao, Xizhou Zhu

The rapid advancement of Large Language Models (LLMs) has led to an influx of
efforts to extend their capabilities to multimodal tasks. Among them, growing
attention has been focused on monolithic Multimodal Large Language Models
(MLLMs) that integrate visual encoding and language decoding into a single LLM.
Despite the structural simplicity and deployment-friendliness, training a
monolithic MLLM with promising performance still remains challenging. In
particular, the popular approaches adopt continuous pre-training to extend a
pre-trained LLM to a monolithic MLLM, which suffers from catastrophic
forgetting and leads to performance degeneration. In this paper, we aim to
overcome this limitation from the perspective of delta tuning. Specifically,
our core idea is to embed visual parameters into a pre-trained LLM, thereby
incrementally learning visual knowledge from massive data via delta tuning,
i.e., freezing the LLM when optimizing the visual parameters. Based on this
principle, we present Mono-InternVL, a novel monolithic MLLM that seamlessly
integrates a set of visual experts via a multimodal mixture-of-experts
structure. Moreover, we propose an innovative pre-training strategy to maximize
the visual capability of Mono-InternVL, namely Endogenous Visual Pre-training
(EViP). In particular, EViP is designed as a progressive learning process for
visual experts, which aims to fully exploit the visual knowledge from noisy
data to high-quality data. To validate our approach, we conduct extensive
experiments on 16 benchmarks. Experimental results not only validate the
superior performance of Mono-InternVL compared to the state-of-the-art MLLM on
6 multimodal benchmarks, e.g., +113 points over InternVL-1.5 on OCRBench, but
also confirm its better deployment efficiency, with first token latency reduced
by up to 67%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±å·²å°è´å¤§éåªåå°å¶è½åæ´å±å°å¤æ¨¡æä»»åãå¶ä¸­ï¼è¶ä¾è¶å¤çéæ³¨éä¸­å¨å®é«å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¸ï¼å®å°è¦è¦ºç·¨ç¢¼åèªè¨è§£ç¢¼æ´åå°ä¸å LLM ä¸­ãåç®¡çµæ§ç°¡å®ä¸ææ¼é¨ç½²ï¼ä½è¨ç·´ä¸åå·æè¯å¥½æ§è½çå®é« MLLM ä»ç¶å·æææ°æ§ãå·é«èè¨ï¼æµè¡çæ¹æ³æ¡ç¨é£çºé è¨ç·´å°é è¨ç·´ç LLM æ´å±å°å®é« MLLMï¼éæå°è´ç½é£æ§éºå¿ä¸¦å°è´æ§è½ä¸éãå¨æ¬æä¸­ï¼æåæ¨å¨å¾å¢éèª¿æ´çè§åº¦åæéä¸éå¶ãå·é«ä¾èªªï¼æåçæ ¸å¿ææ³æ¯å°è¦è¦ºåæ¸åµå¥å°é è¨ç·´ç LLM ä¸­ï¼å¾èééå¢éèª¿æ´å¾æµ·éæ¸æä¸­å¢éå­¸ç¿è¦è¦ºç¥è­ï¼å³å¨åªåè¦è¦ºåæ¸æåçµ LLMãåºæ¼éä¸åçï¼æåæåºäº Mono-InternVLï¼éæ¯ä¸åæ°ç©çå®é« MLLMï¼å®ééå¤æ¨¡æå°å®¶æ··åçµæ§ç¡ç¸«æ´åäºä¸çµè¦è¦ºå°å®¶ãæ­¤å¤ï¼æåæåºäºä¸ç¨®åµæ°çé è¨ç·´ç­ç¥ï¼ä»¥æå¤§å Mono-InternVL çè¦è¦ºè½åï¼å³å§çè¦è¦ºé è¨ç·´ (EViP)ãå·é«ä¾èªªï¼EViP è¢«è¨­è¨çºè¦è¦ºå°å®¶çæ¼¸é²å­¸ç¿éç¨ï¼æ¨å¨ååå©ç¨å¾åªè²æ¸æå°é«è³ªéæ¸æçè¦è¦ºç¥è­ãçºäºé©è­æåçåæ³ï¼æåå¨ 16 ååºæºä¸é²è¡äºå»£æ³çå¯¦é©ãå¯¦é©çµæä¸åé©è­äº Mono-InternVL èæåé²ç MLLM å¨ 6 åå¤æ¨¡æåºæºä¸çåè¶æ§è½ï¼ä¾å¦ï¼å¨ OCRBench ä¸æ¯ InternVL-1.5 é« 113 åï¼èä¸éç¢ºèªäºå¶æ´å¥½çé¨ç½²æçï¼é¦åä»¤çå»¶é²éä½äºé«é 67%ã

##### **From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions**
2410.08197v1 by Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen

Tool learning enables Large Language Models (LLMs) to interact with external
environments by invoking tools, serving as an effective strategy to mitigate
the limitations inherent in their pre-training data. In this process, tool
documentation plays a crucial role by providing usage instructions for LLMs,
thereby facilitating effective tool utilization. This paper concentrates on the
critical challenge of bridging the comprehension gap between LLMs and external
tools due to the inadequacies and inaccuracies inherent in existing
human-centric tool documentation. We propose a novel framework, DRAFT, aimed at
Dynamically Refining tool documentation through the Analysis of Feedback and
Trails emanating from LLMs' interactions with external tools. This methodology
pivots on an innovative trial-and-error approach, consisting of three distinct
learning phases: experience gathering, learning from experience, and
documentation rewriting, to iteratively enhance the tool documentation. This
process is further optimized by implementing a diversity-promoting exploration
strategy to ensure explorative diversity and a tool-adaptive termination
mechanism to prevent overfitting while enhancing efficiency. Extensive
experiments on multiple datasets demonstrate that DRAFT's iterative,
feedback-based refinement significantly ameliorates documentation quality,
fostering a deeper comprehension and more effective utilization of tools by
LLMs. Notably, our analysis reveals that the tool documentation refined via our
approach demonstrates robust cross-model generalization capabilities.

æè¦ï¼å·¥å·å­¸ç¿è®å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééå¼å«å·¥å·èå¤é¨ç°å¢äºåï¼ä½çºä¸ç¨®ææçç­ç¥ä¾æ¸è¼å¶é è¨ç·´è³æä¸­åºæçéå¶ãå¨æ­¤éç¨ä¸­ï¼å·¥å·æä»¶æ®æ¼äºééµçè§è²ï¼çº LLM æä¾ä½¿ç¨èªªæï¼å¾èä¿é²ææçå·¥å·å©ç¨ãæ¬æå°æ³¨æ¼ç±æ¼ç¾æäººé¡çºä¸­å¿çå·¥å·æä»¶ä¸­çä¸è¶³åä¸æºç¢ºæ§ï¼å¨ LLM åå¤é¨å·¥å·ä¹éå½åçè§£å·®è·çéå¤§ææ°ãæåæåºäºä¸åæ°çæ¡æ¶ DRAFTï¼æ¨å¨ééåæ LLM èå¤é¨å·¥å·äºåç¢ççåé¥åè»è·¡ï¼åæç²¾çå·¥å·æä»¶ãæ­¤æ¹æ³åºæ¼åµæ°çè©¦é¯æ³ï¼åå«ä¸åä¸åçå­¸ç¿éæ®µï¼ç¶é©æ¶éãå¾ç¶é©ä¸­å­¸ç¿åæä»¶éå¯«ï¼ä»¥åè¦å¢å¼·å·¥å·æä»¶ãæ­¤æµç¨é²ä¸æ­¥ééå¯¦æ½ä¿é²å¤æ¨£æ§çæ¢ç´¢ç­ç¥ä¾æä½³åï¼ä»¥ç¢ºä¿æ¢ç´¢çå¤æ¨£æ§ï¼ä¸¦ééå·¥å·é©æçµæ­¢æ©å¶ä¾é²æ­¢éåº¦æ¬åï¼åææé«æçãå¨å¤åè³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼DRAFT çè¿­ä»£å¼ãåºæ¼åé¥çç²¾çé¡¯èæ¹åäºæä»¶åè³ªï¼ä¿é² LLM å°å·¥å·çæ´æ·±å¥çè§£åæ´ææçå©ç¨ãå¼å¾æ³¨æçæ¯ï¼æåçåæè¡¨æï¼ééæåçæ¹æ³ç²¾ççå·¥å·æä»¶å±ç¤ºäºå¼·å¤§çè·¨æ¨¡åæ³åè½åã

##### **MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code**
2410.08196v1 by Zimu Lu, Aojun Zhou, Ke Wang, Houxing Ren, Weikang Shi, Junting Pan, Mingjie Zhan, Hongsheng Li

Code has been shown to be effective in enhancing the mathematical reasoning
abilities of large language models due to its precision and accuracy. Previous
works involving continued mathematical pretraining often include code that
utilizes math-related packages, which are primarily designed for fields such as
engineering, machine learning, signal processing, or module testing, rather
than being directly focused on mathematical reasoning. In this paper, we
introduce a novel method for generating mathematical code accompanied with
corresponding reasoning steps for continued pretraining. Our approach begins
with the construction of a high-quality mathematical continued pretraining
dataset by incorporating math-related web data, code using mathematical
packages, math textbooks, and synthetic data. Next, we construct reasoning
steps by extracting LaTeX expressions, the conditions needed for the
expressions, and the results of the expressions from the previously collected
dataset. Based on this extracted information, we generate corresponding code to
accurately capture the mathematical reasoning process. Appending the generated
code to each reasoning step results in data consisting of paired natural
language reasoning steps and their corresponding code. Combining this data with
the original dataset results in a 19.2B-token high-performing mathematical
pretraining corpus, which we name MathCode-Pile. Training several popular base
models with this corpus significantly improves their mathematical abilities,
leading to the creation of the MathCoder2 family of models. All of our data
processing and training code is open-sourced, ensuring full transparency and
easy reproducibility of the entire data collection and training pipeline. The
code is released at https://github.com/mathllm/MathCoder2 .

æè¦ï¼<paragraph>ç¨å¼ç¢¼å·²è¢«è­å¯¦è½æææåå¤§åèªè¨æ¨¡åçæ¸å­¸æ¨çè½åï¼å çºå®ç²¾æºä¸æºç¢ºãååæ¶åæçºæ¸å­¸é è¨ç·´çç ç©¶ï¼éå¸¸åå«ä½¿ç¨èæ¸å­¸ç¸éå¥ä»¶çç¨å¼ç¢¼ï¼éäºå¥ä»¶ä¸»è¦è¨­è¨çµ¦å·¥ç¨ãæ©å¨å­¸ç¿ãè¨èèçææ¨¡çµæ¸¬è©¦ç­é åï¼èä¸æ¯ç´æ¥å°æ³¨æ¼æ¸å­¸æ¨çãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼ç¢çæ¸å­¸ç¨å¼ç¢¼ï¼ä¸¦éä¸å°æçæ¨çæ­¥é©ï¼ä»¥æçºé²è¡é è¨ç·´ãæåçåæ³å¾å»ºç«ä¸åé«åè³ªçæ¸å­¸æçºé è¨ç·´è³æééå§ï¼æ¹æ³æ¯ç´å¥èæ¸å­¸ç¸éçç¶²è·¯è³æãä½¿ç¨æ¸å­¸å¥ä»¶çç¨å¼ç¢¼ãæ¸å­¸æç§æ¸ååæè³æãæ¥ä¸ä¾ï¼æåééå¾ååæ¶éçè³æéä¸­èå LaTeX è¡¨éå¼ãè¡¨éå¼æéçæ¢ä»¶ï¼ä»¥åè¡¨éå¼ççµæï¼ä¾å»ºæ§æ¨çæ­¥é©ãæ ¹æéäºèåçè³è¨ï¼æåç¢çå°æçç¨å¼ç¢¼ï¼ä»¥æºç¢ºæææ¸å­¸æ¨çéç¨ãå°ç¢ççç¨å¼ç¢¼éå å°æ¯åæ¨çæ­¥é©ï¼å°±æç¢çç±æå°çèªç¶èªè¨æ¨çæ­¥é©åå¶å°æç¨å¼ç¢¼çµæçè³æãå°éäºè³æèåå§è³æéçµåï¼å°±æç¢çä¸å 19.2B åç¬¦èçé«æè½æ¸å­¸é è¨ç·´èªæåº«ï¼æåå°å¶å½åçº MathCode-Pileãä½¿ç¨éåèªæåº«è¨ç·´å¹¾åç±éçåºæ¬æ¨¡åï¼å¤§å¹æåäºå®åçæ¸å­¸è½åï¼é²èåµé åº MathCoder2 æ¨¡åå®¶æãæåææçè³æèçåè¨ç·´ç¨å¼ç¢¼é½æ¯éæºçï¼ç¢ºä¿æ´åè³ææ¶éåè¨ç·´ç®¡ç·çå®å¨éæåº¦åå®¹æéç¾æ§ãç¨å¼ç¢¼å·²æ¼ https://github.com/mathllm/MathCoder2 ç¼å¸ã</paragraph>

##### **GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment**
2410.08193v1 by Yuancheng Xu, Udari Madhushani Sehwag, Alec Koppel, Sicheng Zhu, Bang An, Furong Huang, Sumitra Ganesh

Large Language Models (LLMs) exhibit impressive capabilities but require
careful alignment with human preferences. Traditional training-time methods
finetune LLMs using human preference datasets but incur significant training
costs and require repeated training to handle diverse user preferences.
Test-time alignment methods address this by using reward models (RMs) to guide
frozen LLMs without retraining. However, existing test-time approaches rely on
trajectory-level RMs which are designed to evaluate complete responses, making
them unsuitable for autoregressive text generation that requires computing
next-token rewards from partial responses. To address this, we introduce
GenARM, a test-time alignment approach that leverages the Autoregressive Reward
Model--a novel reward parametrization designed to predict next-token rewards
for efficient and effective autoregressive generation. Theoretically, we
demonstrate that this parametrization can provably guide frozen LLMs toward any
distribution achievable by traditional RMs within the KL-regularized
reinforcement learning framework. Experimental results show that GenARM
significantly outperforms prior test-time alignment baselines and matches the
performance of training-time methods. Additionally, GenARM enables efficient
weak-to-strong guidance, aligning larger LLMs with smaller RMs without the high
costs of training larger models. Furthermore, GenARM supports multi-objective
alignment, allowing real-time trade-offs between preference dimensions and
catering to diverse user preferences without retraining.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºä»¤äººå°è±¡æ·±å»çè½åï¼ä½éè¦ä»ç´°éåäººé¡çåå¥½ãå³çµ±çè¨ç·´æéæ¹æ³ä½¿ç¨äººé¡åå¥½è³æéå¾®èª¿ LLMï¼ä½æç¢çå¤§éçè¨ç·´ææ¬ï¼ä¸¦ä¸éè¦åè¦è¨ç·´æè½èçä¸åçä½¿ç¨èåå¥½ãæ¸¬è©¦æéå°é½æ¹æ³ééä½¿ç¨çåµæ¨¡å (RM) ä¾æå°åçµç LLM èç¡ééæ°è¨ç·´ä¾è§£æ±ºéååé¡ãç¶èï¼ç¾æçæ¸¬è©¦æéæ¹æ³ä¾è³´æ¼è»è·¡ç´å¥ç RMï¼éäº RM è¢«è¨­è¨ç¨æ¼è©ä¼°å®æ´çåæï¼éä½¿å¾å®åä¸é©åéè¦å¾é¨ååæä¸­è¨ç®ä¸ä¸åä»£å¹£çåµçèªè¿´æ­¸ææ¬çæãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº GenARMï¼ä¸ç¨®æ¸¬è©¦æéå°é½æ¹æ³ï¼å®å©ç¨èªè¿´æ­¸çåµæ¨¡åââä¸ç¨®æ°ç©ççåµåæ¸åï¼æ¨å¨é æ¸¬ä¸ä¸åä»£å¹£çåµï¼ä»¥å¯¦ç¾é«æä¸ææçèªè¿´æ­¸çæãå¨çè«ä¸ï¼æåè­æäºéååæ¸åå¯ä»¥è­æå¼å°åçµç LLM æèä»»ä½å¨ KL æ­£ååå¼·åå­¸ç¿æ¡æ¶å§ç±å³çµ± RM å¯å¯¦ç¾çåå¸ãå¯¦é©çµæè¡¨æï¼GenARM æé¡¯åªæ¼ååçæ¸¬è©¦æéå°é½åºæºï¼ä¸¦ä¸èè¨ç·´æéæ¹æ³çæ§è½ç¸å¹éãæ­¤å¤ï¼GenARM è½å¤ å¯¦ç¾é«æçå¼±å°å¼·å¼å°ï¼å¨ä¸å¢å è¨ç·´å¤§åæ¨¡åçé«ææ¬çææ³ä¸ï¼å°è¼å¤§ç LLM èè¼å°ç RM å°é½ãæ­¤å¤ï¼GenARM æ¯æ´å¤ç®æ¨å°é½ï¼åè¨±å¨åå¥½ç¶­åº¦ä¹éé²è¡å¯¦ææ¬è¡¡ï¼ä¸¦å¨ä¸éæ°è¨ç·´çææ³ä¸è¿åä¸åçä½¿ç¨èåå¥½ã

##### **DifFRelight: Diffusion-Based Facial Performance Relighting**
2410.08188v1 by Mingming He, Pascal Clausen, Ahmet Levent TaÅel, Li Ma, Oliver Pilarski, Wenqi Xian, Laszlo Rikker, Xueming Yu, Ryan Burgert, Ning Yu, Paul Debevec

We present a novel framework for free-viewpoint facial performance relighting
using diffusion-based image-to-image translation. Leveraging a subject-specific
dataset containing diverse facial expressions captured under various lighting
conditions, including flat-lit and one-light-at-a-time (OLAT) scenarios, we
train a diffusion model for precise lighting control, enabling high-fidelity
relit facial images from flat-lit inputs. Our framework includes
spatially-aligned conditioning of flat-lit captures and random noise, along
with integrated lighting information for global control, utilizing prior
knowledge from the pre-trained Stable Diffusion model. This model is then
applied to dynamic facial performances captured in a consistent flat-lit
environment and reconstructed for novel-view synthesis using a scalable dynamic
3D Gaussian Splatting method to maintain quality and consistency in the relit
results. In addition, we introduce unified lighting control by integrating a
novel area lighting representation with directional lighting, allowing for
joint adjustments in light size and direction. We also enable high dynamic
range imaging (HDRI) composition using multiple directional lights to produce
dynamic sequences under complex lighting conditions. Our evaluations
demonstrate the models efficiency in achieving precise lighting control and
generalizing across various facial expressions while preserving detailed
features such as skintexture andhair. The model accurately reproduces complex
lighting effects like eye reflections, subsurface scattering, self-shadowing,
and translucency, advancing photorealism within our framework.

æè¦ï¼<paragraph>æåæåºä¸åæ°ç©çæ¶æ§ï¼ç¨æ¼èªç±è¦é»äººèæ§è½éæ°æåï¼ä½¿ç¨åºæ¼æ´æ£çå½±åè½å½±åè½æãå©ç¨åå«å¨åç¨®åç§æ¢ä»¶ä¸æ·åçåç¨®é¢é¨è¡¨æçä¸»é¡ç¹å®è³æéï¼åæ¬å¹³é¢ååä¸æ¬¡ä¸åï¼OLATï¼å ´æ¯ï¼æåè¨ç·´ä¸åæ´æ£æ¨¡åä»¥é²è¡ç²¾ç¢ºçåç§æ§å¶ï¼å¾å¹³é¢åè¼¸å¥ä¸­åç¨é«ä¿çéæ°é»äº®çé¢é¨å½±åãæåçæ¶æ§åæ¬å¹³é¢åæ·ååé¨æ©éè¨çç©ºéå°é½æ¢ä»¶ï¼ä»¥åç¨æ¼å¨å±æ§å¶çæ´ååç§è³è¨ï¼å©ç¨é åè¨ç·´ç Stable Diffusion æ¨¡åçåé©ç¥è­ãç¶å¾å°æ­¤æ¨¡åæç¨æ¼å¨ä¸è´çå¹³é¢åç°å¢ä¸­æ·åçåæé¢é¨è¡¨æ¼ï¼ä¸¦ä½¿ç¨å¯æ´åçåæ 3D é«æ¯å´ç¹ªæ¹æ³éå»ºä»¥é²è¡æ°è¦ååæï¼ä»¥ç¶­æéæ°é»äº®çµæçåè³ªåä¸è´æ§ãæ­¤å¤ï¼æåééæ´åä¸åæ°ç©åååç§è¡¨ç¤ºèæ¹ååç§ä¾å¼å¥çµ±ä¸åç§æ§å¶ï¼åè¨±å°åç§å¤§å°åæ¹åé²è¡è¯åèª¿æ´ãæåéåç¨ä½¿ç¨å¤åæ¹ååçé«åæç¯åæåï¼HDRIï¼åæï¼ä»¥å¨è¤éçåç§æ¢ä»¶ä¸ç¢çåæåºåãæåçè©ä¼°è­æäºè©²æ¨¡åå¨å¯¦ç¾ç²¾ç¢ºåç§æ§å¶åæ¦æ¬åç¨®é¢é¨è¡¨ææ¹é¢çæçï¼åæä¿çäºç®èç´çåé ­é«®ç­è©³ç´°ç¹å¾µãè©²æ¨¡åæºç¢ºå°éç¾äºè¤éçåç§ææï¼ä¾å¦ç¼çåå°ãæ¬¡è¡¨é¢æ£å°ãèªé®è½ååéæï¼æ¨åäºæåæ¶æ§ä¸­çå¯«å¯¦ä¸»ç¾©ã</paragraph>

##### **MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models**
2410.08182v1 by Wenbo Hu, Jia-Chen Gu, Zi-Yi Dou, Mohsen Fayyaz, Pan Lu, Kai-Wei Chang, Nanyun Peng

Existing multimodal retrieval benchmarks primarily focus on evaluating
whether models can retrieve and utilize external textual knowledge for question
answering. However, there are scenarios where retrieving visual information is
either more beneficial or easier to access than textual data. In this paper, we
introduce a multimodal retrieval-augmented generation benchmark, MRAG-Bench, in
which we systematically identify and categorize scenarios where visually
augmented knowledge is better than textual knowledge, for instance, more images
from varying viewpoints. MRAG-Bench consists of 16,130 images and 1,353
human-annotated multiple-choice questions across 9 distinct scenarios. With
MRAG-Bench, we conduct an evaluation of 10 open-source and 4 proprietary large
vision-language models (LVLMs). Our results show that all LVLMs exhibit greater
improvements when augmented with images compared to textual knowledge,
confirming that MRAG-Bench is vision-centric. Additionally, we conduct
extensive analysis with MRAG-Bench, which offers valuable insights into
retrieval-augmented LVLMs. Notably, the top-performing model, GPT-4o, faces
challenges in effectively leveraging retrieved knowledge, achieving only a
5.82% improvement with ground-truth information, in contrast to a 33.16%
improvement observed in human participants. These findings highlight the
importance of MRAG-Bench in encouraging the community to enhance LVLMs' ability
to utilize retrieved visual knowledge more effectively.

æè¦ï¼ç¾æçå¤æ¨¡ææª¢ç´¢åºæºä¸»è¦éä¸­å¨è©ä¼°æ¨¡åæ¯å¦è½æª¢ç´¢åå©ç¨å¤é¨ææ¬ç¥è­ä¾åç­åé¡ãç¶èï¼å¨æäºææ³ä¸ï¼æª¢ç´¢è¦è¦ºè³è¨æ¯æª¢ç´¢æå­è³ææ´æå©ææ´å®¹æãå¨æ¬æä¸­ï¼æåå¼é²äºä¸åå¤æ¨¡ææª¢ç´¢å¢å¼·çæåºæº MRAG-Benchï¼å¶ä¸­æåç³»çµ±æ§å°æ¾åºä¸¦åé¡åºè¦è¦ºå¢å¼·ç¥è­åªæ¼æå­ç¥è­çææ³ï¼ä¾å¦æ´å¤ä¾èªä¸åè¦è§çå½±åãMRAG-Bench åå« 16,130 å¼µå½±åå 1,353 åç±äººé¡è¨»è§£çå¤éé¸æé¡ï¼æ¶µè 9 ç¨®ä¸åçææ³ãéé MRAG-Benchï¼æåå° 10 åéæºå 4 åå°æçå¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) é²è¡è©ä¼°ãæåççµæé¡¯ç¤ºï¼ææ LVLMs å¨å å¥å½±åå¾é½å±ç¾åºæ¯å å¥æå­ç¥è­ææ´å¤§çé²æ­¥ï¼è­å¯¦ MRAG-Bench ä»¥è¦è¦ºçºä¸­å¿ãæ­¤å¤ï¼æåä½¿ç¨ MRAG-Bench é²è¡å»£æ³çåæï¼éæä¾äºæå¹å¼çè¦è§£ï¼è®æåæ·±å¥äºè§£æª¢ç´¢å¢å¼· LVLMsãå¼å¾æ³¨æçæ¯ï¼è¡¨ç¾æä½³çæ¨¡å GPT-4o å¨ææå©ç¨æª¢ç´¢å°çç¥è­æ¹é¢é¢è¨ææ°ï¼åç²å¾ 5.82% ççå¯¦è³è¨é²æ­¥ï¼èäººé¡åèèè§å¯å°ç 33.16% é²æ­¥å½¢æå°æ¯ãéäºç¼ç¾çªé¡¯äº MRAG-Bench çéè¦æ§ï¼å®é¼åµç¤¾ç¾¤æå LVLMs æ´ææå°å©ç¨æª¢ç´¢å°çè¦è¦ºç¥è­çè½åã

##### **Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models**
2410.08174v1 by Qingni Wang, Tiantian Geng, Zhiyuan Wang, Teng Wang, Bo Fu, Feng Zheng

Multimodal Large Language Models (MLLMs) exhibit promising advancements
across various tasks, yet they still encounter significant trustworthiness
issues. Prior studies apply Split Conformal Prediction (SCP) in language
modeling to construct prediction sets with statistical guarantees. However,
these methods typically rely on internal model logits or are restricted to
multiple-choice settings, which hampers their generalizability and adaptability
in dynamic, open-ended environments. In this paper, we introduce TRON, a
two-step framework for risk control and assessment, applicable to any MLLM that
supports sampling in both open-ended and closed-ended scenarios. TRON comprises
two main components: (1) a novel conformal score to sample response sets of
minimum size, and (2) a nonconformity score to identify high-quality responses
based on self-consistency theory, controlling the error rates by two specific
risk levels. Furthermore, we investigate semantic redundancy in prediction sets
within open-ended contexts for the first time, leading to a promising
evaluation metric for MLLMs based on average set size. Our comprehensive
experiments across four Video Question-Answering (VideoQA) datasets utilizing
eight MLLMs show that TRON achieves desired error rates bounded by two
user-specified risk levels. Additionally, deduplicated prediction sets maintain
adaptiveness while being more efficient and stable for risk assessment under
different risk levels.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å¨åç§ä»»å¡ä¸­è¡¨ç°åºæå¸æçè¿æ­¥ï¼ä½å®ä»¬ä»ç¶éå°éå¤§çå¯ä¿¡åº¦é®é¢ãååçç ç©¶å¨è¯­è¨å»ºæ¨¡ä¸­åºç¨åè£ä¿å½¢é¢æµ (SCP) æ¥æå»ºå·æç»è®¡ä¿è¯çé¢æµéãç¶èï¼è¿äºæ¹æ³éå¸¸ä¾èµäºåé¨æ¨¡å logit æä»éäºå¤é¡¹éæ©è®¾ç½®ï¼è¿é»ç¢äºå®ä»¬å¨å¨æãå¼æ¾å¼ç¯å¢ä¸­çæ³åæ§åéåºæ§ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äº TRONï¼è¿æ¯ä¸ä¸ªéç¨äºä»»ä½æ¯æå¨å¼æ¾å¼åå°é­å¼åºæ¯ä¸­è¿è¡éæ ·ç MLLM çé£é©æ§å¶åè¯ä¼°çä¸¤æ­¥æ¡æ¶ãTRON åå«ä¸¤ä¸ªä¸»è¦ç»ä»¶ï¼(1) ä¸ä¸ªæ°é¢çä¿å½¢åæ°ï¼ç¨äºå¯¹æå°å¤§å°çååºéè¿è¡éæ ·ï¼ä»¥å (2) ä¸ä¸ªä¸ç¬¦ååæ°ï¼ç¨äºæ ¹æ®èªæ´½æ§çè®ºè¯å«é«è´¨éçååºï¼éè¿ä¸¤ä¸ªç¹å®çé£é©çº§å«æ§å¶éè¯¯çãæ­¤å¤ï¼æä»¬é¦æ¬¡ç ç©¶äºå¼æ¾å¼è¯­å¢ä¸­é¢æµéä¸­çè¯­ä¹åä½ï¼ä»èä¸ºåºäºå¹³åéå¤§å°ç MLLM æä¾äºä¸ä¸ªæå¸æçè¯ä¼°ææ ãæä»¬å¨å©ç¨å«ä¸ª MLLM çåä¸ªè§é¢é®ç­ (VideoQA) æ°æ®éä¸è¿è¡çå¨é¢å®éªè¡¨æï¼TRON å®ç°äºç±ä¸¤ä¸ªç¨æ·æå®çé£é©çº§å«éå®çææéè¯¯çãæ­¤å¤ï¼éå¤æ°æ®å é¤çé¢æµéä¿æéåºæ§ï¼åæ¶å¨ä¸åé£é©çº§å«ä¸å¯¹é£é©è¯ä¼°æ´ææãæ´ç¨³å®ã

##### **On the Evaluation of Generative Robotic Simulations**
2410.08172v1 by Feng Chen, Botian Xu, Pu Hua, Peiqi Duan, Yanchao Yang, Yi Ma, Huazhe Xu

Due to the difficulty of acquiring extensive real-world data, robot
simulation has become crucial for parallel training and sim-to-real transfer,
highlighting the importance of scalable simulated robotic tasks. Foundation
models have demonstrated impressive capacities in autonomously generating
feasible robotic tasks. However, this new paradigm underscores the challenge of
adequately evaluating these autonomously generated tasks. To address this, we
propose a comprehensive evaluation framework tailored to generative
simulations. Our framework segments evaluation into three core aspects:
quality, diversity, and generalization. For single-task quality, we evaluate
the realism of the generated task and the completeness of the generated
trajectories using large language models and vision-language models. In terms
of diversity, we measure both task and data diversity through text similarity
of task descriptions and world model loss trained on collected task
trajectories. For task-level generalization, we assess the zero-shot
generalization ability on unseen tasks of a policy trained with multiple
generated tasks. Experiments conducted on three representative task generation
pipelines demonstrate that the results from our framework are highly consistent
with human evaluations, confirming the feasibility and validity of our
approach. The findings reveal that while metrics of quality and diversity can
be achieved through certain methods, no single approach excels across all
metrics, suggesting a need for greater focus on balancing these different
metrics. Additionally, our analysis further highlights the common challenge of
low generalization capability faced by current works. Our anonymous website:
https://sites.google.com/view/evaltasks.

æè¦ï¼<paragraph>ç±æ¼é£ä»¥åå¾å»£æ³ççå¯¦ä¸çè³æï¼æ©å¨äººæ¨¡æ¬å·²æçºå¹³è¡è¨ç·´åæ¨¡æ¬å°çå¯¦è½ç§»çééµï¼å¼·èª¿å¯æ´åæ¨¡æ¬æ©å¨äººä»»åçéè¦æ§ãåºç¤æ¨¡åå·²å±ç¤ºåºèªä¸»ç¢çå¯è¡æ©å¨äººä»»åçé©äººè½åãç¶èï¼éåæ°ç¯ä¾å¼·èª¿äºååè©ä¼°éäºèªä¸»ç¢çä»»åçææ°ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åéèº«æé çç¶åè©ä¼°æ¶æ§ï¼é©ç¨æ¼çææ¨¡æ¬ãæåçæ¶æ§å°è©ä¼°åçºä¸åæ ¸å¿é¢åï¼åè³ªãå¤æ¨£æ§åæ¦åãå°æ¼å®ä¸ä»»ååè³ªï¼æåä½¿ç¨å¤§åèªè¨æ¨¡ååè¦è¦ºèªè¨æ¨¡åè©ä¼°çæä»»åççå¯¦æ§åçæè»è·¡çå®æ´æ§ãå¨å¤æ¨£æ§æ¹é¢ï¼æåééä»»åæè¿°çæå­ç¸ä¼¼æ§åå¨æ¶éçä»»åè»è·¡ä¸è¨ç·´çä¸çæ¨¡åæå¤±ï¼ä¾è¡¡éä»»ååè³æçå¤æ¨£æ§ãå°æ¼ä»»åå±¤ç´çæ¦åï¼æåè©ä¼°å¨ä½¿ç¨å¤åçæä»»åè¨ç·´çç­ç¥ä¸­ï¼å°æªè¦ä»»åçé¶æ¬¡å­¸ç¿æ¦åè½åãå¨ä¸åä»£è¡¨æ§ä»»åçæç®¡ç·ä¸é²è¡çå¯¦é©è­æï¼æåæ¶æ§ççµæèäººé¡è©ä¼°é«åº¦ä¸è´ï¼è­å¯¦æåæ¹æ³çå¯è¡æ§åæææ§ãç ç©¶çµæé¡¯ç¤ºï¼éç¶åè³ªåå¤æ¨£æ§çææ¨å¯ééç¹å®æ¹æ³éæï¼ä½æ²æå®ä¸æ¹æ³å¨ææææ¨ä¸é½è¡¨ç¾åºè²ï¼éè¡¨ç¤ºéè¦æ´å°æ³¨æ¼å¹³è¡¡éäºä¸åçææ¨ãæ­¤å¤ï¼æåçåæé²ä¸æ­¥å¼·èª¿äºç¶åå·¥ä½é¢è¨çä½æ¦åè½åçå±åææ°ãæåçå¿åç¶²ç«ï¼https://sites.google.com/view/evaltasksã</paragraph>

##### **Agent S: An Open Agentic Framework that Uses Computers Like a Human**
2410.08164v1 by Saaket Agashe, Jiuzhou Han, Shuyu Gan, Jiachen Yang, Ang Li, Xin Eric Wang

We present Agent S, an open agentic framework that enables autonomous
interaction with computers through a Graphical User Interface (GUI), aimed at
transforming human-computer interaction by automating complex, multi-step
tasks. Agent S aims to address three key challenges in automating computer
tasks: acquiring domain-specific knowledge, planning over long task horizons,
and handling dynamic, non-uniform interfaces. To this end, Agent S introduces
experience-augmented hierarchical planning, which learns from external
knowledge search and internal experience retrieval at multiple levels,
facilitating efficient task planning and subtask execution. In addition, it
employs an Agent-Computer Interface (ACI) to better elicit the reasoning and
control capabilities of GUI agents based on Multimodal Large Language Models
(MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the
baseline by 9.37% on success rate (an 83.6% relative improvement) and achieves
a new state-of-the-art. Comprehensive analysis highlights the effectiveness of
individual components and provides insights for future improvements.
Furthermore, Agent S demonstrates broad generalizability to different operating
systems on a newly-released WindowsAgentArena benchmark. Code available at
https://github.com/simular-ai/Agent-S.

æè¦ï¼<paragraph>æåæåº Agent Sï¼ä¸åéæ¾çä»£çæ¡æ¶ï¼å¯ééåå½¢ä½¿ç¨èä»é¢ (GUI) èé»è¦é²è¡èªä¸»äºåï¼æ¨å¨ééèªååè¤éçå¤æ­¥é©ä»»åä¾è½è®äººæ©äºåãAgent S æ¨å¨è§£æ±ºèªååé»è¦ä»»åä¸­çä¸åééµææ°ï¼æ·åç¹å®é åç¥è­ãè¦åé·ä»»åæç¨ï¼ä»¥åèçåæãéçµ±ä¸çä»é¢ãçºæ­¤ï¼Agent S å°å¥äºç¶é©å¢å¼·éå±¤å¼è¦åï¼å®æå¾å¤åå±¤ç´çå¤é¨ç¥è­æå°åå§é¨ç¶é©æ·åä¸­å­¸ç¿ï¼ä¿é²ææççä»»åè¦ååå­ä»»åå·è¡ãæ­¤å¤ï¼å®æ¡ç¨ä»£çé»è¦ä»é¢ (ACI)ï¼ä»¥æ ¹æå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æ´ä½³å°å¼åº GUI ä»£ççæ¨çåæ§å¶è½åãå¨ OSWorld åºæºä¸çè©ä¼°é¡¯ç¤ºï¼Agent S å¨æåçä¸æ¯åºæºé«åº 9.37%ï¼ç¸å°æå 83.6%ï¼ï¼ä¸¦åµä¸æ°çæè¡æ°´æºãå¨é¢çåæçªé¡¯äºåå¥åä»¶çæææ§ï¼ä¸¦çºæªä¾çæ¹é²æä¾è¦è§£ãæ­¤å¤ï¼Agent S å¨æ°ç¼å¸ç WindowsAgentArena åºæºä¸å±ç¤ºäºå°ä¸åä½æ¥­ç³»çµ±çå»£æ³éç¨æ§ãç¨å¼ç¢¼å¯æ¼ https://github.com/simular-ai/Agent-S åå¾ã</paragraph>

##### **The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading**
2410.08162v1 by Keren Gruteke Klein, Yoav Meiri, Omer Shubi, Yevgeni Berzak

The effect of surprisal on processing difficulty has been a central topic of
investigation in psycholinguistics. Here, we use eyetracking data to examine
three language processing regimes that are common in daily life but have not
been addressed with respect to this question: information seeking, repeated
processing, and the combination of the two. Using standard regime-agnostic
surprisal estimates we find that the prediction of surprisal theory regarding
the presence of a linear effect of surprisal on processing times, extends to
these regimes. However, when using surprisal estimates from regime-specific
contexts that match the contexts and tasks given to humans, we find that in
information seeking, such estimates do not improve the predictive power of
processing times compared to standard surprisals. Further, regime-specific
contexts yield near zero surprisal estimates with no predictive power for
processing times in repeated reading. These findings point to misalignments of
task and memory representations between humans and current language models, and
question the extent to which such models can be used for estimating cognitively
relevant quantities. We further discuss theoretical challenges posed by these
results.

æè¦ï¼é©è¨å°èçé£åº¦ä¹å½±é¿ä¸ç´æ¯å¿çèªè¨å­¸èª¿æ¥çä¸­å¿è­°é¡ãå¨æ­¤ï¼æåä½¿ç¨ç¼åè¿½è¹¤è³æä¾æª¢è¦æ¥å¸¸çæ´»ä¸­å¸¸è¦çä¸ç¨®èªè¨èçæ¨¡å¼ï¼ä½å°æªéå°æ­¤åé¡å ä»¥æ¢è¨ï¼è³è¨å°æ±ãéè¤èçï¼ä»¥åå©èççµåãä½¿ç¨æ¨æºçèæ¨¡å¼ç¡éçé©è¨ä¼°è¨ï¼æåç¼ç¾é©è¨çè«å°èçæéä¸­é©è¨ç·æ§ææå­å¨çé æ¸¬ï¼å»¶ä¼¸è³éäºæ¨¡å¼ãç¶èï¼ç¶ä½¿ç¨ä¾èªèäººé¡æçµ¦äºçèçµ¡åä»»åç¸ç¬¦çæ¨¡å¼ç¹å®èçµ¡çé©è¨ä¼°è¨æï¼æåç¼ç¾ï¼å¨è³è¨å°æ±ä¸­ï¼æ­¤é¡ä¼°è¨ä¸¦æªæ¹åèçæéçé æ¸¬è½åï¼èæ¨æºé©è¨ç¸æ¯ãæ­¤å¤ï¼æ¨¡å¼ç¹å®èçµ¡ç¢çæ¥è¿æ¼é¶çé©è¨ä¼°è¨ï¼å¨éè¤é±è®ä¸­å°èçæéæ²æé æ¸¬è½åãéäºç¼ç¾æåºäººé¡èç¶åèªè¨æ¨¡åä¹éçä»»ååè¨æ¶è¡¨å¾µçä¸ä¸è´ï¼ä¸¦è³ªçæ­¤é¡æ¨¡åå¯ç¨æ¼ä¼°è¨èªç¥ç¸éæ¸éãæåé²ä¸æ­¥è¨è«éäºçµææåºççè«ææ°ã

##### **Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning**
2410.08146v1 by Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang Geng, Jacob Eisenstein, Rishabh Agarwal, Alekh Agarwal, Jonathan Berant, Aviral Kumar

A promising approach for improving reasoning in large language models is to
use process reward models (PRMs). PRMs provide feedback at each step of a
multi-step reasoning trace, potentially improving credit assignment over
outcome reward models (ORMs) that only provide feedback at the final step.
However, collecting dense, per-step human labels is not scalable, and training
PRMs from automatically-labeled data has thus far led to limited gains. To
improve a base policy by running search against a PRM or using it as dense
rewards for reinforcement learning (RL), we ask: "How should we design process
rewards?". Our key insight is that, to be effective, the process reward for a
step should measure progress: a change in the likelihood of producing a correct
response in the future, before and after taking the step, corresponding to the
notion of step-level advantages in RL. Crucially, this progress should be
measured under a prover policy distinct from the base policy. We theoretically
characterize the set of good provers and our results show that optimizing
process rewards from such provers improves exploration during test-time search
and online RL. In fact, our characterization shows that weak prover policies
can substantially improve a stronger base policy, which we also observe
empirically. We validate our claims by training process advantage verifiers
(PAVs) to predict progress under such provers, and show that compared to ORMs,
test-time search against PAVs is $>8\%$ more accurate, and $1.5-5\times$ more
compute-efficient. Online RL with dense rewards from PAVs enables one of the
first results with $5-6\times$ gain in sample efficiency, and $>6\%$ gain in
accuracy, over ORMs.

æè¦ï¼ä¸ç¨®æ¹åå¤§åèªè¨æ¨¡åä¸­æ¨çè½åç promising æ¹æ³æ¯ä½¿ç¨éç¨çåµæ¨¡å (PRM)ãPRM å¨å¤æ­¥é©æ¨çè¿½è¹¤çæ¯ä¸æ­¥æä¾åé¥ï¼æ½å¨æ¹åäºå°çµæçåµæ¨¡å (ORM) çä¿¡ç¨åéï¼èå¾èåå¨æå¾ä¸æ­¥æä¾åé¥ã
ç¶èï¼æ¶éå¯éçãææ­¥é©é²è¡çäººé¡æ¨ç±¤ä¸¦éå¯æ´åçï¼èå¾èªåæ¨ç±¤è³æè¨ç·´ PRM è³ä»åç²å¾æéçé²å±ãçºäºéééå° PRM å·è¡æå°æå°å¶ç¨ä½å¼·åå­¸ç¿ (RL) çå¯éçåµä¾æ¹ååºç¤æ¿ç­ï¼æåæåºçåï¼ãæåæå¦ä½è¨­è¨éç¨çåµï¼ãæåçééµè¦è§£å¨æ¼ï¼éç¨çåµè¥è¦ææï¼å°æ¼æåæ­¥é©èè¨ï¼æè¡¡éé²åº¦ï¼å¨æ¡åæ­¥é©ä¹ååä¹å¾ï¼ç¢çæ­£ç¢ºåæçå¯è½æ§ç¼çè®åï¼éå°ææ¼ RL ä¸­æ­¥é©å±¤ç´åªå¢çæ¦å¿µãè³ééè¦çæ¯ï¼æå¨èåºç¤æ¿ç­ä¸åçè­æèæ¿ç­ä¸è¡¡éæ­¤é²åº¦ãæåå¨çè«ä¸æè¿°äºè¯å¥½çè­æèçµåï¼æåççµæé¡¯ç¤ºï¼æä½³åä¾èªæ­¤é¡è­æèçéç¨çåµææ¹åæ¸¬è©¦æéæå°åç·ä¸ RL ä¸­çæ¢ç´¢ãäºå¯¦ä¸ï¼æåçæè¿°é¡¯ç¤ºï¼å¼±è­æèæ¿ç­å¯ä»¥å¤§å¹æ¹åè¼å¼·çåºç¤æ¿ç­ï¼éä¹æ¯æåå¨ç¶é©ä¸è§å¯å°çãæåééè¨ç·´éç¨åªå¢é©è­å¨ (PAV) ä¾é©è­æåçèªªæ³ï¼ä»¥é æ¸¬å¨éäºè­æèä¸çé²åº¦ï¼ä¸¦é¡¯ç¤ºè ORM ç¸æ¯ï¼éå° PAV çæ¸¬è©¦æéæå°æºç¢ºåº¦æé«äº $>8\%$ï¼è¨ç®æçæé«äº $1.5-5\times$ãéé PAV çå¯éçåµé²è¡ç·ä¸ RLï¼ç²å¾äºæ¨£æ¬æçæé« $5-6\times$ãæºç¢ºåº¦æé« $>6\%$ çé¦æ¹çµæï¼åªæ¼ ORMã

##### **Insight Over Sight? Exploring the Vision-Knowledge Conflicts in Multimodal LLMs**
2410.08145v1 by Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu

This paper explores the problem of commonsense-level vision-knowledge
conflict in Multimodal Large Language Models (MLLMs), where visual information
contradicts model's internal commonsense knowledge (see Figure 1). To study
this issue, we introduce an automated pipeline, augmented with
human-in-the-loop quality control, to establish a benchmark aimed at simulating
and assessing the conflicts in MLLMs. Utilizing this pipeline, we have crafted
a diagnostic benchmark comprising 374 original images and 1,122 high-quality
question-answer (QA) pairs. This benchmark covers two types of conflict target
and three question difficulty levels, providing a thorough assessment tool.
Through this benchmark, we evaluate the conflict-resolution capabilities of
nine representative MLLMs across various model families and find a noticeable
over-reliance on textual queries. Drawing on these findings, we propose a novel
prompting strategy, "Focus-on-Vision" (FoV), which markedly enhances MLLMs'
ability to favor visual data over conflicting textual knowledge. Our detailed
analysis and the newly proposed strategy significantly advance the
understanding and mitigating of vision-knowledge conflicts in MLLMs. The data
and code are made publicly available.

æè¦ï¼æ¬ææ¢è¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¸­å¸¸è­å±¤ç´è¦è¦ºç¥è­è¡çªçåé¡ï¼å¶ä¸­è¦è¦ºè³è¨èæ¨¡åçå§é¨å¸¸è­ç¥è­ç¸çç¾ï¼è¦å 1ï¼ãçºäºç ç©¶éååé¡ï¼æåå¼é²äºä¸åèªååç®¡éï¼ä¸¦çµåäººå·¥è¿´ååè³ªæ§ç®¡ï¼ä»¥å»ºç«ä¸ååºæºï¼ç¨æ¼æ¨¡æ¬åè©ä¼° MLLM ä¸­çè¡çªãå©ç¨æ­¤ç®¡éï¼æåè£½ä½äºä¸åè¨ºæ·åºæºï¼åå« 374 å¼µåå§åçå 1,122 åé«åè³ªçåç­ (QA) éå°ãæ­¤åºæºæ¶µèå©ç¨®è¡çªç®æ¨åä¸ååé¡é£åº¦ç­ç´ï¼æä¾äºä¸åå¨é¢çè©ä¼°å·¥å·ãééæ­¤åºæºï¼æåè©ä¼°äºä¹åä»£è¡¨æ§ MLLM å¨ä¸åæ¨¡åç³»åä¸­çè¡çªè§£æ±ºè½åï¼ä¸¦ç¼ç¾æé¡¯éåº¦ä¾è³´æå­æ¥è©¢ãæ ¹æéäºç¼ç¾ï¼æåæåºäºä¸ç¨®æ°ç©çæç¤ºç­ç¥ãå°æ³¨æ¼è¦è¦ºã(FoV)ï¼å®é¡¯èå¢å¼·äº MLLM åªåè¦è¦ºè³æèéè¡çªæå­ç¥è­çè½åãæåè©³ç´°çåæåæ°æåºçç­ç¥å¤§å¹æ¨é²äºå° MLLM ä¸­è¦è¦ºç¥è­è¡çªççè§£åç·©è§£ãè³æåç¨å¼ç¢¼å·²å¬éæä¾ã

##### **DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory**
2410.08143v1 by Yutong Wang, Jiali Zeng, Xuebo Liu, Derek F. Wong, Fandong Meng, Jie Zhou, Min Zhang

Large language models (LLMs) have achieved reasonable quality improvements in
machine translation (MT). However, most current research on MT-LLMs still faces
significant challenges in maintaining translation consistency and accuracy when
processing entire documents. In this paper, we introduce DelTA, a
Document-levEL Translation Agent designed to overcome these limitations. DelTA
features a multi-level memory structure that stores information across various
granularities and spans, including Proper Noun Records, Bilingual Summary,
Long-Term Memory, and Short-Term Memory, which are continuously retrieved and
updated by auxiliary LLM-based components. Experimental results indicate that
DelTA significantly outperforms strong baselines in terms of translation
consistency and quality across four open/closed-source LLMs and two
representative document translation datasets, achieving an increase in
consistency scores by up to 4.58 percentage points and in COMET scores by up to
3.16 points on average. DelTA employs a sentence-by-sentence translation
strategy, ensuring no sentence omissions and offering a memory-efficient
solution compared to the mainstream method. Furthermore, DelTA improves pronoun
translation accuracy, and the summary component of the agent also shows promise
as a tool for query-based summarization tasks. We release our code and data at
https://github.com/YutongWang1216/DocMTAgent.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ©å¨ç¿»è­¯ (MT) ä¸­ç²å¾äºåççåè³ªæåãç¶èï¼ç®åå¤§å¤æ¸éæ¼ MT-LLM çç ç©¶å¨èçå®æ´æä»¶æï¼å¨ç¶­æç¿»è­¯çä¸è´æ§åæºç¢ºæ§æ¹é¢ä»é¢è¨éå¤§ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äº DelTAï¼éæ¯ä¸åæä»¶ç´å¥ç¿»è­¯ä»£çï¼æ¨å¨åæéäºéå¶ãDelTA å·æå¤å±¤ç´è¨æ¶é«çµæ§ï¼å¯å¨åç¨®ç²åº¦åç¯åå§å²å­è³è¨ï¼åæ¬å°æåè©è¨éãéèªæè¦ãé·æè¨æ¶é«åç­æè¨æ¶é«ï¼éäºè¨æ¶é«æç±è¼å©çåºæ¼ LLM ççµä»¶æçºæ·ååæ´æ°ãå¯¦é©çµæè¡¨æï¼å¨ç¿»è­¯ä¸è´æ§ååè³ªæ¹é¢ï¼DelTA æé¡¯åªæ¼å¼·å¤§çåºæºï¼æ¶µèååéæ¾/éæº LLM åå©åå·ä»£è¡¨æ§çæä»¶ç¿»è­¯è³æéï¼å¨ä¸è´æ§è©åæ¹é¢æé«äºå¤é 4.58 åç¾åé»ï¼å¨ COMET è©åæ¹é¢å¹³åæé«äºå¤é 3.16 åãDelTA æ¡ç¨éå¥ç¿»è­¯ç­ç¥ï¼ç¢ºä¿ä¸éºæ¼å¥å­ï¼ä¸¦æä¾èä¸»æµæ¹æ³ç¸æ¯è¨æ¶é«æçé«çè§£æ±ºæ¹æ¡ãæ­¤å¤ï¼DelTA æ¹åäºä»£åè©ç¿»è­¯çæºç¢ºæ§ï¼èä»£ççæè¦çµä»¶ä¹é¡¯ç¤ºåºä½çºåºæ¼æ¥è©¢çæè¦ä»»åå·¥å·çæ½åãæåå¨ https://github.com/YutongWang1216/DocMTAgent éåºæåçç¨å¼ç¢¼åè³æã

##### **Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction**
2410.08134v1 by Jarrid Rector-Brooks, Mohsin Hasan, Zhangzhi Peng, Zachary Quinn, Chenghao Liu, Sarthak Mittal, Nouha Dziri, Michael Bronstein, Yoshua Bengio, Pranam Chatterjee, Alexander Tong, Avishek Joey Bose

Generative modeling of discrete data underlies important applications
spanning text-based agents like ChatGPT to the design of the very building
blocks of life in protein sequences. However, application domains need to exert
control over the generated data by steering the generative process - typically
via RLHF - to satisfy a specified property, reward, or affinity metric. In this
paper, we study the problem of steering Masked Diffusion Models (MDMs), a
recent class of discrete diffusion models that offer a compelling alternative
to traditional autoregressive models. We introduce Discrete Denoising Posterior
Prediction (DDPP), a novel framework that casts the task of steering
pre-trained MDMs as a problem of probabilistic inference by learning to sample
from a target Bayesian posterior. Our DDPP framework leads to a family of three
novel objectives that are all simulation-free, and thus scalable while applying
to general non-differentiable reward functions. Empirically, we instantiate
DDPP by steering MDMs to perform class-conditional pixel-level image modeling,
RLHF-based alignment of MDMs using text-based rewards, and finetuning protein
language models to generate more diverse secondary structures and shorter
proteins. We substantiate our designs via wet-lab validation, where we observe
transient expression of reward-optimized protein sequences.

æè¦ï¼çæå¼ç¦»æ£æ°æ®å»ºæ¨¡æ¯éè¦åºç¨çåºç¡ï¼æ¶µçäºåºäºææ¬çä»£çï¼å¦ ChatGPTï¼å°èç½è´¨åºåä¸­çå½åºæ¬ç»æé¨åçè®¾è®¡ãç¶èï¼åºç¨é¢åéè¦éè¿æ§å¶çæè¿ç¨ï¼éå¸¸éè¿ RLHFï¼æ¥æ§å¶çæçæ°æ®ï¼ä»¥æ»¡è¶³æå®çå±æ§ãå¥å±æäº²ååº¦ææ ãå¨æ¬æä¸­ï¼æä»¬ç ç©¶äºæ§å¶æ©ç æ©æ£æ¨¡å (MDM) çé®é¢ï¼MDM æ¯ç¦»æ£æ©æ£æ¨¡åçææ°ç±»å«ï¼ä¸ºä¼ ç»çèªåå½æ¨¡åæä¾äºå¼äººæ³¨ç®çæ¿ä»£æ¹æ¡ãæä»¬å¼å¥äºç¦»æ£å»åªåéªé¢æµ (DDPP)ï¼è¿æ¯ä¸ç§æ°é¢çæ¡æ¶ï¼å®å°æ§å¶é¢è®­ç» MDM çä»»å¡è½¬åä¸ºæ¦çæ¨çé®é¢ï¼æ¹æ³æ¯å­¦ä¹ ä»ç®æ è´å¶æ¯åéªä¸­éæ ·ãæä»¬ç DDPP æ¡æ¶äº§çäºä¸ç³»åä¸ä¸ªæ°é¢çç®æ ï¼å®ä»¬é½æ¯æ æ¨¡æçï¼å æ­¤å¨åºç¨äºä¸è¬ä¸å¯å¾®åå¥å±å½æ°æ¶å·æå¯æ©å±æ§ãå­ç»éªï¼æä»¬éè¿æ§å¶ MDM æ¥æ§è¡åºäºç±»çåç´ çº§å¾åå»ºæ¨¡ãä½¿ç¨åºäºææ¬å¥å±ç MDM ç RLHF å¯¹é½ï¼ä»¥åå¾®è°èç½è´¨è¯­è¨æ¨¡åæ¥çææ´å¤æ ·åçäºçº§ç»æåæ´ç­çèç½è´¨ï¼ä»èå®ä¾å DDPPãæä»¬éè¿æ¹¿å®éªå®¤éªè¯æ¥è¯å®æä»¬çè®¾è®¡ï¼å¨è¯¥éªè¯ä¸­ï¼æä»¬è§å¯å°äºå¥å±ä¼åèç½è´¨åºåçç¬æ¶è¡¨è¾¾ã

##### **Assessing Episodic Memory in LLMs with Sequence Order Recall Tasks**
2410.08133v1 by Mathis Pink, Vy A. Vo, Qinyuan Wu, Jianing Mu, Javier S. Turek, Uri Hasson, Kenneth A. Norman, Sebastian Michelmann, Alexander Huth, Mariya Toneva

Current LLM benchmarks focus on evaluating models' memory of facts and
semantic relations, primarily assessing semantic aspects of long-term memory.
However, in humans, long-term memory also includes episodic memory, which links
memories to their contexts, such as the time and place they occurred. The
ability to contextualize memories is crucial for many cognitive tasks and
everyday functions. This form of memory has not been evaluated in LLMs with
existing benchmarks. To address the gap in evaluating memory in LLMs, we
introduce Sequence Order Recall Tasks (SORT), which we adapt from tasks used to
study episodic memory in cognitive psychology. SORT requires LLMs to recall the
correct order of text segments, and provides a general framework that is both
easily extendable and does not require any additional annotations. We present
an initial evaluation dataset, Book-SORT, comprising 36k pairs of segments
extracted from 9 books recently added to the public domain. Based on a human
experiment with 155 participants, we show that humans can recall sequence order
based on long-term memory of a book. We find that models can perform the task
with high accuracy when relevant text is given in-context during the SORT
evaluation. However, when presented with the book text only during training,
LLMs' performance on SORT falls short. By allowing to evaluate more aspects of
memory, we believe that SORT will aid in the emerging development of
memory-augmented models.

æè¦ï¼ç¾æç LLM åºæºå´éæ¼è©ä¼°æ¨¡åå°äºå¯¦åèªç¾©éä¿çè¨æ¶ï¼ä¸»è¦è©ä¼°é·æè¨æ¶çèªç¾©æ¹é¢ãç¶èï¼å¨äººé¡ä¸­ï¼é·æè¨æ¶ä¹åæ¬æç¯è¨æ¶ï¼å®å°è¨æ¶èå¶èæ¯è¯ç¹«èµ·ä¾ï¼ä¾å¦å®åç¼ççæéåå°é»ãå°è¨æ¶æå¢åçè½åå°æ¼è¨±å¤èªç¥ä»»ååæ¥å¸¸åè½è³ééè¦ãéç¨®å½¢å¼çè¨æ¶å°æªå¨ç¾æåºæºä¸­ä½¿ç¨ LLM é²è¡è©ä¼°ãçºäºè§£æ±ºè©ä¼° LLM ä¸­è¨æ¶çå·®è·ï¼æåå¼å¥äºåºåé åºå¬åä»»å (SORT)ï¼æåæ ¹æç¨æ¼ç ç©¶èªç¥å¿çå­¸ä¸­æç¯è¨æ¶çä»»åå°å¶é²è¡äºæ¹ç·¨ãSORT è¦æ± LLM å¬åææ¬çæ®µçæ­£ç¢ºé åºï¼ä¸¦æä¾äºä¸åæ¢å®¹ææ´å±åä¸éè¦ä»»ä½é¡å¤è¨»éçéç¨æ¡æ¶ãæåæåºäºåå§è©ä¼°æ¸æé Book-SORTï¼å¶ä¸­åå«å¾æè¿æ·»å å°å¬å±é åç 9 æ¬æ¸ä¸­æåç 36k å°çæ®µãæ ¹æå° 155 ååèèçå¯¦é©ï¼æåè¡¨æäººé¡å¯ä»¥æ ¹æä¸æ¬æ¸çé·æè¨æ¶ä¾åæ¶åºåé åºãæåç¼ç¾ï¼ç¶å¨ SORT è©ä¼°æéå¨ä¸ä¸æä¸­çµ¦åºç¸éææ¬æï¼æ¨¡åå¯ä»¥éå¸¸æºç¢ºå°å·è¡ä»»åãç¶èï¼ç¶å¨è¨ç·´æéåæä¾æ¸ç±ææ¬æï¼LLM å¨ SORT ä¸çè¡¨ç¾æä¸éãééåè¨±è©ä¼°è¨æ¶çæ´å¤æ¹é¢ï¼æåç¸ä¿¡ SORT å°æå©æ¼è¨æ¶å¢å¼·æ¨¡åçæ°èç¼å±ã

##### **Think Beyond Size: Dynamic Prompting for More Effective Reasoning**
2410.08130v1 by Kamesh R

This paper presents Dynamic Prompting, a novel framework aimed at improving
the reasoning capabilities of Large Language Models (LLMs). In contrast to
conventional static prompting methods, Dynamic Prompting enables the adaptive
modification of prompt sequences and step counts based on real-time task
complexity and model performance. This dynamic adaptation facilitates more
efficient problem-solving, particularly in smaller models, by reducing
hallucinations and repetitive cycles. Our empirical evaluations demonstrate
that Dynamic Prompting allows smaller LLMs to perform competitively with much
larger models, thereby challenging the conventional emphasis on model size as
the primary determinant of reasoning efficacy.

æè¦ï¼æ¬ææåºåææç¤ºï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨æ¹åå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãèå³çµ±çéææç¤ºæ¹æ³ç¸æ¯ï¼åææç¤ºè½å¤ æ ¹æå¯¦æä»»åè¤éåº¦åæ¨¡åæè½ï¼èªé©æå°ä¿®æ¹æç¤ºåºååæ­¥é©æ¸ãéç¨®åæé©ææå©æ¼æ´ææå°è§£æ±ºåé¡ï¼ç¹å¥æ¯å¨è¼å°çæ¨¡åä¸­ï¼å çºå®è½æ¸å°å¹»è¦ºåéè¤çå¾ªç°ãæåçå¯¦è­è©ä¼°è¡¨æï¼åææç¤ºè®è¼å°ç LLM è½èè¼å¤§çæ¨¡åç«¶ç­ï¼å¾èææ°äºå³çµ±ä¸å¼·èª¿æ¨¡åå¤§å°ä½çºæ¨çæè½ä¸»è¦æ±ºå®å ç´ çè§é»ã

##### **Mars: Situated Inductive Reasoning in an Open-World Environment**
2410.08126v1 by Xiaojuan Tang, Jiaqi Li, Yitao Liang, Song-chun Zhu, Muhan Zhang, Zilong Zheng

Large Language Models (LLMs) trained on massive corpora have shown remarkable
success in knowledge-intensive tasks. Yet, most of them rely on pre-stored
knowledge. Inducing new general knowledge from a specific environment and
performing reasoning with the acquired knowledge -- \textit{situated inductive
reasoning}, is crucial and challenging for machine intelligence. In this paper,
we design Mars, an interactive environment devised for situated inductive
reasoning. It introduces counter-commonsense game mechanisms by modifying
terrain, survival setting and task dependency while adhering to certain
principles. In Mars, agents need to actively interact with their surroundings,
derive useful rules and perform decision-making tasks in specific contexts. We
conduct experiments on various RL-based and LLM-based methods, finding that
they all struggle on this challenging situated inductive reasoning benchmark.
Furthermore, we explore \textit{Induction from Reflection}, where we instruct
agents to perform inductive reasoning from history trajectory. The superior
performance underscores the importance of inductive reasoning in Mars. Through
Mars, we aim to galvanize advancements in situated inductive reasoning and set
the stage for developing the next generation of AI systems that can reason in
an adaptive and context-sensitive way.

æè¦ï¼<paragraph>å¨é¾å¤§èªæåº«ä¸è¨ç·´çå¤§åèªè¨æ¨¡å (LLM) å·²å¨ç¥è­å¯éåä»»åä¸­å±ç¾åºé©äººçææãç¶èï¼å®åå¤§å¤ä¾è³´æ¼é åå²å­çç¥è­ãå¾ç¹å®ç°å¢ä¸­æ¨æ¼åºæ°çå¸¸è­ï¼ä¸¦å©ç¨ç²å¾çç¥è­é²è¡æ¨çââãæå¢æ­¸ç´æ¨çãï¼å°æ¼æ©å¨æºæ§èè¨è³ééè¦ä¸å·æææ°æ§ãå¨æ¬æä¸­ï¼æåè¨­è¨äºç«æï¼ä¸åå°çºæå¢æ­¸ç´æ¨çèè¨­è¨çäºåå¼ç°å¢ãå®ééä¿®æ¹å°å½¢ãçå­è¨­å®åä»»åä¾è³´éä¿ï¼å¼å¥äºåå¸¸è­çéæ²æ©å¶ï¼åæéµå®æäºååãå¨ç«æä¸­ï¼ä»£çäººéè¦ç©æ¥µèå¨åç°å¢äºåï¼æ¨å°åºæç¨çè¦åï¼ä¸¦å¨ç¹å®æå¢ä¸­å·è¡æ±ºç­ä»»åãæåå°åç¨®åºæ¼ RL ååºæ¼ LLM çæ¹æ³é²è¡å¯¦é©ï¼ç¼ç¾å®åå¨éåå·æææ°æ§çæå¢æ­¸ç´æ¨çåºæºä¸é½é¢è¨å°é£ãæ­¤å¤ï¼æåæ¢è¨äºãå¾åæä¸­æ­¸ç´ãï¼å¶ä¸­æåæç¤ºä»£çäººå¾æ­·å²è»è·¡ä¸­å·è¡æ­¸ç´æ¨çãåªç°çè¡¨ç¾å¼·èª¿äºæ­¸ç´æ¨çå¨ç«æä¸­çéè¦æ§ãééç«æï¼æåæ¨å¨æ¿åµæå¢æ­¸ç´æ¨ççé²å±ï¼ä¸¦çºéç¼ä¸ä¸ä»£è½å¤ ä»¥é©ææ§åæå¢ææçæ¹å¼æ¨ççäººå·¥æºæ§ç³»çµ±å¥ å®åºç¤ã</paragraph>

##### **Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection**
2410.08121v1 by Moirangthem Tiken Singh, Rabinder Kumar Prasad, Gurumayum Robert Michael, N K Kaphungkui, N. Hemarjit Singh

The digital revolution has significantly impacted financial transactions,
leading to a notable increase in credit card usage. However, this convenience
comes with a trade-off: a substantial rise in fraudulent activities.
Traditional machine learning methods for fraud detection often struggle to
capture the inherent interconnectedness within financial data. This paper
proposes a novel approach for credit card fraud detection that leverages Graph
Neural Networks (GNNs) with attention mechanisms applied to heterogeneous graph
representations of financial data. Unlike homogeneous graphs, heterogeneous
graphs capture intricate relationships between various entities in the
financial ecosystem, such as cardholders, merchants, and transactions,
providing a richer and more comprehensive data representation for fraud
analysis. To address the inherent class imbalance in fraud data, where genuine
transactions significantly outnumber fraudulent ones, the proposed approach
integrates an autoencoder. This autoencoder, trained on genuine transactions,
learns a latent representation and flags deviations during reconstruction as
potential fraud. This research investigates two key questions: (1) How
effectively can a GNN with an attention mechanism detect and prevent credit
card fraud when applied to a heterogeneous graph? (2) How does the efficacy of
the autoencoder with attention approach compare to traditional methods? The
results are promising, demonstrating that the proposed model outperforms
benchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR
of 0.89 and an F1-score of 0.81. This research significantly advances fraud
detection systems and the overall security of financial transactions by
leveraging GNNs with attention mechanisms and addressing class imbalance
through an autoencoder.

æè¦ï¼<paragraph>æ¸ä½é©å½å°éèäº¤æç¢çéå¤§å½±é¿ï¼å°è´ä¿¡ç¨å¡ä½¿ç¨çå¤§å¹å¢å ãç¶èï¼éç¨®ä¾¿å©æ§ä¹å¸¶ä¾äºä¸ååæ¨ï¼è©é¨æ´»åå¤§å¹å¢å ãå³çµ±çæ©å¨å­¸ç¿æ¹æ³å¸¸é£ä»¥ææéèè³æä¸­åºæçç¸äºéè¯æ§ãæ¬ææåºäºä¸ç¨®æ°çä¿¡ç¨å¡è©é¨åµæ¸¬æ¹æ³ï¼å®å©ç¨åç¥ç¶ç¶²è·¯ (GNN) åæ³¨ææ©å¶ï¼æç¨æ¼éèè³æçç°è³ªåè¡¨è¡¨ç¤ºãèåè³ªåè¡¨ä¸åï¼ç°è³ªåè¡¨ææäºéèçæç³»çµ±ä¸­åç¨®å¯¦é«ä¹éçè¤ééä¿ï¼ä¾å¦æå¡äººãåå®¶åäº¤æï¼çºè©é¨åææä¾æ´è±å¯ãæ´å¨é¢çè³æè¡¨ç¤ºãçºäºè§£æ±ºè©é¨è³æä¸­åºæçé¡å¥ä¸å¹³è¡¡åé¡ï¼å¶ä¸­çå¯¦äº¤æé å¤æ¼è©é¨äº¤æï¼ææåºçæ¹æ³æ´åäºä¸åèªåç·¨ç¢¼å¨ãéåèªåç·¨ç¢¼å¨å¨çå¯¦äº¤æä¸­è¨ç·´ï¼å­¸ç¿æ½å¨è¡¨ç¤ºï¼ä¸¦å¨éå»ºéç¨ä¸­æ¨è¨åå·®çºæ½å¨è©é¨ãæ¬ç ç©¶æ¢è¨äºå©åééµåé¡ï¼(1) ç¶æç¨æ¼ç°è³ªåè¡¨æï¼å·ææ³¨æåæ©å¶ç GNN å¨åµæ¸¬åé é²ä¿¡ç¨å¡è©é¨æ¹é¢æå¤ææï¼(2) å·ææ³¨æåæ¹æ³çèªåç·¨ç¢¼å¨çæè½èå³çµ±æ¹æ³ç¸æ¯å¦ä½ï¼çµæä»¤äººæ»¿æï¼è­æææåºçæ¨¡ååªæ¼åºæºæ¼ç®æ³ï¼ä¾å¦ Graph Sage å FI-GRLï¼éå° 0.89 çåªç° AUC-PR å 0.81 ç F1 åæ¸ãæ¬ç ç©¶ééå©ç¨å·ææ³¨æåæ©å¶ç GNNï¼ä¸¦ééèªåç·¨ç¢¼å¨è§£æ±ºé¡å¥ä¸å¹³è¡¡åé¡ï¼å¤§å¹æåäºè©é¨åµæ¸¬ç³»çµ±åéèäº¤æçæ´é«å®å¨æ§ã</paragraph>

##### **Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System**
2410.08115v1 by Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun

Large Language Model (LLM) based multi-agent systems (MAS) show remarkable
potential in collaborative problem-solving, yet they still face critical
challenges: low communication efficiency, poor scalability, and a lack of
effective parameter-updating optimization methods. We present Optima, a novel
framework that addresses these issues by significantly enhancing both
communication efficiency and task effectiveness in LLM-based MAS through LLM
training. Optima employs an iterative generate, rank, select, and train
paradigm with a reward function balancing task performance, token efficiency,
and communication readability. We explore various RL algorithms, including
Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid
approaches, providing insights into their effectiveness-efficiency trade-offs.
We integrate Monte Carlo Tree Search-inspired techniques for DPO data
generation, treating conversation turns as tree nodes to explore diverse
interaction paths. Evaluated on common multi-agent tasks, including
information-asymmetric question answering and complex reasoning, Optima shows
consistent and substantial improvements over single-agent baselines and vanilla
MAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than
10\% tokens on tasks requiring heavy information exchange. Moreover, Optima's
efficiency gains open new possibilities for leveraging inference-compute more
effectively, leading to improved inference-time scaling laws. By addressing
fundamental challenges in LLM-based MAS, Optima shows the potential towards
scalable, efficient, and effective MAS
(https://chenweize1998.github.io/optima-project-page).

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) çºåºç¤çå¤éä»£çç³»çµ± (MAS) å¨åä½åé¡è§£æ±ºæ¹é¢å±ç¾äºéå¡çæ½åï¼ä½ä»é¢è¨ééµææ°ï¼ä½æºéæçãå¯æ´åæ§å·®ï¼ä»¥åç¼ºä¹ææçåæ¸æ´æ°æä½³åæ¹æ³ãæåæåº Optimaï¼ä¸åæ°ç©çæ¶æ§ï¼éé LLM è¨ç·´å¤§å¹æå LLM çºåºç¤ç MAS ä¸­çæºéæçåä»»åæè½ï¼ä¾è§£æ±ºéäºåé¡ãOptima æ¡ç¨åè¦çæãæåãé¸æåè¨ç·´çç¯ä¾ï¼å¶çåµå½æ¸å¹³è¡¡äºä»»åè¡¨ç¾ãç¬¦èæçåæºéå¯è®æ§ãæåæ¢è¨äºåç¨® RL æ¼ç®æ³ï¼åæ¬ç£ç£å¾®èª¿ãç´æ¥åå¥½æä½³åï¼ä»¥åå¶æ··åæ¹æ³ï¼é²ä¸æ­¥äºè§£å¶æè½æççæ¬è¡¡åæ¨ãæåæ´åäºèå°å¡ç¾æ¨¹çæå°åç¼çæè¡ï¼ç¨æ¼ DPO è³æç¢çï¼å°å°è©±ååè¦çºæ¨¹çç¯é»ï¼ä»¥æ¢ç´¢å¤æ¨£åçäºåè·¯å¾ãå¨å¸¸è¦çå¤éä»£çä»»åä¸­é²è¡è©ä¼°ï¼åæ¬è³è¨ä¸å°ç¨±åç­åè¤éæ¨çï¼Optima å¨å®ä¸ä»£çåºæºååºæ¼ Llama 3 8B çé¦è MAS ä¸å±ç¾äºä¸è´ä¸é¡¯èçé²æ­¥ï¼å¨éè¦å¤§éè³è¨äº¤æçä»»åä¸­ï¼ä»¥ä¸å° 10% çç¬¦èç²å¾äºé«é 2.8 åçæè½æåãæ­¤å¤ï¼Optima çæçæåçºæ´ææå°éç¨æ¨çéç®éåäºæ°çå¯è½æ§ï¼é²èæ¹åæ¨çæéçç¸®æ¾å®å¾ãééè§£æ±º LLM çºåºç¤ç MAS ä¸­çåºæ¬ææ°ï¼Optima å±ç¾äºéåå¯æ´åãé«æåææç MAS çæ½å
(https://chenweize1998.github.io/optima-project-page)ã</paragraph>

##### **Robust AI-Generated Text Detection by Restricted Embeddings**
2410.08113v1 by Kristian Kuznetsov, Eduard Tulchinskii, Laida Kushnareva, German Magai, Serguei Barannikov, Sergey Nikolenko, Irina Piontkovskaya

Growing amount and quality of AI-generated texts makes detecting such content
more difficult. In most real-world scenarios, the domain (style and topic) of
generated data and the generator model are not known in advance. In this work,
we focus on the robustness of classifier-based detectors of AI-generated text,
namely their ability to transfer to unseen generators or semantic domains. We
investigate the geometry of the embedding space of Transformer-based text
encoders and show that clearing out harmful linear subspaces helps to train a
robust classifier, ignoring domain-specific spurious features. We investigate
several subspace decomposition and feature selection strategies and achieve
significant improvements over state of the art methods in cross-domain and
cross-generator transfer. Our best approaches for head-wise and
coordinate-based subspace removal increase the mean out-of-distribution (OOD)
classification score by up to 9% and 14% in particular setups for RoBERTa and
BERT embeddings respectively. We release our code and data:
https://github.com/SilverSolver/RobustATD

æè¦ï¼äººå·¥æºè½çæææ¬çæ°éåè´¨éä¸æ­æé«ï¼ä½¿å¾æ£æµæ­¤ç±»åå®¹åå¾æ´å å°é¾ãå¨å¤§å¤æ°å®éåºæ¯ä¸­ï¼çææ°æ®çåï¼æ ·å¼åä¸»é¢ï¼åçæå¨æ¨¡åäºåå¹¶ä¸ç¥éãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬ä¸æ³¨äºåºäºåç±»å¨ç AI çæçææ¬æ£æµå¨çé²æ£æ§ï¼å³å®ä»¬è½¬ç§»å°æªè§ççæå¨æè¯­ä¹åçè½åãæä»¬ç ç©¶äºåºäº Transformer çææ¬ç¼ç å¨çåµå¥ç©ºé´çå ä½å½¢ç¶ï¼å¹¶è¡¨ææ¸é¤æå®³ççº¿æ§å­ç©ºé´æå©äºè®­ç»é²æ£åç±»å¨ï¼å¿½ç¥ç¹å®äºåçèåç¹å¾ãæä»¬ç ç©¶äºå ä¸ªå­ç©ºé´åè§£åç¹å¾éæ©ç­ç¥ï¼å¹¶å¨è·¨ååè·¨çæå¨è½¬ç§»ä¸­å®ç°äºå¯¹ç°æææ¯çéå¤§æ¹è¿ãæä»¬ç¨äºéå¤´ååºäºåæ çå­ç©ºé´ç§»é¤çæä½³æ¹æ³å°å¹³ååå¸å¤ (OOD) åç±»åæ°åå«æé«äº RoBERTa å BERT åµå¥çç¹å®è®¾ç½®ä¸­ç 9% å 14%ãæä»¬åå¸æä»¬çä»£ç åæ°æ®ï¼https://github.com/SilverSolver/RobustATD

##### **Active Fourier Auditor for Estimating Distributional Properties of ML Models**
2410.08111v1 by Ayoub Ajarra, Bishwamittra Ghosh, Debabrota Basu

With the pervasive deployment of Machine Learning (ML) models in real-world
applications, verifying and auditing properties of ML models have become a
central concern. In this work, we focus on three properties: robustness,
individual fairness, and group fairness. We discuss two approaches for auditing
ML model properties: estimation with and without reconstruction of the target
model under audit. Though the first approach is studied in the literature, the
second approach remains unexplored. For this purpose, we develop a new
framework that quantifies different properties in terms of the Fourier
coefficients of the ML model under audit but does not parametrically
reconstruct it. We propose the Active Fourier Auditor (AFA), which queries
sample points according to the Fourier coefficients of the ML model, and
further estimates the properties. We derive high probability error bounds on
AFA's estimates, along with the worst-case lower bounds on the sample
complexity to audit them. Numerically we demonstrate on multiple datasets and
models that AFA is more accurate and sample-efficient to estimate the
properties of interest than the baselines.

æè¦ï¼é¨èæ©å¨å­¸ç¿ (ML) æ¨¡åå¨å¯¦éæç¨ä¸­å»£æ³é¨ç½²ï¼é©è­åå¯©æ ¸ ML æ¨¡åçå±¬æ§å·²æçºä¸é æ ¸å¿éæ³¨äºé ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼ä¸åå±¬æ§ï¼ç©©å¥æ§ãåå¥å¬å¹³æ§åç¾¤é«å¬å¹³æ§ãæåè¨è«äºå¯©æ ¸ ML æ¨¡åå±¬æ§çå©ç¨®æ¹æ³ï¼å¨æåæ²æéå»ºå¯©æ ¸ç®æ¨æ¨¡åçææ³ä¸é²è¡ä¼°è¨ãåç®¡ç¬¬ä¸ç¨®æ¹æ³å¨æç»ä¸­å¾å°äºç ç©¶ï¼ä½ç¬¬äºç¨®æ¹æ³ä»æªå¾å°æ¢ç´¢ãçºæ­¤ï¼æåéç¼äºä¸åæ°çæ¡æ¶ï¼è©²æ¡æ¶æ ¹æå¯©æ ¸ä¸­ç ML æ¨¡åçåç«èä¿æ¸å°ä¸åçå±¬æ§é²è¡éåï¼ä½ä¸æå°å¶é²è¡åæ¸åéå»ºãæåæåºäºä¸»ååç«èå¯©æ ¸å¨ (AFA)ï¼å®æ ¹æ ML æ¨¡åçåç«èä¿æ¸æ¥è©¢æ¨£æ¬é»ï¼ä¸¦é²ä¸æ­¥ä¼°è¨å±¬æ§ãæåæ¨å°åº AFA ä¼°è¨çé«æ©çèª¤å·®çéï¼ä»¥åå¯©æ ¸å®åçæ¨£æ¬è¤éåº¦çæå£ææ³ä¸çãæåå¨å¤åæ¸æéåæ¨¡åä¸æ¸å¼è­æï¼AFA æ¯åºæºç·æ´æºç¢ºä¸æ´å·æ¨£æ¬æçï¼å¯ä»¥ä¼°è¨æèè¶£çå±¬æ§ã

##### **A Closer Look at Machine Unlearning for Large Language Models**
2410.08109v1 by Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin

Large language models (LLMs) may memorize sensitive or copyrighted content,
raising privacy and legal concerns. Due to the high cost of retraining from
scratch, researchers attempt to employ machine unlearning to remove specific
content from LLMs while preserving the overall performance. In this paper, we
discuss several issues in machine unlearning for LLMs and provide our insights
on possible approaches. To address the issue of inadequate evaluation of model
outputs after unlearning, we introduce three additional metrics to evaluate
token diversity, sentence semantics, and factual correctness. We then
categorize unlearning methods into untargeted and targeted, and discuss their
issues respectively. Specifically, the behavior that untargeted unlearning
attempts to approximate is unpredictable and may involve hallucinations, and
existing regularization is insufficient for targeted unlearning. To alleviate
these issues, we propose using the objective of maximizing entropy (ME) for
untargeted unlearning and incorporate answer preservation (AP) loss as
regularization for targeted unlearning. Experimental results across three
scenarios, i.e., fictitious unlearning, continual unlearning, and real-world
unlearning, demonstrate the effectiveness of our approaches. The code is
available at https://github.com/sail-sg/closer-look-LLM-unlearning.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¯è½æè¨æ¶æææåçæ¬ä¿è­·çå§å®¹ï¼å¼ç¼é±ç§åæ³å¾åé¡ãç±æ¼å¾é ­éå§éæ°è¨ç·´çææ¬å¾é«ï¼ç ç©¶äººå¡åè©¦æ¡ç¨æ©å¨éºå¿ä¾ç§»é¤ LLM ä¸­çç¹å®å§å®¹ï¼åæä¿çæ´é«æè½ãå¨æ¬æä¸­ï¼æåè¨è«äº LLM æ©å¨éºå¿çå¹¾ååé¡ï¼ä¸¦æä¾æåå°å¯è½æ¹æ³çè¦è§£ãçºäºè§£æ±ºéºå¿å¾æ¨¡åè¼¸åºçè©ä¼°ä¸è¶³åé¡ï¼æåå¼å¥äºä¸åé¡å¤çææ¨ä¾è©ä¼°ä»£å¹£å¤æ¨£æ§ãå¥å­èªç¾©åäºå¯¦æ­£ç¢ºæ§ãç¶å¾ï¼æåå°éºå¿æ¹æ³åé¡çºéç®æ¨åç®æ¨ï¼ä¸¦åå¥è¨è«å®åçåé¡ãå·é«ä¾èªªï¼éç®æ¨éºå¿åè©¦è¿ä¼¼çè¡çºæ¯ä¸å¯é æ¸¬çï¼å¯è½æ¶åå¹»è¦ºï¼èç¾æçæ­£ååä¸è¶³ä»¥é²è¡ç®æ¨éºå¿ãçºäºç·©è§£éäºåé¡ï¼æåå»ºè­°ä½¿ç¨æå¤§åçµ (ME) çç®æ¨é²è¡éç®æ¨éºå¿ï¼ä¸¦å°ç­æ¡ä¿ç (AP) æå¤±ç´å¥ç®æ¨éºå¿çæ­£ååãå¨èæ§éºå¿ãæçºéºå¿åçå¯¦ä¸çéºå¿éä¸ç¨®å ´æ¯ä¸­çå¯¦é©çµæè­æäºæåæ¹æ³çæææ§ãç¨å¼ç¢¼å¯å¨ https://github.com/sail-sg/closer-look-LLM-unlearning åå¾ã

##### **What Makes Large Language Models Reason in (Multi-Turn) Code Generation?**
2410.08105v1 by Kunhao Zheng, Juliette Decugis, Jonas Gehring, Taco Cohen, Benjamin Negrevergne, Gabriel Synnaeve

Prompting techniques such as chain-of-thought have established themselves as
a popular vehicle for improving the outputs of large language models (LLMs).
For code generation, however, their exact mechanics and efficacy are
under-explored. We thus investigate the effects of a wide range of prompting
strategies with a focus on automatic re-prompting over multiple turns and
computational requirements. After systematically decomposing reasoning,
instruction, and execution feedback prompts, we conduct an extensive grid
search on the competitive programming benchmarks CodeContests and TACO for
multiple LLM families and sizes (Llama 3.0 and 3.1, 8B, 70B, 405B, and GPT-4o).
Our study reveals strategies that consistently improve performance across all
models with small and large sampling budgets. We then show how finetuning with
such an optimal configuration allows models to internalize the induced
reasoning process and obtain improvements in performance and scalability for
multi-turn code generation.

æè¦ï¼æç¤ºæè¡ï¼ä¾å¦ææ³éï¼å·²ç¢ºç«çºæ¹åå¤§åèªè¨æ¨¡å (LLM) è¼¸åºçç±éè¼é«ã
ç¶èï¼å°æ¼ç¨å¼ç¢¼ç¢çï¼å®åç¢ºåçæ©å¶åæåå°æªå¾å°ååæ¢è¨ãå æ­¤ï¼æåç ç©¶äºåç¨®æç¤ºç­ç¥çå½±é¿ï¼éé»éæ³¨å¤è¼ªèªåéæ°æç¤ºåéç®éæ±ãå¨ç³»çµ±åè§£æ¨çãæä»¤åå·è¡åé¥æç¤ºå¾ï¼æåå°ç«¶ç­æ§ç¨å¼è¨­è¨åºæº CodeContests å TACO é²è¡äºå»£æ³çç¶²æ ¼æå°ï¼ä»¥æ¶µèå¤å LLM å®¶æåè¦æ¨¡ï¼Llama 3.0 å 3.1ã8Bã70Bã405B å GPT-4oï¼ã
æåçç ç©¶æ­ç¤ºäºå¨æææ¨¡åä¸­æçºæ¹åæè½çç­ç¥ï¼éäºæ¨¡åå·æå°åå¤§æ½æ¨£é ç®ãç¶å¾ï¼æåå±ç¤ºäºå¦ä½ä½¿ç¨æ­¤é¡æä½³éç½®é²è¡å¾®èª¿ï¼ä½¿æ¨¡åè½å¤ å§åèªå°æ¨çéç¨ï¼ä¸¦ç²å¾å¤è¼ªç¨å¼ç¢¼ç¢ççæè½åå¯æ´åæ§æ¹åã

##### **Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining**
2410.08102v1 by Tianyi Bai, Ling Yang, Zhen Hao Wong, Jiahui Peng, Xinlin Zhuang, Chi Zhang, Lijun Wu, Qiu Jiantao, Wentao Zhang, Binhang Yuan, Conghui He

Efficient data selection is crucial to accelerate the pretraining of large
language models (LLMs). While various methods have been proposed to enhance
data efficiency, limited research has addressed the inherent conflicts between
these approaches to achieve optimal data selection for LLM pretraining. To
tackle this problem, we propose a novel multi-agent collaborative data
selection mechanism. In this framework, each data selection method serves as an
independent agent, and an agent console is designed to dynamically integrate
the information from all agents throughout the LLM training process. We conduct
extensive empirical studies to evaluate our multi-agent framework. The
experimental results demonstrate that our approach significantly improves data
efficiency, accelerates convergence in LLM training, and achieves an average
performance gain of 10.5% across multiple language model benchmarks compared to
the state-of-the-art methods.

æè¦ï¼ææççè³æé¸åå°æ¼å éå¤§åèªè¨æ¨¡å (LLM) çé è¨ç·´è³ééè¦ãéç¶å·²ç¶æåºäºåç¨®æ¹æ³ä¾æåè³ææçï¼ä½éå°éäºæ¹æ³ä¹éçåºæè¡çªä»¥éæ LLM é è¨ç·´çæä½³è³æé¸åï¼ç¸éç ç©¶å»å¾æéãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°ç©çå¤éä»£çäººåä½è³æé¸åæ©å¶ãå¨éåæ¶æ§ä¸­ï¼æ¯åè³æé¸åæ¹æ³é½ä½çºä¸åç¨ç«çä»£çäººï¼èä¸åä»£çäººæ§å¶å°åè¢«è¨­è¨æå¨ LLM è¨ç·´éç¨ä¸­åææ´åææä»£çäººçè³è¨ãæåé²è¡äºå»£æ³çå¯¦è­ç ç©¶ä¾è©ä¼°æåçå¤éä»£çäººæ¶æ§ãå¯¦é©çµæè­æï¼æåçæ¹æ³é¡¯èæåäºè³ææçï¼å éäº LLM è¨ç·´ä¸­çæ¶æéåº¦ï¼ä¸¦ä¸å¨å¤åèªè¨æ¨¡ååºæºæ¸¬è©¦ä¸­ï¼èæåé²çæ¹æ³ç¸æ¯ï¼éå°äºå¹³å 10.5% çæè½æåã

##### **A Generative AI Technique for Synthesizing a Digital Twin for U.S. Residential Solar Adoption and Generation**
2410.08098v1 by Aparna Kishore, Swapna Thorve, Madhav Marathe

Residential rooftop solar adoption is considered crucial for reducing carbon
emissions. The lack of photovoltaic (PV) data at a finer resolution (e.g.,
household, hourly levels) poses a significant roadblock to informed
decision-making. We discuss a novel methodology to generate a highly granular,
residential-scale realistic dataset for rooftop solar adoption across the
contiguous United States. The data-driven methodology consists of: (i)
integrated machine learning models to identify PV adopters, (ii) methods to
augment the data using explainable AI techniques to glean insights about key
features and their interactions, and (iii) methods to generate household-level
hourly solar energy output using an analytical model. The resulting synthetic
datasets are validated using real-world data and can serve as a digital twin
for modeling downstream tasks. Finally, a policy-based case study utilizing the
digital twin for Virginia demonstrated increased rooftop solar adoption with
the 30\% Federal Solar Investment Tax Credit, especially in
Low-to-Moderate-Income communities.

æè¦ï¼ä½å®å±é å¤ªé½è½æ¡ç¨è¢«èªçºæ¯æ¸å°ç¢³ææ¾çééµãç¼ºä¹æ´ç´°ç·»è§£æåº¦ï¼ä¾å¦å®¶åº­ãæ¯å°æç­ç´ï¼çåé»ï¼PVï¼æ¸æï¼å°ææºæ±ºç­å¶å®æ§æéå¤§éç¤ãæåè¨è«ä¸ç¨®æ°æ¹æ³ï¼ä»¥ç¢çä¸åé«åº¦ç´°ç·»ãä½å®è¦æ¨¡çå¯¦éæ¸æéï¼ç¨æ¼ç¾åæ¬åçå±é å¤ªé½è½æ¡ç¨ãè³æé©åçæ¹æ³åæ¬ï¼(i) æ´åæ©å¨å­¸ç¿æ¨¡åä»¥è­å¥åé»æ¡ç¨èï¼(ii) ä½¿ç¨å¯è§£é AI æè¡æ´åæ¸æçæ¹æ³ï¼ä»¥æ¶ééæ¼ééµç¹å¾µåå¶äº¤äºä½ç¨çè¦è§£ï¼ä»¥å (iii) ä½¿ç¨åææ¨¡åç¢çå®¶åº­ç­ç´æ¯å°æå¤ªé½è½è¼¸åºçæ¹æ³ãç¢ççåææ¸æéä½¿ç¨çå¯¦ä¸çæ¸æé©è­ï¼ä¸¦ä¸å¯ä»¥ç¨ä½å»ºæ¨¡ä¸æ¸¸ä»»åçæ¸ä½éèèãæå¾ï¼å©ç¨æ¸ä½éèèéå°ç¶­åå°¼äºå·é²è¡çåºæ¼æ¿ç­çæ¡ä¾ç ç©¶ï¼è­æå±é å¤ªé½è½æ¡ç¨çé¨è 30% è¯é¦å¤ªé½è½æè³ç¨æ¶æµåèå¢å ï¼å°¤å¶æ¯å¨ä¸­ä½æ¶å¥ç¤¾åã

##### **Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**
2410.08085v1 by Yuan Sui, Bryan Hooi

Recent works integrating Knowledge Graphs (KGs) have led to promising
improvements in enhancing reasoning accuracy of Large Language Models (LLMs).
However, current benchmarks mainly focus on closed tasks, leaving a gap in the
assessment of more complex, real-world scenarios. This gap has also obscured
the evaluation of KGs' potential to mitigate the problem of hallucination in
LLMs. To fill the gap, we introduce OKGQA, a new benchmark specifically
designed to assess LLMs enhanced with KGs under open-ended, real-world question
answering scenarios. OKGQA is designed to closely reflect the complexities of
practical applications using questions from different types, and incorporates
specific metrics to measure both the reduction in hallucinations and the
enhancement in reasoning capabilities. To consider the scenario in which KGs
may have varying levels of mistakes, we further propose another experiment
setting OKGQA-P to assess model performance when the semantics and structure of
KGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore
whether KGs can make LLMs more trustworthy in an open-ended setting, and (2)
conduct a comparative analysis to shed light on methods and future directions
for leveraging KGs to reduce LLMs' hallucination. We believe that this study
can facilitate a more complete performance comparison and encourage continuous
improvement in integrating KGs with LLMs.

æè¦ï¼è¿æçç¥è¯å¾è°± (KG) æ´åç ç©¶ï¼å·²æåå¤§åè¯­è¨æ¨¡å (LLM) æ¨çåç¡®åº¦çè¡¨ç°ã
ç¶èï¼ç°æçåºåæµè¯ä¸»è¦çéäºå°é­å¼ä»»å¡ï¼å¨è¯ä¼°æ´å¤æãæ´å®éçåºæ¯æ¶å­å¨ç¼ºå£ãæ­¤ç¼ºå£ä¹æ¨¡ç³äºç¥è¯å¾è°±å¨åè½» LLM å¹»è§é®é¢ä¸çæ½åè¯ä¼°ãä¸ºäºå¡«è¡¥æ­¤ç¼ºå£ï¼æä»¬å¼å¥äº OKGQAï¼è¿æ¯ä¸ä¸ªä¸é¨è®¾è®¡ç¨æ¥è¯ä¼°å¨å¼æ¾å¼ãå®éé®ç­åºæ¯ä¸­ï¼å¢å¼ºäºç¥è¯å¾è°±ç LLM çæ°åºåæµè¯ãOKGQA æ¨å¨ç´§å¯åæ å®éåºç¨ä¸­çå¤ææ§ï¼ä½¿ç¨ä¸åç±»åçé¢ç®ï¼å¹¶çº³å¥ç¹å®ææ æ¥è¡¡éå¹»è§çåå°åæ¨çè½åçå¢å¼ºãä¸ºäºèèç¥è¯å¾è°±å¯è½å­å¨ä¸åç¨åº¦éè¯¯çåºæ¯ï¼æä»¬è¿ä¸æ­¥æåºäºå¦ä¸ä¸ªå®éªè®¾ç½® OKGQA-Pï¼ä»¥è¯ä¼°å½ç¥è¯å¾è°±çè¯­ä¹åç»æè¢«æææ°å¨åæ±¡ææ¶çæ¨¡åæ§è½ãOKGQA æ¨å¨ (1) æ¢ç´¢ç¥è¯å¾è°±æ¯å¦è½ä½¿ LLM å¨å¼æ¾å¼è®¾ç½®ä¸­æ´å¼å¾ä¿¡èµï¼ä»¥å (2) è¿è¡æ¯è¾åæï¼ä»¥éæå©ç¨ç¥è¯å¾è°±æ¥åå° LLM å¹»è§çæ¹æ³åæªæ¥æ¹åãæä»¬ç¸ä¿¡è¿é¡¹ç ç©¶å¯ä»¥ä¿è¿æ´å®æ´çæ§è½æ¯è¾ï¼å¹¶é¼å±æç»­æ¹è¿ç¥è¯å¾è°±ä¸ LLM çæ´åã

##### **Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning**
2410.08081v1 by Shuhe Wang, Guoyin Wang, Jiwei Li, Eduard Hovy, Chen Guo

Packing, initially utilized in the pre-training phase, is an optimization
technique designed to maximize hardware resource efficiency by combining
different training sequences to fit the model's maximum input length. Although
it has demonstrated effectiveness during pre-training, there remains a lack of
comprehensive analysis for the supervised fine-tuning (SFT) stage on the
following points: (1) whether packing can effectively enhance training
efficiency while maintaining performance, (2) the suitable size of the model
and dataset for fine-tuning with the packing method, and (3) whether packing
unrelated or related training samples might cause the model to either
excessively disregard or over-rely on the context.
  In this paper, we perform extensive comparisons between SFT methods using
padding and packing, covering SFT datasets ranging from 69K to 1.2M and models
from 8B to 70B. This provides the first comprehensive analysis of the
advantages and limitations of packing versus padding, as well as practical
considerations for implementing packing in various training scenarios. Our
analysis covers various benchmarks, including knowledge, reasoning, and coding,
as well as GPT-based evaluations, time efficiency, and other fine-tuning
parameters. We also open-source our code for fine-tuning and evaluation and
provide checkpoints fine-tuned on datasets of different sizes, aiming to
advance future research on packing methods. Code is available at:
https://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.

æè¦ï¼<paragraph>å¨é è¨ç·´éæ®µæåä½¿ç¨çå°è£æ¯ä¸ç¨®æä½³åæè¡ï¼æ¨å¨ééçµåä¸åçè¨ç·´åºåä»¥ç¬¦åæ¨¡åçæå¤§è¼¸å¥é·åº¦ä¾æå¤§åç¡¬é«è³æºæçãåç®¡å®å·²å¨é è¨ç·´éç¨ä¸­è­æå¶æææ§ï¼ä½éå°ç£ç£å¼å¾®èª¿ (SFT) éæ®µä»ç¼ºä¹ä»¥ä¸æ¹é¢çå¨é¢åæï¼(1) å°è£æ¯å¦è½æææåè¨ç·´æçï¼åæç¶­ææè½ï¼(2) é©ç¨æ¼å°è£æ¹æ³å¾®èª¿çæ¨¡ååè³æéçé©ç¶å¤§å°ï¼ä»¥å (3) å°è£ç¡éæç¸éçè¨ç·´æ¨£æ¬æ¯å¦å¯è½å°è´æ¨¡åéåº¦å¿½ç¥æéåº¦ä¾è³´ä¸ä¸æã
å¨æ¬è«æä¸­ï¼æåå°ä½¿ç¨å¡«ååå°è£ç SFT æ¹æ³é²è¡å»£æ³æ¯è¼ï¼æ¶µèå¾ 69K å° 1.2M ç SFT è³æéåå¾ 8B å° 70B çæ¨¡åãéæä¾äºå°è£ç¸å°æ¼å¡«åçåªç¼ºé»ï¼ä»¥åå¨åç¨®è¨ç·´å ´æ¯ä¸­å¯¦ä½å°è£çå¯¦åèéçé¦æ¬¡å¨é¢åæãæåçåææ¶µèåç¨®åºæºï¼åæ¬ç¥è­ãæ¨çåç·¨ç¢¼ï¼ä»¥ååºæ¼ GPT çè©ä¼°ãæéæçåå¶ä»å¾®èª¿åæ¸ãæåä¹éæ¾åå§ç¢¼é²è¡å¾®èª¿åè©ä¼°ï¼ä¸¦æä¾éå°ä¸åå¤§å°è³æéå¾®èª¿çæª¢æ¥é»ï¼ç®æ¨æ¯æ¨é²å°è£æ¹æ³çæªä¾ç ç©¶ãç¨å¼ç¢¼å¯æ¼æ­¤èåå¾ï¼
https://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-fileã</paragraph>

##### **Unlearning-based Neural Interpretations**
2410.08069v1 by Ching Lam Choi, Alexandre Duplessis, Serge Belongie

Gradient-based interpretations often require an anchor point of comparison to
avoid saturation in computing feature importance. We show that current
baselines defined using static functions--constant mapping, averaging or
blurring--inject harmful colour, texture or frequency assumptions that deviate
from model behaviour. This leads to accumulation of irregular gradients,
resulting in attribution maps that are biased, fragile and manipulable.
Departing from the static approach, we propose UNI to compute an (un)learnable,
debiased and adaptive baseline by perturbing the input towards an unlearning
direction of steepest ascent. Our method discovers reliable baselines and
succeeds in erasing salient features, which in turn locally smooths the
high-curvature decision boundaries. Our analyses point to unlearning as a
promising avenue for generating faithful, efficient and robust interpretations.

æè¦ï¼åºæ¼æ¢¯åº¦çè©®ééå¸¸éè¦ä¸åæ¯è¼é¨é»ä¾é¿åå¨è¨ç®ç¹å¾µéè¦æ§æé£½åãæåé¡¯ç¤ºç®åä½¿ç¨éæå½æ¸å®ç¾©çåºæºç·ï¼æå®æ å°ãå¹³åææ¨¡ç³ï¼ææ³¨å¥æå®³çé¡è²ãç´çæé »çåè¨­ï¼éäºåè¨­æåé¢æ¨¡åè¡çºãéæå°è´ä¸è¦åæ¢¯åº¦çç´¯ç©ï¼é²èç¢çæåå·®ãèå¼±ä¸å¯æç¸±çæ­¸å åãæåè·³è«éææ¹æ³ï¼æåº UNI ä¾è¨ç®ä¸åï¼ä¸å¯ï¼å­¸ç¿ãå»åä¸èªé©æçåºæºç·ï¼æ¹æ³æ¯æåæé¡ä¸åçåæ¶å­¸ç¿æ¹åæ¾åè¼¸å¥ãæåçæ¨¡åç¼ç¾å¯é çåºæºç·ï¼ä¸¦æåæ¶é¤é¡¯èç¹å¾µï¼é²èå±é¨å¹³æ»é«æ²çæ±ºç­éçãæåçåææåºåæ¶å­¸ç¿æ¯ä¸åæå¸æçéå¾ï¼å¯ä»¥ç¢çå¿ å¯¦ãææä¸å¼·å¥çè©®éã

##### **Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models**
2410.08068v1 by Wenting Tan, Dongxiao Chen, Jieting Xue, Zihao Wang, Taijie Chen

Large Language Models (LLMs) exhibit impressive performance across various
domains but still struggle with arithmetic reasoning tasks. Recent work shows
the effectiveness of prompt design methods in enhancing reasoning capabilities.
However, these approaches overlook crucial requirements for prior knowledge of
specific concepts, theorems, and tricks to tackle most arithmetic reasoning
problems successfully. To address this issue, we propose a novel and effective
Teaching-Inspired Integrated Framework, which emulates the instructional
process of a teacher guiding students. This method equips LLMs with essential
concepts, relevant theorems, and similar problems with analogous solution
approaches, facilitating the enhancement of reasoning abilities. Additionally,
we introduce two new Chinese datasets, MathMC and MathToF, both with detailed
explanations and answers. Experiments are conducted on nine benchmarks which
demonstrates that our approach improves the reasoning accuracy of LLMs. With
GPT-4 and our framework, we achieve new state-of-the-art performance on four
math benchmarks (AddSub, SVAMP, Math23K and AQuA) with accuracies of 98.2%
(+3.3%), 93.9% (+0.2%), 94.3% (+7.2%) and 81.1% (+1.2%). Our data and code are
available at https://github.com/SallyTan13/Teaching-Inspired-Prompting.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®é åå±ç¾åºä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼ä½å¨ç®è¡æ¨çä»»åä¸­ä»æå°é£ãæè¿çç ç©¶é¡¯ç¤ºï¼æç¤ºè¨­è¨æ¹æ³å¨å¢å¼·æ¨çè½åæ¹é¢å¾ææãç¶èï¼éäºæ¹æ³å¿½ç¥äºå°ç¹å®æ¦å¿µãå®çåæå·§çååç¥è­ï¼éäºç¥è­å°æ¼æåè§£æ±ºå¤§å¤æ¸ç®è¡æ¨çåé¡è³ééè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°ç©ä¸ææçæå­¸éææ´åæ¡æ¶ï¼æ¨¡æ¬èå¸«æå°å­¸ççæå­¸éç¨ãæ­¤æ¹æ³çº LLM æä¾äºå¿è¦çæ¦å¿µãç¸éå®çåé¡ä¼¼åé¡ï¼ä»¥åé¡ä¼¼çè§£æ±ºæ¹æ³ï¼æå©æ¼å¢å¼·æ¨çè½åãæ­¤å¤ï¼æåéä»ç´¹äºå©åæ°çä¸­æè³æé MathMC å MathToFï¼å®åé½æä¾äºè©³ç´°çè§£éåç­æ¡ãå¨ä¹ååºæºä¸é²è¡äºå¯¦é©ï¼çµæè¡¨ææåçåæ³æé«äº LLM çæ¨çæºç¢ºåº¦ãéé GPT-4 åæåçæ¡æ¶ï¼æåå¨ååæ¸å­¸åºæº (AddSubãSVAMPãMath23K å AQuA) ä¸éå°äºæ°çæåé²æ§è½ï¼æºç¢ºåº¦åå¥çº 98.2% (+3.3%)ã93.9% (+0.2%)ã94.3% (+7.2%) å 81.1% (+1.2%)ãæåçè³æåç¨å¼ç¢¼å¯å¨ https://github.com/SallyTan13/Teaching-Inspired-Prompting åå¾ã

##### **Reward-Augmented Data Enhances Direct Preference Alignment of LLMs**
2410.08067v1 by Shenao Zhang, Zhihan Liu, Boyi Liu, Yufeng Zhang, Yingxiang Yang, Yongfei Liu, Liyu Chen, Tao Sun, Zhaoran Wang

Preference alignment in Large Language Models (LLMs) has significantly
improved their ability to adhere to human instructions and intentions. However,
existing direct alignment algorithms primarily focus on relative preferences
and often overlook the qualitative aspects of responses. Striving to maximize
the implicit reward gap between the chosen and the slightly inferior rejected
responses can cause overfitting and unnecessary unlearning of the high-quality
rejected responses. The unawareness of the reward scores also drives the LLM to
indiscriminately favor the low-quality chosen responses and fail to generalize
to responses with the highest rewards, which are sparse in data. To overcome
these shortcomings, our study introduces reward-conditioned LLM policies that
discern and learn from the entire spectrum of response quality within the
dataset, helping extrapolate to more optimal regions. We propose an effective
yet simple data relabeling method that conditions the preference pairs on
quality scores to construct a reward-augmented dataset. This dataset is easily
integrated with existing direct alignment algorithms and is applicable to any
preference dataset. The experimental results across instruction-following
benchmarks including AlpacaEval, MT-Bench, and Arena-Hard-Auto demonstrate that
our approach consistently boosts the performance of DPO by a considerable
margin across diverse models. Additionally, our method improves the average
accuracy on various academic benchmarks. When applying our method to on-policy
data, the resulting DPO model achieves SOTA results on AlpacaEval. Through
ablation studies, we demonstrate that our method not only maximizes the utility
of preference data but also mitigates the issue of unlearning, demonstrating
its broad effectiveness beyond mere dataset expansion. Our code is available at
https://github.com/shenao-zhang/reward-augmented-preference.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä¸­çåå¥½å°é½é¡¯èæåäºå®åéµå®äººé¡æä»¤åæåçè½åãç¶èï¼ç¾æçç´æ¥å°é½æ¼ç®æ³ä¸»è¦éæ³¨ç¸å°åå¥½ï¼ä¸å¸¸å¸¸å¿½ç¥åæçè³ªåé¢åãåªåæå¤§åæé¸åæåç¥éä¸ç±çè¢«æçµåæä¹éçé±å«çåµå·®è·ï¼å¯è½å°è´éåº¦æ¬ååä¸å¿è¦å°éºå¿é«åè³ªçè¢«æçµåæãå°çåµåæ¸çç¡ç¥ä¹é©ä½¿ LLM æ¯«ç¡åå¥å°åå¥½ä½åè³ªçæé¸åæï¼ä¸ç¡æ³æ¦æ¬å°çåµæé«çåæï¼èéäºåæå¨è³æä¸­æ¯ç¨ççãçºäºåæéäºç¼ºé»ï¼æåçç ç©¶å¼å¥äºçåµæ¢ä»¶ç LLM æ¿ç­ï¼å®è½è¾¨å¥ä¸¦å¾è³æéå§åæåè³ªçæ´åç¯åä¸­å­¸ç¿ï¼æå©æ¼å¤æ¨å°æ´ä½³çååãæåæåºä¸åææä¸ç°¡å®çè³æéæ°æ¨ç±¤æ¹æ³ï¼å®ä»¥åè³ªåæ¸çºæ¢ä»¶çåå¥½å°ä¾å»ºæ§ä¸åçåµå¢å¼·çè³æéãéåè³æéå¾å®¹æèç¾æçç´æ¥å°é½æ¼ç®æ³æ´åï¼ä¸é©ç¨æ¼ä»»ä½åå¥½è³æéãå¨åæ¬ AlpacaEvalãMT-Bench å Arena-Hard-Auto å¨å§çæä»¤éµå¾ªåºæºä¸­çå¯¦é©çµæé¡¯ç¤ºï¼æåçåæ³ä¸è´å°ä»¥ç¸ç¶å¤§çå¹åº¦æåäºä¸åæ¨¡åç DPO æè½ãæ­¤å¤ï¼æåçåæ³ä¹æåäºåç¨®å­¸è¡åºæºçå¹³åæºç¢ºåº¦ãç¶å°æåçåæ³æç¨æ¼ç­ç¥è³ææï¼ç¢çç DPO æ¨¡åå¨ AlpacaEval ä¸éå°äº SOTA çµæãééæ¶èç ç©¶ï¼æåè­æäºæåçåæ³ä¸åæå¤§åäºåå¥½è³æçæç¨ï¼ä¹æ¸è¼äºéºå¿çåé¡ï¼è­æäºå®è¶è¶å®ç´çè³æéæ´åçå»£æ³æåãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/shenao-zhang/reward-augmented-preference åå¾ã

##### **Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions**
2410.08058v1 by Inderjeet Nair, Jiaye Tan, Xiaotian Su, Anne Gere, Xu Wang, Lu Wang

Providing feedback is widely recognized as crucial for refining students'
writing skills. Recent advances in language models (LMs) have made it possible
to automatically generate feedback that is actionable and well-aligned with
human-specified attributes. However, it remains unclear whether the feedback
generated by these models is truly effective in enhancing the quality of
student revisions. Moreover, prompting LMs with a precise set of instructions
to generate feedback is nontrivial due to the lack of consensus regarding the
specific attributes that can lead to improved revising performance. To address
these challenges, we propose PROF that PROduces Feedback via learning from LM
simulated student revisions. PROF aims to iteratively optimize the feedback
generator by directly maximizing the effectiveness of students' overall
revising performance as simulated by LMs. Focusing on an economic essay
assignment, we empirically test the efficacy of PROF and observe that our
approach not only surpasses a variety of baseline methods in effectiveness of
improving students' writing but also demonstrates enhanced pedagogical values,
even though it was not explicitly trained for this aspect.

æè¦ï¼æä¾åé¥è¢«å»£æ³èªçºå°æ¼ç²¾é²å­¸ççå¯«ä½æå·§è³ééè¦ãèªè¨æ¨¡å (LM) çææ°é²å±è®èªåç¢çåé¥æçºå¯è½ï¼èéäºåé¥å·æå¯æä½æ§ï¼ä¸èäººé¡æå®çå±¬æ§é«åº¦ä¸è´ãç¶èï¼ç±éäºæ¨¡åç¢ççåé¥æ¯å¦ççè½æææåå­¸çä¿®æ¹çåè³ªï¼ä»ä¸æ¸æ¥ãæ­¤å¤ï¼ç±æ¼å°æ¼å¯è½å°è´ä¿®æ¹è¡¨ç¾æåçç¹å®å±¬æ§ç¼ºä¹å±è­ï¼å æ­¤æç¤º LM ç¢çåé¥æï¼ä½¿ç¨ä¸çµç²¾ç¢ºçèªªæä¸¦éæäºãçºäºæå°éäºææ°ï¼æåæåº PROFï¼å®ééå­¸ç¿ LM æ¨¡æ¬çå­¸çä¿®æ¹ä¾ç¢çåé¥ãPROF çç®æ¨æ¯ééç´æ¥æå¤§åå­¸çæ´é«ä¿®æ¹è¡¨ç¾çæææ§ï¼ç± LM æ¨¡æ¬ï¼ï¼ä¾åè¦æä½³ååé¥ç¢çå¨ãæåèéæ¼ç¶æ¿è«æä½æ¥­ï¼å¯¦è­æ¸¬è©¦ PROF çæè½ï¼ä¸¦è§å¯å°æåçåæ³ä¸åå¨æåå­¸çå¯«ä½çæææ§æ¹é¢è¶è¶åç¨®åºæºæ¹æ³ï¼å³ä½¿å¨éåé¢åä¸¦æªç¶éæç¢ºè¨ç·´ï¼ä¹å±ç¾åºå¢å¼·çæå­¸å¹å¼ã

##### **A Target-Aware Analysis of Data Augmentation for Hate Speech Detection**
2410.08053v1 by Camilla Casula, Sara Tonelli

Hate speech is one of the main threats posed by the widespread use of social
networks, despite efforts to limit it. Although attention has been devoted to
this issue, the lack of datasets and case studies centered around scarcely
represented phenomena, such as ableism or ageism, can lead to hate speech
detection systems that do not perform well on underrepresented identity groups.
Given the unpreceded capabilities of LLMs in producing high-quality data, we
investigate the possibility of augmenting existing data with generative
language models, reducing target imbalance. We experiment with augmenting 1,000
posts from the Measuring Hate Speech corpus, an English dataset annotated with
target identity information, adding around 30,000 synthetic examples using both
simple data augmentation methods and different types of generative models,
comparing autoregressive and sequence-to-sequence approaches. We find
traditional DA methods to often be preferable to generative models, but the
combination of the two tends to lead to the best results. Indeed, for some hate
categories such as origin, religion, and disability, hate speech classification
using augmented data for training improves by more than 10% F1 over the no
augmentation baseline. This work contributes to the development of systems for
hate speech detection that are not only better performing but also fairer and
more inclusive towards targets that have been neglected so far.

æè¦ï¼ä»æ¨è¨è«æ¯ç¤¾äº¤ç¶²è·¯å»£æ³ä½¿ç¨æå¸¶ä¾çä¸»è¦å¨èä¹ä¸ï¼åç®¡å·²æ¡åæªæ½å ä»¥éå¶ãåç®¡å·²å°æ­¤åé¡çµ¦äºéæ³¨ï¼ä½ç¼ºä¹ä»¥é®®å°è¢«ä»£è¡¨çç¾è±¡ï¼ä¾å¦æ­§è¦æ®ç¾ææ­§è¦å¹´é½¡ï¼çºä¸­å¿çè³æéåæ¡ä¾ç ç©¶ï¼å¯è½å°è´ä»æ¨è¨è«åµæ¸¬ç³»çµ±ç¡æ³å°ä»£è¡¨æ§ä¸è¶³çèº«åç¾¤é«ç¼æ®è¯å¥½æç¨ãèéå° LLM å¨ç¢çé«åè³ªè³ææ¹é¢çç¡èå«æ¯è½åï¼æåæ¢è¨äºä½¿ç¨çæå¼èªè¨æ¨¡åæ´åç¾æè³æçå¯è½æ§ï¼ä»¥æ¸å°ç®æ¨å¤±è¡¡ãæååè©¦æ´åãè¡¡éä»æ¨è¨è«ãèªæåº«ä¸­ç 1,000 ç¯è²¼æï¼éæ¯ä¸åæ¨è¨»æç®æ¨èº«åè³è¨çè±æè³æéï¼ä½¿ç¨ç°¡å®çè³ææ´åæ¹æ³åä¸åé¡åççæå¼æ¨¡åæ°å¢ç´ 30,000 ååæç¯ä¾ï¼æ¯è¼èªè¿´æ­¸ååºåå°åºåçæ¹æ³ãæåç¼ç¾å³çµ±ç DA æ¹æ³éå¸¸åªæ¼çæå¼æ¨¡åï¼ä½å©èççµåå¾å¾æå¸¶ä¾æä½³çµæãäºå¯¦ä¸ï¼å°æ¼æäºä»æ¨é¡å¥ï¼ä¾å¦åºèº«ãå®æåæ®ç¾ï¼ä½¿ç¨æ´åè³æé²è¡è¨ç·´çä»æ¨è¨è«åé¡å¨ F1 ä¸æ¯æ²ææ´åçåºæºç·æ¹é²äº 10% ä»¥ä¸ãéé å·¥ä½æå©æ¼éç¼ä»æ¨è¨è«åµæ¸¬ç³»çµ±ï¼ä¸åæè½æ´å¥½ï¼èä¸å°è¿ä»è¢«å¿½è¦çç®æ¨æ´å¬å¹³ãæ´å·åå®¹æ§ã

##### **VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers**
2410.08048v1 by Jianing Qi, Hao Tang, Zhigang Zhu

Recent advancements in test time compute, particularly through the use of
verifier models, have significantly enhanced the reasoning capabilities of
Large Language Models (LLMs). This generator-verifier approach closely
resembles the actor-critic framework in reinforcement learning (RL). However,
current verifier models in LLMs often rely on supervised fine-tuning without
temporal difference learning such as Q-learning. This paper introduces
VerifierQ, a novel approach that integrates Offline Q-learning into LLM
verifier models. We address three key challenges in applying Q-learning to
LLMs: (1) handling utterance-level Markov Decision Processes (MDPs), (2)
managing large action spaces, and (3) mitigating overestimation bias. VerifierQ
introduces a modified Bellman update for bounded Q-values, incorporates
Implicit Q-learning (IQL) for efficient action space management, and integrates
a novel Conservative Q-learning (CQL) formulation for balanced Q-value
estimation. Our method enables parallel Q-value computation and improving
training efficiency. While recent work has explored RL techniques like MCTS for
generators, VerifierQ is among the first to investigate the verifier (critic)
aspect in LLMs through Q-learning. This integration of RL principles into
verifier models complements existing advancements in generator techniques,
potentially enabling more robust and adaptive reasoning in LLMs. Experimental
results on mathematical reasoning tasks demonstrate VerifierQ's superior
performance compared to traditional supervised fine-tuning approaches, with
improvements in efficiency, accuracy and robustness. By enhancing the synergy
between generation and evaluation capabilities, VerifierQ contributes to the
ongoing evolution of AI systems in addressing complex cognitive tasks across
various domains.

æè¦ï¼<paragraph>æè¿å¨æ¸¬è©¦æéè¨ç®æ¹é¢çé²å±ï¼ç¹å¥æ¯ééé©è­æ¨¡åçä½¿ç¨ï¼å¤§å¹æåäºå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãéç¨®çæå¨é©è­æ¹æ³èå¼·åå­¸ç¿ (RL) ä¸­çè¡åè-è©è«èæ¶æ§éå¸¸ç¸ä¼¼ãç¶èï¼LLM ä¸­ç®åçé©è­æ¨¡åéå¸¸ä¾è³´æ¼ç£ç£å¾®èª¿ï¼èæ²ææéå·®å­¸ç¿ï¼ä¾å¦ Q å­¸ç¿ãæ¬æä»ç´¹äº VerifierQï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å°é¢ç· Q å­¸ç¿æ´åå° LLM é©è­æ¨¡åä¸­ãæåè§£æ±ºäºå° Q å­¸ç¿æç¨æ¼ LLM çä¸åä¸»è¦ææ°ï¼(1) èçè©±èªç´é¦¬å¯å¤«æ±ºç­éç¨ (MDP)ï¼(2) ç®¡çå¤§ååä½ç©ºéï¼ä»¥å (3) æ¸è¼é«ä¼°åå·®ãVerifierQ éå°æç Q å¼å¼å¥äºä¿®æ¹å¾ç Bellman æ´æ°ï¼çµåäºé±å¼ Q å­¸ç¿ (IQL) ä»¥é²è¡ææçåä½ç©ºéç®¡çï¼ä¸¦æ´åäºä¸ç¨®æ°çä¿å® Q å­¸ç¿ (CQL) å¬å¼ï¼ä»¥é²è¡å¹³è¡¡ç Q å¼ä¼°è¨ãæåçæ¨¡åæ¯æ´ä¸¦è¡ Q å¼è¨ç®ï¼ä¸¦æé«è¨ç·´æçãéç¶æè¿çç ç©¶æ¢ç´¢äº MCTS ç­ RL æè¡ä»¥ç¨æ¼çæå¨ï¼ä½ VerifierQ æ¯ç¬¬ä¸åéé Q å­¸ç¿æ¢è¨ LLM ä¸­é©è­èï¼è©è«èï¼æ¹é¢çç ç©¶ãéç¨®å° RL ååæ´åå°é©è­æ¨¡åä¸­çåæ³ï¼è£åäºçæå¨æè¡ä¸­ç¾æçé²å±ï¼æ½å¨å°è® LLM è½å¤ é²è¡æ´å¼·å¥ä¸é©ææ§æ´å¼·çæ¨çãæ¸å­¸æ¨çä»»åçå¯¦é©çµæè­æäº VerifierQ åªæ¼å³çµ±ç£ç£å¾®èª¿æ¹æ³ï¼å¨æçãæºç¢ºæ§åå¼·å¥æ§æ¹é¢é½æææåãééå å¼·çæèè©ä¼°è½åä¹éçååä½ç¨ï¼VerifierQ æå©æ¼ AI ç³»çµ±æçºæ¼é²ï¼ä»¥è§£æ±ºåç¨®é åä¸­çè¤éèªç¥ä»»åã</paragraph>

##### **Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations**
2410.08049v1 by Yiyuan Zhang, Xiaohan Ding, Xiangyu Yue

This paper proposes the paradigm of large convolutional kernels in designing
modern Convolutional Neural Networks (ConvNets). We establish that employing a
few large kernels, instead of stacking multiple smaller ones, can be a superior
design strategy. Our work introduces a set of architecture design guidelines
for large-kernel ConvNets that optimize their efficiency and performance. We
propose the UniRepLKNet architecture, which offers systematical architecture
design principles specifically crafted for large-kernel ConvNets, emphasizing
their unique ability to capture extensive spatial information without deep
layer stacking. This results in a model that not only surpasses its
predecessors with an ImageNet accuracy of 88.0%, an ADE20K mIoU of 55.6%, and a
COCO box AP of 56.4% but also demonstrates impressive scalability and
performance on various modalities such as time-series forecasting, audio, point
cloud, and video recognition. These results indicate the universal modeling
abilities of large-kernel ConvNets with faster inference speed compared with
vision transformers. Our findings reveal that large-kernel ConvNets possess
larger effective receptive fields and a higher shape bias, moving away from the
texture bias typical of smaller-kernel CNNs. All codes and models are publicly
available at https://github.com/AILab-CVC/UniRepLKNet promoting further
research and development in the community.

æè¦ï¼æ¬ææåºå¨è¨­è¨ç¾ä»£å·ç©ç¥ç¶ç¶²è·¯ (ConvNets) æä½¿ç¨å¤§åå·ç©æ ¸çç¯ä¾ãæåç¢ºç«ä½¿ç¨å°æ¸å¤§åæ ¸ï¼èä¸æ¯å çå¤åè¼å°çæ ¸ï¼å¯è½æ¯ä¸ç¨®åªè¶çè¨­è¨ç­ç¥ãæåçç ç©¶å¼å¥äºä¸çµå¤§åæ ¸ ConvNets çæ¶æ§è¨­è¨æºåï¼ä»¥æä½³åå¶æçåæè½ãæåæåº UniRepLKNet æ¶æ§ï¼å®æä¾äºå°éçºå¤§åæ ¸ ConvNets è¨­è¨çç³»çµ±åæ¶æ§è¨­è¨ååï¼å¼·èª¿å®åå¨ä¸é²è¡æ·±åº¦å±¤å ççææ³ä¸æ·åå»£æ³ç©ºéè³è¨çç¨ç¹è½åãéç¢çäºä¸åæ¨¡åï¼ä¸åä»¥ 88.0% ç ImageNet æºç¢ºåº¦ã55.6% ç ADE20K mIoU å 56.4% ç COCO çå­ AP è¶è¶å¶åèº«ï¼éå±ç¤ºäºä»¤äººå°è±¡æ·±å»çå¯æ´åæ§åæè½å¨åç¨®æ¨¡å¼ä¸çè¡¨ç¾ï¼ä¾å¦æéåºåé æ¸¬ãé³è¨ãé»é²åå½±çè¾¨è­ãéäºçµæè¡¨æï¼èè¦è¦ºè½æå¨ç¸æ¯ï¼å¤§åæ ¸ ConvNets å·æéç¨çå»ºæ¨¡è½åï¼ä¸æ¨çéåº¦æ´å¿«ãæåçç ç©¶çµæè¡¨æï¼å¤§åæ ¸ ConvNets å·ææ´å¤§çæææåéåæ´é«çå½¢çåå·®ï¼é é¢äºè¼å°æ ¸ CNN çå¸åç´çåå·®ãææç¨å¼ç¢¼åæ¨¡åé½å¬éå¨ https://github.com/AILab-CVC/UniRepLKNetï¼ä»¥ä¿é²ç¤¾ç¾¤é²ä¸æ­¥çç ç©¶åéç¼ã

##### **Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning**
2410.08047v1 by Hyun Ryu, Gyeongman Kim, Hyemin S. Lee, Eunho Yang

Complex logical reasoning tasks require a long sequence of reasoning, which a
large language model (LLM) with chain-of-thought prompting still falls short.
To alleviate this issue, neurosymbolic approaches incorporate a symbolic
solver. Specifically, an LLM only translates a natural language problem into a
satisfiability (SAT) problem that consists of first-order logic formulas, and a
sound symbolic solver returns a mathematically correct solution. However, we
discover that LLMs have difficulties to capture complex logical semantics
hidden in the natural language during translation. To resolve this limitation,
we propose a Compositional First-Order Logic Translation. An LLM first parses a
natural language sentence into newly defined logical dependency structures that
consist of an atomic subsentence and its dependents, then sequentially
translate the parsed subsentences. Since multiple logical dependency structures
and sequential translations are possible for a single sentence, we also
introduce two Verification algorithms to ensure more reliable results. We
utilize an SAT solver to rigorously compare semantics of generated first-order
logic formulas and select the most probable one. We evaluate the proposed
method, dubbed CLOVER, on seven logical reasoning benchmarks and show that it
outperforms the previous neurosymbolic approaches and achieves new
state-of-the-art results.

æè¦ï¼è¤éçéè¼¯æ¨çä»»åéè¦ä¸é£ä¸²çæ¨çï¼èå·ææèéæç¤ºçå¤§èªè¨æ¨¡å (LLM) ä»ç¡æ³éæã
çºäºç·©è§£éååé¡ï¼ç¥ç¶ç¬¦èæ¹æ³æ´åäºä¸åç¬¦èæ±è§£å¨ãå·é«ä¾èªªï¼LLM åªæå°èªç¶èªè¨åé¡è½æçºç±ä¸ééè¼¯å¬å¼çµæçå¯æ»¿è¶³æ§ (SAT) åé¡ï¼èå¥å¨çç¬¦èæ±è§£å¨æåå³ä¸åæ¸å­¸ä¸æ­£ç¢ºçè§£ãç¶èï¼æåç¼ç¾ LLM é£ä»¥å¨è½æéç¨ä¸­æ·åé±èå¨èªç¶èªè¨ä¸­çè¤ééè¼¯èªç¾©ãçºäºè§£æ±ºéåéå¶ï¼æåæåºäºä¸åçµåä¸ééè¼¯è½æãLLM æåå°ä¸åèªç¶èªè¨å¥å­è§£æææ°å®ç¾©çéè¼¯ä¾è³´çµæ§ï¼å¶ä¸­åå«ä¸ååå­å­å¥åå¶ä¾è³´é ï¼ç¶å¾ä¾åºè½æè§£æå¾çå­å¥ãç±æ¼å®ä¸å¥å­æå¤åå¯è½çéè¼¯ä¾è³´çµæ§åé åºè½æï¼æåä¹å¼å¥äºå©åé©è­æ¼ç®æ³ä¾ç¢ºä¿çµææ´å¯é ãæåå©ç¨ SAT æ±è§£å¨å´æ ¼æ¯è¼ç¢ççéè¼¯å¬å¼çèªç¾©ï¼ä¸¦é¸åºæå¯è½çå¬å¼ãæåå¨ä¸åéè¼¯æ¨çåºæºä¸è©ä¼°ææåºçæ¹æ³ï¼ç¨±çº CLOVERï¼ä¸¦é¡¯ç¤ºå®åªæ¼ååçç¥ç¶ç¬¦èæ¹æ³ï¼ä¸¦åå¾æ°çæåé²çµæã

##### **The Rise of AI-Generated Content in Wikipedia**
2410.08044v1 by Creston Brooks, Samuel Eggert, Denis Peskoff

The rise of AI-generated content in popular information sources raises
significant concerns about accountability, accuracy, and bias amplification.
Beyond directly impacting consumers, the widespread presence of this content
poses questions for the long-term viability of training language models on vast
internet sweeps. We use GPTZero, a proprietary AI detector, and Binoculars, an
open-source alternative, to establish lower bounds on the presence of
AI-generated content in recently created Wikipedia pages. Both detectors reveal
a marked increase in AI-generated content in recent pages compared to those
from before the release of GPT-3.5. With thresholds calibrated to achieve a 1%
false positive rate on pre-GPT-3.5 articles, detectors flag over 5% of newly
created English Wikipedia articles as AI-generated, with lower percentages for
German, French, and Italian articles. Flagged Wikipedia articles are typically
of lower quality and are often self-promotional or partial towards a specific
viewpoint on controversial topics.

æè¦ï¼äººå·¥æºè½çæå§å®¹å¨ç±éè³è¨ä¾æºä¸­èèµ·ï¼å¼ç¼äºå°æ¼åè²¬å¶ãæºç¢ºæ§ååè¦æ´æ£çéå¤§çæ®ã
é¤äºç´æ¥å½±é¿æ¶è²»èä¹å¤ï¼æ­¤é¡å§å®¹çå»£æ³å­å¨ä¹å°å¨å»£æ³ç¶²éç¶²è·¯ææä¸­è¨ç·´èªè¨æ¨¡åçé·æå¯è¡æ§æåºäºè³ªçãæåä½¿ç¨å°æç AI åµæ¸¬å¨ GPTZero åéæ¾åå§ç¢¼æ¿ä»£æ¹æ¡ Binocularsï¼ä¾å»ºç«æè¿å»ºç«çç¶­åºç¾ç§é é¢ä¸­ AI çæçå§å®¹å­å¨çä¸éãè GPT-3.5 ç¼å¸ä¹åçé é¢ç¸æ¯ï¼å©ååµæ¸¬å¨é½é¡¯ç¤ºæè¿çé é¢ä¸­ AI çæçå§å®¹é¡¯èå¢å ãè¨­å®é¾å¼ä»¥å¨ GPT-3.5 ä¹åçæç« ä¸­éå° 1% çèª¤å¤çï¼åµæ¸¬å¨å°è¶é 5% çæ°å»ºç«çè±æç¶­åºç¾ç§æç« æ¨è¨çº AI çæçï¼å¾·æãæ³æåç¾©å¤§å©ææç« çç¾åæ¯è¼ä½ãæ¨è¨çç¶­åºç¾ç§æç« éå¸¸åè³ªè¼ä½ï¼èä¸ç¶å¸¸èªæå®£å³æååæ¼æç­è­°æ§ä¸»é¡çç¹å®è§é»ã

##### **Strategic Classification With Externalities**
2410.08032v1 by Yiling Chen, Safwan Hossain, Evi Micha, Ariel Procaccia

We propose a new variant of the strategic classification problem: a principal
reveals a classifier, and $n$ agents report their (possibly manipulated)
features to be classified. Motivated by real-world applications, our model
crucially allows the manipulation of one agent to affect another; that is, it
explicitly captures inter-agent externalities. The principal-agent interactions
are formally modeled as a Stackelberg game, with the resulting agent
manipulation dynamics captured as a simultaneous game. We show that under
certain assumptions, the pure Nash Equilibrium of this agent manipulation game
is unique and can be efficiently computed. Leveraging this result, PAC learning
guarantees are established for the learner: informally, we show that it is
possible to learn classifiers that minimize loss on the distribution, even when
a random number of agents are manipulating their way to a pure Nash
Equilibrium. We also comment on the optimization of such classifiers through
gradient-based approaches. This work sets the theoretical foundations for a
more realistic analysis of classifiers that are robust against multiple
strategic actors interacting in a common environment.

æè¦ï¼æåæåºç­ç¥åé¡åé¡çæ°è®é«ï¼ä¸åå§è¨äººæ­é²ä¸ååé¡å¨ï¼è $n$ åä»£çå ±åä»åï¼å¯è½ç¶éèª¿æ´ï¼çç¹æ§ä»¥é²è¡åé¡ãæåçæ¨¡ååå°çå¯¦ä¸çæç¨çåç¼ï¼è³ééè¦çæ¯åè¨±ä¸åä»£ççèª¿æ´å½±é¿å¦ä¸åä»£çï¼ä¹å°±æ¯èªªï¼å®æç¢ºå°ææå°ä»£çéçå¤é¨æ§ãå§è¨-ä»£çäºåè¢«æ­£å¼å»ºæ¨¡çºä¸å Stackelberg éæ²ï¼ä¸¦å°ç±æ­¤ç¢ççä»£çèª¿æ´åæææçºä¸ååæ­¥éæ²ãæåè¡¨æå¨æäºåè¨­ä¸ï¼éåä»£çèª¿æ´éæ²çç´ç´è¨±åè¡¡æ¯å¯ä¸çï¼ä¸¦ä¸å¯ä»¥ææå°è¨ç®ãå©ç¨éåçµæï¼çºå­¸ç¿èå»ºç«äº PAC å­¸ç¿ä¿è­ï¼éæ­£å¼å°ï¼æåè¡¨ææå¯è½å­¸ç¿æå°ååéæå¤±çåé¡å¨ï¼å³ä½¿å¨é¨æ©æ¸éçä»£çæ­£å¨èª¿æ´ä»åçæ¹å¼ä»¥éå°ç´ç´è¨±åè¡¡æä¹æ¯å¦æ­¤ãæåéè©è«äºééåºæ¼æ¢¯åº¦çéå¾å°æ­¤é¡åé¡å¨é²è¡åªåçåé¡ãéé å·¥ä½çºå°å¨å±åç°å¢ä¸­äºåçãéå°å¤åç­ç¥åèèå·æé­¯æ£æ§çåé¡å¨çæ´ç¾å¯¦çåæå¥ å®äºçè«åºç¤ã

##### **Private Language Models via Truncated Laplacian Mechanism**
2410.08027v1 by Tianhao Huang, Tao Yang, Ivan Habernal, Lijie Hu, Di Wang

Deep learning models for NLP tasks are prone to variants of privacy attacks.
To prevent privacy leakage, researchers have investigated word-level
perturbations, relying on the formal guarantees of differential privacy (DP) in
the embedding space. However, many existing approaches either achieve
unsatisfactory performance in the high privacy regime when using the Laplacian
or Gaussian mechanism, or resort to weaker relaxations of DP that are inferior
to the canonical DP in terms of privacy strength. This raises the question of
whether a new method for private word embedding can be designed to overcome
these limitations. In this paper, we propose a novel private embedding method
called the high dimensional truncated Laplacian mechanism. Specifically, we
introduce a non-trivial extension of the truncated Laplacian mechanism, which
was previously only investigated in one-dimensional space cases. Theoretically,
we show that our method has a lower variance compared to the previous private
word embedding methods. To further validate its effectiveness, we conduct
comprehensive experiments on private embedding and downstream tasks using three
datasets. Remarkably, even in the high privacy regime, our approach only incurs
a slight decrease in utility compared to the non-private scenario.

æè¦ï¼æ·±åº¦å­¸ç¿æ¨¡åå°æ¼èªç¶èªè¨èçä»»åå®¹æåå°åç¨®é±ç§æ»æã
çºäºé²æ­¢é±ç§å¤æ´©ï¼ç ç©¶äººå¡å·²ç¶ç ç©¶äºè©ç´æ¾åï¼ä¾è³´æ¼åµå¥ç©ºéä¸­å·®åé±ç§ (DP) çæ­£å¼ä¿è­ãç¶èï¼è¨±å¤ç¾ææ¹æ³å¨ä½¿ç¨ææ®ææ¯æé«æ¯æ©å¶æï¼å¨é«é±ç§æ©å¶ä¸­ç¡æ³éå°ä»¤äººæ»¿æçæè½ï¼æè¨´è«¸æ¼ DP çè¼å¼±æ¾å¯¬ï¼å¶é±ç§å¼·åº¦ä½æ¼æ­£è¦ DPãéå¼ç¼äºä¸ååé¡ï¼å³æ¯å¦å¯ä»¥è¨­è¨ä¸ç¨®æ°çç§æè©åµå¥æ¹æ³ä¾åæéäºéå¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çç§æåµå¥æ¹æ³ï¼ç¨±çºé«ç¶­æªæ·ææ®ææ¯æ©å¶ãå·é«ä¾èªªï¼æåå¼å¥äºæªæ·ææ®ææ¯æ©å¶çéå¹³å¡æ´åï¼è©²æ©å¶ä»¥ååå¨ Ð¾Ð´Ð½Ð¾Ð¼ÐµÑÐ½Ð¾Ð¼ ç©ºéæ¡ä¾ä¸­é²è¡ç ç©¶ãå¨çè«ä¸ï¼æåè¡¨æèååçç§æè©åµå¥æ¹æ³ç¸æ¯ï¼æåçæ¹ââæ³å·æè¼ä½çè®ç°æ§ãçºäºé²ä¸æ­¥é©è­å¶æææ§ï¼æåä½¿ç¨ä¸åè³æéå°ç§æåµå¥åä¸æ¸¸ä»»åé²è¡äºå¨é¢çå¯¦é©ãå¼å¾æ³¨æçæ¯ï¼å³ä½¿å¨é«é±ç§æ©å¶ä¸­ï¼èéç§æå ´æ¯ç¸æ¯ï¼æåçæ¹ââæ³åå°è´æç¨ç¥æä¸éã

##### **The Computational Complexity of Circuit Discovery for Inner Interpretability**
2410.08025v1 by Federico Adolfi, Martina G. Vilas, Todd Wareham

Many proposed applications of neural networks in machine learning,
cognitive/brain science, and society hinge on the feasibility of inner
interpretability via circuit discovery. This calls for empirical and
theoretical explorations of viable algorithmic options. Despite advances in the
design and testing of heuristics, there are concerns about their scalability
and faithfulness at a time when we lack understanding of the complexity
properties of the problems they are deployed to solve. To address this, we
study circuit discovery with classical and parameterized computational
complexity theory: (1) we describe a conceptual scaffolding to reason about
circuit finding queries in terms of affordances for description, explanation,
prediction and control; (2) we formalize a comprehensive set of queries that
capture mechanistic explanation, and propose a formal framework for their
analysis; (3) we use it to settle the complexity of many query variants and
relaxations of practical interest on multi-layer perceptrons (part of, e.g.,
transformers). Our findings reveal a challenging complexity landscape. Many
queries are intractable (NP-hard, $\Sigma^p_2$-hard), remain fixed-parameter
intractable (W[1]-hard) when constraining model/circuit features (e.g., depth),
and are inapproximable under additive, multiplicative, and probabilistic
approximation schemes. To navigate this landscape, we prove there exist
transformations to tackle some of these hard problems (NP- vs.
$\Sigma^p_2$-complete) with better-understood heuristics, and prove the
tractability (PTIME) or fixed-parameter tractability (FPT) of more modest
queries which retain useful affordances. This framework allows us to understand
the scope and limits of interpretability queries, explore viable options, and
compare their resource demands among existing and future architectures.

æè¦ï¼è¨±å¤ç¥ç¶ç¶²è·¯å¨æ©å¨å­¸ç¿ãèªç¥/è¦ç§å­¸åç¤¾æä¸­çæç¨ææ¡ï¼é½åæ±ºæ¼ééé»è·¯ç¼ç¾ä¾é²è¡å§å¨å¯è§£éæ§çå¯è¡æ§ãééè¦å°å¯è¡çæ¼ç®æ³é¸é é²è¡å¯¦è­åçè«ä¸çæ¢è¨ãåç®¡å¨åç¼æ³çè¨­è¨åæ¸¬è©¦æ¹é¢æé²å±ï¼ä½æåå°å¶å¯æ´å±æ§åå¿ å¯¦åº¦ä»æçæ®ï¼å çºæåç®åéç¼ºä¹å°å¶ç¨æ¼è§£æ±ºåé¡çè¤éæ§å±¬æ§ççè§£ãçºäºè§£æ±ºéååé¡ï¼æåä½¿ç¨å¤å¸ååæ¸åè¨ç®è¤éåº¦çè«ä¾ç ç©¶é»è·¯ç¼ç¾ï¼(1) æåæè¿°ä¸åæ¦å¿µæ§æ¯æ¶ï¼ä»¥æè¿°ãèªªæãé æ¸¬åæ§å¶çä¾¿å©æ§ä¾æ¨è«é»è·¯å°æ¾æ¥è©¢ï¼(2) æåæ­£å¼åä¸åå¨é¢çæ¥è©¢éï¼ä»¥æææ©å¶æ§èªªæï¼ä¸¦æåºä¸åæ­£å¼çåææ¶æ§ï¼(3) æåä½¿ç¨å®ä¾è§£æ±ºå¤å±¤æç¥å¨ï¼ä¾å¦Transformerçä¸é¨åï¼ä¸­è¨±å¤æ¥è©¢è®é«åæ¾å¯¬å¯¦éèè¶£çè¤éæ§ãæåçç¼ç¾æ­ç¤ºäºä¸åå·æææ°æ§çè¤éæ§æ ¼å±ãè¨±å¤æ¥è©¢æ¯é£ä»¥èçç (NP-hardã$\Sigma^p_2$-hard)ï¼ç¶ç´ææ¨¡å/é»è·¯ç¹å¾µï¼ä¾å¦æ·±åº¦ï¼æï¼ä»ç¶æ¯åºå®åæ¸é£ä»¥èçç (W[1]-hard)ï¼ä¸¦ä¸å¨å æ³ãä¹æ³åæ©çè¿ä¼¼æ¹æ¡ä¸æ¯ä¸å¯è¿ä¼¼çãçºäºæå°éç¨®ææ³ï¼æåè­æå­å¨è½æä¾è§£æ±ºä¸äºéäºå°é£çåé¡ (NP- å°æ¯ $\Sigma^p_2$-complete) ä½¿ç¨æ´ææ¼çè§£çåç¼æ³ï¼ä¸¦è­æäºæ´é©åº¦çæ¥è©¢çå¯èçæ§ (PTIME) æåºå®åæ¸å¯èçæ§ (FPT)ï¼éäºæ¥è©¢ä¿çäºæç¨çä¾¿å©æ§ãéåæ¶æ§è®æåè½å¤ äºè§£å¯è§£éæ§æ¥è©¢çç¯ååéå¶ï¼æ¢ç´¢å¯è¡çé¸é ï¼ä¸¦æ¯è¼å®åå¨ç¾æåæªä¾æ¶æ§ä¸­çè³æºéæ±ã

##### **Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling**
2410.08024v1 by Alessio Fallani, Ramil Nugmanov, Jose Arjona-Medina, JÃ¶rg Kurt Wegner, Alexandre Tkatchenko, Kostiantyn Chernichenko

We evaluate the impact of pretraining Graph Transformer architectures on
atom-level quantum-mechanical features for the modeling of absorption,
distribution, metabolism, excretion, and toxicity (ADMET) properties of
drug-like compounds. We compare this pretraining strategy with two others: one
based on molecular quantum properties (specifically the HOMO-LUMO gap) and one
using a self-supervised atom masking technique. After fine-tuning on
Therapeutic Data Commons ADMET datasets, we evaluate the performance
improvement in the different models observing that models pretrained with
atomic quantum mechanical properties produce in general better results. We then
analyse the latent representations and observe that the supervised strategies
preserve the pretraining information after finetuning and that different
pretrainings produce different trends in latent expressivity across layers.
Furthermore, we find that models pretrained on atomic quantum mechanical
properties capture more low-frequency laplacian eigenmodes of the input graph
via the attention weights and produce better representations of atomic
environments within the molecule. Application of the analysis to a much larger
non-public dataset for microsomal clearance illustrates generalizability of the
studied indicators. In this case the performances of the models are in
accordance with the representation analysis and highlight, especially for the
case of masking pretraining and atom-level quantum property pretraining, how
model types with similar performance on public benchmarks can have different
performances on large scale pharmaceutical data.

æè¦ï¼æåè©ä¼°é è¨ç·´åå½¢è½æå¨æ¶æ§å°åå­å±¤ç´éå­åå­¸ç¹å¾µçå½±é¿ï¼ç¨æ¼å»ºæ§é¡è¥ç©ååç©çå¸æ¶ãåä½ãä»£è¬ãææ³åæ¯æ§ (ADMET) å±¬æ§æ¨¡åãæåå°æ­¤é è¨ç·´ç­ç¥èå¶ä»å©åç­ç¥é²è¡æ¯è¼ï¼ä¸ååºæ¼åå­éå­å±¬æ§ï¼ç¹å¥æ¯ HOMO-LUMO å·®è·ï¼ï¼å¦ä¸åä½¿ç¨èªç£ç£åå­é®ç½©æè¡ãå¨ Therapeutic Data Commons ADMET è³æéä¸å¾®èª¿å¾ï¼æåè©ä¼°ä¸åæ¨¡åçæè½æåï¼è§å¯å°ä½¿ç¨åå­éå­åå­¸å±¬æ§é è¨ç·´çæ¨¡åéå¸¸æç¢çæ´å¥½ççµæãæ¥èæååææ½å¨è¡¨ç¤ºï¼ä¸¦è§å¯å°ç£ç£ç­ç¥å¨å¾®èª¿å¾æä¿çé è¨ç·´è³è¨ï¼èä¸ä¸åçé è¨ç·´æå¨ä¸åå±¤ç´ç¢çæ½å¨è¡¨éåçä¸åè¶¨å¢ãæ­¤å¤ï¼æåç¼ç¾é è¨ç·´æ¼åå­éå­åå­¸å±¬æ§çæ¨¡åæééæ³¨æåæ¬éæ·åè¼¸å¥åå½¢çæ´å¤ä½é »ææ®ææ¯ç¹å¾µæ¨¡å¼ï¼ä¸¦ç¢çåå­å§åå­ç°å¢çæ´ä½³è¡¨ç¤ºãå°åææç¨æ¼ä¸åæ´å¤§çéå¬éå¾®é«æ¸é¤è³æéï¼èªªæäºæç ç©¶ææ¨çæ¦æ¬æ§ãå¨éç¨®ææ³ä¸ï¼æ¨¡åçæè½ç¬¦åè¡¨ç¤ºåæï¼ä¸¦ç¹å¥å¼·èª¿é®ç½©é è¨ç·´ååå­å±¤ç´éå­å±¬æ§é è¨ç·´çææ³ï¼èªªæå¨å¬éåºæºä¸æè½ç¸ä¼¼çæ¨¡åé¡åå¨å¤§åè¥åè³æä¸å¯è½ææä¸åçæè½ã

##### **GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder**
2410.08023v1 by Junzhou Chen, Xuan Wen, Ronghui Zhang, Bingtao Ren, Di Wu, Zhigang Xu, Danwei Wang

Unsupervised Domain Adaptation (UDA) aims to adapt a model trained on a
labeled source domain to an unlabeled target domain by addressing the domain
shift. Existing Unsupervised Domain Adaptation (UDA) methods often fall short
in fully leveraging contextual information from the target domain, leading to
suboptimal decision boundary separation during source and target domain
alignment. To address this, we introduce GrabDAE, an innovative UDA framework
designed to tackle domain shift in visual classification tasks. GrabDAE
incorporates two key innovations: the Grab-Mask module, which blurs background
information in target domain images, enabling the model to focus on essential,
domain-relevant features through contrastive learning; and the Denoising
Auto-Encoder (DAE), which enhances feature alignment by reconstructing features
and filtering noise, ensuring a more robust adaptation to the target domain.
These components empower GrabDAE to effectively handle unlabeled target domain
data, significantly improving both classification accuracy and robustness.
Extensive experiments on benchmark datasets, including VisDA-2017, Office-Home,
and Office31, demonstrate that GrabDAE consistently surpasses state-of-the-art
UDA methods, setting new performance benchmarks. By tackling UDA's critical
challenges with its novel feature masking and denoising approach, GrabDAE
offers both significant theoretical and practical advancements in domain
adaptation.

æè¦ï¼ç¡ç£ç£åé©æ (UDA) æ¨å¨ééè§£æ±ºåè½ç§»ï¼å°å¨æ¨ç±¤ä¾æºåä¸è¨ç·´çæ¨¡åé©æå°æªæ¨ç±¤ç®æ¨åãç¾æçç¡ç£ç£åé©æ (UDA) æ¹æ³éå¸¸ç¡æ³ååå©ç¨ä¾èªç®æ¨åçä¸ä¸æè³è¨ï¼å°è´å¨ä¾æºåç®æ¨åæ¯å°æéï¼æ¬¡ä½³æ±ºç­éçåé¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº GrabDAEï¼éæ¯ä¸ååµæ°ç UDA æ¶æ§ï¼æ¨å¨èçè¦è¦ºåé¡ä»»åä¸­çåè½ç§»ãGrabDAE çµåäºå©é ééµåµæ°ï¼Grab-Mask æ¨¡çµï¼å®æ¨¡ç³äºç®æ¨åå½±åä¸­çèæ¯è³è¨ï¼ä½¿æ¨¡åè½å¤ ééå°æ¯å­¸ç¿å°æ³¨æ¼å¿è¦çãèåç¸éçç¹å¾µï¼ä»¥åå»éè¨èªåç·¨ç¢¼å¨ (DAE)ï¼å®éééå»ºç¹å¾µåéæ¿¾éè¨ä¾å¢å¼·ç¹å¾µæ¯å°ï¼ç¢ºä¿æ´å¼·å¥çç®æ¨åé©æãéäºåä»¶è³¦äº GrabDAE ææèçæªæ¨ç±¤ç®æ¨åè³æçè½åï¼å¤§å¹æååé¡æºç¢ºåº¦åå¼·å¥æ§ãå¨åæ¬ VisDA-2017ãOffice-Home å Office31 å¨å§çåºæºè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼GrabDAE æçºè¶è¶æåé²ç UDA æ¹æ³ï¼è¨­å®æ°çæè½åºæºãééå©ç¨å¶æ°ç©çç¹å¾µé®ç½©åå»éè¨æ¹æ³ä¾è§£æ±º UDA çééµææ°ï¼GrabDAE å¨åé©æä¸­æä¾äºéè¦ççè«åå¯¦åé²å±ã

##### **Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs**
2410.08020v1 by Jonas HÃ¼botter, Sascha Bongni, Ido Hakimi, Andreas Krause

Recent efforts in fine-tuning language models often rely on automatic data
selection, commonly using Nearest Neighbors retrieval from large datasets.
However, we theoretically show that this approach tends to select redundant
data, limiting its effectiveness or even hurting performance. To address this,
we introduce SIFT, a data selection algorithm designed to reduce uncertainty
about the model's response given a prompt, which unifies ideas from retrieval
and active learning. Whereas Nearest Neighbor retrieval typically fails in the
presence of information duplication, SIFT accounts for information duplication
and optimizes the overall information gain of the selected examples. We focus
our evaluations on fine-tuning at test-time for prompt-specific language
modeling on the Pile dataset, and show that SIFT consistently outperforms
Nearest Neighbor retrieval, with minimal computational overhead. Moreover, we
show that our uncertainty estimates can predict the performance gain of
test-time fine-tuning, and use this to develop an adaptive algorithm that
invests test-time compute proportional to realized performance gains. We
provide the $\texttt{activeft}$ (Active Fine-Tuning) library which can be used
as a drop-in replacement for Nearest Neighbor retrieval.

æè¦ï¼è¿æ¥å¾®è°è¯­è¨æ¨¡åçåªåç»å¸¸ä»°èµèªå¨æ°æ®éåï¼éå¸¸ä½¿ç¨å¤§åæ°æ®éä¸­çæè¿é»æ£ç´¢ãç¶èï¼æä»¬å¨çè®ºä¸è¯æï¼æ­¤æ¹æ³å¾åäºéååä½æ°æ®ï¼éå¶å¶æè½ï¼çè³æå®³æè½ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº SIFTï¼è¿æ¯ä¸ç§æ°æ®éåç®æ³ï¼æ¨å¨åå°æ¨¡åå¨ç»å®æç¤ºæ¶çååºä¸ç¡®å®æ§ï¼å®ç»ä¸äºæ£ç´¢åä¸»å¨å­¦ä¹ çææ³ãæè¿é»æ£ç´¢å¨å­å¨ä¿¡æ¯éå¤çæåµä¸éå¸¸ä¼å¤±è´¥ï¼è SIFT åèèäºä¿¡æ¯éå¤ï¼å¹¶ä¼åäºæéèä¾çæ»ä½ä¿¡æ¯å¢çãæä»¬ä¸æ³¨äºå¨æµè¯æ¶éå¯¹æç¤ºç¹å®è¯­è¨æ¨¡åçå¾®è°å¨ Pile æ°æ®éä¸è¿è¡è¯ä¼°ï¼å¹¶è¡¨æ SIFT å§ç»ä¼äºæè¿é»æ£ç´¢ï¼ä¸è®¡ç®å¼éæå°ãæ­¤å¤ï¼æä»¬è¡¨æï¼æä»¬çä¸ç¡®å®æ§ä¼°è®¡å¯ä»¥é¢æµæµè¯æ¶å¾®è°çæ§è½å¢çï¼å¹¶å©ç¨æ­¤æ¥å¼åä¸ç§èªéåºç®æ³ï¼è¯¥ç®æ³æ ¹æ®å®ç°çæ§è½å¢çææ¯ä¾å°æå¥æµè¯æ¶è®¡ç®ãæä»¬æä¾äº $\texttt{activeft}$ï¼ä¸»å¨å¾®è°ï¼åºï¼å¯ä»¥ç¨ä½æè¿é»æ£ç´¢çæ¿ä»£æ¹æ¡ã

##### **LLM Cascade with Multi-Objective Optimal Consideration**
2410.08014v1 by Kai Zhang, Liqian Peng, Congchao Wang, Alec Go, Xiaozhong Liu

Large Language Models (LLMs) have demonstrated exceptional capabilities in
understanding and generating natural language. However, their high deployment
costs often pose a barrier to practical applications, especially. Cascading
local and server models offers a promising solution to this challenge. While
existing studies on LLM cascades have primarily focused on the performance-cost
trade-off, real-world scenarios often involve more complex requirements. This
paper introduces a novel LLM Cascade strategy with Multi-Objective
Optimization, enabling LLM cascades to consider additional objectives (e.g.,
privacy) and better align with the specific demands of real-world applications
while maintaining their original cascading abilities. Extensive experiments on
three benchmarks validate the effectiveness and superiority of our approach.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨çè§£åç¢çèªç¶èªè¨æ¹é¢çåè¶è½åãç¶èï¼å®åçé«é¨ç½²ææ¬éå¸¸æå°å¯¦éæç¨æ§æéç¤ï¼å°¤å¶æ¯ä¸²æ¥æ¬å°åä¼ºæå¨æ¨¡åçºæ­¤ææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ãéç¶ç¾æéæ¼ LLM ä¸²æ¥çç ç©¶ä¸»è¦éæ³¨æ¼æè½ææ¬æ¬è¡¡ï¼ä½å¯¦éææ³éå¸¸æ¶åæ´è¤éçè¦æ±ãæ¬æä»ç´¹äºä¸åæ°ç LLM ä¸²æ¥ç­ç¥ï¼å·æå¤ç®æ¨æä½³åï¼è® LLM ä¸²æ¥è½å¤ èæ®å¶ä»ç®æ¨ï¼ä¾å¦é±ç§ï¼ï¼ä¸¦å¨ç¶­æå¶åå§ä¸²æ¥è½åçåæï¼æ´å¥½å°ç¬¦åå¯¦éæç¨ç¨å¼çç¹å®éæ±ãå¨ä¸ååºæºä¸é²è¡çå»£æ³å¯¦é©é©è­äºæåæ¹æ³çæææ§ååªè¶æ§ã

##### **Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation**
2410.08001v1 by Qingwen Bu, Hongyang Li, Li Chen, Jisong Cai, Jia Zeng, Heming Cui, Maoqing Yao, Yu Qiao

The increasing demand for versatile robotic systems to operate in diverse and
dynamic environments has emphasized the importance of a generalist policy,
which leverages a large cross-embodiment data corpus to facilitate broad
adaptability and high-level reasoning. However, the generalist would struggle
with inefficient inference and cost-expensive training. The specialist policy,
instead, is curated for specific domain data and excels at task-level precision
with efficiency. Yet, it lacks the generalization capacity for a wide range of
applications. Inspired by these observations, we introduce RoboDual, a
synergistic dual-system that supplements the merits of both generalist and
specialist policy. A diffusion transformer-based specialist is devised for
multi-step action rollouts, exquisitely conditioned on the high-level task
understanding and discretized action output of a vision-language-action (VLA)
based generalist. Compared to OpenVLA, RoboDual achieves 26.7% improvement in
real-world setting and 12% gain on CALVIN by introducing a specialist policy
with merely 20M trainable parameters. It maintains strong performance with 5%
of demonstration data only, and enables a 3.8 times higher control frequency in
real-world deployment. Code would be made publicly available. Our project page
is hosted at: https://opendrivelab.com/RoboDual/

æè¦ï¼é¨èå°å¤åè½æ©å¨äººç³»çµ±å¨å¤æ¨£ä¸åæç°å¢ä¸­éä½çéæ±æ¥çå¢å ï¼å¼·èª¿äºéææ¿ç­çéè¦æ§ï¼è©²æ¿ç­å©ç¨å¤§éçè·¨å·ç¾æ¸æèªæåº«ä¾ä¿é²å»£æ³çé©ææ§åé«å±¤æ¬¡æ¨çãç¶èï¼éæå¨ä½æççæ¨è«åææ¬æè²´çè¨ç·´ä¸­æéå°å°é£ãç¸åå°ï¼å°å®¶æ¿ç­æ¯éå°ç¹å®é åæ¸æé²è¡ç­åï¼ä¸¦å¨ä»»åå±¤ç´ç²¾ç¢ºåº¦åæçæ¹é¢è¡¨ç¾åºè²ãç¶èï¼å®ç¼ºä¹å»£æ³æç¨çä¸è¬åè½åãåå°éäºè§å¯çåç¼ï¼æåå¼å¥äº RoboDualï¼ä¸åååéç³»çµ±ï¼å®è£åäºéæåå°å®¶æ¿ç­çåªé»ãä¸ååºæ¼æ´æ£Transformerçå°å®¶è¢«è¨­è¨ç¨æ¼å¤æ­¥é©åä½å±éï¼ä¸¦æ ¹æåºæ¼è¦è¦ºèªè¨åä½ (VLA) çéæçé«å±¤æ¬¡ä»»åçè§£åé¢æ£ååä½è¼¸åºé²è¡ç²¾ç¢ºèª¿æ´ãè OpenVLA ç¸æ¯ï¼RoboDual å¨ç¾å¯¦ä¸çè¨­ç½®ä¸­æåäº 26.7%ï¼ä¸¦ééåä½¿ç¨ 20M å¯è¨ç·´åæ¸å¼å¥å°å®¶æ¿ç­ï¼å¨ CALVIN ä¸å¢å äº 12%ãå®åä½¿ç¨ 5% çç¤ºç¯æ¸æå°±è½ç¶­æå¼·åçæè½ï¼ä¸¦å¨å¯¦éé¨ç½²ä¸­å¯¦ç¾äºé«åº 3.8 åçæ§å¶é »çãç¨å¼ç¢¼å°å¬éæä¾ãæåçå°æ¡é é¢ç¶²åçºï¼https://opendrivelab.com/RoboDual/

##### **Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets**
2410.07991v1 by Tommaso Giorgi, Lorenzo Cima, Tiziano Fagni, Marco Avvenuti, Stefano Cresci

The rise of online platforms exacerbated the spread of hate speech, demanding
scalable and effective detection. However, the accuracy of hate speech
detection systems heavily relies on human-labeled data, which is inherently
susceptible to biases. While previous work has examined the issue, the
interplay between the characteristics of the annotator and those of the target
of the hate are still unexplored. We fill this gap by leveraging an extensive
dataset with rich socio-demographic information of both annotators and targets,
uncovering how human biases manifest in relation to the target's attributes.
Our analysis surfaces the presence of widespread biases, which we
quantitatively describe and characterize based on their intensity and
prevalence, revealing marked differences. Furthermore, we compare human biases
with those exhibited by persona-based LLMs. Our findings indicate that while
persona-based LLMs do exhibit biases, these differ significantly from those of
human annotators. Overall, our work offers new and nuanced results on human
biases in hate speech annotations, as well as fresh insights into the design of
AI-driven hate speech detection systems.

æè¦ï¼ç·ä¸å¹³å°çèèµ·å åäºä»æ¨è¨è«çæ£æ­ï¼éè¦å¯æ´åä¸ææçåµæ¸¬æ©å¶ãç¶èï¼ä»æ¨è¨è«åµæ¸¬ç³»çµ±çæºç¢ºæ§é«åº¦ä¾è³´æ¼äººå·¥æ¨è¨çè³æï¼èéäºè³ææ¬è³ªä¸å®¹æåå°åè¦çå½±é¿ãéç¶ååçç ç©¶å·²æ¢è¨æ­¤è­°é¡ï¼ä½æ¨è¨èç¹å¾µèä»æ¨ç®æ¨ç¹å¾µä¹éçäº¤äºä½ç¨ä»æªè¢«æ¢è¨ãæåééå©ç¨åå«æ¨è¨èèç®æ¨è±å¯çç¤¾æäººå£çµ±è¨è³è¨ä¹å»£æ³è³æéï¼å¡«è£äºéé ç©ºç½ï¼æ­é²äººé¡åè¦å¦ä½èç®æ¨å±¬æ§ç¸éè¯ãæåçåææµ®ç¾äºå»£æ³åè¦çå­å¨ï¼æåæ ¹æåè¦çå¼·åº¦åæ®éæ§ï¼ä»¥éåçæ¹å¼æè¿°åæè¿°åè¦ï¼æ­é²æé¡¯çå·®ç°ãæ­¤å¤ï¼æåå°äººé¡åè¦èåºæ¼è§è²ç LLM æå±ç¾çåè¦é²è¡æ¯è¼ãæåçç ç©¶çµææåºï¼éç¶åºæ¼è§è²ç LLM ç¢ºå¯¦æå±ç¾åè¦ï¼ä½éäºåè¦èäººå·¥æ¨è¨èçåè¦æé¡¯èçä¸åãç¸½é«èè¨ï¼æåçç ç©¶éå°ä»æ¨è¨è«æ¨è¨ä¸­çäººé¡åè¦æä¾äºæ°çä¸ç´°ç·»ççµæï¼ä¸¦å° AI é©åçä»æ¨è¨è«åµæ¸¬ç³»çµ±çè¨­è¨æä¾äºæ°çè¦è§£ã

##### **Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models**
2410.07985v1 by Bofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin Xu, Zhengyang Tang, Benyou Wang, Daoguang Zan, Shanghaoran Quan, Ge Zhang, Lei Sha, Yichang Zhang, Xuancheng Ren, Tianyu Liu, Baobao Chang

Recent advancements in large language models (LLMs) have led to significant
breakthroughs in mathematical reasoning capabilities. However, existing
benchmarks like GSM8K or MATH are now being solved with high accuracy (e.g.,
OpenAI o1 achieves 94.8% on MATH dataset), indicating their inadequacy for
truly challenging these models. To bridge this gap, we propose a comprehensive
and challenging benchmark specifically designed to assess LLMs' mathematical
reasoning at the Olympiad level. Unlike existing Olympiad-related benchmarks,
our dataset focuses exclusively on mathematics and comprises a vast collection
of 4428 competition-level problems with rigorous human annotation. These
problems are meticulously categorized into over 33 sub-domains and span more
than 10 distinct difficulty levels, enabling a holistic assessment of model
performance in Olympiad-mathematical reasoning. Furthermore, we conducted an
in-depth analysis based on this benchmark. Our experimental results show that
even the most advanced models, OpenAI o1-mini and OpenAI o1-preview, struggle
with highly challenging Olympiad-level problems, with 60.54% and 52.55%
accuracy, highlighting significant challenges in Olympiad-level mathematical
reasoning.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æçé²å±å·²å°è´æ¸å­¸æ¨çè½åçéå¤§çªç ´ãç¶èï¼ç¾æçåºæºï¼ä¾å¦ GSM8K æ MATHï¼ç¾å¨æ­£ä»¥é«æºç¢ºåº¦è¢«è§£æ±ºï¼ä¾å¦ï¼OpenAI o1 å¨ MATH è³æéä¸éå° 94.8%ï¼ï¼è¡¨æå®åä¸è¶³ä»¥çæ­£ææ°éäºæ¨¡åãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¨é¢ä¸å·æææ°æ§çåºæºï¼å°éè¨­è¨ç¨æ¼è©ä¼°å¥§æå¹åç´å¥ç LLM æ¸å­¸æ¨çè½åãèç¾æçå¥§æå¹åç¸éåºæºä¸åï¼æåçè³æéå°æ³¨æ¼æ¸å­¸ï¼ä¸¦åå«å¤§é 4428 åç«¶è³½ç´å¥åé¡ï¼ä¸¦éæäººå·¥ä»ç´°è¨»è§£ãéäºåé¡è¢«ç´°ç·»å°åçº 33 åå­é åï¼ä¸¦è·¨è¶ 10 åä¸åçé£åº¦ç´å¥ï¼å¾èè½å¤ å¨é¢è©ä¼°æ¨¡åå¨å¥§æå¹åæ¸å­¸æ¨çä¸­çè¡¨ç¾ãæ­¤å¤ï¼æåæ ¹ææ­¤åºæºé²è¡äºæ·±å¥åæãæåçå¯¦é©çµæè¡¨æï¼å³ä½¿æ¯æåé²çæ¨¡å OpenAI o1-mini å OpenAI o1-previewï¼å¨æ¥µå·ææ°æ§çå¥§æå¹åç´å¥åé¡ä¸ä¹é£ä»¥æä»ï¼æºç¢ºçåå¥çº 60.54% å 52.55%ï¼çªé¡¯äºå¥§æå¹åç´å¥æ¸å­¸æ¨çä¸­çéå¤§ææ°ã

##### **MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning**
2410.07981v1 by Andrei Manolache, Dragos Tantaru, Mathias Niepert

In this work, we propose a simple transformer-based baseline for multimodal
molecular representation learning, integrating three distinct modalities:
SMILES strings, 2D graph representations, and 3D conformers of molecules. A key
aspect of our approach is the aggregation of 3D conformers, allowing the model
to account for the fact that molecules can adopt multiple conformations-an
important factor for accurate molecular representation. The tokens for each
modality are extracted using modality-specific encoders: a transformer for
SMILES strings, a message-passing neural network for 2D graphs, and an
equivariant neural network for 3D conformers. The flexibility and modularity of
this framework enable easy adaptation and replacement of these encoders, making
the model highly versatile for different molecular tasks. The extracted tokens
are then combined into a unified multimodal sequence, which is processed by a
downstream transformer for prediction tasks. To efficiently scale our model for
large multimodal datasets, we utilize Flash Attention 2 and bfloat16 precision.
Despite its simplicity, our approach achieves state-of-the-art results across
multiple datasets, demonstrating its effectiveness as a strong baseline for
multimodal molecular representation learning.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåæåºä¸åç°¡å®çåºæ¼ Transformer çåºç·ï¼ç¨æ¼å¤æ¨¡æåå­è¡¨ç¤ºå­¸ç¿ï¼æ´åäºä¸ç¨®ä¸åçæ¨¡æï¼SMILES å­ç¬¦ä¸²ã2D åå½¢è¡¨ç¤ºååå­ç 3D æ§è±¡ãæåæ¹æ³çä¸åééµæ¹é¢æ¯ 3D æ§è±¡çèåï¼åè¨±æ¨¡åèæ®åå­å¯ä»¥æ¡ç¨å¤ç¨®æ§è±¡çäºå¯¦ - éæ¯æºç¢ºåå­è¡¨ç¤ºçä¸åéè¦å ç´ ãæ¯åæ¨¡æçç¬¦èé½æ¯ä½¿ç¨ç¹å®æ¼æ¨¡æçç·¨ç¢¼å¨æåçï¼SMILES å­ç¬¦ä¸²ç Transformerã2D åå½¢çè¨æ¯å³éç¥ç¶ç¶²è·¯å 3D æ§è±¡çç­è®ç¥ç¶ç¶²è·¯ãéåæ¶æ§çéæ´»æ§èæ¨¡çµååè¨±è¼é¬èª¿æ´åæ¿æéäºç·¨ç¢¼å¨ï¼ä½¿æ¨¡åå°ä¸åçåå­ä»»åå·æé«åº¦éç¨æ§ãæåçç¬¦èç¶å¾çµåæä¸åçµ±ä¸çå¤æ¨¡æåºåï¼ç±ä¸æ¸¸ Transformer èçä»¥é²è¡é æ¸¬ä»»åãçºäºææå°æ´å±æåçæ¨¡åä»¥é©æå¤§åå¤æ¨¡ææ¸æéï¼æåå©ç¨ Flash Attention 2 å bfloat16 ç²¾åº¦ãåç®¡å¾ç°¡å®ï¼ä½æåçåæ³å¨å¤åæ¸æéä¸é½åå¾äºæåé²ççµæï¼è­æäºå¶ä½çºå¤æ¨¡æåå­è¡¨ç¤ºå­¸ç¿çå¼·å¤§åºç·çæææ§ã

##### **Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling**
2410.07974v1 by Yuanqi Du, Michael Plainer, Rob Brekelmans, Chenru Duan, Frank NoÃ©, Carla P. Gomes, Alan Apsuru-Guzik, Kirill Neklyudov

Rare event sampling in dynamical systems is a fundamental problem arising in
the natural sciences, which poses significant computational challenges due to
an exponentially large space of trajectories. For settings where the dynamical
system of interest follows a Brownian motion with known drift, the question of
conditioning the process to reach a given endpoint or desired rare event is
definitively answered by Doob's h-transform. However, the naive estimation of
this transform is infeasible, as it requires simulating sufficiently many
forward trajectories to estimate rare event probabilities. In this work, we
propose a variational formulation of Doob's $h$-transform as an optimization
problem over trajectories between a given initial point and the desired ending
point. To solve this optimization, we propose a simulation-free training
objective with a model parameterization that imposes the desired boundary
conditions by design. Our approach significantly reduces the search space over
trajectories and avoids expensive trajectory simulation and inefficient
importance sampling estimators which are required in existing methods. We
demonstrate the ability of our method to find feasible transition paths on
real-world molecular simulation and protein folding tasks.

æè¦ï¼ååç³»çµ±ä¸­çç½è¦äºä»¶åæ¨£æ¯ä¸åèªç¶ç§å­¸ä¸­åºç¾çåºæ¬åé¡ï¼ç±æ¼è»è·¡ç©ºéåææ¸ç´å¢é·ï¼å æ­¤æé æéå¤§çè¨ç®ææ°ãå°æ¼èè¶£ååç³»çµ±éµå¾ªå·²ç¥æ¼ç§»çå¸æéåçè¨­å®ï¼æ¢ä»¶åèçä»¥å°éçµ¦å®çµé»ææéç½è¦äºä»¶çåé¡ï¼å·²æç¢ºç± Doob ç h è½æè§£ç­ãç¶èï¼éåè½æçæ¨¸ç´ ä¼°è¨ä¸å¯è¡ï¼å çºå®éè¦æ¨¡æ¬è¶³å¤ å¤çååè»è·¡ä¾ä¼°è¨ç½è¦äºä»¶æ©çãå¨éé å·¥ä½ä¸­ï¼æåæåº Doob ç h è½æçè®åå¬å¼ï¼ä½çºçµ¦å®åå§é»åæéçµé»ä¹éè»è·¡çæä½³ååé¡ãçºäºè§£æ±ºéåæä½³ååé¡ï¼æåæåºä¸åç¡æ¨¡æ¬è¨ç·´ç®æ¨ï¼å¶ä¸­æ¨¡ååæ¸åå¨è¨­è¨ä¸æ½å æéçéçæ¢ä»¶ãæåçåæ³å¤§å¹æ¸å°è»è·¡ä¸çæå°ç©ºéï¼ä¸¦é¿åç¾ææ¹æ³ä¸­æéçæè²´è»è·¡æ¨¡æ¬åä½æçéè¦æ§åæ¨£ä¼°è¨å¨ãæåå±ç¤ºæåçæ¹æ³å¨çå¯¦ä¸ççåå­æ¨¡æ¬åèç½è³ªæºçä»»åä¸­æ¾å°å¯è¡è½æè·¯å¾çè½åã

##### **Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation**
2410.07962v1 by Tomas Bueno Momcilovic, Beat Buesser, Giulio Zizzo, Mark Purcell, Dian Balta

Despite the impressive adaptability of large language models (LLMs),
challenges remain in ensuring their security, transparency, and
interpretability. Given their susceptibility to adversarial attacks, LLMs need
to be defended with an evolving combination of adversarial training and
guardrails. However, managing the implicit and heterogeneous knowledge for
continuously assuring robustness is difficult. We introduce a novel approach
for assurance of the adversarial robustness of LLMs based on formal
argumentation. Using ontologies for formalization, we structure
state-of-the-art attacks and defenses, facilitating the creation of a
human-readable assurance case, and a machine-readable representation. We
demonstrate its application with examples in English language and code
translation tasks, and provide implications for theory and practice, by
targeting engineers, data scientists, users, and auditors.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·æä»¤äººå°è±¡æ·±å»çé©ææ§ï¼
ä½å¨ç¢ºä¿å¶å®å¨æ§ãéæåº¦å
å¯è§£éæ§æ¹é¢ä»å­å¨ææ°ãéæ¼å¶å®¹æåå°å°ææ§æ»æï¼LLM
éè¦çµåå°ææ§è¨ç·´å
è­·æ¬ä¾é²è¡é²ç¦¦ãç¶èï¼ç®¡çé±å«ä¸ç°è³ªçç¥è­ä»¥æçºç¢ºä¿
ç©©å¥æ§å¾å°é£ãæåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼
ç¨æ¼åºæ¼å½¢å¼åè«è­ç¢ºä¿ LLM çå°ææ§ç©©å¥æ§ãä½¿ç¨æ¬é«è«é²è¡å½¢å¼åï¼æåæ¶æ§
æåé²çæ»æåé²ç¦¦ï¼ä¿é²å»ºç«
äººé¡å¯è®çä¿è­æ¡ä¾åæ©å¨å¯è®çè¡¨ç¤ºãæå
ééä»¥å·¥ç¨å¸«ãè³æç§å­¸å®¶ãä½¿ç¨èåå¯©è¨å¡çºç®æ¨ï¼å¨è±èªèªè¨åç¨å¼ç¢¼ä¸­å±ç¤ºå¶æç¨ç¯ä¾
ç¿»è­¯ä»»åï¼ä¸¦æä¾å°çè«åå¯¦åçå½±é¿ã

##### **COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act**
2410.07959v1 by Philipp Guldimann, Alexander Spiridonov, Robin Staab, Nikola JovanoviÄ, Mark Vero, Velko Vechev, Anna Gueorguieva, Mislav BalunoviÄ, Nikola Konstantinov, Pavol Bielik, Petar Tsankov, Martin Vechev

The EU's Artificial Intelligence Act (AI Act) is a significant step towards
responsible AI development, but lacks clear technical interpretation, making it
difficult to assess models' compliance. This work presents COMPL-AI, a
comprehensive framework consisting of (i) the first technical interpretation of
the EU AI Act, translating its broad regulatory requirements into measurable
technical requirements, with the focus on large language models (LLMs), and
(ii) an open-source Act-centered benchmarking suite, based on thorough
surveying and implementation of state-of-the-art LLM benchmarks. By evaluating
12 prominent LLMs in the context of COMPL-AI, we reveal shortcomings in
existing models and benchmarks, particularly in areas like robustness, safety,
diversity, and fairness. This work highlights the need for a shift in focus
towards these aspects, encouraging balanced development of LLMs and more
comprehensive regulation-aligned benchmarks. Simultaneously, COMPL-AI for the
first time demonstrates the possibilities and difficulties of bringing the
Act's obligations to a more concrete, technical level. As such, our work can
serve as a useful first step towards having actionable recommendations for
model providers, and contributes to ongoing efforts of the EU to enable
application of the Act, such as the drafting of the GPAI Code of Practice.

æè¦ï¼æ­ççäººå·¥æºæ§æ³æ¡ï¼AI æ³æ¡ï¼æ¯éåè² è²¬ä»»ç AI éç¼çéè¦ä¸æ­¥ï¼ä½ç¼ºä¹æç¢ºçæè¡è©®éï¼éä½¿å¾è©ä¼°æ¨¡åçåè¦æ§è®å¾å°é£ãéé å·¥ä½æåº COMPL-AIï¼ä¸åå¨é¢çæ¶æ§ï¼åå« (i) å°æ­ç AI æ³æ¡çç¬¬ä¸åæè¡è©®éï¼å°å¶å»£æ³çç£ç®¡è¦æ±è½åçºå¯è¡¡éçæè¡è¦æ±ï¼éé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥å (ii) ä¸åä»¥æ³æ¡çºä¸­å¿çéæºåºæºæ¸¬è©¦å¥ä»¶ï¼åºæ¼å°æåé²ç LLM åºæºæ¸¬è©¦çå¾¹åºèª¿æ¥åå¯¦æ½ãééå¨ COMPL-AI çèæ¯ä¸è©ä¼° 12 åååºç LLMï¼æåæ­é²äºç¾ææ¨¡åååºæºæ¸¬è©¦çç¼ºé»ï¼ç¹å¥æ¯å¨å¥å£¯æ§ãå®å¨æ§ãå¤æ¨£æ§åå¬å¹³æ§ç­é åãéé å·¥ä½å¼·èª¿äºéè¦å°ç¦é»è½ç§»å°éäºæ¹é¢ï¼é¼åµ LLM çå¹³è¡¡ç¼å±åæ´å¨é¢çæ³è¦å°é½åºæºæ¸¬è©¦ãåæï¼COMPL-AI é¦æ¬¡å±ç¤ºäºå°æ³æ¡çç¾©åå·é«åå°æè¡å±¤é¢çå¯è½æ§åé£åº¦ãå æ­¤ï¼æåçç ç©¶å¯ä»¥ä½çºéåå°æ¨¡åä¾æåæåºå¯è¡çå»ºè­°çç¬¬ä¸æ­¥ï¼ä¸¦æå©æ¼æ­ççºå¯¦æ½æ³æ¡æåçæçºåªåï¼ä¾å¦èµ·è GPAI è¡çºå®åã

##### **Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**
2410.07951v1 by Kuleen Sasse, Shinjitha Vadlakonda, Richard E. Kennedy, John D. Osborne

Background: Machine learning methods for clinical named entity recognition
and entity normalization systems can utilize both labeled corpora and Knowledge
Graphs (KGs) for learning. However, infrequently occurring concepts may have
few mentions in training corpora and lack detailed descriptions or synonyms,
even in large KGs. For Disease Entity Recognition (DER) and Disease Entity
Normalization (DEN), this can result in fewer high quality training examples
relative to the number of known diseases. Large Language Model (LLM) generation
of synthetic training examples could improve performance in these information
extraction tasks.
  Methods: We fine-tuned a LLaMa-2 13B Chat LLM to generate a synthetic corpus
containing normalized mentions of concepts from the Unified Medical Language
System (UMLS) Disease Semantic Group. We measured overall and Out of
Distribution (OOD) performance for DER and DEN, with and without synthetic data
augmentation. We evaluated performance on 3 different disease corpora using 4
different data augmentation strategies, assessed using BioBERT for DER and
SapBERT and KrissBERT for DEN.
  Results: Our synthetic data yielded a substantial improvement for DEN, in all
3 training corpora the top 1 accuracy of both SapBERT and KrissBERT improved by
3-9 points in overall performance and by 20-55 points in OOD data. A small
improvement (1-2 points) was also seen for DER in overall performance, but only
one dataset showed OOD improvement.
  Conclusion: LLM generation of normalized disease mentions can improve DEN
relative to normalization approaches that do not utilize LLMs to augment data
with synthetic mentions. Ablation studies indicate that performance gains for
DEN were only partially attributable to improvements in OOD performance. The
same approach has only a limited ability to improve DER. We make our software
and dataset publicly available.

æè¦ï¼<paragraph>èæ¯ï¼è¨åºå½åå¯¦é«è­å¥çæ©å¨å­¸ç¿æ¹æ³åå¯¦é«æ­£è¦åç³»çµ±å¯ä»¥å©ç¨æ¨è¨èªæåº«åç¥è­åè­ (KG) ä¾å­¸ç¿ãç¶èï¼å¨è¨ç·´èªæåº«ä¸­å¾å°åºç¾çæ¦å¿µå¯è½åªæå°æ¸æåï¼å³ä½¿å¨å¤§åç¥è­åè­ä¸­ä¹ç¼ºä¹è©³ç´°çæè¿°æåç¾©è©ãå°æ¼ç¾çå¯¦é«è­å¥ (DER) åç¾çå¯¦é«æ­£è¦å (DEN)ï¼ç¸å°æ¼å·²ç¥ç¾ççæ¸éï¼éå¯è½æå°è´è¼å°çé«åè³ªè¨ç·´ç¯ä¾ãå¤§åèªè¨æ¨¡å (LLM) çæçåæè¨ç·´ç¯ä¾å¯ä»¥æåéäºè³è¨æ·åä»»åçæè½ã
æ¹æ³ï¼æåå¾®èª¿äºä¸å LLaMa-2 13B èå¤© LLMï¼ä»¥ç¢çä¸ååæèªæåº«ï¼å¶ä¸­åå«ä¾èªçµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ç¾çèªç¾©ç¾¤çæ¨æºåæ¦å¿µæåãæåè¡¡éäº DER å DEN çæ´é«ååå¸å¤ (OOD) æè½ï¼æåæ²æåæè³ææ´åãæåä½¿ç¨ 4 ç¨®ä¸åçè³ææ´åç­ç¥è©ä¼°äº 3 åä¸åç¾çèªæåº«çæè½ï¼ä½¿ç¨ BioBERT è©ä¼° DERï¼ä½¿ç¨ SapBERT å KrissBERT è©ä¼° DENã
çµæï¼æåçåæè³æå° DEN ç¢çäºé¡¯èçæ¹åï¼å¨ææ 3 åè¨ç·´èªæåº«ä¸­ï¼SapBERT å KrissBERT çå 1 åæºç¢ºçå¨æ´é«æè½ä¸æé«äº 3-9 åç¾åé»ï¼å¨ OOD è³æä¸­æé«äº 20-55 åç¾åé»ãå¨ DER çæ´é«æè½ä¸ä¹çå°äºå¾®å°çæ¹åï¼1-2 åç¾åé»ï¼ï¼ä½åªæä¸çµè³æé¡¯ç¤ºåº OOD æ¹åã
çµè«ï¼èä¸å©ç¨ LLM æ´åè³æä»¥åææåçæ­£è¦åæ¹æ³ç¸æ¯ï¼LLM çæçæ¨æºåç¾çæåå¯ä»¥æ¹å DENãæ¶èç ç©¶è¡¨æï¼DEN çæè½æååé¨åæ­¸å æ¼ OOD æè½çæ¹åãç¸åçæ¹æ³å°æ¼æ¹å DER çè½åæéãæåå¬éæåçè»é«åè³æéã</paragraph>

##### **The Function-Representation Unification Framework**
2410.07928v1 by Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart, Eduard Alarcon

Cognitive Architectures are the forefront of our research into developing an
artificial cognition. However, they approach the problem from a separated
memory and program model of computation. This model of computation poses a
fundamental problem: the knowledge retrieval heuristic. In this paper we
propose to solve this problem by using a new model of computation, one where
the memory and the program are united: the Function-Representation. We propose
a whole framework about how to implement and use these
Function-Representations, and we explore their potential through mathematical
definitions and proofs. We also talk about different ways to organise multiple
Function-Representations, and explore the kind of functions that these
Function-Representations can implement. Finally, we also explore the
limitations of our proposal.

æè¦ï¼èªç¥æ¶æ§æ¯æåéç¼äººå·¥èªç¥ç ç©¶çåæ²¿ãç¶èï¼ä»åå¾åé¢çè¨æ¶åç¨å¼è¨ç®æ¨¡åä¾æ¢è¨åé¡ãéåè¨ç®æ¨¡åæåºäºåºæ¬åé¡ï¼ç¥è­æ·ååç¼æ³ãå¨æ¬æä¸­ï¼æåæè­°ä½¿ç¨æ°çè¨ç®æ¨¡åä¾è§£æ±ºéååé¡ï¼ä¸åè¨æ¶é«åç¨å¼çµåçæ¨¡åï¼å½æ¸è¡¨ç¤ºãæåæåºä¸åéæ¼å¦ä½å¯¦ä½åä½¿ç¨éäºå½æ¸è¡¨ç¤ºçå®æ´æ¶æ§ï¼ä¸¦ééæ¸å­¸å®ç¾©åè­æä¾æ¢è¨å®åçæ½åãæåä¹è¨è«çµç¹å¤åå½æ¸è¡¨ç¤ºçä¸åæ¹æ³ï¼ä¸¦æ¢è¨éäºå½æ¸è¡¨ç¤ºå¯ä»¥å¯¦ä½çå½æ¸é¡åãæå¾ï¼æåä¹æ¢è¨æåæè­°çéå¶ã

##### **InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions**
2410.07919v1 by Xiang Zhuang, Keyan Ding, Tianwen Lyu, Yinuo Jiang, Xiaotong Li, Zhuoyi Xiang, Zeyuan Wang, Ming Qin, Kehua Feng, Jike Wang, Qiang Zhang, Huajun Chen

Understanding and designing biomolecules, such as proteins and small
molecules, is central to advancing drug discovery, synthetic biology, and
enzyme engineering. Recent breakthroughs in Artificial Intelligence (AI) have
revolutionized biomolecular research, achieving remarkable accuracy in
biomolecular prediction and design. However, a critical gap remains between
AI's computational power and researchers' intuition, using natural language to
align molecular complexity with human intentions. Large Language Models (LLMs)
have shown potential to interpret human intentions, yet their application to
biomolecular research remains nascent due to challenges including specialized
knowledge requirements, multimodal data integration, and semantic alignment
between natural language and biomolecules. To address these limitations, we
present InstructBioMol, a novel LLM designed to bridge natural language and
biomolecules through a comprehensive any-to-any alignment of natural language,
molecules, and proteins. This model can integrate multimodal biomolecules as
input, and enable researchers to articulate design goals in natural language,
providing biomolecular outputs that meet precise biological needs. Experimental
results demonstrate InstructBioMol can understand and design biomolecules
following human instructions. Notably, it can generate drug molecules with a
10% improvement in binding affinity and design enzymes that achieve an ESP
Score of 70.4, making it the only method to surpass the enzyme-substrate
interaction threshold of 60.0 recommended by the ESP developer. This highlights
its potential to transform real-world biomolecular research.

æè¦ï¼<paragraph>äºè§£åè¨­è¨çç©åå­ï¼ä¾å¦èç½è³ªåå°åå­ï¼å°æ¼æ¨é²è¥ç©ç¼ç¾ãåæçç©å­¸åé¶å·¥ç¨è³ééè¦ãæè¿äººå·¥æºè½ (AI) ççªç ´å¾¹åºæ¹è®äºçç©åå­ç ç©¶ï¼å¨çç©åå­é æ¸¬åè¨­è¨æ¹é¢åå¾äºé¡¯èçæºç¢ºæ§ãç¶èï¼AI çè¨ç®è½ååç ç©¶äººå¡çç´è¦ºä¹éä»ç¶å­å¨ééµå·®è·ï¼ä½¿ç¨èªç¶èªè¨å°åå­è¤éæ§èäººé¡æåå°é½ãå¤§åèªè¨æ¨¡å (LLM) å·²é¡¯ç¤ºåºè§£éäººé¡æåçæ½åï¼ä½ç±æ¼åæ¬å°æ¥­ç¥è­è¦æ±ãå¤æ¨¡å¼æ¸ææ´åä»¥åèªç¶èªè¨åçç©åå­ä¹éçèªç¾©å°é½å¨å§çææ°ï¼å®åå¨çç©åå­ç ç©¶ä¸­çæç¨ä»ç¶èæ¼èè½éæ®µãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº InstructBioMolï¼éæ¯ä¸ç¨®æ°ç©ç LLMï¼æ¨å¨ééèªç¶èªè¨ãåå­åèç½è³ªçå¨é¢ä»»æå°é½ä¾æ©æ¥èªç¶èªè¨åçç©åå­ãæ­¤æ¨¡åå¯ä»¥æ´åå¤æ¨¡å¼çç©åå­ä½çºè¼¸å¥ï¼ä¸¦ä½¿ç ç©¶äººå¡è½å¤ ç¨èªç¶èªè¨è¡¨éè¨­è¨ç®æ¨ï¼æä¾æ»¿è¶³ç²¾ç¢ºçç©éæ±ççç©åå­è¼¸åºãå¯¦é©çµæè¡¨æï¼InstructBioMol å¯ä»¥çè§£åè¨­è¨éµå¾ªäººé¡æä»¤ççç©åå­ãå¼å¾æ³¨æçæ¯ï¼å®å¯ä»¥çæçµåè¦ªååæé« 10% çè¥ç©åå­ï¼ä¸¦è¨­è¨åº ESP å¾åéå° 70.4 çé¶ï¼ä½¿å¶æçºå¯ä¸ä¸ç¨®è¶è¶ ESP éç¼äººå¡æ¨è¦ç 60.0 é¶åºç©ç¸äºä½ç¨é¾å¼çæè¡ãéçªé¡¯äºå¶è½è®ç¾å¯¦ä¸ççç©åå­ç ç©¶çæ½åã</paragraph>

##### **ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**
2410.07908v1 by LÃ©o Machado, HÃ©lÃ¨ne Philippe, Ãlodie Ferreres, Julien Khlaut, Julie Dupuis, Korentin Le Floch, Denis Habip Gatenyo, Pascal Roux, Jules GrÃ©gory, Maxime Ronot, Corentin Dancette, Daniel Tordjman, Pierre Manceron, Paul HÃ©rent

Carcinogenesis is a proteiform phenomenon, with tumors emerging in various
locations and displaying complex, diverse shapes. At the crucial intersection
of research and clinical practice, it demands precise and flexible assessment.
However, current biomarkers, such as RECIST 1.1's long and short axis
measurements, fall short of capturing this complexity, offering an approximate
estimate of tumor burden and a simplistic representation of a more intricate
process. Additionally, existing supervised AI models face challenges in
addressing the variability in tumor presentations, limiting their clinical
utility. These limitations arise from the scarcity of annotations and the
models' focus on narrowly defined tasks.
  To address these challenges, we developed ONCOPILOT, an interactive
radiological foundation model trained on approximately 7,500 CT scans covering
the whole body, from both normal anatomy and a wide range of oncological cases.
ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click
and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and
achieving radiologist-level accuracy in RECIST 1.1 measurements. The key
advantage of this foundation model is its ability to surpass state-of-the-art
performance while keeping the radiologist in the loop, a capability that
previous models could not achieve. When radiologists interactively refine the
segmentations, accuracy improves further. ONCOPILOT also accelerates
measurement processes and reduces inter-reader variability, facilitating
volumetric analysis and unlocking new biomarkers for deeper insights.
  This AI assistant is expected to enhance the precision of RECIST 1.1
measurements, unlock the potential of volumetric biomarkers, and improve
patient stratification and clinical care, while seamlessly integrating into the
radiological workflow.

æè¦ï¼<paragraph>è´çä½ç¨æ¯ä¸ç¨®è®å½¢ç¾è±¡ï¼è«ç¤åºç¾å¨åç¨®ä½ç½®ï¼ä¸¦åç¾åºè¤éå¤æ¨£çå½¢çãå¨ç ç©¶åè¨åºå¯¦åçéè¦äº¤æé»ï¼å®éè¦ç²¾ç¢ºä¸å½æ§çè©ä¼°ãç¶èï¼ç®åççç©æ¨è¨ï¼ä¾å¦ RECIST 1.1 çé·è»¸åç­è»¸æ¸¬éï¼ä¸¦ç¡æ³ææå°éç¨®è¤éæ§ï¼åªè½æä¾è«ç¤è² æçè¿ä¼¼ä¼°è¨ï¼ä»¥åå°æ´è¤ééç¨çç°¡åè¡¨ç¤ºãæ­¤å¤ï¼ç¾æçç£ç£å¼ AI æ¨¡åå¨èçè«ç¤è¡¨ç¾çå¯è®æ§æé¢è¨ææ°ï¼éå¶äºå®åçè¨åºæç¨ãéäºéå¶ä¾èªæ¼è¨»è§£çç¨å°æ§ï¼ä»¥åæ¨¡åå°æ³¨æ¼ç¹ç¾©å®ç¾©çä»»åã
çºäºæå°éäºææ°ï¼æåéç¼äº ONCOPILOTï¼éæ¯ä¸åäºåå¼æ¾å°å­¸åºç¤æ¨¡åï¼è¨ç·´æ¼æ¶µèå¨èº«çç´ 7,500 åé»è¦æ·å±¤ææï¼åæ¬æ­£å¸¸è§£åçµæ§åå»£æ³çè«ç¤çä¾ãONCOPILOT ä½¿ç¨è¦è¦ºæç¤ºï¼ä¾å¦é»é¸åéçæ¡ï¼å·è¡ 3D è«ç¤åå²ï¼åªæ¼æåé²çæ¨¡åï¼ä¾å¦ nnUnetï¼ï¼ä¸¦å¨ RECIST 1.1 æ¸¬éä¸­éå°æ¾å°ç§é«å¸«ç­ç´çæºç¢ºåº¦ãéååºç¤æ¨¡åçä¸»è¦åªé»æ¯å®è½å¤ è¶è¶æåé²çæè½ï¼åæè®æ¾å°ç§é«å¸«åèå¶ä¸­ï¼éæ¯ä»¥åçæ¨¡åç¡æ³éå°çåè½ãç¶æ¾å°ç§é«å¸«äºåå¼å°åªååå²æï¼æºç¢ºåº¦æé²ä¸æ­¥æé«ãONCOPILOT éå éäºæ¸¬ééç¨ï¼ä¸¦æ¸å°äºè®èéçè®ç°æ§ï¼ä¿è¿äºé«ç©åæï¼ä¸¦è§£éäºæ°ççç©æ¨è¨ï¼ä»¥ç²å¾æ´æ·±å¥çè¦è§£ã
é è¨éå AI å©çå°æé« RECIST 1.1 æ¸¬éçæºç¢ºåº¦ï¼éæ¾é«ç©çç©æ¨è¨çæ½åï¼ä¸¦æ¹åæ£èåå±¤åè¨åºç§è­·ï¼åæç¡ç¸«æ´åå°æ¾å°å­¸å·¥ä½æµç¨ä¸­ã</paragraph>

##### **Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines**
2410.07896v1 by Junyu Lai, Jiahe Xu, Yao Yang, Yunpeng Huang, Chun Cao, Jingwei Xu

Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of natural language processing and reasoning tasks. However, their
performance in the foundational domain of arithmetic remains unsatisfactory.
When dealing with arithmetic tasks, LLMs often memorize specific examples
rather than learning the underlying computational logic, limiting their ability
to generalize to new problems. In this paper, we propose a Composable
Arithmetic Execution Framework (CAEF) that enables LLMs to learn to execute
step-by-step computations by emulating Turing Machines, thereby gaining a
genuine understanding of computational logic. Moreover, the proposed framework
is highly scalable, allowing composing learned operators to significantly
reduce the difficulty of learning complex operators. In our evaluation, CAEF
achieves nearly 100% accuracy across seven common mathematical operations on
the LLaMA 3.1-8B model, effectively supporting computations involving operands
with up to 100 digits, a level where GPT-4o falls short noticeably in some
settings.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å»£æ³çèªç¶èªè¨èçåæ¨çä»»åä¸­å±ç¾åºéå¡çè½åãç¶èï¼å®åå¨ç®è¡åºç¤é åçè¡¨ç¾ä»ä¸ç¡äººæãå¨èçç®è¡ä»»åæï¼LLM å¸¸å¸¸è¨ä½ç¹å®ç¯ä¾ï¼èä¸æ¯å­¸ç¿åºå±¤çéç®éè¼¯ï¼ééå¶äºå®åå°æ°åé¡çæ¦åè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¯çµåéç®å·è¡æ¡æ¶ (CAEF)ï¼å®è½è® LLM å­¸ç¿ééæ¨¡æ¬åéæ©ä¾å·è¡å¾ªåºæ¼¸é²çéç®ï¼å¾èçæ­£çè§£éç®éè¼¯ãæ­¤å¤ï¼ææåºçæ¡æ¶å·æé«åº¦å¯æ´åæ§ï¼åè¨±çµåå·²å­¸ç¿çéç®å­ï¼ä»¥é¡¯èéä½å­¸ç¿è¤ééç®å­çé£åº¦ãå¨æåçè©ä¼°ä¸­ï¼CAEF å¨ LLaMA 3.1-8B æ¨¡åä¸å°ä¸é å¸¸è¦çæ¸å­¸éç®éå°äºè¿ 100% çæºç¢ºåº¦ï¼ææå°æ¯æ´æ¶åå¤é 100 ä½æ¸éç®åçéç®ï¼éæ¯ GPT-4o å¨æäºè¨­å®ä¸­æé¡¯ä¸è¶³çå±¤ç´ã

##### **Unsupervised Data Validation Methods for Efficient Model Training**
2410.07880v1 by Yurii Paniv

This paper investigates the challenges and potential solutions for improving
machine learning systems for low-resource languages. State-of-the-art models in
natural language processing (NLP), text-to-speech (TTS), speech-to-text (STT),
and vision-language models (VLM) rely heavily on large datasets, which are
often unavailable for low-resource languages. This research explores key areas
such as defining "quality data," developing methods for generating appropriate
data and enhancing accessibility to model training. A comprehensive review of
current methodologies, including data augmentation, multilingual transfer
learning, synthetic data generation, and data selection techniques, highlights
both advancements and limitations. Several open research questions are
identified, providing a framework for future studies aimed at optimizing data
utilization, reducing the required data quantity, and maintaining high-quality
model performance. By addressing these challenges, the paper aims to make
advanced machine learning models more accessible for low-resource languages,
enhancing their utility and impact across various sectors.

æè¦ï¼éç¯è«ææ¢è¨äºæ¹åä½è³æºèªè¨æ©å¨å­¸ç¿ç³»çµ±çææ°åæ½å¨è§£æ±ºæ¹æ¡ãèªç¶èªè¨èç (NLP)ãæå­è½èªé³ (TTS)ãèªé³è½æå­ (STT) åè¦è¦ºèªè¨æ¨¡å (VLM) ä¸­çææ°æ¨¡åå´éä¾è³´å¤§åè³æéï¼èéäºè³æééå¸¸ç¡æ³ç¨æ¼ä½è³æºèªè¨ãæ¬ç ç©¶æ¢è¨äºå¹¾åééµé åï¼ä¾å¦å®ç¾©ãåªè³ªè³æããéç¼çæé©ç¶è³æçæ¹æ³ï¼ä»¥åå¢å¼·æ¨¡åè¨ç·´çå¯å­åæ§ãå°ç¶åæ¹æ³è«çå¨é¢åé¡§ï¼åæ¬è³ææ´åãå¤èªè¨è½ç§»å­¸ç¿ãåæè³æçæåè³æé¸ææè¡ï¼çªåºäºé²å±åéå¶ãç¢ºå®äºå¹¾åéæ¾çç ç©¶åé¡ï¼çºæ¨å¨æä½³åè³æå©ç¨ãæ¸å°æéè³ææ¸éåç¶­æé«åè³ªæ¨¡åæè½çæªä¾ç ç©¶æä¾äºæ¶æ§ãééè§£æ±ºéäºææ°ï¼æ¬ææ¨å¨è®é²éæ©å¨å­¸ç¿æ¨¡åæ´ææ¼ç¨æ¼ä½è³æºèªè¨ï¼é²èæåå¶å¨ååé åçå¯¦ç¨æ§åå½±é¿åã

##### **Benchmarking Agentic Workflow Generation**
2410.07869v1 by Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large Language Models (LLMs), with their exceptional ability to handle a wide
range of tasks, have driven significant advancements in tackling reasoning and
planning tasks, wherein decomposing complex problems into executable workflows
is a crucial step in this process. Existing workflow evaluation frameworks
either focus solely on holistic performance or suffer from limitations such as
restricted scenario coverage, simplistic workflow structures, and lax
evaluation standards. To this end, we introduce WorFBench, a unified workflow
generation benchmark with multi-faceted scenarios and intricate graph workflow
structures. Additionally, we present WorFEval, a systemic evaluation protocol
utilizing subsequence and subgraph matching algorithms to accurately quantify
the LLM agent's workflow generation capabilities. Through comprehensive
evaluations across different types of LLMs, we discover distinct gaps between
the sequence planning capabilities and graph planning capabilities of LLM
agents, with even GPT-4 exhibiting a gap of around 15%. We also train two
open-source models and evaluate their generalization abilities on held-out
tasks. Furthermore, we observe that the generated workflows can enhance
downstream tasks, enabling them to achieve superior performance with less time
during inference. Code and dataset will be available at
https://github.com/zjunlp/WorFBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææèçåç¨®ä»»åçéå¡è½åï¼æ¨åäºè§£æ±ºæ¨çåè¦åä»»åçé¡¯èé²å±ï¼å¶ä¸­å°è¤éåé¡åè§£çºå¯å·è¡å·¥ä½æµç¨æ¯æ­¤éç¨ä¸­è³ééè¦çä¸æ­¥ãç¾æçå·¥ä½æµç¨è©ä¼°æ¡æ¶åªå°æ³¨æ¼æ´é«æè½ï¼æåå°æå¢æ¶µèç¯ååéãå·¥ä½æµç¨çµæ§ç°¡ååè©ä¼°æ¨æºå¯¬é¬ç­éå¶ãçºæ­¤ï¼æåå¼å¥äº WorFBenchï¼ä¸åçµ±ä¸çå·¥ä½æµç¨çæåºæºï¼å·æå¤æ¹é¢çå ´æ¯åè¤éçåå½¢å·¥ä½æµç¨çµæ§ãæ­¤å¤ï¼æåæåºäº WorFEvalï¼ä¸åå©ç¨å­åºååå­åå¹éæ¼ç®æ³ä¾æºç¢ºéå LLM ä»£çå·¥ä½æµç¨çæè½åçç³»çµ±æ§è©ä¼°åå®ãééå°ä¸åé¡å LLM çå¨é¢è©ä¼°ï¼æåç¼ç¾ LLM ä»£ççåºåè¦åè½åååå½¢è¦åè½åä¹éå­å¨æé¡¯çå·®è·ï¼å³ä½¿æ¯ GPT-4 ä¹è¡¨ç¾åºç´ 15% çå·®è·ãæåéè¨ç·´äºå©åéæºæ¨¡åï¼ä¸¦è©ä¼°äºå®åå¨ä¿çä»»åä¸çæ³åè½åãæ­¤å¤ï¼æåè§å¯å°çæççå·¥ä½æµç¨å¯ä»¥å¢å¼·ä¸æ¸¸ä»»åï¼è®å®åå¨æ¨çæéä»¥æ´å°çæéç²å¾æ´å¥½çæè½ãç¨å¼ç¢¼åè³æéå°å¨ https://github.com/zjunlp/WorFBench ä¸æä¾ã

##### **System-2 Reasoning via Generality and Adaptation**
2410.07866v1 by Sejin Kim, Sundong Kim

While significant progress has been made in task-specific applications,
current models struggle with deep reasoning, generality, and adaptation -- key
components of System-2 reasoning that are crucial for achieving Artificial
General Intelligence (AGI). Despite the promise of approaches such as program
synthesis, language models, and transformers, these methods often fail to
generalize beyond their training data and to adapt to novel tasks, limiting
their ability to perform human-like reasoning. This paper explores the
limitations of existing approaches in achieving advanced System-2 reasoning and
highlights the importance of generality and adaptation for AGI. Moreover, we
propose four key research directions to address these gaps: (1) learning human
intentions from action sequences, (2) combining symbolic and neural models, (3)
meta-learning for unfamiliar environments, and (4) reinforcement learning to
reason multi-step. Through these directions, we aim to advance the ability to
generalize and adapt, bringing computational models closer to the reasoning
capabilities required for AGI.

æè¦ï¼åç®¡å¨ç¹å®ä»»åæç¨ç¨å¼æ¹é¢å·²åå¾éå¤§é²å±ï¼
ç®åçæ¨¡åå¨æ·±åº¦æ¨çãæ®éæ§åé©ææ§æ¹é¢ä»æå°é£ï¼èéäºæ¯ç³»çµ± 2 æ¨çä¸­è³ééè¦çééµçµæé¨åï¼å°æ¼å¯¦ç¾äººå·¥éç¨æºæ§ (AGI) è³ééè¦ãåç®¡æç¨å¼åæãèªè¨æ¨¡ååè½æå¨ç­æ¹æ³ï¼ä½éäºæ¹æ³éå¸¸ç¡æ³æ¨å»£å°è¨ç·´è³æä¹å¤ä¸¦é©ææ°ä»»åï¼ééå¶äºå®åå·è¡é¡äººæ¨ççè½åãæ¬ææ¢è¨äºç¾ææ¹æ³å¨å¯¦ç¾é²éç³»çµ± 2 æ¨çæ¹é¢çéå¶ï¼ä¸¦å¼·èª¿äºæ®éæ§åé©ææ§å° AGI çéè¦æ§ãæ­¤å¤ï¼æåæåºäºååééµç ç©¶æ¹åä¾è§£æ±ºéäºå·®è·ï¼(1) å¾åä½åºåä¸­å­¸ç¿äººé¡æåï¼(2) çµåç¬¦èåç¥ç¶æ¨¡åï¼(3) éå°ä¸çæçç°å¢é²è¡åå­¸ç¿ï¼ä»¥å (4) ééå¼·åå­¸ç¿é²è¡å¤æ­¥é©æ¨çãéééäºæ¹åï¼æåæ¨å¨æåæ¨å»£åé©æçè½åï¼è®è¨ç®æ¨¡åæ´æ¥è¿ AGI æéçæ¨çè½åã

##### **RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation**
2410.07864v1 by Songming Liu, Lingxuan Wu, Bangguo Li, Hengkai Tan, Huayu Chen, Zhengyi Wang, Ke Xu, Hang Su, Jun Zhu

Bimanual manipulation is essential in robotics, yet developing foundation
models is extremely challenging due to the inherent complexity of coordinating
two robot arms (leading to multi-modal action distributions) and the scarcity
of training data. In this paper, we present the Robotics Diffusion Transformer
(RDT), a pioneering diffusion foundation model for bimanual manipulation. RDT
builds on diffusion models to effectively represent multi-modality, with
innovative designs of a scalable Transformer to deal with the heterogeneity of
multi-modal inputs and to capture the nonlinearity and high frequency of
robotic data. To address data scarcity, we further introduce a Physically
Interpretable Unified Action Space, which can unify the action representations
of various robots while preserving the physical meanings of original actions,
facilitating learning transferrable physical knowledge. With these designs, we
managed to pre-train RDT on the largest collection of multi-robot datasets to
date and scaled it up to 1.2B parameters, which is the largest diffusion-based
foundation model for robotic manipulation. We finally fine-tuned RDT on a
self-created multi-task bimanual dataset with over 6K+ episodes to refine its
manipulation capabilities. Experiments on real robots demonstrate that RDT
significantly outperforms existing methods. It exhibits zero-shot
generalization to unseen objects and scenes, understands and follows language
instructions, learns new skills with just 1~5 demonstrations, and effectively
handles complex, dexterous tasks. We refer to
https://rdt-robotics.github.io/rdt-robotics/ for the code and videos.

æè¦ï¼éææä½å¨æ©å¨äººæè¡ä¸­è³ééè¦ï¼ç¶èç±æ¼åèª¿å©åæ©å¨æèï¼å°è´å¤æ¨¡å¼åä½åä½ï¼çåºæè¤éæ§ä»¥åè¨ç·´æ¸æçç¨ç¼ºæ§ï¼éç¼åºç¤æ¨¡åæ¥µå·ææ°æ§ãå¨æ¬æä¸­ï¼æåæåºäºæ©å¨äººæ´æ£Transformer (RDT)ï¼éæ¯ä¸åç¨æ¼éææä½çéåµæ§æ´æ£åºç¤æ¨¡åãRDT å»ºç«å¨æ´æ£æ¨¡åä¹ä¸ï¼ä»¥ææè¡¨ç¤ºå¤æ¨¡æï¼ä¸¦æ¡ç¨å¯æ´åTransformerçåµæ°è¨­è¨ä¾èçå¤æ¨¡æè¼¸å¥çç°è³ªæ§ï¼ä¸¦æææ©å¨äººæ¸æçéç·æ§åé«é »çãçºäºè§£æ±ºæ¸æç¨ç¼ºåé¡ï¼æåé²ä¸æ­¥å¼å¥äºä¸åç©çå¯è§£éçµ±ä¸åä½ç©ºéï¼å®å¯ä»¥çµ±ä¸åç¨®æ©å¨äººçåä½è¡¨ç¤ºï¼åæä¿çåå§åä½çç©çæç¾©ï¼ä¿é²å­¸ç¿å¯è½ç§»çç©çç¥è­ãæäºéäºè¨­è¨ï¼æåè¨­æ³å¨è¿ä»çºæ­¢æå¤§çå¤æ©å¨äººæ¸æééåä¸å° RDT é²è¡é è¨ç·´ï¼ä¸¦å°å¶æ´å±å° 1.2B åæ¸ï¼éæ¯æå¤§çåºæ¼æ´æ£çæ©å¨äººæä½åºç¤æ¨¡åãæåæçµå¨ä¸åèªåµçå¤ä»»åéææ¸æéä¸å° RDT é²è¡å¾®èª¿ï¼è©²æ¸æéåå«è¶é 6K åæç¯ï¼ä»¥æåå¶æä½è½åãå¨çå¯¦æ©å¨äººä¸çå¯¦é©è¡¨æï¼RDT æé¡¯åªæ¼ç¾ææ¹æ³ãå®å°æªè¦éçç©é«åå ´æ¯è¡¨ç¾åºé¶æ¬¡å­¸ç¿æ³åï¼çè§£ä¸¦éµå¾ªèªè¨æä»¤ï¼åªé 1~5 æ¬¡ç¤ºç¯å°±è½å­¸ç¿æ°æè½ï¼ä¸¦ææèçè¤éçéå·§ä»»åãæååè https://rdt-robotics.github.io/rdt-robotics/ ç²åä»£ç¢¼åå½±çã

##### **From Logits to Hierarchies: Hierarchical Clustering made Simple**
2410.07858v1 by Emanuele Palumbo, Moritz Vandenhirtz, Alain Ryser, Imant Daunhawer, Julia E. Vogt

The structure of many real-world datasets is intrinsically hierarchical,
making the modeling of such hierarchies a critical objective in both
unsupervised and supervised machine learning. Recently, novel approaches for
hierarchical clustering with deep architectures have been proposed. In this
work, we take a critical perspective on this line of research and demonstrate
that many approaches exhibit major limitations when applied to realistic
datasets, partly due to their high computational complexity. In particular, we
show that a lightweight procedure implemented on top of pre-trained
non-hierarchical clustering models outperforms models designed specifically for
hierarchical clustering. Our proposed approach is computationally efficient and
applicable to any pre-trained clustering model that outputs logits, without
requiring any fine-tuning. To highlight the generality of our findings, we
illustrate how our method can also be applied in a supervised setup, recovering
meaningful hierarchies from a pre-trained ImageNet classifier.

æè¦ï¼è¨±å¤çå¯¦ä¸çè³æéççµæ§æ¬è³ªä¸æ¯éå±¤å¼çï¼
ä½¿å¾å°æ­¤é¡éå±¤å»ºæ¨¡æçºç¡ç£ç£åç£ç£æ©å¨å­¸ç¿ä¸­çéè¦ç®æ¨ãæè¿ï¼
å·²ç¶æåºå·ææ·±åº¦æ¶æ§çéå±¤å¼èé¡æ°æ¹æ³ãå¨éå
å·¥ä½ä¸­ï¼æåå°éæ¢ç ç©¶è·¯ç·æ¡åæ¹å¤æ§çè§é»ï¼ä¸¦è­æ
è¨±å¤æ¹æ³å¨æç¨æ¼å¯¦é
è³æéæè¡¨ç¾åºéå¤§çéå¶ï¼é¨ååå æ¯å®åçé«è¨ç®è¤éåº¦ãç¹å¥æ¯ï¼æå
è¡¨æå¨é åè¨ç·´ç
ééå±¤å¼èé¡æ¨¡åä¹ä¸å¯¦ä½çè¼éç´ç¨åºåªæ¼å°éçº
éå±¤å¼èé¡è¨­è¨çæ¨¡åãæåæåºçæ¹æ³å¨è¨ç®ä¸æ¯ææçï¼ä¸¦ä¸
é©ç¨æ¼ä»»ä½è¼¸åº logit çé åè¨ç·´èé¡æ¨¡åï¼èç¡é
é²è¡ä»»ä½å¾®èª¿ãçºäºå¼·èª¿æåç¼ç¾çæ®éæ§ï¼æå
èªªææåçæ¨¡åå¦ä½ä¹å¯ä»¥æç¨å¨æç£ç£çè¨­å®ä¸­ï¼å¾é åè¨ç·´ç ImageNet åé¡å¨ä¸­æ¢å¾©
ææç¾©çéå±¤ã

##### **Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency**
2410.07839v1 by Tim Knappe, Ryan Li, Ayush Chauhan, Kaylee Chhua, Kevin Zhu, Sean O'Brien

While large language models (LLMs) have rapidly improved their performance on
a broad number of tasks, they still often fall short on reasoning tasks. As
LLMs become more integrated in diverse real-world tasks, advancing their
reasoning capabilities is crucial to their effectiveness in nuanced, complex
problems. Wang et al's self-consistency framework reveals that sampling
multiple rationales before taking a majority vote reliably improves model
performance across various closed-answer reasoning tasks. Standard methods
based on this framework aggregate the final decisions of these rationales but
fail to utilize the detailed step-by-step reasoning paths applied by these
paths. Our work enhances this approach by incorporating and analyzing both the
reasoning paths of these rationales in addition to their final decisions before
taking a majority vote. These methods not only improve the reliability of
reasoning paths but also cause more robust performance on complex reasoning
tasks.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨è¨±å¤ä»»åä¸çè¡¨ç¾è¿éæåï¼ä½å®åå¨æ¨çä»»åä¸ä»ç¶å¸¸è¡¨ç¾ä¸ä½³ãé¨è LLM æ´å¤åå°æ´åå¨åç¨®å¯¦éä»»åä¸­ï¼æåå¶æ¨çè½åå°æ¼å®åå¨ç´°å¾®è¤éåé¡ä¸­çææè³ééè¦ãWang ç­äººçèªæ´½æ¶æ§é¡¯ç¤ºï¼å¨é²è¡å¤æ¸æ±ºæç¥¨åå°å¤åä¾æåæ¨£ï¼å¯ä»¥å¤§å¹æåæ¨¡åå¨åç¨®å°éå¼åç­æ¨çä»»åä¸­çè¡¨ç¾ãåºæ¼æ­¤æ¶æ§çæ¨æºæ¹æ³æå½ç¸½éäºä¾æçæçµæ±ºå®ï¼ä½ç¡æ³å©ç¨éäºä¾æææç¨çè©³ç´°éæ­¥æ¨çè·¯å¾ãæåçç ç©¶ééå¨é²è¡å¤æ¸æ±ºæç¥¨åç´å¥ååæéäºä¾æçæ¨çè·¯å¾ï¼ä»¥åå¶æçµæ±ºå®ï¼ä¾å¼·åæ­¤æ¹æ³ãéäºæ¹æ³ä¸åæåæ¨çè·¯å¾çå¯é æ§ï¼ä¹è®æ¨¡åå¨è¤éæ¨çä»»åä¸­çè¡¨ç¾æ´å¼·å¥ã

##### **MinorityPrompt: Text to Minority Image Generation via Prompt Optimization**
2410.07838v1 by Soobin Um, Jong Chul Ye

We investigate the generation of minority samples using pretrained
text-to-image (T2I) latent diffusion models. Minority instances, in the context
of T2I generation, can be defined as ones living on low-density regions of
text-conditional data distributions. They are valuable for various applications
of modern T2I generators, such as data augmentation and creative AI.
Unfortunately, existing pretrained T2I diffusion models primarily focus on
high-density regions, largely due to the influence of guided samplers (like
CFG) that are essential for producing high-quality generations. To address
this, we present a novel framework to counter the high-density-focus of T2I
diffusion models. Specifically, we first develop an online prompt optimization
framework that can encourage the emergence of desired properties during
inference while preserving semantic contents of user-provided prompts. We
subsequently tailor this generic prompt optimizer into a specialized solver
that promotes the generation of minority features by incorporating a
carefully-crafted likelihood objective. Our comprehensive experiments,
conducted across various types of T2I models, demonstrate that our approach
significantly enhances the capability to produce high-quality minority
instances compared to existing samplers.

æè¦ï¼æåç ç©¶ä½¿ç¨é è¨ç·´çæå­è½åå (T2I) æ½å¨æ´æ£æ¨¡åçæå°æ¸æ¨£æ¬ãå¨ T2I çæçèæ¯ä¸ï¼å°æ¸å¯¦ä¾å¯ä»¥å®ç¾©çºå­å¨æ¼æå­æ¢ä»¶æ¸æåä½çä½å¯åº¦ååä¸­çå¯¦ä¾ãå®åå°æ¼ç¾ä»£ T2I çæå¨çåç¨®æç¨å¾æå¹å¼ï¼ä¾å¦æ¸ææ´åååµæ AIãä¸å¹¸çæ¯ï¼ç¾æçé è¨ç·´ T2I æ´æ£æ¨¡åä¸»è¦éæ³¨é«å¯åº¦ååï¼éå¨å¾å¤§ç¨åº¦ä¸æ¯åå°å¼å°åæ¨£å¨ï¼å¦ CFGï¼çå½±é¿ï¼èå¼å°åæ¨£å¨å°æ¼ç¢çé«åè³ªçæè³ééè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°æ¡æ¶ä¾æå° T2I æ´æ£æ¨¡åçé«å¯åº¦éæ³¨ãå·é«ä¾èªªï¼æåé¦åéç¼ä¸åç·ä¸æç¤ºæä½³åæ¡æ¶ï¼å®å¯ä»¥å¨æ¨çéç¨ä¸­é¼åµæéå±¬æ§çåºç¾ï¼åæä¿çä½¿ç¨èæä¾çæç¤ºçèªç¾©å§å®¹ãæåé¨å¾å°éåéç¨æç¤ºæä½³åå¨èª¿æ´çºä¸åå°éçæ±è§£å¨ï¼ééç´å¥ç²¾å¿è£½ä½çä¼¼ç¶ç®æ¨ä¾ä¿é²å°æ¸ç¹å¾µççæãæåå¨åç¨® T2I æ¨¡åä¸é²è¡çç¶åå¯¦é©è¡¨æï¼èç¾æçåæ¨£å¨ç¸æ¯ï¼æåçåæ³é¡¯èå¢å¼·äºç¢çé«åè³ªå°æ¸å¯¦ä¾çè½åã

##### **Masked Generative Priors Improve World Models Sequence Modelling Capabilities**
2410.07836v1 by Cristian Meo, Mircea Lica, Zarif Ikram, Akihiro Nakano, Vedant Shah, Aniket Rajiv Didolkar, Dianbo Liu, Anirudh Goyal, Justin Dauwels

Deep Reinforcement Learning (RL) has become the leading approach for creating
artificial agents in complex environments. Model-based approaches, which are RL
methods with world models that predict environment dynamics, are among the most
promising directions for improving data efficiency, forming a critical step
toward bridging the gap between research and real-world deployment. In
particular, world models enhance sample efficiency by learning in imagination,
which involves training a generative sequence model of the environment in a
self-supervised manner. Recently, Masked Generative Modelling has emerged as a
more efficient and superior inductive bias for modelling and generating token
sequences. Building on the Efficient Stochastic Transformer-based World Models
(STORM) architecture, we replace the traditional MLP prior with a Masked
Generative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM. We evaluate our
model on two downstream tasks: reinforcement learning and video prediction.
GIT-STORM demonstrates substantial performance gains in RL tasks on the Atari
100k benchmark. Moreover, we apply Transformer-based World Models to continuous
action environments for the first time, addressing a significant gap in prior
research. To achieve this, we employ a state mixer function that integrates
latent state representations with actions, enabling our model to handle
continuous control tasks. We validate this approach through qualitative and
quantitative analyses on the DeepMind Control Suite, showcasing the
effectiveness of Transformer-based World Models in this new domain. Our results
highlight the versatility and efficacy of the MaskGIT dynamics prior, paving
the way for more accurate world models and effective RL policies.

æè¦ï¼æ·±åº¦å¼·åå­¸ç¿ (RL) å·²æçºå¨è¤éç°å¢ä¸­å»ºç«äººå·¥ä»£çç¨å¼çä¸»è¦æ¹æ³ãåºæ¼æ¨¡åçæ¹æ³ï¼å³å·åé æ¸¬ç°å¢åæçä¸çæ¨¡åç RL æ¹æ³ï¼æ¯æ¹åè³ææççææå¸æçæ¹åä¹ä¸ï¼æ§æäºç¸®å°ç ç©¶èå¯¦éé¨ç½²ä¹éå·®è·çééµæ­¥é©ãç¹å¥æ¯ï¼ä¸çæ¨¡åééå¨æ³åä¸­å­¸ç¿ä¾å¢å¼·æ¨£æ¬æçï¼å¶ä¸­æ¶åä»¥èªæç£ç£çæ¹å¼è¨ç·´ç°å¢ççæå¼åºåæ¨¡åãæè¿ï¼é®ç½©çææ¨¡åå·²æçºä¸ç¨®æ´ææçä¸æ´åªè¶çæ­¸ç´åèª¤ï¼ç¨æ¼å»ºæ¨¡åç¢çç¬¦èåºåãå¨åºæ¼ææé¨æ©è®æå¨ä¸çæ¨¡å (STORM) æ¶æ§çåºç¤ä¸ï¼æåç¨é®ç½©çæåé© (ä¾å¦ MaskGIT åé©) åä»£å³çµ±ç MLP åé©ï¼ä¸¦å¼å¥ GIT-STORMãæåå¨å©åä¸æ¸¸ä»»åä¸­è©ä¼°æåçæ¨¡åï¼å¼·åå­¸ç¿åå½±çé æ¸¬ãGIT-STORM å¨ Atari 100k åºæºæ¸¬è©¦ä¸­ç RL ä»»åä¸­å±ç¾åºé¡¯èçæè½æåãæ­¤å¤ï¼æåé¦æ¬¡å°åºæ¼è®æå¨çä¸çæ¨¡åæç¨æ¼é£çºåä½ç°å¢ï¼è§£æ±ºäºååç ç©¶ä¸­çéå¤§å·®è·ãçºæ­¤ï¼æåæ¡ç¨ä¸åçææ··åå¨å½æ¸ï¼å°æ½å¨çæè¡¨ç¤ºèåä½æ´åå¨ä¸èµ·ï¼ä½¿æåçæ¨¡åè½å¤ èçé£çºæ§å¶ä»»åãæåééå¨ DeepMind Control Suite ä¸é²è¡å®æ§åå®éåæä¾é©è­æ­¤æ¹æ³ï¼å±ç¤ºäºåºæ¼è®æå¨çä¸çæ¨¡åå¨æ­¤æ°é åä¸­çæææ§ãæåççµæçªé¡¯äº MaskGIT åæåé©çå¤åè½æ§åæææ§ï¼çºæ´æºç¢ºçä¸çæ¨¡ååææç RL æ¿ç­éªå¹³äºéè·¯ã

##### **NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models**
2410.07830v1 by William Tan, Kevin Zhu

Large Language Models (LLMs) have demonstrated exceptional promise in
translation tasks for high-resource languages. However, their performance in
low-resource languages is limited by the scarcity of both parallel and
monolingual corpora, as well as the presence of noise. Consequently, such LLMs
suffer with alignment and have lagged behind State-of-The-Art (SoTA) neural
machine translation (NMT) models in these settings. This paper introduces
NusaMT-7B, an LLM-based machine translation model for low-resource Indonesian
languages, starting with Balinese and Minangkabau. Leveraging the pretrained
LLaMA2-7B, our approach integrates continued pre-training on monolingual data,
Supervised Fine-Tuning (SFT), self-learning, and an LLM-based data cleaner to
reduce noise in parallel sentences. In the FLORES-200 multilingual translation
benchmark, NusaMT-7B outperforms SoTA models in the spBLEU metric by up to
+6.69 spBLEU in translations into Balinese and Minangkabau, but underperforms
by up to -3.38 spBLEU in translations into higher-resource languages. Our
results show that fine-tuned LLMs can enhance translation quality for
low-resource languages, aiding in linguistic preservation and cross-cultural
communication.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨é«è³æºèªè¨çç¿»è­¯ä»»åä¸­å±ç¾åºéå¡çæ½åãç¶èï¼å®åå¨ä½è³æºèªè¨ä¸­çè¡¨ç¾åå°å¹³è¡èªæåå®èªèªæåº«çç¨ç¼ºä»¥åéè¨çå­å¨æéå¶ãå æ­¤ï¼æ­¤é¡ LLM å¨å°é½æ¹é¢å­å¨åé¡ï¼ä¸¦ä¸å¨éäºè¨­å®ä¸­è½å¾æ¼æåé² (SoTA) ç¥ç¶æ©å¨ç¿»è­¯ (NMT) æ¨¡åãæ¬æä»ç´¹ NusaMT-7Bï¼ä¸ç¨®åºæ¼ LLM çæ©å¨ç¿»è­¯æ¨¡åï¼é©ç¨æ¼ä½è³æºå°å°¼èªè¨ï¼å¾å·´åèªåç±³åå¡ä¿èªéå§ãå©ç¨é åè¨ç·´ç LLaMA2-7Bï¼æåçåæ³æ´åäºå°å®èªæ¸æçæçºé è¨ç·´ãç£ç£å¾®èª¿ (SFT)ãèªå­¸ä»¥ååºæ¼ LLM çæ¸ææ¸çå¨ï¼ä»¥æ¸å°å¹³è¡å¥å­ä¸­çéè¨ãå¨ FLORES-200 å¤èªè¨ç¿»è­¯åºæºä¸­ï¼NusaMT-7B å¨ spBLEU ææ¨ä¸­åªæ¼ SoTA æ¨¡åï¼å¨ç¿»è­¯æå·´åèªåç±³åå¡ä¿èªæï¼spBLEU æé«å¯æé« +6.69ï¼ä½å¨ç¿»è­¯æé«è³æºèªè¨æï¼spBLEU æä½å¯éä½ -3.38ãæåççµæè¡¨æï¼å¾®èª¿å¾ç LLM å¯ä»¥æé«ä½è³æºèªè¨çç¿»è­¯åè³ªï¼æå©æ¼èªè¨ä¿å­åè·¨æåæºéã

##### **Why do objects have many names? A study on word informativeness in language use and lexical systems**
2410.07827v1 by Eleonora Gualdoni, Gemma Boleda

Human lexicons contain many different words that speakers can use to refer to
the same object, e.g., "purple" or "magenta" for the same shade of color. On
the one hand, studies on language use have explored how speakers adapt their
referring expressions to successfully communicate in context, without focusing
on properties of the lexical system. On the other hand, studies in language
evolution have discussed how competing pressures for informativeness and
simplicity shape lexical systems, without tackling in-context communication. We
aim at bridging the gap between these traditions, and explore why a soft
mapping between referents and words is a good solution for communication, by
taking into account both in-context communication and the structure of the
lexicon. We propose a simple measure of informativeness for words and lexical
systems, grounded in a visual space, and analyze color naming data for English
and Mandarin Chinese. We conclude that optimal lexical systems are those where
multiple words can apply to the same referent, conveying different amounts of
information. Such systems allow speakers to maximize communication accuracy and
minimize the amount of information they convey when communicating about
referents in contexts.

æè¦ï¼äººç±»è¯æ±åå«è®¸å¤ä¸åçåè¯ï¼è¯´è¯èå¯ä»¥ä½¿ç¨è¿äºåè¯æ¥æä»£åä¸ä¸ªå¯¹è±¡ï¼ä¾å¦ï¼å¯¹äºåä¸ç§é¢è²çè²è°ï¼å¯ä»¥ä½¿ç¨âç´«è²âæâæ´çº¢è²âãä¸æ¹é¢ï¼è¯­è¨ä½¿ç¨ç ç©¶æ¢è®¨äºè¯´è¯èå¦ä½è°æ´ä»ä»¬çæç§°è¡¨è¾¾ï¼ä»¥ä¾¿å¨ä¸ä¸æä¸­æåå°è¿è¡äº¤æµï¼èæ²¡æä¸æ³¨äºè¯æ±ç³»ç»çå±æ§ãå¦ä¸æ¹é¢ï¼è¯­è¨æ¼åç ç©¶è®¨è®ºäºä¿¡æ¯æ§åç®åæ§ä¹é´çç«äºååå¦ä½å¡é è¯æ±ç³»ç»ï¼èæ²¡æå¤çä¸ä¸æä¸­äº¤æµãæä»¬çç®æ æ¯å¼¥åè¿äºä¼ ç»ä¹é´çå·®è·ï¼å¹¶æ¢è®¨ä¸ºä»ä¹æç§°ç©ååè¯ä¹é´çè½¯æ å°æ¯éè¿èèä¸ä¸æä¸­çäº¤æµåè¯æ±ç»ææ¥è¿è¡äº¤æµçä¸ä¸ªå¥½è§£å³æ¹æ¡ãæä»¬æåºäºä¸ç§ç®åçåè¯åè¯æ±ç³»ç»ä¿¡æ¯æ§åº¦éï¼å®åºäºè§è§ç©ºé´ï¼å¹¶åæäºè±è¯­åæ®éè¯çè²å½©å½åæ°æ®ãæä»¬å¾åºç»è®ºï¼æä½³è¯æ±ç³»ç»æ¯å¤ä¸ªåè¯å¯ä»¥åºç¨äºåä¸æç§°ç©ï¼ä¼ è¾¾ä¸åæ°éçä¿¡æ¯ãè¿æ ·çç³»ç»åè®¸è¯´è¯èæå¤§åäº¤æµåç¡®æ§ï¼å¹¶å¨ä¸ä¸æä¸­äº¤æµæç§°ç©æ¶æå°åä»ä»¬ä¼ è¾¾çä¿¡æ¯éã

##### **Fine-Tuning Language Models for Ethical Ambiguity: A Comparative Study of Alignment with Human Responses**
2410.07826v1 by Pranav Senthilkumar, Visshwa Balasubramanian, Prisha Jain, Aneesa Maity, Jonathan Lu, Kevin Zhu

Language models often misinterpret human intentions due to their handling of
ambiguity, a limitation well-recognized in NLP research. While morally clear
scenarios are more discernible to LLMs, greater difficulty is encountered in
morally ambiguous contexts. In this investigation, we explored LLM calibration
to show that human and LLM judgments are poorly aligned in such scenarios. We
used two curated datasets from the Scruples project for evaluation: DILEMMAS,
which involves pairs of distinct moral scenarios to assess the model's ability
to compare and contrast ethical situations, and ANECDOTES, which presents
individual narratives to evaluate the model's skill in drawing out details,
interpreting, and analyzing distinct moral scenarios. Model answer
probabilities were extracted for all possible choices and compared with human
annotations to benchmark the alignment of three models: Llama-3.1-8b,
Zephyr-7b-beta, and Mistral-7b. Significant improvements were observed after
fine-tuning, with notable enhancements in both cross-entropy and Dirichlet
scores, particularly in the latter. Notably, after fine-tuning, the performance
of Mistral-7B-Instruct-v0.3 was on par with GPT-4o. However, the experimental
models that were examined were all still outperformed by the BERT and RoBERTa
models in terms of cross-entropy scores. Our fine-tuning approach, which
improves the model's understanding of text distributions in a text-to-text
format, effectively enhances performance and alignment in complex
decision-making contexts, underscoring the need for further research to refine
ethical reasoning techniques and capture human judgment nuances.

æè¦ï¼èªè¨æ¨¡åç¶å¸¸æèª¤è§£äººé¡çæåï¼å çºå®åèçæ­§ç¾©çæ¹å¼ï¼éå¨ NLP ç ç©¶ä¸­æ¯ä¸åå»£çºäººç¥çéå¶ãéç¶å°æ¼ LLM ä¾èªªï¼éå¾·æç¢ºçå ´æ¯æ´å®¹æè¾¨è­ï¼ä½å¨éå¾·æ¨¡ç³çèªå¢ä¸­æéå°æ´å¤§çå°é£ãå¨æ­¤ç ç©¶ä¸­ï¼æåæ¢è¨äº LLM æ ¡æ­£ï¼ä»¥è­æäººé¡å LLM çå¤æ·å¨éç¨®å ´æ¯ä¸­å°é½å¾ä¸å¥½ãæåä½¿ç¨äºä¾èª Scruples å°æ¡çå©åæ´çéçè³æéé²è¡è©ä¼°ï¼DILEMMASï¼å¶ä¸­åå«å©çµä¸åçéå¾·å ´æ¯ï¼ç¨æ¼è©ä¼°æ¨¡åæ¯è¼åå°æ¯éå¾·æå¢ççè½åï¼ä»¥å ANECDOTESï¼å¶ä¸­æä¾äºåå¥æè¿°ï¼ç¨æ¼è©ä¼°æ¨¡åå¨æåç´°ç¯ãè©®éååæä¸åçéå¾·å ´æ¯æ¹é¢çæè½ãæ¨¡åç­æ¡æ©çæè¢«æååºä¾ï¼ä»¥ä¾ææå¯è½çé¸æä½¿ç¨ï¼ä¸¦èäººé¡è¨»è§£é²è¡æ¯è¼ï¼ä»¥åºæºæ¸¬è©¦ä¸åæ¨¡åçå°é½ç¨åº¦ï¼Llama-3.1-8bãZephyr-7b-beta å Mistral-7bãå¨å¾®èª¿å¾è§å¯å°é¡¯èçé²æ­¥ï¼ç¹å¥æ¯å¨å¾èä¸­ï¼äº¤åçµå Dirichlet åæ¸é½æé¡¯èçæåãç¹å¥å¼å¾æ³¨æçæ¯ï¼å¾®èª¿å¾ï¼Mistral-7B-Instruct-v0.3 çæè½è GPT-4o ç¸ç¶ãç¶èï¼å¨äº¤åçµåæ¸æ¹é¢ï¼ææª¢é©çå¯¦é©æ¨¡åä»å¨é½è¢« BERT å RoBERTa æ¨¡åè¶è¶ãæåçå¾®èª¿æ¹æ³æ¹é²äºæ¨¡åå°æå­å°æå­æ ¼å¼ä¸­æå­åä½ççè§£ï¼ææå°æåäºå¨è¤éæ±ºç­å¶å®èªå¢ä¸­çæè½åå°é½ç¨åº¦ï¼å¼·èª¿äºé²ä¸æ­¥ç ç©¶ä»¥æ¹åéå¾·æ¨çæè¡åææäººé¡å¤æ·ç´°å¾®å·®å«çå¿è¦æ§ã

##### **Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models**
2410.07825v1 by Zhipeng Chen, Liang Song, Kun Zhou, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

Multi-lingual ability transfer has become increasingly important for the
broad application of large language models (LLMs). Existing work highly relies
on training with the multi-lingual ability-related data, which may be not
available for low-resource languages. To solve it, we propose a Multi-lingual
Ability Extraction and Transfer approach, named as MAET. Our key idea is to
decompose and extract language-agnostic ability-related weights from LLMs, and
transfer them across different languages by simple addition and subtraction
operations without training. Specially, our MAET consists of the extraction and
transfer stages. In the extraction stage, we firstly locate key neurons that
are highly related to specific abilities, and then employ them to extract the
transferable ability-specific weights. In the transfer stage, we further select
the ability-related parameter tensors, and design the merging strategy based on
the linguistic and ability specific weights, to build the multi-lingual
ability-enhanced LLM. To demonstrate the effectiveness of our proposed
approach, we conduct extensive experiments on mathematical and scientific tasks
in both high-resource lingual and low-resource lingual scenarios. Experiment
results have shown that MAET can effectively and efficiently extract and
transfer the advanced abilities, and outperform training-based baseline
methods. Our code and data are available at
\url{https://github.com/RUCAIBox/MAET}.

æè¦ï¼å¤è¯­è¨è½åè¿ç§»å¯¹äºå¤§è¯­è¨æ¨¡å (LLM) çå¹¿æ³åºç¨åå¾è¶æ¥è¶éè¦ãç°æå·¥ä½é«åº¦ä¾èµäºä½¿ç¨ä¸å¤è¯­è¨è½åç¸å³çæ°æ®è¿è¡è®­ç»ï¼è¿å¯¹äºä½èµæºè¯­è¨æ¥è¯´å¯è½ä¸å¯ç¨ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§åä¸º MAET çå¤è¯­è¨è½åæååè¿ç§»æ¹æ³ãæä»¬çå³é®ææ³æ¯ä» LLM ä¸­åè§£åæåä¸è¯­è¨æ å³çè½åç¸å³æéï¼å¹¶éè¿ç®åçå æ³ååæ³è¿ç®å¨ä¸åè¯­è¨ä¹é´è½¬ç§»å®ä»¬ï¼èæ éè®­ç»ãç¹å«å°ï¼æä»¬ç MAET åå«æååè½¬ç§»é¶æ®µãå¨æåé¶æ®µï¼æä»¬é¦åå®ä½ä¸ç¹å®è½åé«åº¦ç¸å³çå³é®ç¥ç»åï¼ç¶åä½¿ç¨å®ä»¬æ¥æåå¯è½¬ç§»çè½åç¹å®æéãå¨è½¬ç§»é¶æ®µï¼æä»¬è¿ä¸æ­¥éæ©ä¸è½åç¸å³çåæ°å¼ éï¼å¹¶æ ¹æ®è¯­è¨åè½åç¹å®æéè®¾è®¡åå¹¶ç­ç¥ï¼ä»¥æå»ºå¤è¯­è¨è½åå¢å¼ºç LLMãä¸ºäºè¯ææä»¬æåºçæ¹æ³çæææ§ï¼æä»¬å¨é«èµæºè¯­è¨åä½èµæºè¯­è¨åºæ¯ä¸­å¯¹æ°å­¦åç§å­¦ä»»å¡è¿è¡äºå¹¿æ³çå®éªãå®éªç»æè¡¨æï¼MAET å¯ä»¥ææå°æååè½¬ç§»é«çº§è½åï¼å¹¶ä¸ä¼äºåºäºè®­ç»çåºçº¿æ¹æ³ãæä»¬çä»£ç åæ°æ®å¯å¨ \url{https://github.com/RUCAIBox/MAET} è·å¾ã

##### **Mitigating Gender Bias in Code Large Language Models via Model Editing**
2410.07820v1 by Zhanyue Qin, Haochuan Wang, Zecheng Wang, Deyuan Liu, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Dianbo Sui

In recent years, with the maturation of large language model (LLM) technology
and the emergence of high-quality programming code datasets, researchers have
become increasingly confident in addressing the challenges of program synthesis
automatically. However, since most of the training samples for LLMs are
unscreened, it is inevitable that LLMs' performance may not align with
real-world scenarios, leading to the presence of social bias. To evaluate and
quantify the gender bias in code LLMs, we propose a dataset named CodeGenBias
(Gender Bias in the Code Generation) and an evaluation metric called FB-Score
(Factual Bias Score) based on the actual gender distribution of correlative
professions. With the help of CodeGenBias and FB-Score, we evaluate and analyze
the gender bias in eight mainstream Code LLMs. Previous work has demonstrated
that model editing methods that perform well in knowledge editing have the
potential to mitigate social bias in LLMs. Therefore, we develop a model
editing approach named MG-Editing (Multi-Granularity model Editing), which
includes the locating and editing phases. Our model editing method MG-Editing
can be applied at five different levels of model parameter granularity: full
parameters level, layer level, module level, row level, and neuron level.
Extensive experiments not only demonstrate that our MG-Editing can effectively
mitigate the gender bias in code LLMs while maintaining their general code
generation capabilities, but also showcase its excellent generalization. At the
same time, the experimental results show that, considering both the gender bias
of the model and its general code generation capability, MG-Editing is most
effective when applied at the row and neuron levels of granularity.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼éçå¤§è¯­è¨æ¨¡å (LLM) ææ¯çæç
ä»¥åé«è´¨éç¼ç¨ä»£ç æ°æ®éçåºç°ï¼ç ç©¶äººåå¯¹
èªå¨è§£å³ç¨åºåæçææè¶æ¥è¶æä¿¡å¿ãç¶èï¼ç±äº LLM çå¤§å¤æ°è®­ç»æ ·æ¬æ¯
æªç»ç­éçï¼å æ­¤ LLM çæ§è½ä¸å¯é¿åå°å¯è½ä¸
ç°å®ä¸çåºæ¯ä¸ä¸è´ï¼ä»èå¯¼è´ç¤¾ä¼åè§çå­å¨ãä¸ºäºè¯ä¼°å
éåä»£ç  LLM ä¸­çæ§å«åè§ï¼æä»¬æåºäºä¸ä¸ªåä¸º CodeGenBias çæ°æ®é
ï¼ä»£ç çæä¸­çæ§å«åè§ï¼åä¸ä¸ªåºäºç¸å³èä¸çå®éæ§å«åå¸çè¯ä¼°ææ ï¼ç§°ä¸º FB-Score
ï¼äºå®åè§åæ°ï¼ãå¨ CodeGenBias å FB-Score çå¸®å©ä¸ï¼æä»¬è¯ä¼°ååæ
äºå«ä¸ªä¸»æµä»£ç  LLM ä¸­çæ§å«åè§ãä»¥åçå·¥ä½å·²ç»è¯æ
å¨ç¥è¯ç¼è¾ä¸­è¡¨ç°è¯å¥½çæ¨¡åç¼è¾æ¹æ³å·æ
åè½» LLM ä¸­ç¤¾ä¼åè§ãå æ­¤ï¼æä»¬å¼åäºä¸ä¸ªåä¸º MG-Editing çæ¨¡å
ç¼è¾æ¹æ³ï¼å¤ç²åº¦æ¨¡åç¼è¾ï¼ï¼å¶ä¸­åæ¬å®ä½åç¼è¾é¶æ®µãæä»¬çæ¨¡åç¼è¾æ¹æ³ MG-Editing
å¯ä»¥å¨æ¨¡ååæ°ç²åº¦çäºä¸ªä¸åçº§å«ä¸åºç¨ï¼å®æ´
åæ°çº§å«ãå±çº§å«ãæ¨¡åçº§å«ãè¡çº§å«åç¥ç»åçº§å«ã
å¤§éçå®éªä¸ä»è¯æäºæä»¬ç MG-Editing å¯ä»¥ææ
åè½»ä»£ç  LLM ä¸­çæ§å«åè§ï¼åæ¶ä¿æå¶éç¨ä»£ç 
çæè½åï¼ä½ä¹å±ç¤ºäºå¶åºè²çæ³åè½åãåæ¶ï¼å®éªç»æè¡¨æï¼èèæ¨¡åçæ§å«åè§
åå¶éç¨ä»£ç çæè½åï¼MG-Editing å¨è¡åç¥ç»åçº§å«åºç¨æ¶æææ
ç²åº¦ã</paragraph>

##### **Uncovering Overfitting in Large Language Model Editing**
2410.07819v1 by Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen

Knowledge editing has been proposed as an effective method for updating and
correcting the internal knowledge of Large Language Models (LLMs). However,
existing editing methods often struggle with complex tasks, such as multi-hop
reasoning. In this paper, we identify and investigate the phenomenon of Editing
Overfit, where edited models assign disproportionately high probabilities to
the edit target, hindering the generalization of new knowledge in complex
scenarios. We attribute this issue to the current editing paradigm, which
places excessive emphasis on the direct correspondence between the input prompt
and the edit target for each edit sample. To further explore this issue, we
introduce a new benchmark, EVOKE (EValuation of Editing Overfit in Knowledge
Editing), along with fine-grained evaluation metrics. Through comprehensive
experiments and analysis, we demonstrate that Editing Overfit is prevalent in
current editing methods and that common overfitting mitigation strategies are
of limited effectiveness in knowledge editing. To overcome this, inspired by
LLMs' knowledge recall mechanisms, we propose a new plug-and-play strategy
called Learn to Inference (LTI), which introduce a Multi-stage Inference
Constraint module to guide the edited models in recalling new knowledge
similarly to how unedited LLMs leverage knowledge through in-context learning.
Extensive experimental results across a wide range of tasks validate the
effectiveness of LTI in mitigating Editing Overfit.

æè¦ï¼ç¥è­ç·¨è¼¯å·²è¢«æè­°çºæ´æ°åä¿®æ­£å¤§åèªè¨æ¨¡å (LLM) å§é¨ç¥è­çæææ¹æ³ãç¶èï¼ç¾æçç·¨è¼¯æ¹æ³éå¸¸é£ä»¥èçè¤éçä»»åï¼ä¾å¦å¤è·³æ¨çãå¨æ¬æä¸­ï¼æåæ¾åºä¸¦ç ç©¶ç·¨è¼¯éåº¦æ¬åçç¾è±¡ï¼å¶ä¸­å·²ç·¨è¼¯æ¨¡åæå°ä¸ææ¯ä¾çé«æ©çåéçµ¦ç·¨è¼¯ç®æ¨ï¼é»ç¤è¤éå ´æ¯ä¸­æ°ç¥è­çæ¦åãæåå°æ­¤åé¡æ­¸å æ¼ç®åçç·¨è¼¯ç¯ä¾ï¼è©²ç¯ä¾éåº¦å¼·èª¿è¼¸å¥æç¤ºåæ¯åç·¨è¼¯ç¯ä¾çç·¨è¼¯ç®æ¨ä¹éçç´æ¥å°æéä¿ãçºäºé²ä¸æ­¥æ¢è¨éååé¡ï¼æåå¼å¥äºä¸åæ°çåºæº EVOKEï¼ç¥è­ç·¨è¼¯ä¸­ç·¨è¼¯éåº¦æ¬åçè©ä¼°ï¼ï¼ä»¥åç´°ç²åº¦çè©ä¼°ææ¨ãééå¨é¢çå¯¦é©ååæï¼æåè­æç·¨è¼¯éåº¦æ¬åå¨ç®åçç·¨è¼¯æ¹æ³ä¸­å¾æ®éï¼èå¸¸è¦çéåº¦æ¬åç·©è§£ç­ç¥å¨ç¥è­ç·¨è¼¯ä¸­çæææéãçºäºåæéååé¡ï¼åå° LLM ç¥è­åæº¯æ©å¶çåç¼ï¼æåæåºäºä¸ç¨®æ°çå³æå³ç¨ç­ç¥ï¼ç¨±çºå­¸ç¿æ¨è« (LTI)ï¼å®å¼å¥äºä¸åå¤éæ®µæ¨è«ç´ææ¨¡çµï¼ä»¥å¼å°å·²ç·¨è¼¯çæ¨¡ååæº¯æ°ç¥è­ï¼é¡ä¼¼æ¼æªç·¨è¼¯ç LLM å¦ä½ééæå¢å­¸ç¿ä¾å©ç¨ç¥è­ãå¨åç¨®ä»»åä¸­é²è¡çå»£æ³å¯¦é©çµæé©è­äº LTI å¨ç·©è§£ç·¨è¼¯éåº¦æ¬åæ¹é¢çæææ§ã

##### **Temporal-Difference Variational Continual Learning**
2410.07812v1 by Luckeciano C. Melo, Alessandro Abate, Yarin Gal

A crucial capability of Machine Learning models in real-world applications is
the ability to continuously learn new tasks. This adaptability allows them to
respond to potentially inevitable shifts in the data-generating distribution
over time. However, in Continual Learning (CL) settings, models often struggle
to balance learning new tasks (plasticity) with retaining previous knowledge
(memory stability). Consequently, they are susceptible to Catastrophic
Forgetting, which degrades performance and undermines the reliability of
deployed systems. Variational Continual Learning methods tackle this challenge
by employing a learning objective that recursively updates the posterior
distribution and enforces it to stay close to the latest posterior estimate.
Nonetheless, we argue that these methods may be ineffective due to compounding
approximation errors over successive recursions. To mitigate this, we propose
new learning objectives that integrate the regularization effects of multiple
previous posterior estimations, preventing individual errors from dominating
future posterior updates and compounding over time. We reveal insightful
connections between these objectives and Temporal-Difference methods, a popular
learning mechanism in Reinforcement Learning and Neuroscience. We evaluate the
proposed objectives on challenging versions of popular CL benchmarks,
demonstrating that they outperform standard Variational CL methods and
non-variational baselines, effectively alleviating Catastrophic Forgetting.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨å¯¦éæç¨ä¸­çä¸é ééµè½åæ¯
æçºå­¸ç¿æ°ä»»åçè½åãéç¨®é©ææ§è®å®åè½å¤ 
é¨èæéæ¨ç§»å°è³æç¢çåä½ä¸­æ½å¨çä¸å¯é¿åçè½è®ååºåæãç¶èï¼å¨æçºå­¸ç¿ (CL) è¨­å®ä¸­ï¼æ¨¡åéå¸¸é£ä»¥å¨å­¸ç¿æ°ä»»åï¼å¯å¡æ§ï¼èä¿çååç¥è­ï¼è¨æ¶ç©©å®æ§ï¼ä¹éåå¾å¹³è¡¡ãå æ­¤ï¼å®åå®¹æç¼çç½é£æ§éºå¿ï¼éæéä½æè½ä¸¦æå®³å·²é¨ç½²ç³»çµ±çå¯é æ§ãè®ç°æçºå­¸ç¿æ¹æ³ééæ¡ç¨å­¸ç¿ç®æ¨ä¾æå°éåææ°ï¼è©²ç®æ¨æéè¿´æ´æ°å¾é©åä½ä¸¦å¼·å¶å¶ç¶­æå¨ææ°çå¾é©ä¼°è¨å¼éè¿ãåç®¡å¦æ­¤ï¼æåèªçºéäºæ¹æ³å¯è½å é£çºéè¿´çè¿ä¼¼èª¤å·®èç¡æãçºäºæ¸è¼éååé¡ï¼æåæåºæ°çå­¸ç¿ç®æ¨ï¼çµåå¤åååå¾é©ä¼°è¨å¼çæ­£ååææï¼é²æ­¢åå¥èª¤å·®ä¸»å°æªä¾çå¾é©æ´æ°ä¸¦é¨èæéæ¨ç§»èç´¯ç©ãæåæ­ç¤ºäºéäºç®æ¨èæåºå·®åæ¹æ³ä¹éçæ·±å¥éè¯ï¼æåºå·®åæ¹æ³æ¯å¼·åå­¸ç¿åç¥ç¶ç§å­¸ä¸­ä¸ç¨®æµè¡çå­¸ç¿æ©å¶ãæåå¨ç±é CL åºæºçææ°çæ¬ä¸è©ä¼°ææåºçç®æ¨ï¼è­æå®ååªæ¼æ¨æºçè®ç° CL æ¹æ³åéè®ç°åºæºï¼ææå°æ¸è¼äºç½é£æ§éºå¿ã

##### **Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?**
2410.07809v1 by GÃ¼rkan Soykan, GÃ¶zde GÃ¼l Åahin

Multilingual language models often perform unevenly across different
languages due to limited generalization capabilities for some languages. This
issue is significant because of the growing interest in making universal
language models that work well for all languages. Instruction tuning with
multilingual instruction-response pairs has been used to improve model
performance across various languages. However, this approach is challenged by
high computational costs, a lack of quality tuning data for all languages, and
the "curse of multilinguality" -- the performance drop per language after
adding many languages. Recent studies have found that working with datasets
with few languages and a smaller number of instances can be beneficial. Yet,
there exists no systematic investigation into how choosing different languages
affects multilingual instruction tuning. Our study proposes a method to select
languages for instruction tuning in a linguistically informed way, aiming to
boost model performance across languages and tasks. We use a simple algorithm
to choose diverse languages and test their effectiveness on various benchmarks
and open-ended questions. Our results show that this careful selection
generally leads to better outcomes than choosing languages at random. We
suggest a new and simple way of enhancing multilingual models by selecting
diverse languages based on linguistic features that could help develop better
multilingual systems and guide dataset creation efforts. All resources,
including the code for language selection and multilingual instruction tuning,
are made available in our official repository at
https://github.com/GGLAB-KU/ling-informed-mit enabling reproducibility and
further research in this area.

æè¦ï¼å¤èªè¨èªè¨æ¨¡åéå¸¸å¨ä¸åèªè¨ä¹éè¡¨ç¾ä¸åï¼éæ¯å çºæäºèªè¨çæ¦æ¬è½åæéãéååé¡å¾éè¦ï¼å çºäººåè¶ä¾è¶æèè¶£å»ºç«å°ææèªè¨é½ææçéç¨èªè¨æ¨¡åãééå¤èªè¨æä»¤åæéå°é²è¡æä»¤èª¿æ´ï¼å·²ç¨æ¼æ¹ååç¨®èªè¨çæ¨¡åæè½ãç¶èï¼éåæ¹æ³åå°é«éç®ææ¬ãç¼ºä¹ææèªè¨çåè³ªèª¿æ´è³æï¼ä»¥åãå¤èªè¨çè©åãçææ°ï¼ä¹å°±æ¯å¨å å¥è¨±å¤èªè¨å¾ï¼æ¯åèªè¨çæè½é½æä¸éãæè¿çç ç©¶ç¼ç¾ï¼ä½¿ç¨èªè¨è¼å°ä¸å¯¦ä¾æ¸éè¼å°çè³æéæå¾æå¹«å©ãç¶èï¼ç®åå°æªç³»çµ±æ§å°æ¢è¨é¸æä¸åèªè¨å¦ä½å½±é¿å¤èªè¨æä»¤èª¿æ´ãæåçç ç©¶æåºäºä¸ç¨®æ¹æ³ä¾ä»¥èªè¨å­¸çºåºç¤çæ¹å¼é¸ææä»¤èª¿æ´çèªè¨ï¼ç®çæ¯æåè·¨èªè¨åä»»åçæ¨¡åæè½ãæåä½¿ç¨ä¸åç°¡å®çæ¼ç®æ³ä¾é¸æä¸åçèªè¨ï¼ä¸¦å¨åç¨®åºæºåéæ¾å¼åé¡ä¸æ¸¬è©¦å¶æææ§ãæåççµæé¡¯ç¤ºï¼éç¨®ä»ç´°çé¸æéå¸¸ææ¯é¨æ©é¸æèªè¨å¸¶ä¾æ´å¥½çææãæåå»ºè­°ä¸ç¨®æ°ä¸ç°¡å®çæ¹æ³ï¼ééæ ¹æèªè¨ç¹å¾µé¸æä¸åçèªè¨ä¾å¢å¼·å¤èªè¨æ¨¡åï¼éæå©æ¼éç¼æ´å¥½çå¤èªè¨ç³»çµ±ï¼ä¸¦å¼å°è³æéå»ºç«å·¥ä½ãææè³æºï¼åæ¬èªè¨é¸æåå¤èªè¨æä»¤èª¿æ´çç¨å¼ç¢¼ï¼é½å¯ä»¥å¨æåçå®æ¹å­æ¾åº«ä¸­åå¾ï¼https://github.com/GGLAB-KU/ling-informed-mitï¼ä»¥å©æ¼åç¾æ§ï¼ä¸¦é²ä¸æ­¥ç ç©¶éåé åã

##### **Rewriting Conversational Utterances with Instructed Large Language Models**
2410.07797v1 by Elnara Galimzhanova, Cristina Ioana Muntean, Franco Maria Nardini, Raffaele Perego, Guido Rocchietti

Many recent studies have shown the ability of large language models (LLMs) to
achieve state-of-the-art performance on many NLP tasks, such as question
answering, text summarization, coding, and translation. In some cases, the
results provided by LLMs are on par with those of human experts. These models'
most disruptive innovation is their ability to perform tasks via zero-shot or
few-shot prompting. This capability has been successfully exploited to train
instructed LLMs, where reinforcement learning with human feedback is used to
guide the model to follow the user's requests directly. In this paper, we
investigate the ability of instructed LLMs to improve conversational search
effectiveness by rewriting user questions in a conversational setting. We study
which prompts provide the most informative rewritten utterances that lead to
the best retrieval performance. Reproducible experiments are conducted on
publicly-available TREC CAST datasets. The results show that rewriting
conversational utterances with instructed LLMs achieves significant
improvements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and
11.5% in Recall@500 over state-of-the-art techniques.

æè¦ï¼è¨±å¤æè¿çç ç©¶é¡¯ç¤ºï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¨±å¤ NLP ä»»åä¸å±ç¾åºæåé²çæè½ï¼ä¾å¦åç­ãæå­æè¦ãç·¨ç¢¼åç¿»è­¯ãå¨æäºææ³ä¸ï¼LLM æä¾ççµæèäººé¡å°å®¶ççµæä¸ç¸ä¸ä¸ãéäºæ¨¡åæå·ç ´å£æ§çåµæ°æ¯å®åè½å¤ ééé¶æ¬¡å­¸ç¿æå°æ¬¡å­¸ç¿æç¤ºä¾å·è¡ä»»åãéç¨®è½åå·²æåç¨æ¼è¨ç·´æç¤ºå¼ LLMï¼å¶ä¸­ä½¿ç¨å·æäººé¡åé¥çå¼·åå­¸ç¿ä¾å¼å°æ¨¡åç´æ¥éµå¾ªä½¿ç¨èçè«æ±ãå¨æ¬æä¸­ï¼æåæ¢è¨æç¤ºå¼ LLM å¨å°è©±å¼è¨­å®ä¸­æ¹å¯«ä½¿ç¨èåé¡ï¼ä»¥æåå°è©±å¼æå°æè½çè½åãæåç ç©¶åªäºæç¤ºæä¾äºæå¤è³è¨çæ¹å¯«èªå¥ï¼éäºèªå¥å¯å¸¶ä¾æä½³çæª¢ç´¢æè½ãå¯å¨å¬éç TREC CAST è³æéä¸é²è¡å¯è¤è£½çå¯¦é©ãçµæé¡¯ç¤ºï¼ä½¿ç¨æç¤ºå¼ LLM æ¹å¯«å°è©±å¼èªå¥ï¼å¨ MRR æ¹é¢ç²å¾é«é 25.2% çé¡¯èæåï¼å¨ Precision@1 æ¹é¢ç²å¾ 31.7% çæåï¼å¨ NDCG@3 æ¹é¢ç²å¾ 27% çæåï¼å¨ Recall@500 æ¹é¢ç²å¾ 11.5% çæåï¼åªæ¼æåé²çæè¡ã

##### **Do Current Language Models Support Code Intelligence for R Programming Language?**
2410.07793v1 by ZiXiao Zhao, Fatemeh H. Fard

Recent advancements in developing Pre-trained Language Models for Code
(Code-PLMs) have urged many areas of Software Engineering (SE) and brought
breakthrough results for many SE tasks. Though these models have achieved the
state-of-the-art performance for SE tasks for many popular programming
languages, such as Java and Python, the Scientific Software and its related
languages like R programming language have rarely benefited or even been
evaluated with the Code-PLMs. Research has shown that R has many differences
with other programming languages and requires specific techniques. In this
study, we provide the first insights for code intelligence for R. For this
purpose, we collect and open source an R dataset, and evaluate Code-PLMs for
the two tasks of code summarization and method name prediction using several
settings and strategies, including the differences in two R styles, Tidy-verse
and Base R. Our results demonstrate that the studied models have experienced
varying degrees of performance degradation when processing R programming
language code, which is supported by human evaluation. Additionally, not all
models show performance improvement in R-specific tasks even after
multi-language fine-tuning. The dual syntax paradigms in R significantly impact
the models' performance, particularly in code summarization tasks. Furthermore,
the project-specific context inherent in R codebases significantly impacts the
performance when attempting cross-project training.

æè¦ï¼æè¿å¨éç¼ç¨å¼ç¢¼é è¨ç·´èªè¨æ¨¡å (Code-PLM) æ¹é¢åå¾çé²å±ï¼å·²ä¿ä½¿è»é«å·¥ç¨ (SE) çè¨±å¤é åï¼ä¸¦çºè¨±å¤ SE ä»»åå¸¶ä¾çªç ´æ§çææãåç®¡éäºæ¨¡åå·²éå°è¨±å¤ç±éç¨å¼èªè¨ï¼ä¾å¦ Java å Pythonï¼ç SE ä»»åéå°äºæåé²çæè½ï¼ä½ç§å­¸è»é«åå¶ç¸éèªè¨ï¼ä¾å¦ R ç¨å¼èªè¨ï¼å¾å°åçï¼çè³å¾å°ä½¿ç¨ Code-PLM é²è¡è©ä¼°ãç ç©¶è¡¨æï¼R èå¶ä»ç¨å¼èªè¨æè¨±å¤ä¸åä¹èï¼éè¦ç¹å®çæè¡ãå¨éé ç ç©¶ä¸­ï¼æåæä¾äº R çç¨å¼ç¢¼æºæ§çç¬¬ä¸åè¦è§£ãçºæ­¤ï¼æåæ¶éä¸¦éæ¾åå§ç¢¼ R è³æéï¼ä¸¦ä½¿ç¨å¤ç¨®è¨­å®åç­ç¥ï¼åæ¬å©ç¨® R é¢¨æ ¼çå·®ç°ï¼Tidy-verse å Base Rï¼ä¾è©ä¼° Code-PLM çç¨å¼ç¢¼æè¦åæ¹æ³åç¨±é æ¸¬éå©åä»»åãæåççµæè¡¨æï¼å¨èç R ç¨å¼èªè¨ç¨å¼ç¢¼æï¼æç ç©¶çæ¨¡åç¶æ­·äºä¸åç¨åº¦çæè½ä¸éï¼éå¾å°äºäººå·¥è©ä¼°çæ¯æ´ãæ­¤å¤ï¼å³ä½¿å¨å¤èªè¨å¾®èª¿ä¹å¾ï¼ä¸¦éæææ¨¡åå¨ R ç¹å®ä»»åä¸­é½é¡¯ç¤ºåºæè½æåãR ä¸­çééèªæ³ç¯ä¾é¡¯èå½±é¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨ç¨å¼ç¢¼æè¦ä»»åä¸­ãæ­¤å¤ï¼R ç¨å¼ç¢¼åº«ä¸­åºæçå°æ¡ç¹å®å§å®¹ï¼å¨åè©¦è·¨å°æ¡è¨ç·´æï¼æé¡¯èå½±é¿æè½ã

##### **Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation**
2410.07779v1 by Sweta Agrawal, JosÃ© G. C. de Souza, Ricardo Rei, AntÃ³nio Farinhas, GonÃ§alo Faria, Patrick Fernandes, Nuno M Guerreiro, Andre Martins

Alignment with human preferences is an important step in developing accurate
and safe large language models. This is no exception in machine translation
(MT), where better handling of language nuances and context-specific variations
leads to improved quality. However, preference data based on human feedback can
be very expensive to obtain and curate at a large scale. Automatic metrics, on
the other hand, can induce preferences, but they might not match human
expectations perfectly. In this paper, we propose an approach that leverages
the best of both worlds. We first collect sentence-level quality assessments
from professional linguists on translations generated by multiple high-quality
MT systems and evaluate the ability of current automatic metrics to recover
these preferences. We then use this analysis to curate a new dataset, MT-Pref
(metric induced translation preference) dataset, which comprises 18k instances
covering 18 language directions, using texts sourced from multiple domains
post-2022. We show that aligning TOWER models on MT-Pref significantly improves
translation quality on WMT23 and FLORES benchmarks.

æè¦ï¼èäººé¡åå¥½ä¸è´æ¯éç¼æºç¢ºä¸å®å¨çå·¨éèªè¨æ¨¡åçéè¦æ­¥é©ãæ©å¨ç¿»è­¯ (MT) ä¹ä¸ä¾å¤ï¼å¶ä¸­å°èªè¨å·®ç°ç´°å¾®å·®å¥åç¹å®æ¼èçµ¡çè®åçæ´å¥½èçææååè³ªãç¶èï¼åºæ¼äººé¡åé¥çåå¥½è³æå¨åå¾åæ´çä¸å¯è½éå¸¸æè²´ãå¦ä¸æ¹é¢ï¼èªååææ¨å¯ä»¥èªç¼åå¥½ï¼ä½å®åå¯è½ç¡æ³å®ç¾ç¬¦åäººé¡çææãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®çµåå©å¨å¶ç¾çåæ³ãæåé¦åå¾å°æ¥­èªè¨å­¸å®¶æ¶éç±å¤åé«åè³ª MT ç³»çµ±ç¢ççç¿»è­¯çå¥å­å±¤ç´åè³ªè©ä¼°ï¼ä¸¦è©ä¼°ç¶åèªååææ¨æ¢å¾©éäºåå¥½çè½åãç¶å¾ï¼æåä½¿ç¨æ­¤åææ´çä¸åæ°çè³æé MT-Prefï¼ææ¨èªç¼çç¿»è­¯åå¥½ï¼è³æéï¼å¶ä¸­åå« 18k åå¯¦ä¾ï¼æ¶µè 18 ç¨®èªè¨æ¹åï¼ä½¿ç¨ä¾èª 2022 å¹´ä¹å¾å¤åç¶²åçæå­ãæåå±ç¤ºäºå¨ MT-Pref ä¸èª¿æ´ TOWER æ¨¡åæå¨ WMT23 å FLORES åºæºä¸é¡¯èæåç¿»è­¯åè³ªã

##### **Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models**
2410.07771v1 by Adriana Fernandez-Lopez, Shiwei Liu, Lu Yin, Stavros Petridis, Maja Pantic

This paper investigates the under-explored area of low-rank weight training
for large-scale Conformer-based speech recognition models from scratch. Our
study demonstrates the viability of this training paradigm for such models,
yielding several notable findings. Firstly, we discover that applying a
low-rank structure exclusively to the attention modules can unexpectedly
enhance performance, even with a significant rank reduction of 12%. In
contrast, feed-forward layers present greater challenges, as they begin to
exhibit performance degradation with a moderate 50% rank reduction.
Furthermore, we find that both initialization and layer-wise rank assignment
play critical roles in successful low-rank training. Specifically, employing
SVD initialization and linear layer-wise rank mapping significantly boosts the
efficacy of low-rank weight training. Building on these insights, we introduce
the Low-Rank Speech Model from Scratch (LR-SMS), an approach that achieves
performance parity with full-rank training while delivering substantial
reductions in parameters count (by at least 2x), and training time speedups (by
1.3x for ASR and 1.15x for AVSR).

æè¦ï¼æ¬ææ¢è¨äºå¾é ­éå§è¨ç·´å¤§ååºæ¼ Conformer çèªé³è­å¥æ¨¡åçä½ç§©æ¬éè¨ç·´éåå°æªååæ¢ç´¢çé åãæåçç ç©¶è­æäºéç¨®è¨ç·´ç¯ä¾å°æ­¤é¡æ¨¡åçå¯è¡æ§ï¼ä¸¦ç¢çäºå¹¾é å¼å¾æ³¨æçç¼ç¾ãé¦åï¼æåç¼ç¾åå°ä½ç§©çµæ§æç¨æ¼æ³¨æåæ¨¡çµå°±è½æå¤å°æåæè½ï¼å³ä½¿ç§©å¤§å¹éä½äº 12%ãç¸æ¯ä¹ä¸ï¼åé¥å±¤æå¸¶ä¾æ´å¤§çææ°ï¼å çºå®åæå¨ç§©é©åº¦éä½ 50% çææ³ä¸éå§è¡¨ç¾åºæè½ä¸éãæ­¤å¤ï¼æåç¼ç¾åå§ååéå±¤ç§©ææ´¾å¨ä½ç§©è¨ç·´çæåä¸­é½æ®æ¼èééµè§è²ãå·é«ä¾èªªï¼æ¡ç¨ SVD åå§ååç·æ§éå±¤ç§©å°ææé¡¯èæåä½ç§©æ¬éè¨ç·´çæè½ãåºæ¼éäºè¦è§£ï¼æåå¼å¥äºå¾é ­éå§è¨ç·´çä½ç§©èªé³æ¨¡å (LR-SMS)ï¼éæ¯ä¸ç¨®æ¹æ³ï¼å¯ä»¥å¨åæ¸æ¸éå¤§å¹æ¸å°ï¼è³å° 2 åï¼åè¨ç·´æéå å¿«ï¼ASR çº 1.3 åï¼AVSR çº 1.15 åï¼çææ³ä¸ï¼éå°èå¨ç§©è¨ç·´ç¸ç¶çæè½ã

##### **Dialectical Behavior Therapy Approach to LLM Prompting**
2410.07768v1 by Oxana Vitman, Nika Amaglobeli, Paul Plachinda

Large language models demonstrated state-of-the-art results on various
reasoning tasks when applying the chain-of-thought (CoT) prompting technique.
CoT prompting guides the model into breaking tasks into a few intermediate
steps and provides step-by-step demonstrations. However, solving complex
reasoning tasks remains a challenge. In this paper, we propose a novel
prompting strategy inspired by Dialectical Behavioral Therapy (DBT). DBT, a
form of cognitive-behavioral therapy, aims to help individuals cope with stress
by developing a system of reasoning. We applied DBT's basic concepts of shaping
dialog to construct prompts and conducted experiments on different datasets and
LLMs with various numbers of parameters. Our results show that prompts crafted
with DBT techniques significantly improve results on smaller models, achieving
a 7% increase in accuracy on the StrategyQA, 4.8% on Aqua dataset using 8b
parameters model, and a 16.2% increase on the StrategyQA, 5.3% on GSM8K dataset
with 14b parameters model.

æè¦ï¼å¤§åè¯­è¨æ¨¡åå¨åºç¨æç»´é¾ï¼CoTï¼æç¤ºææ¯æ¶ï¼å¨åç§æ¨çä»»å¡ä¸­å±ç¤ºäºæåè¿çç»æãCoT æç¤ºå¼å¯¼æ¨¡åå°ä»»å¡åè§£ä¸ºå ä¸ªä¸­é´æ­¥éª¤ï¼å¹¶æä¾éæ­¥æ¼ç¤ºãç¶èï¼è§£å³å¤æçæ¨çä»»å¡ä»ç¶æ¯ä¸ä¸ªææãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§åè¾©è¯è¡ä¸ºçæ³ (DBT) å¯åçå¨æ°æç¤ºç­ç¥ãDBT æ¯ä¸ç§è®¤ç¥è¡ä¸ºçæ³ï¼æ¨å¨éè¿å»ºç«æ¨çç³»ç»æ¥å¸®å©ä¸ªäººåºå¯¹ååãæä»¬åºç¨äº DBT å¡é å¯¹è¯çåºæ¬æ¦å¿µæ¥æå»ºæç¤ºï¼å¹¶å¨ä¸åçæ°æ®éåå·æä¸åæ°éåæ°ç LLM ä¸è¿è¡äºå®éªãæä»¬çç»æè¡¨æï¼ä½¿ç¨ DBT ææ¯ç²¾å¿è®¾è®¡çæç¤ºå¯ä»¥æ¾çæé«è¾å°æ¨¡åçç»æï¼å¨ StrategyQA ä¸åç¡®çæé«äº 7%ï¼å¨ä½¿ç¨ 8b åæ°æ¨¡åç Aqua æ°æ®éä¸æé«äº 4.8%ï¼å¨ StrategyQA ä¸æé«äº 16.2%ï¼å¨ä½¿ç¨ 14b åæ°æ¨¡åç GSM8K æ°æ®éä¸æé«äº 5.3%ã

##### **GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps**
2410.07765v1 by Muhammad Umair Nasir, Steven James, Julian Togelius

Large language models (LLMs) have recently demonstrated great success in
generating and understanding natural language. While they have also shown
potential beyond the domain of natural language, it remains an open question as
to what extent and in which way these LLMs can plan. We investigate their
planning capabilities by proposing GameTraversalBenchmark (GTB), a benchmark
consisting of diverse 2D grid-based game maps. An LLM succeeds if it can
traverse through given objectives, with a minimum number of steps and a minimum
number of generation errors. We evaluate a number of LLMs on GTB and found that
GPT-4-Turbo achieved the highest score of 44.97% on GTB\_Score (GTBS), a
composite score that combines the three above criteria. Furthermore, we
preliminarily test large reasoning models, namely o1, which scores $67.84\%$ on
GTBS, indicating that the benchmark remains challenging for current models.
Code, data, and documentation are available at
https://github.com/umair-nasir14/Game-Traversal-Benchmark.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æè¿å¨çæåçè§£èªç¶èªè¨æ¹é¢åå¾äºå·¨å¤§çæåãåç®¡å®åä¹å±ç¾äºè¶è¶èªç¶èªè¨é åçæ½åï¼ä½éäº LLM è½å¨å¤å¤§ç¨åº¦ä¸ä»¥åä»¥ä½ç¨®æ¹å¼é²è¡è¦åï¼ä»ç¶æ¯ä¸åéæ¾æ§çåé¡ãæåééæåº GameTraversalBenchmark (GTB) ä¾æ¢è¨å®åçè¦åè½åï¼GTB æ¯ç±å¤ç¨® 2D ç¶²æ ¼åéæ²å°åçµæçåºæºãå¦æ LLM è½ä»¥æå°çæ­¥é©æ¸åæå°ççæé¯èª¤ï¼ç©¿éçµ¦å®çç®æ¨ï¼åè¡¨ç¤ºå®æåäºãæåå¨ GTB ä¸è©ä¼°äºå¤å LLMï¼ç¼ç¾ GPT-4-Turbo å¨ GTB\_Score (GTBS) ä¸åå¾äº 44.97% çæé«åï¼GTBS æ¯çµåä¸è¿°ä¸åæ¨æºçç¶ååæ¸ãæ­¤å¤ï¼æååæ­¥æ¸¬è©¦äºå¤§åæ¨çæ¨¡åï¼å³ o1ï¼å®å¨ GTBS ä¸çå¾åçº 67.84%ï¼éè¡¨ç¤ºè©²åºæºå°æ¼ç®åçæ¨¡åä¾èªªä»ç¶å·æææ°æ§ãå¯ä»¥å¨ https://github.com/umair-nasir14/Game-Traversal-Benchmark æ¾å°ç¨å¼ç¢¼ãè³æåæä»¶ã

##### **HARIVO: Harnessing Text-to-Image Models for Video Generation**
2410.07763v1 by Mingi Kwon, Seoung Wug Oh, Yang Zhou, Difan Liu, Joon-Young Lee, Haoran Cai, Baqiao Liu, Feng Liu, Youngjung Uh

We present a method to create diffusion-based video models from pretrained
Text-to-Image (T2I) models. Recently, AnimateDiff proposed freezing the T2I
model while only training temporal layers. We advance this method by proposing
a unique architecture, incorporating a mapping network and frame-wise tokens,
tailored for video generation while maintaining the diversity and creativity of
the original T2I model. Key innovations include novel loss functions for
temporal smoothness and a mitigating gradient sampling technique, ensuring
realistic and temporally consistent video generation despite limited public
video data. We have successfully integrated video-specific inductive biases
into the architecture and loss functions. Our method, built on the frozen
StableDiffusion model, simplifies training processes and allows for seamless
integration with off-the-shelf models like ControlNet and DreamBooth. project
page: https://kwonminki.github.io/HARIVO

æè¦ï¼æåæåºä¸åæ¹æ³ï¼å¯ä»¥å¾é è¨ç·´çæå­è½åå (T2I) æ¨¡åä¸­å»ºç«åºæ¼æ´æ£çå½±çæ¨¡åãæè¿ï¼AnimateDiff æè­°åçµ T2I æ¨¡åï¼åæåè¨ç·´æéå±¤ãæåééæåºä¸åç¨ç¹çæ¶æ§ä¾æ¨é²æ­¤æ¹æ³ï¼çµåä¸åå°æç¶²è·¯åéå¹ä»£å¹£ï¼å°éç¨æ¼å½±ççæï¼åæç¶­æåå§ T2I æ¨¡åçå¤æ¨£æ§ååµé åãééµåµæ°åæ¬æéå¹³æ»åº¦çæ°æå¤±å½æ¸åç·©è§£æ¢¯åº¦åæ¨£æè¡ï¼ç¢ºä¿é¼çä¸æéä¸è´çå½±ççæï¼åç®¡åéæ¼å¬éå½±çè³æãæåå·²æåå°å½±çç¹å®çæ­¸ç´åå·®æ´åå°æ¶æ§åæå¤±å½æ¸ä¸­ãæåçæ¨¡åå»ºç«å¨åçµç StableDiffusion æ¨¡åä¸ï¼ç°¡åäºè¨ç·´æµç¨ï¼ä¸¦åè¨±è ControlNet å DreamBooth ç­ç¾ææ¨¡åç¡ç¸«æ´åãå°æ¡é é¢ï¼https://kwonminki.github.io/HARIVO

##### **$\textit{Jump Your Steps}$: Optimizing Sampling Schedule of Discrete Diffusion Models**
2410.07761v1 by Yong-Hyun Park, Chieh-Hsin Lai, Satoshi Hayakawa, Yuhta Takida, Yuki Mitsufuji

Diffusion models have seen notable success in continuous domains, leading to
the development of discrete diffusion models (DDMs) for discrete variables.
Despite recent advances, DDMs face the challenge of slow sampling speeds. While
parallel sampling methods like $\tau$-leaping accelerate this process, they
introduce $\textit{Compounding Decoding Error}$ (CDE), where discrepancies
arise between the true distribution and the approximation from parallel token
generation, leading to degraded sample quality. In this work, we present
$\textit{Jump Your Steps}$ (JYS), a novel approach that optimizes the
allocation of discrete sampling timesteps by minimizing CDE without extra
computational cost. More precisely, we derive a practical upper bound on CDE
and propose an efficient algorithm for searching for the optimal sampling
schedule. Extensive experiments across image, music, and text generation show
that JYS significantly improves sampling quality, establishing it as a
versatile framework for enhancing DDM performance for fast sampling.

æè¦ï¼æ´æ£æ¨¡åå¨é£çºåä¸­å·²ç²å¾é¡¯èçæåï¼é²èä¿æäºé¢æ£è®æ¸çé¢æ£æ´æ£æ¨¡å (DDM) çç¼å±ãåç®¡æè¿æçé²å±ï¼DDM é¢è¨èåæ¨£éåº¦ç·©æ¢çææ°ãéç¶å $\tau$-èºé·ç­ä¸¦è¡åæ¨£æ¹æ³å éäºéåéç¨ï¼ä½å®åå¼å¥äº$\textit{è¤åè§£ç¢¼èª¤å·®}$ (CDE)ï¼å¶ä¸­çå¯¦åä½èä¸¦è¡ç¬¦èç¢ççè¿ä¼¼å¼ä¹éåºç¾å·®ç°ï¼å°è´æ¨£æ¬åè³ªä¸éãå¨éé å·¥ä½ä¸­ï¼æåæåºäº$\textit{è·³èºä½ çæ­¥é©}$ (JYS)ï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼ééæå°å CDE ä¾æä½³åé¢æ£åæ¨£æéæ­¥é·çéç½®ï¼èç¡éé¡å¤çéç®ææ¬ãæ´ç²¾ç¢ºå°èªªï¼æåæ¨å°åº CDE çå¯¦ç¨ä¸éï¼ä¸¦æåºäºä¸ç¨®ç¨æ¼æå°æä½³åæ¨£æç¨çæææ¼ç®æ³ãè·¨è¶å½±åãé³æ¨åæå­çæçå»£æ³å¯¦é©é¡¯ç¤ºï¼JYS å¤§å¹æ¹åäºåæ¨£åè³ªï¼ç¢ºç«äºå®ä½çºä¸åéç¨çæ¡æ¶ï¼ç¨æ¼å¢å¼· DDM æè½ä»¥é²è¡å¿«éåæ¨£ã

##### **Learning Low-Level Causal Relations using a Simulated Robotic Arm**
2410.07751v1 by Miroslav Cibula, Matthias Kerzel, Igor FarkaÅ¡

Causal learning allows humans to predict the effect of their actions on the
known environment and use this knowledge to plan the execution of more complex
actions. Such knowledge also captures the behaviour of the environment and can
be used for its analysis and the reasoning behind the behaviour. This type of
knowledge is also crucial in the design of intelligent robotic systems with
common sense. In this paper, we study causal relations by learning the forward
and inverse models based on data generated by a simulated robotic arm involved
in two sensorimotor tasks. As a next step, we investigate feature attribution
methods for the analysis of the forward model, which reveals the low-level
causal effects corresponding to individual features of the state vector related
to both the arm joints and the environment features. This type of analysis
provides solid ground for dimensionality reduction of the state
representations, as well as for the aggregation of knowledge towards the
explainability of causal effects at higher levels.

æè¦ï¼å æå­¸ç¿è®äººåè½å¤ é æ¸¬å¶è¡çºå°å·²ç¥ç°å¢çå½±é¿ï¼ä¸¦å©ç¨æ­¤ç¥è­ä¾è¦åå·è¡æ´è¤éçè¡çºãæ­¤é¡ç¥è­ä¹ææç°å¢çè¡çºï¼å¯ä¾å¶åæåè¡çºèå¾çæ¨çä½¿ç¨ãæ­¤é¡åçç¥è­å¨å·åå¸¸è­çæºæ§åæ©å¨äººç³»çµ±è¨­è¨ä¸­ä¹è³ééè¦ãå¨æ¬æä¸­ï¼æåééå­¸ç¿åºæ¼æ¨¡æ¬æ©å¨æèåèå©é ææ¸¬éåä»»åæç¢çè³æçæ­£ååååæ¨¡åä¾ç ç©¶å æéä¿ãä½çºä¸ä¸æ­¥ï¼æåèª¿æ¥æ­£åæ¨¡ååæçåè½å±¬æ§æ¹æ³ï¼æ­ç¤ºèæèéç¯åç°å¢ç¹å¾µç¸éççæåéçåå¥ç¹å¾µå°æçä½éå æææãæ­¤é¡åçåæçºçæè¡¨ç¤ºçç¶­åº¦ç¸®æ¸æä¾äºå å¯¦çåºç¤ï¼ä¸¦çºæ´é«å±¤ç´å æææçå¯è§£éæ§å½æ´ç¥è­ã

##### **StepTool: A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs**
2410.07745v1 by Yuanqing Yu, Zhefan Wang, Weizhi Ma, Zhicheng Guo, Jingtao Zhan, Shuai Wang, Chuhan Wu, Zhiqiang Guo, Min Zhang

Despite having powerful reasoning and inference capabilities, Large Language
Models (LLMs) still need external tools to acquire real-time information
retrieval or domain-specific expertise to solve complex tasks, which is
referred to as tool learning. Existing tool learning methods primarily rely on
tuning with expert trajectories, focusing on token-sequence learning from a
linguistic perspective. However, there are several challenges: 1) imitating
static trajectories limits their ability to generalize to new tasks. 2) even
expert trajectories can be suboptimal, and better solution paths may exist. In
this work, we introduce StepTool, a novel step-grained reinforcement learning
framework to improve tool learning in LLMs. It consists of two components:
Step-grained Reward Shaping, which assigns rewards at each tool interaction
based on tool invocation success and its contribution to the task, and
Step-grained Optimization, which uses policy gradient methods to optimize the
model in a multi-step manner. Experimental results demonstrate that StepTool
significantly outperforms existing methods in multi-step, tool-based tasks,
providing a robust solution for complex task environments. Codes are available
at https://github.com/yuyq18/StepTool.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) ææå¼·å¤§çæ¨çåæ¨è«è½åï¼ä½ä»éè¦å¤é¨å·¥å·ä¾ç²åå³æè³è¨æª¢ç´¢æç¹å®é åçå°æ¥­ç¥è­ï¼ä»¥è§£æ±ºè¤éä»»åï¼éè¢«ç¨±çºå·¥å·å­¸ç¿ãç¾æçå·¥å·å­¸ç¿æ¹æ³ä¸»è¦ä¾è³´æ¼å°å®¶è»è·¡çèª¿æ´ï¼å°æ³¨æ¼å¾èªè¨å­¸çè§åº¦é²è¡ä»¤çåºåå­¸ç¿ãç¶èï¼æå¹¾åææ°ï¼1) æ¨¡ä»¿éæè»è·¡éå¶äºå®åæ³åå°æ°ä»»åçè½åã2) å³ä½¿æ¯å°å®¶è»è·¡ä¹å¯è½ä¸æ¯æä½³çï¼ä¸¦ä¸å¯è½å­å¨æ´å¥½çè§£æ±ºæ¹æ¡è·¯å¾ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº StepToolï¼éæ¯ä¸åæ°ç©çæ­¥é©åå¼·åå­¸ç¿æ¡æ¶ï¼ç¨æ¼æ¹é² LLM ä¸­çå·¥å·å­¸ç¿ãå®åå«å©åçµæé¨åï¼æ­¥é©åçåµèª¿æ´ï¼å®æ ¹æå·¥å·èª¿ç¨æååå¶å°ä»»åçè²¢ç»å¨æ¯æ¬¡å·¥å·äºåæåéçåµï¼ä»¥åæ­¥é©åæä½³åï¼å®ä½¿ç¨ç­ç¥æ¢¯åº¦æ¹æ³ä»¥å¤æ­¥é©çæ¹å¼æä½³åæ¨¡åãå¯¦é©çµæè¡¨æï¼StepTool å¨åºæ¼å·¥å·çå¤æ­¥é©ä»»åä¸­é¡¯èåªæ¼ç¾ææ¹æ³ï¼çºè¤éä»»åç°å¢æä¾äºä¸åç©©å¥çè§£æ±ºæ¹æ¡ãç¨å¼ç¢¼å¯å¨ https://github.com/yuyq18/StepTool ç²å¾ã

##### **SLIM: Let LLM Learn More and Forget Less with Soft LoRA and Identity Mixture**
2410.07739v1 by Jiayi Han, Liang Du, Hongwei Du, Xiangguo Zhou, Yiwen Wu, Weibo Zheng, Donghong Han

Although many efforts have been made, it is still a challenge to balance the
training budget, downstream performance, and the general capabilities of the
LLMs in many applications. Training the whole model for downstream tasks is
expensive, and could easily result in catastrophic forgetting. By introducing
parameter-efficient fine-tuning (PEFT), the training cost could be reduced, but
it still suffers from forgetting, and limits the learning on the downstream
tasks. To efficiently fine-tune the LLMs with less limitation to their
downstream performance while mitigating the forgetting of general capabilities,
we propose a novel mixture of expert (MoE) framework based on Soft LoRA and
Identity Mixture (SLIM), that allows dynamic routing between LoRA adapters and
skipping connection, enables the suppression of forgetting. We adopt
weight-yielding with sliding clustering for better out-of-domain distinguish to
enhance the routing. We also propose to convert the mixture of low-rank
adapters to the model merging formulation and introduce fast dynamic merging of
LoRA adapters to keep the general capabilities of the base model. Extensive
experiments demonstrate that the proposed SLIM is comparable to the
state-of-the-art PEFT approaches on the downstream tasks while achieving the
leading performance in mitigating catastrophic forgetting.

æè¦ï¼åç®¡å·²ååºè¨±å¤åªåï¼ä½å¨è¨±å¤æç¨ä¸­å¹³è¡¡ LLM çè¨ç·´é ç®ãä¸æ¸¸æè½åä¸è¬åè½ä»æ¯ä¸é ææ°ãéå°ä¸æ¸¸ä»»åè¨ç·´æ´åæ¨¡åå¾æè²´ï¼èä¸å¾å®¹æå°è´ç½é£æ§éºå¿ãééå¼å¥åæ¸ææå¾®èª¿ (PEFT)ï¼è¨ç·´ææ¬å¯ä»¥éä½ï¼ä½å®ä»ç¶æéºå¿ï¼ä¸¦éå¶ä¸æ¸¸ä»»åçå­¸ç¿ãçºäºææå¾®èª¿ LLMï¼åææ¸å°å°å¶ä¸æ¸¸æè½çéå¶ï¼ä¸¦æ¸è¼ä¸è¬åè½çéºå¿ï¼æåæåºä¸ååºæ¼ Soft LoRA åèº«åæ··å (SLIM) çå°å®¶æ··å (MoE) æ¡æ¶ï¼åè¨±å¨ LoRA é©éå¨åè·³æ¥é£æ¥ä¹éé²è¡åæè·¯ç±ï¼ä¸¦æå¶éºå¿ãæåæ¡ç¨å¸¶ææ»åèé¡çæ¬éè®æ­¥ï¼ä»¥ç²å¾æ´å¥½çç¶²åå¤ååï¼ä»¥å¢å¼·è·¯ç±ãæåéå»ºè­°å°ä½éé©éå¨çæ··åè½æçºæ¨¡ååä½µå¬å¼ï¼ä¸¦å¼å¥ LoRA é©éå¨çå¿«éåæåä½µï¼ä»¥ä¿æåºç¤æ¨¡åçä¸è¬åè½ãå»£æ³çå¯¦é©è­æï¼ææåºç SLIM å¨ä¸æ¸¸ä»»åä¸å¯èæåé²ç PEFT æ¹æ³ç¸åª²ç¾ï¼åæå¨æ¸è¼ç½é£æ§éºå¿æ¹é¢åå¾é åçæè½ã

##### **Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning**
2410.07738v1 by Jingyuan Zhang, Yiyang Duan, Shuaicheng Niu, Yang Cao, Wei Yang Bryan Lim

Federated Domain Adaptation (FDA) is a Federated Learning (FL) scenario where
models are trained across multiple clients with unique data domains but a
shared category space, without transmitting private data. The primary challenge
in FDA is data heterogeneity, which causes significant divergences in gradient
updates when using conventional averaging-based aggregation methods, reducing
the efficacy of the global model. This further undermines both in-domain and
out-of-domain performance (within the same federated system but outside the
local client). To address this, we propose a novel framework called
\textbf{M}ulti-domain \textbf{P}rototype-based \textbf{F}ederated
Fine-\textbf{T}uning (MPFT). MPFT fine-tunes a pre-trained model using
multi-domain prototypes, i.e., pretrained representations enriched with
domain-specific information from category-specific local data. This enables
supervised learning on the server to derive a globally optimized adapter that
is subsequently distributed to local clients, without the intrusion of data
privacy. Empirical results show that MPFT significantly improves both in-domain
and out-of-domain accuracy over conventional methods, enhancing knowledge
preservation and adaptation in FDA. Notably, MPFT achieves convergence within a
single communication round, greatly reducing computation and communication
costs. To ensure privacy, MPFT applies differential privacy to protect the
prototypes. Additionally, we develop a prototype-based feature space hijacking
attack to evaluate robustness, confirming that raw data samples remain
unrecoverable even after extensive training epochs. The complete implementation
of MPFL is available at \url{https://anonymous.4open.science/r/DomainFL/}.

æè¦ï¼<paragraph>è¯é¦åé©æï¼FDAï¼æ¯ä¸ç¨®è¯é¦å­¸ç¿ï¼FLï¼å ´æ¯ï¼å¶ä¸­
æ¨¡åå¨å·æå¯ä¸æ¸æåä½å±äº«é¡å¥ç©ºéçå¤åå®¢æ¶ç«¯ä¸é²è¡è¨ç·´ï¼èä¸æå³è¼¸ç§äººæ¸æãFDA ä¸­çä¸»è¦ææ°æ¯æ¸æç°è³ªæ§ï¼éæå°è´ä½¿ç¨å³çµ±åºæ¼å¹³åçèåæ¹æ³ææ¢¯åº¦æ´æ°åºç¾é¡¯èå·®ç°ï¼å¾èéä½å¨å±æ¨¡åçæè½ãéé²ä¸æ­¥æå®³äºåå§ååå¤æè½ï¼å¨åä¸åè¯é¦ç³»çµ±ä¸­ï¼ä½å¨æ¬å°å®¢æ¶ç«¯ä¹å¤ï¼ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ååçº
\textbf{M}ulti-domain \textbf{P}rototype-based \textbf{F}ederated
Fine-\textbf{T}uning (MPFT) çæ°æ¡æ¶ãMPFT ä½¿ç¨å¤åååå¾®èª¿é è¨ç·´æ¨¡åï¼å³é è¨ç·´è¡¨ç¤ºï¼å¶ä¸­åå«ä¾èªé¡å¥ç¹å®æ¬å°æ¸æçç¹å®æ¼åçä¿¡æ¯ãéä½¿å¾ä¼ºæå¨ä¸çç£ç£å­¸ç¿è½å¤ æ¨å°åºä¸åå¨å±æä½³åçé©éå¨ï¼é¨å¾å°å¶åç¼å°æ¬å°å®¢æ¶ç«¯ï¼èä¸æä¾µç¯æ¸æé±ç§ãç¶é©çµæè¡¨æï¼MPFT å¨åå§ååå¤æºç¢ºåº¦æ¹é¢é½é¡¯èåªæ¼å³çµ±æ¹æ³ï¼å¢å¼·äº FDA ä¸­çç¥è­ä¿çåé©æãå¼å¾æ³¨æçæ¯ï¼MPFT å¨å®æ¬¡éä¿¡ååå§å¯¦ç¾æ¶æï¼å¤§å¤§éä½äºè¨ç®åéä¿¡ææ¬ãçºäºç¢ºä¿é±ç§ï¼MPFT æç¨å·®åé±ç§ä¾ä¿è­·ååãæ­¤å¤ï¼æåéç¼äºä¸ååºæ¼ååçç¹å¾µç©ºéå«ææ»æä¾è©ä¼°é­¯æ£æ§ï¼ç¢ºèªå³ä½¿ç¶éå¤§éçè¨ç·´ææï¼åå§æ¸ææ¨£æ¬ä»ç¶ç¡æ³æ¢å¾©ãMPFL çå®æ´å¯¦ä½å¯å¨ \url{https://anonymous.4open.science/r/DomainFL/} ä¸­åå¾ã</paragraph>

##### **On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models**
2410.07717v1 by Gabriel Jarry, Ramon Dalmau, Philippe Very, Junzi Sun

Accurately estimating aircraft fuel flow is essential for evaluating new
procedures, designing next-generation aircraft, and monitoring the
environmental impact of current aviation practices. This paper investigates the
generalization capabilities of deep learning models in predicting fuel
consumption, focusing particularly on their performance for aircraft types
absent from the training data. We propose a novel methodology that integrates
neural network architectures with domain generalization techniques to enhance
robustness and reliability across a wide range of aircraft. A comprehensive
dataset containing 101 different aircraft types, separated into training and
generalization sets, with each aircraft type set containing 1,000 flights. We
employed the base of aircraft data (BADA) model for fuel flow estimates,
introduced a pseudo-distance metric to assess aircraft type similarity, and
explored various sampling strategies to optimize model performance in
data-sparse regions. Our results reveal that for previously unseen aircraft
types, the introduction of noise into aircraft and engine parameters improved
model generalization. The model is able to generalize with acceptable mean
absolute percentage error between 2\% and 10\% for aircraft close to existing
aircraft, while performance is below 1\% error for known aircraft in the
training set. This study highlights the potential of combining domain-specific
insights with advanced machine learning techniques to develop scalable,
accurate, and generalizable fuel flow estimation models.

æè¦ï¼æºç¢ºä¼°è¨é£æ©çææµéå°æ¼è©ä¼°æ°ç¨åºãè¨­è¨æ°ä¸ä»£é£æ©ä»¥åç£æ§ç¾è¡èªç©ºå¯¦åçç°å¢å½±é¿è³ééè¦ãæ¬ææ¢è¨æ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬çææ¶èæ¹é¢çæ³åè½åï¼ç¹å¥éæ³¨å®åå¨è¨ç·´è³æä¸­æ²æçé£æ©é¡åçæè½ãæåæåºä¸ååµæ°çæ¹æ³è«ï¼å°ç¥ç¶ç¶²è·¯æ¶æ§èé åæ³åæè¡æ´åï¼ä»¥å¢å¼·åç¨®é£æ©çç©©å¥æ§åå¯é æ§ãä¸ååå« 101 ç¨®ä¸åé£æ©é¡åçç¶åè³æéï¼åçºè¨ç·´éåæ³åéï¼æ¯åé£æ©é¡åéåå« 1,000 åèªç­ãæåæ¡ç¨é£æ©è³æåº« (BADA) æ¨¡åä¾ä¼°è¨çææµéï¼å¼é²ä¸åå½è·é¢éåº¦ä¾è©ä¼°é£æ©é¡åçç¸ä¼¼æ§ï¼ä¸¦æ¢ç´¢åç¨®åæ¨£ç­ç¥ï¼ä»¥æä½³åè³æç¨çååçæ¨¡åæè½ãæåççµæé¡¯ç¤ºï¼å°æ¼ä»¥åæªè¦çé£æ©é¡åï¼å¨é£æ©åå¼æåæ¸ä¸­å¼å¥éè¨å¯ä»¥æ¹åæ¨¡åæ³åãå°æ¼æ¥è¿ç¾æé£æ©çé£æ©ï¼è©²æ¨¡åè½å¤ ä»¥ 2% å° 10% ä¹éçå¯æ¥åå¹³åçµå°ç¾åæ¯èª¤å·®é²è¡æ³åï¼èå°æ¼è¨ç·´éä¸­å·²ç¥çé£æ©ï¼æè½ä½æ¼ 1% çèª¤å·®ãéé ç ç©¶å¼·èª¿äºçµåç¹å®é åè¦è§£èé²éæ©å¨å­¸ç¿æè¡ä»¥éç¼å¯æ´åãæºç¢ºä¸å¯æ³åççææµéä¼°è¨æ¨¡åçæ½åã

##### **Learning Tree Pattern Transformations**
2410.07708v1 by Daniel Neider, Leif Sabellek, Johannes Schmidt, Fabian Vehlken, Thomas Zeume

Explaining why and how a tree $t$ structurally differs from another tree
$t^*$ is a question that is encountered throughout computer science, including
in understanding tree-structured data such as XML or JSON data. In this
article, we explore how to learn explanations for structural differences
between pairs of trees from sample data: suppose we are given a set $\{(t_1,
t_1^*),\dots, (t_n, t_n^*)\}$ of pairs of labelled, ordered trees; is there a
small set of rules that explains the structural differences between all pairs
$(t_i, t_i^*)$? This raises two research questions: (i) what is a good notion
of "rule" in this context?; and (ii) how can sets of rules explaining a data
set be learnt algorithmically?
  We explore these questions from the perspective of database theory by (1)
introducing a pattern-based specification language for tree transformations;
(2) exploring the computational complexity of variants of the above algorithmic
problem, e.g. showing NP-hardness for very restricted variants; and (3)
discussing how to solve the problem for data from CS education research using
SAT solvers.

æè¦ï¼<paragraph>è§£éæ¨¹ $t$ å¨çµæ§ä¸èå¦ä¸æ£µæ¨¹ $t^*$ æä½ä¸åï¼ä»¥ååå çºä½ï¼æ¯é»è¦ç§å­¸é åä¸­ç¶å¸¸éå°çåé¡ï¼åæ¬å¨çè§£æ¨¹ççµæ§è³æï¼ä¾å¦ XML æ JSON è³æï¼æãå¨æ¬æä¸­ï¼æåæ¢è¨å¦ä½å¾ç¯ä¾è³æä¸­å­¸ç¿æ¨¹å°ä¹éçµæ§å·®ç°çè§£éï¼åè¨­æåçµ¦å®ä¸çµæ¨ç±¤ãæåºæ¨¹å° $\{(t_1, t_1^*),\dots, (t_n, t_n^*)\}$ï¼æ¯å¦å­å¨ä¸çµå°è¦åï¼å¯ä»¥è§£éææå° $(t_i, t_i^*)$ ä¹éççµæ§å·®ç°ï¼éæåºäºå©åç ç©¶åé¡ï¼(i) å¨éåèçµ¡ä¸­ï¼ãè¦åãçè¯å¥½æ¦å¿µæ¯ä»éº¼ï¼(ii) å¦ä½æ¼ç®æ³å­¸ç¿è§£éè³æéçè¦åéï¼
æåå¾è³æåº«çè«çè§åº¦æ¢è¨éäºåé¡ï¼æ¹æ³æ¯ï¼(1) ä»ç´¹æ¨¹çè½æçåºæ¼æ¨¡å¼çè¦ç¯èªè¨ï¼(2) æ¢è¨ä¸è¿°æ¼ç®æ³åé¡è®é«çè¨ç®è¤éåº¦ï¼ä¾å¦é¡¯ç¤ºéå¸¸åéè®é«ç NP é£åº¦ï¼ä»¥å (3) è¨è«å¦ä½ä½¿ç¨ SAT æ±è§£å¨è§£æ±ºä¾èªé»è¦ç§å­¸æè²ç ç©¶çè³æåé¡ã</paragraph>

##### **AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories**
2410.07706v1 by Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng, Sujian Li

Fine-tuning on agent-environment interaction trajectory data holds
significant promise for surfacing generalized agent capabilities in open-source
large language models (LLMs). In this work, we introduce AgentBank, by far the
largest trajectory tuning data collection featuring more than 50k diverse
high-quality interaction trajectories which comprises 16 tasks covering five
distinct agent skill dimensions. Leveraging a novel annotation pipeline, we are
able to scale the annotated trajectories and generate a trajectory dataset with
minimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a
series of agent models, Samoyed. Our comparative experiments demonstrate the
effectiveness of scaling the interaction trajectory data to acquire generalized
agent capabilities. Additional studies also reveal some key observations
regarding trajectory tuning and agent skill generalization.

æè¦ï¼å¨ä»£çç°å¢äºåè»è·¡è³æä¸é²è¡å¾®èª¿ï¼å°æ¼å¨éæºå¤§åèªè¨æ¨¡å (LLM) ä¸­æµ®ç¾å»£ç¾©çä»£çåè½å·æé¡¯èçå¸æãå¨éåå·¥ä½ä¸­ï¼æåä»ç´¹äº AgentBankï¼ç®åçºæ­¢æå¤§çè»è·¡èª¿æ ¡è³ææ¶éï¼å·æè¶é 50k åå¤æ¨£åçåªè³ªäºåè»è·¡ï¼å¶ä¸­åå«æ¶µèäºåä¸åä»£çæè½ç¶­åº¦ç 16 åä»»åãå©ç¨æ°ç©çè¨»éç®¡éï¼æåè½å¤ æ´å±è¨»éçè»è·¡ä¸¦çæå·ææå°åé£åº¦åå·®çè»è·¡è³æéãæ­¤å¤ï¼æåå¨ AgentBank ä¸å¾®èª¿ LLM ä»¥ç²å¾ä¸ç³»åä»£çæ¨¡åï¼Samoyedãæåçæ¯è¼å¯¦é©è­æäºæ´å±äºåè»è·¡è³æä»¥ç²åå»£ç¾©ä»£çåè½çæææ§ãå¶ä»ç ç©¶ä¹æ­ç¤ºäºä¸äºéæ¼è»è·¡èª¿æ ¡åä»£çæè½æ¦æ¬åçééµè§å¯ã

##### **Multi-Facet Counterfactual Learning for Content Quality Evaluation**
2410.07693v1 by Jiasheng Zheng, Hongyu Lin, Boxi Cao, Meng Liao, Yaojie Lu, Xianpei Han, Le Sun

Evaluating the quality of documents is essential for filtering valuable
content from the current massive amount of information. Conventional approaches
typically rely on a single score as a supervision signal for training content
quality evaluators, which is inadequate to differentiate documents with quality
variations across multiple facets. In this paper, we propose Multi-facet
cOunterfactual LEarning (MOLE), a framework for efficiently constructing
evaluators that perceive multiple facets of content quality evaluation. Given a
specific scenario, we prompt large language models to generate counterfactual
content that exhibits variations in critical quality facets compared to the
original document. Furthermore, we leverage a joint training strategy based on
contrastive learning and supervised learning to enable the evaluator to
distinguish between different quality facets, resulting in more accurate
predictions of content quality scores. Experimental results on 2 datasets
across different scenarios demonstrate that our proposed MOLE framework
effectively improves the correlation of document content quality evaluations
with human judgments, which serve as a valuable toolkit for effective
information acquisition.

æè¦ï¼è©ä¼°æä»¶åè³ªå°æ¼å¾ç¶åå¤§éçè³è¨ä¸­éæ¿¾åºæå¹å¼çå§å®¹è³ééè¦ãå³çµ±æ¹æ³éå¸¸ä¾è³´å®ä¸è©åä½çºè¨ç·´å§å®¹åè³ªè©ä¼°å¡çç£ç£è¨èï¼éä¸è¶³ä»¥ååå¨å¤åé¢åå·æåè³ªå·®ç°çæä»¶ãå¨æ¬æä¸­ï¼æåæåºå¤é¢ååäºå¯¦å­¸ç¿ (MOLE)ï¼ä¸åç¨æ¼ææå»ºæ§è©ä¼°å¡çæ¶æ§ï¼è©²è©ä¼°å¡è½æç¥å§å®¹åè³ªè©ä¼°çå¤åé¢åãéå°ç¹å®æå¢ï¼æåæç¤ºå¤§åèªè¨æ¨¡åç¢çåäºå¯¦å§å®¹ï¼èåå§æä»¶ç¸æ¯ï¼éäºå§å®¹å¨ééµåè³ªé¢åä¸­è¡¨ç¾åºå·®ç°ãæ­¤å¤ï¼æåå©ç¨åºæ¼å°æ¯å­¸ç¿åç£ç£å­¸ç¿çè¯åè¨ç·´ç­ç¥ï¼è®è©ä¼°å¡è½å¤ ååä¸åçåè³ªé¢åï¼é²èæ´æºç¢ºå°é æ¸¬å§å®¹åè³ªè©åãå¨ä¸åæå¢ä¸­ç 2 åè³æéä¸çå¯¦é©çµæè¡¨æï¼æåæåºç MOLE æ¡æ¶ææå°æ¹åäºæä»¶å§å®¹åè³ªè©ä¼°èäººé¡å¤æ·ä¹éçç¸éæ§ï¼éæ¯ä¸åç¨æ¼ææè³è¨ç²åçæå¹å¼å·¥å·åã

##### **Smart Audit System Empowered by LLM**
2410.07677v1 by Xu Yao, Xiaoxu Wu, Xi Li, Huan Xu, Chenlei Li, Ping Huang, Si Li, Xiaoning Ma, Jiulong Shan

Manufacturing quality audits are pivotal for ensuring high product standards
in mass production environments. Traditional auditing processes, however, are
labor-intensive and reliant on human expertise, posing challenges in
maintaining transparency, accountability, and continuous improvement across
complex global supply chains. To address these challenges, we propose a smart
audit system empowered by large language models (LLMs). Our approach introduces
three innovations: a dynamic risk assessment model that streamlines audit
procedures and optimizes resource allocation; a manufacturing compliance
copilot that enhances data processing, retrieval, and evaluation for a
self-evolving manufacturing knowledge base; and a Re-act framework commonality
analysis agent that provides real-time, customized analysis to empower
engineers with insights for supplier improvement. These enhancements elevate
audit efficiency and effectiveness, with testing scenarios demonstrating an
improvement of over 24%.

æè¦ï¼è£½é åè³ªç¨½æ ¸å°æ¼ç¢ºä¿å¤§éçç¢ç°å¢ä¸­çé«ç¢åæ¨æºè³ééè¦ãç¶èï¼å³çµ±çç¨½æ ¸ç¨åºéè¦å¤§éäººåï¼ä¸ä¾è³´æ¼äººçºå°æ¥­ç¥è­ï¼å¨ç¶­æéæåº¦ãè²¬ä»»å¶åè·¨è¤éå¨çä¾æéçæçºæ¹é²æ¹é¢æ§æææ°ãçºäºæå°éäºææ°ï¼æåæåºä¸åç±å¤§åèªè¨æ¨¡å (LLM) è³¦è½çæºæ§ç¨½æ ¸ç³»çµ±ãæåçåæ³å¼é²äºä¸é åµæ°ï¼ç°¡åç¨½æ ¸ç¨åºä¸¦æä½³åè³æºéç½®çåæé¢¨éªè©ä¼°æ¨¡åï¼å¢å¼·è³æèçãæ·ååè©ä¼°ä»¥å»ºç«èªæ¼åè£½é ç¥è­åº«çè£½é åè¦è¼å©ç³»çµ±ï¼ä»¥åæä¾å³æãå®¢è£½ååæä»¥è³¦äºå·¥ç¨å¸«ä¾æåæ¹åè¦è§£ç Re-act æ¶æ§å±æ§åæä»£çãéäºå¼·åæåäºç¨½æ ¸æçåæè½ï¼æ¸¬è©¦æå¢é¡¯ç¤ºæ¹åå¹åº¦è¶é 24%ã

##### **Adversarial Robustness Overestimation and Instability in TRADES**
2410.07675v1 by Jonathan Weiping Li, Ren-Wei Liang, Cheng-Han Yeh, Cheng-Chang Tsai, Kuanchun Yu, Chun-Shien Lu, Shang-Tse Chen

This paper examines the phenomenon of probabilistic robustness overestimation
in TRADES, a prominent adversarial training method. Our study reveals that
TRADES sometimes yields disproportionately high PGD validation accuracy
compared to the AutoAttack testing accuracy in the multiclass classification
task. This discrepancy highlights a significant overestimation of robustness
for these instances, potentially linked to gradient masking. We further analyze
the parameters contributing to unstable models that lead to overestimation. Our
findings indicate that smaller batch sizes, lower beta values (which control
the weight of the robust loss term in TRADES), larger learning rates, and
higher class complexity (e.g., CIFAR-100 versus CIFAR-10) are associated with
an increased likelihood of robustness overestimation. By examining metrics such
as the First-Order Stationary Condition (FOSC), inner-maximization, and
gradient information, we identify the underlying cause of this phenomenon as
gradient masking and provide insights into it. Furthermore, our experiments
show that certain unstable training instances may return to a state without
robust overestimation, inspiring our attempts at a solution. In addition to
adjusting parameter settings to reduce instability or retraining when
overestimation occurs, we recommend incorporating Gaussian noise in inputs when
the FOSC score exceed the threshold. This method aims to mitigate robustness
overestimation of TRADES and other similar methods at its source, ensuring more
reliable representation of adversarial robustness during evaluation.

æè¦ï¼éç¯è«ææ¢è¨äº TRADES ä¸­æ©çç©©å¥æ§é«ä¼°çç¾è±¡ï¼TRADES æ¯ä¸ç¨®èåçå°ææ§è¨ç·´æ¹æ³ãæåçç ç©¶é¡¯ç¤ºï¼å¨å¤é¡å¥åé¡ä»»åä¸­ï¼è AutoAttack æ¸¬è©¦æºç¢ºåº¦ç¸æ¯ï¼TRADES æææç¢çä¸ææ¯ä¾çé« PGD é©è­æºç¢ºåº¦ãéç¨®å·®ç°çªé¡¯äºå°éäºå¯¦ä¾çç©©å¥æ§é«ä¼°ï¼å¯è½èæ¢¯åº¦é®è½æéãæåé²ä¸æ­¥åæäºå°è´é«ä¼°çä¸ç©©å®æ¨¡åçåæ¸ãæåçç¼ç¾è¡¨æï¼è¼å°çæ¹æ¬¡å¤§å°ãè¼ä½ç beta å¼ï¼æ§å¶ TRADES ä¸­ç©©å¥æå¤±é çæ¬éï¼ãè¼é«çå­¸ç¿çåè¼é«çé¡å¥è¤éåº¦ï¼ä¾å¦ï¼CIFAR-100 è CIFAR-10ï¼èç©©å¥æ§é«ä¼°çå¯è½æ§å¢å æéãééæª¢æ¥ä¸éå¹³ç©©æ¢ä»¶ (FOSC)ãå§é¨æå¤§ååæ¢¯åº¦è³è¨ç­ææ¨ï¼æåå°éç¨®ç¾è±¡çæ ¹æ¬åå ç¢ºå®çºæ¢¯åº¦é®è½ï¼ä¸¦å°å¶æä¾äºè¦è§£ãæ­¤å¤ï¼æåçå¯¦é©è¡¨æï¼æäºä¸ç©©å®çè¨ç·´å¯¦ä¾å¯è½æè¿åå°æ²æç©©å¥é«ä¼°ççæï¼éæ¿ç¼äºæååè©¦è§£æ±ºæ¹æ¡ãé¤äºèª¿æ´åæ¸è¨­å®ä»¥æ¸å°ä¸ç©©å®æ§æå¨ç¼çé«ä¼°æéæ°è¨ç·´ä¹å¤ï¼æåå»ºè­°å¨ FOSC åæ¸è¶éé¾å¼æå¨è¼¸å¥ä¸­å å¥é«æ¯åªè²ãéç¨®æ¹æ³æ¨å¨å¾æºé ­æ¸è¼ TRADES åå¶ä»é¡ä¼¼æ¹æ³çç©©å¥æ§é«ä¼°ï¼ç¢ºä¿å¨è©ä¼°éç¨ä¸­æ´å¯é å°è¡¨ç¤ºå°ææ§ç©©å¥æ§ã

##### **Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference**
2410.07673v1 by Jianxing Yu, Shiqi Wang, Han Yin, Zhenlong Sun, Ruobing Xie, Bo Zhang, Yanghui Rao

This paper focuses on detecting clickbait posts on the Web. These posts often
use eye-catching disinformation in mixed modalities to mislead users to click
for profit. That affects the user experience and thus would be blocked by
content provider. To escape detection, malicious creators use tricks to add
some irrelevant non-bait content into bait posts, dressing them up as legal to
fool the detector. This content often has biased relations with non-bait
labels, yet traditional detectors tend to make predictions based on simple
co-occurrence rather than grasping inherent factors that lead to malicious
behavior. This spurious bias would easily cause misjudgments. To address this
problem, we propose a new debiased method based on causal inference. We first
employ a set of features in multiple modalities to characterize the posts.
Considering these features are often mixed up with unknown biases, we then
disentangle three kinds of latent factors from them, including the invariant
factor that indicates intrinsic bait intention; the causal factor which
reflects deceptive patterns in a certain scenario, and non-causal noise. By
eliminating the noise that causes bias, we can use invariant and causal factors
to build a robust model with good generalization ability. Experiments on three
popular datasets show the effectiveness of our approach.

æè¦ï¼æ¬è«æå°æ³¨æ¼åµæ¸¬ç¶²è·¯ä¸çè³åæ¨é¡è²¼æãéäºè²¼æéå¸¸ä½¿ç¨å¼äººæ³¨ç®çé¯èª¤è³è¨ï¼ä¸¦ä»¥æ··åæ¨¡å¼èª¤å°ä½¿ç¨èé»æä»¥ç²å©ãéæå½±é¿ä½¿ç¨èé«é©ï¼å æ­¤æè¢«å§å®¹æä¾èå°éãçºäºéé¿åµæ¸¬ï¼æ¡æåµä½èæä½¿ç¨æå·§å°ä¸äºç¡éçéèªé¤å§å®¹å å¥èªé¤è²¼æä¸­ï¼å°å®åå½è£æåæ³çè²¼æä»¥æå¼åµæ¸¬å¨ãéäºå§å®¹éå¸¸èéèªé¤æ¨ç±¤æåèª¤çéè¯ï¼ä½å³çµ±çåµæ¸¬å¨å¾åæ¼æ ¹æç°¡å®çå±ç¾ï¼èä¸æ¯ææ¡å°è´æ¡æè¡çºçå§å¨å ç´ ä¾ååºé æ¸¬ãéç¨®èåçåèª¤å¾å®¹æé æé¯èª¤å¤æ·ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°çåºæ¼å ææ¨è«çå»åæ¹æ³ãæåé¦åä½¿ç¨å¤ç¨®æ¨¡å¼ä¸­çä¸çµç¹å¾µä¾æè¿°è²¼æãèæ®å°éäºç¹å¾µéå¸¸èæªç¥çåèª¤æ··å¨ä¸èµ·ï¼æåæ¥èå¾ä¸­è§£éä¸ç¨®é¡åçæ½å¨å ç´ ï¼åæ¬è¡¨ç¤ºå§å¨èªé¤æåçä¸è®å ç´ ï¼å¨ç¹å®å ´æ¯ä¸­åæ æ¬ºé¨æ¨¡å¼çå æå ç´ ï¼ä»¥åéå æåªé³ãééæ¶é¤é æåèª¤çåªé³ï¼æåå¯ä»¥ä½¿ç¨ä¸è®åå æå ç´ ä¾å»ºç«ä¸åå·æè¯å¥½æ³åè½åçå¼·å¥æ¨¡åãå¨ä¸åç±éè³æéä¸çå¯¦é©é¡¯ç¤ºäºæåæ¹æ³çæææ§ã

##### **MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization**
2410.07672v1 by Yougang Lyu, Lingyong Yan, Zihan Wang, Dawei Yin, Pengjie Ren, Maarten de Rijke, Zhaochun Ren

As large language models (LLMs) are rapidly advancing and achieving
near-human capabilities, aligning them with human values is becoming more
urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong
alignment problem where we need to effectively align strong student LLMs
through weak supervision generated by weak teachers. Existing alignment methods
mainly focus on strong-to-weak alignment and self-alignment settings, and it is
impractical to adapt them to the much harder weak-to-strong alignment setting.
To fill this gap, we propose a multi-agent contrastive preference optimization
(MACPO) framework. MACPO facilitates weak teachers and strong students to learn
from each other by iteratively reinforcing unfamiliar positive behaviors while
penalizing familiar negative ones. To get this, we devise a mutual positive
behavior augmentation strategy to encourage weak teachers and strong students
to learn from each other's positive behavior and further provide higher quality
positive behavior for the next iteration. Additionally, we propose a hard
negative behavior construction strategy to induce weak teachers and strong
students to generate familiar negative behavior by fine-tuning on negative
behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets,
evaluated using both automatic metrics and human judgments, demonstrate that
MACPO simultaneously improves the alignment performance of strong students and
weak teachers. Moreover, as the number of weak teachers increases, MACPO
achieves better weak-to-strong alignment performance through more iteration
optimization rounds.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¿«éé²æ­¥ä¸¦éå°æ¥è¿äººé¡çè½åï¼ä½¿å¶èäººé¡å¹å¼è§ä¿æä¸è´è®å¾æ´å è¿«åãå¨ LLM åªæ¼äººé¡çå ´æ¯ä¸­ï¼æåé¢è¨ä¸åå¼±å°å¼·çä¸è´æ§åé¡ï¼æåéè¦ééå¼±æå¸«ç¢ççå¼±ç£ç£ä¾ææå°èª¿æ´å¼·å­¸ç LLMãç¾æçä¸è´æ§æ¹æ³ä¸»è¦éæ³¨å¼·å°å¼±çä¸è´æ§åèªå°é½è¨­å®ï¼èä¸å°å®åé©æå°æ´å°é£çå¼±å°å¼·çä¸è´æ§è¨­å®æ¯ä¸åå¯¦éçãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºäºä¸åå¤ä¸»é«å°æ¯åå¥½æä½³å (MACPO) æ¡æ¶ãMACPO ä¿é²å¼±æå¸«åå¼·å­¸çééåè¦å å¼·ä¸çæçæ­£é¢è¡çºä¸¦æ²ç½°çæçè² é¢è¡çºä¾ç¸äºå­¸ç¿ãçºäºå¯¦ç¾éä¸ç®æ¨ï¼æåè¨­è¨äºä¸åç¸äºçæ­£é¢è¡çºå¢å¼·ç­ç¥ä¾é¼åµå¼±æå¸«åå¼·å­¸çç¸äºå­¸ç¿å½¼æ­¤çæ­£é¢è¡çºï¼ä¸¦é²ä¸æ­¥çºä¸ä¸æ¬¡è¿­ä»£æä¾æ´é«åè³ªçæ­£é¢è¡çºãæ­¤å¤ï¼æåæåºäºä¸åç¡¬è² é¢è¡çºæ§å»ºç­ç¥ï¼ä»¥èªå°å¼±æå¸«åå¼·å­¸çééå°è² é¢è¡çºæ¸æé²è¡å¾®èª¿ä¾ç¢ççæçè² é¢è¡çºãå¨ HH-RLHF å PKU-SafeRLHF æ¸æéä¸çå¯¦é©çµæï¼ä½¿ç¨èªåææ¨åäººé¡å¤æ·é²è¡è©ä¼°ï¼è¡¨æ MACPO åææé«äºå¼·å­¸çåå¼±æå¸«çä¸è´æ§è¡¨ç¾ãæ­¤å¤ï¼é¨èå¼±æå¸«çæ¸éå¢å ï¼MACPO ééæ´å¤çè¿­ä»£æä½³åååå¯¦ç¾äºæ´å¥½çå¼±å°å¼·çä¸è´æ§è¡¨ç¾ã

##### **DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation**
2410.07671v1 by Xiaoshan Yu, Chuan Qin, Qi Zhang, Chen Zhu, Haiping Ma, Xingyi Zhang, Hengshu Zhu

The rapid development of online recruitment platforms has created
unprecedented opportunities for job seekers while concurrently posing the
significant challenge of quickly and accurately pinpointing positions that
align with their skills and preferences. Job recommendation systems have
significantly alleviated the extensive search burden for job seekers by
optimizing user engagement metrics, such as clicks and applications, thus
achieving notable success. In recent years, a substantial amount of research
has been devoted to developing effective job recommendation models, primarily
focusing on text-matching based and behavior modeling based methods. While
these approaches have realized impressive outcomes, it is imperative to note
that research on the explainability of recruitment recommendations remains
profoundly unexplored. To this end, in this paper, we propose DISCO, a
hierarchical Disentanglement based Cognitive diagnosis framework, aimed at
flexibly accommodating the underlying representation learning model for
effective and interpretable job recommendations. Specifically, we first design
a hierarchical representation disentangling module to explicitly mine the
hierarchical skill-related factors implied in hidden representations of job
seekers and jobs. Subsequently, we propose level-aware association modeling to
enhance information communication and robust representation learning both
inter- and intra-level, which consists of the interlevel knowledge influence
module and the level-wise contrastive learning. Finally, we devise an
interaction diagnosis module incorporating a neural diagnosis function for
effectively modeling the multi-level recruitment interaction process between
job seekers and jobs, which introduces the cognitive measurement theory.

æè¦ï¼ç·ä¸æåå¹³å°çå¿«éç¼å±çºæ±è·èåµé äºåææªæçæ©æï¼åæä¹å¸¶ä¾äºå¿«éä¸æºç¢ºæ¾åºèå¶æè½ååå¥½ç¸ç¬¦è·ä½çéå¤§ææ°ãæ±è·æ¨è¦ç³»çµ±ééæä½³åä½¿ç¨èåèåº¦ææ¨ï¼ä¾å¦é»æåæå¾µï¼ï¼å¤§å¹æ¸è¼æ±è·èçå»£æ³æå°è² æï¼å èç²å¾é¡¯èçæåãè¿å¹´ä¾ï¼å¤§éç ç©¶è´åæ¼éç¼ææçæ±è·æ¨è¦æ¨¡åï¼ä¸»è¦èéæ¼åºæ¼æå­æ¯å°ååºæ¼è¡çºå»ºæ¨¡çæ¹æ³ãåç®¡éäºæ¹æ³å·²å¯¦ç¾ä»¤äººå°è±¡æ·±å»çææï¼ä½å¿é æ³¨æçæ¯ï¼å°æ¼æåæ¨è¦çå¯è§£éæ§ç ç©¶ä»æªæ·±å¥æ¢è¨ãçºæ­¤ï¼æåå¨æ¬æä¸­æåº DISCOï¼ä¸ååºæ¼éå±¤å¼è§£éçèªç¥è¨ºæ·æ¶æ§ï¼æ¨å¨éæ´»å®¹ç´åºç¤è¡¨å¾µå­¸ç¿æ¨¡åï¼ä»¥æä¾ææä¸å¯è§£éçæ±è·æ¨è¦ãå·é«ä¾èªªï¼æåé¦åè¨­è¨ä¸åéå±¤å¼è¡¨å¾µè§£éæ¨¡çµï¼ä»¥æç¢ºæ¾åºé±å«å¨æ±è·èåè·åçé±èè¡¨å¾µä¸­çéå±¤å¼æè½ç¸éå ç´ ãé¨å¾ï¼æåæåºå±¤ç´æç¥éè¯å»ºæ¨¡ï¼ä»¥å¢å¼·è³è¨å³éåå¼·å¥è¡¨å¾µå­¸ç¿ï¼åæ¬å±¤ç´éç¥è­å½±é¿æ¨¡çµåå±¤ç´å°æ¯å­¸ç¿ãæå¾ï¼æåè¨­è¨äºä¸åäºåè¨ºæ·æ¨¡çµï¼çµåç¥ç¶è¨ºæ·å½æ¸ï¼ä»¥ææå»ºæ¨¡æ±è·èèè·åä¹éçå¤å±¤æ¬¡æåäºåéç¨ï¼ä¸¦å¼å¥èªç¥æ¸¬éçè«ã

##### **StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models**
2410.07652v1 by Minchan Kwon, Gaeun Kim, Jongsuk Kim, Haeil Lee, Junmo Kim

Finding appropriate prompts for the specific task has become an important
issue as the usage of Large Language Models (LLM) has expanded. Reinforcement
Learning (RL) is widely used for prompt tuning, but its inherent instability
and environmental dependency make it difficult to use in practice. In this
paper, we propose StablePrompt, which strikes a balance between training
stability and search space, mitigating the instability of RL and producing
high-performance prompts. We formulate prompt tuning as an online RL problem
between the agent and target LLM and introduce Adaptive Proximal Policy
Optimization (APPO). APPO introduces an LLM anchor model to adaptively adjust
the rate of policy updates. This allows for flexible prompt search while
preserving the linguistic ability of the pre-trained LLM. StablePrompt
outperforms previous methods on various tasks including text classification,
question answering, and text generation. Our code can be found in github.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çä½¿ç¨æ´å¤§ï¼æ¾å°ç¹å®ä»»åçé©ç¶æç¤ºå·²æçºä¸åéè¦è­°é¡ãå¼·åå­¸ç¿ (RL) å»£æ³ç¨æ¼æç¤ºèª¿æ´ï¼ä½å¶å§å¨çä¸ç©©å®æ§èç°å¢ä¾è³´æ§ä½¿å¶é£ä»¥å¨å¯¦åä¸­ä½¿ç¨ãå¨æ¬æä¸­ï¼æåæåº StablePromptï¼å®å¨è¨ç·´ç©©å®æ§èæå°ç©ºéä¹éåå¾å¹³è¡¡ï¼æ¸è¼ RL çä¸ç©©å®æ§ä¸¦ç¢çé«æ§è½æç¤ºãæåå°æç¤ºèª¿æ´å¶å®çºä»£çèç®æ¨ LLM ä¹éçç·ä¸ RL åé¡ï¼ä¸¦å¼å¥é©ææ§è¿ç«¯ç­ç¥æä½³å (APPO)ãAPPO å¼å¥ LLM é¨å®æ¨¡åä¾é©ææ§èª¿æ´ç­ç¥æ´æ°çéçãéåè¨±éæ´»çæç¤ºæå°ï¼åæä¿çé åè¨ç·´ LLM çèªè¨è½åãStablePrompt å¨åç¨®ä»»åä¸åªæ¼ååçåç¨®æ¹æ³ï¼åæ¬æå­åé¡ãåé¡è§£ç­åæå­çæãæåçç¨å¼ç¢¼å¯ä»¥å¨ github ä¸­æ¾å°ã

##### **Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits**
2410.07638v1 by Yunlong Hou, Vincent Y. F. Tan, Zixin Zhong

We propose a {\em novel} piecewise stationary linear bandit (PSLB) model,
where the environment randomly samples a context from an unknown probability
distribution at each changepoint, and the quality of an arm is measured by its
return averaged over all contexts. The contexts and their distribution, as well
as the changepoints are unknown to the agent. We design {\em
Piecewise-Stationary $\varepsilon$-Best Arm Identification$^+$}
(PS$\varepsilon$BAI$^+$), an algorithm that is guaranteed to identify an
$\varepsilon$-optimal arm with probability $\ge 1-\delta$ and with a minimal
number of samples. PS$\varepsilon$BAI$^+$ consists of two subroutines,
PS$\varepsilon$BAI and {\sc Na\"ive $\varepsilon$-BAI} (N$\varepsilon$BAI),
which are executed in parallel. PS$\varepsilon$BAI actively detects
changepoints and aligns contexts to facilitate the arm identification process.
When PS$\varepsilon$BAI and N$\varepsilon$BAI are utilized judiciously in
parallel, PS$\varepsilon$BAI$^+$ is shown to have a finite expected sample
complexity. By proving a lower bound, we show the expected sample complexity of
PS$\varepsilon$BAI$^+$ is optimal up to a logarithmic factor. We compare
PS$\varepsilon$BAI$^+$ to baseline algorithms using numerical experiments which
demonstrate its efficiency. Both our analytical and numerical results
corroborate that the efficacy of PS$\varepsilon$BAI$^+$ is due to the delicate
change detection and context alignment procedures embedded in
PS$\varepsilon$BAI.

æè¦ï¼<paragraph>æåæåºä¸å{\em æ°ç©ç}åæ®µå¹³ç©©ç·æ§è³­å¾æ© (PSLB) æ¨¡åï¼
å¶ä¸­ç°å¢å¨æ¯åè®æ´é»å¾æªç¥æ©çåä½ä¸­é¨æ©æ½æ¨£ä¸åæå¢ï¼èæèçåè³ªåç±å¶å¨æææå¢ä¸­å¹³ååå ±ä¾è¡¡éãæå¢åå¶åä½ä»¥åè®æ´é»å°ä»£çäººèè¨é½æ¯æªç¥çãæåè¨­è¨äº{\em åæ®µå¹³ç©© $\varepsilon$-æä½³æèè¾¨è­$^+$}
(PS$\varepsilon$BAI$^+$)ï¼éæ¯ä¸åæ¼ç®æ³ï¼ä¿è­è½ä»¥æ©ç $\ge 1-\delta$ ä¸æå°çåæ¨£æ¸ç®æ¾åºä¸å $\varepsilon$-æåªæèãPS$\varepsilon$BAI$^+$ åå«å©åå­å¸¸å¼ï¼PS$\varepsilon$BAI å {\sc æ¨¸ç´  $\varepsilon$-BAI} (N$\varepsilon$BAI)ï¼å®åä¸¦è¡å·è¡ãPS$\varepsilon$BAI ä¸»ååµæ¸¬è®æ´é»ä¸¦èª¿æ´æå¢ä»¥å©æ¼æèè¾¨è­æµç¨ãç¶ PS$\varepsilon$BAI å N$\varepsilon$BAI ä¸¦è¡ææºå°ä½¿ç¨æï¼PS$\varepsilon$BAI$^+$ å·²é¡¯ç¤ºå·ææéé æåæ¨£è¤éåº¦ãééè­æä¸çï¼æåé¡¯ç¤º PS$\varepsilon$BAI$^+$ çé æåæ¨£è¤éåº¦æä½³ï¼æå¤å·®ä¸åå°æ¸å å­ãæåä½¿ç¨æ¸å¼å¯¦é©å° PS$\varepsilon$BAI$^+$ èåºç·æ¼ç®æ³é²è¡æ¯è¼ï¼è­æå¶æçãæåçåæåæ¸å¼çµæé½è­å¯¦ PS$\varepsilon$BAI$^+$ çæè½æ­¸å æ¼ PS$\varepsilon$BAI ä¸­åµå¥çç²¾ç´°è®æ´åµæ¸¬åæå¢èª¿æ´ç¨åºã</paragraph>

##### **Automatic Curriculum Expert Iteration for Reliable LLM Reasoning**
2410.07627v1 by Zirui Zhao, Hanze Dong, Amrita Saha, Caiming Xiong, Doyen Sahoo

Hallucinations (i.e., generating plausible but inaccurate content) and
laziness (i.e. excessive refusals or defaulting to "I don't know") persist as
major challenges in LLM reasoning. Current efforts to reduce hallucinations
primarily focus on factual errors in knowledge-grounded tasks, often neglecting
hallucinations related to faulty reasoning. Meanwhile, some approaches render
LLMs overly conservative, limiting their problem-solving capabilities. To
mitigate hallucination and laziness in reasoning tasks, we propose Automatic
Curriculum Expert Iteration (Auto-CEI) to enhance LLM reasoning and align
responses to the model's capabilities--assertively answering within its limits
and declining when tasks exceed them. In our method, Expert Iteration explores
the reasoning trajectories near the LLM policy, guiding incorrect paths back on
track to reduce compounding errors and improve robustness; it also promotes
appropriate "I don't know" responses after sufficient reasoning attempts. The
curriculum automatically adjusts rewards, incentivizing extended reasoning
before acknowledging incapability, thereby pushing the limits of LLM reasoning
and aligning its behaviour with these limits. We compare Auto-CEI with various
SOTA baselines across logical reasoning, mathematics, and planning tasks, where
Auto-CEI achieves superior alignment by effectively balancing assertiveness and
conservativeness.

æè¦ï¼å¹»è¦ºï¼ä¾å¦ç¢çä¼¼æ¯èéä½æèª¤çå§å®¹ï¼åæ¶æ°ï¼ä¾å¦éåº¦æçµæé è¨­çºãæä¸ç¥éãï¼ä»ç¶æ¯ LLM æ¨çä¸­çä¸»è¦ææ°ãç®åæ¸å°å¹»è¦ºçåªåä¸»è¦éä¸­æ¼åºæ¼ç¥è­çä»»åä¸­çäºå¯¦é¯èª¤ï¼èç¶å¸¸å¿½ç¥èé¯èª¤æ¨çç¸éçå¹»è¦ºãåæï¼æäºæ¹æ³æè® LLM éæ¼ä¿å®ï¼éå¶å¶åé¡è§£æ±ºè½åãçºäºæ¸è¼æ¨çä»»åä¸­çå¹»è¦ºåæ¶æ°ï¼æåæåºèªåèª²ç¨å°å®¶è¿­ä»£ (Auto-CEI) ä¾å¢å¼· LLM æ¨çï¼ä¸¦è®åæèæ¨¡åçè½åä¿æä¸è´ââå¨å¶éå¶ç¯åå§èªä¿¡å°åç­ï¼ä¸¦å¨ä»»åè¶åºå¶è½åç¯åææçµãå¨æåçæ¨¡åä¸­ï¼å°å®¶è¿­ä»£æ¢ç´¢ LLM ç­ç¥éè¿çæ¨çè»è·¡ï¼å¼å°ä¸æ­£ç¢ºçè·¯ç·åå°æ­£è»ï¼ä»¥æ¸å°ç´¯ç©é¯èª¤ä¸¦æé«ç©©å¥æ§ï¼å®éé©ç¶å°å¨ç¶éè¶³å¤ çæ¨çåè©¦å¾ä¿é²ãæä¸ç¥éãçåæãèª²ç¨æèªåèª¿æ´çåµï¼å¨æ¿èªç¡è½çºåä¹åæ¿åµå»¶ä¼¸æ¨çï¼å¾èæ´å± LLM æ¨ççéå¶ï¼ä¸¦è®å¶è¡çºèéäºéå¶ä¿æä¸è´ãæåå¨éè¼¯æ¨çãæ¸å­¸åè¦åä»»åä¸­å° Auto-CEI èåç¨® SOTA åºæºé²è¡æ¯è¼ï¼çµæç¼ç¾ Auto-CEI ééææå¹³è¡¡èªä¿¡åä¿å®æåº¦ï¼éå°äºåè¶çä¸è´æ§ã

##### **Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation**
2410.07618v1 by Kaiyuan Liu, Jiahao Mei, Hengyu Zhang, Yihuai Zhang, Xingjiao Wu, Daoguo Dong, Liang He

Although Chinese calligraphy generation has achieved style transfer,
generating calligraphy by specifying the calligrapher, font, and character
style remains challenging. To address this, we propose a new Chinese
calligraphy generation model 'Moyun' , which replaces the Unet in the Diffusion
model with Vision Mamba and introduces the TripleLabel control mechanism to
achieve controllable calligraphy generation. The model was tested on our
large-scale dataset 'Mobao' of over 1.9 million images, and the results
demonstrate that 'Moyun' can effectively control the generation process and
produce calligraphy in the specified style. Even for calligraphy the
calligrapher has not written, 'Moyun' can generate calligraphy that matches the
style of the calligrapher.

æè¦ï¼åç®¡ä¸­ææ¸æ³çæå·²éæé¢¨æ ¼è½ç§»ï¼ä½ééæå®æ¸æ³å®¶ãå­ååå­é«é¢¨æ ¼ä¾çææ¸æ³ä»å·ææ°æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åæ°çä¸­ææ¸æ³çææ¨¡åãå¢¨é²ãï¼å®ç¨ Vision Mamba åä»£ Diffusion æ¨¡åä¸­ç Unetï¼ä¸¦å¼å¥ TripleLabel æ§å¶æ©å¶ä¾éæå¯æ§çæ¸æ³çæãè©²æ¨¡åå·²å¨æåè¶é 190 è¬å¼µåççå¤§è¦æ¨¡è³æéãå¢¨å¯¶ãä¸­é²è¡æ¸¬è©¦ï¼çµæè¡¨æãå¢¨é²ãå¯ä»¥ææå°æ§å¶çæéç¨ï¼ä¸¦ç¢çæå®é¢¨æ ¼çæ¸æ³ãå³ä½¿å°æ¼æ¸æ³å®¶æªå¯«éçæ¸æ³ï¼ãå¢¨é²ãä¹è½çæèæ¸æ³å®¶é¢¨æ ¼ç¸ç¬¦çæ¸æ³ã

