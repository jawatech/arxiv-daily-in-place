{"2502.14644": {"publish_time": "2025-02-20", "title": "LIFT: Improving Long Context Understanding of Large Language Models through Long Input Fine-Tuning", "paper_summary": "Long context understanding remains challenging for large language models due\nto their limited context windows. This paper presents Long Input Fine-Tuning\n(LIFT), a novel framework for long-context modeling that can improve the\nlong-context performance of arbitrary (short-context) LLMs by dynamically\nadapting model parameters based on the long input. Importantly, LIFT, rather\nthan endlessly extending the context window size to accommodate increasingly\nlonger inputs in context, chooses to store and absorb the long input in\nparameter. By fine-tuning the long input into model parameters, LIFT allows\nshort-context LLMs to answer questions even when the required information is\nnot provided in the context during inference. Furthermore, to enhance LIFT\nperformance while maintaining the original in-context learning (ICL)\ncapabilities, we introduce Gated Memory, a specialized attention adapter that\nautomatically balances long input memorization and ICL. We provide a\ncomprehensive analysis of the strengths and limitations of LIFT on long context\nunderstanding, offering valuable directions for future research.", "paper_summary_zh": "\u7531\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u8996\u7a97\u6709\u9650\uff0c\u56e0\u6b64\u5c0d\u65bc\u5b83\u5011\u800c\u8a00\uff0c\u9577\u8a9e\u5883\u7406\u89e3\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u9577\u8f38\u5165\u5fae\u8abf (LIFT)\uff0c\u9019\u662f\u4e00\u500b\u7528\u65bc\u9577\u8a9e\u5883\u5efa\u6a21\u7684\u65b0\u7a4e\u67b6\u69cb\uff0c\u5b83\u53ef\u4ee5\u901a\u904e\u6839\u64da\u9577\u8f38\u5165\u52d5\u614b\u8abf\u6574\u6a21\u578b\u53c3\u6578\u4f86\u6539\u5584\u4efb\u610f\uff08\u77ed\u8a9e\u5883\uff09LLM \u7684\u9577\u8a9e\u5883\u6548\u80fd\u3002\u91cd\u8981\u7684\u662f\uff0cLIFT \u6c92\u6709\u7121\u9650\u64f4\u5145\u4e0a\u4e0b\u6587\u8996\u7a97\u5927\u5c0f\u4ee5\u5bb9\u7d0d\u8a9e\u5883\u4e2d\u8d8a\u4f86\u8d8a\u9577\u7684\u8f38\u5165\uff0c\u800c\u662f\u9078\u64c7\u5c07\u9577\u8f38\u5165\u5132\u5b58\u5728\u53c3\u6578\u4e2d\u4e26\u5438\u6536\u5b83\u3002\u901a\u904e\u5c07\u9577\u8f38\u5165\u5fae\u8abf\u5230\u6a21\u578b\u53c3\u6578\u4e2d\uff0cLIFT \u5141\u8a31\u77ed\u8a9e\u5883 LLM \u56de\u7b54\u554f\u984c\uff0c\u5373\u4f7f\u5728\u63a8\u7406\u671f\u9593\u8a9e\u5883\u4e2d\u6c92\u6709\u63d0\u4f9b\u6240\u9700\u8cc7\u8a0a\u4e5f\u662f\u5982\u6b64\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u5728\u4fdd\u6301\u539f\u59cb\u8a9e\u5883\u4e2d\u5b78\u7fd2 (ICL) \u80fd\u529b\u7684\u540c\u6642\u589e\u5f37 LIFT \u6548\u80fd\uff0c\u6211\u5011\u5f15\u5165\u4e86\u9598\u63a7\u8a18\u61b6\u9ad4\uff0c\u9019\u662f\u4e00\u500b\u81ea\u52d5\u5e73\u8861\u9577\u8f38\u5165\u8a18\u61b6\u548c ICL \u7684\u7279\u6b8a\u6ce8\u610f\u529b\u9069\u914d\u5668\u3002\u6211\u5011\u5c0d LIFT \u5728\u9577\u8a9e\u5883\u7406\u89e3\u65b9\u9762\u7684\u512a\u7f3a\u9ede\u9032\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u70ba\u672a\u4f86\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u65b9\u5411\u3002", "author": "Yansheng Mao et.al.", "authors": "Yansheng Mao, Yufei Xu, Jiaqi Li, Fanxu Meng, Haotong Yang, Zilong Zheng, Xiyuan Wang, Muhan Zhang", "id": "2502.14644v1", "paper_url": "http://arxiv.org/abs/2502.14644v1", "repo": "null"}}