{"2410.22891": {"publish_time": "2024-10-30", "title": "VPO: Leveraging the Number of Votes in Preference Optimization", "paper_summary": "Direct Preference Optimization (DPO) trains a language model using human\npreference data, bypassing the explicit reward modeling phase of Reinforcement\nLearning from Human Feedback (RLHF). By iterating over sentence pairs in a\npreference dataset, DPO enhances generation quality by increasing the\nlikelihood of producing preferred sentences over less favored ones. Preference\ndatasets are typically created by selecting preferred sentences through a\nvoting process involving multiple individuals, as opinions can vary due to the\nsubjective nature of human preferences. While the number of votes offers\ninsight into whether a sentence pair is clearly preferable or controversial,\ncurrent methods do not fully leverage this information. In this paper, we\nintroduce a technique that leverages user voting data to better align with\ndiverse subjective preferences. We employ the Bayesian Minimum Mean Square\nError (Bayesian MMSE) estimator to model the probability that one generation is\npreferable to another. Using this estimated probability as a target, we develop\nthe Vote-based Preference Optimization (VPO) framework, which incorporates the\nnumber of votes on both sides to distinguish between controversial and obvious\ngeneration pairs. We show that previous algorithms, such as DPO and Identity\nPreference Optimization (IPO), can be extended using the proposed framework,\ntermed VDPO and VIPO. Our experiments demonstrate that these proposed\nalgorithms outperform various existing methods, including their base\nalgorithms.", "paper_summary_zh": "\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\uff08DPO\uff09\u4f7f\u7528\u4eba\u985e\u504f\u597d\u8cc7\u6599\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\uff0c\u7e5e\u904e\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2\uff08RLHF\uff09\u7684\u660e\u78ba\u734e\u52f5\u5efa\u6a21\u968e\u6bb5\u3002\u900f\u904e\u5728\u504f\u597d\u8cc7\u6599\u96c6\u4e2d\u7684\u53e5\u5b50\u5c0d\u4e2d\u53cd\u8986\u904b\u7b97\uff0cDPO \u900f\u904e\u589e\u52a0\u7522\u751f\u504f\u597d\u53e5\u5b50\u7684\u6a5f\u7387\uff0c\u9032\u800c\u63d0\u5347\u7522\u751f\u54c1\u8cea\uff0c\u52dd\u904e\u4e0d\u90a3\u9ebc\u53d7\u6b61\u8fce\u7684\u53e5\u5b50\u3002\u504f\u597d\u8cc7\u6599\u96c6\u901a\u5e38\u900f\u904e\u6295\u7968\u7a0b\u5e8f\u5efa\u7acb\uff0c\u4e26\u7531\u591a\u4f4d\u500b\u4eba\u53c3\u8207\uff0c\u56e0\u70ba\u610f\u898b\u53ef\u80fd\u6703\u56e0\u4eba\u985e\u504f\u597d\u7684\u4e3b\u89c0\u6027\u8cea\u800c\u6709\u6240\u4e0d\u540c\u3002\u5118\u7ba1\u6295\u7968\u6578\u63d0\u4f9b\u4e86\u898b\u89e3\uff0c\u8aaa\u660e\u53e5\u5b50\u5c0d\u662f\u5426\u660e\u986f\u8f03\u4f73\u6216\u6709\u722d\u8b70\uff0c\u4f46\u76ee\u524d\u7684\u6280\u8853\u4e26\u672a\u5145\u5206\u5229\u7528\u9019\u4e9b\u8cc7\u8a0a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f15\u9032\u4e00\u9805\u6280\u8853\uff0c\u5229\u7528\u4f7f\u7528\u8005\u6295\u7968\u8cc7\u6599\uff0c\u4ee5\u66f4\u597d\u5730\u8207\u4e0d\u540c\u7684\u4e3b\u89c0\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u6211\u5011\u63a1\u7528\u8c9d\u6c0f\u6700\u5c0f\u5747\u65b9\u8aa4\u5dee\uff08\u8c9d\u6c0f MMSE\uff09\u4f30\u8a08\u5668\uff0c\u4f86\u5efa\u6a21\u4e00\u500b\u7522\u751f\u7d50\u679c\u6bd4\u53e6\u4e00\u500b\u7522\u751f\u7d50\u679c\u66f4\u4f73\u7684\u6a5f\u7387\u3002\u4f7f\u7528\u9019\u500b\u4f30\u8a08\u6a5f\u7387\u4f5c\u70ba\u76ee\u6a19\uff0c\u6211\u5011\u958b\u767c\u4e86\u57fa\u65bc\u6295\u7968\u7684\u504f\u597d\u6700\u4f73\u5316\uff08VPO\uff09\u67b6\u69cb\uff0c\u5176\u4e2d\u7d0d\u5165\u5169\u65b9\u7684\u6295\u7968\u6578\uff0c\u4ee5\u5340\u5206\u6709\u722d\u8b70\u548c\u986f\u800c\u6613\u898b\u7684\u7522\u751f\u5c0d\u3002\u6211\u5011\u5c55\u793a\u4e86\u5148\u524d\u7684\u6f14\u7b97\u6cd5\uff0c\u4f8b\u5982 DPO \u548c\u8eab\u5206\u504f\u597d\u6700\u4f73\u5316\uff08IPO\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u67b6\u69cb\u9032\u884c\u5ef6\u4f38\uff0c\u7a31\u70ba VDPO \u548c VIPO\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u9019\u4e9b\u63d0\u51fa\u7684\u6f14\u7b97\u6cd5\u512a\u65bc\u5404\u7a2e\u73fe\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u5176\u57fa\u672c\u6f14\u7b97\u6cd5\u3002", "author": "Jae Hyeon Cho et.al.", "authors": "Jae Hyeon Cho, Minkyung Park, Byung-Jun Lee", "id": "2410.22891v1", "paper_url": "http://arxiv.org/abs/2410.22891v1", "repo": "https://github.com/ku-dmlab/vpo"}}