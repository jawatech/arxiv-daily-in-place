{"2409.15566": {"publish_time": "2024-09-23", "title": "GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation", "paper_summary": "The ability to form, retrieve, and reason about memories in response to\nstimuli serves as the cornerstone for general intelligence - shaping entities\ncapable of learning, adaptation, and intuitive insight. Large Language Models\n(LLMs) have proven their ability, given the proper memories or context, to\nreason and respond meaningfully to stimuli. However, they are still unable to\noptimally encode, store, and retrieve memories - the ability to do this would\nunlock their full ability to operate as AI agents, and to specialize to niche\ndomains. To remedy this, one promising area of research is Retrieval Augmented\nGeneration (RAG), which aims to augment LLMs by providing them with rich\nin-context examples and information. In question-answering (QA) applications,\nRAG methods embed the text of interest in chunks, and retrieve the most\nrelevant chunks for a prompt using text embeddings. Motivated by human memory\nencoding and retrieval, we aim to improve over standard RAG methods by\ngenerating and encoding higher-level information and tagging the chunks by\ntheir utility to answer questions. We introduce Graphical Eigen Memories For\nRetrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk\nof text in a given text corpus with LLM generated ``utility'' questions,\nconnecting chunks in a graph based on the similarity of both their text and\nutility questions, and then using the eigendecomposition of the memory graph to\nbuild higher level summary nodes that capture the main themes of the text. We\nevaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with\nSBERT, and OpenAI's text encoders on two standard QA tasks, showing that\nGEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also\ndiscuss the implications of having a robust RAG system and future directions.", "paper_summary_zh": "<paragraph>\u6839\u64da\u523a\u6fc0\u5f62\u6210\u3001\u6aa2\u7d22\u548c\u63a8\u7406\u8a18\u61b6\u7684\u80fd\u529b\u662f\u901a\u7528\u667a\u6167\u7684\u57fa\u77f3\uff0c\u5851\u9020\u4e86\u5177\u5099\u5b78\u7fd2\u3001\u9069\u61c9\u548c\u76f4\u89ba\u6d1e\u5bdf\u529b\u7684\u5be6\u9ad4\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u8b49\u660e\u5176\u80fd\u529b\uff0c\u5728\u9069\u7576\u7684\u8a18\u61b6\u6216\u80cc\u666f\u4e0b\uff0c\u5c0d\u523a\u6fc0\u9032\u884c\u63a8\u7406\u548c\u6709\u610f\u7fa9\u5730\u56de\u61c9\u3002\u7136\u800c\uff0c\u5b83\u5011\u4ecd\u7136\u7121\u6cd5\u6700\u4f73\u5730\u7de8\u78bc\u3001\u5132\u5b58\u548c\u6aa2\u7d22\u8a18\u61b6\uff0c\u57f7\u884c\u6b64\u64cd\u4f5c\u7684\u80fd\u529b\u5c07\u89e3\u9396\u5b83\u5011\u4f5c\u70ba AI \u4ee3\u7406\u904b\u4f5c\u4e26\u5c08\u9580\u5316\u70ba\u5229\u57fa\u9818\u57df\u7684\u5168\u90e8\u80fd\u529b\u3002\u70ba\u4e86\u88dc\u6551\u6b64\u554f\u984c\uff0c\u4e00\u500b\u6709\u524d\u666f\u7684\u7814\u7a76\u9818\u57df\u662f\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG)\uff0c\u5176\u76ee\u6a19\u662f\u900f\u904e\u63d0\u4f9b\u8c50\u5bcc\u7684\u4e0a\u4e0b\u6587\u7bc4\u4f8b\u548c\u8cc7\u8a0a\u4f86\u64f4\u5145 LLM\u3002\u5728\u554f\u7b54 (QA) \u61c9\u7528\u7a0b\u5f0f\u4e2d\uff0cRAG \u65b9\u6cd5\u5c07\u611f\u8208\u8da3\u7684\u6587\u5b57\u5206\u584a\u5d4c\u5165\uff0c\u4e26\u4f7f\u7528\u6587\u5b57\u5d4c\u5165\u70ba\u63d0\u793a\u6aa2\u7d22\u6700\u76f8\u95dc\u7684\u5340\u584a\u3002\u53d7\u4eba\u985e\u8a18\u61b6\u7de8\u78bc\u548c\u6aa2\u7d22\u7684\u555f\u767c\uff0c\u6211\u5011\u65e8\u5728\u900f\u904e\u7522\u751f\u548c\u7de8\u78bc\u66f4\u9ad8\u7d1a\u5225\u7684\u8cc7\u8a0a\u4e26\u6839\u64da\u5340\u584a\u56de\u7b54\u554f\u984c\u7684\u6548\u7528\u6a19\u8a18\u5340\u584a\uff0c\u5f9e\u800c\u6539\u9032\u6a19\u6e96 RAG \u65b9\u6cd5\u3002\u6211\u5011\u5f15\u5165\u4e86\u7528\u65bc\u6aa2\u7d22\u589e\u5f37\u751f\u6210\u7684\u5716\u5f62\u7279\u5fb5\u8a18\u61b6 (GEM-RAG)\u3002GEM-RAG \u7684\u5de5\u4f5c\u539f\u7406\u662f\u4f7f\u7528 LLM \u751f\u6210\u7684\u300c\u6548\u7528\u300d\u554f\u984c\u6a19\u8a18\u7d66\u5b9a\u6587\u5b57\u8a9e\u6599\u5eab\u4e2d\u6bcf\u500b\u6587\u5b57\u5340\u584a\uff0c\u6839\u64da\u6587\u5b57\u548c\u6548\u7528\u554f\u984c\u7684\u76f8\u4f3c\u6027\u5c07\u5340\u584a\u9023\u63a5\u5728\u5716\u5f62\u4e2d\uff0c\u7136\u5f8c\u4f7f\u7528\u8a18\u61b6\u5716\u5f62\u7684\u7279\u5fb5\u5206\u89e3\u4f86\u5efa\u7acb\u64f7\u53d6\u6587\u5b57\u4e3b\u984c\u7684\u9ad8\u968e\u6458\u8981\u7bc0\u9ede\u3002\u6211\u5011\u4f7f\u7528 UnifiedQA \u548c GPT-3.5 Turbo \u4f5c\u70ba LLM\uff0c\u4ee5\u53ca SBERT \u548c OpenAI \u7684\u6587\u5b57\u7de8\u78bc\u5668\uff0c\u5728\u5169\u500b\u6a19\u6e96 QA \u4efb\u52d9\u4e2d\u8a55\u4f30 GEM-RAG\uff0c\u986f\u793a GEM-RAG \u5728\u9019\u4e9b\u4efb\u52d9\u4e2d\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684 RAG \u65b9\u6cd5\u3002\u6211\u5011\u9084\u8a0e\u8ad6\u4e86\u64c1\u6709\u5f37\u5927\u7684 RAG \u7cfb\u7d71\u7684\u542b\u610f\u548c\u672a\u4f86\u7684\u65b9\u5411\u3002</paragraph>", "author": "Brendan Hogan Rappazzo et.al.", "authors": "Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes", "id": "2409.15566v1", "paper_url": "http://arxiv.org/abs/2409.15566v1", "repo": "null"}}