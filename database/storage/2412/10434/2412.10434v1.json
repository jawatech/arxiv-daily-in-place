{"2412.10434": {"publish_time": "2024-12-11", "title": "NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language", "paper_summary": "The emergence of Large Language Models (LLMs) has revolutionized many fields,\nnot only traditional natural language processing (NLP) tasks. Recently,\nresearch on applying LLMs to the database field has been booming, and as a\ntypical non-relational database, the use of LLMs in graph database research has\nnaturally gained significant attention. Recent efforts have increasingly\nfocused on leveraging LLMs to translate natural language into graph query\nlanguage (NL2GQL). Although some progress has been made, these methods have\nclear limitations, such as their reliance on streamlined processes that often\noverlook the potential of LLMs to autonomously plan and collaborate with other\nLLMs in tackling complex NL2GQL challenges. To address this gap, we propose\nNAT-NL2GQL, a novel multi-agent framework for translating natural language to\ngraph query language. Specifically, our framework consists of three synergistic\nagents: the Preprocessor agent, the Generator agent, and the Refiner agent. The\nPreprocessor agent manages data processing as context, including tasks such as\nname entity recognition, query rewriting, path linking, and the extraction of\nquery-related schemas. The Generator agent is a fine-tuned LLM trained on\nNL-GQL data, responsible for generating corresponding GQL statements based on\nqueries and their related schemas. The Refiner agent is tasked with refining\nthe GQL or context using error information obtained from the GQL execution\nresults. Given the scarcity of high-quality open-source NL2GQL datasets based\non nGQL syntax, we developed StockGQL, a dataset constructed from a financial\nmarket graph database. It is available at:\nhttps://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL\nand SpCQL datasets reveal that our method significantly outperforms baseline\napproaches, highlighting its potential for advancing NL2GQL research.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\uff0c\u4e0d\u50c5\u5fb9\u5e95\u6539\u8b8a\u4e86\u50b3\u7d71\u7684\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\uff0c\u66f4\u5c0d\u8a31\u591a\u9818\u57df\u9020\u6210\u9769\u547d\u6027\u7684\u5f71\u97ff\u3002\u6700\u8fd1\uff0c\u5c07 LLM \u61c9\u7528\u65bc\u8cc7\u6599\u5eab\u9818\u57df\u7684\u7814\u7a76\u84ec\u52c3\u767c\u5c55\uff0c\u800c\u4f5c\u70ba\u5178\u578b\u7684\u975e\u95dc\u806f\u5f0f\u8cc7\u6599\u5eab\uff0cLLM \u5728\u5716\u5f62\u8cc7\u6599\u5eab\u7814\u7a76\u4e2d\u7684\u61c9\u7528\u81ea\u7136\u5099\u53d7\u95dc\u6ce8\u3002\u6700\u8fd1\u7684\u7814\u7a76\u5de5\u4f5c\u8d8a\u4f86\u8d8a\u8457\u91cd\u65bc\u5229\u7528 LLM \u5c07\u81ea\u7136\u8a9e\u8a00\u8f49\u63db\u6210\u5716\u5f62\u67e5\u8a62\u8a9e\u8a00 (NL2GQL)\u3002\u5118\u7ba1\u5df2\u53d6\u5f97\u4e00\u4e9b\u9032\u5c55\uff0c\u4f46\u9019\u4e9b\u65b9\u6cd5\u4ecd\u6709\u660e\u986f\u7684\u9650\u5236\uff0c\u4f8b\u5982\u5b83\u5011\u4f9d\u8cf4\u7c21\u5316\u7684\u6d41\u7a0b\uff0c\u800c\u9019\u4e9b\u6d41\u7a0b\u5f80\u5f80\u5ffd\u7565\u4e86 LLM \u8207\u5176\u4ed6 LLM \u81ea\u4e3b\u898f\u5283\u548c\u5354\u4f5c\u4ee5\u61c9\u5c0d\u8907\u96dc NL2GQL \u6311\u6230\u7684\u6f5b\u529b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86 NAT-NL2GQL\uff0c\u9019\u662f\u4e00\u500b\u7528\u65bc\u5c07\u81ea\u7136\u8a9e\u8a00\u8f49\u63db\u6210\u5716\u5f62\u67e5\u8a62\u8a9e\u8a00\u7684\u65b0\u7a4e\u591a\u91cd\u4ee3\u7406\u67b6\u69cb\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u67b6\u69cb\u5305\u542b\u4e09\u500b\u5354\u540c\u904b\u4f5c\u7684\u4ee3\u7406\uff1a\u9810\u8655\u7406\u5668\u4ee3\u7406\u3001\u7522\u751f\u5668\u4ee3\u7406\u548c\u7cbe\u7149\u5668\u4ee3\u7406\u3002\u9810\u8655\u7406\u5668\u4ee3\u7406\u7ba1\u7406\u8cc7\u6599\u8655\u7406\u4f5c\u70ba\u80cc\u666f\uff0c\u5305\u62ec\u547d\u540d\u5be6\u9ad4\u8fa8\u8b58\u3001\u67e5\u8a62\u91cd\u5beb\u3001\u8def\u5f91\u9023\u7d50\u548c\u63d0\u53d6\u8207\u67e5\u8a62\u76f8\u95dc\u7684\u67b6\u69cb\u7b49\u4efb\u52d9\u3002\u7522\u751f\u5668\u4ee3\u7406\u662f\u4e00\u500b\u91dd\u5c0d NL-GQL \u8cc7\u6599\u5fae\u8abf\u904e\u7684 LLM\uff0c\u8ca0\u8cac\u6839\u64da\u67e5\u8a62\u53ca\u5176\u76f8\u95dc\u67b6\u69cb\u7522\u751f\u5c0d\u61c9\u7684 GQL \u9673\u8ff0\u3002\u7cbe\u7149\u5668\u4ee3\u7406\u8ca0\u8cac\u4f7f\u7528\u5f9e GQL \u57f7\u884c\u7d50\u679c\u53d6\u5f97\u7684\u932f\u8aa4\u8cc7\u8a0a\u4f86\u7cbe\u7149 GQL \u6216\u80cc\u666f\u3002\u9451\u65bc\u57fa\u65bc nGQL \u8a9e\u6cd5\u7684\u512a\u8cea\u958b\u6e90 NL2GQL \u8cc7\u6599\u96c6\u7a00\u5c11\uff0c\u6211\u5011\u958b\u767c\u4e86 StockGQL\uff0c\u9019\u662f\u4e00\u500b\u5f9e\u91d1\u878d\u5e02\u5834\u5716\u5f62\u8cc7\u6599\u5eab\u5efa\u69cb\u7684\u8cc7\u6599\u96c6\u3002\u5b83\u53ef\u65bc\u4ee5\u4e0b\u4f4d\u7f6e\u53d6\u5f97\uff1ahttps://github.com/leonyuancode/StockGQL\u3002\u5728 StockGQL \u548c SpCQL \u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u6a21\u578b\u660e\u986f\u512a\u65bc\u57fa\u6e96\u65b9\u6cd5\uff0c\u7a81\u986f\u4e86\u5176\u5728\u63a8\u52d5 NL2GQL \u7814\u7a76\u65b9\u9762\u7684\u6f5b\u529b\u3002", "author": "Yuanyuan Liang et.al.", "authors": "Yuanyuan Liang, Tingyu Xie, Gan Peng, Zihao Huang, Yunshi Lan, Weining Qian", "id": "2412.10434v1", "paper_url": "http://arxiv.org/abs/2412.10434v1", "repo": "null"}}