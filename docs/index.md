# arxiv-daily
 Automated deployment @ 2024-09-12 09:02:00 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v1](http://arxiv.org/abs/2407.15851v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|

#### Abstracts
##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v1 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
extant surveys on the trustworthiness of foundation models fail to address
their specific variations and applications within the medical imaging domain.
This survey paper reviews the current research on foundation models in the
major medical imaging applications, with a focus on segmentation, medical
report generation, medical question and answering (Q&A), and disease diagnosis,
which includes trustworthiness discussion in their manuscripts. We explore the
complex challenges of making foundation models for medical image analysis
trustworthy, associated with each application, and summarize the current
concerns and strategies to enhance trustworthiness. Furthermore, we explore the
future promises of these models in revolutionizing patient care. Our analysis
underscores the imperative for advancing towards trustworthy AI in medical
image analysis, advocating for a balanced approach that fosters innovation
while ensuring ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像上的快速進展代表著在增強診斷準確度和個人化治療方面邁出了一大步。然而，基礎模型在醫療保健中的部署需要嚴格檢查其可信度，包括隱私、穩健性、可靠性、可解釋性和公平性。當前關於醫學影像中基礎模型的調查文獻顯示出相當大的差距，特別是在可信度方面。此外，現有的關於基礎模型可信度的調查未能解決其在醫學影像領域內的具體變化和應用。這篇調查論文回顧了當前關於基礎模型在主要醫學影像應用中的研究，重點關注分割、醫療報告生成、醫療問題和解答 (Q&A) 以及疾病診斷，其中包括手稿中的可信度討論。我們探討了讓用於醫學影像分析的基礎模型值得信賴的複雜挑戰，與每個應用相關，並總結了當前提高可信度的問題和策略。此外，我們探討了這些模型在革新患者照護方面的未來前景。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，提倡一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

摘要：<paragraph>人工智慧系統的說明很少能滿足受演算法決策 (ADM) 影響的人們的資訊需求。傳達的資訊與影響利害關係人重要的資訊之間的差距，可能會阻礙了解和遵守法規架構，例如人工智慧法案。為了解決這個差距，我們提出了「XAI 初學者問題庫」：受影響利害關係人資訊需求的目錄，涵蓋兩個 ADM 使用案例（就業預測和健康監測），涵蓋資料、系統脈絡、系統使用和系統規格類別。資訊需求是透過訪談研究收集的，參與者在詢問後收到說明。參與者進一步回報他們的理解和決策信心，顯示雖然在收到說明後信心傾向於增加，但參與者也遇到了理解挑戰，例如無法說明為什麼他們的理解感覺不完整。說明進一步影響參與者對系統風險和好處的看法，他們會根據使用案例確認或改變這些看法。當風險被認為很高時，參與者表示特別有興趣了解意圖的說明，例如為什麼以及為了什麼目的而建立系統。透過這項工作，我們旨在透過在決策採用 ADM 系統時提供相關資訊和挑戰的概覽，來支援將受影響的利害關係人納入可解釋性。我們最後總結我們的發現，列出六項關鍵影響，這些影響會告知未來針對受影響利害關係人受眾說明的設計。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫療領域中已取得顯著進展，在醫學影像、病人照護和其他領域中出現了新興應用。雖然這些應用已在回顧性研究中被證實是成功的，但實際上只有極少數應用於實務。醫療 AI 領域面臨著各種挑戰，包括建立使用者信任、遵守法規、使用資料符合倫理。可解釋 AI (XAI) 的目標是讓人類了解 AI 並相信其結果。本文針對最近幾年發表的 198 篇文章的具代表性樣本，提出有關醫療決策支援的 XAI 解決方案的最新發展的文獻回顧。相關文章的系統性綜合整理產生了多項發現：(1) 這些解決方案大多採用與模型無關的 XAI 技術，(2) 深度學習模型的使用率高於其他類型的機器學習模型，(3) 可解釋性被用於促進信任，但很少有研究報告醫師參與迴圈，(4) 視覺和互動式使用者介面對於理解系統的解釋和建議更有用。需要更多醫療和 AI 專家合作進行研究，這有助於為醫療領域的 XAI 解決方案的設計、實作和評估提供適當架構。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是治療不孕症最廣泛的方法之一。其主要挑戰之一是評估和選擇胚胎進行植入，此過程具有很大的臨床間和臨床內變異性。基於深度學習的方法正受到關注，但其不透明的性質會影響其在臨床環境中的接受度，而透明度在決策制定中至關重要。在本文中，我們分析了 AI 輔助胚胎分析模型的可解釋性方面的現有工作，並找出其局限性。我們還討論了如何將這些模型作為決策支持系統整合到臨床環境中，同時考慮臨床醫生和患者的需求。最後，我們提出了提高可解釋性和可信度的準則，推進這項技術朝著既定的臨床實務邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程 (RE) 領域中，可解釋人工智慧 (XAI) 在將 AI 支持的系統與使用者需求、社會期望和法規標準相符方面的重要性日益顯著，已獲得認可。一般來說，可解釋性已成為影響系統品質的重要非功能需求。然而，可解釋性與效能之間的假定權衡挑戰了可解釋性的假定正面影響。如果滿足可解釋性的需求需要降低系統效能，那麼必須仔細考慮這些品質面向中哪一個優先，以及如何在它們之間進行折衷。在本文中，我們批判性地探討了這種假定的權衡。我們認為，最好的方法是以一種細緻的方式來處理，這種方式包含資源可用性、領域特性和風險考量。透過提供未來研究和最佳實務的基礎，這項工作旨在提升 AI 的 RE 領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schlüter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）领域，可解释人工智能（XAI）在将人工智能支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益凸显，并获得了认可。一般来说，可解释性已成为影响系统质量的重要非功能性需求。然而，可解释性和性能之间的权衡挑战了可解释性的正面影响。如果满足可解释性的要求需要降低系统性能，那么必须仔细考虑这些质量方面中的哪一个优先，以及如何在它们之间进行权衡。在本文中，我们批判性地考察了所谓的权衡。我们认为，最好以一种细致入微的方式来处理它，这种方式结合了资源可用性、领域特征和风险考虑。通过为未来的研究和最佳实践提供基础，这项工作旨在推进人工智能的 RE 领域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文嚴格評估歐洲委員會提出的 AI 法案對風險管理和風險可接受性的方法，用於對基本權利和安全構成風險的高風險 AI 系統。該法案旨在以相稱的監管負擔促進「值得信賴」的 AI。其關於風險可接受性的條款要求將高風險系統的殘餘風險減低或消除「盡可能」，並考慮「技術狀態」。此準則，特別是如果狹義解釋，無法執行，既不促進相稱的監管負擔，也不促進可信賴性。相比之下，議會對風險管理條款的最新修正草案引入了「合理性」、成本效益分析，並且更透明地說明了風險可接受性判斷的價值觀和背景性質。本文論證議會的方法更可行，且能更好地平衡相稱性和可信賴性的目標。本文說明風險可接受性判斷中的合理性會帶來什麼，並根據過失法和歐洲醫療器材法規中的原則進行說明。本文主張風險可接受性判斷的方法需要穩固的公民合法性基礎：包括監管機構的詳細指導或參與，以及受影響利害關係人的有意義投入。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：可解釋人工智慧 (XAI) 是機器學習中快速進展的領域，旨在解開複雜模型的預測。XAI 在敏感應用中特別需要，例如在醫療保健中，當診斷、建議和治療選擇可能依賴於人工智慧系統做出的決策時。人工智慧方法也已廣泛用於老化研究，特別是在開發生物時鐘模型和識別老化和與年齡相關疾病的生物標誌物方面。然而，這裡 XAI 的潛力有待充分認識。我們討論了 XAI 在開發「老化時鐘」方面的應用，並對按特定生理系統的重點分類的文獻進行了全面的分析。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, Jörg Schlötterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋設計的影像分類器，也是黑箱 AI 的一個有前途的替代方案。這篇論文探討了解釋性機器學習，特別是 PIP-Net，在真實世界醫學影像資料上自動化診斷支援的適用性和潛力。PIP-Net 學習人類可理解的原型影像部分，我們評估其在骨折檢測和皮膚癌診斷方面的準確性和可解釋性。我們發現 PIP-Net 的決策制定過程符合醫學分類標準，同時僅提供影像層級類別標籤。由於 PIP-Net 對原型的無監督預訓練，因此可以輕鬆識別資料品質問題，例如 X 光中的不需要文字或標籤錯誤。此外，我們首次展示人類可以透過直接停用不需要的原型來手動修正 PIP-Net 的推理。我們得出結論，部分原型模型由於其可解釋性和進階模型除錯的潛力，因此有望應用於醫療。

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

摘要：可解釋 AI (XAI) 是機器學習研究中日益重要的領域，其目標是讓黑箱模型透明且可解釋。在本文中，我們提出了一種新的 XAI 方法，該方法使用由特徵條件置換產生的所謂反事實路徑。該演算法透過識別特徵的順序置換來衡量特徵重要性，這些置換最能影響模型預測的變化。它特別適合根據包含領域知識的知識圖譜中的反事實路徑來產生解釋。反事實路徑在解釋和視覺化黑箱模型時，為目前的 XAI 方法引入了額外的圖形維度。使用合成和醫療資料進行的實驗證明了我們方法的實用適用性。

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

摘要：在人工智能 (AI) 的可解釋性領域中，已經看到越來越多的研究和學術興趣。然而，在解釋機器學習演算法的結果時缺乏人性化和個人化的詮釋，這顯著阻礙了臨床醫生在研究和臨床實務中接受這些方法。為了解決這個問題，我們的研究使用反事實解釋來探討「如果？」情境在醫學研究中的適用性。我們的目標是擴展我們對用於診斷小兒後顱窩腦腫瘤的磁共振成像 (MRI) 特徵的理解，超越現有的界線。在我們的案例研究中，所提出的概念提供了一種新穎的方法來檢視替代決策情境，提供個人化和特定於情境的見解，從而能夠驗證預測並釐清在不同情況下的差異。此外，我們探討了反事實用於資料擴充的潛在用途，並評估其作為我們醫學研究案例中替代方法的可行性。結果證明了使用反事實解釋來增強臨床研究中 AI 驅動方法的接受度的潛力。

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

摘要：目前人工智能領域的進展導致了各種類型的人工智慧驅動的失智症評估的發展，可用於識別處於失智症早期階段的患者。它可以徹底改變失智症護理設置。重要的是，醫療界要了解各種人工智能評估，並根據其有效性、效率、實用性、可靠性和準確性程度，考慮選擇它們來早期識別失智症患者 (PwD)。另一方面，人工智能開發人員也應該了解各種非人工智能評估以及最近開發的人工智能評估。因此，這篇臨床醫生和人工智能工程師都可以閱讀的論文填補了文獻中關於向臨床醫生解釋現有失智症識別解決方案以及向人工智能工程師解釋所用技術和最廣泛的失智症數據集的空白。它遵循對人工智能和非人工智能失智症評估論文的回顧，為人工智能和醫療界提供有關各種失智症評估的寶貴信息。討論和結論重點介紹了最突出的研究方向和現有解決方案的成熟度。

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

摘要：<paragraph>可解釋性對人工智慧 (AI) 技術構成一項重大挑戰。當前對可解釋 AI (XAI) 的研究缺乏提取學習任務整體知識的效率，因此存在不精確的顯著性、與情境無關的缺失和含糊意義等缺陷。在本文中，我們提出類別關聯嵌入 (CAE) 方法來解決這些問題。我們採用編碼器-解碼器架構來嵌入樣本特徵，並同時將它們分為類別相關和個體相關的樣式向量。將給定樣本的個體樣式代碼與另一個樣本的類別樣式代碼重新組合，會產生一個具有保留個體特徵但改變類別分配的合成樣本，遵循循環對抗學習策略。類別關聯嵌入將所有實例的全局類別相關特徵提煉到一個統一的領域中，並在類別之間有良好的區分。然後可以提取不同類別之間的轉換規則，並進一步應用於個別實例。然後，我們提出一個主動 XAI 框架，它沿著引導路徑操作特定樣本的類別樣式向量，朝著反類別移動，從而產生一系列具有相同個體特徵的反例合成樣本。將這些反事實樣本與原始樣本進行比較，可以對分類任務的性質提供全局、直觀的說明。我們採用該框架進行醫學影像分類任務，結果表明，與現有方法相比，可以獲得更精確的顯著性圖，並具有強大的與情境無關的表示。此外，疾病病理學可以直接通過在類別樣式空間中遍歷路徑來進行可視化。</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, Iñigo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

摘要：提供基於機器學習的 AI 預測的高品質說明是一項具有挑戰性和複雜性的任務。要順利進行，它需要具備下列因素：選擇適當的說明普遍性/特殊性層級；考量說明受益人對所考慮的 AI 任務的熟悉程度假設；參照促成決策的特定元素；利用可能不屬於預測程序的一部分的額外知識（例如專家證據）；並提供支持否定假設的證據。最後，系統需要以清晰可解釋且可能令人信服的方式制定說明。基於這些考量，ANTIDOTE 促成了可解釋 AI 的整合願景，其中深度學習程序的低階特徵與人類論證能力的高階架構相結合。ANTIDOTE 將利用深度學習與論證的跨領域能力，來支持可解釋 AI 更廣泛且創新的觀點，其中對臨床案例審議的高品質說明需求至關重要。作為該專案的第一個成果，我們發布了 Antidote CasiMedicos 資料集，以利於一般可解釋 AI 的研究，特別是醫療領域的論證。

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

摘要：<paragraph>近年來，圖神經網路的進展迅速，在藥物發現、醫療診斷和推薦系統方面都有許多新發展。雖然這些進展很重要，但許多網路都是「黑盒子」，對於網路到底在學習「什麼」了解甚少。許多高風險應用，例如藥物發現，需要模型提供人類可以理解的解釋，以便使用者可以辨識錯誤並發現新知識。因此，可解釋 AI 演算法的開發對於我們獲取 AI 的好處至關重要。
我們提出了一種稱為 eXplainable Insight (XInsight) 的 GNN 可解釋性演算法，它使用 GFlowNets 產生模型解釋分佈。由於 GFlowNets 會產生機率與獎勵成正比的物件，因此與先前僅學習最大獎勵範例的方法相比，XInsight 可以產生多樣化的解釋集合。我們透過為在兩個圖形分類任務中訓練的 GNN 產生解釋來展示 XInsight：使用 MUTAG 資料集對致突變化合物進行分類，並使用我們已開放原始碼的合成資料集對非環狀圖形進行分類。我們透過使用 QSAR 建模分析產生的化合物來展示 XInsight 解釋的效用，我們發現 XInsight 會產生按親脂性（已知的致突變相關性）分群的化合物。我們的結果顯示 XInsight 會產生一個解釋分佈，揭示模型所展示的底層關係。它們也強調產生多樣化解釋集合的重要性，因為它使我們能夠發現模型中的隱藏關係，並為進一步分析提供有價值的指導。</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-10**|**Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort**|Cristian Trout et.al.|[2409.06672v1](http://arxiv.org/abs/2409.06672v1)|null|
|**2024-09-10**|**EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**|Danli Shi et.al.|[2409.06644v2](http://arxiv.org/abs/2409.06644v2)|null|
|**2024-09-10**|**Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**|Zoe Hancox et.al.|[2409.06585v1](http://arxiv.org/abs/2409.06585v1)|[link](https://github.com/zoehancox/sparse_tgcnn)|
|**2024-09-10**|**MAGDA: Multi-agent guideline-driven diagnostic assistance**|David Bani-Harouni et.al.|[2409.06351v1](http://arxiv.org/abs/2409.06351v1)|null|
|**2024-09-10**|**Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis**|Xin Zhang et.al.|[2409.06209v1](http://arxiv.org/abs/2409.06209v1)|null|
|**2024-09-10**|**Can Large Language Models Unlock Novel Scientific Research Ideas?**|Sandeep Kumar et.al.|[2409.06185v1](http://arxiv.org/abs/2409.06185v1)|null|
|**2024-09-10**|**Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks**|Georgios Chochlakis et.al.|[2409.06173v1](http://arxiv.org/abs/2409.06173v1)|[link](https://github.com/gchochla/cot-priors)|
|**2024-09-10**|**Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings**|Dong Han et.al.|[2409.06147v1](http://arxiv.org/abs/2409.06147v1)|null|
|**2024-09-09**|**Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research**|Osama Zafar et.al.|[2409.06069v1](http://arxiv.org/abs/2409.06069v1)|null|
|**2024-09-09**|**ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language**|Zhaoyue Sun et.al.|[2409.05592v1](http://arxiv.org/abs/2409.05592v1)|null|
|**2024-09-09**|**Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models**|Camilo Thorne et.al.|[2409.05486v1](http://arxiv.org/abs/2409.05486v1)|null|
|**2024-09-09**|**KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**|Yingshu Li et.al.|[2409.05370v1](http://arxiv.org/abs/2409.05370v1)|null|
|**2024-09-09**|**Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis**|Nirmalya Thakur et.al.|[2409.05292v2](http://arxiv.org/abs/2409.05292v2)|null|
|**2024-09-09**|**RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation**|Quoc-Bao Nguyen-Le et.al.|[2409.05280v1](http://arxiv.org/abs/2409.05280v1)|[link](https://github.com/kyle-paul/RotCAtt-TransUNet-plusplus)|
|**2024-09-07**|**Activation Function Optimization Scheme for Image Classification**|Abdur Rahman et.al.|[2409.04915v1](http://arxiv.org/abs/2409.04915v1)|null|
|**2024-09-07**|**LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs**|Yongxin Deng et.al.|[2409.04744v1](http://arxiv.org/abs/2409.04744v1)|null|
|**2024-09-07**|**NapTune: Efficient Model Tuning for Mood Classification using Previous Night's Sleep Measures along with Wearable Time-series**|Debaditya Shome et.al.|[2409.04723v1](http://arxiv.org/abs/2409.04723v1)|null|
|**2024-09-07**|**A Comprehensive Survey on Evidential Deep Learning and Its Applications**|Junyu Gao et.al.|[2409.04720v1](http://arxiv.org/abs/2409.04720v1)|null|
|**2024-09-07**|**A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting**|Cheng Wan et.al.|[2409.04704v1](http://arxiv.org/abs/2409.04704v1)|null|
|**2024-09-06**|**The Impact of Scanner Domain Shift on Deep Learning Performance in Medical Imaging: an Experimental Study**|Gregory Szumel et.al.|[2409.04368v1](http://arxiv.org/abs/2409.04368v1)|null|
|**2024-09-06**|**CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis**|William Knottenbelt et.al.|[2409.04290v1](http://arxiv.org/abs/2409.04290v1)|[link](https://github.com/knottwill/CoxKAN)|
|**2024-09-06**|**Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework**|Daniel J. Tan et.al.|[2409.04224v1](http://arxiv.org/abs/2409.04224v1)|null|
|**2024-09-06**|**Large Language Models in Drug Discovery and Development: From Disease Mechanisms to Clinical Trials**|Yizhen Zheng et.al.|[2409.04481v1](http://arxiv.org/abs/2409.04481v1)|null|
|**2024-09-06**|**FODA-PG for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes**|Kai Shu et.al.|[2409.03947v1](http://arxiv.org/abs/2409.03947v1)|null|
|**2024-09-05**|**A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application**|Esther Lagemann et.al.|[2409.03933v1](http://arxiv.org/abs/2409.03933v1)|null|
|**2024-09-05**|**Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Cord Paralysis**|Yucong Zhang et.al.|[2409.03597v1](http://arxiv.org/abs/2409.03597v1)|null|
|**2024-09-05**|**Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation**|Prerak Mody et.al.|[2409.03470v1](http://arxiv.org/abs/2409.03470v1)|[link](https://github.com/prerakmody/bayesuncertainty-error-correspondence)|
|**2024-09-05**|**Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time**|Francisco de Arriba-Pérez et.al.|[2409.03375v1](http://arxiv.org/abs/2409.03375v1)|null|
|**2024-09-05**|**Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning**|Juan A. Berrios Moya et.al.|[2409.03147v1](http://arxiv.org/abs/2409.03147v1)|null|
|**2024-09-04**|**MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation**|Shehan Perera et.al.|[2409.03062v1](http://arxiv.org/abs/2409.03062v1)|[link](https://github.com/osupcvlab/mobileunetr)|
|**2024-09-04**|**Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test**|Junyoung Park et.al.|[2409.02883v1](http://arxiv.org/abs/2409.02883v1)|null|
|**2024-09-04**|**Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon**|Ramon Tavares et.al.|[2409.02681v1](http://arxiv.org/abs/2409.02681v1)|null|
|**2024-09-04**|**SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments**|Wenwu Guo et.al.|[2409.02598v1](http://arxiv.org/abs/2409.02598v1)|[link](https://github.com/wenwucode/surgtrack)|
|**2024-09-04**|**Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models**|Chih-Yuan Li et.al.|[2409.02530v1](http://arxiv.org/abs/2409.02530v1)|null|
|**2024-09-03**|**Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback**|Deepak Raina et.al.|[2409.02337v1](http://arxiv.org/abs/2409.02337v1)|null|
|**2024-09-03**|**Action-Based ADHD Diagnosis in Video**|Yichun Li et.al.|[2409.02261v1](http://arxiv.org/abs/2409.02261v1)|null|
|**2024-09-03**|**A Deployed Online Reinforcement Learning Algorithm In An Oral Health Clinical Trial**|Anna L. Trella et.al.|[2409.02069v1](http://arxiv.org/abs/2409.02069v1)|[link](https://github.com/StatisticalReinforcementLearningLab/oralytics-post-deployment-analysis)|
|**2024-09-03**|**TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation**|Bobby Azad et.al.|[2409.02018v1](http://arxiv.org/abs/2409.02018v1)|null|
|**2024-09-03**|**A randomized simulation trial evaluating ABiMed, a clinical decision support system for medication reviews and polypharmacy management**|Abdelmalek Mouazer et.al.|[2409.01903v1](http://arxiv.org/abs/2409.01903v1)|null|
|**2024-09-03**|**Training on the Benchmark Is Not All You Need**|Shiwen Ni et.al.|[2409.01790v1](http://arxiv.org/abs/2409.01790v1)|[link](https://github.com/nishiwen1214/Benchmark-leakage-detection)|
|**2024-09-03**|**Classifier-Free Diffusion-Based Weakly-Supervised Approach for Health Indicator Derivation in Rotating Machines: Advancing Early Fault Detection and Condition Monitoring**|Wenyang Hu et.al.|[2409.01676v1](http://arxiv.org/abs/2409.01676v1)|null|
|**2024-09-03**|**A Multimodal Object-level Contrast Learning Method for Cancer Survival Risk Prediction**|Zekang Yang et.al.|[2409.02145v1](http://arxiv.org/abs/2409.02145v1)|[link](https://github.com/yang-ze-kang/MOC)|
|**2024-09-03**|**A Time-Intensity Aware Pipeline for Generating Late-Stage Breast DCE-MRI using Generative Adversarial Models**|Ruben D. Fonnegra et.al.|[2409.01596v1](http://arxiv.org/abs/2409.01596v1)|null|
|**2024-09-02**|**Kvasir-VQA: A Text-Image Pair GI Tract Dataset**|Sushant Gautam et.al.|[2409.01437v1](http://arxiv.org/abs/2409.01437v1)|[link](https://github.com/simula/Kvasir-VQA)|
|**2024-09-02**|**SeCo-INR: Semantically Conditioned Implicit Neural Representations for Improved Medical Image Super-Resolution**|Mevan Ekanayake et.al.|[2409.01013v1](http://arxiv.org/abs/2409.01013v1)|null|
|**2024-09-01**|**Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation**|Sajib Acharjee Dip et.al.|[2409.00873v1](http://arxiv.org/abs/2409.00873v1)|null|
|**2024-09-01**|**Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**|Derian Boer et.al.|[2409.00861v1](http://arxiv.org/abs/2409.00861v1)|[link](https://github.com/kramerlab/4StepFocus)|
|**2024-09-01**|**Building FKG.in: a Knowledge Graph for Indian Food**|Saransh Kumar Gupta et.al.|[2409.00830v1](http://arxiv.org/abs/2409.00830v1)|null|
|**2024-09-01**|**AgGym: An agricultural biotic stress simulation environment for ultra-precision management planning**|Mahsa Khosravi et.al.|[2409.00735v1](http://arxiv.org/abs/2409.00735v1)|null|
|**2024-09-01**|**LPUWF-LDM: Enhanced Latent Diffusion Model for Precise Late-phase UWF-FA Generation on Limited Dataset**|Zhaojie Fang et.al.|[2409.00726v1](http://arxiv.org/abs/2409.00726v1)|[link](https://github.com/Tinysqua/LPUWF-LDM)|
|**2024-09-01**|**BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation Dataset for Developing Computer-Aided Diagnostic Systems**|Shams Nafisa Ali et.al.|[2409.00724v1](http://arxiv.org/abs/2409.00724v1)|[link](https://github.com/sani002/HS-Dataset)|
|**2024-09-01**|**Multiscale Color Guided Attention Ensemble Classifier for Age-Related Macular Degeneration using Concurrent Fundus and Optical Coherence Tomography Images**|Pragya Gupta et.al.|[2409.00718v1](http://arxiv.org/abs/2409.00718v1)|null|
|**2024-09-01**|**Curriculum Prompting Foundation Models for Medical Image Segmentation**|Xiuqi Zheng et.al.|[2409.00695v1](http://arxiv.org/abs/2409.00695v1)|[link](https://github.com/annazzz-zxq/curriculum-prompting)|
|**2024-08-31**|**Large Language Models-Enabled Digital Twins for Precision Medicine in Rare Gynecological Tumors**|Jacqueline Lammert et.al.|[2409.00544v1](http://arxiv.org/abs/2409.00544v1)|[link](https://github.com/LammertJ/RGT-Digital-Twin)|
|**2024-08-31**|**Density Adaptive Attention-based Speech Network: Enhancing Feature Understanding for Mental Health Disorders**|Georgios Ioannides et.al.|[2409.00391v1](http://arxiv.org/abs/2409.00391v1)|null|
|**2024-08-31**|**Objective Features Extracted from Motor Activity Time Series for Food Addiction Analysis Using Machine Learning**|Mikhail Borisenkov et.al.|[2409.00310v1](http://arxiv.org/abs/2409.00310v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-30**|**Deep Neural Networks for Predicting Recurrence and Survival in Patients with Esophageal Cancer After Surgery**|Yuhan Zheng et.al.|[2409.00163v1](http://arxiv.org/abs/2409.00163v1)|null|
|**2024-08-30**|**NDP: Next Distribution Prediction as a More Broad Target**|Junhao Ruan et.al.|[2408.17377v1](http://arxiv.org/abs/2408.17377v1)|null|
|**2024-08-30**|**Disease Classification and Impact of Pretrained Deep Convolution Neural Networks on Diverse Medical Imaging Datasets across Imaging Modalities**|Jutika Borah et.al.|[2408.17011v2](http://arxiv.org/abs/2408.17011v2)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-29**|**Toward Robust Early Detection of Alzheimer's Disease via an Integrated Multimodal Learning Approach**|Yifei Chen et.al.|[2408.16343v1](http://arxiv.org/abs/2408.16343v1)|[link](https://github.com/justlfc03/mstnet)|
|**2024-08-29**|**Coalitions of AI-based Methods Predict 15-Year Risks of Breast Cancer Metastasis Using Real-World Clinical Data with AUC up to 0.9**|Xia Jiang et.al.|[2408.16256v1](http://arxiv.org/abs/2408.16256v1)|null|
|**2024-08-29**|**M4CXR: Exploring Multi-task Potentials of Multi-modal Large Language Models for Chest X-ray Interpretation**|Jonggwon Park et.al.|[2408.16213v1](http://arxiv.org/abs/2408.16213v1)|null|
|**2024-08-28**|**A Survey on Evaluation of Multimodal Large Language Models**|Jiaxing Huang et.al.|[2408.15769v1](http://arxiv.org/abs/2408.15769v1)|null|
|**2024-08-28**|**Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep Feed-forward Neural Network**|Yijun Zhou et.al.|[2408.15498v1](http://arxiv.org/abs/2408.15498v1)|null|
|**2024-08-27**|**What Is Required for Empathic AI? It Depends, and Why That Matters for AI Developers and Users**|Jana Schaich Borg et.al.|[2408.15354v1](http://arxiv.org/abs/2408.15354v1)|null|
|**2024-08-27**|**Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance**|Weiyi Zhang et.al.|[2408.15217v1](http://arxiv.org/abs/2408.15217v1)|null|
|**2024-08-27**|**Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy**|Daniil Filienko et.al.|[2409.00112v1](http://arxiv.org/abs/2409.00112v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-27**|**MiWaves Reinforcement Learning Algorithm**|Susobhan Ghosh et.al.|[2408.15076v1](http://arxiv.org/abs/2408.15076v1)|[link](https://github.com/statisticalreinforcementlearninglab/miwaves_rl_service)|
|**2024-08-27**|**Mamba2MIL: State Space Duality Based Multiple Instance Learning for Computational Pathology**|Yuqi Zhang et.al.|[2408.15032v1](http://arxiv.org/abs/2408.15032v1)|[link](https://github.com/yuqizhang-buaa/mamba2mil)|
|**2024-08-27**|**Sequence-aware Pre-training for Echocardiography Probe Guidance**|Haojun Jiang et.al.|[2408.15026v1](http://arxiv.org/abs/2408.15026v1)|null|
|**2024-08-27**|**Evaluating the Predictive Features of Person-Centric Knowledge Graph Embeddings: Unfolding Ablation Studies**|Christos Theodoropoulos et.al.|[2408.15294v2](http://arxiv.org/abs/2408.15294v2)|null|
|**2024-08-27**|**Sequential-Scanning Dual-Energy CT Imaging Using High Temporal Resolution Image Reconstruction and Error-Compensated Material Basis Image Generation**|Qiaoxin Li et.al.|[2408.14754v1](http://arxiv.org/abs/2408.14754v1)|null|
|**2024-08-27**|**Large Language Models for Disease Diagnosis: A Scoping Review**|Shuang Zhou et.al.|[2409.00097v1](http://arxiv.org/abs/2409.00097v1)|null|
|**2024-08-26**|**Improving Clinical Note Generation from Complex Doctor-Patient Conversation**|Yizhan Li et.al.|[2408.14568v1](http://arxiv.org/abs/2408.14568v1)|null|
|**2024-08-26**|**Temporal Ensemble Logic**|Guo-Qiang Zhang et.al.|[2408.14443v2](http://arxiv.org/abs/2408.14443v2)|null|
|**2024-08-26**|**MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues**|Kuluhan Binici et.al.|[2408.14418v2](http://arxiv.org/abs/2408.14418v2)|null|
|**2024-08-26**|**Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs**|Xiaoman Zhang et.al.|[2408.14397v1](http://arxiv.org/abs/2408.14397v1)|[link](https://github.com/rajpurkarlab/rexkg)|
|**2024-08-26**|**Foundation Models for Music: A Survey**|Yinghao Ma et.al.|[2408.14340v3](http://arxiv.org/abs/2408.14340v3)|[link](https://github.com/nicolaus625/fm4music)|
|**2024-08-26**|**Uncertainties of Latent Representations in Computer Vision**|Michael Kirchhof et.al.|[2408.14281v1](http://arxiv.org/abs/2408.14281v1)|null|
|**2024-08-26**|**Automatic Medical Report Generation: Methods and Applications**|Li Guo et.al.|[2408.13988v1](http://arxiv.org/abs/2408.13988v1)|null|
|**2024-08-25**|**Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models**|Seyed Amir Ahmad Safavi-Naini et.al.|[2409.00084v2](http://arxiv.org/abs/2409.00084v2)|[link](https://github.com/sdamirsa/llm-vlm-in-gastroenterology)|
|**2024-08-25**|**PropSAM: A Propagation-Based Model for Segmenting Any 3D Objects in Multi-Modal Medical Images**|Zifan Chen et.al.|[2408.13836v1](http://arxiv.org/abs/2408.13836v1)|null|
|**2024-08-24**|**Submodular Maximization Approaches for Equitable Client Selection in Federated Learning**|Andrés Catalino Castillo Jiménez et.al.|[2408.13683v2](http://arxiv.org/abs/2408.13683v2)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-23**|**HBIC: A Biclustering Algorithm for Heterogeneous Datasets**|Adán José-García et.al.|[2408.13217v1](http://arxiv.org/abs/2408.13217v1)|[link](https://github.com/clementchauvet/py-hbic)|
|**2024-08-23**|**Causal machine learning for sustainable agroecosystems**|Vasileios Sitokonstantinou et.al.|[2408.13155v1](http://arxiv.org/abs/2408.13155v1)|null|
|**2024-08-23**|**Has Multimodal Learning Delivered Universal Intelligence in Healthcare? A Comprehensive Survey**|Qika Lin et.al.|[2408.12880v1](http://arxiv.org/abs/2408.12880v1)|[link](https://github.com/deepreasoning/aihealth)|
|**2024-08-23**|**COVID-19 Probability Prediction Using Machine Learning: An Infectious Approach**|Mohsen Asghari Ilani et.al.|[2408.12841v1](http://arxiv.org/abs/2408.12841v1)|null|
|**2024-08-23**|**Exploring Machine Learning Models for Lung Cancer Level Classification: A comparative ML Approach**|Mohsen Asghari Ilani et.al.|[2408.12838v1](http://arxiv.org/abs/2408.12838v1)|null|
|**2024-08-23**|**Phrasing for UX: Enhancing Information Engagement through Computational Linguistics and Creative Analytics**|Nimrod Dvir et.al.|[2409.00064v1](http://arxiv.org/abs/2409.00064v1)|null|
|**2024-08-22**|**From Radiologist Report to Image Label: Assessing Latent Dirichlet Allocation in Training Neural Networks for Orthopedic Radiograph Classification**|Jakub Olczak et.al.|[2408.13284v1](http://arxiv.org/abs/2408.13284v1)|null|
|**2024-08-22**|**MultiMed: Massively Multimodal and Multitask Medical Understanding**|Shentong Mo et.al.|[2408.12682v1](http://arxiv.org/abs/2408.12682v1)|null|
|**2024-08-22**|**RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**|Xiaohan Wang et.al.|[2408.12579v1](http://arxiv.org/abs/2408.12579v1)|null|
|**2024-08-22**|**Automatic Organ and Pan-cancer Segmentation in Abdomen CT: the FLARE 2023 Challenge**|Jun Ma et.al.|[2408.12534v1](http://arxiv.org/abs/2408.12534v1)|null|
|**2024-08-22**|**MEDCO: Medical Education Copilots Based on A Multi-Agent Framework**|Hao Wei et.al.|[2408.12496v1](http://arxiv.org/abs/2408.12496v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-22**|**WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation**|Palak Handa et.al.|[2408.12466v1](http://arxiv.org/abs/2408.12466v1)|[link](https://github.com/misahub2023/benchmarking-codes-of-the-wcebleedgen-dataset)|

#### Abstracts
##### **Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort**
2409.06672v1 by Cristian Trout

Many experts believe that AI systems will sooner or later pose uninsurable
risks, including existential risks. This creates an extreme judgment-proof
problem: few if any parties can be held accountable ex post in the event of
such a catastrophe. This paper proposes a novel solution: a
government-provided, mandatory indemnification program for AI developers. The
program uses risk-priced indemnity fees to induce socially optimal levels of
care. Risk-estimates are determined by surveying experts, including indemnified
developers. The Bayesian Truth Serum mechanism is employed to incent honest and
effortful responses. Compared to alternatives, this approach arguably better
leverages all private information, and provides a clearer signal to indemnified
developers regarding what risks they must mitigate to lower their fees. It's
recommended that collected fees be used to help fund the safety research
developers need, employing a fund matching mechanism (Quadratic Financing) to
induce an optimal supply of this public good. Under Quadratic Financing, safety
research projects would compete for private contributions from developers,
signaling how much each is to be supplemented with public funds.

摘要：許多專家相信 AI 系統遲早會造成無法承保的風險，包括生存風險。這會造成極端的無法追究責任問題：在發生此類災難時，幾乎沒有任何一方可以事後被追究責任。本文提出了一個創新的解決方案：政府提供的 AI 開發人員強制性補償計畫。該計畫使用風險定價的補償費用來誘使達到社會最適程度的照護。風險估計值是由調查專家（包括獲得補償的開發人員）來決定。貝氏真話血清機制被用來激勵誠實且努力的回應。與其他方法相比，這種方法可以說能更好地利用所有私人資訊，並向獲得補償的開發人員提供更明確的訊號，說明他們必須減輕哪些風險才能降低費用。建議將收取的費用用於資助安全研究開發人員所需的研究，並採用基金配對機制（二次方融資）來誘使提供這種公共財的最佳供應。在二次方融資下，安全研究計畫將競爭開發人員的私人捐款，並表示其中有多少將由公共資金補充。

##### **EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**
2409.06644v2 by Danli Shi, Weiyi Zhang, Jiancheng Yang, Siyu Huang, Xiaolan Chen, Mayinuer Yusufu, Kai Jin, Shan Lin, Shunming Liu, Qing Zhang, Mingguang He

Early detection of eye diseases like glaucoma, macular degeneration, and
diabetic retinopathy is crucial for preventing vision loss. While artificial
intelligence (AI) foundation models hold significant promise for addressing
these challenges, existing ophthalmic foundation models primarily focus on a
single modality, whereas diagnosing eye diseases requires multiple modalities.
A critical yet often overlooked aspect is harnessing the multi-view information
across various modalities for the same patient. Additionally, due to the
long-tail nature of ophthalmic diseases, standard fully supervised or
unsupervised learning approaches often struggle. Therefore, it is essential to
integrate clinical text to capture a broader spectrum of diseases. We propose
EyeCLIP, a visual-language foundation model developed using over 2.77 million
multi-modal ophthalmology images with partial text data. To fully leverage the
large multi-modal unlabeled and labeled data, we introduced a pretraining
strategy that combines self-supervised reconstructions, multi-modal image
contrastive learning, and image-text contrastive learning to learn a shared
representation of multiple modalities. Through evaluation using 14 benchmark
datasets, EyeCLIP can be transferred to a wide range of downstream tasks
involving ocular and systemic diseases, achieving state-of-the-art performance
in disease classification, visual question answering, and cross-modal
retrieval. EyeCLIP represents a significant advancement over previous methods,
especially showcasing few-shot, even zero-shot capabilities in real-world
long-tail scenarios.

摘要：早期偵測青光眼、黃斑部病變和糖尿病視網膜病變等眼疾對於預防視力喪失至關重要。儘管人工智慧 (AI) 基礎模型在應對這些挑戰方面極具前景，但現有的眼科基礎模型主要關注於單一模式，而診斷眼疾需要多種模式。一個重要但經常被忽視的方面是利用同一患者不同模式的多視圖資訊。此外，由於眼科疾病的長尾性質，標準的全監督或無監督學習方法通常難以應付。因此，整合臨床文本以涵蓋更廣泛的疾病譜系至關重要。我們提出 EyeCLIP，這是一個視覺語言基礎模型，使用超過 277 萬張具有部分文字資料的多模式眼科影像開發而成。為了充分利用大量的多模式未標記和標記資料，我們引入了一種預訓練策略，結合了自我監督重建、多模式影像對比學習和影像文字對比學習，以學習多種模式的共享表徵。透過使用 14 個基準資料集進行評估，EyeCLIP 可以轉移到涉及眼部和全身疾病的廣泛下游任務，在疾病分類、視覺問題解答和跨模式檢索中實現最先進的效能。EyeCLIP 代表了對先前方法的重大進展，特別是在現實世界長尾場景中展示了小樣本，甚至零樣本的能力。

##### **Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**
2409.06585v1 by Zoe Hancox, Sarah R. Kingsbury, Andrew Clegg, Philip G. Conaghan, Samuel D. Relton

Background: Hip replacement procedures improve patient lives by relieving
pain and restoring mobility. Predicting hip replacement in advance could reduce
pain by enabling timely interventions, prioritising individuals for surgery or
rehabilitation, and utilising physiotherapy to potentially delay the need for
joint replacement. This study predicts hip replacement a year in advance to
enhance quality of life and health service efficiency. Methods: Adapting
previous work using Temporal Graph Convolutional Neural Network (TG-CNN)
models, we construct temporal graphs from primary care medical event codes,
sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip
replacement risk. We match hip replacement cases to controls by age, sex, and
Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187
controls, predicts hip replacement one year in advance. We validate the model
on two unseen datasets, recalibrating for class imbalance. Additionally, we
conduct an ablation study and compare against four baseline models. Results:
Our best model predicts hip replacement risk one year in advance with an AUROC
of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),
achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after
recalibration. Conclusions: The TG-CNN model effectively predicts hip
replacement risk by identifying patterns in patient trajectories, potentially
improving understanding and management of hip-related conditions.

摘要：背景：髖關節置換手術可減輕疼痛並恢復行動能力，進而改善患者生活。預測髖關節置換手術有助於及時介入、優先安排個人進行手術或復健，並利用物理治療來延緩關節置換手術的必要性，進而減少疼痛。本研究預測一年後的髖關節置換手術，以提升生活品質和醫療服務效率。方法：採用時間圖形卷積神經網路 (TG-CNN) 模型改編先前的研究，我們從 ResearchOne EHR 40-75 歲患者的主要照護醫療事件代碼建構時間圖形，以預測髖關節置換手術風險。我們根據年齡、性別和多重剝奪指數，將髖關節置換手術病例與對照組進行配對。該模型針對 9,187 個病例和 9,187 個對照組進行訓練，預測一年後的髖關節置換手術。我們在兩個未見數據集驗證模型，並重新校準以解決類別不平衡問題。此外，我們進行消融研究，並與四個基準模型進行比較。結果：我們最佳的模型預測一年後的髖關節置換手術風險，AUROC 為 0.724 (95% CI：0.715-0.733)，AUPRC 為 0.185 (95% CI：0.160-0.209)，重新校準後校準斜率為 1.107 (95% CI：1.074-1.139)。結論：TG-CNN 模型可有效預測髖關節置換手術風險，方法是找出患者軌跡中的模式，進而潛在改善對髖關節相關疾病的了解和管理。

##### **MAGDA: Multi-agent guideline-driven diagnostic assistance**
2409.06351v1 by David Bani-Harouni, Nassir Navab, Matthias Keicher

In emergency departments, rural hospitals, or clinics in less developed
regions, clinicians often lack fast image analysis by trained radiologists,
which can have a detrimental effect on patients' healthcare. Large Language
Models (LLMs) have the potential to alleviate some pressure from these
clinicians by providing insights that can help them in their decision-making.
While these LLMs achieve high test results on medical exams showcasing their
great theoretical medical knowledge, they tend not to follow medical
guidelines. In this work, we introduce a new approach for zero-shot
guideline-driven decision support. We model a system of multiple LLM agents
augmented with a contrastive vision-language model that collaborate to reach a
patient diagnosis. After providing the agents with simple diagnostic
guidelines, they will synthesize prompts and screen the image for findings
following these guidelines. Finally, they provide understandable
chain-of-thought reasoning for their diagnosis, which is then self-refined to
consider inter-dependencies between diseases. As our method is zero-shot, it is
adaptable to settings with rare diseases, where training data is limited, but
expert-crafted disease descriptions are available. We evaluate our method on
two chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing
performance improvement over existing zero-shot methods and generalizability to
rare diseases.

摘要：在急診室、鄉村醫院或欠發達地區的診所，臨床醫師常常缺乏受過訓練的放射科醫師進行快速的影像分析，這可能會對病患的醫療保健造成不利影響。大型語言模型 (LLM) 有潛力減輕這些臨床醫師的一些壓力，方法是提供見解，協助他們進行決策。儘管這些 LLM 在展示其豐富的理論醫學知識的醫學考試中獲得了很高的測試結果，但它們往往不遵循醫療指南。在這項工作中，我們介紹了一種新的零次學習指導方針驅動決策支援方法。我們模擬了一個多個 LLM 代理系統，並增強了一個對比視覺語言模型，該模型協作以達成病患診斷。在為代理提供簡單的診斷指南後，它們將綜合提示並根據這些指南篩選影像以找出發現。最後，它們為其診斷提供可以理解的思路推理，然後自我精進以考量疾病之間的相互依存關係。由於我們的模型是零次學習，因此它可以適應罕見疾病的設定，在這種設定中，訓練資料有限，但有專家製作的疾病描述可用。我們在兩個胸部 X 光片資料集，CheXpert 和 ChestX-ray 14 Longtail，評估我們的模型，展示了相較於現有的零次學習方法的效能提升，以及對罕見疾病的概括性。

##### **Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis**
2409.06209v1 by Xin Zhang, Deval Mehta, Yanan Hu, Chao Zhu, David Darby, Zhen Yu, Daniel Merlo, Melissa Gresle, Anneke Van Der Walt, Helmut Butzkueven, Zongyuan Ge

Survival analysis holds a crucial role across diverse disciplines, such as
economics, engineering and healthcare. It empowers researchers to analyze both
time-invariant and time-varying data, encompassing phenomena like customer
churn, material degradation and various medical outcomes. Given the complexity
and heterogeneity of such data, recent endeavors have demonstrated successful
integration of deep learning methodologies to address limitations in
conventional statistical approaches. However, current methods typically involve
cluttered probability distribution function (PDF), have lower sensitivity in
censoring prediction, only model static datasets, or only rely on recurrent
neural networks for dynamic modelling. In this paper, we propose a novel
survival regression method capable of producing high-quality unimodal PDFs
without any prior distribution assumption, by optimizing novel
Margin-Mean-Variance loss and leveraging the flexibility of Transformer to
handle both temporal and non-temporal data, coined UniSurv. Extensive
experiments on several datasets demonstrate that UniSurv places a significantly
higher emphasis on censoring compared to other methods.

摘要：存活分析在經濟、工程和醫療保健等不同學科中扮演著至關重要的角色。它讓研究人員能夠分析時不變和時變數據，包含客戶流失、材料降解和各種醫療結果等現象。鑑於此類數據的複雜性和異質性，最近的努力已證明成功整合深度學習方法以解決傳統統計方法的限制。然而，目前的方法通常涉及雜亂的機率分佈函數 (PDF)，在審查預測中具有較低的敏感性，僅對靜態數據集進行建模，或僅依賴遞迴神經網路進行動態建模。在本文中，我們提出了一種新穎的存活迴歸方法，能夠在沒有任何先驗分佈假設的情況下產生高品質的單峰 PDF，藉由最佳化新穎的邊際平均值變異損失，並利用 Transformer 的靈活性來處理時間和非時間數據，稱為 UniSurv。在幾個數據集上的廣泛實驗證明，與其他方法相比，UniSurv 對審查的重視程度顯著提高。

##### **Can Large Language Models Unlock Novel Scientific Research Ideas?**
2409.06185v1 by Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal

"An idea is nothing more nor less than a new combination of old elements"
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.

摘要：「一個想法不過就是舊元素的新組合而已」
(Young, J.W.)。大型語言模型 (LLM) 和公開的 ChatGPT 廣泛採用，標誌著人工智能 (AI) 整合到人們日常生活中的重要轉折點。本研究探討了 LLM 在根據研究論文資訊產生新研究想法方面的能力。我們對五個領域（例如化學、電腦、經濟、醫學和物理）中的 4 個 LLM 進行了徹底檢查。我們發現 Claude-2 和 GPT-4 產生的未來研究想法比 GPT-3.5 和 Gemini 更符合作者的觀點。我們還發現，Claude-2 產生的未來研究想法比 GPT-4、GPT-3.5 和 Gemini 1.0 更為多樣化。我們進一步對產生的未來研究想法的新穎性、相關性和可行性進行了人工評估。本調查提供了對 LLM 在產生想法中不斷演變的角色的見解，突出了其能力和限制。我們的研究有助於評估和利用語言模型來產生未來研究想法的持續努力。我們公開提供我們的數據集和程式碼。

##### **Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks**
2409.06173v1 by Georgios Chochlakis, Niyantha Maruthu Pandiyan, Kristina Lerman, Shrikanth Narayanan

In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the
dominant technique for performing natural language tasks, as it does not
require updating the model parameters with gradient-based methods. ICL promises
to "adapt" the LLM to perform the present task at a competitive or
state-of-the-art level at a fraction of the computational cost. ICL can be
augmented by incorporating the reasoning process to arrive at the final label
explicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.
However, recent work has found that ICL relies mostly on the retrieval of task
priors and less so on "learning" to perform tasks, especially for complex
subjective domains like emotion and morality, where priors ossify posterior
predictions. In this work, we examine whether "enabling" reasoning also creates
the same behavior in LLMs, wherein the format of CoT retrieves reasoning priors
that remain relatively unchanged despite the evidence in the prompt. We find
that, surprisingly, CoT indeed suffers from the same posterior collapse as ICL
for larger language models. Code is avalaible at
https://github.com/gchochla/cot-priors.

摘要：大型語言模型 (LLM) 中的語境學習 (ICL) 已成為執行自然語言任務的主流技術，因為它不需要使用基於梯度的模型參數來更新。ICL 承諾以極低的計算成本「調整」LLM，以在競爭或最先進的層級執行當前任務。ICL 可以透過在提示中明確地納入推理過程來擴充，以得出最終標籤，這項技術稱為思考鏈 (CoT) 提示。然而，最近的研究發現，ICL 主要依賴於任務先驗的檢索，較少依賴於「學習」執行任務，特別是對於情緒和道德等複雜的主觀領域，其中先驗會僵化後驗預測。在這項研究中，我們探討「啟用」推理是否也會在 LLM 中產生相同的行為，其中 CoT 的格式會檢索推理先驗，儘管提示中的證據不同，但這些先驗仍然相對不變。我們發現，令人驚訝的是，對於較大的語言模型，CoT 確實會與 ICL 發生相同的後驗崩潰。程式碼可於 https://github.com/gchochla/cot-priors 取得。

##### **Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings**
2409.06147v1 by Dong Han, Jihye Moon, Luís Roberto Mercado Díaz, Darren Chen, Devan Williams, Eric Y. Ding, Khanh-Van Tran, David D. McManus, Ki H. Chon

Most deep learning models of multiclass arrhythmia classification are tested
on fingertip photoplethysmographic (PPG) data, which has higher signal-to-noise
ratios compared to smartwatch-derived PPG, and the best reported sensitivity
value for premature atrial/ventricular contraction (PAC/PVC) detection is only
75%. To improve upon PAC/PVC detection sensitivity while maintaining high AF
detection, we use multi-modal data which incorporates 1D PPG, accelerometers,
and heart rate data as the inputs to a computationally efficient 1D
bi-directional Gated Recurrent Unit (1D-Bi-GRU) model to detect three
arrhythmia classes. We used motion-artifact prone smartwatch PPG data from the
NIH-funded Pulsewatch clinical trial. Our multimodal model tested on 72
subjects achieved an unprecedented 83% sensitivity for PAC/PVC detection while
maintaining a high accuracy of 97.31% for AF detection. These results
outperformed the best state-of-the-art model by 20.81% for PAC/PVC and 2.55%
for AF detection even while our model was computationally more efficient (14
times lighter and 2.7 faster).

摘要：大多數多類心律不整分類的深度學習模型都是在指尖光電容積描記法 (PPG) 資料上進行測試，與智慧手錶衍生的 PPG 相比，其訊號雜訊比更高，而對於期前心房/心室收縮 (PAC/PVC) 偵測所報告的最佳敏感度值僅為 75%。為了在維持高房顫偵測的同時提高 PAC/PVC 偵測敏感度，我們使用多模式資料，將 1D PPG、加速度計和心率資料作為計算效率高的 1D 雙向閘控遞迴單元 (1D-Bi-GRU) 模型的輸入，以偵測三類心律不整。我們使用了美國國家衛生研究院資助的 Pulsewatch 臨床試驗中的運動偽影易感智慧手錶 PPG 資料。我們在 72 名受試者身上測試的多模式模型，對於 PAC/PVC 偵測達到了前所未有的 83% 敏感度，同時對於房顫偵測維持了 97.31% 的高準確度。即使我們的模型在計算上更有效率（輕 14 倍，快 2.7 倍），這些結果仍比最先進的模型在 PAC/PVC 偵測上高出 20.81%，在房顫偵測上高出 2.55%。

##### **Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research**
2409.06069v1 by Osama Zafar, Rosemarie Santa Gonzalez, Gabriel Wilkins, Alfonso Morales, Erman Ayday

Digital agriculture leverages technology to enhance crop yield, disease
resilience, and soil health, playing a critical role in agricultural research.
However, it raises privacy concerns such as adverse pricing, price
discrimination, higher insurance costs, and manipulation of resources,
deterring farm operators from sharing data due to potential misuse. This study
introduces a privacy-preserving framework that addresses these risks while
allowing secure data sharing for digital agriculture. Our framework enables
comprehensive data analysis while protecting privacy. It allows stakeholders to
harness research-driven policies that link public and private datasets. The
proposed algorithm achieves this by: (1) identifying similar farmers based on
private datasets, (2) providing aggregate information like time and location,
(3) determining trends in price and product availability, and (4) correlating
trends with public policy data, such as food insecurity statistics. We validate
the framework with real-world Farmer's Market datasets, demonstrating its
efficacy through machine learning models trained on linked privacy-preserved
data. The results support policymakers and researchers in addressing food
insecurity and pricing issues. This work significantly contributes to digital
agriculture by providing a secure method for integrating and analyzing data,
driving advancements in agricultural technology and development.

摘要：數位農業利用科技來提升作物產量、疾病復原力和土壤健康，在農業研究中扮演關鍵角色。
然而，它引發了隱私問題，例如不利定價、價格歧視、較高的保險成本和資源操縱，由於潛在的誤用，阻止了農場經營者分享資料。本研究提出一個保護隱私的架構，它能解決這些風險，同時允許安全的資料共享以進行數位農業。我們的架構能進行全面的資料分析，同時保護隱私。它允許利害關係人利用研究驅動的政策，連結公共和私人資料集。所提出的演算法透過以下方式達成此目標：(1) 根據私人資料集識別類似的農民，(2) 提供總和資訊，例如時間和地點，(3) 確定價格和產品可用性的趨勢，以及 (4) 將趨勢與公共政策資料相關聯，例如糧食不安全統計。我們使用真實世界的農夫市集資料集驗證了這個架構，透過在連結的保護隱私資料上訓練的機器學習模型，證明了它的效力。這些結果支持政策制定者和研究人員解決糧食不安全和定價問題。這項工作透過提供一個整合和分析資料的安全方法，大幅貢獻了數位農業，推動農業技術和發展的進步。

##### **ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language**
2409.05592v1 by Zhaoyue Sun, Jiazheng Li, Gabriele Pergola, Yulan He

Predicting unknown drug-drug interactions (DDIs) is crucial for improving
medication safety. Previous efforts in DDI prediction have typically focused on
binary classification or predicting DDI categories, with the absence of
explanatory insights that could enhance trust in these predictions. In this
work, we propose to generate natural language explanations for DDI predictions,
enabling the model to reveal the underlying pharmacodynamics and
pharmacokinetics mechanisms simultaneously as making the prediction. To do
this, we have collected DDI explanations from DDInter and DrugBank and
developed various models for extensive experiments and analysis. Our models can
provide accurate explanations for unknown DDIs between known drugs. This paper
contributes new tools to the field of DDI prediction and lays a solid
foundation for further research on generating explanations for DDI predictions.

摘要：預測未知的藥物交互作用 (DDI) 對於改善藥物安全至關重要。先前在 DDI 預測方面所做的努力通常集中於二元分類或預測 DDI 類別，而缺乏能夠增強這些預測的可信度的解釋性見解。在這項工作中，我們建議為 DDI 預測產生自然語言解釋，使模型能夠同時揭示藥效學和藥物動力學機制，並進行預測。為此，我們從 DDInter 和 DrugBank 收集了 DDI 解釋，並開發了各種模型進行廣泛的實驗和分析。我們的模型可以為已知藥物之間未知的 DDI 提供準確的解釋。本文為 DDI 預測領域貢獻了新的工具，並為進一步研究 DDI 預測的解釋生成奠定了堅實的基礎。

##### **Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models**
2409.05486v1 by Camilo Thorne, Christian Druckenbrodt, Kinga Szarkowska, Deepika Goyal, Pranita Marajan, Vijay Somanath, Corey Harper, Mao Yan, Tony Scerri

The quality and capabilities of large language models cannot be currently
fully assessed with automated, benchmark evaluations. Instead, human
evaluations that expand on traditional qualitative techniques from natural
language generation literature are required. One recent best-practice consists
in using A/B-testing frameworks, which capture preferences of human evaluators
for specific models. In this paper we describe a human evaluation experiment
focused on the biomedical domain (health, biology, chemistry/pharmacology)
carried out at Elsevier. In it a large but not massive (8.8B parameter)
decoder-only foundational transformer trained on a relatively small (135B
tokens) but highly curated collection of Elsevier datasets is compared to
OpenAI's GPT-3.5-turbo and Meta's foundational 7B parameter Llama 2 model
against multiple criteria. Results indicate -- even if IRR scores were
generally low -- a preference towards GPT-3.5-turbo, and hence towards models
that possess conversational abilities, are very large and were trained on very
large datasets. But at the same time, indicate that for less massive models
training on smaller but well-curated training sets can potentially give rise to
viable alternatives in the biomedical domain.

摘要：大型語言模型的品質和能力目前無法使用自動化基準評估來完全評估。相反，需要使用擴展自然語言生成文獻中傳統定性技術的人類評估。一個最近的最佳實務是使用 A/B 測試框架，該框架會擷取人類評估者對特定模型的偏好。在本文中，我們描述了專注於生物醫學領域（健康、生物學、化學/藥理學）的人類評估實驗，該實驗在 Elsevier 進行。其中，一個大型但並非龐大（8.8B 參數）僅解碼器基礎Transformer在相對較小（135B 令牌）但經過高度策展的 Elsevier 資料集上訓練，與 OpenAI 的 GPT-3.5-turbo 和 Meta 的基礎 7B 參數 Llama 2 模型進行比較，針對多個標準。結果表明——即使 IRR 分數普遍較低——偏好 GPT-3.5-turbo，因此偏好具備對話能力、非常龐大且在非常龐大的資料集上訓練的模型。但同時，表明對於較小規模的模型，在較小但經過良好策展的訓練集上訓練，有可能在生物醫學領域產生可行的替代方案。

##### **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**
2409.05370v1 by Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, Luping Zhou

Harnessing the robust capabilities of Large Language Models (LLMs) for
narrative generation, logical reasoning, and common-sense knowledge
integration, this study delves into utilizing LLMs to enhance automated
radiology report generation (R2Gen). Despite the wealth of knowledge within
LLMs, efficiently triggering relevant knowledge within these large models for
specific tasks like R2Gen poses a critical research challenge. This paper
presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration
framework based on LLMs. Utilizing a frozen LLM to generate reports, the
framework integrates a knowledge graph to unlock chest disease-related
knowledge within the LLM to enhance the clinical utility of generated reports.
This is achieved by leveraging the knowledge graph to distill disease-related
features in a designed way. Since a radiology report encompasses both normal
and disease-related findings, the extracted graph-enhanced disease-related
features are integrated with regional image features, attending to both
aspects. We explore two fusion methods to automatically prioritize and select
the most relevant features. The fused features are employed by LLM to generate
reports that are more sensitive to diseases and of improved quality. Our
approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.

摘要：<paragraph>利用大型語言模型 (LLM) 強大的功能，進行敘事生成、邏輯推理和常識知識整合，本研究深入探討利用 LLM 來增強自動化放射報告生成 (R2Gen)。儘管 LLM 擁有豐富的知識，但要有效觸發這些大型模型中與特定任務（如 R2Gen）相關的知識，是一個重要的研究挑戰。本文提出了 KARGEN，一個基於 LLM 的知識增強自動化放射報告生成框架。利用凍結的 LLM 來生成報告，該框架整合了一個知識圖譜，以解鎖 LLM 中與胸部疾病相關的知識，以增強生成報告的臨床效用。這是透過利用知識圖譜以設計的方式提取與疾病相關的特徵來實現的。由於放射報告包含正常和疾病相關的發現，因此提取的圖形增強疾病相關特徵與區域影像特徵整合，兼顧兩個方面。我們探索了兩種融合方法，以自動優先排序和選擇最相關的特徵。融合的特徵由 LLM 使用，以生成對疾病更敏感且品質更高的報告。我們的做法在 MIMIC-CXR 和 IU-Xray 資料集上展示了有希望的結果。</paragraph>

##### **Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis**
2409.05292v2 by Nirmalya Thakur

The world is currently experiencing an outbreak of mpox, which has been
declared a Public Health Emergency of International Concern by WHO. No prior
work related to social media mining has focused on the development of a dataset
of Instagram posts about the mpox outbreak. The work presented in this paper
aims to address this research gap and makes two scientific contributions to
this field. First, it presents a multilingual dataset of 60,127 Instagram posts
about mpox, published between July 23, 2022, and September 5, 2024. The
dataset, available at https://dx.doi.org/10.21227/7fvc-y093, contains Instagram
posts about mpox in 52 languages. For each of these posts, the Post ID, Post
Description, Date of publication, language, and translated version of the post
(translation to English was performed using the Google Translate API) are
presented as separate attributes in the dataset. After developing this dataset,
sentiment analysis, hate speech detection, and anxiety or stress detection were
performed. This process included classifying each post into (i) one of the
sentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or
neutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no
anxiety/stress detected. These results are presented as separate attributes in
the dataset. Second, this paper presents the results of performing sentiment
analysis, hate speech analysis, and anxiety or stress analysis. The variation
of the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and
neutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and
50.64%, respectively. In terms of hate speech detection, 95.75% of the posts
did not contain hate and the remaining 4.25% of the posts contained hate.
Finally, 72.05% of the posts did not indicate any anxiety/stress, and the
remaining 27.95% of the posts represented some form of anxiety/stress.

摘要：世界目前正在经历猴痘疫情，世界卫生组织已宣布猴痘疫情为国际关注的突发公共卫生事件。此前没有与社交媒体挖掘相关的研究集中于开发有关猴痘疫情的 Instagram 帖子的数据集。本文介绍的研究旨在解决这一研究空白，并对该领域做出两项科学贡献。首先，它提供了 60,127 条有关猴痘的 Instagram 帖子的多语言数据集，这些帖子发布于 2022 年 7 月 23 日至 2024 年 9 月 5 日之间。该数据集可在 https://dx.doi.org/10.21227/7fvc-y093 处获得，其中包含 52 种语言的有关猴痘的 Instagram 帖子。对于其中每篇帖子，帖子 ID、帖子描述、发布日期、语言和帖子的翻译版本（使用 Google 翻译 API 翻译成英文）作为单独的属性显示在数据集中。在开发此数据集后，进行了情感分析、仇恨言论检测以及焦虑或压力检测。此过程包括将每篇帖子分类为 (i) 情感类别之一，即恐惧、惊讶、快乐、悲伤、愤怒、厌恶或中立，(ii) 仇恨或非仇恨，以及 (iii) 检测到焦虑/压力或未检测到焦虑/压力。这些结果作为单独的属性显示在数据集中。其次，本文介绍了执行情感分析、仇恨言论分析和焦虑或压力分析的结果。观察到情感类别的变化——恐惧、惊讶、快乐、悲伤、愤怒、厌恶和中立分别为 27.95%、2.57%、8.69%、5.94%、2.69%、1.53% 和 50.64%。在仇恨言论检测方面，95.75% 的帖子不包含仇恨，其余 4.25% 的帖子包含仇恨。最后，72.05% 的帖子没有表现出任何焦虑/压力，其余 27.95% 的帖子代表某种形式的焦虑/压力。

##### **RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation**
2409.05280v1 by Quoc-Bao Nguyen-Le, Tuan-Hy Le, Anh-Triet Do, Quoc-Huy Trinh

Cardiovascular disease is a major global health concern, contributing
significantly to global mortality. Accurately segmenting cardiac medical
imaging data is crucial for reducing fatality rates associated with these
conditions. However, current state-of-the-art (SOTA) neural networks, including
CNN-based and Transformer-based approaches, face challenges in capturing both
inter-slice connections and intra-slice details, especially in datasets
featuring intricate, long-range details along the z-axis like coronary
arteries. Existing methods also struggle with differentiating non-cardiac
components from the myocardium, resulting in segmentation inaccuracies and the
"spraying" phenomenon. To address these issues, we introduce
RotCAtt-TransUNet++, a novel architecture designed for robust segmentation of
intricate cardiac structures. Our approach enhances global context modeling
through multiscale feature aggregation and nested skip connections in the
encoder. Transformer layers facilitate capturing intra-slice interactions,
while a rotatory attention mechanism handles inter-slice connectivity. A
channel-wise cross-attention gate integrates multiscale information and decoder
features, effectively bridging semantic gaps. Experimental results across
multiple datasets demonstrate superior performance over current methods,
achieving near-perfect annotation of coronary arteries and myocardium. Ablation
studies confirm that our rotatory attention mechanism significantly improves
segmentation accuracy by transforming embedded vectorized patches in semantic
dimensional space.

摘要：心血管疾病是全球主要的健康問題，對全球死亡率有顯著的影響。準確分割心臟醫學影像資料對於降低這些疾病相關的死亡率至關重要。然而，目前的先進神經網路，包括基於 CNN 和基於 Transformer 的方法，在擷取層間連接和層內細節方面面臨挑戰，特別是在具有沿著 z 軸的複雜、長程細節的資料集，例如冠狀動脈。現有方法也難以區分非心臟成分和心肌，導致分割不準確和「噴灑」現象。為了解決這些問題，我們引入了 RotCAtt-TransUNet++，一種專為複雜心臟結構的穩健分割而設計的新穎架構。我們的做法透過編碼器中的多尺度特徵聚合和巢狀跳躍連接增強了全局背景建模。Transformer 層促進擷取層內交互作用，而旋轉注意機制則處理層間連接。通道式交叉注意閘門整合了多尺度資訊和解碼器特徵，有效地彌合了語義差距。跨多個資料集的實驗結果證明了其優於目前方法的效能，實現了冠狀動脈和心肌的近乎完美的註解。消融研究證實，我們的旋轉注意機制透過轉換語義維度空間中的嵌入向量化補丁，顯著地提高了分割準確度。

##### **Activation Function Optimization Scheme for Image Classification**
2409.04915v1 by Abdur Rahman, Lu He, Haifeng Wang

Activation function has a significant impact on the dynamics, convergence,
and performance of deep neural networks. The search for a consistent and
high-performing activation function has always been a pursuit during deep
learning model development. Existing state-of-the-art activation functions are
manually designed with human expertise except for Swish. Swish was developed
using a reinforcement learning-based search strategy. In this study, we propose
an evolutionary approach for optimizing activation functions specifically for
image classification tasks, aiming to discover functions that outperform
current state-of-the-art options. Through this optimization framework, we
obtain a series of high-performing activation functions denoted as Exponential
Error Linear Unit (EELU). The developed activation functions are evaluated for
image classification tasks from two perspectives: (1) five state-of-the-art
neural network architectures, such as ResNet50, AlexNet, VGG16, MobileNet, and
Compact Convolutional Transformer which cover computationally heavy to light
neural networks, and (2) eight standard datasets, including CIFAR10,
Imagenette, MNIST, Fashion MNIST, Beans, Colorectal Histology, CottonWeedID15,
and TinyImageNet which cover from typical machine vision benchmark,
agricultural image applications to medical image applications. Finally, we
statistically investigate the generalization of the resultant activation
functions developed through the optimization scheme. With a Friedman test, we
conclude that the optimization scheme is able to generate activation functions
that outperform the existing standard ones in 92.8% cases among 28 different
cases studied, and $-x\cdot erf(e^{-x})$ is found to be the best activation
function for image classification generated by the optimization scheme.

摘要：<paragraph>激活函數對深度神經網路的動態、收斂和效能有顯著的影響。在深度學習模型開發過程中，一直致力於尋找一致且效能高的激活函數。現有的最先進激活函數，除了 Swish 之外，都是由人類專家手動設計的。Swish 是使用基於強化學習的搜尋策略開發的。在本研究中，我們提出了一種演化方法，專門針對圖像分類任務最佳化激活函數，旨在發現效能優於現有最先進選項的函數。透過這個最佳化架構，我們獲得了一系列效能高的激活函數，表示為指數誤差線性單元 (EELU)。已針對兩個觀點評估已開發的激活函數，用於圖像分類任務：(1) 五種最先進的神經網路架構，例如 ResNet50、AlexNet、VGG16、MobileNet 和 Compact Convolutional Transformer，涵蓋從計算量重的到輕量的網路，(2) 八個標準資料集，包括 CIFAR10、Imagenette、MNIST、Fashion MNIST、Beans、Colorectal Histology、CottonWeedID15 和 TinyImageNet，涵蓋從典型的機器視覺基準、農業影像應用到醫學影像應用。最後，我們統計調查了透過最佳化方案開發的結果激活函數的概化。透過 Friedman 檢定，我們得出結論，最佳化方案能夠產生在 28 個不同的研究案例中，有 92.8% 的案例效能優於現有標準函數，並且發現 $-x\cdot erf(e^{-x})$ 是最佳化方案產生的最佳影像分類激活函數。</paragraph>

##### **LMGT: Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs**
2409.04744v1 by Yongxin Deng, Xihe Qiu, Xiaoyu Tan, Wei Chu, Yinghui Xu

The uncertainty inherent in the environmental transition model of
Reinforcement Learning (RL) necessitates a careful balance between exploration
and exploitation to optimize the use of computational resources for accurately
estimating an agent's expected reward. Achieving balance in control systems is
particularly challenging in scenarios with sparse rewards. However, given the
extensive prior knowledge available for many environments, it is redundant to
begin learning from scratch in such settings. To address this, we introduce
\textbf{L}anguage \textbf{M}odel \textbf{G}uided \textbf{T}rade-offs (i.e.,
\textbf{LMGT}), a novel, sample-efficient framework that leverages the
comprehensive prior knowledge embedded in Large Language Models (LLMs) and
their adeptness at processing non-standard data forms, such as wiki tutorials.
LMGT proficiently manages the exploration-exploitation trade-off by employing
reward shifts guided by LLMs, which direct agents' exploration endeavors,
thereby improving sample efficiency. We have thoroughly tested LMGT across
various RL tasks and deployed it in industrial-grade RL recommendation systems,
where it consistently outperforms baseline methods. The results indicate that
our framework can significantly reduce the time cost required during the
training phase in RL.

摘要：在強化學習（RL）的環境轉換模型中，固有的不確定性需要在探索和利用之間取得仔細的平衡，以最佳化計算資源的使用，以精準估計代理預期的獎勵。在控制系統中取得平衡在獎勵稀疏的情況下特別具有挑戰性。然而，由於許多環境都有廣泛的先驗知識，因此在這種設定中從頭開始學習是多餘的。為了解決這個問題，我們引入了**L**anguage **M**odel **G**uided **T**rade-offs（即**LMGT**），這是一個新穎且樣本效率高的架構，它利用了大型語言模型（LLM）中嵌入的全面先驗知識，以及它們處理非標準數據形式（例如 wiki 教程）的靈活性。LMGT 透過採用由 LLM 引導的獎勵轉移來熟練地管理探索-利用權衡，指導代理的探索工作，從而提高樣本效率。我們已經徹底測試了 LMGT 在各種 RL 任務中的表現，並將其部署在工業級 RL 推薦系統中，在這些系統中，它始終優於基線方法。結果表明，我們的架構可以顯著減少 RL 訓練階段所需的時間成本。

##### **NapTune: Efficient Model Tuning for Mood Classification using Previous Night's Sleep Measures along with Wearable Time-series**
2409.04723v1 by Debaditya Shome, Nasim Montazeri Ghahjaverestan, Ali Etemad

Sleep is known to be a key factor in emotional regulation and overall mental
health. In this study, we explore the integration of sleep measures from the
previous night into wearable-based mood recognition. To this end, we propose
NapTune, a novel prompt-tuning framework that utilizes sleep-related measures
as additional inputs to a frozen pre-trained wearable time-series encoder by
adding and training lightweight prompt parameters to each Transformer layer.
Through rigorous empirical evaluation, we demonstrate that the inclusion of
sleep data using NapTune not only improves mood recognition performance across
different wearable time-series namely ECG, PPG, and EDA, but also makes it more
sample-efficient. Our method demonstrates significant improvements over the
best baselines and unimodal variants. Furthermore, we analyze the impact of
adding sleep-related measures on recognizing different moods as well as the
influence of individual sleep-related measures.

摘要：睡眠已知是情緒調節和整體心理健康中的關鍵因素。在本研究中，我們探討將前一晚的睡眠測量整合到可穿戴式情緒辨識中。為此，我們提出了 NapTune，這是一個新穎的提示調整框架，它利用與睡眠相關的測量作為凍結預訓練可穿戴時間序列編碼器的附加輸入，方法是將輕量級提示參數新增並訓練到每個 Transformer 層。透過嚴謹的經驗評估，我們證明使用 NapTune 納入睡眠數據不僅改善了不同可穿戴時間序列（即心電圖、光電容積描記和皮電活動）的情緒辨識效能，還讓它更具樣本效率。我們的模型證明了相較於最佳基線和單模態變異，有顯著的改善。此外，我們分析了新增與睡眠相關的測量對辨識不同情緒的影響，以及個別與睡眠相關的測量的影響。

##### **A Comprehensive Survey on Evidential Deep Learning and Its Applications**
2409.04720v1 by Junyu Gao, Mengyuan Chen, Liangyu Xiang, Changsheng Xu

Reliable uncertainty estimation has become a crucial requirement for the
industrial deployment of deep learning algorithms, particularly in high-risk
applications such as autonomous driving and medical diagnosis. However,
mainstream uncertainty estimation methods, based on deep ensembling or Bayesian
neural networks, generally impose substantial computational overhead. To
address this challenge, a novel paradigm called Evidential Deep Learning (EDL)
has emerged, providing reliable uncertainty estimation with minimal additional
computation in a single forward pass. This survey provides a comprehensive
overview of the current research on EDL, designed to offer readers a broad
introduction to the field without assuming prior knowledge. Specifically, we
first delve into the theoretical foundation of EDL, the subjective logic
theory, and discuss its distinctions from other uncertainty estimation
frameworks. We further present existing theoretical advancements in EDL from
four perspectives: reformulating the evidence collection process, improving
uncertainty estimation via OOD samples, delving into various training
strategies, and evidential regression networks. Thereafter, we elaborate on its
extensive applications across various machine learning paradigms and downstream
tasks. In the end, an outlook on future directions for better performances and
broader adoption of EDL is provided, highlighting potential research avenues.

摘要：可靠的不確定性估計已成為深度學習演算法產業部署的關鍵需求，特別是在高風險應用中，例如自動駕駛和醫療診斷。然而，基於深度集成或貝氏神經網路的主流不確定性估計方法通常會造成大量的計算負擔。為了應對這項挑戰，一種稱為證據深度學習 (EDL) 的新範例應運而生，它在單次前向傳遞中以最少的額外運算提供可靠的不確定性估計。這項調查對 EDL 的現有研究提供全面的概述，旨在為讀者提供該領域的廣泛介紹，而無需假設先備知識。具體來說，我們首先深入探討 EDL 的理論基礎，即主觀邏輯理論，並討論其與其他不確定性估計架構的區別。我們進一步從四個角度介紹 EDL 中現有的理論進展：重新制定證據收集過程、透過 OOD 樣本改善不確定性估計、深入探討各種訓練策略以及證據回歸網路。此後，我們詳細說明它在各種機器學習範例和下游任務中的廣泛應用。最後，我們提供了對未來方向的展望，以期獲得更好的效能和更廣泛地採用 EDL，並重點介紹潛在的研究途徑。

##### **A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting**
2409.04704v1 by Cheng Wan, Chenjie Xie, Longfei Liu, Dan Wu, Ye Li

Continuous blood pressure (BP) monitoring is essential for timely diagnosis
and intervention in critical care settings. However, BP varies significantly
across individuals, this inter-patient variability motivates the development of
personalized models tailored to each patient's physiology. In this work, we
propose a personalized BP forecasting model mainly using electrocardiogram
(ECG) and photoplethysmogram (PPG) signals. This time-series model incorporates
2D representation learning to capture complex physiological relationships.
Experiments are conducted on datasets collected from three diverse scenarios
with BP measurements from 60 subjects total. Results demonstrate that the model
achieves accurate and robust BP forecasts across scenarios within the
Association for the Advancement of Medical Instrumentation (AAMI) standard
criteria. This reliable early detection of abnormal fluctuations in BP is
crucial for at-risk patients undergoing surgery or intensive care. The proposed
model provides a valuable addition for continuous BP tracking to reduce
mortality and improve prognosis.

摘要：持續的血壓 (BP) 監控對於重症監護環境中的及時診斷和干預至關重要。然而，BP 因人而異，這種患者間變異性促使開發針對每位患者生理狀況量身打造的個人化模型。在這項工作中，我們提出了一種個人化 BP 預測模型，主要使用心電圖 (ECG) 和光電容積描記法 (PPG) 信號。此時間序列模型結合了 2D 表徵學習以捕捉複雜的生理關係。實驗是在從三種不同情境收集的資料集上進行，總共來自 60 位受試者的 BP 測量。結果表明，該模型在醫學儀器促進協會 (AAMI) 標準標準內實現了跨情境的準確且穩健的 BP 預測。對於接受手術或重症監護的高風險患者而言，這種對 BP 異常波動的可靠早期檢測至關重要。所提出的模型為持續 BP 追蹤提供了有價值的補充，以降低死亡率並改善預後。

##### **The Impact of Scanner Domain Shift on Deep Learning Performance in Medical Imaging: an Experimental Study**
2409.04368v1 by Gregory Szumel, Brian Guo, Darui Lu, Rongze Gui, Tingyu Wang, Nicholas Konz, Maciej A. Mazurowski

Purpose: Medical images acquired using different scanners and protocols can
differ substantially in their appearance. This phenomenon, scanner domain
shift, can result in a drop in the performance of deep neural networks which
are trained on data acquired by one scanner and tested on another. This
significant practical issue is well-acknowledged, however, no systematic study
of the issue is available across different modalities and diagnostic tasks.
Materials and Methods: In this paper, we present a broad experimental study
evaluating the impact of scanner domain shift on convolutional neural network
performance for different automated diagnostic tasks. We evaluate this
phenomenon in common radiological modalities, including X-ray, CT, and MRI.
Results: We find that network performance on data from a different scanner is
almost always worse than on same-scanner data, and we quantify the degree of
performance drop across different datasets. Notably, we find that this drop is
most severe for MRI, moderate for X-ray, and quite small for CT, on average,
which we attribute to the standardized nature of CT acquisition systems which
is not present in MRI or X-ray. We also study how injecting varying amounts of
target domain data into the training set, as well as adding noise to the
training data, helps with generalization. Conclusion: Our results provide
extensive experimental evidence and quantification of the extent of performance
drop caused by scanner domain shift in deep learning across different
modalities, with the goal of guiding the future development of robust deep
learning models for medical image analysis.

摘要：<paragraph>目的：使用不同掃描儀和協定取得的醫學影像，在影像外觀上可能會有顯著差異。這種現象稱為掃描儀領域偏移，可能會導致深度神經網路的效能下降，而這些網路是針對由一種掃描儀取得的資料進行訓練，並在另一種掃描儀上進行測試。這個重要的實際問題已獲得廣泛認可，但目前尚未針對不同形式和診斷任務進行系統性研究。材料和方法：在本文中，我們提出了一項廣泛的實驗研究，評估掃描儀領域偏移對不同自動化診斷任務的卷積神經網路效能的影響。我們在常見的放射學形式中評估這種現象，包括 X 光、電腦斷層掃描和磁振造影。結果：我們發現，來自不同掃描儀的資料在網路上的效能幾乎總是比來自相同掃描儀的資料差，我們量化了不同資料集效能下降的程度。值得注意的是，我們發現這種下降在磁振造影中最为嚴重，在 X 光中為中等，在電腦斷層掃描中相當小，平均而言，我們將其歸因於電腦斷層掃描取得系統的標準化性質，而磁振造影或 X 光中不存在這種性質。我們還研究了將不同數量的目標領域資料注入訓練集，以及向訓練資料加入雜訊，如何有助於泛化。結論：我們的結果提供了廣泛的實驗證據，並量化了深度學習中由掃描儀領域偏移造成的效能下降程度，目標是引導未來針對醫學影像分析的強健深度學習模型的發展。</paragraph>

##### **CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis**
2409.04290v1 by William Knottenbelt, Zeyu Gao, Rebecca Wray, Woody Zhidong Zhang, Jiashuai Liu, Mireia Crispin-Ortuzar

Survival analysis is a branch of statistics used for modeling the time until
a specific event occurs and is widely used in medicine, engineering, finance,
and many other fields. When choosing survival models, there is typically a
trade-off between performance and interpretability, where the highest
performance is achieved by black-box models based on deep learning. This is a
major problem in fields such as medicine where practitioners are reluctant to
blindly trust black-box models to make important patient decisions.
Kolmogorov-Arnold Networks (KANs) were recently proposed as an interpretable
and accurate alternative to multi-layer perceptrons (MLPs). We introduce
CoxKAN, a Cox proportional hazards Kolmogorov-Arnold Network for interpretable,
high-performance survival analysis. We evaluate the proposed CoxKAN on 4
synthetic datasets and 9 real medical datasets. The synthetic experiments
demonstrate that CoxKAN accurately recovers interpretable symbolic formulae for
the hazard function, and effectively performs automatic feature selection.
Evaluation on the 9 real datasets show that CoxKAN consistently outperforms the
Cox proportional hazards model and achieves performance that is superior or
comparable to that of tuned MLPs. Furthermore, we find that CoxKAN identifies
complex interactions between predictor variables that would be extremely
difficult to recognise using existing survival methods, and automatically finds
symbolic formulae which uncover the precise effect of important biomarkers on
patient risk.

摘要：生存分析是統計學的一個分支，用於建模特定事件發生的時間，並廣泛用於醫學、工程、金融和許多其他領域。在選擇生存模型時，通常在性能和可解釋性之間進行權衡，其中最高性能是由基於深度學習的黑盒模型實現的。這在醫學等領域是一個主要問題，因為從業者不願意盲目信任黑盒模型來做出重要的患者決策。Kolmogorov-阿諾德網絡 (KAN) 最近被提議作為多層感知器 (MLP) 的可解釋且準確的替代方案。我們引入了 CoxKAN，這是一個用於可解釋、高性能生存分析的 Cox 比例風險 Kolmogorov-Arnold 網絡。我們在 4 個合成數據集和 9 個真實醫療數據集上評估了所提出的 CoxKAN。合成實驗表明，CoxKAN 準確地恢復了風險函數的可解釋符號公式，並有效地執行自動特徵選擇。對 9 個真實數據集的評估表明，CoxKAN 始終優於 Cox 比例風險模型，並且達到了優於或與調整後的 MLP 相當的性能。此外，我們發現 CoxKAN 識別了預測變量之間的複雜交互作用，這些交互作用使用現有的生存方法極難識別，並自動找到揭示重要生物標誌物對患者風險的準確影響的符號公式。

##### **Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework**
2409.04224v1 by Daniel J. Tan, Qianyi Xu, Kay Choong See, Dilruk Perera, Mengling Feng

Multi-organ diseases present significant challenges due to their simultaneous
impact on multiple organ systems, necessitating complex and adaptive treatment
strategies. Despite recent advancements in AI-powered healthcare decision
support systems, existing solutions are limited to individual organ systems.
They often ignore the intricate dependencies between organ system and thereby
fails to provide holistic treatment recommendations that are useful in
practice. We propose a novel hierarchical multi-agent reinforcement learning
(HMARL) framework to address these challenges. This framework uses dedicated
agents for each organ system, and model dynamic through explicit inter-agent
communication channels, enabling coordinated treatment strategies across
organs. Furthermore, we introduce a dual-layer state representation technique
to contextualize patient conditions at various hierarchical levels, enhancing
the treatment accuracy and relevance. Through extensive qualitative and
quantitative evaluations in managing sepsis (a complex multi-organ disease),
our approach demonstrates its ability to learn effective treatment policies
that significantly improve patient survival rates. This framework marks a
substantial advancement in clinical decision support systems, pioneering a
comprehensive approach for multi-organ treatment recommendations.

摘要：多器官疾病由於同時影響多個器官系統，因此會帶來重大的挑戰，需要複雜且具有適應性的治療策略。儘管 AI 驅動的醫療保健決策支援系統最近有進展，但現有解決方案僅限於個別器官系統。它們常常忽略器官系統之間的複雜依賴性，因此無法提供實務上有用的整體治療建議。我們提出一個新穎的分層多智能體強化學習 (HMARL) 架構來解決這些挑戰。此架構為每個器官系統使用專用智能體，並透過明確的智能體間通訊管道建模動態，讓不同器官之間的治療策略能夠協調。此外，我們引入雙層狀態表示技術，在各種層級語境化病患狀況，以提升治療準確性和相關性。透過在敗血症（一種複雜的多器官疾病）管理中進行廣泛的定性和定量評估，我們的做法展示了它學習有效治療政策的能力，可顯著改善病患存活率。此架構標誌著臨床決策支援系統的一大進步，開創了多器官治療建議的全面性方法。

##### **Large Language Models in Drug Discovery and Development: From Disease Mechanisms to Clinical Trials**
2409.04481v1 by Yizhen Zheng, Huan Yee Koh, Maddie Yang, Li Li, Lauren T. May, Geoffrey I. Webb, Shirui Pan, George Church

The integration of Large Language Models (LLMs) into the drug discovery and
development field marks a significant paradigm shift, offering novel
methodologies for understanding disease mechanisms, facilitating drug
discovery, and optimizing clinical trial processes. This review highlights the
expanding role of LLMs in revolutionizing various stages of the drug
development pipeline. We investigate how these advanced computational models
can uncover target-disease linkage, interpret complex biomedical data, enhance
drug molecule design, predict drug efficacy and safety profiles, and facilitate
clinical trial processes. Our paper aims to provide a comprehensive overview
for researchers and practitioners in computational biology, pharmacology, and
AI4Science by offering insights into the potential transformative impact of
LLMs on drug discovery and development.

摘要：大型語言模型（LLM）整合到藥物發現和開發領域標誌著重大的典範轉移，提供了解疾病機制、促進藥物發現和優化臨床試驗流程的新方法。本綜述重點介紹了 LLM 在革新藥物開發管線各個階段中日益重要的作用。我們探討了這些先進的計算模型如何揭示靶點疾病關聯性、解釋複雜的生物醫學數據、增強藥物分子設計、預測藥物療效和安全性，以及促進臨床試驗流程。我們的論文旨在為計算生物學、藥理學和 AI4Science 的研究人員和從業者提供全面的概述，深入了解 LLM 對藥物發現和開發的潛在變革性影響。

##### **FODA-PG for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes**
2409.03947v1 by Kai Shu, Yuzhuo Jia, Ziyang Zhang, Jiechao Gao

Automatic Medical Imaging Narrative generation aims to alleviate the workload
of radiologists by producing accurate clinical descriptions directly from
radiological images. However, the subtle visual nuances and domain-specific
terminology in medical images pose significant challenges compared to generic
image captioning tasks. Existing approaches often neglect the vital distinction
between normal and abnormal findings, leading to suboptimal performance. In
this work, we propose FODA-PG, a novel Fine-grained Organ-Disease Adaptive
Partitioning Graph framework that addresses these limitations through
domain-adaptive learning. FODA-PG constructs a granular graphical
representation of radiological findings by separating disease-related
attributes into distinct "disease-specific" and "disease-free" categories based
on their clinical significance and location. This adaptive partitioning enables
our model to capture the nuanced differences between normal and pathological
states, mitigating the impact of data biases. By integrating this fine-grained
semantic knowledge into a powerful transformer-based architecture and providing
rigorous mathematical justifications for its effectiveness, FODA-PG generates
precise and clinically coherent reports with enhanced generalization
capabilities. Extensive experiments on the IU-Xray and MIMIC-CXR benchmarks
demonstrate the superiority of our approach over state-of-the-art methods,
highlighting the importance of domain adaptation in medical report generation.

摘要：自動醫學影像敘述生成旨在透過直接從放射影像產生精確的臨床描述，減輕放射科醫師的工作負擔。然而，與一般影像標題任務相比，醫學影像中的細微視覺差異和特定領域術語會帶來重大挑戰。現有方法常常忽略正常與異常發現之間的重要區別，導致次佳效能。在這項工作中，我們提出 FODA-PG，這是一個新穎的細粒度器官疾病自適應分割圖形架構，透過領域自適應學習來解決這些限制。FODA-PG 透過將疾病相關屬性依據其臨床重要性和位置分為不同的「特定疾病」和「無疾病」類別，來建構放射學發現的細粒度圖形表示。這種自適應分割使我們的模型能夠捕捉正常與病理狀態之間的細微差異，減輕資料偏差的影響。透過將這種細粒度語義知識整合到強大的基於轉換器的架構中，並提供其有效性的嚴謹數學證明，FODA-PG 能夠生成精確且臨床上連貫的報告，並具備增強的概括能力。在 IU-Xray 和 MIMIC-CXR 基準上的廣泛實驗證明了我們的方法優於最先進的方法，突顯了領域適應在醫學報告生成中的重要性。

##### **A deep learning approach to wall-shear stress quantification: From numerical training to zero-shot experimental application**
2409.03933v1 by Esther Lagemann, Julia Roeb, Steven L. Brunton, Christian Lagemann

The accurate quantification of wall-shear stress dynamics is of substantial
importance for various applications in fundamental and applied research,
spanning areas from human health to aircraft design and optimization. Despite
significant progress in experimental measurement techniques and post-processing
algorithms, temporally resolved wall-shear stress dynamics with adequate
spatial resolution and within a suitable spatial domain remain an elusive goal.
To address this gap, we introduce a deep learning architecture that ingests
wall-parallel velocity fields from the logarithmic layer of turbulent
wall-bounded flows and outputs the corresponding 2D wall-shear stress fields
with identical spatial resolution and domain size. From a physical perspective,
our framework acts as a surrogate model encapsulating the various mechanisms
through which highly energetic outer-layer flow structures influence the
governing wall-shear stress dynamics. The network is trained in a supervised
fashion on a unified dataset comprising direct numerical simulations of
statistically 1D turbulent channel and spatially developing turbulent boundary
layer flows at friction Reynolds numbers ranging from 390 to 1,500. We
demonstrate a zero-shot applicability to experimental velocity fields obtained
from Particle-Image Velocimetry measurements and verify the physical accuracy
of the wall-shear stress estimates with synchronized wall-shear stress
measurements using the Micro-Pillar Shear-Stress Sensor for Reynolds numbers up
to 2,000. In summary, the presented framework lays the groundwork for
extracting inaccessible experimental wall-shear stress information from readily
available velocity measurements and thus, facilitates advancements in a variety
of experimental applications.

摘要：<paragraph>準確量化壁面剪應力動態對於基礎和應用研究中的各種應用具有實質性的重要性，涵蓋從人類健康到飛機設計和優化的領域。儘管在實驗測量技術和後處理演算法方面取得了顯著進展，但時間解析壁面剪應力動態仍具有足夠的空間解析度和在合適的空間域中仍然是一個難以捉摸的目標。為了解決這個差距，我們引入了一個深度學習架構，它從湍流壁面約束流的對數層中攝取壁面平行速度場，並輸出相應的 2D 壁面剪應力場，具有相同的空間解析度和域大小。從物理角度來看，我們的框架充當一個代理模型，概括了高能量外層流結構影響控制壁面剪應力動態的各種機制。該網路以監督方式在一個統一的數據集上進行訓練，該數據集包含統計 1D 湍流通道的直接數值模擬和空間發展的湍流邊界層流，摩擦雷諾數範圍從 390 到 1,500。我們展示了對從粒子影像測速測量中獲得的實驗速度場的零次應用，並使用微柱剪應力感測器對雷諾數最高 2,000 的同步壁面剪應力測量驗證了壁面剪應力估計的物理準確性。總之，所提出的框架為從容易獲得的速度測量中提取無法獲得的實驗壁面剪應力資訊奠定了基礎，從而促進了各種實驗應用中的進展。</paragraph>

##### **Multimodal Laryngoscopic Video Analysis for Assisted Diagnosis of Vocal Cord Paralysis**
2409.03597v1 by Yucong Zhang, Xin Zou, Jinshan Yang, Wenjun Chen, Faya Liang, Ming Li

This paper presents the Multimodal Analyzing System for Laryngoscope (MASL),
a system that combines audio and video data to automatically extract key
segments and metrics from laryngeal videostroboscopic videos for clinical
assessment. MASL integrates glottis detection with keyword spotting to analyze
patient vocalizations and refine video highlights for better inspection of
vocal cord movements. The system includes a strobing video extraction module
that identifies frames by analyzing hue, saturation, and value fluctuations.
MASL also provides effective metrics for vocal cord paralysis detection,
employing a two-stage glottis segmentation process using U-Net followed by
diffusion-based refinement to reduce false positives. Instead of glottal area
waveforms, MASL estimates anterior glottic angle waveforms (AGAW) from glottis
masks, evaluating both left and right vocal cords to detect unilateral vocal
cord paralysis (UVFP). By comparing AGAW variances, MASL distinguishes between
left and right paralysis. Ablation studies and experiments on public and
real-world datasets validate MASL's segmentation module and demonstrate its
ability to provide reliable metrics for UVFP diagnosis.

摘要：本文提出了喉镜多模态分析系统 (MASL)，
该系统结合音频和视频数据，自动从喉部视频频闪镜视频中提取关键
片段和指标，用于临床评估。MASL 将声门检测与关键词识别相结合，以分析
患者发声并细化视频重点，以便更好地检查声带运动。该系统包括一个频闪视频提取模块，
该模块通过分析色相、饱和度和值波动来识别帧。
MASL 还为声带麻痹检测提供了有效的指标，
采用两阶段声门分割过程，使用 U-Net，然后进行基于扩散的细化以减少误报。MASL 不使用声门面积波形，而是从声门掩模中估计前声门角波形 (AGAW)，评估左右声带以检测单侧声带麻痹 (UVFP)。通过比较 AGAW 方差，MASL 区分左右麻痹。消融研究和对公共和真实世界数据集的实验验证了 MASL 的分割模块，并证明了其提供可靠的 UVFP 诊断指标的能力。

##### **Improving Uncertainty-Error Correspondence in Deep Bayesian Medical Image Segmentation**
2409.03470v1 by Prerak Mody, Nicolas F. Chaves-de-Plaza, Chinmay Rao, Eleftheria Astrenidou, Mischa de Ridder, Nienke Hoekstra, Klaus Hildebrandt, Marius Staring

Increased usage of automated tools like deep learning in medical image
segmentation has alleviated the bottleneck of manual contouring. This has
shifted manual labour to quality assessment (QA) of automated contours which
involves detecting errors and correcting them. A potential solution to
semi-automated QA is to use deep Bayesian uncertainty to recommend potentially
erroneous regions, thus reducing time spent on error detection. Previous work
has investigated the correspondence between uncertainty and error, however, no
work has been done on improving the "utility" of Bayesian uncertainty maps such
that it is only present in inaccurate regions and not in the accurate ones. Our
work trains the FlipOut model with the Accuracy-vs-Uncertainty (AvU) loss which
promotes uncertainty to be present only in inaccurate regions. We apply this
method on datasets of two radiotherapy body sites, c.f. head-and-neck CT and
prostate MR scans. Uncertainty heatmaps (i.e. predictive entropy) are evaluated
against voxel inaccuracies using Receiver Operating Characteristic (ROC) and
Precision-Recall (PR) curves. Numerical results show that when compared to the
Bayesian baseline the proposed method successfully suppresses uncertainty for
accurate voxels, with similar presence of uncertainty for inaccurate voxels.
Code to reproduce experiments is available at
https://github.com/prerakmody/bayesuncertainty-error-correspondence

摘要：深度學習等自動化工具在醫學影像分割中使用率提升，減輕了手動輪廓描繪的瓶頸。這已將手動勞動轉移到自動輪廓的品質評估 (QA)，其中包含偵測錯誤並修正它們。半自動化 QA 的潛在解決方案是使用深度貝氏不確定性來建議潛在的錯誤區域，從而減少花費在錯誤偵測上的時間。先前的研究已調查不確定性和錯誤之間的對應關係，然而，尚未對改善貝氏不確定性地圖的「效用」進行研究，以使其僅出現在不準確區域，而不出現在準確區域。我們的研究使用準確度對抗不確定性 (AvU) 損失來訓練 FlipOut 模型，這會促使不確定性僅出現在不準確區域。我們將此方法應用於兩個放射治療部位的資料集，即頭頸部電腦斷層掃描和前列腺核磁共振掃描。使用接收器操作特性 (ROC) 和精確度召回率 (PR) 曲線，針對體素不準確性評估不確定性熱圖（即預測熵）。數值結果顯示，與貝氏基準相比，所提出的方法成功地抑制準確體素的不確定性，對於不準確體素的不確定性存在類似情況。可在 https://github.com/prerakmody/bayesuncertainty-error-correspondence 取得重現實驗的程式碼

##### **Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time**
2409.03375v1 by Francisco de Arriba-Pérez, Silvia García-Méndez

Based on official estimates, 50 million people worldwide are affected by
dementia, and this number increases by 10 million new patients every year.
Without a cure, clinical prognostication and early intervention represent the
most effective ways to delay its progression. To this end, Artificial
Intelligence and computational linguistics can be exploited for natural
language analysis, personalized assessment, monitoring, and treatment. However,
traditional approaches need more semantic knowledge management and
explicability capabilities. Moreover, using Large Language Models (LLMs) for
cognitive decline diagnosis is still scarce, even though these models represent
the most advanced way for clinical-patient communication using intelligent
systems. Consequently, we leverage an LLM using the latest Natural Language
Processing (NLP) techniques in a chatbot solution to provide interpretable
Machine Learning prediction of cognitive decline in real-time.
Linguistic-conceptual features are exploited for appropriate natural language
analysis. Through explainability, we aim to fight potential biases of the
models and improve their potential to help clinical workers in their diagnosis
decisions. More in detail, the proposed pipeline is composed of (i) data
extraction employing NLP-based prompt engineering; (ii) stream-based data
processing including feature engineering, analysis, and selection; (iii)
real-time classification; and (iv) the explainability dashboard to provide
visual and natural language descriptions of the prediction outcome.
Classification results exceed 80 % in all evaluation metrics, with a recall
value for the mental deterioration class about 85 %. To sum up, we contribute
with an affordable, flexible, non-invasive, personalized diagnostic system to
this work.

摘要：<paragraph>根據官方的估計，全球約有 5000 萬人罹患失智症，且這個數字每年增加 1000 萬名新患者。在沒有治癒方法的情況下，臨床預後和早期介入是延緩其惡化的最有效方法。為此，人工智慧和計算語言學可被用於自然語言分析、個人化評估、監控和治療。然而，傳統方法需要更多語義知識管理和可解釋性能力。此外，儘管這些模型代表了使用智慧系統進行臨床患者溝通的最先進方式，但將大型語言模型 (LLM) 用於認知能力下降診斷仍然很少見。因此，我們利用聊天機器人解決方案中使用最新自然語言處理 (NLP) 技術的 LLM，以提供對認知能力下降的機器學習預測。語言概念特徵被用於適當的自然語言分析。透過可解釋性，我們旨在消除模型的潛在偏差，並提高其在診斷決策中協助臨床工作者的潛力。更詳細地說，所提出的管道包括：(i) 使用基於 NLP 的提示工程進行資料萃取；(ii) 串流式資料處理，包括特徵工程、分析和選擇；(iii) 即時分類；以及 (iv) 可解釋性儀表板，以提供預測結果的可視化和自然語言描述。分類結果在所有評估指標中都超過 80%，心智退化類別的召回率約為 85%。總而言之，我們為這項工作貢獻了一個經濟實惠、靈活、非侵入性、個人化的診斷系統。</paragraph>

##### **Addressing the Gaps in Early Dementia Detection: A Path Towards Enhanced Diagnostic Models through Machine Learning**
2409.03147v1 by Juan A. Berrios Moya

The rapid global aging trend has led to an increase in dementia cases,
including Alzheimer's disease, underscoring the urgent need for early and
accurate diagnostic methods. Traditional diagnostic techniques, such as
cognitive tests, neuroimaging, and biomarker analysis, face significant
limitations in sensitivity, accessibility, and cost, particularly in the early
stages. This study explores the potential of machine learning (ML) as a
transformative approach to enhance early dementia detection by leveraging ML
models to analyze and integrate complex multimodal datasets, including
cognitive assessments, neuroimaging, and genetic information. A comprehensive
review of existing literature was conducted to evaluate various ML models,
including supervised learning, deep learning, and advanced techniques such as
ensemble learning and transformer models, assessing their accuracy,
interpretability, and potential for clinical integration. The findings indicate
that while ML models show significant promise in improving diagnostic precision
and enabling earlier interventions, challenges remain in their
generalizability, interpretability, and ethical deployment. This research
concludes by outlining future directions aimed at enhancing the clinical
utility of ML models in dementia detection, emphasizing interdisciplinary
collaboration and ethically sound frameworks to improve early detection and
intervention strategies for Alzheimer's disease and other forms of dementia.

摘要：全球人口快速老化趨勢導致失智症病例增加，包括阿茲海默症，突顯出早期且準確的診斷方法的迫切需求。傳統的診斷技術，例如認知測驗、神經影像和生物標記分析，在敏感性、可及性和成本方面面臨重大限制，特別是在早期階段。本研究探討機器學習 (ML) 作為一種變革性方法的潛力，通過利用 ML 模型分析和整合複雜的多模式數據集，包括認知評估、神經影像和遺傳信息，來增強早期失智症檢測。對現有文獻進行了全面回顧，以評估各種 ML 模型，包括監督學習、深度學習和先進技術，例如集成學習和Transformer模型，評估其準確性、可解釋性和臨床整合的潛力。研究結果表明，儘管 ML 模型在提高診斷精度和實現早期干預方面顯示出顯著的希望，但其可概化性、可解釋性和道德部署仍然存在挑戰。本研究最後概述了旨在增強 ML 模型在失智症檢測中的臨床效用的未來方向，強調跨學科合作和道德健全的框架，以改善阿茲海默症和其他形式失智症的早期檢測和干預策略。

##### **MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation**
2409.03062v1 by Shehan Perera, Yunus Erzurumlu, Deepak Gulati, Alper Yilmaz

Skin cancer segmentation poses a significant challenge in medical image
analysis. Numerous existing solutions, predominantly CNN-based, face issues
related to a lack of global contextual understanding. Alternatively, some
approaches resort to large-scale Transformer models to bridge the global
contextual gaps, but at the expense of model size and computational complexity.
Finally many Transformer based approaches rely primarily on CNN based decoders
overlooking the benefits of Transformer based decoding models. Recognizing
these limitations, we address the need efficient lightweight solutions by
introducing MobileUNETR, which aims to overcome the performance constraints
associated with both CNNs and Transformers while minimizing model size,
presenting a promising stride towards efficient image segmentation. MobileUNETR
has 3 main features. 1) MobileUNETR comprises of a lightweight hybrid
CNN-Transformer encoder to help balance local and global contextual feature
extraction in an efficient manner; 2) A novel hybrid decoder that
simultaneously utilizes low-level and global features at different resolutions
within the decoding stage for accurate mask generation; 3) surpassing large and
complex architectures, MobileUNETR achieves superior performance with 3 million
parameters and a computational complexity of 1.3 GFLOP resulting in 10x and 23x
reduction in parameters and FLOPS, respectively. Extensive experiments have
been conducted to validate the effectiveness of our proposed method on four
publicly available skin lesion segmentation datasets, including ISIC 2016, ISIC
2017, ISIC 2018, and PH2 datasets. The code will be publicly available at:
https://github.com/OSUPCVLab/MobileUNETR.git

摘要：皮膚癌分割在醫學影像分析中構成一項重大挑戰。現有許多解決方案（主要是基於 CNN）面臨缺乏整體背景理解的問題。或者，一些方法訴諸於大規模 Transformer 模型來彌合整體背景差距，但犧牲了模型大小和計算複雜度。最後，許多基於 Transformer 的方法主要依賴於基於 CNN 的解碼器，而忽視了基於 Transformer 的解碼模型的優點。認識到這些限制，我們通過引入 MobileUNETR 來解決對高效輕量級解決方案的需求，其目標是克服與 CNN 和 Transformer 相關的效能限制，同時最小化模型大小，為高效影像分割邁出有希望的一步。MobileUNETR 有 3 個主要特點。1) MobileUNETR 包含一個輕量級混合 CNN-Transformer 編碼器，以有效的方式幫助平衡局部和整體背景特徵提取；2) 一個新穎的混合解碼器，在解碼階段同時利用不同解析度下的低階和整體特徵，以進行精確的遮罩生成；3) 超越大型而複雜的架構，MobileUNETR 以 300 萬個參數和 1.3 GFLOP 的計算複雜度實現了卓越的效能，分別減少了 10 倍和 23 倍的參數和 FLOP。已經進行了廣泛的實驗，以驗證我們提出的方法在四個公開可用的皮膚病變分割資料集（包括 ISIC 2016、ISIC 2017、ISIC 2018 和 PH2 資料集）上的有效性。程式碼將公開於：https://github.com/OSUPCVLab/MobileUNETR.git

##### **Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test**
2409.02883v1 by Junyoung Park, Eun Hyun Seo, Sunjun Kim, SangHak Yi, Kun Ho Lee, Sungho Won

Drawing tests like the Rey Complex Figure Test (RCFT) are widely used to
assess cognitive functions such as visuospatial skills and memory, making them
valuable tools for detecting mild cognitive impairment (MCI). Despite their
utility, existing predictive models based on these tests often suffer from
limitations like small sample sizes and lack of external validation, which
undermine their reliability. We developed a multi-stream deep learning
framework that integrates two distinct processing streams: a multi-head
self-attention based spatial stream using raw RCFT images and a scoring stream
employing a previously developed automated scoring system. Our model was
trained on data from 1,740 subjects in the Korean cohort and validated on an
external hospital dataset of 222 subjects from Korea. The proposed multi-stream
model demonstrated superior performance over baseline models (AUC = 0.872,
Accuracy = 0.781) in external validation. The integration of both spatial and
scoring streams enables the model to capture intricate visual details from the
raw images while also incorporating structured scoring data, which together
enhance its ability to detect subtle cognitive impairments. This dual approach
not only improves predictive accuracy but also increases the robustness of the
model, making it more reliable in diverse clinical settings. Our model has
practical implications for clinical settings, where it could serve as a
cost-effective tool for early MCI screening.

摘要：雷氏複雜圖形測驗 (RCFT) 等繪畫測驗廣泛用於評估視覺空間技能和記憶力等認知功能，使其成為檢測輕度認知障礙 (MCI) 的寶貴工具。儘管它們很有用，但基於這些測驗的現有預測模型通常會受到樣本量小和缺乏外部驗證等限制，這會損害其可靠性。我們開發了一個多串流深度學習框架，它整合了兩個不同的處理串流：一個基於多頭自注意力，使用原始 RCFT 影像的空間串流，以及一個採用先前開發的自動評分系統的評分串流。我們的模型在韓國群組中 1,740 名受試者的資料上進行訓練，並在來自韓國的 222 名受試者的外部醫院資料集上進行驗證。所提出的多串流模型在外部驗證中表現出優於基準模型的效能 (AUC = 0.872，準確率 = 0.781)。空間和評分串流的整合使模型能夠從原始影像擷取複雜的視覺細節，同時也能納入結構化的評分資料，這共同增強了它檢測細微認知障礙的能力。這種雙重方法不僅提高了預測準確性，也增加了模型的穩健性，使其在不同的臨床環境中更可靠。我們的模型對臨床環境有實際的意義，它可以在其中作為早期 MCI 篩檢的具成本效益的工具。

##### **Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon**
2409.02681v1 by Ramon Tavares

This study presents a comprehensive methodology for modeling and forecasting
the historical time series of fire spots detected by the AQUA_M-T satellite in
the Amazon, Brazil. The approach utilizes a mixed Recurrent Neural Network
(RNN) model, combining Long Short-Term Memory (LSTM) and Gated Recurrent Unit
(GRU) architectures to predict monthly accumulations of daily detected fire
spots. A summary of the data revealed a consistent seasonality over time, with
annual maximum and minimum fire spot values tending to repeat at the same
periods each year. The primary objective is to verify whether the forecasts
capture this inherent seasonality through rigorous statistical analysis. The
methodology involved careful data preparation, model configuration, and
training using cross-validation with two seeds, ensuring that the data
generalizes well to the test and validation sets, and confirming the
convergence of the model parameters. The results indicate that the mixed LSTM
and GRU model offers improved accuracy in forecasting 12 months ahead,
demonstrating its effectiveness in capturing complex temporal patterns and
modeling the observed time series. This research significantly contributes to
the application of deep learning techniques in environmental monitoring,
specifically in fire spot forecasting. In addition to improving forecast
accuracy, the proposed approach highlights the potential for adaptation to
other time series forecasting challenges, opening new avenues for research and
development in machine learning and natural phenomenon prediction. Keywords:
Time Series Forecasting, Recurrent Neural Networks, Deep Learning.

摘要：本研究提出了一個全面的方法，用於建模和預測巴西亞馬遜地區由 AQUA_M-T 衛星偵測到的歷史火災點時間序列。該方法採用混合遞迴神經網路 (RNN) 模型，結合長短期記憶 (LSTM) 和門控遞迴單元 (GRU) 架構，以預測每日偵測火災點的月累計值。對資料的摘要顯示出隨著時間推移而出現的一致季節性，每年的年度最大和最小火災點值傾向於在同一時期重複出現。主要目標是透過嚴謹的統計分析驗證預測是否捕捉到這種固有的季節性。該方法涉及仔細的資料準備、模型配置，以及使用兩個種子的交叉驗證進行訓練，確保資料能很好地推廣到測試和驗證集，並確認模型參數的收斂性。結果表明，混合 LSTM 和 GRU 模型在預測 12 個月後提供了更高的準確度，證明了其在捕捉複雜時間模式和建模觀測時間序列方面的有效性。本研究顯著地促进了深度學習技術在環境監測中的應用，特別是在火災點預測方面。除了提高預測準確度外，所提出的方法還強調了適應其他時間序列預測挑戰的潛力，為機器學習和自然現象預測的研究和開發開闢了新的途徑。關鍵字：時間序列預測、遞迴神經網路、深度學習。

##### **SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments**
2409.02598v1 by Wenwu Guo, Jinlin Wu, Zhen Chen, Qingxiang Zhao, Miao Xu, Zhen Lei, Hongbin Liu

Vision-based surgical navigation has received increasing attention due to its
non-invasive, cost-effective, and flexible advantages. In particular, a
critical element of the vision-based navigation system is tracking surgical
instruments. Compared with 2D instrument tracking methods, 3D instrument
tracking has broader value in clinical practice, but is also more challenging
due to weak texture, occlusion, and lack of Computer-Aided Design (CAD) models
for 3D registration. To solve these challenges, we propose the SurgTrack, a
two-stage 3D instrument tracking method for CAD-free and robust real-world
applications. In the first registration stage, we incorporate an Instrument
Signed Distance Field (SDF) modeling the 3D representation of instruments,
achieving CAD-freed 3D registration. Due to this, we can obtain the location
and orientation of instruments in the 3D space by matching the video stream
with the registered SDF model. In the second tracking stage, we devise a
posture graph optimization module, leveraging the historical tracking results
of the posture memory pool to optimize the tracking results and improve the
occlusion robustness. Furthermore, we collect the Instrument3D dataset to
comprehensively evaluate the 3D tracking of surgical instruments. The extensive
experiments validate the superiority and scalability of our SurgTrack, by
outperforming the state-of-the-arts with a remarkable improvement. The code and
dataset are available at https://github.com/wenwucode/SurgTrack.

摘要：<paragraph>基於視覺的外科導航由於其非侵入性、成本效益和靈活性優勢而受到越來越多的關注。特別是，基於視覺的導航系統的一個關鍵元素是追蹤手術器械。與 2D 器械追蹤方法相比，3D 器械追蹤在臨床實務中具有更廣泛的價值，但由於紋理弱、遮擋和缺乏用於 3D 配準的電腦輔助設計 (CAD) 模型，因此也更具挑戰性。為了解決這些挑戰，我們提出 SurgTrack，一種適用於無 CAD 和穩健的真實世界應用程式的兩階段 3D 器械追蹤方法。在第一個配準階段，我們整合一個器械簽署距離場 (SDF)，對器械的 3D 表徵進行建模，實現無 CAD 的 3D 配準。因此，我們可以透過將視訊串流與已配準的 SDF 模型進行匹配，取得器械在 3D 空間中的位置和方向。在第二個追蹤階段，我們設計一個姿勢圖最佳化模組，利用姿勢記憶池的歷史追蹤結果來最佳化追蹤結果並改善遮擋的穩健性。此外，我們收集 Instrument3D 資料集，以全面評估手術器械的 3D 追蹤。廣泛的實驗驗證了我們 SurgTrack 的優越性和可擴充性，以顯著的改進優於現有技術。程式碼和資料集可在 https://github.com/wenwucode/SurgTrack 取得。</paragraph>

##### **Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models**
2409.02530v1 by Chih-Yuan Li, Jun-Ting Wu, Chan Hsu, Ming-Yen Lin, Yihuang Kang

The estimated Glomerular Filtration Rate (eGFR) is an essential indicator of
kidney function in clinical practice. Although traditional equations and
Machine Learning (ML) models using clinical and laboratory data can estimate
eGFR, accurately predicting future eGFR levels remains a significant challenge
for nephrologists and ML researchers. Recent advances demonstrate that Large
Language Models (LLMs) and Large Multimodal Models (LMMs) can serve as robust
foundation models for diverse applications. This study investigates the
potential of LMMs to predict future eGFR levels with a dataset consisting of
laboratory and clinical values from 50 patients. By integrating various
prompting techniques and ensembles of LMMs, our findings suggest that these
models, when combined with precise prompts and visual representations of eGFR
trajectories, offer predictive performance comparable to existing ML models.
This research extends the application of foundation models and suggests avenues
for future studies to harness these models in addressing complex medical
forecasting challenges.

摘要：估計的腎小球過濾率 (eGFR) 是臨床實務中腎臟功能的重要指標。雖然傳統方程式和使用臨床與實驗室資料的機器學習 (ML) 模型可以估計 eGFR，但準確預測未來 eGFR 水平仍然是腎臟科醫師和 ML 研究人員的一大挑戰。最近的研究進展顯示，大型語言模型 (LLM) 和大型多模態模型 (LMM) 可以作為各種應用程式的強健基礎模型。本研究探討 LMM 預測未來 eGFR 水平的潛力，其資料集包含 50 位病患的實驗室和臨床數值。透過整合各種提示技術和 LMM 的合奏，我們的研究結果顯示，這些模型在結合精確提示和 eGFR 軌跡的視覺化表示時，可提供與現有 ML 模型相近的預測效能。這項研究擴展了基礎模型的應用，並為未來研究利用這些模型來應對複雜的醫療預測挑戰提供了途徑。

##### **Coaching a Robotic Sonographer: Learning Robotic Ultrasound with Sparse Expert's Feedback**
2409.02337v1 by Deepak Raina, Mythra V. Balakuntala, Byung Wook Kim, Juan Wachs, Richard Voyles

Ultrasound is widely employed for clinical intervention and diagnosis, due to
its advantages of offering non-invasive, radiation-free, and real-time imaging.
However, the accessibility of this dexterous procedure is limited due to the
substantial training and expertise required of operators. The robotic
ultrasound (RUS) offers a viable solution to address this limitation;
nonetheless, achieving human-level proficiency remains challenging. Learning
from demonstrations (LfD) methods have been explored in RUS, which learns the
policy prior from a dataset of offline demonstrations to encode the mental
model of the expert sonographer. However, active engagement of experts, i.e.
Coaching, during the training of RUS has not been explored thus far. Coaching
is known for enhancing efficiency and performance in human training. This paper
proposes a coaching framework for RUS to amplify its performance. The framework
combines DRL (self-supervised practice) with sparse expert's feedback through
coaching. The DRL employs an off-policy Soft Actor-Critic (SAC) network, with a
reward based on image quality rating. The coaching by experts is modeled as a
Partially Observable Markov Decision Process (POMDP), which updates the policy
parameters based on the correction by the expert. The validation study on
phantoms showed that coaching increases the learning rate by $25\%$ and the
number of high-quality image acquisition by $74.5\%$.

摘要：超音波因其提供非侵入性、無輻射且即時影像的優點，而廣泛用於臨床介入和診斷。
然而，由於操作員需要大量的訓練和專業知識，限制了此靈活程序的可及性。機器人超音波 (RUS) 提供了一個可行的解決方案來解決此限制；
儘管如此，要達到人類等級的熟練度仍然具有挑戰性。學習示範 (LfD) 方法已在 RUS 中進行探討，它從離線示範的資料集學習先驗策略，以編碼專家超音波檢查員的心智模型。然而，迄今尚未探討專家在 RUS 訓練期間的積極參與，即指導。指導已知可以提高人類訓練的效率和績效。本文提出了一個 RUS 指導架構，以提升其績效。此架構結合了 DRL（自我監督實務）與透過指導提供的專家稀疏回饋。DRL 使用離線策略軟性動作-評論 (SAC) 網路，並根據影像品質評分給予獎勵。專家的指導被建模為部分可觀察馬可夫決策過程 (POMDP)，它根據專家的修正來更新策略參數。在模擬人體模型上的驗證研究顯示，指導將學習率提高了 $25\%$，高品質影像擷取數量提高了 $74.5\%$。

##### **Action-Based ADHD Diagnosis in Video**
2409.02261v1 by Yichun Li, Yuxing Yang, Syed Nohsen Naqvi

Attention Deficit Hyperactivity Disorder (ADHD) causes significant impairment
in various domains. Early diagnosis of ADHD and treatment could significantly
improve the quality of life and functioning. Recently, machine learning methods
have improved the accuracy and efficiency of the ADHD diagnosis process.
However, the cost of the equipment and trained staff required by the existing
methods are generally huge. Therefore, we introduce the video-based frame-level
action recognition network to ADHD diagnosis for the first time. We also record
a real multi-modal ADHD dataset and extract three action classes from the video
modality for ADHD diagnosis. The whole process data have been reported to
CNTW-NHS Foundation Trust, which would be reviewed by medical
consultants/professionals and will be made public in due course.

摘要：注意力缺陷過動症 (ADHD) 會在各種領域造成顯著的損害。提早診斷 ADHD 並接受治療可以大幅改善生活品質和功能。最近，機器學習方法已經提升了 ADHD 診斷程序的準確度和效率。然而，現有方法所需的設備和訓練有素的人員成本通常很高。因此，我們首次將基於影片的幀級動作辨識網路引入 ADHD 診斷。我們也記錄了一個真正的多模式 ADHD 資料集，並從影片模式中萃取出三個動作類別以進行 ADHD 診斷。整個流程的資料已經回報給 CNTW-NHS 基金會，將由醫療顧問/專業人士審查，並將適時公開。

##### **A Deployed Online Reinforcement Learning Algorithm In An Oral Health Clinical Trial**
2409.02069v1 by Anna L. Trella, Kelly W. Zhang, Hinal Jajal, Inbal Nahum-Shani, Vivek Shetty, Finale Doshi-Velez, Susan A. Murphy

Dental disease is a prevalent chronic condition associated with substantial
financial burden, personal suffering, and increased risk of systemic diseases.
Despite widespread recommendations for twice-daily tooth brushing, adherence to
recommended oral self-care behaviors remains sub-optimal due to factors such as
forgetfulness and disengagement. To address this, we developed Oralytics, a
mHealth intervention system designed to complement clinician-delivered
preventative care for marginalized individuals at risk for dental disease.
Oralytics incorporates an online reinforcement learning algorithm to determine
optimal times to deliver intervention prompts that encourage oral self-care
behaviors. We have deployed Oralytics in a registered clinical trial. The
deployment required careful design to manage challenges specific to the
clinical trials setting in the U.S. In this paper, we (1) highlight key design
decisions of the RL algorithm that address these challenges and (2) conduct a
re-sampling analysis to evaluate algorithm design decisions. A second phase
(randomized control trial) of Oralytics is planned to start in spring 2025.

摘要：牙科疾病是一種普遍的慢性疾病，與大量的經濟負擔、個人痛苦和增加的全身疾病風險有關。儘管普遍建議每天刷牙兩次，但由於健忘和脫離等因素，對建議的口腔自我保健行為的依從性仍然低於最佳水平。為了解決這個問題，我們開發了 Oralytics，一個 mHealth 介入系統，旨在補充臨床醫生提供的預防保健，以預防有牙科疾病風險的邊緣化個人。Oralytics 結合了一個在線強化學習演算法，以確定提供介入提示的最佳時間，這些提示鼓勵口腔自我保健行為。我們已在註冊的臨床試驗中部署了 Oralytics。該部署需要仔細的設計來管理美國臨床試驗設置中具體的挑戰。在本文中，我們（1）重點介紹了解決這些挑戰的 RL 演算法的關鍵設計決策，以及（2）進行重新抽樣分析以評估演算法設計決策。Oralytics 的第二階段（隨機對照試驗）計劃於 2025 年春季開始。

##### **TransDAE: Dual Attention Mechanism in a Hierarchical Transformer for Efficient Medical Image Segmentation**
2409.02018v1 by Bobby Azad, Pourya Adibfar, Kaiqun Fu

In healthcare, medical image segmentation is crucial for accurate disease
diagnosis and the development of effective treatment strategies. Early
detection can significantly aid in managing diseases and potentially prevent
their progression. Machine learning, particularly deep convolutional neural
networks, has emerged as a promising approach to addressing segmentation
challenges. Traditional methods like U-Net use encoding blocks for local
representation modeling and decoding blocks to uncover semantic relationships.
However, these models often struggle with multi-scale objects exhibiting
significant variations in texture and shape, and they frequently fail to
capture long-range dependencies in the input data. Transformers designed for
sequence-to-sequence predictions have been proposed as alternatives, utilizing
global self-attention mechanisms. Yet, they can sometimes lack precise
localization due to insufficient granular details. To overcome these
limitations, we introduce TransDAE: a novel approach that reimagines the
self-attention mechanism to include both spatial and channel-wise associations
across the entire feature space, while maintaining computational efficiency.
Additionally, TransDAE enhances the skip connection pathway with an inter-scale
interaction module, promoting feature reuse and improving localization
accuracy. Remarkably, TransDAE outperforms existing state-of-the-art methods on
the Synaps multi-organ dataset, even without relying on pre-trained weights.

摘要：在医疗保健领域，医学影像分割对于准确的疾病诊断和有效治疗策略的开发至关重要。早期检测可以极大地帮助控制疾病，并可能防止疾病进展。机器学习，尤其是深度卷积神经网络，已成为解决分割挑战的一种有前途的方法。U-Net 等传统方法使用编码块进行局部表示建模和解码块来揭示语义关系。然而，这些模型通常难以处理在纹理和形状上表现出显着变化的多尺度对象，并且它们经常无法捕获输入数据中的远程依赖关系。专为序列到序列预测而设计的 Transformer 已被提出作为替代方案，利用全局自注意力机制。然而，由于粒度细节不足，它们有时可能缺乏精确的定位。为了克服这些限制，我们引入了 TransDAE：一种新颖的方法，它重新构想了自注意力机制，以包含整个特征空间中的空间和通道关联，同时保持计算效率。此外，TransDAE 通过尺度间交互模块增强了跳跃连接路径，促进了特征重用并提高了定位精度。值得注意的是，即使不依赖预训练权重，TransDAE 在 Synaps 多器官数据集上也优于现有的最先进方法。

##### **A randomized simulation trial evaluating ABiMed, a clinical decision support system for medication reviews and polypharmacy management**
2409.01903v1 by Abdelmalek Mouazer, Sophie Dubois, Romain Léguillon, Nada Boudegzdame, Thibaud Levrard, Yoann Le Bars, Christian Simon, Brigitte Séroussi, Julien Grosjean, Romain Lelong, Catherine Letord, Stéfan Darmoni, Karima Sedki, Pierre Meneton, Rosy Tsopra, Hector Falcoff, Jean-Baptiste Lamy

Background: Medication review is a structured interview of the patient,
performed by the pharmacist and aimed at optimizing drug treatments. In
practice, medication review is a long and cognitively-demanding task that
requires specific knowledge. Clinical practice guidelines have been proposed,
but their application is tedious. Methods: We designed ABiMed, a clinical
decision support system for medication reviews, based on the implementation of
the STOPP/START v2 guidelines and on the visual presentation of aggregated drug
knowledge using tables, graphs and flower glyphs. We evaluated ABiMed with 39
community pharmacists during a randomized simulation trial, each pharmacist
performing a medication review for two fictitious patients without ABiMed, and
two others with ABiMed. We recorded the problems identified by the pharmacists,
the interventions proposed, the response time, the perceived usability and the
comments. Pharmacists' medication reviews were compared to an expert-designed
gold standard. Results: With ABiMed, pharmacists found 1.6 times more relevant
drug-related problems during the medication review (p=1.1e-12) and proposed
better interventions (p=9.8e-9), without needing more time (p=0.56). The System
Usability Scale score is 82.7, which is ranked "excellent". In their comments,
pharmacists appreciated the visual aspect of ABiMed and its ability to compare
the current treatment with the proposed one. A multifactor analysis showed no
difference in the support offered by ABiMed according to the pharmacist's age
or sex, in terms of percentage of problems identified or quality of the
proposed interventions. Conclusions: The use of an intelligent and visual
clinical decision support system can help pharmacists when they perform
medication reviews. Our main perspective is the validation of the system in
clinical conditions.

摘要：<paragraph>背景：用藥審查是由藥師執行的一種結構化患者訪談，目的在於優化藥物治療。在實務上，用藥審查是一項冗長且認知需求高的任務，需要具備特定知識。雖然已提出臨床實務指引，但其應用很繁瑣。方法：我們根據 STOPP/START v2 指引的實作，並使用表格、圖表和花形符號視覺化呈現彙整的藥物知識，設計了一套用藥審查的臨床決策支援系統 ABiMed。我們在隨機模擬試驗中，讓 39 位社區藥師評估 ABiMed，每位藥師針對兩位虛構患者執行用藥審查，兩次沒有使用 ABiMed，兩次使用 ABiMed。我們記錄了藥師識別出的問題、建議的介入措施、反應時間、感知可用性和評論。將藥師的用藥審查與專家設計的金標準進行比較。結果：使用 ABiMed 後，藥師在用藥審查期間發現了多 1.6 倍相關的藥物相關問題（p=1.1e-12），並提出更好的介入措施（p=9.8e-9），而無需花費更多時間（p=0.56）。系統可用性評分為 82.7，被評為「優良」。在他們的評論中，藥師讚賞 ABiMed 的視覺化面向，以及它比較目前治療與建議治療的能力。多因素分析顯示，ABiMed 提供的支援在藥師的年齡或性別方面沒有差異，就識別出的問題百分比或建議介入措施的品質而言。結論：使用智慧且視覺化的臨床決策支援系統，可以協助藥師執行用藥審查。我們的觀點主要是驗證系統在臨床條件下的效度。</paragraph>

##### **Training on the Benchmark Is Not All You Need**
2409.01790v1 by Shiwen Ni, Xiangtao Kong, Chengming Li, Xiping Hu, Ruifeng Xu, Jia Zhu, Min Yang

The success of Large Language Models (LLMs) relies heavily on the huge amount
of pre-training data learned in the pre-training phase. The opacity of the
pre-training process and the training data causes the results of many benchmark
tests to become unreliable. If any model has been trained on a benchmark test
set, it can seriously hinder the health of the field. In order to automate and
efficiently test the capabilities of large language models, numerous mainstream
benchmarks adopt a multiple-choice format. As the swapping of the contents of
multiple-choice options does not affect the meaning of the question itself, we
propose a simple and effective data leakage detection method based on this
property. Specifically, we shuffle the contents of the options in the data to
generate the corresponding derived data sets, and then detect data leakage
based on the model's log probability distribution over the derived data sets.
If there is a maximum and outlier in the set of log probabilities, it indicates
that the data is leaked. Our method is able to work under black-box conditions
without access to model training data or weights, effectively identifying data
leakage from benchmark test sets in model pre-training data, including both
normal scenarios and complex scenarios where options may have been shuffled
intentionally or unintentionally. Through experiments based on two LLMs and
benchmark designs, we demonstrate the effectiveness of our method. In addition,
we evaluate the degree of data leakage of 31 mainstream open-source LLMs on
four benchmark datasets and give a ranking of the leaked LLMs for each
benchmark, and we find that the Qwen family of LLMs has the highest degree of
data leakage.

摘要：大型語言模型 (LLM) 的成功在很大程度上取決於預訓練階段中學習到的海量預訓練數據。預訓練過程和訓練數據的不透明性導致許多基準測試的結果變得不可靠。如果任何模型已在基準測試集中進行訓練，則可能會嚴重阻礙該領域的發展。為了自動化且有效地測試大型語言模型的能力，許多主流基準採用多選題格式。由於多選題選項內容的互換不影響問題本身的含義，因此我們提出了一種基於此屬性的簡單且有效的数据洩漏檢測方法。具體來說，我們將數據中選項的內容隨機排列以生成對應的派生數據集，然後根據模型在派生數據集上的對數概率分佈檢測數據洩漏。如果對數概率集中存在最大值和異常值，則表示數據已洩漏。我們的方法能夠在不訪問模型訓練數據或權重的黑盒條件下工作，有效地識別模型預訓練數據中基準測試集的數據洩漏，包括選項可能已有意或無意地被打亂的正常場景和複雜場景。通過基於兩個 LLM 和基準設計的實驗，我們證明了我們方法的有效性。此外，我們評估了 31 個主流開源 LLM 在四個基準數據集上的數據洩漏程度，並對每個基準的洩漏 LLM 進行了排名，我們發現 Qwen 家族的 LLM 具有最高的數據洩漏程度。

##### **Classifier-Free Diffusion-Based Weakly-Supervised Approach for Health Indicator Derivation in Rotating Machines: Advancing Early Fault Detection and Condition Monitoring**
2409.01676v1 by Wenyang Hu, Gaetan Frusque, Tianyang Wang, Fulei Chu, Olga Fink

Deriving health indicators of rotating machines is crucial for their
maintenance. However, this process is challenging for the prevalent adopted
intelligent methods since they may take the whole data distributions, not only
introducing noise interference but also lacking the explainability. To address
these issues, we propose a diffusion-based weakly-supervised approach for
deriving health indicators of rotating machines, enabling early fault detection
and continuous monitoring of condition evolution. This approach relies on a
classifier-free diffusion model trained using healthy samples and a few
anomalies. This model generates healthy samples. and by comparing the
differences between the original samples and the generated ones in the envelope
spectrum, we construct an anomaly map that clearly identifies faults. Health
indicators are then derived, which can explain the fault types and mitigate
noise interference. Comparative studies on two cases demonstrate that the
proposed method offers superior health monitoring effectiveness and robustness
compared to baseline models.

摘要：推導旋轉機器的健康指標對於其維護至關重要。然而，這個過程對普遍採用的智能方法來說具有挑戰性，因為它們可能會採用整個資料分佈，不僅會引入雜訊干擾，而且缺乏可解釋性。為了解決這些問題，我們提出了一種基於擴散的弱監督式方法，用於推導旋轉機器的健康指標，實現早期故障檢測和狀態演變的持續監控。這種方法依賴於使用健康樣本和一些異常值訓練的無分類器擴散模型。這個模型會產生健康樣本。並且通過比較封套譜中原始樣本和生成樣本之間的差異，我們構建了一個異常圖，可以清楚地識別故障。然後推導出健康指標，可以解釋故障類型並減輕雜訊干擾。對兩個案例的比較研究表明，與基準模型相比，所提出的方法提供了卓越的健康監控有效性和魯棒性。

##### **A Multimodal Object-level Contrast Learning Method for Cancer Survival Risk Prediction**
2409.02145v1 by Zekang Yang, Hong Liu, Xiangdong Wang

Computer-aided cancer survival risk prediction plays an important role in the
timely treatment of patients. This is a challenging weakly supervised ordinal
regression task associated with multiple clinical factors involved such as
pathological images, genomic data and etc. In this paper, we propose a new
training method, multimodal object-level contrast learning, for cancer survival
risk prediction. First, we construct contrast learning pairs based on the
survival risk relationship among the samples in the training sample set. Then
we introduce the object-level contrast learning method to train the survival
risk predictor. We further extend it to the multimodal scenario by applying
cross-modal constrast. Considering the heterogeneity of pathological images and
genomics data, we construct a multimodal survival risk predictor employing
attention-based and self-normalizing based nerural network respectively.
Finally, the survival risk predictor trained by our proposed method outperforms
state-of-the-art methods on two public multimodal cancer datasets for survival
risk prediction.

摘要：電腦輔助癌症存活風險預測在病患的及時治療中扮演著重要的角色。這是一個困難的弱監督序數回歸任務，與多重臨床因素有關，例如病理圖像、基因組數據等。在本文中，我們提出了一種新的訓練方法，多模態物件層級對比學習，用於癌症存活風險預測。首先，我們根據訓練樣本集中樣本之間的存活風險關係建立對比學習對。接著，我們引入物件層級對比學習方法來訓練存活風險預測器。我們進一步將其延伸至多模態場景，透過應用跨模態對比。考量到病理圖像和基因體數據的異質性，我們分別採用基於注意力的和自標準化的神經網路來建構多模態存活風險預測器。最後，我們提出的方法所訓練的存活風險預測器在兩個公開的多模態癌症資料集上，在存活風險預測方面優於最先進的方法。

##### **A Time-Intensity Aware Pipeline for Generating Late-Stage Breast DCE-MRI using Generative Adversarial Models**
2409.01596v1 by Ruben D. Fonnegra, Maria Liliana Hernández, Juan C. Caicedo, Gloria M. Díaz

Contrast-enhancement pattern analysis is critical in breast magnetic
resonance imaging (MRI) to distinguish benign from probably malignant tumors.
However, contrast-enhanced image acquisitions are time-consuming and very
expensive. As an alternative to physical acquisition, this paper proposes a
comprehensive pipeline for the generation of accurate long-term (late)
contrast-enhanced breast MRI from the early counterpart. The proposed strategy
focuses on preserving the contrast agent pattern in the enhanced regions while
maintaining visual properties in the entire synthesized images. To that end, a
novel loss function that leverages the biological behavior of contrast agent
(CA) in tissue, given by the Time-Intensity (TI) enhancement curve, is proposed
to optimize a pixel-attention based generative model. In addition, unlike
traditional normalization and standardization methods, we developed a new
normalization strategy that maintains the contrast enhancement pattern across
the image sequences at multiple timestamps. This ensures the prevalence of the
CA pattern after image preprocessing, unlike conventional approaches.
Furthermore, in order to objectively evaluate the clinical quality of the
synthesized images, two metrics are also introduced to measure the differences
between the TI curves of enhanced regions of the acquired and synthesized
images. The experimental results showed that the proposed strategy generates
images that significantly outperform diagnostic quality in contrast-enhanced
regions while maintaining the spatial features of the entire image. This
results suggest a potential use of synthetic late enhanced images generated via
deep learning in clinical scenarios.

摘要：對比增強模式分析在乳房磁共振影像 (MRI) 中至關重要，可用於區分良性腫瘤和可能是惡性腫瘤。
然而，對比增強影像的擷取非常耗時且昂貴。作為物理擷取的替代方案，本文提出了一個全面的管道，用於從早期對應物生成準確的長期（晚期）對比增強乳房 MRI。所提出的策略著重於在增強區域中保留對比劑模式，同時在整個合成影像中維持視覺屬性。為此，提出了一種新穎的損失函數，利用對比劑 (CA) 在組織中的生物行為（由時間強度 (TI) 增強曲線給出），以最佳化基於像素注意力的生成模型。此外，與傳統的正規化和標準化方法不同，我們開發了一種新的正規化策略，可在多個時間戳的影像序列中維持對比增強模式。這確保了影像前處理後 CA 模式的普遍性，這與傳統方法不同。此外，為了客觀評估合成影像的臨床品質，還引入了兩個指標來測量擷取和合成影像的增強區域的 TI 曲線之間的差異。實驗結果顯示，所提出的策略產生的影像在對比增強區域中的診斷品質明顯優於其他影像，同時維持了整個影像的空間特徵。這些結果表明，在臨床場景中，通過深度學習生成的合成晚期增強影像具有潛在用途。

##### **Kvasir-VQA: A Text-Image Pair GI Tract Dataset**
2409.01437v1 by Sushant Gautam, Andrea Storås, Cise Midoglu, Steven A. Hicks, Vajira Thambawita, Pål Halvorsen, Michael A. Riegler

We introduce Kvasir-VQA, an extended dataset derived from the HyperKvasir and
Kvasir-Instrument datasets, augmented with question-and-answer annotations to
facilitate advanced machine learning tasks in Gastrointestinal (GI)
diagnostics. This dataset comprises 6,500 annotated images spanning various GI
tract conditions and surgical instruments, and it supports multiple question
types including yes/no, choice, location, and numerical count. The dataset is
intended for applications such as image captioning, Visual Question Answering
(VQA), text-based generation of synthetic medical images, object detection, and
classification. Our experiments demonstrate the dataset's effectiveness in
training models for three selected tasks, showcasing significant applications
in medical image analysis and diagnostics. We also present evaluation metrics
for each task, highlighting the usability and versatility of our dataset. The
dataset and supporting artifacts are available at
https://datasets.simula.no/kvasir-vqa.

摘要：我們引進 Kvasir-VQA，一個由 HyperKvasir 和 Kvasir-Instrument 資料集衍生的延伸資料集，並加入問題與解答註解，以促進在胃腸 (GI) 診斷中的進階機器學習任務。此資料集包含 6,500 個註解影像，涵蓋各種 GI 道狀況和手術器械，並且支援包括是非題、選擇題、位置和數字計數等多種類型的問題。此資料集適用於影像標題、視覺問答 (VQA)、合成醫學影像的文字生成、物件偵測和分類等應用程式。我們的實驗證明此資料集在訓練三個選定任務的模型中具有成效，展示了在醫學影像分析和診斷中重要的應用。我們也為每個任務提供評估指標，突顯我們資料集的可用性和多功能性。此資料集和支援工件可於 https://datasets.simula.no/kvasir-vqa 取得。

##### **SeCo-INR: Semantically Conditioned Implicit Neural Representations for Improved Medical Image Super-Resolution**
2409.01013v1 by Mevan Ekanayake, Zhifeng Chen, Gary Egan, Mehrtash Harandi, Zhaolin Chen

Implicit Neural Representations (INRs) have recently advanced the field of
deep learning due to their ability to learn continuous representations of
signals without the need for large training datasets. Although INR methods have
been studied for medical image super-resolution, their adaptability to
localized priors in medical images has not been extensively explored. Medical
images contain rich anatomical divisions that could provide valuable local
prior information to enhance the accuracy and robustness of INRs. In this work,
we propose a novel framework, referred to as the Semantically Conditioned INR
(SeCo-INR), that conditions an INR using local priors from a medical image,
enabling accurate model fitting and interpolation capabilities to achieve
super-resolution. Our framework learns a continuous representation of the
semantic segmentation features of a medical image and utilizes it to derive the
optimal INR for each semantic region of the image. We tested our framework
using several medical imaging modalities and achieved higher quantitative
scores and more realistic super-resolution outputs compared to state-of-the-art
methods.

摘要：隱式神經表徵 (INR) 近期由於其無需大量訓練資料集就能學習訊號的連續表徵的能力，而推動了深度學習領域的進展。儘管 INR 方法已被研究用於醫學影像超解析度，但其對於醫學影像中局部先驗的適應性尚未被廣泛探討。醫學影像包含豐富的解剖學區分，這些區分可以提供有價值的局部先驗資訊，以增強 INR 的準確性和穩健性。在這項工作中，我們提出了一個新穎的架構，稱為語義條件 INR (SeCo-INR)，它使用醫學影像中的局部先驗來調整 INR，實現準確的模型擬合和插值能力，以實現超解析度。我們的架構學習醫學影像的語意分割特徵的連續表徵，並利用它為影像的每個語意區域推導最佳 INR。我們使用多種醫學影像方式測試我們的架構，並與最先進的方法相比，達到了更高的量化評分和更逼真的超解析度輸出。

##### **Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation**
2409.00873v1 by Sajib Acharjee Dip, Kazi Hasan Ibn Arif, Uddip Acharjee Shuvo, Ishtiaque Ahmed Khan, Na Meng

In the realm of dermatology, the complexity of diagnosing skin conditions
manually necessitates the expertise of dermatologists. Accurate identification
of various skin ailments, ranging from cancer to inflammatory diseases, is
paramount. However, existing artificial intelligence (AI) models in dermatology
face challenges, particularly in accurately diagnosing diseases across diverse
skin tones, with a notable performance gap in darker skin. Additionally, the
scarcity of publicly available, unbiased datasets hampers the development of
inclusive AI diagnostic tools. To tackle the challenges in accurately
predicting skin conditions across diverse skin tones, we employ a
transfer-learning approach that capitalizes on the rich, transferable knowledge
from various image domains. Our method integrates multiple pre-trained models
from a wide range of sources, including general and specific medical images, to
improve the robustness and inclusiveness of the skin condition predictions. We
rigorously evaluated the effectiveness of these models using the Diverse
Dermatology Images (DDI) dataset, which uniquely encompasses both
underrepresented and common skin tones, making it an ideal benchmark for
assessing our approach. Among all methods, Med-ViT emerged as the top performer
due to its comprehensive feature representation learned from diverse image
sources. To further enhance performance, we conducted domain adaptation using
additional skin image datasets such as HAM10000. This adaptation significantly
improved model performance across all models.

摘要：<paragraph>在皮肤病学领域，人工诊断皮肤状况的复杂性需要皮肤科医师的专业知识。从癌症到炎症性疾病，对各种皮肤疾病的准确识别至关重要。然而，现有的皮肤病学人工智能 (AI) 模型面临挑战，尤其是在准确诊断不同肤色的疾病时，在较深的肤色上存在明显的性能差距。此外，公开可用的无偏数据集的稀缺性阻碍了包容性 AI 诊断工具的开发。为了应对准确预测不同肤色皮肤状况的挑战，我们采用了一种迁移学习方法，该方法利用了来自各种图像域的丰富可转移知识。我们的方法集成了来自广泛来源的多个预训练模型，包括一般和特定的医学图像，以提高皮肤状况预测的稳健性和包容性。我们使用 Diverse Dermatology Images (DDI) 数据集严格评估了这些模型的有效性，该数据集独特地包含了代表性不足和常见的肤色，使其成为评估我们方法的理想基准。在所有方法中，Med-ViT 由于其从各种图像来源中学到的综合特征表示而成为表现最好的方法。为了进一步提高性能，我们使用 HAM10000 等其他皮肤图像数据集进行了域适应。这种适应显着提高了所有模型的模型性能。</paragraph>

##### **Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**
2409.00861v1 by Derian Boer, Fabian Koch, Stefan Kramer

Large Language Models (LLMs) frequently lack domain-specific knowledge and
even fine-tuned models tend to hallucinate. Hence, more reliable models that
can include external knowledge are needed. We present a pipeline, 4StepFocus,
and specifically a preprocessing step, that can substantially improve the
answers of LLMs. This is achieved by providing guided access to external
knowledge making use of the model's ability to capture relational context and
conduct rudimentary reasoning by themselves. The method narrows down
potentially correct answers by triplets-based searches in a semi-structured
knowledge base in a direct, traceable fashion, before switching to latent
representations for ranking those candidates based on unstructured data. This
distinguishes it from related methods that are purely based on latent
representations. 4StepFocus consists of the steps: 1) Triplet generation for
extraction of relational data by an LLM, 2) substitution of variables in those
triplets to narrow down answer candidates employing a knowledge graph, 3)
sorting remaining candidates with a vector similarity search involving
associated non-structured data, 4) reranking the best candidates by the LLM
with background data provided. Experiments on a medical, a product
recommendation, and an academic paper search test set demonstrate that this
approach is indeed a powerful augmentation. It not only adds relevant traceable
background information from information retrieval, but also improves
performance considerably in comparison to state-of-the-art methods. This paper
presents a novel, largely unexplored direction and therefore provides a wide
range of future work opportunities. Used source code is available at
https://github.com/kramerlab/4StepFocus.

摘要：大型語言模型 (LLM) 經常缺乏特定領域的知識，即使經過微調的模型也容易產生幻覺。因此，需要更多可靠的模型來納入外部知識。我們提出了一個流程 4StepFocus，特別是預處理步驟，可以大幅改善 LLM 的答案。這是透過提供受引導的外部知識存取，利用模型自行擷取關聯性脈絡和進行基本推理的能力來實現的。此方法透過在半結構化知識庫中進行基於三元組的搜尋，以直接且可追蹤的方式縮小潛在正確答案的範圍，然後再切換到潛在表徵，根據非結構化資料對這些候選答案進行排名。這與純粹基於潛在表徵的相關方法有所區別。4StepFocus 包含以下步驟：1) 由 LLM 進行三元組產生以擷取關聯資料，2) 在這些三元組中替換變數，以採用知識圖表縮小答案候選範圍，3) 使用涉及關聯非結構化資料的向量相似性搜尋對剩餘候選答案進行排序，4) 由 LLM 重新對最佳候選答案進行排名，並提供背景資料。在醫療、產品推薦和學術論文搜尋測試集中進行的實驗證明，這種方法確實是一種強大的擴充。它不僅增加了來自資訊檢索的相关可追蹤背景資訊，而且與最先進的方法相比，也大幅提升了效能。本文提出了一個新穎且鮮少探索的方向，因此提供了廣泛的未來工作機會。使用的原始碼可在 https://github.com/kramerlab/4StepFocus 取得。

##### **Building FKG.in: a Knowledge Graph for Indian Food**
2409.00830v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Ramesh Jain

This paper presents an ontology design along with knowledge engineering, and
multilingual semantic reasoning techniques to build an automated system for
assimilating culinary information for Indian food in the form of a knowledge
graph. The main focus is on designing intelligent methods to derive ontology
designs and capture all-encompassing knowledge about food, recipes,
ingredients, cooking characteristics, and most importantly, nutrition, at
scale. We present our ongoing work in this workshop paper, describe in some
detail the relevant challenges in curating knowledge of Indian food, and
propose our high-level ontology design. We also present a novel workflow that
uses AI, LLM, and language technology to curate information from recipe blog
sites in the public domain to build knowledge graphs for Indian food. The
methods for knowledge curation proposed in this paper are generic and can be
replicated for any domain. The design is application-agnostic and can be used
for AI-driven smart analysis, building recommendation systems for Personalized
Digital Health, and complementing the knowledge graph for Indian food with
contextual information such as user information, food biochemistry, geographic
information, agricultural information, etc.

摘要：本文提出了一個知識工程和多語言語義推理技術的本体設計，用於建立一個自動化系統，以知識圖譜的形式吸收印度料理的烹飪資訊。重點在於設計智慧方法，以推導本体設計，並全面擷取關於食物、食譜、食材、烹飪特性，以及最重要的營養的知識，並擴大規模。我們在這個研討會論文中介紹了我們正在進行的工作，詳細描述了整理印度料理知識相關的挑戰，並提出了我們的高階本体設計。我們也提出了一種新的工作流程，它使用 AI、LLM 和語言技術，從公共領域的食譜部落格網站中整理資訊，以建立印度料理的知識圖譜。本文提出的知識整理方法是通用的，可以複製到任何領域。設計與應用無關，可用於 AI 驅動的智慧分析、建立個人化數位健康推薦系統，以及使用使用者資訊、食物生物化學、地理資訊、農業資訊等脈絡資訊，來補充印度料理的知識圖譜。

##### **AgGym: An agricultural biotic stress simulation environment for ultra-precision management planning**
2409.00735v1 by Mahsa Khosravi, Matthew Carroll, Kai Liang Tan, Liza Van der Laan, Joscif Raigne, Daren S. Mueller, Arti Singh, Aditya Balu, Baskar Ganapathysubramanian, Asheesh Kumar Singh, Soumik Sarkar

Agricultural production requires careful management of inputs such as
fungicides, insecticides, and herbicides to ensure a successful crop that is
high-yielding, profitable, and of superior seed quality. Current
state-of-the-art field crop management relies on coarse-scale crop management
strategies, where entire fields are sprayed with pest and disease-controlling
chemicals, leading to increased cost and sub-optimal soil and crop management.
To overcome these challenges and optimize crop production, we utilize machine
learning tools within a virtual field environment to generate localized
management plans for farmers to manage biotic threats while maximizing profits.
Specifically, we present AgGym, a modular, crop and stress agnostic simulation
framework to model the spread of biotic stresses in a field and estimate yield
losses with and without chemical treatments. Our validation with real data
shows that AgGym can be customized with limited data to simulate yield outcomes
under various biotic stress conditions. We further demonstrate that deep
reinforcement learning (RL) policies can be trained using AgGym for designing
ultra-precise biotic stress mitigation strategies with potential to increase
yield recovery with less chemicals and lower cost. Our proposed framework
enables personalized decision support that can transform biotic stress
management from being schedule based and reactive to opportunistic and
prescriptive. We also release the AgGym software implementation as a community
resource and invite experts to contribute to this open-sourced publicly
available modular environment framework. The source code can be accessed at:
https://github.com/SCSLabISU/AgGym.

摘要：農業生產需要小心管理輸入，例如殺菌劑、殺蟲劑和除草劑，以確保作物成功、高產、有利可圖且具有優良的種子品質。目前最先進的田間作物管理依賴於粗略的作物管理策略，其中整個田地都噴灑了控制病蟲害的化學物質，導致成本增加和土壤和作物管理不佳。為了克服這些挑戰並優化作物生產，我們在虛擬田間環境中利用機器學習工具為農民生成局部管理計畫，以管理生物威脅並同時最大化利潤。具體來說，我們提出了 AgGym，一個模組化、作物和壓力不可知的模擬架構，用於模擬田間生物壓力的擴散，並估算有和沒有化學處理的產量損失。我們使用真實數據進行驗證，顯示 AgGym 可以使用有限的數據進行自訂，以模擬各種生物壓力條件下的產量結果。我們進一步證明，深度強化學習 (RL) 政策可以使用 AgGym 進行訓練，以設計超精確的生物壓力緩解策略，並有可能以更少的化學物質和更低的成本增加產量恢復。我們提出的架構啟用了個人化決策支援，可以將生物壓力管理從基於時間表和被動轉變為機會主義和規範性。我們還將 AgGym 軟體實作作為社區資源釋出，並邀請專家為這個開放原始碼且公開可用的模組化環境架構做出貢獻。可以在以下位置取得原始碼：https://github.com/SCSLabISU/AgGym。

##### **LPUWF-LDM: Enhanced Latent Diffusion Model for Precise Late-phase UWF-FA Generation on Limited Dataset**
2409.00726v1 by Zhaojie Fang, Xiao Yu, Guanyu Zhou, Ke Zhuang, Yifei Chen, Ruiquan Ge, Changmiao Wang, Gangyong Jia, Qing Wu, Juan Ye, Maimaiti Nuliqiman, Peifang Xu, Ahmed Elazab

Ultra-Wide-Field Fluorescein Angiography (UWF-FA) enables precise
identification of ocular diseases using sodium fluorescein, which can be
potentially harmful. Existing research has developed methods to generate UWF-FA
from Ultra-Wide-Field Scanning Laser Ophthalmoscopy (UWF-SLO) to reduce the
adverse reactions associated with injections. However, these methods have been
less effective in producing high-quality late-phase UWF-FA, particularly in
lesion areas and fine details. Two primary challenges hinder the generation of
high-quality late-phase UWF-FA: the scarcity of paired UWF-SLO and
early/late-phase UWF-FA datasets, and the need for realistic generation at
lesion sites and potential blood leakage regions. This study introduces an
improved latent diffusion model framework to generate high-quality late-phase
UWF-FA from limited paired UWF images. To address the challenges as mentioned
earlier, our approach employs a module utilizing Cross-temporal Regional
Difference Loss, which encourages the model to focus on the differences between
early and late phases. Additionally, we introduce a low-frequency enhanced
noise strategy in the diffusion forward process to improve the realism of
medical images. To further enhance the mapping capability of the variational
autoencoder module, especially with limited datasets, we implement a Gated
Convolutional Encoder to extract additional information from conditional
images. Our Latent Diffusion Model for Ultra-Wide-Field Late-Phase Fluorescein
Angiography (LPUWF-LDM) effectively reconstructs fine details in late-phase
UWF-FA and achieves state-of-the-art results compared to other existing methods
when working with limited datasets. Our source code is available at:
https://github.com/Tinysqua/****.

摘要：超廣角螢光血管造影（UWF-FA）使用可能具有潛在危害的鈉螢光素，可精確識別眼疾。現有研究已開發出從超廣角掃描雷射眼科鏡（UWF-SLO）產生 UWF-FA 的方法，以減少與注射相關的不良反應。然而，這些方法在產生高品質的後期 UWF-FA 方面效果較差，特別是在病灶區域和精細細節方面。產生高品質後期 UWF-FA 面臨兩項主要挑戰：配對的 UWF-SLO 和早期/後期 UWF-FA 資料集稀少，以及需要在病灶部位和潛在出血區域進行逼真的產生。本研究引進一種改良的潛在擴散模型架構，從有限配對的 UWF 影像產生高品質的後期 UWF-FA。為了應對前面提到的挑戰，我們的方法採用一個模組，利用跨時間區域差異損失，鼓勵模型專注於早期和後期之間的差異。此外，我們在擴散前向過程中引進一種低頻增強雜訊策略，以改善醫學影像的真實性。為了進一步增強變異自動編碼器模組的對應能力，特別是在資料集有限的情況下，我們實作一個閘控卷積編碼器，從條件影像中萃取額外資訊。我們針對超廣角後期螢光血管造影（LPUWF-LDM）的潛在擴散模型有效重建後期 UWF-FA 中的精細細節，並在使用有限資料集時，與其他現有方法相比，達到最先進的結果。我們的原始碼可在以下網址取得：
https://github.com/Tinysqua/****。

##### **BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation Dataset for Developing Computer-Aided Diagnostic Systems**
2409.00724v1 by Shams Nafisa Ali, Afia Zahin, Samiul Based Shuvo, Nusrat Binta Nizam, Shoyad Ibn Sabur Khan Nuhash, Sayeed Sajjad Razin, S. M. Sakeef Sani, Farihin Rahman, Nawshad Binta Nizam, Farhat Binte Azam, Rakib Hossen, Sumaiya Ohab, Nawsabah Noor, Taufiq Hasan

Cardiac auscultation, an integral tool in diagnosing cardiovascular diseases
(CVDs), often relies on the subjective interpretation of clinicians, presenting
a limitation in consistency and accuracy. Addressing this, we introduce the
BUET Multi-disease Heart Sound (BMD-HS) dataset - a comprehensive and
meticulously curated collection of heart sound recordings. This dataset,
encompassing 864 recordings across five distinct classes of common heart
sounds, represents a broad spectrum of valvular heart diseases, with a focus on
diagnostically challenging cases. The standout feature of the BMD-HS dataset is
its innovative multi-label annotation system, which captures a diverse range of
diseases and unique disease states. This system significantly enhances the
dataset's utility for developing advanced machine learning models in automated
heart sound classification and diagnosis. By bridging the gap between
traditional auscultation practices and contemporary data-driven diagnostic
methods, the BMD-HS dataset is poised to revolutionize CVD diagnosis and
management, providing an invaluable resource for the advancement of cardiac
health research. The dataset is publicly available at this link:
https://github.com/mHealthBuet/BMD-HS-Dataset.

摘要：心臟聽診是診斷心血管疾病 (CVD) 的一項整合工具，通常依賴於臨床醫師的主觀詮釋，在一致性和準確性方面存在限制。為了解決這個問題，我們引入了 BUET 多重疾病心音 (BMD-HS) 資料集，這是一個全面且經過精心策劃的心音錄音資料集。此資料集包含五種常見心音的 864 個錄音，代表了廣泛的心瓣膜疾病，重點在於診斷困難的病例。BMD-HS 資料集的突出特點是其創新的多標籤註解系統，它涵蓋了各種疾病和獨特的疾病狀態。這個系統顯著增強了資料集在開發自動心音分類和診斷中進階機器學習模型的效用。透過彌合傳統聽診實務與當代資料驅動診斷方法之間的差距，BMD-HS 資料集準備好革新心血管疾病的診斷和管理，為心臟健康研究的進展提供寶貴的資源。此資料集可透過以下連結公開取得：https://github.com/mHealthBuet/BMD-HS-Dataset。

##### **Multiscale Color Guided Attention Ensemble Classifier for Age-Related Macular Degeneration using Concurrent Fundus and Optical Coherence Tomography Images**
2409.00718v1 by Pragya Gupta, Subhamoy Mandal, Debashree Guha, Debjani Chakraborty

Automatic diagnosis techniques have evolved to identify age-related macular
degeneration (AMD) by employing single modality Fundus images or optical
coherence tomography (OCT). To classify ocular diseases, fundus and OCT images
are the most crucial imaging modalities used in the clinical setting. Most deep
learning-based techniques are established on a single imaging modality, which
contemplates the ocular disorders to a specific extent and disregards other
modality that comprises exhaustive information among distinct imaging
modalities. This paper proposes a modality-specific multiscale color space
embedding integrated with the attention mechanism based on transfer learning
for classification (MCGAEc), which can efficiently extract the distinct
modality information at various scales using the distinct color spaces. In this
work, we first introduce the modality-specific multiscale color space encoder
model, which includes diverse feature representations by integrating distinct
characteristic color spaces on a multiscale into a unified framework. The
extracted features from the prior encoder module are incorporated with the
attention mechanism to extract the global features representation, which is
integrated with the prior extracted features and transferred to the random
forest classifier for the classification of AMD. To analyze the performance of
the proposed MCGAEc method, a publicly available multi-modality dataset from
Project Macula for AMD is utilized and compared with the existing models.

摘要：自動診斷技術已演進到能透過使用單一模式眼底影像或光學相干斷層掃描 (OCT) 來辨識年齡相關性黃斑部病變 (AMD)。為了分類眼疾，眼底和 OCT 影像是臨床環境中使用最關鍵的影像模式。大多數基於深度學習的技術建立在單一影像模式上，它在一定程度上考量了眼疾，卻忽略了其他模式，而其他模式包含了不同影像模式之間的詳盡資訊。本文提出了一種模式特定的多尺度色彩空間嵌入整合，並基於用於分類的轉移學習的注意力機制 (MCGAEc)，它能使用不同的色彩空間在不同的尺度上有效提取不同的模式資訊。在這項工作中，我們首先介紹了模式特定的多尺度色彩空間編碼器模型，它透過將不同的特徵色彩空間整合到多尺度中，來納入不同的特徵表徵到一個統一的架構中。從先前的編碼器模組中提取的特徵與注意力機制結合，以提取全域特徵表徵，它與先前提取的特徵整合，並轉移到隨機森林分類器，以進行 AMD 分類。為了分析所提出的 MCGAEc 方法的效能，我們利用了來自 Project Macula for AMD 的公開多模式資料集，並與現有模型進行比較。

##### **Curriculum Prompting Foundation Models for Medical Image Segmentation**
2409.00695v1 by Xiuqi Zheng, Yuhang Zhang, Haoran Zhang, Hongrui Liang, Xueqi Bao, Zhuqing Jiang, Qicheng Lao

Adapting large pre-trained foundation models, e.g., SAM, for medical image
segmentation remains a significant challenge. A crucial step involves the
formulation of a series of specialized prompts that incorporate specific
clinical instructions. Past works have been heavily reliant on a singular type
of prompt for each instance, necessitating manual input of an ideally correct
prompt, which is less efficient. To tackle this issue, we propose to utilize
prompts of different granularity, which are sourced from original images to
provide a broader scope of clinical insights. However, combining prompts of
varying types can pose a challenge due to potential conflicts. In response, we
have designed a coarse-to-fine mechanism, referred to as curriculum prompting,
that progressively integrates prompts of different types. Through extensive
experiments on three public medical datasets across various modalities, we
demonstrate the effectiveness of our proposed approach, which not only
automates the prompt generation process but also yields superior performance
compared to other SAM-based medical image segmentation methods. Code is
available at: https://github.com/AnnaZzz-zxq/Curriculum-Prompting.

摘要：調整大型預訓練基礎模型（例如 SAM）以進行醫學影像分割仍是一項重大挑戰。關鍵步驟涉及制定一系列包含特定臨床說明的專門提示。過去的工作在很大程度上依賴於每個例項的單一提示類型，這需要手動輸入理想的正確提示，效率較低。為了解決這個問題，我們建議利用不同粒度的提示，這些提示來自原始影像，以提供更廣泛的臨床見解。然而，由於潛在衝突，結合不同類型的提示可能會構成挑戰。為了解決這個問題，我們設計了一種由粗到細的機制，稱為課程提示，它逐步整合不同類型的提示。透過對各種模式下的三個公共醫學資料集進行廣泛的實驗，我們證明了我們提出的方法的有效性，它不僅自動化提示生成過程，而且與其他基於 SAM 的醫學影像分割方法相比，還產生了更好的效能。程式碼可在以下位置取得：https://github.com/AnnaZzz-zxq/Curriculum-Prompting。

##### **Large Language Models-Enabled Digital Twins for Precision Medicine in Rare Gynecological Tumors**
2409.00544v1 by Jacqueline Lammert, Nicole Pfarr, Leonid Kuligin, Sonja Mathes, Tobias Dreyer, Luise Modersohn, Patrick Metzger, Dyke Ferber, Jakob Nikolas Kather, Daniel Truhn, Lisa Christine Adams, Keno Kyrill Bressem, Sebastian Lange, Kristina Schwamborn, Martin Boeker, Marion Kiechle, Ulrich A. Schatz, Holger Bronger, Maximilian Tschochohei

Rare gynecological tumors (RGTs) present major clinical challenges due to
their low incidence and heterogeneity. The lack of clear guidelines leads to
suboptimal management and poor prognosis. Molecular tumor boards accelerate
access to effective therapies by tailoring treatment based on biomarkers,
beyond cancer type. Unstructured data that requires manual curation hinders
efficient use of biomarker profiling for therapy matching. This study explores
the use of large language models (LLMs) to construct digital twins for
precision medicine in RGTs.
  Our proof-of-concept digital twin system integrates clinical and biomarker
data from institutional and published cases (n=21) and literature-derived data
(n=655 publications with n=404,265 patients) to create tailored treatment plans
for metastatic uterine carcinosarcoma, identifying options potentially missed
by traditional, single-source analysis. LLM-enabled digital twins efficiently
model individual patient trajectories. Shifting to a biology-based rather than
organ-based tumor definition enables personalized care that could advance RGT
management and thus enhance patient outcomes.

摘要：罕見婦科腫瘤 (RGT) 由於其低發生率和異質性，對臨床帶來重大挑戰。缺乏明確的指引導致次佳管理和不良預後。分子腫瘤委員會透過根據生物標記客製化治療，加速取得有效療法，超越癌症類型。需要手動整理的非結構化資料阻礙了生物標記分析在療法配對中的有效使用。本研究探討使用大型語言模型 (LLM) 為 RGT 的精準醫療建構數位雙胞胎。
我們的概念驗證數位雙胞胎系統整合了來自機構和已發表的案例 (n=21) 的臨床和生物標記資料，以及來自文獻的資料 (n=655 篇出版物，n=404,265 名患者)，為轉移性子宮肉瘤癌制定客製化治療計畫，找出傳統單一來源分析可能遺漏的選項。LLM 啟用的數位雙胞胎有效地模擬個別患者的軌跡。從基於器官的腫瘤定義轉變為基於生物學的定義，能實現個人化照護，進而提升 RGT 管理並改善患者預後。

##### **Density Adaptive Attention-based Speech Network: Enhancing Feature Understanding for Mental Health Disorders**
2409.00391v1 by Georgios Ioannides, Adrian Kieback, Aman Chadha, Aaron Elkins

Speech-based depression detection poses significant challenges for automated
detection due to its unique manifestation across individuals and data scarcity.
Addressing these challenges, we introduce DAAMAudioCNNLSTM and
DAAMAudioTransformer, two parameter efficient and explainable models for audio
feature extraction and depression detection. DAAMAudioCNNLSTM features a novel
CNN-LSTM framework with multi-head Density Adaptive Attention Mechanism (DAAM),
focusing dynamically on informative speech segments. DAAMAudioTransformer,
leveraging a transformer encoder in place of the CNN-LSTM architecture,
incorporates the same DAAM module for enhanced attention and interpretability.
These approaches not only enhance detection robustness and interpretability but
also achieve state-of-the-art performance: DAAMAudioCNNLSTM with an F1 macro
score of 0.702 and DAAMAudioTransformer with an F1 macro score of 0.72 on the
DAIC-WOZ dataset, without reliance on supplementary information such as vowel
positions and speaker information during training/validation as in previous
approaches. Both models' significant explainability and efficiency in
leveraging speech signals for depression detection represent a leap towards
more reliable, clinically useful diagnostic tools, promising advancements in
speech and mental health care. To foster further research in this domain, we
make our code publicly available.

摘要：語音型憂鬱檢測對自動化檢測來說是一大挑戰，因為它在不同個體間的表現獨特，且資料稀少。為了應對這些挑戰，我們引入了 DAAMAudioCNNLSTM 和 DAAMAudioTransformer，這兩個參數有效且可解釋的模型，用於音訊特徵萃取和憂鬱檢測。DAAMAudioCNNLSTM 採用創新的 CNN-LSTM 架構，搭配多頭密度自適應注意力機制 (DAAM)，動態關注於有意義的語音區段。DAAMAudioTransformer 利用Transformer編碼器取代 CNN-LSTM 架構，並納入相同的 DAAM 模組，以增強注意力和可解釋性。這些方法不僅增強了檢測的穩健性和可解釋性，還達到了最先進的效能：DAAMAudioCNNLSTM 的 F1 巨觀分數為 0.702，DAAMAudioTransformer 在 DAIC-WOZ 資料集上的 F1 巨觀分數為 0.72，在訓練/驗證期間不依賴於輔助資訊，例如母音位置和說話者資訊，這與先前的做法不同。這兩個模型在利用語音訊號進行憂鬱檢測方面具有顯著的可解釋性和效率，代表著朝向更可靠、臨床上有用的診斷工具邁進了一大步，並預示著語音和心理保健的進步。為了促進這個領域的進一步研究，我們公開了我們的程式碼。

##### **Objective Features Extracted from Motor Activity Time Series for Food Addiction Analysis Using Machine Learning**
2409.00310v1 by Mikhail Borisenkov, Andrei Velichko, Maksim Belyaev, Dmitry Korzun, Tatyana Tserne, Larisa Bakutova, Denis Gubin

This study investigates machine learning algorithms to identify objective
features for diagnosing food addiction (FA) and assessing confirmed symptoms
(SC). Data were collected from 81 participants (mean age: 21.5 years, range:
18-61 years, women: 77.8%) whose FA and SC were measured using the Yale Food
Addiction Scale (YFAS). Participants provided demographic and anthropometric
data, completed the YFAS, the Zung Self-Rating Depression Scale, and the Dutch
Eating Behavior Questionnaire, and wore an actimeter on the non-dominant wrist
for a week to record motor activity. Analysis of the actimetric data identified
significant statistical and entropy-based features that accurately predicted FA
and SC using ML. The Matthews correlation coefficient (MCC) was the primary
metric. Activity-related features were more effective for FA prediction
(MCC=0.88) than rest-related features (MCC=0.68). For SC, activity segments
yielded MCC=0.47, rest segments MCC=0.38, and their combination MCC=0.51.
Significant correlations were also found between actimetric features related to
FA, emotional, and restrained eating behaviors, supporting the model's
validity. Our results support the concept of a human bionic suite composed of
IoT devices and ML sensors, which implements health digital assistance with
real-time monitoring and analysis of physiological indicators related to FA and
SC.

摘要：本研究調查機器學習演算法，以識別診斷食物成癮 (FA) 和評估已確認症狀 (SC) 的客觀特徵。資料來自 81 位參與者（平均年齡：21.5 歲，範圍：18-61 歲，女性：77.8%），其 FA 和 SC 是使用耶魯食物成癮量表 (YFAS) 測量的。參與者提供了人口統計和人類測量資料，完成了 YFAS、Zung 自我評量憂鬱量表和荷蘭飲食行為問卷，並在非慣用手腕上佩戴活動計一週以記錄運動活動。對活動計資料的分析識別出重要的統計和基於熵的特徵，這些特徵使用機器學習準確預測了 FA 和 SC。馬修斯相關係數 (MCC) 是主要指標。與休息相關的特徵（MCC=0.68）相比，與活動相關的特徵對於 FA 預測更有效（MCC=0.88）。對於 SC，活動區段產生的 MCC=0.47，休息區段 MCC=0.38，組合後 MCC=0.51。還發現與 FA、情緒和受限飲食行為相關的活動計特徵之間存在顯著相關性，這支持了模型的有效性。我們的結果支持由物聯網裝置和機器學習感測器組成的人體仿生套件的概念，該套件實作了健康數位協助，並對與 FA 和 SC 相關的生理指標進行即時監控和分析。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **Deep Neural Networks for Predicting Recurrence and Survival in Patients with Esophageal Cancer After Surgery**
2409.00163v1 by Yuhan Zheng, Jessie A Elliott, John V Reynolds, Sheraz R Markar, Bartłomiej W. Papież, ENSURE study group

Esophageal cancer is a major cause of cancer-related mortality
internationally, with high recurrence rates and poor survival even among
patients treated with curative-intent surgery. Investigating relevant
prognostic factors and predicting prognosis can enhance post-operative clinical
decision-making and potentially improve patients' outcomes. In this work, we
assessed prognostic factor identification and discriminative performances of
three models for Disease-Free Survival (DFS) and Overall Survival (OS) using a
large multicenter international dataset from ENSURE study. We first employed
Cox Proportional Hazards (CoxPH) model to assess the impact of each feature on
outcomes. Subsequently, we utilised CoxPH and two deep neural network
(DNN)-based models, DeepSurv and DeepHit, to predict DFS and OS. The
significant prognostic factors identified by our models were consistent with
clinical literature, with post-operative pathologic features showing higher
significance than clinical stage features. DeepSurv and DeepHit demonstrated
comparable discriminative accuracy to CoxPH, with DeepSurv slightly
outperforming in both DFS and OS prediction tasks, achieving C-index of 0.735
and 0.74, respectively. While these results suggested the potential of DNNs as
prognostic tools for improving predictive accuracy and providing personalised
guidance with respect to risk stratification, CoxPH still remains an adequately
good prediction model, with the data used in this study.

摘要：食道癌是國際間癌症相關死亡的主要原因，即使接受根治性手術的患者，復發率高且存活率低。探討相關預後因子並預測預後，可以增進術後臨床決策制定，並可能改善患者的結果。在這項工作中，我們評估了三種模型的預後因子識別和判別效能，分別針對無疾病存活期 (DFS) 和整體存活期 (OS)，使用 ENSURE 研究的大型多中心國際數據集。我們首先採用 Cox 比例風險 (CoxPH) 模型來評估每個特徵對結果的影響。隨後，我們利用 CoxPH 和兩個基於深度神經網路 (DNN) 的模型 DeepSurv 和 DeepHit 來預測 DFS 和 OS。我們的模型識別出的顯著預後因子與臨床文獻一致，術後病理特徵顯示出比臨床分期特徵更高的顯著性。DeepSurv 和 DeepHit 展現出與 CoxPH 相當的判別準確度，DeepSurv 在 DFS 和 OS 預測任務中表現略勝一籌，分別達到 C 指數 0.735 和 0.74。雖然這些結果表明 DNN 作為預後工具的潛力，可以提高預測準確度並針對風險分層提供個人化指導，但 CoxPH 仍然是足夠好的預測模型，使用本研究中的數據。

##### **NDP: Next Distribution Prediction as a More Broad Target**
2408.17377v1 by Junhao Ruan, Abudukeyumu Abudula, Xinyu Liu, Bei Li, Yinqiao Li, Chenglong Wang, Yuchun Fan, Yuan Ge, Tong Xiao, Jingbo Zhu

Large language models (LLMs) trained on next-token prediction (NTP) paradigm
have demonstrated powerful capabilities. However, the existing NTP paradigm
contains several limitations, particularly related to planned task
complications and error propagation during inference. In our work, we extend
the critique of NTP, highlighting its limitation also due to training with a
narrow objective: the prediction of a sub-optimal one-hot distribution. To
support this critique, we conducted a pre-experiment treating the output
distribution from powerful LLMs as efficient world data compression. By
evaluating the similarity between the $n$-gram distribution and the one-hot
distribution with LLMs, we observed that the $n$-gram distributions align more
closely with the output distribution of LLMs. Based on this insight, we
introduce Next Distribution Prediction (NDP), which uses $n$-gram distributions
to replace the one-hot targets, enhancing learning without extra online
training time. We conducted experiments across translation, general task,
language transfer, and medical domain adaptation. Compared to NTP, NDP can
achieve up to +2.97 COMET improvement in translation tasks, +0.61 average
improvement in general tasks, and incredible +10.75 average improvement in the
medical domain. This demonstrates the concrete benefits of addressing the
target narrowing problem, pointing to a new direction for future work on
improving NTP.

摘要：大型語言模型 (LLM) 根據下一個符號預測 (NTP) 範例進行訓練，已展現強大的功能。然而，現有的 NTP 範例包含了幾個限制，特別是與計畫任務複雜性和推論期間的錯誤傳播有關。在我們的研究中，我們擴展了 NTP 的批判，強調其限制也由於使用狹隘的目標進行訓練：預測次佳的一熱分佈。為了支持這項批判，我們進行了一個前置實驗，將強大 LLM 的輸出分佈視為有效的世界資料壓縮。透過評估 $n$-gram 分佈與 LLM 的一熱分佈之間的相似性，我們觀察到 $n$-gram 分佈與 LLM 的輸出分佈更為接近。基於這個見解，我們引入了下一個分佈預測 (NDP)，它使用 $n$-gram 分佈來取代一熱目標，在沒有額外線上訓練時間的情況下，加強學習。我們進行了翻譯、一般任務、語言轉移和醫學領域適應的實驗。與 NTP 相比，NDP 在翻譯任務中可以達到 +2.97 COMET 改進，在一般任務中平均改進 +0.61，在醫學領域中令人難以置信的平均改進 +10.75。這證明了解決目標收窄問題的具體好處，指出了改進 NTP 未來工作的全新方向。

##### **Disease Classification and Impact of Pretrained Deep Convolution Neural Networks on Diverse Medical Imaging Datasets across Imaging Modalities**
2408.17011v2 by Jutika Borah, Kumaresh Sarmah, Hidam Kumarjit Singh

Imaging techniques such as Chest X-rays, whole slide images, and optical
coherence tomography serve as the initial screening and detection for a wide
variety of medical pulmonary and ophthalmic conditions respectively. This paper
investigates the intricacies of using pretrained deep convolutional neural
networks with transfer learning across diverse medical imaging datasets with
varying modalities for binary and multiclass classification. We conducted a
comprehensive performance analysis with ten network architectures and model
families each with pretraining and random initialization. Our finding showed
that the use of pretrained models as fixed feature extractors yields poor
performance irrespective of the datasets. Contrary, histopathology microscopy
whole slide images have better performance. It is also found that deeper and
more complex architectures did not necessarily result in the best performance.
This observation implies that the improvements in ImageNet are not parallel to
the medical imaging tasks. Within a medical domain, the performance of the
network architectures varies within model families with shifts in datasets.
This indicates that the performance of models within a specific modality may
not be conclusive for another modality within the same domain. This study
provides a deeper understanding of the applications of deep learning techniques
in medical imaging and highlights the impact of pretrained networks across
different medical imaging datasets under five different experimental settings.

摘要：影像技術，例如胸部 X 光、全切片影像和光學相干斷層掃描，分別作為各種醫學肺部和眼科疾病的初步篩檢和偵測。本文探討了使用預訓練深度卷積神經網路搭配遷移學習，橫跨不同醫療影像資料集，以進行二元和多類別分類的複雜性。我們對十種網路架構和模型系列進行了全面的效能分析，每個架構和系列都經過預訓練和隨機初始化。我們的發現顯示，將預訓練模型用作固定特徵萃取器會產生不佳的效能，與資料集無關。相反地，組織病理學顯微鏡全切片影像有較好的效能。我們也發現，較深且複雜的架構並非一定會產生最佳效能。此觀察結果意味著 ImageNet 的改良並未與醫療影像任務平行。在醫療領域內，網路架構的效能會隨著資料集的轉換而改變模型系列。這表示在特定模式中模型的效能可能無法決定在同一個領域中另一種模式的效能。本研究提供了對深度學習技術在醫療影像中的應用更深入的理解，並強調了預訓練網路在五種不同實驗設定下跨不同醫療影像資料集的影響。

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Toward Robust Early Detection of Alzheimer's Disease via an Integrated Multimodal Learning Approach**
2408.16343v1 by Yifei Chen, Shenghao Zhu, Zhaojie Fang, Chang Liu, Binfeng Zou, Yuhe Wang, Shuo Chang, Fan Jia, Feiwei Qin, Jin Fan, Yong Peng, Changmiao Wang

Alzheimer's Disease (AD) is a complex neurodegenerative disorder marked by
memory loss, executive dysfunction, and personality changes. Early diagnosis is
challenging due to subtle symptoms and varied presentations, often leading to
misdiagnosis with traditional unimodal diagnostic methods due to their limited
scope. This study introduces an advanced multimodal classification model that
integrates clinical, cognitive, neuroimaging, and EEG data to enhance
diagnostic accuracy. The model incorporates a feature tagger with a tabular
data coding architecture and utilizes the TimesBlock module to capture
intricate temporal patterns in Electroencephalograms (EEG) data. By employing
Cross-modal Attention Aggregation module, the model effectively fuses Magnetic
Resonance Imaging (MRI) spatial information with EEG temporal data,
significantly improving the distinction between AD, Mild Cognitive Impairment,
and Normal Cognition. Simultaneously, we have constructed the first AD
classification dataset that includes three modalities: EEG, MRI, and tabular
data. Our innovative approach aims to facilitate early diagnosis and
intervention, potentially slowing the progression of AD. The source code and
our private ADMC dataset are available at https://github.com/JustlfC03/MSTNet.

摘要：阿茲海默症 (AD) 是一種複雜的神經退化性疾病，特徵是記憶力喪失、執行功能障礙和人格改變。由於症狀微妙且表現形式多樣，早期診斷具有挑戰性，通常由於傳統單模態診斷方法的範圍有限而導致誤診。本研究引入了一個先進的多模態分類模型，它整合了臨床、認知、神經影像和腦電圖數據，以提高診斷準確性。該模型結合了一個具有表格數據編碼架構的特徵標籤器，並利用 TimesBlock 模組來捕捉腦電圖 (EEG) 數據中的複雜時間模式。通過採用跨模態注意力聚合模組，該模型有效地融合了磁共振成像 (MRI) 空間資訊和腦電圖時間數據，顯著改善了 AD、輕度認知障礙和正常認知之間的區別。同時，我們構建了第一個 AD 分類數據集，其中包含三種模態：腦電圖、磁共振成像和表格數據。我們的創新方法旨在促進早期診斷和干預，潛在地減緩 AD 的進展。原始碼和我們的私人 ADMC 數據集可在 https://github.com/JustlfC03/MSTNet 獲得。

##### **Coalitions of AI-based Methods Predict 15-Year Risks of Breast Cancer Metastasis Using Real-World Clinical Data with AUC up to 0.9**
2408.16256v1 by Xia Jiang, Yijun Zhou, Alan Wells, Adam Brufsky

Breast cancer is one of the two cancers responsible for the most deaths in
women, with about 42,000 deaths each year in the US. That there are over
300,000 breast cancers newly diagnosed each year suggests that only a fraction
of the cancers result in mortality. Thus, most of the women undergo seemingly
curative treatment for localized cancers, but a significant later succumb to
metastatic disease for which current treatments are only temporizing for the
vast majority. The current prognostic metrics are of little actionable value
for 4 of the 5 women seemingly cured after local treatment, and many women are
exposed to morbid and even mortal adjuvant therapies unnecessarily, with these
adjuvant therapies reducing metastatic recurrence by only a third. Thus, there
is a need for better prognostics to target aggressive treatment at those who
are likely to relapse and spare those who were actually cured. While there is a
plethora of molecular and tumor-marker assays in use and under-development to
detect recurrence early, these are time consuming, expensive and still often
un-validated as to actionable prognostic utility. A different approach would
use large data techniques to determine clinical and histopathological
parameters that would provide accurate prognostics using existing data. Herein,
we report on machine learning, together with grid search and Bayesian Networks
to develop algorithms that present a AUC of up to 0.9 in ROC analyses, using
only extant data. Such algorithms could be rapidly translated to clinical
management as they do not require testing beyond routine tumor evaluations.

摘要：乳癌是造成女性死亡人數最多的兩種癌症之一，每年約有 42,000 名女性死於乳癌。每年有超過 300,000 例乳癌新確診，這表示只有少部分癌症會導致死亡。因此，大多數女性接受局部癌症的根治性治療，但許多人後來仍會死於轉移性疾病，而目前的治療方法對絕大多數患者來說只是暫時的。目前的預後指標對於 5 名接受局部治療後看似治癒的女性中，有 4 名幾乎沒有實際價值，許多女性不必要地接受病態甚至致命的輔助療法，而這些輔助療法僅能將轉移性復發率降低三分之一。因此，需要更好的預後指標，才能針對那些可能復發的人進行積極治療，並避免那些實際上已經治癒的人接受治療。雖然有許多分子和腫瘤標記檢測方法正在使用和開發中，可以及早發現復發，但這些方法耗時、昂貴，而且作為可操作的預後工具，其效用仍然常常未經驗證。另一種方法會使用大量的資料技術，來確定臨床和組織病理學參數，並使用現有資料提供準確的預後指標。在此，我們報告了機器學習，以及網格搜尋和貝氏網路，用來開發演算法，在 ROC 分析中提供高達 0.9 的 AUC，僅使用現有資料。此類演算法可以快速轉換為臨床管理，因為它們不需要進行常規腫瘤評估以外的測試。

##### **M4CXR: Exploring Multi-task Potentials of Multi-modal Large Language Models for Chest X-ray Interpretation**
2408.16213v1 by Jonggwon Park, Soobum Kim, Byungmu Yoon, Jihun Hyun, Kyoyun Choi

The rapid evolution of artificial intelligence, especially in large language
models (LLMs), has significantly impacted various domains, including
healthcare. In chest X-ray (CXR) analysis, previous studies have employed LLMs,
but with limitations: either underutilizing the multi-tasking capabilities of
LLMs or lacking clinical accuracy. This paper presents M4CXR, a multi-modal LLM
designed to enhance CXR interpretation. The model is trained on a visual
instruction-following dataset that integrates various task-specific datasets in
a conversational format. As a result, the model supports multiple tasks such as
medical report generation (MRG), visual grounding, and visual question
answering (VQA). M4CXR achieves state-of-the-art clinical accuracy in MRG by
employing a chain-of-thought prompting strategy, in which it identifies
findings in CXR images and subsequently generates corresponding reports. The
model is adaptable to various MRG scenarios depending on the available inputs,
such as single-image, multi-image, and multi-study contexts. In addition to
MRG, M4CXR performs visual grounding at a level comparable to specialized
models and also demonstrates outstanding performance in VQA. Both quantitative
and qualitative assessments reveal M4CXR's versatility in MRG, visual
grounding, and VQA, while consistently maintaining clinical accuracy.

摘要：人工智慧的快速發展，特別是在大型語言模型 (LLM) 中，已對包括醫療保健在內的各個領域產生重大影響。在胸部 X 光 (CXR) 分析中，先前的研究已採用 LLM，但有其限制：不是未能充分利用 LLM 的多任務處理能力，就是缺乏臨床準確性。本文提出 M4CXR，一種多模態 LLM，旨在增強 CXR 解釋。該模型訓練於視覺指令遵循資料集，其中以對話格式整合各種特定任務資料集。因此，該模型支援多項任務，例如醫療報告產生 (MRG)、視覺基礎和視覺問題回答 (VQA)。M4CXR 透過採用思考鏈提示策略，在 MRG 中達成最先進的臨床準確性，其中它會識別 CXR 影像中的發現，並隨後產生對應的報告。該模型可根據可用輸入（例如單一影像、多重影像和多重研究脈絡）適應各種 MRG 情境。除了 MRG 之外，M4CXR 以與專門模型相當的層級執行視覺基礎，並在 VQA 中展現出色的效能。定量和定性評估均顯示出 M4CXR 在 MRG、視覺基礎和 VQA 中的多功能性，同時持續維持臨床準確性。

##### **A Survey on Evaluation of Multimodal Large Language Models**
2408.15769v1 by Jiaxing Huang, Jingyi Zhang

Multimodal Large Language Models (MLLMs) mimic human perception and reasoning
system by integrating powerful Large Language Models (LLMs) with various
modality encoders (e.g., vision, audio), positioning LLMs as the "brain" and
various modality encoders as sensory organs. This framework endows MLLMs with
human-like capabilities, and suggests a potential pathway towards achieving
artificial general intelligence (AGI). With the emergence of all-round MLLMs
like GPT-4V and Gemini, a multitude of evaluation methods have been developed
to assess their capabilities across different dimensions. This paper presents a
systematic and comprehensive review of MLLM evaluation methods, covering the
following key aspects: (1) the background of MLLMs and their evaluation; (2)
"what to evaluate" that reviews and categorizes existing MLLM evaluation tasks
based on the capabilities assessed, including general multimodal recognition,
perception, reasoning and trustworthiness, and domain-specific applications
such as socioeconomic, natural sciences and engineering, medical usage, AI
agent, remote sensing, video and audio processing, 3D point cloud analysis, and
others; (3) "where to evaluate" that summarizes MLLM evaluation benchmarks into
general and specific benchmarks; (4) "how to evaluate" that reviews and
illustrates MLLM evaluation steps and metrics; Our overarching goal is to
provide valuable insights for researchers in the field of MLLM evaluation,
thereby facilitating the development of more capable and reliable MLLMs. We
emphasize that evaluation should be regarded as a critical discipline,
essential for advancing the field of MLLMs.

摘要：多模態大型語言模型 (MLLM) 透過整合強大的大型語言模型 (LLM) 與各種模態編碼器（例如視覺、音訊），模擬人類的感知和推理系統，將 LLM 定位為「大腦」，而將各種模態編碼器定位為感官器官。此架構賦予 MLLM 類似人類的能力，並提出實現人工通用智慧 (AGI) 的潛在途徑。隨著 GPT-4V 和 Gemini 等全方位 MLLM 的出現，已經開發出多種評估方法來評估它們在不同維度上的能力。本文對 MLLM 評估方法進行了系統且全面的回顧，涵蓋以下幾個關鍵面向：(1) MLLM 及其評估的背景；(2)「要評估什麼」根據評估的能力，回顧並分類現有的 MLLM 評估任務，包括一般多模態辨識、感知、推理和可信度，以及特定領域的應用，例如社會經濟、自然科學和工程、醫療用途、AI 代理、遙測、影片和音訊處理、3D 點雲分析等；(3)「在哪裡評估」將 MLLM 評估基準總結為一般基準和特定基準；(4)「如何評估」回顧並說明 MLLM 評估步驟和指標。我們的首要目標是為 MLLM 評估領域的研究人員提供有價值的見解，從而促進更強大且可靠的 MLLM 的開發。我們強調評估應被視為一項關鍵的學科，對於推進 MLLM 領域至關重要。

##### **Deep Learning to Predict Late-Onset Breast Cancer Metastasis: the Single Hyperparameter Grid Search (SHGS) Strategy for Meta Tuning Concerning Deep Feed-forward Neural Network**
2408.15498v1 by Yijun Zhou, Om Arora-Jain, Xia Jiang

While machine learning has advanced in medicine, its widespread use in
clinical applications, especially in predicting breast cancer metastasis, is
still limited. We have been dedicated to constructing a DFNN model to predict
breast cancer metastasis n years in advance. However, the challenge lies in
efficiently identifying optimal hyperparameter values through grid search,
given the constraints of time and resources. Issues such as the infinite
possibilities for continuous hyperparameters like l1 and l2, as well as the
time-consuming and costly process, further complicate the task. To address
these challenges, we developed Single Hyperparameter Grid Search (SHGS)
strategy, serving as a preselection method before grid search. Our experiments
with SHGS applied to DFNN models for breast cancer metastasis prediction focus
on analyzing eight target hyperparameters: epochs, batch size, dropout, L1, L2,
learning rate, decay, and momentum. We created three figures, each depicting
the experiment results obtained from three LSM-I-10-Plus-year datasets. These
figures illustrate the relationship between model performance and the target
hyperparameter values. For each hyperparameter, we analyzed whether changes in
this hyperparameter would affect model performance, examined if there were
specific patterns, and explored how to choose values for the particular
hyperparameter. Our experimental findings reveal that the optimal value of a
hyperparameter is not only dependent on the dataset but is also significantly
influenced by the settings of other hyperparameters. Additionally, our
experiments suggested some reduced range of values for a target hyperparameter,
which may be helpful for low-budget grid search. This approach serves as a
prior experience and foundation for subsequent use of grid search to enhance
model performance.

摘要：儘管機器學習在醫學領域已有所進展，但其在臨床應用中的廣泛使用，特別是在預測乳癌轉移方面，仍有其限制。我們致力於建構 DFNN 模型，以預測乳癌轉移 n 年。然而，挑戰在於透過網格搜尋有效率地找出最佳超參數值，這受到時間和資源的限制。諸如 l1 和 l2 等連續超參數的可能性無窮，以及耗時且昂貴的過程等問題，更讓這項任務變得複雜。為了應對這些挑戰，我們開發了單一超參數網格搜尋 (SHGS) 策略，作為網格搜尋前的預選方法。我們針對乳癌轉移預測應用的 DFNN 模型進行 SHGS 實驗，重點分析八個目標超參數：epoch 次數、批次大小、中斷、L1、L2、學習率、衰減和動量。我們製作了三幅圖，每幅圖都描繪了從三個 LSM-I-10-Plus-year 資料集獲得的實驗結果。這些圖表說明了模型效能與目標超參數值之間的關係。對於每個超參數，我們分析了超參數的變動是否會影響模型效能，並檢視是否有特定模式，以及如何針對特定超參數選擇值。我們的實驗結果顯示，超參數的最佳值不僅取決於資料集，也受到其他超參數設定的顯著影響。此外，我們的實驗建議縮小目標超參數值的範圍，這可能有助於低預算的網格搜尋。此方法可作為後續使用網格搜尋以增強模型效能的先前經驗和基礎。

##### **What Is Required for Empathic AI? It Depends, and Why That Matters for AI Developers and Users**
2408.15354v1 by Jana Schaich Borg, Hannah Read

Interest is growing in artificial empathy, but so is confusion about what
artificial empathy is or needs to be. This confusion makes it challenging to
navigate the technical and ethical issues that accompany empathic AI
development. Here, we outline a framework for thinking about empathic AI based
on the premise that different constellations of capabilities associated with
empathy are important for different empathic AI applications. We describe
distinctions of capabilities that we argue belong under the empathy umbrella,
and show how three medical empathic AI use cases require different sets of
these capabilities. We conclude by discussing why appreciation of the diverse
capabilities under the empathy umbrella is important for both AI creators and
users.

摘要：對人工同理心越來越感興趣，但對於人工同理心是什麼或需要什麼也越來越困惑。這種混淆使得難以解決伴隨同理心 AI 開發而來的技術和倫理問題。在此，我們概述了一個思考同理心 AI 的架構，其基於這樣一個前提：與同理心相關的不同能力組合對於不同的同理心 AI 應用很重要。我們描述了我們認為屬於同理心範疇的能力區別，並展示了三個醫療同理心 AI 使用案例需要這些能力的不同組合。我們最後討論了為什麼欣賞同理心範疇下的各種能力對於 AI 創造者和使用者都很重要的原因。

##### **Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance**
2408.15217v1 by Weiyi Zhang, Siyu Huang, Jiancheng Yang, Ruoyu Chen, Zongyuan Ge, Yingfeng Zheng, Danli Shi, Mingguang He

Fundus Fluorescein Angiography (FFA) is a critical tool for assessing retinal
vascular dynamics and aiding in the diagnosis of eye diseases. However, its
invasive nature and less accessibility compared to Color Fundus (CF) images
pose significant challenges. Current CF to FFA translation methods are limited
to static generation. In this work, we pioneer dynamic FFA video generation
from static CF images. We introduce an autoregressive GAN for smooth,
memory-saving frame-by-frame FFA synthesis. To enhance the focus on dynamic
lesion changes in FFA regions, we design a knowledge mask based on clinical
experience. Leveraging this mask, our approach integrates innovative knowledge
mask-guided techniques, including knowledge-boosted attention, knowledge-aware
discriminators, and mask-enhanced patchNCE loss, aimed at refining generation
in critical areas and addressing the pixel misalignment challenge. Our method
achieves the best FVD of 1503.21 and PSNR of 11.81 compared to other common
video generation approaches. Human assessment by an ophthalmologist confirms
its high generation quality. Notably, our knowledge mask surpasses supervised
lesion segmentation masks, offering a promising non-invasive alternative to
traditional FFA for research and clinical applications. The code is available
at https://github.com/Michi-3000/Fundus2Video.

摘要：眼底螢光血管攝影 (FFA) 是評估視網膜血管動力學和協助診斷眼疾的重要工具。然而，與彩色眼底 (CF) 影像相比，其侵入性較高且取得不易，因此造成重大挑戰。目前 CF 轉換成 FFA 的翻譯方法僅限於靜態產生。在這項工作中，我們率先從靜態 CF 影像產生動態 FFA 影片。我們引入一個自迴歸 GAN，以進行流暢且節省記憶體的逐幀 FFA 合成。為了加強對 FFA 區域中動態病灶變化的關注，我們根據臨床經驗設計了一個知識遮罩。透過利用這個遮罩，我們的做法整合了創新的知識遮罩引導技術，包括知識增強的注意力、知識感知的辨別器以及遮罩增強的 patchNCE 損失，旨在改善關鍵區域的生成並解決像素未對齊的挑戰。與其他常見的影片生成方法相比，我們的做法達到了最佳的 FVD 1503.21 和 PSNR 11.81。眼科醫師的人為評估證實了其生成品質很高。值得注意的是，我們的知識遮罩超越了有監督的病灶分割遮罩，為傳統 FFA 提供了一個有前途的非侵入性替代方案，可用於研究和臨床應用。程式碼可在 https://github.com/Michi-3000/Fundus2Video 取得。

##### **Toward Large Language Models as a Therapeutic Tool: Comparing Prompting Techniques to Improve GPT-Delivered Problem-Solving Therapy**
2409.00112v1 by Daniil Filienko, Yinzhou Wang, Caroline El Jazmi, Serena Xie, Trevor Cohen, Martine De Cock, Weichao Yuwen

While Large Language Models (LLMs) are being quickly adapted to many domains,
including healthcare, their strengths and pitfalls remain under-explored. In
our study, we examine the effects of prompt engineering to guide Large Language
Models (LLMs) in delivering parts of a Problem-Solving Therapy (PST) session
via text, particularly during the symptom identification and assessment phase
for personalized goal setting. We present evaluation results of the models'
performances by automatic metrics and experienced medical professionals. We
demonstrate that the models' capability to deliver protocolized therapy can be
improved with the proper use of prompt engineering methods, albeit with
limitations. To our knowledge, this study is among the first to assess the
effects of various prompting techniques in enhancing a generalist model's
ability to deliver psychotherapy, focusing on overall quality, consistency, and
empathy. Exploring LLMs' potential in delivering psychotherapy holds promise
with the current shortage of mental health professionals amid significant
needs, enhancing the potential utility of AI-based and AI-enhanced care
services.

摘要：隨著大型語言模型（LLM）快速適應於許多領域，包括醫療保健，它們的優勢和缺陷仍未得到充分探索。在我們的研究中，我們探討了提示工程在引導大型語言模型（LLM）通過文字提供問題解決療法（PST）環節的部分內容的效果，特別是在症狀識別和評估階段，用於個性化目標設定。我們通過自動化指標和經驗豐富的醫療專業人員展示了模型性能的評估結果。我們證明了模型提供程式化治療的能力可以使用提示工程方法適當使用來改進，儘管有局限性。據我們所知，這項研究是第一批評估各種提示技術對增強通才模型提供心理治療能力的影響的研究之一，重點關注整體品質、一致性和同理心。在心理健康專業人員嚴重短缺且需求巨大的情況下，探索 LLM 在提供心理治療方面的潛力很有前景，增強了基於 AI 和 AI 增強的護理服務的潛在效用。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **MiWaves Reinforcement Learning Algorithm**
2408.15076v1 by Susobhan Ghosh, Yongyi Guo, Pei-Yao Hung, Lara Coughlin, Erin Bonar, Inbal Nahum-Shani, Maureen Walton, Susan Murphy

The escalating prevalence of cannabis use poses a significant public health
challenge globally. In the U.S., cannabis use is more prevalent among emerging
adults (EAs) (ages 18-25) than any other age group, with legalization in the
multiple states contributing to a public perception that cannabis is less risky
than in prior decades. To address this growing concern, we developed MiWaves, a
reinforcement learning (RL) algorithm designed to optimize the delivery of
personalized intervention prompts to reduce cannabis use among EAs. MiWaves
leverages domain expertise and prior data to tailor the likelihood of delivery
of intervention messages. This paper presents a comprehensive overview of the
algorithm's design, including key decisions and experimental outcomes. The
finalized MiWaves RL algorithm was deployed in a clinical trial from March to
May 2024.

摘要：大麻使用率不斷上升，對全球公共衛生構成重大挑戰。在美國，大麻使用率在年輕成年人（EA）（18-25 歲）中比任何其他年齡組都要普遍，多個州的合法化導致公眾認為大麻比過去幾十年風險較低。為了解決這個日益嚴重的問題，我們開發了 MiWaves，這是一種增強學習 (RL) 演算法，旨在優化個性化干預提示的傳遞，以減少 EA 中的大麻使用。MiWaves 利用領域專業知識和先前的數據來調整干預訊息傳遞的可能性。本文全面概述了演算法的設計，包括關鍵決策和實驗結果。最終的 MiWaves RL 演算法已於 2024 年 3 月至 5 月在臨床試驗中部署。

##### **Mamba2MIL: State Space Duality Based Multiple Instance Learning for Computational Pathology**
2408.15032v1 by Yuqi Zhang, Xiaoqian Zhang, Jiakai Wang, Yuancheng Yang, Taiying Peng, Chao Tong

Computational pathology (CPath) has significantly advanced the clinical
practice of pathology. Despite the progress made, Multiple Instance Learning
(MIL), a promising paradigm within CPath, continues to face challenges,
particularly related to incomplete information utilization. Existing
frameworks, such as those based on Convolutional Neural Networks (CNNs),
attention, and selective scan space state sequential model (SSM), lack
sufficient flexibility and scalability in fusing diverse features, and cannot
effectively fuse diverse features. Additionally, current approaches do not
adequately exploit order-related and order-independent features, resulting in
suboptimal utilization of sequence information. To address these limitations,
we propose a novel MIL framework called Mamba2MIL. Our framework utilizes the
state space duality model (SSD) to model long sequences of patches of whole
slide images (WSIs), which, combined with weighted feature selection, supports
the fusion processing of more branching features and can be extended according
to specific application needs. Moreover, we introduce a sequence transformation
method tailored to varying WSI sizes, which enhances sequence-independent
features while preserving local sequence information, thereby improving
sequence information utilization. Extensive experiments demonstrate that
Mamba2MIL surpasses state-of-the-art MIL methods. We conducted extensive
experiments across multiple datasets, achieving improvements in nearly all
performance metrics. Specifically, on the NSCLC dataset, Mamba2MIL achieves a
binary tumor classification AUC of 0.9533 and an accuracy of 0.8794. On the
BRACS dataset, it achieves a multiclass classification AUC of 0.7986 and an
accuracy of 0.4981. The code is available at
https://github.com/YuqiZhang-Buaa/Mamba2MIL.

摘要：<paragraph>計算病理學 (CPath) 已顯著提升病理學的臨床實務。儘管已有進展，作為 CPath 中一個有前途的範例，多重實例學習 (MIL) 持續面臨挑戰，特別是與不完整資訊使用有關。現有的架構，例如基於卷積神經網路 (CNN)、注意力和選擇性掃描空間狀態序列模型 (SSM) 的架構，在融合各種特徵時缺乏足夠的彈性和可擴充性，且無法有效融合各種特徵。此外，目前的作法並未充分利用與順序相關和與順序無關的特徵，導致序列資訊使用率不佳。為了解決這些限制，我們提出一個名為 Mamba2MIL 的新 MIL 架構。我們的架構利用狀態空間對偶模型 (SSD) 來建模全幻燈片影像 (WSI) 的長序列貼片，這與加權特徵選取結合使用，支援更多分支特徵的融合處理，且可根據特定應用需求進行延伸。此外，我們引入一種針對不同 WSI 大小量身打造的序列轉換方法，這增強了與序列無關的特徵，同時保留了局部序列資訊，進而改善序列資訊使用率。廣泛的實驗證明 Mamba2MIL 超越了最先進的 MIL 方法。我們在多個資料集上進行廣泛的實驗，在幾乎所有效能指標上均獲得改善。特別是在 NSCLC 資料集上，Mamba2MIL 達到 0.9533 的二元腫瘤分類 AUC 和 0.8794 的準確度。在 BRACS 資料集上，它達到 0.7986 的多類別分類 AUC 和 0.4981 的準確度。程式碼可在 https://github.com/YuqiZhang-Buaa/Mamba2MIL 取得。</paragraph>

##### **Sequence-aware Pre-training for Echocardiography Probe Guidance**
2408.15026v1 by Haojun Jiang, Zhenguo Sun, Yu Sun, Ning Jia, Meng Li, Shaqi Luo, Shiji Song, Gao Huang

Cardiac ultrasound probe guidance aims to help novices adjust the 6-DOF probe
pose to obtain high-quality sectional images. Cardiac ultrasound faces two
major challenges: (1) the inherently complex structure of the heart, and (2)
significant individual variations. Previous works have only learned the
population-averaged 2D and 3D structures of the heart rather than personalized
cardiac structural features, leading to a performance bottleneck. Clinically,
we observed that sonographers adjust their understanding of a patient's cardiac
structure based on prior scanning sequences, thereby modifying their scanning
strategies. Inspired by this, we propose a sequence-aware self-supervised
pre-training method. Specifically, our approach learns personalized 2D and 3D
cardiac structural features by predicting the masked-out images and actions in
a scanning sequence. We hypothesize that if the model can predict the missing
content it has acquired a good understanding of the personalized cardiac
structure. In the downstream probe guidance task, we also introduced a sequence
modeling approach that models individual cardiac structural information based
on the images and actions from historical scan data, enabling more accurate
navigation decisions. Experiments on a large-scale dataset with 1.36 million
samples demonstrated that our proposed sequence-aware paradigm can
significantly reduce navigation errors, with translation errors decreasing by
15.90% to 36.87% and rotation errors decreasing by 11.13% to 20.77%, compared
to state-of-the-art methods.

摘要：<paragraph>心臟超音波探頭引導旨在幫助新手調整 6-DOF 探頭姿勢，以取得高品質的斷面影像。心臟超音波面臨兩項主要挑戰：(1) 心臟結構複雜且固有，以及 (2) 個體差異顯著。先前的研究僅學習了整體平均的 2D 和 3D 心臟結構，而非個人化的解剖特徵，導致效能瓶頸。臨床上，我們觀察到超音波技師會根據先前的掃描序列調整他們對患者心臟結構的理解，進而修改他們的掃描策略。受到此啟發，我們提出一個具序列感知的自監督預訓練方法。具體來說，我們的做法透過預測掃描序列中遮罩的影像和動作，來學習個人化的 2D 和 3D 心臟解剖特徵。我們假設，如果模型可以預測遺漏的內容，它便對個人化的解剖結構有了良好的理解。在下游的探頭引導任務中，我們也導入一個序列建模方法，該方法根據歷史掃描資料中的影像和動作，模擬個別心臟解剖資訊，進而做出更精確的導航決策。在有 136 萬個樣本的大規模資料集上進行的實驗證明，我們提出的具序列感知的典範可以大幅減少導航錯誤，其中平移錯誤減少了 15.90% 至 36.87%，旋轉錯誤減少了 11.13% 至 20.77%，與最先進的方法相比。</paragraph>

##### **Evaluating the Predictive Features of Person-Centric Knowledge Graph Embeddings: Unfolding Ablation Studies**
2408.15294v2 by Christos Theodoropoulos, Natasha Mulligan, Joao Bettencourt-Silva

Developing novel predictive models with complex biomedical information is
challenging due to various idiosyncrasies related to heterogeneity,
standardization or sparseness of the data. We previously introduced a
person-centric ontology to organize information about individual patients, and
a representation learning framework to extract person-centric knowledge graphs
(PKGs) and to train Graph Neural Networks (GNNs). In this paper, we propose a
systematic approach to examine the results of GNN models trained with both
structured and unstructured information from the MIMIC-III dataset. Through
ablation studies on different clinical, demographic, and social data, we show
the robustness of this approach in identifying predictive features in PKGs for
the task of readmission prediction.

摘要：開發具有複雜生物醫學資訊的新穎預測模型，由於資料的異質性、標準化或稀疏性，因此具有挑戰性。我們先前介紹了一個以人為中心的本體，用於組織有關個別患者的資訊，以及一個表示學習架構，用於提取以人為中心的知識圖譜 (PKG) 和訓練圖形神經網路 (GNN)。在本文中，我們提出了一種系統性的方法來檢驗使用 MIMIC-III 資料集中的結構化和非結構化資訊訓練的 GNN 模型的結果。透過對不同的臨床、人口統計和社會資料進行消融研究，我們展示了這種方法在識別 PKG 中的預測特徵以進行再入院預測任務時的穩健性。

##### **Sequential-Scanning Dual-Energy CT Imaging Using High Temporal Resolution Image Reconstruction and Error-Compensated Material Basis Image Generation**
2408.14754v1 by Qiaoxin Li, Ruifeng Chen, Peng Wang, Guotao Quan, Yanfeng Du, Dong Liang, Yinsheng Li

Dual-energy computed tomography (DECT) has been widely used to obtain
quantitative elemental composition of imaged subjects for personalized and
precise medical diagnosis. Compared with DECT leveraging advanced X-ray source
and/or detector technologies, the use of the sequential-scanning data
acquisition scheme to implement DECT may make a broader impact on clinical
practice because this scheme requires no specialized hardware designs and can
be directly implemented into conventional CT systems. However, since the
concentration of iodinated contrast agent in the imaged subject varies over
time, sequentially scanned data sets acquired at two tube potentials are
temporally inconsistent. As existing material basis image reconstruction
approaches assume that the data sets acquired at two tube potentials are
temporally consistent, the violation of this assumption results in inaccurate
quantification of material concentration. In this work, we developed
sequential-scanning DECT imaging using high temporal resolution image
reconstruction and error-compensated material basis image generation,
ACCELERATION in short, to address the technical challenge induced by temporal
inconsistency of sequentially scanned data sets and improve quantification
accuracy of material concentration in sequential-scanning DECT. ACCELERATION
has been validated and evaluated using numerical simulation data sets generated
from clinical human subject exams and experimental human subject studies.
Results demonstrated the improvement of quantification accuracy and image
quality using ACCELERATION.

摘要：雙能量電腦斷層掃描 (DECT) 已廣泛用於取得影像化受試者的定量元素組成，以進行個人化且精確的醫療診斷。與使用進階 X 光源和/或偵測器技術的 DECT 相比，使用連續掃描資料擷取方案來實作 DECT 可能對臨床實務產生更廣泛的影響，因為此方案不需要專門的硬體設計，且可直接實作到傳統 CT 系統中。然而，由於影像化受試者中碘化對比劑的濃度會隨時間而變化，因此在兩個管電位下擷取的連續掃描資料集在時間上並不一致。由於現有的材料基礎影像重建方法假設在兩個管電位下擷取的資料集在時間上是一致的，因此違反此假設會導致材料濃度的量化不準確。在這項工作中，我們開發了使用高時間解析度影像重建和誤差補償材料基礎影像產生的連續掃描 DECT 影像，簡稱 ACCELERATION，以解決連續掃描資料集時間不一致所引發的技術挑戰，並改善連續掃描 DECT 中材料濃度的量化準確度。ACCELERATION 已使用從臨床人體受試者檢查和實驗人體受試者研究產生的數值模擬資料集進行驗證和評估。結果證明使用 ACCELERATION 可改善量化準確度和影像品質。

##### **Large Language Models for Disease Diagnosis: A Scoping Review**
2409.00097v1 by Shuang Zhou, Zidu Xu, Mian Zhang, Chunpu Xu, Yawen Guo, Zaifu Zhan, Sirui Ding, Jiashuo Wang, Kaishuai Xu, Yi Fang, Liqiao Xia, Jeremy Yeung, Daochen Zha, Mingquan Lin, Rui Zhang

Automatic disease diagnosis has become increasingly valuable in clinical
practice. The advent of large language models (LLMs) has catalyzed a paradigm
shift in artificial intelligence, with growing evidence supporting the efficacy
of LLMs in diagnostic tasks. Despite the growing attention in this field, many
critical research questions remain under-explored. For instance, what diseases
and LLM techniques have been investigated for diagnostic tasks? How can
suitable LLM techniques and evaluation methods be selected for clinical
decision-making? To answer these questions, we performed a comprehensive
analysis of LLM-based methods for disease diagnosis. This scoping review
examined the types of diseases, associated organ systems, relevant clinical
data, LLM techniques, and evaluation methods reported in existing studies.
Furthermore, we offered guidelines for data preprocessing and the selection of
appropriate LLM techniques and evaluation strategies for diagnostic tasks. We
also assessed the limitations of current research and delineated the challenges
and future directions in this research field. In summary, our review outlined a
blueprint for LLM-based disease diagnosis, helping to streamline and guide
future research endeavors.

摘要：自動疾病診斷在臨床實務中變得越來越有價值。大語言模型 (LLM) 的出現催化了人工智能的典範轉移，越來越多證據支持 LLM 在診斷任務中的效能。儘管這個領域受到越來越多的關注，但許多關鍵的研究問題仍未得到充分探討。例如，哪些疾病和 LLM 技術已被調查用於診斷任務？如何為臨床決策制定選擇合適的 LLM 技術和評估方法？為了回答這些問題，我們對基於 LLM 的疾病診斷方法進行了全面的分析。這項範圍探討回顧了現有研究中報告的疾病類型、相關器官系統、相關臨床資料、LLM 技術和評估方法。此外，我們提供了資料前處理和選擇適當的 LLM 技術和評估策略以進行診斷任務的指南。我們還評估了當前研究的限制，並描述了這個研究領域的挑戰和未來方向。總之，我們的回顧概述了基於 LLM 的疾病診斷藍圖，有助於簡化和指導未來的研究工作。

##### **Improving Clinical Note Generation from Complex Doctor-Patient Conversation**
2408.14568v1 by Yizhan Li, Sifan Wu, Christopher Smith, Thomas Lo, Bang Liu

Writing clinical notes and documenting medical exams is a critical task for
healthcare professionals, serving as a vital component of patient care
documentation. However, manually writing these notes is time-consuming and can
impact the amount of time clinicians can spend on direct patient interaction
and other tasks. Consequently, the development of automated clinical note
generation systems has emerged as a clinically meaningful area of research
within AI for health. In this paper, we present three key contributions to the
field of clinical note generation using large language models (LLMs). First, we
introduce CliniKnote, a comprehensive dataset consisting of 1,200 complex
doctor-patient conversations paired with their full clinical notes. This
dataset, created and curated by medical experts with the help of modern neural
networks, provides a valuable resource for training and evaluating models in
clinical note generation tasks. Second, we propose the K-SOAP (Keyword,
Subjective, Objective, Assessment, and Plan) note format, which enhances
traditional SOAP~\cite{podder2023soap} (Subjective, Objective, Assessment, and
Plan) notes by adding a keyword section at the top, allowing for quick
identification of essential information. Third, we develop an automatic
pipeline to generate K-SOAP notes from doctor-patient conversations and
benchmark various modern LLMs using various metrics. Our results demonstrate
significant improvements in efficiency and performance compared to standard LLM
finetuning methods.

摘要：撰寫臨床筆記和記錄醫療檢查是醫療保健專業人員的一項重要任務，是患者照護文件中的重要組成部分。然而，手動撰寫這些筆記很耗時，並且會影響臨床醫生花在直接患者互動和其他任務上的時間。因此，自動化臨床筆記生成系統的開發已成為 AI 在健康領域中具有臨床意義的研究領域。在本文中，我們提出了使用大型語言模型 (LLM) 進行臨床筆記生成的領域的 3 項關鍵貢獻。首先，我們介紹了 CliniKnote，這是一個綜合性數據集，包含 1,200 個複雜的醫患對話及其完整的臨床筆記。此數據集由醫學專家在現代神經網路的幫助下創建和策劃，為臨床筆記生成任務中的模型訓練和評估提供了寶貴的資源。其次，我們提出了 K-SOAP（關鍵字、主觀、客觀、評估和計畫）筆記格式，它通過在頂部添加一個關鍵字部分來增強傳統的 SOAP~\cite{podder2023soap}（主觀、客觀、評估和計畫）筆記，以便快速識別基本資訊。第三，我們開發了一個自動化管道，從醫患對話中生成 K-SOAP 筆記，並使用各種指標對各種現代 LLM 進行基準測試。我們的結果表明，與標準 LLM 微調方法相比，效率和性能有了顯著的提升。

##### **Temporal Ensemble Logic**
2408.14443v2 by Guo-Qiang Zhang

We introduce Temporal Ensemble Logic (TEL), a monadic, first-order modal
logic for linear-time temporal reasoning. TEL includes primitive temporal
constructs such as ``always up to $t$ time later'' ($\Box_t$), ``sometimes
before $t$ time in the future'' ($\Diamond_t$), and ``$t$-time later''
$\varphi_t$. TEL has been motivated from the requirement for rigor and
reproducibility for cohort specification and discovery in clinical and
population health research, to fill a gap in formalizing temporal reasoning in
biomedicine. Existing logical frameworks such as linear temporal logic are too
restrictive to express temporal and sequential properties in biomedicine, or
too permissive in semantic constructs, such as in Halpern-Shoham logic, to
serve this purpose. In this paper, we first introduce TEL in a general set up,
with discrete and dense time as special cases. We then focus on the theoretical
development of discrete TEL on the temporal domain of positive integers
$\mathbb{N}^+$, denoted as ${\rm TEL}_{\mathbb{N}^+}$. ${\rm
TEL}_{\mathbb{N}^+}$ is strictly more expressive than the standard monadic
second order logic, characterized by B\"{u}chi automata. We present its formal
semantics, a proof system, and provide a proof for the undecidability of the
satisfiability of ${\rm TEL}_{\mathbb{N}^+}$. We also include initial results
on expressiveness and decidability fragments for ${\rm TEL}_{\mathbb{N}^+}$,
followed by application outlook and discussions.

摘要：<paragraph>我們介紹時間集合邏輯 (TEL)，一種用於線性時間時態推理的一階單子模態邏輯。TEL 包含原始時態結構，例如「始終在 $t$ 時間後」($\Box_t$)、「有時在未來 $t$ 時間前」($\Diamond_t$) 和「$t$ 時間後」$\varphi_t$。TEL 的動機是為了臨床和人口健康研究中群組規範和發現的嚴謹性和可再現性，以填補生物醫學中時態推理形式化的空白。現有的邏輯框架（例如線性時態邏輯）對於表達生物醫學中的時態和順序屬性過於嚴格，或者在語義結構上過於寬鬆（例如在 Halpern-Shoham 邏輯中），無法達到此目的。在本文中，我們首先在一般設置中介紹 TEL，其中離散時間和稠密時間為特殊情況。然後，我們專注於正整數時間域 $\mathbb{N}^+$ 上離散 TEL 的理論發展，表示為 ${\rm TEL}_{\mathbb{N}^+}$. ${\rm TEL}_{\mathbb{N}^+}$ 比標準單子二階邏輯更具表達力，其特徵在於 B\"{u}chi 自動機。我們展示其形式語義、證明系統，並提供 ${\rm TEL}_{\mathbb{N}^+}$ 可滿足性的不可判定性的證明。我們還包括 ${\rm TEL}_{\mathbb{N}^+}$ 的表達力和可判定片段的初步結果，然後是應用前景和討論。</paragraph>

##### **MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues**
2408.14418v2 by Kuluhan Binici, Abhinav Ramesh Kashyap, Viktor Schlegel, Andy T. Liu, Vijay Prakash Dwivedi, Thanh-Tung Nguyen, Xiaoxue Gao, Nancy F. Chen, Stefan Winkler

Automatic Speech Recognition (ASR) systems are pivotal in transcribing speech
into text, yet the errors they introduce can significantly degrade the
performance of downstream tasks like summarization. This issue is particularly
pronounced in clinical dialogue summarization, a low-resource domain where
supervised data for fine-tuning is scarce, necessitating the use of ASR models
as black-box solutions. Employing conventional data augmentation for enhancing
the noise robustness of summarization models is not feasible either due to the
unavailability of sufficient medical dialogue audio recordings and
corresponding ASR transcripts. To address this challenge, we propose MEDSAGE,
an approach for generating synthetic samples for data augmentation using Large
Language Models (LLMs). Specifically, we leverage the in-context learning
capabilities of LLMs and instruct them to generate ASR-like errors based on a
few available medical dialogue examples with audio recordings. Experimental
results show that LLMs can effectively model ASR noise, and incorporating this
noisy data into the training process significantly improves the robustness and
accuracy of medical dialogue summarization systems. This approach addresses the
challenges of noisy ASR outputs in critical applications, offering a robust
solution to enhance the reliability of clinical dialogue summarization.

摘要：自動語音辨識 (ASR) 系統在將語音轉錄成文字方面至關重要，但它們所產生的錯誤可能會大幅降低摘要等下游任務的效能。這個問題在臨床對話摘要中特別明顯，這是一個低資源的領域，其中用於微調的監督資料很稀少，因此必須使用 ASR 模型作為黑盒解決方案。由於缺乏足夠的醫療對話音訊錄音和對應的 ASR 轉錄，採用傳統資料擴充來增強摘要模型的抗噪性也不可行。為了應對這個挑戰，我們提出了 MEDSAGE，這是一種使用大型語言模型 (LLM) 產生合成樣本進行資料擴充的方法。具體來說，我們利用 LLM 的情境學習能力，並指示它們根據少數帶有音訊錄音的可用醫療對話範例產生類似的 ASR 錯誤。實驗結果顯示，LLM 可以有效地模擬 ASR 雜訊，而將這些雜訊資料納入訓練過程中可以顯著提高醫療對話摘要系統的穩健性和準確性。這種方法應對了關鍵應用中 ASR 輸出雜訊的問題，提供了一個穩健的解決方案來增強臨床對話摘要的可靠性。

##### **Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs**
2408.14397v1 by Xiaoman Zhang, Julián N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar

Recent advancements in artificial intelligence have significantly improved
the automatic generation of radiology reports. However, existing evaluation
methods fail to reveal the models' understanding of radiological images and
their capacity to achieve human-level granularity in descriptions. To bridge
this gap, we introduce a system, named ReXKG, which extracts structured
information from processed reports to construct a comprehensive radiology
knowledge graph. We then propose three metrics to evaluate the similarity of
nodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs
(ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparative
analysis of AI-generated and human-written radiology reports, assessing the
performance of both specialist and generalist models. Our study provides a
deeper understanding of the capabilities and limitations of current AI models
in radiology report generation, offering valuable insights for improving model
performance and clinical applicability.

摘要：近期人工智能的進展顯著改善了放射報告的自動生成。然而，現有的評估方法無法揭示模型對放射影像的理解，以及它們在描述中達到人類層級精細度的能力。為了彌補這個差距，我們引進一個名為 ReXKG 的系統，它從處理過的報告中萃取出結構化的資訊，以建構一個全面的放射知識圖譜。接著，我們提出三個指標來評估各種知識圖譜中節點的相似性 (ReXKG-NSC)、邊緣的分布 (ReXKG-AMS) 和子圖的涵蓋範圍 (ReXKG-SCS)。我們對 AI 生成的和人類撰寫的放射報告進行深入的比較分析，評估專家和通才模型的效能。我們的研究提供對目前 AI 模型在放射報告生成中的能力和限制更深入的理解，並提供有價值的見解來改善模型效能和臨床應用。

##### **Foundation Models for Music: A Survey**
2408.14340v3 by Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wenhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang

In recent years, foundation models (FMs) such as large language models (LLMs)
and latent diffusion models (LDMs) have profoundly impacted diverse sectors,
including music. This comprehensive review examines state-of-the-art (SOTA)
pre-trained models and foundation models in music, spanning from representation
learning, generative learning and multimodal learning. We first contextualise
the significance of music in various industries and trace the evolution of AI
in music. By delineating the modalities targeted by foundation models, we
discover many of the music representations are underexplored in FM development.
Then, emphasis is placed on the lack of versatility of previous methods on
diverse music applications, along with the potential of FMs in music
understanding, generation and medical application. By comprehensively exploring
the details of the model pre-training paradigm, architectural choices,
tokenisation, finetuning methodologies and controllability, we emphasise the
important topics that should have been well explored, like instruction tuning
and in-context learning, scaling law and emergent ability, as well as
long-sequence modelling etc. A dedicated section presents insights into music
agents, accompanied by a thorough analysis of datasets and evaluations
essential for pre-training and downstream tasks. Finally, by underscoring the
vital importance of ethical considerations, we advocate that following research
on FM for music should focus more on such issues as interpretability,
transparency, human responsibility, and copyright issues. The paper offers
insights into future challenges and trends on FMs for music, aiming to shape
the trajectory of human-AI collaboration in the music realm.

摘要：近年來，基礎模型 (FM)，例如大型語言模型 (LLM) 和潛在擴散模型 (LDM)，已對包括音樂在內的不同產業產生深遠影響。這篇全面性的評論探討了音樂領域中最先進 (SOTA) 的預訓練模型和基礎模型，涵蓋了表徵學習、生成式學習和多模態學習。我們首先將音樂在各產業的重要性脈絡化，並追溯 AI 在音樂中的演進。透過描繪基礎模型所針對的模態，我們發現許多音樂表徵在 FM 開發中尚未被充分探索。接著，我們強調先前方法在不同音樂應用中缺乏多樣性，以及 FM 在音樂理解、生成和醫療應用中的潛力。透過全面探討模型預訓練典範、架構選擇、標記化、微調方法和可控性的細節，我們強調了應深入探討的重要主題，例如指令微調和情境學習、規模定律和新興能力，以及長序列建模等。專門的章節提供了對音樂代理的見解，並附有對預訓練和下游任務至關重要的資料集和評估的深入分析。最後，透過強調倫理考量的至關重要性，我們主張後續關於音樂 FM 的研究應更專注於可解釋性、透明度、人類責任和版權問題等議題。本文提供了對音樂 FM 未來挑戰和趨勢的見解，旨在形塑人類與 AI 在音樂領域中合作的軌跡。

##### **Uncertainties of Latent Representations in Computer Vision**
2408.14281v1 by Michael Kirchhof

Uncertainty quantification is a key pillar of trustworthy machine learning.
It enables safe reactions under unsafe inputs, like predicting only when the
machine learning model detects sufficient evidence, discarding anomalous data,
or emitting warnings when an error is likely to be inbound. This is
particularly crucial in safety-critical areas like medical image classification
or self-driving cars. Despite the plethora of proposed uncertainty
quantification methods achieving increasingly higher scores on performance
benchmarks, uncertainty estimates are often shied away from in practice. Many
machine learning projects start from pretrained latent representations that
come without uncertainty estimates. Uncertainties would need to be trained by
practitioners on their own, which is notoriously difficult and
resource-intense.
  This thesis makes uncertainty estimates easily accessible by adding them to
the latent representation vectors of pretrained computer vision models. Besides
proposing approaches rooted in probability and decision theory, such as
Monte-Carlo InfoNCE (MCInfoNCE) and loss prediction, we delve into both
theoretical and empirical questions. We show that these unobservable
uncertainties about unobservable latent representations are indeed provably
correct. We also provide an uncertainty-aware representation learning (URL)
benchmark to compare these unobservables against observable ground-truths.
Finally, we compile our findings to pretrain lightweight representation
uncertainties on large-scale computer vision models that transfer to unseen
datasets in a zero-shot manner.
  Our findings do not only advance the current theoretical understanding of
uncertainties over latent variables, but also facilitate the access to
uncertainty quantification for future researchers inside and outside the field,
enabling straightforward but trustworthy machine learning.

摘要：不確定量化是值得信賴機器學習的一大支柱。
它能讓機器學習模型在不安全的輸入下做出安全的反應，例如只在機器學習模型偵測到足夠證據時才進行預測、捨棄異常資料，或是在可能發生錯誤時發出警告。這在醫療影像分類或自駕車等安全關鍵領域中特別重要。儘管有許多已提出的不確定量化方法在效能基準上取得越來越高的分數，但在實務上卻常常迴避不確定性估計。許多機器學習專案從預訓練的潛在表徵開始，而這些表徵沒有不確定性估計。實務工作者需要自行訓練不確定性，這出了名的困難且耗費資源。
本論文透過將不確定性估計新增到預訓練電腦視覺模型的潛在表徵向量中，讓不確定性估計易於取得。除了提出植基於機率和決策理論的方法，例如蒙地卡羅資訊對比估計 (MCInfoNCE) 和損失預測之外，我們還深入探討理論和實證問題。我們證明這些關於不可觀察潛在表徵的不可觀察不確定性確實可以證明是正確的。我們還提供一個不確定性感知表徵學習 (URL) 基準，用來比較這些不可觀察的不確定性與可觀察的真實值。最後，我們將我們的發現彙整起來，在大型電腦視覺模型上預訓練輕量級表徵不確定性，並以零次學習的方式轉移到未見過的資料集。
我們的發現不僅提升了當前對潛在變數不確定性的理論理解，還促進了未來研究人員在該領域內外取得不確定量化，進而實現直接但值得信賴的機器學習。

##### **Automatic Medical Report Generation: Methods and Applications**
2408.13988v1 by Li Guo, Anas M. Tahir, Dong Zhang, Z. Jane Wang, Rabab K. Ward

The increasing demand for medical imaging has surpassed the capacity of
available radiologists, leading to diagnostic delays and potential
misdiagnoses. Artificial intelligence (AI) techniques, particularly in
automatic medical report generation (AMRG), offer a promising solution to this
dilemma. This review comprehensively examines AMRG methods from 2021 to 2024.
It (i) presents solutions to primary challenges in this field, (ii) explores
AMRG applications across various imaging modalities, (iii) introduces publicly
available datasets, (iv) outlines evaluation metrics, (v) identifies techniques
that significantly enhance model performance, and (vi) discusses unresolved
issues and potential future research directions. This paper aims to provide a
comprehensive understanding of the existing literature and inspire valuable
future research.

摘要：由於對醫學影像的需求日益增長，已經超過了現有放射科醫師的能力，導致診斷延誤和潛在的誤診。人工智慧 (AI) 技術，特別是在自動醫療報告生成 (AMRG) 方面，為此困境提供了有希望的解決方案。本篇評論全面探討了 2021 年至 2024 年的 AMRG 方法。它 (i) 提出解決此領域中主要挑戰的方案，(ii) 探討 AMRG 在各種影像模式中的應用，(iii) 介紹公開可用的資料集，(iv) 概述評估指標，(v) 找出顯著提升模型效能的技術，以及 (vi) 討論尚未解決的問題和潛在的未來研究方向。本文旨在提供對現有文獻的全面了解，並激發有價值的未來研究。

##### **Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models**
2409.00084v2 by Seyed Amir Ahmad Safavi-Naini, Shuhaib Ali, Omer Shahab, Zahra Shahhoseini, Thomas Savage, Sara Rafiee, Jamil S Samaan, Reem Al Shabeeb, Farah Ladak, Jamie O Yang, Juan Echavarria, Sumbal Babar, Aasma Shaukat, Samuel Margolis, Nicholas P Tatonetti, Girish Nadkarni, Bara El Kurdi, Ali Soroush

Background and Aims: This study evaluates the medical reasoning performance
of large language models (LLMs) and vision language models (VLMs) in
gastroenterology.
  Methods: We used 300 gastroenterology board exam-style multiple-choice
questions, 138 of which contain images to systematically assess the impact of
model configurations and parameters and prompt engineering strategies utilizing
GPT-3.5. Next, we assessed the performance of proprietary and open-source LLMs
(versions), including GPT (3.5, 4, 4o, 4omini), Claude (3, 3.5), Gemini (1.0),
Mistral, Llama (2, 3, 3.1), Mixtral, and Phi (3), across different interfaces
(web and API), computing environments (cloud and local), and model precisions
(with and without quantization). Finally, we assessed accuracy using a
semiautomated pipeline.
  Results: Among the proprietary models, GPT-4o (73.7%) and Claude3.5-Sonnet
(74.0%) achieved the highest accuracy, outperforming the top open-source
models: Llama3.1-405b (64%), Llama3.1-70b (58.3%), and Mixtral-8x7b (54.3%).
Among the quantized open-source models, the 6-bit quantized Phi3-14b (48.7%)
performed best. The scores of the quantized models were comparable to those of
the full-precision models Llama2-7b, Llama2--13b, and Gemma2-9b. Notably, VLM
performance on image-containing questions did not improve when the images were
provided and worsened when LLM-generated captions were provided. In contrast, a
10% increase in accuracy was observed when images were accompanied by
human-crafted image descriptions.
  Conclusion: In conclusion, while LLMs exhibit robust zero-shot performance in
medical reasoning, the integration of visual data remains a challenge for VLMs.
Effective deployment involves carefully determining optimal model
configurations, encouraging users to consider either the high performance of
proprietary models or the flexible adaptability of open-source models.

摘要：<paragraph>背景與目標：本研究評估大型語言模型 (LLM) 和視覺語言模型 (VLM) 在腸胃病學中的醫療推理表現。
方法：我們使用 300 個腸胃病學專科考試風格的多選題，其中 138 個包含影像，以系統性地評估模型配置和參數以及利用 GPT-3.5 的提示工程策略的影響。接下來，我們評估專有和開源 LLM（版本）的表現，包括 GPT（3.5、4、4o、4omini）、Claude（3、3.5）、Gemini（1.0）、Mistral、Llama（2、3、3.1）、Mixtral 和 Phi（3），跨不同介面（網路和 API）、運算環境（雲端和本地）和模型精確度（有和沒有量化）。最後，我們使用半自動化管道評估準確度。
結果：在專有模型中，GPT-4o（73.7%）和 Claude3.5-Sonnet（74.0%）達到最高準確度，優於頂尖的開源模型：Llama3.1-405b（64%）、Llama3.1-70b（58.3%）和 Mixtral-8x7b（54.3%）。在量化的開源模型中，6 位元量化的 Phi3-14b（48.7%）表現最佳。量化模型的分數與全精度模型 Llama2-7b、Llama2--13b 和 Gemma2-9b 相當。值得注意的是，當提供影像時，VLM 在包含影像的問題上的表現並未改善，而在提供 LLM 生成的標題時表現惡化。相反地，當影像附有人工製作的影像描述時，準確度觀察到增加了 10%。
結論：結論而言，雖然 LLM 在醫療推理中表現出強健的零次學習表現，但視覺資料的整合仍然是 VLM 的一項挑戰。有效的部署涉及仔細確定最佳模型配置，鼓勵使用者考慮專有模型的高效能或開源模型的靈活適應性。</paragraph>

##### **PropSAM: A Propagation-Based Model for Segmenting Any 3D Objects in Multi-Modal Medical Images**
2408.13836v1 by Zifan Chen, Xinyu Nan, Jiazheng Li, Jie Zhao, Haifeng Li, Zilin Lin, Haoshen Li, Heyun Chen, Yiting Liu, Bin Dong, Li Zhang, Lei Tang

Volumetric segmentation is crucial for medical imaging but is often
constrained by labor-intensive manual annotations and the need for
scenario-specific model training. Furthermore, existing general segmentation
models are inefficient due to their design and inferential approaches.
Addressing this clinical demand, we introduce PropSAM, a propagation-based
segmentation model that optimizes the use of 3D medical structure information.
PropSAM integrates a CNN-based UNet for intra-slice processing with a
Transformer-based module for inter-slice propagation, focusing on structural
and semantic continuities to enhance segmentation across various modalities.
Distinctively, PropSAM operates on a one-view prompt, such as a 2D bounding box
or sketch mask, unlike conventional models that require two-view prompts. It
has demonstrated superior performance, significantly improving the Dice
Similarity Coefficient (DSC) across 44 medical datasets and various imaging
modalities, outperforming models like MedSAM and SegVol with an average DSC
improvement of 18.1%. PropSAM also maintains stable predictions despite prompt
deviations and varying propagation configurations, confirmed by one-way ANOVA
tests with P>0.5985 and P>0.6131, respectively. Moreover, PropSAM's efficient
architecture enables faster inference speeds (Wilcoxon rank-sum test, P<0.001)
and reduces user interaction time by 37.8% compared to two-view prompt models.
Its ability to handle irregular and complex objects with robust performance
further demonstrates its potential in clinical settings, facilitating more
automated and reliable medical imaging analyses with minimal retraining.

摘要：體積分割對於醫學影像至關重要，但通常受到耗費大量人力的標註和特定場景模型訓練需求的限制。此外，現有的通用分割模型由於其設計和推論方法而效率低下。為了滿足這項臨床需求，我們引入了 PropSAM，這是一種基於傳播的分割模型，優化了 3D 醫學結構資訊的使用。PropSAM 整合了一個基於 CNN 的 UNet，用於切片內處理，以及一個基於 Transformer 的模組，用於切片間傳播，重點關注結構和語義連續性，以增強各種模式下的分割。與需要兩視提示的傳統模型不同，PropSAM 獨特地運作於單視提示上，例如 2D 邊界框或草圖遮罩。它已證明具有優異的效能，顯著改善了 44 個醫學資料集和各種影像模式下的骰子相似係數 (DSC)，優於 MedSAM 和 SegVol 等模型，平均 DSC 提升了 18.1%。儘管提示偏差和傳播配置不同，PropSAM 仍能維持穩定的預測，這已通過單向 ANOVA 測試得到證實，分別為 P>0.5985 和 P>0.6131。此外，PropSAM 的高效架構能實現更快的推論速度（Wilcoxon 等級和總和檢定，P<0.001），並將使用者互動時間減少了 37.8%，優於兩視提示模型。它在處理不規則和複雜物件時能展現出穩健的效能，進一步證明了其在臨床環境中的潛力，有助於以最少的重新訓練進行更自動化和可靠的醫學影像分析。

##### **Submodular Maximization Approaches for Equitable Client Selection in Federated Learning**
2408.13683v2 by Andrés Catalino Castillo Jiménez, Ege C. Kaya, Lintao Ye, Abolfazl Hashemi

In a conventional Federated Learning framework, client selection for training
typically involves the random sampling of a subset of clients in each
iteration. However, this random selection often leads to disparate performance
among clients, raising concerns regarding fairness, particularly in
applications where equitable outcomes are crucial, such as in medical or
financial machine learning tasks. This disparity typically becomes more
pronounced with the advent of performance-centric client sampling techniques.
This paper introduces two novel methods, namely SUBTRUNC and UNIONFL, designed
to address the limitations of random client selection. Both approaches utilize
submodular function maximization to achieve more balanced models. By modifying
the facility location problem, they aim to mitigate the fairness concerns
associated with random selection. SUBTRUNC leverages client loss information to
diversify solutions, while UNIONFL relies on historical client selection data
to ensure a more equitable performance of the final model. Moreover, these
algorithms are accompanied by robust theoretical guarantees regarding
convergence under reasonable assumptions. The efficacy of these methods is
demonstrated through extensive evaluations across heterogeneous scenarios,
revealing significant improvements in fairness as measured by a client
dissimilarity metric.

摘要：在傳統的聯邦學習框架中，訓練的用戶端選擇通常涉及在每次迭代中隨機抽取用戶端子集。然而，這種隨機選擇通常會導致用戶端之間的表現差異，引發了公平性的擔憂，特別是在公平結果至關重要的應用中，例如醫療或金融機器學習任務。這種差異通常會隨著以效能為中心的用戶端抽樣技術的出現而變得更加明顯。本文介紹了兩種新方法，即 SUBTRUNC 和 UNIONFL，旨在解決隨機用戶端選擇的限制。這兩種方法都利用次模函數最大化來實現更平衡的模型。通過修改設施位置問題，它們旨在緩解與隨機選擇相關的公平性問題。SUBTRUNC 利用用戶端損失資訊來分散解決方案，而 UNIONFL 依賴於歷史用戶端選擇資料，以確保最終模型的效能更公平。此外，這些演算法附帶了關於合理假設下收斂性的強大理論保證。這些方法的效力通過各種異質場景的廣泛評估得到證明，顯示出公平性有顯著改善，這是通過用戶端差異度量指標測量的。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **HBIC: A Biclustering Algorithm for Heterogeneous Datasets**
2408.13217v1 by Adán José-García, Julie Jacques, Clément Chauvet, Vincent Sobanski, Clarisse Dhaenens

Biclustering is an unsupervised machine-learning approach aiming to cluster
rows and columns simultaneously in a data matrix. Several biclustering
algorithms have been proposed for handling numeric datasets. However,
real-world data mining problems often involve heterogeneous datasets with mixed
attributes. To address this challenge, we introduce a biclustering approach
called HBIC, capable of discovering meaningful biclusters in complex
heterogeneous data, including numeric, binary, and categorical data. The
approach comprises two stages: bicluster generation and bicluster model
selection. In the initial stage, several candidate biclusters are generated
iteratively by adding and removing rows and columns based on the frequency of
values in the original matrix. In the second stage, we introduce two approaches
for selecting the most suitable biclusters by considering their size and
homogeneity. Through a series of experiments, we investigated the suitability
of our approach on a synthetic benchmark and in a biomedical application
involving clinical data of systemic sclerosis patients. The evaluation
comparing our method to existing approaches demonstrates its ability to
discover high-quality biclusters from heterogeneous data. Our biclustering
approach is a starting point for heterogeneous bicluster discovery, leading to
a better understanding of complex underlying data structures.

摘要：雙聚類是一種非監督機器學習方法，旨在同時對資料矩陣中的列和行進行聚類。已提出多種雙聚類演算法來處理數值資料集。然而，現實世界的資料探勘問題通常涉及具有混合屬性的異質資料集。為了應對這一挑戰，我們引入了一種名為 HBIC 的雙聚類方法，它能夠在複雜的異質資料（包括數值、二進制和類別資料）中發現有意義的雙聚類。該方法包括兩個階段：雙聚類生成和雙聚類模型選擇。在初始階段，通過根據原始矩陣中的值頻率新增和移除列和行，反覆生成多個候選雙聚類。在第二階段，我們引入了兩種方法，通過考慮雙聚類的大小和同質性來選擇最合適的雙聚類。通過一系列實驗，我們研究了我們的方法在合成基準和涉及全身性硬化症患者臨床資料的生物醫學應用中的適用性。將我們的演算法與現有方法進行比較，評估結果證明了其從異質資料中發現高品質雙聚類的能力。我們的雙聚類方法是異質雙聚類發現的起點，有助於更好地理解複雜的底層資料結構。

##### **Causal machine learning for sustainable agroecosystems**
2408.13155v1 by Vasileios Sitokonstantinou, Emiliano Díaz Salas Porras, Jordi Cerdà Bautista, Maria Piles, Ioannis Athanasiadis, Hannah Kerner, Giulia Martini, Lily-belle Sweet, Ilias Tsoumas, Jakob Zscheischler, Gustau Camps-Valls

In a changing climate, sustainable agriculture is essential for food security
and environmental health. However, it is challenging to understand the complex
interactions among its biophysical, social, and economic components. Predictive
machine learning (ML), with its capacity to learn from data, is leveraged in
sustainable agriculture for applications like yield prediction and weather
forecasting. Nevertheless, it cannot explain causal mechanisms and remains
descriptive rather than prescriptive. To address this gap, we propose causal
ML, which merges ML's data processing with causality's ability to reason about
change. This facilitates quantifying intervention impacts for evidence-based
decision-making and enhances predictive model robustness. We showcase causal ML
through eight diverse applications that benefit stakeholders across the
agri-food chain, including farmers, policymakers, and researchers.

摘要：在氣候變遷的影響下，永續農業對於糧食安全和環境健康至關重要。然而，要了解其生物物理、社會和經濟成分之間的複雜互動卻是一項挑戰。預測機器學習 (ML) 具備從資料中學習的能力，因此被運用於永續農業中，例如產量預測和天氣預報等應用。儘管如此，它無法解釋因果機制，且仍然是描述性的而非規範性的。為了解決這個差距，我們提出了因果 ML，它將 ML 的資料處理與因果關係推理變化的能力結合在一起。這有助於量化干預影響，以利於基於證據的決策制定，並增強預測模型的穩健性。我們透過八個不同的應用展示因果 ML，這些應用惠及農業食品鏈中的利害關係人，包括農民、政策制定者和研究人員。

##### **Has Multimodal Learning Delivered Universal Intelligence in Healthcare? A Comprehensive Survey**
2408.12880v1 by Qika Lin, Yifan Zhu, Xin Mei, Ling Huang, Jingying Ma, Kai He, Zhen Peng, Erik Cambria, Mengling Feng

The rapid development of artificial intelligence has constantly reshaped the
field of intelligent healthcare and medicine. As a vital technology, multimodal
learning has increasingly garnered interest due to data complementarity,
comprehensive modeling form, and great application potential. Currently,
numerous researchers are dedicating their attention to this field, conducting
extensive studies and constructing abundant intelligent systems. Naturally, an
open question arises that has multimodal learning delivered universal
intelligence in healthcare? To answer the question, we adopt three unique
viewpoints for a holistic analysis. Firstly, we conduct a comprehensive survey
of the current progress of medical multimodal learning from the perspectives of
datasets, task-oriented methods, and universal foundation models. Based on
them, we further discuss the proposed question from five issues to explore the
real impacts of advanced techniques in healthcare, from data and technologies
to performance and ethics. The answer is that current technologies have NOT
achieved universal intelligence and there remains a significant journey to
undertake. Finally, in light of the above reviews and discussions, we point out
ten potential directions for exploration towards the goal of universal
intelligence in healthcare.

摘要：人工智能的快速发展持续重塑着智能医疗和医学领域。作为一项至关重要的技术，多模态学习由于数据互补性、综合建模形式和巨大的应用潜力而日益受到关注。目前，众多研究者将注意力投向这一领域，开展了广泛的研究并构建了丰富的智能系统。自然而然地，一个开放的问题出现了，即多模态学习是否在医疗保健中提供了通用智能？为了回答这个问题，我们采用三个独特的视角进行整体分析。首先，我们从数据集、面向任务的方法和通用基础模型的角度对医学多模态学习的当前进展进行了全面的调查。在此基础上，我们进一步从五个问题讨论了提出的问题，以探讨先进技术在医疗保健中的实际影响，从数据和技术到性能和伦理。答案是，当前技术尚未实现通用智能，并且仍有很长的路要走。最后，根据上述回顾和讨论，我们指出了实现医疗保健通用智能目标的十个潜在探索方向。

##### **COVID-19 Probability Prediction Using Machine Learning: An Infectious Approach**
2408.12841v1 by Mohsen Asghari Ilani, Saba Moftakhar Tehran, Ashkan Kavei, Arian Radmehr

The ongoing COVID-19 pandemic continues to pose significant challenges to
global public health, despite the widespread availability of vaccines. Early
detection of the disease remains paramount in curbing its transmission and
mitigating its impact on public health systems. In response, this study delves
into the application of advanced machine learning (ML) techniques for
predicting COVID-19 infection probability. We conducted a rigorous
investigation into the efficacy of various ML models, including XGBoost, LGBM,
AdaBoost, Logistic Regression, Decision Tree, RandomForest, CatBoost, KNN, and
Deep Neural Networks (DNN). Leveraging a dataset comprising 4000 samples, with
3200 allocated for training and 800 for testing, our experiment offers
comprehensive insights into the performance of these models in COVID-19
prediction. Our findings reveal that Deep Neural Networks (DNN) emerge as the
top-performing model, exhibiting superior accuracy and recall metrics. With an
impressive accuracy rate of 89%, DNN demonstrates remarkable potential in early
COVID-19 detection. This underscores the efficacy of deep learning approaches
in leveraging complex data patterns to identify COVID-19 infections accurately.
This study underscores the critical role of machine learning, particularly deep
learning methodologies, in augmenting early detection efforts amidst the
ongoing pandemic. The success of DNN in accurately predicting COVID-19
infection probability highlights the importance of continued research and
development in leveraging advanced technologies to combat infectious diseases.

摘要：持續進行的 COVID-19 大流行病持續對全球公共衛生構成重大挑戰，儘管疫苗已廣泛提供。早期發現疾病仍然是遏制其傳播和減輕其對公共衛生系統影響的首要任務。為此，本研究深入探討先進機器學習 (ML) 技術在預測 COVID-19 感染機率方面的應用。我們對各種 ML 模型的效能進行了嚴謹的調查，包括 XGBoost、LGBM、AdaBoost、邏輯迴歸、決策樹、隨機森林、CatBoost、KNN 和深度神經網路 (DNN)。利用包含 4000 個樣本的資料集，其中 3200 個分配給訓練，800 個分配給測試，我們的實驗對這些模型在 COVID-19 預測中的效能提供了全面的見解。我們的研究結果顯示，深度神經網路 (DNN) 成為表現最佳的模型，展現出優異的準確度和召回率指標。DNN 以 89% 的驚人準確度，證明了在早期 COVID-19 檢測中的傑出潛力。這突顯了深度學習方法在利用複雜資料模式準確識別 COVID-19 感染方面的效能。本研究強調了機器學習，特別是深度學習方法，在持續的大流行病中擴增早期檢測工作中的關鍵作用。DNN 在準確預測 COVID-19 感染機率方面的成功，突顯了持續研究和開發利用先進技術來對抗傳染病的重要性。

##### **Exploring Machine Learning Models for Lung Cancer Level Classification: A comparative ML Approach**
2408.12838v1 by Mohsen Asghari Ilani, Saba Moftakhar Tehran, Ashkan Kavei, Hamed Alizadegan

This paper explores machine learning (ML) models for classifying lung cancer
levels to improve diagnostic accuracy and prognosis. Through parameter tuning
and rigorous evaluation, we assess various ML algorithms. Techniques like
minimum child weight and learning rate monitoring were used to reduce
overfitting and optimize performance. Our findings highlight the robust
performance of Deep Neural Network (DNN) models across all phases. Ensemble
methods, including voting and bagging, also showed promise in enhancing
predictive accuracy and robustness. However, Support Vector Machine (SVM)
models with the Sigmoid kernel faced challenges, indicating a need for further
refinement. Overall, our study provides insights into ML-based lung cancer
classification, emphasizing the importance of parameter tuning to optimize
model performance and improve diagnostic accuracy in oncological care.

摘要：本論文探討機器學習 (ML) 模型，用於分類肺癌等級以提升診斷準確度和預後。透過參數調整和嚴謹評估，我們評估各種 ML 演算法。使用最小子權重和學習率監控等技術來減少過度擬合並最佳化效能。我們的研究結果強調深度神經網路 (DNN) 模型在所有階段的強健效能。包括投票和 bagging 在內的整體方法，也在提升預測準確度和強健性方面展現優勢。然而，使用 Sigmoid 核心的支援向量機 (SVM) 模型面臨挑戰，顯示需要進一步改良。整體而言，我們的研究提供機器學習為基礎的肺癌分類見解，強調參數調整對於最佳化模型效能和提升腫瘤照護診斷準確度的重要性。

##### **Phrasing for UX: Enhancing Information Engagement through Computational Linguistics and Creative Analytics**
2409.00064v1 by Nimrod Dvir

This study explores the relationship between textual features and Information
Engagement (IE) on digital platforms. It highlights the impact of computational
linguistics and analytics on user interaction. The READ model is introduced to
quantify key predictors like representativeness, ease of use, affect, and
distribution, which forecast engagement levels. The model's effectiveness is
validated through AB testing and randomized trials, showing strong predictive
performance in participation (accuracy: 0.94), perception (accuracy: 0.85),
perseverance (accuracy: 0.81), and overall IE (accuracy: 0.97).
  While participation metrics are strong, perception and perseverance show
slightly lower recall and F1-scores, indicating some challenges. The study
demonstrates that modifying text based on the READ model's insights leads to
significant improvements. For example, increasing representativeness and
positive affect boosts selection rates by 11 percent, raises evaluation
averages from 3.98 to 4.46, and improves retention rates by 11 percent. These
findings highlight the importance of linguistic factors in IE, providing a
framework for enhancing digital text engagement. The research offers practical
strategies applicable to fields like education, health, and media.

摘要：本研究探討了數位平台上文本特徵與資訊參與度 (IE) 之間的關係。它強調了計算語言學和分析對使用者互動的影響。READ 模型被引入用於量化關鍵預測因子，例如代表性、易用性、影響力，以及預測參與程度的分布。該模型的有效性已通過 AB 測試和隨機試驗得到驗證，在參與度（準確度：0.94）、感知（準確度：0.85）、堅持度（準確度：0.81）和整體 IE（準確度：0.97）中顯示出強大的預測效能。雖然參與度指標很強，但感知和堅持度顯示出稍低的召回率和 F1 分數，表明存在一些挑戰。研究表明，根據 READ 模型的見解修改文字會帶來顯著的改進。例如，提高代表性和正面影響力可將選擇率提高 11%，將評分平均值從 3.98 提高到 4.46，並將保留率提高 11%。這些發現強調了語言因素在 IE 中的重要性，提供了一個增強數位文字參與度的框架。該研究提供了適用於教育、健康和媒體等領域的實用策略。

##### **From Radiologist Report to Image Label: Assessing Latent Dirichlet Allocation in Training Neural Networks for Orthopedic Radiograph Classification**
2408.13284v1 by Jakub Olczak, Max Gordon

Background: Radiography (X-rays) is the dominant modality in orthopedics, and
improving the interpretation of radiographs is clinically relevant. Machine
learning (ML) has revolutionized data analysis and has been applied to
medicine, with some success, in the form of natural language processing (NLP)
and artificial neural networks (ANN). Latent Dirichlet allocation (LDA) is an
NLP method that automatically categorizes documents into topics. Successfully
applying ML to orthopedic radiography could enable the creation of
computer-aided decision systems for use in the clinic. We studied how an
automated ML pipeline could classify orthopedic trauma radiographs from
radiologist reports. Methods: Wrist and ankle radiographs from Danderyd
Hospital in Sweden taken between 2002 and 2015, with radiologist reports. LDA
was used to create image labels for radiographs from the radiologist reports.
Radiographs and labels were used to train an image recognition ANN. The ANN
outcomes were manually reviewed to get an accurate estimate of the method's
utility and accuracy. Results: Image Labels generated via LDA could
successfully train the ANN. The ANN reached an accuracy between 91% and 60%
compared to a gold standard, depending on the label. Conclusions: We found that
LDA was unsuited to label orthopedic radiographs from reports with high
accuracy. However, despite this, the ANN could learn to detect some features in
radiographs with high accuracy. The study also illustrates how ML and ANN can
be applied to medical research.

摘要：<paragraph>背景：放射科中，放射線照相（X 光）是主要的模式，而改善放射線照相的解讀在臨床上具有相關性。機器學習（ML）徹底改變了數據分析，並以自然語言處理（NLP）和人工神經網路（ANN）的形式應用於醫學，並取得了一些成功。潛在狄利克雷配置（LDA）是一種 NLP 方法，可自動將文件分類為主題。成功將 ML 應用於骨科放射線照相可以創建電腦輔助決策系統，供診所使用。我們研究了自動化 ML 管線如何從放射科醫師的報告中對骨科創傷放射線照相進行分類。方法：使用放射科醫師的報告，於 2002 年至 2015 年間在瑞典 Danderyd 醫院拍攝的手腕和腳踝放射線照相。LDA 用於根據放射科醫師的報告為放射線照相建立影像標籤。放射線照相和標籤用於訓練影像辨識 ANN。手動檢閱 ANN 結果以準確估計方法的效用和準確性。結果：透過 LDA 生成的影像標籤可以成功訓練 ANN。與黃金標準相比，ANN 達到了 91% 到 60% 的準確度，具體取決於標籤。結論：我們發現 LDA 不適合從報告中標記骨科放射線照相，準確度高。然而，儘管如此，ANN 仍可以學習以高準確度偵測放射線照相中的一些特徵。該研究還說明了 ML 和 ANN 如何應用於醫學研究。</paragraph>

##### **MultiMed: Massively Multimodal and Multitask Medical Understanding**
2408.12682v1 by Shentong Mo, Paul Pu Liang

Biomedical data is inherently multimodal, consisting of electronic health
records, medical imaging, digital pathology, genome sequencing, wearable
sensors, and more. The application of artificial intelligence tools to these
multifaceted sensing technologies has the potential to revolutionize the
prognosis, diagnosis, and management of human health and disease. However,
current approaches to biomedical AI typically only train and evaluate with one
or a small set of medical modalities and tasks. This limitation hampers the
development of comprehensive tools that can leverage the rich interconnected
information across many heterogeneous biomedical sensors. To address this
challenge, we present MultiMed, a benchmark designed to evaluate and enable
large-scale learning across a wide spectrum of medical modalities and tasks.
MultiMed consists of 2.56 million samples across ten medical modalities such as
medical reports, pathology, genomics, and protein data, and is structured into
eleven challenging tasks, including disease prognosis, protein structure
prediction, and medical question answering. Using MultiMed, we conduct
comprehensive experiments benchmarking state-of-the-art unimodal, multimodal,
and multitask models. Our analysis highlights the advantages of training
large-scale medical models across many related modalities and tasks. Moreover,
MultiMed enables studies of generalization across related medical concepts,
robustness to real-world noisy data and distribution shifts, and novel modality
combinations to improve prediction performance. MultiMed will be publicly
available and regularly updated and welcomes inputs from the community.

摘要：生物医学数据本质上是多模态的，由电子健康记录、医学影像、数字病理学、基因组测序、可穿戴传感器等组成。将人工智能工具应用于这些多方面的传感技术有可能彻底改变人类健康和疾病的预后、诊断和管理。然而，当前对生物医学人工智能的方法通常只针对一种或一小组医学方式和任务进行训练和评估。这种限制阻碍了能够利用许多异构生物医学传感器之间的丰富互联信息来开发综合工具。为了应对这一挑战，我们提出了 MultiMed，这是一个旨在评估和支持跨广泛医学方式和任务进行大规模学习的基准。MultiMed 包含了十种医学方式（例如医学报告、病理学、基因组学和蛋白质数据）中的 256 万个样本，并被构建成十一个具有挑战性的任务，包括疾病预后、蛋白质结构预测和医学问题解答。使用 MultiMed，我们进行了全面的实验，对最先进的单模态、多模态和多任务模型进行了基准测试。我们的分析突出了跨许多相关方式和任务训练大规模医学模型的优势。此外，MultiMed 支持对相关医学概念的泛化、对真实世界噪声数据和分布变化的鲁棒性以及新的方式组合以提高预测性能的研究。MultiMed 将公开提供并定期更新，并欢迎社区的意见。

##### **RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**
2408.12579v1 by Xiaohan Wang, Xiaoyan Yang, Yuqi Zhu, Yue Shen, Jian Wang, Peng Wei, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang

Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve
performance competitively with human experts across various medical benchmarks.
However, they still face challenges in making professional diagnoses akin to
physicians, particularly in efficiently gathering patient information and
reasoning the final diagnosis. To this end, we introduce the RuleAlign
framework, designed to align LLMs with specific diagnostic rules. We develop a
medical dialogue dataset comprising rule-based communications between patients
and physicians and design an alignment learning approach through preference
learning. Experimental results demonstrate the effectiveness of the proposed
approach. We hope that our work can serve as an inspiration for exploring the
potential of LLMs as AI physicians.

摘要：大型語言模型（LLM），例如 GPT-4、MedPaLM-2 和 Med-Gemini，在各種醫療基準上達到了與人類專家競爭的表現。
然而，他們在做出類似於醫師的專業診斷方面仍面臨挑戰，特別是在有效收集患者資訊和推論最終診斷方面。為此，我們引入了 RuleAlign 框架，旨在將 LLM 與特定診斷規則保持一致。我們開發了一個醫療對話資料集，其中包含患者與醫師之間基於規則的溝通，並透過偏好學習設計了一種比對學習方法。實驗結果證明了所提方法的有效性。我們希望我們的工作能激勵探索 LLM 作為 AI 醫師的潛力。

##### **Automatic Organ and Pan-cancer Segmentation in Abdomen CT: the FLARE 2023 Challenge**
2408.12534v1 by Jun Ma, Yao Zhang, Song Gu, Cheng Ge, Ershuai Wang, Qin Zhou, Ziyan Huang, Pengju Lyu, Jian He, Bo Wang

Organ and cancer segmentation in abdomen Computed Tomography (CT) scans is
the prerequisite for precise cancer diagnosis and treatment. Most existing
benchmarks and algorithms are tailored to specific cancer types, limiting their
ability to provide comprehensive cancer analysis. This work presents the first
international competition on abdominal organ and pan-cancer segmentation by
providing a large-scale and diverse dataset, including 4650 CT scans with
various cancer types from over 40 medical centers. The winning team established
a new state-of-the-art with a deep learning-based cascaded framework, achieving
average Dice Similarity Coefficient scores of 92.3% for organs and 64.9% for
lesions on the hidden multi-national testing set. The dataset and code of top
teams are publicly available, offering a benchmark platform to drive further
innovations https://codalab.lisn.upsaclay.fr/competitions/12239.

摘要：器官和癌症分割在腹部電腦斷層掃描 (CT) 中是精確癌症診斷和治療的先決條件。大多數現有的基準和演算法都是針對特定癌症類型量身打造，這限制了它們提供全面癌症分析的能力。這項工作提供了第一個關於腹部器官和泛癌分割的國際競賽，方法是提供一個大型且多樣化的資料集，其中包括來自 40 多個醫療中心的 4650 個 CT 掃描，其中包含各種癌症類型。獲勝團隊建立了一個新的最先進的深度學習級聯框架，在隱藏的多國測試集中實現了器官的平均 Dice 相似性系數分數 92.3%，病灶的平均 Dice 相似性系數分數 64.9%。頂尖團隊的資料集和程式碼公開提供，提供了一個基準平台，以推動進一步的創新 https://codalab.lisn.upsaclay.fr/competitions/12239。

##### **MEDCO: Medical Education Copilots Based on A Multi-Agent Framework**
2408.12496v1 by Hao Wei, Jianing Qiu, Haibao Yu, Wu Yuan

Large language models (LLMs) have had a significant impact on diverse
research domains, including medicine and healthcare. However, the potential of
LLMs as copilots in medical education remains underexplored. Current
AI-assisted educational tools are limited by their solitary learning approach
and inability to simulate the multi-disciplinary and interactive nature of
actual medical training. To address these limitations, we propose MEDCO
(Medical EDucation COpilots), a novel multi-agent-based copilot system
specially developed to emulate real-world medical training environments. MEDCO
incorporates three primary agents: an agentic patient, an expert doctor, and a
radiologist, facilitating a multi-modal and interactive learning environment.
Our framework emphasizes the learning of proficient question-asking skills,
multi-disciplinary collaboration, and peer discussions between students. Our
experiments show that simulated virtual students who underwent training with
MEDCO not only achieved substantial performance enhancements comparable to
those of advanced models, but also demonstrated human-like learning behaviors
and improvements, coupled with an increase in the number of learning samples.
This work contributes to medical education by introducing a copilot that
implements an interactive and collaborative learning approach. It also provides
valuable insights into the effectiveness of AI-integrated training paradigms.

摘要：大型語言模型 (LLM) 對不同研究領域產生重大影響，包括醫學和保健。然而，LLM 作為醫學教育副手的潛力仍未被充分探討。目前的 AI 輔助教育工具受到其單獨學習方法的限制，且無法模擬實際醫學訓練的多學科和互動性質。為了解決這些限制，我們提出 MEDCO（醫學教育副手），一種新穎的多代理人協作系統，專門開發用於模擬真實世界的醫學訓練環境。MEDCO 結合了三個主要代理人：一個代理人患者、一個專家醫生和一個放射科醫生，促進多模式和互動學習環境。我們的架構強調學習熟練的提問技巧、跨學科協作和學生之間的同儕討論。我們的實驗表明，接受 MEDCO 訓練的模擬虛擬學生不僅獲得與進階模型相當的顯著效能提升，還表現出類似人類的學習行為和進步，並伴隨著學習樣本數量的增加。這項工作透過引入一個實施互動和協作學習方法的副手，對醫學教育有所貢獻。它也提供了對 AI 整合訓練模式有效性的寶貴見解。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation**
2408.12466v1 by Palak Handa, Manas Dhir, Amirreza Mahbod, Florian Schwarzhans, Ramona Woitek, Nidhi Goel, Deepak Gunjan

Computer-based analysis of Wireless Capsule Endoscopy (WCE) is crucial.
However, a medically annotated WCE dataset for training and evaluation of
automatic classification, detection, and segmentation of bleeding and
non-bleeding frames is currently lacking. The present work focused on
development of a medically annotated WCE dataset called WCEbleedGen for
automatic classification, detection, and segmentation of bleeding and
non-bleeding frames. It comprises 2,618 WCE bleeding and non-bleeding frames
which were collected from various internet resources and existing WCE datasets.
A comprehensive benchmarking and evaluation of the developed dataset was done
using nine classification-based, three detection-based, and three
segmentation-based deep learning models. The dataset is of high-quality, is
class-balanced and contains single and multiple bleeding sites. Overall, our
standard benchmark results show that Visual Geometric Group (VGG) 19, You Only
Look Once version 8 nano (YOLOv8n), and Link network (Linknet) performed best
in automatic classification, detection, and segmentation-based evaluations,
respectively. Automatic bleeding diagnosis is crucial for WCE video
interpretations. This diverse dataset will aid in developing of real-time,
multi-task learning-based innovative solutions for automatic bleeding diagnosis
in WCE. The dataset and code are publicly available at
https://zenodo.org/records/10156571 and
https://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset.

摘要：<paragraph>無線膠囊內視鏡 (WCE) 的電腦分析至關重要。
然而，目前缺乏一個醫學標註的 WCE 資料集，用於訓練和評估出血和非出血幀的自動分類、檢測和分割。本研究專注於開發一個名為 WCEbleedGen 的醫學標註 WCE 資料集，用於出血和非出血幀的自動分類、檢測和分割。它包含 2,618 個 WCE 出血和非出血幀，這些幀是從各種網路資源和現有的 WCE 資料集中收集的。使用九個基於分類、三個基於檢測和三個基於分割的深度學習模型對開發的資料集進行了全面的基準測試和評估。該資料集質量高、類別平衡且包含單個和多個出血部位。總體而言，我們的標準基準測試結果表明，Visual Geometric Group (VGG) 19、You Only Look Once 版本 8 nano (YOLOv8n) 和 Link 網路 (Linknet) 在自動分類、檢測和基於分割的評估中表現最佳，分別。自動出血診斷對於 WCE 視訊解讀至關重要。這個多樣化的資料集將有助於開發用於 WCE 中自動出血診斷的基於實時、多任務學習的創新解決方案。該資料集和程式碼可在 https://zenodo.org/records/10156571 和 https://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset 公開獲得。</paragraph>


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-10**|**Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving**|Kairui Ding et.al.|[2409.06702v1](http://arxiv.org/abs/2409.06702v1)|null|
|**2024-09-10**|**Geometric-Averaged Preference Optimization for Soft Preference Labels**|Hiroki Furuta et.al.|[2409.06691v1](http://arxiv.org/abs/2409.06691v1)|null|
|**2024-09-10**|**Benchmarking Sub-Genre Classification For Mainstage Dance Music**|Hongzhi Shu et.al.|[2409.06690v1](http://arxiv.org/abs/2409.06690v1)|null|
|**2024-09-10**|**E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning**|Zihan Liao et.al.|[2409.06679v1](http://arxiv.org/abs/2409.06679v1)|null|
|**2024-09-10**|**Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI**|Cristian Trout et.al.|[2409.06673v1](http://arxiv.org/abs/2409.06673v1)|null|
|**2024-09-10**|**LLaMA-Omni: Seamless Speech Interaction with Large Language Models**|Qingkai Fang et.al.|[2409.06666v1](http://arxiv.org/abs/2409.06666v1)|[link](https://github.com/ictnlp/llama-omni)|
|**2024-09-10**|**Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens**|Taejin Park et.al.|[2409.06656v1](http://arxiv.org/abs/2409.06656v1)|null|
|**2024-09-10**|**EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**|Danli Shi et.al.|[2409.06644v2](http://arxiv.org/abs/2409.06644v2)|null|
|**2024-09-10**|**TeXBLEU: Automatic Metric for Evaluate LaTeX Format**|Kyudan Jung et.al.|[2409.06639v1](http://arxiv.org/abs/2409.06639v1)|[link](https://github.com/kyudan1/texbleu)|
|**2024-09-10**|**MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders**|Wenyu Zhang et.al.|[2409.06635v1](http://arxiv.org/abs/2409.06635v1)|null|
|**2024-09-10**|**A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio**|Ningyuan Xi et.al.|[2409.06624v1](http://arxiv.org/abs/2409.06624v1)|null|
|**2024-09-10**|**Exploring Italian sentence embeddings properties through multi-tasking**|Vivi Nastase et.al.|[2409.06622v1](http://arxiv.org/abs/2409.06622v1)|null|
|**2024-09-10**|**Label-free Monitoring of Self-Supervised Learning Progress**|Isaac Xu et.al.|[2409.06612v1](http://arxiv.org/abs/2409.06612v1)|null|
|**2024-09-10**|**Alleviating Hallucinations in Large Language Models with Scepticism Modeling**|Yetao Wu et.al.|[2409.06601v1](http://arxiv.org/abs/2409.06601v1)|null|
|**2024-09-10**|**GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering**|Sacha Muller et.al.|[2409.06595v1](http://arxiv.org/abs/2409.06595v1)|null|
|**2024-09-10**|**Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**|Zoe Hancox et.al.|[2409.06585v1](http://arxiv.org/abs/2409.06585v1)|[link](https://github.com/zoehancox/sparse_tgcnn)|
|**2024-09-10**|**Quantifying and Enabling the Interpretability of CLIP-like Models**|Avinash Madasu et.al.|[2409.06579v1](http://arxiv.org/abs/2409.06579v1)|null|
|**2024-09-10**|**Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement**|Vivi Nastase et.al.|[2409.06567v1](http://arxiv.org/abs/2409.06567v1)|null|
|**2024-09-10**|**Indirect Dynamic Negotiation in the Nash Demand Game**|Tatiana V. Guy et.al.|[2409.06566v1](http://arxiv.org/abs/2409.06566v1)|null|
|**2024-09-10**|**From LIMA to DeepLIMA: following a new path of interoperability**|Victor Bocharov et.al.|[2409.06550v1](http://arxiv.org/abs/2409.06550v1)|null|
|**2024-09-10**|**Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings**|Jan Elfes et.al.|[2409.06540v1](http://arxiv.org/abs/2409.06540v1)|null|
|**2024-09-10**|**Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games**|Juhwan Choi et.al.|[2409.06518v1](http://arxiv.org/abs/2409.06518v1)|null|
|**2024-09-10**|**Sine, Transient, Noise Neural Modeling of Piano Notes**|Riccardo Simionato et.al.|[2409.06513v1](http://arxiv.org/abs/2409.06513v1)|null|
|**2024-09-10**|**Aligning Machine and Human Visual Representations across Abstraction Levels**|Lukas Muttenthaler et.al.|[2409.06509v1](http://arxiv.org/abs/2409.06509v1)|null|
|**2024-09-10**|**Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout**|Atharva Gundawar et.al.|[2409.06477v1](http://arxiv.org/abs/2409.06477v1)|null|
|**2024-09-10**|**An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition**|Yi-Cheng Wang et.al.|[2409.06468v1](http://arxiv.org/abs/2409.06468v1)|null|
|**2024-09-10**|**Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles**|Qiujing Lu et.al.|[2409.06450v1](http://arxiv.org/abs/2409.06450v1)|null|
|**2024-09-10**|**HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data**|Hossein Hajipour et.al.|[2409.06446v1](http://arxiv.org/abs/2409.06446v1)|null|
|**2024-09-10**|**Learning Generative Interactive Environments By Trained Agent Exploration**|Naser Kazemi et.al.|[2409.06445v1](http://arxiv.org/abs/2409.06445v1)|[link](https://github.com/insait-institute/genieredux)|
|**2024-09-10**|**GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning**|Kento Kawaharazuka et.al.|[2409.06427v1](http://arxiv.org/abs/2409.06427v1)|null|
|**2024-09-10**|**Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes**|Ludvig Lemner et.al.|[2409.06416v1](http://arxiv.org/abs/2409.06416v1)|null|
|**2024-09-10**|**Length Desensitization in Directed Preference Optimization**|Wei Liu et.al.|[2409.06411v1](http://arxiv.org/abs/2409.06411v1)|null|
|**2024-09-10**|**Coarse-Grained Sense Inventories Based on Semantic Matching between English Dictionaries**|Masato Kikuchi et.al.|[2409.06386v1](http://arxiv.org/abs/2409.06386v1)|null|
|**2024-09-10**|**Enhancing Sequential Recommendations through Multi-Perspective Reflections and Iteration**|Weicong Qin et.al.|[2409.06377v1](http://arxiv.org/abs/2409.06377v1)|null|
|**2024-09-10**|**SpeechTaxi: On Multilingual Semantic Speech Classification**|Lennart Keller et.al.|[2409.06372v1](http://arxiv.org/abs/2409.06372v1)|null|
|**2024-09-10**|**Distilling Generative-Discriminative Representations for Very Low-Resolution Face Recognition**|Junzheng Zhang et.al.|[2409.06371v1](http://arxiv.org/abs/2409.06371v1)|null|
|**2024-09-10**|**Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development**|Tianwu Lei et.al.|[2409.06367v1](http://arxiv.org/abs/2409.06367v1)|null|
|**2024-09-10**|**Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks**|Teresa Dorszewski et.al.|[2409.06362v1](http://arxiv.org/abs/2409.06362v1)|null|
|**2024-09-10**|**MAGDA: Multi-agent guideline-driven diagnostic assistance**|David Bani-Harouni et.al.|[2409.06351v1](http://arxiv.org/abs/2409.06351v1)|null|
|**2024-09-10**|**VoiceWukong: Benchmarking Deepfake Voice Detection**|Ziwei Yan et.al.|[2409.06348v1](http://arxiv.org/abs/2409.06348v1)|null|
|**2024-09-10**|**Compute-Update Federated Learning: A Lattice Coding Approach**|Seyed Mohammad Azimi-Abarghouyi et.al.|[2409.06343v1](http://arxiv.org/abs/2409.06343v1)|null|
|**2024-09-10**|**Retrieval Or Holistic Understanding? Dolce: Differentiate Our Long Context Evaluation Tasks**|Zi Yang et.al.|[2409.06338v1](http://arxiv.org/abs/2409.06338v1)|null|
|**2024-09-10**|**Towards Agentic AI on Particle Accelerators**|Antonin Sulc et.al.|[2409.06336v1](http://arxiv.org/abs/2409.06336v1)|null|
|**2024-09-10**|**Extracting Paragraphs from LLM Token Activations**|Nicholas Pochinkov et.al.|[2409.06328v1](http://arxiv.org/abs/2409.06328v1)|null|
|**2024-09-10**|**LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs**|Siqing Li et.al.|[2409.06323v1](http://arxiv.org/abs/2409.06323v1)|null|
|**2024-09-10**|**An End-to-End Approach for Chord-Conditioned Song Generation**|Shuochen Gao et.al.|[2409.06307v1](http://arxiv.org/abs/2409.06307v1)|null|
|**2024-09-10**|**Enhancing Long Video Understanding via Hierarchical Event-Based Memory**|Dingxin Cheng et.al.|[2409.06299v1](http://arxiv.org/abs/2409.06299v1)|null|
|**2024-09-10**|**User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study**|Julien Albert et.al.|[2409.06297v1](http://arxiv.org/abs/2409.06297v1)|null|
|**2024-09-10**|**Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models**|Zitao Chen et.al.|[2409.06280v1](http://arxiv.org/abs/2409.06280v1)|null|
|**2024-09-10**|**Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models**|Yao Shu et.al.|[2409.06277v2](http://arxiv.org/abs/2409.06277v2)|[link](https://github.com/allen4747/Ferret)|
|**2024-09-10**|**Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking**|Jihyun Lee et.al.|[2409.06263v1](http://arxiv.org/abs/2409.06263v1)|null|
|**2024-09-10**|**DiPT: Enhancing LLM reasoning through diversified perspective-taking**|Hoang Anh Just et.al.|[2409.06241v1](http://arxiv.org/abs/2409.06241v1)|null|
|**2024-09-10**|**NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit**|Linfeng Zhang et.al.|[2409.06226v1](http://arxiv.org/abs/2409.06226v1)|null|
|**2024-09-10**|**Enhancing Temporal Understanding in Audio Question Answering for Large Audio Language Models**|Arvind Krishna Sridhar et.al.|[2409.06223v1](http://arxiv.org/abs/2409.06223v1)|null|
|**2024-09-10**|**Advancing Topic Segmentation of Broadcasted Speech with Multilingual Semantic Embeddings**|Sakshi Deo Shukla et.al.|[2409.06222v1](http://arxiv.org/abs/2409.06222v1)|null|
|**2024-09-10**|**CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities**|Rashik Shahriar Akash et.al.|[2409.06220v1](http://arxiv.org/abs/2409.06220v1)|null|
|**2024-09-10**|**SubRegWeigh: Effective and Efficient Annotation Weighing with Subword Regularization**|Kohei Tsuji et.al.|[2409.06216v1](http://arxiv.org/abs/2409.06216v1)|null|
|**2024-09-10**|**Towards Generalizable Scene Change Detection**|Jaewoo Kim et.al.|[2409.06214v1](http://arxiv.org/abs/2409.06214v1)|null|
|**2024-09-10**|**STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning**|Jaeseong Lee et.al.|[2409.06211v1](http://arxiv.org/abs/2409.06211v1)|null|
|**2024-09-10**|**Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis**|Xin Zhang et.al.|[2409.06209v1](http://arxiv.org/abs/2409.06209v1)|null|
|**2024-09-10**|**SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs**|Wanli Qian et.al.|[2409.06205v1](http://arxiv.org/abs/2409.06205v1)|null|
|**2024-09-10**|**NOVI : Chatbot System for University Novice with BERT and LLMs**|Yoonji Nam et.al.|[2409.06192v1](http://arxiv.org/abs/2409.06192v1)|null|
|**2024-09-10**|**Can Large Language Models Unlock Novel Scientific Research Ideas?**|Sandeep Kumar et.al.|[2409.06185v1](http://arxiv.org/abs/2409.06185v1)|null|
|**2024-09-10**|**SQLucid: Grounding Natural Language Database Queries with Interactive Explanations**|Yuan Tian et.al.|[2409.06178v1](http://arxiv.org/abs/2409.06178v1)|[link](https://github.com/magic-yuantian/sqlucid)|
|**2024-09-10**|**Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks**|Georgios Chochlakis et.al.|[2409.06173v1](http://arxiv.org/abs/2409.06173v1)|[link](https://github.com/gchochla/cot-priors)|
|**2024-09-10**|**Deep Learning and Large Language Models for Audio and Text Analysis in Predicting Suicidal Acts in Chinese Psychological Support Hotlines**|Yining Chen et.al.|[2409.06164v1](http://arxiv.org/abs/2409.06164v1)|null|
|**2024-09-10**|**Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings**|Dong Han et.al.|[2409.06147v1](http://arxiv.org/abs/2409.06147v1)|null|
|**2024-09-10**|**Draw an Audio: Leveraging Multi-Instruction for Video-to-Audio Synthesis**|Qi Yang et.al.|[2409.06135v1](http://arxiv.org/abs/2409.06135v1)|null|
|**2024-09-10**|**Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review**|Neha Prakriya et.al.|[2409.06131v1](http://arxiv.org/abs/2409.06131v1)|null|
|**2024-09-10**|**On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective**|Aoting Hu et.al.|[2409.06130v1](http://arxiv.org/abs/2409.06130v1)|[link](https://github.com/katerina828/iwe)|
|**2024-09-10**|**Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science**|E. Wes Bethel et.al.|[2409.06122v1](http://arxiv.org/abs/2409.06122v1)|null|
|**2024-09-09**|**PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for Safe Navigation Under Perception Uncertainty**|Sara Pohland et.al.|[2409.06111v1](http://arxiv.org/abs/2409.06111v1)|null|
|**2024-09-09**|**Doppelgänger's Watch: A Split Objective Approach to Large Language Models**|Shervin Ghasemlou et.al.|[2409.06107v1](http://arxiv.org/abs/2409.06107v1)|null|
|**2024-09-09**|**ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog**|Yujian Gan et.al.|[2409.06097v1](http://arxiv.org/abs/2409.06097v1)|null|
|**2024-09-09**|**Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer**|Michele Mancusi et.al.|[2409.06096v1](http://arxiv.org/abs/2409.06096v1)|null|
|**2024-09-09**|**Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**|Dongyue Li et.al.|[2409.06091v1](http://arxiv.org/abs/2409.06091v1)|[link](https://github.com/virtuosoresearch/scalablemtl)|
|**2024-09-09**|**MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization**|Faezeh Faez et.al.|[2409.06077v1](http://arxiv.org/abs/2409.06077v1)|null|
|**2024-09-09**|**DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection**|Joymallya Chakraborty et.al.|[2409.06072v1](http://arxiv.org/abs/2409.06072v1)|null|
|**2024-09-09**|**Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research**|Osama Zafar et.al.|[2409.06069v1](http://arxiv.org/abs/2409.06069v1)|null|
|**2024-09-09**|**MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data**|Jianyi Zhang et.al.|[2409.06067v1](http://arxiv.org/abs/2409.06067v1)|null|
|**2024-09-09**|**Identifying the sources of ideological bias in GPT models through linguistic variation in output**|Christina Walker et.al.|[2409.06043v1](http://arxiv.org/abs/2409.06043v1)|null|
|**2024-09-09**|**Investigating Causal Cues: Strengthening Spoofed Audio Detection with Human-Discernible Linguistic Features**|Zahra Khanjani et.al.|[2409.06033v1](http://arxiv.org/abs/2409.06033v1)|null|
|**2024-09-09**|**SongCreator: Lyrics-based Universal Song Generation**|Shun Lei et.al.|[2409.06029v1](http://arxiv.org/abs/2409.06029v1)|null|
|**2024-09-09**|**Deep Generative Model for Mechanical System Configuration Design**|Yasaman Etesam et.al.|[2409.06016v1](http://arxiv.org/abs/2409.06016v1)|null|
|**2024-09-09**|**Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings**|Leanne Nortje et.al.|[2409.06013v1](http://arxiv.org/abs/2409.06013v1)|null|
|**2024-09-09**|**TransformerRanker: A Tool for Efficiently Finding the Best-Suited Language Models for Downstream Classification Tasks**|Lukas Garbas et.al.|[2409.05997v1](http://arxiv.org/abs/2409.05997v1)|[link](https://github.com/flairnlp/transformer-ranker)|
|**2024-09-09**|**MessIRve: A Large-Scale Spanish Information Retrieval Dataset**|Francisco Valentini et.al.|[2409.05994v1](http://arxiv.org/abs/2409.05994v1)|null|
|**2024-09-09**|**A Comprehensive Comparison Between ANNs and KANs For Classifying EEG Alzheimer's Data**|Akshay Sunkara et.al.|[2409.05989v1](http://arxiv.org/abs/2409.05989v1)|null|
|**2024-09-09**|**AI for Mathematics Mathematical Formalized Problem Solving and Theorem Proving in Different Fields in Lean4**|Xichen Tang et.al.|[2409.05977v1](http://arxiv.org/abs/2409.05977v1)|null|
|**2024-09-09**|**A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets**|Mariana Yukari Noguti et.al.|[2409.05972v1](http://arxiv.org/abs/2409.05972v1)|null|
|**2024-09-09**|**Promptable Closed-loop Traffic Simulation**|Shuhan Tan et.al.|[2409.05863v1](http://arxiv.org/abs/2409.05863v1)|null|
|**2024-09-09**|**MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct**|Run Luo et.al.|[2409.05840v1](http://arxiv.org/abs/2409.05840v1)|null|
|**2024-09-09**|**DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning**|Condy Bao et.al.|[2409.05938v1](http://arxiv.org/abs/2409.05938v1)|null|
|**2024-09-09**|**Improving Pretraining Data Using Perplexity Correlations**|Tristan Thrush et.al.|[2409.05816v1](http://arxiv.org/abs/2409.05816v1)|null|
|**2024-09-09**|**The Future of Software Testing: AI-Powered Test Case Generation and Validation**|Mohammad Baqar et.al.|[2409.05808v1](http://arxiv.org/abs/2409.05808v1)|null|
|**2024-09-09**|**Benchmarking Chinese Knowledge Rectification in Large Language Models**|Tianhe Lu et.al.|[2409.05806v1](http://arxiv.org/abs/2409.05806v1)|[link](https://github.com/zjunlp/easyedit)|
|**2024-09-09**|**Enhancing Preference-based Linear Bandits via Human Response Time**|Shen Li et.al.|[2409.05798v1](http://arxiv.org/abs/2409.05798v1)|null|
|**2024-09-09**|**NeurLZ: On Enhancing Lossy Compression Performance based on Error-Controlled Neural Learning for Scientific Data**|Wenqi Jia et.al.|[2409.05785v2](http://arxiv.org/abs/2409.05785v2)|null|
|**2024-09-09**|**Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models**|Emily Cheng et.al.|[2409.05771v1](http://arxiv.org/abs/2409.05771v1)|null|
|**2024-09-09**|**Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models**|Rohit Jena et.al.|[2409.06493v1](http://arxiv.org/abs/2409.06493v1)|null|

#### Abstracts
##### **Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving**
2409.06702v1 by Kairui Ding, Boyuan Chen, Yuchen Su, Huan-ang Gao, Bu Jin, Chonghao Sima, Wuqiang Zhang, Xiaohui Li, Paul Barsch, Hongyang Li, Hao Zhao

End-to-end architectures in autonomous driving (AD) face a significant
challenge in interpretability, impeding human-AI trust. Human-friendly natural
language has been explored for tasks such as driving explanation and 3D
captioning. However, previous works primarily focused on the paradigm of
declarative interpretability, where the natural language interpretations are
not grounded in the intermediate outputs of AD systems, making the
interpretations only declarative. In contrast, aligned interpretability
establishes a connection between language and the intermediate outputs of AD
systems. Here we introduce Hint-AD, an integrated AD-language system that
generates language aligned with the holistic perception-prediction-planning
outputs of the AD model. By incorporating the intermediate outputs and a
holistic token mixer sub-network for effective feature adaptation, Hint-AD
achieves desirable accuracy, achieving state-of-the-art results in driving
language tasks including driving explanation, 3D dense captioning, and command
prediction. To facilitate further study on driving explanation task on
nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and
models will be publicly available.

摘要：端對端自動駕駛 (AD) 架構在可解釋性上會面臨重大挑戰，阻礙人類對 AI 的信任。人類友善的自然語言已被探索用於駕駛解釋和 3D 字幕等任務。然而，先前的作品主要集中在宣告式可解釋性的範例上，其中自然語言解釋並未奠基於 AD 系統的中間輸出，使得解釋僅為宣告式。相反地，校準的可解釋性在語言和 AD 系統的中間輸出之間建立了連結。在此我們介紹 Hint-AD，一個整合的 AD 語言系統，用於產生與 AD 模型的整體感知預測規劃輸出校準的語言。透過結合中間輸出和一個用於有效特徵適應的整體標記混合器子網路，Hint-AD 達到了理想的準確度，在駕駛語言任務中取得了最先進的成果，包括駕駛解釋、3D 密集字幕和指令預測。為了促進在 nuScenes 上進一步研究駕駛解釋任務，我們還介紹了一個人類標記的資料集 Nu-X。程式碼、資料集和模型將公開提供。

##### **Geometric-Averaged Preference Optimization for Soft Preference Labels**
2409.06691v1 by Hiroki Furuta, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur

Many algorithms for aligning LLMs with human preferences assume that human
preferences are binary and deterministic. However, it is reasonable to think
that they can vary with different individuals, and thus should be
distributional to reflect the fine-grained relationship between the responses.
In this work, we introduce the distributional soft preference labels and
improve Direct Preference Optimization (DPO) with a weighted geometric average
of the LLM output likelihood in the loss function. In doing so, the scale of
learning loss is adjusted based on the soft labels, and the loss with equally
preferred responses would be close to zero. This simple modification can be
easily applied to any DPO family and helps the models escape from the
over-optimization and objective mismatch prior works suffer from. In our
experiments, we simulate the soft preference labels with AI feedback from LLMs
and demonstrate that geometric averaging consistently improves performance on
standard benchmarks for alignment research. In particular, we observe more
preferable responses than binary labels and significant improvements with data
where modestly-confident labels are in the majority.

摘要：許多用於將 LLM 與人類偏好對齊的演算法假設人類偏好是二元的且確定的。然而，可以合理地認為它們會因人而異，因此應以分佈式方式反映回應之間的細微關係。在這項工作中，我們引入了分佈式軟偏好標籤，並使用損失函數中 LLM 輸出似然加權幾何平均值改進了直接偏好最佳化 (DPO)。在這樣做的過程中，學習損失的規模會根據軟標籤進行調整，並且具有相同偏好回應的損失將接近於零。這個簡單的修改可以輕鬆應用於任何 DPO 家族，並幫助模型擺脫過度最佳化和目標不匹配的問題。在我們的實驗中，我們使用來自 LLM 的 AI 回饋模擬軟偏好標籤，並證明幾何平均始終改善對齊研究的標準基準的效能。特別是，我們觀察到比二元標籤更理想的回應，並且在中度自信標籤佔多數的資料中獲得顯著的改進。

##### **Benchmarking Sub-Genre Classification For Mainstage Dance Music**
2409.06690v1 by Hongzhi Shu, Xinglin Li, Hongyu Jiang, Minghao Fu, Xinyu Li

Music classification, with a wide range of applications, is one of the most
prominent tasks in music information retrieval. To address the absence of
comprehensive datasets and high-performing methods in the classification of
mainstage dance music, this work introduces a novel benchmark comprising a new
dataset and a baseline. Our dataset extends the number of sub-genres to cover
most recent mainstage live sets by top DJs worldwide in music festivals. A
continuous soft labeling approach is employed to account for tracks that span
multiple sub-genres, preserving the inherent sophistication. For the baseline,
we developed deep learning models that outperform current state-of-the-art
multimodel language models, which struggle to identify house music sub-genres,
emphasizing the need for specialized models trained on fine-grained datasets.
Our benchmark is applicable to serve for application scenarios such as music
recommendation, DJ set curation, and interactive multimedia, where we also
provide video demos. Our code is on
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.

摘要：音樂分類擁有廣泛的應用，是音樂資訊檢索中最突出的任務之一。為了解決主流舞曲分類中缺乏全面資料集和高性能方法的問題，這項工作引入了一個包含新資料集和基準的新基準。我們的資料集擴展了子類型的數量，涵蓋了全球頂尖 DJ 在音樂節中的最新主流現場表演。採用連續軟標籤方法來考量橫跨多個子類型的曲目，保留其固有的複雜性。對於基準，我們開發了深度學習模型，其效能優於目前的最新多模式語言模型，而後者難以識別浩室音樂子類型，強調了針對細粒度資料集訓練的專門模型的必要性。我們的基準適用於音樂推薦、DJ 組合策展和互動多媒體等應用場景，我們也提供影片示範。我們的程式碼位於
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}。

##### **E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning**
2409.06679v1 by Zihan Liao, Jun Wang, Hang Yu, Lingxiao Wei, Jianguo Li, Jun Wang, Wei Zhang

In the realm of Large Language Models (LLMs), the ability to process long
contexts is increasingly crucial for tasks such as multi-round dialogues, code
generation, and document summarization. This paper addresses the challenges of
enhancing the long-context performance, reducing computational complexity, and
leveraging pretrained models collectively termed the "impossible triangle." We
introduce E2LLM (Encoder Elongated Large Language Models), a novel approach
that effectively navigates this paradox. The method involves splitting long
contexts into chunks, compressing each into embedding vectors via a pretrained
text encoder, and utilizing an adapter to align these representations with a
decoder-only LLM. Two training objectives, focusing on reconstruction of the
encoder output and long-context instruction fine-tuning, are employed to
facilitate the understanding of soft prompts by the LLM. Experimental results
demonstrate that E2LLM achieves superior performance in long-context scenarios
while balancing efficiency, performance, and compatibility with pretrained
models. Our framework thus represents a significant advancement in the field,
contributing to effective long-text modeling.

摘要：在大語言模型 (LLM) 領域中，處理長語境的能耐對於多輪對話、程式碼產生和文件摘要等任務越來越重要。本文探討了增強長語境效能、降低計算複雜度和運用預訓練模型的挑戰，這些挑戰統稱為「不可能三角」。我們引入了 E2LLM（編碼器延伸大語言模型），這是一種新穎的方法，可以有效地解決這個悖論。此方法包括將長語境分割成區塊，透過預訓練文本編碼器將每個區塊壓縮成嵌入向量，並使用適配器將這些表示與僅解碼器 LLM 對齊。兩個訓練目標，專注於重建編碼器輸出和長語境指令微調，用於促進 LLM 對軟提示的理解。實驗結果表明，E2LLM 在長語境場景中實現了卓越的效能，同時平衡了效率、效能和與預訓練模型的相容性。因此，我們的架構代表了該領域的重大進展，有助於有效的長文本建模。

##### **Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI**
2409.06673v1 by Cristian Trout

As AI systems become more autonomous and capable, experts warn of them
potentially causing catastrophic losses. Drawing on the successful precedent
set by the nuclear power industry, this paper argues that developers of
frontier AI models should be assigned limited, strict, and exclusive third
party liability for harms resulting from Critical AI Occurrences (CAIOs) -
events that cause or easily could have caused catastrophic losses. Mandatory
insurance for CAIO liability is recommended to overcome developers'
judgment-proofness, mitigate winner's curse dynamics, and leverage insurers'
quasi-regulatory abilities. Based on theoretical arguments and observations
from the analogous nuclear power context, insurers are expected to engage in a
mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and
providing loss prevention guidance in the context of insuring against
heavy-tail risks from AI. While not a substitute for regulation, clear
liability assignment and mandatory insurance can help efficiently allocate
resources to risk-modeling and safe design, facilitating future regulatory
efforts.

摘要：隨著 AI 系統變得更加自主且強大，專家警告它們可能會造成災難性的損失。本文借鑑核能產業設定的成功先例，主張前沿 AI 模型的開發者應承擔有限、嚴格且專屬的第三方責任，以彌補關鍵 AI 事件 (CAIO) 所造成的損害，而 CAIO 是造成或可能造成災難性損失的事件。建議強制為 CAIO 責任投保，以克服開發者的抗辯不能性，減輕贏家的詛咒動態，並利用保險人的準監管能力。根據理論論點和類比核能脈絡的觀察，保險人預計將從事因果風險建模、監控、遊說更嚴格的法規，以及在承保 AI 重尾風險的背景下提供損失預防指導。儘管無法取代法規，但明確的責任分配和強制保險有助於有效分配資源以進行風險建模和安全設計，促進未來的法規制定工作。

##### **LLaMA-Omni: Seamless Speech Interaction with Large Language Models**
2409.06666v1 by Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, Yang Feng

Models like GPT-4o enable real-time interaction with large language models
(LLMs) through speech, significantly enhancing user experience compared to
traditional text-based interaction. However, there is still a lack of
exploration on how to build speech interaction models based on open-source
LLMs. To address this, we propose LLaMA-Omni, a novel model architecture
designed for low-latency and high-quality speech interaction with LLMs.
LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,
and a streaming speech decoder. It eliminates the need for speech
transcription, and can simultaneously generate text and speech responses
directly from speech instructions with extremely low latency. We build our
model based on the latest Llama-3.1-8B-Instruct model. To align the model with
speech interaction scenarios, we construct a dataset named InstructS2S-200K,
which includes 200K speech instructions and corresponding speech responses.
Experimental results show that compared to previous speech-language models,
LLaMA-Omni provides better responses in both content and style, with a response
latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3
days on just 4 GPUs, paving the way for the efficient development of
speech-language models in the future.

摘要：LLaMA-Omni 等模型能透過語音與大型語言模型 (LLM) 進行即時互動，與傳統的文字互動相比，大幅提升使用者體驗。然而，關於如何根據開放原始碼 LLM 建構語音互動模型，目前仍缺乏探討。為了解決這個問題，我們提出 LLaMA-Omni，一種新穎的模型架構，專為與 LLM 進行低延遲、高品質的語音互動而設計。LLaMA-Omni 整合了預訓練的語音編碼器、語音適配器、LLM 和串流語音解碼器。它消除了語音轉錄的需要，並能直接從語音指令產生文字和語音回應，且延遲極低。我們根據最新的 Llama-3.1-8B-Instruct 模型建立我們的模型。為了讓模型與語音互動情境相符，我們建構了一個名為 InstructS2S-200K 的資料集，其中包含 200K 個語音指令和對應的語音回應。實驗結果顯示，與先前的語音語言模型相比，LLaMA-Omni 在內容和風格上提供了更好的回應，回應延遲低至 226 毫秒。此外，訓練 LLaMA-Omni 只需要不到 3 天的時間，而且僅使用 4 個 GPU，為未來語音語言模型的有效開發鋪路。

##### **Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens**
2409.06656v1 by Taejin Park, Ivan Medennikov, Kunal Dhawan, Weiqing Wang, He Huang, Nithin Rao Koluguri, Krishna C. Puvvada, Jagadeesh Balam, Boris Ginsburg

We propose Sortformer, a novel neural model for speaker diarization, trained
with unconventional objectives compared to existing end-to-end diarization
models. The permutation problem in speaker diarization has long been regarded
as a critical challenge. Most prior end-to-end diarization systems employ
permutation invariant loss (PIL), which optimizes for the permutation that
yields the lowest error. In contrast, we introduce Sort Loss, which enables a
diarization model to autonomously resolve permutation, with or without PIL. We
demonstrate that combining Sort Loss and PIL achieves performance competitive
with state-of-the-art end-to-end diarization models trained exclusively with
PIL. Crucially, we present a streamlined multispeaker ASR architecture that
leverages Sortformer as a speaker supervision model, embedding speaker label
estimation within the ASR encoder state using a sinusoidal kernel function.
This approach resolves the speaker permutation problem through sorted
objectives, effectively bridging speaker-label timestamps and speaker tokens.
In our experiments, we show that the proposed multispeaker ASR architecture,
enhanced with speaker supervision, improves performance via adapter techniques.
Code and trained models will be made publicly available via the NVIDIA NeMo
framework

摘要：我們提出 Sortformer，這是一個用於說話者分組的新型神經模型，它與現有的端到端分組模型相比，採用了非常規的目標進行訓練。說話者分組中的排列問題長期以來一直被認為是一個關鍵挑戰。大多數先前的端到端分組系統採用排列不變損失 (PIL)，它針對產生最低錯誤的排列進行優化。相比之下，我們引入了分類損失，它使分組模型能夠自主解決排列，無論是否使用 PIL。我們證明了將分類損失和 PIL 結合起來，可以實現與僅使用 PIL 訓練的最新端到端分組模型相媲美的效能。至關重要的是，我們提出了一個簡化的多說話者 ASR 架構，它利用 Sortformer 作為說話者監督模型，使用正弦核函數在 ASR 編碼器狀態中嵌入說話者標籤估計。這種方法通過分類目標解決了說話者排列問題，有效地橋接了說話者標籤時間戳和說話者標記。在我們的實驗中，我們展示了通過適配器技術增強的建議多說話者 ASR 架構通過適配器技術改善了效能。程式碼和訓練好的模型將通過 NVIDIA NeMo 框架公開。

##### **EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**
2409.06644v2 by Danli Shi, Weiyi Zhang, Jiancheng Yang, Siyu Huang, Xiaolan Chen, Mayinuer Yusufu, Kai Jin, Shan Lin, Shunming Liu, Qing Zhang, Mingguang He

Early detection of eye diseases like glaucoma, macular degeneration, and
diabetic retinopathy is crucial for preventing vision loss. While artificial
intelligence (AI) foundation models hold significant promise for addressing
these challenges, existing ophthalmic foundation models primarily focus on a
single modality, whereas diagnosing eye diseases requires multiple modalities.
A critical yet often overlooked aspect is harnessing the multi-view information
across various modalities for the same patient. Additionally, due to the
long-tail nature of ophthalmic diseases, standard fully supervised or
unsupervised learning approaches often struggle. Therefore, it is essential to
integrate clinical text to capture a broader spectrum of diseases. We propose
EyeCLIP, a visual-language foundation model developed using over 2.77 million
multi-modal ophthalmology images with partial text data. To fully leverage the
large multi-modal unlabeled and labeled data, we introduced a pretraining
strategy that combines self-supervised reconstructions, multi-modal image
contrastive learning, and image-text contrastive learning to learn a shared
representation of multiple modalities. Through evaluation using 14 benchmark
datasets, EyeCLIP can be transferred to a wide range of downstream tasks
involving ocular and systemic diseases, achieving state-of-the-art performance
in disease classification, visual question answering, and cross-modal
retrieval. EyeCLIP represents a significant advancement over previous methods,
especially showcasing few-shot, even zero-shot capabilities in real-world
long-tail scenarios.

摘要：早期偵測青光眼、黃斑部病變和糖尿病視網膜病變等眼疾對於預防視力喪失至關重要。儘管人工智慧 (AI) 基礎模型在應對這些挑戰方面極具前景，但現有的眼科基礎模型主要關注於單一模式，而診斷眼疾需要多種模式。一個重要但經常被忽視的方面是利用同一患者不同模式的多視圖資訊。此外，由於眼科疾病的長尾性質，標準的全監督或無監督學習方法通常難以應付。因此，整合臨床文本以涵蓋更廣泛的疾病譜系至關重要。我們提出 EyeCLIP，這是一個視覺語言基礎模型，使用超過 277 萬張具有部分文字資料的多模式眼科影像開發而成。為了充分利用大量的多模式未標記和標記資料，我們引入了一種預訓練策略，結合了自我監督重建、多模式影像對比學習和影像文字對比學習，以學習多種模式的共享表徵。透過使用 14 個基準資料集進行評估，EyeCLIP 可以轉移到涉及眼部和全身疾病的廣泛下游任務，在疾病分類、視覺問題解答和跨模式檢索中實現最先進的效能。EyeCLIP 代表了對先前方法的重大進展，特別是在現實世界長尾場景中展示了小樣本，甚至零樣本的能力。

##### **TeXBLEU: Automatic Metric for Evaluate LaTeX Format**
2409.06639v1 by Kyudan Jung, Nam-Joon Kim, Hyongon Ryu, Sieun Hyeon, Seung-jun Lee, Hyeok-jae Lee

LaTeX is highly suited to creating documents with special formatting,
particularly in the fields of science, technology, mathematics, and computer
science. Despite the increasing use of mathematical expressions in LaTeX format
with language models, there are no evaluation metrics for evaluating them. In
this study, we propose TeXBLEU, an evaluation metric tailored for mathematical
expressions in LaTeX format, based on the n-gram-based BLEU metric that is
widely used for translation tasks. The proposed TeXBLEU includes a predefined
tokenizer trained on the arXiv paper dataset and a finetuned embedding model.
It also considers the positional embedding of tokens. Simultaneously, TeXBLEU
compares tokens based on n-grams and computes the score using exponentiation of
a logarithmic sum, similar to the original BLEU. Experimental results show that
TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER,
and WER when compared to human evaluation data on the test dataset of the
MathBridge dataset, which contains 1,000 data points. The average correlation
coefficient with human evaluation was 0.71, which is an improvement of 87%
compared with BLEU, which had the highest correlation with human evaluation
data among the existing metrics. The code is available at
https://github.com/KyuDan1/TeXBLEU.

摘要：LaTeX 非常適合用於建立具有特殊格式的文件，
尤其是在科學、技術、數學和電腦科學領域。儘管 LaTeX 格式的數學表達式在語言模型中使用越來越多，
但沒有評估指標可以評估它們。在這項研究中，我們提出 TeXBLEU，這是一個針對 LaTeX 格式的數學表達式而設計的評估指標，它基於廣泛用於翻譯任務的 n-gram 為基礎的 BLEU 指標。所提出的 TeXBLEU 包含一個預先定義的標記化器，該標記化器在 arXiv 論文資料集上進行訓練，並包含一個微調的嵌入模型。
它還考慮了標記的位置嵌入。同時，TeXBLEU 根據 n-gram 比較標記，並使用對數和的指數計算分數，類似於原始 BLEU。實驗結果顯示，與 MathBridge 資料集的測試資料集上的人類評估資料相比，TeXBLEU 優於傳統評估指標，例如 BLEU、Rouge、CER 和 WER。MathBridge 資料集包含 1,000 個資料點。與人類評估的平均相關係數為 0.71，與 BLEU 相比，改進了 87%，而 BLEU 在現有指標中與人類評估資料相關性最高。程式碼可在 https://github.com/KyuDan1/TeXBLEU 取得。

##### **MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders**
2409.06635v1 by Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw

The rapid advancements in large language models (LLMs) have significantly
enhanced natural language processing capabilities, facilitating the development
of AudioLLMs that process and understand speech and audio inputs alongside
text. Existing AudioLLMs typically combine a pre-trained audio encoder with a
pre-trained LLM, which are subsequently finetuned on specific audio tasks.
However, the pre-trained audio encoder has constrained capacity to capture
features for new tasks and datasets. To address this, we propose to incorporate
mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE
supplements a base encoder with a pool of relatively light weight encoders,
selectively activated based on the audio input to enhance feature extraction
without significantly increasing model size. Our empirical results demonstrate
that MoWE effectively improves multi-task performance, broadening the
applicability of AudioLLMs to more diverse audio tasks.

摘要：大型語言模型 (LLM) 的快速進展顯著提升了自然語言處理能力，促进了 AudioLLM 的發展，AudioLLM 能處理和理解語音和音訊輸入以及文字。現有的 AudioLLM 通常將預先訓練的音訊編碼器與預先訓練的 LLM 結合，然後針對特定音訊任務進行微調。然而，預先訓練的音訊編碼器在擷取新任務和資料集特徵的能力受到限制。為了解決這個問題，我們提議將「弱」編碼器混合 (MoWE) 納入 AudioLLM 架構。MoWE 使用一群相對輕量的編碼器補充基本編碼器，根據音訊輸入有選擇地啟用，以增強特徵擷取，而不會顯著增加模型大小。我們的實證結果證明，MoWE 有效地改進了多任務效能，擴大了 AudioLLM 在更多元音訊任務中的適用性。

##### **A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio**
2409.06624v1 by Ningyuan Xi, Yetao Wu, Kun Fan, Teng Chen, Qingqing Gu, Peng Yu, Jinxian Qu, Chenxi Liu, Zhonglin Jiang, Yong Chen, Luo Ji

Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to
obtain the unfamiliar language skill or adapt into new domains. The huge
training cost of CPT often asks for cautious choice of key hyper-parameters
such as the mixture ratio of extra language or domain corpus. However, there is
no systematic study which bridge the gap between the optimal mixture ratio and
the actual model performance, and the gap between experimental scaling law and
the actual deployment in the full model size. In this paper, we perform CPT on
Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal
correlation between the Additional Language Mixture Ratio (ALMR) and the
Learning Rate (LR) on the 8B size which directly indicate the optimal
experimental set up. By thorough choice of hyper-parameter, and subsequent
fine-tuning, the model capability is improved not only on the Chinese-related
benchmark, but also some specific domains including math, coding and emotional
intelligence. We deploy the final 70B version of LLM on an real-life chat
system which obtain satisfying performance.

摘要：大型语言模型 (LLM) 经常需要持续预训练 (CPT) 以获得不熟悉的语言技能或适应新领域。CPT 的巨额训练成本通常需要谨慎选择关键超参数，例如额外语言或领域语料库的混合比例。然而，没有系统性的研究来弥合理想混合比例与实际模型性能之间的差距，以及实验缩放定律与实际部署在完整模型规模之间的差距。在本文中，我们在 Llama-3 8B 和 70B 上执行 CPT 以增强其中文能力。我们研究了 8B 大小上的附加语言混合比例 (ALMR) 和学习率 (LR) 之间的最优相关性，该相关性直接指示最优实验设置。通过彻底选择超参数和随后的微调，模型能力不仅在与中文相关的基准上得到提升，而且在包括数学、编码和情商在内的一些特定领域也得到提升。我们在一个现实生活聊天系统上部署了 LLM 的最终 70B 版本，该系统获得了令人满意的性能。

##### **Exploring Italian sentence embeddings properties through multi-tasking**
2409.06622v1 by Vivi Nastase, Giuseppe Samo, Chunyang Jiang, Paola Merlo

We investigate to what degree existing LLMs encode abstract linguistic
information in Italian in a multi-task setting. We exploit curated synthetic
data on a large scale -- several Blackbird Language Matrices (BLMs) problems in
Italian -- and use them to study how sentence representations built using
pre-trained language models encode specific syntactic and semantic information.
We use a two-level architecture to model separately a compression of the
sentence embeddings into a representation that contains relevant information
for a task, and a BLM task. We then investigate whether we can obtain
compressed sentence representations that encode syntactic and semantic
information relevant to several BLM tasks. While we expected that the sentence
structure -- in terms of sequence of phrases/chunks -- and chunk properties
could be shared across tasks, performance and error analysis show that the
clues for the different tasks are encoded in different manners in the sentence
embeddings, suggesting that abstract linguistic notions such as constituents or
thematic roles does not seem to be present in the pretrained sentence
embeddings.

摘要：我們調查現有 LLM 在多任務設定中編碼義大利文抽象語言資訊的程度。我們利用大量策展的合成資料（義大利文的幾個 Blackbird Language Matrices (BLM) 問題），並用它們來研究使用預先訓練的語言模型建構的句子表徵如何編碼特定的句法和語義資訊。我們使用二層架構來分別模擬句子嵌入壓縮成包含任務相關資訊的表徵，以及 BLM 任務。我們接著調查我們是否能取得編碼句法和語義資訊的壓縮句子表徵，這些資訊與幾個 BLM 任務相關。雖然我們預期句子結構（以詞組/區塊序列表示）和區塊屬性可以在任務間共用，但效能和錯誤分析顯示，不同任務的線索以不同方式編碼在句子嵌入中，這表示抽象語言概念（例如成分或主題角色）似乎不存在於預先訓練的句子嵌入中。

##### **Label-free Monitoring of Self-Supervised Learning Progress**
2409.06612v1 by Isaac Xu, Scott Lowe, Thomas Trappenberg

Self-supervised learning (SSL) is an effective method for exploiting
unlabelled data to learn a high-level embedding space that can be used for
various downstream tasks. However, existing methods to monitor the quality of
the encoder -- either during training for one model or to compare several
trained models -- still rely on access to annotated data. When SSL
methodologies are applied to new data domains, a sufficiently large labelled
dataset may not always be available. In this study, we propose several
evaluation metrics which can be applied on the embeddings of unlabelled data
and investigate their viability by comparing them to linear probe accuracy (a
common metric which utilizes an annotated dataset). In particular, we apply
$k$-means clustering and measure the clustering quality with the silhouette
score and clustering agreement. We also measure the entropy of the embedding
distribution. We find that while the clusters did correspond better to the
ground truth annotations as training of the network progressed, label-free
clustering metrics correlated with the linear probe accuracy only when training
with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally,
although entropy did not always have strong correlations with LP accuracy, this
appears to be due to instability arising from early training, with the metric
stabilizing and becoming more reliable at later stages of learning.
Furthermore, while entropy generally decreases as learning progresses, this
trend reverses for SimSiam. More research is required to establish the cause
for this unexpected behaviour. Lastly, we find that while clustering based
approaches are likely only viable for same-architecture comparisons, entropy
may be architecture-independent.

摘要：<paragraph>自监督学习 (SSL) 是一种有效的方法，可利用未标记的数据学习可用于各种下游任务的高级嵌入空间。然而，用于监控编码器质量的现有方法——无论是针对一个模型的训练期间还是用于比较多个训练模型——仍然依赖于对注释数据的访问。当 SSL 方法应用于新的数据域时，可能并不总是可以使用足够大的标记数据集。在这项研究中，我们提出了几种评估指标，可应用于未标记数据的嵌入，并通过将它们与线性探测准确度（一种利用注释数据集的常见指标）进行比较来调查其可行性。特别是，我们应用 k 均值聚类，并使用轮廓得分和聚类一致性来衡量聚类质量。我们还测量嵌入分布的熵。我们发现，虽然随着网络训练的进行，聚类确实更好地对应于真实注释，但无标签聚类指标仅在使用 SSL 方法 SimCLR 和 MoCo-v2 训练时与线性探测准确度相关，而与 SimSiam 无关。此外，尽管熵并不总是与 LP 准确度有很强的相关性，但这似乎是由于早期训练引起的不稳定性，随着学习的后期，该指标会稳定并变得更加可靠。此外，虽然熵通常随着学习的进行而降低，但对于 SimSiam，这种趋势会逆转。需要更多的研究来确定这种意外行为的原因。最后，我们发现，虽然基于聚类的方法可能只适用于相同架构的比较，但熵可能是与架构无关的。</paragraph>

##### **Alleviating Hallucinations in Large Language Models with Scepticism Modeling**
2409.06601v1 by Yetao Wu, Yihong Wang, Teng Chen, Chenxi Liu, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Zhonglin Jiang, Yong Chen, Luo Ji

Hallucinations is a major challenge for large language models (LLMs),
prevents adoption in diverse fields. Uncertainty estimation could be used for
alleviating the damages of hallucinations. The skeptical emotion of human could
be useful for enhancing the ability of self estimation. Inspirited by this
observation, we proposed a new approach called Skepticism Modeling (SM). This
approach is formalized by combining the information of token and logits for
self estimation. We construct the doubt emotion aware data, perform continual
pre-training, and then fine-tune the LLMs, improve their ability of self
estimation. Experimental results demonstrate this new approach effectively
enhances a model's ability to estimate their uncertainty, and validate its
generalization ability of other tasks by out-of-domain experiments.

摘要：幻覺是大型語言模型 (LLM) 的一項重大挑戰，
防止在不同領域中採用。不確定性估計可用於
減輕幻覺的損害。人類的懷疑情緒可能
有助於增強自我估計的能力。受到這個啟發
觀察，我們提出了一種稱為懷疑建模 (SM) 的新方法。這
種方法透過結合代幣和對數的信息進行自我估計而形式化。我們建構懷疑情緒感知數據，執行持續
預訓練，然後微調 LLM，提升它們自我估計的能力。實驗結果證明這種新方法有效
增強模型估計其不確定性的能力，並透過領域外實驗驗證其對其他任務的泛化能力。

##### **GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering**
2409.06595v1 by Sacha Muller, António Loison, Bilel Omrani, Gautier Viaud

Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use
Large Language Models (LLMs) alongside private and up-to-date knowledge bases.
In this work, we address the challenges of using LLM-as-a-Judge when evaluating
grounded answers generated by RAG systems. To assess the calibration and
discrimination capabilities of judge models, we identify 7 generator failure
modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a
meta-evaluation benchmark of 144 unit tests. This benchmark reveals that
existing automated RAG evaluation frameworks often overlook important failure
modes, even when using GPT-4 as a judge.
  To improve on the current design of automated RAG evaluation frameworks, we
propose a novel pipeline and find that while closed models perform well on
GroUSE, state-of-the-art open-source judges do not generalize to our proposed
criteria, despite strong correlation with GPT-4's judgement. Our findings
suggest that correlation with GPT-4 is an incomplete proxy for the practical
performance of judge models and should be supplemented with evaluations on unit
tests for precise failure mode detection.
  We further show that finetuning Llama-3 on GPT-4's reasoning traces
significantly boosts its evaluation capabilities, improving upon both
correlation with GPT-4's evaluations and calibration on reference situations.

摘要：檢索增強生成 (RAG) 已成為一種常見範例，可將大型語言模型 (LLM) 與私人且最新的知識庫一起使用。在這項工作中，我們在評估 RAG 系統生成的基礎答案時，探討了使用 LLM 作為評審時所面臨的挑戰。為了評估評審模型的校準和區分能力，我們找出 7 種生成器故障模式，並引入了 GroUSE（評估人員的基礎問答單元評分），這是一個包含 144 個單元測試的元評估基準。此基準揭示了現有的自動化 RAG 評估架構通常會忽略重要的故障模式，即使使用 GPT-4 作為評審也是如此。為了改善自動化 RAG 評估架構的當前設計，我們提出了一個新的管道，並發現封閉模型在 GroUSE 上表現良好，但最先進的開源評審並未概括到我們提出的標準，儘管與 GPT-4 的判斷有很強的相關性。我們的研究結果表明，與 GPT-4 的相關性是評審模型實際效能的不完整代理，應補充單元測試的評估，以進行精確的故障模式偵測。我們進一步表明，在 GPT-4 的推理軌跡上微調 Llama-3 可顯著提升其評估能力，同時改善與 GPT-4 評估的相關性，並校準參考情況。

##### **Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**
2409.06585v1 by Zoe Hancox, Sarah R. Kingsbury, Andrew Clegg, Philip G. Conaghan, Samuel D. Relton

Background: Hip replacement procedures improve patient lives by relieving
pain and restoring mobility. Predicting hip replacement in advance could reduce
pain by enabling timely interventions, prioritising individuals for surgery or
rehabilitation, and utilising physiotherapy to potentially delay the need for
joint replacement. This study predicts hip replacement a year in advance to
enhance quality of life and health service efficiency. Methods: Adapting
previous work using Temporal Graph Convolutional Neural Network (TG-CNN)
models, we construct temporal graphs from primary care medical event codes,
sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip
replacement risk. We match hip replacement cases to controls by age, sex, and
Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187
controls, predicts hip replacement one year in advance. We validate the model
on two unseen datasets, recalibrating for class imbalance. Additionally, we
conduct an ablation study and compare against four baseline models. Results:
Our best model predicts hip replacement risk one year in advance with an AUROC
of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),
achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after
recalibration. Conclusions: The TG-CNN model effectively predicts hip
replacement risk by identifying patterns in patient trajectories, potentially
improving understanding and management of hip-related conditions.

摘要：背景：髖關節置換手術可減輕疼痛並恢復行動能力，進而改善患者生活。預測髖關節置換手術有助於及時介入、優先安排個人進行手術或復健，並利用物理治療來延緩關節置換手術的必要性，進而減少疼痛。本研究預測一年後的髖關節置換手術，以提升生活品質和醫療服務效率。方法：採用時間圖形卷積神經網路 (TG-CNN) 模型改編先前的研究，我們從 ResearchOne EHR 40-75 歲患者的主要照護醫療事件代碼建構時間圖形，以預測髖關節置換手術風險。我們根據年齡、性別和多重剝奪指數，將髖關節置換手術病例與對照組進行配對。該模型針對 9,187 個病例和 9,187 個對照組進行訓練，預測一年後的髖關節置換手術。我們在兩個未見數據集驗證模型，並重新校準以解決類別不平衡問題。此外，我們進行消融研究，並與四個基準模型進行比較。結果：我們最佳的模型預測一年後的髖關節置換手術風險，AUROC 為 0.724 (95% CI：0.715-0.733)，AUPRC 為 0.185 (95% CI：0.160-0.209)，重新校準後校準斜率為 1.107 (95% CI：1.074-1.139)。結論：TG-CNN 模型可有效預測髖關節置換手術風險，方法是找出患者軌跡中的模式，進而潛在改善對髖關節相關疾病的了解和管理。

##### **Quantifying and Enabling the Interpretability of CLIP-like Models**
2409.06579v1 by Avinash Madasu, Yossi Gandelsman, Vasudev Lal, Phillip Howard

CLIP is one of the most popular foundational models and is heavily used for
many vision-language tasks. However, little is known about the inner workings
of CLIP. To bridge this gap we propose a study to quantify the interpretability
in CLIP like models. We conduct this study on six different CLIP models from
OpenAI and OpenCLIP which vary by size, type of pre-training data and patch
size. Our approach begins with using the TEXTSPAN algorithm and in-context
learning to break down individual attention heads into specific properties. We
then evaluate how easily these heads can be interpreted using new metrics which
measure property consistency within heads and property disentanglement across
heads. Our findings reveal that larger CLIP models are generally more
interpretable than their smaller counterparts. To further assist users in
understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a
tool designed for interpretability analysis. CLIP-InterpreT offers five types
of analyses: property-based nearest neighbor search, per-head topic
segmentation, contrastive segmentation, per-head nearest neighbors of an image,
and per-head nearest neighbors of text.

摘要：CLIP 是最流行的基础模型之一，被广泛用于许多视觉语言任务。然而，关于 CLIP 的内部工作原理知之甚少。为了弥合这一差距，我们提出了一项研究来量化 CLIP 等模型的可解释性。我们对 OpenAI 和 OpenCLIP 的六个不同的 CLIP 模型进行了这项研究，这些模型的大小、预训练数据类型和补丁大小各不相同。我们的方法首先使用 TEXTSPAN 算法和上下文学习将各个注意力头分解为特定属性。然后我们评估使用新指标解释这些头的容易程度，这些指标测量头内属性一致性和头间属性解耦。我们的研究结果表明，较大的 CLIP 模型通常比较小的模型更具可解释性。为了进一步帮助用户了解 CLIP 模型的内部工作原理，我们引入了 CLIP-InterpreT，这是一个专为可解释性分析而设计的工具。CLIP-InterpreT 提供五种类型的分析：基于属性的最近邻搜索、每个头的主题分割、对比分割、图像的每个头的最近邻和文本的每个头的最近邻。

##### **Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement**
2409.06567v1 by Vivi Nastase, Chunyang Jiang, Giuseppe Samo, Paola Merlo

In this paper, our goal is to investigate to what degree multilingual
pretrained language models capture cross-linguistically valid abstract
linguistic representations. We take the approach of developing curated
synthetic data on a large scale, with specific properties, and using them to
study sentence representations built using pretrained language models. We use a
new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to
focus on a specific grammatical structural phenomenon -- subject-verb agreement
across a variety of sentence structures -- in several languages. Finding a
solution to this task requires a system detecting complex linguistic patterns
and paradigms in text representations. Using a two-level architecture that
solves the problem in two steps -- detect syntactic objects and their
properties in individual sentences, and find patterns across an input sequence
of sentences -- we show that despite having been trained on multilingual texts
in a consistent manner, multilingual pretrained language models have
language-specific differences, and syntactic structure is not shared, even
across closely related languages.

摘要：在本文中，我们的目标是研究多语言预训练语言模型在多大程度上捕捉到跨语言有效的抽象语言表征。我们采取的方法是在大规模上开发经过整理的合成数据，具有特定属性，并使用它们来研究使用预训练语言模型构建的句子表征。我们使用一项新的多项选择任务和数据集，即黑鸟语言矩阵 (BLM)，以专注于一种特定的语法结构现象——跨多种句子结构的主谓一致——在多种语言中。找到解决此任务的方法需要一个系统来检测文本表征中的复杂语言模式和范例。使用一个两级架构，分两步解决问题——检测单个句子中的句法对象及其属性，并在输入句子序列中查找模式——我们表明，尽管以一致的方式在多语言文本上进行训练，多语言预训练语言模型具有语言特异性差异，即使在密切相关的语言中，句法结构也没有共享。

##### **Indirect Dynamic Negotiation in the Nash Demand Game**
2409.06566v1 by Tatiana V. Guy, Jitka Homolová, Aleksej Gaj

The paper addresses a problem of sequential bilateral bargaining with
incomplete information. We proposed a decision model that helps agents to
successfully bargain by performing indirect negotiation and learning the
opponent's model. Methodologically the paper casts heuristically-motivated
bargaining of a self-interested independent player into a framework of Bayesian
learning and Markov decision processes. The special form of the reward
implicitly motivates the players to negotiate indirectly, via closed-loop
interaction. We illustrate the approach by applying our model to the Nash
demand game, which is an abstract model of bargaining. The results indicate
that the established negotiation: i) leads to coordinating players' actions;
ii) results in maximising success rate of the game and iii) brings more
individual profit to the players.

摘要：本文讨论了在信息不完全的情况下进行顺序双边谈判的问题。我们提出了一种决策模型，通过执行间接谈判和学习对手的模型来帮助代理人成功地进行谈判。从方法论上讲，该论文将自私的独立参与者的启发式激励讨价还价纳入贝叶斯学习和马尔可夫决策过程的框架中。奖励的特殊形式隐含地激励参与者通过闭环交互间接谈判。我们通过将我们的模型应用于纳什需求博弈（一种讨价还价的抽象模型）来说明这种方法。结果表明，既定的谈判：i）导致协调参与者的行动；ii）导致最大化博弈的成功率，并且 iii）为参与者带来更多个人利益。

##### **From LIMA to DeepLIMA: following a new path of interoperability**
2409.06550v1 by Victor Bocharov, Romaric Besançon, Gaël de Chalendar, Olivier Ferret, Nasredine Semmar

In this article, we describe the architecture of the LIMA (Libre Multilingual
Analyzer) framework and its recent evolution with the addition of new text
analysis modules based on deep neural networks. We extended the functionality
of LIMA in terms of the number of supported languages while preserving existing
configurable architecture and the availability of previously developed
rule-based and statistical analysis components. Models were trained for more
than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora,
and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number
of supported languages and to generate models that could be integrated into
other platforms. This integration of ubiquitous Deep Learning Natural Language
Processing models and the use of standard annotated collections using Universal
Dependencies can be viewed as a new path of interoperability, through the
normalization of models and data, that are complementary to a more standard
technical interoperability, implemented in LIMA through services available in
Docker containers on Docker Hub.

摘要：在本文中，我們描述了 LIMA（Libre Multilingual Analyzer）架構及其最近加入基於深度神經網路的新文字分析模組的演進。我們在保留現有可組態架構和先前開發的基於規則和統計分析元件可用性的同時，擴充了 LIMA 在支援語言數量方面的功能。針對 Universal Dependencies 2.5 語料庫、WikiNer 語料庫和 CoNLL-03 資料集為超過 60 種語言訓練模型。Universal Dependencies 讓我們得以增加支援語言的數量，並產生可整合到其他平台的模型。普遍的深度學習自然語言處理模型的整合，以及使用 Universal Dependencies 的標準註解集合，可視為一種透過模型和資料的標準化而產生的新的互操作性途徑，這對於 LIMA 中透過 Docker Hub 上的 Docker 容器中可用的服務所實作的更標準化的技術互操作性而言，具有互補性。

##### **Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings**
2409.06540v1 by Jan Elfes

Given the profound impact of narratives across various societal levels, from
personal identities to international politics, it is crucial to understand
their distribution and development over time. This is particularly important in
online spaces. On the Web, narratives can spread rapidly and intensify societal
divides and conflicts. While many qualitative approaches exist, quantifying
narratives remains a significant challenge. Computational narrative analysis
lacks frameworks that are both comprehensive and generalizable. To address this
gap, we introduce a numerical narrative representation grounded in
structuralist linguistic theory. Chiefly, Greimas' Actantial Model represents a
narrative through a constellation of six functional character roles. These
so-called actants are genre-agnostic, making the model highly generalizable. We
extract the actants using an open-source LLM and integrate them into a
Narrative-Structured Text Embedding that captures both the semantics and
narrative structure of a text. We demonstrate the analytical insights of the
method on the example of 5000 full-text news articles from Al Jazeera and The
Washington Post on the Israel-Palestine conflict. Our method successfully
distinguishes articles that cover the same topics but differ in narrative
structure.

摘要：由於敘事在各個社會層面，從個人身分到國際政治，都有深遠的影響，因此了解敘事的分布和發展過程至關重要。這在網路空間中尤其重要。在網路上，敘事可以迅速傳播並加劇社會分歧和衝突。儘管有許多定性方法，但量化敘事仍然是一項重大的挑戰。計算敘事分析缺乏既全面又可概括的架構。為了解決這個差距，我們引入了一個基於結構主義語言理論的數值敘事表徵。最重要的是，格雷馬斯的行動者模型通過一組六個功能角色來表示敘事。這些所謂的行動者與類型無關，使得該模型具有高度的概括性。我們使用開源 LLM 提取行動者，並將它們整合到一個敘事結構化文字嵌入中，該嵌入同時捕捉文本的語義和敘事結構。我們在半島電視台和華盛頓郵報上關於巴以衝突的 5000 篇全文新聞文章的範例中展示了該方法的分析見解。我們的模型成功區分了涵蓋相同主題但敘事結構不同的文章。

##### **Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games**
2409.06518v1 by Juhwan Choi, YoungBin Kim

Large language models (LLMs) have become a dominant approach in natural
language processing, yet their internal knowledge structures remain largely
unexplored. In this paper, we analyze the internal knowledge structures of LLMs
using historical medal tallies from the Olympic Games. We task the models with
providing the medal counts for each team and identifying which teams achieved
specific rankings. Our results reveal that while state-of-the-art LLMs perform
remarkably well in reporting medal counts for individual teams, they struggle
significantly with questions about specific rankings. This suggests that the
internal knowledge structures of LLMs are fundamentally different from those of
humans, who can easily infer rankings from known medal counts. To support
further research, we publicly release our code, dataset, and model outputs.

摘要：大型語言模型 (LLM) 已成為自然語言處理領域的主流方法，但它們的內部知識結構在很大程度上仍未被探索。在本文中，我們使用奧運會的歷史獎牌數分析了 LLM 的內部知識結構。我們要求模型提供每個團隊的獎牌數，並找出哪些團隊達到了特定排名。我們的結果表明，雖然最先進的 LLM 在報告個別團隊的獎牌數方面表現出色，但它們在關於特定排名的問題上卻遇到了很大的困難。這表明 LLM 的內部知識結構與人類的內部知識結構有根本的不同，人類可以輕鬆地從已知的獎牌數中推斷出排名。為了支持進一步的研究，我們公開發布了我們的代碼、數據集和模型輸出。

##### **Sine, Transient, Noise Neural Modeling of Piano Notes**
2409.06513v1 by Riccardo Simionato, Stefano Fasciani

This paper introduces a novel method for emulating piano sounds. We propose
to exploit the sine, transient, and noise decomposition to design a
differentiable spectral modeling synthesizer replicating piano notes. Three
sub-modules learn these components from piano recordings and generate the
corresponding harmonic, transient, and noise signals. Splitting the emulation
into three independently trainable models reduces the modeling tasks'
complexity. The quasi-harmonic content is produced using a differentiable
sinusoidal model guided by physics-derived formulas, whose parameters are
automatically estimated from audio recordings. The noise sub-module uses a
learnable time-varying filter, and the transients are generated using a deep
convolutional network. From singular notes, we emulate the coupling between
different keys in trichords with a convolutional-based network. Results show
the model matches the partial distribution of the target while predicting the
energy in the higher part of the spectrum presents more challenges. The energy
distribution in the spectra of the transient and noise components is accurate
overall. While the model is more computationally and memory efficient,
perceptual tests reveal limitations in accurately modeling the attack phase of
notes. Despite this, it generally achieves perceptual accuracy in emulating
single notes and trichords.

摘要：本文介紹一種模擬鋼琴音效的新方法。我們建議利用正弦波、暫態和雜訊分解來設計一個可微分頻譜建模合成器，以複製鋼琴音符。三個子模組從鋼琴錄音中學習這些組成部分，並產生相應的諧波、暫態和雜訊訊號。將模擬拆分為三個獨立可訓練的模型，降低了建模任務的複雜性。準諧波內容是使用由物理公式引導的可微分正弦模型產生的，其參數會從音訊錄音中自動估計。雜訊子模組使用可學習的時間變異濾波器，而暫態是使用深度卷積網路產生的。從單一音符中，我們模擬了三和弦中不同鍵之間的耦合，使用基於卷積的網路。結果顯示，該模型匹配目標的部分分佈，同時預測光譜高部分的能量提出了更多挑戰。暫態和雜訊組成部分光譜中的能量分佈整體上是準確的。雖然該模型在運算和記憶體方面更有效率，但感知測試顯示在準確建模音符的攻擊階段方面有其限制。儘管如此，它通常在模擬單音符和三和弦時達到感知準確度。

##### **Aligning Machine and Human Visual Representations across Abstraction Levels**
2409.06509v1 by Lukas Muttenthaler, Klaus Greff, Frieda Born, Bernhard Spitzer, Simon Kornblith, Michael C. Mozer, Klaus-Robert Müller, Thomas Unterthiner, Andrew K. Lampinen

Deep neural networks have achieved success across a wide range of
applications, including as models of human behavior in vision tasks. However,
neural network training and human learning differ in fundamental ways, and
neural networks often fail to generalize as robustly as humans do, raising
questions regarding the similarity of their underlying representations. What is
missing for modern learning systems to exhibit more human-like behavior? We
highlight a key misalignment between vision models and humans: whereas human
conceptual knowledge is hierarchically organized from fine- to coarse-scale
distinctions, model representations do not accurately capture all these levels
of abstraction. To address this misalignment, we first train a teacher model to
imitate human judgments, then transfer human-like structure from its
representations into pretrained state-of-the-art vision foundation models.
These human-aligned models more accurately approximate human behavior and
uncertainty across a wide range of similarity tasks, including a new dataset of
human judgments spanning multiple levels of semantic abstractions. They also
perform better on a diverse set of machine learning tasks, increasing
generalization and out-of-distribution robustness. Thus, infusing neural
networks with additional human knowledge yields a best-of-both-worlds
representation that is both more consistent with human cognition and more
practically useful, thus paving the way toward more robust, interpretable, and
human-like artificial intelligence systems.

摘要：深度神经网络在广泛的應用中取得成功，包括作為視覺任務中人類行為的模型。然而，神經網路訓練和人類學習在基本方式上有所不同，而且神經網路通常無法像人類那樣穩健地概括，這引發了關於它們底層表徵相似性的問題。現代學習系統缺少什麼才能表現出更像人類的行為？我們強調了視覺模型和人類之間的一個關鍵錯位：人類概念知識從精細到粗略的區別分層組織，而模型表徵並未準確捕捉所有這些抽象層級。為了解決這種錯位，我們首先訓練一個教師模型來模仿人類判斷，然後將其表徵中類人的結構轉移到預先訓練的最新視覺基礎模型中。這些與人類一致的模型更準確地逼近人類行為和不確定性，涵蓋廣泛的相似性任務，包括一個跨越多個語義抽象層級的人類判斷新資料集。它們在各種機器學習任務上的表現也更好，提高了泛化性和分佈外穩健性。因此，為神經網路注入額外的人類知識產生了一個兩全其美的表徵，它既更符合人類認知，又更實用，從而為更穩健、可解釋和類人的人工智慧系統鋪平了道路。

##### **Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout**
2409.06477v1 by Atharva Gundawar, Yuchao Li, Dimitri Bertsekas

In this paper we apply model predictive control (MPC), rollout, and
reinforcement learning (RL) methodologies to computer chess. We introduce a new
architecture for move selection, within which available chess engines are used
as components. One engine is used to provide position evaluations in an
approximation in value space MPC/RL scheme, while a second engine is used as
nominal opponent, to emulate or approximate the moves of the true opponent
player.
  We show that our architecture improves substantially the performance of the
position evaluation engine. In other words our architecture provides an
additional layer of intelligence, on top of the intelligence of the engines on
which it is based. This is true for any engine, regardless of its strength: top
engines such as Stockfish and Komodo Dragon (of varying strengths), as well as
weaker engines.
  Structurally, our basic architecture selects moves by a one-move lookahead
search, with an intermediate move generated by a nominal opponent engine, and
followed by a position evaluation by another chess engine. Simpler schemes that
forego the use of the nominal opponent, also perform better than the position
evaluator, but not quite by as much. More complex schemes, involving multistep
lookahead, may also be used and generally tend to perform better as the length
of the lookahead increases.
  Theoretically, our methodology relies on generic cost improvement properties
and the superlinear convergence framework of Newton's method, which
fundamentally underlies approximation in value space, and related MPC/RL and
rollout/policy iteration schemes. A critical requirement of this framework is
that the first lookahead step should be executed exactly. This fact has guided
our architectural choices, and is apparently an important factor in improving
the performance of even the best available chess engines.

摘要：<paragraph>在本文中，我们将模型预测控制 (MPC)、展开和强化学习 (RL) 方法应用于计算机国际象棋。我们引入了一种新的走法选择架构，其中可用的国际象棋引擎被用作组件。一个引擎用于在价值空间 MPC/RL 方案中提供位置评估，而另一个引擎则用作名义上的对手，以模拟或近似真实对手玩家的走法。
我们表明我们的架构大幅提升了位置评估引擎的性能。换句话说，我们的架构提供了一层额外的智能，建立在它所基于的引擎的智能之上。这适用于任何引擎，无论其强度如何：顶级引擎，如 Stockfish 和 Komodo Dragon（强度各异），以及较弱的引擎。
在结构上，我们的基本架构通过一步预测搜索选择走法，其中一步是由名义上的对手引擎生成的，然后由另一个国际象棋引擎进行位置评估。舍弃使用名义对手的更简单的方案也比位置评估器表现得更好，但没有好那么多。涉及多步预测的更复杂的方案也可以使用，并且通常随着预测长度的增加而表现得更好。
从理论上讲，我们的方法依赖于通用成本改进属性和牛顿法的超线性收敛框架，该框架从根本上支持价值空间中的近似，以及相关的 MPC/RL 和展开/策略迭代方案。这个框架的一个关键要求是第一步预测应该准确执行。这一事实指导了我们的架构选择，而且显然是提高甚至最好的可用国际象棋引擎性能的一个重要因素。</paragraph>

##### **An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition**
2409.06468v1 by Yi-Cheng Wang, Li-Ting Pai, Bi-Cheng Yan, Hsin-Wei Wang, Chi-Han Lin, Berlin Chen

End-to-end (E2E) automatic speech recognition (ASR) models have become
standard practice for various commercial applications. However, in real-world
scenarios, the long-tailed nature of word distribution often leads E2E ASR
models to perform well on common words but fall short in recognizing uncommon
ones. Recently, the notion of a contextual adapter (CA) was proposed to infuse
external knowledge represented by a context word list into E2E ASR models.
Although CA can improve recognition performance on rare words, two crucial data
imbalance problems remain. First, when using low-frequency words as context
words during training, since these words rarely occur in the utterance, CA
becomes prone to overfit on attending to the <no-context> token due to
higher-frequency words not being present in the context list. Second, the
long-tailed distribution within the context list itself still causes the model
to perform poorly on low-frequency context words. In light of this, we explore
in-depth the impact of altering the context list to have words with different
frequency distributions on model performance, and meanwhile extend CA with a
simple yet effective context-balanced learning objective. A series of
experiments conducted on the AISHELL-1 benchmark dataset suggests that using
all vocabulary words from the training corpus as the context list and pairing
them with our balanced objective yields the best performance, demonstrating a
significant reduction in character error rate (CER) by up to 1.21% and a more
pronounced 9.44% reduction in the error rate of zero-shot words.

摘要：端對端 (E2E) 自動語音辨識 (ASR) 模型已成為各種商業應用中的標準實務。然而，在真實世界的場景中，詞彙分佈的長尾特性常常導致 E2E ASR 模型在常見詞彙上表現良好，但在辨識不常見詞彙時卻表現不佳。最近，有人提出情境式適配器 (CA) 的概念，將由情境詞彙清單所代表的外部知識注入 E2E ASR 模型中。儘管 CA 能夠提升罕見詞彙的辨識效能，但仍存在兩個關鍵的資料不平衡問題。首先，在訓練期間使用低頻率詞彙作為情境詞彙時，由於這些詞彙很少出現在語句中，因此 CA 容易過度擬合，專注於 <no-context> 權杖，因為較高頻率的詞彙並未出現在情境清單中。其次，情境清單本身內的長尾分佈仍會導致模型在低頻率情境詞彙上的表現不佳。有鑑於此，我們深入探討改變情境清單以納入具有不同頻率分佈的詞彙對模型效能的影響，同時使用一個簡單但有效的平衡情境學習目標來延伸 CA。在 AISHELL-1 基準資料集上進行的一系列實驗顯示，使用訓練語料庫中的所有詞彙作為情境清單，並將其與我們的平衡目標配對，可產生最佳效能，證明字元錯誤率 (CER) 大幅降低了 1.21%，而零次學習詞彙的錯誤率則大幅降低了 9.44%。

##### **Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles**
2409.06450v1 by Qiujing Lu, Xuanhan Wang, Yiwei Jiang, Guangming Zhao, Mingyue Ma, Shuo Feng

The generation of corner cases has become increasingly crucial for
efficiently testing autonomous vehicles prior to road deployment. However,
existing methods struggle to accommodate diverse testing requirements and often
lack the ability to generalize to unseen situations, thereby reducing the
convenience and usability of the generated scenarios. A method that facilitates
easily controllable scenario generation for efficient autonomous vehicles (AV)
testing with realistic and challenging situations is greatly needed. To address
this, we proposed OmniTester: a multimodal Large Language Model (LLM) based
framework that fully leverages the extensive world knowledge and reasoning
capabilities of LLMs. OmniTester is designed to generate realistic and diverse
scenarios within a simulation environment, offering a robust solution for
testing and evaluating AVs. In addition to prompt engineering, we employ tools
from Simulation of Urban Mobility to simplify the complexity of codes generated
by LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a
self-improvement mechanism to enhance the LLM's understanding of scenarios,
thereby increasing its ability to produce more realistic scenes. In the
experiments, we demonstrated the controllability and realism of our approaches
in generating three types of challenging and complex scenarios. Additionally,
we showcased its effectiveness in reconstructing new scenarios described in
crash report, driven by the generalization capability of LLMs.

摘要：自動駕駛車輛在路測前，產生邊緣案例已變得越來越重要，以便能有效地進行測試。然而，現有方法難以適應多樣化的測試需求，而且常常缺乏對未見情況進行概化的能力，因而降低了產生情境的便利性和可用性。我們非常需要一種方法，以便於控制情境產生，以進行有效率的自動駕駛車輛 (AV) 測試，並包含逼真且具挑戰性的情況。為了解決這個問題，我們提出了 OmniTester：一個多模態大型語言模型 (LLM) 基底架構，它充分利用了 LLM 廣泛的世界知識和推理能力。OmniTester 旨在在模擬環境中產生逼真且多樣化的情境，為測試和評估 AV 提供了一個強大的解決方案。除了提示工程外，我們還採用了都市機動模擬工具，以簡化 LLM 所產生程式碼的複雜性。此外，我們整合了檢索強化產生和自我改善機制，以增強 LLM 對情境的理解，從而提高其產生更逼真場景的能力。在實驗中，我們展示了我們的途徑在產生三種類型的具挑戰性和複雜情境中的可控性和真實性。此外，我們展示了它在重建碰撞報告中描述的新情境方面的有效性，這得益於 LLM 的概化能力。

##### **HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data**
2409.06446v1 by Hossein Hajipour, Lea Schönherr, Thorsten Holz, Mario Fritz

Large language models (LLMs) have shown great potential for automatic code
generation and form the basis for various tools such as GitHub Copilot.
However, recent studies highlight that many LLM-generated code contains serious
security vulnerabilities. While previous work tries to address this by training
models that generate secure code, these attempts remain constrained by limited
access to training data and labor-intensive data preparation.
  In this paper, we introduce HexaCoder, a novel approach to enhance the
ability of LLMs to generate secure codes by automatically synthesizing secure
codes, which reduces the effort of finding suitable training data. HexaCoder
comprises two key components: an oracle-guided data synthesis pipeline and a
two-step process for secure code generation. The data synthesis pipeline
generates pairs of vulnerable and fixed codes for specific Common Weakness
Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing
vulnerable code. A security oracle identifies vulnerabilities, and a
state-of-the-art LLM repairs them by extending and/or editing the codes,
creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA)
method. Each example of our fine-tuning dataset includes the necessary
security-related libraries and code that form the basis of our novel two-step
generation approach. This allows the model to integrate security-relevant
libraries before generating the main code, significantly reducing the number of
generated vulnerable codes by up to 85% compared to the baseline methods. We
perform extensive evaluations on three different benchmarks for four LLMs,
demonstrating that HexaCoder not only improves the security of the generated
code but also maintains a high level of functional correctness.

摘要：大型語言模型 (LLM) 在自動程式碼生成方面展現了巨大的潛力，並成為各種工具的基礎，例如 GitHub Copilot。然而，最近的研究強調，許多 LLM 生成的程式碼包含嚴重的安全漏洞。雖然先前的研究嘗試透過訓練產生安全程式碼的模型來解決此問題，但這些嘗試仍受到訓練資料取得受限和資料準備工作繁重的限制。在本文中，我們介紹 HexaCoder，這是一種透過自動合成安全程式碼來增強 LLM 產生安全程式碼能力的新方法，它減少了尋找合適訓練資料的精力。HexaCoder 包含兩個關鍵組成部分：一個由 Oracle 引導的資料合成管線，以及一個用於產生安全程式碼的兩步驟程序。資料合成管線透過利用最先進的 LLM 來修復有漏洞的程式碼，為特定常見弱點列舉 (CWE) 類型產生有漏洞和已修復程式碼的配對。安全 Oracle 會識別漏洞，而最先進的 LLM 會透過延伸和/或編輯程式碼來修復這些漏洞，並建立資料配對，以使用低秩適應 (LoRA) 方法進行微調。我們的微調資料集的每個範例都包含必要的安全相關函式庫和程式碼，這些程式碼構成我們新穎兩步驟生成方法的基礎。這允許模型在產生主程式碼之前整合與安全相關的函式庫，與基線方法相比，可顯著減少多達 85% 的有漏洞程式碼數量。我們針對四個 LLM 的三個不同基準進行廣泛評估，證明 HexaCoder 不僅提高了所產生程式碼的安全性，還維持了高水準的功能正確性。

##### **Learning Generative Interactive Environments By Trained Agent Exploration**
2409.06445v1 by Naser Kazemi, Nedko Savov, Danda Paudel, Luc Van Gool

World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .

摘要：世界模型在解釋和模擬複雜環境的規則和動作中愈發重要。Genie 是一個最近的模型，它擅長從視覺多樣的環境中學習，但依賴於昂貴的人工收集的數據。我們觀察到，他們使用隨機代理的替代方法對於探索環境來說過於受限。我們建議通過採用基於強化學習的代理來改進模型以進行數據生成。這種方法產生多樣化的數據集，增強了模型在環境中適應和執行各種場景和現實動作的能力。在本文中，我們首先發布模型 GenieRedux——一個基於 Genie 的實現。此外，我們還介紹了 GenieRedux-G，這是一個變體，它使用代理現成的動作來分解驗證期間的動作預測不確定性。我們的評估，包括複製 Coinrun 案例研究，表明 GenieRedux-G 使用訓練有素的代理探索，實現了卓越的視覺保真度和可控性。所提出的方法可重現、可擴展且適用於新型環境。我們的代碼庫可在 https://github.com/insait-institute/GenieRedux 獲得。

##### **GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning**
2409.06427v1 by Kento Kawaharazuka, Kei Okada, Masayuki Inaba

Humans can autonomously learn the relationship between sensation and motion
in their own bodies, estimate and control their own body states, and move while
continuously adapting to the current environment. On the other hand, current
robots control their bodies by learning the network structure described by
humans from their experiences, making certain assumptions on the relationship
between sensors and actuators. In addition, the network model does not adapt to
changes in the robot's body, the tools that are grasped, or the environment,
and there is no unified theory, not only for control but also for state
estimation, anomaly detection, simulation, and so on. In this study, we propose
a Generalized Multisensory Correlational Model (GeMuCo), in which the robot
itself acquires a body schema describing the correlation between sensors and
actuators from its own experience, including model structures such as network
input/output. The robot adapts to the current environment by updating this body
schema model online, estimates and controls its body state, and even performs
anomaly detection and simulation. We demonstrate the effectiveness of this
method by applying it to tool-use considering changes in grasping state for an
axis-driven robot, to joint-muscle mapping learning for a musculoskeletal
robot, and to full-body tool manipulation for a low-rigidity plastic-made
humanoid.

摘要：人類可以自主學習身體中感覺和動作之間的關係，估計和控制自己的身體狀態，並在持續適應當前環境的同時移動。另一方面，當前的機器人通過從經驗中學習人類描述的網路結構來控制其身體，對感測器和致動器之間的關係做出某些假設。此外，網路模型不會適應機器人身體、所抓取的工具或環境的變化，而且不僅對於控制，而且對於狀態估計、異常偵測、模擬等，都沒有統一的理論。在本研究中，我們提出了一個廣義的多感官相關模型 (GeMuCo)，其中機器人本身從自己的經驗中獲取描述感測器和致動器之間相關性的身體模式，包括網路輸入/輸出等模型結構。機器人通過在線上更新這個身體模式模型來適應當前環境，估計和控制其身體狀態，甚至執行異常偵測和模擬。我們通過將此方法應用於考慮軸驅動機器人的抓握狀態變化、用於肌肉骨骼機器人的關節肌肉對應學習以及用於低剛性塑膠製成的類人機器人的全身工具操作，來證明此方法的有效性。

##### **Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes**
2409.06416v1 by Ludvig Lemner, Linnea Wahlgren, Gregory Gay, Nasser Mohammadiha, Jingxiong Liu, Joakim Wennerberg

Much of the cost and effort required during the software testing process is
invested in performing test maintenance - the addition, removal, or
modification of test cases to keep the test suite in sync with the
system-under-test or to otherwise improve its quality. Tool support could
reduce the cost - and improve the quality - of test maintenance by automating
aspects of the process or by providing guidance and support to developers.
  In this study, we explore the capabilities and applications of large language
models (LLMs) - complex machine learning models adapted to textual analysis -
to support test maintenance. We conducted a case study at Ericsson AB where we
explored the triggers that indicate the need for test maintenance, the actions
that LLMs can take, and the considerations that must be made when deploying
LLMs in an industrial setting. We also proposed and demonstrated
implementations of two multi-agent architectures that can predict which test
cases require maintenance following a change to the source code. Collectively,
these contributions advance our theoretical and practical understanding of how
LLMs can be deployed to benefit industrial test maintenance processes.

摘要：軟體測試過程中所需的大量成本和精力，都投入在執行測試維護上，包括新增、移除或修改測試案例，以使測試套件與受測系統同步，或以其他方式改善其品質。工具支援可透過自動化處理程序，或提供開發人員指導和支援，來降低成本並改善測試維護的品質。在本研究中，我們探討大型語言模型 (LLM) 的功能和應用，LLM 是複雜的機器學習模型，適用於文本分析，可支援測試維護。我們在愛立信公司進行了一項個案研究，探討了表示需要測試維護的觸發因素、LLM 可執行的動作，以及在工業環境中部署 LLM 時必須考量的因素。我們也提出並展示了兩個多重代理架構的實作，這些架構可以預測在原始碼變更後哪些測試案例需要維護。這些貢獻共同提升了我們對如何部署 LLM 以利於工業測試維護程序的理論和實務理解。

##### **Length Desensitization in Directed Preference Optimization**
2409.06411v1 by Wei Liu, Yang Bai, Chengcheng Han, Rongxiang Weng, Jun Xu, Xuezhi Cao, Jingang Wang, Xunliang Cai

Direct Preference Optimization (DPO) is widely utilized in the Reinforcement
Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs)
with human preferences, thereby enhancing both their harmlessness and efficacy.
However, it has been observed that DPO tends to over-optimize for verbosity,
which can detrimentally affect both performance and user experience. In this
paper, we conduct an in-depth theoretical analysis of DPO's optimization
objective and reveal a strong correlation between its implicit reward and data
length. This correlation misguides the optimization direction, resulting in
length sensitivity during the DPO training and leading to verbosity. To address
this issue, we propose a length-desensitization improvement method for DPO,
termed LD-DPO. The proposed method aims to desensitize DPO to data length by
decoupling explicit length preference, which is relatively insignificant, from
the other implicit preferences, thereby enabling more effective learning of the
intrinsic preferences. We utilized two settings (Base and Instruct) of
Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various
benchmarks including MT-Bench and AlpacaEval 2. The experimental results
indicate that LD-DPO consistently outperforms DPO and other baseline methods,
achieving more concise responses with a 10-40\% reduction in length compared to
DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can
indeed achieve length desensitization and align the model more closely with
human-real preferences.

摘要：直接偏好最佳化（DPO）廣泛用於人類回饋強化學習（RLHF）階段，以將大型語言模型（LLM）與人類偏好結合，從而增強其無害性和效能。然而，觀察到 DPO 傾向於過度最佳化冗長性，這可能會對效能和使用者體驗造成負面影響。在本文中，我們對 DPO 的最佳化目標進行深入的理論分析，並揭示其隱含獎勵與資料長度之間的強烈關聯。這種關聯會誤導最佳化方向，導致 DPO 訓練期間長度敏感，並導致冗長。為了解決這個問題，我們提出了一種長度去敏化改善方法，稱為 LD-DPO。所提出的方法旨在透過將顯式的長度偏好（相對不重要）與其他隱含偏好分開，讓 DPO 對資料長度去敏化，從而能更有效地學習內在偏好。我們利用 Llama2-13B、Llama3-8B 和 Qwen2-7B 的兩個設定（基礎和指令）在各種基準上進行實驗驗證，包括 MT-Bench 和 AlpacaEval 2。實驗結果表明，LD-DPO 持續優於 DPO 和其他基線方法，與 DPO 相比，長度減少了 10-40%，產生了更簡潔的回應。我們進行了深入的實驗分析，以證明 LD-DPO 確實可以實現長度去敏化，並使模型更接近人類真實偏好。

##### **Coarse-Grained Sense Inventories Based on Semantic Matching between English Dictionaries**
2409.06386v1 by Masato Kikuchi, Masatsugu Ono, Toshioki Soga, Tetsu Tanabe, Tadachika Ozono

WordNet is one of the largest handcrafted concept dictionaries visualizing
word connections through semantic relationships. It is widely used as a word
sense inventory in natural language processing tasks. However, WordNet's
fine-grained senses have been criticized for limiting its usability. In this
paper, we semantically match sense definitions from Cambridge dictionaries and
WordNet and develop new coarse-grained sense inventories. We verify the
effectiveness of our inventories by comparing their semantic coherences with
that of Coarse Sense Inventory. The advantages of the proposed inventories
include their low dependency on large-scale resources, better aggregation of
closely related senses, CEFR-level assignments, and ease of expansion and
improvement.

摘要：WordNet 是最大的手工概念字典之一，它通过语义关系可视化单词连接。它被广泛用作自然语言处理任务中的词义清单。然而，WordNet 的细粒度词义因限制其可用性而受到批评。在本文中，我们对剑桥词典和 WordNet 中的词义定义进行了语义匹配，并开发了新的粗粒度词义清单。我们通过比较它们与粗粒度词义清单的语义连贯性来验证我们清单的有效性。所提出清单的优点包括它们对大规模资源的低依赖性、对密切相关的词义的更好聚合、CEFR 级别的分配以及易于扩展和改进。

##### **Enhancing Sequential Recommendations through Multi-Perspective Reflections and Iteration**
2409.06377v1 by Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Xiao Zhang, Ming He, Jianping Fan, Jun Xu

Sequence recommendation (SeqRec) aims to predict the next item a user will
interact with by understanding user intentions and leveraging collaborative
filtering information. Large language models (LLMs) have shown great promise in
recommendation tasks through prompt-based, fixed reflection libraries, and
fine-tuning techniques. However, these methods face challenges, including lack
of supervision, inability to optimize reflection sources, inflexibility to
diverse user needs, and high computational costs. Despite promising results,
current studies primarily focus on reflections of users' explicit preferences
(e.g., item titles) while neglecting implicit preferences (e.g., brands) and
collaborative filtering information. This oversight hinders the capture of
preference shifts and dynamic user behaviors. Additionally, existing approaches
lack mechanisms for reflection evaluation and iteration, often leading to
suboptimal recommendations. To address these issues, we propose the Mixture of
REflectors (MoRE) framework, designed to model and learn dynamic user
preferences in SeqRec. Specifically, MoRE introduces three reflectors for
generating LLM-based reflections on explicit preferences, implicit preferences,
and collaborative signals. Each reflector incorporates a self-improving
strategy, termed refining-and-iteration, to evaluate and iteratively update
reflections. Furthermore, a meta-reflector employs a contextual bandit
algorithm to select the most suitable expert and corresponding reflections for
each user's recommendation, effectively capturing dynamic preferences.
Extensive experiments on three real-world datasets demonstrate that MoRE
consistently outperforms state-of-the-art methods, requiring less training time
and GPU memory compared to other LLM-based approaches in SeqRec.

摘要：序列推薦（SeqRec）旨在透過了解使用者意圖，並利用協同過濾資訊，預測使用者將互動的下一項內容。大型語言模型（LLM）透過基於提示的固定反射函式庫和微調技術，在推薦任務中展現極佳的前景。然而，這些方法面臨挑戰，包括缺乏監督、無法最佳化反射來源、對多元使用者需求缺乏彈性，以及高運算成本。儘管有令人振奮的成果，目前的研究主要關注使用者明確偏好的反射（例如項目標題），而忽略了隱含偏好（例如品牌）和協同過濾資訊。這種疏忽阻礙了偏好轉變和動態使用者行為的捕捉。此外，現有方法缺乏反射評估和迭代機制，通常導致次佳推薦。為了解決這些問題，我們提出混合反射器（MoRE）架構，旨在建模和學習 SeqRec 中的動態使用者偏好。具體來說，MoRE 導入三個反射器，用於針對明確偏好、隱含偏好和協同訊號產生基於 LLM 的反射。每個反射器都包含一個自我提升策略，稱為精煉和迭代，用於評估和反覆更新反射。此外，元反射器採用情境式多臂老虎機演算法，為每個使用者的推薦選擇最合適的專家和對應反射，有效捕捉動態偏好。在三個真實世界資料集上的廣泛實驗證明，與 SeqRec 中其他基於 LLM 的方法相比，MoRE 持續優於最先進的方法，且所需的訓練時間和 GPU 記憶體較少。

##### **SpeechTaxi: On Multilingual Semantic Speech Classification**
2409.06372v1 by Lennart Keller, Goran Glavaš

Recent advancements in multilingual speech encoding as well as transcription
raise the question of the most effective approach to semantic speech
classification. Concretely, can (1) end-to-end (E2E) classifiers obtained by
fine-tuning state-of-the-art multilingual speech encoders (MSEs) match or
surpass the performance of (2) cascading (CA), where speech is first
transcribed into text and classification is delegated to a text-based
classifier. To answer this, we first construct SpeechTaxi, an 80-hour
multilingual dataset for semantic speech classification of Bible verses,
covering 28 diverse languages. We then leverage SpeechTaxi to conduct a wide
range of experiments comparing E2E and CA in monolingual semantic speech
classification as well as in cross-lingual transfer. We find that E2E based on
MSEs outperforms CA in monolingual setups, i.e., when trained on in-language
data. However, MSEs seem to have poor cross-lingual transfer abilities, with
E2E substantially lagging CA both in (1) zero-shot transfer to languages unseen
in training and (2) multilingual training, i.e., joint training on multiple
languages. Finally, we devise a novel CA approach based on transcription to
Romanized text as a language-agnostic intermediate representation and show that
it represents a robust solution for languages without native ASR support. Our
SpeechTaxi dataset is publicly available at: https://huggingface.co/
datasets/LennartKeller/SpeechTaxi/.

摘要：<paragraph>多語言語音編碼和轉錄的最新進展引發了關於語義語音分類最有效方法的問題。具體來說，通過微調最先進的多語言語音編碼器 (MSE) 獲得的 (1) 端到端 (E2E) 分類器是否可以匹配或超越 (2) 串聯 (CA) 的性能，其中語音首先轉錄成文本，分類委派給基於文本的分類器。為了解答這個問題，我們首先構建了 SpeechTaxi，一個用於聖經詩句語義語音分類的 80 小時的語音資料集，涵蓋 28 種不同的語言。然後，我們利用 SpeechTaxi 進行了一系列廣泛的實驗，比較了單語言語義語音分類以及跨語言轉移中的 E2E 和 CA。我們發現基於 MSE 的 E2E 在單語言設置中優於 CA，即在語言內數據上進行訓練時。然而，MSE 似乎具有較差的跨語言傳輸能力，E2E 在 (1) 零次傳輸到訓練中未見的語言和 (2) 多語言訓練，即在多種語言上進行聯合訓練方面都遠遠落後於 CA。最後，我們設計了一種基於轉錄為羅馬化文本的新穎 CA 方法，作為與語言無關的中間表示，並表明它代表了對沒有原生 ASR 支持的語言的強健解決方案。我們的 SpeechTaxi 資料集可在以下位置公開獲得：https://huggingface.co/datasets/LennartKeller/SpeechTaxi/。</paragraph>

##### **Distilling Generative-Discriminative Representations for Very Low-Resolution Face Recognition**
2409.06371v1 by Junzheng Zhang, Weijia Guo, Bochao Liu, Ruixin Shi, Yong Li, Shiming Ge

Very low-resolution face recognition is challenging due to the serious loss
of informative facial details in resolution degradation. In this paper, we
propose a generative-discriminative representation distillation approach that
combines generative representation with cross-resolution aligned knowledge
distillation. This approach facilitates very low-resolution face recognition by
jointly distilling generative and discriminative models via two distillation
modules. Firstly, the generative representation distillation takes the encoder
of a diffusion model pretrained for face super-resolution as the generative
teacher to supervise the learning of the student backbone via feature
regression, and then freezes the student backbone. After that, the
discriminative representation distillation further considers a pretrained face
recognizer as the discriminative teacher to supervise the learning of the
student head via cross-resolution relational contrastive distillation. In this
way, the general backbone representation can be transformed into discriminative
head representation, leading to a robust and discriminative student model for
very low-resolution face recognition. Our approach improves the recovery of the
missing details in very low-resolution faces and achieves better knowledge
transfer. Extensive experiments on face datasets demonstrate that our approach
enhances the recognition accuracy of very low-resolution faces, showcasing its
effectiveness and adaptability.

摘要：由於解析度降低時會嚴重喪失具資訊性的臉部細節，因此解析度極低的臉部辨識具有挑戰性。在本文中，我們提出了一種生成式辨識表徵蒸餾方法，結合生成式表徵與跨解析度對齊知識蒸餾。此方法透過兩個蒸餾模組，共同蒸餾生成式與辨識模型，進而促進解析度極低的臉部辨識。首先，生成式表徵蒸餾將預訓練用於臉部超解析度的擴散模型編碼器視為生成式教師，透過特徵回歸監督學生主幹的學習，然後凍結學生主幹。之後，辨識表徵蒸餾進一步將預訓練的臉部辨識器視為辨識教師，透過跨解析度關係對比蒸餾監督學生頭部的學習。透過這種方式，一般主幹表徵可以轉換為辨識頭部表徵，進而產生一個用於解析度極低的臉部辨識的強健且具辨識力的學生模型。我們的做法改善了解析度極低臉部中遺失細節的復原，並達到了更好的知識傳遞。對臉部資料集進行的廣泛實驗證明，我們的做法增強了解析度極低臉部的辨識精確度，展示了其有效性與適應性。

##### **Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development**
2409.06367v1 by Tianwu Lei, Bohan Wang, Silin Chen, Shurong Cao, Ningmu Zou

Anomaly detection is a crucial process in industrial manufacturing and has
made significant advancements recently. However, there is a large variance
between the data used in the development and the data collected by the
production environment. Therefore, we present the Texture-AD benchmark based on
representative texture-based anomaly detection to evaluate the effectiveness of
unsupervised anomaly detection algorithms in real-world applications. This
dataset includes images of 15 different cloth, 14 semiconductor wafers and 10
metal plates acquired under different optical schemes. In addition, it includes
more than 10 different types of defects produced during real manufacturing
processes, such as scratches, wrinkles, color variations and point defects,
which are often more difficult to detect than existing datasets. All anomalous
areas are provided with pixel-level annotations to facilitate comprehensive
evaluation using anomaly detection models. Specifically, to adapt to diverse
products in automated pipelines, we present a new evaluation method and results
of baseline algorithms. The experimental results show that Texture-AD is a
difficult challenge for state-of-the-art algorithms. To our knowledge,
Texture-AD is the first dataset to be devoted to evaluating industrial defect
detection algorithms in the real world. The dataset is available at
https://XXX.

摘要：異常偵測在工業製造中是一個至關重要的程序，並且最近已取得重大進展。然而，用於開發的資料與生產環境收集的資料之間存在很大的差異。因此，我們提出了基於代表性紋理異常偵測的 Texture-AD 評量基準，以評估無監督異常偵測演算法在實際應用中的有效性。此資料集包含在不同光學方案下取得的 15 種不同布料、14 片半導體晶圓和 10 片金屬板的影像。此外，它還包含在實際製造過程中產生的 10 多種不同類型的缺陷，例如刮痕、皺紋、顏色變化和點缺陷，這些缺陷通常比現有資料集更難偵測。所有異常區域都提供像素級註解，以利於使用異常偵測模型進行全面評估。具體來說，為了適應自動化管道中的各種產品，我們提出了一種新的評估方法和基線演算法的結果。實驗結果表明，Texture-AD 對最先進的演算法來說是一個艱難的挑戰。據我們所知，Texture-AD 是第一個致力於評估實際環境中的工業缺陷偵測演算法的資料集。此資料集可在 https://XXX 取得。

##### **Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks**
2409.06362v1 by Teresa Dorszewski, Lenka Tětková, Lorenz Linhardt, Lars Kai Hansen

Understanding how neural networks align with human cognitive processes is a
crucial step toward developing more interpretable and reliable AI systems.
Motivated by theories of human cognition, this study examines the relationship
between \emph{convexity} in neural network representations and
\emph{human-machine alignment} based on behavioral data. We identify a
correlation between these two dimensions in pretrained and fine-tuned vision
transformer models. Our findings suggest that the convex regions formed in
latent spaces of neural networks to some extent align with human-defined
categories and reflect the similarity relations humans use in cognitive tasks.
While optimizing for alignment generally enhances convexity, increasing
convexity through fine-tuning yields inconsistent effects on alignment, which
suggests a complex relationship between the two. This study presents a first
step toward understanding the relationship between the convexity of latent
representations and human-machine alignment.

摘要：了解神经網路如何與人類認知過程相符，是朝開發更具可解釋性與可信賴性的 AI 系統邁進的關鍵一步。本研究受到人類認知理論的啟發，探討神經網路表示中的「凸性」與根據行為資料的「人機對齊」之間的關係。我們在預訓練和微調的視覺轉換器模型中，找出這兩個面向之間的關聯性。我們的發現顯示，在神經網路的潛在空間中形成的凸區域，在某種程度上與人類定義的類別相符，並反映了人類在認知任務中使用的相似性關係。雖然針對對齊進行最佳化通常會增強凸性，但透過微調來增加凸性，對對齊的影響卻不一致，這表明兩者之間的關係很複雜。本研究為了解潛在表示的凸性與人機對齊之間的關係，踏出了第一步。

##### **MAGDA: Multi-agent guideline-driven diagnostic assistance**
2409.06351v1 by David Bani-Harouni, Nassir Navab, Matthias Keicher

In emergency departments, rural hospitals, or clinics in less developed
regions, clinicians often lack fast image analysis by trained radiologists,
which can have a detrimental effect on patients' healthcare. Large Language
Models (LLMs) have the potential to alleviate some pressure from these
clinicians by providing insights that can help them in their decision-making.
While these LLMs achieve high test results on medical exams showcasing their
great theoretical medical knowledge, they tend not to follow medical
guidelines. In this work, we introduce a new approach for zero-shot
guideline-driven decision support. We model a system of multiple LLM agents
augmented with a contrastive vision-language model that collaborate to reach a
patient diagnosis. After providing the agents with simple diagnostic
guidelines, they will synthesize prompts and screen the image for findings
following these guidelines. Finally, they provide understandable
chain-of-thought reasoning for their diagnosis, which is then self-refined to
consider inter-dependencies between diseases. As our method is zero-shot, it is
adaptable to settings with rare diseases, where training data is limited, but
expert-crafted disease descriptions are available. We evaluate our method on
two chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing
performance improvement over existing zero-shot methods and generalizability to
rare diseases.

摘要：在急診室、鄉村醫院或欠發達地區的診所，臨床醫師常常缺乏受過訓練的放射科醫師進行快速的影像分析，這可能會對病患的醫療保健造成不利影響。大型語言模型 (LLM) 有潛力減輕這些臨床醫師的一些壓力，方法是提供見解，協助他們進行決策。儘管這些 LLM 在展示其豐富的理論醫學知識的醫學考試中獲得了很高的測試結果，但它們往往不遵循醫療指南。在這項工作中，我們介紹了一種新的零次學習指導方針驅動決策支援方法。我們模擬了一個多個 LLM 代理系統，並增強了一個對比視覺語言模型，該模型協作以達成病患診斷。在為代理提供簡單的診斷指南後，它們將綜合提示並根據這些指南篩選影像以找出發現。最後，它們為其診斷提供可以理解的思路推理，然後自我精進以考量疾病之間的相互依存關係。由於我們的模型是零次學習，因此它可以適應罕見疾病的設定，在這種設定中，訓練資料有限，但有專家製作的疾病描述可用。我們在兩個胸部 X 光片資料集，CheXpert 和 ChestX-ray 14 Longtail，評估我們的模型，展示了相較於現有的零次學習方法的效能提升，以及對罕見疾病的概括性。

##### **VoiceWukong: Benchmarking Deepfake Voice Detection**
2409.06348v1 by Ziwei Yan, Yanjie Zhao, Haoyu Wang

With the rapid advancement of technologies like text-to-speech (TTS) and
voice conversion (VC), detecting deepfake voices has become increasingly
crucial. However, both academia and industry lack a comprehensive and intuitive
benchmark for evaluating detectors. Existing datasets are limited in language
diversity and lack many manipulations encountered in real-world production
environments.
  To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate
the performance of deepfake voice detectors. To build the dataset, we first
collected deepfake voices generated by 19 advanced and widely recognized
commercial tools and 15 open-source tools. We then created 38 data variants
covering six types of manipulations, constructing the evaluation dataset for
deepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200
Chinese deepfake voice samples. Using VoiceWukong, we evaluated 12
state-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of
13.50%, while all others exceeded 20%. Our findings reveal that these detectors
face significant challenges in real-world applications, with dramatically
declining performance. In addition, we conducted a user study with more than
300 participants. The results are compared with the performance of the 12
detectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio,
where different detectors and humans exhibit varying identification
capabilities for deepfake voices at different deception levels, while the LALM
demonstrates no detection ability at all. Furthermore, we provide a leaderboard
for deepfake voice detection, publicly available at
{https://voicewukong.github.io}.

摘要：<paragraph>隨著文字轉語音 (TTS) 和語音轉換 (VC) 等技術的快速進步，偵測深度造假語音變得越來越重要。然而，學術界和業界都缺乏一個全面且直觀的基準來評估偵測器。現有的資料集在語言多樣性方面受到限制，並且缺乏在現實世界生產環境中遇到的許多操作。
  為了填補這個空白，我們提出了 VoiceWukong，一個旨在評估深度造假語音偵測器效能的基準。為了建立資料集，我們首先收集了由 19 個先進且廣泛認可的商業工具和 15 個開源工具生成的深度造假語音。然後，我們創建了 38 種資料變體，涵蓋六種類型的操作，構建了深度造假語音偵測的評估資料集。因此，VoiceWukong 包含 265,200 個英文和 148,200 個中文深度造假語音範例。使用 VoiceWukong，我們評估了 12 個最先進的偵測器。AASIST2 達到了 13.50% 的最佳等錯率 (EER)，而其他所有偵測器都超過了 20%。我們的研究結果顯示，這些偵測器在現實世界應用中面臨重大挑戰，效能大幅下降。此外，我們進行了一項有超過 300 名參與者的使用者研究。結果與 12 個偵測器的效能以及多模式大型語言模型 (MLLM)（即 Qwen2-Audio）進行比較，其中不同的偵測器和人類在不同欺騙層級對深度造假語音展現出不同的辨識能力，而 LALM 則完全沒有偵測能力。此外，我們提供了一個深度造假語音偵測排行榜，可在 {https://voicewukong.github.io} 公開取得。</paragraph>

##### **Compute-Update Federated Learning: A Lattice Coding Approach**
2409.06343v1 by Seyed Mohammad Azimi-Abarghouyi, Lav R. Varshney

This paper introduces a federated learning framework that enables
over-the-air computation via digital communications, using a new joint
source-channel coding scheme. Without relying on channel state information at
devices, this scheme employs lattice codes to both quantize model parameters
and exploit interference from the devices. We propose a novel receiver
structure at the server, designed to reliably decode an integer combination of
the quantized model parameters as a lattice point for the purpose of
aggregation. We present a mathematical approach to derive a convergence bound
for the proposed scheme and offer design remarks. In this context, we suggest
an aggregation metric and a corresponding algorithm to determine effective
integer coefficients for the aggregation in each communication round. Our
results illustrate that, regardless of channel dynamics and data heterogeneity,
our scheme consistently delivers superior learning accuracy across various
parameters and markedly surpasses other over-the-air methodologies.

摘要：本文提出了一個聯合學習架構，它使用一個新的聯合源通道編碼方案，通過數位通訊進行空中運算。在不依賴於設備上的通道狀態資訊的情況下，此方案採用格碼來量化模型參數並利用來自設備的干擾。我們在伺服器上提出了一個新穎的接收器結構，旨在可靠地將量化模型參數的整數組合解碼為格點，以進行聚合。我們提出了一種數學方法來推導所提出方案的收斂界限，並提供設計說明。在這種情況下，我們建議使用聚合指標和對應演算法來確定每一輪通訊中聚合的有效整數係數。我們的結果表明，無論通道動態和資料異質性如何，我們的方案都能在各種參數中持續提供優異的學習準確度，並顯著超越其他空中方法。

##### **Retrieval Or Holistic Understanding? Dolce: Differentiate Our Long Context Evaluation Tasks**
2409.06338v1 by Zi Yang

We argue that there are two major distinct capabilities in long context
understanding: retrieval and holistic understanding. Understanding and further
improving LLMs' long context capabilities would not be possible without knowing
the tasks' focus categories. We aim to automatically identify retrieval focused
and holistic understanding focused problems from suites of benchmarks and
quantitatively measure the difficulty within each focus. In this paper, we
present the Dolce framework, which parameterizes each problem by $\lambda$
(complexity) and $k$ (redundancy) and assigns to one of five predefined focus
categories. We propose to sample short contexts from the full context and
estimate the probability an LLM solves the problem using the sampled spans. To
find the $\lambda$ and $k$ for each problem, we further propose a mixture model
of a non-parametric background noise component and a parametric/non-parametric
hybrid oracle component, where we derive the probability functions
parameterized by $\lambda$ and $k$ for both the correct-or-wrong (COW) scenario
and the partial-point-in-grading (PIG) scenario. Our proposed methods can
identify 0% to 67% of the problems are retrieval focused and 0% to 90% of the
problems are holistic understanding focused across 44 existing long context
evaluation tasks.

摘要：我們主張長文理解中有兩個主要的區別能力：檢索和整體理解。了解和進一步改進 LLM 的長文理解能力，在不知道任務的重點類別是不可能的。我們的目標是從基準套件中自動識別以檢索為重點和以整體理解為重點的問題，並定量測量每個重點中的難度。在本文中，我們提出了 Dolce 框架，它通過 $\lambda$（複雜性）和 $k$（冗餘）對每個問題進行參數化，並將其分配到五個預定義的重點類別之一。我們建議從完整文中抽取簡短的語境，並估計 LLM 使用抽取的跨度解決問題的機率。為了找到每個問題的 $\lambda$ 和 $k$，我們進一步提出了非參數背景噪音組成和參數/非參數混合神諭組成的混合模型，其中我們推導出在正確或錯誤 (COW) 場景和部分分數評分 (PIG) 場景中由 $\lambda$ 和 $k$ 參數化的機率函數。我們提出的方法可以識別出 0% 到 67% 的問題以檢索為重點，以及 0% 到 90% 的問題以整體理解為重點，涵蓋 44 個現有的長文評估任務。

##### **Towards Agentic AI on Particle Accelerators**
2409.06336v1 by Antonin Sulc, Thorsten Hellert, Raimund Kammering, Hayden Houscher, Jason St. John

As particle accelerators grow in complexity, traditional control methods face
increasing challenges in achieving optimal performance. This paper envisions a
paradigm shift: a decentralized multi-agent framework for accelerator control,
powered by Large Language Models (LLMs) and distributed among autonomous
agents. We present a proposition of a self-improving decentralized system where
intelligent agents handle high-level tasks and communication and each agent is
specialized control individual accelerator components.
  This approach raises some questions: What are the future applications of AI
in particle accelerators? How can we implement an autonomous complex system
such as a particle accelerator where agents gradually improve through
experience and human feedback? What are the implications of integrating a
human-in-the-loop component for labeling operational data and providing expert
guidance? We show two examples, where we demonstrate viability of such
architecture.

摘要：隨著粒子加速器的複雜度不斷提升，傳統的控制方法在達成最佳效能時面臨越來越大的挑戰。本文構想了一種典範轉移：一種由大型語言模型 (LLM) 驅動且分佈在自主代理之間的加速器控制去中心化多代理架構。我們提出了一個自我提升的去中心化系統的命題，其中智慧代理處理高階任務和通訊，且每個代理專門控制個別加速器元件。
這種方法引發了一些問題：AI 在粒子加速器中的未來應用是什麼？我們如何實作一個自主複雜系統，例如粒子加速器，其中代理會透過經驗和人類回饋逐漸提升？將人類置於迴路中元件以標記作業資料並提供專家指導的影響是什麼？我們展示了兩個範例，說明這種架構的可行性。

##### **Extracting Paragraphs from LLM Token Activations**
2409.06328v1 by Nicholas Pochinkov, Angelo Benoit, Lovkush Agarwal, Zainab Ali Majid, Lucile Ter-Minassian

Generative large language models (LLMs) excel in natural language processing
tasks, yet their inner workings remain underexplored beyond token-level
predictions. This study investigates the degree to which these models decide
the content of a paragraph at its onset, shedding light on their contextual
understanding. By examining the information encoded in single-token
activations, specifically the "\textbackslash n\textbackslash n" double newline
token, we demonstrate that patching these activations can transfer significant
information about the context of the following paragraph, providing further
insights into the model's capacity to plan ahead.

摘要：生成式大型語言模型 (LLM) 在自然語言處理任務中表現出色，但它們的內部運作仍未被充分探索，僅止於符號層級的預測。本研究探討這些模型在段落開頭決定內容的程度，進而闡明它們的上下文理解能力。透過檢視單一符號激活中編碼的資訊，特別是「\n\n」雙換行符號，我們證明修補這些激活可以傳遞後續段落上下文的顯著資訊，進一步了解模型的超前規劃能力。

##### **LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs**
2409.06323v1 by Siqing Li, Jin-Duk Park, Wei Huang, Xin Cao, Won-Yong Shin, Zhiqiang Xu

Heterogeneous graph neural networks (HGNNs) have significantly propelled the
information retrieval (IR) field. Still, the effectiveness of HGNNs heavily
relies on high-quality labels, which are often expensive to acquire. This
challenge has shifted attention towards Heterogeneous Graph Contrastive
Learning (HGCL), which usually requires pre-defined meta-paths. However, our
findings reveal that meta-path combinations significantly affect performance in
unsupervised settings, an aspect often overlooked in current literature.
Existing HGCL methods have considerable variability in outcomes across
different meta-path combinations, thereby challenging the optimization process
to achieve consistent and high performance. In response, we introduce
\textsf{LAMP} (\underline{\textbf{L}}earn\underline{\textbf{A}}ble
\underline{\textbf{M}}eta-\underline{\textbf{P}}ath), a novel adversarial
contrastive learning approach that integrates various meta-path sub-graphs into
a unified and stable structure, leveraging the overlap among these sub-graphs.
To address the denseness of this integrated sub-graph, we propose an
adversarial training strategy for edge pruning, maintaining sparsity to enhance
model performance and robustness. \textsf{LAMP} aims to maximize the difference
between meta-path and network schema views for guiding contrastive learning to
capture the most meaningful information. Our extensive experimental study
conducted on four diverse datasets from the Heterogeneous Graph Benchmark (HGB)
demonstrates that \textsf{LAMP} significantly outperforms existing
state-of-the-art unsupervised models in terms of accuracy and robustness.

摘要：異質圖神經網路 (HGNN) 已顯著推動資訊檢索 (IR) 領域。儘管如此，HGNN 的有效性極度依賴於高品質標籤，而取得這些標籤通常成本高昂。這項挑戰已將注意力轉移到異質圖對比學習 (HGCL)，這通常需要預先定義的元路徑。然而，我們的研究結果顯示，元路徑組合會顯著影響無監督設定中的效能，而這項面向在現行文獻中常被忽略。現有的 HGCL 方法在不同的元路徑組合中具有相當大的結果變異性，因此挑戰了最佳化流程，難以達成一致且高品質的效能。為了解決這個問題，我們引入了 \textsf{LAMP}（可學習元路徑），這是一種新穎的對抗式對比學習方法，將各種元路徑子圖整合到統一且穩定的結構中，並利用這些子圖之間的重疊。為了解決這個整合子圖的稠密度，我們提出了一種對抗訓練策略，用於邊緣修剪，並維持稀疏性以增強模型效能與穩健性。\textsf{LAMP} 旨在最大化元路徑與網路架構檢視之間的差異，以引導對比學習擷取最有意義的資訊。我們在異質圖基準 (HGB) 中的四個不同資料集上進行廣泛的實驗研究，證明 \textsf{LAMP} 在準確度和穩健性方面顯著優於現有的最先進無監督模型。

##### **An End-to-End Approach for Chord-Conditioned Song Generation**
2409.06307v1 by Shuochen Gao, Shun Lei, Fan Zhuo, Hangyu Liu, Feng Liu, Boshi Tang, Qiaochu Huang, Shiyin Kang, Zhiyong Wu

The Song Generation task aims to synthesize music composed of vocals and
accompaniment from given lyrics. While the existing method, Jukebox, has
explored this task, its constrained control over the generations often leads to
deficiency in music performance. To mitigate the issue, we introduce an
important concept from music composition, namely chords, to song generation
networks. Chords form the foundation of accompaniment and provide vocal melody
with associated harmony. Given the inaccuracy of automatic chord extractors, we
devise a robust cross-attention mechanism augmented with dynamic weight
sequence to integrate extracted chord information into song generations and
reduce frame-level flaws, and propose a novel model termed Chord-Conditioned
Song Generator (CSG) based on it. Experimental evidence demonstrates our
proposed method outperforms other approaches in terms of musical performance
and control precision of generated songs.

摘要：歌曲生成任務旨在合成由人聲和伴奏組成的音樂，並從給定的歌詞中生成。雖然現有方法 Jukebox 已探討此任務，但其對生成過程的受限控制通常會導致音樂表現力不足。為了減輕此問題，我們將音樂創作中的重要概念和弦引入歌曲生成網路中。和弦構成伴奏的基礎，並為人聲旋律提供相關的和聲。由於自動和弦提取器的準確性不足，我們設計了一個強健的交叉注意力機制，並使用動態權重序列將提取的和弦資訊整合到歌曲生成中，並減少幀級缺陷，並提出一個基於此的新模型，稱為和弦條件歌曲生成器 (CSG)。實驗證據表明，我們提出的方法在音樂表現力和生成歌曲的控制精度方面優於其他方法。

##### **Enhancing Long Video Understanding via Hierarchical Event-Based Memory**
2409.06299v1 by Dingxin Cheng, Mingda Li, Jingyu Liu, Yongxin Guo, Bin Jiang, Qingbin Liu, Xi Chen, Bo Zhao

Recently, integrating visual foundation models into large language models
(LLMs) to form video understanding systems has attracted widespread attention.
Most of the existing models compress diverse semantic information within the
whole video and feed it into LLMs for content comprehension. While this method
excels in short video understanding, it may result in a blend of multiple event
information in long videos due to coarse compression, which causes information
redundancy. Consequently, the semantics of key events might be obscured within
the vast information that hinders the model's understanding capabilities. To
address this issue, we propose a Hierarchical Event-based Memory-enhanced LLM
(HEM-LLM) for better understanding of long videos. Firstly, we design a novel
adaptive sequence segmentation scheme to divide multiple events within long
videos. In this way, we can perform individual memory modeling for each event
to establish intra-event contextual connections, thereby reducing information
redundancy. Secondly, while modeling current event, we compress and inject the
information of the previous event to enhance the long-term inter-event
dependencies in videos. Finally, we perform extensive experiments on various
video understanding tasks and the results show that our model achieves
state-of-the-art performances.

摘要：最近，将视觉基础模型整合到大型语言模型 (LLM) 中以形成视频理解系统已引起广泛关注。
大多数现有模型都会压缩整个视频中的各种语义信息，并将其输入 LLM 以进行内容理解。虽然此方法在短视频理解方面表现出色，但由于粗略的压缩，它可能会导致长视频中多个事件信息的混合，从而导致信息冗余。因此，关键事件的语义可能会被隐藏在大量信息中，从而阻碍模型的理解能力。为了解决这个问题，我们提出了一种分层事件记忆增强 LLM (HEM-LLM) 以便更好地理解长视频。首先，我们设计了一种新颖的自适应序列分割方案，以划分长视频中的多个事件。通过这种方式，我们可以对每个事件执行单独的记忆建模，以建立事件内部的上下文连接，从而减少信息冗余。其次，在对当前事件进行建模时，我们压缩并注入前一个事件的信息，以增强视频中长期事件间的依赖关系。最后，我们对各种视频理解任务进行了广泛的实验，结果表明我们的模型取得了最先进的性能。

##### **User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study**
2409.06297v1 by Julien Albert, Martin Balfroid, Miriam Doh, Jeremie Bogaert, Luca La Fisca, Liesbet De Vos, Bryan Renard, Vincent Stragier, Emmanuel Jean

Recommender systems have become integral to our digital experiences, from
online shopping to streaming platforms. Still, the rationale behind their
suggestions often remains opaque to users. While some systems employ a
graph-based approach, offering inherent explainability through paths
associating recommended items and seed items, non-experts could not easily
understand these explanations. A popular alternative is to convert graph-based
explanations into textual ones using a template and an algorithm, which we
denote here as ''template-based'' explanations. Yet, these can sometimes come
across as impersonal or uninspiring. A novel method would be to employ large
language models (LLMs) for this purpose, which we denote as ''LLM-based''. To
assess the effectiveness of LLMs in generating more resonant explanations, we
conducted a pilot study with 25 participants. They were presented with three
explanations: (1) traditional template-based, (2) LLM-based rephrasing of the
template output, and (3) purely LLM-based explanations derived from the
graph-based explanations. Although subject to high variance, preliminary
findings suggest that LLM-based explanations may provide a richer and more
engaging user experience, further aligning with user expectations. This study
sheds light on the potential limitations of current explanation methods and
offers promising directions for leveraging large language models to improve
user satisfaction and trust in recommender systems.

摘要：推薦系統已成為我們數位體驗中不可或缺的一部分，從線上購物到串流平台皆是如此。然而，其建議背後的原理通常對使用者來說仍不透明。儘管有些系統採用基於圖形的做法，透過連結推薦項目與種子項目的路徑提供內在的可解釋性，但非專家無法輕易理解這些解釋。一種常見的替代方法是使用範本和演算法將基於圖形的解釋轉換為文字解釋，我們在此將其表示為「基於範本」的解釋。然而，這些解釋有時會顯得制式或缺乏靈感。一種新穎的方法是為此目的採用大型語言模型 (LLM)，我們將其表示為「基於 LLM」。為了評估 LLM 在產生更具共鳴解釋方面的有效性，我們進行了一項有 25 位參與者的試驗研究。我們向他們展示了三種解釋：(1) 傳統基於範本的解釋，(2) LLM 對範本輸出的重新表述，以及 (3) 純粹從基於圖形的解釋衍生的基於 LLM 的解釋。儘管存在高度變異，但初步結果表明，基於 LLM 的解釋可能提供更豐富、更吸引人的使用者體驗，進一步符合使用者的期望。這項研究揭示了當前解釋方法的潛在限制，並為利用大型語言模型來提升使用者滿意度和對推薦系統的信任提供了有希望的方向。

##### **Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models**
2409.06280v1 by Zitao Chen, Karthik Pattabiraman

The rise of deep learning (DL) has led to a surging demand for training data,
which incentivizes the creators of DL models to trawl through the Internet for
training materials. Meanwhile, users often have limited control over whether
their data (e.g., facial images) are used to train DL models without their
consent, which has engendered pressing concerns.
  This work proposes MembershipTracker, a practical data provenance tool that
can empower ordinary users to take agency in detecting the unauthorized use of
their data in training DL models. We view tracing data provenance through the
lens of membership inference (MI). MembershipTracker consists of a lightweight
data marking component to mark the target data with small and targeted changes,
which can be strongly memorized by the model trained on them; and a specialized
MI-based verification process to audit whether the model exhibits strong
memorization on the target samples.
  Overall, MembershipTracker only requires the users to mark a small fraction
of data (0.005% to 0.1% in proportion to the training set), and it enables the
users to reliably detect the unauthorized use of their data (average 0%
FPR@100% TPR). We show that MembershipTracker is highly effective across
various settings, including industry-scale training on the full-size
ImageNet-1k dataset. We finally evaluate MembershipTracker under multiple
classes of countermeasures.

摘要：深度學習 (DL) 的興起導致對訓練資料的需求激增，這激勵了 DL 模型的創建者在網路上搜尋訓練資料。同時，使用者通常無法控制他們的資料（例如：人臉影像）是否在未經他們同意的情況下被用來訓練 DL 模型，這引起了迫切的關注。
這項工作提出了 MembershipTracker，一個實用的資料來源工具，可以讓一般使用者在偵測他們的資料在訓練 DL 模型時被未經授權使用時，採取行動。我們透過成員推論 (MI) 的角度來追蹤資料來源。MembershipTracker 包含一個輕量級資料標記元件，用小而有針對性的變更來標記目標資料，這些變更可以被訓練在這些資料上的模型牢記；以及一個專門的基於 MI 的驗證程序，用來稽核模型是否對目標樣本展現強烈的記憶。
總體而言，MembershipTracker 只需要使用者標記一小部分資料（相對於訓練集，比例為 0.005% 到 0.1%），它讓使用者能夠可靠地偵測到他們的資料被未經授權使用（平均 0% FPR@100% TPR）。我們展示了 MembershipTracker 在各種設定中都非常有效，包括在全尺寸 ImageNet-1k 資料集上進行產業規模的訓練。最後，我們在多種對策類別下評估了 MembershipTracker。

##### **Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models**
2409.06277v2 by Yao Shu, Wenyang Hu, See-Kiong Ng, Bryan Kian Hsiang Low, Fei Richard Yu

Large Language Models (LLMs) have become indispensable in numerous real-world
applications. Unfortunately, fine-tuning these models at scale, especially in
federated settings where data privacy and communication efficiency are
critical, presents significant challenges. Existing methods often resort to
parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but
this typically comes at the cost of model accuracy. To address these
limitations, we propose federated full-parameter tuning at scale for LLMs
(Ferret), the first first-order method with shared randomness to enable
scalable full-parameter tuning of LLMs across decentralized data sources while
maintaining competitive model accuracy. Ferret accomplishes this through three
aspects: (1) it employs widely applied first-order methods for efficient local
updates; (2) it projects these updates into a low-dimensional space to
considerably reduce communication overhead; and (3) it reconstructs local
updates from this low-dimensional space with shared randomness to facilitate
effective full-parameter global aggregation, ensuring fast convergence and
competitive final performance. Our rigorous theoretical analyses and insights
along with extensive experiments, show that Ferret significantly enhances the
scalability of existing federated full-parameter tuning approaches by achieving
high computational efficiency, reduced communication overhead, and fast
convergence, all while maintaining competitive model accuracy. Our
implementation is available at https://github.com/allen4747/Ferret.

摘要：大型語言模型 (LLM) 已成為許多真實世界應用中不可或缺的一部分。不幸的是，微調這些模型的規模，尤其是在聯邦設置中，資料隱私和通訊效率至關重要，這提出了重大的挑戰。現有方法通常訴諸於參數高效微調 (PEFT) 來減輕通訊負擔，但這通常是以模型準確性為代價。為了解決這些限制，我們提出了一種針對 LLM 的聯邦全參數調整規模 (Ferret)，這是一種具有共享隨機性的第一階方法，能夠在分散式資料來源中對 LLM 進行可擴充的全參數調整，同時保持競爭力的模型準確性。Ferret 通過三個方面實現了這一點：(1) 它採用廣泛應用的第一階方法進行高效的本地更新；(2) 它將這些更新投影到低維空間中，以顯著減少通訊負擔；(3) 它使用共享隨機性從這個低維空間重建本地更新，以促進有效的全參數全局聚合，確保快速收斂和有競爭力的最終效能。我們嚴謹的理論分析和見解以及廣泛的實驗表明，Ferret 顯著提高了現有聯邦全參數調整方法的可擴充性，方法是實現高計算效率、降低通訊負擔和快速收斂，同時保持有競爭力的模型準確性。我們的實作可在 https://github.com/allen4747/Ferret 取得。

##### **Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking**
2409.06263v1 by Jihyun Lee, Solee Im, Wonjun Lee, Gary Geunbae Lee

Dialogue State Tracking (DST) is a key part of task-oriented dialogue
systems, identifying important information in conversations. However, its
accuracy drops significantly in spoken dialogue environments due to named
entity errors from Automatic Speech Recognition (ASR) systems. We introduce a
simple yet effective data augmentation method that targets those entities to
improve the robustness of DST model. Our novel method can control the placement
of errors using keyword-highlighted prompts while introducing phonetically
similar errors. As a result, our method generated sufficient error patterns on
keywords, leading to improved accuracy in noised and low-accuracy ASR
environments.

摘要：對話狀態追蹤 (DST) 是任務導向對話系統的重要部分，用於識別對話中的重要資訊。然而，由於自動語音辨識 (ASR) 系統中的命名實體錯誤，其準確度在口語對話環境中大幅下降。我們引入一種簡單但有效的資料擴充方法，針對這些實體以提高 DST 模型的健全性。我們的創新方法可以在引入音似錯誤的同時，使用關鍵字突顯提示來控制錯誤的放置。因此，我們的模型在關鍵字上產生足夠的錯誤模式，從而提高了有雜訊和低準確度 ASR 環境中的準確度。

##### **DiPT: Enhancing LLM reasoning through diversified perspective-taking**
2409.06241v1 by Hoang Anh Just, Mahavir Dabas, Lifu Huang, Ming Jin, Ruoxi Jia

Existing work on improving language model reasoning typically explores a
single solution path, which can be prone to errors. Inspired by
perspective-taking in social studies, this paper introduces DiPT, a novel
approach that complements current reasoning methods by explicitly incorporating
diversified viewpoints. This approach allows the model to gain a deeper
understanding of the problem's context and identify the most effective solution
path during the inference stage. Additionally, it provides a general
data-centric AI recipe for augmenting existing data to improve their quality
for fine-tuning.
  Our empirical results demonstrate that DiPT can be flexibly integrated into
existing methods that focus on a single reasoning approach, enhancing their
reasoning performance and stability when presented with paraphrased problems.
Furthermore, we illustrate improved context understanding by maintaining the
model's safe outputs against "jailbreaking" prompts intentionally designed to
bypass safeguards built into deployed models. Lastly, we show that fine-tuning
with data enriched with diverse perspectives can boost the reasoning
capabilities of the model compared to fine-tuning with raw data alone.

摘要：現有的改善語言模型推理的工作通常會探索單一的解決方案路徑，這可能會容易出錯。受到社會研究中觀點採用的啟發，本文介紹了 DiPT，這是一種新方法，透過明確納入多元觀點來補充目前的推理方法。此方法允許模型更深入地了解問題的背景，並在推理階段找出最有效的解決方案路徑。此外，它提供了一種通用的以資料為中心的 AI 配方，用於擴充現有資料，以提升其微調品質。
我們的實證結果證明，DiPT 可以靈活地整合到專注於單一推理方法的現有方法中，在遇到轉述問題時，提升其推理效能和穩定性。此外，透過維持模型對於「越獄」提示的安全性輸出，我們展示了改善的背景理解，而這些提示旨在繞過部署模型中內建的防護措施。最後，我們展示了使用豐富多元觀點的資料進行微調，與僅使用原始資料進行微調相比，可以提升模型的推理能力。

##### **NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit**
2409.06226v1 by Linfeng Zhang, Changyue Hu, Zhiyu Quan

As the body of academic literature continues to grow, researchers face
increasing difficulties in effectively searching for relevant resources.
Existing databases and search engines often fall short of providing a
comprehensive and contextually relevant collection of academic literature. To
address this issue, we propose a novel framework that leverages Natural
Language Processing (NLP) techniques. This framework automates the retrieval,
summarization, and clustering of academic literature within a specific research
domain. To demonstrate the effectiveness of our approach, we introduce CyLit,
an NLP-powered repository specifically designed for the cyber risk literature.
CyLit empowers researchers by providing access to context-specific resources
and enabling the tracking of trends in the dynamic and rapidly evolving field
of cyber risk. Through the automatic processing of large volumes of data, our
NLP-powered solution significantly enhances the efficiency and specificity of
academic literature searches. We compare the literature categorization results
of CyLit to those presented in survey papers or generated by ChatGPT,
highlighting the distinctive insights this tool provides into cyber risk
research literature. Using NLP techniques, we aim to revolutionize the way
researchers discover, analyze, and utilize academic resources, ultimately
fostering advancements in various domains of knowledge.

摘要：隨著學術文獻的數量持續增加，研究人員在有效搜尋相關資源時面臨越來越大的困難。現有的資料庫和搜尋引擎通常無法提供全面且與脈絡相關的學術文獻集合。為了解決這個問題，我們提出一個新的架構，它利用自然語言處理 (NLP) 技術。這個架構自動化特定研究領域內學術文獻的檢索、摘要和分群。為了證明我們方法的有效性，我們引入了 CyLit，一個專門為網路風險文獻設計的 NLP 驅動儲存庫。CyLit 透過提供對特定脈絡資源的存取，並在動態且快速演進的網路風險領域追蹤趨勢，賦能研究人員。透過大量資料的自動化處理，我們 NLP 驅動的解決方案大幅提升學術文獻搜尋的效率和專一性。我們將 CyLit 的文獻分類結果與調查論文中提出的結果或由 ChatGPT 產生的結果進行比較，強調這個工具對網路風險研究文獻提供的獨特見解。透過使用 NLP 技術，我們旨在革新研究人員發現、分析和利用學術資源的方式，最終促進各個知識領域的進展。

##### **Enhancing Temporal Understanding in Audio Question Answering for Large Audio Language Models**
2409.06223v1 by Arvind Krishna Sridhar, Yinyi Guo, Erik Visser

The Audio Question Answering task includes audio event classification, audio
captioning, and open ended reasoning. Recently, Audio Question Answering has
garnered attention due to the advent of Large Audio Language Models. Current
literature focuses on constructing LALMs by integrating audio encoders with
text only Large Language Models through a projection module. While Large Audio
Language Models excel in general audio understanding, they are limited in
temporal reasoning which may hinder their commercial applications and on device
deployment. This paper addresses these challenges and limitations in audio
temporal reasoning. First, we introduce a data augmentation technique for
generating reliable audio temporal questions and answers using an LLM. Second,
we propose a continued finetuning curriculum learning strategy to specialize in
temporal reasoning without compromising performance on finetuned tasks.
Finally, we develop a reliable and transparent automated metric, assisted by an
LLM, to measure the correlation between Large Audio Language Model responses
and ground truth data intelligently. We demonstrate the effectiveness of our
proposed techniques using SOTA LALMs on public audio benchmark datasets.

摘要：音訊問答任務包括音訊事件分類、音訊字幕和開放式推理。最近，由於大型音訊語言模型的出現，音訊問答引起了關注。目前的文獻著重於透過投影模組將音訊編碼器與純文字大型語言模型整合，來建構 LALM。雖然大型音訊語言模型在一般音訊理解方面表現出色，但它們在時間推理方面受到限制，這可能會阻礙其商業應用和裝置部署。本文探討了音訊時間推理中的這些挑戰和限制。首先，我們引入一種資料擴充技術，使用 LLM 來產生可靠的音訊時間問題和答案。其次，我們提出一個持續微調課程學習策略，專精於時間推理，同時不影響微調任務的效能。最後，我們開發了一個可靠且透明的自動化指標，由 LLM 協助，以智慧的方式衡量大型音訊語言模型回應與地面實況資料之間的關聯性。我們使用公開音訊基準資料集上的 SOTA LALM，展示了我們所提出技術的有效性。

##### **Advancing Topic Segmentation of Broadcasted Speech with Multilingual Semantic Embeddings**
2409.06222v1 by Sakshi Deo Shukla, Pavel Denisov, Tugtekin Turan

Recent advancements in speech-based topic segmentation have highlighted the
potential of pretrained speech encoders to capture semantic representations
directly from speech. Traditionally, topic segmentation has relied on a
pipeline approach in which transcripts of the automatic speech recognition
systems are generated, followed by text-based segmentation algorithms. In this
paper, we introduce an end-to-end scheme that bypasses this conventional
two-step process by directly employing semantic speech encoders for
segmentation. Focused on the broadcasted news domain, which poses unique
challenges due to the diversity of speakers and topics within single
recordings, we address the challenge of accessing topic change points
efficiently in an end-to-end manner. Furthermore, we propose a new benchmark
for spoken news topic segmentation by utilizing a dataset featuring
approximately 1000 hours of publicly available recordings across six European
languages and including an evaluation set in Hindi to test the model's
cross-domain performance in a cross-lingual, zero-shot scenario. This setup
reflects real-world diversity and the need for models adapting to various
linguistic settings. Our results demonstrate that while the traditional
pipeline approach achieves a state-of-the-art $P_k$ score of 0.2431 for
English, our end-to-end model delivers a competitive $P_k$ score of 0.2564.
When trained multilingually, these scores further improve to 0.1988 and 0.2370,
respectively. To support further research, we release our model along with data
preparation scripts, facilitating open research on multilingual spoken news
topic segmentation.

摘要：<paragraph>最近在基於語音的主題區段化方面的新進展突顯了預先訓練的語音編碼器在直接從語音擷取語義表示方面的潛力。傳統上，主題區段化依賴於管線方法，其中會產生自動語音識別系統的轉錄，然後再進行基於文字的區段化演算法。在本文中，我們介紹了一個端到端的架構，它透過直接採用語義語音編碼器進行區段化，來繞過這個傳統的兩步驟流程。專注於廣播新聞領域，由於單一錄音中講者和主題的多樣性，因此構成了獨特的挑戰，我們以端到端的方式解決了有效存取主題變更點的挑戰。此外，我們透過利用一個包含六種歐洲語言約 1000 小時的公開錄音的資料集，並在印地語中加入一個評估集，來測試模型在跨語言、零次學習場景中的跨網域效能，進而提出一個新的基準，用於口說新聞主題區段化。此設定反映了真實世界的多樣性，以及模型適應各種語言設定的需求。我們的結果顯示，雖然傳統的管線方法達到了 0.2431 的最先進 $P_k$ 分數，但我們的端到端模型提供了 0.2564 的競爭性 $P_k$ 分數。當以多語言方式訓練時，這些分數進一步提高到 0.1988 和 0.2370。為了支持進一步的研究，我們發布了我們的模型以及資料準備腳本，促進了多語言口說新聞主題區段化的公開研究。</paragraph>

##### **CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities**
2409.06220v1 by Rashik Shahriar Akash, Radiful Islam, S. M. Saiful Islam Badhon, K. S. M. Tozammel Hossain

Cervical cancer affects millions of women worldwide and has a significantly
higher survival rate when diagnosed early. Pap smears and cervical biopsies are
vital screening tools for detecting such cancer. However, the success of these
screening processes depends on the skills of cytologists. A recent trend in
diagnostic cytology is to apply machine-learning-based models to classify
cancer using cell images. These automated models have been shown to perform
just as well as, or even better than, expert cytologists. Some notable methods
for classifying cervix cancers include ResNet50, VGG16, MobileNetV2, and
InceptionV3, based on deep convolutional neural networks (CNN). However, these
methods are computationally expensive. We present CerviXpert, a
multi-structural Convolutional Neural Network, to identify cervix cancer. We
perform extensive experiments on a publicly available dataset, SiPaKMeD, to
show the efficacy of our method. CerviXpert presents a promising solution for
efficient cervical cancer screening and diagnosis by striking a balance between
accuracy and practical feasibility.

摘要：子宮頸癌影響全球數百萬名女性，且在早期診斷時存活率顯著提高。子宮頸抹片檢查和子宮頸切片檢查是偵測此類癌症的重要篩檢工具。然而，這些篩檢過程的成功與否取決於細胞學家的技能。診斷細胞學的最新趨勢是應用基於機器學習的模型，以使用細胞影像對癌症進行分類。這些自動化模型已被證明執行得與專家細胞學家一樣好，甚至更好。一些用於分類子宮頸癌的著名方法包括 ResNet50、VGG16、MobileNetV2 和 InceptionV3，這些方法基於深度卷積神經網路 (CNN)。然而，這些方法在計算上很昂貴。我們提出 CerviXpert，一種多結構卷積神經網路，用於識別子宮頸癌。我們對一個公開可用的資料集 SiPaKMeD 進行廣泛的實驗，以證明我們方法的有效性。CerviXpert 為有效的子宮頸癌篩檢和診斷提供了一個有前途的解決方案，它在準確性和實用可行性之間取得了平衡。

##### **SubRegWeigh: Effective and Efficient Annotation Weighing with Subword Regularization**
2409.06216v1 by Kohei Tsuji, Tatsuya Hiraoka, Yuchang Cheng, Tomoya Iwakura

Many datasets of natural language processing (NLP) sometimes include
annotation errors. Researchers have attempted to develop methods to reduce the
adverse effect of errors in datasets automatically. However, an existing method
is time-consuming because it requires many trained models to detect errors. We
propose a novel method to reduce the time of error detection. Specifically, we
use a tokenization technique called subword regularization to create
pseudo-multiple models which are used to detect errors. Our proposed method,
SubRegWeigh, can perform annotation weighting four to five times faster than
the existing method. Additionally, SubRegWeigh improved performance in both
document classification and named entity recognition tasks. In experiments with
pseudo-incorrect labels, pseudo-incorrect labels were adequately detected.

摘要：許多自然語言處理 (NLP) 的資料集有時會包含註解錯誤。研究人員已嘗試開發方法，以自動減少資料集中錯誤的不利影響。然而，現有方法很耗時，因為它需要許多訓練過的模型來偵測錯誤。我們提出了一種新方法來減少錯誤偵測的時間。具體來說，我們使用一種稱為次字正規化的標記化技術來建立用於偵測錯誤的偽多重模型。我們提出的方法 SubRegWeigh 可以比現有方法快四到五倍地執行註解加權。此外，SubRegWeigh 在文件分類和命名實體辨識任務中都改進了效能。在使用偽不正確標籤的實驗中，偽不正確標籤被充分地偵測出來。

##### **Towards Generalizable Scene Change Detection**
2409.06214v1 by Jaewoo Kim, Uehwan Kim

Scene Change Detection (SCD) is vital for applications such as visual
surveillance and mobile robotics. However, current SCD methods exhibit a bias
to the temporal order of training datasets and limited performance on unseen
domains; coventional SCD benchmarks are not able to evaluate generalization or
temporal consistency. To tackle these limitations, we introduce a Generalizable
Scene Change Detection Framework (GeSCF) in this work. The proposed GeSCF
leverages localized semantics of a foundation model without any re-training or
fine-tuning -- for generalization over unseen domains. Specifically, we design
an adaptive thresholding of the similarity distribution derived from facets of
the pre-trained foundation model to generate initial pseudo-change mask. We
further utilize Segment Anything Model's (SAM) class-agnostic masks to refine
pseudo-masks. Moreover, our proposed framework maintains commutative operations
in all settings to ensure complete temporal consistency. Finally, we define new
metrics, evaluation dataset, and evaluation protocol for Generalizable Scene
Change Detection (GeSCD). Extensive experiments demonstrate that GeSCF excels
across diverse and challenging environments -- establishing a new benchmark for
SCD performance.

摘要：場景變更偵測 (SCD) 對於視覺監控和行動機器人等應用至關重要。然而，目前的 SCD 方法對訓練資料集的時間順序有偏見，且在未見過的領域中效能有限；傳統的 SCD 評量基準無法評估概化或時間一致性。為了克服這些限制，我們在這項工作中引入了可概化的場景變更偵測架構 (GeSCF)。所提出的 GeSCF 利用基礎模型的局部語意，而無需任何重新訓練或微調，以概化到未見過的領域。具體來說，我們設計了一個自適應閾值，用於從預先訓練好的基礎模型的各個方面衍生的相似性分佈，以產生初始的偽變更遮罩。我們進一步利用 Segment Anything Model (SAM) 的類別不可知遮罩來精緻化偽遮罩。此外，我們提出的架構在所有設定中都維持交換運算，以確保完全的時間一致性。最後，我們定義了新的指標、評量資料集和評量協定，用於可概化的場景變更偵測 (GeSCD)。廣泛的實驗證明，GeSCF 在多樣化且具挑戰性的環境中表現出色，為 SCD 效能建立了一個新的基準。

##### **STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning**
2409.06211v1 by Jaeseong Lee, seung-won hwang, Aurick Qiao, Daniel F Campos, Zhewei Yao, Yuxiong He

Mixture-of-experts (MoEs) have been adopted for reducing inference costs by
sparsely activating experts in Large language models (LLMs). Despite this
reduction, the massive number of experts in MoEs still makes them expensive to
serve. In this paper, we study how to address this, by pruning MoEs. Among
pruning methodologies, unstructured pruning has been known to achieve the
highest performance for a given pruning ratio, compared to structured pruning,
since the latter imposes constraints on the sparsification structure. This is
intuitive, as the solution space of unstructured pruning subsumes that of
structured pruning. However, our counterintuitive finding reveals that expert
pruning, a form of structured pruning, can actually precede unstructured
pruning to outperform unstructured-only pruning. As existing expert pruning,
requiring $O(\frac{k^n}{\sqrt{n}})$ forward passes for $n$ experts, cannot
scale for recent MoEs, we propose a scalable alternative with $O(1)$
complexity, yet outperforming the more expensive methods. The key idea is
leveraging a latent structure between experts, based on behavior similarity,
such that the greedy decision of whether to prune closely captures the joint
pruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized
MoE with 128 experts, our method needs only one H100 and two hours to achieve
nearly no loss in performance with 40% sparsity, even in generative tasks such
as GSM8K, where state-of-the-art unstructured pruning fails to. The code will
be made publicly available.

摘要：<paragraph>混合专家 (MoE) 已被采用以通过稀疏激活大型语言模型 (LLM) 中的专家来降低推理成本。尽管有此降低，但 MoE 中大量的专家仍然使其服务成本高昂。在本文中，我们研究了如何通过修剪 MoE 来解决这个问题。在修剪方法中，与结构化修剪相比，非结构化修剪已知可以针对给定的修剪比率实现最高性能，因为后者对稀疏化结构施加了约束。这是直观的，因为非结构化修剪的解空间包含了结构化修剪的解空间。然而，我们的反直觉发现表明，专家修剪（一种结构化修剪形式）实际上可以先于非结构化修剪，以优于仅非结构化修剪的性能。由于现有的专家修剪需要针对 n 个专家进行 O($\frac{k^n}{\sqrt{n}}$) 前向传递，因此无法扩展到最近的 MoE，我们提出了一种具有 O(1) 复杂度且优于更昂贵方法的可扩展替代方案。关键思想是利用专家之间的潜在结构（基于行为相似性），以便贪婪地决定是否修剪可以紧密捕捉联合修剪效果。我们的方法非常有效——对于 Snowflake Arctic（一个具有 128 个专家的 480B 大小的 MoE），我们的方法只需要一个 H100 和两个小时即可在生成性任务（例如 GSM8K）中实现几乎没有性能损失且具有 40% 的稀疏性，而最先进的非结构化修剪无法做到这一点。代码将公开提供。</paragraph>

##### **Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis**
2409.06209v1 by Xin Zhang, Deval Mehta, Yanan Hu, Chao Zhu, David Darby, Zhen Yu, Daniel Merlo, Melissa Gresle, Anneke Van Der Walt, Helmut Butzkueven, Zongyuan Ge

Survival analysis holds a crucial role across diverse disciplines, such as
economics, engineering and healthcare. It empowers researchers to analyze both
time-invariant and time-varying data, encompassing phenomena like customer
churn, material degradation and various medical outcomes. Given the complexity
and heterogeneity of such data, recent endeavors have demonstrated successful
integration of deep learning methodologies to address limitations in
conventional statistical approaches. However, current methods typically involve
cluttered probability distribution function (PDF), have lower sensitivity in
censoring prediction, only model static datasets, or only rely on recurrent
neural networks for dynamic modelling. In this paper, we propose a novel
survival regression method capable of producing high-quality unimodal PDFs
without any prior distribution assumption, by optimizing novel
Margin-Mean-Variance loss and leveraging the flexibility of Transformer to
handle both temporal and non-temporal data, coined UniSurv. Extensive
experiments on several datasets demonstrate that UniSurv places a significantly
higher emphasis on censoring compared to other methods.

摘要：存活分析在經濟、工程和醫療保健等不同學科中扮演著至關重要的角色。它讓研究人員能夠分析時不變和時變數據，包含客戶流失、材料降解和各種醫療結果等現象。鑑於此類數據的複雜性和異質性，最近的努力已證明成功整合深度學習方法以解決傳統統計方法的限制。然而，目前的方法通常涉及雜亂的機率分佈函數 (PDF)，在審查預測中具有較低的敏感性，僅對靜態數據集進行建模，或僅依賴遞迴神經網路進行動態建模。在本文中，我們提出了一種新穎的存活迴歸方法，能夠在沒有任何先驗分佈假設的情況下產生高品質的單峰 PDF，藉由最佳化新穎的邊際平均值變異損失，並利用 Transformer 的靈活性來處理時間和非時間數據，稱為 UniSurv。在幾個數據集上的廣泛實驗證明，與其他方法相比，UniSurv 對審查的重視程度顯著提高。

##### **SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs**
2409.06205v1 by Wanli Qian, Chenfeng Gao, Anup Sathya, Ryo Suzuki, Ken Nakagaki

This paper introduces text-to-shape-display, a novel approach to generating
dynamic shape changes in pin-based shape displays through natural language
commands. By leveraging large language models (LLMs) and AI-chaining, our
approach allows users to author shape-changing behaviors on demand through text
prompts without programming. We describe the foundational aspects necessary for
such a system, including the identification of key generative elements
(primitive, animation, and interaction) and design requirements to enhance user
interaction, based on formative exploration and iterative design processes.
Based on these insights, we develop SHAPE-IT, an LLM-based authoring tool for a
24 x 24 shape display, which translates the user's textual command into
executable code and allows for quick exploration through a web-based control
interface. We evaluate the effectiveness of SHAPE-IT in two ways: 1)
performance evaluation and 2) user evaluation (N= 10). The study conclusions
highlight the ability to facilitate rapid ideation of a wide range of
shape-changing behaviors with AI. However, the findings also expose
accuracy-related challenges and limitations, prompting further exploration into
refining the framework for leveraging AI to better suit the unique requirements
of shape-changing systems.

摘要：本文介紹文字轉形狀顯示，這是一種透過自然語言指令在基於釘狀的形狀顯示器上產生動態形狀變化的創新方法。透過利用大型語言模型 (LLM) 和 AI 鏈結，我們的做法讓使用者能夠透過文字提示按需撰寫形狀變換行為，而無需編寫程式。我們描述了這種系統所需的基礎面向，包括識別關鍵的生成元素（基本、動畫和互動）以及基於形成探索和反覆設計流程來增強使用者互動的設計需求。根據這些見解，我們開發了 SHAPE-IT，這是一種針對 24 x 24 形狀顯示器所設計、基於 LLM 的創作工具，它會將使用者的文字指令轉換為可執行的程式碼，並允許透過基於網路的控制介面進行快速探索。我們以兩種方式評估 SHAPE-IT 的有效性：1）效能評估和 2）使用者評估（N= 10）。研究結論強調了透過 AI 促進各種形狀變換行為快速發想的可能性。然而，研究結果也揭露了與準確性相關的挑戰和限制，促使進一步探索精進架構以更好地滿足形狀變換系統的獨特需求。

##### **NOVI : Chatbot System for University Novice with BERT and LLMs**
2409.06192v1 by Yoonji Nam, TaeWoong Seo, Gyeongcheol Shin, Sangji Lee, JaeEun Im

To mitigate the difficulties of university freshmen in adapting to university
life, we developed NOVI, a chatbot system based on GPT-4o. This system utilizes
post and comment data from SKKU 'Everytime', a university community site.
Developed using LangChain, NOVI's performance has been evaluated with a BLEU
score, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR
score. This approach is not only limited to help university freshmen but is
also expected to help various people adapting to new environments with
different data. This research explores the development and potential
application of new educational technology tools, contributing to easier social
adaptation for beginners and settling a foundation for future advancement in
LLM studies.

摘要：為了減輕大學新鮮人適應大學生活的困難，我們開發了基於 GPT-4o 的聊天機器人系統 NOVI。此系統利用了 SKKU「Everytime」大學社群網站的貼文和留言資料。NOVI 是使用 LangChain 開發的，其效能已使用 BLEU 分數、困惑度分數、ROUGE-1 分數、ROUGE-2 分數、ROUGE-L 分數和 METEOR 分數進行評估。此方法不僅限於幫助大學新鮮人，也預期可以協助各種人適應新環境，並使用不同的資料。本研究探討了新教育科技工具的開發和潛在應用，有助於初學者更輕鬆地適應社會，並為 LLM 研究的未來進展奠定基礎。

##### **Can Large Language Models Unlock Novel Scientific Research Ideas?**
2409.06185v1 by Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal

"An idea is nothing more nor less than a new combination of old elements"
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.

摘要：「一個想法不過就是舊元素的新組合而已」
(Young, J.W.)。大型語言模型 (LLM) 和公開的 ChatGPT 廣泛採用，標誌著人工智能 (AI) 整合到人們日常生活中的重要轉折點。本研究探討了 LLM 在根據研究論文資訊產生新研究想法方面的能力。我們對五個領域（例如化學、電腦、經濟、醫學和物理）中的 4 個 LLM 進行了徹底檢查。我們發現 Claude-2 和 GPT-4 產生的未來研究想法比 GPT-3.5 和 Gemini 更符合作者的觀點。我們還發現，Claude-2 產生的未來研究想法比 GPT-4、GPT-3.5 和 Gemini 1.0 更為多樣化。我們進一步對產生的未來研究想法的新穎性、相關性和可行性進行了人工評估。本調查提供了對 LLM 在產生想法中不斷演變的角色的見解，突出了其能力和限制。我們的研究有助於評估和利用語言模型來產生未來研究想法的持續努力。我們公開提供我們的數據集和程式碼。

##### **SQLucid: Grounding Natural Language Database Queries with Interactive Explanations**
2409.06178v1 by Yuan Tian, Jonathan K. Kummerfeld, Toby Jia-Jun Li, Tianyi Zhang

Though recent advances in machine learning have led to significant
improvements in natural language interfaces for databases, the accuracy and
reliability of these systems remain limited, especially in high-stakes domains.
This paper introduces SQLucid, a novel user interface that bridges the gap
between non-expert users and complex database querying processes. SQLucid
addresses existing limitations by integrating visual correspondence,
intermediate query results, and editable step-by-step SQL explanations in
natural language to facilitate user understanding and engagement. This unique
blend of features empowers users to understand and refine SQL queries easily
and precisely. Two user studies and one quantitative experiment were conducted
to validate SQLucid's effectiveness, showing significant improvement in task
completion accuracy and user confidence compared to existing interfaces. Our
code is available at https://github.com/magic-YuanTian/SQLucid.

摘要：儘管機器學習的最新進展已大幅提升資料庫的自然語言介面，但這些系統的準確性和可靠性仍然有限，尤其是在高風險領域。本文介紹 SQLucid，這是一種新穎的使用者介面，用以彌補非專家使用者與複雜資料庫查詢流程之間的差距。SQLucid 整合視覺對應、中間查詢結果，以及以自然語言編寫的可編輯分步式 SQL 說明，來解決現有限制，以促進使用者理解和參與。這種獨特的功能組合讓使用者能夠輕鬆且精確地理解和修改 SQL 查詢。進行了兩項使用者研究和一項量化實驗，以驗證 SQLucid 的有效性，結果顯示與現有介面相比，任務完成準確度和使用者信心都有顯著提升。我們的程式碼可在 https://github.com/magic-YuanTian/SQLucid 取得。

##### **Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks**
2409.06173v1 by Georgios Chochlakis, Niyantha Maruthu Pandiyan, Kristina Lerman, Shrikanth Narayanan

In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the
dominant technique for performing natural language tasks, as it does not
require updating the model parameters with gradient-based methods. ICL promises
to "adapt" the LLM to perform the present task at a competitive or
state-of-the-art level at a fraction of the computational cost. ICL can be
augmented by incorporating the reasoning process to arrive at the final label
explicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.
However, recent work has found that ICL relies mostly on the retrieval of task
priors and less so on "learning" to perform tasks, especially for complex
subjective domains like emotion and morality, where priors ossify posterior
predictions. In this work, we examine whether "enabling" reasoning also creates
the same behavior in LLMs, wherein the format of CoT retrieves reasoning priors
that remain relatively unchanged despite the evidence in the prompt. We find
that, surprisingly, CoT indeed suffers from the same posterior collapse as ICL
for larger language models. Code is avalaible at
https://github.com/gchochla/cot-priors.

摘要：大型語言模型 (LLM) 中的語境學習 (ICL) 已成為執行自然語言任務的主流技術，因為它不需要使用基於梯度的模型參數來更新。ICL 承諾以極低的計算成本「調整」LLM，以在競爭或最先進的層級執行當前任務。ICL 可以透過在提示中明確地納入推理過程來擴充，以得出最終標籤，這項技術稱為思考鏈 (CoT) 提示。然而，最近的研究發現，ICL 主要依賴於任務先驗的檢索，較少依賴於「學習」執行任務，特別是對於情緒和道德等複雜的主觀領域，其中先驗會僵化後驗預測。在這項研究中，我們探討「啟用」推理是否也會在 LLM 中產生相同的行為，其中 CoT 的格式會檢索推理先驗，儘管提示中的證據不同，但這些先驗仍然相對不變。我們發現，令人驚訝的是，對於較大的語言模型，CoT 確實會與 ICL 發生相同的後驗崩潰。程式碼可於 https://github.com/gchochla/cot-priors 取得。

##### **Deep Learning and Large Language Models for Audio and Text Analysis in Predicting Suicidal Acts in Chinese Psychological Support Hotlines**
2409.06164v1 by Yining Chen, Jianqiang Li, Changwei Song, Qing Zhao, Yongsheng Tong, Guanghui Fu

Suicide is a pressing global issue, demanding urgent and effective preventive
interventions. Among the various strategies in place, psychological support
hotlines had proved as a potent intervention method. Approximately two million
people in China attempt suicide annually, with many individuals making multiple
attempts. Prompt identification and intervention for high-risk individuals are
crucial to preventing tragedies. With the rapid advancement of artificial
intelligence (AI), especially the development of large-scale language models
(LLMs), new technological tools have been introduced to the field of mental
health. This study included 1284 subjects, and was designed to validate whether
deep learning models and LLMs, using audio and transcribed text from support
hotlines, can effectively predict suicide risk. We proposed a simple LLM-based
pipeline that first summarizes transcribed text from approximately one hour of
speech to extract key features, and then predict suicidial bahaviours in the
future. We compared our LLM-based method with the traditional manual scale
approach in a clinical setting and with five advanced deep learning models.
Surprisingly, the proposed simple LLM pipeline achieved strong performance on a
test set of 46 subjects, with an F1 score of 76\% when combined with manual
scale rating. This is 7\% higher than the best speech-based deep learning
models and represents a 27.82\% point improvement in F1 score compared to using
the manual scale apporach alone. Our study explores new applications of LLMs
and demonstrates their potential for future use in suicide prevention efforts.

摘要：自殺是一個迫切的全球問題，需要緊急且有效的預防性干預措施。在現有各種策略中，心理支持熱線已被證明是一種有效的干預方法。中國每年約有 200 萬人企圖自殺，其中許多人多次企圖。及時識別和干預高風險個體對於預防悲劇至關重要。隨著人工智能 (AI) 的快速發展，特別是大規模語言模型 (LLM) 的發展，新的技術工具已被引入心理健康領域。本研究納入了 1284 名受試者，旨在驗證使用來自支持熱線的音訊和轉錄文字的深度學習模型和 LLM 是否可以有效預測自殺風險。我們提出了一個基於 LLM 的簡單管道，它首先總結大約一小時語音的轉錄文字以提取關鍵特徵，然後預測未來的自殺行為。我們在臨床環境中將基於 LLM 的方法與傳統的手動量表方法以及五種先進的深度學習模型進行了比較。令人驚訝的是，所提出的簡單 LLM 管道在 46 名受試者的測試集中取得了強勁的表現，與手動量表評分相結合時的 F1 分數為 76%。這比最好的基於語音的深度學習模型高出 7%，並且與僅使用手動量表方法相比，F1 分數提高了 27.82%。我們的研究探索了 LLM 的新應用，並展示了它們在未來自殺預防工作中的潛力。

##### **Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings**
2409.06147v1 by Dong Han, Jihye Moon, Luís Roberto Mercado Díaz, Darren Chen, Devan Williams, Eric Y. Ding, Khanh-Van Tran, David D. McManus, Ki H. Chon

Most deep learning models of multiclass arrhythmia classification are tested
on fingertip photoplethysmographic (PPG) data, which has higher signal-to-noise
ratios compared to smartwatch-derived PPG, and the best reported sensitivity
value for premature atrial/ventricular contraction (PAC/PVC) detection is only
75%. To improve upon PAC/PVC detection sensitivity while maintaining high AF
detection, we use multi-modal data which incorporates 1D PPG, accelerometers,
and heart rate data as the inputs to a computationally efficient 1D
bi-directional Gated Recurrent Unit (1D-Bi-GRU) model to detect three
arrhythmia classes. We used motion-artifact prone smartwatch PPG data from the
NIH-funded Pulsewatch clinical trial. Our multimodal model tested on 72
subjects achieved an unprecedented 83% sensitivity for PAC/PVC detection while
maintaining a high accuracy of 97.31% for AF detection. These results
outperformed the best state-of-the-art model by 20.81% for PAC/PVC and 2.55%
for AF detection even while our model was computationally more efficient (14
times lighter and 2.7 faster).

摘要：大多數多類心律不整分類的深度學習模型都是在指尖光電容積描記法 (PPG) 資料上進行測試，與智慧手錶衍生的 PPG 相比，其訊號雜訊比更高，而對於期前心房/心室收縮 (PAC/PVC) 偵測所報告的最佳敏感度值僅為 75%。為了在維持高房顫偵測的同時提高 PAC/PVC 偵測敏感度，我們使用多模式資料，將 1D PPG、加速度計和心率資料作為計算效率高的 1D 雙向閘控遞迴單元 (1D-Bi-GRU) 模型的輸入，以偵測三類心律不整。我們使用了美國國家衛生研究院資助的 Pulsewatch 臨床試驗中的運動偽影易感智慧手錶 PPG 資料。我們在 72 名受試者身上測試的多模式模型，對於 PAC/PVC 偵測達到了前所未有的 83% 敏感度，同時對於房顫偵測維持了 97.31% 的高準確度。即使我們的模型在計算上更有效率（輕 14 倍，快 2.7 倍），這些結果仍比最先進的模型在 PAC/PVC 偵測上高出 20.81%，在房顫偵測上高出 2.55%。

##### **Draw an Audio: Leveraging Multi-Instruction for Video-to-Audio Synthesis**
2409.06135v1 by Qi Yang, Binjie Mao, Zili Wang, Xing Nie, Pengfei Gao, Ying Guo, Cheng Zhen, Pengfei Yan, Shiming Xiang

Foley is a term commonly used in filmmaking, referring to the addition of
daily sound effects to silent films or videos to enhance the auditory
experience. Video-to-Audio (V2A), as a particular type of automatic foley task,
presents inherent challenges related to audio-visual synchronization. These
challenges encompass maintaining the content consistency between the input
video and the generated audio, as well as the alignment of temporal and
loudness properties within the video. To address these issues, we construct a
controllable video-to-audio synthesis model, termed Draw an Audio, which
supports multiple input instructions through drawn masks and loudness signals.
To ensure content consistency between the synthesized audio and target video,
we introduce the Mask-Attention Module (MAM), which employs masked video
instruction to enable the model to focus on regions of interest. Additionally,
we implement the Time-Loudness Module (TLM), which uses an auxiliary loudness
signal to ensure the synthesis of sound that aligns with the video in both
loudness and temporal dimensions. Furthermore, we have extended a large-scale
V2A dataset, named VGGSound-Caption, by annotating caption prompts. Extensive
experiments on challenging benchmarks across two large-scale V2A datasets
verify Draw an Audio achieves the state-of-the-art. Project page:
https://yannqi.github.io/Draw-an-Audio/.

摘要：福利是電影製作中常用的術語，指的是在默片或影片中加入日常音效，以增強聽覺體驗。影片轉音訊 (V2A) 是一種特殊的自動福利任務，在音訊視覺同步方面存在固有的挑戰。這些挑戰包括在輸入影片和產生的音訊之間維持內容一致性，以及影片中時間和響度的屬性對齊。為了解決這些問題，我們構建了一個可控的影片轉音訊合成模型，稱為繪製音訊，它支援透過繪製遮罩和響度訊號提供多重輸入指令。為了確保合成音訊和目標影片之間的內容一致性，我們引入了遮罩注意模組 (MAM)，它採用遮罩影片指令，讓模型能夠專注於感興趣的區域。此外，我們實作了時間響度模組 (TLM)，它使用輔助響度訊號來確保合成音訊在響度和時間維度上與影片對齊。此外，我們透過註解字幕提示，擴充了一個名為 VGGSound-Caption 的大型 V2A 資料集。在兩個大型 V2A 資料集中的具有挑戰性的基準上進行的廣泛實驗驗證，繪製音訊達到了最先進的技術水準。專案頁面：https://yannqi.github.io/Draw-an-Audio/。

##### **Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review**
2409.06131v1 by Neha Prakriya, Jui-Nan Yen, Cho-Jui Hsieh, Jason Cong

Large Language Model (LLM) pretraining traditionally relies on autoregressive
language modeling on randomly sampled data blocks from web-scale datasets. We
take inspiration from human learning techniques like spaced repetition to
hypothesize that random data sampling for LLMs leads to high training cost and
low quality models which tend to forget data. In order to effectively commit
web-scale information to long-term memory, we propose the LFR (Learn, Focus,
and Review) pedagogy, a new dynamic training paradigm which focuses and
repeatedly reviews complex data blocks at systematic intervals based on the
model's learning pace and progress. LFR records the model perplexities for
different data blocks and frequently revisits blocks with higher perplexity
which are more likely to be forgotten. We pretrain the GPT-2 models (124M -
1.5B) from scratch on the OpenWebText dataset using LFR. We test on downstream
tasks from the language modeling, question answering, translation, and problem
solving domains to achieve consistently lower perplexity and higher accuracy
than the baseline OpenAI models, while obtaining a 20x pretraining speed-up.

摘要：大型語言模型 (LLM) 預訓練傳統上依賴於隨機取樣資料區塊的自動迴歸語言模型化，這些資料區塊來自網路規模的資料集。我們從人類學習技巧（例如間隔重複）中獲得靈感，假設 LLM 的隨機資料取樣會導致高訓練成本和低品質模型，而這些模型往往會遺忘資料。為了有效地將網路規模的資訊提交至長期記憶體，我們提出 LFR（學習、專注和複習）教學法，這是一種新的動態訓練範例，會根據模型的學習步調和進度，在系統性的間隔中專注於複雜的資料區塊並反覆複習。LFR 會記錄模型對於不同資料區塊的困惑度，並頻繁地重新檢視困惑度較高的區塊，因為這些區塊較容易被遺忘。我們從頭開始使用 LFR 在 OpenWebText 資料集上預訓練 GPT-2 模型（124M - 1.5B）。我們在語言模型化、問題解答、翻譯和問題解決領域的下游任務上進行測試，與基準 OpenAI 模型相比，我們始終獲得較低的困惑度和較高的準確度，同時獲得 20 倍的預訓練加速。

##### **On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective**
2409.06130v1 by Aoting Hu, Yanzhi Chen, Renjie Xie, Adrian Weller

Safeguarding the intellectual property of machine learning models has emerged
as a pressing concern in AI security. Model watermarking is a powerful
technique for protecting ownership of machine learning models, yet its
reliability has been recently challenged by recent watermark removal attacks.
In this work, we investigate why existing watermark embedding techniques
particularly those based on backdooring are vulnerable. Through an
information-theoretic analysis, we show that the resilience of watermarking
against erasure attacks hinges on the choice of trigger-set samples, where
current uses of out-distribution trigger-set are inherently vulnerable to
white-box adversaries. Based on this discovery, we propose a novel model
watermarking scheme, In-distribution Watermark Embedding (IWE), to overcome the
limitations of existing method. To further minimise the gap to clean models, we
analyze the role of logits as watermark information carriers and propose a new
approach to better conceal watermark information within the logits. Experiments
on real-world datasets including CIFAR-100 and Caltech-101 demonstrate that our
method robustly defends against various adversaries with negligible accuracy
loss (< 0.1%).

摘要：機器學習模型的智慧財產權保障已成為 AI 安全中迫切的關注事項。模型浮水印是一種強大的技術，用於保護機器學習模型的所有權，但最近的浮水印移除攻擊對其可靠性提出了挑戰。在這項工作中，我們探討了現有的浮水印嵌入技術，特別是那些基於後門的技術，為何容易受到攻擊。透過資訊理論分析，我們表明浮水印對擦除攻擊的復原力取決於觸發器組範例的選擇，其中目前對分布外觸發器組的使用本質上容易受到白盒對手的攻擊。基於這一發現，我們提出了一種新穎的模型浮水印方案，即分佈內浮水印嵌入 (IWE)，以克服現有方法的限制。為了進一步縮小與乾淨模型的差距，我們分析了邏輯作為浮水印資訊載體的作用，並提出了一種新的方法，以便在邏輯中更好地隱藏浮水印資訊。在包括 CIFAR-100 和 Caltech-101 在內的真實世界資料集上的實驗表明，我們的模型可以穩健地抵禦各種對手，而準確度損失可以忽略不計 (< 0.1%)。

##### **Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science**
2409.06122v1 by E. Wes Bethel, Vianna Cramer, Alexander del Rio, Lothar Narins, Chris Pestano, Satvik Verma, Erick Arias, Nicola Bertelli, Talita Perciano, Syun'ichi Shiraiwa, Álvaro Sánchez Villar, Greg Wallace, John C. Wright

This work presents a detailed case study on using Generative AI (GenAI) to
develop AI surrogates for simulation models in fusion energy research. The
scope includes the methodology, implementation, and results of using GenAI to
assist in model development and optimization, comparing these results with
previous manually developed models.

摘要：這項工作提供了一個詳細的案例研究，探討使用生成式 AI (GenAI) 來為融合能源研究中的模擬模型開發 AI 代理。範圍包括使用 GenAI 協助模型開發和最佳化的方法、實施和結果，並將這些結果與先前手動開發的模型進行比較。

##### **PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for Safe Navigation Under Perception Uncertainty**
2409.06111v1 by Sara Pohland, Claire Tomlin

Perception-based navigation systems are useful for unmanned ground vehicle
(UGV) navigation in complex terrains, where traditional depth-based navigation
schemes are insufficient. However, these data-driven methods are highly
dependent on their training data and can fail in surprising and dramatic ways
with little warning. To ensure the safety of the vehicle and the surrounding
environment, it is imperative that the navigation system is able to recognize
the predictive uncertainty of the perception model and respond safely and
effectively in the face of uncertainty. In an effort to enable safe navigation
under perception uncertainty, we develop a probabilistic and
reconstruction-based competency estimation (PaRCE) method to estimate the
model's level of familiarity with an input image as a whole and with specific
regions in the image. We find that the overall competency score can correctly
predict correctly classified, misclassified, and out-of-distribution (OOD)
samples. We also confirm that the regional competency maps can accurately
distinguish between familiar and unfamiliar regions across images. We then use
this competency information to develop a planning and control scheme that
enables effective navigation while maintaining a low probability of error. We
find that the competency-aware scheme greatly reduces the number of collisions
with unfamiliar obstacles, compared to a baseline controller with no competency
awareness. Furthermore, the regional competency information is very valuable in
enabling efficient navigation.

摘要：基於感知的導航系統對於無人地面載具 (UGV) 在複雜地形中進行導航很有用，在這些地形中，傳統的基於深度的導航方案是不夠的。然而，這些資料驅動的方法高度依賴於其訓練資料，並且可能會以令人驚訝且戲劇性的方式在幾乎沒有警告的情況下失敗。為了確保車輛和周圍環境的安全，導航系統必須能夠識別感知模型的預測不確定性，並在不確定性面前做出安全有效的回應。為了在感知不確定性下實現安全導航，我們開發了一種基於概率和重建的勝任力估計 (PaRCE) 方法，以估計模型對輸入影像整體和影像中特定區域的熟悉程度。我們發現，整體勝任力評分可以正確預測正確分類、分類錯誤和分佈外 (OOD) 樣本。我們還確認，區域勝任力圖可以準確區分影像中的熟悉和不熟悉區域。然後，我們使用此勝任力資訊來開發一種規劃和控制方案，在保持低錯誤機率的同時，能夠有效導航。我們發現，與沒有勝任力感知的基準控制器相比，具備勝任力感知的方案大幅減少了與不熟悉障礙物的碰撞次數。此外，區域勝任力資訊對於實現有效導航非常有價值。

##### **Doppelgänger's Watch: A Split Objective Approach to Large Language Models**
2409.06107v1 by Shervin Ghasemlou, Ashish Katiyar, Aparajita Saraf, Seungwhan Moon, Mangesh Pujari, Pinar Donmez, Babak Damavandi, Anuj Kumar

In this paper, we investigate the problem of "generation supervision" in
large language models, and present a novel bicameral architecture to separate
supervision signals from their core capability, helpfulness. Doppelg\"anger, a
new module parallel to the underlying language model, supervises the generation
of each token, and learns to concurrently predict the supervision score(s) of
the sequences up to and including each token. In this work, we present the
theoretical findings, and leave the report on experimental results to a
forthcoming publication.

摘要：在本文中，我們探討大型語言模型中的「生成監督」問題，並提出了一種新穎的兩院制架構，以將監督訊號從其核心能力（樂於助人）中分離出來。Doppelgänger 是一個與底層語言模型並行的全新模組，用來監督每個符號的生成，並學習同時預測每個符號（包含符號在內）之前序列的監督分數。在這項工作中，我們提出了理論發現，並將實驗結果報告留待後續出版。

##### **ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog**
2409.06097v1 by Yujian Gan, Changling Li, Jinxia Xie, Luou Wen, Matthew Purver, Massimo Poesio

We introduce ClarQ-LLM, an evaluation framework consisting of bilingual
English-Chinese conversation tasks, conversational agents and evaluation
metrics, designed to serve as a strong benchmark for assessing agents' ability
to ask clarification questions in task-oriented dialogues. The benchmark
includes 31 different task types, each with 10 unique dialogue scenarios
between information seeker and provider agents. The scenarios require the
seeker to ask questions to resolve uncertainty and gather necessary information
to complete tasks. Unlike traditional benchmarks that evaluate agents based on
fixed dialogue content, ClarQ-LLM includes a provider conversational agent to
replicate the original human provider in the benchmark. This allows both
current and future seeker agents to test their ability to complete information
gathering tasks through dialogue by directly interacting with our provider
agent. In tests, LLAMA3.1 405B seeker agent managed a maximum success rate of
only 60.05\%, showing that ClarQ-LLM presents a strong challenge for future
research.

摘要：我們推出 ClarQ-LLM，這是一個評估框架，由雙語英語-中文對話任務、對話代理和評估指標組成，旨在作為評估代理在任務導向對話中提出澄清問題的能力的強大基準。該基準包含 31 種不同的任務類型，每個任務類型都包含信息尋求者和提供者代理之間的 10 個獨特對話場景。這些場景要求尋求者提出問題以解決不確定性並收集必要的資訊以完成任務。與根據固定對話內容評估代理的傳統基準不同，ClarQ-LLM 包含一個提供者對話代理，以複製基準中的原始人類提供者。這允許當前和未來的尋求者代理透過直接與我們的提供者代理互動來測試他們完成資訊收集任務的能力。在測試中，LLAMA3.1 405B 尋求者代理僅管理 60.05% 的最高成功率，這表明 ClarQ-LLM 對未來的研究提出了嚴峻的挑戰。

##### **Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer**
2409.06096v1 by Michele Mancusi, Yurii Halychansky, Kin Wai Cheuk, Chieh-Hsin Lai, Stefan Uhlich, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Yuhki Mitsufuji

Music timbre transfer is a challenging task that involves modifying the
timbral characteristics of an audio signal while preserving its melodic
structure. In this paper, we propose a novel method based on dual diffusion
bridges, trained using the CocoChorales Dataset, which consists of unpaired
monophonic single-instrument audio data. Each diffusion model is trained on a
specific instrument with a Gaussian prior. During inference, a model is
designated as the source model to map the input audio to its corresponding
Gaussian prior, and another model is designated as the target model to
reconstruct the target audio from this Gaussian prior, thereby facilitating
timbre transfer. We compare our approach against existing unsupervised timbre
transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental
results demonstrate that our method achieves both better Fr\'echet Audio
Distance (FAD) and melody preservation, as reflected by lower pitch distances
(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise
level from the Gaussian prior, $\sigma$, can be adjusted to control the degree
of melody preservation and amount of timbre transferred.

摘要：音樂音色轉移是一項具有挑戰性的任務，它涉及修改音訊訊號的音色特徵，同時保留其旋律結構。在本文中，我們提出了一種基於雙擴散橋接的新方法，使用 CocoChorales 資料集進行訓練，該資料集包含未配對的單音單樂器音訊資料。每個擴散模型都使用具有高斯先驗的特定樂器進行訓練。在推理過程中，一個模型被指定為源模型，將輸入音訊對應到其對應的高斯先驗，另一個模型被指定為目標模型，從這個高斯先驗重建目標音訊，從而促進音色轉移。我們將我們的模型與現有的無監督音色轉移模型（例如 VAEGAN 和高斯流橋接 (GFB)）進行比較。實驗結果表明，與 VAEGAN 和 GFB 相比，我們的模型在 Fr\'echet 音訊距離 (FAD) 和旋律保留方面都取得了更好的效果，這反映在較低的音高距離 (DPD) 上。此外，我們發現來自高斯先驗的噪聲級別 $\sigma$ 可以調整，以控制旋律保留的程度和轉移的音色數量。

##### **Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**
2409.06091v1 by Dongyue Li, Aneesh Sharma, Hongyang R. Zhang

Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a "base" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.

摘要：多任務學習是一種廣泛使用的範例，用於在不同的任務上訓練模型，其應用範圍從圖神經網路到語言模型微調。由於任務可能會相互干擾，因此建模它們關係的一個關鍵概念是任務親和性。這包括成對任務親和性，在成對任務之間計算，以及高階親和性，在任務子集之間計算。天真地計算其中任何一個都需要重複訓練來自各種任務組合的資料，這在計算上很密集。我們提出了一種新的演算法 Grad-TAG，它可以在沒有重複訓練的情況下估計任務親和性。
Grad-TAG 的關鍵思想是為所有任務訓練一個「基礎」模型，然後使用線性化技術來估計模型對特定任務組合的損失。線性化通過計算損失的基於梯度的近似值來工作，使用梯度的低維投影作為特徵，在邏輯迴歸中預測任務組合的標籤。我們證明了當基於梯度的近似值準確時，線性化模型可以證明地近似損失，並且在幾個大型模型上經驗驗證了這一點。然後，給定估計的任務親和性，我們設計了一個半定程式，通過最大化叢集的平均密度來對類似的任務進行叢集。
我們評估了 Grad-TAG 在七個資料集上的效能，包括圖形上的多標籤分類，以及語言模型的指令微調。我們的任務親和性估計與真實親和性距離在 2.7% 以內，同時只需要 3% 的 FLOP 進行完整訓練。在我們最大的圖形（有 2100 萬條邊和 500 個標籤任務）上，我們的演算法提供的估計與真實親和性距離在 5% 以內，只使用 112 個 GPU 小時。我們的結果表明，與現有方法相比，Grad-TAG 在效能和執行時間權衡方面取得了優異的表現。

##### **MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization**
2409.06077v1 by Faezeh Faez, Raika Karimi, Yingxue Zhang, Xing Li, Lei Chen, Mingxuan Yuan, Mahdi Biparva

Electronic Design Automation (EDA) is essential for IC design and has
recently benefited from AI-based techniques to improve efficiency. Logic
synthesis, a key EDA stage, transforms high-level hardware descriptions into
optimized netlists. Recent research has employed machine learning to predict
Quality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis
recipes. However, the severe scarcity of data due to a very limited number of
available AIGs results in overfitting, significantly hindering performance.
Additionally, the complexity and large number of nodes in AIGs make plain GNNs
less effective for learning expressive graph-level representations. To tackle
these challenges, we propose MTLSO - a Multi-Task Learning approach for Logic
Synthesis Optimization. On one hand, it maximizes the use of limited data by
training the model across different tasks. This includes introducing an
auxiliary task of binary multi-label graph classification alongside the primary
regression task, allowing the model to benefit from diverse supervision
sources. On the other hand, we employ a hierarchical graph representation
learning strategy to improve the model's capacity for learning expressive
graph-level representations of large AIGs, surpassing traditional plain GNNs.
Extensive experiments across multiple datasets and against state-of-the-art
baselines demonstrate the superiority of our method, achieving an average
performance gain of 8.22\% for delay and 5.95\% for area.

摘要：電子設計自動化 (EDA) 對 IC 設計至關重要，最近受益於基於 AI 的技術來提高效率。邏輯綜合是 EDA 的關鍵階段，它將高級硬體描述轉換為最佳化的網路表。最近的研究採用機器學習來預測與反相器圖 (AIG) 和綜合配方配對的結果品質 (QoR)。然而，由於可用 AIG 數量極少，導致資料嚴重匱乏，造成過度擬合，嚴重阻礙效能。此外，AIG 中的複雜性和大量節點使純粹的 GNN 在學習表達式圖形級別表示時效率較低。為了應對這些挑戰，我們提出 MTLSO - 一種邏輯綜合最佳化的多任務學習方法。一方面，它透過在不同任務中訓練模型來最大化使用有限的資料。這包括在主要回歸任務的同時引入二元多標籤圖分類的輔助任務，讓模型受益於多樣化的監督來源。另一方面，我們採用階層式圖形表示學習策略來提高模型學習大型 AIG 的表達式圖形級別表示的能力，超越傳統的純粹 GNN。跨多個資料集以及與最先進的基準進行的廣泛實驗證明了我們方法的優越性，在延遲方面獲得了 8.22% 的平均效能提升，在面積方面獲得了 5.95% 的提升。

##### **DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection**
2409.06072v1 by Joymallya Chakraborty, Wei Xia, Anirban Majumder, Dan Ma, Walid Chaabene, Naveed Janvekar

Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.

摘要：大型語言模型 (LLM) 已在自然語言處理任務中展現出非凡的能力。然而，它們在高風險領域中的實際應用，例如詐騙和濫用偵測，仍然是一個需要進一步探索的領域。現有的應用程式通常狹隘地專注於特定任務，例如毒性或仇恨言論偵測。在本文中，我們提出一個全面的基準測試套件，旨在評估 LLM 在各種真實世界場景中識別和減輕欺詐和濫用語言的效能。我們的基準涵蓋了一組不同的任務，包括偵測垃圾郵件、仇恨言論、厭惡女性的語言等等。我們評估了幾種最先進的 LLM，包括來自 Anthropic、Mistral AI 和 AI21 家族的模型，以全面評估它們在這個關鍵領域的能力。結果表明，儘管 LLM 在個別的詐騙和濫用偵測任務中表現出熟練的基準效能，但它們的效能因任務而異，特別是在需要細緻務實推理的任務中表現不佳，例如識別各種形式的厭惡女性的語言。這些發現對 LLM 在高風險應用中的負責任開發和部署具有重要的意義。我們的基準測試套件可以作為研究人員和實務工作者的工具，用於系統性地評估 LLM 的多任務詐騙偵測，並推動建立更強大、更值得信賴且在道德上更一致的詐騙和濫用偵測系統。

##### **Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research**
2409.06069v1 by Osama Zafar, Rosemarie Santa Gonzalez, Gabriel Wilkins, Alfonso Morales, Erman Ayday

Digital agriculture leverages technology to enhance crop yield, disease
resilience, and soil health, playing a critical role in agricultural research.
However, it raises privacy concerns such as adverse pricing, price
discrimination, higher insurance costs, and manipulation of resources,
deterring farm operators from sharing data due to potential misuse. This study
introduces a privacy-preserving framework that addresses these risks while
allowing secure data sharing for digital agriculture. Our framework enables
comprehensive data analysis while protecting privacy. It allows stakeholders to
harness research-driven policies that link public and private datasets. The
proposed algorithm achieves this by: (1) identifying similar farmers based on
private datasets, (2) providing aggregate information like time and location,
(3) determining trends in price and product availability, and (4) correlating
trends with public policy data, such as food insecurity statistics. We validate
the framework with real-world Farmer's Market datasets, demonstrating its
efficacy through machine learning models trained on linked privacy-preserved
data. The results support policymakers and researchers in addressing food
insecurity and pricing issues. This work significantly contributes to digital
agriculture by providing a secure method for integrating and analyzing data,
driving advancements in agricultural technology and development.

摘要：數位農業利用科技來提升作物產量、疾病復原力和土壤健康，在農業研究中扮演關鍵角色。
然而，它引發了隱私問題，例如不利定價、價格歧視、較高的保險成本和資源操縱，由於潛在的誤用，阻止了農場經營者分享資料。本研究提出一個保護隱私的架構，它能解決這些風險，同時允許安全的資料共享以進行數位農業。我們的架構能進行全面的資料分析，同時保護隱私。它允許利害關係人利用研究驅動的政策，連結公共和私人資料集。所提出的演算法透過以下方式達成此目標：(1) 根據私人資料集識別類似的農民，(2) 提供總和資訊，例如時間和地點，(3) 確定價格和產品可用性的趨勢，以及 (4) 將趨勢與公共政策資料相關聯，例如糧食不安全統計。我們使用真實世界的農夫市集資料集驗證了這個架構，透過在連結的保護隱私資料上訓練的機器學習模型，證明了它的效力。這些結果支持政策制定者和研究人員解決糧食不安全和定價問題。這項工作透過提供一個整合和分析資料的安全方法，大幅貢獻了數位農業，推動農業技術和發展的進步。

##### **MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data**
2409.06067v1 by Jianyi Zhang, Hao Frank Yang, Ang Li, Xin Guo, Pu Wang, Haiming Wang, Yiran Chen, Hai Li

Previous studies on federated learning (FL) often encounter performance
degradation due to data heterogeneity among different clients. In light of the
recent advances in multimodal large language models (MLLMs), such as GPT-4v and
LLaVA, which demonstrate their exceptional proficiency in multimodal tasks,
such as image captioning and multimodal question answering. We introduce a
novel federated learning framework, named Multimodal Large Language Model
Assisted Federated Learning (MLLM-FL), which which employs powerful MLLMs at
the server end to address the heterogeneous and long-tailed challenges. Owing
to the advanced cross-modality representation capabilities and the extensive
open-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing
the extensive, yet previously underexploited, open-source data accessible from
websites and powerful server-side computational resources. Hence, the MLLM-FL
not only enhances the performance but also avoids increasing the risk of
privacy leakage and the computational burden on local devices, distinguishing
it from prior methodologies. Our framework has three key stages. Initially,
prior to local training on local datasets of clients, we conduct global
visual-text pretraining of the model. This pretraining is facilitated by
utilizing the extensive open-source data available online, with the assistance
of multimodal large language models. Subsequently, the pretrained model is
distributed among various clients for local training. Finally, once the locally
trained models are transmitted back to the server, a global alignment is
carried out under the supervision of MLLMs to further enhance the performance.
Experimental evaluations on established benchmarks, show that our framework
delivers promising performance in the typical scenarios with data heterogeneity
and long-tail distribution across different clients in FL.

摘要：先前的聯合學習 (FL) 研究通常會遇到效能降低的問題，原因在於不同用戶端之間的資料異質性。有鑑於多模態大型語言模型 (MLLM)（例如 GPT-4v 和 LLaVA）的最新進展，這些模型在多模態任務（例如影像標題和多模態問答）中展現出卓越的熟練度。我們引進一個名為多模態大型語言模型輔助聯合學習 (MLLM-FL) 的創新聯合學習架構，它在伺服器端採用強大的 MLLM 來應對異質性和長尾挑戰。由於 MLLM 具備先進的跨模態表徵能力和廣泛的開放式詞彙先備知識，我們的架構擅長利用從網站和強大的伺服器端運算資源取得的廣泛但先前未充分利用的開放原始碼資料。因此，MLLM-FL 不僅能提升效能，還能避免增加隱私外洩的風險和本地裝置的運算負擔，這讓它有別於先前的研究方法。我們的架構有三個關鍵階段。最初，在用戶端的本地資料集進行本地訓練之前，我們會執行模型的全球視覺文字預訓練。這個預訓練會利用線上取得的廣泛開放原始碼資料，並在多模態大型語言模型的協助下進行。隨後，預訓練模型會分發給各個用戶端進行本地訓練。最後，當本地訓練的模型傳回伺服器後，會在 MLLM 的監督下執行全球比對，以進一步提升效能。在既定的基準上的實驗評估顯示，我們的架構在 FL 中不同用戶端具有資料異質性和長尾分佈的典型場景中，提供了令人滿意的效能。

##### **Identifying the sources of ideological bias in GPT models through linguistic variation in output**
2409.06043v1 by Christina Walker, Joan C. Timoneda

Extant work shows that generative AI models such as GPT-3.5 and 4 perpetuate
social stereotypes and biases. One concerning but less explored source of bias
is ideology. Do GPT models take ideological stances on politically sensitive
topics? In this article, we provide an original approach to identifying
ideological bias in generative models, showing that bias can stem from both the
training data and the filtering algorithm. We leverage linguistic variation in
countries with contrasting political attitudes to evaluate bias in average GPT
responses to sensitive political topics in those languages. First, we find that
GPT output is more conservative in languages that map well onto conservative
societies (i.e., Polish), and more liberal in languages used uniquely in
liberal societies (i.e., Swedish). This result provides strong evidence of
training data bias in GPT models. Second, differences across languages observed
in GPT-3.5 persist in GPT-4, even though GPT-4 is significantly more liberal
due to OpenAI's filtering policy. Our main takeaway is that generative model
training must focus on high-quality, curated datasets to reduce bias, even if
it entails a compromise in training data size. Filtering responses after
training only introduces new biases and does not remove the underlying training
biases.

摘要：現有的研究顯示，生成式 AI 模型（例如 GPT-3.5 和 4）會延續社會刻板印象和偏見。意識形態是一個令人擔憂但較少探討的偏見來源。GPT 模型是否對政治敏感議題採取意識形態立場？在本文中，我們提供一種辨識生成式模型中意識形態偏見的原創方法，並說明偏見可能來自訓練資料和篩選演算法。我們利用政治態度截然不同的國家中的語言差異，來評估 GPT 對這些語言中敏感政治議題的平均回應中的偏見。首先，我們發現 GPT 輸出的保守程度，在對應於保守社會的語言（例如波蘭語）中較高，而在僅用於自由社會的語言（例如瑞典語）中較低。此結果提供了 GPT 模型中訓練資料偏見的有力證據。其次，GPT-3.5 中觀察到的跨語言差異在 GPT-4 中仍然存在，儘管 GPT-4 由於 OpenAI 的篩選政策而顯著地更為自由。我們的重點是，即使這會犧牲訓練資料的大小，生成式模型訓練也必須專注於高品質、經過整理的資料集，以減少偏見。訓練後篩選回應只會引入新的偏見，並不會消除潛在的訓練偏見。

##### **Investigating Causal Cues: Strengthening Spoofed Audio Detection with Human-Discernible Linguistic Features**
2409.06033v1 by Zahra Khanjani, Tolulope Ale, Jianwu Wang, Lavon Davis, Christine Mallinson, Vandana P. Janeja

Several types of spoofed audio, such as mimicry, replay attacks, and
deepfakes, have created societal challenges to information integrity. Recently,
researchers have worked with sociolinguistics experts to label spoofed audio
samples with Expert Defined Linguistic Features (EDLFs) that can be discerned
by the human ear: pitch, pause, word-initial and word-final release bursts of
consonant stops, audible intake or outtake of breath, and overall audio
quality. It is established that there is an improvement in several deepfake
detection algorithms when they augmented the traditional and common features of
audio data with these EDLFs. In this paper, using a hybrid dataset comprised of
multiple types of spoofed audio augmented with sociolinguistic annotations, we
investigate causal discovery and inferences between the discernible linguistic
features and the label in the audio clips, comparing the findings of the causal
models with the expert ground truth validation labeling process. Our findings
suggest that the causal models indicate the utility of incorporating linguistic
features to help discern spoofed audio, as well as the overall need and
opportunity to incorporate human knowledge into models and techniques for
strengthening AI models. The causal discovery and inference can be used as a
foundation of training humans to discern spoofed audio as well as automating
EDLFs labeling for the purpose of performance improvement of the common
AI-based spoofed audio detectors.

摘要：<paragraph>多種類型的偽造音訊，例如模仿、重播攻擊和深度造假，對資訊的完整性造成了社會挑戰。最近，研究人員與社會語言學專家合作，使用人類耳朵可以辨別的專家定義語言特徵 (EDLF) 標註偽造音訊樣本：音高、停頓、輔音停頓的字首和字尾釋放爆破音、可聽見的吸氣或呼氣，以及整體音訊品質。已確立在使用這些 EDLF 擴充傳統且常見的音訊資料特徵時，多種深度造假偵測演算法會有改善。在本文中，使用包含多種類型偽造音訊且擴充社會語言學註解的混合資料集，我們探討可辨別的語言特徵與音訊片段中的標籤之間的因果發現和推論，並將因果模型的發現與專家實地驗證標籤處理程序進行比較。我們的發現表明，因果模型顯示了納入語言特徵以幫助辨別偽造音訊的效用，以及將人類知識納入模型和技術以強化 AI 模型的整體需求和機會。因果發現和推論可用作訓練人類辨別偽造音訊的基礎，以及自動化 EDLF 標籤處理以改善常見的 AI 基於偽造音訊偵測器的效能。</paragraph>

##### **SongCreator: Lyrics-based Universal Song Generation**
2409.06029v1 by Shun Lei, Yixuan Zhou, Boshi Tang, Max W. Y. Lam, Feng Liu, Hangyu Liu, Jingcheng Wu, Shiyin Kang, Zhiyong Wu, Helen Meng

Music is an integral part of human culture, embodying human intelligence and
creativity, of which songs compose an essential part. While various aspects of
song generation have been explored by previous works, such as singing voice,
vocal composition and instrumental arrangement, etc., generating songs with
both vocals and accompaniment given lyrics remains a significant challenge,
hindering the application of music generation models in the real world. In this
light, we propose SongCreator, a song-generation system designed to tackle this
challenge. The model features two novel designs: a meticulously designed
dual-sequence language model (DSLM) to capture the information of vocals and
accompaniment for song generation, and an additional attention mask strategy
for DSLM, which allows our model to understand, generate and edit songs, making
it suitable for various song-related generation tasks. Extensive experiments
demonstrate the effectiveness of SongCreator by achieving state-of-the-art or
competitive performances on all eight tasks. Notably, it surpasses previous
works by a large margin in lyrics-to-song and lyrics-to-vocals. Additionally,
it is able to independently control the acoustic conditions of the vocals and
accompaniment in the generated song through different prompts, exhibiting its
potential applicability. Our samples are available at
https://songcreator.github.io/.

摘要：音樂是人類文化中不可或缺的一部分，體現了人類的智慧和創造力，其中歌曲構成了一個重要的部分。雖然以前的作品已經探索了歌曲生成的各個方面，例如歌唱聲音、人聲作曲和器樂編排等，但給定歌詞生成人聲和伴奏的歌曲仍然是一個重大的挑戰，阻礙了音樂生成模型在現實世界中的應用。有鑑於此，我們提出了 SongCreator，一個旨在應對這一挑戰的歌曲生成系統。該模型具有兩個新穎的設計：一個精心設計的雙序列語言模型 (DSLM) 來擷取歌曲生成的人聲和伴奏資訊，以及一個額外的 DSLM 注意力遮罩策略，它允許我們的模型理解、生成和編輯歌曲，使其適用於各種與歌曲相關的生成任務。廣泛的實驗通過在所有八項任務中實現最先進或有競爭力的表現，證明了 SongCreator 的有效性。值得注意的是，它在歌詞轉歌曲和歌詞轉人聲方面比以前的作品有了很大的進步。此外，它能夠通過不同的提示獨立控制生成歌曲中人聲和伴奏的聲學條件，展示了其潛在的適用性。我們的範例可以在 https://songcreator.github.io/ 取得。

##### **Deep Generative Model for Mechanical System Configuration Design**
2409.06016v1 by Yasaman Etesam, Hyunmin Cheong, Mohammadmehdi Ataei, Pradeep Kumar Jayaraman

Generative AI has made remarkable progress in addressing various design
challenges. One prominent area where generative AI could bring significant
value is in engineering design. In particular, selecting an optimal set of
components and their interfaces to create a mechanical system that meets design
requirements is one of the most challenging and time-consuming tasks for
engineers. This configuration design task is inherently challenging due to its
categorical nature, multiple design requirements a solution must satisfy, and
the reliance on physics simulations for evaluating potential solutions. These
characteristics entail solving a combinatorial optimization problem with
multiple constraints involving black-box functions. To address this challenge,
we propose a deep generative model to predict the optimal combination of
components and interfaces for a given design problem. To demonstrate our
approach, we solve a gear train synthesis problem by first creating a synthetic
dataset using a grammar, a parts catalogue, and a physics simulator. We then
train a Transformer using this dataset, named GearFormer, which can not only
generate quality solutions on its own, but also augment search methods such as
an evolutionary algorithm and Monte Carlo tree search. We show that GearFormer
outperforms such search methods on their own in terms of satisfying the
specified design requirements with orders of magnitude faster generation time.
Additionally, we showcase the benefit of hybrid methods that leverage both
GearFormer and search methods, which further improve the quality of the
solutions.

摘要：生成式 AI 在解決各種設計挑戰方面取得了顯著進展。生成式 AI 可能帶來顯著價值的一個顯著領域是工程設計。特別是，選擇一組最佳的組件及其介面，以建立符合設計要求的機械系統，是工程師最具挑戰性和最耗時的工作之一。此組態設計任務本質上具有挑戰性，因為其分類性質、解決方案必須滿足的各種設計要求，以及依賴物理模擬來評估潛在解決方案。這些特性需要解決一個組合最佳化問題，其中包含涉及黑盒函數的各種約束。為了應對這一挑戰，我們提出了一個深度生成模型，以預測特定設計問題的組件和介面的最佳組合。為了展示我們的做法，我們首先使用語法、零件目錄和物理模擬器建立一個合成資料集，來解決齒輪組合成問題。然後，我們使用此資料集訓練一個 Transformer，命名為 GearFormer，它不僅可以自行產生高品質的解決方案，還可以擴充搜尋方法，例如演化演算法和蒙地卡羅樹搜尋。我們展示了 GearFormer 在滿足指定設計要求方面優於這些搜尋方法，而且生成時間快了幾個數量級。此外，我們展示了同時利用 GearFormer 和搜尋方法的混合方法的優點，這進一步提高了解決方案的品質。

##### **Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings**
2409.06013v1 by Leanne Nortje, Dan Oneata, Herman Kamper

Given an image query, visually prompted keyword localisation (VPKL) aims to
find occurrences of the depicted word in a speech collection. This can be
useful when transcriptions are not available for a low-resource language (e.g.
if it is unwritten). Previous work showed that VPKL can be performed with a
visually grounded speech model trained on paired images and unlabelled speech.
But all experiments were done on English. Moreover, transcriptions were used to
get positive and negative pairs for the contrastive loss. This paper introduces
a few-shot learning scheme to mine pairs automatically without transcriptions.
On English, this results in only a small drop in performance. We also - for the
first time - consider VPKL on a real low-resource language, Yoruba. While
scores are reasonable, here we see a bigger drop in performance compared to
using ground truth pairs because the mining is less accurate in Yoruba.

摘要：給定圖像查詢，視覺提示關鍵字定位 (VPKL) 旨在尋找語音集合中所描繪單詞的出現。當低資源語言沒有轉錄時，這可能會很有用（例如，如果它是未寫的）。先前的研究表明，VPKL 可以使用在配對圖像和未標記語音上訓練的視覺基礎語音模型來執行。但所有實驗都是在英語上進行的。此外，轉錄被用於為對比損失獲得正負對。本文介紹了一種少次學習方案，可以在沒有轉錄的情況下自動挖掘對。在英語中，這只會導致性能略微下降。我們還首次考慮了真正的低資源語言約魯巴語上的 VPKL。雖然分數合理，但與使用地面實況對相比，我們在此看到性能下降更大，因為約魯巴語中的挖掘不太準確。

##### **TransformerRanker: A Tool for Efficiently Finding the Best-Suited Language Models for Downstream Classification Tasks**
2409.05997v1 by Lukas Garbas, Max Ploner, Alan Akbik

Classification tasks in NLP are typically addressed by selecting a
pre-trained language model (PLM) from a model hub, and fine-tuning it for the
task at hand. However, given the very large number of PLMs that are currently
available, a practical challenge is to determine which of them will perform
best for a specific downstream task. With this paper, we introduce
TransformerRanker, a lightweight library that efficiently ranks PLMs for
classification tasks without the need for computationally costly fine-tuning.
Our library implements current approaches for transferability estimation
(LogME, H-Score, kNN), in combination with layer aggregation options, which we
empirically showed to yield state-of-the-art rankings of PLMs (Garbas et al.,
2024). We designed the interface to be lightweight and easy to use, allowing
users to directly connect to the HuggingFace Transformers and Dataset
libraries. Users need only select a downstream classification task and a list
of PLMs to create a ranking of likely best-suited PLMs for their task. We make
TransformerRanker available as a pip-installable open-source library
https://github.com/flairNLP/transformer-ranker.

摘要：NLP 中的分類任務通常透過從模型中心選擇預先訓練好的語言模型 (PLM)，並針對手邊的任務進行微調來處理。然而，考量到目前可用的 PLM 數量龐大，一個實際的挑戰是要找出哪個 PLM 對於特定下游任務的執行成效最佳。透過這篇論文，我們引入了 TransformerRanker，這是一個輕量級的程式庫，可以有效地對 PLM 進行分類任務排名，而無需進行計算成本高昂的微調。我們的程式庫實作了目前用於可轉移性估計的方法 (LogME、H 分數、kNN)，並結合了層聚合選項，我們透過實證證明可產生 PLM 的最先進排名 (Garbas 等人，2024)。我們設計了這個介面，使其輕量且易於使用，讓使用者可以直接連接到 HuggingFace Transformers 和 Dataset 程式庫。使用者只需選擇一個下游分類任務和一個 PLM 清單，即可為任務建立一個可能最適合的 PLM 排名。我們將 TransformerRanker 作為一個可透過 pip 安裝的開源程式庫提供 https://github.com/flairNLP/transformer-ranker。

##### **MessIRve: A Large-Scale Spanish Information Retrieval Dataset**
2409.05994v1 by Francisco Valentini, Viviana Cotik, Damián Furman, Ivan Bercovich, Edgar Altszyler, Juan Manuel Pérez

Information retrieval (IR) is the task of finding relevant documents in
response to a user query. Although Spanish is the second most spoken native
language, current IR benchmarks lack Spanish data, hindering the development of
information access tools for Spanish speakers. We introduce MessIRve, a
large-scale Spanish IR dataset with around 730 thousand queries from Google's
autocomplete API and relevant documents sourced from Wikipedia. MessIRve's
queries reflect diverse Spanish-speaking regions, unlike other datasets that
are translated from English or do not consider dialectal variations. The large
size of the dataset allows it to cover a wide variety of topics, unlike smaller
datasets. We provide a comprehensive description of the dataset, comparisons
with existing datasets, and baseline evaluations of prominent IR models. Our
contributions aim to advance Spanish IR research and improve information access
for Spanish speakers.

摘要：資訊檢索 (IR) 是根據使用者查詢尋找相關文件的工作。儘管西班牙語是第二大母語，但目前的 IR 基準缺乏西班牙語資料，這阻礙了為西班牙語使用者開發資訊存取工具。我們引入了 MessIRve，一個大規模的西班牙語 IR 資料集，其中包含來自 Google 自動完成 API 的約 73 萬個查詢和來自維基百科的相关文件。與從英語翻譯或不考慮方言變異的其他資料集不同，MessIRve 的查詢反映了不同的西班牙語系地區。與較小的資料集不同，該資料集的大規模使它能夠涵蓋各種主題。我們提供了資料集的全面描述、與現有資料集的比較，以及對著名 IR 模型的基線評估。我們的貢獻旨在推進西班牙語 IR 研究，並改善西班牙語使用者的資訊存取。

##### **A Comprehensive Comparison Between ANNs and KANs For Classifying EEG Alzheimer's Data**
2409.05989v1 by Akshay Sunkara, Sriram Sattiraju, Aakarshan Kumar, Zaryab Kanjiani, Himesh Anumala

Alzheimer's Disease is an incurable cognitive condition that affects
thousands of people globally. While some diagnostic methods exist for
Alzheimer's Disease, many of these methods cannot detect Alzheimer's in its
earlier stages. Recently, researchers have explored the use of
Electroencephalogram (EEG) technology for diagnosing Alzheimer's. EEG is a
noninvasive method of recording the brain's electrical signals, and EEG data
has shown distinct differences between patients with and without Alzheimer's.
In the past, Artificial Neural Networks (ANNs) have been used to predict
Alzheimer's from EEG data, but these models sometimes produce false positive
diagnoses. This study aims to compare losses between ANNs and Kolmogorov-Arnold
Networks (KANs) across multiple types of epochs, learning rates, and nodes. The
results show that across these different parameters, ANNs are more accurate in
predicting Alzheimer's Disease from EEG signals.

摘要：阿茲海默症是一種無法治癒的認知疾病，影響全球數千人。雖然阿茲海默症有一些診斷方法，但這些方法中的許多無法在早期階段檢測出阿茲海默症。最近，研究人員探索了使用腦電圖 (EEG) 技術診斷阿茲海默症。EEG 是一種非侵入性的方法，用於記錄大腦的電信號，而 EEG 數據顯示出患有阿茲海默症和未患有阿茲海默症的患者之間存在顯著差異。過去，人工神經網路 (ANN) 已被用於從 EEG 數據中預測阿茲海默症，但這些模型有時會產生假陽性診斷。本研究旨在比較多個類型的時期、學習率和節點之間 ANN 和 Kolmogorov-Arnold 網路 (KAN) 之間的損失。結果表明，在這些不同的參數中，ANN 在從 EEG 信號中預測阿茲海默症方面更準確。

##### **AI for Mathematics Mathematical Formalized Problem Solving and Theorem Proving in Different Fields in Lean4**
2409.05977v1 by Xichen Tang

Using computerized verifiable formal languages like Lean 4 to prove
mathematical theorems has a significant impact on mathematical formalization.
Lean 4 offers prominent potential for advancing mathematical reasoning.
However, existing efforts are limited to mathematical formalization languages
in substantial online corpora and are dedicated to keeping pace with rapidly
evolving languages. To bridge the gap between the traditional and computerized
proof, my approach to formalizing theorem proving involves generating formal
steps and complete proofs using Large Language Models (LLMs) based on Natural
Language (NL) proofs. The method is to introduce the basic structure and
tactics in general, determine how AI can assist the mathematical formalization
process to improve its performance, and give examples of solving problems in
Lean 4 comparing to NL, mainly in IMO, and a sample theorem proving in abstract
algebra.

摘要：使用 Lean 4 等可計算驗證形式語言來證明數學定理對數學形式化有重大影響。
Lean 4 為推進數學推理提供了顯著的潛力。
然而，現有的努力僅限於大量的在線語料庫中的數學形式化語言，並且致力於跟上快速發展的語言。為了彌合傳統和計算機化證明之間的差距，我對定理證明形式化的方法涉及使用基於自然語言 (NL) 證明的生成形式步驟和完整證明的大語言模型 (LLM)。該方法是介紹一般性的基本結構和策略，確定 AI 如何協助數學形式化過程以提高其性能，並給出在 Lean 4 中解決問題的示例，與 NL 進行比較，主要在 IMO 中，以及在抽象代數中的樣本定理證明。

##### **A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets**
2409.05972v1 by Mariana Yukari Noguti, Edduardo Vellasques, Luiz Eduardo Soares Oliveira

Recent advances in language modelling has significantly decreased the need of
labelled data in text classification tasks. Transformer-based models,
pre-trained on unlabeled data, can outmatch the performance of models trained
from scratch for each task. However, the amount of labelled data need to
fine-tune such type of model is still considerably high for domains requiring
expert-level annotators, like the legal domain. This paper investigates the
best strategies for optimizing the use of a small labeled dataset and large
amounts of unlabeled data and perform a classification task in the legal area
with 50 predefined topics. More specifically, we use the records of demands to
a Brazilian Public Prosecutor's Office aiming to assign the descriptions in one
of the subjects, which currently demands deep legal knowledge for manual
filling. The task of optimizing the performance of classifiers in this scenario
is especially challenging, given the low amount of resources available
regarding the Portuguese language, especially in the legal domain. Our results
demonstrate that classic supervised models such as logistic regression and SVM
and the ensembles random forest and gradient boosting achieve better
performance along with embeddings extracted with word2vec when compared to BERT
language model. The latter demonstrates superior performance in association
with the architecture of the model itself as a classifier, having surpassed all
previous models in that regard. The best result was obtained with Unsupervised
Data Augmentation (UDA), which jointly uses BERT, data augmentation, and
strategies of semi-supervised learning, with an accuracy of 80.7% in the
aforementioned task.

摘要：<paragraph>語言模型的最新進展大幅降低了文本分類任務中標註資料的需求。以未標註資料預先訓練的 Transformer 模型，其效能可以超越從頭針對每個任務訓練的模型。然而，對於需要專家級註解者的領域（例如法律領域），微調此類模型所需的標註資料量仍然相當高。本文探討了最佳策略，以最佳化使用小型標註資料集和大量未標註資料，並在法律領域執行分類任務，其中包含 50 個預先定義的主題。更具體地說，我們使用巴西檢察官辦公室的要求記錄，旨在將說明指派到其中一個主題，目前需要深厚的法律知識才能手動填寫。在這種情況下，最佳化分類器效能的任務特別具有挑戰性，因為葡萄牙語可用的資源很少，特別是在法律領域。我們的結果表明，與 BERT 語言模型相比，經典監督模型（例如邏輯迴歸和 SVM）以及隨機森林和梯度提升的集成，在與 word2vec 提取的嵌入式處理時，可以獲得更好的效能。後者與模型本身的架構作為分類器結合使用時，表現出優異的效能，在這個方面超越了所有先前的模型。最佳結果是透過非監督資料擴充 (UDA) 獲得的，它結合使用了 BERT、資料擴充和半監督學習策略，在上述任務中達到了 80.7% 的準確度。</paragraph>

##### **Promptable Closed-loop Traffic Simulation**
2409.05863v1 by Shuhan Tan, Boris Ivanovic, Yuxiao Chen, Boyi Li, Xinshuo Weng, Yulong Cao, Philipp Krähenbühl, Marco Pavone

Simulation stands as a cornerstone for safe and efficient autonomous driving
development. At its core a simulation system ought to produce realistic,
reactive, and controllable traffic patterns. In this paper, we propose ProSim,
a multimodal promptable closed-loop traffic simulation framework. ProSim allows
the user to give a complex set of numerical, categorical or textual prompts to
instruct each agent's behavior and intention. ProSim then rolls out a traffic
scenario in a closed-loop manner, modeling each agent's interaction with other
traffic participants. Our experiments show that ProSim achieves high prompt
controllability given different user prompts, while reaching competitive
performance on the Waymo Sim Agents Challenge when no prompt is given. To
support research on promptable traffic simulation, we create
ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with
over 10M text prompts for over 520k real-world driving scenarios. We will
release code of ProSim as well as data and labeling tools of
ProSim-Instruct-520k at https://ariostgx.github.io/ProSim.

摘要：模擬作為安全且有效率的自動駕駛開發的基石。模擬系統的核心在於產生逼真、具反應性且可控制的交通模式。在本文中，我們提出 ProSim，一個多模態可提示閉環交通模擬架構。ProSim 允許使用者提供一組複雜的數值、類別或文字提示，以指示每個代理的行為和意圖。然後，ProSim 以閉環方式推出交通場景，模擬每個代理與其他交通參與者的互動。我們的實驗顯示，在沒有提示的情況下，ProSim 在不同的使用者提示下實現了很高的提示可控性，同時在 Waymo Sim Agents Challenge 中達到了競爭力的表現。為了支持可提示交通模擬的研究，我們建立了 ProSim-Instruct-520k，一個多模態提示場景配對的駕駛資料集，其中包含超過 10M 個文字提示，適用於超過 520k 個真實世界的駕駛場景。我們將在 https://ariostgx.github.io/ProSim 上釋出 ProSim 的程式碼以及 ProSim-Instruct-520k 的資料和標籤工具。

##### **MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct**
2409.05840v1 by Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li

The development of Multimodal Large Language Models (MLLMs) has seen
significant advancements. However, the quantity and quality of multimodal
instruction data have emerged as significant bottlenecks in their progress.
Manually creating multimodal instruction data is both time-consuming and
inefficient, posing challenges in producing instructions of high complexity.
Moreover, distilling instruction data from black-box commercial models (e.g.,
GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains
performance to that of these models. The challenge of curating diverse and
complex instruction data remains substantial. We propose MMEvol, a novel
multimodal instruction data evolution framework that combines fine-grained
perception evolution, cognitive reasoning evolution, and interaction evolution.
This iterative approach breaks through data quality bottlenecks to generate a
complex and diverse image-text instruction dataset, thereby empowering MLLMs
with enhanced capabilities. Beginning with an initial set of instructions,
SEED-163K, we utilize MMEvol to systematically broadens the diversity of
instruction types, integrates reasoning steps to enhance cognitive
capabilities, and extracts detailed information from images to improve visual
understanding and robustness. To comprehensively evaluate the effectiveness of
our data, we train LLaVA-NeXT using the evolved data and conduct experiments
across 13 vision-language tasks. Compared to the baseline trained with seed
data, our approach achieves an average accuracy improvement of 3.1 points and
reaches state-of-the-art (SOTA) performance on 9 of these tasks.

摘要：多模态大语言模型（MLLM）的发展已取得显著进展。然而，多模态指令数据的数量和质量已成为其进步中的重大瓶颈。手动创建多模态指令数据既费时又低效，在生成高复杂度指令时会造成挑战。此外，从黑箱商业模型（例如 GPT-4o、GPT-4V）中提取指令数据通常会导致指令数据过于简单，这会将性能限制在这些模型的性能范围内。对多样且复杂指令数据进行整理的挑战仍然很大。我们提出了 MMEvol，这是一种新颖的多模态指令数据演化框架，它结合了细粒度的感知演化、认知推理演化和交互演化。这种迭代方法突破了数据质量瓶颈，生成复杂且多样的图像文本指令数据集，从而增强了 MLLM 的能力。从一组初始指令 SEED-163K 开始，我们利用 MMEvol 系统地拓宽指令类型的多样性，整合推理步骤以增强认知能力，并从图像中提取详细信息以提高视觉理解和鲁棒性。为了全面评估我们数据的有效性，我们使用演化数据训练 LLaVA-NeXT，并在 13 项视觉语言任务中进行实验。与使用种子数据训练的基线相比，我们的方法将平均准确度提高了 3.1 个百分点，并在其中 9 项任务上达到了最先进 (SOTA) 的性能。

##### **DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning**
2409.05938v1 by Condy Bao, Fuxiao Liu

Since the advent of CRISPR-Cas9, a groundbreaking gene-editing technology
that enables precise genomic modifications via a short RNA guide sequence,
there has been a marked increase in the accessibility and application of this
technology across various fields. The success of CRISPR-Cas9 has spurred
further investment and led to the discovery of additional CRISPR systems,
including CRISPR-Cas13. Distinct from Cas9, which targets DNA, Cas13 targets
RNA, offering unique advantages for gene modulation. We focus on Cas13d, a
variant known for its collateral activity where it non-specifically cleaves
adjacent RNA molecules upon activation, a feature critical to its function. We
introduce DeepFM-Crispr, a novel deep learning model developed to predict the
on-target efficiency and evaluate the off-target effects of Cas13d. This model
harnesses a large language model to generate comprehensive representations rich
in evolutionary and structural data, thereby enhancing predictions of RNA
secondary structures and overall sgRNA efficacy. A transformer-based
architecture processes these inputs to produce a predictive efficacy score.
Comparative experiments show that DeepFM-Crispr not only surpasses traditional
models but also outperforms recent state-of-the-art deep learning methods in
terms of prediction accuracy and reliability.

摘要：自 CRISPR-Cas9 問世以來，這項突破性的基因編輯技術
可透過短 RNA 引導序列執行精準的基因體修改，
此技術在各個領域的可近性和應用性都有顯著的提升。CRISPR-Cas9 的成功
激勵了更多投資，並導致發現更多 CRISPR 系統，
包含 CRISPR-Cas13。與鎖定 DNA 的 Cas9 不同，Cas13 鎖定
RNA，提供基因調控的獨特優勢。我們專注於 Cas13d，一種
已知具有附帶活性變異，在活化後會非特定地切割
相鄰的 RNA 分子，此特性對其功能至關重要。我們介紹 DeepFM-Crispr，一種
新穎的深度學習模型，用於預測目標效率並評估 Cas13d 的脫靶效應。此模型
利用大型語言模型來產生包含豐富演化和結構資料的全面表徵，從而增強對 RNA
二級結構和整體 sgRNA 效能的預測。一個基於Transformer的
架構處理這些輸入以產生預測效能分數。比較實驗顯示 DeepFM-Crispr 不僅超越傳統
模型，在預測準確性和可靠性方面也優於近期最先進的深度學習方法。

##### **Improving Pretraining Data Using Perplexity Correlations**
2409.05816v1 by Tristan Thrush, Christopher Potts, Tatsunori Hashimoto

Quality pretraining data is often seen as the key to high-performance
language models. However, progress in understanding pretraining data has been
slow due to the costly pretraining runs required for data selection
experiments. We present a framework that avoids these costs and selects
high-quality pretraining data without any LLM training of our own. Our work is
based on a simple observation: LLM losses on many pretraining texts are
correlated with downstream benchmark performance, and selecting
high-correlation documents is an effective pretraining data selection method.
We build a new statistical framework for data selection centered around
estimates of perplexity-benchmark correlations and perform data selection using
a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of
thousands of web domains. In controlled pretraining experiments at the 160M
parameter scale on 8 benchmarks, our approach outperforms DSIR on every
benchmark, while matching the best data selector found in DataComp-LM, a
hand-engineered bigram classifier.

摘要：高质量预训练数据通常被视为高性能语言模型的关键。然而，由于数据选择实验需要昂贵的预训练运行，因此对预训练数据的理解进展缓慢。我们提出了一个避免这些成本的框架，并在不进行任何 LLM 训练的情况下选择高质量的预训练数据。我们的工作基于一个简单的观察：许多预训练文本上的 LLM 损失与下游基准性能相关，并且选择高相关性文档是一种有效的预训练数据选择方法。我们构建了一个新的统计框架，用于数据选择，该框架围绕困惑度基准相关性的估计展开，并使用从数万个网络域中的文本中获取的 90 个 LLM 样本执行数据选择。在 8 个基准上的 160M 参数规模的受控预训练实验中，我们的方法在每个基准上都优于 DSIR，同时匹配了在 DataComp-LM 中发现的最佳数据选择器，即手工制作的二元分类器。

##### **The Future of Software Testing: AI-Powered Test Case Generation and Validation**
2409.05808v1 by Mohammad Baqar, Rajat Khanda

Software testing is a crucial phase in the software development lifecycle
(SDLC), ensuring that products meet necessary functional, performance, and
quality benchmarks before release. Despite advancements in automation,
traditional methods of generating and validating test cases still face
significant challenges, including prolonged timelines, human error, incomplete
test coverage, and high costs of manual intervention. These limitations often
lead to delayed product launches and undetected defects that compromise
software quality and user satisfaction. The integration of artificial
intelligence (AI) into software testing presents a promising solution to these
persistent challenges. AI-driven testing methods automate the creation of
comprehensive test cases, dynamically adapt to changes, and leverage machine
learning to identify high-risk areas in the codebase. This approach enhances
regression testing efficiency while expanding overall test coverage.
Furthermore, AI-powered tools enable continuous testing and self-healing test
cases, significantly reducing manual oversight and accelerating feedback loops,
ultimately leading to faster and more reliable software releases. This paper
explores the transformative potential of AI in improving test case generation
and validation, focusing on its ability to enhance efficiency, accuracy, and
scalability in testing processes. It also addresses key challenges associated
with adapting AI for testing, including the need for high quality training
data, ensuring model transparency, and maintaining a balance between automation
and human oversight. Through case studies and examples of real-world
applications, this paper illustrates how AI can significantly enhance testing
efficiency across both legacy and modern software systems.

摘要：軟體測試是軟體開發生命週期 (SDLC) 中至關重要的一個階段，確保產品在發布前符合必要的運作、效能和品質基準。儘管自動化技術進步，但產生和驗證測試案例的傳統方法仍然面臨重大挑戰，包括時間線拉長、人為錯誤、測試涵蓋不完全，以及人工介入的高成本。這些限制通常會導致產品發布延誤和未偵測到的缺陷，進而損害軟體品質和使用者滿意度。將人工智慧 (AI) 整合到軟體測試中，為這些持續存在的挑戰提供了有希望的解決方案。AI 驅動的測試方法可以自動建立全面的測試案例，動態適應變更，並利用機器學習來識別程式碼庫中的高風險區域。這種方法可以提升回歸測試效率，同時擴展整體測試涵蓋範圍。此外，AI 驅動的工具可以進行持續測試和自我修復測試案例，大幅減少人工監督並加速回饋迴圈，最終實現更快速且更可靠的軟體發布。本文探討了 AI 在改善測試案例產生和驗證方面的變革潛力，重點在於它增強測試流程中效率、準確性和可擴充性的能力。本文也探討了將 AI 應用於測試時會遇到的主要挑戰，包括對高品質訓練資料的需求、確保模型透明度，以及在自動化和人工監督之間取得平衡。透過案例研究和真實世界應用範例，本文說明了 AI 如何能大幅提升傳統和現代軟體系統的測試效率。

##### **Benchmarking Chinese Knowledge Rectification in Large Language Models**
2409.05806v1 by Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen

While Large Language Models (LLMs) exhibit remarkable generative
capabilities, they are not without flaws, particularly in the form of
hallucinations. This issue is even more pronounced when LLMs are applied to
specific languages and domains. For example, LLMs may generate nonsense
information when handling Chinese ancient poetry, proverbs, or idioms, owing to
the lack of specific knowledge. To this end, this paper introduces a benchmark
for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,
we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of
knowledge from various sources, including classical texts, idioms, and content
from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,
antithesis, and logical constructs inherent in the Chinese language. Through
the analysis of this dataset, we uncover the challenges faced by current LLMs
in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge
editing techniques on this dataset unveil the substantial scope for advancement
in the rectification of Chinese knowledge. Code and dataset are available at
https://github.com/zjunlp/EasyEdit.

摘要：大型语言模型 (LLM) 虽然表现出非凡的生成能力，但也并非没有缺陷，特别是幻觉形式的缺陷。当 LLM 应用于特定语言和领域时，这个问题更为明显。例如，由于缺乏特定知识，LLM 在处理中国古代诗歌、谚语或成语时可能会产生无意义的信息。为此，本文通过知识编辑引入了一个用于纠正 LLM 中中文知识的基准。具体来说，我们通过从各种来源（包括经典文本、成语和百度贴吧若知八的的内容）收集七种类型的知识，引入了新的中文数据集 CKnowEdit，从而解释了中文语言中固有的独特多音、对立和逻辑结构。通过对该数据集的分析，我们发现了当前 LLM 在掌握中文时面临的挑战。此外，我们对该数据集上最先进的知识编辑技术的评估揭示了纠正中文知识的巨大进步空间。代码和数据集可在 https://github.com/zjunlp/EasyEdit 获得。

##### **Enhancing Preference-based Linear Bandits via Human Response Time**
2409.05798v1 by Shen Li, Yuyang Zhang, Zhaolin Ren, Claire Liang, Na Li, Julie A. Shah

Binary human choice feedback is widely used in interactive preference
learning for its simplicity, but it provides limited information about
preference strength. To overcome this limitation, we leverage human response
times, which inversely correlate with preference strength, as complementary
information. Our work integrates the EZ-diffusion model, which jointly models
human choices and response times, into preference-based linear bandits. We
introduce a computationally efficient utility estimator that reformulates the
utility estimation problem using both choices and response times as a linear
regression problem. Theoretical and empirical comparisons with traditional
choice-only estimators reveal that for queries with strong preferences ("easy"
queries), choices alone provide limited information, while response times offer
valuable complementary information about preference strength. As a result,
incorporating response times makes easy queries more useful. We demonstrate
this advantage in the fixed-budget best-arm identification problem, with
simulations based on three real-world datasets, consistently showing
accelerated learning when response times are incorporated.

摘要：二元人類選擇回饋因其簡潔性而廣泛用於互動式偏好學習，但它提供的偏好強度資訊有限。為了克服此限制，我們利用與偏好強度呈反比的人類反應時間，作為補充資訊。我們的研究將 EZ 擴散模型整合到偏好式線性賭徒中，該模型共同建模人類選擇和反應時間。我們引入了一個計算效率高的效用估計器，它使用選擇和反應時間作為線性回歸問題來重新制定效用估計問題。與傳統的僅選擇估計器的理論和實證比較表明，對於具有強烈偏好的查詢（「容易」查詢），僅選擇提供有限的資訊，而反應時間提供有價值的補充資訊，說明偏好強度。因此，納入反應時間使簡單的查詢更有用。我們在固定預算最佳臂識別問題中展示了此優勢，模擬基於三個真實世界資料集，始終顯示在納入反應時間時，加速學習。

##### **NeurLZ: On Enhancing Lossy Compression Performance based on Error-Controlled Neural Learning for Scientific Data**
2409.05785v2 by Wenqi Jia, Youyuan Liu, Zhewen Hu, Jinzhen Wang, Boyuan Zhang, Wei Niu, Junzhou Huang, Stavros Kalafatis, Sian Jin, Miao Yin

Large-scale scientific simulations generate massive datasets that pose
significant challenges for storage and I/O. While traditional lossy compression
techniques can improve performance, balancing compression ratio, data quality,
and throughput remains difficult. To address this, we propose NeurLZ, a novel
cross-field learning-based and error-controlled compression framework for
scientific data. By integrating skipping DNN models, cross-field learning, and
error control, our framework aims to substantially enhance lossy compression
performance. Our contributions are three-fold: (1) We design a lightweight
skipping model to provide high-fidelity detail retention, further improving
prediction accuracy. (2) We adopt a cross-field learning approach to
significantly improve data prediction accuracy, resulting in a substantially
improved compression ratio. (3) We develop an error control approach to provide
strict error bounds according to user requirements. We evaluated NeurLZ on
several real-world HPC application datasets, including Nyx (cosmological
simulation), Miranda (large turbulence simulation), and Hurricane (weather
simulation). Experiments demonstrate that our framework achieves up to a 90%
relative reduction in bit rate under the same data distortion, compared to the
best existing approach.

摘要：大規模的科學模擬會產生大量的資料集，對儲存和 I/O 造成嚴峻的挑戰。雖然傳統的有損壓縮技術可以提升效能，但要在壓縮率、資料品質和處理量之間取得平衡仍很困難。為了解決這個問題，我們提出了 NeurLZ，一個創新的基於跨領域學習和錯誤控制的科學資料壓縮架構。透過整合跳過 DNN 模型、跨領域學習和錯誤控制，我們的架構旨在大幅提升有損壓縮效能。我們的貢獻有三方面：(1) 我們設計了一個輕量級跳過模型來提供高保真細節保留，進一步提升預測準確度。(2) 我們採用跨領域學習方法來大幅提升資料預測準確度，進而大幅提升壓縮率。(3) 我們開發了一個錯誤控制方法來根據使用者需求提供嚴格的錯誤界限。我們在多個真實世界的 HPC 應用程式資料集上評估了 NeurLZ，包括 Nyx (宇宙學模擬)、Miranda (大型湍流模擬) 和 Hurricane (天氣模擬)。實驗證明，與現有的最佳方法相比，我們的架構在相同的資料失真下，可將位元率相對降低多達 90%。

##### **Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models**
2409.05771v1 by Emily Cheng, Richard J. Antonello

Research has repeatedly demonstrated that intermediate hidden states
extracted from large language models are able to predict measured brain
response to natural language stimuli. Yet, very little is known about the
representation properties that enable this high prediction performance. Why is
it the intermediate layers, and not the output layers, that are most capable
for this unique and highly general transfer task? In this work, we show that
evidence from language encoding models in fMRI supports the existence of a
two-phase abstraction process within LLMs. We use manifold learning methods to
show that this abstraction process naturally arises over the course of training
a language model and that the first "composition" phase of this abstraction
process is compressed into fewer layers as training continues. Finally, we
demonstrate a strong correspondence between layerwise encoding performance and
the intrinsic dimensionality of representations from LLMs. We give initial
evidence that this correspondence primarily derives from the inherent
compositionality of LLMs and not their next-word prediction properties.

摘要：研究已一再證明，從大型語言模型中提取的中間隱藏狀態能夠預測大腦對自然語言刺激的測量反應。然而，對於能夠實現這種高預測性能的表徵特性，我們所知甚少。為什麼是中間層，而不是輸出層，最能勝任這項獨特且高度通用的轉移任務？在這項工作中，我們展示了 fMRI 中語言編碼模型的證據支持 LLM 中存在兩階段抽象過程。我們使用流形學習方法來展示這個抽象過程在語言模型訓練過程中自然產生，並且這個抽象過程的第一個「組合」階段會隨著訓練的進行而壓縮到更少的層中。最後，我們展示了層級編碼性能與 LLM 中表徵的內在維度之間的強對應關係。我們給出的初步證據表明，這種對應關係主要源於 LLM 固有的組合性，而不是它們的下一詞預測特性。

##### **Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models**
2409.06493v1 by Rohit Jena, Ali Taghibakhshi, Sahil Jain, Gerald Shen, Nima Tajbakhsh, Arash Vahdat

Text-to-image (T2I) diffusion models have become prominent tools for
generating high-fidelity images from text prompts. However, when trained on
unfiltered internet data, these models can produce unsafe, incorrect, or
stylistically undesirable images that are not aligned with human preferences.
To address this, recent approaches have incorporated human preference datasets
to fine-tune T2I models or to optimize reward functions that capture these
preferences. Although effective, these methods are vulnerable to reward
hacking, where the model overfits to the reward function, leading to a loss of
diversity in the generated images. In this paper, we prove the inevitability of
reward hacking and study natural regularization techniques like KL divergence
and LoRA scaling, and their limitations for diffusion models. We also introduce
Annealed Importance Guidance (AIG), an inference-time regularization inspired
by Annealed Importance Sampling, which retains the diversity of the base model
while achieving Pareto-Optimal reward-diversity tradeoffs. Our experiments
demonstrate the benefits of AIG for Stable Diffusion models, striking the
optimal balance between reward optimization and image diversity. Furthermore, a
user study confirms that AIG improves diversity and quality of generated images
across different model architectures and reward functions.

摘要：文本到图像 (T2I) 扩散模型已成为根据文本提示生成高保真图像的重要工具。然而，当在未经筛选的互联网数据上进行训练时，这些模型可能会产生不安全、不正确或风格上不可取的图像，这些图像与人类偏好不符。为了解决这个问题，最近的方法已经纳入了人类偏好数据集来微调 T2I 模型或优化捕获这些偏好的奖励函数。尽管有效，但这些方法容易受到奖励黑客攻击，其中模型过度拟合奖励函数，导致生成图像的多样性丧失。在本文中，我们证明了奖励黑客攻击的不可避免性，并研究了自然正则化技术，如 KL 散度和 LoRA 缩放，以及它们对扩散模型的限制。我们还引入了退火重要性指导 (AIG)，这是一种受退火重要性采样启发的推理时间正则化，它保留了基础模型的多样性，同时实现了帕累托最优的奖励多样性权衡。我们的实验展示了 AIG 对稳定扩散模型的好处，在奖励优化和图像多样性之间取得了最佳平衡。此外，一项用户研究证实，AIG 提升了不同模型架构和奖励函数下生成图像的多样性和质量。


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-10**|**User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study**|Julien Albert et.al.|[2409.06297v1](http://arxiv.org/abs/2409.06297v1)|null|
|**2024-09-09**|**Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**|Dongyue Li et.al.|[2409.06091v1](http://arxiv.org/abs/2409.06091v1)|[link](https://github.com/virtuosoresearch/scalablemtl)|
|**2024-09-09**|**SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**|Alireza Ghafarollahi et.al.|[2409.05556v1](http://arxiv.org/abs/2409.05556v1)|[link](https://github.com/lamm-mit/SciAgentsDiscovery)|
|**2024-09-09**|**Assessing SPARQL capabilities of Large Language Models**|Lars-Peter Meyer et.al.|[2409.05925v1](http://arxiv.org/abs/2409.05925v1)|[link](https://github.com/aksw/llm-kg-bench-results)|
|**2024-09-09**|**KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**|Yingshu Li et.al.|[2409.05370v1](http://arxiv.org/abs/2409.05370v1)|null|
|**2024-09-07**|**Action is the primary key: a categorical framework for episode description and logical reasoning**|Yoshiki Fukada et.al.|[2409.04793v1](http://arxiv.org/abs/2409.04793v1)|null|
|**2024-09-06**|**Accelerating Training with Neuron Interaction and Nowcasting Networks**|Boris Knyazev et.al.|[2409.04434v1](http://arxiv.org/abs/2409.04434v1)|[link](https://github.com/samsungsailmontreal/nino)|
|**2024-09-06**|**Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**|Desiree Heim et.al.|[2409.04286v1](http://arxiv.org/abs/2409.04286v1)|null|
|**2024-09-06**|**GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**|Ziyin Zhang et.al.|[2409.04183v1](http://arxiv.org/abs/2409.04183v1)|null|
|**2024-09-06**|**Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**|Larissa Pusch et.al.|[2409.04181v1](http://arxiv.org/abs/2409.04181v1)|null|
|**2024-09-06**|**Refining Wikidata Taxonomy using Large Language Models**|Yiwen Peng et.al.|[2409.04056v1](http://arxiv.org/abs/2409.04056v1)|null|
|**2024-09-06**|**Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**|Miao Fan et.al.|[2409.04009v1](http://arxiv.org/abs/2409.04009v1)|null|
|**2024-09-05**|**Rx Strategist: Prescription Verification using LLM Agents System**|Phuc Phan Van et.al.|[2409.03440v1](http://arxiv.org/abs/2409.03440v1)|null|
|**2024-09-05**|**iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**|Yassir Lairgi et.al.|[2409.03284v1](http://arxiv.org/abs/2409.03284v1)|[link](https://github.com/AuvaLab/itext2kg)|
|**2024-09-05**|**GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**|Yukun Cao et.al.|[2409.03258v1](http://arxiv.org/abs/2409.03258v1)|null|
|**2024-09-05**|**Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**|Jie Ma et.al.|[2409.03155v1](http://arxiv.org/abs/2409.03155v1)|[link](https://github.com/reml-group/dog)|
|**2024-09-04**|**Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**|Junyoung Lee et.al.|[2409.02481v1](http://arxiv.org/abs/2409.02481v1)|null|
|**2024-09-04**|**Multi-modal Situated Reasoning in 3D Scenes**|Xiongkun Linghu et.al.|[2409.02389v1](http://arxiv.org/abs/2409.02389v1)|null|
|**2024-09-02**|**Grounding Language Models in Autonomous Loco-manipulation Tasks**|Jin Wang et.al.|[2409.01326v1](http://arxiv.org/abs/2409.01326v1)|null|
|**2024-09-02**|**LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning**|Haoran Yang et.al.|[2409.01145v1](http://arxiv.org/abs/2409.01145v1)|null|
|**2024-09-01**|**Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**|Derian Boer et.al.|[2409.00861v1](http://arxiv.org/abs/2409.00861v1)|[link](https://github.com/kramerlab/4StepFocus)|
|**2024-09-01**|**Building FKG.in: a Knowledge Graph for Indian Food**|Saransh Kumar Gupta et.al.|[2409.00830v1](http://arxiv.org/abs/2409.00830v1)|null|
|**2024-09-01**|**Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph**|Yuxiang Wang et.al.|[2409.00727v1](http://arxiv.org/abs/2409.00727v1)|null|
|**2024-08-31**|**WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction**|Oktie Hassanzadeh et.al.|[2409.00331v1](http://arxiv.org/abs/2409.00331v1)|[link](https://github.com/IBM/wikicausal)|
|**2024-08-29**|**LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models**|Jingyi Wang et.al.|[2408.16224v2](http://arxiv.org/abs/2408.16224v2)|null|
|**2024-08-28**|**LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**|Ruirui Chen et.al.|[2408.15903v1](http://arxiv.org/abs/2408.15903v1)|null|
|**2024-08-27**|**VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities**|Shusaku Egami et.al.|[2408.14895v2](http://arxiv.org/abs/2408.14895v2)|[link](https://github.com/aistairc/virtualhome_aist)|
|**2024-08-27**|**XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model**|Yasir Ali Farrukh et.al.|[2408.16021v1](http://arxiv.org/abs/2408.16021v1)|null|
|**2024-08-26**|**Process Trace Querying using Knowledge Graphs and Notation3**|William Van Woensel et.al.|[2409.04452v1](http://arxiv.org/abs/2409.04452v1)|null|
|**2024-08-26**|**PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method**|Runtao Ren et.al.|[2409.00092v1](http://arxiv.org/abs/2409.00092v1)|null|
|**2024-08-26**|**DynamicRouteGPT: A Real-Time Multi-Vehicle Dynamic Navigation Framework Based on Large Language Models**|Ziai Zhou et.al.|[2408.14185v1](http://arxiv.org/abs/2408.14185v1)|null|
|**2024-08-26**|**Exploring the Potential of Large Language Models for Heterophilic Graphs**|Yuxia Wu et.al.|[2408.14134v1](http://arxiv.org/abs/2408.14134v1)|null|
|**2024-08-26**|**Towards Graph Prompt Learning: A Survey and Beyond**|Qingqing Long et.al.|[2408.14520v2](http://arxiv.org/abs/2408.14520v2)|null|
|**2024-08-25**|**CodeGraph: Enhancing Graph Reasoning of LLMs with Code**|Qiaolong Cai et.al.|[2408.13863v1](http://arxiv.org/abs/2408.13863v1)|null|
|**2024-08-25**|**LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings**|Duo Wang et.al.|[2408.14512v1](http://arxiv.org/abs/2408.14512v1)|null|
|**2024-08-24**|**Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models**|Sakhinana Sagar Srinivas et.al.|[2408.13661v1](http://arxiv.org/abs/2408.13661v1)|null|
|**2024-08-24**|**GNN: Graph Neural Network and Large Language Model for Data Discovery**|Thomas Hoang et.al.|[2408.13609v2](http://arxiv.org/abs/2408.13609v2)|null|
|**2024-08-24**|**HRGraph: Leveraging LLMs for HR Data Knowledge Graphs with Information Propagation-based Job Recommendation**|Azmine Toushik Wasi et.al.|[2408.13521v1](http://arxiv.org/abs/2408.13521v1)|[link](https://github.com/azminewasi/hrgraph)|
|**2024-08-24**|**Integrating Multi-Head Convolutional Encoders with Cross-Attention for Improved SPARQL Query Translation**|Yi-Hui Chen et.al.|[2408.13432v1](http://arxiv.org/abs/2408.13432v1)|null|
|**2024-08-23**|**CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers**|Ekaterina Trofimova et.al.|[2408.13366v1](http://arxiv.org/abs/2408.13366v1)|null|
|**2024-08-23**|**Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving**|Sakhinana Sagar Srinivas et.al.|[2408.14494v1](http://arxiv.org/abs/2408.14494v1)|null|
|**2024-08-22**|**A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**|Ekdeep Singh Lubana et.al.|[2408.12578v2](http://arxiv.org/abs/2408.12578v2)|[link](https://github.com/ekdeepslubana/conceptpercolation)|
|**2024-08-22**|**Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language**|Arief Purnama Muharram et.al.|[2409.00061v1](http://arxiv.org/abs/2409.00061v1)|null|
|**2024-08-22**|**Cell-ontology guided transcriptome foundation model**|Xinyu Yuan et.al.|[2408.12373v1](http://arxiv.org/abs/2408.12373v1)|null|
|**2024-08-22**|**Graph Retrieval Augmented Trustworthiness Reasoning**|Ying Zhu et.al.|[2408.12333v2](http://arxiv.org/abs/2408.12333v2)|[link](https://github.com/EvoNexusX/Graph-Retrieval-Augmented-Trustworthiness-Reasoning)|
|**2024-08-22**|**MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient**|Yanzeng Li et.al.|[2408.12236v1](http://arxiv.org/abs/2408.12236v1)|null|
|**2024-08-22**|**Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning**|Junlin He et.al.|[2408.12116v1](http://arxiv.org/abs/2408.12116v1)|null|
|**2024-08-21**|**Enabling Small Models for Zero-Shot Classification through Model Label Learning**|Jia Zhang et.al.|[2408.11449v1](http://arxiv.org/abs/2408.11449v1)|null|
|**2024-08-20**|**Hide Your Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Neural Carrier Articles**|Zhilong Wang et.al.|[2408.11182v1](http://arxiv.org/abs/2408.11182v1)|null|
|**2024-08-20**|**Public Health in Disaster: Emotional Health and Life Incidents Extraction during Hurricane Harvey**|Thomas Hoang et.al.|[2408.11133v1](http://arxiv.org/abs/2408.11133v1)|null|
|**2024-08-20**|**Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains**|Rui Yang et.al.|[2408.10819v1](http://arxiv.org/abs/2408.10819v1)|null|
|**2024-08-20**|**Hologram Reasoning for Solving Algebra Problems with Geometry Diagrams**|Litian Huang et.al.|[2408.10592v1](http://arxiv.org/abs/2408.10592v1)|[link](https://github.com/ferretdoll/hgr)|
|**2024-08-19**|**Query languages for neural networks**|Martin Grohe et.al.|[2408.10362v2](http://arxiv.org/abs/2408.10362v2)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124v1](http://arxiv.org/abs/2408.10124v1)|[link](https://github.com/zhangtia16/molgraph-lardo)|
|**2024-08-19**|**Geometry Informed Tokenization of Molecules for Language Model Generation**|Xiner Li et.al.|[2408.10120v1](http://arxiv.org/abs/2408.10120v1)|null|
|**2024-08-19**|**GLIMMER: Incorporating Graph and Lexical Features in Unsupervised Multi-Document Summarization**|Ran Liu et.al.|[2408.10115v1](http://arxiv.org/abs/2408.10115v1)|[link](https://github.com/oswald1997/glimmer)|
|**2024-08-19**|**SEMDR: A Semantic-Aware Dual Encoder Model for Legal Judgment Prediction with Legal Clue Tracing**|Pengjie Liu et.al.|[2408.09717v1](http://arxiv.org/abs/2408.09717v1)|null|
|**2024-08-18**|**Revisiting the Graph Reasoning Ability of Large Language Models: Case Studies in Translation, Connectivity and Shortest Path**|Xinnan Dai et.al.|[2408.09529v1](http://arxiv.org/abs/2408.09529v1)|null|
|**2024-08-18**|**Retrieval-Augmented Generation Meets Data-Driven Tabula Rasa Approach for Temporal Knowledge Graph Forecasting**|Geethan Sannidhi et.al.|[2408.13273v1](http://arxiv.org/abs/2408.13273v1)|null|
|**2024-08-18**|**Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models**|Kening Zheng et.al.|[2408.09429v1](http://arxiv.org/abs/2408.09429v1)|null|
|**2024-08-16**|**ASGM-KG: Unveiling Alluvial Gold Mining Through Knowledge Graphs**|Debashis Gupta et.al.|[2408.08972v1](http://arxiv.org/abs/2408.08972v1)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782v1](http://arxiv.org/abs/2408.08782v1)|[link](https://github.com/cw-wan/EmoDynamiX-v2)|
|**2024-08-16**|**Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**|Zhongjian Zhang et.al.|[2408.08685v1](http://arxiv.org/abs/2408.08685v1)|null|
|**2024-08-16**|**RoarGraph: A Projected Bipartite Graph for Efficient Cross-Modal Approximate Nearest Neighbor Search**|Meng Chen et.al.|[2408.08933v1](http://arxiv.org/abs/2408.08933v1)|[link](https://github.com/matchyc/RoarGraph)|
|**2024-08-16**|**Handling abort commands for household kitchen robots**|Darius Has et.al.|[2408.14480v1](http://arxiv.org/abs/2408.14480v1)|null|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535v1](http://arxiv.org/abs/2408.08535v1)|null|
|**2024-08-15**|**VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool**|Chia-Tung Ho et.al.|[2408.08927v1](http://arxiv.org/abs/2408.08927v1)|null|
|**2024-08-15**|**Graph Retrieval-Augmented Generation: A Survey**|Boci Peng et.al.|[2408.08921v2](http://arxiv.org/abs/2408.08921v2)|[link](https://github.com/pengboci/graphrag-survey)|
|**2024-08-14**|**Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability**|Jiri Hron et.al.|[2408.07852v1](http://arxiv.org/abs/2408.07852v1)|null|
|**2024-08-14**|**ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model**|Xuanqing Yu et.al.|[2408.07840v1](http://arxiv.org/abs/2408.07840v1)|null|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611v2](http://arxiv.org/abs/2408.07611v2)|null|
|**2024-08-14**|**Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals**|Tobias A. Opsahl et.al.|[2408.07453v1](http://arxiv.org/abs/2408.07453v1)|[link](https://github.com/tobias-opsahl/fact-or-fiction)|
|**2024-08-13**|**LLMs can Schedule**|Henrik Abgaryan et.al.|[2408.06993v1](http://arxiv.org/abs/2408.06993v1)|[link](https://github.com/starjob42/datasetjsp)|
|**2024-08-13**|**Causal Agent based on Large Language Model**|Kairong Han et.al.|[2408.06849v1](http://arxiv.org/abs/2408.06849v1)|[link](https://github.com/kairong-han/causal_agent)|
|**2024-08-13**|**Unlock the Power of Frozen LLMs in Knowledge Graph Completion**|Bo Xue et.al.|[2408.06787v1](http://arxiv.org/abs/2408.06787v1)|null|
|**2024-08-13**|**Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models**|Jialiang Wang et.al.|[2408.06717v1](http://arxiv.org/abs/2408.06717v1)|null|
|**2024-08-12**|**Body Transformer: Leveraging Robot Embodiment for Policy Learning**|Carmelo Sferrazza et.al.|[2408.06316v1](http://arxiv.org/abs/2408.06316v1)|null|
|**2024-08-12**|**ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers**|Aristi Papastavrou et.al.|[2408.06040v1](http://arxiv.org/abs/2408.06040v1)|null|
|**2024-08-12**|**ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models**|Ronak Pradeep et.al.|[2408.05948v1](http://arxiv.org/abs/2408.05948v1)|null|
|**2024-08-11**|**The Cognitive Revolution in Interpretability: From Explaining Behavior to Interpreting Representations and Algorithms**|Adam Davies et.al.|[2408.05859v1](http://arxiv.org/abs/2408.05859v1)|null|
|**2024-08-10**|**Investigating Instruction Tuning Large Language Models on Graphs**|Kerui Zhu et.al.|[2408.05457v1](http://arxiv.org/abs/2408.05457v1)|[link](https://github.com/zhukerui/graph-instruction-tuning)|
|**2024-08-10**|**Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation**|Wenbo Shang et.al.|[2408.05456v1](http://arxiv.org/abs/2408.05456v1)|null|
|**2024-08-10**|**LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification**|Hongde Liu et.al.|[2408.05404v1](http://arxiv.org/abs/2408.05404v1)|[link](https://github.com/wxljz/laida)|
|**2024-08-09**|**Text classification optimization algorithm based on graph neural network**|Erdi Gao et.al.|[2408.15257v1](http://arxiv.org/abs/2408.15257v1)|null|
|**2024-08-09**|**SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions**|Zhi-Qi Cheng et.al.|[2408.05357v1](http://arxiv.org/abs/2408.05357v1)|null|
|**2024-08-09**|**A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**|Ye Yuan et.al.|[2408.05141v3](http://arxiv.org/abs/2408.05141v3)|null|
|**2024-08-09**|**Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning**|Wenbin Hu et.al.|[2408.07091v2](http://arxiv.org/abs/2408.07091v2)|null|
|**2024-08-09**|**HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**|Bhaskarjit Sarmah et.al.|[2408.04948v1](http://arxiv.org/abs/2408.04948v1)|null|
|**2024-08-08**|**DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**|Xin Sun et.al.|[2408.04400v1](http://arxiv.org/abs/2408.04400v1)|null|
|**2024-08-08**|**MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**|Haoxuan Li et.al.|[2408.04388v1](http://arxiv.org/abs/2408.04388v1)|[link](https://github.com/luminosityx/mm-forecast)|
|**2024-08-08**|**Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**|Hsuan-Lei Shao et.al.|[2408.04382v1](http://arxiv.org/abs/2408.04382v1)|null|
|**2024-08-08**|**Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**|Wangying Yang et.al.|[2408.07084v2](http://arxiv.org/abs/2408.07084v2)|null|
|**2024-08-08**|**wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**|Khai Le-Duc et.al.|[2408.04174v1](http://arxiv.org/abs/2408.04174v1)|[link](https://github.com/leduckhai/wav2graph)|
|**2024-08-07**|**ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**|William Y. Zhu et.al.|[2408.04102v1](http://arxiv.org/abs/2408.04102v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v2](http://arxiv.org/abs/2408.03910v2)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**PAGED: A Benchmark for Procedural Graphs Extraction from Documents**|Weihong Du et.al.|[2408.03630v2](http://arxiv.org/abs/2408.03630v2)|[link](https://github.com/scunlp/paged)|
|**2024-08-07**|**Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**|Zaijing Li et.al.|[2408.03615v1](http://arxiv.org/abs/2408.03615v1)|null|
|**2024-08-07**|**Exploring the extent of similarities in software failures across industries using LLMs**|Martin Detloff et.al.|[2408.03528v2](http://arxiv.org/abs/2408.03528v2)|null|
|**2024-08-06**|**Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**|Jinglong Gao et.al.|[2408.03079v1](http://arxiv.org/abs/2408.03079v1)|null|
|**2024-08-06**|**Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**|Daniel Steinigen et.al.|[2408.03010v1](http://arxiv.org/abs/2408.03010v1)|[link](https://github.com/chrschy/fact-finder)|

#### Abstracts
##### **User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study**
2409.06297v1 by Julien Albert, Martin Balfroid, Miriam Doh, Jeremie Bogaert, Luca La Fisca, Liesbet De Vos, Bryan Renard, Vincent Stragier, Emmanuel Jean

Recommender systems have become integral to our digital experiences, from
online shopping to streaming platforms. Still, the rationale behind their
suggestions often remains opaque to users. While some systems employ a
graph-based approach, offering inherent explainability through paths
associating recommended items and seed items, non-experts could not easily
understand these explanations. A popular alternative is to convert graph-based
explanations into textual ones using a template and an algorithm, which we
denote here as ''template-based'' explanations. Yet, these can sometimes come
across as impersonal or uninspiring. A novel method would be to employ large
language models (LLMs) for this purpose, which we denote as ''LLM-based''. To
assess the effectiveness of LLMs in generating more resonant explanations, we
conducted a pilot study with 25 participants. They were presented with three
explanations: (1) traditional template-based, (2) LLM-based rephrasing of the
template output, and (3) purely LLM-based explanations derived from the
graph-based explanations. Although subject to high variance, preliminary
findings suggest that LLM-based explanations may provide a richer and more
engaging user experience, further aligning with user expectations. This study
sheds light on the potential limitations of current explanation methods and
offers promising directions for leveraging large language models to improve
user satisfaction and trust in recommender systems.

摘要：推薦系統已成為我們數位體驗中不可或缺的一部分，從線上購物到串流平台皆是如此。然而，其建議背後的原理通常對使用者來說仍不透明。儘管有些系統採用基於圖形的做法，透過連結推薦項目與種子項目的路徑提供內在的可解釋性，但非專家無法輕易理解這些解釋。一種常見的替代方法是使用範本和演算法將基於圖形的解釋轉換為文字解釋，我們在此將其表示為「基於範本」的解釋。然而，這些解釋有時會顯得制式或缺乏靈感。一種新穎的方法是為此目的採用大型語言模型 (LLM)，我們將其表示為「基於 LLM」。為了評估 LLM 在產生更具共鳴解釋方面的有效性，我們進行了一項有 25 位參與者的試驗研究。我們向他們展示了三種解釋：(1) 傳統基於範本的解釋，(2) LLM 對範本輸出的重新表述，以及 (3) 純粹從基於圖形的解釋衍生的基於 LLM 的解釋。儘管存在高度變異，但初步結果表明，基於 LLM 的解釋可能提供更豐富、更吸引人的使用者體驗，進一步符合使用者的期望。這項研究揭示了當前解釋方法的潛在限制，並為利用大型語言模型來提升使用者滿意度和對推薦系統的信任提供了有希望的方向。

##### **Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity**
2409.06091v1 by Dongyue Li, Aneesh Sharma, Hongyang R. Zhang

Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a "base" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.

摘要：多任務學習是一種廣泛使用的範例，用於在不同的任務上訓練模型，其應用範圍從圖神經網路到語言模型微調。由於任務可能會相互干擾，因此建模它們關係的一個關鍵概念是任務親和性。這包括成對任務親和性，在成對任務之間計算，以及高階親和性，在任務子集之間計算。天真地計算其中任何一個都需要重複訓練來自各種任務組合的資料，這在計算上很密集。我們提出了一種新的演算法 Grad-TAG，它可以在沒有重複訓練的情況下估計任務親和性。
Grad-TAG 的關鍵思想是為所有任務訓練一個「基礎」模型，然後使用線性化技術來估計模型對特定任務組合的損失。線性化通過計算損失的基於梯度的近似值來工作，使用梯度的低維投影作為特徵，在邏輯迴歸中預測任務組合的標籤。我們證明了當基於梯度的近似值準確時，線性化模型可以證明地近似損失，並且在幾個大型模型上經驗驗證了這一點。然後，給定估計的任務親和性，我們設計了一個半定程式，通過最大化叢集的平均密度來對類似的任務進行叢集。
我們評估了 Grad-TAG 在七個資料集上的效能，包括圖形上的多標籤分類，以及語言模型的指令微調。我們的任務親和性估計與真實親和性距離在 2.7% 以內，同時只需要 3% 的 FLOP 進行完整訓練。在我們最大的圖形（有 2100 萬條邊和 500 個標籤任務）上，我們的演算法提供的估計與真實親和性距離在 5% 以內，只使用 112 個 GPU 小時。我們的結果表明，與現有方法相比，Grad-TAG 在效能和執行時間權衡方面取得了優異的表現。

##### **SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning**
2409.05556v1 by Alireza Ghafarollahi, Markus J. Buehler

A key challenge in artificial intelligence is the creation of systems capable
of autonomously advancing scientific understanding by exploring novel domains,
identifying complex patterns, and uncovering previously unseen connections in
vast scientific data. In this work, we present SciAgents, an approach that
leverages three core concepts: (1) the use of large-scale ontological knowledge
graphs to organize and interconnect diverse scientific concepts, (2) a suite of
large language models (LLMs) and data retrieval tools, and (3) multi-agent
systems with in-situ learning capabilities. Applied to biologically inspired
materials, SciAgents reveals hidden interdisciplinary relationships that were
previously considered unrelated, achieving a scale, precision, and exploratory
power that surpasses traditional human-driven research methods. The framework
autonomously generates and refines research hypotheses, elucidating underlying
mechanisms, design principles, and unexpected material properties. By
integrating these capabilities in a modular fashion, the intelligent system
yields material discoveries, critique and improve existing hypotheses, retrieve
up-to-date data about existing research, and highlights their strengths and
limitations. Our case studies demonstrate scalable capabilities to combine
generative AI, ontological representations, and multi-agent modeling,
harnessing a `swarm of intelligence' similar to biological systems. This
provides new avenues for materials discovery and accelerates the development of
advanced materials by unlocking Nature's design principles.

摘要：在人工智能中，一個關鍵的挑戰是創造出有能力透過探索新領域、識別複雜模式，以及在大量的科學數據中發現前所未見的關聯，來自主推進科學理解的系統。在這項工作中，我們提出了 SciAgents，一種利用三個核心概念的方法：(1) 使用大規模的本体知識圖譜來整理和連結不同的科學概念，(2) 一套大型語言模型 (LLM) 和數據檢索工具，以及 (3) 具有原位學習能力的多代理系統。應用於生物啟發材料，SciAgents 揭示了以前被認為無關的隱藏跨學科關係，達到了超越傳統人為研究方法的規模、精確度和探索能力。該框架自主生成和優化研究假設，闡明基礎機制、設計原理和意外的材料特性。透過以模組化方式整合這些能力，智能系統產生材料發現、批判和改進現有假設、檢索關於現有研究的最新數據，並強調它們的優點和限制。我們的案例研究展示了結合生成式 AI、本体表示和多代理建模的可擴充能力，利用類似於生物系統的「智慧群體」。這為材料發現提供了新途徑，並透過解鎖大自然的設計原理來加速先進材料的開發。

##### **Assessing SPARQL capabilities of Large Language Models**
2409.05925v1 by Lars-Peter Meyer, Johannes Frey, Felix Brei, Natanael Arndt

The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.

摘要：大型語言模型 (LLM) 與知識圖譜 (KG) 的整合為知識驅動應用程式提供了顯著的綜效潛力。一種可能的整合是解釋和產生形式化語言，例如語義網路中使用的語言，而 SPARQL 是存取 KG 的核心技術。在本文中，我們專注於衡量 LLM 開箱即用的能力，以使用 SPARQL，更具體地說，使用 SPARQL SELECT 查詢應用量化方法。
  我們在 LLM-KG-Bench 架構中實作了各種基準測試任務，以自動執行和評估多個 LLM。這些任務評估了語法、語義讀取、語義建立和知識圖譜提示包含的角色等面向的能力。
  有了這些新的基準測試任務，我們評估了 GPT、Gemini 和 Claude 模型的選項。我們的研究結果表明，使用 SPARQL SELECT 查詢對於 LLM 來說仍然具有挑戰性，並且在很大程度上取決於具體的 LLM 以及任務的複雜性。儘管修復基本的語法錯誤似乎對目前評估的最佳 LLM 來說不成問題，但在某些情況下建立語義正確的 SPARQL SELECT 查詢很困難。

##### **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**
2409.05370v1 by Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, Luping Zhou

Harnessing the robust capabilities of Large Language Models (LLMs) for
narrative generation, logical reasoning, and common-sense knowledge
integration, this study delves into utilizing LLMs to enhance automated
radiology report generation (R2Gen). Despite the wealth of knowledge within
LLMs, efficiently triggering relevant knowledge within these large models for
specific tasks like R2Gen poses a critical research challenge. This paper
presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration
framework based on LLMs. Utilizing a frozen LLM to generate reports, the
framework integrates a knowledge graph to unlock chest disease-related
knowledge within the LLM to enhance the clinical utility of generated reports.
This is achieved by leveraging the knowledge graph to distill disease-related
features in a designed way. Since a radiology report encompasses both normal
and disease-related findings, the extracted graph-enhanced disease-related
features are integrated with regional image features, attending to both
aspects. We explore two fusion methods to automatically prioritize and select
the most relevant features. The fused features are employed by LLM to generate
reports that are more sensitive to diseases and of improved quality. Our
approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.

摘要：<paragraph>利用大型語言模型 (LLM) 強大的功能，進行敘事生成、邏輯推理和常識知識整合，本研究深入探討利用 LLM 來增強自動化放射報告生成 (R2Gen)。儘管 LLM 擁有豐富的知識，但要有效觸發這些大型模型中與特定任務（如 R2Gen）相關的知識，是一個重要的研究挑戰。本文提出了 KARGEN，一個基於 LLM 的知識增強自動化放射報告生成框架。利用凍結的 LLM 來生成報告，該框架整合了一個知識圖譜，以解鎖 LLM 中與胸部疾病相關的知識，以增強生成報告的臨床效用。這是透過利用知識圖譜以設計的方式提取與疾病相關的特徵來實現的。由於放射報告包含正常和疾病相關的發現，因此提取的圖形增強疾病相關特徵與區域影像特徵整合，兼顧兩個方面。我們探索了兩種融合方法，以自動優先排序和選擇最相關的特徵。融合的特徵由 LLM 使用，以生成對疾病更敏感且品質更高的報告。我們的做法在 MIMIC-CXR 和 IU-Xray 資料集上展示了有希望的結果。</paragraph>

##### **Action is the primary key: a categorical framework for episode description and logical reasoning**
2409.04793v1 by Yoshiki Fukada

This research presents a computational framework for describing and
recognizing episodes and for logical reasoning. This framework, named
cognitive-logs, consists of a set of relational and graph databases.
Cognitive-logs record knowledge, particularly in episodes that consist of
"actions" represented by verbs in natural languages and "participants" who
perform the actions. These objects are connected by arrows (morphisms) that
link each action to its participant and link cause to effect. Operations based
on category theory enable comparisons between episodes and deductive
inferences, including abstractions of stories. One of the goals of this study
is to develop a database-driven artificial intelligence. This artificial
intelligence thinks like a human but possesses the accuracy and rigour of a
machine. The vast capacities of databases (up to petabyte scales in current
technologies) enable the artificial intelligence to store a greater volume of
knowledge than neural-network based artificial intelligences. Cognitive-logs
serve as a model of human cognition and designed with references to cognitive
linguistics. Cognitive-logs also have the potential to model various human mind
activities.

摘要：本研究提出一個計算框架，用來描述和辨識事件以及進行邏輯推理。這個框架名為認知日誌，包含一組關聯式和圖形資料庫。認知日誌記錄知識，特別是包含由自然語言中的動詞表示的「動作」和執行動作的「參與者」的事件。這些物件由箭頭（態射）連接，將每個動作連結到其參與者，並將原因連結到結果。基於範疇論的運算可比較事件和演繹推論，包括故事的抽象化。本研究的目標之一是開發一個資料庫驅動的人工智慧。這個人工智慧思考方式像人類，但擁有機器般的準確性和嚴謹性。資料庫的龐大容量（在目前的技術中可達皮位元組等級）使人工智慧能夠儲存比基於神經網路的人工智慧更大的知識量。認知日誌作為人類認知的模型，並參考認知語言學進行設計。認知日誌也有潛力模擬各種人類心智活動。

##### **Accelerating Training with Neuron Interaction and Nowcasting Networks**
2409.04434v1 by Boris Knyazev, Abhinav Moudgil, Guillaume Lajoie, Eugene Belilovsky, Simon Lacoste-Julien

Neural network training can be accelerated when a learnable update rule is
used in lieu of classic adaptive optimizers (e.g. Adam). However, learnable
update rules can be costly and unstable to train and use. A simpler recently
proposed approach to accelerate training is to use Adam for most of the
optimization steps and periodically, only every few steps, nowcast (predict
future) parameters. We improve this approach by Neuron interaction and
Nowcasting (NiNo) networks. NiNo leverages neuron connectivity and graph neural
networks to more accurately nowcast parameters by learning in a supervised way
from a set of training trajectories over multiple tasks. We show that in some
networks, such as Transformers, neuron connectivity is non-trivial. By
accurately modeling neuron connectivity, we allow NiNo to accelerate Adam
training by up to 50\% in vision and language tasks.

摘要：神经网络训练可以加速，当一个可学习的更新规则被用来代替经典的自适应优化器（例如 Adam）。然而，可学习的更新规则可能是昂贵且不稳定的，需要训练和使用。一种最近提出的更简单的加速训练的方法是，对于大多数的优化步骤使用 Adam，并且定期地，仅每隔几步，预测（预测未来）参数。我们通过神经元交互和预测（NiNo）网络来改进这种方法。NiNo 利用神经元连接和图神经网络，通过从多个任务中的一组训练轨迹中以监督方式学习，更准确地预测参数。我们表明，在一些网络中，例如 Transformer，神经元连接是非平凡的。通过准确地建模神经元连接，我们允许 NiNo 将 Adam 训练加速高达 50%，用于视觉和语言任务。

##### **Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets**
2409.04286v1 by Desiree Heim, Christian Jilek, Adrian Ulges, Andreas Dengel

Current publicly available knowledge work data collections lack diversity,
extensive annotations, and contextual information about the users and their
documents. These issues hinder objective and comparable data-driven evaluations
and optimizations of knowledge work assistance systems. Due to the considerable
resources needed to collect such data in real-life settings and the necessity
of data censorship, collecting such a dataset appears nearly impossible. For
this reason, we propose a configurable, multi-agent knowledge work dataset
generator. This system simulates collaborative knowledge work among agents
producing Large Language Model-generated documents and accompanying data
traces. Additionally, the generator captures all background information, given
in its configuration or created during the simulation process, in a knowledge
graph. Finally, the resulting dataset can be utilized and shared without
privacy or confidentiality concerns.
  This paper introduces our approach's design and vision and focuses on
generating authentic knowledge work documents using Large Language Models. Our
study involving human raters who assessed 53% of the generated and 74% of the
real documents as realistic demonstrates the potential of our approach.
Furthermore, we analyze the authenticity criteria mentioned in the
participants' comments and elaborate on potential improvements for identified
common issues.

摘要：<paragraph>目前公開可用的知識工作資料蒐集缺乏多元性、廣泛註解和使用者及其文件背景資訊。這些問題阻礙了客觀且可比較的資料驅動評估，以及知識工作協助系統的最佳化。由於在現實生活中蒐集此類資料需要大量資源，而且必須審查資料，蒐集此類資料組顯然幾乎不可能。因此，我們提出一個可設定的多重代理知識工作資料組產生器。此系統模擬代理之間的協作知識工作，產生大型語言模型產生的文件和隨附的資料追蹤。此外，產生器會擷取所有背景資訊，在組態中提供或在模擬過程中建立，並將其儲存在知識圖譜中。最後，產生的資料組可以使用和分享，無須擔心隱私或機密性。
本文介紹我們方法的設計和願景，並專注於使用大型語言模型產生真實的知識工作文件。我們的研究涉及人類評分員，他們評估了 53% 的產生文件和 74% 的真實文件為真實，這證明了我們方法的潛力。此外，我們分析參與者評論中提到的真實性標準，並詳細說明已識別常見問題的潛在改善方法。</paragraph>

##### **GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding**
2409.04183v1 by Ziyin Zhang, Hang Yu, Shijie Li, Peng Di, Jianguo Li, Rui Wang

Programming languages possess rich semantic information such as data flow
that is represented by graphs and not available from the surface form of source
code. Recent code language models have scaled to billions of parameters, but
model source code solely as text tokens while ignoring any other structural
information. Conversely, models that do encode structural information of code
make modifications to the Transformer architecture, limiting their scale and
compatibility with pretrained LLMs. In this work, we take the best of both
worlds with GALLa - Graph Aligned Large Language Model. GALLa utilizes graph
neural networks and cross-modal alignment technologies to inject the structural
information of code into LLMs as an auxiliary task during finetuning. This
framework is both model-agnostic and task-agnostic, as it can be applied to any
code LLM for any code downstream task, and requires the structural graph data
only at training time from a corpus unrelated to the finetuning data, while
incurring no cost at inference time over the baseline LLM. Experiments on five
code tasks with four different baseline LLMs ranging in size from 350M to 8B
validate the effectiveness of GALLa, demonstrating consistent improvement over
the baseline, even for powerful models such as LLaMA3.

摘要：程式語言擁有豐富的語意資訊，例如由圖形表示且無法從原始碼表面形式取得的資料流程。最近的程式碼語言模型已擴充至數十億個參數，但模型原始碼僅作為文字符號，而忽略任何其他結構資訊。反之，編碼程式碼結構資訊的模型會修改 Transformer 架構，限制其規模和與預先訓練的 LLM 的相容性。在這項工作中，我們採用 GALLa（圖形對齊大型語言模型）擷取兩全其美的優點。GALLa 利用圖形神經網路和跨模態對齊技術，在微調期間將程式碼的結構資訊注入 LLM 作為輔助任務。此架構同時不依賴模型和任務，因為它可以應用於任何程式碼 LLM 的任何程式碼下游任務，並且僅在訓練期間從與微調資料無關的語料庫取得結構圖形資料，同時在推論期間不產生比基準 LLM 更高的成本。在五個程式碼任務中進行實驗，使用四個不同的基準 LLM，規模從 350M 到 8B，驗證 GALLa 的有效性，證明即使對於 LLaMA3 等強大模型，也能持續優於基準。

##### **Combining LLMs and Knowledge Graphs to Reduce Hallucinations in Question Answering**
2409.04181v1 by Larissa Pusch, Tim O. F. Conrad

Advancements in natural language processing have revolutionized the way we
can interact with digital information systems, such as databases, making them
more accessible. However, challenges persist, especially when accuracy is
critical, as in the biomedical domain. A key issue is the hallucination
problem, where models generate information unsupported by the underlying data,
potentially leading to dangerous misinformation. This paper presents a novel
approach designed to bridge this gap by combining Large Language Models (LLM)
and Knowledge Graphs (KG) to improve the accuracy and reliability of
question-answering systems, on the example of a biomedical KG. Built on the
LangChain framework, our method incorporates a query checker that ensures the
syntactical and semantic validity of LLM-generated queries, which are then used
to extract information from a Knowledge Graph, substantially reducing errors
like hallucinations. We evaluated the overall performance using a new benchmark
dataset of 50 biomedical questions, testing several LLMs, including GPT-4 Turbo
and llama3:70b. Our results indicate that while GPT-4 Turbo outperforms other
models in generating accurate queries, open-source models like llama3:70b show
promise with appropriate prompt engineering. To make this approach accessible,
a user-friendly web-based interface has been developed, allowing users to input
natural language queries, view generated and corrected Cypher queries, and
verify the resulting paths for accuracy. Overall, this hybrid approach
effectively addresses common issues such as data gaps and hallucinations,
offering a reliable and intuitive solution for question answering systems. The
source code for generating the results of this paper and for the user-interface
can be found in our Git repository: https://git.zib.de/lpusch/cyphergenkg-gui

摘要：自然語言處理的進展徹底改變了我們與數位資訊系統（例如資料庫）互動的方式，讓這些系統變得更易於存取。然而，挑戰仍然存在，尤其是在準確性至關重要的情況下，例如在生物醫學領域。一個關鍵問題是幻覺問題，其中模型會產生未經基礎資料驗證的資訊，可能導致危險的錯誤資訊。本文提出了一種新穎的方法，旨在透過結合大型語言模型 (LLM) 和知識圖譜 (KG) 來彌補這個差距，以提高生物醫學 KG 中問答系統的準確性和可靠性。我們的技術建立在 LangChain 框架上，結合了一個查詢檢查器，可確保 LLM 生成的查詢在語法和語意上有效，然後用於從知識圖譜中萃取資訊，大幅減少幻覺等錯誤。我們使用一個新的 50 個生物醫學問題基準資料集評估了整體效能，測試了包括 GPT-4 Turbo 和 llama3:70b 在內的幾個 LLM。我們的結果顯示，雖然 GPT-4 Turbo 在產生準確查詢方面優於其他模型，但像 llama3:70b 這樣的開源模型在適當的提示工程下顯示出前景。為了讓這種方法易於使用，我們開發了一個使用者友善的網路介面，讓使用者可以輸入自然語言查詢、檢視產生和更正的 Cypher 查詢，並驗證結果路徑的準確性。總體而言，這種混合方法有效地解決了資料差距和幻覺等常見問題，為問答系統提供了一個可靠且直觀的解決方案。本文結果產生的原始碼和使用者介面的原始碼可以在我們的 Git 儲存庫中找到：https://git.zib.de/lpusch/cyphergenkg-gui

##### **Refining Wikidata Taxonomy using Large Language Models**
2409.04056v1 by Yiwen Peng, Thomas Bonald, Mehwish Alam

Due to its collaborative nature, Wikidata is known to have a complex
taxonomy, with recurrent issues like the ambiguity between instances and
classes, the inaccuracy of some taxonomic paths, the presence of cycles, and
the high level of redundancy across classes. Manual efforts to clean up this
taxonomy are time-consuming and prone to errors or subjective decisions. We
present WiKC, a new version of Wikidata taxonomy cleaned automatically using a
combination of Large Language Models (LLMs) and graph mining techniques.
Operations on the taxonomy, such as cutting links or merging classes, are
performed with the help of zero-shot prompting on an open-source LLM. The
quality of the refined taxonomy is evaluated from both intrinsic and extrinsic
perspectives, on a task of entity typing for the latter, showing the practical
interest of WiKC.

摘要：由於其協作性質，Wikidata 已知具有複雜的分類法，並有重複發生的問題，例如實例和類別之間的歧義、某些分類路徑的不準確性、循環的存在，以及類別之間的高冗餘。手動清理此分類法的工作既耗時又容易出現錯誤或主觀判斷。我們提出 WiKC，這是 Wikidata 分類法的新版本，使用大型語言模型 (LLM) 和圖形挖掘技術自動清理。分類法上的操作，例如剪切鏈接或合併類別，是在開源 LLM 上借助零次提示的幫助下執行的。精煉分類法的品質從內在和外在的觀點進行評估，在後者的實體分型任務上，顯示了 WiKC 的實際興趣。

##### **Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features**
2409.04009v1 by Miao Fan, Yeqi Bai, Mingming Sun, Ping Li

Relation classification (RC) plays a pivotal role in both natural language
understanding and knowledge graph completion. It is generally formulated as a
task to recognize the relationship between two entities of interest appearing
in a free-text sentence. Conventional approaches on RC, regardless of feature
engineering or deep learning based, can obtain promising performance on
categorizing common types of relation leaving a large proportion of
unrecognizable long-tail relations due to insufficient labeled instances for
training. In this paper, we consider few-shot learning is of great practical
significance to RC and thus improve a modern framework of metric learning for
few-shot RC. Specifically, we adopt the large-margin ProtoNet with fine-grained
features, expecting they can generalize well on long-tail relations. Extensive
experiments were conducted by FewRel, a large-scale supervised few-shot RC
dataset, to evaluate our framework: LM-ProtoNet (FGF). The results demonstrate
that it can achieve substantial improvements over many baseline approaches.

摘要：關係分類 (RC) 在自然語言理解和知識圖譜完成中扮演著關鍵角色。它通常被表述為一個任務，用於辨識出現在自由文字句子中的兩個感興趣實體之間的關係。無論是基於特徵工程還是深度學習的傳統 RC 方法，都可以對常見的關係類型進行分類，從而獲得有希望的效能，但由於訓練標籤實例不足，因此無法辨識出大量的長尾關係。在本文中，我們認為少樣本學習對 RC 具有重要的實用意義，因此改進了度量學習的現代框架，以進行少樣本 RC。具體來說，我們採用具有細粒度特徵的大邊距 ProtoNet，期望它們能在長尾關係上很好地概括。我們使用大型監督少樣本 RC 資料集 FewRel 進行了廣泛的實驗，以評估我們的框架：LM-ProtoNet (FGF)。結果表明，它可以比許多基線方法獲得顯著改進。

##### **Rx Strategist: Prescription Verification using LLM Agents System**
2409.03440v1 by Phuc Phan Van, Dat Nguyen Minh, An Dinh Ngoc, Huy Phan Thanh

To protect patient safety, modern pharmaceutical complexity demands strict
prescription verification. We offer a new approach - Rx Strategist - that makes
use of knowledge graphs and different search strategies to enhance the power of
Large Language Models (LLMs) inside an agentic framework. This multifaceted
technique allows for a multi-stage LLM pipeline and reliable information
retrieval from a custom-built active ingredient database. Different facets of
prescription verification, such as indication, dose, and possible drug
interactions, are covered in each stage of the pipeline. We alleviate the
drawbacks of monolithic LLM techniques by spreading reasoning over these
stages, improving correctness and reliability while reducing memory demands.
Our findings demonstrate that Rx Strategist surpasses many current LLMs,
achieving performance comparable to that of a highly experienced clinical
pharmacist. In the complicated world of modern medications, this combination of
LLMs with organized knowledge and sophisticated search methods presents a
viable avenue for reducing prescription errors and enhancing patient outcomes.

摘要：為了保護患者安全，現代藥品複雜性要求嚴格的處方驗證。我們提供一種新方法 - Rx Strategist - 它利用知識圖譜和不同的搜尋策略來增強代理架構內大型語言模型 (LLM) 的功能。這種多方面的技術允許多階段的 LLM 管線和從自訂主動成分資料庫中可靠地擷取資訊。處方驗證的不同面向，例如適應症、劑量和可能的藥物交互作用，都在管線的每個階段中涵蓋。我們透過將推理分散在這些階段來減輕單一 LLM 技術的缺點，同時提高正確性和可靠性，並減少記憶體需求。我們的研究結果表明，Rx Strategist 超越許多現有的 LLM，達到與經驗豐富的臨床藥劑師相當的表現。在現代藥物複雜的世界中，這種將 LLM 與有組織的知識和先進搜尋方法相結合，為減少處方錯誤和改善患者預後提供了可行的途徑。

##### **iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models**
2409.03284v1 by Yassir Lairgi, Ludovic Moncla, Rémy Cazabet, Khalid Benabdeslem, Pierre Cléau

Most available data is unstructured, making it challenging to access valuable
information. Automatically building Knowledge Graphs (KGs) is crucial for
structuring data and making it accessible, allowing users to search for
information effectively. KGs also facilitate insights, inference, and
reasoning. Traditional NLP methods, such as named entity recognition and
relation extraction, are key in information retrieval but face limitations,
including the use of predefined entity types and the need for supervised
learning. Current research leverages large language models' capabilities, such
as zero- or few-shot learning. However, unresolved and semantically duplicated
entities and relations still pose challenges, leading to inconsistent graphs
and requiring extensive post-processing. Additionally, most approaches are
topic-dependent. In this paper, we propose iText2KG, a method for incremental,
topic-independent KG construction without post-processing. This plug-and-play,
zero-shot method is applicable across a wide range of KG construction scenarios
and comprises four modules: Document Distiller, Incremental Entity Extractor,
Incremental Relation Extractor, and Graph Integrator and Visualization. Our
method demonstrates superior performance compared to baseline methods across
three scenarios: converting scientific papers to graphs, websites to graphs,
and CVs to graphs.

摘要：大部分可用資料為非結構化，這使得存取有價值的資訊變得具有挑戰性。自動建立知識圖譜 (KG) 對於結構化資料和讓資料易於存取至關重要，讓使用者能夠有效地搜尋資訊。KG 也促進見解、推論和推理。傳統的 NLP 方法，例如命名實體辨識和關係萃取，在資訊檢索中是關鍵，但面臨限制，包括使用預定義的實體類型和需要監督式學習。目前的研究所利用大型語言模型的能力，例如零次或少次學習。然而，未解決和語義重複的實體和關係仍然構成挑戰，導致圖形不一致，需要廣泛的後處理。此外，大多數方法都依賴於主題。在本文中，我們提出 iText2KG，一種用於漸進式、與主題無關的 KG 建構方法，無需後處理。這種即插即用、零次的方法適用於廣泛的 KG 建構場景，並包含四個模組：文件精餾器、漸進式實體萃取器、漸進式關係萃取器，以及圖形整合器和視覺化器。與基線方法相比，我們的模型在三種場景中展現出卓越的效能：將科學論文轉換為圖形、網站轉換為圖形，以及履歷轉換為圖形。

##### **GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding**
2409.03258v1 by Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S. Kevin Zhou

Although Large Language Models (LLMs) have demonstrated potential in
processing graphs, they struggle with comprehending graphical structure
information through prompts of graph description sequences, especially as the
graph size increases. We attribute this challenge to the uneven memory
performance of LLMs across different positions in graph description sequences,
known as ''positional biases''. To address this, we propose GraphInsight, a
novel framework aimed at improving LLMs' comprehension of both macro- and
micro-level graphical information. GraphInsight is grounded in two key
strategies: 1) placing critical graphical information in positions where LLMs
exhibit stronger memory performance, and 2) investigating a lightweight
external knowledge base for regions with weaker memory performance, inspired by
retrieval-augmented generation (RAG). Moreover, GraphInsight explores
integrating these two strategies into LLM agent processes for composite graph
tasks that require multi-step reasoning. Extensive empirical studies on
benchmarks with a wide range of evaluation tasks show that GraphInsight
significantly outperforms all other graph description methods (e.g., prompting
techniques and reordering strategies) in understanding graph structures of
varying sizes.

摘要：儘管大型語言模型 (LLM) 已展現出處理圖形的能力，但它們在透過圖形描述序列提示理解圖形結構資訊時會遇到困難，特別是在圖形大小增加時。我們將此挑戰歸因於 LLM 在圖形描述序列中不同位置的記憶力表現不均，稱為「位置偏誤」。為了解決這個問題，我們提出了 GraphInsight，一個旨在改善 LLM 對巨觀和微觀層級圖形資訊理解的新框架。GraphInsight 以兩個關鍵策略為基礎：1) 將關鍵圖形資訊放置在 LLM 展現較強記憶力表現的位置，以及 2) 調查一個受到檢索增強生成 (RAG) 啟發的、針對記憶力表現較弱區域的輕量級外部知識庫。此外，GraphInsight 探索將這兩個策略整合到 LLM 代理程序中，以處理需要多步驟推理的複合圖形任務。在具有廣泛評量任務的基準上進行的廣泛實證研究顯示，GraphInsight 在理解各種大小的圖形結構方面，明顯優於所有其他圖形描述方法（例如提示技巧和重新排序策略）。

##### **Debate on Graph: a Flexible and Reliable Reasoning Framework for Large Language Models**
2409.03155v1 by Jie Ma, Zhitao Gao, Qi Chai, Wangchun Sun, Pinghui Wang, Hongbin Pei, Jing Tao, Lingyun Song, Jun Liu, Chen Zhang, Lizhen Cui

Large Language Models (LLMs) may suffer from hallucinations in real-world
applications due to the lack of relevant knowledge. In contrast, knowledge
graphs encompass extensive, multi-relational structures that store a vast array
of symbolic facts. Consequently, integrating LLMs with knowledge graphs has
been extensively explored, with Knowledge Graph Question Answering (KGQA)
serving as a critical touchstone for the integration. This task requires LLMs
to answer natural language questions by retrieving relevant triples from
knowledge graphs. However, existing methods face two significant challenges:
\textit{excessively long reasoning paths distracting from the answer
generation}, and \textit{false-positive relations hindering the path
refinement}. In this paper, we propose an iterative interactive KGQA framework
that leverages the interactive learning capabilities of LLMs to perform
reasoning and Debating over Graphs (DoG). Specifically, DoG employs a
subgraph-focusing mechanism, allowing LLMs to perform answer trying after each
reasoning step, thereby mitigating the impact of lengthy reasoning paths. On
the other hand, DoG utilizes a multi-role debate team to gradually simplify
complex questions, reducing the influence of false-positive relations. This
debate mechanism ensures the reliability of the reasoning process. Experimental
results on five public datasets demonstrate the effectiveness and superiority
of our architecture. Notably, DoG outperforms the state-of-the-art method ToG
by 23.7\% and 9.1\% in accuracy on WebQuestions and GrailQA, respectively.
Furthermore, the integration experiments with various LLMs on the mentioned
datasets highlight the flexibility of DoG. Code is available at
\url{https://github.com/reml-group/DoG}.

摘要：<paragraph>大型語言模型 (LLM) 由於缺乏相關知識，在實際應用中可能會產生幻覺。相較之下，知識圖譜包含廣泛的多重關係結構，儲存大量符號事實。因此，將 LLM 與知識圖譜整合已廣泛探討，其中知識圖譜問題解答 (KGQA) 成為整合的重要試金石。此任務要求 LLM 透過從知識圖譜中擷取相關三元組來回答自然語言問題。然而，現有方法面臨兩項重大挑戰：\textit{過長的推理路徑會分散回答產生}，以及\textit{錯誤正向關係阻礙路徑精煉}。在本文中，我們提出一個反覆互動的 KGQA 框架，它利用 LLM 的互動學習能力來執行推理和圖形辯論 (DoG)。具體來說，DoG 採用子圖聚焦機制，允許 LLM 在每個推理步驟後執行答案嘗試，從而減輕冗長推理路徑的影響。另一方面，DoG 利用多角色辯論小組逐漸簡化複雜問題，減少錯誤正向關係的影響。這種辯論機制確保了推理過程的可靠性。在五個公共數據集上的實驗結果證明了我們架構的有效性和優越性。值得注意的是，DoG 在 WebQuestions 和 GrailQA 上的準確度分別比最先進的方法 ToG 高出 23.7% 和 9.1%。此外，在上述數據集上與各種 LLM 的整合實驗突顯了 DoG 的靈活性。程式碼可在\url{https://github.com/reml-group/DoG}取得。</paragraph>

##### **Word and Phrase Features in Graph Convolutional Network for Automatic Question Classification**
2409.02481v1 by Junyoung Lee, Ninad Dixit, Kaustav Chakrabarti, S. Supraja

Effective question classification is crucial for AI-driven educational tools,
enabling adaptive learning systems to categorize questions by skill area,
difficulty level, and competence. This classification not only supports
educational diagnostics and analytics but also enhances complex tasks like
information retrieval and question answering by associating questions with
relevant categories. Traditional methods, often based on word embeddings and
conventional classifiers, struggle to capture the nuanced relationships in
natural language, leading to suboptimal performance. To address this, we
propose a novel approach leveraging graph convolutional networks (GCNs), named
Phrase Question-Graph Convolutional Network (PQ-GCN) to better model the
inherent structure of questions. By representing questions as graphs -- where
nodes signify words or phrases and edges denote syntactic or semantic
relationships -- our method allows GCNs to learn from the interconnected nature
of language more effectively. Additionally, we explore the incorporation of
phrase-based features to enhance classification accuracy, especially in
low-resource settings. Our findings demonstrate that GCNs, augmented with these
features, offer a promising solution for more accurate and context-aware
question classification, bridging the gap between graph neural network research
and practical educational applications.

摘要：有效的問題分類對於 AI 驅動的教育工具至關重要，
讓適應性學習系統能依據技能領域、
難度等級和能力對問題進行分類。這種分類不僅支援
教育診斷和分析，還能透過將問題與
相關類別關聯起來，增強資訊檢索和問題解答等複雜任務。傳統方法通常建立在詞嵌入和
傳統分類器上，難以捕捉自然語言中的細微關係，導致次佳效能。為了解決這個問題，我們
提出了一種創新的方法，利用圖形卷積網路 (GCN)，稱為
Phrase Question-Graph Convolutional Network (PQ-GCN) 來更好地建模問題的內在結構。透過將問題表示為圖形——其中
節點表示詞或詞組，邊緣表示語法或語義關係——我們的模型允許 GCN 更有效地從語言的相互連結性質中學習。此外，我們探索了整合
基於詞組的特徵以增強分類準確度，特別是在
低資源設定中。我們的研究結果表明，GCN 在這些
特徵的增強下，為更準確且具備情境感知能力的問題分類提供了一個有前途的解決方案，縮小了圖形神經網路研究
與實際教育應用之間的差距。

##### **Multi-modal Situated Reasoning in 3D Scenes**
2409.02389v1 by Xiongkun Linghu, Jiangyong Huang, Xuesong Niu, Xiaojian Ma, Baoxiong Jia, Siyuan Huang

Situation awareness is essential for understanding and reasoning about 3D
scenes in embodied AI agents. However, existing datasets and benchmarks for
situated understanding are limited in data modality, diversity, scale, and task
scope. To address these limitations, we propose Multi-modal Situated Question
Answering (MSQA), a large-scale multi-modal situated reasoning dataset,
scalably collected leveraging 3D scene graphs and vision-language models (VLMs)
across a diverse range of real-world 3D scenes. MSQA includes 251K situated
question-answering pairs across 9 distinct question categories, covering
complex scenarios within 3D scenes. We introduce a novel interleaved
multi-modal input setting in our benchmark to provide text, image, and point
cloud for situation and question description, resolving ambiguity in previous
single-modality convention (e.g., text). Additionally, we devise the
Multi-modal Situated Next-step Navigation (MSNN) benchmark to evaluate models'
situated reasoning for navigation. Comprehensive evaluations on MSQA and MSNN
highlight the limitations of existing vision-language models and underscore the
importance of handling multi-modal interleaved inputs and situation modeling.
Experiments on data scaling and cross-domain transfer further demonstrate the
efficacy of leveraging MSQA as a pre-training dataset for developing more
powerful situated reasoning models.

摘要：情境感知對於理解和推理具身 AI 代理中的 3D 場景至關重要。然而，現有的資料集和基準在資料模態、多樣性、規模和任務範圍方面對於情境理解來說是有限的。為了解決這些限制，我們提出了多模態情境問答 (MSQA)，這是一個大型多模態情境推理資料集，可透過利用 3D 場景圖和視覺語言模型 (VLM) 在各種真實世界 3D 場景中進行可擴充收集。MSQA 包含 251K 個情境問答對，涵蓋 9 個不同的問題類別，涵蓋 3D 場景中的複雜場景。我們在基準中引入了一種新穎的交錯多模態輸入設定，以提供文字、影像和點雲，用於情境和問題描述，解決以前單一模態慣例（例如文字）中的歧義。此外，我們設計了多模態情境下一步導航 (MSNN) 基準，以評估模型的導航情境推理。MSQA 和 MSNN 的綜合評估突顯了現有視覺語言模型的限制，並強調了處理多模態交錯輸入和情境建模的重要性。資料擴充和跨領域轉移的實驗進一步證明了利用 MSQA 作為預訓練資料集來開發更強大的情境推理模型的有效性。

##### **Grounding Language Models in Autonomous Loco-manipulation Tasks**
2409.01326v1 by Jin Wang, Nikos Tsagarakis

Humanoid robots with behavioral autonomy have consistently been regarded as
ideal collaborators in our daily lives and promising representations of
embodied intelligence. Compared to fixed-based robotic arms, humanoid robots
offer a larger operational space while significantly increasing the difficulty
of control and planning. Despite the rapid progress towards general-purpose
humanoid robots, most studies remain focused on locomotion ability with few
investigations into whole-body coordination and tasks planning, thus limiting
the potential to demonstrate long-horizon tasks involving both mobility and
manipulation under open-ended verbal instructions. In this work, we propose a
novel framework that learns, selects, and plans behaviors based on tasks in
different scenarios. We combine reinforcement learning (RL) with whole-body
optimization to generate robot motions and store them into a motion library. We
further leverage the planning and reasoning features of the large language
model (LLM), constructing a hierarchical task graph that comprises a series of
motion primitives to bridge lower-level execution with higher-level planning.
Experiments in simulation and real-world using the CENTAURO robot show that the
language model based planner can efficiently adapt to new loco-manipulation
tasks, demonstrating high autonomy from free-text commands in unstructured
scenes.

摘要：具有行為自主權的人形機器人一直被視為我們日常生活中理想的合作者，也是具體智能的有希望的代表。與固定式機器手臂相比，人形機器人提供了更大的操作空間，同時顯著增加了控制和規劃的難度。儘管朝著通用人形機器人快速發展，但大多數研究仍然集中在運動能力上，很少研究全身協調和任務規劃，從而限制了展示涉及移動和操作的長期任務的潛力，同時還能接受開放式口頭指令。在這項工作中，我們提出了一個新的框架，該框架可以根據不同場景中的任務學習、選擇和規劃行為。我們將強化學習 (RL) 與全身優化相結合，以生成機器人動作並將其存儲到動作庫中。我們進一步利用大型語言模型 (LLM) 的規劃和推理功能，構建了一個分層任務圖，其中包含一系列運動原語，以橋接低級執行和高級規劃。在模擬和使用 CENTAURO 機器人的現實世界中的實驗表明，基於語言模型的規劃器可以有效適應新的運動操作任務，證明了在非結構化場景中從自由文本命令中獲得的高度自主性。

##### **LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning**
2409.01145v1 by Haoran Yang, Xiangyu Zhao, Sirui Huang, Qing Li, Guandong Xu

Graph Contrastive Learning (GCL) is a potent paradigm for self-supervised
graph learning that has attracted attention across various application
scenarios. However, GCL for learning on Text-Attributed Graphs (TAGs) has yet
to be explored. Because conventional augmentation techniques like feature
embedding masking cannot directly process textual attributes on TAGs. A naive
strategy for applying GCL to TAGs is to encode the textual attributes into
feature embeddings via a language model and then feed the embeddings into the
following GCL module for processing. Such a strategy faces three key
challenges: I) failure to avoid information loss, II) semantic loss during the
text encoding phase, and III) implicit augmentation constraints that lead to
uncontrollable and incomprehensible results. In this paper, we propose a novel
GCL framework named LATEX-GCL to utilize Large Language Models (LLMs) to
produce textual augmentations and LLMs' powerful natural language processing
(NLP) abilities to address the three limitations aforementioned to pave the way
for applying GCL to TAG tasks. Extensive experiments on four high-quality TAG
datasets illustrate the superiority of the proposed LATEX-GCL method. The
source codes and datasets are released to ease the reproducibility, which can
be accessed via this link: https://anonymous.4open.science/r/LATEX-GCL-0712.

摘要：圖形對比學習 (GCL) 是自監督圖形學習的強大範例，已在各種應用場景中引起關注。然而，GCL 對於在文本註解圖形 (TAG) 上學習尚未被探討。因為特徵嵌入遮罩等傳統擴充技術無法直接處理 TAG 上的文本屬性。將 GCL 應用於 TAG 的一種天真策略是通過語言模型將文本屬性編碼到特徵嵌入中，然後將嵌入輸入後續的 GCL 模組進行處理。這種策略面臨三個關鍵挑戰：I) 無法避免資訊遺失，II) 在文本編碼階段發生語義遺失，以及 III) 導致無法控制且難以理解結果的隱式擴充約束。在本文中，我們提出一個名為 LATEX-GCL 的新穎 GCL 框架，利用大型語言模型 (LLM) 來產生文本擴充，以及 LLM 強大的自然語言處理 (NLP) 能力來解決上述三個限制，為將 GCL 應用於 TAG 任務鋪平道路。在四個高品質 TAG 資料集上的大量實驗說明了所提出的 LATEX-GCL 方法的優越性。原始碼和資料集已發布以簡化可重製性，可透過此連結存取：https://anonymous.4open.science/r/LATEX-GCL-0712。

##### **Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering**
2409.00861v1 by Derian Boer, Fabian Koch, Stefan Kramer

Large Language Models (LLMs) frequently lack domain-specific knowledge and
even fine-tuned models tend to hallucinate. Hence, more reliable models that
can include external knowledge are needed. We present a pipeline, 4StepFocus,
and specifically a preprocessing step, that can substantially improve the
answers of LLMs. This is achieved by providing guided access to external
knowledge making use of the model's ability to capture relational context and
conduct rudimentary reasoning by themselves. The method narrows down
potentially correct answers by triplets-based searches in a semi-structured
knowledge base in a direct, traceable fashion, before switching to latent
representations for ranking those candidates based on unstructured data. This
distinguishes it from related methods that are purely based on latent
representations. 4StepFocus consists of the steps: 1) Triplet generation for
extraction of relational data by an LLM, 2) substitution of variables in those
triplets to narrow down answer candidates employing a knowledge graph, 3)
sorting remaining candidates with a vector similarity search involving
associated non-structured data, 4) reranking the best candidates by the LLM
with background data provided. Experiments on a medical, a product
recommendation, and an academic paper search test set demonstrate that this
approach is indeed a powerful augmentation. It not only adds relevant traceable
background information from information retrieval, but also improves
performance considerably in comparison to state-of-the-art methods. This paper
presents a novel, largely unexplored direction and therefore provides a wide
range of future work opportunities. Used source code is available at
https://github.com/kramerlab/4StepFocus.

摘要：大型語言模型 (LLM) 經常缺乏特定領域的知識，即使經過微調的模型也容易產生幻覺。因此，需要更多可靠的模型來納入外部知識。我們提出了一個流程 4StepFocus，特別是預處理步驟，可以大幅改善 LLM 的答案。這是透過提供受引導的外部知識存取，利用模型自行擷取關聯性脈絡和進行基本推理的能力來實現的。此方法透過在半結構化知識庫中進行基於三元組的搜尋，以直接且可追蹤的方式縮小潛在正確答案的範圍，然後再切換到潛在表徵，根據非結構化資料對這些候選答案進行排名。這與純粹基於潛在表徵的相關方法有所區別。4StepFocus 包含以下步驟：1) 由 LLM 進行三元組產生以擷取關聯資料，2) 在這些三元組中替換變數，以採用知識圖表縮小答案候選範圍，3) 使用涉及關聯非結構化資料的向量相似性搜尋對剩餘候選答案進行排序，4) 由 LLM 重新對最佳候選答案進行排名，並提供背景資料。在醫療、產品推薦和學術論文搜尋測試集中進行的實驗證明，這種方法確實是一種強大的擴充。它不僅增加了來自資訊檢索的相关可追蹤背景資訊，而且與最先進的方法相比，也大幅提升了效能。本文提出了一個新穎且鮮少探索的方向，因此提供了廣泛的未來工作機會。使用的原始碼可在 https://github.com/kramerlab/4StepFocus 取得。

##### **Building FKG.in: a Knowledge Graph for Indian Food**
2409.00830v1 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Ramesh Jain

This paper presents an ontology design along with knowledge engineering, and
multilingual semantic reasoning techniques to build an automated system for
assimilating culinary information for Indian food in the form of a knowledge
graph. The main focus is on designing intelligent methods to derive ontology
designs and capture all-encompassing knowledge about food, recipes,
ingredients, cooking characteristics, and most importantly, nutrition, at
scale. We present our ongoing work in this workshop paper, describe in some
detail the relevant challenges in curating knowledge of Indian food, and
propose our high-level ontology design. We also present a novel workflow that
uses AI, LLM, and language technology to curate information from recipe blog
sites in the public domain to build knowledge graphs for Indian food. The
methods for knowledge curation proposed in this paper are generic and can be
replicated for any domain. The design is application-agnostic and can be used
for AI-driven smart analysis, building recommendation systems for Personalized
Digital Health, and complementing the knowledge graph for Indian food with
contextual information such as user information, food biochemistry, geographic
information, agricultural information, etc.

摘要：本文提出了一個知識工程和多語言語義推理技術的本体設計，用於建立一個自動化系統，以知識圖譜的形式吸收印度料理的烹飪資訊。重點在於設計智慧方法，以推導本体設計，並全面擷取關於食物、食譜、食材、烹飪特性，以及最重要的營養的知識，並擴大規模。我們在這個研討會論文中介紹了我們正在進行的工作，詳細描述了整理印度料理知識相關的挑戰，並提出了我們的高階本体設計。我們也提出了一種新的工作流程，它使用 AI、LLM 和語言技術，從公共領域的食譜部落格網站中整理資訊，以建立印度料理的知識圖譜。本文提出的知識整理方法是通用的，可以複製到任何領域。設計與應用無關，可用於 AI 驅動的智慧分析、建立個人化數位健康推薦系統，以及使用使用者資訊、食物生物化學、地理資訊、農業資訊等脈絡資訊，來補充印度料理的知識圖譜。

##### **Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph**
2409.00727v1 by Yuxiang Wang, Xiao Yan, Shiyu Jin, Quanqing Xu, Chuanhui Yang, Yuanyuan Zhu, Chuang Hu, Bo Du, Jiawei Jiang

Text-attributed graph (TAG) is an important type of graph structured data
with text descriptions for each node. Few- and zero-shot node classification on
TAGs have many applications in fields such as academia and social networks.
However, the two tasks are challenging due to the lack of supervision signals,
and existing methods only use the contrastive loss to align graph-based node
embedding and language-based text embedding. In this paper, we propose Hound to
improve accuracy by introducing more supervision signals, and the core idea is
to go beyond the node-text pairs that come with data. Specifically, we design
three augmentation techniques, i.e., node perturbation, text matching, and
semantics negation to provide more reference nodes for each text and vice
versa. Node perturbation adds/drops edges to produce diversified node
embeddings that can be matched with a text. Text matching retrieves texts with
similar embeddings to match with a node. Semantics negation uses a negative
prompt to construct a negative text with the opposite semantics, which is
contrasted with the original node and text. We evaluate Hound on 5 datasets and
compare with 13 state-of-the-art baselines. The results show that Hound
consistently outperforms all baselines, and its accuracy improvements over the
best-performing baseline are usually over 5%.

摘要：文字属性圖 (TAG) 是一種重要的圖形結構化資料類型，其中每個節點都有文字描述。TAG 上的少樣本和零樣本節點分類在學術界和社交網路等領域有許多應用。然而，由於缺乏監督訊號，這兩個任務具有挑戰性，現有方法僅使用對比損失來對齊基於圖形節點的嵌入和基於語言的文字嵌入。在本文中，我們提出 Hound 來透過引入更多監督訊號來改善準確度，其核心思想是超越資料中附帶的節點文字對。具體來說，我們設計了三種擴充技術，即節點擾動、文字配對和語義否定，為每個文字提供更多參考節點，反之亦然。節點擾動新增/刪除邊緣以產生可以與文字配對的多樣化節點嵌入。文字配對擷取具有類似嵌入的文字以與節點配對。語義否定使用負面提示來建構具有相反語義的負面文字，與原始節點和文字形成對比。我們在 5 個資料集上評估 Hound，並與 13 個最先進的基線進行比較。結果表明，Hound 在所有基線上始終表現優異，其準確度通常比效能最佳的基線提高了 5% 以上。

##### **WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction**
2409.00331v1 by Oktie Hassanzadeh

Recently, there has been an increasing interest in the construction of
general-domain and domain-specific causal knowledge graphs. Such knowledge
graphs enable reasoning for causal analysis and event prediction, and so have a
range of applications across different domains. While great progress has been
made toward automated construction of causal knowledge graphs, the evaluation
of such solutions has either focused on low-level tasks (e.g., cause-effect
phrase extraction) or on ad hoc evaluation data and small manual evaluations.
In this paper, we present a corpus, task, and evaluation framework for causal
knowledge graph construction. Our corpus consists of Wikipedia articles for a
collection of event-related concepts in Wikidata. The task is to extract causal
relations between event concepts from the corpus. The evaluation is performed
in part using existing causal relations in Wikidata to measure recall, and in
part using Large Language Models to avoid the need for manual or crowd-sourced
evaluation. We evaluate a pipeline for causal knowledge graph construction that
relies on neural models for question answering and concept linking, and show
how the corpus and the evaluation framework allow us to effectively find the
right model for each task. The corpus and the evaluation framework are publicly
available.

摘要：<paragraph>最近，人們對通用領域和特定領域因果知識圖譜的建構越來越感興趣。此類知識圖譜能夠推理因果分析和事件預測，因此在不同領域中有廣泛的應用。雖然在因果知識圖譜的自動建構方面取得了重大進展，但此類解決方案的評估要嘛著重於低階任務（例如因果關係短語擷取），要嘛著重於臨時評估資料和小型手動評估。在本文中，我們提出了一個語料庫、任務和因果知識圖譜建構評估架構。我們的語料庫包含維基百科文章，其中包含 Wikidata 中一系列事件相關概念。任務是從語料庫中擷取事件概念之間的因果關係。評估部分使用 Wikidata 中現有的因果關係來衡量召回率，部分使用大型語言模型來避免手動或群眾外包評估的需要。我們評估了一個因果知識圖譜建構管道，該管道依賴於用於問答和概念連結的神經模型，並展示了語料庫和評估架構如何讓我們有效地為每個任務找到合適的模型。語料庫和評估架構公開提供。</paragraph>

##### **LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models**
2408.16224v2 by Jingyi Wang, Jianzhong Ju, Jian Luan, Zhidong Deng

Recent advances in large vision-language models (VLMs) typically employ
vision encoders based on the Vision Transformer (ViT) architecture. The
division of the images into patches by ViT results in a fragmented perception,
thereby hindering the visual understanding capabilities of VLMs. In this paper,
we propose an innovative enhancement to address this limitation by introducing
a Scene Graph Expression (SGE) module in VLMs. This module extracts and
structurally expresses the complex semantic information within images, thereby
improving the foundational perception and understanding abilities of VLMs.
Extensive experiments demonstrate that integrating our SGE module significantly
enhances the VLM's performance in vision-language tasks, indicating its
effectiveness in preserving intricate semantic details and facilitating better
visual understanding.

摘要：近來大型視覺語言模型 (VLM) 的進展通常採用基於視覺轉換器 (ViT) 架構的視覺編碼器。ViT 將影像分割成區塊會造成破碎的感知，從而阻礙 VLM 的視覺理解能力。在本文中，我們提出了一項創新的增強功能，透過在 VLM 中引入場景圖表達 (SGE) 模組來解決此限制。此模組會萃取影像中的複雜語意資訊並以結構化的方式表達，從而改善 VLM 的基礎感知和理解能力。廣泛的實驗證明，整合我們的 SGE 模組能顯著提升 VLM 在視覺語言任務中的效能，表示它在保留複雜的語意細節和促進更好的視覺理解方面很有效。

##### **LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments**
2408.15903v1 by Ruirui Chen, Weifeng Jiang, Chengwei Qin, Ishaan Singh Rawal, Cheston Tan, Dongkyu Choi, Bo Xiong, Bo Ai

The rapid obsolescence of information in Large Language Models (LLMs) has
driven the development of various techniques to incorporate new facts. However,
existing methods for knowledge editing still face difficulties with multi-hop
questions that require accurate fact identification and sequential logical
reasoning, particularly among numerous fact updates. To tackle these
challenges, this paper introduces Graph Memory-based Editing for Large Language
Models (GMeLLo), a straitforward and effective method that merges the explicit
knowledge representation of Knowledge Graphs (KGs) with the linguistic
flexibility of LLMs. Beyond merely leveraging LLMs for question answering,
GMeLLo employs these models to convert free-form language into structured
queries and fact triples, facilitating seamless interaction with KGs for rapid
updates and precise multi-hop reasoning. Our results show that GMeLLo
significantly surpasses current state-of-the-art knowledge editing methods in
the multi-hop question answering benchmark, MQuAKE, especially in scenarios
with extensive knowledge edits.

摘要：大型語言模型 (LLM) 中資訊快速過時，促使各種技術發展以納入新事實。然而，現有的知識編輯方法在需要準確事實辨識和順序邏輯推理的多跳問題上仍面臨困難，特別是在眾多事實更新中。為了應對這些挑戰，本文介紹了大型語言模型的圖記憶編輯 (GMeLLo)，這是一種直接且有效的方法，結合了知識圖譜 (KG) 的明確知識表示與 LLM 的語言靈活性。GMeLLo 不僅利用 LLM 來回答問題，還使用這些模型將自由形式的語言轉換為結構化查詢和事實三元組，促進與 KG 的無縫互動，以便快速更新和精確的多跳推理。我們的結果表明，在多跳問題回答基準 MQuAKE 中，GMeLLo 明顯超越了當前最先進的知識編輯方法，特別是在廣泛知識編輯的場景中。

##### **VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities**
2408.14895v2 by Shusaku Egami, Takahiro Ugai, Swe Nwe Nwe Htun, Ken Fukuda

Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data
(e.g., images and videos) into symbols, have attracted attention as resources
enabling knowledge processing and machine learning across modalities. However,
the construction of MMKGs for videos consisting of multiple events, such as
daily activities, is still in the early stages. In this paper, we construct an
MMKG based on synchronized multi-view simulated videos of daily activities.
Besides representing the content of daily life videos as event-centric
knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as
bounding boxes within video frames. In addition, we provide support tools for
querying our MMKG. As an application example, we demonstrate that our MMKG
facilitates benchmarking vision-language models by providing the necessary
vision-language datasets for a tailored task.

摘要：多模態知識圖（MMKG）將各種非符號數據（例如，影像和影片）轉換為符號，成為一種資源，能讓跨模態的知識處理和機器學習成為可能。然而，對於包含多個事件（例如日常生活活動）的影片，其 MMKG 的建構仍處於早期階段。在本文中，我們基於每日活動的同步多視角模擬影片，建構了一個 MMKG。除了將日常生活影片的內容表示為以事件為中心的知識外，我們的 MMKG 也包含逐幀的細微變化，例如影片幀中的邊界框。此外，我們還提供了用於查詢 MMKG 的支援工具。作為應用範例，我們展示了我們的 MMKG 如何透過提供特定任務所需的視覺語言資料集，來促進視覺語言模型的基準測試。

##### **XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model**
2408.16021v1 by Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian

In the rapidly evolving field of cybersecurity, the integration of flow-level
and packet-level information for real-time intrusion detection remains a
largely untapped area of research. This paper introduces "XG-NID," a novel
framework that, to the best of our knowledge, is the first to fuse flow-level
and packet-level data within a heterogeneous graph structure, offering a
comprehensive analysis of network traffic. Leveraging a heterogeneous graph
neural network (GNN) with graph-level classification, XG-NID uniquely enables
real-time inference while effectively capturing the intricate relationships
between flow and packet payload data. Unlike traditional GNN-based
methodologies that predominantly analyze historical data, XG-NID is designed to
accommodate the heterogeneous nature of network traffic, providing a robust and
real-time defense mechanism. Our framework extends beyond mere classification;
it integrates Large Language Models (LLMs) to generate detailed, human-readable
explanations and suggest potential remedial actions, ensuring that the insights
produced are both actionable and comprehensible. Additionally, we introduce a
new set of flow features based on temporal information, further enhancing the
contextual and explainable inferences provided by our model. To facilitate
practical application and accessibility, we developed "GNN4ID," an open-source
tool that enables the extraction and transformation of raw network traffic into
the proposed heterogeneous graph structure, seamlessly integrating flow and
packet-level data. Our comprehensive quantitative comparative analysis
demonstrates that XG-NID achieves an F1 score of 97\% in multi-class
classification, outperforming existing baseline and state-of-the-art methods.
This sets a new standard in Network Intrusion Detection Systems by combining
innovative data fusion with enhanced interpretability and real-time
capabilities.

摘要：<paragraph>在快速發展的網路安全領域中，整合流層級和封包層級資訊以進行即時入侵偵測，仍然是一個尚未開發的研究領域。本文介紹「XG-NID」，一個創新的架構，據我們所知，這是第一個在異質圖形結構中融合流層級和封包層級資料的架構，提供對網路流量的全面分析。透過利用異質圖形神經網路 (GNN) 和圖形層級分類，XG-NID 獨特地實現即時推論，同時有效擷取流和封包酬載資料之間的複雜關係。與傳統基於 GNN 的方法（主要分析歷史資料）不同，XG-NID 被設計成適應網路流量的異質性，提供強大且即時的防禦機制。我們的架構不僅限於分類；它整合大型語言模型 (LLM) 以產生詳細、人類可讀的解釋並建議潛在的補救措施，確保產生的見解既可操作又易於理解。此外，我們根據時間資訊引入一組新的流特徵，進一步增強模型提供的脈絡和可解釋推論。為了促進實際應用和可及性，我們開發了「GNN4ID」，一個開放原始碼工具，可以將原始網路流量提取並轉換為建議的異質圖形結構，無縫整合流和封包層級資料。我們全面的定量比較分析表明，XG-NID 在多類別分類中達到 97% 的 F1 分數，優於現有的基準和最先進的方法。這透過結合創新的資料融合、增強的可解釋性和即時功能，在網路入侵偵測系統中樹立了新的標準。</paragraph>

##### **Process Trace Querying using Knowledge Graphs and Notation3**
2409.04452v1 by William Van Woensel

In process mining, a log exploration step allows making sense of the event
traces; e.g., identifying event patterns and illogical traces, and gaining
insight into their variability. To support expressive log exploration, the
event log can be converted into a Knowledge Graph (KG), which can then be
queried using general-purpose languages. We explore the creation of semantic KG
using the Resource Description Framework (RDF) as a data model, combined with
the general-purpose Notation3 (N3) rule language for querying. We show how
typical trace querying constraints, inspired by the state of the art, can be
implemented in N3. We convert case- and object-centric event logs into a
trace-based semantic KG; OCEL2 logs are hereby "flattened" into traces based on
object paths through the KG. This solution offers (a) expressivity, as queries
can instantiate constraints in multiple ways and arbitrarily constrain
attributes and relations (e.g., actors, resources); (b) flexibility, as OCEL2
event logs can be serialized as traces in arbitrary ways based on the KG; and
(c) extensibility, as others can extend our library by leveraging the same
implementation patterns.

摘要：在流程挖掘中，日志探索步骤可以理解事件轨迹；例如，识别事件模式和非逻辑轨迹，并深入了解其可变性。为了支持表达性日志探索，事件日志可以转换为知识图 (KG)，然后可以使用通用语言对其进行查询。我们探索使用资源描述框架 (RDF) 作为数据模型创建语义 KG，并结合通用 Notation3 (N3) 规则语言进行查询。我们展示了如何使用 N3 实现受现有技术启发的典型轨迹查询约束。我们将案例和对象中心事件日志转换为基于轨迹的语义 KG；OCEL2 日志在此被“扁平化”为基于通过 KG 的对象路径的轨迹。此解决方案提供 (a) 表达力，因为查询可以以多种方式实例化约束并任意约束属性和关系（例如，参与者、资源）；(b) 灵活，因为 OCEL2 事件日志可以基于 KG 以任意方式序列化为轨迹；以及 (c) 可扩展性，因为其他人可以通过利用相同的实现模式来扩展我们的库。

##### **PatentGPT: A Large Language Model for Patent Drafting Using Knowledge-based Fine-tuning Method**
2409.00092v1 by Runtao Ren, Jian Ma

As humanity stands on the brink of a new era of technological innovation, the
ability to rapidly transform creative ideas into protected intellectual
property (IP) is more crucial than ever. However, the conventional processes
for patent drafting are fraught with challenges, demanding a nuanced
understanding of advanced field knowledge and technical concepts. Existing
large language models (LLMs), while powerful, often fall short in this IP
creation domain due to their lack of specialized knowledge and
context-awareness necessary for generating technically accurate patent
documents. To bridge this critical gap, we propose a groundbreaking framework
for Knowledge Fine-Tuning (KFT) of LLMs, designed to endow AI with the ability
to autonomously mine, understand, and apply domain-specific knowledge. Our
model, PatentGPT leverages a unique combination of knowledge graph-based
pre-training, domain-specific supervised fine-tuning (SFT), and reinforcement
learning from human feedback (RLHF). Through extensive evaluation, PatentGPT
has demonstrated outstanding performance, scoring up to approximately 400%
higher in patent related benchmark tests compared to state-of-the-art models.
By KFT method the model's capability to not only assist but also augment human
creativity and innovation, our approach sets a new standard for AI-driven
intellectual property generation, paving the way for more efficient and
effective invention processes.

摘要：<paragraph>隨著人類邁入科技創新的新紀元，迅速將創意點子轉化為受保護的智慧財產（IP）的能力比以往任何時候都更加重要。然而，傳統的專利起草程序充滿挑戰，需要對先進領域知識和技術概念有細緻入微的了解。現有的大型語言模型（LLM）雖然強大，但由於缺乏產生技術上準確的專利文件的專業知識和情境意識，因此常常無法滿足此 IP 創作領域的需求。為了彌補這個關鍵差距，我們提出了一個創新的 LLM 知識微調 (KFT) 架構，旨在賦予 AI 自主挖掘、理解和應用特定領域知識的能力。我們的模型 PatentGPT 充分利用了基於知識圖表的預訓練、特定領域的監督式微調 (SFT) 和人類回饋的強化學習 (RLHF) 的獨特組合。透過廣泛的評估，PatentGPT 已展現出傑出的表現，在與最先進模型相比的專利相關基準測試中，得分高出約 400%。透過 KFT 方法，此模型不僅能夠協助，還能擴增人類的創造力和創新力，我們的做法為 AI 驅動的智慧財產生成樹立了新標準，為更有效率且更有效的發明流程鋪路。</paragraph>

##### **DynamicRouteGPT: A Real-Time Multi-Vehicle Dynamic Navigation Framework Based on Large Language Models**
2408.14185v1 by Ziai Zhou, Bin Zhou, Hao Liu

Real-time dynamic path planning in complex traffic environments presents
challenges, such as varying traffic volumes and signal wait times. Traditional
static routing algorithms like Dijkstra and A* compute shortest paths but often
fail under dynamic conditions. Recent Reinforcement Learning (RL) approaches
offer improvements but tend to focus on local optima, risking dead-ends or
boundary issues. This paper proposes a novel approach based on causal inference
for real-time dynamic path planning, balancing global and local optimality. We
first use the static Dijkstra algorithm to compute a globally optimal baseline
path. A distributed control strategy then guides vehicles along this path. At
intersections, DynamicRouteGPT performs real-time decision-making for local
path selection, considering real-time traffic, driving preferences, and
unexpected events. DynamicRouteGPT integrates Markov chains, Bayesian
inference, and large-scale pretrained language models like Llama3 8B to provide
an efficient path planning solution. It dynamically adjusts to traffic
scenarios and driver preferences and requires no pre-training, offering broad
applicability across road networks. A key innovation is the construction of
causal graphs for counterfactual reasoning, optimizing path decisions.
Experimental results show that our method achieves state-of-the-art performance
in real-time dynamic path planning for multiple vehicles while providing
explainable path selections, offering a novel and efficient solution for
complex traffic environments.

摘要：在複雜交通環境中進行實時動態路徑規劃會面臨挑戰，例如交通流量變化和信號等待時間。傳統的靜態路由演算法，例如 Dijkstra 和 A*，會計算最短路徑，但通常在動態條件下會失敗。最近的強化學習 (RL) 方法提供了改進，但傾向於關注局部最優，冒著陷入死胡同或邊界問題的風險。本文提出了一種基於因果推論的新穎方法，用於實時動態路徑規劃，平衡全局和局部最優性。我們首先使用靜態 Dijkstra 演算法計算全局最優基線路徑。然後，一個分布式控制策略沿著這條路徑引導車輛。在交叉路口，DynamicRouteGPT 針對局部路徑選擇執行實時決策，考量實時交通、駕駛偏好和意外事件。DynamicRouteGPT 整合了馬可夫鏈、貝氏推論和 Llama3 8B 等大規模預先訓練的語言模型，以提供有效的路徑規劃解決方案。它會動態調整到交通狀況和駕駛偏好，並且不需要預先訓練，在道路網路上提供廣泛的適用性。一個關鍵創新是建立反事實推理的因果圖，以最佳化路徑決策。實驗結果顯示，我們的模型在多輛車輛的實時動態路徑規劃中達到最先進的效能，同時提供可解釋的路徑選擇，為複雜的交通環境提供一種新穎且有效的解決方案。

##### **Exploring the Potential of Large Language Models for Heterophilic Graphs**
2408.14134v1 by Yuxia Wu, Shujie Li, Yuan Fang, Chuan Shi

Graph Neural Networks (GNNs) are essential for various graph-based learning
tasks. Notably, classical GNN architectures operate under the assumption of
homophily, which posits that connected nodes are likely to share similar
features. However, this assumption limits the effectiveness of GNNs in handling
heterophilic graphs where connected nodes often exhibit dissimilar
characteristics. Existing approaches for homophily graphs such as non-local
neighbor extension and architectural refinement overlook the rich textual data
associated with nodes, which could unlock deeper insights into these
heterophilic contexts. With advancements in Large Language Models (LLMs), there
is significant promise to enhance GNNs by leveraging the extensive open-world
knowledge within LLMs to more effectively interpret and utilize textual data
for characterizing heterophilic graphs. In this work, we explore the potential
of LLMs for modeling heterophilic graphs and propose a novel two-stage
framework: LLM-enhanced edge discriminator and LLM-guided edge reweighting.
Specifically, in the first stage, we fine-tune the LLM to better identify
homophilic and heterophilic edges based on the textual information of their
nodes. In the second stage, we adaptively manage message propagation in GNNs
for different edge types based on node features, structures, and heterophilic
or homophilic characteristics. To cope with the computational demands when
deploying LLMs in practical scenarios, we further explore model distillation
techniques to fine-tune smaller, more efficient models that maintain
competitive performance. Extensive experiments validate the effectiveness of
our framework, demonstrating the feasibility of using LLMs to enhance GNNs for
node classification on heterophilic graphs.

摘要：圖神經網路 (GNN) 對於各種基於圖形的學習任務至關重要。值得注意的是，傳統的 GNN 架構在同質性的假設下運作，該假設認為連接的節點可能共享類似的特徵。然而，此假設限制了 GNN 在處理異質性圖形中的效能，其中連接的節點通常表現出不同的特徵。現有的同質性圖形方法（例如非局部鄰域延伸和架構改進）忽略了與節點相關的豐富文本資料，這可以深入了解這些異質性脈絡。隨著大型語言模型 (LLM) 的進步，透過利用 LLM 中廣泛的開放世界知識來增強 GNN，對於更有效地詮釋和利用文本資料來表徵異質性圖形有很大的希望。在這項工作中，我們探討了 LLM 在異質性圖形建模中的潛力，並提出了一個新穎的兩階段架構：LLM 增強邊緣判別器和 LLM 引導邊緣重新加權。具體來說，在第一階段，我們微調 LLM 以根據其節點的文本資訊，更好地識別同質性和異質性邊緣。在第二階段，我們根據節點特徵、結構和異質性或同質性特徵，自適應地管理 GNN 中不同邊緣類型的訊息傳遞。為了應對在實際場景中部署 LLM 時的計算需求，我們進一步探討模型萃取技術，以微調較小、更有效率的模型，以維持競爭力。廣泛的實驗驗證了我們架構的有效性，證明了使用 LLM 來增強 GNN 以進行異質性圖形上的節點分類的可行性。

##### **Towards Graph Prompt Learning: A Survey and Beyond**
2408.14520v2 by Qingqing Long, Yuchen Yan, Peiyan Zhang, Chen Fang, Wentao Cui, Zhiyuan Ning, Meng Xiao, Ning Cao, Xiao Luo, Lingjun Xu, Shiyue Jiang, Zheng Fang, Chong Chen, Xian-Sheng Hua, Yuanchun Zhou

Large-scale "pre-train and prompt learning" paradigms have demonstrated
remarkable adaptability, enabling broad applications across diverse domains
such as question answering, image recognition, and multimodal retrieval. This
approach fully leverages the potential of large-scale pre-trained models,
reducing downstream data requirements and computational costs while enhancing
model applicability across various tasks. Graphs, as versatile data structures
that capture relationships between entities, play pivotal roles in fields such
as social network analysis, recommender systems, and biological graphs. Despite
the success of pre-train and prompt learning paradigms in Natural Language
Processing (NLP) and Computer Vision (CV), their application in graph domains
remains nascent. In graph-structured data, not only do the node and edge
features often have disparate distributions, but the topological structures
also differ significantly. This diversity in graph data can lead to
incompatible patterns or gaps between pre-training and fine-tuning on
downstream graphs. We aim to bridge this gap by summarizing methods for
alleviating these disparities. This includes exploring prompt design
methodologies, comparing related techniques, assessing application scenarios
and datasets, and identifying unresolved problems and challenges. This survey
categorizes over 100 relevant works in this field, summarizing general design
principles and the latest applications, including text-attributed graphs,
molecules, proteins, and recommendation systems. Through this extensive review,
we provide a foundational understanding of graph prompt learning, aiming to
impact not only the graph mining community but also the broader Artificial
General Intelligence (AGI) community.

摘要：<paragraph>大規模「預訓練和提示學習」範例已展現出非凡的適應力，能廣泛應用於各種領域，例如問答、影像辨識和多模態檢索。此方法充分發揮大型預訓練模型的潛力，減少下游資料需求和運算成本，同時提升模型在各種任務中的適用性。圖形作為能捕捉實體之間關係的多功能資料結構，在社群網路分析、推薦系統和生物圖形等領域扮演著關鍵角色。儘管預訓練和提示學習範例在自然語言處理 (NLP) 和電腦視覺 (CV) 中獲得成功，但它們在圖形領域的應用仍處於起步階段。在圖形結構化資料中，節點和邊緣特徵不僅常有不同的分佈，拓撲結構也差異很大。圖形資料中的這種多樣性可能導致預訓練和微調之間出現不相容的模式或差距。我們旨在透過總結減輕這些差異的方法來彌補此差距。這包括探索提示設計方法、比較相關技術、評估應用場景和資料集，以及找出未解決的問題和挑戰。本調查歸類了此領域中超過 100 篇相關作品，總結了一般設計原則和最新應用，包括文字屬性圖形、分子、蛋白質和推薦系統。透過這項廣泛的回顧，我們提供了圖形提示學習的基本理解，旨在不僅影響圖形挖掘社群，也影響更廣泛的人工通用智慧 (AGI) 社群。</paragraph>

##### **CodeGraph: Enhancing Graph Reasoning of LLMs with Code**
2408.13863v1 by Qiaolong Cai, Zhaowei Wang, Shizhe Diao, James Kwok, Yangqiu Song

With the increasing popularity of large language models (LLMs), reasoning on
basic graph algorithm problems is an essential intermediate step in assessing
their abilities to process and infer complex graph reasoning tasks. Existing
methods usually convert graph-structured data to textual descriptions and then
use LLMs for reasoning and computation. However, LLMs often produce computation
errors on arithmetic parts in basic graph algorithm problems, such as counting
number of edges. In addition, they struggle to control or understand the output
of the reasoning process, raising concerns about whether LLMs are simply
guessing. In this paper, we introduce CodeGraph, a method that encodes graph
problem solutions as code. The methods solve new graph problems by learning
from exemplars, generating programs, and executing them via a program
interpreter. Using the few-shot setting, we evaluate CodeGraph with the base
LLM being GPT-3.5 Turbo, Llama3-70B Instruct, Mixtral-8x22B Instruct, and
Mixtral-8x7B Instruct. Experimental results on six tasks with six graph
encoding methods in the GraphQA dataset demonstrate that CodeGraph can boost
performance on graph reasoning tasks inside LLMs by 1.3% to 58.6%, depending on
the task. Compared to the existing methods, CodeGraph demonstrates strong
performance on arithmetic problems in graph tasks and offers a more
controllable and interpretable approach to the reasoning process.

摘要：隨著大型語言模型 (LLM) 的日漸普及，對基本圖形演算法問題進行推理是評估它們處理和推論複雜圖形推理任務的能力中一個重要的中間步驟。現有的方法通常會將圖形結構化的資料轉換成文字描述，然後使用 LLM 進行推理和運算。然而，LLM 通常會在基本圖形演算法問題中，例如計算邊緣數量，對算術部分產生運算錯誤。此外，它們難以控制或理解推理過程的輸出，這引發了 LLM 是否只是在猜測的疑慮。在本文中，我們介紹了 CodeGraph，這是一種將圖形問題解決方案編碼為程式碼的方法。這些方法透過學習範例、產生程式，並透過程式碼直譯器執行它們來解決新的圖形問題。使用少次嘗試設定，我們使用基礎 LLM 為 GPT-3.5 Turbo、Llama3-70B Instruct、Mixtral-8x22B Instruct 和 Mixtral-8x7B Instruct 來評估 CodeGraph。在 GraphQA 資料集中使用六種圖形編碼方法對六項任務進行的實驗結果表明，CodeGraph 可以將 LLM 中的圖形推理任務的效能提升 1.3% 到 58.6%，具體取決於任務。與現有方法相比，CodeGraph 在圖形任務中的算術問題上表現出強勁的效能，並為推理過程提供更具可控性和可解釋性的方法。

##### **LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings**
2408.14512v1 by Duo Wang, Yuan Zuo, Fengzhi Li, Junjie Wu

Zero-shot graph machine learning, especially with graph neural networks
(GNNs), has garnered significant interest due to the challenge of scarce
labeled data. While methods like self-supervised learning and graph prompt
learning have been extensively explored, they often rely on fine-tuning with
task-specific labels, limiting their effectiveness in zero-shot scenarios.
Inspired by the zero-shot capabilities of instruction-fine-tuned large language
models (LLMs), we introduce a novel framework named Token Embedding-Aligned
Graph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and
cross-task zero-shot learners for graph machine learning. Concretely, we
pretrain a GNN, aligning its representations with token embeddings of an LLM.
We then train a linear projector that transforms the GNN's representations into
a fixed number of graph token embeddings without tuning the LLM. A unified
instruction is designed for various graph tasks at different levels, such as
node classification (node-level) and link prediction (edge-level). These design
choices collectively enhance our method's effectiveness in zero-shot learning,
setting it apart from existing methods. Experiments show that our graph token
embeddings help the LLM predictor achieve state-of-the-art performance on
unseen datasets and tasks compared to other methods using LLMs as predictors.

摘要：零範例圖形機器學習，特別是圖形神經網路 (GNN)，由於稀有標籤資料的挑戰而備受關注。雖然自監督式學習和圖形提示學習等方法已被廣泛探索，但它們通常依賴於任務特定標籤的微調，這限制了它們在零範例場景中的有效性。受到指令微調大型語言模型 (LLM) 的零範例功能的啟發，我們引入了一個名為 Token Embedding-Aligned Graph Language Model (TEA-GLM) 的新框架，它利用 LLM 作為跨資料集和跨任務的零範例學習器，用於圖形機器學習。具體來說，我們預訓練一個 GNN，將其表示與 LLM 的 token embedding 對齊。然後，我們訓練一個線性投影機，將 GNN 的表示轉換為固定數量的圖形 token embedding，而無需調整 LLM。統一的指令是為不同層級的各種圖形任務設計的，例如節點分類（節點層級）和連結預測（邊緣層級）。這些設計選擇共同增強了我們的方法在零範例學習中的有效性，使其有別於現有方法。實驗表明，與使用 LLM 作為預測器的其他方法相比，我們的圖形 token embedding 幫助 LLM 預測器在未見過的資料集和任務上實現了最先進的效能。

##### **Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models**
2408.13661v1 by Sakhinana Sagar Srinivas, Geethan Sannidhi, Venkataramana Runkana

Characterizing materials with electron micrographs is a crucial task in
fields such as semiconductors and quantum materials. The complex hierarchical
structure of micrographs often poses challenges for traditional classification
methods. In this study, we propose an innovative backbone architecture for
analyzing electron micrographs. We create multi-modal representations of the
micrographs by tokenizing them into patch sequences and, additionally,
representing them as vision graphs, commonly referred to as patch attributed
graphs. We introduce the Hierarchical Network Fusion (HNF), a multi-layered
network structure architecture that facilitates information exchange between
the multi-modal representations and knowledge integration across different
patch resolutions. Furthermore, we leverage large language models (LLMs) to
generate detailed technical descriptions of nanomaterials as auxiliary
information to assist in the downstream task. We utilize a cross-modal
attention mechanism for knowledge fusion across cross-domain
representations(both image-based and linguistic insights) to predict the
nanomaterial category. This multi-faceted approach promises a more
comprehensive and accurate representation and classification of micrographs for
nanomaterial identification. Our framework outperforms traditional methods,
overcoming challenges posed by distributional shifts, and facilitating
high-throughput screening.

摘要：利用電子顯微照片來表徵材料，在半導體和量子材料等領域中是一項至關重要的任務。顯微照片複雜的分層結構通常會對傳統分類方法帶來挑戰。在這項研究中，我們提出了一種創新的主幹架構，用於分析電子顯微照片。我們透過將顯微照片代換成區塊序列來建立其多模態表示，此外，我們還將其表示為視覺圖形，通常稱為區塊屬性圖形。我們引入了分層網路融合 (HNF)，這是一種多層網路結構架構，有助於多模態表示之間的資訊交換，以及不同區塊解析度之間的知識整合。此外，我們利用大型語言模型 (LLM) 來產生奈米材料的詳細技術說明，作為輔助資訊，以協助下游任務。我們利用跨模態注意力機制，在跨領域表示（基於影像和語言洞察力）中進行知識融合，以預測奈米材料類別。這種多方面的做法有望為奈米材料識別提供更全面且準確的表示和分類。我們的架構優於傳統方法，克服了分佈轉移帶來的挑戰，並促進了高通量篩選。

##### **GNN: Graph Neural Network and Large Language Model for Data Discovery**
2408.13609v2 by Thomas Hoang

Our algorithm GNN: Graph Neural Network and Large Language Model for Data
Discovery inherit the benefits of \cite{hoang2024plod} (PLOD: Predictive
Learning Optimal Data Discovery), \cite{Hoang2024BODBO} (BOD: Blindly Optimal
Data Discovery) in terms of overcoming the challenges of having to predefine
utility function and the human input for attribute ranking, which helps prevent
the time-consuming loop process. In addition to these previous works, our
algorithm GNN leverages the advantages of graph neural networks and large
language models to understand text type values that cannot be understood by
PLOD and MOD, thus making the task of predicting outcomes more reliable. GNN
could be seen as an extension of PLOD in terms of understanding the text type
value and the user's preferences, not only numerical values but also text
values, making the promise of data science and analytics purposes.

摘要：我們的演算法 GNN：圖神經網路和大語言模型，用於資料探索，繼承了 \cite{hoang2024plod}（PLOD：預測性最佳資料探索）、\cite{Hoang2024BODBO}（BOD：盲目最佳資料探索）的優點，在於克服必須預先定義效用函數和人類輸入屬性排名的挑戰，這有助於防止耗時的迴圈處理。除了這些先前的作品，我們的演算法 GNN 利用圖神經網路和大語言模型的優點，來理解 PLOD 和 MOD 無法理解的文字類型值，從而使預測結果的任務更可靠。GNN 可以視為 PLOD 在理解文字類型值和使用者偏好方面的延伸，不僅是數值，還有文字值，這實現了資料科學和分析目的的承諾。

##### **HRGraph: Leveraging LLMs for HR Data Knowledge Graphs with Information Propagation-based Job Recommendation**
2408.13521v1 by Azmine Toushik Wasi

Knowledge Graphs (KGs) serving as semantic networks, prove highly effective
in managing complex interconnected data in different domains, by offering a
unified, contextualized, and structured representation with flexibility that
allows for easy adaptation to evolving knowledge. Processing complex Human
Resources (HR) data, KGs can help in different HR functions like recruitment,
job matching, identifying learning gaps, and enhancing employee retention.
Despite their potential, limited efforts have been made to implement practical
HR knowledge graphs. This study addresses this gap by presenting a framework
for effectively developing HR knowledge graphs from documents using Large
Language Models. The resulting KG can be used for a variety of downstream
tasks, including job matching, identifying employee skill gaps, and many more.
In this work, we showcase instances where HR KGs prove instrumental in precise
job matching, yielding advantages for both employers and employees. Empirical
evidence from experiments with information propagation in KGs and Graph Neural
Nets, along with case studies underscores the effectiveness of KGs in tasks
such as job and employee recommendations and job area classification. Code and
data are available at : https://github.com/azminewasi/HRGraph

摘要：知識圖譜 (KG) 作為語義網路，證明在管理不同領域中複雜的互連資料方面非常有效，透過提供統一、脈絡化且結構化的表示，並具備靈活性，可輕鬆適應不斷變化的知識。KG 處理複雜的人力資源 (HR) 資料，有助於不同的 HR 功能，例如招募、工作匹配、找出學習差距和提升員工留存率。儘管有其潛力，但實作實用的 HR 知識圖譜的努力有限。本研究透過提出一個架構，從文件中使用大型語言模型有效開發 HR 知識圖譜，來解決這個差距。產生的 KG 可用於各種下游任務，包括工作匹配、找出員工技能差距等。在這項工作中，我們展示了 HR KG 在精確工作匹配中證明有用的範例，為雇主和員工帶來優勢。透過 KG 和圖形神經網路中資訊傳播的實驗所得的實證，以及案例研究，強調了 KG 在工作和員工推薦以及工作領域分類等任務中的有效性。程式碼和資料可在以下位置取得：https://github.com/azminewasi/HRGraph

##### **Integrating Multi-Head Convolutional Encoders with Cross-Attention for Improved SPARQL Query Translation**
2408.13432v1 by Yi-Hui Chen, Eric Jui-Lin Lu, Kwan-Ho Cheng

The main task of the KGQA system (Knowledge Graph Question Answering) is to
convert user input questions into query syntax (such as SPARQL). With the rise
of modern popular encoders and decoders like Transformer and ConvS2S, many
scholars have shifted the research direction of SPARQL generation to the Neural
Machine Translation (NMT) architecture or the generative AI field of
Text-to-SPARQL. In NMT-based QA systems, the system treats knowledge base query
syntax as a language. It uses NMT-based translation models to translate natural
language questions into query syntax. Scholars use popular architectures
equipped with cross-attention, such as Transformer, ConvS2S, and BiLSTM, to
train translation models for query syntax. To achieve better query results,
this paper improved the ConvS2S encoder and added multi-head attention from the
Transformer, proposing a Multi-Head Conv encoder (MHC encoder) based on the
n-gram language model. The principle is to use convolutional layers to capture
local hidden features in the input sequence with different receptive fields,
using multi-head attention to calculate dependencies between them. Ultimately,
we found that the translation model based on the Multi-Head Conv encoder
achieved better performance than other encoders, obtaining 76.52\% and 83.37\%
BLEU-1 (BiLingual Evaluation Understudy) on the QALD-9 and LC-QuAD-1.0
datasets, respectively. Additionally, in the end-to-end system experiments on
the QALD-9 and LC-QuAD-1.0 datasets, we achieved leading results over other
KGQA systems, with Macro F1-measures reaching 52\% and 66\%, respectively.
Moreover, the experimental results show that with limited computational
resources, if one possesses an excellent encoder-decoder architecture and
cross-attention, experts and scholars can achieve outstanding performance
equivalent to large pre-trained models using only general embeddings.

摘要：知識圖表問答系統 (KGQA) 的主要任務是將使用者輸入的問題轉換成查詢語法 (例如 SPARQL)。隨著 Transformer 和 ConvS2S 等現代流行編碼器和解碼器的崛起，許多學者已將 SPARQL 生成的研究方向轉移到神經機器翻譯 (NMT) 架構或文字轉 SPARQL 的生成式人工智慧領域。在基於 NMT 的問答系統中，系統將知識庫查詢語法視為一種語言。它使用基於 NMT 的翻譯模型將自然語言問題轉換成查詢語法。學者使用配備跨注意力機制的熱門架構，例如 Transformer、ConvS2S 和 BiLSTM，來訓練查詢語法的翻譯模型。為了獲得更好的查詢結果，本文改進了 ConvS2S 編碼器，並從 Transformer 中加入多頭注意力機制，提出了一個基於 n-gram 語言模型的多頭卷積編碼器 (MHC 編碼器)。其原理是使用卷積層以不同的感受野擷取輸入序列中的局部隱藏特徵，並使用多頭注意力機制計算它們之間的依賴關係。最終，我們發現基於多頭卷積編碼器的翻譯模型比其他編碼器獲得了更好的效能，分別在 QALD-9 和 LC-QuAD-1.0 資料集上獲得 76.52% 和 83.37% 的 BLEU-1（雙語評估研究）分數。此外，在 QALD-9 和 LC-QuAD-1.0 資料集的端到端系統實驗中，我們在其他 KGQA 系統中取得了領先的結果，巨觀 F1 測量值分別達到 52% 和 66%。此外，實驗結果表明，如果擁有出色的編碼器-解碼器架構和跨注意力機制，即使在運算資源有限的情況下，專家和學者仍可以使用一般的嵌入來獲得等同於大型預訓練模型的傑出效能。

##### **CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers**
2408.13366v1 by Ekaterina Trofimova, Emil Sataev, Abhijit Singh Jowhari

This paper presents CodeRefine, a novel framework for automatically
transforming research paper methodologies into functional code using Large
Language Models (LLMs). Our multi-step approach first extracts and summarizes
key text chunks from papers, analyzes their code relevance, and creates a
knowledge graph using a predefined ontology. Code is then generated from this
structured representation and enhanced through a proposed retrospective
retrieval-augmented generation approach. CodeRefine addresses the challenge of
bridging theoretical research and practical implementation, offering a more
accurate alternative to LLM zero-shot prompting. Evaluations on diverse
scientific papers demonstrate CodeRefine's ability to improve code
implementation from the paper, potentially accelerating the adoption of
cutting-edge algorithms in real-world applications.

摘要：本篇論文提出 CodeRefine，一個利用大型語言模型 (LLM) 將研究論文方法自動轉換為功能程式碼的新穎架構。我們的多步驟方法首先從論文中萃取並摘要出關鍵文字區塊，分析其程式碼相關性，並使用預定義的本体建立知識圖譜。接著從這個結構化表示產生程式碼，並透過提出的回溯式檢索增強產生方法進行強化。CodeRefine 解決了理論研究與實際實作之間的鴻溝，提供比 LLM 零次提示更精確的替代方案。在各種科學論文上的評估證明了 CodeRefine 從論文改善程式碼實作的能力，這有潛力加速尖端演算法在實際應用中的採用。

##### **Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving**
2408.14494v1 by Sakhinana Sagar Srinivas, Vijay Sri Vaikunth, Venkataramana Runkana

We present the Process Engineering Operations Assistant (PEOA), an AI-driven
framework designed to solve complex problems in the chemical and process
industries. The framework employs a modular architecture orchestrated by a
meta-agent, which serves as the central coordinator, managing an action
generator and instruction-tuned small-scale language models (expert models).
The action generator decomposes complex problems into sub-tasks and identifies
suitable expert models to execute each, delivering precise solutions for
multi-step problem-solving. Key techniques include advanced knowledge modeling
using property graphs for improved information retrieval, facilitating more
accurate and contextually relevant solutions. Additionally, the framework
utilizes a teacher-student transfer-learning approach with GPT-4 (Omni) to
fine-tune the action generator and expert models for domain adaptation,
alongside an iterative problem-solving mechanism with sophisticated error
handling. Custom datasets were developed to evaluate the framework against
leading proprietary language models on various engineering tasks. The results
demonstrate the framework effectiveness in automating calculations,
accelerating prototyping, and providing AI-augmented decision support for
industrial processes, marking a significant advancement in process engineering
capabilities.

摘要：我們提出了製程工程作業助理 (PEOA)，這是一個由 AI 驅動的架構，旨在解決化學和製程產業中的複雜問題。該架構採用模組化架構，由一個元代理程式協調，該代理程式作為中央協調器，管理動作產生器和指令調整的小規模語言模型 (專家模型)。動作產生器將複雜的問題分解為子任務，並識別合適的專家模型來執行每個任務，為多步驟問題解決提供精確的解決方案。關鍵技術包括使用屬性圖進行進階知識建模，以改善資訊檢索，提供更準確且與脈絡相關的解決方案。此外，該架構採用教師-學生傳輸學習方法，使用 GPT-4 (Omni) 來微調動作產生器和專家模型，以進行領域適應，以及具備精緻錯誤處理功能的迭代問題解決機制。開發了自訂資料集，以針對各種工程任務評估該架構與領先的專有語言模型。結果證明了該架構在自動化計算、加速建模和提供 AI 增強決策支援方面的有效性，標誌著製程工程能力的重大進展。

##### **A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**
2408.12578v2 by Ekdeep Singh Lubana, Kyogo Kawaguchi, Robert P. Dick, Hidenori Tanaka

Increase in data, size, or compute can lead to sudden learning of specific
capabilities by a neural network -- a phenomenon often called "emergence''.
Beyond scientific understanding, establishing the causal factors underlying
such emergent capabilities is crucial to enable risk regulation frameworks for
AI. In this work, we seek inspiration from study of emergent properties in
other fields and propose a phenomenological definition for the concept in the
context of neural networks. Our definition implicates the acquisition of
general structures underlying the data-generating process as a cause of sudden
performance growth for specific, narrower tasks. We empirically investigate
this definition by proposing an experimental system grounded in a
context-sensitive formal language and find that Transformers trained to perform
tasks on top of strings from this language indeed exhibit emergent
capabilities. Specifically, we show that once the language's underlying grammar
and context-sensitivity inducing structures are learned by the model,
performance on narrower tasks suddenly begins to improve. We then analogize our
network's learning dynamics with the process of percolation on a bipartite
graph, establishing a formal phase transition model that predicts the shift in
the point of emergence observed in our experiments when changing the data
structure. Overall, our experimental and theoretical frameworks yield a step
towards better defining, characterizing, and predicting emergence in neural
networks.

摘要：<paragraph>資料、規模或運算的增加，可能會導致神經網路突然學會特定能力——這種現象常稱為「湧現」。除了科學理解之外，確立這種湧現能力背後的基本原因，對於為 AI 建立風險法規框架至關重要。在這項工作中，我們從其他領域中對湧現特性的研究中尋求靈感，並針對神經網路中的概念提出現象學定義。我們的定義暗示，取得資料產生程序背後的通用結構，是特定、較狹隘任務突然效能提升的原因。我們透過提出一個以情境敏感形式語言為基礎的實驗系統，對這個定義進行實證研究，發現經過訓練以執行這個語言中字串頂部任務的 Transformer，確實展現出湧現能力。具體來說，我們展示出模型一旦學會語言的底層文法和情境敏感誘導結構，對較狹隘任務的效能就會突然開始提升。接著我們將網路的學習動態類比為二部圖上的滲流過程，建立一個正式的相變模型，用於預測在改變資料結構時，我們在實驗中觀察到的湧現點位移。整體而言，我們的實驗和理論框架朝著更完善地定義、描述和預測神經網路中的湧現邁進了一步。</paragraph>

##### **Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language**
2409.00061v1 by Arief Purnama Muharram, Ayu Purwarianti

Automated fact-checking is a key strategy to overcome the spread of COVID-19
misinformation on the internet. These systems typically leverage deep learning
approaches through Natural Language Inference (NLI) to verify the truthfulness
of information based on supporting evidence. However, one challenge that arises
in deep learning is performance stagnation due to a lack of knowledge during
training. This study proposes using a Knowledge Graph (KG) as external
knowledge to enhance NLI performance for automated COVID-19 fact-checking in
the Indonesian language. The proposed model architecture comprises three
modules: a fact module, an NLI module, and a classifier module. The fact module
processes information from the KG, while the NLI module handles semantic
relationships between the given premise and hypothesis. The representation
vectors from both modules are concatenated and fed into the classifier module
to produce the final result. The model was trained using the generated
Indonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.
Our study demonstrates that incorporating KGs can significantly improve NLI
performance in fact-checking, achieving the best accuracy of 0,8616. This
suggests that KGs are a valuable component for enhancing NLI performance in
automated fact-checking.

摘要：自動事實查核是克服網路上 COVID-19 錯誤資訊散播的一項關鍵策略。這些系統通常透過自然語言推論 (NLI) 來利用深度學習方法，根據支援證據驗證資訊的真實性。然而，在深度學習中會出現一個挑戰，那就是在訓練期間因缺乏知識而導致效能停滯。這項研究提出使用知識圖譜 (KG) 作為外部知識，以增強自動化 COVID-19 事實查核的 NLI 效能，並以印尼語進行。所提出的模型架構包含三個模組：事實模組、NLI 模組和分類器模組。事實模組處理來自 KG 的資訊，而 NLI 模組則處理給定前提和假設之間的語義關係。來自兩個模組的表示向量會串接起來，並輸入分類器模組以產生最終結果。此模型使用產生的印尼語 COVID-19 事實查核資料集和 COVID-19 KG Bahasa Indonesia 進行訓練。我們的研究證明，納入 KG 可以顯著改善事實查核中的 NLI 效能，達到 0.8616 的最佳準確度。這表示 KG 是增強自動化事實查核中 NLI 效能的寶貴組成部分。

##### **Cell-ontology guided transcriptome foundation model**
2408.12373v1 by Xinyu Yuan, Zhihao Zhan, Zuobai Zhang, Manqi Zhou, Jianan Zhao, Boyu Han, Yue Li, Jian Tang

Transcriptome foundation models TFMs hold great promises of deciphering the
transcriptomic language that dictate diverse cell functions by self-supervised
learning on large-scale single-cell gene expression data, and ultimately
unraveling the complex mechanisms of human diseases. However, current TFMs
treat cells as independent samples and ignore the taxonomic relationships
between cell types, which are available in cell ontology graphs. We argue that
effectively leveraging this ontology information during the TFM pre-training
can improve learning biologically meaningful gene co-expression patterns while
preserving TFM as a general purpose foundation model for downstream zero-shot
and fine-tuning tasks. To this end, we present \textbf{s}ingle \textbf{c}ell,
\textbf{Cell}-\textbf{o}ntology guided TFM scCello. We introduce cell-type
coherence loss and ontology alignment loss, which are minimized along with the
masked gene expression prediction loss during the pre-training. The novel loss
component guide scCello to learn the cell-type-specific representation and the
structural relation between cell types from the cell ontology graph,
respectively. We pre-trained scCello on 22 million cells from CellxGene
database leveraging their cell-type labels mapped to the cell ontology graph
from Open Biological and Biomedical Ontology Foundry. Our TFM demonstrates
competitive generalization and transferability performance over the existing
TFMs on biologically important tasks including identifying novel cell types of
unseen cells, prediction of cell-type-specific marker genes, and cancer drug
responses.

摘要：<paragraph>轉錄組基礎模型 TFM 承諾解碼轉錄組語言，它透過在大型單細胞基因表現資料上進行自我監督學習，來決定不同的細胞功能，並最終解開人類疾病的複雜機制。然而，目前的 TFM 將細胞視為獨立樣本，並忽略細胞類型之間的分類關係，而這在細胞本體論圖表中是可用的。我們認為在 TFM 預訓練期間有效利用此本體論資訊，可以改善學習生物學上有意義的基因共表現模式，同時保留 TFM 作為下游零次學習和微調任務的一般用途基礎模型。為此，我們提出單細胞、細胞本體論引導的 TFM scCello。我們引入細胞類型一致性損失和本體論對齊損失，在預訓練期間會將其與遮罩基因表現預測損失一起最小化。這個新穎的損失組件引導 scCello 分別從細胞本體論圖表中學習細胞類型特定表示和細胞類型之間的結構關係。我們在 CellxGene 資料庫中對 2200 萬個細胞進行 scCello 預訓練，利用其細胞類型標籤對應到開放生物和生物醫學本體鑄造廠的細胞本體論圖表。我們的 TFM 在生物學上重要的任務上展示了比現有 TFM 更具競爭力的泛化和可轉移性，包括識別未見細胞的新細胞類型、預測細胞類型特定標記基因和癌症藥物反應。</paragraph>

##### **Graph Retrieval Augmented Trustworthiness Reasoning**
2408.12333v2 by Ying Zhu, Shengchang Li, Ziqian Kong, Peilan Xu

Trustworthiness reasoning is crucial in multiplayer games with incomplete
information, enabling agents to identify potential allies and adversaries,
thereby enhancing reasoning and decision-making processes. Traditional
approaches relying on pre-trained models necessitate extensive domain-specific
data and considerable reward feedback, with their lack of real-time
adaptability hindering their effectiveness in dynamic environments. In this
paper, we introduce the Graph Retrieval Augmented Reasoning (GRATR) framework,
leveraging the Retrieval-Augmented Generation (RAG) technique to bolster
trustworthiness reasoning in agents. GRATR constructs a dynamic trustworthiness
graph, updating it in real-time with evidential information, and retrieves
relevant trust data to augment the reasoning capabilities of Large Language
Models (LLMs). We validate our approach through experiments on the multiplayer
game "Werewolf," comparing GRATR against baseline LLM and LLM enhanced with
Native RAG and Rerank RAG. Our results demonstrate that GRATR surpasses the
baseline methods by over 30\% in winning rate, with superior reasoning
performance. Moreover, GRATR effectively mitigates LLM hallucinations, such as
identity and objective amnesia, and crucially, it renders the reasoning process
more transparent and traceable through the use of the trustworthiness graph.

摘要：<paragraph>在信息不完整的多人遊戲中，可信度推理至關重要，讓代理人能夠識別潛在的盟友和敵人，從而增強推理和決策制定過程。依賴預先訓練模型的傳統方法需要大量的特定領域數據和大量的獎勵回饋，而它們缺乏實時適應性會阻礙它們在動態環境中的有效性。在本文中，我們介紹了圖形檢索增強推理 (GRATR) 框架，利用檢索增強生成 (RAG) 技術來加強代理人的可信度推理。GRATR 構建了一個動態可信度圖形，並使用證據信息實時更新它，並檢索相關的信任數據以增強大型語言模型 (LLM) 的推理能力。我們通過多人遊戲「狼人」的實驗驗證了我們的做法，將 GRATR 與基準 LLM 和使用 Native RAG 和 Rerank RAG 增強的 LLM 進行了比較。我們的結果表明，GRATR 在獲勝率上比基準方法高出 30%，具有卓越的推理性能。此外，GRATR 有效地減輕了 LLM 的幻覺，例如身份和目標健忘症，最重要的是，它通過使用可信度圖形使推理過程更透明且可追蹤。</paragraph>

##### **MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient**
2408.12236v1 by Yanzeng Li, Cheng Zeng, Jinchao Zhang, Jie Zhou, Lei Zou

Medical education relies heavily on Simulated Patients (SPs) to provide a
safe environment for students to practice clinical skills, including medical
image analysis. However, the high cost of recruiting qualified SPs and the lack
of diverse medical imaging datasets have presented significant challenges. To
address these issues, this paper introduces MedDiT, a novel
knowledge-controlled conversational framework that can dynamically generate
plausible medical images aligned with simulated patient symptoms, enabling
diverse diagnostic skill training. Specifically, MedDiT integrates various
patient Knowledge Graphs (KGs), which describe the attributes and symptoms of
patients, to dynamically prompt Large Language Models' (LLMs) behavior and
control the patient characteristics, mitigating hallucination during medical
conversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is
incorporated to generate medical images according to the specified patient
attributes in the KG. In this paper, we present the capabilities of MedDiT
through a practical demonstration, showcasing its ability to act in diverse
simulated patient cases and generate the corresponding medical images. This can
provide an abundant and interactive learning experience for students, advancing
medical education by offering an immersive simulation platform for future
healthcare professionals. The work sheds light on the feasibility of
incorporating advanced technologies like LLM, KG, and DiT in education
applications, highlighting their potential to address the challenges faced in
simulated patient-based medical education.

摘要：醫學教育高度依賴模擬病人 (SP) 提供一個安全的環境，讓學生練習臨床技能，包括醫學影像分析。然而，招募合格 SP 的高成本和缺乏多樣的醫學影像資料集已造成顯著的挑戰。為了解決這些問題，本文介紹 MedDiT，一個新穎的知識控制對話架構，它可以動態產生符合模擬病人症狀的合理醫學影像，實現多樣的診斷技能訓練。具體來說，MedDiT 整合了各種病人知識圖譜 (KG)，描述病人的屬性和症狀，以動態提示大型語言模型 (LLM) 的行為，並控制病人特徵，減輕醫學對話中的幻覺。此外，還納入一個經過微調的擴散Transformer (DiT) 模型，根據 KG 中指定的病人屬性產生醫學影像。在本文中，我們透過實際示範展示 MedDiT 的功能，展示它在不同模擬病人案例中作用並產生相應醫學影像的能力。這可以為學生提供豐富且互動的學習體驗，透過提供身歷其境的模擬平台，提升醫學教育，造福未來的醫療保健專業人員。這項工作闡明了在教育應用中整合 LLM、KG 和 DiT 等先進技術的可行性，突顯它們在解決模擬病人為基礎的醫學教育所面臨挑戰的潛力。

##### **Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning**
2408.12116v1 by Junlin He, Tong Nie, Wei Ma

In the geospatial domain, universal representation models are significantly
less prevalent than their extensive use in natural language processing and
computer vision. This discrepancy arises primarily from the high costs
associated with the input of existing representation models, which often
require street views and mobility data. To address this, we develop a novel,
training-free method that leverages large language models (LLMs) and auxiliary
map data from OpenStreetMap to derive geolocation representations (LLMGeovec).
LLMGeovec can represent the geographic semantics of city, country, and global
scales, which acts as a generic enhancer for spatio-temporal learning.
Specifically, by direct feature concatenation, we introduce a simple yet
effective paradigm for enhancing multiple spatio-temporal tasks including
geographic prediction (GP), long-term time series forecasting (LTSF), and
graph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly
integrate into a wide spectrum of spatio-temporal learning models, providing
immediate enhancements. Experimental results demonstrate that LLMGeovec
achieves global coverage and significantly boosts the performance of leading
GP, LTSF, and GSTF models.

摘要：在空間地理領域，通用表示模型顯著少於它們在自然語言處理和電腦視覺中的廣泛使用。這種差異主要源於現有表示模型的輸入成本高，這通常需要街景和流動性資料。為了解決這個問題，我們開發一種新穎的免訓練方法，利用大型語言模型 (LLM) 和 OpenStreetMap 的輔助地圖資料來推導地理位置表示 (LLMGeovec)。LLMGeovec 可以表示城市、國家和全球規模的地理語義，作為時空學習的通用增強器。具體來說，通過直接特徵串接，我們引入了一個簡單但有效的範例，用於增強多個時空任務，包括地理預測 (GP)、長期時間序列預測 (LTSF) 和基於圖形的時空預測 (GSTF)。LLMGeovec 可以無縫整合到廣泛的時空學習模型中，提供立即的增強。實驗結果表明，LLMGeovec 達到了全球覆蓋率，並顯著提升了領先的 GP、LTSF 和 GSTF 模型的效能。

##### **Enabling Small Models for Zero-Shot Classification through Model Label Learning**
2408.11449v1 by Jia Zhang, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li

Vision-language models (VLMs) like CLIP have demonstrated impressive
zero-shot ability in image classification tasks by aligning text and images but
suffer inferior performance compared with task-specific expert models. On the
contrary, expert models excel in their specialized domains but lack zero-shot
ability for new tasks. How to obtain both the high performance of expert models
and zero-shot ability is an important research direction. In this paper, we
attempt to demonstrate that by constructing a model hub and aligning models
with their functionalities using model labels, new tasks can be solved in a
zero-shot manner by effectively selecting and reusing models in the hub. We
introduce a novel paradigm, Model Label Learning (MLL), which bridges the gap
between models and their functionalities through a Semantic Directed Acyclic
Graph (SDAG) and leverages an algorithm, Classification Head Combination
Optimization (CHCO), to select capable models for new tasks. Compared with the
foundation model paradigm, it is less costly and more scalable, i.e., the
zero-shot ability grows with the sizes of the model hub. Experiments on seven
real-world datasets validate the effectiveness and efficiency of MLL,
demonstrating that expert models can be effectively reused for zero-shot tasks.
Our code will be released publicly.

摘要：視覺語言模型（VLM），例如 CLIP，已在影像分類任務中展現令人印象深刻的零次學習能力，方法是對齊文字和影像，但與特定任務的專家模型相比，其效能較差。相反地，專家模型在其專業領域中表現出色，但對於新任務缺乏零次學習能力。如何同時獲得專家模型的高效能和零次學習能力，是一個重要的研究方向。在本文中，我們嘗試透過建立模型中心，並使用模型標籤將模型與其功能對齊，證明可以透過有效選擇和重複使用中心中的模型，以零次學習的方式解決新任務。我們提出了一種新的範例，即模型標籤學習（MLL），它透過語義導向非循環圖（SDAG）彌合模型及其功能之間的差距，並利用一種演算法，即分類頭組合最佳化（CHCO），為新任務選擇有能力的模型。與基礎模型範例相比，它的成本較低且更具可擴充性，也就是說，零次學習能力會隨著模型中心規模的擴大而增長。在七個真實世界資料集上的實驗驗證了 MLL 的有效性和效率，證明了專家模型可以有效地重複用於零次學習任務。我們的程式碼將公開發布。

##### **Hide Your Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Neural Carrier Articles**
2408.11182v1 by Zhilong Wang, Haizhou Wang, Nanqing Luo, Lan Zhang, Xiaoyan Sun, Yebo Cao, Peng Liu

Jailbreak attacks on Language Model Models (LLMs) entail crafting prompts
aimed at exploiting the models to generate malicious content. This paper
proposes a new type of jailbreak attacks which shift the attention of the LLM
by inserting a prohibited query into a carrier article. The proposed attack
leverage the knowledge graph and a composer LLM to automatically generating a
carrier article that is similar to the topic of the prohibited query but does
not violate LLM's safeguards. By inserting the malicious query to the carrier
article, the assembled attack payload can successfully jailbreak LLM. To
evaluate the effectiveness of our method, we leverage 4 popular categories of
``harmful behaviors'' adopted by related researches to attack 6 popular LLMs.
Our experiment results show that the proposed attacking method can successfully
jailbreak all the target LLMs which high success rate, except for Claude-3.

摘要：語言模型模型（LLM）的越獄攻擊涉及製作提示，旨在利用模型來產生惡意內容。本文提出了一種新型的越獄攻擊，它通過在載體文章中插入禁止查詢來轉移 LLM 的注意力。提議的攻擊利用知識圖譜和作曲家 LLM 自動生成與禁止查詢的主題相似但不會違反 LLM 保障措施的載體文章。通過將惡意查詢插入載體文章中，組裝的攻擊有效載荷可以成功越獄 LLM。為了評估我們方法的有效性，我們利用相關研究採用的 4 類流行的「有害行為」來攻擊 6 個流行的 LLM。我們的實驗結果表明，所提出的攻擊方法可以成功越獄所有目標 LLM，成功率很高，除了 Claude-3。

##### **Public Health in Disaster: Emotional Health and Life Incidents Extraction during Hurricane Harvey**
2408.11133v1 by Thomas Hoang, Quynh Anh Nguyen, Long Nguyen

Countless disasters have resulted from climate change, causing severe damage
to infrastructure and the economy. These disasters have significant societal
impacts, necessitating mental health services for the millions affected. To
prepare for and respond effectively to such events, it is important to
understand people's emotions and the life incidents they experience before and
after a disaster strikes. In this case study, we collected a dataset of
approximately 400,000 public tweets related to the storm. Using a BERT-based
model, we predicted the emotions associated with each tweet. To efficiently
identify these topics, we utilized the Latent Dirichlet Allocation (LDA)
technique for topic modeling, which allowed us to bypass manual content
analysis and extract meaningful patterns from the data. However, rather than
stopping at topic identification like previous methods \cite{math11244910}, we
further refined our analysis by integrating Graph Neural Networks (GNN) and
Large Language Models (LLM). The GNN was employed to generate embeddings and
construct a similarity graph of the tweets, which was then used to optimize
clustering. Subsequently, we used an LLM to automatically generate descriptive
names for each event cluster, offering critical insights for disaster
preparedness and response strategies.

摘要：無數的災難是由於氣候變遷所造成的，對基礎建設和經濟造成嚴重的損害。這些災難對社會造成重大的影響，需要為數百萬受災民眾提供心理健康服務。為了有效地為此類事件做好準備並作出回應，了解人們的情緒以及他們在災難發生前後所經歷的生活事件非常重要。在本案例研究中，我們收集了一個包含約 400,000 則與風暴相關的公開推文的資料集。使用基於 BERT 的模型，我們預測了與每則推文相關的情緒。為了有效率地找出這些主題，我們利用了潛在狄利克雷配置 (LDA) 技術進行主題建模，這讓我們能夠繞過手動內容分析，從資料中萃取出有意義的模式。然而，我們並未像先前的研究方法 \cite{math11244910} 那樣僅止於主題辨識，而是進一步整合圖神經網路 (GNN) 和大型語言模型 (LLM) 來優化我們的分析。GNN 被用於產生嵌入和建構推文的相似性圖，然後用於最佳化分群。隨後，我們使用 LLM 為每個事件群集自動產生描述性名稱，為災害防範和應變策略提供重要的見解。

##### **Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains**
2408.10819v1 by Rui Yang, Jiahao Zhu, Jianping Man, Li Fang, Yi Zhou

Knowledge graph completion (KGC) aims to identify missing triples in a
knowledge graph (KG). This is typically achieved through tasks such as link
prediction and instance completion. However, these methods often focus on
either static knowledge graphs (SKGs) or temporal knowledge graphs (TKGs),
addressing only within-scope triples. This paper introduces a new generative
completion framework called Generative Subgraph-based KGC (GS-KGC). GS-KGC
employs a question-answering format to directly generate target entities,
addressing the challenge of questions having multiple possible answers. We
propose a strategy that extracts subgraphs centered on entities and
relationships within the KG, from which negative samples and neighborhood
information are separately obtained to address the one-to-many problem. Our
method generates negative samples using known facts to facilitate the discovery
of new information. Furthermore, we collect and refine neighborhood path data
of known entities, providing contextual information to enhance reasoning in
large language models (LLMs). Our experiments evaluated the proposed method on
four SKGs and two TKGs, achieving state-of-the-art Hits@1 metrics on five
datasets. Analysis of the results shows that GS-KGC can discover new triples
within existing KGs and generate new facts beyond the closed KG, effectively
bridging the gap between closed-world and open-world KGC.

摘要：知識圖譜補全 (KGC) 的目標是識別知識圖譜 (KG) 中遺失的三元組。這通常透過連結預測和實例補全等任務達成。然而，這些方法通常專注於靜態知識圖譜 (SKG) 或時序知識圖譜 (TKG)，僅處理範圍內的三元組。本文介紹一個名為生成子圖為基礎的 KGC (GS-KGC) 的新生成補全架構。GS-KGC 使用問答格式直接生成目標實體，以解決問題有多個可能答案的挑戰。我們提出一個策略，從知識圖譜中以實體和關係為中心的子圖，從中分別取得負面樣本和鄰域資訊，以解決一對多問題。我們的模型使用已知事實生成負面樣本，以利發現新資訊。此外，我們收集並精煉已知實體的鄰域路徑資料，提供背景資訊以增強大型語言模型 (LLM) 中的推理。我們的實驗在四個 SKG 和兩個 TKG 上評估所提出的方法，在五個資料集上達成最先進的 Hits@1 指標。結果分析顯示，GS-KGC 能夠在現有的 KG 中發現新的三元組，並生成封閉 KG 以外的新事實，有效地縮小封閉世界和開放世界 KGC 之間的差距。

##### **Hologram Reasoning for Solving Algebra Problems with Geometry Diagrams**
2408.10592v1 by Litian Huang, Xinguo Yu, Feng Xiong, Bin He, Shengbing Tang, Jiawen Fu

Solving Algebra Problems with Geometry Diagrams (APGDs) is still a
challenging problem because diagram processing is not studied as intensively as
language processing. To work against this challenge, this paper proposes a
hologram reasoning scheme and develops a high-performance method for solving
APGDs by using this scheme. To reach this goal, it first defines a hologram,
being a kind of graph, and proposes a hologram generator to convert a given
APGD into a hologram, which represents the entire information of APGD and the
relations for solving the problem can be acquired from it by a uniform way.
Then HGR, a hologram reasoning method employs a pool of prepared graph models
to derive algebraic equations, which is consistent with the geometric theorems.
This method is able to be updated by adding new graph models into the pool.
Lastly, it employs deep reinforcement learning to enhance the efficiency of
model selection from the pool. The entire HGR not only ensures high solution
accuracy with fewer reasoning steps but also significantly enhances the
interpretability of the solution process by providing descriptions of all
reasoning steps. Experimental results demonstrate the effectiveness of HGR in
improving both accuracy and interpretability in solving APGDs.

摘要：利用幾何圖形圖（APGD）解決代數問題仍然是一個具有挑戰性的問題，因為圖形處理的研究不如語言處理那麼深入。為了應對這一挑戰，本文提出了一種全息推理方案，並開發了一種使用該方案解決 APGD 的高性能方法。為了達到這個目標，它首先定義了一個全息圖，作為一種圖形，並提出了一個全息圖生成器，將給定的 APGD 轉換為一個全息圖，它表示 APGD 的全部信息，並且可以通過統一的方式從中獲取解決問題的關係。然後，HGR，一種全息推理方法，採用一組準備好的圖形模型來推導代數方程式，這與幾何定理是一致的。這種方法可以通過向池中添加新的圖形模型來更新。最後，它採用深度強化學習來提高從池中選擇模型的效率。整個 HGR 不僅確保了較少的推理步驟即可獲得較高的求解精度，而且還通過提供所有推理步驟的描述來顯著增強了解決過程的可解釋性。實驗結果證明了 HGR 在提高求解 APGD 的準確性和可解釋性方面的有效性。

##### **Query languages for neural networks**
2408.10362v2 by Martin Grohe, Christoph Standke, Juno Steegmans, Jan Van den Bussche

We lay the foundations for a database-inspired approach to interpreting and
understanding neural network models by querying them using declarative
languages. Towards this end we study different query languages, based on
first-order logic, that mainly differ in their access to the neural network
model. First-order logic over the reals naturally yields a language which views
the network as a black box; only the input--output function defined by the
network can be queried. This is essentially the approach of constraint query
languages. On the other hand, a white-box language can be obtained by viewing
the network as a weighted graph, and extending first-order logic with summation
over weight terms. The latter approach is essentially an abstraction of SQL. In
general, the two approaches are incomparable in expressive power, as we will
show. Under natural circumstances, however, the white-box approach can subsume
the black-box approach; this is our main result. We prove the result concretely
for linear constraint queries over real functions definable by feedforward
neural networks with a fixed number of hidden layers and piecewise linear
activation functions.

摘要：<paragraph>我們奠定了一個受資料庫啟發的基礎，用於透過使用宣告式語言對神經網路模型進行詮釋和理解。為了達到這個目的，我們研究了基於一階邏輯的不同查詢語言，它們主要在於對神經網路模型的存取方式不同。一階實數邏輯自然會產生一種語言，將網路視為一個黑盒子；只能查詢網路定義的輸入輸出函數。這基本上是約束查詢語言的方法。另一方面，可以透過將網路視為一個加權圖，並將一階邏輯延伸到權重項上的總和，來取得一個白盒語言。後者方法基本上是 SQL 的抽象。一般來說，這兩種方法在表達能力上無法相提並論，我們將會證明這一點。然而，在自然情況下，白盒方法可以包含黑盒方法；這是我們的重點。我們具體證明了線性約束查詢對於由具有固定數量隱藏層和分段線性激活函數的前饋神經網路可定義的實函數。</paragraph>

##### **Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**
2408.10124v1 by Tianyu Zhang, Yuxiang Ren, Chengbin Hou, Hairong Lv, Xuegong Zhang

Molecular property prediction is a crucial foundation for drug discovery. In
recent years, pre-trained deep learning models have been widely applied to this
task. Some approaches that incorporate prior biological domain knowledge into
the pre-training framework have achieved impressive results. However, these
methods heavily rely on biochemical experts, and retrieving and summarizing
vast amounts of domain knowledge literature is both time-consuming and
expensive. Large Language Models (LLMs) have demonstrated remarkable
performance in understanding and efficiently providing general knowledge.
Nevertheless, they occasionally exhibit hallucinations and lack precision in
generating domain-specific knowledge. Conversely, Domain-specific Small Models
(DSMs) possess rich domain knowledge and can accurately calculate molecular
domain-related metrics. However, due to their limited model size and singular
functionality, they lack the breadth of knowledge necessary for comprehensive
representation learning. To leverage the advantages of both approaches in
molecular property prediction, we propose a novel Molecular Graph
representation learning framework that integrates Large language models and
Domain-specific small models (MolGraph-LarDo). Technically, we design a
two-stage prompt strategy where DSMs are introduced to calibrate the knowledge
provided by LLMs, enhancing the accuracy of domain-specific information and
thus enabling LLMs to generate more precise textual descriptions for molecular
samples. Subsequently, we employ a multi-modal alignment method to coordinate
various modalities, including molecular graphs and their corresponding
descriptive texts, to guide the pre-training of molecular representations.
Extensive experiments demonstrate the effectiveness of the proposed method.

摘要：分子特性預測是藥物發現的關鍵基礎。近年來，預訓練深度學習模型已廣泛應用於此任務。一些將先驗生物領域知識納入預訓練架構的方法已取得令人印象深刻的成果。然而，這些方法嚴重依賴於生物化學專家，並且檢索和總結大量的領域知識文獻既耗時又昂貴。大型語言模型 (LLM) 在理解和有效提供一般知識方面展示了卓越的性能。儘管如此，它們偶爾會出現幻覺，並且在生成特定領域的知識時缺乏精確性。相反，特定領域的小模型 (DSM) 擁有豐富的領域知識，並且可以準確計算與分子領域相關的指標。然而，由於它們有限的模型大小和單一功能，它們缺乏全面表示學習所需的知識廣度。為了在分子特性預測中利用這兩種方法的優點，我們提出了一個新穎的分子圖表示學習框架，它集成了大型語言模型和特定領域的小模型 (MolGraph-LarDo)。在技術上，我們設計了一個兩階段提示策略，其中引入 DSM 來校準 LLM 提供的知識，提高特定領域信息的準確性，從而使 LLM 能夠為分子樣本生成更精確的文本描述。隨後，我們採用多模態對齊方法來協調各種模態，包括分子圖及其對應的描述性文本，以指導分子表示的預訓練。廣泛的實驗證明了所提出方法的有效性。

##### **Geometry Informed Tokenization of Molecules for Language Model Generation**
2408.10120v1 by Xiner Li, Limei Wang, Youzhi Luo, Carl Edwards, Shurui Gui, Yuchao Lin, Heng Ji, Shuiwang Ji

We consider molecule generation in 3D space using language models (LMs),
which requires discrete tokenization of 3D molecular geometries. Although
tokenization of molecular graphs exists, that for 3D geometries is largely
unexplored. Here, we attempt to bridge this gap by proposing the Geo2Seq, which
converts molecular geometries into $SE(3)$-invariant 1D discrete sequences.
Geo2Seq consists of canonical labeling and invariant spherical representation
steps, which together maintain geometric and atomic fidelity in a format
conducive to LMs. Our experiments show that, when coupled with Geo2Seq, various
LMs excel in molecular geometry generation, especially in controlled generation
tasks.

摘要：我們考慮使用語言模型 (LM) 在 3D 空間中生成分子，這需要對 3D 分子幾何結構進行離散的標記化。儘管存在分子圖的標記化，但對 3D 幾何結構的標記化在很大程度上尚未被探索。在此，我們嘗試通過提出 Geo2Seq 來彌合這一差距，該方法將分子幾何結構轉換為 $SE(3)$ 不變的 1D 離散序列。Geo2Seq 包含規範標籤和不變球面表示步驟，它們共同以有利於 LM 的格式保持幾何和原子保真度。我們的實驗表明，當與 Geo2Seq 結合使用時，各種 LM 在分子幾何生成方面表現出色，特別是在受控生成任務中。

##### **GLIMMER: Incorporating Graph and Lexical Features in Unsupervised Multi-Document Summarization**
2408.10115v1 by Ran Liu, Ming Liu, Min Yu, Jianguo Jiang, Gang Li, Dan Zhang, Jingyuan Li, Xiang Meng, Weiqing Huang

Pre-trained language models are increasingly being used in multi-document
summarization tasks. However, these models need large-scale corpora for
pre-training and are domain-dependent. Other non-neural unsupervised
summarization approaches mostly rely on key sentence extraction, which can lead
to information loss. To address these challenges, we propose a lightweight yet
effective unsupervised approach called GLIMMER: a Graph and LexIcal features
based unsupervised Multi-docuMEnt summaRization approach. It first constructs a
sentence graph from the source documents, then automatically identifies
semantic clusters by mining low-level features from raw texts, thereby
improving intra-cluster correlation and the fluency of generated sentences.
Finally, it summarizes clusters into natural sentences. Experiments conducted
on Multi-News, Multi-XScience and DUC-2004 demonstrate that our approach
outperforms existing unsupervised approaches. Furthermore, it surpasses
state-of-the-art pre-trained multi-document summarization models (e.g. PEGASUS
and PRIMERA) under zero-shot settings in terms of ROUGE scores. Additionally,
human evaluations indicate that summaries generated by GLIMMER achieve high
readability and informativeness scores. Our code is available at
https://github.com/Oswald1997/GLIMMER.

摘要：预训练语言模型在多文件摘要任务中被越来越多地使用。然而，这些模型需要大规模语料库进行预训练，并且依赖于领域。其他非神经无监督摘要方法主要依赖于关键句子提取，这可能导致信息丢失。为了应对这些挑战，我们提出了一种轻量级但有效的无监督方法，称为 GLIMMER：一种基于图和词汇特征的无监督多文档摘要方法。它首先从源文档构建一个句子图，然后通过从原始文本中挖掘低级特征自动识别语义簇，从而提高簇内相关性和生成句子的流畅性。最后，它将簇总结为自然句子。在 Multi-News、Multi-XScience 和 DUC-2004 上进行的实验表明，我们的方法优于现有的无监督方法。此外，在零样本设置下，它在 ROUGE 得分方面超越了最先进的预训练多文档摘要模型（例如 PEGASUS 和 PRIMERA）。此外，人类评估表明，GLIMMER 生成的摘要获得了很高的可读性和信息性得分。我们的代码可在 https://github.com/Oswald1997/GLIMMER 获得。

##### **SEMDR: A Semantic-Aware Dual Encoder Model for Legal Judgment Prediction with Legal Clue Tracing**
2408.09717v1 by Pengjie Liu, Wang Zhang, Yulong Ding, Xuefeng Zhang, Shuang-Hua Yang

Legal Judgment Prediction (LJP) aims to form legal judgments based on the
criminal fact description. However, researchers struggle to classify confusing
criminal cases, such as robbery and theft, which requires LJP models to
distinguish the nuances between similar crimes. Existing methods usually design
handcrafted features to pick up necessary semantic legal clues to make more
accurate legal judgment predictions. In this paper, we propose a Semantic-Aware
Dual Encoder Model (SEMDR), which designs a novel legal clue tracing mechanism
to conduct fine-grained semantic reasoning between criminal facts and
instruments. Our legal clue tracing mechanism is built from three reasoning
levels: 1) Lexicon-Tracing, which aims to extract criminal facts from criminal
descriptions; 2) Sentence Representation Learning, which contrastively trains
language models to better represent confusing criminal facts; 3) Multi-Fact
Reasoning, which builds a reasons graph to propagate semantic clues among fact
nodes to capture the subtle difference among criminal facts. Our legal clue
tracing mechanism helps SEMDR achieve state-of-the-art on the CAIL2018 dataset
and shows its advance in few-shot scenarios. Our experiments show that SEMDR
has a strong ability to learn more uniform and distinguished representations
for criminal facts, which helps to make more accurate predictions on confusing
criminal cases and reduces the model uncertainty during making judgments. All
codes will be released via GitHub.

摘要：法律判決預測 (LJP) 旨在根據犯罪事實描述形成法律判決。然而，研究人員難以對搶劫和盜竊等令人困惑的刑事案件進行分類，這需要 LJP 模型區分類似犯罪之間的細微差別。現有方法通常設計手工特徵以獲取必要的語義法律線索，以做出更準確的法律判決預測。在本文中，我們提出了一個語義感知雙編碼器模型 (SEMDR)，它設計了一種新穎的法律線索追蹤機制，以在犯罪事實和工具之間進行細粒度的語義推理。我們的法律線索追蹤機制建立在三個推理層級之上：1) 詞彙追蹤，旨在從犯罪描述中提取犯罪事實；2) 句子表示學習，對比訓練語言模型以更好地表示令人困惑的犯罪事實；3) 多事實推理，構建一個原因圖，在事實節點之間傳播語義線索，以捕捉犯罪事實之間的細微差別。我們的法律線索追蹤機制幫助 SEMDR 在 CAIL2018 資料集上實現了最先進的技術，並展示了其在少鏡頭場景中的進步。我們的實驗表明，SEMDR 具有學習更統一和區別的犯罪事實表示的強大能力，這有助於對令人困惑的刑事案件做出更準確的預測，並在做出判決時減少模型的不確定性。所有代碼都將通過 GitHub 發布。

##### **Revisiting the Graph Reasoning Ability of Large Language Models: Case Studies in Translation, Connectivity and Shortest Path**
2408.09529v1 by Xinnan Dai, Qihao Wen, Yifei Shen, Hongzhi Wen, Dongsheng Li, Jiliang Tang, Caihua Shan

Large Language Models (LLMs) have achieved great success in various reasoning
tasks. In this work, we focus on the graph reasoning ability of LLMs. Although
theoretical studies proved that LLMs are capable of handling graph reasoning
tasks, empirical evaluations reveal numerous failures. To deepen our
understanding on this discrepancy, we revisit the ability of LLMs on three
fundamental graph tasks: graph description translation, graph connectivity, and
the shortest-path problem. Our findings suggest that LLMs can fail to
understand graph structures through text descriptions and exhibit varying
performance for all these three fundamental tasks. Meanwhile, we perform a
real-world investigation on knowledge graphs and make consistent observations
with our findings. The codes and datasets are available.

摘要：大型語言模型 (LLM) 在各種推理任務中已取得巨大的成功。在這項工作中，我們專注於 LLM 的圖形推理能力。儘管理論研究證明 LLM 有能力處理圖形推理任務，但經驗評估顯示出許多失敗。為了加深我們對這種差異的理解，我們重新探討 LLM 在三個基本圖形任務上的能力：圖形描述翻譯、圖形連通性和最短路徑問題。我們的研究結果表明，LLM 可能無法通過文本描述理解圖形結構，並且在所有這三個基本任務中表現出不同的性能。同時，我們對知識圖譜進行了現實世界的調查，並對我們的發現進行了一致的觀察。代碼和數據集可用。

##### **Retrieval-Augmented Generation Meets Data-Driven Tabula Rasa Approach for Temporal Knowledge Graph Forecasting**
2408.13273v1 by Geethan Sannidhi, Sagar Srinivas Sakhinana, Venkataramana Runkana

Pre-trained large language models (PLLMs) like OpenAI ChatGPT and Google
Gemini face challenges such as inaccurate factual recall, hallucinations,
biases, and future data leakage for temporal Knowledge Graph (tKG) forecasting.
To address these issues, we introduce sLA-tKGF (small-scale language assistant
for tKG forecasting), which utilizes Retrieval-Augmented Generation (RAG)
aided, custom-trained small-scale language models through a tabula rasa
approach from scratch for effective tKG forecasting. Our framework constructs
knowledge-infused prompts with relevant historical data from tKGs, web search
results, and PLLMs-generated textual descriptions to understand historical
entity relationships prior to the target time. It leverages these external
knowledge-infused prompts for deeper understanding and reasoning of
context-specific semantic and temporal information to zero-shot prompt
small-scale language models for more accurate predictions of future events
within tKGs. It reduces hallucinations and mitigates distributional shift
challenges through comprehending changing trends over time. As a result, it
enables more accurate and contextually grounded forecasts of future events
while minimizing computational demands. Rigorous empirical studies demonstrate
our framework robustness, scalability, and state-of-the-art (SOTA) performance
on benchmark datasets with interpretable and trustworthy tKG forecasting.

摘要：預訓練大型語言模型（PLLM），例如 OpenAI ChatGPT 和 Google
Gemini 面臨挑戰，例如不準確的事實回憶、幻覺、
偏見和時間知識圖（tKG）預測的未來數據洩漏。
為了解決這些問題，我們引入了 sLA-tKGF（tKG 預測的小規模語言助理），它利用檢索增強生成（RAG）
輔助，從頭開始通過白板法自訂訓練的小規模語言模型，以進行有效的 tKG 預測。我們的架構建構
注入知識的提示，其中包含來自 tKG、網路搜尋
結果和 PLLM 生成的文字描述，以了解目標時間之前的歷史實體關係。它利用這些外部
注入知識的提示，以更深入地理解和推理
特定於脈絡的語義和時間資訊，以零次提示小規模語言模型，以更準確地預測 tKG 中的未來事件。它減少幻覺並透過了解隨時間變化的趨勢來減輕分佈轉移挑戰。因此，它
能更準確且有脈絡地預測未來事件，同時將運算需求降至最低。嚴謹的實證研究證明
我們的架構具有穩健性、可擴充性和最先進（SOTA）效能
在基準資料集上進行可解釋且值得信賴的 tKG 預測。

##### **Reefknot: A Comprehensive Benchmark for Relation Hallucination Evaluation, Analysis and Mitigation in Multimodal Large Language Models**
2408.09429v1 by Kening Zheng, Junkai Chen, Yibo Yan, Xin Zou, Xuming Hu

Hallucination issues persistently plagued current multimodal large language
models (MLLMs). While existing research primarily focuses on object-level or
attribute-level hallucinations, sidelining the more sophisticated relation
hallucinations that necessitate advanced reasoning abilities from MLLMs.
Besides, recent benchmarks regarding relation hallucinations lack in-depth
evaluation and effective mitigation. Moreover, their datasets are typically
derived from a systematic annotation process, which could introduce inherent
biases due to the predefined process. To handle the aforementioned challenges,
we introduce Reefknot, a comprehensive benchmark specifically targeting
relation hallucinations, consisting of over 20,000 samples derived from
real-world scenarios. Specifically, we first provide a systematic definition of
relation hallucinations, integrating perspectives from perceptive and cognitive
domains. Furthermore, we construct the relation-based corpus utilizing the
representative scene graph dataset Visual Genome (VG), from which semantic
triplets follow real-world distributions. Our comparative evaluation across
three distinct tasks revealed a substantial shortcoming in the capabilities of
current MLLMs to mitigate relation hallucinations. Finally, we advance a novel
confidence-based mitigation strategy tailored to tackle the relation
hallucinations problem. Across three datasets, including Reefknot, we observed
an average reduction of 9.75% in the hallucination rate. We believe our paper
sheds valuable insights into achieving trustworthy multimodal intelligence. Our
dataset and code will be released upon paper acceptance.

摘要：幻覺問題持續困擾著當前的多模態大型語言模型 (MLLM)。雖然現有研究主要關注物件層級或屬性層級的幻覺，但卻忽視了需要 MLLM 具備進階推理能力的更複雜關係幻覺。此外，關於關係幻覺的最新基準缺乏深入評估和有效的緩解措施。而且，他們的資料集通常來自系統化的註釋過程，這可能會因為預先定義的過程而引入固有的偏差。為了應對上述挑戰，我們引入了 Reefknot，這是一個專門針對關係幻覺的綜合基準，包含超過 20,000 個來自真實世界場景的範例。具體來說，我們首先提供關係幻覺的系統性定義，整合來自知覺和認知領域的觀點。此外，我們利用具有代表性的場景圖形資料集 Visual Genome (VG) 建構基於關係的語料庫，語義三元組遵循真實世界的分佈。我們在三個不同的任務中進行比較評估，揭示了當前 MLLM 在減輕關係幻覺方面的能力存在重大缺陷。最後，我們提出了一種新的基於信心的緩解策略，專門用於解決關係幻覺問題。在包括 Reefknot 在內的三個資料集中，我們觀察到幻覺率平均降低了 9.75%。我們相信我們的論文對實現值得信賴的多模態智慧提供了寶貴的見解。我們的資料集和程式碼將在論文被接受後發布。

##### **ASGM-KG: Unveiling Alluvial Gold Mining Through Knowledge Graphs**
2408.08972v1 by Debashis Gupta, Aditi Golder, Luis Fernendez, Miles Silman, Greg Lersen, Fan Yang, Bob Plemmons, Sarra Alqahtani, Paul Victor Pauca

Artisanal and Small-Scale Gold Mining (ASGM) is a low-cost yet highly
destructive mining practice, leading to environmental disasters across the
world's tropical watersheds. The topic of ASGM spans multiple domains of
research and information, including natural and social systems, and knowledge
is often atomized across a diversity of media and documents. We therefore
introduce a knowledge graph (ASGM-KG) that consolidates and provides crucial
information about ASGM practices and their environmental effects. The current
version of ASGM-KG consists of 1,899 triples extracted using a large language
model (LLM) from documents and reports published by both non-governmental and
governmental organizations. These documents were carefully selected by a group
of tropical ecologists with expertise in ASGM. This knowledge graph was
validated using two methods. First, a small team of ASGM experts reviewed and
labeled triples as factual or non-factual. Second, we devised and applied an
automated factual reduction framework that relies on a search engine and an LLM
for labeling triples. Our framework performs as well as five baselines on a
publicly available knowledge graph and achieves over 90 accuracy on our ASGM-KG
validated by domain experts. ASGM-KG demonstrates an advancement in knowledge
aggregation and representation for complex, interdisciplinary environmental
crises such as ASGM.

摘要：手工和小型採金（ASGM）是一種低成本但高度破壞性的採礦實務，導致全球熱帶流域發生環境災難。ASGM 的主題涵蓋多個研究和資訊領域，包括自然和社會系統，而知識通常分散在各種媒體和文件中。因此，我們引入知識圖譜 (ASGM-KG)，它整合並提供有關 ASGM 實務及其環境影響的重要資訊。目前版本的 ASGM-KG 包含 1,899 個三元組，這些三元組是使用大型語言模型 (LLM) 從非政府組織和政府組織發布的文件和報告中提取出來的。這些文件是由一群具有 ASGM 專業知識的熱帶生態學家仔細挑選的。這個知識圖譜使用兩種方法驗證。首先，一小組 ASGM 專家審查並將三元組標記為事實或非事實。其次，我們設計並應用了一個自動化的事實簡化架構，該架構依賴於搜尋引擎和 LLM 來標記三元組。我們的架構在公開的知識圖譜上執行得與五個基準一樣好，並在我們由領域專家驗證的 ASGM-KG 上達到超過 90 的準確度。ASGM-KG 展示了複雜的跨學科環境危機（例如 ASGM）的知識彙整和表示方面的一項進展。

##### **EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**
2408.08782v1 by Chenwei Wan, Matthieu Labeau, Chloé Clavel

Designing emotionally intelligent conversational systems to provide comfort
and advice to people experiencing distress is a compelling area of research.
Previous efforts have focused on developing modular dialogue systems that treat
socio-emotional strategy prediction as an auxiliary task and generate
strategy-conditioned responses with customized decoders. Recently, with
advancements in large language models (LLMs), end-to-end dialogue agents
without explicit socio-emotional strategy prediction steps have become
prevalent. However, despite their excellence in language generation, recent
studies show that LLMs' inherent preference bias towards certain
socio-emotional strategies hinders the delivery of high-quality emotional
support. To address this challenge, we propose decoupling strategy prediction
from language generation, and introduce a novel dialogue strategy predictor,
EmoDynamiX, which models the discourse dynamics between user emotions and
system strategies using a heterogeneous graph. Additionally, we make use of the
Emotion Recognition in Conversations (ERC) task and design a flexible
mixed-emotion module to capture fine-grained emotional states of the user.
Experimental results on two ESC datasets show EmoDynamiX outperforms previous
state-of-the-art methods with a significant margin.

摘要：設計情緒智能對話系統以提供安慰和建議給經歷痛苦的人是一個引人入勝的研究領域。
先前的努力集中於開發模組化對話系統，將社會情緒策略預測視為輔助任務，並使用自訂解碼器產生策略條件化的回應。最近，隨著大型語言模型 (LLM) 的進步，沒有明確社會情緒策略預測步驟的端到端對話代理已變得普遍。然而，儘管它們在語言生成方面表現出色，但最近的研究表明，LLM 對某些社會情緒策略的固有偏好會阻礙提供高品質的情緒支持。為了應對這一挑戰，我們建議將策略預測與語言生成解耦，並引入一種新穎的對話策略預測器 EmoDynamiX，它使用異質圖形對使用者情緒和系統策略之間的話語動態進行建模。此外，我們利用對話中的情緒辨識 (ERC) 任務並設計了一個靈活的混合情緒模組來捕捉使用者的細緻情緒狀態。在兩個 ESC 資料集上的實驗結果顯示，EmoDynamiX 以顯著的幅度優於先前的最新方法。

##### **Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?**
2408.08685v1 by Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi

Graph neural networks (GNNs) are vulnerable to adversarial perturbations,
especially for topology attacks, and many methods that improve the robustness
of GNNs have received considerable attention. Recently, we have witnessed the
significant success of large language models (LLMs), leading many to explore
the great potential of LLMs on GNNs. However, they mainly focus on improving
the performance of GNNs by utilizing LLMs to enhance the node features.
Therefore, we ask: Will the robustness of GNNs also be enhanced with the
powerful understanding and inference capabilities of LLMs? By presenting the
empirical results, we find that despite that LLMs can improve the robustness of
GNNs, there is still an average decrease of 23.1% in accuracy, implying that
the GNNs remain extremely vulnerable against topology attack. Therefore,
another question is how to extend the capabilities of LLMs on graph adversarial
robustness. In this paper, we propose an LLM-based robust graph structure
inference framework, LLM4RGNN, which distills the inference capabilities of
GPT-4 into a local LLM for identifying malicious edges and an LM-based edge
predictor for finding missing important edges, so as to recover a robust graph
structure. Extensive experiments demonstrate that LLM4RGNN consistently
improves the robustness across various GNNs. Even in some cases where the
perturbation ratio increases to 40%, the accuracy of GNNs is still better than
that on the clean graph.

摘要：圖形神經網路 (GNN) 容易受到對抗性擾動的影響，
特別是拓撲攻擊，許多改善 GNN 魯棒性的方法都備受關注。最近，我們見證了大型語言模型 (LLM) 的顯著成功，導致許多人探索 LLM 在 GNN 上的巨大潛力。然而，他們主要專注於利用 LLM 增強節點特徵來改善 GNN 的效能。
因此，我們問：LLM 強大的理解和推理能力是否也會增強 GNN 的魯棒性？透過呈現實證結果，我們發現儘管 LLM 可以改善 GNN 的魯棒性，但準確度仍平均下降 23.1%，這表示 GNN 仍然極容易受到拓撲攻擊。因此，另一個問題是如何擴展 LLM 在圖形對抗魯棒性上的能力。在本文中，我們提出一個基於 LLM 的魯棒圖形結構推理框架 LLM4RGNN，它將 GPT-4 的推理能力提煉成一個用於識別惡意邊緣的本地 LLM，以及一個用於尋找遺失重要邊緣的基於 LM 的邊緣預測器，以便恢復一個魯棒的圖形結構。廣泛的實驗證明，LLM4RGNN 持續改善各種 GNN 的魯棒性。即使在某些擾動率增加到 40% 的情況下，GNN 的準確度仍然優於乾淨圖形。

##### **RoarGraph: A Projected Bipartite Graph for Efficient Cross-Modal Approximate Nearest Neighbor Search**
2408.08933v1 by Meng Chen, Kai Zhang, Zhenying He, Yinan Jing, X. Sean Wang

Approximate Nearest Neighbor Search (ANNS) is a fundamental and critical
component in many applications, including recommendation systems and large
language model-based applications. With the advancement of multimodal neural
models, which transform data from different modalities into a shared
high-dimensional space as feature vectors, cross-modal ANNS aims to use the
data vector from one modality (e.g., texts) as the query to retrieve the most
similar items from another (e.g., images or videos). However, there is an
inherent distribution gap between embeddings from different modalities, and
cross-modal queries become Out-of-Distribution (OOD) to the base data.
Consequently, state-of-the-art ANNS approaches suffer poor performance for OOD
workloads. In this paper, we quantitatively analyze the properties of the OOD
workloads to gain an understanding of their ANNS efficiency. Unlike
single-modal workloads, we reveal OOD queries spatially deviate from base data,
and the k-nearest neighbors of an OOD query are distant from each other in the
embedding space. The property breaks the assumptions of existing ANNS
approaches and mismatches their design for efficient search. With insights from
the OOD workloads, we propose pRojected bipartite Graph (RoarGraph), an
efficient ANNS graph index built under the guidance of query distribution.
Extensive experiments show that RoarGraph significantly outperforms
state-of-the-art approaches on modern cross-modal datasets, achieving up to
3.56x faster search speed at a 90% recall rate for OOD queries.

摘要：近似最近邻搜索 (ANNS) 是许多应用程序中的基本关键组件，包括推荐系统和基于大语言模型的应用程序。随着多模态神经模型的发展，它将来自不同模态的数据转换为共享的高维空间作为特征向量，跨模态 ANNS 旨在使用来自一个模态（例如文本）的数据向量作为查询，以检索来自另一个模态（例如图像或视频）最相似的项目。但是，不同模态的嵌入之间存在固有的分布差距，并且跨模态查询对于基础数据而言成为分布外 (OOD)。因此，最先进的 ANNS 方法对于 OOD 工作负载的性能很差。在本文中，我们定量分析了 OOD 工作负载的属性，以了解其 ANNS 效率。与单模态工作负载不同，我们揭示了 OOD 查询在空间上偏离基础数据，并且 OOD 查询的 k 个最近邻在嵌入空间中彼此相距甚远。该属性打破了现有 ANNS 方法的假设，并且不匹配它们为高效搜索而设计的假设。通过对 OOD 工作负载的见解，我们提出了 pRojected 二分图 (RoarGraph)，这是一种在查询分布指导下构建的高效 ANNS 图形索引。大量的实验表明，RoarGraph 在现代跨模态数据集上明显优于最先进的方法，在 OOD 查询的 90% 召回率下实现了高达 3.56 倍的更快搜索速度。

##### **Handling abort commands for household kitchen robots**
2408.14480v1 by Darius Has, Adrian Groza, Mihai Pomarlan

We propose a solution for handling abort commands given to robots. The
solution is exemplified with a running scenario with household kitchen robots.
The robot uses planning to find sequences of actions that must be performed in
order to gracefully cancel a previously received command. The Planning Domain
Definition Language (PDDL) is used to write a domain to model kitchen
activities and behaviours, and this domain is enriched with knowledge from
online ontologies and knowledge graphs, like DBPedia. We discuss the results
obtained in different scenarios.

摘要：我們提出了一個處理發送給機器人的中止命令的解決方案。
這個解決方案以家用廚房機器人的執行情境為例。
機器人使用規劃來尋找必須執行的動作序列，以便優雅地取消先前接收的命令。規劃領域定義語言 (PDDL) 用於撰寫一個網域來建模廚房活動和行為，而這個網域則透過線上本体和知識圖表（例如 DBPedia）的知識來豐富。我們討論在不同情境中獲得的結果。

##### **CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**
2408.08535v1 by Rong-Ching Chang, Jiawei Zhang

Despite advancements in Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG) systems, their effectiveness is often hindered by a lack of
integration with entity relationships and community structures, limiting their
ability to provide contextually rich and accurate information retrieval for
fact-checking. We introduce CommunityKG-RAG (Community Knowledge
Graph-Retrieval Augmented Generation), a novel zero-shot framework that
integrates community structures within Knowledge Graphs (KGs) with RAG systems
to enhance the fact-checking process. Capable of adapting to new domains and
queries without additional training, CommunityKG-RAG utilizes the multi-hop
nature of community structures within KGs to significantly improve the accuracy
and relevance of information retrieval. Our experimental results demonstrate
that CommunityKG-RAG outperforms traditional methods, representing a
significant advancement in fact-checking by offering a robust, scalable, and
efficient solution.

摘要：儘管大型語言模型 (LLM) 和檢索增強生成 (RAG) 系統有進步，但它們的有效性經常受到缺乏與實體關係和社群結構整合的阻礙，限制了它們提供脈絡豐富且準確的資訊檢索以進行事實查核的能力。我們介紹 CommunityKG-RAG（社群知識圖譜檢索增強生成），這是一個新穎的零次學習架構，它將知識圖譜 (KG) 內的社群結構與 RAG 系統整合，以增強事實查核流程。CommunityKG-RAG 無需額外訓練就能適應新的領域和查詢，它利用 KG 內社群結構的多跳特性，大幅提升資訊檢索的準確性和相關性。我們的實驗結果證明 CommunityKG-RAG 優於傳統方法，代表著事實查核的重大進步，提供了一個強健、可擴充且有效率的解決方案。

##### **VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool**
2408.08927v1 by Chia-Tung Ho, Haoxing Ren, Brucek Khailany

Due to the growing complexity of modern Integrated Circuits (ICs), automating
hardware design can prevent a significant amount of human error from the
engineering process and result in less errors. Verilog is a popular hardware
description language for designing and modeling digital systems; thus, Verilog
generation is one of the emerging areas of research to facilitate the design
process. In this work, we propose VerilogCoder, a system of multiple Artificial
Intelligence (AI) agents for Verilog code generation, to autonomously write
Verilog code and fix syntax and functional errors using collaborative Verilog
tools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we
propose a task planner that utilizes a novel Task and Circuit Relation Graph
retrieval method to construct a holistic plan based on module descriptions. To
debug and fix functional errors, we develop a novel and efficient abstract
syntax tree (AST)-based waveform tracing tool, which is integrated within the
autonomous Verilog completion flow. The proposed methodology successfully
generates 94.2% syntactically and functionally correct Verilog code, surpassing
the state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.

摘要：由於現代整合電路 (IC) 的複雜性日益增加，自動化硬體設計可以防止工程過程中出現大量的人為錯誤，並減少錯誤。Verilog 是一種流行的硬體描述語言，用於設計和建模數位系統；因此，Verilog 產生是新興的研究領域之一，旨在促進設計過程。在這項工作中，我們提出 VerilogCoder，一個由多個人工智慧 (AI) 代理組成的系統，用於 Verilog 程式碼產生，以自主撰寫 Verilog 程式碼並使用協作式 Verilog 工具（例如，語法檢查器、模擬器和波形追蹤器）修復語法和功能錯誤。首先，我們提出一個任務規劃器，它利用新穎的任務和電路關係圖擷取方法，根據模組描述建構一個整體計畫。為了除錯和修復功能錯誤，我們開發了一個新穎且高效的基於抽象語法樹 (AST) 的波形追蹤工具，它整合在自主 Verilog 完成流程中。所提出的方法成功產生了 94.2% 語法和功能正確的 Verilog 程式碼，在 VerilogEval-Human v2 基準上比最先進的方法高出 33.9%。

##### **Graph Retrieval-Augmented Generation: A Survey**
2408.08921v2 by Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, Siliang Tang

Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable
success in addressing the challenges of Large Language Models (LLMs) without
necessitating retraining. By referencing an external knowledge base, RAG
refines LLM outputs, effectively mitigating issues such as ``hallucination'',
lack of domain-specific knowledge, and outdated information. However, the
complex structure of relationships among different entities in databases
presents challenges for RAG systems. In response, GraphRAG leverages structural
information across entities to enable more precise and comprehensive retrieval,
capturing relational knowledge and facilitating more accurate, context-aware
responses. Given the novelty and potential of GraphRAG, a systematic review of
current technologies is imperative. This paper provides the first comprehensive
overview of GraphRAG methodologies. We formalize the GraphRAG workflow,
encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced
Generation. We then outline the core technologies and training methods at each
stage. Additionally, we examine downstream tasks, application domains,
evaluation methodologies, and industrial use cases of GraphRAG. Finally, we
explore future research directions to inspire further inquiries and advance
progress in the field. In order to track recent progress in this field, we set
up a repository at \url{https://github.com/pengboci/GraphRAG-Survey}.

摘要：最近，检索增强生成 (RAG) 在解决大型语言模型 (LLM) 的挑战方面取得了显着成功，而无需重新训练。通过参考外部知识库，RAG 改进了 LLM 的输出，有效地减轻了诸如「幻觉」、缺乏特定领域知识和信息过时等问题。然而，数据库中不同实体之间关系的复杂结构给 RAG 系统带来了挑战。作为回应，GraphRAG 利用实体之间的结构信息来实现更精确和全面的检索，捕获关系知识并促进更准确、更具上下文感知的响应。鉴于 GraphRAG 的新颖性和潜力，对当前技术进行系统审查势在必行。本文提供了 GraphRAG 方法的第一个全面概述。我们形式化了 GraphRAG 工作流，包括基于图的索引、图引导的检索和图增强的生成。然后，我们在每个阶段概述了核心技术和训练方法。此外，我们还研究了 GraphRAG 的下游任务、应用领域、评估方法和工业用例。最后，我们探讨了未来的研究方向，以激发进一步的探究并推进该领域的进展。为了追踪该领域的最新进展，我们在 \url{https://github.com/pengboci/GraphRAG-Survey} 上建立了一个存储库。

##### **Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability**
2408.07852v1 by Jiri Hron, Laura Culp, Gamaleldin Elsayed, Rosanne Liu, Ben Adlam, Maxwell Bileschi, Bernd Bohnet, JD Co-Reyes, Noah Fiedel, C. Daniel Freeman, Izzeddin Gur, Kathleen Kenealy, Jaehoon Lee, Peter J. Liu, Gaurav Mishra, Igor Mordatch, Azade Nova, Roman Novak, Aaron Parisi, Jeffrey Pennington, Alex Rizkowsky, Isabelle Simpson, Hanie Sedghi, Jascha Sohl-dickstein, Kevin Swersky, Sharad Vikram, Tris Warkentin, Lechao Xiao, Kelvin Xu, Jasper Snoek, Simon Kornblith

While many capabilities of language models (LMs) improve with increased
training budget, the influence of scale on hallucinations is not yet fully
understood. Hallucinations come in many forms, and there is no universally
accepted definition. We thus focus on studying only those hallucinations where
a correct answer appears verbatim in the training set. To fully control the
training data content, we construct a knowledge graph (KG)-based dataset, and
use it to train a set of increasingly large LMs. We find that for a fixed
dataset, larger and longer-trained LMs hallucinate less. However, hallucinating
on $\leq5$% of the training data requires an order of magnitude larger model,
and thus an order of magnitude more compute, than Hoffmann et al. (2022)
reported was optimal. Given this costliness, we study how hallucination
detectors depend on scale. While we see detector size improves performance on
fixed LM's outputs, we find an inverse relationship between the scale of the LM
and the detectability of its hallucinations.

摘要：雖然語言模型 (LM) 的許多能力會隨著訓練預算的增加而有所提升，但規模對幻覺的影響尚未完全了解。幻覺有許多形式，且沒有普遍接受的定義。因此，我們只專注於研究訓練集中出現正確答案的幻覺。為了完全控制訓練資料內容，我們建構了一個基於知識圖譜 (KG) 的資料集，並使用它來訓練一組越來越大的 LM。我們發現對於固定的資料集，規模較大且訓練時間較長的 LM 產生的幻覺較少。然而，在 $\leq5$% 的訓練資料上產生幻覺需要規模大一個數量級的模型，因此比 Hoffmann 等人 (2022) 所報告的最佳規模多一個數量級的運算成本。考量到這種成本，我們研究幻覺偵測器如何取決於規模。雖然我們看到偵測器規模會提升對固定 LM 輸出的效能，但我們發現 LM 的規模與其幻覺的可偵測性之間存在反比關係。

##### **ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model**
2408.07840v1 by Xuanqing Yu, Wangtao Sun, Jingwei Li, Kang Liu, Chengbao Liu, Jie Tan

In the realm of event prediction, temporal knowledge graph forecasting (TKGF)
stands as a pivotal technique. Previous approaches face the challenges of not
utilizing experience during testing and relying on a single short-term history,
which limits adaptation to evolving data. In this paper, we introduce the
Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by
integrating dynamic causal rule mining (DCRM) and dual history augmented
generation (DHAG). DCRM dynamically constructs causal rules from real-time
data, allowing for swift adaptation to new causal relationships. In parallel,
DHAG merges short-term and long-term historical contexts, leveraging a
bi-branch approach to enrich event prediction. Our framework demonstrates
notable performance enhancements across diverse datasets, with significant
Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language
models (LLMs) for event prediction without necessitating extensive retraining.
The ONSEP framework not only advances the field of TKGF but also underscores
the potential of neural-symbolic approaches in adapting to dynamic data
environments.

摘要：在事件預測領域中，時序知識圖譜預測 (TKGF) 是一個關鍵技術。先前的做法面臨在測試期間不利用經驗以及依賴單一短期歷史的挑戰，這限制了對演化資料的適應性。在本文中，我們介紹了線上神經符號事件預測 (ONSEP) 架構，它透過整合動態因果規則挖掘 (DCRM) 和雙重歷史擴充生成 (DHAG) 來創新。DCRM 從即時資料中動態建構因果規則，允許快速適應新的因果關係。同時，DHAG 合併短期和長期歷史脈絡，利用雙分支方法來豐富事件預測。我們的架構在各種資料集上展示出顯著的效能提升，Hit@k (k=1,3,10) 有顯著的改善，展示了它在無需廣泛重新訓練的情況下擴充大型語言模型 (LLM) 以進行事件預測的能力。ONSEP 架構不僅推動了 TKGF 領域，也強調了神經符號方法在適應動態資料環境中的潛力。

##### **WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**
2408.07611v2 by Weijian Xie, Xuefeng Liang, Yuhui Liu, Kaihua Ni, Hong Cheng, Zetian Hu

Large Language Models (LLMs) have greatly contributed to the development of
adaptive intelligent agents and are positioned as an important way to achieve
Artificial General Intelligence (AGI). However, LLMs are prone to produce
factually incorrect information and often produce "phantom" content that
undermines their reliability, which poses a serious challenge for their
deployment in real-world scenarios. Enhancing LLMs by combining external
databases and information retrieval mechanisms is an effective path. To address
the above challenges, we propose a new approach called WeKnow-RAG, which
integrates Web search and Knowledge Graphs into a "Retrieval-Augmented
Generation (RAG)" system. First, the accuracy and reliability of LLM responses
are improved by combining the structured representation of Knowledge Graphs
with the flexibility of dense vector retrieval. WeKnow-RAG then utilizes
domain-specific knowledge graphs to satisfy a variety of queries and domains,
thereby improving performance on factual information and complex reasoning
tasks by employing multi-stage web page retrieval techniques using both sparse
and dense retrieval methods. Our approach effectively balances the efficiency
and accuracy of information retrieval, thus improving the overall retrieval
process. Finally, we also integrate a self-assessment mechanism for the LLM to
evaluate the trustworthiness of the answers it generates. Our approach proves
its outstanding effectiveness in a wide range of offline experiments and online
submissions.

摘要：大型語言模型 (LLM) 極大地促进了自適應智能代理的開發，並被定位為實現人工通用智慧 (AGI) 的重要途徑。然而，LLM 容易產生事實上不正確的資訊，而且常常產生「幻影」內容，這會破壞其可靠性，對其在現實世界場景中的部署構成嚴峻挑戰。結合外部資料庫和資訊檢索機制來增強 LLM 是一種有效的方法。為了應對上述挑戰，我們提出了一種稱為 WeKnow-RAG 的新方法，它將網路搜尋和知識圖譜整合到「檢索增強生成 (RAG)」系統中。首先，透過結合知識圖譜的結構化表示和稠密向量檢索的靈活性，來提升 LLM 回應的準確性和可靠性。WeKnow-RAG 接著利用特定領域的知識圖譜來滿足各種查詢和領域，從而透過使用稀疏和稠密檢索方法的多階段網頁檢索技術，來提升事實資訊和複雜推理任務的效能。我們的做法有效地平衡了資訊檢索的效率和準確性，進而改善整體檢索流程。最後，我們還整合了一個 LLM 自我評估機制，以評估其所產生答案的可信度。我們的做法在廣泛的離線實驗和線上提交中證明了其傑出的有效性。

##### **Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals**
2408.07453v1 by Tobias A. Opsahl

Despite recent success in natural language processing (NLP), fact
verification still remains a difficult task. Due to misinformation spreading
increasingly fast, attention has been directed towards automatically verifying
the correctness of claims. In the domain of NLP, this is usually done by
training supervised machine learning models to verify claims by utilizing
evidence from trustworthy corpora. We present efficient methods for verifying
claims on a dataset where the evidence is in the form of structured knowledge
graphs. We use the FactKG dataset, which is constructed from the DBpedia
knowledge graph extracted from Wikipedia. By simplifying the evidence retrieval
process, from fine-tuned language models to simple logical retrievals, we are
able to construct models that both require less computational resources and
achieve better test-set accuracy.

摘要：儘管在自然語言處理 (NLP) 中獲得近期成功，事實驗證仍然是一項艱難的任務。由於錯誤資訊傳播得越來越快，注意力已轉向自動驗證聲明的正確性。在 NLP 領域中，這通常透過訓練監督式機器學習模型來完成，這些模型利用來自可信賴語料庫的證據來驗證聲明。我們提出有效的方法來驗證資料集中的聲明，其中證據是以結構化知識圖表的形式呈現。我們使用 FactKG 資料集，它是由從維基百科中萃取的 DBpedia 知識圖表所建構。透過簡化證據擷取流程，從微調語言模型到簡單的邏輯擷取，我們能夠建構既需要較少計算資源，又能達到較佳測試集準確度的模型。

##### **LLMs can Schedule**
2408.06993v1 by Henrik Abgaryan, Ararat Harutyunyan, Tristan Cazenave

The job shop scheduling problem (JSSP) remains a significant hurdle in
optimizing production processes. This challenge involves efficiently allocating
jobs to a limited number of machines while minimizing factors like total
processing time or job delays. While recent advancements in artificial
intelligence have yielded promising solutions, such as reinforcement learning
and graph neural networks, this paper explores the potential of Large Language
Models (LLMs) for JSSP. We introduce the very first supervised 120k dataset
specifically designed to train LLMs for JSSP. Surprisingly, our findings
demonstrate that LLM-based scheduling can achieve performance comparable to
other neural approaches. Furthermore, we propose a sampling method that
enhances the effectiveness of LLMs in tackling JSSP.

摘要：作業車間排程問題 (JSSP) 仍然是最佳化生產流程中的一大障礙。這項挑戰涉及將作業有效分配到數量有限的機器，同時將總處理時間或作業延遲等因素降至最低。儘管人工智慧的最新進展已產生有希望的解決方案，例如強化學習和圖形神經網路，但本文探討了大型語言模型 (LLM) 在 JSSP 中的潛力。我們引入了第一個監督式 120k 資料集，專門用於訓練 JSSP 的 LLM。令人驚訝的是，我們的研究結果表明，基於 LLM 的排程可以達到與其他神經方法相當的效能。此外，我們提出了一種抽樣方法，可增強 LLM 在處理 JSSP 中的有效性。

##### **Causal Agent based on Large Language Model**
2408.06849v1 by Kairong Han, Kun Kuang, Ziyu Zhao, Junjian Ye, Fei Wu

Large language models (LLMs) have achieved significant success across various
domains. However, the inherent complexity of causal problems and causal theory
poses challenges in accurately describing them in natural language, making it
difficult for LLMs to comprehend and use them effectively. Causal methods are
not easily conveyed through natural language, which hinders LLMs' ability to
apply them accurately. Additionally, causal datasets are typically tabular,
while LLMs excel in handling natural language data, creating a structural
mismatch that impedes effective reasoning with tabular data. This lack of
causal reasoning capability limits the development of LLMs. To address these
challenges, we have equipped the LLM with causal tools within an agent
framework, named the Causal Agent, enabling it to tackle causal problems. The
causal agent comprises tools, memory, and reasoning modules. In the tools
module, the causal agent applies causal methods to align tabular data with
natural language. In the reasoning module, the causal agent employs the ReAct
framework to perform reasoning through multiple iterations with the tools. In
the memory module, the causal agent maintains a dictionary instance where the
keys are unique names and the values are causal graphs. To verify the causal
ability of the causal agent, we established a benchmark consisting of four
levels of causal problems: variable level, edge level, causal graph level, and
causal effect level. We generated a test dataset of 1.3K using ChatGPT-3.5 for
these four levels of issues and tested the causal agent on the datasets. Our
methodology demonstrates remarkable efficacy on the four-level causal problems,
with accuracy rates all above 80%. For further insights and implementation
details, our code is accessible via the GitHub repository
https://github.com/Kairong-Han/Causal_Agent.

摘要：大型語言模型 (LLM) 已在各個領域取得重大成功。然而，因果問題和因果理論的內在複雜性，在自然語言中準確描述它們時構成挑戰，這使得 LLM 難以理解並有效使用它們。因果方法不易透過自然語言傳達，這阻礙了 LLM 準確應用它們的能力。此外，因果資料集通常是表格化的，而 LLM 擅長處理自然語言資料，這造成了結構上的不匹配，阻礙了對表格資料進行有效的推理。這種缺乏因果推理能力限制了 LLM 的發展。為了應對這些挑戰，我們在一個代理框架中為 LLM 配備了因果工具，稱為因果代理，使它能夠解決因果問題。因果代理包含工具、記憶體和推理模組。在工具模組中，因果代理應用因果方法將表格資料與自然語言對齊。在推理模組中，因果代理採用 ReAct 框架，透過與工具進行多次反覆運算來執行推理。在記憶體模組中，因果代理維護一個字典實例，其中鍵是唯一名稱，而值是因果圖。為了驗證因果代理的因果能力，我們建立了一個基準，其中包含四個層級的因果問題：變數層級、邊層級、因果圖層級和因果效應層級。我們使用 ChatGPT-3.5 為這四個層級的問題產生了 1.3K 的測試資料集，並在資料集上測試了因果代理。我們的這套方法在四個層級的因果問題上展現了顯著的功效，準確率都高於 80%。有關進一步的見解和實作細節，我們的程式碼可透過 GitHub 儲存庫 https://github.com/Kairong-Han/Causal_Agent 取得。

##### **Unlock the Power of Frozen LLMs in Knowledge Graph Completion**
2408.06787v1 by Bo Xue, Yi Xu, Yunchong Song, Yiming Pang, Yuyang Ren, Jiaxin Ding, Luoyi Fu, Xinbing Wang

Classical knowledge graph completion (KGC) methods rely solely on structural
information, struggling with the inherent sparsity of knowledge graphs (KGs).
Large Language Models (LLMs) learn extensive knowledge from large corpora with
powerful context modeling, which is ideal for mitigating the limitations of
previous methods. Directly fine-tuning LLMs offers great capability but comes
at the cost of huge time and memory consumption, while utilizing frozen LLMs
yields suboptimal results. In this work, we aim to leverage LLMs for KGC
effectively and efficiently. We capture the context-aware hidden states of
knowledge triples by employing prompts to stimulate the intermediate layers of
LLMs. We then train a data-efficient classifier on these hidden states to
harness the inherent capabilities of frozen LLMs in KGC. We also generate
entity descriptions with subgraph sampling on KGs, reducing the ambiguity of
triplets and enriching the knowledge representation. Extensive experiments on
standard benchmarks showcase the efficiency and effectiveness of our approach.
We outperform classical KGC methods on most datasets and match the performance
of fine-tuned LLMs. Additionally, compared to fine-tuned LLMs, we boost GPU
memory efficiency by \textbf{$188\times$} and speed up training+inference by
\textbf{$13.48\times$}.

摘要：傳統知識圖譜完成 (KGC) 方法僅依賴結構化資訊，難以應對知識圖譜 (KG) 內在的稀疏性。大型語言模型 (LLM) 從大型語料庫中學習廣泛的知識，並具備強大的情境建模能力，這對於緩解先前方法的限制非常理想。直接微調 LLM 可提供強大的能力，但代價是耗費大量時間和記憶體，而利用凍結的 LLM 則會產生次佳結果。在這項工作中，我們旨在有效且高效地利用 LLM 來進行 KGC。我們透過使用提示來刺激 LLM 的中間層，捕捉到知識三元組的情境感知隱藏狀態。然後，我們在這些隱藏狀態上訓練一個資料有效率的分類器，以利用凍結 LLM 在 KGC 中的內在能力。我們還透過在 KG 上進行子圖抽樣來產生實體描述，減少三元組的模糊性並豐富知識表示。標準基準上的廣泛實驗展示了我們方法的效率和有效性。我們在多數資料集上優於傳統的 KGC 方法，並與微調後的 LLM 達到相同的效能。此外，與微調後的 LLM 相比，我們將 GPU 記憶體效率提升了 **$188\times$**，並將訓練 + 推論速度提升了 **$13.48\times$**。

##### **Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models**
2408.06717v1 by Jialiang Wang, Shimin Di, Hanmo Liu, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou

Graph Neural Networks (GNNs), like other neural networks, have shown
remarkable success but are hampered by the complexity of their architecture
designs, which heavily depend on specific data and tasks. Traditionally,
designing proper architectures involves trial and error, which requires
intensive manual effort to optimize various components. To reduce human
workload, researchers try to develop automated algorithms to design GNNs.
However, both experts and automated algorithms suffer from two major issues in
designing GNNs: 1) the substantial computational resources expended in
repeatedly trying candidate GNN architectures until a feasible design is
achieved, and 2) the intricate and prolonged processes required for humans or
algorithms to accumulate knowledge of the interrelationship between graphs,
GNNs, and performance.
  To further enhance the automation of GNN architecture design, we propose a
computation-friendly way to empower Large Language Models (LLMs) with
specialized knowledge in designing GNNs, thereby drastically shortening the
computational overhead and development cycle of designing GNN architectures.
Our framework begins by establishing a knowledge retrieval pipeline that
comprehends the intercorrelations between graphs, GNNs, and performance. This
pipeline converts past model design experiences into structured knowledge for
LLM reference, allowing it to quickly suggest initial model proposals.
Subsequently, we introduce a knowledge-driven search strategy that emulates the
exploration-exploitation process of human experts, enabling quick refinement of
initial proposals within a promising scope. Extensive experiments demonstrate
that our framework can efficiently deliver promising (e.g., Top-5.77%) initial
model proposals for unseen datasets within seconds and without any prior
training and achieve outstanding search performance in a few iterations.

摘要：圖形神經網路 (GNN) 與其他神經網路一樣，已展現出顯著的成功，但其架構設計的複雜性卻阻礙了進一步的發展，而這種複雜性在很大程度上取決於具體的資料和任務。傳統上，設計適當的架構需要反覆嘗試，這需要大量的人工工作才能最佳化各種元件。為了減少人力的負擔，研究人員嘗試開發自動化演算法來設計 GNN。然而，專家和自動化演算法在設計 GNN 時都會遇到兩個主要問題：1) 在反覆嘗試候選 GNN 架構以達成可行的設計之前，會耗費大量的運算資源，以及 2) 人類或演算法需要花費大量複雜而漫長的程序才能累積有關圖形、GNN 和效能之間相互關係的知識。
為了進一步提升 GNN 架構設計的自動化，我們提出了一種運算友善的方式，讓大型語言模型 (LLM) 具備設計 GNN 的專業知識，從而大幅縮短設計 GNN 架構的運算負擔和開發週期。我們的架構首先建立一個知識擷取管道，了解圖形、GNN 和效能之間的相互關聯性。這個管道將過去的模型設計經驗轉換成結構化的知識，供 LLM 參考，讓 LLM 能夠快速提出初步的模型建議。隨後，我們引入一種知識驅動的搜尋策略，模擬人類專家的探索與開發程序，讓 LLM 能在有希望的範圍內快速改善初步建議。廣泛的實驗證明，我們的架構可以在幾秒鐘內有效地針對未見過的資料集提供有希望的 (例如，前 5.77%) 初步模型建議，而且無需任何先前的訓練，並在幾次反覆運算中就能達成傑出的搜尋效能。

##### **Body Transformer: Leveraging Robot Embodiment for Policy Learning**
2408.06316v1 by Carmelo Sferrazza, Dun-Ming Huang, Fangchen Liu, Jongmin Lee, Pieter Abbeel

In recent years, the transformer architecture has become the de facto
standard for machine learning algorithms applied to natural language processing
and computer vision. Despite notable evidence of successful deployment of this
architecture in the context of robot learning, we claim that vanilla
transformers do not fully exploit the structure of the robot learning problem.
Therefore, we propose Body Transformer (BoT), an architecture that leverages
the robot embodiment by providing an inductive bias that guides the learning
process. We represent the robot body as a graph of sensors and actuators, and
rely on masked attention to pool information throughout the architecture. The
resulting architecture outperforms the vanilla transformer, as well as the
classical multilayer perceptron, in terms of task completion, scaling
properties, and computational efficiency when representing either imitation or
reinforcement learning policies. Additional material including the open-source
code is available at https://sferrazza.cc/bot_site.

摘要：近年来，变压器架构已成为应用于自然语言处理和计算机视觉的机器学习算法的实际标准。尽管有显着证据表明在机器人学习的背景下成功部署了此架构，但我们声称原始变压器并未充分利用机器人学习问题的结构。因此，我们提出了 Body Transformer (BoT)，一种通过提供指导学习过程的归纳偏差来利用机器人体现的架构。我们将机器人主体表示为传感器和执行器的图形，并依靠掩码注意力来汇集整个架构中的信息。在完成任务、缩放属性和计算效率方面，无论是表示模仿还是强化学习策略，由此产生的架构都优于原始变压器以及经典的多层感知器。包括开源代码在内的其他材料可从 https://sferrazza.cc/bot_site 获得。

##### **ARPA: A Novel Hybrid Model for Advancing Visual Word Disambiguation Using Large Language Models and Transformers**
2408.06040v1 by Aristi Papastavrou, Maria Lymperaiou, Giorgos Stamou

In the rapidly evolving fields of natural language processing and computer
vision, Visual Word Sense Disambiguation (VWSD) stands as a critical, yet
challenging task. The quest for models that can seamlessly integrate and
interpret multimodal data is more pressing than ever. Imagine a system that can
understand language with the depth and nuance of human cognition, while
simultaneously interpreting the rich visual context of the world around it.
  We present ARPA, an architecture that fuses the unparalleled contextual
understanding of large language models with the advanced feature extraction
capabilities of transformers, which then pass through a custom Graph Neural
Network (GNN) layer to learn intricate relationships and subtle nuances within
the data. This innovative architecture not only sets a new benchmark in visual
word disambiguation but also introduces a versatile framework poised to
transform how linguistic and visual data interact by harnessing the synergistic
strengths of its components, ensuring robust performance even in the most
complex disambiguation scenarios. Through a series of experiments and
comparative analysis, we reveal the substantial advantages of our model,
underscoring its potential to redefine standards in the field. Beyond its
architectural prowess, our architecture excels through experimental
enrichments, including sophisticated data augmentation and multi-modal training
techniques.
  ARPA's introduction marks a significant milestone in visual word
disambiguation, offering a compelling solution that bridges the gap between
linguistic and visual modalities. We invite researchers and practitioners to
explore the capabilities of our model, envisioning a future where such hybrid
models drive unprecedented advancements in artificial intelligence.

摘要：在自然語言處理和電腦視覺快速演進的領域中，視覺詞彙消歧 (VWSD) 是一個關鍵且具有挑戰性的任務。尋找能夠無縫整合和詮釋多模態資料的模型比以往任何時候都更加迫切。想像一個系統，它可以像人類認知一樣深入且細緻地理解語言，同時還能詮釋周圍世界的豐富視覺脈絡。
我們提出 ARPA，一種架構，它融合了大型語言模型無與倫比的脈絡理解能力和 Transformer 的進階特徵萃取能力，然後通過一個自訂圖形神經網路 (GNN) 層來學習資料中的複雜關係和細微差異。這種創新的架構不僅在視覺詞彙消歧中設定了新的基準，還引入了一個多功能的框架，準備通過利用其組成部分的協同優勢來轉變語言和視覺資料的互動方式，確保即使在最複雜的消歧場景中也能有強健的效能。透過一系列的實驗和比較分析，我們揭示了我們模型的顯著優勢，強調了它在重新定義該領域標準的潛力。除了其架構優勢之外，我們的架構還通過實驗豐富化而表現出色，包括精密的資料擴充和多模態訓練技術。
ARPA 的推出標誌著視覺詞彙消歧的一個重要里程碑，提供了一個引人注目的解決方案，彌合了語言和視覺模態之間的差距。我們邀請研究人員和從業人員探索我們模型的能力，展望一個由這種混合模型推動人工智慧前所未有的進步的未來。

##### **ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models**
2408.05948v1 by Ronak Pradeep, Daniel Lee, Ali Mousavi, Jeff Pound, Yisi Sang, Jimmy Lin, Ihab Ilyas, Saloni Potdar, Mostafa Arefiyan, Yunyao Li

The rapid advancement of Large Language Models (LLMs) and conversational
assistants necessitates dynamic, scalable, and configurable conversational
datasets for training and evaluation. These datasets must accommodate diverse
user interaction modes, including text and voice, each presenting unique
modeling challenges. Knowledge Graphs (KGs), with their structured and evolving
nature, offer an ideal foundation for current and precise knowledge. Although
human-curated KG-based conversational datasets exist, they struggle to keep
pace with the rapidly changing user information needs. We present ConvKGYarn, a
scalable method for generating up-to-date and configurable conversational KGQA
datasets. Qualitative psychometric analyses confirm our method can generate
high-quality datasets rivaling a popular conversational KGQA dataset while
offering it at scale and covering a wide range of human-interaction
configurations. We showcase its utility by testing LLMs on diverse
conversations - exploring model behavior on conversational KGQA sets with
different configurations grounded in the same KG fact set. Our results
highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate
parametric knowledge of LLMs, thus offering a robust solution to the constantly
evolving landscape of conversational assistants.

摘要：隨著大型語言模型 (LLM) 和對話式助理的快速進步，需要動態、可擴充且可設定的對話式資料集來進行訓練和評估。這些資料集必須容納不同的使用者互動模式，包括文字和語音，每種模式都呈現獨特的建模挑戰。知識圖譜 (KG) 具有結構化且不斷演進的特性，為當前和精確的知識提供了理想的基礎。儘管存在人工策展的基於知識圖譜的對話式資料集，但它們難以跟上快速變化的使用者資訊需求。我們提出 ConvKGYarn，這是一種可擴充的方法，用於產生最新的且可設定的對話式 KGQA 資料集。定性的心理測量分析證實，我們的模型可以產生與流行的對話式 KGQA 資料集相媲美的優質資料集，同時大規模提供資料集，並涵蓋廣泛的人機互動設定。我們透過在不同的對話中測試 LLM 來展示其效用，探索模型在對話式 KGQA 設定上的行為，這些設定基於相同的知識圖譜事實集。我們的結果突顯了 ConvKGYarn 改善 KGQA 基礎和評估 LLM 參數化知識的能力，從而為不斷演進的對話式助理領域提供了一個強大的解決方案。

##### **The Cognitive Revolution in Interpretability: From Explaining Behavior to Interpreting Representations and Algorithms**
2408.05859v1 by Adam Davies, Ashkan Khakzar

Artificial neural networks have long been understood as "black boxes": though
we know their computation graphs and learned parameters, the knowledge encoded
by these weights and functions they perform are not inherently interpretable.
As such, from the early days of deep learning, there have been efforts to
explain these models' behavior and understand them internally; and recently,
mechanistic interpretability (MI) has emerged as a distinct research area
studying the features and implicit algorithms learned by foundation models such
as large language models. In this work, we aim to ground MI in the context of
cognitive science, which has long struggled with analogous questions in
studying and explaining the behavior of "black box" intelligent systems like
the human brain. We leverage several important ideas and developments in the
history of cognitive science to disentangle divergent objectives in MI and
indicate a clear path forward. First, we argue that current methods are ripe to
facilitate a transition in deep learning interpretation echoing the "cognitive
revolution" in 20th-century psychology that shifted the study of human
psychology from pure behaviorism toward mental representations and processing.
Second, we propose a taxonomy mirroring key parallels in computational
neuroscience to describe two broad categories of MI research, semantic
interpretation (what latent representations are learned and used) and
algorithmic interpretation (what operations are performed over representations)
to elucidate their divergent goals and objects of study. Finally, we elaborate
the parallels and distinctions between various approaches in both categories,
analyze the respective strengths and weaknesses of representative works,
clarify underlying assumptions, outline key challenges, and discuss the
possibility of unifying these modes of interpretation under a common framework.

摘要：人工神經網路長期以來都被視為「黑盒子」：儘管我們知道它們的運算圖表和學習參數，但這些權重和它們執行的函數所編碼的知識並非天生就可解釋。因此，從深度學習的早期開始，就有許多人致力於解釋這些模型的行為並在內部理解它們；最近，機制可解釋性 (MI) 已成為一個獨特的的研究領域，探討基礎模型（例如大型語言模型）學習到的特徵和隱式演算法。在這項工作中，我們旨在將 MI 基於認知科學的背景，認知科學長期以來一直在研究和解釋「黑盒子」智能系統（例如人腦）的行為時，努力解決類似的問題。我們利用認知科學史上幾個重要的想法和發展，來解開 MI 中不同的目標，並指出明確的前進道路。首先，我們認為當前的各種方法已準備好促進深度學習解釋的轉變，這呼應了 20 世紀心理學中的「認知革命」，將人類心理學的研究從純粹的行為主義轉向心智表徵和處理。其次，我們提出一個分類法，反映計算神經科學中的關鍵相似之處，以描述 MI 研究的兩個廣泛類別，語義解釋（學習和使用的潛在表徵是什麼）和演算法解釋（在表徵上執行的運算是什麼），以闡明它們不同的目標和研究對象。最後，我們闡述了這兩個類別中各種方法之間的相似之處和區別，分析代表性作品的優缺點，釐清基本假設，概述關鍵挑戰，並討論在一個共同架構下統一這些解釋模式的可能性。

##### **Investigating Instruction Tuning Large Language Models on Graphs**
2408.05457v1 by Kerui Zhu, Bo-Wei Huang, Bowen Jin, Yizhu Jiao, Ming Zhong, Kevin Chang, Shou-De Lin, Jiawei Han

Inspired by the recent advancements of Large Language Models (LLMs) in NLP
tasks, there's growing interest in applying LLMs to graph-related tasks. This
study delves into the capabilities of instruction-following LLMs for engaging
with real-world graphs, aiming to offer empirical insights into how LLMs can
effectively interact with graphs and generalize across graph tasks. We begin by
constructing a dataset designed for instruction tuning, which comprises a
diverse collection of 79 graph-related tasks from academic and e-commerce
domains, featuring 44,240 training instances and 18,960 test samples. Utilizing
this benchmark, our initial investigation focuses on identifying the optimal
graph representation that serves as a conduit for LLMs to understand complex
graph structures. Our findings indicate that JSON format for graph
representation consistently outperforms natural language and code formats
across various LLMs and graph types. Furthermore, we examine the key factors
that influence the generalization abilities of instruction-tuned LLMs by
evaluating their performance on both in-domain and out-of-domain graph tasks.

摘要：受到自然語言處理 (NLP) 中大型語言模型 (LLM) 近期進展的啟發，將 LLM 應用於與圖表相關任務的興趣日益濃厚。本研究探討了遵循指令的 LLM 的功能，以從事真實世界的圖表，旨在提供 LLM 如何有效地與圖表互動並在圖表任務中進行概括的經驗見解。我們從構建一個專為指令調整而設計的資料集開始，其中包含來自學術和電子商務領域的 79 個圖表相關任務的多元化集合，包含 44,240 個訓練實例和 18,960 個測試樣本。利用此基準，我們的初步調查重點在於識別最佳圖表表示，作為 LLM 理解複雜圖表結構的管道。我們的研究結果表明，JSON 格式的圖表表示在各種 LLM 和圖表類型中始終優於自然語言和程式碼格式。此外，我們探討了影響指令調整 LLM 概括能力的主要因素，方法是評估它們在領域內和領域外圖表任務上的表現。

##### **Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation**
2408.05456v1 by Wenbo Shang, Xuliang Zhu, Xin Huang

Unified graph representation learning aims to produce node embeddings, which
can be applied to multiple downstream applications. However, existing studies
based on graph neural networks and language models either suffer from the
limitations of numerous training needed toward specific downstream predictions
or have shallow semantic features. In this work, we propose a novel Path-LLM
model to learn unified graph representation, which leverages a powerful large
language model (LLM) to incorporate our proposed path features. Our Path-LLM
framework consists of several well-designed techniques. First, we develop a new
mechanism of long-to-short shortest path (L2SP) selection, which covers
essential connections between different dense groups. An in-depth comparison of
different path selection plans is offered to illustrate the strength of our
designed L2SP. Then, we design path textualization to obtain L2SP-based
training texts. Next, we feed the texts into a self-supervised LLM training
process to learn embeddings. Extensive experiments on benchmarks validate the
superiority of Path-LLM against the state-of-the-art WalkLM method on two
classical graph learning tasks (node classification and link prediction) and
one NP-hard graph query processing task (keyword search), meanwhile saving more
than 90% of training paths.

摘要：統一圖形表徵學習旨在產生節點嵌入，可用於多個下游應用程式。然而，現有的基於圖形神經網路和語言模型的研究，不是因需要針對特定下游預測而進行大量訓練而受到限制，就是語意特徵淺薄。在這項工作中，我們提出了一個新穎的 Path-LLM 模型來學習統一的圖形表徵，它利用強大的大型語言模型 (LLM) 來納入我們提出的路徑特徵。我們的 Path-LLM 框架包含了多項設計良好的技術。首先，我們開發了一種新的長到短最短路徑 (L2SP) 選擇機制，它涵蓋了不同密集群組之間的必要連接。提供了不同路徑選擇方案的深入比較，以說明我們設計的 L2SP 的優勢。然後，我們設計路徑文字化以獲得基於 L2SP 的訓練文本。接下來，我們將文本輸入到自監督 LLM 訓練過程中以學習嵌入。在基準上的大量實驗驗證了 Path-LLM 在兩個經典圖形學習任務（節點分類和連結預測）和一個 NP 難圖形查詢處理任務（關鍵字搜尋）上優於最先進的 WalkLM 方法，同時節省了超過 90% 的訓練路徑。

##### **LaiDA: Linguistics-aware In-context Learning with Data Augmentation for Metaphor Components Identification**
2408.05404v1 by Hongde Liu, Chenyuan He, Feiyang Meng, Changyong Niu, Yuxiang Jia

Metaphor Components Identification (MCI) contributes to enhancing machine
understanding of metaphors, thereby advancing downstream natural language
processing tasks. However, the complexity, diversity, and dependency on context
and background knowledge pose significant challenges for MCI. Large language
models (LLMs) offer new avenues for accurate comprehension of complex natural
language texts due to their strong semantic analysis and extensive commonsense
knowledge. In this research, a new LLM-based framework is proposed, named
Linguistics-aware In-context Learning with Data Augmentation (LaiDA).
Specifically, ChatGPT and supervised fine-tuning are utilized to tailor a
high-quality dataset. LaiDA incorporates a simile dataset for pre-training. A
graph attention network encoder generates linguistically rich feature
representations to retrieve similar examples. Subsequently, LLM is fine-tuned
with prompts that integrate linguistically similar examples. LaiDA ranked 2nd
in Subtask 2 of NLPCC2024 Shared Task 9, demonstrating its effectiveness. Code
and data are available at https://github.com/WXLJZ/LaiDA.

摘要：隱喻組成辨識 (MCI) 有助於提升機器對隱喻的理解，進而推動下游的自然語言處理任務。不過，複雜性、多樣性，以及對脈絡和背景知識的依賴性，對 MCI 而言是重大的挑戰。大型語言模型 (LLM) 由於其強大的語意分析和廣泛的常識知識，為準確理解複雜的自然語言文本提供了新途徑。本研究提出了一個新的基於 LLM 的架構，稱為具備資料擴充功能的語言感知情境學習 (LaiDA)。具體來說，ChatGPT 和監督微調用於調整一個高品質的資料集。LaiDA 結合了一個比喻資料集進行預訓練。一個圖形注意力網路編碼器產生語言豐富的特徵表示，以擷取類似的範例。隨後，LLM 使用整合了語言相似範例的提示進行微調。LaiDA 在 NLPCC2024 共享任務 9 的子任務 2 中排名第 2，證明了其有效性。程式碼和資料可在 https://github.com/WXLJZ/LaiDA 取得。

##### **Text classification optimization algorithm based on graph neural network**
2408.15257v1 by Erdi Gao, Haowei Yang, Dan Sun, Haohao Xia, Yuhan Ma, Yuanjing Zhu

In the field of natural language processing, text classification, as a basic
task, has important research value and application prospects. Traditional text
classification methods usually rely on feature representations such as the bag
of words model or TF-IDF, which overlook the semantic connections between words
and make it challenging to grasp the deep structural details of the text.
Recently, GNNs have proven to be a valuable asset for text classification
tasks, thanks to their capability to handle non-Euclidean data efficiently.
However, the existing text classification methods based on GNN still face
challenges such as complex graph structure construction and high cost of model
training. This paper introduces a text classification optimization algorithm
utilizing graph neural networks. By introducing adaptive graph construction
strategy and efficient graph convolution operation, the accuracy and efficiency
of text classification are effectively improved. The experimental results
demonstrate that the proposed method surpasses traditional approaches and
existing GNN models across multiple public datasets, highlighting its superior
performance and feasibility for text classification tasks.

摘要：在自然語言處理領域，文本分類作為一項基礎任務，具有重要的研究價值和應用前景。傳統的文本分類方法通常依賴於詞袋模型或 TF-IDF 等特徵表示，這忽視了詞彙之間的語義聯繫，使得難以把握文本的深層結構細節。近年來，GNN 已被證明是文本分類任務的寶貴資產，這歸功於它們有效處理非歐幾里得數據的能力。然而，基於 GNN 的現有文本分類方法仍然面臨著圖結構構建複雜、模型訓練成本高等挑戰。本文提出了一種利用圖神經網絡的文本分類優化算法。通過引入自適應圖構建策略和高效的圖卷積運算，有效地提高了文本分類的準確率和效率。實驗結果表明，該方法在多個公開數據集上超越了傳統方法和現有的 GNN 模型，凸顯了其在文本分類任務中的優越性能和可行性。

##### **SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions**
2408.05357v1 by Zhi-Qi Cheng, Yifei Dong, Aike Shi, Wei Liu, Yuzhi Hu, Jason O'Connor, Alexander Hauptmann, Kate Whitefoot

The electric vehicle (EV) battery supply chain's vulnerability to disruptions
necessitates advanced predictive analytics. We present SHIELD (Schema-based
Hierarchical Induction for EV supply chain Disruption), a system integrating
Large Language Models (LLMs) with domain expertise for EV battery supply chain
risk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a
comprehensive knowledge library, (2) a disruption analysis system utilizing
fine-tuned language models for event extraction, multi-dimensional similarity
matching for schema matching, and Graph Convolutional Networks (GCNs) with
logical constraints for prediction, and (3) an interactive interface for
visualizing results and incorporating expert feedback to enhance
decision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023),
SHIELD outperforms baseline GCNs and LLM+prompt methods (e.g., GPT-4o) in
disruption prediction. These results demonstrate SHIELD's effectiveness in
combining LLM capabilities with domain expertise for enhanced supply chain risk
assessment.

摘要：電動車 (EV) 電池供應鏈容易受到干擾，因此需要進階的預測分析。我們提出 SHIELD（基於架構的 EV 供應鏈中斷階層式歸納），這是一個整合大型語言模型 (LLM) 與 EV 電池供應鏈風險評估領域專業知識的系統。SHIELD 結合：(1) LLM 驅動的架構學習，用於建置一個全面的知識庫，(2) 一個中斷分析系統，利用微調語言模型進行事件萃取、多維度相似性比對用於架構比對，以及帶有邏輯約束的圖形卷積網路 (GCN) 用於預測，以及 (3) 一個互動介面，用於視覺化結果和納入專家回饋以增強決策制定。在來自 365 個來源的 12,070 段落（2022-2023 年）上進行評估，SHIELD 在中斷預測方面優於基準 GCN 和 LLM+提示方法（例如，GPT-4o）。這些結果證明了 SHIELD 在結合 LLM 功能與領域專業知識以增強供應鏈風險評估方面的有效性。

##### **A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**
2408.05141v3 by Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang

Retrieval-augmented generation (RAG) is a framework enabling large language
models (LLMs) to enhance their accuracy and reduce hallucinations by
integrating external knowledge bases. In this paper, we introduce a hybrid RAG
system enhanced through a comprehensive suite of optimizations that
significantly improve retrieval quality, augment reasoning capabilities, and
refine numerical computation ability. We refined the text chunks and tables in
web pages, added attribute predictors to reduce hallucinations, conducted LLM
Knowledge Extractor and Knowledge Graph Extractor, and finally built a
reasoning strategy with all the references. We evaluated our system on the CRAG
dataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and
online evaluations demonstrate that our system significantly enhances complex
reasoning capabilities. In local evaluations, we have significantly improved
accuracy and reduced error rates compared to the baseline model, achieving a
notable increase in scores. In the meanwhile, we have attained outstanding
results in online assessments, demonstrating the performance and generalization
capabilities of the proposed system. The source code for our system is released
in \url{https://gitlab.aicrowd.com/shizueyy/crag-new}.

摘要：檢索增強生成 (RAG) 是一個框架，使大型語言模型 (LLM) 能夠透過整合外部知識庫來增強其準確度並減少幻覺。在本文中，我們介紹了一個混合的 RAG 系統，透過一組全面的最佳化來增強，這些最佳化顯著地改善了檢索品質、增強推理能力，並改善數值計算能力。我們改進了網頁中的文字區塊和表格，加入屬性預測器以減少幻覺，執行了 LLM 知識萃取器和知識圖表萃取器，並最終建構了一個包含所有參考的推理策略。我們在 Meta CRAG KDD Cup 2024 競賽中透過 CRAG 資料集評估我們的系統。在地端和線上評估都證明我們的系統顯著地增強了複雜的推理能力。在地端評估中，與基線模型相比，我們顯著地改善了準確度並降低了錯誤率，達到了顯著的評分提升。同時，我們在線上評估中獲得了傑出的結果，證明了所提出的系統的效能和泛化能力。我們系統的原始碼已在 \url{https://gitlab.aicrowd.com/shizueyy/crag-new} 中發布。

##### **Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning**
2408.07091v2 by Wenbin Hu, Huihao Jing, Qi Hu, Haoran Li, Yangqiu Song

Textual graphs are ubiquitous in real-world applications, featuring rich text
information with complex relationships, which enables advanced research across
various fields. Textual graph representation learning aims to generate
low-dimensional feature embeddings from textual graphs that can improve the
performance of downstream tasks. A high-quality feature embedding should
effectively capture both the structural and the textual information in a
textual graph. However, most textual graph dataset benchmarks rely on word2vec
techniques to generate feature embeddings, which inherently limits their
capabilities. Recent works on textual graph representation learning can be
categorized into two folds: supervised and unsupervised methods. Supervised
methods finetune a language model on labeled nodes, which have limited
capabilities when labeled data is scarce. Unsupervised methods, on the other
hand, extract feature embeddings by developing complex training pipelines. To
address these limitations, we propose a novel unified unsupervised learning
autoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ
language models as the backbone of the autoencoder, with pretraining on text
reconstruction. Additionally, we add an auxiliary loss term to make the feature
embeddings aware of the local graph structure. Our method maintains simplicity
in the training process and demonstrates generalizability across diverse
textual graphs and downstream tasks. We evaluate our method on two core graph
representation learning downstream tasks: node classification and link
prediction. Comprehensive experiments demonstrate that our approach
substantially enhances the performance of diverse graph neural networks (GNNs)
across multiple textual graph datasets.

摘要：<paragraph>文本圖表在現實世界的應用中無處不在，它具有豐富的文字資訊和複雜的關係，這使得它能夠在各種領域進行先進的研究。文本圖表表示學習旨在從文本圖表中產生低維特徵嵌入，這可以改善下游任務的效能。一個高品質的特徵嵌入應該有效地擷取文本圖表中的結構和文字資訊。然而，大多數文本圖表資料集基準依賴 word2vec 技術來產生特徵嵌入，這在根本上限制了它們的能力。最近關於文本圖表表示學習的研究可以分為兩類：監督式和非監督式方法。監督式方法在標籤節點上微調語言模型，當標籤資料稀少時，它們的能力有限。另一方面，非監督式方法透過開發複雜的訓練管線來提取特徵嵌入。為了解決這些限制，我們提出了一個新穎的統一非監督式學習自動編碼器框架，稱為節點層級圖形自動編碼器（NodeGAE）。我們採用語言模型作為自動編碼器的骨幹，並在文字重建上進行預訓練。此外，我們還新增了一個輔助損失項，以使特徵嵌入認識到局部圖形結構。我們的模型在訓練過程中保持了簡潔性，並展示了在不同的文本圖表和下游任務中的泛化性。我們在兩個核心圖形表示學習下游任務上評估了我們的模型：節點分類和連結預測。綜合實驗表明，我們的模型方法大幅提升了多個文本圖形資料集中的各種圖形神經網路（GNN）的效能。</paragraph>

##### **HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**
2408.04948v1 by Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta

Extraction and interpretation of intricate information from unstructured text
data arising in financial applications, such as earnings call transcripts,
present substantial challenges to large language models (LLMs) even using the
current best practices to use Retrieval Augmented Generation (RAG) (referred to
as VectorRAG techniques which utilize vector databases for information
retrieval) due to challenges such as domain specific terminology and complex
formats of the documents. We introduce a novel approach based on a combination,
called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called
GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for
information extraction from financial documents that is shown to be capable of
generating accurate and contextually relevant answers. Using experiments on a
set of financial earning call transcripts documents which come in the form of
Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we
show that HybridRAG which retrieves context from both vector database and KG
outperforms both traditional VectorRAG and GraphRAG individually when evaluated
at both the retrieval and generation stages in terms of retrieval accuracy and
answer generation. The proposed technique has applications beyond the financial
domain

摘要：從非結構化文本資料中擷取和詮釋複雜資訊，例如財務應用中產生的收益電話會議記錄，即使使用當前使用檢索擴充生成 (RAG) 的最佳實務（稱為 VectorRAG 技術，它使用向量資料庫來進行資訊檢索），由於領域特定術語和文件格式複雜等挑戰，對大型語言模型 (LLM) 而言仍構成重大挑戰。我們提出一個基於稱為 HybridRAG 的組合的新方法，其結合了基於知識圖譜 (KG) 的 RAG 技術（稱為 GraphRAG）和 VectorRAG 技術，以增強財務文件資訊擷取的問答 (Q&A) 系統，證明它能夠產生準確且與脈絡相關的答案。使用一組以問答格式呈現的財務收益電話會議記錄文件進行實驗，因此提供了自然的一組真實問答對，我們表明 HybridRAG 從向量資料庫和 KG 中擷取脈絡，在檢索和生成階段的檢索準確度和答案生成方面，都優於傳統的 VectorRAG 和 GraphRAG。所提出的技術具有超出財務領域的應用

##### **DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**
2408.04400v1 by Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang

This paper addresses the challenge of out-of-distribution (OOD)
generalization in graph machine learning, a field rapidly advancing yet
grappling with the discrepancy between source and target data distributions.
Traditional graph learning algorithms, based on the assumption of uniform
distribution between training and test data, falter in real-world scenarios
where this assumption fails, resulting in suboptimal performance. A principal
factor contributing to this suboptimal performance is the inherent simplicity
bias of neural networks trained through Stochastic Gradient Descent (SGD),
which prefer simpler features over more complex yet equally or more predictive
ones. This bias leads to a reliance on spurious correlations, adversely
affecting OOD performance in various tasks such as image recognition, natural
language understanding, and graph classification. Current methodologies,
including subgraph-mixup and information bottleneck approaches, have achieved
partial success but struggle to overcome simplicity bias, often reinforcing
spurious correlations. To tackle this, we propose DIVE, training a collection
of models to focus on all label-predictive subgraphs by encouraging the models
to foster divergence on the subgraph mask, which circumvents the limitation of
a model solely focusing on the subgraph corresponding to simple structural
patterns. Specifically, we employs a regularizer to punish overlap in extracted
subgraphs across models, thereby encouraging different models to concentrate on
distinct structural patterns. Model selection for robust OOD performance is
achieved through validation accuracy. Tested across four datasets from GOOD
benchmark and one dataset from DrugOOD benchmark, our approach demonstrates
significant improvement over existing methods, effectively addressing the
simplicity bias and enhancing generalization in graph machine learning.

摘要：<paragraph>這篇論文探討了圖形機器學習中非分佈 (OOD) 概化的挑戰，這是一個快速發展的領域，但卻在應對來源和目標資料分佈之間的差異上遇到困難。傳統的圖形學習演算法基於訓練資料和測試資料之間均勻分佈的假設，但在這個假設失效的實際情況中會出現問題，導致次佳效能。造成這種次佳效能的主要因素是透過隨機梯度下降 (SGD) 訓練的神經網路固有的簡化偏差，它偏好較簡單的特徵，而非更複雜但預測能力相同或更高的特徵。這種偏差會導致依賴虛假相關性，對各種任務（例如影像辨識、自然語言理解和圖形分類）的 OOD 效能產生負面影響。目前的技術方法，包括子圖混合和資訊瓶頸方法，已取得部分成功，但仍難以克服簡化偏差，而且常常會強化虛假相關性。為了解決這個問題，我們提出了 DIVE，訓練一組模型以關注所有標籤預測子圖，方法是鼓勵模型在子圖遮罩上促進差異，這避開了模型僅關注對應於簡單結構模式的子圖的限制。具體來說，我們採用一個正規化器來懲罰模型之間提取的子圖中的重疊，從而鼓勵不同的模型專注於不同的結構模式。透過驗證準確度，可以選擇模型以獲得穩健的 OOD 效能。我們的做法在 GOOD 基準中的四個資料集和 DrugOOD 基準中的其中一個資料集上進行了測試，結果顯示出比現有方法有顯著的進步，有效地解決了簡化偏差，並增強了圖形機器學習中的概化能力。</paragraph>

##### **MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models**
2408.04388v1 by Haoxuan Li, Zhengmao Yang, Yunshan Ma, Yi Bin, Yang Yang, Tat-Seng Chua

We study an emerging and intriguing problem of multimodal temporal event
forecasting with large language models. Compared to using text or graph
modalities, the investigation of utilizing images for temporal event
forecasting has not been fully explored, especially in the era of large
language models (LLMs). To bridge this gap, we are particularly interested in
two key questions of: 1) why images will help in temporal event forecasting,
and 2) how to integrate images into the LLM-based forecasting framework. To
answer these research questions, we propose to identify two essential functions
that images play in the scenario of temporal event forecasting, i.e.,
highlighting and complementary. Then, we develop a novel framework, named
MM-Forecast. It employs an Image Function Identification module to recognize
these functions as verbal descriptions using multimodal large language models
(MLLMs), and subsequently incorporates these function descriptions into
LLM-based forecasting models. To evaluate our approach, we construct a new
multimodal dataset, MidEast-TE-mm, by extending an existing event dataset
MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast
can correctly identify the image functions, and further more, incorporating
these verbal function descriptions significantly improves the forecasting
performance. The dataset, code, and prompts are available at
https://github.com/LuminosityX/MM-Forecast.

摘要：我們研究多模態時間事件預測中一個新興且有趣的語言模型問題。相較於使用文字或圖表模態，利用影像進行時間事件預測的研究尚未被充分探索，特別是在大型語言模型 (LLM) 的時代。為了填補這個空白，我們特別感興趣的兩個關鍵問題是：1) 為什麼影像有助於時間事件預測，以及 2) 如何將影像整合到基於 LLM 的預測框架中。為了回答這些研究問題，我們提議找出影像在時間事件預測場景中扮演的兩個基本功能，即突顯和補充。然後，我們開發一個名為 MM-Forecast 的新框架。它使用影像功能識別模組，使用多模態大型語言模型 (MLLM) 將這些功能識別為文字描述，並隨後將這些功能描述納入基於 LLM 的預測模型中。為了評估我們的方法，我們通過使用影像擴充現有的事件資料集 MidEast-TE-mini，建構了一個新的多模態資料集 MidEast-TE-mm。實證研究表明，我們的 MM-Forecast 可以正確識別影像功能，此外，納入這些文字功能描述可以顯著改善預測效能。資料集、程式碼和提示可在 https://github.com/LuminosityX/MM-Forecast 取得。

##### **Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments**
2408.04382v1 by Hsuan-Lei Shao

In court practice, legal professionals rely on their training to provide
opinions that resolve cases, one of the most crucial aspects being the ability
to identify similar judgments from previous courts efficiently. However,
finding a similar case is challenging and often depends on experience, legal
domain knowledge, and extensive labor hours, making veteran lawyers or judges
indispensable. This research aims to automate the analysis of judgment text
similarity. We utilized a judgment dataset labeled as the "golden standard" by
experts, which includes human-verified features that can be converted into an
"expert similarity score." We then constructed a knowledge graph based on
"case-article" relationships, ranking each case using natural language
processing to derive a "Node2vec similarity score." By evaluating these two
similarity scores, we identified their discrepancies and relationships. The
results can significantly reduce the labor hours required for legal searches
and recommendations, with potential applications extending to various fields of
information retrieval.

摘要：在法庭實務中，法律專業人士依賴其培訓提供意見以解決案件，其中最關鍵的方面之一是有效識別先前法院的類似判決的能力。然而，找出類似案件具有挑戰性，且通常取決於經驗、法律領域知識和大量的勞動時間，這使得資深律師或法官不可或缺。本研究旨在自動化判決文本相似性的分析。我們利用專家標記為「黃金標準」的判決資料集，其中包括可轉換為「專家相似性評分」的人工驗證特徵。然後，我們根據「案例-條文」關係建構知識圖譜，使用自然語言處理對每個案例進行排名，以得出「Node2vec 相似性評分」。透過評估這兩個相似性評分，我們找出其差異和關係。結果可以大幅減少法律搜尋和建議所需的勞動時間，潛在應用範圍擴及資訊檢索的各個領域。

##### **Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**
2408.07084v2 by Wangying Yang, Zitao Zheng, Shi Bo, Zhizhong Wu, Bo Zhang, Yuanfang Yang

This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model
designed to predict future medical diagnoses from electronic health records
with enhanced accuracy. The DHCE model innovates by identifying and
differentiating acute and chronic diseases within a patient's visit history,
constructing dynamic hypergraphs that capture the complex, high-order
interactions between diseases. It surpasses traditional recurrent neural
networks and graph neural networks by effectively integrating clinical event
data, reflected through medical language model-assisted encoding, into a robust
patient representation. Through extensive experiments on two benchmark
datasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,
significantly outpacing established baseline models in the precision of
sequential diagnosis prediction.

摘要：本研究引入了一個開創性的動態超圖網路 (DHCE) 模型，旨在透過電子健康記錄預測未來的醫療診斷，並提高準確性。DHCE 模型透過辨識和區分病患就診病史中的急性病和慢性病，建構動態超圖以擷取疾病之間複雜的高階互動，進而創新。它透過將臨床事件資料有效整合到健全的病患表徵中，並透過醫療語言模型輔助編碼反映出來，超越了傳統的遞迴神經網路和圖神經網路。透過在兩個基準資料集 MIMIC-III 和 MIMIC-IV 上進行廣泛的實驗，DHCE 模型展現出優異的效能，在序貫診斷預測的準確度上顯著超越既定的基準模型。

##### **wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech**
2408.04174v1 by Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy

Knowledge graphs (KGs) enhance the performance of large language models
(LLMs) and search engines by providing structured, interconnected data that
improves reasoning and context-awareness. However, KGs only focus on text data,
thereby neglecting other modalities such as speech. In this work, we introduce
wav2graph, the first framework for supervised learning knowledge graph from
speech data. Our pipeline are straightforward: (1) constructing a KG based on
transcribed spoken utterances and a named entity database, (2) converting KG
into embedding vectors, and (3) training graph neural networks (GNNs) for node
classification and link prediction tasks. Through extensive experiments
conducted in inductive and transductive learning contexts using
state-of-the-art GNN models, we provide baseline results and error analysis for
node classification and link prediction tasks on human transcripts and
automatic speech recognition (ASR) transcripts, including evaluations using
both encoder-based and decoder-based node embeddings, as well as monolingual
and multilingual acoustic pre-trained models. All related code, data, and
models are published online.

摘要：知識圖譜 (KG) 透過提供結構化、相互連結的資料，進而改善大型語言模型 (LLM) 和搜尋引擎的效能，提升推理和脈絡感知。然而，KG 只關注文字資料，因此忽略了其他形式，例如語音。在這項工作中，我們介紹 wav2graph，這是第一個從語音資料中監督學習知識圖譜的架構。我們的流程很直接：(1) 根據轉錄的口語表達和命名實體資料庫建構 KG，(2) 將 KG 轉換為嵌入向量，以及 (3) 訓練圖形神經網路 (GNN) 以進行節點分類和連結預測任務。透過使用最先進的 GNN 模型在歸納和轉導學習的環境中進行廣泛的實驗，我們提供節點分類和連結預測任務的基準結果和錯誤分析，其中包括使用編碼器為基礎和解碼器為基礎的節點嵌入，以及單語和多語音學預訓練模型的評估。所有相關程式碼、資料和模型皆已在線上發布。

##### **ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling**
2408.04102v1 by William Y. Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang

Recognizing and disentangling visual attributes from objects is a foundation
to many computer vision applications. While large vision language
representations like CLIP had largely resolved the task of zero-shot object
recognition, zero-shot visual attribute recognition remains a challenge because
CLIP's contrastively-learned vision-language representation cannot effectively
capture object-attribute dependencies. In this paper, we target this weakness
and propose a sentence generation-based retrieval formulation for attribute
recognition that is novel in 1) explicitly modeling a to-be-measured and
retrieved object-attribute relation as a conditional probability graph, which
converts the recognition problem into a dependency-sensitive language-modeling
problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this
reformulation and naturally distilling its knowledge of image-object-attribute
relations to use towards attribute recognition. Specifically, for each
attribute to be recognized on an image, we measure the visual-conditioned
probability of generating a short sentence encoding the attribute's relation to
objects on the image. Unlike contrastive retrieval, which measures likelihood
by globally aligning elements of the sentence to the image, generative
retrieval is sensitive to the order and dependency of objects and attributes in
the sentence. We demonstrate through experiments that generative retrieval
consistently outperforms contrastive retrieval on two visual reasoning
datasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual
Genome Attribute Ranking (VGARank).

摘要：辨識和區分物件的視覺屬性，是許多電腦視覺應用程式的基礎。雖然像 CLIP 這樣的大型視覺語言表徵，已在很大程度上解決了零次學習物件辨識的任務，但零次學習視覺屬性辨識仍然是一個挑戰，因為 CLIP 對比學習的視覺語言表徵，無法有效擷取物件屬性依賴性。在本文中，我們針對此弱點，並提出一個基於句子生成的檢索公式，用於屬性辨識，其新穎之處在於：1) 明確地將待測量和檢索的物件屬性關係建模為條件機率圖，這將辨識問題轉換為依賴敏感的語言模型問題；2) 在此重新公式化上應用大型預訓練的視覺語言模型 (VLM)，並自然地萃取其對影像物件屬性關係的知識，用於屬性辨識。具體來說，對於要在影像上辨識的每個屬性，我們測量在影像上編碼屬性與物件關係的簡短句子的視覺條件機率。與對比檢索不同，對比檢索是透過將句子的元素整體比對到影像來測量可能性，生成檢索則對句子中物件和屬性的順序和依賴性很敏感。我們透過實驗證明，生成檢索在兩個視覺推理資料集，野外視覺屬性 (VAW) 和我們新提出的視覺基因組屬性排名 (VGARank) 上，始終優於對比檢索。

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v2 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Fei Wang, Michael Shieh, Wenmeng Zhou

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce CodexGraph, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, CodexGraph enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess CodexGraph using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, CodexGraph demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

摘要：大型语言模型 (LLM) 在独立代码任务中表现出色，例如 HumanEval 和 MBPP，但在处理整个代码存储库时却遇到了困难。这个挑战促进了对在存储库规模上增强 LLM 代码库交互的研究。当前的解决方案依赖于基于相似性的检索或手动工具和 API，每种解决方案都有明显的缺点。基于相似性的检索在复杂任务中通常召回率较低，而手动工具和 API 通常是特定于任务的，并且需要专业知识，从而降低了它们在不同代码任务和实际应用中的泛化性。为了减轻这些限制，我们引入了 CodexGraph，这是一个将 LLM 代理与从代码存储库中提取的图形数据库界面集成的系统。通过利用图形数据库的结构属性和图形查询语言的灵活性，CodexGraph 使 LLM 代理能够构建和执行查询，从而实现精确的、代码结构感知的上下文检索和代码导航。我们使用三个基准对 CodexGraph 进行了评估：CrossCodeEval、SWE-bench 和 EvoCodeBench。此外，我们还开发了五个实际的编码应用程序。通过统一的图形数据库模式，CodexGraph 在学术和现实世界环境中都展示了竞争性能和潜力，展示了其在软件工程中的多功能性和有效性。我们的应用程序演示：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。

##### **PAGED: A Benchmark for Procedural Graphs Extraction from Documents**
2408.03630v2 by Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei

Automatic extraction of procedural graphs from documents creates a low-cost
way for users to easily understand a complex procedure by skimming visual
graphs. Despite the progress in recent studies, it remains unanswered: whether
the existing studies have well solved this task (Q1) and whether the emerging
large language models (LLMs) can bring new opportunities to this task (Q2). To
this end, we propose a new benchmark PAGED, equipped with a large high-quality
dataset and standard evaluations. It investigates five state-of-the-art
baselines, revealing that they fail to extract optimal procedural graphs well
because of their heavy reliance on hand-written rules and limited available
data. We further involve three advanced LLMs in PAGED and enhance them with a
novel self-refine strategy. The results point out the advantages of LLMs in
identifying textual elements and their gaps in building logical structures. We
hope PAGED can serve as a major landmark for automatic procedural graph
extraction and the investigations in PAGED can offer insights into the research
on logic reasoning among non-sequential elements.

摘要：自動從文件中萃取程序圖表是一種低成本的方式，讓使用者能透過瀏覽視覺化圖表，輕鬆理解複雜的程序。儘管近期研究已有所進展，但仍有待解答的問題：現有的研究是否已妥善解決此任務（Q1），以及新興的大語言模型（LLM）是否能為此任務帶來新的契機（Q2）。為此，我們提出一個新的基準 PAGED，配備大型高品質資料集和標準評量。它探討了五個最先進的基線，揭示了它們無法良好地萃取最佳程序圖表，原因在於它們過度依賴手寫規則和有限的可用資料。我們進一步在 PAGED 中納入三個先進的 LLM，並透過新穎的自精進策略加以強化。結果指出 LLM 在識別文本元素方面的優勢，以及它們在建立邏輯結構方面的差距。我們希望 PAGED 能成為自動程序圖表萃取的主要里程碑，而 PAGED 中的探討能為非順序元素間的邏輯推理研究提供見解。

##### **Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**
2408.03615v1 by Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie

Building a general-purpose agent is a long-standing vision in the field of
artificial intelligence. Existing agents have made remarkable progress in many
domains, yet they still struggle to complete long-horizon tasks in an open
world. We attribute this to the lack of necessary world knowledge and
multimodal experience that can guide agents through a variety of long-horizon
tasks. In this paper, we propose a Hybrid Multimodal Memory module to address
the above challenges. It 1) transforms knowledge into Hierarchical Directed
Knowledge Graph that allows agents to explicitly represent and learn world
knowledge, and 2) summarises historical information into Abstracted Multimodal
Experience Pool that provide agents with rich references for in-context
learning. On top of the Hybrid Multimodal Memory module, a multimodal agent,
Optimus-1, is constructed with dedicated Knowledge-guided Planner and
Experience-Driven Reflector, contributing to a better planning and reflection
in the face of long-horizon tasks in Minecraft. Extensive experimental results
show that Optimus-1 significantly outperforms all existing agents on
challenging long-horizon task benchmarks, and exhibits near human-level
performance on many tasks. In addition, we introduce various Multimodal Large
Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show
that Optimus-1 exhibits strong generalization with the help of the Hybrid
Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.

摘要：打造一個通用代理是人工智慧領域長久以來的願景。現有的代理在許多領域都有顯著的進步，但它們仍難以在開放世界中完成長時程任務。我們將此歸因於缺乏必要的知識和多模態經驗，這些知識和經驗可以引導代理完成各種長時程任務。在本文中，我們提出一個混合多模態記憶體模組來解決上述挑戰。它 1) 將知識轉換為階層式導向知識圖，讓代理能夠明確地表示和學習世界知識，以及 2) 將歷史資訊摘要成抽象的多模態經驗池，為代理提供豐富的參考，以便進行情境學習。在混合多模態記憶體模組之上，建構了一個多模態代理，Optimus-1，它具備專用的知識導向規劃器和經驗驅動的反射器，有助於在 Minecraft 中面對長時程任務時進行更好的規劃和反思。廣泛的實驗結果顯示，Optimus-1 在具有挑戰性的長時程任務基準上顯著優於所有現有代理，並且在許多任務上展現出接近人類的效能。此外，我們引入各種多模態大型語言模型 (MLLM) 作為 Optimus-1 的骨幹。實驗結果顯示，Optimus-1 在混合多模態記憶體模組的幫助下展現出強大的泛化能力，在許多任務上優於 GPT-4V 基準。

##### **Exploring the extent of similarities in software failures across industries using LLMs**
2408.03528v2 by Martin Detloff

The rapid evolution of software development necessitates enhanced safety
measures. Extracting information about software failures from companies is
becoming increasingly more available through news articles.
  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)
model to extract industry-specific information. Although the FAIL model's
database is rich in information, it could benefit from further categorization
and industry-specific insights to further assist software engineers.
  In previous work news articles were collected from reputable sources and
categorized by incidents inside a database. Prompt engineering and Large
Language Models (LLMs) were then applied to extract relevant information
regarding the software failure. This research extends these methods by
categorizing articles into specific domains and types of software failures. The
results are visually represented through graphs.
  The analysis shows that throughout the database some software failures occur
significantly more often in specific industries. This categorization provides a
valuable resource for software engineers and companies to identify and address
common failures.
  This research highlights the synergy between software engineering and Large
Language Models (LLMs) to automate and enhance the analysis of software
failures. By transforming data from the database into an industry specific
model, we provide a valuable resource that can be used to identify common
vulnerabilities, predict potential risks, and implement proactive measures for
preventing software failures. Leveraging the power of the current FAIL database
and data visualization, we aim to provide an avenue for safer and more secure
software in the future.

摘要：<paragraph>軟體開發快速演進，迫切需要增強安全措施。從公司新聞文章中萃取軟體故障資訊正變得越來越容易。
此研究利用大型語言模型（LLM）故障分析調查（FAIL）模型萃取產業特定資訊。儘管 FAIL 模型的資料庫資訊豐富，但若能進一步分類並提供產業特定見解，將有助於軟體工程師。
在先前的研究中，我們從信譽良好的來源收集新聞文章，並將其分類為資料庫中的事件。接著應用提示工程和大型語言模型（LLM）萃取與軟體故障相關的資訊。此研究透過將文章分類到特定領域和軟體故障類型，延伸了這些方法。結果透過圖表視覺化呈現。
分析顯示，在整個資料庫中，某些軟體故障在特定產業中發生的頻率顯著較高。此分類為軟體工程師和公司提供了寶貴的資源，可識別並解決常見故障。
此研究強調了軟體工程與大型語言模型（LLM）之間的綜效作用，可自動化並增強軟體故障分析。透過將資料庫中的資料轉換為產業特定模型，我們提供了一項寶貴的資源，可用於識別常見漏洞、預測潛在風險，並實施主動措施來預防軟體故障。我們利用現有 FAIL 資料庫和資料視覺化的優勢，旨在為未來提供更安全且穩定的軟體。</paragraph>

##### **Enhancing Complex Causality Extraction via Improved Subtask Interaction and Knowledge Fusion**
2408.03079v1 by Jinglong Gao, Chen Lu, Xiao Ding, Zhongyang Li, Ting Liu, Bing Qin

Event Causality Extraction (ECE) aims at extracting causal event pairs from
texts. Despite ChatGPT's recent success, fine-tuning small models remains the
best approach for the ECE task. However, existing fine-tuning based ECE methods
cannot address all three key challenges in ECE simultaneously: 1) Complex
Causality Extraction, where multiple causal-effect pairs occur within a single
sentence; 2) Subtask~ Interaction, which involves modeling the mutual
dependence between the two subtasks of ECE, i.e., extracting events and
identifying the causal relationship between extracted events; and 3) Knowledge
Fusion, which requires effectively fusing the knowledge in two modalities,
i.e., the expressive pretrained language models and the structured knowledge
graphs. In this paper, we propose a unified ECE framework (UniCE to address all
three issues in ECE simultaneously. Specifically, we design a subtask
interaction mechanism to enable mutual interaction between the two ECE
subtasks. Besides, we design a knowledge fusion mechanism to fuse knowledge in
the two modalities. Furthermore, we employ separate decoders for each subtask
to facilitate complex causality extraction. Experiments on three benchmark
datasets demonstrate that our method achieves state-of-the-art performance and
outperforms ChatGPT with a margin of at least 30% F1-score. More importantly,
our model can also be used to effectively improve the ECE performance of
ChatGPT via in-context learning.

摘要：事件因果關係萃取 (ECE) 的目標是從文本中萃取出因果事件對。儘管 ChatGPT 最近獲得成功，微調小型模型仍是 ECE 任務的最佳方法。然而，現有的基於微調的 ECE 方法無法同時解決 ECE 中的三個主要挑戰：1) 複雜因果關係萃取，其中多個因果關係對出現在單一句子中；2) 子任務互動，這涉及對 ECE 的兩個子任務（即萃取事件和識別萃取事件之間的因果關係）之間的相互依賴性進行建模；3) 知識融合，這需要有效地融合兩種模式中的知識，即表達式的預訓練語言模型和結構化的知識圖譜。在本文中，我們提出一個統一的 ECE 框架 (UniCE)，以同時解決 ECE 中的所有三個問題。具體來說，我們設計了一個子任務互動機制，以實現兩個 ECE 子任務之間的相互互動。此外，我們設計了一個知識融合機制來融合兩種模式中的知識。此外，我們針對每個子任務採用單獨的解碼器，以促進複雜因果關係的萃取。在三個基準資料集上的實驗表明，我們的方法達到了最先進的效能，並且以至少 30% 的 F1 分數優於 ChatGPT。更重要的是，我們的模型也可以透過情境學習有效地提升 ChatGPT 的 ECE 效能。

##### **Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs**
2408.03010v1 by Daniel Steinigen, Roman Teucher, Timm Heine Ruland, Max Rudat, Nicolas Flores-Herr, Peter Fischer, Nikola Milosevic, Christopher Schymura, Angelo Ziletti

Recent advancements in Large Language Models (LLMs) have showcased their
proficiency in answering natural language queries. However, their effectiveness
is hindered by limited domain-specific knowledge, raising concerns about the
reliability of their responses. We introduce a hybrid system that augments LLMs
with domain-specific knowledge graphs (KGs), thereby aiming to enhance factual
correctness using a KG-based retrieval approach. We focus on a medical KG to
demonstrate our methodology, which includes (1) pre-processing, (2) Cypher
query generation, (3) Cypher query processing, (4) KG retrieval, and (5)
LLM-enhanced response generation. We evaluate our system on a curated dataset
of 69 samples, achieving a precision of 78\% in retrieving correct KG nodes.
Our findings indicate that the hybrid system surpasses a standalone LLM in
accuracy and completeness, as verified by an LLM-as-a-Judge evaluation method.
This positions the system as a promising tool for applications that demand
factual correctness and completeness, such as target identification -- a
critical process in pinpointing biological entities for disease treatment or
crop enhancement. Moreover, its intuitive search interface and ability to
provide accurate responses within seconds make it well-suited for
time-sensitive, precision-focused research contexts. We publish the source code
together with the dataset and the prompt templates used.

摘要：大型語言模型 (LLM) 的最新進展展示了它們在回答自然語言查詢方面的能力。然而，它們的有效性受到特定領域知識有限的阻礙，這引起了對其回應可靠性的擔憂。我們引入了一個混合系統，該系統使用特定領域的知識圖譜 (KG) 來擴充 LLM，從而旨在使用基於 KG 的檢索方法來增強事實正確性。我們專注於一個醫學 KG 來演示我們的 methodology，其中包括 (1) 預處理，(2) Cypher 查詢生成，(3) Cypher 查詢處理，(4) KG 檢索，以及 (5) LLM 增強的回應生成。我們在一個由 69 個樣本組成的精選數據集上評估我們的系統，在檢索正確的 KG 節點時達到了 78% 的精度。我們的研究結果表明，混合系統在準確性和完整性方面都超過了單獨的 LLM，這通過 LLM 作為評審評估方法得到驗證。這將系統定位為對應用程式來說一個有前途的工具，這些應用程式需要事實正確性和完整性，例如目標識別——在疾病治療或作物改良中精確定位生物實體的關鍵過程。此外，其直觀的搜尋介面和在數秒內提供準確回應的能力使其非常適合時間敏感、注重精確度的研究情境。我們將原始碼與數據集和使用的提示範本一起發布。

