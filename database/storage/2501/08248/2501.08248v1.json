{"2501.08248": {"publish_time": "2025-01-14", "title": "Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models", "paper_summary": "Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.", "paper_summary_zh": "\u9577\u6587\u672c\u8a9e\u8a00\u6a21\u578b (LCLM) \u7684\u6700\u65b0\u9032\u5c55\u6709\u671b\u900f\u904e\u7c21\u5316\u7ba1\u7dda\u4f86\u8f49\u63db\u6aa2\u7d22\u589e\u5f37\u7522\u751f (RAG)\u3002LCLM \u900f\u904e\u5176\u64f4\u5145\u7684\u5167\u5bb9\u8996\u7a97\uff0c\u53ef\u4ee5\u8655\u7406\u6574\u500b\u77e5\u8b58\u5eab\uff0c\u4e26\u76f4\u63a5\u57f7\u884c\u6aa2\u7d22\u548c\u63a8\u7406\uff0c\u6211\u5011\u5c07\u6b64\u529f\u80fd\u5b9a\u7fa9\u70ba\u60c5\u5883\u5167\u6aa2\u7d22\u548c\u63a8\u7406 (ICR^2)\u3002\u4e0d\u904e\uff0c\u73fe\u6709\u7684\u57fa\u6e96\uff08\u4f8b\u5982 LOFT\uff09\u7d93\u5e38\u900f\u904e\u63d0\u4f9b\u904e\u5ea6\u7c21\u5316\u7684\u5167\u5bb9\u4f86\u9ad8\u4f30 LCLM \u7684\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63a8\u51fa ICR^2\uff0c\u9019\u662f\u4e00\u500b\u900f\u904e\u7d0d\u5165\u4f7f\u7528\u5f37\u5927\u6aa2\u7d22\u5668\u6aa2\u7d22\u5230\u7684\u6df7\u6dc6\u6bb5\u843d\uff0c\u5728\u66f4\u5be6\u969b\u7684\u5834\u666f\u4e2d\u8a55\u4f30 LCLM \u7684\u57fa\u6e96\u3002\u63a5\u8457\uff0c\u6211\u5011\u63d0\u51fa\u4e09\u7a2e\u65b9\u6cd5\u4f86\u63d0\u5347 LCLM \u7684\u6548\u80fd\uff1a(1) \u5148\u6aa2\u7d22\u5f8c\u7522\u751f\u7684\u5fae\u8abf\u3001(2) \u6aa2\u7d22\u6ce8\u610f\u529b\u63a2\u6e2c\uff0c\u5b83\u4f7f\u7528\u6ce8\u610f\u529b\u6a19\u982d\u5728\u89e3\u78bc\u671f\u9593\u904e\u6ffe\u548c\u53bb\u9664\u96dc\u8a0a\uff0c\u4ee5\u53ca (3) \u5728\u7522\u751f\u6a19\u982d\u65c1\u9032\u884c\u806f\u5408\u6aa2\u7d22\u6a19\u982d\u8a13\u7df4\u3002\u6211\u5011\u5728 LOFT \u548c ICR^2 \u4e0a\u5c0d\u4e94\u500b\u77e5\u540d\u7684 LCLM \u9032\u884c\u8a55\u4f30\uff0c\u8b49\u660e\u6211\u5011\u7684\u6700\u4f73\u65b9\u6cd5\u61c9\u7528\u65bc Mistral-7B \u6642\u6709\u986f\u8457\u9032\u6b65\uff1a\u8207\u539f\u59cb RAG \u548c\u76e3\u7763\u5fae\u8abf\u76f8\u6bd4\uff0c\u5728 LOFT \u4e0a\u7684\u5b8c\u5168\u6bd4\u5c0d\u589e\u52a0\u4e86 17 \u548c 15 \u9ede\uff0c\u5728 ICR^2 \u4e0a\u589e\u52a0\u4e86 13 \u548c 2 \u9ede\u3002\u5373\u4f7f\u5b83\u662f\u4e00\u500b\u5c0f\u5f97\u591a\u7684\u6a21\u578b\uff0c\u4f46\u5728\u5927\u591a\u6578\u4efb\u52d9\u4e0a\u4ecd\u512a\u65bc GPT-4-Turbo\u3002", "author": "Yifu Qiu et.al.", "authors": "Yifu Qiu, Varun Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han", "id": "2501.08248v1", "paper_url": "http://arxiv.org/abs/2501.08248v1", "repo": "null"}}