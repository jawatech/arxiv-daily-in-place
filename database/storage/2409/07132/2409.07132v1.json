{"2409.07132": {"publish_time": "2024-09-11", "title": "LLM-based feature generation from text for interpretable machine learning", "paper_summary": "Existing text representations such as embeddings and bag-of-words are not\nsuitable for rule learning due to their high dimensionality and absent or\nquestionable feature-level interpretability. This article explores whether\nlarge language models (LLMs) could address this by extracting a small number of\ninterpretable features from text. We demonstrate this process on two datasets\n(CORD-19 and M17+) containing several thousand scientific articles from\nmultiple disciplines and a target being a proxy for research impact. An\nevaluation based on testing for the statistically significant correlation with\nresearch impact has shown that LLama 2-generated features are semantically\nmeaningful. We consequently used these generated features in text\nclassification to predict the binary target variable representing the citation\nrate for the CORD-19 dataset and the ordinal 5-class target representing an\nexpert-awarded grade in the M17+ dataset. Machine-learning models trained on\nthe LLM-generated features provided similar predictive performance to the\nstate-of-the-art embedding model SciBERT for scientific text. The LLM used only\n62 features compared to 768 features in SciBERT embeddings, and these features\nwere directly interpretable, corresponding to notions such as article\nmethodological rigor, novelty, or grammatical correctness. As the final step,\nwe extract a small number of well-interpretable action rules. Consistently\ncompetitive results obtained with the same LLM feature set across both\nthematically diverse datasets show that this approach generalizes across\ndomains.", "paper_summary_zh": "\u73fe\u6709\u7684\u6587\u672c\u8868\u793a\uff0c\u4f8b\u5982\u5d4c\u5165\u548c\u8a5e\u888b\uff0c\u7531\u65bc\u5176\u9ad8\u7dad\u5ea6\u548c\u7f3a\u4e4f\u6216\u6709\u7591\u554f\u7684\u529f\u80fd\u7d1a\u5225\u53ef\u89e3\u91cb\u6027\uff0c\u56e0\u6b64\u4e0d\u9069\u5408\u898f\u5247\u5b78\u7fd2\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u662f\u5426\u53ef\u4ee5\u901a\u904e\u5f9e\u6587\u672c\u4e2d\u63d0\u53d6\u5c11\u6578\u53ef\u89e3\u91cb\u7279\u5fb5\u4f86\u89e3\u6c7a\u6b64\u554f\u984c\u3002\u6211\u5011\u5728\u5169\u500b\u6578\u64da\u96c6\uff08CORD-19 \u548c M17+\uff09\u4e0a\u5c55\u793a\u4e86\u9019\u500b\u904e\u7a0b\uff0c\u9019\u4e9b\u6578\u64da\u96c6\u5305\u542b\u4f86\u81ea\u591a\u500b\u5b78\u79d1\u7684\u6578\u5343\u7bc7\u79d1\u5b78\u6587\u7ae0\uff0c\u76ee\u6a19\u662f\u4f5c\u70ba\u7814\u7a76\u5f71\u97ff\u529b\u7684\u4ee3\u7406\u3002\u57fa\u65bc\u5c0d\u8207\u7814\u7a76\u5f71\u97ff\u529b\u5177\u6709\u7d71\u8a08\u986f\u8457\u76f8\u95dc\u6027\u7684\u6e2c\u8a66\u7684\u8a55\u4f30\u8868\u660e\uff0cLLama 2 \u751f\u6210\u7684\u7279\u5fb5\u5728\u8a9e\u7fa9\u4e0a\u662f\u6709\u610f\u7fa9\u7684\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5728\u6587\u672c\u5206\u985e\u4e2d\u4f7f\u7528\u4e86\u9019\u4e9b\u751f\u6210\u7684\u7279\u6027\u4f86\u9810\u6e2c\u4ee3\u8868 CORD-19 \u6578\u64da\u96c6\u5f15\u6587\u7387\u7684\u4e8c\u5143\u76ee\u6a19\u8b8a\u91cf\u548c\u4ee3\u8868 M17+ \u6578\u64da\u96c6\u4e2d\u5c08\u5bb6\u8a55\u5206\u7684\u5e8f\u6578 5 \u985e\u76ee\u6a19\u3002\u5728 LLM \u751f\u6210\u7684\u7279\u5fb5\u4e0a\u8a13\u7df4\u7684\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u63d0\u4f9b\u4e86\u8207\u79d1\u5b78\u6587\u672c\u7684\u6700\u65b0\u5d4c\u5165\u6a21\u578b SciBERT \u985e\u4f3c\u7684\u9810\u6e2c\u6027\u80fd\u3002\u8207 SciBERT \u5d4c\u5165\u4e2d\u7684 768 \u500b\u7279\u5fb5\u76f8\u6bd4\uff0cLLM \u50c5\u4f7f\u7528\u4e86 62 \u500b\u7279\u5fb5\uff0c\u4e26\u4e14\u9019\u4e9b\u7279\u5fb5\u662f\u76f4\u63a5\u53ef\u89e3\u91cb\u7684\uff0c\u5c0d\u61c9\u65bc\u6587\u7ae0\u65b9\u6cd5\u8ad6\u56b4\u8b39\u6027\u3001\u65b0\u7a4e\u6027\u6216\u8a9e\u6cd5\u6b63\u78ba\u6027\u7b49\u6982\u5ff5\u3002\u4f5c\u70ba\u6700\u5f8c\u4e00\u6b65\uff0c\u6211\u5011\u63d0\u53d6\u4e86\u5c11\u6578\u53ef\u5f88\u597d\u89e3\u91cb\u7684\u52d5\u4f5c\u898f\u5247\u3002\u5728\u5169\u500b\u4e3b\u984c\u591a\u6a23\u5316\u7684\u6578\u64da\u96c6\u4e2d\u4f7f\u7528\u76f8\u540c\u7684 LLM \u7279\u5fb5\u96c6\u7372\u5f97\u7684\u6301\u7e8c\u7af6\u722d\u7d50\u679c\u8868\u660e\uff0c\u9019\u7a2e\u65b9\u6cd5\u53ef\u4ee5\u63a8\u5ee3\u5230\u5404\u500b\u9818\u57df\u3002", "author": "Vojt\u011bch Balek et.al.", "authors": "Vojt\u011bch Balek, Luk\u00e1\u0161 S\u00fdkora, Vil\u00e9m Sklen\u00e1k, Tom\u00e1\u0161 Kliegr", "id": "2409.07132v1", "paper_url": "http://arxiv.org/abs/2409.07132v1", "repo": "null"}}