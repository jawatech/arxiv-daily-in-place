{"2409.20361": {"publish_time": "2024-09-30", "title": "Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference", "paper_summary": "Large language models have demonstrated promising capabilities upon scaling\nup parameters. However, serving large language models incurs substantial\ncomputation and memory movement costs due to their large scale. Quantization\nmethods have been employed to reduce service costs and latency. Nevertheless,\noutliers in activations hinder the development of INT4 weight-activation\nquantization. Existing approaches separate outliers and normal values into two\nmatrices or migrate outliers from activations to weights, suffering from high\nlatency or accuracy degradation. Based on observing activations from large\nlanguage models, outliers can be classified into channel-wise and spike\noutliers. In this work, we propose Rotated Runtime Smooth (RRS), a\nplug-and-play activation smoother for quantization, consisting of Runtime\nSmooth and the Rotation operation. Runtime Smooth (RS) is introduced to\neliminate channel-wise outliers by smoothing activations with channel-wise\nmaximums during runtime. The rotation operation can narrow the gap between\nspike outliers and normal values, alleviating the effect of victims caused by\nchannel-wise smoothing. The proposed method outperforms the state-of-the-art\nmethod in the LLaMA and Qwen families and improves WikiText-2 perplexity from\n57.33 to 6.66 for INT4 inference.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6269\u5927\u53c2\u6570\u65f6\u5df2\u5c55\u793a\u51fa\u6709\u5e0c\u671b\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5927\u89c4\u6a21\uff0c\u63d0\u4f9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u4ea7\u751f\u5927\u91cf\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u79fb\u52a8\u6210\u672c\u3002\u91cf\u5316\u65b9\u6cd5\u5df2\u88ab\u7528\u6765\u964d\u4f4e\u670d\u52a1\u6210\u672c\u548c\u5ef6\u8fdf\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u6fc0\u6d3b\u4e2d\u7684\u5f02\u5e38\u503c\u963b\u788d\u4e86 INT4 \u6743\u91cd\u6fc0\u6d3b\u91cf\u5316\u7684\u53d1\u5c55\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5c06\u5f02\u5e38\u503c\u548c\u6b63\u5e38\u503c\u5206\u6210\u4e24\u4e2a\u77e9\u9635\uff0c\u6216\u5c06\u5f02\u5e38\u503c\u4ece\u6fc0\u6d3b\u8fc1\u79fb\u5230\u6743\u91cd\uff0c\u4ece\u800c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u6216\u7cbe\u5ea6\u4e0b\u964d\u3002\u57fa\u4e8e\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6fc0\u6d3b\u89c2\u5bdf\uff0c\u5f02\u5e38\u503c\u53ef\u4ee5\u5206\u7c7b\u4e3a\u901a\u9053\u5185\u5f02\u5e38\u503c\u548c\u5c16\u5cf0\u5f02\u5e38\u503c\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u65cb\u8f6c\u8fd0\u884c\u65f6\u5e73\u6ed1 (RRS)\uff0c\u8fd9\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u6fc0\u6d3b\u5e73\u6ed1\u5668\uff0c\u7528\u4e8e\u91cf\u5316\uff0c\u7531\u8fd0\u884c\u65f6\u5e73\u6ed1\u548c\u65cb\u8f6c\u64cd\u4f5c\u7ec4\u6210\u3002\u5f15\u5165\u8fd0\u884c\u65f6\u5e73\u6ed1 (RS) \u4ee5\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u4f7f\u7528\u901a\u9053\u5185\u6700\u5927\u503c\u5e73\u6ed1\u6fc0\u6d3b\u6765\u6d88\u9664\u901a\u9053\u5185\u5f02\u5e38\u503c\u3002\u65cb\u8f6c\u64cd\u4f5c\u53ef\u4ee5\u7f29\u5c0f\u5c16\u5cf0\u5f02\u5e38\u503c\u548c\u6b63\u5e38\u503c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u51cf\u8f7b\u901a\u9053\u5185\u5e73\u6ed1\u9020\u6210\u7684\u53d7\u5bb3\u5f71\u54cd\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e LLaMA \u548c Qwen \u7cfb\u5217\u4e2d\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u5c06 WikiText-2 \u7684\u56f0\u60d1\u5ea6\u4ece 57.33 \u63d0\u9ad8\u5230 6.66\uff0c\u7528\u4e8e INT4 \u63a8\u65ad\u3002", "author": "Ke Yi et.al.", "authors": "Ke Yi, Zengke Liu, Jianwei Zhang, Chengyuan Li, Tong Zhang, Junyang Lin, Jingren Zhou", "id": "2409.20361v1", "paper_url": "http://arxiv.org/abs/2409.20361v1", "repo": "null"}}