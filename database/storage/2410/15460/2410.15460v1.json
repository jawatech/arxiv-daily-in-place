{"2410.15460": {"publish_time": "2024-10-20", "title": "Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training", "paper_summary": "As large language models (LLMs) become increasingly deployed across various\nindustries, concerns regarding their reliability, particularly due to\nhallucinations-outputs that are factually inaccurate or irrelevant to user\ninput-have grown. Our research investigates the relationship between the\ntraining process and the emergence of hallucinations to address a key gap in\nexisting research that focuses primarily on post hoc detection and mitigation\nstrategies. Using models from the Pythia suite (70M-12B parameters) and several\nhallucination detection metrics, we analyze hallucination trends throughout\ntraining and explore LLM internal dynamics. We introduce SEnsitive Neuron\nDropout (SeND), a novel training protocol designed to mitigate hallucinations\nby reducing variance during training. SeND achieves this by deterministically\ndropping neurons with significant variability on a dataset, referred to as\nSensitive Neurons. In addition, we develop an unsupervised hallucination\ndetection metric, Efficient EigenScore (EES), which approximates the\ntraditional EigenScore in 2x speed. This efficient metric is integrated into\nour protocol, allowing SeND to be both computationally scalable and effective\nat reducing hallucinations. Our empirical evaluation demonstrates that our\napproach improves LLM reliability at test time by up to 40% compared to normal\ntraining while also providing an efficient method to improve factual accuracy\nwhen adapting LLMs to domains such as Wikipedia and Medical datasets.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5404\u7522\u696d\u7684\u90e8\u7f72\u65e5\u76ca\u5ee3\u6cdb\uff0c\u5c0d\u65bc\u5176\u53ef\u9760\u6027\u7684\u7591\u616e\u4e5f\u96a8\u4e4b\u589e\u52a0\uff0c\u7279\u5225\u662f\u5e7b\u89ba\u8f38\u51fa\uff0c\u5373\u8207\u4e8b\u5be6\u4e0d\u7b26\u6216\u8207\u4f7f\u7528\u8005\u8f38\u5165\u7121\u95dc\u7684\u8f38\u51fa\u3002\u6211\u5011\u7684\u7814\u7a76\u8abf\u67e5\u8a13\u7df4\u6d41\u7a0b\u8207\u5e7b\u89ba\u51fa\u73fe\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u4ee5\u89e3\u6c7a\u73fe\u6709\u7814\u7a76\u7684\u95dc\u9375\u5dee\u8ddd\uff0c\u800c\u73fe\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u4e8b\u5f8c\u5075\u6e2c\u548c\u7de9\u89e3\u7b56\u7565\u3002\u6211\u5011\u4f7f\u7528 Pythia \u7d44\u5408\uff0870M-12B \u53c3\u6578\uff09\u4e2d\u7684\u6a21\u578b\u548c\u5e7e\u500b\u5e7b\u89ba\u5075\u6e2c\u6307\u6a19\uff0c\u5206\u6790\u6574\u500b\u8a13\u7df4\u904e\u7a0b\u4e2d\u7684\u5e7b\u89ba\u8da8\u52e2\uff0c\u4e26\u63a2\u7d22 LLM \u5167\u90e8\u52d5\u614b\u3002\u6211\u5011\u5f15\u5165\u4e86\u654f\u611f\u795e\u7d93\u5143\u4e2d\u65b7\uff08SeND\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u8a13\u7df4\u5354\u5b9a\uff0c\u65e8\u5728\u900f\u904e\u6e1b\u5c11\u8a13\u7df4\u671f\u9593\u7684\u8b8a\u7570\u4f86\u6e1b\u8f15\u5e7b\u89ba\u3002SeND \u900f\u904e\u78ba\u5b9a\u6027\u5730\u6368\u68c4\u8cc7\u6599\u96c6\u4e0a\u8b8a\u7570\u986f\u8457\u7684\u795e\u7d93\u5143\uff08\u7a31\u70ba\u654f\u611f\u795e\u7d93\u5143\uff09\u4f86\u9054\u6210\u6b64\u76ee\u7684\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u7121\u76e3\u7763\u7684\u5e7b\u89ba\u5075\u6e2c\u6307\u6a19\uff0c\u5373\u6709\u6548\u7279\u5fb5\u503c\uff08EES\uff09\uff0c\u5b83\u4ee5 2 \u500d\u7684\u901f\u5ea6\u8fd1\u4f3c\u50b3\u7d71\u7684\u7279\u5fb5\u503c\u3002\u9019\u500b\u6709\u6548\u7684\u6307\u6a19\u6574\u5408\u5230\u6211\u5011\u7684\u5354\u5b9a\u4e2d\uff0c\u8b93 SeND \u5728\u8a08\u7b97\u4e0a\u53ef\u64f4\u5145\u4e14\u6709\u6548\u6e1b\u5c11\u5e7b\u89ba\u3002\u6211\u5011\u7684\u7d93\u9a57\u8a55\u4f30\u986f\u793a\uff0c\u8207\u4e00\u822c\u8a13\u7df4\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5728\u6e2c\u8a66\u6642\u9593\u5c07 LLM \u7684\u53ef\u9760\u6027\u63d0\u5347\u4e86 40%\uff0c\u540c\u6642\u4e5f\u63d0\u4f9b\u4e86\u4e00\u7a2e\u6709\u6548\u7684\u65b9\u6cd5\u4f86\u63d0\u5347\u4e8b\u5be6\u6e96\u78ba\u5ea6\uff0c\u4f8b\u5982\u5c07 LLM \u9069\u61c9\u5230\u7dad\u57fa\u767e\u79d1\u548c\u91ab\u7642\u8cc7\u6599\u96c6\u7b49\u9818\u57df\u3002", "author": "Shahrad Mohammadzadeh et.al.", "authors": "Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi", "id": "2410.15460v1", "paper_url": "http://arxiv.org/abs/2410.15460v1", "repo": "null"}}