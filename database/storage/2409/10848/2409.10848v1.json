{"2409.10848": {"publish_time": "2024-09-17", "title": "3DFacePolicy: Speech-Driven 3D Facial Animation with Diffusion Policy", "paper_summary": "Audio-driven 3D facial animation has made immersive progress both in research\nand application developments. The newest approaches focus on Transformer-based\nmethods and diffusion-based methods, however, there is still gap in the\nvividness and emotional expression between the generated animation and real\nhuman face. To tackle this limitation, we propose 3DFacePolicy, a diffusion\npolicy model for 3D facial animation prediction. This method generates variable\nand realistic human facial movements by predicting the 3D vertex trajectory on\nthe 3D facial template with diffusion policy instead of facial generation for\nevery frame. It takes audio and vertex states as observations to predict the\nvertex trajectory and imitate real human facial expressions, which keeps the\ncontinuous and natural flow of human emotions. The experiments show that our\napproach is effective in variable and dynamic facial motion synthesizing.", "paper_summary_zh": "\u97f3\u8a0a\u9a45\u52d5\u7684 3D \u81c9\u90e8\u52d5\u756b\u5728\u7814\u7a76\u548c\u61c9\u7528\u958b\u767c\u4e0a\u90fd\u6709\u986f\u8457\u9032\u5c55\u3002\u6700\u65b0\u7684\u65b9\u6cd5\u5c08\u6ce8\u65bc\u57fa\u65bc Transformer \u7684\u65b9\u6cd5\u548c\u57fa\u65bc\u64f4\u6563\u7684\u65b9\u6cd5\uff0c\u7136\u800c\uff0c\u5728\u751f\u6210\u7684\u52d5\u756b\u548c\u771f\u5be6\u4eba\u81c9\u4e4b\u9593\u5728\u751f\u52d5\u6027\u548c\u60c5\u7dd2\u8868\u9054\u4e0a\u4ecd\u6709\u5dee\u8ddd\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 3DFacePolicy\uff0c\u4e00\u7a2e\u7528\u65bc 3D \u81c9\u90e8\u52d5\u756b\u9810\u6e2c\u7684\u64f4\u6563\u7b56\u7565\u6a21\u578b\u3002\u6b64\u65b9\u6cd5\u901a\u904e\u5728 3D \u81c9\u90e8\u7bc4\u672c\u4e0a\u9810\u6e2c 3D \u9802\u9ede\u8ecc\u8de1\uff0c\u800c\u4e0d\u662f\u70ba\u6bcf\u500b\u5e40\u751f\u6210\u81c9\u90e8\uff0c\u4f86\u751f\u6210\u53ef\u8b8a\u4e14\u903c\u771f\u7684\u771f\u4eba\u81c9\u90e8\u52d5\u4f5c\u3002\u5b83\u5c07\u97f3\u8a0a\u548c\u9802\u9ede\u72c0\u614b\u4f5c\u70ba\u89c0\u5bdf\u503c\uff0c\u4ee5\u9810\u6e2c\u9802\u9ede\u8ecc\u8de1\u4e26\u6a21\u4eff\u771f\u5be6\u7684\u4eba\u81c9\u8868\u60c5\uff0c\u5f9e\u800c\u4fdd\u6301\u4eba\u985e\u60c5\u7dd2\u7684\u9023\u7e8c\u6027\u548c\u81ea\u7136\u6d41\u52d5\u3002\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5728\u53ef\u8b8a\u4e14\u52d5\u614b\u7684\u81c9\u90e8\u52d5\u4f5c\u5408\u6210\u65b9\u9762\u662f\u6709\u6548\u7684\u3002", "author": "Xuanmeng Sha et.al.", "authors": "Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Yuki Uranishi", "id": "2409.10848v1", "paper_url": "http://arxiv.org/abs/2409.10848v1", "repo": "null"}}