{"2405.10938": {"publish_time": "2024-05-17", "title": "Observational Scaling Laws and the Predictability of Language Model Performance", "paper_summary": "Understanding how language model performance varies with scale is critical to\nbenchmark and algorithm development. Scaling laws are one approach to building\nthis understanding, but the requirement of training models across many\ndifferent scales has limited their use. We propose an alternative,\nobservational approach that bypasses model training and instead builds scaling\nlaws from ~80 publically available models. Building a single scaling law from\nmultiple model families is challenging due to large variations in their\ntraining compute efficiencies and capabilities. However, we show that these\nvariations are consistent with a simple, generalized scaling law where language\nmodel performance is a function of a low-dimensional capability space, and\nmodel families only vary in their efficiency in converting training compute to\ncapabilities. Using this approach, we show the surprising predictability of\ncomplex scaling phenomena: we show that several emergent phenomena follow a\nsmooth, sigmoidal behavior and are predictable from small models; we show that\nthe agent performance of models such as GPT-4 can be precisely predicted from\nsimpler non-agentic benchmarks; and we show how to predict the impact of\npost-training interventions like Chain-of-Thought and Self-Consistency as\nlanguage model capabilities continue to improve.", "paper_summary_zh": "\u4e86\u89e3\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u5982\u4f55\u968f\u7740\u89c4\u6a21\u800c\u53d8\u5316\u5bf9\u4e8e\u57fa\u51c6\u548c\u7b97\u6cd5\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002\u7f29\u653e\u5b9a\u5f8b\u662f\u5efa\u7acb\u8fd9\u79cd\u7406\u89e3\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u4f46\u8de8\u8bb8\u591a\u4e0d\u540c\u89c4\u6a21\u8bad\u7ec3\u6a21\u578b\u7684\u8981\u6c42\u9650\u5236\u4e86\u5b83\u4eec\u7684\u4f7f\u7528\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u66ff\u4ee3\u6027\u7684\u89c2\u5bdf\u65b9\u6cd5\uff0c\u5b83\u7ed5\u8fc7\u4e86\u6a21\u578b\u8bad\u7ec3\uff0c\u800c\u662f\u4ece\u7ea6 80 \u4e2a\u516c\u5f00\u53ef\u7528\u7684\u6a21\u578b\u4e2d\u6784\u5efa\u7f29\u653e\u5b9a\u5f8b\u3002\u7531\u4e8e\u8bad\u7ec3\u8ba1\u7b97\u6548\u7387\u548c\u80fd\u529b\u7684\u5dee\u5f02\u5f88\u5927\uff0c\u56e0\u6b64\u5f88\u96be\u4ece\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u6784\u5efa\u4e00\u4e2a\u5355\u4e00\u7684\u7f29\u653e\u5b9a\u5f8b\u3002\u7136\u800c\uff0c\u6211\u4eec\u8868\u660e\u8fd9\u4e9b\u53d8\u5316\u4e0e\u4e00\u4e2a\u7b80\u5355\u7684\u3001\u901a\u7528\u7684\u7f29\u653e\u5b9a\u5f8b\u662f\u4e00\u81f4\u7684\uff0c\u5176\u4e2d\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u662f\u4f4e\u7ef4\u80fd\u529b\u7a7a\u95f4\u7684\u51fd\u6570\uff0c\u800c\u6a21\u578b\u7cfb\u5217\u4ec5\u5728\u5c06\u8bad\u7ec3\u8ba1\u7b97\u8f6c\u6362\u4e3a\u80fd\u529b\u65b9\u9762\u7684\u6548\u7387\u4e0a\u6709\u6240\u4e0d\u540c\u3002\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u590d\u6742\u7f29\u653e\u73b0\u8c61\u7684\u60ca\u4eba\u53ef\u9884\u6d4b\u6027\uff1a\u6211\u4eec\u8868\u660e\uff0c\u51e0\u4e2a\u65b0\u5174\u73b0\u8c61\u9075\u5faa\u5e73\u6ed1\u7684 S \u5f62\u884c\u4e3a\uff0c\u5e76\u4e14\u53ef\u4ee5\u4ece\u5c0f\u578b\u6a21\u578b\u4e2d\u9884\u6d4b\uff1b\u6211\u4eec\u8868\u660e\uff0cGPT-4 \u7b49\u6a21\u578b\u7684\u4ee3\u7406\u6027\u80fd\u53ef\u4ee5\u4ece\u66f4\u7b80\u5355\u7684\u975e\u4ee3\u7406\u57fa\u51c6\u4e2d\u51c6\u786e\u9884\u6d4b\uff1b\u6211\u4eec\u5c55\u793a\u4e86\u5982\u4f55\u9884\u6d4b\u50cf\u601d\u60f3\u94fe\u548c\u81ea\u6d3d\u6027\u8fd9\u6837\u7684\u540e\u8bad\u7ec3\u5e72\u9884\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u4e0d\u65ad\u63d0\u9ad8\u3002", "author": "Yangjun Ruan et.al.", "authors": "Yangjun Ruan, Chris J. Maddison, Tatsunori Hashimoto", "id": "2405.10938v1", "paper_url": "http://arxiv.org/abs/2405.10938v1", "repo": "null"}}