{"2501.13074": {"publish_time": "2025-01-22", "title": "Autonomy-of-Experts Models", "paper_summary": "Mixture-of-Experts (MoE) models mostly use a router to assign tokens to\nspecific expert modules, activating only partial parameters and often\noutperforming dense models. We argue that the separation between the router's\ndecision-making and the experts' execution is a critical yet overlooked issue,\nleading to suboptimal expert selection and ineffective learning. To address\nthis, we propose Autonomy-of-Experts (AoE), a novel MoE paradigm in which\nexperts autonomously select themselves to process inputs. AoE is based on the\ninsight that an expert is aware of its own capacity to effectively process a\ntoken, an awareness reflected in the scale of its internal activations. In AoE,\nrouters are removed; instead, experts pre-compute internal activations for\ninputs and are ranked based on their activation norms. Only the top-ranking\nexperts proceed with the forward pass, while the others abort. The overhead of\npre-computing activations is reduced through a low-rank weight factorization.\nThis self-evaluating-then-partner-comparing approach ensures improved expert\nselection and effective learning. We pre-train language models having 700M up\nto 4B parameters, demonstrating that AoE outperforms traditional MoE models\nwith comparable efficiency.", "paper_summary_zh": "\u6df7\u5408\u4e13\u5bb6 (MoE) \u6a21\u578b\u4e3b\u8981\u4f7f\u7528\u8def\u7531\u5668\u5c07\u4ee3\u5e63\u5206\u914d\u7d66\u7279\u5b9a\u5c08\u5bb6\u6a21\u7d44\uff0c\u53ea\u555f\u52d5\u90e8\u5206\u53c3\u6578\uff0c\u4e26\u4e14\u901a\u5e38\u512a\u65bc\u7a20\u5bc6\u6a21\u578b\u3002\u6211\u5011\u8a8d\u70ba\u8def\u7531\u5668\u7684\u6c7a\u7b56\u5236\u5b9a\u8207\u5c08\u5bb6\u7684\u57f7\u884c\u4e4b\u9593\u7684\u5340\u5225\u662f\u4e00\u500b\u95dc\u9375\u4f46\u88ab\u5ffd\u8996\u7684\u554f\u984c\uff0c\u5c0e\u81f4\u5c08\u5bb6\u9078\u64c7\u6b21\u4f73\u548c\u5b78\u7fd2\u7121\u6548\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u5c08\u5bb6\u81ea\u4e3b (AoE)\uff0c\u4e00\u7a2e\u65b0\u7684 MoE \u5178\u7bc4\uff0c\u5176\u4e2d\u5c08\u5bb6\u81ea\u4e3b\u9078\u64c7\u81ea\u5df1\u4f86\u8655\u7406\u8f38\u5165\u3002AoE \u57fa\u65bc\u9019\u6a23\u7684\u898b\u89e3\uff1a\u5c08\u5bb6\u77e5\u9053\u81ea\u5df1\u6709\u6548\u8655\u7406\u4ee3\u5e63\u7684\u80fd\u529b\uff0c\u9019\u7a2e\u610f\u8b58\u53cd\u6620\u5728\u5176\u5167\u90e8\u6fc0\u6d3b\u7684\u898f\u6a21\u4e2d\u3002\u5728 AoE \u4e2d\uff0c\u8def\u7531\u5668\u88ab\u79fb\u9664\uff1b\u76f8\u53cd\uff0c\u5c08\u5bb6\u6703\u9810\u5148\u8a08\u7b97\u8f38\u5165\u7684\u5167\u90e8\u6fc0\u6d3b\uff0c\u4e26\u6839\u64da\u5176\u6fc0\u6d3b\u7bc4\u6578\u9032\u884c\u6392\u540d\u3002\u53ea\u6709\u6392\u540d\u6700\u9ad8\u7684\u5c08\u5bb6\u624d\u6703\u7e7c\u7e8c\u9032\u884c\u524d\u5411\u50b3\u905e\uff0c\u800c\u5176\u4ed6\u5c08\u5bb6\u5247\u4e2d\u65b7\u3002\u901a\u904e\u4f4e\u968e\u6b0a\u91cd\u5206\u89e3\uff0c\u53ef\u4ee5\u6e1b\u5c11\u9810\u5148\u8a08\u7b97\u6fc0\u6d3b\u7684\u958b\u92b7\u3002\u9019\u7a2e\u81ea\u8a55\u7136\u5f8c\u8207\u5408\u4f5c\u5925\u4f34\u6bd4\u8f03\u7684\u65b9\u6cd5\u78ba\u4fdd\u4e86\u6539\u9032\u7684\u5c08\u5bb6\u9078\u64c7\u548c\u6709\u6548\u7684\u5b78\u7fd2\u3002\u6211\u5011\u9810\u5148\u8a13\u7df4\u4e86\u5177\u6709 700M \u5230 4B \u53c3\u6578\u7684\u8a9e\u8a00\u6a21\u578b\uff0c\u8b49\u660e AoE \u512a\u65bc\u5177\u6709\u53ef\u6bd4\u6548\u7387\u7684\u50b3\u7d71 MoE \u6a21\u578b\u3002", "author": "Ang Lv et.al.", "authors": "Ang Lv, Ruobing Xie, Yining Qian, Songhao Wu, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan", "id": "2501.13074v1", "paper_url": "http://arxiv.org/abs/2501.13074v1", "repo": "null"}}