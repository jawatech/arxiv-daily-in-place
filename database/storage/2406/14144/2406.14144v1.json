{"2406.14144": {"publish_time": "2024-06-20", "title": "Finding Safety Neurons in Large Language Models", "paper_summary": "Large language models (LLMs) excel in various capabilities but also pose\nsafety risks such as generating harmful content and misinformation, even after\nsafety alignment. In this paper, we explore the inner mechanisms of safety\nalignment from the perspective of mechanistic interpretability, focusing on\nidentifying and analyzing safety neurons within LLMs that are responsible for\nsafety behaviors. We propose generation-time activation contrasting to locate\nthese neurons and dynamic activation patching to evaluate their causal effects.\nExperiments on multiple recent LLMs show that: (1) Safety neurons are sparse\nand effective. We can restore $90$% safety performance with intervention only\non about $5$% of all the neurons. (2) Safety neurons encode transferrable\nmechanisms. They exhibit consistent effectiveness on different red-teaming\ndatasets. The finding of safety neurons also interprets \"alignment tax\". We\nobserve that the identified key neurons for safety and helpfulness\nsignificantly overlap, but they require different activation patterns of the\nshared neurons. Furthermore, we demonstrate an application of safety neurons in\ndetecting unsafe outputs before generation. Our findings may promote further\nresearch on understanding LLM alignment. The source codes will be publicly\nreleased to facilitate future research.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u529f\u80fd\u4e0a\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u4e5f\u5b58\u5728\u5b89\u5168\u98a8\u96aa\uff0c\u4f8b\u5982\u5373\u4f7f\u5728\u5b89\u5168\u5c0d\u9f4a\u5f8c\uff0c\u4e5f\u6703\u7522\u751f\u6709\u5bb3\u5167\u5bb9\u548c\u932f\u8aa4\u8a0a\u606f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5f9e\u6a5f\u5236\u53ef\u89e3\u91cb\u6027\u7684\u89d2\u5ea6\u63a2\u8a0e\u5b89\u5168\u5c0d\u9f4a\u7684\u5167\u90e8\u6a5f\u5236\uff0c\u91cd\u9ede\u5728\u65bc\u8b58\u5225\u548c\u5206\u6790\u5c0d LLM \u4e2d\u5b89\u5168\u884c\u70ba\u8ca0\u8cac\u7684\u5b89\u5168\u795e\u7d93\u5143\u3002\u6211\u5011\u63d0\u51fa\u751f\u6210\u6642\u9593\u6fc0\u6d3b\u5c0d\u6bd4\u4f86\u5b9a\u4f4d\u9019\u4e9b\u795e\u7d93\u5143\uff0c\u4e26\u52d5\u614b\u6fc0\u6d3b\u4fee\u88dc\u4f86\u8a55\u4f30\u5b83\u5011\u7684\u56e0\u679c\u6548\u61c9\u3002\u5c0d\u591a\u500b\u8fd1\u671f LLM \u7684\u5be6\u9a57\u8868\u660e\uff1a(1) \u5b89\u5168\u795e\u7d93\u5143\u7a00\u758f\u4e14\u6709\u6548\u3002\u6211\u5011\u50c5\u5c0d\u7d04 5% \u7684\u6240\u6709\u795e\u7d93\u5143\u9032\u884c\u5e72\u9810\uff0c\u5c31\u80fd\u6062\u5fa9 90% \u7684\u5b89\u5168\u6548\u80fd\u3002(2) \u5b89\u5168\u795e\u7d93\u5143\u7de8\u78bc\u53ef\u8f49\u79fb\u7684\u6a5f\u5236\u3002\u5b83\u5011\u5728\u4e0d\u540c\u7684\u7d05\u968a\u8cc7\u6599\u96c6\u4e0a\u8868\u73fe\u51fa\u4e00\u81f4\u7684\u6709\u6548\u6027\u3002\u5b89\u5168\u795e\u7d93\u5143\u7684\u767c\u73fe\u4e5f\u89e3\u91cb\u4e86\u300c\u5c0d\u9f4a\u7a05\u300d\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u5b89\u5168\u548c\u6709\u7528\u7684\u5df2\u8b58\u5225\u95dc\u9375\u795e\u7d93\u5143\u6709\u986f\u8457\u91cd\u758a\uff0c\u4f46\u5b83\u5011\u9700\u8981\u5171\u4eab\u795e\u7d93\u5143\u7684\u4e0d\u540c\u6fc0\u6d3b\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c55\u793a\u4e86\u5b89\u5168\u795e\u7d93\u5143\u5728\u751f\u6210\u4e4b\u524d\u6aa2\u6e2c\u4e0d\u5b89\u5168\u8f38\u51fa\u7684\u61c9\u7528\u3002\u6211\u5011\u7684\u767c\u73fe\u53ef\u80fd\u6703\u4fc3\u9032\u9032\u4e00\u6b65\u7814\u7a76\uff0c\u4ee5\u4e86\u89e3 LLM \u5c0d\u9f4a\u3002\u539f\u59cb\u78bc\u5c07\u516c\u958b\u767c\u5e03\uff0c\u4ee5\u5229\u65bc\u672a\u4f86\u7684\u7814\u7a76\u3002", "author": "Jianhui Chen et.al.", "authors": "Jianhui Chen, Xiaozhi Wang, Zijun Yao, Yushi Bai, Lei Hou, Juanzi Li", "id": "2406.14144v1", "paper_url": "http://arxiv.org/abs/2406.14144v1", "repo": "null"}}