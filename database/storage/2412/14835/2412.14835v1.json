{"2412.14835": {"publish_time": "2024-12-19", "title": "Progressive Multimodal Reasoning via Active Retrieval", "paper_summary": "Multi-step multimodal reasoning tasks pose significant challenges for\nmultimodal large language models (MLLMs), and finding effective ways to enhance\ntheir performance in such scenarios remains an unresolved issue. In this paper,\nwe propose AR-MCTS, a universal framework designed to progressively improve the\nreasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo\nTree Search (MCTS). Our approach begins with the development of a unified\nretrieval module that retrieves key supporting insights for solving complex\nreasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in\nautomated multimodal reasoning verification, we employ the MCTS algorithm\ncombined with an active retrieval mechanism, which enables the automatic\ngeneration of step-wise annotations. This strategy dynamically retrieves key\ninsights for each reasoning step, moving beyond traditional beam search\nsampling to improve the diversity and reliability of the reasoning space.\nAdditionally, we introduce a process reward model that aligns progressively to\nsupport the automatic verification of multimodal reasoning tasks. Experimental\nresults across three complex multimodal reasoning benchmarks confirm the\neffectiveness of the AR-MCTS framework in enhancing the performance of various\nmultimodal models. Further analysis demonstrates that AR-MCTS can optimize\nsampling diversity and accuracy, yielding reliable multimodal reasoning.", "paper_summary_zh": "\u591a\u6b65\u9a5f\u591a\u6a21\u614b\u63a8\u7406\u4efb\u52d9\u5c0d\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u69cb\u6210\u91cd\u5927\u6311\u6230\uff0c\u800c\u5c0b\u627e\u6709\u6548\u65b9\u6cd5\u4f86\u63d0\u5347\u5b83\u5011\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\u7684\u6548\u80fd\u4ecd\u7136\u662f\u4e00\u500b\u672a\u89e3\u6c7a\u7684\u554f\u984c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa AR-MCTS\uff0c\u4e00\u500b\u901a\u7528\u6846\u67b6\uff0c\u65e8\u5728\u900f\u904e\u4e3b\u52d5\u6aa2\u7d22 (AR) \u548c\u8499\u5730\u5361\u7f85\u6a39\u72c0\u641c\u5c0b (MCTS) \u9010\u6b65\u63d0\u5347 MLLM \u7684\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u7684\u505a\u6cd5\u5f9e\u958b\u767c\u4e00\u500b\u7d71\u4e00\u7684\u6aa2\u7d22\u6a21\u7d44\u958b\u59cb\uff0c\u8a72\u6a21\u7d44\u5f9e\u6df7\u5408\u6a21\u5f0f\u6aa2\u7d22\u8a9e\u6599\u5eab\u4e2d\u6aa2\u7d22\u89e3\u6c7a\u8907\u96dc\u63a8\u7406\u554f\u984c\u7684\u4e3b\u8981\u652f\u6301\u898b\u89e3\u3002\u70ba\u4e86\u5f4c\u5408\u81ea\u52d5\u5316\u591a\u6a21\u614b\u63a8\u7406\u9a57\u8b49\u7684\u5dee\u8ddd\uff0c\u6211\u5011\u63a1\u7528 MCTS \u6f14\u7b97\u6cd5\u7d50\u5408\u4e3b\u52d5\u6aa2\u7d22\u6a5f\u5236\uff0c\u9019\u4f7f\u5f97\u80fd\u5920\u81ea\u52d5\u7522\u751f\u9010\u6b65\u8a3b\u89e3\u3002\u6b64\u7b56\u7565\u52d5\u614b\u6aa2\u7d22\u6bcf\u500b\u63a8\u7406\u6b65\u9a5f\u7684\u4e3b\u8981\u898b\u89e3\uff0c\u8d85\u8d8a\u50b3\u7d71\u7684\u6ce2\u675f\u641c\u5c0b\u53d6\u6a23\uff0c\u4ee5\u63d0\u5347\u63a8\u7406\u7a7a\u9593\u7684\u591a\u6a23\u6027\u548c\u53ef\u9760\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e00\u500b\u904e\u7a0b\u56de\u994b\u6a21\u578b\uff0c\u9010\u6b65\u8abf\u6574\u4ee5\u652f\u63f4\u591a\u6a21\u614b\u63a8\u7406\u4efb\u52d9\u7684\u81ea\u52d5\u9a57\u8b49\u3002\u5728\u4e09\u500b\u8907\u96dc\u7684\u591a\u6a21\u614b\u63a8\u7406\u57fa\u6e96\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u5be6\u4e86 AR-MCTS \u6846\u67b6\u5728\u63d0\u5347\u5404\u7a2e\u591a\u6a21\u614b\u6a21\u578b\u6548\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u9032\u4e00\u6b65\u7684\u5206\u6790\u8b49\u660e AR-MCTS \u80fd\u5920\u6700\u4f73\u5316\u53d6\u6a23\u591a\u6a23\u6027\u548c\u6e96\u78ba\u5ea6\uff0c\u7522\u751f\u53ef\u9760\u7684\u591a\u6a21\u614b\u63a8\u7406\u3002", "author": "Guanting Dong et.al.", "authors": "Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen", "id": "2412.14835v1", "paper_url": "http://arxiv.org/abs/2412.14835v1", "repo": "null"}}