{"2406.09838": {"publish_time": "2024-06-14", "title": "Vision-Language Models Meet Meteorology: Developing Models for Extreme Weather Events Detection with Heatmaps", "paper_summary": "Real-time detection and prediction of extreme weather protect human lives and\ninfrastructure. Traditional methods rely on numerical threshold setting and\nmanual interpretation of weather heatmaps with Geographic Information Systems\n(GIS), which can be slow and error-prone. Our research redefines Extreme\nWeather Events Detection (EWED) by framing it as a Visual Question Answering\n(VQA) problem, thereby introducing a more precise and automated solution.\nLeveraging Vision-Language Models (VLM) to simultaneously process visual and\ntextual data, we offer an effective aid to enhance the analysis process of\nweather heatmaps. Our initial assessment of general-purpose VLMs (e.g.,\nGPT-4-Vision) on EWED revealed poor performance, characterized by low accuracy\nand frequent hallucinations due to inadequate color differentiation and\ninsufficient meteorological knowledge. To address these challenges, we\nintroduce ClimateIQA, the first meteorological VQA dataset, which includes\n8,760 wind gust heatmaps and 254,040 question-answer pairs covering four\nquestion types, both generated from the latest climate reanalysis data. We also\npropose Sparse Position and Outline Tracking (SPOT), an innovative technique\nthat leverages OpenCV and K-Means clustering to capture and depict color\ncontours in heatmaps, providing ClimateIQA with more accurate color spatial\nlocation information. Finally, we present Climate-Zoo, the first meteorological\nVLM collection, which adapts VLMs to meteorological applications using the\nClimateIQA dataset. Experiment results demonstrate that models from Climate-Zoo\nsubstantially outperform state-of-the-art general VLMs, achieving an accuracy\nincrease from 0% to over 90% in EWED verification. The datasets and models in\nthis study are publicly available for future climate science research:\nhttps://github.com/AlexJJJChen/Climate-Zoo.", "paper_summary_zh": "<paragraph>\u6975\u7aef\u5929\u6c23\u7684\u5373\u6642\u5075\u6e2c\u8207\u9810\u6e2c\u80fd\u4fdd\u8b77\u4eba\u985e\u751f\u547d\u548c\u57fa\u790e\u5efa\u8a2d\u3002\u50b3\u7d71\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u6578\u503c\u95be\u503c\u8a2d\u5b9a\u548c\u4eba\u5de5\u5224\u8b80\u5e36\u6709\u5730\u7406\u8cc7\u8a0a\u7cfb\u7d71 (GIS) \u7684\u5929\u6c23\u71b1\u5716\uff0c\u9019\u53ef\u80fd\u6703\u5f88\u7de9\u6162\u4e14\u5bb9\u6613\u51fa\u932f\u3002\u6211\u5011\u7684\u7814\u7a76\u900f\u904e\u5c07\u6975\u7aef\u5929\u6c23\u4e8b\u4ef6\u5075\u6e2c (EWED) \u91cd\u65b0\u5b9a\u7fa9\u70ba\u8996\u89ba\u554f\u7b54 (VQA) \u554f\u984c\uff0c\u5f9e\u800c\u63d0\u51fa\u66f4\u7cbe\u78ba\u4e14\u81ea\u52d5\u5316\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u5229\u7528\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u4f86\u540c\u6642\u8655\u7406\u8996\u89ba\u548c\u6587\u5b57\u8cc7\u6599\uff0c\u63d0\u4f9b\u6709\u6548\u7684\u8f14\u52a9\u5de5\u5177\u4f86\u589e\u5f37\u5929\u6c23\u71b1\u5716\u7684\u5206\u6790\u6d41\u7a0b\u3002\u6211\u5011\u5c0d\u4e00\u822c\u7528\u9014 VLM\uff08\u4f8b\u5982 GPT-4-Vision\uff09\u5728 EWED \u4e0a\u7684\u521d\u6b65\u8a55\u4f30\u986f\u793a\u6548\u80fd\u4e0d\u4f73\uff0c\u5176\u7279\u5fb5\u662f\u6e96\u78ba\u5ea6\u4f4e\u4e14\u983b\u7e41\u51fa\u73fe\u5e7b\u89ba\uff0c\u539f\u56e0\u662f\u984f\u8272\u5340\u5206\u4e0d\u8db3\u4e14\u6c23\u8c61\u77e5\u8b58\u4e0d\u8db3\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u5f15\u5165\u4e86 ClimateIQA\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u6c23\u8c61 VQA \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b 8,760 \u500b\u9663\u98a8\u71b1\u5716\u548c 254,040 \u500b\u554f\u984c\u89e3\u7b54\u5c0d\uff0c\u6db5\u84cb\u56db\u7a2e\u985e\u578b\u7684\u554f\u984c\uff0c\u5169\u8005\u90fd\u662f\u5f9e\u6700\u65b0\u7684\u6c23\u5019\u518d\u5206\u6790\u8cc7\u6599\u4e2d\u7522\u751f\u7684\u3002\u6211\u5011\u9084\u63d0\u51fa\u4e86\u7a00\u758f\u4f4d\u7f6e\u548c\u8f2a\u5ed3\u8ffd\u8e64 (SPOT)\uff0c\u9019\u662f\u4e00\u7a2e\u5275\u65b0\u7684\u6280\u8853\uff0c\u5229\u7528 OpenCV \u548c K-Means \u805a\u985e\u4f86\u64f7\u53d6\u548c\u63cf\u7e6a\u71b1\u5716\u4e2d\u7684\u984f\u8272\u8f2a\u5ed3\uff0c\u70ba ClimateIQA \u63d0\u4f9b\u66f4\u6e96\u78ba\u7684\u984f\u8272\u7a7a\u9593\u4f4d\u7f6e\u8cc7\u8a0a\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c55\u793a\u4e86 Climate-Zoo\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u6c23\u8c61 VLM \u5f59\u6574\uff0c\u5b83\u4f7f\u7528 ClimateIQA \u8cc7\u6599\u96c6\u5c07 VLM \u8abf\u6574\u70ba\u6c23\u8c61\u61c9\u7528\u7a0b\u5f0f\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cClimate-Zoo \u4e2d\u7684\u6a21\u578b\u5927\u5e45\u512a\u65bc\u6700\u5148\u9032\u7684\u901a\u7528 VLM\uff0c\u5728 EWED \u9a57\u8b49\u4e2d\u5c07\u6e96\u78ba\u5ea6\u5f9e 0% \u63d0\u9ad8\u5230 90% \u4ee5\u4e0a\u3002\u672c\u7814\u7a76\u4e2d\u7684\u8cc7\u6599\u96c6\u548c\u6a21\u578b\u516c\u958b\u63d0\u4f9b\uff0c\u4f9b\u672a\u4f86\u7684\u6c23\u5019\u79d1\u5b78\u7814\u7a76\u4f7f\u7528\uff1ahttps://github.com/AlexJJJChen/Climate-Zoo\u3002</paragraph>", "author": "Jian Chen et.al.", "authors": "Jian Chen, Peilin Zhou, Yining Hua, Dading Chong, Meng Cao, Yaowei Li, Zixuan Yuan, Bing Zhu, Junwei Liang", "id": "2406.09838v1", "paper_url": "http://arxiv.org/abs/2406.09838v1", "repo": "https://github.com/AlexJJJChen/Climate-Zoo"}}