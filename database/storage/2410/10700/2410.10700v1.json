{"2410.10700": {"publish_time": "2024-10-14", "title": "Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues", "paper_summary": "This study exposes the safety vulnerabilities of Large Language Models (LLMs)\nin multi-turn interactions, where malicious users can obscure harmful intents\nacross several queries. We introduce ActorAttack, a novel multi-turn attack\nmethod inspired by actor-network theory, which models a network of semantically\nlinked actors as attack clues to generate diverse and effective attack paths\ntoward harmful targets. ActorAttack addresses two main challenges in multi-turn\nattacks: (1) concealing harmful intents by creating an innocuous conversation\ntopic about the actor, and (2) uncovering diverse attack paths towards the same\nharmful target by leveraging LLMs' knowledge to specify the correlated actors\nas various attack clues. In this way, ActorAttack outperforms existing\nsingle-turn and multi-turn attack methods across advanced aligned LLMs, even\nfor GPT-o1. We will publish a dataset called SafeMTData, which includes\nmulti-turn adversarial prompts and safety alignment data, generated by\nActorAttack. We demonstrate that models safety-tuned using our safety dataset\nare more robust to multi-turn attacks. Code is available at\nhttps://github.com/renqibing/ActorAttack.", "paper_summary_zh": "\u672c\u7814\u7a76\u63ed\u9732\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u591a\u8f2a\u4e92\u52d5\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5176\u4e2d\u60e1\u610f\u4f7f\u7528\u8005\u53ef\u4ee5\u5728\u591a\u500b\u67e5\u8a62\u4e2d\u96b1\u85cf\u6709\u5bb3\u610f\u5716\u3002\u6211\u5011\u5f15\u5165\u4e86 ActorAttack\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u8f2a\u653b\u64ca\u65b9\u6cd5\uff0c\u9748\u611f\u4f86\u81ea\u65bc\u884c\u52d5\u8005\u7db2\u8def\u7406\u8ad6\uff0c\u5b83\u5c07\u8a9e\u7fa9\u9023\u7d50\u884c\u52d5\u8005\u7684\u7db2\u8def\u5efa\u6a21\u70ba\u653b\u64ca\u7dda\u7d22\uff0c\u4ee5\u7522\u751f\u591a\u6a23\u5316\u4e14\u6709\u6548\u7684\u653b\u64ca\u8def\u5f91\uff0c\u9032\u800c\u9396\u5b9a\u6709\u5bb3\u76ee\u6a19\u3002ActorAttack \u61c9\u5c0d\u4e86\u591a\u8f2a\u653b\u64ca\u4e2d\u7684\u5169\u500b\u4e3b\u8981\u6311\u6230\uff1a(1) \u900f\u904e\u5275\u9020\u95dc\u65bc\u884c\u52d5\u8005\u7684\u7121\u5bb3\u5c0d\u8a71\u4e3b\u984c\u4f86\u96b1\u85cf\u6709\u5bb3\u610f\u5716\uff0c\u4ee5\u53ca (2) \u900f\u904e\u5229\u7528 LLM \u7684\u77e5\u8b58\u5c07\u76f8\u95dc\u884c\u52d5\u8005\u6307\u5b9a\u70ba\u5404\u7a2e\u653b\u64ca\u7dda\u7d22\uff0c\u9032\u800c\u63ed\u9732\u901a\u5f80\u76f8\u540c\u6709\u5bb3\u76ee\u6a19\u7684\u591a\u6a23\u5316\u653b\u64ca\u8def\u5f91\u3002\u900f\u904e\u9019\u7a2e\u65b9\u5f0f\uff0cActorAttack \u5728\u5148\u9032\u7684\u5c0d\u9f4a LLM \u4e2d\u512a\u65bc\u73fe\u6709\u7684\u55ae\u8f2a\u548c\u591a\u8f2a\u653b\u64ca\u65b9\u6cd5\uff0c\u5373\u4f7f\u662f\u5c0d\u65bc GPT-o1 \u4e5f\u662f\u5982\u6b64\u3002\u6211\u5011\u5c07\u767c\u5e03\u4e00\u500b\u540d\u70ba SafeMTData \u7684\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u7531 ActorAttack \u751f\u6210\u7684\u591a\u8f2a\u5c0d\u6297\u63d0\u793a\u548c\u5b89\u5168\u5c0d\u9f4a\u8cc7\u6599\u3002\u6211\u5011\u8b49\u660e\u4f7f\u7528\u6211\u5011\u7684\u5b89\u5168\u8cc7\u6599\u96c6\u9032\u884c\u5b89\u5168\u8abf\u6574\u7684\u6a21\u578b\u5c0d\u65bc\u591a\u8f2a\u653b\u64ca\u66f4\u5177\u9b6f\u68d2\u6027\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/renqibing/ActorAttack \u53d6\u5f97\u3002", "author": "Qibing Ren et.al.", "authors": "Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao", "id": "2410.10700v1", "paper_url": "http://arxiv.org/abs/2410.10700v1", "repo": "https://github.com/renqibing/actorattack"}}