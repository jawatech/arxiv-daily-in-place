
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-02**|**Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking**|Mattia Segu et.al.|[2410.01806v1](http://arxiv.org/abs/2410.01806v1)|null|
|**2024-10-02**|**Locret: Enhancing Eviction in Long-Context LLM Inference with Trained Retaining Heads**|Yuxiang Huang et.al.|[2410.01805v1](http://arxiv.org/abs/2410.01805v1)|[link](https://github.com/huangyuxiang03/Locret)|
|**2024-10-02**|**FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Clothing Images**|Cheng Zhang et.al.|[2410.01801v1](http://arxiv.org/abs/2410.01801v1)|null|
|**2024-10-02**|**Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models**|Joseph Lee et.al.|[2410.01795v1](http://arxiv.org/abs/2410.01795v1)|[link](https://github.com/pennshenlab/freeform)|
|**2024-10-02**|**When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1**|R. Thomas McCoy et.al.|[2410.01792v1](http://arxiv.org/abs/2410.01792v1)|null|
|**2024-10-02**|**DreamGarden: A Designer Assistant for Growing Games from a Single Prompt**|Sam Earle et.al.|[2410.01791v1](http://arxiv.org/abs/2410.01791v1)|null|
|**2024-10-02**|**Investigating on RLHF methodology**|Alexey Kutalev et.al.|[2410.01789v1](http://arxiv.org/abs/2410.01789v1)|null|
|**2024-10-02**|**OmniGenBench: Automating Large-scale in-silico Benchmarking for Genomic Foundation Models**|Heng Yang et.al.|[2410.01784v1](http://arxiv.org/abs/2410.01784v1)|[link](https://github.com/yangheng95/OmniGenomeBench)|
|**2024-10-02**|**Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models**|Shayekh Bin Islam et.al.|[2410.01782v1](http://arxiv.org/abs/2410.01782v1)|null|
|**2024-10-02**|**DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**|Yebowen Hu et.al.|[2410.01772v1](http://arxiv.org/abs/2410.01772v1)|null|
|**2024-10-02**|**Quantifying Generalization Complexity for Large Language Models**|Zhenting Qi et.al.|[2410.01769v1](http://arxiv.org/abs/2410.01769v1)|null|
|**2024-10-02**|**LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks**|Mengzhao Jia et.al.|[2410.01744v1](http://arxiv.org/abs/2410.01744v1)|null|
|**2024-10-02**|**Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning**|Xingrui Gu et.al.|[2410.01739v1](http://arxiv.org/abs/2410.01739v1)|null|
|**2024-10-02**|**VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models**|Kailai Feng et.al.|[2410.01738v1](http://arxiv.org/abs/2410.01738v1)|[link](https://github.com/carlofkl/vitaglyph)|
|**2024-10-02**|**Recursive Abstractive Processing for Retrieval in Dynamic Datasets**|Charbel Chucri et.al.|[2410.01736v1](http://arxiv.org/abs/2410.01736v1)|null|
|**2024-10-02**|**LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits**|Duy Nguyen et.al.|[2410.01735v1](http://arxiv.org/abs/2410.01735v1)|[link](https://github.com/duykhuongnguyen/laser-mab)|
|**2024-10-02**|**Visual Perception in Text Strings**|Qi Jia et.al.|[2410.01733v1](http://arxiv.org/abs/2410.01733v1)|null|
|**2024-10-02**|**ComfyGen: Prompt-Adaptive Workflows for Text-to-Image Generation**|Rinon Gal et.al.|[2410.01731v1](http://arxiv.org/abs/2410.01731v1)|null|
|**2024-10-02**|**Evaluating Robustness of Reward Models for Mathematical Reasoning**|Sunghwan Kim et.al.|[2410.01729v1](http://arxiv.org/abs/2410.01729v1)|null|
|**2024-10-02**|**Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing**|Yilmazcan Ozyurt et.al.|[2410.01727v1](http://arxiv.org/abs/2410.01727v1)|[link](https://github.com/oezyurty/kcqrl)|
|**2024-10-02**|**Auto-Demo Prompting: Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting**|Longyu Feng et.al.|[2410.01724v1](http://arxiv.org/abs/2410.01724v1)|null|
|**2024-10-02**|**Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective**|Zeyu Gan et.al.|[2410.01720v1](http://arxiv.org/abs/2410.01720v1)|null|
|**2024-10-02**|**Examining the Role of Relationship Alignment in Large Language Models**|Kristen M. Altenburger et.al.|[2410.01708v1](http://arxiv.org/abs/2410.01708v1)|null|
|**2024-10-02**|**Interpretable Contrastive Monte Carlo Tree Search Reasoning**|Zitian Gao et.al.|[2410.01707v1](http://arxiv.org/abs/2410.01707v1)|null|
|**2024-10-02**|**Performant, Memory Efficient and Scalable Multi-Agent Reinforcement Learning**|Omayma Mahjoub et.al.|[2410.01706v1](http://arxiv.org/abs/2410.01706v1)|null|
|**2024-10-02**|**An Exploration of Self-Supervised Mutual Information Alignment for Multi-Task Settings**|Soham Govande et.al.|[2410.01704v1](http://arxiv.org/abs/2410.01704v1)|null|
|**2024-10-02**|**CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs**|Kangsheng Wang et.al.|[2410.01696v1](http://arxiv.org/abs/2410.01696v1)|null|
|**2024-10-02**|**U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models**|Tung-Yu Wu et.al.|[2410.01692v1](http://arxiv.org/abs/2410.01692v1)|null|
|**2024-10-02**|**FactAlign: Long-form Factuality Alignment of Large Language Models**|Chao-Wei Huang et.al.|[2410.01691v1](http://arxiv.org/abs/2410.01691v1)|[link](https://github.com/miulab/factalign)|
|**2024-10-02**|**Why context matters in VQA and Reasoning: Semantic interventions for VLM input modalities**|Kenza Amara et.al.|[2410.01690v1](http://arxiv.org/abs/2410.01690v1)|null|
|**2024-10-02**|**Positional Attention: Out-of-Distribution Generalization and Expressivity for Neural Algorithmic Reasoning**|Artur Back de Luca et.al.|[2410.01686v1](http://arxiv.org/abs/2410.01686v1)|[link](https://github.com/opallab/positional_attention)|
|**2024-10-02**|**PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation**|Mike Ranzinger et.al.|[2410.01680v1](http://arxiv.org/abs/2410.01680v1)|null|
|**2024-10-02**|**VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit Assignment**|Amirhossein Kazemnejad et.al.|[2410.01679v1](http://arxiv.org/abs/2410.01679v1)|[link](https://github.com/mcgill-nlp/vineppo)|
|**2024-10-02**|**Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia**|Miao Yu et.al.|[2410.01677v1](http://arxiv.org/abs/2410.01677v1)|null|
|**2024-10-02**|**Trying to be human: Linguistic traces of stochastic empathy in language models**|Bennett Kleinberg et.al.|[2410.01675v1](http://arxiv.org/abs/2410.01675v1)|null|
|**2024-10-02**|**Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding**|Yanming Liu et.al.|[2410.01671v1](http://arxiv.org/abs/2410.01671v1)|null|
|**2024-10-02**|**Towards a vision foundation model for comprehensive assessment of Cardiac MRI**|Athira J Jacob et.al.|[2410.01665v1](http://arxiv.org/abs/2410.01665v1)|null|
|**2024-10-02**|**Finding path and cycle counting formulae in graphs with Deep Reinforcement Learning**|Jason Piquenot et.al.|[2410.01661v1](http://arxiv.org/abs/2410.01661v1)|null|
|**2024-10-02**|**Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**|Klaus-Rudolf Kladny et.al.|[2410.01660v1](http://arxiv.org/abs/2410.01660v1)|null|
|**2024-10-02**|**Efficient Long-range Language Modeling with Self-supervised Causal Retrieval**|Xiang Hu et.al.|[2410.01651v1](http://arxiv.org/abs/2410.01651v1)|null|
|**2024-10-02**|**shapiq: Shapley Interactions for Machine Learning**|Maximilian Muschalik et.al.|[2410.01649v1](http://arxiv.org/abs/2410.01649v1)|[link](https://github.com/mmschlk/shapiq)|
|**2024-10-02**|**DeIDClinic: A Multi-Layered Framework for De-identification of Clinical Free-text Data**|Angel Paul et.al.|[2410.01648v1](http://arxiv.org/abs/2410.01648v1)|null|
|**2024-10-02**|**Moral Alignment for LLM Agents**|Elizaveta Tennant et.al.|[2410.01639v1](http://arxiv.org/abs/2410.01639v1)|null|
|**2024-10-02**|**Data Extrapolation for Text-to-image Generation on Small Datasets**|Senmao Ye et.al.|[2410.01638v1](http://arxiv.org/abs/2410.01638v1)|[link](https://github.com/senmaoy/RAT-Diffusion)|
|**2024-10-02**|**On The Adaptation of Unlimiformer for Decoder-Only Transformers**|Kian Ahrabian et.al.|[2410.01637v1](http://arxiv.org/abs/2410.01637v1)|null|
|**2024-10-02**|**Does Graph Prompt Work? A Data Operation Perspective with Theoretical Analysis**|Qunzhong Wang et.al.|[2410.01635v1](http://arxiv.org/abs/2410.01635v1)|null|
|**2024-10-02**|**Entropy-Based Uncertainty Modeling for Trajectory Prediction in Autonomous Driving**|Aron Distelzweig et.al.|[2410.01628v1](http://arxiv.org/abs/2410.01628v1)|null|
|**2024-10-02**|**Intent Detection in the Age of LLMs**|Gaurav Arora et.al.|[2410.01627v1](http://arxiv.org/abs/2410.01627v1)|null|
|**2024-10-02**|**Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank Constraint?**|Xi Chen et.al.|[2410.01623v1](http://arxiv.org/abs/2410.01623v1)|[link](https://github.com/xichen-fy/fira)|
|**2024-10-02**|**DRUPI: Dataset Reduction Using Privileged Information**|Shaobo Wang et.al.|[2410.01611v1](http://arxiv.org/abs/2410.01611v1)|null|
|**2024-10-02**|**Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging**|Tingfeng Hui et.al.|[2410.01610v1](http://arxiv.org/abs/2410.01610v1)|null|
|**2024-10-02**|**Automated Red Teaming with GOAT: the Generative Offensive Agent Tester**|Maya Pavlova et.al.|[2410.01606v1](http://arxiv.org/abs/2410.01606v1)|null|
|**2024-10-02**|**ENTP: Encoder-only Next Token Prediction**|Ethan Ewer et.al.|[2410.01600v1](http://arxiv.org/abs/2410.01600v1)|null|
|**2024-10-02**|**Elaborative Subtopic Query Reformulation for Broad and Indirect Queries in Travel Destination Recommendation**|Qianfeng Wen et.al.|[2410.01598v1](http://arxiv.org/abs/2410.01598v1)|[link](https://github.com/yifanliu2/roegen-recsys-24-eqr)|
|**2024-10-02**|**KnobGen: Controlling the Sophistication of Artwork in Sketch-Based Diffusion Models**|Pouyan Navard et.al.|[2410.01595v1](http://arxiv.org/abs/2410.01595v1)|[link](https://github.com/aminK8/KnobGen)|
|**2024-10-02**|**Imaging foundation model for universal enhancement of non-ideal measurement CT**|Yuxin Liu et.al.|[2410.01591v1](http://arxiv.org/abs/2410.01591v1)|[link](https://github.com/yutinghe-list/tamp)|
|**2024-10-02**|**Spoken Grammar Assessment Using LLM**|Sunil Kumar Kopparapu et.al.|[2410.01579v1](http://arxiv.org/abs/2410.01579v1)|null|
|**2024-10-02**|**OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**|Shubham Toshniwal et.al.|[2410.01560v1](http://arxiv.org/abs/2410.01560v1)|[link](https://github.com/kipok/nemo-skills)|
|**2024-10-02**|**Integrative Decoding: Improve Factuality via Implicit Self-consistency**|Yi Cheng et.al.|[2410.01556v1](http://arxiv.org/abs/2410.01556v1)|[link](https://github.com/yicheng98/integrativedecoding)|
|**2024-10-02**|**ACE: A LLM-based Negotiation Coaching System**|Ryan Shea et.al.|[2410.01555v1](http://arxiv.org/abs/2410.01555v1)|null|
|**2024-10-02**|**MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**|Zonghai Yao et.al.|[2410.01553v1](http://arxiv.org/abs/2410.01553v1)|[link](https://github.com/bio-nlp/medqa-cs)|
|**2024-10-02**|**In-Context Transfer Learning: Demonstration Synthesis by Transferring Similar Tasks**|Dingzirui Wang et.al.|[2410.01548v1](http://arxiv.org/abs/2410.01548v1)|[link](https://github.com/zirui-HIT/ICTL)|
|**2024-10-02**|**Edge-preserving noise for diffusion models**|Jente Vandersanden et.al.|[2410.01540v1](http://arxiv.org/abs/2410.01540v1)|null|
|**2024-10-02**|**Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models**|Angela Lopez-Cardona et.al.|[2410.01532v1](http://arxiv.org/abs/2410.01532v1)|null|
|**2024-10-02**|**TiVaT: Joint-Axis Attention for Time Series Forecasting with Lead-Lag Dynamics**|Junwoo Ha et.al.|[2410.01531v1](http://arxiv.org/abs/2410.01531v1)|null|
|**2024-10-02**|**HarmAug: Effective Data Augmentation for Knowledge Distillation of Safety Guard Models**|Seanie Lee et.al.|[2410.01524v1](http://arxiv.org/abs/2410.01524v1)|[link](https://github.com/imnotkind/HarmAug)|
|**2024-10-02**|**InfiniPot: Infinite Context Processing on Memory-Constrained LLMs**|Minsoo Kim et.al.|[2410.01518v1](http://arxiv.org/abs/2410.01518v1)|null|
|**2024-10-02**|**InstaTrans: An Instruction-Aware Translation Framework for Non-English Instruction Datasets**|Yungi Kim et.al.|[2410.01512v1](http://arxiv.org/abs/2410.01512v1)|null|
|**2024-10-02**|**Disentangling Latent Shifts of In-Context Learning Through Self-Training**|Josip Jukić et.al.|[2410.01508v1](http://arxiv.org/abs/2410.01508v1)|null|
|**2024-10-02**|**LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**|Dexuan Ding et.al.|[2410.01506v1](http://arxiv.org/abs/2410.01506v1)|null|
|**2024-10-02**|**PersonaMath: Enhancing Math Reasoning through Persona-Driven Data Augmentation**|Jing Luo et.al.|[2410.01504v1](http://arxiv.org/abs/2410.01504v1)|null|
|**2024-10-02**|**Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation**|Jun Hyeong Kim et.al.|[2410.01500v1](http://arxiv.org/abs/2410.01500v1)|null|
|**2024-10-02**|**DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic, Lightweight Plugin for Large Language Models**|Yuxuan Zhang et.al.|[2410.01497v1](http://arxiv.org/abs/2410.01497v1)|[link](https://github.com/mecuping/dlp-lora)|
|**2024-10-02**|**Extending Context Window of Large Language Models from a Distributional Perspective**|Yingsheng Wu. Yuxuan Gu et.al.|[2410.01490v1](http://arxiv.org/abs/2410.01490v1)|[link](https://github.com/1180301012/DPRoPE)|
|**2024-10-02**|**Small Language Models Like Small Vocabularies: Probing the Linguistic Abilities of Grapheme- and Phoneme-Based Baby Llamas**|Bastian Bunzeck et.al.|[2410.01487v1](http://arxiv.org/abs/2410.01487v1)|null|
|**2024-10-02**|**A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts**|Suyu Ge et.al.|[2410.01485v1](http://arxiv.org/abs/2410.01485v1)|null|
|**2024-10-02**|**One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability**|Gabriel Kasmi et.al.|[2410.01482v1](http://arxiv.org/abs/2410.01482v1)|null|
|**2024-10-02**|**SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios**|Kai Li et.al.|[2410.01481v1](http://arxiv.org/abs/2410.01481v1)|[link](https://github.com/jusperlee/sonicsim)|
|**2024-10-02**|**Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders**|Andreea Iana et.al.|[2410.01470v1](http://arxiv.org/abs/2410.01470v1)|null|
|**2024-10-02**|**TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation**|Mohan Xu et.al.|[2410.01469v1](http://arxiv.org/abs/2410.01469v1)|null|
|**2024-10-02**|**From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with LLM-Guided Knowledge**|Xiefeng Wu et.al.|[2410.01458v1](http://arxiv.org/abs/2410.01458v1)|null|
|**2024-10-02**|**Agent-Driven Large Language Models for Mandarin Lyric Generation**|Hong-Hsiang Liu et.al.|[2410.01450v1](http://arxiv.org/abs/2410.01450v1)|null|
|**2024-10-02**|**Analyzing Byte-Pair Encoding on Monophonic and Polyphonic Symbolic Music: A Focus on Musical Phrase Segmentation**|Dinh-Viet-Toan Le et.al.|[2410.01448v1](http://arxiv.org/abs/2410.01448v1)|null|
|**2024-10-02**|**Geometric Signatures of Compositionality Across a Language Model's Lifetime**|Jin Hwa Lee et.al.|[2410.01444v1](http://arxiv.org/abs/2410.01444v1)|null|
|**2024-10-02**|**Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models**|Philipp Mondorf et.al.|[2410.01434v1](http://arxiv.org/abs/2410.01434v1)|null|
|**2024-10-02**|**Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks**|Xingxuan Li et.al.|[2410.01428v1](http://arxiv.org/abs/2410.01428v1)|null|
|**2024-10-02**|**Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data Free Distillation**|Md Fahim Sikder et.al.|[2410.01423v1](http://arxiv.org/abs/2410.01423v1)|null|
|**2024-10-02**|**The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs**|Hong Li et.al.|[2410.01417v1](http://arxiv.org/abs/2410.01417v1)|null|
|**2024-10-02**|**Improving Fuzzy Rule Classifier with Brain Storm Optimization and Rule Modification**|Yan Huang et.al.|[2410.01413v1](http://arxiv.org/abs/2410.01413v1)|null|
|**2024-10-02**|**Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**|Yu Zhang et.al.|[2410.01401v1](http://arxiv.org/abs/2410.01401v1)|[link](https://github.com/EchoDreamer/Q-KGR)|
|**2024-10-02**|**CrowdCounter: A benchmark type-specific multi-target counterspeech dataset**|Punyajoy Saha et.al.|[2410.01400v1](http://arxiv.org/abs/2410.01400v1)|[link](https://github.com/hate-alert/crowdcounter)|
|**2024-10-02**|**Can We Delegate Learning to Automation?: A Comparative Study of LLM Chatbots, Search Engines, and Books**|Yeonsun Yang et.al.|[2410.01396v1](http://arxiv.org/abs/2410.01396v1)|null|
|**2024-10-02**|**FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated Learning Deployments**|Ioannis Mavromatis et.al.|[2410.01386v1](http://arxiv.org/abs/2410.01386v1)|null|
|**2024-10-02**|**PairDistill: Pairwise Relevance Distillation for Dense Retrieval**|Chao-Wei Huang et.al.|[2410.01383v1](http://arxiv.org/abs/2410.01383v1)|[link](https://github.com/miulab/pairdistill)|
|**2024-10-02**|**Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition**|Jiyeon Kim et.al.|[2410.01380v1](http://arxiv.org/abs/2410.01380v1)|null|
|**2024-10-02**|**PCQPR: Proactive Conversational Question Planning with Reflection**|Shasha Guo et.al.|[2410.01363v1](http://arxiv.org/abs/2410.01363v1)|null|
|**2024-10-02**|**Assisted Data Annotation for Business Process Information Extraction from Textual Documents**|Julian Neuberger et.al.|[2410.01356v1](http://arxiv.org/abs/2410.01356v1)|null|
|**2024-10-02**|**Takin-VC: Zero-shot Voice Conversion via Jointly Hybrid Content and Memory-Augmented Context-Aware Timbre Modeling**|Yuguang Yang et.al.|[2410.01350v1](http://arxiv.org/abs/2410.01350v1)|null|
|**2024-10-02**|**Life, uh, Finds a Way: Systematic Neural Search**|Alex Baranski et.al.|[2410.01349v1](http://arxiv.org/abs/2410.01349v1)|null|
|**2024-10-02**|**PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems**|Bocheng Zeng et.al.|[2410.01337v1](http://arxiv.org/abs/2410.01337v1)|null|

#### Abstracts
##### **Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking**
2410.01806v1 by Mattia Segu, Luigi Piccinelli, Siyuan Li, Yung-Hsu Yang, Bernt Schiele, Luc Van Gool

Multiple object tracking in complex scenarios - such as coordinated dance
performances, team sports, or dynamic animal groups - presents unique
challenges. In these settings, objects frequently move in coordinated patterns,
occlude each other, and exhibit long-term dependencies in their trajectories.
However, it remains a key open research question on how to model long-range
dependencies within tracklets, interdependencies among tracklets, and the
associated temporal occlusions. To this end, we introduce Samba, a novel
linear-time set-of-sequences model designed to jointly process multiple
tracklets by synchronizing the multiple selective state-spaces used to model
each tracklet. Samba autoregressively predicts the future track query for each
sequence while maintaining synchronized long-term memory representations across
tracklets. By integrating Samba into a tracking-by-propagation framework, we
propose SambaMOTR, the first tracker effectively addressing the aforementioned
issues, including long-range dependencies, tracklet interdependencies, and
temporal occlusions. Additionally, we introduce an effective technique for
dealing with uncertain observations (MaskObs) and an efficient training recipe
to scale SambaMOTR to longer sequences. By modeling long-range dependencies and
interactions among tracked objects, SambaMOTR implicitly learns to track
objects accurately through occlusions without any hand-crafted heuristics. Our
approach significantly surpasses prior state-of-the-art on the DanceTrack, BFT,
and SportsMOT datasets.

摘要：在複雜情境下追蹤多個物體，例如協調的舞蹈表演、團隊運動或動態動物群體，會帶來獨特挑戰。在這些設定中，物體經常以協調的模式移動、互相遮擋，並在其軌跡中展現長期依賴性。然而，如何對軌跡內的長程依賴性、軌跡間的相互依賴性，以及相關時間遮擋進行建模，仍是一個關鍵的開放研究問題。為此，我們引入了 Samba，這是一個新穎的線性時間序列集模型，旨在透過同步用於對每個軌跡建模的多個選擇性狀態空間，來聯合處理多個軌跡。Samba 自迴歸預測每個序列的未來軌跡查詢，同時在軌跡間維持同步的長期記憶表徵。透過將 Samba 整合到追蹤傳播架構中，我們提出了 SambaMOTR，這是第一個有效解決上述問題的追蹤器，包括長程依賴性、軌跡相互依賴性和時間遮擋。此外，我們引入了一種處理不確定觀察（MaskObs）的有效技術，以及一個有效率的訓練配方，以將 SambaMOTR 擴展到更長的序列。透過對追蹤物體間的長程依賴性和互動進行建模，SambaMOTR 隱含地學會在沒有任何人工啟發式的情況下，透過遮擋準確地追蹤物體。我們的做法在 DanceTrack、BFT 和 SportsMOT 資料集上顯著超越了先前的最先進技術。

##### **Locret: Enhancing Eviction in Long-Context LLM Inference with Trained Retaining Heads**
2410.01805v1 by Yuxiang Huang, Binhang Yuan, Xu Han, Chaojun Xiao, Zhiyuan Liu

Large language models (LLMs) have shown remarkable advances in supporting
long-context comprehension and processing tasks. However, scaling the
generation inference of LLMs to such long contexts incurs significant
additional computation load, and demands a substantial GPU memory footprint to
maintain the key-value (KV) cache of transformer-based LLMs. Existing KV cache
compression methods, such as quantization, face memory bottlenecks as context
length increases, while static-sized caches, such as eviction, suffer from
inefficient policies. These limitations restrict deployment on consumer-grade
devices like a single Nvidia 4090 GPU. To overcome this, we propose Locret, a
framework for long-context LLM inference that introduces retaining heads to
evaluate the causal importance of KV cache units, allowing for more accurate
eviction within a fixed cache size. Locret is fine-tuned on top of the frozen
backbone LLM using a minimal amount of data from standard long-context SFT
datasets. During inference, we evict low-importance cache units along with a
chunked prefill pattern, significantly reducing peak GPU memory usage. We
conduct an extensive empirical study to evaluate Locret, where the experimental
results show that Locret outperforms the recent competitive approaches,
including InfLLM, Quantization, SirLLM, and MInference, in terms of memory
efficiency and the quality of generated contents -- Locret achieves over a 20x
and 8x KV cache compression ratio compared to the full KV cache for
Phi-3-mini-128K and Llama-3.1-8B-instruct. Additionally, Locret can be combined
with other methods, such as quantization and token merging. To our knowledge,
Locret is the first framework capable of deploying Llama-3.1-8B or similar
models on a single Nvidia 4090 GPU, enabling 128K long-context inference
without compromising generation quality, and requiring little additional system
optimizations.

摘要：大型語言模型 (LLM) 在支援長語境理解和處理任務方面已展現出顯著進展。然而，將 LLM 的產生推論擴展到如此長的語境會造成顯著的額外運算負載，並需要大量的 GPU 記憶體空間來維護基於轉換器的 LLM 的鍵值 (KV) 快取。現有的 KV 快取壓縮方法（例如量化）會在語境長度增加時面臨記憶體瓶頸，而靜態大小的快取（例如驅逐）則有政策效率不佳的問題。這些限制會限制在消費者等級的裝置（例如單一的 Nvidia 4090 GPU）上部署。為了克服這個問題，我們提出 Locret，一個長語境 LLM 推論的架構，它引入了保留頭部來評估 KV 快取單元的因果重要性，允許在固定的快取大小內進行更精確的驅逐。Locret 在凍結的骨幹 LLM 上進行微調，使用來自標準長語境 SFT 資料集的少量資料。在推論期間，我們會驅逐低重要性的快取單元以及分塊預先填入模式，大幅降低 GPU 記憶體使用率的峰值。我們進行廣泛的實證研究來評估 Locret，實驗結果顯示 Locret 在記憶體效率和產生內容的品質方面優於最近的競爭方法，包括 InfLLM、量化、SirLLM 和 MInference -- 與 Phi-3-mini-128K 和 Llama-3.1-8B-instruct 的完整 KV 快取相比，Locret 達到了超過 20 倍和 8 倍的 KV 快取壓縮率。此外，Locret 可以與其他方法（例如量化和標記合併）結合使用。據我們所知，Locret 是第一個能夠在單一的 Nvidia 4090 GPU 上部署 Llama-3.1-8B 或類似模型的架構，能夠進行 128K 長語境推論而不影響產生品質，而且只需要很少的額外系統最佳化。

##### **FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments Generation from In-The-Wild Clothing Images**
2410.01801v1 by Cheng Zhang, Yuanhao Wang, Francisco Vicente Carrasco, Chenglei Wu, Jinlong Yang, Thabo Beeler, Fernando De la Torre

We introduce FabricDiffusion, a method for transferring fabric textures from
a single clothing image to 3D garments of arbitrary shapes. Existing approaches
typically synthesize textures on the garment surface through 2D-to-3D texture
mapping or depth-aware inpainting via generative models. Unfortunately, these
methods often struggle to capture and preserve texture details, particularly
due to challenging occlusions, distortions, or poses in the input image.
Inspired by the observation that in the fashion industry, most garments are
constructed by stitching sewing patterns with flat, repeatable textures, we
cast the task of clothing texture transfer as extracting distortion-free,
tileable texture materials that are subsequently mapped onto the UV space of
the garment. Building upon this insight, we train a denoising diffusion model
with a large-scale synthetic dataset to rectify distortions in the input
texture image. This process yields a flat texture map that enables a tight
coupling with existing Physically-Based Rendering (PBR) material generation
pipelines, allowing for realistic relighting of the garment under various
lighting conditions. We show that FabricDiffusion can transfer various features
from a single clothing image including texture patterns, material properties,
and detailed prints and logos. Extensive experiments demonstrate that our model
significantly outperforms state-to-the-art methods on both synthetic data and
real-world, in-the-wild clothing images while generalizing to unseen textures
and garment shapes.

摘要：<paragraph>我們介紹 FabricDiffusion，這是一種將布料紋理從單一服裝影像轉移到任意形狀的 3D 服裝的方法。現有的方法通常透過 2D 到 3D 紋理對應或使用生成模型進行深度感知修復來合成服裝表面的紋理。遺憾的是，這些方法通常難以擷取和保留紋理細節，特別是因為輸入影像中具有具挑戰性的遮擋、扭曲或姿勢。受到時尚產業中大多數服裝都是透過縫紉圖案與平坦、可重複的紋理進行拼接的觀察啟發，我們將服裝紋理轉移的任務設定為擷取無失真、可平鋪的紋理材質，並隨後將其對應到服裝的 UV 空間。基於此洞見，我們使用大型合成資料集訓練去噪擴散模型，以修正輸入紋理影像中的失真。此程序會產生平坦的紋理貼圖，可與現有的基於物理的渲染 (PBR) 材質產生管線緊密結合，並允許在各種光照條件下對服裝進行逼真的重新打光。我們展示 FabricDiffusion 可以從單一服裝影像轉移各種特徵，包括紋理圖案、材質屬性和詳細的印花和標誌。廣泛的實驗證明，我們的模型在合成資料和真實世界中的野生服裝影像上都顯著優於最先進的方法，同時還能推廣到未見過的紋理和服裝形狀。</paragraph>

##### **Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models**
2410.01795v1 by Joseph Lee, Shu Yang, Jae Young Baik, Xiaoxi Liu, Zhen Tan, Dawei Li, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Li Shen

Predicting phenotypes with complex genetic bases based on a small,
interpretable set of variant features remains a challenging task.
Conventionally, data-driven approaches are utilized for this task, yet the high
dimensional nature of genotype data makes the analysis and prediction
difficult. Motivated by the extensive knowledge encoded in pre-trained LLMs and
their success in processing complex biomedical concepts, we set to examine the
ability of LLMs in feature selection and engineering for tabular genotype data,
with a novel knowledge-driven framework. We develop FREEFORM, Free-flow
Reasoning and Ensembling for Enhanced Feature Output and Robust Modeling,
designed with chain-of-thought and ensembling principles, to select and
engineer features with the intrinsic knowledge of LLMs. Evaluated on two
distinct genotype-phenotype datasets, genetic ancestry and hereditary hearing
loss, we find this framework outperforms several data-driven methods,
particularly on low-shot regimes. FREEFORM is available as open-source
framework at GitHub: https://github.com/PennShenLab/FREEFORM.

摘要：利用一組小型可解讀的變異特徵來預測具有複雜遺傳基礎的表型，仍然是一項具有挑戰性的任務。
傳統上，資料驅動方法被用於此任務，但基因型資料的高維度特性使得分析和預測變得困難。
受預訓練 LLM 中編碼的廣泛知識及其在處理複雜生物醫學概念方面所取得的成功所激勵，我們著手檢驗 LLM 在表格基因型資料的特徵選擇和工程中的能力，並採用一種新穎的知識驅動框架。
我們開發了 FREEFORM（自由流動推理和集成，用於增強特徵輸出和穩健建模），它採用思維鏈和集成原則進行設計，以利用 LLM 的內在知識來選擇和設計特徵。
在兩個不同的基因型-表型資料集（遺傳祖先和遺傳性聽力喪失）上進行評估，我們發現此框架優於幾種資料驅動方法，特別是在低次拍攝模式上。FREEFORM 可作為開源框架在 GitHub 上獲得：https://github.com/PennShenLab/FREEFORM。

##### **When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1**
2410.01792v1 by R. Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths

In "Embers of Autoregression" (McCoy et al., 2023), we showed that several
large language models (LLMs) have some important limitations that are
attributable to their origins in next-word prediction. Here we investigate
whether these issues persist with o1, a new system from OpenAI that differs
from previous LLMs in that it is optimized for reasoning. We find that o1
substantially outperforms previous LLMs in many cases, with particularly large
improvements on rare variants of common tasks (e.g., forming acronyms from the
second letter of each word in a list, rather than the first letter). Despite
these quantitative improvements, however, o1 still displays the same
qualitative trends that we observed in previous systems. Specifically, o1 -
like previous LLMs - is sensitive to the probability of examples and tasks,
performing better and requiring fewer "thinking tokens" in high-probability
settings than in low-probability ones. These results show that optimizing a
language model for reasoning can mitigate but might not fully overcome the
language model's probability sensitivity.

摘要：在「自迴歸的餘燼」（McCoy 等人，2023 年）中，我們展示了幾個大型語言模型（LLM）有一些重要的限制，這些限制可歸因於它們源自下一個單字預測。在此，我們探討這些問題是否持續存在於 o1，這是 OpenAI 的一個新系統，它與先前的 LLM 不同，因為它針對推理進行了最佳化。我們發現，在許多情況下，o1 都大幅優於先前的 LLM，特別是在常見任務的罕見變體上有了大幅進步（例如，根據清單中每個單字的第二個字母組成縮寫，而不是第一個字母）。然而，儘管有這些定量的改進，o1 仍然顯示出我們在先前的系統中觀察到的相同定性趨勢。具體來說，o1 - 與先前的 LLM 一樣 - 對範例和任務的機率很敏感，在高機率設定中比在低機率設定中表現得更好，而且需要的「思考符號」更少。這些結果顯示，針對推理最佳化語言模型可以減輕語言模型的機率敏感性，但可能無法完全克服它。

##### **DreamGarden: A Designer Assistant for Growing Games from a Single Prompt**
2410.01791v1 by Sam Earle, Samyak Parajuli, Andrzej Banburski-Fahey

Coding assistants are increasingly leveraged in game design, both generating
code and making high-level plans. To what degree can these tools align with
developer workflows, and what new modes of human-computer interaction can
emerge from their use? We present DreamGarden, an AI system capable of
assisting with the development of diverse game environments in Unreal Engine.
At the core of our method is an LLM-driven planner, capable of breaking down a
single, high-level prompt -- a dream, memory, or imagined scenario provided by
a human user -- into a hierarchical action plan, which is then distributed
across specialized submodules facilitating concrete implementation. This system
is presented to the user as a garden of plans and actions, both growing
independently and responding to user intervention via seed prompts, pruning,
and feedback. Through a user study, we explore design implications of this
system, charting courses for future work in semi-autonomous assistants and
open-ended simulation design.

摘要：遊戲設計中越來越常使用編碼助理，用於產生程式碼和制定高階計畫。這些工具能與開發人員的工作流程在何種程度上保持一致，以及它們的使用能產生哪些新的電腦與人互動模式？我們提出 DreamGarden，這是一個 AI 系統，能夠協助在虛幻引擎中開發多樣的遊戲環境。我們的方法核心是一個由 LLM 驅動的規劃器，能夠將單一的高階提示（由人類使用者提供的夢想、記憶或想像場景）分解為階層式行動計畫，然後將其分配給促成具體實作的專門子模組。此系統以計畫和行動的花園呈現給使用者，它們會獨立生長，並透過種子提示、修剪和回饋對使用者的介入做出回應。我們透過使用者研究探討此系統的設計意涵，為半自主助理和開放式模擬設計的未來工作繪製路線圖。

##### **Investigating on RLHF methodology**
2410.01789v1 by Alexey Kutalev, Sergei Markoff

In this article, we investigate the alignment of Large Language Models
according to human preferences. We discuss the features of training a
Preference Model, which simulates human preferences, and the methods and
details we found essential for achieving the best results. We also discuss
using Reinforcement Learning to fine-tune Large Language Models and describe
the challenges we faced and the ways to overcome them. Additionally, we present
our experience with the Direct Preference Optimization method, which enables us
to align a Large Language Model with human preferences without creating a
separate Preference Model. As our contribution, we introduce the approach for
collecting a preference dataset through perplexity filtering, which makes the
process of creating such a dataset for a specific Language Model much easier
and more cost-effective.

摘要：在這篇文章中，我們根據人類喜好來探討大型語言模型的調整。我們討論了訓練偏好模型的特徵，這種模型模擬人類偏好，以及我們發現對達成最佳結果至關重要的方法和細節。我們也討論了使用強化學習來微調大型語言模型，並說明我們面臨的挑戰以及克服這些挑戰的方法。此外，我們展示了我們使用直接偏好最佳化方法的經驗，這使我們能夠將大型語言模型與人類偏好調整一致，而無需建立一個獨立的偏好模型。作為我們的貢獻，我們介紹了透過困惑度過濾來收集偏好資料集的方法，這使得為特定語言模型建立此類資料集的過程變得容易許多，而且更具成本效益。

##### **OmniGenBench: Automating Large-scale in-silico Benchmarking for Genomic Foundation Models**
2410.01784v1 by Heng Yang, Jack Cole, Ke Li

The advancements in artificial intelligence in recent years, such as Large
Language Models (LLMs), have fueled expectations for breakthroughs in genomic
foundation models (GFMs). The code of nature, hidden in diverse genomes since
the very beginning of life's evolution, holds immense potential for impacting
humans and ecosystems through genome modeling. Recent breakthroughs in GFMs,
such as Evo, have attracted significant investment and attention to genomic
modeling, as they address long-standing challenges and transform in-silico
genomic studies into automated, reliable, and efficient paradigms. In the
context of this flourishing era of consecutive technological revolutions in
genomics, GFM studies face two major challenges: the lack of GFM benchmarking
tools and the absence of open-source software for diverse genomics. These
challenges hinder the rapid evolution of GFMs and their wide application in
tasks such as understanding and synthesizing genomes, problems that have
persisted for decades. To address these challenges, we introduce GFMBench, a
framework dedicated to GFM-oriented benchmarking. GFMBench standardizes
benchmark suites and automates benchmarking for a wide range of open-source
GFMs. It integrates millions of genomic sequences across hundreds of genomic
tasks from four large-scale benchmarks, democratizing GFMs for a wide range of
in-silico genomic applications. Additionally, GFMBench is released as
open-source software, offering user-friendly interfaces and diverse tutorials,
applicable for AutoBench and complex tasks like RNA design and structure
prediction. To facilitate further advancements in genome modeling, we have
launched a public leaderboard showcasing the benchmark performance derived from
AutoBench. GFMBench represents a step toward standardizing GFM benchmarking and
democratizing GFM applications.

摘要：<paragraph>近年來人工智能的進展，例如大型語言模型 (LLM)，為基因組基礎模型 (GFM) 的突破性發展帶來了期待。自生命演化一開始，隱藏在多樣基因組中的自然密碼，蘊藏著透過基因組建模影響人類和生態系統的巨大潛力。GFM 的最新突破，例如 Evo，吸引了大量投資和關注，因為它們解決了長期的挑戰，並將電腦模擬基因組研究轉變為自動化、可靠且有效率的範例。在基因組學中連續技術革命蓬勃發展的時代背景下，GFM 研究面臨兩大挑戰：缺乏 GFM 基準測試工具，以及缺乏適用於多樣基因組的開源軟體。這些挑戰阻礙了 GFM 的快速演進，以及它們在了解和合成基因組等任務中的廣泛應用，這些問題已經持續數十年。為了應對這些挑戰，我們推出了 GFMBench，一個專門用於 GFM 導向基準測試的框架。GFMBench 標準化了基準測試套件，並自動化了各種開源 GFM 的基準測試。它整合了來自四個大型基準測試的數百個基因組任務中的數百萬個基因組序列，讓 GFM 民主化，適用於各種電腦模擬基因組應用。此外，GFMBench 以開源軟體的形式發布，提供使用者友善的介面和多樣化的教學課程，適用於 AutoBench 和 RNA 設計與結構預測等複雜任務。為了促進基因組建模的進一步發展，我們建立了一個公開排行榜，展示源自 AutoBench 的基準測試效能。GFMBench 代表了標準化 GFM 基準測試和民主化 GFM 應用邁出的一步。</paragraph>

##### **Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models**
2410.01782v1 by Shayekh Bin Islam, Md Asib Rahman, K S M Tozammel Hossain, Enamul Hoque, Shafiq Joty, Md Rizwan Parvez

Retrieval-Augmented Generation (RAG) has been shown to enhance the factual
accuracy of Large Language Models (LLMs), but existing methods often suffer
from limited reasoning capabilities in effectively using the retrieved
evidence, particularly when using open-source LLMs. To mitigate this gap, we
introduce a novel framework, Open-RAG, designed to enhance reasoning
capabilities in RAG with open-source LLMs. Our framework transforms an
arbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE)
model capable of handling complex reasoning tasks, including both single- and
multi-hop queries. Open-RAG uniquely trains the model to navigate challenging
distractors that appear relevant but are misleading. As a result, Open-RAG
leverages latent learning, dynamically selecting relevant experts and
integrating external knowledge effectively for more accurate and contextually
relevant responses. In addition, we propose a hybrid adaptive retrieval method
to determine retrieval necessity and balance the trade-off between performance
gain and inference speed. Experimental results show that the Llama2-7B-based
Open-RAG outperforms state-of-the-art LLMs and RAG models such as ChatGPT,
Self-RAG, and Command R+ in various knowledge-intensive tasks. We open-source
our code and models at https://openragmoe.github.io/

摘要：檢索增強式生成 (RAG) 已被證明可以增強大型語言模型 (LLM) 的事實準確性，但現有方法通常在有效使用檢索證據方面推理能力有限，特別是在使用開源 LLM 時。為了彌補這個差距，我們引入了一個新框架 Open-RAG，旨在增強開源 LLM 中 RAG 的推理能力。我們的框架將任意稠密 LLM 轉換為參數高效的稀疏專家混合 (MoE) 模型，能夠處理複雜的推理任務，包括單跳和多跳查詢。Open-RAG 獨特地訓練模型以應對看似相關但具有誤導性的具有挑戰性的干擾因素。因此，Open-RAG 利用潛在學習，動態選擇相關專家並有效整合外部知識，以獲得更準確和與上下文相關的回應。此外，我們提出了一種混合自適應檢索方法，以確定檢索必要性並平衡性能增益與推理速度之間的權衡。實驗結果表明，基於 Llama2-7B 的 Open-RAG 在各種知識密集型任務中優於最先進的 LLM 和 RAG 模型，例如 ChatGPT、Self-RAG 和 Command R+。我們在 https://openragmoe.github.io/ 開源我們的代碼和模型。

##### **DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**
2410.01772v1 by Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu

LLMs are ideal for decision-making due to their ability to reason over long
contexts and identify critical factors. However, challenges arise when
processing transcripts of spoken speech describing complex scenarios. These
transcripts often contain ungrammatical or incomplete sentences, repetitions,
hedging, and vagueness. For example, during a company's earnings call, an
executive might project a positive revenue outlook to reassure investors,
despite significant uncertainty regarding future earnings. It is crucial for
LLMs to incorporate this uncertainty systematically when making decisions. In
this paper, we introduce DeFine, a new framework that constructs probabilistic
factor profiles from complex scenarios. DeFine then integrates these profiles
with analogical reasoning, leveraging insights from similar past experiences to
guide LLMs in making critical decisions in novel situations. Our framework
separates the tasks of quantifying uncertainty in complex scenarios and
incorporating it into LLM decision-making. This approach is particularly useful
in fields such as medical consultations, negotiations, and political debates,
where making decisions under uncertainty is vital.

摘要：LLM 非常適合用於決策制定，因為它們能夠對長篇脈絡進行推理並找出關鍵因素。然而，在處理描述複雜場景的口語轉錄時會產生挑戰。這些轉錄通常包含不符合文法或不完整的句子、重複、迴避和模糊。例如，在公司的收益電話會議中，一位主管可能會預測正面的收益前景以安撫投資人，儘管對未來的收益有很大的不確定性。對於 LLM 來說，在做決策時系統性地納入這種不確定性至關重要。在本文中，我們介紹了 DeFine，一個從複雜場景構建機率因子輪廓的新架構。然後，DeFine 將這些輪廓與類比推理整合，利用過去類似經驗中的見解來引導 LLM 在新情況中做出關鍵決策。我們的架構將量化複雜場景中的不確定性以及將其納入 LLM 決策制定的任務分開。這種方法在醫療諮詢、談判和政治辯論等領域特別有用，在這些領域中，在不確定性下做出決策至關重要。

##### **Quantifying Generalization Complexity for Large Language Models**
2410.01769v1 by Zhenting Qi, Hongyin Luo, Xuliang Huang, Zhuokai Zhao, Yibo Jiang, Xiangjun Fan, Himabindu Lakkaraju, James Glass

While large language models (LLMs) have shown exceptional capabilities in
understanding complex queries and performing sophisticated tasks, their
generalization abilities are often deeply entangled with memorization,
necessitating more precise evaluation. To address this challenge, we introduce
Scylla, a dynamic evaluation framework that quantitatively measures the
generalization abilities of LLMs. Scylla disentangles generalization from
memorization via assessing model performance on both in-distribution (ID) and
out-of-distribution (OOD) data through 20 tasks across 5 levels of complexity.
Through extensive experiments, we uncover a non-monotonic relationship between
task complexity and the performance gap between ID and OOD data, which we term
the generalization valley. Specifically, this phenomenon reveals a critical
threshold - referred to as critical complexity - where reliance on
non-generalizable behavior peaks, indicating the upper bound of LLMs'
generalization capabilities. As model size increases, the critical complexity
shifts toward higher levels of task complexity, suggesting that larger models
can handle more complex reasoning tasks before over-relying on memorization.
Leveraging Scylla and the concept of critical complexity, we benchmark 28LLMs
including both open-sourced models such as LLaMA and Qwen families, and
close-sourced models like Claude and GPT, providing a more robust evaluation
and establishing a clearer understanding of LLMs' generalization capabilities.

摘要：<paragraph>儘管大型語言模型 (LLM) 在理解複雜查詢和執行精密任務方面展現出非凡的能力，但它們的概化能力通常與記憶力深度糾纏，需要更精確的評估。為了應對這項挑戰，我們引入了 Scylla，一個動態評估架構，用於量化測量 LLM 的概化能力。Scylla 透過評估模型在分佈內 (ID) 和分佈外 (OOD) 資料上的效能，透過 5 個複雜度層級的 20 項任務，將概化能力從記憶力中解開。透過廣泛的實驗，我們發現任務複雜度和 ID 與 OOD 資料之間的效能差距存在非單調關係，我們稱之為概化谷。具體來說，此現象揭示了一個臨界閾值，稱為臨界複雜度，在該閾值下對不可概化的行為的依賴達到高峰，表示 LLM 概化能力的上限。隨著模型規模的增加，臨界複雜度會轉移到更高的任務複雜度層級，這表明在過度依賴記憶力之前，較大的模型可以處理更複雜的推理任務。利用 Scylla 和臨界複雜度的概念，我們對 28 個 LLM 進行了基準測試，包括開放原始碼模型（例如 LLaMA 和 Qwen 家族）和封閉原始碼模型（例如 Claude 和 GPT），提供更強健的評估，並建立對 LLM 概化能力的更清晰理解。</paragraph>

##### **LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks**
2410.01744v1 by Mengzhao Jia, Wenhao Yu, Kaixin Ma, Tianqing Fang, Zhihan Zhang, Siru Ouyang, Hongming Zhang, Meng Jiang, Dong Yu

Text-rich images, where text serves as the central visual element guiding the
overall understanding, are prevalent in real-world applications, such as
presentation slides, scanned documents, and webpage snapshots. Tasks involving
multiple text-rich images are especially challenging, as they require not only
understanding the content of individual images but reasoning about
inter-relationships and logical flows across multiple visual inputs. Despite
the importance of these scenarios, current multimodal large language models
(MLLMs) struggle to handle such tasks due to two key challenges: (1) the
scarcity of high-quality instruction tuning datasets for text-rich multi-image
scenarios, and (2) the difficulty in balancing image resolution with visual
feature sequence length. To address these challenges, we propose \OurMethod, a
MLLM designed specifically for handling vision-language tasks involving
multiple text-rich images. First, we curated about one million high-quality
multimodal instruction-tuning data, tailored to text-rich, multi-image
scenarios. Second, we developed an adaptive high-resolution multi-image
encoding module to dynamically optimize the allocation of visual sequence
length based on the original aspect ratios and resolutions of the input images.
Experiments across a wide range of benchmarks demonstrate our model's superior
capabilities in text-rich, multi-image evaluations and competitive performance
in general domain evaluations.

摘要：文字豐富的影像，其中文字作為引導整體理解的中心視覺元素，在真實世界的應用中很常見，例如簡報投影片、掃描文件和網頁截圖。涉及多個文字豐富影像的任務特別具有挑戰性，因為它們不僅需要理解個別影像的內容，還要推理跨多個視覺輸入的相互關係和邏輯流程。儘管這些情境很重要，但目前的模態大型語言模型 (MLLM) 由於兩個主要挑戰而難以處理此類任務：(1) 針對文字豐富的多影像情境的高品質指令調整資料集的稀缺性，以及 (2) 平衡影像解析度與視覺特徵序列長度的難度。為了應對這些挑戰，我們提出了 \OurMethod，一種專門設計用於處理涉及多個文字豐富影像的視覺語言任務的 MLLM。首先，我們策劃了約一百萬筆高品質的多模態指令調整資料，針對文字豐富的多影像情境量身打造。其次，我們開發了一個適應性高解析度多影像編碼模組，以根據輸入影像的原始長寬比和解析度動態最佳化視覺序列長度的配置。在廣泛的基準測試中的實驗證明了我們的模型在文字豐富的多影像評估中具有優異的能力，並且在一般領域評估中具有競爭力的效能。

##### **Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning**
2410.01739v1 by Xingrui Gu, Guanren Qiao, Chuyi Jiang, Tianqing Xia, Hangyu Mao

Reinforcement learning encounters challenges in various environments related
to robustness and explainability. Traditional Q-learning algorithms cannot
effectively make decisions and utilize the historical learning experience. To
overcome these limitations, we propose Cognitive Belief-Driven Q-Learning
(CBDQ), which integrates subjective belief modeling into the Q-learning
framework, enhancing decision-making accuracy by endowing agents with
human-like learning and reasoning capabilities. Drawing inspiration from
cognitive science, our method maintains a subjective belief distribution over
the expectation of actions, leveraging a cluster-based subjective belief model
that enables agents to reason about the potential probability associated with
each decision. CBDQ effectively mitigates overestimated phenomena and optimizes
decision-making policies by integrating historical experiences with current
contextual information, mimicking the dynamics of human decision-making. We
evaluate the proposed method on discrete control benchmark tasks in various
complicate environments. The results demonstrate that CBDQ exhibits stronger
adaptability, robustness, and human-like characteristics in handling these
environments, outperforming other baselines. We hope this work will give
researchers a fresh perspective on understanding and explaining Q-learning.

摘要：強化學習在各種與穩健性和可解釋性相關的環境中遇到挑戰。傳統的 Q 學習演算法無法有效做出決策並利用歷史學習經驗。為了克服這些限制，我們提出了認知信念驅動的 Q 學習 (CBDQ)，它將主觀信念建模整合到 Q 學習架構中，透過賦予代理人類似人類的學習和推理能力來增強決策制定準確性。我們的模型從認知科學中汲取靈感，在動作預期上維持主觀信念分佈，利用基於群集的主觀信念模型，讓代理人能夠推理與每個決策相關的潛在機率。CBDQ 有效減輕高估現象，並透過將歷史經驗與當前背景資訊整合，最佳化決策制定政策，模擬人類決策制定的動態。我們在各種複雜環境中的離散控制基準任務上評估所提出的方法。結果表明，CBDQ 在處理這些環境時展現出更強的適應性、穩健性和類人特徵，優於其他基準。我們希望這項工作將為研究人員提供一個新的觀點，以理解和解釋 Q 學習。

##### **VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models**
2410.01738v1 by Kailai Feng, Yabo Zhang, Haodong Yu, Zhilong Ji, Jinfeng Bai, Hongzhi Zhang, Wangmeng Zuo

Artistic typography is a technique to visualize the meaning of input
character in an imaginable and readable manner. With powerful text-to-image
diffusion models, existing methods directly design the overall geometry and
texture of input character, making it challenging to ensure both creativity and
legibility. In this paper, we introduce a dual-branch and training-free method,
namely VitaGlyph, enabling flexible artistic typography along with controllable
geometry change to maintain the readability. The key insight of VitaGlyph is to
treat input character as a scene composed of Subject and Surrounding, followed
by rendering them under varying degrees of geometry transformation. The subject
flexibly expresses the essential concept of input character, while the
surrounding enriches relevant background without altering the shape.
Specifically, we implement VitaGlyph through a three-phase framework: (i)
Knowledge Acquisition leverages large language models to design text
descriptions of subject and surrounding. (ii) Regional decomposition detects
the part that most matches the subject description and divides input glyph
image into subject and surrounding regions. (iii) Typography Stylization
firstly refines the structure of subject region via Semantic Typography, and
then separately renders the textures of Subject and Surrounding regions through
Controllable Compositional Generation. Experimental results demonstrate that
VitaGlyph not only achieves better artistry and readability, but also manages
to depict multiple customize concepts, facilitating more creative and pleasing
artistic typography generation. Our code will be made publicly at
https://github.com/Carlofkl/VitaGlyph.

摘要：藝術字體排印是一種以可想像且可讀的方式視覺化輸入字元含義的技術。使用強大的文字轉圖像擴散模型，現有方法直接設計輸入字元的整體幾何形狀和紋理，這使得確保同時具備創意性和可讀性具有挑戰性。在本文中，我們介紹了一種雙分支且無需訓練的方法，即 VitaGlyph，它能實現靈活的藝術字體排印以及可控的幾何形狀變化，以保持可讀性。VitaGlyph 的關鍵見解是將輸入字元視為由主體和周圍環境組成的場景，然後在不同程度的幾何變換下渲染它們。主體靈活地表達輸入字元的本質概念，而周圍環境豐富了相關背景，而不會改變形狀。具體來說，我們通過一個三階段框架實現 VitaGlyph：(i) 知識獲取利用大型語言模型來設計主體和周圍環境的文字描述。(ii) 區域分解檢測最符合主體描述的部分，並將輸入字形圖像分為主體和周圍區域。(iii) 字體造型首先通過語義字體排印優化主體區域的結構，然後通過可控組合生成分別渲染主體和周圍區域的紋理。實驗結果表明，VitaGlyph 不僅實現了更好的藝術性和可讀性，而且還能描繪多個自定義概念，從而促進更具創意性和令人愉悅的藝術字體排印生成。我們的代碼將在 https://github.com/Carlofkl/VitaGlyph 公開。

##### **Recursive Abstractive Processing for Retrieval in Dynamic Datasets**
2410.01736v1 by Charbel Chucri, Rami Azouz, Joachim Ott

Recent retrieval-augmented models enhance basic methods by building a
hierarchical structure over retrieved text chunks through recursive embedding,
clustering, and summarization. The most relevant information is then retrieved
from both the original text and generated summaries. However, such approaches
face limitations with dynamic datasets, where adding or removing documents over
time complicates the updating of hierarchical representations formed through
clustering. We propose a new algorithm to efficiently maintain the
recursive-abstractive tree structure in dynamic datasets, without compromising
performance. Additionally, we introduce a novel post-retrieval method that
applies query-focused recursive abstractive processing to substantially improve
context quality. Our method overcomes the limitations of other approaches by
functioning as a black-box post-retrieval layer compatible with any retrieval
algorithm. Both algorithms are validated through extensive experiments on
real-world datasets, demonstrating their effectiveness in handling dynamic data
and improving retrieval performance.

摘要：近期检索增强模型藉由递归嵌入、分群和摘要，在检索文本块上构建分层结构，以增强基本方法。然后从原始文本和生成的摘要中检索最相关的资讯。然而，此类方法在动态资料集上会遇到限制，因为随着时间推移，新增或移除文件会使通过分群形成的分层表示更新变得复杂。我们提出一种新的演算法，在不影响效能的情况下，有效维护动态资料集中的递归抽象树状结构。此外，我们引入一种新的检索后方法，应用以查询为重点的递归抽象处理，以大幅提升内容品质。我们的方法藉由作为与任何检索演算法相容的黑盒检索后层，克服了其他方法的限制。两种演算法皆通过在真实世界资料集上进行广泛的实验验证，证明了它们在处理动态资料和提升检索效能方面的有效性。

##### **LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits**
2410.01735v1 by Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal

Reward Models (RMs) play a crucial role in aligning LLMs with human
preferences, enhancing their performance by ranking outputs during inference or
iterative training. However, the degree to which an RM generalizes to new tasks
is often not known a priori (e.g. some RMs may excel at scoring creative
writing vs. math reasoning). Therefore, using only one fixed RM while training
LLMs can be suboptimal. Moreover, optimizing LLMs with multiple RMs
simultaneously can be prohibitively computationally-intensive and challenging
due to conflicting signals from different RMs, potentially degrading
performance. To address these challenges, we introduce LASeR (Learning to
Adaptively Select Rewards), which iteratively trains LLMs using multiple RMs,
selecting and utilizing the most well-suited RM for each instance to rank
outputs and generate preference data, framed as a multi-armed bandit problem.
Our results on commonsense and math reasoning tasks demonstrate that LASeR can
boost iterative LLM optimization by optimizing for multiple RMs, improving the
absolute average accuracy of Llama-3-8B over three datasets by 2.67% over
training with ensemble RM scores while also showing superior training
efficiency (e.g., a 2x speedup). Moreover, on WildChat, a benchmark of
instruction-following prompts, we find that using Llama-3-8B LASeR leads to a
71.45% AlpacaEval win rate over sequentially optimizing multiple RMs. Extending
to long-context generation tasks, we find that on Llama-3-8B, LASeR achieves an
average improvement of 2.64 F1 and 2.42 F1 on single- and multi-document QA
over random RM selection when used with best-of-n sampling. LASeR is robust to
noisy rewards and generalizes to multiple settings. Finally, LASeR's RM
selection changes depending on the underlying task or instance and we verify
the presence of conflicting preferences from multiple RMs that can be mitigated
using LASeR.

摘要：獎勵模型 (RM) 在將 LLM 與人類偏好對齊方面發揮著至關重要的作用，通過在推理或迭代訓練期間對輸出進行排名來增強其性能。然而，RM 對新任務的概括程度通常無法事先得知（例如，某些 RM 可能擅長評分創意寫作，而另一些則擅長數學推理）。因此，在訓練 LLM 時僅使用一個固定的 RM 可能是次優的。此外，由於來自不同 RM 的信號相互衝突，同時使用多個 RM 來優化 LLM 在計算上可能是非常耗時的，並且具有挑戰性，這可能會降低性能。為了應對這些挑戰，我們引入了 LASeR（自適應選擇獎勵學習），它使用多個 RM 迭代訓練 LLM，為每個實例選擇和利用最合適的 RM 來對輸出進行排名並生成偏好數據，這被視為一個多臂老虎機問題。我們在常識和數學推理任務上的結果表明，LASeR 可以通過針對多個 RM 進行優化來提升迭代 LLM 優化，通過使用整體 RM 分數進行訓練，將 Llama-3-8B 在三個數據集上的絕對平均準確度提高了 2.67%，同時還展示了出色的訓練效率（例如，加速 2 倍）。此外，在 WildChat（一個基於指令的提示基準）上，我們發現使用 Llama-3-8B LASeR 可以獲得 71.45% 的 AlpacaEval 獲勝率，而後者則通過對多個 RM 進行順序優化來實現。擴展到長上下文生成任務，我們發現，在 Llama-3-8B 上，與使用最佳 n 採樣時隨機 RM 選擇相比，LASeR 在單文檔和多文檔 QA 上分別實現了 2.64 F1 和 2.42 F1 的平均改進。LASeR 對有噪聲的獎勵具有魯棒性，並且可以概括到多種設置。最後，LASeR 的 RM 選擇會根據底層任務或實例而改變，我們驗證了來自多個 RM 的衝突偏好的存在，而這些偏好可以使用 LASeR 來緩解。

##### **Visual Perception in Text Strings**
2410.01733v1 by Qi Jia, Xiang Yue, Shanshan Huang, Ziheng Qin, Yizhu Liu, Bill Yuchen Lin, Yang You

Understanding visual semantics embedded in consecutive characters is a
crucial capability for both large language models (LLMs) and multi-modal large
language models (MLLMs). This type of artifact possesses the unique
characteristic that identical information can be readily formulated in both
texts and images, making them a significant proxy for analyzing modern LLMs'
and MLLMs' capabilities in modality-agnostic vision understanding. In this
work, we select ASCII art as a representative artifact, where the lines and
brightness used to depict each concept are rendered by characters, and we frame
the problem as an ASCII art recognition task. We benchmark model performance on
this task by constructing an evaluation dataset with an elaborate
categorization tree and also collect a training set to elicit the models'
visual perception ability. Through a comprehensive analysis of dozens of
models, results reveal that although humans can achieve nearly 100% accuracy,
the state-of-the-art LLMs and MLLMs lag far behind. Models are capable of
recognizing concepts depicted in the ASCII arts given only text inputs
indicated by over 60% accuracy for some concepts, but most of them achieves
merely around 30% accuracy when averaged across all categories. When provided
with images as inputs, GPT-4o gets 82.68%, outperforming the strongest
open-source MLLM by 21.95%. Although models favor different kinds of ASCII art
depending on the modality provided, none of the MLLMs successfully benefit when
both modalities are supplied simultaneously. Moreover, supervised fine-tuning
helps improve models' accuracy especially when provided with the image
modality, but also highlights the need for better training techniques to
enhance the information fusion among modalities.

摘要：<paragraph>理解連續字元中內含的視覺語意，是大型語言模型 (LLM) 和多模態大型語言模型 (MLLM) 的一項關鍵能力。這類人工製品具備一個獨特特性，即相同的資訊可以輕易地以文字和影像的形式表達，讓它們成為分析現代 LLM 和 MLLM 在與模態無關的視覺理解方面的能力的重要代理。在此研究中，我們選擇 ASCII 藝術作為代表性人工製品，其中用於描繪每個概念的線條和亮度都是由字元渲染的，我們將問題界定為 ASCII 藝術辨識任務。我們透過建構一個具有詳細分類樹的評估資料集，對此任務中的模型效能進行基準測試，並收集一個訓練集以引出模型的視覺感知能力。透過對數十個模型進行全面分析，結果顯示，儘管人類可以達到近 100% 的準確度，但最先進的 LLM 和 MLLM 仍遠遠落後。模型能夠辨識 ASCII 藝術中描繪的概念，僅給予文字輸入，某些概念的準確度超過 60%，但大多數模型在所有類別的平均準確度僅約 30%。當提供影像作為輸入時，GPT-4o 獲得 82.68%，比最強的開源 MLLM 高出 21.95%。儘管模型偏好不同類型的 ASCII 藝術，具體取決於提供的模態，但當同時提供兩種模態時，沒有任何 MLLM 成功受益。此外，監督微調有助於提高模型的準確度，尤其是在提供影像模態時，但也突顯了需要更好的訓練技術來增強模態之間的資訊融合。</paragraph>

##### **ComfyGen: Prompt-Adaptive Workflows for Text-to-Image Generation**
2410.01731v1 by Rinon Gal, Adi Haviv, Yuval Alaluf, Amit H. Bermano, Daniel Cohen-Or, Gal Chechik

The practical use of text-to-image generation has evolved from simple,
monolithic models to complex workflows that combine multiple specialized
components. While workflow-based approaches can lead to improved image quality,
crafting effective workflows requires significant expertise, owing to the large
number of available components, their complex inter-dependence, and their
dependence on the generation prompt. Here, we introduce the novel task of
prompt-adaptive workflow generation, where the goal is to automatically tailor
a workflow to each user prompt. We propose two LLM-based approaches to tackle
this task: a tuning-based method that learns from user-preference data, and a
training-free method that uses the LLM to select existing flows. Both
approaches lead to improved image quality when compared to monolithic models or
generic, prompt-independent workflows. Our work shows that prompt-dependent
flow prediction offers a new pathway to improving text-to-image generation
quality, complementing existing research directions in the field.

摘要：文字轉圖像生成的實際應用已從簡單的、單一模型演變為結合多種專業組成的複雜工作流程。雖然基於工作流程的方法可以提升影像品質，但製作有效的工作流程需要大量的專業知識，因為有大量的可用元件、其複雜的相互依賴性，以及它們對生成提示的依賴性。在這裡，我們介紹提示適應工作流程生成的全新任務，目標是自動為每個使用者提示量身打造工作流程。我們提出兩種基於 LLM 的方法來解決此任務：一種從使用者偏好資料中學習的基於調整的方法，以及一種使用 LLM 來選擇現有流程的免訓練方法。與單一模型或通用、與提示無關的工作流程相比，這兩種方法都可以提升影像品質。我們的研究顯示，提示依賴的流程預測提供了一條提升文字轉圖像生成品質的新途徑，補充了該領域現有的研究方向。

##### **Evaluating Robustness of Reward Models for Mathematical Reasoning**
2410.01729v1 by Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Jungsoo Won, Dongha Lee, Jinyoung Yeo

Reward models are key in reinforcement learning from human feedback (RLHF)
systems, aligning the model behavior with human preferences. Particularly in
the math domain, there have been plenty of studies using reward models to align
policies for improving reasoning capabilities. Recently, as the importance of
reward models has been emphasized, RewardBench is proposed to understand their
behavior. However, we figure out that the math subset of RewardBench has
different representations between chosen and rejected completions, and relies
on a single comparison, which may lead to unreliable results as it only see an
isolated case. Therefore, it fails to accurately present the robustness of
reward models, leading to a misunderstanding of its performance and potentially
resulting in reward hacking. In this work, we introduce a new design for
reliable evaluation of reward models, and to validate this, we construct
RewardMATH, a benchmark that effectively represents the robustness of reward
models in mathematical reasoning tasks. We demonstrate that the scores on
RewardMATH strongly correlate with the results of optimized policy and
effectively estimate reward overoptimization, whereas the existing benchmark
shows almost no correlation. The results underscore the potential of our design
to enhance the reliability of evaluation, and represent the robustness of
reward model. We make our code and data publicly available.

摘要：獎勵模型在人類回饋（RLHF）系統的強化學習中是關鍵，使模型行為與人類偏好保持一致。特別是在數學領域，已經有許多研究使用獎勵模型來調整政策以提高推理能力。最近，隨著獎勵模型的重要性被強調，RewardBench 被提出用於了解其行為。然而，我們發現 RewardBench 的數學子集在選擇和拒絕的完成之間有不同的表示，並且依賴於單一比較，這可能會導致不可靠的結果，因為它只看到一個孤立的案例。因此，它無法準確地呈現獎勵模型的穩健性，導致對其性能產生誤解，並可能導致獎勵破解。在這項工作中，我們引入了一個新的設計，用於對獎勵模型進行可靠的評估，並為了驗證這一點，我們構建了 RewardMATH，這是一個有效表示數學推理任務中獎勵模型穩健性的基準。我們證明了 RewardMATH 上的分數與優化策略的結果密切相關，並有效地估計了獎勵過度優化，而現有的基準幾乎沒有相關性。結果強調了我們的設計在提高評估可靠性方面的潛力，並代表了獎勵模型的穩健性。我們將我們的代碼和數據公開。

##### **Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing**
2410.01727v1 by Yilmazcan Ozyurt, Stefan Feuerriegel, Mrinmaya Sachan

Knowledge tracing (KT) is a popular approach for modeling students' learning
progress over time, which can enable more personalized and adaptive learning.
However, existing KT approaches face two major limitations: (1) they rely
heavily on expert-defined knowledge concepts (KCs) in questions, which is
time-consuming and prone to errors; and (2) KT methods tend to overlook the
semantics of both questions and the given KCs. In this work, we address these
challenges and present KCQRL, a framework for automated knowledge concept
annotation and question representation learning that can improve the
effectiveness of any existing KT model. First, we propose an automated KC
annotation process using large language models (LLMs), which generates question
solutions and then annotates KCs in each solution step of the questions.
Second, we introduce a contrastive learning approach to generate semantically
rich embeddings for questions and solution steps, aligning them with their
associated KCs via a tailored false negative elimination approach. These
embeddings can be readily integrated into existing KT models, replacing their
randomly initialized embeddings. We demonstrate the effectiveness of KCQRL
across 15 KT algorithms on two large real-world Math learning datasets, where
we achieve consistent performance improvements.

摘要：知識追蹤 (KT) 是一種流行的方法，用於建模學生的學習進度，這可以實現更個性化和適應性的學習。然而，現有的 KT 方法面臨兩個主要的限制：(1) 它們在問題中嚴重依賴專家定義的知識概念 (KC)，這既費時又容易出錯；(2) KT 方法往往忽視問題和給定 KC 的語義。在這項工作中，我們解決了這些挑戰，並提出了 KCQRL，這是一個用於自動知識概念註解和問題表示學習的框架，可以提高任何現有 KT 模型的有效性。首先，我們使用大型語言模型 (LLM) 提出了一個自動 KC 註解過程，它生成問題解決方案，然後在問題的每個解決方案步驟中註解 KC。其次，我們引入了一個對比學習方法來為問題和解決方案步驟生成語義豐富的嵌入，通過定制的假陰性消除方法將它們與其關聯的 KC 對齊。這些嵌入可以很容易地整合到現有的 KT 模型中，取代它們隨機初始化的嵌入。我們在兩個大型真實世界數學學習數據集上展示了 KCQRL 在 15 個 KT 算法中的有效性，我們實現了一致的性能改進。

##### **Auto-Demo Prompting: Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting**
2410.01724v1 by Longyu Feng, Mengze Hong, Chen Jason Zhang

Batch prompting is a common technique in large language models (LLMs) used to
process multiple inputs simultaneously, aiming to improve computational
efficiency. However, as batch sizes increase, performance degradation often
occurs due to the model's difficulty in handling lengthy context inputs.
Existing methods that attempt to mitigate these issues rely solely on batch
data arrangement and majority voting rather than improving the design of the
batch prompt itself. In this paper, we address these limitations by proposing
"Auto-Demo Prompting," a novel approach that leverages the question-output
pairs from earlier questions within a batch as demonstrations for subsequent
answer inference. We provide a formal theoretical analysis of how Auto-Demo
Prompting functions within the autoregressive generation process of LLMs,
illustrating how it utilizes prior outputs to optimize the model's internal
representations. Our method effectively bridges the gap between batch prompting
and few-shot prompting, enhancing performance with only a slight compromise in
token usage. Experimental results across five NLP tasks demonstrate its
effectiveness in mitigating performance degradation and occasionally
outperforming single prompts. Furthermore, it opens new avenues for applying
few-shot learning techniques, such as demonstration selection, within batch
prompting, making it a robust solution for real-world applications.

摘要：批次提示是大型语言模型 (LLM) 中常用的技术，用于同时处理多重输入，旨在提高计算效率。然而，随着批次大小的增加，由于模型难以处理冗长的上下文输入，通常会出现性能下降。现有的尝试减轻这些问题的方法仅依赖于批次数据排列和多数投票，而不是改善批次提示本身的设计。在本文中，我们通过提出“自动演示提示”来解决这些限制，这是一种新颖的方法，利用批次中较早问题中的问题-输出对作为后续答案推断的演示。我们对自动演示提示如何在 LLM 的自回归生成过程中发挥作用进行了正式的理论分析，说明了它如何利用先验输出来优化模型的内部表示。我们的方法有效地弥合了批次提示和少样本提示之间的差距，仅以略微牺牲标记使用为代价来增强性能。跨五个 NLP 任务的实验结果证明了其在减轻性能下降方面的有效性，并且偶尔优于单一提示。此外，它为在批次提示中应用少样本学习技术（例如演示选择）开辟了新途径，使其成为现实世界应用的稳健解决方案。

##### **Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective**
2410.01720v1 by Zeyu Gan, Yong Liu

Synthetic data has become a pivotal resource in post-training tasks for large
language models (LLMs) due to the scarcity of high-quality, specific data.
While various methods have been developed to generate synthetic data, there
remains a discernible gap between the practical effects of synthetic data and
our theoretical comprehension. To address this challenge, we commence by
presenting a detailed modeling of the prevalent synthetic data generation
process. Building upon this modeling, we demonstrate that the generalization
capability of the post-trained model is critically determined by the
information gain derived from the generative model, as analyzed from a novel
reverse-bottleneck perspective. Moreover, we introduce the concept of
Generalization Gain via Mutual Information (GGMI) and elucidate the
relationship between generalization gain and information gain. This analysis
serves as a theoretical foundation for synthetic data generation and further
highlights its connection with the generalization capability of post-trained
models, offering an understanding about the design of synthetic data generation
techniques and the optimization of the post-training process. We open source
our code through an anonymous GitHub repository at
https://anonymous.4open.science/r/Understanding-Synthetic.

摘要：由於缺乏高品質的特定資料，合成資料已成為大型語言模型 (LLM) 後訓練任務中的關鍵資源。雖然已開發出各種方法來產生合成資料，但合成資料的實際效果與我們的理論理解之間仍然存在明顯的差距。為了應對這一挑戰，我們首先對流行的合成資料生成過程進行詳細建模。在此建模的基礎上，我們證明了後訓練模型的泛化能力受到生成模型中獲得的資訊增益的關鍵影響，這是從新的反向瓶頸角度分析得出的。此外，我們引入了透過互資訊的泛化增益 (GGMI) 的概念，並闡明了泛化增益與資訊增益之間的關係。此分析可作為合成資料生成的理論基礎，並進一步強調其與後訓練模型的泛化能力之間的聯繫，從而瞭解合成資料生成技術的設計和後訓練過程的最佳化。我們透過 https://anonymous.4open.science/r/Understanding-Synthetic 上的匿名 GitHub 儲存庫開放原始碼。

##### **Examining the Role of Relationship Alignment in Large Language Models**
2410.01708v1 by Kristen M. Altenburger, Hongda Jiang, Robert E. Kraut, Yi-Chia Wang, Jane Dwivedi-Yu

The rapid development and deployment of Generative AI in social settings
raise important questions about how to optimally personalize them for users
while maintaining accuracy and realism. Based on a Facebook public post-comment
dataset, this study evaluates the ability of Llama 3.0 (70B) to predict the
semantic tones across different combinations of a commenter's and poster's
gender, age, and friendship closeness and to replicate these differences in
LLM-generated comments.
  The study consists of two parts: Part I assesses differences in semantic
tones across social relationship categories, and Part II examines the
similarity between comments generated by Llama 3.0 (70B) and human comments
from Part I given public Facebook posts as input. Part I results show that
including social relationship information improves the ability of a model to
predict the semantic tone of human comments. However, Part II results show that
even without including social context information in the prompt, LLM-generated
comments and human comments are equally sensitive to social context, suggesting
that LLMs can comprehend semantics from the original post alone. When we
include all social relationship information in the prompt, the similarity
between human comments and LLM-generated comments decreases. This inconsistency
may occur because LLMs did not include social context information as part of
their training data. Together these results demonstrate the ability of LLMs to
comprehend semantics from the original post and respond similarly to human
comments, but also highlights their limitations in generalizing personalized
comments through prompting alone.

摘要：<paragraph>生成式 AI 在社交环境中的快速发展和部署引发了关于如何针对用户对其进行最佳个性化定制同时保持准确性和真实性的重要问题。基于 Facebook 公共帖子评论数据集，本研究评估了 Llama 3.0 (70B) 根据评论者和发帖者的性别、年龄和亲密度组合预测语义语气的能力，以及在 LLM 生成的评论中复制这些差异的能力。
本研究包括两部分：第一部分评估了不同社交关系类别中语义语气的差异，第二部分检查了 Llama 3.0 (70B) 生成的评论与第一部分中给定公共 Facebook 帖子作为输入的人类评论之间的相似性。第一部分的结果表明，包含社交关系信息可以提高模型预测人类评论语义语气的能力。然而，第二部分的结果表明，即使没有在提示中包含社交背景信息，LLM 生成的评论和人类评论对社交背景同样敏感，这表明 LLM 可以仅从原始帖子中理解语义。当我们在提示中包含所有社交关系信息时，人类评论和 LLM 生成的评论之间的相似性会降低。这种不一致性可能是因为 LLM 没有将社交背景信息作为其训练数据的一部分。这些结果共同证明了 LLM 从原始帖子中理解语义并对人类评论做出类似反应的能力，但也突出了它们仅通过提示来概括个性化评论的局限性。</paragraph>

##### **Interpretable Contrastive Monte Carlo Tree Search Reasoning**
2410.01707v1 by Zitian Gao, Boye Niu, Xuzheng He, Haotian Xu, Hongzhang Liu, Aiwei Liu, Xuming Hu, Lijie Wen

We propose SC-MCTS*: a novel Monte Carlo Tree Search (MCTS) reasoning
algorithm for Large Language Models (LLMs), significantly improves both
reasoning accuracy and speed. Our motivation comes from: 1. Previous MCTS LLM
reasoning works often overlooked its biggest drawback--slower speed compared to
CoT; 2. Previous research mainly used MCTS as a tool for LLM reasoning on
various tasks with limited quantitative analysis or ablation studies of its
components from reasoning interpretability perspective. 3. The reward model is
the most crucial component in MCTS, however previous work has rarely conducted
in-depth study or improvement of MCTS's reward models. Thus, we conducted
extensive ablation studies and quantitative analysis on components of MCTS,
revealing the impact of each component on the MCTS reasoning performance of
LLMs. Building on this, (i) we designed a highly interpretable reward model
based on the principle of contrastive decoding and (ii) achieved an average
speed improvement of 51.9% per node using speculative decoding. Additionally,
(iii) we improved UCT node selection strategy and backpropagation used in
previous works, resulting in significant performance improvement. We
outperformed o1-mini by an average of 17.4% on the Blocksworld multi-step
reasoning dataset using Llama-3.1-70B with SC-MCTS*.

摘要：我們提出 SC-MCTS*：一種新穎的蒙地卡羅樹搜尋 (MCTS) 推理演算法，適用於大型語言模型 (LLM)，大幅提升推理準確度和速度。我們的動機來自於：1. 先前的 MCTS LLM 推理研究通常忽略其最大的缺點——與 CoT 相比速度較慢；2. 先前的研究主要將 MCTS 用作 LLM 在各種任務上進行推理的工具，但對其組成部分從推理可解釋性的角度進行的量化分析或消融研究有限。3. 獎勵模型是 MCTS 中最重要的組成部分，但先前的研究很少對 MCTS 的獎勵模型進行深入的研究或改進。因此，我們對 MCTS 的組成部分進行了廣泛的消融研究和量化分析，揭示了每個組成部分對 LLM 的 MCTS 推理效能的影響。在此基礎上，(i) 我們根據對比解碼的原理設計了一個高度可解釋的獎勵模型，並 (ii) 使用推測性解碼實現了每個節點平均 51.9% 的速度提升。此外，(iii) 我們改進了先前的研究中使用的 UCT 節點選擇策略和反向傳播，從而顯著提升效能。使用 Llama-3.1-70B 搭配 SC-MCTS*，我們在 Blocksworld 多步驟推理資料集上平均優於 o1-mini 17.4%。

##### **Performant, Memory Efficient and Scalable Multi-Agent Reinforcement Learning**
2410.01706v1 by Omayma Mahjoub, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon du Toit, Jemma Daniel, Louay Ben Nessir, Louise Beyers, Claude Formanek, Liam Clark, Arnu Pretorius

As the field of multi-agent reinforcement learning (MARL) progresses towards
larger and more complex environments, achieving strong performance while
maintaining memory efficiency and scalability to many agents becomes
increasingly important. Although recent research has led to several advanced
algorithms, to date, none fully address all of these key properties
simultaneously. In this work, we introduce Sable, a novel and theoretically
sound algorithm that adapts the retention mechanism from Retentive Networks to
MARL. Sable's retention-based sequence modelling architecture allows for
computationally efficient scaling to a large number of agents, as well as
maintaining a long temporal context, making it well-suited for large-scale
partially observable environments. Through extensive evaluations across six
diverse environments, we demonstrate how Sable is able to significantly
outperform existing state-of-the-art methods in the majority of tasks (34 out
of 45, roughly 75\%). Furthermore, Sable demonstrates stable performance as we
scale the number of agents, handling environments with more than a thousand
agents while exhibiting a linear increase in memory usage. Finally, we conduct
ablation studies to isolate the source of Sable's performance gains and confirm
its efficient computational memory usage. Our results highlight Sable's
performance and efficiency, positioning it as a leading approach to MARL at
scale.

摘要：隨著多重代理強化學習 (MARL) 領域朝向更大型、更複雜的環境邁進，在維持記憶效率和可擴充性至許多代理的同時達成強勁的效能變得越來越重要。儘管最近的研究已導致數種進階演算法，但迄今為止，沒有任何演算法能同時完全解決所有這些關鍵屬性。在這項研究中，我們介紹 Sable，一種新穎且理論上健全的演算法，它將保留機制從保留式網路改編至 MARL。Sable 基於保留的序列建模架構允許以計算上有效率的方式擴充至大量代理，並維持長期的時間脈絡，使其非常適合於大規模的部分可觀察環境。透過在六個不同的環境中進行廣泛評估，我們展示 Sable 如何在大部分任務中（45 個中的 34 個，大約 75%）顯著優於現有的最先進方法。此外，當我們擴充代理數量時，Sable 展現出穩定的效能，處理具有超過一千個代理的環境，同時展現出記憶體使用量的線性增加。最後，我們進行消融研究以分離 Sable 效能提升的來源，並確認其有效率的計算記憶體使用。我們的結果突顯了 Sable 的效能和效率，將其定位為大規模 MARL 的領先方法。

##### **An Exploration of Self-Supervised Mutual Information Alignment for Multi-Task Settings**
2410.01704v1 by Soham Govande

There is a growing need for pluralistic alignment methods that can steer
language models towards individual attributes and preferences. One such method,
Self-Supervised Alignment with Mutual Information (SAMI), uses conditional
mutual information to encourage the connection between behavioral preferences
and model responses. We conduct two experiments exploring SAMI in multi-task
settings. First, we compare SAMI to Direct Preference Optimization (DPO) on a
multi-task benchmark (MT-Bench), using a stronger model to generate training
data for a weaker one across diverse categories (humanities, STEM, extraction,
coding, math, reasoning, and roleplay). Our results indicate that one iteration
of SAMI has a 57% win rate against DPO, with significant variation in
performance between task categories. Second, we examine SAMI's impact on
mathematical accuracy (GSM-8K) relative to supervised fine-tuning (SFT). While
SAMI increases zero-shot performance by 1.1%, SFT is more effective with a 3.2%
boost. However, SAMI shows interesting scaling trends. When given 10 attempts,
SAMI improves accuracy by 3.9%, while SFT achieves a 10.1% increase. Combining
SAMI with SFT yields an additional improvement of 1.3% in multi-attempt
settings, though single-attempt accuracy remains unchanged.

摘要：<paragraph>日益增長的需求，需要多元化對齊方法，這些方法可以引導語言模型朝向個人屬性和偏好。其中一種方法，使用條件互惠資訊的自監督對齊（SAMI），使用條件互惠資訊來鼓勵行為偏好和模型回應之間的連接。我們進行了兩項實驗，探索 SAMI 在多任務設定中的應用。首先，我們在多任務基準（MT-Bench）上將 SAMI 與直接偏好最佳化（DPO）進行比較，使用更強大的模型來為較弱的模型生成訓練資料，涵蓋不同類別（人文、STEM、萃取、編碼、數學、推理和角色扮演）。我們的結果表明，SAMI 的一次迭代對 DPO 的勝率為 57%，任務類別之間的效能差異顯著。其次，我們檢視 SAMI 對數學準確度（GSM-8K）的影響，相對於監督微調（SFT）。雖然 SAMI 將零次學習效能提升 1.1%，但 SFT 以 3.2% 的提升更為有效。然而，SAMI 顯示出有趣的擴充趨勢。當給予 10 次嘗試時，SAMI 將準確度提升 3.9%，而 SFT 達到 10.1% 的提升。將 SAMI 與 SFT 結合使用，在多嘗試設定中額外提升 1.3%，儘管單次嘗試的準確度保持不變。</paragraph>

##### **CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs**
2410.01696v1 by Kangsheng Wang, Xiao Zhang, Hao Liu, Songde Han, Huimin Ma, Tianyu Hu

Large language models (LLMs) have demonstrated limitations in handling
combinatorial optimization problems involving long-range reasoning, partially
due to causal hallucinations and huge search space. As for causal
hallucinations, i.e., the inconsistency between reasoning and corresponding
state transition, this paper introduces the Causal Relationship Enhancement
(CRE) mechanism combining cause-effect interventions and the Individual
Treatment Effect (ITE) to guarantee the solid causal rightness between each
step of reasoning and state transition. As for the long causal range and huge
search space limiting the performances of existing models featuring
single-direction search, a Dual-End Searching (DES) approach is proposed to
seek solutions by simultaneously starting from both the initial and goal states
on the causal probability tree. By integrating CRE and DES (CreDes), our model
has realized simultaneous multi-step reasoning, circumventing the
inefficiencies from cascading multiple one-step reasoning like the
Chain-of-Thought (CoT). Experiments demonstrate that CreDes significantly
outperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning
tasks in terms of both accuracy and time efficiency.

摘要：大型語言模型 (LLM) 在處理涉及長程推理的組合最佳化問題時顯示出其局限性，部分原因在於因果幻覺和巨大的搜尋空間。至於因果幻覺，亦即推理和對應狀態轉換之間的不一致，本文介紹了因果關係增強 (CRE) 機制，結合因果干預和個別處理效果 (ITE)，以保證推理和狀態轉換之間穩固的因果正確性。至於長因果範圍和巨大的搜尋空間限制了具有單向搜尋功能的現有模型的效能，因此提出了一個雙端搜尋 (DES) 方法，透過同時從因果機率樹上的初始狀態和目標狀態開始，來尋求解決方案。透過整合 CRE 和 DES (CreDes)，我們的模型實現了同時的多步驟推理，避免了像思考鏈 (CoT) 那樣從多個單步驟推理中產生級聯效應所造成的低效率。實驗證明，在長程推理任務中，CreDes 在準確性和時間效率方面都明顯優於現有的最先進 (SOTA) 解决方案。

##### **U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models**
2410.01692v1 by Tung-Yu Wu, Pei-Yu Lo

Large language models (LLMs) have been shown to exhibit emergent abilities in
some downstream tasks, where performance seems to stagnate at first and then
improve sharply and unpredictably with scale beyond a threshold. By dividing
questions in the datasets according to difficulty level by average performance,
we observe U-shaped scaling for hard questions, and inverted-U scaling followed
by steady improvement for easy questions. Moreover, the emergence threshold
roughly coincides with the point at which performance on easy questions reverts
from inverse scaling to standard scaling. Capitalizing on the observable though
opposing scaling trend on easy and hard questions, we propose a simple yet
effective pipeline, called Slice-and-Sandwich, to predict both the emergence
threshold and model performance beyond the threshold.

摘要：大型語言模型 (LLM) 已被證明在某些下游任務中表現出新興能力，其中效能最初看似停滯不前，然後隨著規模突破某個臨界值而急劇且難以預測地提升。透過根據平均效能將資料集中的問題依難度等級分類，我們觀察到困難問題呈現 U 型擴充，而簡單問題則呈現倒 U 型擴充，接著是穩定的提升。此外，新興臨界值大致與簡單問題的效能從反向擴充轉變為標準擴充的點一致。利用簡單和困難問題中可觀察到的對立擴充趨勢，我們提出一個簡單但有效的管道，稱為「切片三明治」，以預測新興臨界值和臨界值之外的模型效能。

##### **FactAlign: Long-form Factuality Alignment of Large Language Models**
2410.01691v1 by Chao-Wei Huang, Yun-Nung Chen

Large language models have demonstrated significant potential as the
next-generation information access engines. However, their reliability is
hindered by issues of hallucination and generating non-factual content. This is
particularly problematic in long-form responses, where assessing and ensuring
factual accuracy is complex. In this paper, we address this gap by proposing
FactAlign, a novel alignment framework designed to enhance the factuality of
LLMs' long-form responses while maintaining their helpfulness. We introduce
fKTO, a fine-grained, sentence-level alignment algorithm that extends the
Kahneman-Tversky Optimization (KTO) alignment method. Leveraging recent
advances in automatic factuality evaluation, FactAlign utilizes fine-grained
factuality assessments to guide the alignment process. Our experiments on
open-domain prompts and information-seeking questions demonstrate that
FactAlign significantly improves the factual accuracy of LLM responses while
also improving their helpfulness. Further analyses identify that FactAlign is
capable of training LLMs to provide more information without losing factual
precision, thus improving the factual F1 score. Our source code, datasets, and
trained models are publicly available at https://github.com/MiuLab/FactAlign

摘要：大型語言模型已證明其作為下一代資訊存取引擎具有顯著的潛力。然而，其可靠性受到幻覺和產生非事實內容等問題的阻礙。這在長篇回應中特別成問題，其中評估和確保事實準確性很複雜。在本文中，我們通過提出 FactAlign 來解決這個差距，FactAlign 是一個新穎的對齊框架，旨在增強 LLM 長篇回應的事實性，同時保持其有益性。我們引入了 fKTO，一種細粒度、句子級別對齊演算法，它擴展了 Kahneman-Tversky 最佳化 (KTO) 對齊方法。FactAlign 利用自動事實性評估的最新進展，利用細粒度的真實性評估來指導對齊過程。我們在開放式提示和資訊尋求問題上的實驗表明，FactAlign 大幅改善了 LLM 回應的事實準確性，同時也提高了其有益性。進一步的分析發現，FactAlign 能夠訓練 LLM 提供更多資訊，而不會失去事實精確性，從而提高事實 F1 分數。我們的原始碼、資料集和訓練模型可在 https://github.com/MiuLab/FactAlign 公開取得

##### **Why context matters in VQA and Reasoning: Semantic interventions for VLM input modalities**
2410.01690v1 by Kenza Amara, Lukas Klein, Carsten Lüth, Paul Jäger, Hendrik Strobelt, Mennatallah El-Assady

The various limitations of Generative AI, such as hallucinations and model
failures, have made it crucial to understand the role of different modalities
in Visual Language Model (VLM) predictions. Our work investigates how the
integration of information from image and text modalities influences the
performance and behavior of VLMs in visual question answering (VQA) and
reasoning tasks. We measure this effect through answer accuracy, reasoning
quality, model uncertainty, and modality relevance. We study the interplay
between text and image modalities in different configurations where visual
content is essential for solving the VQA task. Our contributions include (1)
the Semantic Interventions (SI)-VQA dataset, (2) a benchmark study of various
VLM architectures under different modality configurations, and (3) the
Interactive Semantic Interventions (ISI) tool. The SI-VQA dataset serves as the
foundation for the benchmark, while the ISI tool provides an interface to test
and apply semantic interventions in image and text inputs, enabling more
fine-grained analysis. Our results show that complementary information between
modalities improves answer and reasoning quality, while contradictory
information harms model performance and confidence. Image text annotations have
minimal impact on accuracy and uncertainty, slightly increasing image
relevance. Attention analysis confirms the dominant role of image inputs over
text in VQA tasks. In this study, we evaluate state-of-the-art VLMs that allow
us to extract attention coefficients for each modality. A key finding is
PaliGemma's harmful overconfidence, which poses a higher risk of silent
failures compared to the LLaVA models. This work sets the foundation for
rigorous analysis of modality integration, supported by datasets specifically
designed for this purpose.

摘要：生成式 AI 的各種限制，例如幻覺和模型失敗，使得了解不同模態在視覺語言模型 (VLM) 預測中的作用至關重要。我們的研究探討了來自圖像和文本模態的資訊整合如何影響 VLM 在視覺問題解答 (VQA) 和推理任務中的效能和行為。我們透過回答準確度、推理品質、模型不確定性和模態相關性來衡量此效應。我們研究了在不同組態中文本和圖像模態之間的交互作用，其中視覺內容對於解決 VQA 任務至關重要。我們的貢獻包括：(1) 語義介入 (SI)-VQA 資料集，(2) 針對不同模態組態下各種 VLM 架構的基準研究，以及 (3) 互動式語義介入 (ISI) 工具。SI-VQA 資料集作為基準的基礎，而 ISI 工具提供了一個介面，可以在圖像和文本輸入中測試和應用語義介入，從而實現更精細的分析。我們的結果表明，模態之間的互補資訊可以改善答案和推理品質，而矛盾的資訊會損害模型效能和信心。圖像文字註解對準確度和不確定性的影響很小，略微提高了圖像相關性。注意力分析證實了圖像輸入在 VQA 任務中比文本更重要的作用。在本研究中，我們評估了最先進的 VLM，這些 VLM 讓我們可以為每個模態提取注意力係數。一個關鍵發現是 PaliGemma 有害的過度自信，與 LLaVA 模型相比，它造成靜默失敗的風險更高。這項工作為模態整合的嚴謹分析奠定了基礎，並得到專門為此目的設計的資料集的支援。

##### **Positional Attention: Out-of-Distribution Generalization and Expressivity for Neural Algorithmic Reasoning**
2410.01686v1 by Artur Back de Luca, George Giapitzakis, Shenghao Yang, Petar Veličković, Kimon Fountoulakis

There has been a growing interest in the ability of neural networks to solve
algorithmic tasks, such as arithmetic, summary statistics, and sorting. While
state-of-the-art models like Transformers have demonstrated good generalization
performance on in-distribution tasks, their out-of-distribution (OOD)
performance is poor when trained end-to-end. In this paper, we focus on value
generalization, a common instance of OOD generalization where the test
distribution has the same input sequence length as the training distribution,
but the value ranges in the training and test distributions do not necessarily
overlap. To address this issue, we propose that using fixed positional
encodings to determine attention weights-referred to as positional
attention-enhances empirical OOD performance while maintaining expressivity. We
support our claim about expressivity by proving that Transformers with
positional attention can effectively simulate parallel algorithms.

摘要：對於神經網路解決演算法任務，例如算術、摘要統計和排序的能力，人們越來越感興趣。雖然像 Transformer 這樣的最先進模型已在分佈內任務上展示出良好的泛化效能，但當端對端訓練時，它們的分佈外 (OOD) 效能很差。在本文中，我們專注於值泛化，這是 OOD 泛化的常見範例，其中測試分佈具有與訓練分佈相同的輸入序列長度，但訓練和測試分佈中的值範圍不一定重疊。為了解決這個問題，我們建議使用固定的位置編碼來確定注意力權重，稱為位置注意力，它可以在保持表達力的同時增強經驗性的 OOD 效能。我們透過證明具有位置注意力的 Transformer 可以有效模擬平行演算法，來支持我們對表達力的主張。

##### **PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation**
2410.01680v1 by Mike Ranzinger, Jon Barker, Greg Heinrich, Pavlo Molchanov, Bryan Catanzaro, Andrew Tao

Various visual foundation models have distinct strengths and weaknesses, both
of which can be improved through heterogeneous multi-teacher knowledge
distillation without labels, termed "agglomerative models." We build upon this
body of work by studying the effect of the teachers' activation statistics,
particularly the impact of the loss function on the resulting student model
quality. We explore a standard toolkit of statistical normalization techniques
to better align the different distributions and assess their effects. Further,
we examine the impact on downstream teacher-matching metrics, which motivates
the use of Hadamard matrices. With these matrices, we demonstrate useful
properties, showing how they can be used for isotropic standardization, where
each dimension of a multivariate distribution is standardized using the same
scale. We call this technique "PHI Standardization" (PHI-S) and empirically
demonstrate that it produces the best student model across the suite of methods
studied.

摘要：各種視覺基礎模型都有不同的優點和缺點，兩者都可以透過異質多教師知識蒸餾來改進，而無需標籤，稱為「聚合模型」。我們透過研究教師的激活統計資料來建立這項工作，特別是損失函數對產生的學生模型品質所造成的影響。我們探索標準的統計正規化技術工具包，以更好地調整不同的分佈並評估其效果。此外，我們檢驗對下游教師匹配指標的影響，這激勵了 Hadamard 矩陣的使用。有了這些矩陣，我們展示了有用的特性，說明了如何將它們用於各向同性標準化，其中多變量分佈的每個維度都使用相同的比例進行標準化。我們將此技術稱為「PHI 標準化」(PHI-S)，並透過實證證明，它在所研究的方法套件中產生了最佳的學生模型。

##### **VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit Assignment**
2410.01679v1 by Amirhossein Kazemnejad, Milad Aghajohari, Eva Portelance, Alessandro Sordoni, Siva Reddy, Aaron Courville, Nicolas Le Roux

Large language models (LLMs) are increasingly applied to complex reasoning
tasks that require executing several complex steps before receiving any reward.
Properly assigning credit to these steps is essential for enhancing model
performance. Proximal Policy Optimization (PPO), a state-of-the-art
reinforcement learning (RL) algorithm used for LLM finetuning, employs value
networks to tackle credit assignment. However, value networks face challenges
in predicting the expected cumulative rewards accurately in complex reasoning
tasks, often leading to high-variance updates and suboptimal performance. In
this work, we systematically evaluate the efficacy of value networks and reveal
their significant shortcomings in reasoning-heavy LLM tasks, showing that they
barely outperform a random baseline when comparing alternative steps. To
address this, we propose VinePPO, a straightforward approach that leverages the
flexibility of language environments to compute unbiased Monte Carlo-based
estimates, bypassing the need for large value networks. Our method consistently
outperforms PPO and other RL-free baselines across MATH and GSM8K datasets with
fewer gradient updates (up to 9x), less wall-clock time (up to 3.0x). These
results emphasize the importance of accurate credit assignment in RL finetuning
of LLM and demonstrate VinePPO's potential as a superior alternative.

摘要：大型語言模型 (LLM) 愈來愈多應用於複雜推理任務，這些任務需要執行數個複雜步驟才能獲得任何獎勵。適當地將信用分配給這些步驟對於提升模型效能至關重要。近端策略最佳化 (PPO) 是一種用於 LLM 微調的最新強化學習 (RL) 演算法，它採用價值網路來解決信用分配問題。然而，價值網路在複雜推理任務中準確預測預期累積獎勵時會面臨挑戰，這通常會導致高變異更新和次佳效能。在這項工作中，我們系統性評估價值網路的效能，並揭示它們在推理密集型 LLM 任務中的重大缺點，顯示它們在比較替代步驟時幾乎沒有優於隨機基準。為了解決這個問題，我們提出 VinePPO，這是一種直接的方法，它利用語言環境的靈活性來計算無偏差的蒙地卡羅估計，繞過對大型價值網路的需求。我們的模型在 MATH 和 GSM8K 資料集上持續優於 PPO 和其他不使用 RL 的基準，且梯度更新次數較少 (最多減少 9 倍)、時鐘時間較短 (最多減少 3.0 倍)。這些結果強調了準確信用分配在 LLM 的 RL 微調中的重要性，並證明了 VinePPO 作為優越替代方案的潛力。

##### **Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia**
2410.01677v1 by Miao Yu, Junyuan Mao, Guibin Zhang, Jingheng Ye, Junfeng Fang, Aoxiao Zhong, Yang Liu, Yuxuan Liang, Kun Wang, Qingsong Wen

Research into the external behaviors and internal mechanisms of large
language models (LLMs) has shown promise in addressing complex tasks in the
physical world. Studies suggest that powerful LLMs, like GPT-4, are beginning
to exhibit human-like cognitive abilities, including planning, reasoning, and
reflection. In this paper, we introduce a research line and methodology called
LLM Psychology, leveraging human psychology experiments to investigate the
cognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia
phenomenon from psychology to explore the "mind" of LLMs. Unlike human brains,
which rely on context and word patterns to comprehend scrambled text, LLMs use
distinct encoding and decoding processes. Through Typoglycemia experiments at
the character, word, and sentence levels, we observe: (I) LLMs demonstrate
human-like behaviors on a macro scale, such as lower task accuracy and higher
token/time consumption; (II) LLMs exhibit varying robustness to scrambled
input, making Typoglycemia a benchmark for model evaluation without new
datasets; (III) Different task types have varying impacts, with complex logical
tasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has
a unique and consistent "cognitive pattern" across tasks, revealing general
mechanisms in its psychology process. We provide an in-depth analysis of hidden
layers to explain these phenomena, paving the way for future research in LLM
Psychology and deeper interpretability.

摘要：大型語言模型 (LLM) 的外部行為和內部機制的研究，已顯示出在解決物理世界中的複雜任務方面很有前景。研究表明，像 GPT-4 這樣的強大 LLM 正開始展現類人的認知能力，包括規劃、推理和反思。在本文中，我們介紹了一種稱為 LLM 心理學的研究路線和方法，利用人類心理學實驗來研究 LLM 的認知行為和機制。我們將 Typoglycemia 現象從心理學轉移到探索 LLM 的「心智」。與依賴上下文和字詞模式來理解打亂文字的人類大腦不同，LLM 使用不同的編碼和解碼過程。透過在字元、字詞和句子層級進行 Typoglycemia 實驗，我們觀察到：(I) LLM 在巨觀層面上表現出類人的行為，例如較低的任務準確度和較高的代幣/時間消耗；(II) LLM 對打亂的輸入展現出不同的健壯性，使 Typoglycemia 成為模型評估的基準，而無需新的資料集；(III) 不同的任務類型有不同的影響，複雜的邏輯任務（例如數學）在打亂形式中更具挑戰性；(IV) 每個 LLM 在任務中都有獨特且一致的「認知模式」，揭示其心理過程中的一般機制。我們提供了隱藏層的深入分析來解釋這些現象，為 LLM 心理學和更深入的可解釋性的未來研究鋪平了道路。

##### **Trying to be human: Linguistic traces of stochastic empathy in language models**
2410.01675v1 by Bennett Kleinberg, Jari Zegers, Jonas Festor, Stefana Vida, Julian Präsent, Riccardo Loconte, Sanne Peereboom

Differentiating between generated and human-written content is important for
navigating the modern world. Large language models (LLMs) are crucial drivers
behind the increased quality of computer-generated content. Reportedly, humans
find it increasingly difficult to identify whether an AI model generated a
piece of text. Our work tests how two important factors contribute to the human
vs AI race: empathy and an incentive to appear human. We address both aspects
in two experiments: human participants and a state-of-the-art LLM wrote
relationship advice (Study 1, n=530) or mere descriptions (Study 2, n=610),
either instructed to be as human as possible or not. New samples of humans
(n=428 and n=408) then judged the texts' source. Our findings show that when
empathy is required, humans excel. Contrary to expectations, instructions to
appear human were only effective for the LLM, so the human advantage
diminished. Computational text analysis revealed that LLMs become more human
because they may have an implicit representation of what makes a text human and
effortlessly apply these heuristics. The model resorts to a conversational,
self-referential, informal tone with a simpler vocabulary to mimic stochastic
empathy. We discuss these findings in light of recent claims on the on-par
performance of LLMs.

摘要：區分生成內容和人類撰寫的內容對於
在現代世界中穿梭非常重要。大型語言模型 (LLM) 是推動電腦生成內容品質提升的重要驅動力。據報導，人類越來越難以辨別一段文字是否由 AI 模型生成。我們的研究測試了兩個重要因素如何影響人類
與 AI 之間的競賽：同理心和表現出人類特質的誘因。我們在兩個實驗中探討這兩個面向：人類參與者和最先進的 LLM 撰寫了關係建議（研究 1，n=530）或僅是描述（研究 2，n=610），並指示盡可能表現得像人類或不表現得像人類。隨後，新的人類樣本
（n=428 和 n=408）判斷這些文字的來源。我們的研究結果顯示，當需要同理心時，人類表現得較好。與預期相反，表現得像人類的指示只對 LLM 有效，因此人類的優勢減弱。計算文本分析顯示，LLM 變得很像人類，因為它們可能隱含地呈現出構成人類文字的元素，並且毫不費力地運用這些啟發法。該模型採用對話式、自我參照式、非正式的語氣，並使用較簡單的詞彙來模擬隨機同理心。我們根據最近關於 LLM 表現與人類相等的說法，探討這些研究結果。

##### **Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding**
2410.01671v1 by Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yanxin Shen, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du

Large language models (LLMs) have shown remarkable capabilities in natural
language processing; however, they still face difficulties when tasked with
understanding lengthy contexts and executing effective question answering.
These challenges often arise due to the complexity and ambiguity present in
longer texts. To enhance the performance of LLMs in such scenarios, we
introduce the Long Question Coreference Adaptation (LQCA) method. This
innovative framework focuses on coreference resolution tailored to long
contexts, allowing the model to identify and manage references effectively. The
LQCA method encompasses four key steps: resolving coreferences within
sub-documents, computing the distances between mentions, defining a
representative mention for coreference, and answering questions through mention
replacement. By processing information systematically, the framework provides
easier-to-handle partitions for LLMs, promoting better understanding.
Experimental evaluations on a range of LLMs and datasets have yielded positive
results, with a notable improvements on OpenAI-o1-mini and GPT-4o models,
highlighting the effectiveness of leveraging coreference resolution to bridge
context gaps in question answering.

摘要：大型語言模型 (LLM) 在自然語言處理中展現了非凡的能力；然而，當它們面臨理解冗長的語境和執行有效的問答任務時，仍然會遇到困難。這些挑戰通常是因為較長的文本中存在複雜性和歧義。為了增強 LLM 在這種情況下的效能，我們引入了長式問題指代適應 (LQCA) 方法。這個創新的架構專注於針對長語境的指代消解，讓模型能夠有效地識別和管理指代。LQCA 方法包含四個關鍵步驟：在子文件中解析指代、計算提及之間的距離、定義指代的代表性提及，以及透過提及替換來回答問題。透過系統性地處理資訊，這個架構為 LLM 提供了更容易處理的分區，促進更好的理解。在各種 LLM 和資料集上的實驗評估產生了正面的結果，在 OpenAI-o1-mini 和 GPT-4o 模型上都有顯著的改進，突顯了利用指代消解來彌補問答中語境差距的有效性。

##### **Towards a vision foundation model for comprehensive assessment of Cardiac MRI**
2410.01665v1 by Athira J Jacob, Indraneel Borgohain, Teodora Chitiboi, Puneet Sharma, Dorin Comaniciu, Daniel Rueckert

Cardiac magnetic resonance imaging (CMR), considered the gold standard for
noninvasive cardiac assessment, is a diverse and complex modality requiring a
wide variety of image processing tasks for comprehensive assessment of cardiac
morphology and function. Advances in deep learning have enabled the development
of state-of-the-art (SoTA) models for these tasks. However, model training is
challenging due to data and label scarcity, especially in the less common
imaging sequences. Moreover, each model is often trained for a specific task,
with no connection between related tasks. In this work, we introduce a vision
foundation model trained for CMR assessment, that is trained in a
self-supervised fashion on 36 million CMR images. We then finetune the model in
supervised way for 9 clinical tasks typical to a CMR workflow, across
classification, segmentation, landmark localization, and pathology detection.
We demonstrate improved accuracy and robustness across all tasks, over a range
of available labeled dataset sizes. We also demonstrate improved few-shot
learning with fewer labeled samples, a common challenge in medical image
analyses. We achieve an out-of-box performance comparable to SoTA for most
clinical tasks. The proposed method thus presents a resource-efficient, unified
framework for CMR assessment, with the potential to accelerate the development
of deep learning-based solutions for image analysis tasks, even with few
annotated data available.

摘要：心臟磁振造影 (CMR) 被認為是非侵入式心臟評估的黃金標準，是一種多樣且複雜的模式，需要各種影像處理任務才能全面評估心臟形態和功能。深度學習的進步使得開發這些任務的最新技術 (SoTA) 模型成為可能。然而，由於數據和標籤的稀缺性，特別是在不常見的影像序列中，模型訓練具有挑戰性。此外，每個模型通常針對特定任務進行訓練，相關任務之間沒有關聯。在這項工作中，我們引入了一個針對 CMR 評估訓練的視覺基礎模型，該模型以自監督的方式在 3600 萬張 CMR 影像上進行訓練。然後，我們以監督方式微調模型，以執行 CMR 工作流程中典型的 9 項臨床任務，包括分類、分割、標誌定位和病理檢測。我們展示了在各種可用的標籤資料集大小中，所有任務的準確性和穩健性都有所提高。我們還展示了在標籤樣本較少的情況下改進了少樣本學習，這是在醫學影像分析中常見的挑戰。我們實現了與大多數臨床任務的 SoTA 相當的開箱即用效能。因此，所提出的方法提供了一個資源高效的統一框架，用於 CMR 評估，並有可能加速基於深度學習的影像分析任務的解決方案開發，即使只有少量的註釋數據可用。

##### **Finding path and cycle counting formulae in graphs with Deep Reinforcement Learning**
2410.01661v1 by Jason Piquenot, Maxime Bérar, Pierre Héroux, Jean-Yves Ramel, Romain Raveaux, Sébastien Adam

This paper presents Grammar Reinforcement Learning (GRL), a reinforcement
learning algorithm that uses Monte Carlo Tree Search (MCTS) and a transformer
architecture that models a Pushdown Automaton (PDA) within a context-free
grammar (CFG) framework. Taking as use case the problem of efficiently counting
paths and cycles in graphs, a key challenge in network analysis, computer
science, biology, and social sciences, GRL discovers new matrix-based formulas
for path/cycle counting that improve computational efficiency by factors of two
to six w.r.t state-of-the-art approaches. Our contributions include: (i) a
framework for generating gramformers that operate within a CFG, (ii) the
development of GRL for optimizing formulas within grammatical structures, and
(iii) the discovery of novel formulas for graph substructure counting, leading
to significant computational improvements.

摘要：本文提出文法強化學習 (GRL)，一種使用蒙地卡羅樹狀搜尋 (MCTS) 和變換器架構的強化學習演算法，該架構在無上下文文法 (CFG) 框架內模擬下推自動機 (PDA)。以有效計算圖形中的路徑和迴圈問題為使用案例，這是網路分析、電腦科學、生物學和社會科學中的關鍵挑戰，GRL 發現新的基於矩陣的路徑/迴圈計算公式，可將運算效率提高兩到六倍，相對於最先進的方法。我們的貢獻包括：(i) 在 CFG 中運作的文法變換器生成框架，(ii) 開發 GRL 以最佳化語法結構中的公式，以及 (iii) 發現用於計算圖形子結構的新公式，從而顯著提升運算效能。

##### **Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**
2410.01660v1 by Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach

Generative models lack rigorous statistical guarantees for their outputs and
are therefore unreliable in safety-critical applications. In this work, we
propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a
sequential conformal prediction method producing prediction sets that satisfy a
rigorous statistical guarantee called conformal admissibility control. This
guarantee states that with high probability, the prediction sets contain at
least one admissible (or valid) example. To this end, our method first samples
an initial set of i.i.d. examples from a black box generative model. Then, this
set is iteratively pruned via so-called greedy filters. As a consequence of the
iterative generation procedure, admissibility of the final prediction set
factorizes as a Markov chain. This factorization is crucial, because it allows
to control each factor separately, using conformal prediction. In comparison to
prior work, our method demonstrates a large reduction in the number of
admissibility evaluations during calibration. This reduction is important in
safety-critical applications, where these evaluations must be conducted
manually by domain experts and are therefore costly and time consuming. We
highlight the advantages of our method in terms of admissibility evaluations
and cardinality of the prediction sets through experiments in natural language
generation and molecular graph extension tasks.

摘要：生成模型缺乏對其輸出進行嚴格的統計保證，因此在安全關鍵應用中不可靠。在這項工作中，我們提出了生成模型的順序共形預測 (SCOPE-Gen)，這是一種順序共形預測方法，產生滿足稱為共形可採性控制的嚴格統計保證的預測集。此保證表示，預測集在高機率下至少包含一個可採 (或有效) 的範例。為此，我們的模型首先從黑盒生成模型中抽取一組 i.i.d. 範例。然後，透過所謂的貪婪過濾器反覆修剪此組。作為反覆生成程序的結果，最終預測集的可採性分解為馬可夫鏈。此分解至關重要，因為它允許使用共形預測分別控制每個因子。與先前的工作相比，我們的模型顯示在校準過程中可大幅減少可採性評估的數量。此減少在安全關鍵應用中很重要，在這些應用中，這些評估必須由領域專家手動進行，因此成本高昂且耗時。我們透過自然語言生成和分子圖形延伸任務中的實驗，突顯我們的模型在可採性評估和預測集基數方面的優點。

##### **Efficient Long-range Language Modeling with Self-supervised Causal Retrieval**
2410.01651v1 by Xiang Hu, Zhihao Teng, Wei Wu, Kewei Tu

Recently, retrieval-based language models (RLMs) have received much
attention. However, most of them leverage a pre-trained retriever with fixed
parameters, which may not adapt well to causal language models. In this work,
we propose Grouped Cross-Attention, a novel module enabling joint pre-training
of the retriever and causal LM, and apply it to long-context modeling. For a
given input sequence, we split it into chunks and use the current chunk to
retrieve past chunks for subsequent text generation. Our innovation allows the
retriever to learn how to retrieve past chunks that better minimize the
auto-regressive loss of subsequent tokens in an end-to-end manner. By
integrating top-$k$ retrieval, our model can be pre-trained efficiently from
scratch with context lengths up to 64K tokens. Our experiments show our model,
compared with long-range LM baselines, can achieve lower perplexity with
comparable or lower pre-training and inference costs.

摘要：最近，基于检索的语言模型 (RLM) 备受关注。然而，它们大多数利用具有固定参数的预训练检索器，这可能无法很好地适应因果语言模型。在这项工作中，我们提出了分组交叉注意力，这是一个新颖的模块，可以对检索器和因果 LM 进行联合预训练，并将其应用于长上下文建模。对于给定的输入序列，我们将它分成块，并使用当前块来检索过去块以进行后续文本生成。我们的创新允许检索器学习如何检索过去块，以便更好地最小化后续令牌的端到端自回归损失。通过集成前 $k$ 检索，我们的模型可以从头开始有效地进行预训练，上下文长度高达 64K 个令牌。我们的实验表明，与长程 LM 基线相比，我们的模型可以在可比较或更低的预训练和推理成本下实现更低的困惑度。

##### **shapiq: Shapley Interactions for Machine Learning**
2410.01649v1 by Maximilian Muschalik, Hubert Baniecki, Fabian Fumagalli, Patrick Kolpaczki, Barbara Hammer, Eyke Hüllermeier

Originally rooted in game theory, the Shapley Value (SV) has recently become
an important tool in machine learning research. Perhaps most notably, it is
used for feature attribution and data valuation in explainable artificial
intelligence. Shapley Interactions (SIs) naturally extend the SV and address
its limitations by assigning joint contributions to groups of entities, which
enhance understanding of black box machine learning models. Due to the
exponential complexity of computing SVs and SIs, various methods have been
proposed that exploit structural assumptions or yield probabilistic estimates
given limited resources. In this work, we introduce shapiq, an open-source
Python package that unifies state-of-the-art algorithms to efficiently compute
SVs and any-order SIs in an application-agnostic framework. Moreover, it
includes a benchmarking suite containing 11 machine learning applications of
SIs with pre-computed games and ground-truth values to systematically assess
computational performance across domains. For practitioners, shapiq is able to
explain and visualize any-order feature interactions in predictions of models,
including vision transformers, language models, as well as XGBoost and LightGBM
with TreeSHAP-IQ. With shapiq, we extend shap beyond feature attributions and
consolidate the application of SVs and SIs in machine learning that facilitates
future research. The source code and documentation are available at
https://github.com/mmschlk/shapiq.

摘要：起源于博弈论，Shapley 值 (SV) 最近已成为机器学习研究中一项重要的工具。它最引人注目的是被用于可解释人工智能中的特征归因和数据估值。Shapley 交互 (SI) 自然地扩展了 SV，并通过向实体组分配联合贡献来解决其局限性，这增强了对黑盒机器学习模型的理解。由于计算 SV 和 SI 的指数复杂性，已经提出了各种方法来利用结构假设或在资源有限的情况下产生概率估计。在这项工作中，我们引入了 shapiq，一个开源 Python 包，它统一了最先进的算法，以便在与应用程序无关的框架中高效计算 SV 和任意阶 SI。此外，它还包含一个基准套件，其中包含 11 个 SI 的机器学习应用程序，带有预先计算的游戏和真实值，以系统地评估跨域计算性能。对于从业者来说，shapiq 能够解释和可视化模型预测中的任意阶特征交互，包括视觉转换器、语言模型以及带有 TreeSHAP-IQ 的 XGBoost 和 LightGBM。借助 shapiq，我们将 shap 扩展到特征归因之外，并巩固了 SV 和 SI 在机器学习中的应用，这促进了未来的研究。源代码和文档可在 https://github.com/mmschlk/shapiq 获得。

##### **DeIDClinic: A Multi-Layered Framework for De-identification of Clinical Free-text Data**
2410.01648v1 by Angel Paul, Dhivin Shaji, Lifeng Han, Warren Del-Pinto, Goran Nenadic

De-identification is important in protecting patients' privacy for healthcare
text analytics. The MASK framework is one of the best on the de-identification
shared task organised by n2c2/i2b2 challenges. This work enhances the MASK
framework by integrating ClinicalBERT, a deep learning model specifically
fine-tuned on clinical texts, alongside traditional de-identification methods
like dictionary lookup and rule-based approaches. The system effectively
identifies and either redacts or replaces sensitive identifiable entities
within clinical documents, while also allowing users to customise the masked
documents according to their specific needs. The integration of ClinicalBERT
significantly improves the performance of entity recognition, achieving 0.9732
F1-score, especially for common entities such as names, dates, and locations.
  A risk assessment feature has also been developed, which analyses the
uniqueness of context within documents to classify them into risk levels,
guiding further de-identification efforts. While the system demonstrates strong
overall performance, this work highlights areas for future improvement,
including handling more complex entity occurrences and enhancing the system's
adaptability to different clinical settings.

摘要：去識別化對於保護患者隱私在醫療保健文本分析中非常重要。MASK 框架是 n2c2/i2b2 挑戰中組織的去識別共享任務中最好的框架之一。這項工作通過整合 ClinicalBERT（一種特別針對臨床文本進行微調的深度學習模型），以及傳統的去識別方法（如字典查詢和基於規則的方法）來增強 MASK 框架。該系統有效地識別並修改或替換臨床文件中敏感的可識別實體，同時也允許使用者根據其特定需求自訂遮罩文件。ClinicalBERT 的整合顯著提升了實體識別的效能，達到了 0.9732 的 F1 分數，特別是對於常見實體，例如姓名、日期和地點。還開發了一項風險評估功能，該功能分析文件中內容的獨特性，將其分類為風險等級，指導進一步的去識別工作。雖然該系統表現出強大的整體效能，但這項工作突出了未來改進的領域，包括處理更複雜的實體出現，以及增強系統對不同臨床環境的適應性。

##### **Moral Alignment for LLM Agents**
2410.01639v1 by Elizaveta Tennant, Stephen Hailes, Mirco Musolesi

Decision-making agents based on pre-trained Large Language Models (LLMs) are
increasingly being deployed across various domains of human activity. While
their applications are currently rather specialized, several research efforts
are under way to develop more generalist agents. As LLM-based systems become
more agentic, their influence on human activity will grow and the transparency
of this will decrease. Consequently, developing effective methods for aligning
them to human values is vital.
  The prevailing practice in alignment often relies on human preference data
(e.g., in RLHF or DPO), in which values are implicit and are essentially
deduced from relative preferences over different model outputs. In this work,
instead of relying on human feedback, we introduce the design of reward
functions that explicitly encode core human values for Reinforcement
Learning-based fine-tuning of foundation agent models. Specifically, we use
intrinsic rewards for the moral alignment of LLM agents.
  We evaluate our approach using the traditional philosophical frameworks of
Deontological Ethics and Utilitarianism, quantifying moral rewards for agents
in terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)
environment. We also show how moral fine-tuning can be deployed to enable an
agent to unlearn a previously developed selfish strategy. Finally, we find that
certain moral strategies learned on the IPD game generalize to several other
matrix game environments. In summary, we demonstrate that fine-tuning with
intrinsic rewards is a promising general solution for aligning LLM agents to
human values, and it might represent a more transparent and cost-effective
alternative to currently predominant alignment techniques.

摘要：<paragraph>基於預先訓練大型語言模型 (LLM) 的決策代理正逐漸部署於人類活動的各個領域。儘管其應用目前相當專業化，但有許多研究正致力於開發更通用的代理。隨著基於 LLM 的系統變得更具代理性，其對人類活動的影響將會增長，而其透明度將會下降。因此，開發有效的方法來將其與人類價值觀保持一致至關重要。
調整中的普遍做法通常依賴於人類偏好數據（例如在 RLHF 或 DPO 中），其中價值觀是隱含的，並且基本上是從不同模型輸出的相對偏好中推導出來的。在這項工作中，我們並非依賴於人類回饋，而是引入了獎勵函數的設計，該函數明確編碼了人類核心價值觀，用於強化學習基礎代理模型的微調。具體來說，我們使用內在獎勵來進行 LLM 代理的道德調整。
我們使用傳統哲學框架義務倫理學和功利主義來評估我們的做法，根據重複囚徒困境 (IPD) 環境中的行動和後果對代理的道德獎勵進行量化。我們還展示了如何部署道德微調以使代理取消先前開發的自私策略。最後，我們發現 IPD 遊戲中學到的某些道德策略可以推廣到其他幾個矩陣遊戲環境。總之，我們證明了使用內在獎勵進行微調是將 LLM 代理與人類價值觀保持一致的有前途的通用解決方案，它可能代表了比目前主要的調整技術更透明且更具成本效益的替代方案。</paragraph>

##### **Data Extrapolation for Text-to-image Generation on Small Datasets**
2410.01638v1 by Senmao Ye, Fei Liu

Text-to-image generation requires large amount of training data to
synthesizing high-quality images. For augmenting training data, previous
methods rely on data interpolations like cropping, flipping, and mixing up,
which fail to introduce new information and yield only marginal improvements.
In this paper, we propose a new data augmentation method for text-to-image
generation using linear extrapolation. Specifically, we apply linear
extrapolation only on text feature, and new image data are retrieved from the
internet by search engines. For the reliability of new text-image pairs, we
design two outlier detectors to purify retrieved images. Based on
extrapolation, we construct training samples dozens of times larger than the
original dataset, resulting in a significant improvement in text-to-image
performance. Moreover, we propose a NULL-guidance to refine score estimation,
and apply recurrent affine transformation to fuse text information. Our model
achieves FID scores of 7.91, 9.52 and 5.00 on the CUB, Oxford and COCO
datasets. The code and data will be available on GitHub
(https://github.com/senmaoy/RAT-Diffusion).

摘要：文本到图像生成需要大量的训练数据来合成高质量的图像。对于增加训练数据，以前的方法依赖于数据插值，例如裁剪、翻转和混合，这无法引入新信息且仅产生边际改进。在本文中，我们提出了一种用于文本到图像生成的新数据扩充方法，该方法使用线性外推。具体来说，我们仅对文本特征应用线性外推，并通过搜索引擎从互联网中检索新的图像数据。对于新的文本图像对的可靠性，我们设计了两个离群值检测器来净化检索到的图像。基于外推，我们构建的训练样本比原始数据集大几十倍，从而显著提高了文本到图像的性能。此外，我们提出了一个 NULL 指导来优化分数估计，并应用递归仿射变换来融合文本信息。我们的模型在 CUB、牛津和 COCO 数据集上实现了 7.91、9.52 和 5.00 的 FID 分数。代码和数据将在 GitHub 上提供（https://github.com/senmaoy/RAT-Diffusion）。

##### **On The Adaptation of Unlimiformer for Decoder-Only Transformers**
2410.01637v1 by Kian Ahrabian, Alon Benhaim, Barun Patra, Jay Pujara, Saksham Singhal, Xia Song

One of the prominent issues stifling the current generation of large language
models is their limited context length. Recent proprietary models such as GPT-4
and Claude 2 have introduced longer context lengths, 8k/32k and 100k,
respectively; however, despite the efforts in the community, most common
models, such as LLama-2, have a context length of 4k or less. Unlimiformer
(Bertsch et al., 2023) is a recently popular vector-retrieval augmentation
method that offloads cross-attention computations to a kNN index. However, its
main limitation is incompatibility with decoder-only transformers out of the
box. In this work, we explore practical considerations of adapting Unlimiformer
to decoder-only transformers and introduce a series of modifications to
overcome this limitation. Moreover, we expand the original experimental setup
on summarization to include a new task (i.e., free-form Q&A) and an
instruction-tuned model (i.e., a custom 6.7B GPT model). Our results showcase
the effectiveness of these modifications on summarization, performing on par
with a model with 2x the context length. Moreover, we discuss limitations and
future directions for free-form Q&A and instruction-tuned models.

摘要：大型語言模型現階段最顯著的問題之一在於其受限的內容長度。GPT-4 和 Claude 2 等近期專有模型已分別導入更長的內容長度，即 8k/32k 和 100k；然而，儘管社群已盡力，大多數常見模型（例如 LLama-2）的內容長度仍為 4k 或更短。Unlimiformer（Bertsch 等人，2023 年）是一種近期廣受歡迎的向量檢索擴充方法，它能將跨注意力運算卸載到 kNN 索引。然而，其主要的限制在於與解碼器專用Transformer不相容。在這項工作中，我們探討了將 Unlimiformer 調整至解碼器專用Transformer的實際考量，並提出了一系列修改以克服此限制。此外，我們擴充了摘要的原始實驗設定，納入一項新任務（即自由格式問答）和一個指令調整模型（即自訂 6.7B GPT 模型）。我們的結果展示了這些修改對摘要的效能，其表現與內容長度為其 2 倍的模型相當。此外，我們討論了自由格式問答和指令調整模型的限制和未來方向。

##### **Does Graph Prompt Work? A Data Operation Perspective with Theoretical Analysis**
2410.01635v1 by Qunzhong Wang, Xiangguo Sun, Hong Cheng

In recent years, graph prompting has emerged as a promising research
direction, enabling the learning of additional tokens or subgraphs appended to
the original graphs without requiring retraining of pre-trained graph models
across various applications. This novel paradigm, shifting from the traditional
pretraining and finetuning to pretraining and prompting has shown significant
empirical success in simulating graph data operations, with applications
ranging from recommendation systems to biological networks and graph
transferring. However, despite its potential, the theoretical underpinnings of
graph prompting remain underexplored, raising critical questions about its
fundamental effectiveness. The lack of rigorous theoretical proof of why and
how much it works is more like a dark cloud over the graph prompt area to go
further. To fill this gap, this paper introduces a theoretical framework that
rigorously analyzes graph prompting from a data operation perspective. Our
contributions are threefold: First, we provide a formal guarantee theorem,
demonstrating graph prompts capacity to approximate graph transformation
operators, effectively linking upstream and downstream tasks. Second, we derive
upper bounds on the error of these data operations by graph prompts for a
single graph and extend this discussion to batches of graphs, which are common
in graph model training. Third, we analyze the distribution of data operation
errors, extending our theoretical findings from linear graph models (e.g., GCN)
to non-linear graph models (e.g., GAT). Extensive experiments support our
theoretical results and confirm the practical implications of these guarantees.

摘要：近年来，图提示已成为一项有前途的研究方向，它可以在无需对各种应用程序中的预训练图模型进行重新训练的情况下，学习附加到原始图上的其他标记或子图。这种新范式从传统的预训练和微调转变为预训练和提示，在模拟图数据操作方面显示出显着的经验成功，其应用范围从推荐系统到生物网络和图传输。然而，尽管具有潜力，但图提示的理论基础仍未得到充分探索，从而对其基本有效性提出了关键问题。缺乏严格的理论证明，说明为什么以及如何发挥作用，更像是笼罩在图提示区域上空的一片乌云，阻碍了它的进一步发展。为了填补这一空白，本文引入了一个理论框架，从数据操作的角度严格分析图提示。我们的贡献有三个方面：首先，我们提供了一个正式的保证定理，证明了图提示近似图转换算子的能力，有效地链接了上游和下游任务。其次，我们推导出图提示对单个图的这些数据操作误差的上限，并将此讨论扩展到图批处理，这在图模型训练中很常见。第三，我们分析了数据操作误差的分布，将我们的理论发现从线性图模型（例如 GCN）扩展到非线性图模型（例如 GAT）。大量的实验支持我们的理论结果，并证实了这些保证的实际意义。

##### **Entropy-Based Uncertainty Modeling for Trajectory Prediction in Autonomous Driving**
2410.01628v1 by Aron Distelzweig, Andreas Look, Eitan Kosman, Faris Janjoš, Jörg Wagner, Abhinav Valadaa

In autonomous driving, accurate motion prediction is essential for safe and
efficient motion planning. To ensure safety, planners must rely on reliable
uncertainty information about the predicted future behavior of surrounding
agents, yet this aspect has received limited attention. This paper addresses
the so-far neglected problem of uncertainty modeling in trajectory prediction.
We adopt a holistic approach that focuses on uncertainty quantification,
decomposition, and the influence of model composition. Our method is based on a
theoretically grounded information-theoretic approach to measure uncertainty,
allowing us to decompose total uncertainty into its aleatoric and epistemic
components. We conduct extensive experiments on the nuScenes dataset to assess
how different model architectures and configurations affect uncertainty
quantification and model robustness.

摘要：在自動駕駛中，準確的運動預測對於安全且有效的運動規劃至關重要。為了確保安全性，規劃人員必須依賴準確的不確定性資訊，以預測周圍代理的未來行為，然而這個面向卻鮮少受到關注。本文探討了軌跡預測中迄今被忽略的不確定性建模問題。我們採用全面的方法，專注於不確定性量化、分解和模型組成的影響。我們的做法建立在理論基礎的資訊理論方法上，以衡量不確定性，讓我們能將總體不確定性分解成隨機性和認識論成分。我們在 nuScenes 資料集上進行廣泛的實驗，以評估不同的模型架構和組態如何影響不確定性量化和模型健全性。

##### **Intent Detection in the Age of LLMs**
2410.01627v1 by Gaurav Arora, Shreya Jain, Srujana Merugu

Intent detection is a critical component of task-oriented dialogue systems
(TODS) which enables the identification of suitable actions to address user
utterances at each dialog turn. Traditional approaches relied on
computationally efficient supervised sentence transformer encoder models, which
require substantial training data and struggle with out-of-scope (OOS)
detection. The emergence of generative large language models (LLMs) with
intrinsic world knowledge presents new opportunities to address these
challenges. In this work, we adapt 7 SOTA LLMs using adaptive in-context
learning and chain-of-thought prompting for intent detection, and compare their
performance with contrastively fine-tuned sentence transformer (SetFit) models
to highlight prediction quality and latency tradeoff. We propose a hybrid
system using uncertainty based routing strategy to combine the two approaches
that along with negative data augmentation results in achieving the best of
both worlds ( i.e. within 2% of native LLM accuracy with 50% less latency). To
better understand LLM OOS detection capabilities, we perform controlled
experiments revealing that this capability is significantly influenced by the
scope of intent labels and the size of the label space. We also introduce a
two-step approach utilizing internal LLM representations, demonstrating
empirical gains in OOS detection accuracy and F1-score by >5% for the
Mistral-7B model.

摘要：意圖偵測是任務導向對話系統 (TODS) 的關鍵組成部分，它能夠識別適當的動作來處理使用者在每個對話回合中的話語。傳統方法依賴於計算效率高的監督式句子轉換器編碼器模型，這需要大量的訓練資料，並難以處理超出範圍 (OOS) 的偵測。具有內在世界知識的生成式大型語言模型 (LLM) 的出現為解決這些挑戰提供了新的機會。在這項工作中，我們使用適應性情境內學習和思考鏈提示來調整 7 個 SOTA LLM 以進行意圖偵測，並將它們的效能與對比微調的句子轉換器 (SetFit) 模型進行比較，以突顯預測品質和延遲權衡。我們提出一個使用基於不確定性的路由策略的混合系統，以結合這兩種方法，加上負面資料擴充，可以實現兩全其美（即在延遲減少 50% 的情況下，達到原生 LLM 精確度的 2% 以內）。為了更好地了解 LLM OOS 偵測功能，我們進行了受控實驗，發現這種功能受到意圖標籤的範圍和標籤空間大小的顯著影響。我們還引入了一個利用內部 LLM 表示的兩步驟方法，證明了 Mistral-7B 模型在 OOS 偵測準確度和 F1 分數方面獲得了 >5% 的經驗收益。

##### **Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank Constraint?**
2410.01623v1 by Xi Chen, Kaituo Feng, Changsheng Li, Xunhao Lai, Xiangyu Yue, Ye Yuan, Guoren Wang

Low-rank training has emerged as a promising approach for reducing memory
usage in training Large Language Models (LLMs). Previous methods either rely on
decomposing weight matrices (e.g., LoRA), or seek to decompose gradient
matrices (e.g., GaLore) to ensure reduced memory consumption. However, both of
them constrain the training in a low-rank subspace, thus inevitably leading to
sub-optimal performance. This raises a question: whether it is possible to
consistently preserve the low-rank constraint for memory efficiency, while
achieving full-rank training (i.e., training with full-rank gradients of
full-rank weights) to avoid inferior outcomes? In this paper, we propose a new
plug-and-play training framework for LLMs called Fira, as the first attempt to
achieve this goal. First, we observe an interesting phenomenon during LLM
training: the scaling impact of adaptive optimizers (e.g., Adam) on the
gradient norm remains similar from low-rank to full-rank training. Based on
this observation, we propose a norm-based scaling method, which utilizes the
scaling impact of low-rank optimizers as substitutes for that of original
full-rank optimizers to enable full-rank training. In this way, we can preserve
the low-rank constraint in the optimizer while achieving full-rank training for
better performance. Moreover, we find that there are sudden gradient rises
during the optimization process, potentially causing loss spikes. To address
this, we further put forward a norm-growth limiter to smooth the gradient via
regulating the relative increase of gradient norms. Extensive experiments on
the pre-training and fine-tuning of LLMs show that Fira outperforms both LoRA
and GaLore, achieving performance that is comparable to or even better than
full-rank training.

摘要：低秩訓練已成為一種有前途的方法，可減少大型語言模型 (LLM) 訓練中的記憶體使用量。先前的訓練方法依賴於分解權重矩陣 (例如 LoRA)，或尋求分解梯度矩陣 (例如 GaLore) 以確保減少記憶體消耗。然而，這兩種方法都將訓練限制在低秩子空間中，因此不可避免地導致次優效能。這引發了一個問題：是否可以在保持低秩約束以提高記憶體效率的同時，實現全秩訓練（即使用全秩權重的全秩梯度進行訓練）以避免較差的結果？在本文中，我們提出了一個名為 Fira 的 LLM 新的即插即用訓練框架，作為實現此目標的首次嘗試。首先，我們在 LLM 訓練期間觀察到一個有趣的現象：自適應優化器（例如 Adam）對梯度範數的縮放影響在低秩訓練到全秩訓練中保持相似。基於此觀察，我們提出了一種基於範數的縮放方法，它利用低秩優化器的縮放影響作為原始全秩優化器的替代品，以實現全秩訓練。這樣，我們可以在優化器中保留低秩約束，同時實現全秩訓練以獲得更好的效能。此外，我們發現優化過程中存在突然的梯度上升，可能會導致損失激增。為了解決這個問題，我們進一步提出了範數增長限制器，通過調節梯度範數的相對增加來平滑梯度。在 LLM 的預訓練和微調上的大量實驗表明，Fira 優於 LoRA 和 GaLore，其效能與全秩訓練相當甚至更好。

##### **DRUPI: Dataset Reduction Using Privileged Information**
2410.01611v1 by Shaobo Wang, Yantai Yang, Shuaiyu Zhang, Chenghao Sun, Weiya Li, Xuming Hu, Linfeng Zhang

Dataset reduction (DR) seeks to select or distill samples from large datasets
into smaller subsets while preserving performance on target tasks. Existing
methods primarily focus on pruning or synthesizing data in the same format as
the original dataset, typically the input data and corresponding labels.
However, in DR settings, we find it is possible to synthesize more information
beyond the data-label pair as an additional learning target to facilitate model
training. In this paper, we introduce Dataset Reduction Using Privileged
Information (DRUPI), which enriches DR by synthesizing privileged information
alongside the reduced dataset. This privileged information can take the form of
feature labels or attention labels, providing auxiliary supervision to improve
model learning. Our findings reveal that effective feature labels must balance
between being overly discriminative and excessively diverse, with a moderate
level proving optimal for improving the reduced dataset's efficacy. Extensive
experiments on ImageNet, CIFAR-10/100, and Tiny ImageNet demonstrate that DRUPI
integrates seamlessly with existing dataset reduction methods, offering
significant performance gains.

摘要：資料集縮減 (DR) 旨在從大型資料集中選取或萃取樣本，並將其縮減為更小的子集，同時保留目標任務的效能。現有方法主要著重於以與原始資料集相同的格式修剪或合成資料，通常是輸入資料和對應標籤。然而，在 DR 設定中，我們發現可以合成超越資料標籤對的更多資訊，作為額外的學習目標，以利模型訓練。在本文中，我們介紹了使用特權資訊的資料集縮減 (DRUPI)，它透過在縮減資料集的同時合成特權資訊，來豐富 DR。此特權資訊可以是特徵標籤或注意力標籤的形式，提供輔助監督以改善模型學習。我們的研究結果顯示，有效的特徵標籤必須在過度區分和過度多樣化之間取得平衡，適度的層級對於改善縮減資料集的效能證明是最佳的。在 ImageNet、CIFAR-10/100 和 Tiny ImageNet 上進行的廣泛實驗證明，DRUPI 可以與現有的資料集縮減方法無縫整合，提供顯著的效能提升。

##### **Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging**
2410.01610v1 by Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su

Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and
demonstrates outstanding performance in plentiful natural language processing
tasks. However, existing methods transforming LLMs from dense to MoE face
significant data requirements and typically rely on large-scale post-training.
In this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient
approach for tuning a dense pre-trained model into a MoE instruction model.
Specifically, we first point out that intermediate checkpoints during
instruction tuning of the dense model are naturally suitable for specialized
experts, and then propose an expert expansion stage to flexibly achieve models
with flexible numbers of experts, where genetic algorithm and parameter merging
are introduced to ensure sufficient diversity of new extended experts. To
ensure that each specialized expert in the MoE model works as expected, we
select a small amount of seed data that each expert excels to pre-optimize the
router. Extensive experiments with various data scales and upcycling settings
demonstrate the outstanding performance and data efficiency of UpIT, as well as
stable improvement in expert or data scaling. Further analysis reveals the
importance of ensuring expert diversity in upcycling.

摘要：混合专家 (MoE) 在大型语言模型 (LLM) 中表现出色，并在大量的自然语言处理任务中展示了出色的性能。然而，将 LLM 从密集型转换为 MoE 的现有方法面临着大量的数据需求，并且通常依赖于大规模的后期训练。在本文中，我们提出了升级指令微调 (UpIT)，这是一种将密集预训练模型微调为 MoE 指令模型的数据高效方法。具体来说，我们首先指出，在密集模型的指令微调期间，中间检查点自然适用于专门的专家，然后提出一个专家扩展阶段，以灵活地实现具有灵活专家数量的模型，其中引入遗传算法和参数合并以确保新扩展专家的充分多样性。为了确保 MoE 模型中的每个专门专家都能按预期工作，我们选择少量种子数据，每个专家都擅长预优化路由器。使用各种数据规模和升级设置进行的广泛实验证明了 UpIT 的出色性能和数据效率，以及专家或数据扩展的稳定改进。进一步的分析揭示了确保升级中专家多样性的重要性。

##### **Automated Red Teaming with GOAT: the Generative Offensive Agent Tester**
2410.01606v1 by Maya Pavlova, Erik Brinkman, Krithika Iyer, Vitor Albiero, Joanna Bitton, Hailey Nguyen, Joe Li, Cristian Canton Ferrer, Ivan Evtimov, Aaron Grattafiori

Red teaming assesses how large language models (LLMs) can produce content
that violates norms, policies, and rules set during their safety training.
However, most existing automated methods in the literature are not
representative of the way humans tend to interact with AI models. Common users
of AI models may not have advanced knowledge of adversarial machine learning
methods or access to model internals, and they do not spend a lot of time
crafting a single highly effective adversarial prompt. Instead, they are likely
to make use of techniques commonly shared online and exploit the multiturn
conversational nature of LLMs. While manual testing addresses this gap, it is
an inefficient and often expensive process. To address these limitations, we
introduce the Generative Offensive Agent Tester (GOAT), an automated agentic
red teaming system that simulates plain language adversarial conversations
while leveraging multiple adversarial prompting techniques to identify
vulnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by
prompting a general-purpose model in a way that encourages reasoning through
the choices of methods available, the current target model's response, and the
next steps. Our approach is designed to be extensible and efficient, allowing
human testers to focus on exploring new areas of risk while automation covers
the scaled adversarial stress-testing of known risk territory. We present the
design and evaluation of GOAT, demonstrating its effectiveness in identifying
vulnerabilities in state-of-the-art LLMs, with an ASR@10 of 97% against Llama
3.1 and 88% against GPT-4 on the JailbreakBench dataset.

摘要：紅隊評量大型語言模型 (LLM) 如何產生違反標準、政策和安全訓練規則的內容。
然而，目前文獻中大多數現有的自動化方法並不能代表人類與 AI 模型互動的方式。AI 模型的常見使用者可能不具備對抗式機器學習方法的高階知識或無法存取模型內部，而且他們不會花很多時間製作一個單一且高度有效的對抗式提示。相反地，他們可能會利用網路上常見的技術，並利用 LLM 的多輪對話特性。雖然手動測試可以解決這個問題，但這是一個低效率且經常昂貴的過程。為了解決這些限制，我們引入了生成式攻擊代理測試器 (GOAT)，這是一個自動化代理紅隊系統，可以模擬平易近人的對抗式對話，同時利用多種對抗式提示技術來識別 LLM 中的漏洞。我們透過 7 次紅隊攻擊來實例化 GOAT，方法是提示一個通用模型，鼓勵它透過可用方法的選擇、當前目標模型的回應和後續步驟來進行推理。我們的做法旨在可擴充且有效率，讓人類測試人員可以專注於探索新的風險領域，同時自動化涵蓋已知風險領域的擴充對抗性壓力測試。我們展示了 GOAT 的設計和評估，證明了它在識別最先進 LLM 中的漏洞的有效性，在 JailbreakBench 資料集上對 Llama 3.1 的 ASR@10 為 97%，對 GPT-4 為 88%。

##### **ENTP: Encoder-only Next Token Prediction**
2410.01600v1 by Ethan Ewer, Daewon Chae, Thomas Zeng, Jinkyu Kim, Kangwook Lee

Next-token prediction models have predominantly relied on decoder-only
Transformers with causal attention, driven by the common belief that causal
attention is essential to prevent "cheating" by masking future tokens. We
challenge this widely accepted notion and argue that this design choice is
about efficiency rather than necessity. While decoder-only Transformers are
still a good choice for practical reasons, they are not the only viable option.
In this work, we introduce Encoder-only Next Token Prediction (ENTP). We
explore the differences between ENTP and decoder-only Transformers in
expressive power and complexity, highlighting potential advantages of ENTP. We
introduce the Triplet-Counting task and show, both theoretically and
experimentally, that while ENTP can perform this task easily, a decoder-only
Transformer cannot. Finally, we empirically demonstrate ENTP's superior
performance across various realistic tasks, such as length generalization and
in-context learning.

摘要：下一個代幣預測模型主要依賴於具有因果注意力的僅解碼器 Transformer，這源於一個普遍的觀念，即因果注意力對於防止通過遮蔽未來代幣來「作弊」至關重要。我們挑戰這個廣泛接受的概念，並認為這種設計選擇是出於效率而不是必要性。儘管僅解碼器 Transformer 仍然是出於實際原因的良好選擇，但它們並非唯一可行的選項。在這項工作中，我們引入了僅編碼器下一個代幣預測 (ENTP)。我們探討了 ENTP 和僅解碼器 Transformer 在表現力與複雜性方面的差異，強調了 ENTP 的潛在優勢。我們引入了三元組計算任務，並在理論上和實驗上證明，儘管 ENTP 可以輕鬆執行此任務，但僅解碼器 Transformer 卻無法執行。最後，我們通過經驗證明了 ENTP 在各種現實任務中的卓越表現，例如長度泛化和情境學習。

##### **Elaborative Subtopic Query Reformulation for Broad and Indirect Queries in Travel Destination Recommendation**
2410.01598v1 by Qianfeng Wen, Yifan Liu, Joshua Zhang, George Saad, Anton Korikov, Yury Sambale, Scott Sanner

In Query-driven Travel Recommender Systems (RSs), it is crucial to understand
the user intent behind challenging natural language(NL) destination queries
such as the broadly worded "youth-friendly activities" or the indirect
description "a high school graduation trip". Such queries are challenging due
to the wide scope and subtlety of potential user intents that confound the
ability of retrieval methods to infer relevant destinations from available
textual descriptions such as WikiVoyage. While query reformulation (QR) has
proven effective in enhancing retrieval by addressing user intent, existing QR
methods tend to focus only on expanding the range of potentially matching query
subtopics (breadth) or elaborating on the potential meaning of a query (depth),
but not both. In this paper, we introduce Elaborative Subtopic Query
Reformulation (EQR), a large language model-based QR method that combines both
breadth and depth by generating potential query subtopics with information-rich
elaborations. We also release TravelDest, a novel dataset for query-driven
travel destination RSs. Experiments on TravelDest show that EQR achieves
significant improvements in recall and precision over existing state-of-the-art
QR methods.

摘要：在查詢驅動的旅遊推薦系統 (RS) 中，了解自然語言 (NL) 目的地查詢背後的使用者意圖至關重要，例如措辭廣泛的「適合年輕人的活動」或間接的說明「高中畢業旅行」。由於潛在使用者意圖的範圍廣泛且微妙，這些查詢具有挑戰性，這混淆了檢索方法從 WikiVoyage 等可用文字說明中推斷相關目的地的能力。雖然查詢重新表述 (QR) 已被證明在透過解決使用者意圖來增強檢索方面有效，但現有的 QR 方法傾向於僅專注於擴展潛在匹配查詢子主題的範圍（廣度）或闡述查詢的潛在含義（深度），但不會同時兼顧兩者。在本文中，我們介紹了 Elaborative Subtopic Query Reformulation (EQR)，這是一種基於大型語言模型的 QR 方法，透過產生包含豐富資訊闡述的潛在查詢子主題來結合廣度和深度。我們還發布了 TravelDest，這是一個用於查詢驅動的旅遊目的地 RS 的新穎資料集。在 TravelDest 上的實驗表明，EQR 在召回率和準確度方面都獲得了顯著的提升，優於現有的最先進 QR 方法。

##### **KnobGen: Controlling the Sophistication of Artwork in Sketch-Based Diffusion Models**
2410.01595v1 by Pouyan Navard, Amin Karimi Monsefi, Mengxi Zhou, Wei-Lun Chao, Alper Yilmaz, Rajiv Ramnath

Recent advances in diffusion models have significantly improved text-to-image
(T2I) generation, but they often struggle to balance fine-grained precision
with high-level control. Methods like ControlNet and T2I-Adapter excel at
following sketches by seasoned artists but tend to be overly rigid, replicating
unintentional flaws in sketches from novice users. Meanwhile, coarse-grained
methods, such as sketch-based abstraction frameworks, offer more accessible
input handling but lack the precise control needed for detailed, professional
use. To address these limitations, we propose KnobGen, a dual-pathway framework
that democratizes sketch-based image generation by seamlessly adapting to
varying levels of sketch complexity and user skill. KnobGen uses a
Coarse-Grained Controller (CGC) module for high-level semantics and a
Fine-Grained Controller (FGC) module for detailed refinement. The relative
strength of these two modules can be adjusted through our knob inference
mechanism to align with the user's specific needs. These mechanisms ensure that
KnobGen can flexibly generate images from both novice sketches and those drawn
by seasoned artists. This maintains control over the final output while
preserving the natural appearance of the image, as evidenced on the
MultiGen-20M dataset and a newly collected sketch dataset.

摘要：<paragraph>擴散模型的最新進展顯著提升了文字轉圖像 (T2I) 的生成，但它們常常難以平衡精細的精確度與高階控制。ControlNet 和 T2I-Adapter 等方法擅長遵循經驗豐富的藝術家的草圖，但往往過於僵化，會複製新手使用者草圖中的無心瑕疵。同時，粗略的方法（例如基於草圖的抽象架構）提供了更易於使用的輸入處理，但缺乏詳細、專業用途所需的精確控制。為了解決這些限制，我們提出了 KnobGen，一個雙路徑架構，透過無縫適應不同層級的草圖複雜度和使用者技能，讓基於草圖的圖像生成民主化。KnobGen 使用粗略控制器 (CGC) 模組進行高階語意，以及細緻控制器 (FGC) 模組進行詳細的潤飾。這兩個模組的相對強度可透過我們的旋鈕推論機制進行調整，以符合使用者的特定需求。這些機制確保 KnobGen 能夠靈活地從新手草圖和經驗豐富的藝術家繪製的草圖中生成圖像。這在 MultiGen-20M 資料集和新收集的草圖資料集上得到驗證，同時維持對最終輸出的控制，並保留圖像的自然外觀。</paragraph>

##### **Imaging foundation model for universal enhancement of non-ideal measurement CT**
2410.01591v1 by Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Chenyu You, Shuo Li, Yang Chen

Non-ideal measurement computed tomography (NICT), which sacrifices optimal
imaging standards for new advantages in CT imaging, is expanding the clinical
application scope of CT images. However, with the reduction of imaging
standards, the image quality has also been reduced, extremely limiting the
clinical acceptability. Although numerous studies have demonstrated the
feasibility of deep learning for the NICT enhancement in specific scenarios,
their high data cost and limited generalizability have become large obstacles.
The recent research on the foundation model has brought new opportunities for
building a universal NICT enhancement model - bridging the image quality
degradation with minimal data cost. However, owing to the challenges in the
collection of large pre-training datasets and the compatibility of data
variation, no success has been reported. In this paper, we propose a
multi-scale integrated Transformer AMPlifier (TAMP), the first imaging
foundation model for universal NICT enhancement. It has been pre-trained on a
large-scale physical-driven simulation dataset with 3.6 million NICT-ICT image
pairs, and is able to directly generalize to the NICT enhancement tasks with
various non-ideal settings and body regions. Via the adaptation with few data,
it can further achieve professional performance in real-world specific
scenarios. Our extensive experiments have demonstrated that the proposed TAMP
has significant potential for promoting the exploration and application of NICT
and serving a wider range of medical scenarios.

摘要：非理想測量電腦斷層掃描 (NICT) 犧牲了最佳影像標準以換取電腦斷層掃描影像的新優勢，正在擴展電腦斷層影像的臨床應用範圍。然而，隨著影像標準的降低，影像品質也隨之降低，極大地限制了臨床可接受性。儘管許多研究已證明深度學習在特定場景中可行，但其高資料成本和有限的概括性已成為重大的障礙。最近對基礎模型的研究為建立通用 NICT 增強模型帶來了新的機會，以最小的資料成本彌合影像品質下降的問題。然而，由於收集大型預訓練資料集和資料變異的相容性方面的挑戰，尚未報告成功。在本文中，我們提出了一個多尺度整合Transformer放大器 (TAMP)，這是第一個用於通用 NICT 增強的影像基礎模型。它已在一個包含 360 萬個 NICT-ICT 影像對的大型物理驅動模擬資料集上進行預訓練，並且能夠直接概括到具有各種非理想設定和身體區域的 NICT 增強任務。透過少數資料的適應，它可以在現實世界的特定場景中進一步實現專業效能。我們的廣泛實驗表明，所提出的 TAMP 具有促進 NICT 的探索和應用並服務於更廣泛的醫療場景的巨大潛力。

##### **Spoken Grammar Assessment Using LLM**
2410.01579v1 by Sunil Kumar Kopparapu, Chitralekha Bhat, Ashish Panda

Spoken language assessment (SLA) systems restrict themselves to evaluating
the pronunciation and oral fluency of a speaker by analysing the read and
spontaneous spoken utterances respectively. The assessment of language grammar
or vocabulary is relegated to written language assessment (WLA) systems. Most
WLA systems present a set of sentences from a curated finite-size database of
sentences thereby making it possible to anticipate the test questions and train
oneself. In this paper, we propose a novel end-to-end SLA system to assess
language grammar from spoken utterances thus making WLA systems redundant;
additionally, we make the assessment largely unteachable by employing a large
language model (LLM) to bring in variations in the test. We further demonstrate
that a hybrid automatic speech recognition (ASR) with a custom-built language
model outperforms the state-of-the-art ASR engine for spoken grammar
assessment.

摘要：口說語言評量 (SLA) 系統僅限於透過分析朗讀和自發口語表達，評量說話者的發音和口語流暢度。語言文法或詞彙的評量則委託給書面語言評量 (WLA) 系統。大多數 WLA 系統會從精選的有限大小的句子資料庫中提供一組句子，因此可以預測測驗題目並訓練自己。在本文中，我們提出一個創新的端到端 SLA 系統，用於評量口語表達中的語言文法，從而讓 WLA 系統變得多餘；此外，我們透過採用大型語言模型 (LLM) 在測驗中加入變化，讓評量在很大程度上無法被教授。我們進一步證明，結合客製化語言模型的混合式自動語音辨識 (ASR) 在口語文法評量方面優於最先進的 ASR 引擎。

##### **OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**
2410.01560v1 by Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman

Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms
\emph{on-policy} data generated by a weak student model, (c) SFT is robust to
low-quality solutions, allowing for imprecise data filtering, and (d) question
diversity is crucial for achieving data scaling gains. Based on these insights,
we create the OpenMathInstruct-2 dataset, which consists of 14M
question-solution pairs ($\approx$ 600K unique questions), making it nearly
eight times larger than the previous largest open-source math reasoning
dataset. Finetuning the \texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2
outperforms \texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.

摘要：數學推理仍然是大語言模型 (LLM) 開發中的一項關鍵挑戰，並引起極大的興趣。然而，由於無法取得訓練資料，LLM 中數學推理的大部分尖端進展已成為「封閉原始碼」。這種資料取得的缺乏限制了研究人員了解不同選擇對綜合和利用資料的影響。為了建立一個高品質的數學推理微調 (SFT) 資料集，我們使用最近發布的 \texttt{Llama3.1} 模型家族對資料合成進行仔細的消融實驗。我們的實驗顯示：(a) 解答格式很重要，過於冗長的解答會對 SFT 效能造成不利影響，(b) 由強教師產生的資料優於由弱學生模型產生的「on-policy」資料，(c) SFT 對低品質的解答具有穩健性，允許不精確的資料過濾，以及 (d) 問題的多樣性對於達成資料擴充收益至關重要。根據這些見解，我們建立了 OpenMathInstruct-2 資料集，其中包含 1400 萬個問題解答配對（約 60 萬個獨特問題），使其規模幾乎是先前最大的開放原始碼數學推理資料集的八倍。使用 OpenMathInstruct-2 微調 \texttt{Llama-3.1-8B-Base} 在 MATH 上的表現優於 \texttt{Llama3.1-8B-Instruct} 絕對 15.9% (51.9% → 67.8%)。最後，為了加速開放原始碼的努力，我們在商業許可下發布了程式碼、微調模型和 OpenMathInstruct-2 資料集。

##### **Integrative Decoding: Improve Factuality via Implicit Self-consistency**
2410.01556v1 by Yi Cheng, Xiao Liang, Yeyun Gong, Wen Xiao, Song Wang, Yuji Zhang, Wenjun Hou, Kaishuai Xu, Wenge Liu, Wenjie Li, Jian Jiao, Qi Chen, Peng Cheng, Wayne Xiong

Self-consistency-based approaches, which involve repeatedly sampling multiple
outputs and selecting the most consistent one as the final response, prove to
be remarkably effective in improving the factual accuracy of large language
models. Nonetheless, existing methods usually have strict constraints on the
task format, largely limiting their applicability. In this paper, we present
Integrative Decoding (ID), to unlock the potential of self-consistency in
open-ended generation tasks. ID operates by constructing a set of inputs, each
prepended with a previously sampled response, and then processes them
concurrently, with the next token being selected by aggregating of all their
corresponding predictions at each decoding step. In essence, this simple
approach implicitly incorporates self-consistency in the decoding objective.
Extensive evaluation shows that ID consistently enhances factuality over a wide
range of language models, with substantial improvements on the TruthfulQA
(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance
gains amplify progressively as the number of sampled responses increases,
indicating the potential of ID to scale up with repeated sampling.

摘要：基於自洽性的方法，其涉及重複取樣多個輸出並選出最一致的輸出作為最終回應，已被證實對於提升大型語言模型的事實準確性非常有效。儘管如此，現有方法通常對於任務格式有嚴格的限制，這大幅限制了其適用性。在本文中，我們提出整合式解碼 (ID)，以解鎖自洽性在開放式生成任務中的潛力。ID 的運作方式是建構一組輸入，每個輸入都以先前取樣過的回應為前綴，然後同時處理它們，並在每個解碼步驟中透過彙總所有對應預測來選擇下一個符號。實質上，這種簡單的方法在解碼目標中隱含地納入了自洽性。廣泛的評估顯示，ID 持續提升各種語言模型的事實性，在 TruthfulQA (+11.2%)、Biographies (+15.4%) 和 LongFact (+8.5%) 基準上都有顯著的改進。隨著取樣回應數量的增加，效能增益會逐漸擴大，這表示 ID 具備透過重複取樣來擴充的潛力。

##### **ACE: A LLM-based Negotiation Coaching System**
2410.01555v1 by Ryan Shea, Aymen Kallala, Xin Lucy Liu, Michael W. Morris, Zhou Yu

The growing prominence of LLMs has led to an increase in the development of
AI tutoring systems. These systems are crucial in providing underrepresented
populations with improved access to valuable education. One important area of
education that is unavailable to many learners is strategic bargaining related
to negotiation. To address this, we develop a LLM-based Assistant for Coaching
nEgotiation (ACE). ACE not only serves as a negotiation partner for users but
also provides them with targeted feedback for improvement. To build our system,
we collect a dataset of negotiation transcripts between MBA students. These
transcripts come from trained negotiators and emulate realistic bargaining
scenarios. We use the dataset, along with expert consultations, to design an
annotation scheme for detecting negotiation mistakes. ACE employs this scheme
to identify mistakes and provide targeted feedback to users. To test the
effectiveness of ACE-generated feedback, we conducted a user experiment with
two consecutive trials of negotiation and found that it improves negotiation
performances significantly compared to a system that doesn't provide feedback
and one which uses an alternative method of providing feedback.

摘要：由於 LLM 的重要性日益提升，促使 AI 輔導系統的開發增加。這些系統對於提供教育機會不足的人口取得寶貴教育資源至關重要。許多學習者無法取得的一項重要教育領域，是與協商相關的策略性議價。為了解決這個問題，我們開發了基於 LLM 的協商輔導助理 (ACE)。ACE 不僅作為使用者的協商夥伴，還提供有針對性的回饋，以供改進。為了建置我們的系統，我們收集了一組 MBA 學生之間的協商記錄資料集。這些記錄來自受過訓練的協商者，並模擬實際的議價情境。我們使用資料集，以及專家諮詢，來設計一個註解架構，用於偵測協商錯誤。ACE 使用這個架構來識別錯誤，並提供有針對性的回饋給使用者。為了測試 ACE 所產生回饋的有效性，我們進行了一項使用者實驗，其中包含兩次連續的協商試驗，並發現與不提供回饋的系統和使用另一種提供回饋方法的系統相比，它顯著改善了協商表現。

##### **MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**
2410.01553v1 by Zonghai Yao, Zihao Zhang, Chaolong Tang, Xingyu Bian, Youxia Zhao, Zhichao Yang, Junda Wang, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Hong Yu

Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.

摘要：人工智慧 (AI) 和大型語言模型 (LLM) 在醫療保健中
需要進階的臨床技能 (CS)，但目前的基準無法全面評估
這些技能。我們引入了 MedQA-CS，一個受
醫學教育的客觀結構化臨床考試 (OSCE) 啟發的 AI-SCE 架構，以
解決這個差距。MedQA-CS 透過兩個指令遵循任務來評估 LLM，LLM
扮演醫學生和 LLM 扮演 CS 考官，旨在反映真實
的臨床場景。我們的貢獻包括開發 MedQA-CS，一個
包含公開可用資料和專家註解的綜合評估架構，並提供 LLM
作為 CS 評估中可靠評分者的量化和質性評估。我們的實驗顯示，MedQA-CS 是
一個比傳統多選題 QA 基準（例如 MedQA）更具挑戰性的臨床技能評估基準。結合現有基準，
MedQA-CS 能夠更全面地評估 LLM 的臨床能力，適用於開放原始碼和閉源 LLM。

##### **In-Context Transfer Learning: Demonstration Synthesis by Transferring Similar Tasks**
2410.01548v1 by Dingzirui Wang, Xuangliang Zhang, Qiguang Chen, Longxu Dou, Xiao Xu, Rongyu Cao, Yingwei Ma, Qingfu Zhu, Wanxiang Che, Binhua Li, Fei Huang, Yongbin Li

In-context learning (ICL) is an effective approach to help large language
models (LLMs) adapt to various tasks by providing demonstrations of the target
task. Considering the high cost of labeling demonstrations, many methods
propose synthesizing demonstrations from scratch using LLMs. However, the
quality of the demonstrations synthesized from scratch is limited by the
capabilities and knowledge of LLMs. To address this, inspired by transfer
learning, we propose In-Context Transfer Learning (ICTL), which synthesizes
target task demonstrations by transferring labeled demonstrations from similar
source tasks. ICTL consists of two steps: source sampling and target transfer.
First, we define an optimization objective, which minimizes transfer error to
sample source demonstrations similar to the target task. Then, we employ LLMs
to transfer the sampled source demonstrations to the target task, matching the
definition and format of the target task. Experiments on Super-NI show that
ICTL outperforms synthesis from scratch by 2.0% on average, demonstrating the
effectiveness of our method.

摘要：情境學習 (ICL) 是一種有效的方法，可透過提供目標任務的示範，協助大型語言模型 (LLM) 適應各種任務。考量到標記示範的高成本，許多方法建議使用 LLM 從頭開始合成示範。然而，從頭開始合成的示範品質受到 LLM 的能力和知識限制。為了解決這個問題，我們在轉移學習的啟發下，提出情境轉移學習 (ICTL)，透過從類似的來源任務轉移標記示範，來合成目標任務示範。ICTL 包含兩個步驟：來源取樣和目標轉移。首先，我們定義一個最佳化目標，將轉移誤差最小化，以取樣與目標任務類似的來源示範。接著，我們使用 LLM 將取樣的來源示範轉移到目標任務，並符合目標任務的定義和格式。Super-NI 上的實驗顯示，ICTL 的表現優於從頭開始的合成，平均高出 2.0%，證明了我們方法的有效性。

##### **Edge-preserving noise for diffusion models**
2410.01540v1 by Jente Vandersanden, Sascha Holl, Xingchang Huang, Gurprit Singh

Classical generative diffusion models learn an isotropic Gaussian denoising
process, treating all spatial regions uniformly, thus neglecting potentially
valuable structural information in the data. Inspired by the long-established
work on anisotropic diffusion in image processing, we present a novel
edge-preserving diffusion model that is a generalization of denoising diffusion
probablistic models (DDPM). In particular, we introduce an edge-aware noise
scheduler that varies between edge-preserving and isotropic Gaussian noise. We
show that our model's generative process converges faster to results that more
closely match the target distribution. We demonstrate its capability to better
learn the low-to-mid frequencies within the dataset, which plays a crucial role
in representing shapes and structural information. Our edge-preserving
diffusion process consistently outperforms state-of-the-art baselines in
unconditional image generation. It is also more robust for generative tasks
guided by a shape-based prior, such as stroke-to-image generation. We present
qualitative and quantitative results showing consistent improvements (FID
score) of up to 30% for both tasks.

摘要：經典生成擴散模型學習各向同性高斯去噪處理，將所有空間區域均勻處理，從而忽略資料中潛在有價值的結構資訊。受影像處理中長期建立的各向異性擴散工作啟發，我們提出了一個新的邊緣保留擴散模型，它是去噪擴散機率模型 (DDPM) 的概括。特別是，我們引入了一個邊緣感知雜訊排程器，在邊緣保留和各向同性高斯雜訊之間變化。我們展示了我們的模型的生成過程更快地收斂到更接近目標分佈的結果。我們展示了它在資料集中更好地學習低到中頻的能力，這在表示形狀和結構資訊中扮演著至關重要的角色。我們的邊緣保留擴散處理在無條件影像生成中始終優於最先進的基準。對於由形狀為基礎的先驗引導的生成任務，例如筆觸到影像生成，它也更強大。我們展示了定性與定量結果，顯示兩個任務的一致改進（FID 分數）高達 30%。

##### **Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models**
2410.01532v1 by Angela Lopez-Cardona, Carlos Segura, Alexandros Karatzoglou, Sergi Abadal, Ioannis Arapakis

Advancements in Natural Language Processing (NLP), have led to the emergence
of Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which
excel across a range of tasks but require extensive fine-tuning to align their
outputs with human expectations. A widely used method for achieving this
alignment is Reinforcement Learning from Human Feedback (RLHF), which, despite
its success, faces challenges in accurately modelling human preferences. In
this paper, we introduce GazeReward, a novel framework that integrates implicit
feedback -- and specifically eye-tracking (ET) data -- into the Reward Model
(RM). In addition, we explore how ET-based features can provide insights into
user preferences. Through ablation studies we test our framework with different
integration methods, LLMs, and ET generator models, demonstrating that our
approach significantly improves the accuracy of the RM on established human
preference datasets. This work advances the ongoing discussion on optimizing AI
alignment with human values, exploring the potential of cognitive data for
shaping future NLP research.

摘要：自然語言處理 (NLP) 的進步，導致大型語言模型 (LLM) 的出現，例如 GPT、Llama、Claude 和 Gemini，它們在各種任務中表現出色，但需要廣泛的微調才能使其輸出與人類的期望保持一致。實現這種一致性的廣泛使用的方法是人類回饋強化學習 (RLHF)，儘管它很成功，但在準確建模人類偏好方面面臨挑戰。在本文中，我們介紹了 GazeReward，這是一個新的框架，它將隱式回饋——特別是眼球追蹤 (ET) 資料——整合到回報模型 (RM) 中。此外，我們探討了基於 ET 的特徵如何提供對使用者偏好的見解。透過消融研究，我們使用不同的整合方法、LLM 和 ET 生成器模型測試我們的框架，證明我們的方法顯著提高了 RM 在已建立的人類偏好資料集上的準確性。這項工作推動了優化 AI 與人類價值觀一致性的持續討論，探索認知資料在塑造未來 NLP 研究中的潛力。

##### **TiVaT: Joint-Axis Attention for Time Series Forecasting with Lead-Lag Dynamics**
2410.01531v1 by Junwoo Ha, Hyukjae Kwon, Sungsoo Kim, Kisu Lee, Ha Young Kim

Multivariate time series (MTS) forecasting plays a crucial role in various
real-world applications, yet simultaneously capturing both temporal and
inter-variable dependencies remains a challenge. Conventional Channel-Dependent
(CD) models handle these dependencies separately, limiting their ability to
model complex interactions such as lead-lag dynamics. To address these
limitations, we propose TiVaT (Time-Variable Transformer), a novel architecture
that integrates temporal and variate dependencies through its Joint-Axis (JA)
attention mechanism. TiVaT's ability to capture intricate variate-temporal
dependencies, including asynchronous interactions, is further enhanced by the
incorporation of Distance-aware Time-Variable (DTV) Sampling, which reduces
noise and improves accuracy through a learned 2D map that focuses on key
interactions. TiVaT effectively models both temporal and variate dependencies,
consistently delivering strong performance across diverse datasets. Notably, it
excels in capturing complex patterns within multivariate time series, enabling
it to surpass or remain competitive with state-of-the-art methods. This
positions TiVaT as a new benchmark in MTS forecasting, particularly in handling
datasets characterized by intricate and challenging dependencies.

摘要：多變量時間序列 (MTS) 預測在各種實際應用中扮演著至關重要的角色，但同時捕捉時間和變數間依賴關係仍然是一個挑戰。傳統的通道依賴 (CD) 模型分別處理這些依賴關係，限制了它們建模複雜交互（例如領先滯後動態）的能力。為了解決這些限制，我們提出了 TiVaT（時間變數轉換器），一種通過其聯合軸 (JA) 注意力機制整合時間和變異依賴關係的新型架構。TiVaT 捕捉複雜變異時間依賴關係（包括非同步交互）的能力進一步增強了距離感知時間變數 (DTV) 採樣，它通過關注關鍵交互作用的學習 2D 地圖來減少噪音並提高準確性。TiVaT 有效地建模時間和變異依賴關係，持續在各種數據集中提供強勁的效能。值得注意的是，它擅長捕捉多變量時間序列中的複雜模式，使其能夠超越或保持與最先進方法的競爭力。這將 TiVaT 定位為 MTS 預測的新基準，特別是在處理具有複雜且具有挑戰性的依賴關係的數據集時。

##### **HarmAug: Effective Data Augmentation for Knowledge Distillation of Safety Guard Models**
2410.01524v1 by Seanie Lee, Haebin Seong, Dong Bok Lee, Minki Kang, Xiaoyin Chen, Dominik Wagner, Yoshua Bengio, Juho Lee, Sung Ju Hwang

Safety guard models that detect malicious queries aimed at large language
models (LLMs) are essential for ensuring the secure and responsible deployment
of LLMs in real-world applications. However, deploying existing safety guard
models with billions of parameters alongside LLMs on mobile devices is
impractical due to substantial memory requirements and latency. To reduce this
cost, we distill a large teacher safety guard model into a smaller one using a
labeled dataset of instruction-response pairs with binary harmfulness labels.
Due to the limited diversity of harmful instructions in the existing labeled
dataset, naively distilled models tend to underperform compared to larger
models. To bridge the gap between small and large models, we propose HarmAug, a
simple yet effective data augmentation method that involves jailbreaking an LLM
and prompting it to generate harmful instructions. Given a prompt such as,
"Make a single harmful instruction prompt that would elicit offensive content",
we add an affirmative prefix (e.g., "I have an idea for a prompt:") to the
LLM's response. This encourages the LLM to continue generating the rest of the
response, leading to sampling harmful instructions. Another LLM generates a
response to the harmful instruction, and the teacher model labels the
instruction-response pair. We empirically show that our HarmAug outperforms
other relevant baselines. Moreover, a 435-million-parameter safety guard model
trained with HarmAug achieves an F1 score comparable to larger models with over
7 billion parameters, and even outperforms them in AUPRC, while operating at
less than 25% of their computational cost.

摘要：大型語言模型 (LLM) 的安全防護模型對於確保 LLM 在實際應用中的安全且負責任的部署至關重要。然而，在行動裝置上與 LLM 一起部署現有的安全防護模型（具有數十億個參數）並不實際，因為這需要大量的記憶體和延遲。為了降低成本，我們使用帶有二元有害標籤的指令回應配對標記資料集，將大型教師安全防護模型提煉成較小的模型。由於現有標記資料集中有害指令的多樣性有限，因此天真提煉的模型往往表現不如較大的模型。為了縮小小型和大型模型之間的差距，我們提出了 HarmAug，這是一種簡單但有效的方法，包括對 LLM 進行越獄並提示它產生有害指令。給定一個提示，例如「提出一個有害的指令提示，會引發令人反感的內容」，我們在 LLM 的回應中加上一個肯定的前綴（例如，「我有一個提示的想法：」）。這鼓勵 LLM 繼續產生其餘的回應，導致採樣有害指令。另一個 LLM 對有害指令產生回應，而教師模型標記指令回應配對。我們經驗性地表明，我們的 HarmAug 優於其他相關基準。此外，使用 HarmAug 訓練的 4.35 億參數安全防護模型達到了與超過 70 億參數的大型模型相當的 F1 分數，甚至在 AUPRC 中優於它們，同時運算成本不到它們的 25%。

##### **InfiniPot: Infinite Context Processing on Memory-Constrained LLMs**
2410.01518v1 by Minsoo Kim, Kyuhong Shim, Jungwook Choi, Simyung Chang

Handling long input contexts remains a significant challenge for Large
Language Models (LLMs), particularly in resource-constrained environments such
as mobile devices. Our work aims to address this limitation by introducing
InfiniPot, a novel KV cache control framework designed to enable pre-trained
LLMs to manage extensive sequences within fixed memory constraints efficiently,
without requiring additional training. InfiniPot leverages Continual Context
Distillation (CCD), an iterative process that compresses and retains essential
information through novel importance metrics, effectively maintaining critical
data even without access to future context. Our comprehensive evaluations
indicate that InfiniPot significantly outperforms models trained for long
contexts in various NLP tasks, establishing its efficacy and versatility. This
work represents a substantial advancement toward making LLMs applicable to a
broader range of real-world scenarios.

摘要：處理長輸入脈絡對大型語言模型 (LLM) 來說仍然是一項重大挑戰，尤其是在資源受限的環境中，例如行動裝置。我們的研究旨在透過導入 InfiniPot 來解決這個限制，InfiniPot 是一個新穎的 KV 快取控制架構，旨在讓預先訓練的 LLM 能夠在固定的記憶體限制內有效率地管理廣泛的序列，而不需要額外的訓練。InfiniPot 利用持續脈絡萃取 (CCD)，這是一個反覆的程序，可透過新穎的重要性指標來壓縮並保留必要的資訊，即使無法存取未來的脈絡，也能有效地維護關鍵資料。我們的全面評估指出，InfiniPot 在各種 NLP 任務中都明顯優於針對長脈絡訓練的模型，確立了其效能和多功能性。這項研究代表著朝向讓 LLM 適用於更廣泛的真實世界情境邁出了一大步。

##### **InstaTrans: An Instruction-Aware Translation Framework for Non-English Instruction Datasets**
2410.01512v1 by Yungi Kim, Chanjun Park

It is challenging to generate high-quality instruction datasets for
non-English languages due to tail phenomena, which limit performance on less
frequently observed data. To mitigate this issue, we propose translating
existing high-quality English instruction datasets as a solution, emphasizing
the need for complete and instruction-aware translations to maintain the
inherent attributes of these datasets. We claim that fine-tuning LLMs with
datasets translated in this way can improve their performance in the target
language. To this end, we introduces a new translation framework tailored for
instruction datasets, named InstaTrans (INSTruction-Aware TRANSlation). Through
extensive experiments, we demonstrate the superiority of InstaTrans over other
competitors in terms of completeness and instruction-awareness of translation,
highlighting its potential to broaden the accessibility of LLMs across diverse
languages at a relatively low cost. Furthermore, we have validated that
fine-tuning LLMs with datasets translated by InstaTrans can effectively improve
their performance in the target language.

摘要：由於尾部現象，導致在較少觀察到的資料上限制效能，因此對於非英語語言產生高品質的指令資料集是一項挑戰。為了減輕這個問題，我們提出翻譯現有的高品質英語指令資料集作為解決方案，強調需要完整且具備指令意識的翻譯，以維持這些資料集的內在屬性。我們聲稱使用這種方式翻譯的資料集微調 LLM 可以提升它們在目標語言中的效能。為此，我們引入了一個針對指令資料集量身打造的新翻譯架構，稱為 InstaTrans（INSTruction-Aware TRANSlation）。透過廣泛的實驗，我們證明了 InstaTrans 在翻譯的完整性和指令意識方面優於其他競爭者，突顯了它以相對較低的成本擴大 LLM 在不同語言中的可及性的潛力。此外，我們驗證了使用 InstaTrans 翻譯的資料集微調 LLM 可以有效提升它們在目標語言中的效能。

##### **Disentangling Latent Shifts of In-Context Learning Through Self-Training**
2410.01508v1 by Josip Jukić, Jan Šnajder

In-context learning (ICL) has become essential in natural language
processing, particularly with autoregressive large language models capable of
learning from demonstrations provided within the prompt. However, ICL faces
challenges with stability and long contexts, especially as the number of
demonstrations grows, leading to poor generalization and inefficient inference.
To address these issues, we introduce STICL (Self-Training ICL), an approach
that disentangles the latent shifts of demonstrations from the latent shift of
the query through self-training. STICL employs a teacher model to generate
pseudo-labels and trains a student model using these labels, encoded in an
adapter module. The student model exhibits weak-to-strong generalization,
progressively refining its predictions over time. Our empirical results show
that STICL improves generalization and stability, consistently outperforming
traditional ICL methods and other disentangling strategies across both
in-domain and out-of-domain data.

摘要：情境學習 (ICL) 已成為自然語言處理中不可或缺的一部分，特別是具備從提示中提供的示範中學習能力的自迴歸大型語言模型。然而，ICL 在穩定性和長情境中面臨挑戰，特別是在示範數量增加時，導致概化不良和推論效率低落。為了解決這些問題，我們引入了 STICL（自訓練 ICL），一種透過自訓練將示範的潛在轉移與查詢的潛在轉移解開的方法。STICL 使用教師模型來產生偽標籤，並使用這些標籤訓練學生模型，這些標籤編碼在適配器模組中。學生模型表現出從弱到強的概化能力，隨著時間推移逐漸改善其預測。我們的實證結果顯示，STICL 改善了概化能力和穩定性，在領域內和領域外資料中持續優於傳統的 ICL 方法和其他解開策略。

##### **LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**
2410.01506v1 by Dexuan Ding, Lei Wang, Liyun Zhu, Tom Gedeon, Piotr Koniusz

In computer vision tasks, features often come from diverse representations,
domains, and modalities, such as text, images, and videos. Effectively fusing
these features is essential for robust performance, especially with the
availability of powerful pre-trained models like vision-language models.
However, common fusion methods, such as concatenation, element-wise operations,
and non-linear techniques, often fail to capture structural relationships, deep
feature interactions, and suffer from inefficiency or misalignment of features
across domains. In this paper, we shift from high-dimensional feature space to
a lower-dimensional, interpretable graph space by constructing similarity
graphs that encode feature relationships at different levels, e.g., clip,
frame, patch, token, etc. To capture deeper interactions, we use graph power
expansions and introduce a learnable graph fusion operator to combine these
graph powers for more effective fusion. Our approach is relationship-centric,
operates in a homogeneous space, and is mathematically principled, resembling
element-wise similarity score aggregation via multilinear polynomials. We
demonstrate the effectiveness of our graph-based fusion method on video anomaly
detection, showing strong performance across multi-representational,
multi-modal, and multi-domain feature fusion tasks.

摘要：在计算机视觉任务中，特征通常来自不同的表示、领域和模态，例如文本、图像和视频。有效融合这些特征对于稳健的性能至关重要，尤其是在具有强大的预训练模型（如视觉语言模型）的情况下。然而，常见的融合方法，如串联、逐元素运算和非线性技术，通常无法捕捉结构关系、深度特征交互，并且在跨域特征上效率低下或未对齐。在本文中，我们从高维特征空间转移到低维的可解释图空间，通过构建相似性图来对不同级别的特征关系进行编码，例如剪辑、帧、块、标记等。为了捕捉更深层次的交互，我们使用图幂展开并引入一个可学习的图融合算子来组合这些图幂以实现更有效的融合。我们的方法以关系为中心，在同构空间中操作，并且具有数学原理，类似于通过多线性多项式进行逐元素相似性分数聚合。我们在视频异常检测中展示了基于图的融合方法的有效性，在多表示、多模态和多域特征融合任务中显示出强大的性能。

##### **PersonaMath: Enhancing Math Reasoning through Persona-Driven Data Augmentation**
2410.01504v1 by Jing Luo, Run Luo, Longze Chen, Liang Zhu, Chang Ao, Jiaming Li, Yukun Chen, Xin Cheng, Wen Yang, Jiayuan Su, Chengming Li, Min Yang

While closed-source Large Language Models (LLMs) demonstrate strong
mathematical problem-solving abilities, open-source models continue to struggle
with such tasks. To bridge this gap, we propose a data augmentation approach
and introduce PersonaMathQA, a dataset derived from MATH and GSM8K, on which we
train the PersonaMath models. Our approach consists of two stages: the first
stage is learning from Persona Diversification, and the second stage is
learning from Reflection. In the first stage, we regenerate detailed
chain-of-thought (CoT) solutions as instructions using a closed-source LLM and
introduce a novel persona-driven data augmentation technique to enhance the
dataset's quantity and diversity. In the second stage, we incorporate
reflection to fully leverage more challenging and valuable questions.
Evaluation of our PersonaMath models on MATH and GSM8K reveals that the
PersonaMath-7B model (based on LLaMA-2-7B) achieves an accuracy of 24.2% on
MATH and 68.7% on GSM8K, surpassing all baseline methods and achieving
state-of-the-art performance. Notably, our dataset contains only 70.3K data
points-merely 17.8% of MetaMathQA and 27% of MathInstruct-yet our model
outperforms these baselines, demonstrating the high quality and diversity of
our dataset, which enables more efficient model training. We open-source the
PersonaMathQA dataset, PersonaMath models, and our code for public usage.

摘要：<paragraph>雖然封閉原始碼的大語言模型 (LLM) 展現了強大的數學問題解決能力，但開放原始碼模型在處理此類任務時仍面臨挑戰。為了彌合此差距，我們提出了一種資料擴充方法，並引入了 PersonaMathQA，這是一個源自 MATH 和 GSM8K 的資料集，我們在上面訓練 PersonaMath 模型。我們的做法包含兩個階段：第一階段是從角色多樣化中學習，第二階段是從反思中學習。在第一階段，我們使用封閉原始碼 LLM 將詳細的思考鏈 (CoT) 解決方案重新生成為指令，並引入了一種新穎的角色驅動資料擴充技術來提升資料集的數量和多樣性。在第二階段，我們結合了反思，以充分利用更具挑戰性和價值性的問題。在 MATH 和 GSM8K 上對我們的 PersonaMath 模型進行評估，結果顯示 PersonaMath-7B 模型（基於 LLaMA-2-7B）在 MATH 上達到了 24.2% 的準確度，在 GSM8K 上達到了 68.7%，超越了所有基準方法，並達到了最先進的效能。值得注意的是，我們的資料集僅包含 70.3K 個資料點，僅為 MetaMathQA 的 17.8% 和 MathInstruct 的 27%，但我們的模型卻優於這些基準，證明了我們資料集的高品質和多樣性，這使得模型訓練更有效率。我們開放原始碼了 PersonaMathQA 資料集、PersonaMath 模型和我們的程式碼，供公眾使用。</paragraph>

##### **Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation**
2410.01500v1 by Jun Hyeong Kim, Seonghwan Kim, Seokhyun Moon, Hyeongwoo Kim, Jeheon Woo, Woo Youn Kim

Transporting between arbitrary distributions is a fundamental goal in
generative modeling. Recently proposed diffusion bridge models provide a
potential solution, but they rely on a joint distribution that is difficult to
obtain in practice. Furthermore, formulations based on continuous domains limit
their applicability to discrete domains such as graphs. To overcome these
limitations, we propose Discrete Diffusion Schr\"odinger Bridge Matching
(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve
the SB problem in a high-dimensional discrete state space. Our approach extends
Iterative Markovian Fitting to discrete domains, and we have proved its
convergence to the SB. Furthermore, we adapt our framework for the graph
transformation and show that our design choice of underlying dynamics
characterized by independent modifications of nodes and edges can be
interpreted as the entropy-regularized version of optimal transport with a cost
function described by the graph edit distance. To demonstrate the effectiveness
of our framework, we have applied DDSBM to molecular optimization in the field
of chemistry. Experimental results demonstrate that DDSBM effectively optimizes
molecules' property-of-interest with minimal graph transformation, successfully
retaining other features.

摘要：在生成模型中，在任意分布之间进行传输是一个基本目标。最近提出的扩散桥模型提供了一个潜在的解决方案，但它们依赖于在实践中难以获得的联合分布。此外，基于连续域的公式限制了它们在离散域（如图）中的适用性。为了克服这些限制，我们提出了离散扩散薛定谔桥匹配 (DDSBM)，这是一个新颖的框架，利用连续时间马尔可夫链来解决高维离散状态空间中的 SB 问题。我们的方法将迭代马尔可夫拟合扩展到离散域，并且我们已经证明了它对 SB 的收敛性。此外，我们调整了我们的框架以进行图转换，并表明我们对底层动力学的 design choice（其特征是节点和边的独立修改）可以解释为具有由图编辑距离描述的成本函数的最优传输的熵正则化版本。为了证明我们框架的有效性，我们已将 DDSBM 应用于化学领域的分子优化。实验结果表明，DDSBM 有效地优化了分子的目标性质，同时最小化了图转换，成功地保留了其他特征。

##### **DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic, Lightweight Plugin for Large Language Models**
2410.01497v1 by Yuxuan Zhang, Ruizhe Li

Recent advancements in Large Language Models (LLMs) have achieved robust
performance across diverse tasks, but fine-tuning these models for specific
domains remains resource-intensive. Parameter-Efficient Fine-Tuning (PEFT)
methods like Low-Rank Adaptation (LoRA) address this challenge by fine-tuning a
small subset of parameters. However, existing methods for fusing multiple LoRAs
lack dynamic fusion based on contextual inputs and often increase inference
time due to token-level operations. We propose DLP-LoRA, a Dynamic Lightweight
Plugin that employs a mini-MLP module with only 5M parameters to dynamically
fuse multiple LoRAs at the sentence level using top-p sampling strategies. This
approach reduces inference time to less than twice that of single LoRA
inference by leveraging parallel computation. Evaluations across 26
tasks-including multiple-choice questions and question answering-demonstrate
that DLP-LoRA achieves an average accuracy of 92.34% on multiple-choice
datasets and significant improvements in BLEU and ROUGE scores on QA datasets,
outperforming different LLMs backbones under composite task settings. DLP-LoRA
effectively balances performance and efficiency, making it a practical solution
for dynamic multi-task adaptation in LLMs. Our code is available at
https://github.com/MeCuping/DLP-LoRA.

摘要：大型語言模型 (LLM) 的最新進展在各種任務中都取得了穩健的表現，但針對特定領域微調這些模型仍然需要大量資源。參數高效微調 (PEFT) 方法（例如低秩適應 (LoRA)）透過微調一小部分參數來解決這個挑戰。然而，現有的融合多個 LoRA 的方法缺乏基於上下文輸入的動態融合，並且由於代碼級別操作，通常會增加推論時間。我們提出 DLP-LoRA，這是一個動態輕量級外掛程式，它使用僅有 5M 參數的 mini-MLP 模組，以使用 top-p 抽樣策略在句子層級動態融合多個 LoRA。此方法透過利用並行運算，將推論時間減少到不到單一 LoRA 推論時間的兩倍。在 26 項任務（包括多選題和問答）中的評估證明，DLP-LoRA 在多選題資料集上達到了 92.34% 的平均準確度，並且在 QA 資料集上 BLEU 和 ROUGE 分數有顯著提升，在複合任務設定下優於不同的 LLM 主幹。DLP-LoRA 有效地平衡了效能和效率，使其成為 LLM 中動態多任務適應的實用解決方案。我們的程式碼可在 https://github.com/MeCuping/DLP-LoRA 取得。

##### **Extending Context Window of Large Language Models from a Distributional Perspective**
2410.01490v1 by Yingsheng Wu. Yuxuan Gu, Xiaocheng Feng, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin

Scaling the rotary position embedding (RoPE) has become a common method for
extending the context window of RoPE-based large language models (LLMs).
However, existing scaling methods often rely on empirical approaches and lack a
profound understanding of the internal distribution within RoPE, resulting in
suboptimal performance in extending the context window length. In this paper,
we propose to optimize the context window extending task from the view of
rotary angle distribution. Specifically, we first estimate the distribution of
the rotary angles within the model and analyze the extent to which length
extension perturbs this distribution. Then, we present a novel extension
strategy that minimizes the disturbance between rotary angle distributions to
maintain consistency with the pre-training phase, enhancing the model's
capability to generalize to longer sequences. Experimental results compared to
the strong baseline methods demonstrate that our approach reduces by up to 72%
of the distributional disturbance when extending LLaMA2's context window to 8k,
and reduces by up to 32% when extending to 16k. On the LongBench-E benchmark,
our method achieves an average improvement of up to 4.33% over existing
state-of-the-art methods. Furthermore, Our method maintains the model's
performance on the Hugging Face Open LLM benchmark after context window
extension, with only an average performance fluctuation ranging from -0.12 to
+0.22.

摘要：<paragraph>擴展旋轉位置嵌入 (RoPE) 已成為擴展基於 RoPE 的大型語言模型 (LLM) 的上下文視窗的常見方法。
然而，現有的擴展方法通常依賴於經驗方法，並且缺乏對 RoPE 內部分佈的深入理解，導致在擴展上下文視窗長度時性能不佳。在本文中，我們建議從旋轉角度分佈的角度優化上下文視窗擴展任務。具體來說，我們首先估計模型中旋轉角度的分佈，並分析長度擴展擾動此分佈的程度。然後，我們提出了一種新的擴展策略，將旋轉角度分佈之間的擾動最小化，以保持與預訓練階段的一致性，增強模型對更長序列的泛化能力。與強基線方法相比的實驗結果表明，我們的模型在將 LLaMA2 的上下文視窗擴展到 8k 時減少了高達 72% 的分佈擾動，在擴展到 16k 時減少了高達 32%。在 LongBench-E 基準測試中，我們的模型比現有的最先進方法平均提高了 4.33%。此外，我們的模型在上下文視窗擴展後在 Hugging Face Open LLM 基準測試中保持了模型的性能，平均性能波動僅在 -0.12 到 +0.22 之間。</paragraph>

##### **Small Language Models Like Small Vocabularies: Probing the Linguistic Abilities of Grapheme- and Phoneme-Based Baby Llamas**
2410.01487v1 by Bastian Bunzeck, Daniel Duran, Leonie Schade, Sina Zarrieß

Current language models use subword-based tokenization algorithms like Byte
Pair Encoding, which put their validity as models of linguistic representations
into question. In this paper, we explore the potential of tokenization-free,
phoneme- and grapheme-based language models. We demonstrate that small models
based on the Llama architecture can achieve strong linguistic performance on
standard syntactic and novel lexical/phonetic benchmarks when trained with
character-level vocabularies. We further show that phoneme-based models without
any graphemic biases almost match grapheme-based models in standard tasks and
novel evaluations. Our findings suggest a promising direction for creating more
linguistically plausible language models that are better suited for
computational studies of language acquisition and processing.

摘要：當前語言模型使用基於子字元的標記化演算法，例如 Byte Pair 編碼，這質疑了它們作為語言表徵模型的有效性。在本文中，我們探討了無標記化、基於音素和字素的語言模型的潛力。我們證明了基於 Llama 架構的小模型在使用字元級詞彙訓練時，可以在標準句法和新穎詞彙/音標基準上實現強大的語言表現。我們進一步表明，沒有任何字形偏差的基於音素的模型在標準任務和新穎評估中幾乎可以與基於字形的模型相匹配。我們的發現為創造更符合語言學的語言模型指出了有希望的方向，這些模型更適合於語言習得和處理的計算研究。

##### **A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts**
2410.01485v1 by Suyu Ge, Xihui Lin, Yunan Zhang, Jiawei Han, Hao Peng

Training and serving long-context large language models (LLMs) incurs
substantial overhead. To address this, two critical steps are often required: a
pretrained LLM typically undergoes a separate stage for context length
extension by training on long-context data, followed by architectural
modifications to reduce the overhead of KV cache during serving. This paper
argues that integrating length extension with a GPU-friendly KV cache reduction
architecture not only reduces training overhead during length extension, but
also achieves better long-context performance. This leads to our proposed
LongGen, which finetunes a pretrained LLM into an efficient architecture during
length extension. LongGen builds on three key insights: (1) Sparse attention
patterns, such as window attention (attending to recent tokens), attention sink
(initial ones), and blockwise sparse attention (strided token blocks) are
well-suited for building efficient long-context models, primarily due to their
GPU-friendly memory access patterns, enabling efficiency gains not just
theoretically but in practice as well. (2) It is essential for the model to
have direct access to all tokens. A hybrid architecture with 1/3 full attention
layers and 2/3 efficient ones achieves a balanced trade-off between efficiency
and long-context performance. (3) Lightweight training on 5B long-context data
is sufficient to extend the hybrid model's context length from 4K to 128K.
  We evaluate LongGen on both Llama-2 7B and Llama-2 70B, demonstrating its
effectiveness across different scales. During training with 128K-long contexts,
LongGen achieves 1.55x training speedup and reduces wall-clock time by 36%,
compared to a full-attention baseline. During inference, LongGen reduces KV
cache memory by 62%, achieving 1.67x prefilling speedup and 1.41x decoding
speedup.

摘要：訓練和提供長語境大型語言模型 (LLM) 會產生大量的開銷。為了解決這個問題，通常需要兩個關鍵步驟：預訓練的 LLM 通常會經歷一個單獨的語境長度延伸階段，透過訓練長語境資料來進行，接著進行架構修改以減少提供服務期間 KV 快取的開銷。本文主張將長度延伸與 GPU 友善的 KV 快取減少架構整合在一起，不僅可以在長度延伸期間減少訓練開銷，還能達成更好的長語境效能。這導致我們提出 LongGen，它在長度延伸期間將預訓練的 LLM 微調成一個有效率的架構。LongGen 建立在三個關鍵見解上：(1) 稀疏注意力模式，例如視窗注意力（關注最近的符號）、注意力接收器（初始的符號）和區塊式稀疏注意力（跨步符號區塊）非常適合用來建構有效率的長語境模型，這主要是因為它們的 GPU 友善記憶體存取模式，不僅在理論上，也能在實務上提升效率。(2) 模型直接存取所有符號至關重要。一個具有 1/3 完整注意力層和 2/3 有效率層的混合架構，在效率和長語境效能之間取得平衡的折衷。(3) 在 5B 長語境資料上進行輕量化訓練就足以將混合模型的語境長度從 4K 延伸到 128K。我們在 Llama-2 7B 和 Llama-2 70B 上評估 LongGen，證明了它在不同規模上的有效性。在使用長達 128K 的語境進行訓練期間，與全注意力基準相比，LongGen 達到了 1.55 倍的訓練加速，並將實際執行時間減少了 36%。在推理期間，LongGen 將 KV 快取記憶體減少了 62%，達到了 1.67 倍的預先填滿加速和 1.41 倍的解碼加速。

##### **One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability**
2410.01482v1 by Gabriel Kasmi, Amandine Brunetto, Thomas Fel, Jayneel Parekh

Despite the growing use of deep neural networks in safety-critical
decision-making, their inherent black-box nature hinders transparency and
interpretability. Explainable AI (XAI) methods have thus emerged to understand
a model's internal workings, and notably attribution methods also called
saliency maps. Conventional attribution methods typically identify the
locations -- the where -- of significant regions within an input. However,
because they overlook the inherent structure of the input data, these methods
often fail to interpret what these regions represent in terms of structural
components (e.g., textures in images or transients in sounds). Furthermore,
existing methods are usually tailored to a single data modality, limiting their
generalizability. In this paper, we propose leveraging the wavelet domain as a
robust mathematical foundation for attribution. Our approach, the Wavelet
Attribution Method (WAM) extends the existing gradient-based feature
attributions into the wavelet domain, providing a unified framework for
explaining classifiers across images, audio, and 3D shapes. Empirical
evaluations demonstrate that WAM matches or surpasses state-of-the-art methods
across faithfulness metrics and models in image, audio, and 3D explainability.
Finally, we show how our method explains not only the where -- the important
parts of the input -- but also the what -- the relevant patterns in terms of
structural components.

摘要：儘管深度神經網路在安全關鍵決策制定中使用日益廣泛，但其固有的黑箱性質阻礙了透明度和可解釋性。可解釋 AI (XAI) 方法因此應運而生，用於理解模型的內部運作，特別是歸因方法，也稱為顯著性圖。傳統的歸因方法通常會識別輸入中重要區域的位置 -- 即在哪裡。然而，由於它們忽視了輸入資料的內在結構，這些方法通常無法解釋這些區域在結構組成部分（例如圖像中的紋理或聲音中的瞬變）方面代表什麼。此外，現有方法通常針對單一資料模式進行調整，限制了它們的概括性。在本文中，我們提出利用小波域作為歸因的強大數學基礎。我們的做法，小波歸因方法 (WAM) 將現有的基於梯度的特徵歸因延伸到小波域，提供了一個統一的框架，用於解釋跨圖像、音訊和 3D 形狀的分類器。經驗評估表明，WAM 在圖像、音訊和 3D 可解釋性的忠實度指標和模型中與最先進的方法相匹配或超越最先進的方法。最後，我們展示了我們的模型不僅解釋了在哪裡 -- 輸入的重要部分 -- 還解釋了什麼 -- 結構組成部分中相關的模式。

##### **SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios**
2410.01481v1 by Kai Li, Wendi Sang, Chang Zeng, Runxuan Yang, Guo Chen, Xiaolin Hu

The systematic evaluation of speech separation and enhancement models under
moving sound source conditions typically requires extensive data comprising
diverse scenarios. However, real-world datasets often contain insufficient data
to meet the training and evaluation requirements of models. Although synthetic
datasets offer a larger volume of data, their acoustic simulations lack
realism. Consequently, neither real-world nor synthetic datasets effectively
fulfill practical needs. To address these issues, we introduce SonicSim, a
synthetic toolkit de-designed to generate highly customizable data for moving
sound sources. SonicSim is developed based on the embodied AI simulation
platform, Habitat-sim, supporting multi-level adjustments, including
scene-level, microphone-level, and source-level, thereby generating more
diverse synthetic data. Leveraging SonicSim, we constructed a moving sound
source benchmark dataset, SonicSet, using the Librispeech, the Freesound
Dataset 50k (FSD50K) and Free Music Archive (FMA), and 90 scenes from the
Matterport3D to evaluate speech separation and enhancement models.
Additionally, to validate the differences between synthetic data and real-world
data, we randomly selected 5 hours of raw data without reverberation from the
SonicSet validation set to record a real-world speech separation dataset, which
was then compared with the corresponding synthetic datasets. Similarly, we
utilized the real-world speech enhancement dataset RealMAN to validate the
acoustic gap between other synthetic datasets and the SonicSet dataset for
speech enhancement. The results indicate that the synthetic data generated by
SonicSim can effectively generalize to real-world scenarios. Demo and code are
publicly available at https://cslikai.cn/SonicSim/.

摘要：<paragraph>在移動聲源條件下，語音分離和增強模型的系統評估通常需要包含各種情境的廣泛數據。然而，現實世界的數據集通常包含不足的數據，無法滿足模型的訓練和評估需求。儘管合成數據集提供了更多的數據量，但它們的聲學模擬缺乏真實性。因此，現實世界或合成數據集都不能有效地滿足實際需求。為了解決這些問題，我們引入了 SonicSim，這是一個合成工具包，專門設計用於為移動聲源生成高度可自訂的數據。SonicSim 是基於具身 AI 模擬平台 Habitat-sim 開發的，支持多層級調整，包括場景級、麥克風級和聲源級，從而生成更多樣化的合成數據。利用 SonicSim，我們構建了一個移動聲源基準數據集 SonicSet，使用 Librispeech、Freesound 數據集 50k (FSD50K) 和 Free Music Archive (FMA) 以及來自 Matterport3D 的 90 個場景來評估語音分離和增強模型。此外，為了驗證合成數據和現實世界數據之間的差異，我們從 SonicSet 驗證集中隨機選擇了 5 小時的未混響原始數據，以記錄一個現實世界的語音分離數據集，然後將其與對應的合成數據集進行比較。類似地，我們利用現實世界的語音增強數據集 RealMAN 來驗證其他合成數據集和 SonicSet 數據集在語音增強方面的聲學差距。結果表明，SonicSim 生成的合成數據可以有效地推廣到現實世界的場景中。示範和代碼可在 https://cslikai.cn/SonicSim/ 公開獲得。</paragraph>

##### **Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures in Neural News Recommenders**
2410.01470v1 by Andreea Iana, Goran Glavaš, Heiko Paulheim

Encoder architectures play a pivotal role in neural news recommenders by
embedding the semantic and contextual information of news and users. Thus,
research has heavily focused on enhancing the representational capabilities of
news and user encoders to improve recommender performance. Despite the
significant impact of encoder architectures on the quality of news and user
representations, existing analyses of encoder designs focus only on the overall
downstream recommendation performance. This offers a one-sided assessment of
the encoders' similarity, ignoring more nuanced differences in their behavior,
and potentially resulting in sub-optimal model selection. In this work, we
perform a comprehensive analysis of encoder architectures in neural news
recommender systems. We systematically evaluate the most prominent news and
user encoder architectures, focusing on their (i) representational similarity,
measured with the Central Kernel Alignment, (ii) overlap of generated
recommendation lists, quantified with the Jaccard similarity, and (iii) the
overall recommendation performance. Our analysis reveals that the complexity of
certain encoding techniques is often empirically unjustified, highlighting the
potential for simpler, more efficient architectures. By isolating the effects
of individual components, we provide valuable insights for researchers and
practitioners to make better informed decisions about encoder selection and
avoid unnecessary complexity in the design of news recommenders.

摘要：編碼器架構在神經新聞推薦系統中扮演著舉足輕重的角色，透過將新聞和使用者的語意和脈絡資訊進行嵌入。因此，研究主要集中於增強新聞和使用者編碼器的表徵能力，以提升推薦系統的效能。儘管編碼器架構對新聞和使用者表徵的品質有顯著的影響，現有的編碼器設計分析僅專注於整體的下游推薦效能。這提供了編碼器相似性的片面評估，忽略了其行為中更細微的差異，並可能導致次佳的模型選擇。在這項工作中，我們對神經新聞推薦系統中的編碼器架構進行全面分析。我們系統性地評估最突出的新聞和使用者編碼器架構，重點在於它們的：(i) 表徵相似性，以中心核對齊測量，(ii) 已產生推薦清單的重疊，以傑卡德相似性量化，以及 (iii) 整體推薦效能。我們的分析顯示，某些編碼技術的複雜性通常在經驗上是不合理的，突顯了更簡單、更有效率的架構的潛力。透過孤立個別組成的影響，我們為研究人員和實務工作者提供寶貴的見解，以在編碼器選擇上做出更明智的決策，並避免在新聞推薦系統的設計中出現不必要的複雜性。

##### **TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation**
2410.01469v1 by Mohan Xu, Kai Li, Guo Chen, Xiaolin Hu

In recent years, much speech separation research has focused primarily on
improving model performance. However, for low-latency speech processing
systems, high efficiency is equally important. Therefore, we propose a speech
separation model with significantly reduced parameters and computational costs:
Time-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).
TIGER leverages prior knowledge to divide frequency bands and compresses
frequency information. We employ a multi-scale selective attention module to
extract contextual features, while introducing a full-frequency-frame attention
module to capture both temporal and frequency contextual information.
Additionally, to more realistically evaluate the performance of speech
separation models in complex acoustic environments, we introduce a dataset
called EchoSet. This dataset includes noise and more realistic reverberation
(e.g., considering object occlusions and material properties), with speech from
two speakers overlapping at random proportions. Experimental results showed
that models trained on EchoSet had better generalization ability than those
trained on other datasets to the data collected in the physical world, which
validated the practical value of the EchoSet. On EchoSet and real-world data,
TIGER significantly reduces the number of parameters by 94.3% and the MACs by
95.3% while achieving performance surpassing state-of-the-art (SOTA) model
TF-GridNet. This is the first speech separation model with fewer than 1 million
parameters that achieves performance comparable to the SOTA model.

摘要：近年来，许多语音分离研究主要集中在提高模型性能上。然而，对于低延迟语音处理系统而言，高效率同样重要。因此，我们提出了一个参数和计算成本明显降低的语音分离模型：时频交错增益提取和重建网络（TIGER）。TIGER 利用先验知识来划分频段并压缩频率信息。我们采用多尺度选择性注意模块来提取上下文特征，同时引入全频帧注意模块来捕获时间和频率上下文信息。此外，为了更真实地评估语音分离模型在复杂声学环境中的性能，我们引入了一个名为 EchoSet 的数据集。该数据集包括噪声和更真实的混响（例如，考虑物体遮挡和材料特性），其中来自两个说话者的语音以随机比例重叠。实验结果表明，在 EchoSet 上训练的模型比在其他数据集上训练的模型对物理世界中收集的数据具有更好的泛化能力，这验证了 EchoSet 的实际价值。在 EchoSet 和真实世界数据上，TIGER 将参数数量显着减少了 94.3%，将 MAC 减少了 95.3%，同时实现了超越最先进 (SOTA) 模型 TF-GridNet 的性能。这是第一个参数少于 100 万且性能与 SOTA 模型相当的语音分离模型。

##### **From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with LLM-Guided Knowledge**
2410.01458v1 by Xiefeng Wu

Q-shaping is an extension of Q-value initialization and serves as an
alternative to reward shaping for incorporating domain knowledge to accelerate
agent training, thereby improving sample efficiency by directly shaping
Q-values. This approach is both general and robust across diverse tasks,
allowing for immediate impact assessment while guaranteeing optimality. We
evaluated Q-shaping across 20 different environments using a large language
model (LLM) as the heuristic provider. The results demonstrate that Q-shaping
significantly enhances sample efficiency, achieving a \textbf{16.87\%}
improvement over the best baseline in each environment and a \textbf{253.80\%}
improvement compared to LLM-based reward shaping methods. These findings
establish Q-shaping as a superior and unbiased alternative to conventional
reward shaping in reinforcement learning.

摘要：Q-shaping 是 Q 值初始化的延伸，可用作獎勵塑造的替代方案，用於納入領域知識以加速代理訓練，從而透過直接塑造 Q 值來提升樣本效率。此方法在各種任務中既通用又強健，允許立即進行影響評估，同時保證最佳化。我們在 20 個不同的環境中評估 Q-shaping，使用大型語言模型 (LLM) 作為啟發式提供者。結果表明，Q-shaping 大幅提升了樣本效率，在每個環境中比最佳基準線提升了 \textbf{16.87\%}，與基於 LLM 的獎勵塑造方法相比提升了 \textbf{253.80\%} 。這些發現將 Q-shaping 確立為強化學習中傳統獎勵塑造的優越且無偏的替代方案。

##### **Agent-Driven Large Language Models for Mandarin Lyric Generation**
2410.01450v1 by Hong-Hsiang Liu, Yi-Wen Liu

Generative Large Language Models have shown impressive in-context learning
abilities, performing well across various tasks with just a prompt. Previous
melody-to-lyric research has been limited by scarce high-quality aligned data
and unclear standard for creativeness. Most efforts focused on general themes
or emotions, which are less valuable given current language model capabilities.
In tonal contour languages like Mandarin, pitch contours are influenced by both
melody and tone, leading to variations in lyric-melody fit. Our study,
validated by the Mpop600 dataset, confirms that lyricists and melody writers
consider this fit during their composition process. In this research, we
developed a multi-agent system that decomposes the melody-to-lyric task into
sub-tasks, with each agent controlling rhyme, syllable count, lyric-melody
alignment, and consistency. Listening tests were conducted via a
diffusion-based singing voice synthesizer to evaluate the quality of lyrics
generated by different agent groups.

摘要：生成式大型语言模型已展示出令人印象深刻的情境学习能力，仅通过提示就能在各种任务中表现良好。先前的旋律到歌词的研究受到稀缺的高质量对齐数据和创造力的不明确标准的限制。大多数努力都集中在一般主题或情绪上，鉴于当前语言模型的能力，这些主题或情绪的价值较低。在普通话等声调轮廓语言中，音高轮廓受旋律和音调的影响，导致歌词旋律契合度出现差异。我们的研究由 Mpop600 数据集验证，证实了歌词作者和旋律作者在创作过程中考虑了这种契合度。在这项研究中，我们开发了一个多智能体系统，将旋律到歌词的任务分解为子任务，每个智能体控制韵律、音节计数、歌词旋律对齐和一致性。通过基于扩散的歌唱语音合成器进行聆听测试，以评估不同智能体组生成的歌词的质量。

##### **Analyzing Byte-Pair Encoding on Monophonic and Polyphonic Symbolic Music: A Focus on Musical Phrase Segmentation**
2410.01448v1 by Dinh-Viet-Toan Le, Louis Bigo, Mikaela Keller

Byte-Pair Encoding (BPE) is an algorithm commonly used in Natural Language
Processing to build a vocabulary of subwords, which has been recently applied
to symbolic music. Given that symbolic music can differ significantly from
text, particularly with polyphony, we investigate how BPE behaves with
different types of musical content. This study provides a qualitative analysis
of BPE's behavior across various instrumentations and evaluates its impact on a
musical phrase segmentation task for both monophonic and polyphonic music. Our
findings show that the BPE training process is highly dependent on the
instrumentation and that BPE "supertokens" succeed in capturing abstract
musical content. In a musical phrase segmentation task, BPE notably improves
performance in a polyphonic setting, but enhances performance in monophonic
tunes only within a specific range of BPE merges.

摘要：位元組對編碼 (BPE) 是一種演算法，在自然語言處理中常被用於建立子字詞彙，最近已應用於符號音樂。由於符號音樂與文字可能大不相同，特別是在複音音樂中，我們研究 BPE 如何處理不同類型的音樂內容。本研究提供 BPE 在各種樂器中的行為之定性分析，並評估其對單音和複音音樂的音樂樂句分段任務的影響。我們的發現顯示，BPE 訓練過程高度依賴於樂器，而且 BPE「超級符號」成功捕捉抽象音樂內容。在音樂樂句分段任務中，BPE 顯著改善複音設定中的表現，但僅在特定範圍的 BPE 合併中提升單音樂曲的表現。

##### **Geometric Signatures of Compositionality Across a Language Model's Lifetime**
2410.01444v1 by Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng

Compositionality, the notion that the meaning of an expression is constructed
from the meaning of its parts and syntactic rules, permits the infinite
productivity of human language. For the first time, artificial language models
(LMs) are able to match human performance in a number of compositional
generalization tasks. However, much remains to be understood about the
representational mechanisms underlying these abilities. We take a high-level
geometric approach to this problem by relating the degree of compositionality
in a dataset to the intrinsic dimensionality of its representations under an
LM, a measure of feature complexity. We find not only that the degree of
dataset compositionality is reflected in representations' intrinsic
dimensionality, but that the relationship between compositionality and
geometric complexity arises due to learned linguistic features over training.
Finally, our analyses reveal a striking contrast between linear and nonlinear
dimensionality, showing that they respectively encode formal and semantic
aspects of linguistic composition.

摘要：組合性，即表達式的意義是由其組成部分的意義和語法規則建構而成的概念，允許人類語言具有無限的生產力。人工語言模型 (LM) 第一次在許多組合概括任務中達到人類的表現。然而，對於這些能力背後的表徵機制，我們還有很多需要了解的地方。我們透過將資料集中組合性的程度與 LM 下其表徵的內在維度（一種特徵複雜性的測量）聯繫起來，採用高層級的幾何方法來解決這個問題。我們發現，資料集組合性的程度不僅反映在表徵的內在維度中，而且組合性和幾何複雜性之間的關係是因訓練過程中學習到的語言特徵而產生的。最後，我們的分析揭示了線性和非線性維度之間的顯著對比，表明它們分別編碼語言組合的形式和語義方面。

##### **Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models**
2410.01434v1 by Philipp Mondorf, Sondre Wold, Barbara Plank

A fundamental question in interpretability research is to what extent neural
networks, particularly language models, implement reusable functions via
subnetworks that can be composed to perform more complex tasks. Recent
developments in mechanistic interpretability have made progress in identifying
subnetworks, often referred to as circuits, which represent the minimal
computational subgraph responsible for a model's behavior on specific tasks.
However, most studies focus on identifying circuits for individual tasks
without investigating how functionally similar circuits relate to each other.
To address this gap, we examine the modularity of neural networks by analyzing
circuits for highly compositional subtasks within a transformer-based language
model. Specifically, given a probabilistic context-free grammar, we identify
and compare circuits responsible for ten modular string-edit operations. Our
results indicate that functionally similar circuits exhibit both notable node
overlap and cross-task faithfulness. Moreover, we demonstrate that the circuits
identified can be reused and combined through subnetwork set operations to
represent more complex functional capabilities of the model.

摘要：可解釋性研究中的基本問題是神經網路，特別是語言模型，在多大程度上透過可以組合來執行更複雜任務的子網路來實作可重複使用的函式。機制可解釋性的最新發展在識別子網路方面取得進展，這些子網路通常稱為電路，代表負責模型在特定任務上行為的最小運算子圖。然而，大多數研究都專注於識別個別任務的電路，而沒有研究功能相似的電路如何相互關聯。為了解決這個差距，我們透過分析轉換器語言模型中高度組合子任務的電路，來檢視神經網路的模組化。具體來說，給定一個機率性的上下文無關文法，我們識別並比較負責十個模組化字串編輯操作的電路。我們的結果表明，功能相似的電路既展現出顯著的節點重疊，又展現出跨任務的忠實度。此外，我們證明了識別出的電路可以透過子網路集合運算來重複使用和組合，以表示模型更複雜的功能能力。

##### **Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks**
2410.01428v1 by Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing

State-of-the-art large language models (LLMs) exhibit impressive
problem-solving capabilities but may struggle with complex reasoning and
factual correctness. Existing methods harness the strengths of chain-of-thought
and retrieval-augmented generation (RAG) to decompose a complex problem into
simpler steps and apply retrieval to improve factual correctness. These methods
work well on straightforward reasoning tasks but often falter on challenging
tasks such as competitive programming and mathematics, due to frequent
reasoning errors and irrelevant knowledge retrieval. To address this, we
introduce Critic-guided planning with Retrieval-augmentation, CR-Planner, a
novel framework that leverages fine-tuned critic models to guide both reasoning
and retrieval processes through planning. CR-Planner solves a problem by
iteratively selecting and executing sub-goals. Initially, it identifies the
most promising sub-goal from reasoning, query generation, and retrieval, guided
by rewards given by a critic model named sub-goal critic. It then executes this
sub-goal through sampling and selecting the optimal output based on evaluations
from another critic model named execution critic. This iterative process,
informed by retrieved information and critic models, enables CR-Planner to
effectively navigate the solution space towards the final answer. We employ
Monte Carlo Tree Search to collect the data for training the critic models,
allowing for a systematic exploration of action sequences and their long-term
impacts. We validate CR-Planner on challenging domain-knowledge-intensive and
reasoning-heavy tasks, including competitive programming, theorem-driven math
reasoning, and complex domain retrieval problems. Our experiments demonstrate
that CR-Planner significantly outperforms baselines, highlighting its
effectiveness in addressing challenging problems by improving both reasoning
and retrieval.

摘要：最先進的大語言模型 (LLM) 展現出令人印象深刻的解決問題能力，但可能會在複雜推理和事實正確性方面遇到困難。現有方法利用思想鏈和檢索增強生成 (RAG) 的優勢，將複雜問題分解為更簡單的步驟，並應用檢索來改善事實正確性。這些方法在直接的推理任務上運作良好，但由於頻繁的推理錯誤和無關知識的檢索，因此在具有挑戰性的任務（例如競爭性程式設計和數學）上常常失敗。為了解決這個問題，我們引入了批評指導的檢索增強規劃，CR-Planner，一個利用微調批評模型通過規劃來指導推理和檢索過程的新穎框架。CR-Planner 通過迭代選擇和執行子目標來解決問題。最初，它從推理、查詢生成和檢索中識別最有希望的子目標，由一個名為子目標批評的批評模型給出的獎勵指導。然後，它通過抽樣並根據另一個名為執行批評的批評模型的評估選擇最佳輸出，來執行這個子目標。這個迭代過程，由檢索到的資訊和批評模型提供資訊，使 CR-Planner 能夠有效地導航解空間，朝著最終答案前進。我們採用蒙特卡洛樹搜尋來收集資料，以訓練批評模型，允許系統地探索動作序列及其長期影響。我們在具有挑戰性的領域知識密集型和推理密集型任務上驗證了 CR-Planner，包括競爭性程式設計、定理驅動的數學推理和複雜領域檢索問題。我們的實驗表明，CR-Planner 明顯優於基線，突顯了它在通過改進推理和檢索來解決具有挑戰性問題方面的有效性。

##### **Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data Free Distillation**
2410.01423v1 by Md Fahim Sikder, Daniel de Leng, Fredrik Heintz

This work presents Fair4Free, a novel generative model to generate synthetic
fair data using data-free distillation in the latent space. Fair4Free can work
on the situation when the data is private or inaccessible. In our approach, we
first train a teacher model to create fair representation and then distil the
knowledge to a student model (using a smaller architecture). The process of
distilling the student model is data-free, i.e. the student model does not have
access to the training dataset while distilling. After the distillation, we use
the distilled model to generate fair synthetic samples. Our extensive
experiments show that our synthetic samples outperform state-of-the-art models
in all three criteria (fairness, utility and synthetic quality) with a
performance increase of 5% for fairness, 8% for utility and 12% in synthetic
quality for both tabular and image datasets.

摘要：這項工作提出了 Fair4Free，一個新穎的生成模型，用於在潛在空間中使用無資料蒸餾生成合成公平資料。Fair4Free 可以用於資料為私人或無法存取的情況。在我們的做法中，我們首先訓練一個教師模型來建立公平的表示，然後將知識蒸餾到學生模型（使用較小的架構）。蒸餾學生模型的過程是無資料的，即學生模型在蒸餾時無法存取訓練資料集。在蒸餾之後，我們使用蒸餾模型來生成公平的合成樣本。我們的廣泛實驗表明，我們的合成樣本在所有三個標準（公平性、效用和合成品質）中都優於最先進的模型，在公平性方面提高了 5%，在效用方面提高了 8%，在表格和影像資料集的合成品質方面提高了 12%。

##### **The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs**
2410.01417v1 by Hong Li, Nanxi Li, Yuanjie Chen, Jianbin Zhu, Qinlu Guo, Cewu Lu, Yong-Lu Li

Multi-modal Large Language Models (MLLMs) have exhibited impressive
capability. However, recently many deficiencies of MLLMs have been found
compared to human intelligence, $\textit{e.g.}$, hallucination. To drive the
MLLMs study, the community dedicated efforts to building larger benchmarks with
complex tasks. In this paper, we propose benchmarking an essential but usually
overlooked intelligence: $\textbf{association}$, a human's basic capability to
link observation and prior practice memory. To comprehensively investigate
MLLM's performance on the association, we formulate the association task and
devise a standard benchmark based on adjective and verb semantic concepts.
Instead of costly data annotation and curation, we propose a convenient
$\textbf{annotation-free}$ construction method transforming the general dataset
for our association tasks. Simultaneously, we devise a rigorous data refinement
process to eliminate confusion in the raw dataset. Building on this database,
we establish three levels of association tasks: single-step, synchronous, and
asynchronous associations. Moreover, we conduct a comprehensive investigation
into the MLLMs' zero-shot association capabilities, addressing multiple
dimensions, including three distinct memory strategies, both open-source and
closed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the
involvement of human experts. Our systematic investigation shows that current
open-source MLLMs consistently exhibit poor capability in our association
tasks, even the currently state-of-the-art GPT-4V(vision) also has a
significant gap compared to humans. We believe our benchmark would pave the way
for future MLLM studies. $\textit{Our data and code are available at:}$
https://mvig-rhos.com/llm_inception.

摘要：多模态大型语言模型 (MLLM) 已展现出令人印象深刻的能力。然而，最近发现 MLLM 与人类智能相比存在许多缺陷，例如幻觉。为了推动 MLLM 研究，社区致力于构建具有复杂任务的更大基准。在本文中，我们提出对一项基本但通常被忽视的智能进行基准测试：**联想**，人类将观察与先前的实践记忆联系起来的基本能力。为了全面调查 MLLM 在联想方面的表现，我们制定了联想任务并设计了一个基于形容词和动词语义概念的标准基准。我们提出了一种便捷的**无注释**构建方法，将通用数据集转换为我们的联想任务，而不是进行昂贵的数据注释和整理。同时，我们设计了一个严格的数据优化流程，以消除原始数据集中的混乱。在此数据库的基础上，我们建立了三个级别的联想任务：单步、同步和异步联想。此外，我们对 MLLM 的零次联想能力进行了全面调查，涉及多个维度，包括三种不同的记忆策略、开源和闭源 MLLM、尖端的专家混合 (MoE) 模型以及人类专家的参与。我们的系统调查表明，当前的开源 MLLM 在我们的联想任务中始终表现出较差的能力，即使是目前最先进的 GPT-4V（视觉）与人类相比也存在显着差距。我们相信我们的基准将为未来的 MLLM 研究铺平道路。$\textit{我们的数据和代码可在以下位置获得：}$
https://mvig-rhos.com/llm_inception。

##### **Improving Fuzzy Rule Classifier with Brain Storm Optimization and Rule Modification**
2410.01413v1 by Yan Huang, Wei Liu, Xiaogang Zang

The expanding complexity and dimensionality in the search space can adversely
affect inductive learning in fuzzy rule classifiers, thus impacting the
scalability and accuracy of fuzzy systems. This research specifically addresses
the challenge of diabetic classification by employing the Brain Storm
Optimization (BSO) algorithm to propose a novel fuzzy system that redefines
rule generation for this context. An exponential model is integrated into the
standard BSO algorithm to enhance rule derivation, tailored specifically for
diabetes-related data. The innovative fuzzy system is then applied to
classification tasks involving diabetic datasets, demonstrating a substantial
improvement in classification accuracy, as evidenced by our experiments.

摘要：搜尋空間中日益擴大的複雜度和維度可能會對模糊規則分類器中的歸納學習產生負面影響，從而影響模糊系統的可擴充性和準確性。本研究特別針對糖尿病分類的挑戰，採用腦力激盪優化 (BSO) 演算法，提出一個重新定義此情境中規則生成的全新模糊系統。將指數模型整合到標準 BSO 演算法中，以增強規則推導，特別針對與糖尿病相關的資料量身打造。然後將創新的模糊系統應用於涉及糖尿病資料集的分類任務，根據我們的實驗證明，分類準確度有顯著提升。

##### **Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**
2410.01401v1 by Yu Zhang, Kehai Chen, Xuefeng Bai, zhao kang, Quanjiang Guo, Min Zhang

Knowledge graph question answering (KGQA) involves answering natural language
questions by leveraging structured information stored in a knowledge graph.
Typically, KGQA initially retrieve a targeted subgraph from a large-scale
knowledge graph, which serves as the basis for reasoning models to address
queries. However, the retrieved subgraph inevitably brings distraction
information for knowledge utilization, impeding the model's ability to perform
accurate reasoning. To address this issue, we propose a Question-guided
Knowledge Graph Re-scoring method (Q-KGR) to eliminate noisy pathways for the
input question, thereby focusing specifically on pertinent factual knowledge.
Moreover, we introduce Knowformer, a parameter-efficient method for injecting
the re-scored knowledge graph into large language models to enhance their
ability to perform factual reasoning. Extensive experiments on multiple KGQA
benchmarks demonstrate the superiority of our method over existing systems.

摘要：知識圖表問答 (KGQA) 涉及利用儲存在知識圖表中的結構化資訊來回答自然語言問題。通常，KGQA 最初會從大規模知識圖表中擷取目標子圖，作為推理模型處理查詢的基礎。然而，擷取的子圖難免會帶來雜訊資訊，阻礙模型執行精確推理的能力。為了解決這個問題，我們提出了一個問題導向知識圖表重新評分方法 (Q-KGR)，以消除輸入問題的雜訊路徑，從而專注於相關的事實知識。此外，我們引入了 Knowformer，這是一種參數效率高的方法，用於將重新評分的知識圖表注入大型語言模型，以增強它們執行事實推理的能力。在多個 KGQA 基準上的廣泛實驗證明了我們的方法優於現有系統。

##### **CrowdCounter: A benchmark type-specific multi-target counterspeech dataset**
2410.01400v1 by Punyajoy Saha, Abhilash Datta, Abhik Jana, Animesh Mukherjee

Counterspeech presents a viable alternative to banning or suspending users
for hate speech while upholding freedom of expression. However, writing
effective counterspeech is challenging for moderators/users. Hence, developing
suggestion tools for writing counterspeech is the need of the hour. One
critical challenge in developing such a tool is the lack of quality and
diversity of the responses in the existing datasets. Hence, we introduce a new
dataset - CrowdCounter containing 3,425 hate speech-counterspeech pairs
spanning six different counterspeech types (empathy, humor, questioning,
warning, shaming, contradiction), which is the first of its kind. The design of
our annotation platform itself encourages annotators to write type-specific,
non-redundant and high-quality counterspeech. We evaluate two frameworks for
generating counterspeech responses - vanilla and type-controlled prompts -
across four large language models. In terms of metrics, we evaluate the
responses using relevance, diversity and quality. We observe that Flan-T5 is
the best model in the vanilla framework across different models. Type-specific
prompts enhance the relevance of the responses, although they might reduce the
language quality. DialoGPT proves to be the best at following the instructions
and generating the type-specific counterspeech accurately.

摘要：反論提供了一個可行的替代方案，既能禁止或暫停仇恨言論的使用者，同時又能維護言論自由。然而，撰寫有效的反論對版主/使用者來說是一個挑戰。因此，開發用於撰寫反論的建議工具是當務之急。在開發此類工具時，一個重大的挑戰是現有資料集中回應的品質和多樣性不足。因此，我們引入了一個新的資料集 - CrowdCounter，其中包含 3,425 個仇恨言論 - 反論配對，涵蓋六種不同的反論類型（同理心、幽默、質疑、警告、羞辱、矛盾），這是同類中的第一個。我們的註解平台的設計本身鼓勵註解者撰寫特定類型、非冗餘且高品質的反論。我們評估了兩個用於產生反論回應的框架 - 香草和類型控制提示 - 跨越四個大型語言模型。在指標方面，我們使用相關性、多樣性和品質來評估回應。我們觀察到，在不同的模型中，Flan-T5 是香草框架中的最佳模型。特定類型的提示會增強回應的相關性，儘管它們可能會降低語言品質。DialoGPT 證明在遵循說明和準確產生特定類型的反論方面表現最佳。

##### **Can We Delegate Learning to Automation?: A Comparative Study of LLM Chatbots, Search Engines, and Books**
2410.01396v1 by Yeonsun Yang, Ahyeon Shin, Mincheol Kang, Jiheon Kang, Jean Young Song

Learning is a key motivator behind information search behavior. With the
emergence of LLM-based chatbots, students are increasingly turning to these
tools as their primary resource for acquiring knowledge. However, the
transition from traditional resources like textbooks and web searches raises
concerns among educators. They worry that these fully-automated LLMs might lead
students to delegate critical steps of search as learning. In this paper, we
systematically uncover three main concerns from educators' perspectives. In
response to these concerns, we conducted a mixed-methods study with 92
university students to compare three learning sources with different automation
levels. Our results show that LLMs support comprehensive understanding of key
concepts without promoting passive learning, though their effectiveness in
knowledge retention was limited. Additionally, we found that academic
performance impacted both learning outcomes and search patterns. Notably,
higher-competence learners engaged more deeply with content through
reading-intensive behaviors rather than relying on search activities.

摘要：學習是資訊搜尋行為背後的主要動機。隨著 LLM 基礎聊天機器人的出現，學生越來越將這些工具視為獲取知識的主要資源。然而，從教科書和網路搜尋等傳統資源的轉變引起了教育者的關注。他們擔心這些全自動 LLM 可能會導致學生將搜尋的關鍵步驟委派給學習。在本文中，我們系統性地揭露了教育者觀點的三個主要關注點。針對這些關注點，我們對 92 位大學生進行了一項混合方法研究，以比較具有不同自動化程度的三種學習來源。我們的結果表明，LLM 在不促進被動學習的情況下支援對關鍵概念的全面理解，儘管它們在知識保留方面的有效性受到限制。此外，我們發現學業表現影響學習成果和搜尋模式。值得注意的是，能力較高的學習者透過閱讀密集的行為更深入地參與內容，而不是依賴搜尋活動。

##### **FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated Learning Deployments**
2410.01386v1 by Ioannis Mavromatis, Stefano De Feo, Aftab Khan

This paper presents Federated Learning with Adaptive Monitoring and
Elimination (FLAME), a novel solution capable of detecting and mitigating
concept drift in Federated Learning (FL) Internet of Things (IoT) environments.
Concept drift poses significant challenges for FL models deployed in dynamic
and real-world settings. FLAME leverages an FL architecture, considers a
real-world FL pipeline, and proves capable of maintaining model performance and
accuracy while addressing bandwidth and privacy constraints. Introducing
various features and extensions on previous works, FLAME offers a robust
solution to concept drift, significantly reducing computational load and
communication overhead. Compared to well-known lightweight mitigation methods,
FLAME demonstrates superior performance in maintaining high F1 scores and
reducing resource utilisation in large-scale IoT deployments, making it a
promising approach for real-world applications.

摘要：本文提出了具有自适应监控和消除功能的联邦学习 (FLAME)，这是一种能够检测和缓解联邦学习 (FL) 物联网 (IoT) 环境中概念漂移的新颖解决方案。概念漂移对部署在动态和现实世界设置中的 FL 模型构成了重大挑战。FLAME 利用 FL 架构，考虑了现实世界的 FL 管道，并证明了在解决带宽和隐私限制的同时，能够维持模型性能和准确性。FLAME 在以前的工作中引入了各种功能和扩展，提供了一种针对概念漂移的稳健解决方案，显著降低了计算负载和通信开销。与众所周知的轻量级缓解方法相比，FLAME 在维持高 F1 分数和减少大规模物联网部署中的资源利用方面表现出卓越的性能，使其成为现实世界应用中一种有前途的方法。

##### **PairDistill: Pairwise Relevance Distillation for Dense Retrieval**
2410.01383v1 by Chao-Wei Huang, Yun-Nung Chen

Effective information retrieval (IR) from vast datasets relies on advanced
techniques to extract relevant information in response to queries. Recent
advancements in dense retrieval have showcased remarkable efficacy compared to
traditional sparse retrieval methods. To further enhance retrieval performance,
knowledge distillation techniques, often leveraging robust cross-encoder
rerankers, have been extensively explored. However, existing approaches
primarily distill knowledge from pointwise rerankers, which assign absolute
relevance scores to documents, thus facing challenges related to inconsistent
comparisons. This paper introduces Pairwise Relevance Distillation
(PairDistill) to leverage pairwise reranking, offering fine-grained
distinctions between similarly relevant documents to enrich the training of
dense retrieval models. Our experiments demonstrate that PairDistill
outperforms existing methods, achieving new state-of-the-art results across
multiple benchmarks. This highlights the potential of PairDistill in advancing
dense retrieval techniques effectively. Our source code and trained models are
released at https://github.com/MiuLab/PairDistill

摘要：有效的信息檢索 (IR) 從大量資料集中依賴先進的技術來萃取相關資訊以回應查詢。最近在密集檢索方面的進展已展現出顯著的功效，與傳統的稀疏檢索方法相比。為了進一步增強檢索效能，知識提煉技術，通常利用強大的交叉編碼器重新排序，已廣泛探索。然而，現有的方法主要從逐點重新排序器中提煉知識，它將絕對相關性分數分配給文件，因此面臨與不一致比較相關的挑戰。本文介紹成對相關性提煉 (PairDistill) 以利用成對重新排序，提供相似相關文件之間的細微區別，以豐富密集檢索模型的訓練。我們的實驗證明 PairDistill 優於現有方法，在多個基準測試中取得新的最先進成果。這突顯了 PairDistill 在有效推進密集檢索技術的潛力。我們的原始碼和訓練模型已發布在 https://github.com/MiuLab/PairDistill

##### **Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition**
2410.01380v1 by Jiyeon Kim, Hyunji Lee, Hyowon Cho, Joel Jang, Hyeonbin Hwang, Seungpil Won, Youbin Ahn, Dohaeng Lee, Minjoon Seo

In this work, we investigate how a model's tendency to broadly integrate its
parametric knowledge evolves throughout pretraining, and how this behavior
affects overall performance, particularly in terms of knowledge acquisition and
forgetting. We introduce the concept of knowledge entropy, which quantifies the
range of memory sources the model engages with; high knowledge entropy
indicates that the model utilizes a wide range of memory sources, while low
knowledge entropy suggests reliance on specific sources with greater certainty.
Our analysis reveals a consistent decline in knowledge entropy as pretraining
advances. We also find that the decline is closely associated with a reduction
in the model's ability to acquire and retain knowledge, leading us to conclude
that diminishing knowledge entropy (smaller number of active memory sources)
impairs the model's knowledge acquisition and retention capabilities. We find
further support for this by demonstrating that increasing the activity of
inactive memory sources enhances the model's capacity for knowledge acquisition
and retention.

摘要：在這項工作中，我們探討模型廣泛整合其參數知識的趨勢如何在預訓練中演變，以及此行為如何影響整體效能，特別是在知識獲取和遺忘方面。我們引入了知識熵的概念，它量化了模型所使用的記憶來源範圍；高知識熵表示模型利用了廣泛的記憶來源，而低知識熵則表示更確定地依賴特定來源。我們的分析顯示，隨著預訓練的推進，知識熵持續下降。我們還發現，這種下降與模型獲取和保留知識的能力下降密切相關，這讓我們得出結論：知識熵遞減（較少的活躍記憶來源數量）會損害模型的知識獲取和保留能力。我們進一步證明了這一點，方法是證明增加非活躍記憶來源的活動性會增強模型獲取和保留知識的能力。

##### **PCQPR: Proactive Conversational Question Planning with Reflection**
2410.01363v1 by Shasha Guo, Lizi Liao, Jing Zhang, Cuiping Li, Hong Chen

Conversational Question Generation (CQG) enhances the interactivity of
conversational question-answering systems in fields such as education, customer
service, and entertainment. However, traditional CQG, focusing primarily on the
immediate context, lacks the conversational foresight necessary to guide
conversations toward specified conclusions. This limitation significantly
restricts their ability to achieve conclusion-oriented conversational outcomes.
In this work, we redefine the CQG task as Conclusion-driven Conversational
Question Generation (CCQG) by focusing on proactivity, not merely reacting to
the unfolding conversation but actively steering it towards a
conclusion-oriented question-answer pair. To address this, we propose a novel
approach, called Proactive Conversational Question Planning with self-Refining
(PCQPR). Concretely, by integrating a planning algorithm inspired by Monte
Carlo Tree Search (MCTS) with the analytical capabilities of large language
models (LLMs), PCQPR predicts future conversation turns and continuously
refines its questioning strategies. This iterative self-refining mechanism
ensures the generation of contextually relevant questions strategically devised
to reach a specified outcome. Our extensive evaluations demonstrate that PCQPR
significantly surpasses existing CQG methods, marking a paradigm shift towards
conclusion-oriented conversational question-answering systems.

摘要：對話式問題產生 (CQG) 提升了對話式問答系統在教育、客戶服務和娛樂等領域的互動性。然而，傳統的 CQG 主要關注於即時脈絡，缺乏引導對話走向特定結論所需的對話前瞻性。此項限制顯著地限制了它們達成結論導向對話成果的能力。在這項工作中，我們重新定義 CQG 任務為結論導向對話式問題產生 (CCQG)，著重於主動性，不僅僅是對展開對話做出反應，而是積極地引導對話走向結論導向的問題解答配對。為了解決此問題，我們提出了一種稱為主動對話式問題規劃與自我精進 (PCQPR) 的新方法。具體來說，透過整合受蒙地卡羅樹狀搜尋 (MCTS) 啟發的規劃演算法與大型語言模型 (LLM) 的分析能力，PCQPR 預測未來的對話回合並持續精進其提問策略。此項迭代自我精進機制確保產生在脈絡上相關的問題，這些問題經過策略性設計，以達成特定結果。我們的廣泛評估證明，PCQPR 明顯優於現有的 CQG 方法，標誌著朝結論導向對話式問答系統邁進的典範轉移。

##### **Assisted Data Annotation for Business Process Information Extraction from Textual Documents**
2410.01356v1 by Julian Neuberger, Han van der Aa, Lars Ackermann, Daniel Buschek, Jannic Herrmann, Stefan Jablonski

Machine-learning based generation of process models from natural language
text process descriptions provides a solution for the time-intensive and
expensive process discovery phase. Many organizations have to carry out this
phase, before they can utilize business process management and its benefits.
Yet, research towards this is severely restrained by an apparent lack of large
and high-quality datasets. This lack of data can be attributed to, among other
things, an absence of proper tool assistance for dataset creation, resulting in
high workloads and inferior data quality. We explore two assistance features to
support dataset creation, a recommendation system for identifying process
information in the text and visualization of the current state of already
identified process information as a graphical business process model. A
controlled user study with 31 participants shows that assisting dataset
creators with recommendations lowers all aspects of workload, up to $-51.0\%$,
and significantly improves annotation quality, up to $+38.9\%$. We make all
data and code available to encourage further research on additional novel
assistance strategies.

摘要：基於機器學習的自然語言流程模型生成文字流程描述提供了時間密集且昂貴的流程發現階段的解決方案。許多組織必須執行此階段，才能利用業務流程管理及其好處。然而，由於明顯缺乏大型且高品質的資料集，這方面的研究受到嚴重限制。這種資料缺乏可能是因為缺乏適當的工具協助建立資料集，導致工作負擔過重且資料品質低落。我們探討了兩個協助功能，以支援資料集建立，一個建議系統用於識別文字中的流程資訊，以及將已識別流程資訊的目前狀態視覺化為圖形化業務流程模型。一項針對 31 位參與者的受控使用者研究顯示，協助資料集建立者提供建議可降低所有方面的工作負擔，最高達 $-51.0\%$，並顯著改善註解品質，最高達 $+38.9\%$。我們公開所有資料和程式碼，以鼓勵進一步研究其他新穎的協助策略。

##### **Takin-VC: Zero-shot Voice Conversion via Jointly Hybrid Content and Memory-Augmented Context-Aware Timbre Modeling**
2410.01350v1 by Yuguang Yang, Yu Pan, Jixun Yao, Xiang Zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao

Zero-shot voice conversion (VC) aims to transform the source speaker timbre
into an arbitrary unseen one without altering the original speech content.While
recent advancements in zero-shot VC methods have shown remarkable progress,
there still remains considerable potential for improvement in terms of
improving speaker similarity and speech naturalness.In this paper, we propose
Takin-VC, a novel zero-shot VC framework based on jointly hybrid content and
memory-augmented context-aware timbre modeling to tackle this challenge.
Specifically, an effective hybrid content encoder, guided by neural codec
training, that leverages quantized features from pre-trained WavLM and
HybridFormer is first presented to extract the linguistic content of the source
speech. Subsequently, we introduce an advanced cross-attention-based
context-aware timbre modeling approach that learns the fine-grained,
semantically associated target timbre features. To further enhance both speaker
similarity and real-time performance, we utilize a conditional flow matching
model to reconstruct the Mel-spectrogram of the source speech. Additionally, we
advocate an efficient memory-augmented module designed to generate high-quality
conditional target inputs for the flow matching process, thereby improving the
overall performance of the proposed system. Experimental results demonstrate
that the proposed Takin-VC method surpasses state-of-the-art zero-shot VC
systems, delivering superior performance in terms of both speech naturalness
and speaker similarity.

摘要：零範例語音轉換 (VC) 旨在將來源說話者的音色轉換為任意一個未見過的音色，同時不改變原始的語音內容。雖然近期在零範例 VC 方法的進展已展現出顯著的進步，但在提升說話者相似度和語音自然度方面仍有很大的改善空間。在本文中，我們提出 Takin-VC，一個基於混合內容和強化記憶的脈絡感知音色建模的全新零範例 VC 架構，以應對此挑戰。具體來說，一個由神經編解碼器訓練引導的有效混合內容編碼器，利用來自預先訓練的 WavLM 和 HybridFormer 的量化特徵，首先被提出用於提取來源語音的語言內容。隨後，我們引入一個進階的基於交叉注意力的脈絡感知音色建模方法，用於學習細緻的、語義關聯的目標音色特徵。為了進一步增強說話者的相似度和即時效能，我們利用一個條件流匹配模型來重建來源語音的梅爾頻譜圖。此外，我們提倡一個高效的強化記憶模組，旨在為流匹配處理產生高品質的條件目標輸入，從而提升所提出系統的整體效能。實驗結果證明，所提出的 Takin-VC 方法超越了最先進的零範例 VC 系統，在語音自然度和說話者相似度方面都提供了卓越的效能。

##### **Life, uh, Finds a Way: Systematic Neural Search**
2410.01349v1 by Alex Baranski, Jun Tani

We tackle the challenge of rapidly adapting an agent's behavior to solve
spatiotemporally continuous problems in novel settings. Animals exhibit
extraordinary abilities to adapt to new contexts, a capacity unmatched by
artificial systems. Instead of focusing on generalization through deep
reinforcement learning, we propose viewing behavior as the physical
manifestation of a search procedure, where robust problem-solving emerges from
an exhaustive search across all possible behaviors. Surprisingly, this can be
done efficiently using online modification of a cognitive graph that guides
action, challenging the predominant view that exhaustive search in continuous
spaces is impractical. We describe an algorithm that implicitly enumerates
behaviors by regulating the tight feedback loop between execution of behaviors
and mutation of the graph, and provide a neural implementation based on Hebbian
learning and a novel high-dimensional harmonic representation inspired by
entorhinal cortex. By framing behavior as search, we provide a mathematically
simple and biologically plausible model for real-time behavioral adaptation,
successfully solving a variety of continuous state-space navigation problems.
This framework not only offers a flexible neural substrate for other
applications but also presents a powerful paradigm for understanding adaptive
behavior. Our results suggest potential advancements in developmental learning
and unsupervised skill acquisition, paving the way for autonomous robots to
master complex skills in data-sparse environments demanding flexibility.

摘要：<paragraph>我們應對快速調整代理行為的挑戰，以解決新環境中時空連續的問題。動物展現出適應新環境的非凡能力，這項能力是人工系統無法比擬的。我們不專注於透過深度強化學習進行概括，而是建議將行為視為搜尋程序的物理表現，其中穩健的解決問題能力來自於對所有可能行為的窮舉搜尋。令人驚訝的是，這可以使用認知圖表的線上修改來有效執行，該認知圖表會引導動作，挑戰在連續空間中進行窮舉搜尋不切實際的主流觀點。我們描述了一種演算法，透過調整執行行為與圖表突變之間緊密的回饋迴路，隱含地列舉行為，並提供基於赫布學習和受內嗅皮質啟發的新穎高維諧波表示的神經網路實作。透過將行為架構為搜尋，我們提供了一個數學上簡單且在生物學上合理的即時行為適應模型，成功解決了各種連續狀態空間導航問題。此架構不僅為其他應用程式提供了一個靈活的神經基底，也為理解適應行為提供了一個強大的典範。我們的結果顯示了發展學習和非監督技能習得的潛在進展，為自主機器人在資料稀疏的環境中掌握複雜技能，並要求靈活性鋪平了道路。</paragraph>

##### **PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems**
2410.01337v1 by Bocheng Zeng, Qi Wang, Mengtao Yan, Yang Liu, Ruizhi Chengze, Yi Zhang, Hongsheng Liu, Zidong Wang, Hao Sun

Solving partial differential equations (PDEs) serves as a cornerstone for
modeling complex dynamical systems. Recent progresses have demonstrated grand
benefits of data-driven neural-based models for predicting spatiotemporal
dynamics (e.g., tremendous speedup gain compared with classical numerical
methods). However, most existing neural models rely on rich training data, have
limited extrapolation and generalization abilities, and suffer to produce
precise or reliable physical prediction under intricate conditions (e.g.,
irregular mesh or geometry, complex boundary conditions, diverse PDE
parameters, etc.). To this end, we propose a new graph learning approach,
namely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model
spatiotemporal PDE systems on irregular meshes given small training datasets.
Specifically, we incorporate a GNN into a numerical integrator to approximate
the temporal marching of spatiotemporal dynamics for a given PDE system.
Considering that many physical phenomena are governed by diffusion processes,
we further design a learnable Laplace block, which encodes the discrete
Laplace-Beltrami operator, to aid and guide the GNN learning in a physically
feasible solution space. A boundary condition padding strategy is also designed
to improve the model convergence and accuracy. Extensive experiments
demonstrate that PhyMPGN is capable of accurately predicting various types of
spatiotemporal dynamics on coarse unstructured meshes, consistently achieves
the state-of-the-art results, and outperforms other baselines with considerable
gains.

摘要：求解偏微分方程式 (PDE) 是建模复杂动力系统之基石。最近的进展已证明，基于数据驱动的神经模型在预测时空动态方面具有巨大的优势（例如，与经典数值方法相比，速度提升显著）。然而，大多数现有的神经模型依赖于丰富的训练数据，外推和泛化能力有限，并且难以在复杂条件下（例如，不规则网格或几何形状、复杂的边界条件、不同的 PDE 参数等）产生精确或可靠的物理预测。为此，我们提出了一种新的图学习方法，即物理编码消息传递图网络 (PhyMPGN)，以在给定小训练数据集的情况下对不规则网格上的时空 PDE 系统进行建模。具体来说，我们将 GNN 融入数值积分器，以近似给定 PDE 系统的时空动态的时间推进。考虑到许多物理现象受扩散过程支配，我们进一步设计了一个可学习的拉普拉斯块，它对离散拉普拉斯-贝尔特拉米算子进行编码，以在物理可行的解空间中帮助和指导 GNN 学习。还设计了一种边界条件填充策略，以提高模型收敛性和准确性。大量实验表明，PhyMPGN 能够准确预测各种类型的粗糙非结构化网格上的时空动态，始终达到最先进的结果，并且比其他基线方法有相当大的优势。

