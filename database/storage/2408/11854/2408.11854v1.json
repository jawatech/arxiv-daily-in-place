{"2408.11854": {"publish_time": "2024-08-15", "title": "When Raw Data Prevails: Are Large Language Model Embeddings Effective in Numerical Data Representation for Medical Machine Learning Applications?", "paper_summary": "The introduction of Large Language Models (LLMs) has advanced data\nrepresentation and analysis, bringing significant progress in their use for\nmedical questions and answering. Despite these advancements, integrating\ntabular data, especially numerical data pivotal in clinical contexts, into LLM\nparadigms has not been thoroughly explored. In this study, we examine the\neffectiveness of vector representations from last hidden states of LLMs for\nmedical diagnostics and prognostics using electronic health record (EHR) data.\nWe compare the performance of these embeddings with that of raw numerical EHR\ndata when used as feature inputs to traditional machine learning (ML)\nalgorithms that excel at tabular data learning, such as eXtreme Gradient\nBoosting. We focus on instruction-tuned LLMs in a zero-shot setting to\nrepresent abnormal physiological data and evaluating their utilities as feature\nextractors to enhance ML classifiers for predicting diagnoses, length of stay,\nand mortality. Furthermore, we examine prompt engineering techniques on\nzero-shot and few-shot LLM embeddings to measure their impact comprehensively.\nAlthough findings suggest the raw data features still prevails in medical ML\ntasks, zero-shot LLM embeddings demonstrate competitive results, suggesting a\npromising avenue for future research in medical applications.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5f15\u5165\u63d0\u5347\u4e86\u8cc7\u6599\u8868\u793a\u548c\u5206\u6790\uff0c\u70ba\u5176\u5728\u91ab\u7642\u554f\u984c\u548c\u89e3\u7b54\u4e2d\u7684\u61c9\u7528\u5e36\u4f86\u986f\u8457\u9032\u5c55\u3002\u5118\u7ba1\u6709\u9019\u4e9b\u9032\u5c55\uff0c\u5c07\u8868\u683c\u8cc7\u6599\uff0c\u7279\u5225\u662f\u5728\u81e8\u5e8a\u80cc\u666f\u4e2d\u81f3\u95dc\u91cd\u8981\u7684\u6578\u503c\u8cc7\u6599\u6574\u5408\u5230 LLM \u5178\u7bc4\u4e2d\u5c1a\u672a\u5f97\u5230\u5fb9\u5e95\u63a2\u8a0e\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u4f86\u81ea LLM \u6700\u5f8c\u96b1\u85cf\u72c0\u614b\u7684\u5411\u91cf\u8868\u793a\u5728\u4f7f\u7528\u96fb\u5b50\u5065\u5eb7\u8a18\u9304 (EHR) \u8cc7\u6599\u9032\u884c\u91ab\u7642\u8a3a\u65b7\u548c\u9810\u5f8c\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u5c07\u9019\u4e9b\u5d4c\u5165\u7684\u6548\u80fd\u8207\u539f\u59cb\u6578\u503c EHR \u8cc7\u6599\u7684\u6548\u80fd\u9032\u884c\u6bd4\u8f03\uff0c\u5f8c\u8005\u7528\u4f5c\u50b3\u7d71\u6a5f\u5668\u5b78\u7fd2 (ML) \u6f14\u7b97\u6cd5\u7684\u7279\u5fb5\u8f38\u5165\uff0c\u9019\u4e9b\u6f14\u7b97\u6cd5\u64c5\u9577\u8868\u683c\u8cc7\u6599\u5b78\u7fd2\uff0c\u4f8b\u5982 eXtreme Gradient Boosting\u3002\u6211\u5011\u5c08\u6ce8\u65bc\u5728\u96f6\u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u9032\u884c\u6307\u4ee4\u8abf\u6574\u7684 LLM\uff0c\u4ee5\u8868\u793a\u7570\u5e38\u751f\u7406\u8cc7\u6599\uff0c\u4e26\u8a55\u4f30\u5176\u4f5c\u70ba\u7279\u5fb5\u8403\u53d6\u5668\u7684\u6548\u7528\uff0c\u4ee5\u589e\u5f37 ML \u5206\u985e\u5668\uff0c\u7528\u65bc\u9810\u6e2c\u8a3a\u65b7\u3001\u4f4f\u9662\u6642\u9593\u548c\u6b7b\u4ea1\u7387\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u96f6\u6b21\u5b78\u7fd2\u548c\u5c11\u6b21\u5b78\u7fd2 LLM \u5d4c\u5165\u7684\u63d0\u793a\u5de5\u7a0b\u6280\u8853\uff0c\u4ee5\u5168\u9762\u8861\u91cf\u5176\u5f71\u97ff\u3002\u5118\u7ba1\u7814\u7a76\u7d50\u679c\u8868\u660e\u539f\u59cb\u8cc7\u6599\u7279\u5fb5\u5728\u91ab\u7642 ML \u4efb\u52d9\u4e2d\u4ecd\u7136\u4f54\u512a\u52e2\uff0c\u4f46\u96f6\u6b21\u5b78\u7fd2 LLM \u5d4c\u5165\u5c55\u793a\u4e86\u5177\u6709\u7af6\u722d\u529b\u7684\u7d50\u679c\uff0c\u9019\u8868\u660e\u4e86\u672a\u4f86\u91ab\u7642\u61c9\u7528\u7814\u7a76\u7684\u4e00\u500b\u6709\u524d\u666f\u7684\u9014\u5f91\u3002", "author": "Yanjun Gao et.al.", "authors": "Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Matthew Churpek, Majid Afshar", "id": "2408.11854v1", "paper_url": "http://arxiv.org/abs/2408.11854v1", "repo": "null"}}