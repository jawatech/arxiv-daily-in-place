{"2501.14269": {"publish_time": "2025-01-24", "title": "Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation", "paper_summary": "Multi-modal sequential recommendation (SR) leverages multi-modal data to\nlearn more comprehensive item features and user preferences than traditional SR\nmethods, which has become a critical topic in both academia and industry.\nExisting methods typically focus on enhancing multi-modal information utility\nthrough adaptive modality fusion to capture the evolving of user preference\nfrom user-item interaction sequences. However, most of them overlook the\ninterference caused by redundant interest-irrelevant information contained in\nrich multi-modal data. Additionally, they primarily rely on implicit temporal\ninformation based solely on chronological ordering, neglecting explicit\ntemporal signals that could more effectively represent dynamic user interest\nover time. To address these limitations, we propose a Hierarchical time-aware\nMixture of experts for multi-modal Sequential Recommendation (HM4SR) with a\ntwo-level Mixture of Experts (MoE) and a multi-task learning strategy.\nSpecifically, the first MoE, named Interactive MoE, extracts essential user\ninterest-related information from the multi-modal data of each item. Then, the\nsecond MoE, termed Temporal MoE, captures user dynamic interests by introducing\nexplicit temporal embeddings from timestamps in modality encoding. To further\naddress data sparsity, we propose three auxiliary supervision tasks:\nsequence-level category prediction (CP) for item feature understanding,\ncontrastive learning on ID (IDCL) to align sequence context with user\ninterests, and placeholder contrastive learning (PCL) to integrate temporal\ninformation with modalities for dynamic interest modeling. Extensive\nexperiments on four public datasets verify the effectiveness of HM4SR compared\nto several state-of-the-art approaches.", "paper_summary_zh": "\u591a\u6a21\u6001\u987a\u5e8f\u63a8\u8350\uff08SR\uff09\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u6765\u5b66\u4e60\u6bd4\u4f20\u7edf SR \u65b9\u6cd5\u66f4\u5168\u9762\u7684\u9879\u76ee\u7279\u5f81\u548c\u7528\u6237\u504f\u597d\uff0c\u8fd9\u5df2\u6210\u4e3a\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u5173\u952e\u8bfe\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4e13\u6ce8\u4e8e\u901a\u8fc7\u81ea\u9002\u5e94\u6a21\u6001\u878d\u5408\u6765\u589e\u5f3a\u591a\u6a21\u6001\u4fe1\u606f\u6548\u7528\uff0c\u4ee5\u4ece\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u5e8f\u5217\u4e2d\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u6f14\u53d8\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u65b9\u6cd5\u5ffd\u7565\u4e86\u4e30\u5bcc\u591a\u6a21\u6001\u6570\u636e\u4e2d\u5305\u542b\u7684\u5197\u4f59\u4e0e\u5174\u8da3\u65e0\u5173\u7684\u4fe1\u606f\u6240\u9020\u6210\u7684\u5e72\u6270\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4ec5\u57fa\u4e8e\u65f6\u95f4\u987a\u5e8f\u7684\u9690\u5f0f\u65f6\u95f4\u4fe1\u606f\uff0c\u800c\u5ffd\u7565\u4e86\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8868\u793a\u52a8\u6001\u7528\u6237\u5174\u8da3\u7684\u663e\u5f0f\u65f6\u95f4\u4fe1\u53f7\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u4e24\u7ea7\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u7b56\u7565\u7684\u5206\u5c42\u65f6\u95f4\u611f\u77e5\u4e13\u5bb6\u6df7\u5408\u7528\u4e8e\u591a\u6a21\u6001\u987a\u5e8f\u63a8\u8350\uff08HM4SR\uff09\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7b2c\u4e00\u4e2a MoE\uff0c\u79f0\u4e3a\u4ea4\u4e92\u5f0f MoE\uff0c\u4ece\u6bcf\u4e2a\u9879\u76ee\u7684\u6a21\u6001\u6570\u636e\u4e2d\u63d0\u53d6\u57fa\u672c\u7684\u4e0e\u7528\u6237\u5174\u8da3\u76f8\u5173\u7684\u4fe1\u606f\u3002\u7136\u540e\uff0c\u7b2c\u4e8c\u4e2a MoE\uff0c\u79f0\u4e3a\u65f6\u95f4 MoE\uff0c\u901a\u8fc7\u5728\u6a21\u6001\u7f16\u7801\u4e2d\u5f15\u5165\u65f6\u95f4\u6233\u7684\u663e\u5f0f\u65f6\u95f4\u5d4c\u5165\u6765\u6355\u6349\u7528\u6237\u52a8\u6001\u5174\u8da3\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u89e3\u51b3\u6570\u636e\u7a00\u758f\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e09\u4e2a\u8f85\u52a9\u76d1\u7763\u4efb\u52a1\uff1a\u7528\u4e8e\u9879\u76ee\u7279\u5f81\u7406\u89e3\u7684\u5e8f\u5217\u7ea7\u7c7b\u522b\u9884\u6d4b\uff08CP\uff09\u3001\u7528\u4e8e\u5c06\u5e8f\u5217\u4e0a\u4e0b\u6587\u4e0e\u7528\u6237\u5174\u8da3\u5bf9\u9f50\u7684 ID \u5bf9\u6bd4\u5b66\u4e60\uff08IDCL\uff09\uff0c\u4ee5\u53ca\u7528\u4e8e\u5c06\u65f6\u95f4\u4fe1\u606f\u4e0e\u6a21\u6001\u6574\u5408\u4ee5\u8fdb\u884c\u52a8\u6001\u5174\u8da3\u5efa\u6a21\u7684\u5360\u4f4d\u7b26\u5bf9\u6bd4\u5b66\u4e60\uff08PCL\uff09\u3002\u5728\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86 HM4SR \u4e0e\u51e0\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\u7684\u6709\u6548\u6027\u3002", "author": "Shengzhe Zhang et.al.", "authors": "Shengzhe Zhang, Liyi Chen, Dazhong Shen, Chao Wang, Hui Xiong", "id": "2501.14269v1", "paper_url": "http://arxiv.org/abs/2501.14269v1", "repo": "https://github.com/SStarCCat/HM4SR"}}