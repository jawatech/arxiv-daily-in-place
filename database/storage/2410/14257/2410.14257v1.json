{"2410.14257": {"publish_time": "2024-10-18", "title": "Revisiting SLO and Goodput Metrics in LLM Serving", "paper_summary": "Large language models (LLMs) have achieved remarkable performance and are\nwidely deployed in various applications, while the serving of LLM inference has\nraised concerns about user experience and serving throughput. Accordingly,\nservice level objectives (SLOs) and goodput-the number of requests that meet\nSLOs per second-are introduced to evaluate the performance of LLM serving.\nHowever, existing metrics fail to capture the nature of user experience. We\nobserve two ridiculous phenomena in existing metrics: 1) delaying token\ndelivery can smooth the tail time between tokens (tail TBT) of a request and 2)\ndropping the request that fails to meet the SLOs midway can improve goodput.\n  In this paper, we revisit SLO and goodput metrics in LLM serving and propose\na unified metric framework smooth goodput including SLOs and goodput to reflect\nthe nature of user experience in LLM serving. The framework can adapt to\nspecific goals of different tasks by setting parameters. We re-evaluate the\nperformance of different LLM serving systems under multiple workloads based on\nthis unified framework and provide possible directions for future optimization\nof existing strategies. We hope that this framework can provide a unified\nstandard for evaluating LLM serving and foster researches in the field of LLM\nserving optimization to move in a cohesive direction.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u53d6\u5f97\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u4e26\u5ee3\u6cdb\u90e8\u7f72\u65bc\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u4e2d\uff0c\u800c LLM \u63a8\u8ad6\u7684\u670d\u52d9\u5df2\u5f15\u767c\u5c0d\u4f7f\u7528\u8005\u9ad4\u9a57\u548c\u670d\u52d9\u50b3\u8f38\u91cf\u7684\u7591\u616e\u3002\u56e0\u6b64\uff0c\u670d\u52d9\u7b49\u7d1a\u76ee\u6a19 (SLO) \u548c\u50b3\u8f38\u91cf\uff08\u6bcf\u79d2\u7b26\u5408 SLO \u7684\u8acb\u6c42\u6578\u91cf\uff09\u88ab\u5f15\u5165\u4ee5\u8a55\u4f30 LLM \u670d\u52d9\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u6307\u6a19\u7121\u6cd5\u6355\u6349\u4f7f\u7528\u8005\u9ad4\u9a57\u7684\u672c\u8cea\u3002\u6211\u5011\u5728\u73fe\u6709\u7684\u6307\u6a19\u4e2d\u89c0\u5bdf\u5230\u5169\u500b\u8352\u8b2c\u7684\u73fe\u8c61\uff1a1) \u5ef6\u9072\u4ee4\u724c\u50b3\u905e\u53ef\u4ee5\u5e73\u6ed1\u8acb\u6c42\u7684\u4ee4\u724c\u4e4b\u9593\u7684\u5c3e\u7aef\u6642\u9593 (tail TBT)\uff0c2) \u653e\u68c4\u7121\u6cd5\u6eff\u8db3 SLO \u7684\u8acb\u6c42\u53ef\u4ee5\u6539\u5584\u50b3\u8f38\u91cf\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u91cd\u65b0\u6aa2\u8996 LLM \u670d\u52d9\u4e2d\u7684 SLO \u548c\u50b3\u8f38\u91cf\u6307\u6a19\uff0c\u4e26\u63d0\u51fa\u4e00\u500b\u7d71\u4e00\u7684\u6307\u6a19\u67b6\u69cb\u5e73\u6ed1\u50b3\u8f38\u91cf\uff0c\u5305\u62ec SLO \u548c\u50b3\u8f38\u91cf\uff0c\u4ee5\u53cd\u6620 LLM \u670d\u52d9\u4e2d\u4f7f\u7528\u8005\u9ad4\u9a57\u7684\u672c\u8cea\u3002\u8a72\u67b6\u69cb\u53ef\u4ee5\u900f\u904e\u8a2d\u5b9a\u53c3\u6578\u4f86\u9069\u61c9\u4e0d\u540c\u4efb\u52d9\u7684\u7279\u5b9a\u76ee\u6a19\u3002\u6211\u5011\u6839\u64da\u9019\u500b\u7d71\u4e00\u7684\u67b6\u69cb\uff0c\u5728\u591a\u500b\u5de5\u4f5c\u8ca0\u8f09\u4e0b\u91cd\u65b0\u8a55\u4f30\u4e0d\u540c LLM \u670d\u52d9\u7cfb\u7d71\u7684\u6548\u80fd\uff0c\u4e26\u70ba\u73fe\u6709\u7b56\u7565\u7684\u672a\u4f86\u6700\u4f73\u5316\u63d0\u4f9b\u53ef\u80fd\u7684\u65b9\u91dd\u3002\u6211\u5011\u5e0c\u671b\u9019\u500b\u67b6\u69cb\u53ef\u4ee5\u70ba\u8a55\u4f30 LLM \u670d\u52d9\u63d0\u4f9b\u4e00\u500b\u7d71\u4e00\u7684\u6a19\u6e96\uff0c\u4e26\u4fc3\u9032 LLM \u670d\u52d9\u6700\u4f73\u5316\u9818\u57df\u7684\u7814\u7a76\u671d\u5411\u4e00\u500b\u4e00\u81f4\u7684\u65b9\u5411\u524d\u9032\u3002", "author": "Zhibin Wang et.al.", "authors": "Zhibin Wang, Shipeng Li, Yuhang Zhou, Xue Li, Rong Gu, Nguyen Cam-Tu, Chen Tian, Sheng Zhong", "id": "2410.14257v1", "paper_url": "http://arxiv.org/abs/2410.14257v1", "repo": "null"}}