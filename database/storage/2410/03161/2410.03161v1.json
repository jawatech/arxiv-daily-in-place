{"2410.03161": {"publish_time": "2024-10-04", "title": "Adaptive Masking Enhances Visual Grounding", "paper_summary": "In recent years, zero-shot and few-shot learning in visual grounding have\ngarnered considerable attention, largely due to the success of large-scale\nvision-language pre-training on expansive datasets such as LAION-5B and\nDataComp-1B. However, the continuous expansion of these datasets presents\nsignificant challenges, particularly with respect to data availability and\ncomputational overhead, thus creating a bottleneck in the advancement of\nlow-shot learning capabilities. In this paper, we propose IMAGE, Interpretative\nMAsking with Gaussian radiation modEling, aimed at enhancing vocabulary\ngrounding in low-shot learning scenarios without necessitating an increase in\ndataset size. Drawing inspiration from cognitive science and the recent success\nof masked autoencoders (MAE), our method leverages adaptive masking on salient\nregions of the feature maps generated by the vision backbone. This enables the\nmodel to learn robust, generalized representations through the reconstruction\nof occluded information, thereby facilitating effective attention to both local\nand global features. We evaluate the efficacy of our approach on benchmark\ndatasets, including COCO and ODinW, demonstrating its superior performance in\nzero-shot and few-shot tasks. Experimental results consistently show that IMAGE\noutperforms baseline models, achieving enhanced generalization and improved\nperformance in low-shot scenarios. These findings highlight the potential of\nadaptive feature manipulation through attention mechanisms and Gaussian\nmodeling as a promising alternative to approaches that rely on the continual\nscaling of dataset sizes for the advancement of zero-shot and few-shot\nlearning. Our code is publicly available at https://github.com/git-lenny/IMAGE.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u89c6\u89c9\u57fa\u7840\u4e2d\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u5907\u53d7\u5173\u6ce8\uff0c\u8fd9\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5f52\u529f\u4e8e\u5728 LAION-5B \u548c DataComp-1B \u7b49\u6269\u5c55\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u9884\u8bad\u7ec3\u7684\u6210\u529f\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u6301\u7eed\u6269\u5c55\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u53ef\u7528\u6027\u548c\u8ba1\u7b97\u5f00\u9500\u65b9\u9762\uff0c\u4ece\u800c\u5728\u4f4e\u6837\u672c\u5b66\u4e60\u80fd\u529b\u7684\u63d0\u5347\u65b9\u9762\u9020\u6210\u4e86\u74f6\u9888\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 IMAGE\uff0c\u5373\u4f7f\u7528\u9ad8\u65af\u8f90\u5c04\u5efa\u6a21\u7684\u89e3\u91ca\u6027\u63a9\u853d\uff0c\u65e8\u5728\u589e\u5f3a\u4f4e\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u8bcd\u6c47\u57fa\u7840\uff0c\u800c\u65e0\u9700\u589e\u52a0\u6570\u636e\u96c6\u5927\u5c0f\u3002\u4ece\u8ba4\u77e5\u79d1\u5b66\u548c\u63a9\u7801\u81ea\u52a8\u7f16\u7801\u5668 (MAE) \u7684\u6700\u65b0\u6210\u529f\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u4e86\u5bf9\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\u751f\u6210\u7684\u7279\u5f81\u56fe\u7684\u663e\u7740\u533a\u57df\u7684\u81ea\u9002\u5e94\u63a9\u853d\u3002\u8fd9\u4f7f\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u91cd\u5efa\u88ab\u906e\u6321\u7684\u4fe1\u606f\u6765\u5b66\u4e60\u9c81\u68d2\u7684\u3001\u6cdb\u5316\u7684\u8868\u793a\uff0c\u4ece\u800c\u4fc3\u8fdb\u5bf9\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u7684\u6709\u6548\u5173\u6ce8\u3002\u6211\u4eec\u5728\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5305\u62ec COCO \u548c ODinW\uff09\u4e0a\u8bc4\u4f30\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u4efb\u52a1\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u4e00\u81f4\u8868\u660e\uff0cIMAGE \u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u4f4e\u6837\u672c\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u589e\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6539\u8fdb\u7684\u6027\u80fd\u3002\u8fd9\u4e9b\u53d1\u73b0\u7a81\u51fa\u4e86\u81ea\u9002\u5e94\u7279\u5f81\u64cd\u4f5c\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u6ce8\u610f\u673a\u5236\u548c\u9ad8\u65af\u5efa\u6a21\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u9014\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u53d6\u4ee3\u4f9d\u8d56\u4e8e\u6570\u636e\u96c6\u5927\u5c0f\u7684\u6301\u7eed\u6269\u5c55\u6765\u63a8\u8fdb\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u7684\u4ee3\u7801\u5df2\u516c\u5f00\u53d1\u5e03\uff0c\u7f51\u5740\u4e3a https://github.com/git-lenny/IMAGE\u3002", "author": "Sen Jia et.al.", "authors": "Sen Jia, Lei Li", "id": "2410.03161v1", "paper_url": "http://arxiv.org/abs/2410.03161v1", "repo": "null"}}