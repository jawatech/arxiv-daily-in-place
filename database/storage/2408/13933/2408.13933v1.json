{"2408.13933": {"publish_time": "2024-08-25", "title": "MobileQuant: Mobile-friendly Quantization for On-device Language Models", "paper_summary": "Large language models (LLMs) have revolutionized language processing,\ndelivering outstanding results across multiple applications. However, deploying\nLLMs on edge devices poses several challenges with respect to memory, energy,\nand compute costs, limiting their widespread use in devices such as mobile\nphones. A promising solution is to reduce the number of bits used to represent\nweights and activations. While existing works have found partial success at\nquantizing LLMs to lower bitwidths, e.g. 4-bit weights, quantizing activations\nbeyond 16 bits often leads to large computational overheads due to poor\non-device quantization support, or a considerable accuracy drop. Yet, 8-bit\nactivations are very attractive for on-device deployment as they would enable\nLLMs to fully exploit mobile-friendly hardware, e.g. Neural Processing Units\n(NPUs). In this work, we make a first attempt to facilitate the on-device\ndeployment of LLMs using integer-only quantization. We first investigate the\nlimitations of existing quantization methods for on-device deployment, with a\nspecial focus on activation quantization. We then address these limitations by\nintroducing a simple post-training quantization method, named MobileQuant, that\nextends previous weight equivalent transformation works by jointly optimizing\nthe weight transformation and activation range parameters in an end-to-end\nmanner. MobileQuant demonstrates superior capabilities over existing methods by\n1) achieving near-lossless quantization on a wide range of LLM benchmarks, 2)\nreducing latency and energy consumption by 20\\%-50\\% compared to current\non-device quantization strategies, 3) requiring limited compute budget, 4)\nbeing compatible with mobile-friendly compute units, e.g. NPU.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5fb9\u5e95\u6539\u8b8a\u4e86\u8a9e\u8a00\u8655\u7406\uff0c\u5728\u591a\u7a2e\u61c9\u7528\u4e2d\u63d0\u4f9b\u4e86\u5091\u51fa\u7684\u6210\u679c\u3002\u7136\u800c\uff0c\u5728\u908a\u7de3\u88dd\u7f6e\u4e0a\u90e8\u7f72 LLM \u5728\u8a18\u61b6\u9ad4\u3001\u80fd\u6e90\u548c\u904b\u7b97\u6210\u672c\u65b9\u9762\u63d0\u51fa\u4e86\u82e5\u5e72\u6311\u6230\uff0c\u9650\u5236\u4e86\u5b83\u5011\u5728\u884c\u52d5\u96fb\u8a71\u7b49\u88dd\u7f6e\u4e2d\u7684\u5ee3\u6cdb\u4f7f\u7528\u3002\u4e00\u500b\u6709\u524d\u9014\u7684\u89e3\u6c7a\u65b9\u6848\u662f\u6e1b\u5c11\u7528\u65bc\u8868\u793a\u6b0a\u91cd\u548c\u6fc0\u6d3b\u7684\u4f4d\u5143\u6578\u3002\u5118\u7ba1\u73fe\u6709\u4f5c\u54c1\u5728\u5c07 LLM \u91cf\u5316\u70ba\u8f03\u4f4e\u4f4d\u5bec\u5ea6\uff08\u4f8b\u5982 4 \u4f4d\u5143\u6b0a\u91cd\uff09\u65b9\u9762\u53d6\u5f97\u4e86\u90e8\u5206\u6210\u529f\uff0c\u4f46\u5c07\u6fc0\u6d3b\u91cf\u5316\u5230 16 \u4f4d\u5143\u4ee5\u4e0a\u901a\u5e38\u6703\u5c0e\u81f4\u5de8\u5927\u7684\u904b\u7b97\u958b\u92b7\uff0c\u9019\u662f\u7531\u65bc\u88dd\u7f6e\u4e0a\u91cf\u5316\u652f\u63f4\u4e0d\u4f73\u6216\u7cbe\u78ba\u5ea6\u5927\u5e45\u4e0b\u964d\u6240\u81f4\u3002\u7136\u800c\uff0c8 \u4f4d\u5143\u6fc0\u6d3b\u5c0d\u65bc\u88dd\u7f6e\u4e0a\u90e8\u7f72\u975e\u5e38\u6709\u5438\u5f15\u529b\uff0c\u56e0\u70ba\u5b83\u5011\u80fd\u8b93 LLM \u5145\u5206\u5229\u7528\u884c\u52d5\u88dd\u7f6e\u53cb\u5584\u7684\u786c\u9ad4\uff0c\u4f8b\u5982\u795e\u7d93\u8655\u7406\u55ae\u5143 (NPU)\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u9996\u6b21\u5617\u8a66\u4f7f\u7528\u50c5\u6574\u6578\u91cf\u5316\u4f86\u4fc3\u9032 LLM \u7684\u88dd\u7f6e\u4e0a\u90e8\u7f72\u3002\u6211\u5011\u9996\u5148\u63a2\u8a0e\u73fe\u6709\u91cf\u5316\u65b9\u6cd5\u5728\u88dd\u7f6e\u4e0a\u90e8\u7f72\u7684\u9650\u5236\uff0c\u7279\u5225\u95dc\u6ce8\u6fc0\u6d3b\u91cf\u5316\u3002\u7136\u5f8c\uff0c\u6211\u5011\u900f\u904e\u5f15\u5165\u4e00\u7a2e\u540d\u70ba MobileQuant \u7684\u7c21\u55ae\u8a13\u7df4\u5f8c\u91cf\u5316\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u8a72\u65b9\u6cd5\u900f\u904e\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u5171\u540c\u6700\u4f73\u5316\u6b0a\u91cd\u8f49\u63db\u548c\u6fc0\u6d3b\u7bc4\u570d\u53c3\u6578\uff0c\u4f86\u5ef6\u4f38\u5148\u524d\u7684\u6b0a\u91cd\u7b49\u6548\u8f49\u63db\u5de5\u4f5c\u3002MobileQuant \u5c55\u793a\u4e86\u6bd4\u73fe\u6709\u65b9\u6cd5\u66f4\u512a\u8d8a\u7684\u80fd\u529b\uff0c\u65b9\u6cd5\u662f 1) \u5728\u5ee3\u6cdb\u7684 LLM \u8a55\u91cf\u57fa\u6e96\u4e0a\u9054\u6210\u8fd1\u4e4e\u7121\u640d\u5931\u7684\u91cf\u5316\uff0c2) \u8207\u76ee\u524d\u7684\u88dd\u7f6e\u4e0a\u91cf\u5316\u7b56\u7565\u76f8\u6bd4\uff0c\u5c07\u5ef6\u9072\u548c\u80fd\u6e90\u6d88\u8017\u964d\u4f4e\u4e86 20%-50%\uff0c3) \u9700\u8981\u7684\u904b\u7b97\u9810\u7b97\u6709\u9650\uff0c4) \u8207\u884c\u52d5\u88dd\u7f6e\u53cb\u5584\u7684\u904b\u7b97\u55ae\u5143\uff08\u4f8b\u5982 NPU\uff09\u76f8\u5bb9\u3002", "author": "Fuwen Tan et.al.", "authors": "Fuwen Tan, Royson Lee, \u0141ukasz Dudziak, Shell Xu Hu, Sourav Bhattacharya, Timothy Hospedales, Georgios Tzimiropoulos, Brais Martinez", "id": "2408.13933v1", "paper_url": "http://arxiv.org/abs/2408.13933v1", "repo": "https://github.com/saic-fi/mobilequant"}}