{"2409.02512": {"publish_time": "2024-09-04", "title": "Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal", "paper_summary": "Artificial neural networks, especially recent diffusion-based models, have\nshown remarkable superiority in gaming, control, and QA systems, where the\ntraining tasks' datasets are usually static. However, in real-world\napplications, such as robotic control of reinforcement learning (RL), the tasks\nare changing, and new tasks arise in a sequential order. This situation poses\nthe new challenge of plasticity-stability trade-off for training an agent who\ncan adapt to task changes and retain acquired knowledge. In view of this, we\npropose a rehearsal-based continual diffusion model, called Continual Diffuser\n(CoD), to endow the diffuser with the capabilities of quick adaptation\n(plasticity) and lasting retention (stability). Specifically, we first\nconstruct an offline benchmark that contains 90 tasks from multiple domains.\nThen, we train the CoD on each task with sequential modeling and conditional\ngeneration for making decisions. Next, we preserve a small portion of previous\ndatasets as the rehearsal buffer and replay it to retain the acquired\nknowledge. Extensive experiments on a series of tasks show CoD can achieve a\npromising plasticity-stability trade-off and outperform existing\ndiffusion-based methods and other representative baselines on most tasks.", "paper_summary_zh": "\u4eba\u5de5\u795e\u7d93\u7db2\u8def\uff0c\u5c24\u5176\u662f\u8fd1\u671f\u57fa\u65bc\u64f4\u6563\u7684\u6a21\u578b\uff0c\u5728\u904a\u6232\u3001\u63a7\u5236\u548c\u554f\u7b54\u7cfb\u7d71\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u512a\u8d8a\u6027\uff0c\u5176\u4e2d\u8a13\u7df4\u4efb\u52d9\u7684\u8cc7\u6599\u96c6\u901a\u5e38\u662f\u975c\u614b\u7684\u3002\u7136\u800c\uff0c\u5728\u771f\u5be6\u4e16\u754c\u7684\u61c9\u7528\u4e2d\uff0c\u4f8b\u5982\u5f37\u5316\u5b78\u7fd2 (RL) \u7684\u6a5f\u5668\u4eba\u63a7\u5236\uff0c\u4efb\u52d9\u6703\u767c\u751f\u8b8a\u5316\uff0c\u800c\u4e14\u6703\u6309\u9806\u5e8f\u51fa\u73fe\u65b0\u4efb\u52d9\u3002\u9019\u7a2e\u60c5\u6cc1\u5c0d\u8a13\u7df4\u4ee3\u7406\u4eba\u9069\u61c9\u4efb\u52d9\u8b8a\u5316\u4e26\u4fdd\u7559\u7fd2\u5f97\u77e5\u8b58\u63d0\u51fa\u4e86\u53ef\u5851\u6027\u7a69\u5b9a\u6027\u6b0a\u8861\u7684\u65b0\u6311\u6230\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u8907\u7fd2\u7684\u6301\u7e8c\u64f4\u6563\u6a21\u578b\uff0c\u7a31\u70ba\u6301\u7e8c\u64f4\u6563\u5668 (CoD)\uff0c\u8ce6\u4e88\u64f4\u6563\u5668\u5feb\u901f\u9069\u61c9\uff08\u53ef\u5851\u6027\uff09\u548c\u6301\u4e45\u4fdd\u7559\uff08\u7a69\u5b9a\u6027\uff09\u7684\u80fd\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9996\u5148\u69cb\u5efa\u4e00\u500b\u5305\u542b\u4f86\u81ea\u591a\u500b\u9818\u57df\u7684 90 \u500b\u4efb\u52d9\u7684\u96e2\u7dda\u57fa\u6e96\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528\u9806\u5e8f\u5efa\u6a21\u548c\u689d\u4ef6\u751f\u6210\u5c0d\u6bcf\u500b\u4efb\u52d9\u8a13\u7df4 CoD \u4ee5\u505a\u51fa\u6c7a\u7b56\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u4fdd\u7559\u4e00\u5c0f\u90e8\u5206\u5148\u524d\u7684\u8cc7\u6599\u96c6\u4f5c\u70ba\u8907\u7fd2\u7de9\u885d\u5340\uff0c\u4e26\u91cd\u64ad\u5b83\u4ee5\u4fdd\u7559\u7fd2\u5f97\u7684\u77e5\u8b58\u3002\u5728\u4e00\u7cfb\u5217\u4efb\u52d9\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0cCoD \u53ef\u4ee5\u5be6\u73fe\u6709\u524d\u666f\u7684\u53ef\u5851\u6027\u7a69\u5b9a\u6027\u6b0a\u8861\uff0c\u4e26\u5728\u591a\u6578\u4efb\u52d9\u4e0a\u512a\u65bc\u73fe\u6709\u7684\u57fa\u65bc\u64f4\u6563\u7684\u65b9\u6cd5\u548c\u5176\u4ed6\u4ee3\u8868\u6027\u57fa\u6e96\u3002", "author": "Jifeng Hu et.al.", "authors": "Jifeng Hu, Li Shen, Sili Huang, Zhejian Yang, Hechang Chen, Lichao Sun, Yi Chang, Dacheng Tao", "id": "2409.02512v1", "paper_url": "http://arxiv.org/abs/2409.02512v1", "repo": "null"}}