{"2302.01241": {"publish_time": "2023-02-02", "title": "Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses", "paper_summary": "Many visualizations have been developed for explainable AI (XAI), but they\noften require further reasoning by users to interpret. We argue that XAI should\nsupport diagrammatic and abductive reasoning for the AI to perform hypothesis\ngeneration and evaluation to reduce the interpretability gap. We propose\nDiagrammatization to i) perform Peircean abductive-deductive reasoning, ii)\nfollow domain conventions, and iii) explain with diagrams visually or verbally.\nWe implemented DiagramNet for a clinical application to predict cardiac\ndiagnoses from heart auscultation, and explain with shape-based murmur\ndiagrams. In modeling studies, we found that DiagramNet not only provides\nfaithful murmur shape explanations, but also has better prediction performance\nthan baseline models. We further demonstrate the interpretability and\ntrustworthiness of diagrammatic explanations in a qualitative user study with\nmedical students, showing that clinically-relevant, diagrammatic explanations\nare preferred over technical saliency map explanations. This work contributes\ninsights into providing domain-conventional abductive explanations for\nuser-centric XAI.", "paper_summary_zh": "", "author": "Brian Y. Lim et.al.", "authors": "Brian Y. Lim,Joseph P. Cahaly,Chester Y. F. Sng,Adam Chew", "id": "2302.01241v2", "paper_url": "http://arxiv.org/abs/2302.01241v2", "repo": "null"}}