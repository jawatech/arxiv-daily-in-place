{"2406.18333": {"publish_time": "2024-06-26", "title": "Continuous Sign Language Recognition Using Intra-inter Gloss Attention", "paper_summary": "Many continuous sign language recognition (CSLR) studies adopt\ntransformer-based architectures for sequence modeling due to their powerful\ncapacity for capturing global contexts. Nevertheless, vanilla self-attention,\nwhich serves as the core module of the transformer, calculates a weighted\naverage over all time steps; therefore, the local temporal semantics of sign\nvideos may not be fully exploited. In this study, we introduce a novel module\nin sign language recognition studies, called intra-inter gloss attention\nmodule, to leverage the relationships among frames within glosses and the\nsemantic and grammatical dependencies between glosses in the video. In the\nintra-gloss attention module, the video is divided into equally sized chunks\nand a self-attention mechanism is applied within each chunk. This localized\nself-attention significantly reduces complexity and eliminates noise introduced\nby considering non-relative frames. In the inter-gloss attention module, we\nfirst aggregate the chunk-level features within each gloss chunk by average\npooling along the temporal dimension. Subsequently, multi-head self-attention\nis applied to all chunk-level features. Given the non-significance of the\nsigner-environment interaction, we utilize segmentation to remove the\nbackground of the videos. This enables the proposed model to direct its focus\ntoward the signer. Experimental results on the PHOENIX-2014 benchmark dataset\ndemonstrate that our method can effectively extract sign language features in\nan end-to-end manner without any prior knowledge, improve the accuracy of CSLR,\nand achieve the word error rate (WER) of 20.4 on the test set which is a\ncompetitive result compare to the state-of-the-art which uses additional\nsupervisions.", "paper_summary_zh": "\u8a31\u591a\u9023\u7e8c\u624b\u8a9e\u8b58\u5225 (CSLR) \u7814\u7a76\u63a1\u7528\u57fa\u65bc\u8f49\u63db\u5668\u7684\u67b6\u69cb\u9032\u884c\u5e8f\u5217\u5efa\u6a21\uff0c\u56e0\u70ba\u5b83\u5011\u5177\u6709\u6355\u6349\u5168\u5c40\u8108\u7d61\u7684\u5f37\u5927\u80fd\u529b\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u4f5c\u70ba\u8f49\u63db\u5668\u6838\u5fc3\u6a21\u7d44\u7684\u9999\u8349\u81ea\u6ce8\u610f\u529b\u6703\u8a08\u7b97\u6240\u6709\u6642\u9593\u6b65\u9577\u7684\u52a0\u6b0a\u5e73\u5747\u503c\uff1b\u56e0\u6b64\uff0c\u624b\u8a9e\u5f71\u7247\u7684\u5c40\u90e8\u6642\u9593\u8a9e\u7fa9\u53ef\u80fd\u7121\u6cd5\u88ab\u5145\u5206\u5229\u7528\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5728\u624b\u8a9e\u8b58\u5225\u7814\u7a76\u4e2d\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u6a21\u7d44\uff0c\u7a31\u70ba\u53e5\u5167\u53e5\u9593\u5149\u7167\u6ce8\u610f\u529b\u6a21\u7d44\uff0c\u4ee5\u5229\u7528\u624b\u52e2\u5167\u7684\u5e40\u4e4b\u9593\u7684\u95dc\u4fc2\u4ee5\u53ca\u5f71\u7247\u4e2d\u624b\u52e2\u4e4b\u9593\u7684\u8a9e\u7fa9\u548c\u8a9e\u6cd5\u4f9d\u8cf4\u6027\u3002\u5728\u53e5\u5167\u6ce8\u610f\u529b\u6a21\u7d44\u4e2d\uff0c\u5f71\u7247\u88ab\u5206\u6210\u5927\u5c0f\u76f8\u7b49\u7684\u584a\uff0c\u4e26\u5728\u6bcf\u500b\u584a\u5167\u61c9\u7528\u81ea\u6ce8\u610f\u529b\u6a5f\u5236\u3002\u9019\u7a2e\u5c40\u90e8\u81ea\u6ce8\u610f\u529b\u986f\u8457\u964d\u4f4e\u4e86\u8907\u96dc\u6027\uff0c\u4e26\u6d88\u9664\u4e86\u8003\u616e\u975e\u76f8\u95dc\u5e40\u6240\u7522\u751f\u7684\u96dc\u8a0a\u3002\u5728\u53e5\u9593\u6ce8\u610f\u529b\u6a21\u7d44\u4e2d\uff0c\u6211\u5011\u9996\u5148\u900f\u904e\u6cbf\u6642\u9593\u7dad\u5ea6\u9032\u884c\u5e73\u5747\u6c60\u5316\uff0c\u5f59\u7e3d\u6bcf\u500b\u624b\u52e2\u584a\u5167\u7684\u584a\u7d1a\u7279\u5fb5\u3002\u96a8\u5f8c\uff0c\u5c07\u591a\u982d\u81ea\u6ce8\u610f\u529b\u61c9\u7528\u65bc\u6240\u6709\u584a\u7d1a\u7279\u5fb5\u3002\u9451\u65bc\u624b\u52e2\u8005\u74b0\u5883\u4e92\u52d5\u7684\u4e0d\u986f\u8457\u6027\uff0c\u6211\u5011\u5229\u7528\u5206\u5272\u4f86\u79fb\u9664\u5f71\u7247\u7684\u80cc\u666f\u3002\u9019\u4f7f\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u5920\u5c07\u5176\u7126\u9ede\u5c0e\u5411\u624b\u52e2\u8005\u3002PHOENIX-2014 \u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u80fd\u5920\u5728\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u4e2d\u6709\u6548\u5730\u63d0\u53d6\u624b\u8a9e\u7279\u5fb5\uff0c\u800c\u7121\u9700\u4efb\u4f55\u5148\u9a57\u77e5\u8b58\uff0c\u63d0\u9ad8 CSLR \u7684\u6e96\u78ba\u6027\uff0c\u4e26\u5728\u6e2c\u8a66\u96c6\u4e0a\u5be6\u73fe 20.4 \u7684\u5b57\u5143\u932f\u8aa4\u7387 (WER)\uff0c\u9019\u662f\u4e00\u500b\u8207\u4f7f\u7528\u984d\u5916\u76e3\u7763\u7684\u6700\u65b0\u6280\u8853\u76f8\u6bd4\u5177\u6709\u7af6\u722d\u529b\u7684\u7d50\u679c\u3002", "author": "Hossein Ranjbar et.al.", "authors": "Hossein Ranjbar, Alireza Taheri", "id": "2406.18333v1", "paper_url": "http://arxiv.org/abs/2406.18333v1", "repo": "null"}}