{"2411.00871": {"publish_time": "2024-10-31", "title": "LLaMo: Large Language Model-based Molecular Graph Assistant", "paper_summary": "Large Language Models (LLMs) have demonstrated remarkable generalization and\ninstruction-following capabilities with instruction tuning. The advancements in\nLLMs and instruction tuning have led to the development of Large\nVision-Language Models (LVLMs). However, the competency of the LLMs and\ninstruction tuning have been less explored in the molecular domain. Thus, we\npropose LLaMo: Large Language Model-based Molecular graph assistant, which is\nan end-to-end trained large molecular graph-language model. To bridge the\ndiscrepancy between the language and graph modalities, we present the\nmulti-level graph projector that transforms graph representations into graph\ntokens by abstracting the output representations of each GNN layer and motif\nrepresentations with the cross-attention mechanism. We also introduce\nmachine-generated molecular graph instruction data to instruction-tune the\nlarge molecular graph-language model for general-purpose molecule and language\nunderstanding. Our extensive experiments demonstrate that LLaMo shows the best\nperformance on diverse tasks, such as molecular description generation,\nproperty prediction, and IUPAC name prediction. The code of LLaMo is available\nat https://github.com/mlvlab/LLaMo.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u793a\u51fa\u5353\u8d8a\u7684\u6982\u62ec\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u5e76\u8fdb\u884c\u6307\u4ee4\u8c03\u6574\u3002LLM \u548c\u6307\u4ee4\u8c03\u6574\u7684\u8fdb\u6b65\u5bfc\u81f4\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (LVLMs) \u7684\u53d1\u5c55\u3002\u7136\u800c\uff0cLLM \u548c\u6307\u4ee4\u8c03\u6574\u7684\u80fd\u529b\u5728\u5206\u5b50\u9886\u57df\u7684\u7814\u7a76\u8f83\u5c11\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 LLaMo\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u56fe\u52a9\u624b\uff0c\u8fd9\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u5927\u5206\u5b50\u56fe\u8bed\u8a00\u6a21\u578b\u3002\u4e3a\u4e86\u5f25\u5408\u8bed\u8a00\u548c\u56fe\u6a21\u5f0f\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u591a\u7ea7\u56fe\u6295\u5f71\u4eea\uff0c\u5b83\u901a\u8fc7\u62bd\u8c61\u6bcf\u4e2a GNN \u5c42\u7684\u8f93\u51fa\u8868\u793a\u548c\u57fa\u5e8f\u8868\u793a\uff08\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff09\u5c06\u56fe\u8868\u793a\u8f6c\u6362\u4e3a\u56fe\u6807\u8bb0\u3002\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u673a\u5668\u751f\u6210\u7684\u5206\u5b50\u56fe\u6307\u4ee4\u6570\u636e\uff0c\u4ee5\u5bf9\u5927\u578b\u5206\u5b50\u56fe\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6307\u4ee4\u8c03\u6574\uff0c\u4ee5\u7528\u4e8e\u901a\u7528\u5206\u5b50\u548c\u8bed\u8a00\u7406\u89e3\u3002\u6211\u4eec\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLaMo \u5728\u5206\u5b50\u63cf\u8ff0\u751f\u6210\u3001\u5c5e\u6027\u9884\u6d4b\u548c IUPAC \u540d\u79f0\u9884\u6d4b\u7b49\u4e0d\u540c\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u6700\u4f73\u6027\u80fd\u3002LLaMo \u7684\u4ee3\u7801\u53ef\u5728 https://github.com/mlvlab/LLaMo \u83b7\u5f97\u3002", "author": "Jinyoung Park et.al.", "authors": "Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim", "id": "2411.00871v1", "paper_url": "http://arxiv.org/abs/2411.00871v1", "repo": "null"}}