{"2411.06928": {"publish_time": "2024-11-11", "title": "Electroencephalogram-based Multi-class Decoding of Attended Speakers' Direction with Audio Spatial Spectrum", "paper_summary": "Decoding the directional focus of an attended speaker from listeners'\nelectroencephalogram (EEG) signals is essential for developing brain-computer\ninterfaces to improve the quality of life for individuals with hearing\nimpairment. Previous works have concentrated on binary directional focus\ndecoding, i.e., determining whether the attended speaker is on the left or\nright side of the listener. However, a more precise decoding of the exact\ndirection of the attended speaker is necessary for effective speech processing.\nAdditionally, audio spatial information has not been effectively leveraged,\nresulting in suboptimal decoding results. In this paper, we observe that, on\nour recently presented dataset with 15-class directional focus, models relying\nexclusively on EEG inputs exhibits significantly lower accuracy when decoding\nthe directional focus in both leave-one-subject-out and leave-one-trial-out\nscenarios. By integrating audio spatial spectra with EEG features, the decoding\naccuracy can be effectively improved. We employ the CNN, LSM-CNN, and\nEEG-Deformer models to decode the directional focus from listeners' EEG signals\nwith the auxiliary audio spatial spectra. The proposed Sp-Aux-Deformer model\nachieves notable 15-class decoding accuracies of 57.48% and 61.83% in\nleave-one-subject-out and leave-one-trial-out scenarios, respectively.", "paper_summary_zh": "\u89e3\u78bc\u807d\u773e\u8166\u96fb\u5716 (EEG) \u8a0a\u865f\u4e2d\u53d7\u95dc\u6ce8\u8aaa\u8a71\u8005\u7684\u65b9\u5411\u7126\u9ede\u5c0d\u65bc\u958b\u767c\u8166\u96fb\u8166\u4ecb\u9762\u81f3\u95dc\u91cd\u8981\uff0c\u4ee5\u63d0\u9ad8\u807d\u529b\u53d7\u640d\u8005\u7684\u751f\u6d3b\u54c1\u8cea\u3002\u5148\u524d\u7684\u7814\u7a76\u96c6\u4e2d\u65bc\u4e8c\u9032\u4f4d\u65b9\u5411\u7126\u9ede\u89e3\u78bc\uff0c\u5373\u5224\u65b7\u53d7\u95dc\u6ce8\u7684\u8aaa\u8a71\u8005\u5728\u807d\u773e\u7684\u5de6\u5074\u9084\u662f\u53f3\u5074\u3002\u7136\u800c\uff0c\u7cbe\u78ba\u89e3\u78bc\u53d7\u95dc\u6ce8\u8aaa\u8a71\u8005\u7684\u78ba\u5207\u65b9\u5411\u5c0d\u65bc\u6709\u6548\u7684\u8a9e\u97f3\u8655\u7406\u662f\u5fc5\u8981\u7684\u3002\u6b64\u5916\uff0c\u97f3\u8a0a\u7a7a\u9593\u8cc7\u8a0a\u5c1a\u672a\u88ab\u6709\u6548\u5229\u7528\uff0c\u5c0e\u81f4\u6b21\u4f73\u89e3\u78bc\u7d50\u679c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u5728\u6211\u5011\u6700\u8fd1\u63d0\u51fa\u7684 15 \u985e\u65b9\u5411\u7126\u9ede\u8cc7\u6599\u96c6\u4e2d\uff0c\u50c5\u4f9d\u8cf4 EEG \u8f38\u5165\u7684\u6a21\u578b\u5728\u96e2\u958b\u4e00\u500b\u53d7\u8a66\u8005\u548c\u96e2\u958b\u4e00\u500b\u8a66\u9a57\u7684\u5834\u666f\u4e2d\u89e3\u78bc\u65b9\u5411\u7126\u9ede\u6642\uff0c\u6e96\u78ba\u5ea6\u986f\u8457\u964d\u4f4e\u3002\u900f\u904e\u5c07\u97f3\u8a0a\u7a7a\u9593\u983b\u8b5c\u8207 EEG \u7279\u5fb5\u6574\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u89e3\u78bc\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u63a1\u7528 CNN\u3001LSM-CNN \u548c EEG-Deformer \u6a21\u578b\u5f9e\u807d\u773e\u7684 EEG \u8a0a\u865f\u4e2d\u89e3\u78bc\u65b9\u5411\u7126\u9ede\uff0c\u4e26\u8f14\u4ee5\u97f3\u8a0a\u7a7a\u9593\u983b\u8b5c\u3002\u63d0\u51fa\u7684 Sp-Aux-Deformer \u6a21\u578b\u5206\u5225\u5728\u96e2\u958b\u4e00\u500b\u53d7\u8a66\u8005\u548c\u96e2\u958b\u4e00\u500b\u8a66\u9a57\u7684\u5834\u666f\u4e2d\u9054\u5230\u986f\u8457\u7684 15 \u985e\u89e3\u78bc\u6e96\u78ba\u5ea6 57.48% \u548c 61.83%\u3002", "author": "Yuanming Zhang et.al.", "authors": "Yuanming Zhang, Jing Lu, Zhibin Lin, Fei Chen, Haoliang Du, Xia Gao", "id": "2411.06928v1", "paper_url": "http://arxiv.org/abs/2411.06928v1", "repo": "null"}}