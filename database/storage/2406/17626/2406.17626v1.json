{"2406.17626": {"publish_time": "2024-06-25", "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference", "paper_summary": "As large language models (LLMs) constantly evolve, ensuring their safety\nremains a critical research problem. Previous red-teaming approaches for LLM\nsafety have primarily focused on single prompt attacks or goal hijacking. To\nthe best of our knowledge, we are the first to study LLM safety in multi-turn\ndialogue coreference. We created a dataset of 1,400 questions across 14\ncategories, each featuring multi-turn coreference safety attacks. We then\nconducted detailed evaluations on five widely used open-source LLMs. The\nresults indicated that under multi-turn coreference safety attacks, the highest\nattack success rate was 56% with the LLaMA2-Chat-7b model, while the lowest was\n13.9% with the Mistral-7B-Instruct model. These findings highlight the safety\nvulnerabilities in LLMs during dialogue coreference interactions.", "paper_summary_zh": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e0d\u65ad\u53d1\u5c55\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u7684\u7814\u7a76\u95ee\u9898\u3002\u4ee5\u524d\u9488\u5bf9 LLM \u5b89\u5168\u6027\u7684\u7ea2\u961f\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e00\u63d0\u793a\u653b\u51fb\u6216\u76ee\u6807\u52ab\u6301\u4e0a\u3002\u636e\u6211\u4eec\u6240\u77e5\uff0c\u6211\u4eec\u662f\u7b2c\u4e00\u4e2a\u5728\u591a\u8f6e\u5bf9\u8bdd\u5171\u6307\u4e2d\u7814\u7a76 LLM \u5b89\u5168\u6027\u7684\u4eba\u3002\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b 14 \u4e2a\u7c7b\u522b\u7684 1,400 \u4e2a\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u95ee\u9898\u90fd\u5305\u542b\u591a\u8f6e\u5171\u6307\u5b89\u5168\u653b\u51fb\u3002\u7136\u540e\uff0c\u6211\u4eec\u5bf9\u4e94\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90 LLM \u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u8f6e\u5171\u6307\u5b89\u5168\u653b\u51fb\u4e0b\uff0c\u653b\u51fb\u6210\u529f\u7387\u6700\u9ad8\u7684\u662f LLaMA2-Chat-7b \u6a21\u578b\uff0c\u4e3a 56%\uff0c\u800c\u6700\u4f4e\u7684\u662f Mistral-7B-Instruct \u6a21\u578b\uff0c\u4e3a 13.9%\u3002\u8fd9\u4e9b\u53d1\u73b0\u7a81\u51fa\u4e86 LLM \u5728\u5bf9\u8bdd\u5171\u6307\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "author": "Erxin Yu et.al.", "authors": "Erxin Yu, Jing Li, Ming Liao, Siqi Wang, Zuchen Gao, Fei Mi, Lanqing Hong", "id": "2406.17626v1", "paper_url": "http://arxiv.org/abs/2406.17626v1", "repo": "null"}}