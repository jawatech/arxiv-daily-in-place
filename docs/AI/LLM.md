
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-05**|**LaRa: Efficient Large-Baseline Radiance Fields**|Anpei Chen et.al.|[2407.04699v1](http://arxiv.org/abs/2407.04699v1)|null|
|**2024-07-05**|**Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs**|Rudolf Laine et.al.|[2407.04694v1](http://arxiv.org/abs/2407.04694v1)|null|
|**2024-07-05**|**ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models**|Yuzhe Gu et.al.|[2407.04693v1](http://arxiv.org/abs/2407.04693v1)|null|
|**2024-07-05**|**Missed Causes and Ambiguous Effects: Counterfactuals Pose Challenges for Interpreting Neural Networks**|Aaron Mueller et.al.|[2407.04690v1](http://arxiv.org/abs/2407.04690v1)|null|
|**2024-07-05**|**Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge**|Yuanze Lin et.al.|[2407.04681v1](http://arxiv.org/abs/2407.04681v1)|null|
|**2024-07-05**|**Lost in Translation: The Algorithmic Gap Between LMs and the Brain**|Tommaso Tosato et.al.|[2407.04680v1](http://arxiv.org/abs/2407.04680v1)|null|
|**2024-07-05**|**XQSV: A Structurally Variable Network to Imitate Human Play in Xiangqi**|Chenliang Zhou et.al.|[2407.04678v1](http://arxiv.org/abs/2407.04678v1)|null|
|**2024-07-05**|**Is plantar thermography a valid digital biomarker for characterising diabetic foot ulceration risk?**|Akshay Jagadeesh et.al.|[2407.04676v1](http://arxiv.org/abs/2407.04676v1)|null|
|**2024-07-05**|**Pretraining End-to-End Keyword Search with Automatically Discovered Acoustic Units**|Bolaji Yusuf et.al.|[2407.04652v1](http://arxiv.org/abs/2407.04652v1)|[link](https://github.com/beer-asr/beer)|
|**2024-07-05**|**Efficient Materials Informatics between Rockets and Electrons**|Adam M. Krajewski et.al.|[2407.04648v1](http://arxiv.org/abs/2407.04648v1)|null|
|**2024-07-05**|**Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models**|Bolaji Yusuf et.al.|[2407.04641v1](http://arxiv.org/abs/2407.04641v1)|null|
|**2024-07-05**|**Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**|Reza Averly et.al.|[2407.04629v1](http://arxiv.org/abs/2407.04629v1)|null|
|**2024-07-05**|**Learning to (Learn at Test Time): RNNs with Expressive Hidden States**|Yu Sun et.al.|[2407.04620v1](http://arxiv.org/abs/2407.04620v1)|[link](https://github.com/test-time-training/ttt-lm-jax)|
|**2024-07-05**|**Isomorphic Pruning for Vision Models**|Gongfan Fang et.al.|[2407.04616v1](http://arxiv.org/abs/2407.04616v1)|[link](https://github.com/vainf/isomorphic-pruning)|
|**2024-07-05**|**ARM: Efficient Guided Decoding with Autoregressive Reward Models**|Sergey Troshin et.al.|[2407.04615v1](http://arxiv.org/abs/2407.04615v1)|null|
|**2024-07-05**|**Written Term Detection Improves Spoken Term Detection**|Bolaji Yusuf et.al.|[2407.04601v1](http://arxiv.org/abs/2407.04601v1)|[link](https://github.com/bolajiy/golden-retriever)|
|**2024-07-05**|**Feature Attenuation of Defective Representation Can Resolve Incomplete Masking on Anomaly Detection**|YeongHyeon Park et.al.|[2407.04597v1](http://arxiv.org/abs/2407.04597v1)|null|
|**2024-07-05**|**Testing learning hypotheses using neural networks by manipulating learning data**|Cara Su-Yi Leong et.al.|[2407.04593v1](http://arxiv.org/abs/2407.04593v1)|null|
|**2024-07-05**|**VRSD: Rethinking Similarity and Diversity for Retrieval in Large Language Models**|Hang Gao et.al.|[2407.04573v1](http://arxiv.org/abs/2407.04573v1)|null|
|**2024-07-05**|**Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition**|Aditya K Surikuchi et.al.|[2407.04559v1](http://arxiv.org/abs/2407.04559v1)|null|
|**2024-07-05**|**Spontaneous Reward Hacking in Iterative Self-Refinement**|Jane Pan et.al.|[2407.04549v1](http://arxiv.org/abs/2407.04549v1)|null|
|**2024-07-05**|**Real-time Timbre Remapping with Differentiable DSP**|Jordie Shier et.al.|[2407.04547v1](http://arxiv.org/abs/2407.04547v1)|null|
|**2024-07-05**|**Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations**|Matthias Lindemann et.al.|[2407.04543v1](http://arxiv.org/abs/2407.04543v1)|null|
|**2024-07-05**|**PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts**|Ana-Cristina Rogoz et.al.|[2407.04541v1](http://arxiv.org/abs/2407.04541v1)|[link](https://github.com/ana-rogoz/poprero)|
|**2024-07-05**|**PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers**|Ananthu Aniraj et.al.|[2407.04538v1](http://arxiv.org/abs/2407.04538v1)|[link](https://github.com/ananthu-aniraj/pdiscoformer)|
|**2024-07-05**|**Performance Analysis of Speech Encoders for Low-Resource SLU and ASR in Tunisian Dialect**|Salima Mdhaffar et.al.|[2407.04533v1](http://arxiv.org/abs/2407.04533v1)|null|
|**2024-07-05**|**GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning**|Aleksander Ficek et.al.|[2407.04528v1](http://arxiv.org/abs/2407.04528v1)|null|
|**2024-07-05**|**Enhancing learning in artificial neural networks through cellular heterogeneity and neuromodulatory signaling**|Alejandro Rodriguez-Garcia et.al.|[2407.04525v1](http://arxiv.org/abs/2407.04525v1)|null|
|**2024-07-05**|**LayerShuffle: Enhancing Robustness in Vision Transformers by Randomizing Layer Execution Order**|Matthias Freiberger et.al.|[2407.04513v1](http://arxiv.org/abs/2407.04513v1)|null|
|**2024-07-05**|**When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions**|Jérémy Perez et.al.|[2407.04503v1](http://arxiv.org/abs/2407.04503v1)|null|
|**2024-07-05**|**Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**|Tianshu Feng et.al.|[2407.04486v1](http://arxiv.org/abs/2407.04486v1)|null|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|null|
|**2024-07-05**|**Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models**|Vyas Raina et.al.|[2407.04482v1](http://arxiv.org/abs/2407.04482v1)|null|
|**2024-07-05**|**EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context**|Hannes Kunstmann et.al.|[2407.04472v1](http://arxiv.org/abs/2407.04472v1)|null|
|**2024-07-05**|**Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games**|Nathan Herr et.al.|[2407.04467v1](http://arxiv.org/abs/2407.04467v1)|null|
|**2024-07-05**|**Using LLMs to label medical papers according to the CIViC evidence model**|Markus Hisch et.al.|[2407.04466v1](http://arxiv.org/abs/2407.04466v1)|null|
|**2024-07-05**|**Generalists vs. Specialists: Evaluating Large Language Models for Urdu**|Samee Arif et.al.|[2407.04459v1](http://arxiv.org/abs/2407.04459v1)|null|
|**2024-07-05**|**Robust Multimodal Learning via Representation Decoupling**|Shicai Wei et.al.|[2407.04458v1](http://arxiv.org/abs/2407.04458v1)|null|
|**2024-07-05**|**Hindsight Preference Learning for Offline Preference-based Reinforcement Learning**|Chen-Xiao Gao et.al.|[2407.04451v1](http://arxiv.org/abs/2407.04451v1)|[link](https://github.com/typoverflow/wiserl)|
|**2024-07-05**|**TokenVerse: Unifying Speech and NLP Tasks via Transducer-based ASR**|Shashi Kumar et.al.|[2407.04444v1](http://arxiv.org/abs/2407.04444v1)|null|
|**2024-07-05**|**From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs**|Marion Bartl et.al.|[2407.04434v1](http://arxiv.org/abs/2407.04434v1)|null|
|**2024-07-05**|**The Complexity of Symmetry Breaking Beyond Lex-Leader**|Markus Anders et.al.|[2407.04419v1](http://arxiv.org/abs/2407.04419v1)|null|
|**2024-07-05**|**Enabling On-Device LLMs Personalization with Smartphone Sensing**|Shiquan Zhang et.al.|[2407.04418v1](http://arxiv.org/abs/2407.04418v1)|null|
|**2024-07-05**|**Waterfall: Framework for Robust and Scalable Text Watermarking**|Gregory Kang Ruey Lau et.al.|[2407.04411v1](http://arxiv.org/abs/2407.04411v1)|null|
|**2024-07-05**|**Discovering symbolic expressions with parallelized tree search**|Kai Ruan et.al.|[2407.04405v1](http://arxiv.org/abs/2407.04405v1)|[link](https://github.com/intell-sci-comput/pts)|
|**2024-07-05**|**Graph-Guided Test-Time Adaptation for Glaucoma Diagnosis using Fundus Photography**|Qian Zeng et.al.|[2407.04396v1](http://arxiv.org/abs/2407.04396v1)|null|
|**2024-07-05**|**Multi-Branch Auxiliary Fusion YOLO with Re-parameterization Heterogeneous Convolutional for accurate object detection**|Zhiqiang Yang et.al.|[2407.04381v1](http://arxiv.org/abs/2407.04381v1)|[link](https://github.com/yang-0201/MAF-YOLO)|
|**2024-07-05**|**Exploiting the equivalence between quantum neural networks and perceptrons**|Chris Mingard et.al.|[2407.04371v1](http://arxiv.org/abs/2407.04371v1)|null|
|**2024-07-05**|**Regulating Model Reliance on Non-Robust Features by Smoothing Input Marginal Density**|Peiyu Yang et.al.|[2407.04370v1](http://arxiv.org/abs/2407.04370v1)|null|
|**2024-07-05**|**Romanization Encoding For Multilingual ASR**|Wen Ding et.al.|[2407.04368v1](http://arxiv.org/abs/2407.04368v1)|null|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-05**|**Dance of the ADS: Orchestrating Failures through Historically-Informed Scenario Fuzzing**|Tong Wang et.al.|[2407.04359v1](http://arxiv.org/abs/2407.04359v1)|null|
|**2024-07-05**|**AI-Based Beam-Level and Cell-Level Mobility Management for High Speed Railway Communications**|Wen Li et.al.|[2407.04336v1](http://arxiv.org/abs/2407.04336v1)|null|
|**2024-07-05**|**Geometrically Inspired Kernel Machines for Collaborative Learning Beyond Gradient Descent**|Mohit Kumar et.al.|[2407.04335v1](http://arxiv.org/abs/2407.04335v1)|null|
|**2024-07-05**|**MuseBarControl: Enhancing Fine-Grained Control in Symbolic Music Generation through Pre-Training and Counterfactual Loss**|Yangyang Shu et.al.|[2407.04331v1](http://arxiv.org/abs/2407.04331v1)|null|
|**2024-07-05**|**Knowledge-based Drug Samples' Comparison**|Sébastien Guillemin et.al.|[2407.04317v1](http://arxiv.org/abs/2407.04317v1)|null|
|**2024-07-05**|**Crafting Large Language Models for Enhanced Interpretability**|Chung-En Sun et.al.|[2407.04307v1](http://arxiv.org/abs/2407.04307v1)|null|
|**2024-07-05**|**Jailbreak Attacks and Defenses Against Large Language Models: A Survey**|Sibo Yi et.al.|[2407.04295v1](http://arxiv.org/abs/2407.04295v1)|null|
|**2024-07-05**|**Systematic Evaluation of Online Speaker Diarization Systems Regarding their Latency**|Roman Aperdannier et.al.|[2407.04293v1](http://arxiv.org/abs/2407.04293v1)|null|
|**2024-07-05**|**MARS: Paying more attention to visual attributes for text-based person search**|Alex Ergasti et.al.|[2407.04287v1](http://arxiv.org/abs/2407.04287v1)|[link](https://github.com/ergastialex/mars)|
|**2024-07-05**|**Robust Decision Transformer: Tackling Data Corruption in Offline RL via Sequence Modeling**|Jiawei Xu et.al.|[2407.04285v1](http://arxiv.org/abs/2407.04285v1)|null|
|**2024-07-05**|**LearnerVoice: A Dataset of Non-Native English Learners' Spontaneous Speech**|Haechan Kim et.al.|[2407.04280v1](http://arxiv.org/abs/2407.04280v1)|null|
|**2024-07-05**|**BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks**|Jieying Xue et.al.|[2407.04279v1](http://arxiv.org/abs/2407.04279v1)|[link](https://github.com/yingjie7/BiosERC)|
|**2024-07-05**|**Variational Partial Group Convolutions for Input-Aware Partial Equivariance of Rotations and Color-Shifts**|Hyunsu Kim et.al.|[2407.04271v1](http://arxiv.org/abs/2407.04271v1)|null|
|**2024-07-05**|**NeuFair: Neural Network Fairness Repair with Dropout**|Vishnu Asutosh Dasu et.al.|[2407.04268v1](http://arxiv.org/abs/2407.04268v1)|null|
|**2024-07-05**|**Unsupervised Video Summarization via Reinforcement Learning and a Trained Evaluator**|Mehryar Abbasi et.al.|[2407.04258v1](http://arxiv.org/abs/2407.04258v1)|null|
|**2024-07-05**|**ArAIEval Shared Task: Propagandistic Techniques Detection in Unimodal and Multimodal Arabic Content**|Maram Hasanain et.al.|[2407.04247v1](http://arxiv.org/abs/2407.04247v1)|null|
|**2024-07-05**|**Autoverse: An Evolvable Game Langugage for Learning Robust Embodied Agents**|Sam Earle et.al.|[2407.04221v1](http://arxiv.org/abs/2407.04221v1)|null|
|**2024-07-05**|**Smart Vision-Language Reasoners**|Denisa Roberts et.al.|[2407.04212v1](http://arxiv.org/abs/2407.04212v1)|[link](https://github.com/smarter-vlm/smarter)|
|**2024-07-04**|**HAF-RM: A Hybrid Alignment Framework for Reward Model Training**|Shujun Liu et.al.|[2407.04185v1](http://arxiv.org/abs/2407.04185v1)|null|
|**2024-07-04**|**Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms**|Joshua Ashkinaze et.al.|[2407.04183v1](http://arxiv.org/abs/2407.04183v1)|null|
|**2024-07-04**|**Orchestrating LLMs with Different Personalizations**|Jin Peng Zhou et.al.|[2407.04181v1](http://arxiv.org/abs/2407.04181v1)|null|
|**2024-07-04**|**Defense Against Syntactic Textual Backdoor Attacks with Token Substitution**|Xinglin Li et.al.|[2407.04179v1](http://arxiv.org/abs/2407.04179v1)|null|
|**2024-07-04**|**Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs**|Faisal Hamman et.al.|[2407.04173v1](http://arxiv.org/abs/2407.04173v1)|null|
|**2024-07-04**|**ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild**|Ahmed Masry et.al.|[2407.04172v1](http://arxiv.org/abs/2407.04172v1)|[link](https://github.com/vis-nlp/chartgemma)|
|**2024-07-04**|**ELCC: the Emergent Language Corpus Collection**|Brendon Boldt et.al.|[2407.04158v1](http://arxiv.org/abs/2407.04158v1)|null|
|**2024-07-04**|**Mixture of A Million Experts**|Xu Owen He et.al.|[2407.04153v1](http://arxiv.org/abs/2407.04153v1)|null|
|**2024-07-04**|**VoxAct-B: Voxel-Based Acting and Stabilizing Policy for Bimanual Manipulation**|I-Chun Arthur Liu et.al.|[2407.04152v1](http://arxiv.org/abs/2407.04152v1)|null|
|**2024-07-04**|**Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers**|Terry Tong et.al.|[2407.04151v1](http://arxiv.org/abs/2407.04151v1)|null|
|**2024-07-04**|**Towards Automating Text Annotation: A Case Study on Semantic Proximity Annotation using GPT-4**|Sachin Yadav et.al.|[2407.04130v1](http://arxiv.org/abs/2407.04130v1)|null|
|**2024-07-04**|**Biometric Authentication Based on Enhanced Remote Photoplethysmography Signal Morphology**|Zhaodong Sun et.al.|[2407.04127v1](http://arxiv.org/abs/2407.04127v1)|[link](https://github.com/zhaodongsun/rppg_biometrics)|
|**2024-07-04**|**Query-Guided Self-Supervised Summarization of Nursing Notes**|Ya Gao et.al.|[2407.04125v1](http://arxiv.org/abs/2407.04125v1)|null|
|**2024-07-04**|**Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models**|Yuyan Chen et.al.|[2407.04121v1](http://arxiv.org/abs/2407.04121v1)|null|
|**2024-07-04**|**MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization**|Yuyan Chen et.al.|[2407.04118v1](http://arxiv.org/abs/2407.04118v1)|null|
|**2024-07-04**|**Predictive Coding Networks and Inference Learning: Tutorial and Survey**|Björn van Zwol et.al.|[2407.04117v1](http://arxiv.org/abs/2407.04117v1)|null|
|**2024-07-04**|**MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**|Asma Alkhaldi et.al.|[2407.04106v1](http://arxiv.org/abs/2407.04106v1)|null|
|**2024-07-04**|**Can Pre-trained Language Models Understand Chinese Humor?**|Yuyan Chen et.al.|[2407.04105v1](http://arxiv.org/abs/2407.04105v1)|null|
|**2024-07-04**|**Advances in Diffusion Models for Image Data Augmentation: A Review of Methods, Models, Evaluation Metrics and Future Research Directions**|Panagiotis Alimisis et.al.|[2407.04103v1](http://arxiv.org/abs/2407.04103v1)|null|
|**2024-07-04**|**Stephanie: Step-by-Step Dialogues for Mimicking Human Interactions in Social Conversations**|Hao Yang et.al.|[2407.04093v1](http://arxiv.org/abs/2407.04093v1)|null|
|**2024-07-04**|**Advanced Artificial Intelligence Strategy for Optimizing Urban Rail Network Design using Nature-Inspired Algorithms**|Hariram Sampath Kumar et.al.|[2407.04087v1](http://arxiv.org/abs/2407.04087v1)|null|
|**2024-07-04**|**AXOLOTL'24 Shared Task on Multilingual Explainable Semantic Change Modeling**|Mariia Fedorova et.al.|[2407.04079v1](http://arxiv.org/abs/2407.04079v1)|null|
|**2024-07-04**|**DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning**|Chengpeng Li et.al.|[2407.04078v1](http://arxiv.org/abs/2407.04078v1)|[link](https://github.com/chengpengli1003/dotamath)|
|**2024-07-04**|**Sparsest Models Elude Pruning: An Exposé of Pruning's Current Capabilities**|Stephen Zhang et.al.|[2407.04075v1](http://arxiv.org/abs/2407.04075v1)|null|
|**2024-07-04**|**A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations**|Md Tahmid Rahman Laskar et.al.|[2407.04069v1](http://arxiv.org/abs/2407.04069v1)|null|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|null|
|**2024-07-04**|**Benchmark on Drug Target Interaction Modeling from a Structure Perspective**|Xinnan Zhang et.al.|[2407.04055v1](http://arxiv.org/abs/2407.04055v1)|[link](https://github.com/justinwjl/gtb-dti)|
|**2024-07-04**|**FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs**|Tongyi SpeechTeam et.al.|[2407.04051v1](http://arxiv.org/abs/2407.04051v1)|null|
|**2024-07-04**|**Deep Content Understanding Toward Entity and Aspect Target Sentiment Analysis on Foundation Models**|Vorakit Vorakitphan et.al.|[2407.04050v1](http://arxiv.org/abs/2407.04050v1)|null|
|**2024-07-04**|**Improving Accented Speech Recognition using Data Augmentation based on Unsupervised Text-to-Speech Synthesis**|Cong-Thanh Do et.al.|[2407.04047v1](http://arxiv.org/abs/2407.04047v1)|null|
|**2024-07-04**|**Systematic Task Exploration with LLMs: A Study in Citation Text Generation**|Furkan Şahinuç et.al.|[2407.04046v1](http://arxiv.org/abs/2407.04046v1)|null|

#### Abstracts
##### **LaRa: Efficient Large-Baseline Radiance Fields**
2407.04699v1 by Anpei Chen, Haofei Xu, Stefano Esposito, Siyu Tang, Andreas Geiger

Radiance field methods have achieved photorealistic novel view synthesis and
geometry reconstruction. But they are mostly applied in per-scene optimization
or small-baseline settings. While several recent works investigate feed-forward
reconstruction with large baselines by utilizing transformers, they all operate
with a standard global attention mechanism and hence ignore the local nature of
3D reconstruction. We propose a method that unifies local and global reasoning
in transformer layers, resulting in improved quality and faster convergence.
Our model represents scenes as Gaussian Volumes and combines this with an image
encoder and Group Attention Layers for efficient feed-forward reconstruction.
Experimental results demonstrate that our model, trained for two days on four
GPUs, demonstrates high fidelity in reconstructing 360&deg radiance fields, and
robustness to zero-shot and out-of-domain testing.

摘要：輻射場方法已實現逼真的新視圖合成和幾何重建。但它們大多用於場景優化或小基線設置。儘管最近有幾項工作利用Transformer研究大基線的饋送前向重建，但它們都使用標準的全局注意力機制，因此忽略了 3D 重建的局部性質。我們提出了一種在Transformer層中統一局部和全局推理的方法，從而提高了品質並加快了收斂速度。我們的模型將場景表示為高斯體積，並將其與圖像編碼器和群組注意力層結合，以進行高效的饋送前向重建。實驗結果表明，我們的模型在四個 GPU 上訓練兩天，在重建 360 度輻射場方面表現出高保真度，並且對零次學習和域外測試具有魯棒性。

##### **Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs**
2407.04694v1 by Rudolf Laine, Bilal Chughtai, Jan Betley, Kaivalya Hariharan, Jeremy Scheurer, Mikita Balesni, Marius Hobbhahn, Alexander Meinke, Owain Evans

AI assistants such as ChatGPT are trained to respond to users by saying, "I
am a large language model". This raises questions. Do such models know that
they are LLMs and reliably act on this knowledge? Are they aware of their
current circumstances, such as being deployed to the public? We refer to a
model's knowledge of itself and its circumstances as situational awareness. To
quantify situational awareness in LLMs, we introduce a range of behavioral
tests, based on question answering and instruction following. These tests form
the $\textbf{Situational Awareness Dataset (SAD)}$, a benchmark comprising 7
task categories and over 13,000 questions. The benchmark tests numerous
abilities, including the capacity of LLMs to (i) recognize their own generated
text, (ii) predict their own behavior, (iii) determine whether a prompt is from
internal evaluation or real-world deployment, and (iv) follow instructions that
depend on self-knowledge.
  We evaluate 16 LLMs on SAD, including both base (pretrained) and chat models.
While all models perform better than chance, even the highest-scoring model
(Claude 3 Opus) is far from a human baseline on certain tasks. We also observe
that performance on SAD is only partially predicted by metrics of general
knowledge (e.g. MMLU). Chat models, which are finetuned to serve as AI
assistants, outperform their corresponding base models on SAD but not on
general knowledge tasks. The purpose of SAD is to facilitate scientific
understanding of situational awareness in LLMs by breaking it down into
quantitative abilities. Situational awareness is important because it enhances
a model's capacity for autonomous planning and action. While this has potential
benefits for automation, it also introduces novel risks related to AI safety
and control. Code and latest results available at
https://situational-awareness-dataset.org .

摘要：<paragraph>ChatGPT 等 AI 助理经过训练，会以「我是大型语言模型」来回应使用者。这引发了一些问题。这些模型是否知道自己是大语言模型，并可靠地根据这项知识采取行动？他们是否意识到自己的当前情况，例如被部署到公众面前？我们将模型对自身及其情况的了解称为情境感知。为了量化大语言模型中的情境感知，我们引入了一系列的行为测试，这些测试基于问答和指令遵循。这些测试构成了「情境感知数据集 (SAD)」，这是一个包含 7 个任务类别和超过 13,000 个问题的基准。该基准测试了许多能力，包括大语言模型 (i) 识别自己生成文本的能力、(ii) 预测自己的行为、(iii) 确定提示是来自内部评估还是实际部署，以及 (iv) 遵循依赖于自我知识的指令。
我们对 16 个大语言模型进行了 SAD 评估，包括基础（预训练）模型和聊天模型。虽然所有模型的表现都优于机会，但即使是得分最高（Claude 3 Opus）的模型在某些任务上也远低于人类基准。我们还观察到，SAD 上的性能仅部分由一般知识指标（例如 MMLU）预测。经过微调以充当 AI 助理的聊天模型在 SAD 上的表现优于其对应基础模型，但在一般知识任务上则不然。SAD 的目的是通过将其分解为定量能力，促进对大语言模型中情境感知的科学理解。情境感知很重要，因为它增强了模型自主规划和行动的能力。虽然这可能对自动化有好处，但它也引入了与 AI 安全和控制相关的新风险。代码和最新结果可在 https://situational-awareness-dataset.org 获得。</paragraph>

##### **ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models**
2407.04693v1 by Yuzhe Gu, Ziwei Ji, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen

Large language models (LLMs) exhibit hallucinations in long-form
question-answering tasks across various domains and wide applications. Current
hallucination detection and mitigation datasets are limited in domains and
sizes, which struggle to scale due to prohibitive labor costs and insufficient
reliability of existing hallucination annotators. To facilitate the scalable
oversight of LLM hallucinations, this paper introduces an iterative
self-training framework that simultaneously and progressively scales up the
hallucination annotation dataset and improves the accuracy of the hallucination
annotator. Based on the Expectation Maximization (EM) algorithm, in each
iteration, the framework first applies a hallucination annotation pipeline to
annotate a scaled dataset and then trains a more accurate hallucination
annotator on the dataset. This new hallucination annotator is adopted in the
hallucination annotation pipeline used for the next iteration. Extensive
experimental results demonstrate that the finally obtained hallucination
annotator with only 7B parameters surpasses the performance of GPT-4 and
obtains new state-of-the-art hallucination detection results on HaluEval and
HalluQA by zero-shot inference. Such an annotator can not only evaluate the
hallucination levels of various LLMs on the large-scale dataset but also help
to mitigate the hallucination of LLMs generations, with the Natural Language
Inference (NLI) metric increasing from 25% to 37% on HaluEval.

摘要：大型語言模型 (LLM) 在各種領域和廣泛應用中表現出長篇問答任務中的幻覺。當前的幻覺檢測和緩解數據集在領域和規模上受到限制，由於高昂的人工成本和現有幻覺註解器的可靠性不足，因此難以擴展。為了促進 LLM 幻覺的可擴展監督，本文介紹了一個迭代自訓練框架，該框架同時且逐步擴展幻覺註解數據集並提高幻覺註解器的準確性。基於期望最大化 (EM) 演算法，在每次迭代中，該框架首先應用幻覺註解管道來註解一個縮放的數據集，然後在數據集上訓練一個更準確的幻覺註解器。這個新的幻覺註解器被採用在用於下一次迭代的幻覺註解管道中。大量的實驗結果表明，最終獲得的幻覺註解器只有 7B 參數，就超過了 GPT-4 的性能，並通過零次學習推理在 HaluEval 和 HalluQA 上獲得了新的最先進的幻覺檢測結果。這樣的註解器不僅可以評估各種 LLM 在大型數據集上的幻覺等級，還可以幫助減輕 LLM 生成的幻覺，自然語言推理 (NLI) 指標從 HaluEval 上的 25% 增加到 37%。

##### **Missed Causes and Ambiguous Effects: Counterfactuals Pose Challenges for Interpreting Neural Networks**
2407.04690v1 by Aaron Mueller

Interpretability research takes counterfactual theories of causality for
granted. Most causal methods rely on counterfactual interventions to inputs or
the activations of particular model components, followed by observations of the
change in models' output logits or behaviors. While this yields more faithful
evidence than correlational methods, counterfactuals nonetheless have key
problems that bias our findings in specific and predictable ways. Specifically,
(i) counterfactual theories do not effectively capture multiple independently
sufficient causes of the same effect, which leads us to miss certain causes
entirely; and (ii) counterfactual dependencies in neural networks are generally
not transitive, which complicates methods for extracting and interpreting
causal graphs from neural networks. We discuss the implications of these
challenges for interpretability researchers and propose concrete suggestions
for future work.

摘要：可解釋性研究將因果關係的反事實理論視為理所當然。大多數因果方法依賴於對輸入或特定模型組件的激活進行反事實干預，然後觀察模型輸出邏輯或行為的變化。雖然這比相關方法產生更可靠的證據，但反事實仍然存在關鍵問題，這些問題會以特定且可預測的方式影響我們的發現。具體來說，(i) 反事實理論無法有效捕捉同一個效果的許多獨立充分原因，這導致我們完全錯過某些原因；(ii) 神經網路中的反事實依賴性通常不是遞移的，這使得從神經網路中提取和解釋因果圖的方法變得複雜。我們討論了這些挑戰對可解釋性研究人員的影響，並提出具體建議以供未來的工作。

##### **Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge**
2407.04681v1 by Yuanze Lin, Yunsheng Li, Dongdong Chen, Weijian Xu, Ronald Clark, Philip Torr, Lu Yuan

In recent years, multimodal large language models (MLLMs) have made
significant strides by training on vast high-quality image-text datasets,
enabling them to generally understand images well. However, the inherent
difficulty in explicitly conveying fine-grained or spatially dense information
in text, such as masks, poses a challenge for MLLMs, limiting their ability to
answer questions requiring an understanding of detailed or localized visual
elements. Drawing inspiration from the Retrieval-Augmented Generation (RAG)
concept, this paper proposes a new visual prompt approach to integrate
fine-grained external knowledge, gleaned from specialized vision models (e.g.,
instance segmentation/OCR models), into MLLMs. This is a promising yet
underexplored direction for enhancing MLLMs' performance. Our approach diverges
from concurrent works, which transform external knowledge into additional text
prompts, necessitating the model to indirectly learn the correspondence between
visual content and text coordinates. Instead, we propose embedding fine-grained
knowledge information directly into a spatial embedding map as a visual prompt.
This design can be effortlessly incorporated into various MLLMs, such as LLaVA
and Mipha, considerably improving their visual understanding performance.
Through rigorous experiments, we demonstrate that our method can enhance MLLM
performance across nine benchmarks, amplifying their fine-grained context-aware
capabilities.

摘要：近年來，多模態大型語言模型 (MLLM) 在大量高品質影像文字資料集上訓練後，已取得顯著進展，讓它們能普遍理解影像。然而，在文字中明確傳達精細或空間密集的資訊（例如遮罩）的固有困難，對 MLLM 構成挑戰，限制了它們回答需要了解詳細或局部視覺元素的問題的能力。本文從檢索增強生成 (RAG) 概念中汲取靈感，提出了一種新的視覺提示方法，以整合從專業視覺模型（例如實例分割/OCR 模型）收集到的精細外部知識，融入 MLLM 中。這是增強 MLLM 效能的一個有前景但尚未充分探索的方向。我們的做法與同時進行的工作不同，這些工作將外部知識轉換為額外的文字提示，需要模型間接學習視覺內容和文字座標之間的對應關係。相反地，我們建議將精細的知識資訊直接嵌入空間嵌入映射中，作為視覺提示。此設計可以毫不費力地整合到各種 MLLM 中，例如 LLaVA 和 Mipha，大幅提升它們的視覺理解效能。透過嚴謹的實驗，我們證明了我們的方法可以增強 MLLM 在九個基準測試中的效能，擴大它們的精細脈絡感知能力。

##### **Lost in Translation: The Algorithmic Gap Between LMs and the Brain**
2407.04680v1 by Tommaso Tosato, Pascal Jr Tikeng Notsawo, Saskia Helbling, Irina Rish, Guillaume Dumas

Language Models (LMs) have achieved impressive performance on various
linguistic tasks, but their relationship to human language processing in the
brain remains unclear. This paper examines the gaps and overlaps between LMs
and the brain at different levels of analysis, emphasizing the importance of
looking beyond input-output behavior to examine and compare the internal
processes of these systems. We discuss how insights from neuroscience, such as
sparsity, modularity, internal states, and interactive learning, can inform the
development of more biologically plausible language models. Furthermore, we
explore the role of scaling laws in bridging the gap between LMs and human
cognition, highlighting the need for efficiency constraints analogous to those
in biological systems. By developing LMs that more closely mimic brain
function, we aim to advance both artificial intelligence and our understanding
of human cognition.

摘要：語言模型 (LM) 在各種語言任務中已取得令人印象深刻的表現，但它們與大腦中人類語言處理的關係仍不明朗。本文探討了 LM 與大腦在不同分析層級之間的差距和重疊，強調了除了輸入輸出行為之外，檢視和比較這些系統的內部處理過程的重要性。我們討論了神經科學的見解，例如稀疏性、模組化、內部狀態和互動式學習，如何能為更具生物學合理性的語言模型的發展提供資訊。此外，我們探討了規模定律在縮小 LM 與人類認知之間差距中的作用，強調了類似於生物系統中效率限制的需求。透過開發更接近大腦功能的 LM，我們旨在推進人工智慧和我們對人類認知的理解。

##### **XQSV: A Structurally Variable Network to Imitate Human Play in Xiangqi**
2407.04678v1 by Chenliang Zhou

In this paper, we introduce an innovative deep learning architecture, termed
Xiangqi Structurally Variable (XQSV), designed to emulate the behavioral
patterns of human players in Xiangqi, or Chinese Chess. The unique attribute of
XQSV is its capacity to alter its structural configuration dynamically,
optimizing performance for the task based on the particular subset of data on
which it is trained. We have incorporated several design improvements to
significantly enhance the network's predictive accuracy, including a local
illegal move filter, an Elo range partitioning, a sequential one-dimensional
input, and a simulation of imperfect memory capacity. Empirical evaluations
reveal that XQSV attains a predictive accuracy of approximately 40%, with its
performance peaking within the trained Elo range. This indicates the model's
success in mimicking the play behavior of individuals within that specific
range. A three-terminal Turing Test was employed to demonstrate that the XQSV
model imitates human behavior more accurately than conventional Xiangqi
engines, rendering it indistinguishable from actual human opponents. Given the
inherent nondeterminism in human gameplay, we propose two supplementary relaxed
evaluation metrics. To our knowledge, XQSV represents the first model to mimic
Xiangqi players.

摘要：<paragraph>在本文中，我們介紹了一種創新的深度學習架構，稱為象棋結構變量 (XQSV)，旨在模擬象棋或中國象棋中人類玩家的行為模式。XQSV 的獨特屬性是能夠動態改變其結構配置，根據其接受訓練的特定數據子集，針對任務優化性能。我們已納入多項設計改進，以顯著提高網路的預測準確度，包括局部非法移動過濾器、Elo 範圍分區、序列一維輸入和不完美記憶容量模擬。經驗評估顯示，XQSV 達到了約 40% 的預測準確度，其性能在訓練後的 Elo 範圍內達到峰值。這表明模型在模擬該特定範圍內個體的遊戲行為方面取得了成功。採用三終端圖靈測試來證明 XQSV 模型比傳統象棋引擎更準確地模仿人類行為，使其與實際人類對手無法區分。鑑於人類遊戲中固有的非決定性，我們提出了兩個補充性的放寬評估指標。據我們所知，XQSV 是第一個模擬象棋玩家的模型。</paragraph>

##### **Is plantar thermography a valid digital biomarker for characterising diabetic foot ulceration risk?**
2407.04676v1 by Akshay Jagadeesh, Chanchanok Aramrat, Aqsha Nur, Poppy Mallinson, Sanjay Kinra

Background: In the absence of prospective data on diabetic foot ulcers (DFU),
cross-sectional associations with causal risk factors (peripheral neuropathy,
and peripheral arterial disease (PAD)) could be used to establish the validity
of plantar thermography for DFU risk stratification.
  Methods: First, we investigated the associations between the intrinsic
clusters of plantar thermographic images with several DFU risk factors using an
unsupervised deep-learning framework. We then studied associations between
obtained thermography clusters and DFU risk factors. Second, to identify those
associations with predictive power, we used supervised learning to train
Convolutional Neural Network (CNN) regression/classification models that
predicted the risk factor based on the thermograph (and visual) input.
  Findings: Our dataset comprised 282 thermographs from type 2 diabetes
mellitus patients (aged 56.31 +- 9.18 years, 51.42 % males). On clustering, we
found two overlapping clusters (silhouette score = 0.10, indicating weak
separation). There was strong evidence for associations between assigned
clusters and several factors related to diabetic foot ulceration such as
peripheral neuropathy, PAD, number of diabetes complications, and composite DFU
risk prediction scores such as Martins-Mendes, PODUS-2020, and SIGN. However,
models predicting said risk factors had poor performances.
  Interpretation: The strong associations between intrinsic thermography
clusters and several DFU risk factors support the validity of using
thermography for characterising DFU risk. However, obtained associations did
not prove to be predictive, likely due to, spectrum bias, or because
thermography and classical risk factors characterise incompletely overlapping
portions of the DFU risk construct. Our findings highlight the challenges in
standardising ground truths when defining novel digital biomarkers.

摘要：背景：由於缺乏糖尿病足部潰瘍 (DFU) 的前瞻性數據，
與因果風險因子（周邊神經病變，
和周邊動脈疾病 (PAD)）的橫斷面關聯可用於建立足底熱像檢查的有效性
用於 DFU 風險分層。
方法：首先，我們使用非監督深度學習框架研究了足底熱像圖的內在集群與幾個 DFU 風險因子之間的關聯。然後我們研究了獲得的熱像圖集群與 DFU 風險因子之間的關聯。其次，為了確定具有預測能力的那些關聯，我們使用監督學習來訓練
卷積神經網絡 (CNN) 回歸/分類模型，該模型根據熱像圖（和視覺）輸入預測風險因子。
發現：我們的數據集包含來自 2 型糖尿病的 282 個熱像圖
患者（年齡 56.31 +- 9.18 歲，男性 51.42%）。在聚類時，我們
發現兩個重疊的集群（輪廓得分 = 0.10，表示分離較弱）。有強有力的證據表明分配的
集群和與糖尿病足部潰瘍相關的幾個因素，例如
周圍神經病變、PAD、糖尿病併發症數量和綜合 DFU
風險預測評分，例如 Martins-Mendes、PODUS-2020 和 SIGN。然而，
預測所述風險因子的模型表現不佳。
解釋：內在熱像圖之間的強關聯
集群和幾個 DFU 風險因子支持使用
熱像檢查來表徵 DFU 風險。然而，獲得的關聯並未被證明具有預測性，可能是由於光譜偏差或因為
熱像檢查和經典風險因素表徵不完全重疊
DFU 風險結構的一部分。我們的發現突出了在定義新數字時標準化基本事實的挑戰生物標記。

##### **Pretraining End-to-End Keyword Search with Automatically Discovered Acoustic Units**
2407.04652v1 by Bolaji Yusuf, Jan "Honza" Černocký, Murat Saraçlar

End-to-end (E2E) keyword search (KWS) has emerged as an alternative and
complimentary approach to conventional keyword search which depends on the
output of automatic speech recognition (ASR) systems. While E2E methods greatly
simplify the KWS pipeline, they generally have worse performance than their
ASR-based counterparts, which can benefit from pretraining with untranscribed
data. In this work, we propose a method for pretraining E2E KWS systems with
untranscribed data, which involves using acoustic unit discovery (AUD) to
obtain discrete units for untranscribed data and then learning to locate
sequences of such units in the speech. We conduct experiments across languages
and AUD systems: we show that finetuning such a model significantly outperforms
a model trained from scratch, and the performance improvements are generally
correlated with the quality of the AUD system used for pretraining.

摘要：端對端 (E2E) 關鍵字搜尋 (KWS) 已成為一種替代且互補的方法，用於傳統關鍵字搜尋，後者取決於自動語音辨識 (ASR) 系統的輸出。雖然 E2E 方法極大地簡化了 KWS 管線，但它們通常比其基於 ASR 的對應方法效能較差，而基於 ASR 的對應方法可以受益於未轉錄資料的預訓練。在這項工作中，我們提出了一種使用未轉錄資料預訓練 E2E KWS 系統的方法，其中涉及使用音響單位發現 (AUD) 來取得未轉錄資料的離散單位，然後學習在語音中找到此類單位的序列。我們跨語言和 AUD 系統進行實驗：我們顯示微調此類模型的效能顯著優於從頭開始訓練的模型，而效能改善通常與用於預訓練的 AUD 系統的品質相關。

##### **Efficient Materials Informatics between Rockets and Electrons**
2407.04648v1 by Adam M. Krajewski

The true power of computational research typically can lay in either what it
accomplishes or what it enables others to accomplish. In this work, both
avenues are simultaneously embraced across several distinct efforts existing at
three general scales of abstractions of what a material is - atomistic,
physical, and design. At each, an efficient materials informatics
infrastructure is being built from the ground up based on (1) the fundamental
understanding of the underlying prior knowledge, including the data, (2)
deployment routes that take advantage of it, and (3) pathways to extend it in
an autonomous or semi-autonomous fashion, while heavily relying on artificial
intelligence (AI) to guide well-established DFT-based ab initio and
CALPHAD-based thermodynamic methods.
  The resulting multi-level discovery infrastructure is highly generalizable as
it focuses on encoding problems to solve them easily rather than looking for an
existing solution. To showcase it, this dissertation discusses the design of
multi-alloy functionally graded materials (FGMs) incorporating ultra-high
temperature refractory high entropy alloys (RHEAs) towards gas turbine and jet
engine efficiency increase reducing CO2 emissions, as well as hypersonic
vehicles. It leverages a new graph representation of underlying mathematical
space using a newly developed algorithm based on combinatorics, not subject to
many problems troubling the community. Underneath, property models and phase
relations are learned from optimized samplings of the largest and highest
quality dataset of HEA in the world, called ULTERA. At the atomistic level, a
data ecosystem optimized for machine learning (ML) from over 4.5 million
relaxed structures, called MPDD, is used to inform experimental observations
and improve thermodynamic models by providing stability data enabled by a new
efficient featurization framework.

摘要：計算研究的真正力量通常在於它所完成的事情或它使他人能夠完成的事情。在這項工作中，這兩個途徑同時在三個不同的層面上被同時採用，這些層面存在於材料的抽象的三個一般尺度上——原子、物理和設計。在每個層面上，一個高效的材料信息學基礎設施正在從頭開始建立，基於 (1) 對基礎先驗知識的理解，包括數據，(2) 利用它的部署路線，以及 (3) 以自主或半自主的方式擴展它的途徑，同時依賴人工智能 (AI) 來指導完善的 DFT 為基礎的從頭算起和 CALPHAD 為基礎的熱力學方法。
由此產生的多級發現基礎設施具有高度的概括性，因為它專注於編碼問題以輕鬆地解決它們，而不是尋找現有的解決方案。為了展示它，本文討論了多合金功能梯度材料 (FGM) 的設計，它結合了超高溫耐火高熵合金 (RHEA)，以提高燃氣輪機和噴氣發動機的效率，減少二氧化碳排放，以及高超音速飛行器。它利用了一種新的數學空間圖形表示，使用一種新開發的基於組合學的算法，不受困擾社區的許多問題的影響。在下面，從世界上最大、質量最高的高熵合金數據集 ULTERA 的優化抽樣中學習屬性模型和相關係。在原子層面上，一個針對機器學習 (ML) 優化的數據生態系統，來自 450 萬個以上的放鬆結構，稱為 MPDD，用於通知實驗觀察並通過一個新的高效特徵化框架提供的穩定性數據來改進熱力學模型。

##### **Speculative Speech Recognition by Audio-Prefixed Low-Rank Adaptation of Language Models**
2407.04641v1 by Bolaji Yusuf, Murali Karthick Baskar, Andrew Rosenberg, Bhuvana Ramabhadran

This paper explores speculative speech recognition (SSR), where we empower
conventional automatic speech recognition (ASR) with speculation capabilities,
allowing the recognizer to run ahead of audio. We introduce a metric for
measuring SSR performance and we propose a model which does SSR by combining a
RNN-Transducer-based ASR system with an audio-prefixed language model (LM). The
ASR system transcribes ongoing audio and feeds the resulting transcripts, along
with an audio-dependent prefix, to the LM, which speculates likely completions
for the transcriptions. We experiment with a variety of ASR datasets on which
show the efficacy our method and the feasibility of SSR as a method of reducing
ASR latency.

摘要：本文探討推測性語音辨識 (SSR)，我們賦予傳統自動語音辨識 (ASR) 推測能力，讓辨識器能超前音訊執行。我們引入一個用於衡量 SSR 效能的指標，並提出一個模型，透過結合基於 RNN-Transducer 的 ASR 系統與音訊前置語言模型 (LM) 來執行 SSR。ASR 系統轉錄正在進行的音訊，並將轉錄結果與音訊相關的前置詞一起提供給 LM，由 LM 推測轉錄的可能完成內容。我們使用各種 ASR 資料集進行實驗，結果顯示我們的方法有效，且 SSR 可行作為一種降低 ASR 延遲的方法。

##### **Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**
2407.04629v1 by Reza Averly, Xia Ning

Clinical named entity recognition (NER) aims to retrieve important entities
within clinical narratives. Recent works have demonstrated that large language
models (LLMs) can achieve strong performance in this task. While previous works
focus on proprietary LLMs, we investigate how open NER LLMs, trained
specifically for entity recognition, perform in clinical NER. In this paper, we
aim to improve them through a novel framework, entity decomposition with
filtering, or EDF. Our key idea is to decompose the entity recognition task
into several retrievals of sub-entity types. We also introduce a filtering
mechanism to remove incorrect entities. Our experimental results demonstrate
the efficacy of our framework across all metrics, models, datasets, and entity
types. Our analysis reveals that entity decomposition can recognize previously
missed entities with substantial improvement. We further provide a
comprehensive evaluation of our framework and an in-depth error analysis to
pave future works.

摘要：臨床命名實體識別 (NER) 旨在擷取臨床敘述中的重要實體。最近的研究表明，大型語言模型 (LLM) 可以在此任務中實現強大的效能。雖然先前的研究專注於專有的 LLM，但我們探討了專門針對實體識別訓練的開放式 NER LLM 在臨床 NER 中的表現。在本文中，我們旨在透過一個新穎的架構來改善它們，即帶有過濾的實體分解，或 EDF。我們的關鍵想法是將實體識別任務分解為多個子實體類型的擷取。我們還引入了一個過濾機制來移除不正確的實體。我們的實驗結果證明了我們架構在所有指標、模型、資料集和實體類型中的效能。我們的分析顯示，實體分解可以識別先前遺漏的實體，並有顯著的改善。我們進一步提供了我們架構的全面評估和深入的錯誤分析，為未來的研究鋪路。

##### **Learning to (Learn at Test Time): RNNs with Expressive Hidden States**
2407.04620v1 by Yu Sun, Xinhao Li, Karan Dalal, Jiarui Xu, Arjun Vikram, Genghan Zhang, Yann Dubois, Xinlei Chen, Xiaolong Wang, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin

Self-attention performs well in long context but has quadratic complexity.
Existing RNN layers have linear complexity, but their performance in long
context is limited by the expressive power of their hidden state. We propose a
new class of sequence modeling layers with linear complexity and an expressive
hidden state. The key idea is to make the hidden state a machine learning model
itself, and the update rule a step of self-supervised learning. Since the
hidden state is updated by training even on test sequences, our layers are
called Test-Time Training (TTT) layers. We consider two instantiations:
TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer
MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B
parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both
TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer,
they can keep reducing perplexity by conditioning on more tokens, while Mamba
cannot after 16k context. With preliminary systems optimization, TTT-Linear is
already faster than Transformer at 8k context and matches Mamba in wall-clock
time. TTT-MLP still faces challenges in memory I/O, but shows larger potential
in long context, pointing to a promising direction for future research.

摘要：自注意力在長語境中表現良好，但具有二次複雜度。
現有的 RNN 層具有線性複雜度，但它們在長語境中的表現受到其隱藏狀態表達能力的限制。我們提出了一類具有線性複雜度和表達性隱藏狀態的新型序列建模層。關鍵思想是將隱藏狀態本身作為一個機器學習模型，並將更新規則作為自監督學習的一個步驟。由於隱藏狀態通過訓練即使在測試序列上也會更新，因此我們的層被稱為測試時訓練 (TTT) 層。我們考慮了兩個實例：TTT-Linear 和 TTT-MLP，它們的隱藏狀態分別是一個線性模型和一個兩層 MLP。我們在 125M 到 1.3B 參數的規模上評估我們的實例，並與一個強大的 Transformer 和一個現代 RNN Mamba 進行比較。TTT-Linear 和 TTT-MLP 都匹配或超過了基準。與 Transformer 類似，它們可以通過對更多令牌進行條件化來持續降低困惑度，而 Mamba 在 16k 語境後則不能。通過初步的系統優化，TTT-Linear 在 8k 語境下已經比 Transformer 更快，並且在時鐘時間上與 Mamba 匹配。TTT-MLP 仍然面臨內存 I/O 的挑戰，但在長語境中顯示出更大的潛力，這為未來的研究指明了一個有希望的方向。

##### **Isomorphic Pruning for Vision Models**
2407.04616v1 by Gongfan Fang, Xinyin Ma, Michael Bi Mi, Xinchao Wang

Structured pruning reduces the computational overhead of deep neural networks
by removing redundant sub-structures. However, assessing the relative
importance of different sub-structures remains a significant challenge,
particularly in advanced vision models featuring novel mechanisms and
architectures like self-attention, depth-wise convolutions, or residual
connections. These heterogeneous substructures usually exhibit diverged
parameter scales, weight distributions, and computational topology, introducing
considerable difficulty to importance comparison. To overcome this, we present
Isomorphic Pruning, a simple approach that demonstrates effectiveness across a
range of network architectures such as Vision Transformers and CNNs, and
delivers competitive performance across different model sizes. Isomorphic
Pruning originates from an observation that, when evaluated under a pre-defined
importance criterion, heterogeneous sub-structures demonstrate significant
divergence in their importance distribution, as opposed to isomorphic
structures that present similar importance patterns. This inspires us to
perform isolated ranking and comparison on different types of sub-structures
for more reliable pruning. Our empirical results on ImageNet-1K demonstrate
that Isomorphic Pruning surpasses several pruning baselines dedicatedly
designed for Transformers or CNNs. For instance, we improve the accuracy of
DeiT-Tiny from 74.52% to 77.50% by pruning an off-the-shelf DeiT-Base model.
And for ConvNext-Tiny, we enhanced performance from 82.06% to 82.18%, while
reducing the number of parameters and memory usage. Code is available at
\url{https://github.com/VainF/Isomorphic-Pruning}.

摘要：<paragraph>結構化剪枝透過移除冗餘的子結構，來降低深度神經網路的運算負擔。然而，評估不同子結構的相對重要性仍然是一項重大的挑戰，特別是在具備自注意力、深度卷積或殘差連接等新機制和架構的先進視覺模型中。這些異質子結構通常展現出不同的參數規模、權重分配和運算拓撲，為重要性比較帶來了相當大的困難。為了克服這個問題，我們提出了同構剪枝，這是一種簡單的方法，證明了在各種網路架構（例如 Vision Transformers 和 CNN）中的有效性，並在不同的模型規模中提供了有競爭力的效能。同構剪枝源於一個觀察，即在預定義的重要性準則下進行評估時，異質子結構在其重要性分佈上表現出顯著的差異，而同構結構則呈現出相似的重要性模式。這啟發我們對不同類型的子結構執行孤立的排名和比較，以進行更可靠的剪枝。我們在 ImageNet-1K 上的實證結果證明，同構剪枝超越了專門為 Transformer 或 CNN 設計的幾個剪枝基準。例如，我們將現成的 DeiT-Base 模型進行剪枝，將 DeiT-Tiny 的準確度從 74.52% 提升至 77.50%。對於 ConvNext-Tiny，我們將效能從 82.06% 提升至 82.18%，同時減少了參數數量和記憶體使用量。程式碼可在 \url{https://github.com/VainF/Isomorphic-Pruning} 取得。</paragraph>

##### **ARM: Efficient Guided Decoding with Autoregressive Reward Models**
2407.04615v1 by Sergey Troshin, Vlad Niculae, Antske Fokkens

Language models trained on large amounts of data require careful tuning to be
safely deployed in real world. We revisit the guided decoding paradigm, where
the goal is to augment the logits of the base language model using the scores
from a task-specific reward model. We propose a simple but efficient
parameterization of the autoregressive reward model enabling fast and effective
guided decoding. On detoxification and sentiment control tasks, we show that
our efficient parameterization performs on par with RAD, a strong but less
efficient guided decoding approach.

摘要：在大量資料上訓練的語言模型需要小心調整，才能安全地部署在現實世界。我們重新探討引導式解碼範例，其中目標是使用特定於任務的獎勵模型的分數來擴充基礎語言模型的 logit。我們提出自迴歸獎勵模型的簡單但有效的參數化，使引導式解碼快速且有效。在解毒和情緒控制任務中，我們展示我們的有效參數化表現與 RAD 相當，RAD 是一種強大但效率較低的引導式解碼方法。

##### **Written Term Detection Improves Spoken Term Detection**
2407.04601v1 by Bolaji Yusuf, Murat Saraçlar

End-to-end (E2E) approaches to keyword search (KWS) are considerably simpler
in terms of training and indexing complexity when compared to approaches which
use the output of automatic speech recognition (ASR) systems. This
simplification however has drawbacks due to the loss of modularity. In
particular, where ASR-based KWS systems can benefit from external unpaired text
via a language model, current formulations of E2E KWS systems have no such
mechanism. Therefore, in this paper, we propose a multitask training objective
which allows unpaired text to be integrated into E2E KWS without complicating
indexing and search. In addition to training an E2E KWS model to retrieve text
queries from spoken documents, we jointly train it to retrieve text queries
from masked written documents. We show empirically that this approach can
effectively leverage unpaired text for KWS, with significant improvements in
search performance across a wide variety of languages. We conduct analysis
which indicates that these improvements are achieved because the proposed
method improves document representations for words in the unpaired text.
Finally, we show that the proposed method can be used for domain adaptation in
settings where in-domain paired data is scarce or nonexistent.

摘要：端對端 (E2E) 關鍵字搜尋 (KWS) 方法在訓練和索引複雜度方面比使用自動語音辨識 (ASR) 系統結果的方法簡單許多。然而，這種簡化由於模組化的喪失而有其缺點。特別是，基於 ASR 的 KWS 系統可以透過語言模型從外部未配對文字中受益，目前 E2E KWS 系統的公式化並無此機制。因此，在本文中，我們提出了一個多任務訓練目標，允許將未配對文字整合到 E2E KWS 中，而不會使索引和搜尋複雜化。除了訓練 E2E KWS 模型從口述文件中擷取文字查詢之外，我們還聯合訓練它從遮罩書面文件中擷取文字查詢。我們透過經驗證明，此方法可以有效地利用未配對文字進行 KWS，在各種語言中大幅提升搜尋效能。我們進行的分析指出，這些提升之所以達成，是因為所提出的方法改進了未配對文字中單字的文件表示。最後，我們展示所提出的方法可用於領域適應，在其中網域內配對資料稀少或不存在的情況下。

##### **Feature Attenuation of Defective Representation Can Resolve Incomplete Masking on Anomaly Detection**
2407.04597v1 by YeongHyeon Park, Sungho Kang, Myung Jin Kim, Hyeong Seok Kim, Juneho Yi

In unsupervised anomaly detection (UAD) research, while state-of-the-art
models have reached a saturation point with extensive studies on public
benchmark datasets, they adopt large-scale tailor-made neural networks (NN) for
detection performance or pursued unified models for various tasks. Towards edge
computing, it is necessary to develop a computationally efficient and scalable
solution that avoids large-scale complex NNs. Motivated by this, we aim to
optimize the UAD performance with minimal changes to NN settings. Thus, we
revisit the reconstruction-by-inpainting approach and rethink to improve it by
analyzing strengths and weaknesses. The strength of the SOTA methods is a
single deterministic masking approach that addresses the challenges of random
multiple masking that is inference latency and output inconsistency.
Nevertheless, the issue of failure to provide a mask to completely cover
anomalous regions is a remaining weakness. To mitigate this issue, we propose
Feature Attenuation of Defective Representation (FADeR) that only employs two
MLP layers which attenuates feature information of anomaly reconstruction
during decoding. By leveraging FADeR, features of unseen anomaly patterns are
reconstructed into seen normal patterns, reducing false alarms. Experimental
results demonstrate that FADeR achieves enhanced performance compared to
similar-scale NNs. Furthermore, our approach exhibits scalability in
performance enhancement when integrated with other single deterministic masking
methods in a plug-and-play manner.

摘要：在無監督異常偵測 (UAD) 研究中，儘管最先進的模型已針對公眾基準資料集進行廣泛研究而達到飽和點，但它們採用了大規模客製化神經網路 (NN) 來偵測效能，或針對各種任務追求統一模型。為了達到邊緣運算，有必要開發一種計算有效率且可擴充的解決方案，以避免大規模複雜的 NN。基於這個動機，我們旨在以最小的 NN 設定變更來最佳化 UAD 效能。因此，我們重新探討了透過修復重建的方法，並透過分析優缺點來重新思考以改善它。SOTA 方法的優點是一種單一的確定性遮罩方法，它解決了隨機多重遮罩的挑戰，即推論延遲和輸出不一致。儘管如此，無法提供遮罩來完全覆蓋異常區域的問題仍然是一個缺點。為了減輕這個問題，我們提出了缺陷表徵特徵衰減 (FADeR)，它僅使用兩個 MLP 層，在解碼過程中衰減異常重建的特徵資訊。透過利用 FADeR，未見異常模式的特徵被重建成已見的正常模式，減少誤報。實驗結果表明，與類似規模的 NN 相比，FADeR 達到了增強的效能。此外，我們的做法在與其他單一確定性遮罩方法以即插即用方式整合時，展現了效能增強的可擴充性。

##### **Testing learning hypotheses using neural networks by manipulating learning data**
2407.04593v1 by Cara Su-Yi Leong, Tal Linzen

Although passivization is productive in English, it is not completely general
-- some exceptions exist (e.g. *One hour was lasted by the meeting). How do
English speakers learn these exceptions to an otherwise general pattern? Using
neural network language models as theories of acquisition, we explore the
sources of indirect evidence that a learner can leverage to learn whether a
verb can passivize. We first characterize English speakers' judgments of
exceptions to the passive, confirming that speakers find some verbs more
passivizable than others. We then show that a neural network language model can
learn restrictions to the passive that are similar to those displayed by
humans, suggesting that evidence for these exceptions is available in the
linguistic input. We test the causal role of two hypotheses for how the
language model learns these restrictions by training models on modified
training corpora, which we create by altering the existing training corpora to
remove features of the input implicated by each hypothesis. We find that while
the frequency with which a verb appears in the passive significantly affects
its passivizability, the semantics of the verb does not. This study highlight
the utility of altering a language model's training data for answering
questions where complete control over a learner's input is vital.

摘要：儘管被動語態在英語中具有生產力，但它並非完全普遍
-- 有一些例外（例如 *One hour was lasted by the meeting）。英語使用者如何學習這些例外情況以適應其他一般模式？使用神經網路語言模型作為習得理論，我們探討了學習者可以利用的間接證據來源，以學習動詞是否可以被動化。我們首先描述英語使用者對被動語態例外的判斷，確認使用者發現某些動詞比其他動詞更容易被動化。然後，我們展示一個神經網路語言模型可以學習到與人類表現類似的被動語態限制，這表明這些例外的證據可以在語言輸入中獲得。我們測試了兩個假設對語言模型學習這些限制的因果關係，方法是在修改後的訓練語料庫上訓練模型，我們通過更改現有的訓練語料庫來刪除每個假設所涉及的輸入特徵。我們發現，儘管動詞出現在被動語態中的頻率顯著影響其被動化，但動詞的語義並未受到影響。這項研究強調了改變語言模型訓練資料以回答問題的效用，在這些問題中，對學習者輸入的完全控制至關重要。

##### **VRSD: Rethinking Similarity and Diversity for Retrieval in Large Language Models**
2407.04573v1 by Hang Gao, Yongfeng Zhang

Vector retrieval algorithms are vital for semantic queries in the evolving
landscape of Large Language Models (LLMs). Retrieving vectors that
simultaneously meet criteria for both similarity and diversity significantly
enhances the capabilities of LLM-based agents. Despite the widespread use of
the Maximal Marginal Relevance (MMR) in retrieval scenarios with relevance and
diversity requirements, fluctuations caused by variations in the parameter $
\lambda $ within the MMR complicate the determination of the optimization
trajectory in vector spaces, thus obscuring the direction of enhancement.
Moreover, there is a lack of a robust theoretical analysis for the constraints
of similarity and diversity in retrieval processes. This paper introduces a
novel approach to characterizing both constraints through the relationship
between the sum vector and the query vector. The proximity of these vectors
addresses the similarity constraint, while necessitating that individual
vectors within the sum vector divergently align with the query vector to
satisfy the diversity constraint. We also formulate a new combinatorial
optimization challenge, taking a selection of $k$ vectors from a set of
candidates such that their sum vector maximally aligns with the query vector, a
problem we demonstrate to be NP-complete. This establishes the profound
difficulty of pursuing similarity and diversity simultaneously in vector
retrieval and lays a theoretical groundwork for further research. Additionally,
we present the heuristic algorithm Vectors Retrieval with Similarity and
Diversity (VRSD) which not only has a definitive optimization goal and eschews
the need for preset parameters but also offers a modest reduction in time
complexity compared to MMR. Empirical validation further confirm that VRSD
significantly surpasses MMR across various datasets.

摘要：向量检索算法对于大型语言模型（LLM）不断演变的语义查询至关重要。同时满足相似性和多样性标准的检索向量极大地增强了基于 LLM 的代理的功能。尽管在具有相关性和多样性要求的检索场景中广泛使用了最大边际相关性 (MMR)，但 MMR 中参数 $ \lambda $ 的变化导致的波动使优化轨迹在向量空间中的确定变得复杂，从而模糊了增强的方向。此外，缺乏对检索过程中相似性和多样性约束的稳健理论分析。本文介绍了一种通过总向量和查询向量之间的关系来表征这两个约束的新方法。这些向量的接近度解决了相似性约束，同时要求总向量中的各个向量与查询向量发散对齐以满足多样性约束。我们还制定了一个新的组合优化挑战，从一组候选向量中选择 $k$ 个向量，使得它们的总向量与查询向量最大对齐，我们证明这是一个 NP 完全问题。这确立了在向量检索中同时追求相似性和多样性的深刻困难，并为进一步的研究奠定了理论基础。此外，我们提出了具有相似性和多样性的向量检索启发式算法 (VRSD)，它不仅具有明确的优化目标，而且无需预设参数，还与 MMR 相比在时间复杂度上提供了适度的降低。经验验证进一步证实，VRSD 在各种数据集上都明显优于 MMR。

##### **Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition**
2407.04559v1 by Aditya K Surikuchi, Raquel Fernández, Sandro Pezzelle

Visual storytelling consists in generating a natural language story given a
temporally ordered sequence of images. This task is not only challenging for
models, but also very difficult to evaluate with automatic metrics since there
is no consensus about what makes a story 'good'. In this paper, we introduce a
novel method that measures story quality in terms of human likeness regarding
three key aspects highlighted in previous work: visual grounding, coherence,
and repetitiveness. We then use this method to evaluate the stories generated
by several models, showing that the foundation model LLaVA obtains the best
result, but only slightly so compared to TAPM, a 50-times smaller visual
storytelling model. Upgrading the visual and language components of TAPM
results in a model that yields competitive performance with a relatively low
number of parameters. Finally, we carry out a human evaluation study, whose
results suggest that a 'good' story may require more than a human-like level of
visual grounding, coherence, and repetition.

摘要：視覺說故事包含在給定時間順序的影像序列中產生自然語言故事。此任務不僅對模型具有挑戰性，而且由於對於什麼構成「好」故事沒有共識，因此也很難使用自動化指標進行評估。在本文中，我們介紹一種新方法，該方法根據先前工作中強調的三個關鍵方面（視覺基礎、連貫性和重複性）衡量故事品質，以符合人類喜好。然後，我們使用此方法評估由多個模型產生的故事，顯示基礎模型 LLaVA 獲得最佳結果，但與 TAPM（一個小 50 倍的視覺說故事模型）相比，僅略勝一籌。升級 TAPM 的視覺和語言組件會產生一個模型，該模型以相對較少的參數產生具有競爭力的性能。最後，我們進行一項人類評估研究，其結果表明「好」故事可能需要高於人類層級的視覺基礎、連貫性和重複性。

##### **Spontaneous Reward Hacking in Iterative Self-Refinement**
2407.04549v1 by Jane Pan, He He, Samuel R. Bowman, Shi Feng

Language models are capable of iteratively improving their outputs based on
natural language feedback, thus enabling in-context optimization of user
preference. In place of human users, a second language model can be used as an
evaluator, providing feedback along with numerical ratings which the generator
attempts to optimize. However, because the evaluator is an imperfect proxy of
user preference, this optimization can lead to reward hacking, where the
evaluator's ratings improve while the generation quality remains stagnant or
even decreases as judged by actual user preference. The concern of reward
hacking is heightened in iterative self-refinement where the generator and the
evaluator use the same underlying language model, in which case the
optimization pressure can drive them to exploit shared vulnerabilities. Using
an essay editing task, we show that iterative self-refinement leads to
deviation between the language model evaluator and human judgment,
demonstrating that reward hacking can occur spontaneously in-context with the
use of iterative self-refinement. In addition, we study conditions under which
reward hacking occurs and observe two factors that affect reward hacking
severity: model size and context sharing between the generator and the
evaluator.

摘要：語言模型能夠根據自然語言回饋反覆改善其輸出，從而能夠在上下文中最佳化使用者偏好。第二個語言模型可以取代人類使用者作為評估者，提供回饋和數字評分，而生成器會嘗試最佳化這些評分。然而，由於評估者是使用者偏好的不完美代理，因此這種最佳化可能會導致獎勵駭客，也就是評估者的評分提高，但生成品質卻停滯不前，甚至根據實際使用者偏好判斷而下降。在生成器和評估器使用相同底層語言模型的互動式自我精進中，獎勵駭客的疑慮會加劇，這種情況下，最佳化壓力可能會驅使它們利用共有的漏洞。我們使用一篇論文編輯任務，展示互動式自我精進會導致語言模型評估器和人類判斷之間出現偏差，證明獎勵駭客可能會在使用互動式自我精進時自發地發生在上下文中。此外，我們研究了獎勵駭客發生的條件，並觀察到兩個會影響獎勵駭客嚴重性的因素：模型大小和生成器與評估器之間的上下文共享。

##### **Real-time Timbre Remapping with Differentiable DSP**
2407.04547v1 by Jordie Shier, Charalampos Saitis, Andrew Robertson, Andrew McPherson

Timbre is a primary mode of expression in diverse musical contexts. However,
prevalent audio-driven synthesis methods predominantly rely on pitch and
loudness envelopes, effectively flattening timbral expression from the input.
Our approach draws on the concept of timbre analogies and investigates how
timbral expression from an input signal can be mapped onto controls for a
synthesizer. Leveraging differentiable digital signal processing, our method
facilitates direct optimization of synthesizer parameters through a novel
feature difference loss. This loss function, designed to learn relative timbral
differences between musical events, prioritizes the subtleties of graded timbre
modulations within phrases, allowing for meaningful translations in a timbre
space. Using snare drum performances as a case study, where timbral expression
is central, we demonstrate real-time timbre remapping from acoustic snare drums
to a differentiable synthesizer modeled after the Roland TR-808.

摘要：音色是各種音樂情境中主要的表現模式。然而，普遍的音訊驅動合成方法主要依賴音高和響度包絡線，有效地將輸入音色的表現扁平化。我們的做法汲取音色類比的概念，並探討如何將輸入訊號的音色表現對應到合成器的控制項上。透過運用可微分的數位訊號處理，我們的做法促成合成器參數的直接最佳化，透過一種新穎的特徵差異損失。此損失函數旨在學習音樂事件之間相對的音色差異，優先考慮短語中漸進音色調變的細微差別，允許在音色空間中進行有意義的轉換。以小軍鼓的演奏為案例研究，其中音色表現是核心，我們展示了從原聲小軍鼓到可微分合成器的即時音色重新對應，該合成器以 Roland TR-808 為模型。

##### **Strengthening Structural Inductive Biases by Pre-training to Perform Syntactic Transformations**
2407.04543v1 by Matthias Lindemann, Alexander Koller, Ivan Titov

Models need appropriate inductive biases to effectively learn from small
amounts of data and generalize systematically outside of the training
distribution. While Transformers are highly versatile and powerful, they can
still benefit from enhanced structural inductive biases for seq2seq tasks,
especially those involving syntactic transformations, such as converting active
to passive voice or semantic parsing. In this paper, we propose to strengthen
the structural inductive bias of a Transformer by intermediate pre-training to
perform synthetically generated syntactic transformations of dependency trees
given a description of the transformation. Our experiments confirm that this
helps with few-shot learning of syntactic tasks such as chunking, and also
improves structural generalization for semantic parsing. Our analysis shows
that the intermediate pre-training leads to attention heads that keep track of
which syntactic transformation needs to be applied to which token, and that the
model can leverage these attention heads on downstream tasks.

摘要：模型需要適當的歸納偏誤，才能從少量資料中有效學習，並在訓練分佈之外進行系統化概化。雖然 Transformer 非常靈活且強大，但它們仍可以從增強的結構歸納偏誤中受益，特別是那些涉及句法轉換的 seq2seq 任務，例如將主動語態轉換為被動語態或語義解析。在本文中，我們建議透過中間預訓練來加強 Transformer 的結構歸納偏誤，以執行從屬樹的合成生成句法轉換，並提供轉換說明。我們的實驗證實，這有助於句法任務的少量學習，例如分塊，並改善語義解析的結構概化。我們的分析顯示，中間預訓練會導致關注點頭部追蹤哪些句法轉換需要應用於哪些標記，以及模型可以在下游任務中利用這些關注點頭部。

##### **PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts**
2407.04541v1 by Ana-Cristina Rogoz, Maria Ilinca Nechita, Radu Tudor Ionescu

We introduce PoPreRo, the first dataset for Popularity Prediction of Romanian
posts collected from Reddit. The PoPreRo dataset includes a varied compilation
of post samples from five distinct subreddits of Romania, totaling 28,107 data
samples. Along with our novel dataset, we introduce a set of competitive models
to be used as baselines for future research. Interestingly, the top-scoring
model achieves an accuracy of 61.35% and a macro F1 score of 60.60% on the test
set, indicating that the popularity prediction task on PoPreRo is very
challenging. Further investigations based on few-shot prompting the Falcon-7B
Large Language Model also point in the same direction. We thus believe that
PoPreRo is a valuable resource that can be used to evaluate models on
predicting the popularity of social media posts in Romanian. We release our
dataset at https://github.com/ana-rogoz/PoPreRo.

摘要：我們介紹 PoPreRo，這是從 Reddit 收集的羅馬尼亞貼文流行度預測第一個資料集。PoPreRo 資料集包含來自羅馬尼亞五個不同子版的各種貼文範例，總計 28,107 個資料範例。除了我們的新穎資料集，我們還介紹了一組競爭模型，可用作未來研究的基準。有趣的是，得分最高的模型在測試集中達到了 61.35% 的準確度和 60.60% 的巨集 F1 分數，這表示在 PoPreRo 上的流行度預測任務非常具有挑戰性。基於 Falcon-7B 大型語言模型的少量提示進一步調查也指向了相同的方向。因此，我們相信 PoPreRo 是一個有價值的資源，可用於評估模型對預測羅馬尼亞社群媒體貼文流行度的能力。我們在 https://github.com/ana-rogoz/PoPreRo 發布我們的資料集。

##### **PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers**
2407.04538v1 by Ananthu Aniraj, Cassio F. Dantas, Dino Ienco, Diego Marcos

Computer vision methods that explicitly detect object parts and reason on
them are a step towards inherently interpretable models. Existing approaches
that perform part discovery driven by a fine-grained classification task make
very restrictive assumptions on the geometric properties of the discovered
parts; they should be small and compact. Although this prior is useful in some
cases, in this paper we show that pre-trained transformer-based vision models,
such as self-supervised DINOv2 ViT, enable the relaxation of these constraints.
In particular, we find that a total variation (TV) prior, which allows for
multiple connected components of any size, substantially outperforms previous
work. We test our approach on three fine-grained classification benchmarks:
CUB, PartImageNet and Oxford Flowers, and compare our results to previously
published methods as well as a re-implementation of the state-of-the-art method
PDiscoNet with a transformer-based backbone. We consistently obtain substantial
improvements across the board, both on part discovery metrics and the
downstream classification task, showing that the strong inductive biases in
self-supervised ViT models require to rethink the geometric priors that can be
used for unsupervised part discovery.

摘要：電腦視覺方法明確偵測物件部分並對其進行推理，這是朝向內在可解釋模型邁進的一步。現有方法執行由細緻分類任務驅動的部分發現，對發現部分的幾何屬性做出非常嚴格的假設；它們應該小而緊湊。雖然此先驗在某些情況下很有用，但在本文中，我們展示了預先訓練好的基於轉換器的視覺模型（例如自監督 DINOv2 ViT）能夠放寬這些約束。特別是，我們發現允許多個任意大小的連接組件的總變異 (TV) 先驗，大幅優於先前的研究。我們在三個細緻分類基準測試：CUB、PartImageNet 和 Oxford Flowers 上測試我們的做法，並將我們的結果與先前發表的各種方法以及使用基於轉換器的骨幹對最先進方法 PDiscoNet 進行重新實作的方法進行比較。我們在各方面持續獲得大幅改善，無論是在部分發現指標或下游分類任務上，這顯示自監督 ViT 模型中的強誘導偏差需要重新思考可用於無監督部分發現的幾何先驗。

##### **Performance Analysis of Speech Encoders for Low-Resource SLU and ASR in Tunisian Dialect**
2407.04533v1 by Salima Mdhaffar, Haroun Elleuch, Fethi Bougares, Yannick Estève

Speech encoders pretrained through self-supervised learning (SSL) have
demonstrated remarkable performance in various downstream tasks, including
Spoken Language Understanding (SLU) and Automatic Speech Recognition (ASR). For
instance, fine-tuning SSL models for such tasks has shown significant
potential, leading to improvements in the SOTA performance across challenging
datasets. In contrast to existing research, this paper contributes by comparing
the effectiveness of SSL approaches in the context of (i) the low-resource
spoken Tunisian Arabic dialect and (ii) its combination with a low-resource SLU
and ASR scenario, where only a few semantic annotations are available for
fine-tuning. We conduct experiments using many SSL speech encoders on the
TARIC-SLU dataset. We use speech encoders that were pre-trained on either
monolingual or multilingual speech data. Some of them have also been refined
without in-domain nor Tunisian data through multimodal supervised
teacher-student paradigm. This study yields numerous significant findings that
we are discussing in this paper.

摘要：透過自我監督學習 (SSL) 預先訓練的語音編碼器已在各種下游任務中展現出顯著的表現，包括口語理解 (SLU) 和自動語音辨識 (ASR)。例如，微調此類任務的 SSL 模型已展現出顯著的潛力，進而提升各種挑戰性資料集的 SOTA 表現。與現有研究相反，本文透過比較 SSL 方法在 (i) 低資源突尼西亞阿拉伯語方言和 (ii) 其與低資源 SLU 和 ASR 情境的結合中之有效性，進而做出貢獻，其中只有少數語意標註可供微調。我們在 TARIC-SLU 資料集上使用許多 SSL 語音編碼器進行實驗。我們使用預先在單語或多語言語音資料上訓練的語音編碼器。其中一些也已透過多模態監督師生範式進行精煉，而無需使用領域內或突尼西亞資料。本研究產生許多重要的發現，我們將在本文中進行討論。

##### **GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning**
2407.04528v1 by Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev

Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation
(RAG) have become popular methods for adapting large language models while
minimizing compute requirements. In this paper, we apply PEFT methods
(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer
(RETRO) and a baseline GPT model across several sizes, ranging from 823 million
to 48 billion parameters. We show that RETRO models outperform GPT models in
zero-shot settings due to their unique pre-training process but GPT models have
higher performance potential with PEFT. Additionally, our study indicates that
8B parameter models strike an optimal balance between cost and performance and
P-tuning lags behind other PEFT techniques. We further provide a comparative
analysis of between applying PEFT to an Instruction-tuned RETRO model and base
RETRO model. This work presents the first comprehensive comparison of various
PEFT methods integrated with RAG, applied to both GPT and RETRO models,
highlighting their relative performance.

摘要：參數高效微調 (PEFT) 和檢索增強生成 (RAG) 已成為在最小化運算需求的同時，適應大型語言模型的熱門方法。在本文中，我們將 PEFT 方法 (P-tuning、適配器和 LoRA) 應用於修改後的檢索增強式 Transformer (RETRO) 和一個基線 GPT 模型，其大小範圍從 8.23 億到 480 億個參數。我們表明，由於其獨特的預訓練過程，RETRO 模型在零次學習設置中優於 GPT 模型，但 GPT 模型在 PEFT 中具有更高的效能潛力。此外，我們的研究表明，8B 參數模型在成本和效能之間取得了最佳平衡，而 P-tuning 落後於其他 PEFT 技術。我們進一步提供了將 PEFT 應用於指令微調 RETRO 模型和基礎 RETRO 模型之間的比較分析。這項工作首次對整合 RAG 的各種 PEFT 方法進行了全面比較，並應用於 GPT 和 RETRO 模型，突出了它們的相對效能。

##### **Enhancing learning in artificial neural networks through cellular heterogeneity and neuromodulatory signaling**
2407.04525v1 by Alejandro Rodriguez-Garcia, Jie Mei, Srikanth Ramaswamy

Recent progress in artificial intelligence (AI) has been driven by insights
from neuroscience, particularly with the development of artificial neural
networks (ANNs). This has significantly enhanced the replication of complex
cognitive tasks such as vision and natural language processing. Despite these
advances, ANNs struggle with continual learning, adaptable knowledge transfer,
robustness, and resource efficiency - capabilities that biological systems
handle seamlessly. Specifically, ANNs often overlook the functional and
morphological diversity of the brain, hindering their computational
capabilities. Furthermore, incorporating cell-type specific neuromodulatory
effects into ANNs with neuronal heterogeneity could enable learning at two
spatial scales: spiking behavior at the neuronal level, and synaptic plasticity
at the circuit level, thereby potentially enhancing their learning abilities.
In this article, we summarize recent bio-inspired models, learning rules and
architectures and propose a biologically-informed framework for enhancing ANNs.
Our proposed dual-framework approach highlights the potential of spiking neural
networks (SNNs) for emulating diverse spiking behaviors and dendritic
compartments to simulate morphological and functional diversity of neuronal
computations. Finally, we outline how the proposed approach integrates
brain-inspired compartmental models and task-driven SNNs, balances
bioinspiration and complexity, and provides scalable solutions for pressing AI
challenges, such as continual learning, adaptability, robustness, and
resource-efficiency.

摘要：近期人工智能 (AI) 的進展是由神經科學的見解推動的，特別是人工神經網路 (ANN) 的發展。這顯著增強了複雜認知任務的複製，例如視覺和自然語言處理。儘管有這些進展，ANN 在持續學習、適應性知識轉移、穩健性和資源效率方面仍然有困難，而這些能力是生物系統可以無縫處理的。具體來說，ANN 常常忽略大腦的功能和形態多樣性，阻礙了它們的計算能力。此外，將細胞類型特異性神經調製效應納入具有神經元異質性的 ANN 中可以實現兩個空間尺度的學習：神經元層面的尖峰行為和電路層面的突觸可塑性，從而潛在地增強它們的學習能力。在本文中，我們總結了最近的生物啟發模型、學習規則和架構，並提出了用於增強 ANN 的生物信息框架。我們提出的雙框架方法突出了尖峰神經網路 (SNN) 模擬多樣化尖峰行為和樹突隔室以模擬神經元計算的形態和功能多樣性的潛力。最後，我們概述了所提出的方法如何整合受大腦啟發的隔室模型和任務驅動的 SNN，平衡生物啟發和複雜性，並為持續學習、適應性、穩健性和資源效率等緊迫的人工智慧挑戰提供可擴充的解決方案。

##### **LayerShuffle: Enhancing Robustness in Vision Transformers by Randomizing Layer Execution Order**
2407.04513v1 by Matthias Freiberger, Peter Kun, Anders Sundnes Løvlie, Sebastian Risi

Due to their architecture and how they are trained, artificial neural
networks are typically not robust toward pruning, replacing, or shuffling
layers at test time. However, such properties would be desirable for different
applications, such as distributed neural network architectures where the order
of execution cannot be guaranteed or parts of the network can fail during
inference. In this work, we address these issues through a number of proposed
training approaches for vision transformers whose most important component is
randomizing the execution order of attention modules at training time. We show
that with our proposed approaches, vision transformers are indeed capable to
adapt to arbitrary layer execution orders at test time assuming one tolerates a
reduction (about 20\%) in accuracy at the same model size. We also find that
our trained models can be randomly merged with each other resulting in
functional ("Frankenstein") models without loss of performance compared to the
source models. Finally, we layer-prune our models at test time and find that
their performance declines gracefully.

摘要：由於人工神經網路的架構及其訓練方式，通常不會針對測試時的修剪、替換或層級洗牌具有穩健性。然而，這類屬性對於不同的應用程式而言是理想的，例如無法保證執行順序或網路部分在推論期間可能會失敗的分布式神經網路架構。在這項工作中，我們透過多種建議的訓練方法來解決這些問題，這些方法適用於視覺轉換器，其最重要的組成部分是訓練期間隨機化注意力模組的執行順序。我們展示，透過建議的方法，視覺轉換器確實有能力適應測試期間的任意層執行順序，假設在相同模型大小下容忍準確度降低（約 20%）。我們也發現，我們訓練的模型可以隨機彼此合併，產生功能性的（「科學怪人」）模型，而與原始模型相比，效能並不會降低。最後，我們在測試期間對模型進行層級修剪，並發現其效能會優雅地衰減。

##### **When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions**
2407.04503v1 by Jérémy Perez, Corentin Léger, Grgur Kovač, Cédric Colas, Gaia Molinaro, Maxime Derex, Pierre-Yves Oudeyer, Clément Moulin-Frier

As large language models (LLMs) start interacting with each other and
generating an increasing amount of text online, it becomes crucial to better
understand how information is transformed as it passes from one LLM to the
next. While significant research has examined individual LLM behaviors,
existing studies have largely overlooked the collective behaviors and
information distortions arising from iterated LLM interactions. Small biases,
negligible at the single output level, risk being amplified in iterated
interactions, potentially leading the content to evolve towards attractor
states. In a series of telephone game experiments, we apply a transmission
chain design borrowed from the human cultural evolution literature: LLM agents
iteratively receive, produce, and transmit texts from the previous to the next
agent in the chain. By tracking the evolution of text toxicity, positivity,
difficulty, and length across transmission chains, we uncover the existence of
biases and attractors, and study their dependence on the initial text, the
instructions, language model, and model size. For instance, we find that more
open-ended instructions lead to stronger attraction effects compared to more
constrained tasks. We also find that different text properties display
different sensitivity to attraction effects, with toxicity leading to stronger
attractors than length. These findings highlight the importance of accounting
for multi-step transmission dynamics and represent a first step towards a more
comprehensive understanding of LLM cultural dynamics.

摘要：隨著大型語言模型 (LLM) 開始彼此互動，並在網路上產生越來越多文字，因此了解資訊在從一個 LLM 傳遞到另一個 LLM 的過程中如何轉換變得至關重要。雖然許多研究探討了個別 LLM 行為，但現有研究在很大程度上忽略了重複 LLM 互動所產生的集體行為和資訊扭曲。輕微的偏差在單一輸出層級上可以忽略不計，但在重複互動中可能會被放大，可能導致內容朝著吸引子狀態演化。在連串的傳話遊戲實驗中，我們運用從人類文化演化文獻中借用的傳輸鏈設計：LLM 代理人會重複接收、產生和傳輸文字，從前一個代理人傳遞到鏈中的下一個代理人。透過追蹤傳輸鏈中文字毒性、正面性、難度和長度的演變，我們揭露了偏差和吸引子的存在，並研究它們對初始文字、指令、語言模型和模型大小的依賴性。例如，我們發現與更受限的任務相比，更開放式的指令會導致更強的吸引效應。我們還發現不同的文字屬性對吸引效應的敏感度不同，其中毒性會導致比長度更強的吸引子。這些發現強調了考量多步驟傳輸動態的重要性，並代表了朝著更全面了解 LLM 文化動態邁出的第一步。

##### **Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**
2407.04486v1 by Tianshu Feng, Rohan Gnanaolivu, Abolfazl Safikhani, Yuanhang Liu, Jun Jiang, Nicholas Chia, Alexander Partin, Priyanka Vasanthakumari, Yitan Zhu, Chen Wang

Human cancers present a significant public health challenge and require the
discovery of novel drugs through translational research. Transcriptomics
profiling data that describes molecular activities in tumors and cancer cell
lines are widely utilized for predicting anti-cancer drug responses. However,
existing AI models face challenges due to noise in transcriptomics data and
lack of biological interpretability. To overcome these limitations, we
introduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel
neural network framework that incorporates a variational component to mitigate
noise effects and integrates traceable gene ontology into the neural network
architecture for encoding cancer transcriptomics data. Key innovations include
a local interpretability-guided method for identifying ontology paths, a
visualization tool to elucidate biological mechanisms of drug responses, and
the application of centralized large scale hyperparameter optimization. VETE
demonstrated robust accuracy in cancer cell line classification and drug
response prediction. Additionally, it provided traceable biological
explanations for both tasks and offers insights into the mechanisms underlying
its predictions. VETE bridges the gap between AI-driven predictions and
biologically meaningful insights in cancer research, which represents a
promising advancement in the field.

摘要：人類癌症對公共衛生構成重大挑戰，需要透過轉譯研究發現新藥物。描述腫瘤和癌細胞株分子活動的轉錄組學分析資料廣泛用於預測抗癌藥物反應。然而，現有的 AI 模型因轉錄組學資料中的雜訊和缺乏生物學可解釋性而面臨挑戰。為了克服這些限制，我們引入了 VETE（變異和解釋性轉錄組學編碼器），這是一種新穎的神經網路架構，它結合了變異組成以減輕雜訊效應，並將可追蹤的基因本體整合到神經網路架構中以編碼癌症轉錄組學資料。關鍵創新包括一種局部可解釋性引導方法，用於識別本體路徑，一種用於闡明藥物反應的生物機制的視覺化工具，以及集中式大規模超參數最佳化的應用。VETE 在癌細胞株分類和藥物反應預測方面表現出穩健的準確性。此外，它為這兩個任務提供了可追蹤的生物學解釋，並提供了對其預測背後機制的見解。VETE 彌合了 AI 驅動預測與癌症研究中具有生物學意義的見解之間的差距，這代表了該領域的一項有前途的進展。

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

摘要：大型語言模型廣泛應用於各種任務中，例如客戶支援、內容創作、教育輔導和提供財務指導。然而，一個眾所周知的缺點是它們傾向於產生幻覺。這損害了這些模型所提供資訊的可信度，影響了決策制定和使用者信心。我們提出了一種透過觀察潛在空間的結構並找出幻覺和非幻覺生成中的關聯來偵測幻覺的方法。我們建立了一個圖形結構，連接在嵌入空間中緊密相連的生成。此外，我們採用了一個圖形注意力網路，它利用訊息傳遞來彙總來自相鄰節點的資訊，並根據每個相鄰節點的相關性為其指定不同程度的重要性。我們的研究結果顯示，1) 潛在空間中存在一個結構，可以區分幻覺和非幻覺生成，2) 圖形注意力網路可以學習這個結構並將其概括到未見的生成中，以及 3) 當納入對比學習時，我們方法的穩健性會得到增強。當根據基於證據的基準進行評估時，我們的模型在無法取得基於搜尋的方法的情況下，表現得類似。

##### **Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models**
2407.04482v1 by Vyas Raina, Mark Gales

Speech enabled foundation models, either in the form of flexible speech
recognition based systems or audio-prompted large language models (LLMs), are
becoming increasingly popular. One of the interesting aspects of these models
is their ability to perform tasks other than automatic speech recognition (ASR)
using an appropriate prompt. For example, the OpenAI Whisper model can perform
both speech transcription and speech translation. With the development of
audio-prompted LLMs there is the potential for even greater control options. In
this work we demonstrate that with this greater flexibility the systems can be
susceptible to model-control adversarial attacks. Without any access to the
model prompt it is possible to modify the behaviour of the system by
appropriately changing the audio input. To illustrate this risk, we demonstrate
that it is possible to prepend a short universal adversarial acoustic segment
to any input speech signal to override the prompt setting of an ASR foundation
model. Specifically, we successfully use a universal adversarial acoustic
segment to control Whisper to always perform speech translation, despite being
set to perform speech transcription. Overall, this work demonstrates a new form
of adversarial attack on multi-tasking speech enabled foundation models that
needs to be considered prior to the deployment of this form of model.

摘要：語音啟用的基礎模型，無論是以彈性語音辨識為基礎的系統或音訊提示的大型語言模型 (LLM) 形式，都變得越來越普遍。這些模型的有趣面向之一是它們能夠執行自動語音辨識 (ASR) 以外的任務，使用適當的提示即可。例如，OpenAI Whisper 模型可以執行語音轉錄和語音翻譯。隨著音訊提示式 LLM 的發展，有潛力獲得更大的控制選項。在這項工作中，我們展示了有了這種更大的彈性，這些系統可能會受到模型控制對抗攻擊的影響。在無法取得模型提示的情況下，可以透過適當地改變音訊輸入來修改系統的行為。為了說明這個風險，我們展示了可以將一個簡短的通用對抗音訊片段附加到任何輸入語音訊號，以覆寫 ASR 基礎模型的提示設定。具體來說，我們成功地使用通用對抗音訊片段來控制 Whisper，使其始終執行語音翻譯，儘管設定為執行語音轉錄。總的來說，這項工作展示了一種新的多任務語音啟用基礎模型對抗攻擊形式，在部署這種形式的模型之前需要考慮這種攻擊形式。

##### **EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context**
2407.04472v1 by Hannes Kunstmann, Joseph Ollier, Joel Persson, Florian von Wangenheim

Large language models (LLMs) present an enormous evolution in the strategic
potential of conversational recommender systems (CRS). Yet to date, research
has predominantly focused upon technical frameworks to implement LLM-driven
CRS, rather than end-user evaluations or strategic implications for firms,
particularly from the perspective of a small to medium enterprises (SME) that
makeup the bedrock of the global economy. In the current paper, we detail the
design of an LLM-driven CRS in an SME setting, and its subsequent performance
in the field using both objective system metrics and subjective user
evaluations. While doing so, we additionally outline a short-form revised
ResQue model for evaluating LLM-driven CRS, enabling replicability in a rapidly
evolving field. Our results reveal good system performance from a user
experience perspective (85.5% recommendation accuracy) but underscore latency,
cost, and quality issues challenging business viability. Notably, with a median
cost of $0.04 per interaction and a latency of 5.7s, cost-effectiveness and
response time emerge as crucial areas for achieving a more user-friendly and
economically viable LLM-driven CRS for SME settings. One major driver of these
costs is the use of an advanced LLM as a ranker within the retrieval-augmented
generation (RAG) technique. Our results additionally indicate that relying
solely on approaches such as Prompt-based learning with ChatGPT as the
underlying LLM makes it challenging to achieve satisfying quality in a
production environment. Strategic considerations for SMEs deploying an
LLM-driven CRS are outlined, particularly considering trade-offs in the current
technical landscape.

摘要：大型語言模型 (LLM) 展示了對話式推薦系統 (CRS) 的策略潛力中出現的巨大演進。然而，到目前為止，研究主要集中於實作 LLM 驅動的 CRS 的技術架構，而不是最終使用者的評估或對企業的策略影響，尤其是從構成全球經濟基石的中小型企業 (SME) 的角度來看。在目前的論文中，我們詳細說明了在 SME 設定中 LLM 驅動的 CRS 的設計，以及它隨後在使用客觀系統指標和主觀使用者評估的領域中的效能。在這樣做的同時，我們另外概述了一個簡短的修訂版 ResQue 模型，用於評估 LLM 驅動的 CRS，並在快速演進的領域中實現可複製性。我們的結果揭示了從使用者體驗角度來看良好的系統效能（85.5% 的推薦準確度），但強調了延遲、成本和品質問題對企業可行性構成挑戰。值得注意的是，每次互動的平均成本為 0.04 美元，延遲為 5.7 秒，因此成本效益和回應時間成為在 SME 設定中實現更使用者友善且經濟可行的 LLM 驅動 CRS 的關鍵領域。這些成本的一個主要驅動力是在檢索擴充產生 (RAG) 技術中使用進階 LLM 作為排名器。我們的結果另外指出，僅依賴於提示式學習等方法，並以 ChatGPT 作為底層 LLM，使得在生產環境中很難達到令人滿意的品質。概述了部署 LLM 驅動 CRS 的 SME 的策略考量，特別是考量到當前技術環境中的權衡取捨。

##### **Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games**
2407.04467v1 by Nathan Herr, Fernando Acero, Roberta Raileanu, María Pérez-Ortiz, Zhibin Li

Large Language Models (LLMs) have been increasingly used in real-world
settings, yet their strategic abilities remain largely unexplored. Game theory
provides a good framework for assessing the decision-making abilities of LLMs
in interactions with other agents. Although prior studies have shown that LLMs
can solve these tasks with carefully curated prompts, they fail when the
problem setting or prompt changes. In this work we investigate LLMs' behaviour
in strategic games, Stag Hunt and Prisoner Dilemma, analyzing performance
variations under different settings and prompts. Our results show that the
tested state-of-the-art LLMs exhibit at least one of the following systematic
biases: (1) positional bias, (2) payoff bias, or (3) behavioural bias.
Subsequently, we observed that the LLMs' performance drops when the game
configuration is misaligned with the affecting biases. Performance is assessed
based on the selection of the correct action, one which agrees with the
prompted preferred behaviours of both players. Alignment refers to whether the
LLM's bias aligns with the correct action. For example, GPT-4o's average
performance drops by 34% when misaligned. Additionally, the current trend of
"bigger and newer is better" does not hold for the above, where GPT-4o (the
current best-performing LLM) suffers the most substantial performance drop.
Lastly, we note that while chain-of-thought prompting does reduce the effect of
the biases on most models, it is far from solving the problem at the
fundamental level.

摘要：<paragraph>大型語言模型 (LLM) 在現實世界中的應用日益廣泛，但它們的策略能力仍未得到充分探索。博弈論提供了一個良好的框架，用於評估 LLM 在與其他代理互動時的決策能力。儘管先前的研究表明，LLM 可以通過精心策劃的提示來解決這些任務，但當問題設置或提示發生變化時，它們就會失敗。在這項工作中，我們研究了 LLM 在策略博弈、Stag Hunt 和囚徒困境中的行為，分析了在不同設置和提示下的性能變化。我們的結果表明，經過測試的最新 LLM 表現出以下系統性偏差中至少一種：(1) 位置偏差，(2) 報酬偏差，或 (3) 行為偏差。隨後，我們觀察到，當遊戲配置與影響偏差不一致時，LLM 的性能會下降。性能評估基於正確動作的選擇，該動作與提示的兩個玩家的首選行為一致。對齊是指 LLM 的偏差是否與正確的動作對齊。例如，當 GPT-4o 錯位時，其平均性能下降 34%。此外，上述情況並不符合「越大、更新越好」的當前趨勢，其中 GPT-4o（當前性能最佳的 LLM）遭受了最顯著的性能下降。最後，我們注意到，儘管思考鏈提示確實減少了偏差對大多數模型的影響，但遠未從根本上解決問題。</paragraph>

##### **Using LLMs to label medical papers according to the CIViC evidence model**
2407.04466v1 by Markus Hisch, Xing David Wang

We introduce the sequence classification problem CIViC Evidence to the field
of medical NLP. CIViC Evidence denotes the multi-label classification problem
of assigning labels of clinical evidence to abstracts of scientific papers
which have examined various combinations of genomic variants, cancer types, and
treatment approaches. We approach CIViC Evidence using different language
models: We fine-tune pretrained checkpoints of BERT and RoBERTa on the CIViC
Evidence dataset and challenge their performance with models of the same
architecture which have been pretrained on domain-specific text. In this
context, we find that BiomedBERT and BioLinkBERT can outperform BERT on CIViC
Evidence (+0.8% and +0.9% absolute improvement in class-support weighted F1
score). All transformer-based models show a clear performance edge when
compared to a logistic regression trained on bigram tf-idf scores (+1.5 - 2.7%
improved F1 score). We compare the aforementioned BERT-like models to OpenAI's
GPT-4 in a few-shot setting (on a small subset of our original test dataset),
demonstrating that, without additional prompt-engineering or fine-tuning, GPT-4
performs worse on CIViC Evidence than our six fine-tuned models (66.1% weighted
F1 score compared to 71.8% for the best fine-tuned model). However, performance
gets reasonably close to the benchmark of a logistic regression model trained
on bigram tf-idf scores (67.7% weighted F1 score).

摘要：<paragraph>我們將序列分類問題 CIViC Evidence 引入醫學 NLP 領域。CIViC Evidence 表示將臨床證據標籤指派給已檢查過各種基因組變異、癌症類型和治療方法的科學論文摘要的多標籤分類問題。我們使用不同的語言模型來處理 CIViC Evidence：我們微調 BERT 和 RoBERTa 的預訓練檢查點，並使用在特定領域文本上預訓練的相同架構模型挑戰它們的效能。在此背景下，我們發現 BiomedBERT 和 BioLinkBERT 可以優於 BERT 在 CIViC Evidence 上的表現（類別支援加權 F1 分數絕對改善 +0.8% 和 +0.9%）。與在二元詞組 tf-idf 分數上訓練的邏輯迴歸相比，所有基於 Transformer 的模型都顯示出明顯的效能優勢（改善 F1 分數 +1.5 - 2.7%）。我們在一個小範圍設定（在我們原始測試資料集的一個小部分上）中比較前述類 BERT 模型與 OpenAI 的 GPT-4，證明在沒有額外的提示工程或微調的情況下，GPT-4 在 CIViC Evidence 上的表現比我們六個微調模型差（加權 F1 分數為 66.1%，而最佳微調模型為 71.8%）。然而，效能相當接近在二元詞組 tf-idf 分數上訓練的邏輯迴歸模型的基準（加權 F1 分數為 67.7%）。</paragraph>

##### **Generalists vs. Specialists: Evaluating Large Language Models for Urdu**
2407.04459v1 by Samee Arif, Abdul Hameed Azeemi, Agha Ali Raza, Awais Athar

In this paper, we compare general-purpose pretrained models, GPT-4-Turbo and
Llama-3-8b-Instruct with special-purpose models fine-tuned on specific tasks,
XLM-Roberta-large, mT5-large, and Llama-3-8b-Instruct. We focus on seven
classification and six generation tasks to evaluate the performance of these
models on Urdu language. Urdu has 70 million native speakers, yet it remains
underrepresented in Natural Language Processing (NLP). Despite the frequent
advancements in Large Language Models (LLMs), their performance in low-resource
languages, including Urdu, still needs to be explored. We also conduct a human
evaluation for the generation tasks and compare the results with the
evaluations performed by GPT-4-Turbo and Llama-3-8b-Instruct. We find that
special-purpose models consistently outperform general-purpose models across
various tasks. We also find that the evaluation done by GPT-4-Turbo for
generation tasks aligns more closely with human evaluation compared to the
evaluation by Llama-3-8b-Instruct. This paper contributes to the NLP community
by providing insights into the effectiveness of general and specific-purpose
LLMs for low-resource languages.

摘要：<paragraph>在本文中，我們比較了通用預訓練模型 GPT-4-Turbo 和
Llama-3-8b-Instruct，以及針對特定任務進行微調的特殊用途模型，
XLM-Roberta-large、mT5-large 和 Llama-3-8b-Instruct。我們專注於七項
分類和六項生成任務，以評估這些
模型在烏爾都語中的表現。烏爾都語有 7000 萬母語使用者，但它在自然語言處理 (NLP) 中仍然
代表性不足。儘管大型語言模型 (LLM) 經常取得進展，但它們在低資源
語言（包括烏爾都語）中的表現仍有待探討。我們還對生成任務進行了人工
評估，並將結果與 GPT-4-Turbo 和 Llama-3-8b-Instruct 執行的評估進行了比較。我們發現
特殊用途模型在各種任務中始終優於通用模型。我們還發現，GPT-4-Turbo 對
生成任務所做的評估與人工評估相比，與 Llama-3-8b-Instruct 的評估更為接近。本文通過提供對一般和特定用途
LLM 對低資源語言的有效性的見解，為 NLP 社群做出貢獻。</paragraph>

##### **Robust Multimodal Learning via Representation Decoupling**
2407.04458v1 by Shicai Wei, Yang Luo, Yuji Wang, Chunbo Luo

Multimodal learning robust to missing modality has attracted increasing
attention due to its practicality. Existing methods tend to address it by
learning a common subspace representation for different modality combinations.
However, we reveal that they are sub-optimal due to their implicit constraint
on intra-class representation. Specifically, the sample with different
modalities within the same class will be forced to learn representations in the
same direction. This hinders the model from capturing modality-specific
information, resulting in insufficient learning. To this end, we propose a
novel Decoupled Multimodal Representation Network (DMRNet) to assist robust
multimodal learning. Specifically, DMRNet models the input from different
modality combinations as a probabilistic distribution instead of a fixed point
in the latent space, and samples embeddings from the distribution for the
prediction module to calculate the task loss. As a result, the direction
constraint from the loss minimization is blocked by the sampled representation.
This relaxes the constraint on the inference representation and enables the
model to capture the specific information for different modality combinations.
Furthermore, we introduce a hard combination regularizer to prevent DMRNet from
unbalanced training by guiding it to pay more attention to hard modality
combinations. Finally, extensive experiments on multimodal classification and
segmentation tasks demonstrate that the proposed DMRNet outperforms the
state-of-the-art significantly.

摘要：多模态学习对丢失的模态具有鲁棒性，由于其实用性而受到越来越多的关注。现有方法倾向于通过学习不同模态组合的公共子空间表示来解决它。然而，我们发现它们由于其对类内表示的隐式约束而次优。具体来说，同一类中具有不同模态的样本将被迫学习同一方向的表示。这阻碍了模型捕获特定于模态的信息，导致学习不足。为此，我们提出了一种新颖的解耦多模态表示网络 (DMRNet) 来辅助鲁棒多模态学习。具体来说，DMRNet 将来自不同模态组合的输入建模为概率分布，而不是潜在空间中的固定点，并从分布中采样嵌入以供预测模块计算任务损失。因此，来自损失最小化的方向约束被采样的表示所阻止。这放宽了对推理表示的约束，并使模型能够捕获不同模态组合的特定信息。此外，我们引入了一个硬组合正则化器，以防止 DMRNet 通过引导其更多地关注硬模态组合来进行不平衡的训练。最后，在多模态分类和分割任务上的大量实验表明，所提出的 DMRNet 明显优于最先进的技术。

##### **Hindsight Preference Learning for Offline Preference-based Reinforcement Learning**
2407.04451v1 by Chen-Xiao Gao, Shengjun Fang, Chenjun Xiao, Yang Yu, Zongzhang Zhang

Offline preference-based reinforcement learning (RL), which focuses on
optimizing policies using human preferences between pairs of trajectory
segments selected from an offline dataset, has emerged as a practical avenue
for RL applications. Existing works rely on extracting step-wise reward signals
from trajectory-wise preference annotations, assuming that preferences
correlate with the cumulative Markovian rewards. However, such methods fail to
capture the holistic perspective of data annotation: Humans often assess the
desirability of a sequence of actions by considering the overall outcome rather
than the immediate rewards. To address this challenge, we propose to model
human preferences using rewards conditioned on future outcomes of the
trajectory segments, i.e. the hindsight information. For downstream RL
optimization, the reward of each step is calculated by marginalizing over
possible future outcomes, the distribution of which is approximated by a
variational auto-encoder trained using the offline dataset. Our proposed
method, Hindsight Preference Learning (HPL), can facilitate credit assignment
by taking full advantage of vast trajectory data available in massive unlabeled
datasets. Comprehensive empirical studies demonstrate the benefits of HPL in
delivering robust and advantageous rewards across various domains. Our code is
publicly released at https://github.com/typoverflow/WiseRL.

摘要：離線基於偏好的強化學習 (RL)，專注於使用人類偏好來最佳化策略，這些偏好來自離線資料集中選擇的軌跡區段對之間，已成為 RL 應用的一條實用途徑。現有工作依賴於從軌跡偏好註解中提取逐步獎勵訊號，假設偏好與累積馬可夫獎勵相關。然而，這些方法未能捕捉到資料註解的整體觀點：人類通常透過考量整體結果而非立即獎勵，來評估一系列動作的可取性。為了應對這個挑戰，我們提議使用受軌跡區段未來結果制約的獎勵，亦即後見之明資訊，來建模人類偏好。對於下游 RL 最佳化，每個步驟的獎勵是透過對可能的未來結果進行邊際化來計算，其分佈由使用離線資料集訓練的變異自動編碼器來近似。我們提出的方法，後見之明偏好學習 (HPL)，可以透過充分利用大量未標記資料集中可用的龐大軌跡資料，來促進信用分配。全面的實證研究證明了 HPL 在提供各種領域的穩健且有利獎勵方面的優點。我們的程式碼已公開發布在 https://github.com/typoverflow/WiseRL。

##### **TokenVerse: Unifying Speech and NLP Tasks via Transducer-based ASR**
2407.04444v1 by Shashi Kumar, Srikanth Madikeri, Juan Zuluaga-Gomez, Iuliia Nigmatulina, Esaú Villatoro-Tello, Sergio Burdisso, Petr Motlicek, Karthik Pandia, Aravind Ganapathiraju

In traditional conversational intelligence from speech, a cascaded pipeline
is used, involving tasks such as voice activity detection, diarization,
transcription, and subsequent processing with different NLP models for tasks
like semantic endpointing and named entity recognition (NER). Our paper
introduces TokenVerse, a single Transducer-based model designed to handle
multiple tasks. This is achieved by integrating task-specific tokens into the
reference text during ASR model training, streamlining the inference and
eliminating the need for separate NLP models. In addition to ASR, we conduct
experiments on 3 different tasks: speaker change detection, endpointing, and
NER. Our experiments on a public and a private dataset show that the proposed
method improves ASR by up to 7.7% in relative WER while outperforming the
cascaded pipeline approach in individual task performance. Additionally, we
present task transfer learning to a new task within an existing TokenVerse.

摘要：在傳統的語音對話式智能中，使用串聯管道，涉及語音活動偵測、分段、轉錄，以及隨後使用不同的 NLP 模型進行後續處理，以執行語意終端點和命名實體識別 (NER) 等任務。我們的論文介紹了 TokenVerse，這是一個單一的基於轉換器的模型，旨在處理多項任務。這是透過在 ASR 模型訓練期間將特定於任務的代幣整合到參考文字中來實現的，簡化了推論並消除了對單獨 NLP 模型的需求。除了 ASR 之外，我們還對 3 項不同的任務進行了實驗：說話者變更偵測、終端點和 NER。我們在公開和私人資料集上的實驗表明，所提出的方法將 ASR 的相對 WER 提高了 7.7%，同時在個別任務效能上優於串聯管道方法。此外，我們展示了在現有的 TokenVerse 中將任務轉移學習到新任務。

##### **From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs**
2407.04434v1 by Marion Bartl, Susan Leavy

Gender bias is not only prevalent in Large Language Models (LLMs) and their
training data, but also firmly ingrained into the structural aspects of
language itself. Therefore, adapting linguistic structures within LLM training
data to promote gender-inclusivity can make gender representations within the
model more inclusive. The focus of our work are gender-exclusive affixes in
English, such as in 'show-girl' or 'man-cave', which can perpetuate gender
stereotypes and binary conceptions of gender. We use an LLM training dataset to
compile a catalogue of 692 gender-exclusive terms along with gender-neutral
variants and from this, develop a gender-inclusive fine-tuning dataset, the
'Tiny Heap'. Fine-tuning three different LLMs with this dataset, we observe an
overall reduction in gender-stereotyping tendencies across the models. Our
approach provides a practical method for enhancing gender inclusivity in LLM
training data and contributes to incorporating queer-feminist linguistic
activism in bias mitigation research in NLP.

摘要：性別偏見不僅普遍存在於大型語言模型 (LLM) 及其訓練資料中，也根深蒂固於語言本身的結構面向。因此，調整 LLM 訓練資料中的語言結構以促進性別包容性，可以讓模型中的性別表徵更具包容性。我們工作的重點在於英語中的性別專屬字尾，例如「show-girl」或「man-cave」，這些字尾可能會強化性別刻板印象和二元性別觀念。我們使用 LLM 訓練資料集編纂一份目錄，其中包含 692 個性別專屬詞彙與性別中立變體，並根據此目錄開發一個性別包容微調資料集「Tiny Heap」。使用此資料集微調三個不同的 LLM，我們觀察到所有模型的性別刻板印象傾向都有整體性的降低。我們的做法提供了一個實用的方法，可以在 LLM 訓練資料中加強性別包容性，並有助於在 NLP 的偏見緩解研究中納入酷兒女性主義語言行動主義。

##### **The Complexity of Symmetry Breaking Beyond Lex-Leader**
2407.04419v1 by Markus Anders, Sofia Brenner, Gaurav Rattan

Symmetry breaking is a widely popular approach to enhance solvers in
constraint programming, such as those for SAT or MIP. Symmetry breaking
predicates (SBPs) typically impose an order on variables and single out the
lexicographic leader (lex-leader) in each orbit of assignments. Although it is
NP-hard to find complete lex-leader SBPs, incomplete lex-leader SBPs are widely
used in practice.
  In this paper, we investigate the complexity of computing complete SBPs,
lex-leader or otherwise, for SAT. Our main result proves a natural barrier for
efficiently computing SBPs: efficient certification of graph non-isomorphism.
Our results explain the difficulty of obtaining short SBPs for important CP
problems, such as matrix-models with row-column symmetries and graph generation
problems. Our results hold even when SBPs are allowed to introduce additional
variables. We show polynomial upper bounds for breaking certain symmetry
groups, namely automorphism groups of trees and wreath products of groups with
efficient SBPs.

摘要：對稱性中斷是一種廣泛流行的方法，用於增強約束式編程中的求解器，例如用於 SAT 或 MIP 的求解器。對稱性中斷謂詞 (SBP) 通常對變數施加順序，並在每個指派軌道中挑出字典序引導 (lex-leader)。雖然找到完整的 lex-leader SBP 是 NP 難題，但實務上廣泛使用不完整的 lex-leader SBP。
在本文中，我們探討了計算 SAT 的完整 SBP（無論是 lex-leader 還是其他）的複雜性。我們的結論證明了一個有效的 SBP 計算的自然障礙：圖形非同構的有效驗證。我們的結論解釋了為重要的 CP 問題取得短 SBP 的難度，例如具有行列對稱矩陣模型和圖形生成問題。即使允許 SBP 引入額外變數，我們的結論仍然成立。我們展示了中斷特定對稱群的多項式上界，即樹的同構群和具有有效 SBP 的群的環狀積。

##### **Enabling On-Device LLMs Personalization with Smartphone Sensing**
2407.04418v1 by Shiquan Zhang, Ying Ma, Le Fang, Hong Jia, Simon D'Alfonso, Vassilis Kostakos

This demo presents a novel end-to-end framework that combines on-device large
language models (LLMs) with smartphone sensing technologies to achieve
context-aware and personalized services. The framework addresses critical
limitations of current personalization solutions via cloud-based LLMs, such as
privacy concerns, latency and cost, and limited personal sensor data. To
achieve this, we innovatively proposed deploying LLMs on smartphones with
multimodal sensor data and customized prompt engineering, ensuring privacy and
enhancing personalization performance through context-aware sensing. A case
study involving a university student demonstrated the proposed framework's
capability to provide tailored recommendations. In addition, we show that the
proposed framework achieves the best trade-off in privacy, performance,
latency, cost, battery and energy consumption between on-device and cloud LLMs.
Future work aims to integrate more diverse sensor data and conduct large-scale
user studies to further refine the personalization. We envision the proposed
framework could significantly improve user experiences in various domains such
as healthcare, productivity, and entertainment by providing secure,
context-aware, and efficient interactions directly on users' devices.

摘要：此範例展示了一個新穎的端對端架構，結合裝置上的大型語言模型 (LLM) 與智慧型手機感測技術，以達成具情境感知和個人化的服務。此架構解決了現行基於雲端 LLM 的個人化解決方案的重大限制，例如隱私疑慮、延遲和成本，以及個人感測器資料有限。為達成此目標，我們創新地提出在智慧型手機上部署 LLM，並具備多模式感測器資料和自訂提示工程，確保隱私並透過具情境感知的感測強化個人化效能。一項涉及大學生的案例研究證明，所提出的架構有能力提供客製化建議。此外，我們證明所提出的架構在裝置上和雲端 LLM 之間，在隱私、效能、延遲、成本、電池和能源消耗方面，達到了最佳的權衡。未來的研究工作旨在整合更多樣化的感測器資料，並進行大規模的使用者研究，以進一步優化個人化。我們預期，所提出的架構可以透過在使用者裝置上直接提供安全、具情境感知且有效率的互動，大幅改善各種領域（例如醫療保健、生產力和娛樂）的使用者體驗。

##### **Waterfall: Framework for Robust and Scalable Text Watermarking**
2407.04411v1 by Gregory Kang Ruey Lau, Xinyuan Niu, Hieu Dao, Jiangwei Chen, Chuan-Sheng Foo, Bryan Kian Hsiang Low

Protecting intellectual property (IP) of text such as articles and code is
increasingly important, especially as sophisticated attacks become possible,
such as paraphrasing by large language models (LLMs) or even unauthorized
training of LLMs on copyrighted text to infringe such IP. However, existing
text watermarking methods are not robust enough against such attacks nor
scalable to millions of users for practical implementation. In this paper, we
propose Waterfall, the first training-free framework for robust and scalable
text watermarking applicable across multiple text types (e.g., articles, code)
and languages supportable by LLMs, for general text and LLM data provenance.
Waterfall comprises several key innovations, such as being the first to use LLM
as paraphrasers for watermarking along with a novel combination of techniques
that are surprisingly effective in achieving robust verifiability and
scalability. We empirically demonstrate that Waterfall achieves significantly
better scalability, robust verifiability, and computational efficiency compared
to SOTA article-text watermarking methods, and also showed how it could be
directly applied to the watermarking of code.

摘要：保護文章和程式碼等文字的智慧財產（IP）日益重要，特別是因為複雜的攻擊變為可能，例如大型語言模型（LLM）的同義改寫，甚至未經授權訓練 LLM 侵犯此類 IP 的受版權保護文字。然而，現有的文字浮水印方法對於此類攻擊不夠強大，也不足以擴展到數百萬使用者以進行實際實作。在本文中，我們提出 Waterfall，這是第一個適用於 LLM 支援的多種文字類型（例如文章、程式碼）和語言的強大且可擴展的文字浮水印的無訓練架構，適用於一般文字和 LLM 資料來源。Waterfall 包含多項關鍵創新，例如首次將 LLM 用作浮水印的同義改寫者，並結合多種技術，這些技術在實現強大的可驗證性和可擴展性方面出人意料地有效。我們透過實證證明，與 SOTA 文章文字浮水印方法相比，Waterfall 在可擴展性、強大的可驗證性和運算效率方面有顯著的進步，並展示它如何直接應用於程式碼的浮水印。

##### **Discovering symbolic expressions with parallelized tree search**
2407.04405v1 by Kai Ruan, Ze-Feng Gao, Yike Guo, Hao Sun, Ji-Rong Wen, Yang Liu

Symbolic regression plays a crucial role in modern scientific research thanks
to its capability of discovering concise and interpretable mathematical
expressions from data. A grand challenge lies in the arduous search for
parsimonious and generalizable mathematical formulas, in an infinite search
space, while intending to fit the training data. Existing algorithms have faced
a critical bottleneck of accuracy and efficiency over a decade when handling
problems of complexity, which essentially hinders the pace of applying symbolic
regression for scientific exploration across interdisciplinary domains. To this
end, we introduce a parallelized tree search (PTS) model to efficiently distill
generic mathematical expressions from limited data. Through a series of
extensive experiments, we demonstrate the superior accuracy and efficiency of
PTS for equation discovery, which greatly outperforms the state-of-the-art
baseline models on over 80 synthetic and experimental datasets (e.g., lifting
its performance by up to 99% accuracy improvement and one-order of magnitude
speed up). PTS represents a key advance in accurate and efficient data-driven
discovery of symbolic, interpretable models (e.g., underlying physical laws)
and marks a pivotal transition towards scalable symbolic learning.

摘要：符號迴歸在現代科學研究中扮演著至關重要的角色，因為它有能力從資料中發現簡潔且可解釋的數學表達式。一個巨大的挑戰在於在一個無限的搜尋空間中，在打算擬合訓練資料的同時，艱難地搜尋簡約且可概化的數學公式。現有的演算法在處理複雜性問題時，在準確度和效率方面面臨著十多年的關鍵瓶頸，這在實質上阻礙了符號迴歸在跨學科領域中應用於科學探索的步伐。為此，我們引入了一個並行樹搜尋 (PTS) 模型，以有效地從有限的資料中萃取通用的數學表達式。透過一系列廣泛的實驗，我們展示了 PTS 在方程式發現方面的優異準確度和效率，在超過 80 個合成和實驗資料集上大幅優於最先進的基準模型（例如，將其效能提升了高達 99% 的準確度改進和一個數量級的速度提升）。PTS 代表了準確且有效率的資料驅動符號化、可解釋模型（例如，基礎物理定律）發現方面的一項關鍵進展，並標誌著朝向可擴充符號學習的關鍵轉變。

##### **Graph-Guided Test-Time Adaptation for Glaucoma Diagnosis using Fundus Photography**
2407.04396v1 by Qian Zeng, Fan Zhang

Glaucoma is a leading cause of irreversible blindness worldwide. While deep
learning approaches using fundus images have largely improved early diagnosis
of glaucoma, variations in images from different devices and locations (known
as domain shifts) challenge the use of pre-trained models in real-world
settings. To address this, we propose a novel Graph-guided Test-Time Adaptation
(GTTA) framework to generalize glaucoma diagnosis models to unseen test
environments. GTTA integrates the topological information of fundus images into
the model training, enhancing the model's transferability and reducing the risk
of learning spurious correlation. During inference, GTTA introduces a novel
test-time training objective to make the source-trained classifier
progressively adapt to target patterns with reliable class conditional
estimation and consistency regularization. Experiments on cross-domain glaucoma
diagnosis benchmarks demonstrate the superiority of the overall framework and
individual components under different backbone networks.

摘要：青光眼是全球不可逆失明的主要原因。虽然使用眼底图像的深度学习方法已极大改善了青光眼的早期诊断，但来自不同设备和位置的图像差异（称为域偏移）对真实世界设置中预训练模型的使用构成了挑战。为了解决这个问题，我们提出了一个新颖的图引导测试时自适应 (GTTA) 框架，将青光眼诊断模型推广到未见的测试环境。GTTA 将眼底图像的拓扑信息整合到模型训练中，增强了模型的可迁移性并降低了学习虚假相关性的风险。在推理过程中，GTTA 引入了一个新颖的测试时训练目标，使源训练分类器逐步适应目标模式，具有可靠的类条件估计和一致性正则化。跨域青光眼诊断基准的实验表明，整体框架和不同骨干网络下的各个组件都具有优越性。

##### **Multi-Branch Auxiliary Fusion YOLO with Re-parameterization Heterogeneous Convolutional for accurate object detection**
2407.04381v1 by Zhiqiang Yang, Qiu Guan, Keer Zhao, Jianmin Yang, Xinli Xu, Haixia Long, Ying Tang

Due to the effective performance of multi-scale feature fusion, Path
Aggregation FPN (PAFPN) is widely employed in YOLO detectors. However, it
cannot efficiently and adaptively integrate high-level semantic information
with low-level spatial information simultaneously. We propose a new model named
MAF-YOLO in this paper, which is a novel object detection framework with a
versatile neck named Multi-Branch Auxiliary FPN (MAFPN). Within MAFPN, the
Superficial Assisted Fusion (SAF) module is designed to combine the output of
the backbone with the neck, preserving an optimal level of shallow information
to facilitate subsequent learning. Meanwhile, the Advanced Assisted Fusion
(AAF) module deeply embedded within the neck conveys a more diverse range of
gradient information to the output layer.
  Furthermore, our proposed Re-parameterized Heterogeneous Efficient Layer
Aggregation Network (RepHELAN) module ensures that both the overall model
architecture and convolutional design embrace the utilization of heterogeneous
large convolution kernels. Therefore, this guarantees the preservation of
information related to small targets while simultaneously achieving the
multi-scale receptive field. Finally, taking the nano version of MAF-YOLO for
example, it can achieve 42.4% AP on COCO with only 3.76M learnable parameters
and 10.51G FLOPs, and approximately outperforms YOLOv8n by about 5.1%. The
source code of this work is available at:
https://github.com/yang-0201/MAF-YOLO.

摘要：由於多尺度特徵融合的有效執行，路徑聚合 FPN (PAFPN) 被廣泛用於 YOLO 偵測器。然而，它無法同時有效率且自適應地整合高層級語意資訊與低層級空間資訊。我們在本文中提出一個名為 MAF-YOLO 的新模型，它是一個新穎的物件偵測架構，具有名為多分支輔助 FPN (MAFPN) 的通用頸部。在 MAFPN 內，表面輔助融合 (SAF) 模組被設計用於結合骨幹的輸出與頸部，保留最佳程度的淺層資訊以利後續學習。同時，進階輔助融合 (AAF) 模組深嵌於頸部內，傳達更多元範圍的梯度資訊至輸出層。
此外，我們提出的重新參數化異質高效層聚合網路 (RepHELAN) 模組確保整體模型架構與卷積設計都採用異質大卷積核。因此，這保證了與小目標相關資訊的保留，同時達成多尺度感受野。最後，以 MAF-YOLO 的奈米版本為例，它可以在 COCO 上達成 42.4% 的 AP，僅有 3.76M 可學習參數與 10.51G FLOP，並且大致上比 YOLOv8n 優出約 5.1%。這項工作的原始碼可以在以下網址取得：
https://github.com/yang-0201/MAF-YOLO。

##### **Exploiting the equivalence between quantum neural networks and perceptrons**
2407.04371v1 by Chris Mingard, Jessica Pointing, Charles London, Yoonsoo Nam, Ard A. Louis

Quantum machine learning models based on parametrized quantum circuits, also
called quantum neural networks (QNNs), are considered to be among the most
promising candidates for applications on near-term quantum devices. Here we
explore the expressivity and inductive bias of QNNs by exploiting an exact
mapping from QNNs with inputs $x$ to classical perceptrons acting on $x \otimes
x$ (generalised to complex inputs). The simplicity of the perceptron
architecture allows us to provide clear examples of the shortcomings of current
QNN models, and the many barriers they face to becoming useful general-purpose
learning algorithms. For example, a QNN with amplitude encoding cannot express
the Boolean parity function for $n\geq 3$, which is but one of an exponential
number of data structures that such a QNN is unable to express. Mapping a QNN
to a classical perceptron simplifies training, allowing us to systematically
study the inductive biases of other, more expressive embeddings on Boolean
data. Several popular embeddings primarily produce an inductive bias towards
functions with low class balance, reducing their generalisation performance
compared to deep neural network architectures which exhibit much richer
inductive biases. We explore two alternate strategies that move beyond standard
QNNs. In the first, we use a QNN to help generate a classical DNN-inspired
kernel. In the second we draw an analogy to the hierarchical structure of deep
neural networks and construct a layered non-linear QNN that is provably fully
expressive on Boolean data, while also exhibiting a richer inductive bias than
simple QNNs. Finally, we discuss characteristics of the QNN literature that may
obscure how hard it is to achieve quantum advantage over deep learning
algorithms on classical data.

摘要：<paragraph>基於參數化量子電路，也稱為量子神經網路 (QNN) 的量子機器學習模型，被認為是近期量子裝置應用中最有前途的候選者之一。在此，我們透過利用從輸入 $x$ 的 QNN 到作用於 $x \otimes x$ 的經典感知器的精確對應（推廣到複數輸入），來探討 QNN 的表達能力和歸納偏誤。感知器架構的簡潔性使我們能夠提供當前 QNN 模型缺點的明確範例，以及它們成為有用的通用學習演算法所面臨的許多障礙。例如，具有振幅編碼的 QNN 無法表達 $n\geq 3$ 的布林同位函數，而這只是此類 QNN 無法表達的指數級別資料結構之一。將 QNN 對應到經典感知器簡化了訓練，使我們能夠系統性地研究布林資料上其他更具表達力的嵌入的歸納偏誤。幾個廣受歡迎的嵌入主要產生對類別平衡低的功能的歸納偏誤，與表現出更豐富歸納偏誤的深度神經網路架構相比，降低了它們的泛化效能。我們探索了超越標準 QNN 的兩種替代策略。在第一個策略中，我們使用 QNN 來幫助產生經典 DNN 啟發的核。在第二個策略中，我們將類比於深度神經網路的階層結構，並建構一個分層非線性 QNN，它在布林資料上已被證明具有完全的表達能力，同時也表現出比簡單 QNN 更豐富的歸納偏誤。最後，我們討論了 QNN 文獻的特徵，這些特徵可能會模糊在經典資料上實現量子優勢優於深度學習演算法的難度。</paragraph>

##### **Regulating Model Reliance on Non-Robust Features by Smoothing Input Marginal Density**
2407.04370v1 by Peiyu Yang, Naveed Akhtar, Mubarak Shah, Ajmal Mian

Trustworthy machine learning necessitates meticulous regulation of model
reliance on non-robust features. We propose a framework to delineate and
regulate such features by attributing model predictions to the input. Within
our approach, robust feature attributions exhibit a certain consistency, while
non-robust feature attributions are susceptible to fluctuations. This behavior
allows identification of correlation between model reliance on non-robust
features and smoothness of marginal density of the input samples. Hence, we
uniquely regularize the gradients of the marginal density w.r.t. the input
features for robustness. We also devise an efficient implementation of our
regularization to address the potential numerical instability of the underlying
optimization process. Moreover, we analytically reveal that, as opposed to our
marginal density smoothing, the prevalent input gradient regularization
smoothens conditional or joint density of the input, which can cause limited
robustness. Our experiments validate the effectiveness of the proposed method,
providing clear evidence of its capability to address the feature leakage
problem and mitigate spurious correlations. Extensive results further establish
that our technique enables the model to exhibit robustness against
perturbations in pixel values, input gradients, and density.

摘要：值得信賴的機器學習需要對模型依賴於非穩健特徵進行細緻的規範。我們提出一個框架，通過將模型預測歸因於輸入，來描述和規範此類特徵。在我們的做法中，穩健的特徵歸因表現出一定的穩定性，而非穩健的特徵歸因則容易發生波動。這種行為允許識別模型對非穩健特徵的依賴性與輸入樣本邊際密度的平滑度之間的相關性。因此，我們對輸入特徵相對於邊際密度的梯度進行獨特規範化，以增強穩健性。我們還設計了一個有效的規範化實現，以解決底層優化過程的潛在數值不穩定性。此外，我們分析揭示，與我們的邊際密度平滑相反，流行的輸入梯度規範化平滑了輸入的條件或聯合密度，這可能會導致有限的穩健性。我們的實驗驗證了所提出方法的有效性，提供了其解決特徵洩漏問題和減輕虛假相關性的能力的明確證據。廣泛的結果進一步確立了我們的技術使模型能夠表現出對像素值、輸入梯度和密度的擾動的穩健性。

##### **Romanization Encoding For Multilingual ASR**
2407.04368v1 by Wen Ding, Fei Jia, Hainan Xu, Yu Xi, Junjie Lai, Boris Ginsburg

We introduce romanization encoding for script-heavy languages to optimize
multilingual and code-switching Automatic Speech Recognition (ASR) systems. By
adopting romanization encoding alongside a balanced concatenated tokenizer
within a FastConformer-RNNT framework equipped with a Roman2Char module, we
significantly reduce vocabulary and output dimensions, enabling larger training
batches and reduced memory consumption. Our method decouples acoustic modeling
and language modeling, enhancing the flexibility and adaptability of the
system. In our study, applying this method to Mandarin-English ASR resulted in
a remarkable 63.51% vocabulary reduction and notable performance gains of
13.72% and 15.03% on SEAME code-switching benchmarks. Ablation studies on
Mandarin-Korean and Mandarin-Japanese highlight our method's strong capability
to address the complexities of other script-heavy languages, paving the way for
more versatile and effective multilingual ASR systems.

摘要：我們為文字繁重的語言引入羅馬化編碼，以最佳化多語言和語碼轉換自動語音辨識 (ASR) 系統。藉由在配備 Roman2Char 模組的 FastConformer-RNNT 架構中採用羅馬化編碼和平衡串接分詞器，我們大幅減少詞彙和輸出維度，能進行較大規模的訓練批次，並減少記憶體消耗。我們的做法將聲學模型和語言模型分開，提升系統的彈性和適應力。在我們的研究中，將此方法應用於國語-英語 ASR，結果詞彙減少了 63.51%，在 SEAME 語碼轉換基準上獲得了 13.72% 和 15.03% 的顯著效能提升。國語-韓語和國語-日語的消融研究突顯了我們的方法在處理其他文字繁重語言的複雜性方面具有強大的能力，為更多元且有效的多語言 ASR 系統鋪路。

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

摘要：生成式 AI 的進步擴展了大型語言模型 (LLM) 在自主代理開發中的潛在應用。實現真正的自主性需要累積和更新從與環境互動中獲得的知識，並有效利用它。當前的基於 LLM 的方法利用過去的經驗，使用完整的觀察、摘要或檢索擴充。然而，這些非結構化的記憶表徵並不能促進複雜決策制定中必不可少的推理和規劃。在我們的研究中，我們介紹了 AriGraph，這是一種新方法，其中代理構建了一個記憶圖，該圖在探索環境時整合了語義和情節記憶。這種圖形結構促進了相互聯繫的概念的有效關聯性檢索，與代理的當前狀態和目標相關，從而作為一個有效的環境模型，增強了代理的探索和規劃能力。我們展示了我們的 Ariadne LLM 代理，配備了這種提議的記憶架構，並增強了規劃和決策制定，有效地處理了 TextWorld 環境中零次學習的複雜任務。我們的做法顯著優於已建立的方法，例如完整歷史、摘要和檢索增強生成，在各種任務中，包括來自第一個 TextWorld 問題競賽的烹飪挑戰和房屋清潔和拼圖尋寶等新任務。

##### **Dance of the ADS: Orchestrating Failures through Historically-Informed Scenario Fuzzing**
2407.04359v1 by Tong Wang, Taotao Gu, Huan Deng, Hu Li, Xiaohui Kuang, Gang Zhao

As autonomous driving systems (ADS) advance towards higher levels of
autonomy, orchestrating their safety verification becomes increasingly
intricate. This paper unveils ScenarioFuzz, a pioneering scenario-based fuzz
testing methodology. Designed like a choreographer who understands the past
performances, it uncovers vulnerabilities in ADS without the crutch of
predefined scenarios. Leveraging map road networks, such as OPENDRIVE, we
extract essential data to form a foundational scenario seed corpus. This
corpus, enriched with pertinent information, provides the necessary boundaries
for fuzz testing in the absence of starting scenarios. Our approach integrates
specialized mutators and mutation techniques, combined with a graph neural
network model, to predict and filter out high-risk scenario seeds, optimizing
the fuzzing process using historical test data. Compared to other methods, our
approach reduces the time cost by an average of 60.3%, while the number of
error scenarios discovered per unit of time increases by 103%. Furthermore, we
propose a self-supervised collision trajectory clustering method, which aids in
identifying and summarizing 54 high-risk scenario categories prone to inducing
ADS faults. Our experiments have successfully uncovered 58 bugs across six
tested systems, emphasizing the critical safety concerns of ADS.

摘要：隨著自動駕駛系統（ADS）朝著更高層級的自動化邁進，協調其安全驗證變得越來越複雜。本文揭示了 ScenarioFuzz，這是一種開創性的基於情境的模糊測試方法。它像一位了解過去表演的編舞家一樣設計，在沒有預定義情境的情況下揭露 ADS 中的漏洞。利用地圖道路網路，例如 OPENDRIVE，我們提取必要的資料以形成基礎情境種子語料庫。這個語料庫經過相關資訊的豐富化，在沒有起始情境的情況下提供了模糊測試所需的界限。我們的做法整合了專用變異器和變異技術，結合圖神經網路模型，以預測和過濾出高風險情境種子，使用歷史測試資料最佳化模糊化程序。與其他方法相比，我們的做法平均減少了 60.3% 的時間成本，同時每單位時間發現的錯誤情境數量增加了 103%。此外，我們提出了一種自我監督的碰撞軌跡聚類方法，有助於識別和總結 54 個容易導致 ADS 故障的高風險情境類別。我們的實驗已成功發現六個測試系統中的 58 個錯誤，突顯了 ADS 的關鍵安全問題。

##### **AI-Based Beam-Level and Cell-Level Mobility Management for High Speed Railway Communications**
2407.04336v1 by Wen Li, Wei Chen, Shiyue Wang, Yuanyuan Zhang, Michail Matthaiou, Bo Ai

High-speed railway (HSR) communications are pivotal for ensuring rail safety,
operations, maintenance, and delivering passenger information services. The
high speed of trains creates rapidly time-varying wireless channels, increases
the signaling overhead, and reduces the system throughput, making it difficult
to meet the growing and stringent needs of HSR applications. In this article,
we explore artificial intelligence (AI)-based beam-level and cell-level
mobility management suitable for HSR communications, including the use cases,
inputs, outputs, and key performance indicators (KPI)s of AI models.
Particularly, in comparison to traditional down-sampling spatial beam
measurements, we show that the compressed spatial multi-beam measurements via
compressive sensing lead to improved spatial-temporal beam prediction.
Moreover, we demonstrate the performance gains of AI-assisted cell handover
over traditional mobile handover mechanisms. In addition, we observe that the
proposed approaches to reduce the measurement overhead achieve comparable radio
link failure performance with the traditional approach that requires all the
beam measurements of all cells, while the former methods can save 50% beam
measurement overhead.

摘要：高速鐵路（HSR）通訊對於確保鐵路安全、營運、維護和提供乘客資訊服務至關重要。火車的高速會造成快速變動的無線通道，增加信號傳輸開銷，並降低系統吞吐量，這使得難以滿足高速鐵路應用日益增長且嚴格的需求。在本文中，我們探討適用於高速鐵路通訊的人工智慧（AI）為基礎的波束級別和單元級別行動管理，包括 AI 模型的使用案例、輸入、輸出和關鍵績效指標（KPI）。特別是，與傳統的下採樣空間波束測量相比，我們說明透過壓縮感測進行壓縮的空間多波束測量會改善空間時間波束預測。此外，我們展示了 AI 輔助單元交接在傳統行動交接機制上獲得的效能提升。此外，我們觀察到，所提出的方法可減少測量開銷，並獲得與傳統方法相當的無線連結故障效能，而傳統方法需要所有單元的全部波束測量，而前述方法可以節省 50% 的波束測量開銷。

##### **Geometrically Inspired Kernel Machines for Collaborative Learning Beyond Gradient Descent**
2407.04335v1 by Mohit Kumar, Alexander Valentinitsch, Magdalena Fuchs, Mathias Brucker, Juliana Bowles, Adnan Husakovic, Ali Abbas, Bernhard A. Moser

This paper develops a novel mathematical framework for collaborative learning
by means of geometrically inspired kernel machines which includes statements on
the bounds of generalisation and approximation errors, and sample complexity.
For classification problems, this approach allows us to learn bounded geometric
structures around given data points and hence solve the global model learning
problem in an efficient way by exploiting convexity properties of the related
optimisation problem in a Reproducing Kernel Hilbert Space (RKHS). In this way,
we can reduce classification problems to determining the closest bounded
geometric structure from a given data point. Further advantages that come with
our solution is that our approach does not require clients to perform multiple
epochs of local optimisation using stochastic gradient descent, nor require
rounds of communication between client/server for optimising the global model.
We highlight that numerous experiments have shown that the proposed method is a
competitive alternative to the state-of-the-art.

摘要：本文開發了一種新的數學框架，用於透過幾何啟發的核機器進行協作學習，其中包含概化和近似誤差的界限以及範例複雜度的陳述。對於分類問題，此方法允許我們學習給定資料點周圍的受限幾何結構，並因此利用相關最佳化問題在再生核希爾伯特空間 (RKHS) 中的凸性屬性來以有效的方式解決全球模型學習問題。這樣一來，我們可以將分類問題簡化為從給定資料點中確定最接近的受限幾何結構。我們的解決方案具有的其他優點是，我們的方法不需要用戶使用隨機梯度下降法執行多個時期的局部最佳化，也不需要用戶與伺服器之間進行多輪通訊來最佳化全球模型。我們強調，大量實驗顯示，所提出的方法是現有技術的競爭替代方案。

##### **MuseBarControl: Enhancing Fine-Grained Control in Symbolic Music Generation through Pre-Training and Counterfactual Loss**
2407.04331v1 by Yangyang Shu, Haiming Xu, Ziqin Zhou, Anton van den Hengel, Lingqiao Liu

Automatically generating symbolic music-music scores tailored to specific
human needs-can be highly beneficial for musicians and enthusiasts. Recent
studies have shown promising results using extensive datasets and advanced
transformer architectures. However, these state-of-the-art models generally
offer only basic control over aspects like tempo and style for the entire
composition, lacking the ability to manage finer details, such as control at
the level of individual bars. While fine-tuning a pre-trained symbolic music
generation model might seem like a straightforward method for achieving this
finer control, our research indicates challenges in this approach. The model
often fails to respond adequately to new, fine-grained bar-level control
signals. To address this, we propose two innovative solutions. First, we
introduce a pre-training task designed to link control signals directly with
corresponding musical tokens, which helps in achieving a more effective
initialization for subsequent fine-tuning. Second, we implement a novel
counterfactual loss that promotes better alignment between the generated music
and the control prompts. Together, these techniques significantly enhance our
ability to control music generation at the bar level, showing a 13.06\%
improvement over conventional methods. Our subjective evaluations also confirm
that this enhanced control does not compromise the musical quality of the
original pre-trained generative model.

摘要：自動生成針對特定人類需求量身打造的符號音樂樂譜，對於音樂家和愛好者而言可能非常有益。最近的研究表明，使用廣泛的數據集和先進的Transformer架構顯示出有希望的結果。然而，這些最先進的模型通常只對整個樂曲的節奏和風格等方面提供基本的控制，缺乏管理更精細細節的能力，例如在個別小節層級的控制。雖然微調預先訓練好的符號音樂生成模型似乎是實現這種更精細控制的直接方法，但我們的研究表明這種方法存在挑戰。該模型通常無法對新的、細緻的小節層級控制信號做出充分的響應。為了解決這個問題，我們提出了兩個創新的解決方案。首先，我們引入一個預先訓練任務，旨在將控制信號直接與對應的音樂符號聯繫起來，這有助於為後續微調實現更有效的初始化。其次，我們實作了一個新穎的反事實損失，以促進生成的音樂與控制提示之間更好的對齊。這些技術共同顯著增強了我們在小節層級控制音樂生成的能力，比傳統方法提高了 13.06%。我們的主觀評估也證實，這種增強的控制不會損害原始預先訓練生成模型的音樂品質。

##### **Knowledge-based Drug Samples' Comparison**
2407.04317v1 by Sébastien Guillemin, Ana Roxin, Laurence Dujourdy, Ludovic Journaux

Drug sample comparison is a process used by the French National police to
identify drug distribution networks. The current approach is based on manual
comparison done by forensic experts. In this article, we present our approach
to acquire, formalise, and specify expert knowledge to improve the current
process. For modelling the underlying knowledge we use an ontology coupled with
logical rules. The different steps of our approach are designed to be reused in
other application domains. The results obtained are explainable making them
usable by experts in different fields.

摘要：藥物樣品比對是法國國家警察用來識別藥物分銷網路的程序。目前的做法是基於法醫專家進行手動比對。在本文中，我們提出我們取得、形式化和具體化專家知識的方法，以改善目前的程序。為了建模基礎知識，我們使用結合邏輯規則的本體論。我們方法的不同步驟被設計為可在其他應用程式領域中重複使用。所獲得的結果具有可解釋性，使不同領域的專家能夠使用。

##### **Crafting Large Language Models for Enhanced Interpretability**
2407.04307v1 by Chung-En Sun, Tuomas Oikarinen, Tsui-Wei Weng

We introduce the Concept Bottleneck Large Language Model (CB-LLM), a
pioneering approach to creating inherently interpretable Large Language Models
(LLMs). Unlike traditional black-box LLMs that rely on post-hoc interpretation
methods with limited neuron function insights, CB-LLM sets a new standard with
its built-in interpretability, scalability, and ability to provide clear,
accurate explanations. This innovation not only advances transparency in
language models but also enhances their effectiveness. Our unique Automatic
Concept Correction (ACC) strategy successfully narrows the performance gap with
conventional black-box LLMs, positioning CB-LLM as a model that combines the
high accuracy of traditional LLMs with the added benefit of clear
interpretability -- a feature markedly absent in existing LLMs.

摘要：我們介紹概念瓶頸大型語言模型 (CB-LLM)，一種創新的方法，用於建立本質上可解釋的大型語言模型 (LLM)。與依賴於事後解釋方法（神經元功能見解有限）的傳統黑盒 LLM 不同，CB-LLM 以其內建的可解釋性、可擴充性和提供清晰、準確解釋的能力，樹立了新的標準。這項創新不僅提升了語言模型的透明度，也增強了它們的有效性。我們獨特的自動概念校正 (ACC) 策略成功地縮小了與傳統黑盒 LLM 的效能差距，將 CB-LLM 定位為一個結合傳統 LLM 高準確度和清晰可解釋性附加優勢的模型，而這項功能在現有的 LLM 中顯著缺失。

##### **Jailbreak Attacks and Defenses Against Large Language Models: A Survey**
2407.04295v1 by Sibo Yi, Yule Liu, Zhen Sun, Tianshuo Cong, Xinlei He, Jiaxing Song, Ke Xu, Qi Li

Large Language Models (LLMs) have performed exceptionally in various
text-generative tasks, including question answering, translation, code
completion, etc. However, the over-assistance of LLMs has raised the challenge
of "jailbreaking", which induces the model to generate malicious responses
against the usage policy and society by designing adversarial prompts. With the
emergence of jailbreak attack methods exploiting different vulnerabilities in
LLMs, the corresponding safety alignment measures are also evolving. In this
paper, we propose a comprehensive and detailed taxonomy of jailbreak attack and
defense methods. For instance, the attack methods are divided into black-box
and white-box attacks based on the transparency of the target model. Meanwhile,
we classify defense methods into prompt-level and model-level defenses.
Additionally, we further subdivide these attack and defense methods into
distinct sub-classes and present a coherent diagram illustrating their
relationships. We also conduct an investigation into the current evaluation
methods and compare them from different perspectives. Our findings aim to
inspire future research and practical implementations in safeguarding LLMs
against adversarial attacks. Above all, although jailbreak remains a
significant concern within the community, we believe that our work enhances the
understanding of this domain and provides a foundation for developing more
secure LLMs.

摘要：大型語言模型 (LLM) 在各種文字生成任務中表現得非常好，包括問答、翻譯、程式碼補全等。然而，LLM 的過度協助引起了「越獄」的挑戰，這會誘使模型透過設計對抗性提示來針對使用政策和社會產生惡意的回應。隨著利用 LLM 中不同漏洞的越獄攻擊方法的出現，相應的安全比對措施也在不斷發展。在本文中，我們提出了越獄攻擊和防禦方法的全面且詳細分類。例如，攻擊方法根據目標模型的透明度分為黑盒攻擊和白盒攻擊。同時，我們將防禦方法分類為提示級別防禦和模型級別防禦。此外，我們進一步將這些攻擊和防禦方法細分為不同的子類別，並展示了一個說明其關係的連貫圖表。我們還對當前的評估方法進行了調查，並從不同的角度對它們進行了比較。我們的研究結果旨在激勵未來的研究和實務實作，以保護 LLM 免受對抗性攻擊。最重要的是，儘管越獄仍然是社群中的重大問題，但我們相信我們的研究增強了對這個領域的理解，並為開發更安全的 LLM 提供了基礎。

##### **Systematic Evaluation of Online Speaker Diarization Systems Regarding their Latency**
2407.04293v1 by Roman Aperdannier, Sigurd Schacht, Alexander Piazza

In this paper, different online speaker diarization systems are evaluated on
the same hardware with the same test data with regard to their latency. The
latency is the time span from audio input to the output of the corresponding
speaker label. As part of the evaluation, various model combinations within the
DIART framework, a diarization system based on the online clustering algorithm
UIS-RNN-SML, and the end-to-end online diarization system FS-EEND are compared.
The lowest latency is achieved for the DIART-pipeline with the embedding model
pyannote/embedding and the segmentation model pyannote/segmentation. The
FS-EEND system shows a similarly good latency. In general there is currently no
published research that compares several online diarization systems in terms of
their latency. This makes this work even more relevant.

摘要：在本文中，在延遲方面，使用相同的硬體和相同的測試資料評估不同的線上說話者日記化系統。延遲是指從音訊輸入到對應說話者標籤輸出的時間範圍。作為評估的一部分，比較了線上聚類演算法 UIS-RNN-SML 為基礎的日記化系統 DIART 框架內的各種模型組合，以及端對端的線上日記化系統 FS-EEND。延遲最低的是採用嵌入模型 pyannote/embedding 和分段模型 pyannote/segmentation 的 DIART-pipeline。FS-EEND 系統展現出類似良好的延遲。一般來說，目前沒有已發表的針對延遲比較多個線上日記化系統的研究。這使得這項工作更具相關性。

##### **MARS: Paying more attention to visual attributes for text-based person search**
2407.04287v1 by Alex Ergasti, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati

Text-based person search (TBPS) is a problem that gained significant interest
within the research community. The task is that of retrieving one or more
images of a specific individual based on a textual description. The multi-modal
nature of the task requires learning representations that bridge text and image
data within a shared latent space. Existing TBPS systems face two major
challenges. One is defined as inter-identity noise that is due to the inherent
vagueness and imprecision of text descriptions and it indicates how
descriptions of visual attributes can be generally associated to different
people; the other is the intra-identity variations, which are all those
nuisances e.g. pose, illumination, that can alter the visual appearance of the
same textual attributes for a given subject. To address these issues, this
paper presents a novel TBPS architecture named MARS
(Mae-Attribute-Relation-Sensitive), which enhances current state-of-the-art
models by introducing two key components: a Visual Reconstruction Loss and an
Attribute Loss. The former employs a Masked AutoEncoder trained to reconstruct
randomly masked image patches with the aid of the textual description. In doing
so the model is encouraged to learn more expressive representations and
textual-visual relations in the latent space. The Attribute Loss, instead,
balances the contribution of different types of attributes, defined as
adjective-noun chunks of text. This loss ensures that every attribute is taken
into consideration in the person retrieval process. Extensive experiments on
three commonly used datasets, namely CUHK-PEDES, ICFG-PEDES, and RSTPReid,
report performance improvements, with significant gains in the mean Average
Precision (mAP) metric w.r.t. the current state of the art.

摘要：<paragraph>基於文字的人員搜尋 (TBPS) 是在研究社群中獲得顯著關注的問題。這項任務是根據文字描述，擷取一位或多位特定個人的影像。多模態任務的性質需要學習表徵，以在共享的潛在空間中橋接文字和影像資料。現有的 TBPS 系統面臨兩項主要的挑戰。其一是定義為「身分間雜訊」，這是由於文字描述的本質模糊且不精確，且它指出視覺屬性的描述通常可以與不同的人關聯；另一個是「身分內變異」，也就是所有那些例如姿勢、光線等會改變給定主體相同文字屬性的視覺外觀的討厭因素。為了解決這些問題，本文提出名為 MARS (Mae-Attribute-Relation-Sensitive) 的新穎 TBPS 架構，透過引入兩個關鍵元件來增強目前最先進的模型：視覺重建損失和屬性損失。前者使用遮罩式自動編碼器，在文字描述的輔助下訓練以重建隨機遮罩的影像區塊。在這樣做的過程中，會鼓勵模型學習潛在空間中更具表現力的表徵和文字視覺關係。另一方面，屬性損失則平衡不同類型屬性的貢獻，定義為文字的形容詞名詞區塊。此損失確保在人員擷取過程中考量每個屬性。在三個常用資料集 (CUHK-PEDES、ICFG-PEDES 和 RSTPReid) 上進行的廣泛實驗報告了效能提升，平均準確度 (mAP) 指標相較於目前的最新技術有顯著的進步。</paragraph>

##### **Robust Decision Transformer: Tackling Data Corruption in Offline RL via Sequence Modeling**
2407.04285v1 by Jiawei Xu, Rui Yang, Feng Luo, Meng Fang, Baoxiang Wang, Lei Han

Learning policies from offline datasets through offline reinforcement
learning (RL) holds promise for scaling data-driven decision-making and
avoiding unsafe and costly online interactions. However, real-world data
collected from sensors or humans often contains noise and errors, posing a
significant challenge for existing offline RL methods. Our study indicates that
traditional offline RL methods based on temporal difference learning tend to
underperform Decision Transformer (DT) under data corruption, especially when
the amount of data is limited. This suggests the potential of sequential
modeling for tackling data corruption in offline RL. To further unleash the
potential of sequence modeling methods, we propose Robust Decision Transformer
(RDT) by incorporating several robust techniques. Specifically, we introduce
Gaussian weighted learning and iterative data correction to reduce the effect
of corrupted data. Additionally, we leverage embedding dropout to enhance the
model's resistance to erroneous inputs. Extensive experiments on MoJoCo,
KitChen, and Adroit tasks demonstrate RDT's superior performance under diverse
data corruption compared to previous methods. Moreover, RDT exhibits remarkable
robustness in a challenging setting that combines training-time data corruption
with testing-time observation perturbations. These results highlight the
potential of robust sequence modeling for learning from noisy or corrupted
offline datasets, thereby promoting the reliable application of offline RL in
real-world tasks.

摘要：透過離線強化學習 (RL) 從離線資料集學習政策，有望擴展資料驅動的決策制定，並避免不安全且代價高昂的線上互動。然而，從感測器或人類收集的真實世界資料通常包含雜訊和錯誤，對現有的離線 RL 方法構成重大挑戰。我們的研究指出，基於時間差分學習的傳統離線 RL 方法在資料損毀時往往表現不佳，特別是在資料量有限的情況下。這表明序列建模在應對離線 RL 中的資料損毀方面具有潛力。為了進一步發揮序列建模方法的潛力，我們透過整合多種強健技術提出強健決策轉換器 (RDT)。具體來說，我們引入了高斯加權學習和反覆資料校正，以減少損毀資料的影響。此外，我們利用嵌入式中斷來增強模型對錯誤輸入的抵抗力。在 MoJoCo、KitChen 和 Adroit 任務上的廣泛實驗證明，與先前的相比，RDT 在不同的資料損毀下表現出優異的性能。此外，RDT 在結合訓練時間資料損毀和測試時間觀測擾動的具有挑戰性的設定中表現出顯著的強健性。這些結果突顯了強健序列建模在從有雜訊或損毀的離線資料集中學習的潛力，從而促進離線 RL 在真實世界任務中的可靠應用。

##### **LearnerVoice: A Dataset of Non-Native English Learners' Spontaneous Speech**
2407.04280v1 by Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang, Juho Kim

Prevalent ungrammatical expressions and disfluencies in spontaneous speech
from second language (L2) learners pose unique challenges to Automatic Speech
Recognition (ASR) systems. However, few datasets are tailored to L2 learner
speech. We publicly release LearnerVoice, a dataset consisting of 50.04 hours
of audio and transcriptions of L2 learners' spontaneous speech. Our linguistic
analysis reveals that transcriptions in our dataset contain L2S (L2 learner's
Spontaneous speech) features, consisting of ungrammatical expressions and
disfluencies (e.g., filler words, word repetitions, self-repairs, false
starts), significantly more than native speech datasets. Fine-tuning
whisper-small.en with LearnerVoice achieves a WER of 10.26%, 44.2% lower than
vanilla whisper-small.en. Furthermore, our qualitative analysis indicates that
54.2% of errors from the vanilla model on LearnerVoice are attributable to L2S
features, with 48.1% of them being reduced in the fine-tuned model.

摘要：在第二语言 (L2) 学习者的自发性言语中普遍存在的语法错误和不流畅性，对自动语音识别 (ASR) 系统提出了独特的挑战。然而，很少有数据集专门针对 L2 学习者的语音。我们公开发布 LearnerVoice，这是一个包含 50.04 小时音频和 L2 学习者自发性语音转录的数据集。我们的语言分析显示，我们数据集中的转录包含 L2S（L2 学习者的自发性语音）特征，包括语法错误和不流畅性（例如填词、重复词、自我修复、错误开始），明显多于母语语音数据集。使用 LearnerVoice 对 whisper-small.en 进行微调，WER 达到 10.26%，比原始 whisper-small.en 低 44.2%。此外，我们的定性分析表明，原始模型在 LearnerVoice 上的 54.2% 错误可归因于 L2S 特征，其中 48.1% 在微调模型中得到减少。

##### **BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks**
2407.04279v1 by Jieying Xue, Minh Phuong Nguyen, Blake Matheny, Le Minh Nguyen

In the Emotion Recognition in Conversation task, recent investigations have
utilized attention mechanisms exploring relationships among utterances from
intra- and inter-speakers for modeling emotional interaction between them.
However, attributes such as speaker personality traits remain unexplored and
present challenges in terms of their applicability to other tasks or
compatibility with diverse model architectures. Therefore, this work introduces
a novel framework named BiosERC, which investigates speaker characteristics in
a conversation. By employing Large Language Models (LLMs), we extract the
"biographical information" of the speaker within a conversation as
supplementary knowledge injected into the model to classify emotional labels
for each utterance. Our proposed method achieved state-of-the-art (SOTA)
results on three famous benchmark datasets: IEMOCAP, MELD, and EmoryNLP,
demonstrating the effectiveness and generalization of our model and showcasing
its potential for adaptation to various conversation analysis tasks. Our source
code is available at https://github.com/yingjie7/BiosERC.

摘要：在對話中的情緒辨識任務中，最近的研究利用注意機制探討對話者和對話者之間的發言關係，以建構他們之間的情緒互動模型。然而，諸如說話者人格特質等屬性仍未被探討，且在它們適用於其他任務或與各種模型架構相容性方面存在挑戰。因此，本研究提出一個名為 BiosERC 的新架構，探討對話中的說話者特徵。透過採用大型語言模型 (LLM)，我們擷取對話中說話者的「傳記資訊」作為補充知識，注入模型中，以對每個發言的情緒標籤進行分類。我們提出的方法在三個著名的基準資料集：IEMOCAP、MELD 和 EmoryNLP 上取得最先進 (SOTA) 的結果，證明了我們模型的有效性和概括性，並展示了它在適應各種對話分析任務方面的潛力。我們的原始碼可以在 https://github.com/yingjie7/BiosERC 取得。

##### **Variational Partial Group Convolutions for Input-Aware Partial Equivariance of Rotations and Color-Shifts**
2407.04271v1 by Hyunsu Kim, Yegon Kim, Hongseok Yang, Juho Lee

Group Equivariant CNNs (G-CNNs) have shown promising efficacy in various
tasks, owing to their ability to capture hierarchical features in an
equivariant manner. However, their equivariance is fixed to the symmetry of the
whole group, limiting adaptability to diverse partial symmetries in real-world
datasets, such as limited rotation symmetry of handwritten digit images and
limited color-shift symmetry of flower images. Recent efforts address this
limitation, one example being Partial G-CNN which restricts the output group
space of convolution layers to break full equivariance. However, such an
approach still fails to adjust equivariance levels across data. In this paper,
we propose a novel approach, Variational Partial G-CNN (VP G-CNN), to capture
varying levels of partial equivariance specific to each data instance. VP G-CNN
redesigns the distribution of the output group elements to be conditioned on
input data, leveraging variational inference to avoid overfitting. This enables
the model to adjust its equivariance levels according to the needs of
individual data points. Additionally, we address training instability inherent
in discrete group equivariance models by redesigning the reparametrizable
distribution. We demonstrate the effectiveness of VP G-CNN on both toy and
real-world datasets, including MNIST67-180, CIFAR10, ColorMNIST, and
Flowers102. Our results show robust performance, even in uncertainty metrics.

摘要：群等變式 CNN (G-CNN) 在各種任務中展現出有希望的功效，因為它們能夠以等變式的方式擷取階層特徵。然而，它們的等變式固定在整個群的對稱性上，限制了適應真實世界資料集中多樣化的部分對稱性，例如手寫數字影像的有限旋轉對稱性，以及花朵影像的有限色彩變換對稱性。最近的研究解決了這個限制，一個範例是 Partial G-CNN，它限制了卷積層的輸出群空間以打破完全等變式。然而，這種方法仍然無法調整資料中的等變式層級。在本文中，我們提出了一種新方法，變分 Partial G-CNN (VP G-CNN)，以擷取特定於每個資料實例的不同程度的部分等變式。VP G-CNN 重新設計了輸出群元素的分配，以輸入資料為條件，並利用變分推論來避免過度擬合。這使模型能夠根據個別資料點的需求調整其等變式層級。此外，我們透過重新設計可重新參數化的分配，來解決離散群等變式模型中固有的訓練不穩定性。我們在玩具和真實世界資料集上展示了 VP G-CNN 的有效性，包括 MNIST67-180、CIFAR10、ColorMNIST 和 Flowers102。我們的結果顯示出穩健的效能，即使在不確定性指標中也是如此。

##### **NeuFair: Neural Network Fairness Repair with Dropout**
2407.04268v1 by Vishnu Asutosh Dasu, Ashish Kumar, Saeid Tizpaz-Niari, Gang Tan

This paper investigates the neural dropout method as a post-processing bias
mitigation for deep neural networks (DNNs). Neural-driven software solutions
are increasingly applied in socially critical domains with significant fairness
implications. While neural networks are exceptionally good at finding
statistical patterns from data, they are notorious for overfitting to the
training datasets that may encode and amplify existing biases from the
historical data. Existing bias mitigation algorithms often require either
modifying the input dataset or modifying the learning algorithms. We posit that
the prevalent dropout methods that prevent over-fitting during training by
randomly dropping neurons may be an effective and less intrusive approach to
improve fairness of pre-trained DNNs. However, finding the ideal set of neurons
to drop is a combinatorial problem. We propose NeuFair, a family of
post-processing randomized algorithms that mitigate unfairness in pre-trained
DNNs. Our randomized search is guided by an objective to minimize
discrimination while maintaining the model utility. We show that our design of
randomized algorithms provides statistical guarantees on finding optimal
solutions, and we empirically evaluate the efficacy and efficiency of NeuFair
in improving fairness, with minimal or no performance degradation. Our results
show that NeuFair improves fairness by up to 69% and outperforms
state-of-the-art post-processing bias techniques.

摘要：這篇論文探討神經網路中斷法作為深度神經網路 (DNN) 的後處理偏誤緩解。神經驅動軟體解決方案日益用於具有重大公平性影響的社會關鍵領域。儘管神經網路非常擅長從資料中找出統計模式，但它們以過度擬合編碼並放大歷史資料中既有偏誤的訓練資料集而臭名昭著。現有的偏誤緩解演算法通常需要修改輸入資料集或修改學習演算法。我們假設流行的中斷法在訓練期間透過隨機中斷神經元來防止過度擬合，可能是一種有效且較不具侵入性的方法，可以改善預訓練 DNN 的公平性。然而，找出中斷的理想神經元組是一個組合問題。我們提出 NeuFair，一個後處理隨機演算法家族，可以緩解預訓練 DNN 中的不公平性。我們的隨機搜尋由一個目標引導，旨在最小化歧視，同時維持模型效用。我們證明我們的隨機演算法設計提供了找到最佳解的統計保證，並且我們實證評估了 NeuFair 在改善公平性方面的效能和效率，幾乎沒有或沒有效能下降。我們的結果顯示，NeuFair 將公平性提升了 69%，並且優於最先進的後處理偏誤技術。

##### **Unsupervised Video Summarization via Reinforcement Learning and a Trained Evaluator**
2407.04258v1 by Mehryar Abbasi, Hadi Hadizadeh, Parvaneh Saeedi

This paper presents a novel approach for unsupervised video summarization
using reinforcement learning. It aims to address the existing limitations of
current unsupervised methods, including unstable training of adversarial
generator-discriminator architectures and reliance on hand-crafted reward
functions for quality evaluation. The proposed method is based on the concept
that a concise and informative summary should result in a reconstructed video
that closely resembles the original. The summarizer model assigns an importance
score to each frame and generates a video summary. In the proposed scheme,
reinforcement learning, coupled with a unique reward generation pipeline, is
employed to train the summarizer model. The reward generation pipeline trains
the summarizer to create summaries that lead to improved reconstructions. It
comprises a generator model capable of reconstructing masked frames from a
partially masked video, along with a reward mechanism that compares the
reconstructed video from the summary against the original. The video generator
is trained in a self-supervised manner to reconstruct randomly masked frames,
enhancing its ability to generate accurate summaries. This training pipeline
results in a summarizer model that better mimics human-generated video
summaries compared to methods relying on hand-crafted rewards. The training
process consists of two stable and isolated training steps, unlike adversarial
architectures. Experimental results demonstrate promising performance, with
F-scores of 62.3 and 54.5 on TVSum and SumMe datasets, respectively.
Additionally, the inference stage is 300 times faster than our previously
reported state-of-the-art method.

摘要：<paragraph>本文提出了一個使用強化學習進行無監督影片摘要的新方法。它旨在解決現有無監督方法的限制，包括對抗生成器 - 判別器架構的不穩定訓練和依賴人工獎勵函數進行品質評估。所提出的方法基於這樣一個概念：簡潔且內容豐富的摘要應產生與原始影片非常相似的重建影片。摘要模型為每個畫面指定一個重要性分數並生成影片摘要。在所提出的方案中，強化學習與獨特的獎勵產生管道相結合，用於訓練摘要模型。獎勵產生管道訓練摘要模型以建立摘要，從而改善重建。它包含一個生成器模型，能夠從部分遮罩的影片中重建遮罩畫面，以及一個獎勵機制，用於比較摘要的重建影片與原始影片。影片生成器以自監督的方式進行訓練，以重建隨機遮罩的畫面，增強其生成準確摘要的能力。與依賴人工獎勵的方法相比，此訓練管道產生了一個摘要模型，可以更好地模擬人為生成的影片摘要。與對抗架構不同，訓練過程包含兩個穩定且孤立的訓練步驟。實驗結果證明了有希望的效能，在 TVSum 和 SumMe 資料集上的 F 分數分別為 62.3 和 54.5。此外，推論階段比我們先前報導的最新方法快 300 倍。</paragraph>

##### **ArAIEval Shared Task: Propagandistic Techniques Detection in Unimodal and Multimodal Arabic Content**
2407.04247v1 by Maram Hasanain, Md. Arid Hasan, Fatema Ahmed, Reem Suwaileh, Md. Rafiul Biswas, Wajdi Zaghouani, Firoj Alam

We present an overview of the second edition of the ArAIEval shared task,
organized as part of the ArabicNLP 2024 conference co-located with ACL 2024. In
this edition, ArAIEval offers two tasks: (i) detection of propagandistic
textual spans with persuasion techniques identification in tweets and news
articles, and (ii) distinguishing between propagandistic and non-propagandistic
memes. A total of 14 teams participated in the final evaluation phase, with 6
and 9 teams participating in Tasks 1 and 2, respectively. Finally, 11 teams
submitted system description papers. Across both tasks, we observed that
fine-tuning transformer models such as AraBERT was at the core of the majority
of the participating systems. We provide a description of the task setup,
including a description of the dataset construction and the evaluation setup.
We further provide a brief overview of the participating systems. All datasets
and evaluation scripts are released to the research community
(https://araieval.gitlab.io/). We hope this will enable further research on
these important tasks in Arabic.

摘要：我們提供 ArAIEval 共享任務第二版的概觀，
作為 ArabicNLP 2024 會議的一部分，與 ACL 2024 共同舉辦。在
此版本中，ArAIEval 提供兩個任務：(i) 偵測宣傳性
文字跨距，並在推文和新聞中識別說服技巧
文章，以及 (ii) 區分宣傳性和非宣傳性
迷因。共有 14 個團隊參與決賽評分階段，其中 6
和 9 個團隊分別參與任務 1 和 2。最後，11 個團隊
提交了系統說明文件。在兩個任務中，我們觀察到
微調Transformer模型（例如 AraBERT）是大多數參與系統的核心
系統。我們提供任務設定的說明，
包括資料集建置和評分設定的說明。
我們進一步簡要概述參與系統。所有資料集
和評分腳本都發布到研究社群
(https://araieval.gitlab.io/)。我們希望這將有助於進一步研究
這些重要的阿拉伯語任務。

##### **Autoverse: An Evolvable Game Langugage for Learning Robust Embodied Agents**
2407.04221v1 by Sam Earle, Julian Togelius

We introduce Autoverse, an evolvable, domain-specific language for
single-player 2D grid-based games, and demonstrate its use as a scalable
training ground for Open-Ended Learning (OEL) algorithms. Autoverse uses
cellular-automaton-like rewrite rules to describe game mechanics, allowing it
to express various game environments (e.g. mazes, dungeons, sokoban puzzles)
that are popular testbeds for Reinforcement Learning (RL) agents. Each rewrite
rule can be expressed as a series of simple convolutions, allowing for
environments to be parallelized on the GPU, thereby drastically accelerating RL
training. Using Autoverse, we propose jump-starting open-ended learning by
imitation learning from search. In such an approach, we first evolve Autoverse
environments (their rules and initial map topology) to maximize the number of
iterations required by greedy tree search to discover a new best solution,
producing a curriculum of increasingly complex environments and playtraces. We
then distill these expert playtraces into a neural-network-based policy using
imitation learning. Finally, we use the learned policy as a starting point for
open-ended RL, where new training environments are continually evolved to
maximize the RL player agent's value function error (a proxy for its regret, or
the learnability of generated environments), finding that this approach
improves the performance and generality of resultant player agents.

摘要：<paragraph>我們介紹 Autoverse，這是一種可演化的、特定領域的語言，適用於單人 2D 網格遊戲，並展示其作為開放式學習 (OEL) 演算法的可擴充訓練場地的用途。Autoverse 使用類似於細胞自動機的重寫規則來描述遊戲機制，使其能夠表達各種遊戲環境（例如迷宮、地下城、倉庫番拼圖），這些環境是強化學習 (RL) 代理的熱門測試平台。每個重寫規則都可以表示為一系列簡單的卷積，允許在 GPU 上並行化環境，從而大幅加速 RL 訓練。使用 Autoverse，我們提出通過搜尋中的模仿學習來啟動開放式學習。在這種方法中，我們首先演化 Autoverse 環境（其規則和初始地圖拓撲）以最大化貪婪樹搜尋發現新最佳解所需的迭代次數，產生越來越複雜的環境和播放軌跡的課程。然後，我們使用模仿學習將這些專家播放軌跡提煉成基於神經網路的策略。最後，我們使用學習到的策略作為開放式 RL 的起點，其中不斷演化新的訓練環境以最大化 RL 玩家代理的價值函數誤差（其遺憾的代理，或生成環境的可學習性），發現這種方法可以改善結果玩家代理的效能和普遍性。</paragraph>

##### **Smart Vision-Language Reasoners**
2407.04212v1 by Denisa Roberts, Lucas Roberts

In this article, we investigate vision-language models (VLM) as reasoners.
The ability to form abstractions underlies mathematical reasoning,
problem-solving, and other Math AI tasks. Several formalisms have been given to
these underlying abstractions and skills utilized by humans and intelligent
systems for reasoning. Furthermore, human reasoning is inherently multimodal,
and as such, we focus our investigations on multimodal AI. In this article, we
employ the abstractions given in the SMART task (Simple Multimodal Algorithmic
Reasoning Task) introduced in \cite{cherian2022deep} as meta-reasoning and
problem-solving skills along eight axes: math, counting, path, measure, logic,
spatial, and pattern. We investigate the ability of vision-language models to
reason along these axes and seek avenues of improvement. Including composite
representations with vision-language cross-attention enabled learning
multimodal representations adaptively from fused frozen pretrained backbones
for better visual grounding. Furthermore, proper hyperparameter and other
training choices led to strong improvements (up to $48\%$ gain in accuracy) on
the SMART task, further underscoring the power of deep multimodal learning. The
smartest VLM, which includes a novel QF multimodal layer, improves upon the
best previous baselines in every one of the eight fundamental reasoning skills.
End-to-end code is available at https://github.com/smarter-vlm/smarter.

摘要：<paragraph>在本文中，我們探討視覺語言模型 (VLM) 作為推理者。
形成抽象化的能力是數學推理、問題解決和其他數學 AI 任務的基礎。
已經給出了幾種形式主義來表示人類和智能系統用於推理的基本抽象化和技能。
此外，人類推理本質上是多模態的，因此，我們將研究重點放在多模態 AI 上。
在本文中，我們採用 SMART 任務（簡單多模態演算法推理任務）中給出的抽象化，
它在 \cite{cherian2022deep} 中被引入為元推理和問題解決技能，並沿著以下八個軸線進行：
數學、計數、路徑、測量、邏輯、空間和模式。我們探討視覺語言模型沿著這些軸線推理的能力，
並尋求改進途徑。包含具有視覺語言交叉注意力的複合表示，
能夠自適應地從融合的凍結預訓練主幹學習多模態表示，以獲得更好的視覺基礎。
此外，適當的超參數和其他訓練選擇導致 SMART 任務的顯著改進（準確度提升高達 $48\%$），
進一步強調了深度多模態學習的力量。最聰明的 VLM 包含一個新穎的 QF 多模態層，
在八項基本推理技能的每一項中都改進了先前的最佳基準。
端到端程式碼可在 https://github.com/smarter-vlm/smarter 中取得。</paragraph>

##### **HAF-RM: A Hybrid Alignment Framework for Reward Model Training**
2407.04185v1 by Shujun Liu, Xiaoyu Shen, Yuhang Lai, Siyuan Wang, Shengbin Yue, Zengfeng Huang, Xuanjing Huang, Zhongyu Wei

The reward model has become increasingly important in alignment, assessment,
and data construction for large language models (LLMs). Most existing
researchers focus on enhancing reward models through data improvements,
following the conventional training framework for reward models that directly
optimizes the predicted rewards. In this paper, we propose a hybrid alignment
framework HaF-RM for reward model training by introducing an additional
constraint on token-level policy probabilities in addition to the reward score.
It can simultaneously supervise the internal preference model at the token
level and optimize the mapping layer of the reward model at the sequence level.
Theoretical justifications and experiment results on five datasets show the
validity and effectiveness of our proposed hybrid framework for training a
high-quality reward model. By decoupling the reward modeling procedure and
incorporating hybrid supervision, our HaF-RM framework offers a principled and
effective approach to enhancing the performance and alignment of reward models,
a critical component in the responsible development of powerful language
models. We release our code at https://haf-rm.github.io.

摘要：獎勵模型在大型語言模型 (LLM) 的比對、評估和資料建構中變得越來越重要。多數現有研究人員專注於透過資料改進來強化獎勵模型，遵循直接最佳化預測獎勵的獎勵模型傳統訓練架構。在本文中，我們提出一個混合比對架構 HaF-RM，用於獎勵模型訓練，方法是在獎勵分數之外，針對代幣層級政策機率引入額外限制。它可以同時監督代幣層級的內部偏好模型，並最佳化序列層級的獎勵模型對應層。在五個資料集上的理論論證和實驗結果顯示，我們提出的混合架構對於訓練高品質獎勵模型的有效性和效能。透過將獎勵建模程序解耦，並納入混合監督，我們的 HaF-RM 架構提供了一個有原則且有效的途徑，用於強化獎勵模型的效能和比對，這是負責任地開發強大語言模型中的關鍵元件。我們在 https://haf-rm.github.io/ 發布我們的程式碼。

##### **Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms**
2407.04183v1 by Joshua Ashkinaze, Ruijia Guan, Laura Kurek, Eytan Adar, Ceren Budak, Eric Gilbert

Large language models (LLMs) are trained on broad corpora and then used in
communities with specialized norms. Is providing LLMs with community rules
enough for models to follow these norms? We evaluate LLMs' capacity to detect
(Task 1) and correct (Task 2) biased Wikipedia edits according to Wikipedia's
Neutral Point of View (NPOV) policy. LLMs struggled with bias detection,
achieving only 64% accuracy on a balanced dataset. Models exhibited contrasting
biases (some under- and others over-predicted bias), suggesting distinct priors
about neutrality. LLMs performed better at generation, removing 79% of words
removed by Wikipedia editors. However, LLMs made additional changes beyond
Wikipedia editors' simpler neutralizations, resulting in high-recall but
low-precision editing. Interestingly, crowdworkers rated AI rewrites as more
neutral (70%) and fluent (61%) than Wikipedia-editor rewrites. Qualitative
analysis found LLMs sometimes applied NPOV more comprehensively than Wikipedia
editors but often made extraneous non-NPOV-related changes (such as grammar).
LLMs may apply rules in ways that resonate with the public but diverge from
community experts. While potentially effective for generation, LLMs may reduce
editor agency and increase moderation workload (e.g., verifying additions).
Even when rules are easy to articulate, having LLMs apply them like community
members may still be difficult.

摘要：大型語言模型（LLM）在廣泛的語料庫上進行訓練，然後在具有特殊規範的社群中使用。提供 LLM 社群規則是否足以讓模型遵循這些規範？我們評估 LLM 根據維基百科的中立觀點（NPOV）政策檢測（任務 1）和更正（任務 2）有偏差的維基百科編輯的能力。LLM 在偏差檢測方面遇到困難，在平衡的資料集上只達到 64% 的準確度。模型表現出對比的偏差（一些預測偏差不足，另一些則預測過度），這表明對中立性的先驗不同。LLM 在生成方面表現得更好，移除了維基百科編輯者移除的 79% 的字詞。然而，LLM 做出了超出維基百科編輯者更簡單的中立化的額外更改，導致高召回率但低精確度的編輯。有趣的是，群眾工作者將 AI 重寫評為比維基百科編輯重寫更中立（70%）和流暢（61%）。定性分析發現，LLM 有時比維基百科編輯者更全面地應用 NPOV，但經常做出與 NPOV 無關的額外更改（例如語法）。LLM 可能以與公眾產生共鳴的方式應用規則，但與社群專家不同。儘管在生成方面可能有效，但 LLM 可能會減少編輯者代理並增加審核工作量（例如，驗證新增內容）。即使規則很容易表達，讓 LLM 像社群成員一樣應用它們可能仍然很困難。

##### **Orchestrating LLMs with Different Personalizations**
2407.04181v1 by Jin Peng Zhou, Katie Z Luo, Jingwen Gu, Jason Yuan, Kilian Q. Weinberger, Wen Sun

This paper presents a novel approach to aligning large language models (LLMs)
with individual human preferences, sometimes referred to as Reinforcement
Learning from \textit{Personalized} Human Feedback (RLPHF). Given stated
preferences along multiple dimensions, such as helpfulness, conciseness, or
humor, the goal is to create an LLM without re-training that best adheres to
this specification. Starting from specialized expert LLMs, each trained for one
such particular preference dimension, we propose a black-box method that merges
their outputs on a per-token level. We train a lightweight Preference Control
Model (PCM) that dynamically translates the preference description and current
context into next-token prediction weights. By combining the expert models'
outputs at the token level, our approach dynamically generates text that
optimizes the given preference. Empirical tests show that our method matches or
surpasses existing preference merging techniques, providing a scalable,
efficient alternative to fine-tuning LLMs for individual personalization.

摘要：本文提出了一種新方法，用於將大型語言模型 (LLM) 與個人人類偏好對齊，有時稱為從「個人化」人類回饋中進行強化學習 (RLPHF)。給定多維度的既定偏好，例如有幫助、簡潔或幽默，目標是創建一個無需重新訓練的 LLM，以最佳方式遵守此規範。從針對一個此類特定偏好維度進行訓練的專業專家 LLM 開始，我們提出了一種黑盒方法，將其輸出在每個代幣層級合併。我們訓練了一個輕量級偏好控制模型 (PCM)，它會動態地將偏好描述和當前內容轉換為下一個代幣預測權重。透過在代幣層級結合專家模型的輸出，我們的做法會動態產生最佳化既定偏好的文字。實證測試顯示，我們的做法符合或超越現有的偏好合併技術，提供了一個可擴充、有效率的替代方案，用於微調個人化 LLM。

##### **Defense Against Syntactic Textual Backdoor Attacks with Token Substitution**
2407.04179v1 by Xinglin Li, Xianwen He, Yao Li, Minhao Cheng

Textual backdoor attacks present a substantial security risk to Large
Language Models (LLM). It embeds carefully chosen triggers into a victim model
at the training stage, and makes the model erroneously predict inputs
containing the same triggers as a certain class. Prior backdoor defense methods
primarily target special token-based triggers, leaving syntax-based triggers
insufficiently addressed. To fill this gap, this paper proposes a novel online
defense algorithm that effectively counters syntax-based as well as special
token-based backdoor attacks. The algorithm replaces semantically meaningful
words in sentences with entirely different ones but preserves the syntactic
templates or special tokens, and then compares the predicted labels before and
after the substitution to determine whether a sentence contains triggers.
Experimental results confirm the algorithm's performance against these two
types of triggers, offering a comprehensive defense strategy for model
integrity.

摘要：文本後門攻擊對大型語言模型 (LLM) 構成重大安全風險。它在訓練階段將精心挑選的觸發器嵌入受害者模型中，並讓模型錯誤地預測包含與特定類別相同的觸發器的輸入。先前的後門防禦方法主要針對基於特殊令牌的觸發器，而語法觸發器則處理不足。為了填補這一空白，本文提出了一種新穎的在線防禦演算法，可以有效地對抗基於語法的後門攻擊以及基於特殊令牌的後門攻擊。該演算法用完全不同的詞彙取代句子中具有語義意義的詞彙，但保留語法範本或特殊令牌，然後比較替換前後預測的標籤，以確定句子是否包含觸發器。實驗結果證實了該演算法對這兩種觸發器的效能，為模型完整性提供了一個全面的防禦策略。

##### **Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs**
2407.04173v1 by Faisal Hamman, Pasan Dissanayake, Saumitra Mishra, Freddy Lecue, Sanghamitra Dutta

Fine-tuning large language models (LLMs) on limited tabular data for
classification tasks can lead to \textit{fine-tuning multiplicity}, where
equally well-performing models make conflicting predictions on the same inputs
due to variations in the training process (i.e., seed, random weight
initialization, retraining on additional or deleted samples). This raises
critical concerns about the robustness and reliability of Tabular LLMs,
particularly when deployed for high-stakes decision-making, such as finance,
hiring, education, healthcare, etc. This work formalizes the challenge of
fine-tuning multiplicity in Tabular LLMs and proposes a novel metric to
quantify the robustness of individual predictions without expensive model
retraining. Our metric quantifies a prediction's stability by analyzing
(sampling) the model's local behavior around the input in the embedding space.
Interestingly, we show that sampling in the local neighborhood can be leveraged
to provide probabilistic robustness guarantees against a broad class of
fine-tuned models. By leveraging Bernstein's Inequality, we show that
predictions with sufficiently high robustness (as defined by our measure) will
remain consistent with high probability. We also provide empirical evaluation
on real-world datasets to support our theoretical results. Our work highlights
the importance of addressing fine-tuning instabilities to enable trustworthy
deployment of LLMs in high-stakes and safety-critical applications.

摘要：微调大型语言模型 (LLM) 以用于分类任务的有限表格数据可能导致“微调多重性”，其中性能同样良好的模型对相同的输入做出相互矛盾的预测，这是由于训练过程中的变化（即种子、随机权重初始化、在附加或已删除的样本上重新训练）。这引发了对表格 LLM 的稳健性和可靠性的关键担忧，尤其是在部署用于高风险决策时，例如金融、招聘、教育、医疗保健等。这项工作将表格 LLM 中微调多重性的挑战形式化，并提出了一种新颖的指标来量化单个预测的稳健性，而无需进行昂贵的模型重新训练。我们的指标通过分析（采样）模型在嵌入空间中围绕输入的局部行为来量化预测的稳定性。有趣的是，我们表明在局部邻域中采样可以用来针对广泛的微调模型提供概率稳健性保证。通过利用伯恩斯坦不等式，我们表明具有足够高稳健性（由我们的度量定义）的预测将始终保持高概率。我们还提供对真实世界数据集的经验评估来支持我们的理论结果。我们的工作强调了解决微调不稳定性的重要性，以便在高风险和安全关键型应用中可信地部署 LLM。

##### **ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild**
2407.04172v1 by Ahmed Masry, Megh Thakkar, Aayush Bajaj, Aaryaman Kartha, Enamul Hoque, Shafiq Joty

Given the ubiquity of charts as a data analysis, visualization, and
decision-making tool across industries and sciences, there has been a growing
interest in developing pre-trained foundation models as well as general purpose
instruction-tuned models for chart understanding and reasoning. However,
existing methods suffer crucial drawbacks across two critical axes affecting
the performance of chart representation models: they are trained on data
generated from underlying data tables of the charts, ignoring the visual trends
and patterns in chart images, and use weakly aligned vision-language backbone
models for domain-specific training, limiting their generalizability when
encountering charts in the wild. We address these important drawbacks and
introduce ChartGemma, a novel chart understanding and reasoning model developed
over PaliGemma. Rather than relying on underlying data tables, ChartGemma is
trained on instruction-tuning data generated directly from chart images, thus
capturing both high-level trends and low-level visual information from a
diverse set of charts. Our simple approach achieves state-of-the-art results
across $5$ benchmarks spanning chart summarization, question answering, and
fact-checking, and our elaborate qualitative studies on real-world charts show
that ChartGemma generates more realistic and factually correct summaries
compared to its contemporaries. We release the code, model checkpoints,
dataset, and demos at https://github.com/vis-nlp/ChartGemma.

摘要：鉴于图表作为数据分析、可视化和跨行业和科学的决策工具的普遍性，人们对开发预先训练的基础模型以及针对图表理解和推理进行通用指令调整的模型越来越感兴趣。然而，现有方法在影响图表表示模型性能的两个关键轴线上存在严重的缺陷：它们是在从图表的基础数据表生成的数据上进行训练的，忽略了图表图像中的视觉趋势和模式，并使用弱对齐的视觉语言主干模型进行特定领域的训练，限制了它们在遇到野生的图表时的泛化能力。我们解决了这些重要的缺点，并引入了 ChartGemma，这是一个在 PaliGemma 上开发的新型图表理解和推理模型。ChartGemma 并不是依赖于基础数据表，而是根据直接从图表图像生成的指令调整数据进行训练，从而从各种图表中捕获高级趋势和低级视觉信息。我们简单的做法在跨越图表摘要、问题解答和事实检查的 5 个基准测试中取得了最先进的结果，并且我们对真实世界图表进行的精心定性研究表明，与同类产品相比，ChartGemma 生成了更真实且事实正确的摘要。我们在 https://github.com/vis-nlp/ChartGemma 上发布了代码、模型检查点、数据集和演示。

##### **ELCC: the Emergent Language Corpus Collection**
2407.04158v1 by Brendon Boldt, David Mortensen

We introduce the Emergent Language Corpus Collection (ELCC): a collection of
corpora collected from open source implementations of emergent communication
systems across the literature. These systems include a variety of signalling
game environments as well as more complex tasks like a social deduction game
and embodied navigation. Each corpus is annotated with metadata describing the
characteristics of the source system as well as a suite of analyses of the
corpus (e.g., size, entropy, average message length). Currently, research
studying emergent languages requires directly running different systems which
takes time away from actual analyses of such languages, limits the variety of
languages that are studied, and presents a barrier to entry for researchers
without a background in deep learning. The availability of a substantial
collection of well-documented emergent language corpora, then, will enable new
directions of research which focus their purview on the properties of emergent
languages themselves rather than on experimental apparatus.

摘要：我們介紹新興語言語料庫集 (ELCC)：一個從文獻中收集到的新興通訊系統開放原始碼實作的語料庫集。這些系統包含各種信號遊戲環境以及更複雜的任務，例如社交推理遊戲和具身導航。每個語料庫都附有描述原始系統特徵的元資料，以及對語料庫的一組分析（例如大小、熵、平均訊息長度）。目前，研究新興語言需要直接執行不同的系統，這會耗費實際分析這些語言的時間，限制所研究語言的多樣性，並對沒有深度學習背景的研究人員構成進入障礙。因此，大量有良好文件的新興語言語料庫的可用性，將能讓研究朝著新的方向發展，其視野著重於新興語言本身的屬性，而非實驗裝置。

##### **Mixture of A Million Experts**
2407.04153v1 by Xu Owen He

The feedforward (FFW) layers in standard transformer architectures incur a
linear increase in computational costs and activation memory as the hidden
layer width grows. Sparse mixture-of-experts (MoE) architectures have emerged
as a viable approach to address this issue by decoupling model size from
computational cost. The recent discovery of the fine-grained MoE scaling law
shows that higher granularity leads to better performance. However, existing
MoE models are limited to a small number of experts due to computational and
optimization challenges. This paper introduces PEER (parameter efficient expert
retrieval), a novel layer design that utilizes the product key technique for
sparse retrieval from a vast pool of tiny experts (over a million). Experiments
on language modeling tasks demonstrate that PEER layers outperform dense FFWs
and coarse-grained MoEs in terms of performance-compute trade-off. By enabling
efficient utilization of a massive number of experts, PEER unlocks the
potential for further scaling of transformer models while maintaining
computational efficiency.

摘要：標準Transformer架構中的前饋 (FFW) 層會隨著隱藏層寬度的增加而導致計算成本和激活記憶體呈線性增加。稀疏混合專家 (MoE) 架構已成為一種可行的解決方案，透過解耦模型大小和計算成本來解決此問題。最近發現的細粒度 MoE 擴充法則顯示，更高的粒度會帶來更好的效能。然而，現有的 MoE 模型由於計算和最佳化挑戰而僅限於少數專家。本文介紹了 PEER (參數高效專家檢索)，這是一種新穎的層級設計，它利用產品金鑰技術從龐大的微小專家池 (超過一百萬) 中進行稀疏檢索。在語言模型任務上的實驗證明，PEER 層在效能計算折衷方面優於密集 FFW 和粗粒度 MoE。透過有效利用大量專家，PEER 釋放了Transformer模型進一步擴充的潛力，同時維持計算效率。

##### **VoxAct-B: Voxel-Based Acting and Stabilizing Policy for Bimanual Manipulation**
2407.04152v1 by I-Chun Arthur Liu, Sicheng He, Daniel Seita, Gaurav Sukhatme

Bimanual manipulation is critical to many robotics applications. In contrast
to single-arm manipulation, bimanual manipulation tasks are challenging due to
higher-dimensional action spaces. Prior works leverage large amounts of data
and primitive actions to address this problem, but may suffer from sample
inefficiency and limited generalization across various tasks. To this end, we
propose VoxAct-B, a language-conditioned, voxel-based method that leverages
Vision Language Models (VLMs) to prioritize key regions within the scene and
reconstruct a voxel grid. We provide this voxel grid to our bimanual
manipulation policy to learn acting and stabilizing actions. This approach
enables more efficient policy learning from voxels and is generalizable to
different tasks. In simulation, we show that VoxAct-B outperforms strong
baselines on fine-grained bimanual manipulation tasks. Furthermore, we
demonstrate VoxAct-B on real-world $\texttt{Open Drawer}$ and $\texttt{Open
Jar}$ tasks using two UR5s. Code, data, and videos will be available at
https://voxact-b.github.io.

摘要：雙手操作對於許多機器人應用至關重要。與單臂操作相比，雙手操作任務具有挑戰性，因為動作空間的維度較高。先前的研究利用大量的資料和原始動作來解決這個問題，但可能會造成樣本效率低落和在各種任務中概化有限。為了解決這個問題，我們提出了 VoxAct-B，一種以語言為條件的基於體素的方法，它利用視覺語言模型 (VLM) 優先處理場景中的關鍵區域並重建體素網格。我們將這個體素網格提供給我們的雙手操作策略，以學習動作和穩定動作。這種方法能從體素中更有效率地學習策略，並且可以概化到不同的任務。在模擬中，我們展示了 VoxAct-B 在精細的雙手操作任務中優於強大的基準。此外，我們在使用兩個 UR5 的真實世界 $\texttt{Open Drawer}$ 和 $\texttt{Open Jar}$ 任務中展示了 VoxAct-B。程式碼、資料和影片將在 https://voxact-b.github.io/ 上提供。

##### **Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers**
2407.04151v1 by Terry Tong, Jiashu Xu, Qin Liu, Muhao Chen

The security of multi-turn conversational large language models (LLMs) is
understudied despite it being one of the most popular LLM utilization.
Specifically, LLMs are vulnerable to data poisoning backdoor attacks, where an
adversary manipulates the training data to cause the model to output malicious
responses to predefined triggers. Specific to the multi-turn dialogue setting,
LLMs are at the risk of even more harmful and stealthy backdoor attacks where
the backdoor triggers may span across multiple utterances, giving lee-way to
context-driven attacks. In this paper, we explore a novel distributed backdoor
trigger attack that serves to be an extra tool in an adversary's toolbox that
can interface with other single-turn attack strategies in a plug and play
manner. Results on two representative defense mechanisms indicate that
distributed backdoor triggers are robust against existing defense strategies
which are designed for single-turn user-model interactions, motivating us to
propose a new defense strategy for the multi-turn dialogue setting that is more
challenging. To this end, we also explore a novel contrastive decoding based
defense that is able to mitigate the backdoor with a low computational
tradeoff.

摘要：儘管多輪對話式大型語言模型 (LLM) 是最受歡迎的 LLM 利用方式之一，但其安全性卻鮮少受到研究。具體來說，LLM 容易受到資料中毒後門攻擊，攻擊者會在訓練資料中動手腳，讓模型對預先定義的觸發器產生惡意的回應。針對多輪對話設定，LLM 甚至有風險會受到更具危害性和隱蔽性的後門攻擊，因為後門觸發器可能會跨越多個語句，為情境驅動攻擊留有餘地。在本文中，我們探討一種新穎的分布式後門觸發器攻擊，這將成為攻擊者工具箱中的額外工具，可以透過即插即用的方式與其他單輪攻擊策略介接。針對兩種代表性防禦機制的結果顯示，分布式後門觸發器對於現有防禦策略具有強健性，而這些策略是針對單輪使用者模型互動所設計的，這促使我們提出針對多輪對話設定的新防禦策略，而這個策略更具挑戰性。為此，我們也探討一種新穎的對比式解碼防禦，這能夠以低運算折衷來減輕後門影響。

##### **Towards Automating Text Annotation: A Case Study on Semantic Proximity Annotation using GPT-4**
2407.04130v1 by Sachin Yadav, Tejaswi Choppa, Dominik Schlechtweg

This paper explores using GPT-3.5 and GPT-4 to automate the data annotation
process with automatic prompting techniques. The main aim of this paper is to
reuse human annotation guidelines along with some annotated data to design
automatic prompts for LLMs, focusing on the semantic proximity annotation task.
Automatic prompts are compared to customized prompts. We further implement the
prompting strategies into an open-source text annotation tool, enabling easy
online use via the OpenAI API. Our study reveals the crucial role of accurate
prompt design and suggests that prompting GPT-4 with human-like instructions is
not straightforwardly possible for the semantic proximity task. We show that
small modifications to the human guidelines already improve the performance,
suggesting possible ways for future research.

摘要：本文探討使用 GPT-3.5 和 GPT-4 自動化資料標註流程，並使用自動提示技術。本文的主要目標是重複使用人類標註指南以及一些標註資料，以設計 LLM 的自動提示，專注於語義接近標註任務。將自動提示與自訂提示進行比較。我們進一步將提示策略實作到開源文字標註工具中，讓使用者能透過 OpenAI API 輕鬆線上使用。我們的研究揭露了準確提示設計的關鍵角色，並建議使用類似人類的指示提示 GPT-4 並非語義接近任務的直接作法。我們顯示，對人類指南進行微調已能提升效能，這建議了未來研究的可能途徑。

##### **Biometric Authentication Based on Enhanced Remote Photoplethysmography Signal Morphology**
2407.04127v1 by Zhaodong Sun, Xiaobai Li, Jukka Komulainen, Guoying Zhao

Remote photoplethysmography (rPPG) is a non-contact method for measuring
cardiac signals from facial videos, offering a convenient alternative to
contact photoplethysmography (cPPG) obtained from contact sensors. Recent
studies have shown that each individual possesses a unique cPPG signal
morphology that can be utilized as a biometric identifier, which has inspired
us to utilize the morphology of rPPG signals extracted from facial videos for
person authentication. Since the facial appearance and rPPG are mixed in the
facial videos, we first de-identify facial videos to remove facial appearance
while preserving the rPPG information, which protects facial privacy and
guarantees that only rPPG is used for authentication. The de-identified videos
are fed into an rPPG model to get the rPPG signal morphology for
authentication. In the first training stage, unsupervised rPPG training is
performed to get coarse rPPG signals. In the second training stage, an
rPPG-cPPG hybrid training is performed by incorporating external cPPG datasets
to achieve rPPG biometric authentication and enhance rPPG signal morphology.
Our approach needs only de-identified facial videos with subject IDs to train
rPPG authentication models. The experimental results demonstrate that rPPG
signal morphology hidden in facial videos can be used for biometric
authentication. The code is available at
https://github.com/zhaodongsun/rppg_biometrics.

摘要：遠端光電容積描記法 (rPPG) 是一種非接觸式方法，用於測量臉部影片中的心臟訊號，提供一種方便的替代方案，用於從接觸式感測器取得的接觸式光電容積描記法 (cPPG)。最近的研究顯示，每個個體都擁有獨特的 cPPG 訊號形態，可用作生物辨識識別碼，這啟發我們利用從臉部影片中擷取的 rPPG 訊號形態進行人員驗證。由於臉部外觀和 rPPG 混合在臉部影片中，我們首先對臉部影片進行去識別，以移除臉部外觀，同時保留 rPPG 資訊，這保護了臉部隱私並保證只有 rPPG 用於驗證。去識別的影片會輸入 rPPG 模型，以取得 rPPG 訊號形態進行驗證。在第一個訓練階段，執行無監督 rPPG 訓練，以取得粗略的 rPPG 訊號。在第二個訓練階段，執行 rPPG-cPPG 混合訓練，透過納入外部 cPPG 資料集，以達成 rPPG 生物辨識驗證，並增強 rPPG 訊號形態。我們的做法只需要去識別的臉部影片和主體 ID，即可訓練 rPPG 驗證模型。實驗結果證明，隱藏在臉部影片中的 rPPG 訊號形態可用於生物辨識驗證。程式碼可在 https://github.com/zhaodongsun/rppg_biometrics 取得。

##### **Query-Guided Self-Supervised Summarization of Nursing Notes**
2407.04125v1 by Ya Gao, Hans Moen, Saila Koivusalo, Miika Koskinen, Pekka Marttinen

Nursing notes, an important component of Electronic Health Records (EHRs),
keep track of the progression of a patient's health status during a care
episode. Distilling the key information in nursing notes through text
summarization techniques can improve clinicians' efficiency in understanding
patients' conditions when reviewing nursing notes. However, existing
abstractive summarization methods in the clinical setting have often overlooked
nursing notes and require the creation of reference summaries for supervision
signals, which is time-consuming. In this work, we introduce QGSumm, a
query-guided self-supervised domain adaptation framework for nursing note
summarization. Using patient-related clinical queries as guidance, our approach
generates high-quality, patient-centered summaries without relying on reference
summaries for training. Through automatic and manual evaluation by an expert
clinician, we demonstrate the strengths of our approach compared to the
state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot
settings. Ultimately, our approach provides a new perspective on conditional
text summarization, tailored to the specific interests of clinical personnel.

摘要：護理記錄是電子健康紀錄 (EHR) 的重要組成部分，
在照護過程中追蹤病患的健康狀態進展。利用文字摘要技術提煉護理記錄中的關鍵資訊，可以提升臨床醫師在檢視護理記錄時了解病患狀況的效率。然而，現有的臨床摘要方法常常忽略護理記錄，且需要建立參考摘要作為監督訊號，這非常耗時。在這項工作中，我們提出 QGSumm，一個用於護理記錄摘要的查詢引導式自我監督領域適應架構。我們的做法使用與病患相關的臨床查詢作為指引，在訓練中不依賴參考摘要，就能產生高品質、以病患為中心的摘要。透過專家臨床醫師的自動和手動評估，我們展示了我們的方法與最先進的大語言模型 (LLM) 相比在零次學習和少次學習設定中的優勢。最終，我們的做法為條件式文字摘要提供了新的觀點，專門針對臨床人員的特定興趣量身打造。

##### **Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models**
2407.04121v1 by Yuyan Chen, Qiang Fu, Yichen Yuan, Zhihao Wen, Ge Fan, Dayiheng Liu, Dongmei Zhang, Zhixu Li, Yanghua Xiao

Large Language Models (LLMs) have gained widespread adoption in various
natural language processing tasks, including question answering and dialogue
systems. However, a major drawback of LLMs is the issue of hallucination, where
they generate unfaithful or inconsistent content that deviates from the input
source, leading to severe consequences. In this paper, we propose a robust
discriminator named RelD to effectively detect hallucination in LLMs' generated
answers. RelD is trained on the constructed RelQA, a bilingual
question-answering dialogue dataset along with answers generated by LLMs and a
comprehensive set of metrics. Our experimental results demonstrate that the
proposed RelD successfully detects hallucination in the answers generated by
diverse LLMs. Moreover, it performs well in distinguishing hallucination in
LLMs' generated answers from both in-distribution and out-of-distribution
datasets. Additionally, we also conduct a thorough analysis of the types of
hallucinations that occur and present valuable insights. This research
significantly contributes to the detection of reliable answers generated by
LLMs and holds noteworthy implications for mitigating hallucination in the
future work.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中廣泛採用，包括問答和對話系統。然而，LLM 的一個主要缺點是幻覺問題，它們會產生與輸入來源不同的不忠實或不一致的內容，導致嚴重的後果。在本文中，我們提出了一個名為 RelD 的強健判別器，以有效檢測 LLM 生成的答案中的幻覺。RelD 是在構造的 RelQA 上訓練的，RelQA 是雙語問答對話數據集，以及 LLM 生成的答案和一組綜合指標。我們的實驗結果表明，所提出的 RelD 成功檢測了各種 LLM 生成的答案中的幻覺。此外，它在區分 LLM 生成的答案中的幻覺與分佈內和分佈外數據集方面表現良好。此外，我們還對發生的幻覺類型進行了徹底的分析，並提出了寶貴的見解。這項研究顯著有助於檢測 LLM 生成的可靠答案，並對未來工作中減輕幻覺具有重要的意義。

##### **MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization**
2407.04118v1 by Yuyan Chen, Zhihao Wen, Ge Fan, Zhengyu Chen, Wei Wu, Dayiheng Liu, Zhixu Li, Bang Liu, Yanghua Xiao

Prompt engineering, as an efficient and effective way to leverage Large
Language Models (LLM), has drawn a lot of attention from the research
community. The existing research primarily emphasizes the importance of
adapting prompts to specific tasks, rather than specific LLMs. However, a good
prompt is not solely defined by its wording, but also binds to the nature of
the LLM in question. In this work, we first quantitatively demonstrate that
different prompts should be adapted to different LLMs to enhance their
capabilities across various downstream tasks in NLP. Then we novelly propose a
model-adaptive prompt optimizer (MAPO) method that optimizes the original
prompts for each specific LLM in downstream tasks. Extensive experiments
indicate that the proposed method can effectively refine prompts for an LLM,
leading to significant improvements over various downstream tasks.

摘要：提示工程作為一種有效率且有效的方法來利用大型語言模型 (LLM)，已經引起了研究社群的許多關注。現有的研究主要強調調整提示以適應特定任務，而不是特定 LLM 的重要性。然而，一個好的提示不僅由其文字定義，還與有問題的 LLM 的性質相關。在這項工作中，我們首先定量證明，應將不同的提示調整為不同的 LLM，以增強其在 NLP 中各種下游任務中的能力。然後，我們新穎地提出了一個模型自適應提示優化器 (MAPO) 方法，該方法針對下游任務中的每個特定 LLM 優化原始提示。大量的實驗表明，所提出的方法可以有效地改善 LLM 的提示，從而顯著改善各種下游任務。

##### **Predictive Coding Networks and Inference Learning: Tutorial and Survey**
2407.04117v1 by Björn van Zwol, Ro Jefferson, Egon L. van den Broek

Recent years have witnessed a growing call for renewed emphasis on
neuroscience-inspired approaches in artificial intelligence research, under the
banner of $\textit{NeuroAI}$. This is exemplified by recent attention gained by
predictive coding networks (PCNs) within machine learning (ML). PCNs are based
on the neuroscientific framework of predictive coding (PC), which views the
brain as a hierarchical Bayesian inference model that minimizes prediction
errors from feedback connections. PCNs trained with inference learning (IL)
have potential advantages to traditional feedforward neural networks (FNNs)
trained with backpropagation. While historically more computationally
intensive, recent improvements in IL have shown that it can be more efficient
than backpropagation with sufficient parallelization, making PCNs promising
alternatives for large-scale applications and neuromorphic hardware. Moreover,
PCNs can be mathematically considered as a superset of traditional FNNs, which
substantially extends the range of possible architectures for both supervised
and unsupervised learning. In this work, we provide a comprehensive review as
well as a formal specification of PCNs, in particular placing them in the
context of modern ML methods, and positioning PC as a versatile and promising
framework worthy of further study by the ML community.

摘要：近年来，在人工智能研究中，人们越来越呼吁重新重视受神经科学启发的方法，并将其称为$\textit{NeuroAI}$。机器学习（ML）中预测编码网络（PCN）最近受到的关注就是一个例子。PCN 基于预测编码（PC）的神经科学框架，该框架将大脑视为一个分层的贝叶斯推理模型，该模型最小化反馈连接的预测误差。使用推理学习（IL）训练的 PCN 具有传统前馈神经网络（FNN）所没有的潜在优势，后者使用反向传播进行训练。虽然在历史上计算量更大，但 IL 的最新改进表明，如果并行化充分，它可以比反向传播更有效，这使得 PCN 成为大规模应用程序和神经形态硬件的有前途的替代方案。此外，PCN 在数学上可以被视为传统 FNN 的超集，这大大扩展了有监督学习和无监督学习的可能架构范围。在这项工作中，我们提供了 PCN 的全面综述以及正式规范，特别是将它们置于现代 ML 方法的背景下，并将 PC 定位为一个通用且有前途的框架，值得 ML 社区进一步研究。

##### **MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**
2407.04106v1 by Asma Alkhaldi, Raneem Alnajim, Layan Alabdullatef, Rawan Alyahya, Jun Chen, Deyao Zhu, Ahmed Alsinan, Mohamed Elhoseiny

Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.

摘要：隨著人工智慧 (AI) 的最新進展，醫療保健領域出現了顯著的突破，特別是在改善診斷程序方面。然而，先前的研究通常僅限於有限的功能。這項研究引入了 MiniGPT-Med，這是一種源自大規模語言模型且專為醫療應用而設計的視覺語言模型。MiniGPT-Med 在各種影像模式中展現出非凡的多功能性，包括 X 光、電腦斷層掃描和 MRI，進而增強其效用。該模型能夠執行諸如醫療報告生成、視覺問答 (VQA) 和醫療影像中的疾病識別等任務。它將影像和文字臨床資料整合處理，顯著提高了診斷準確性。我們的實證評估證實了 MiniGPT-Med 在疾病基礎、醫療報告生成和 VQA 基準上的優異表現，這代表了縮小協助放射診斷實務差距的重要一步。此外，它在醫療報告生成方面達到了最先進的表現，比先前的最佳模型高出 19% 的準確度。MiniGPT-Med 有望成為放射診斷的通用介面，進而提升各種醫療影像應用中的診斷效率。

##### **Can Pre-trained Language Models Understand Chinese Humor?**
2407.04105v1 by Yuyan Chen, Zhixu Li, Jiaqing Liang, Yanghua Xiao, Bang Liu, Yunwen Chen

Humor understanding is an important and challenging research in natural
language processing. As the popularity of pre-trained language models (PLMs),
some recent work makes preliminary attempts to adopt PLMs for humor recognition
and generation. However, these simple attempts do not substantially answer the
question: {\em whether PLMs are capable of humor understanding?} This paper is
the first work that systematically investigates the humor understanding ability
of PLMs. For this purpose, a comprehensive framework with three evaluation
steps and four evaluation tasks is designed. We also construct a comprehensive
Chinese humor dataset, which can fully meet all the data requirements of the
proposed evaluation framework. Our empirical study on the Chinese humor dataset
yields some valuable observations, which are of great guiding value for future
optimization of PLMs in humor understanding and generation.

摘要：幽默理解是自然語言處理中一項重要且具有挑戰性的研究。隨著預訓練語言模型 (PLM) 的普及，一些近期研究嘗試初步採用 PLM 來進行幽默識別和生成。然而，這些簡單的嘗試並未實質性地回答這個問題：{\em PLM 是否具備幽默理解能力？} 本論文是第一個系統性探討 PLM 幽默理解能力的研究。為此，設計了一個包含三個評估步驟和四個評估任務的綜合框架。我們還構建了一個全面的中文幽默數據集，它可以完全滿足所提出的評估框架的所有數據需求。我們對中文幽默數據集進行的實證研究產生了一些有價值的觀察，這些觀察對於未來優化 PLM 在幽默理解和生成方面的能力具有重要的指導意義。

##### **Advances in Diffusion Models for Image Data Augmentation: A Review of Methods, Models, Evaluation Metrics and Future Research Directions**
2407.04103v1 by Panagiotis Alimisis, Ioannis Mademlis, Panagiotis Radoglou-Grammatikis, Panagiotis Sarigiannidis, Georgios Th. Papadopoulos

Image data augmentation constitutes a critical methodology in modern computer
vision tasks, since it can facilitate towards enhancing the diversity and
quality of training datasets; thereby, improving the performance and robustness
of machine learning models in downstream tasks. In parallel, augmentation
approaches can also be used for editing/modifying a given image in a context-
and semantics-aware way. Diffusion Models (DMs), which comprise one of the most
recent and highly promising classes of methods in the field of generative
Artificial Intelligence (AI), have emerged as a powerful tool for image data
augmentation, capable of generating realistic and diverse images by learning
the underlying data distribution. The current study realizes a systematic,
comprehensive and in-depth review of DM-based approaches for image
augmentation, covering a wide range of strategies, tasks and applications. In
particular, a comprehensive analysis of the fundamental principles, model
architectures and training strategies of DMs is initially performed.
Subsequently, a taxonomy of the relevant image augmentation methods is
introduced, focusing on techniques regarding semantic manipulation,
personalization and adaptation, and application-specific augmentation tasks.
Then, performance assessment methodologies and respective evaluation metrics
are analyzed. Finally, current challenges and future research directions in the
field are discussed.

摘要：影像資料擴充構成現代電腦視覺任務中一項重要的方法論，因為它可以促進訓練資料集的多樣性和品質的提升；進而提升機器學習模型在下游任務中的效能和穩健性。與此同時，擴充方法也可以用於以一種與脈絡和語意相關的方式編輯/修改給定的影像。擴散模型 (DM) 是生成式人工智慧 (AI) 領域中最具潛力和最新的一類方法，已經成為影像資料擴充的強大工具，它能透過學習底層資料分佈來生成逼真且多樣化的影像。本研究對基於 DM 的影像擴充方法進行系統性、全面且深入的回顧，涵蓋廣泛的策略、任務和應用。特別是，最初對 DM 的基本原理、模型架構和訓練策略進行了全面的分析。隨後，介紹了相關影像擴充方法的分類，重點關注語意操作、個人化和適應以及特定應用擴充任務的技術。然後，分析了性能評估方法和各自的評估指標。最後，討論了該領域當前的挑戰和未來的研究方向。

##### **Stephanie: Step-by-Step Dialogues for Mimicking Human Interactions in Social Conversations**
2407.04093v1 by Hao Yang, Hongyuan Lu, Xinhua Zeng, Yang Liu, Xiang Zhang, Haoran Yang, Yumeng Zhang, Yiran Wei, Wai Lam

In the rapidly evolving field of natural language processing, dialogue
systems primarily employ a single-step dialogue paradigm. Although this
paradigm is efficient, it lacks the depth and fluidity of human interactions
and does not appear natural. We introduce a novel \textbf{Step}-by-Step
Dialogue Paradigm (Stephanie), designed to mimic the ongoing dynamic nature of
human conversations. By employing a dual learning strategy and a further-split
post-editing method, we generated and utilized a high-quality step-by-step
dialogue dataset to fine-tune existing large language models, enabling them to
perform step-by-step dialogues. We thoroughly present Stephanie. Tailored
automatic and human evaluations are conducted to assess its effectiveness
compared to the traditional single-step dialogue paradigm. We will release
code, Stephanie datasets, and Stephanie LLMs to facilitate the future of
chatbot eras.

摘要：在快速發展的自然語言處理領域中，對話系統主要採用單步對話範例。儘管此範例有效率，但它缺乏人類互動的深度和流暢度，且顯得不夠自然。我們引進一種新穎的**逐步**對話範例（Stephanie），旨在模仿人類對話持續進行的動態本質。透過採用雙重學習策略和進一步分割的後編輯方法，我們產生並利用高品質的逐步對話資料集來微調現有的大型語言模型，讓它們能夠執行逐步對話。我們徹底呈現 Stephanie。進行量身打造的自動和人工評估，以評估其相較於傳統單步對話範例的有效性。我們將釋出程式碼、Stephanie 資料集和 Stephanie LLM，以促進聊天機器人時代的未來發展。

##### **Advanced Artificial Intelligence Strategy for Optimizing Urban Rail Network Design using Nature-Inspired Algorithms**
2407.04087v1 by Hariram Sampath Kumar, Archana Singh, Manish Kumar Ojha

This study introduces an innovative methodology for the planning of metro
network routes within the urban environment of Chennai, Tamil Nadu, India. A
comparative analysis of the modified Ant Colony Optimization (ACO) method
(previously developed) with recent breakthroughs in nature-inspired algorithms
demonstrates the modified ACO's superiority over modern techniques. By
utilizing the modified ACO algorithm, the most efficient routes connecting the
origin and destination of the metro route are generated. Additionally, the
model is applied to the existing metro network to highlight variations between
the model's results and the current network. The Google Maps platform,
integrated with Python, handles real-time data, including land utilization,
Geographical Information Systems (GIS) data, census information, and points of
interest. This processing enables the identification of stops within the city
and along the chosen routes. The resulting metro network showcases substantial
benefits compared to conventional route planning methods, with noteworthy
enhancements in workforce productivity, decreased planning time, and
cost-efficiency. This study significantly enhances the efficiency of urban
transport systems, specifically in rapidly changing metropolitan settings such
as chennai.

摘要：本研究提出了一種創新的方法，用於規劃印度泰米爾納德邦欽奈市區內的捷運網路路線。修改過的蟻群最佳化 (ACO) 方法（先前開發）與自然啟發演算法的最新突破進行比較分析，證明了修改過的 ACO 優於現代技術。藉由利用修改過的 ACO 演算法，產生連接捷運路線起點和終點的最有效率路線。此外，將模型應用於現有的捷運網路，以突顯模型結果與目前網路之間的差異。整合 Python 的 Google 地圖平台處理即時資料，包括土地利用、地理資訊系統 (GIS) 資料、人口普查資訊和景點。此處理程序可識別城市內和沿著所選路線的停靠站。與傳統路線規劃方法相比，所產生的捷運網路展示出顯著的優點，在勞動力生產力、規劃時間縮短和成本效益方面都有顯著的提升。本研究顯著提升了都市運輸系統的效率，特別是在像欽奈這樣快速變化的都會區。

##### **AXOLOTL'24 Shared Task on Multilingual Explainable Semantic Change Modeling**
2407.04079v1 by Mariia Fedorova, Timothee Mickus, Niko Partanen, Janine Siewert, Elena Spaziani, Andrey Kutuzov

This paper describes the organization and findings of AXOLOTL'24, the first
multilingual explainable semantic change modeling shared task. We present new
sense-annotated diachronic semantic change datasets for Finnish and Russian
which were employed in the shared task, along with a surprise test-only German
dataset borrowed from an existing source. The setup of AXOLOTL'24 is new to the
semantic change modeling field, and involves subtasks of identifying unknown
(novel) senses and providing dictionary-like definitions to these senses. The
methods of the winning teams are described and compared, thus paving a path
towards explainability in computational approaches to historical change of
meaning.

摘要：本論文描述了 AXOLOTL'24 的組織和發現，這是第一個多語言可解釋語義變更建模共享任務。我們提供了用於共享任務的芬蘭語和俄語的新的感官註釋歷時語義變更數據集，以及從現有來源借用的驚喜測試專用德語數據集。AXOLOTL'24 的設置在語義變更建模領域是新的，並涉及識別未知（新穎）感官和為這些感官提供類似字典的定義的子任務。描述並比較了獲勝團隊的方法，從而為計算方法中歷史意義變化的可解釋性鋪平了道路。

##### **DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning**
2407.04078v1 by Chengpeng Li, Guanting Dong, Mingfeng Xue, Ru Peng, Xiang Wang, Dayiheng Liu

Large language models (LLMs) have made impressive progress in handling simple
math problems, yet they still struggle with more challenging and complex
mathematical tasks. In this paper, we introduce a series of LLMs that employs
the Decomposition of thought with code assistance and self-correction for
mathematical reasoning, dubbed as DotaMath. DotaMath models tackle complex
mathematical tasks by decomposing them into simpler logical subtasks,
leveraging code to solve these subtasks, obtaining fine-grained feedback from
the code interpreter, and engaging in self-reflection and correction. By
annotating diverse interactive tool-use trajectories and employing query
evolution on GSM8K and MATH datasets, we generate an instruction fine-tuning
dataset called DotaMathQA with 574K query-response pairs. We train a series of
base LLMs using imitation learning on DotaMathQA, resulting in DotaMath models
that achieve remarkable performance compared to open-source LLMs across various
in-domain and out-of-domain benchmarks. Notably, DotaMath-deepseek-7B showcases
an outstanding performance of 64.8% on the competitive MATH dataset and 86.7%
on GSM8K. Besides, DotaMath-deepseek-7B maintains strong competitiveness on a
series of in-domain and out-of-domain benchmarks (Avg. 80.1%). Looking forward,
we anticipate that the DotaMath paradigm will open new pathways for addressing
intricate mathematical problems. Our code is publicly available at
https://github.com/ChengpengLi1003/DotaMath.

摘要：大型語言模型 (LLM) 在處理簡單的數學問題上已取得令人印象深刻的進展，但它們在更具挑戰性和複雜性的數學任務上仍面臨困難。在本文中，我們介紹了一系列 LLM，它們採用了帶有代碼輔助和自我修正的思想分解進行數學推理，稱為 DotaMath。DotaMath 模型通過將複雜的數學任務分解成更簡單的邏輯子任務，利用代碼解決這些子任務，從代碼解釋器中獲得細緻的回饋，並進行自我反省和修正來解決複雜的數學任務。通過註解多樣化的互動工具使用軌跡並在 GSM8K 和 MATH 資料集上使用查詢演進，我們生成了包含 574K 個查詢回應對的指令微調資料集，稱為 DotaMathQA。我們使用模仿學習在 DotaMathQA 上訓練了一系列基礎 LLM，從而產生了 DotaMath 模型，這些模型在各種領域內和領域外基準測試中實現了與開源 LLM 相比顯著的效能。值得注意的是，DotaMath-deepseek-7B 在競爭激烈的 MATH 資料集上展示了 64.8% 的出色效能，在 GSM8K 上展示了 86.7% 的出色效能。此外，DotaMath-deepseek-7B 在一系列領域內和領域外基準測試中保持了強勁的競爭力（平均 80.1%）。展望未來，我們預期 DotaMath 典範將為解決複雜的數學問題開啟新的途徑。我們的程式碼可在 https://github.com/ChengpengLi1003/DotaMath 公開取得。

##### **Sparsest Models Elude Pruning: An Exposé of Pruning's Current Capabilities**
2407.04075v1 by Stephen Zhang, Vardan Papyan

Pruning has emerged as a promising approach for compressing large-scale
models, yet its effectiveness in recovering the sparsest of models has not yet
been explored. We conducted an extensive series of 485,838 experiments,
applying a range of state-of-the-art pruning algorithms to a synthetic dataset
we created, named the Cubist Spiral. Our findings reveal a significant gap in
performance compared to ideal sparse networks, which we identified through a
novel combinatorial search algorithm. We attribute this performance gap to
current pruning algorithms' poor behaviour under overparameterization, their
tendency to induce disconnected paths throughout the network, and their
propensity to get stuck at suboptimal solutions, even when given the optimal
width and initialization. This gap is concerning, given the simplicity of the
network architectures and datasets used in our study. We hope that our research
encourages further investigation into new pruning techniques that strive for
true network sparsity.

摘要：修剪已成為壓縮大型模型的一種有前途的方法，但其在恢復最稀疏模型方面的有效性尚未得到探索。我們進行了一系列廣泛的 485,838 次實驗，將一系列最先進的修剪演算法應用於我們建立的名為 Cubist Spiral 的合成資料集。我們的研究結果顯示，與我們透過新穎的組合搜尋演算法識別出的理想稀疏網路相比，效能存在顯著差距。我們將此效能差距歸因於目前修剪演算法在過度參數化下的不良行為、它們在整個網路中誘發斷開路徑的傾向，以及它們即使在給定最佳寬度和初始化時仍容易陷入次佳解的傾向。考慮到我們研究中使用的網路架構和資料集的簡單性，這個差距令人擔憂。我們希望我們的研究能鼓勵進一步研究新的修剪技術，以尋求真正的網路稀疏性。

##### **A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations**
2407.04069v1 by Md Tahmid Rahman Laskar, Sawsan Alqahtani, M Saiful Bari, Mizanur Rahman, Mohammad Abdullah Matin Khan, Haidar Khan, Israt Jahan, Amran Bhuiyan, Chee Wei Tan, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty, Jimmy Huang

Large Language Models (LLMs) have recently gained significant attention due
to their remarkable capabilities in performing diverse tasks across various
domains. However, a thorough evaluation of these models is crucial before
deploying them in real-world applications to ensure they produce reliable
performance. Despite the well-established importance of evaluating LLMs in the
community, the complexity of the evaluation process has led to varied
evaluation setups, causing inconsistencies in findings and interpretations. To
address this, we systematically review the primary challenges and limitations
causing these inconsistencies and unreliable evaluations in various steps of
LLM evaluation. Based on our critical review, we present our perspectives and
recommendations to ensure LLM evaluations are reproducible, reliable, and
robust.

摘要：大型語言模型 (LLM) 近期因其在執行各種領域中的不同任務時表現出的非凡能力而獲得極大的關注。然而，在將這些模型部署至真實世界應用程式中之前，徹底評估這些模型至關重要，以確保它們能產生可靠的效能。儘管在社群中已確立評估 LLM 的重要性，但評估程序的複雜性導致評估設定出現差異，進而造成發現和詮釋上的不一致。為了解決這個問題，我們系統性地檢視了造成這些不一致性和不可靠評估的主要挑戰和限制，這些挑戰和限制存在於 LLM 評估的不同步驟中。根據我們的批判性檢視，我們提出我們的觀點和建議，以確保 LLM 評估的可複製性、可靠性和穩健性。

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

摘要：符號句子意義表徵，例如 AMR（抽象意義表徵），提供表達性和結構化的語義圖表，作為簡化下游 NLP 任務的中介。然而，大型語言模型 (LLM) 的指令遵循能力提供了一個捷徑來有效解決 NLP 任務，質疑語義圖表的效用。同時，最近的研究也表明僅將意義表徵用作 LLM 的輔助工具的難度。我們重新審視語義圖表在語法簡化中的位置，語法簡化的任務是在保留句子結構的同時簡化句子結構，這需要語義理解，並在一個新的複雜且自然的數據集上對其進行評估。我們提出的基於 AMR 的方法 AMRS$^3$ 證明了最先進的意義表徵可以導致易於實現的簡化方法，在成本、可解釋性和泛化方面具有競爭優勢和獨特優勢。以 AMRS$^3$ 為錨點，我們發現語法簡化是一項語義圖表有助於 LLM 提示的任務。我們提出 AMRCoC 提示，指導 LLM 模擬圖形演算法，對 AMR 圖形進行明確的符號推理，並展示其在改進 LLM 在以語義為中心的任務（如語法簡化）方面的潛力。

##### **Benchmark on Drug Target Interaction Modeling from a Structure Perspective**
2407.04055v1 by Xinnan Zhang, Jialin Wu, Junyi Xie, Tianlong Chen, Kaixiong Zhou

The prediction modeling of drug-target interactions is crucial to drug
discovery and design, which has seen rapid advancements owing to deep learning
technologies. Recently developed methods, such as those based on graph neural
networks (GNNs) and Transformers, demonstrate exceptional performance across
various datasets by effectively extracting structural information. However, the
benchmarking of these novel methods often varies significantly in terms of
hyperparameter settings and datasets, which limits algorithmic progress. In
view of these, we conduct a comprehensive survey and benchmark for drug-target
interaction modeling from a structure perspective, via integrating tens of
explicit (i.e., GNN-based) and implicit (i.e., Transformer-based) structure
learning algorithms. To this end, we first unify the hyperparameter setting
within each class of structure learning methods. Moreover, we conduct a
macroscopical comparison between these two classes of encoding strategies as
well as the different featurization techniques that inform molecules' chemical
and physical properties. We then carry out the microscopical comparison between
all the integrated models across the six datasets, via comprehensively
benchmarking their effectiveness and efficiency. Remarkably, the summarized
insights from the benchmark studies lead to the design of model combos. We
demonstrate that our combos can achieve new state-of-the-art performance on
various datasets associated with cost-effective memory and computation. Our
code is available at
\hyperlink{https://github.com/justinwjl/GTB-DTI/tree/main}{https://github.com/justinwjl/GTB-DTI/tree/main}.

摘要：<paragraph>藥物標靶交互作用的預測建模對藥物發現和設計至關重要，而這方面已因深度學習技術而快速進步。最近開發的方法，例如基於圖神經網路 (GNN) 和 Transformer 的方法，透過有效提取結構資訊，在各種資料集上展現出卓越的效能。然而，這些新方法的基準測試在超參數設定和資料集方面常常有顯著差異，這限制了演算法的進展。有鑑於此，我們透過整合數十種明確（即基於 GNN）和隱式（即基於 Transformer）結構學習演算法，進行全面的調查和基準測試，從結構的角度建構藥物標靶交互作用模型。為此，我們首先統一每種類別結構學習方法的超參數設定。此外，我們對這兩種類別的編碼策略以及用於告知分子的化學和物理特性的不同特徵化技術進行宏觀比較。接著，我們透過全面評量其有效性和效率，對所有整合模型在六個資料集上進行微觀比較。值得注意的是，基準研究中總結的見解導致模型組合的設計。我們證明我們的組合可以在與具成本效益的記憶體和運算相關的各種資料集上，達成新的最先進效能。我們的程式碼可以在
\hyperlink{https://github.com/justinwjl/GTB-DTI/tree/main}{https://github.com/justinwjl/GTB-DTI/tree/main} 取得。</paragraph>

##### **FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs**
2407.04051v1 by Tongyi SpeechTeam

This report introduces FunAudioLLM, a model family designed to enhance
natural voice interactions between humans and large language models (LLMs). At
its core are two innovative models: SenseVoice, which handles multilingual
speech recognition, emotion recognition, and audio event detection; and
CosyVoice, which facilitates natural speech generation with control over
multiple languages, timbre, speaking style, and speaker identity.
SenseVoice-Small delivers exceptionally low-latency ASR for 5 languages, and
SenseVoice-Large supports high-precision ASR for over 50 languages, while
CosyVoice excels in multi-lingual voice generation, zero-shot in-context
learning, cross-lingual voice cloning, and instruction-following capabilities.
The models related to SenseVoice and CosyVoice have been open-sourced on
Modelscope and Huggingface, along with the corresponding training, inference,
and fine-tuning codes released on GitHub. By integrating these models with
LLMs, FunAudioLLM enables applications such as speech-to-speech translation,
emotional voice chat, interactive podcasts, and expressive audiobook narration,
thereby pushing the boundaries of voice interaction technology. Demos are
available at https://fun-audio-llm.github.io, and the code can be accessed at
https://github.com/FunAudioLLM.

摘要：本報告介紹 FunAudioLLM，這是一個模型系列，旨在增強人類與大型語言模型 (LLM) 之間的自然語音互動。其核心是兩個創新模型：SenseVoice，負責多語言語音辨識、情緒辨識和音訊事件偵測；以及 CosyVoice，促進自然語音生成，並控制多種語言、音色、說話風格和說話者身分。SenseVoice-Small 提供 5 種語言的極低延遲 ASR，而 SenseVoice-Large 支援超過 50 種語言的高精度 ASR，而 CosyVoice 則擅長多語言語音生成、零次學習、跨語言語音複製和指令遵循能力。與 SenseVoice 和 CosyVoice 相關的模型已在 Modelscope 和 Huggingface 上開源，同時對應的訓練、推論和微調程式碼已在 GitHub 上發布。透過將這些模型與 LLM 整合，FunAudioLLM 能支援語音轉語音翻譯、情緒化語音聊天、互動式播客和表達式有聲書旁白等應用程式，從而擴展語音互動技術的界限。示範可在 https://fun-audio-llm.github.io 取得，而程式碼可在 https://github.com/FunAudioLLM 取得。

##### **Deep Content Understanding Toward Entity and Aspect Target Sentiment Analysis on Foundation Models**
2407.04050v1 by Vorakit Vorakitphan, Milos Basic, Guilhaume Leroy Meline

Introducing Entity-Aspect Sentiment Triplet Extraction (EASTE), a novel
Aspect-Based Sentiment Analysis (ABSA) task which extends
Target-Aspect-Sentiment Detection (TASD) by separating aspect categories (e.g.,
food#quality) into pre-defined entities (e.g., meal, drink) and aspects (e.g.,
taste, freshness) which add a fine-gainer level of complexity, yet help
exposing true sentiment of chained aspect to its entity. We explore the task of
EASTE solving capabilities of language models based on transformers
architecture from our proposed unified-loss approach via token classification
task using BERT architecture to text generative models such as Flan-T5,
Flan-Ul2 to Llama2, Llama3 and Mixtral employing different alignment techniques
such as zero/few-shot learning, Parameter Efficient Fine Tuning (PEFT) such as
Low-Rank Adaptation (LoRA). The model performances are evaluated on the
SamEval-2016 benchmark dataset representing the fair comparison to existing
works. Our research not only aims to achieve high performance on the EASTE task
but also investigates the impact of model size, type, and adaptation techniques
on task performance. Ultimately, we provide detailed insights and achieving
state-of-the-art results in complex sentiment analysis.

摘要：推出實體面向情緒三元組萃取 (EASTE)，這是一種新穎的面向面向情緒分析 (ABSA) 任務，透過將面向類別（例如 food#quality）區分為預先定義的實體（例如 meal、drink）和面向（例如 taste、freshness）來延伸目標面向情緒偵測 (TASD)，這增加了精細的複雜性層級，但有助於揭露面向鏈結到其實體的真實情緒。我們探討 EASTE 的任務解決能力，這些能力基於透過代碼分類任務，從我們建議的統一損失方法中，使用 BERT 架構的轉換器架構，到文字生成模型，例如 Flan-T5、Flan-Ul2 到 Llama2、Llama3 和 Mixtral，採用不同的比對技術，例如零次/少量學習、參數有效微調 (PEFT)，例如低秩適應 (LoRA)。模型效能會在 SamEval-2016 基準資料集上評估，這代表與現有作品的公平比較。我們的研究不僅旨在於 EASTE 任務上達成高效能，也探討模型大小、類型和適應技術對任務效能的影響。最終，我們提供詳細見解，並在複雜情緒分析中達成最先進的結果。

##### **Improving Accented Speech Recognition using Data Augmentation based on Unsupervised Text-to-Speech Synthesis**
2407.04047v1 by Cong-Thanh Do, Shuhei Imai, Rama Doddipatla, Thomas Hain

This paper investigates the use of unsupervised text-to-speech synthesis
(TTS) as a data augmentation method to improve accented speech recognition. TTS
systems are trained with a small amount of accented speech training data and
their pseudo-labels rather than manual transcriptions, and hence unsupervised.
This approach enables the use of accented speech data without manual
transcriptions to perform data augmentation for accented speech recognition.
Synthetic accented speech data, generated from text prompts by using the TTS
systems, are then combined with available non-accented speech data to train
automatic speech recognition (ASR) systems. ASR experiments are performed in a
self-supervised learning framework using a Wav2vec2.0 model which was
pre-trained on large amount of unsupervised accented speech data. The accented
speech data for training the unsupervised TTS are read speech, selected from
L2-ARCTIC and British Isles corpora, while spontaneous conversational speech
from the Edinburgh international accents of English corpus are used as the
evaluation data. Experimental results show that Wav2vec2.0 models which are
fine-tuned to downstream ASR task with synthetic accented speech data,
generated by the unsupervised TTS, yield up to 6.1% relative word error rate
reductions compared to a Wav2vec2.0 baseline which is fine-tuned with the
non-accented speech data from Librispeech corpus.

摘要：這篇論文探討了將非監督文字轉語音合成 (TTS) 用作資料擴充方法，以改善重音語音辨識。TTS 系統使用少量重音語音訓練資料和其偽標籤（而非手動轉錄）進行訓練，因此是非監督的。此方法能使用重音語音資料，而無需手動轉錄，就能為重音語音辨識執行資料擴充。由 TTS 系統使用文字提示產生的合成重音語音資料，會與現有的非重音語音資料結合，以訓練自動語音辨識 (ASR) 系統。ASR 實驗是在自監督學習架構中進行，使用 Wav2vec2.0 模型，該模型經過大量非監督重音語音資料預訓練。用於訓練非監督 TTS 的重音語音資料是朗讀語音，選自 L2-ARCTIC 和英國群島語料庫，而愛丁堡國際英語口音語料庫中的自發對話語音則用作評估資料。實驗結果顯示，針對下游 ASR 任務進行微調的 Wav2vec2.0 模型，使用非監督 TTS 生成的合成重音語音資料，與使用 Librispeech 語料庫中的非重音語音資料進行微調的 Wav2vec2.0 基準相比，相對字元錯誤率降低了 6.1%。

##### **Systematic Task Exploration with LLMs: A Study in Citation Text Generation**
2407.04046v1 by Furkan Şahinuç, Ilia Kuznetsov, Yufang Hou, Iryna Gurevych

Large language models (LLMs) bring unprecedented flexibility in defining and
executing complex, creative natural language generation (NLG) tasks. Yet, this
flexibility brings new challenges, as it introduces new degrees of freedom in
formulating the task inputs and instructions and in evaluating model
performance. To facilitate the exploration of creative NLG tasks, we propose a
three-component research framework that consists of systematic input
manipulation, reference data, and output measurement. We use this framework to
explore citation text generation -- a popular scholarly NLP task that lacks
consensus on the task definition and evaluation metric and has not yet been
tackled within the LLM paradigm. Our results highlight the importance of
systematically investigating both task instruction and input configuration when
prompting LLMs, and reveal non-trivial relationships between different
evaluation metrics used for citation text generation. Additional human
generation and human evaluation experiments provide new qualitative insights
into the task to guide future research in citation text generation. We make our
code and data publicly available.

摘要：大型語言模型 (LLM) 在定義和執行複雜、創意的自然語言生成 (NLG) 任務方面帶來前所未有的靈活性。然而，這種靈活性帶來了新的挑戰，因為它在制定任務輸入和說明以及評估模型效能方面引入了新的自由度。為了促進對創意 NLG 任務的探索，我們提出了一個由系統性輸入操作、參考資料和輸出測量組成的三組成研究框架。我們使用這個框架來探討引文文字生成——一項流行的學術 NLP 任務，它缺乏任務定義和評估指標的共識，並且尚未在 LLM 範例中得到解決。我們的結果強調了在提示 LLM 時系統性地研究任務指令和輸入配置的重要性，並揭示了用於引文文字生成的不同評估指標之間的非平凡關係。額外的生成和人類評估實驗提供了對任務的新定性見解，以指導引文文字生成方面的未來研究。我們公開我們的程式碼和資料。

