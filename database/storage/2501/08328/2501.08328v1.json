{"2501.08328": {"publish_time": "2025-01-14", "title": "PokerBench: Training Large Language Models to become Professional Poker Players", "paper_summary": "We introduce PokerBench - a benchmark for evaluating the poker-playing\nabilities of large language models (LLMs). As LLMs excel in traditional NLP\ntasks, their application to complex, strategic games like poker poses a new\nchallenge. Poker, an incomplete information game, demands a multitude of skills\nsuch as mathematics, reasoning, planning, strategy, and a deep understanding of\ngame theory and human psychology. This makes Poker the ideal next frontier for\nlarge language models. PokerBench consists of a comprehensive compilation of\n11,000 most important scenarios, split between pre-flop and post-flop play,\ndeveloped in collaboration with trained poker players. We evaluate prominent\nmodels including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,\nfinding that all state-of-the-art LLMs underperform in playing optimal poker.\nHowever, after fine-tuning, these models show marked improvements. We validate\nPokerBench by having models with different scores compete with each other,\ndemonstrating that higher scores on PokerBench lead to higher win rates in\nactual poker games. Through gameplay between our fine-tuned model and GPT-4, we\nalso identify limitations of simple supervised fine-tuning for learning optimal\nplaying strategy, suggesting the need for more advanced methodologies for\neffectively training language models to excel in games. PokerBench thus\npresents a unique benchmark for a quick and reliable evaluation of the\npoker-playing ability of LLMs as well as a comprehensive benchmark to study the\nprogress of LLMs in complex game-playing scenarios. The dataset and code will\nbe made available at: \\url{https://github.com/pokerllm/pokerbench}.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63a8\u51fa PokerBench - \u4e00\u500b\u7528\u65bc\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u64b2\u514b\u904a\u6232\u80fd\u529b\u7684\u57fa\u6e96\u3002\u7531\u65bc LLM \u5728\u50b3\u7d71 NLP \u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u56e0\u6b64\u5c07\u5176\u61c9\u7528\u65bc\u64b2\u514b\u7b49\u8907\u96dc\u7684\u7b56\u7565\u904a\u6232\u69cb\u6210\u4e86\u4e00\u9805\u65b0\u7684\u6311\u6230\u3002\u64b2\u514b\u662f\u4e00\u7a2e\u4e0d\u5b8c\u5168\u8cc7\u8a0a\u904a\u6232\uff0c\u9700\u8981\u5927\u91cf\u7684\u6280\u80fd\uff0c\u4f8b\u5982\u6578\u5b78\u3001\u63a8\u7406\u3001\u898f\u5283\u3001\u7b56\u7565\uff0c\u4ee5\u53ca\u5c0d\u535a\u5f08\u8ad6\u548c\u4eba\u985e\u5fc3\u7406\u5b78\u7684\u6df1\u5165\u7406\u89e3\u3002\u9019\u4f7f\u5f97\u64b2\u514b\u6210\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u7406\u60f3\u4e0b\u4e00\u500b\u524d\u6cbf\u3002PokerBench \u5305\u542b 11,000 \u500b\u6700\u91cd\u8981\u7684\u5834\u666f\u7684\u7d9c\u5408\u5f59\u7de8\uff0c\u5206\u70ba\u7ffb\u724c\u524d\u548c\u7ffb\u724c\u5f8c\u904a\u6232\uff0c\u4e26\u8207\u8a13\u7df4\u6709\u7d20\u7684\u64b2\u514b\u73a9\u5bb6\u5408\u4f5c\u958b\u767c\u3002\u6211\u5011\u8a55\u4f30\u4e86\u5305\u62ec GPT-4\u3001ChatGPT 3.5 \u4ee5\u53ca\u5404\u7a2e Llama \u548c Gemma \u7cfb\u5217\u6a21\u578b\u5728\u5167\u7684\u77e5\u540d\u6a21\u578b\uff0c\u767c\u73fe\u6240\u6709\u6700\u5148\u9032\u7684 LLM \u5728\u73a9\u6700\u4f73\u64b2\u514b\u6642\u8868\u73fe\u4e0d\u4f73\u3002\u7136\u800c\uff0c\u5728\u5fae\u8abf\u5f8c\uff0c\u9019\u4e9b\u6a21\u578b\u986f\u793a\u51fa\u986f\u8457\u7684\u6539\u9032\u3002\u6211\u5011\u901a\u904e\u8b93\u5177\u6709\u4e0d\u540c\u5206\u6578\u7684\u6a21\u578b\u76f8\u4e92\u7af6\u722d\u4f86\u9a57\u8b49 PokerBench\uff0c\u8b49\u660e PokerBench \u4e0a\u8f03\u9ad8\u7684\u5206\u6578\u6703\u5c0e\u81f4\u5be6\u969b\u64b2\u514b\u904a\u6232\u4e2d\u8f03\u9ad8\u7684\u7372\u52dd\u7387\u3002\u901a\u904e\u6211\u5011\u5fae\u8abf\u7684\u6a21\u578b\u548c GPT-4 \u4e4b\u9593\u7684\u904a\u6232\uff0c\u6211\u5011\u9084\u767c\u73fe\u4e86\u7c21\u55ae\u7684\u76e3\u7763\u5fae\u8abf\u5728\u5b78\u7fd2\u6700\u4f73\u904a\u6232\u7b56\u7565\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u9019\u8868\u660e\u9700\u8981\u66f4\u5148\u9032\u7684\u65b9\u6cd5\u4f86\u6709\u6548\u5730\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u5728\u904a\u6232\u4e2d\u8868\u73fe\u51fa\u8272\u3002\u56e0\u6b64\uff0cPokerBench \u70ba\u5feb\u901f\u53ef\u9760\u5730\u8a55\u4f30 LLM \u7684\u64b2\u514b\u904a\u6232\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u500b\u7368\u7279\u7684\u57fa\u6e96\uff0c\u4e26\u63d0\u4f9b\u4e86\u4e00\u500b\u5168\u9762\u7684\u57fa\u6e96\u4f86\u7814\u7a76 LLM \u5728\u8907\u96dc\u904a\u6232\u5834\u666f\u4e2d\u7684\u9032\u5c55\u3002\u6578\u64da\u96c6\u548c\u4ee3\u78bc\u5c07\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u63d0\u4f9b\uff1a\\url{https://github.com/pokerllm/pokerbench}\u3002</paragraph>", "author": "Richard Zhuang et.al.", "authors": "Richard Zhuang, Akshat Gupta, Richard Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli", "id": "2501.08328v1", "paper_url": "http://arxiv.org/abs/2501.08328v1", "repo": "https://github.com/pokerllm/pokerbench"}}