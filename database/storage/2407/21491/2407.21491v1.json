{"2407.21491": {"publish_time": "2024-07-31", "title": "Generative Expressive Conversational Speech Synthesis", "paper_summary": "Conversational Speech Synthesis (CSS) aims to express a target utterance with\nthe proper speaking style in a user-agent conversation setting. Existing CSS\nmethods employ effective multi-modal context modeling techniques to achieve\nempathy understanding and expression. However, they often need to design\ncomplex network architectures and meticulously optimize the modules within\nthem. In addition, due to the limitations of small-scale datasets containing\nscripted recording styles, they often fail to simulate real natural\nconversational styles. To address the above issues, we propose a novel\ngenerative expressive CSS system, termed GPT-Talker.We transform the multimodal\ninformation of the multi-turn dialogue history into discrete token sequences\nand seamlessly integrate them to form a comprehensive user-agent dialogue\ncontext. Leveraging the power of GPT, we predict the token sequence, that\nincludes both semantic and style knowledge, of response for the agent. After\nthat, the expressive conversational speech is synthesized by the\nconversation-enriched VITS to deliver feedback to the user.Furthermore, we\npropose a large-scale Natural CSS Dataset called NCSSD, that includes both\nnaturally recorded conversational speech in improvised styles and dialogues\nextracted from TV shows. It encompasses both Chinese and English languages,\nwith a total duration of 236 hours.We conducted comprehensive experiments on\nthe reliability of the NCSSD and the effectiveness of our GPT-Talker. Both\nsubjective and objective evaluations demonstrate that our model outperforms\nother state-of-the-art CSS systems significantly in terms of naturalness and\nexpressiveness. The Code, Dataset, and Pre-trained Model are available at:\nhttps://github.com/AI-S2-Lab/GPT-Talker.", "paper_summary_zh": "\u5c0d\u8a71\u5f0f\u8a9e\u97f3\u5408\u6210 (CSS) \u65e8\u5728\u5728\u4f7f\u7528\u8005\u4ee3\u7406\u5c0d\u8a71\u8a2d\u5b9a\u4e2d\uff0c\u4ee5\u9069\u7576\u7684\u8aaa\u8a71\u98a8\u683c\u8868\u9054\u76ee\u6a19\u8a9e\u53e5\u3002\u73fe\u6709\u7684 CSS \u65b9\u6cd5\u63a1\u7528\u6709\u6548\u7684\u591a\u6a21\u5f0f\u8108\u7d61\u5efa\u6a21\u6280\u8853\uff0c\u4ee5\u9054\u6210\u540c\u7406\u7406\u89e3\u8207\u8868\u9054\u3002\u7136\u800c\uff0c\u4ed6\u5011\u7d93\u5e38\u9700\u8981\u8a2d\u8a08\u8907\u96dc\u7684\u7db2\u8def\u67b6\u69cb\uff0c\u4e26\u4ed4\u7d30\u512a\u5316\u5176\u4e2d\u7684\u6a21\u7d44\u3002\u6b64\u5916\uff0c\u7531\u65bc\u5305\u542b\u8173\u672c\u9304\u88fd\u98a8\u683c\u7684\u5c0f\u898f\u6a21\u8cc7\u6599\u96c6\u7684\u9650\u5236\uff0c\u4ed6\u5011\u7d93\u5e38\u7121\u6cd5\u6a21\u64ec\u771f\u5be6\u81ea\u7136\u7684\u5c0d\u8a71\u98a8\u683c\u3002\u70ba\u4e86\u89e3\u6c7a\u4e0a\u8ff0\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u751f\u6210\u8868\u9054\u5f0f CSS \u7cfb\u7d71\uff0c\u7a31\u70ba GPT-Talker\u3002\u6211\u5011\u5c07\u591a\u8f2a\u5c0d\u8a71\u6b77\u7a0b\u7684\u591a\u6a21\u5f0f\u8cc7\u8a0a\u8f49\u63db\u70ba\u96e2\u6563\u7684\u7b26\u865f\u5e8f\u5217\uff0c\u4e26\u5c07\u5b83\u5011\u7121\u7e2b\u6574\u5408\uff0c\u4ee5\u5f62\u6210\u4e00\u500b\u5168\u9762\u7684\u4f7f\u7528\u8005\u4ee3\u7406\u5c0d\u8a71\u8108\u7d61\u3002\u5229\u7528 GPT \u7684\u5f37\u5927\u529f\u80fd\uff0c\u6211\u5011\u9810\u6e2c\u4e86\u56de\u61c9\u7684\u7b26\u865f\u5e8f\u5217\uff0c\u5176\u4e2d\u5305\u62ec\u4ee3\u7406\u7684\u8a9e\u610f\u548c\u98a8\u683c\u77e5\u8b58\u3002\u5728\u90a3\u4e4b\u5f8c\uff0c\u8868\u9054\u5f0f\u7684\u5c0d\u8a71\u5f0f\u8a9e\u97f3\u7531\u5c0d\u8a71\u8c50\u5bcc\u7684 VITS \u5408\u6210\uff0c\u4ee5\u5411\u4f7f\u7528\u8005\u63d0\u4f9b\u56de\u994b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba NCSSD \u7684\u5927\u578b\u81ea\u7136 CSS \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u62ec\u4ee5\u5373\u8208\u98a8\u683c\u81ea\u7136\u9304\u88fd\u7684\u5c0d\u8a71\u5f0f\u8a9e\u97f3\uff0c\u4ee5\u53ca\u5f9e\u96fb\u8996\u7bc0\u76ee\u4e2d\u64f7\u53d6\u7684\u5c0d\u8a71\u3002\u5b83\u5305\u542b\u4e2d\u6587\u548c\u82f1\u6587\uff0c\u7e3d\u6642\u9577\u70ba 236 \u5c0f\u6642\u3002\u6211\u5011\u5c0d NCSSD \u7684\u53ef\u9760\u6027\u548c\u6211\u5011 GPT-Talker \u7684\u6709\u6548\u6027\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\u3002\u4e3b\u89c0\u548c\u5ba2\u89c0\u8a55\u4f30\u5747\u8b49\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u81ea\u7136\u6027\u548c\u8868\u73fe\u529b\u65b9\u9762\u660e\u986f\u512a\u65bc\u5176\u4ed6\u6700\u5148\u9032\u7684 CSS \u7cfb\u7d71\u3002\u7a0b\u5f0f\u78bc\u3001\u8cc7\u6599\u96c6\u548c\u9810\u8a13\u7df4\u6a21\u578b\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://github.com/AI-S2-Lab/GPT-Talker\u3002", "author": "Rui Liu et.al.", "authors": "Rui Liu, Yifan Hu, Ren Yi, Yin Xiang, Haizhou Li", "id": "2407.21491v1", "paper_url": "http://arxiv.org/abs/2407.21491v1", "repo": "null"}}