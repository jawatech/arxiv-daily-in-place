{"2406.08428": {"publish_time": "2024-06-12", "title": "Improving Noise Robustness through Abstractions and its Impact on Machine Learning", "paper_summary": "Noise is a fundamental problem in learning theory with huge effects in the\napplication of Machine Learning (ML) methods, due to real world data tendency\nto be noisy. Additionally, introduction of malicious noise can make ML methods\nfail critically, as is the case with adversarial attacks. Thus, finding and\ndeveloping alternatives to improve robustness to noise is a fundamental problem\nin ML. In this paper, we propose a method to deal with noise: mitigating its\neffect through the use of data abstractions. The goal is to reduce the effect\nof noise over the model's performance through the loss of information produced\nby the abstraction. However, this information loss comes with a cost: it can\nresult in an accuracy reduction due to the missing information. First, we\nexplored multiple methodologies to create abstractions, using the training\ndataset, for the specific case of numerical data and binary classification\ntasks. We also tested how these abstractions can affect robustness to noise\nwith several experiments that explore the robustness of an Artificial Neural\nNetwork to noise when trained using raw data \\emph{vs} when trained using\nabstracted data. The results clearly show that using abstractions is a viable\napproach for developing noise robust ML methods.", "paper_summary_zh": "\u566a\u8072\u662f\u5b78\u7fd2\u7406\u8ad6\u4e2d\u4e00\u500b\u57fa\u672c\u7684\u554f\u984c\uff0c\u5b83\u5c0d\u6a5f\u5668\u5b78\u7fd2 (ML) \u65b9\u6cd5\u7684\u61c9\u7528\u6709\u5f88\u5927\u7684\u5f71\u97ff\uff0c\u9019\u662f\u56e0\u70ba\u73fe\u5be6\u4e16\u754c\u7684\u8cc7\u6599\u50be\u5411\u65bc\u6709\u96dc\u8a0a\u3002\u6b64\u5916\uff0c\u5f15\u5165\u60e1\u610f\u7684\u96dc\u8a0a\u53ef\u80fd\u6703\u5c0e\u81f4 ML \u65b9\u6cd5\u56b4\u91cd\u5931\u6557\uff0c\u5c31\u50cf\u5c0d\u6297\u653b\u64ca\u7684\u60c5\u6cc1\u4e00\u6a23\u3002\u56e0\u6b64\uff0c\u5c0b\u627e\u548c\u958b\u767c\u66ff\u4ee3\u65b9\u6848\u4ee5\u63d0\u9ad8\u5c0d\u96dc\u8a0a\u7684\u9b6f\u68d2\u6027\u662f ML \u4e2d\u7684\u4e00\u500b\u57fa\u672c\u554f\u984c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u8655\u7406\u96dc\u8a0a\u7684\u65b9\u6cd5\uff1a\u900f\u904e\u4f7f\u7528\u8cc7\u6599\u62bd\u8c61\u4f86\u6e1b\u8f15\u5176\u5f71\u97ff\u3002\u76ee\u6a19\u662f\u900f\u904e\u62bd\u8c61\u7522\u751f\u7684\u8cc7\u8a0a\u640d\u5931\u4f86\u6e1b\u5c11\u96dc\u8a0a\u5c0d\u6a21\u578b\u6548\u80fd\u7684\u5f71\u97ff\u3002\u7136\u800c\uff0c\u9019\u7a2e\u8cc7\u8a0a\u640d\u5931\u662f\u6709\u4ee3\u50f9\u7684\uff1a\u5b83\u53ef\u80fd\u6703\u56e0\u70ba\u7f3a\u5c11\u8cc7\u8a0a\u800c\u5c0e\u81f4\u6e96\u78ba\u5ea6\u4e0b\u964d\u3002\u9996\u5148\uff0c\u6211\u5011\u63a2\u7d22\u4e86\u591a\u7a2e\u65b9\u6cd5\u4f86\u5efa\u7acb\u62bd\u8c61\uff0c\u4f7f\u7528\u8a13\u7df4\u8cc7\u6599\u96c6\uff0c\u91dd\u5c0d\u6578\u503c\u8cc7\u6599\u548c\u4e8c\u5143\u5206\u985e\u4efb\u52d9\u7684\u7279\u5b9a\u6848\u4f8b\u3002\u6211\u5011\u9084\u6e2c\u8a66\u4e86\u9019\u4e9b\u62bd\u8c61\u5982\u4f55\u5f71\u97ff\u5c0d\u96dc\u8a0a\u7684\u9b6f\u68d2\u6027\uff0c\u9032\u884c\u4e86\u591a\u9805\u5be6\u9a57\u4f86\u63a2\u8a0e\u4eba\u5de5\u795e\u7d93\u7db2\u8def\u5728\u4f7f\u7528\u539f\u59cb\u8cc7\u6599\u8a13\u7df4\u6642\u8207\u4f7f\u7528\u62bd\u8c61\u5316\u8cc7\u6599\u8a13\u7df4\u6642\u7684\u6297\u96dc\u8a0a\u6027\u3002\u7d50\u679c\u6e05\u695a\u5730\u8868\u660e\uff0c\u4f7f\u7528\u62bd\u8c61\u5316\u662f\u4e00\u7a2e\u53ef\u884c\u7684\u9014\u5f91\uff0c\u53ef\u958b\u767c\u51fa\u6297\u96dc\u8a0a\u7684 ML \u65b9\u6cd5\u3002", "author": "Alfredo Ibias et.al.", "authors": "Alfredo Ibias, Karol Capala, Varun Ravi Varma, Anna Drozdz, Jose Sousa", "id": "2406.08428v1", "paper_url": "http://arxiv.org/abs/2406.08428v1", "repo": "null"}}