{"2405.06247": {"publish_time": "2024-05-10", "title": "Disttack: Graph Adversarial Attacks Toward Distributed GNN Training", "paper_summary": "Graph Neural Networks (GNNs) have emerged as potent models for graph\nlearning. Distributing the training process across multiple computing nodes is\nthe most promising solution to address the challenges of ever-growing\nreal-world graphs. However, current adversarial attack methods on GNNs neglect\nthe characteristics and applications of the distributed scenario, leading to\nsuboptimal performance and inefficiency in attacking distributed GNN training.\n  In this study, we introduce Disttack, the first framework of adversarial\nattacks for distributed GNN training that leverages the characteristics of\nfrequent gradient updates in a distributed system. Specifically, Disttack\ncorrupts distributed GNN training by injecting adversarial attacks into one\nsingle computing node. The attacked subgraphs are precisely perturbed to induce\nan abnormal gradient ascent in backpropagation, disrupting gradient\nsynchronization between computing nodes and thus leading to a significant\nperformance decline of the trained GNN. We evaluate Disttack on four large\nreal-world graphs by attacking five widely adopted GNNs. Compared with the\nstate-of-the-art attack method, experimental results demonstrate that Disttack\namplifies the model accuracy degradation by 2.75$\\times$ and achieves speedup\nby 17.33$\\times$ on average while maintaining unnoticeability.", "paper_summary_zh": "\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u5df2\u6210\u70ba\u5716\u5f62\u5b78\u7fd2\u7684\u5f37\u5927\u6a21\u578b\u3002\u5c07\u8a13\u7df4\u6d41\u7a0b\u5206\u4f48\u5728\u591a\u500b\u904b\u7b97\u7bc0\u9ede\u4e0a\u662f\u61c9\u5c0d\u4e0d\u65b7\u6210\u9577\u7684\u771f\u5be6\u4e16\u754c\u5716\u5f62\u6311\u6230\u7684\u6700\u6709\u5e0c\u671b\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u7136\u800c\uff0c\u76ee\u524d\u91dd\u5c0d GNN \u7684\u5c0d\u6297\u653b\u64ca\u65b9\u6cd5\u5ffd\u7565\u4e86\u5206\u4f48\u5f0f\u5834\u666f\u7684\u7279\u5fb5\u548c\u61c9\u7528\uff0c\u5c0e\u81f4\u5728\u653b\u64ca\u5206\u4f48\u5f0f GNN \u8a13\u7df4\u6642\u6027\u80fd\u4e0d\u4f73\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 Disttack\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u91dd\u5c0d\u5206\u4f48\u5f0f GNN \u8a13\u7df4\u7684\u5c0d\u6297\u653b\u64ca\u6846\u67b6\uff0c\u5b83\u5229\u7528\u4e86\u5206\u4f48\u5f0f\u7cfb\u7d71\u4e2d\u983b\u7e41\u68af\u5ea6\u66f4\u65b0\u7684\u7279\u5fb5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cDisttack \u901a\u904e\u5411\u55ae\u4e00\u904b\u7b97\u7bc0\u9ede\u6ce8\u5165\u5c0d\u6297\u653b\u64ca\u4f86\u7834\u58de\u5206\u4f48\u5f0f GNN \u8a13\u7df4\u3002\u88ab\u653b\u64ca\u7684\u5b50\u5716\u88ab\u7cbe\u78ba\u5730\u64fe\u52d5\u4ee5\u5728\u53cd\u5411\u50b3\u64ad\u4e2d\u8a98\u767c\u7570\u5e38\u68af\u5ea6\u4e0a\u5347\uff0c\u7834\u58de\u904b\u7b97\u7bc0\u9ede\u4e4b\u9593\u7684\u68af\u5ea6\u540c\u6b65\uff0c\u5f9e\u800c\u5c0e\u81f4\u8a13\u7df4\u597d\u7684 GNN \u7684\u6027\u80fd\u986f\u8457\u4e0b\u964d\u3002\u6211\u5011\u901a\u904e\u653b\u64ca\u4e94\u500b\u5ee3\u6cdb\u63a1\u7528\u7684 GNN \u5728\u56db\u500b\u5927\u578b\u771f\u5be6\u4e16\u754c\u5716\u5f62\u4e0a\u8a55\u4f30\u4e86 Disttack\u3002\u8207\u6700\u5148\u9032\u7684\u653b\u64ca\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cDisttack \u5c07\u6a21\u578b\u6e96\u78ba\u5ea6\u4e0b\u964d\u5e45\u5ea6\u653e\u5927\u4e86 2.75 \u500d\uff0c\u540c\u6642\u5728\u4fdd\u6301\u4e0d\u53ef\u5bdf\u89ba\u6027\u7684\u60c5\u6cc1\u4e0b\u5e73\u5747\u63d0\u901f 17.33 \u500d\u3002", "author": "Yuxiang Zhang et.al.", "authors": "Yuxiang Zhang, Xin Liu, Meng Wu, Wei Yan, Mingyu Yan, Xiaochun Ye, Dongrui Fan", "id": "2405.06247v1", "paper_url": "http://arxiv.org/abs/2405.06247v1", "repo": "https://github.com/zhangyxrepo/disttack"}}