{"2405.18014": {"publish_time": "2024-05-28", "title": "Coupled Mamba: Enhanced Multi-modal Fusion with Coupled State Space Model", "paper_summary": "The essence of multi-modal fusion lies in exploiting the complementary\ninformation inherent in diverse modalities. However, prevalent fusion methods\nrely on traditional neural architectures and are inadequately equipped to\ncapture the dynamics of interactions across modalities, particularly in\npresence of complex intra- and inter-modality correlations. Recent advancements\nin State Space Models (SSMs), notably exemplified by the Mamba model, have\nemerged as promising contenders. Particularly, its state evolving process\nimplies stronger modality fusion paradigm, making multi-modal fusion on SSMs an\nappealing direction. However, fusing multiple modalities is challenging for\nSSMs due to its hardware-aware parallelism designs. To this end, this paper\nproposes the Coupled SSM model, for coupling state chains of multiple\nmodalities while maintaining independence of intra-modality state processes.\nSpecifically, in our coupled scheme, we devise an inter-modal hidden states\ntransition scheme, in which the current state is dependent on the states of its\nown chain and that of the neighbouring chains at the previous time-step. To\nfully comply with the hardware-aware parallelism, we devise an expedite coupled\nstate transition scheme and derive its corresponding global convolution kernel\nfor parallelism. Extensive experiments on CMU-MOSEI, CH-SIMS, CH-SIMSV2 through\nmulti-domain input verify the effectiveness of our model compared to current\nstate-of-the-art methods, improved F1-Score by 0.4\\%, 0.9\\%, and 2.3\\% on the\nthree datasets respectively, 49\\% faster inference and 83.7\\% GPU memory save.\nThe results demonstrate that Coupled Mamba model is capable of enhanced\nmulti-modal fusion.", "paper_summary_zh": "\u591a\u6a21\u614b\u878d\u5408\u7684\u7cbe\u9ad3\u5728\u65bc\u5229\u7528\u4e0d\u540c\u6a21\u614b\u4e2d\u56fa\u6709\u7684\u4e92\u88dc\u8cc7\u8a0a\u3002\u7136\u800c\uff0c\u73fe\u884c\u7684\u878d\u5408\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u50b3\u7d71\u7684\u795e\u7d93\u67b6\u69cb\uff0c\u4e26\u4e14\u7121\u6cd5\u5145\u5206\u6355\u6349\u6a21\u614b\u9593\u4e92\u52d5\u7684\u52d5\u614b\uff0c\u7279\u5225\u662f\u5728\u5b58\u5728\u8907\u96dc\u7684\u6a21\u614b\u5167\u90e8\u548c\u6a21\u614b\u9593\u95dc\u806f\u7684\u60c5\u6cc1\u4e0b\u3002\u72c0\u614b\u7a7a\u9593\u6a21\u578b (SSM) \u7684\u6700\u65b0\u9032\u5c55\uff0c\u7279\u5225\u662f\u4ee5 Mamba \u6a21\u578b\u70ba\u4f8b\uff0c\u5df2\u6210\u70ba\u6709\u5e0c\u671b\u7684\u7af6\u722d\u8005\u3002\u5177\u9ad4\u800c\u8a00\uff0c\u5b83\u7684\u72c0\u614b\u6f14\u5316\u904e\u7a0b\u610f\u5473\u8457\u66f4\u5f37\u5927\u7684\u6a21\u614b\u878d\u5408\u7bc4\u4f8b\uff0c\u4f7f SSM \u4e0a\u7684\u591a\u6a21\u614b\u878d\u5408\u6210\u70ba\u4e00\u500b\u6709\u5438\u5f15\u529b\u7684\u65b9\u5411\u3002\u7136\u800c\uff0c\u7531\u65bc\u5176\u786c\u9ad4\u611f\u77e5\u4e26\u884c\u8a2d\u8a08\uff0c\u5c0d SSM \u878d\u5408\u591a\u500b\u6a21\u614b\u5177\u6709\u6311\u6230\u6027\u3002\u70ba\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u8026\u5408 SSM \u6a21\u578b\uff0c\u7528\u65bc\u8026\u5408\u591a\u500b\u6a21\u614b\u7684\u72c0\u614b\u93c8\uff0c\u540c\u6642\u4fdd\u6301\u6a21\u614b\u5167\u90e8\u72c0\u614b\u904e\u7a0b\u7684\u7368\u7acb\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728\u6211\u5011\u7684\u8026\u5408\u65b9\u6848\u4e2d\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u6a21\u614b\u9593\u96b1\u85cf\u72c0\u614b\u8f49\u63db\u65b9\u6848\uff0c\u5176\u4e2d\u7576\u524d\u72c0\u614b\u4f9d\u8cf4\u65bc\u5176\u81ea\u8eab\u93c8\u7684\u72c0\u614b\u548c\u524d\u4e00\u6642\u9593\u6b65\u4e2d\u76f8\u9130\u93c8\u7684\u72c0\u614b\u3002\u70ba\u4e86\u5b8c\u5168\u7b26\u5408\u786c\u9ad4\u611f\u77e5\u4e26\u884c\u6027\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u52a0\u901f\u8026\u5408\u72c0\u614b\u8f49\u63db\u65b9\u6848\uff0c\u4e26\u63a8\u5c0e\u4e86\u5176\u5c0d\u61c9\u7684\u5168\u5c40\u5377\u7a4d\u6838\u4ee5\u5be6\u73fe\u4e26\u884c\u6027\u3002\u901a\u904e\u591a\u9818\u57df\u8f38\u5165\u5c0d CMU-MOSEI\u3001CH-SIMS\u3001CH-SIMSV2 \u7684\u5ee3\u6cdb\u5be6\u9a57\u9a57\u8b49\u4e86\u6211\u5011\u6a21\u578b\u8207\u7576\u524d\u6700\u5148\u9032\u65b9\u6cd5\u76f8\u6bd4\u7684\u6709\u6548\u6027\uff0c\u5206\u5225\u5728\u4e09\u500b\u6578\u64da\u96c6\u4e0a\u6539\u9032\u4e86 F1 \u5206\u6578 0.4%\u30010.9% \u548c 2.3%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e86 49%\uff0cGPU \u8a18\u61b6\u9ad4\u7bc0\u7701\u4e86 83.7%\u3002\u7d50\u679c\u8868\u660e\uff0c\u8026\u5408 Mamba \u6a21\u578b\u80fd\u5920\u589e\u5f37\u591a\u6a21\u614b\u878d\u5408\u3002", "author": "Wenbing Li et.al.", "authors": "Wenbing Li, Hang Zhou, Junqing Yu, Zikai Song, Wei Yang", "id": "2405.18014v2", "paper_url": "http://arxiv.org/abs/2405.18014v2", "repo": "null"}}