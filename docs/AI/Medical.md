
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|null|
|**2024-12-09**|**Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**|Le Song et.al.|[2412.06993v1](http://arxiv.org/abs/2412.06993v1)|[link](https://github.com/genbio-ai/aido)|
|**2024-12-09**|**Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**|Sahil Sethi et.al.|[2412.06717v1](http://arxiv.org/abs/2412.06717v1)|null|
|**2024-12-09**|**Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**|Aqib Nazir Mir et.al.|[2412.06709v1](http://arxiv.org/abs/2412.06709v1)|null|
|**2024-12-09**|**Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**|Sooyong Jang et.al.|[2412.06624v1](http://arxiv.org/abs/2412.06624v1)|null|
|**2024-12-09**|**Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**|Biman Barua et.al.|[2412.06874v1](http://arxiv.org/abs/2412.06874v1)|null|
|**2024-12-09**|**Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**|Yubo Zhou et.al.|[2412.06600v1](http://arxiv.org/abs/2412.06600v1)|null|
|**2024-12-09**|**HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**|Jiayan Chen et.al.|[2412.06530v1](http://arxiv.org/abs/2412.06530v1)|null|
|**2024-12-09**|**Simulating Human-like Daily Activities with Desire-driven Autonomy**|Yiding Wang et.al.|[2412.06435v1](http://arxiv.org/abs/2412.06435v1)|null|
|**2024-12-09**|**CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**|Yijie Dang et.al.|[2412.06314v1](http://arxiv.org/abs/2412.06314v1)|null|
|**2024-12-09**|**A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**|Quansong He et.al.|[2412.06262v1](http://arxiv.org/abs/2412.06262v1)|[link](https://github.com/nayutayuki/lightweight-nmode-decoders-for-u-like-networks)|
|**2024-12-09**|**MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**|Qinfeng Zhu et.al.|[2412.06211v1](http://arxiv.org/abs/2412.06211v1)|null|
|**2024-12-09**|**Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**|Guoxiao Zhang et.al.|[2412.06860v1](http://arxiv.org/abs/2412.06860v1)|null|
|**2024-12-09**|**MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**|Kangyu Zhu et.al.|[2412.06141v1](http://arxiv.org/abs/2412.06141v1)|[link](https://github.com/aiming-lab/mmedpo)|
|**2024-12-08**|**Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**|Akshat Choube et.al.|[2412.06018v1](http://arxiv.org/abs/2412.06018v1)|null|
|**2024-12-08**|**MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**|Xuefeng Ni et.al.|[2412.05876v1](http://arxiv.org/abs/2412.05876v1)|[link](https://github.com/xuefeng-ni/mg-3d)|
|**2024-12-08**|**Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**|Dinesh Parthasarathy et.al.|[2412.05852v1](http://arxiv.org/abs/2412.05852v1)|null|
|**2024-12-07**|**Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**|Abd Ur Rehman et.al.|[2412.05632v1](http://arxiv.org/abs/2412.05632v1)|null|
|**2024-12-07**|**UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**|Saba Hesaraki et.al.|[2412.05585v1](http://arxiv.org/abs/2412.05585v1)|null|
|**2024-12-07**|**Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**|Atit Pokharel et.al.|[2412.05583v2](http://arxiv.org/abs/2412.05583v2)|null|
|**2024-12-07**|**Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**|Cailian Ruan et.al.|[2412.05536v1](http://arxiv.org/abs/2412.05536v1)|null|
|**2024-12-06**|**Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**|Fang Zeng et.al.|[2412.06828v1](http://arxiv.org/abs/2412.06828v1)|null|
|**2024-12-06**|**Enhancing FKG.in: automating Indian food composition analysis**|Saransh Kumar Gupta et.al.|[2412.05248v2](http://arxiv.org/abs/2412.05248v2)|null|
|**2024-12-06**|**Are Frontier Large Language Models Suitable for Q&A in Science Centres?**|Jacob Watson et.al.|[2412.05200v1](http://arxiv.org/abs/2412.05200v1)|null|
|**2024-12-06**|**SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**|Jinlin Wu et.al.|[2412.05187v1](http://arxiv.org/abs/2412.05187v1)|[link](https://github.com/franciszchen/surgbox)|
|**2024-12-06**|**Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**|Thomas Sievers et.al.|[2412.05013v1](http://arxiv.org/abs/2412.05013v1)|null|
|**2024-12-06**|**Backdooring Outlier Detection Methods: A Novel Attack Approach**|ZeinabSadat Taghavi et.al.|[2412.05010v1](http://arxiv.org/abs/2412.05010v1)|null|
|**2024-12-06**|**Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**|Thomas Bartz-Beielstein et.al.|[2412.04950v1](http://arxiv.org/abs/2412.04950v1)|null|
|**2024-12-06**|**Estimating the treatment effect over time under general interference through deep learner integrated TMLE**|Suhan Guo et.al.|[2412.04799v1](http://arxiv.org/abs/2412.04799v1)|null|
|**2024-12-06**|**Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**|Mahfuzul Haque et.al.|[2412.04792v1](http://arxiv.org/abs/2412.04792v1)|null|
|**2024-12-06**|**DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**|Shadab Ahamed et.al.|[2412.04766v1](http://arxiv.org/abs/2412.04766v1)|null|
|**2024-12-06**|**PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**|Hongjin Lin et.al.|[2412.04714v1](http://arxiv.org/abs/2412.04714v1)|null|
|**2024-12-05**|**Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**|Chenyu Wang et.al.|[2412.04606v1](http://arxiv.org/abs/2412.04606v1)|null|
|**2024-12-05**|**CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**|Subash Neupane et.al.|[2412.04254v1](http://arxiv.org/abs/2412.04254v1)|null|
|**2024-12-05**|**Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**|Amnon Bleich et.al.|[2412.04067v1](http://arxiv.org/abs/2412.04067v1)|null|
|**2024-12-05**|**FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**|Jiechao Gao et.al.|[2412.03851v1](http://arxiv.org/abs/2412.03851v1)|null|
|**2024-12-05**|**ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**|Hongming Li et.al.|[2412.03800v1](http://arxiv.org/abs/2412.03800v1)|null|
|**2024-12-05**|**Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**|Abdelrahaman A. Hassan et.al.|[2412.03796v1](http://arxiv.org/abs/2412.03796v1)|null|
|**2024-12-05**|**Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**|Yerin Choi et.al.|[2412.03784v1](http://arxiv.org/abs/2412.03784v1)|null|
|**2024-12-04**|**Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**|Dilan Mian et.al.|[2412.03740v1](http://arxiv.org/abs/2412.03740v1)|null|
|**2024-12-04**|**MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**|Haoning Wu et.al.|[2412.04106v1](http://arxiv.org/abs/2412.04106v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v2](http://arxiv.org/abs/2412.02819v2)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Jingyuan Yi et.al.|[2412.02801v2](http://arxiv.org/abs/2412.02801v2)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v2](http://arxiv.org/abs/2412.02012v2)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v2](http://arxiv.org/abs/2412.01031v2)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|
|**2024-12-01**|**TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**|Rulin Zhou et.al.|[2412.00787v1](http://arxiv.org/abs/2412.00787v1)|null|
|**2024-12-01**|**Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**|Firdavs Nasriddinov et.al.|[2412.00760v1](http://arxiv.org/abs/2412.00760v1)|[link](https://github.com/firdavsn/SurgicalFeedbackAI)|
|**2024-11-30**|**Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**|Resmi Ramachandranpillai et.al.|[2412.00606v1](http://arxiv.org/abs/2412.00606v1)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|Théo Fagnoni et.al.|[2412.00573v2](http://arxiv.org/abs/2412.00573v2)|null|
|**2024-11-30**|**Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**|Łukasz Grzybowski et.al.|[2412.00559v1](http://arxiv.org/abs/2412.00559v1)|null|
|**2024-11-30**|**Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**|Yue Zhou et.al.|[2412.00554v2](http://arxiv.org/abs/2412.00554v2)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-30**|**One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**|Jingzhe Liu et.al.|[2412.00315v1](http://arxiv.org/abs/2412.00315v1)|null|
|**2024-11-30**|**BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**|Karine Karine et.al.|[2412.00308v1](http://arxiv.org/abs/2412.00308v1)|null|
|**2024-11-29**|**Fine Tuning Large Language Models to Deliver CBT for Depression**|Talha Tahir et.al.|[2412.00251v1](http://arxiv.org/abs/2412.00251v1)|[link](https://github.com/ttahir-git/FineTuning_LLMs_for_CBT_for_Depression)|
|**2024-11-29**|**Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**|Tianqi Shang et.al.|[2412.00245v1](http://arxiv.org/abs/2412.00245v1)|[link](https://github.com/hwq0726/sdoh-kg)|
|**2024-11-29**|**Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**|Guiran Liu et.al.|[2411.19922v1](http://arxiv.org/abs/2411.19922v1)|null|
|**2024-11-29**|**Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**|Heloisa Oss Boll et.al.|[2411.19742v1](http://arxiv.org/abs/2411.19742v1)|[link](https://github.com/hossboll/patient-gnn)|
|**2024-11-29**|**Multimodal Whole Slide Foundation Model for Pathology**|Tong Ding et.al.|[2411.19666v1](http://arxiv.org/abs/2411.19666v1)|[link](https://github.com/mahmoodlab/titan)|
|**2024-11-29**|**SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders**|Niki Martinel et.al.|[2411.19544v1](http://arxiv.org/abs/2411.19544v1)|null|
|**2024-11-29**|**Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification**|Ruimin Peng et.al.|[2411.19502v1](http://arxiv.org/abs/2411.19502v1)|null|
|**2024-11-29**|**Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine**|Zhi Li et.al.|[2411.19447v1](http://arxiv.org/abs/2411.19447v1)|[link](https://github.com/RicoLeehdu/SISeg)|
|**2024-11-28**|**Libra: Leveraging Temporal Images for Biomedical Radiology Analysis**|Xi Zhang et.al.|[2411.19378v1](http://arxiv.org/abs/2411.19378v1)|[link](https://github.com/X-iZhang/Libra)|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-28**|**FonTS: Text Rendering with Typography and Style Controls**|Wenda Shi et.al.|[2412.00136v1](http://arxiv.org/abs/2412.00136v1)|null|
|**2024-11-28**|**Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG**|Xinxu Wei et.al.|[2411.19230v1](http://arxiv.org/abs/2411.19230v1)|null|
|**2024-11-28**|**Open-Sora Plan: Open-Source Large Video Generation Model**|Bin Lin et.al.|[2412.00131v1](http://arxiv.org/abs/2412.00131v1)|[link](https://github.com/pku-yuangroup/open-sora-plan)|
|**2024-11-28**|**CovidLLM: A Robust Large Language Model with Missing Value Adaptation and Multi-Objective Learning Strategy for Predicting Disease Severity and Clinical Outcomes in COVID-19 Patients**|Shengjun Zhu et.al.|[2412.03593v1](http://arxiv.org/abs/2412.03593v1)|[link](https://github.com/sysll/CovidLLM)|
|**2024-11-28**|**A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by Wearable Technologies and Artificial Intelligence**|Chenyu Tang et.al.|[2411.19000v1](http://arxiv.org/abs/2411.19000v1)|null|

#### Abstracts
##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多 NLP 任務上表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，
利用檢索增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，
能穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：
非平穩環境的持續演變可能導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。
為了應對這些挑戰，我們引入了多目標多臂老虎機增強的 RAG 框架，
並在實務中採用具備多元能力的各種檢索方法，以應對豐富且不斷演變的檢索情境。
在此框架中，每個檢索方法都被視為一個不同的「手臂」。
該系統利用即時使用者回饋來適應動態環境，
根據輸入查詢和每個手臂的歷史多目標效能來選擇適當的檢索方法。
在兩個基準 KGQA 資料集上進行的廣泛實驗表明，
我們的模型在非平穩設定中顯著優於基線模型，同時在平穩環境中達到最先進的效能。
程式碼和資料可於 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

摘要：<paragraph>建模使用者偏好主要透過觀察使用者與系統中不同元素的互動記錄。
根據歷史資料調整個人偏好的內容是連續推薦的主要目標。
問題的本質，以及在各個領域觀察到的良好效能，激勵了Transformer架構的使用，在增加模型參數數量時，已證明能有效利用越來越多訓練資料。這種規模行為引起了極大的關注，因為它在設計和訓練更大模型時提供了有價值的指導。
從訓練大型語言模型中觀察到的規模法則中汲取靈感，我們探討了連續推薦的類似原則。
我們使用了完整的 Amazon 產品資料集，其他研究僅部分探討過，並揭示了與在語言模型中發現的類似的規模行為。計算最佳訓練是可能的，但需要仔細分析特定於應用程式的計算效能折衷。
我們還展示了效能規模轉化為下游任務，透過對較小的特定任務領域微調較大的預訓練模型。我們的做法和發現為模型訓練和在實際高維度偏好空間中部署提供了策略性路線圖，促進更好的訓練和推理效率。
我們希望這篇論文能彌合Transformer潛力與實際推薦系統中高維度連續推薦的內在複雜性之間的差距。
程式碼和模型可以在 https://github.com/mercadolibre/srt 找到</paragraph>

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

摘要：以語音對話為最佳化的人工智慧系統正快速出現。此類模型在醫療保健方面很有趣，因為這些聲控助理可以支援長者並能進行遠距健康監控。然而，效能的瓶頸在於這些裝置在實際運作上的表現如何，以及長者如何體驗它們，但這方面的研究卻很稀少。我們回顧了長者使用聲控人工智慧的狀況，並重點說明各種以使用者和技術為中心的議題，在能實現有效的聲控人工智慧以進行長者照護之前，這些議題都需要加以考量。

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

摘要：磁振造影 (MRI) 對於診斷和規劃各種醫療狀況的治療至關重要，因為它能夠產生揭示不同組織特徵的多系列影像。然而，整合這些不同的系列以形成連貫的分析會帶來重大的挑戰，例如不同的空間解析度和對比模式，同時需要大量的註解資料，但在臨床實務中卻很稀少。由於這些問題，我們引入了一種新穎的跨系列遮罩 (CSM) 策略，以便以自我監督的方式有效地學習 MRI 表徵。具體來說，CSM 從隨機抽樣區域和系列的子集開始，然後對其進行策略性遮罩。在訓練過程中，跨系列表徵是透過利用未遮罩的資料來重建遮罩部分而學習的。這個過程不僅整合了不同系列的資訊，還促進了對系列內和系列間關聯性和互補性的建模能力。透過學習到的表徵，下游任務（例如分割和分類）也會得到增強。以腦組織分割、乳房腫瘤良性/惡性分類和前列腺癌診斷為例，我們的模型在公開資料集和內部資料集上都達到了最先進的效能。

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

摘要：利害關係人（從模型開發人員到政策制定者）尋求將大型語言模型 (LLM) 的雙重使用風險降至最低。對此目標的公開挑戰在於，技術保障措施是否能阻止 LLM 的濫用，即使模型可通過微調進行自訂，或模型權重完全開放時亦然。為了解決此問題，最近有幾項研究提出方法，以產生適用於開放權重 LLM 的耐用 LLM 保障措施，這些保障措施能承受透過微調對模型權重進行的對抗性修改。這有望提高對手的成本，即使在對手可以直接微調模型權重的強威脅模型下亦然。然而，在本文中，我們敦促更仔細地描述這些方法的限制。透過多項案例研究，我們證明即使評估這些防禦措施也極其困難，並且很容易誤導受眾，讓他們認為保障措施比實際上更耐用。我們從我們辨識出的評估陷阱中汲取教訓，並建議未來的研究謹慎地將主張限制在更受限、定義明確且經過嚴格審查的威脅模型中，這可以為利害關係人提供更有用且坦率的評估。

##### **Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels**
2412.06993v1 by Le Song, Eran Segal, Eric Xing

We present an approach of using AI to model and simulate biology and life.
Why is it important? Because at the core of medicine, pharmacy, public health,
longevity, agriculture and food security, environmental protection, and clean
energy, it is biology at work. Biology in the physical world is too complex to
manipulate and always expensive and risky to tamper with. In this perspective,
we layout an engineering viable approach to address this challenge by
constructing an AI-Driven Digital Organism (AIDO), a system of integrated
multiscale foundation models, in a modular, connectable, and holistic fashion
to reflect biological scales, connectedness, and complexities. An AIDO opens up
a safe, affordable and high-throughput alternative platform for predicting,
simulating and programming biology at all levels from molecules to cells to
individuals. We envision that an AIDO is poised to trigger a new wave of
better-guided wet-lab experimentation and better-informed first-principle
reasoning, which can eventually help us better decode and improve life.

摘要：我們提出了一種使用 AI 來建模和模擬生物學和生命的方法。
為什麼這很重要？因為在醫學、藥學、公共衛生、
長壽、農業和食品安全、環境保護和清潔
能源的核心，都是生物學在運作。物理世界中的生物學太過複雜，
難以操作，而且總是昂貴且有風險。從這個角度來看，
我們制定了一種可行的工程方法來解決這個挑戰，方法是
構建一個 AI 驅動的數位生物體 (AIDO)，一個整合的
多尺度基礎模型系統，以模組化、可連接和整體的方式
來反映生物尺度、連通性和複雜性。AIDO 開啟了一個安全、
負擔得起且高通量的替代平台，用於預測、
模擬和編程從分子到細胞到個體的所有層級的生物學。我們預計 AIDO 將引發一波
由更佳指導的濕式實驗和更完善的第一原理
推理的新浪潮，最終可以幫助我們更好地解碼和改善生命。

##### **Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning**
2412.06717v1 by Sahil Sethi, Sai Reddy, Mansi Sakarvadia, Jordan Serotte, Darlington Nwaudo, Nicholas Maassen, Lewis Shi

Bankart lesions, or anterior-inferior glenoid labral tears, are
diagnostically challenging on standard MRIs due to their subtle imaging
features-often necessitating invasive MRI arthrograms (MRAs). This study
develops deep learning (DL) models to detect Bankart lesions on both standard
MRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on
MRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from
558 patients who underwent arthroscopy. Ground truth labels were derived from
intraoperative findings, the gold standard for Bankart lesion diagnosis.
Separate DL models for MRAs and standard MRIs were trained using the Swin
Transformer architecture, pre-trained on a public knee MRI dataset. Predictions
from sagittal, axial, and coronal views were ensembled to optimize performance.
The models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71
standard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of
standard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,
86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on
standard MRIs and MRAs, respectively. These results match or surpass
radiologist performance on our dataset and reported literature metrics.
Notably, our model's performance on non-invasive standard MRIs matched or
surpassed the radiologists interpreting MRAs. This study demonstrates the
feasibility of using DL to address the diagnostic challenges posed by subtle
pathologies like Bankart lesions. Our models demonstrate potential to improve
diagnostic confidence, reduce reliance on invasive imaging, and enhance
accessibility to care.

摘要：Bankart 病灶，或前下盂唇撕裂，由於其影像特徵微妙，在標準核磁共振成像中診斷具有挑戰性，通常需要侵入性核磁共振血管造影 (MRA)。本研究開發深度學習 (DL) 模型，用於在標準核磁共振成像和核磁共振血管造影中檢測 Bankart 病灶，旨在提高診斷準確性並減少對核磁共振血管造影的依賴。我們從 558 名接受關節鏡檢查的患者中策劃了一組 586 例肩部核磁共振成像 (335 例標準，251 例核磁共振血管造影) 的數據集。基本事實標籤來自術中發現，這是 Bankart 病灶診斷的黃金標準。使用 Swin Transformer 架構訓練了核磁共振血管造影和標準核磁共振成像的單獨深度學習模型，並在公開的膝部核磁共振成像數據集上進行預訓練。矢狀面、軸面和冠狀面的預測結果被組合起來以優化性能。這些模型在 20% 的保留測試集（117 例核磁共振成像：46 例核磁共振血管造影，71 例標準核磁共振成像）上進行了評估。在 31.9% 的核磁共振血管造影和 8.6% 的標準核磁共振成像中發現了 Bankart 病灶。這些模型在標準核磁共振成像和核磁共振血管造影中的 AUC 分別達到 0.87（86% 準確度，83% 靈敏度，86% 特異度）和 0.90（85% 準確度，82% 靈敏度，86% 特異度）。這些結果與放射科醫生對我們數據集的表現相匹配或超過，並超過了報告的文獻指標。值得注意的是，我們的模型在非侵入性標準核磁共振成像中的表現與放射科醫生對核磁共振血管造影的解釋相匹配或超過。本研究證明了使用深度學習來解決 Bankart 病灶等微妙病理診斷挑戰的可行性。我們的模型展示了提高診斷信心、減少對侵入性影像檢查的依賴以及增強獲得照護的機會的潛力。

##### **Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection**
2412.06709v1 by Aqib Nazir Mir, Iqra Nissar, Mumtaz Ahmed, Sarfaraz Masood, Danish Raza Rizvi

Deep learning holds tremendous potential in healthcare for uncovering hidden
patterns within extensive clinical datasets, aiding in the diagnosis of various
diseases. Parkinson's disease (PD) is a neurodegenerative condition
characterized by the deterioration of brain function. In the initial stages of
PD, automatic diagnosis poses a challenge due to the similarity in behavior
between individuals with PD and those who are healthy. Our objective is to
propose an effective model that can aid in the early detection of Parkinson's
disease. We employed the VGRF gait signal dataset sourced from Physionet for
distinguishing between healthy individuals and those diagnosed with Parkinson's
disease. This paper introduces a novel deep learning architecture based on the
LSTM network for automatically detecting freezing of gait episodes in
Parkinson's disease patients. In contrast to conventional machine learning
algorithms, this method eliminates manual feature engineering and proficiently
captures prolonged temporal dependencies in gait patterns, thereby improving
the diagnosis of Parkinson's disease. The LSTM network resolves the issue of
vanishing gradients by employing memory blocks in place of self-connected
hidden units, allowing for optimal information assimilation. To prevent
overfitting, dropout and L2 regularization techniques have been employed.
Additionally, the stochastic gradient-based optimizer Adam is used for the
optimization process. The results indicate that our proposed approach surpasses
current state-of-the-art models in FOG episode detection, achieving an accuracy
of 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This
demonstrates its potential as a superior classification method for Parkinson's
disease detection.

摘要：深度學習在醫療保健領域擁有巨大的潛力，可用於發掘廣泛臨床資料集中的隱藏模式，協助診斷各種疾病。帕金森氏症 (PD) 是一種神經退化性疾病，其特徵是大腦功能惡化。在 PD 的初期階段，由於 PD 患者與健康者的行為相似，因此自動診斷具有挑戰性。我們的目標是提出一個有效的模型，可以幫助早期檢測帕金森氏症。我們採用了來自 Physionet 的 VGRF 步態信號資料集，用於區分健康個體和被診斷出患有帕金森氏症的個體。本文介紹了一種基於 LSTM 網路的深度學習新架構，用於自動檢測帕金森氏症患者的步態凍結發作。與傳統機器學習演算法相比，此方法消除了手動特徵工程，並熟練地捕捉步態模式中的長時間依賴性，從而改進了帕金森氏症的診斷。LSTM 網路通過使用記憶區塊代替自連接隱藏單元來解決梯度消失問題，從而實現最佳資訊同化。為了防止過度擬合，已採用中斷和 L2 正則化技術。此外，隨機梯度優化器 Adam 用於優化過程。結果表明，我們提出的方法在 FOG 發作檢測方面超越了當前最先進的模型，達到了 97.71% 的準確率、99% 的靈敏度、98% 的精確度和 96% 的特異性。這證明了其作為帕金森氏症檢測的優越分類方法的潛力。

##### **Fundus Image-based Visual Acuity Assessment with PAC-Guarantees**
2412.06624v1 by Sooyong Jang, Kuk Jin Jang, Hyonyoung Choi, Yong-Seop Han, Seongjin Lee, Jin-hyun Kim, Insup Lee

Timely detection and treatment are essential for maintaining eye health.
Visual acuity (VA), which measures the clarity of vision at a distance, is a
crucial metric for managing eye health. Machine learning (ML) techniques have
been introduced to assist in VA measurement, potentially alleviating
clinicians' workloads. However, the inherent uncertainties in ML models make
relying solely on them for VA prediction less than ideal. The VA prediction
task involves multiple sources of uncertainty, requiring more robust
approaches. A promising method is to build prediction sets or intervals rather
than point estimates, offering coverage guarantees through techniques like
conformal prediction and Probably Approximately Correct (PAC) prediction sets.
Despite the potential, to date, these approaches have not been applied to the
VA prediction task.To address this, we propose a method for deriving prediction
intervals for estimating visual acuity from fundus images with a PAC guarantee.
Our experimental results demonstrate that the PAC guarantees are upheld, with
performance comparable to or better than that of two prior works that do not
provide such guarantees.

摘要：及時地偵測和治療對於維持眼睛健康至關重要。
視力（VA），用於測量遠距離視覺的清晰度，是維持眼睛健康的關鍵指標。機器學習（ML）技術已被引入以協助 VA 測量，潛在地減輕臨床醫師的工作負擔。然而，ML 模型中固有的不確定性使得僅依賴它們進行 VA 預測並非理想。VA 預測任務涉及多種不確定性來源，需要更強大的方法。一種有前途的方法是建立預測集合或區間，而不是點估計，通過像共形預測和大概正確（PAC）預測集合這樣的技術提供覆蓋率保證。儘管有潛力，但迄今為止，這些方法尚未應用於 VA 預測任務。為了解決這個問題，我們提出了一種從眼底圖像估計視力的預測區間的方法，並提供 PAC 保證。我們的實驗結果表明，PAC 保證得到維持，其性能與不提供此類保證的兩項先前工作的性能相當或更好。

##### **Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices**
2412.06874v1 by Biman Barua, M. Shamim Kaiser

The rapid growth of the travel industry has increased the need for real-time
optimization in reservation systems that could take care of huge data and
transaction volumes. This study proposes a hybrid framework that ut folds an
Artificial Intelligence and a Microservices approach for the performance
optimization of the system. The AI algorithms forecast demand patterns,
optimize the allocation of resources, and enhance decision-making driven by
Microservices architecture, hence decentralizing system components for
scalability, fault tolerance, and reduced downtime. The model provided focuses
on major problems associated with the travel reservation systems such as
latency of systems, load balancing and data consistency. It endows the systems
with predictive models based on AI improved ability to forecast user demands.
Microservices would also take care of different scales during uneven traffic
patterns. Hence, both aspects ensure better handling of peak loads and spikes
while minimizing delays and ensuring high service quality. A comparison was
made between traditional reservation models, which are monolithic and the new
model of AI-Microservices. Comparatively, the analysis results state that there
is a drastic improvement in processing times where the system uptime and
resource utilization proved the capability of AI and the microservices in
transforming the travel industry in terms of reservation. This research work
focused on AI and Microservices towards real-time optimization, providing
critical insight into how to move forward with practical recommendations for
upgrading travel reservation systems with this technology.

摘要：旅遊產業快速成長，提升了預訂系統中即時最佳化的需求，這個系統可以處理龐大的資料和交易量。本研究提出一個混合架構，它結合人工智慧和微服務方法來最佳化系統效能。人工智慧演算法預測需求模式，最佳化資源配置，並加強由微服務架構驅動的決策制定，因此分散系統元件以利於擴充性、容錯能力和減少停機時間。所提供的模型專注於與旅遊預訂系統相關的主要問題，例如系統延遲、負載平衡和資料一致性。它賦予系統預測模型，基於人工智慧提升預測使用者需求的能力。微服務也會在流量模式不均時處理不同的規模。因此，這兩個面向確保能更好地處理尖峰負載和流量激增，同時將延遲降到最低並確保高服務品質。比較傳統的預訂模型（單體式）和新的 AI-微服務模型。比較之下，分析結果指出處理時間有顯著改善，其中系統正常運行時間和資源使用率證明了人工智慧和微服務在預訂方面轉型旅遊產業的能力。這項研究工作專注於人工智慧和微服務，以實現即時最佳化，提供關鍵見解，說明如何透過實用建議，使用這項技術升級旅遊預訂系統。

##### **Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System**
2412.06600v1 by Yubo Zhou, Weizhen Bian, Kaitai Zhang, Xiaohan Gu

In traditional medical practices, music therapy has proven effective in
treating various psychological and physiological ailments. Particularly in
Eastern traditions, the Five Elements Music Therapy (FEMT), rooted in
traditional Chinese medicine, possesses profound cultural significance and
unique therapeutic philosophies. With the rapid advancement of Information
Technology and Artificial Intelligence, applying these modern technologies to
FEMT could enhance the personalization and cultural relevance of the therapy
and potentially improve therapeutic outcomes. In this article, we developed a
music therapy system for the first time by applying the theory of the five
elements in music therapy to practice. This innovative approach integrates
advanced Information Technology and Artificial Intelligence with Five-Element
Music Therapy (FEMT) to enhance personalized music therapy practices. As
traditional music therapy predominantly follows Western methodologies, the
unique aspects of Eastern practices, specifically the Five-Element theory from
traditional Chinese medicine, should be considered. This system aims to bridge
this gap by utilizing computational technologies to provide a more
personalized, culturally relevant, and therapeutically effective music therapy
experience.

摘要：在傳統的醫療實務中，音樂治療已被證實能有效治療各種心理和生理疾病。特別在東方傳統中，根源於中醫的五行音樂療法（FEMT）具有深遠的文化意義和獨特的治療哲學。隨著資訊科技和人工智慧的快速進展，將這些現代科技應用於 FEMT 能增強治療的個人化和文化相關性，並可能改善治療效果。在本文中，我們首次透過將音樂治療中的五行理論應用於實務，開發出一個音樂治療系統。這種創新的方法將先進的資訊科技和人工智慧與五行音樂療法（FEMT）整合，以增強個人化的音樂治療實務。由於傳統的音樂治療主要遵循西方的做法，因此應考慮東方實務的獨特面向，特別是中醫的五行理論。此系統旨在透過利用運算科技來彌合此差距，提供更個人化、文化相關且治療效果更好的音樂治療體驗。

##### **HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation**
2412.06530v1 by Jiayan Chen, Kai Li, Zhanjin Wang, Zhan Wang, Jianqiang Huang

Hepatic echinococcosis (HE) is a prevalent disease in economically
underdeveloped pastoral areas, where adequate medical resources are usually
lacking. Existing methods often ignore multi-scale feature fusion or focus only
on feature fusion between adjacent levels, which may lead to insufficient
feature fusion. To address these issues, we propose HES-UNet, an efficient and
accurate model for HE lesion segmentation. This model combines convolutional
layers and attention modules to capture local and global features. During
downsampling, the multi-directional downsampling block (MDB) is employed to
integrate high-frequency and low-frequency features, effectively extracting
image details. The multi-scale aggregation block (MAB) aggregates multi-scale
feature information. In contrast, the multi-scale upsampling Block (MUB) learns
highly abstract features and supplies this information to the skip connection
module to fuse multi-scale features. Due to the distinct regional
characteristics of HE, there is currently no publicly available high-quality
dataset for training our model. We collected CT slice data from 268 patients at
a certain hospital to train and evaluate the model. The experimental results
show that HES-UNet achieves state-of-the-art performance on our dataset,
achieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is
1.09% higher than that of TransUNet. The project page is available at
https://chenjiayan-qhu.github.io/HES-UNet-page.

摘要：肝包蟲病（HE）在經濟落後的畜牧地區盛行，那裡通常缺乏足夠的醫療資源。現有方法通常忽略多尺度特徵融合，或僅關注相鄰層之間的特徵融合，這可能導致特徵融合不足。為了解決這些問題，我們提出了 HES-UNet，這是一種用於 HE 病灶分割的高效且準確的模型。此模型結合了卷積層和注意力模組，以擷取局部和全局特徵。在降採樣過程中，採用多向降採樣區塊 (MDB) 來整合高頻和低頻特徵，有效提取影像細節。多尺度聚合區塊 (MAB) 聚合多尺度特徵資訊。相反，多尺度上採樣區塊 (MUB) 會學習高度抽象的特徵，並將此資訊提供給跳躍連接模組，以融合多尺度特徵。由於 HE 的區域特徵不同，目前沒有公開可用的高品質資料集可供訓練我們的模型。我們從某家醫院收集了 268 位患者的 CT 切片資料，以訓練和評估模型。實驗結果表明，HES-UNet 在我們的資料集上達到了最先進的效能，整體 Dice 相似性係數 (DSC) 達到 89.21%，比 TransUNet 高 1.09%。專案頁面可於 https://chenjiayan-qhu.github.io/HES-UNet-page 取得。

##### **Simulating Human-like Daily Activities with Desire-driven Autonomy**
2412.06435v1 by Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang

Existing task-oriented AI agents often depend on explicit instructions or
external rewards, limiting their ability to be driven by intrinsic motivations
like humans. In this paper, we present a desire-driven autonomy framework to
guide a Large Language Model-based (LLM-based) agent to simulate human-like
daily activities. In contrast to previous agents, our Desire-driven Autonomous
Agent (D2A) operates on the principle of intrinsic desire, allowing it to
propose and select tasks that fulfill its motivational framework autonomously.
Inspired by the Theory of Needs, the motivational framework incorporates an
understanding of human-like desires, such as the need for social interaction,
personal fulfillment, and self-care. Utilizing a desire-driven task generation
mechanism, the agent evaluates its current state and takes a sequence of
activities aligned with its intrinsic motivations. Through simulations, we
demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,
contextually relevant daily activities while exhibiting variability and
adaptability similar to human behavior. A comparative analysis with other
LLM-based frameworks demonstrates that our approach significantly enhances the
rationality of the simulated activities.

摘要：現有的任務導向 AI 代理通常依賴明確的指示或外部獎勵，這限制了它們像人類一樣由內在動機驅動的能力。在本文中，我們提出了一個慾望驅動的自主框架，以指導基於大型語言模型 (LLM) 的代理模擬類人的日常活動。與之前的代理不同，我們的慾望驅動自主代理 (D2A) 遵循內在慾望的原則，允許它自主提出和選擇符合其動機框架的任務。受需求理論的啟發，動機框架包含對類人慾望的理解，例如社會互動、個人滿足和自我保健的需要。利用慾望驅動任務生成機制，代理評估其當前狀態並採取一系列與其內在動機一致的活動。通過模擬，我們證明了我們的慾望驅動自主代理 (D2A) 產生了連貫、與上下文相關的日常活動，同時表現出與人類行為相似的可變性和適應性。與其他基於 LLM 的框架進行比較分析表明，我們的做法顯著提高了模擬活動的合理性。

##### **CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images**
2412.06314v1 by Yijie Dang, Weijun Ma, Xiaohu Luo

Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has
emerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical
settings, the segmentation of lung infections from computed tomography images
enables rapid and accurate quantification and diagnosis of COVID-19.
Segmentation of COVID-19 infections in the lungs poses a formidable challenge,
primarily due to the indistinct boundaries and limited contrast presented by
ground glass opacity manifestations. Moreover, the confounding similarity
between infiltrates, lung tissues, and lung walls further complicates this
segmentation task. To address these challenges, this paper introduces a novel
deep network architecture, called CAD-Unet, for segmenting COVID-19 lung
infections. In this architecture, capsule networks are incorporated into the
existing Unet framework. Capsule networks represent a novel network
architecture that differs from traditional convolutional neural networks. They
utilize vectors for information transfer among capsules, facilitating the
extraction of intricate lesion spatial information. Additionally, we design a
capsule encoder path and establish a coupling path between the unet encoder and
the capsule encoder. This design maximizes the complementary advantages of both
network structures while achieving efficient information fusion. \noindent
Finally, extensive experiments are conducted on four publicly available
datasets, encompassing binary segmentation tasks and multi-class segmentation
tasks. The experimental results demonstrate the superior segmentation
performance of the proposed model. The code has been released at:
https://github.com/AmanoTooko-jie/CAD-Unet.

摘要：自 2019 年 COVID-19 大流行爆发以来，医学影像已成为诊断 COVID-19 肺炎的主要方式。在临床环境中，从计算机断层扫描图像中分割肺部感染，可以快速、准确地量化和诊断 COVID-19。分割肺部中的 COVID-19 感染是一个艰巨的挑战，这主要是由于毛玻璃样变现出的边界不清晰且对比度有限。此外，浸润、肺组织和肺壁之间的混淆相似性进一步复杂化了这项分割任务。为了应对这些挑战，本文介绍了一种新颖的深度网络架构，称为 CAD-Unet，用于分割 COVID-19 肺部感染。在此架构中，胶囊网络被纳入现有的 Unet 框架中。胶囊网络代表了一种新颖的网络架构，它不同于传统的卷积神经网络。它们利用向量在胶囊之间进行信息传输，促进了复杂病变空间信息的提取。此外，我们设计了一个胶囊编码器路径，并在 unet 编码器和胶囊编码器之间建立了一个耦合路径。这种设计最大限度地发挥了两种网络结构的互补优势，同时实现了高效的信息融合。\noindent
最后，在四个公开可用的数据集上进行了广泛的实验，包括二进制分割任务和多类分割任务。实验结果证明了所提出模型的卓越分割性能。该代码已发布在：
https://github.com/AmanoTooko-jie/CAD-Unet。

##### **A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder**
2412.06262v1 by Quansong He, Xiaojun Yao, Jun Wu, Zhang Yi, Tao He

In recent years, advanced U-like networks have demonstrated remarkable
performance in medical image segmentation tasks. However, their drawbacks,
including excessive parameters, high computational complexity, and slow
inference speed, pose challenges for practical implementation in scenarios with
limited computational resources. Existing lightweight U-like networks have
alleviated some of these problems, but they often have pre-designed structures
and consist of inseparable modules, limiting their application scenarios. In
this paper, we propose three plug-and-play decoders by employing different
discretization methods of the neural memory Ordinary Differential Equations
(nmODEs). These decoders integrate features at various levels of abstraction by
processing information from skip connections and performing numerical
operations on upward path. Through experiments on the PH2, ISIC2017, and
ISIC2018 datasets, we embed these decoders into different U-like networks,
demonstrating their effectiveness in significantly reducing the number of
parameters and FLOPs while maintaining performance. In summary, the proposed
discretized nmODEs decoders are capable of reducing the number of parameters by
about 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt
to all U-like networks. Our code is available at
https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.

摘要：近年來，先進的 U 型網路在醫學影像分割任務中展現出卓越的表現。然而，它們的缺點包括過多的參數、高運算複雜度和緩慢的推論速度，對在運算資源有限的情況下實際執行構成挑戰。現有的輕量級 U 型網路已經減輕了這些問題，但它們通常有預先設計的結構，並包含不可分離的模組，限制了它們的應用場景。在本文中，我們透過採用神經記憶常微分方程式 (nmODE) 的不同離散化方法，提出了三個即插即用的解碼器。這些解碼器透過處理來自跳躍連接的資訊，並在向上路徑上執行數值運算，整合了不同抽象層級的特徵。透過在 PH2、ISIC2017 和 ISIC2018 資料集上的實驗，我們將這些解碼器嵌入到不同的 U 型網路中，證明它們在顯著減少參數和 FLOP 的同時，還能維持效能。總之，所提出的離散 nmODE 解碼器能夠將參數數量減少約 20% ~ 50%，FLOP 最多減少 74%，同時具備適應所有 U 型網路的潛力。我們的程式碼可以在 https://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks 取得。

##### **MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery**
2412.06211v1 by Qinfeng Zhu, Yuan Fang, Lei Fan

Crack detection is a critical task in structural health monitoring, aimed at
assessing the structural integrity of bridges, buildings, and roads to prevent
potential failures. Vision-based crack detection has become the mainstream
approach due to its ease of implementation and effectiveness. Fusing infrared
(IR) channels with red, green and blue (RGB) channels can enhance feature
representation and thus improve crack detection. However, IR and RGB channels
often differ in resolution. To align them, higher-resolution RGB images
typically need to be downsampled to match the IR image resolution, which leads
to the loss of fine details. Moreover, crack detection performance is
restricted by the limited receptive fields and high computational complexity of
traditional image segmentation networks. Inspired by the recently proposed
Mamba neural architecture, this study introduces a two-stage paradigm called
MSCrackMamba, which leverages Vision Mamba along with a super-resolution
network to address these challenges. Specifically, to align IR and RGB
channels, we first apply super-resolution to IR channels to match the
resolution of RGB channels for data fusion. Vision Mamba is then adopted as the
backbone network, while UperNet is employed as the decoder for crack detection.
Our approach is validated on the large-scale Crack Detection dataset Crack900,
demonstrating an improvement of 3.55% in mIoU compared to the best-performing
baseline methods.

摘要：裂縫偵測在結構健康監測中是一項重要的任務，旨在評估橋樑、建築物和道路的結構完整性，以防止潛在的故障。基於視覺的裂縫偵測由於其易於實作和有效性，已成為主流方法。將紅外線 (IR) 通道與紅色、綠色和藍色 (RGB) 通道融合可以增強特徵表示，進而改善裂縫偵測。然而，IR 和 RGB 通道通常解析度不同。為了對齊它們，通常需要對較高解析度的 RGB 影像進行降採樣以匹配 IR 影像解析度，這會導致精細細節的遺失。此外，裂縫偵測效能受到傳統影像分割網路有限的感受野和高運算複雜度的限制。受近期提出的 Mamba 神經架構啟發，本研究引入了一個稱為 MSCrackMamba 的兩階段範例，它利用 Vision Mamba 和超解析度網路來應對這些挑戰。具體來說，為了對齊 IR 和 RGB 通道，我們首先對 IR 通道應用超解析度，以匹配 RGB 通道的解析度，以進行資料融合。然後採用 Vision Mamba 作為骨幹網路，同時採用 UperNet 作為裂縫偵測的解碼器。我們的做法已在大型裂縫偵測資料集 Crack900 中得到驗證，與效能最佳的基準方法相比，mIoU 提升了 3.55%。

##### **Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction**
2412.06860v1 by Guoxiao Zhang, Yi Wei, Yadong Zhang, Huajian Feng, Qiang Liu

Click-Through Rate (CTR) prediction is essential in online advertising, where
semantic information plays a pivotal role in shaping user decisions and
enhancing CTR effectiveness. Capturing and modeling deep semantic information,
such as a user's preference for "H\"aagen-Dazs' HEAVEN strawberry light ice
cream" due to its health-conscious and premium attributes, is challenging.
Traditional semantic modeling often overlooks these intricate details at the
user and item levels. To bridge this gap, we introduce a novel approach that
models deep semantic information end-to-end, leveraging the comprehensive world
knowledge capabilities of Large Language Models (LLMs). Our proposed
LLM-infused CTR prediction framework(Multi-level Deep Semantic Information
Infused CTR model via Distillation, MSD) is designed to uncover deep semantic
insights by utilizing LLMs to extract and distill critical information into a
smaller, more efficient model, enabling seamless end-to-end training and
inference. Importantly, our framework is carefully designed to balance
efficiency and effectiveness, ensuring that the model not only achieves high
performance but also operates with optimal resource utilization. Online A/B
tests conducted on the Meituan sponsored-search system demonstrate that our
method significantly outperforms baseline models in terms of Cost Per Mile
(CPM) and CTR, validating its effectiveness, scalability, and balanced approach
in real-world applications.

摘要：點擊率 (CTR) 預測在線上廣告中至關重要，其中語意資訊在塑造使用者決策和提升 CTR 效益方面扮演著關鍵角色。擷取和建模深入的語意資訊（例如使用者偏好「H\"aagen-Dazs' HEAVEN 草莓輕盈冰淇淋」，因為它具有注重健康和高級的屬性）是一項挑戰。傳統的語意建模通常會忽略使用者和項目層級的這些複雜細節。為了彌補此差距，我們提出了一種創新的方法，該方法可以端對端地建模深入語意資訊，並利用大型語言模型 (LLM) 的全面世界知識能力。我們提出的 LLM 注入 CTR 預測架構（透過知識萃取的多層級深入語意資訊注入 CTR 模型，MSD）旨在透過利用 LLM 萃取和提煉關鍵資訊到一個更小、更有效率的模型中，來發掘深入的語意洞察，實現無縫端對端訓練和推論。重要的是，我們的架構經過仔細設計，以平衡效率和效能，確保模型不僅能達成高性能，還能以最佳資源利用率運作。在美團贊助搜尋系統上進行的線上 A/B 測試證明，我們的模型在每千次成本 (CPM) 和 CTR 方面顯著優於基線模型，驗證了其在實際應用中的有效性、可擴充性和平衡方法。

##### **MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization**
2412.06141v1 by Kangyu Zhu, Peng Xia, Yun Li, Hongtu Zhu, Sheng Wang, Huaxiu Yao

The advancement of Large Vision-Language Models (LVLMs) has propelled their
application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter
factuality challenges due to modality misalignment, where the models prioritize
textual knowledge over visual input, leading to hallucinations that contradict
information in medical images. Previous attempts to enhance modality alignment
in Med-LVLMs through preference optimization have inadequately mitigated
clinical relevance in preference data, making these samples easily
distinguishable and reducing alignment effectiveness. To address this
challenge, we propose MMedPO, a novel multimodal medical preference
optimization approach that considers the clinical relevance of preference
samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference
data by introducing two types of dispreference: (1) plausible hallucinations
injected through target Med-LVLMs or GPT-4o to produce medically inaccurate
responses, and (2) lesion region neglect achieved through local lesion-noising,
disrupting visual understanding of critical areas. We then calculate clinical
relevance for each sample based on scores from multiple Med-LLMs and visual
tools, and integrate these scores into the preference optimization process as
weights, enabling effective alignment. Our experiments demonstrate that MMedPO
significantly enhances factual accuracy in Med-LVLMs, achieving substantial
improvements over existing preference optimization methods by averaging 14.2%
and 51.7% across the Med-VQA and report generation tasks. Our code are
available in https://github.com/aiming-lab/MMedPO.

摘要：大型視覺語言模型 (LVLMs) 的進步推動了它們在醫療領域的應用。然而，醫學 LVLMs (Med-LVLMs) 由於模態錯位而遇到事實挑戰，其中模型優先考慮文字知識而非視覺輸入，導致幻覺與醫學影像中的資訊相矛盾。先前嘗試透過偏好最佳化來增強 Med-LVLMs 中的模態對齊，在偏好資料中不足以減輕臨床相關性，使得這些範例容易區分，並降低對齊效果。為了應對這項挑戰，我們提出 MMedPO，一種新的多模態醫學偏好最佳化方法，它考慮偏好範例的臨床相關性，以增強 Med-LVLM 對齊。MMedPO 透過引入兩種類型的反偏好來管理多模態偏好資料：(1) 合理的幻覺透過目標 Med-LVLMs 或 GPT-4o 注入，以產生醫學上不準確的回應，以及 (2) 透過局部病灶雜訊實現病灶區域忽略，破壞對關鍵區域的視覺理解。然後，我們根據來自多個 Med-LLMs 和視覺工具的分數計算每個範例的臨床相關性，並將這些分數作為權重整合到偏好最佳化過程中，以實現有效對齊。我們的實驗證明，MMedPO 明顯增強了 Med-LVLMs 中的事實準確性，在 Med-VQA 和報告生成任務中，平均分別比現有的偏好最佳化方法提高了 14.2% 和 51.7%。我們的程式碼可以在 https://github.com/aiming-lab/MMedPO 中取得。

##### **Imputation Matters: A Deeper Look into an Overlooked Step in Longitudinal Health and Behavior Sensing Research**
2412.06018v1 by Akshat Choube, Rahul Majethia, Sohini Bhattacharya, Vedant Das Swain, Jiachen Li, Varun Mishra

Longitudinal passive sensing studies for health and behavior outcomes often
have missing and incomplete data. Handling missing data effectively is thus a
critical data processing and modeling step. Our formative interviews with
researchers working in longitudinal health and behavior passive sensing
revealed a recurring theme: most researchers consider imputation a low-priority
step in their analysis and inference pipeline, opting to use simple and
off-the-shelf imputation strategies without comprehensively evaluating its
impact on study outcomes. Through this paper, we call attention to the
importance of imputation. Using publicly available passive sensing datasets for
depression, we show that prioritizing imputation can significantly impact the
study outcomes -- with our proposed imputation strategies resulting in up to
31% improvement in AUROC to predict depression over the original imputation
strategy. We conclude by discussing the challenges and opportunities with
effective imputation in longitudinal sensing studies.

摘要：縱向被動感測研究對於健康和行為結果常常有缺失和不完整的資料。有效處理缺失資料因此是資料處理和建模的重要步驟。我們與從事縱向健康和行為被動感測的研究人員進行的形成性訪談揭露了一個反覆出現的主題：大多數研究人員認為內插是其分析和推論流程中優先順序較低的一個步驟，選擇使用簡單且現成的內插策略，而沒有全面評估其對研究結果的影響。透過這篇論文，我們呼籲重視內插。使用公開的被動感測資料集進行憂鬱症研究，我們證明優先考慮內插會對研究結果產生重大影響——我們提出的內插策略使 AUROC 預測憂鬱症的能力比原始內插策略提高了 31%。最後，我們討論了在縱向感測研究中有效內插的挑戰和機會。

##### **MG-3D: Multi-Grained Knowledge-Enhanced 3D Medical Vision-Language Pre-training**
2412.05876v1 by Xuefeng Ni, Linshan Wu, Jiaxin Zhuang, Qiong Wang, Mingxiang Wu, Varut Vardhanabhuti, Lihai Zhang, Hanyu Gao, Hao Chen

3D medical image analysis is pivotal in numerous clinical applications.
However, the scarcity of labeled data and limited generalization capabilities
hinder the advancement of AI-empowered models. Radiology reports are easily
accessible and can serve as weakly-supervised signals. However, large-scale
vision-language pre-training (VLP) remains underexplored in 3D medical image
analysis. Specifically, the insufficient investigation into multi-grained
radiology semantics and their correlations across patients leads to
underutilization of large-scale volume-report data.
  Considering intra-patient cross-modal semantic consistency and inter-patient
semantic correlations, we propose a multi-task VLP method, MG-3D, pre-trained
on large-scale data (47.1K), addressing the challenges by the following two
aspects: 1) Establishing the correspondence between volume semantics and
multi-grained medical knowledge of each patient with cross-modal global
alignment and complementary modality-guided local reconstruction, ensuring
intra-patient features of different modalities cohesively represent the same
semantic content; 2) Correlating inter-patient visual semantics based on
fine-grained report correlations across patients, and keeping sensitivity to
global individual differences via contrastive learning, enhancing the
discriminative feature representation. Furthermore, we delve into the scaling
law to explore potential performance improvements. Comprehensive evaluations
across nine uni- and cross-modal clinical tasks are carried out to assess model
efficacy. Extensive experiments on both internal and external datasets
demonstrate the superior transferability, scalability, and generalization of
MG-3D, showcasing its potential in advancing feature representation for 3D
medical image analysis. Code will be available:
https://github.com/Xuefeng-Ni/MG-3D.

摘要：<paragraph>3D 醫學影像分析在眾多臨床應用中至關重要。
然而，標記資料的稀缺和有限的概化能力
阻礙了 AI 賦能模型的進步。放射報告容易獲得，可以用作弱監督信號。然而，大規模
視覺語言預訓練 (VLP) 在 3D 醫學影像
分析中仍未得到充分探索。具體來說，對多粒度
放射語義及其在患者之間的相關性研究不足，導致大規模體積報告數據利用不足。
考慮到患者內部跨模態語義一致性和患者間
語義相關性，我們提出了一種多任務 VLP 方法 MG-3D，預訓練
在大型數據 (47.1K) 上，通過以下兩個方面解決挑戰：1) 建立體積語義和
每個患者的多粒度醫學知識之間的對應關係，通過跨模態全局
對齊和互補模態引導的局部重建，確保不同模態的患者內部特徵一致地表示相同的
語義內容；2) 基於患者之間的細粒度報告相關性對患者間的視覺語義進行關聯，並通過對比學習保持對
全局個體差異的敏感性，增強判別特徵表示。此外，我們深入研究了擴展
定律以探索潛在的性能改進。跨越九項單模態和跨模態臨床任務的綜合評估是進行的，以評估模型
效能。在內部和外部數據集上的廣泛實驗
證明了 MG-3D 的卓越可傳遞性、可擴展性和泛化性，展示了其在推進 3D
醫學影像分析特徵表示方面的潛力。代碼將提供：
https://github.com/Xuefeng-Ni/MG-3D。</paragraph>

##### **Evolving Algebraic Multigrid Methods Using Grammar-Guided Genetic Programming**
2412.05852v1 by Dinesh Parthasarathy, Wayne Bradford Mitchell, Harald Köstler

Multigrid methods despite being known to be asymptotically optimal
algorithms, depend on the careful selection of their individual components for
efficiency. Also, they are mostly restricted to standard cycle types like V-,
F-, and W-cycles. We use grammar rules to generate arbitrary-shaped cycles,
wherein the smoothers and their relaxation weights are chosen independently at
each step within the cycle. We call this a flexible multigrid cycle. These
flexible cycles are used in Algebraic Multigrid (AMG) methods with the help of
grammar rules and optimized using genetic programming. The flexible AMG methods
are implemented in the software library of hypre, and the programs are
optimized separately for two cases: a standalone AMG solver for a 3D
anisotropic problem and an AMG preconditioner with conjugate gradient for a
multiphysics code. We observe that the optimized flexible cycles provide higher
efficiency and better performance than the standard cycle types.

摘要：多重網格法儘管已知為漸近最佳演算法，但其效率取決於其個別組成的仔細選擇。此外，它們大多侷限於標準循環類型，例如 V、F 和 W 循環。我們使用語法規則來產生任意形狀的循環，其中平滑器及其鬆弛權重在循環中的每個步驟中獨立選擇。我們稱之為彈性多重網格循環。這些彈性循環在代數多重網格 (AMG) 方法中使用，並在語法規則的幫助下使用遺傳程式設計進行最佳化。彈性 AMG 方法在 hypre 的軟體程式庫中實作，且程式針對兩種情況分別最佳化：3D 異向性問題的獨立 AMG 求解器，以及多物理場程式碼的共軛梯度 AMG 預處理器。我們觀察到最佳化的彈性循環提供比標準循環類型更高的效率和更好的效能。

##### **Biological Brain Age Estimation using Sex-Aware Adversarial Variational Autoencoder with Multimodal Neuroimages**
2412.05632v1 by Abd Ur Rehman, Azka Rehman, Muhammad Usman, Abdullah Shahid, Sung-Min Gho, Aleum Lee, Tariq M. Khan, Imran Razzak

Brain aging involves structural and functional changes and therefore serves
as a key biomarker for brain health. Combining structural magnetic resonance
imaging (sMRI) and functional magnetic resonance imaging (fMRI) has the
potential to improve brain age estimation by leveraging complementary data.
However, fMRI data, being noisier than sMRI, complicates multimodal fusion.
Traditional fusion methods often introduce more noise than useful information,
which can reduce accuracy compared to using sMRI alone. In this paper, we
propose a novel multimodal framework for biological brain age estimation,
utilizing a sex-aware adversarial variational autoencoder (SA-AVAE). Our
framework integrates adversarial and variational learning to effectively
disentangle the latent features from both modalities. Specifically, we
decompose the latent space into modality-specific codes and shared codes to
represent complementary and common information across modalities, respectively.
To enhance the disentanglement, we introduce cross-reconstruction and
shared-distinct distance ratio loss as regularization terms. Importantly, we
incorporate sex information into the learned latent code, enabling the model to
capture sex-specific aging patterns for brain age estimation via an integrated
regressor module. We evaluate our model using the publicly available OpenBHB
dataset, a comprehensive multi-site dataset for brain age estimation. The
results from ablation studies and comparisons with state-of-the-art methods
demonstrate that our framework outperforms existing approaches and shows
significant robustness across various age groups, highlighting its potential
for real-time clinical applications in the early detection of neurodegenerative
diseases.

摘要：大腦老化涉及結構和功能的改變，因此可作為大腦健康的關鍵生物標記。結合結構性磁振造影 (sMRI) 和功能性磁振造影 (fMRI) 有可能透過利用互補數據來改善大腦年齡估計。然而，fMRI 資料比 sMRI 雜訊更多，這使得多模態融合變得複雜。傳統融合方法通常會引入比有用資訊更多雜訊，這可能會降低與單獨使用 sMRI 相比的準確性。在本文中，我們提出一個用於生物大腦年齡估計的新多模態框架，利用一個有性別意識的對抗變異自動編碼器 (SA-AVAE)。我們的框架整合了對抗和變異學習，以有效地解開來自兩種模態的潛在特徵。具體而言，我們將潛在空間分解為特定於模態的代碼和共享代碼，分別表示跨模態的互補和共同資訊。為了增強解開，我們引入了交叉重建和共享不同距離比率損失作為正則化項。重要的是，我們將性別資訊納入學習到的潛在代碼中，使模型能夠透過整合回歸模組，捕捉特定於性別的老化模式，以進行大腦年齡估計。我們使用公開可用的 OpenBHB 資料集評估我們的模型，這是一個用於大腦年齡估計的綜合多場域資料集。消融研究和與最先進方法的比較結果表明，我們的框架優於現有方法，並在各個年齡組中顯示出顯著的穩健性，突顯了其在神經退化性疾病早期檢測中的即時臨床應用潛力。

##### **UNet++ and LSTM combined approach for Breast Ultrasound Image Segmentation**
2412.05585v1 by Saba Hesaraki, Morteza Akbari, Ramin Mousa

Breast cancer stands as a prevalent cause of fatality among females on a
global scale, with prompt detection playing a pivotal role in diminishing
mortality rates. The utilization of ultrasound scans in the BUSI dataset for
medical imagery pertaining to breast cancer has exhibited commendable
segmentation outcomes through the application of UNet and UNet++ networks.
Nevertheless, a notable drawback of these models resides in their inattention
towards the temporal aspects embedded within the images. This research
endeavors to enrich the UNet++ architecture by integrating LSTM layers and
self-attention mechanisms to exploit temporal characteristics for segmentation
purposes. Furthermore, the incorporation of a Multiscale Feature Extraction
Module aims to grasp varied scale features within the UNet++. Through the
amalgamation of our proposed methodology with data augmentation on the BUSI
with GT dataset, an accuracy rate of 98.88%, specificity of 99.53%, precision
of 95.34%, sensitivity of 91.20%, F1-score of 93.74, and Dice coefficient of
92.74% are achieved. These findings demonstrate competitiveness with
cutting-edge techniques outlined in existing literature.

摘要：乳癌是全球女性死亡的主要原因，及早發現對於降低死亡率扮演關鍵角色。在 BUSI 資料集中使用超音波掃描進行乳癌相關的醫學影像，透過應用 UNet 和 UNet++ 網路已展現出令人滿意的分割結果。然而，這些模型一個顯著的缺點在於它們忽略了影像中包含的時間面向。本研究致力於透過整合 LSTM 層和自我注意機制來豐富 UNet++ 架構，以利用時間特徵進行分割。此外，整合多尺度特徵萃取模組旨在掌握 UNet++ 中各種尺度的特徵。透過將我們提出的方法與 BUSI with GT 資料集上的資料擴充結合，達到了 98.88% 的準確率、99.53% 的特異性、95.34% 的精確度、91.20% 的敏感度、93.74 的 F1 分數，以及 92.74% 的 Dice 係數。這些發現證明了與現有文獻中概述的尖端技術具有競爭力。

##### **Electrocardiogram (ECG) Based Cardiac Arrhythmia Detection and Classification using Machine Learning Algorithms**
2412.05583v2 by Atit Pokharel, Shashank Dahal, Pratik Sapkota, Bhupendra Bimal Chhetri

The rapid advancements in Artificial Intelligence, specifically Machine
Learning (ML) and Deep Learning (DL), have opened new prospects in medical
sciences for improved diagnosis, prognosis, and treatment of severe health
conditions. This paper focuses on the development of an ML model with high
predictive accuracy to classify arrhythmic electrocardiogram (ECG) signals. The
ECG signals datasets utilized in this study were sourced from the PhysioNet and
MIT-BIH databases. The research commenced with binary classification, where an
optimized Bidirectional Long Short-Term Memory (Bi-LSTM) model yielded
excellent results in differentiating normal and atrial fibrillation signals. A
pivotal aspect of this research was a survey among medical professionals, which
not only validated the practicality of AI-based ECG classifiers but also
identified areas for improvement, including accuracy and the inclusion of more
arrhythmia types. These insights drove the development of an advanced
Convolutional Neural Network (CNN) system capable of classifying five different
types of ECG signals with better accuracy and precision. The CNN model's robust
performance was ensured through rigorous stratified 5-fold cross validation. A
web portal was also developed to demonstrate real-world utility, offering
access to the trained model for real-time classification. This study highlights
the potential applications of such models in remote health monitoring,
predictive healthcare, assistive diagnostic tools, and simulated environments
for educational training and interdisciplinary collaboration between data
scientists and medical personnel.

摘要：人工智慧的快速進展，特別是機器學習（ML）和深度學習（DL），為醫學科學開闢了新的前景，以改善嚴重健康狀況的診斷、預後和治療。本文重點在於開發具有高預測精度的 ML 模型，用於分類心律不整心電圖 (ECG) 信號。本研究中使用的 ECG 信號資料集來自 PhysioNet 和 MIT-BIH 資料庫。研究從二元分類開始，其中經過最佳化的雙向長短期記憶 (Bi-LSTM) 模型在區分正常和心房顫動信號方面產生了極佳的結果。本研究的一個關鍵方面是針對醫護專業人員進行的調查，這不僅驗證了基於 AI 的 ECG 分類器的實用性，還找出改進領域，包括準確性和納入更多心律不整類型。這些見解推動了先進卷積神經網路 (CNN) 系統的開發，該系統能夠以更高的準確度和精確度對五種類型的 ECG 信號進行分類。透過嚴格的分層 5 倍交叉驗證，確保了 CNN 模型的強健效能。還開發了一個網路入口網站來展示真實世界的效用，提供存取已訓練模型以進行即時分類。本研究強調了此類模型在遠距健康監測、預測性醫療保健、輔助診斷工具以及用於教育訓練和資料科學家與醫護人員之間跨領域合作的模擬環境中的潛在應用。

##### **Comprehensive Evaluation of Multimodal AI Models in Medical Imaging Diagnosis: From Data Augmentation to Preference-Based Comparison**
2412.05536v1 by Cailian Ruan, Chengyue Huang, Yahe Yang

This study introduces an evaluation framework for multimodal models in
medical imaging diagnostics. We developed a pipeline incorporating data
preprocessing, model inference, and preference-based evaluation, expanding an
initial set of 500 clinical cases to 3,000 through controlled augmentation. Our
method combined medical images with clinical observations to generate
assessments, using Claude 3.5 Sonnet for independent evaluation against
physician-authored diagnoses. The results indicated varying performance across
models, with Llama 3.2-90B outperforming human diagnoses in 85.27% of cases. In
contrast, specialized vision models like BLIP2 and Llava showed preferences in
41.36% and 46.77% of cases, respectively. This framework highlights the
potential of large multimodal models to outperform human diagnostics in certain
tasks.

摘要：本研究引入了一個用於醫療影像診斷中多模態模型的評估框架。我們開發了一個結合了資料前處理、模型推論和基於偏好的評估的管道，透過受控擴充將最初的 500 個臨床案例擴充到 3,000 個。我們的做法結合了醫學影像和臨床觀察，以產生評估，使用 Claude 3.5 Sonnet 對抗醫師撰寫的診斷進行獨立評估。結果顯示不同模型的表現不同，其中 Llama 3.2-90B 在 85.27% 的案例中優於人類診斷。相比之下，專門的視覺模型，例如 BLIP2 和 Llava，分別在 41.36% 和 46.77% 的案例中顯示出偏好。此框架突顯了大型多模態模型在某些任務中優於人類診斷的潛力。

##### **Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System**
2412.06828v1 by Fang Zeng, Zhiliang Lyu, Quanzheng Li, Xiang Li

This study introduces "RadCouncil," a multi-agent Large Language Model (LLM)
framework designed to enhance the generation of impressions in radiology
reports from the finding section. RadCouncil comprises three specialized
agents: 1) a "Retrieval" Agent that identifies and retrieves similar reports
from a vector database, 2) a "Radiologist" Agent that generates impressions
based on the finding section of the given report plus the exemplar reports
retrieved by the Retrieval Agent, and 3) a "Reviewer" Agent that evaluates the
generated impressions and provides feedback. The performance of RadCouncil was
evaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and
qualitative criteria assessed by GPT-4, using chest X-ray as a case study.
Experiment results show improvements in RadCouncil over the single-agent
approach across multiple dimensions, including diagnostic accuracy, stylistic
concordance, and clarity. This study highlights the potential of utilizing
multiple interacting LLM agents, each with a dedicated task, to enhance
performance in specialized medical tasks and the development of more robust and
adaptable healthcare AI solutions.

摘要：本研究引入了「RadCouncil」，一個多重代理大型語言模型 (LLM)
框架，旨在增強放射科報告中印象的產生，特別是發現部分。RadCouncil 包含三個專門的代理：1) 一個「檢索」代理，用於識別並從向量資料庫中檢索類似的報告，2) 一個「放射科醫師」代理，用於根據給定報告的發現部分加上檢索代理檢索到的範例報告，產生印象，以及 3) 一個「審查者」代理，用於評估產生的印象並提供回饋。RadCouncil 的效能使用量化指標 (BLEU、ROUGE、BERTScore) 進行評估，並使用胸部 X 光作為案例研究，由 GPT-4 評估質化標準。實驗結果顯示，RadCouncil 在多個面向都有改進，包括診斷準確性、風格一致性，以及清晰度，優於單一代理方法。本研究強調了利用多個互動式 LLM 代理的潛力，每個代理都有專門的任務，以增強在專業醫療任務中的效能，並開發更強健且適應性更強的醫療保健 AI 解決方案。

##### **Enhancing FKG.in: automating Indian food composition analysis**
2412.05248v2 by Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta Trilok-Kumar, Ramesh Jain

This paper presents a novel approach to compute food composition data for
Indian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The
primary focus is to provide a broad overview of an automated food composition
analysis workflow and describe its core functionalities: nutrition data
aggregation, food composition analysis, and LLM-augmented information
resolution. This workflow aims to complement FKG.in and iteratively supplement
food composition data from verified knowledge bases. Additionally, this paper
highlights the challenges of representing Indian food and accessing food
composition data digitally. It also reviews three key sources of food
composition data: the Indian Food Composition Tables, the Indian Nutrient
Databank, and the Nutritionix API. Furthermore, it briefly outlines how users
can interact with the workflow to obtain diet-based health recommendations and
detailed food composition information for numerous recipes. We then explore the
complex challenges of analyzing Indian recipe information across dimensions
such as structure, multilingualism, and uncertainty as well as present our
ongoing work on LLM-based solutions to address these issues. The methods
proposed in this workshop paper for AI-driven knowledge curation and
information resolution are application-agnostic, generalizable, and replicable
for any domain.

摘要：本文提出了一個創新的方法，使用印度食品知識圖譜 (FKG.in) 和 LLM 來計算印度食譜的食品成分數據。主要重點是提供自動化食品成分分析工作流程的廣泛概述，並描述其核心功能：營養數據彙總、食品成分分析和 LLM 增強的信息解析。此工作流程旨在補充 FKG.in，並反覆補充來自驗證知識庫的食品成分數據。此外，本文重點介紹了表示印度食品和以數位方式存取食品成分數據的挑戰。它還回顧了食品成分數據的三個關鍵來源：印度食品成分表、印度營養資料庫和 Nutritionix API。此外，它簡要概述了使用者如何與工作流程互動以獲得基於飲食的健康建議和大量食譜的詳細食品成分資訊。然後，我們探討了分析印度食譜資訊在結構、多語言和不確定性等方面的複雜挑戰，並展示我們在基於 LLM 的解決方案上進行的持續工作，以解決這些問題。本文研討會論文中提出的 AI 驅動知識策展和資訊解析方法與應用程式無關，可概括且可複製到任何領域。

##### **Are Frontier Large Language Models Suitable for Q&A in Science Centres?**
2412.05200v1 by Jacob Watson, Fabrício Góes, Marco Volpe, Talles Medeiros

This paper investigates the suitability of frontier Large Language Models
(LLMs) for Q&A interactions in science centres, with the aim of boosting
visitor engagement while maintaining factual accuracy. Using a dataset of
questions collected from the National Space Centre in Leicester (UK), we
evaluated responses generated by three leading models: OpenAI's GPT-4, Claude
3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard
and creative responses tailored to an 8-year-old audience, and these responses
were assessed by space science experts based on accuracy, engagement, clarity,
novelty, and deviation from expected answers. The results revealed a trade-off
between creativity and accuracy, with Claude outperforming GPT and Gemini in
both maintaining clarity and engaging young audiences, even when asked to
generate more creative responses. Nonetheless, experts observed that higher
novelty was generally associated with reduced factual reliability across all
models. This study highlights the potential of LLMs in educational settings,
emphasizing the need for careful prompt engineering to balance engagement with
scientific rigor.

摘要：這篇論文探討前沿大型語言模型 (LLM) 在科學中心問答互動中的適用性，目的是在維持事實準確性的同時提升訪客參與度。我們使用從英國萊斯特國家太空中心收集的提問資料集，評估了三個領先模型生成的回應：OpenAI 的 GPT-4、Claude 3.5 Sonnet 和 Google Gemini 1.5。每個模型都被提示針對 8 歲的受眾量身打造標準和有創意的回應，而這些回應則由太空科學專家根據準確性、參與度、清晰度、新穎性和與預期答案的偏差進行評估。結果顯示創造力與準確性之間存在權衡，Claude 在維持清晰度和吸引年輕受眾方面優於 GPT 和 Gemini，即使被要求產生更多有創意的回應。儘管如此，專家們觀察到，所有模型中較高的新穎性通常與較低的實際可靠性相關。這項研究強調了 LLM 在教育環境中的潛力，並強調需要仔細提示工程以平衡參與度和科學嚴謹性。

##### **SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot**
2412.05187v1 by Jinlin Wu, Xusheng Liang, Xuexue Bai, Zhen Chen

Surgical interventions, particularly in neurology, represent complex and
high-stakes scenarios that impose substantial cognitive burdens on surgical
teams. Although deliberate education and practice can enhance cognitive
capabilities, surgical training opportunities remain limited due to patient
safety concerns. To address these cognitive challenges in surgical training and
operation, we propose SurgBox, an agent-driven sandbox framework to
systematically enhance the cognitive capabilities of surgeons in immersive
surgical simulations. Specifically, our SurgBox leverages large language models
(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically
replicate various surgical roles, enabling realistic training environments for
deliberate practice. In particular, we devise Surgery Copilot, an AI-driven
assistant to actively coordinate the surgical information stream and support
clinical decision-making, thereby diminishing the cognitive workload of
surgical teams during surgery. By incorporating a novel Long-Short Memory
mechanism, our Surgery Copilot can effectively balance immediate procedural
assistance with comprehensive surgical knowledge. Extensive experiments using
real neurosurgical procedure records validate our SurgBox framework in both
enhancing surgical cognitive capabilities and supporting clinical
decision-making. By providing an integrated solution for training and
operational support to address cognitive challenges, our SurgBox framework
advances surgical education and practice, potentially transforming surgical
outcomes and healthcare quality. The code is available at
https://github.com/franciszchen/SurgBox.

摘要：外科手術，特別是在神經外科，代表了複雜且高風險的場景，對外科團隊施加了巨大的認知負擔。儘管經過深思熟慮的教育和實踐可以增強認知能力，但由於患者安全問題，外科培訓機會仍然有限。為了應對外科培訓和手術中的這些認知挑戰，我們提出了 SurgBox，一個由代理驅動的沙盒框架，用於系統地增強外科醫生在沉浸式外科模擬中的認知能力。具體來說，我們的 SurgBox 利用大型語言模型 (LLM) 和量身定制的檢索增強生成 (RAG) 來真實地複製各種外科角色，為深思熟慮的實踐提供逼真的培訓環境。特別是，我們設計了手術副駕駛，一個由 AI 驅動的助手，用於主動協調外科信息流並支持臨床決策制定，從而減少外科團隊在手術期間的認知負擔。通過結合一種新穎的長短期記憶機制，我們的 Surgery Copilot 可以有效地平衡即時程序協助和全面的外科知識。使用真實的神經外科手術記錄進行的廣泛實驗驗證了我們的 SurgBox 框架，既能增強外科認知能力，又能支持臨床決策制定。通過提供一個綜合的培訓和運營支持解決方案來應對認知挑戰，我們的 SurgBox 框架推動了外科教育和實踐，有可能改變外科結果和醫療保健質量。代碼可在 https://github.com/franciszchen/SurgBox 獲得。

##### **Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector**
2412.05013v1 by Thomas Sievers, Nele Russwinkel

Is it possible to integrate a humanoid social robot into the work processes
or customer care in an official environment, e.g. in municipal offices? If so,
what could such an application scenario look like and what skills would the
robot need to have when interacting with human customers? What are requirements
for this kind of interactions? We have devised an application scenario for such
a case, determined the necessary or desirable capabilities of the robot,
developed a corresponding robot application and carried out initial tests and
evaluations in a project together with the Kiel City Council. One of the most
important insights gained in the project was that a humanoid robot with natural
language processing capabilities based on large language models as well as
human-like gestures and posture changes (animations) proved to be much more
preferred by users compared to standard browser-based solutions on tablets for
an information system in the City Council. Furthermore, we propose a connection
of the ACT-R cognitive architecture with the robot, where an ACT-R model is
used in interaction with the robot application to cognitively process and
enhance a dialogue between human and robot.

摘要：是否可能將類人社會機器人整合到工作流程或官方環境中的客戶服務中，例如市政辦公室？如果是這樣，這樣的應用場景可能會是什麼樣子，而機器人在與人類客戶互動時需要具備哪些技能？這種互動有哪些要求？我們為這種情況設計了一個應用場景，確定了機器人必要或理想的能力，開發了一個對應的機器人應用程式，並與基爾市議會共同在一個專案中進行了初步測試和評估。該專案獲得的最重要見解之一是，與平板電腦上用於市議會資訊系統的標準瀏覽器解決方案相比，具有人工語言處理能力（基於大型語言模型）以及類人的手勢和姿勢變化（動畫）的類人機器人被使用者更為青睞。此外，我們建議將 ACT-R 認知架構與機器人連接起來，其中 ACT-R 模型用於與機器人應用程式互動，以認知處理和增強人與機器人之間的對話。

##### **Backdooring Outlier Detection Methods: A Novel Attack Approach**
2412.05010v1 by ZeinabSadat Taghavi, Hossein Mirzaei

There have been several efforts in backdoor attacks, but these have primarily
focused on the closed-set performance of classifiers (i.e., classification).
This has left a gap in addressing the threat to classifiers' open-set
performance, referred to as outlier detection in the literature. Reliable
outlier detection is crucial for deploying classifiers in critical real-world
applications such as autonomous driving and medical image analysis. First, we
show that existing backdoor attacks fall short in affecting the open-set
performance of classifiers, as they have been specifically designed to confuse
intra-closed-set decision boundaries. In contrast, an effective backdoor attack
for outlier detection needs to confuse the decision boundary between the closed
and open sets. Motivated by this, in this study, we propose BATOD, a novel
Backdoor Attack targeting the Outlier Detection task. Specifically, we design
two categories of triggers to shift inlier samples to outliers and vice versa.
We evaluate BATOD using various real-world datasets and demonstrate its
superior ability to degrade the open-set performance of classifiers compared to
previous attacks, both before and after applying defenses.

摘要：對於後門攻擊已經有幾項努力，但這些主要集中在分類器的閉集效能（即分類）上。這使得在處理分類器開放集效能的威脅上出現了一個缺口，在文獻中稱為異常值偵測。可靠的異常值偵測對於在關鍵的真實世界應用中部署分類器至關重要，例如自動駕駛和醫學影像分析。首先，我們展示現有的後門攻擊在影響分類器的開放集效能方面不足，因為它們被特別設計用來混淆閉集內決策邊界。相比之下，有效的異常值偵測後門攻擊需要混淆閉集和開放集之間的決策邊界。有鑑於此，在本研究中，我們提出 BATOD，一種針對異常值偵測任務的新型後門攻擊。具體來說，我們設計了兩種類型的觸發器，將內點樣本轉移到異常值，反之亦然。我們使用各種真實世界資料集評估 BATOD，並展示了它在降低分類器的開放集效能方面的優異能力，與之前在應用防禦措施之前和之後的攻擊相比。

##### **Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes**
2412.04950v1 by Thomas Bartz-Beielstein, Axel Wellendorf, Noah Pütz, Jens Brandt, Alexander Hinterleitner, Richard Schulz, Richard Scholz, Olaf Mersmann, Robin Knabe

The increasing shortage of nursing staff and the acute risk of falls in
nursing homes pose significant challenges for the healthcare system. This study
presents the development of an automated fall detection system integrated into
care beds, aimed at enhancing patient safety without compromising privacy
through wearables or video monitoring. Mechanical vibrations transmitted
through the bed frame are processed using a short-time Fourier transform,
enabling robust classification of distinct human fall patterns with a
convolutional neural network. Challenges pertaining to the quantity and
diversity of the data are addressed, proposing the generation of additional
data with a specific emphasis on enhancing variation. While the model shows
promising results in distinguishing fall events from noise using lab data,
further testing in real-world environments is recommended for validation and
improvement. Despite limited available data, the proposed system shows the
potential for an accurate and rapid response to falls, mitigating health
implications, and addressing the needs of an aging population. This case study
was performed as part of the ZIM Project. Further research on sensors enhanced
by artificial intelligence will be continued in the ShapeFuture Project.

摘要：護理人員日益短缺，且護理之家發生跌倒的風險極高，對醫療保健系統構成重大挑戰。本研究提出將自動化跌倒偵測系統整合至護理床，旨在提升病患安全，同時透過穿戴式裝置或視訊監控來保護隱私。透過床架傳遞的機械振動會使用短時距傅立葉轉換進行處理，並能利用卷積神經網路對不同人類跌倒模式進行穩健分類。針對資料數量和多樣性的挑戰，提出產生額外資料的建議，特別著重於增加變化性。雖然此模型在使用實驗室資料區分跌倒事件和雜訊時顯示出有希望的結果，但建議在真實環境中進一步測試以進行驗證和改進。儘管可用資料有限，但所提出的系統顯示出對跌倒事件做出準確且快速的反應的潛力，減輕健康影響，並滿足老齡化人口的需求。此案例研究是作為 ZIM 專案的一部分進行的。ShapeFuture 專案將持續進行人工智慧增強感測器的進一步研究。

##### **Estimating the treatment effect over time under general interference through deep learner integrated TMLE**
2412.04799v1 by Suhan Guo, Furao Shen, Ni Li

Understanding the effects of quarantine policies in populations with
underlying social networks is crucial for public health, yet most causal
inference methods fail here due to their assumption of independent individuals.
We introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood
Estimation (TMLE) method designed to estimate time-sensitive treatment effects
in observational data. DeepNetTMLE mitigates bias from time-varying confounders
under general interference by incorporating a temporal module and domain
adversarial training to build intervention-invariant representations. This
process removes associations between current treatments and historical
variables, while the targeting step maintains the bias-variance trade-off,
enhancing the reliability of counterfactual predictions. Using simulations of a
``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we
show that DeepNetTMLE achieves lower bias and more precise confidence intervals
in counterfactual estimates, enabling optimal quarantine recommendations within
budget constraints, surpassing state-of-the-art methods.

摘要：了解具有潛在社交網絡的人群中隔離政策的影響對於公共衛生至關重要，但由於假設個人獨立，大多數因果推論方法在此處失敗。我們引入了 DeepNetTMLE，這是一種深度學習增強的目標最大似然估計 (TMLE) 方法，旨在估計觀測數據中的時間敏感處理效果。DeepNetTMLE 透過整合時間模組和領域對抗訓練來建立介入不變表示，從而減輕一般干擾下時變混雜因素的偏差。此過程消除了當前處理與歷史變數之間的關聯，而目標設定步驟則維持偏差變異權衡，增強反事實預測的可靠性。使用具有不同隔離覆蓋率的「易感者-感染者-康復者」模型的模擬，我們表明 DeepNetTMLE 在反事實估計中實現了較低的偏差和更精確的信心區間，從而在預算限制內實現了最佳隔離建議，超越了最先進的方法。

##### **Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models**
2412.04792v1 by Mahfuzul Haque, Abu Saleh Musa Miah, Debashish Gupta, Md. Maruf Al Hossain Prince, Tanzina Alam, Nusrat Sharmin, Mohammed Sowket Ali, Jungpil Shin

Heart disease is a leading cause of premature death worldwide, particularly
among middle-aged and older adults, with men experiencing a higher prevalence.
According to the World Health Organization (WHO), non-communicable diseases,
including heart disease, account for 25\% (17.9 million) of global deaths, with
over 43,204 annual fatalities in Bangladesh. However, the development of heart
disease detection (HDD) systems tailored to the Bangladeshi population remains
underexplored due to the lack of benchmark datasets and reliance on manual or
limited-data approaches. This study addresses these challenges by introducing
new, ethically sourced HDD dataset, BIG-Dataset and CD dataset which
incorporates comprehensive data on symptoms, examination techniques, and risk
factors. Using advanced machine learning techniques, including Logistic
Regression and Random Forest, we achieved a remarkable testing accuracy of up
to 96.6\% with Random Forest. The proposed AI-driven system integrates these
models and datasets to provide real-time, accurate diagnostics and personalized
healthcare recommendations. By leveraging structured datasets and
state-of-the-art machine learning algorithms, this research offers an
innovative solution for scalable and effective heart disease detection, with
the potential to reduce mortality rates and improve clinical outcomes.

摘要：<paragraph>心臟病是全球過早死亡的主因，特別是在中年和老年人中，男性發生率較高。根據世界衛生組織 (WHO) 的數據，包括心臟病在內的非傳染性疾病占全球死亡人數的 25%（1790 萬），孟加拉國每年有超過 43,204 人死於心臟病。然而，由於缺乏基準數據集和依賴手動或數據有限的方法，針對孟加拉國人口量身打造的心臟病檢測 (HDD) 系統的開發仍未得到充分探索。本研究通過引入新的、符合道德標準的 HDD 數據集、BIG 數據集和 CD 數據集來應對這些挑戰，其中包含有關症狀、檢查技術和風險因素的全面數據。使用先進的機器學習技術，包括邏輯迴歸和隨機森林，我們使用隨機森林實現了高達 96.6% 的顯著測試準確度。所提出的 AI 驅動系統整合了這些模型和數據集，以提供實時的準確診斷和個性化的醫療保健建議。通過利用結構化數據集和最先進的機器學習算法，本研究為可擴展且有效的心臟病檢測提供了一個創新的解決方案，具有降低死亡率和改善臨床結果的潛力。</paragraph>

##### **DAWN-SI: Data-Aware and Noise-Informed Stochastic Interpolation for Solving Inverse Problems**
2412.04766v1 by Shadab Ahamed, Eldad Haber

Inverse problems, which involve estimating parameters from incomplete or
noisy observations, arise in various fields such as medical imaging,
geophysics, and signal processing. These problems are often ill-posed,
requiring regularization techniques to stabilize the solution. In this work, we
employ $\textit{Stochastic Interpolation}$ (SI), a generative framework that
integrates both deterministic and stochastic processes to map a simple
reference distribution, such as a Gaussian, to the target distribution. Our
method $\textbf{DAWN-SI}$: $\textbf{D}$ata-$\textbf{AW}$are and
$\textbf{N}$oise-informed $\textbf{S}$tochastic $\textbf{I}$nterpolation
incorporates data and noise embedding, allowing the model to access
representations about the measured data explicitly and also account for noise
in the observations, making it particularly robust in scenarios where data is
noisy or incomplete. By learning a time-dependent velocity field, SI not only
provides accurate solutions but also enables uncertainty quantification by
generating multiple plausible outcomes. Unlike pre-trained diffusion models,
which may struggle in highly ill-posed settings, our approach is trained
specifically for each inverse problem and adapts to varying noise levels. We
validate the effectiveness and robustness of our method through extensive
numerical experiments on tasks such as image deblurring and tomography.

摘要：反問題涉及從不完整或有雜訊的觀測中估計參數，出現在各種領域，例如醫學影像、地球物理和訊號處理。這些問題通常是不適定的，需要正則化技術來穩定解。在這項工作中，我們採用隨機插值 (SI)，一種生成式架構，整合確定性和隨機過程，將簡單的參考分佈（例如高斯分佈）對應到目標分佈。我們的 DAWS-SI 方法：資料感知和雜訊知情的隨機插值，結合資料和雜訊嵌入，讓模型能夠明確存取關於測量資料的表示，並考量觀測中的雜訊，使其在資料有雜訊或不完整的情況下特別穩健。透過學習與時間相關的速度場，SI 不僅提供精確的解，還能透過產生多個合理的結果來量化不確定性。與預先訓練的擴散模型不同，後者在高度不適定的設定中可能會遇到困難，我們的做法是針對每個反問題進行訓練，並適應不同的雜訊等級。我們透過廣泛的數值實驗驗證了我們方法的有效性和穩健性，這些任務包括影像去模糊和斷層掃描。

##### **PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images**
2412.04714v1 by Hongjin Lin, Matthew Nazari, Derek Zheng

Reliable large-scale data on the state of forests is crucial for monitoring
ecosystem health, carbon stock, and the impact of climate change. Current
knowledge of tree species distribution relies heavily on manual data collection
in the field, which often takes years to complete, resulting in limited
datasets that cover only a small subset of the world's forests. Recent works
show that state-of-the-art deep learning models using Light Detection and
Ranging (LiDAR) images enable accurate and scalable classification of tree
species in various ecosystems. While LiDAR images contain rich 3D information,
most previous works flatten the 3D images into 2D projections to use
Convolutional Neural Networks (CNNs). This paper offers three significant
contributions: (1) we apply the deep learning framework for tree classification
in tropical savannas; (2) we use Airborne LiDAR images, which have a lower
resolution but greater scalability than Terrestrial LiDAR images used in most
previous works; (3) we introduce the approach of directly feeding 3D point
cloud images into a vision transformer model (PCTreeS). Our results show that
the PCTreeS approach outperforms current CNN baselines with 2D projections in
AUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper
also motivates further LiDAR image collection and validation for accurate
large-scale automatic classification of tree species.

摘要：可靠的大規模森林狀態資料對於監測生態系統健康、碳儲量和氣候變遷的影響至關重要。目前對樹種分布的了解極度依賴於實地手動收集資料，這通常需要花費數年才能完成，導致只能涵蓋全球少數森林的有限資料集。最近的研究顯示，使用光探測和測距 (LiDAR) 影像的最新深度學習模型，可以在各種生態系統中對樹種進行準確且可擴充的分類。儘管 LiDAR 影像包含豐富的 3D 資訊，但大多數先前的研究會將 3D 影像壓縮成 2D 投影，以使用卷積神經網路 (CNN)。本文提供了三項重要的貢獻：(1) 我們將深度學習架構應用於熱帶稀樹草原的樹種分類；(2) 我們使用機載 LiDAR 影像，其解析度較低，但可擴充性比大多數先前研究中使用的地面 LiDAR 影像更高；(3) 我們引入了直接將 3D 點雲影像輸入到視覺Transformer模型 (PCTreeS) 的方法。我們的結果顯示，PCTreeS 方法在 AUC (0.81)、整體準確度 (0.72) 和訓練時間 (~45 分鐘) 方面優於當前使用 2D 投影的 CNN 基準。本文也激勵進一步收集和驗證 LiDAR 影像，以進行準確的大規模樹種自動分類。

##### **Semantic Consistency-Based Uncertainty Quantification for Factuality in Radiology Report Generation**
2412.04606v1 by Chenyu Wang, Weichao Zhou, Shantanu Ghosh, Kayhan Batmanghelich, Wenchao Li

Radiology report generation (RRG) has shown great potential in assisting
radiologists by automating the labor-intensive task of report writing. While
recent advancements have improved the quality and coherence of generated
reports, ensuring their factual correctness remains a critical challenge.
Although generative medical Vision Large Language Models (VLLMs) have been
proposed to address this issue, these models are prone to hallucinations and
can produce inaccurate diagnostic information. To address these concerns, we
introduce a novel Semantic Consistency-Based Uncertainty Quantification
framework that provides both report-level and sentence-level uncertainties.
Unlike existing approaches, our method does not require modifications to the
underlying model or access to its inner state, such as output token logits,
thus serving as a plug-and-play module that can be seamlessly integrated with
state-of-the-art models. Extensive experiments demonstrate the efficacy of our
method in detecting hallucinations and enhancing the factual accuracy of
automatically generated radiology reports. By abstaining from high-uncertainty
reports, our approach improves factuality scores by $10$%, achieved by
rejecting $20$% of reports using the Radialog model on the MIMIC-CXR dataset.
Furthermore, sentence-level uncertainty flags the lowest-precision sentence in
each report with an $82.9$% success rate.

摘要：放射科报告生成 (RRG) 已显示出极大的潜力，可通过自动执行报告编写的劳动密集型任务来协助放射科医生。虽然最近的进步提高了生成报告的质量和连贯性，但确保其事实正确性仍然是一项重大挑战。尽管已提出生成性医学视觉大语言模型 (VLLM) 来解决此问题，但这些模型容易出现幻觉并可能产生不准确的诊断信息。为了解决这些问题，我们引入了一个新颖的基于语义一致性的不确定性量化框架，该框架提供报告级和句子级的不确定性。与现有方法不同，我们的方法不需要修改底层模型或访问其内部状态（例如输出标记 logit），因此可用作即插即用模块，可以与最先进的模型无缝集成。广泛的实验表明了我们的方法在检测幻觉和提高自动生成的放射科报告的事实准确性方面的功效。通过避免高度不确定的报告，我们的方法将真实性得分提高了 10%，这是通过使用 MIMIC-CXR 数据集上的 Radialog 模型拒绝 20% 的报告实现的。此外，句子级不确定性标记了每份报告中精度最低的句子，成功率为 82.9%。

##### **CLINICSUM: Utilizing Language Models for Generating Clinical Summaries from Patient-Doctor Conversations**
2412.04254v1 by Subash Neupane, Himanshu Tripathi, Shaswata Mitra, Sean Bozorgzad, Sudip Mittal, Shahram Rahimi, Amin Amirlatifi

This paper presents ClinicSum, a novel framework designed to automatically
generate clinical summaries from patient-doctor conversations. It utilizes a
two-module architecture: a retrieval-based filtering module that extracts
Subjective, Objective, Assessment, and Plan (SOAP) information from
conversation transcripts, and an inference module powered by fine-tuned
Pre-trained Language Models (PLMs), which leverage the extracted SOAP data to
generate abstracted clinical summaries. To fine-tune the PLM, we created a
training dataset of consisting 1,473 conversations-summaries pair by
consolidating two publicly available datasets, FigShare and MTS-Dialog, with
ground truth summaries validated by Subject Matter Experts (SMEs). ClinicSum's
effectiveness is evaluated through both automatic metrics (e.g., ROUGE,
BERTScore) and expert human assessments. Results show that ClinicSum
outperforms state-of-the-art PLMs, demonstrating superior precision, recall,
and F-1 scores in automatic evaluations and receiving high preference from SMEs
in human assessment, making it a robust solution for automated clinical
summarization.

摘要：本文介紹 ClinicSum，這是一個新穎的架構，旨在自動從病患與醫師的對話中產生臨床摘要。它利用一個雙模組架構：一個基於檢索的過濾模組，從對話轉錄中萃取主觀、客觀、評估和計畫 (SOAP) 資訊，以及一個由微調過之預先訓練語言模型 (PLM) 提供動力的推論模組，它利用萃取的 SOAP 資料產生摘要的臨床摘要。為了微調 PLM，我們建立了一個訓練資料集，其中包含 1,473 組對話摘要，透過合併兩個公開可用的資料集 FigShare 和 MTS-Dialog，以及由主題專家 (SME) 驗證的真實摘要。ClinicSum 的效能透過自動評量指標 (例如 ROUGE、BERTScore) 和專家人類評估進行評量。結果顯示 ClinicSum 勝過現有最先進的 PLM，在自動評量中展現出優異的精確度、召回率和 F-1 分數，並在人類評估中獲得 SME 的高度偏好，使其成為自動臨床摘要的強健解決方案。

##### **Automated Medical Report Generation for ECG Data: Bridging Medical Text and Signal Processing with Deep Learning**
2412.04067v1 by Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad

Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public

摘要：深度學習和自然語言生成技術的最新進展顯著改善了影像標題，能為視覺內容提供自動化的人類語言描述。在這項工作中，我們將這些標題技術應用於產生類似臨床醫師對心電圖資料的詮釋。這項研究利用既有的心電圖資料集，並附上由醫療保健專業人員 (HCP) 撰寫的自由文字報告作為訓練資料。這些報告雖然常常不一致，但為自動化學習提供了有價值的基礎。我們引入了一個編碼器-解碼器方法，使用這些報告來訓練模型，以產生心電圖事件的詳細描述。這代表心電圖分析自動化的重大進展，在零次學習分類和自動化臨床決策支援中具有潛在應用。此模型在各種資料集上進行測試，包括 1 導程和 12 導程心電圖。它明顯優於邱等人的現有最佳參考模型，與參考模型達成的 24.51% 相比，達到了 55.53% 的 METEOR 分數。此外，討論了幾個關鍵的設計選擇，提供了對這個領域中當前挑戰和創新的全面概述。此研究的原始程式碼在我們的 Git 儲存庫 https://git.zib.de/ableich/ecg-comment-generation-public 中公開。

##### **FedMetaMed: Federated Meta-Learning for Personalized Medication in Distributed Healthcare Systems**
2412.03851v1 by Jiechao Gao, Yuangang Li

Personalized medication aims to tailor healthcare to individual patient
characteristics. However, the heterogeneity of patient data across healthcare
systems presents significant challenges to achieving accurate and effective
personalized treatments. Ethical concerns further complicate the aggregation of
large volumes of data from diverse institutions. Federated Learning (FL) offers
a promising decentralized solution by enabling collaborative model training
through the exchange of client models rather than raw data, thus preserving
privacy. However, existing FL methods often suffer from retrogression during
server aggregation, leading to a decline in model performance in real-world
medical FL settings. To address data variability in distributed healthcare
systems, we introduce Federated Meta-Learning for Personalized Medication
(FedMetaMed), which combines federated learning and meta-learning to create
models that adapt to diverse patient data across healthcare systems. The
FedMetaMed framework aims to produce superior personalized models for
individual clients by addressing these limitations. Specifically, we introduce
Cumulative Fourier Aggregation (CFA) at the server to improve stability and
effectiveness in global knowledge aggregation. CFA achieves this by gradually
integrating client models from low to high frequencies. At the client level, we
implement a Collaborative Transfer Optimization (CTO) strategy with a
three-step process - Retrieve, Reciprocate, and Refine - to enhance the
personalized local model through seamless global knowledge transfer.
Experiments on real-world medical imaging datasets demonstrate that FedMetaMed
outperforms state-of-the-art FL methods, showing superior generalization even
on out-of-distribution cohorts.

摘要：個人化醫療旨在針對個別患者特徵調整醫療保健。然而，醫療系統中患者資料的異質性對達成準確且有效的個人化治療帶來重大挑戰。倫理問題進一步使來自不同機構的大量資料的彙總複雜化。聯邦學習 (FL) 提供了一種有前景的分散式解決方案，透過交換客戶模型而非原始資料來實現協作模型訓練，從而保護隱私。然而，現有的 FL 方法在伺服器彙總期間經常遭受退化，導致實際醫療 FL 設定中的模型效能下降。為了解決分散式醫療系統中的資料變異性，我們引入了個人化藥物聯邦元學習 (FedMetaMed)，它結合了聯邦學習和元學習來建立模型，以適應醫療系統中不同的患者資料。FedMetaMed 框架旨在透過解決這些限制，為個別客戶產生優越的個人化模型。具體來說，我們在伺服器端引入了累積傅立葉彙總 (CFA)，以改善全球知識彙總的穩定性和有效性。CFA 透過逐步整合從低頻率到高頻率的客戶模型來實現這一點。在客戶端層級，我們實施了一種協作傳輸最佳化 (CTO) 策略，採用三步驟流程 - 擷取、回饋和精煉 - 透過無縫的全球知識傳輸來增強個人化本地模型。在實際醫療影像資料集上的實驗表明，FedMetaMed 優於最先進的 FL 方法，即使在非分佈群組中也展現出優越的泛化性。

##### **ELEMENT: Episodic and Lifelong Exploration via Maximum Entropy**
2412.03800v1 by Hongming Li, Shujian Yu, Bin Liu, Jose C. Principe

This paper proposes \emph{Episodic and Lifelong Exploration via Maximum
ENTropy} (ELEMENT), a novel, multiscale, intrinsically motivated reinforcement
learning (RL) framework that is able to explore environments without using any
extrinsic reward and transfer effectively the learned skills to downstream
tasks. We advance the state of the art in three ways. First, we propose a
multiscale entropy optimization to take care of the fact that previous maximum
state entropy, for lifelong exploration with millions of state observations,
suffers from vanishing rewards and becomes very expensive computationally
across iterations. Therefore, we add an episodic maximum entropy over each
episode to speedup the search further. Second, we propose a novel intrinsic
reward for episodic entropy maximization named \emph{average episodic state
entropy} which provides the optimal solution for a theoretical upper bound of
the episodic state entropy objective. Third, to speed the lifelong entropy
maximization, we propose a $k$ nearest neighbors ($k$NN) graph to organize the
estimation of the entropy and updating processes that reduces the computation
substantially. Our ELEMENT significantly outperforms state-of-the-art intrinsic
rewards in both episodic and lifelong setups. Moreover, it can be exploited in
task-agnostic pre-training, collecting data for offline reinforcement learning,
etc.

摘要：本文提出了一种新颖的多尺度、内在动机强化学习 (RL) 框架，名为“通过最大熵进行情景和终身探索”(ELEMENT)，该框架能够在不使用任何外在奖励的情况下探索环境，并有效地将所学技能转移到下游任务中。我们在三个方面提升了技术水平。首先，我们提出了多尺度熵优化，以解决以下事实：先前的最大状态熵在进行数百万次状态观察的终身探索时，会遭受奖励消失的影响，并且在每次迭代中都会变得非常昂贵。因此，我们在每个情景中添加了一个情景最大熵，以进一步加快搜索速度。其次，我们提出了一种新的内在奖励，用于情景熵最大化，名为“平均情景状态熵”，它为情景状态熵目标的理论上限提供了最优解。第三，为了加快终身熵最大化，我们提出了一个 $k$ 近邻 ($k$NN) 图，用于组织熵的估计和更新过程，从而大幅减少了计算。我们的 ELEMENT 在情景和终身设置中都明显优于最先进的内在奖励。此外，它还可以用于与任务无关的预训练、收集离线强化学习数据等。

##### **Automated Multi-Label Annotation for Mental Health Illnesses Using Large Language Models**
2412.03796v1 by Abdelrahaman A. Hassan, Radwa J. Hanafy, Mohammed E. Fouda

The growing prevalence and complexity of mental health disorders present
significant challenges for accurate diagnosis and treatment, particularly in
understanding the interplay between co-occurring conditions. Mental health
disorders, such as depression and Anxiety, often co-occur, yet current datasets
derived from social media posts typically focus on single-disorder labels,
limiting their utility in comprehensive diagnostic analyses. This paper
addresses this critical gap by proposing a novel methodology for cleaning,
sampling, labeling, and combining data to create versatile multi-label
datasets. Our approach introduces a synthetic labeling technique to transform
single-label datasets into multi-label annotations, capturing the complexity of
overlapping mental health conditions. To achieve this, two single-label
datasets are first merged into a foundational multi-label dataset, enabling
realistic analyses of co-occurring diagnoses. We then design and evaluate
various prompting strategies for large language models (LLMs), ranging from
single-label predictions to unrestricted prompts capable of detecting any
present disorders. After rigorously assessing multiple LLMs and prompt
configurations, the optimal combinations are identified and applied to label
six additional single-disorder datasets from RMHD. The result is SPAADE-DR, a
robust, multi-label dataset encompassing diverse mental health conditions. This
research demonstrates the transformative potential of LLM-driven synthetic
labeling in advancing mental health diagnostics from social media data, paving
the way for more nuanced, data-driven insights into mental health care.

摘要：隨著心理健康障礙的盛行率和複雜性日益增加，對於準確診斷和治療提出了嚴峻的挑戰，特別是在了解共存疾病之間的相互作用時。心理健康障礙，例如憂鬱症和焦慮症，經常共存，但目前從社群媒體貼文中衍生的資料集通常只關注單一障礙標籤，限制了它們在全面診斷分析中的效用。本文透過提出一個創新的方法來清理、抽樣、標籤和組合資料，以建立多功能的多標籤資料集，來解決這個關鍵的差距。我們的做法引進了一種合成標籤技術，將單標籤資料集轉換為多標籤註解，捕捉重疊心理健康狀況的複雜性。為了達成這個目標，首先將兩個單標籤資料集合併成一個基礎多標籤資料集，以進行共存診斷的實際分析。然後，我們設計並評估大型語言模型 (LLM) 的各種提示策略，從單標籤預測到能夠偵測任何現有障礙的無限制提示。在嚴格評估多個 LLM 和提示配置後，找出最佳組合並應用於標籤來自 RMHD 的六個其他單一障礙資料集。結果是 SPAADE-DR，一個包含各種心理健康狀況的強健多標籤資料集。這項研究展示了 LLM 驅動的合成標籤在推進從社群媒體資料進行心理健康診斷的轉型潛力，為更細緻、資料驅動的心理保健見解鋪路。

##### **Speech Recognition-based Feature Extraction for Enhanced Automatic Severity Classification in Dysarthric Speech**
2412.03784v1 by Yerin Choi, Jeehyun Lee, Myoung-Wan Koo

Due to the subjective nature of current clinical evaluation, the need for
automatic severity evaluation in dysarthric speech has emerged. DNN models
outperform ML models but lack user-friendly explainability. ML models offer
explainable results at a feature level, but their performance is comparatively
lower. Current ML models extract various features from raw waveforms to predict
severity. However, existing methods do not encompass all dysarthric features
used in clinical evaluation. To address this gap, we propose a feature
extraction method that minimizes information loss. We introduce an ASR
transcription as a novel feature extraction source. We finetune the ASR model
for dysarthric speech, then use this model to transcribe dysarthric speech and
extract word segment boundary information. It enables capturing finer
pronunciation and broader prosodic features. These features demonstrated an
improved severity prediction performance to existing features: balanced
accuracy of 83.72%.

摘要：由於當前臨床評估的主觀性，因此出現了對構音障礙言語中自動嚴重程度評估的需求。DNN 模型優於 ML 模型，但缺乏使用者友善的可解釋性。ML 模型在特徵層級提供可解釋的結果，但其效能相對較低。當前的 ML 模型從原始波形中擷取各種特徵以預測嚴重程度。然而，現有方法並未涵蓋臨床評估中使用的所有構音障礙特徵。為了解決這個差距，我們提出了一種可將資訊損失降至最低的特徵擷取方法。我們引入了 ASR 轉錄作為一種新穎的特徵擷取來源。我們為構音障礙言語微調 ASR 模型，然後使用此模型轉錄構音障礙言語並擷取字元區段邊界資訊。它可以擷取更精細的發音和更廣泛的韻律特徵。這些特徵顯示出比現有特徵更好的嚴重程度預測效能：平衡準確度為 83.72%。

##### **Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety**
2412.03740v1 by Dilan Mian

The world can be a complex and difficult place to navigate. People with
High-Functioning Autistic Spectrum Disorder as well as general social
ineptitude often face navigation challenges that individuals of other
demographics simply do not themselves. This can become even more pronounced
with people of that specific group when they are in their teenage years and
early adulthood (that being the usual age range of college students). When they
are at such a vulnerable age, they can be far more susceptible to the struggles
of becoming comfortable and content with social interactions as well as having
strong relationships (outside their immediate family). Concerning this, the
rapid emergence of artificial intelligence chatbots has led to many of them
being used to benefit people of different ages and demographics with easy
accessibility. With this, if there is anything that people with
High-Functioning ASD and social ineptitude want when it comes to guidance
towards self-improvement, surely easy accessibility would be one. What are the
potential benefits and limitations of using a Mindstudio AI-powered chatbot to
provide mental health support for teens and young adults with the
aforementioned conditions? What could be done with a tool like this to help
those individuals navigate ethical dilemmas within different social
environments to reduce existing social tensions? This paper addresses these
queries and offers insights to inform future discussions on the subject.

摘要：世界可能是一個複雜且難以應付的地方。高功能自閉症譜系障礙以及一般社交無能的人，經常會面對其他人口統計資料中的人根本不會遇到的應對挑戰。當他們處於青少年時期和成年初期（通常是大學生的年齡範圍）時，這種情況可能會變得更加明顯。當他們處於如此脆弱的年齡時，他們更容易受到社交互動感到自在和滿足的掙扎，以及擁有牢固關係（在他們的直系親屬之外）的影響。關於這一點，人工智慧聊天機器人的快速出現，導致許多人被用於造福不同年齡和人口統計資料的人，並具有易於存取性。有了這個，如果患有高功能自閉症和社交無能的人在自我提升的指導方面有任何想要的東西，那麼易於存取肯定會是一個。使用由 Mindstudio AI 提供技術支援的聊天機器人，為患有上述情況的青少年和年輕人提供心理健康支援，有哪些潛在的好處和限制？可以使用這樣的工具來幫助那些人應對不同社會環境中的道德困境，以減少現有的社會緊張局勢，可以做些什麼？本文探討這些問題，並提供見解，為未來關於此主題的討論提供資訊。

##### **MRGen: Diffusion-based Controllable Data Engine for MRI Segmentation towards Unannotated Modalities**
2412.04106v1 by Haoning Wu, Ziheng Zhao, Ya Zhang, Weidi Xie, Yanfeng Wang

Medical image segmentation has recently demonstrated impressive progress with
deep neural networks, yet the heterogeneous modalities and scarcity of mask
annotations limit the development of segmentation models on unannotated
modalities. This paper investigates a new paradigm for leveraging generative
models in medical applications: controllably synthesizing data for unannotated
modalities, without requiring registered data pairs. Specifically, we make the
following contributions in this paper: (i) we collect and curate a large-scale
radiology image-text dataset, MedGen-1M, comprising modality labels,
attributes, region, and organ information, along with a subset of organ mask
annotations, to support research in controllable medical image generation; (ii)
we propose a diffusion-based data engine, termed MRGen, which enables
generation conditioned on text prompts and masks, synthesizing MR images for
diverse modalities lacking mask annotations, to train segmentation models on
unannotated modalities; (iii) we conduct extensive experiments across various
modalities, illustrating that our data engine can effectively synthesize
training samples and extend MRI segmentation towards unannotated modalities.

摘要：醫學影像分割最近已透過深度神經網路展現驚人的進展，但異質模態和標籤稀少限制了在未標註模態上開發分割模型。本文探討了一個新典範，以利用生成模型在醫學應用中：可控地合成未標註模態的資料，而無需註冊資料對。具體來說，我們在本文中做出以下貢獻：(i) 我們收集並策劃了一個大規模的放射影像文字資料集 MedGen-1M，包含模態標籤、屬性、區域和器官資訊，以及一部分器官標籤，以支援可控醫學影像生成的相關研究；(ii) 我們提出了一個基於擴散的資料引擎，稱為 MRGen，它能夠根據文字提示和標籤生成條件，合成缺乏標籤註解的不同模態的 MR 影像，以訓練未標註模態的分割模型；(iii) 我們在各種模態中進行了廣泛的實驗，說明我們的資料引擎可以有效地合成訓練樣本，並將 MRI 分割延伸至未標註的模態。

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

摘要：大多數用於醫學影像分析的資料驅動模型仰賴通用擴充功能來提升效能。實驗證據已證實其有效性，但其背後不明確的機制對醫學界廣泛接受和信任此類方法構成阻礙。我們重新檢視並承認醫學影像與傳統數位影像的獨特特性，因此提出更具彈性且與放射線掃描程序密切配合的醫學特定擴充演算法。該方法根據極座標上的半徑執行正弦扭曲射線的逐段仿射，從而模擬人平躺在掃描台上時的不確定姿勢。我們的方法可以在不影響軸向平面上基本相對位置的情況下生成人體內臟分佈。引入了兩種非自適應演算法，即基於 Meta 的掃描台移除和相似性導引參數搜尋，以加強我們擴充方法的穩健性。實驗表明，我們的演算法在不需要更多資料樣本的情況下，就能提升多個著名分割架構的準確性。我們的預覽程式碼可在 https://github.com/MGAMZ/PSBPD 中取得。

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

摘要：鉴于心血管疾病在全球的普遍性，迫切需要容易获取的早期筛查方法。通常，这需要医疗从业人员检查心脏听诊是否有不规则的声音，然后进行超声心动图和心电图检查。为了使早期诊断民主化，我们提出了一种用户友好的解决方案，用于检测异常心脏声音，利用移动电话和一个轻量级神经网络，该神经网络针对设备内推理进行了优化。与以前依赖于专用听诊器的做法不同，我们的方法直接分析音频记录，这得益于一种称为 IConNet 的新颖架构。IConNet 是一种可解释的卷积神经网络，利用音频信号处理的见解，提高效率，并提供从原始波形信号中提取神经模式的透明性。这是朝向医疗保健中可信赖的人工智能迈出的重要一步，有助于远程健康监测工作。

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

摘要：我們提出一個多方面的彈性網路 (MRNet)，這是一個創新的架構，
開發用於醫學影像轉影像的翻譯，其優於 MRI 轉 CT 和 MRI 轉 MRI 轉換的最新方法。MRNet
利用 Segment Anything Model (SAM) 來利用基於頻率的特徵，以建立一種強大的方法，用於先進的醫學影像轉換。此
架構使用強大的 SAM 影像編碼器從不同的資料集提取全面的多尺度特徵，並執行解析度感知特徵融合，持續將 U-Net 編碼器輸出與 SAM 衍生的特徵整合在一起。
此融合最佳化傳統的 U-Net 跳躍連接，同時利用基於Transformer的上下文分析。翻譯由一個創新的雙遮罩配置補充，它結合了動態注意模式和一個專門的損失函數，旨在解決區域對應不匹配的問題，同時保留了整體解剖結構和組織細節。廣泛的驗證研究顯示，MRNet 優於最先進的架構，特別是在維持解剖保真度和最小化轉換偽影方面。

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

摘要：變形金剛現在普遍用於序列建模任務，但由於注意力機制的二次方成本，它們擴展到多維數據仍然是一個挑戰。在本文中，我們提出了高階變形金剛 (HOT)，這是一種新穎的架構，旨在有效處理具有兩個以上軸線的數據，即高階張量。為了應對與高階張量注意力相關的計算挑戰，我們引入了一種新穎的克羅內克分解注意力機制，該機制將注意力成本降低到每個軸線維度的二次方，而不是輸入張量的總大小的二次方。為了進一步提高效率，HOT 利用核化注意力，將複雜度降低到線性。此策略保持了模型的表現力，同時實現了可擴展的注意力計算。我們在兩個高維任務上驗證了 HOT 的有效性，包括多元時間序列預測和 3D 醫學影像分類。實驗結果表明，HOT 在顯著提高計算效率的同時實現了競爭力的效能，展示了其應對各種複雜的多維數據的潛力。

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現出令人印象深刻的能力，然而它們在醫療保健等敏感領域的使用，特別是電子健康紀錄 (EHR)，由於隱私問題和有限的運算資源而面臨重大挑戰。本文提出了一個緊湊的 LLM 框架，旨在在具有嚴格隱私要求和有限使用高性能 GPU 的環境中進行本地部署。我們引入了一種新穎的預處理技術，它使用資訊萃取方法，例如正規表示法，來過濾和強調臨床筆記中的關鍵資訊，增強較小 LLM 在 EHR 資料上的效能。我們的框架使用零次學習和少次學習範例在私人和公開可用的 (MIMIC-IV) 資料集上進行評估，我們也比較它在 MIMIC-IV 資料集上與微調 LLM 的效能。結果表明，我們的預處理方法顯著提升了較小 LLM 的預測準確度，使其適用於高度隱私、資源受限的應用程式。這項研究提供了寶貴的見解，用於最佳化 LLM 效能以應對敏感、資料密集型任務，同時解決運算和隱私限制。

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

摘要：本研究探討區塊鏈技術在醫療保健中的整合，專注於提升電子健康紀錄 (EHR) 管理的安全性與效率。我們提出一個創新的以太坊系統，賦予患者安全地控制其醫療數據的權力。我們的做法解決了醫療保健區塊鏈實作中的主要挑戰，包括可擴充性、隱私和法規遵循。該系統整合了數位簽章、基於角色的存取控制和多層架構，以確保安全且受控的存取。我們開發了一個具有使用者友善介面的去中心化應用程式 (dApp)，適用於患者、醫生和管理員，展示了我們解決方案的實際應用。在醫療保健專業人員和 IT 專家之間進行的一項調查顯示，他們對區塊鏈的採用有濃厚興趣，但也強調了對整合成本的擔憂。該研究探討了未來的強化，包括與 IoT 裝置整合和 AI 驅動的分析，有助於安全、高效且可互操作的醫療保健系統的演進，該系統利用尖端技術改善患者照護。

##### **CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**
2412.02819v2 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering
16k\textasciitilde128k, 695 samples in total, the annotations are human-driven.
We evaluate commercial and open-source models on CNNSum and conduct a detailed
analysis. Based on the observations, we further conduct fine-tuning exploration
with short-context summary data. In our study: (1) GPT-4o underperformed, due
to excessive subjective commentary. (2) Currently, long-context summarization
mainly relies on memory ability, small LLMs with stable longer context lengths
are the most cost-effective. Using long data concatenated from short-context
summaries makes a significant improvement. (3) Prompt templates may cause a
large performance gap but can be mitigated through fine-tuning. (4) Fine-tuned
Chat or Instruction versions may harm the Base model and further fine-tuning
cannot bridge performance gap. (5) while models with RoPE base scaling exhibit
strong extrapolation potential, their performance may vary significantly when
combined with other interpolation methods and need careful selection. (6)
CNNSum provides more reliable and insightful evaluation results than other
benchmarks. We release CNNSum to advance research in this field.

摘要：<paragraph>大型語言模型 (LLM) 已在許多長語境任務中獲得深入研究。然而，由於標註成本高昂，用於訓練或評估的高品質長語境摘要資料集稀缺，限制了進一步的研究。在本文中，我們介紹了 CNNSum，一個新的多尺度中文長語境小說摘要基準，包括四個子集，長度涵蓋 16k\textasciitilde128k，共 695 個範例，標註由人工驅動。我們在 CNNSum 上評估了商業和開源模型，並進行了詳細分析。根據觀察結果，我們進一步使用短語境摘要資料進行微調探索。在我們的研究中：(1) GPT-4o 表現不佳，原因是過度的主觀評論。(2) 目前，長語境摘要主要依賴記憶能力，具有穩定較長語境長度的小型 LLM 最具成本效益。使用從短語境摘要串聯而成的長資料，可以顯著提升效果。(3) 提示範本可能會造成很大的效能差距，但可以透過微調來減輕。(4) 微調的聊天或指令版本可能會損害基礎模型，而進一步的微調也無法彌合效能差距。(5) 雖然具有 RoPE 基礎縮放的模型展現出強大的外推潛力，但與其他內插方法結合時，其效能可能會大幅變化，需要仔細選擇。(6) CNNSum 提供比其他基準更可靠且有見地的評估結果。我們發布 CNNSum 以推動此領域的研究。</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v2 by Jingyuan Yi, Peiyang Yu, Tianyi Huang, Zeqiu Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

摘要：<paragraph>針對最新的粒子群最佳化演算法，本文提出改良的 Transformer 模型，以提升心臟病預測的準確度，並提供新的演算法思維。我們首先使用三種主流機器學習分類演算法——決策樹、隨機森林與 XGBoost，並輸出這三種模型的混淆矩陣。結果顯示隨機森林模型在預測心臟病分類上表現最佳，準確度為 92.2%。接著，我們將基於粒子群最佳化 (PSO) 演算法的 Transformer 模型套用於相同資料集進行分類實驗。結果顯示該模型的分類準確度高達 96.5%，比隨機森林高出 4.3 個百分點，驗證了 PSO 在最佳化 Transformer 模型上的有效性。從上述研究中，我們可以看出粒子群最佳化顯著提升了 Transformer 在心臟病預測上的表現。提升預測心臟病的能力是一項全球性的優先要務，對全人類都有益。準確的預測可以增進公共衛生、優化醫療資源並降低醫療保健成本，進而促進全球人口的健康和社會生產力。這項進展為更有效率的健康管理鋪路，並支持建立一個更健康、更具韌性的全球社群。</paragraph>

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

摘要：深度學習的最新進展大幅革新了臨床診斷和治療領域，提供了改善各種臨床領域診斷精準度和治療效果的新方法，進而推動精準醫療的追求。多器官和多模態資料集的可用性日益增加，加速了大規模醫療多模態基礎模型 (MMFM) 的發展。這些模型以其強大的概化能力和豐富的表徵能力而聞名，正日益被改編以解決廣泛的臨床任務，從早期診斷到個人化治療策略。本篇評論提供了對 MMFM 近期發展的全面分析，重點關注三個關鍵面向：資料集、模型架構和臨床應用。我們也探討了最佳化多模態表徵的挑戰和機會，並討論這些進展如何透過改善患者預後和更有效率的臨床工作流程，形塑醫療保健的未來。

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

摘要：醫療影像在醫療保健中至關重要，可提供患者解剖結構和病理學的重要見解，有助於診斷和治療。X 光、磁振造影 (MRI)、電腦斷層掃描 (CT) 和超音波 (US) 等非侵入式技術，可捕捉器官、組織和異常的詳細影像。有效分析這些影像需要精確的分割，以描繪感興趣區域 (ROI)，例如器官或病灶。傳統的分割方法依賴於手動特徵萃取，既費時又因專家而異。人工智慧 (AI) 和深度學習 (DL) 的最新進展，特別是 U-Net 和其變體 (U-Net++ 和 U-Net 3+) 等卷積模型，已透過自動化流程和提高準確度，轉變了醫療影像分割 (MIS)。這些模型能跨越各種影像模式進行有效且精確的逐像素分類，克服了手動分割的限制。本篇評論探討了各種醫療影像技術，審查了 U-Net 架構及其改編，並討論了它們在不同模式中的應用。它也找出了 MIS 中常見的挑戰，並提出了潛在的解決方案。

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

摘要：<paragraph>從真實世界資料中還原物理驅動模型，即基礎動態系統的控制方程式組，一直是近期的研究重點。現有方法大多在具有非現實高取樣率的模擬資料上執行，或需要所有系統變數的明確測量值，這在真實世界的部署中並不可行。此外，這些方法假設對物理系統的外部擾動的時間戳是先驗已知的，且沒有不確定性，隱含地忽略了任何感測器時間同步或人為回報錯誤。在本文中，我們提出了一種基於新穎液態時間常數神經網路 (LTC-NN) 的架構，以從真實世界資料中還原物理動態的基礎模型。LTC-NN 節點的自動微分特性克服了與低取樣率相關的問題，LTC-NN 節點隱藏層的前向傳遞中輸入依賴的時間常數會產生一個巨大的隱式物理動態搜尋空間，基於物理模型求解器的資料重建損失引導了對正確隱式動態集的搜尋，並且在稠密層中使用中斷正則化確保了最稀疏模型的提取。此外，為了考慮擾動計時錯誤，我們利用稠密層節點來搜尋輸入位移，這將導致最低的重建損失。在四個基準動態系統（三個使用模擬資料，一個使用真實世界資料）上的實驗表明，LTC-NN 架構在恢復隱式物理模型係數方面比最先進的稀疏模型恢復方法更準確。我們還介紹了四個額外的案例研究（總共八個），這些研究涉及模擬中的真實醫療範例和真實世界的臨床資料，以展示我們的做法在實務中恢復基礎模型的有效性。</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

摘要：<paragraph>許多研究致力於發現特定遺傳性疾病，但其在廣泛的疾病類型和分類中的分類仍然難以捉摸。遺傳性疾病的早期診斷能及時介入並改善結果。本研究實作機器學習模型，使用出生或嬰兒時期可測量的基本臨床指標，以在生命的早期階段進行診斷。監督式學習演算法實作在一個包含 22083 個實例的資料集上，其中包含 42 個特徵，例如家族史、新生兒指標和基本實驗室檢驗。進行了廣泛的超參數調整、特徵工程和選擇。開發了兩個多類別分類器：一個用於預測疾病類型（粒線體、多因素和單基因），另一個用於預測亞型（9 種疾病）。使用準確度、精確度、召回率和 F1 分數評估效能。CatBoost 分類器在預測遺傳性疾病類型方面達到了 77% 的最高準確度。對於亞型，SVM 達到了 80% 的最高準確度。本研究證明了在機器學習模型中使用基本臨床資料進行早期分類和診斷各種遺傳性疾病的可行性。將機器學習應用於基本臨床指標，可以在較大的資料集上驗證後及時進行干預。有必要進行進一步的研究以改善此資料集上的模型效能。</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

摘要：隨著大規模視覺語言模型的出現，僅使用醫療影像作為輸入，並透過簡單提示引導，即可產生逼真的放射科報告。然而，由於其對發現的描述有事實上的錯誤，因此其實際效用受到限制。在本文中，我們提出了一個用於可解釋事實查核的新模型，該模型可識別報告中發現的錯誤及其位置。具體來說，我們分析了自動化報告方法所產生的錯誤類型，並從真實資料集中衍生出一個新的合成影像資料集，其中配對了發現及其位置的真實和虛假描述。然後在這個資料集上訓練一個新的多標籤跨模態對比回歸網路。我們評估了產生的事實查核模型及其在更正由多個 SOTA 自動化報告工具在各種基準資料集上產生的報告中的效用，結果表明透過這種錯誤偵測和更正，報告品質獲得了超過 40% 的提升。

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

摘要：自大型語言模型 (LLM) 出現以來，有效利用其在醫療保健中的潛力的挑戰已成為重中之重。使用 LLM 從非結構化臨床筆記中提取見解的一個關鍵障礙在於提示工程過程。儘管它在確定任務績效中扮演著舉足輕重的角色，但仍缺乏明確的提示最佳化框架。目前解決此差距的方法採用手動提示優化方法，其中領域專家與提示工程師合作建立最佳提示，這非常耗時且難以擴展，或透過採用自動提示最佳化方法，其中領域專家的輸入價值並未充分實現。為了解決這個問題，我們提出了 StructEase，這是一個新穎的框架，它彌合了自動化與提示工程中人類專業知識輸入之間的差距。該框架的核心創新是 SamplEase，這是一種迭代式抽樣演算法，它識別出專家回饋能顯著提升績效的高價值案例。這種方法將專家介入降到最低，以有效提升分類結果。這種有針對性的方法減少了標籤冗餘，減輕了人為錯誤，並提升了分類結果。我們使用來自美國國家電子傷害監測系統 (NEISS) 的去識別化臨床敘述資料集評估了 StructEase 的績效，與目前的方法相比，分類績效有了顯著的提升。我們的研究結果強調了專家整合在 LLM 工作流程中的價值，在維持最少專家工作量的同時，達到了 F1 分數的顯著提升。透過結合透明度、彈性和可擴展性，StructEase 為一個框架奠定了基礎，將專家輸入整合到醫療保健及其他領域的 LLM 工作流程中。

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

摘要：隨著全球高齡化加劇，老年人的健康管理已成為社會關注的焦點。本研究設計並實作一個智慧老人照護服務模型，以解決老人健康行為預測中的資料異質性、健康狀態複雜性、長期依賴性與資料流失、行為突變、資料隱私等問題。該模型透過多模態資料融合、資料流失處理、非線性預測、緊急事件偵測、隱私保護等模組，達到老人健康行為的精準預測與動態管理。在實驗設計上，基於多來源資料集與市場調查結果，該模型在健康行為預測、緊急事件偵測、個人化服務等方面均展現出優異的表現。實驗結果顯示，該模型能有效提升健康行為預測的準確性與魯棒性，並滿足智慧老人照護領域的實際應用需求。未來隨著更多資料的整合與技術的進一步優化，該模型將為智慧老人照護服務提供更強大的技術支撐。

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v2 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

摘要：由於體積龐大，體積掃描和全玻片病理圖像 (WSI) 通常透過從局部區域提取嵌入式處理，然後聚合器從此組中做出預測。然而，目前的方法需要事後可視化技術（例如 Grad-CAM），而且常常無法定位小型但臨床上至關重要的細節。為了解決這些限制，我們引入了 INSIGHT，這是一種新穎的弱監督聚合器，它將熱圖生成整合為歸納偏誤。從預先訓練好的特徵圖開始，INSIGHT 使用帶有小型卷積核的檢測模組來擷取精細的細節，以及帶有較廣泛感受野的上下文模組來抑制局部誤報。產生的內部熱圖突出了診斷相關區域。在 CT 和 WSI 基準上，INSIGHT 達到了最先進的分類結果和高弱標記語義分割效能。專案網站和程式碼可於下列網址取得：
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

摘要：癌症臨床試驗由於缺乏面向參與者的資訊和教育資源，常常在招募和參與方面面臨挑戰。本研究探討了大型語言模型 (LLM)，特別是 GPT4，從臨床試驗知情同意書中產生對患者友善的教育內容的潛力。我們使用來自 ClinicalTrials.gov 的資料，採用零次學習來建立試驗摘要，以及一次學習來開發多選題，並透過患者調查和群眾外包註解來評估其有效性。結果顯示，GPT4 生成的摘要具有可讀性和全面性，並且可能提高患者對臨床試驗的理解和興趣。多選題展示出很高的準確度，並且與群眾外包註解者達成共識。對於這兩種資源類型，我們發現了需要持續的人工監督的幻覺。這些發現展示了 LLM「開箱即用」的潛力，可以用最少的試驗特定工程來支援臨床試驗教育材料的產生，但仍需要採用有人在迴路中的實作來避免錯誤資訊的風險。

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

摘要：加護病房 (ICU) 提供重症照護和生命支持，給予醫院中病情最嚴重和受傷最嚴重的患者。由於對加護病房的需求快速且空前地增長，特別是在 COVID-19 期間，準確找出病情最危急的患者有助於醫院更有效地分配資源並挽救更多生命。預測加護病房轉診和其他無法預見事件 (PICTURE) 模型透過將面臨迫在眉睫的加護病房轉診、呼吸衰竭或死亡的高風險患者與風險較低的患者區分開來，預測患者惡化。本研究旨在實作深度學習模型，以基準化 XGBoost 模型的效能，後者是一種在預測方面具有競爭力的現有模型。

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

摘要：精準的睡眠分期分類對於了解睡眠障礙和改善整體健康至關重要。本研究提出一個新的三階段方法，使用 ECG 訊號進行睡眠分期分類，提供了一個更易於取得的替代方案，傳統方法通常依賴於 EEG 等複雜的模式。在第 1 和第 2 階段，我們初始化兩個網路的權重，然後在第 3 階段整合它們以進行全面的分類。在第一階段，我們使用特徵模仿網路 (FIN) 估計關鍵特徵，以實現更高的準確度和更快的收斂。第二階段專注於透過 ECG 訊號的時頻表示來識別 N1 睡眠階段。最後，第三階段整合前一階段的模型，並採用 Kolmogorov-Arnold 網路 (KAN) 來分類五個不同的睡眠階段。此外，資料擴充技術，特別是 SMOTE，用於增強對 N1 等代表性不足階段的分類能力。我們的結果證明了分類效能有顯著的改善，整體準確度為 80.79%，整體 kappa 為 0.73。該模型對清醒、N1、N2、N3 和 REM 的特定準確度分別為 86.70%、60.36%、83.89%、84.85% 和 87.16%。本研究強調了權重初始化和資料擴充在使用 ECG 訊號最佳化睡眠分期分類中的重要性。

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

摘要：稀疏視圖電腦斷層掃描 (CT) 是一種新興的協定，旨在減少醫療影像中的 X 射線劑量輻射。傳統的濾波反向投影演算法重建因稀疏資料而導致嚴重的偽影。相比之下，基於模型的迭代重建 (MBIR) 演算法，雖然透過正則化在減輕雜訊方面表現得更好，但對於臨床使用而言，其計算成本過高。本文介紹了一種創新的技術，稱為 Deep Guess 加速方案，它使用訓練過的類神經網路來加速正則化的 MBIR 並增強重建準確度。我們整合了最先進的深度學習工具，為求解非凸模型的近端演算法初始化一個聰明的起始猜測，從而僅在幾次迭代中計算出可解釋的解影像。在真實 CT 影像上的實驗結果證明了 Deep Guess 在（非常）稀疏斷層攝影協定中的有效性，在該協定中，它克服了其單純的變分對應物和許多最先進的資料驅動方法。我們還考慮了無真實依據的實作，並測試了所提出的架構對雜訊的穩健性。

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

摘要：社群媒體平台，特別是 Reddit 的 r/Epilepsy 社群，提供了癲癇患者 (PWE) 及其照顧者的經驗獨特觀點。這項研究分析了 57k 則貼文和 533k 則留言，探討不同人口統計資料（例如年齡、性別和關係）中的主要主題。我們的發現強調了關於癲癇相關挑戰的重要討論，包括憂鬱症（39.75% 的貼文表示有嚴重症狀）、駕駛限制、職場問題和癲癇女性的懷孕相關問題。我們引進了一項創新的參與度指標 F(P)，它結合了貼文長度、情緒分數和可讀性，以量化社群互動。這項分析強調了整合性照護的重要性，它能同時解決 PWE 面臨的神經和心理健康挑戰。這項研究的見解提供了針對性支持和意識介入策略。

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

摘要：臨床決策制定 (CDM) 是一個複雜、動態的過程，對於醫療保健的提供至關重要，然而對於人工智慧系統來說，它仍然是一項重大的挑戰。雖然大型語言模型 (LLM) 基礎代理已使用執照考試和知識問答任務對一般醫療知識進行了測試，但它們在實際場景中的 CDM 中的表現受到缺乏反映實際醫療實務的綜合測試資料集的限制。為了解決這個差距，我們提出了 MedChain，這是一個包含 12,163 個臨床案例的資料集，涵蓋了臨床工作流程的五個關鍵階段。MedChain 以現實世界臨床實務的三個關鍵特徵區別於現有的基準：個人化、互動性和順序性。此外，為了應對現實世界的 CDM 挑戰，我們還提出了 MedChain-Agent，這是一個整合了回饋機制和 MCase-RAG 模組的人工智慧系統，用於從先前的案例中學習並調整其回應。MedChain-Agent 在動態收集資訊和處理順序性臨床任務方面展現了顯著的適應性，顯著優於現有方法。相關的資料集和程式碼將在本文被接受後發布。

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

摘要：深度學習工具整合在胃腸道視覺中，在診斷、治療和整體病人照護方面具有顯著進展的潛力。然而，一個重大的挑戰是，這些工具傾向於做出過度自信的預測，即使在遇到未見或新出現的疾病模式時，也會破壞其可靠性。
我們將此可靠性的關鍵問題，架構為一個異常分佈 (OOD) 偵測問題，其中以前未見和新出現的疾病被視為 OOD 範例。然而，由於分佈內 (ID) 和 OOD 範例之間的重疊特徵表示，胃腸道影像構成了一項獨特的挑戰。現有的方法通常忽略此特性，因為它們主要是為自然影像資料集而開發，其中特徵區別較為明顯。儘管有重疊，我們假設分佈內範例的特徵會聚集在其真實類別的質心附近，導致到最近質心的距離較短。相反地，OOD 範例與所有類別質心的距離相等。基於此觀察，我們在特徵空間中提出了一個用於胃腸道 OOD 偵測的新穎最近質心距離差 (NCCD) 分數。
在多個深度學習架構和兩個公開基準 Kvasir2 和 Gastrovision 中的評估，證明了我們的方法與幾種最先進的方法相比的有效性。程式碼和實作細節公開於：
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

摘要：早期皮膚異常偵測在診斷和治療皮膚癌中扮演著至關重要的角色。使用 AI 驅動的裝置分割受影響的皮膚區域相對常見，並支援診斷流程。然而，由於需要高解析度影像和個別病灶通常不明確的邊界，要達成高性能仍是一項重大的挑戰。同時，醫療裝置要求分割模型具有小的記憶體佔用空間和低運算成本。基於這些需求，我們引進了一種名為 MambaU-Lite 的新型輕量級模型，它結合了 Mamba 和 CNN 架構的優點，特點是只有超過 400K 個參數和超過 1G flops 的運算成本。為了增強全局背景和局部特徵萃取，我們提出了 P-Mamba 塊，這是一個新的組成部分，它結合了 VSS 塊和多個池化層，使模型能夠有效地學習多尺度特徵並增強分割性能。我們在兩個皮膚資料集 ISIC2018 和 PH2 上評估了模型的性能，產生了有希望的結果。我們的原始程式碼將公開於：https://github.com/nqnguyen812/MambaU-Lite。

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

摘要：近來，愈來愈多人於各種社群媒體平台發布其心理狀態。利用此資料，可以開發出基於 AI 的系統，用於評估個人的心理健康，例如自殺風險。本文是一項針對自殺風險評估的研究，利用 Reddit 資料，並利用基礎語言模型來識別社群媒體貼文的模式。我們已經證明，使用較小的語言模型（即小於 5 億個參數）也可以有效，這與參數大於 5 億個的 LLM 相比。我們提出 Su-RoBERTa，一個針對自殺風險預測任務進行微調的 RoBERTa，它利用標記和未標記的 Reddit 資料，並透過使用 GPT-2 模型進行資料擴充來解決類別不平衡的問題。我們的 Su-RoBERTa 模型在最終評估期間獲得了 69.84% 的加權 F1 分數。本文證明了基礎語言模型在分析與心理健康相關的風險因子方面的有效性，並具備高效的運算管道

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

摘要：醫療病患資料總是多模態的。影像、文字、年齡、性別、組織病理學資料只是此脈絡下不同模態的幾個例子。處理和整合這些多模態資料，並使用深度學習方法，由於其在醫療程序（例如診斷和病患治療計畫）的龐大潛力，因此至關重要。在這項工作中，我們重新訓練一個多模態Transformer基礎模型，用於疾病分類。為此，我們使用來自 OpenI 的文字影像配對資料集，其中包含與臨床報告相關的 2D 胸部 X 光。我們的重點在於融合方法，用於合併從醫療資料集提取的文字和影像資訊。測試了具有 LLaMA II 主幹模型的不同架構結構。特定於模態特徵的早期融合會產生更好的結果，最佳模型達到 97.10% 的平均 AUC，高於從架構更深層次進行的後期融合（最佳模型：96.67% 的平均 AUC）。兩者都優於在相同多模態資料集上測試的前分類模型。新推出的多模態架構可以毫不費力地應用於其他多模態資料集，並且可以輕鬆改編以進行進一步的研究，特別是（但不限於）醫療 AI 領域。

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

摘要：放射學實務的核心挑戰，在於整合複雜的影像資料與臨床資訊，以產生可行的見解。語言的細緻運用是各種活動的關鍵，包括管理請求、描述和解讀影像結果的臨床資料，以及簡潔地記錄和傳達結果。大型語言模型 (LLM) 的出現，提供了一個機會來改善放射學中大量資料的管理和解讀。儘管主要是一般用途，這些先進的計算模型在專業的語言相關任務中展現出令人印象深刻的能力，即使沒有特定的訓練。要解鎖 LLM 在放射學中的潛力，需要基本了解其基礎，以及應對其獨特之處的策略性方法。這篇評論從實務放射學和機器學習專業知識以及近期文獻中汲取，為讀者提供 LLM 在放射學中的潛力的見解。它檢視了迄今為止在 LLM 快速演變的領域中經得起時間考驗的最佳實務。這包括針對放射學實務最佳化 LLM 特性的實務建議，以及限制、有效的提示和微調策略。

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

摘要：物件追蹤是現代創新中的一項基本工具，應用於國防系統、自動駕駛車輛和生物醫學研究中。它能精準地辨識、監控和時空分析連續畫面中的物件，提供動態行為的見解。在細胞生物學中，物件追蹤對於揭露細胞機制至關重要，例如遷移、交互作用和對藥物或病原體的反應。這些見解推動了對疾病進程和治療干預的理解的突破。
隨著時間的推移，物件追蹤方法已從傳統的基於特徵的方法演變為先進的機器學習和深度學習架構。雖然傳統方法在受控環境中是可靠的，但它們在有遮擋、光線變化和物件密度高的複雜環境中會遇到困難。深度學習模型通過提供更高的準確性、適應性和魯棒性來應對這些挑戰。
本綜述將物件追蹤技術分為傳統、統計、基於特徵和機器學習範例，重點關注生物醫學應用。這些方法對於追蹤細胞和亞細胞結構至關重要，促進了我們對健康和疾病的理解。討論了關鍵的效能指標，包括準確性、效率和適應性。本文探討了當前方法的局限性，並重點介紹了新興趨勢，以指導下一代生物醫學研究和更廣泛的科學領域追蹤系統的開發。

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v2 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

摘要：最近已开发出几种评估指标，仅基于使用词法、语义或临床命名实体识别方法的文本信息，自动评估胸部 X 光片的生成式 AI 报告的质量。在本文中，我们开发了一种新的报告质量评估方法，首先提取细粒度的发现模式，捕捉大量临床发现的位置、左右性和严重性。然后，我们执行短语接地以定位其在胸部 X 光片图像上的相关解剖区域。然后将文本和视觉测量相结合，对生成报告的质量进行评分。我们展示了将此评估指标与其他文本指标在源自 MIMIC 集合的金标准数据集上进行比较的结果，并展示了其对事实错误的鲁棒性和敏感性。

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

摘要：傳統語言模型已廣泛評估軟體工程領域，但 ChatGPT 和 Gemini 的潛力尚未被完全探索。為了填補這個差距，本文提出了全面的案例研究，以探討這兩種語言模型在開發各種需求工程應用程式方面的潛力。它深入探討了不同層級專家知識提示對這兩種語言模型預測精度的影響。在 4 個不同的需求工程任務公共基準資料集，它比較了這兩種語言模型與現有任務特定機器/深度學習預測器和傳統語言模型的效能。具體來說，本文利用 4 個基準資料集；Pure（7,445 個樣本，需求萃取）、PROMISE（622 個樣本，需求分類）、REQuestA（300 個問答 (QA) 對）和航太資料集（6347 個字，需求 NER 標記）。我們的實驗顯示，與 ChatGPT 相比，Gemini 需要更仔細的提示工程才能提供準確的預測。此外，在需求萃取基準資料集，最先進的 F1 分數為 0.86，而 ChatGPT 和 Gemini 分別達到 0.76 和 0.77。需求分類資料集的最先進 F1 分數為 0.96，而這兩種語言模型都為 0.78。在命名實體識別 (NER) 任務中，最先進的 F1 分數為 0.92，而 ChatGPT 產生 0.36，Gemini 產生 0.25。類似地，在問答資料集，最先進的 F1 分數為 0.90，而 ChatGPT 和 Gemini 分別產生 0.91 和 0.88。我們的實驗表明，Gemini 需要比 ChatGPT 更精確的提示工程。除了問答之外，這兩個模型在其他任務的表現都低於目前的最新預測器。

##### **TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**
2412.00787v1 by Rulin Zhou, Yingjie Feng, Guankun Wang, Xiaopin Zhong, Zongze Wu, Qiang Wu, Xi Zhang

Adenoid hypertrophy stands as a common cause of obstructive sleep
apnea-hypopnea syndrome in children. It is characterized by snoring, nasal
congestion, and growth disorders. Computed Tomography (CT) emerges as a pivotal
medical imaging modality, utilizing X-rays and advanced computational
techniques to generate detailed cross-sectional images. Within the realm of
pediatric airway assessments, CT imaging provides an insightful perspective on
the shape and volume of enlarged adenoids. Despite the advances of deep
learning methods for medical imaging analysis, there remains an emptiness in
the segmentation of adenoid hypertrophy in CT scans. To address this research
gap, we introduce TSUBF-Nett (Trans-Spatial UNet-like Network based on
Bi-direction Fusion), a 3D medical image segmentation framework. TSUBF-Net is
engineered to effectively discern intricate 3D spatial interlayer features in
CT scans and enhance the extraction of boundary-blurring features. Notably, we
propose two innovative modules within the U-shaped network architecture:the
Trans-Spatial Perception module (TSP) and the Bi-directional Sampling
Collaborated Fusion module (BSCF).These two modules are in charge of operating
during the sampling process and strategically fusing down-sampled and
up-sampled features, respectively. Furthermore, we introduce the Sobel loss
term, which optimizes the smoothness of the segmentation results and enhances
model accuracy. Extensive 3D segmentation experiments are conducted on several
datasets. TSUBF-Net is superior to the state-of-the-art methods with the lowest
HD95: 7.03, IoU:85.63, and DSC: 92.26 on our own AHSD dataset. The results in
the other two public datasets also demonstrate that our methods can robustly
and effectively address the challenges of 3D segmentation in CT scans.

摘要：腺樣體肥大是兒童阻塞性睡眠呼吸中止低通氣綜合徵的常見原因。其特徵為打鼾、鼻塞和生長障礙。電腦斷層掃描 (CT) 是一種重要的醫學影像模式，利用 X 射線和先進的計算技術生成詳細的橫斷面影像。在小兒氣道評估領域，CT 影像提供了腺樣體肥大的形狀和體積的深刻見解。儘管深度學習方法在醫學影像分析方面取得了進展，但 CT 掃描中腺樣體肥大的分割仍存在空缺。為了解決這個研究差距，我們引入了 TSUBF-Nett（基於雙向融合的 Trans-Spatial UNet 類網路），這是一個 3D 醫學影像分割框架。TSUBF-Net 被設計為有效識別 CT 掃描中複雜的 3D 空間互層特徵，並增強邊界模糊特徵的提取。值得注意的是，我們在 U 形網路架構中提出了兩個創新的模組：Trans-Spatial 感知模組 (TSP) 和雙向採樣協作融合模組 (BSCF)。這兩個模組負責在採樣過程中運作，並分別策略性地融合下採樣和上採樣特徵。此外，我們引入了 Sobel 損失項，它優化了分割結果的平滑度並增強了模型的準確性。在多個資料集上進行了廣泛的 3D 分割實驗。TSUBF-Net 優於最先進的方法，在我們自己的 AHSD 資料集上具有最低的 HD95：7.03、IoU：85.63 和 DSC：92.26。其他兩個公共資料集中的結果也表明，我們的模型可以穩健有效地解決 CT 掃描中 3D 分割的挑戰。

##### **Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**
2412.00760v1 by Firdavs Nasriddinov, Rafal Kocielnik, Arushi Gupta, Cherine Yang, Elyssa Wong, Anima Anandkumar, Andrew Hung

This work introduces the first framework for reconstructing surgical dialogue
from unstructured real-world recordings, which is crucial for characterizing
teaching tasks. In surgical training, the formative verbal feedback that
trainers provide to trainees during live surgeries is crucial for ensuring
safety, correcting behavior immediately, and facilitating long-term skill
acquisition. However, analyzing and quantifying this feedback is challenging
due to its unstructured and specialized nature. Automated systems are essential
to manage these complexities at scale, allowing for the creation of structured
datasets that enhance feedback analysis and improve surgical education. Our
framework integrates voice activity detection, speaker diarization, and
automated speech recaognition, with a novel enhancement that 1) removes
hallucinations (non-existent utterances generated during speech recognition
fueled by noise in the operating room) and 2) separates speech from trainers
and trainees using few-shot voice samples. These aspects are vital for
reconstructing accurate surgical dialogues and understanding the roles of
operating room participants. Using data from 33 real-world surgeries, we
demonstrated the system's capability to reconstruct surgical teaching dialogues
and detect feedback instances effectively (F1 score of 0.79+/-0.07). Moreover,
our hallucination removal step improves feedback detection performance by ~14%.
Evaluation on downstream clinically relevant tasks of predicting Behavioral
Adjustment of trainees and classifying Technical feedback, showed performances
comparable to manual annotations with F1 scores of 0.82+/0.03 and 0.81+/0.03
respectively. These results highlight the effectiveness of our framework in
supporting clinically relevant tasks and improving over manual methods.

摘要：<paragraph>這項工作介紹了第一個用於重建手術對話的架構，該架構來自非結構化的真實世界錄音，這對於描述教學任務至關重要。在外科培訓中，培訓者在現場手術期間向受訓者提供的形成性言語回饋對於確保安全、立即糾正行為和促進長期技能習得至關重要。然而，由於其非結構化和專業性質，對此回饋進行分析和量化具有挑戰性。自動化系統對於大規模管理這些複雜性至關重要，允許創建結構化的資料集，以增強回饋分析並改善外科教育。我們的架構整合了語音活動偵測、說話者日記和自動語音識別，並具有一個新穎的增強功能，該功能 1) 消除了幻覺（在手術室的噪音引發語音識別期間產生的不存在的語句）和 2) 使用少數語音樣本將培訓者和受訓者的語音分開。這些方面對於重建準確的手術對話和理解手術室參與者的角色至關重要。使用來自 33 次真實手術的資料，我們展示了該系統重建手術教學對話和有效檢測回饋實例的能力（F1 分數為 0.79+/-0.07）。此外，我們的幻覺消除步驟將回饋檢測效能提升了約 14%。在預測受訓者的行為調整和分類技術回饋的下游臨床相關任務的評估中，顯示出與 F1 分數分別為 0.82+/0.03 和 0.81+/0.03 的手動標註相當的效能。這些結果突顯了我們的架構在支援臨床相關任務和改進手動方法方面的有效性。</paragraph>

##### **Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**
2412.00606v1 by Resmi Ramachandranpillai, Kishore Sampath, Ayaazuddin Mohammad, Malihe Alikhani

Biases in automated clinical decision-making using Electronic Healthcare
Records (EHR) impose significant disparities in patient care and treatment
outcomes. Conventional approaches have primarily focused on bias mitigation
strategies stemming from single attributes, overlooking intersectional
subgroups -- groups formed across various demographic intersections (such as
race, gender, ethnicity, etc.). Rendering single-attribute mitigation
strategies to intersectional subgroups becomes statistically irrelevant due to
the varying distribution and bias patterns across these subgroups. The
multimodal nature of EHR -- data from various sources such as combinations of
text, time series, tabular, events, and images -- adds another layer of
complexity as the influence on minority groups may fluctuate across modalities.
In this paper, we take the initial steps to uncover potential intersectional
biases in predictions by sourcing extensive multimodal datasets, MIMIC-Eye1 and
MIMIC-IV ED, and propose mitigation at the intersectional subgroup level. We
perform and benchmark downstream tasks and bias evaluation on the datasets by
learning a unified text representation from multimodal sources, harnessing the
enormous capabilities of the pre-trained clinical Language Models (LM),
MedBERT, Clinical BERT, and Clinical BioBERT. Our findings indicate that the
proposed sub-group-specific bias mitigation is robust across different
datasets, subgroups, and embeddings, demonstrating effectiveness in addressing
intersectional biases in multimodal settings.

摘要：電子病歷 (EHR) 中自動化臨床決策的偏差會對患者照護和治療結果造成顯著的差異。傳統方法主要專注於單一屬性的偏差緩解策略，忽略了交叉群體——在各種人口統計交叉點（例如種族、性別、種族等）形成的群體。由於這些子群的分布和偏差模式不同，將單一屬性緩解策略應用於交叉子群在統計上變得無關緊要。EHR 的多模態性質——來自各種來源的數據，例如文本、時間序列、表格、事件和圖像的組合——增加了另一層複雜性，因為對少數群體的影響可能會在不同模式之間波動。在本文中，我們採取了初步步驟，通過採集廣泛的多模態數據集 MIMIC-Eye1 和 MIMIC-IV ED 來揭示預測中的潛在交叉偏差，並提出在交叉子群級別進行緩解。我們通過從多模態來源學習統一的文本表示，利用預訓練的臨床語言模型 (LM)、MedBERT、Clinical BERT 和 Clinical BioBERT 的強大功能，對數據集執行並基準下游任務和偏差評估。我們的研究結果表明，所提出的子群特定偏差緩解在不同的數據集、子群和嵌入中都是穩健的，證明了在多模態設置中解決交叉偏差的有效性。

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v2 by Théo Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include integrating a Work
Knowledge Graph (WKG) into a Large Work Model (LWM) to enable the generation of
context-aware, semantically aligned, structured and auditable Workflows. It
further introduces a two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. Finally, we present Opus
Alpha 1 Large and Opus Alpha 1 Small that outperform state-of-the-art LLMs by
38% and 29% respectively in Workflow Generation for a Medical Coding use case.

摘要：這篇論文介紹了 Opus，一個用於產生和最佳化工作流程的新穎架構，專為複雜的業務流程外包 (BPO) 使用案例量身打造，重點在於降低成本和提升品質，同時遵守既定的產業流程和營運限制。我們的做法根據意圖產生可執行的工作流程，意圖定義為客戶輸入、客戶輸出和流程背景的對齊。這些工作流程表示為有向無環圖 (DAG)，節點為包含可執行指令序列的任務，包括工具和人類專家的審查。我們採用兩階段方法：工作流程產生和工作流程最佳化。在產生階段，工作流程使用大型工作模型 (LWM) 產生，該模型由編碼特定領域程序和運作知識的工作知識圖 (WKG) 提供資訊。在最佳化階段，工作流程轉換為工作流程圖 (WFG)，其中通過路徑最佳化來確定最佳工作流程。我們的實驗表明，最先進的大型語言模型 (LLM) 在可靠地擷取詳細的流程資料以及產生符合產業規範的工作流程方面面臨挑戰。這篇論文的主要貢獻包括將工作知識圖 (WKG) 整合到大型工作模型 (LWM) 中，以產生具備情境感知、語義對齊、結構化和可稽核的工作流程。它進一步介紹了一種兩階段方法，將基於意圖的工作流程產生與基於圖形的工作流程最佳化相結合。最後，我們展示了 Opus Alpha 1 Large 和 Opus Alpha 1 Small，它們在醫療編碼使用案例中分別比最先進的 LLM 在工作流程產生方面高出 38% 和 29%。

##### **Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**
2412.00559v1 by Łukasz Grzybowski, Jakub Pokrywka, Michał Ciesiółka, Jeremi I. Kaczmarek, Marek Kubis

Large Language Models (LLMs) have demonstrated significant potential in
handling specialized tasks, including medical problem-solving. However, most
studies predominantly focus on English-language contexts. This study introduces
a novel benchmark dataset based on Polish medical licensing and specialization
exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing
doctors pursuing specialization. The dataset was web-scraped from publicly
available resources provided by the Medical Examination Center and the Chief
Medical Chamber. It comprises over 24,000 exam questions, including a subset of
parallel Polish-English corpora, where the English portion was professionally
translated by the examination center for foreign candidates. By creating a
structured benchmark from these existing exam questions, we systematically
evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and
Polish-specific models, and compare their performance against human medical
students. Our analysis reveals that while models like GPT-4o achieve near-human
performance, significant challenges persist in cross-lingual translation and
domain-specific understanding. These findings underscore disparities in model
performance across languages and medical specialties, highlighting the
limitations and ethical considerations of deploying LLMs in clinical practice.

摘要：大型語言模型 (LLM) 已展現出在處理專業任務（包括醫療問題解決）方面具有的顯著潛力。然而，大多數研究主要關注於英語語境。本研究引入了基於波蘭醫學許可和專科考試 (LEK、LDEK、PES) 的新基準資料集，由醫學博士候選人和從事專科的執業醫生參加。該資料集從醫學考試中心和首席醫學部門提供的公開資源中進行網路抓取。它包含超過 24,000 個考試題目，包括波蘭語-英語語料庫的子集，其中英語部分由考試中心為外籍考生專業翻譯。通過根據這些現有考試題目建立結構化基準，我們系統性地評估了最先進的 LLM，包括通用、特定領域和特定於波蘭的模型，並將其性能與人類醫學生進行比較。我們的分析表明，儘管 GPT-4o 等模型達到了接近人類的性能，但跨語言翻譯和特定領域理解中仍然存在重大挑戰。這些發現強調了跨語言和醫學專業的模型性能差異，突顯了在臨床實踐中部署 LLM 的局限性和倫理考量。

##### **Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**
2412.00554v2 by Yue Zhou, Barbara Di Eugenio, Lu Cheng

This paper studies the performance of large language models (LLMs),
particularly regarding demographic fairness, in solving real-world healthcare
tasks. We evaluate state-of-the-art LLMs with three prevalent learning
frameworks across six diverse healthcare tasks and find significant challenges
in applying LLMs to real-world healthcare tasks and persistent fairness issues
across demographic groups. We also find that explicitly providing demographic
information yields mixed results, while LLM's ability to infer such details
raises concerns about biased health predictions. Utilizing LLMs as autonomous
agents with access to up-to-date guidelines does not guarantee performance
improvement. We believe these findings reveal the critical limitations of LLMs
in healthcare fairness and the urgent need for specialized research in this
area.

摘要：本文研究大型語言模型 (LLM) 的效能，特別是在解決真實世界的醫療保健任務時的人口統計公平性方面。我們使用三種流行的學習架構，在六項不同的醫療保健任務中評估最先進的 LLM，並發現將 LLM 應用於真實世界的醫療保健任務時有重大挑戰，以及不同人口統計群體之間持續存在公平性問題。我們還發現，明確提供人口統計資訊會產生好壞參半的結果，而 LLM 推斷此類細節的能力引發了對有偏差的健康預測的擔憂。利用 LLM 作為具有存取最新指南的自主代理並不保證效能會提升。我們相信這些發現揭示了 LLM 在醫療保健公平性方面的重大限制，以及對此領域進行專門研究的迫切需要。

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**
2412.00315v1 by Jingzhe Liu, Haitao Mao, Zhikai Chen, Wenqi Fan, Mingxuan Ju, Tong Zhao, Neil Shah, Jiliang Tang

Graph Neural Networks (GNNs) have emerged as a powerful tool to capture
intricate network patterns, achieving success across different domains.
However, existing GNNs require careful domain-specific architecture designs and
training from scratch on each dataset, leading to an expertise-intensive
process with difficulty in generalizing across graphs from different domains.
Therefore, it can be hard for practitioners to infer which GNN model can
generalize well to graphs from their domains. To address this challenge, we
propose a novel cross-domain pretraining framework, "one model for one graph,"
which overcomes the limitations of previous approaches that failed to use a
single GNN to capture diverse graph patterns across domains with significant
gaps. Specifically, we pretrain a bank of expert models, with each one
corresponding to a specific dataset. When inferring to a new graph, gating
functions choose a subset of experts to effectively integrate prior model
knowledge while avoiding negative transfer. Extensive experiments consistently
demonstrate the superiority of our proposed method on both link prediction and
node classification tasks.

摘要：圖形神經網路 (GNN) 已成為捕捉複雜網路模式的強大工具，在不同領域皆取得成功。
然而，現有的 GNN 需要仔細的特定於領域的架構設計，並針對每個資料集從頭開始訓練，導致專業知識密集的過程，難以概括來自不同領域的圖形。
因此，從業者很難推斷哪個 GNN 模型可以很好地概括到其領域的圖形。為了應對這一挑戰，我們提出了一個新穎的跨領域預訓練框架，「一個模型對應一個圖形」，它克服了先前方法的限制，這些限制無法使用單個 GNN 來捕捉跨越具有顯著差距的領域的不同圖形模式。具體來說，我們預訓練了一組專家模型，每一個都對應一個特定資料集。在推論到一個新圖形時，閘控函數會選擇一個專家子集，以有效整合先前的模型知識，同時避免負面傳遞。廣泛的實驗持續證明了我們提出的方法在連結預測和節點分類任務上的優越性。

##### **BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**
2412.00308v1 by Karine Karine, Susan A. Murphy, Benjamin M. Marlin

In settings where the application of reinforcement learning (RL) requires
running real-world trials, including the optimization of adaptive health
interventions, the number of episodes available for learning can be severely
limited due to cost or time constraints. In this setting, the bias-variance
trade-off of contextual bandit methods can be significantly better than that of
more complex full RL methods. However, Thompson sampling bandits are limited to
selecting actions based on distributions of immediate rewards. In this paper,
we extend the linear Thompson sampling bandit to select actions based on a
state-action utility function consisting of the Thompson sampler's estimate of
the expected immediate reward combined with an action bias term. We use batch
Bayesian optimization over episodes to learn the action bias terms with the
goal of maximizing the expected return of the extended Thompson sampler. The
proposed approach is able to learn optimal policies for a strictly broader
class of Markov decision processes (MDPs) than standard Thompson sampling.
Using an adaptive intervention simulation environment that captures key aspects
of behavioral dynamics, we show that the proposed method can significantly
out-perform standard Thompson sampling in terms of total return, while
requiring significantly fewer episodes than standard value function and policy
gradient methods.

摘要：在需要使用強化學習 (RL) 進行實際世界試驗，包括最佳化適應性健康干預措施的設定中，可用於學習的回合數可能會因為成本或時間限制而受到嚴重限制。在此設定中，情境強盜方法的偏差變異取捨會顯著優於更複雜的完整 RL 方法。不過，湯普森抽樣強盜只能根據立即獎勵的分配來選擇行動。在本文中，我們延伸線性湯普森抽樣強盜，以根據狀態行動效用函數選擇行動，該函數包含湯普森採樣器對預期立即獎勵的估計值，以及動作偏差項。我們使用批次貝氏最佳化在回合中學習動作偏差項，目標是最大化延伸湯普森採樣器的預期回報。提出的方法能夠為比標準湯普森抽樣更廣泛的馬可夫決策程序 (MDP) 類別學習最佳策略。使用捕捉行為動態關鍵層面的適應性干預模擬環境，我們證明所提出的方法在總回報方面可以顯著優於標準湯普森抽樣，同時所需回合數遠少於標準價值函數和策略梯度方法。

##### **Fine Tuning Large Language Models to Deliver CBT for Depression**
2412.00251v1 by Talha Tahir

Cognitive Behavioral Therapy (CBT) is a well-established, evidence-based
treatment for Major Depressive Disorder. Unfortunately, there exist significant
barriers to individuals accessing CBT, including cost, scarcity of therapists
and stigma. This study explores the feasibility of fine-tuning small open
weight large language models (LLMs) to deliver CBT for depression. Using 58
sets of synthetic CBT transcripts generated by the Nous Research fine-tune of
Llama 3.1 405b, we fine-tuned three models: Mistral 7b v0.3, Qwen 2.5 7b, and
Llama 3.1 8b. CBT fidelity was evaluated through a modified Cognitive Therapy
Rating Scale (CTRS). All fine-tuned models were compared against each other, as
well as their instruct-tuned variants. Simulated patient transcripts were
generated for the purpose of evaluating model performance, with the instruct
and CBT-tuned models acting as the therapist and DeepSeek-V2.5 acting as the
patient. These simulated transcripts were evaluated on a modified CTRS by
Gemini 1.5 Pro-002. Our findings demonstrated that the CBT-tuned models
significantly outperformed their instruct-tuned counterparts, with an average
improvement of 11.33 points (p < 0.001) on total CTRS score. Llama 3.1 8b had
the strongest performance (mean CTRS score 67.86 +/- 7.24), followed by Qwen
2.5 7b (64.28 +/- 9.55) and Mistral 7b v0.3 (64.17 +/- 9.79), with these
differences between models being statistically significant. The CBT-tuned
models were competent in implementing core CBT techniques and providing
empathetic responses, however, there were limitations observed in agenda
adherence, exploration depth and long-context coherence. This study establishes
that CBT specific fine-tuning can effectively encode therapeutic competencies
in small LLMs, though significant technical and ethical considerations must be
resolved prior to clinical deployment.

摘要：<paragraph>認知行為療法 (CBT) 是一種治療重度憂鬱症的完善且有實證基礎的療法。不幸的是，個人接受 CBT 仍存在重大障礙，包括費用、治療師稀缺和汙名化。本研究探討微調小型開放式權重大型語言模型 (LLM) 以提供 CBT 治療憂鬱症的可行性。使用 Nous Research 微調 Llama 3.1 405b 所產生的 58 組合成 CBT 謄本，我們微調了三個模型：Mistral 7b v0.3、Qwen 2.5 7b 和 Llama 3.1 8b。CBT 保真度透過修正後的認知治療評分量表 (CTRS) 進行評估。所有微調模型彼此比較，以及它們的指令微調變體。模擬患者謄本是為了評估模型效能而產生的，指令和 CBT 微調模型扮演治療師，而 DeepSeek-V2.5 扮演患者。這些模擬謄本由 Gemini 1.5 Pro-002 使用修正後的 CTRS 進行評估。我們的研究結果顯示，CBT 微調模型顯著優於其指令微調模型，CTRS 總分平均提升 11.33 分 (p < 0.001)。Llama 3.1 8b 效能最強 (CTRS 平均分數 67.86 +/- 7.24)，其次是 Qwen 2.5 7b (64.28 +/- 9.55) 和 Mistral 7b v0.3 (64.17 +/- 9.79)，這些模型之間的差異具有統計顯著性。CBT 微調模型在實施核心 CBT 技術和提供同理回應方面表現得很好，然而在議程遵循、探索深度和長脈絡連貫性方面仍有觀察到的限制。本研究證實，特定於 CBT 的微調可以有效地將治療能力編碼到小型 LLM 中，儘管在臨床部署之前必須解決重大的技術和倫理考量。</paragraph>

##### **Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**
2412.00245v1 by Tianqi Shang, Weiqing He, Tianlong Chen, Ying Ding, Huanmei Wu, Kaixiong Zhou, Li Shen

Social determinants of health (SDoH) play a crucial role in patient health
outcomes, yet their integration into biomedical knowledge graphs remains
underexplored. This study addresses this gap by constructing an SDoH-enriched
knowledge graph using the MIMIC-III dataset and PrimeKG. We introduce a novel
fairness formulation for graph embeddings, focusing on invariance with respect
to sensitive SDoH information. Via employing a heterogeneous-GCN model for
drug-disease link prediction, we detect biases related to various SDoH factors.
To mitigate these biases, we propose a post-processing method that
strategically reweights edges connected to SDoHs, balancing their influence on
graph representations. This approach represents one of the first comprehensive
investigations into fairness issues within biomedical knowledge graphs
incorporating SDoH. Our work not only highlights the importance of considering
SDoH in medical informatics but also provides a concrete method for reducing
SDoH-related biases in link prediction tasks, paving the way for more equitable
healthcare recommendations. Our code is available at
\url{https://github.com/hwq0726/SDoH-KG}.

摘要：社會健康決定因素（SDoH）在患者健康結果中扮演著至關重要的角色，但它們整合到生物醫學知識圖譜中的部分仍有待探討。本研究透過使用 MIMIC-III 資料集和 PrimeKG 建構一個 SDoH 豐富的知識圖譜來解決這個差距。我們針對圖形嵌入引入一個新的公平性公式，專注於對敏感的 SDoH 資訊保持不變性。透過採用異質 GCN 模型進行藥物疾病連結預測，我們偵測到與各種 SDoH 因子相關的偏差。為了減輕這些偏差，我們提出一個後處理方法，該方法策略性地重新加權連接到 SDoH 的邊緣，平衡它們對圖表表示的影響。此方法代表了將 SDoH 納入生物醫學知識圖譜中公平性問題的第一個全面調查之一。我們的研究不僅強調了在醫學資訊學中考量 SDoH 的重要性，也提供了一個具體的方法來減少連結預測任務中與 SDoH 相關的偏差，為更公平的醫療保健建議鋪路。我們的程式碼可在 \url{https://github.com/hwq0726/SDoH-KG} 取得。

##### **Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**
2411.19922v1 by Guiran Liu, Binrong Zhu

This study investigated the dynamic connectivity patterns between EEG and
fMRI modalities, contributing to our understanding of brain network
interactions. By employing a comprehensive approach that integrated static and
dynamic analyses of EEG-fMRI data, we were able to uncover distinct
connectivity states and characterize their temporal fluctuations. The results
revealed modular organization within the intrinsic connectivity networks (ICNs)
of the brain, highlighting the significant roles of sensory systems and the
default mode network. The use of a sliding window technique allowed us to
assess how functional connectivity varies over time, further elucidating the
transient nature of brain connectivity. Additionally, our findings align with
previous literature, reinforcing the notion that cognitive states can be
effectively identified through short-duration data, specifically within the
30-60 second timeframe. The established relationships between connectivity
strength and cognitive processes, particularly during different visual states,
underscore the relevance of our approach for future research into brain
dynamics. Overall, this study not only enhances our understanding of the
interplay between EEG and fMRI signals but also paves the way for further
exploration into the neural correlates of cognitive functions and their
implications in clinical settings. Future research should focus on refining
these methodologies and exploring their applications in various cognitive and
clinical contexts.

摘要：本研究調查了腦電圖和功能性磁振造影之間的動態連接模式，有助於我們了解腦網路互動。透過採用整合靜態和動態腦電圖功能性磁振造影資料分析的綜合方法，我們得以揭示不同的連接狀態並描述其時間波動。結果顯示腦部內在連接網路 (ICN) 中的模組化組織，突顯了感官系統和預設模式網路的重要角色。滑動視窗技術的使用讓我們得以評估功能性連接如何隨時間變化，進一步闡明腦部連接的暫時性。此外，我們的研究結果與先前的文獻一致，強化了透過短時資料（特別是在 30-60 秒的時間範圍內）可以有效識別認知狀態的概念。連接強度和認知過程之間建立的關係，特別是在不同的視覺狀態下，強調了我們的途徑與未來腦部動態研究相關性。整體而言，本研究不僅增強了我們對腦電圖和功能性磁振造影訊號之間交互作用的理解，也為進一步探索認知功能的神經相關性及其在臨床環境中的意義鋪路。未來的研究應專注於優化這些方法並探討其在各種認知和臨床背景中的應用。

##### **Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**
2411.19742v1 by Heloisa Oss Boll, Ali Amirahmadi, Amira Soliman, Stefan Byttner, Mariana Recamonde-Mendoza

Objective: In modern healthcare, accurately predicting diseases is a crucial
matter. This study introduces a novel approach using graph neural networks
(GNNs) and a Graph Transformer (GT) to predict the incidence of heart failure
(HF) on a patient similarity graph at the next hospital visit. Materials and
Methods: We used electronic health records (EHR) from the MIMIC-III dataset and
applied the K-Nearest Neighbors (KNN) algorithm to create a patient similarity
graph using embeddings from diagnoses, procedures, and medications. Three
models - GraphSAGE, Graph Attention Network (GAT), and Graph Transformer (GT) -
were implemented to predict HF incidence. Model performance was evaluated using
F1 score, AUROC, and AUPRC metrics, and results were compared against baseline
algorithms. An interpretability analysis was performed to understand the
model's decision-making process. Results: The GT model demonstrated the best
performance (F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168). Although the
Random Forest (RF) baseline achieved a similar AUPRC value, the GT model
offered enhanced interpretability due to the use of patient relationships in
the graph structure. A joint analysis of attention weights, graph connectivity,
and clinical features provided insight into model predictions across different
classification groups. Discussion and Conclusion: Graph-based approaches such
as GNNs provide an effective framework for predicting HF. By leveraging a
patient similarity graph, GNNs can capture complex relationships in EHR data,
potentially improving prediction accuracy and clinical interpretability.

摘要：<paragraph>目標：在現代醫療保健中，準確預測疾病是一項至關重要的問題。本研究介紹了一種使用圖神經網絡 (GNN) 和圖形轉換器 (GT) 的新方法，用於預測下次醫院就診時患者相似圖表上的心臟衰竭 (HF) 發生率。材料和方法：我們使用了 MIMIC-III 資料集中的電子健康記錄 (EHR)，並應用 K-最近鄰 (KNN) 演算法，使用來自診斷、程序和藥物的嵌入來建立患者相似圖表。實作了三個模型 - GraphSAGE、圖形注意力網路 (GAT) 和圖形轉換器 (GT) - 來預測 HF 發生率。使用 F1 分數、AUROC 和 AUPRC 指標評估模型效能，並將結果與基準演算法進行比較。執行了解釋性分析以了解模型的決策過程。結果：GT 模型表現出最佳效能 (F1 分數：0.5361，AUROC：0.7925，AUPRC：0.5168)。儘管隨機森林 (RF) 基準達到了類似的 AUPRC 值，但由於在圖形結構中使用了患者關係，因此 GT 模型提供了增強的解釋性。對注意力權重、圖形連通性和臨床特徵的聯合分析提供了對不同分類群組中模型預測的見解。討論和結論：基於圖形的方法（例如 GNN）提供了預測 HF 的有效框架。透過利用患者相似圖形，GNN 可以擷取 EHR 資料中的複雜關係，進而可能提高預測準確度和臨床解釋性。</paragraph>

##### **Multimodal Whole Slide Foundation Model for Pathology**
2411.19666v1 by Tong Ding, Sophia J. Wagner, Andrew H. Song, Richard J. Chen, Ming Y. Lu, Andrew Zhang, Anurag J. Vaidya, Guillaume Jaume, Muhammad Shaban, Ahrong Kim, Drew F. K. Williamson, Bowen Chen, Cristina Almagro-Perez, Paul Doucet, Sharifa Sahai, Chengkuan Chen, Daisuke Komura, Akihiro Kawabe, Shumpei Ishikawa, Georg Gerber, Tingying Peng, Long Phi Le, Faisal Mahmood

The field of computational pathology has been transformed with recent
advances in foundation models that encode histopathology region-of-interests
(ROIs) into versatile and transferable feature representations via
self-supervised learning (SSL). However, translating these advancements to
address complex clinical challenges at the patient and slide level remains
constrained by limited clinical data in disease-specific cohorts, especially
for rare clinical conditions. We propose TITAN, a multimodal whole slide
foundation model pretrained using 335,645 WSIs via visual self-supervised
learning and vision-language alignment with corresponding pathology reports and
423,122 synthetic captions generated from a multimodal generative AI copilot
for pathology. Without any finetuning or requiring clinical labels, TITAN can
extract general-purpose slide representations and generate pathology reports
that generalize to resource-limited clinical scenarios such as rare disease
retrieval and cancer prognosis. We evaluate TITAN on diverse clinical tasks and
find that TITAN outperforms both ROI and slide foundation models across machine
learning settings such as linear probing, few-shot and zero-shot
classification, rare cancer retrieval and cross-modal retrieval, and pathology
report generation.

摘要：計算病理學領域已因基礎模型的最新進展而轉型，這些模型透過自監督學習 (SSL) 將組織病理學感興趣區域 (ROI) 編碼成多功能且可轉移的特徵表示。然而，要解決患者和切片層面的複雜臨床挑戰，將這些進展轉化為解決方案仍受限於特定疾病群體中有限的臨床資料，尤其是罕見的臨床情況。我們提出 TITAN，這是一個多模態全切片基礎模型，使用 335,645 個 WSI 透過視覺自監督學習和與對應病理報告的視覺語言對齊，以及由多模態生成式 AI 輔助員為病理學生成的 423,122 個合成標題進行預訓練。在沒有任何微調或需要臨床標籤的情況下，TITAN 可以提取通用切片表示，並生成病理報告，以概括到資源有限的臨床場景，例如罕見疾病檢索和癌症預後。我們在不同的臨床任務上評估 TITAN，發現 TITAN 在機器學習設定中優於 ROI 和切片基礎模型，例如線性探查、少次學習和零次學習分類、罕見癌症檢索和跨模態檢索，以及病理報告生成。

##### **SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders**
2411.19544v1 by Niki Martinel, Mariano Serrao, Christian Micheloni

We introduce a novel state-space model (SSM)-based framework for
skeleton-based human action recognition, with an anatomically-guided
architecture that improves state-of-the-art performance in both clinical
diagnostics and general action recognition tasks. Our approach decomposes
skeletal motion analysis into spatial, temporal, and spatio-temporal streams,
using channel partitioning to capture distinct movement characteristics
efficiently. By implementing a structured, multi-directional scanning strategy
within SSMs, our model captures local joint interactions and global motion
patterns across multiple anatomical body parts. This anatomically-aware
decomposition enhances the ability to identify subtle motion patterns critical
in medical diagnosis, such as gait anomalies associated with neurological
conditions. On public action recognition benchmarks, i.e., NTU RGB+D, NTU RGB+D
120, and NW-UCLA, our model outperforms current state-of-the-art methods,
achieving accuracy improvements up to $3.2\%$ with lower computational
complexity than previous leading transformer-based models. We also introduce a
novel medical dataset for motion-based patient neurological disorder analysis
to validate our method's potential in automated disease diagnosis.

摘要：<paragraph>我們提出一個新穎的基於狀態空間模型 (SSM) 的框架，用於基於骨架的人類動作識別，它具有解剖學指導架構，可改善臨床診斷和一般動作識別任務的最新技術性能。我們的做法將骨骼運動分析分解為空間、時間和時空流，使用通道分割來有效捕捉不同的運動特徵。通過在 SSM 中實施結構化、多向掃描策略，我們的模型捕捉到多個解剖身體部位的局部關節交互和整體運動模式。這種解剖學感知分解增強了識別微妙運動模式的能力，這些模式在醫學診斷中至關重要，例如與神經系統疾病相關的步態異常。在公共動作識別基準上，即 NTU RGB+D、NTU RGB+D 120 和 NW-UCLA，我們的模型優於當前最先進的方法，與以前領先的基於Transformer的模型相比，在較低的計算複雜度下實現了高達 3.2% 的準確度改進。我們還引入了一個新的醫學數據集，用於基於運動的患者神經系統疾病分析，以驗證我們的方法在自動疾病診斷中的潛力。</paragraph>

##### **Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification**
2411.19502v1 by Ruimin Peng, Jiayu An, Dongrui Wu

Electroencephalogram (EEG)-based seizure subtype classification enhances
clinical diagnosis efficiency. Source-free semi-supervised domain adaptation
(SF-SSDA), which transfers a pre-trained model to a new dataset with no source
data and limited labeled target data, can be used for privacy-preserving
seizure subtype classification. This paper considers two challenges in SF-SSDA
for EEG-based seizure subtype classification: 1) How to effectively fuse both
raw EEG data and expert knowledge in classifier design? 2) How to align the
source and target domain distributions for SF-SSDA? We propose a Knowledge-Data
Fusion based SF-SSDA approach, KDF-MutualSHOT, for EEG-based seizure subtype
classification. In source model training, KDF uses Jensen-Shannon Divergence to
facilitate mutual learning between a feature-driven Decision Tree-based model
and a data-driven Transformer-based model. To adapt KDF to a new target
dataset, an SF-SSDA algorithm, MutualSHOT, is developed, which features a
consistency-based pseudo-label selection strategy. Experiments on the public
TUSZ and CHSZ datasets demonstrated that KDF-MutualSHOT outperformed other
supervised and source-free domain adaptation approaches in cross-subject
seizure subtype classification.

摘要：基於腦電圖 (EEG) 的癲癇亞型分類可提升臨床診斷效率。無來源半監督領域適應 (SF-SSDA) 可將預先訓練的模型轉移至沒有來源資料且標籤目標資料有限的新資料集，可用於隱私保護的癲癇亞型分類。本文探討 SF-SSDA 在基於 EEG 的癲癇亞型分類中的兩個挑戰：1) 如何有效融合原始 EEG 資料和分類器設計中的專家知識？2) 如何調整 SF-SSDA 的來源和目標網域分佈？我們提出一個基於知識資料融合的 SF-SSDA 方法，KDF-MutualSHOT，用於基於 EEG 的癲癇亞型分類。在來源模型訓練中，KDF 使用 Jensen-Shannon 距離促進特徵驅動的決策樹模型和資料驅動的 Transformer 模型之間的相互學習。為了將 KDF 調整至新的目標資料集，開發了一個 SF-SSDA 演算法，MutualSHOT，其特點是基於一致性的偽標籤選擇策略。在公開的 TUSZ 和 CHSZ 資料集上的實驗表明，KDF-MutualSHOT 在跨受試者癲癇亞型分類中優於其他監督式和無來源領域適應方法。

##### **Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine**
2411.19447v1 by Zhi Li, Kai Zhao, Yaqi Wang, Shuai Wang

In medical image analysis, achieving fast, efficient, and accurate
segmentation is essential for automated diagnosis and treatment. Although
recent advancements in deep learning have significantly improved segmentation
accuracy, current models often face challenges in adaptability and
generalization, particularly when processing multi-modal medical imaging data.
These limitations stem from the substantial variations between imaging
modalities and the inherent complexity of medical data. To address these
challenges, we propose the Strategy-driven Interactive Segmentation Model
(SISeg), built on SAM2, which enhances segmentation performance across various
medical imaging modalities by integrating a selection engine. To mitigate
memory bottlenecks and optimize prompt frame selection during the inference of
2D image sequences, we developed an automated system, the Adaptive Frame
Selection Engine (AFSE). This system dynamically selects the optimal prompt
frames without requiring extensive prior medical knowledge and enhances the
interpretability of the model's inference process through an interactive
feedback mechanism. We conducted extensive experiments on 10 datasets covering
7 representative medical imaging modalities, demonstrating the SISeg model's
robust adaptability and generalization in multi-modal tasks. The project page
and code will be available at: [URL].

摘要：在医学影像分析中，实现快速、高效和准确的分割对于自动化诊断和治疗至关重要。尽管深度学习的最新进展显著提高了分割准确性，但当前模型在适应性和泛化性方面常常面临挑战，尤其是在处理多模态医学影像数据时。这些限制源于影像方式之间的巨大差异和医学数据的固有复杂性。为了应对这些挑战，我们提出了基于 SAM2 的策略驱动交互式分割模型 (SISeg)，它通过集成选择引擎来增强各种医学影像方式的分割性能。为了缓解内存瓶颈并优化 2D 图像序列推理期间的提示帧选择，我们开发了一个自动化系统，即自适应帧选择引擎 (AFSE)。该系统在无需广泛的先前医学知识的情况下动态选择最佳提示帧，并通过交互式反馈机制增强模型推理过程的可解释性。我们在涵盖 7 种代表性医学影像方式的 10 个数据集上进行了广泛的实验，展示了 SISeg 模型在多模态任务中的鲁棒适应性和泛化性。项目页面和代码将提供在：[URL]。

##### **Libra: Leveraging Temporal Images for Biomedical Radiology Analysis**
2411.19378v1 by Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho

Radiology report generation (RRG) is a challenging task, as it requires a
thorough understanding of medical images, integration of multiple temporal
inputs, and accurate report generation. Effective interpretation of medical
images, such as chest X-rays (CXRs), demands sophisticated visual-language
reasoning to map visual findings to structured reports. Recent studies have
shown that multimodal large language models (MLLMs) can acquire multimodal
capabilities by aligning with pre-trained vision encoders. However, current
approaches predominantly focus on single-image analysis or utilise rule-based
symbolic processing to handle multiple images, thereby overlooking the
essential temporal information derived from comparing current images with prior
ones. To overcome this critical limitation, we introduce Libra, a
temporal-aware MLLM tailored for CXR report generation using temporal images.
Libra integrates a radiology-specific image encoder with a MLLM and utilises a
novel Temporal Alignment Connector to capture and synthesise temporal
information of images across different time points with unprecedented
precision. Extensive experiments show that Libra achieves new state-of-the-art
performance among the same parameter scale MLLMs for RRG tasks on the
MIMIC-CXR. Specifically, Libra improves the RadCliQ metric by 12.9% and makes
substantial gains across all lexical metrics compared to previous models.

摘要：放射學報告生成 (RRG) 是一項具有挑戰性的任務，因為它需要透徹了解醫學影像、整合多個時間輸入以及準確的報告生成。有效解讀醫學影像，例如胸部 X 光 (CXR)，需要複雜的視覺語言推理才能將視覺發現對應到結構化的報告中。最近的研究表明，多模態大型語言模型 (MLLM) 可以透過與預先訓練的視覺編碼器對齊來獲得多模態能力。然而，目前的方法主要專注於單一影像分析或利用基於規則的符號處理來處理多個影像，從而忽略了從比較當前影像與先前影像中得出的基本時間資訊。為了克服這個關鍵限制，我們引入了 Libra，一個專為使用時間影像進行 CXR 報告生成的時態感知 MLLM。Libra 將放射學專用影像編碼器與 MLLM 整合在一起，並利用一個新穎的時間對齊連接器來擷取和合成不同時間點影像的時間資訊，並具有前所未有的精確度。廣泛的實驗表明，Libra 在 MIMIC-CXR 的 RRG 任務中，在同參數規模的 MLLM 中取得了新的最先進效能。具體來說，Libra 將 RadCliQ 指標提升了 12.9%，並在所有詞彙指標方面都比以前的模型取得了顯著進步。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **FonTS: Text Rendering with Typography and Style Controls**
2412.00136v1 by Wenda Shi, Yiren Song, Dengming Zhang, Jiaming Liu, Xingxing Zou

Visual text images are prevalent in various applications, requiring careful
font selection and typographic choices. Recent advances in Diffusion
Transformer (DiT)-based text-to-image (T2I) models show promise in automating
these processes. However, these methods still face challenges such as
inconsistent fonts, style variation, and limited fine-grained control,
particularly at the word level. This paper proposes a two-stage DiT-based
pipeline to address these issues by enhancing controllability over typography
and style in text rendering. We introduce Typography Control (TC) finetuning,
an efficient parameter fine-tuning method, and enclosing typography control
tokens (ETC-tokens), which enable precise word-level application of typographic
features. To further enhance style control, we present a Style Control Adapter
(SCA) that injects style information through image inputs independent of text
prompts. Through comprehensive experiments, we demonstrate the effectiveness of
our approach in achieving superior word-level typographic control, font
consistency, and style consistency in Basic and Artistic Text Rendering (BTR
and ATR) tasks. Our results mark a significant advancement in the precision and
adaptability of T2I models, presenting new possibilities for creative
applications and design-oriented tasks.

摘要：視覺文字圖像在各種應用中很普遍，需要仔細選擇字體和排版選項。最近在基於擴散轉換器 (DiT) 的文字轉圖像 (T2I) 模型的進展顯示出自動化這些程序的潛力。然而，這些方法仍然面臨諸如字體不一致、樣式變化和有限的細粒度控制等挑戰，特別是在文字層級。本文提出了一個基於 DiT 的兩階段管道來解決這些問題，方法是增強對文字渲染中的排版和樣式的可控性。我們引入了排版控制 (TC) 微調，一種高效的參數微調方法，以及封裝排版控制代幣 (ETC 代幣)，它能精確地應用字體功能在文字層級。為了進一步增強樣式控制，我們提出了一個樣式控制適配器 (SCA)，它通過圖像輸入注入樣式資訊，而與文字提示無關。透過全面的實驗，我們證明了我們的方法在實現優異的文字層級排版控制、字體一致性和基本和藝術文字渲染 (BTR 和 ATR) 任務中的樣式一致性方面的有效性。我們的結果標誌著 T2I 模型的精確度和適應性的重大進展，為創意應用和設計導向任務提供了新的可能性。

##### **Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG**
2411.19230v1 by Xinxu Wei, Kanhao Zhao, Yong Jiao, Nancy B. Carlisle, Hua Xie, Yu Zhang

Effectively utilizing extensive unlabeled high-density EEG data to improve
performance in scenarios with limited labeled low-density EEG data presents a
significant challenge. In this paper, we address this by framing it as a graph
transfer learning and knowledge distillation problem. We propose a Unified
Pre-trained Graph Contrastive Masked Autoencoder Distiller, named EEG-DisGCMAE,
to bridge the gap between unlabeled/labeled and high/low-density EEG data. To
fully leverage the abundant unlabeled EEG data, we introduce a novel unified
graph self-supervised pre-training paradigm, which seamlessly integrates Graph
Contrastive Pre-training and Graph Masked Autoencoder Pre-training. This
approach synergistically combines contrastive and generative pre-training
techniques by reconstructing contrastive samples and contrasting the
reconstructions. For knowledge distillation from high-density to low-density
EEG data, we propose a Graph Topology Distillation loss function, allowing a
lightweight student model trained on low-density data to learn from a teacher
model trained on high-density data, effectively handling missing electrodes
through contrastive distillation. To integrate transfer learning and
distillation, we jointly pre-train the teacher and student models by
contrasting their queries and keys during pre-training, enabling robust
distillers for downstream tasks. We demonstrate the effectiveness of our method
on four classification tasks across two clinical EEG datasets with abundant
unlabeled data and limited labeled data. The experimental results show that our
approach significantly outperforms contemporary methods in both efficiency and
accuracy.

摘要：<paragraph>有效利用大量未標籤的高密度腦電圖資料，以改善標籤資料有限的低密度腦電圖資料情境中的效能，是一項重大的挑戰。在本文中，我們將其視為圖形傳輸學習與知識萃取問題來探討。我們提出一個統一的預訓練圖形對比遮罩自動編碼器萃取器，稱為 EEG-DisGCMAE，以彌合未標籤/標籤和高/低密度腦電圖資料之間的差距。為了充分利用大量的未標籤腦電圖資料，我們引入了一個新穎的統一圖形自我監督預訓練範例，它無縫整合了圖形對比預訓練和圖形遮罩自動編碼器預訓練。此方法透過重建對比樣本和對比重建結果，協同結合了對比和生成預訓練技術。對於從高密度到低密度腦電圖資料的知識萃取，我們提出了一個圖形拓撲萃取損失函數，允許在低密度資料上訓練的輕量級學生模型從在高密度資料上訓練的老師模型中學習，透過對比萃取有效處理遺失的電極。為了整合傳輸學習和萃取，我們透過在預訓練期間對比它們的查詢和金鑰，共同預訓練老師和學生模型，為下游任務啟用穩健的萃取器。我們在兩個臨床腦電圖資料集上展示了我們的方法在四個分類任務中的有效性，這些資料集具有大量的未標籤資料和有限的標籤資料。實驗結果表明，我們的做法在效率和準確性方面都顯著優於當代方法。</paragraph>

##### **Open-Sora Plan: Open-Source Large Video Generation Model**
2412.00131v1 by Bin Lin, Yunyang Ge, Xinhua Cheng, Zongjian Li, Bin Zhu, Shaodong Wang, Xianyi He, Yang Ye, Shenghai Yuan, Liuhan Chen, Tanghui Jia, Junwu Zhang, Zhenyu Tang, Yatian Pang, Bin She, Cen Yan, Zhiheng Hu, Xiaoyi Dong, Lin Chen, Zhang Pan, Xing Zhou, Shaoling Dong, Yonghong Tian, Li Yuan

We introduce Open-Sora Plan, an open-source project that aims to contribute a
large generation model for generating desired high-resolution videos with long
durations based on various user inputs. Our project comprises multiple
components for the entire video generation process, including a Wavelet-Flow
Variational Autoencoder, a Joint Image-Video Skiparse Denoiser, and various
condition controllers. Moreover, many assistant strategies for efficient
training and inference are designed, and a multi-dimensional data curation
pipeline is proposed for obtaining desired high-quality data. Benefiting from
efficient thoughts, our Open-Sora Plan achieves impressive video generation
results in both qualitative and quantitative evaluations. We hope our careful
design and practical experience can inspire the video generation research
community. All our codes and model weights are publicly available at
\url{https://github.com/PKU-YuanGroup/Open-Sora-Plan}.

摘要：我們推出 Open-Sora Plan，這是一個開放原始碼專案，旨在為根據各種使用者輸入來產生所需的高解析度影片提供一個大型生成模型，並具備長時間的持續時間。我們的專案包含了整個影片生成處理流程的多個組成部分，包括小波流變分自動編碼器、聯合影像影片 Skiparse 去雜訊器，以及各種條件控制器。此外，還設計了許多用於高效訓練與推論的輔助策略，並提出了一個多維資料策展管道，用於取得所需的高品質資料。受益於高效的想法，我們的 Open-Sora Plan 在定性和定量評估中都達到了令人印象深刻的影片生成結果。我們希望我們仔細的設計和實務經驗可以激勵影片生成研究社群。我們所有的程式碼和模型權重都公開在 \url{https://github.com/PKU-YuanGroup/Open-Sora-Plan}。

##### **CovidLLM: A Robust Large Language Model with Missing Value Adaptation and Multi-Objective Learning Strategy for Predicting Disease Severity and Clinical Outcomes in COVID-19 Patients**
2412.03593v1 by Shengjun Zhu, Siyu Liu, Yang Li, Qing Lei, Hongyan Hou, Hewei Jiang, Shujuan Guo, Feng Wang, Rongshang Chen, Xionglin Fan, Shengce Tao, Jiaxin Cai

Coronavirus Disease 2019 (COVID-19), which emerged in 2019, has caused
millions of deaths worldwide. Although effective vaccines have been developed
to mitigate severe symptoms, certain populations, particularly the elderly and
those with comorbidities, remain at high risk for severe outcomes and increased
mortality. Consequently, early identification of the severity and clinical
outcomes of the disease in these patients is vital to prevent adverse
prognoses. Although traditional machine learning and deep learning models have
been widely employed in this area, the potential of large language models
(LLMs) remains largely unexplored. Our research focuses primarily on
constructing specialized prompts and adopting multi-objective learning
strategies. We started by selecting serological indicators that significantly
correlate with clinical outcomes and disease severity to serve as input data
for the model. Blood test samples often contain numerous missing values, and
traditional models generally rely on imputation to handle these gaps in the
data. In contrast, LLMs offer the advantage of robust semantic understanding.
By setting prompts, we can explicitly inform the model when a feature's value
is missing, without the need for imputation. For the multi-objective learning
strategy, the model is designed to first predict disease severity and then
predict clinical outcomes. Given that LLMs utilize both the input text and the
generated tokens as input for generating the next token, the predicted severity
is used as a basis for generating the clinical outcome. During the fine-tuning
of the LLM, the two objectives influence and improve each other. Our
experiments were implemented based on the ChatGLM model. The results
demonstrate the effectiveness of LLMs in this task, suggesting promising
potential for further development.

摘要：2019 年出現的冠狀病毒疾病 (COVID-19) 已造成全球數百萬人死亡。儘管已研發出有效的疫苗來減輕嚴重症狀，但某些族群，尤其是老年人和有合併症者，仍然面臨嚴重的後果和死亡率增加的高風險。因此，及早辨識這些患者的疾病嚴重程度和臨床結果對於預防不良預後至關重要。儘管傳統機器學習和深度學習模型已廣泛用於此領域，但大型語言模型 (LLM) 的潛力仍未被充分探索。我們的研究主要專注於建構專業提示和採用多目標學習策略。我們首先選擇與臨床結果和疾病嚴重程度顯著相關的血清指標，作為模型的輸入資料。血液檢驗樣本通常包含許多缺失值，而傳統模型通常依賴插補來處理資料中的這些空白。相比之下，LLM 提供了強大的語義理解優勢。透過設定提示，我們可以明確告知模型何時缺少特徵值，而無需插補。對於多目標學習策略，模型被設計為先預測疾病嚴重程度，然後預測臨床結果。由於 LLM 將輸入文字和產生的符號同時作為輸入來產生下一個符號，因此預測的嚴重程度被用作產生臨床結果的基礎。在 LLM 的微調過程中，這兩個目標會相互影響和改善。我們的實驗是基於 ChatGLM 模型實作的。結果證明了 LLM 在此任務中的有效性，顯示出進一步發展的潛力。

##### **A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by Wearable Technologies and Artificial Intelligence**
2411.19000v1 by Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti

At-home rehabilitation for post-stroke patients presents significant
challenges, as continuous, personalized care is often limited outside clinical
settings. Additionally, the absence of comprehensive solutions addressing
diverse rehabilitation needs in home environments complicates recovery efforts.
Here, we introduce a smart home platform that integrates wearable sensors,
ambient monitoring, and large language model (LLM)-powered assistance to
provide seamless health monitoring and intelligent support. The system
leverages machine learning enabled plantar pressure arrays for motor recovery
assessment (94% classification accuracy), a wearable eye-tracking module for
cognitive evaluation, and ambient sensors for precise smart home control (100%
operational success, <1 s latency). Additionally, the LLM-powered agent,
Auto-Care, offers real-time interventions, such as health reminders and
environmental adjustments, enhancing user satisfaction by 29%. This work
establishes a fully integrated platform for long-term, personalized
rehabilitation, offering new possibilities for managing chronic conditions and
supporting aging populations.

摘要：居家復健對於中風患者來說是一大挑戰，因為持續且個人化的照護通常在臨床環境之外受到限制。此外，缺乏解決居家環境中多元復健需求的全面性解決方案，讓復原工作更形複雜。在此，我們介紹一個整合穿戴式感測器、環境監控和大型語言模型 (LLM) 驅動協助的智慧居家平台，提供無縫的健康監控和智慧支援。此系統利用機器學習啟用的足底壓力陣列進行運動復原評估 (94% 分類準確度)、穿戴式眼球追蹤模組進行認知評估，以及環境感測器進行精準的智慧居家控制 (100% 操作成功，<1 秒延遲)。此外，LLM 驅動的代理程式 Auto-Care 提供即時介入措施，例如健康提醒和環境調整，將使用者滿意度提升 29%。這項工作建立了一個長期、個人化的復健全整合平台，為管理慢性疾病和支持高齡人口提供了新的可能性。

