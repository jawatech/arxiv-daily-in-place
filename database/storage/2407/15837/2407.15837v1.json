{"2407.15837": {"publish_time": "2024-07-22", "title": "Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning", "paper_summary": "Masked Image Modeling (MIM) has emerged as a promising method for deriving\nvisual representations from unlabeled image data by predicting missing pixels\nfrom masked portions of images. It excels in region-aware learning and provides\nstrong initializations for various tasks, but struggles to capture high-level\nsemantics without further supervised fine-tuning, likely due to the low-level\nnature of its pixel reconstruction objective. A promising yet unrealized\nframework is learning representations through masked reconstruction in latent\nspace, combining the locality of MIM with the high-level targets. However, this\napproach poses significant training challenges as the reconstruction targets\nare learned in conjunction with the model, potentially leading to trivial or\nsuboptimal solutions.Our study is among the first to thoroughly analyze and\naddress the challenges of such framework, which we refer to as Latent MIM.\nThrough a series of carefully designed experiments and extensive analysis, we\nidentify the source of these challenges, including representation collapsing\nfor joint online/target optimization, learning objectives, the high region\ncorrelation in latent space and decoding conditioning. By sequentially\naddressing these issues, we demonstrate that Latent MIM can indeed learn\nhigh-level representations while retaining the benefits of MIM models.", "paper_summary_zh": "\u906e\u853d\u5f71\u50cf\u5efa\u6a21 (MIM) \u5df2\u6210\u70ba\u4e00\u7a2e\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u65bc\u900f\u904e\u9810\u6e2c\u5f71\u50cf\u906e\u853d\u90e8\u5206\u7684\u907a\u5931\u50cf\u7d20\uff0c\u5f9e\u672a\u6a19\u8a18\u7684\u5f71\u50cf\u8cc7\u6599\u4e2d\u884d\u751f\u8996\u89ba\u8868\u793a\u3002\u5b83\u5728\u5340\u57df\u611f\u77e5\u5b78\u7fd2\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u4e26\u70ba\u5404\u7a2e\u4efb\u52d9\u63d0\u4f9b\u5f37\u5927\u7684\u521d\u59cb\u8a2d\u5b9a\uff0c\u4f46\u537b\u96e3\u4ee5\u5728\u6c92\u6709\u9032\u4e00\u6b65\u76e3\u7763\u5fae\u8abf\u7684\u60c5\u6cc1\u4e0b\u6355\u6349\u5230\u9ad8\u5c64\u6b21\u8a9e\u610f\uff0c\u9019\u53ef\u80fd\u662f\u7531\u65bc\u5176\u50cf\u7d20\u91cd\u5efa\u76ee\u6a19\u7684\u4f4e\u5c64\u6b21\u672c\u8cea\u6240\u81f4\u3002\u4e00\u500b\u6709\u524d\u9014\u4f46\u5c1a\u672a\u5be6\u73fe\u7684\u67b6\u69cb\u662f\u900f\u904e\u6f5b\u5728\u7a7a\u9593\u4e2d\u7684\u906e\u853d\u91cd\u5efa\u4f86\u5b78\u7fd2\u8868\u793a\uff0c\u7d50\u5408 MIM \u7684\u5c40\u90e8\u6027\u8207\u9ad8\u5c64\u6b21\u76ee\u6a19\u3002\u7136\u800c\uff0c\u9019\u7a2e\u65b9\u6cd5\u6703\u5e36\u4f86\u91cd\u5927\u7684\u8a13\u7df4\u6311\u6230\uff0c\u56e0\u70ba\u91cd\u5efa\u76ee\u6a19\u662f\u8207\u6a21\u578b\u7d50\u5408\u5b78\u7fd2\u7684\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u5fae\u4e0d\u8db3\u9053\u6216\u6b21\u4f73\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u6211\u5011\u7684\u7814\u7a76\u662f\u7b2c\u4e00\u6279\u5fb9\u5e95\u5206\u6790\u548c\u89e3\u6c7a\u6b64\u985e\u67b6\u69cb\u6311\u6230\u7684\u7814\u7a76\u4e4b\u4e00\uff0c\u6211\u5011\u7a31\u4e4b\u70ba\u6f5b\u5728 MIM\u3002\u900f\u904e\u4e00\u7cfb\u5217\u7cbe\u5fc3\u8a2d\u8a08\u7684\u5be6\u9a57\u548c\u5ee3\u6cdb\u7684\u5206\u6790\uff0c\u6211\u5011\u627e\u51fa\u9019\u4e9b\u6311\u6230\u7684\u6839\u6e90\uff0c\u5305\u62ec\u806f\u5408\u7dda\u4e0a/\u76ee\u6a19\u6700\u4f73\u5316\u3001\u5b78\u7fd2\u76ee\u6a19\u3001\u6f5b\u5728\u7a7a\u9593\u4e2d\u7684\u9ad8\u5340\u57df\u76f8\u95dc\u6027\u548c\u89e3\u78bc\u689d\u4ef6\u7684\u8868\u793a\u5d29\u6f70\u3002\u900f\u904e\u5faa\u5e8f\u6f38\u9032\u5730\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u8b49\u660e\u6f5b\u5728 MIM \u78ba\u5be6\u53ef\u4ee5\u5728\u4fdd\u7559 MIM \u6a21\u578b\u512a\u9ede\u7684\u540c\u6642\u5b78\u7fd2\u9ad8\u5c64\u6b21\u8868\u793a\u3002", "author": "Yibing Wei et.al.", "authors": "Yibing Wei, Abhinav Gupta, Pedro Morgado", "id": "2407.15837v1", "paper_url": "http://arxiv.org/abs/2407.15837v1", "repo": "https://github.com/yibingwei-1/latentmim"}}