{"2407.16667": {"publish_time": "2024-07-23", "title": "RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent", "paper_summary": "Recently, advanced Large Language Models (LLMs) such as GPT-4 have been\nintegrated into many real-world applications like Code Copilot. These\napplications have significantly expanded the attack surface of LLMs, exposing\nthem to a variety of threats. Among them, jailbreak attacks that induce toxic\nresponses through jailbreak prompts have raised critical safety concerns. To\nidentify these threats, a growing number of red teaming approaches simulate\npotential adversarial scenarios by crafting jailbreak prompts to test the\ntarget LLM. However, existing red teaming methods do not consider the unique\nvulnerabilities of LLM in different scenarios, making it difficult to adjust\nthe jailbreak prompts to find context-specific vulnerabilities. Meanwhile,\nthese methods are limited to refining jailbreak templates using a few mutation\noperations, lacking the automation and scalability to adapt to different\nscenarios. To enable context-aware and efficient red teaming, we abstract and\nmodel existing attacks into a coherent concept called \"jailbreak strategy\" and\npropose a multi-agent LLM system named RedAgent that leverages these strategies\nto generate context-aware jailbreak prompts. By self-reflecting on contextual\nfeedback in an additional memory buffer, RedAgent continuously learns how to\nleverage these strategies to achieve effective jailbreaks in specific contexts.\nExtensive experiments demonstrate that our system can jailbreak most black-box\nLLMs in just five queries, improving the efficiency of existing red teaming\nmethods by two times. Additionally, RedAgent can jailbreak customized LLM\napplications more efficiently. By generating context-aware jailbreak prompts\ntowards applications on GPTs, we discover 60 severe vulnerabilities of these\nreal-world applications with only two queries per vulnerability. We have\nreported all found issues and communicated with OpenAI and Meta for bug fixes.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u4f8b\u5982 GPT-4\uff0c\u5df2\u6574\u5408\u5230\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u4f8b\u5982 Code Copilot\u3002\u8fd9\u4e9b\u5e94\u7528\u663e\u8457\u6269\u5927\u4e86 LLM \u7684\u653b\u51fb\u9762\uff0c\u4f7f\u5b83\u4eec\u9762\u4e34\u5404\u79cd\u5a01\u80c1\u3002\u5176\u4e2d\uff0c\u901a\u8fc7\u8d8a\u72f1\u63d0\u793a\u8bf1\u53d1\u6709\u5bb3\u53cd\u5e94\u7684\u8d8a\u72f1\u653b\u51fb\u5f15\u53d1\u4e86\u5173\u952e\u7684\u5b89\u5168\u95ee\u9898\u3002\u4e3a\u4e86\u8bc6\u522b\u8fd9\u4e9b\u5a01\u80c1\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u7ea2\u961f\u65b9\u6cd5\u901a\u8fc7\u7cbe\u5fc3\u5236\u4f5c\u8d8a\u72f1\u63d0\u793a\u6765\u6a21\u62df\u6f5c\u5728\u7684\u5bf9\u6297\u573a\u666f\uff0c\u4ee5\u6d4b\u8bd5\u76ee\u6807 LLM\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u7ea2\u961f\u65b9\u6cd5\u5e76\u672a\u8003\u8651 LLM \u5728\u4e0d\u540c\u573a\u666f\u4e2d\u7684\u72ec\u7279\u6f0f\u6d1e\uff0c\u8fd9\u4f7f\u5f97\u96be\u4ee5\u8c03\u6574\u8d8a\u72f1\u63d0\u793a\u6765\u67e5\u627e\u7279\u5b9a\u4e8e\u4e0a\u4e0b\u6587\u7684\u6f0f\u6d1e\u3002\u540c\u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4ec5\u9650\u4e8e\u4f7f\u7528\u5c11\u6570\u53d8\u5f02\u64cd\u4f5c\u6765\u4f18\u5316\u8d8a\u72f1\u6a21\u677f\uff0c\u7f3a\u4e4f\u9002\u5e94\u4e0d\u540c\u573a\u666f\u7684\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002\u4e3a\u4e86\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u9ad8\u6548\u7684\u7ea2\u961f\uff0c\u6211\u4eec\u5c06\u73b0\u6709\u7684\u653b\u51fb\u62bd\u8c61\u5e76\u5efa\u6a21\u4e3a\u4e00\u4e2a\u8fde\u8d2f\u7684\u6982\u5ff5\uff0c\u79f0\u4e3a\u201c\u8d8a\u72f1\u7b56\u7565\u201d\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3a RedAgent \u7684\u591a\u4ee3\u7406 LLM \u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u8fd9\u4e9b\u7b56\u7565\u6765\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8d8a\u72f1\u63d0\u793a\u3002\u901a\u8fc7\u5728\u9644\u52a0\u7684\u5185\u5b58\u7f13\u51b2\u533a\u4e2d\u81ea\u7701\u4e0a\u4e0b\u6587\u53cd\u9988\uff0cRedAgent \u6301\u7eed\u5b66\u4e60\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u7b56\u7565\u5728\u7279\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u8d8a\u72f1\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u4ec5\u5728\u4e94\u6b21\u67e5\u8be2\u4e2d\u5c31\u80fd\u8d8a\u72f1\u5927\u591a\u6570\u9ed1\u76d2 LLM\uff0c\u4ece\u800c\u5c06\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\u7684\u6548\u7387\u63d0\u9ad8\u4e86\u4e24\u500d\u3002\u6b64\u5916\uff0cRedAgent \u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8d8a\u72f1\u5b9a\u5236\u7684 LLM \u5e94\u7528\u7a0b\u5e8f\u3002\u901a\u8fc7\u9488\u5bf9 GPT \u4e0a\u7684\u5e94\u7528\u7a0b\u5e8f\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8d8a\u72f1\u63d0\u793a\uff0c\u6211\u4eec\u4ec5\u901a\u8fc7\u6bcf\u4e2a\u6f0f\u6d1e\u4e24\u6b21\u67e5\u8be2\u5c31\u53d1\u73b0\u4e86\u8fd9\u4e9b\u5b9e\u9645\u5e94\u7528\u7a0b\u5e8f\u7684 60 \u4e2a\u4e25\u91cd\u6f0f\u6d1e\u3002\u6211\u4eec\u5df2\u62a5\u544a\u6240\u6709\u53d1\u73b0\u7684\u95ee\u9898\uff0c\u5e76\u4e0e OpenAI \u548c Meta \u6c9f\u901a\u4ee5\u4fee\u590d\u9519\u8bef\u3002</paragraph>", "author": "Huiyu Xu et.al.", "authors": "Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren", "id": "2407.16667v1", "paper_url": "http://arxiv.org/abs/2407.16667v1", "repo": "null"}}