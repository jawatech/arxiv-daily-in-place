{"2408.04392": {"publish_time": "2024-08-08", "title": "Open-domain Implicit Format Control for Large Language Model Generation", "paper_summary": "Controlling the format of outputs generated by large language models (LLMs)\nis a critical functionality in various applications. Current methods typically\nemploy constrained decoding with rule-based automata or fine-tuning with\nmanually crafted format instructions, both of which struggle with open-domain\nformat requirements. To address this limitation, we introduce a novel framework\nfor controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.\nThis study investigates LLMs' capabilities to follow open-domain, one-shot\nconstraints and replicate the format of the example answers. We observe that\nthis is a non-trivial problem for current LLMs. We also develop a dataset\ncollection methodology for supervised fine-tuning that enhances the open-domain\nformat control of LLMs without degrading output quality, as well as a benchmark\non which we evaluate both the helpfulness and format correctness of LLM\noutputs. The resulting datasets, named OIFC-SFT, along with the related code,\nwill be made publicly available at https://github.com/cofe-ai/OIFC.", "paper_summary_zh": "\u63a7\u5236\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u751f\u6210\u7684\u8f38\u51fa\u683c\u5f0f\u5728\u5404\u7a2e\u61c9\u7528\u4e2d\u662f\u4e00\u9805\u95dc\u9375\u529f\u80fd\u3002\u76ee\u524d\u7684\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u57fa\u65bc\u898f\u5247\u7684\u81ea\u52d5\u6a5f\u9032\u884c\u7d04\u675f\u89e3\u78bc\u6216\u4f7f\u7528\u4eba\u5de5\u88fd\u4f5c\u7684\u683c\u5f0f\u6307\u4ee4\u9032\u884c\u5fae\u8abf\uff0c\u9019\u5169\u7a2e\u65b9\u6cd5\u90fd\u96e3\u4ee5\u6eff\u8db3\u958b\u653e\u9818\u57df\u7684\u683c\u5f0f\u8981\u6c42\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u6846\u67b6\uff0c\u7528\u65bc\u5728 LLM \u4e2d\u9032\u884c\u53d7\u63a7\u751f\u6210\uff0c\u5229\u7528\u7528\u6236\u63d0\u4f9b\u7684\u55ae\u6b21\u554f\u7b54\u5c0d\u3002\u9019\u9805\u7814\u7a76\u8abf\u67e5\u4e86 LLM \u9075\u5faa\u958b\u653e\u9818\u57df\u3001\u55ae\u6b21\u7d04\u675f\u548c\u8907\u88fd\u7bc4\u4f8b\u7b54\u6848\u683c\u5f0f\u7684\u80fd\u529b\u3002\u6211\u5011\u89c0\u5bdf\u5230\u9019\u5c0d\u65bc\u76ee\u524d\u7684 LLM \u4f86\u8aaa\u662f\u4e00\u500b\u4e0d\u5e73\u51e1\u7684\u554f\u984c\u3002\u6211\u5011\u9084\u958b\u767c\u4e86\u4e00\u7a2e\u7528\u65bc\u76e3\u7763\u5fae\u8abf\u7684\u6578\u64da\u96c6\u6536\u96c6\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u589e\u5f37\u4e86 LLM \u7684\u958b\u653e\u9818\u57df\u683c\u5f0f\u63a7\u5236\uff0c\u800c\u4e0d\u6703\u964d\u4f4e\u8f38\u51fa\u8cea\u91cf\uff0c\u4e26\u5efa\u7acb\u4e86\u4e00\u500b\u57fa\u6e96\uff0c\u6211\u5011\u6839\u64da\u6b64\u57fa\u6e96\u8a55\u4f30 LLM \u8f38\u51fa\u7684\u6709\u7528\u6027\u548c\u683c\u5f0f\u6b63\u78ba\u6027\u3002\u751f\u6210\u7684\u6578\u64da\u96c6\u540d\u70ba OIFC-SFT\uff0c\u9023\u540c\u76f8\u95dc\u4ee3\u78bc\uff0c\u5c07\u5728 https://github.com/cofe-ai/OIFC \u4e0a\u516c\u958b\u3002", "author": "Yiqun Yao et.al.", "authors": "Yiqun Yao, Wenjia Ma, Xuezhi Fang, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang", "id": "2408.04392v1", "paper_url": "http://arxiv.org/abs/2408.04392v1", "repo": "null"}}