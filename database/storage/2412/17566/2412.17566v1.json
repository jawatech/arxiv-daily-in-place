{"2412.17566": {"publish_time": "2024-12-23", "title": "The Dynamic Duo of Collaborative Masking and Target for Advanced Masked Autoencoder Learning", "paper_summary": "Masked autoencoders (MAE) have recently succeeded in self-supervised vision\nrepresentation learning. Previous work mainly applied custom-designed (e.g.,\nrandom, block-wise) masking or teacher (e.g., CLIP)-guided masking and targets.\nHowever, they ignore the potential role of the self-training (student) model in\ngiving feedback to the teacher for masking and targets. In this work, we\npresent to integrate Collaborative Masking and Targets for boosting Masked\nAutoEncoders, namely CMT-MAE. Specifically, CMT-MAE leverages a simple\ncollaborative masking mechanism through linear aggregation across attentions\nfrom both teacher and student models. We further propose using the output\nfeatures from those two models as the collaborative target of the decoder. Our\nsimple and effective framework pre-trained on ImageNet-1K achieves\nstate-of-the-art linear probing and fine-tuning performance. In particular,\nusing ViT-base, we improve the fine-tuning results of the vanilla MAE from\n83.6% to 85.7%.", "paper_summary_zh": "\u906e\u7f69\u5f0f\u81ea\u52a8\u7f16\u7801\u5668 (MAE) \u6700\u8fd1\u5728\u81ea\u76d1\u7763\u89c6\u89c9\u8868\u793a\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\u3002\u5148\u524d\u7684\u5de5\u4f5c\u4e3b\u8981\u5e94\u7528\u81ea\u5b9a\u4e49\u8bbe\u8ba1\uff08\u4f8b\u5982\uff0c\u968f\u673a\u3001\u533a\u5757\u5f0f\uff09\u906e\u7f69\u6216\u6559\u5e08\uff08\u4f8b\u5982\uff0cCLIP\uff09\u6307\u5bfc\u7684\u906e\u7f69\u548c\u76ee\u6807\u3002\u7136\u800c\uff0c\u4ed6\u4eec\u5ffd\u7565\u4e86\u81ea\u8bad\u7ec3\uff08\u5b66\u751f\uff09\u6a21\u578b\u5728\u5411\u6559\u5e08\u63d0\u4f9b\u906e\u7f69\u548c\u76ee\u6807\u53cd\u9988\u65b9\u9762\u7684\u6f5c\u5728\u4f5c\u7528\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u96c6\u6210\u534f\u4f5c\u906e\u7f69\u548c\u76ee\u6807\u4ee5\u63d0\u5347\u906e\u7f69\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5373 CMT-MAE\u3002\u5177\u4f53\u6765\u8bf4\uff0cCMT-MAE \u901a\u8fc7\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u7684\u6ce8\u610f\u529b\u8de8\u7ebf\u6027\u805a\u5408\u5229\u7528\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u534f\u4f5c\u906e\u7f69\u673a\u5236\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4f7f\u7528\u8fd9\u4e24\u4e2a\u6a21\u578b\u7684\u8f93\u51fa\u7279\u5f81\u4f5c\u4e3a\u89e3\u7801\u5668\u7684\u534f\u4f5c\u76ee\u6807\u3002\u6211\u4eec\u7b80\u5355\u800c\u6709\u6548\u7684\u6846\u67b6\u5728 ImageNet-1K \u4e0a\u7ecf\u8fc7\u9884\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ebf\u6027\u63a2\u6d4b\u548c\u5fae\u8c03\u6027\u80fd\u3002\u7279\u522b\u662f\uff0c\u4f7f\u7528 ViT-base\uff0c\u6211\u4eec\u5c06\u539f\u59cb MAE \u7684\u5fae\u8c03\u7ed3\u679c\u4ece 83.6% \u63d0\u9ad8\u5230 85.7%\u3002", "author": "Shentong Mo et.al.", "authors": "Shentong Mo", "id": "2412.17566v1", "paper_url": "http://arxiv.org/abs/2412.17566v1", "repo": "null"}}