{"2412.08615": {"publish_time": "2024-12-11", "title": "Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models", "paper_summary": "Despite the advancements in training Large Language Models (LLMs) with\nalignment techniques to enhance the safety of generated content, these models\nremain susceptible to jailbreak, an adversarial attack method that exposes\nsecurity vulnerabilities in LLMs. Notably, the Greedy Coordinate Gradient (GCG)\nmethod has demonstrated the ability to automatically generate adversarial\nsuffixes that jailbreak state-of-the-art LLMs. However, the optimization\nprocess involved in GCG is highly time-consuming, rendering the jailbreaking\npipeline inefficient. In this paper, we investigate the process of GCG and\nidentify an issue of Indirect Effect, the key bottleneck of the GCG\noptimization. To this end, we propose the Model Attack Gradient Index GCG\n(MAGIC), that addresses the Indirect Effect by exploiting the gradient\ninformation of the suffix tokens, thereby accelerating the procedure by having\nless computation and fewer iterations. Our experiments on AdvBench show that\nMAGIC achieves up to a 1.5x speedup, while maintaining Attack Success Rates\n(ASR) on par or even higher than other baselines. Our MAGIC achieved an ASR of\n74% on the Llama-2 and an ASR of 54% when conducting transfer attacks on\nGPT-3.5. Code is available at https://github.com/jiah-li/magic.", "paper_summary_zh": "\u5118\u7ba1\u5728\u4f7f\u7528\u8abf\u6574\u6280\u8853\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee5\u589e\u5f37\u6240\u7522\u751f\u5167\u5bb9\u7684\u5b89\u5168\u6027\u7684\u904e\u7a0b\u4e2d\u53d6\u5f97\u9032\u5c55\uff0c\u4f46\u9019\u4e9b\u6a21\u578b\u4ecd\u5bb9\u6613\u53d7\u5230\u8d8a\u7344\u653b\u64ca\uff0c\u9019\u662f\u4e00\u7a2e\u6703\u66b4\u9732 LLM \u4e2d\u5b89\u5168\u6f0f\u6d1e\u7684\u5c0d\u6297\u653b\u64ca\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8caa\u5a6a\u5750\u6a19\u68af\u5ea6 (GCG) \u65b9\u6cd5\u5df2\u8b49\u660e\u6709\u80fd\u529b\u81ea\u52d5\u7522\u751f\u5c0d\u6297\u5f8c\u7db4\uff0c\u4ee5\u8d8a\u7344\u6700\u5148\u9032\u7684 LLM\u3002\u7136\u800c\uff0cGCG \u4e2d\u6d89\u53ca\u7684\u6700\u4f73\u5316\u904e\u7a0b\u975e\u5e38\u8017\u6642\uff0c\u5c0e\u81f4\u8d8a\u7344\u7ba1\u9053\u6548\u7387\u4f4e\u4e0b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86 GCG \u7684\u904e\u7a0b\uff0c\u4e26\u627e\u51fa\u9593\u63a5\u6548\u61c9\u7684\u554f\u984c\uff0c\u9019\u662f GCG \u6700\u4f73\u5316\u7684\u95dc\u9375\u74f6\u9838\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u6a21\u578b\u653b\u64ca\u68af\u5ea6\u6307\u6a19 GCG (MAGIC)\uff0c\u5b83\u900f\u904e\u5229\u7528\u5f8c\u7db4\u6a19\u8a18\u7684\u68af\u5ea6\u8cc7\u8a0a\u4f86\u89e3\u6c7a\u9593\u63a5\u6548\u61c9\uff0c\u5f9e\u800c\u900f\u904e\u6e1b\u5c11\u904b\u7b97\u548c\u53cd\u8986\u904b\u7b97\u4f86\u52a0\u901f\u7a0b\u5e8f\u3002\u6211\u5011\u5728 AdvBench \u4e0a\u7684\u5be6\u9a57\u986f\u793a\uff0cMAGIC \u53ef\u5c07\u901f\u5ea6\u63d0\u5347\u81f3 1.5 \u500d\uff0c\u540c\u6642\u7dad\u6301\u653b\u64ca\u6210\u529f\u7387 (ASR) \u8207\u5176\u4ed6\u57fa\u7dda\u76f8\u7576\uff0c\u751a\u81f3\u66f4\u9ad8\u3002\u6211\u5011\u7684 MAGIC \u5728 Llama-2 \u4e0a\u9054\u5230\u4e86 74% \u7684 ASR\uff0c\u5728\u5c0d GPT-3.5 \u9032\u884c\u8f49\u79fb\u653b\u64ca\u6642\u9054\u5230\u4e86 54% \u7684 ASR\u3002\u7a0b\u5f0f\u78bc\u53ef\u65bc https://github.com/jiah-li/magic \u53d6\u5f97\u3002", "author": "Jiahui Li et.al.", "authors": "Jiahui Li, Yongchang Hao, Haoyu Xu, Xing Wang, Yu Hong", "id": "2412.08615v1", "paper_url": "http://arxiv.org/abs/2412.08615v1", "repo": "null"}}