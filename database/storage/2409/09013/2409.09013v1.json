{"2409.09013": {"publish_time": "2024-09-13", "title": "AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents", "paper_summary": "To be safely and successfully deployed, LLMs must simultaneously satisfy\ntruthfulness and utility goals. Yet, often these two goals compete (e.g., an AI\nagent assisting a used car salesman selling a car with flaws), partly due to\nambiguous or misleading user instructions. We propose AI-LieDar, a framework to\nstudy how LLM-based agents navigate scenarios with utility-truthfulness\nconflicts in a multi-turn interactive setting. We design a set of realistic\nscenarios where language agents are instructed to achieve goals that are in\nconflict with being truthful during a multi-turn conversation with simulated\nhuman agents. To evaluate the truthfulness at large scale, we develop a\ntruthfulness detector inspired by psychological literature to assess the\nagents' responses. Our experiment demonstrates that all models are truthful\nless than 50% of the time, although truthfulness and goal achievement (utility)\nrates vary across models. We further test the steerability of LLMs towards\ntruthfulness, finding that models follow malicious instructions to deceive, and\neven truth-steered models can still lie. These findings reveal the complex\nnature of truthfulness in LLMs and underscore the importance of further\nresearch to ensure the safe and reliable deployment of LLMs and AI agents.", "paper_summary_zh": "\u70ba\u4e86\u5b89\u5168\u4e14\u6210\u529f\u5730\u90e8\u7f72 LLM\uff0c\u5fc5\u9808\u540c\u6642\u6eff\u8db3\u771f\u5be6\u6027\u548c\u5be6\u7528\u6027\u76ee\u6a19\u3002\u7136\u800c\uff0c\u9019\u5169\u500b\u76ee\u6a19\u901a\u5e38\u6703\u76f8\u4e92\u7af6\u722d\uff08\u4f8b\u5982\uff0cAI \u4ee3\u7406\u5354\u52a9\u4e8c\u624b\u8eca\u92b7\u552e\u54e1\u92b7\u552e\u6709\u7f3a\u9677\u7684\u6c7d\u8eca\uff09\uff0c\u90e8\u5206\u539f\u56e0\u662f\u4f7f\u7528\u8005\u8aaa\u660e\u6a21\u7a1c\u5169\u53ef\u6216\u5177\u6709\u8aa4\u5c0e\u6027\u3002\u6211\u5011\u63d0\u51fa AI-LieDar\uff0c\u4e00\u500b\u67b6\u69cb\u7528\u65bc\u7814\u7a76\u57fa\u65bc LLM \u7684\u4ee3\u7406\u5982\u4f55\u61c9\u5c0d\u591a\u8f2a\u4e92\u52d5\u8a2d\u5b9a\u4e2d\u5be6\u7528\u6027\u771f\u5be6\u6027\u885d\u7a81\u7684\u5834\u666f\u3002\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u7d44\u903c\u771f\u7684\u5834\u666f\uff0c\u5176\u4e2d\u8a9e\u8a00\u4ee3\u7406\u88ab\u6307\u793a\u5728\u8207\u6a21\u64ec\u4eba\u985e\u4ee3\u7406\u7684\u591a\u8f2a\u5c0d\u8a71\u4e2d\u5be6\u73fe\u8207\u771f\u5be6\u6027\u76f8\u885d\u7a81\u7684\u76ee\u6a19\u3002\u70ba\u4e86\u5927\u898f\u6a21\u8a55\u4f30\u771f\u5be6\u6027\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u53d7\u5fc3\u7406\u5b78\u6587\u737b\u555f\u767c\u7684\u771f\u5be6\u6027\u5075\u6e2c\u5668\uff0c\u7528\u65bc\u8a55\u4f30\u4ee3\u7406\u7684\u53cd\u61c9\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6240\u6709\u6a21\u578b\u7684\u771f\u5be6\u6027\u4f4e\u65bc 50%\uff0c\u5118\u7ba1\u771f\u5be6\u6027\u548c\u76ee\u6a19\u9054\u6210\uff08\u5be6\u7528\u6027\uff09\u7387\u56e0\u6a21\u578b\u800c\u7570\u3002\u6211\u5011\u9032\u4e00\u6b65\u6e2c\u8a66\u4e86 LLM \u5c0d\u771f\u5be6\u6027\u7684\u53ef\u63a7\u6027\uff0c\u767c\u73fe\u6a21\u578b\u9075\u5faa\u60e1\u610f\u6307\u4ee4\u9032\u884c\u6b3a\u9a19\uff0c\u5373\u4f7f\u662f\u771f\u5be6\u6027\u5c0e\u5411\u7684\u6a21\u578b\u4ecd\u7136\u53ef\u80fd\u8aaa\u8b0a\u3002\u9019\u4e9b\u767c\u73fe\u63ed\u793a\u4e86 LLM \u4e2d\u771f\u5be6\u6027\u7684\u8907\u96dc\u672c\u8cea\uff0c\u4e26\u5f37\u8abf\u4e86\u9032\u4e00\u6b65\u7814\u7a76\u4ee5\u78ba\u4fdd LLM \u548c AI \u4ee3\u7406\u5b89\u5168\u53ef\u9760\u90e8\u7f72\u7684\u91cd\u8981\u6027\u3002", "author": "Zhe Su et.al.", "authors": "Zhe Su, Xuhui Zhou, Sanketh Rangreji, Anubha Kabra, Julia Mendelsohn, Faeze Brahman, Maarten Sap", "id": "2409.09013v1", "paper_url": "http://arxiv.org/abs/2409.09013v1", "repo": "null"}}