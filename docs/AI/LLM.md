
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-25**|**EXTRACT: Efficient Policy Learning by Extracting Transferrable Robot Skills from Offline Data**|Jesse Zhang et.al.|[2406.17768v1](http://arxiv.org/abs/2406.17768v1)|null|
|**2024-06-25**|**BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning**|Ercong Nie et.al.|[2406.17764v1](http://arxiv.org/abs/2406.17764v1)|null|
|**2024-06-25**|**DiffusionPDE: Generative PDE-Solving Under Partial Observation**|Jiahe Huang et.al.|[2406.17763v1](http://arxiv.org/abs/2406.17763v1)|null|
|**2024-06-25**|**CaLMQA: Exploring culturally specific long-form question answering across 23 languages**|Shane Arora et.al.|[2406.17761v1](http://arxiv.org/abs/2406.17761v1)|[link](https://github.com/2015aroras/calmqa)|
|**2024-06-25**|**Accelerating Clinical Evidence Synthesis with Large Language Models**|Zifeng Wang et.al.|[2406.17755v1](http://arxiv.org/abs/2406.17755v1)|null|
|**2024-06-25**|**Measuring and Benchmarking Large Language Models' Capabilities to Generate Persuasive Language**|Amalie Brogaard Pauli et.al.|[2406.17753v1](http://arxiv.org/abs/2406.17753v1)|null|
|**2024-06-25**|**Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon**|USVSN Sai Prashanth et.al.|[2406.17746v1](http://arxiv.org/abs/2406.17746v1)|null|
|**2024-06-25**|**Following Length Constraints in Instructions**|Weizhe Yuan et.al.|[2406.17744v1](http://arxiv.org/abs/2406.17744v1)|null|
|**2024-06-25**|**Point-SAM: Promptable 3D Segmentation Model for Point Clouds**|Yuchen Zhou et.al.|[2406.17741v1](http://arxiv.org/abs/2406.17741v1)|[link](https://github.com/zyc00/point-sam)|
|**2024-06-25**|**Structured Unrestricted-Rank Matrices for Parameter Efficient Fine-tuning**|Arijit Sehanobish et.al.|[2406.17740v1](http://arxiv.org/abs/2406.17740v1)|null|
|**2024-06-25**|**Find Parent then Label Children: A Two-stage Taxonomy Completion Method with Pre-trained Language Model**|Fei Xia et.al.|[2406.17739v1](http://arxiv.org/abs/2406.17739v1)|null|
|**2024-06-25**|**LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users**|Elinor Poole-Dayan et.al.|[2406.17737v1](http://arxiv.org/abs/2406.17737v1)|null|
|**2024-06-25**|**ViANLI: Adversarial Natural Language Inference for Vietnamese**|Tin Van Huynh et.al.|[2406.17716v1](http://arxiv.org/abs/2406.17716v1)|null|
|**2024-06-25**|**Compositional Models for Estimating Causal Effects**|Purva Pruthi et.al.|[2406.17714v1](http://arxiv.org/abs/2406.17714v1)|null|
|**2024-06-25**|**Data curation via joint example selection further accelerates multimodal learning**|Talfan Evans et.al.|[2406.17711v1](http://arxiv.org/abs/2406.17711v1)|null|
|**2024-06-25**|**FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model**|Feijie Wu et.al.|[2406.17706v1](http://arxiv.org/abs/2406.17706v1)|null|
|**2024-06-25**|**HGTDP-DTA: Hybrid Graph-Transformer with Dynamic Prompt for Drug-Target Binding Affinity Prediction**|Xi Xiao et.al.|[2406.17697v1](http://arxiv.org/abs/2406.17697v1)|null|
|**2024-06-25**|**From Distributional to Overton Pluralism: Investigating Large Language Model Alignment**|Thom Lake et.al.|[2406.17692v1](http://arxiv.org/abs/2406.17692v1)|[link](https://github.com/thomlake/investigating-alignment)|
|**2024-06-25**|**Unified Auto-Encoding with Masked Diffusion**|Philippe Hansen-Estruch et.al.|[2406.17688v1](http://arxiv.org/abs/2406.17688v1)|null|
|**2024-06-25**|**VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation**|Kun Qian et.al.|[2406.17681v2](http://arxiv.org/abs/2406.17681v2)|[link](https://github.com/qbetterk/VarBench)|
|**2024-06-25**|**Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models**|Yuan Li et.al.|[2406.17675v1](http://arxiv.org/abs/2406.17675v1)|null|
|**2024-06-25**|**This Paper Had the Smartest Reviewers -- Flattery Detection Utilising an Audio-Textual Transformer-Based Approach**|Lukas Christ et.al.|[2406.17667v1](http://arxiv.org/abs/2406.17667v1)|null|
|**2024-06-25**|**LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic**|Aditya Kalyanpur et.al.|[2406.17663v1](http://arxiv.org/abs/2406.17663v1)|null|
|**2024-06-25**|**DKPROMPT: Domain Knowledge Prompting Vision-Language Models for Open-World Planning**|Xiaohan Zhang et.al.|[2406.17659v1](http://arxiv.org/abs/2406.17659v1)|null|
|**2024-06-25**|**MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for Multi-View 3D Object Detection**|Michelle Adeline et.al.|[2406.17654v1](http://arxiv.org/abs/2406.17654v1)|null|
|**2024-06-25**|**Leveraging Large Language Models for Software Model Completion: Results from Industrial and Public Datasets**|Christof Tinnes et.al.|[2406.17651v1](http://arxiv.org/abs/2406.17651v1)|null|
|**2024-06-25**|**ELIZA Reinterpreted: The world's first chatbot was not intended as a chatbot at all**|Jeff Shrager et.al.|[2406.17650v1](http://arxiv.org/abs/2406.17650v1)|null|
|**2024-06-25**|**Variationist: Exploring Multifaceted Variation and Bias in Written Language Data**|Alan Ramponi et.al.|[2406.17647v1](http://arxiv.org/abs/2406.17647v1)|null|
|**2024-06-25**|**Banishing LLM Hallucinations Requires Rethinking Generalization**|Johnny Li et.al.|[2406.17642v1](http://arxiv.org/abs/2406.17642v1)|null|
|**2024-06-25**|**BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging**|Zeinab Sherkatghanad et.al.|[2406.17640v1](http://arxiv.org/abs/2406.17640v1)|null|
|**2024-06-25**|**Mitigate the Gap: Investigating Approaches for Improving Cross-Modal Alignment in CLIP**|Sedigheh Eslami et.al.|[2406.17639v2](http://arxiv.org/abs/2406.17639v2)|null|
|**2024-06-25**|**Aligning Diffusion Models with Noise-Conditioned Perception**|Alexander Gambashidze et.al.|[2406.17636v1](http://arxiv.org/abs/2406.17636v1)|null|
|**2024-06-25**|**Knowledge Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated Training Labels**|Nicholas Pangakis et.al.|[2406.17633v1](http://arxiv.org/abs/2406.17633v1)|null|
|**2024-06-25**|**CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference**|Erxin Yu et.al.|[2406.17626v1](http://arxiv.org/abs/2406.17626v1)|null|
|**2024-06-25**|**Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models**|Zhiyuan Wen et.al.|[2406.17624v1](http://arxiv.org/abs/2406.17624v1)|null|
|**2024-06-25**|**Towards Building an End-to-End Multilingual Automatic Lyrics Transcription Model**|Jiawen Huang et.al.|[2406.17618v1](http://arxiv.org/abs/2406.17618v1)|null|
|**2024-06-25**|**Aligning Programming Language and Natural Language: Exploring Design Choices in Multi-Modal Transformer-Based Embedding for Bug Localization**|Partha Chakraborty et.al.|[2406.17615v1](http://arxiv.org/abs/2406.17615v1)|[link](https://zenodo.org/record/10519746)|
|**2024-06-25**|**Diffusion-based Adversarial Purification for Intrusion Detection**|Mohamed Amine Merzouk et.al.|[2406.17606v1](http://arxiv.org/abs/2406.17606v1)|null|
|**2024-06-25**|**"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?**|Beiduo Chen et.al.|[2406.17600v1](http://arxiv.org/abs/2406.17600v1)|null|
|**2024-06-25**|**LongIns: A Challenging Long-context Instruction-based Exam for LLMs**|Shawn Gavin et.al.|[2406.17588v2](http://arxiv.org/abs/2406.17588v2)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-25**|**Beyond Text-to-SQL for IoT Defense: A Comprehensive Framework for Querying and Classifying IoT Threats**|Ryan Pavlich et.al.|[2406.17574v1](http://arxiv.org/abs/2406.17574v1)|null|
|**2024-06-25**|**FrenchToxicityPrompts: a Large Benchmark for Evaluating and Mitigating Toxicity in French Texts**|Caroline Brun et.al.|[2406.17566v1](http://arxiv.org/abs/2406.17566v1)|null|
|**2024-06-25**|**Multi-property Steering of Large Language Models with Dynamic Activation Composition**|Daniel Scalena et.al.|[2406.17563v1](http://arxiv.org/abs/2406.17563v1)|null|
|**2024-06-25**|**The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale**|Guilherme Penedo et.al.|[2406.17557v1](http://arxiv.org/abs/2406.17557v1)|null|
|**2024-06-25**|**Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft**|Chalamalasetti Kranti et.al.|[2406.17553v1](http://arxiv.org/abs/2406.17553v1)|null|
|**2024-06-25**|**CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained Models using Greedy Coordinate Descent**|Pranav Ajit Nair et.al.|[2406.17542v2](http://arxiv.org/abs/2406.17542v2)|null|
|**2024-06-25**|**SincVAE: a New Approach to Improve Anomaly Detection on EEG Data Using SincNet and Variational Autoencoder**|Andrea Pollastro et.al.|[2406.17537v1](http://arxiv.org/abs/2406.17537v1)|null|
|**2024-06-25**|**Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark**|Fabio Mercorio et.al.|[2406.17535v1](http://arxiv.org/abs/2406.17535v1)|null|
|**2024-06-25**|**Retrieval-style In-Context Learning for Few-shot Hierarchical Text Classification**|Huiyao Chen et.al.|[2406.17534v1](http://arxiv.org/abs/2406.17534v1)|null|
|**2024-06-25**|**Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study**|Keyu Wang et.al.|[2406.17532v1](http://arxiv.org/abs/2406.17532v1)|null|
|**2024-06-25**|**Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness**|Lucrezia Grassi et.al.|[2406.17531v1](http://arxiv.org/abs/2406.17531v1)|null|
|**2024-06-25**|**LumberChunker: Long-Form Narrative Document Segmentation**|Andr√© V. Duarte et.al.|[2406.17526v1](http://arxiv.org/abs/2406.17526v1)|[link](https://github.com/joaodsmarques/lumberchunker)|
|**2024-06-25**|**Entropy-Based Decoding for Retrieval-Augmented Large Language Models**|Zexuan Qiu et.al.|[2406.17519v1](http://arxiv.org/abs/2406.17519v1)|null|
|**2024-06-25**|**Benchmarking Mental State Representations in Language Models**|Matteo Bortoletto et.al.|[2406.17513v1](http://arxiv.org/abs/2406.17513v1)|null|
|**2024-06-25**|**MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation**|Yusheng Liao et.al.|[2406.17484v1](http://arxiv.org/abs/2406.17484v1)|null|
|**2024-06-25**|**Transformer-based Named Entity Recognition with Combined Data Representation**|Micha≈Ç Marci≈Ñczuk et.al.|[2406.17474v1](http://arxiv.org/abs/2406.17474v1)|null|
|**2024-06-25**|**TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification**|Joshua Niemeijer et.al.|[2406.17473v1](http://arxiv.org/abs/2406.17473v1)|null|
|**2024-06-25**|**Dynamic Scheduling for Vehicle-to-Vehicle Communications Enhanced Federated Learning**|Jintao Yan et.al.|[2406.17470v1](http://arxiv.org/abs/2406.17470v1)|null|
|**2024-06-25**|**Enhancing Tool Retrieval with Iterative Feedback from Large Language Models**|Qiancheng Xu et.al.|[2406.17465v1](http://arxiv.org/abs/2406.17465v1)|null|
|**2024-06-25**|**The Tree of Diffusion Life: Evolutionary Embeddings to Understand the Generation Process of Diffusion Models**|Vidya Prasad et.al.|[2406.17462v1](http://arxiv.org/abs/2406.17462v1)|null|
|**2024-06-25**|**Improving Grammatical Error Correction via Contextual Data Augmentation**|Yixuan Wang et.al.|[2406.17456v1](http://arxiv.org/abs/2406.17456v1)|null|
|**2024-06-25**|**Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain**|Davide Mazzaccara et.al.|[2406.17453v1](http://arxiv.org/abs/2406.17453v1)|null|
|**2024-06-25**|**Pseudo Labelling for Enhanced Masked Autoencoders**|Srinivasa Rao Nandam et.al.|[2406.17450v1](http://arxiv.org/abs/2406.17450v1)|null|
|**2024-06-25**|**Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights**|Hao Yang et.al.|[2406.17430v1](http://arxiv.org/abs/2406.17430v1)|null|
|**2024-06-25**|**CuDA2: An approach for Incorporating Traitor Agents into Cooperative Multi-Agent Systems**|Zhen Chen et.al.|[2406.17425v1](http://arxiv.org/abs/2406.17425v1)|null|
|**2024-06-25**|**Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA**|Minzheng Wang et.al.|[2406.17419v1](http://arxiv.org/abs/2406.17419v1)|[link](https://github.com/mozerwang/loong)|
|**2024-06-25**|**Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing LLMs Beyond Integer Bit-Levels**|Razvan-Gabriel Dumitru et.al.|[2406.17415v2](http://arxiv.org/abs/2406.17415v2)|null|
|**2024-06-25**|**Make Some Noise: Unlocking Language Model Parallel Inference Capability through Noisy Training**|Yixuan Wang et.al.|[2406.17404v1](http://arxiv.org/abs/2406.17404v1)|null|
|**2024-06-25**|**Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance**|Manon Reusens et.al.|[2406.17385v1](http://arxiv.org/abs/2406.17385v1)|null|
|**2024-06-25**|**A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens**|Zhijie Nie et.al.|[2406.17378v1](http://arxiv.org/abs/2406.17378v1)|null|
|**2024-06-25**|**A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs**|Vaibhav Singh et.al.|[2406.17377v1](http://arxiv.org/abs/2406.17377v1)|null|
|**2024-06-25**|**Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic Speech Detection**|Duc-Tuan Truong et.al.|[2406.17376v1](http://arxiv.org/abs/2406.17376v1)|[link](https://github.com/ductuantruong/tcm_add)|
|**2024-06-25**|**An Empirical Study on the Characteristics of Bias upon Context Length Variation for Bangla**|Jayanta Sadhu et.al.|[2406.17375v1](http://arxiv.org/abs/2406.17375v1)|null|
|**2024-06-25**|**Leveraging Synthetic Audio Data for End-to-End Low-Resource Speech Translation**|Yasmin Moslem et.al.|[2406.17363v1](http://arxiv.org/abs/2406.17363v1)|null|
|**2024-06-25**|**Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers**|Lei Chen et.al.|[2406.17343v1](http://arxiv.org/abs/2406.17343v1)|null|
|**2024-06-25**|**Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**|Hongliang Zeng et.al.|[2406.17342v1](http://arxiv.org/abs/2406.17342v1)|null|
|**2024-06-25**|**Joint Admission Control and Resource Allocation of Virtual Network Embedding via Hierarchical Deep Reinforcement Learning**|Tianfu Wang et.al.|[2406.17334v1](http://arxiv.org/abs/2406.17334v1)|[link](https://github.com/geminilight/hrl-acra)|
|**2024-06-25**|**Dual-Space Knowledge Distillation for Large Language Models**|Songming Zhang et.al.|[2406.17328v1](http://arxiv.org/abs/2406.17328v1)|[link](https://github.com/songmzhang/dskd)|
|**2024-06-25**|**Delving into the Utilisation of ChatGPT in Scientific Publications in Astronomy**|Simone Astarita et.al.|[2406.17324v1](http://arxiv.org/abs/2406.17324v1)|null|
|**2024-06-25**|**Retrieval Augmented Instruction Tuning for Open NER with Large Language Models**|Tingyu Xie et.al.|[2406.17305v1](http://arxiv.org/abs/2406.17305v1)|[link](https://github.com/emma1066/retrieval-augmented-it-openner)|
|**2024-06-25**|**Leveraging LLMs for Dialogue Quality Measurement**|Jinghan Jia et.al.|[2406.17304v1](http://arxiv.org/abs/2406.17304v1)|null|
|**2024-06-25**|**Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models**|Wenhao Shi et.al.|[2406.17294v2](http://arxiv.org/abs/2406.17294v2)|null|
|**2024-06-25**|**Hyperbolic Knowledge Transfer in Cross-Domain Recommendation System**|Xin Yang et.al.|[2406.17289v1](http://arxiv.org/abs/2406.17289v1)|null|
|**2024-06-25**|**Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models**|Yang Yan et.al.|[2406.17287v1](http://arxiv.org/abs/2406.17287v1)|[link](https://github.com/kuri-leo/bigfive-llm-predictor)|
|**2024-06-25**|**SetBERT: Enhancing Retrieval Performance for Boolean Logic and Set Operation Queries**|Quan Mai et.al.|[2406.17282v2](http://arxiv.org/abs/2406.17282v2)|null|
|**2024-06-25**|**OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure**|Jikai Wang et.al.|[2406.17276v1](http://arxiv.org/abs/2406.17276v1)|[link](https://github.com/jikai0wang/opt-tree)|
|**2024-06-25**|**Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?**|Jianfeng He et.al.|[2406.17274v1](http://arxiv.org/abs/2406.17274v1)|null|
|**2024-06-25**|**DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**|Zhehao Zhang et.al.|[2406.17271v1](http://arxiv.org/abs/2406.17271v1)|[link](https://github.com/salt-nlp/darg)|
|**2024-06-25**|**AG-LSEC: Audio Grounded Lexical Speaker Error Correction**|Rohit Paturi et.al.|[2406.17266v1](http://arxiv.org/abs/2406.17266v1)|null|
|**2024-06-25**|**D2LLM: Decomposed and Distilled Large Language Models for Semantic Search**|Zihan Liao et.al.|[2406.17262v1](http://arxiv.org/abs/2406.17262v1)|null|
|**2024-06-25**|**TRAWL: Tensor Reduced and Approximated Weights for Large Language Models**|Yiran Luo et.al.|[2406.17261v1](http://arxiv.org/abs/2406.17261v1)|null|
|**2024-06-25**|**Mitigating Hallucination in Fictional Character Role-Play**|Nafis Sadeq et.al.|[2406.17260v1](http://arxiv.org/abs/2406.17260v1)|null|
|**2024-06-25**|**Leveraging Parameter-Efficient Transfer Learning for Multi-Lingual Text-to-Speech Adaptation**|Yingting Li et.al.|[2406.17257v1](http://arxiv.org/abs/2406.17257v1)|null|
|**2024-06-25**|**MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning**|Zhenlong Dai et.al.|[2406.17255v1](http://arxiv.org/abs/2406.17255v1)|null|
|**2024-06-25**|**How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?**|Huaizhi Ge et.al.|[2406.17253v1](http://arxiv.org/abs/2406.17253v1)|null|
|**2024-06-25**|**TopoGCL: Topological Graph Contrastive Learning**|Yuzhou Chen et.al.|[2406.17251v1](http://arxiv.org/abs/2406.17251v1)|[link](https://github.com/topogclaaai24/topogcl)|
|**2024-06-25**|**Beyond Silence: Bias Analysis through Loss and Asymmetric Approach in Audio Anti-Spoofing**|Hye-jin Shim et.al.|[2406.17246v1](http://arxiv.org/abs/2406.17246v1)|null|
|**2024-06-25**|**Unlocking Continual Learning Abilities in Language Models**|Wenyu Du et.al.|[2406.17245v1](http://arxiv.org/abs/2406.17245v1)|[link](https://github.com/wenyudu/migu)|
|**2024-06-25**|**What Do the Circuits Mean? A Knowledge Edit View**|Huaizhi Ge et.al.|[2406.17241v1](http://arxiv.org/abs/2406.17241v1)|null|

#### Abstracts
##### **EXTRACT: Efficient Policy Learning by Extracting Transferrable Robot Skills from Offline Data**
2406.17768v1 by Jesse Zhang, Minho Heo, Zuxin Liu, Erdem Biyik, Joseph J Lim, Yao Liu, Rasool Fakoor

Most reinforcement learning (RL) methods focus on learning optimal policies
over low-level action spaces. While these methods can perform well in their
training environments, they lack the flexibility to transfer to new tasks.
Instead, RL agents that can act over useful, temporally extended skills rather
than low-level actions can learn new tasks more easily. Prior work in
skill-based RL either requires expert supervision to define useful skills,
which is hard to scale, or learns a skill-space from offline data with
heuristics that limit the adaptability of the skills, making them difficult to
transfer during downstream RL. Our approach, EXTRACT, instead utilizes
pre-trained vision language models to extract a discrete set of semantically
meaningful skills from offline data, each of which is parameterized by
continuous arguments, without human supervision. This skill parameterization
allows robots to learn new tasks by only needing to learn when to select a
specific skill and how to modify its arguments for the specific task. We
demonstrate through experiments in sparse-reward, image-based, robot
manipulation environments that EXTRACT can more quickly learn new tasks than
prior works, with major gains in sample efficiency and performance over prior
skill-based RL. Website at https://www.jessezhang.net/projects/extract/.

ÊëòË¶ÅÔºöÂ§ßÂ§öÊï∞Âº∫ÂåñÂ≠¶‰π† (RL) ÊñπÊ≥ï‰∏ìÊ≥®‰∫éÂ≠¶‰π†‰ΩéÁ∫ßÂä®‰ΩúÁ©∫Èó¥‰∏äÁöÑÊúÄ‰ºòÁ≠ñÁï•„ÄÇËôΩÁÑ∂Ëøô‰∫õÊñπÊ≥ïÂèØ‰ª•Âú®ÂÖ∂ËÆ≠ÁªÉÁéØÂ¢É‰∏≠Ë°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂÆÉ‰ª¨Áº∫‰πèËΩ¨ÁßªÂà∞Êñ∞‰ªªÂä°ÁöÑÁÅµÊ¥ªÊÄß„ÄÇÁõ∏ÂèçÔºåËÉΩÂ§ü‰ΩúÁî®‰∫éÊúâÁî®„ÄÅÊó∂Èó¥Âª∂ÈïøÁöÑÊäÄËÉΩËÄå‰∏çÊòØ‰ΩéÁ∫ßÂä®‰ΩúÁöÑ RL ‰ª£ÁêÜÂèØ‰ª•Êõ¥ÂÆπÊòìÂú∞Â≠¶‰π†Êñ∞‰ªªÂä°„ÄÇÂü∫‰∫éÊäÄËÉΩÁöÑ RL ‰∏≠ÁöÑÂÖàÂâçÂ∑•‰ΩúË¶Å‰πàÈúÄË¶Å‰∏ìÂÆ∂ÁõëÁù£Êù•ÂÆö‰πâÊúâÁî®ÁöÑÊäÄËÉΩÔºàÂæàÈöæÊâ©Â±ïÔºâÔºåË¶Å‰πà‰ªéÁ¶ªÁ∫øÊï∞ÊçÆ‰∏≠Â≠¶‰π†ÊäÄËÉΩÁ©∫Èó¥ÔºåËÄåÂêØÂèëÂºèÊñπÊ≥ïÈôêÂà∂‰∫ÜÊäÄËÉΩÁöÑÈÄÇÂ∫îÊÄßÔºå‰ΩøÂÖ∂Èöæ‰ª•Âú®ÂêéÁ´Ø RL ÊúüÈó¥ËΩ¨Áßª„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï EXTRACT ÂàôÂà©Áî®È¢ÑËÆ≠ÁªÉÁöÑËßÜËßâËØ≠Ë®ÄÊ®°Âûã‰ªéÁ¶ªÁ∫øÊï∞ÊçÆ‰∏≠ÊèêÂèñ‰∏ÄÁªÑÁ¶ªÊï£ÁöÑËØ≠‰πâÊúâÊÑè‰πâÁöÑÊäÄËÉΩÔºåÊØè‰∏™ÊäÄËÉΩÈÉΩÁî±ËøûÁª≠ÂèÇÊï∞ÂèÇÊï∞ÂåñÔºåÊó†ÈúÄ‰∫∫Â∑•ÁõëÁù£„ÄÇËøôÁßçÊäÄËÉΩÂèÇÊï∞ÂåñÂÖÅËÆ∏Êú∫Âô®‰∫∫ÈÄöËøá‰ªÖÈúÄÂ≠¶‰π†‰ΩïÊó∂ÈÄâÊã©ÁâπÂÆöÊäÄËÉΩ‰ª•ÂèäÂ¶Ç‰Ωï‰øÆÊîπÂÖ∂ÂèÇÊï∞‰ª•ÈÄÇÂ∫îÁâπÂÆö‰ªªÂä°Êù•Â≠¶‰π†Êñ∞‰ªªÂä°„ÄÇÊàë‰ª¨ÈÄöËøáÂú®Á®ÄÁñèÂ•ñÂä±„ÄÅÂü∫‰∫éÂõæÂÉèÁöÑÊú∫Âô®‰∫∫Êìç‰ΩúÁéØÂ¢É‰∏≠ÁöÑÂÆûÈ™åË°®ÊòéÔºåEXTRACT ÂèØ‰ª•ÊØî‰ª•ÂâçÁöÑÂ∑•‰ΩúÊõ¥Âø´Âú∞Â≠¶‰π†Êñ∞‰ªªÂä°ÔºåÂú®Ê†∑Êú¨ÊïàÁéáÂíåÊÄßËÉΩÊñπÈù¢ÂèñÂæó‰∫ÜÊØî‰ª•ÂâçÂü∫‰∫éÊäÄËÉΩÁöÑ RL ÁöÑÈáçÂ§ßÊî∂Áõä„ÄÇÁΩëÁ´ô‰Ωç‰∫é https://www.jessezhang.net/projects/extract/„ÄÇ

##### **BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning**
2406.17764v1 by Ercong Nie, Bo Shao, Zifeng Ding, Mingyang Wang, Helmut Schmid, Hinrich Sch√ºtze

Large language models (LLMs) possess extensive parametric knowledge, but this
knowledge is difficult to update with new information because retraining is
very expensive and infeasible for closed-source models. Knowledge editing (KE)
has emerged as a viable solution for updating the knowledge of LLMs without
compromising their overall performance. On-the-fly KE methods, inspired by
in-context learning (ICL), have shown great promise and allow LLMs to be
treated as black boxes. In the past, KE was primarily employed in English
contexts, whereas the potential for cross-lingual KE in current English-centric
LLMs has not been fully explored. To foster more research in this direction, we
introduce the BMIKE-53 benchmark for evaluating cross-lingual KE on 53 diverse
languages across three KE task types. We also propose a gradient-free KE method
called Multilingual In-context Knowledge Editing (MIKE) and evaluate it on
BMIKE-53. Our evaluation focuses on cross-lingual knowledge transfer in terms
of reliability, generality, locality, and portability, offering valuable
insights and a framework for future research in cross-lingual KE. Our code and
data are publicly accessible via the anonymous repository at
https://anonymous.4open.science/r/MIKE.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâÂª£Ê≥õÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òÔºå‰ΩÜÁî±ÊñºÈáçÊñ∞Ë®ìÁ∑¥ÈùûÂ∏∏ÊòÇË≤¥‰∏îÂ∞çÈñâÊ∫êÊ®°Âûã‰∏çÂèØË°åÔºåÂõ†Ê≠§Èõ£‰ª•‰ΩøÁî®Êñ∞Ë≥áË®äÊõ¥Êñ∞Ê≠§Áü•Ë≠ò„ÄÇÁü•Ë≠òÁ∑®ËºØ (KE) Â∑≤ÊàêÁÇ∫Âú®‰∏çÂΩ±Èüø LLM Êï¥È´îÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÊõ¥Êñ∞ÂÖ∂Áü•Ë≠òÁöÑÂèØË°åËß£Ê±∫ÊñπÊ°à„ÄÇÂèóÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÂïüÁôºÁöÑÂç≥ÊôÇ KE ÊñπÊ≥ïÂ∑≤Â±ïÁèæÊ•µÂ§ßÊΩõÂäõÔºå‰∏¶ÂÖÅË®±Â∞á LLM Ë¶ñÁÇ∫ÈªëÁõíÂ≠ê„ÄÇÈÅéÂéªÔºåKE ‰∏ªË¶ÅÁî®ÊñºËã±Ë™ûÊÉÖÂ¢ÉÔºåËÄåÁõÆÂâç‰ª•Ëã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑ LLM ‰∏≠Ë∑®Ë™ûË®Ä KE ÁöÑÊΩõÂäõÂ∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Êõ¥Â§öÈÄôÊñπÈù¢ÁöÑÁ†îÁ©∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü BMIKE-53 Âü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ 53 Á®Æ‰∏çÂêåË™ûË®ÄÂú®‰∏âÁ®Æ KE ‰ªªÂãôÈ°ûÂûã‰∏≠ÁöÑË∑®Ë™ûË®Ä KE„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫Â§öË™ûË®ÄÊÉÖÂ¢ÉÁü•Ë≠òÁ∑®ËºØ (MIKE) ÁöÑÁÑ°Ê¢ØÂ∫¶ KE ÊñπÊ≥ïÔºå‰∏¶Âú® BMIKE-53 ‰∏äÂ∞çÂÖ∂ÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÈáçÈªûÂú®ÊñºË∑®Ë™ûË®ÄÁü•Ë≠òËΩâÁßªÁöÑÂèØÈù†ÊÄß„ÄÅÊôÆÈÅçÊÄß„ÄÅÂ±ÄÈÉ®ÊÄßÂíåÂèØÁßªÊ§çÊÄßÔºåÁÇ∫Ë∑®Ë™ûË®Ä KE ÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõÊúâÂÉπÂÄºÁöÑË¶ãËß£ÂíåÊ°ÜÊû∂„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÈÄèÈÅé https://anonymous.4open.science/r/MIKE ‰∏äÁöÑÂåøÂêçÂÑ≤Â≠òÂ∫´ÂÖ¨ÈñãÂ≠òÂèñ„ÄÇ

##### **DiffusionPDE: Generative PDE-Solving Under Partial Observation**
2406.17763v1 by Jiahe Huang, Guandao Yang, Zichen Wang, Jeong Joon Park

We introduce a general framework for solving partial differential equations
(PDEs) using generative diffusion models. In particular, we focus on the
scenarios where we do not have the full knowledge of the scene necessary to
apply classical solvers. Most existing forward or inverse PDE approaches
perform poorly when the observations on the data or the underlying coefficients
are incomplete, which is a common assumption for real-world measurements. In
this work, we propose DiffusionPDE that can simultaneously fill in the missing
information and solve a PDE by modeling the joint distribution of the solution
and coefficient spaces. We show that the learned generative priors lead to a
versatile framework for accurately solving a wide range of PDEs under partial
observation, significantly outperforming the state-of-the-art methods for both
forward and inverse directions.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÈÄöÁî®Êû∂ÊßãÔºåÁî®ÁîüÊàêÊì¥Êï£Ê®°ÂûãËß£Ê±∫ÂÅèÂæÆÂàÜÊñπÁ®ãÂºè (PDE)„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÊàëÂÄëÊ≤íÊúâÂ†¥ÊôØÁöÑÂÆåÊï¥Áü•Ë≠òÔºåÁÑ°Ê≥ïÊáâÁî®Á∂ìÂÖ∏Ê±ÇËß£Âô®ÁöÑÊÉÖÊ≥Å„ÄÇÁï∂Ë≥áÊñôÊàñÂü∫Á§é‰øÇÊï∏ÁöÑËßÄÊ∏¨‰∏çÂÆåÊï¥ÊôÇÔºåÁèæÊúâÁöÑÊ≠£ÂêëÊàñÂèçÂêë PDE ÊñπÊ≥ïÂ§ßÂ§öË°®Áèæ‰∏ç‰Ω≥ÔºåÈÄôÊòØÁèæÂØ¶‰∏ñÁïåÊ∏¨ÈáèÁöÑ‰∏ÄÂÄãÂ∏∏Ë¶ãÂÅáË®≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ DiffusionPDEÔºåÂÆÉÂèØ‰ª•ÂêåÊôÇÂ°´Ë£úÈÅ∫Â§±ÁöÑË≥áË®ä‰∏¶ÈÄèÈÅéÂ∞çËß£Âíå‰øÇÊï∏Á©∫ÈñìÁöÑËÅØÂêàÂàÜ‰ΩàÂª∫Ê®°‰æÜÊ±ÇËß£ PDE„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ≠∏ÁøíÂà∞ÁöÑÁîüÊàêÂÖàÈ©óÂ∞éËá¥‰∫Ü‰∏ÄÂÄãÈÄöÁî®ÁöÑÊ°ÜÊû∂ÔºåÁî®ÊñºÂú®ÈÉ®ÂàÜËßÄÊ∏¨‰∏ãÊ∫ñÁ¢∫Ê±ÇËß£ÂêÑÁ®Æ PDEÔºåÈ°ØËëóÂÑ™ÊñºÊ≠£ÂêëÂíåÂèçÂêëÊñπÂêëÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇ

##### **CaLMQA: Exploring culturally specific long-form question answering across 23 languages**
2406.17761v1 by Shane Arora, Marzena Karpinska, Hung-Ting Chen, Ipsita Bhattacharjee, Mohit Iyyer, Eunsol Choi

Large language models (LLMs) are commonly used for long-form question
answering, which requires them to generate paragraph-length answers to complex
questions. While long-form QA has been well-studied in English via many
different datasets and evaluation metrics, this research has not been extended
to cover most other languages. To bridge this gap, we introduce CaLMQA, a
collection of 2.6K complex questions spanning 23 languages, including
under-resourced, rarely-studied languages such as Fijian and Kirundi. Our
dataset includes both naturally-occurring questions collected from community
web forums as well as questions written by native speakers, whom we hire for
this purpose. Our process yields diverse, complex questions that reflect
cultural topics (e.g. traditions, laws, news) and the language usage of native
speakers. We conduct automatic evaluation across a suite of open- and
closed-source models using our novel metric CaLMScore, which detects incorrect
language and token repetitions in answers, and observe that the quality of
LLM-generated answers degrades significantly for some low-resource languages.
We perform human evaluation on a subset of models and see that model
performance is significantly worse for culturally specific questions than for
culturally agnostic questions. Our findings highlight the need for further
research in LLM multilingual capabilities and non-English LFQA evaluation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∏∏Áî®ÊñºÈï∑ÁØáÂïèÁ≠îÔºåÈÄôÈúÄË¶ÅÂÆÉÂÄëÈáùÂ∞çË§áÈõúÂïèÈ°åÁî¢ÁîüÊÆµËêΩÈï∑Â∫¶ÁöÑÁ≠îÊ°à„ÄÇÈõñÁÑ∂Èï∑ÁØáÂïèÁ≠îÂ∑≤ÈÄèÈÅéË®±Â§ö‰∏çÂêåÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊåáÊ®ôÂú®Ëã±Êñá‰∏≠ÂæóÂà∞ÂÖÖÂàÜÁ†îÁ©∂Ôºå‰ΩÜÊ≠§Á†îÁ©∂Â∞öÊú™Êì¥Â±ïÂà∞Ê∂µËìãÂ§ßÂ§öÊï∏ÂÖ∂‰ªñË™ûË®Ä„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CaLMQAÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 2.6K ÂÄãË§áÈõúÂïèÈ°åÁöÑÈõÜÂêàÔºåÊ∂µËìã 23 Á®ÆË™ûË®ÄÔºåÂåÖÊã¨ÊñêÊøüË™ûÂíåÂü∫ÈöÜËø™Ë™ûÁ≠âË≥áÊ∫ê‰∏çË∂≥„ÄÅÈÆÆÂ∞ëÁ†îÁ©∂ÁöÑË™ûË®Ä„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÂåÖÂê´ÂæûÁ§æÁæ§Á∂≤Ë∑ØË´ñÂ£áÊî∂ÈõÜÂà∞ÁöÑËá™ÁÑ∂ÁôºÁîüÂïèÈ°åÔºå‰ª•ÂèäÊàëÂÄëÁÇ∫Ê≠§ÁõÆÁöÑËÅòË´ãÊØçË™û‰∫∫Â£´Êí∞ÂØ´ÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÊµÅÁ®ãÁî¢Áîü‰∫ÜÂ§öÂÖÉ„ÄÅË§áÈõúÁöÑÂïèÈ°åÔºåÂèçÊò†‰∫ÜÊñáÂåñ‰∏ªÈ°åÔºà‰æãÂ¶ÇÂÇ≥Áµ±„ÄÅÊ≥ïÂæã„ÄÅÊñ∞ËÅûÔºâÂíåÊØçË™û‰∫∫Â£´ÁöÑË™ûË®Ä‰ΩøÁî®„ÄÇÊàëÂÄë‰ΩøÁî®ÊàëÂÄëÁöÑÊñ∞Á©éÊåáÊ®ô CaLMScore Â∞ç‰∏ÄÁ≥ªÂàóÈñãÊîæÂíåÈñâÊ∫êÊ®°ÂûãÈÄ≤Ë°åËá™ÂãïË©ï‰º∞ÔºåË©≤ÊåáÊ®ôÊúÉÂÅµÊ∏¨Á≠îÊ°à‰∏≠ÁöÑ‰∏çÊ≠£Á¢∫Ë™ûË®ÄÂíåÈáçË§áË®òËôüÔºå‰∏¶ËßÄÂØüÂà∞ LLM ÁîüÊàêÁöÑÁ≠îÊ°àÂìÅË≥™Â∞çÊñºÊüê‰∫õ‰ΩéË≥áÊ∫êË™ûË®ÄÊúÉÈ°ØËëó‰∏ãÈôç„ÄÇÊàëÂÄëÂ∞çÊ®°ÂûãÁöÑÂ≠êÈõÜÈÄ≤Ë°å‰∫∫Â∑•Ë©ï‰º∞Ôºå‰∏¶ÁôºÁèæÈáùÂ∞çÁâπÂÆöÊñáÂåñÂïèÈ°åÁöÑÊ®°ÂûãÊïàËÉΩÈ°ØËëó‰ΩéÊñºÈáùÂ∞çÊñáÂåñ‰∏çÂèØÁü•ÂïèÈ°åÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ LLM Â§öË™ûË®ÄËÉΩÂäõÂíåÈùûËã±Êñá LFQA Ë©ï‰º∞ÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Accelerating Clinical Evidence Synthesis with Large Language Models**
2406.17755v1 by Zifeng Wang, Lang Cao, Benjamin Danek, Yichi Zhang, Qiao Jin, Zhiyong Lu, Jimeng Sun

Automatic medical discovery by AI is a dream of many. One step toward that
goal is to create an AI model to understand clinical studies and synthesize
clinical evidence from the literature. Clinical evidence synthesis currently
relies on systematic reviews of clinical trials and retrospective analyses from
medical literature. However, the rapid expansion of publications presents
challenges in efficiently identifying, summarizing, and updating evidence. We
introduce TrialMind, a generative AI-based pipeline for conducting medical
systematic reviews, encompassing study search, screening, and data extraction
phases. We utilize large language models (LLMs) to drive each pipeline
component while incorporating human expert oversight to minimize errors. To
facilitate evaluation, we also create a benchmark dataset TrialReviewBench, a
custom dataset with 870 annotated clinical studies from 25 meta-analysis papers
across various medical treatments. Our results demonstrate that TrialMind
significantly improves the literature review process, achieving high recall
rates (0.897-1.000) in study searching from over 20 million PubMed studies and
outperforming traditional language model embeddings-based methods in screening
(Recall@20 of 0.227-0.246 vs. 0.000-0.102). Furthermore, our approach surpasses
direct GPT-4 performance in result extraction, with accuracy ranging from 0.65
to 0.84. We also support clinical evidence synthesis in forest plots, as
validated by eight human annotators who preferred TrialMind over the GPT-4
baseline with a winning rate of 62.5%-100% across the involved reviews. Our
findings suggest that an LLM-based clinical evidence synthesis approach, such
as TrialMind, can enable reliable and high-quality clinical evidence synthesis
to improve clinical research efficiency.

ÊëòË¶ÅÔºö<paragraph>Ë®±Â§ö‰∫∫Â§¢ÊÉ≥ËëóÁî± AI Ëá™ÂãïÈÄ≤Ë°åÈÜ´Â≠∏ÁôºÁèæ„ÄÇÊúùÊ≠§ÁõÆÊ®ôÈÇÅÈÄ≤ÁöÑ‰∏ÄÊ≠•ÊòØÂª∫Á´ã‰∏ÄÂÄã AI Ê®°Âûã‰æÜÁêÜËß£Ëá®Â∫äÁ†îÁ©∂Ôºå‰∏¶ÂæûÊñáÁçª‰∏≠Á∂úÂêàËá®Â∫äË≠âÊìö„ÄÇËá®Â∫äË≠âÊìöÁ∂úÂêàÁõÆÂâç‰æùË≥¥ÊñºËá®Â∫äË©¶È©óÁöÑÁ≥ªÁµ±ÊÄßÂõûÈ°ßÂíåÈÜ´Â≠∏ÊñáÁçªÁöÑÂõûÊ∫ØÊÄßÂàÜÊûê„ÄÇÁÑ∂ËÄåÔºåÂá∫ÁâàÁâ©ÁöÑÂø´ÈÄüÊì¥ÂºµÂú®ÊúâÊïàÂú∞Ë≠òÂà•„ÄÅÁ∏ΩÁµêÂíåÊõ¥Êñ∞Ë≠âÊìöÊñπÈù¢ÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü TrialMindÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÁîüÊàêÂºè AI ÁöÑÁÆ°ÈÅìÔºåÁî®ÊñºÈÄ≤Ë°åÈÜ´Â≠∏Á≥ªÁµ±ÊÄßÂõûÈ°ßÔºåÂåÖÊã¨Á†îÁ©∂ÊêúÂ∞ã„ÄÅÁØ©ÈÅ∏ÂíåÊï∏ÊìöËêÉÂèñÈöéÊÆµ„ÄÇÊàëÂÄëÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÈ©ÖÂãïÊØèÂÄãÁÆ°ÈÅìÁµÑ‰ª∂ÔºåÂêåÊôÇÁµêÂêà‰∫∫È°ûÂ∞àÂÆ∂Áõ£Áù£‰ª•ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Ê∏õÂ∞ëÈåØË™§„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Ë©ï‰º∞ÔºåÊàëÂÄëÈÇÑÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñÊï∏ÊìöÈõÜ TrialReviewBenchÔºåÈÄôÊòØ‰∏ÄÂÄãËá™Ë®ÇÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ 25 ÁØáÈóúÊñºÂêÑÁ®ÆÈÜ´ÁôÇÊ≤ªÁôÇÁöÑÂÖÉÂàÜÊûêË´ñÊñáÁöÑ 870 È†ÖË®ªËß£Ëá®Â∫äÁ†îÁ©∂„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåTrialMind Â§ßÂπÖÊîπÂñÑ‰∫ÜÊñáÁçªÂõûÈ°ßÊµÅÁ®ãÔºåÂú®Ë∂ÖÈÅé 2000 Ëê¨ÁØá PubMed Á†îÁ©∂‰∏≠ÈÅîÂà∞‰∫ÜÂæàÈ´òÁöÑÂè¨ÂõûÁéá (0.897-1.000)Ôºå‰∏¶Âú®ÁØ©ÈÅ∏ÊñπÈù¢ÂÑ™ÊñºÂü∫ÊñºÂÇ≥Áµ±Ë™ûË®ÄÊ®°ÂûãÂµåÂÖ•ÁöÑÊñπÊ≥ïÔºàÂè¨ÂõûÁéá @20 ÁÇ∫ 0.227-0.246ÔºåÁõ∏ËºÉÊñº 0.000-0.102Ôºâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÁµêÊûúËêÉÂèñÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÁõ¥Êé•ÁöÑ GPT-4 ÊïàËÉΩÔºåÊ∫ñÁ¢∫Â∫¶ÁØÑÂúçÂæû 0.65 Âà∞ 0.84„ÄÇÊàëÂÄëÈÇÑÊîØÊè¥Ê£ÆÊûóÂúñ‰∏≠ÁöÑËá®Â∫äË≠âÊìöÁ∂úÂêàÔºåÈÄôÈªûÂ∑≤Áç≤ÂæóÂÖ´‰Ωç‰∫∫È°ûË®ªËß£ËÄÖÁöÑÈ©óË≠âÔºå‰ªñÂÄëÂú®Áõ∏ÈóúÂõûÈ°ß‰∏≠‰ª• 62.5%-100% ÁöÑÁç≤ÂãùÁéáÂÅèÂ•Ω TrialMindÔºåÂãùÈÅé GPT-4 Âü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÂü∫Êñº LLM ÁöÑËá®Â∫äË≠âÊìöÁ∂úÂêàÊñπÊ≥ïÔºà‰æãÂ¶Ç TrialMindÔºâÂèØ‰ª•ÂØ¶ÁèæÂèØÈù†‰∏îÈ´òÂìÅË≥™ÁöÑËá®Â∫äË≠âÊìöÁ∂úÂêàÔºå‰ª•ÊèêÈ´òËá®Â∫äÁ†îÁ©∂ÊïàÁéá„ÄÇ</paragraph>

##### **Measuring and Benchmarking Large Language Models' Capabilities to Generate Persuasive Language**
2406.17753v1 by Amalie Brogaard Pauli, Isabelle Augenstein, Ira Assent

We are exposed to much information trying to influence us, such as teaser
messages, debates, politically framed news, and propaganda - all of which use
persuasive language. With the recent interest in Large Language Models (LLMs),
we study the ability of LLMs to produce persuasive text. As opposed to prior
work which focuses on particular domains or types of persuasion, we conduct a
general study across various domains to measure and benchmark to what degree
LLMs produce persuasive text - both when explicitly instructed to rewrite text
to be more or less persuasive and when only instructed to paraphrase. To this
end, we construct a new dataset, Persuasive-Pairs, of pairs each consisting of
a short text and of a text rewritten by an LLM to amplify or diminish
persuasive language. We multi-annotate the pairs on a relative scale for
persuasive language. This data is not only a valuable resource in itself, but
we also show that it can be used to train a regression model to predict a score
of persuasive language between text pairs. This model can score and benchmark
new LLMs across domains, thereby facilitating the comparison of different LLMs.
Finally, we discuss effects observed for different system prompts. Notably, we
find that different 'personas' in the system prompt of LLaMA3 change the
persuasive language in the text substantially, even when only instructed to
paraphrase. These findings underscore the importance of investigating
persuasive language in LLM generated text.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊúÉÊé•Ëß∏Âà∞Ë®±Â§öË©¶ÂúñÂΩ±ÈüøÊàëÂÄëÁöÑË≥áË®äÔºå‰æãÂ¶ÇÈ†êÂëäË®äÊÅØ„ÄÅËæØË´ñ„ÄÅÊîøÊ≤ªÊ°ÜÊû∂Êñ∞ËÅûÂíåÂÆ£ÂÇ≥ÔºåÊâÄÊúâÈÄô‰∫õÈÉΩ‰ΩøÁî®ÂÖ∑Ë™™ÊúçÂäõÁöÑË™ûË®Ä„ÄÇÈö®ËëóÊúÄËøëÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËààË∂£ÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü LLM Áî¢ÁîüÂÖ∑Ë™™ÊúçÂäõÊñáÂ≠óÁöÑËÉΩÂäõ„ÄÇËàáÂ∞àÊ≥®ÊñºÁâπÂÆöÈ†òÂüüÊàñË™™ÊúçÈ°ûÂûãÁöÑÂÖàÂâçÁ†îÁ©∂Áõ∏ÂèçÔºåÊàëÂÄëÂú®ÂêÑÁ®ÆÈ†òÂüüÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†Ö‰∏ÄËà¨ÊÄßÁ†îÁ©∂Ôºå‰ª•Ë°°ÈáèÂíåÂü∫Ê∫ñ LLM Áî¢ÁîüÂÖ∑Ë™™ÊúçÂäõÊñáÂ≠óÁöÑÁ®ãÂ∫¶ÔºåÁÑ°Ë´ñÊòØÂú®ÊòéÁ¢∫ÊåáÁ§∫ÊîπÂØ´ÊñáÂ≠ó‰ª•‰ΩøÂÖ∂Êõ¥ÂÖ∑Ë™™ÊúçÂäõÊàñÊõ¥‰∏çÂÖ∑Ë™™ÊúçÂäõÊôÇÔºåÊàñÂÉÖÊåáÁ§∫ÈÄ≤Ë°åÂêåÁæ©ÊîπÂØ´ÊôÇ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊñ∞Ë≥áÊñôÈõÜ Persuasive-PairsÔºåÂÖ∂‰∏≠ÊØè‰∏ÄÂ∞çÈÉΩÂåÖÂê´‰∏ÄÊÆµÁ∞°Áü≠ÊñáÂ≠óÂíå‰∏ÄÊÆµÁî± LLM ÊîπÂØ´ÁöÑÊñáÂ≠óÔºå‰ª•Êì¥Â§ßÊàñÊ∏õÂ∞ëÂÖ∑Ë™™ÊúçÂäõÁöÑË™ûË®Ä„ÄÇÊàëÂÄë‰ª•Áõ∏Â∞çÈáèË°®Â∞çÈÄô‰∫õÂ∞çÈÄ≤Ë°åÂ§öÈáçË®ªËß£Ôºå‰ª•Ë°®Á§∫ÂÖ∑Ë™™ÊúçÂäõÁöÑË™ûË®Ä„ÄÇÈÄô‰∫õË≥áÊñôÊú¨Ë∫´‰∏çÂÉÖÊòØ‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑË≥áÊ∫êÔºåÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂÆÉÂèØÁî®ÊñºË®ìÁ∑¥ÂõûÊ≠∏Ê®°ÂûãÔºå‰ª•È†êÊ∏¨ÊñáÊú¨Â∞ç‰πãÈñìÂÖ∑Ë™™ÊúçÂäõÁöÑË™ûË®ÄÂàÜÊï∏„ÄÇÊ≠§Ê®°ÂûãÂèØ‰ª•Âú®ÂêÑÂÄãÈ†òÂüüÂ∞çÊñ∞ÁöÑ LLM ÈÄ≤Ë°åË©ïÂàÜÂíåÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂæûËÄå‰øÉÈÄ≤Â∞ç‰∏çÂêå LLM ÁöÑÊØîËºÉ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÂ∞ç‰∏çÂêåÁ≥ªÁµ±ÊèêÁ§∫ËßÄÂØüÂà∞ÁöÑÂΩ±Èüø„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæ LLaMA3 Á≥ªÁµ±ÊèêÁ§∫‰∏≠ÁöÑ‰∏çÂêå„ÄåËßíËâ≤„ÄçÊúÉÂ§ßÂπÖÊîπËÆäÊñáÂ≠ó‰∏≠ÁöÑÂÖ∑Ë™™ÊúçÂäõË™ûË®ÄÔºåÂç≥‰ΩøÂÉÖÊåáÁ§∫ÈÄ≤Ë°åÂêåÁæ©ÊîπÂØ´ÊôÇ‰πüÊòØÂ¶ÇÊ≠§„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜË™øÊü• LLM ÁîüÊàêÁöÑÊñáÂ≠ó‰∏≠ÂÖ∑Ë™™ÊúçÂäõË™ûË®ÄÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon**
2406.17746v1 by USVSN Sai Prashanth, Alvin Deng, Kyle O'Brien, Jyothir S V, Mohammad Aflah Khan, Jaydeep Borkar, Christopher A. Choquette-Choo, Jacob Ray Fuehne, Stella Biderman, Tracy Ke, Katherine Lee, Naomi Saphra

Memorization in language models is typically treated as a homogenous
phenomenon, neglecting the specifics of the memorized data. We instead model
memorization as the effect of a set of complex factors that describe each
sample and relate it to the model and corpus. To build intuition around these
factors, we break memorization down into a taxonomy: recitation of highly
duplicated sequences, reconstruction of inherently predictable sequences, and
recollection of sequences that are neither. We demonstrate the usefulness of
our taxonomy by using it to construct a predictive model for memorization. By
analyzing dependencies and inspecting the weights of the predictive model, we
find that different factors influence the likelihood of memorization
differently depending on the taxonomic category.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑË®òÊÜ∂ÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫‰∏ÄÁ®ÆÂêåË≥™ÁèæË±°ÔºåÂøΩÁï•‰∫ÜË®òÊÜ∂Êï∏ÊìöÁöÑÂÖ∑È´îÊÉÖÊ≥Å„ÄÇÊàëÂÄëÂèçÈÅé‰æÜÂ∞áË®òÊÜ∂Âª∫Ê®°ÁÇ∫‰∏ÄÁµÑË§áÈõúÂõ†Á¥†ÁöÑÊïàÊáâÔºåÈÄô‰∫õÂõ†Á¥†ÊèèËø∞ÊØèÂÄãÁØÑ‰æã‰∏¶Â∞áÂÖ∂ËàáÊ®°ÂûãÂíåË™ûÊñôÂ∫´ËÅØÁπ´Ëµ∑‰æÜ„ÄÇÁÇ∫‰∫ÜÂª∫Á´ãÂ∞çÈÄô‰∫õÂõ†Á¥†ÁöÑÁõ¥Ë¶∫ÔºåÊàëÂÄëÂ∞áË®òÊÜ∂ÂàÜËß£ÁÇ∫‰∏ÄÂÄãÂàÜÈ°ûÊ≥ïÔºöÈ´òÂ∫¶ÈáçË§áÂ∫èÂàóÁöÑËÉåË™¶„ÄÅÂõ∫ÊúâÂèØÈ†êÊ∏¨Â∫èÂàóÁöÑÈáçÂª∫‰ª•ÂèäÊó¢‰∏çÊòØ‰πü‰∏çÊòØÁöÑÂ∫èÂàóÁöÑÂõûÊÜ∂„ÄÇÊàëÂÄëÈÄöÈÅé‰ΩøÁî®ÂÆÉ‰æÜÊßãÂª∫Ë®òÊÜ∂ÁöÑÈ†êÊ∏¨Ê®°Âûã‰æÜË≠âÊòéÊàëÂÄëÁöÑÂàÜÈ°ûÊ≥ïÁöÑÊúâÁî®ÊÄß„ÄÇÈÄöÈÅéÂàÜÊûê‰æùË≥¥Èóú‰øÇ‰∏¶Ê™¢Êü•È†êÊ∏¨Ê®°ÂûãÁöÑÊ¨äÈáçÔºåÊàëÂÄëÁôºÁèæ‰∏çÂêåÁöÑÂõ†Á¥†ÊúÉÊ†πÊìöÂàÜÈ°ûÈ°ûÂà•‰∏çÂêåÂú∞ÂΩ±ÈüøË®òÊÜ∂ÁöÑÂèØËÉΩÊÄß„ÄÇ

##### **Following Length Constraints in Instructions**
2406.17744v1 by Weizhe Yuan, Ilia Kulikov, Ping Yu, Kyunghyun Cho, Sainbayar Sukhbaatar, Jason Weston, Jing Xu

Aligned instruction following models can better fulfill user requests than
their unaligned counterparts. However, it has been shown that there is a length
bias in evaluation of such models, and that training algorithms tend to exploit
this bias by learning longer responses. In this work we show how to train
models that can be controlled at inference time with instructions containing
desired length constraints. Such models are superior in length instructed
evaluations, outperforming standard instruction following models such as GPT4,
Llama 3 and Mixtral.

ÊëòË¶ÅÔºöÂ∞çÈΩäÊåá‰ª§ÈÅµÂæ™Ê®°ÂûãÊØîÂÖ∂Êú™Â∞çÈΩäÁöÑÊ®°ÂûãËÉΩÊõ¥Â•ΩÂú∞ÊªøË∂≥Áî®Êà∂ÁöÑË¶ÅÊ±Ç„ÄÇÁÑ∂ËÄåÔºåÁ†îÁ©∂Ë°®ÊòéÔºåÊ≠§È°ûÊ®°ÂûãÁöÑË©ï‰º∞Â≠òÂú®Èï∑Â∫¶ÂÅèÂ∑ÆÔºåËÄå‰∏îË®ìÁ∑¥ÊºîÁÆóÊ≥ïÊúÉÂà©Áî®Ê≠§ÂÅèÂ∑ÆÔºåÂ≠∏ÁøíÊõ¥Èï∑ÁöÑÂõûÊáâ„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫Â¶Ç‰ΩïË®ìÁ∑¥Ê®°ÂûãÔºå‰ΩøÂÖ∂ËÉΩÂú®Êé®Ë´ñÊôÇÈñì‰ΩøÁî®ÂåÖÂê´ÊâÄÈúÄÈï∑Â∫¶Á¥ÑÊùüÁöÑÊåá‰ª§ÈÄ≤Ë°åÊéßÂà∂„ÄÇÊ≠§È°ûÊ®°ÂûãÂú®Èï∑Â∫¶ÊåáÂ∞éË©ï‰º∞‰∏≠Ë°®ÁèæÂÑ™Áï∞ÔºåÂÑ™Êñº GPT4„ÄÅLlama 3 Âíå Mixtral Á≠âÊ®ôÊ∫ñÊåá‰ª§ÈÅµÂæ™Ê®°Âûã„ÄÇ

##### **Point-SAM: Promptable 3D Segmentation Model for Point Clouds**
2406.17741v1 by Yuchen Zhou, Jiayuan Gu, Tung Yen Chiang, Fanbo Xiang, Hao Su

The development of 2D foundation models for image segmentation has been
significantly advanced by the Segment Anything Model (SAM). However, achieving
similar success in 3D models remains a challenge due to issues such as
non-unified data formats, lightweight models, and the scarcity of labeled data
with diverse masks. To this end, we propose a 3D promptable segmentation model
(Point-SAM) focusing on point clouds. Our approach utilizes a transformer-based
method, extending SAM to the 3D domain. We leverage part-level and object-level
annotations and introduce a data engine to generate pseudo labels from SAM,
thereby distilling 2D knowledge into our 3D model. Our model outperforms
state-of-the-art models on several indoor and outdoor benchmarks and
demonstrates a variety of applications, such as 3D annotation. Codes and demo
can be found at https://github.com/zyc00/Point-SAM.

ÊëòË¶ÅÔºö2D ÂΩ±ÂÉèÂàÜÂâ≤Âü∫Á§éÊ®°ÂûãÁöÑÁôºÂ±ïÂ∑≤Âõ† Segment Anything Model (SAM) ËÄåÂ§ßÂπÖÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈùûÁµ±‰∏ÄË≥áÊñôÊ†ºÂºè„ÄÅËºïÈáèÁ¥öÊ®°ÂûãÔºå‰ª•ÂèäÊ®ôÁ±§Ë≥áÊñôÁº∫‰πèÂ§öÊ®£ÂåñÈÅÆÁΩ©Á≠âÂïèÈ°åÔºåÂú® 3D Ê®°Âûã‰∏≠ÂèñÂæóÈ°û‰ººÁöÑÊàêÂäü‰ªçÊòØ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÈªûÈõ≤ÁöÑ 3D ÂèØÊèêÁ§∫ÂºèÂàÜÂâ≤Ê®°Âûã (Point-SAM)„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂà©Áî®Âü∫Êñº Transformer ÁöÑÊñπÊ≥ïÔºåÂ∞á SAM Êì¥Â±ïÂà∞ 3D È†òÂüü„ÄÇÊàëÂÄëÂà©Áî®ÈÉ®ÂàÜÁ¥öÂíåÁâ©‰ª∂Á¥öË®ªËß£Ôºå‰∏¶ÂºïÂÖ•‰∏ÄÂÄãË≥áÊñôÂºïÊìéÂæû SAM Áî¢ÁîüÂÅΩÊ®ôÁ±§ÔºåÂæûËÄåÂ∞á 2D Áü•Ë≠òÊèêÁÖâÂà∞ÊàëÂÄëÁöÑ 3D Ê®°Âûã‰∏≠„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â§öÂÄãÂÆ§ÂÖßÂíåÂÆ§Â§ñÂü∫Ê∫ñ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂêÑÁ®ÆÊáâÁî®Ôºå‰æãÂ¶Ç 3D Ë®ªËß£„ÄÇÁ®ãÂºèÁ¢ºÂíåÁ§∫ÁØÑÂèØ‰ª•Âú® https://github.com/zyc00/Point-SAM ‰∏≠ÊâæÂà∞„ÄÇ

##### **Structured Unrestricted-Rank Matrices for Parameter Efficient Fine-tuning**
2406.17740v1 by Arijit Sehanobish, Avinava Dubey, Krzysztof Choromanski, Somnath Basu Roy Chowdhury, Deepali Jain, Vikas Sindhwani, Snigdha Chaturvedi

Recent efforts to scale Transformer models have demonstrated rapid progress
across a wide range of tasks (Wei et al., 2022). However, fine-tuning these
models for downstream tasks is expensive due to their large parameter counts.
Parameter-efficient fine-tuning (PEFT) approaches have emerged as a viable
alternative by allowing us to fine-tune models by updating only a small number
of parameters. In this work, we propose a general framework for parameter
efficient fine-tuning (PEFT), based on structured unrestricted-rank matrices
(SURM) which can serve as a drop-in replacement for popular approaches such as
Adapters and LoRA. Unlike other methods like LoRA, SURMs provides more
flexibility in finding the right balance between compactness and
expressiveness. This is achieved by using low displacement rank matrices
(LDRMs), which hasn't been used in this context before. SURMs remain
competitive with baselines, often providing significant quality improvements
while using a smaller parameter budget. SURMs achieve 5-7% accuracy gains on
various image classification tasks while replacing low-rank matrices in LoRA.
It also results in up to 12x reduction of the number of parameters in adapters
(with virtually no loss in quality) on the GLUE benchmark.

ÊëòË¶ÅÔºöÊúÄËøëÂØπ Transformer Ê®°ÂûãËøõË°åÊâ©Â±ïÁöÑÂ∞ùËØïÂ±ïÁ§∫‰∫ÜÂêÑÁßç‰ªªÂä°ÁöÑÂø´ÈÄüËøõÂ±ïÔºàWei Á≠â‰∫∫Ôºå2022 Âπ¥Ôºâ„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éËøô‰∫õÊ®°ÂûãÁöÑÂèÇÊï∞Êï∞ÈáèÂ∫ûÂ§ßÔºåÂõ†Ê≠§‰∏∫‰∏ãÊ∏∏‰ªªÂä°ËøõË°åÂæÆË∞ÉÈùûÂ∏∏ÊòÇË¥µ„ÄÇÂèÇÊï∞È´òÊïàÂæÆË∞É (PEFT) ÊñπÊ≥ïÂ∑≤ÁªèÊàê‰∏∫‰∏ÄÁßçÂèØË°åÁöÑÊõø‰ª£ÊñπÊ°àÔºåÂÆÉÂÖÅËÆ∏Êàë‰ª¨‰ªÖÈÄöËøáÊõ¥Êñ∞Â∞ëÈáèÂèÇÊï∞Êù•ÂæÆË∞ÉÊ®°Âûã„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÁªìÊûÑÂåñÊó†ÈôêÂà∂Áß©Áü©Èòµ (SURM) ÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞É (PEFT) ÁöÑÈÄöÁî®Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÂèØ‰ª•‰Ωú‰∏∫ÊµÅË°åÊñπÊ≥ïÔºà‰æãÂ¶ÇÈÄÇÈÖçÂô®Âíå LoRAÔºâÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ‰∏é LoRA Á≠âÂÖ∂‰ªñÊñπÊ≥ï‰∏çÂêåÔºåSURM Âú®ÂØªÊâæÁ¥ßÂáëÊÄßÂíåË°®Áé∞Âäõ‰πãÈó¥ÁöÑÈÄÇÂΩìÂπ≥Ë°°ÊñπÈù¢Êèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÁÅµÊ¥ªÊÄß„ÄÇËøôÊòØÈÄöËøá‰ΩøÁî®‰ΩéÁΩÆÊç¢Áß©Áü©Èòµ (LDRM) ÂÆûÁé∞ÁöÑÔºåËøôÂú®‰ª•Ââç‰ªéÊú™Âú®ËØ•‰∏ä‰∏ãÊñá‰∏≠‰ΩøÁî®Ëøá„ÄÇSURM ‰ªçÁÑ∂ÂÖ∑Êúâ‰∏éÂü∫Á∫øÁõ∏ÂΩìÁöÑÁ´û‰∫âÂäõÔºåÈÄöÂ∏∏Âú®‰ΩøÁî®ËæÉÂ∞èÂèÇÊï∞È¢ÑÁÆóÁöÑÂêåÊó∂Êèê‰æõÊòæËëóÁöÑË¥®ÈáèÊîπËøõ„ÄÇSURM Âú®ÂêÑÁßçÂõæÂÉèÂàÜÁ±ª‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫Ü 5-7% ÁöÑÂáÜÁ°ÆÂ∫¶ÊèêÂçáÔºåÂêåÊó∂ÊõøÊç¢‰∫Ü LoRA ‰∏≠ÁöÑ‰ΩéÁß©Áü©Èòµ„ÄÇÂú® GLUE Âü∫ÂáÜÊµãËØï‰∏≠ÔºåÂÆÉËøòÂØºËá¥ÈÄÇÈÖçÂô®‰∏≠ÂèÇÊï∞Êï∞ÈáèÂáèÂ∞ë‰∫Ü 12 ÂÄçÔºàÂá†‰πéÊ≤°ÊúâË¥®ÈáèÊçüÂ§±Ôºâ„ÄÇ

##### **Find Parent then Label Children: A Two-stage Taxonomy Completion Method with Pre-trained Language Model**
2406.17739v1 by Fei Xia, Yixuan Weng, Shizhu He, Kang Liu, Jun Zhao

Taxonomies, which organize domain concepts into hierarchical structures, are
crucial for building knowledge systems and downstream applications. As domain
knowledge evolves, taxonomies need to be continuously updated to include new
concepts. Previous approaches have mainly focused on adding concepts to the
leaf nodes of the existing hierarchical tree, which does not fully utilize the
taxonomy's knowledge and is unable to update the original taxonomy structure
(usually involving non-leaf nodes). In this paper, we propose a two-stage
method called ATTEMPT for taxonomy completion. Our method inserts new concepts
into the correct position by finding a parent node and labeling child nodes.
Specifically, by combining local nodes with prompts to generate natural
sentences, we take advantage of pre-trained language models for
hypernym/hyponymy recognition. Experimental results on two public datasets
(including six domains) show that ATTEMPT performs best on both taxonomy
completion and extension tasks, surpassing existing methods.

ÊëòË¶ÅÔºöÂàÜÈ°ûÊ≥ïÊúÉÂ∞áÈ†òÂüüÊ¶ÇÂøµÁµÑÁπîÊàêÈöéÂ±§ÁµêÊßãÔºåÂ∞çÊñºÂª∫ÊßãÁü•Ë≠òÁ≥ªÁµ±Âíå‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºèËá≥ÈóúÈáçË¶Å„ÄÇÈö®ËëóÈ†òÂüüÁü•Ë≠òÁöÑÊºîÈÄ≤ÔºåÂàÜÈ°ûÊ≥ïÈúÄË¶ÅÊåÅÁ∫åÊõ¥Êñ∞ÊâçËÉΩÁ¥çÂÖ•Êñ∞Ê¶ÇÂøµ„ÄÇÂÖàÂâçÁöÑÂÅöÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÂ∞áÊ¶ÇÂøµÊñ∞Â¢ûËá≥ÁèæÊúâÈöéÂ±§Ê®πÁãÄÁµêÊßãÁöÑËëâÁØÄÈªûÔºåÈÄô‰∏¶Êú™ÂÖÖÂàÜÂà©Áî®ÂàÜÈ°ûÊ≥ïÁöÑÁü•Ë≠òÔºå‰πüÁÑ°Ê≥ïÊõ¥Êñ∞ÂéüÂßãÂàÜÈ°ûÊ≥ïÁµêÊßãÔºàÈÄöÂ∏∏Ê∂âÂèäÈùûËëâÁØÄÈªûÔºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ ATTEMPT ÁöÑÂÖ©ÈöéÊÆµÊñπÊ≥ïÔºåÁî®ÊñºÂàÜÈ°ûÊ≥ïÂÆåÊàê„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅéÂ∞ãÊâæÁà∂ÁØÄÈªûÂíåÊ®ôË®òÂ≠êÁØÄÈªûÔºåÂ∞áÊñ∞Ê¶ÇÂøµÊèíÂÖ•Ê≠£Á¢∫‰ΩçÁΩÆ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈÄèÈÅéÂ∞áÂ±ÄÈÉ®ÁØÄÈªûËàáÊèêÁ§∫ÁµêÂêà‰ª•Áî¢ÁîüËá™ÁÑ∂Âè•Â≠êÔºåÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°Âûã‰æÜÈÄ≤Ë°å‰∏ä‰ΩçË©û/‰∏ã‰ΩçË©ûËæ®Ë≠ò„ÄÇÂú®ÂÖ©ÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜÔºàÂåÖÊã¨ÂÖ≠ÂÄãÈ†òÂüüÔºâ‰∏äÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåATTEMPT Âú®ÂàÜÈ°ûÊ≥ïÂÆåÊàêÂíåÊì¥ÂÖÖ‰ªªÂãô‰∏äÂùáË°®ÁèæÊúÄ‰Ω≥ÔºåË∂ÖË∂ä‰∫ÜÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users**
2406.17737v1 by Elinor Poole-Dayan, Deb Roy, Jad Kabbara

While state-of-the-art Large Language Models (LLMs) have shown impressive
performance on many tasks, there has been extensive research on undesirable
model behavior such as hallucinations and bias. In this work, we investigate
how the quality of LLM responses changes in terms of information accuracy,
truthfulness, and refusals depending on three user traits: English proficiency,
education level, and country of origin. We present extensive experimentation on
three state-of-the-art LLMs and two different datasets targeting truthfulness
and factuality. Our findings suggest that undesirable behaviors in
state-of-the-art LLMs occur disproportionately more for users with lower
English proficiency, of lower education status, and originating from outside
the US, rendering these models unreliable sources of information towards their
most vulnerable users.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúÄÂÖàÈÄ≤ÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë®±Â§ö‰ªªÂãô‰∏äÂ±ïÁèæ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑË°®ÁèæÔºå‰ΩÜÂ∞çÊñºÂπªË¶∫ÂíåÂÅèË¶ãÁ≠â‰∏çËâØÊ®°ÂûãË°åÁÇ∫ÔºåÂ∑≤ÊúâÂª£Ê≥õÁöÑÁ†îÁ©∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é LLM ÂõûÊáâÁöÑÂìÅË≥™Â¶Ç‰ΩïÊ†πÊìö‰∏âÈ†Ö‰ΩøÁî®ËÄÖÁâπË≥™ËÄåÊîπËÆäÔºåÂåÖÊã¨Ë≥áË®äÊ∫ñÁ¢∫ÊÄß„ÄÅÁúüÂØ¶ÊÄßÂíåÊãíÁµïÔºöËã±Ë™ûËÉΩÂäõ„ÄÅÊïôËÇ≤Á®ãÂ∫¶ÂíåÂéüÁ±çÂúã„ÄÇÊàëÂÄëÈáùÂ∞ç‰∏âÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ LLM ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•ÂèäÂÖ©ÂÄãÈáùÂ∞çÁúüÂØ¶ÊÄßÂíå‰∫ãÂØ¶ÊÄßÁöÑ‰∏çÂêåË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰∏≠ÁöÑ‰∏çËâØË°åÁÇ∫Â∞çËã±Ë™ûËÉΩÂäõËºÉ‰Ωé„ÄÅÊïôËÇ≤Á®ãÂ∫¶ËºÉ‰Ωé‰ª•ÂèäÂéüÁ±çÂúã‰∏çÂú®ÁæéÂúãÁöÑ‰ΩøÁî®ËÄÖ‰æÜË™™ÔºåÁôºÁîüÊ©üÁéá‰∏çÊàêÊØî‰æãÂú∞ËºÉÈ´òÔºåÈÄô‰ΩøÂæóÈÄô‰∫õÊ®°ÂûãÂ∞çÂÖ∂ÊúÄÂº±Âã¢ÁöÑ‰ΩøÁî®ËÄÖ‰æÜË™™ÊàêÁÇ∫‰∏çÂèØÈù†ÁöÑË≥áË®ä‰æÜÊ∫ê„ÄÇ

##### **ViANLI: Adversarial Natural Language Inference for Vietnamese**
2406.17716v1 by Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen

The development of Natural Language Processing (NLI) datasets and models has
been inspired by innovations in annotation design. With the rapid development
of machine learning models today, the performance of existing machine learning
models has quickly reached state-of-the-art results on a variety of tasks
related to natural language processing, including natural language inference
tasks. By using a pre-trained model during the annotation process, it is
possible to challenge current NLI models by having humans produce
premise-hypothesis combinations that the machine model cannot correctly
predict. To remain attractive and challenging in the research of natural
language inference for Vietnamese, in this paper, we introduce the adversarial
NLI dataset to the NLP research community with the name ViANLI. This data set
contains more than 10K premise-hypothesis pairs and is built by a continuously
adjusting process to obtain the most out of the patterns generated by the
annotators. ViANLI dataset has brought many difficulties to many current SOTA
models when the accuracy of the most powerful model on the test set only
reached 48.4%. Additionally, the experimental results show that the models
trained on our dataset have significantly improved the results on other
Vietnamese NLI datasets.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLI) Ë≥áÊñôÈõÜÂíåÊ®°ÂûãÁöÑÈñãÁôºÈùàÊÑü‰æÜËá™ÊñºÊ®ôË®ªË®≠Ë®àÁöÑÂâµÊñ∞„ÄÇÈö®ËëóÁï∂‰ªäÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÁèæÊúâÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÂ∑≤ËøÖÈÄüÂú®ÂêÑÁ®ÆËàáËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁõ∏ÈóúÁöÑ‰ªªÂãô‰∏äÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊàêÊûúÔºåÂåÖÊã¨Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ‰ªªÂãô„ÄÇÈÄèÈÅéÂú®Ê®ôË®ªÈÅéÁ®ã‰∏≠‰ΩøÁî®È†êÂÖàË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÂèØ‰ª•ÈÄèÈÅéËÆì‰∫∫ÂÄëÁî¢ÁîüÊ©üÂô®Ê®°ÂûãÁÑ°Ê≥ïÊ≠£Á¢∫È†êÊ∏¨ÁöÑÂâçÊèêÂÅáË®≠ÁµÑÂêà‰æÜÊåëÊà∞Áï∂ÂâçÁöÑ NLI Ê®°Âûã„ÄÇÁÇ∫‰∫ÜÂú®Ë∂äÂçóË™ûËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñÁöÑÁ†îÁ©∂‰∏≠‰øùÊåÅÂê∏ÂºïÂäõÂíåÊåëÊà∞ÊÄßÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂêë NLP Á†îÁ©∂Á§æÁæ§‰ªãÁ¥πÂ∞çÊäóÂºè NLI Ë≥áÊñôÈõÜÔºå‰∏¶Â∞áÂÖ∂ÂëΩÂêçÁÇ∫ ViANLI„ÄÇÊ≠§Ë≥áÊñôÈõÜÂåÖÂê´Ë∂ÖÈÅé 10K ÂÄãÂâçÊèêÂÅáË®≠Â∞çÔºå‰∏¶ÈÄèÈÅéÊåÅÁ∫åË™øÊï¥ÁöÑÊµÅÁ®ãÂª∫ÁΩÆÔºå‰ª•ÂÖÖÂàÜÂà©Áî®Ê®ôË®ªÂì°Áî¢ÁîüÁöÑÊ®°Âºè„ÄÇViANLI Ë≥áÊñôÈõÜÁÇ∫Ë®±Â§öÁèæÊúâÁöÑ SOTA Ê®°ÂûãÂ∏∂‰æÜ‰∫ÜË®±Â§öÂõ∞Èõ£ÔºåÂõ†ÁÇ∫Âú®Ê∏¨Ë©¶ÈõÜ‰∏äÊúÄÂº∑Â§ßÊ®°ÂûãÁöÑÊ∫ñÁ¢∫Â∫¶ÂÉÖÈÅîÂà∞ 48.4%„ÄÇÊ≠§Â§ñÔºåÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÂ∑≤È°ØËëóÊîπÂñÑÂÖ∂‰ªñË∂äÂçóË™û NLI Ë≥áÊñôÈõÜÁöÑÁµêÊûú„ÄÇ

##### **Compositional Models for Estimating Causal Effects**
2406.17714v1 by Purva Pruthi, David Jensen

Many real-world systems can be represented as sets of interacting components.
Examples of such systems include computational systems such as query
processors, natural systems such as cells, and social systems such as families.
Many approaches have been proposed in traditional (associational) machine
learning to model such structured systems, including statistical relational
models and graph neural networks. Despite this prior work, existing approaches
to estimating causal effects typically treat such systems as single units,
represent them with a fixed set of variables and assume a homogeneous
data-generating process. We study a compositional approach for estimating
individual treatment effects (ITE) in structured systems, where each unit is
represented by the composition of multiple heterogeneous components. This
approach uses a modular architecture to model potential outcomes at each
component and aggregates component-level potential outcomes to obtain the
unit-level potential outcomes. We discover novel benefits of the compositional
approach in causal inference - systematic generalization to estimate
counterfactual outcomes of unseen combinations of components and improved
overlap guarantees between treatment and control groups compared to the
classical methods for causal effect estimation. We also introduce a set of
novel environments for empirically evaluating the compositional approach and
demonstrate the effectiveness of our approach using both simulated and
real-world data.

ÊëòË¶ÅÔºöË®±Â§öÁúüÂØ¶‰∏ñÁïåÁöÑÁ≥ªÁµ±ÈÉΩÂèØ‰ª•Ë°®Á§∫ÁÇ∫‰∫íÂãïÁµÑ‰ª∂ÁöÑÈõÜÂêà„ÄÇ
Ê≠§È°ûÁ≥ªÁµ±ÁöÑÁØÑ‰æãÂåÖÊã¨ÈÅãÁÆóÁ≥ªÁµ±Ôºà‰æãÂ¶ÇÊü•Ë©¢ËôïÁêÜÂô®Ôºâ„ÄÅËá™ÁÑ∂Á≥ªÁµ±Ôºà‰æãÂ¶ÇÁ¥∞ËÉûÔºâÂíåÁ§æÊúÉÁ≥ªÁµ±Ôºà‰æãÂ¶ÇÂÆ∂Â∫≠Ôºâ„ÄÇ
ÂÇ≥Áµ±ÔºàÈóúËÅØÂºèÔºâÊ©üÂô®Â≠∏Áøí‰∏≠Â∑≤ÊèêÂá∫Ë®±Â§öÊñπÊ≥ï‰æÜÂª∫Ê®°Ê≠§È°ûÁµêÊßãÂåñÁ≥ªÁµ±ÔºåÂåÖÊã¨Áµ±Ë®àÈóú‰øÇÊ®°ÂûãÂíåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÂÖàÂâçÁöÑÂ∑•‰ΩúÔºåÁèæÊúâÁöÑÂõ†ÊûúÈóú‰øÇ‰º∞Ë®àÊñπÊ≥ïÈÄöÂ∏∏Â∞áÊ≠§È°ûÁ≥ªÁµ±Ë¶ñÁÇ∫ÂñÆ‰∏ÄÂñÆ‰ΩçÔºå‰ΩøÁî®‰∏ÄÁµÑÂõ∫ÂÆöÁöÑËÆäÊï∏Ë°®Á§∫ÂÆÉÂÄëÔºå‰∏¶ÂÅáË®≠Ë≥áÊñôÁî¢ÁîüÈÅéÁ®ãÊòØÂêåË≥™ÁöÑ„ÄÇÊàëÂÄëÁ†îÁ©∂‰∏ÄÁ®ÆÁµÑÂêàÂºèÊñπÊ≥ïÔºåÁî®Êñº‰º∞Ë®àÁµêÊßãÂåñÁ≥ªÁµ±‰∏≠ÁöÑÂÄãÂà•ËôïÁêÜÊïàÊûú (ITE)ÔºåÂÖ∂‰∏≠ÊØèÂÄãÂñÆ‰ΩçÈÉΩÁî±Â§öÂÄãÁï∞Ë≥™ÁµÑ‰ª∂ÁöÑÁµÑÂêàË°®Á§∫„ÄÇÊ≠§ÊñπÊ≥ï‰ΩøÁî®Ê®°ÁµÑÂåñÊû∂Êßã‰æÜÂª∫Ê®°ÊØèÂÄãÁµÑ‰ª∂ÁöÑÊΩõÂú®ÁµêÊûúÔºå‰∏¶ÂΩôÁ∏ΩÁµÑ‰ª∂Â±§Á¥öÁöÑÊΩõÂú®ÁµêÊûú‰ª•Áç≤ÂæóÂñÆ‰ΩçÂ±§Á¥öÁöÑÊΩõÂú®ÁµêÊûú„ÄÇÊàëÂÄëÁôºÁèæÁµÑÂêàÂºèÊñπÊ≥ïÂú®Âõ†ÊûúÊé®Ë´ñ‰∏≠ÂÖ∑ÊúâÊñ∞Á©éÁöÑÂÑ™Èªû - Á≥ªÁµ±ÂåñÊ¶ÇÂåñ‰ª•‰º∞Ë®àÊú™Ë¶ãÁµÑ‰ª∂ÁµÑÂêàÁöÑÂèç‰∫ãÂØ¶ÁµêÊûúÔºå‰ª•ÂèäËàáÂõ†ÊûúÈóú‰øÇ‰º∞Ë®àÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåËôïÁêÜÁµÑÂíåÂ∞çÁÖßÁµÑ‰πãÈñìÁöÑÈáçÁñä‰øùË≠âÂæóÂà∞ÊîπÂñÑ„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∏ÄÁµÑÊñ∞Á©éÁöÑÁí∞Â¢ÉÔºåÁî®ÊñºÁ∂ìÈ©óË©ï‰º∞ÁµÑÂêàÂºèÊñπÊ≥ïÔºå‰∏¶‰ΩøÁî®Ê®°Êì¨ÂíåÁúüÂØ¶‰∏ñÁïåË≥áÊñôË≠âÊòéÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Data curation via joint example selection further accelerates multimodal learning**
2406.17711v1 by Talfan Evans, Nikhil Parthasarathy, Hamza Merzic, Olivier J. Henaff

Data curation is an essential component of large-scale pretraining. In this
work, we demonstrate that jointly selecting batches of data is more effective
for learning than selecting examples independently. Multimodal contrastive
objectives expose the dependencies between data and thus naturally yield
criteria for measuring the joint learnability of a batch. We derive a simple
and tractable algorithm for selecting such batches, which significantly
accelerate training beyond individually-prioritized data points. As performance
improves by selecting from larger super-batches, we also leverage recent
advances in model approximation to reduce the associated computational
overhead. As a result, our approach--multimodal contrastive learning with joint
example selection (JEST)--surpasses state-of-the-art models with up to
13$\times$ fewer iterations and 10$\times$ less computation. Essential to the
performance of JEST is the ability to steer the data selection process towards
the distribution of smaller, well-curated datasets via pretrained reference
models, exposing the level of data curation as a new dimension for neural
scaling laws.

ÊëòË¶ÅÔºöÊï∏ÊìöÁ≠ñÂ±ïÊòØÂ§ßË¶èÊ®°È†êË®ìÁ∑¥ÁöÑÂøÖË¶ÅÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË≠âÊòé‰∫ÜËÅØÂêàÈÅ∏ÊìáÊï∏ÊìöÊâπÊ¨°ÊØîÁç®Á´ãÈÅ∏ÊìáÁØÑ‰æãÊõ¥ÊúâÊïàÂú∞ÈÄ≤Ë°åÂ≠∏Áøí„ÄÇÂ§öÊ®°ÊÖãÂ∞çÊØîÁõÆÊ®ôÊè≠Èú≤‰∫ÜÊï∏Êìö‰πãÈñìÁöÑ‰æùË≥¥ÊÄßÔºåÂõ†Ê≠§Ëá™ÁÑ∂ËÄåÁÑ∂Âú∞Áî¢Áîü‰∫ÜË°°ÈáèÊâπÊ¨°ËÅØÂêàÂèØÂ≠∏ÁøíÊÄßÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÊé®Â∞éÂá∫‰∏ÄÂÄãÁ∞°ÂñÆ‰∏îÊòìÊñºÊáâÁî®ÁöÑÊºîÁÆóÊ≥ï‰æÜÈÅ∏ÊìáÈÄô‰∫õÊâπÊ¨°ÔºåÈÄôÈ°ØËëóÂú∞Âä†ÈÄü‰∫ÜË®ìÁ∑¥ÔºåË∂ÖË∂ä‰∫ÜÂÄãÂà•ÂÑ™ÂÖàÂåñÁöÑÊï∏ÊìöÈªû„ÄÇÈö®ËëóÂæûÊõ¥Â§ßÁöÑË∂ÖÁ¥öÊâπÊ¨°‰∏≠ÈÄ≤Ë°åÈÅ∏ÊìáËÄåÊèêÈ´òÊïàËÉΩÔºåÊàëÂÄë‰πüÂà©Áî®‰∫ÜÊ®°ÂûãËøë‰ºº‰∏≠ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰æÜÊ∏õÂ∞ëÁõ∏ÈóúÁöÑÈÅãÁÆóÈñãÈä∑„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ï‚Äî‚ÄîÂÖ∑ÊúâËÅØÂêàÁØÑ‰æãÈÅ∏Êìá (JEST) ÁöÑÂ§öÊ®°ÊÖãÂ∞çÊØîÂ≠∏Áøí‚Äî‚ÄîË∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÔºåËø≠‰ª£Ê¨°Êï∏Ê∏õÂ∞ë‰∫Ü 13 ÂÄçÔºåÈÅãÁÆóÈáèÊ∏õÂ∞ë‰∫Ü 10 ÂÄç„ÄÇÂ∞çÊñº JEST ÁöÑÊïàËÉΩËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåËÉΩÂ§†ÈÄèÈÅéÈ†êË®ìÁ∑¥ÁöÑÂèÉËÄÉÊ®°ÂûãÂ∞áÊï∏ÊìöÈÅ∏ÊìáÈÅéÁ®ãÂºïÂ∞éÂà∞ËºÉÂ∞è„ÄÅÁ≠ñÂ±ïËâØÂ•ΩÁöÑË≥áÊñôÈõÜÁöÑÂàÜÂ∏ÉÔºåÂ∞áÊï∏ÊìöÁ≠ñÂ±ïÁöÑÂ±§Á¥öÊè≠Èú≤ÁÇ∫Á•ûÁ∂ìÊì¥ÂÖÖÂÆöÂæãÁöÑÊñ∞Èù¢Âêë„ÄÇ

##### **FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model**
2406.17706v1 by Feijie Wu, Zitao Li, Yaliang Li, Bolin Ding, Jing Gao

Large language models (LLMs) show amazing performance on many domain-specific
tasks after fine-tuning with some appropriate data. However, many
domain-specific data are privately distributed across multiple owners. Thus,
this dilemma raises the interest in how to perform LLM fine-tuning in federated
learning (FL). However, confronted with limited computation and communication
capacities, FL clients struggle to fine-tune an LLM effectively. To this end,
we introduce FedBiOT, a resource-efficient LLM fine-tuning approach to FL.
Specifically, our method involves the server generating a compressed LLM and
aligning its performance with the full model. Subsequently, the clients
fine-tune a lightweight yet important part of the compressed model, referred to
as an adapter. Notice that as the server has no access to the private data
owned by the clients, the data used for alignment by the server has a different
distribution from the one used for fine-tuning by clients. We formulate the
problem into a bi-level optimization problem to minimize the negative effect of
data discrepancy and derive the updating rules for the server and clients. We
conduct extensive experiments on LLaMA-2, empirically showing that the adapter
has exceptional performance when reintegrated into the global LLM. The results
also indicate that the proposed FedBiOT significantly reduces resource
consumption compared to existing benchmarks, all while achieving comparable
performance levels.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂæÆË™ø‰∏Ä‰∫õÈÅ©Áï∂Êï∏ÊìöÂæåÔºåÂú®Ë®±Â§öÁâπÂÆöÈ†òÂüü‰ªªÂãô‰∏äË°®ÁèæÂá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåË®±Â§öÁâπÂÆöÈ†òÂüüÊï∏ÊìöÂú®Â§öÂÄãÊâÄÊúâËÄÖ‰πãÈñìÁßÅ‰∏ãÂàÜÁôº„ÄÇÂõ†Ê≠§ÔºåÈÄôÂÄãÂÖ©Èõ£Â±ÄÈù¢ÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞çÂ¶Ç‰ΩïÂú®ËÅØÂêàÂ≠∏Áøí (FL) ‰∏≠Âü∑Ë°å LLM ÂæÆË™øÁöÑËààË∂£„ÄÇÁÑ∂ËÄåÔºåÈù¢Â∞çÊúâÈôêÁöÑË®àÁÆóÂíåÈÄö‰ø°ËÉΩÂäõÔºåFL ÂÆ¢Êà∂Á´ØÈõ£‰ª•ÊúâÊïàÂú∞ÂæÆË™ø LLM„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FedBiOTÔºå‰∏ÄÁ®ÆÈÅ©Áî®Êñº FL ÁöÑË≥áÊ∫êÈ´òÊïà LLM ÂæÆË™øÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊ∂âÂèä‰º∫ÊúçÂô®ÁîüÊàêÂ£ìÁ∏ÆÁöÑ LLMÔºå‰∏¶‰ΩøÂÖ∂ÊÄßËÉΩËàáÂÆåÊï¥Ê®°Âûã‰øùÊåÅ‰∏ÄËá¥„ÄÇÈö®ÂæåÔºåÂÆ¢Êà∂Á´ØÂæÆË™øÂ£ìÁ∏ÆÊ®°Âûã‰∏≠ËºïÈáè‰ΩÜÈáçË¶ÅÁöÑÈÉ®ÂàÜÔºåÁ®±ÁÇ∫ÈÅ©ÈÖçÂô®„ÄÇË´ãÊ≥®ÊÑèÔºåÁî±Êñº‰º∫ÊúçÂô®ÁÑ°Ê≥ïË®™ÂïèÂÆ¢Êà∂Á´ØÊìÅÊúâÁöÑÁßÅ‰∫∫Êï∏ÊìöÔºåÂõ†Ê≠§‰º∫ÊúçÂô®Áî®ÊñºÂ∞çÈΩäÁöÑÊï∏ÊìöËàáÂÆ¢Êà∂Á´ØÁî®ÊñºÂæÆË™øÁöÑÊï∏ÊìöÂàÜ‰Ωà‰∏çÂêå„ÄÇÊàëÂÄëÂ∞áÂïèÈ°åË°®Ëø∞ÁÇ∫‰∏ÄÂÄãÈõôÂ±§ÂÑ™ÂåñÂïèÈ°åÔºå‰ª•ÊúÄÂ∞èÂåñÊï∏ÊìöÂ∑ÆÁï∞ÁöÑË≤†Èù¢ÂΩ±ÈüøÔºå‰∏¶Êé®Â∞éÂá∫‰º∫ÊúçÂô®ÂíåÂÆ¢Êà∂Á´ØÁöÑÊõ¥Êñ∞Ë¶èÂâá„ÄÇÊàëÂÄëÂ∞ç LLaMA-2 ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂØ¶Ë≠âË°®ÊòéÔºåÂ∞áÈÅ©ÈÖçÂô®ÈáçÊñ∞Êï¥ÂêàÂà∞ÂÖ®Â±Ä LLM ‰∏≠ÊôÇÔºåÂÖ∂ÊÄßËÉΩÁï∞Â∏∏Âá∫Ëâ≤„ÄÇÁµêÊûúÈÇÑË°®ÊòéÔºåËàáÁèæÊúâÂü∫Ê∫ñÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑ FedBiOT Â§ßÂ§ßÈôç‰Ωé‰∫ÜË≥áÊ∫êÊ∂àËÄóÔºåÂêåÊôÇÈÅîÂà∞‰∫ÜÁõ∏Áï∂ÁöÑÊÄßËÉΩÊ∞¥Âπ≥„ÄÇ

##### **HGTDP-DTA: Hybrid Graph-Transformer with Dynamic Prompt for Drug-Target Binding Affinity Prediction**
2406.17697v1 by Xi Xiao, Wentao Wang, Jiacheng Xie, Lijing Zhu, Gaofei Chen, Zhengji Li, Tianyang Wang, Min Xu

Drug target binding affinity (DTA) is a key criterion for drug screening.
Existing experimental methods are time-consuming and rely on limited structural
and domain information. While learning-based methods can model sequence and
structural information, they struggle to integrate contextual data and often
lack comprehensive modeling of drug-target interactions. In this study, we
propose a novel DTA prediction method, termed HGTDP-DTA, which utilizes dynamic
prompts within a hybrid Graph-Transformer framework. Our method generates
context-specific prompts for each drug-target pair, enhancing the model's
ability to capture unique interactions. The introduction of prompt tuning
further optimizes the prediction process by filtering out irrelevant noise and
emphasizing task-relevant information, dynamically adjusting the input features
of the molecular graph. The proposed hybrid Graph-Transformer architecture
combines structural information from Graph Convolutional Networks (GCNs) with
sequence information captured by Transformers, facilitating the interaction
between global and local information. Additionally, we adopted the multi-view
feature fusion method to project molecular graph views and affinity subgraph
views into a common feature space, effectively combining structural and
contextual information. Experiments on two widely used public datasets, Davis
and KIBA, show that HGTDP-DTA outperforms state-of-the-art DTA prediction
methods in both prediction performance and generalization ability.

ÊëòË¶ÅÔºöËó•Áâ©Ê®ôÈù∂ÁµêÂêàË¶™ÂíåÂäõ (DTA) ÊòØËó•Áâ©ÁØ©ÈÅ∏ÁöÑ‰∏ÄÂÄãÈóúÈçµÊ®ôÊ∫ñ„ÄÇ
ÁèæÊúâÁöÑÂØ¶È©óÊñπÊ≥ïËÄóÊôÇÔºå‰∏î‰æùË≥¥ÊúâÈôêÁöÑÁµêÊßãÂíåÁµêÊßãÂüüË≥áË®ä„ÄÇÈõñÁÑ∂Âü∫ÊñºÂ≠∏ÁøíÁöÑÊñπÊ≥ïÂèØ‰ª•Âª∫Ê®°Â∫èÂàóÂíåÁµêÊßãË≥áË®äÔºå‰ΩÜÂÆÉÂÄëÈõ£‰ª•Êï¥ÂêàËÑàÁµ°Ë≥áÊñôÔºå‰∏îÂæÄÂæÄÁº∫‰πèÂ∞çËó•Áâ©Ê®ôÈù∂‰∫§‰∫í‰ΩúÁî®ÁöÑÂÖ®Èù¢Âª∫Ê®°„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑ DTA È†êÊ∏¨ÊñπÊ≥ïÔºåÁ®±ÁÇ∫ HGTDP-DTAÔºåÂÆÉÂú®Ê∑∑ÂêàÂúñÂΩ¢ËΩâÊèõÂô®Ê°ÜÊû∂‰∏≠‰ΩøÁî®ÂãïÊÖãÊèêÁ§∫„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÁÇ∫ÊØèÂ∞çËó•Áâ©Ê®ôÈù∂Áî¢ÁîüÁâπÂÆöÊñºËÑàÁµ°ÁöÑÊèêÁ§∫ÔºåÂ¢ûÂº∑Ê®°ÂûãÊçïÊçâÁç®Áâπ‰∫§‰∫í‰ΩúÁî®ÁöÑËÉΩÂäõ„ÄÇÊèêÁ§∫Ë™øÊï¥ÁöÑÂºïÂÖ•ÈÄ≤‰∏ÄÊ≠•ÊúÄ‰Ω≥ÂåñÈ†êÊ∏¨ÊµÅÁ®ãÔºåÈÄèÈÅéÊøæÈô§ÁÑ°ÈóúÈõúË®äÂíåÂº∑Ë™øËàá‰ªªÂãôÁõ∏ÈóúÁöÑË≥áË®äÔºåÂãïÊÖãË™øÊï¥ÂàÜÂ≠êÂúñÂΩ¢ÁöÑËº∏ÂÖ•ÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ∑∑ÂêàÂúñÂΩ¢ËΩâÊèõÂô®Êû∂ÊßãÁµêÂêà‰∫Ü‰æÜËá™ÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) ÁöÑÁµêÊßãË≥áË®äÂíåËΩâÊèõÂô®ÊçïÊçâÁöÑÂ∫èÂàóË≥áË®äÔºå‰øÉÈÄ≤‰∫ÜÂÖ®ÂüüÂíåÂ±ÄÈÉ®Ë≥áË®ä‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî®Â§öË¶ñÂúñÁâπÂæµËûçÂêàÊñπÊ≥ïÔºåÂ∞áÂàÜÂ≠êÂúñÂΩ¢Ë¶ñÂúñÂíåË¶™ÂíåÂäõÂ≠êÂúñË¶ñÂúñÊäïÂΩ±Âà∞‰∏ÄÂÄãÂÖ±ÂêåÁöÑÁâπÂæµÁ©∫ÈñìÔºåÊúâÊïàÂú∞ÁµêÂêà‰∫ÜÁµêÊßãÂíåËÑàÁµ°Ë≥áË®ä„ÄÇÂú®ÂÖ©ÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ Davis Âíå KIBA ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåHGTDP-DTA Âú®È†êÊ∏¨ÊïàËÉΩÂíåÊ≥õÂåñËÉΩÂäõÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ DTA È†êÊ∏¨ÊñπÊ≥ï„ÄÇ

##### **From Distributional to Overton Pluralism: Investigating Large Language Model Alignment**
2406.17692v1 by Thom Lake, Eunsol Choi, Greg Durrett

The alignment process changes several properties of a large language model's
(LLM's) output distribution. We analyze two aspects of post-alignment
distributional shift of LLM responses. First, we re-examine previously reported
reductions in response diversity post-alignment. Our analysis suggests that an
apparent drop in the diversity of responses is largely explained by quality
control and information aggregation. Alignment suppresses irrelevant and
unhelpful content while shifting the output distribution toward longer
responses that cover information spanning several responses from the base LLM,
essentially presenting diverse information in a single response. Finding little
evidence that alignment suppresses useful information, it is natural to ask the
opposite question: do aligned models surface information that cannot be
recovered from base models? Our second investigation shows this is not the case
and the behavior of aligned models is recoverable from base models without
fine-tuning. A combination of in-context examples and lower-resolution semantic
hints about response content can elicit responses from base LLMs that are as
similar to alignment-tuned LLM responses as alignment-tuned LLM responses are
to each other. Taken together, these results indicate that current alignment
techniques capture but do not extend the useful subset of assistant-like base
LLM behavior, providing further evidence for the Superficial Alignment
Hypothesis. They also show that in-context alignment can go surprisingly far as
a strategy for imitating aligned LLMs without fine-tuning. Our code and data is
available at https://github.com/thomlake/investigating-alignment.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËº∏Âá∫ÂàÜ‰ΩàÊúÉÂõ†ÁÇ∫Â∞çÈΩäÁ®ãÂ∫èËÄåÁî¢ÁîüËÆäÂãï„ÄÇÊàëÂÄëÂàÜÊûê LLM ÂõûÊáâÂú®Â∞çÈΩäÂæåÂàÜ‰ΩàËΩâÁßªÁöÑÂÖ©ÂÄãÈù¢Âêë„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÈáçÊñ∞Ê™¢Ë¶ñÂÖàÂâçÂ†±ÂëäÁöÑÂõûÊáâÂ§öÊ®£ÊÄßÂú®Â∞çÈΩäÂæå‰∏ãÈôç„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂõûÊáâÂ§öÊ®£ÊÄßÊòéÈ°Ø‰∏ãÈôçÔºåÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèØÊ≠∏Âõ†ÊñºÂìÅË≥™ÊéßÁÆ°ÂíåË≥áË®äÂΩôÊï¥„ÄÇÂ∞çÈΩäÊúÉÊäëÂà∂‰∏çÁõ∏Èóú‰∏îÁÑ°ÁõäÁöÑÂÖßÂÆπÔºåÂêåÊôÇÂ∞áËº∏Âá∫ÂàÜ‰ΩàËΩâÁßªËá≥ËºÉÈï∑ÁöÑÂõûÊáâÔºåÊ∂µËìã‰∫Ü LLM Âü∫Á§éÊ®°Âûã‰∏≠Â§öÂÄãÂõûÊáâÁöÑË≥áË®äÔºåÊú¨Ë≥™‰∏äÊòØÂú®ÂñÆ‰∏ÄÂõûÊáâ‰∏≠ÂëàÁèæÂ§öÊ®£ÂåñÁöÑË≥áË®ä„ÄÇÁî±ÊñºÂπæ‰πéÊ≤íÊúâË≠âÊìöÈ°ØÁ§∫Â∞çÈΩäÊúÉÊäëÂà∂ÊúâÁî®ÁöÑË≥áË®äÔºåÂõ†Ê≠§Ëá™ÁÑ∂ÊúÉÂïèÁõ∏ÂèçÁöÑÂïèÈ°åÔºöÂ∞çÈΩäÁöÑÊ®°ÂûãÊòØÂê¶ÊúÉÊµÆÁèæÂü∫Á§éÊ®°ÂûãÁÑ°Ê≥ïÂæ©ÂéüÁöÑË≥áË®äÔºüÊàëÂÄëÁöÑÁ¨¨‰∫åÊ¨°Ë™øÊü•È°ØÁ§∫‰∏¶ÈùûÂ¶ÇÊ≠§ÔºåËÄå‰∏îÂ∞çÈΩäÊ®°ÂûãÁöÑË°åÁÇ∫ÂèØ‰ª•ÂæûÂü∫Á§éÊ®°Âûã‰∏≠Âæ©ÂéüÔºåËÄåÁÑ°ÈúÄÂæÆË™ø„ÄÇÁµêÂêàÊÉÖÂ¢É‰∏≠ÁöÑÁØÑ‰æãÂíåÈóúÊñºÂõûÊáâÂÖßÂÆπÁöÑËºÉ‰ΩéËß£ÊûêÂ∫¶Ë™ûÊÑèÊèêÁ§∫ÔºåÂèØ‰ª•ÂºïÁôºÂü∫Á§é LLM ÁöÑÂõûÊáâÔºåÈÄô‰∫õÂõûÊáâËàáÂ∞çÈΩäÂæÆË™øÁöÑ LLM ÂõûÊáâ‰∏ÄÊ®£È°û‰ººÔºåËÄåÂ∞çÈΩäÂæÆË™øÁöÑ LLM ÂõûÊáâÂΩºÊ≠§‰πãÈñì‰πü‰∏ÄÊ®£È°û‰ºº„ÄÇÁ∂úÂêà‰æÜÁúãÔºåÈÄô‰∫õÁµêÊûúÈ°ØÁ§∫ÁõÆÂâçÁöÑÂ∞çÈΩäÊäÄË°ìÊçïÊçâ‰∫ÜÈ°ûÂä©ÁêÜÂü∫Á§é LLM Ë°åÁÇ∫ÁöÑÊúâÁî®Â≠êÈõÜÔºå‰ΩÜ‰∏¶Êú™Âª∂‰º∏Ë©≤Â≠êÈõÜÔºåÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜË°®Èù¢Â∞çÈΩäÂÅáË™™„ÄÇÂÆÉÂÄë‰πüÈ°ØÁ§∫ÊÉÖÂ¢É‰∏≠Â∞çÈΩäÂèØ‰ª•ÊàêÁÇ∫‰∏ÄÁ®Æ‰ª§‰∫∫È©öË®ùÁöÑÁ≠ñÁï•ÔºåÁî®ÊñºÊ®°‰ªøÂ∞çÈΩäÁöÑ LLMÔºåËÄåÁÑ°ÈúÄÂæÆË™ø„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÊñº https://github.com/thomlake/investigating-alignment ÂèñÂæó„ÄÇ

##### **Unified Auto-Encoding with Masked Diffusion**
2406.17688v1 by Philippe Hansen-Estruch, Sriram Vishwanath, Amy Zhang, Manan Tomar

At the core of both successful generative and self-supervised representation
learning models there is a reconstruction objective that incorporates some form
of image corruption. Diffusion models implement this approach through a
scheduled Gaussian corruption process, while masked auto-encoder models do so
by masking patches of the image. Despite their different approaches, the
underlying similarity in their methodologies suggests a promising avenue for an
auto-encoder capable of both de-noising tasks. We propose a unified
self-supervised objective, dubbed Unified Masked Diffusion (UMD), that combines
patch-based and noise-based corruption techniques within a single auto-encoding
framework. Specifically, UMD modifies the diffusion transformer (DiT) training
process by introducing an additional noise-free, high masking representation
step in the diffusion noising schedule, and utilizes a mixed masked and noised
image for subsequent timesteps. By integrating features useful for diffusion
modeling and for predicting masked patch tokens, UMD achieves strong
performance in downstream generative and representation learning tasks,
including linear probing and class-conditional generation. This is achieved
without the need for heavy data augmentations, multiple views, or additional
encoders. Furthermore, UMD improves over the computational efficiency of prior
diffusion based methods in total training time. We release our code at
https://github.com/philippe-eecs/small-vision.

ÊëòË¶ÅÔºöÂú®ÊàêÂäüÁöÑÁîüÊàêÂºèÂíåËá™ÁõëÁù£Ë°®Á§∫Â≠¶‰π†Ê®°ÂûãÁöÑÊ†∏ÂøÉÔºåÂ≠òÂú®‰∏Ä‰∏™ÈáçÂª∫ÁõÆÊ†áÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊüêÁßçÂΩ¢ÂºèÁöÑÂõæÂÉèÊçüÂùè„ÄÇÊâ©Êï£Ê®°ÂûãÈÄöËøáÈ¢ÑÂÆöÁöÑÈ´òÊñØÊçüÂùèËøáÁ®ãÂÆûÁé∞Ê≠§ÊñπÊ≥ïÔºåËÄåÊé©Á†ÅËá™Âä®ÁºñÁ†ÅÂô®Ê®°ÂûãÈÄöËøáÊé©ÁõñÂõæÂÉèÁöÑÂùóÊù•ÂÆûÁé∞Ê≠§ÊñπÊ≥ï„ÄÇÂ∞ΩÁÆ°ÂÆÉ‰ª¨ÁöÑÊñπÊ≥ï‰∏çÂêåÔºå‰ΩÜÂÆÉ‰ª¨ÁöÑÊñπÊ≥ïËÆ∫‰∏≠ÁöÑÊΩúÂú®Áõ∏‰ººÊÄßË°®Êòé‰∫Ü‰∏ÄÁßçÊúâÂ∏åÊúõÁöÑÈÄîÂæÑÔºåÂç≥ËÉΩÂ§üÊâßË°åÂéªÂô™‰ªªÂä°ÁöÑËá™Âä®ÁºñÁ†ÅÂô®„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑËá™ÁõëÁù£ÁõÆÊ†áÔºåÁß∞‰∏∫Áªü‰∏ÄÊé©Á†ÅÊâ©Êï£ (UMD)ÔºåÂÆÉÂú®Âçï‰∏™Ëá™Âä®ÁºñÁ†ÅÊ°ÜÊû∂ÂÜÖÁªìÂêà‰∫ÜÂü∫‰∫éÂùóÂíåÂü∫‰∫éÂô™Â£∞ÁöÑÊçüÂùèÊäÄÊúØ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåUMD ÈÄöËøáÂú®Êâ©Êï£Âô™Â£∞ËÆ°Âàí‰∏≠ÂºïÂÖ•È¢ùÂ§ñÁöÑÊó†Âô™Â£∞„ÄÅÈ´òÊé©Á†ÅË°®Á§∫Ê≠•È™§Êù•‰øÆÊîπÊâ©Êï£ÂèòÊç¢Âô® (DiT) ËÆ≠ÁªÉËøáÁ®ãÔºåÂπ∂Âà©Áî®Ê∑∑ÂêàÊé©Á†ÅÂíåÂô™Â£∞ÂõæÂÉèËøõË°åÂêéÁª≠Êó∂Èó¥Ê≠•Èïø„ÄÇÈÄöËøáÊï¥ÂêàÂØπÊâ©Êï£Âª∫Ê®°ÂíåÈ¢ÑÊµãÊé©Á†ÅÂùóÊ†áËÆ∞ÊúâÁî®ÁöÑÁâπÂæÅÔºåUMD Âú®‰∏ãÊ∏∏ÁîüÊàêÂºèÂíåË°®Á§∫Â≠¶‰π†‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÂº∫Â§ßÁöÑÊÄßËÉΩÔºåÂåÖÊã¨Á∫øÊÄßÊé¢ÊµãÂíåÁ±ªÊù°‰ª∂ÁîüÊàê„ÄÇËøôÊòØÂú®‰∏çÈúÄË¶ÅÂ§ßÈáèÊï∞ÊçÆÂ¢ûÂº∫„ÄÅÂ§ö‰∏™ËßÜÂõæÊàñÂÖ∂‰ªñÁºñÁ†ÅÂô®ÁöÑÊÉÖÂÜµ‰∏ãÂÆûÁé∞ÁöÑ„ÄÇÊ≠§Â§ñÔºåUMD ÊèêÈ´ò‰∫ÜÂü∫‰∫éÊâ©Êï£ÁöÑÂÖàÂâçÊñπÊ≥ïÂú®ÊÄªËÆ≠ÁªÉÊó∂Èó¥ÂÜÖÁöÑËÆ°ÁÆóÊïàÁéá„ÄÇÊàë‰ª¨Âú® https://github.com/philippe-eecs/small-vision ‰∏äÂèëÂ∏É‰∫ÜÊàë‰ª¨ÁöÑ‰ª£Á†Å„ÄÇ

##### **VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation**
2406.17681v2 by Kun Qian, Shunji Wan, Claudia Tang, Youzhi Wang, Xuanming Zhang, Maximillian Chen, Zhou Yu

As large language models achieve impressive scores on traditional benchmarks,
an increasing number of researchers are becoming concerned about benchmark data
leakage during pre-training, commonly known as the data contamination problem.
To ensure fair evaluation, recent benchmarks release only the training and
validation sets, keeping the test set labels closed-source. They require anyone
wishing to evaluate his language model to submit the model's predictions for
centralized processing and then publish the model's result on their
leaderboard. However, this submission process is inefficient and prevents
effective error analysis. To address this issue, we propose to variabilize
benchmarks and evaluate language models dynamically. Specifically, we extract
variables from each test case and define a value range for each variable. For
each evaluation, we sample new values from these value ranges to create unique
test cases, thus ensuring a fresh evaluation each time. We applied this
variable perturbation method to four datasets: GSM8K, ARC, CommonsenseQA, and
TruthfulQA, which cover mathematical generation and multiple-choice tasks. Our
experimental results demonstrate that this approach provides a more accurate
assessment of the true capabilities of language models, effectively mitigating
the contamination problem.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÂÇ≥Áµ±Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠Áç≤ÂæóÈ©ö‰∫∫ÁöÑÂàÜÊï∏Ôºå
Ë∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂‰∫∫Âì°ÈñãÂßãÊìîÂøÉÈ†êË®ìÁ∑¥ÊúüÈñìÁöÑÂü∫Ê∫ñË≥áÊñô
Â§ñÊ¥©ÔºåÈÄôÈÄöÂ∏∏Á®±ÁÇ∫Ë≥áÊñôÊ±°ÊüìÂïèÈ°å„ÄÇ
ÁÇ∫‰∫ÜÁ¢∫‰øùÂÖ¨Âπ≥Ë©ïÈáèÔºåÊúÄËøëÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶Âè™ÈáãÂá∫Ë®ìÁ∑¥Âíå
È©óË≠âÈõÜÔºå‰∏¶Â∞áÊ∏¨Ë©¶ÈõÜÊ®ôÁ±§‰øùÊåÅÁÇ∫Â∞ÅÈñâÂéüÂßãÁ¢º„ÄÇ‰ªñÂÄëË¶ÅÊ±Ç‰ªª‰Ωï
Â∏åÊúõË©ï‰º∞ÂÖ∂Ë™ûË®ÄÊ®°ÂûãÁöÑ‰∫∫Êèê‰∫§Ê®°ÂûãÁöÑÈ†êÊ∏¨Ôºå‰ª•ÈÄ≤Ë°å
ÈõÜ‰∏≠ËôïÁêÜÔºåÁÑ∂ÂæåÂú®‰ªñÂÄëÁöÑÊéíË°åÊ¶ú‰∏äÂÖ¨Â∏ÉÊ®°ÂûãÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÈÄôÂÄãÊèê‰∫§ÈÅéÁ®ãÊïàÁéá‰Ωé‰∏ãÔºå‰∏îÁÑ°Ê≥ïÈÄ≤Ë°å
ÊúâÊïàÁöÑÈåØË™§ÂàÜÊûê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂª∫Ë≠∞Â∞á
Âü∫Ê∫ñÊ∏¨Ë©¶ËÆäÊï∏ÂåñÔºå‰∏¶ÂãïÊÖãË©ï‰º∞Ë™ûË®ÄÊ®°Âûã„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÊàëÂÄëÂæûÊØèÂÄãÊ∏¨Ë©¶Ê°à‰æã‰∏≠Êì∑Âèñ
ËÆäÊï∏Ôºå‰∏¶ÁÇ∫ÊØèÂÄãËÆäÊï∏ÂÆöÁæ©‰∏ÄÂÄãÂÄºÂüü„ÄÇÂ∞çÊñº
ÊØèÂÄãË©ï‰º∞ÔºåÊàëÂÄëÂæûÈÄô‰∫õÂÄºÂüü‰∏≠ÊäΩÊ®£Êñ∞ÁöÑÂÄºÔºå‰ª•Âª∫Á´ãÁç®ÁâπÁöÑ
Ê∏¨Ë©¶Ê°à‰æãÔºåÂæûËÄåÊØèÊ¨°ÈÉΩËÉΩÁ¢∫‰øùÈÄ≤Ë°åÊñ∞ÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÂ∞áÈÄôÂÄã
ËÆäÊï∏ÊìæÂãïÊñπÊ≥ïÊáâÁî®ÊñºÂõõÂÄãË≥áÊñôÈõÜÔºöGSM8K„ÄÅARC„ÄÅCommonsenseQA Âíå
TruthfulQAÔºåÈÄô‰∫õË≥áÊñôÈõÜÊ∂µËìãÊï∏Â≠∏ÁîüÊàêÂíåÂ§öÈÅ∏È°å‰ªªÂãô„ÄÇÊàëÂÄëÁöÑ
ÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÈÄôÁ®ÆÊñπÊ≥ïÂèØ‰ª•Êõ¥Ê∫ñÁ¢∫Âú∞Ë©ï‰º∞Ë™ûË®ÄÊ®°ÂûãÁöÑÁúüÊ≠£ËÉΩÂäõÔºåÊúâÊïàÂú∞Ê∏õËºï
Ê±°ÊüìÂïèÈ°å„ÄÇ

##### **Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models**
2406.17675v1 by Yuan Li, Yue Huang, Hongyi Wang, Xiangliang Zhang, James Zou, Lichao Sun

Large Language Models (LLMs) have demonstrated exceptional task-solving
capabilities, increasingly adopting roles akin to human-like assistants. The
broader integration of LLMs into society has sparked interest in whether they
manifest psychological attributes, and whether these attributes are
stable-inquiries that could deepen the understanding of their behaviors.
Inspired by psychometrics, this paper presents a framework for investigating
psychology in LLMs, including psychological dimension identification,
assessment dataset curation, and assessment with results validation. Following
this framework, we introduce a comprehensive psychometrics benchmark for LLMs
that covers six psychological dimensions: personality, values, emotion, theory
of mind, motivation, and intelligence. This benchmark includes thirteen
datasets featuring diverse scenarios and item types. Our findings indicate that
LLMs manifest a broad spectrum of psychological attributes. We also uncover
discrepancies between LLMs' self-reported traits and their behaviors in
real-world scenarios. This paper demonstrates a thorough psychometric
assessment of LLMs, providing insights into reliable evaluation and potential
applications in AI and social sciences.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫ÂçìË∂äÁöÑ‰ªªÂãôËß£Ê±∫ËÉΩÂäõÔºå‰∏¶ÈÄêÊº∏ÊâÆÊºîÈ°û‰ºº‰∫∫È°ûÂä©ÁêÜÁöÑËßíËâ≤„ÄÇ LLM Êõ¥Âª£Ê≥õÂú∞Êï¥ÂêàÂà∞Á§æÊúÉ‰∏≠ÔºåÂ∑≤ÂºïËµ∑‰∫∫ÂÄëÂ∞çÂÖ∂ÊòØÂê¶Ë°®ÁèæÂá∫ÂøÉÁêÜÂ±¨ÊÄßÔºå‰ª•ÂèäÈÄô‰∫õÂ±¨ÊÄßÊòØÂê¶Á©©ÂÆöÔºåÈÄô‰∫õÊé¢Ë®éÂèØËÉΩÊúâÂä©ÊñºÊ∑±ÂÖ•‰∫ÜËß£ÂÖ∂Ë°åÁÇ∫„ÄÇÂèóÂà∞ÂøÉÁêÜÊ∏¨ÈáèÁöÑÂïüÁôºÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁî®ÊñºË™øÊü• LLM ÂøÉÁêÜÂ≠∏ÁöÑÊû∂ÊßãÔºåÂåÖÊã¨ÂøÉÁêÜÁ∂≠Â∫¶Ë≠òÂà•„ÄÅË©ï‰º∞Ë≥áÊñôÈõÜÁ≠ñÂ±ïÔºå‰ª•ÂèäÈÄèÈÅéÈ©óË≠âÁµêÊûúÈÄ≤Ë°åË©ï‰º∞„ÄÇÈÅµÂæ™Ê≠§Êû∂ÊßãÔºåÊàëÂÄëÁÇ∫ LLM ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂøÉÁêÜÊ∏¨ÈáèÂü∫Ê∫ñÔºåÊ∂µËìãÂÖ≠ÂÄãÂøÉÁêÜÁ∂≠Â∫¶Ôºö‰∫∫Ê†º„ÄÅÂÉπÂÄºËßÄ„ÄÅÊÉÖÁ∑í„ÄÅÂøÉÊô∫ÁêÜË´ñ„ÄÅÂãïÊ©üÂíåÊô∫Âäõ„ÄÇÊ≠§Âü∫Ê∫ñÂåÖÂê´ 13 ÂÄãË≥áÊñôÈõÜÔºåÊ∂µËìãÂêÑÁ®ÆÊÉÖÂ¢ÉÂíåÈ†ÖÁõÆÈ°ûÂûã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåLLM Ë°®ÁèæÂá∫Âª£Ê≥õÁöÑÂøÉÁêÜÂ±¨ÊÄß„ÄÇÊàëÂÄëÈÇÑÁôºÁèæ LLM Ëá™ÊàëÂ†±ÂëäÁöÑÁâπË≥™ËàáÂÖ∂Âú®ÁúüÂØ¶‰∏ñÁïåÊÉÖÂ¢É‰∏≠ÁöÑË°åÁÇ∫‰πãÈñìÂ≠òÂú®Â∑ÆÁï∞„ÄÇÊú¨ÊñáÂ±ïÁ§∫‰∫ÜÂ∞ç LLM ÈÄ≤Ë°åÂæπÂ∫ïÁöÑÂøÉÁêÜÊ∏¨ÈáèË©ï‰º∞ÔºåÊèê‰æõ‰∫ÜÂ∞ç AI ÂíåÁ§æÊúÉÁßëÂ≠∏‰∏≠ÂèØÈù†Ë©ï‰º∞ÂíåÊΩõÂú®ÊáâÁî®Ë¶ãËß£„ÄÇ

##### **This Paper Had the Smartest Reviewers -- Flattery Detection Utilising an Audio-Textual Transformer-Based Approach**
2406.17667v1 by Lukas Christ, Shahin Amiriparian, Friederike Hawighorst, Ann-Kathrin Schill, Angelo Boutalikakis, Lorenz Graf-Vlachy, Andreas K√∂nig, Bj√∂rn W. Schuller

Flattery is an important aspect of human communication that facilitates
social bonding, shapes perceptions, and influences behavior through strategic
compliments and praise, leveraging the power of speech to build rapport
effectively. Its automatic detection can thus enhance the naturalness of
human-AI interactions. To meet this need, we present a novel audio textual
dataset comprising 20 hours of speech and train machine learning models for
automatic flattery detection. In particular, we employ pretrained AST,
Wav2Vec2, and Whisper models for the speech modality, and Whisper TTS models
combined with a RoBERTa text classifier for the textual modality. Subsequently,
we build a multimodal classifier by combining text and audio representations.
Evaluation on unseen test data demonstrates promising results, with Unweighted
Average Recall scores reaching 82.46% in audio-only experiments, 85.97% in
text-only experiments, and 87.16% using a multimodal approach.

ÊëòË¶ÅÔºöÂ•âÊâøÊòØ‰∫∫Á±ªÊ≤üÈÄö‰∏≠‰∏Ä‰∏™ÈáçË¶ÅÁöÑÊñπÈù¢ÔºåÂÆÉÈÄöËøáÁ≠ñÁï•ÊÄßÁöÑËµûÁæéÂíåË°®Êâ¨Êù•‰øÉËøõÁ§æ‰∫§ËÅîÁ≥ª„ÄÅÂ°ëÈÄ†ËÆ§Áü•Âπ∂ÂΩ±ÂìçË°å‰∏∫ÔºåÂà©Áî®Ë®ÄËØ≠ÁöÑÂäõÈáèÊúâÊïàÂú∞Âª∫Á´ãËûçÊ¥ΩÂÖ≥Á≥ª„ÄÇÂõ†Ê≠§ÔºåÂØπÂÖ∂ËøõË°åËá™Âä®Ê£ÄÊµãÂèØ‰ª•Â¢ûÂº∫‰∫∫Êú∫‰∫§‰∫íÁöÑËá™ÁÑ∂ÊÄß„ÄÇ‰∏∫‰∫ÜÊª°Ë∂≥Ëøô‰∏ÄÈúÄÊ±ÇÔºåÊàë‰ª¨Êèê‰æõ‰∫Ü‰∏Ä‰∏™Êñ∞È¢ñÁöÑÈü≥ËßÜÈ¢ëÊñáÊú¨Êï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 20 Â∞èÊó∂ÁöÑËØ≠Èü≥ÔºåÂπ∂ËÆ≠ÁªÉÊú∫Âô®Â≠¶‰π†Ê®°Âûã‰ª•ËøõË°åËá™Âä®Â•âÊâøÊ£ÄÊµã„ÄÇÁâπÂà´ÊòØÔºåÊàë‰ª¨‰∏∫ËØ≠Èü≥Ê®°ÂºèÈááÁî®‰∫ÜÈ¢ÑËÆ≠ÁªÉÁöÑ AST„ÄÅWav2Vec2 Âíå Whisper Ê®°ÂûãÔºåÂπ∂‰∏∫ÊñáÊú¨Ê®°ÂºèÁªìÂêà‰∫Ü Whisper TTS Ê®°ÂûãÂíå RoBERTa ÊñáÊú¨ÂàÜÁ±ªÂô®„ÄÇÈöèÂêéÔºåÊàë‰ª¨ÈÄöËøáÁªÑÂêàÊñáÊú¨ÂíåÈü≥È¢ëË°®Á§∫Êù•ÊûÑÂª∫‰∏Ä‰∏™Â§öÊ®°ÊÄÅÂàÜÁ±ªÂô®„ÄÇÂØπÊú™ËßÅÊµãËØïÊï∞ÊçÆÁöÑËØÑ‰º∞ÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûúÔºåÂú®‰ªÖÈü≥È¢ëÂÆûÈ™å‰∏≠ÔºåÊú™Âä†ÊùÉÂπ≥ÂùáÂè¨ÂõûÁéáÂæóÂàÜËææÂà∞ 82.46%ÔºåÂú®‰ªÖÊñáÊú¨ÂÆûÈ™å‰∏≠ËææÂà∞ 85.97%ÔºåÂú®‰ΩøÁî®Â§öÊ®°ÊÄÅÊñπÊ≥ïÊó∂ËææÂà∞ 87.16%„ÄÇ

##### **LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic**
2406.17663v1 by Aditya Kalyanpur, Kailash Saravanakumar, Victor Barres, Jennifer Chu-Carroll, David Melville, David Ferrucci

We introduce LLM-ARC, a neuro-symbolic framework designed to enhance the
logical reasoning capabilities of Large Language Models (LLMs), by combining
them with an Automated Reasoning Critic (ARC). LLM-ARC employs an Actor-Critic
method where the LLM Actor generates declarative logic programs along with
tests for semantic correctness, while the Automated Reasoning Critic evaluates
the code, runs the tests and provides feedback on test failures for iterative
refinement. Implemented using Answer Set Programming (ASP), LLM-ARC achieves a
new state-of-the-art accuracy of 88.32% on the FOLIO benchmark which tests
complex logical reasoning capabilities. Our experiments demonstrate significant
improvements over LLM-only baselines, highlighting the importance of logic test
generation and iterative self-refinement. We achieve our best result using a
fully automated self-supervised training loop where the Actor is trained on
end-to-end dialog traces with Critic feedback. We discuss potential
enhancements and provide a detailed error analysis, showcasing the robustness
and efficacy of LLM-ARC for complex natural language reasoning tasks.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫Ü LLM-ARCÔºåÈÄôÊòØ‰∏ÄÂÄãÁ•ûÁ∂ìÁ¨¶ËôüÊ°ÜÊû∂ÔºåÊó®Âú®ÈÄèÈÅéÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáËá™ÂãïÊé®ÁêÜÊâπË©ïÂô® (ARC) ÁµêÂêàËµ∑‰æÜÔºå‰æÜÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈÇèËºØÊé®ÁêÜËÉΩÂäõ„ÄÇLLM-ARC Êé°Áî® Actor-Critic ÊñπÊ≥ïÔºåÂÖ∂‰∏≠ LLM Actor ÊúÉÁî¢ÁîüÂÆ£ÂëäÂºèÈÇèËºØÁ®ãÂºèÔºå‰∏¶ÈáùÂ∞çË™ûÊÑèÊ≠£Á¢∫ÊÄßÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåËÄåËá™ÂãïÊé®ÁêÜÊâπË©ïÂô®ÊúÉË©ï‰º∞Á®ãÂºèÁ¢º„ÄÅÂü∑Ë°åÊ∏¨Ë©¶Ôºå‰∏¶ÈáùÂ∞çÊ∏¨Ë©¶Â§±ÊïóÊèê‰æõÂõûÈ•ãÔºå‰ª•ÈÄ≤Ë°åÂèçË¶ÜÊîπÈÄ≤„ÄÇLLM-ARC ‰ΩøÁî® Answer Set Programming (ASP) ÂØ¶‰ΩúÔºåÂú® FOLIO Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÈÅîÂà∞‰∫Ü 88.32% ÁöÑÊúÄÊñ∞Ê∫ñÁ¢∫Â∫¶ÔºåË©≤Âü∫Ê∫ñÊ∏¨Ë©¶ÊúÉÊ∏¨Ë©¶Ë§áÈõúÁöÑÈÇèËºØÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫Ü LLM-only Âü∫Ê∫ñÁöÑÈ°ØËëóÊîπÈÄ≤ÔºåÁ™ÅÈ°Ø‰∫ÜÈÇèËºØÊ∏¨Ë©¶Áî¢ÁîüËàáÂèçË¶ÜËá™ÊàëÊîπÈÄ≤ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄë‰ΩøÁî®ÂÖ®Ëá™ÂãïËá™ÊàëÁõ£Áù£Ë®ìÁ∑¥Ëø¥ÂúàÈÅîÂà∞‰∫ÜÊúÄ‰Ω≥ÁµêÊûúÔºåÂÖ∂‰∏≠ Actor ÊúÉÂú®Á´ØÂ∞çÁ´ØÂ∞çË©±ËøΩËπ§‰∏≠‰ΩøÁî®ÊâπË©ïËÄÖÁöÑÂõûÈ•ãÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊàëÂÄëË®éË´ñ‰∫ÜÊΩõÂú®ÁöÑÂ¢ûÂº∑ÂäüËÉΩÔºå‰∏¶Êèê‰æõ‰∫ÜË©≥Á¥∞ÁöÑÈåØË™§ÂàÜÊûêÔºåÂ±ïÁ§∫‰∫Ü LLM-ARC Âú®Ë§áÈõúËá™ÁÑ∂Ë™ûË®ÄÊé®ÁêÜ‰ªªÂãô‰∏≠ÁöÑÂº∑ÂÅ•ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

##### **DKPROMPT: Domain Knowledge Prompting Vision-Language Models for Open-World Planning**
2406.17659v1 by Xiaohan Zhang, Zainab Altaweel, Yohei Hayamizu, Yan Ding, Saeid Amiri, Hao Yang, Andy Kaminski, Chad Esselink, Shiqi Zhang

Vision-language models (VLMs) have been applied to robot task planning
problems, where the robot receives a task in natural language and generates
plans based on visual inputs. While current VLMs have demonstrated strong
vision-language understanding capabilities, their performance is still far from
being satisfactory in planning tasks. At the same time, although classical task
planners, such as PDDL-based, are strong in planning for long-horizon tasks,
they do not work well in open worlds where unforeseen situations are common. In
this paper, we propose a novel task planning and execution framework, called
DKPROMPT, which automates VLM prompting using domain knowledge in PDDL for
classical planning in open worlds. Results from quantitative experiments show
that DKPROMPT outperforms classical planning, pure VLM-based and a few other
competitive baselines in task completion rate.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤ÊáâÁî®ÊñºÊ©üÂô®‰∫∫‰ªªÂãôË¶èÂäÉÂïèÈ°åÔºåÂÖ∂‰∏≠Ê©üÂô®‰∫∫ÊúÉ‰ª•Ëá™ÁÑ∂Ë™ûË®ÄÊé•Êî∂‰ªªÂãôÔºå‰∏¶Ê†πÊìöË¶ñË¶∫Ëº∏ÂÖ•Áî¢ÁîüË®àÁï´„ÄÇÈõñÁÑ∂ÁõÆÂâçÁöÑ VLM Â∑≤Â±ïÁèæÂá∫Âº∑Â§ßÁöÑË¶ñË¶∫Ë™ûË®ÄÁêÜËß£ËÉΩÂäõÔºå‰ΩÜÂÖ∂Âú®Ë¶èÂäÉ‰ªªÂãô‰∏≠ÁöÑË°®Áèæ‰ªçÈÅ†Êú™‰ª§‰∫∫ÊªøÊÑè„ÄÇÂêåÊôÇÔºåÂÑòÁÆ°Âü∫Êñº PDDL Á≠âÁöÑÂÇ≥Áµ±‰ªªÂãôË¶èÂäÉÂô®Âú®Ë¶èÂäÉÈï∑Êúü‰ªªÂãôÊñπÈù¢ÂæàÂº∑Â§ßÔºå‰ΩÜÂú®‰∏çÂèØÈ†êË¶ãÁöÑÊÉÖÊ≥ÅÂæàÂ∏∏Ë¶ãÁöÑÈñãÊîæ‰∏ñÁïå‰∏≠ÔºåÂÆÉÂÄëÁÑ°Ê≥ïÁôºÊèÆ‰ΩúÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ DKPROMPT ÁöÑÊñ∞‰ªªÂãôË¶èÂäÉÂíåÂü∑Ë°åÊû∂ÊßãÔºåÂÆÉ‰ΩøÁî® PDDL ‰∏≠ÁöÑÈ†òÂüüÁü•Ë≠òËá™ÂãïÂåñ VLM ÊèêÁ§∫Ôºå‰ª•ÈÄ≤Ë°åÈñãÊîæ‰∏ñÁïå‰∏≠ÁöÑÂÇ≥Áµ±Ë¶èÂäÉ„ÄÇÂÆöÈáèÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåDKPROMPT Âú®‰ªªÂãôÂÆåÊàêÁéáÊñπÈù¢ÂÑ™ÊñºÂÇ≥Áµ±Ë¶èÂäÉ„ÄÅÁ¥îÁ≤πÂü∫Êñº VLM ÁöÑË¶èÂäÉ‰ª•ÂèäÂÖ∂‰ªñ‰∏Ä‰∫õÂÖ∑ÊúâÁ´∂Áà≠ÂäõÁöÑÂü∫Á∑ö„ÄÇ

##### **MDHA: Multi-Scale Deformable Transformer with Hybrid Anchors for Multi-View 3D Object Detection**
2406.17654v1 by Michelle Adeline, Junn Yong Loo, Vishnu Monn Baskaran

Multi-view 3D object detection is a crucial component of autonomous driving
systems. Contemporary query-based methods primarily depend either on
dataset-specific initialization of 3D anchors, introducing bias, or utilize
dense attention mechanisms, which are computationally inefficient and
unscalable. To overcome these issues, we present MDHA, a novel sparse
query-based framework, which constructs adaptive 3D output proposals using
hybrid anchors from multi-view, multi-scale input. Fixed 2D anchors are
combined with depth predictions to form 2.5D anchors, which are projected to
obtain 3D proposals. To ensure high efficiency, our proposed Anchor Encoder
performs sparse refinement and selects the top-k anchors and features.
Moreover, while existing multi-view attention mechanisms rely on projecting
reference points to multiple images, our novel Circular Deformable Attention
mechanism only projects to a single image but allows reference points to
seamlessly attend to adjacent images, improving efficiency without compromising
on performance. On the nuScenes val set, it achieves 46.4% mAP and 55.0% NDS
with a ResNet101 backbone. MDHA significantly outperforms the baseline, where
anchor proposals are modelled as learnable embeddings.

ÊëòË¶ÅÔºöÂ§öË¶ñÂúñ 3D Áâ©‰ª∂ÂÅµÊ∏¨ÊòØËá™ÂãïÈßïÈßõÁ≥ªÁµ±ÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÁï∂‰ª£Âü∫ÊñºÊü•Ë©¢ÁöÑÊñπÊ≥ï‰∏ªË¶Å‰æùË≥¥Êñº 3D Èå®ÈªûÁöÑÁâπÂÆöË≥áÊñôÈõÜÂàùÂßãÂåñÔºåÂºïÂÖ•ÂÅèÂ∑ÆÔºåÊàñÂà©Áî®ÂØÜÈõÜÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÈÄôÂú®Ë®àÁÆó‰∏äÊïàÁéá‰Ωé‰∏ã‰∏îÁÑ°Ê≥ïÊì¥Â±ï„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MDHAÔºå‰∏ÄÂÄãÂâµÊñ∞ÁöÑÁ®ÄÁñèÂü∫ÊñºÊü•Ë©¢ÁöÑÊ°ÜÊû∂ÔºåÂÆÉ‰ΩøÁî®‰æÜËá™Â§öË¶ñÂúñ„ÄÅÂ§öÂ∞∫Â∫¶Ëº∏ÂÖ•ÁöÑÊ∑∑ÂêàÈå®ÈªûÊßãÂª∫Ëá™ÈÅ©Êáâ 3D Ëº∏Âá∫Âª∫Ë≠∞„ÄÇÂõ∫ÂÆöÁöÑ 2D Èå®ÈªûËàáÊ∑±Â∫¶È†êÊ∏¨Áõ∏ÁµêÂêàÔºåÂΩ¢Êàê 2.5D Èå®ÈªûÔºå‰∏¶ÊäïÂΩ±‰ª•Áç≤Âæó 3D Âª∫Ë≠∞„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÈ´òÊïàÁéáÔºåÊàëÂÄëÊèêÂá∫ÁöÑ Anchor Encoder Âü∑Ë°åÁ®ÄÁñèË™øÊï¥Ôºå‰∏¶ÈÅ∏ÊìáÂâç k ÂÄãÈå®ÈªûÂíåÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÈõñÁÑ∂ÁèæÊúâÁöÑÂ§öË¶ñÂúñÊ≥®ÊÑèÂäõÊ©üÂà∂‰æùË≥¥ÊñºÂ∞áÂèÉËÄÉÈªûÊäïÂΩ±Âà∞Â§öÂÄãÂΩ±ÂÉèÔºå‰ΩÜÊàëÂÄëÂâµÊñ∞ÁöÑ Circular Deformable Attention Ê©üÂà∂ÂÉÖÊäïÂΩ±Âà∞ÂñÆ‰∏ÄÂΩ±ÂÉèÔºå‰ΩÜÂÖÅË®±ÂèÉËÄÉÈªûÁÑ°Á∏´Âú∞ÈóúÊ≥®Áõ∏ÈÑ∞ÂΩ±ÂÉèÔºåÂæûËÄåÂú®‰∏çÂΩ±ÈüøÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÊèêÈ´òÊïàÁéá„ÄÇÂú® nuScenes val Ë®≠ÂÆö‰∏≠ÔºåÂÆÉ‰ΩøÁî® ResNet101 ‰∏ªÂππÈÅîÂà∞‰∫Ü 46.4% mAP Âíå 55.0% NDS„ÄÇMDHA ÊòéÈ°ØÂÑ™ÊñºÂü∫Á∑öÔºåÂÖ∂‰∏≠Èå®ÈªûÂª∫Ë≠∞Ë¢´Âª∫Ê®°ÁÇ∫ÂèØÂ≠∏ÁøíÁöÑÂµåÂÖ•„ÄÇ

##### **Leveraging Large Language Models for Software Model Completion: Results from Industrial and Public Datasets**
2406.17651v1 by Christof Tinnes, Alisa Welter, Sven Apel

Modeling structure and behavior of software systems plays a crucial role in
the industrial practice of software engineering. As with other software
engineering artifacts, software models are subject to evolution. Supporting
modelers in evolving software models with recommendations for model completions
is still an open problem, though. In this paper, we explore the potential of
large language models for this task. In particular, we propose an approach,
retrieval-augmented generation, leveraging large language models, model
histories, and retrieval-augmented generation for model completion. Through
experiments on three datasets, including an industrial application, one public
open-source community dataset, and one controlled collection of simulated model
repositories, we evaluate the potential of large language models for model
completion with retrieval-augmented generation. We found that large language
models are indeed a promising technology for supporting software model
evolution (62.30% semantically correct completions on real-world industrial
data and up to 86.19% type-correct completions). The general inference
capabilities of large language models are particularly useful when dealing with
concepts for which there are few, noisy, or no examples at all.

ÊëòË¶ÅÔºöÂú®ËªüÈ´îÂ∑•Á®ãÁöÑÁî¢Ê•≠ÂØ¶Âãô‰∏≠ÔºåËªüÈ´îÁ≥ªÁµ±ÁöÑÁµêÊßãÂíåË°åÁÇ∫Âª∫Ê®°ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇËàáÂÖ∂‰ªñËªüÈ´îÂ∑•Á®ãÁî¢Âá∫Áâ©‰∏ÄÊ®£ÔºåËªüÈ´îÊ®°Âûã‰πüÊúÉÈö®ËëóÊôÇÈñìÊºîÂåñ„ÄÇÁÑ∂ËÄåÔºåÊîØÊè¥Âª∫Ê®°‰∫∫Âì°‰ΩøÁî®Ê®°ÂûãÂÆåÊàêÂª∫Ë≠∞‰æÜÊºîÂåñËªüÈ´îÊ®°Âûã‰ªçÊòØ‰∏ÄÂÄãÂ∞öÊú™Ëß£Ê±∫ÁöÑÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÄôÂÄã‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÁ®±ÁÇ∫Ê™¢Á¥¢Â¢ûÂº∑ÂºèÁîüÊàêÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã„ÄÅÊ®°ÂûãÊ≠∑Âè≤Ë®òÈåÑÂíåÊ™¢Á¥¢Â¢ûÂº∑ÂºèÁîüÊàê‰æÜÂÆåÊàêÊ®°Âûã„ÄÇÈÄèÈÅéÂú®‰∏âÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©óÔºåÂåÖÊã¨‰∏ÄÂÄãÁî¢Ê•≠ÊáâÁî®Á®ãÂºè„ÄÅ‰∏ÄÂÄãÂÖ¨ÈñãÁöÑÈñãÊ∫êÁ§æÁæ§Ë≥áÊñôÈõÜÔºå‰ª•Âèä‰∏ÄÂÄãÊ®°Êì¨Ê®°ÂûãÂÑ≤Â≠òÂ∫´ÁöÑÂèóÊéßÈõÜÂêàÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®‰ΩøÁî®Ê™¢Á¥¢Â¢ûÂº∑ÂºèÁîüÊàêÈÄ≤Ë°åÊ®°ÂûãÂÆåÊàêÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁôºÁèæÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ¢∫ÂØ¶ÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊäÄË°ìÔºåÂèØ‰ª•Áî®‰æÜÊîØÊè¥ËªüÈ´îÊ®°ÂûãÊºîÂåñÔºàÂú®ÁúüÂØ¶‰∏ñÁïåÁöÑÁî¢Ê•≠Ë≥áÊñô‰∏äÔºåÊúâ 62.30% ÁöÑË™ûÁæ©Ê≠£Á¢∫ÂÆåÊàêÔºåÈ°ûÂûãÊ≠£Á¢∫ÂÆåÊàêÁöÑÊØî‰æãÊúÄÈ´òÂèØÈÅî 86.19%Ôºâ„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑ‰∏ÄËà¨Êé®Ë´ñËÉΩÂäõÂú®ËôïÁêÜÂπæ‰πéÊ≤íÊúâ„ÄÅÊúâÈõúË®äÊàñÂÆåÂÖ®Ê≤íÊúâÁØÑ‰æãÁöÑÊ¶ÇÂøµÊôÇÁâπÂà•ÊúâÁî®„ÄÇ

##### **ELIZA Reinterpreted: The world's first chatbot was not intended as a chatbot at all**
2406.17650v1 by Jeff Shrager

ELIZA, often considered the world's first chatbot, was written by Joseph
Weizenbaum in the early 1960s. Weizenbaum did not intend to invent the chatbot,
but rather to build a platform for research into human-machine conversation and
the important cognitive processes of interpretation and misinterpretation. His
purpose was obscured by ELIZA's fame, resulting in large part from the
fortuitous timing of it's creation, and it's escape into the wild. In this
paper I provide a rich historical context for ELIZA's creation, demonstrating
that ELIZA arose from the intersection of some of the central threads in the
technical history of AI. I also briefly discuss how ELIZA escaped into the
world, and how its accidental escape, along with several coincidental turns of
the programming language screws, led both to the misapprehension that ELIZA was
intended as a chatbot, and to the loss of the original ELIZA to history for
over 50 years.

ÊëòË¶ÅÔºöELIZAÔºåÂ∏∏Ë¢´Ë™çÁÇ∫ÊòØ‰∏ñÁïå‰∏äÁ¨¨‰∏ÄÂÄãËÅäÂ§©Ê©üÂô®‰∫∫ÔºåÁî±Á¥ÑÁëüÂ§´¬∑È≠èÊ£ÆÈÆëÂßÜÂú® 1960 Âπ¥‰ª£ÂàùÊúüÁ∑®ÂØ´„ÄÇÈ≠èÊ£ÆÈÆëÂßÜ‰∏¶ÈùûÊúâÊÑèÁôºÊòéËÅäÂ§©Ê©üÂô®‰∫∫ÔºåËÄåÊòØÁÇ∫‰∫ÜÂª∫Á´ã‰∏ÄÂÄãÁ†îÁ©∂‰∫∫Ê©üÂ∞çË©±‰ª•ÂèäËß£ÈáãÂíåË™§Ëß£ÁöÑÈáçË¶ÅË™çÁü•ÈÅéÁ®ãÁöÑÂπ≥Âè∞„ÄÇ‰ªñÁöÑÁõÆÁöÑË¢´ ELIZA ÁöÑÂêçËÅ≤ÊâÄÊé©ËìãÔºåÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÁî±ÊñºÂÖ∂Ââµ‰ΩúÁöÑÊôÇÊ©üÂ∑ßÂêàÔºå‰ª•ÂèäÂÆÉÈÄÉÈÄ∏Âà∞ÈáéÂ§ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÁÇ∫ ELIZA ÁöÑÂâµ‰ΩúÊèê‰æõ‰∫Ü‰∏ÄÂÄãË±êÂØåÁöÑÊ≠∑Âè≤ËÉåÊôØÔºåË≠âÊòé ELIZA ‰æÜËá™Êñº AI ÊäÄË°ìÂè≤‰∏≠‰∏Ä‰∫õ‰∏≠ÂøÉÁ∑öÁ¥¢ÁöÑ‰∫§ÂåØËôï„ÄÇÊàë‰πüÁ∞°Ë¶ÅÂú∞Ë®éË´ñ‰∫Ü ELIZA Â¶Ç‰ΩïÈÄÉÈÄ∏Âà∞‰∏ñÁïåÔºå‰ª•ÂèäÂÆÉÂ¶Ç‰ΩïÊÑèÂ§ñÈÄÉÈÄ∏Ôºå‰ª•ÂèäÁ∑®Á®ãË™ûË®ÄËû∫Áµ≤ÁöÑÂπæÂÄãÂ∑ßÂêàËΩâÊäòÔºåÊó¢Â∞éËá¥‰∫Ü ELIZA Ë¢´Ë™§Ëß£ÁÇ∫ËÅäÂ§©Ê©üÂô®‰∫∫Ôºå‰πüÂ∞éËá¥‰∫ÜÂéüÂßã ELIZA Âú®Ê≠∑Âè≤‰∏äÈÅ∫Â§±‰∫Ü 50 Â§öÂπ¥„ÄÇ

##### **Variationist: Exploring Multifaceted Variation and Bias in Written Language Data**
2406.17647v1 by Alan Ramponi, Camilla Casula, Stefano Menini

Exploring and understanding language data is a fundamental stage in all areas
dealing with human language. It allows NLP practitioners to uncover quality
concerns and harmful biases in data before training, and helps linguists and
social scientists to gain insight into language use and human behavior. Yet,
there is currently a lack of a unified, customizable tool to seamlessly inspect
and visualize language variation and bias across multiple variables, language
units, and diverse metrics that go beyond descriptive statistics. In this
paper, we introduce Variationist, a highly-modular, extensible, and
task-agnostic tool that fills this gap. Variationist handles at once a
potentially unlimited combination of variable types and semantics across
diversity and association metrics with regards to the language unit of choice,
and orchestrates the creation of up to five-dimensional interactive charts for
over 30 variable type-semantics combinations. Through our case studies on
computational dialectology, human label variation, and text generation, we show
how Variationist enables researchers from different disciplines to effortlessly
answer specific research questions or unveil undesired associations in language
data. A Python library, code, documentation, and tutorials are made publicly
available to the research community.

ÊëòË¶ÅÔºöÊé¢Á¥¢ÂíåÁêÜËß£Ë™ûË®ÄË≥áÊñôÊòØÊâÄÊúâËôïÁêÜ‰∫∫È°ûË™ûË®ÄÈ†òÂüüÁöÑÂü∫Êú¨ÈöéÊÆµ„ÄÇÂÆÉÂÖÅË®± NLP ÂæûÊ•≠‰∫∫Âì°Âú®Ë®ìÁ∑¥ÂâçÁôºÁèæË≥áÊñô‰∏≠ÁöÑÂìÅË≥™ÂïèÈ°åÂíåÊúâÂÆ≥ÂÅèË¶ãÔºå‰∏¶Âπ´Âä©Ë™ûË®ÄÂ≠∏ÂÆ∂ÂíåÁ§æÊúÉÁßëÂ≠∏ÂÆ∂Ê∑±ÂÖ•‰∫ÜËß£Ë™ûË®Ä‰ΩøÁî®Âíå‰∫∫È°ûË°åÁÇ∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁº∫‰πè‰∏ÄÂÄãÁµ±‰∏ÄÁöÑ„ÄÅÂèØËá™Ë®ÇÁöÑÂ∑•ÂÖ∑‰æÜÁÑ°Á∏´Âú∞Ê™¢Êü•ÂíåË¶ñË¶∫ÂåñË∑®Â§öÂÄãËÆäÊï∏„ÄÅË™ûË®ÄÂñÆ‰ΩçÂíåË∂ÖË∂äÊèèËø∞ÊÄßÁµ±Ë®àÁöÑÂêÑÁ®ÆÊåáÊ®ôÁöÑË™ûË®ÄËÆäÁï∞ÂíåÂÅèË¶ã„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü VariationistÔºåÈÄôÊòØ‰∏ÄÂÄãÈ´òÂ∫¶Ê®°ÁµÑÂåñ„ÄÅÂèØÊì¥ÂÖÖ‰∏îËàá‰ªªÂãôÁÑ°ÈóúÁöÑÂ∑•ÂÖ∑ÔºåÂ°´Ë£ú‰∫ÜÈÄô‰∏ÄÁ©∫ÁôΩ„ÄÇVariationist ÂêåÊôÇËôïÁêÜËÆäÊï∏È°ûÂûãÂíåË™ûÁæ©ÁöÑÊΩõÂú®ÁÑ°ÈôêÁµÑÂêàÔºåË∑®Ë∂äËàáÊâÄÈÅ∏Ë™ûË®ÄÂñÆ‰ΩçÁöÑÁõ∏ÈóúÊÄßÂíåÈóúËÅØÊÄßÊåáÊ®ôÔºå‰∏¶ÂçîË™øÂª∫Á´ãÂ§öÈÅî‰∫îÁ∂≠‰∫íÂãïÂúñË°®Ôºå‰ª•Ê∂µËìã 30 Â§öÂÄãËÆäÊï∏È°ûÂûãË™ûÁæ©ÁµÑÂêà„ÄÇÈÄèÈÅéÊàëÂÄëÂú®Ë®àÁÆóÊñπË®ÄÂ≠∏„ÄÅ‰∫∫È°ûÊ®ôÁ±§ËÆäÁï∞ÂíåÊñáÊú¨ÁîüÊàêÁöÑÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü Variationist Â¶Ç‰Ωï‰Ωø‰∏çÂêåÈ†òÂüüÁöÑÁ†îÁ©∂‰∫∫Âì°ËÉΩÂ§†ÊØ´‰∏çË≤ªÂäõÂú∞ÂõûÁ≠îÂÖ∑È´îÁöÑÁ†îÁ©∂ÂïèÈ°åÊàñÊè≠Á§∫Ë™ûË®ÄË≥áÊñô‰∏≠‰∏çÈúÄË¶ÅÁöÑÈóúËÅØÊÄß„ÄÇPython Â∫´„ÄÅÁ®ãÂºèÁ¢º„ÄÅÊñá‰ª∂ÂíåÊïôÂ≠∏Ë™≤Á®ãÂ∑≤ÂÖ¨ÈñãÊèê‰æõÁµ¶Á†îÁ©∂Á§æÁæ§„ÄÇ

##### **Banishing LLM Hallucinations Requires Rethinking Generalization**
2406.17642v1 by Johnny Li, Saksham Consul, Eda Zhou, James Wong, Naila Farooqui, Yuxin Ye, Nithyashree Manohar, Zhuxiaona Wei, Tian Wu, Ben Echols, Sharon Zhou, Gregory Diamos

Despite their powerful chat, coding, and reasoning abilities, Large Language
Models (LLMs) frequently hallucinate. Conventional wisdom suggests that
hallucinations are a consequence of a balance between creativity and
factuality, which can be mitigated, but not eliminated, by grounding the LLM in
external knowledge sources. Through extensive systematic experiments, we show
that these traditional approaches fail to explain why LLMs hallucinate in
practice. Specifically, we show that LLMs augmented with a massive Mixture of
Memory Experts (MoME) can easily memorize large datasets of random numbers. We
corroborate these experimental findings with a theoretical construction showing
that simple neural networks trained to predict the next token hallucinate when
the training loss is above a threshold as it usually does in practice when
training on internet scale data. We interpret our findings by comparing against
traditional retrieval methods for mitigating hallucinations. We use our
findings to design a first generation model for removing hallucinations --
Lamini-1 -- that stores facts in a massive mixture of millions of memory
experts that are retrieved dynamically.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊìÅÊúâÂº∑Â§ßÁöÑËÅäÂ§©„ÄÅÁ∑®Á¢ºÂíåÊé®ÁêÜËÉΩÂäõÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Á∂ìÂ∏∏ÊúÉÂá∫ÁèæÂπªË¶∫„ÄÇÂÇ≥Áµ±Êô∫ÊÖßË™çÁÇ∫ÂπªË¶∫ÊòØÂâµÈÄ†ÂäõÂíå‰∫ãÂØ¶ÊÄß‰πãÈñìÂπ≥Ë°°ÁöÑÁµêÊûúÔºåÈÄôÁ®ÆÂπ≥Ë°°ÂèØ‰ª•ÈÄèÈÅéÂ∞á LLM Âü∫ÊñºÂ§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫ê‰æÜÊ∏õËºïÔºå‰ΩÜÁÑ°Ê≥ïÊ∂àÈô§„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÁ≥ªÁµ±ÊÄßÂØ¶È©óÔºåÊàëÂÄëË≠âÊòéÈÄô‰∫õÂÇ≥Áµ±ÊñπÊ≥ïÁÑ°Ê≥ïËß£ÈáãÁÇ∫‰ªÄÈ∫º LLM Âú®ÂØ¶Âãô‰∏≠ÊúÉÂá∫ÁèæÂπªË¶∫„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË≠âÊòé‰∫ÜÈÄèÈÅéÂ§ßÈáèË®òÊÜ∂Â∞àÂÆ∂Ê∑∑Âêà (MoME) Â¢ûÂº∑ÁöÑ LLM ÂèØ‰ª•ËºïÈ¨ÜË®ò‰ΩèÂ§ßÈáèÈö®Ê©üÊï∏Â≠óÁöÑË≥áÊñôÈõÜ„ÄÇÊàëÂÄëÁî®‰∏ÄÂÄãÁêÜË´ñÂª∫Êßã‰æÜË≠âÂØ¶ÈÄô‰∫õÂØ¶È©óÁôºÁèæÔºåË≠âÊòéË®ìÁ∑¥‰æÜÈ†êÊ∏¨‰∏ã‰∏ÄÂÄãÊ®ôË®òÁöÑÁ∞°ÂñÆÁ•ûÁ∂ìÁ∂≤Ë∑ØÊúÉÂú®Ë®ìÁ∑¥ÊêçÂ§±È´òÊñºÈñæÂÄºÊôÇÂá∫ÁèæÂπªË¶∫ÔºåÈÄôÈÄöÂ∏∏ÊúÉÂú®Ë®ìÁ∑¥Á∂≤Ë∑ØË¶èÊ®°Ë≥áÊñôÊôÇÁôºÁîü„ÄÇÊàëÂÄëÈÄèÈÅéËàáÂÇ≥Áµ±ÁöÑÊì∑ÂèñÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ‰æÜË©ÆÈáãÊàëÂÄëÁöÑÁôºÁèæÔºå‰ª•Ê∏õËºïÂπªË¶∫„ÄÇÊàëÂÄëÂà©Áî®ÊàëÂÄëÁöÑÁôºÁèæË®≠Ë®à‰∫Ü‰∏ÄÂÄãÁ¨¨‰∏Ä‰ª£Ê®°Âûã‰æÜÁßªÈô§ÂπªË¶∫ -- Lamini-1 -- ÂÆÉÊúÉÂ∞á‰∫ãÂØ¶ÂÑ≤Â≠òÂú®Êï∏ÁôæËê¨ÂÄãË®òÊÜ∂Â∞àÂÆ∂ÁöÑÈæêÂ§ßÊ∑∑Âêà‰∏≠Ôºå‰∏¶ÊúÉÂãïÊÖãÊì∑ÂèñÈÄô‰∫õ‰∫ãÂØ¶„ÄÇ

##### **BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging**
2406.17640v1 by Zeinab Sherkatghanad, Moloud Abdar, Mohammadreza Bakhtyari, Vladimir Makarenkov

Test-time augmentation (TTA) is a well-known technique employed during the
testing phase of computer vision tasks. It involves aggregating multiple
augmented versions of input data. Combining predictions using a simple average
formulation is a common and straightforward approach after performing TTA. This
paper introduces a novel framework for optimizing TTA, called BayTTA
(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,
we generate a model list associated with different variations of the input data
created through TTA. Then, we use BMA to combine model predictions weighted by
their respective posterior probabilities. Such an approach allows one to take
into account model uncertainty, and thus to enhance the predictive performance
of the related machine learning or deep learning model. We evaluate the
performance of BayTTA on various public data, including three medical image
datasets comprising skin cancer, breast cancer, and chest X-ray images and two
well-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental
results indicate that BayTTA can be effectively integrated into
state-of-the-art deep learning models used in medical image analysis as well as
into some popular pre-trained CNN models such as VGG-16, MobileNetV2,
DenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in
their accuracy and robustness performance.

ÊëòË¶ÅÔºöÊ∏¨Ë©¶ÊôÇÈñìÊì¥ÂÖÖ (TTA) ÊòØ‰∏ÄÁ®ÆÂú®ÈõªËÖ¶Ë¶ñË¶∫‰ªªÂãôÁöÑÊ∏¨Ë©¶ÈöéÊÆµ‰∏≠Âª£Ê≥õ‰ΩøÁî®ÁöÑÊäÄË°ì„ÄÇÂÆÉÊ∂âÂèäËÅöÂêàËº∏ÂÖ•Ë≥áÊñôÁöÑË®±Â§öÊì¥ÂÖÖÁâàÊú¨„ÄÇÂú®Âü∑Ë°å TTA ‰πãÂæåÔºå‰ΩøÁî®Á∞°ÂñÆÂπ≥ÂùáÂÖ¨ÂºèÁµÑÂêàÈ†êÊ∏¨ÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ã‰∏îÁõ¥Êé•ÁöÑÊñπÊ≥ï„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁî®ÊñºÊúÄ‰Ω≥Âåñ TTA ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÁ®±ÁÇ∫ BayTTAÔºàÂü∫ÊñºË≤ùÊ∞èÁöÑ TTAÔºâÔºåÂÆÉÂü∫ÊñºË≤ùÊ∞èÊ®°ÂûãÂπ≥Âùá (BMA)„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÁî¢Áîü‰∏ÄÂÄãËàáËº∏ÂÖ•Ë≥áÊñôÁöÑ‰∏çÂêåËÆäÁï∞Áõ∏ÈóúÁöÑÊ®°ÂûãÊ∏ÖÂñÆÔºåÈÄô‰∫õËÆäÁï∞ÊòØÈÄèÈÅé TTA Âª∫Á´ãÁöÑ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî® BMA ‰æÜÁµÑÂêàÊ®°ÂûãÈ†êÊ∏¨ÔºåÂÖ∂Ê¨äÈáçÁî±ÂÆÉÂÄëÂêÑËá™ÁöÑÂæåÈ©óÊ©üÁéáÊ±∫ÂÆö„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±ËÄÉÊÖÆÊ®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂæûËÄåÂ¢ûÂº∑Áõ∏ÈóúÊ©üÂô®Â≠∏ÁøíÊàñÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÈ†êÊ∏¨ÊÄßËÉΩ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÂÖ¨ÈñãË≥áÊñô‰∏äË©ï‰º∞ BayTTA ÁöÑÊÄßËÉΩÔºåÂåÖÊã¨‰∏âÂÄãÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁöÆËÜöÁôå„ÄÅ‰π≥ÁôåÂíåËÉ∏ÈÉ® X ÂÖâÂΩ±ÂÉèÔºå‰ª•ÂèäÂÖ©ÂÄãËëóÂêçÁöÑÂü∫Âõ†Á∑®ËºØË≥áÊñôÈõÜÔºåCRISPOR Âíå GUIDE-seq„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåBayTTA ÂèØ‰ª•ÊúâÊïàÊï¥ÂêàÂà∞Áî®ÊñºÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûêÁöÑÊúÄÊñ∞Ê∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏≠Ôºå‰ª•Âèä‰∏Ä‰∫õÊµÅË°åÁöÑÈ†êË®ìÁ∑¥ CNN Ê®°Âûã‰∏≠Ôºå‰æãÂ¶Ç VGG-16„ÄÅMobileNetV2„ÄÅDenseNet201„ÄÅResNet152V2 Âíå InceptionRes-NetV2ÔºåÂæûËÄåÊèêÂçáÂÆÉÂÄëÁöÑÊ∫ñÁ¢∫Â∫¶ÂíåÂÅ•Â£ØÊÄßË°®Áèæ„ÄÇ

##### **Mitigate the Gap: Investigating Approaches for Improving Cross-Modal Alignment in CLIP**
2406.17639v2 by Sedigheh Eslami, Gerard de Melo

Contrastive Language--Image Pre-training (CLIP) has manifested remarkable
improvements in zero-shot classification and cross-modal vision-language tasks.
Yet, from a geometrical point of view, the CLIP embedding space has been found
to have a pronounced modality gap. This gap renders the embedding space overly
sparse and disconnected, with different modalities being densely distributed in
distinct subregions of the hypersphere. In this work, we aim at answering two
main questions: 1. Does sharing the parameter space between the multi-modal
encoders reduce the modality gap? 2. Can the gap be mitigated by pushing apart
the uni-modal embeddings via intra-modality separation? We design AlignCLIP, in
order to answer these questions and show that answers to both questions are
positive. Through extensive experiments, we show that AlignCLIP achieves
noticeable enhancements in the cross-modal alignment of the embeddings, and
thereby, reduces the modality gap, while maintaining the performance across
several downstream evaluations, such as zero-shot image classification,
zero-shot multi-modal retrieval and zero-shot semantic text similarity.

ÊëòË¶ÅÔºöÂ∞çÊØîË™ûË®ÄÂΩ±ÂÉèÈ†êË®ìÁ∑¥ (CLIP) Â∑≤Â±ïÁèæÂá∫Âú®Èõ∂Ê¨°ÂàÜÈ°ûÂíåË∑®Ê®°ÊÖãË¶ñË¶∫Ë™ûË®Ä‰ªªÂãô‰∏≠È°ØËëóÁöÑÊîπÈÄ≤„ÄÇÁÑ∂ËÄåÔºåÂæûÂπæ‰ΩïËßÄÈªû‰æÜÁúãÔºåÁôºÁèæ CLIP ÂµåÂÖ•Á©∫ÈñìÂÖ∑ÊúâÊòéÈ°ØÁöÑÊ®°ÊÖãÂ∑ÆË∑ù„ÄÇÊ≠§Â∑ÆË∑ù‰ΩøÂµåÂÖ•Á©∫ÈñìÈÅéÊñºÁ®ÄÁñè‰∏î‰∏çÈÄ£Á∫åÔºå‰∏î‰∏çÂêåÊ®°ÊÖãÂØÜÈõÜÂàÜ‰ΩàÂú®Ë∂ÖÁêÉÈ´îÁöÑ‰∏çÂêåÂ≠êÂçÄÂüü‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®ÂõûÁ≠îÂÖ©ÂÄã‰∏ªË¶ÅÂïèÈ°åÔºö1. Âú®Â§öÊ®°ÊÖãÁ∑®Á¢ºÂô®‰πãÈñìÂÖ±‰∫´ÂèÉÊï∏Á©∫ÈñìÊòØÂê¶ÊúÉÁ∏ÆÂ∞èÊ®°ÊÖãÂ∑ÆË∑ùÔºü2. ÊòØÂê¶ÂèØ‰ª•ÈÄèÈÅéÈÄèÈÅéÊ®°ÊÖãÂÖßÂàÜÈöîÂ∞áÂñÆÊ®°ÊÖãÂµåÂÖ•ÂàÜÈñã‰æÜÁ∏ÆÂ∞èÂ∑ÆË∑ùÔºüÊàëÂÄëË®≠Ë®à‰∫Ü AlignCLIPÔºå‰ª•ÂõûÁ≠îÈÄô‰∫õÂïèÈ°åÔºå‰∏¶Ë°®ÊòéÂ∞çÈÄôÂÖ©ÂÄãÂïèÈ°åÁöÑÁ≠îÊ°àÈÉΩÊòØËÇØÂÆöÁöÑ„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëË°®Êòé AlignCLIP Âú®ÂµåÂÖ•ÁöÑË∑®Ê®°ÊÖãÂ∞çÈΩä‰∏≠Áç≤ÂæóÈ°ØËëóÁöÑÂ¢ûÂº∑ÔºåÂæûËÄåÁ∏ÆÂ∞è‰∫ÜÊ®°ÊÖãÂ∑ÆË∑ùÔºåÂêåÊôÇÁ∂≠ÊåÅ‰∫ÜÂ§öÂÄã‰∏ãÊ∏∏Ë©ï‰º∞ÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÈõ∂Ê¨°ÂΩ±ÂÉèÂàÜÈ°û„ÄÅÈõ∂Ê¨°Â§öÊ®°ÊÖãÊ™¢Á¥¢ÂíåÈõ∂Ê¨°Ë™ûÊÑèÊñáÂ≠óÁõ∏‰ººÊÄß„ÄÇ

##### **Aligning Diffusion Models with Noise-Conditioned Perception**
2406.17636v1 by Alexander Gambashidze, Anton Kulikov, Yuriy Sosnin, Ilya Makarov

Recent advancements in human preference optimization, initially developed for
Language Models (LMs), have shown promise for text-to-image Diffusion Models,
enhancing prompt alignment, visual appeal, and user preference. Unlike LMs,
Diffusion Models typically optimize in pixel or VAE space, which does not align
well with human perception, leading to slower and less efficient training
during the preference alignment stage. We propose using a perceptual objective
in the U-Net embedding space of the diffusion model to address these issues.
Our approach involves fine-tuning Stable Diffusion 1.5 and XL using Direct
Preference Optimization (DPO), Contrastive Preference Optimization (CPO), and
supervised fine-tuning (SFT) within this embedding space. This method
significantly outperforms standard latent-space implementations across various
metrics, including quality and computational cost. For SDXL, our approach
provides 60.8\% general preference, 62.2\% visual appeal, and 52.1\% prompt
following against original open-sourced SDXL-DPO on the PartiPrompts dataset,
while significantly reducing compute. Our approach not only improves the
efficiency and quality of human preference alignment for diffusion models but
is also easily integrable with other optimization techniques. The training code
and LoRA weights will be available here:
https://huggingface.co/alexgambashidze/SDXL\_NCP-DPO\_v0.1

ÊëòË¶ÅÔºöÊúÄËøëÂú®‰∫∫È°ûÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÈù¢ÁöÑÈÄ≤Â±ïÔºåÊúÄÂàùÊòØÁÇ∫Ë™ûË®ÄÊ®°Âûã (LM) ÈñãÁôºÁöÑÔºåÂ∑≤È°ØÁ§∫Âá∫Â∞çÊñáÂ≠óÂà∞ÂΩ±ÂÉèÁöÑÊì¥Êï£Ê®°ÂûãÂæàÊúâÂâçÊôØÔºåÂ¢ûÂº∑ÊèêÁ§∫Â∞çÈΩä„ÄÅË¶ñË¶∫Âê∏ÂºïÂäõÂíåÁî®Êà∂ÂÅèÂ•Ω„ÄÇËàá LM ‰∏çÂêåÔºåÊì¥Êï£Ê®°ÂûãÈÄöÂ∏∏Âú®ÂÉèÁ¥†Êàñ VAE Á©∫Èñì‰∏≠ÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÔºåÈÄôËàá‰∫∫È°ûÊÑüÁü•‰∏çÁ¨¶ÔºåÂ∞éËá¥Âú®ÂÅèÂ•ΩÂ∞çÈΩäÈöéÊÆµË®ìÁ∑¥Êõ¥ÊÖ¢‰∏îÊïàÁéáÊõ¥‰Ωé„ÄÇÊàëÂÄëÂª∫Ë≠∞Âú®Êì¥Êï£Ê®°ÂûãÁöÑ U-Net ÂµåÂÖ•Á©∫Èñì‰∏≠‰ΩøÁî®ÊÑüÁü•ÁõÆÊ®ô‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÊã¨‰ΩøÁî®Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO)„ÄÅÂ∞çÊØîÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (CPO) ÂíåÂú®ÈÄôÂÄãÂµåÂÖ•Á©∫ÈñìÂÖßÁöÑÁõ£Áù£ÂºèÂæÆË™ø (SFT) ‰æÜÂæÆË™ø Stable Diffusion 1.5 Âíå XL„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂú®ÂêÑÁ®ÆÊåáÊ®ô‰∏äÊòéÈ°ØÂÑ™ÊñºÊ®ôÊ∫ñÁöÑÊΩõÂú®Á©∫ÈñìÂØ¶‰ΩúÔºåÂåÖÊã¨ÂìÅË≥™ÂíåÈÅãÁÆóÊàêÊú¨„ÄÇÂ∞çÊñº SDXLÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂú® PartiPrompts Ë≥áÊñôÈõÜ‰∏äÊèê‰æõ 60.8% ÁöÑ‰∏ÄËà¨ÂÅèÂ•Ω„ÄÅ62.2% ÁöÑË¶ñË¶∫Âê∏ÂºïÂäõÂíå 52.1% ÁöÑÊèêÁ§∫ÈÅµÂæ™ÔºåÂêåÊôÇÈ°ØËëóÊ∏õÂ∞ëÈÅãÁÆó„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏çÂÉÖÊèêÈ´ò‰∫ÜÊì¥Êï£Ê®°ÂûãÁöÑ‰∫∫È°ûÂÅèÂ•ΩÂ∞çÈΩäÁöÑÊïàÁéáÂíåÂìÅË≥™ÔºåËÄå‰∏îÂæàÂÆπÊòìËàáÂÖ∂‰ªñÊúÄ‰Ω≥ÂåñÊäÄË°ìÊï¥Âêà„ÄÇË®ìÁ∑¥Á®ãÂºèÁ¢ºÂíå LoRA Ê¨äÈáçÂ∞áÂú®Ê≠§ËôïÊèê‰æõÔºö
https://huggingface.co/alexgambashidze/SDXL\_NCP-DPO\_v0.1

##### **Knowledge Distillation in Automated Annotation: Supervised Text Classification with LLM-Generated Training Labels**
2406.17633v1 by Nicholas Pangakis, Samuel Wolken

Computational social science (CSS) practitioners often rely on human-labeled
data to fine-tune supervised text classifiers. We assess the potential for
researchers to augment or replace human-generated training data with surrogate
training labels from generative large language models (LLMs). We introduce a
recommended workflow and test this LLM application by replicating 14
classification tasks and measuring performance. We employ a novel corpus of
English-language text classification data sets from recent CSS articles in
high-impact journals. Because these data sets are stored in password-protected
archives, our analyses are less prone to issues of contamination. For each
task, we compare supervised classifiers fine-tuned using GPT-4 labels against
classifiers fine-tuned with human annotations and against labels from GPT-4 and
Mistral-7B with few-shot in-context learning. Our findings indicate that
supervised classification models fine-tuned on LLM-generated labels perform
comparably to models fine-tuned with labels from human annotators. Fine-tuning
models using LLM-generated labels can be a fast, efficient and cost-effective
method of building supervised text classifiers.

ÊëòË¶ÅÔºöË®àÁÆóÁ§æÊúÉÁßëÂ≠∏ (CSS) ÂØ¶ÂãôÂ∑•‰ΩúËÄÖÂ∏∏‰æùË≥¥‰∫∫Â∑•Ê®ôÁ±§Ë≥áÊñô‰æÜÂæÆË™øÁõ£Áù£ÂºèÊñáÂ≠óÂàÜÈ°ûÂô®„ÄÇÊàëÂÄëË©ï‰º∞Á†îÁ©∂‰∫∫Âì°Âà©Áî®ÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊõø‰ª£Ë®ìÁ∑¥Ê®ôÁ±§‰æÜÊì¥ÂÖÖÊàñÂèñ‰ª£‰∫∫Â∑•Áî¢ÁîüÁöÑË®ìÁ∑¥Ë≥áÊñôÁöÑÊΩõÂäõ„ÄÇÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÂª∫Ë≠∞ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºå‰∏¶ÈÄèÈÅéË§áË£Ω 14 ÂÄãÂàÜÈ°û‰ªªÂãôÂíåË°°ÈáèÊïàËÉΩ‰æÜÊ∏¨Ë©¶ÈÄôÂÄã LLM ÊáâÁî®Á®ãÂºè„ÄÇÊàëÂÄëÊé°Áî®‰∏ÄÂÄãÊñ∞Á©éÁöÑËã±ÊñáÊñáÂ≠óÂàÜÈ°ûË≥áÊñôÈõÜË™ûÊñôÂ∫´ÔºåË©≤Ë™ûÊñôÂ∫´ÂèñËá™È´òÂΩ±ÈüøÂäõÊúüÂàäËøëÊúüÁöÑ CSS ÊñáÁ´†„ÄÇÁî±ÊñºÈÄô‰∫õË≥áÊñôÈõÜÂÑ≤Â≠òÂú®ÂèóÂØÜÁ¢º‰øùË≠∑ÁöÑÊ™îÊ°à‰∏≠ÔºåÊàëÂÄëÁöÑÂàÜÊûêËºÉ‰∏çÂÆπÊòìÂèóÂà∞Ê±ôÊüìÂïèÈ°åÁöÑÂΩ±Èüø„ÄÇÂ∞çÊñºÊØèÂÄã‰ªªÂãôÔºåÊàëÂÄëÊØîËºÉ‰ΩøÁî® GPT-4 Ê®ôÁ±§ÂæÆË™øÁöÑÁõ£Áù£ÂºèÂàÜÈ°ûÂô®Ëàá‰ΩøÁî®‰∫∫Â∑•Ê®ôË®ªÂæÆË™øÁöÑÂàÜÈ°ûÂô®Ôºå‰ª•Âèä‰ΩøÁî® GPT-4 Âíå Mistral-7B ÈÄ≤Ë°åÂ∞ëÈáèÊ¨°Êï∏ÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑÊ®ôÁ±§„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫Ôºå‰ΩøÁî® LLM Áî¢ÁîüÁöÑÊ®ôÁ±§ÂæÆË™øÁöÑÁõ£Áù£ÂºèÂàÜÈ°ûÊ®°ÂûãÔºåÂÖ∂ÊïàËÉΩËàá‰ΩøÁî®‰∫∫Â∑•Ê®ôË®ªËÄÖÊ®ôÁ±§ÂæÆË™øÁöÑÊ®°ÂûãÁõ∏Áï∂„ÄÇ‰ΩøÁî® LLM Áî¢ÁîüÁöÑÊ®ôÁ±§ÂæÆË™øÊ®°ÂûãÂèØËÉΩÊòØÂª∫ÊßãÁõ£Áù£ÂºèÊñáÂ≠óÂàÜÈ°ûÂô®ÁöÑ‰∏ÄÁ®ÆÂø´ÈÄü„ÄÅÊúâÊïàÁéá‰∏îÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑÊñπÊ≥ï„ÄÇ

##### **CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference**
2406.17626v1 by Erxin Yu, Jing Li, Ming Liao, Siqi Wang, Zuchen Gao, Fei Mi, Lanqing Hong

As large language models (LLMs) constantly evolve, ensuring their safety
remains a critical research problem. Previous red-teaming approaches for LLM
safety have primarily focused on single prompt attacks or goal hijacking. To
the best of our knowledge, we are the first to study LLM safety in multi-turn
dialogue coreference. We created a dataset of 1,400 questions across 14
categories, each featuring multi-turn coreference safety attacks. We then
conducted detailed evaluations on five widely used open-source LLMs. The
results indicated that under multi-turn coreference safety attacks, the highest
attack success rate was 56% with the LLaMA2-Chat-7b model, while the lowest was
13.9% with the Mistral-7B-Instruct model. These findings highlight the safety
vulnerabilities in LLMs during dialogue coreference interactions.

ÊëòË¶ÅÔºöÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏çÊñ≠ÂèëÂ±ïÔºåÁ°Æ‰øùÂÖ∂ÂÆâÂÖ®ÊÄß‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÁöÑÁ†îÁ©∂ÈóÆÈ¢ò„ÄÇ‰ª•ÂâçÈíàÂØπ LLM ÂÆâÂÖ®ÊÄßÁöÑÁ∫¢ÈòüÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®Âçï‰∏ÄÊèêÁ§∫ÊîªÂáªÊàñÁõÆÊ†áÂä´ÊåÅ‰∏ä„ÄÇÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåÊàë‰ª¨ÊòØÁ¨¨‰∏Ä‰∏™Âú®Â§öËΩÆÂØπËØùÂÖ±Êåá‰∏≠Á†îÁ©∂ LLM ÂÆâÂÖ®ÊÄßÁöÑ‰∫∫„ÄÇÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ 14 ‰∏™Á±ªÂà´ÁöÑ 1,400 ‰∏™ÈóÆÈ¢òÁöÑÊï∞ÊçÆÈõÜÔºåÊØè‰∏™ÈóÆÈ¢òÈÉΩÂåÖÂê´Â§öËΩÆÂÖ±ÊåáÂÆâÂÖ®ÊîªÂáª„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂØπ‰∫îÁßçÂπøÊ≥õ‰ΩøÁî®ÁöÑÂºÄÊ∫ê LLM ËøõË°å‰∫ÜËØ¶ÁªÜÁöÑËØÑ‰º∞„ÄÇÁªìÊûúË°®ÊòéÔºåÂú®Â§öËΩÆÂÖ±ÊåáÂÆâÂÖ®ÊîªÂáª‰∏ãÔºåÊîªÂáªÊàêÂäüÁéáÊúÄÈ´òÁöÑÊòØ LLaMA2-Chat-7b Ê®°ÂûãÔºå‰∏∫ 56%ÔºåËÄåÊúÄ‰ΩéÁöÑÊòØ Mistral-7B-Instruct Ê®°ÂûãÔºå‰∏∫ 13.9%„ÄÇËøô‰∫õÂèëÁé∞Á™ÅÂá∫‰∫Ü LLM Âú®ÂØπËØùÂÖ±Êåá‰∫§‰∫íËøáÁ®ã‰∏≠ÁöÑÂÆâÂÖ®ÊºèÊ¥û„ÄÇ

##### **Self-assessment, Exhibition, and Recognition: a Review of Personality in Large Language Models**
2406.17624v1 by Zhiyuan Wen, Yu Yang, Jiannong Cao, Haoming Sun, Ruosong Yang, Shuaiqi Liu

As large language models (LLMs) appear to behave increasingly human-like in
text-based interactions, more and more researchers become interested in
investigating personality in LLMs. However, the diversity of psychological
personality research and the rapid development of LLMs have led to a broad yet
fragmented landscape of studies in this interdisciplinary field. Extensive
studies across different research focuses, different personality psychometrics,
and different LLMs make it challenging to have a holistic overview and further
pose difficulties in applying findings to real-world applications. In this
paper, we present a comprehensive review by categorizing current studies into
three research problems: self-assessment, exhibition, and recognition, based on
the intrinsic characteristics and external manifestations of personality in
LLMs. For each problem, we provide a thorough analysis and conduct in-depth
comparisons of their corresponding solutions. Besides, we summarize research
findings and open challenges from current studies and further discuss their
underlying causes. We also collect extensive publicly available resources to
facilitate interested researchers and developers. Lastly, we discuss the
potential future research directions and application scenarios. Our paper is
the first comprehensive survey of up-to-date literature on personality in LLMs.
By presenting a clear taxonomy, in-depth analysis, promising future directions,
and extensive resource collections, we aim to provide a better understanding
and facilitate further advancements in this emerging field.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âü∫ÊñºÊñáÂ≠óÁöÑ‰∫íÂãï‰∏≠Ë°®ÁèæÂá∫Ë∂ä‰æÜË∂äÂÉè‰∫∫È°ûÁöÑË°åÁÇ∫ÔºåË∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂‰∫∫Âì°ÈñãÂßãÊúâËààË∂£Êé¢Ë®é LLM ‰∏≠ÁöÑ‰∫∫Ê†ºÁâπË≥™„ÄÇÁÑ∂ËÄåÔºåÂøÉÁêÜ‰∫∫Ê†ºÁ†îÁ©∂ÁöÑÂ§öÊ®£ÊÄßÂíå LLM ÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂ∞éËá¥ÈÄôÂÄãË∑®È†òÂüüÈ†òÂüüÁöÑÁ†îÁ©∂ÂëàÁèæÂá∫Âª£Ê≥õ‰ΩÜÊîØÈõ¢Á†¥Á¢éÁöÑÊ®£Ë≤å„ÄÇÊ©´Ë∑®‰∏çÂêåÁ†îÁ©∂ÈáçÈªû„ÄÅ‰∏çÂêå‰∫∫Ê†ºÂøÉÁêÜÊ∏¨ÈáèÊ≥ïÂíå‰∏çÂêå LLM ÁöÑÂª£Ê≥õÁ†îÁ©∂Ôºå‰ΩøÂæóÈõ£‰ª•ÂÖ®Èù¢‰∫ÜËß£Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÈÄ†ÊàêÂ∞áÁ†îÁ©∂ÁµêÊûúÊáâÁî®ÊñºÂØ¶ÈöõÊáâÁî®‰∏äÁöÑÂõ∞Èõ£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂ∞áÁõÆÂâçÁöÑÁ†îÁ©∂ÂàÜÈ°ûÁÇ∫‰∏âÂÄãÁ†îÁ©∂ÂïèÈ°åÔºöËá™ÊàëË©ïÈáè„ÄÅÂ±ïÁèæÂíåËæ®Ë≠òÔºåÂü∫Êñº LLM ‰∏≠‰∫∫Ê†ºÁâπË≥™ÁöÑÂÖßÂú®ÁâπÂæµÂíåÂ§ñÂú®Ë°®ÁèæÔºåÊèêÂá∫‰∫Ü‰∏Ä‰ªΩÂÖ®Èù¢ÁöÑÂõûÈ°ß„ÄÇÂ∞çÊñºÊØèÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂæπÂ∫ïÁöÑÂàÜÊûêÔºå‰∏¶Â∞çÂÖ∂Â∞çÊáâÁöÑËß£Ê±∫ÊñπÊ°àÈÄ≤Ë°åÊ∑±ÂÖ•ÊØîËºÉ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ∏ΩÁµê‰∫ÜÁõÆÂâçÁ†îÁ©∂ÁöÑÁ†îÁ©∂ÁµêÊûúÂíåÈñãÊîæÊÄßÊåëÊà∞Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Êé¢Ë®éÂÖ∂ÊΩõÂú®ÂéüÂõ†„ÄÇÊàëÂÄë‰πüËíêÈõÜ‰∫ÜÂª£Ê≥õÁöÑÂÖ¨ÈñãË≥áÊ∫êÔºå‰ª•ÂçîÂä©ÊúâËààË∂£ÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÈñãÁôº‰∫∫Âì°„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÊΩõÂú®ÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêëÂíåÊáâÁî®ÊÉÖÂ¢É„ÄÇÊàëÂÄëÁöÑË´ñÊñáÊòØÁ¨¨‰∏Ä‰ªΩÈóúÊñº LLM ‰∏≠‰∫∫Ê†ºÁâπË≥™ÁöÑÊúÄÊñ∞ÊñáÁçªÁöÑÂÖ®Èù¢Ë™øÊü•„ÄÇÈÄèÈÅéÊèêÂá∫ÊòéÁ¢∫ÁöÑÂàÜÈ°ûÊ≥ï„ÄÅÊ∑±ÂÖ•ÁöÑÂàÜÊûê„ÄÅÊúâÂâçÊôØÁöÑÊú™‰æÜÊñπÂêëÂíåÂª£Ê≥õÁöÑË≥áÊ∫êËíêÈõÜÔºåÊàëÂÄëÊó®Âú®Êèê‰æõÊõ¥Â•ΩÁöÑÁêÜËß£Ôºå‰∏¶‰øÉÈÄ≤ÈÄôÂÄãÊñ∞ËààÈ†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ï„ÄÇ

##### **Towards Building an End-to-End Multilingual Automatic Lyrics Transcription Model**
2406.17618v1 by Jiawen Huang, Emmanouil Benetos

Multilingual automatic lyrics transcription (ALT) is a challenging task due
to the limited availability of labelled data and the challenges introduced by
singing, compared to multilingual automatic speech recognition. Although some
multilingual singing datasets have been released recently, English continues to
dominate these collections. Multilingual ALT remains underexplored due to the
scale of data and annotation quality. In this paper, we aim to create a
multilingual ALT system with available datasets. Inspired by architectures that
have been proven effective for English ALT, we adapt these techniques to the
multilingual scenario by expanding the target vocabulary set. We then evaluate
the performance of the multilingual model in comparison to its monolingual
counterparts. Additionally, we explore various conditioning methods to
incorporate language information into the model. We apply analysis by language
and combine it with the language classification performance. Our findings
reveal that the multilingual model performs consistently better than the
monolingual models trained on the language subsets. Furthermore, we demonstrate
that incorporating language information significantly enhances performance.

ÊëòË¶ÅÔºöÂ§öË™ûË®ÄËá™ÂãïÊ≠åË©ûËΩâÈåÑ (ALT) ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÂéüÂõ†Âú®ÊñºÊ®ôÁ±§Ë≥áÊñôÁöÑÂèØÁî®ÊÄßÊúâÈôêÔºå‰ª•ÂèäËàáÂ§öË™ûË®ÄËá™ÂãïË™ûÈü≥Ëæ®Ë≠òÁõ∏ÊØîÔºåÂî±Ê≠åÊâÄÂ∏∂‰æÜÁöÑÊåëÊà∞„ÄÇÂÑòÁÆ°ÊúÄËøëÂ∑≤ÁôºÂ∏É‰∏Ä‰∫õÂ§öË™ûË®ÄÊ≠åÂî±Ë≥áÊñôÈõÜÔºå‰ΩÜËã±Ë™ûÂú®ÈÄô‰∫õË≥áÊñôÈõÜ‰∏≠‰ªç‰Ωî‰∏ªÂ∞éÂú∞‰Ωç„ÄÇÁî±ÊñºË≥áÊñôË¶èÊ®°ÂíåÊ®ôË®ªÂìÅË≥™ÔºåÂ§öË™ûË®Ä ALT ‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®‰ΩøÁî®ÁèæÊúâË≥áÊñôÈõÜÂª∫Á´ã‰∏ÄÂÄãÂ§öË™ûË®Ä ALT Á≥ªÁµ±„ÄÇÂèóÂà∞Â∑≤Ë¢´Ë≠âÊòéÂ∞çËã±Ë™û ALT ÊúâÊïàÁöÑÊû∂ÊßãÂïüÁôºÔºåÊàëÂÄëÈÄèÈÅéÊì¥ÂÖÖÁõÆÊ®ôË©ûÂΩôÈõÜÔºåÂ∞áÈÄô‰∫õÊäÄË°ìË™øÊï¥Âà∞Â§öË™ûË®ÄÂ†¥ÊôØ„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË©ï‰º∞Â§öË™ûË®ÄÊ®°ÂûãÁöÑÊïàËÉΩÔºå‰∏¶ËàáÂÖ∂ÂñÆË™ûË®ÄÂ∞çÊáâÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Á¥¢ÂêÑÁ®ÆÊ¢ù‰ª∂ÂåñÊñπÊ≥ïÔºå‰ª•Â∞áË™ûË®ÄË≥áË®äÁ¥çÂÖ•Ê®°Âûã‰∏≠„ÄÇÊàëÂÄëÊåâË™ûË®ÄÈÄ≤Ë°åÂàÜÊûêÔºå‰∏¶Â∞áÂÖ∂ËàáË™ûË®ÄÂàÜÈ°ûÊïàËÉΩÁµêÂêà„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåÂ§öË™ûË®ÄÊ®°ÂûãÁöÑÊïàËÉΩÂßãÁµÇÂÑ™Êñº‰ª•Ë™ûË®ÄÂ≠êÈõÜË®ìÁ∑¥ÁöÑÂñÆË™ûË®ÄÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòéÁ¥çÂÖ•Ë™ûË®ÄË≥áË®äÂèØÈ°ØËëóÊèêÂçáÊïàËÉΩ„ÄÇ

##### **Aligning Programming Language and Natural Language: Exploring Design Choices in Multi-Modal Transformer-Based Embedding for Bug Localization**
2406.17615v1 by Partha Chakraborty, Venkatraman Arumugam, Meiyappan Nagappan

Bug localization refers to the identification of source code files which is
in a programming language and also responsible for the unexpected behavior of
software using the bug report, which is a natural language. As bug localization
is labor-intensive, bug localization models are employed to assist software
developers. Due to the domain difference between source code files and bug
reports, modern bug-localization systems, based on deep learning models, rely
heavily on embedding techniques that project bug reports and source code files
into a shared vector space. The creation of an embedding involves several
design choices, but the impact of these choices on the quality of embedding and
the performance of bug localization models remains unexplained in current
research.
  To address this gap, our study evaluated 14 distinct embedding models to gain
insights into the effects of various design choices. Subsequently, we developed
bug localization models utilizing these embedding models to assess the
influence of these choices on the performance of the localization models. Our
findings indicate that the pre-training strategies significantly affect the
quality of the embedding. Moreover, we discovered that the familiarity of the
embedding models with the data has a notable impact on the bug localization
model's performance. Notably, when the training and testing data are collected
from different projects, the performance of the bug localization models
exhibits substantial fluctuations.

ÊëòË¶ÅÔºöÈåØË™§ÂÆö‰ΩçÊòØÊåáË≠òÂà•Á®ãÂºèÁ¢ºÊ™îÊ°àÔºåÈÄô‰∫õÊ™îÊ°à‰ΩøÁî®ÈåØË™§Â†±ÂëäÔºà‰∏ÄÁ®ÆËá™ÁÑ∂Ë™ûË®ÄÔºâ‰ª•Á®ãÂºèË™ûË®ÄÊí∞ÂØ´Ôºå‰∏¶Ë≤†Ë≤¨ËªüÈ´îÁöÑÁï∞Â∏∏Ë°åÁÇ∫„ÄÇÁî±ÊñºÈåØË™§ÂÆö‰ΩçÈúÄË¶ÅÂ§ßÈáè‰∫∫ÂäõÔºåÂõ†Ê≠§Êé°Áî®ÈåØË™§ÂÆö‰ΩçÊ®°Âûã‰æÜÂçîÂä©ËªüÈ´îÈñãÁôº‰∫∫Âì°„ÄÇÁî±ÊñºÂéüÂßãÁ¢ºÊ™îÊ°àÂíåÈåØË™§Â†±Âëä‰πãÈñìÁöÑÈ†òÂüüÂ∑ÆÁï∞ÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÁèæ‰ª£ÈåØË™§ÂÆö‰ΩçÁ≥ªÁµ±ÔºåÊ•µÂ∫¶‰æùË≥¥Â∞áÈåØË™§Â†±ÂëäÂíåÂéüÂßãÁ¢ºÊ™îÊ°àÊäïÂ∞ÑÂà∞ÂÖ±‰∫´ÂêëÈáèÁ©∫ÈñìÁöÑÂµåÂÖ•ÊäÄË°ì„ÄÇÂª∫Á´ãÂµåÂÖ•Ê∂âÂèäÂ§öÈ†ÖË®≠Ë®àÈÅ∏ÊìáÔºå‰ΩÜÈÄô‰∫õÈÅ∏ÊìáÂ∞çÂµåÂÖ•ÂìÅË≥™ÂíåÈåØË™§ÂÆö‰ΩçÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÂú®ÁõÆÂâçÁöÑÁ†îÁ©∂ÊâÄ‰∏≠‰ªçÊú™Áç≤ÂæóËß£Èáã„ÄÇ
ÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë©ï‰º∞‰∫Ü 14 ÂÄã‰∏çÂêåÁöÑÂµåÂÖ•Ê®°ÂûãÔºå‰ª•Ê∑±ÂÖ•‰∫ÜËß£ÂêÑÁ®ÆË®≠Ë®àÈÅ∏ÊìáÁöÑÂΩ±Èüø„ÄÇÈö®ÂæåÔºåÊàëÂÄëÈñãÁôº‰∫ÜÂà©Áî®ÈÄô‰∫õÂµåÂÖ•Ê®°ÂûãÁöÑÈåØË™§ÂÆö‰ΩçÊ®°ÂûãÔºå‰ª•Ë©ï‰º∞ÈÄô‰∫õÈÅ∏ÊìáÂ∞çÂÆö‰ΩçÊ®°ÂûãÊïàËÉΩÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊåáÂá∫ÔºåÈ†êË®ìÁ∑¥Á≠ñÁï•ÊúÉÈ°ØËëóÂΩ±ÈüøÂµåÂÖ•ÂìÅË≥™„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæÂµåÂÖ•Ê®°ÂûãÂ∞çË≥áÊñôÁöÑÁÜüÊÇâÂ∫¶ÔºåÂ∞çÈåØË™§ÂÆö‰ΩçÊ®°ÂûãÁöÑÊïàËÉΩÊúâÈ°ØËëóÂΩ±Èüø„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁï∂Ë®ìÁ∑¥ÂíåÊ∏¨Ë©¶Ë≥áÊñôÂæû‰∏çÂêåÁöÑÂ∞àÊ°àÊî∂ÈõÜÊôÇÔºåÈåØË™§ÂÆö‰ΩçÊ®°ÂûãÁöÑÊïàËÉΩÊúÉÂá∫ÁèæÂ§ßÂπÖÊ≥¢Âãï„ÄÇ

##### **Diffusion-based Adversarial Purification for Intrusion Detection**
2406.17606v1 by Mohamed Amine Merzouk, Erwan Beurier, Reda Yaich, Nora Boulahia-Cuppens, Fr√©d√©ric Cuppens

The escalating sophistication of cyberattacks has encouraged the integration
of machine learning techniques in intrusion detection systems, but the rise of
adversarial examples presents a significant challenge. These crafted
perturbations mislead ML models, enabling attackers to evade detection or
trigger false alerts. As a reaction, adversarial purification has emerged as a
compelling solution, particularly with diffusion models showing promising
results. However, their purification potential remains unexplored in the
context of intrusion detection. This paper demonstrates the effectiveness of
diffusion models in purifying adversarial examples in network intrusion
detection. Through a comprehensive analysis of the diffusion parameters, we
identify optimal configurations maximizing adversarial robustness with minimal
impact on normal performance. Importantly, this study reveals insights into the
relationship between diffusion noise and diffusion steps, representing a novel
contribution to the field. Our experiments are carried out on two datasets and
against 5 adversarial attacks. The implementation code is publicly available.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÊîªÊìäÁöÑÊó•ÁõäË§áÈõúÂåñ‰øÉ‰ΩøÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÊï¥ÂêàÂà∞ÂÖ•‰æµÂÅµÊ∏¨Á≥ªÁµ±‰∏≠Ôºå‰ΩÜÂ∞çÊäóÁØÑ‰æãÁöÑËààËµ∑Â∏∂‰æÜÈáçÂ§ßÊåëÊà∞„ÄÇÈÄô‰∫õÁ≤æÂøÉË£Ω‰ΩúÁöÑÊìæÂãïÊúÉË™§Â∞éÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåËÆìÊîªÊìäËÄÖÂæó‰ª•Ë¶èÈÅøÂÅµÊ∏¨ÊàñËß∏ÁôºÈåØË™§Ë≠¶Â†±„ÄÇ‰ΩúÁÇ∫ÊáâÂ∞çÔºåÂ∞çÊäóÊ∑®ÂåñÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÂºï‰∫∫Ê≥®ÁõÆÁöÑËß£Ê±∫ÊñπÊ°àÔºåÁâπÂà•ÊòØÊì¥Êï£Ê®°ÂûãÈ°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®ÂÖ•‰æµÂÅµÊ∏¨‰∏≠ÁöÑÊ∑®ÂåñÊΩõÂäõ‰ªçÊú™Ë¢´Êé¢Á¥¢„ÄÇÊú¨ÊñáÂ±ïÁ§∫‰∫ÜÊì¥Êï£Ê®°ÂûãÂú®Á∂≤Ë∑ØÂÖ•‰æµÂÅµÊ∏¨‰∏≠Ê∑®ÂåñÂ∞çÊäóÁØÑ‰æãÁöÑÊúâÊïàÊÄß„ÄÇÈÄèÈÅéÂ∞çÊì¥Êï£ÂèÉÊï∏ÈÄ≤Ë°åÂÖ®Èù¢ÂàÜÊûêÔºåÊàëÂÄëÊâæÂá∫ÊúÄ‰Ω≥ÁµÑÊÖãÔºåÊúÄÂ§ßÂåñÂ∞çÊäóÂΩàÊÄßÔºåÂêåÊôÇÂ∞áÂ∞çÊ≠£Â∏∏ÊïàËÉΩÁöÑÂΩ±ÈüøÈôçËá≥ÊúÄ‰Ωé„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÈÄôÈ†ÖÁ†îÁ©∂Êè≠Á§∫‰∫ÜÊì¥Êï£ÈõúË®äÂíåÊì¥Êï£Ê≠•È©ü‰πãÈñìÁöÑÈóú‰øÇÔºåÈÄôÂ∞çË©≤È†òÂüü‰æÜË™™ÊòØ‰∏ÄÈ†ÖÂâµÊñ∞ÁöÑË≤¢Áçª„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂú®ÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÔºå‰∏¶ÈáùÂ∞ç 5 Á®ÆÂ∞çÊäóÊîªÊìä„ÄÇÂØ¶‰ΩúÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨Èñã„ÄÇ

##### **"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?**
2406.17600v1 by Beiduo Chen, Xinpeng Wang, Siyao Peng, Robert Litschko, Anna Korhonen, Barbara Plank

Human label variation (HLV) is a valuable source of information that arises
when multiple human annotators provide different labels for valid reasons. In
Natural Language Inference (NLI) earlier approaches to capturing HLV involve
either collecting annotations from many crowd workers to represent human
judgment distribution (HJD) or use expert linguists to provide detailed
explanations for their chosen labels. While the former method provides denser
HJD information, obtaining it is resource-intensive. In contrast, the latter
offers richer textual information but it is challenging to scale up to many
human judges. Besides, large language models (LLMs) are increasingly used as
evaluators (``LLM judges'') but with mixed results, and few works aim to study
HJDs. This study proposes to exploit LLMs to approximate HJDs using a small
number of expert labels and explanations. Our experiments show that a few
explanations significantly improve LLMs' ability to approximate HJDs with and
without explicit labels, thereby providing a solution to scale up annotations
for HJD. However, fine-tuning smaller soft-label aware models with the
LLM-generated model judgment distributions (MJDs) presents partially
inconsistent results: while similar in distance, their resulting fine-tuned
models and visualized distributions differ substantially. We show the
importance of complementing instance-level distance measures with a
global-level shape metric and visualization to more effectively evaluate MJDs
against human judgment distributions.

ÊëòË¶ÅÔºö‰∫∫È°ûÊ®ôÁ±§ËÆäÁï∞ (HLV) ÊòØÊúâÂÉπÂÄºÁöÑË®äÊÅØ‰æÜÊ∫êÔºåÁï∂Â§öÂÄã‰∫∫È°ûË®ªËß£ËÄÖÂá∫ÊñºÊúâÊïàÂéüÂõ†Êèê‰æõ‰∏çÂêåÁöÑÊ®ôÁ±§ÊôÇÂ∞±ÊúÉÂá∫Áèæ„ÄÇÂú®Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI) ‰∏≠ÔºåÊì∑Âèñ HLV ÁöÑÊó©ÊúüÊñπÊ≥ïÂåÖÊã¨ÂæûË®±Â§öÁæ§ÁúæÂ∑•‰ΩúËÄÖÊî∂ÈõÜË®ªËß£‰ª•Ë°®Á§∫‰∫∫È°ûÂà§Êñ∑ÂàÜ‰Ωà (HJD)ÔºåÊàñ‰ΩøÁî®Â∞àÂÆ∂Ë™ûË®ÄÂ≠∏ÂÆ∂Êèê‰æõÂÖ∂ÊâÄÈÅ∏Ê®ôÁ±§ÁöÑË©≥Á¥∞Ë™™Êòé„ÄÇÈõñÁÑ∂Ââç‰∏ÄÁ®ÆÊñπÊ≥ïÊèê‰æõ‰∫ÜÊõ¥ÂØÜÈõÜÁöÑ HJD Ë≥áË®äÔºå‰ΩÜÂèñÂæóÂÆÉÈúÄË¶ÅÂ§ßÈáèË≥áÊ∫ê„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÂæåËÄÖÊèê‰æõ‰∫ÜÊõ¥Ë±êÂØåÁöÑÊñáÂ≠óË≥áË®äÔºå‰ΩÜË¶ÅÊì¥Â±ïÂà∞Ë®±Â§ö‰∫∫È°ûË©ïÂØ©Âì°ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ë∂ä‰æÜË∂äÂ§öÂú∞Ë¢´Áî®‰ΩúË©ï‰º∞ËÄÖÔºà``LLM Ë©ïÂØ©Âì°''ÔºâÔºå‰ΩÜÁµêÊûúÂ•ΩÂ£ûÂèÉÂçäÔºåËÄå‰∏îÂæàÂ∞ëÊúâÁ†îÁ©∂Êó®Âú®Á†îÁ©∂ HJD„ÄÇÊú¨Á†îÁ©∂Âª∫Ë≠∞Âà©Áî® LLM ‰ΩøÁî®Â∞ëÊï∏Â∞àÂÆ∂Ê®ôÁ±§ÂíåË™™Êòé‰æÜËøë‰ºº HJD„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºå‰∏Ä‰∫õË™™ÊòéÈ°ØËëóÊèêÈ´ò‰∫Ü LLM Ëøë‰ºº HJD ÁöÑËÉΩÂäõÔºåÁÑ°Ë´ñÊòØÂê¶ÊúâÊòéÁ¢∫Ê®ôÁ±§ÔºåÂæûËÄåÁÇ∫ HJD ÁöÑË®ªËß£Êì¥Â±ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãËß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî® LLM ÁîüÊàêÁöÑÊ®°ÂûãÂà§Êñ∑ÂàÜ‰Ωà (MJD) ÂæÆË™øËºÉÂ∞èÁöÑËªüÊ®ôÁ±§ÊÑüÁü•Ê®°ÂûãÊúÉÁî¢ÁîüÈÉ®ÂàÜ‰∏ç‰∏ÄËá¥ÁöÑÁµêÊûúÔºöÈõñÁÑ∂Ë∑ùÈõ¢Áõ∏‰ººÔºå‰ΩÜÂÖ∂Áî¢ÁîüÁöÑÂæÆË™øÊ®°ÂûãÂíåÂèØË¶ñÂåñÂàÜ‰ΩàÊúâÂæàÂ§ß‰∏çÂêå„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ÂÖ®Â±ÄÂΩ¢ÁãÄÊåáÊ®ôÂíåË¶ñË¶∫ÂåñË£úÂÖÖ‰æãÈ†ÖÁ¥öË∑ùÈõ¢Ê∏¨ÈáèÁöÑÈáçË¶ÅÊÄßÔºå‰ª•‰æøÊõ¥ÊúâÊïàÂú∞ÈáùÂ∞ç‰∫∫È°ûÂà§Êñ∑ÂàÜ‰ΩàË©ï‰º∞ MJD„ÄÇ

##### **LongIns: A Challenging Long-context Instruction-based Exam for LLMs**
2406.17588v2 by Shawn Gavin, Tuney Zheng, Jiaheng Liu, Quehry Que, Noah Wang, Jian Yang, Chenchen Zhang, Wenhao Huang, Wenhu Chen, Ge Zhang

The long-context capabilities of large language models (LLMs) have been a hot
topic in recent years. To evaluate the performance of LLMs in different
scenarios, various assessment benchmarks have emerged. However, as most of
these benchmarks focus on identifying key information to answer questions,
which mainly requires the retrieval ability of LLMs, these benchmarks can
partially represent the reasoning performance of LLMs from large amounts of
information. Meanwhile, although LLMs often claim to have context windows of
32k, 128k, 200k, or even longer, these benchmarks fail to reveal the actual
supported length of these LLMs. To address these issues, we propose the LongIns
benchmark dataset, a challenging long-context instruction-based exam for LLMs,
which is built based on the existing instruction datasets. Specifically, in our
LongIns, we introduce three evaluation settings: Global Instruction & Single
Task (GIST), Local Instruction & Single Task (LIST), and Local Instruction &
Multiple Tasks (LIMT). Based on LongIns, we perform comprehensive evaluations
on existing LLMs and have the following important findings: (1). The
top-performing GPT-4 with 128k context length performs poorly on the evaluation
context window of 16k in our LongIns. (2). For the multi-hop reasoning ability
of many existing LLMs, significant efforts are still needed under short context
windows (less than 4k).

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈï∑ÊñáÊú¨ËôïÁêÜËÉΩÂäõ‰∏ÄÁõ¥ÊòØÁÜ±ÈñÄË©±È°å„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ LLM Âú®‰∏çÂêåÂ†¥ÊôØ‰∏≠ÁöÑË°®ÁèæÔºåÂá∫Áèæ‰∫ÜÂêÑÁ®ÆË©ï‰º∞Âü∫Ê∫ñ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂ§ßÂ§öÊï∏ÈÄô‰∫õÂü∫Ê∫ñÈÉΩÂ∞àÊ≥®ÊñºË≠òÂà•ÈóúÈçµË≥áË®ä‰ª•ÂõûÁ≠îÂïèÈ°åÔºåÈÄô‰∏ªË¶ÅÈúÄË¶Å LLM ÁöÑÊ™¢Á¥¢ËÉΩÂäõÔºåÂõ†Ê≠§ÈÄô‰∫õÂü∫Ê∫ñÂè™ËÉΩÈÉ®ÂàÜ‰ª£Ë°® LLM ÂæûÂ§ßÈáèË≥áË®ä‰∏≠ÈÄ≤Ë°åÊé®ÁêÜÁöÑË°®Áèæ„ÄÇÂêåÊôÇÔºåÂÑòÁÆ° LLM Á∂ìÂ∏∏ËÅ≤Á®±ÂÖ∑Êúâ 32k„ÄÅ128k„ÄÅ200k ÁîöËá≥Êõ¥Èï∑ÁöÑ‰∏ä‰∏ãÊñáË¶ñÁ™óÔºå‰ΩÜÈÄô‰∫õÂü∫Ê∫ñÊú™ËÉΩÊè≠Á§∫ÈÄô‰∫õ LLM ÁöÑÂØ¶ÈöõÊîØÊè¥Èï∑Â∫¶„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü LongIns Âü∫Ê∫ñË≥áÊñôÈõÜÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫ÊñºÊåá‰ª§ÁöÑÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ LLM Èï∑ÊñáÊú¨ËÄÉË©¶ÔºåÂÆÉÊòØÊ†πÊìöÁèæÊúâÁöÑÊåá‰ª§Ë≥áÊñôÈõÜÂª∫Á´ãÁöÑ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®ÊàëÂÄëÁöÑ LongIns ‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏âÁ®ÆË©ï‰º∞Ë®≠ÂÆöÔºöÂÖ®Â±ÄÊåá‰ª§ÂíåÂñÆ‰∏Ä‰ªªÂãô (GIST)„ÄÅÂ±ÄÈÉ®Êåá‰ª§ÂíåÂñÆ‰∏Ä‰ªªÂãô (LIST) ‰ª•ÂèäÂ±ÄÈÉ®Êåá‰ª§ÂíåÂ§öÂÄã‰ªªÂãô (LIMT)„ÄÇÊ†πÊìö LongInsÔºåÊàëÂÄëÂ∞çÁèæÊúâÁöÑ LLM ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË©ï‰º∞Ôºå‰∏¶Êúâ‰∫Ü‰ª•‰∏ãÈáçË¶ÅÁöÑÁôºÁèæÔºö(1)„ÄÇÂú®ÊàëÂÄëÁöÑ LongIns ‰∏≠ÔºåË°®ÁèæÊúÄ‰Ω≥ÁöÑ GPT-4ÔºåÂÖ∂‰∏ä‰∏ãÊñáÈï∑Â∫¶ÁÇ∫ 128kÔºåÂú® 16k ÁöÑË©ï‰º∞‰∏ä‰∏ãÊñáË¶ñÁ™ó‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇ(2)„ÄÇÂ∞çÊñºË®±Â§öÁèæÊúâ LLM ÁöÑÂ§öË∑≥Êé®ÁêÜËÉΩÂäõÔºåÂú®Áü≠‰∏ä‰∏ãÊñáË¶ñÁ™óÔºàÂ∞èÊñº 4kÔºâ‰∏ã‰ªçÈúÄË¶ÅÂ§ßÈáèÁöÑÂä™Âäõ„ÄÇ

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâÁõÆÂâçÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùË≥¥ÊñºÁº∫‰πèÂèØËß£ÈáãÊÄßÁöÑÈªëÁõíÊ©üÂô®Â≠∏ÁøíÊ®°Âûã„ÄÇÂèØËß£ÈáãÊÄß‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÈ†òÂüüËá¥ÂäõÊñºËß£Ê±∫ÈÄôÂÄã‰∏ªË¶ÅÂïèÈ°åÔºåÈÄôÂú®ÈáëËûç„ÄÅÊ≥ïÂæãÂíåÂÅ•Â∫∑Á≠âÈ´òÈ¢®Èö™È†òÂüüËá≥ÈóúÈáçË¶Å„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÁØÑÁñáË´ñÂÆöÁæ© AI Ê®°ÂûãÂèäÂÖ∂ÂèØËß£ÈáãÊÄßÁöÑÊñπÊ≥ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊé°Áî®ÁµÑÂêàÊ®°ÂûãÁöÑÊ¶ÇÂøµÔºåÂÆÉ‰ª•ÂΩ¢ÂºèÂº¶ÂúñÁöÑÂΩ¢ÂºèÁúãÂæÖÊ®°ÂûãÔºåÈÄô‰∫õÂº¶ÂúñÊçïÁç≤‰∫ÜÊ®°ÂûãÁöÑÊäΩË±°ÁµêÊßãÂèäÂÖ∂ÂÖ∑È´îÂØ¶Áèæ„ÄÇÈÄôÁ®ÆÁ∂úÂêàËßÄÈªûÂåÖÂê´‰∫ÜÁ¢∫ÂÆöÊÄß„ÄÅÊ¶ÇÁéáÊÄßÂíåÈáèÂ≠êÊ®°Âûã„ÄÇÊàëÂÄëÂ∞áÂêÑÁ®Æ AI Ê®°Âûã‰ΩúÁÇ∫ÁµÑÂêàÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåÂåÖÊã¨Á∑öÊÄßÂíåÂü∫ÊñºË¶èÂâáÁöÑÊ®°Âûã„ÄÅÔºàÈÅûËø¥ÔºâÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformer„ÄÅVAEÔºå‰ª•ÂèäÂõ†ÊûúÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÊ†πÊìöÊ®°ÂûãÁöÑÁµÑÂêàÁµêÊßãÁµ¶Âá∫Ê®°ÂûãËß£ÈáãÁöÑÂÆöÁæ©ÔºåÂ±ïÁ§∫Â¶Ç‰ΩïÂàÜÊûêÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÔºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜÊæÑÊ∏Ö XAI ‰∏≠ÁöÑÂ∏∏Ë¶ã‰∏ªÈ°å„ÄÇÊàëÂÄëÁôºÁèæÔºåËÆìÊ®ôÊ∫ñÁöÑ„ÄåÂÖßÂú®ÂèØËß£Èáã„ÄçÊ®°ÂûãÂ¶ÇÊ≠§ÈÄèÊòéÁöÑÂéüÂõ†Âú®ÂúñË°®‰∏≠Ë°®ÁèæÂæóÊúÄÁÇ∫Ê∏ÖÊ•ö„ÄÇÈÄôÂºïÂ∞éÊàëÂÄëÂæóÂá∫Êõ¥‰∏ÄËà¨ÁöÑÁµÑÂêàÂèØËß£ÈáãÔºàCIÔºâÊ®°ÂûãÊ¶ÇÂøµÔºåÂÆÉÂè¶Â§ñÈÇÑÂåÖÊã¨Âõ†Êûú„ÄÅÊ¶ÇÂøµÁ©∫ÈñìÂíå DisCoCirc Ê®°Âûã„ÄÇ
Êé•‰∏ã‰æÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü CI Ê®°ÂûãÁöÑÂèØËß£ÈáãÊÄßÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂÄëÁöÑÁµÑÂêàÁµêÊßãÂÖÅË®±Ë®àÁÆóÂÖ∂‰ªñÊÑüËààË∂£ÁöÑÈáèÔºå‰∏¶ÂèØËÉΩÈÄöÈÅéÂåπÈÖçÊ®°ÂûãÁöÑÁµêÊßã‰æÜ‰øÉÈÄ≤ÂæûÊ®°ÂûãÂà∞Ë¢´Âª∫Ê®°ÁèæË±°ÁöÑÊé®ÁêÜ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂÄëÂÖÅË®±Â∞çÂÖ∂Ë°åÁÇ∫ÈÄ≤Ë°åÂúñËß£Ë™™ÊòéÔºåÈÄô‰∫õË™™ÊòéÂü∫ÊñºÂΩ±ÈüøÁ¥ÑÊùü„ÄÅÂúñËß£ÊâãË°ìÂíåÈáçÂØ´Ë™™Êòé„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÁöÑË®±Â§öÊú™‰æÜÊñπÂêëÔºåÊèêÂá∫‰∫ÜÂ¶Ç‰ΩïÂú®ÂØ¶Ë∏ê‰∏≠Â≠∏ÁøíÈÄôÁ®ÆÊúâÊÑèÁæ©ÁöÑÁµêÊßãÂåñÊ®°ÂûãÁöÑÂïèÈ°å„ÄÇ</paragraph>

##### **Beyond Text-to-SQL for IoT Defense: A Comprehensive Framework for Querying and Classifying IoT Threats**
2406.17574v1 by Ryan Pavlich, Nima Ebadi, Richard Tarbell, Billy Linares, Adrian Tan, Rachael Humphreys, Jayanta Kumar Das, Rambod Ghandiparsi, Hannah Haley, Jerris George, Rocky Slavin, Kim-Kwang Raymond Choo, Glenn Dietrich, Anthony Rios

Recognizing the promise of natural language interfaces to databases, prior
studies have emphasized the development of text-to-SQL systems. While
substantial progress has been made in this field, existing research has
concentrated on generating SQL statements from text queries. The broader
challenge, however, lies in inferring new information about the returned data.
Our research makes two major contributions to address this gap. First, we
introduce a novel Internet-of-Things (IoT) text-to-SQL dataset comprising
10,985 text-SQL pairs and 239,398 rows of network traffic activity. The dataset
contains additional query types limited in prior text-to-SQL datasets, notably
temporal-related queries. Our dataset is sourced from a smart building's IoT
ecosystem exploring sensor read and network traffic data. Second, our dataset
allows two-stage processing, where the returned data (network traffic) from a
generated SQL can be categorized as malicious or not. Our results show that
joint training to query and infer information about the data can improve
overall text-to-SQL performance, nearly matching substantially larger models.
We also show that current large language models (e.g., GPT3.5) struggle to
infer new information about returned data, thus our dataset provides a novel
test bed for integrating complex domain-specific reasoning into LLMs.

ÊëòË¶ÅÔºöË™çË≠òÂà∞Ëá™ÁÑ∂Ë™ûË®Ä‰ªãÈù¢Â∞çË≥áÊñôÂ∫´ÁöÑÊâøË´æÔºåÂÖàÂâçÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫ÜÊñáÊú¨Âà∞ SQL Á≥ªÁµ±ÁöÑÈñãÁôº„ÄÇÈõñÁÑ∂ÈÄôÂÄãÈ†òÂüüÂ∑≤Á∂ìÂèñÂæó‰∫ÜÂØ¶Ë≥™ÈÄ≤Â±ïÔºå‰ΩÜÁèæÊúâÁöÑÁ†îÁ©∂ÈõÜ‰∏≠Âú®ÂæûÊñáÂ≠óÊü•Ë©¢Áî¢Áîü SQL Èô≥Ëø∞„ÄÇÁÑ∂ËÄåÔºåÊõ¥Âª£Ê≥õÁöÑÊåëÊà∞Âú®ÊñºÊé®Ë´ñÂá∫ÈóúÊñºËøîÂõûË≥áÊñôÁöÑÊñ∞Ë≥áË®ä„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Â∞çËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÂÅöÂá∫‰∫ÜÂÖ©È†ÖÈáçÂ§ßË≤¢Áçª„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁâ©ËÅØÁ∂≤ (IoT) ÊñáÊú¨Âà∞ SQL Ë≥áÊñôÈõÜÔºåÂåÖÂê´ 10,985 ÂÄãÊñáÊú¨Âà∞ SQL Â∞çÂíå 239,398 ÂàóÁöÑÁ∂≤Ë∑ØÊµÅÈáèÊ¥ªÂãï„ÄÇË©≤Ë≥áÊñôÈõÜÂåÖÂê´ÂÖàÂâçÊñáÊú¨Âà∞ SQL Ë≥áÊñôÈõÜ‰∏≠ÂèóÈôêÁöÑÈ°çÂ§ñÊü•Ë©¢È°ûÂûãÔºåÁâπÂà•ÊòØËàáÊôÇÈñìÁõ∏ÈóúÁöÑÊü•Ë©¢„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰æÜËá™Êô∫ÊÖßÂª∫ÁØâÁöÑÁâ©ËÅØÁ∂≤ÁîüÊÖãÁ≥ªÁµ±ÔºåÊé¢Á¥¢ÊÑüÊ∏¨Âô®ËÆÄÂèñÂíåÁ∂≤Ë∑ØÊµÅÈáèË≥áÊñô„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÁöÑË≥áÊñôÈõÜÂÖÅË®±ÂÖ©ÈöéÊÆµËôïÁêÜÔºåÂÖ∂‰∏≠ÂæûÁî¢ÁîüÁöÑ SQL ËøîÂõûÁöÑË≥áÊñôÔºàÁ∂≤Ë∑ØÊµÅÈáèÔºâÂèØ‰ª•ÂàÜÈ°ûÁÇ∫ÊÉ°ÊÑèÊàñÈùûÊÉ°ÊÑè„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåËÅØÂêàË®ìÁ∑¥Êü•Ë©¢ÂíåÊé®Ë´ñË≥áÊñôË≥áË®äÂèØ‰ª•ÊîπÂñÑÊï¥È´îÊñáÊú¨Âà∞ SQL ÁöÑÊïàËÉΩÔºåÂπæ‰πéËàáÂ§ßÂπÖÊõ¥Â§ßÁöÑÊ®°ÂûãÁõ∏ÂåπÈÖç„ÄÇÊàëÂÄë‰πüË°®ÊòéÔºåÁõÆÂâçÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºà‰æãÂ¶Ç GPT3.5ÔºâÈõ£‰ª•Êé®Ë´ñÂá∫ÈóúÊñºËøîÂõûË≥áÊñôÁöÑÊñ∞Ë≥áË®äÔºåÂõ†Ê≠§ÊàëÂÄëÁöÑË≥áÊñôÈõÜÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÁî®ÊñºÂ∞áË§áÈõúÁöÑÁâπÂÆöÈ†òÂüüÊé®ÁêÜÊï¥ÂêàÂà∞ LLM ‰∏≠„ÄÇ

##### **FrenchToxicityPrompts: a Large Benchmark for Evaluating and Mitigating Toxicity in French Texts**
2406.17566v1 by Caroline Brun, Vassilina Nikoulina

Large language models (LLMs) are increasingly popular but are also prone to
generating bias, toxic or harmful language, which can have detrimental effects
on individuals and communities. Although most efforts is put to assess and
mitigate toxicity in generated content, it is primarily concentrated on
English, while it's essential to consider other languages as well. For
addressing this issue, we create and release FrenchToxicityPrompts, a dataset
of 50K naturally occurring French prompts and their continuations, annotated
with toxicity scores from a widely used toxicity classifier. We evaluate 14
different models from four prevalent open-sourced families of LLMs against our
dataset to assess their potential toxicity across various dimensions. We hope
that our contribution will foster future research on toxicity detection and
mitigation beyond Englis

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâË∂ä‰æÜË∂äÂèóÊ≠°ËøéÔºå‰ΩÜ‰πüÂæàÂÆπÊòìÁî¢ÁîüÊúâÂÅèË¶ã„ÄÅÊúâÊØíÊàñÊúâÂÆ≥ÁöÑË™ûË®ÄÔºåÈÄôÂèØËÉΩÊúÉÂ∞çÂÄã‰∫∫ÂíåÁ§æÁæ§Áî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÈõñÁÑ∂Â§ßÂ§öÊï∏ÁöÑÂä™ÂäõÈÉΩÊîæÂú®Ë©ï‰º∞ÂíåÊ∏õËºïÁîüÊàêÂÖßÂÆπ‰∏≠ÁöÑÊØíÊÄß‰∏äÔºå‰ΩÜ‰∏ªË¶ÅÈõÜ‰∏≠Âú®Ëã±Ë™û‰∏äÔºåÂêåÊôÇ‰πüÂøÖÈ†àËÄÉÊÖÆÂÖ∂‰ªñË™ûË®Ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂª∫Á´ã‰∏¶ÁôºÂ∏É FrenchToxicityPromptsÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 50K ÂÄãËá™ÁÑ∂ÁôºÁîüÁöÑÊ≥ïË™ûÊèêÁ§∫ÂèäÂÖ∂Âª∂Á∫åÁöÑË≥áÊñôÈõÜÔºå‰∏¶‰ΩøÁî®Âª£Ê≥õ‰ΩøÁî®ÁöÑÊØíÊÄßÂàÜÈ°ûÂô®Ê®ôË®òÊØíÊÄßÂàÜÊï∏„ÄÇÊàëÂÄëÊ†πÊìöË≥áÊñôÈõÜË©ï‰º∞‰æÜËá™ÂõõÂÄãÊµÅË°åÁöÑ LLM ÈñãÊ∫êÁ≥ªÂàóÁöÑ 14 ÂÄã‰∏çÂêåÊ®°ÂûãÔºå‰ª•Ë©ï‰º∞ÂÆÉÂÄëÂú®‰∏çÂêåÈù¢ÂêëÁöÑÊΩõÂú®ÊØíÊÄß„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑË≤¢ÁçªÂ∞á‰øÉÈÄ≤Êú™‰æÜÂ∞çËã±Ë™û‰ª•Â§ñÁöÑÊØíÊÄßÂÅµÊ∏¨ÂíåÊ∏õÁ∑©ÁöÑÁ†îÁ©∂„ÄÇ

##### **Multi-property Steering of Large Language Models with Dynamic Activation Composition**
2406.17563v1 by Daniel Scalena, Gabriele Sarti, Malvina Nissim

Activation steering methods were shown to be effective in conditioning
language model generation by additively intervening over models' intermediate
representations. However, the evaluation of these techniques has so far been
limited to single conditioning properties and synthetic settings. In this work,
we conduct a comprehensive evaluation of various activation steering
strategies, highlighting the property-dependent nature of optimal parameters to
ensure a robust effect throughout generation. To address this issue, we propose
Dynamic Activation Composition, an information-theoretic approach to modulate
the steering intensity of one or more properties throughout generation. Our
experiments on multi-property steering show that our method successfully
maintains high conditioning while minimizing the impact of conditioning on
generation fluency.

ÊëòË¶ÅÔºöÊøÄÊ¥ªËΩ¨ÂêëÊñπÊ≥ïË¢´Ë≠âÊòéÂú®ÈÄöÈÅéÂ∞çÊ®°ÂûãÁöÑ‰∏≠ÈñìË°®Á§∫ÈÄ≤Ë°åÂä†ÊÄßÂπ≤È†ê‰æÜË™øÁØÄË™ûË®ÄÊ®°ÂûãÁîüÊàêÊñπÈù¢ÊòØÊúâÊïàÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåÂ∞çÈÄô‰∫õÊäÄË°ìÁöÑË©ï‰º∞ÂÉÖÈôêÊñºÂñÆ‰∏ÄË™øÁØÄÂ±¨ÊÄßÂíåÂêàÊàêË®≠ÁΩÆ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞çÂêÑÁ®ÆÊøÄÊ¥ªËΩâÂêëÁ≠ñÁï•ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢Ë©ï‰º∞ÔºåÂº∑Ë™ø‰∫ÜÊúÄ‰Ω≥ÂèÉÊï∏ÁöÑÂ±¨ÊÄß‰æùË≥¥ÊÄßÔºå‰ª•Á¢∫‰øùÂú®Êï¥ÂÄãÁîüÊàêÈÅéÁ®ã‰∏≠Áî¢ÁîüÁ©©ÂÅ•ÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂãïÊÖãÊøÄÊ¥ªÁµÑÂêàÔºåÈÄôÊòØ‰∏ÄÁ®Æ‰ø°ÊÅØË´ñÊñπÊ≥ïÔºåÁî®ÊñºÂú®Êï¥ÂÄãÁîüÊàêÈÅéÁ®ã‰∏≠Ë™øÁØÄ‰∏ÄÂÄãÊàñÂ§öÂÄãÂ±¨ÊÄßÁöÑËΩâÂêëÂº∑Â∫¶„ÄÇÊàëÂÄëÂ∞çÂ§öÂ±¨ÊÄßËΩâÂêëÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊúÄÂ§ßÁ®ãÂ∫¶Âú∞Èôç‰ΩéË™øÁØÄÂ∞çÁîüÊàêÊµÅÊö¢ÊÄßÁöÑÂΩ±ÈüøÁöÑÂêåÊôÇÔºåÊàêÂäüÂú∞‰øùÊåÅ‰∫ÜÈ´òË™øÁØÄ„ÄÇ

##### **The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale**
2406.17557v1 by Guilherme Penedo, Hynek Kydl√≠ƒçek, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, Thomas Wolf

The performance of a large language model (LLM) depends heavily on the
quality and size of its pretraining dataset. However, the pretraining datasets
for state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly
available and very little is known about how they were created. In this work,
we introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl
snapshots that produces better-performing LLMs than other open pretraining
datasets. To advance the understanding of how best to curate high-quality
pretraining datasets, we carefully document and ablate all of the design
choices used in FineWeb, including in-depth investigations of deduplication and
filtering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion
token collection of educational text filtered from FineWeb. LLMs pretrained on
FineWeb-Edu exhibit dramatically better performance on knowledge- and
reasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we
publicly release our data curation codebase and all of the models trained
during our ablation experiments.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊïàËÉΩÂèñÊ±∫ÊñºÂÖ∂È†êË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÂìÅË≥™ÂíåË¶èÊ®°„ÄÇÁÑ∂ËÄåÔºåÊúÄÂÖàÈÄ≤ÁöÑÈñãÊîæ LLMÔºà‰æãÂ¶Ç Llama 3 Âíå MixtralÔºâÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏¶Êú™ÂÖ¨ÈñãÔºåËÄå‰∏îÊàëÂÄëÂ∞çÊñºÂÆÉÂÄëÁöÑÂª∫Á´ãÊñπÂºèÊâÄÁü•ÁîöÂ∞ë„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FineWebÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± 96 ÂÄã Common Crawl Âø´ÁÖßË°çÁîüÁöÑ 15 ÂÖÜÂÄã‰ª£Âπ£ÁöÑË≥áÊñôÈõÜÔºåÂÆÉÁî¢ÁîüÁöÑ LLM ÊïàËÉΩÂÑ™ÊñºÂÖ∂‰ªñÈñãÊîæÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜ„ÄÇÁÇ∫‰∫ÜÂ¢ûÈÄ≤ÊàëÂÄëÂ∞çÊñºÂ¶Ç‰ΩïÊúÄ‰Ω≥Á≠ñÂäÉÈ´òÂìÅË≥™È†êË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÁêÜËß£ÔºåÊàëÂÄë‰ªîÁ¥∞Ë®òÈåÑ‰∏¶Ê∂àËûç‰∫Ü FineWeb ‰∏≠‰ΩøÁî®ÁöÑÊâÄÊúâË®≠Ë®àÈÅ∏ÊìáÔºåÂåÖÊã¨Â∞çÈáçË§áË≥áÊñôÂà™Èô§ÂíåÈÅéÊøæÁ≠ñÁï•ÁöÑÊ∑±ÂÖ•Êé¢Ë®é„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FineWeb-EduÔºåÈÄôÊòØ‰∏ÄÂÄãÂæû FineWeb ‰∏≠ÈÅéÊøæÂá∫ÁöÑ 1.3 ÂÖÜÂÄã‰ª£Âπ£ÁöÑÊïôËÇ≤ÊñáÊú¨ÈõÜÂêà„ÄÇÂú® FineWeb-Edu ‰∏äÈ†êË®ìÁ∑¥ÁöÑ LLM Âú®Áü•Ë≠òÂíåÊé®ÁêÜÂØÜÈõÜÁöÑÂü∫Ê∫ñÔºà‰æãÂ¶Ç MMLU Âíå ARCÔºâ‰∏äÂ±ïÁèæÂá∫È°ØËëóÊõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÈô§‰∫ÜÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÂÖ¨ÈñãÁôºÂ∏É‰∫ÜÊàëÂÄëÁöÑË≥áÊñôÁ≠ñÂäÉÁ®ãÂºèÁ¢ºÂ∫´‰ª•ÂèäÂú®ÊàëÂÄëÁöÑÊ∂àËûçÂØ¶È©ó‰∏≠Ë®ìÁ∑¥ÁöÑÊâÄÊúâÊ®°Âûã„ÄÇ

##### **Retrieval-Augmented Code Generation for Situated Action Generation: A Case Study on Minecraft**
2406.17553v1 by Chalamalasetti Kranti, Sherzod Hakimov, David Schlangen

In the Minecraft Collaborative Building Task, two players collaborate: an
Architect (A) provides instructions to a Builder (B) to assemble a specified
structure using 3D blocks. In this work, we investigate the use of large
language models (LLMs) to predict the sequence of actions taken by the Builder.
Leveraging LLMs' in-context learning abilities, we use few-shot prompting
techniques, that significantly improve performance over baseline methods.
Additionally, we present a detailed analysis of the gaps in performance for
future work

ÊëòË¶ÅÔºöÂú® Minecraft Âçî‰ΩúÂª∫ÈÄ†‰ªªÂãô‰∏≠ÔºåÂÖ©‰ΩçÁé©ÂÆ∂Âçî‰ΩúÔºö‰∏ÄÂêçÂª∫ÁØâÂ∏´ (A) Âêë‰∏ÄÂêçÂª∫ÈÄ†ËÄÖ (B) Êèê‰æõÊåáÁ§∫Ôºå‰ΩøÁî® 3D ÊñπÂ°äÁµÑË£ù‰∏ÄÂÄãÊåáÂÆöÁöÑÁµêÊßã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÈ†êÊ∏¨Âª∫ÈÄ†ËÄÖÊé°ÂèñÁöÑÂãï‰ΩúÈ†ÜÂ∫è„ÄÇÂà©Áî® LLM ÁöÑÊÉÖÂ¢ÉÂ≠∏ÁøíËÉΩÂäõÔºåÊàëÂÄë‰ΩøÁî®Â∞ëÊ¨°ÊèêÁ§∫ÊäÄË°ìÔºåÂ§ßÂπÖÊèêÂçá‰∫ÜÂü∫Ê∫ñÊñπÊ≥ïÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈáùÂ∞çÊïàËÉΩÂ∑ÆË∑ùÊèêÂá∫Ë©≥Á¥∞ÁöÑÂàÜÊûêÔºå‰ª•Âà©ÊñºÂæåÁ∫åÂ∑•‰Ωú

##### **CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained Models using Greedy Coordinate Descent**
2406.17542v2 by Pranav Ajit Nair, Arun Sai Suggala

Large language models (LLMs) have recently demonstrated remarkable
performance across diverse language tasks. But their deployment is often
constrained by their substantial computational and storage requirements.
Quantization has emerged as a key technique for addressing this challenge,
enabling the compression of large models with minimal impact on performance.
The recent GPTQ algorithm, a post-training quantization (PTQ) method, has
proven highly effective for compressing LLMs, sparking a wave of research that
leverages GPTQ as a core component. Recognizing the pivotal role of GPTQ in the
PTQ landscape, we introduce CDQuant, a simple and scalable alternative to GPTQ
with improved performance. CDQuant uses coordinate descent to minimize the
layer-wise reconstruction loss to achieve high-quality quantized weights. Our
algorithm is easy to implement and scales efficiently to models with hundreds
of billions of parameters. Through extensive evaluation on the PaLM2 model
family, we demonstrate that CDQuant consistently outperforms GPTQ across
diverse model sizes and quantization levels. In particular, for INT2
quantization of PaLM2-Otter, CDQuant achieves a 10% reduction in perplexity
compared to GPTQ.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËøëÊúüÂú®ÂêÑÁ®ÆË™ûË®Ä‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊïàËÉΩ„ÄÇ‰ΩÜÂÖ∂ÈÉ®ÁΩ≤ÈÄöÂ∏∏ÂèóÂà∞ÂÖ∂ÈæêÂ§ßÁöÑÈÅãÁÆóÂíåÂÑ≤Â≠òÈúÄÊ±ÇÊâÄÈôêÂà∂„ÄÇÈáèÂåñÂ∑≤ÊàêÁÇ∫Ëß£Ê±∫Ê≠§ÊåëÊà∞ÁöÑ‰∏ÄÈ†ÖÈóúÈçµÊäÄË°ìÔºåËÉΩÂ£ìÁ∏ÆÂ§ßÂûãÊ®°ÂûãÔºå‰∏îÂ∞çÊïàËÉΩÁöÑÂΩ±ÈüøÊ•µÂ∞è„ÄÇÊúÄËøëÁöÑ GPTQ ÊºîÁÆóÊ≥ïÔºå‰∏ÄÁ®ÆË®ìÁ∑¥ÂæåÈáèÂåñ (PTQ) ÊñπÊ≥ïÔºåÂ∑≤Ë¢´Ë≠âÊòéÂ∞çÊñºÂ£ìÁ∏Æ LLM ÈùûÂ∏∏ÊúâÊïàÔºåÂºïÁôº‰∫Ü‰∏ÄÊ≥¢‰ª• GPTQ ÁÇ∫Ê†∏ÂøÉÂÖÉ‰ª∂ÁöÑÁ†îÁ©∂Êµ™ÊΩÆ„ÄÇÈëëÊñº GPTQ Âú® PTQ È†òÂüü‰∏≠ÁöÑÈóúÈçµËßíËâ≤ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü CDQuantÔºå‰∏ÄÁ®ÆÁ∞°ÂñÆ‰∏îÂèØÊì¥ÂÖÖÁöÑ GPTQ Êõø‰ª£ÊñπÊ°àÔºå‰∏îÊïàËÉΩÊúâÊâÄÊèêÂçá„ÄÇCDQuant ‰ΩøÁî®Â∫ßÊ®ô‰∏ãÈôç‰æÜÊúÄÂ∞èÂåñÂ±§Á¥öÈáçÂª∫ÊêçÂ§±Ôºå‰ª•ÈÅîÊàêÈ´òÂìÅË≥™ÁöÑÈáèÂåñÊ¨äÈáç„ÄÇÊàëÂÄëÁöÑÊºîÁÆóÊ≥ïÊòìÊñºÂØ¶‰ΩúÔºå‰∏îÂèØÊúâÊïàÊì¥ÂÖÖËá≥ÂÖ∑ÊúâÊï∏ÂçÉÂÑÑÂÄãÂèÉÊï∏ÁöÑÊ®°Âûã„ÄÇÈÄèÈÅéÂ∞ç PaLM2 Ê®°ÂûãÁ≥ªÂàóÈÄ≤Ë°åÂª£Ê≥õË©ï‰º∞ÔºåÊàëÂÄëË≠âÊòé CDQuant Âú®ÂêÑÁ®ÆÊ®°ÂûãÂ§ßÂ∞èÂíåÈáèÂåñÂ±§Á¥ö‰∏≠ÂßãÁµÇÂÑ™Êñº GPTQ„ÄÇÁâπÂà•ÊòØÔºåÂ∞çÊñº PaLM2-Otter ÁöÑ INT2 ÈáèÂåñÔºåCDQuant Ëàá GPTQ Áõ∏ÊØîÔºåÂõ∞ÊÉëÂ∫¶Èôç‰Ωé‰∫Ü 10%„ÄÇ

##### **SincVAE: a New Approach to Improve Anomaly Detection on EEG Data Using SincNet and Variational Autoencoder**
2406.17537v1 by Andrea Pollastro, Francesco Isgr√≤, Roberto Prevete

Over the past few decades, electroencephalography (EEG) monitoring has become
a pivotal tool for diagnosing neurological disorders, particularly for
detecting seizures. Epilepsy, one of the most prevalent neurological diseases
worldwide, affects approximately the 1 \% of the population. These patients
face significant risks, underscoring the need for reliable, continuous seizure
monitoring in daily life. Most of the techniques discussed in the literature
rely on supervised Machine Learning (ML) methods. However, the challenge of
accurately labeling variations in epileptic EEG waveforms complicates the use
of these approaches. Additionally, the rarity of ictal events introduces an
high imbalancing within the data, which could lead to poor prediction
performance in supervised learning approaches. Instead, a semi-supervised
approach allows to train the model only on data not containing seizures, thus
avoiding the issues related to the data imbalancing. This work proposes a
semi-supervised approach for detecting epileptic seizures from EEG data,
utilizing a novel Deep Learning-based method called SincVAE. This proposal
incorporates the learning of an ad-hoc array of bandpass filter as a first
layer of a Variational Autoencoder (VAE), potentially eliminating the
preprocessing stage where informative band frequencies are identified and
isolated. Results indicate that SincVAE improves seizure detection in EEG data
and is capable of identifying early seizures during the preictal stage as well
as monitoring patients throughout the postictal stage.

ÊëòË¶ÅÔºöÂú®ÈÅéÂéªÁöÑÂπæÂçÅÂπ¥‰∏≠ÔºåËÖ¶ÈõªÂúñ (EEG) Áõ£ÊéßÂ∑≤ÊàêÁÇ∫Ë®∫Êñ∑Á•ûÁ∂ìÁñæÁóÖÁöÑÈáçË¶ÅÂ∑•ÂÖ∑ÔºåÁâπÂà•ÊòØÂ∞çÊñºÊ™¢Ê∏¨Áô≤ÁôáÁôº‰Ωú„ÄÇÁô≤ÁôáÊòØÂÖ®ÁêÉÊúÄÊôÆÈÅçÁöÑÁ•ûÁ∂ìÁñæÁóÖ‰πã‰∏ÄÔºåÂΩ±ÈüøËëóÂ§ßÁ¥Ñ 1% ÁöÑ‰∫∫Âè£„ÄÇÈÄô‰∫õÊÇ£ËÄÖÈù¢Ëá®ËëóÈáçÂ§ßÁöÑÈ¢®Èö™ÔºåÈÄôÂá∏È°Ø‰∫ÜÂú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÈÄ≤Ë°åÂèØÈù†„ÄÅÊåÅÁ∫åÁöÑÁô≤ÁôáÁôº‰ΩúÁõ£ÊéßÁöÑÂøÖË¶ÅÊÄß„ÄÇÊñáÁçª‰∏≠Ë®éË´ñÁöÑÂ§ßÂ§öÊï∏ÊäÄË°ìÈÉΩ‰æùË≥¥ÊñºÁõ£Áù£ÂºèÊ©üÂô®Â≠∏Áøí (ML) ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÊ∫ñÁ¢∫Ê®ôË®òÁô≤Áôá EEG Ê≥¢ÂΩ¢ËÆäÂåñÁöÑÊåëÊà∞‰ΩøÂæóÈÄô‰∫õÊñπÊ≥ïÁöÑ‰ΩøÁî®ËÆäÂæóË§áÈõú„ÄÇÊ≠§Â§ñÔºåÁôº‰Ωú‰∫ã‰ª∂ÁöÑÁΩïË¶ãÊÄßÂ∞éËá¥Êï∏Êìö‰∏≠Â≠òÂú®Âö¥ÈáçÁöÑÂ§±Ë°°ÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥Áõ£Áù£ÂºèÂ≠∏ÁøíÊñπÊ≥ïÁöÑÈ†êÊ∏¨ÊïàÊûú‰∏ç‰Ω≥„ÄÇÁõ∏ÂèçÔºåÂçäÁõ£Áù£ÂºèÊñπÊ≥ïÂÖÅË®±ÂÉÖ‰ΩøÁî®‰∏çÂåÖÂê´Áô≤ÁôáÁôº‰ΩúÁöÑÊï∏Êìö‰æÜË®ìÁ∑¥Ê®°ÂûãÔºåÂæûËÄåÈÅøÂÖçËàáÊï∏ÊìöÂ§±Ë°°Áõ∏ÈóúÁöÑÂïèÈ°å„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂçäÁõ£Áù£ÂºèÊñπÊ≥ïÔºåÁî®ÊñºÂæû EEG Êï∏Êìö‰∏≠Ê™¢Ê∏¨Áô≤ÁôáÁôº‰ΩúÔºåÂà©Áî®‰∏ÄÁ®ÆÁ®±ÁÇ∫ SincVAE ÁöÑÊñ∞Á©éÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ï„ÄÇÊ≠§ÊèêÊ°àÂ∞áÂ≠∏Áøí‰∏ÄÁµÑÁâπÂà•Ë®≠Ë®àÁöÑÂ∏∂ÈÄöÊøæÊ≥¢Âô®‰ΩúÁÇ∫ËÆäÂàÜËá™Á∑®Á¢ºÂô® (VAE) ÁöÑÁ¨¨‰∏ÄÂ±§ÔºåÂæûËÄåÊΩõÂú®Âú∞Ê∂àÈô§‰∫ÜË≠òÂà•ÂíåÂàÜÈõ¢‰ø°ÊÅØÈ†ªÂ∏∂ÁöÑÈ†êËôïÁêÜÈöéÊÆµ„ÄÇÁµêÊûúË°®ÊòéÔºåSincVAE ÊîπÂñÑ‰∫Ü EEG Êï∏Êìö‰∏≠ÁöÑÁô≤ÁôáÁôº‰ΩúÊ™¢Ê∏¨Ôºå‰∏¶‰∏îËÉΩÂ§†Âú®Áôº‰ΩúÂâçÈöéÊÆµË≠òÂà•Êó©ÊúüÁô≤ÁôáÁôº‰ΩúÔºå‰∏¶Âú®Áôº‰ΩúÂæåÈöéÊÆµÁõ£ÊéßÊÇ£ËÄÖ„ÄÇ

##### **Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark**
2406.17535v1 by Fabio Mercorio, Mario Mezzanzanica, Daniele Potert√¨, Antonio Serino, Andrea Seveso

Recent advancements in Large Language Models (LLMs) have significantly
enhanced their ability to generate and manipulate human language, highlighting
their potential across various applications. Evaluating LLMs in languages other
than English is crucial for ensuring their linguistic versatility, cultural
relevance, and applicability in diverse global contexts, thus broadening their
usability and effectiveness. We tackle this challenge by introducing a
structured benchmark using the INVALSI tests, a set of well-established
assessments designed to measure educational competencies across Italy. Our
study makes three primary contributions: Firstly, we adapt the INVALSI
benchmark for automated LLM evaluation, which involves rigorous adaptation of
the test format to suit automated processing while retaining the essence of the
original tests. Secondly, we provide a detailed assessment of current LLMs,
offering a crucial reference point for the academic community. Finally, we
visually compare the performance of these models against human results.
Additionally, researchers are invited to submit their models for ongoing
evaluation, ensuring the benchmark remains a current and valuable resource.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÂ¢ûÂº∑‰∫ÜÂÆÉÂÄëÁî¢ÁîüÂíåËôïÁêÜ‰∫∫È°ûË™ûË®ÄÁöÑËÉΩÂäõÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉÂÄëÂú®ÂêÑÁ®ÆÊáâÁî®‰∏≠ÁöÑÊΩõÂäõ„ÄÇË©ï‰º∞Èô§Ëã±Ë™û‰ª•Â§ñË™ûË®Ä‰∏≠ÁöÑ LLMÔºåÂ∞çÊñºÁ¢∫‰øùÂÆÉÂÄëÁöÑË™ûË®ÄÈÄöÁî®ÊÄß„ÄÅÊñáÂåñÁõ∏ÈóúÊÄßÂíåÂú®‰∏çÂêåÂÖ®ÁêÉËÉåÊôØ‰∏ãÁöÑÈÅ©Áî®ÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂæûËÄåÊì¥Â±ïÂÆÉÂÄëÁöÑÂèØÁî®ÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÄöÈÅé‰ΩøÁî® INVALSI Ê∏¨Ë©¶ÂºïÂÖ•ÁµêÊßãÂåñÂü∫Ê∫ñ‰æÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåINVALSI Ê∏¨Ë©¶ÊòØ‰∏ÄÂ•óÂÆåÂñÑÁöÑË©ï‰º∞ÔºåÊó®Âú®Ë°°ÈáèÁæ©Â§ßÂà©ÂêÑÂú∞ÁöÑÊïôËÇ≤ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂÅöÂá∫‰∫Ü‰∏âÈ†Ö‰∏ªË¶ÅË≤¢ÁçªÔºöÈ¶ñÂÖàÔºåÊàëÂÄëË™øÊï¥ INVALSI Âü∫Ê∫ñ‰ª•ÈÄ≤Ë°åËá™ÂãïÂåñ LLM Ë©ï‰º∞ÔºåÂÖ∂‰∏≠Ê∂âÂèäÂö¥Ê†ºË™øÊï¥Ê∏¨Ë©¶Ê†ºÂºè‰ª•ÈÅ©ÊáâËá™ÂãïÂåñËôïÁêÜÔºåÂêåÊôÇ‰øùÁïôÂéüÂßãÊ∏¨Ë©¶ÁöÑÁ≤æÈ´ì„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÂ∞çÁõÆÂâçÁöÑ LLM Êèê‰æõË©≥Á¥∞Ë©ï‰º∞ÔºåÁÇ∫Â≠∏Ë°ìÁïåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈáçË¶ÅÁöÑÂèÉËÄÉÈªû„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞áÈÄô‰∫õÊ®°ÂûãÁöÑÊÄßËÉΩËàá‰∫∫È°ûÁöÑÁµêÊûúÈÄ≤Ë°åË¶ñË¶∫ÊØîËºÉ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÄË´ãÁ†îÁ©∂‰∫∫Âì°Êèê‰∫§‰ªñÂÄëÁöÑÊ®°ÂûãÈÄ≤Ë°åÊåÅÁ∫åË©ï‰º∞ÔºåÁ¢∫‰øùÂü∫Ê∫ñ‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊúÄÊñ∞‰∏îÊúâÂÉπÂÄºÁöÑË≥áÊ∫ê„ÄÇ

##### **Retrieval-style In-Context Learning for Few-shot Hierarchical Text Classification**
2406.17534v1 by Huiyao Chen, Yu Zhao, Zulong Chen, Mengjia Wang, Liangyue Li, Meishan Zhang, Min Zhang

Hierarchical text classification (HTC) is an important task with broad
applications, while few-shot HTC has gained increasing interest recently. While
in-context learning (ICL) with large language models (LLMs) has achieved
significant success in few-shot learning, it is not as effective for HTC
because of the expansive hierarchical label sets and extremely-ambiguous
labels. In this work, we introduce the first ICL-based framework with LLM for
few-shot HTC. We exploit a retrieval database to identify relevant
demonstrations, and an iterative policy to manage multi-layer hierarchical
labels. Particularly, we equip the retrieval database with HTC label-aware
representations for the input texts, which is achieved by continual training on
a pretrained language model with masked language modeling (MLM), layer-wise
classification (CLS, specifically for HTC), and a novel divergent contrastive
learning (DCL, mainly for adjacent semantically-similar labels) objective.
Experimental results on three benchmark datasets demonstrate superior
performance of our method, and we can achieve state-of-the-art results in
few-shot HTC.

ÊëòË¶ÅÔºöÂ±§Á¥öÊñáÊú¨ÂàÜÈ°û (HTC) ÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂÖ∑ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÔºåËÄåÂ∞ëÊ®£Êú¨ HTC Ëøë‰æÜÂÇôÂèóÈóúÊ≥®„ÄÇÈõñÁÑ∂ÂÖ∑ÂÇôÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊÉÖÂ¢ÉÂÖßÂ≠∏Áøí (ICL) Â∑≤Âú®Â∞ëÊ®£Êú¨Â≠∏Áøí‰∏≠Áç≤ÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÁî±ÊñºÈæêÂ§ßÁöÑÂ±§Á¥öÊ®ôÁ±§ÁµÑÂíåÊ•µÂÖ∂Ê®°Á≥äÁöÑÊ®ôÁ±§ÔºåÂÆÉÂ∞ç HTC ËÄåË®Ä‰∏¶ÈùûÈÇ£È∫ºÊúâÊïà„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ¨¨‰∏ÄÂÄãÂü∫Êñº ICL ÁöÑ LLM Ê°ÜÊû∂ÔºåÁî®ÊñºÂ∞ëÊ®£Êú¨ HTC„ÄÇÊàëÂÄëÂà©Áî®Ê™¢Á¥¢Ë≥áÊñôÂ∫´‰æÜË≠òÂà•Áõ∏ÈóúÁ§∫ÁØÑÔºå‰∏¶Êé°Áî®ÂèçË¶ÜÈÅãÁÆóÊîøÁ≠ñ‰æÜÁÆ°ÁêÜÂ§öÂ±§Â±§Á¥öÊ®ôÁ±§„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄë‰ΩøÁî® HTC Ê®ôÁ±§ÊÑüÁü•Ë°®Âæµ‰æÜÁÇ∫Ê™¢Á¥¢Ë≥áÊñôÂ∫´ÈÖçÂÇôËº∏ÂÖ•ÊñáÊú¨ÔºåÈÄôÂèØÈÄèÈÅéÊåÅÁ∫åÂú®È†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã‰∏äÈÄ≤Ë°åÈÅÆÁΩ©Ë™ûË®ÄÂª∫Ê®° (MLM)„ÄÅÂ±§Á¥öÂàÜÈ°û (CLSÔºåÁâπÂà•ÈáùÂ∞ç HTC) Âíå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁôºÊï£Â∞çÊØîÂ≠∏Áøí (DCLÔºå‰∏ªË¶ÅÈáùÂ∞çÁõ∏ÈÑ∞ÁöÑË™ûÁæ©Áõ∏‰ººÊ®ôÁ±§) ÁõÆÊ®ô‰æÜÈÅîÊàê„ÄÇÂú®‰∏âÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Áï∞ÊïàËÉΩÔºåËÄå‰∏îÊàëÂÄëÂèØ‰ª•Âú®Â∞ëÊ®£Êú¨ HTC ‰∏≠Áç≤ÂæóÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûú„ÄÇ

##### **Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study**
2406.17532v1 by Keyu Wang, Guilin Qi, Jiaqi Li, Songlin Zhai

Large language models (LLMs) have shown significant achievements in solving a
wide range of tasks. Recently, LLMs' capability to store, retrieve and infer
with symbolic knowledge has drawn a great deal of attention, showing their
potential to understand structured information. However, it is not yet known
whether LLMs can understand Description Logic (DL) ontologies. In this work, we
empirically analyze the LLMs' capability of understanding DL-Lite ontologies
covering 6 representative tasks from syntactic and semantic aspects. With
extensive experiments, we demonstrate both the effectiveness and limitations of
LLMs in understanding DL-Lite ontologies. We find that LLMs can understand
formal syntax and model-theoretic semantics of concepts and roles. However,
LLMs struggle with understanding TBox NI transitivity and handling ontologies
with large ABoxes. We hope that our experiments and analyses provide more
insights into LLMs and inspire to build more faithful knowledge engineering
solutions.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëß£Ê±∫Âª£Ê≥õÁöÑ‰ªªÂãôÊñπÈù¢Â∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÊàêÂ∞±„ÄÇÊúÄËøëÔºåLLM ÂÑ≤Â≠ò„ÄÅÊì∑ÂèñÂíåÊé®Ë´ñÁ¨¶ËôüÁü•Ë≠òÁöÑËÉΩÂäõÂºïËµ∑‰∫ÜÊ•µÂ§ßÁöÑÈóúÊ≥®ÔºåÈ°ØÁ§∫Âá∫ÂÆÉÂÄëÁêÜËß£ÁµêÊßãÂåñË≥áË®äÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•ö LLM ÊòØÂê¶ËÉΩÁêÜËß£ÊèèËø∞ÈÇèËºØ (DL) Áü•Ë≠òÂ∫´„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂæûÂè•Ê≥ïÂíåË™ûÁæ©Â±§Èù¢ÂØ¶Ë≠âÂàÜÊûê LLM ÁêÜËß£ DL-Lite Áü•Ë≠òÂ∫´ÁöÑËÉΩÂäõÔºåÊ∂µËìã 6 È†Ö‰ª£Ë°®ÊÄß‰ªªÂãô„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü LLM Âú®ÁêÜËß£ DL-Lite Áü•Ë≠òÂ∫´ÊñπÈù¢ÁöÑÊïàËÉΩÂíåÈôêÂà∂„ÄÇÊàëÂÄëÁôºÁèæ LLM ËÉΩÁêÜËß£Ê¶ÇÂøµÂíåËßíËâ≤ÁöÑÂΩ¢ÂºèÂè•Ê≥ïÂíåÊ®°ÂûãË´ñË™ûÁæ©„ÄÇÁÑ∂ËÄåÔºåLLM Âú®ÁêÜËß£ TBox NI ÂÇ≥ÈÅûÊÄßÂíåËôïÁêÜÂÖ∑ÊúâÂ§ßÂûã ABox ÁöÑÁü•Ë≠òÂ∫´ÊñπÈù¢ÊúâÂõ∞Èõ£„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÂØ¶È©óÂíåÂàÜÊûêËÉΩÁÇ∫ LLM Êèê‰æõÊõ¥Â§öË¶ãËß£Ôºå‰∏¶ÊøÄÂãµÂª∫ÊßãÊõ¥Âø†ÂØ¶ÁöÑÁü•Ë≠òÂ∑•Á®ãËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness**
2406.17531v1 by Lucrezia Grassi, Carmine Tommaso Recchiuto, Antonio Sgorbissa

This paper presents a system for diversity-aware autonomous conversation
leveraging the capabilities of large language models (LLMs). The system adapts
to diverse populations and individuals, considering factors like background,
personality, age, gender, and culture. The conversation flow is guided by the
structure of the system's pre-established knowledge base, while LLMs are tasked
with various functions, including generating diversity-aware sentences.
Achieving diversity-awareness involves providing carefully crafted prompts to
the models, incorporating comprehensive information about users, conversation
history, contextual details, and specific guidelines. To assess the system's
performance, we conducted both controlled and real-world experiments, measuring
a wide range of performance indicators.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁ≥ªÁµ±ÔºåÁî®ÊñºÂ§öÂÖÉÂåñÁöÑËá™‰∏ªÂ∞çË©±ÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõ„ÄÇË©≤Á≥ªÁµ±ÈÅ©Êáâ‰∏çÂêåÁöÑÊóèÁæ§ÂíåÂÄã‰∫∫ÔºåËÄÉÊÖÆËÉåÊôØ„ÄÅÂÄãÊÄß„ÄÅÂπ¥ÈΩ°„ÄÅÊÄßÂà•ÂíåÊñáÂåñÁ≠âÂõ†Á¥†„ÄÇÂ∞çË©±ÊµÅÁ®ãÁî±Á≥ªÁµ±È†êÂÖàÂª∫Á´ãÁöÑÁü•Ë≠òÂ∫´ÁµêÊßãÂºïÂ∞éÔºåËÄå LLM ÂâáË≤†Ë≤¨ÂêÑÁ®ÆÂäüËÉΩÔºåÂåÖÊã¨ÁîüÊàêÂ§öÂÖÉÂåñÁöÑÂè•Â≠ê„ÄÇÂØ¶ÁèæÂ§öÂÖÉÂåñÊÑèË≠òÊ∂âÂèäÂêëÊ®°ÂûãÊèê‰æõÁ≤æÂøÉË£Ω‰ΩúÁöÑÊèêÁ§∫ÔºåÁ¥çÂÖ•ÊúâÈóú‰ΩøÁî®ËÄÖ„ÄÅÂ∞çË©±Ë®òÈåÑ„ÄÅ‰∏ä‰∏ãÊñáË©≥Á¥∞Ë≥áÊñôÂíåÂÖ∑È´îÊåáÂçóÁöÑÂÖ®Èù¢Ë≥áË®ä„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Á≥ªÁµ±ÁöÑÊïàËÉΩÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂèóÊéßÂíåÁúüÂØ¶‰∏ñÁïåÁöÑÂØ¶È©óÔºåË°°Èáè‰∫ÜÂª£Ê≥õÁöÑÊïàËÉΩÊåáÊ®ô„ÄÇ

##### **LumberChunker: Long-Form Narrative Document Segmentation**
2406.17526v1 by Andr√© V. Duarte, Jo√£o Marques, Miguel Gra√ßa, Miguel Freire, Lei Li, Arlindo L. Oliveira

Modern NLP tasks increasingly rely on dense retrieval methods to access
up-to-date and relevant contextual information. We are motivated by the premise
that retrieval benefits from segments that can vary in size such that a
content's semantic independence is better captured. We propose LumberChunker, a
method leveraging an LLM to dynamically segment documents, which iteratively
prompts the LLM to identify the point within a group of sequential passages
where the content begins to shift. To evaluate our method, we introduce
GutenQA, a benchmark with 3000 "needle in a haystack" type of question-answer
pairs derived from 100 public domain narrative books available on Project
Gutenberg. Our experiments show that LumberChunker not only outperforms the
most competitive baseline by 7.37% in retrieval performance (DCG@20) but also
that, when integrated into a RAG pipeline, LumberChunker proves to be more
effective than other chunking methods and competitive baselines, such as the
Gemini 1.5M Pro. Our Code and Data are available at
https://github.com/joaodsmarques/LumberChunker

ÊëòË¶ÅÔºöÁèæ‰ª£ NLP ‰ªªÂãôË∂ä‰æÜË∂ä‰æùË≥¥ÂØÜÈõÜÊ™¢Á¥¢ÊñπÊ≥ï‰æÜÂ≠òÂèñÊúÄÊñ∞‰∏îÁõ∏ÈóúÁöÑËÑàÁµ°Ë≥áË®ä„ÄÇÊàëÂÄëÁöÑÂãïÊ©üÊòØÂü∫ÊñºÊ™¢Á¥¢ÂèóÁõäÊñºÂ§ßÂ∞èÂèØËÆäÁöÑÂçÄÊÆµÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞Êì∑ÂèñÂÖßÂÆπÁöÑË™ûÊÑèÁç®Á´ãÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ LumberChunkerÔºå‰∏ÄÁ®ÆÂà©Áî® LLM ÂãïÊÖãÂçÄÈöîÊñá‰ª∂ÁöÑÊñπÊ≥ïÔºåÂÆÉÊúÉÂèçË¶ÜÊèêÁ§∫ LLM ÊâæÂá∫ÈÄ£Á∫åÊÆµËêΩÁæ§ÁµÑ‰∏≠ÂÖßÂÆπÈñãÂßãËΩâÁßªÁöÑÈªû„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÊàëÂÄëÁöÑÈÄôÈ†ÖÊñπÊ≥ïÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü GutenQAÔºå‰∏ÄÂÄãÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ 3000 ÂÄã„ÄåÂ§ßÊµ∑ÊíàÈáù„ÄçÈ°ûÂûãÁöÑÂïèÁ≠îÂ∞çÔºåÈÄô‰∫õÂ∞ç‰æÜËá™Â∞àÊ°àÂè§È®∞Â†°‰∏ä 100 Êú¨ÂèØÂÖ¨ÈñãÂèñÂæóÁöÑÊïò‰∫ãÊõ∏Á±ç„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåLumberChunker ‰∏çÂÉÖÂú®Ê™¢Á¥¢ÊïàËÉΩ (DCG@20) ‰∏äÂÑ™ÊñºÁ´∂Áà≠ÊúÄÊøÄÁÉàÁöÑÂü∫Ê∫ñ 7.37%ÔºåËÄå‰∏îÔºåÁï∂Êï¥ÂêàÂà∞ RAG ÁÆ°Á∑ö‰∏≠ÊôÇÔºåLumberChunker Ë≠âÊòéÊØîÂÖ∂‰ªñÂçÄÂ°äÊñπÊ≥ïÂíåÁ´∂Áà≠Âü∫Ê∫ñÊõ¥ÊúâÊïàÔºå‰æãÂ¶Ç Gemini 1.5M Pro„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/joaodsmarques/LumberChunker ÂèñÂæó

##### **Entropy-Based Decoding for Retrieval-Augmented Large Language Models**
2406.17519v1 by Zexuan Qiu, Zijing Ou, Bin Wu, Jingjing Li, Aiwei Liu, Irwin King

Augmenting Large Language Models (LLMs) with retrieved external knowledge has
proven effective for improving the factual accuracy of generated responses.
Despite their success, retrieval-augmented LLMs still face the distractibility
issue, where the generated responses are negatively influenced by noise from
both external and internal knowledge sources. In this paper, we introduce a
novel, training-free decoding method guided by entropy considerations to
mitigate this issue. Our approach utilizes entropy-based document-parallel
ensemble decoding to prioritize low-entropy distributions from retrieved
documents, thereby enhancing the extraction of relevant information of context.
Additionally, it incorporates a contrastive decoding mechanism that contrasts
the obtained low-entropy ensemble distribution with the high-entropy
distribution derived from the model's internal knowledge across layers, which
ensures a greater emphasis on reliable external information. Extensive
experiments on open-domain question answering datasets demonstrate the
superiority of our method.

ÊëòË¶ÅÔºöÊì¥ÂÖÖÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÊì∑ÂèñÂ§ñÈÉ®Áü•Ë≠òÂ∑≤Ë¢´Ë≠âÂØ¶ÂèØÊúâÊïàÊèêÂçáÂõûÊáâ‰∫ãÂØ¶ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂÑòÁÆ°ÂÆÉÂÄëÂæàÊàêÂäüÔºå‰ΩÜÊì∑ÂèñÊì¥ÂÖÖÁöÑ LLM ‰ªçÈù¢Ëá®ÂàÜÂøÉÂïèÈ°åÔºåÂÖ∂‰∏≠Áî¢ÁîüÁöÑÂõûÊáâÂèóÂà∞‰æÜËá™Â§ñÈÉ®ÂíåÂÖßÈÉ®Áü•Ë≠ò‰æÜÊ∫êÈõúË®äÁöÑË≤†Èù¢ÂΩ±Èüø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ„ÄÅÂÖçË®ìÁ∑¥ÁöÑËß£Á¢ºÊñπÊ≥ïÔºå‰ª•ÁÜµËÄÉÈáèÁÇ∫Â∞éÂêë‰æÜÊ∏õËºïÊ≠§ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂà©Áî®Âü∫ÊñºÁÜµÁöÑÊñá‰ª∂Âπ≥Ë°åÊï¥È´îËß£Á¢ºÔºå‰ª•ÂÑ™ÂÖàËôïÁêÜÊì∑ÂèñÊñá‰ª∂‰∏≠ÁöÑ‰ΩéÁÜµÂàÜ‰ΩàÔºåÂæûËÄåÂ¢ûÂº∑Â∞çËÑàÁµ°Áõ∏ÈóúË≥áË®äÁöÑÊèêÂèñ„ÄÇÊ≠§Â§ñÔºåÂÆÉÁµêÂêàÂ∞çÊØîËß£Á¢ºÊ©üÂà∂ÔºåÂ∞áÂèñÂæóÁöÑ‰ΩéÁÜµÊï¥È´îÂàÜ‰ΩàËàáÊ®°ÂûãÂæûÂêÑÂ±§‰∏≠Ë°çÁîüÁöÑÈ´òÁÜµÂàÜ‰ΩàÈÄ≤Ë°åÂ∞çÊØîÔºåÈÄôÁ¢∫‰øù‰∫ÜÊõ¥Âº∑Ë™øÂèØÈù†ÁöÑÂ§ñÈÉ®Ë≥áË®ä„ÄÇÂú®ÈñãÊîæÈ†òÂüüÂïèÁ≠îË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **Benchmarking Mental State Representations in Language Models**
2406.17513v1 by Matteo Bortoletto, Constantin Ruhdorfer, Lei Shi, Andreas Bulling

While numerous works have assessed the generative performance of language
models (LMs) on tasks requiring Theory of Mind reasoning, research into the
models' internal representation of mental states remains limited. Recent work
has used probing to demonstrate that LMs can represent beliefs of themselves
and others. However, these claims are accompanied by limited evaluation, making
it difficult to assess how mental state representations are affected by model
design and training choices. We report an extensive benchmark with various LM
types with different model sizes, fine-tuning approaches, and prompt designs to
study the robustness of mental state representations and memorisation issues
within the probes. Our results show that the quality of models' internal
representations of the beliefs of others increases with model size and, more
crucially, with fine-tuning. We are the first to study how prompt variations
impact probing performance on theory of mind tasks. We demonstrate that models'
representations are sensitive to prompt variations, even when such variations
should be beneficial. Finally, we complement previous activation editing
experiments on Theory of Mind tasks and show that it is possible to improve
models' reasoning performance by steering their activations without the need to
train any probe.

ÊëòË¶ÅÔºöÂÑòÁÆ°Ë®±Â§ö‰ΩúÂìÅÂ∑≤Á∂ìË©ï‰º∞‰∫ÜË™ûË®ÄÊ®°Âûã (LM) Âú®ÈúÄË¶ÅÂøÉÊô∫ÁêÜË´ñÊé®ÁêÜÁöÑ‰ªªÂãô‰∏äÁöÑÁîüÊàêÊïàËÉΩÔºå‰ΩÜÂ∞çÊñºÂøÉÊô∫ÁãÄÊÖãÊ®°ÂûãÁöÑÂÖßÈÉ®Ë°®ÂæµÁöÑÁ†îÁ©∂‰ªçÁÑ∂ÊúâÈôê„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤‰ΩøÁî®Êé¢Ê∏¨‰æÜË≠âÊòé LM ÂèØ‰ª•Ë°®ÂæµËá™Â∑±ÂíåÂà•‰∫∫ÁöÑ‰ø°Âøµ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õË™™Ê≥ï‰º¥Èö®ËëóÊúâÈôêÁöÑË©ï‰º∞ÔºåÈÄô‰ΩøÂæóÈõ£‰ª•Ë©ï‰º∞ÂøÉÊô∫ÁãÄÊÖãË°®ÂæµÂ¶Ç‰ΩïÂèóÂà∞Ê®°ÂûãË®≠Ë®àÂíåË®ìÁ∑¥ÈÅ∏ÊìáÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂ†±Âëä‰∫Ü‰∏ÄÂÄãÂª£Ê≥õÁöÑÂü∫Ê∫ñÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂÖ∑Êúâ‰∏çÂêåÊ®°ÂûãÂ§ßÂ∞è„ÄÅÂæÆË™øÊñπÊ≥ïÂíåÊèêÁ§∫Ë®≠Ë®àÁöÑÂêÑÁ®Æ LM È°ûÂûãÔºå‰ª•Á†îÁ©∂Êé¢Ê∏¨‰∏≠ÁöÑÂøÉÊô∫ÁãÄÊÖãË°®ÂæµÂíåË®òÊÜ∂ÂïèÈ°åÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊ®°ÂûãÂ∞ç‰ªñ‰∫∫‰ø°ÂøµÁöÑÂÖßÈÉ®Ë°®ÂæµÁöÑÂìÅË≥™ÊúÉÈö®ËëóÊ®°ÂûãÂ§ßÂ∞èÁöÑÂ¢ûÂä†ËÄåÂ¢ûÂä†ÔºåÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÈö®ËëóÂæÆË™øËÄåÂ¢ûÂä†„ÄÇÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÁ†îÁ©∂ÊèêÁ§∫ËÆäÁï∞Â¶Ç‰ΩïÂΩ±ÈüøÂøÉÊô∫ÁêÜË´ñ‰ªªÂãôÊé¢Ê∏¨ÊïàËÉΩÁöÑ‰∫∫„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊ®°ÂûãÁöÑË°®ÂæµÂ∞çÊèêÁ§∫ËÆäÁï∞ÂæàÊïèÊÑüÔºåÂç≥‰ΩøÈÄô‰∫õËÆäÁï∞ÊáâË©≤ÊòØÂ•ΩÁöÑ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË£úÂÖÖ‰∫Ü‰πãÂâçÂú®ÂøÉÊô∫ÁêÜË´ñ‰ªªÂãô‰∏äÈÄ≤Ë°åÁöÑÊøÄÊ¥ªÁ∑®ËºØÂØ¶È©óÔºå‰∏¶Ë°®ÊòéÂèØ‰ª•ÈÄèÈÅéÂºïÂ∞éÊ®°ÂûãÁöÑÊøÄÊ¥ª‰æÜÊîπÂñÑÊ®°ÂûãÁöÑÊé®ÁêÜÊïàËÉΩÔºåËÄåÁÑ°ÈúÄË®ìÁ∑¥‰ªª‰ΩïÊé¢Ê∏¨„ÄÇ

##### **MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation**
2406.17484v1 by Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang

Large language models (LLMs) have shown substantial progress in natural
language understanding and generation, proving valuable especially in the
medical field. Despite advancements, challenges persist due to the complexity
and diversity inherent in medical tasks, which can be categorized as
knowledge-intensive tasks and alignment-required tasks. Previous approaches
either ignore the latter task or focus on a minority of tasks and hence lose
generalization. To address these drawbacks, we propose a progressive
fine-tuning pipeline. This pipeline employs a Knowledge Aggregator and a Noise
aggregator to encode diverse knowledge in the first stage and filter out
detrimental information. In the second stage, we drop the Noise Aggregator to
avoid the interference of suboptimal representation and leverage an additional
alignment module optimized towards an orthogonal direction to the knowledge
space to mitigate knowledge forgetting. Based on this two-stage paradigm, we
proposed a Medical LLM through decoupling Clinical Alignment and Knowledge
Aggregation (MedCare), which is designed to achieve state-of-the-art (SOTA)
performance on over 20 medical tasks, as well as SOTA results on specific
medical alignment tasks. Various model sizes of MedCare (1.8B, 7B, 14B) all
demonstrate significant improvements over existing models with similar model
sizes.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Ëá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇÈ†òÂüüË≠âÊòé‰∫ÜÂÖ∂ÂÉπÂÄº„ÄÇÂÑòÁÆ°ÊúâÈÄ≤Â±ïÔºå‰ΩÜÁî±ÊñºÈÜ´ÁôÇ‰ªªÂãôÂõ∫ÊúâÁöÑË§áÈõúÊÄßÂíåÂ§öÊ®£ÊÄßÔºåÊåëÊà∞‰æùÁÑ∂Â≠òÂú®ÔºåÈÄô‰∫õ‰ªªÂãôÂèØÊ≠∏È°ûÁÇ∫Áü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÂíåÈúÄË¶ÅÂ∞çÈΩäÁöÑ‰ªªÂãô„ÄÇÂÖàÂâçÁöÑÂÅöÊ≥ïË¶Å‰πàÂøΩÁï•ÂæåËÄÖ‰ªªÂãôÔºåË¶Å‰πàÂ∞àÊ≥®ÊñºÂ∞ëÊï∏‰ªªÂãôÔºåÂõ†Ê≠§Â§±Âéª‰∫ÜÊ¶ÇÊã¨ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫ÈªûÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊº∏ÈÄ≤ÂºèÂæÆË™øÁÆ°ÈÅì„ÄÇÊ≠§ÁÆ°ÈÅìÂú®Á¨¨‰∏ÄÈöéÊÆµÊé°Áî®Áü•Ë≠òËÅöÂêàÂô®ÂíåÂô™Èü≥ËÅöÂêàÂô®Â∞ç‰∏çÂêåÁöÑÁü•Ë≠òÈÄ≤Ë°åÁ∑®Á¢ºÔºå‰∏¶ÈÅéÊøæÊéâÊúâÂÆ≥‰ø°ÊÅØ„ÄÇÂú®Á¨¨‰∫åÈöéÊÆµÔºåÊàëÂÄëÊîæÊ£ÑÂô™Èü≥ËÅöÂêàÂô®Ôºå‰ª•ÈÅøÂÖçÊ¨°ÂÑ™Ë°®Á§∫ÁöÑÂπ≤ÊìæÔºå‰∏¶Âà©Áî®È°çÂ§ñÂ∞çÈΩäÊ®°ÁµÑÔºåË©≤Ê®°ÁµÑÈáùÂ∞çËàáÁü•Ë≠òÁ©∫ÈñìÊ≠£‰∫§ÁöÑÊñπÂêëÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÔºå‰ª•Ê∏õËºïÁü•Ë≠òÈÅ∫Âøò„ÄÇÂü∫ÊñºÈÄôÂÄãÂÖ©ÈöéÊÆµÁØÑ‰æãÔºåÊàëÂÄëÈÄöÈÅéËß£ËÄ¶Ëá®Â∫äÂ∞çÈΩäÂíåÁü•Ë≠òËÅöÂêà (MedCare) ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈÜ´ÁôÇ LLMÔºåÂÖ∂Ë®≠Ë®àÊó®Âú®Âú® 20 Â§öÈ†ÖÈÜ´ÁôÇ‰ªªÂãô‰∏äÂØ¶ÁèæÊúÄÂÖàÈÄ≤ (SOTA) ÊïàËÉΩÔºå‰ª•ÂèäÂú®ÁâπÂÆöÈÜ´ÁôÇÂ∞çÈΩä‰ªªÂãô‰∏äÂØ¶Áèæ SOTA ÁµêÊûú„ÄÇMedCare ÁöÑÂêÑÁ®ÆÊ®°ÂûãÂ§ßÂ∞èÔºà1.8B„ÄÅ7B„ÄÅ14BÔºâÂùáÈ°ØÁ§∫Âá∫ÊØîÂÖ∑ÊúâÈ°û‰ººÊ®°ÂûãÂ§ßÂ∞èÁöÑÁèæÊúâÊ®°ÂûãÊúâÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇ

##### **Transformer-based Named Entity Recognition with Combined Data Representation**
2406.17474v1 by Micha≈Ç Marci≈Ñczuk

This study examines transformer-based models and their effectiveness in named
entity recognition tasks. The study investigates data representation
strategies, including single, merged, and context, which respectively use one
sentence, multiple sentences, and sentences joined with attention to context
per vector. Analysis shows that training models with a single strategy may lead
to poor performance on different data representations. To address this
limitation, the study proposes a combined training procedure that utilizes all
three strategies to improve model stability and adaptability. The results of
this approach are presented and discussed for four languages (English, Polish,
Czech, and German) across various datasets, demonstrating the effectiveness of
the combined strategy.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®éÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÂèäÂÖ∂Âú®ÂëΩÂêçÂØ¶È´îËæ®Ë≠ò‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ë™øÊü•Ë≥áÊñôË°®Á§∫Á≠ñÁï•ÔºåÂåÖÊã¨ÂñÆ‰∏Ä„ÄÅÂêà‰ΩµÂíåË™ûÂ¢ÉÔºåÂàÜÂà•‰ΩøÁî®‰∏ÄÂÄãÂè•Â≠ê„ÄÅÂ§öÂÄãÂè•Â≠êÂíåËàáË™ûÂ¢ÉÊ≥®ÊÑèÂäõÁµêÂêàÁöÑÂè•Â≠ê‰ΩúÁÇ∫ÊØèÂÄãÂêëÈáèÁöÑËº∏ÂÖ•„ÄÇÂàÜÊûêÈ°ØÁ§∫Ôºå‰ΩøÁî®ÂñÆ‰∏ÄÁ≠ñÁï•Ë®ìÁ∑¥Ê®°ÂûãÂèØËÉΩÊúÉÂú®‰∏çÂêåÁöÑË≥áÊñôË°®Á§∫‰∏äÂ∞éËá¥ÊïàËÉΩ‰∏ç‰Ω≥„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÈôêÂà∂ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÁµêÂêàË®ìÁ∑¥Á®ãÂ∫èÔºåÂà©Áî®ÊâÄÊúâ‰∏âÁ®ÆÁ≠ñÁï•‰æÜÊèêÂçáÊ®°ÂûãÁöÑÁ©©ÂÆöÊÄßÂíåÈÅ©ÊáâÊÄß„ÄÇÊ≠§ÊñπÊ≥ïÁöÑÁµêÊûúÈáùÂ∞çÂõõÁ®ÆË™ûË®ÄÔºàËã±Ë™û„ÄÅÊ≥¢Ëò≠Ë™û„ÄÅÊç∑ÂÖãË™ûÂíåÂæ∑Ë™ûÔºâÂú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂëàÁèæÂíåË®éË´ñÔºåË≠âÊòé‰∫ÜÁµêÂêàÁ≠ñÁï•ÁöÑÊïàËÉΩ„ÄÇ

##### **TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification**
2406.17473v1 by Joshua Niemeijer, Jan Ehrhardt, Hristina Uzunova, Heinz Handels

The usage of medical image data for the training of large-scale machine
learning approaches is particularly challenging due to its scarce availability
and the costly generation of data annotations, typically requiring the
engagement of medical professionals. The rapid development of generative models
allows towards tackling this problem by leveraging large amounts of realistic
synthetically generated data for the training process. However, randomly
choosing synthetic samples, might not be an optimal strategy.
  In this work, we investigate the targeted generation of synthetic training
data, in order to improve the accuracy and robustness of image classification.
Therefore, our approach aims to guide the generative model to synthesize data
with high epistemic uncertainty, since large measures of epistemic uncertainty
indicate underrepresented data points in the training set. During the image
generation we feed images reconstructed by an auto encoder into the classifier
and compute the mutual information over the class-probability distribution as a
measure for uncertainty.We alter the feature space of the autoencoder through
an optimization process with the objective of maximizing the classifier
uncertainty on the decoded image. By training on such data we improve the
performance and robustness against test time data augmentations and adversarial
attacks on several classifications tasks.

ÊëòË¶ÅÔºöÁî±ÊñºÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñôÁöÑÂèñÂæó‰∏çÊòìÔºå‰∏îË≥áÊñôÊ®ôË®ªÁöÑÁî¢ÁîüÊàêÊú¨È´òÊòÇÔºåÈÄöÂ∏∏ÈúÄË¶ÅÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÂèÉËàáÔºåÂõ†Ê≠§‰ΩøÁî®ÈÜ´ÁôÇÂΩ±ÂÉèË≥áÊñô‰æÜË®ìÁ∑¥Â§ßÂûãÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁîüÊàêÂºèÊ®°ÂûãÁöÑÂø´ÈÄüÁôºÂ±ïÔºåÂÖÅË®±ÈÄèÈÅéÂà©Áî®Â§ßÈáèÈÄºÁúüÁöÑÂêàÊàêË≥áÊñô‰æÜË®ìÁ∑¥ÊµÅÁ®ãÔºå‰ª•Ëß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÈö®Ê©üÈÅ∏ÊìáÂêàÊàêÊ®£Êú¨ÂèØËÉΩ‰∏çÊòØÊúÄ‰Ω≥Á≠ñÁï•„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂ÂêàÊàêË®ìÁ∑¥Ë≥áÊñôÁöÑÁõÆÊ®ôÁîüÊàêÔºå‰ª•ÊèêÈ´òÂΩ±ÂÉèÂàÜÈ°ûÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊó®Âú®ÂºïÂ∞éÁîüÊàêÂºèÊ®°ÂûãÂêàÊàêÂÖ∑ÊúâÈ´òË™çË≠òË´ñ‰∏çÁ¢∫ÂÆöÊÄßÁöÑË≥áÊñôÔºåÂõ†ÁÇ∫Ë™çË≠òË´ñ‰∏çÁ¢∫ÂÆöÊÄßÁöÑÈ´òÊåáÊ®ôË°®Á§∫Ë®ìÁ∑¥ÈõÜ‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑË≥áÊñôÈªû„ÄÇÂú®ÂΩ±ÂÉèÁîüÊàêÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëÂ∞áËá™ÂãïÁ∑®Á¢ºÂô®ÈáçÂª∫ÁöÑÂΩ±ÂÉèËº∏ÂÖ•ÂàÜÈ°ûÂô®Ôºå‰∏¶Ë®àÁÆóÈ°ûÂà•Ê©üÁéáÂàÜ‰ΩàÁöÑ‰∫íË≥áË®ä‰ΩúÁÇ∫‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊåáÊ®ô„ÄÇÊàëÂÄëÈÄèÈÅéÂÑ™ÂåñÊµÅÁ®ã‰æÜÊîπËÆäËá™ÂãïÁ∑®Á¢ºÂô®ÁöÑÁâπÂæµÁ©∫ÈñìÔºåÁõÆÊ®ôÊòØÊúÄÂ§ßÂåñËß£Á¢ºÂΩ±ÂÉè‰∏äÂàÜÈ°ûÂô®ÁöÑÊú™Á¢∫ÂÆöÊÄß„ÄÇÈÄèÈÅéË®ìÁ∑¥Ê≠§È°ûË≥áÊñôÔºåÊàëÂÄëÊîπÂñÑ‰∫ÜÂú®Â§öÈ†ÖÂàÜÈ°û‰ªªÂãô‰∏≠Â∞çÊ∏¨Ë©¶ÊôÇÈñìË≥áÊñôÊì¥ÂÖÖÂíåÂ∞çÊäóÊîªÊìäÁöÑÊïàËÉΩÂíåÁ©©ÂÅ•ÊÄß„ÄÇ

##### **Dynamic Scheduling for Vehicle-to-Vehicle Communications Enhanced Federated Learning**
2406.17470v1 by Jintao Yan, Tan Chen, Yuxuan Sun, Zhaojun Nan, Sheng Zhou, Zhisheng Niu

Leveraging the computing and sensing capabilities of vehicles, vehicular
federated learning (VFL) has been applied to edge training for connected
vehicles. The dynamic and interconnected nature of vehicular networks presents
unique opportunities to harness direct vehicle-to-vehicle (V2V) communications,
enhancing VFL training efficiency. In this paper, we formulate a stochastic
optimization problem to optimize the VFL training performance, considering the
energy constraints and mobility of vehicles, and propose a V2V-enhanced dynamic
scheduling (VEDS) algorithm to solve it. The model aggregation requirements of
VFL and the limited transmission time due to mobility result in a stepwise
objective function, which presents challenges in solving the problem. We thus
propose a derivative-based drift-plus-penalty method to convert the long-term
stochastic optimization problem to an online mixed integer nonlinear
programming (MINLP) problem, and provide a theoretical analysis to bound the
performance gap between the online solution and the offline optimal solution.
Further analysis of the scheduling priority reduces the original problem into a
set of convex optimization problems, which are efficiently solved using the
interior-point method. Experimental results demonstrate that compared with the
state-of-the-art benchmarks, the proposed algorithm enhances the image
classification accuracy on the CIFAR-10 dataset by 3.18% and reduces the
average displacement errors on the Argoverse trajectory prediction dataset by
10.21%.

ÊëòË¶ÅÔºö<paragraph>Âà©Áî®ËªäËºõÁöÑË®àÁÆóÂíåÊÑüÊ∏¨ËÉΩÂäõÔºåËªäËºõËÅØÈÇ¶Â≠∏Áøí (VFL) Â∑≤ÊáâÁî®ÊñºÈÄ£Á∂≤ËªäËºõÁöÑÈÇäÁ∑£Ë®ìÁ∑¥„ÄÇËªäËºõÁ∂≤Ë∑ØÁöÑÂãïÊÖãÂíå‰∫íÈÄ£ÁâπÊÄßÊèê‰æõ‰∫ÜÂà©Áî®ËªäÂ∞çËªä (V2V) Áõ¥Êé•ÈÄöË®äÁöÑÁç®ÁâπÊ©üÊúÉÔºåÈÄ≤ËÄåÊèêÂçá VFL Ë®ìÁ∑¥ÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÈö®Ê©üÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºå‰ª•ÊúÄ‰Ω≥Âåñ VFL Ë®ìÁ∑¥ÊïàËÉΩÔºåËÄÉÈáèËªäËºõÁöÑËÉΩÊ∫êÈôêÂà∂ÂíåÊµÅÂãïÊÄßÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄã V2V Â¢ûÂº∑ÂãïÊÖãÊéíÁ®ã (VEDS) ÊºîÁÆóÊ≥ï‰æÜËß£Ê±∫ÂÆÉ„ÄÇVFL ÁöÑÊ®°ÂûãËÅöÂêàÈúÄÊ±ÇÂíåÊµÅÂãïÊÄßÈÄ†ÊàêÁöÑÂÇ≥Ëº∏ÊôÇÈñìÊúâÈôêÔºåÂ∞éËá¥‰∏ÄÂÄãÈöéÊ¢ØÂºèÁõÆÊ®ôÂáΩÊï∏ÔºåÈÄôÂú®Ëß£Ê±∫ÂïèÈ°åÊôÇÂ∏∂‰æÜÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂ∞éÊï∏ÁöÑÊºÇÁßªÂä†Êá≤ÁΩ∞ÊñπÊ≥ïÔºåÂ∞áÈï∑ÊúüÈö®Ê©üÊúÄ‰Ω≥ÂåñÂïèÈ°åËΩâÊèõÁÇ∫‰∏ÄÂÄãÁ∑ö‰∏äÊ∑∑ÂêàÊï¥Êï∏ÈùûÁ∑öÊÄßË¶èÂäÉ (MINLP) ÂïèÈ°åÔºå‰∏¶Êèê‰æõ‰∏ÄÂÄãÁêÜË´ñÂàÜÊûê‰æÜÁïåÂÆöÁ∑ö‰∏äËß£ËàáÈõ¢Á∑öÊúÄ‰Ω≥Ëß£‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêÊéíÁ®ãÂÑ™ÂÖàÈ†ÜÂ∫èÔºåÂ∞áÂéüÂßãÂïèÈ°åÁ∞°ÂåñÁÇ∫‰∏ÄÁµÑÂá∏ÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºå‰ΩøÁî®ÂÖßÈªûÊ≥ïÊúâÊïàÂú∞Ëß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïÂ∞á CIFAR-10 Ë≥áÊñôÈõÜ‰∏äÁöÑÂΩ±ÂÉèÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 3.18%Ôºå‰∏¶Â∞á Argoverse ËªåË∑°È†êÊ∏¨Ë≥áÊñôÈõÜ‰∏äÁöÑÂπ≥Âùá‰ΩçÁßªË™§Â∑ÆÈôç‰Ωé‰∫Ü 10.21%„ÄÇ</paragraph>

##### **Enhancing Tool Retrieval with Iterative Feedback from Large Language Models**
2406.17465v1 by Qiancheng Xu, Yongqi Li, Heming Xia, Wenjie Li

Tool learning aims to enhance and expand large language models' (LLMs)
capabilities with external tools, which has gained significant attention
recently. Current methods have shown that LLMs can effectively handle a certain
amount of tools through in-context learning or fine-tuning. However, in
real-world scenarios, the number of tools is typically extensive and
irregularly updated, emphasizing the necessity for a dedicated tool retrieval
component. Tool retrieval is nontrivial due to the following challenges: 1)
complex user instructions and tool descriptions; 2) misalignment between tool
retrieval and tool usage models. To address the above issues, we propose to
enhance tool retrieval with iterative feedback from the large language model.
Specifically, we prompt the tool usage model, i.e., the LLM, to provide
feedback for the tool retriever model in multi-round, which could progressively
improve the tool retriever's understanding of instructions and tools and reduce
the gap between the two standalone components. We build a unified and
comprehensive benchmark to evaluate tool retrieval models. The extensive
experiments indicate that our proposed approach achieves advanced performance
in both in-domain evaluation and out-of-domain evaluation.

ÊëòË¶ÅÔºöÂ∑•ÂÖ∑Â≠¶‰π†Êó®Âú®ÈÄöËøáÂ§ñÈÉ®Â∑•ÂÖ∑Â¢ûÂº∫ÂíåÊâ©Â±ïÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÂäüËÉΩÔºåËøôÊúÄËøëÂºïËµ∑‰∫ÜÊûÅÂ§ßÁöÑÂÖ≥Ê≥®„ÄÇÂΩìÂâçÁöÑÊñπÊ≥ïË°®ÊòéÔºåLLM ÂèØ‰ª•ÈÄöËøá‰∏ä‰∏ãÊñáÂ≠¶‰π†ÊàñÂæÆË∞ÉÊù•ÊúâÊïàÂ§ÑÁêÜ‰∏ÄÂÆöÊï∞ÈáèÁöÑÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÔºåÂ∑•ÂÖ∑ÁöÑÊï∞ÈáèÈÄöÂ∏∏ÂæàÂ§ß‰∏îÊõ¥Êñ∞‰∏çËßÑÂæãÔºåÂº∫Ë∞É‰∫Ü‰∏ìÈó®ÁöÑÂ∑•ÂÖ∑Ê£ÄÁ¥¢ÁªÑ‰ª∂ÁöÑÂøÖË¶ÅÊÄß„ÄÇÁî±‰∫é‰ª•‰∏ãÊåëÊàòÔºåÂ∑•ÂÖ∑Ê£ÄÁ¥¢Âπ∂ÈùûÊòì‰∫ãÔºö1) Â§çÊùÇÁöÑÁî®Êà∑Êåá‰ª§ÂíåÂ∑•ÂÖ∑ÊèèËø∞Ôºõ2) Â∑•ÂÖ∑Ê£ÄÁ¥¢ÂíåÂ∑•ÂÖ∑‰ΩøÁî®Ê®°Âûã‰πãÈó¥ÁöÑ‰∏ç‰∏ÄËá¥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥‰∏äËø∞ÈóÆÈ¢òÔºåÊàë‰ª¨Âª∫ËÆÆ‰ΩøÁî®Êù•Ëá™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑËø≠‰ª£ÂèçÈ¶àÊù•Â¢ûÂº∫Â∑•ÂÖ∑Ê£ÄÁ¥¢„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÊèêÁ§∫Â∑•ÂÖ∑‰ΩøÁî®Ê®°ÂûãÔºåÂç≥ LLMÔºåÂú®Â§öËΩÆ‰∏≠‰∏∫Â∑•ÂÖ∑Ê£ÄÁ¥¢Âô®Ê®°ÂûãÊèê‰æõÂèçÈ¶àÔºåËøôÂèØ‰ª•ÈÄêÊ≠•ÊèêÈ´òÂ∑•ÂÖ∑Ê£ÄÁ¥¢Âô®ÂØπÊåá‰ª§ÂíåÂ∑•ÂÖ∑ÁöÑÁêÜËß£ÔºåÂπ∂Áº©Â∞è‰∏§‰∏™Áã¨Á´ãÁªÑ‰ª∂‰πãÈó¥ÁöÑÂ∑ÆË∑ù„ÄÇÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Áªü‰∏Ä‰∏îÂÖ®Èù¢ÁöÑÂü∫ÂáÜÊù•ËØÑ‰º∞Â∑•ÂÖ∑Ê£ÄÁ¥¢Ê®°Âûã„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®ÂüüÂÜÖËØÑ‰º∞ÂíåÂüüÂ§ñËØÑ‰º∞‰∏≠ÈÉΩÂèñÂæó‰∫ÜÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

##### **The Tree of Diffusion Life: Evolutionary Embeddings to Understand the Generation Process of Diffusion Models**
2406.17462v1 by Vidya Prasad, Hans van Gorp, Christina Humer, Anna Vilanova, Nicola Pezzotti

Diffusion models generate high-quality samples by corrupting data with
Gaussian noise and iteratively reconstructing it with deep learning, slowly
transforming noisy images into refined outputs. Understanding this data
evolution is important for interpretability but is complex due to its
high-dimensional evolutionary nature. While traditional dimensionality
reduction methods like t-distributed stochastic neighborhood embedding (t-SNE)
aid in understanding high-dimensional spaces, they neglect evolutionary
structure preservation. Hence, we propose Tree of Diffusion Life (TDL), a
method to understand data evolution in the generative process of diffusion
models. TDL samples a diffusion model's generative space via instances with
varying prompts and employs image encoders to extract semantic meaning from
these samples, projecting them to an intermediate space. It employs a novel
evolutionary embedding algorithm that explicitly encodes the iterations while
preserving the high-dimensional relations, facilitating the visualization of
data evolution. This embedding leverages three metrics: a standard t-SNE loss
to group semantically similar elements, a displacement loss to group elements
from the same iteration step, and an instance alignment loss to align elements
of the same instance across iterations. We present rectilinear and radial
layouts to represent iterations, enabling comprehensive exploration. We assess
various feature extractors and highlight TDL's potential with prominent
diffusion models like GLIDE and Stable Diffusion with different prompt sets.
TDL simplifies understanding data evolution within diffusion models, offering
valuable insights into their functioning.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÈÄèÈÅéÂä†ÂÖ•È´òÊñØÈõúË®äÂà∞Ë≥áÊñô‰∏≠‰∏¶Áî®Ê∑±Â∫¶Â≠∏ÁøíÂèçË¶ÜÈáçÂª∫Ë≥áÊñôÔºåÁî¢ÁîüÈ´òÂìÅË≥™ÁöÑÊ®£Êú¨Ôºå‰∏¶ÊÖ¢ÊÖ¢Â∞áÊúâÈõúË®äÁöÑÂúñÁâáËΩâÊèõÊàêÁ≤æÁ∑ªÁöÑËº∏Âá∫„ÄÇ‰∫ÜËß£ÈÄôÁ®ÆË≥áÊñôÊºîÂåñÂ∞çÊñºÂèØËß£ÈáãÊÄßÂæàÈáçË¶ÅÔºå‰ΩÜÁî±ÊñºÂÖ∂È´òÁ∂≠Â∫¶ÁöÑÊºîÂåñÊÄßË≥™ÔºåÈÄôÂæàË§áÈõú„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÁöÑÈôçÁ∂≠ÊñπÊ≥ïÔºå‰æãÂ¶Ç t ÂàÜ‰ΩàÈö®Ê©üÈÑ∞ÂüüÂµåÂÖ• (t-SNE)ÔºåÊúâÂä©ÊñºÁêÜËß£È´òÁ∂≠Â∫¶Á©∫ÈñìÔºå‰ΩÜÂÆÉÂÄëÂøΩÁï•‰∫ÜÊºîÂåñÁµêÊßãÁöÑ‰øùÂ≠ò„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Êì¥Êï£ÁîüÂëΩÊ®π (TDL)Ôºå‰∏ÄÁ®Æ‰∫ÜËß£Êì¥Êï£Ê®°ÂûãÁîüÊàêÈÅéÁ®ã‰∏≠Ë≥áÊñôÊºîÂåñÁöÑÊñπÊ≥ï„ÄÇTDL ÈÄèÈÅéÂÖ∑Êúâ‰∏çÂêåÊèêÁ§∫ÁöÑÂØ¶‰æãÂèñÊ®£Êì¥Êï£Ê®°ÂûãÁöÑÁîüÊàêÁ©∫ÈñìÔºå‰∏¶‰ΩøÁî®ÂΩ±ÂÉèÁ∑®Á¢ºÂô®ÂæûÈÄô‰∫õÊ®£Êú¨‰∏≠ÊèêÂèñË™ûÁæ©ÊÑèÁæ©ÔºåÂ∞áÂÆÉÂÄëÊäïÂΩ±Âà∞‰∏≠ÈñìÁ©∫Èñì„ÄÇÂÆÉÊé°Áî®‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊºîÂåñÂµåÂÖ•ÊºîÁÆóÊ≥ïÔºåÂú®‰øùÁïôÈ´òÁ∂≠Â∫¶Èóú‰øÇÁöÑÂêåÊôÇÊòéÁ¢∫Á∑®Á¢ºËø≠‰ª£Ôºå‰øÉÈÄ≤Ë≥áÊñôÊºîÂåñÁöÑË¶ñË¶∫Âåñ„ÄÇÊ≠§ÂµåÂÖ•Âà©Áî®‰∏âÂÄãÊåáÊ®ôÔºöÊ®ôÊ∫ñ t-SNE ÊêçÂ§±ÂáΩÊï∏‰æÜÂ∞áË™ûÁæ©Áõ∏‰ººÁöÑÂÖÉÁ¥†ÂàÜÁµÑ„ÄÅ‰ΩçÁßªÊêçÂ§±ÂáΩÊï∏‰æÜÂ∞á‰æÜËá™Áõ∏ÂêåËø≠‰ª£Ê≠•È©üÁöÑÂÖÉÁ¥†ÂàÜÁµÑÔºå‰ª•ÂèäÂØ¶‰æãÂ∞çÈΩäÊêçÂ§±ÂáΩÊï∏‰æÜÂ∞çÈΩäÂêå‰∏ÄÂØ¶‰æã‰∏≠Ë∑®Ëø≠‰ª£ÁöÑÂÖÉÁ¥†„ÄÇÊàëÂÄëÊèêÂá∫Áõ¥Á∑öÂíåÂæëÂêë‰ΩàÂ±Ä‰æÜË°®Á§∫Ëø≠‰ª£ÔºåÂØ¶ÁèæÂÖ®Èù¢ÁöÑÊé¢Á¥¢„ÄÇÊàëÂÄëË©ï‰º∞ÂêÑÁ®ÆÁâπÂæµËêÉÂèñÂô®Ôºå‰∏¶Âº∑Ë™ø TDL Âú®ÂÖ∑Êúâ‰∏çÂêåÊèêÁ§∫ÈõÜÁöÑ GLIDE Âíå Stable Diffusion Á≠âÈ°ØËëóÊì¥Êï£Ê®°Âûã‰∏≠ÁöÑÊΩõÂäõ„ÄÇTDL Á∞°Âåñ‰∫ÜÂ∞çÊì¥Êï£Ê®°Âûã‰∏≠Ë≥áÊñôÊºîÂåñÁöÑÁêÜËß£ÔºåÊèê‰æõ‰∫ÜÂ∞çÂÖ∂ÈÅã‰ΩúÁöÑÂØ∂Ë≤¥Ë¶ãËß£„ÄÇ

##### **Improving Grammatical Error Correction via Contextual Data Augmentation**
2406.17456v1 by Yixuan Wang, Baoxin Wang, Yijun Liu, Qingfu Zhu, Dayong Wu, Wanxiang Che

Nowadays, data augmentation through synthetic data has been widely used in
the field of Grammatical Error Correction (GEC) to alleviate the problem of
data scarcity. However, these synthetic data are mainly used in the
pre-training phase rather than the data-limited fine-tuning phase due to
inconsistent error distribution and noisy labels. In this paper, we propose a
synthetic data construction method based on contextual augmentation, which can
ensure an efficient augmentation of the original data with a more consistent
error distribution. Specifically, we combine rule-based substitution with
model-based generation, using the generative model to generate a richer context
for the extracted error patterns. Besides, we also propose a relabeling-based
data cleaning method to mitigate the effects of noisy labels in synthetic data.
Experiments on CoNLL14 and BEA19-Test show that our proposed augmentation
method consistently and substantially outperforms strong baselines and achieves
the state-of-the-art level with only a few synthetic data.

ÊëòË¶ÅÔºöÂ¶Ç‰ªäÔºåÈÄèÈÅéÂêàÊàêË≥áÊñôÈÄ≤Ë°åË≥áÊñôÊì¥Â¢ûÂ∑≤Âª£Ê≥õÁî®ÊñºÊñáÊ≥ïÈåØË™§‰øÆÊ≠£ (GEC) È†òÂüüÔºå‰ª•Ê∏õËºïË≥áÊñôÁ®ÄÂ∞ëÁöÑÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂêàÊàêË≥áÊñô‰∏ªË¶ÅÁî®ÊñºÈ†êË®ìÁ∑¥ÈöéÊÆµÔºåËÄåÈùûË≥áÊñôÊúâÈôêÁöÑÂæÆË™øÈöéÊÆµÔºåÂéüÂõ†Âú®ÊñºÈåØË™§ÂàÜ‰Ωà‰∏ç‰∏ÄËá¥‰∏îÊ®ôÁ±§ÊúâÈõúË®ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºËÑàÁµ°Êì¥Â¢ûÁöÑÂêàÊàêË≥áÊñôÂª∫ÊßãÊñπÊ≥ïÔºåÈÄôÂèØ‰ª•Á¢∫‰øù‰ª•Êõ¥‰∏ÄËá¥ÁöÑÈåØË™§ÂàÜ‰ΩàÊúâÊïàÊì¥Â¢ûÂéüÂßãË≥áÊñô„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÂü∫ÊñºË¶èÂâáÁöÑÊõøÊèõËàáÂü∫ÊñºÊ®°ÂûãÁöÑÁîüÊàêÁµêÂêàËµ∑‰æÜÔºå‰ΩøÁî®ÁîüÊàêÊ®°Âûã‰æÜÁÇ∫ÊèêÂèñÁöÑÈåØË™§Ê®°ÂºèÁîüÊàêÊõ¥Ë±êÂØåÁöÑËÑàÁµ°„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈáçÊñ∞Ê®ôË®òÁöÑË≥áÊñôÊ∏ÖÁêÜÊñπÊ≥ïÔºå‰ª•Ê∏õËºïÂêàÊàêË≥áÊñô‰∏≠ÈõúË®äÊ®ôÁ±§ÁöÑÂΩ±Èüø„ÄÇÂú® CoNLL14 Âíå BEA19-Test ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊì¥Â¢ûÊñπÊ≥ïÂßãÁµÇ‰∏îÂ§ßÂπÖÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñÔºå‰∏îÂÉÖ‰ΩøÁî®Â∞ëÈáèÁöÑÂêàÊàêË≥áÊñôÂ∞±ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊ∞¥Âπ≥„ÄÇ

##### **Learning to Ask Informative Questions: Enhancing LLMs with Preference Optimization and Expected Information Gain**
2406.17453v1 by Davide Mazzaccara, Alberto Testoni, Raffaella Bernardi

Questions are essential tools for acquiring the necessary information to
complete information-seeking tasks. However, large language models (LLMs),
especially open-source models, often perform poorly in generating informative
questions, as measured by expected information gain (EIG). In this paper, we
propose a method to enhance the informativeness of LLM-generated questions in
20-question game dialogues. We sample multiple questions from the same model
(LLAMA 2-CHAT 7B) for each game and create pairs of low-EIG and high-EIG
questions to apply a Direct Preference Optimization (DPO) algorithm. Our
results show that this method produces more effective questions (in terms of
EIG), even in domains different from those used to train the DPO model.

ÊëòË¶ÅÔºöÂïèÈ°åÊòØÁç≤ÂèñÂÆåÊàêË≥áË®äÂ∞ãÊ±Ç‰ªªÂãôÊâÄÈúÄË≥áË®äÁöÑÂü∫Êú¨Â∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÁâπÂà•ÊòØÈñãÊ∫êÊ®°ÂûãÔºåÂú®Áî¢ÁîüË≥áË®äÊÄßÂïèÈ°åÊñπÈù¢ÂæÄÂæÄË°®Áèæ‰∏ç‰Ω≥ÔºåËÄåË≥áË®äÂ¢ûÁõäÈ†êÊúüÂÄº (EIG) ÊòØË°°ÈáèÊ®ôÊ∫ñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ï‰æÜÂ¢ûÂº∑ LLM ÁîüÊàêÁöÑÂïèÈ°åÂú® 20 È°åÂïèÁ≠îÂ∞çË©±‰∏≠ÁöÑË≥áË®äÊÄß„ÄÇÊàëÂÄëÂæûÂêå‰∏ÄÂÄãÊ®°ÂûãÔºàLLAMA 2-CHAT 7BÔºâÁÇ∫ÊØèÂÄãÈÅäÊà≤ÊäΩÊ®£Â§öÂÄãÂïèÈ°åÔºå‰∏¶Âª∫Á´ã‰Ωé EIG ÂíåÈ´ò EIG ÂïèÈ°åÂ∞çÔºå‰ª•ÊáâÁî®Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) ÊºîÁÆóÊ≥ï„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊ≠§ÊñπÊ≥ïÁî¢Áîü‰∫ÜÊõ¥ÊúâÊïàÁöÑÂïèÈ°åÔºàÊ†πÊìö EIGÔºâÔºåÂç≥‰ΩøÂú®ËàáÁî®ÊñºË®ìÁ∑¥ DPO Ê®°Âûã‰∏çÂêåÁöÑÈ†òÂüü‰∏≠‰πüÊòØÂ¶ÇÊ≠§„ÄÇ

##### **Pseudo Labelling for Enhanced Masked Autoencoders**
2406.17450v1 by Srinivasa Rao Nandam, Sara Atito, Zhenhua Feng, Josef Kittler, Muhammad Awais

Masked Image Modeling (MIM)-based models, such as SdAE, CAE, GreenMIM, and
MixAE, have explored different strategies to enhance the performance of Masked
Autoencoders (MAE) by modifying prediction, loss functions, or incorporating
additional architectural components. In this paper, we propose an enhanced
approach that boosts MAE performance by integrating pseudo labelling for both
class and data tokens, alongside replacing the traditional pixel-level
reconstruction with token-level reconstruction. This strategy uses cluster
assignments as pseudo labels to promote instance-level discrimination within
the network, while token reconstruction requires generation of discrete tokens
encapturing local context. The targets for pseudo labelling and reconstruction
needs to be generated by a teacher network. To disentangle the generation of
target pseudo labels and the reconstruction of the token features, we decouple
the teacher into two distinct models, where one serves as a labelling teacher
and the other as a reconstruction teacher. This separation proves empirically
superior to a single teacher, while having negligible impact on throughput and
memory consumption. Incorporating pseudo-labelling as an auxiliary task has
demonstrated notable improvements in ImageNet-1K and other downstream tasks,
including classification, semantic segmentation, and detection.

ÊëòË¶ÅÔºöÂü∫ÊñºÈÅÆÁΩ©ÂúñÂÉèÂª∫Ê®° (MIM) ÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç SdAE„ÄÅCAE„ÄÅGreenMIM Âíå MixAEÔºåÂ∑≤Êé¢Á¥¢‰∏çÂêåÁöÑÁ≠ñÁï•ÔºåËóâÁî±‰øÆÊîπÈ†êÊ∏¨„ÄÅÊêçÂ§±ÂáΩÊï∏ÊàñÊï¥ÂêàÈ°çÂ§ñÁöÑÊû∂ÊßãÂÖÉ‰ª∂‰æÜÊèêÂçáÈÅÆÁΩ©Ëá™ÂãïÁ∑®Á¢ºÂô® (MAE) ÁöÑÊïàËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂ¢ûÂº∑ÊñπÊ≥ïÔºåÈÄèÈÅéÊï¥ÂêàÈ°ûÂà•ÂíåË≥áÊñô‰ª£Á¢ºÁöÑÂÅΩÊ®ôÁ±§Ôºå‰ª•ÂèäÁî®‰ª£Á¢ºÂ±§Á¥öÈáçÂª∫Âèñ‰ª£ÂÇ≥Áµ±ÁöÑÂÉèÁ¥†Â±§Á¥öÈáçÂª∫Ôºå‰æÜÊèêÂçá MAE ÊïàËÉΩ„ÄÇÊ≠§Á≠ñÁï•‰ΩøÁî®Âè¢ÈõÜÂàÜÈÖç‰ΩúÁÇ∫ÂÅΩÊ®ôÁ±§Ôºå‰ª•‰øÉÈÄ≤Á∂≤Ë∑ØÂÖßÁöÑÂØ¶‰æãÂ±§Á¥öËæ®Âà•ÔºåËÄå‰ª£Á¢ºÈáçÂª∫ÂâáÈúÄË¶ÅÁî¢ÁîüÊì∑ÂèñÂ±ÄÈÉ®ÂÖßÂÆπÁöÑÈõ¢Êï£‰ª£Á¢º„ÄÇÂÅΩÊ®ôÁ±§ÂíåÈáçÂª∫ÁöÑÁõÆÊ®ôÈúÄË¶ÅÁî±ÊïôÂ∏´Á∂≤Ë∑ØÁî¢Áîü„ÄÇÁÇ∫‰∫ÜËß£ÈñãÁõÆÊ®ôÂÅΩÊ®ôÁ±§ÁöÑÁî¢ÁîüÂíå‰ª£Á¢ºÁâπÂæµÁöÑÈáçÂª∫ÔºåÊàëÂÄëÂ∞áÊïôÂ∏´Ëß£ËÄ¶ÊàêÂÖ©ÂÄã‰∏çÂêåÁöÑÊ®°ÂûãÔºåÂÖ∂‰∏≠‰∏ÄÂÄã‰ΩúÁÇ∫Ê®ôÁ±§ÊïôÂ∏´ÔºåÂè¶‰∏ÄÂÄã‰ΩúÁÇ∫ÈáçÂª∫ÊïôÂ∏´„ÄÇÊ≠§ÂàÜÈõ¢Á∂ìÈÅéÂØ¶Ë≠âË≠âÊòéÂÑ™ÊñºÂñÆ‰∏ÄÊïôÂ∏´ÔºåÂêåÊôÇÂ∞çÂêûÂêêÈáèÂíåË®òÊÜ∂È´îÊ∂àËÄóÁöÑÂΩ±ÈüøÂèØ‰ª•ÂøΩÁï•‰∏çË®à„ÄÇÂ∞áÂÅΩÊ®ôÁ±§Á¥çÂÖ•ËºîÂä©‰ªªÂãôÂ∑≤Ë≠âÂØ¶È°ØËëóÊèêÂçá ImageNet-1K ÂíåÂÖ∂‰ªñ‰∏ãÊ∏∏‰ªªÂãôÔºåÂåÖÊã¨ÂàÜÈ°û„ÄÅË™ûÊÑèÂàÜÂâ≤ÂíåÂÅµÊ∏¨„ÄÇ

##### **Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights**
2406.17430v1 by Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari

Large Multimodal Models (LMMs) have achieved great success recently,
demonstrating a strong capability to understand multimodal information and to
interact with human users. Despite the progress made, the challenge of
detecting high-risk interactions in multimodal settings, and in particular in
speech modality, remains largely unexplored. Conventional research on risk for
speech modality primarily emphasises the content (e.g., what is captured as
transcription). However, in speech-based interactions, paralinguistic cues in
audio can significantly alter the intended meaning behind utterances. In this
work, we propose a speech-specific risk taxonomy, covering 8 risk categories
under hostility (malicious sarcasm and threats), malicious imitation (age,
gender, ethnicity), and stereotypical biases (age, gender, ethnicity). Based on
the taxonomy, we create a small-scale dataset for evaluating current LMMs
capability in detecting these categories of risk. We observe even the latest
models remain ineffective to detect various paralinguistic-specific risks in
speech (e.g., Gemini 1.5 Pro is performing only slightly above random
baseline). Warning: this paper contains biased and offensive examples.

ÊëòË¶ÅÔºöÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã (LMM) ËøëÊù•ÂèñÂæóÂ∑®Â§ßÊàêÂäüÔºå
Â±ïÁ§∫Âá∫ÁêÜËß£Â§öÊ®°ÊÄÅ‰ø°ÊÅØÂíå‰∏é‰∫∫Á±ªÁî®Êà∑‰∫§‰∫íÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫ÜËøõÂ±ïÔºå
Âú®Â§öÊ®°ÊÄÅËÆæÁΩÆ‰∏≠Ê£ÄÊµãÈ´òÈ£éÈô©‰∫§‰∫íÁöÑÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®
ËØ≠Èü≥Ê®°ÊÄÅ‰∏≠ÔºåÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞Êé¢Á¥¢„ÄÇÈíàÂØπ
ËØ≠Èü≥Ê®°ÊÄÅÁöÑÈ£éÈô©ÁöÑ‰º†ÁªüÁ†îÁ©∂‰∏ªË¶ÅÂº∫Ë∞ÉÂÜÖÂÆπÔºà‰æãÂ¶ÇÔºåÊçïËé∑‰∏∫
ËΩ¨ÂΩïÁöÑÂÜÖÂÆπÔºâ„ÄÇÁÑ∂ËÄåÔºåÂú®Âü∫‰∫éËØ≠Èü≥ÁöÑ‰∫§‰∫í‰∏≠Ôºå
Èü≥È¢ë‰∏≠ÁöÑÂâØËØ≠Ë®ÄÁ∫øÁ¥¢ÂèØ‰ª•ÊòæËëóÊîπÂèòËØùËØ≠ËÉåÂêéÁöÑÈ¢ÑÊúüÂê´‰πâ„ÄÇÂú®Ëøô
È°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÁâπÂÆö‰∫éËØ≠Èü≥ÁöÑÈ£éÈô©ÂàÜÁ±ªÊ≥ïÔºåÊ∂µÁõñ‰∫ÜÊïåÊÑèÔºàÊÅ∂ÊÑèËÆΩÂà∫ÂíåÂ®ÅËÉÅÔºâ„ÄÅÊÅ∂ÊÑèÊ®°‰ªøÔºàÂπ¥ÈæÑ„ÄÅ
ÊÄßÂà´„ÄÅÁßçÊóèÔºâÂíåÂàªÊùøÂÅèËßÅÔºàÂπ¥ÈæÑ„ÄÅÊÄßÂà´„ÄÅÁßçÊóèÔºâ‰∏ãÁöÑ 8 ‰∏™È£éÈô©Á±ªÂà´„ÄÇÂü∫‰∫é
ÂàÜÁ±ªÊ≥ïÔºåÊàë‰ª¨ÂàõÂª∫‰∫Ü‰∏Ä‰∏™Â∞èËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÁî®‰∫éËØÑ‰º∞ÂΩìÂâç LMM
Ê£ÄÊµãËøô‰∫õÈ£éÈô©Á±ªÂà´ÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ËßÇÂØüÂà∞ÔºåÂç≥‰ΩøÊòØÊúÄÊñ∞ÁöÑ
Ê®°ÂûãÂú®Ê£ÄÊµãËØ≠Èü≥‰∏≠ÁöÑÂêÑÁßçÁâπÂÆö‰∫éÂâØËØ≠Ë®ÄÁöÑÈ£éÈô©ÊñπÈù¢‰ªçÁÑ∂Êó†Êïà
Ôºà‰æãÂ¶ÇÔºåGemini 1.5 Pro ÁöÑË°®Áé∞‰ªÖÁï•È´ò‰∫éÈöèÊú∫
Âü∫Á∫øÔºâ„ÄÇË≠¶ÂëäÔºöÊú¨ÊñáÂåÖÂê´ÊúâÂÅèËßÅÂíåÂÜíÁäØÊÄßÁöÑÁ§∫‰æã„ÄÇ

##### **CuDA2: An approach for Incorporating Traitor Agents into Cooperative Multi-Agent Systems**
2406.17425v1 by Zhen Chen, Yong Liao, Youpeng Zhao, Zipeng Dai, Jian Zhao

Cooperative Multi-Agent Reinforcement Learning (CMARL) strategies are well
known to be vulnerable to adversarial perturbations. Previous works on
adversarial attacks have primarily focused on white-box attacks that directly
perturb the states or actions of victim agents, often in scenarios with a
limited number of attacks. However, gaining complete access to victim agents in
real-world environments is exceedingly difficult. To create more realistic
adversarial attacks, we introduce a novel method that involves injecting
traitor agents into the CMARL system. We model this problem as a Traitor Markov
Decision Process (TMDP), where traitors cannot directly attack the victim
agents but can influence their formation or positioning through collisions. In
TMDP, traitors are trained using the same MARL algorithm as the victim agents,
with their reward function set as the negative of the victim agents' reward.
Despite this, the training efficiency for traitors remains low because it is
challenging for them to directly associate their actions with the victim
agents' rewards. To address this issue, we propose the Curiosity-Driven
Adversarial Attack (CuDA2) framework. CuDA2 enhances the efficiency and
aggressiveness of attacks on the specified victim agents' policies while
maintaining the optimal policy invariance of the traitors. Specifically, we
employ a pre-trained Random Network Distillation (RND) module, where the extra
reward generated by the RND module encourages traitors to explore states
unencountered by the victim agents. Extensive experiments on various scenarios
from SMAC demonstrate that our CuDA2 framework offers comparable or superior
adversarial attack capabilities compared to other baselines.

ÊëòË¶ÅÔºöÂêà‰ΩúÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (CMARL) Á≠ñÁï•Â∑≤Âª£ÁÇ∫‰∫∫Áü•ÔºåÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊìæÂãïÁöÑÂΩ±Èüø„ÄÇÂÖàÂâçÂ∞çÊäóÊÄßÊîªÊìäÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Âú®Áõ¥Êé•ÊìæÂãïÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÁöÑÁãÄÊÖãÊàñÂãï‰ΩúÁöÑÁôΩÁõíÊîªÊìäÔºåÈÄöÂ∏∏Âú®ÊîªÊìäÊ¨°Êï∏ÊúâÈôêÁöÑÂ†¥ÊôØ‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂú®ÁèæÂØ¶Áí∞Â¢É‰∏≠ÂÆåÂÖ®Â≠òÂèñÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÊ•µÁÇ∫Âõ∞Èõ£„ÄÇÁÇ∫‰∫ÜÂâµÈÄ†Êõ¥ÈÄºÁúüÁöÑÂ∞çÊäóÊÄßÊîªÊìäÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂåÖÊã¨Â∞áÂèõÂæíÊô∫ËÉΩÈ´îÊ≥®ÂÖ• CMARL Á≥ªÁµ±„ÄÇÊàëÂÄëÂ∞áÊ≠§ÂïèÈ°åÂª∫Ê®°ÁÇ∫ÂèõÂæíÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (TMDP)ÔºåÂÖ∂‰∏≠ÂèõÂæíÁÑ°Ê≥ïÁõ¥Êé•ÊîªÊìäÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÔºå‰ΩÜÂèØ‰ª•ÈÄèÈÅéÁ¢∞ÊíûÂΩ±ÈüøÂÖ∂ÂΩ¢ÊàêÊàñÂÆö‰Ωç„ÄÇÂú® TMDP ‰∏≠ÔºåÂèõÂæí‰ΩøÁî®ËàáÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÁõ∏ÂêåÁöÑ MARL ÊºîÁÆóÊ≥ïÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂÖ∂ÁçéÂãµÂáΩÊï∏Ë®≠ÂÆöÁÇ∫ÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÁçéÂãµÁöÑË≤†ÂÄº„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂèõÂæíÁöÑË®ìÁ∑¥ÊïàÁéá‰ªçÁÑ∂Âæà‰ΩéÔºåÂõ†ÁÇ∫‰ªñÂÄëÈõ£‰ª•Â∞áËá™Â∑±ÁöÑÂãï‰ΩúÁõ¥Êé•ËàáÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÁöÑÁçéÂãµËÅØÁπ´Ëµ∑‰æÜ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ•ΩÂ•áÂøÉÈ©ÖÂãïÂ∞çÊäóÊÄßÊîªÊìä (CuDA2) Ê°ÜÊû∂„ÄÇCuDA2 ÊèêÈ´ò‰∫ÜÂ∞çÊåáÂÆöÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÁ≠ñÁï•ÁöÑÊîªÊìäÊïàÁéáÂíå‰æµÁï•ÊÄßÔºåÂêåÊôÇÁ∂≠ÊåÅÂèõÂæíÁöÑÊúÄ‰Ω≥Á≠ñÁï•‰∏çËÆäÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÈö®Ê©üÁ∂≤Ë∑ØËí∏È§æ (RND) Ê®°ÁµÑÔºåÂÖ∂‰∏≠ RND Ê®°ÁµÑÁî¢ÁîüÁöÑÈ°çÂ§ñÁçéÂãµÈºìÂãµÂèõÂæíÊé¢Á¥¢ÂèóÂÆ≥ËÄÖÊô∫ËÉΩÈ´îÊú™ÈÅ≠ÈÅáÁöÑÁãÄÊÖã„ÄÇÂú® SMAC ÁöÑÂêÑÁ®ÆÂ†¥ÊôØ‰∏≠ÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåËàáÂÖ∂‰ªñÂü∫Ê∫ñÁõ∏ÊØîÔºåÊàëÂÄëÁöÑ CuDA2 Ê°ÜÊû∂Êèê‰æõ‰∫ÜÁõ∏Áï∂ÊàñÊõ¥ÂÑ™Ë∂äÁöÑÂ∞çÊäóÊÄßÊîªÊìäËÉΩÂäõ„ÄÇ

##### **Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA**
2406.17419v1 by Minzheng Wang, Longze Chen, Cheng Fu, Shengyi Liao, Xinghua Zhang, Bingli Wu, Haiyang Yu, Nan Xu, Lei Zhang, Run Luo, Yunshui Li, Min Yang, Fei Huang, Yongbin Li

Long-context modeling capabilities have garnered widespread attention,
leading to the emergence of Large Language Models (LLMs) with ultra-context
windows. Meanwhile, benchmarks for evaluating long-context LLMs are gradually
catching up. However, existing benchmarks employ irrelevant noise texts to
artificially extend the length of test cases, diverging from the real-world
scenarios of long-context applications. To bridge this gap, we propose a novel
long-context benchmark, Loong, aligning with realistic scenarios through
extended multi-document question answering (QA). Unlike typical document QA, in
Loong's test cases, each document is relevant to the final answer, ignoring any
document will lead to the failure of the answer. Furthermore, Loong introduces
four types of tasks with a range of context lengths: Spotlight Locating,
Comparison, Clustering, and Chain of Reasoning, to facilitate a more realistic
and comprehensive evaluation of long-context understanding. Extensive
experiments indicate that existing long-context language models still exhibit
considerable potential for enhancement. Retrieval augmented generation (RAG)
achieves poor performance, demonstrating that Loong can reliably assess the
model's long-context modeling capabilities.

ÊëòË¶ÅÔºöÈï∑Ë™ûÂ¢ÉÂª∫Ê®°ËÉΩÂäõÂÇôÂèóÈóúÊ≥®Ôºå‰øÉ‰ΩøÂÖ∑ÂÇôË∂ÖÈï∑Ë™ûÂ¢ÉË¶ñÁ™óÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊáâÈÅãËÄåÁîü„ÄÇËàáÊ≠§ÂêåÊôÇÔºåÁî®ÊñºË©ï‰º∞Èï∑Ë™ûÂ¢É LLM ÁöÑÂü∫Ê∫ñ‰πüÈÄêÊº∏Ë∑ü‰∏äËÖ≥Ê≠•„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫Ê∫ñÊé°Áî®ÁÑ°ÈóúÁöÑÈõúË®äÊñáÂ≠ó‰æÜ‰∫∫Â∑•Âª∂Èï∑Ê∏¨Ë©¶Ê°à‰æãÁöÑÈï∑Â∫¶ÔºåÂÅèÈõ¢‰∫ÜÈï∑Ë™ûÂ¢ÉÊáâÁî®Á®ãÂºèÁöÑÁúüÂØ¶Â†¥ÊôØ„ÄÇÁÇ∫‰∫ÜÂΩåÂêàÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÈï∑Ë™ûÂ¢ÉÂü∫Ê∫ñ LoongÔºåÈÄèÈÅéÊì¥Â±ïÁöÑÂ§öÊñá‰ª∂ÂïèÁ≠î (QA) ËàáÁèæÂØ¶Â†¥ÊôØ‰øùÊåÅ‰∏ÄËá¥„ÄÇËàáÂÖ∏ÂûãÁöÑÊñá‰ª∂ÂïèÁ≠î‰∏çÂêåÔºåÂú® Loong ÁöÑÊ∏¨Ë©¶Ê°à‰æã‰∏≠ÔºåÊØèÂÄãÊñá‰ª∂ÈÉΩËàáÊúÄÁµÇÁ≠îÊ°àÁõ∏ÈóúÔºåÂøΩÁï•‰ªª‰ΩïÊñá‰ª∂ÈÉΩÊúÉÂ∞éËá¥Á≠îÊ°àÂ§±Êïó„ÄÇÊ≠§Â§ñÔºåLoong Â∞éÂÖ•‰∫ÜÂõõÁ®ÆÈ°ûÂûãÁöÑ‰ªªÂãôÔºåÊ∂µËìãÁØÑÂúçÂª£Ê≥õÁöÑË™ûÂ¢ÉÈï∑Â∫¶ÔºöÁÑ¶ÈªûÂÆö‰Ωç„ÄÅÊØîËºÉ„ÄÅÂàÜÁæ§ÂíåÊé®ÁêÜÈèàÔºå‰ª•Âà©ÊñºÂ∞çÈï∑Ë™ûÂ¢ÉÁêÜËß£ÈÄ≤Ë°åÊõ¥ÁèæÂØ¶‰∏îÂÖ®Èù¢ÁöÑË©ï‰º∞„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÁèæÊúâÁöÑÈï∑Ë™ûÂ¢ÉË™ûË®ÄÊ®°Âûã‰ªçÊúâÂæàÂ§ßÁöÑÂ¢ûÂº∑ÊΩõÂäõ„ÄÇÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÁöÑË°®Áèæ‰∏ç‰Ω≥ÔºåË≠âÊòé Loong ËÉΩÂ§†ÂèØÈù†Âú∞Ë©ï‰º∞Ê®°ÂûãÁöÑÈï∑Ë™ûÂ¢ÉÂª∫Ê®°ËÉΩÂäõ„ÄÇ

##### **Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing LLMs Beyond Integer Bit-Levels**
2406.17415v2 by Razvan-Gabriel Dumitru, Vikas Yadav, Rishabh Maheshwary, Paul-Ioan Clotan, Sathwik Tejaswi Madhusudhan, Mihai Surdeanu

We present a simple variable quantization approach that quantizes different
layers of a large language model (LLM) at different bit levels. Specifically,
we quantize the most important layers to higher bit precision and less
important layers to lower bits to achieve floating point quantization levels.
We propose two effective strategies to measure the importance of layers within
LLMs: the first measures the importance of a layer based on how different its
output embeddings are from the input embeddings (the higher the better); the
second estimates the importance of a layer using the number of layer weights
that are much larger than average (the smaller the better). We show that
quantizing different layers at varying bits according to our importance scores
results in minimal performance drop with a far more compressed model size.
Finally, we present several practical key takeaways from our variable
layer-wise quantization experiments: (a) LLM performance under variable
quantization remains close to the original model until 25-50% of layers are
moved in lower quantization using our proposed ordering but only until 5-10% if
moved using no specific ordering; (b) Quantizing LLMs to lower bits performs
substantially better than pruning unless extreme quantization (2-bit) is used;
and (c) Layer-wise quantization to lower bits works better in the case of
larger LLMs with more layers compared to smaller LLMs with fewer layers. The
code used to run the experiments is available at:
https://github.com/RazvanDu/LayerwiseQuant.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∞°ÂñÆÁöÑËÆäÊï∏ÈáèÂåñÊñπÊ≥ïÔºå‰ª•‰∏çÂêåÁöÑ‰ΩçÂÖÉÁ¥öÂà•ÈáèÂåñÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑ‰∏çÂêåÂ±§„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÊúÄÈáçË¶ÅÁöÑÂ±§ÈáèÂåñÁÇ∫Êõ¥È´òÁöÑ‰ΩçÂÖÉÁ≤æÂ∫¶ÔºåËÄåÂ∞áËºÉ‰∏çÈáçË¶ÅÁöÑÂ±§ÈáèÂåñÁÇ∫ËºÉ‰ΩéÁöÑ‰ΩçÂÖÉÔºå‰ª•ÂØ¶ÁèæÊµÆÈªûÈáèÂåñÁ¥öÂà•„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©Á®ÆÊúâÊïàÁöÑÁ≠ñÁï•‰æÜË°°Èáè LLM ÂÖßÂ±§ÁöÑÈáçË¶ÅÊÄßÔºöÁ¨¨‰∏ÄÂÄãÁ≠ñÁï•Ê†πÊìöÂ±§ÁöÑËº∏Âá∫ÂµåÂÖ•ËàáËº∏ÂÖ•ÂµåÂÖ•ÁöÑÂ∑ÆÁï∞‰æÜË°°ÈáèÂ±§ÁöÑÈáçË¶ÅÊÄßÔºàÂ∑ÆÁï∞Ë∂äÂ§ßË∂äÂ•ΩÔºâÔºõÁ¨¨‰∫åÂÄãÁ≠ñÁï•‰ΩøÁî®ÈÅ†Â§ßÊñºÂπ≥ÂùáÂÄºÁöÑÂ±§Ê¨äÈáçÁöÑÊï∏Èáè‰æÜ‰º∞Ë®àÂ±§ÁöÑÈáçË¶ÅÊÄßÔºàË∂äÂ∞èË∂äÂ•ΩÔºâ„ÄÇÊàëÂÄëË°®ÊòéÔºåÊ†πÊìöÊàëÂÄëÁöÑÈáçË¶ÅÊÄßÂàÜÊï∏Ôºå‰ª•‰∏çÂêåÁöÑ‰ΩçÂÖÉÈáèÂåñ‰∏çÂêåÁöÑÂ±§ÔºåÊúÉÂ∞éËá¥ÊïàËÉΩ‰∏ãÈôçÊ•µÂ∞èÔºå‰ΩÜÊ®°ÂûãÂ§ßÂ∞èÂçªÂ§ßÂπÖÂ£ìÁ∏Æ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂæûÂèØËÆäÂ±§Á¥öÈáèÂåñÂØ¶È©ó‰∏≠ÊèêÂá∫ÂπæÂÄãÂØ¶Áî®ÁöÑÈóúÈçµÁµêË´ñÔºö(a) Âú®ÂèØËÆäÈáèÂåñ‰∏ãÔºåLLM ÊïàËÉΩÊé•ËøëÂéüÂßãÊ®°ÂûãÔºåÁõ¥Âà∞ 25-50% ÁöÑÂ±§‰ΩøÁî®ÊàëÂÄëÂª∫Ë≠∞ÁöÑÊéíÂ∫èÁßªËá≥ËºÉ‰ΩéÈáèÂåñÔºå‰ΩÜÂ¶ÇÊûú‰ΩøÁî®Ê≤íÊúâÁâπÂÆöÊéíÂ∫èÔºåÂâáÂè™ÊúÉÊé•Ëøë 5-10%Ôºõ(b) Â∞á LLM ÈáèÂåñÁÇ∫ËºÉ‰ΩéÁöÑ‰ΩçÂÖÉÊØî‰øÆÂâ™Âü∑Ë°åÂæóÊõ¥Â•ΩÔºåÈô§Èùû‰ΩøÁî®Ê•µÁ´ØÈáèÂåñ (2 ‰ΩçÂÖÉ)Ôºõ(c) ËàáÂÖ∑ÊúâËºÉÂ∞ëÂ±§ÁöÑÂ∞èÂûã LLM Áõ∏ÊØîÔºåÂ±§Á¥öÈáèÂåñÂà∞ËºÉ‰Ωé‰ΩçÂÖÉÂú®ÂÖ∑ÊúâËºÉÂ§öÂ±§ÁöÑÂ§ßÂûã LLM ‰∏≠ÊïàÊûúÊõ¥Â•Ω„ÄÇÁî®ÊñºÂü∑Ë°åÂØ¶È©óÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂèñÂæóÔºöhttps://github.com/RazvanDu/LayerwiseQuant„ÄÇ</paragraph>

##### **Make Some Noise: Unlocking Language Model Parallel Inference Capability through Noisy Training**
2406.17404v1 by Yixuan Wang, Xianzhen Luo, Fuxuan Wei, Yijun Liu, Qingfu Zhu, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che

Existing speculative decoding methods typically require additional model
structure and training processes to assist the model for draft token
generation. This makes the migration of acceleration methods to the new model
more costly and more demanding on device memory. To address this problem, we
propose the Make Some Noise (MSN) training framework as a replacement for the
supervised fine-tuning stage of the large language model. The training method
simply introduces some noise at the input for the model to learn the denoising
task. It significantly enhances the parallel decoding capability of the model
without affecting the original task capability. In addition, we propose a
tree-based retrieval-augmented Jacobi (TR-Jacobi) decoding strategy to further
improve the inference speed of MSN models. Experiments in both the general and
code domains have shown that MSN can improve inference speed by 2.3-2.7x times
without compromising model performance. The MSN model also achieves comparable
acceleration ratios to the SOTA model with additional model structure on
Spec-Bench.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÊé®Ê∏¨ÊÄßËß£Á¢ºÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÈ°çÂ§ñÁöÑÊ®°ÂûãÁµêÊßãÂíåË®ìÁ∑¥ÊµÅÁ®ãÔºå‰ª•ÂçîÂä©Ê®°ÂûãÈÄ≤Ë°åËçâÁ®ø‰ª§ÁâåÁîüÊàê„ÄÇÈÄô‰ΩøÂæóÂä†ÈÄüÊñπÊ≥ïÈÅ∑ÁßªÂà∞Êñ∞Ê®°ÂûãÁöÑÊàêÊú¨Êõ¥È´òÔºå‰∏¶‰∏îÂ∞çË£ùÁΩÆË®òÊÜ∂È´îÁöÑË¶ÅÊ±Ç‰πüÊõ¥È´ò„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫Â∞á Make Some Noise (MSN) Ë®ìÁ∑¥Êû∂Êßã‰ΩúÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁõ£Áù£ÂæÆË™øÈöéÊÆµÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇË®ìÁ∑¥ÊñπÊ≥ïÂÉÖÂú®Ëº∏ÂÖ•Á´ØÂºïÂÖ•‰∏Ä‰∫õÈõúË®äÔºåËÆìÊ®°ÂûãÂ≠∏ÁøíÂéªÈõúË®ä‰ªªÂãô„ÄÇÂÆÉÈ°ØËëóÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÁöÑ‰∏¶Ë°åËß£Á¢ºËÉΩÂäõÔºåËÄå‰∏çÊúÉÂΩ±ÈüøÂéüÂßã‰ªªÂãôËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÊ®πÁöÑÊ™¢Á¥¢Â¢ûÂº∑ Jacobi (TR-Jacobi) Ëß£Á¢ºÁ≠ñÁï•Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´ò MSN Ê®°ÂûãÁöÑÊé®ÁêÜÈÄüÂ∫¶„ÄÇ‰∏ÄËà¨ÂíåÁ®ãÂºèÁ¢ºÈ†òÂüüÁöÑÂØ¶È©óË°®ÊòéÔºåMSN ÂèØ‰ª•Â∞áÊé®ÁêÜÈÄüÂ∫¶ÊèêÈ´ò 2.3-2.7 ÂÄçÔºåËÄå‰∏çÊúÉÊêçÂÆ≥Ê®°ÂûãÊïàËÉΩ„ÄÇMSN Ê®°ÂûãÂú® Spec-Bench ‰∏ä‰πüÈÅîÂà∞‰∫ÜËàá SOTA Ê®°ÂûãÁõ∏Áï∂ÁöÑÂä†ÈÄüÊØîÔºå‰∏¶ÂÖ∑ÂÇôÈ°çÂ§ñÁöÑÊ®°ÂûãÁµêÊßã„ÄÇ

##### **Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance**
2406.17385v1 by Manon Reusens, Philipp Borchert, Jochen De Weerdt, Bart Baesens

Large Language Models (LLMs) excel at providing information acquired during
pretraining on large-scale corpora and following instructions through user
prompts. This study investigates whether the quality of LLM responses varies
depending on the demographic profile of users. Considering English as the
global lingua franca, along with the diversity of its dialects among speakers
of different native languages, we explore whether non-native English speakers
receive lower-quality or even factually incorrect responses from LLMs more
frequently. Our results show that performance discrepancies occur when LLMs are
prompted by native versus non-native English speakers and persist when
comparing native speakers from Western countries with others. Additionally, we
find a strong anchoring effect when the model recognizes or is made aware of
the user's nativeness, which further degrades the response quality when
interacting with non-native speakers. Our analysis is based on a newly
collected dataset with over 12,000 unique annotations from 124 annotators,
including information on their native language and English proficiency.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊìÖÈï∑Êèê‰æõÂú®Â§ßÂûãË™ûÊñôÂ∫´‰∏äÈ†êË®ìÁ∑¥ÊúüÈñìÁç≤ÂæóÁöÑË≥áË®äÔºå‰∏¶ÈÅµÂæ™‰ΩøÁî®ËÄÖÊèêÁ§∫ÁöÑÊåá‰ª§„ÄÇÊú¨Á†îÁ©∂Ë™øÊü• LLM ÂõûÊáâÁöÑÂìÅË≥™ÊòØÂê¶ÊúÉÂõ†‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫Ë≥áÊñôËÄåÁï∞„ÄÇËÄÉÈáèÂà∞Ëã±Ë™û‰ΩúÁÇ∫ÂÖ®ÁêÉÈÄöÁî®Ë™ûÔºå‰ª•Âèä‰∏çÂêåÊØçË™û‰ΩøÁî®ËÄÖ‰πãÈñìÊñπË®ÄÁöÑÂ§öÊ®£ÊÄßÔºåÊàëÂÄëÊé¢Ë®éÈùûËã±Ë™ûÊØçË™û‰ΩøÁî®ËÄÖÊòØÂê¶Êõ¥Â∏∏Âæû LLM Êî∂Âà∞ÂìÅË≥™ËºÉÂ∑ÆÁîöËá≥‰∫ãÂØ¶ÈåØË™§ÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÁï∂ LLM Áî±Ëã±Ë™ûÊØçË™ûÂíåÈùûÊØçË™û‰ΩøÁî®ËÄÖÊèêÁ§∫ÊôÇÔºåÊïàËÉΩÂ∑ÆÁï∞Â∞±ÊúÉÁôºÁîüÔºå‰∏îÂú®Â∞áË•øÊñπÂúãÂÆ∂ÁöÑÊØçË™û‰ΩøÁî®ËÄÖËàáÂÖ∂‰ªñÂúãÂÆ∂ÈÄ≤Ë°åÊØîËºÉÊôÇÔºåÈÄôÁ®ÆÂ∑ÆÁï∞‰ªçÁÑ∂Â≠òÂú®„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæÁï∂Ê®°ÂûãËæ®Ë≠òÊàñÂæóÁü•‰ΩøÁî®ËÄÖÁöÑÊØçË™ûÊôÇÔºåÊúÉÁî¢ÁîüÂº∑ÁÉàÁöÑÈå®ÂÆöÊïàÊáâÔºåÈÄôÊúÉÈÄ≤‰∏ÄÊ≠•Èôç‰ΩéËàáÈùûÊØçË™û‰ΩøÁî®ËÄÖ‰∫íÂãïÊôÇÁöÑÂõûÊáâÂìÅË≥™„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÂü∫Êñº‰∏ÄÂÄãÊñ∞Êî∂ÈõÜÁöÑË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ 124 ‰ΩçË®ªËß£ËÄÖÁöÑ 12,000 Â§öÂÄãÁç®ÁâπË®ªËß£ÔºåÂåÖÊã¨‰ªñÂÄëÊØçË™ûÂíåËã±Ë™ûËÉΩÂäõÁöÑË≥áË®ä„ÄÇ

##### **A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens**
2406.17378v1 by Zhijie Nie, Richong Zhang, Zhanyu Wu

Text embeddings from large language models (LLMs) have achieved excellent
results in tasks such as information retrieval, semantic textual similarity,
etc. In this work, we show an interesting finding: when feeding a text into the
embedding LLMs, the obtained text embedding will be able to be aligned with the
key tokens in the input text. We first fully analyze this phenomenon on eight
embedding LLMs and show that this phenomenon is universal and is not affected
by model architecture, training strategy, and embedding method. With a deeper
analysis, we then find that the main change in embedding space between the
embedding LLMs and their original generative LLMs is in the first principal
component. By adjusting the first principal component, we can align text
embedding with the key tokens. Finally, we give several examples to demonstrate
the vast application potential of this finding: (1) we propose a simple and
practical sparse retrieval method based on the aligned tokens, which can
achieve 80\% of the dense retrieval effect of the same model while reducing the
computation significantly; (2) we show that our findings provide a fresh
perspective to help understand fuzzy concepts (e.g., semantic relatedness vs.
semantic similarity) and emerging technologies (e.g., instruction-following
embedding) in this field.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñáÂ≠óÂµåÂÖ•Âú®Ë≥áË®äÊ™¢Á¥¢„ÄÅË™ûÁæ©ÊñáÂ≠óÁõ∏‰ººÂ∫¶Á≠â‰ªªÂãô‰∏≠Áç≤Âæó‰∫ÜÊ•µ‰Ω≥ÁöÑÁµêÊûú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÊúâË∂£ÁöÑÁôºÁèæÔºöÁï∂Â∞áÊñáÂ≠óËº∏ÂÖ•ÂµåÂÖ•Âºè LLM ÊôÇÔºåÁç≤ÂæóÁöÑÊñáÂ≠óÂµåÂÖ•Â∞áËÉΩÂ§†ËàáËº∏ÂÖ•ÊñáÂ≠ó‰∏≠ÁöÑÈóúÈçµÊ®ôË®òÂ∞çÈΩä„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú®ÂÖ´ÂÄãÂµåÂÖ•Âºè LLM ‰∏äÂÖ®Èù¢ÂàÜÊûê‰∫ÜÊ≠§ÁèæË±°Ôºå‰∏¶Ë°®ÊòéÊ≠§ÁèæË±°ÊòØÊôÆÈÅçÁöÑÔºå‰∏çÂèóÊ®°ÂûãÊû∂Êßã„ÄÅË®ìÁ∑¥Á≠ñÁï•ÂíåÂµåÂÖ•ÊñπÊ≥ïÁöÑÂΩ±Èüø„ÄÇÈÄèÈÅéÊõ¥Ê∑±ÂÖ•ÁöÑÂàÜÊûêÔºåÊàëÂÄëÁôºÁèæÂµåÂÖ•Âºè LLM ËàáÂÖ∂ÂéüÂßãÁîüÊàêÂºè LLM ‰πãÈñìÂµåÂÖ•Á©∫ÈñìÁöÑ‰∏ªË¶ÅËÆäÂåñÂú®ÊñºÁ¨¨‰∏Ä‰∏ªÊàêÂàÜ„ÄÇÈÄèÈÅéË™øÊï¥Á¨¨‰∏Ä‰∏ªÊàêÂàÜÔºåÊàëÂÄëÂèØ‰ª•Â∞áÊñáÂ≠óÂµåÂÖ•ËàáÈóúÈçµÊ®ôË®òÂ∞çÈΩä„ÄÇÊúÄÂæåÔºåÊàëÂÄëËàâ‰∫ÜÂπæÂÄã‰æãÂ≠ê‰æÜË™™ÊòéÊ≠§ÁôºÁèæÁöÑÂª£Ê≥õÊáâÁî®ÊΩõÂäõÔºö(1) ÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂ∞çÈΩäÊ®ôË®òÁöÑÁ∞°ÂñÆ‰∏îÂØ¶Áî®ÁöÑÁ®ÄÁñèÊ™¢Á¥¢ÊñπÊ≥ïÔºåÂÆÉÂèØ‰ª•Âú®È°ØËëóÈôç‰ΩéÈÅãÁÆóÈáèÁöÑÂêåÊôÇÔºåÈÅîÂà∞Áõ∏ÂêåÊ®°Âûã 80% ÁöÑÁ®†ÂØÜÊ™¢Á¥¢ÊïàÊûúÔºõ(2) ÊàëÂÄëÂ±ïÁ§∫ÊàëÂÄëÁöÑÁôºÁèæÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËßÄÈªûÔºåÊúâÂä©ÊñºÁêÜËß£Ê≠§È†òÂüü‰∏≠ÁöÑÊ®°Á≥äÊ¶ÇÂøµÔºà‰æãÂ¶ÇÔºåË™ûÁæ©Áõ∏ÈóúÊÄßËàáË™ûÁæ©Áõ∏‰ººÊÄßÔºâÂíåÊñ∞ËààÊäÄË°ìÔºà‰æãÂ¶ÇÔºåÈÅµÂæ™Êåá‰ª§ÁöÑÂµåÂÖ•Ôºâ„ÄÇ

##### **A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs**
2406.17377v1 by Vaibhav Singh, Amrith Krishna, Karthika NJ, Ganesh Ramakrishnan

Low-resource languages, by its very definition, tend to be under represented
in the pre-training corpora of Large Language Models. In this work, we
investigate three low-resource cross-lingual approaches that enable an LLM
adapt to tasks in previously unseen languages. Llama-2 is an LLM where Indic
languages, among many other language families, contribute to less than
$0.005\%$ of the total $2$ trillion token pre-training corpora. In this work,
we experiment with the English-dominated Llama-2 for cross-lingual transfer to
three Indic languages, Bengali, Hindi, and Tamil as target languages. We study
three approaches for cross-lingual transfer, under ICL and fine-tuning. One, we
find that adding additional supervisory signals via a dominant language in the
LLM, leads to improvements, both under in-context learning and fine-tuning.
Two, adapting the target languages to word reordering may be beneficial under
ICL, but its impact diminishes with fine tuning. Finally, continued
pre-training in one low-resource language can improve model performance for
other related low-resource languages.

ÊëòË¶ÅÔºö‰ΩéË≥áÊ∫êË™ûË®ÄÔºåÈ°ßÂêçÊÄùÁæ©ÔºåÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈ†êË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÂæÄÂæÄ‰ª£Ë°®ÊÄß‰∏çË∂≥„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü‰∏âÁ®Æ‰ΩéË≥áÊ∫êË∑®Ë™ûË®ÄÊñπÊ≥ïÔºåÈÄô‰∫õÊñπÊ≥ï‰Ωø LLM ËÉΩÂ§†ÈÅ©Êáâ‰ª•ÂâçÊú™Ë¶ãË™ûË®Ä‰∏≠ÁöÑ‰ªªÂãô„ÄÇLlama-2 ÊòØ‰∏ÄÁ®Æ LLMÔºåÂÖ∂‰∏≠Âç∞Â∫¶Ë™ûË®ÄÔºà‰ª•ÂèäË®±Â§öÂÖ∂‰ªñË™ûË®ÄÁ≥ªÂàóÔºâÂú®Á∏ΩË®à 2 ÂÖÜÂÄã token ÁöÑÈ†êË®ìÁ∑¥Ë™ûÊñôÂ∫´‰∏≠ÊâÄ‰ΩîÊØî‰æã‰∏çÂà∞ 0.005%„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂòóË©¶‰ΩøÁî®‰ª•Ëã±Ë™ûÁÇ∫‰∏ªÁöÑ Llama-2 ÈÄ≤Ë°åË∑®Ë™ûË®ÄËΩâÁßªÔºåÁõÆÊ®ôË™ûË®ÄÁÇ∫‰∏âÁ®ÆÂç∞Â∫¶Ë™ûË®ÄÔºöÂ≠üÂä†ÊãâË™û„ÄÅÂç∞Âú∞Ë™ûÂíåÊ≥∞Á±≥ÁàæË™û„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫ÜË∑®Ë™ûË®ÄËΩâÁßªÁöÑ‰∏âÁ®ÆÊñπÊ≥ïÔºåÂåÖÊã¨ ICL ÂíåÂæÆË™ø„ÄÇ‰∏Ä„ÄÅÊàëÂÄëÁôºÁèæÈÄöÈÅé LLM ‰∏≠ÁöÑ‰∏ªÂ∞éË™ûË®ÄÊ∑ªÂä†È°çÂ§ñÁöÑÁõ£Áù£‰ø°ËôüÔºåÁÑ°Ë´ñÊòØÂú®ÊÉÖÂ¢ÉÂ≠∏ÁøíÈÇÑÊòØÂæÆË™ø‰∏ãÔºåÈÉΩËÉΩÂ∏∂‰æÜÊîπÈÄ≤„ÄÇ‰∫å„ÄÅÂú® ICL ‰∏ãÔºåÂ∞áÁõÆÊ®ôË™ûË®ÄÈÅ©ÊáâË©ûÂ∫èË™øÊï¥ÂèØËÉΩÊòØÊúâÁõäÁöÑÔºå‰ΩÜÂÖ∂ÂΩ±ÈüøÊúÉÈö®ËëóÂæÆË™øËÄåÊ∏õÂº±„ÄÇÊúÄÂæåÔºåÂú®‰∏ÄÂÄã‰ΩéË≥áÊ∫êË™ûË®Ä‰∏≠ÊåÅÁ∫åÈ†êË®ìÁ∑¥ÂèØ‰ª•ÊèêÈ´òÊ®°ÂûãÂ∞çÂÖ∂‰ªñÁõ∏Èóú‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÊÄßËÉΩ„ÄÇ

##### **Temporal-Channel Modeling in Multi-head Self-Attention for Synthetic Speech Detection**
2406.17376v1 by Duc-Tuan Truong, Ruijie Tao, Tuan Nguyen, Hieu-Thi Luong, Kong Aik Lee, Eng Siong Chng

Recent synthetic speech detectors leveraging the Transformer model have
superior performance compared to the convolutional neural network counterparts.
This improvement could be due to the powerful modeling ability of the
multi-head self-attention (MHSA) in the Transformer model, which learns the
temporal relationship of each input token. However, artifacts of synthetic
speech can be located in specific regions of both frequency channels and
temporal segments, while MHSA neglects this temporal-channel dependency of the
input sequence. In this work, we proposed a Temporal-Channel Modeling (TCM)
module to enhance MHSA's capability for capturing temporal-channel
dependencies. Experimental results on the ASVspoof 2021 show that with only
0.03M additional parameters, the TCM module can outperform the state-of-the-art
system by 9.25% in EER. Further ablation study reveals that utilizing both
temporal and channel information yields the most improvement for detecting
synthetic speech.

ÊëòË¶ÅÔºöÊúÄËøëÂà©Áî® Transformer Ê®°ÂûãÁöÑÂêàÊàêË™ûÈü≥ÂÅµÊ∏¨Âô®ËàáÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÂ∞çÊáâÈ†ÖÁõ∏ÊØîÂÖ∑ÊúâÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÈÄôÂÄãÈÄ≤Ê≠•ÂèØËÉΩÊòØÁî±Êñº Transformer Ê®°Âûã‰∏≠Â§öÈ†≠Ëá™ÊàëÊ≥®ÊÑè (MHSA) ÁöÑÂº∑Â§ßÂª∫Ê®°ËÉΩÂäõÔºåÂÆÉÂ≠∏ÁøíÊØèÂÄãËº∏ÂÖ•Ê®ôË®òÁöÑÊôÇÈñìÈóú‰øÇ„ÄÇÁÑ∂ËÄåÔºåÂêàÊàêË™ûÈü≥ÁöÑÂÅΩÂΩ±ÂèØËÉΩ‰ΩçÊñºÈ†ªÁéáÈÄöÈÅìÂíåÊôÇÈñìÂçÄÊÆµÁöÑÁâπÂÆöÂçÄÂüüÔºåËÄå MHSA ÂøΩÁï•‰∫ÜËº∏ÂÖ•Â∫èÂàóÁöÑÈÄôÁ®ÆÊôÇÈñìÈÄöÈÅì‰æùË≥¥ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊôÇÈñìÈÄöÈÅìÂª∫Ê®° (TCM) Ê®°ÁµÑÔºå‰ª•Â¢ûÂº∑ MHSA Êì∑ÂèñÊôÇÈñìÈÄöÈÅì‰æùË≥¥ÊÄßÁöÑËÉΩÂäõ„ÄÇASVspoof 2021 ÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂÉÖ‰ΩøÁî® 0.03M ÁöÑÈ°çÂ§ñÂèÉÊï∏ÔºåTCM Ê®°ÁµÑÂ∞±ËÉΩÂú® EER ‰∏≠‰ª• 9.25% ÁöÑË°®ÁèæÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁ≥ªÁµ±„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÂêåÊôÇÂà©Áî®ÊôÇÈñìÂíåÈÄöÈÅìË≥áË®äÂèØ‰ª•ÁÇ∫ÂêàÊàêË™ûÈü≥ÂÅµÊ∏¨Â∏∂‰æÜÊúÄÂ§ßÁöÑÈÄ≤Ê≠•„ÄÇ

##### **An Empirical Study on the Characteristics of Bias upon Context Length Variation for Bangla**
2406.17375v1 by Jayanta Sadhu, Ayan Antik Khan, Abhik Bhattacharjee, Rifat Shahriyar

Pretrained language models inherently exhibit various social biases,
prompting a crucial examination of their social impact across various
linguistic contexts due to their widespread usage. Previous studies have
provided numerous methods for intrinsic bias measurements, predominantly
focused on high-resource languages. In this work, we aim to extend these
investigations to Bangla, a low-resource language. Specifically, in this study,
we (1) create a dataset for intrinsic gender bias measurement in Bangla, (2)
discuss necessary adaptations to apply existing bias measurement methods for
Bangla, and (3) examine the impact of context length variation on bias
measurement, a factor that has been overlooked in previous studies. Through our
experiments, we demonstrate a clear dependency of bias metrics on context
length, highlighting the need for nuanced considerations in Bangla bias
analysis. We consider our work as a stepping stone for bias measurement in the
Bangla Language and make all of our resources publicly available to support
future research.

ÊëòË¶ÅÔºöÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÊú¨Ë≥™‰∏äÂ±ïÁèæÂá∫ÂêÑÁ®ÆÁ§æÊúÉÂÅèË¶ãÔºå
‰øÉ‰ΩøÂ∞çÂÖ∂Âú®ÂêÑÁ®ÆË™ûË®ÄÁí∞Â¢É‰∏≠ÁöÑÁ§æÊúÉÂΩ±ÈüøÈÄ≤Ë°åÈóúÈçµÂØ©Êü•ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëË¢´Âª£Ê≥õ‰ΩøÁî®„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂
Êèê‰æõ‰∫ÜË®±Â§öÂÖßÂú®ÂÅèË¶ãÊ∏¨ÈáèÊñπÊ≥ïÔºå‰∏ªË¶ÅÈõÜ‰∏≠Âú®È´òË≥áÊ∫êË™ûË®Ä‰∏ä„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â∞áÈÄô‰∫õ
Ë™øÊü•Êì¥Â±ïÂà∞Â≠üÂä†ÊãâË™ûÔºå‰∏ÄÁ®Æ‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄë (1) ÁÇ∫Â≠üÂä†ÊãâË™û‰∏≠ÁöÑÂÖßÂú®ÊÄßÂà•ÂÅèË¶ãÊ∏¨ÈáèÂª∫Á´ã‰∏ÄÂÄãÊï∏ÊìöÈõÜÔºå(2)
Ë®éË´ñÁÇ∫Â≠üÂä†ÊãâË™ûÊáâÁî®ÁèæÊúâÁöÑÂÅèË¶ãÊ∏¨ÈáèÊñπÊ≥ïÊâÄÈúÄÁöÑÈÅ©ÊáâÔºå‰ª•Âèä (3) Ê™¢Êü•‰∏ä‰∏ãÊñáÈï∑Â∫¶ËÆäÂåñÂ∞çÂÅèË¶ã
Ê∏¨ÈáèÁöÑÂΩ±ÈüøÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖàÂâçÁ†îÁ©∂‰∏≠Ë¢´ÂøΩË¶ñÁöÑÂõ†Á¥†„ÄÇÈÄèÈÅéÊàëÂÄëÁöÑ
ÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÅèË¶ãÊåáÊ®ôÂ∞ç‰∏ä‰∏ãÊñáÈï∑Â∫¶ÁöÑÊòéÈ°Ø‰æùË≥¥ÊÄßÔºåÂº∑Ë™ø‰∫ÜÂú®Â≠üÂä†ÊãâË™ûÂÅèË¶ã
ÂàÜÊûê‰∏≠ÈúÄË¶ÅÁ¥∞Á∑ªÁöÑËÄÉÈáè„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁ†îÁ©∂Ë¶ñÁÇ∫Â≠üÂä†ÊãâË™û‰∏≠ÂÅèË¶ãÊ∏¨ÈáèÁöÑÂ¢äËÖ≥Áü≥Ôºå‰∏¶ÂÖ¨ÈñãÊàëÂÄëÊâÄÊúâÁöÑË≥áÊ∫ê‰ª•ÊîØÊåÅ
Êú™‰æÜÁöÑÁ†îÁ©∂„ÄÇ

##### **Leveraging Synthetic Audio Data for End-to-End Low-Resource Speech Translation**
2406.17363v1 by Yasmin Moslem

This paper describes our system submission to the International Conference on
Spoken Language Translation (IWSLT 2024) for Irish-to-English speech
translation. We built end-to-end systems based on Whisper, and employed a
number of data augmentation techniques, such as speech back-translation and
noise augmentation. We investigate the effect of using synthetic audio data and
discuss several methods for enriching signal diversity.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèèËø∞‰∫ÜÊàëÂÄëÂú®ÂúãÈöõË™ûÈü≥Ë™ûË®ÄÁøªË≠ØÊúÉË≠∞ (IWSLT 2024) ÁöÑÊÑõÁàæËò≠Ë™ûÂà∞Ëã±Ë™ûË™ûÈü≥ÁøªË≠ØÁ≥ªÁµ±Êèê‰∫§„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜÂü∫Êñº Whisper ÁöÑÁ´ØÂà∞Á´ØÁ≥ªÁµ±Ôºå‰∏¶Êé°Áî®‰∫ÜÂ§öÁ®ÆÊï∏ÊìöÊì¥ÂÖÖÊäÄË°ìÔºå‰æãÂ¶ÇË™ûÈü≥ÂèçÂêëÁøªË≠ØÂíåÂô™ËÅ≤Êì¥ÂÖÖ„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü‰ΩøÁî®ÂêàÊàêÈü≥È†ªÊï∏ÊìöÁöÑÂΩ±ÈüøÔºå‰∏¶Ë®éË´ñ‰∫ÜÂ§öÁ®ÆË±êÂØå‰ø°ËôüÂ§öÊ®£ÊÄßÁöÑÊñπÊ≥ï„ÄÇ

##### **Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers**
2406.17343v1 by Lei Chen, Yuan Meng, Chen Tang, Xinzhu Ma, Jingyan Jiang, Xin Wang, Zhi Wang, Wenwu Zhu

Recent advancements in diffusion models, particularly the trend of
architectural transformation from UNet-based Diffusion to Diffusion Transformer
(DiT), have significantly improved the quality and scalability of image
synthesis. Despite the incredible generative quality, the large computational
requirements of these large-scale models significantly hinder the deployments
in real-world scenarios. Post-training Quantization (PTQ) offers a promising
solution by compressing model sizes and speeding up inference for the
pretrained models while eliminating model retraining. However, we have observed
the existing PTQ frameworks exclusively designed for both ViT and conventional
Diffusion models fall into biased quantization and result in remarkable
performance degradation. In this paper, we find that the DiTs typically exhibit
considerable variance in terms of both weight and activation, which easily runs
out of the limited numerical representations. To address this issue, we devise
Q-DiT, which seamlessly integrates three techniques: fine-grained quantization
to manage substantial variance across input channels of weights and
activations, an automatic search strategy to optimize the quantization
granularity and mitigate redundancies, and dynamic activation quantization to
capture the activation changes across timesteps. Extensive experiments on the
ImageNet dataset demonstrate the effectiveness of the proposed Q-DiT.
Specifically, when quantizing DiT-XL/2 to W8A8 on ImageNet 256x256, Q-DiT
achieves a remarkable reduction in FID by 1.26 compared to the baseline. Under
a W4A8 setting, it maintains high fidelity in image generation, showcasing only
a marginal increase in FID and setting a new benchmark for efficient,
high-quality quantization in diffusion transformers. Code is available at
\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}.

ÊëòË¶ÅÔºö<paragraph>Êì¥Êï£Ê®°ÂûãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂæûÂü∫Êñº UNet ÁöÑÊì¥Êï£Âà∞Êì¥Êï£ËÆäÊèõÂô® (DiT) ÁöÑÊû∂ÊßãËΩâÊèõË∂®Âã¢ÔºåÂ§ßÂπÖÊèêÂçá‰∫ÜÂΩ±ÂÉèÂêàÊàêÁöÑÂìÅË≥™ÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÂÑòÁÆ°ÁîüÊàêÂìÅË≥™‰ª§‰∫∫È©öÂòÜÔºå‰ΩÜÈÄô‰∫õÂ§ßÂûãÊ®°ÂûãÈæêÂ§ßÁöÑÈÅãÁÆóÈúÄÊ±ÇÔºåÂ§ßÂπÖÈòªÁ§ô‰∫ÜÂú®ÂØ¶ÈöõÂ†¥ÊôØ‰∏≠ÁöÑÈÉ®ÁΩ≤„ÄÇË®ìÁ∑¥ÂæåÈáèÂåñ (PTQ) Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåÈÄèÈÅéÂ£ìÁ∏ÆÊ®°ÂûãÂ§ßÂ∞è‰∏¶Âä†ÈÄüÈ†êË®ìÁ∑¥Ê®°ÂûãÁöÑÊé®Ë´ñÔºåÂêåÊôÇÊ∂àÈô§Ê®°ÂûãÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëËßÄÂØüÂà∞ÁèæÊúâÁöÑ PTQ Ê°ÜÊû∂Â∞àÈñÄË®≠Ë®àÁµ¶ ViT ÂíåÂÇ≥Áµ±Êì¥Êï£Ê®°ÂûãÔºåÊúÉÈô∑ÂÖ•ÊúâÂÅèÂ∑ÆÁöÑÈáèÂåñÔºå‰∏¶Â∞éËá¥È°ØËëóÁöÑÊïàËÉΩ‰∏ãÈôç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÁèæ DiT ÈÄöÂ∏∏Âú®Ê¨äÈáçÂíåÊøÄÊ¥ªÊñπÈù¢Ë°®ÁèæÂá∫Áõ∏Áï∂Â§ßÁöÑÂ∑ÆÁï∞ÔºåÈÄôÂæàÂÆπÊòìË∂ÖÂá∫ÊúâÈôêÁöÑÊï∏ÂÄºË°®Á§∫ÁØÑÂúç„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëË®≠Ë®à‰∫Ü Q-DiTÔºåÂÆÉÁÑ°Á∏´Êï¥Âêà‰∫Ü‰∏âÁ®ÆÊäÄË°ìÔºöÁ¥∞Á≤íÂ∫¶ÈáèÂåñ‰ª•ÁÆ°ÁêÜÊ¨äÈáçÂíåÊøÄÊ¥ªËº∏ÂÖ•ÈÄöÈÅì‰πãÈñìÁöÑÂØ¶Ë≥™Â∑ÆÁï∞„ÄÅËá™ÂãïÊêúÂ∞ãÁ≠ñÁï•‰ª•ÊúÄ‰Ω≥ÂåñÈáèÂåñÁ≤íÂ∫¶‰∏¶Ê∏õËºïÂÜóÈ§òÔºå‰ª•ÂèäÂãïÊÖãÊøÄÊ¥ªÈáèÂåñ‰ª•ÊçïÊçâÊôÇÈñìÊ≠•Èï∑‰πãÈñìÁöÑÊøÄÊ¥ªËÆäÂåñ„ÄÇÂú® ImageNet Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑ Q-DiT ÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÁï∂Â∞á DiT-XL/2 ÈáèÂåñÁÇ∫ ImageNet 256x256 ‰∏äÁöÑ W8A8 ÊôÇÔºåËàáÂü∫Á∑öÁõ∏ÊØîÔºåQ-DiT Âú® FID ‰∏äÂØ¶Áèæ‰∫ÜÈ°ØËëóÁöÑ 1.26 Ê∏õÂ∞ë„ÄÇÂú® W4A8 Ë®≠ÂÆö‰∏ãÔºåÂÆÉÂú®ÂΩ±ÂÉèÁîüÊàê‰∏≠Á∂≠ÊåÅÈ´ò‰øùÁúüÂ∫¶ÔºåÂÉÖÂ±ïÁ§∫ FID ÁöÑÈÇäÈöõÂ¢ûÂä†Ôºå‰∏¶ÁÇ∫Êì¥Êï£ËÆäÊèõÂô®‰∏≠ÁöÑÈ´òÊïà„ÄÅÈ´òÂìÅË≥™ÈáèÂåñË®≠ÂÆö‰∫ÜÊñ∞ÁöÑÂü∫Ê∫ñ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú®\href{https://github.com/Juanerx/Q-DiT}{https://github.com/Juanerx/Q-DiT}ÂèñÂæó„ÄÇ</paragraph>

##### **Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds**
2406.17342v1 by Hongliang Zeng, Ping Zhang, Fang Li, Jiahua Wang, Tingyu Ye, Pengteng Guo

In the field of 2D image generation modeling and representation learning,
Masked Generative Encoder (MAGE) has demonstrated the synergistic potential
between generative modeling and representation learning. Inspired by this, we
propose Point-MAGE to extend this concept to point cloud data. Specifically,
this framework first utilizes a Vector Quantized Variational Autoencoder
(VQVAE) to reconstruct a neural field representation of 3D shapes, thereby
learning discrete semantic features of point patches. Subsequently, by
combining the masking model with variable masking ratios, we achieve
synchronous training for both generation and representation learning.
Furthermore, our framework seamlessly integrates with existing point cloud
self-supervised learning (SSL) models, thereby enhancing their performance. We
extensively evaluate the representation learning and generation capabilities of
Point-MAGE. In shape classification tasks, Point-MAGE achieved an accuracy of
94.2% on the ModelNet40 dataset and 92.9% (+1.3%) on the ScanObjectNN dataset.
Additionally, it achieved new state-of-the-art performance in few-shot learning
and part segmentation tasks. Experimental results also confirmed that
Point-MAGE can generate detailed and high-quality 3D shapes in both
unconditional and conditional settings.

ÊëòË¶ÅÔºöÂú® 2D ÂΩ±ÂÉèÁîüÊàêÂª∫Ê®°ÂíåË°®ÂæµÂ≠∏ÁøíÈ†òÂüü‰∏≠Ôºå
ÈÅÆÁΩ©ÁîüÊàêÁ∑®Á¢ºÂô® (MAGE) Â∑≤Ë≠âÊòéÁîüÊàêÂª∫Ê®°ÂíåË°®ÂæµÂ≠∏Áøí‰πãÈñìÁöÑÂçîÂêåÊΩõÂäõ„ÄÇÂèóÊ≠§ÂïüÁôºÔºåÊàëÂÄë
ÊèêÂá∫Èªû MAGE Â∞áÊ≠§Ê¶ÇÂøµÂª∂‰º∏Ëá≥ÈªûÈõ≤Ë≥áÊñô„ÄÇÂÖ∑È´î‰æÜË™™Ôºå
Ê≠§Ê°ÜÊû∂È¶ñÂÖàÂà©Áî®ÂêëÈáèÈáèÂåñËÆäÂàÜËá™Á∑®Á¢ºÂô® (VQVAE) ‰æÜÈáçÂª∫ 3D ÂΩ¢ÁãÄÁöÑÁ•ûÁ∂ìÂ†¥Ë°®ÂæµÔºåÂæûËÄå
Â≠∏ÁøíÈªûÁãÄÂúñÊ°àÁöÑÈõ¢Êï£Ë™ûÁæ©ÁâπÂæµ„ÄÇÈö®ÂæåÔºåÈÄöÈÅéÂ∞áÈÅÆÁΩ©Ê®°ÂûãËàáÂèØËÆäÈÅÆÁΩ©ÊØîÁéáÁµêÂêàÔºåÊàëÂÄëÂØ¶Áèæ
ÂêåÊôÇË®ìÁ∑¥ÁîüÊàêÂíåË°®ÂæµÂ≠∏Áøí„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂ËàáÁèæÊúâÁöÑÈªûÈõ≤
Ëá™ÊàëÁõ£Áù£Â≠∏Áøí (SSL) Ê®°ÂûãÁÑ°Á∏´Êï¥ÂêàÔºåÂæûËÄåÂ¢ûÂº∑ÂÖ∂ÊïàËÉΩ„ÄÇÊàëÂÄë
Âª£Ê≥õË©ï‰º∞‰∫ÜÈªû MAGE ÁöÑË°®ÂæµÂ≠∏ÁøíÂíåÁîüÊàêËÉΩÂäõ„ÄÇÂú®ÂΩ¢ÁãÄÂàÜÈ°û‰ªªÂãô‰∏≠ÔºåÈªû MAGE Âú® ModelNet40 Ë≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫Ü
94.2% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂú® ScanObjectNN Ë≥áÊñôÈõÜ‰∏äÈÅîÂà∞‰∫Ü 92.9%Ôºà+1.3%Ôºâ„ÄÇ
Ê≠§Â§ñÔºåÂÆÉÂú®Â∞èÊ®£Êú¨Â≠∏ÁøíÂíåÈÉ®ÂàÜÂàÜÂâ≤‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜÊñ∞ÁöÑÊúÄÂÖàÈÄ≤ÊïàËÉΩ„ÄÇÂØ¶È©óÁµêÊûú‰πüË≠âÂØ¶‰∫Ü
Èªû MAGE ËÉΩÂú®ÁÑ°Ê¢ù‰ª∂ÂíåÊúâÊ¢ù‰ª∂Ë®≠ÂÆö‰∏ãÁîüÊàêË©≥Á¥∞‰∏îÈ´òÂìÅË≥™ÁöÑ 3D ÂΩ¢ÁãÄ„ÄÇ

##### **Joint Admission Control and Resource Allocation of Virtual Network Embedding via Hierarchical Deep Reinforcement Learning**
2406.17334v1 by Tianfu Wang, Li Shen, Qilin Fan, Tong Xu, Tongliang Liu, Hui Xiong

As an essential resource management problem in network virtualization,
virtual network embedding (VNE) aims to allocate the finite resources of
physical network to sequentially arriving virtual network requests (VNRs) with
different resource demands. Since this is an NP-hard combinatorial optimization
problem, many efforts have been made to provide viable solutions. However, most
existing approaches have either ignored the admission control of VNRs, which
has a potential impact on long-term performances, or not fully exploited the
temporal and topological features of the physical network and VNRs. In this
paper, we propose a deep Hierarchical Reinforcement Learning approach to learn
a joint Admission Control and Resource Allocation policy for VNE, named
HRL-ACRA. Specifically, the whole VNE process is decomposed into an upper-level
policy for deciding whether to admit the arriving VNR or not and a lower-level
policy for allocating resources of the physical network to meet the requirement
of VNR through the HRL approach. Considering the proximal policy optimization
as the basic training algorithm, we also adopt the average reward method to
address the infinite horizon problem of the upper-level agent and design a
customized multi-objective intrinsic reward to alleviate the sparse reward
issue of the lower-level agent. Moreover, we develop a deep feature-aware graph
neural network to capture the features of VNR and physical network and exploit
a sequence-to-sequence model to generate embedding actions iteratively.
Finally, extensive experiments are conducted in various settings, and show that
HRL-ACRA outperforms state-of-the-art baselines in terms of both the acceptance
ratio and long-term average revenue. Our code is available at
\url{https://github.com/GeminiLight/hrl-acra}.

ÊëòË¶ÅÔºö<paragraph>‰ΩúÁÇ∫Á∂≤Ë∑ØËôõÊì¨Âåñ‰∏≠‰∏ÄÈ†ÖÈáçË¶ÅÁöÑË≥áÊ∫êÁÆ°ÁêÜÂïèÈ°åÔºå
ËôõÊì¨Á∂≤Ë∑ØÂµåÂÖ•ÔºàVNEÔºâÊó®Âú®Â∞áÂØ¶È´îÁ∂≤Ë∑ØÁöÑÊúâÈôêË≥áÊ∫êÂàÜÈÖçÁµ¶‰æùÂ∫èÊäµÈÅîÁöÑËôõÊì¨Á∂≤Ë∑ØË´ãÊ±ÇÔºàVNRÔºâÔºåÂÖ∂Ë≥áÊ∫êÈúÄÊ±ÇÂêÑ‰∏çÁõ∏Âêå„ÄÇÁî±ÊñºÈÄôÊòØ‰∏ÄÂÄã NP Èõ£ÁµÑÂêàÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºåÂõ†Ê≠§Â∑≤ÊäïÂÖ•Ë®±Â§öÂøÉÂäõ‰æÜÊèê‰æõÂèØË°åÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÁèæÊúâÊñπÊ≥ïÈÉΩÂøΩÁï•‰∫Ü VNR ÁöÑÊé•Á¥çÊéßÂà∂ÔºåÈÄôÂèØËÉΩÊúÉÂ∞çÈï∑ÊúüÊïàËÉΩÈÄ†ÊàêÂΩ±ÈüøÔºåÊàñËÄÖÊ≤íÊúâÂÖÖÂàÜÂà©Áî®ÂØ¶È´îÁ∂≤Ë∑ØÂíå VNR ÁöÑÊôÇÈñìÂíåÊãìÊí≤ÁâπÂæµ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ∑±Â∫¶ÈöéÂ±§ÂºèÂº∑ÂåñÂ≠∏ÁøíÊñπÊ≥ï‰æÜÂ≠∏Áøí VNE ÁöÑËÅØÂêàÊé•Á¥çÊéßÂà∂ÂíåË≥áÊ∫êÂàÜÈÖçÊîøÁ≠ñÔºåÁ®±ÁÇ∫ HRL-ACRA„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊï¥ÂÄã VNE Á®ãÂ∫èË¢´ÂàÜËß£ÁÇ∫‰∏ÄÂÄã‰∏äÂ±§ÊîøÁ≠ñÔºåÁî®ÊñºÊ±∫ÂÆöÊòØÂê¶Êé•Á¥çÊäµÈÅîÁöÑ VNRÔºå‰ª•Âèä‰∏ÄÂÄã‰∏ãÂ±§ÊîøÁ≠ñÔºåÁî®ÊñºÈÄèÈÅé HRL ÊñπÊ≥ïÂàÜÈÖçÂØ¶È´îÁ∂≤Ë∑ØÁöÑË≥áÊ∫ê‰ª•ÊªøË∂≥ VNR ÁöÑÈúÄÊ±Ç„ÄÇËÄÉÊÖÆÂà∞ËøëÁ´ØÊîøÁ≠ñÊúÄ‰Ω≥Âåñ‰ΩúÁÇ∫Âü∫Êú¨ÁöÑË®ìÁ∑¥ÊºîÁÆóÊ≥ïÔºåÊàëÂÄë‰πüÊé°Áî®Âπ≥ÂùáÁçéÂãµÊ≥ï‰æÜËß£Ê±∫‰∏äÂ±§‰ª£ÁêÜÁöÑÁÑ°ÈôêÊôÇÈñìËª∏ÂïèÈ°åÔºå‰∏¶Ë®≠Ë®à‰∏ÄÂÄãËá™Ë®ÇÁöÑÂ§öÁõÆÊ®ôÂÖßÂú®ÁçéÂãµ‰æÜÁ∑©Ëß£‰∏ãÂ±§‰ª£ÁêÜÁöÑÁ®ÄÁñèÁçéÂãµÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊ∑±Â∫¶ÁâπÂæµÊÑüÁü•ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜÊì∑Âèñ VNR ÂíåÂØ¶È´îÁ∂≤Ë∑ØÁöÑÁâπÂæµÔºå‰∏¶Âà©Áî®Â∫èÂàóÂà∞Â∫èÂàóÊ®°Âûã‰æÜÂèçË¶ÜÁî¢ÁîüÂµåÂÖ•Âãï‰Ωú„ÄÇÊúÄÂæåÔºåÂú®ÂêÑÁ®ÆË®≠ÂÆö‰∏≠ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÁµêÊûúÈ°ØÁ§∫ HRL-ACRA Âú®Êé•ÂèóÁéáÂíåÈï∑ÊúüÂπ≥ÂùáÊî∂ÁõäÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®
\url{https://github.com/GeminiLight/hrl-acra} ÂèñÂæó„ÄÇ</paragraph>

##### **Dual-Space Knowledge Distillation for Large Language Models**
2406.17328v1 by Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng Chen, Jinan Xu

Knowledge distillation (KD) is known as a promising solution to compress
large language models (LLMs) via transferring their knowledge to smaller
models. During this process, white-box KD methods usually minimize the distance
between the output distributions of the two models so that more knowledge can
be transferred. However, in the current white-box KD framework, the output
distributions are from the respective output spaces of the two models, using
their own prediction heads. We argue that the space discrepancy will lead to
low similarity between the teacher model and the student model on both
representation and distribution levels. Furthermore, this discrepancy also
hinders the KD process between models with different vocabularies, which is
common for current LLMs. To address these issues, we propose a dual-space
knowledge distillation (DSKD) framework that unifies the output spaces of the
two models for KD. On the basis of DSKD, we further develop a cross-model
attention mechanism, which can automatically align the representations of the
two models with different vocabularies. Thus, our framework is not only
compatible with various distance functions for KD (e.g., KL divergence) like
the current framework, but also supports KD between any two LLMs regardless of
their vocabularies. Experiments on task-agnostic instruction-following
benchmarks show that DSKD significantly outperforms the current white-box KD
framework with various distance functions, and also surpasses existing KD
methods for LLMs with different vocabularies.

ÊëòË¶ÅÔºöÁü•ËØÜËí∏È¶è (KD) ÊòØ‰∏ÄÁßçÊúâÂâçÈÄîÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂèØÈÄöËøáÂ∞ÜÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÁü•ËØÜËΩ¨ÁßªÂà∞ËæÉÂ∞èÁöÑÊ®°Âûã‰∏≠Êù•ÂéãÁº©Â§ßËØ≠Ë®ÄÊ®°Âûã (LLM)„ÄÇÂú®Ê≠§ËøáÁ®ã‰∏≠ÔºåÁôΩÁõí KD ÊñπÊ≥ïÈÄöÂ∏∏‰ºöÊúÄÂ∞èÂåñ‰∏§‰∏™Ê®°ÂûãËæìÂá∫ÂàÜÂ∏É‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºå‰ª•‰æøÂèØ‰ª•ËΩ¨ÁßªÊõ¥Â§öÁü•ËØÜ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂΩìÂâçÁöÑÁôΩÁõí KD Ê°ÜÊû∂‰∏≠ÔºåËæìÂá∫ÂàÜÂ∏ÉÊù•Ëá™‰∏§‰∏™Ê®°ÂûãÂêÑËá™ÁöÑËæìÂá∫Á©∫Èó¥ÔºåÂπ∂‰ΩøÁî®ÂÆÉ‰ª¨Ëá™Â∑±ÁöÑÈ¢ÑÊµãÂ§¥„ÄÇÊàë‰ª¨ËÆ§‰∏∫ÔºåËøôÁßçÁ©∫Èó¥Â∑ÆÂºÇ‰ºöÂØºËá¥ÊïôÂ∏àÊ®°ÂûãÂíåÂ≠¶ÁîüÊ®°ÂûãÂú®Ë°®Á§∫ÂíåÂàÜÂ∏ÉÂ±ÇÈù¢‰∏äÁõ∏‰ººÂ∫¶ËæÉ‰Ωé„ÄÇÊ≠§Â§ñÔºåËøôÁßçÂ∑ÆÂºÇËøòÈòªÁ¢ç‰∫ÜÂÖ∑Êúâ‰∏çÂêåËØçÊ±áË°®ÁöÑÊ®°Âûã‰πãÈó¥ÁöÑ KD ËøáÁ®ãÔºåËøôÂØπ‰∫éÂΩìÂâçÁöÑ LLM Êù•ËØ¥ÂæàÂ∏∏ËßÅ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™ÂèåÁ©∫Èó¥Áü•ËØÜËí∏È¶è (DSKD) Ê°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Áªü‰∏Ä‰∫Ü‰∏§‰∏™Ê®°ÂûãÁöÑËæìÂá∫Á©∫Èó¥‰ª•ËøõË°å KD„ÄÇÂú® DSKD ÁöÑÂü∫Á°Ä‰∏äÔºåÊàë‰ª¨Ëøõ‰∏ÄÊ≠•ÂºÄÂèë‰∫Ü‰∏ÄÁßçË∑®Ê®°ÂûãÊ≥®ÊÑèÊú∫Âà∂ÔºåÂÆÉÂèØ‰ª•Ëá™Âä®ÂØπÈΩêÂÖ∑Êúâ‰∏çÂêåËØçÊ±áË°®ÁöÑ‰∏§‰∏™Ê®°ÂûãÁöÑË°®Á§∫„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨ÁöÑÊ°ÜÊû∂‰∏ç‰ªÖ‰∏é KD ÁöÑÂêÑÁßçË∑ùÁ¶ªÂáΩÊï∞Ôºà‰æãÂ¶Ç KL Êï£Â∫¶ÔºâÂÖºÂÆπÔºàÂ¶ÇÂΩìÂâçÊ°ÜÊû∂ÔºâÔºåËÄå‰∏îËøòÊîØÊåÅÂú®‰ªª‰Ωï‰∏§‰∏™ LLM ‰πãÈó¥ËøõË°å KDÔºåËÄå‰∏çÁÆ°ÂÆÉ‰ª¨ÁöÑËØçÊ±áË°®Â¶Ç‰Ωï„ÄÇÂú®‰∏é‰ªªÂä°Êó†ÂÖ≥ÁöÑÊåá‰ª§ÈÅµÂæ™Âü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåDSKD Âú®ÂêÑÁßçË∑ùÁ¶ªÂáΩÊï∞‰∏ãÊòéÊòæ‰ºò‰∫éÂΩìÂâçÁöÑÁôΩÁõí KD Ê°ÜÊû∂ÔºåÂπ∂‰∏îËøòË∂ÖË∂ä‰∫ÜÁé∞ÊúâÁöÑÈíàÂØπÂÖ∑Êúâ‰∏çÂêåËØçÊ±áË°®ÁöÑ LLM ÁöÑ KD ÊñπÊ≥ï„ÄÇ

##### **Delving into the Utilisation of ChatGPT in Scientific Publications in Astronomy**
2406.17324v1 by Simone Astarita, Sandor Kruk, Jan Reerink, Pablo G√≥mez

Rapid progress in the capabilities of machine learning approaches in natural
language processing has culminated in the rise of large language models over
the last two years. Recent works have shown unprecedented adoption of these for
academic writing, especially in some fields, but their pervasiveness in
astronomy has not been studied sufficiently. To remedy this, we extract words
that ChatGPT uses more often than humans when generating academic text and
search a total of 1 million articles for them. This way, we assess the
frequency of word occurrence in published works in astronomy tracked by the
NASA Astrophysics Data System since 2000. We then perform a statistical
analysis of the occurrences. We identify a list of words favoured by ChatGPT
and find a statistically significant increase for these words against a control
group in 2024, which matches the trend in other disciplines. These results
suggest a widespread adoption of these models in the writing of astronomy
papers. We encourage organisations, publishers, and researchers to work
together to identify ethical and pragmatic guidelines to maximise the benefits
of these systems while maintaining scientific rigour.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊñπÊ≥ïÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜËÉΩÂäõÊñπÈù¢ÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåÂú®ÈÅéÂéªÂÖ©Âπ¥‰∏≠ÈÅîÂà∞‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑËààËµ∑„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÈÄô‰∫õÊ®°ÂûãÂú®Â≠∏Ë°ìÂØ´‰Ωú‰∏≠ÂæóÂà∞‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÊé°Áî®ÔºåÁâπÂà•ÊòØÂú®Êüê‰∫õÈ†òÂüüÔºå‰ΩÜÂÆÉÂÄëÂú®Â§©ÊñáÊñπÈù¢ÁöÑÊôÆÂèäÁ®ãÂ∫¶Â∞öÊú™ÂæóÂà∞ÂÖÖÂàÜÁöÑÁ†îÁ©∂„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÊèêÂèñ‰∫Ü ChatGPT Âú®ÁîüÊàêÂ≠∏Ë°ìÊñáÊú¨ÊôÇÊØî‰∫∫È°ûÊõ¥Â∏∏‰ΩøÁî®ÁöÑË©ûÂΩôÔºå‰∏¶Âú®Á∏ΩË®à 100 Ëê¨ÁØáÊñáÁ´†‰∏≠ÊêúÂ∞ãÈÄô‰∫õË©ûÂΩô„ÄÇÈÄöÈÅéÈÄôÁ®ÆÊñπÂºèÔºåÊàëÂÄëË©ï‰º∞‰∫ÜËá™ 2000 Âπ¥‰ª•‰æÜ NASA Â§©È´îÁâ©ÁêÜÊï∏ÊìöÁ≥ªÁµ±ËøΩËπ§ÁöÑÂ§©ÊñáÂ≠∏Â∑≤ÁôºË°®‰ΩúÂìÅ‰∏≠Ë©ûÂΩôÂá∫ÁèæÁöÑÈ†ªÁéá„ÄÇÁÑ∂ÂæåÊàëÂÄëÂ∞çÂá∫ÁèæÁöÑÈ†ªÁéáÈÄ≤Ë°åÁµ±Ë®àÂàÜÊûê„ÄÇÊàëÂÄëÊâæÂá∫ ChatGPT ÂÅèÂ•ΩÁöÑË©ûÂΩôÊ∏ÖÂñÆÔºå‰∏¶ÁôºÁèæÈÄô‰∫õË©ûÂΩôÂú® 2024 Âπ¥Áõ∏Â∞çÊñºÂ∞çÁÖßÁµÑÊúâÁµ±Ë®àÈ°ØËëóÁöÑÂ¢ûÂä†ÔºåÈÄôËàáÂÖ∂‰ªñÂ≠∏ÁßëÁöÑË∂®Âã¢Áõ∏Á¨¶„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÈÄô‰∫õÊ®°ÂûãÂú®Êí∞ÂØ´Â§©ÊñáÂ≠∏Ë´ñÊñáÊñπÈù¢ÂæóÂà∞‰∫ÜÂª£Ê≥õÊé°Áî®„ÄÇÊàëÂÄëÈºìÂãµÁµÑÁπî„ÄÅÂá∫ÁâàÂïÜÂíåÁ†îÁ©∂‰∫∫Âì°ÂÖ±ÂêåÂä™ÂäõÔºåÊâæÂá∫Âêà‰πéÈÅìÂæ∑ÂíåÂØ¶Áî®ÁöÑÊ∫ñÂâáÔºå‰ª•ÊúÄÂ§ßÂåñÈÄô‰∫õÁ≥ªÁµ±ÁöÑÁõäËôïÔºåÂêåÊôÇ‰øùÊåÅÁßëÂ≠∏ÁöÑÂö¥Ë¨πÊÄß„ÄÇ

##### **Retrieval Augmented Instruction Tuning for Open NER with Large Language Models**
2406.17305v1 by Tingyu Xie, Jian Zhang, Yan Zhang, Yuanyuan Liang, Qi Li, Hongwei Wang

The strong capability of large language models (LLMs) has been applied to
information extraction (IE) through either retrieval augmented prompting or
instruction tuning (IT). However, the best way to incorporate information with
LLMs for IE remains an open question. In this paper, we explore Retrieval
Augmented Instruction Tuning (RA-IT) for IE, focusing on the task of open named
entity recognition (NER). Specifically, for each training sample, we retrieve
semantically similar examples from the training dataset as the context and
prepend them to the input of the original instruction. To evaluate our RA-IT
approach more thoroughly, we construct a Chinese IT dataset for open NER and
evaluate RA-IT in both English and Chinese scenarios. Experimental results
verify the effectiveness of RA-IT across various data sizes and in both English
and Chinese scenarios. We also conduct thorough studies to explore the impacts
of various retrieval strategies in the proposed RA-IT framework. Code and data
are available at: https://github.com/Emma1066/Retrieval-Augmented-IT-OpenNER

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂº∑Â§ßÂäüËÉΩÂ∑≤ÈÄèÈÅéÊ™¢Á¥¢Êì¥ÂÖÖÊèêÁ§∫ÊàñÊåá‰ª§ÂæÆË™ø (IT) ÊáâÁî®ÊñºË≥áË®äËêÉÂèñ (IE)„ÄÇÁÑ∂ËÄåÔºåÂ∞áË≥áË®äËàá LLM Êï¥Âêà‰ª•ÈÄ≤Ë°å IE ÁöÑÊúÄ‰Ω≥ÊñπÂºè‰ªçÊòØ‰∏ÄÂÄãÈñãÊîæÊÄßÁöÑÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁî®Êñº IE ÁöÑÊ™¢Á¥¢Êì¥ÂÖÖÊåá‰ª§ÂæÆË™ø (RA-IT)ÔºåÈáçÈªûÊîæÂú®ÈñãÊîæÂºèÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÁöÑ‰ªªÂãô‰∏ä„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂ∞çÊñºÊØèÂÄãË®ìÁ∑¥ÁØÑ‰æãÔºåÊàëÂÄëÂæûË®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏≠Êì∑ÂèñË™ûÁæ©‰∏äÁõ∏‰ººÁöÑÁØÑ‰æã‰ΩúÁÇ∫ËÉåÊôØÔºå‰∏¶Â∞áÂÆÉÂÄëÂä†Âà∞ÂéüÂßãÊåá‰ª§ÁöÑËº∏ÂÖ•‰πãÂâç„ÄÇÁÇ∫‰∫ÜÊõ¥ÂæπÂ∫ïÂú∞Ë©ï‰º∞ÊàëÂÄëÁöÑ RA-IT ÊñπÊ≥ïÔºåÊàëÂÄëÂª∫Êßã‰∫Ü‰∏ÄÂÄãÁî®ÊñºÈñãÊîæÂºè NER ÁöÑ‰∏≠Êñá IT Ë≥áÊñôÈõÜÔºå‰∏¶Âú®Ëã±ÊñáÂíå‰∏≠ÊñáÂ†¥ÊôØ‰∏≠Ë©ï‰º∞ RA-IT„ÄÇÂØ¶È©óÁµêÊûúÈ©óË≠â‰∫Ü RA-IT Âú®ÂêÑÁ®ÆË≥áÊñôÂ§ßÂ∞è‰ª•ÂèäËã±ÊñáÂíå‰∏≠ÊñáÂ†¥ÊôØ‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄë‰πüÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑÁ†îÁ©∂Ôºå‰ª•Êé¢Ë®éÂú®ÊèêË≠∞ÁöÑ RA-IT Êû∂Êßã‰∏≠ÂêÑÁ®ÆÊ™¢Á¥¢Á≠ñÁï•ÁöÑÂΩ±Èüø„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/Emma1066/Retrieval-Augmented-IT-OpenNER ÂèñÂæó

##### **Leveraging LLMs for Dialogue Quality Measurement**
2406.17304v1 by Jinghan Jia, Abi Komma, Timothy Leffel, Xujun Peng, Ajay Nagesh, Tamer Soliman, Aram Galstyan, Anoop Kumar

In task-oriented conversational AI evaluation, unsupervised methods poorly
correlate with human judgments, and supervised approaches lack generalization.
Recent advances in large language models (LLMs) show robust zeroshot and
few-shot capabilities across NLP tasks. This paper explores using LLMs for
automated dialogue quality evaluation, experimenting with various
configurations on public and proprietary datasets. Manipulating factors such as
model size, in-context examples, and selection techniques, we examine
"chain-of-thought" (CoT) reasoning and label extraction procedures. Our results
show that (1) larger models yield more accurate dialogue labels; (2)
algorithmic selection of in-context examples outperforms random selection; (3)
CoT reasoning where an LLM is asked to provide justifications before outputting
final labels improves performance; and (4) fine-tuned LLMs outperform
out-of-the-box ones. Our results indicate that LLMs that are suitably
fine-tuned and have sufficient reasoning capabilities can be leveraged for
automated dialogue evaluation.

ÊëòË¶ÅÔºöÂú®Èù¢Âêë‰ªªÂãôÁöÑÂ∞çË©±Âºè AI Ë©ï‰º∞‰∏≠ÔºåÈùûÁõ£Áù£ÂºèÊñπÊ≥ïËàá‰∫∫È°ûÂà§Êñ∑ÈóúËÅØÊÄß‰ΩéÔºåËÄåÁõ£Áù£ÂºèÊñπÊ≥ïÁº∫‰πèÊ¶ÇÊã¨ÊÄß„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂú®ÂêÑÁ®Æ NLP ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫Âº∑Â§ßÁöÑÈõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÊ¨°Â≠∏ÁøíËÉΩÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®é‰ΩøÁî® LLM ÈÄ≤Ë°åËá™ÂãïÂ∞çË©±ÂìÅË≥™Ë©ï‰º∞Ôºå‰∏¶Âú®ÂÖ¨ÈñãÂíåÂ∞àÊúâË≥áÊñôÈõÜ‰∏äÂòóË©¶ÂêÑÁ®ÆË®≠ÂÆö„ÄÇÊàëÂÄëÈÄèÈÅéË™øÊï¥Ê®°ÂûãÂ§ßÂ∞è„ÄÅËÑàÁµ°ÁØÑ‰æãÂíåÈÅ∏ÊìáÊäÄË°ìÁ≠âÂõ†Á¥†ÔºåÊ™¢Ë¶ñ„ÄåÊÄùÁ∂≠Èèà„Äç(CoT) Êé®ÁêÜÂíåÊ®ôÁ±§ËêÉÂèñÁ®ãÂ∫è„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫Ôºö(1) ËºÉÂ§ßÁöÑÊ®°ÂûãÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫ÁöÑÂ∞çË©±Ê®ôÁ±§Ôºõ(2) ËÑàÁµ°ÁØÑ‰æãÁöÑÊºîÁÆóÊ≥ïÈÅ∏ÊìáÂÑ™ÊñºÈö®Ê©üÈÅ∏ÊìáÔºõ(3) CoT Êé®ÁêÜÔºåÂÖ∂‰∏≠Ë¶ÅÊ±Ç LLM Âú®Ëº∏Âá∫ÊúÄÁµÇÊ®ôÁ±§ÂâçÊèê‰æõ‰æùÊìöÔºåÂèØÊîπÂñÑÊïàËÉΩÔºõ(4) ÂæÆË™øÂæåÁöÑ LLM ÂÑ™ÊñºÈñãÁÆ±Âç≥Áî®ÁöÑ LLM„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÈÅ©Áï∂Âú∞ÂæÆË™ø‰∏îÂÖ∑ÂÇôË∂≥Â§†Êé®ÁêÜËÉΩÂäõÁöÑ LLM ÂèØÁî®ÊñºËá™ÂãïÂ∞çË©±Ë©ï‰º∞„ÄÇ

##### **Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models**
2406.17294v2 by Wenhao Shi, Zhiqiang Hu, Yi Bin, Junhua Liu, Yang Yang, See-Kiong Ng, Lidong Bing, Roy Ka-Wei Lee

Large language models (LLMs) have demonstrated impressive reasoning
capabilities, particularly in textual mathematical problem-solving. However,
existing open-source image instruction fine-tuning datasets, containing limited
question-answer pairs per image, do not fully exploit visual information to
enhance the multimodal mathematical reasoning capabilities of Multimodal LLMs
(MLLMs). To bridge this gap, we address the lack of high-quality, diverse
multimodal mathematical datasets by collecting 40K high-quality images with
question-answer pairs from 24 existing datasets and synthesizing 320K new
pairs, creating the MathV360K dataset, which enhances both the breadth and
depth of multimodal mathematical questions. We introduce Math-LLaVA, a
LLaVA-1.5-based model fine-tuned with MathV360K. This novel approach
significantly improves the multimodal mathematical reasoning capabilities of
LLaVA-1.5, achieving a 19-point increase and comparable performance to GPT-4V
on MathVista's minitest split. Furthermore, Math-LLaVA demonstrates enhanced
generalizability, showing substantial improvements on the MMMU benchmark. Our
research highlights the importance of dataset diversity and synthesis in
advancing MLLMs' mathematical reasoning abilities. The code and data are
available at: \url{https://github.com/HZQ950419/Math-LLaVA}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂ∞§ÂÖ∂Âú®ÊñáÂ≠óÊï∏Â≠∏ÂïèÈ°åÊ±ÇËß£ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈñãÊîæÂéüÂßãÁ¢ºÂΩ±ÂÉèÊåá‰ª§ÂæÆË™øË≥áÊñôÈõÜÂåÖÂê´ÊØèÂÄãÂΩ±ÂÉèÊúâÈôêÁöÑÂïèÈ°åËß£Á≠îÈÖçÂ∞çÔºå‰∏¶Êú™ÂÖÖÂàÜÂà©Áî®Ë¶ñË¶∫Ë≥áË®ä‰æÜÂ¢ûÂº∑Â§öÊ®°ÊÖã LLM (MLLM) ÁöÑÂ§öÊ®°ÊÖãÊï∏Â≠∏Êé®ÁêÜËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÈÄèÈÅéÂæû 24 ÂÄãÁèæÊúâË≥áÊñôÈõÜ‰∏≠Êî∂ÈõÜ 40K ÂÄãÈôÑÊúâÂïèÈ°åËß£Á≠îÈÖçÂ∞çÁöÑÈ´òÂìÅË≥™ÂΩ±ÂÉèÔºå‰∏¶ÂêàÊàê 320K ÂÄãÊñ∞ÈÖçÂ∞çÔºåËß£Ê±∫‰∫ÜÁº∫‰πèÈ´òÂìÅË≥™„ÄÅÂ§öÊ®£ÂåñÁöÑÂ§öÊ®°ÊÖãÊï∏Â≠∏Ë≥áÊñôÈõÜÁöÑÂïèÈ°åÔºåÈÄ≤ËÄåÂª∫Á´ã‰∫Ü MathV360K Ë≥áÊñôÈõÜÔºåË©≤Ë≥áÊñôÈõÜÊì¥Â±ï‰∫ÜÂ§öÊ®°ÊÖãÊï∏Â≠∏ÂïèÈ°åÁöÑÂª£Â∫¶ÂíåÊ∑±Â∫¶„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü Math-LLaVAÔºåÈÄôÊòØ‰∏ÄÂÄã‰ª• MathV360K ÂæÆË™øÁöÑ LLaVA-1.5 Âü∫Á§éÊ®°Âûã„ÄÇÈÄôÁ®ÆÊñ∞ÊñπÊ≥ïÂ§ßÂπÖÊîπÂñÑ‰∫Ü LLaVA-1.5 ÁöÑÂ§öÊ®°ÊÖãÊï∏Â≠∏Êé®ÁêÜËÉΩÂäõÔºåÂú® MathVista ÁöÑËø∑‰Ω†Ê∏¨Ë©¶ÂàÜÂâ≤‰∏≠Áç≤Âæó‰∫Ü 19 ÂàÜÁöÑÊèêÂçáÔºå‰∏¶ÈÅîÂà∞Ëàá GPT-4V Áõ∏Áï∂ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåMath-LLaVA Â±ïÁèæÂá∫Â¢ûÂº∑ÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂú® MMMU Ë©ïÈáèÂü∫Ê∫ñ‰∏äÁç≤Âæó‰∫ÜÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Á™ÅÈ°Ø‰∫ÜË≥áÊñôÈõÜÂ§öÊ®£ÊÄßÂíåÂêàÊàêÂú®ÊèêÂçá MLLM Êï∏Â≠∏Êé®ÁêÜËÉΩÂäõÊñπÈù¢ÁöÑÈáçË¶ÅÊÄß„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÊñº‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºö\url{https://github.com/HZQ950419/Math-LLaVA}„ÄÇ

##### **Hyperbolic Knowledge Transfer in Cross-Domain Recommendation System**
2406.17289v1 by Xin Yang, Heng Chang, Zhijian La, Jinze Yang, Xingrun Li, Yu Lu, Shuaiqiang Wang, Dawei Yin, Erxue Min

Cross-Domain Recommendation (CDR) seeks to utilize knowledge from different
domains to alleviate the problem of data sparsity in the target recommendation
domain, and it has been gaining more attention in recent years. Although there
have been notable advancements in this area, most current methods represent
users and items in Euclidean space, which is not ideal for handling long-tail
distributed data in recommendation systems. Additionally, adding data from
other domains can worsen the long-tail characteristics of the entire dataset,
making it harder to train CDR models effectively. Recent studies have shown
that hyperbolic methods are particularly suitable for modeling long-tail
distributions, which has led us to explore hyperbolic representations for users
and items in CDR scenarios. However, due to the distinct characteristics of the
different domains, applying hyperbolic representation learning to CDR tasks is
quite challenging. In this paper, we introduce a new framework called
Hyperbolic Contrastive Learning (HCTS), designed to capture the unique features
of each domain while enabling efficient knowledge transfer between domains. We
achieve this by embedding users and items from each domain separately and
mapping them onto distinct hyperbolic manifolds with adjustable curvatures for
prediction. To improve the representations of users and items in the target
domain, we develop a hyperbolic contrastive learning module for knowledge
transfer. Extensive experiments on real-world datasets demonstrate that
hyperbolic manifolds are a promising alternative to Euclidean space for CDR
tasks.

ÊëòË¶ÅÔºöË∑®ÂüüÊé®Ëñ¶ÔºàCDRÔºâÊó®Âú®Âà©Áî®‰∏çÂêåÈ†òÂüüÁöÑÁü•Ë≠ò‰æÜÁ∑©Ëß£ÁõÆÊ®ôÊé®Ëñ¶È†òÂüü‰∏≠Ë≥áÊñôÁ®ÄÁñèÁöÑÂïèÈ°åÔºå‰∏¶‰∏îËøëÂπ¥‰æÜÂÇôÂèóÈóúÊ≥®„ÄÇÂÑòÁÆ°Âú®Ê≠§È†òÂüüÂ∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜÂ§ßÂ§öÊï∏Áï∂ÂâçÊñπÊ≥ïÈÉΩÂú®Ê≠êÂπæÈáåÂæóÁ©∫Èñì‰∏≠Ë°®Á§∫‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆÔºåÈÄô‰∏¶‰∏çÈÅ©ÂêàËôïÁêÜÊé®Ëñ¶Á≥ªÁµ±‰∏≠ÁöÑÈï∑Â∞æÂàÜ‰ΩàË≥áÊñô„ÄÇÊ≠§Â§ñÔºåÂæûÂÖ∂‰ªñÈ†òÂüüÊñ∞Â¢ûË≥áÊñôÂèØËÉΩÊúÉÊÉ°ÂåñÊï¥ÂÄãË≥áÊñôÈõÜÁöÑÈï∑Â∞æÁâπÊÄßÔºåÈÄô‰ΩøÂæóÊõ¥Èõ£ÊúâÊïàË®ìÁ∑¥ CDR Ê®°Âûã„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÈõôÊõ≤ÊñπÊ≥ïÁâπÂà•ÈÅ©ÂêàÊñºÂ∞çÈï∑Â∞æÂàÜ‰ΩàÈÄ≤Ë°åÂª∫Ê®°ÔºåÈÄô‰øÉ‰ΩøÊàëÂÄëÊé¢Á¥¢ CDR Â†¥ÊôØ‰∏≠‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆÁöÑÈõôÊõ≤Ë°®Á§∫„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰∏çÂêåÈ†òÂüüÁöÑÁç®ÁâπÁâπÊÄßÔºåÂ∞áÈõôÊõ≤Ë°®Á§∫Â≠∏ÁøíÊáâÁî®Êñº CDR ‰ªªÂãôÈùûÂ∏∏ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁ®±ÁÇ∫ÈõôÊõ≤Â∞çÊØîÂ≠∏ÁøíÔºàHCTSÔºâÁöÑÊñ∞Ê°ÜÊû∂ÔºåÊó®Âú®Êì∑ÂèñÊØèÂÄãÈ†òÂüüÁöÑÁç®ÁâπÁâπÂæµÔºåÂêåÊôÇÂØ¶ÁèæÈ†òÂüü‰πãÈñìÁöÑÊúâÊïàÁü•Ë≠òËΩâÁßª„ÄÇÊàëÂÄëÈÄèÈÅéÂàÜÂà•ÂµåÂÖ•ÊØèÂÄãÈ†òÂüüÁöÑ‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆÔºå‰∏¶Â∞áÂÆÉÂÄëÊò†Â∞ÑÂà∞ÂÖ∑ÊúâÂèØË™øÊï¥Êõ≤ÁéáÁöÑ‰∏çÂêåÈõôÊõ≤ÊµÅÂΩ¢‰∏ä‰ª•ÈÄ≤Ë°åÈ†êÊ∏¨Ôºå‰æÜÈÅîÊàêÊ≠§ÁõÆÊ®ô„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÁõÆÊ®ôÈ†òÂüü‰∏≠‰ΩøÁî®ËÄÖÂíåÈ†ÖÁõÆÁöÑË°®Á§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÈõôÊõ≤Â∞çÊØîÂ≠∏ÁøíÊ®°ÁµÑÔºåÁî®ÊñºÁü•Ë≠òËΩâÁßª„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂ§ßÈáèÂØ¶È©óË°®ÊòéÔºåÈõôÊõ≤ÊµÅÂΩ¢ÊòØ CDR ‰ªªÂãô‰∏≠Ê≠êÂπæÈáåÂæóÁ©∫ÈñìÁöÑÊúâÂ∏åÊúõÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ

##### **Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models**
2406.17287v1 by Yang Yan, Lizhi Ma, Anqi Li, Jingsong Ma, Zhenzhong Lan

Accurate assessment of personality traits is crucial for effective
psycho-counseling, yet traditional methods like self-report questionnaires are
time-consuming and biased. This study exams whether Large Language Models
(LLMs) can predict the Big Five personality traits directly from counseling
dialogues and introduces an innovative framework to perform the task. Our
framework applies role-play and questionnaire-based prompting to condition LLMs
on counseling sessions, simulating client responses to the Big Five Inventory.
We evaluated our framework on 853 real-world counseling sessions, finding a
significant correlation between LLM-predicted and actual Big Five traits,
proving the validity of framework. Moreover, ablation studies highlight the
importance of role-play simulations and task simplification via questionnaires
in enhancing prediction accuracy. Meanwhile, our fine-tuned Llama3-8B model,
utilizing Direct Preference Optimization with Supervised Fine-Tuning, achieves
a 130.95\% improvement, surpassing the state-of-the-art Qwen1.5-110B by 36.94\%
in personality prediction validity. In conclusion, LLMs can predict personality
based on counseling dialogues. Our code and model are publicly available at
\url{https://github.com/kuri-leo/BigFive-LLM-Predictor}, providing a valuable
tool for future research in computational psychometrics.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫Ë©ï‰º∞‰∫∫Ê†ºÁâπË≥™Â∞çÊñºÊúâÊïàÁöÑÂøÉÁêÜË´ÆÂïÜËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂÇ≥Áµ±ÊñπÊ≥ïÔºà‰æãÂ¶ÇËá™ÊàëÂ†±ÂëäÂïèÂç∑ÔºâÊó¢ËÄóÊôÇÂèàÂ≠òÂú®ÂÅèË¶ã„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÂê¶ËÉΩÁõ¥Êé•ÂæûË´ÆÂïÜÂ∞çË©±‰∏≠È†êÊ∏¨Â§ß‰∫î‰∫∫Ê†ºÁâπË≥™Ôºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊû∂Êßã‰æÜÂü∑Ë°åÈÄôÈ†Ö‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÊáâÁî®ËßíËâ≤ÊâÆÊºîÂíåÂü∫ÊñºÂïèÂç∑ÁöÑÊèêÁ§∫ÔºåÂú®Ë´ÆÂïÜÊúÉË´á‰∏≠Â∞ç LLM ÈÄ≤Ë°åÊ¢ù‰ª∂ÂåñÔºåÊ®°Êì¨ÂÆ¢Êà∂Â∞çÂ§ß‰∫î‰∫∫Ê†ºÈáèË°®ÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÂ∞ç 853 ÂÄãÁúüÂØ¶‰∏ñÁïåÁöÑË´ÆÂïÜÊúÉË´áË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊû∂ÊßãÔºåÁôºÁèæ LLM È†êÊ∏¨ÁöÑÂ§ß‰∫îÁâπË≥™ËàáÂØ¶ÈöõÂ§ß‰∫îÁâπË≥™‰πãÈñìÂ≠òÂú®È°ØËëóÁõ∏ÈóúÊÄßÔºåË≠âÊòé‰∫ÜÊû∂ÊßãÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊ∂àËûçÁ†îÁ©∂Âº∑Ë™ø‰∫ÜËßíËâ≤ÊâÆÊºîÊ®°Êì¨ÂíåÈÄèÈÅéÂïèÂç∑Á∞°Âåñ‰ªªÂãôÂ∞çÊñºÊèêÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÂêåÊôÇÔºåÊàëÂÄëÂæÆË™øÂæåÁöÑ Llama3-8B Ê®°ÂûãÔºåÂà©Áî®Â∏∂ÊúâÁõ£Áù£ÂæÆË™øÁöÑÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºåÂú®‰∫∫Ê†ºÈ†êÊ∏¨ÊúâÊïàÊÄß‰∏äÂèñÂæó‰∫Ü 130.95% ÁöÑÊîπÈÄ≤ÔºåÊØîÊúÄÂÖàÈÄ≤ÁöÑ Qwen1.5-110B È´òÂá∫ 36.94%„ÄÇÁ∏Ω‰πãÔºåLLM ÂèØ‰ª•Ê†πÊìöË´ÆÂïÜÂ∞çË©±È†êÊ∏¨‰∫∫Ê†º„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂ∑≤ÂÖ¨ÈñãÁôºÂ∏ÉÂú® \url{https://github.com/kuri-leo/BigFive-LLM-Predictor}ÔºåÁÇ∫Ë®àÁÆóÂøÉÁêÜÊ∏¨ÈáèÂ≠∏ÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑÂ∑•ÂÖ∑„ÄÇ

##### **SetBERT: Enhancing Retrieval Performance for Boolean Logic and Set Operation Queries**
2406.17282v2 by Quan Mai, Susan Gauch, Douglas Adams

We introduce SetBERT, a fine-tuned BERT-based model designed to enhance query
embeddings for set operations and Boolean logic queries, such as Intersection
(AND), Difference (NOT), and Union (OR). SetBERT significantly improves
retrieval performance for logic-structured queries, an area where both
traditional and neural retrieval methods typically underperform. We propose an
innovative use of inversed-contrastive loss, focusing on identifying the
negative sentence, and fine-tuning BERT with a dataset generated via prompt
GPT. Furthermore, we demonstrate that, unlike other BERT-based models,
fine-tuning with triplet loss actually degrades performance for this specific
task. Our experiments reveal that SetBERT-base not only significantly
outperforms BERT-base (up to a 63% improvement in Recall) but also achieves
performance comparable to the much larger BERT-large model, despite being only
one-third the size.

ÊëòË¶ÅÔºöÊàëÂÄëÂºïÂÖ•‰∫Ü SetBERTÔºå‰∏ÄÂÄãÁ∂ìÈÅéÂæÆË™øÁöÑ BERT Ê®°ÂûãÔºåÊó®Âú®Â¢ûÂº∑ÈõÜÂêàÈÅãÁÆóÂíåÂ∏ÉÊûóÈÇèËºØÊü•Ë©¢Ôºà‰æãÂ¶Ç‰∫§ÈõÜ (AND)„ÄÅÂ∑ÆÈõÜ (NOT) ÂíåËÅØÈõÜ (OR)ÔºâÁöÑÊü•Ë©¢ÂµåÂÖ•„ÄÇSetBERT Â§ßÂπÖÊèêÂçá‰∫ÜÈÇèËºØÁµêÊßãÊü•Ë©¢ÁöÑÊ™¢Á¥¢ÊïàËÉΩÔºåÈÄôÊòØÂÇ≥Áµ±ÂíåÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ™¢Á¥¢ÊñπÊ≥ïÈÄöÂ∏∏Ë°®Áèæ‰∏ç‰Ω≥ÁöÑÈ†òÂüü„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÂèçÂêëÂ∞çÊØîÊêçÂ§±‰ΩøÁî®ÊñπÂºèÔºåÂ∞àÊ≥®ÊñºË≠òÂà•Ë≤†ÂêëÂè•Â≠êÔºå‰∏¶‰ΩøÁî®ÈÄèÈÅéÊèêÁ§∫ GPT ÁîüÊàêÁöÑË≥áÊñôÈõÜÂæÆË™ø BERT„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòé‰∫ÜËàáÂÖ∂‰ªñ BERT Ê®°Âûã‰∏çÂêåÔºå‰ΩøÁî®‰∏âÈáçÊêçÂ§±ÈÄ≤Ë°åÂæÆË™øÂØ¶Èöõ‰∏äÊúÉÈôç‰ΩéÊ≠§ÁâπÂÆö‰ªªÂãôÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåSetBERT-base ‰∏çÂÉÖÈ°ØËëóÂÑ™Êñº BERT-baseÔºàÂè¨ÂõûÁéáÊèêÂçáÈÅî 63%ÔºâÔºåËÄå‰∏îÂÑòÁÆ°Âè™Êúâ‰∏âÂàÜ‰πã‰∏ÄÁöÑÂ§ßÂ∞èÔºå‰ΩÜÊïàËÉΩÂèØËàáÂ§ßÂæóÂ§öÁöÑ BERT-large Ê®°ÂûãÁõ∏Â™≤Áæé„ÄÇ

##### **OPT-Tree: Speculative Decoding with Adaptive Draft Tree Structure**
2406.17276v1 by Jikai Wang, Yi Su, Juntao Li, Qinrong Xia, Zi Ye, Xinyu Duan, Zhefeng Wang, Min Zhang

Autoregressive language models demonstrate excellent performance in various
scenarios. However, the inference efficiency is limited by its
one-step-one-word generation mode, which has become a pressing problem recently
as the models become increasingly larger. Speculative decoding employs a "draft
and then verify" mechanism to allow multiple tokens to be generated in one
step, realizing lossless acceleration. Existing methods mainly adopt fixed
heuristic draft structures, which fail to adapt to different situations to
maximize the acceptance length during verification. To alleviate this dilemma,
we proposed OPT-Tree, an algorithm to construct adaptive and scalable draft
trees. It searches the optimal tree structure that maximizes the mathematical
expectation of the acceptance length in each decoding step. Experimental
results reveal that OPT-Tree outperforms the existing draft structures and
achieves a speed-up ratio of up to 3.2 compared with autoregressive decoding.
If the draft model is powerful enough and the node budget is sufficient, it can
generate more than ten tokens in a single step. Our code is available at
https://github.com/Jikai0Wang/OPT-Tree.

ÊëòË¶ÅÔºöËá™ÂõûÂΩíËØ≠Ë®ÄÊ®°ÂûãÂú®ÂêÑÁßçÂú∫ÊôØ‰∏≠Ë°®Áé∞Âá∫‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂÖ∂Êé®ÁêÜÊïàÁéáÂèóÂà∞ÂÖ∂‰∏ÄÊ≠•‰∏ÄËØçÁöÑÁîüÊàêÊ®°ÂºèÁöÑÈôêÂà∂ÔºåÈöèÁùÄÊ®°ÂûãÂèòÂæóË∂äÊù•Ë∂äÂ§ßÔºåËøôÂ∑≤Êàê‰∏∫ÊúÄËøëÁöÑ‰∏Ä‰∏™Á¥ßËø´ÈóÆÈ¢ò„ÄÇÊé®ÊµãËß£Á†ÅÈááÁî®‚ÄúÂÖàËµ∑ËçâÂÜçÈ™åËØÅ‚ÄùÁöÑÊú∫Âà∂ÔºåÂÖÅËÆ∏‰∏ÄÊ≠•ÁîüÊàêÂ§ö‰∏™Ê†áËÆ∞ÔºåÂÆûÁé∞Êó†ÊçüÂä†ÈÄü„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÈááÁî®Âõ∫ÂÆöÁöÑÂêØÂèëÂºèËçâÁ®øÁªìÊûÑÔºåÊó†Ê≥ïÈÄÇÂ∫î‰∏çÂêåÁöÑÊÉÖÂÜµ‰ª•ÊúÄÂ§ßÂåñÈ™åËØÅÊúüÈó¥ÁöÑÊé•ÂèóÈïøÂ∫¶„ÄÇ‰∏∫‰∫ÜÁºìËß£Ëøô‰∏ÄÂõ∞Â¢ÉÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü OPT-TreeÔºå‰∏ÄÁßçÊûÑÂª∫Ëá™ÈÄÇÂ∫î‰∏îÂèØÊâ©Â±ïÁöÑËçâÁ®øÊ†ëÁöÑÁÆóÊ≥ï„ÄÇÂÆÉÊêúÁ¥¢ÊúÄ‰ºòÊ†ëÁªìÊûÑÔºå‰ª•ÊúÄÂ§ßÂåñÊØè‰∏™Ëß£Á†ÅÊ≠•È™§‰∏≠Êé•ÂèóÈïøÂ∫¶ÁöÑÊï∞Â≠¶ÊúüÊúõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåOPT-Tree ‰ºò‰∫éÁé∞ÊúâÁöÑËçâÁ®øÁªìÊûÑÔºå‰∏éËá™ÂõûÂΩíËß£Á†ÅÁõ∏ÊØîÔºåÂÆûÁé∞‰∫ÜÈ´òËææ 3.2 ÁöÑÂä†ÈÄüÊØî„ÄÇÂ¶ÇÊûúËçâÁ®øÊ®°ÂûãË∂≥Â§üÂº∫Â§ßÔºåÂπ∂‰∏îËäÇÁÇπÈ¢ÑÁÆóÂÖÖË∂≥ÔºåÂÆÉÂèØ‰ª•Âú®‰∏ÄÊ≠•‰∏≠ÁîüÊàêÂçÅÂ§ö‰∏™Ê†áËÆ∞„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØ‰ª•Âú® https://github.com/Jikai0Wang/OPT-Tree ‰∏≠Ëé∑Âæó„ÄÇ

##### **Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?**
2406.17274v1 by Jianfeng He, Runing Yang, Linlin Yu, Changbin Li, Ruoxi Jia, Feng Chen, Ming Jin, Chang-Tien Lu

Text summarization, a key natural language generation (NLG) task, is vital in
various domains. However, the high cost of inaccurate summaries in
risk-critical applications, particularly those involving human-in-the-loop
decision-making, raises concerns about the reliability of uncertainty
estimation on text summarization (UE-TS) evaluation methods. This concern stems
from the dependency of uncertainty model metrics on diverse and potentially
conflicting NLG metrics. To address this issue, we introduce a comprehensive
UE-TS benchmark incorporating 31 NLG metrics across four dimensions. The
benchmark evaluates the uncertainty estimation capabilities of two large
language models and one pre-trained language model on three datasets, with
human-annotation analysis incorporated where applicable. We also assess the
performance of 14 common uncertainty estimation methods within this benchmark.
Our findings emphasize the importance of considering multiple uncorrelated NLG
metrics and diverse uncertainty estimation methods to ensure reliable and
efficient evaluation of UE-TS techniques.

ÊëòË¶ÅÔºöÊñáÊú¨ÊëòË¶ÅÔºå‰∏ÄÁ®ÆÈóúÈçµÁöÑËá™ÁÑ∂Ë™ûË®ÄÁîüÊàê (NLG) ‰ªªÂãôÔºåÂú®ÂêÑÁ®ÆÈ†òÂüü‰∏≠Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂú®È¢®Èö™ÈóúÈçµÊáâÁî®‰∏≠‰∏çÊ∫ñÁ¢∫ÊëòË¶ÅÁöÑÈ´òÊàêÊú¨ÔºåÁâπÂà•ÊòØÈÇ£‰∫õÊ∂âÂèä‰∫∫È°ûÂèÉËàáÊ±∫Á≠ñÁöÑÊáâÁî®ÔºåÂºïËµ∑‰∫Ü‰∫∫ÂÄëÂ∞çÊñáÊú¨ÊëòË¶Å‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®à (UE-TS) Ë©ï‰º∞ÊñπÊ≥ïÂèØÈù†ÊÄßÁöÑÊìîÊÜÇ„ÄÇÈÄôÁ®ÆÊìîÊÜÇÊ∫êÊñº‰∏çÁ¢∫ÂÆöÊÄßÊ®°ÂûãÊåáÊ®ôÂ∞çÂ§öÊ®£‰∏îÊΩõÂú®Ë°ùÁ™ÅÁöÑ NLG ÊåáÊ®ôÁöÑ‰æùË≥¥ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ∂úÂêà UE-TS Âü∫Ê∫ñÔºåÂåÖÂê´‰∫ÜÂõõÂÄãÁ∂≠Â∫¶‰∏≠ÁöÑ 31 ÂÄã NLG ÊåáÊ®ô„ÄÇË©≤Âü∫Ê∫ñË©ï‰º∞‰∫ÜÂÖ©ÂÄãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂíå‰∏ÄÂÄãÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂú®‰∏âÂÄãÊï∏ÊìöÈõÜ‰∏äÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àËÉΩÂäõÔºå‰∏¶Âú®ÈÅ©Áî®ÁöÑÊÉÖÊ≥Å‰∏ãÁ¥çÂÖ•‰∫Ü‰∫∫Â∑•Ë®ªÈáãÂàÜÊûê„ÄÇÊàëÂÄëÈÇÑÂú®ÈÄôÂÄãÂü∫Ê∫ñ‰∏≠Ë©ï‰º∞‰∫Ü 14 Á®ÆÂ∏∏Ë¶ãÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜËÄÉÊÖÆÂ§öÂÄã‰∏çÁõ∏ÈóúÁöÑ NLG ÊåáÊ®ôÂíåÂ§öÊ®£ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊñπÊ≥ï‰ª•Á¢∫‰øù UE-TS ÊäÄË°ìÁöÑÂèØÈù†‰∏îÊúâÊïàÁöÑË©ï‰º∞ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**
2406.17271v1 by Zhehao Zhang, Jiaao Chen, Diyi Yang

The current paradigm of evaluating Large Language Models (LLMs) through
static benchmarks comes with significant limitations, such as vulnerability to
data contamination and a lack of adaptability to the evolving capabilities of
LLMs. Therefore, evaluation methods that can adapt and generate evaluation data
with controlled complexity are urgently needed. In this work, we introduce
Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to
dynamically extend current benchmarks with controlled complexity and diversity.
Specifically, we first extract the reasoning graphs of data points in current
benchmarks and then perturb the reasoning graphs to generate novel testing
data. Such newly generated test samples can have different levels of complexity
while maintaining linguistic diversity similar to the original benchmarks. We
further use a code-augmented LLM to ensure the label correctness of newly
generated data. We apply our DARG framework to diverse reasoning tasks in four
domains with 15 state-of-the-art LLMs. Experimental results show that almost
all LLMs experience a performance decrease with increased complexity and
certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit
more biases when being evaluated via the data generated by DARG with higher
complexity levels. These observations provide useful insights into how to
dynamically and adaptively evaluate LLMs. The code is available at
https://github.com/SALT-NLP/DARG.

ÊëòË¶ÅÔºöÁõÆÂâçÈÄèÈÅéÈùúÊÖãÂü∫Ê∫ñË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁØÑ‰æã‰º¥Èö®ËëóÈ°ØËëóÁöÑÈôêÂà∂Ôºå‰æãÂ¶ÇÂÆπÊòìÂèóÂà∞Ë≥áÊñôÊ±°ÊüìÔºå‰ª•ÂèäÁº∫‰πèÈÅ©Êáâ LLM ‰∏çÊñ∑ÊºîÈÄ≤ÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåËø´ÂàáÈúÄË¶ÅËÉΩÂ§†ÈÅ©Êáâ‰∏¶Áî¢ÁîüÂÖ∑ÊúâÂèóÊéßË§áÈõúÊÄßÁöÑË©ï‰º∞Ë≥áÊñôÁöÑË©ï‰º∞ÊñπÊ≥ï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéËá™ÈÅ©ÊáâÊé®ÁêÜÂúñÂΩ¢ÊºîÂåñ (DARG) ÂºïÂÖ• LLM ÁöÑÂãïÊÖãË©ï‰º∞Ôºå‰ª•ÂãïÊÖãÂª∂‰º∏ÁõÆÂâçÂÖ∑ÊúâÂèóÊéßË§áÈõúÊÄßÂíåÂ§öÊ®£ÊÄßÁöÑÂü∫Ê∫ñ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÊì∑ÂèñÁõÆÂâçÂü∫Ê∫ñ‰∏≠Ë≥áÊñôÈªûÁöÑÊé®ÁêÜÂúñÂΩ¢ÔºåÁÑ∂ÂæåÊìæÂãïÊé®ÁêÜÂúñÂΩ¢‰ª•Áî¢ÁîüÊñ∞ÁöÑÊ∏¨Ë©¶Ë≥áÊñô„ÄÇÈÄô‰∫õÊñ∞Áî¢ÁîüÁöÑÊ∏¨Ë©¶Ê®£Êú¨ÂèØ‰ª•Êúâ‰∏çÂêåÁöÑË§áÈõúÊÄßÂ±§Á¥öÔºåÂêåÊôÇÁ∂≠ÊåÅËàáÂéüÂßãÂü∫Ê∫ñÈ°û‰ººÁöÑË™ûË®ÄÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•‰ΩøÁî®Á®ãÂºèÁ¢ºÂ¢ûÂº∑ÁöÑ LLM ‰æÜÁ¢∫‰øùÊñ∞Áî¢ÁîüË≥áÊñôÁöÑÊ®ôÁ±§Ê≠£Á¢∫ÊÄß„ÄÇÊàëÂÄëÂ∞á DARG Êû∂ÊßãÂ•óÁî®ÊñºÂõõÂÄãÈ†òÂüü‰∏≠ÁöÑÂêÑÁ®ÆÊé®ÁêÜ‰ªªÂãôÔºå‰∏¶‰ΩøÁî® 15 ÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLM„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåÂπæ‰πéÊâÄÊúâ LLM Âú®Ë§áÈõúÊÄßÂ¢ûÂä†ÁöÑÊÉÖÊ≥Å‰∏ãÈÉΩÊúÉÂá∫ÁèæÊïàËÉΩ‰∏ãÈôçÔºåËÄåÊüê‰∫õ LLM ÂâáË°®ÁèæÂá∫È°ØËëóÁöÑ‰∏ãÈôç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæ LLM Âú®ÈÄèÈÅé DARG Áî¢ÁîüÂÖ∑ÊúâËºÉÈ´òË§áÈõúÊÄßÂ±§Á¥öÁöÑË≥áÊñôÈÄ≤Ë°åË©ï‰º∞ÊôÇÔºåÊúÉË°®ÁèæÂá∫Êõ¥Â§öÂÅèÂ∑Æ„ÄÇÈÄô‰∫õËßÄÂØüÁµêÊûúÊèê‰æõ‰∫ÜÊúâÁî®ÁöÑË¶ãËß£ÔºåË™™ÊòéÂ¶Ç‰ΩïÂãïÊÖã‰∏îËá™ÈÅ©ÊáâÂú∞Ë©ï‰º∞ LLM„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/SALT-NLP/DARG ÂèñÂæó„ÄÇ

##### **AG-LSEC: Audio Grounded Lexical Speaker Error Correction**
2406.17266v1 by Rohit Paturi, Xiang Li, Sundararajan Srinivasan

Speaker Diarization (SD) systems are typically audio-based and operate
independently of the ASR system in traditional speech transcription pipelines
and can have speaker errors due to SD and/or ASR reconciliation, especially
around speaker turns and regions of speech overlap. To reduce these errors, a
Lexical Speaker Error Correction (LSEC), in which an external language model
provides lexical information to correct the speaker errors, was recently
proposed. Though the approach achieves good Word Diarization error rate (WDER)
improvements, it does not use any additional acoustic information and is prone
to miscorrections. In this paper, we propose to enhance and acoustically ground
the LSEC system with speaker scores directly derived from the existing SD
pipeline. This approach achieves significant relative WDER reductions in the
range of 25-40% over the audio-based SD, ASR system and beats the LSEC system
by 15-25% relative on RT03-CTS, Callhome American English and Fisher datasets.

ÊëòË¶ÅÔºöË™™Ë©±ËÄÖÊó•Ë®òÂåñ (SD) Á≥ªÁµ±ÈÄöÂ∏∏ÊòØÂü∫ÊñºÈü≥Ë®äÔºå‰∏¶Áç®Á´ãÊñºÂÇ≥Áµ±Ë™ûÈü≥ËΩâÈåÑÁÆ°Á∑ö‰∏≠ÁöÑ ASR Á≥ªÁµ±ÈÅã‰ΩúÔºå‰∏îÂèØËÉΩÂõ† SD Âíå/Êàñ ASR Ë™øÊï¥ËÄåÁî¢ÁîüË™™Ë©±ËÄÖÈåØË™§ÔºåÁâπÂà•ÊòØÂú®Ë™™Ë©±ËÄÖËº™ÊµÅÁôºË®ÄÂíåË™ûÈü≥ÈáçÁñäÂçÄÂüüÈôÑËøë„ÄÇÁÇ∫‰∫ÜÊ∏õÂ∞ëÈÄô‰∫õÈåØË™§ÔºåÊúÄËøëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË©ûÂΩôË™™Ë©±ËÄÖÈåØË™§‰øÆÊ≠£ (LSEC)ÔºåÂÖ∂‰∏≠Â§ñÈÉ®Ë™ûË®ÄÊ®°ÂûãÊèê‰æõË©ûÂΩôË≥áË®ä‰æÜ‰øÆÊ≠£Ë™™Ë©±ËÄÖÈåØË™§„ÄÇÂÑòÁÆ°Ê≠§ÊñπÊ≥ïÂèØÊúâÊïàÊîπÂñÑË©ûÂΩôÊó•Ë®òÂåñÈåØË™§Áéá (WDER)Ôºå‰ΩÜÂÆÉ‰∏¶Êú™‰ΩøÁî®‰ªª‰ΩïÈ°çÂ§ñÁöÑÈü≥Ë®äË≥áË®äÔºå‰∏îÂÆπÊòìÁôºÁîüÈåØË™§‰øÆÊ≠£„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêË≠∞‰ΩøÁî®Áõ¥Êé•ÂæûÁèæÊúâ SD ÁÆ°Á∑öË°çÁîüÁöÑË™™Ë©±ËÄÖÂàÜÊï∏‰æÜÂ¢ûÂº∑ÂíåÂª∫Á´ã LSEC Á≥ªÁµ±ÁöÑÈü≥Ë®äÂü∫Á§é„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂú®Èü≥Ë®äÂü∫Á§é SD„ÄÅASR Á≥ªÁµ±‰∏äÂØ¶Áèæ‰∫Ü 25-40% ÁöÑÈ°ØËëóÁõ∏Â∞ç WDER Èôç‰ΩéÔºå‰∏¶Âú® RT03-CTS„ÄÅCallhome ÁæéÂºèËã±Ë™ûÂíå Fisher Ë≥áÊñôÈõÜ‰∏äÊØî LSEC Á≥ªÁµ±È´òÂá∫ 15-25%„ÄÇ

##### **D2LLM: Decomposed and Distilled Large Language Models for Semantic Search**
2406.17262v1 by Zihan Liao, Hang Yu, Jianguo Li, Jun Wang, Wei Zhang

The key challenge in semantic search is to create models that are both
accurate and efficient in pinpointing relevant sentences for queries. While
BERT-style bi-encoders excel in efficiency with pre-computed embeddings, they
often miss subtle nuances in search tasks. Conversely, GPT-style LLMs with
cross-encoder designs capture these nuances but are computationally intensive,
hindering real-time applications. In this paper, we present D2LLMs-Decomposed
and Distilled LLMs for semantic search-that combines the best of both worlds.
We decompose a cross-encoder into an efficient bi-encoder integrated with
Pooling by Multihead Attention and an Interaction Emulation Module, achieving
nuanced understanding and pre-computability. Knowledge from the LLM is
distilled into this model using contrastive, rank, and feature imitation
techniques. Our experiments show that D2LLM surpasses five leading baselines in
terms of all metrics across three tasks, particularly improving NLI task
performance by at least 6.45%. The source code is available at
https://github.com/codefuse-ai/D2LLM.

ÊëòË¶ÅÔºöË™ûÊÑèÊêúÂ∞ãÁöÑ‰∏ªË¶ÅÊåëÊà∞Âú®ÊñºÂª∫Á´ãÁ≤æÊ∫ñ‰∏îÊúâÊïàÁéáÁöÑÊ®°ÂûãÔºå‰ª•ÊâæÂá∫ËàáÊü•Ë©¢Áõ∏ÈóúÁöÑÂè•Â≠ê„ÄÇÈõñÁÑ∂ BERT ÂºèÈõôÁ∑®Á¢ºÂô®Âú®È†êÂÖàË®àÁÆóÁöÑÂµåÂÖ•‰∏≠Ë°®ÁèæÂá∫ÊïàÁéáÔºå‰ΩÜÂÆÉÂÄëÂú®ÊêúÂ∞ã‰ªªÂãô‰∏≠Â∏∏Â∏∏ÊúÉÈÅ∫ÊºèÁ¥∞ÂæÆÁöÑÂ∑ÆÁï∞„ÄÇÁõ∏ÂèçÂú∞ÔºåÂÖ∑Êúâ‰∫§ÂèâÁ∑®Á¢ºÂô®Ë®≠Ë®àÁöÑ GPT Âºè LLM ÂèØ‰ª•ÊçïÊçâÂà∞ÈÄô‰∫õÂ∑ÆÁï∞Ôºå‰ΩÜË®àÁÆóÈáèÂæàÂ§ßÔºåÊúÉÈòªÁ§ôÂØ¶ÊôÇÊáâÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ D2LLMÔºåÂç≥ÂàÜËß£ÂíåËêÉÂèñÁöÑ LLMÔºåÁî®ÊñºË™ûÊÑèÊêúÂ∞ãÔºåÁµêÂêàÂÖ©ÂÖ®ÂÖ∂ÁæéÁöÑÂÑ™Èªû„ÄÇÊàëÂÄëÂ∞á‰∫§ÂèâÁ∑®Á¢ºÂô®ÂàÜËß£Êàê‰∏ÄÂÄãÊúâÊïàÁéáÁöÑÈõôÁ∑®Á¢ºÂô®ÔºåÊï¥ÂêàÂ§öÈ†≠Ê≥®ÊÑèÂäõÊ±†ÂåñÂíå‰∫íÂãïÊ®°Êì¨Ê®°ÁµÑÔºåÂØ¶ÁèæÁ¥∞ÂæÆÁöÑÁêÜËß£ÂíåÈ†êÂÖàË®àÁÆó„ÄÇÊàëÂÄë‰ΩøÁî®Â∞çÊØî„ÄÅÊéíÂ∫èÂíåÁâπÂæµÊ®°Êì¨ÊäÄË°ìÔºåÂ∞á LLM ÁöÑÁü•Ë≠òËêÉÂèñÂà∞ÈÄôÂÄãÊ®°Âûã‰∏≠„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåD2LLM Âú®‰∏âÂÄã‰ªªÂãôÁöÑÊâÄÊúâÊåáÊ®ô‰∏≠ÈÉΩË∂ÖË∂ä‰∫Ü‰∫îÂÄã‰∏ªË¶ÅÁöÑÂü∫Ê∫ñÔºåÁâπÂà•ÊòØÂ∞á NLI ‰ªªÂãôÁöÑÊïàËÉΩÊèêÂçá‰∫ÜËá≥Â∞ë 6.45%„ÄÇÂéüÂßãÁ¢ºÂèØÂú® https://github.com/codefuse-ai/D2LLM ÂèñÂæó„ÄÇ

##### **TRAWL: Tensor Reduced and Approximated Weights for Large Language Models**
2406.17261v1 by Yiran Luo, Het Patel, Yu Fu, Dawon Ahn, Jia Chen, Yue Dong, Evangelos E. Papalexakis

Large language models (LLMs) have fundamentally transformed artificial
intelligence, catalyzing recent advancements while imposing substantial
environmental and computational burdens. We introduce TRAWL (Tensor Reduced and
Approximated Weights for Large Language Models), a novel methodology for
optimizing LLMs through tensor decomposition. TRAWL leverages diverse
strategies to exploit matrices within transformer-based architectures,
realizing notable performance enhancements without necessitating retraining.
The most significant improvements were observed through a layer-by-layer
intervention strategy, particularly when applied to fully connected weights of
the final layers, yielding up to 16% enhancement in accuracy without the need
for additional data or fine-tuning. These results underscore the importance of
targeted and adaptive techniques in increasing the efficiency and effectiveness
of large language model optimization, thereby promoting the development of more
sustainable and accessible AI systems.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûÊ†πÊú¨‰∏äÊîπËÆä‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÔºåÂÇ¨Âåñ‰∫ÜËøëÊúüÁöÑÈÄ≤Â±ïÔºåÂêåÊôÇ‰πüÂ∏∂‰æÜÂ∑®Â§ßÁöÑÁí∞Â¢ÉÂíåÈÅãÁÆóË≤†Êìî„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü TRAWLÔºàÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂºµÈáèÁ∞°ÂåñÂíåËøë‰ººÊ¨äÈáçÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈÄèÈÅéÂºµÈáèÂàÜËß£‰æÜÊúÄ‰Ω≥Âåñ LLM ÁöÑÊñ∞ÊñπÊ≥ï„ÄÇTRAWL Êé°Áî®‰∏çÂêåÁöÑÁ≠ñÁï•‰æÜÂà©Áî®Âü∫ÊñºTransformerÁöÑÊû∂Êßã‰∏≠ÁöÑÁü©Èô£ÔºåÂØ¶ÁèæÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºåËÄåÁÑ°ÈúÄÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÊúÄÈ°ØËëóÁöÑÊîπÈÄ≤ÊòØÈÄèÈÅéÈÄêÂ±§‰ªãÂÖ•Á≠ñÁï•ËßÄÂØüÂà∞ÁöÑÔºåÁâπÂà•ÊòØÊáâÁî®ÊñºÊúÄÂæå‰∏ÄÂ±§ÁöÑÂÖ®ÈÄ£Êé•Ê¨äÈáçÊôÇÔºåÂú®ÁÑ°ÈúÄÈ°çÂ§ñË≥áÊñôÊàñÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 16%„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜÊúâÈáùÂ∞çÊÄßÂíåËá™ÈÅ©ÊáâÊäÄË°ìÂú®ÊèêÈ´òÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊúÄ‰Ω≥ÂåñÁöÑÊïàÁéáÂíåÊïàËÉΩÊñπÈù¢ÁöÑÈáçË¶ÅÊÄßÔºåÂæûËÄå‰øÉÈÄ≤Êõ¥Ê∞∏Á∫å‰∏îÂèØÂ≠òÂèñÁöÑ‰∫∫Â∑•Êô∫ÊÖßÁ≥ªÁµ±ÁöÑÁôºÂ±ï„ÄÇ

##### **Mitigating Hallucination in Fictional Character Role-Play**
2406.17260v1 by Nafis Sadeq, Zhouhang Xie, Byungkyu Kang, Prarit Lamba, Xiang Gao, Julian McAuley

Role-playing has wide-ranging applications in customer support, embodied
agents, computational social science, etc. The influence of parametric world
knowledge of large language models (LLMs) often causes role-playing characters
to act out of character and hallucinate about things outside the scope of their
knowledge. In this work, we focus on the evaluation and mitigation of
hallucination in fictional character role-play. We introduce a dataset with
more than 2,000 characters and 72,000 interviews, including 18,000 adversarial
questions. We propose RoleFact, a role-playing method that mitigates
hallucination by modulating the influence of parametric knowledge using a
pre-calibrated confidence threshold. Experiments show that the proposed method
improves the factual precision of generated responses by 18% for adversarial
questions with a 44% reduction in temporal hallucination for time-sensitive
interviews. The code and the dataset will be available at
https://github.com/NafisSadeq/rolefact.git.

ÊëòË¶ÅÔºöËßíËâ≤ÊâÆÊºîÂú®ÂÆ¢Êúç„ÄÅÂÖ∑Ë±°‰ª£ÁêÜ„ÄÅËÆ°ÁÆóÁ§æ‰ºöÁßëÂ≠¶Á≠âÊñπÈù¢ÊúâÁùÄÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂèÇÊï∞Âåñ‰∏ñÁïåÁü•ËØÜÁöÑÂΩ±ÂìçÂ∏∏Â∏∏‰ºöÂØºËá¥ËßíËâ≤ÊâÆÊºîËßíËâ≤ÁöÑË°å‰∏∫ËÑ±Á¶ªËßíËâ≤ÔºåÂπ∂‰∏îÂØπË∂ÖÂá∫ÂÖ∂Áü•ËØÜËåÉÂõ¥ÁöÑ‰∫ãÁâ©‰∫ßÁîüÂπªËßâ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨‰∏ìÊ≥®‰∫éËØÑ‰º∞ÂíåÂáèËΩªËôöÊûÑËßíËâ≤ËßíËâ≤ÊâÆÊºî‰∏≠ÁöÑÂπªËßâ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Êï∞ÊçÆÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 2,000 Â§ö‰∏™ËßíËâ≤Âíå 72,000 Ê¨°ÈááËÆøÔºåÂåÖÊã¨ 18,000 ‰∏™ÂØπÊäóÊÄßÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü RoleFactÔºåËøôÊòØ‰∏ÄÁßçÈÄöËøá‰ΩøÁî®È¢ÑÂÖàÊ†°ÂáÜÁöÑÁΩÆ‰ø°Â∫¶ÈòàÂÄºÊù•Ë∞ÉËäÇÂèÇÊï∞ÂåñÁü•ËØÜÁöÑÂΩ±ÂìçÊù•ÂáèËΩªÂπªËßâÁöÑËßíËâ≤ÊâÆÊºîÊñπÊ≥ï„ÄÇÂÆûÈ™åË°®ÊòéÔºåÂØπ‰∫éÂØπÊäóÊÄßÈóÆÈ¢òÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞ÜÁîüÊàêÂìçÂ∫îÁöÑ‰∫ãÂÆûÂáÜÁ°ÆÊÄßÊèêÈ´ò‰∫Ü 18%ÔºåËÄåÂØπ‰∫éÊó∂Èó¥ÊïèÊÑüÁöÑÈááËÆøÔºåÊó∂Èó¥ÂπªËßâÂáèÂ∞ë‰∫Ü 44%„ÄÇ‰ª£Á†ÅÂíåÊï∞ÊçÆÈõÜÂ∞ÜÂú® https://github.com/NafisSadeq/rolefact.git ‰∏äÊèê‰æõ„ÄÇ

##### **Leveraging Parameter-Efficient Transfer Learning for Multi-Lingual Text-to-Speech Adaptation**
2406.17257v1 by Yingting Li, Ambuj Mehrish, Bryan Chew, Bo Cheng, Soujanya Poria

Different languages have distinct phonetic systems and vary in their prosodic
features making it challenging to develop a Text-to-Speech (TTS) model that can
effectively synthesise speech in multilingual settings. Furthermore, TTS
architecture needs to be both efficient enough to capture nuances in multiple
languages and efficient enough to be practical for deployment. The standard
approach is to build transformer based model such as SpeechT5 and train it on
large multilingual dataset. As the size of these models grow the conventional
fine-tuning for adapting these model becomes impractical due to heavy
computational cost. In this paper, we proposes to integrate parameter-efficient
transfer learning (PETL) methods such as adapters and hypernetwork with TTS
architecture for multilingual speech synthesis. Notably, in our experiments
PETL methods able to achieve comparable or even better performance compared to
full fine-tuning with only $\sim$2.5\% tunable parameters.The code and samples
are available at: https://anonymous.4open.science/r/multilingualTTS-BA4C.

ÊëòË¶ÅÔºö‰∏çÂêåÁöÑË™ûË®ÄÂÖ∑Êúâ‰∏çÂêåÁöÑÈü≥Á≥ªÁ≥ªÁµ±Ôºå‰∏îÂú®ÈüªÂæãÁâπÂæµ‰∏äÊúâÊâÄ‰∏çÂêåÔºåÈÄô‰ΩøÂæóÈñãÁôºÂá∫ËÉΩÂú®Â§öË™ûË®ÄÁí∞Â¢É‰∏≠ÊúâÊïàÂêàÊàêË™ûÈü≥ÁöÑÊñáÂ≠óËΩâË™ûÈü≥ (TTS) Ê®°ÂûãËÆäÂæóÊ•µÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåTTS Êû∂ÊßãÂøÖÈ†àÊó¢ËÉΩÊúâÊïàÊçïÊçâÂ§öÁ®ÆË™ûË®ÄÁöÑÁ¥∞ÂæÆÂ∑ÆÂà•ÔºåÂèàË∂≥Â§†ÊúâÊïàÁéá‰ª•Âà©ÊñºÂØ¶ÈöõÈÉ®ÁΩ≤„ÄÇÊ®ôÊ∫ñÂÅöÊ≥ïÊòØÂª∫Á´ãÂü∫ÊñºËΩâÊèõÂô®ÁöÑÊ®°ÂûãÔºà‰æãÂ¶Ç SpeechT5ÔºâÔºå‰∏¶Âú®Â§ßÂûãÂ§öË™ûË®ÄË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÂÆÉ„ÄÇÈö®ËëóÈÄô‰∫õÊ®°ÂûãÁöÑË¶èÊ®°Ë∂ä‰æÜË∂äÂ§ßÔºåÂÇ≥Áµ±ÁöÑÂæÆË™ø‰ª•Ë™øÊï¥ÈÄô‰∫õÊ®°ÂûãËÆäÂæó‰∏çÂàáÂØ¶ÈöõÔºåÂõ†ÁÇ∫Ë®àÁÆóÊàêÊú¨ÈÅéÊñºÈæêÂ§ß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÂèÉÊï∏ÊúâÊïàÁéáÁöÑÈÅ∑ÁßªÂ≠∏Áøí (PETL) ÊñπÊ≥ïÔºà‰æãÂ¶ÇÈÅ©ÈÖçÂô®ÂíåË∂ÖÁ∂≤Ë∑ØÔºâËàá TTS Êû∂ÊßãÊï¥ÂêàÔºå‰ª•ÈÄ≤Ë°åÂ§öË™ûË®ÄË™ûÈü≥ÂêàÊàê„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåPETL ÊñπÊ≥ïËÉΩÂ§†ÈÅîÂà∞ËàáÂÆåÊï¥ÂæÆË™øÁõ∏Áï∂ÁîöËá≥Êõ¥Â•ΩÁöÑÊïàËÉΩÔºåËÄåÂèØË™øÊï¥ÁöÑÂèÉÊï∏ÂÉÖÁ¥ÑÁÇ∫ 2.5%„ÄÇÁ®ãÂºèÁ¢ºÂíåÁØÑ‰æãÂèØÊñº‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÔºöhttps://anonymous.4open.science/r/multilingualTTS-BA4C„ÄÇ

##### **MPCODER: Multi-user Personalized Code Generator with Explicit and Implicit Style Representation Learning**
2406.17255v1 by Zhenlong Dai, Chang Yao, WenKang Han, Ying Yuan, Zhipeng Gao, Jingyuan Chen

Large Language Models (LLMs) have demonstrated great potential for assisting
developers in their daily development. However, most research focuses on
generating correct code, how to use LLMs to generate personalized code has
seldom been investigated. To bridge this gap, we proposed MPCoder (Multi-user
Personalized Code Generator) to generate personalized code for multiple users.
To better learn coding style features, we utilize explicit coding style
residual learning to capture the syntax code style standards and implicit style
learning to capture the semantic code style conventions. We train a multi-user
style adapter to better differentiate the implicit feature representations of
different users through contrastive learning, ultimately enabling personalized
code generation for multiple users. We further propose a novel evaluation
metric for estimating similarities between codes of different coding styles.
The experimental results show the effectiveness of our approach for this novel
task.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫Âú®ÂçîÂä©ÈñãÁôº‰∫∫Âì°Êó•Â∏∏ÈñãÁôºÊñπÈù¢ÂÖ∑ÊúâÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏Á†îÁ©∂ÈÉΩÂ∞àÊ≥®ÊñºÁî¢ÁîüÊ≠£Á¢∫ÁöÑÁ®ãÂºèÁ¢ºÔºåËÄåÈÆÆÂ∞ëÊé¢Ë®éÂ¶Ç‰Ωï‰ΩøÁî® LLM ‰æÜÁî¢ÁîüÂÄã‰∫∫ÂåñÁöÑÁ®ãÂºèÁ¢º„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÈ†ÖÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MPCoderÔºàÂ§ö‰ΩøÁî®ËÄÖÂÄã‰∫∫ÂåñÁ®ãÂºèÁ¢ºÁî¢ÁîüÂô®Ôºâ‰æÜÁÇ∫Â§ö‰Ωç‰ΩøÁî®ËÄÖÁî¢ÁîüÂÄã‰∫∫ÂåñÁöÑÁ®ãÂºèÁ¢º„ÄÇÁÇ∫‰∫ÜÊõ¥Ê∑±ÂÖ•Âú∞Â≠∏ÁøíÁ®ãÂºèÁ¢ºÈ¢®Ê†ºÁâπÂæµÔºåÊàëÂÄëÂà©Áî®ÊòéÁ¢∫ÁöÑÁ®ãÂºèÁ¢ºÈ¢®Ê†ºÊÆòÂ∑ÆÂ≠∏Áøí‰æÜÊì∑ÂèñË™ûÊ≥ïÁ®ãÂºèÁ¢ºÈ¢®Ê†ºÊ®ôÊ∫ñÔºå‰∏¶Âà©Áî®Èö±Âê´È¢®Ê†ºÂ≠∏Áøí‰æÜÊì∑ÂèñË™ûÁæ©Á®ãÂºèÁ¢ºÈ¢®Ê†ºÊÖ£‰æã„ÄÇÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÂ§ö‰ΩøÁî®ËÄÖÈ¢®Ê†ºÈÅ©ÈÖçÂô®Ôºå‰ª•ÈÄèÈÅéÂ∞çÊØîÂ≠∏Áøí‰æÜÊõ¥Â•ΩÂú∞ÂçÄÂàÜ‰∏çÂêå‰ΩøÁî®ËÄÖÁöÑÈö±Âê´ÁâπÂæµË°®Á§∫ÔºåÊúÄÁµÇÂØ¶ÁèæÈáùÂ∞çÂ§ö‰Ωç‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫ÂåñÁ®ãÂºèÁ¢ºÁî¢Áîü„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑË©ï‰º∞ÊåáÊ®ôÔºåÁî®Êñº‰º∞Ë®à‰∏çÂêåÁ®ãÂºèÁ¢ºÈ¢®Ê†ºÁöÑÁ®ãÂºèÁ¢º‰πãÈñìÁöÑÁõ∏‰ººÊÄß„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞çÊñºÈÄôÈ†ÖÊñ∞Á©é‰ªªÂãôÁöÑÊúâÊïàÊÄß„ÄÇ

##### **How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?**
2406.17253v1 by Huaizhi Ge, Frank Rudzicz, Zining Zhu

As large language models (LLMs) are widely deployed, targeted editing of
their knowledge has become a critical challenge. Recently, advancements in
model editing techniques, such as Rank-One Model Editing (ROME), have paved the
way for updating LLMs with new knowledge. However, the efficacy of these
methods varies across different types of knowledge. This study investigates the
capability of knowledge editing methods to incorporate new knowledge with
varying degrees of "perplexingness", a term we use to describe the initial
difficulty LLMs have in understanding new concepts. We begin by quantifying the
"perplexingness" of target knowledge using pre-edit conditional probabilities,
and assess the efficacy of edits through post-edit conditional probabilities.
Utilizing the widely-used CounterFact dataset, we find significant negative
correlations between the "perplexingness" of the new knowledge and the edit
efficacy across all 12 scenarios. To dive deeper into this phenomenon, we
introduce a novel dataset, HierarchyData, consisting of 99 hyponym-hypernym
pairs across diverse categories. Our analysis reveal that more abstract
concepts (hypernyms) tend to be more perplexing than their specific
counterparts (hyponyms). Further exploration into the influence of knowledge
hierarchy on editing outcomes indicates that knowledge positioned at higher
hierarchical levels is more challenging to modify in some scenarios. Our
research highlights a previously overlooked aspect of LLM editing: the variable
efficacy of editing methods in handling perplexing knowledge. By revealing how
hierarchical relationships can influence editing outcomes, our findings offer
new insights into the challenges of updating LLMs and pave the way for more
nuanced approaches to model editing in the future.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âª£Ê≥õÈÉ®ÁΩ≤ÔºåÊúâÈáùÂ∞çÊÄßÂú∞Á∑®ËºØÂÖ∂Áü•Ë≠òÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞„ÄÇÊúÄËøëÔºåÊ®°ÂûãÁ∑®ËºØÊäÄË°ìÁöÑÈÄ≤Â±ïÔºå‰æãÂ¶ÇÁß©‰∏ÄÊ®°ÂûãÁ∑®ËºØ (ROME)ÔºåÁÇ∫‰ΩøÁî®Êñ∞Áü•Ë≠òÊõ¥Êñ∞ LLM Èã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑÂäüÊïàÂõ†‰∏çÂêåÈ°ûÂûãÁöÑÁü•Ë≠òËÄåÁï∞„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÁü•Ë≠òÁ∑®ËºØÊñπÊ≥ïÂ∞áÂÖ∑Êúâ‰∏çÂêåÁ®ãÂ∫¶„ÄåÂõ∞ÊÉëÊÄß„ÄçÁöÑÊñ∞Áü•Ë≠òÁ¥çÂÖ•ÂÖ∂‰∏≠ÁöÑËÉΩÂäõÔºåÊàëÂÄë‰ΩøÁî®ÈÄôÂÄãË°ìË™û‰æÜÊèèËø∞ LLM Âú®ÁêÜËß£Êñ∞Ê¶ÇÂøµÊôÇÁöÑÂàùÂßãÂõ∞Èõ£„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®È†êÁ∑®ËºØÊ¢ù‰ª∂Ê©üÁéáÂ∞çÁõÆÊ®ôÁü•Ë≠òÁöÑ„ÄåÂõ∞ÊÉëÊÄß„ÄçÈÄ≤Ë°åÈáèÂåñÔºå‰∏¶ÈÄèÈÅéÂæåÁ∑®ËºØÊ¢ù‰ª∂Ê©üÁéáË©ï‰º∞Á∑®ËºØÁöÑÂäüÊïà„ÄÇÂà©Áî®Âª£Ê≥õ‰ΩøÁî®ÁöÑ CounterFact Ë≥áÊñôÈõÜÔºåÊàëÂÄëÁôºÁèæÊñ∞Áü•Ë≠òÁöÑ„ÄåÂõ∞ÊÉëÊÄß„ÄçËàáÊâÄÊúâ 12 Á®ÆÊÉÖÊ≥Å‰∏ãÁöÑÁ∑®ËºØÂäüÊïà‰πãÈñìÂ≠òÂú®È°ØËëóÁöÑË≤†Áõ∏Èóú„ÄÇÁÇ∫‰∫ÜÊõ¥Ê∑±ÂÖ•Êé¢Ë®éÈÄôÂÄãÁèæË±°ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊñ∞ÁöÑË≥áÊñôÈõÜ HierarchyDataÔºåÂÖ∂‰∏≠ÂåÖÂê´ 99 ÂÄãË∑®È°ûÂà•ÁöÑ‰ΩéÈöéË©û-È´òÈöéË©ûÂ∞ç„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÊõ¥ÊäΩË±°ÁöÑÊ¶ÇÂøµÔºàÈ´òÈöéË©ûÔºâÂæÄÂæÄÊØîÂÆÉÂÄëÂÖ∑È´îÁöÑÂ∞çÊáâÊ¶ÇÂøµÔºà‰ΩéÈöéË©ûÔºâÊõ¥‰ª§‰∫∫Âõ∞ÊÉë„ÄÇÈÄ≤‰∏ÄÊ≠•Êé¢Ë®éÁü•Ë≠òÂ±§Á¥öÂ∞çÁ∑®ËºØÁµêÊûúÁöÑÂΩ±ÈüøË°®ÊòéÔºåÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÔºå‰ΩçÊñºËºÉÈ´òÂ±§Á¥öÁöÑÁü•Ë≠òÊõ¥Èõ£‰ª•‰øÆÊîπ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™ø‰∫Ü LLM Á∑®ËºØ‰∏≠ÂÖàÂâçË¢´ÂøΩÁï•ÁöÑ‰∏ÄÂÄãÈù¢ÂêëÔºöÁ∑®ËºØÊñπÊ≥ïÂú®ËôïÁêÜ‰ª§‰∫∫Âõ∞ÊÉëÁöÑÁü•Ë≠òÊôÇÂäüÊïàÁöÑÂèØËÆäÊÄß„ÄÇÈÄèÈÅéÊè≠Á§∫Â±§Á¥öÈóú‰øÇÂ¶Ç‰ΩïÂΩ±ÈüøÁ∑®ËºØÁµêÊûúÔºåÊàëÂÄëÁöÑÁôºÁèæÁÇ∫Êõ¥Êñ∞ LLM ÁöÑÊåëÊà∞Êèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£Ôºå‰∏¶ÁÇ∫Êú™‰æÜÊõ¥Á¥∞Á∑ªÁöÑÊ®°ÂûãÁ∑®ËºØÊñπÊ≥ïÈã™Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ</paragraph>

##### **TopoGCL: Topological Graph Contrastive Learning**
2406.17251v1 by Yuzhou Chen, Jose Frias, Yulia R. Gel

Graph contrastive learning (GCL) has recently emerged as a new concept which
allows for capitalizing on the strengths of graph neural networks (GNNs) to
learn rich representations in a wide variety of applications which involve
abundant unlabeled information. However, existing GCL approaches largely tend
to overlook the important latent information on higher-order graph
substructures. We address this limitation by introducing the concepts of
topological invariance and extended persistence on graphs to GCL. In
particular, we propose a new contrastive mode which targets topological
representations of the two augmented views from the same graph, yielded by
extracting latent shape properties of the graph at multiple resolutions. Along
with the extended topological layer, we introduce a new extended persistence
summary, namely, extended persistence landscapes (EPL) and derive its
theoretical stability guarantees. Our extensive numerical results on
biological, chemical, and social interaction graphs show that the new
Topological Graph Contrastive Learning (TopoGCL) model delivers significant
performance gains in unsupervised graph classification for 11 out of 12
considered datasets and also exhibits robustness under noisy scenarios.

ÊëòË¶ÅÔºöÂúñÂΩ¢Â∞çÊØîÂ≠∏Áøí (GCL) ËøëÊúüÊµÆÁèæÁÇ∫‰∏ÄÁ®ÆÊñ∞Ê¶ÇÂøµÔºåÂÆÉÂà©Áî®ÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÁöÑÂÑ™Âã¢ÔºåÂú®ÂêÑÁ®ÆÊáâÁî®‰∏≠Â≠∏ÁøíË±êÂØåÁöÑË°®ÂæµÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§ßÈáèÊú™Ê®ôË®òË≥áË®ä„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ GCL ÊñπÊ≥ïÂ§ßÂ§öÂÇæÂêëÊñºÂøΩÁï•È´òÈöéÂúñÂΩ¢Â≠êÁµêÊßã‰∏≠ÈáçË¶ÅÁöÑÊΩõÂú®Ë≥áË®ä„ÄÇÊàëÂÄëÈÄèÈÅéÂú® GCL ‰∏≠ÂºïÂÖ•ÊãìÊí≤‰∏çËÆäÊÄßÂíåÂúñÂΩ¢‰∏äÁöÑÊì¥ÂÖÖÊåÅ‰πÖÊÄßÊ¶ÇÂøµ‰æÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂ∞çÊØîÊ®°ÂºèÔºåÂÆÉÈáùÂ∞ç‰æÜËá™Âêå‰∏ÄÂÄãÂúñÂΩ¢ÁöÑÂÖ©ÂÄãÊì¥ÂÖÖÊ™¢Ë¶ñÁöÑÊãìÊí≤Ë°®ÂæµÔºåËóâÁî±ÊèêÂèñÂúñÂΩ¢Âú®Â§öÂÄãËß£ÊûêÂ∫¶‰∏ãÁöÑÊΩõÂú®ÂΩ¢ÁãÄÂ±¨ÊÄß‰æÜÁî¢Áîü„ÄÇÈö®ËëóÊì¥ÂÖÖÊãìÊí≤Â±§ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÊñ∞ÁöÑÊì¥ÂÖÖÊåÅ‰πÖÊÄßÊëòË¶ÅÔºåÂç≥Êì¥ÂÖÖÊåÅ‰πÖÊÄßÊôØËßÄ (EPL)Ôºå‰∏¶Êé®Â∞éÂá∫ÂÖ∂ÁêÜË´ñÁ©©ÂÆöÊÄß‰øùË≠â„ÄÇÊàëÂÄëÂú®ÁîüÁâ©„ÄÅÂåñÂ≠∏ÂíåÁ§æ‰∫§‰∫íÂãïÂúñÂΩ¢‰∏äÁöÑÂª£Ê≥õÊï∏ÂÄºÁµêÊûúÈ°ØÁ§∫ÔºåÊñ∞ÁöÑÊãìÊí≤ÂúñÂΩ¢Â∞çÊØîÂ≠∏Áøí (TopoGCL) Ê®°ÂûãÂú® 12 ÂÄãËÄÉÊÖÆ‰∏≠ÁöÑË≥áÊñôÈõÜ‰∏≠Êúâ 11 ÂÄãË≥áÊñôÈõÜÁöÑÁÑ°Áõ£Áù£ÂúñÂΩ¢ÂàÜÈ°û‰∏≠Êèê‰æõ‰∫ÜÈ°ØËëóÁöÑÊïàËÉΩÊèêÂçáÔºå‰∏¶‰∏îÂú®ÊúâÈõúË®äÁöÑÊÉÖÊ≥Å‰∏ã‰πüÂ±ïÁèæÂá∫Á©©ÂÅ•ÊÄß„ÄÇ

##### **Beyond Silence: Bias Analysis through Loss and Asymmetric Approach in Audio Anti-Spoofing**
2406.17246v1 by Hye-jin Shim, Md Sahidullah, Jee-weon Jung, Shinji Watanabe, Tomi Kinnunen

Current trends in audio anti-spoofing detection research strive to improve
models' ability to generalize across unseen attacks by learning to identify a
variety of spoofing artifacts. This emphasis has primarily focused on the spoof
class. Recently, several studies have noted that the distribution of silence
differs between the two classes, which can serve as a shortcut. In this paper,
we extend class-wise interpretations beyond silence. We employ loss analysis
and asymmetric methodologies to move away from traditional attack-focused and
result-oriented evaluations towards a deeper examination of model behaviors.
Our investigations highlight the significant differences in training dynamics
between the two classes, emphasizing the need for future research to focus on
robust modeling of the bonafide class.

ÊëòË¶ÅÔºöÁï∂ÂâçÈü≥Ë®äÈò≤ÂÅΩÂÅµÊ∏¨ÁöÑÁ†îÁ©∂Ë∂®Âã¢Ëá¥ÂäõÊñºÊèêÂçáÊ®°ÂûãÂ∞çÊú™Ë¶ãÊîªÊìäÁöÑÊ¶ÇÂåñËÉΩÂäõÔºåÊñπÊ≥ïÊòØÂ≠∏ÁøíË≠òÂà•ÂêÑÁ®ÆÂÅΩÈÄ†‰∫∫Â∑•Ë£ΩÂìÅ„ÄÇÈÄôÁ®ÆÈáçÈªû‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂÅΩÈÄ†È°ûÂà•‰∏ä„ÄÇÊúÄËøëÔºåÂ§öÈ†ÖÁ†îÁ©∂ÊåáÂá∫ÔºåÂÖ©Á®ÆÈ°ûÂà•‰πãÈñìÁöÑÈùúÈªòÂàÜ‰Ωà‰∏çÂêåÔºåÈÄôÂèØ‰ª•‰ΩúÁÇ∫Êç∑Âæë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞áÈ°ûÂà•Ëß£ÈáãÂª∂‰º∏Âà∞ÈùúÈªò‰πãÂ§ñ„ÄÇÊàëÂÄëÊé°Áî®ÊêçÂ§±ÂàÜÊûêÂíåÈùûÂ∞çÁ®±ÊñπÊ≥ïÔºåÂæûÂÇ≥Áµ±‰ª•ÊîªÊìäÁÇ∫ÈáçÈªûÂíå‰ª•ÁµêÊûúÁÇ∫Â∞éÂêëÁöÑË©ï‰º∞ËΩâÂêëÊõ¥Ê∑±ÂÖ•Âú∞Êé¢Ë®éÊ®°ÂûãË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑË™øÊü•Âº∑Ë™ø‰∫ÜÂÖ©ÂÄãÈ°ûÂà•‰πãÈñìË®ìÁ∑¥ÂãïÊÖãÁöÑÈ°ØËëóÂ∑ÆÁï∞ÔºåÂº∑Ë™øÊú™‰æÜÁ†îÁ©∂ÈúÄË¶ÅÂ∞àÊ≥®ÊñºÁúüÂØ¶È°ûÂà•ÁöÑÁ©©ÂÅ•Âª∫Ê®°„ÄÇ

##### **Unlocking Continual Learning Abilities in Language Models**
2406.17245v1 by Wenyu Du, Shuang Cheng, Tongxu Luo, Zihan Qiu, Zeyu Huang, Ka Chun Cheung, Reynold Cheng, Jie Fu

Language models (LMs) exhibit impressive performance and generalization
capabilities. However, LMs struggle with the persistent challenge of
catastrophic forgetting, which undermines their long-term sustainability in
continual learning (CL). Existing approaches usually address the issue by
incorporating old task data or task-wise inductive bias into LMs. However, old
data and accurate task information are often unavailable or costly to collect,
hindering the availability of current CL approaches for LMs. To address this
limitation, we introduce $\textbf{MIGU}$ ($\textbf{M}$agn$\textbf{I}$tude-based
$\textbf{G}$radient $\textbf{U}$pdating for continual learning), a
rehearsal-free and task-label-free method that only updates the model
parameters with large magnitudes of output in LMs' linear layers. MIGU is based
on our observation that the L1-normalized magnitude distribution of the output
in LMs' linear layers is different when the LM models deal with different task
data. By imposing this simple constraint on the gradient update process, we can
leverage the inherent behaviors of LMs, thereby unlocking their innate CL
abilities. Our experiments demonstrate that MIGU is universally applicable to
all three LM architectures (T5, RoBERTa, and Llama2), delivering
state-of-the-art or on-par performance across continual finetuning and
continual pre-training settings on four CL benchmarks. For example, MIGU brings
a 15.2% average accuracy improvement over conventional parameter-efficient
finetuning baselines in a 15-task CL benchmark. MIGU can also seamlessly
integrate with all three existing CL types to further enhance performance. Code
is available at \href{https://github.com/wenyudu/MIGU}{this https URL}.

ÊëòË¶ÅÔºö<paragraph>Ë™ûË®ÄÊ®°Âûã (LM) Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩÂíåÊ¶ÇÂåñËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåLM Èù¢Ëá®ÊåÅÁ∫åÁöÑÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÊåëÊà∞ÔºåÈÄôÊúÉÊêçÂÆ≥ÂÖ∂Âú®ÊåÅÁ∫åÂ≠∏Áøí (CL) ‰∏≠ÁöÑÈï∑ÊúüÊ∞∏Á∫åÊÄß„ÄÇÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏ÈÄèÈÅéÂ∞áËàä‰ªªÂãôË≥áÊñôÊàñ‰ªªÂãôÊòéÊô∫ÁöÑÊ≠∏Á¥çÂÅèÂ∑ÆÁ¥çÂÖ• LM ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåËàäË≥áÊñôÂíåÊ∫ñÁ¢∫ÁöÑ‰ªªÂãôË≥áË®äÈÄöÂ∏∏ÁÑ°Ê≥ïÂèñÂæóÊàñÊî∂ÈõÜÊàêÊú¨È´òÊòÇÔºåÈÄôÈòªÁ§ô‰∫ÜÁõÆÂâç LM ÁöÑ CL ÊñπÊ≥ïÁöÑÂèØÁî®ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü $\textbf{MIGU}$Ôºà$\textbf{M}$agn$\textbf{I}$tude-based $\textbf{G}$radient $\textbf{U}$pdating for continual learningÔºâÔºå‰∏ÄÁ®ÆÁÑ°ÈúÄË§áÁøíÂíå‰ªªÂãôÊ®ôÁ±§ÁöÑÊñπÊ≥ïÔºåÂÆÉÂè™Êõ¥Êñ∞ LM Á∑öÊÄßÂ±§‰∏≠Ëº∏Âá∫ÂπÖÂ∫¶Â§ßÁöÑÊ®°ÂûãÂèÉÊï∏„ÄÇMIGU Âü∫ÊñºÊàëÂÄëÁöÑËßÄÂØüÔºåÂç≥Áï∂ LM Ê®°ÂûãËôïÁêÜ‰∏çÂêåÁöÑ‰ªªÂãôË≥áÊñôÊôÇÔºåLM Á∑öÊÄßÂ±§‰∏≠Ëº∏Âá∫ÁöÑ L1 Ê®ôÊ∫ñÂåñÂπÖÂ∫¶ÂàÜ‰ΩàÊòØ‰∏çÂêåÁöÑ„ÄÇÈÄèÈÅéÂ∞çÊ¢ØÂ∫¶Êõ¥Êñ∞ÈÅéÁ®ãÊñΩÂä†ÈÄôÂÄãÁ∞°ÂñÆÁöÑÁ¥ÑÊùüÔºåÊàëÂÄëÂèØ‰ª•Âà©Áî® LM ÁöÑÂõ∫ÊúâË°åÁÇ∫ÔºåÂæûËÄåËß£ÈéñÂÖ∂Â§©ÁîüÁöÑ CL ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåMIGU ÊôÆÈÅçÈÅ©Áî®ÊñºÊâÄÊúâ‰∏âÁ®Æ LM Êû∂ÊßãÔºàT5„ÄÅRoBERTa Âíå Llama2ÔºâÔºåÂú®ÂõõÂÄã CL Âü∫Ê∫ñ‰∏äÊèê‰æõÊúÄÂÖàÈÄ≤ÊàñÂêåÁ≠âÁöÑÊïàËÉΩÔºåÂåÖÊã¨ÊåÅÁ∫åÂæÆË™øÂíåÊåÅÁ∫åÈ†êË®ìÁ∑¥Ë®≠ÂÆö„ÄÇ‰æãÂ¶ÇÔºåÂú® 15 ÂÄã‰ªªÂãôÁöÑ CL Âü∫Ê∫ñ‰∏≠ÔºåMIGU ÊØîÂÇ≥Áµ±ÁöÑÂèÉÊï∏ÊúâÊïàÂæÆË™øÂü∫Ê∫ñÊèêÈ´ò‰∫Ü 15.2% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶„ÄÇMIGU ‰πüÂèØ‰ª•ÁÑ°Á∏´Êï¥ÂêàÊâÄÊúâ‰∏âÁ®ÆÈ°ûÂûãÁöÑÁèæÊúâ CLÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® \href{https://github.com/wenyudu/MIGU}{ÈÄôÂÄã https URL} ÂèñÂæó„ÄÇ</paragraph>

##### **What Do the Circuits Mean? A Knowledge Edit View**
2406.17241v1 by Huaizhi Ge, Frank Rudzicz, Zining Zhu

In the field of language model interpretability, circuit discovery is gaining
popularity. Despite this, the true meaning of these circuits remain largely
unanswered. We introduce a novel method to learn their meanings as a holistic
object through the lens of knowledge editing. We extract circuits in the
GPT2-XL model using diverse text classification datasets, and use hierarchical
relations datasets to explore knowledge editing in the circuits. Our findings
indicate that these circuits contain entity knowledge but resist new knowledge
more than complementary circuits during knowledge editing. Additionally, we
examine the impact of circuit size, discovering that an ideal "theoretical
circuit" where essential knowledge is concentrated likely incorporates more
than 5% but less than 50% of the model's parameters. We also assess the overlap
between circuits from different datasets, finding moderate similarities. What
constitutes these circuits, then? We find that up to 60% of the circuits
consist of layer normalization modules rather than attention or MLP modules,
adding evidence to the ongoing debates regarding knowledge localization. In
summary, our findings offer new insights into the functions of the circuits,
and introduce research directions for further interpretability and safety
research of language models.

ÊëòË¶ÅÔºöÂú®Ë™ûË®ÄÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑÈ†òÂüü‰∏≠ÔºåÈõªË∑ØÁôºÁèæÊ≠£Áç≤Âæó
ÊôÆÂèä„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÈõªË∑ØÁöÑÁúüÊ≠£Âê´Áæ©Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÊú™ÂæóÂà∞Ëß£Á≠î„ÄÇÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÈÄöÈÅéÁü•Ë≠òÁ∑®ËºØÁöÑË¶ñËßíÂ∞áÂÆÉÂÄëÁöÑÂê´Áæ©‰ΩúÁÇ∫‰∏ÄÂÄãÊï¥È´îÂ∞çË±°ÈÄ≤Ë°åÂ≠∏Áøí„ÄÇÊàëÂÄë‰ΩøÁî®Â§öÊ®£ÂåñÁöÑÊñáÊú¨ÂàÜÈ°ûÊï∏ÊìöÈõÜÊèêÂèñ GPT2-XL Ê®°Âûã‰∏≠ÁöÑÈõªË∑ØÔºå‰∏¶‰ΩøÁî®ÂàÜÂ±§Èóú‰øÇÊï∏ÊìöÈõÜÊé¢Á¥¢ÈõªË∑Ø‰∏≠ÁöÑÁü•Ë≠òÁ∑®ËºØ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈÄô‰∫õÈõªË∑ØÂåÖÂê´ÂØ¶È´îÁü•Ë≠òÔºå‰ΩÜÂú®Áü•Ë≠òÁ∑®ËºØÈÅéÁ®ã‰∏≠ÊØî‰∫íË£úÈõªË∑ØÊõ¥ÊäóÊãíÊñ∞Áü•Ë≠ò„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊ™¢Êü•‰∫ÜÈõªË∑ØÂ§ßÂ∞èÁöÑÂΩ±ÈüøÔºåÁôºÁèæ‰∫Ü‰∏ÄÂÄãÁêÜÊÉ≥ÁöÑ„ÄåÁêÜË´ñÈõªË∑Ø„ÄçÔºåÂÖ∂‰∏≠ÈõÜ‰∏≠‰∫ÜÂøÖË¶ÅÁöÑÁü•Ë≠òÔºåÂèØËÉΩÂåÖÂê´Ë∂ÖÈÅé 5% ‰ΩÜÂ∞ëÊñºÊ®°ÂûãÂèÉÊï∏ÁöÑ 50%„ÄÇÊàëÂÄëÈÇÑË©ï‰º∞‰∫Ü‰æÜËá™‰∏çÂêåÊï∏ÊìöÈõÜÁöÑÈõªË∑Ø‰πãÈñìÁöÑÈáçÁñäÔºåÁôºÁèæÊúâ‰∏≠Á≠âÁõ∏‰ººÊÄß„ÄÇÈÇ£È∫ºÔºåÈÄô‰∫õÈõªË∑ØÁî±‰ªÄÈ∫ºÁµÑÊàêÂë¢ÔºüÊàëÂÄëÁôºÁèæÔºåÈ´òÈÅî 60% ÁöÑÈõªË∑ØÁî±Â±§Ê≠∏‰∏ÄÂåñÊ®°ÁµÑÁµÑÊàêÔºåËÄå‰∏çÊòØÊ≥®ÊÑèÂäõÊàñ MLP Ê®°ÁµÑÔºåÈÄôÁÇ∫ÈóúÊñºÁü•Ë≠òÊú¨Âú∞ÂåñÁöÑÊåÅÁ∫åÁà≠Ë´ñÊèê‰æõ‰∫ÜË≠âÊìö„ÄÇÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁÇ∫ÈõªË∑ØÁöÑÂäüËÉΩÊèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£Ôºå‰∏¶ÁÇ∫Ë™ûË®ÄÊ®°ÂûãÁöÑÈÄ≤‰∏ÄÊ≠•ÂèØËß£ÈáãÊÄßÂíåÂÆâÂÖ®ÊÄßÁ†îÁ©∂ÂºïÂÖ•‰∫ÜÁ†îÁ©∂ÊñπÂêë„ÄÇ

