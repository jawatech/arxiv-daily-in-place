{"2407.14321": {"publish_time": "2024-07-19", "title": "Multimodal Misinformation Detection using Large Vision-Language Models", "paper_summary": "The increasing proliferation of misinformation and its alarming impact have\nmotivated both industry and academia to develop approaches for misinformation\ndetection and fact checking. Recent advances on large language models (LLMs)\nhave shown remarkable performance in various tasks, but whether and how LLMs\ncould help with misinformation detection remains relatively underexplored. Most\nof existing state-of-the-art approaches either do not consider evidence and\nsolely focus on claim related features or assume the evidence to be provided.\nFew approaches consider evidence retrieval as part of the misinformation\ndetection but rely on fine-tuning models. In this paper, we investigate the\npotential of LLMs for misinformation detection in a zero-shot setting. We\nincorporate an evidence retrieval component into the process as it is crucial\nto gather pertinent information from various sources to detect the veracity of\nclaims. To this end, we propose a novel re-ranking approach for multimodal\nevidence retrieval using both LLMs and large vision-language models (LVLM). The\nretrieved evidence samples (images and texts) serve as the input for an\nLVLM-based approach for multimodal fact verification (LVLM4FV). To enable a\nfair evaluation, we address the issue of incomplete ground truth for evidence\nsamples in an existing evidence retrieval dataset by annotating a more complete\nset of evidence samples for both image and text retrieval. Our experimental\nresults on two datasets demonstrate the superiority of the proposed approach in\nboth evidence retrieval and fact verification tasks and also better\ngeneralization capability across dataset compared to the supervised baseline.", "paper_summary_zh": "<paragraph>\u9519\u8bef\u8a0a\u606f\u548c\u8b66\u5831\u5f71\u97ff\u7684\u64f4\u6563\u589e\u52a0\uff0c\u4fc3\u4f7f\u7522\u696d\u548c\u5b78\u8853\u754c\u958b\u767c\u932f\u8aa4\u8a0a\u606f\u5075\u6e2c\u548c\u4e8b\u5be6\u67e5\u6838\u7684\u65b9\u6cd5\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u986f\u8457\u7684\u8868\u73fe\uff0c\u4f46 LLM \u662f\u5426\u80fd\u5354\u52a9\u932f\u8aa4\u8a0a\u606f\u5075\u6e2c\uff0c\u4ee5\u53ca\u5982\u4f55\u5354\u52a9\uff0c\u4ecd\u76f8\u5c0d\u672a\u88ab\u5145\u5206\u63a2\u8a0e\u3002\u73fe\u6709\u7684\u6700\u5148\u9032\u65b9\u6cd5\u5927\u591a\u4e0d\u8003\u616e\u8b49\u64da\uff0c\u50c5\u5c08\u6ce8\u65bc\u8207\u8072\u660e\u76f8\u95dc\u7684\u7279\u5fb5\uff0c\u6216\u5047\u8a2d\u5df2\u63d0\u4f9b\u8b49\u64da\u3002\u5c11\u6578\u65b9\u6cd5\u5c07\u8b49\u64da\u6aa2\u7d22\u8996\u70ba\u932f\u8aa4\u8a0a\u606f\u5075\u6e2c\u7684\u4e00\u90e8\u5206\uff0c\u4f46\u4f9d\u8cf4\u5fae\u8abf\u6a21\u578b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e LLM \u5728\u96f6\u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u9032\u884c\u932f\u8aa4\u8a0a\u606f\u5075\u6e2c\u7684\u6f5b\u529b\u3002\u6211\u5011\u5c07\u8b49\u64da\u6aa2\u7d22\u5143\u4ef6\u7d0d\u5165\u6d41\u7a0b\u4e2d\uff0c\u56e0\u70ba\u5f9e\u5404\u7a2e\u4f86\u6e90\u6536\u96c6\u76f8\u95dc\u8cc7\u8a0a\u5c0d\u65bc\u5075\u6e2c\u8072\u660e\u7684\u771f\u5be6\u6027\u81f3\u95dc\u91cd\u8981\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u4f7f\u7528 LLM \u548c\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLM) \u7684\u591a\u6a21\u614b\u8b49\u64da\u6aa2\u7d22\u7684\u91cd\u65b0\u6392\u5e8f\u65b9\u6cd5\u3002\u6aa2\u7d22\u5230\u7684\u8b49\u64da\u7bc4\u4f8b\uff08\u5f71\u50cf\u548c\u6587\u5b57\uff09\u4f5c\u70ba LVLM \u57fa\u65bc\u591a\u6a21\u614b\u4e8b\u5be6\u9a57\u8b49 (LVLM4FV) \u65b9\u6cd5\u7684\u8f38\u5165\u3002\u70ba\u4e86\u9032\u884c\u516c\u5e73\u7684\u8a55\u4f30\uff0c\u6211\u5011\u900f\u904e\u70ba\u5f71\u50cf\u548c\u6587\u5b57\u6aa2\u7d22\u6a19\u8a3b\u4e00\u7d44\u66f4\u5b8c\u6574\u7684\u8b49\u64da\u7bc4\u4f8b\uff0c\u4f86\u89e3\u6c7a\u73fe\u6709\u8b49\u64da\u6aa2\u7d22\u8cc7\u6599\u96c6\u4e2d\u8b49\u64da\u7bc4\u4f8b\u4e0d\u5b8c\u6574\u7684\u554f\u984c\u3002\u6211\u5011\u5728\u5169\u500b\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8b49\u64da\u6aa2\u7d22\u548c\u4e8b\u5be6\u9a57\u8b49\u4efb\u52d9\u4e2d\u7684\u512a\u7570\u6027\uff0c\u4e26\u4e14\u8207\u76e3\u7763\u5f0f\u57fa\u6e96\u76f8\u6bd4\uff0c\u5728\u8cc7\u6599\u96c6\u9593\u4e5f\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002</paragraph>", "author": "Sahar Tahmasebi et.al.", "authors": "Sahar Tahmasebi, Eric M\u00fcller-Budack, Ralph Ewerth", "id": "2407.14321v1", "paper_url": "http://arxiv.org/abs/2407.14321v1", "repo": "null"}}