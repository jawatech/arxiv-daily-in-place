{"2405.04798": {"publish_time": "2024-05-08", "title": "From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control", "paper_summary": "Hierarchical control for robotics has long been plagued by the need to have a\nwell defined interface layer to communicate between high-level task planners\nand low-level policies. With the advent of LLMs, language has been emerging as\na prospective interface layer. However, this has several limitations. Not all\ntasks can be decomposed into steps that are easily expressible in natural\nlanguage (e.g. performing a dance routine). Further, it makes end-to-end\nfinetuning on embodied data challenging due to domain shift and catastrophic\nforgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB)\n-- as an alternate architecture to overcome these limitations. \\method~uses a\nlearnable latent code to act as a bridge between LLMs and low-level policies.\nThis enables LLMs to flexibly communicate goals in the task plan without being\nentirely constrained by language limitations. Additionally, it enables\nend-to-end finetuning without destroying the embedding space of word tokens\nlearned during pre-training. Through experiments on Language Table and Calvin,\ntwo common language based benchmarks for embodied agents, we find that\n\\method~outperforms baselines (including those w/ GPT-4V) that leverage pure\nlanguage as the interface layer on tasks that require reasoning and multi-step\nbehaviors.", "paper_summary_zh": "\u968e\u5c64\u5f0f\u6a5f\u5668\u4eba\u63a7\u5236\u9577\u671f\u4ee5\u4f86\u4e00\u76f4\u53d7\u5230\u9700\u8981\u6709\u660e\u78ba\u4ecb\u9762\u5c64\u4f86\u6e9d\u901a\u9ad8\u968e\u4efb\u52d9\u898f\u5283\u8005\u548c\u4f4e\u968e\u653f\u7b56\u7684\u56f0\u64fe\u3002\u96a8\u8457 LLM \u7684\u51fa\u73fe\uff0c\u8a9e\u8a00\u5df2\u6210\u70ba\u6f5b\u5728\u7684\u4ecb\u9762\u5c64\u3002\u7136\u800c\uff0c\u9019\u6709\u5e7e\u500b\u9650\u5236\u3002\u4e26\u975e\u6240\u6709\u4efb\u52d9\u90fd\u80fd\u5206\u89e3\u6210\u5bb9\u6613\u7528\u81ea\u7136\u8a9e\u8a00\u8868\u9054\u7684\u6b65\u9a5f\uff08\u4f8b\u5982\u57f7\u884c\u821e\u8e48\u52d5\u4f5c\uff09\u3002\u6b64\u5916\uff0c\u7531\u65bc\u9818\u57df\u8f49\u79fb\u548c\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u9019\u4f7f\u5f97\u91dd\u5c0d\u5177\u9ad4\u8cc7\u6599\u9032\u884c\u7aef\u5230\u7aef\u5fae\u8abf\u5177\u6709\u6311\u6230\u6027\u3002\u6211\u5011\u4ecb\u7d39\u4e86\u6211\u5011\u7684\u6a21\u578b\u2014\u2014\u53ef\u5b78\u7fd2\u6f5b\u5728\u78bc\u4f5c\u70ba\u6a4b\u6a11 (LCB)\u2014\u2014\u4f5c\u70ba\u4e00\u7a2e\u514b\u670d\u9019\u4e9b\u9650\u5236\u7684\u66ff\u4ee3\u67b6\u69cb\u3002\\method~\u4f7f\u7528\u53ef\u5b78\u7fd2\u6f5b\u5728\u78bc\u4f5c\u70ba LLM \u548c\u4f4e\u968e\u653f\u7b56\u4e4b\u9593\u7684\u6a4b\u6a11\u3002\u9019\u4f7f LLM \u80fd\u5920\u9748\u6d3b\u5730\u50b3\u9054\u4efb\u52d9\u8a08\u756b\u4e2d\u7684\u76ee\u6a19\uff0c\u800c\u4e0d\u6703\u5b8c\u5168\u53d7\u5230\u8a9e\u8a00\u9650\u5236\u7684\u7d04\u675f\u3002\u6b64\u5916\uff0c\u5b83\u53ef\u4ee5\u5728\u4e0d\u7834\u58de\u9810\u8a13\u7df4\u671f\u9593\u5b78\u7fd2\u5230\u7684\u6587\u5b57\u7b26\u865f\u5d4c\u5165\u7a7a\u9593\u7684\u60c5\u6cc1\u4e0b\u9032\u884c\u7aef\u5230\u7aef\u5fae\u8abf\u3002\u900f\u904e\u5c0d\u8a9e\u8a00\u8868\u683c\u548c\u51f1\u6587\u9032\u884c\u5be6\u9a57\uff0c\u9019\u5169\u500b\u662f\u5177\u9ad4\u4ee3\u7406\u7684\u5e38\u898b\u8a9e\u8a00\u57fa\u6e96\uff0c\u6211\u5011\u767c\u73fe\\method~\u512a\u65bc\u57fa\u6e96\uff08\u5305\u62ec\u90a3\u4e9b\u4f7f\u7528 GPT-4V \u7684\u57fa\u6e96\uff09\uff0c\u9019\u4e9b\u57fa\u6e96\u5728\u9700\u8981\u63a8\u7406\u548c\u591a\u6b65\u9a5f\u884c\u70ba\u7684\u4efb\u52d9\u4e0a\u5229\u7528\u7d14\u8a9e\u8a00\u4f5c\u70ba\u4ecb\u9762\u5c64\u3002", "author": "Yide Shentu et.al.", "authors": "Yide Shentu, Philipp Wu, Aravind Rajeswaran, Pieter Abbeel", "id": "2405.04798v1", "paper_url": "http://arxiv.org/abs/2405.04798v1", "repo": "null"}}