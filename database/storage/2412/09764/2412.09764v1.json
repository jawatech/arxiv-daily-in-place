{"2412.09764": {"publish_time": "2024-12-12", "title": "Memory Layers at Scale", "paper_summary": "Memory layers use a trainable key-value lookup mechanism to add extra\nparameters to a model without increasing FLOPs. Conceptually, sparsely\nactivated memory layers complement compute-heavy dense feed-forward layers,\nproviding dedicated capacity to store and retrieve information cheaply. This\nwork takes memory layers beyond proof-of-concept, proving their utility at\ncontemporary scale. On downstream tasks, language models augmented with our\nimproved memory layer outperform dense models with more than twice the\ncomputation budget, as well as mixture-of-expert models when matched for both\ncompute and parameters. We find gains are especially pronounced for factual\ntasks. We provide a fully parallelizable memory layer implementation,\ndemonstrating scaling laws with up to 128B memory parameters, pretrained to 1\ntrillion tokens, comparing to base models with up to 8B parameters.", "paper_summary_zh": "\u8a18\u61b6\u5c64\u4f7f\u7528\u53ef\u8a13\u7df4\u7684\u9375\u503c\u67e5\u8a62\u6a5f\u5236\uff0c\u5728\u4e0d\u589e\u52a0 FLOP \u7684\u60c5\u6cc1\u4e0b\u70ba\u6a21\u578b\u65b0\u589e\u984d\u5916\u53c3\u6578\u3002\u5f9e\u6982\u5ff5\u4e0a\u4f86\u8aaa\uff0c\u7a00\u758f\u6fc0\u6d3b\u8a18\u61b6\u5c64\u88dc\u5145\u4e86\u8a08\u7b97\u5bc6\u96c6\u7684\u7a20\u5bc6\u524d\u994b\u5c64\uff0c\u63d0\u4f9b\u4e86\u5c08\u9580\u7684\u5bb9\u91cf\u4f86\u5ec9\u50f9\u5132\u5b58\u548c\u64f7\u53d6\u8cc7\u8a0a\u3002\u9019\u9805\u5de5\u4f5c\u5c07\u8a18\u61b6\u5c64\u5e36\u96e2\u4e86\u6982\u5ff5\u9a57\u8b49\uff0c\u8b49\u660e\u4e86\u5b83\u5011\u5728\u7576\u4ee3\u898f\u6a21\u4e0a\u7684\u6548\u7528\u3002\u5728\u4e0b\u6e38\u4efb\u52d9\u4e2d\uff0c\u4f7f\u7528\u6211\u5011\u6539\u826f\u7684\u8a18\u61b6\u5c64\u589e\u5f37\u7684\u8a9e\u8a00\u6a21\u578b\uff0c\u5176\u6548\u80fd\u512a\u65bc\u8a08\u7b97\u9810\u7b97\u589e\u52a0\u5169\u500d\u4ee5\u4e0a\u7684\u7a20\u5bc6\u6a21\u578b\uff0c\u4ee5\u53ca\u5728\u8a08\u7b97\u548c\u53c3\u6578\u65b9\u9762\u90fd\u5339\u914d\u7684\u5c08\u5bb6\u6df7\u5408\u6a21\u578b\u3002\u6211\u5011\u767c\u73fe\u6536\u76ca\u5728\u4e8b\u5be6\u4efb\u52d9\u4e2d\u7279\u5225\u660e\u986f\u3002\u6211\u5011\u63d0\u4f9b\u4e86\u4e00\u500b\u5b8c\u5168\u53ef\u4e26\u884c\u7684\u8a18\u61b6\u5c64\u5be6\u4f5c\uff0c\u5c55\u793a\u4e86\u9ad8\u9054 128B \u8a18\u61b6\u9ad4\u53c3\u6578\u7684\u7e2e\u653e\u5b9a\u5f8b\uff0c\u9810\u8a13\u7df4\u5230 1 \u5146\u500b token\uff0c\u8207\u9ad8\u9054 8B \u53c3\u6578\u7684\u57fa\u672c\u6a21\u578b\u9032\u884c\u6bd4\u8f03\u3002", "author": "Vincent-Pierre Berges et.al.", "authors": "Vincent-Pierre Berges, Barlas O\u011fuz, Daniel Haziza, Wen-tau Yih, Luke Zettlemoyer, Gargi Gosh", "id": "2412.09764v1", "paper_url": "http://arxiv.org/abs/2412.09764v1", "repo": "https://github.com/facebookresearch/memory"}}