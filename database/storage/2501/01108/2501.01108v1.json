{"2501.01108": {"publish_time": "2025-01-02", "title": "MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization", "paper_summary": "Recent years have witnessed the success of foundation models pre-trained with\nself-supervised learning (SSL) in various music informatics understanding\ntasks, including music tagging, instrument classification, key detection, and\nmore. In this paper, we propose a self-supervised music representation learning\nmodel for music understanding. Distinguished from previous studies adopting\nrandom projection or existing neural codec, the proposed model, named MuQ, is\ntrained to predict tokens generated by Mel Residual Vector Quantization\n(Mel-RVQ). Our Mel-RVQ utilizes residual linear projection structure for Mel\nspectrum quantization to enhance the stability and efficiency of target\nextraction and lead to better performance. Experiments in a large variety of\ndownstream tasks demonstrate that MuQ outperforms previous self-supervised\nmusic representation models with only 0.9K hours of open-source pre-training\ndata. Scaling up the data to over 160K hours and adopting iterative training\nconsistently improve the model performance. To further validate the strength of\nour model, we present MuQ-MuLan, a joint music-text embedding model based on\ncontrastive learning, which achieves state-of-the-art performance in the\nzero-shot music tagging task on the MagnaTagATune dataset. Code and checkpoints\nare open source in https://github.com/tencent-ailab/MuQ.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u5728\u5404\u79cd\u97f3\u4e50\u4fe1\u606f\u5b66\u7406\u89e3\u4efb\u52a1\u4e2d\uff0c\u5229\u7528\u81ea\u6211\u76d1\u7763\u5b66\u4e60 (SSL) \u9884\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u5305\u62ec\u97f3\u4e50\u6807\u8bb0\u3001\u4e50\u5668\u5206\u7c7b\u3001\u952e\u68c0\u6d4b\u7b49\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u97f3\u4e50\u7406\u89e3\u7684\u81ea\u6211\u76d1\u7763\u97f3\u4e50\u8868\u5f81\u5b66\u4e60\u6a21\u578b\u3002\u4e0e\u91c7\u7528\u968f\u673a\u6295\u5f71\u6216\u73b0\u6709\u795e\u7ecf\u7f16\u89e3\u7801\u5668\u7684\u5148\u524d\u7684\u7814\u7a76\u4e0d\u540c\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b MuQ \u88ab\u8bad\u7ec3\u4e3a\u9884\u6d4b Mel \u6b8b\u5dee\u77e2\u91cf\u91cf\u5316 (Mel-RVQ) \u751f\u6210\u7684\u6807\u8bb0\u3002\u6211\u4eec\u7684 Mel-RVQ \u5229\u7528\u6b8b\u5dee\u7ebf\u6027\u6295\u5f71\u7ed3\u6784\u5bf9 Mel \u8c31\u8fdb\u884c\u91cf\u5316\uff0c\u4ee5\u589e\u5f3a\u76ee\u6807\u63d0\u53d6\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\uff0c\u5e76\u5e26\u6765\u66f4\u597d\u7684\u6027\u80fd\u3002\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMuQ \u4ec5\u4f7f\u7528 0.9K \u5c0f\u65f6\u7684\u5f00\u6e90\u9884\u8bad\u7ec3\u6570\u636e\u5c31\u4f18\u4e8e\u5148\u524d\u7684\u81ea\u6211\u76d1\u7763\u97f3\u4e50\u8868\u5f81\u6a21\u578b\u3002\u5c06\u6570\u636e\u6269\u5c55\u5230\u8d85\u8fc7 160K \u5c0f\u65f6\u5e76\u91c7\u7528\u8fed\u4ee3\u8bad\u7ec3\u53ef\u4ee5\u6301\u7eed\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u6211\u4eec\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 MuQ-MuLan\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u8054\u5408\u97f3\u4e50\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u5728 MagnaTagATune \u6570\u636e\u96c6\u4e0a\u7684\u96f6\u6837\u672c\u97f3\u4e50\u6807\u8bb0\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u4ee3\u7801\u548c\u68c0\u67e5\u70b9\u5728 https://github.com/tencent-ailab/MuQ \u4e2d\u5f00\u6e90\u3002", "author": "Haina Zhu et.al.", "authors": "Haina Zhu, Yizhi Zhou, Hangting Chen, Jianwei Yu, Ziyang Ma, Rongzhi Gu, Wei Tan, Xie Chen", "id": "2501.01108v1", "paper_url": "http://arxiv.org/abs/2501.01108v1", "repo": "null"}}