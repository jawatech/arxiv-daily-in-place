{"2408.11382": {"publish_time": "2024-08-21", "title": "On the Interchangeability of Positional Embeddings in Multilingual Neural Machine Translation Models", "paper_summary": "Standard Neural Machine Translation (NMT) models have traditionally been\ntrained with Sinusoidal Positional Embeddings (PEs), which are inadequate for\ncapturing long-range dependencies and are inefficient for long-context or\ndocument-level translation. In contrast, state-of-the-art large language models\n(LLMs) employ relative PEs, demonstrating superior length generalization. This\nwork explores the potential for efficiently switching the Positional Embeddings\nof pre-trained NMT models from absolute sinusoidal PEs to relative approaches\nsuch as RoPE and ALiBi. Our findings reveal that sinusoidal PEs can be\neffectively replaced with RoPE and ALiBi with negligible or no performance\nloss, achieved by fine-tuning on a small fraction of high-quality data.\nAdditionally, models trained without Positional Embeddings (NoPE) are not a\nviable solution for Encoder-Decoder architectures, as they consistently\nunder-perform compared to models utilizing any form of Positional Embedding.\nFurthermore, even a model trained from scratch with these relative PEs slightly\nunder-performs a fine-tuned model, underscoring the efficiency and validity of\nour hypothesis.", "paper_summary_zh": "\u6a19\u6e96\u795e\u7d93\u6a5f\u5668\u7ffb\u8b6f (NMT) \u6a21\u578b\u50b3\u7d71\u4e0a\u4f7f\u7528\u6b63\u5f26\u4f4d\u7f6e\u5d4c\u5165 (PE) \u9032\u884c\u8a13\u7df4\uff0c\u9019\u5c0d\u65bc\u6355\u6349\u9577\u8ddd\u96e2\u4f9d\u8cf4\u6027\u662f\u4e0d\u5920\u7684\uff0c\u4e26\u4e14\u5c0d\u65bc\u9577\u6587\u6216\u6587\u4ef6\u7d1a\u5225\u7684\u7ffb\u8b6f\u6548\u7387\u4f4e\u4e0b\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6700\u5148\u9032\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u4f7f\u7528\u76f8\u5c0d PE\uff0c\u5c55\u793a\u4e86\u512a\u8d8a\u7684\u9577\u5ea6\u6cdb\u5316\u3002\u9019\u9805\u5de5\u4f5c\u63a2\u8a0e\u4e86\u6709\u6548\u5207\u63db\u9810\u8a13\u7df4 NMT \u6a21\u578b\u7684\u4f4d\u7f6e\u5d4c\u5165\u7684\u53ef\u80fd\u6027\uff0c\u5f9e\u7d55\u5c0d\u6b63\u5f26 PE \u8f49\u63db\u70ba\u76f8\u5c0d\u65b9\u6cd5\uff0c\u4f8b\u5982 RoPE \u548c ALiBi\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u6b63\u5f26 PE \u53ef\u4ee5\u6709\u6548\u5730\u7528 RoPE \u548c ALiBi \u66ff\u63db\uff0c\u800c\u5e7e\u4e4e\u4e0d\u6703\u6216\u4e0d\u6703\u9020\u6210\u6548\u80fd\u640d\u5931\uff0c\u9019\u53ef\u900f\u904e\u5fae\u8abf\u4e00\u5c0f\u90e8\u5206\u9ad8\u54c1\u8cea\u8cc7\u6599\u4f86\u5be6\u73fe\u3002\u6b64\u5916\uff0c\u6c92\u6709\u4f4d\u7f6e\u5d4c\u5165 (NoPE) \u8a13\u7df4\u7684\u6a21\u578b\u4e26\u975e\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u67b6\u69cb\u7684\u53ef\u884c\u89e3\u6c7a\u65b9\u6848\uff0c\u56e0\u70ba\u8207\u4f7f\u7528\u4efb\u4f55\u5f62\u5f0f\u7684\u4f4d\u7f6e\u5d4c\u5165\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u5b83\u5011\u59cb\u7d42\u8868\u73fe\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u5f9e\u982d\u958b\u59cb\u4f7f\u7528\u9019\u4e9b\u76f8\u5c0d PE \u8a13\u7df4\u7684\u6a21\u578b\uff0c\u5176\u6548\u80fd\u4e5f\u7565\u4f4e\u65bc\u5fae\u8abf\u6a21\u578b\uff0c\u9019\u5f37\u8abf\u4e86\u6211\u5011\u5047\u8a2d\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002", "author": "Varun Gumma et.al.", "authors": "Varun Gumma, Pranjal A. Chitale, Kalika Bali", "id": "2408.11382v1", "paper_url": "http://arxiv.org/abs/2408.11382v1", "repo": "null"}}