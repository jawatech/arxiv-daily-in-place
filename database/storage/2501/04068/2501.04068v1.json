{"2501.04068": {"publish_time": "2025-01-07", "title": "Explainable Reinforcement Learning for Formula One Race Strategy", "paper_summary": "In Formula One, teams compete to develop their cars and achieve the highest\npossible finishing position in each race. During a race, however, teams are\nunable to alter the car, so they must improve their cars' finishing positions\nvia race strategy, i.e. optimising their selection of which tyre compounds to\nput on the car and when to do so. In this work, we introduce a reinforcement\nlearning model, RSRL (Race Strategy Reinforcement Learning), to control race\nstrategies in simulations, offering a faster alternative to the industry\nstandard of hard-coded and Monte Carlo-based race strategies. Controlling cars\nwith a pace equating to an expected finishing position of P5.5 (where P1\nrepresents first place and P20 is last place), RSRL achieves an average\nfinishing position of P5.33 on our test race, the 2023 Bahrain Grand Prix,\noutperforming the best baseline of P5.63. We then demonstrate, in a\ngeneralisability study, how performance for one track or multiple tracks can be\nprioritised via training. Further, we supplement model predictions with feature\nimportance, decision tree-based surrogate models, and decision tree\ncounterfactuals towards improving user trust in the model. Finally, we provide\nillustrations which exemplify our approach in real-world situations, drawing\nparallels between simulations and reality.", "paper_summary_zh": "\u5728\u4e00\u7ea7\u65b9\u7a0b\u5f0f\u8d5b\u8f66\u4e2d\uff0c\u8f66\u961f\u7ade\u76f8\u5f00\u53d1\u4ed6\u4eec\u7684\u8d5b\u8f66\uff0c\u5e76\u5728\u6bcf\u573a\u6bd4\u8d5b\u4e2d\u53d6\u5f97\u5c3d\u53ef\u80fd\u9ad8\u7684\u5b8c\u8d5b\u540d\u6b21\u3002\u7136\u800c\uff0c\u5728\u6bd4\u8d5b\u671f\u95f4\uff0c\u8f66\u961f\u65e0\u6cd5\u6539\u53d8\u8d5b\u8f66\uff0c\u56e0\u6b64\u4ed6\u4eec\u5fc5\u987b\u901a\u8fc7\u6bd4\u8d5b\u7b56\u7565\u6765\u63d0\u9ad8\u8d5b\u8f66\u7684\u5b8c\u8d5b\u540d\u6b21\uff0c\u5373\u4f18\u5316\u9009\u62e9\u4f55\u65f6\u4e3a\u8d5b\u8f66\u66f4\u6362\u54ea\u79cd\u8f6e\u80ce\u914d\u65b9\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0cRSRL\uff08\u6bd4\u8d5b\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\uff09\uff0c\u6765\u63a7\u5236\u6a21\u62df\u4e2d\u7684\u6bd4\u8d5b\u7b56\u7565\uff0c\u4e3a\u4e1a\u754c\u6807\u51c6\u7684\u786c\u7f16\u7801\u548c\u57fa\u4e8e\u8499\u7279\u5361\u7f57\u7684\u6bd4\u8d5b\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5feb\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7528\u4e0e\u9884\u671f\u5b8c\u8d5b\u540d\u6b21 P5.5 \u76f8\u5f53\u7684\u901f\u5ea6\u63a7\u5236\u8d5b\u8f66\uff08\u5176\u4e2d P1 \u4ee3\u8868\u7b2c\u4e00\u540d\uff0cP20 \u4e3a\u6700\u540e\u4e00\u540d\uff09\uff0cRSRL \u5728\u6211\u4eec\u7684\u6d4b\u8bd5\u6bd4\u8d5b\u4e2d\u83b7\u5f97\u4e86 P5.33 \u7684\u5e73\u5747\u5b8c\u8d5b\u540d\u6b21\uff0c2023 \u5e74\u5df4\u6797\u5927\u5956\u8d5b\uff0c\u4f18\u4e8e P5.63 \u7684\u6700\u4f73\u57fa\u51c6\u3002\u7136\u540e\u6211\u4eec\u5728\u4e00\u4e2a\u901a\u7528\u6027\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8bad\u7ec3\u4f18\u5148\u8003\u8651\u4e00\u6761\u8d5b\u9053\u6216\u591a\u6761\u8d5b\u9053\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7528\u7279\u5f81\u91cd\u8981\u6027\u3001\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u66ff\u4ee3\u6a21\u578b\u548c\u51b3\u7b56\u6811\u53cd\u4e8b\u5b9e\u6765\u8865\u5145\u6a21\u578b\u9884\u6d4b\uff0c\u4ee5\u63d0\u9ad8\u7528\u6237\u5bf9\u6a21\u578b\u7684\u4fe1\u4efb\u3002\u6700\u540e\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u8bf4\u660e\u6211\u4eec\u65b9\u6cd5\u5728\u73b0\u5b9e\u4e16\u754c\u60c5\u51b5\u4e2d\u7684\u793a\u4f8b\uff0c\u5728\u6a21\u62df\u548c\u73b0\u5b9e\u4e4b\u95f4\u753b\u51fa\u76f8\u4f3c\u4e4b\u5904\u3002", "author": "Devin Thomas et.al.", "authors": "Devin Thomas, Junqi Jiang, Avinash Kori, Aaron Russo, Steffen Winkler, Stuart Sale, Joseph McMillan, Francesco Belardinelli, Antonio Rago", "id": "2501.04068v1", "paper_url": "http://arxiv.org/abs/2501.04068v1", "repo": "null"}}