{"2407.02466": {"publish_time": "2024-07-02", "title": "PWM: Policy Learning with Large World Models", "paper_summary": "Reinforcement Learning (RL) has achieved impressive results on complex tasks\nbut struggles in multi-task settings with different embodiments. World models\noffer scalability by learning a simulation of the environment, yet they often\nrely on inefficient gradient-free optimization methods. We introduce Policy\nlearning with large World Models (PWM), a novel model-based RL algorithm that\nlearns continuous control policies from large multi-task world models. By\npre-training the world model on offline data and using it for first-order\ngradient policy learning, PWM effectively solves tasks with up to 152 action\ndimensions and outperforms methods using ground-truth dynamics. Additionally,\nPWM scales to an 80-task setting, achieving up to 27% higher rewards than\nexisting baselines without the need for expensive online planning.\nVisualizations and code available at https://policy-world-model.github.io", "paper_summary_zh": "\u5f37\u5316\u5b78\u7fd2 (RL) \u5728\u8907\u96dc\u4efb\u52d9\u4e0a\u5df2\u53d6\u5f97\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6210\u679c\uff0c\u4f46\u5c0d\u65bc\u5177\u6709\u4e0d\u540c\u5177\u9ad4\u5be6\u4f8b\u7684\u591a\u4efb\u52d9\u8a2d\u5b9a\u5247\u6709\u56f0\u96e3\u3002\u4e16\u754c\u6a21\u578b\u900f\u904e\u5b78\u7fd2\u74b0\u5883\u6a21\u64ec\u4f86\u63d0\u4f9b\u53ef\u64f4\u5145\u6027\uff0c\u4f46\u5b83\u5011\u901a\u5e38\u4f9d\u8cf4\u65bc\u4f4e\u6548\u7387\u7684\u7121\u68af\u5ea6\u6700\u4f73\u5316\u65b9\u6cd5\u3002\u6211\u5011\u5f15\u5165\u4e86\u5927\u578b\u4e16\u754c\u6a21\u578b (PWM) \u7684\u7b56\u7565\u5b78\u7fd2\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u57fa\u65bc\u6a21\u578b\u7684 RL \u6f14\u7b97\u6cd5\uff0c\u5b83\u5f9e\u5927\u578b\u591a\u4efb\u52d9\u4e16\u754c\u6a21\u578b\u4e2d\u5b78\u7fd2\u9023\u7e8c\u63a7\u5236\u7b56\u7565\u3002\u900f\u904e\u5728\u96e2\u7dda\u8cc7\u6599\u4e0a\u9810\u5148\u8a13\u7df4\u4e16\u754c\u6a21\u578b\uff0c\u4e26\u5c07\u5176\u7528\u65bc\u4e00\u968e\u68af\u5ea6\u7b56\u7565\u5b78\u7fd2\uff0cPWM \u6709\u6548\u5730\u89e3\u6c7a\u4e86\u5177\u6709\u9ad8\u9054 152 \u500b\u52d5\u4f5c\u7dad\u5ea6\u7684\u4efb\u52d9\uff0c\u4e26\u512a\u65bc\u4f7f\u7528\u771f\u5be6\u52d5\u614b\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0cPWM \u53ef\u64f4\u5145\u5230 80 \u500b\u4efb\u52d9\u8a2d\u5b9a\uff0c\u6bd4\u73fe\u6709\u7684\u57fa\u7dda\u9ad8\u51fa 27% \u7684\u734e\u52f5\uff0c\u800c\u7121\u9700\u6602\u8cb4\u7684\u7dda\u4e0a\u898f\u5283\u3002\u8996\u89ba\u5316\u548c\u7a0b\u5f0f\u78bc\u53ef\u65bc https://policy-world-model.github.io \u53d6\u5f97", "author": "Ignat Georgiev et.al.", "authors": "Ignat Georgiev, Varun Giridhar, Nicklas Hansen, Animesh Garg", "id": "2407.02466v1", "paper_url": "http://arxiv.org/abs/2407.02466v1", "repo": "null"}}