{"2502.13131": {"publish_time": "2025-02-18", "title": "Rethinking Diverse Human Preference Learning through Principal Component Analysis", "paper_summary": "Understanding human preferences is crucial for improving foundation models\nand building personalized AI systems. However, preferences are inherently\ndiverse and complex, making it difficult for traditional reward models to\ncapture their full range. While fine-grained preference data can help,\ncollecting it is expensive and hard to scale. In this paper, we introduce\nDecomposed Reward Models (DRMs), a novel approach that extracts diverse human\npreferences from binary comparisons without requiring fine-grained annotations.\nOur key insight is to represent human preferences as vectors and analyze them\nusing Principal Component Analysis (PCA). By constructing a dataset of\nembedding differences between preferred and rejected responses, DRMs identify\northogonal basis vectors that capture distinct aspects of preference. These\ndecomposed rewards can be flexibly combined to align with different user needs,\noffering an interpretable and scalable alternative to traditional reward\nmodels. We demonstrate that DRMs effectively extract meaningful preference\ndimensions (e.g., helpfulness, safety, humor) and adapt to new users without\nadditional training. Our results highlight DRMs as a powerful framework for\npersonalized and interpretable LLM alignment.", "paper_summary_zh": "\u7406\u89e3\u4eba\u985e\u504f\u597d\u5c0d\u65bc\u6539\u9032\u57fa\u790e\u6a21\u578b\u548c\u5efa\u69cb\u500b\u4eba\u5316 AI \u7cfb\u7d71\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u504f\u597d\u672c\u8cea\u4e0a\u662f\u591a\u6a23\u4e14\u8907\u96dc\u7684\uff0c\u9019\u4f7f\u5f97\u50b3\u7d71\u7684\u734e\u52f5\u6a21\u578b\u96e3\u4ee5\u6355\u6349\u5176\u5168\u90e8\u7bc4\u570d\u3002\u96d6\u7136\u7d30\u7dfb\u7684\u504f\u597d\u6578\u64da\u53ef\u80fd\u6709\u6240\u5e6b\u52a9\uff0c\u4f46\u6536\u96c6\u9019\u4e9b\u6578\u64da\u65e2\u6602\u8cb4\u53c8\u96e3\u4ee5\u64f4\u5c55\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u89e3\u69cb\u734e\u52f5\u6a21\u578b (DRM)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u5f9e\u4e8c\u5143\u6bd4\u8f03\u4e2d\u63d0\u53d6\u591a\u6a23\u5316\u7684\u4eba\u985e\u504f\u597d\uff0c\u800c\u4e0d\u9700\u8981\u7d30\u7dfb\u7684\u8a3b\u89e3\u3002\u6211\u5011\u7684\u95dc\u9375\u898b\u89e3\u662f\u5c07\u4eba\u985e\u504f\u597d\u8868\u793a\u70ba\u5411\u91cf\uff0c\u4e26\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790 (PCA) \u5c0d\u5176\u9032\u884c\u5206\u6790\u3002\u900f\u904e\u5efa\u69cb\u504f\u597d\u548c\u62d2\u7d55\u56de\u61c9\u4e4b\u9593\u5d4c\u5165\u5dee\u7570\u7684\u6578\u64da\u96c6\uff0cDRM \u8b58\u5225\u51fa\u6b63\u4ea4\u57fa\u5411\u91cf\uff0c\u9019\u4e9b\u5411\u91cf\u6355\u6349\u504f\u597d\u7684\u4e0d\u540c\u9762\u5411\u3002\u9019\u4e9b\u89e3\u69cb\u7684\u734e\u52f5\u53ef\u4ee5\u9748\u6d3b\u5730\u7d50\u5408\u5728\u4e00\u8d77\uff0c\u4ee5\u7b26\u5408\u4e0d\u540c\u7684\u4f7f\u7528\u8005\u9700\u6c42\uff0c\u63d0\u4f9b\u4e00\u7a2e\u53ef\u89e3\u91cb\u4e14\u53ef\u64f4\u5c55\u7684\u50b3\u7d71\u734e\u52f5\u6a21\u578b\u66ff\u4ee3\u65b9\u6848\u3002\u6211\u5011\u8b49\u660e\u4e86 DRM \u53ef\u4ee5\u6709\u6548\u5730\u63d0\u53d6\u6709\u610f\u7fa9\u7684\u504f\u597d\u7dad\u5ea6\uff08\u4f8b\u5982\uff0c\u6709\u7528\u6027\u3001\u5b89\u5168\u6027\u3001\u5e7d\u9ed8\u611f\uff09\uff0c\u4e26\u5728\u4e0d\u9700\u8981\u984d\u5916\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u9069\u61c9\u65b0\u7684\u4f7f\u7528\u8005\u3002\u6211\u5011\u7684\u7d50\u679c\u7a81\u986f\u4e86 DRM \u4f5c\u70ba\u500b\u4eba\u5316\u4e14\u53ef\u89e3\u91cb\u7684 LLM \u5c0d\u9f4a\u5f37\u5927\u67b6\u69cb\u3002", "author": "Feng Luo et.al.", "authors": "Feng Luo, Rui Yang, Hao Sun, Chunyuan Deng, Jiarui Yao, Jingyan Shen, Huan Zhang, Hanjie Chen", "id": "2502.13131v1", "paper_url": "http://arxiv.org/abs/2502.13131v1", "repo": "null"}}