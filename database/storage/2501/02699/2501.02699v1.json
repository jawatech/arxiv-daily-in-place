{"2501.02699": {"publish_time": "2025-01-06", "title": "EAGLE: Enhanced Visual Grounding Minimizes Hallucinations in Instructional Multimodal Models", "paper_summary": "Large language models and vision transformers have demonstrated impressive\nzero-shot capabilities, enabling significant transferability in downstream\ntasks. The fusion of these models has resulted in multi-modal architectures\nwith enhanced instructional capabilities. Despite incorporating vast image and\nlanguage pre-training, these multi-modal architectures often generate responses\nthat deviate from the ground truth in the image data. These failure cases are\nknown as hallucinations. Current methods for mitigating hallucinations\ngenerally focus on regularizing the language component, improving the fusion\nmodule, or ensembling multiple visual encoders to improve visual\nrepresentation. In this paper, we address the hallucination issue by directly\nenhancing the capabilities of the visual component. Our approach, named EAGLE,\nis fully agnostic to the LLM or fusion module and works as a post-pretraining\napproach that improves the grounding and language alignment of the visual\nencoder. We show that a straightforward reformulation of the original\ncontrastive pre-training task results in an improved visual encoder that can be\nincorporated into the instructional multi-modal architecture without additional\ninstructional training. As a result, EAGLE achieves a significant reduction in\nhallucinations across multiple challenging benchmarks and tasks.", "paper_summary_zh": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8f6c\u6362\u5668\u5df2\u5c55\u793a\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u53ef\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5b9e\u73b0\u663e\u8457\u7684\u53ef\u8fc1\u79fb\u6027\u3002\u8fd9\u4e9b\u6a21\u578b\u7684\u878d\u5408\u4ea7\u751f\u4e86\u5177\u6709\u589e\u5f3a\u6307\u4ee4\u80fd\u529b\u7684\u591a\u6a21\u6001\u67b6\u6784\u3002\u5c3d\u7ba1\u878d\u5408\u4e86\u5927\u91cf\u7684\u56fe\u50cf\u548c\u8bed\u8a00\u9884\u8bad\u7ec3\uff0c\u4f46\u8fd9\u4e9b\u591a\u6a21\u6001\u67b6\u6784\u901a\u5e38\u4f1a\u751f\u6210\u504f\u79bb\u56fe\u50cf\u6570\u636e\u4e2d\u57fa\u672c\u4e8b\u5b9e\u7684\u54cd\u5e94\u3002\u8fd9\u4e9b\u5931\u8d25\u6848\u4f8b\u88ab\u79f0\u4e3a\u5e7b\u89c9\u3002\u5f53\u524d\u51cf\u8f7b\u5e7b\u89c9\u7684\u65b9\u6cd5\u901a\u5e38\u96c6\u4e2d\u5728\u6b63\u5219\u5316\u8bed\u8a00\u7ec4\u4ef6\u3001\u6539\u8fdb\u878d\u5408\u6a21\u5757\u6216\u96c6\u6210\u591a\u4e2a\u89c6\u89c9\u7f16\u7801\u5668\u4ee5\u6539\u8fdb\u89c6\u89c9\u8868\u793a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u76f4\u63a5\u589e\u5f3a\u89c6\u89c9\u7ec4\u4ef6\u7684\u80fd\u529b\u6765\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u540d\u4e3a EAGLE\uff0c\u5b83\u5b8c\u5168\u72ec\u7acb\u4e8e LLM \u6216\u878d\u5408\u6a21\u5757\uff0c\u5e76\u4f5c\u4e3a\u4e00\u79cd\u540e\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u53ef\u6539\u8fdb\u89c6\u89c9\u7f16\u7801\u5668\u7684\u63a5\u5730\u548c\u8bed\u8a00\u5bf9\u9f50\u3002\u6211\u4eec\u8868\u660e\uff0c\u5bf9\u539f\u59cb\u5bf9\u6bd4\u9884\u8bad\u7ec3\u4efb\u52a1\u7684\u76f4\u63a5\u91cd\u65b0\u8868\u8ff0\u4ea7\u751f\u4e86\u6539\u8fdb\u7684\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u8be5\u7f16\u7801\u5668\u53ef\u4ee5\u5408\u5e76\u5230\u6307\u4ee4\u6027\u591a\u6a21\u6001\u67b6\u6784\u4e2d\uff0c\u800c\u65e0\u9700\u989d\u5916\u7684\u6307\u4ee4\u6027\u8bad\u7ec3\u3002\u56e0\u6b64\uff0cEAGLE \u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u548c\u4efb\u52a1\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\u3002", "author": "Andr\u00e9s Villa et.al.", "authors": "Andr\u00e9s Villa, Juan Le\u00f3n Alc\u00e1zar, Motasem Alfarra, Vladimir Araujo, Alvaro Soto, Bernard Ghanem", "id": "2501.02699v1", "paper_url": "http://arxiv.org/abs/2501.02699v1", "repo": "null"}}