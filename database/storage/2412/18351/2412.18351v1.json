{"2412.18351": {"publish_time": "2024-12-24", "title": "Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering", "paper_summary": "Large Language Models (LLMs) have achieved impressive results in\nknowledge-based Visual Question Answering (VQA). However existing methods still\nhave challenges: the inability to use external tools autonomously, and the\ninability to work in teams. Humans tend to know whether they need to use\nexternal tools when they encounter a new question, e.g., they tend to be able\nto give a direct answer to a familiar question, whereas they tend to use tools\nsuch as search engines when they encounter an unfamiliar question. In addition,\nhumans also tend to collaborate and discuss with others to get better answers.\nInspired by this, we propose the multi-agent voting framework. We design three\nLLM-based agents that simulate different levels of staff in a team, and assign\nthe available tools according to the levels. Each agent provides the\ncorresponding answer, and finally all the answers provided by the agents are\nvoted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our\napproach outperforms other baselines by 2.2 and 1.0, respectively.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u57fa\u65bc\u77e5\u8b58\u7684\u8996\u89ba\u554f\u7b54 (VQA) \u4e2d\u53d6\u5f97\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6210\u679c\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u4ecd\u6709\u6311\u6230\uff1a\u7121\u6cd5\u81ea\u4e3b\u4f7f\u7528\u5916\u90e8\u5de5\u5177\uff0c\u4ee5\u53ca\u7121\u6cd5\u5718\u968a\u5408\u4f5c\u3002\u4eba\u985e\u50be\u5411\u65bc\u77e5\u9053\u5728\u9047\u5230\u65b0\u554f\u984c\u6642\u662f\u5426\u9700\u8981\u4f7f\u7528\u5916\u90e8\u5de5\u5177\uff0c\u4f8b\u5982\uff0c\u4ed6\u5011\u50be\u5411\u65bc\u80fd\u5920\u76f4\u63a5\u56de\u7b54\u719f\u6089\u7684\u554f\u984c\uff0c\u800c\u7576\u4ed6\u5011\u9047\u5230\u4e0d\u719f\u6089\u7684\u554f\u984c\u6642\uff0c\u4ed6\u5011\u50be\u5411\u65bc\u4f7f\u7528\u641c\u7d22\u5f15\u64ce\u7b49\u5de5\u5177\u3002\u6b64\u5916\uff0c\u4eba\u985e\u4e5f\u50be\u5411\u65bc\u8207\u4ed6\u4eba\u5408\u4f5c\u548c\u8a0e\u8ad6\u4ee5\u7372\u5f97\u66f4\u597d\u7684\u7b54\u6848\u3002\u53d7\u6b64\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u591a\u4e3b\u9ad4\u6295\u7968\u6846\u67b6\u3002\u6211\u5011\u8a2d\u8a08\u4e86\u4e09\u500b\u57fa\u65bc LLM \u7684\u4e3b\u9ad4\uff0c\u6a21\u64ec\u5718\u968a\u4e2d\u4e0d\u540c\u5c64\u7d1a\u7684\u54e1\u5de5\uff0c\u4e26\u6839\u64da\u5c64\u7d1a\u5206\u914d\u53ef\u7528\u5de5\u5177\u3002\u6bcf\u500b\u4e3b\u9ad4\u63d0\u4f9b\u76f8\u61c9\u7684\u7b54\u6848\uff0c\u6700\u5f8c\u6240\u6709\u4e3b\u9ad4\u63d0\u4f9b\u7684\u7b54\u6848\u90fd\u7d93\u904e\u6295\u7968\u4ee5\u7372\u5f97\u6700\u7d42\u7b54\u6848\u3002OK-VQA \u548c A-OKVQA \u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5206\u5225\u6bd4\u5176\u4ed6\u57fa\u6e96\u9ad8\u51fa 2.2 \u548c 1.0\u3002", "author": "Zhongjian Hu et.al.", "authors": "Zhongjian Hu, Peng Yang, Bing Li, Zhenqi Wang", "id": "2412.18351v1", "paper_url": "http://arxiv.org/abs/2412.18351v1", "repo": "null"}}