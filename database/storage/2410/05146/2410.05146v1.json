{"2410.05146": {"publish_time": "2024-10-07", "title": "CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation", "paper_summary": "Models for streaming speech translation (ST) can achieve high accuracy and\nlow latency if they're developed with vast amounts of paired audio in the\nsource language and written text in the target language. Yet, these text labels\nfor the target language are often pseudo labels due to the prohibitive cost of\nmanual ST data labeling. In this paper, we introduce a methodology named\nConnectionist Temporal Classification guided modality matching (CTC-GMM) that\nenhances the streaming ST model by leveraging extensive machine translation\n(MT) text data. This technique employs CTC to compress the speech sequence into\na compact embedding sequence that matches the corresponding text sequence,\nallowing us to utilize matched {source-target} language text pairs from the MT\ncorpora to refine the streaming ST model further. Our evaluations with FLEURS\nand CoVoST2 show that the CTC-GMM approach can increase translation accuracy\nrelatively by 13.9% and 6.4% respectively, while also boosting decoding speed\nby 59.7% on GPU.", "paper_summary_zh": "\u4e32\u6d41\u8a9e\u97f3\u7ffb\u8b6f (ST) \u6a21\u578b\u5982\u679c\u4f7f\u7528\u5927\u91cf\u914d\u5c0d\u7684\u539f\u59cb\u8a9e\u8a00\u97f3\u8a0a\u548c\u76ee\u6a19\u8a9e\u8a00\u66f8\u9762\u6587\u5b57\u4f86\u958b\u767c\uff0c\u53ef\u4ee5\u9054\u5230\u9ad8\u6e96\u78ba\u5ea6\u548c\u4f4e\u5ef6\u9072\u3002\u7136\u800c\uff0c\u7531\u65bc\u4eba\u5de5 ST \u8cc7\u6599\u6a19\u8a18\u7684\u6210\u672c\u904e\u9ad8\uff0c\u9019\u4e9b\u76ee\u6a19\u8a9e\u8a00\u7684\u6587\u5b57\u6a19\u7c64\u901a\u5e38\u662f\u507d\u6a19\u7c64\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e00\u7a2e\u540d\u70ba\u9023\u63a5\u4e3b\u7fa9\u6642\u5e8f\u5206\u985e\u5f15\u5c0e\u6a21\u614b\u5339\u914d (CTC-GMM) \u7684\u65b9\u6cd5\uff0c\u900f\u904e\u5229\u7528\u5927\u91cf\u7684\u6a5f\u5668\u7ffb\u8b6f (MT) \u6587\u5b57\u8cc7\u6599\u4f86\u589e\u5f37\u4e32\u6d41 ST \u6a21\u578b\u3002\u6b64\u6280\u8853\u63a1\u7528 CTC \u5c07\u8a9e\u97f3\u5e8f\u5217\u58d3\u7e2e\u6210\u4e00\u500b\u7dca\u6e4a\u7684\u5d4c\u5165\u5e8f\u5217\uff0c\u8207\u5c0d\u61c9\u7684\u6587\u5b57\u5e8f\u5217\u76f8\u7b26\uff0c\u8b93\u6211\u5011\u80fd\u5920\u5229\u7528 MT \u8a9e\u6599\u5eab\u4e2d\u5339\u914d\u7684 {\u539f\u59cb\u8a9e\u8a00-\u76ee\u6a19\u8a9e\u8a00} \u8a9e\u8a00\u6587\u5b57\u5c0d\u9032\u4e00\u6b65\u6539\u5584\u4e32\u6d41 ST \u6a21\u578b\u3002\u6211\u5011\u4f7f\u7528 FLEURS \u548c CoVoST2 \u9032\u884c\u8a55\u4f30\uff0c\u7d50\u679c\u986f\u793a CTC-GMM \u65b9\u6cd5\u53ef\u4ee5\u5206\u5225\u5c07\u7ffb\u8b6f\u6e96\u78ba\u5ea6\u63d0\u9ad8 13.9% \u548c 6.4%\uff0c\u540c\u6642\u5728 GPU \u4e0a\u5c07\u89e3\u78bc\u901f\u5ea6\u63d0\u5347 59.7%\u3002", "author": "Rui Zhao et.al.", "authors": "Rui Zhao, Jinyu Li, Ruchao Fan, Matt Post", "id": "2410.05146v1", "paper_url": "http://arxiv.org/abs/2410.05146v1", "repo": "null"}}