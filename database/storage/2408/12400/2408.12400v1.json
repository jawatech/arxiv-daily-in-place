{"2408.12400": {"publish_time": "2024-08-22", "title": "Multi-Style Facial Sketch Synthesis through Masked Generative Modeling", "paper_summary": "The facial sketch synthesis (FSS) model, capable of generating sketch\nportraits from given facial photographs, holds profound implications across\nmultiple domains, encompassing cross-modal face recognition, entertainment,\nart, media, among others. However, the production of high-quality sketches\nremains a formidable task, primarily due to the challenges and flaws associated\nwith three key factors: (1) the scarcity of artist-drawn data, (2) the\nconstraints imposed by limited style types, and (3) the deficiencies of\nprocessing input information in existing models. To address these difficulties,\nwe propose a lightweight end-to-end synthesis model that efficiently converts\nimages to corresponding multi-stylized sketches, obviating the necessity for\nany supplementary inputs (\\eg, 3D geometry). In this study, we overcome the\nissue of data insufficiency by incorporating semi-supervised learning into the\ntraining process. Additionally, we employ a feature extraction module and style\nembeddings to proficiently steer the generative transformer during the\niterative prediction of masked image tokens, thus achieving a continuous\nstylized output that retains facial features accurately in sketches. The\nextensive experiments demonstrate that our method consistently outperforms\nprevious algorithms across multiple benchmarks, exhibiting a discernible\ndisparity.", "paper_summary_zh": "\u4eba\u81c9\u7d20\u63cf\u5408\u6210 (FSS) \u6a21\u578b\u80fd\u5920\u6839\u64da\u7d66\u5b9a\u7684\u9762\u90e8\u7167\u7247\u7522\u751f\u7d20\u63cf\u8096\u50cf\uff0c\u5728\u591a\u500b\u9818\u57df\u5177\u6709\u6df1\u9060\u7684\u5f71\u97ff\uff0c\u5305\u62ec\u8de8\u6a21\u614b\u4eba\u81c9\u8b58\u5225\u3001\u5a1b\u6a02\u3001\u85dd\u8853\u3001\u5a92\u9ad4\u7b49\u3002\u7136\u800c\uff0c\u7522\u751f\u9ad8\u54c1\u8cea\u7d20\u63cf\u4ecd\u7136\u662f\u4e00\u9805\u8271\u9245\u7684\u4efb\u52d9\uff0c\u9019\u4e3b\u8981\u662f\u7531\u65bc\u8207\u4e09\u500b\u95dc\u9375\u56e0\u7d20\u76f8\u95dc\u7684\u6311\u6230\u548c\u7f3a\u9677\uff1a(1) \u85dd\u8853\u5bb6\u7e6a\u88fd\u6578\u64da\u7684\u7a00\u7f3a\u6027\uff0c(2) \u53d7\u9650\u6a23\u5f0f\u985e\u578b\u7684\u7d04\u675f\uff0c\u4ee5\u53ca (3) \u73fe\u6709\u6a21\u578b\u4e2d\u8655\u7406\u8f38\u5165\u4fe1\u606f\u7684\u7f3a\u9677\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u96e3\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u8f15\u91cf\u7d1a\u7aef\u5230\u7aef\u5408\u6210\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u5c07\u5716\u50cf\u8f49\u63db\u70ba\u5c0d\u61c9\u7684\u591a\u6a23\u5f0f\u7d20\u63cf\uff0c\u5f9e\u800c\u6d88\u9664\u4e86\u5c0d\u4efb\u4f55\u88dc\u5145\u8f38\u5165\uff08\u4f8b\u5982 3D \u5e7e\u4f55\uff09\u7684\u9700\u8981\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u901a\u904e\u5c07\u534a\u76e3\u7763\u5b78\u7fd2\u7d0d\u5165\u8a13\u7df4\u904e\u7a0b\u4f86\u514b\u670d\u6578\u64da\u4e0d\u8db3\u7684\u554f\u984c\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a1\u7528\u7279\u5fb5\u63d0\u53d6\u6a21\u7d44\u548c\u6a23\u5f0f\u5d4c\u5165\uff0c\u4ee5\u4fbf\u5728\u906e\u853d\u5716\u50cf\u6a19\u8a18\u7684\u8fed\u4ee3\u9810\u6e2c\u904e\u7a0b\u4e2d\u719f\u7df4\u5730\u5f15\u5c0e\u751f\u6210\u5f0f\u8f49\u63db\u5668\uff0c\u5f9e\u800c\u7372\u5f97\u9023\u7e8c\u7684\u6a23\u5f0f\u5316\u8f38\u51fa\uff0c\u6e96\u78ba\u5730\u4fdd\u7559\u7d20\u63cf\u4e2d\u7684\u9762\u90e8\u7279\u5fb5\u3002\u5927\u91cf\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u591a\u500b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u59cb\u7d42\u512a\u65bc\u5148\u524d\u7684\u6f14\u7b97\u6cd5\uff0c\u8868\u73fe\u51fa\u660e\u986f\u7684\u5dee\u7570\u3002", "author": "Bowen Sun et.al.", "authors": "Bowen Sun, Guo Lu, Shibao Zheng", "id": "2408.12400v1", "paper_url": "http://arxiv.org/abs/2408.12400v1", "repo": "null"}}