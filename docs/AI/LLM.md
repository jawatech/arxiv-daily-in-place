
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-23**|**PuzzleAvatar: Assembling 3D Avatars from Personal Albums**|Yuliang Xiu et.al.|[2405.14869v1](http://arxiv.org/abs/2405.14869v1)|null|
|**2024-05-23**|**Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**|Basile Van Hoorick et.al.|[2405.14868v1](http://arxiv.org/abs/2405.14868v1)|null|
|**2024-05-23**|**A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns**|Asaf Yehudai et.al.|[2405.14863v1](http://arxiv.org/abs/2405.14863v1)|null|
|**2024-05-23**|**Bitune: Bidirectional Instruction-Tuning**|Dawid J. Kopiczko et.al.|[2405.14862v1](http://arxiv.org/abs/2405.14862v1)|null|
|**2024-05-23**|**Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models**|Gen Li et.al.|[2405.14861v1](http://arxiv.org/abs/2405.14861v1)|null|
|**2024-05-23**|**Semantica: An Adaptable Image-Conditioned Diffusion Model**|Manoj Kumar et.al.|[2405.14857v1](http://arxiv.org/abs/2405.14857v1)|null|
|**2024-05-23**|**Privileged Sensing Scaffolds Reinforcement Learning**|Edward S. Hu et.al.|[2405.14853v1](http://arxiv.org/abs/2405.14853v1)|null|
|**2024-05-23**|**A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis**|Yue Yang et.al.|[2405.14839v1](http://arxiv.org/abs/2405.14839v1)|null|
|**2024-05-23**|**From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step**|Yuntian Deng et.al.|[2405.14838v1](http://arxiv.org/abs/2405.14838v1)|null|
|**2024-05-23**|**HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**|Bernal Jiménez Gutiérrez et.al.|[2405.14831v1](http://arxiv.org/abs/2405.14831v1)|null|
|**2024-05-23**|**PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher**|Dongjun Kim et.al.|[2405.14822v1](http://arxiv.org/abs/2405.14822v1)|null|
|**2024-05-23**|**Implicit Personalization in Language Models: A Systematic Study**|Zhijing Jin et.al.|[2405.14808v1](http://arxiv.org/abs/2405.14808v1)|null|
|**2024-05-23**|**Can LLMs Solve longer Math Word Problems Better?**|Xin Xu et.al.|[2405.14804v1](http://arxiv.org/abs/2405.14804v1)|null|
|**2024-05-23**|**Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions**|Mohamed Debbagh et.al.|[2405.14796v1](http://arxiv.org/abs/2405.14796v1)|null|
|**2024-05-23**|**Lessons from the Trenches on Reproducible Evaluation of Language Models**|Stella Biderman et.al.|[2405.14782v1](http://arxiv.org/abs/2405.14782v1)|null|
|**2024-05-23**|**Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning**|Nay Myat Min et.al.|[2405.14781v1](http://arxiv.org/abs/2405.14781v1)|null|
|**2024-05-23**|**Smart Bilingual Focused Crawling of Parallel Documents**|Cristian García-Romero et.al.|[2405.14779v1](http://arxiv.org/abs/2405.14779v1)|null|
|**2024-05-23**|**Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from Human Input**|Andi Peng et.al.|[2405.14769v1](http://arxiv.org/abs/2405.14769v1)|null|
|**2024-05-23**|**WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models**|Peng Wang et.al.|[2405.14768v1](http://arxiv.org/abs/2405.14768v1)|[link](https://github.com/zjunlp/easyedit)|
|**2024-05-23**|**FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models**|Hongyang Yang et.al.|[2405.14767v1](http://arxiv.org/abs/2405.14767v1)|[link](https://github.com/ai4finance-foundation/finrobot)|
|**2024-05-23**|**Evaluating Large Language Models for Public Health Classification and Extraction Tasks**|Joshua Harris et.al.|[2405.14766v1](http://arxiv.org/abs/2405.14766v1)|null|
|**2024-05-23**|**Axioms for AI Alignment from Human Feedback**|Luise Ge et.al.|[2405.14758v1](http://arxiv.org/abs/2405.14758v1)|null|
|**2024-05-23**|**A Transformer-Based Approach for Smart Invocation of Automatic Code Completion**|Aral de Moor et.al.|[2405.14753v1](http://arxiv.org/abs/2405.14753v1)|null|
|**2024-05-23**|**Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams**|Juyoung Yun et.al.|[2405.14750v1](http://arxiv.org/abs/2405.14750v1)|null|
|**2024-05-23**|**MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs**|Georgios Chatzigeorgakidis et.al.|[2405.14748v1](http://arxiv.org/abs/2405.14748v1)|null|
|**2024-05-23**|**TopoLogic: An Interpretable Pipeline for Lane Topology Reasoning on Driving Scenes**|Yanping Fu et.al.|[2405.14747v1](http://arxiv.org/abs/2405.14747v1)|null|
|**2024-05-23**|**SimPO: Simple Preference Optimization with a Reference-Free Reward**|Yu Meng et.al.|[2405.14734v1](http://arxiv.org/abs/2405.14734v1)|[link](https://github.com/princeton-nlp/simpo)|
|**2024-05-23**|**Intervention and Conditioning in Causal Bayesian Networks**|Sainyam Galhotra et.al.|[2405.14728v1](http://arxiv.org/abs/2405.14728v1)|null|
|**2024-05-23**|**CAPE: Context-Adaptive Positional Encoding for Length Extrapolation**|Chuanyang Zheng et.al.|[2405.14722v1](http://arxiv.org/abs/2405.14722v1)|[link](https://github.com/chuanyang-zheng/cape)|
|**2024-05-23**|**Decision-Focused Forecasting: Decision Losses for Multistage Optimisation**|Egon Peršak et.al.|[2405.14719v1](http://arxiv.org/abs/2405.14719v1)|null|
|**2024-05-23**|**HTN-Based Tutors: A New Intelligent Tutoring Framework Based on Hierarchical Task Networks**|Momin N. Siddiqui et.al.|[2405.14716v2](http://arxiv.org/abs/2405.14716v2)|null|
|**2024-05-23**|**Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models**|Young Kyun Jang et.al.|[2405.14715v1](http://arxiv.org/abs/2405.14715v1)|null|
|**2024-05-23**|**Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces**|Tommaso Calo et.al.|[2405.14713v1](http://arxiv.org/abs/2405.14713v1)|null|
|**2024-05-23**|**G3: An Effective and Adaptive Framework for Worldwide Geolocalization Using Large Multi-Modality Models**|Pengyue Jia et.al.|[2405.14702v1](http://arxiv.org/abs/2405.14702v1)|null|
|**2024-05-23**|**High Fidelity Scene Text Synthesis**|Yibin Wang et.al.|[2405.14701v1](http://arxiv.org/abs/2405.14701v1)|null|
|**2024-05-23**|**A Declarative System for Optimizing AI Workloads**|Chunwei Liu et.al.|[2405.14696v1](http://arxiv.org/abs/2405.14696v1)|null|
|**2024-05-23**|**CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System**|Qinghua Guan et.al.|[2405.14691v1](http://arxiv.org/abs/2405.14691v1)|null|
|**2024-05-23**|**Efficiency for Free: Ideal Data Are Transportable Representations**|Peng Sun et.al.|[2405.14669v1](http://arxiv.org/abs/2405.14669v1)|null|
|**2024-05-23**|**Fisher Flow Matching for Generative Modeling over Discrete Data**|Oscar Davis et.al.|[2405.14664v1](http://arxiv.org/abs/2405.14664v1)|null|
|**2024-05-23**|**Implicit In-context Learning**|Zhuowei Li et.al.|[2405.14660v1](http://arxiv.org/abs/2405.14660v1)|null|
|**2024-05-23**|**Efficient Medical Question Answering with Knowledge-Augmented Question Generation**|Julien Khlaut et.al.|[2405.14654v1](http://arxiv.org/abs/2405.14654v1)|null|
|**2024-05-23**|**Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models**|Yiming Chen et.al.|[2405.14646v1](http://arxiv.org/abs/2405.14646v1)|null|
|**2024-05-23**|**Reinforcement Learning for Fine-tuning Text-to-speech Diffusion Models**|Jingyi Chen et.al.|[2405.14632v1](http://arxiv.org/abs/2405.14632v1)|null|
|**2024-05-23**|**Calibrated Self-Rewarding Vision Language Models**|Yiyang Zhou et.al.|[2405.14622v1](http://arxiv.org/abs/2405.14622v1)|null|
|**2024-05-23**|**Explaining Multi-modal Large Language Models by Analyzing their Vision Perception**|Loris Giulivi et.al.|[2405.14612v1](http://arxiv.org/abs/2405.14612v1)|null|
|**2024-05-23**|**ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification**|Xuan-May Le et.al.|[2405.14608v1](http://arxiv.org/abs/2405.14608v1)|null|
|**2024-05-23**|**Logical Characterizations of Recurrent Graph Neural Networks with Reals and Floats**|Veeti Ahvonen et.al.|[2405.14606v1](http://arxiv.org/abs/2405.14606v1)|null|
|**2024-05-23**|**A Watermark for Low-entropy and Unbiased Generation in Large Language Models**|Minjia Mao et.al.|[2405.14604v1](http://arxiv.org/abs/2405.14604v1)|[link](https://github.com/djwei96/sta)|
|**2024-05-23**|**A FAIR and Free Prompt-based Research Assistant**|Mahsa Shamsabadi et.al.|[2405.14601v1](http://arxiv.org/abs/2405.14601v1)|null|
|**2024-05-23**|**Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs**|Qingyuan Li et.al.|[2405.14597v1](http://arxiv.org/abs/2405.14597v1)|null|
|**2024-05-23**|**Data Augmentation Techniques for Process Extraction from Scientific Publications**|Yuni Susanti et.al.|[2405.14594v1](http://arxiv.org/abs/2405.14594v1)|null|
|**2024-05-23**|**Base of RoPE Bounds Context Length**|Xin Men et.al.|[2405.14591v1](http://arxiv.org/abs/2405.14591v1)|null|
|**2024-05-23**|**Representation noising effectively prevents harmful fine-tuning on LLMs**|Domenic Rosati et.al.|[2405.14577v1](http://arxiv.org/abs/2405.14577v1)|null|
|**2024-05-23**|**AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents**|Christopher Rawles et.al.|[2405.14573v1](http://arxiv.org/abs/2405.14573v1)|null|
|**2024-05-23**|**PrivCirNet: Efficient Private Inference via Block Circulant Transformation**|Tianshi Xu et.al.|[2405.14569v1](http://arxiv.org/abs/2405.14569v1)|null|
|**2024-05-23**|**Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet**|Loris Giulivi et.al.|[2405.14563v1](http://arxiv.org/abs/2405.14563v1)|null|
|**2024-05-23**|**Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models**|Abhishek Kumar et.al.|[2405.14555v1](http://arxiv.org/abs/2405.14555v1)|null|
|**2024-05-23**|**UDKAG: Augmenting Large Vision-Language Models with Up-to-Date Knowledge**|Chuanhao Li et.al.|[2405.14554v1](http://arxiv.org/abs/2405.14554v1)|null|
|**2024-05-23**|**Regressor-free Molecule Generation to Support Drug Response Prediction**|Kun Li et.al.|[2405.14536v1](http://arxiv.org/abs/2405.14536v1)|null|
|**2024-05-23**|**Exploring Alignment in Shared Cross-lingual Spaces**|Basel Mousi et.al.|[2405.14535v1](http://arxiv.org/abs/2405.14535v1)|null|
|**2024-05-23**|**ArchesWeather: An efficient AI weather forecasting model at 1.5° resolution**|Guillaume Couairon et.al.|[2405.14527v1](http://arxiv.org/abs/2405.14527v1)|null|
|**2024-05-23**|**Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property**|Yuya Yoshikawa et.al.|[2405.14522v1](http://arxiv.org/abs/2405.14522v1)|null|
|**2024-05-23**|**Unchosen Experts Can Contribute Too: Unleashing MoE Models' Power by Self-Contrast**|Chufan Shi et.al.|[2405.14507v1](http://arxiv.org/abs/2405.14507v1)|null|
|**2024-05-23**|**SIAVC: Semi-Supervised Framework for Industrial Accident Video Classification**|Zuoyong Li et.al.|[2405.14506v1](http://arxiv.org/abs/2405.14506v1)|null|
|**2024-05-23**|**Explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing**|Jaime González-González et.al.|[2405.14505v1](http://arxiv.org/abs/2405.14505v1)|null|
|**2024-05-23**|**Enhanced Spatiotemporal Prediction Using Physical-guided And Frequency-enhanced Recurrent Neural Networks**|Xuanle Zhao et.al.|[2405.14504v1](http://arxiv.org/abs/2405.14504v1)|null|
|**2024-05-23**|**Impact of Non-Standard Unicode Characters on Security and Comprehension in Large Language Models**|Johan S Daniel et.al.|[2405.14490v1](http://arxiv.org/abs/2405.14490v1)|[link](https://github.com/raidedcluster/non-standard_unicode_jailbreaks)|
|**2024-05-23**|**MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability**|Yanrui Du et.al.|[2405.14488v1](http://arxiv.org/abs/2405.14488v1)|[link](https://github.com/dyr1/mogu)|
|**2024-05-23**|**RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models**|Xiangkun Hu et.al.|[2405.14486v1](http://arxiv.org/abs/2405.14486v1)|[link](https://github.com/amazon-science/refchecker)|
|**2024-05-23**|**SLIFER: Investigating Performance and Robustness of Malware Detection Pipelines**|Andrea Ponte et.al.|[2405.14478v1](http://arxiv.org/abs/2405.14478v1)|null|
|**2024-05-23**|**MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes**|Ruiyuan Gao et.al.|[2405.14475v1](http://arxiv.org/abs/2405.14475v1)|null|
|**2024-05-23**|**Poisson Variational Autoencoder**|Hadi Vafaii et.al.|[2405.14473v1](http://arxiv.org/abs/2405.14473v1)|null|
|**2024-05-23**|**Segformer++: Efficient Token-Merging Strategies for High-Resolution Semantic Segmentation**|Daniel Kienzle et.al.|[2405.14467v1](http://arxiv.org/abs/2405.14467v1)|null|
|**2024-05-23**|**Worldwide Federated Training of Language Models**|Alex Iacob et.al.|[2405.14446v1](http://arxiv.org/abs/2405.14446v1)|null|
|**2024-05-23**|**Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study**|Lena Schmidt et.al.|[2405.14445v1](http://arxiv.org/abs/2405.14445v1)|null|
|**2024-05-23**|**Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models**|Alejo Lopez-Avila et.al.|[2405.14437v1](http://arxiv.org/abs/2405.14437v1)|[link](https://github.com/vsuarezpaniagua/3-phase_finetuning)|
|**2024-05-23**|**RaFe: Ranking Feedback Improves Query Rewriting for RAG**|Shengyu Mao et.al.|[2405.14431v1](http://arxiv.org/abs/2405.14431v1)|null|
|**2024-05-23**|**PipeFusion: Displaced Patch Pipeline Parallelism for Inference of Diffusion Transformer Models**|Jiannan Wang et.al.|[2405.14430v1](http://arxiv.org/abs/2405.14430v1)|null|
|**2024-05-23**|**Mitigating Quantization Errors Due to Activation Spikes in GLU-Based LLMs**|Jaewoo Yang et.al.|[2405.14428v1](http://arxiv.org/abs/2405.14428v1)|[link](https://github.com/onnoo/activation-spikes)|
|**2024-05-23**|**Unraveling overoptimism and publication bias in ML-driven science**|Pouria Saidi et.al.|[2405.14422v1](http://arxiv.org/abs/2405.14422v1)|null|
|**2024-05-23**|**Proving Theorems Recursively**|Haiming Wang et.al.|[2405.14414v1](http://arxiv.org/abs/2405.14414v1)|null|
|**2024-05-23**|**Large Language Models for Explainable Decisions in Dynamic Digital Twins**|Nan Zhang et.al.|[2405.14411v1](http://arxiv.org/abs/2405.14411v1)|null|
|**2024-05-23**|**SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition with Jaccard Attentive Spiking Neural Network**|Weiyu Guo et.al.|[2405.14398v1](http://arxiv.org/abs/2405.14398v1)|null|
|**2024-05-23**|**Instruction Tuning With Loss Over Instructions**|Zhengyan Shi et.al.|[2405.14394v1](http://arxiv.org/abs/2405.14394v1)|null|
|**2024-05-23**|**Explainable Few-shot Knowledge Tracing**|Haoxuan Li et.al.|[2405.14391v1](http://arxiv.org/abs/2405.14391v1)|null|
|**2024-05-23**|**stl2vec: Semantic and Interpretable Vector Representation of Temporal Logic**|Gaia Saveri et.al.|[2405.14389v1](http://arxiv.org/abs/2405.14389v1)|null|
|**2024-05-23**|**Evaluation of the Programming Skills of Large Language Models**|Luc Bryan Heitz et.al.|[2405.14388v1](http://arxiv.org/abs/2405.14388v1)|null|
|**2024-05-23**|**Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis**|Aline Étienne et.al.|[2405.14385v1](http://arxiv.org/abs/2405.14385v1)|null|
|**2024-05-23**|**Reliable Trajectory Prediction and Uncertainty Quantification with Conditioned Diffusion Models**|Marion Neumeier et.al.|[2405.14384v1](http://arxiv.org/abs/2405.14384v1)|null|
|**2024-05-23**|**Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering**|Zhihua Wen et.al.|[2405.14383v1](http://arxiv.org/abs/2405.14383v1)|null|
|**2024-05-23**|**Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?**|Thomas Greatrix et.al.|[2405.14379v1](http://arxiv.org/abs/2405.14379v1)|null|
|**2024-05-23**|**CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization**|Zi Yang et.al.|[2405.14377v1](http://arxiv.org/abs/2405.14377v1)|null|
|**2024-05-23**|**MiniCache: KV Cache Compression in Depth Dimension for Large Language Models**|Akide Liu et.al.|[2405.14366v1](http://arxiv.org/abs/2405.14366v1)|null|
|**2024-05-23**|**JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models**|Kun Zhou et.al.|[2405.14365v1](http://arxiv.org/abs/2405.14365v1)|null|
|**2024-05-23**|**DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data**|Huajian Xin et.al.|[2405.14333v1](http://arxiv.org/abs/2405.14333v1)|null|
|**2024-05-23**|**LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision**|Mateusz Pach et.al.|[2405.14331v1](http://arxiv.org/abs/2405.14331v1)|null|
|**2024-05-23**|**Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI**|Guanxiong Luo et.al.|[2405.14327v2](http://arxiv.org/abs/2405.14327v2)|null|
|**2024-05-23**|**Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration**|Yang Zhang et.al.|[2405.14314v1](http://arxiv.org/abs/2405.14314v1)|null|
|**2024-05-23**|**Improving Gloss-free Sign Language Translation by Reducing Representation Density**|Jinhui Ye et.al.|[2405.14312v1](http://arxiv.org/abs/2405.14312v1)|null|
|**2024-05-23**|**Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient Transformer Models**|Yongxin Guo et.al.|[2405.14297v1](http://arxiv.org/abs/2405.14297v1)|null|

#### Abstracts
##### **PuzzleAvatar: Assembling 3D Avatars from Personal Albums**
2405.14869v1 by Yuliang Xiu, Yufei Ye, Zhen Liu, Dimitrios Tzionas, Michael J. Black

Generating personalized 3D avatars is crucial for AR/VR. However, recent
text-to-3D methods that generate avatars for celebrities or fictional
characters, struggle with everyday people. Methods for faithful reconstruction
typically require full-body images in controlled settings. What if a user could
just upload their personal "OOTD" (Outfit Of The Day) photo collection and get
a faithful avatar in return? The challenge is that such casual photo
collections contain diverse poses, challenging viewpoints, cropped views, and
occlusion (albeit with a consistent outfit, accessories and hairstyle). We
address this novel "Album2Human" task by developing PuzzleAvatar, a novel model
that generates a faithful 3D avatar (in a canonical pose) from a personal OOTD
album, while bypassing the challenging estimation of body and camera pose. To
this end, we fine-tune a foundational vision-language model (VLM) on such
photos, encoding the appearance, identity, garments, hairstyles, and
accessories of a person into (separate) learned tokens and instilling these
cues into the VLM. In effect, we exploit the learned tokens as "puzzle pieces"
from which we assemble a faithful, personalized 3D avatar. Importantly, we can
customize avatars by simply inter-changing tokens. As a benchmark for this new
task, we collect a new dataset, called PuzzleIOI, with 41 subjects in a total
of nearly 1K OOTD configurations, in challenging partial photos with paired
ground-truth 3D bodies. Evaluation shows that PuzzleAvatar not only has high
reconstruction accuracy, outperforming TeCH and MVDreamBooth, but also a unique
scalability to album photos, and strong robustness. Our model and data will be
public.

摘要：<paragraph>生成個性化 3D 頭像對於 AR/VR 至關重要。然而，最近的文字轉 3D 方法可為名人或虛構角色生成頭像，但在一般人身上卻有困難。忠實重建的方法通常需要在受控環境中拍攝全身影像。如果使用者只需上傳他們的個人「OOTD」（每日穿搭）照片集，就能換取一個忠實的頭像，那該有多好？挑戰在於此類休閒照片集包含姿勢多樣、視角有挑戰性、裁切的視角和遮擋（儘管服裝、配件和髮型一致）。我們透過開發 PuzzleAvatar 來處理這個新穎的「相簿轉人類」任務，這是一個新穎的模型，可從個人的 OOTD 相簿生成一個忠實的 3D 頭像（採用標準姿勢），同時繞過身體和相機姿勢的困難估計。為此，我們微調了此類照片上的基礎視覺語言模型 (VLM)，將一個人的外觀、身分、服裝、髮型和配件編碼成（分開的）學習代幣，並將這些線索灌輸到 VLM 中。實際上，我們利用學習到的代幣作為「拼圖碎片」，從中組裝一個忠實的個性化 3D 頭像。重要的是，我們可以透過簡單地交換代幣來自訂頭像。作為這個新任務的基準，我們收集了一個名為 PuzzleIOI 的新資料集，其中包含 41 個主體，總共近 1K 個 OOTD 組態，採用具有配對地面實況 3D 身體的具挑戰性部分照片。評估顯示，PuzzleAvatar 不僅具有高重建準確度，優於 TeCH 和 MVDreamBooth，而且還具有獨特的相簿照片擴充性，以及強大的穩健性。我們的模型和資料將公開。</paragraph>

##### **Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis**
2405.14868v1 by Basile Van Hoorick, Rundi Wu, Ege Ozguroglu, Kyle Sargent, Ruoshi Liu, Pavel Tokmakov, Achal Dave, Changxi Zheng, Carl Vondrick

Accurate reconstruction of complex dynamic scenes from just a single
viewpoint continues to be a challenging task in computer vision. Current
dynamic novel view synthesis methods typically require videos from many
different camera viewpoints, necessitating careful recording setups, and
significantly restricting their utility in the wild as well as in terms of
embodied AI applications. In this paper, we propose $\textbf{GCD}$, a
controllable monocular dynamic view synthesis pipeline that leverages
large-scale diffusion priors to, given a video of any scene, generate a
synchronous video from any other chosen perspective, conditioned on a set of
relative camera pose parameters. Our model does not require depth as input, and
does not explicitly model 3D scene geometry, instead performing end-to-end
video-to-video translation in order to achieve its goal efficiently. Despite
being trained on synthetic multi-view video data only, zero-shot real-world
generalization experiments show promising results in multiple domains,
including robotics, object permanence, and driving environments. We believe our
framework can potentially unlock powerful applications in rich dynamic scene
understanding, perception for robotics, and interactive 3D video viewing
experiences for virtual reality.

摘要：僅從單一視點準確重建複雜的動態場景，在電腦視覺中持續成為一項艱難的任務。目前的動態新視圖合成方法通常需要來自許多不同相機視點的影片，這需要仔細的錄製設定，並顯著限制它們在野外以及具身 AI 應用方面的效用。在本文中，我們提出 $\textbf{GCD}$，一種可控的單眼動態視圖合成管道，它利用大規模擴散先驗，在給定任何場景影片的情況下，根據一組相對相機姿勢參數生成來自任何其他選擇視角的同步影片。我們的模型不需要深度作為輸入，也不明確建模 3D 場景幾何，而是執行端對端的影片到影片轉換，以有效達成其目標。儘管僅在合成多視圖影片資料上訓練，但零次學習真實世界概化實驗在多個領域顯示出有希望的結果，包括機器人技術、物體恆常性和駕駛環境。我們相信我們的架構有可能在豐富的動態場景理解、機器人感知以及虛擬實境互動式 3D 影片觀看體驗中開啟強大的應用程式。

##### **A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns**
2405.14863v1 by Asaf Yehudai, Taelin Karidi, Gabriel Stanovsky, Ariel Goldstein, Omri Abend

Cross-domain alignment refers to the task of mapping a concept from one
domain to another. For example, ``If a \textit{doctor} were a \textit{color},
what color would it be?''. This seemingly peculiar task is designed to
investigate how people represent concrete and abstract concepts through their
mappings between categories and their reasoning processes over those mappings.
In this paper, we adapt this task from cognitive science to evaluate the
conceptualization and reasoning abilities of large language models (LLMs)
through a behavioral study. We examine several LLMs by prompting them with a
cross-domain mapping task and analyzing their responses at both the population
and individual levels. Additionally, we assess the models' ability to reason
about their predictions by analyzing and categorizing their explanations for
these mappings. The results reveal several similarities between humans' and
models' mappings and explanations, suggesting that models represent concepts
similarly to humans. This similarity is evident not only in the model
representation but also in their behavior. Furthermore, the models mostly
provide valid explanations and deploy reasoning paths that are similar to those
of humans.

摘要：跨領域比對是指將一個領域的概念對應到另一個領域的任務。例如：「如果『醫生』是一種『顏色』，它會是什麼顏色？」。這個看似奇怪的任務旨在探討人們如何透過類別之間的對應和對這些對應的推理過程，來表示具體和抽象的概念。在本文中，我們從認知科學中改編了這個任務，透過行為研究來評估大型語言模型 (LLM) 的概念化和推理能力。我們透過提示 LLM 進行跨領域比對任務，並在族群和個人層面分析他們的回應來檢視多個 LLM。此外，我們透過分析和分類這些比對的解釋，來評估模型推理其預測的能力。結果顯示人類和模型的比對和解釋之間有許多相似之處，這表示模型以類似於人類的方式來表示概念。這種相似性不僅表現在模型的表示上，也表現在他們的行為上。此外，這些模型大多提供有效的解釋，並採用類似於人類的推理路徑。

##### **Bitune: Bidirectional Instruction-Tuning**
2405.14862v1 by Dawid J. Kopiczko, Tijmen Blankevoort, Yuki M. Asano

We introduce Bitune, a method that improves instruction-tuning of pretrained
decoder-only large language models, leading to consistent gains on downstream
tasks. Bitune applies both causal and bidirectional attention to the prompt, to
obtain a better representation of the query or instruction. We realize this by
introducing two sets of parameters, for which we apply parameter-efficient
finetuning techniques. These causal and bidirectional features are then
combined into a weighted average with trainable coefficients, which is
subsequently used to generate new tokens. We demonstrate significant
improvements in zero-shot performance on commonsense reasoning, arithmetic, and
language understanding tasks, while extensive ablation studies validate the
role of each component and demonstrate the method's agnosticism to different
PEFT techniques.

摘要：我們引入了 Bitune，這是一種改善預先訓練的僅解碼器大型語言模型的指令微調的方法，從而對下游任務產生持續的收益。Bitune 對提示應用因果和雙向注意，以獲得查詢或指令的更好表示。我們通過引入兩組參數來實現這一點，我們對其應用參數高效的微調技術。然後將這些因果和雙向特徵與可訓練係數組合成加權平均值，隨後用於生成新的符號。我們展示了常識推理、算術和語言理解任務的零次學習效能的顯著改進，而廣泛的消融研究驗證了每個組成部分的作用，並證明了該方法對不同的 PEFT 技術的不可知論。

##### **Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models**
2405.14861v1 by Gen Li, Yuling Yan

This paper investigates score-based diffusion models when the underlying
target distribution is concentrated on or near low-dimensional manifolds within
the higher-dimensional space in which they formally reside, a common
characteristic of natural image distributions. Despite previous efforts to
understand the data generation process of diffusion models, existing
theoretical support remains highly suboptimal in the presence of
low-dimensional structure, which we strengthen in this paper. For the popular
Denoising Diffusion Probabilistic Model (DDPM), we find that the dependency of
the error incurred within each denoising step on the ambient dimension $d$ is
in general unavoidable. We further identify a unique design of coefficients
that yields a converges rate at the order of $O(k^{2}/\sqrt{T})$ (up to log
factors), where $k$ is the intrinsic dimension of the target distribution and
$T$ is the number of steps. This represents the first theoretical demonstration
that the DDPM sampler can adapt to unknown low-dimensional structures in the
target distribution, highlighting the critical importance of coefficient
design. All of this is achieved by a novel set of analysis tools that
characterize the algorithmic dynamics in a more deterministic manner.

摘要：本文探討基於分數的擴散模型，當基礎目標分佈集中在高維空間中低維流形上或其附近時，這是自然影像分佈的常見特徵。儘管之前已努力了解擴散模型的資料產生過程，但現有的理論支持在存在低維結構的情況下仍然極為次優，我們在本文中加強了這一點。對於流行的去噪擴散機率模型 (DDPM)，我們發現每個去噪步驟中產生的誤差對環境維度 $d$ 的依賴性通常是不可避免的。我們進一步找出一個獨特的係數設計，其收斂速度為 $O(k^{2}/\sqrt{T})$ 的階數（最多為對數因子），其中 $k$ 為目標分佈的本質維度，而 $T$ 為步驟數。這是第一個理論證明，表明 DDPM 採樣器可以適應目標分佈中未知的低維結構，突顯了係數設計至關重要的重要性。所有這些都是通過一組新穎的分析工具實現的，這些工具以更確定性的方式描述演算法動態。

##### **Semantica: An Adaptable Image-Conditioned Diffusion Model**
2405.14857v1 by Manoj Kumar, Neil Houlsby, Emiel Hoogeboom

We investigate the task of adapting image generative models to different
datasets without finetuneing. To this end, we introduce Semantica, an
image-conditioned diffusion model capable of generating images based on the
semantics of a conditioning image. Semantica is trained exclusively on
web-scale image pairs, that is it receives a random image from a webpage as
conditional input and models another random image from the same webpage. Our
experiments highlight the expressivity of pretrained image encoders and
necessity of semantic-based data filtering in achieving high-quality image
generation. Once trained, it can adaptively generate new images from a dataset
by simply using images from that dataset as input. We study the transfer
properties of Semantica on ImageNet, LSUN Churches, LSUN Bedroom and SUN397.

摘要：我們研究了在不微調的情況下將影像生成模型調整至不同資料集的任務。為此，我們引入了 Semantica，一種基於影像條件的擴散模型，能夠根據條件影像的語義來生成影像。Semantica 專門在網路規模的影像對上受訓，也就是說它接收來自網頁的隨機影像作為條件輸入，並對來自同一個網頁的另一個隨機影像進行建模。我們的實驗突出了預訓練影像編碼器的表現力，以及在達成高品質影像生成中語義資料過濾的必要性。受訓完成後，它可以透過單純使用來自資料集的影像作為輸入，自適應地從資料集中產生新的影像。我們研究了 Semantica 在 ImageNet、LSUN Churches、LSUN Bedroom 和 SUN397 上的轉移特性。

##### **Privileged Sensing Scaffolds Reinforcement Learning**
2405.14853v1 by Edward S. Hu, James Springer, Oleh Rybkin, Dinesh Jayaraman

We need to look at our shoelaces as we first learn to tie them but having
mastered this skill, can do it from touch alone. We call this phenomenon
"sensory scaffolding": observation streams that are not needed by a master
might yet aid a novice learner. We consider such sensory scaffolding setups for
training artificial agents. For example, a robot arm may need to be deployed
with just a low-cost, robust, general-purpose camera; yet its performance may
improve by having privileged training-time-only access to informative albeit
expensive and unwieldy motion capture rigs or fragile tactile sensors. For
these settings, we propose "Scaffolder", a reinforcement learning approach
which effectively exploits privileged sensing in critics, world models, reward
estimators, and other such auxiliary components that are only used at training
time, to improve the target policy. For evaluating sensory scaffolding agents,
we design a new "S3" suite of ten diverse simulated robotic tasks that explore
a wide range of practical sensor setups. Agents must use privileged camera
sensing to train blind hurdlers, privileged active visual perception to help
robot arms overcome visual occlusions, privileged touch sensors to train robot
hands, and more. Scaffolder easily outperforms relevant prior baselines and
frequently performs comparably even to policies that have test-time access to
the privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/

摘要：我們在學習綁鞋帶時需要看著鞋帶，但一旦掌握了這項技能，就可以只靠觸覺就能完成。我們稱這種現象為「感官鷹架」：對大師來說不需要的觀察流，卻可能有助於新手學習。我們考慮將這種感官鷹架設置用於訓練人工代理。例如，機器人手臂可能只需要配備一個低成本、強固、通用的相機；然而，如果在訓練期間獨家取得昂貴且笨重的動作捕捉裝置或脆弱的觸覺感測器的存取權，其性能可能會有所提升。對於這些設定，我們提出「鷹架」，一種強化學習方法，有效利用批評者、世界模型、獎勵估計器和其他此類輔助元件中的特權感測，這些元件只在訓練期間使用，以改善目標策略。為了評估感官鷹架代理，我們設計了一套名為「S3」的新模擬機器人任務套件，其中包含十項不同的任務，探討了廣泛的實用感測器設置。代理必須使用特權相機感測器來訓練盲人跨欄者，使用特權主動視覺感知來幫助機器人手臂克服視覺遮擋，使用特權觸覺感測器來訓練機器人手，等等。鷹架輕鬆超越了相關的先前基準，而且即使對於在測試時可以存取特權感測器的策略，其表現也經常相當。網站：https://penn-pal-lab.github.io/scaffolder/

##### **A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis**
2405.14839v1 by Yue Yang, Mona Gandhi, Yufei Wang, Yifan Wu, Michael S. Yao, Chris Callison-Burch, James C. Gee, Mark Yatskar

While deep networks have achieved broad success in analyzing natural images,
when applied to medical scans, they often fail in unexcepted situations. We
investigate this challenge and focus on model sensitivity to domain shifts,
such as data sampled from different hospitals or data confounded by demographic
variables such as sex, race, etc, in the context of chest X-rays and skin
lesion images. A key finding we show empirically is that existing visual
backbones lack an appropriate prior from the architecture for reliable
generalization in these settings. Taking inspiration from medical training, we
propose giving deep networks a prior grounded in explicit medical knowledge
communicated in natural language. To this end, we introduce Knowledge-enhanced
Bottlenecks (KnoBo), a class of concept bottleneck models that incorporates
knowledge priors that constrain it to reason with clinically relevant factors
found in medical textbooks or PubMed. KnoBo uses retrieval-augmented language
models to design an appropriate concept space paired with an automatic training
procedure for recognizing the concept. We evaluate different resources of
knowledge and recognition architectures on a broad range of domain shifts
across 20 datasets. In our comprehensive evaluation with two imaging
modalities, KnoBo outperforms fine-tuned models on confounded datasets by 32.4%
on average. Finally, evaluations reveal that PubMed is a promising resource for
making medical models less sensitive to domain shift, outperforming other
resources on both diversity of information and final prediction performance.

摘要：儘管深度網路在分析自然影像方面已獲得廣泛成功，但當應用於醫學影像時，它們常常在意外的情況下失效。我們探討這個挑戰，並專注於模型對領域轉移的敏感性，例如從不同醫院取樣的資料，或在胸部 X 光和皮膚病灶影像中，因人口統計變數（例如性別、種族等）而混淆的資料。我們實證顯示的一個關鍵發現是，現有的視覺主幹缺乏來自架構的適當先驗，無法在這些設定中進行可靠的概化。從醫學訓練中汲取靈感，我們建議為深度網路提供一個植基於自然語言中傳達的明確醫學知識的先驗。為此，我們引入了知識增強瓶頸（KnoBo），一種概念瓶頸模型類別，它結合了知識先驗，約束其根據醫學教科書或 PubMed 中發現的臨床相關因素進行推理。KnoBo 使用檢索增強語言模型來設計一個適當的概念空間，並搭配一個自動訓練程序來識別概念。我們在 20 個資料集的廣泛領域轉移中評估了不同的知識和識別架構資源。在我們對兩種影像模式進行的全面評估中，KnoBo 在混淆的資料集上平均優於微調模型 32.4%。最後，評估顯示 PubMed 是讓醫學模型對領域轉移不那麼敏感的有希望資源，在資訊的多樣性和最終預測效能方面都優於其他資源。

##### **From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step**
2405.14838v1 by Yuntian Deng, Yejin Choi, Stuart Shieber

When leveraging language models for reasoning tasks, generating explicit
chain-of-thought (CoT) steps often proves essential for achieving high accuracy
in final outputs. In this paper, we investigate if models can be taught to
internalize these CoT steps. To this end, we propose a simple yet effective
method for internalizing CoT steps: starting with a model trained for explicit
CoT reasoning, we gradually remove the intermediate steps and finetune the
model. This process allows the model to internalize the intermediate reasoning
steps, thus simplifying the reasoning process while maintaining high
performance. Our approach enables a GPT-2 Small model to solve 9-by-9
multiplication with up to 99% accuracy, whereas standard training cannot solve
beyond 4-by-4 multiplication. Furthermore, our method proves effective on
larger language models, such as Mistral 7B, achieving over 50% accuracy on
GSM8K without producing any intermediate steps.

摘要：在利用語言模型進行推理任務時，產生明確的思考鏈（CoT）步驟通常被證明對於在最終輸出中實現高準確度至關重要。在本文中，我們探討模型是否可以被教授內化這些 CoT 步驟。為此，我們提出了一種簡單但有效的內化 CoT 步驟的方法：從一個訓練用於明確 CoT 推理的模型開始，我們逐漸移除中間步驟並微調模型。此過程允許模型內化中間推理步驟，從而簡化推理過程，同時保持高性能。我們的做法使 GPT-2 Small 模型能夠以高達 99% 的準確度解決 9x9 乘法，而標準訓練無法解決 4x4 乘法以上的問題。此外，我們的做法被證明對大型語言模型（例如 Mistral 7B）有效，在 GSM8K 上實現了 50% 以上的準確度，而沒有產生任何中間步驟。

##### **HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**
2405.14831v1 by Bernal Jiménez Gutiérrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, Yu Su

In order to thrive in hostile and ever-changing natural environments,
mammalian brains evolved to store large amounts of knowledge about the world
and continually integrate new information while avoiding catastrophic
forgetting. Despite the impressive accomplishments, large language models
(LLMs), even with retrieval-augmented generation (RAG), still struggle to
efficiently and effectively integrate a large amount of new experiences after
pre-training. In this work, we introduce HippoRAG, a novel retrieval framework
inspired by the hippocampal indexing theory of human long-term memory to enable
deeper and more efficient knowledge integration over new experiences. HippoRAG
synergistically orchestrates LLMs, knowledge graphs, and the Personalized
PageRank algorithm to mimic the different roles of neocortex and hippocampus in
human memory. We compare HippoRAG with existing RAG methods on multi-hop
question answering and show that our method outperforms the state-of-the-art
methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves
comparable or better performance than iterative retrieval like IRCoT while
being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into
IRCoT brings further substantial gains. Finally, we show that our method can
tackle new types of scenarios that are out of reach of existing methods. Code
and data are available at https://github.com/OSU-NLP-Group/HippoRAG.

摘要：為了在惡劣且瞬息萬變的自然環境中茁壯成長，
哺乳動物的大腦演化出儲存大量關於世界知識的能力，
並在避免災難性遺忘的同時持續整合新資訊。儘管有令人印象深刻的成就，
大型語言模型 (LLM)，即使具備檢索增強生成 (RAG)，仍難以
在預訓練後有效率且有效地整合大量新經驗。在這項工作中，我們介紹 HippoRAG，一種創新的檢索架構，
靈感來自人類長期記憶的海馬迴索引理論，以在新的經驗中實現更深入且更有效率的知識整合。HippoRAG
協同編排 LLM、知識圖譜和個人化 PageRank 演算法，以模擬人類記憶中新皮質和海馬迴的不同角色。我們將 HippoRAG 與現有的 RAG 方法進行多跳式問答比較，並展示我們的
方法顯著優於最先進的方法，最多達 20%。使用 HippoRAG 的單步檢索可實現
與 IRCoT 等迭代檢索相當或更好的效能，同時成本降低 10-30 倍，速度加快 6-13 倍，將 HippoRAG 整合到
IRCoT 中可帶來進一步的實質收益。最後，我們展示我們的
方法可以處理現有方法無法達到的新型態場景。程式碼
和資料可在 https://github.com/OSU-NLP-Group/HippoRAG 取得。

##### **PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher**
2405.14822v1 by Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, Stefano Ermon

To accelerate sampling, diffusion models (DMs) are often distilled into
generators that directly map noise to data in a single step. In this approach,
the resolution of the generator is fundamentally limited by that of the teacher
DM. To overcome this limitation, we propose Progressive Growing of Diffusion
Autoencoder (PaGoDA), a technique to progressively grow the resolution of the
generator beyond that of the original teacher DM. Our key insight is that a
pre-trained, low-resolution DM can be used to deterministically encode
high-resolution data to a structured latent space by solving the PF-ODE forward
in time (data-to-noise), starting from an appropriately down-sampled image.
Using this frozen encoder in an auto-encoder framework, we train a decoder by
progressively growing its resolution. From the nature of progressively growing
decoder, PaGoDA avoids re-training teacher/student models when we upsample the
student model, making the whole training pipeline much cheaper. In experiments,
we used our progressively growing decoder to upsample from the pre-trained
model's 64x64 resolution to generate 512x512 samples, achieving 2x faster
inference compared to single-step distilled Stable Diffusion like LCM. PaGoDA
also achieved state-of-the-art FIDs on ImageNet across all resolutions from
64x64 to 512x512. Additionally, we demonstrated PaGoDA's effectiveness in
solving inverse problems and enabling controllable generation.

摘要：<paragraph>為了加速取樣，擴散模型 (DM) 經常被提煉成生成器，在單一步驟中直接將雜訊對應到資料。在這種方法中，生成器的解析度基本上受到教師 DM 的限制。為了克服這個限制，我們提出擴散自編碼器的漸進式成長 (PaGoDA)，這是一種技術，可以漸進式地成長生成器的解析度，超越原始教師 DM。我們的關鍵見解是，預先訓練的低解析度 DM 可以用來確定性地將高解析度資料編碼到結構化的潛在空間，方法是從適當地向下取樣的影像開始，隨著時間 (資料到雜訊) 解決 PF-ODE 正向。在自動編碼器架構中使用這個凍結編碼器，我們透過漸進式地成長它的解析度來訓練一個解碼器。從漸進式成長解碼器的本質來看，PaGoDA 在我們上採樣學生模型時避免重新訓練教師/學生模型，讓整個訓練流程便宜許多。在實驗中，我們使用漸進式成長解碼器從預先訓練模型的 64x64 解析度上採樣，以產生 512x512 樣本，與 LCM 等單步驟提煉的 Stable Diffusion 相比，推論速度快了 2 倍。PaGoDA 也在從 64x64 到 512x512 的所有解析度上，在 ImageNet 達到最先進的 FID。此外，我們展示了 PaGoDA 在解決反問題和啟用可控生成方面的效能。</paragraph>

##### **Implicit Personalization in Language Models: A Systematic Study**
2405.14808v1 by Zhijing Jin, Nils Heil, Jiarui Liu, Shehzaad Dhuliawala, Yahang Qi, Bernhard Schölkopf, Rada Mihalcea, Mrinmaya Sachan

Implicit Personalization (IP) is a phenomenon of language models inferring a
user's background from the implicit cues in the input prompts and tailoring the
response based on this inference. While previous work has touched upon various
instances of this problem, there lacks a unified framework to study this
behavior. This work systematically studies IP through a rigorous mathematical
formulation, a multi-perspective moral reasoning framework, and a set of case
studies. Our theoretical foundation for IP relies on a structural causal model
and introduces a novel method, indirect intervention, to estimate the causal
effect of a mediator variable that cannot be directly intervened upon. Beyond
the technical approach, we also introduce a set of moral reasoning principles
based on three schools of moral philosophy to study when IP may or may not be
ethically appropriate. Equipped with both mathematical and ethical insights, we
present three diverse case studies illustrating the varied nature of the IP
problem and offer recommendations for future research. Our code and data are at
https://github.com/jiarui-liu/IP.

摘要：隱含個性化 (IP) 是語言模型從輸入提示中的隱含線索推斷出使用者的背景，並根據此推論調整回應的一種現象。儘管先前的工作已觸及此問題的各種情況，但仍缺乏統一的架構來研究此行為。這項工作透過嚴謹的數學公式、多觀點的道德推理架構和一組案例研究，系統性地研究 IP。我們對 IP 的理論基礎依賴於結構因果模型，並引入一種新方法，間接介入，來評估無法直接介入的中介變數的因果關係。除了技術方法之外，我們還根據三種道德哲學流派引入了一組道德推理原則，以研究 IP 何時可能或可能不適當。具備數學和道德見解後，我們提出了三個不同的案例研究，說明 IP 問題的性質多樣，並提出未來研究的建議。我們的程式碼和資料在 https://github.com/jiarui-liu/IP。

##### **Can LLMs Solve longer Math Word Problems Better?**
2405.14804v1 by Xin Xu, Tong Xiao, Zitong Chao, Zhenya Huang, Can Yang, Yang Wang

Math Word Problems (MWPs) are crucial for evaluating the capability of Large
Language Models (LLMs), with current research primarily focusing on questions
with concise contexts. However, as real-world math problems often involve
complex circumstances, LLMs' ability to solve long MWPs is vital for their
applications in these scenarios, yet remains under-explored. This study
pioneers the exploration of Context Length Generalizability (CoLeG), the
ability of LLMs to solve long MWPs. We introduce Extended Grade-School Math
(E-GSM), a collection of MWPs with lengthy narratives. Two novel metrics are
proposed to assess the efficacy and resilience of LLMs in solving these
problems. Our examination of existing zero-shot prompting techniques and both
proprietary and open-source LLMs reveals a general deficiency in CoLeG. To
alleviate these challenges, we propose distinct approaches for different
categories of LLMs. For proprietary LLMs, a new instructional prompt is
proposed to mitigate the influence of long context. For open-source LLMs, a new
data augmentation task is developed to improve CoLeG. Our comprehensive results
demonstrate the effectiveness of our proposed methods, showing not only
improved performance on E-GSM but also generalizability across several other
MWP benchmarks. Our findings pave the way for future research in employing LLMs
for complex, real-world applications, offering practical solutions to current
limitations and opening avenues for further exploration of model
generalizability and training methodologies.

摘要：數學文字題 (MWP) 對於評估大型語言模型 (LLM) 的能力至關重要，目前的
研究主要集中在具有簡潔背景的問題上。然而，由於現實世界的數學問題通常涉及
複雜的情況，LLM 解決長 MWP 的能力對於它們在這些場景中的應用至關重要，但仍
未得到充分探索。本研究開創了對語境長度泛化性 (CoLeG) 的探索，即 LLM 解決
長 MWP 的能力。我們引入了擴展小學數學 (E-GSM)，這是一個具有冗長敘述的 MWP
集合。提出了兩個新穎的指標來評估 LLM 在解決這些問題中的功效和韌性。我們
對現有的零次提示技術和專有和開源 LLM 的檢查揭示了 CoLeG 的普遍缺陷。為了
緩解這些挑戰，我們針對不同類別的 LLM 提出不同的方法。對於專有 LLM，提議
了一個新的教學提示來減輕長語境的影響。對於開源 LLM，開發了一個新的數據增
強任務來改進 CoLeG。我們的綜合結果證明了我們提出的方法的有效性，不僅展示
了 E-GSM 上的改進性能，而且在其他幾個 MWP 基準上也具有普遍性。我們的發現
為未來採用 LLM 進行複雜的現實世界應用鋪平了道路，為當前的限制提供了實際
解決方案，並為進一步探索模型泛化性和訓練方法開闢了途徑。

##### **Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions**
2405.14796v1 by Mohamed Debbagh, Yixue Liu, Zhouzhou Zheng, Xintong Jiang, Shangpeng Sun, Mark Lefsrud

A plant growth simulation can be characterized as a reconstructed visual
representation of a plant or plant system. The phenotypic characteristics and
plant structures are controlled by the scene environment and other contextual
attributes. Considering the temporal dependencies and compounding effects of
various factors on growth trajectories, we formulate a probabilistic approach
to the simulation task by solving a frame synthesis and pattern recognition
problem. We introduce a Sequence-Informed Plant Growth Simulation framework
(SI-PGS) that employs a conditional generative model to implicitly learn a
distribution of possible plant representations within a dynamic scene from a
fusion of low dimensional temporal sensor and context data. Methods such as
controlled latent sampling and recurrent output connections are used to improve
coherence in plant structures between frames of predictions. In this work, we
demonstrate that SI-PGS is able to capture temporal dependencies and
continuously generate realistic frames of a plant scene.

摘要：植物生長模擬可以特徵化為植物或植物系統的重建視覺表示。表型特徵和植物結構受場景環境和其它情境屬性控制。考慮到時間依賴性和各種因素對生長軌跡的複合效應，我們透過解決幀合成和模式識別問題，為模擬任務制定一個機率方法。我們引入一個序列資訊植物生長模擬架構 (SI-PGS)，它採用條件生成模型來隱式學習一個動態場景中可能植物表示的分配，來自低維度時間感測器和情境資料的融合。受控潛在抽樣和遞迴輸出連接等方法用於改善預測幀之間植物結構的相干性。在這項工作中，我們展示 SI-PGS 能夠擷取時間依賴性，並持續產生植物場景的逼真幀。

##### **Lessons from the Trenches on Reproducible Evaluation of Language Models**
2405.14782v1 by Stella Biderman, Hailey Schoelkopf, Lintang Sutawika, Leo Gao, Jonathan Tow, Baber Abbasi, Alham Fikri Aji, Pawan Sasanka Ammanamanchi, Sidney Black, Jordan Clive, Anthony DiPofi, Julen Etxaniz, Benjamin Fattori, Jessica Zosa Forde, Charles Foster, Mimansa Jaiswal, Wilson Y. Lee, Haonan Li, Charles Lovering, Niklas Muennighoff, Ellie Pavlick, Jason Phang, Aviya Skowron, Samson Tan, Xiangru Tang, Kevin A. Wang, Genta Indra Winata, François Yvon, Andy Zou

Effective evaluation of language models remains an open challenge in NLP.
Researchers and engineers face methodological issues such as the sensitivity of
models to evaluation setup, difficulty of proper comparisons across methods,
and the lack of reproducibility and transparency. In this paper we draw on
three years of experience in evaluating large language models to provide
guidance and lessons for researchers. First, we provide an overview of common
challenges faced in language model evaluation. Second, we delineate best
practices for addressing or lessening the impact of these challenges on
research. Third, we present the Language Model Evaluation Harness (lm-eval): an
open source library for independent, reproducible, and extensible evaluation of
language models that seeks to address these issues. We describe the features of
the library as well as case studies in which the library has been used to
alleviate these methodological concerns.

摘要：語言模型的有效評估在 NLP 中仍然是一個公開的挑戰。研究人員和工程師面臨方法論問題，例如模型對評估設定的敏感性、跨方法適當比較難度，以及缺乏可複製性和透明性。在本文中，我們利用三年來評估大型語言模型的經驗，為研究人員提供指導和經驗教訓。首先，我們概述了語言模型評估中面臨的常見挑戰。其次，我們描述了解決或減輕這些挑戰對研究影響的最佳實務。第三，我們展示了語言模型評估工具 (lm-eval)：一個用於獨立、可複製且可擴充語言模型評估的開源程式庫，旨在解決這些問題。我們描述了程式庫的功能，以及程式庫用於緩解這些方法論問題的案例研究。

##### **Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning**
2405.14781v1 by Nay Myat Min, Long H. Pham, Jun Sun

The application of deep neural network models in various security-critical
applications has raised significant security concerns, particularly the risk of
backdoor attacks. Neural backdoors pose a serious security threat as they allow
attackers to maliciously alter model behavior. While many defenses have been
explored, existing approaches are often bounded by model-specific constraints,
or necessitate complex alterations to the training process, or fall short
against diverse backdoor attacks. In this work, we introduce a novel method for
comprehensive and effective elimination of backdoors, called ULRL (short for
UnLearn and ReLearn for backdoor removal). ULRL requires only a small set of
clean samples and works effectively against all kinds of backdoors. It first
applies unlearning for identifying suspicious neurons and then targeted neural
weight tuning for backdoor mitigation (i.e., by promoting significant weight
deviation on the suspicious neurons). Evaluated against 12 different types of
backdoors, ULRL is shown to significantly outperform state-of-the-art methods
in eliminating backdoors whilst preserving the model utility.

摘要：深度神經網路模型在各種安全關鍵應用中的應用引發了重大的安全疑慮，尤其是後門攻擊的風險。神經後門構成嚴重的安全威脅，因為它們允許攻擊者惡意地改變模型行為。儘管已經探索了許多防禦措施，但現有方法通常受到特定模型限制的約束，或需要對訓練過程進行複雜的修改，或無法應對各種後門攻擊。在這項工作中，我們提出了一種新穎的方法，用於全面有效地消除後門，稱為 ULRL（後門移除的 UnLearn 和 ReLearn 的縮寫）。ULRL 只需要一小組乾淨的樣本，並且可以有效地對抗所有類型的後門。它首先應用取消學習來識別可疑神經元，然後針對神經權重調整進行後門緩解（即通過在可疑神經元上促進顯著的權重偏差）。根據 12 種不同類型的後門進行評估，ULRL 被證明在消除後門的同時保留模型效用方面顯著優於最先進的方法。

##### **Smart Bilingual Focused Crawling of Parallel Documents**
2405.14779v1 by Cristian García-Romero, Miquel Esplà-Gomis, Felipe Sánchez-Martínez

Crawling parallel texts $\unicode{x2014}$texts that are mutual
translations$\unicode{x2014}$ from the Internet is usually done following a
brute-force approach: documents are massively downloaded in an unguided
process, and only a fraction of them end up leading to actual parallel content.
In this work we propose a smart crawling method that guides the crawl towards
finding parallel content more rapidly. Our approach builds on two different
models: one that infers the language of a document from its URL, and another
that infers whether a pair of URLs link to parallel documents. We evaluate both
models in isolation and their integration into a crawling tool. The results
demonstrate the individual effectiveness of both models and highlight that
their combination enables the early discovery of parallel content during
crawling, leading to a reduction in the amount of downloaded documents deemed
useless, and yielding a greater quantity of parallel documents compared to
conventional crawling approaches.

摘要：網路上的平行語料（互相翻譯的語料）爬取通常採用蠻力法：大量下載文件，過程中不加引導，而只有其中一小部分最後會成為真正的平行內容。在這項研究中，我們提出了一種智慧型爬取方法，引導爬取器更快速地找到平行內容。我們的做法建立在兩個不同的模型上：一個根據網址推論文件的語言，另一個推論一對網址是否連結到平行文件。我們分別評估這兩個模型，以及它們整合到爬取工具中的效果。結果證明了這兩個模型的個別效能，並強調它們的結合可以在爬取過程中提早發現平行內容，減少下載被視為無用的文件數量，並產生比傳統爬取方法更多平行文件。

##### **Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from Human Input**
2405.14769v1 by Andi Peng, Yuying Sun, Tianmin Shu, David Abel

Humans use social context to specify preferences over behaviors, i.e. their
reward functions. Yet, algorithms for inferring reward models from preference
data do not take this social learning view into account. Inspired by pragmatic
human communication, we study how to extract fine-grained data regarding why an
example is preferred that is useful for learning more accurate reward models.
We propose to enrich binary preference queries to ask both (1) which features
of a given example are preferable in addition to (2) comparisons between
examples themselves. We derive an approach for learning from these
feature-level preferences, both for cases where users specify which features
are reward-relevant, and when users do not. We evaluate our approach on linear
bandit settings in both vision- and language-based domains. Results support the
efficiency of our approach in quickly converging to accurate rewards with fewer
comparisons vs. example-only labels. Finally, we validate the real-world
applicability with a behavioral experiment on a mushroom foraging task. Our
findings suggest that incorporating pragmatic feature preferences is a
promising approach for more efficient user-aligned reward learning.

摘要：人類使用社會脈絡來指定對行為的偏好，即他們的獎勵功能。然而，從偏好資料推論獎勵模型的演算法並未考量這種社會學習觀點。受務實人類溝通的啟發，我們研究如何提取有關為何偏好範例的細微資料，這對於學習更準確的獎勵模型很有用。我們建議豐富二元偏好查詢，以詢問 (1) 給定範例的哪些特徵較佳，以及 (2) 範例之間的比較。我們推導出從這些特徵層級偏好學習的方法，適用於使用者指定哪些特徵與獎勵相關的情況，以及使用者未指定的情況。我們在基於視覺和語言的領域中，針對線性賭博機設定評估我們的做法。結果支持我們的方法在使用較少比較次數的情況下，能快速收斂到準確的獎勵，相較於僅範例標籤。最後，我們透過蘑菇覓食任務的行為實驗，驗證了其在現實世界的適用性。我們的研究結果表明，納入務實特徵偏好是一種有前途的做法，可以更有效率地進行使用者對齊的獎勵學習。

##### **WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models**
2405.14768v1 by Peng Wang, Zexi Li, Ningyu Zhang, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large language models (LLMs) need knowledge updates to meet the ever-growing
world facts and correct the hallucinated responses, facilitating the methods of
lifelong model editing. Where the updated knowledge resides in memories is a
fundamental question for model editing. In this paper, we find that editing
either long-term memory (direct model parameters) or working memory
(non-parametric knowledge of neural network activations/representations by
retrieval) will result in an impossible triangle -- reliability,
generalization, and locality can not be realized together in the lifelong
editing settings. For long-term memory, directly editing the parameters will
cause conflicts with irrelevant pretrained knowledge or previous edits (poor
reliability and locality). For working memory, retrieval-based activations can
hardly make the model understand the edits and generalize (poor
generalization). Therefore, we propose WISE to bridge the gap between memories.
In WISE, we design a dual parametric memory scheme, which consists of the main
memory for the pretrained knowledge and a side memory for the edited knowledge.
We only edit the knowledge in the side memory and train a router to decide
which memory to go through when given a query. For continual editing, we devise
a knowledge-sharding mechanism where different sets of edits reside in distinct
subspaces of parameters, and are subsequently merged into a shared memory
without conflicts. Extensive experiments show that WISE can outperform previous
model editing methods and overcome the impossible triangle under lifelong model
editing of question answering, hallucination, and out-of-distribution settings
across trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code will be
released at https://github.com/zjunlp/EasyEdit.

摘要：大型語言模型 (LLM) 需要知識更新才能滿足不斷增長的
世界事實並修正虛構的回應，促進終身模型編輯的方法。更新的知識存放在哪個記憶體中是
模型編輯的基本問題。在本文中，我們發現編輯
長期記憶（直接模型參數）或工作記憶
（神經網路激活/表示的非參數知識，透過擷取）將導致不可能三角——可靠性、
概化和局部性無法在終身
編輯設定中同時實現。對於長期記憶，直接編輯參數將
會與不相關的預訓練知識或先前的編輯產生衝突（可靠性和局部性不佳）。對於工作記憶，基於擷取的激活難以讓模型了解編輯並概化（概化不佳）。因此，我們提出 WISE 來彌補記憶之間的差距。
在 WISE 中，我們設計了一個雙參數記憶架構，其中包含用於預訓練知識的主記憶體和用於編輯知識的側邊記憶體。
我們只編輯側邊記憶體中的知識，並訓練一個路由器來決定在給定查詢時要通過哪個記憶體。對於持續編輯，我們設計了一個知識分片機制，其中不同的編輯組位於參數的不同子空間中，然後合併到一個共用記憶體中，而不會發生衝突。大量的實驗表明，WISE 可以優於先前的
模型編輯方法，並在問題解答、虛構和趨勢 LLM 架構（例如 GPT、LLaMA 和 Mistral）的分布外設定下的終身模型編輯中克服不可能三角。程式碼將於 https://github.com/zjunlp/EasyEdit 發布。

##### **FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models**
2405.14767v1 by Hongyang Yang, Boyu Zhang, Neng Wang, Cheng Guo, Xiaoli Zhang, Likun Lin, Junlin Wang, Tianyu Zhou, Mao Guan, Runjia Zhang, Christina Dan Wang

As financial institutions and professionals increasingly incorporate Large
Language Models (LLMs) into their workflows, substantial barriers, including
proprietary data and specialized knowledge, persist between the finance sector
and the AI community. These challenges impede the AI community's ability to
enhance financial tasks effectively. Acknowledging financial analysis's
critical role, we aim to devise financial-specialized LLM-based toolchains and
democratize access to them through open-source initiatives, promoting wider AI
adoption in financial decision-making.
  In this paper, we introduce FinRobot, a novel open-source AI agent platform
supporting multiple financially specialized AI agents, each powered by LLM.
Specifically, the platform consists of four major layers: 1) the Financial AI
Agents layer that formulates Financial Chain-of-Thought (CoT) by breaking
sophisticated financial problems down into logical sequences; 2) the Financial
LLM Algorithms layer dynamically configures appropriate model application
strategies for specific tasks; 3) the LLMOps and DataOps layer produces
accurate models by applying training/fine-tuning techniques and using
task-relevant data; 4) the Multi-source LLM Foundation Models layer that
integrates various LLMs and enables the above layers to access them directly.
Finally, FinRobot provides hands-on for both professional-grade analysts and
laypersons to utilize powerful AI techniques for advanced financial analysis.
We open-source FinRobot at
\url{https://github.com/AI4Finance-Foundation/FinRobot}.

摘要：隨著金融機構和專業人士將大型語言模型（LLM）納入其工作流程，專有數據和專業知識等實質性障礙持續存在於金融部門和 AI 社群之間。這些挑戰阻礙了 AI 社群有效提升金融任務的能力。認識到金融分析的關鍵作用，我們旨在設計以 LLM 為基礎的金融專業工具鏈，並透過開源計畫讓所有人都能使用它們，以促進在金融決策中更廣泛地採用 AI。
在本文中，我們介紹 FinRobot，一個新穎的開源 AI 代理平台，支援多個以 LLM 為動力的金融專業 AI 代理。具體來說，這個平台包含四個主要層級：1) 金融 AI 代理層，透過將複雜的金融問題分解為邏輯序列，制定金融思維鏈（CoT）；2) 金融 LLM 演算法層，針對特定任務動態配置適當的模型應用策略；3) LLMOps 和 DataOps 層，透過應用訓練/微調技術並使用與任務相關的數據，產生準確的模型；4) 多來源 LLM 基礎模型層，整合各種 LLM 並讓上述層級能夠直接存取它們。
最後，FinRobot 為專業級分析師和外行人提供實作方式，以利用強大的 AI 技術進行進階的金融分析。我們在
\url{https://github.com/AI4Finance-Foundation/FinRobot} 開源 FinRobot。

##### **Evaluating Large Language Models for Public Health Classification and Extraction Tasks**
2405.14766v1 by Joshua Harris, Timothy Laurence, Leo Loman, Fan Grayson, Toby Nonnenmacher, Harry Long, Loes WalsGriffith, Amy Douglas, Holly Fountain, Stelios Georgiou, Jo Hardstaff, Kathryn Hopkins, Y-Ling Chi, Galena Kuyumdzhieva, Lesley Larkin, Samuel Collins, Hamish Mohammed, Thomas Finnie, Luke Hounsome, Steven Riley

Advances in Large Language Models (LLMs) have led to significant interest in
their potential to support human experts across a range of domains, including
public health. In this work we present automated evaluations of LLMs for public
health tasks involving the classification and extraction of free text. We
combine six externally annotated datasets with seven new internally annotated
datasets to evaluate LLMs for processing text related to: health burden,
epidemiological risk factors, and public health interventions. We initially
evaluate five open-weight LLMs (7-70 billion parameters) across all tasks using
zero-shot in-context learning. We find that Llama-3-70B-Instruct is the highest
performing model, achieving the best results on 15/17 tasks (using micro-F1
scores). We see significant variation across tasks with all open-weight LLMs
scoring below 60% micro-F1 on some challenging tasks, such as Contact
Classification, while all LLMs achieve greater than 80% micro-F1 on others,
such as GI Illness Classification. For a subset of 12 tasks, we also evaluate
GPT-4 and find comparable results to Llama-3-70B-Instruct, which scores equally
or outperforms GPT-4 on 6 of the 12 tasks. Overall, based on these initial
results we find promising signs that LLMs may be useful tools for public health
experts to extract information from a wide variety of free text sources, and
support public health surveillance, research, and interventions.

摘要：大型語言模型 (LLM) 的進展引起了人們對其在包括公共衛生在內的多個領域支持人類專家的潛力的濃厚興趣。在這項工作中，我們針對涉及自由文字分類和提取的公共衛生任務，對 LLM 進行了自動化評估。我們將六個外部註釋數據集與七個新的內部註釋數據集結合起來，以評估 LLM 處理與以下相關文本的能力：健康負擔、流行病學風險因素和公共衛生干預措施。我們最初使用零次學習在上下文中評估五個開放權重 LLM（70-700 億個參數）的所有任務。我們發現 Llama-3-70B-Instruct 是性能最高的模型，在 15/17 個任務上取得了最佳結果（使用微 F1 分數）。我們發現所有開放權重 LLM 在所有任務中的表現差異很大，在某些具有挑戰性的任務（例如接觸分類）上得分低於 60% 的微 F1，而所有 LLM 在其他任務（例如胃腸道疾病分類）上都取得了大於 80% 的微 F1。對於 12 個任務的子集，我們還評估了 GPT-4，並發現其結果與 Llama-3-70B-Instruct 相當，後者在 12 個任務中的 6 個任務上得分相等或優於 GPT-4。總體而言，根據這些初步結果，我們發現有希望的跡象表明 LLM 可能成為公共衛生專家從各種自由文本來源中提取信息的有用工具，並支持公共衛生監測、研究和干預措施。

##### **Axioms for AI Alignment from Human Feedback**
2405.14758v1 by Luise Ge, Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira, Yevgeniy Vorobeychik, Junlin Wu

In the context of reinforcement learning from human feedback (RLHF), the
reward function is generally derived from maximum likelihood estimation of a
random utility model based on pairwise comparisons made by humans. The problem
of learning a reward function is one of preference aggregation that, we argue,
largely falls within the scope of social choice theory. From this perspective,
we can evaluate different aggregation methods via established axioms, examining
whether these methods meet or fail well-known standards. We demonstrate that
both the Bradley-Terry-Luce Model and its broad generalizations fail to meet
basic axioms. In response, we develop novel rules for learning reward functions
with strong axiomatic guarantees. A key innovation from the standpoint of
social choice is that our problem has a linear structure, which greatly
restricts the space of feasible rules and leads to a new paradigm that we call
linear social choice.

摘要：在人類回饋（RLHF）的強化學習背景下，獎勵函數通常來自基於人類進行的成對比較的最大似然估計隨機效用模型。學習獎勵函數的問題是一種偏好聚合，我們認為這在很大程度上屬於社會選擇理論的範圍。從這個角度來看，我們可以通過既定的公理評估不同的聚合方法，考察這些方法是否滿足或不滿足眾所周知的標準。我們證明了 Bradley-Terry-Luce 模型及其廣泛的概括都無法滿足基本公理。作為回應，我們制定了具有強有力的公理保證的學習獎勵函數的新規則。從社會選擇的觀點來看，一個關鍵的創新是我們的問題具有線性結構，這極大地限制了可行規則的空間，並導致了一個我們稱之為線性社會選擇的新範例。

##### **A Transformer-Based Approach for Smart Invocation of Automatic Code Completion**
2405.14753v1 by Aral de Moor, Arie van Deursen, Maliheh Izadi

Transformer-based language models are highly effective for code completion,
with much research dedicated to enhancing the content of these completions.
Despite their effectiveness, these models come with high operational costs and
can be intrusive, especially when they suggest too often and interrupt
developers who are concentrating on their work. Current research largely
overlooks how these models interact with developers in practice and neglects to
address when a developer should receive completion suggestions. To tackle this
issue, we developed a machine learning model that can accurately predict when
to invoke a code completion tool given the code context and available telemetry
data.
  To do so, we collect a dataset of 200k developer interactions with our
cross-IDE code completion plugin and train several invocation filtering models.
Our results indicate that our small-scale transformer model significantly
outperforms the baseline while maintaining low enough latency. We further
explore the search space for integrating additional telemetry data into a
pre-trained transformer directly and obtain promising results. To further
demonstrate our approach's practical potential, we deployed the model in an
online environment with 34 developers and provided real-world insights based on
74k actual invocations.

摘要：基於 Transformer 的語言模型對於程式碼補完非常有效，許多研究致力於加強這些補完的內容。儘管這些模型很有效，但它們的運作成本很高，而且可能會造成干擾，特別是在它們過於頻繁地提出建議並中斷專注於工作的開發人員時。目前的許多研究都忽略了這些模型實際上如何與開發人員互動，而且忽略了何時應該向開發人員提供補完建議的問題。為了解決這個問題，我們開發了一個機器學習模型，它可以根據程式碼內容和可用的遙測資料準確預測何時呼叫程式碼補完工具。為此，我們收集了一個包含 20 萬個開發人員與我們的跨 IDE 程式碼補完外掛程式互動的資料集，並訓練了幾個呼叫過濾模型。我們的結果表明，我們的微型 Transformer 模型顯著優於基線，同時維持足夠低的延遲。我們進一步探索了將額外的遙測資料直接整合到預先訓練的 Transformer 的搜尋空間，並獲得了有希望的結果。為了進一步證明我們的方法的實際潛力，我們在一個線上環境中部署了這個模型，其中有 34 位開發人員，並根據 7 萬 4 千個實際呼叫提供了真實世界的見解。

##### **Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams**
2405.14750v1 by Juyoung Yun, Jungmin Shin

Solar flares, especially C, M, and X class, pose significant risks to
satellite operations, communication systems, and power grids. We present a
novel approach for predicting extreme solar flares using HMI intensitygrams and
magnetograms. By detecting sunspots from intensitygrams and extracting magnetic
field patches from magnetograms, we train a Residual Network (ResNet) to
classify extreme class flares. Our model demonstrates high accuracy, offering a
robust tool for predicting extreme solar flares and improving space weather
forecasting. Additionally, we show that HMI magnetograms provide more useful
data for deep learning compared to other SDO AIA images by better capturing
features critical for predicting flare magnitudes. This study underscores the
importance of identifying magnetic fields in solar flare prediction, marking a
significant advancement in solar activity prediction with practical
implications for mitigating space weather impacts.

摘要：太陽耀斑，尤其是 C、M 和 X 等級，對衛星運作、通訊系統和電網造成重大風險。我們提出了一種使用 HMI 強度圖和磁像圖預測極端太陽耀斑的新方法。我們透過從強度圖中偵測太陽黑子，並從磁像圖中萃取磁場斑塊，來訓練殘差網路 (ResNet) 分類極端等級耀斑。我們的模型展現出高準確性，提供了一個用於預測極端太陽耀斑和改善太空天氣預測的強大工具。此外，我們證明與其他 SDO AIA 影像相比，HMI 磁像圖提供了更多有用的資料用於深度學習，因為它能更好地擷取預測耀斑大小的關鍵特徵。這項研究強調了在太陽耀斑預測中辨識磁場的重要性，標誌著太陽活動預測的重大進展，並對減輕太空天氣影響具有實際意義。

##### **MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs**
2405.14748v1 by Georgios Chatzigeorgakidis, Konstantinos Lentzos, Dimitrios Skoutas

Predicting future values in multivariate time series is vital across various
domains. This work explores the use of large language models (LLMs) for this
task. However, LLMs typically handle one-dimensional data. We introduce
MultiCast, a zero-shot LLM-based approach for multivariate time series
forecasting. It allows LLMs to receive multivariate time series as input,
through three novel token multiplexing solutions that effectively reduce
dimensionality while preserving key repetitive patterns. Additionally, a
quantization scheme helps LLMs to better learn these patterns, while
significantly reducing token use for practical applications. We showcase the
performance of our approach in terms of RMSE and execution time against
state-of-the-art approaches on three real-world datasets.

摘要：預測多變量時間序列中的未來值在各個領域至關重要。本研究探討將大型語言模型 (LLM) 用於此任務。然而，LLM 通常處理一維資料。我們導入 MultiCast，這是一種基於 LLM 的零次學習方法，用於多變量時間序列預測。它允許 LLM 透過三種新穎的代幣多工解決方案接收多變量時間序列作為輸入，這些解決方案可有效降低維度，同時保留關鍵的重複模式。此外，量化方案有助於 LLM 更佳地學習這些模式，同時大幅減少實際應用中的代幣使用。我們展示了我們的方法在 RMSE 和執行時間方面的效能，並針對三個真實世界資料集與最先進的方法進行比較。

##### **TopoLogic: An Interpretable Pipeline for Lane Topology Reasoning on Driving Scenes**
2405.14747v1 by Yanping Fu, Wenbin Liao, Xinyuan Liu, Hang xu, Yike Ma, Feng Dai, Yucheng Zhang

As an emerging task that integrates perception and reasoning, topology
reasoning in autonomous driving scenes has recently garnered widespread
attention. However, existing work often emphasizes "perception over reasoning":
they typically boost reasoning performance by enhancing the perception of lanes
and directly adopt MLP to learn lane topology from lane query. This paradigm
overlooks the geometric features intrinsic to the lanes themselves and are
prone to being influenced by inherent endpoint shifts in lane detection.
  To tackle this issue, we propose an interpretable method for lane topology
reasoning based on lane geometric distance and lane query similarity, named
TopoLogic.
  This method mitigates the impact of endpoint shifts in geometric space, and
introduces explicit similarity calculation in semantic space as a complement.
By integrating results from both spaces, our methods provides more
comprehensive information for lane topology.
  Ultimately, our approach significantly outperforms the existing
state-of-the-art methods on the mainstream benchmark OpenLane-V2 (23.9 v.s.
10.9 in TOP$_{ll}$ and 44.1 v.s. 39.8 in OLS on subset_A. Additionally, our
proposed geometric distance topology reasoning method can be incorporated into
well-trained models without re-training, significantly boost the performance of
lane topology reasoning. The code is released at
https://github.com/Franpin/TopoLogic.

摘要：作為一個整合感知和推理的新興任務，在自動駕駛場景中的拓撲推理最近廣泛受到關注。然而，現有的工作通常強調「感知大於推理」：他們通常透過增強車道感知來提升推理效能，並直接採用 MLP 從車道查詢中學習車道拓撲。此範例忽略了車道本身固有的幾何特徵，且容易受到車道偵測中固有的端點偏移影響。為了解決這個問題，我們提出一個基於車道幾何距離和車道查詢相似性的可解釋車道拓撲推理方法，命名為 TopoLogic。此方法減輕了幾何空間中端點偏移的影響，並引入語意空間中的明確相似性計算作為補充。透過整合來自兩個空間的結果，我們的模型提供了更全面的車道拓撲資訊。最終，我們的做法在主流基準 OpenLane-V2 上明顯優於現有的最先進方法（在 subset_A 上的 TOP$_{ll}$ 為 23.9 對 10.9，OLS 為 44.1 對 39.8）。此外，我們提出的幾何距離拓撲推理方法可以整合到訓練良好的模型中，而無需重新訓練，大幅提升車道拓撲推理的效能。程式碼已在 https://github.com/Franpin/TopoLogic 發布。

##### **SimPO: Simple Preference Optimization with a Reference-Free Reward**
2405.14734v1 by Yu Meng, Mengzhou Xia, Danqi Chen

Direct Preference Optimization (DPO) is a widely used offline preference
optimization algorithm that reparameterizes reward functions in reinforcement
learning from human feedback (RLHF) to enhance simplicity and training
stability. In this work, we propose SimPO, a simpler yet more effective
approach. The effectiveness of SimPO is attributed to a key design: using the
average log probability of a sequence as the implicit reward. This reward
formulation better aligns with model generation and eliminates the need for a
reference model, making it more compute and memory efficient. Additionally, we
introduce a target reward margin to the Bradley-Terry objective to encourage a
larger margin between the winning and losing responses, further enhancing the
algorithm's performance. We compare SimPO to DPO and its latest variants across
various state-of-the-art training setups, including both base and
instruction-tuned models like Mistral and Llama3. We evaluated on extensive
instruction-following benchmarks, including AlpacaEval 2, MT-Bench, and the
recent challenging Arena-Hard benchmark. Our results demonstrate that SimPO
consistently and significantly outperforms existing approaches without
substantially increasing response length. Specifically, SimPO outperforms DPO
by up to 6.4 points on AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our
top-performing model, built on Llama3-8B-Instruct, achieves a remarkable 44.7
length-controlled win rate on AlpacaEval 2 -- surpassing Claude 3 Opus on the
leaderboard, and a 33.8 win rate on Arena-Hard -- making it the strongest 8B
open-source model.

摘要：直接偏好最佳化 (DPO) 是一種廣泛使用的離線偏好最佳化演算法，它會重新參數化人類回饋 (RLHF) 中強化學習的獎勵函數，以提升簡潔性和訓練穩定性。在本文中，我們提出 SimPO，一種更簡單但更有效的方法。SimPO 的有效性歸功於一個關鍵設計：使用序列的平均對數機率作為內隱獎勵。此獎勵公式更符合模型生成，並消除了對參考模型的需求，使其更具運算和記憶體效率。此外，我們在 Bradley-Terry 目標中引入了目標獎勵邊際，以鼓勵獲勝和失敗回應之間有更大的邊際，進一步提升演算法的效能。我們在各種最先進的訓練設定中比較了 SimPO 和 DPO 及其最新變體，包括基礎模型和 Mistral 和 Llama3 等經過指令調整的模型。我們在廣泛的指令遵循基準上進行評估，包括 AlpacaEval 2、MT-Bench 和最近具有挑戰性的 Arena-Hard 基準。我們的結果證明，SimPO 持續且顯著地優於現有方法，而不會大幅增加回應長度。具體來說，SimPO 在 AlpacaEval 2 上比 DPO 高出 6.4 分，在 Arena-Hard 上高出 7.5 分。我們建立在 Llama3-8B-Instruct 上的效能最佳模型在 AlpacaEval 2 上達到了驚人的 44.7 長度控制獲勝率，在排行榜上超越了 Claude 3 Opus，在 Arena-Hard 上達到了 33.8 的獲勝率，使其成為最強大的 8B 開源模型。

##### **Intervention and Conditioning in Causal Bayesian Networks**
2405.14728v1 by Sainyam Galhotra, Joseph Y. Halpern

Causal models are crucial for understanding complex systems and identifying
causal relationships among variables. Even though causal models are extremely
popular, conditional probability calculation of formulas involving
interventions pose significant challenges. In case of Causal Bayesian Networks
(CBNs), Pearl assumes autonomy of mechanisms that determine interventions to
calculate a range of probabilities. We show that by making simple yet often
realistic independence assumptions, it is possible to uniquely estimate the
probability of an interventional formula (including the well-studied notions of
probability of sufficiency and necessity). We discuss when these assumptions
are appropriate. Importantly, in many cases of interest, when the assumptions
are appropriate, these probability estimates can be evaluated using
observational data, which carries immense significance in scenarios where
conducting experiments is impractical or unfeasible.

摘要：因果模型对于理解复杂系统和识别变量之间的因果关系至关重要。尽管因果模型非常流行，但涉及干预的公式的条件概率计算却带来了重大挑战。在因果贝叶斯网络 (CBN) 的情况下，Pearl 假设确定干预的机制是自主的，以计算一系列概率。我们表明，通过做出简单但通常是现实的独立性假设，可以唯一估计干预公式的概率（包括充分性和必要性的概率等经过充分研究的概念）。我们讨论了这些假设何时适用。重要的是，在许多感兴趣的情况下，当假设适用时，可以使用观察数据评估这些概率估计，这在进行实验不切实际或不可行的情况下具有重要意义。

##### **CAPE: Context-Adaptive Positional Encoding for Length Extrapolation**
2405.14722v1 by Chuanyang Zheng, Yihang Gao, Han Shi, Minbin Huang, Jingyao Li, Jing Xiong, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li

Positional encoding plays a crucial role in transformers, significantly
impacting model performance and length generalization. Prior research has
introduced absolute positional encoding (APE) and relative positional encoding
(RPE) to distinguish token positions in given sequences. However, both APE and
RPE remain fixed after model training regardless of input data, limiting their
adaptability and flexibility. Hence, we expect that the desired positional
encoding should be context-adaptive and can be dynamically adjusted with the
given attention. In this paper, we propose a Context-Adaptive Positional
Encoding (CAPE) method, which dynamically and semantically adjusts based on
input context and learned fixed priors. Experimental validation on real-world
datasets (Arxiv, Books3, and CHE) demonstrates that CAPE enhances model
performances in terms of trained length and length generalization, where the
improvements are statistically significant. The model visualization suggests
that our model can keep both local and anti-local information. Finally, we
successfully train the model on sequence length 128 and achieve better
performance at evaluation sequence length 8192, compared with other static
positional encoding methods, revealing the benefit of the adaptive positional
encoding method.

摘要：位置編碼在 Transformer 中扮演著至關重要的角色，它會顯著影響模型效能和長度泛化。先前的研究引入了絕對位置編碼 (APE) 和相對位置編碼 (RPE) 來區分給定序列中的代幣位置。然而，APE 和 RPE 在模型訓練後仍然固定不變，與輸入資料無關，這限制了它們的適應性和靈活性。因此，我們預期所需的定位編碼應具備適應語境的特性，並可根據給定的注意力進行動態調整。在本文中，我們提出了一種語境適應位置編碼 (CAPE) 方法，它會根據輸入語境和學習到的固定先驗進行動態且語義化的調整。在真實世界資料集 (Arxiv、Books3 和 CHE) 上進行的實驗驗證表明，CAPE 在訓練長度和長度泛化方面增強了模型效能，其中改進具有統計顯著性。模型視覺化顯示我們的模型可以保留局部和反局部資訊。最後，我們成功地訓練了序列長度為 128 的模型，並在評估序列長度為 8192 時獲得了比其他靜態位置編碼方法更好的效能，這揭示了自適應位置編碼方法的優點。

##### **Decision-Focused Forecasting: Decision Losses for Multistage Optimisation**
2405.14719v1 by Egon Peršak, Miguel F. Anjos

Decision-focused learning has emerged as a promising approach for decision
making under uncertainty by training the upstream predictive aspect of the
pipeline with respect to the quality of the downstream decisions. Most existing
work has focused on single stage problems. Many real-world decision problems
are more appropriately modelled using multistage optimisation as contextual
information such as prices or demand is revealed over time and decisions now
have a bearing on future decisions. We propose decision-focused forecasting, a
multiple-implicitlayer model which in its training accounts for the
intertemporal decision effects of forecasts using differentiable optimisation.
The recursive model reflects a fully differentiable multistage optimisation
approach. We present an analysis of the gradients produced by this model
showing the adjustments made to account for the state-path caused by
forecasting. We demonstrate an application of the model to an energy storage
arbitrage task and report that our model outperforms existing approaches.

摘要：以決策為中心的學習已成為一種有前途的方法，可透過針對下游決策品質訓練管線的上游預測面向，在不確定性下進行決策。現有的大部分研究都集中在單階段問題。許多實際的決策問題更適合使用多階段最佳化進行建模，因為價格或需求等背景資訊會隨著時間推移而揭露，而且當前的決策會影響未來的決策。我們提出以決策為中心的預測，這是一個多重隱含層模型，在訓練中會使用可微最佳化來考量預測的時序決策效果。遞迴模型反映了一個完全可微的多階段最佳化方法。我們提出對此模型產生的梯度進行分析，顯示了為考量預測所造成的狀態路徑而進行的調整。我們示範將此模型應用於能源儲存套利任務，並報告我們的模型優於現有方法。

##### **HTN-Based Tutors: A New Intelligent Tutoring Framework Based on Hierarchical Task Networks**
2405.14716v2 by Momin N. Siddiqui, Adit Gupta, Jennifer M. Reddig, Christopher J. MacLellan

Intelligent tutors have shown success in delivering a personalized and
adaptive learning experience. However, there exist challenges regarding the
granularity of knowledge in existing frameworks and the resulting instructions
they can provide. To address these issues, we propose HTN-based tutors, a new
intelligent tutoring framework that represents expert models using Hierarchical
Task Networks (HTNs). Like other tutoring frameworks, it allows flexible
encoding of different problem-solving strategies while providing the additional
benefit of a hierarchical knowledge organization. We leverage the latter to
create tutors that can adapt the granularity of their scaffolding. This
organization also aligns well with the compositional nature of skills.

摘要：智能導師已展現出提供個人化和適應性學習體驗的成功。然而，現有架構中知識的粒度及其產生的指示存在挑戰。為了解決這些問題，我們提出基於 HTN 的導師，這是一個新的智能輔導框架，它使用階層任務網路 (HTN) 來表示專家模型。與其他輔導框架一樣，它允許靈活編碼不同的問題解決策略，同時提供階層知識組織的額外好處。我們利用後者來創建可以調整其鷹架粒度的導師。這種組織也與技能的組合性質非常一致。

##### **Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models**
2405.14715v1 by Young Kyun Jang, Ser-nam Lim

Modern retrieval systems often struggle with upgrading to new and more
powerful models due to the incompatibility of embeddings between the old and
new models. This necessitates a costly process known as backfilling, which
involves re-computing the embeddings for a large number of data samples. In
vision, Backward-compatible Training (BT) has been proposed to ensure that the
new model aligns with the old model's embeddings. This paper extends the
concept of vision-only BT to the field of cross-modal retrieval, marking the
first attempt to address Cross-modal BT (XBT). Our goal is to achieve
backward-compatibility between Vision-Language Pretraining (VLP) models, such
as CLIP, for the cross-modal retrieval task. To address XBT challenges, we
propose an efficient solution: a projection module that maps the new model's
embeddings to those of the old model. This module, pretrained solely with text
data, significantly reduces the number of image-text pairs required for XBT
learning, and, once it is pretrained, it avoids using the old model during
training. Furthermore, we utilize parameter-efficient training strategies that
improve efficiency and preserve the off-the-shelf new model's knowledge by
avoiding any modifications. Experimental results on cross-modal retrieval
datasets demonstrate the effectiveness of XBT and its potential to enable
backfill-free upgrades when a new VLP model emerges.

摘要：現代檢索系統常因舊模型與新模型的嵌入式不符，而難以升級至更新且功能更強大的模型。這需要一個名為回填的昂貴程序，其中涉及重新計算大量數據樣本的嵌入式。在視覺上，已提出向後相容訓練 (BT) 以確保新模型與舊模型的嵌入式對齊。本文將視覺專用 BT 的概念延伸至跨模態檢索領域，標誌著首次嘗試解決跨模態 BT (XBT)。我們的目標是達成視覺語言預訓練 (VLP) 模型（例如 CLIP）之間的向後相容性，以進行跨模態檢索任務。為了解決 XBT 挑戰，我們提出了一個有效的解決方案：一個投影模組，將新模型的嵌入式對應至舊模型的嵌入式。此模組僅使用文字資料預先訓練，大幅減少 XBT 學習所需的影像文字配對數量，且預先訓練後，在訓練期間便不再使用舊模型。此外，我們利用參數有效訓練策略來提升效率並保留現成的全新模型知識，藉由避免任何修改。跨模態檢索資料集上的實驗結果證明了 XBT 的有效性，以及當新的 VLP 模型出現時，它能進行無回填升級的潛力。

##### **Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces**
2405.14713v1 by Tommaso Calo, Christopher J. MacLellan

Intelligent Tutoring Systems (ITSs) have shown great potential in delivering
personalized and adaptive education, but their widespread adoption has been
hindered by the need for specialized programming and design skills. Existing
approaches overcome the programming limitations with no-code authoring through
drag and drop, however they assume that educators possess the necessary skills
to design effective and engaging tutor interfaces. To address this assumption
we introduce generative AI capabilities to assist educators in creating tutor
interfaces that meet their needs while adhering to design principles. Our
approach leverages Large Language Models (LLMs) and prompt engineering to
generate tutor layout and contents based on high-level requirements provided by
educators as inputs. However, to allow them to actively participate in the
design process, rather than relying entirely on AI-generated solutions, we
allow generation both at the entire interface level and at the individual
component level. The former provides educators with a complete interface that
can be refined using direct manipulation, while the latter offers the ability
to create specific elements to be added to the tutor interface. A small-scale
comparison shows the potential of our approach to enhance the efficiency of
tutor interface design. Moving forward, we raise critical questions for
assisting educators with generative AI capabilities to create personalized,
effective, and engaging tutors, ultimately enhancing their adoption.

摘要：智慧型教學系統 (ITSs) 在提供個人化和適應性教育方面展現了極大的潛力，但其廣泛採用受到對專業程式設計和設計技能需求的阻礙。現有的方法透過拖放克服了程式設計限制，但它們假設教育工作者具備設計有效且引人入勝的教學介面的必要技能。為了解決此假設，我們引入了生成式 AI 能力，以協助教育工作者建立符合其需求且遵循設計原則的教學介面。我們的做法利用大型語言模型 (LLMs) 和提示工程，根據教育工作者提供的輸入，生成教學介面配置和內容。然而，為了讓他們積極參與設計流程，而不是完全依賴 AI 生成的解決方案，我們允許在整個介面層級和個別元件層級進行生成。前者為教育工作者提供了一個完整的介面，可以使用直接操作進行修改，而後者則提供建立特定元素以新增到教學介面中的能力。小規模的比較顯示了我們的方法在提升教學介面設計效率方面的潛力。展望未來，我們提出了關鍵問題，以協助教育工作者利用生成式 AI 能力建立個人化、有效且引人入勝的教學，最終提升其採用率。

##### **G3: An Effective and Adaptive Framework for Worldwide Geolocalization Using Large Multi-Modality Models**
2405.14702v1 by Pengyue Jia, Yiding Liu, Xiaopeng Li, Xiangyu Zhao, Yuhao Wang, Yantong Du, Xiao Han, Xuetao Wei, Shuaiqiang Wang, Dawei Yin

Worldwide geolocalization aims to locate the precise location at the
coordinate level of photos taken anywhere on the Earth. It is very challenging
due to 1) the difficulty of capturing subtle location-aware visual semantics,
and 2) the heterogeneous geographical distribution of image data. As a result,
existing studies have clear limitations when scaled to a worldwide context.
They may easily confuse distant images with similar visual contents, or cannot
adapt to various locations worldwide with different amounts of relevant data.
To resolve these limitations, we propose G3, a novel framework based on
Retrieval-Augmented Generation (RAG). In particular, G3 consists of three
steps, i.e., Geo-alignment, Geo-diversification, and Geo-verification to
optimize both retrieval and generation phases of worldwide geolocalization.
During Geo-alignment, our solution jointly learns expressive multi-modal
representations for images, GPS and textual descriptions, which allows us to
capture location-aware semantics for retrieving nearby images for a given
query. During Geo-diversification, we leverage a prompt ensembling method that
is robust to inconsistent retrieval performance for different image queries.
Finally, we combine both retrieved and generated GPS candidates in
Geo-verification for location prediction. Experiments on two well-established
datasets IM2GPS3k and YFCC4k verify the superiority of G3 compared to other
state-of-the-art methods.

摘要：全球地理定位旨在精確定位地球上任何地方拍攝的照片的座標層級。由於 1) 難以捕捉微妙的位置感知視覺語義，以及 2) 影像資料的異質地理分佈，因此這是一個非常具有挑戰性的任務。因此，現有的研究在擴展到全球範圍時具有明顯的限制。它們很容易將具有類似視覺內容的遠端影像混淆，或者無法適應全球各地具有不同相關資料量的各種位置。為了解決這些限制，我們提出了 G3，一個基於檢索增強生成 (RAG) 的新框架。特別是，G3 包含三個步驟，即地理對齊、地理多樣化和地理驗證，以最佳化全球地理定位的檢索和生成階段。在地理對齊期間，我們的解決方案聯合學習影像、GPS 和文字描述的表達式多模態表示，這使我們能夠捕捉位置感知語義，以檢索給定查詢的附近影像。在地理多樣化期間，我們利用提示集成方法，該方法對於不同影像查詢的不一致檢索效能具有魯棒性。最後，我們在地理驗證中結合檢索和生成的 GPS 候選項，以進行位置預測。在兩個公認的資料集 IM2GPS3k 和 YFCC4k 上的實驗驗證了 G3 優於其他最先進方法的優越性。

##### **High Fidelity Scene Text Synthesis**
2405.14701v1 by Yibin Wang, Weizhong Zhang, Jianwei Zheng, Cheng Jin

Scene text synthesis involves rendering specified texts onto arbitrary
images. Current methods typically formulate this task in an end-to-end manner
but lack effective character-level guidance during training. Besides, their
text encoders, pre-trained on a single font type, struggle to adapt to the
diverse font styles encountered in practical applications. Consequently, these
methods suffer from character distortion, repetition, and absence, particularly
in polystylistic scenarios. To this end, this paper proposes DreamText for
high-fidelity scene text synthesis. Our key idea is to reconstruct the
diffusion training process, introducing more refined guidance tailored to this
task, to expose and rectify the model's attention at the character level and
strengthen its learning of text regions. This transformation poses a hybrid
optimization challenge, involving both discrete and continuous variables. To
effectively tackle this challenge, we employ a heuristic alternate optimization
strategy. Meanwhile, we jointly train the text encoder and generator to
comprehensively learn and utilize the diverse font present in the training
dataset. This joint training is seamlessly integrated into the alternate
optimization process, fostering a synergistic relationship between learning
character embedding and re-estimating character attention. Specifically, in
each step, we first encode potential character-generated position information
from cross-attention maps into latent character masks. These masks are then
utilized to update the representation of specific characters in the current
step, which, in turn, enables the generator to correct the character's
attention in the subsequent steps. Both qualitative and quantitative results
demonstrate the superiority of our method to the state of the art.

摘要：場景文字合成涉及將指定的文字渲染到任意影像。目前的技術通常以端對端的方式制定此任務，但在訓練期間缺乏有效的字元級指導。此外，其文字編碼器預先訓練於單一字體類型上，難以適應實際應用中遇到的各種字體樣式。因此，這些技術會出現字元扭曲、重複和遺失，特別是在多樣化風格的場景中。為此，本文提出 DreamText 以進行高保真場景文字合成。我們的關鍵構想是重建擴散訓練過程，引入針對此任務量身打造的更精確指導，以揭露和修正模型在字元級的注意力，並加強其對文字區域的學習。此轉換構成一個混合最佳化挑戰，涉及離散和連續變數。為了有效應對此挑戰，我們採用啟發式交替最佳化策略。同時，我們聯合訓練文字編碼器和生成器，以全面學習和利用訓練資料集中存在的各種字體。此聯合訓練無縫整合到交替最佳化過程中，促進學習字元嵌入和重新估計字元注意力的協同關係。具體來說，在每個步驟中，我們首先將來自交叉注意力圖的潛在字元生成位置資訊編碼到潛在字元遮罩中。然後利用這些遮罩來更新當前步驟中特定字元的表示，這反過來又使生成器能夠在後續步驟中修正字元的注意力。定性和定量結果都證明了我們的方法優於現有技術。

##### **A Declarative System for Optimizing AI Workloads**
2405.14696v1 by Chunwei Liu, Matthew Russo, Michael Cafarella, Lei Cao, Peter Baille Chen, Zui Chen, Michael Franklin, Tim Kraska, Samuel Madden, Gerardo Vitagliano

Modern AI models provide the key to a long-standing dream: processing
analytical queries about almost any kind of data. Until recently, it was
difficult and expensive to extract facts from company documents, data from
scientific papers, or insights from image and video corpora. Today's models can
accomplish these tasks with high accuracy. However, a programmer who wants to
answer a substantive AI-powered query must orchestrate large numbers of models,
prompts, and data operations. For even a single query, the programmer has to
make a vast number of decisions such as the choice of model, the right
inference method, the most cost-effective inference hardware, the ideal prompt
design, and so on. The optimal set of decisions can change as the query changes
and as the rapidly-evolving technical landscape shifts. In this paper we
present Palimpzest, a system that enables anyone to process AI-powered
analytical queries simply by defining them in a declarative language. The
system uses its cost optimization framework -- which explores the search space
of AI models, prompting techniques, and related foundation model optimizations
-- to implement the query with the best trade-offs between runtime, financial
cost, and output data quality. We describe the workload of AI-powered analytics
tasks, the optimization methods that Palimpzest uses, and the prototype system
itself. We evaluate Palimpzest on tasks in Legal Discovery, Real Estate Search,
and Medical Schema Matching. We show that even our simple prototype offers a
range of appealing plans, including one that is 3.3x faster, 2.9x cheaper, and
offers better data quality than the baseline method. With parallelism enabled,
Palimpzest can produce plans with up to a 90.3x speedup at 9.1x lower cost
relative to a single-threaded GPT-4 baseline, while obtaining an F1-score
within 83.5% of the baseline. These require no additional work by the user.

摘要：現代 AI 模型提供了實現長久夢想的方法：處理幾乎任何類型資料的分析查詢。直到最近，從公司文件、科學論文中萃取事實，或從影像和影片資料集中取得見解，都是困難且昂貴的。今日的模型可以高精確度完成這些任務。然而，想要回答實質 AI 驅動查詢的程式設計師，必須協調大量的模型、提示和資料操作。即使只是一個單一的查詢，程式設計師都必須做出大量的決策，例如模型的選擇、正確的推論方法、最具成本效益的推論硬體、理想的提示設計等等。最佳的決策組合會隨著查詢的變更和快速變化的技術環境而改變。在本文中，我們提出 Palimpzest，這是一個系統，讓任何人只要使用宣告式語言定義 AI 驅動的分析查詢，就能處理這些查詢。此系統使用其成本最佳化架構（探索 AI 模型、提示技術和相關基礎模型最佳化的搜尋空間）來實作查詢，在執行時間、財務成本和輸出資料品質之間取得最佳的平衡。我們描述了 AI 驅動分析任務的工作負載、Palimpzest 使用的最佳化方法和原型系統本身。我們在法律發現、房地產搜尋和醫療架構比對任務中評估 Palimpzest。我們展示了即使是我們簡單的原型，也能提供一系列有吸引力的計畫，包括一個比基準方法快 3.3 倍、便宜 2.9 倍，且提供更好資料品質的計畫。在啟用平行處理的情況下，Palimpzest 可以產生速度提升達 90.3 倍、成本降低達 9.1 倍的計畫，相較於單執行緒 GPT-4 基準，同時獲得 F1 分數達基準的 83.5%。這些都不需要使用者額外的工作。

##### **CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System**
2405.14691v1 by Qinghua Guan, Jinhui Ouyang, Di Wu, Weiren Yu

The spatiotemporal data generated by massive sensors in the Internet of
Things (IoT) is extremely dynamic, heterogeneous, large scale and
time-dependent. It poses great challenges (e.g. accuracy, reliability, and
stability) in real-time analysis and decision making for different IoT
applications. The complexity of IoT data prevents the common people from
gaining a deeper understanding of it. Agentized systems help address the lack
of data insight for the common people. We propose a generic framework, namely
CityGPT, to facilitate the learning and analysis of IoT time series with an
end-to-end paradigm. CityGPT employs three agents to accomplish the
spatiotemporal analysis of IoT data. The requirement agent facilitates user
inputs based on natural language. Then, the analysis tasks are decomposed into
temporal and spatial analysis processes, completed by corresponding data
analysis agents (temporal and spatial agents). Finally, the spatiotemporal
fusion agent visualizes the system's analysis results by receiving analysis
results from data analysis agents and invoking sub-visualization agents, and
can provide corresponding textual descriptions based on user demands. To
increase the insight for common people using our framework, we have agnentized
the framework, facilitated by a large language model (LLM), to increase the
data comprehensibility. Our evaluation results on real-world data with
different time dependencies show that the CityGPT framework can guarantee
robust performance in IoT computing.

摘要：物聯網 (IoT) 中大量感測器產生的時空資料極具動態性、異質性、大規模且依賴時間而定。這對不同 IoT 應用程式的即時分析和決策制定構成極大的挑戰（例如準確性、可靠性和穩定性）。IoT 資料的複雜性讓一般人難以深入了解。代理系統有助於解決一般人缺乏資料洞察力的問題。我們提出一個通用架構，即 CityGPT，以促進以端對端範例學習和分析 IoT 時間序列。CityGPT 使用三個代理來完成 IoT 資料的時空分析。需求代理根據自然語言促進使用者輸入。然後，將分析任務分解為時間和空間分析流程，並由對應的資料分析代理（時間和空間代理）完成。最後，時空融合代理透過接收資料分析代理的分析結果並呼叫子視覺化代理，將系統的分析結果視覺化，並可根據使用者的需求提供對應的文字說明。為了增加一般人使用我們架構的洞察力，我們利用大型語言模型 (LLM) 代理化架構，以增加資料的可理解性。我們在具有不同時間依賴性的真實世界資料上進行的評估結果顯示，CityGPT 架構可以保證在 IoT 運算中具有穩健的效能。

##### **Efficiency for Free: Ideal Data Are Transportable Representations**
2405.14669v1 by Peng Sun, Yi Jiang, Tao Lin

Data, the seminal opportunity and challenge in modern machine learning,
currently constrains the scalability of representation learning and impedes the
pace of model evolution. Existing paradigms tackle the issue of learning
efficiency over massive datasets from the perspective of self-supervised
learning and dataset distillation independently, while neglecting the untapped
potential of accelerating representation learning from an intermediate
standpoint. In this work, we delve into defining the ideal data properties from
both optimization and generalization perspectives. We propose that
model-generated representations, despite being trained on diverse tasks and
architectures, converge to a shared linear space, facilitating effective linear
transport between models. Furthermore, we demonstrate that these
representations exhibit properties conducive to the formation of ideal data.
The theoretical/empirical insights therein inspire us to propose a
Representation Learning Accelerator (ReLA), which leverages a task- and
architecture-agnostic, yet publicly available, free model to form a dynamic
data subset and thus accelerate (self-)supervised learning. For instance,
employing a CLIP ViT B/16 as a prior model for dynamic data generation,
ReLA-aided BYOL can train a ResNet-50 from scratch with 50% of ImageNet-1K,
yielding performance surpassing that of training on the full dataset.
Additionally, employing a ResNet-18 pre-trained on CIFAR-10 can enhance
ResNet-50 training on 10% of ImageNet-1K, resulting in a 7.7% increase in
accuracy.

摘要：<paragraph>資料，在現代機器學習中是開創性的機遇和挑戰，
目前限制了表徵學習的可擴充性，並阻礙了模型演化的速度。現有的範例從自監督學習和資料集蒸餾的觀點來解決海量資料集上學習效率的問題，同時忽略了從中間立場加速表徵學習的未開發潛力。在這項工作中，我們深入探討從最佳化和概括的觀點定義理想的資料屬性。我們提出模型產生的表徵，儘管是在不同的任務和架構上訓練的，但會收斂到一個共用的線性空間，促進模型之間有效的線性傳輸。此外，我們證明這些表徵表現出有利於形成理想資料的屬性。其中的理論/經驗見解啟發我們提出表徵學習加速器 (ReLA)，它利用任務和架構不可知的，但公開可用的免費模型來形成動態資料子集，從而加速（自我）監督學習。例如，使用 CLIP ViT B/16 作為動態資料生成的先驗模型，ReLA 輔助的 BYOL 可以從頭開始訓練一個 ResNet-50，使用 50% 的 ImageNet-1K，其效能優於在完整資料集上訓練的效能。此外，使用在 CIFAR-10 上預訓練的 ResNet-18 可以增強 ResNet-50 在 10% 的 ImageNet-1K 上的訓練，從而使準確度提高 7.7%。</paragraph>

##### **Fisher Flow Matching for Generative Modeling over Discrete Data**
2405.14664v1 by Oscar Davis, Samuel Kessler, Mircea Petrache, {İ}smail {İ}lkan Ceylan, Avishek Joey Bose

Generative modeling over discrete data has recently seen numerous success
stories, with applications spanning language modeling, biological sequence
design, and graph-structured molecular data. The predominant generative
modeling paradigm for discrete data is still autoregressive, with more recent
alternatives based on diffusion or flow-matching falling short of their
impressive performance in continuous data settings, such as image or video
generation. In this work, we introduce Fisher-Flow, a novel flow-matching model
for discrete data. Fisher-Flow takes a manifestly geometric perspective by
considering categorical distributions over discrete data as points residing on
a statistical manifold equipped with its natural Riemannian metric: the
$\textit{Fisher-Rao metric}$. As a result, we demonstrate discrete data itself
can be continuously reparameterised to points on the positive orthant of the
$d$-hypersphere $\mathbb{S}^d_+$, which allows us to define flows that map any
source distribution to target in a principled manner by transporting mass along
(closed-form) geodesics of $\mathbb{S}^d_+$. Furthermore, the learned flows in
Fisher-Flow can be further bootstrapped by leveraging Riemannian optimal
transport leading to improved training dynamics. We prove that the gradient
flow induced by Fisher-Flow is optimal in reducing the forward KL divergence.
  We evaluate Fisher-Flow on an array of synthetic and diverse real-world
benchmarks, including designing DNA Promoter, and DNA Enhancer sequences.
Empirically, we find that Fisher-Flow improves over prior diffusion and
flow-matching models on these benchmarks.

摘要：<paragraph>生成式建模在离散数据上最近已经获得了众多成功案例，其应用涵盖语言建模、生物序列设计和图结构分子数据。离散数据的优势生成式建模范例仍然是自回归，基于扩散或流匹配的最新替代方案在连续数据设置（例如图像或视频生成）中表现不佳。在这项工作中，我们介绍了 Fisher-Flow，这是一种用于离散数据的新型流匹配模型。Fisher-Flow 通过将离散数据上的分类分布视为驻留在具有其自然黎曼度量统计流形的点来考虑明显几何视角：$\textit{Fisher-Rao 度量}$。因此，我们证明离散数据本身可以连续地重新参数化为 $d$-超球面 $\mathbb{S}^d_+$ 的正象限上的点，这使我们能够通过沿着 $\mathbb{S}^d_+$ 的（封闭形式）测地线传输质量，以原则性方式定义将任何源分布映射到目标的流。此外，Fisher-Flow 中学习的流可以通过利用黎曼最优传输进一步自举，从而改善训练动态。我们证明 Fisher-Flow 诱导的梯度流在减少正向 KL 散度方面是最优的。我们在一系列合成和多样化的真实基准上评估 Fisher-Flow，包括设计 DNA 启动子和 DNA 增强子序列。根据经验，我们发现 Fisher-Flow 在这些基准上改进了先前的扩散和流匹配模型。</paragraph>

##### **Implicit In-context Learning**
2405.14660v1 by Zhuowei Li, Zihao Xu, Ligong Han, Yunhe Gao, Song Wen, Di Liu, Hao Wang, Dimitris N. Metaxas

In-context Learning (ICL) empowers large language models (LLMs) to adapt to
unseen tasks during inference by prefixing a few demonstration examples prior
to test queries. Despite its versatility, ICL incurs substantial computational
and memory overheads compared to zero-shot learning and is susceptible to the
selection and order of demonstration examples. In this work, we introduce
Implicit In-context Learning (I2CL), an innovative paradigm that addresses the
challenges associated with traditional ICL by absorbing demonstration examples
within the activation space. I2CL first generates a condensed vector
representation, namely a context vector, from the demonstration examples. It
then integrates the context vector during inference by injecting a linear
combination of the context vector and query activations into the model's
residual streams. Empirical evaluation on nine real-world tasks across three
model architectures demonstrates that I2CL achieves few-shot performance with
zero-shot cost and exhibits robustness against the variation of demonstration
examples. Furthermore, I2CL facilitates a novel representation of "task-ids",
enhancing task similarity detection and enabling effective transfer learning.
We provide a comprehensive analysis of I2CL, offering deeper insights into its
mechanisms and broader implications for ICL. The source code is available at:
https://github.com/LzVv123456/I2CL.

摘要：<paragraph>語境學習 (ICL) 讓大型語言模型 (LLM) 能夠在推論期間適應未見過任務，方法是在測試查詢之前加上幾個示範範例。儘管 ICL 具有多功能性，但與零次學習相比，它會產生大量的計算和記憶體開銷，並且容易受到示範範例的選擇和順序影響。在這項工作中，我們引入了隱式語境學習 (I2CL)，這是一種創新的範例，它透過在啟用空間中吸收示範範例來解決與傳統 ICL 相關的挑戰。I2CL 首先從示範範例產生一個濃縮的向量表示，即語境向量。然後，它透過將語境向量和查詢啟用項目的線性組合注入模型的殘差串流中，在推論期間整合語境向量。在三個模型架構上對九個真實世界任務進行的實證評估表明，I2CL 以零次成本實現了少量次學習效能，並且對示範範例的變化具有穩健性。此外，I2CL 促進了「任務識別碼」的新表示，增強了任務相似性偵測並實現有效的遷移學習。我們對 I2CL 進行了全面的分析，提供了對其機制和對 ICL 更廣泛影響的更深入見解。原始碼可在以下位置取得：https://github.com/LzVv123456/I2CL。</paragraph>

##### **Efficient Medical Question Answering with Knowledge-Augmented Question Generation**
2405.14654v1 by Julien Khlaut, Corentin Dancette, Elodie Ferreres, Alaedine Bennani, Paul Hérent, Pierre Manceron

In the expanding field of language model applications, medical knowledge
representation remains a significant challenge due to the specialized nature of
the domain. Large language models, such as GPT-4, obtain reasonable scores on
medical question answering tasks, but smaller models are far behind. In this
work, we introduce a method to improve the proficiency of a small language
model in the medical domain by employing a two-fold approach. We first
fine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to
generate questions similar to the downstream task, prompted with textbook
knowledge, and use them to fine-tune the model. Additionally, we introduce
ECN-QA, a novel medical question answering dataset containing ``progressive
questions'' composed of related sequential questions. We show the benefits of
our training strategy on this dataset. The study's findings highlight the
potential of small language models in the medical domain when appropriately
fine-tuned. The code and weights are available at
https://github.com/raidium-med/MQG.

摘要：在語言模型應用不斷擴展的領域中，由於該領域的專業性質，醫學知識表示仍然是一個重大的挑戰。大型語言模型，例如 GPT-4，在醫學問題解答任務中獲得了合理的評分，但較小的模型卻遠遠落後。在這項工作中，我們介紹了一種方法，通過採用雙重方法來提高小型語言模型在醫學領域的熟練度。我們首先在醫學教科書語料庫中對模型進行微調。然後，我們使用 GPT-4 生成與下游任務相似的問題，並提示教科書知識，並使用它們對模型進行微調。此外，我們還引入了 ECN-QA，這是一個新穎的醫學問題解答數據集，其中包含由相關順序問題組成的「漸進式問題」。我們展示了我們的訓練策略在這個數據集上的好處。這項研究的發現突出了小型語言模型在適當微調後在醫學領域的潛力。代碼和權重可在 https://github.com/raidium-med/MQG 獲得。

##### **Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models**
2405.14646v1 by Yiming Chen, Chen Zhang, Danqing Luo, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li

The automatic evaluation of natural language generation (NLG) systems
presents a long-lasting challenge. Recent studies have highlighted various
neural metrics that align well with human evaluations. Yet, the robustness of
these evaluators against adversarial perturbations remains largely
under-explored due to the unique challenges in obtaining adversarial data for
different NLG evaluation tasks. To address the problem, we introduce AdvEval, a
novel black-box adversarial framework against NLG evaluators. AdvEval is
specially tailored to generate data that yield strong disagreements between
human and victim evaluators. Specifically, inspired by the recent success of
large language models (LLMs) in text generation and evaluation, we adopt strong
LLMs as both the data generator and gold evaluator. Adversarial data are
automatically optimized with feedback from the gold and victim evaluator. We
conduct experiments on 12 victim evaluators and 11 NLG datasets, spanning tasks
including dialogue, summarization, and question evaluation. The results show
that AdvEval can lead to significant performance degradation of various victim
metrics, thereby validating its efficacy.

摘要：自然語言生成 (NLG) 系統的自動評估是一項長期的挑戰。最近的研究強調了各種與人類評估一致的神經指標。然而，由於在為不同的 NLG 評估任務獲取對抗性資料方面存在獨特挑戰，因此這些評估器對抗對抗性擾動的穩健性在很大程度上仍未得到探索。為了解決這個問題，我們引入了 AdvEval，一個針對 NLG 評估器的全新黑盒對抗性框架。AdvEval 專門用於生成在人類和受害者評估器之間產生強烈分歧的資料。具體來說，受大型語言模型 (LLM) 在文本生成和評估中近期成功的啟發，我們採用強大的 LLM 作為資料生成器和黃金評估器。對抗性資料會自動根據黃金和受害者評估器的回饋進行最佳化。我們對 12 個受害者評估器和 11 個 NLG 資料集進行了實驗，涵蓋對話、摘要和問題評估等任務。結果表明，AdvEval 可以導致各種受害者指標的效能顯著下降，從而驗證了其功效。

##### **Reinforcement Learning for Fine-tuning Text-to-speech Diffusion Models**
2405.14632v1 by Jingyi Chen, Ju-Seung Byun, Micha Elsner, Andrew Perrault

Recent advancements in generative models have sparked significant interest
within the machine learning community. Particularly, diffusion models have
demonstrated remarkable capabilities in synthesizing images and speech. Studies
such as those by Lee et al. [19], Black et al. [4], Wang et al. [36], and Fan
et al. [8] illustrate that Reinforcement Learning with Human Feedback (RLHF)
can enhance diffusion models for image synthesis. However, due to architectural
differences between these models and those employed in speech synthesis, it
remains uncertain whether RLHF could similarly benefit speech synthesis models.
In this paper, we explore the practical application of RLHF to diffusion-based
text-to-speech synthesis, leveraging the mean opinion score (MOS) as predicted
by UTokyo-SaruLab MOS prediction system [29] as a proxy loss. We introduce
diffusion model loss-guided RL policy optimization (DLPO) and compare it
against other RLHF approaches, employing the NISQA speech quality and
naturalness assessment model [21] and human preference experiments for further
evaluation. Our results show that RLHF can enhance diffusion-based
text-to-speech synthesis models, and, moreover, DLPO can better improve
diffusion models in generating natural and high quality speech audios.

摘要：<paragraph>生成模型的最新进展在机器学习社区中引起了极大的兴趣。特别是，扩散模型在图像和语音合成方面表现出了非凡的能力。李等人[19]、布莱克等人[4]、王等人[36]和范等人[8]等人的研究表明，人类反馈强化学习（RLHF）可以增强图像合成的扩散模型。然而，由于这些模型与用于语音合成的模型在架构上的差异，RLHF是否可以同样有利于语音合成模型仍然不确定。在本文中，我们探讨了RLHF在基于扩散的文本到语音合成中的实际应用，利用东京大学SaruLab MOS预测系统[29]预测的平均意见分（MOS）作为代理损失。我们引入了扩散模型损失引导的RL策略优化（DLPO），并将其与其他RLHF方法进行了比较，采用NISQA语音质量和自然度评估模型[21]和人类偏好实验进行进一步评估。我们的结果表明，RLHF可以增强基于扩散的文本到语音合成模型，而且，DLPO可以更好地改进扩散模型，生成自然且高质量的语音音频。</paragraph>

##### **Calibrated Self-Rewarding Vision Language Models**
2405.14622v1 by Yiyang Zhou, Zhiyuan Fan, Dongjie Cheng, Sihan Yang, Zhaorun Chen, Chenhang Cui, Xiyao Wang, Yun Li, Linjun Zhang, Huaxiu Yao

Large Vision-Language Models (LVLMs) have made substantial progress by
integrating pre-trained large language models (LLMs) and vision models through
instruction tuning. Despite these advancements, LVLMs often exhibit the
hallucination phenomenon, where generated text responses appear linguistically
plausible but contradict the input image, indicating a misalignment between
image and text pairs. This misalignment arises because the model tends to
prioritize textual information over visual input, even when both the language
model and visual representations are of high quality. Existing methods leverage
additional models or human annotations to curate preference data and enhance
modality alignment through preference optimization. These approaches may not
effectively reflect the target LVLM's preferences, making the curated
preferences easily distinguishable. Our work addresses these challenges by
proposing the Calibrated Self-Rewarding (CSR) approach, which enables the model
to self-improve by iteratively generating candidate responses, evaluating the
reward for each response, and curating preference data for fine-tuning. In the
reward modeling, we employ a step-wise strategy and incorporate visual
constraints into the self-rewarding process to place greater emphasis on visual
input. Empirical results demonstrate that CSR enhances performance and reduces
hallucinations across ten benchmarks and tasks, achieving substantial
improvements over existing methods by 7.62%. Our empirical results are further
supported by rigorous theoretical analysis, under mild assumptions, verifying
the effectiveness of introducing visual constraints into the self-rewarding
paradigm. Additionally, CSR shows compatibility with different vision-language
models and the ability to incrementally improve performance through iterative
fine-tuning. Our data and code are available at
https://github.com/YiyangZhou/CSR.

摘要：大型視覺語言模型 (LVLMs) 透過指令調整整合預先訓練的大型語言模型 (LLMs) 和視覺模型，取得了顯著進展。儘管有這些進展，LVLMs 經常展現出幻覺現象，其中產生的文字回應在語言上看似合理，但與輸入影像相矛盾，這表示影像和文字配對之間的錯位。這種錯位產生，是因為模型傾向於優先考慮文字資訊而非視覺輸入，即使語言模型和視覺表徵都是高品質的。現有方法利用額外的模型或人工註解來策劃偏好資料，並透過偏好最佳化增強模態對齊。這些方法可能無法有效反映目標 LVLM 的偏好，使得策劃的偏好容易區分。我們的研究透過提議校準自我獎勵 (CSR) 方法來解決這些挑戰，這使模型能夠透過反覆產生候選回應、評估每個回應的獎勵，以及策劃用於微調的偏好資料來自我改善。在獎勵建模中，我們採用逐步策略，並將視覺約束納入自我獎勵過程中，以更強調視覺輸入。實證結果顯示，CSR 提升了效能，並減少了十個基準和任務中的幻覺，比現有方法大幅提升了 7.62%。我們的實證結果進一步獲得嚴謹理論分析的支持，在溫和的假設下，驗證了在自我獎勵範例中引入視覺約束的有效性。此外，CSR 顯示出與不同視覺語言模型的相容性，以及透過反覆微調逐步提升效能的能力。我們的資料和程式碼可在 https://github.com/YiyangZhou/CSR 取得。

##### **Explaining Multi-modal Large Language Models by Analyzing their Vision Perception**
2405.14612v1 by Loris Giulivi, Giacomo Boracchi

Multi-modal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in understanding and generating content across various modalities,
such as images and text. However, their interpretability remains a challenge,
hindering their adoption in critical applications. This research proposes a
novel approach to enhance the interpretability of MLLMs by focusing on the
image embedding component. We combine an open-world localization model with a
MLLM, thus creating a new architecture able to simultaneously produce text and
object localization outputs from the same vision embedding. The proposed
architecture greatly promotes interpretability, enabling us to design a novel
saliency map to explain any output token, to identify model hallucinations, and
to assess model biases through semantic adversarial perturbations.

摘要：多模态大型语言模型 (MLLM) 已展示出在理解和生成跨越各种模态（例如图像和文本）的内容方面的非凡能力。然而，它们的解释性仍然是一个挑战，阻碍了它们在关键应用程序中的采用。本研究提出了一种通过关注图像嵌入组件来增强 MLLM 可解释性的新方法。我们将开放世界定位模型与 MLLM 相结合，从而创建了一种新的架构，能够从相同的视觉嵌入中同时产生文本和对象定位输出。所提出的架构极大地提高了可解释性，使我们能够设计一个新颖的显着性图来解释任何输出标记，识别模型幻觉，并通过语义对抗扰动评估模型偏差。

##### **ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification**
2405.14608v1 by Xuan-May Le, Ling Luo, Uwe Aickelin, Minh-Tuan Tran

Multivariate time series classification (MTSC) has attracted significant
research attention due to its diverse real-world applications. Recently,
exploiting transformers for MTSC has achieved state-of-the-art performance.
However, existing methods focus on generic features, providing a comprehensive
understanding of data, but they ignore class-specific features crucial for
learning the representative characteristics of each class. This leads to poor
performance in the case of imbalanced datasets or datasets with similar overall
patterns but differing in minor class-specific details. In this paper, we
propose a novel Shapelet Transformer (ShapeFormer), which comprises
class-specific and generic transformer modules to capture both of these
features. In the class-specific module, we introduce the discovery method to
extract the discriminative subsequences of each class (i.e. shapelets) from the
training set. We then propose a Shapelet Filter to learn the difference
features between these shapelets and the input time series. We found that the
difference feature for each shapelet contains important class-specific
features, as it shows a significant distinction between its class and others.
In the generic module, convolution filters are used to extract generic features
that contain information to distinguish among all classes. For each module, we
employ the transformer encoder to capture the correlation between their
features. As a result, the combination of two transformer modules allows our
model to exploit the power of both types of features, thereby enhancing the
classification performance. Our experiments on 30 UEA MTSC datasets demonstrate
that ShapeFormer has achieved the highest accuracy ranking compared to
state-of-the-art methods. The code is available at
https://github.com/xuanmay2701/shapeformer.

摘要：多變量時間序列分類 (MTSC) 由於其多樣化的真實世界應用而引起了重大的研究關注。最近，利用Transformer進行 MTSC 已實現了最先進的性能。然而，現有方法專注於通用特徵，提供對數據的全面理解，但它們忽略了對學習每個類別的代表性特徵至關重要的類別特定特徵。這導致在不平衡的數據集或具有相似整體模式但類別特定細節不同的數據集的情況下性能不佳。在本文中，我們提出了一個新穎的 Shapelet Transformer（ShapeFormer），它包含類別特定和通用Transformer模組，以擷取這兩個特徵。在類別特定模組中，我們引入了發現方法，從訓練集中提取每個類別的區分子序列（即 shapelets）。然後，我們提出了一個 Shapelet Filter 來學習這些 shapelets 與輸入時間序列之間的差異特徵。我們發現每個 shapelet 的差異特徵包含重要的類別特定特徵，因為它顯示了其類別與其他類別之間的顯著區別。在通用模組中，卷積濾波器用於提取包含區分所有類別的資訊的通用特徵。對於每個模組，我們採用Transformer編碼器來擷取其特徵之間的關聯。因此，兩個Transformer模組的組合使我們的模型能夠利用兩種特徵的力量，從而增強分類性能。我們在 30 個 UEA MTSC 數據集上的實驗表明，與最先進的方法相比，ShapeFormer 已經取得了最高的準確率排名。程式碼可以在 https://github.com/xuanmay2701/shapeformer 獲得。

##### **Logical Characterizations of Recurrent Graph Neural Networks with Reals and Floats**
2405.14606v1 by Veeti Ahvonen, Damian Heiman, Antti Kuusisto, Carsten Lutz

In pioneering work from 2019, Barcel\'o and coauthors identified logics that
precisely match the expressive power of constant iteration-depth graph neural
networks (GNNs) relative to properties definable in first-order logic. In this
article, we give exact logical characterizations of recurrent GNNs in two
scenarios: (1) in the setting with floating-point numbers and (2) with reals.
For floats, the formalism matching recurrent GNNs is a rule-based modal logic
with counting, while for reals we use a suitable infinitary modal logic, also
with counting. These results give exact matches between logics and GNNs in the
recurrent setting without relativising to a background logic in either case,
but using some natural assumptions about floating-point arithmetic. Applying
our characterizations, we also prove that, relative to graph properties
definable in monadic second-order logic (MSO), our infinitary and rule-based
logics are equally expressive. This implies that recurrent GNNs with reals and
floats have the same expressive power over MSO-definable properties and shows
that, for such properties, also recurrent GNNs with reals are characterized by
a (finitary!) rule-based modal logic. In the general case, in contrast, the
expressive power with floats is weaker than with reals. In addition to
logic-oriented results, we also characterize recurrent GNNs, with both reals
and floats, via distributed automata, drawing links to distributed computing
models.

摘要：在 2019 年的开创性工作中，Barcel\'o 和合著者识别出逻辑，其精确匹配恒定迭代深度图神经网络 (GNN) 的表达能力，相对于一阶逻辑中可定义的属性。在本文中，我们对两种情况下的循环 GNN 给出了精确的逻辑表征：(1) 在浮点数设置中和 (2) 在实数中。对于浮点数，与循环 GNN 匹配的形式主义是一种基于规则的模态逻辑，带有计数，而对于实数，我们使用一种合适的无限模态逻辑，也带有计数。这些结果在循环设置中给出了逻辑和 GNN 之间的精确匹配，在任何情况下都不相对于背景逻辑，但使用了一些关于浮点运算的自然假设。应用我们的表征，我们还证明，相对于单子二阶逻辑 (MSO) 中可定义的图属性，我们的无限和基于规则的逻辑具有同等的表达能力。这意味着具有实数和浮点数的循环 GNN 对于 MSO 可定义的属性具有相同的表达能力，并表明，对于此类属性，具有实数的循环 GNN 也由（有限！）基于规则的模态逻辑表征。相反，在一般情况下，使用浮点数的表达能力弱于使用实数的表达能力。除了面向逻辑的结果外，我们还通过分布式自动机表征具有实数和浮点数的循环 GNN，从而建立与分布式计算模型的联系。

##### **A Watermark for Low-entropy and Unbiased Generation in Large Language Models**
2405.14604v1 by Minjia Mao, Dongjun Wei, Zeyu Chen, Xiao Fang, Michael Chau

Recent advancements in large language models (LLMs) have highlighted the risk
of misuse, raising concerns about accurately detecting LLM-generated content. A
viable solution for the detection problem is to inject imperceptible
identifiers into LLMs, known as watermarks. Previous work demonstrates that
unbiased watermarks ensure unforgeability and preserve text quality by
maintaining the expectation of the LLM output probability distribution.
However, previous unbiased watermarking methods are impractical for local
deployment because they rely on accesses to white-box LLMs and input prompts
during detection. Moreover, these methods fail to provide statistical
guarantees for the type II error of watermark detection. This study proposes
the Sampling One Then Accepting (STA-1) method, an unbiased watermark that does
not require access to LLMs nor prompts during detection and has statistical
guarantees for the type II error. Moreover, we propose a novel tradeoff between
watermark strength and text quality in unbiased watermarks. We show that in
low-entropy scenarios, unbiased watermarks face a tradeoff between watermark
strength and the risk of unsatisfactory outputs. Experimental results on
low-entropy and high-entropy datasets demonstrate that STA-1 achieves text
quality and watermark strength comparable to existing unbiased watermarks, with
a low risk of unsatisfactory outputs. Implementation codes for this study are
available online.

摘要：大型語言模型 (LLM) 的最新進展突顯了誤用風險，引發了準確檢測 LLM 生成的內容的擔憂。檢測問題的可行解決方案是將難以察覺的識別符注入 LLM，稱為浮水印。先前的研究表明，無偏浮水印可確保不可偽造性並透過維持 LLM 輸出機率分佈的預期值來保留文字品質。然而，先前的無偏浮水印方法對於本地部署而言不切實際，因為它們依賴於在檢測期間存取白盒 LLM 和輸入提示。此外，這些方法無法為浮水印檢測的第二型錯誤提供統計保證。本研究提出採樣一個然後接受 (STA-1) 方法，這是一個無偏浮水印，在檢測期間不需要存取 LLM 或提示，並且對第二型錯誤有統計保證。此外，我們提出無偏浮水印中浮水印強度和文字品質之間的新權衡。我們表明，在低熵場景中，無偏浮水印面臨浮水印強度和不令人滿意的輸出風險之間的權衡。在低熵和高熵資料集上的實驗結果表明，STA-1 達到了與現有無偏浮水印相當的文字品質和浮水印強度，且不令人滿意的輸出風險較低。本研究的實作程式碼可在線上取得。

##### **A FAIR and Free Prompt-based Research Assistant**
2405.14601v1 by Mahsa Shamsabadi, Jennifer D'Souza

This demo will present the Research Assistant (RA) tool developed to assist
with six main types of research tasks defined as standardized instruction
templates, instantiated with user input, applied finally as prompts to
well-known--for their sophisticated natural language processing abilities--AI
tools, such as ChatGPT (https://chat.openai.com/) and Gemini
(https://gemini.google.com/app). The six research tasks addressed by RA are:
creating FAIR research comparisons, ideating research topics, drafting grant
applications, writing scientific blogs, aiding preliminary peer reviews, and
formulating enhanced literature search queries. RA's reliance on generative AI
tools like ChatGPT or Gemini means the same research task assistance can be
offered in any scientific discipline. We demonstrate its versatility by sharing
RA outputs in Computer Science, Virology, and Climate Science, where the output
with the RA tool assistance mirrored that from a domain expert who performed
the same research task.

摘要：這個示範將展示研究助理 (RA) 工具，該工具的開發目的是協助進行六種類型的研究任務，這些任務定義為標準化的指令範本，並使用使用者輸入進行實例化，最後將其作為提示套用至以其複雜的自然語言處理能力而聞名的 AI 工具，例如 ChatGPT (https://chat.openai.com/) 和 Gemini (https://gemini.google.com/app)。RA 處理的六項研究任務包括：建立 FAIR 研究比較、構思研究主題、起草補助金申請、撰寫科學部落格、協助初步同行評審以及制定增強的文獻搜尋查詢。RA 依賴 ChatGPT 或 Gemini 等生成式 AI 工具，表示可以在任何科學領域提供相同的研究任務協助。我們透過分享 RA 在電腦科學、病毒學和氣候科學中的輸出，來展示其多功能性，其中使用 RA 工具協助產生的輸出與執行相同研究任務的領域專家所產生的輸出相當。

##### **Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs**
2405.14597v1 by Qingyuan Li, Ran Meng, Yiduo Li, Bo Zhang, Yifan Lu, Yerui Sun, Lin Ma, Yuchen Xie

We introduce Integer Scale, a novel post-training quantization scheme for
large language models that effectively resolves the inference bottleneck in
current fine-grained quantization approaches while maintaining similar
accuracies. Integer Scale is a free lunch as it requires no extra calibration
or fine-tuning which will otherwise incur additional costs. It can be used
plug-and-play for most fine-grained quantization methods. Its integration
results in at most 1.85x end-to-end speed boost over the original counterpart
with comparable accuracy. Additionally, due to the orchestration of the
proposed Integer Scale and fine-grained quantization, we resolved the
quantization difficulty for Mixtral-8x7B and LLaMA-3 models with negligible
performance degradation, and it comes with an end-to-end speed boost of 2.13x,
and 2.31x compared with their FP16 versions respectively.

摘要：我們引入了整數量化，這是一種大型語言模型的創新訓練後量化方案，可有效解決當前細粒度量化方法中的推理瓶頸，同時保持類似的準確度。整數量化是一種免費的午餐，因為它不需要額外的校準或微調，否則會產生額外的成本。它可以用於大多數細粒度量化方法的即插即用。它的整合導致端到端速度提升至多 1.85 倍，與原始對應項相比，具有可比的準確度。此外，由於所提出的整數量化和細粒度量化的協調，我們以可忽略的性能下降解決了 Mixtral-8x7B 和 LLaMA-3 模型的量化難度，並且與它們的 FP16 版本相比，分別具有 2.13 倍和 2.31 倍的端到端速度提升。

##### **Data Augmentation Techniques for Process Extraction from Scientific Publications**
2405.14594v1 by Yuni Susanti

We present data augmentation techniques for process extraction tasks in
scientific publications. We cast the process extraction task as a sequence
labeling task where we identify all the entities in a sentence and label them
according to their process-specific roles. The proposed method attempts to
create meaningful augmented sentences by utilizing (1) process-specific
information from the original sentence, (2) role label similarity, and (3)
sentence similarity. We demonstrate that the proposed methods substantially
improve the performance of the process extraction model trained on chemistry
domain datasets, up to 12.3 points improvement in performance accuracy
(F-score). The proposed methods could potentially reduce overfitting as well,
especially when training on small datasets or in a low-resource setting such as
in chemistry and other scientific domains.

摘要：我們提出用於科學出版物中流程萃取任務的資料擴充技術。我們將流程萃取任務視為一個序列標記任務，在任務中我們辨識句子中的所有實體，並根據它們特定於流程的角色標記它們。所提出的方法嘗試透過利用 (1) 原始句子的特定於流程的資訊、(2) 角色標籤相似度，以及 (3) 句子相似度，來建立有意義的擴充句子。我們證明所提出的方法大幅改善在化學領域資料集上訓練的流程萃取模型的效能，在效能準確度 (F-score) 上改善達 12.3 個百分點。所提出的方法也有可能減少過度擬合，特別是在小資料集上訓練，或在低資源設定中，例如化學和其他科學領域時。

##### **Base of RoPE Bounds Context Length**
2405.14591v1 by Xin Men, Mingyu Xu, Bingning Wang, Qingyu Zhang, Hongyu Lin, Xianpei Han, Weipeng Chen

Position embedding is a core component of current Large Language Models
(LLMs). Rotary position embedding (RoPE), a technique that encodes the position
information with a rotation matrix, has been the de facto choice for position
embedding in many LLMs, such as the Llama series. RoPE has been further
utilized to extend long context capability, which is roughly based on adjusting
the \textit{base} parameter of RoPE to mitigate out-of-distribution (OOD)
problems in position embedding. However, in this paper, we find that LLMs may
obtain a superficial long-context ability based on the OOD theory. We revisit
the role of RoPE in LLMs and propose a novel property of long-term decay, we
derive that the \textit{base of RoPE bounds context length}: there is an
absolute lower bound for the base value to obtain certain context length
capability. Our work reveals the relationship between context length and RoPE
base both theoretically and empirically, which may shed light on future long
context training.

摘要：位置嵌入是當前大型語言模型 (LLM) 的核心組成部分。旋轉位置嵌入 (RoPE) 是一種使用旋轉矩陣編碼位置資訊的技術，一直是許多 LLM 中位置嵌入的實際選擇，例如 Llama 系列。RoPE 已進一步用於擴展長語境功能，這大致基於調整 RoPE 的「base」參數以減輕位置嵌入中的分布外 (OOD) 問題。然而，在本文中，我們發現 LLM 可能基於 OOD 理論獲得表面的長語境能力。我們重新審視 RoPE 在 LLM 中的角色，並提出長期衰減的新特性，我們推論出「RoPE 的 base 限制語境長度」：存在一個絕對下限的 base 值才能獲得一定的語境長度能力。我們的研究在理論和經驗上揭示了語境長度和 RoPE base 之間的關係，這可能為未來的長語境訓練提供啟發。

##### **Representation noising effectively prevents harmful fine-tuning on LLMs**
2405.14577v1 by Domenic Rosati, Jan Wehner, Kai Williams, Łukasz Bartoszcze, David Atanasov, Robie Gonzales, Subhabrata Majumdar, Carsten Maple, Hassan Sajjad, Frank Rudzicz

Releasing open-source large language models (LLMs) presents a dual-use risk
since bad actors can easily fine-tune these models for harmful purposes. Even
without the open release of weights, weight stealing and fine-tuning APIs make
closed models vulnerable to harmful fine-tuning attacks (HFAs). While safety
measures like preventing jailbreaks and improving safety guardrails are
important, such measures can easily be reversed through fine-tuning. In this
work, we propose Representation Noising (RepNoise), a defence mechanism that is
effective even when attackers have access to the weights and the defender no
longer has any control. RepNoise works by removing information about harmful
representations such that it is difficult to recover them during fine-tuning.
Importantly, our defence is also able to generalize across different subsets of
harm that have not been seen during the defence process. Our method does not
degrade the general capability of LLMs and retains the ability to train the
model on harmless tasks. We provide empirical evidence that the effectiveness
of our defence lies in its "depth": the degree to which information about
harmful representations is removed across all layers of the LLM.

摘要：釋出開放原始碼大型語言模型 (LLM) 呈現出雙重風險，因為不法分子可以輕易微調這些模型以進行有害目的。即使沒有公開權重，權重竊取和微調 API 也會讓封閉模型容易受到有害的微調攻擊 (HFA)。雖然預防越獄和改善安全防護措施等安全措施很重要，但此類措施可以輕易透過微調來逆轉。在這項工作中，我們提出表徵雜訊 (RepNoise)，一種防禦機制，即使攻擊者可以存取權重，而且防禦者不再有任何控制權，它仍然有效。RepNoise 的運作方式是移除有關有害表徵的資訊，使其難以在微調期間復原。重要的是，我們的防禦也能概括到防禦過程中未曾見過的不同有害子集。我們的防禦方法不會降低 LLM 的一般能力，並保留訓練模型執行無害任務的能力。我們提供實證證據證明，我們的防禦有效性在於其「深度」：移除有關有害表徵的資訊的程度遍及 LLM 的所有層級。

##### **AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents**
2405.14573v1 by Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyamagundlu, Timothy Lillicrap, Oriana Riva

Autonomous agents that execute human tasks by controlling computers can
enhance human productivity and application accessibility. Yet, progress in this
field will be driven by realistic and reproducible benchmarks. We present
AndroidWorld, a fully functioning Android environment that provides reward
signals for 116 programmatic task workflows across 20 real world Android
applications. Unlike existing interactive environments, which provide a static
test set, AndroidWorld dynamically constructs tasks that are parameterized and
expressed in natural language in unlimited ways, thus enabling testing on a
much larger and realistic suite of tasks. Reward signals are derived from the
computer's system state, making them durable across task variations and
extensible across different apps. To demonstrate AndroidWorld's benefits and
mode of operation, we introduce a new computer control agent, M3A. M3A can
complete 30.6% of the AndroidWorld's tasks, leaving ample room for future work.
Furthermore, we adapt a popular desktop web agent to work on Android, which we
find to be less effective on mobile, suggesting future research is needed to
achieve universal, cross-domain agents. Finally, we conduct a robustness
analysis by testing M3A against a range of task variations on a representative
subset of tasks, demonstrating that variations in task parameters can
significantly alter the complexity of a task and therefore an agent's
performance, highlighting the importance of testing agents under diverse
conditions. AndroidWorld and the experiments in this paper are available at
https://github.com/google-research/android_world.

摘要：<paragraph>透過控制電腦執行人類任務的自主代理人可以
提升人類生產力和應用程式可及性。然而，在這個
領域的進展將由實際且可複製的基準驅動。我們提出
AndroidWorld，一個功能齊全的 Android 環境，提供獎勵
訊號，用於 20 個真實世界 Android 應用程式中的 116 個程式化任務工作流程。與提供靜態
測試集的現有互動式環境不同，AndroidWorld 動態建構以無限方式參數化並以自然語言表達的任務，因此能夠在更大且更實際的任務組上進行測試。獎勵訊號來自電腦的系統狀態，使它們在任務變異中具有持久性，並可擴充到不同的應用程式。為了展示 AndroidWorld 的好處和運作模式，我們引入了一個新的電腦控制代理人 M3A。M3A 可以完成 30.6% 的 AndroidWorld 任務，為未來的任務留下了充足的空間。此外，我們調整了一個流行的桌面網路代理人，使其可以在 Android 上執行，我們發現它在行動裝置上的效果較差，這表示需要未來研究才能達成通用、跨網域的代理人。最後，我們透過在具有代表性的任務子集中針對 M3A 測試一系列任務變異來進行穩健性分析，證明任務參數的變異會顯著改變任務的複雜性，因此也會改變代理人的
效能，這突顯了在不同條件下測試代理人的重要性。本文中的 AndroidWorld 和實驗可在
https://github.com/google-research/android_world 取得。</paragraph>

##### **PrivCirNet: Efficient Private Inference via Block Circulant Transformation**
2405.14569v1 by Tianshi Xu, Lemeng Wu, Runsheng Wang, Meng Li

Homomorphic encryption (HE)-based deep neural network (DNN) inference
protects data and model privacy but suffers from significant computation
overhead. We observe transforming the DNN weights into circulant matrices
converts general matrix-vector multiplications into HE-friendly 1-dimensional
convolutions, drastically reducing the HE computation cost. Hence, in this
paper, we propose \method, a protocol/network co-optimization framework based
on block circulant transformation. At the protocol level, PrivCirNet customizes
the HE encoding algorithm that is fully compatible with the block circulant
transformation and reduces the computation latency in proportion to the block
size. At the network level, we propose a latency-aware formulation to search
for the layer-wise block size assignment based on second-order information.
PrivCirNet also leverages layer fusion to further reduce the inference cost. We
compare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S\&P
2024) and the HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and
Vision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by
$5.0\times$ and $1.3\times$ with iso-accuracy over Bolt, respectively, and
improves accuracy by $4.1\%$ and $12\%$ over SpENCNN, respectively. For
MobileNetV2 on ImageNet, PrivCirNet achieves $1.7\times$ lower latency and
$4.2\%$ better accuracy over Bolt and SpENCNN, respectively. Our code and
checkpoints are available in the supplementary materials.

摘要：<paragraph>基於同態加密 (HE) 的深度神經網路 (DNN) 推論保護資料和模型隱私，但會帶來顯著的計算開銷。我們觀察到將 DNN 權重轉換成循環矩陣，會將一般矩陣-向量乘法轉換成 HE 友好的 1 維卷積，大幅降低 HE 計算成本。因此，在本文中，我們提出 PrivCirNet，一種基於區塊循環轉換的協定/網路共同最佳化架構。在協定層級，PrivCirNet 客製化 HE 編碼演算法，與區塊循環轉換完全相容，並根據區塊大小成比例地減少計算延遲。在網路層級，我們提出一個延遲感知公式，根據二階資訊搜尋層級區塊大小配置。PrivCirNet 也利用層融合進一步降低推論成本。我們將 PrivCirNet 與最先進的基於 HE 的架構 Bolt（IEEE S&P 2024）和 HE 友好的剪枝方法 SpENCNN（ICML 2023）進行比較。對於 Tiny ImageNet 上的 ResNet-18 和 Vision Transformer (ViT)，PrivCirNet 分別以與 Bolt 相同的準確度將延遲降低了 5.0 倍和 1.3 倍，並分別比 SpENCNN 提高了 4.1% 和 12% 的準確度。對於 ImageNet 上的 MobileNetV2，PrivCirNet 分別比 Bolt 和 SpENCNN 降低了 1.7 倍的延遲，並提高了 4.2% 的準確度。我們的程式碼和檢查點可在補充資料中取得。</paragraph>

##### **Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet**
2405.14563v1 by Loris Giulivi, Giacomo Boracchi

Advances in multi-modal embeddings, and in particular CLIP, have recently
driven several breakthroughs in Computer Vision (CV). CLIP has shown impressive
performance on a variety of tasks, yet, its inherently opaque architecture may
hinder the application of models employing CLIP as backbone, especially in
fields where trust and model explainability are imperative, such as in the
medical domain. Current explanation methodologies for CV models rely on
Saliency Maps computed through gradient analysis or input perturbation.
However, these Saliency Maps can only be computed to explain classes relevant
to the end task, often smaller in scope than the backbone training classes. In
the context of models implementing CLIP as their vision backbone, a substantial
portion of the information embedded within the learned representations is thus
left unexplained.
  In this work, we propose Concept Visualization (ConVis), a novel saliency
methodology that explains the CLIP embedding of an image by exploiting the
multi-modal nature of the embeddings. ConVis makes use of lexical information
from WordNet to compute task-agnostic Saliency Maps for any concept, not
limited to concepts the end model was trained on. We validate our use of
WordNet via an out of distribution detection experiment, and test ConVis on an
object localization benchmark, showing that Concept Visualizations correctly
identify and localize the image's semantic content. Additionally, we perform a
user study demonstrating that our methodology can give users insight on the
model's functioning.

摘要：<paragraph>多模態嵌入的進展，特別是 CLIP，最近推動了電腦視覺 (CV) 的多項突破。CLIP 已在各種任務中展現出令人印象深刻的效能，然而，其本質上不透明的架構可能會阻礙採用以 CLIP 為基礎架構的模型，特別是在需要信任和模型可解釋性的領域，例如醫療領域。目前針對 CV 模型的解釋方法依賴於透過梯度分析或輸入擾動計算出的顯著性圖。然而，這些顯著性圖只能計算出與最終任務相關的類別，其範圍通常小於基礎架構訓練類別。在將 CLIP 作為其視覺基礎架構實作的模型中，學習表徵中嵌入的大部分資訊因此無法解釋。
  在這項工作中，我們提出概念視覺化 (ConVis)，這是一種新穎的顯著性方法，透過利用嵌入的多模態特性來解釋影像的 CLIP 嵌入。ConVis 利用 WordNet 中的詞彙資訊，為任何概念計算與任務無關的顯著性圖，而不限於最終模型訓練的那些概念。我們透過一個分佈檢測實驗驗證我們使用 WordNet 的方式，並在一個物件定位基準測試中測試 ConVis，顯示概念視覺化可以正確識別和定位影像的語義內容。此外，我們進行了一項使用者研究，證明我們的方法可以讓使用者深入了解模型的功能。</paragraph>

##### **Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models**
2405.14555v1 by Abhishek Kumar, Sarfaroz Yunusov, Ali Emami

Research on Large Language Models (LLMs) has often neglected subtle biases
that, although less apparent, can significantly influence the models' outputs
toward particular social narratives. This study addresses two such biases
within LLMs: \textit{representative bias}, which denotes a tendency of LLMs to
generate outputs that mirror the experiences of certain identity groups, and
\textit{affinity bias}, reflecting the models' evaluative preferences for
specific narratives or viewpoints. We introduce two novel metrics to measure
these biases: the Representative Bias Score (RBS) and the Affinity Bias Score
(ABS), and present the Creativity-Oriented Generation Suite (CoGS), a
collection of open-ended tasks such as short story writing and poetry
composition, designed with customized rubrics to detect these subtle biases.
Our analysis uncovers marked representative biases in prominent LLMs, with a
preference for identities associated with being white, straight, and men.
Furthermore, our investigation of affinity bias reveals distinctive evaluative
patterns within each model, akin to `bias fingerprints'. This trend is also
seen in human evaluators, highlighting a complex interplay between human and
machine bias perceptions.

摘要：大型語言模型 (LLM) 的研究經常忽略微妙的偏見，儘管這些偏見較不明顯，但仍可能顯著影響模型的輸出，使其傾向於特定的社會敘述。本研究探討了 LLM 中的兩種此類偏見：\textit{代表性偏見}，表示 LLM 傾向於產生反映特定身分群體經驗的輸出，以及\textit{親和力偏見}，反映模型對特定敘述或觀點的評估偏好。我們引入了兩個新指標來衡量這些偏見：代表性偏見分數 (RBS) 和親和力偏見分數 (ABS)，並提出了以創造力為導向的生成套件 (CoGS)，這是一系列開放式任務，例如短篇小說寫作和詩歌創作，並設計了自訂評分標準來偵測這些微妙的偏見。我們的分析揭露了顯著的代表性偏見在著名的 LLM 中，偏好與白人、異性戀和男性相關的身分。此外，我們對親和力偏見的研究揭示了每個模型中獨特的評估模式，類似於「偏見指紋」。這種趨勢也見於人類評估者，突顯了人類和機器偏見感知之間的複雜交互作用。

##### **UDKAG: Augmenting Large Vision-Language Models with Up-to-Date Knowledge**
2405.14554v1 by Chuanhao Li, Zhen Li, Chenchen Jing, Shuo Liu, Wenqi Shao, Yuwei Wu, Ping Luo, Yu Qiao, Kaipeng Zhang

Large vision-language models (LVLMs) are ignorant of the up-to-date
knowledge, such as LLaVA series, because they cannot be updated frequently due
to the large amount of resources required, and therefore fail in many cases.
For example, if a LVLM was released on January 2024, and it wouldn't know the
detailed plot of the new movie Dune 2, which wasn't released until February
2024. To solve the problem, a promising solution is to provide LVLMs with
up-to-date knowledge via internet search during inference, i.e.,
internet-augmented generation (IAG), which is already integrated in some
closed-source commercial LVLMs such as GPT-4V. However, the specific mechanics
underpinning them remain a mystery. In this paper, we propose a plug-and-play
framework, for augmenting existing LVLMs in handling visual question answering
(VQA) about up-to-date knowledge, dubbed UDKAG. A hierarchical filtering model
is trained to effectively and efficiently find the most helpful content from
the websites returned by a search engine to prompt LVLMs with up-to-date
knowledge. To train the model and evaluate our framework's performance, we
propose a pipeline to automatically generate news-related VQA samples to
construct a dataset, dubbed UDK-VQA. A multi-model voting mechanism is
introduced to label the usefulness of website/content for VQA samples to
construct the training set. Experimental results demonstrate the effectiveness
of our framework, outperforming GPT-4V by about 25% in accuracy.

摘要：大型視覺語言模型 (LVLMs) 對於最新知識一無所知，例如 LLaVA 系列，因為它們無法頻繁更新，因為需要大量的資源，因此在許多情況下會失敗。例如，如果 LVLM 在 2024 年 1 月發布，它將不知道直到 2024 年 2 月才發布的新電影《沙丘 2》的詳細情節。為了解決這個問題，一個有希望的解決方案是透過網際網路搜尋提供 LVLMs 最新知識，也就是網路增強生成 (IAG)，這已經整合在一些閉源商業 LVLMs 中，例如 GPT-4V。然而，支撐它們的具體機制仍然是個謎。在本文中，我們提出了一個即插即用的架構，用於增強現有的 LVLMs，以處理有關最新知識的視覺問題解答 (VQA)，稱為 UDKAG。訓練一個階層式過濾模型，從搜尋引擎返回的網站中有效率地找到最有用的內容，以提示 LVLMs 具有最新知識。為了訓練模型並評估我們架構的效能，我們提出了一個管道，自動產生與新聞相關的 VQA 範例，以建構一個名為 UDK-VQA 的資料集。引入多模型投票機制，標記網站/內容對 VQA 範例的有用性，以建構訓練集。實驗結果證明了我們架構的有效性，準確率比 GPT-4V 高出約 25%。

##### **Regressor-free Molecule Generation to Support Drug Response Prediction**
2405.14536v1 by Kun Li, Xiuwen Gong, Shirui Pan, Jia Wu, Bo Du, Wenbin Hu

Drug response prediction (DRP) is a crucial phase in drug discovery, and the
most important metric for its evaluation is the IC50 score. DRP results are
heavily dependent on the quality of the generated molecules. Existing molecule
generation methods typically employ classifier-based guidance, enabling
sampling within the IC50 classification range. However, these methods fail to
ensure the sampling space range's effectiveness, generating numerous
ineffective molecules. Through experimental and theoretical study, we
hypothesize that conditional generation based on the target IC50 score can
obtain a more effective sampling space. As a result, we introduce
regressor-free guidance molecule generation to ensure sampling within a more
effective space and support DRP. Regressor-free guidance combines a diffusion
model's score estimation with a regression controller model's gradient based on
number labels. To effectively map regression labels between drugs and cell
lines, we design a common-sense numerical knowledge graph that constrains the
order of text representations. Experimental results on the real-world dataset
for the DRP task demonstrate our method's effectiveness in drug discovery. The
code is available at:https://anonymous.4open.science/r/RMCD-DBD1.

摘要：藥物反應預測 (DRP) 是藥物發現中的關鍵階段，而評估其最重要的指標是 IC50 分數。DRP 結果高度依賴於生成分子的品質。現有的分子生成方法通常採用基於分類器的引導，在 IC50 分類範圍內進行取樣。然而，這些方法無法確保取樣空間範圍的有效性，會生成大量無效分子。透過實驗和理論研究，我們假設基於目標 IC50 分數的條件式生成可以取得更有效的取樣空間。因此，我們引入了無回歸器引導分子生成，以確保在更有效的空間內取樣，並支援 DRP。無回歸器引導結合了擴散模型的分數估計與基於數字標籤的回歸控制器模型的梯度。為了有效地對藥物和細胞系之間的回歸標籤進行對應，我們設計了一個常識數值知識圖，用於限制文字表示的順序。針對 DRP 任務的真實世界資料集的實驗結果證明了我們的方法在藥物發現中的有效性。程式碼可於以下網址取得：https://anonymous.4open.science/r/RMCD-DBD1。

##### **Exploring Alignment in Shared Cross-lingual Spaces**
2405.14535v1 by Basel Mousi, Nadir Durrani, Fahim Dalvi, Majd Hawasly, Ahmed Abdelali

Despite their remarkable ability to capture linguistic nuances across diverse
languages, questions persist regarding the degree of alignment between
languages in multilingual embeddings. Drawing inspiration from research on
high-dimensional representations in neural language models, we employ
clustering to uncover latent concepts within multilingual models. Our analysis
focuses on quantifying the \textit{alignment} and \textit{overlap} of these
concepts across various languages within the latent space. To this end, we
introduce two metrics \CA{} and \CO{} aimed at quantifying these aspects,
enabling a deeper exploration of multilingual embeddings. Our study encompasses
three multilingual models (\texttt{mT5}, \texttt{mBERT}, and \texttt{XLM-R})
and three downstream tasks (Machine Translation, Named Entity Recognition, and
Sentiment Analysis). Key findings from our analysis include: i) deeper layers
in the network demonstrate increased cross-lingual \textit{alignment} due to
the presence of language-agnostic concepts, ii) fine-tuning of the models
enhances \textit{alignment} within the latent space, and iii) such
task-specific calibration helps in explaining the emergence of zero-shot
capabilities in the models.\footnote{The code is available at
\url{https://github.com/baselmousi/multilingual-latent-concepts}}

摘要：儘管多語言嵌入在捕捉不同語言的語言差異方面有顯著能力，但對於多語言嵌入中語言之間的一致性程度仍存在疑問。從神經語言模型中高維表示的研究中汲取靈感，我們採用聚類來揭示多語言模型中的潛在概念。我們的分析重點在於量化潛在空間中各種語言中這些概念的「一致性」和「重疊」。為此，我們引入了兩個指標 \CA{} 和 \CO{}，旨在量化這些方面，從而能夠更深入地探討多語言嵌入。我們的研究涵蓋了三個多語言模型（\texttt{mT5}、\texttt{mBERT} 和 \texttt{XLM-R}）和三個下游任務（機器翻譯、命名實體識別和情緒分析）。我們的分析中的一些主要發現包括：i) 由於存在與語言無關的概念，網路中較深的層級展示出增加的跨語言「一致性」，ii) 模型的微調增強了潛在空間中的「一致性」，以及 iii) 這種特定於任務的校準有助於解釋模型中零次學習能力的出現。\footnote{程式碼可在 \url{https://github.com/baselmousi/multilingual-latent-concepts} 取得}

##### **ArchesWeather: An efficient AI weather forecasting model at 1.5° resolution**
2405.14527v1 by Guillaume Couairon, Christian Lessig, Anastase Charantonis, Claire Monteleoni

One of the guiding principles for designing AI-based weather forecasting
systems is to embed physical constraints as inductive priors in the neural
network architecture. A popular prior is locality, where the atmospheric data
is processed with local neural interactions, like 3D convolutions or 3D local
attention windows as in Pangu-Weather. On the other hand, some works have shown
great success in weather forecasting without this locality principle, at the
cost of a much higher parameter count.
  In this paper, we show that the 3D local processing in Pangu-Weather is
computationally sub-optimal. We design ArchesWeather, a transformer model that
combines 2D attention with a column-wise attention-based feature interaction
module, and demonstrate that this design improves forecasting skill.
  ArchesWeather is trained at 1.5{\deg} resolution and 24h lead time, with a
training budget of a few GPU-days and a lower inference cost than competing
methods. An ensemble of two of our best models shows competitive RMSE scores
with the IFS HRES and outperforms the 1.4{\deg} 50-members NeuralGCM ensemble
for one day ahead forecasting.
  Code and models will be made publicly available at
https://github.com/gcouairon/ArchesWeather.

摘要：設計基於 AI 的天氣預測系統的指導原則之一，是將物理限制嵌入神經網路架構中作為歸納先驗。一個流行的先驗是局部性，其中大氣資料使用局部神經交互作用進行處理，例如 3D 捲積或 3D 局部注意力視窗，就像在 Pangu-Weather 中一樣。另一方面，一些工作顯示在沒有這種局部性原則的情況下，天氣預測也取得了巨大的成功，但代價是參數數量大幅增加。
在本文中，我們展示了 Pangu-Weather 中的 3D 局部處理在計算上是次佳的。我們設計了 ArchesWeather，這是一個Transformer模型，它結合了 2D 注意力與基於列的注意力特徵交互模組，並證明這種設計改進了預測技巧。
ArchesWeather 以 1.5{\deg} 解析度和 24 小時前導時間進行訓練，訓練預算為幾天 GPU 時間，推論成本低於競爭方法。我們兩個最佳模型的集合顯示出與 IFS HRES 競爭的 RMSE 分數，並在一天後的預測中優於 1.4{\deg} 50 個成員的 NeuralGCM 集合。
程式碼和模型將在 https://github.com/gcouairon/ArchesWeather 公開。

##### **Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property**
2405.14522v1 by Yuya Yoshikawa, Masanari Kimura, Ryotaro Shimizu, Yuki Saito

Techniques that explain the predictions of black-box machine learning models
are crucial to make the models transparent, thereby increasing trust in AI
systems. The input features to the models often have a nested structure that
consists of high- and low-level features, and each high-level feature is
decomposed into multiple low-level features. For such inputs, both high-level
feature attributions (HiFAs) and low-level feature attributions (LoFAs) are
important for better understanding the model's decision. In this paper, we
propose a model-agnostic local explanation method that effectively exploits the
nested structure of the input to estimate the two-level feature attributions
simultaneously. A key idea of the proposed method is to introduce the
consistency property that should exist between the HiFAs and LoFAs, thereby
bridging the separate optimization problems for estimating them. Thanks to this
consistency property, the proposed method can produce HiFAs and LoFAs that are
both faithful to the black-box models and consistent with each other, using a
smaller number of queries to the models. In experiments on image classification
in multiple instance learning and text classification using language models, we
demonstrate that the HiFAs and LoFAs estimated by the proposed method are
accurate, faithful to the behaviors of the black-box models, and provide
consistent explanations.

摘要：技術說明黑箱機器學習模型預測對於讓模型透明化至關重要，進而增加對 AI 系統的信任。模型的輸入特徵通常具有嵌套結構，由高階和低階特徵組成，每個高階特徵分解成多個低階特徵。對於此類輸入，高階特徵歸因 (HiFA) 和低階特徵歸因 (LoFA) 對於更深入了解模型的決策都很重要。在本文中，我們提出了一種與模型無關的局部解釋方法，它有效利用輸入的嵌套結構來同時估計兩級特徵歸因。所提出方法的一個關鍵概念是引入 HiFA 和 LoFA 之間應存在的相容性屬性，從而橋接估計它們的單獨最佳化問題。得益於這種相容性屬性，所提出的方法可以產生對黑箱模型忠實且彼此相容的 HiFA 和 LoFA，同時使用較少數量的查詢來查詢模型。在使用語言模型進行多實例學習和文本分類的影像分類實驗中，我們證明所提出的方法估計的 HiFA 和 LoFA 準確、忠實於黑箱模型的行為，並提供一致的解釋。

##### **Unchosen Experts Can Contribute Too: Unleashing MoE Models' Power by Self-Contrast**
2405.14507v1 by Chufan Shi, Cheng Yang, Xinyu Zhu, Jiahao Wang, Taiqiang Wu, Siheng Li, Deng Cai, Yujiu Yang, Yu Meng

Mixture-of-Experts (MoE) has emerged as a prominent architecture for scaling
model size while maintaining computational efficiency. In MoE, each token in
the input sequence activates a different subset of experts determined by a
routing mechanism. However, the unchosen experts in MoE models do not
contribute to the output, potentially leading to underutilization of the
model's capacity. In this work, we first conduct exploratory studies to
demonstrate that increasing the number of activated experts does not
necessarily improve and can even degrade the output quality. Then, we show that
output distributions from an MoE model using different routing strategies
substantially differ, indicating that different experts do not always act
synergistically. Motivated by these findings, we propose Self-Contrast
Mixture-of-Experts (SCMoE), a training-free strategy that utilizes unchosen
experts in a self-contrast manner during inference. In SCMoE, the next-token
probabilities are determined by contrasting the outputs from strong and weak
activation using the same MoE model. Our method is conceptually simple and
computationally lightweight, as it incurs minimal latency compared to greedy
decoding. Experiments on several benchmarks (GSM8K, StrategyQA, MBPP and
HumanEval) demonstrate that SCMoE can consistently enhance Mixtral 8x7B's
reasoning capability across various domains. For example, it improves the
accuracy on GSM8K from 61.79 to 66.94. Moreover, combining SCMoE with
self-consistency yields additional gains, increasing major@20 accuracy from
75.59 to 78.31.

摘要：混合專家 (MoE) 已成為一種重要的架構，用於擴展模型大小，同時保持運算效率。在 MoE 中，輸入序列中的每個符號會啟動由路由機制決定的不同專家子集。然而，MoE 模型中未選擇的專家不會對輸出做出貢獻，這可能會導致模型容量利用不足。在這項工作中，我們首先進行探索性研究，以證明增加已啟動專家的數量不一定會改善，甚至可能降低輸出品質。然後，我們證明使用不同路由策略的 MoE 模型的輸出分佈有很大不同，這表明不同的專家並不總是協同作用。受到這些發現的啟發，我們提出了自對比混合專家 (SCMoE)，這是一種無需訓練的策略，它在推理過程中以自對比的方式利用未選擇的專家。在 SCMoE 中，下一個符號的機率是由使用相同 MoE 模型對比強弱激活的輸出決定的。我們的程式在概念上很簡單，且運算量很輕，因為與貪婪解碼相比，它產生的延遲最少。在幾個基準測試（GSM8K、StrategyQA、MBPP 和 HumanEval）上的實驗表明，SCMoE 可以持續增強 Mixtral 8x7B 在各種領域的推理能力。例如，它將 GSM8K 的準確度從 61.79 提高到 66.94。此外，將 SCMoE 與自一致性結合使用會產生額外的收益，將 major@20 準確度從 75.59 提高到 78.31。

##### **SIAVC: Semi-Supervised Framework for Industrial Accident Video Classification**
2405.14506v1 by Zuoyong Li, Qinghua Lin, Haoyi Fan, Tiesong Zhao, David Zhang

Semi-supervised learning suffers from the imbalance of labeled and unlabeled
training data in the video surveillance scenario. In this paper, we propose a
new semi-supervised learning method called SIAVC for industrial accident video
classification. Specifically, we design a video augmentation module called the
Super Augmentation Block (SAB). SAB adds Gaussian noise and randomly masks
video frames according to historical loss on the unlabeled data for model
optimization. Then, we propose a Video Cross-set Augmentation Module (VCAM) to
generate diverse pseudo-label samples from the high-confidence unlabeled
samples, which alleviates the mismatch of sampling experience and provides
high-quality training data. Additionally, we construct a new industrial
accident surveillance video dataset with frame-level annotation, namely ECA9,
to evaluate our proposed method. Compared with the state-of-the-art
semi-supervised learning based methods, SIAVC demonstrates outstanding video
classification performance, achieving 88.76\% and 89.13\% accuracy on ECA9 and
Fire Detection datasets, respectively. The source code and the constructed
dataset ECA9 will be released in \url{https://github.com/AlchemyEmperor/SIAVC}.

摘要：半监督学习在视频监控场景中受到标记和未标记训练数据不平衡的影响。在本文中，我们提出了一种称为 SIAVC 的新的半监督学习方法，用于工业事故视频分类。具体来说，我们设计了一个名为超级增强块 (SAB) 的视频增强模块。SAB 根据未标记数据上的历史损失为模型优化添加高斯噪声和随机掩蔽视频帧。然后，我们提出了一个视频交叉集增强模块 (VCAM)，以从高置信度未标记样本中生成不同的伪标签样本，这减轻了抽样经验的不匹配并提供了高质量的训练数据。此外，我们构建了一个新的工业事故监控视频数据集，其中包含帧级注释，即 ECA9，以评估我们提出的方法。与最先进的基于半监督学习的方法相比，SIAVC 展示了出色的视频分类性能，在 ECA9 和 Fire Detection 数据集上分别实现了 88.76% 和 89.13% 的准确率。源代码和构建的数据集 ECA9 将在 \url{https://github.com/AlchemyEmperor/SIAVC} 中发布。

##### **Explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing**
2405.14505v1 by Jaime González-González, Silvia García-Méndez, Francisco de Arriba-Pérez, Francisco J. González-Castaño, Óscar Barba-Seara

Concerns about the effect of greenhouse gases have motivated the development
of certification protocols to quantify the industrial carbon footprint (CF).
These protocols are manual, work-intensive, and expensive. All of the above
have led to a shift towards automatic data-driven approaches to estimate the
CF, including Machine Learning (ML) solutions. Unfortunately, the
decision-making processes involved in these solutions lack transparency from
the end user's point of view, who must blindly trust their outcomes compared to
intelligible traditional manual approaches. In this research, manual and
automatic methodologies for CF estimation were reviewed, taking into account
their transparency limitations. This analysis led to the proposal of a new
explainable ML solution for automatic CF calculations through bank transaction
classification. Consideration should be given to the fact that no previous
research has considered the explainability of bank transaction classification
for this purpose. For classification, different ML models have been employed
based on their promising performance in the literature, such as Support Vector
Machine, Random Forest, and Recursive Neural Networks. The results obtained
were in the 90 % range for accuracy, precision, and recall evaluation metrics.
From their decision paths, the proposed solution estimates the CO2 emissions
associated with bank transactions. The explainability methodology is based on
an agnostic evaluation of the influence of the input terms extracted from the
descriptions of transactions using locally interpretable models. The
explainability terms were automatically validated using a similarity metric
over the descriptions of the target categories. Conclusively, the explanation
performance is satisfactory in terms of the proximity of the explanations to
the associated activity sector descriptions.

摘要：<paragraph>對於溫室氣體影響的關注，促使開發認證協議來量化產業碳足跡 (CF)。
這些協議是手動的、勞動密集的且昂貴的。以上所有因素都導致轉向自動化數據驅動方法來估計 CF，包括機器學習 (ML) 解决方案。不幸的是，這些解決方案中涉及的決策制定過程對於最終用戶而言缺乏透明度，他們必須盲目相信其結果，而不是與可理解的傳統手動方法進行比較。在這項研究中，審查了手動和自動的 CF 估計方法，並考慮了其透明度限制。此分析導致提出了一種新的可解釋 ML 解决方案，通過銀行交易分類進行自動 CF 計算。應考慮到以前沒有研究考慮過銀行交易分類的可解釋性。對於分類，已採用不同的 ML 模型，這些模型基於其在文獻中的良好表現，例如支持向量機、隨機森林和遞歸神經網絡。獲得的結果在準確度、精確度和召回率評估指標方面處於 90% 的範圍內。從其決策路徑中，所提出的解決方案估計了與銀行交易相關的 CO2 排放。可解釋性方法基於使用局部可解釋模型從交易描述中提取的輸入項的影響的不可知評估。可解釋性術語使用相似性指標在目標類別的描述中自動驗證。結論是，在解釋接近相關活動部門描述方面，解釋性能令人滿意。</paragraph>

##### **Enhanced Spatiotemporal Prediction Using Physical-guided And Frequency-enhanced Recurrent Neural Networks**
2405.14504v1 by Xuanle Zhao, Yue Sun, Tielin Zhang, Bo Xu

Spatiotemporal prediction plays an important role in solving natural problems
and processing video frames, especially in weather forecasting and human action
recognition. Recent advances attempt to incorporate prior physical knowledge
into the deep learning framework to estimate the unknown governing partial
differential equations (PDEs), which have shown promising results in
spatiotemporal prediction tasks. However, previous approaches only restrict
neural network architectures or loss functions to acquire physical or PDE
features, which decreases the representative capacity of a neural network.
Meanwhile, the updating process of the physical state cannot be effectively
estimated. To solve the above mentioned problems, this paper proposes a
physical-guided neural network, which utilizes the frequency-enhanced Fourier
module and moment loss to strengthen the model's ability to estimate the
spatiotemporal dynamics. Furthermore, we propose an adaptive second-order
Runge-Kutta method with physical constraints to model the physical states more
precisely. We evaluate our model on both spatiotemporal and video prediction
tasks. The experimental results show that our model outperforms
state-of-the-art methods and performs best in several datasets, with a much
smaller parameter count.

摘要：時空預測在解決自然問題和處理視訊幀中扮演重要角色，尤其是在天氣預測和人類動作辨識中。最近的進展嘗試將先驗物理知識納入深度學習架構，以估計未知的控制偏微分方程式 (PDE)，這在時空預測任務中已展現出有希望的成果。然而，先前的做法僅限制神經網路架構或損失函數來獲取物理或 PDE 特徵，這降低了神經網路的代表能力。同時，物理狀態的更新過程無法有效估計。為了解決上述問題，本文提出了一種物理導向神經網路，它利用頻率增強的傅立葉模組和矩損失來加強模型估計時空動態的能力。此外，我們提出了一種具有物理約束的適應性二階 Runge-Kutta 方法，以更精確地建模物理狀態。我們在時空和視訊預測任務上評估我們的模型。實驗結果顯示，我們的模型優於最先進的方法，並在多個資料集中表現最佳，且參數數量少得多。

##### **Impact of Non-Standard Unicode Characters on Security and Comprehension in Large Language Models**
2405.14490v1 by Johan S Daniel, Anand Pal

The advancement of large language models has significantly improved natural
language processing. However, challenges such as jailbreaks (prompt injections
that cause an LLM to follow instructions contrary to its intended use),
hallucinations (generating incorrect or misleading information), and
comprehension errors remain prevalent. In this report, we present a comparative
analysis of the performance of fifteen distinct models, with each model
undergoing a standardized test comprising 38 queries across three key metrics:
jailbreaks, hallucinations, and comprehension errors. The models are assessed
based on the total occurrences of jailbreaks, hallucinations, and comprehension
errors. Our work exposes these models' inherent vulnerabilities and challenges
the notion of human-level language comprehension of these models. We have
empirically analysed the impact of non-standard Unicode characters on LLMs and
their safeguarding mechanisms on the best-performing LLMs, including GPT-4,
Gemini 1.5 Pro, LlaMA-3-70B, and Claude 3 Opus. By incorporating alphanumeric
symbols from Unicode outside the standard Latin block and variants of
characters in other languages, we observed a reduction in the efficacy of
guardrails implemented through Reinforcement Learning Human Feedback (RLHF).
Consequently, these models exhibit heightened vulnerability to content policy
breaches and prompt leakage. Our study also suggests a need to incorporate
non-standard Unicode text in LLM training data to enhance the capabilities of
these models.

摘要：大型語言模型的進步顯著地改善了自然語言處理。然而，挑戰仍然普遍存在，例如越獄（提示注入導致 LLM 遵循與其預期用途相反的指令）、幻覺（產生不正確或誤導性的資訊）和理解錯誤。在此報告中，我們提出對 15 個不同模型的效能進行比較分析，每個模型都接受一項標準化測試，其中包含 38 個查詢，橫跨三個關鍵指標：越獄、幻覺和理解錯誤。這些模型的評估基礎是越獄、幻覺和理解錯誤的總發生次數。我們的研究揭露了這些模型固有的脆弱性，並挑戰了這些模型具有人類語言理解層級的概念。我們已根據經驗分析非標準 Unicode 字元對 LLM 的影響，以及其對包括 GPT-4、Gemini 1.5 Pro、LlaMA-3-70B 和 Claude 3 Opus 在內的效能最佳 LLM 的防護機制。透過納入標準拉丁區塊和其它語言中字元變體之外的 Unicode 字母數字符號，我們觀察到透過強化學習人類回饋 (RLHF) 實施的護欄效能降低。因此，這些模型對內容政策違規和提示外洩表現出更高的脆弱性。我們的研究還表明需要在 LLM 訓練資料中納入非標準 Unicode 文字，以增強這些模型的能力。

##### **MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability**
2405.14488v1 by Yanrui Du, Sendong Zhao, Danyang Zhao, Ming Ma, Yuhan Chen, Liangyu Huo, Qing Yang, Dongliang Xu, Bing Qin

Large Language Models (LLMs) are increasingly deployed in various
applications. As their usage grows, concerns regarding their safety are rising,
especially in maintaining harmless responses when faced with malicious
instructions. Many defense strategies have been developed to enhance the safety
of LLMs. However, our research finds that existing defense strategies lead LLMs
to predominantly adopt a rejection-oriented stance, thereby diminishing the
usability of their responses to benign instructions. To solve this problem, we
introduce the MoGU framework, designed to enhance LLMs' safety while preserving
their usability. Our MoGU framework transforms the base LLM into two variants:
the usable LLM and the safe LLM, and further employs dynamic routing to balance
their contribution. When encountering malicious instructions, the router will
assign a higher weight to the safe LLM to ensure that responses are harmless.
Conversely, for benign instructions, the router prioritizes the usable LLM,
facilitating usable and helpful responses. On various open-sourced LLMs, we
compare multiple defense strategies to verify the superiority of our MoGU
framework. Besides, our analysis provides key insights into the effectiveness
of MoGU and verifies that our designed routing mechanism can effectively
balance the contribution of each variant by assigning weights. Our work
released the safer Llama2, Vicuna, Falcon, Dolphin, and Baichuan2.

摘要：大型語言模型 (LLM) 愈來愈多地部署在各種應用程式中。隨著其使用量增加，對於其安全性也愈來愈關注，特別是在面對惡意指令時維持無害的回應。已經開發出許多防禦策略來增強 LLM 的安全性。然而，我們的研究發現現有的防禦策略導致 LLM 主要採取以拒絕為導向的立場，從而降低其對良性指令的回應可用性。為了解決這個問題，我們引入了 MoGU 框架，旨在提升 LLM 的安全性，同時保持其可用性。我們的 MoGU 框架將基礎 LLM 轉換為兩個變體：可用的 LLM 和安全的 LLM，並進一步採用動態路由來平衡其貢獻。在遇到惡意指令時，路由器將為安全的 LLM 分配較高的權重，以確保回應無害。相反地，對於良性指令，路由器優先考慮可用的 LLM，以促進可用且有用的回應。在各種開源 LLM 上，我們比較了多種防禦策略，以驗證我們 MoGU 框架的優越性。此外，我們的分析提供了 MoGU 有效性的關鍵見解，並驗證我們設計的路由機制可以透過分配權重來有效平衡每個變體的貢獻。我們的成果發布了更安全的 Llama2、Vicuna、Falcon、Dolphin 和 Baichuan2。

##### **RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models**
2405.14486v1 by Xiangkun Hu, Dongyu Ru, Lin Qiu, Qipeng Guo, Tianhang Zhang, Yang Xu, Yun Luo, Pengfei Liu, Yue Zhang, Zheng Zhang

Large Language Models (LLMs) have shown impressive capabilities but also a
concerning tendency to hallucinate. This paper presents RefChecker, a framework
that introduces claim-triplets to represent claims in LLM responses, aiming to
detect fine-grained hallucinations. In RefChecker, an extractor generates
claim-triplets from a response, which are then evaluated by a checker against a
reference. We delineate three task settings: Zero, Noisy and Accurate Context,
to reflect various real-world use cases. We curated a benchmark spanning
various NLP tasks and annotated 11k claim-triplets from 2.1k responses by seven
LLMs. RefChecker supports both proprietary and open-source models as the
extractor and checker. Experiments demonstrate that claim-triplets enable
superior hallucination detection, compared to other granularities such as
response, sentence and sub-sentence level claims. RefChecker outperforms prior
methods by 6.8 to 26.1 points on our benchmark and the checking results of
RefChecker are strongly aligned with human judgments. This work is open sourced
at https://github.com/amazon-science/RefChecker

摘要：大型語言模型 (LLM) 已展現出令人印象深刻的能力，但也有令人擔心的幻覺傾向。本文介紹了 RefChecker，一個引入了聲明三元組來表示 LLM 回應中的聲明的框架，旨在偵測細微的幻覺。在 RefChecker 中，提取器會從回應中產生聲明三元組，然後由檢查器根據參考進行評估。我們描繪了三種任務設定：零、雜訊和準確的上下文，以反映各種真實世界的用例。我們策劃了一個涵蓋各種 NLP 任務的基準，並註釋了七個 LLM 的 2.1k 個回應中的 11k 個聲明三元組。RefChecker 支援專有和開放原始碼模型作為提取器和檢查器。實驗證明，與其他粒度（例如回應、句子和子句子層級的聲明）相比，聲明三元組能啟用優異的幻覺偵測。RefChecker 在我們的基準上比先前的方法高出 6.8 到 26.1 分，而 RefChecker 的檢查結果與人類的判斷高度一致。這項工作已在 https://github.com/amazon-science/RefChecker 開源

##### **SLIFER: Investigating Performance and Robustness of Malware Detection Pipelines**
2405.14478v1 by Andrea Ponte, Dmitrijs Trizna, Luca Demetrio, Battista Biggio, Fabio Roli

As a result of decades of research, Windows malware detection is approached
through a plethora of techniques. However, there is an ongoing mismatch between
academia -- which pursues an optimal performances in terms of detection rate
and low false alarms -- and the requirements of real-world scenarios. In
particular, academia focuses on combining static and dynamic analysis within a
single or ensemble of models, falling into several pitfalls like (i) firing
dynamic analysis without considering the computational burden it requires; (ii)
discarding impossible-to-analyse samples; and (iii) analysing robustness
against adversarial attacks without considering that malware detectors are
complemented with more non-machine-learning components. Thus, in this paper we
propose SLIFER, a novel Windows malware detection pipeline sequentially
leveraging both static and dynamic analysis, interrupting computations as soon
as one module triggers an alarm, requiring dynamic analysis only when needed.
Contrary to the state of the art, we investigate how to deal with samples
resistance to analysis, showing how much they impact performances, concluding
that it is better to flag them as legitimate to not drastically increase false
alarms. Lastly, we perform a robustness evaluation of SLIFER leveraging
content-injections attacks, and we show that, counter-intuitively, attacks are
blocked more by YARA rules than dynamic analysis due to byte artifacts created
while optimizing the adversarial strategy.

摘要：經過數十年的研究，Windows 惡意軟體偵測透過大量技術方法進行。然而，學術界（追求最佳偵測率和低誤報率）與實際場景需求之間存在持續的不匹配。特別是，學術界著重於在單一或多個模型中結合靜態和動態分析，陷入幾個陷阱，例如：(i) 在未考慮其所需的運算負擔下啟動動態分析；(ii) 捨棄無法分析的範例；(iii) 在未考慮惡意軟體偵測器會搭配更多非機器學習元件的情況下分析對抗攻擊的穩健性。因此，在本文中，我們提出 SLIFER，一種新穎的 Windows 惡意軟體偵測管線，依序運用靜態和動態分析，在一個模組觸發警示後立即中斷運算，僅在需要時才進行動態分析。與現有技術相反，我們探討如何處理對抗分析的範例，顯示它們對效能的影響有多大，並得出將它們標記為合法以避免大幅增加誤報的結論。最後，我們執行 SLIFER 的穩健性評估，利用內容注入攻擊，並顯示，與直覺相反，YARA 規則會比動態分析更能阻擋攻擊，原因是在最佳化對抗策略時產生的位元組人工製品。

##### **MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes**
2405.14475v1 by Ruiyuan Gao, Kai Chen, Zhihao Li, Lanqing Hong, Zhenguo Li, Qiang Xu

While controllable generative models for images and videos have achieved
remarkable success, high-quality models for 3D scenes, particularly in
unbounded scenarios like autonomous driving, remain underdeveloped due to high
data acquisition costs. In this paper, we introduce MagicDrive3D, a novel
pipeline for controllable 3D street scene generation that supports
multi-condition control, including BEV maps, 3D objects, and text descriptions.
Unlike previous methods that reconstruct before training the generative models,
MagicDrive3D first trains a video generation model and then reconstructs from
the generated data. This innovative approach enables easily controllable
generation and static scene acquisition, resulting in high-quality scene
reconstruction. To address the minor errors in generated content, we propose
deformable Gaussian splatting with monocular depth initialization and
appearance modeling to manage exposure discrepancies across viewpoints.
Validated on the nuScenes dataset, MagicDrive3D generates diverse, high-quality
3D driving scenes that support any-view rendering and enhance downstream tasks
like BEV segmentation. Our results demonstrate the framework's superior
performance, showcasing its transformative potential for autonomous driving
simulation and beyond.

摘要：儘管可控制的影像和影片生成模型已取得顯著的成功，但 3D 場景的高品質模型，尤其是在無界限場景（如自動駕駛）中，由於資料取得成本高，仍然發展不足。在本文中，我們介紹了 MagicDrive3D，這是一個可控制 3D 街景生成的新穎管道，支援多條件控制，包括 BEV 地圖、3D 物件和文字說明。與在訓練生成模型前進行重建的先前方法不同，MagicDrive3D 先訓練一個影片生成模型，然後從生成的資料中進行重建。這種創新的方法能輕鬆地控制生成和靜態場景取得，並產生高品質的場景重建。為了解決生成內容中的細微錯誤，我們提出了具有單眼深度初始化和外觀建模的可變形高斯散射，以管理不同視點的曝光差異。在 nuScenes 資料集上驗證後，MagicDrive3D 產生了多樣化、高品質的 3D 駕駛場景，支援任何視圖渲染，並增強了 BEV 分割等下游任務。我們的結果證明了該框架的優異效能，展示了其在自動駕駛模擬及其他領域的轉型潛力。

##### **Poisson Variational Autoencoder**
2405.14473v1 by Hadi Vafaii, Dekel Galor, Jacob L. Yates

Variational autoencoders (VAE) employ Bayesian inference to interpret sensory
inputs, mirroring processes that occur in primate vision across both ventral
(Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways. Despite their
success, traditional VAEs rely on continuous latent variables, which deviates
sharply from the discrete nature of biological neurons. Here, we developed the
Poisson VAE (P-VAE), a novel architecture that combines principles of
predictive coding with a VAE that encodes inputs into discrete spike counts.
Combining Poisson-distributed latent variables with predictive coding
introduces a metabolic cost term in the model loss function, suggesting a
relationship with sparse coding which we verify empirically. Additionally, we
analyze the geometry of learned representations, contrasting the P-VAE to
alternative VAE models. We find that the P-VAEencodes its inputs in relatively
higher dimensions, facilitating linear separability of categories in a
downstream classification task with a much better (5x) sample efficiency. Our
work provides an interpretable computational framework to study brain-like
sensory processing and paves the way for a deeper understanding of perception
as an inferential process.

摘要：變異自動編碼器 (VAE) 使用貝氏推論來詮釋感官輸入，反映靈長類動物視覺在腹側 (Higgins et al., 2021) 和背側 (Vafaii et al., 2023) 通路中發生的過程。儘管它們成功，但傳統的 VAE 依賴於連續潛在變數，這與生物神經元的離散性質有很大的不同。在此，我們開發了 Poisson VAE (P-VAE)，這是一種新穎的架構，它結合了預測編碼原理和將輸入編碼為離散尖峰計數的 VAE。將泊松分布的潛在變數與預測編碼相結合，在模型損失函數中引入了代謝成本項，這表明與稀疏編碼存在關係，我們通過實證驗證了這一點。此外，我們分析了學習表徵的幾何形狀，將 P-VAE 與替代 VAE 模型進行對比。我們發現 P-VAE 將其輸入編碼在相對較高的維度中，促進了下游分類任務中類別的線性可分離性，具有更好的 (5 倍) 樣本效率。我們的研究提供了一個可解釋的計算框架來研究類腦感官處理，並為將感知視為一個推理過程的更深入理解鋪平了道路。

##### **Segformer++: Efficient Token-Merging Strategies for High-Resolution Semantic Segmentation**
2405.14467v1 by Daniel Kienzle, Marco Kantonis, Robin Schön, Rainer Lienhart

Utilizing transformer architectures for semantic segmentation of
high-resolution images is hindered by the attention's quadratic computational
complexity in the number of tokens. A solution to this challenge involves
decreasing the number of tokens through token merging, which has exhibited
remarkable enhancements in inference speed, training efficiency, and memory
utilization for image classification tasks. In this paper, we explore various
token merging strategies within the framework of the Segformer architecture and
perform experiments on multiple semantic segmentation and human pose estimation
datasets. Notably, without model re-training, we, for example, achieve an
inference acceleration of 61% on the Cityscapes dataset while maintaining the
mIoU performance. Consequently, this paper facilitates the deployment of
transformer-based architectures on resource-constrained devices and in
real-time applications.

摘要：利用Transformer架構進行高解析度影像的語意分割，會受到注意力在標記數量上的二次運算複雜度所阻礙。解決這個挑戰的方法包括透過標記合併來減少標記數量，這已在影像分類任務中展現出在推論速度、訓練效率和記憶體使用上的顯著提升。在本文中，我們探討了 Segformer 架構內部的各種標記合併策略，並在多個語意分割和人體姿勢估計資料集上執行實驗。值得注意的是，在不重新訓練模型的情況下，我們在 Cityscapes 資料集上實現了 61% 的推論加速，同時維持 mIoU 效能。因此，本文促進了在資源受限的裝置和即時應用中部署基於Transformer的架構。

##### **Worldwide Federated Training of Language Models**
2405.14446v1 by Alex Iacob, Lorenzo Sani, Bill Marino, Preslav Aleksandrov, Nicholas Donald Lane

The reliance of language model training on massive amounts of computation and
vast datasets scraped from potentially low-quality, copyrighted, or sensitive
data has come into question practically, legally, and ethically. Federated
learning provides a plausible alternative by enabling previously untapped data
to be voluntarily gathered from collaborating organizations. However, when
scaled globally, federated learning requires collaboration across heterogeneous
legal, security, and privacy regimes while accounting for the inherent locality
of language data; this further exacerbates the established challenge of
federated statistical heterogeneity. We propose a Worldwide Federated Language
Model Training~(WorldLM) system based on federations of federations, where each
federation has the autonomy to account for factors such as its industry,
operating jurisdiction, or competitive environment. WorldLM enables such
autonomy in the presence of statistical heterogeneity via partial model
localization by allowing sub-federations to attentively aggregate key layers
from their constituents. Furthermore, it can adaptively share information
across federations via residual layer embeddings. Evaluations of language
modeling on naturally heterogeneous datasets show that WorldLM outperforms
standard federations by up to $1.91\times$, approaches the personalized
performance of fully local models, and maintains these advantages under
privacy-enhancing techniques.

摘要：語言模型訓練仰賴大量運算和從潛在低品質、受版權保護或敏感資料中擷取的龐大資料集，這在實務、法律和倫理上都受到質疑。聯合學習提供了一個可行的替代方案，讓先前未開發的資料能夠從合作組織自願收集。然而，當聯合學習擴展到全球時，需要在異質的法律、安全和隱私制度中進行合作，同時考量語言資料的內在區域性；這進一步加劇了聯合統計異質性的既有挑戰。我們提出了一個基於聯合聯合的全球聯合語言模型訓練 (WorldLM) 系統，其中每個聯合都有自主權來考量其產業、運作管轄權或競爭環境等因素。WorldLM 透過部分模型在地化，讓子聯合專注於聚合其組成部分中的關鍵層，在存在統計異質性的情況下實現這種自主性。此外，它可以透過殘差層嵌入式適應性地在聯合之間分享資訊。在自然異質資料集上進行的語言建模評估顯示，WorldLM 的表現優於標準聯合，最高達 1.91 倍，接近完全在地化模型的個人化表現，並在隱私增強技術下維持這些優勢。

##### **Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study**
2405.14445v1 by Lena Schmidt, Kaitlyn Hair, Sergio Graziozi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, James Thomas

This paper describes a rapid feasibility study of using GPT-4, a large
language model (LLM), to (semi)automate data extraction in systematic reviews.
Despite the recent surge of interest in LLMs there is still a lack of
understanding of how to design LLM-based automation tools and how to robustly
evaluate their performance. During the 2023 Evidence Synthesis Hackathon we
conducted two feasibility studies. Firstly, to automatically extract study
characteristics from human clinical, animal, and social science domain studies.
We used two studies from each category for prompt-development; and ten for
evaluation. Secondly, we used the LLM to predict Participants, Interventions,
Controls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP
dataset. Overall, results indicated an accuracy of around 80%, with some
variability between domains (82% for human clinical, 80% for animal, and 72%
for studies of human social sciences). Causal inference methods and study
design were the data extraction items with the most errors. In the PICO study,
participants and intervention/control showed high accuracy (>80%), outcomes
were more challenging. Evaluation was done manually; scoring methods such as
BLEU and ROUGE showed limited value. We observed variability in the LLMs
predictions and changes in response quality. This paper presents a template for
future evaluations of LLMs in the context of data extraction for systematic
review automation. Our results show that there might be value in using LLMs,
for example as second or third reviewers. However, caution is advised when
integrating models such as GPT-4 into tools. Further research on stability and
reliability in practical settings is warranted for each type of data that is
processed by the LLM.

摘要：這篇論文描述了一個使用 GPT-4（一種大型語言模型，LLM）來（半）自動化系統化回顧中資料萃取的快速可行性研究。儘管最近對 LLM 的興趣激增，但對於如何設計基於 LLM 的自動化工具以及如何穩健地評估其效能，仍然缺乏了解。在 2023 年證據綜合黑客松期間，我們進行了兩項可行性研究。首先，自動從人類臨床、動物和社會科學領域研究中萃取研究特徵。我們使用每個類別中的兩項研究進行提示開發；並使用十項進行評估。其次，我們使用 LLM 來預測 EBM-NLP 資料集中的 100 篇摘要中標記的參與者、干預措施、對照和結果（PICOs）。總體而言，結果顯示準確度約為 80%，不同領域之間存在一些差異（人類臨床為 82%，動物為 80%，人類社會科學研究為 72%）。因果推論方法和研究設計是資料萃取項目中錯誤最多的。在 PICO 研究中，參與者和干預/對照顯示出高準確度（>80%），結果更具挑戰性。評估是手動完成的；BLEU 和 ROUGE 等計分方法顯示的價值有限。我們觀察到 LLM 預測和回應品質變化的變異性。本文提供了 LLM 在系統化回顧自動化的資料萃取背景下的未來評估範本。我們的結果顯示使用 LLM 可能有價值，例如作為第二或第三位審查者。但是，在將 GPT-4 等模型整合到工具中時，建議保持謹慎。對於 LLM 處理的每種類型資料，都有必要進一步研究實際設定中的穩定性和可靠性。

##### **Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models**
2405.14437v1 by Alejo Lopez-Avila, Víctor Suárez-Paniagua

Recently, using large pretrained Transformer models for transfer learning
tasks has evolved to the point where they have become one of the flagship
trends in the Natural Language Processing (NLP) community, giving rise to
various outlooks such as prompt-based, adapters or combinations with
unsupervised approaches, among many others. This work proposes a 3 Phase
technique to adjust a base model for a classification task. First, we adapt the
model's signal to the data distribution by performing further training with a
Denoising Autoencoder (DAE). Second, we adjust the representation space of the
output to the corresponding classes by clustering through a Contrastive
Learning (CL) method. In addition, we introduce a new data augmentation
approach for Supervised Contrastive Learning to correct the unbalanced
datasets. Third, we apply fine-tuning to delimit the predefined categories.
These different phases provide relevant and complementary knowledge to the
model to learn the final task. We supply extensive experimental results on
several datasets to demonstrate these claims. Moreover, we include an ablation
study and compare the proposed method against other ways of combining these
techniques.

摘要：最近，使用大型预训练 Transformer 模型进行迁移学习的任务已经发展到成为自然语言处理 (NLP) 社群中旗舰趋势之一的地步，催生了各种展望，例如基于提示、适配器或与无监督方法相结合，还有许多其他方法。这项工作提出了一种 3 阶段技术，用于调整基础模型以进行分类任务。首先，我们通过使用去噪自动编码器 (DAE) 执行进一步的训练，将模型的信号调整到数据分布。其次，我们通过对比学习 (CL) 方法进行聚类，将输出的表示空间调整到相应的类别。此外，我们引入了一种新的数据扩充方法，用于监督对比学习，以纠正不平衡的数据集。第三，我们应用微调来划定预定义的类别。这些不同的阶段为模型提供了相关且互补的知识，以学习最终任务。我们在多个数据集上提供了广泛的实验结果，以证明这些说法。此外，我们还包括消融研究，并将所提出的方法与结合这些技术的其他方式进行比较。

##### **RaFe: Ranking Feedback Improves Query Rewriting for RAG**
2405.14431v1 by Shengyu Mao, Yong Jiang, Boli Chen, Xiao Li, Peng Wang, Xinyu Wang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang

As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG)
techniques have evolved, query rewriting has been widely incorporated into the
RAG system for downstream tasks like open-domain QA. Many works have attempted
to utilize small models with reinforcement learning rather than costly LLMs to
improve query rewriting. However, current methods require annotations (e.g.,
labeled relevant documents or downstream answers) or predesigned rewards for
feedback, which lack generalization, and fail to utilize signals tailored for
query rewriting. In this paper, we propose ours, a framework for training query
rewriting models free of annotations. By leveraging a publicly available
reranker, ours~provides feedback aligned well with the rewriting objectives.
Experimental results demonstrate that ours~can obtain better performance than
baselines.

摘要：隨著大型語言模型 (LLM) 和檢索擴充生成 (RAG) 技術的演進，查詢改寫已廣泛納入 RAG 系統，用於開放領域問答等下游任務。許多研究嘗試利用小型模型搭配強化學習，而非成本高昂的 LLM，來改善查詢改寫。然而，目前的方法需要註解（例如，標記相關文件或下游答案）或預先設計的回饋獎勵，這缺乏概括性，且無法利用針對查詢改寫量身打造的訊號。在本文中，我們提出我們的框架，用於訓練無需註解的查詢改寫模型。透過利用公開可用的重新排序器，我們的框架可提供與改寫目標高度一致的回饋。實驗結果證明，我們的框架能獲得優於基線的效能。

##### **PipeFusion: Displaced Patch Pipeline Parallelism for Inference of Diffusion Transformer Models**
2405.14430v1 by Jiannan Wang, Jiarui Fang, Aoyu Li, PengCheng Yang

This paper introduces PipeFusion, a novel approach that harnesses multi-GPU
parallelism to address the high computational and latency challenges of
generating high-resolution images with diffusion transformers (DiT) models.
PipeFusion splits images into patches and distributes the network layers across
multiple devices. It employs a pipeline parallel manner to orchestrate
communication and computations. By leveraging the high similarity between the
input from adjacent diffusion steps, PipeFusion eliminates the waiting time in
the pipeline by reusing the one-step stale feature maps to provide context for
the current step. Our experiments demonstrate that it can generate higher image
resolution where existing DiT parallel approaches meet OOM. PipeFusion
significantly reduces the required communication bandwidth, enabling DiT
inference to be hosted on GPUs connected via PCIe rather than the more costly
NVLink infrastructure, which substantially lowers the overall operational
expenses for serving DiT models. Our code is publicly available at
https://github.com/PipeFusion/PipeFusion.

摘要：本文介紹 PipeFusion，一種新穎的方法，它利用多 GPU 並行運算來解決使用擴散Transformer (DiT) 模型產生高解析度影像時所面臨的高運算和延遲挑戰。
PipeFusion 將影像分割成區塊，並將網路層分佈在多個裝置上。它採用流水線並行方式來協調通訊和運算。透過利用相鄰擴散步驟之間輸入的高相似性，PipeFusion 透過重複使用一步舊的特徵圖來提供當前步驟的背景，從而消除了流水線中的等待時間。我們的實驗表明，它可以在現有 DiT 並行方法遇到 OOM 的情況下產生更高的影像解析度。PipeFusion 大幅降低了所需的通訊頻寬，使 DiT 推論能夠在透過 PCIe 連接的 GPU 上執行，而不是成本更高的 NVLink 基礎架構，這大幅降低了服務 DiT 模型的整體營運開銷。我們的程式碼已公開於 https://github.com/PipeFusion/PipeFusion。

##### **Mitigating Quantization Errors Due to Activation Spikes in GLU-Based LLMs**
2405.14428v1 by Jaewoo Yang, Hayun Kim, Younghoon Kim

Modern large language models (LLMs) have established state-of-the-art
performance through architectural improvements, but still require significant
computational cost for inference. In an effort to reduce the inference cost,
post-training quantization (PTQ) has become a popular approach, quantizing
weights and activations to lower precision, such as INT8. In this paper, we
reveal the challenges of activation quantization in GLU variants, which are
widely used in feed-forward network (FFN) of modern LLMs, such as LLaMA family.
The problem is that severe local quantization errors, caused by excessive
magnitudes of activation in GLU variants, significantly degrade the performance
of the quantized LLM. We denote these activations as activation spikes. Our
further observations provide a systematic pattern of activation spikes: 1) The
activation spikes occur in the FFN of specific layers, particularly in the
early and late layers, 2) The activation spikes are dedicated to a couple of
tokens, rather than being shared across a sequence. Based on our observations,
we propose two empirical methods, Quantization-free Module (QFeM) and
Quantization-free Prefix (QFeP), to isolate the activation spikes during
quantization. Our extensive experiments validate the effectiveness of the
proposed methods for the activation quantization, especially with
coarse-grained scheme, of latest LLMs with GLU variants, including LLaMA-2/3,
Mistral, Mixtral, SOLAR, and Gemma. In particular, our methods enhance the
current alleviation techniques (e.g., SmoothQuant) that fail to control the
activation spikes. Code is available at
https://github.com/onnoo/activation-spikes.

摘要：<paragraph>現代大型語言模型 (LLM) 已透過架構改善建立了最先進的效能，但推論仍需要大量的運算成本。為了降低推論成本，訓練後量化 (PTQ) 已成為一種普遍的做法，將權重和啟用量化為較低的精度，例如 INT8。在本文中，我們揭露了 GLU 變體中啟用量化的挑戰，這些變體廣泛用於現代 LLM 的前饋網路 (FFN)，例如 LLaMA 家族。問題在於，GLU 變體中過大的啟用量會造成嚴重的局部量化誤差，大幅降低量化 LLM 的效能。我們將這些啟用稱為啟用尖峰。我們的進一步觀察提供了啟用尖峰的系統模式：1) 啟用尖峰發生在特定層的 FFN，特別是在早期和晚期層，2) 啟用尖峰專屬於幾個 token，而不是在序列中共享。根據我們的觀察，我們提出兩種經驗方法，無量化模組 (QFeM) 和無量化前綴 (QFeP)，以在量化期間隔離啟用尖峰。我們的廣泛實驗驗證了所提出的方法對啟用量化的有效性，特別是對於具有 GLU 變體的最新 LLM（包括 LLaMA-2/3、Mistral、Mixtral、SOLAR 和 Gemma）的粗粒度方案。特別是，我們的這些方法增強了目前的緩解技術（例如 SmoothQuant），而這些技術無法控制啟用尖峰。程式碼可在 https://github.com/onnoo/activation-spikes 取得。</paragraph>

##### **Unraveling overoptimism and publication bias in ML-driven science**
2405.14422v1 by Pouria Saidi, Gautam Dasarathy, Visar Berisha

Machine Learning (ML) is increasingly used across many disciplines with
impressive reported results across many domain areas. However, recent studies
suggest that the published performance of ML models are often overoptimistic
and not reflective of true accuracy were these models to be deployed. Validity
concerns are underscored by findings of a concerning inverse relationship
between sample size and reported accuracy in published ML models across several
domains. This is in contrast with the theory of learning curves in ML, where we
expect accuracy to improve or stay the same with increasing sample size. This
paper investigates the factors contributing to overoptimistic accuracy reports
in ML-based science, focusing on data leakage and publication bias. Our study
introduces a novel stochastic model for observed accuracy, integrating
parametric learning curves and the above biases. We then construct an estimator
based on this model that corrects for these biases in observed data.
Theoretical and empirical results demonstrate that this framework can estimate
the underlying learning curve that gives rise to the observed overoptimistic
results, thereby providing more realistic performance assessments of ML
performance from a collection of published results. We apply the model to
various meta-analyses in the digital health literature, including
neuroimaging-based and speech-based classifications of several neurological
conditions. Our results indicate prevalent overoptimism across these fields and
we estimate the inherent limits of ML-based prediction in each domain.

摘要：機器學習 (ML) 愈來愈廣泛地用於許多領域，在許多領域都報告了令人印象深刻的結果。然而，最近的研究表明，ML 模型已發表的效能往往過於樂觀，且無法反映這些模型部署後的真實準確度。有效性疑慮受到令人擔憂的發現的強調，即在幾個領域中，已發表的 ML 模型中的樣本大小與報告的準確度之間存在反比關係。這與 ML 中的學習曲線理論相反，在 ML 中，我們預期準確度會隨著樣本大小的增加而提升或保持不變。本文探討了導致 ML 基礎科學中過度樂觀的準確度報告的因素，重點在於資料外洩和發表偏誤。我們的研究引入了一個新穎的觀測準確度隨機模型，整合了參數學習曲線和上述偏誤。然後，我們根據此模型建構了一個估計器，以修正觀測資料中的這些偏誤。理論和經驗結果證明，此架構可以估計導致觀測過度樂觀結果的底層學習曲線，從而提供更實際的 ML 效能評估，這些評估來自一系列已發表的結果。我們將此模型應用於數位健康文獻中的各種後設分析，包括基於神經影像和基於語音的幾種神經狀況分類。我們的結果指出這些領域普遍存在過度樂觀，並且我們估計了每個領域中基於 ML 的預測的內在限制。

##### **Proving Theorems Recursively**
2405.14414v1 by Haiming Wang, Huajian Xin, Zhengying Liu, Wenda Li, Yinya Huang, Jianqiao Lu, Zhicheng Yang, Jing Tang, Jian Yin, Zhenguo Li, Xiaodan Liang

Recent advances in automated theorem proving leverages language models to
explore expanded search spaces by step-by-step proof generation. However, such
approaches are usually based on short-sighted heuristics (e.g., log probability
or value function scores) that potentially lead to suboptimal or even
distracting subgoals, preventing us from finding longer proofs. To address this
challenge, we propose POETRY (PrOvE Theorems RecursivelY), which proves
theorems in a recursive, level-by-level manner in the Isabelle theorem prover.
Unlike previous step-by-step methods, POETRY searches for a verifiable sketch
of the proof at each level and focuses on solving the current level's theorem
or conjecture. Detailed proofs of intermediate conjectures within the sketch
are temporarily replaced by a placeholder tactic called sorry, deferring their
proofs to subsequent levels. This approach allows the theorem to be tackled
incrementally by outlining the overall theorem at the first level and then
solving the intermediate conjectures at deeper levels. Experiments are
conducted on the miniF2F and PISA datasets and significant performance gains
are observed in our POETRY approach over state-of-the-art methods. POETRY on
miniF2F achieves an average proving success rate improvement of 5.1%. Moreover,
we observe a substantial increase in the maximum proof length found by POETRY,
from 10 to 26.

摘要：自動定理證明最近的進展利用語言模型，透過逐步證明產生來探索擴展的搜尋空間。然而，此類方法通常基於短視的啟發法（例如，對數機率或價值函數分數），可能會導致次佳甚至令人分心的次目標，讓我們無法找到更長的證明。為了應對此挑戰，我們提出 POETRY（遞迴證明定理），它在 Isabelle 定理證明器中以遞迴、逐層的方式證明定理。與先前的逐步方法不同，POETRY 在每個層級搜尋可驗證的證明草圖，並專注於解決當前層級的定理或猜想。草圖中中間猜想的詳細證明暫時由稱為 sorry 的佔位符策略取代，將其證明遞延到後續層級。此方法允許透過在第一層級概述整體定理，然後在更深層級解決中間猜想，以逐步解決定理。在 miniF2F 和 PISA 資料集上進行實驗，並觀察到我們的 POETRY 方法相較於最先進的方法有顯著的效能提升。POETRY 在 miniF2F 上達成平均證明成功率提升 5.1%。此外，我們觀察到 POETRY 找到的最大證明長度大幅增加，從 10 增加到 26。

##### **Large Language Models for Explainable Decisions in Dynamic Digital Twins**
2405.14411v1 by Nan Zhang, Christian Vergara-Marcillo, Georgios Diamantopoulos, Jingran Shen, Nikos Tziritas, Rami Bahsoon, Georgios Theodoropoulos

Dynamic data-driven Digital Twins (DDTs) can enable informed decision-making
and provide an optimisation platform for the underlying system. By leveraging
principles of Dynamic Data-Driven Applications Systems (DDDAS), DDTs can
formulate computational modalities for feedback loops, model updates and
decision-making, including autonomous ones. However, understanding autonomous
decision-making often requires technical and domain-specific knowledge. This
paper explores using large language models (LLMs) to provide an explainability
platform for DDTs, generating natural language explanations of the system's
decision-making by leveraging domain-specific knowledge bases. A case study
from smart agriculture is presented.

摘要：動態資料驅動的數位分身（DDT）能讓資料驅動的決策制定更明智，並提供一個最佳化平台給底層系統。透過運用動態資料驅動應用系統（DDDAS）的原則，DDT 能制定計算模式，用於回饋迴路、模型更新和決策制定，包括自動決策制定。然而，理解自動決策制定通常需要技術和領域特定的知識。本文探討使用大型語言模型（LLM）來提供 DDT 的可解釋性平台，透過運用領域特定的知識庫，產生系統決策制定的自然語言解釋。本文提供了一個智慧農業的案例研究。

##### **SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition with Jaccard Attentive Spiking Neural Network**
2405.14398v1 by Weiyu Guo, Ying Sun, Yijie Xu, Ziyue Qiao, Yongkui Yang, Hui Xiong

Surface electromyography (sEMG) based gesture recognition offers a natural
and intuitive interaction modality for wearable devices. Despite significant
advancements in sEMG-based gesture-recognition models, existing methods often
suffer from high computational latency and increased energy consumption.
Additionally, the inherent instability of sEMG signals, combined with their
sensitivity to distribution shifts in real-world settings, compromises model
robustness.
  To tackle these challenges, we propose a novel SpGesture framework based on
Spiking Neural Networks, which possesses several unique merits compared with
existing methods: (1) Robustness: By utilizing membrane potential as a memory
list, we pioneer the introduction of Source-Free Domain Adaptation into SNN for
the first time. This enables SpGesture to mitigate the accuracy degradation
caused by distribution shifts. (2) High Accuracy: With a novel Spiking Jaccard
Attention, SpGesture enhances the SNNs' ability to represent sEMG features,
leading to a notable rise in system accuracy. To validate SpGesture's
performance, we collected a new sEMG gesture dataset which has different
forearm postures, where SpGesture achieved the highest accuracy among the
baselines ($89.26\%$). Moreover, the actual deployment on the CPU demonstrated
a system latency below 100ms, well within real-time requirements. This
impressive performance showcases SpGesture's potential to enhance the
applicability of sEMG in real-world scenarios. The code is available at
https://anonymous.4open.science/r/SpGesture.

摘要：表面肌電圖 (sEMG) 手勢辨識為穿戴式裝置提供了自然且直覺的互動方式。儘管 sEMG 手勢辨識模型有顯著的進展，現有的方法通常會遇到高運算延遲和增加的能源消耗。此外，sEMG 訊號內在的不穩定性，加上它們對真實環境中分佈轉移的敏感性，損害了模型的穩健性。
為了應對這些挑戰，我們提出了一個基於尖峰神經網路的創新 SpGesture 架構，與現有方法相比，它具備幾個獨特的優點：(1) 穩健性：透過利用膜電位作為記憶清單，我們率先將無來源域適應引入 SNN。這使 SpGesture 能夠減輕由分佈轉移造成的準確度下降。(2) 高準確度：透過創新的尖峰 Jaccard 注意力，SpGesture 增強了 SNN 表示 sEMG 特徵的能力，導致系統準確度顯著提升。為了驗證 SpGesture 的效能，我們收集了一個新的 sEMG 手勢資料集，其中有不同的前臂姿勢，SpGesture 在基線中獲得最高的準確度 ($89.26\%$)。此外，在 CPU 上的實際部署證明系統延遲低於 100ms，遠低於即時需求。這種令人印象深刻的效能展示了 SpGesture 在現實場景中增強 sEMG 適用性的潛力。程式碼可在 https://anonymous.4open.science/r/SpGesture 取得。

##### **Instruction Tuning With Loss Over Instructions**
2405.14394v1 by Zhengyan Shi, Adam X. Yang, Bin Wu, Laurence Aitchison, Emine Yilmaz, Aldo Lipani

Instruction tuning plays a crucial role in shaping the outputs of language
models (LMs) to desired styles. In this work, we propose a simple yet effective
method, Instruction Modelling (IM), which trains LMs by applying a loss
function to the instruction and prompt part rather than solely to the output
part. Through experiments across 21 diverse benchmarks, we show that, in many
scenarios, IM can effectively improve the LM performance on both NLP tasks
(e.g., MMLU, TruthfulQA, and HumanEval) and open-ended generation benchmarks
(e.g., MT-Bench and AlpacaEval). Remarkably, in the most advantageous case, IM
boosts model performance on AlpacaEval 1.0 by over 100%. We identify two key
factors influencing the effectiveness of IM: (1) The ratio between instruction
length and output length in the training data; and (2) The number of training
examples. We observe that IM is especially beneficial when trained on datasets
with lengthy instructions paired with brief outputs, or under the Superficial
Alignment Hypothesis (SAH) where a small amount of training examples are used
for instruction tuning. Further analysis substantiates our hypothesis that the
improvement can be attributed to reduced overfitting to instruction tuning
datasets. Our work provides practical guidance for instruction tuning LMs,
especially in low-resource scenarios.

摘要：指令微调在塑造语言模型 (LM) 的输出以达到所需的风格方面发挥着至关重要的作用。在这项工作中，我们提出了一种简单但有效的方法，指令建模 (IM)，它通过对指令和提示部分应用损失函数来训练 LM，而不是仅对输出部分应用损失函数。通过对 21 个不同的基准测试进行的实验，我们表明，在许多情况下，IM 可以有效地提高 LM 在 NLP 任务（例如，MMLU、TruthfulQA 和 HumanEval）和开放式生成基准测试（例如，MT-Bench 和 AlpacaEval）上的性能。值得注意的是，在最有利的情况下，IM 将 AlpacaEval 1.0 上的模型性能提升了 100% 以上。我们确定了影响 IM 有效性的两个关键因素：(1) 训练数据中指令长度与输出长度之间的比率；(2) 训练示例的数量。我们观察到，当在指令与简短输出配对的长指令数据集上进行训练时，IM 特别有益，或者在使用少量训练示例进行指令微调的表面对齐假设 (SAH) 下。进一步的分析证实了我们的假设，即改进可以归因于对指令微调数据集的过度拟合减少。我们的工作为指令微调 LM 提供了实用指导，尤其是在资源匮乏的情况下。

##### **Explainable Few-shot Knowledge Tracing**
2405.14391v1 by Haoxuan Li, Jifan Yu, Yuanxin Ouyang, Zhuang Liu, Wenge Rong, Juanzi Li, Zhang Xiong

Knowledge tracing (KT), aiming to mine students' mastery of knowledge by
their exercise records and predict their performance on future test questions,
is a critical task in educational assessment. While researchers achieved
tremendous success with the rapid development of deep learning techniques,
current knowledge tracing tasks fall into the cracks from real-world teaching
scenarios. Relying heavily on extensive student data and solely predicting
numerical performances differs from the settings where teachers assess
students' knowledge state from limited practices and provide explanatory
feedback. To fill this gap, we explore a new task formulation: Explainable
Few-shot Knowledge Tracing. By leveraging the powerful reasoning and generation
abilities of large language models (LLMs), we then propose a cognition-guided
framework that can track the student knowledge from a few student records while
providing natural language explanations. Experimental results from three widely
used datasets show that LLMs can perform comparable or superior to competitive
deep knowledge tracing methods. We also discuss potential directions and call
for future improvements in relevant topics.

摘要：知識追蹤 (KT) 旨在透過學生的練習紀錄探查其知識掌握度，並預測其在未來考試題目的表現，是教育評量中的一項關鍵任務。儘管研究人員在深度學習技術的快速發展下取得了巨大的成功，但目前的知識追蹤任務卻與真實世界的教學場景格格不入。過度依賴大量的學生資料並僅預測數值表現，有別於教師從有限的練習中評估學生知識狀態並提供說明性回饋的設定。為了填補這個差距，我們探索了一項新的任務表述：可解釋的少量知識追蹤。透過利用大型語言模型 (LLM) 強大的推理和生成能力，我們提出了一個認知導向的架構，可以在從少數學生紀錄中追蹤學生的知識，同時提供自然語言的解釋。來自三個廣泛使用的資料集的實驗結果顯示，LLM 可以執行與競爭性的深度知識追蹤方法相當或更優異的表現。我們也討論了潛在的方向，並呼籲在相關主題中進行未來的改進。

##### **stl2vec: Semantic and Interpretable Vector Representation of Temporal Logic**
2405.14389v1 by Gaia Saveri, Laura Nenzi, Luca Bortolussi, Jan Křetínský

Integrating symbolic knowledge and data-driven learning algorithms is a
longstanding challenge in Artificial Intelligence. Despite the recognized
importance of this task, a notable gap exists due to the discreteness of
symbolic representations and the continuous nature of machine-learning
computations. One of the desired bridges between these two worlds would be to
define semantically grounded vector representation (feature embedding) of logic
formulae, thus enabling to perform continuous learning and optimization in the
semantic space of formulae. We tackle this goal for knowledge expressed in
Signal Temporal Logic (STL) and devise a method to compute continuous
embeddings of formulae with several desirable properties: the embedding (i) is
finite-dimensional, (ii) faithfully reflects the semantics of the formulae,
(iii) does not require any learning but instead is defined from basic
principles, (iv) is interpretable. Another significant contribution lies in
demonstrating the efficacy of the approach in two tasks: learning model
checking, where we predict the probability of requirements being satisfied in
stochastic processes; and integrating the embeddings into a neuro-symbolic
framework, to constrain the output of a deep-learning generative model to
comply to a given logical specification.

摘要：整合符號知識和資料驅動學習演算法是人工智慧領域長久以來的挑戰。儘管這項任務的重要性已獲得認可，但由於符號表徵的離散性與機器學習運算的連續性，導致兩者之間存在顯著的差距。連結這兩個世界的其中一個理想橋樑，在於定義邏輯公式的語義基礎向量表徵（特徵嵌入），從而能夠在公式的語義空間中執行連續學習和最佳化。我們針對訊號時序邏輯（STL）中表達的知識來應對這個目標，並設計一種方法來計算具有多項理想特性的公式連續嵌入：嵌入（i）是有限維度的，（ii）忠實反映公式的語義，（iii）不需要任何學習，而是從基本原則中定義的，（iv）具有可解釋性。另一項重大貢獻在於展示這種方法在兩項任務中的效能：學習模型檢查，我們預測需求在隨機過程中獲得滿足的機率；以及將嵌入整合到神經符號框架中，以約束深度學習生成模型的輸出，使其符合給定的邏輯規格。

##### **Evaluation of the Programming Skills of Large Language Models**
2405.14388v1 by Luc Bryan Heitz, Joun Chamas, Christopher Scherb

The advent of Large Language Models (LLM) has revolutionized the efficiency
and speed with which tasks are completed, marking a significant leap in
productivity through technological innovation. As these chatbots tackle
increasingly complex tasks, the challenge of assessing the quality of their
outputs has become paramount. This paper critically examines the output quality
of two leading LLMs, OpenAI's ChatGPT and Google's Gemini AI, by comparing the
quality of programming code generated in both their free versions. Through the
lens of a real-world example coupled with a systematic dataset, we investigate
the code quality produced by these LLMs. Given their notable proficiency in
code generation, this aspect of chatbot capability presents a particularly
compelling area for analysis. Furthermore, the complexity of programming code
often escalates to levels where its verification becomes a formidable task,
underscoring the importance of our study. This research aims to shed light on
the efficacy and reliability of LLMs in generating high-quality programming
code, an endeavor that has significant implications for the field of software
development and beyond.

摘要：大型語言模型 (LLM) 的出現徹底改變了任務完成的效率和速度，標誌著技術創新在生產力方面取得了重大飛躍。由於這些聊天機器人應對越來越複雜的任務，評估其輸出質量的挑戰已變得至關重要。本文通過比較兩個領先的 LLM（OpenAI 的 ChatGPT 和 Google 的 Gemini AI）在其免費版本中生成的程式碼品質，批判性地審查了輸出品質。透過結合真實世界範例和系統性資料集，我們研究了這些 LLM 產生的程式碼品質。鑑於它們在程式碼生成方面的顯著能力，聊天機器人的這個面向提供了一個特別引人入勝的分析領域。此外，程式碼的複雜性通常會上升到難以驗證的程度，這凸顯了我們研究的重要性。本研究旨在闡明 LLM 在生成高品質程式碼方面的效能和可靠性，這項工作對軟體開發領域及其他領域具有重大影響。

##### **Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis**
2405.14385v1 by Aline Étienne, Delphine Battistelli, Gwénolé Lecorvé

The objective of this paper is to predict (A) whether a sentence in a written
text expresses an emotion, (B) the mode(s) in which it is expressed, (C)
whether it is basic or complex, and (D) its emotional category.
  One of our major contributions, through a dataset and a model, is to
integrate the fact that an emotion can be expressed in different modes: from a
direct mode, essentially lexicalized, to a more indirect mode, where emotions
will only be suggested, a mode that NLP approaches generally don't take into
account.
  Another originality is that the scope is on written texts, as opposed usual
work focusing on conversational (often multi-modal) data. In this context,
modes of expression are seen as a factor towards the automatic analysis of
complexity in texts.
  Experiments on French texts show acceptable results compared to the human
annotators' agreement, and outperforming results compared to using a large
language model with in-context learning (i.e. no fine-tuning).

摘要：本文的目的是预测 (A) 书面文本中的句子是否表达情感，(B) 表达情感的方式，(C) 情感是基本还是复杂，以及 (D) 情感类别。
我们的主要贡献之一，通过数据集和模型，是整合这样一个事实：情感可以通过不同的方式表达：从本质上词语化的直接方式，到更间接的方式，其中情感只会得到暗示，这是一种 NLP 方法通常不会考虑的方式。
另一个新颖之处在于，研究范围是书面文本，而不是通常专注于会话（通常是多模态）数据的研究。在此背景下，表达方式被视为自动分析文本复杂性的一个因素。
与人工注释者的一致性相比，法语文本的实验显示出可接受的结果，并且与使用具有上下文学习的大语言模型（即无微调）相比，结果表现优异。

##### **Reliable Trajectory Prediction and Uncertainty Quantification with Conditioned Diffusion Models**
2405.14384v1 by Marion Neumeier, Sebastian Dorn, Michael Botsch, Wolfgang Utschick

This work introduces the conditioned Vehicle Motion Diffusion (cVMD) model, a
novel network architecture for highway trajectory prediction using diffusion
models. The proposed model ensures the drivability of the predicted trajectory
by integrating non-holonomic motion constraints and physical constraints into
the generative prediction module. Central to the architecture of cVMD is its
capacity to perform uncertainty quantification, a feature that is crucial in
safety-critical applications. By integrating the quantified uncertainty into
the prediction process, the cVMD's trajectory prediction performance is
improved considerably. The model's performance was evaluated using the publicly
available highD dataset. Experiments show that the proposed architecture
achieves competitive trajectory prediction accuracy compared to
state-of-the-art models, while providing guaranteed drivable trajectories and
uncertainty quantification.

摘要：本研究提出條件式車輛運動擴散 (cVMD) 模型，這是一個使用擴散模型進行高速公路軌跡預測的新穎網路架構。所提出的模型透過將非完整運動約束和物理約束整合至生成式預測模組中，確保預測軌跡的可駕駛性。cVMD 架構的核心是執行不確定性量化的能力，這項功能在安全關鍵應用中至關重要。透過將量化的不確定性整合至預測過程中，cVMD 的軌跡預測效能大幅提升。該模型的效能使用公開的高維資料集進行評估。實驗顯示，所提出的架構與最先進的模型相比，可達成具競爭力的軌跡預測準確度，同時提供有保證的可駕駛軌跡和不確定性量化。

##### **Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering**
2405.14383v1 by Zhihua Wen, Zhiliang Tian, Zexin Jian, Zhen Huang, Pei Ke, Yifu Gao, Minlie Huang, Dongsheng Li

Large Language Models (LLMs) are widely used for knowledge-seeking yet suffer
from hallucinations. The knowledge boundary (KB) of an LLM limits its factual
understanding, beyond which it may begin to hallucinate. Investigating the
perception of LLMs' KB is crucial for detecting hallucinations and LLMs'
reliable generation. Current studies perceive LLMs' KB on questions with a
concrete answer (close-ended questions) while paying limited attention to
semi-open-ended questions (SoeQ) that correspond to many potential answers.
Some researchers achieve it by judging whether the question is answerable or
not. However, this paradigm is unsuitable for SoeQ, which are usually partially
answerable, containing both answerable and ambiguous (unanswerable) answers.
Ambiguous answers are essential for knowledge-seeking, but they may go beyond
the KB of LLMs. In this paper, we perceive the LLMs' KB with SoeQ by
discovering more ambiguous answers. First, we apply an LLM-based approach to
construct SoeQ and obtain answers from a target LLM. Unfortunately, the output
probabilities of mainstream black-box LLMs are inaccessible to sample for
low-probability ambiguous answers. Therefore, we apply an open-sourced
auxiliary model to explore ambiguous answers for the target LLM. We calculate
the nearest semantic representation for existing answers to estimate their
probabilities, with which we reduce the generation probability of
high-probability answers to achieve a more effective generation. Finally, we
compare the results from the RAG-based evaluation and LLM self-evaluation to
categorize four types of ambiguous answers that are beyond the KB of the target
LLM. Following our method, we construct a dataset to perceive the KB for GPT-4.
We find that GPT-4 performs poorly on SoeQ and is often unaware of its KB.
Besides, our auxiliary model, LLaMA-2-13B, is effective in discovering more
ambiguous answers.

摘要：大型語言模型 (LLM) 廣泛用於知識尋求，但卻會出現幻覺。LLM 的知識邊界 (KB) 限制了其事實理解，超過這個邊界後，它可能會開始產生幻覺。調查 LLM 的 KB 感知對於檢測幻覺和 LLM 的可靠生成至關重要。目前的研究所感知 LLM 的 KB，針對具有具體答案的問題（封閉式問題），同時只關注少量的半開放式問題 (SoeQ)，這些問題對應於許多潛在答案。一些研究人員通過判斷問題是否可回答來實現這一點。然而，這種範例不適合於 SoeQ，SoeQ 通常是部分可回答的，既包含可回答的答案，也包含模稜兩可（不可回答）的答案。模稜兩可的答案對於尋求知識至關重要，但它們可能會超出 LLM 的 KB。在本文中，我們通過發現更多模稜兩可的答案，以 SoeQ 感知 LLM 的 KB。首先，我們應用基於 LLM 的方法來構建 SoeQ，並從目標 LLM 獲取答案。不幸的是，主流黑盒 LLM 的輸出機率無法用於對低機率模稜兩可的答案進行取樣。因此，我們應用了一個開源的輔助模型來探索目標 LLM 的模稜兩可答案。我們計算現有答案最接近的語義表示，以估計它們的機率，然後我們降低高機率答案的生成機率，以實現更有效的生成。最後，我們比較基於 RAG 的評估和 LLM 自我評估的結果，將目標 LLM 的 KB 範圍外的四種類型的模稜兩可答案分類。按照我們的方法，我們構建了一個數據集來感知 GPT-4 的 KB。我們發現 GPT-4 在 SoeQ 上表現不佳，而且常常不知道自己的 KB。此外，我們的輔助模型 LLaMA-2-13B 在發現更多模稜兩可的答案方面很有效。

##### **Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?**
2405.14379v1 by Thomas Greatrix, Roger Whitaker, Liam Turner, Walter Colombo

The potential for Large Language Models (LLMs) to generate new information
offers a potential step change for research and innovation. This is challenging
to assert as it can be difficult to determine what an LLM has previously seen
during training, making "newness" difficult to substantiate. In this paper we
observe that LLMs are able to perform sophisticated reasoning on problems with
a spatial dimension, that they are unlikely to have previously directly
encountered. While not perfect, this points to a significant level of
understanding that state-of-the-art LLMs can now achieve, supporting the
proposition that LLMs are able to yield significant emergent properties. In
particular, Claude 3 is found to perform well in this regard.

摘要：大型語言模型 (LLM) 產生新資訊的潛力為研究和創新提供了潛在的階躍式變革。這一點很難斷言，因為難以確定 LLM 在訓練期間先前看過什麼，這使得「新穎性」難以證實。在本文中，我們觀察到 LLM 能夠對具有空間維度的問題執行複雜的推理，而這些問題不太可能在以前直接遇到過。雖然並不完美，但這表明了最先進的 LLM 現在可以達到的顯著理解水平，支持了 LLM 能夠產生顯著的新興特性的主張。特別是，發現 Claude 3 在這方面表現良好。

##### **CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization**
2405.14377v1 by Zi Yang, Samridhi Choudhary, Xinfeng Xie, Cao Gao, Siegfried Kunzmann, Zheng Zhang

Training large AI models such as deep learning recommendation systems and
foundation language (or multi-modal) models costs massive GPUs and computing
time. The high training cost has become only affordable to big tech companies,
meanwhile also causing increasing concerns about the environmental impact. This
paper presents CoMERA, a Computing- and Memory-Efficient training method via
Rank-Adaptive tensor optimization. CoMERA achieves end-to-end rank-adaptive
tensor-compressed training via a multi-objective optimization formulation, and
improves the training to provide both a high compression ratio and excellent
accuracy in the training process. Our optimized numerical computation (e.g.,
optimized tensorized embedding and tensor-vector contractions) and GPU
implementation eliminate part of the run-time overhead in the tensorized
training on GPU. This leads to, for the first time, $2-3\times$ speedup per
training epoch compared with standard training. CoMERA also outperforms the
recent GaLore in terms of both memory and computing efficiency. Specifically,
CoMERA is $2\times$ faster per training epoch and $9\times$ more
memory-efficient than GaLore on a tested six-encoder transformer with
single-batch training. With further HPC optimization, CoMERA may significantly
reduce the training cost of large language models.

摘要：訓練大型 AI 模型，例如深度學習推薦系統和基礎語言（或多模態）模型，需要大量的 GPU 和運算時間。高昂的訓練成本已成為只有大型科技公司負擔得起，同時也引起人們對環境影響的日益關注。本文提出 CoMERA，一種透過秩自適應張量最佳化進行運算和記憶體高效訓練的方法。CoMERA 透過多目標最佳化公式達成端對端秩自適應張量壓縮訓練，並改善訓練以在訓練過程中提供高壓縮比和優異的準確度。我們最佳化的數值運算（例如最佳化的張量化嵌入和張量向量收縮）和 GPU 實作消除了部分張量化訓練在 GPU 上的執行時間開銷。這導致每訓練週期速度提升 $2-3\times$，與標準訓練相比是首次。CoMERA 在記憶體和運算效率方面也優於最近的 GaLore。具體來說，CoMERA 每個訓練週期快 $2\times$，記憶體效率比在單一批次訓練中測試的六個編碼器Transformer高 $9\times$。透過進一步的 HPC 最佳化，CoMERA 可以大幅降低大型語言模型的訓練成本。

##### **MiniCache: KV Cache Compression in Depth Dimension for Large Language Models**
2405.14366v1 by Akide Liu, Jing Liu, Zizheng Pan, Yefei He, Gholamreza Haffari, Bohan Zhuang

A critical approach for efficiently deploying computationally demanding large
language models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value
states of previously generated tokens, significantly reducing the need for
repetitive computations and thereby lowering latency in autoregressive
generation. However, the size of the KV cache grows linearly with sequence
length, posing challenges for applications requiring long context input and
extensive sequence generation. In this paper, we present a simple yet effective
approach, called MiniCache, to compress the KV cache across layers from a novel
depth perspective, significantly reducing the memory footprint for LLM
inference. Our approach is based on the observation that KV cache states
exhibit high similarity between the adjacent layers in the middle-to-deep
portion of LLMs. To facilitate merging, we propose disentangling the states
into the magnitude and direction components, interpolating the directions of
the state vectors while preserving their lengths unchanged. Furthermore, we
introduce a token retention strategy to keep highly distinct state pairs
unmerged, thus preserving the information with minimal additional storage
overhead. Our MiniCache is training-free and general, complementing existing KV
cache compression strategies, such as quantization and sparsity. We conduct a
comprehensive evaluation of MiniCache utilizing various models including
LLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks,
demonstrating its exceptional performance in achieving superior compression
ratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit
MiniCache achieves a remarkable compression ratio of up to 5.02x, enhances
inference throughput by approximately 5x, and reduces the memory footprint by
41% compared to the FP16 full cache baseline, all while maintaining
near-lossless performance.

摘要：一種有效率地部署計算需求量大的大型語言模型 (LLM) 的關鍵方法是 Key-Value (KV) 快取。KV 快取儲存先前產生的權杖的 key-value 狀態，大幅減少重複運算的需求，進而降低自迴歸生成中的延遲。然而，KV 快取的大小會隨著序列長度線性增加，對需要長脈絡輸入和廣泛序列生成的應用程式構成挑戰。在本文中，我們提出了一個簡單但有效的方法，稱為 MiniCache，從新穎的深度觀點壓縮各層的 KV 快取，大幅減少 LLM 推論的記憶體使用量。我們的做法基於以下觀察：KV 快取狀態在 LLM 的中到深層部分的相鄰層之間具有高度相似性。為了促進合併，我們提出將狀態解開成大小和方向組成，在保留狀態向量長度不變的情況下內插狀態向量的方向。此外，我們引入一種權杖保留策略，以保持高度不同的狀態對不合併，從而以最小的額外儲存空間開銷保留資訊。我們的 MiniCache 不需要訓練且通用，可補充現有的 KV 快取壓縮策略，例如量化和稀疏性。我們對 MiniCache 進行了全面評估，利用各種模型，包括 LLaMA-2、LLaMA-3、Phi-3、Mistral 和 Mixtral，跨多個基準測試，證明了它在達成卓越壓縮率和高處理量方面的出色效能。在 ShareGPT 資料集上，具有 4 位元 MiniCache 的 LLaMA-2-7B 達到了高達 5.02 倍的顯著壓縮率，將推論處理量提升了大約 5 倍，並將記憶體使用量減少了 41%，與 FP16 完整快取基準相比，同時維持近乎無損失的效能。

##### **JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models**
2405.14365v1 by Kun Zhou, Beichen Zhang, Jiapeng Wang, Zhipeng Chen, Wayne Xin Zhao, Jing Sha, Zhichao Sheng, Shijin Wang, Ji-Rong Wen

Mathematical reasoning is an important capability of large language
models~(LLMs) for real-world applications. To enhance this capability, existing
work either collects large-scale math-related texts for pre-training, or relies
on stronger LLMs (\eg GPT-4) to synthesize massive math problems. Both types of
work generally lead to large costs in training or synthesis. To reduce the
cost, based on open-source available texts, we propose an efficient way that
trains a small LLM for math problem synthesis, to efficiently generate
sufficient high-quality pre-training data. To achieve it, we create a dataset
using GPT-4 to distill its data synthesis capability into the small LLM.
Concretely, we craft a set of prompts based on human education stages to guide
GPT-4, to synthesize problems covering diverse math knowledge and difficulty
levels. Besides, we adopt the gradient-based influence estimation method to
select the most valuable math-related texts. The both are fed into GPT-4 for
creating the knowledge distillation dataset to train the small LLM. We leverage
it to synthesize 6 million math problems for pre-training our JiuZhang3.0
model, which only needs to invoke GPT-4 API 9.3k times and pre-train on 4.6B
data. Experimental results have shown that JiuZhang3.0 achieves
state-of-the-art performance on several mathematical reasoning datasets, under
both natural language reasoning and tool manipulation settings. Our code and
data will be publicly released in
\url{https://github.com/RUCAIBox/JiuZhang3.0}.

摘要：<paragraph>數學推理是大語言模型 (LLM) 在實際應用中的一項重要能力。為了增強此能力，現有工作會收集大量的數學相關文本進行預訓練，或依賴更強大的 LLM（例如 GPT-4）來合成大量的數學問題。這兩種工作通常在訓練或合成中產生高昂的成本。為了降低成本，我們基於開放原始碼的文本提出了一種有效的方法，用於訓練一個小型 LLM 以進行數學問題合成，以有效地產生足夠的高品質預訓練數據。為了實現此目的，我們使用 GPT-4 建立一個資料集，將其數據合成能力提煉到小型 LLM 中。具體來說，我們根據人類教育階段制定了一組提示，以指導 GPT-4，以合成涵蓋多樣化數學知識和難度級別的問題。此外，我們採用基於梯度的影響估計方法來選擇最有價值的數學相關文本。兩者都饋入 GPT-4，用於建立知識提煉資料集，以訓練小型 LLM。我們利用它為我們的 JiuZhang3.0 模型合成了 600 萬個數學問題進行預訓練，這只需要調用 GPT-4 API 9.3k 次，並在 4.6B 的數據上進行預訓練。實驗結果表明，JiuZhang3.0 在多個數學推理資料集上達到了最先進的效能，在自然語言推理和工具操作設定下都是如此。我們的程式碼和數據將在
\url{https://github.com/RUCAIBox/JiuZhang3.0} 公開發布。</paragraph>

##### **DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data**
2405.14333v1 by Huajian Xin, Daya Guo, Zhihong Shao, Zhizhou Ren, Qihao Zhu, Bo Liu, Chong Ruan, Wenda Li, Xiaodan Liang

Proof assistants like Lean have revolutionized mathematical proof
verification, ensuring high accuracy and reliability. Although large language
models (LLMs) show promise in mathematical reasoning, their advancement in
formal theorem proving is hindered by a lack of training data. To address this
issue, we introduce an approach to generate extensive Lean 4 proof data derived
from high-school and undergraduate-level mathematical competition problems.
This approach involves translating natural language problems into formal
statements, filtering out low-quality statements, and generating proofs to
create synthetic data. After fine-tuning the DeepSeekMath 7B model on this
synthetic dataset, which comprises 8 million formal statements with proofs, our
model achieved whole-proof generation accuracies of 46.3% with 64 samples and
52% cumulatively on the Lean 4 miniF2F test, surpassing the baseline GPT-4 at
23.0% with 64 samples and a tree search reinforcement learning method at 41.0%.
Additionally, our model successfully proved 5 out of 148 problems in the Lean 4
Formalized International Mathematical Olympiad (FIMO) benchmark, while GPT-4
failed to prove any. These results demonstrate the potential of leveraging
large-scale synthetic data to enhance theorem-proving capabilities in LLMs.
Both the synthetic dataset and the model will be made available to facilitate
further research in this promising field.

摘要：<paragraph>像 Lean 這樣的證明助理已經徹底改變數學證明驗證，確保高度準確性和可靠性。儘管大型語言模型 (LLM) 在數學推理方面表現出潛力，但它們在形式化定理證明方面的進展受到訓練資料不足的阻礙。為了解決這個問題，我們提出了一種方法來產生大量的 Lean 4 證明資料，這些資料來自高中和大學程度的數學競賽題目。此方法包括將自然語言題目轉換為形式化陳述、篩選出低品質陳述，以及產生證明以建立合成資料。在這個包含 800 萬個帶有證明之形式化陳述的合成資料集上微調 DeepSeekMath 7B 模型後，我們的模型在 Lean 4 miniF2F 測試中以 64 個樣本獲得 46.3% 的完整證明產生準確度，累計 52%，超越了在 64 個樣本中準確度為 23.0% 的基準 GPT-4，以及準確度為 41.0% 的樹狀搜尋強化學習方法。此外，我們的模型在 Lean 4 Formalized International Mathematical Olympiad (FIMO) 基準測試中成功證明了 148 個題目中的 5 個，而 GPT-4 則未能證明任何題目。這些結果證明了利用大規模合成資料來增強 LLM 中定理證明能力的潛力。合成資料集和模型都將提供出來，以利於這個有前途的領域的進一步研究。</paragraph>

##### **LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision**
2405.14331v1 by Mateusz Pach, Dawid Rymarczyk, Koryna Lewandowska, Jacek Tabor, Bartosz Zieliński

Prototypical parts networks combine the power of deep learning with the
explainability of case-based reasoning to make accurate, interpretable
decisions. They follow the this looks like that reasoning, representing each
prototypical part with patches from training images. However, a single image
patch comprises multiple visual features, such as color, shape, and texture,
making it difficult for users to identify which feature is important to the
model.
  To reduce this ambiguity, we introduce the Lucid Prototypical Parts Network
(LucidPPN), a novel prototypical parts network that separates color prototypes
from other visual features. Our method employs two reasoning branches: one for
non-color visual features, processing grayscale images, and another focusing
solely on color information. This separation allows us to clarify whether the
model's decisions are based on color, shape, or texture. Additionally, LucidPPN
identifies prototypical parts corresponding to semantic parts of classified
objects, making comparisons between data classes more intuitive, e.g., when two
bird species might differ primarily in belly color.
  Our experiments demonstrate that the two branches are complementary and
together achieve results comparable to baseline methods. More importantly,
LucidPPN generates less ambiguous prototypical parts, enhancing user
understanding.

摘要：原型零件網路結合深度學習的力量與案例推理的可解釋性，做出準確且可詮釋的決策。它們遵循此看起來像那樣的推理，用訓練影像中的補丁表示每個原型零件。然而，單一影像補丁包含多種視覺特徵，例如顏色、形狀和紋理，使用戶難以辨別哪個特徵對模型很重要。
為了減少這種歧義，我們引入了 Lucid 原型零件網路 (LucidPPN)，一種將顏色原型與其他視覺特徵分開的新型原型零件網路。我們的模型採用兩個推理分支：一個用於非色彩視覺特徵，處理灰階影像，另一個則專注於色彩資訊。這種分離讓我們能夠釐清模型的決策是基於顏色、形狀還是紋理。此外，LucidPPN 識別與分類物件的語義零件相應的原型零件，讓資料類別之間的比較更直觀，例如，當兩個鳥類物種可能主要在腹部顏色上有所不同時。
我們的實驗證明這兩個分支是互補的，並且共同達成與基準方法相當的結果。更重要的是，LucidPPN 產生的原型零件較不模稜兩可，增強使用者的理解力。

##### **Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI**
2405.14327v2 by Guanxiong Luo, Shoujin Huang, Martin Uecker

Magnetic resonance imaging (MRI) is a widely used non-invasive imaging
modality. However, a persistent challenge lies in balancing image quality with
imaging speed. This trade-off is primarily constrained by k-space measurements,
which traverse specific trajectories in the spatial Fourier domain (k-space).
These measurements are often undersampled to shorten acquisition times,
resulting in image artifacts and compromised quality. Generative models learn
image distributions and can be used to reconstruct high-quality images from
undersampled k-space data. In this work, we present the autoregressive image
diffusion (AID) model for image sequences and use it to sample the posterior
for accelerated MRI reconstruction. The algorithm incorporates both
undersampled k-space and pre-existing information. Models trained with fastMRI
dataset are evaluated comprehensively. The results show that the AID model can
robustly generate sequentially coherent image sequences. In 3D and dynamic MRI,
the AID can outperform the standard diffusion model and reduce hallucinations,
due to the learned inter-image dependencies.

摘要：磁振造影 (MRI) 是一种广泛使用的非侵入性影像模式。然而，在平衡影像品質與影像速度上仍存在持續的挑戰。這種取捨主要受到 k-space 測量的限制，k-space 測量會在空間傅立葉域 (k-space) 中穿過特定的軌跡。這些測量通常會被欠採樣以縮短擷取時間，導致影像出現偽影和品質受損。生成模型會學習影像分佈，可用於從欠採樣的 k-space 資料重建高品質影像。在這項工作中，我們提出用於影像序列的自迴歸影像擴散 (AID) 模型，並使用它來對加速 MRI 重建的後驗進行抽樣。此演算法結合了欠採樣的 k-space 和預先存在的資訊。使用 fastMRI 資料集訓練的模型經過全面評估。結果顯示 AID 模型可以穩健地生成連續一致的影像序列。在 3D 和動態 MRI 中，由於學習到的影像間依賴性，AID 可以勝過標準擴散模型並減少幻覺。

##### **Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration**
2405.14314v1 by Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong Li, Zhen Wang

Grounding the reasoning ability of large language models (LLMs) for embodied
tasks is challenging due to the complexity of the physical world. Especially,
LLM planning for multi-agent collaboration requires communication of agents or
credit assignment as the feedback to re-adjust the proposed plans and achieve
effective coordination. However, existing methods that overly rely on physical
verification or self-reflection suffer from excessive and inefficient querying
of LLMs. In this paper, we propose a novel framework for multi-agent
collaboration that introduces Reinforced Advantage feedback (ReAd) for
efficient self-refinement of plans. Specifically, we perform critic regression
to learn a sequential advantage function from LLM-planned data, and then treat
the LLM planner as an optimizer to generate actions that maximize the advantage
function. It endows the LLM with the foresight to discern whether the action
contributes to accomplishing the final task. We provide theoretical analysis by
extending advantage-weighted regression in reinforcement learning to
multi-agent systems. Experiments on Overcooked-AI and a difficult variant of
RoCoBench show that ReAd surpasses baselines in success rate, and also
significantly decreases the interaction steps of agents and query rounds of
LLMs, demonstrating its high efficiency for grounding LLMs. More results are
given at \url{https://read-llm.github.io/}.

摘要：由於物理世界的複雜性，要奠定大型語言模型 (LLM) 的推理能力以進行具體任務是一項挑戰。尤其是，LLM 規劃多重代理協作需要代理之間的溝通或信用分配，作為重新調整提議計畫和實現有效協調的回饋。然而，現有方法過度依賴物理驗證或自我反省，會造成 LLM 過度且低效率的查詢。在本文中，我們提出一個多重代理協作的新穎架構，導入強化優勢回饋 (ReAd) 以有效自我改善計畫。具體來說，我們執行批評迴歸，從 LLM 規劃的數據中學習順序優勢函數，然後將 LLM 規劃器視為一個最佳化器，以產生最大化優勢函數的動作。它賦予 LLM 預見力，以辨別動作是否有助於完成最終任務。我們透過將強化學習中的優勢加權迴歸延伸到多重代理系統，提供理論分析。在 Overcooked-AI 和 RoCoBench 的困難變體上進行的實驗顯示，ReAd 在成功率上超越基準，並且顯著減少代理的互動步驟和 LLM 的查詢回合，證明其在奠定 LLM 上的高效率。更多結果請參閱 \url{https://read-llm.github.io/}。

##### **Improving Gloss-free Sign Language Translation by Reducing Representation Density**
2405.14312v1 by Jinhui Ye, Xing Wang, Wenxiang Jiao, Junwei Liang, Hui Xiong

Gloss-free sign language translation (SLT) aims to develop well-performing
SLT systems with no requirement for the costly gloss annotations, but currently
still lags behind gloss-based approaches significantly. In this paper, we
identify a representation density problem that could be a bottleneck in
restricting the performance of gloss-free SLT. Specifically, the representation
density problem describes that the visual representations of semantically
distinct sign gestures tend to be closely packed together in feature space,
which makes gloss-free methods struggle with distinguishing different sign
gestures and suffer from a sharp performance drop. To address the
representation density problem, we introduce a simple but effective contrastive
learning strategy, namely SignCL, which encourages gloss-free models to learn
more discriminative feature representation in a self-supervised manner. Our
experiments demonstrate that the proposed SignCL can significantly reduce the
representation density and improve performance across various translation
frameworks. Specifically, SignCL achieves a significant improvement in BLEU
score for the Sign Language Transformer and GFSLT-VLP on the CSL-Daily dataset
by 39% and 46%, respectively, without any increase of model parameters.
Compared to Sign2GPT, a state-of-the-art method based on large-scale
pre-trained vision and language models, SignCL achieves better performance with
only 35% of its parameters. Implementation and Checkpoints are available at
https://github.com/JinhuiYE/SignCL.

摘要：無光澤手語翻譯 (SLT) 旨在開發出效能良好的 SLT 系統，無需昂貴的光澤註解，但目前仍遠遠落後於基於光澤的方法。在本文中，我們找出一個表示密度問題，這可能是限制無光澤 SLT 效能的瓶頸。具體來說，表示密度問題描述了語義上不同的手勢視覺表示傾向於在特徵空間中緊密結合在一起，這使得無光澤方法難以區分不同的手勢，並導致效能急劇下降。為了解決表示密度問題，我們引入了一個簡單但有效的對比學習策略，即 SignCL，它鼓勵無光澤模型以自監督的方式學習更多具區別性的特徵表示。我們的實驗表明，所提出的 SignCL 可以顯著降低表示密度，並改善各種翻譯框架的效能。具體來說，SignCL 對 CSL-Daily 資料集上的手語轉換器和 GFSLT-VLP 的 BLEU 分數分別提高了 39% 和 46%，而沒有增加任何模型參數。與 Sign2GPT 相比，Sign2GPT 是一種基於大規模預訓練視覺和語言模型的最新方法，SignCL 以其僅 35% 的參數實現了更好的效能。實作和檢查點可在 https://github.com/JinhuiYE/SignCL 取得。

##### **Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient Transformer Models**
2405.14297v1 by Yongxin Guo, Zhenglin Cheng, Xiaoying Tang, Tao Lin

The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the
efficiency of training and inference for Transformer-based foundational models,
yielding promising results. However, the performance of SMoE heavily depends on
the choice of hyper-parameters, such as the number of experts and the number of
experts to be activated (referred to as top-k), resulting in significant
computational overhead due to the extensive model training by searching over
various hyper-parameter configurations. As a remedy, we introduce the Dynamic
Mixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating
method that enables each token to automatically determine the number of experts
to activate. (2) An adaptive process automatically adjusts the number of
experts during training. Extensive numerical results across Vision, Language,
and Vision-Language tasks demonstrate the effectiveness of our approach to
achieve competitive performance compared to GMoE for vision and language tasks,
and MoE-LLaVA for vision-language tasks, while maintaining efficiency by
activating fewer parameters. Our code is available at
https://github.com/LINs-lab/DynMoE.

摘要：稀疏专家混合 (SMoE) 已广泛用于提升基于 Transformer 的基础模型的训练和推理效率，取得了可喜的成果。然而，SMoE 的性能在很大程度上取决于超参数的选择，例如专家数量和要激活的专家数量（称为 top-k），这会导致由于搜索各种超参数配置而进行的广泛模型训练，从而产生巨大的计算开销。为了解决这个问题，我们引入了动态专家混合 (DynMoE) 技术。DynMoE 融合了 (1) 一种新颖的门控方法，使每个标记能够自动确定要激活的专家数量。(2) 一个自适应过程在训练期间自动调整专家数量。跨视觉、语言和视觉语言任务的大量数值结果证明了我们的方法在实现与视觉和语言任务的 GMoE 以及视觉语言任务的 MoE-LLaVA 相比的竞争性能方面的有效性，同时通过激活更少的参数来保持效率。我们的代码可在 https://github.com/LINs-lab/DynMoE 获得。

