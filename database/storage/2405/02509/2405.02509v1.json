{"2405.02509": {"publish_time": "2024-05-03", "title": "Implicit Neural Representations for Robust Joint Sparse-View CT Reconstruction", "paper_summary": "Computed Tomography (CT) is pivotal in industrial quality control and medical\ndiagnostics. Sparse-view CT, offering reduced ionizing radiation, faces\nchallenges due to its under-sampled nature, leading to ill-posed reconstruction\nproblems. Recent advancements in Implicit Neural Representations (INRs) have\nshown promise in addressing sparse-view CT reconstruction. Recognizing that CT\noften involves scanning similar subjects, we propose a novel approach to\nimprove reconstruction quality through joint reconstruction of multiple objects\nusing INRs. This approach can potentially leverage both the strengths of INRs\nand the statistical regularities across multiple objects. While current INR\njoint reconstruction techniques primarily focus on accelerating convergence via\nmeta-initialization, they are not specifically tailored to enhance\nreconstruction quality. To address this gap, we introduce a novel INR-based\nBayesian framework integrating latent variables to capture the inter-object\nrelationships. These variables serve as a dynamic reference throughout the\noptimization, thereby enhancing individual reconstruction fidelity. Our\nextensive experiments, which assess various key factors such as reconstruction\nquality, resistance to overfitting, and generalizability, demonstrate\nsignificant improvements over baselines in common numerical metrics. This\nunderscores a notable advancement in CT reconstruction methods.", "paper_summary_zh": "", "author": "Jiayang Shi et.al.", "authors": "Jiayang Shi,Junyi Zhu,Daniel M. Pelt,K. Joost Batenburg,Matthew B. Blaschko", "id": "2405.02509v1", "paper_url": "http://arxiv.org/abs/2405.02509v1", "repo": "null"}}