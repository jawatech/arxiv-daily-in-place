
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-14**|**Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs**|Edison Jair Bejarano Sepulveda et.al.|[2405.08792v1](http://arxiv.org/abs/2405.08792v1)|null|
|**2024-05-14**|**Kolmogorov-Arnold Networks (KANs) for Time Series Analysis**|Cristian J. Vaca-Rubio et.al.|[2405.08790v1](http://arxiv.org/abs/2405.08790v1)|null|
|**2024-05-14**|**Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram**|Aehong Min et.al.|[2405.08784v1](http://arxiv.org/abs/2405.08784v1)|null|
|**2024-05-14**|**Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling**|Gregory Holste et.al.|[2405.08780v1](http://arxiv.org/abs/2405.08780v1)|null|
|**2024-05-14**|**EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training**|Yulin Wang et.al.|[2405.08768v1](http://arxiv.org/abs/2405.08768v1)|[link](https://github.com/leaplabthu/efficienttrain)|
|**2024-05-14**|**Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**|Akhila Yerukola et.al.|[2405.08760v1](http://arxiv.org/abs/2405.08760v1)|[link](https://github.com/Akhila-Yerukola/generative-intention-resolution)|
|**2024-05-14**|**Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach**|Syed Mhamudul Hasan et.al.|[2405.08755v1](http://arxiv.org/abs/2405.08755v1)|null|
|**2024-05-14**|**From Text to Context: An Entailment Approach for News Stakeholder Classification**|Alapan Kuila et.al.|[2405.08751v1](http://arxiv.org/abs/2405.08751v1)|null|
|**2024-05-14**|**Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis**|Qingpeng Kong et.al.|[2405.08681v1](http://arxiv.org/abs/2405.08681v1)|[link](https://github.com/kqp1227/sensitive-channel-pruning)|
|**2024-05-14**|**Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning**|Alain Riou et.al.|[2405.08679v1](http://arxiv.org/abs/2405.08679v1)|null|
|**2024-05-14**|**Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models**|Bingdong Li et.al.|[2405.08674v1](http://arxiv.org/abs/2405.08674v1)|null|
|**2024-05-14**|**Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research**|Qinglong Cao et.al.|[2405.08668v1](http://arxiv.org/abs/2405.08668v1)|[link](https://github.com/caoql98/GDPL)|
|**2024-05-14**|**Beyond the Black Box: Do More Complex Models Provide Superior XAI Explanations?**|Mateusz Cedro et.al.|[2405.08658v1](http://arxiv.org/abs/2405.08658v1)|null|
|**2024-05-14**|**Thinking Tokens for Language Modeling**|David Herel et.al.|[2405.08644v1](http://arxiv.org/abs/2405.08644v1)|null|
|**2024-05-14**|**ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation**|Dimitris Gkoumas et.al.|[2405.08619v2](http://arxiv.org/abs/2405.08619v2)|null|
|**2024-05-14**|**Towards Geometry-Aware Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization**|Yongfan Lu et.al.|[2405.08604v1](http://arxiv.org/abs/2405.08604v1)|null|
|**2024-05-14**|**A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine**|Hanguang Xiao et.al.|[2405.08603v1](http://arxiv.org/abs/2405.08603v1)|null|
|**2024-05-14**|**EchoTracker: Advancing Myocardial Point Tracking in Echocardiography**|Md Abulkalam Azad et.al.|[2405.08587v1](http://arxiv.org/abs/2405.08587v1)|null|
|**2024-05-14**|**Rethinking the adaptive relationship between Encoder Layers and Decoder Layers**|Yubo Song et.al.|[2405.08570v1](http://arxiv.org/abs/2405.08570v1)|null|
|**2024-05-14**|**The Unseen Targets of Hate -- A Systematic Review of Hateful Communication Datasets**|Zehui Yu et.al.|[2405.08562v1](http://arxiv.org/abs/2405.08562v1)|null|
|**2024-05-14**|**Improving Transformers with Dynamically Composable Multi-Head Attention**|Da Xiao et.al.|[2405.08553v1](http://arxiv.org/abs/2405.08553v1)|[link](https://github.com/caiyun-ai/dcformer)|
|**2024-05-14**|**Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization**|Rui Li et.al.|[2405.08540v1](http://arxiv.org/abs/2405.08540v1)|[link](https://github.com/xxrep/golde)|
|**2024-05-14**|**From Internet of Things Data to Business Processes: Challenges and a Framework**|Juergen Mangler et.al.|[2405.08528v1](http://arxiv.org/abs/2405.08528v1)|null|
|**2024-05-14**|**Falcon 7b for Software Mention Detection in Scholarly Documents**|AmeerAli Khan et.al.|[2405.08514v1](http://arxiv.org/abs/2405.08514v1)|null|
|**2024-05-14**|**Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure**|Odysseas S. Chlapanis et.al.|[2405.08502v1](http://arxiv.org/abs/2405.08502v1)|null|
|**2024-05-14**|**Is Less More? Quality, Quantity and Context in Idiom Processing with Natural Language Models**|Agne Knietaite et.al.|[2405.08497v1](http://arxiv.org/abs/2405.08497v1)|null|
|**2024-05-14**|**Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models**|Andrea Piergentili et.al.|[2405.08477v1](http://arxiv.org/abs/2405.08477v1)|null|
|**2024-05-14**|**GPT-3.5 for Grammatical Error Correction**|Anisia Katinskaia et.al.|[2405.08469v1](http://arxiv.org/abs/2405.08469v1)|null|
|**2024-05-14**|**Challenges and Opportunities in Text Generation Explainability**|Kenza Amara et.al.|[2405.08468v1](http://arxiv.org/abs/2405.08468v1)|null|
|**2024-05-14**|**Evaluating LLMs at Evaluating Temporal Generalization**|Chenghao Zhu et.al.|[2405.08460v1](http://arxiv.org/abs/2405.08460v1)|[link](https://github.com/freedomintelligence/freshbench)|
|**2024-05-14**|**How Alignment Helps Make the Most of Multimodal Data**|Christian Arnold et.al.|[2405.08454v1](http://arxiv.org/abs/2405.08454v1)|null|
|**2024-05-14**|**Understanding the performance gap between online and offline alignment algorithms**|Yunhao Tang et.al.|[2405.08448v1](http://arxiv.org/abs/2405.08448v1)|null|
|**2024-05-14**|**Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline**|Yuanchen Shi et.al.|[2405.08427v1](http://arxiv.org/abs/2405.08427v1)|null|
|**2024-05-14**|**Investigating the 'Autoencoder Behavior' in Speech Self-Supervised Models: a focus on HuBERT's Pretraining**|Valentin Vielzeuf et.al.|[2405.08402v1](http://arxiv.org/abs/2405.08402v1)|null|
|**2024-05-14**|**Stylometric Watermarks for Large Language Models**|Georg Niess et.al.|[2405.08400v1](http://arxiv.org/abs/2405.08400v1)|null|
|**2024-05-14**|**CIER: A Novel Experience Replay Approach with Causal Inference in Deep Reinforcement Learning**|Jingwen Wang et.al.|[2405.08380v1](http://arxiv.org/abs/2405.08380v1)|null|
|**2024-05-14**|**PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles**|Satya Kesav Gundabathula et.al.|[2405.08373v1](http://arxiv.org/abs/2405.08373v1)|null|
|**2024-05-14**|**Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark**|Mengsong Wu et.al.|[2405.08355v1](http://arxiv.org/abs/2405.08355v1)|null|
|**2024-05-14**|**Perivascular space Identification Nnunet for Generalised Usage (PINGU)**|Benjamin Sinclair et.al.|[2405.08337v1](http://arxiv.org/abs/2405.08337v1)|null|
|**2024-05-14**|**Could Chemical LLMs benefit from Message Passing**|Jiaqing Xie et.al.|[2405.08334v1](http://arxiv.org/abs/2405.08334v1)|null|
|**2024-05-14**|**Cross-Dataset Generalization For Retinal Lesions Segmentation**|Cl√©ment Playout et.al.|[2405.08329v1](http://arxiv.org/abs/2405.08329v1)|null|
|**2024-05-14**|**SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models**|Raghuveer Peri et.al.|[2405.08317v1](http://arxiv.org/abs/2405.08317v1)|null|
|**2024-05-14**|**A Decoupling and Aggregating Framework for Joint Extraction of Entities and Relations**|Yao Wang et.al.|[2405.08311v1](http://arxiv.org/abs/2405.08311v1)|null|
|**2024-05-14**|**Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind**|Iris Oved et.al.|[2405.08304v2](http://arxiv.org/abs/2405.08304v2)|null|
|**2024-05-14**|**Distance-Restricted Explanations: Theoretical Underpinnings & Efficient Implementation**|Yacine Izza et.al.|[2405.08297v1](http://arxiv.org/abs/2405.08297v1)|null|
|**2024-05-14**|**SpeechVerse: A Large-scale Generalizable Audio Language Model**|Nilaksh Das et.al.|[2405.08295v1](http://arxiv.org/abs/2405.08295v1)|null|
|**2024-05-14**|**Detecting Fallacies in Climate Misinformation: A Technocognitive Approach to Identifying Misleading Argumentation**|Francisco Zanartu et.al.|[2405.08254v1](http://arxiv.org/abs/2405.08254v1)|null|
|**2024-05-14**|**Smart Sampling: Self-Attention and Bootstrapping for Improved Ensembled Q-Learning**|Muhammad Junaid Khan et.al.|[2405.08252v1](http://arxiv.org/abs/2405.08252v1)|null|
|**2024-05-14**|**Automated classification of multi-parametric body MRI series**|Boah Kim et.al.|[2405.08247v1](http://arxiv.org/abs/2405.08247v1)|null|
|**2024-05-14**|**Compositional Text-to-Image Generation with Dense Blob Representations**|Weili Nie et.al.|[2405.08246v1](http://arxiv.org/abs/2405.08246v1)|null|
|**2024-05-14**|**Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy**|Xiameng Wei et.al.|[2405.08245v1](http://arxiv.org/abs/2405.08245v1)|null|
|**2024-05-13**|**Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT**|Takao Fujii et.al.|[2405.08238v1](http://arxiv.org/abs/2405.08238v1)|null|
|**2024-05-13**|**A predictive learning model can simulate temporal dynamics and context effects found in neural representations of continuous speech**|Oli Danyi Liu et.al.|[2405.08237v1](http://arxiv.org/abs/2405.08237v1)|null|
|**2024-05-13**|**An information-theoretic model of shallow and deep language comprehension**|Jiaxuan Li et.al.|[2405.08223v1](http://arxiv.org/abs/2405.08223v1)|null|
|**2024-05-13**|**Interpreting Latent Student Knowledge Representations in Programming Assignments**|Nigel Fernandez et.al.|[2405.08213v1](http://arxiv.org/abs/2405.08213v1)|null|
|**2024-05-13**|**Towards Energy-Aware Federated Learning via MARL: A Dual-Selection Approach for Model and Client**|Jun Xia et.al.|[2405.08183v1](http://arxiv.org/abs/2405.08183v1)|null|
|**2024-05-13**|**Estimating Direct and Indirect Causal Effects of Spatiotemporal Interventions in Presence of Spatial Interference**|Sahara Ali et.al.|[2405.08174v1](http://arxiv.org/abs/2405.08174v1)|null|
|**2024-05-13**|**CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation**|Kung Yin Hong et.al.|[2405.08172v1](http://arxiv.org/abs/2405.08172v1)|[link](https://github.com/kenrickkung/cantonesetranslation)|
|**2024-05-13**|**LLM Theory of Mind and Alignment: Opportunities and Risks**|Winnie Street et.al.|[2405.08154v1](http://arxiv.org/abs/2405.08154v1)|null|
|**2024-05-13**|**Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness**|Mingchen Li et.al.|[2405.08151v1](http://arxiv.org/abs/2405.08151v1)|null|
|**2024-05-13**|**Many-Shot Regurgitation (MSR) Prompting**|Shashank Sonkar et.al.|[2405.08134v1](http://arxiv.org/abs/2405.08134v1)|[link](https://github.com/luffycodes/Many-Shot-Regurgitation-MIA)|
|**2024-05-13**|**When factorization meets argumentation: towards argumentative explanations**|Jinfeng Zhong et.al.|[2405.08131v1](http://arxiv.org/abs/2405.08131v1)|null|
|**2024-05-13**|**From Questions to Insightful Answers: Building an Informed Chatbot for University Resources**|Subash Neupane et.al.|[2405.08120v1](http://arxiv.org/abs/2405.08120v1)|null|
|**2024-05-13**|**KET-QA: A Dataset for Knowledge Enhanced Table Question Answering**|Mengkang Hu et.al.|[2405.08099v1](http://arxiv.org/abs/2405.08099v1)|null|
|**2024-05-13**|**MambaOut: Do We Really Need Mamba for Vision?**|Weihao Yu et.al.|[2405.07992v2](http://arxiv.org/abs/2405.07992v2)|[link](https://github.com/yuweihao/mambaout)|
|**2024-05-13**|**Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots**|Chengyue Wu et.al.|[2405.07990v1](http://arxiv.org/abs/2405.07990v1)|null|
|**2024-05-13**|**The Platonic Representation Hypothesis**|Minyoung Huh et.al.|[2405.07987v1](http://arxiv.org/abs/2405.07987v1)|[link](https://github.com/minyoungg/platonic-rep)|
|**2024-05-13**|**Localized Adaptive Risk Control**|Matteo Zecchin et.al.|[2405.07976v1](http://arxiv.org/abs/2405.07976v1)|[link](https://github.com/kclip/localized-adaptive-risk-control)|
|**2024-05-13**|**Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation**|Kevin Stangl et.al.|[2405.07969v1](http://arxiv.org/abs/2405.07969v1)|null|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments**|Samuel Schmidgall et.al.|[2405.07960v1](http://arxiv.org/abs/2405.07960v1)|null|
|**2024-05-13**|**Hierarchical Decision Mamba**|Andr√© Correia et.al.|[2405.07943v1](http://arxiv.org/abs/2405.07943v1)|[link](https://github.com/meowatthemoon/hierarchicaldecisionmamba)|
|**2024-05-13**|**RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors**|Liam Dugan et.al.|[2405.07940v1](http://arxiv.org/abs/2405.07940v1)|null|
|**2024-05-13**|**EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning**|Yinzhu Quan et.al.|[2405.07938v1](http://arxiv.org/abs/2405.07938v1)|null|
|**2024-05-13**|**PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition**|Ziyang Zhang et.al.|[2405.07932v2](http://arxiv.org/abs/2405.07932v2)|[link](https://github.com/ed-zh/parden)|
|**2024-05-13**|**Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data**|Mahdi Morafah et.al.|[2405.07925v1](http://arxiv.org/abs/2405.07925v1)|null|
|**2024-05-13**|**Science based AI model certification for new operational environments with application in traffic state estimation**|Daryl Mupupuni et.al.|[2405.07893v1](http://arxiv.org/abs/2405.07893v1)|null|
|**2024-05-13**|**Russian-Language Multimodal Dataset for Automatic Summarization of Scientific Papers**|Alena Tsanda et.al.|[2405.07886v1](http://arxiv.org/abs/2405.07886v1)|null|
|**2024-05-13**|**Zero-Shot Tokenizer Transfer**|Benjamin Minixhofer et.al.|[2405.07883v1](http://arxiv.org/abs/2405.07883v1)|[link](https://github.com/bminixhofer/zett)|
|**2024-05-13**|**Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques**|Michela Lorandi et.al.|[2405.07875v1](http://arxiv.org/abs/2405.07875v1)|null|
|**2024-05-13**|**RLHF Workflow: From Reward Modeling to Online RLHF**|Hanze Dong et.al.|[2405.07863v1](http://arxiv.org/abs/2405.07863v1)|[link](https://github.com/rlhflow/online-rlhf)|
|**2024-05-13**|**Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM**|Xiaoyu Chen et.al.|[2405.07840v1](http://arxiv.org/abs/2405.07840v1)|null|
|**2024-05-13**|**Synthetic Tabular Data Validation: A Divergence-Based Approach**|Patricia A. Apell√°niz et.al.|[2405.07822v1](http://arxiv.org/abs/2405.07822v1)|[link](https://github.com/patricia-a-apellaniz/divergence_estimator)|
|**2024-05-13**|**Quick and Accurate Affordance Learning**|Fedor Scholz et.al.|[2405.07816v1](http://arxiv.org/abs/2405.07816v1)|null|
|**2024-05-13**|**Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles**|Hector Zenil et.al.|[2405.07803v1](http://arxiv.org/abs/2405.07803v1)|null|
|**2024-05-13**|**FreeVA: Offline MLLM as Training-Free Video Assistant**|Wenhao Wu et.al.|[2405.07798v1](http://arxiv.org/abs/2405.07798v1)|[link](https://github.com/whwu95/freeva)|
|**2024-05-13**|**DEPTH: Discourse Education through Pre-Training Hierarchically**|Zachary Bamberger et.al.|[2405.07788v1](http://arxiv.org/abs/2405.07788v1)|[link](https://github.com/zbambergerNLP/depth)|
|**2024-05-13**|**A Comprehensive Analysis of Static Word Embeddings for Turkish**|Karahan Sarƒ±ta≈ü et.al.|[2405.07778v1](http://arxiv.org/abs/2405.07778v1)|[link](https://github.com/turkish-word-embeddings/word-embeddings-repository-for-turkish)|
|**2024-05-13**|**Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI**|Silvia Tulli et.al.|[2405.07773v1](http://arxiv.org/abs/2405.07773v1)|null|
|**2024-05-13**|**Synthetic Test Collections for Retrieval Evaluation**|Hossein A. Rahmani et.al.|[2405.07767v1](http://arxiv.org/abs/2405.07767v1)|null|
|**2024-05-13**|**Challenges and Opportunities of NLP for HR Applications: A Discussion Paper**|Jochen L. Leidner et.al.|[2405.07766v1](http://arxiv.org/abs/2405.07766v1)|null|
|**2024-05-13**|**TANQ: An open domain dataset of table answered questions**|Mubashara Akhtar et.al.|[2405.07765v1](http://arxiv.org/abs/2405.07765v1)|null|
|**2024-05-13**|**LLM4ED: Large Language Models for Automatic Equation Discovery**|Mengge Du et.al.|[2405.07761v1](http://arxiv.org/abs/2405.07761v1)|null|
|**2024-05-13**|**MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction**|Haopeng Wang et.al.|[2405.07759v1](http://arxiv.org/abs/2405.07759v1)|null|
|**2024-05-13**|**Mitigating federated learning contribution allocation instability through randomized aggregation**|Arno Geimer et.al.|[2405.08044v1](http://arxiv.org/abs/2405.08044v1)|null|
|**2024-05-13**|**LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language**|Cagri Toraman et.al.|[2405.07745v1](http://arxiv.org/abs/2405.07745v1)|[link](https://github.com/metunlp/llamaturk)|
|**2024-05-13**|**Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare**|Amandeep Singh Bhatia et.al.|[2405.07735v1](http://arxiv.org/abs/2405.07735v1)|null|
|**2024-05-13**|**Quantifying and Optimizing Global Faithfulness in Persona-driven Role-playing**|Letian Peng et.al.|[2405.07726v1](http://arxiv.org/abs/2405.07726v1)|[link](https://github.com/KomeijiForce/Active_Passive_Constraint_Koishiday_2024)|
|**2024-05-13**|**A Unified Sequence Parallelism Approach for Long Context Generative AI**|Jiarui Fang et.al.|[2405.07719v3](http://arxiv.org/abs/2405.07719v3)|[link](https://github.com/feifeibear/long-context-attention)|
|**2024-05-13**|**OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2**|Mihai Masala et.al.|[2405.07703v3](http://arxiv.org/abs/2405.07703v3)|null|

#### Abstracts
##### **Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs**
2405.08792v1 by Edison Jair Bejarano Sepulveda, Nicolai Potes Hector, Santiago Pineda Montoya, Felipe Ivan Rodriguez, Jaime Enrique Orduy, Alec Rosales Cabezas, Danny Traslavi√±a Navarrete, Sergio Madrid Farfan

This paper explores the potential of large language models (LLMs) to make the
Aeronautical Regulations of Colombia (RAC) more accessible. Given the
complexity and extensive technicality of the RAC, this study introduces a novel
approach to simplifying these regulations for broader understanding. By
developing the first-ever RAC database, which contains 24,478 expertly labeled
question-and-answer pairs, and fine-tuning LLMs specifically for RAC
applications, the paper outlines the methodology for dataset assembly,
expert-led annotation, and model training. Utilizing the Gemma1.1 2b model
along with advanced techniques like Unsloth for efficient VRAM usage and flash
attention mechanisms, the research aims to expedite training processes. This
initiative establishes a foundation to enhance the comprehensibility and
accessibility of RAC, potentially benefiting novices and reducing dependence on
expert consultations for navigating the aviation industry's regulatory
landscape.
  You can visit the dataset
(https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1)
and the model
(https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated) here.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÆìÂì•ÂÄ´ÊØî‰∫ûËà™Á©∫Ê≥ïË¶è (RAC) Êõ¥ÂÆπÊòìÁêÜËß£ÁöÑÊΩõÂäõ„ÄÇÈëëÊñº RAC ÁöÑË§áÈõúÊÄßÂíåÂª£Ê≥õÊäÄË°ìÊÄßÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂåñÈÄô‰∫õÊ≥ïË¶è‰ª•‰øÉÈÄ≤Êõ¥Âª£Ê≥õÁêÜËß£ÁöÑÊñ∞Á©éÊñπÊ≥ï„ÄÇÈÄèÈÅéÈñãÁôºÊúâÂè≤‰ª•‰æÜÁ¨¨‰∏ÄÂÄã RAC Ë≥áÊñôÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´ 24,478 ÂÄãÁî±Â∞àÂÆ∂Ê®ôË®òÁöÑÂïèÈ°åÂíåÁ≠îÊ°àÂ∞çÔºå‰∏¶ÈáùÂ∞ç RAC ÊáâÁî®ÂæÆË™ø LLMÔºåÊú¨ÊñáÊ¶ÇËø∞‰∫ÜË≥áÊñôÈõÜÁµÑË£ù„ÄÅÂ∞àÂÆ∂‰∏ªÂ∞éË®ªËß£ÂíåÊ®°ÂûãË®ìÁ∑¥ÁöÑÊñπÊ≥ï„ÄÇÊú¨Á†îÁ©∂Âà©Áî® Gemma1.1 2b Ê®°Âûã‰ª•Âèä Unsloth Á≠âÂÖàÈÄ≤ÊäÄË°ìÔºå‰ª•ÊúâÊïàÂà©Áî® VRAM ÂíåÈñÉÁèæÊ≥®ÊÑèÂäõÊ©üÂà∂ÔºåÊó®Âú®Âä†ÈÄüË®ìÁ∑¥ÈÅéÁ®ã„ÄÇÊ≠§ËàâÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂü∫Á§éÔºå‰ª•Â¢ûÂº∑ RAC ÁöÑÂèØÁêÜËß£ÊÄßÂíåÂèØÂèäÊÄßÔºåÊΩõÂú®ÂèóÁõäÊñºÊñ∞ÊâãÔºå‰∏¶Ê∏õÂ∞ëÂ∞çÂ∞àÂÆ∂Ë´ÆË©¢ÁöÑ‰æùË≥¥Ôºå‰ª•‰∫ÜËß£Ëà™Á©∫Ê•≠ÁöÑÊ≥ïË¶èÁí∞Â¢É„ÄÇÊÇ®ÂèØ‰ª•Âú®Ê≠§ËôïÊü•ÁúãË≥áÊñôÈõÜ (https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1) ÂíåÊ®°Âûã (https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated)„ÄÇ

##### **Kolmogorov-Arnold Networks (KANs) for Time Series Analysis**
2405.08790v1 by Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, M√†rius Caus

This paper introduces a novel application of Kolmogorov-Arnold Networks
(KANs) to time series forecasting, leveraging their adaptive activation
functions for enhanced predictive modeling. Inspired by the Kolmogorov-Arnold
representation theorem, KANs replace traditional linear weights with
spline-parametrized univariate functions, allowing them to learn activation
patterns dynamically. We demonstrate that KANs outperforms conventional
Multi-Layer Perceptrons (MLPs) in a real-world satellite traffic forecasting
task, providing more accurate results with considerably fewer number of
learnable parameters. We also provide an ablation study of KAN-specific
parameters impact on performance. The proposed approach opens new avenues for
adaptive forecasting models, emphasizing the potential of KANs as a powerful
tool in predictive analytics.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü Kolmogorov-Arnold Á∂≤Ë∑Ø (KAN) Âú®ÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨ÁöÑÊñ∞Á©éÊáâÁî®ÔºåÂà©Áî®ÂÖ∂Ëá™ÈÅ©ÊáâÊøÄÊ¥ªÂáΩÊï∏‰æÜÂ¢ûÂº∑È†êÊ∏¨Ê®°Âûã„ÄÇÂèó Kolmogorov-Arnold Ë°®Á§∫ÂÆöÁêÜÁöÑÂïüÁôºÔºåKAN ‰ª•Ê®£Ê¢ùÂèÉÊï∏ÂåñÁöÑÂñÆËÆäÊï∏ÂáΩÊï∏Âèñ‰ª£ÂÇ≥Áµ±Á∑öÊÄßÊ¨äÈáçÔºåËÆìÂÆÉÂÄëËÉΩÂ§†ÂãïÊÖãÂ≠∏ÁøíÊøÄÊ¥ªÊ®°Âºè„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü KAN Âú®ÂØ¶ÈöõË°õÊòüÊµÅÈáèÈ†êÊ∏¨‰ªªÂãô‰∏≠ÂÑ™ÊñºÂÇ≥Áµ±Â§öÂ±§ÊÑüÁü•Âô® (MLP)ÔºåÂú®ÂèØÂ≠∏ÁøíÂèÉÊï∏Êï∏ÈáèÈ°ØËëóÊ∏õÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ãÊèê‰æõ‰∫ÜÊõ¥Ê∫ñÁ¢∫ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü KAN ÁâπÂÆöÂèÉÊï∏Â∞çÊïàËÉΩÂΩ±ÈüøÁöÑÊ∂àËûçÁ†îÁ©∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÁÇ∫Ëá™ÈÅ©ÊáâÈ†êÊ∏¨Ê®°ÂûãÈñãÂïü‰∫ÜÊñ∞ÁöÑÈÄîÂæëÔºåÂº∑Ë™ø‰∫Ü KAN ‰ΩúÁÇ∫È†êÊ∏¨ÂàÜÊûê‰∏≠Âº∑Â§ßÂ∑•ÂÖ∑ÁöÑÊΩõÂäõ„ÄÇ

##### **Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram**
2405.08784v1 by Aehong Min, Xuan Wang, Rion Brattig Correia, Jordan Rozum, Wendy R. Miller, Luis M. Rocha

We used a dictionary built from biomedical terminology extracted from various
sources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8
million Instagram posts by users who have mentioned an epilepsy-relevant drug
at least once, between 2010 and early 2016. A random sample of 1,771 posts with
2,947 term matches was evaluated by human annotators to identify
false-positives. OpenAI's GPT series models were compared against human
annotation. Frequent terms with a high false-positive rate were removed from
the dictionary. Analysis of the estimated false-positive rates of the annotated
terms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which
were removed from the original dictionary. To study the effect of removing
those terms, we constructed knowledge networks using the refined and the
original dictionaries and performed an eigenvector-centrality analysis on both
networks. We show that the refined dictionary thus produced leads to a
significantly different rank of important terms, as measured by their
eigenvector-centrality of the knowledge networks. Furthermore, the most
important terms obtained after refinement are of greater medical relevance. In
addition, we show that OpenAI's GPT series models fare worse than human
annotators in this task.

ÊëòË¶ÅÔºöÊàëÂÄë‰ΩøÁî®ÂæûÂêÑÁ®Æ‰æÜÊ∫êÔºà‰æãÂ¶Ç DrugBank„ÄÅMedDRA„ÄÅMedlinePlus„ÄÅTCMGeneDITÔºâ‰∏≠ÊèêÂèñÁöÑÁîüÁâ©ÈÜ´Â≠∏Ë°ìË™ûÊâÄÂª∫ÊßãÁöÑË©ûÂÖ∏ÔºåÊ®ôË®ò‰∫Ü 2010 Âπ¥Ëá≥ 2016 Âπ¥Âàù‰πãÈñìÔºåË∂ÖÈÅé 800 Ëê¨ÂâáËá≥Â∞ëÊèêÂèäÈÅé‰∏ÄÊ¨°Áô≤ÁôáÁõ∏ÈóúËó•Áâ©ÁöÑ Instagram Ë≤ºÊñá„ÄÇÁî±‰∫∫È°ûË®ªÈáãËÄÖË©ï‰º∞‰∫Ü 1,771 ÂâáÈö®Ê©üÊäΩÊ®£Ë≤ºÊñáÔºåÂÖ∂‰∏≠ÂåÖÂê´ 2,947 ÂÄãË©ûÂΩôÊØîÂ∞çÔºå‰ª•ÊâæÂá∫ÂÅáÈôΩÊÄß„ÄÇÂ∞á OpenAI ÁöÑ GPT Á≥ªÂàóÊ®°ÂûãËàá‰∫∫È°ûË®ªÈáãÈÄ≤Ë°åÊØîËºÉ„ÄÇÂæûË©ûÂÖ∏‰∏≠ÁßªÈô§‰∫ÜÂÅáÈôΩÊÄßÁéáÈ´òÁöÑÈ†ªÁπÅË©ûÂΩô„ÄÇÂ∞çË®ªÈáãË©ûÂΩôÁöÑ‰º∞Ë®àÂÅáÈôΩÊÄßÁéáÈÄ≤Ë°åÂàÜÊûêÔºåÊè≠Á§∫‰∫Ü Instagram Ë≤ºÊñá‰∏≠‰ΩøÁî®ÁöÑ 8 ÂÄãÊ®°Á®úÂÖ©ÂèØÁöÑË©ûÂΩôÔºàÂä†‰∏äÂêåÁæ©Ë©ûÔºâÔºåÈÄô‰∫õË©ûÂΩôÂ∑≤ÂæûÂéüÂßãË©ûÂÖ∏‰∏≠ÁßªÈô§„ÄÇÁÇ∫‰∫ÜÁ†îÁ©∂ÁßªÈô§ÈÄô‰∫õË©ûÂΩôÁöÑÊïàÊûúÔºåÊàëÂÄë‰ΩøÁî®Á≤æÁÖâÈÅéÁöÑË©ûÂÖ∏ÂíåÂéüÂßãË©ûÂÖ∏Âª∫Êßã‰∫ÜÁü•Ë≠òÁ∂≤Ë∑ØÔºå‰∏¶Â∞çÈÄôÂÖ©ÂÄãÁ∂≤Ë∑ØÂü∑Ë°åÁâπÂæµÂêëÈáè‰∏≠ÂøÉÊÄßÂàÜÊûê„ÄÇÊàëÂÄëÈ°ØÁ§∫ÔºåÂ¶ÇÊ≠§Áî¢ÁîüÁöÑÁ≤æÁÖâÈÅéË©ûÂÖ∏ÊúÉÂ∞éËá¥ÈáçË¶ÅË©ûÂΩôÁöÑÊéíÂêçÈ°ØËëó‰∏çÂêåÔºåÈÄôÊòØÈÄèÈÅéÁü•Ë≠òÁ∂≤Ë∑ØÁöÑÁâπÂæµÂêëÈáè‰∏≠ÂøÉÊÄß‰æÜË°°ÈáèÁöÑ„ÄÇÊ≠§Â§ñÔºåÁ≤æÁÖâÂæåÁç≤ÂæóÁöÑÊúÄÈáçË¶ÅË©ûÂΩôÂÖ∑ÊúâÊõ¥Â§ßÁöÑÈÜ´ÁôÇÁõ∏ÈóúÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈ°ØÁ§∫ OpenAI ÁöÑ GPT Á≥ªÂàóÊ®°ÂûãÂú®ÈÄôÂÄã‰ªªÂãô‰∏≠ÁöÑË°®ÁèæÊØî‰∫∫È°ûË®ªÈáãËÄÖÂ∑Æ„ÄÇ

##### **Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling**
2405.08780v1 by Gregory Holste, Mingquan Lin, Ruiwen Zhou, Fei Wang, Lei Liu, Qi Yan, Sarah H. Van Tassel, Kyle Kovacs, Emily Y. Chew, Zhiyong Lu, Zhangyang Wang, Yifan Peng

Deep learning has enabled breakthroughs in automated diagnosis from medical
imaging, with many successful applications in ophthalmology. However, standard
medical image classification approaches only assess disease presence at the
time of acquisition, neglecting the common clinical setting of longitudinal
imaging. For slow, progressive eye diseases like age-related macular
degeneration (AMD) and primary open-angle glaucoma (POAG), patients undergo
repeated imaging over time to track disease progression and forecasting the
future risk of developing disease is critical to properly plan treatment. Our
proposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamic
disease prognosis from longitudinal medical imaging, modeling the time to
disease from sequences of fundus photography images captured over long,
irregular time periods. Using longitudinal imaging data from the Age-Related
Eye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSA
significantly outperformed a single-image baseline in 19/20 head-to-head
comparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. A
temporal attention analysis also suggested that, while the most recent image is
typically the most influential, prior imaging still provides additional
prognostic value.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤‰ΩøËá™ÂãïË®∫Êñ∑ÂæûÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Áç≤ÂæóÁ™ÅÁ†¥ÔºåÂú®ÁúºÁßë‰∏≠ÊúâË®±Â§öÊàêÂäüÁöÑÊáâÁî®„ÄÇÁÑ∂ËÄåÔºåÊ®ôÊ∫ñÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÈ°ûÊñπÊ≥ïÂÉÖÂú®Êé°ÈõÜÊôÇË©ï‰º∞ÁñæÁóÖÁöÑÂ≠òÂú®ÔºåÂøΩÁï•‰∫ÜÁ∏±ÂêëÂΩ±ÂÉèÁöÑÂ∏∏Ë¶ãËá®Â∫äË®≠ÁΩÆ„ÄÇÂ∞çÊñºÂπ¥ÈΩ°Áõ∏ÈóúÊÄßÈªÉÊñëÈÉ®ÁóÖËÆä (AMD) ÂíåÂéüÁôºÊÄßÈñãÊîæËßíÂûãÈùíÂÖâÁúº (POAG) Á≠âÁ∑©ÊÖ¢„ÄÅÈÄ≤Ë°åÊÄßÁöÑÁúºÁñæÔºåÊÇ£ËÄÖÊúÉÈö®ËëóÊôÇÈñìÊé®ÁßªÊé•ÂèóÈáçË§áÂΩ±ÂÉèÊ™¢Êü•‰ª•ËøΩËπ§ÁñæÁóÖÈÄ≤Á®ãÔºåËÄåÈ†êÊ∏¨Êú™‰æÜÁΩπÊÇ£ÁñæÁóÖÁöÑÈ¢®Èö™Â∞çÊñºÈÅ©Áï∂Âú∞Ë¶èÂäÉÊ≤ªÁôÇËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÁ∏±ÂêëÂ≠òÊ¥ªÂàÜÊûêTransformer (LTSA) ËÉΩÂ§†Ê†πÊìöÁ∏±ÂêëÈÜ´Â≠∏ÂΩ±ÂÉèÈÄ≤Ë°åÂãïÊÖãÁñæÁóÖÈ†êÂæåÔºåÂª∫Ê®°ÂæûÈï∑ÊôÇÈñì„ÄÅ‰∏çË¶èÂâáÊôÇÈñìÊÆµÂÖßÊì∑ÂèñÁöÑÁúºÂ∫ïÊîùÂΩ±ÂΩ±ÂÉèÂ∫èÂàóÂà∞ÁñæÁóÖÁöÑÊôÇÈñì„ÄÇ‰ΩøÁî®‰æÜËá™Âπ¥ÈΩ°Áõ∏ÈóúÊÄßÁúºÁñæÁ†îÁ©∂ (AREDS) ÂíåÁúºÈÉ®È´òË°ÄÂ£ìÊ≤ªÁôÇÁ†îÁ©∂ (OHTS) ÁöÑÁ∏±ÂêëÂΩ±ÂÉèË≥áÊñôÔºåLTSA Âú® 19/20 ÂÄã AMD ÊôöÊúüÈ†êÂæåÊ≠£Èù¢‰∫§ÈãíÊØîËºÉ‰∏≠Âíå 18/20 ÂÄã POAG È†êÂæåÊØîËºÉ‰∏≠È°ØËëóÂÑ™ÊñºÂñÆ‰∏ÄÂΩ±ÂÉèÂü∫Ê∫ñ„ÄÇÊôÇÈñìÊ≥®ÊÑèÂäõÂàÜÊûê‰πüË°®ÊòéÔºåÈõñÁÑ∂ÊúÄËøëÁöÑÂΩ±ÂÉèÈÄöÂ∏∏ÂΩ±ÈüøÊúÄÂ§ßÔºå‰ΩÜÂÖàÂâçÁöÑÂΩ±ÂÉè‰ªçÊèê‰æõÈ°çÂ§ñÁöÑÈ†êÂæåÂÉπÂÄº„ÄÇ

##### **EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training**
2405.08768v1 by Yulin Wang, Yang Yue, Rui Lu, Yizeng Han, Shiji Song, Gao Huang

The superior performance of modern visual backbones usually comes with a
costly training procedure. We contribute to this issue by generalizing the idea
of curriculum learning beyond its original formulation, i.e., training models
using easier-to-harder data. Specifically, we reformulate the training
curriculum as a soft-selection function, which uncovers progressively more
difficult patterns within each example during training, instead of performing
easier-to-harder sample selection. Our work is inspired by an intriguing
observation on the learning dynamics of visual backbones: during the earlier
stages of training, the model predominantly learns to recognize some
'easier-to-learn' discriminative patterns in the data. These patterns, when
observed through frequency and spatial domains, incorporate lower-frequency
components, and the natural image contents without distortion or data
augmentation. Motivated by these findings, we propose a curriculum where the
model always leverages all the training data at every learning stage, yet the
exposure to the 'easier-to-learn' patterns of each example is initiated first,
with harder patterns gradually introduced as training progresses. To implement
this idea in a computationally efficient way, we introduce a cropping operation
in the Fourier spectrum of the inputs, enabling the model to learn from only
the lower-frequency components. Then we show that exposing the contents of
natural images can be readily achieved by modulating the intensity of data
augmentation. Finally, we integrate these aspects and design curriculum
schedules with tailored search algorithms. The resulting method,
EfficientTrain++, is simple, general, yet surprisingly effective. It reduces
the training time of a wide variety of popular models by 1.5-3.0x on
ImageNet-1K/22K without sacrificing accuracy. It also demonstrates efficacy in
self-supervised learning (e.g., MAE).

ÊëòË¶ÅÔºöÁèæ‰ª£Ë¶ñË¶∫È™®ÂππÁöÑÂÑ™Áï∞ÊïàËÉΩÈÄöÂ∏∏‰º¥Èö®ËëóÊòÇË≤¥ÁöÑË®ìÁ∑¥Á®ãÂ∫è„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞áË™≤Á®ãÂ≠∏ÁøíÁöÑÊ¶ÇÂøµÊé®Âª£Âà∞ÂÖ∂ÂéüÂßãÂÖ¨Âºè‰πãÂ§ñ‰æÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÂç≥‰ΩøÁî®ÊòìÊñºÈõ£ÁöÑË≥áÊñôË®ìÁ∑¥Ê®°Âûã„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áË®ìÁ∑¥Ë™≤Á®ãÈáçÊñ∞Ë°®Ëø∞ÁÇ∫ËªüÈÅ∏ÊìáÂáΩÊï∏ÔºåÂú®Ë®ìÁ∑¥ÊúüÈñìÈÄêÊ≠•Êè≠Á§∫ÊØèÂÄãÁØÑ‰æã‰∏≠Êõ¥Âõ∞Èõ£ÁöÑÊ®°ÂºèÔºåËÄå‰∏çÊòØÂü∑Ë°åÊòìÊñºÈõ£ÁöÑÊ®£Êú¨ÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÈùàÊÑü‰æÜËá™Â∞çË¶ñË¶∫È™®ÂππÂ≠∏ÁøíÂãïÊÖãÁöÑÊúâË∂£ËßÄÂØüÔºöÂú®Ë®ìÁ∑¥ÁöÑÊó©ÊúüÈöéÊÆµÔºåÊ®°Âûã‰∏ªË¶ÅÂ≠∏ÁøíË≠òÂà•Ë≥áÊñô‰∏≠‰∏Ä‰∫õ„ÄåËºÉÂÆπÊòìÂ≠∏Áøí„ÄçÁöÑËæ®Âà•Ê®°Âºè„ÄÇÈÄô‰∫õÊ®°ÂºèÂú®ÈÄèÈÅéÈ†ªÁéáÂíåÁ©∫ÈñìÂüüËßÄÂØüÊôÇÔºåÊúÉÁ¥çÂÖ•ËºÉ‰ΩéÈ†ªÁéáÁöÑÁµÑÊàêÔºå‰ª•ÂèäÊ≤íÊúâÂ§±ÁúüÊàñË≥áÊñôÂ¢ûÂº∑ÁöÑËá™ÁÑ∂ÂΩ±ÂÉèÂÖßÂÆπ„ÄÇÂèóÂà∞ÈÄô‰∫õÁôºÁèæÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË™≤Á®ãÔºåÂÖ∂‰∏≠Ê®°ÂûãÂú®ÊØèÂÄãÂ≠∏ÁøíÈöéÊÆµÂßãÁµÇÂà©Áî®ÊâÄÊúâË®ìÁ∑¥Ë≥áÊñôÔºå‰ΩÜÈ¶ñÂÖàÊé•Ëß∏ÊØèÂÄãÁØÑ‰æãÁöÑ„ÄåËºÉÂÆπÊòìÂ≠∏Áøí„ÄçÊ®°ÂºèÔºå‰∏¶Èö®ËëóË®ìÁ∑¥ÁöÑÈÄ≤Â±ïÈÄêÊº∏ÂºïÂÖ•Êõ¥Âõ∞Èõ£ÁöÑÊ®°Âºè„ÄÇÁÇ∫‰∫Ü‰ª•Ë®àÁÆóÊúâÊïàÁéáÁöÑÊñπÂºèÂØ¶‰ΩúÈÄôÂÄãÊÉ≥Ê≥ïÔºåÊàëÂÄëÂú®Ëº∏ÂÖ•ÁöÑÂÇÖÁ´ãËëâÈ†ªË≠ú‰∏≠ÂºïÂÖ•Ë£ÅÂàáÊìç‰ΩúÔºåËÆìÊ®°ÂûãÂè™ËÉΩÂæûËºÉ‰ΩéÈ†ªÁéáÁöÑÁµÑÊàêÂ≠∏Áøí„ÄÇÁÑ∂ÂæåÊàëÂÄëË°®ÊòéÔºåÈÄèÈÅéË™øÊï¥Ë≥áÊñôÂ¢ûÂº∑ÁöÑÂº∑Â∫¶ÔºåÂèØ‰ª•ËºïÊòìÂú∞Êè≠Èú≤Ëá™ÁÑ∂ÂΩ±ÂÉèÁöÑÂÖßÂÆπ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊï¥ÂêàÈÄô‰∫õÈù¢ÂêëÔºå‰∏¶Ë®≠Ë®àÂá∫ÂÖ∑ÂÇôÂÆ¢Ë£ΩÂåñÊêúÂ∞ãÊºîÁÆóÊ≥ïÁöÑË™≤Á®ãÊôÇÁ®ã„ÄÇÁî±Ê≠§Áî¢ÁîüÁöÑÊñπÊ≥ï EfficientTrain++ Á∞°ÂñÆ„ÄÅÈÄöÁî®Ôºå‰ΩÜÊïàÊûúÈ©ö‰∫∫„ÄÇÂÆÉÂú®‰∏çÁäßÁâ≤Ê∫ñÁ¢∫ÊÄßÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂ∞áÂêÑÁ®ÆÁÜ±ÈñÄÊ®°ÂûãÂú® ImageNet-1K/22K ‰∏äÁöÑË®ìÁ∑¥ÊôÇÈñìÊ∏õÂ∞ë‰∫Ü 1.5-3.0 ÂÄç„ÄÇÂÆÉ‰πüË≠âÊòé‰∫ÜÂú®Ëá™ÊàëÁõ£Áù£Â≠∏ÁøíÔºà‰æãÂ¶Ç MAEÔºâ‰∏≠ÁöÑÊïàÂäõ„ÄÇ

##### **Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**
2405.08760v1 by Akhila Yerukola, Saujas Vaduguru, Daniel Fried, Maarten Sap

Humans often express their communicative intents indirectly or non-literally,
which requires their interlocutors -- human or AI -- to understand beyond the
literal meaning of words. While most existing work has focused on
discriminative evaluations, we present a new approach to generatively evaluate
large language models' (LLMs') intention understanding by examining their
responses to non-literal utterances. Ideally, an LLM should respond in line
with the true intention of a non-literal utterance, not its literal
interpretation. Our findings show that LLMs struggle to generate pragmatically
relevant responses to non-literal language, achieving only 50-55% accuracy on
average. While explicitly providing oracle intentions significantly improves
performance (e.g., 75% for Mistral-Instruct), this still indicates challenges
in leveraging given intentions to produce appropriate responses. Using
chain-of-thought to make models spell out intentions yields much smaller gains
(60% for Mistral-Instruct). These findings suggest that LLMs are not yet
effective pragmatic interlocutors, highlighting the need for better approaches
for modeling intentions and utilizing them for pragmatic generation.

ÊëòË¶ÅÔºö‰∫∫È°ûÁ∂ìÂ∏∏ÈñìÊé•ÊàñÈùûÂ≠óÈù¢Âú∞Ë°®ÈÅî‰ªñÂÄëÁöÑÊ∫ùÈÄöÊÑèÂúñÔºåÈÄôÈúÄË¶Å‰ªñÂÄëÁöÑÂ∞çË©±ËÄÖÔºà‰∫∫È°ûÊàñ AIÔºâÁêÜËß£Ë∂ÖË∂äÂ≠óÈù¢ÊÑèÊÄù„ÄÇÈõñÁÑ∂Â§ßÂ§öÊï∏ÁèæÊúâÂ∑•‰ΩúÈÉΩÂ∞àÊ≥®ÊñºÂçÄËæ®ÊÄßË©ï‰º∞Ôºå‰ΩÜÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁîüÊàêÂºèË©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊÑèÂúñÁêÜËß£ÁöÑÊñ∞ÊñπÊ≥ïÔºåÊñπÊ≥ïÊòØÊ™¢Êü•ÂÆÉÂÄëÂ∞çÈùûÂ≠óÈù¢Ë™ûÂè•ÁöÑÂõûÊáâ„ÄÇÁêÜÊÉ≥ÊÉÖÊ≥Å‰∏ãÔºåLLM ÊáâÊ†πÊìöÈùûÂ≠óÈù¢Ë™ûÂè•ÁöÑÁúüÊ≠£ÊÑèÂúñÂÅöÂá∫ÂõûÊáâÔºåËÄå‰∏çÊòØÂÖ∂Â≠óÈù¢Ëß£Èáã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåLLM Èõ£‰ª•Â∞çÈùûÂ≠óÈù¢Ë™ûË®ÄÁî¢ÁîüË™ûÁî®Áõ∏ÈóúÁöÑÂõûÊáâÔºåÂπ≥ÂùáÊ∫ñÁ¢∫ÁéáÂÉÖÁÇ∫ 50-55%„ÄÇÈõñÁÑ∂ÊòéÁ¢∫Êèê‰æõÁ•ûË´≠ÊÑèÂúñÈ°ØËëóÊèêÈ´ò‰∫ÜÊïàËÉΩÔºà‰æãÂ¶ÇÔºåMistral-Instruct ÁÇ∫ 75%ÔºâÔºå‰ΩÜÈÄô‰ªçÁÑ∂Ë°®ÊòéÂú®Âà©Áî®Áµ¶ÂÆöÁöÑÊÑèÂúñÁî¢ÁîüÈÅ©Áï∂ÂõûÊáâÊñπÈù¢Â≠òÂú®ÊåëÊà∞„ÄÇ‰ΩøÁî®ÊÄùÁ∂≠ÈèàËÆìÊ®°ÂûãÊãºÂØ´Âá∫ÊÑèÂúñÁî¢ÁîüÁöÑÂ¢ûÁõäË¶ÅÂ∞èÂæóÂ§öÔºàMistral-Instruct ÁÇ∫ 60%Ôºâ„ÄÇÈÄô‰∫õÁôºÁèæË°®ÊòéÔºåLLM Â∞öÊú™ÊàêÁÇ∫ÊúâÊïàÁöÑË™ûÁî®Â∞çË©±ËÄÖÔºåÁ™ÅÈ°Ø‰∫ÜÂ∞çÂª∫Ê®°ÊÑèÂúñÂíåÂ∞áÂÖ∂Áî®ÊñºË™ûÁî®ÁîüÊàêÁöÑÊõ¥Â•ΩÊñπÊ≥ïÁöÑÈúÄÊ±Ç„ÄÇ

##### **Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach**
2405.08755v1 by Syed Mhamudul Hasan, Alaa M. Alotaibi, Sajedul Talukder, Abdur R. Shahid

With the proliferation of edge devices, there is a significant increase in
attack surface on these devices. The decentralized deployment of threat
intelligence on edge devices, coupled with adaptive machine learning techniques
such as the in-context learning feature of large language models (LLMs),
represents a promising paradigm for enhancing cybersecurity on low-powered edge
devices. This approach involves the deployment of lightweight machine learning
models directly onto edge devices to analyze local data streams, such as
network traffic and system logs, in real-time. Additionally, distributing
computational tasks to an edge server reduces latency and improves
responsiveness while also enhancing privacy by processing sensitive data
locally. LLM servers can enable these edge servers to autonomously adapt to
evolving threats and attack patterns, continuously updating their models to
improve detection accuracy and reduce false positives. Furthermore,
collaborative learning mechanisms facilitate peer-to-peer secure and
trustworthy knowledge sharing among edge devices, enhancing the collective
intelligence of the network and enabling dynamic threat mitigation measures
such as device quarantine in response to detected anomalies. The scalability
and flexibility of this approach make it well-suited for diverse and evolving
network environments, as edge devices only send suspicious information such as
network traffic and system log changes, offering a resilient and efficient
solution to combat emerging cyber threats at the network edge. Thus, our
proposed framework can improve edge computing security by providing better
security in cyber threat detection and mitigation by isolating the edge devices
from the network.

ÊëòË¶ÅÔºöÈö®ËëóÈÇäÁ∑£Ë£ùÁΩÆÁöÑÊøÄÂ¢ûÔºåÈÄô‰∫õË£ùÁΩÆÁöÑÊîªÊìäÈù¢È°ØËëóÂ¢ûÂä†„ÄÇÂú®ÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÂàÜÊï£ÈÉ®ÁΩ≤Â®ÅËÑÖÊÉÖÂ†±ÔºåÂÜçÂä†‰∏äËá™ÈÅ©ÊáâÊ©üÂô®Â≠∏ÁøíÊäÄË°ìÔºå‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊÉÖÂ¢ÉÂ≠∏ÁøíÂäüËÉΩÔºåÈÄô‰ª£Ë°®‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÁØÑ‰æãÔºåÁî®ÊñºÂ¢ûÂº∑‰ΩéÂäüËÄóÈÇäÁ∑£Ë£ùÁΩÆÁöÑÁ∂≤Ë∑ØÂÆâÂÖ®„ÄÇÊ≠§ÊñπÊ≥ïÊ∂âÂèäÂ∞áËºïÈáèÁ¥öÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁõ¥Êé•ÈÉ®ÁΩ≤Âà∞ÈÇäÁ∑£Ë£ùÁΩÆ‰∏äÔºå‰ª•ÂàÜÊûêÊú¨Âú∞Ë≥áÊñô‰∏≤ÊµÅÔºå‰æãÂ¶ÇÁ∂≤Ë∑ØÊµÅÈáèÂíåÁ≥ªÁµ±Ë®òÈåÑÔºå‰∏¶ÈÄ≤Ë°åÂç≥ÊôÇÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÂ∞áÈÅãÁÆó‰ªªÂãôÂàÜÈÖçÂà∞ÈÇäÁ∑£‰º∫ÊúçÂô®ÂèØ‰ª•Ê∏õÂ∞ëÂª∂ÈÅ≤‰∏¶ÊîπÂñÑÂõûÊáâËÉΩÂäõÔºåÂêåÊôÇÈÄèÈÅéÂú®Êú¨Âú∞ËôïÁêÜÊïèÊÑüË≥áÊñô‰æÜÂ¢ûÂº∑Èö±ÁßÅÊ¨ä„ÄÇLLM ‰º∫ÊúçÂô®ÂèØ‰ª•ËÆìÈÄô‰∫õÈÇäÁ∑£‰º∫ÊúçÂô®Ëá™‰∏ªÈÅ©Êáâ‰∏çÊñ∑ËÆäÂåñÁöÑÂ®ÅËÑÖÂíåÊîªÊìäÊ®°ÂºèÔºåÊåÅÁ∫åÊõ¥Êñ∞ÂÖ∂Ê®°Âûã‰ª•ÊèêÈ´òÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶‰∏¶Ê∏õÂ∞ëË™§Â†±„ÄÇÊ≠§Â§ñÔºåÂçî‰ΩúÂ≠∏ÁøíÊ©üÂà∂‰øÉÈÄ≤‰∫ÜÈÇäÁ∑£Ë£ùÁΩÆ‰πãÈñìÁöÑÈªûÂ∞çÈªûÂÆâÂÖ®‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑÁü•Ë≠òÂÖ±‰∫´ÔºåÂ¢ûÂº∑‰∫ÜÁ∂≤Ë∑ØÁöÑÈõÜÈ´îÊô∫ÊÖßÔºå‰∏¶ÂïüÁî®‰∫ÜÂãïÊÖãÂ®ÅËÑÖÁ∑©Ëß£Êé™ÊñΩÔºå‰æãÂ¶ÇÈáùÂ∞çÂÅµÊ∏¨Âà∞ÁöÑÁï∞Â∏∏ÊÉÖÊ≥ÅÈÄ≤Ë°åË£ùÁΩÆÈöîÈõ¢„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÁöÑÂèØÊì¥ÂÖÖÊÄßÂíåÈùàÊ¥ªÊÄß‰ΩøÂÖ∂ÈùûÂ∏∏ÈÅ©ÂêàÂ§öÊ®£Âåñ‰∏î‰∏çÊñ∑ËÆäÂåñÁöÑÁ∂≤Ë∑ØÁí∞Â¢ÉÔºåÂõ†ÁÇ∫ÈÇäÁ∑£Ë£ùÁΩÆÂè™ÊúÉÂÇ≥ÈÄÅÂèØÁñëË≥áË®äÔºå‰æãÂ¶ÇÁ∂≤Ë∑ØÊµÅÈáèÂíåÁ≥ªÁµ±Ë®òÈåÑËÆäÊõ¥ÔºåÊèê‰æõÊúâÈüåÊÄßÂíåÊúâÊïàÁéáÁöÑËß£Ê±∫ÊñπÊ°à‰æÜÂ∞çÊäóÁ∂≤Ë∑ØÈÇäÁ∑£ÁöÑÊñ∞ËààÁ∂≤Ë∑ØÂ®ÅËÑÖ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊû∂ÊßãÂèØ‰ª•ÈÄèÈÅéÂú®Á∂≤Ë∑ØÂ®ÅËÑÖÂÅµÊ∏¨ÂíåÁ∑©Ëß£‰∏≠Êèê‰æõÊõ¥Â•ΩÁöÑÂÆâÂÖ®ÊÄßÔºå‰ª•ÂèäÂ∞áÈÇäÁ∑£Ë£ùÁΩÆËàáÁ∂≤Ë∑ØÈöîÈõ¢Ôºå‰æÜÊîπÂñÑÈÇäÁ∑£ÈÅãÁÆóÂÆâÂÖ®ÊÄß„ÄÇ

##### **From Text to Context: An Entailment Approach for News Stakeholder Classification**
2405.08751v1 by Alapan Kuila, Sudeshna Sarkar

Navigating the complex landscape of news articles involves understanding the
various actors or entities involved, referred to as news stakeholders. These
stakeholders, ranging from policymakers to opposition figures, citizens, and
more, play pivotal roles in shaping news narratives. Recognizing their
stakeholder types, reflecting their roles, political alignments, social
standing, and more, is paramount for a nuanced comprehension of news content.
Despite existing works focusing on salient entity extraction, coverage
variations, and political affiliations through social media data, the automated
detection of stakeholder roles within news content remains an underexplored
domain. In this paper, we bridge this gap by introducing an effective approach
to classify stakeholder types in news articles. Our method involves
transforming the stakeholder classification problem into a natural language
inference task, utilizing contextual information from news articles and
external knowledge to enhance the accuracy of stakeholder type detection.
Moreover, our proposed model showcases efficacy in zero-shot settings, further
extending its applicability to diverse news contexts.

ÊëòË¶ÅÔºöÂú®Ë§áÈõúÁöÑÊñ∞ËÅûÊñáÁ´†È†òÂüü‰∏≠Â∞éËà™ÂåÖÊã¨‰∫ÜËß£Ê∂âÂèäÁöÑÂêÑÁ®ÆË°åÂãïËÄÖÊàñÂØ¶È´îÔºåÁ®±ÁÇ∫Êñ∞ËÅûÂà©ÁõäÁõ∏ÈóúËÄÖ„ÄÇÈÄô‰∫õÂà©ÁõäÁõ∏ÈóúËÄÖÔºåÂæûÊîøÁ≠ñÂà∂ÂÆöËÄÖÂà∞ÂèçÂ∞çÊ¥æ‰∫∫Áâ©„ÄÅÂÖ¨Ê∞ëÁ≠âÁ≠âÔºåÂú®Â°ëÈÄ†Êñ∞ËÅûÊïòËø∞‰∏≠ÊâÆÊºîËëóËàâË∂≥ËºïÈáçÁöÑËßíËâ≤„ÄÇË™çË≠ò‰ªñÂÄëÁöÑÂà©ÁõäÁõ∏ÈóúËÄÖÈ°ûÂûãÔºåÂèçÊò†‰ªñÂÄëÁöÑËßíËâ≤„ÄÅÊîøÊ≤ªÁ´ãÂ†¥„ÄÅÁ§æÊúÉÂú∞‰ΩçÁ≠âÔºåÂ∞çÊñºÁ¥∞Á∑ªÁêÜËß£Êñ∞ËÅûÂÖßÂÆπËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°ÁèæÊúâ‰ΩúÂìÅËëóÈáçÊñºÈ°ØËëóÂØ¶È´îËêÉÂèñ„ÄÅÂ†±Â∞éÂ∑ÆÁï∞ÂíåÈÄèÈÅéÁ§æÁæ§Â™íÈ´îË≥áÊñôÈÄ≤Ë°åÊîøÊ≤ªËÅØÁπ´ÔºåÊñ∞ËÅûÂÖßÂÆπ‰∏≠Âà©ÁõäÁõ∏ÈóúËÄÖËßíËâ≤ÁöÑËá™ÂãïÂåñÂÅµÊ∏¨‰ªçÊòØÊú™ÂÖÖÂàÜÊé¢Ë®éÁöÑÈ†òÂüü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂºïÂÖ•‰∏ÄÁ®ÆÊúâÊïàÊñπÊ≥ï‰æÜÂàÜÈ°ûÊñ∞ËÅûÊñáÁ´†‰∏≠ÁöÑÂà©ÁõäÁõ∏ÈóúËÄÖÈ°ûÂûãÔºå‰ª•ÂΩåÂêàÈÄôÂÄãÂ∑ÆË∑ù„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂåÖÊã¨Â∞áÂà©ÁõäÁõ∏ÈóúËÄÖÂàÜÈ°ûÂïèÈ°åËΩâÊèõÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ‰ªªÂãôÔºåÂà©Áî®Êñ∞ËÅûÊñáÁ´†‰∏≠ÁöÑËÑàÁµ°Ë≥áË®äÂíåÂ§ñÈÉ®Áü•Ë≠ò‰æÜÂ¢ûÂº∑Âà©ÁõäÁõ∏ÈóúËÄÖÈ°ûÂûãÂÅµÊ∏¨ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠Â±ïÁ§∫‰∫ÜÂäüÊïàÊÄßÔºåÈÄ≤‰∏ÄÊ≠•Êì¥Â±ï‰∫ÜÂÖ∂Â∞ç‰∏çÂêåÊñ∞ËÅûËÑàÁµ°ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis**
2405.08681v1 by Qingpeng Kong, Ching-Hao Chiu, Dewen Zeng, Yu-Jen Chen, Tsung-Yi Ho, Jingtong hu, Yiyu Shi

Numerous studies have revealed that deep learning-based medical image
classification models may exhibit bias towards specific demographic attributes,
such as race, gender, and age. Existing bias mitigation methods often achieve
high level of fairness at the cost of significant accuracy degradation. In
response to this challenge, we propose an innovative and adaptable Soft Nearest
Neighbor Loss-based channel pruning framework, which achieves fairness through
channel pruning. Traditionally, channel pruning is utilized to accelerate
neural network inference. However, our work demonstrates that pruning can also
be a potent tool for achieving fairness. Our key insight is that different
channels in a layer contribute differently to the accuracy of different groups.
By selectively pruning critical channels that lead to the accuracy difference
between the privileged and unprivileged groups, we can effectively improve
fairness without sacrificing accuracy significantly. Experiments conducted on
two skin lesion diagnosis datasets across multiple sensitive attributes
validate the effectiveness of our method in achieving state-of-the-art
trade-off between accuracy and fairness. Our code is available at
https://github.com/Kqp1227/Sensitive-Channel-Pruning.

ÊëòË¶ÅÔºöË®±Â§öÁ†îÁ©∂È°ØÁ§∫ÔºåÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÈ°ûÊ®°ÂûãÂèØËÉΩÊúÉÂ∞çÁâπÂÆö‰∫∫Âè£Â±¨ÊÄßÔºà‰æãÂ¶ÇÁ®ÆÊóè„ÄÅÊÄßÂà•ÂíåÂπ¥ÈΩ°ÔºâË°®ÁèæÂá∫ÂÅèË¶ã„ÄÇÁèæÊúâÁöÑÂÅèË¶ãÁ∑©Ëß£ÊñπÊ≥ïÈÄöÂ∏∏‰ª•Â§ßÂπÖÈôç‰ΩéÊ∫ñÁ¢∫Â∫¶ÁÇ∫‰ª£ÂÉπÔºå‰æÜÈÅîÊàêÈ´òÂ∫¶ÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§ÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑ„ÄÅÂèØÈÅ©ÊáâÁöÑÂü∫Êñº Soft Nearest Neighbor Loss ÁöÑÈÄöÈÅìÂâ™ÊûùÊ°ÜÊû∂ÔºåÈÄèÈÅéÈÄöÈÅìÂâ™Êûù‰æÜÂØ¶ÁèæÂÖ¨Âπ≥ÊÄß„ÄÇÂÇ≥Áµ±‰∏äÔºåÈÄöÈÅìÂâ™ÊûùÁî®ÊñºÂä†ÈÄüÁ•ûÁ∂ìÁ∂≤Ë∑ØÊé®Ë´ñ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòéÔºåÂâ™Êûù‰πüÂèØ‰ª•ÊàêÁÇ∫ÂØ¶ÁèæÂÖ¨Âπ≥ÊÄßÁöÑÊúâÂäõÂ∑•ÂÖ∑„ÄÇÊàëÂÄëÁöÑÈóúÈçµË¶ãËß£ÊòØÔºå‰∏ÄÂ±§‰∏≠ÁöÑ‰∏çÂêåÈÄöÈÅìÂ∞ç‰∏çÂêåÁæ§ÁµÑÁöÑÊ∫ñÁ¢∫Â∫¶Êúâ‰∏çÂêåÁöÑË≤¢Áçª„ÄÇÈÄèÈÅéÈÅ∏ÊìáÊÄßÂú∞Ââ™ÊûùÂ∞éËá¥ÁâπÊ¨äÁæ§ÁµÑÂíåÈùûÁâπÊ¨äÁæ§ÁµÑ‰πãÈñìÊ∫ñÁ¢∫Â∫¶Â∑ÆÁï∞ÁöÑÈáçË¶ÅÈÄöÈÅìÔºåÊàëÂÄëÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÈ´òÂÖ¨Âπ≥ÊÄßÔºåËÄå‰∏çÊúÉÈ°ØËëóÁäßÁâ≤Ê∫ñÁ¢∫Â∫¶„ÄÇÂú®ÂÖ©ÂÄãÁöÆËÜöÁóÖËÆäË®∫Êñ∑Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÔºåÊ∂µËìãÂ§öÂÄãÊïèÊÑüÂ±¨ÊÄßÔºåÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®Ê∫ñÁ¢∫Â∫¶ÂíåÂÖ¨Âπ≥ÊÄß‰πãÈñìÂèñÂæóÊúÄÂÖàÈÄ≤ÁöÑÊ¨äË°°ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Kqp1227/Sensitive-Channel-Pruning ÂèñÂæó„ÄÇ

##### **Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning**
2405.08679v1 by Alain Riou, Stefan Lattner, Ga√´tan Hadjeres, Geoffroy Peeters

This paper addresses the problem of self-supervised general-purpose audio
representation learning. We explore the use of Joint-Embedding Predictive
Architectures (JEPA) for this task, which consists of splitting an input
mel-spectrogram into two parts (context and target), computing neural
representations for each, and training the neural network to predict the target
representations from the context representations. We investigate several design
choices within this framework and study their influence through extensive
experiments by evaluating our models on various audio classification
benchmarks, including environmental sounds, speech and music downstream tasks.
We focus notably on which part of the input data is used as context or target
and show experimentally that it significantly impacts the model's quality. In
particular, we notice that some effective design choices in the image domain
lead to poor performance on audio, thus highlighting major differences between
these two modalities.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫ÜËá™Áõ£Áù£ÈÄöÁî®Èü≥Ë®äË°®Á§∫Â≠∏ÁøíÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜËÅØÂêàÂµåÂÖ•È†êÊ∏¨Êû∂Êßã (JEPA) Âú®Ê≠§‰ªªÂãô‰∏≠ÁöÑÊáâÁî®ÔºåË©≤Êû∂ÊßãÂåÖÂê´Â∞áËº∏ÂÖ•ÁöÑ mel È†ªË≠úÂúñÂàÜÂâ≤ÊàêÂÖ©ÈÉ®ÂàÜÔºàËÑàÁµ°ÂíåÁõÆÊ®ôÔºâ„ÄÅÈáùÂ∞çÊØè‰∏ÄÈÉ®ÂàÜË®àÁÆóÁ•ûÁ∂ìË°®Á§∫Ôºå‰ª•ÂèäË®ìÁ∑¥Á•ûÁ∂ìÁ∂≤Ë∑ØÂæûËÑàÁµ°Ë°®Á§∫È†êÊ∏¨ÁõÆÊ®ôË°®Á§∫„ÄÇÊàëÂÄëÂú®Ê≠§Êû∂ÊßãÂÖßÊé¢Ë®é‰∫ÜÊï∏Á®ÆË®≠Ë®àÈÅ∏ÊìáÔºå‰∏¶ÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÁ†îÁ©∂ÂÖ∂ÂΩ±ÈüøÔºåÊñπÊ≥ïÊòØÈáùÂ∞çÂêÑÁ®ÆÈü≥Ë®äÂàÜÈ°ûÂü∫Ê∫ñË©ï‰º∞ÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂåÖÊã¨Áí∞Â¢ÉÈü≥„ÄÅË™ûÈü≥ÂíåÈü≥Ê®Ç‰∏ãÊ∏∏‰ªªÂãô„ÄÇÊàëÂÄëÁâπÂà•Â∞àÊ≥®ÊñºËº∏ÂÖ•Ë≥áÊñôÁöÑÂì™‰∏ÄÈÉ®ÂàÜÁî®‰ΩúËÑàÁµ°ÊàñÁõÆÊ®ôÔºå‰∏¶ÈÄèÈÅéÂØ¶È©óÈ°ØÁ§∫ÂÆÉÊúÉÈ°ØËëóÂΩ±ÈüøÊ®°ÂûãÂìÅË≥™„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÊ≥®ÊÑèÂà∞ÂΩ±ÂÉèÈ†òÂüü‰∏≠‰∏Ä‰∫õÊúâÊïàÁöÑË®≠Ë®àÈÅ∏ÊìáÊúÉÂ∞éËá¥Èü≥Ë®äË°®Áèæ‰∏ç‰Ω≥ÔºåÂõ†Ê≠§Á™ÅÈ°Ø‰∫ÜÈÄôÂÖ©Á®ÆÊ®°Âºè‰πãÈñìÁöÑ‰∏ªË¶ÅÂ∑ÆÁï∞„ÄÇ

##### **Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models**
2405.08674v1 by Bingdong Li, Zixiang Di, Yongfan Lu, Hong Qian, Feng Wang, Peng Yang, Ke Tang, Aimin Zhou

Multi-objective Bayesian optimization (MOBO) has shown promising performance
on various expensive multi-objective optimization problems (EMOPs). However,
effectively modeling complex distributions of the Pareto optimal solutions is
difficult with limited function evaluations. Existing Pareto set learning
algorithms may exhibit considerable instability in such expensive scenarios,
leading to significant deviations between the obtained solution set and the
Pareto set (PS). In this paper, we propose a novel Composite Diffusion Model
based Pareto Set Learning algorithm, namely CDM-PSL, for expensive MOBO.
CDM-PSL includes both unconditional and conditional diffusion model for
generating high-quality samples. Besides, we introduce an information entropy
based weighting method to balance different objectives of EMOPs. This method is
integrated with the guiding strategy, ensuring that all the objectives are
appropriately balanced and given due consideration during the optimization
process; Extensive experimental results on both synthetic benchmarks and
real-world problems demonstrates that our proposed algorithm attains superior
performance compared with various state-of-the-art MOBO algorithms.

ÊëòË¶ÅÔºöÂ§öÁõÆÊ®ôË≤ùÊ∞èÂÑ™Âåñ (MOBO) Âú®ÂêÑÁ®ÆÊòÇË≤¥ÁöÑÂ§öÁõÆÊ®ôÂÑ™ÂåñÂïèÈ°å (EMOP) ‰∏äÂ±ïÁèæÂá∫‰ª§‰∫∫ÊªøÊÑèÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂú®ÂáΩÊï∏Ë©ï‰º∞ÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊúâÊïàÂú∞Âª∫Ê®°Â∏ïÈõ∑ÊâòÊúÄÂÑ™Ëß£ÁöÑË§áÈõúÂàÜ‰ΩàÊòØÂæàÂõ∞Èõ£ÁöÑ„ÄÇÁèæÊúâÁöÑÂ∏ïÈõ∑ÊâòÈõÜÂêàÂ≠∏ÁøíÊºîÁÆóÊ≥ïÂú®ÈÄôÁ®ÆÊòÇË≤¥ÁöÑÂ†¥ÊôØ‰∏≠ÂèØËÉΩÊúÉË°®ÁèæÂá∫Áõ∏Áï∂Á®ãÂ∫¶ÁöÑ‰∏çÁ©©ÂÆöÊÄßÔºåÂ∞éËá¥ÊâÄÁç≤ÂæóÁöÑËß£ÈõÜËàáÂ∏ïÈõ∑ÊâòÈõÜÂêà (PS) ‰πãÈñìÂá∫ÁèæÈ°ØËëóÁöÑÂÅèÂ∑Æ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÂ∏ïÈõ∑ÊâòÈõÜÂêàÂ≠∏ÁøíÊºîÁÆóÊ≥ïÁöÑÊñ∞ÂûãË§áÂêàÊì¥Êï£Ê®°ÂûãÔºåÂç≥ CDM-PSLÔºåÁî®ÊñºÊòÇË≤¥ÁöÑ MOBO„ÄÇCDM-PSL ÂåÖÂê´ÁÑ°Ê¢ù‰ª∂ÂíåÊ¢ù‰ª∂Êì¥Êï£Ê®°ÂûãÔºåÁî®ÊñºÁîüÊàêÈ´òÂìÅË≥™ÁöÑÊ®£Êú¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫ÊñºË≥áË®äÁÜµÁöÑÂä†Ê¨äÊñπÊ≥ïÔºå‰ª•Âπ≥Ë°° EMOP ÁöÑ‰∏çÂêåÁõÆÊ®ô„ÄÇÊ≠§ÊñπÊ≥ïËàáÂºïÂ∞éÁ≠ñÁï•Êï¥ÂêàÔºåÁ¢∫‰øùÊâÄÊúâÁõÆÊ®ôÂú®ÊúÄ‰Ω≥ÂåñÈÅéÁ®ã‰∏≠ÂæóÂà∞ÈÅ©Áï∂ÁöÑÂπ≥Ë°°ÂíåÈÅ©Áï∂ÁöÑËÄÉÈáèÔºõÂú®ÂêàÊàêÂü∫Ê∫ñÂíåÁúüÂØ¶‰∏ñÁïåÂïèÈ°å‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊºîÁÆóÊ≥ïËàáÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑ MOBO ÊºîÁÆóÊ≥ïÁõ∏ÊØîÔºåÂèñÂæó‰∫ÜÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇ

##### **Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research**
2405.08668v1 by Qinglong Cao, Yuntian Chen, Lu Lu, Hao Sun, Zhenzhong Zeng, Xiaokang Yang, Dongxiao Zhang

Large-scale Vision-Language Models (VLMs) have demonstrated exceptional
performance in natural vision tasks, motivating researchers across domains to
explore domain-specific VLMs. However, the construction of powerful
domain-specific VLMs demands vast amounts of annotated data, substantial
electrical energy, and computing resources, primarily accessible to industry,
yet hindering VLM research in academia. To address this challenge and foster
sustainable and equitable VLM research, we present the Generalized Domain
Prompt Learning (GDPL) framework. GDPL facilitates the transfer of VLMs' robust
recognition capabilities from natural vision to specialized domains, without
the need for extensive data or resources. By leveraging small-scale
domain-specific foundation models and minimal prompt samples, GDPL empowers the
language branch with domain knowledge through quaternion networks, uncovering
cross-modal relationships between domain-specific vision features and natural
vision-based contextual embeddings. Simultaneously, GDPL guides the vision
branch into specific domains through hierarchical propagation of generated
vision prompt features, grounded in well-matched vision-language relations.
Furthermore, to fully harness the domain adaptation potential of VLMs, we
introduce a novel low-rank adaptation approach. Extensive experiments across
diverse domains like remote sensing, medical imaging, geology, Synthetic
Aperture Radar, and fluid dynamics, validate the efficacy of GDPL,
demonstrating its ability to achieve state-of-the-art domain recognition
performance in a prompt learning paradigm. Our framework paves the way for
sustainable and inclusive VLM research, transcending the barriers between
academia and industry.

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤Âú®Ëá™ÁÑ∂Ë¶ñË¶∫‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑÊïàËÉΩÔºåÊøÄÂãµÂêÑÈ†òÂüüÁöÑÁ†îÁ©∂‰∫∫Âì°Êé¢Á¥¢ÁâπÂÆöÈ†òÂüüÁöÑ VLM„ÄÇÁÑ∂ËÄåÔºåÂª∫ÊßãÂº∑Â§ßÁöÑÁâπÂÆöÈ†òÂüü VLM ÈúÄË¶ÅÂ§ßÈáèÊ®ôË®ªË≥áÊñô„ÄÅÂ§ßÈáèÁöÑÈõªÂäõÂíåÈÅãÁÆóË≥áÊ∫êÔºåÈÄô‰∫õË≥áÊ∫ê‰∏ªË¶ÅÁî±Áî¢Ê•≠ÂèñÂæóÔºåÂçªÈòªÁ§ô‰∫ÜÂ≠∏Ë°ìÁïåÂ∞ç VLM ÁöÑÁ†îÁ©∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÊåëÊà∞‰∏¶‰øÉÈÄ≤Ê∞∏Á∫å‰∏îÂÖ¨Âπ≥ÁöÑ VLM Á†îÁ©∂ÔºåÊàëÂÄëÊèêÂá∫Âª£Áæ©È†òÂüüÊèêÁ§∫Â≠∏Áøí (GDPL) Êû∂Êßã„ÄÇGDPL ‰øÉÈÄ≤ VLM Âº∑ÂÅ•ÁöÑË≠òÂà•ËÉΩÂäõÂæûËá™ÁÑ∂Ë¶ñË¶∫ËΩâÁßªÂà∞ÁâπÂÆöÈ†òÂüüÔºåËÄå‰∏çÈúÄË¶ÅÈæêÂ§ßÁöÑË≥áÊñôÊàñË≥áÊ∫ê„ÄÇÈÄèÈÅéÈÅãÁî®Â∞èË¶èÊ®°ÁâπÂÆöÈ†òÂüüÂü∫Á§éÊ®°ÂûãÂíåÊúÄÂ∞ëÁöÑÊèêÁ§∫ÁØÑ‰æãÔºåGDPL ÈÄèÈÅéÂõõÂÖÉÊï∏Á∂≤Ë∑ØË≥¶‰∫àË™ûË®ÄÂàÜÊîØÈ†òÂüüÁü•Ë≠òÔºåÊè≠Èú≤ÁâπÂÆöÈ†òÂüüË¶ñË¶∫ÁâπÂæµËàáÂü∫ÊñºËá™ÁÑ∂Ë¶ñË¶∫ÁöÑËÑàÁµ°ÂµåÂÖ•‰πãÈñìÁöÑË∑®Ê®°ÊÖãÈóú‰øÇ„ÄÇÂêåÊôÇÔºåGDPL ÈÄèÈÅéÁî¢ÁîüË¶ñË¶∫ÊèêÁ§∫ÁâπÂæµÁöÑÂàÜÂ±§ÂÇ≥Êí≠ÔºåÂ∞áË¶ñË¶∫ÂàÜÊîØÂºïÂ∞éËá≥ÁâπÂÆöÈ†òÂüüÔºåÈÄô‰∫õÁâπÂæµÂ•†Âü∫ÊñºÂåπÈÖçËâØÂ•ΩÁöÑË¶ñË¶∫Ë™ûË®ÄÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÂÖÖÂàÜÂà©Áî® VLM ÁöÑÈ†òÂüüÈÅ©ÊáâÊΩõÂäõÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰ΩéÈöéÈÅ©ÊáâÊñπÊ≥ï„ÄÇÂú®ÈÅôÊ∏¨„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉè„ÄÅÂú∞Ë≥™Â≠∏„ÄÅÂêàÊàêÂ≠îÂæëÈõ∑ÈÅîÂíåÊµÅÈ´îÂäõÂ≠∏Á≠â‰∏çÂêåÈ†òÂüüÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫Ü GDPL ÁöÑÂäüÊïàÔºåË≠âÊòé‰∫ÜÂÆÉÂú®ÊèêÁ§∫Â≠∏ÁøíÁØÑ‰æã‰∏≠ÂØ¶ÁèæÊúÄÂÖàÈÄ≤È†òÂüüË≠òÂà•ÊïàËÉΩÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÁÇ∫Ê∞∏Á∫å‰∏îÂåÖÂÆπÁöÑ VLM Á†îÁ©∂Èã™Ë∑ØÔºåË∂ÖË∂ä‰∫ÜÂ≠∏Ë°ìÁïåÂíåÁî¢Ê•≠‰πãÈñìÁöÑÈöúÁ§ô„ÄÇ</paragraph>

##### **Beyond the Black Box: Do More Complex Models Provide Superior XAI Explanations?**
2405.08658v1 by Mateusz Cedro, Marcin Chlebus

The increasing complexity of Artificial Intelligence models poses challenges
to interpretability, particularly in the healthcare sector. This study
investigates the impact of deep learning model complexity and Explainable AI
(XAI) efficacy, utilizing four ResNet architectures (ResNet-18, 34, 50, 101).
Through methodical experimentation on 4,369 lung X-ray images of
COVID-19-infected and healthy patients, the research evaluates models'
classification performance and the relevance of corresponding XAI explanations
with respect to the ground-truth disease masks. Results indicate that the
increase in model complexity is associated with a decrease in classification
accuracy and AUC-ROC scores (ResNet-18: 98.4%, 0.997; ResNet-101: 95.9%,
0.988). Notably, in eleven out of twelve statistical tests performed, no
statistically significant differences occurred between XAI quantitative metrics
- Relevance Rank Accuracy and the proposed Positive Attribution Ratio - across
trained models. These results suggest that increased model complexity does not
consistently lead to higher performance or relevance of explanations for
models' decision-making processes.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÊó•ÁõäË§áÈõúÔºåÂ∞çÂèØËß£ÈáãÊÄßÊßãÊàêÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®éÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãË§áÈõúÂ∫¶ÂíåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÂà©Áî®ÂõõÁ®Æ ResNet Êû∂Êßã (ResNet-18„ÄÅ34„ÄÅ50„ÄÅ101)„ÄÇÈÄèÈÅéÂ∞ç 4,369 Âºµ COVID-19 ÊÑüÊüìÂíåÂÅ•Â∫∑ÊÇ£ËÄÖÁöÑËÇ∫ÈÉ® X ÂÖâÂΩ±ÂÉèÈÄ≤Ë°åÊúâÊ¢ùÁêÜÁöÑÂØ¶È©óÔºåÊú¨Á†îÁ©∂Ë©ï‰º∞Ê®°ÂûãÁöÑÂàÜÈ°ûÊïàËÉΩÂíåÂ∞çÊáâ XAI Ëß£ÈáãËàáÂØ¶ÈöõÁñæÁóÖÈÅÆÁΩ©ÁöÑÁõ∏ÈóúÊÄß„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊ®°ÂûãË§áÈõúÂ∫¶ÁöÑÂ¢ûÂä†ËàáÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶Âíå AUC-ROC ÂàÜÊï∏ÁöÑ‰∏ãÈôçÊúâÈóú (ResNet-18Ôºö98.4%Ôºå0.997ÔºõResNet-101Ôºö95.9%Ôºå0.988)„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®ÊâÄÂü∑Ë°åÁöÑÂçÅ‰∫åÈ†ÖÁµ±Ë®àÊ™¢ÂÆö‰∏≠ÔºåÊúâÂçÅ‰∏ÄÊ¨°‰πãÈñìÊ≤íÊúâÁôºÁîüÁµ±Ë®à‰∏äÈ°ØËëóÂ∑ÆÁï∞ XAI ÂÆöÈáèÊåáÊ®ô - Áõ∏ÈóúÊÄßÊéíÂêçÊ∫ñÁ¢∫Â∫¶ÂíåÂª∫Ë≠∞ÁöÑÊ≠£Ê≠∏Âõ†ÊØîÁéá - Âú®Ë®ìÁ∑¥Ê®°Âûã‰πãÈñì„ÄÇÈÄô‰∫õÁµêÊûúË°®ÊòéÔºåÊ®°ÂûãË§áÈõúÂ∫¶ÁöÑÂ¢ûÂä†‰∏¶‰∏çÊúÉÊåÅÁ∫åÂ∞éËá¥Ëß£ÈáãÊïàËÉΩÊàñÊ®°ÂûãÊ±∫Á≠ñÈÅéÁ®ãÁõ∏ÈóúÊÄßÁöÑÊèêÂçá„ÄÇ

##### **Thinking Tokens for Language Modeling**
2405.08644v1 by David Herel, Tomas Mikolov

How much is 56 times 37? Language models often make mistakes in these types
of difficult calculations. This is usually explained by their inability to
perform complex reasoning. Since language models rely on large training sets
and great memorization capability, naturally they are not equipped to run
complex calculations. However, one can argue that humans also cannot perform
this calculation immediately and require a considerable amount of time to
construct the solution. In order to enhance the generalization capability of
language models, and as a parallel to human behavior, we propose to use special
'thinking tokens' which allow the model to perform much more calculations
whenever a complex problem is encountered.

ÊëòË¶ÅÔºö56 ‰πò‰ª• 37 Á≠âÊñºÂ§öÂ∞ëÔºüË™ûË®ÄÊ®°ÂûãÂú®ÈÄô‰∫õÈ°ûÂûãÁöÑÂõ∞Èõ£Ë®àÁÆó‰∏≠Á∂ìÂ∏∏ÊúÉÂá∫ÈåØ„ÄÇÈÄôÈÄöÂ∏∏ÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÁÑ°Ê≥ïÈÄ≤Ë°åË§áÈõúÁöÑÊé®ÁêÜ„ÄÇÁî±ÊñºË™ûË®ÄÊ®°Âûã‰æùË≥¥ÊñºÂ§ßÂûãË®ìÁ∑¥ÈõÜÂíåÂº∑Â§ßÁöÑË®òÊÜ∂ËÉΩÂäõÔºåÂõ†Ê≠§ÂÆÉÂÄëËá™ÁÑ∂ÁÑ°Ê≥ïÂü∑Ë°åË§áÈõúÁöÑË®àÁÆó„ÄÇÁÑ∂ËÄåÔºåÊúâ‰∫∫Ë™çÁÇ∫‰∫∫È°û‰πü‰∏çËÉΩÁ´ãÂç≥Âü∑Ë°åÊ≠§Ë®àÁÆóÔºå‰∏¶‰∏îÈúÄË¶ÅÁõ∏Áï∂Èï∑ÁöÑÊôÇÈñìÊâçËÉΩÂª∫ÊßãËß£Ê≥ï„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑Ë™ûË®ÄÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõÔºå‰∏¶‰∏îËàá‰∫∫È°ûË°åÁÇ∫‰∏¶Ë°åÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®ÁâπÊÆäÁöÑ„ÄåÊÄùËÄÉÁ¨¶Ëôü„ÄçÔºåËÆìÊ®°ÂûãÂú®ÈÅáÂà∞Ë§áÈõúÂïèÈ°åÊôÇËÉΩÂ§†Âü∑Ë°åÊõ¥Â§öË®àÁÆó„ÄÇ

##### **ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation**
2405.08619v2 by Dimitris Gkoumas

The field of chemistry and Artificial Intelligence (AI) intersection is an
area of active research that aims to accelerate scientific discovery. The
integration of large language models (LLMs) with scientific modalities has
shown significant promise in this endeavour. However, challenges persist in
effectively addressing training efficacy and the out-of-distribution problem,
particularly as existing approaches rely on larger models and datasets. In this
context, we focus on machine language-molecule translation and deploy a novel
training approach called contrastive preference optimisation, which avoids
generating translations that are merely adequate but not perfect. To ensure
generalisability and mitigate memorisation effects, we conduct experiments
using only 10\% of the data. Our results demonstrate that our models achieve up
to a 32\% improvement compared to counterpart models. We also introduce a
scalable fine-grained evaluation methodology that accommodates responsibility.

ÊëòË¶ÅÔºöÂåñÂ≠∏Ëàá‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑ‰∫§ÂèâÈ†òÂüüÊòØ‰∏ÄÂÄãÁ©çÊ•µÁ†îÁ©∂È†òÂüüÔºåÊó®Âú®Âä†ÈÄüÁßëÂ≠∏ÁôºÁèæ„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÁßëÂ≠∏Ê®°ÂºèÁöÑÊï¥ÂêàÂ∑≤Âú®Ê≠§È†ÖÂ∑•‰Ωú‰∏≠Â±ïÁèæÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂú®ÊúâÊïàËß£Ê±∫Ë®ìÁ∑¥ÊïàËÉΩÂíåÂàÜÂ∏ÉÂ§ñÂïèÈ°åÊôÇÔºåÊåëÊà∞‰æùÁÑ∂Â≠òÂú®ÔºåÁâπÂà•ÊòØÂõ†ÁÇ∫ÁèæÊúâÊñπÊ≥ï‰æùË≥¥ÊñºËºÉÂ§ßÁöÑÊ®°ÂûãÂíåË≥áÊñôÈõÜ„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÊ©üÂô®Ë™ûË®ÄÂàÜÂ≠êÁøªË≠ØÔºå‰∏¶ÈÉ®ÁΩ≤‰∏ÄÁ®ÆÁ®±ÁÇ∫Â∞çÊØîÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁöÑÂâµÊñ∞Ë®ìÁ∑¥ÊñπÊ≥ïÔºåÈÅøÂÖçÁî¢ÁîüÂÉÖÂÉÖË∂≥Â§†‰ΩÜ‰∏¶‰∏çÂÆåÁæé‰πãÁøªË≠Ø„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÊ¶ÇÊã¨ÊÄß‰∏¶Ê∏õËºïË®òÊÜ∂ÊïàÊáâÔºåÊàëÂÄëÂÉÖ‰ΩøÁî® 10% ÁöÑË≥áÊñôÈÄ≤Ë°åÂØ¶È©ó„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÊòéÔºåËàáÂ∞çÊáâÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÁç≤Âæó‰∫ÜÈ´òÈÅî 32% ÁöÑÊîπÈÄ≤„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂèØÊì¥Â±ïÁöÑÁ¥∞Á≤íÂ∫¶Ë©ï‰º∞ÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë≤¨‰ªª„ÄÇ

##### **Towards Geometry-Aware Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization**
2405.08604v1 by Yongfan Lu, Zixiang Di, Bingdong Li, Shengcai Liu, Hong Qian, Peng Yang, Ke Tang, Aimin Zhou

Multi-objective combinatorial optimization (MOCO) problems are prevalent in
various real-world applications. Most existing neural methods for MOCO problems
rely solely on decomposition and utilize precise hypervolume to enhance
diversity. However, these methods often approximate only limited regions of the
Pareto front and spend excessive time on diversity enhancement because of
ambiguous decomposition and time-consuming hypervolume calculation. To address
these limitations, we design a Geometry-Aware Pareto set Learning algorithm
named GAPL, which provides a novel geometric perspective for neural MOCO via a
Pareto attention model based on hypervolume expectation maximization. In
addition, we propose a hypervolume residual update strategy to enable the
Pareto attention model to capture both local and non-local information of the
Pareto set/front. We also design a novel inference approach to further improve
quality of the solution set and speed up hypervolume calculation and local
subset selection. Experimental results on three classic MOCO problems
demonstrate that our GAPL outperforms state-of-the-art neural baselines via
superior decomposition and efficient diversity enhancement.

ÊëòË¶ÅÔºöÂ§öÁõÆÊ®ôÁµÑÂêàÊúÄ‰Ω≥Âåñ (MOCO) ÂïèÈ°åÂú®ÂêÑÁ®ÆÁúüÂØ¶‰∏ñÁïåÁöÑÊáâÁî®‰∏≠ÂæàÊôÆÈÅç„ÄÇÂ§ßÂ§öÊï∏ÁèæÊúâÁöÑ MOCO ÂïèÈ°åÁ•ûÁ∂ìÊñπÊ≥ïÂÉÖ‰æùË≥¥ÂàÜËß£Ôºå‰∏¶Âà©Áî®Á≤æÁ¢∫ÁöÑË∂ÖÈ´îÁ©ç‰æÜÂ¢ûÂº∑Â§öÊ®£ÊÄß„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖËøë‰ººÂ∏ïÈõ∑ÊâòÂâçÁ∑£ÁöÑÊúâÈôêÂçÄÂüüÔºå‰∏¶‰∏îÁî±ÊñºÂàÜËß£‰∏çÊòéÁ¢∫ÂíåËÄóÊôÇÁöÑË∂ÖÈ´îÁ©çË®àÁÆóËÄåËä±Ë≤ªÈÅéÂ§öÊôÇÈñìÂú®Â§öÊ®£ÊÄßÂ¢ûÂº∑‰∏ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ GAPL ÁöÑÂπæ‰ΩïÊÑüÁü•Â∏ïÈõ∑ÊâòÈõÜÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÂÆÉÈÄèÈÅéÂü∫ÊñºË∂ÖÈ´îÁ©çÊúüÊúõÊúÄÂ§ßÂåñÁöÑÂ∏ïÈõ∑ÊâòÊ≥®ÊÑèÂäõÊ®°ÂûãÁÇ∫Á•ûÁ∂ì MOCO Êèê‰æõ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂπæ‰ΩïËßÄÈªû„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË∂ÖÈ´îÁ©çÊÆòÂ∑ÆÊõ¥Êñ∞Á≠ñÁï•Ôºå‰ΩøÂ∏ïÈõ∑ÊâòÊ≥®ÊÑèÂäõÊ®°ÂûãËÉΩÂ§†Êì∑ÂèñÂ∏ïÈõ∑ÊâòÈõÜ/ÂâçÁ∑£ÁöÑÂ±ÄÈÉ®ÂíåÈùûÂ±ÄÈÉ®Ë≥áË®ä„ÄÇÊàëÂÄëÈÇÑË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊé®Ë´ñÊñπÊ≥ïÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òËß£ÈõÜÁöÑÂìÅË≥™Ôºå‰∏¶Âä†Âø´Ë∂ÖÈ´îÁ©çË®àÁÆóÂíåÂ±ÄÈÉ®Â≠êÈõÜÈÅ∏Êìá„ÄÇÂú®‰∏âÂÄãÁ∂ìÂÖ∏ MOCO ÂïèÈ°å‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑ GAPL ÈÄèÈÅéÂÑ™Áï∞ÁöÑÂàÜËß£ÂíåÊúâÊïàÁöÑÂ§öÊ®£ÊÄßÂ¢ûÂº∑ÔºåÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁ•ûÁ∂ìÂü∫Ê∫ñ„ÄÇ

##### **A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine**
2405.08603v1 by Hanguang Xiao, Feizhong Zhou, Xingyue Liu, Tianqi Liu, Zhipeng Li, Xin Liu, Xiaoxuan Huang

Since the release of ChatGPT and GPT-4, large language models (LLMs) and
multimodal large language models (MLLMs) have garnered significant attention
due to their powerful and general capabilities in understanding, reasoning, and
generation, thereby offering new paradigms for the integration of artificial
intelligence with medicine. This survey comprehensively overviews the
development background and principles of LLMs and MLLMs, as well as explores
their application scenarios, challenges, and future directions in medicine.
Specifically, this survey begins by focusing on the paradigm shift, tracing the
evolution from traditional models to LLMs and MLLMs, summarizing the model
structures to provide detailed foundational knowledge. Subsequently, the survey
details the entire process from constructing and evaluating to using LLMs and
MLLMs with a clear logic. Following this, to emphasize the significant value of
LLMs and MLLMs in healthcare, we survey and summarize 6 promising applications
in healthcare. Finally, the survey discusses the challenges faced by medical
LLMs and MLLMs and proposes a feasible approach and direction for the
subsequent integration of artificial intelligence with medicine. Thus, this
survey aims to provide researchers with a valuable and comprehensive reference
guide from the perspectives of the background, principles, and clinical
applications of LLMs and MLLMs.

ÊëòË¶ÅÔºöËá™ ChatGPT Âíå GPT-4 ÁôºÂ∏É‰ª•‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Âõ†ÂÖ∂Âú®ÁêÜËß£„ÄÅÊé®ÁêÜÂíåÁîüÊàêÊñπÈù¢ÁöÑÂº∑Â§ß‰∏îÈÄöÁî®ÁöÑËÉΩÂäõËÄåÂÇôÂèóÈóúÊ≥®ÔºåÂæûËÄåÁÇ∫‰∫∫Â∑•Êô∫ÊÖßËàáÈÜ´Â≠∏Êï¥ÂêàÊèê‰æõ‰∫ÜÊñ∞ÁöÑÁØÑ‰æã„ÄÇÊú¨Á∂úËø∞ÂÖ®Èù¢Ê¶ÇËø∞‰∫Ü LLM Âíå MLLM ÁöÑÁôºÂ±ïËÉåÊôØÂíåÂéüÁêÜÔºå‰∏¶Êé¢Ë®é‰∫ÜÂÆÉÂÄëÂú®ÈÜ´Â≠∏‰∏≠ÁöÑÊáâÁî®Â†¥ÊôØ„ÄÅÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêë„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊú¨Á∂úËø∞È¶ñÂÖàËëóÈáçÊñºÁØÑ‰æãËΩâÁßªÔºåËøΩÊ∫ØÂæûÂÇ≥Áµ±Ê®°ÂûãÂà∞ LLM Âíå MLLM ÁöÑÊºîËÆäÔºåÁ∏ΩÁµêÊ®°ÂûãÁµêÊßã‰ª•Êèê‰æõË©≥Á¥∞ÁöÑÂü∫Êú¨Áü•Ë≠ò„ÄÇÈö®ÂæåÔºåÊú¨Á∂úËø∞Ë©≥Á¥∞‰ªãÁ¥π‰∫ÜÂæûÊßãÂª∫ÂíåË©ï‰º∞Âà∞‰ΩøÁî® LLM Âíå MLLM ÁöÑÊï¥ÂÄãÈÅéÁ®ãÔºåÈÇèËºØÊ∏ÖÊô∞„ÄÇÁ∑äÊé•ËëóÔºåÁÇ∫‰∫ÜÂº∑Ë™ø LLM Âíå MLLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÈáçË¶ÅÂÉπÂÄºÔºåÊàëÂÄëË™øÊü•‰∏¶Á∏ΩÁµê‰∫ÜÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ 6 ÂÄãÊúâÂâçÊôØÁöÑÊáâÁî®„ÄÇÊúÄÂæåÔºåÊú¨Á∂úËø∞Ë®éË´ñ‰∫ÜÈÜ´Â≠∏ LLM Âíå MLLM Èù¢Ëá®ÁöÑÊåëÊà∞Ôºå‰∏¶ÊèêÂá∫‰∫Ü‰∫∫Â∑•Êô∫ÊÖßËàáÈÜ´Â≠∏ÂæåÁ∫åÊï¥ÂêàÁöÑÂèØË°åÈÄîÂæëÂíåÊñπÂêë„ÄÇÂõ†Ê≠§ÔºåÊú¨Á∂úËø∞Êó®Âú®Âæû LLM Âíå MLLM ÁöÑËÉåÊôØ„ÄÅÂéüÁêÜÂíåËá®Â∫äÊáâÁî®ËßíÂ∫¶ÁÇ∫Á†îÁ©∂‰∫∫Âì°Êèê‰æõÊúâÂÉπÂÄº‰∏îÂÖ®Èù¢ÁöÑÂèÉËÄÉÊåáÂçó„ÄÇ

##### **EchoTracker: Advancing Myocardial Point Tracking in Echocardiography**
2405.08587v1 by Md Abulkalam Azad, Artem Chernyshov, John Nyberg, Ingrid Tveten, Lasse Lovstakken, H√•vard Dalen, Bj√∏rnar Grenne, Andreas √òstvik

Tissue tracking in echocardiography is challenging due to the complex cardiac
motion and the inherent nature of ultrasound acquisitions. Although optical
flow methods are considered state-of-the-art (SOTA), they struggle with
long-range tracking, noise occlusions, and drift throughout the cardiac cycle.
Recently, novel learning-based point tracking techniques have been introduced
to tackle some of these issues. In this paper, we build upon these techniques
and introduce EchoTracker, a two-fold coarse-to-fine model that facilitates the
tracking of queried points on a tissue surface across ultrasound image
sequences. The architecture contains a preliminary coarse initialization of the
trajectories, followed by reinforcement iterations based on fine-grained
appearance changes. It is efficient, light, and can run on mid-range GPUs.
Experiments demonstrate that the model outperforms SOTA methods, with an
average position accuracy of 67% and a median trajectory error of 2.86 pixels.
Furthermore, we show a relative improvement of 25% when using our model to
calculate the global longitudinal strain (GLS) in a clinical test-retest
dataset compared to other methods. This implies that learning-based point
tracking can potentially improve performance and yield a higher diagnostic and
prognostic value for clinical measurements than current techniques. Our source
code is available at: https://github.com/riponazad/echotracker/.

ÊëòË¶ÅÔºöÂú®Ë∂ÖÈü≥Ê≥¢ÂøÉÂãïÂúñ‰∏≠ÔºåÁî±ÊñºË§áÈõúÁöÑÂøÉËáüÈÅãÂãïÂíåË∂ÖÈü≥Ê≥¢Êì∑ÂèñÁöÑÂÖßÂú®ÊÄßË≥™ÔºåÁµÑÁπîËøΩËπ§ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈõñÁÑ∂ÂÖâÊµÅÊ≥ïË¢´Ë™çÁÇ∫ÊòØÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑÊäÄË°ìÔºàSOTAÔºâÔºå‰ΩÜÂÆÉÂÄëÂú®Êï¥ÂÄãÂøÉËáüÈÄ±Êúü‰∏≠Èõ£‰ª•ÈÄ≤Ë°åÈï∑Á®ãËøΩËπ§„ÄÅÈõúË®äÈÅÆËîΩÂíåÊºÇÁßª„ÄÇÊúÄËøëÔºåÂºïÈÄ≤‰∫ÜÂü∫ÊñºÊñ∞Á©éÂ≠∏ÁøíÁöÑÈªûËøΩËπ§ÊäÄË°ì‰æÜËß£Ê±∫ÂÖ∂‰∏≠‰∏Ä‰∫õÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Á´ãÂú®ÈÄô‰∫õÊäÄË°ì‰πã‰∏äÔºå‰∏¶‰ªãÁ¥π‰∫Ü EchoTrackerÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ©ÈáçÁöÑÁ≤óÁï•Âà∞Á≤æÁ¥∞Ê®°ÂûãÔºåÁî®Êñº‰øÉÈÄ≤Âú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂ∫èÂàó‰∏≠ËøΩËπ§ÁµÑÁπîË°®Èù¢‰∏äÁöÑÊü•Ë©¢Èªû„ÄÇË©≤Êû∂ÊßãÂåÖÂê´ËªåË∑°ÁöÑÂàùÊ≠•Á≤óÁï•ÂàùÂßãÂåñÔºåÁÑ∂ÂæåÊ†πÊìöÁ¥∞Á≤íÂ∫¶Â§ñËßÄËÆäÂåñÈÄ≤Ë°åÂº∑ÂåñÂèçË¶ÜÈÅãÁÆó„ÄÇÂÆÉÈ´òÊïà„ÄÅËºïÂ∑ßÔºåÂèØ‰ª•Âú®‰∏≠Èöé GPU ‰∏äÂü∑Ë°å„ÄÇÂØ¶È©óË°®ÊòéÔºåË©≤Ê®°ÂûãÂÑ™Êñº SOTA ÊñπÊ≥ïÔºåÂπ≥Âùá‰ΩçÁΩÆÁ≤æÂ∫¶ÁÇ∫ 67%ÔºåÂπ≥ÂùáËªåË∑°Ë™§Â∑ÆÁÇ∫ 2.86 ÂÉèÁ¥†„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú®Ëá®Â∫äÊ∏¨Ë©¶ÈáçÊ∏¨Ë≥áÊñôÈõÜ‰∏≠‰ΩøÁî®ÊàëÂÄëÁöÑÊ®°ÂûãË®àÁÆóÂÖ®ÁêÉÁ∏±ÂêëÊáâËÆä (GLS) ÊôÇÔºåËàáÂÖ∂‰ªñÊñπÊ≥ïÁõ∏ÊØîÔºåÈ°ØÁ§∫Âá∫ 25% ÁöÑÁõ∏Â∞çÊîπÂñÑ„ÄÇÈÄôË°®Á§∫Âü∫ÊñºÂ≠∏ÁøíÁöÑÈªûËøΩËπ§ÂèØ‰ª•ÊΩõÂú®ÊîπÂñÑÊïàËÉΩÔºå‰∏¶ÊØîÁõÆÂâçÁöÑÊäÄË°ìÁÇ∫Ëá®Â∫äÊ∏¨ÈáèÊèê‰æõÊõ¥È´òÁöÑË®∫Êñ∑ÂíåÈ†êÂæåÂÉπÂÄº„ÄÇÊàëÂÄëÁöÑÂéüÂßãÁ¢ºÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂèñÂæóÔºöhttps://github.com/riponazad/echotracker/„ÄÇ

##### **Rethinking the adaptive relationship between Encoder Layers and Decoder Layers**
2405.08570v1 by Yubo Song

This article explores the adaptive relationship between Encoder Layers and
Decoder Layers using the SOTA model Helsinki-NLP/opus-mt-de-en, which
translates German to English. The specific method involves introducing a
bias-free fully connected layer between the Encoder and Decoder, with different
initializations of the layer's weights, and observing the outcomes of
fine-tuning versus retraining. Four experiments were conducted in total. The
results suggest that directly modifying the pre-trained model structure for
fine-tuning yields suboptimal performance. However, upon observing the outcomes
of the experiments with retraining, this structural adjustment shows
significant potential.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®éÁ∑®Á¢ºÂô®Â±§ÂíåËß£Á¢ºÂô®Â±§‰πãÈñìÁöÑÈÅ©ÊáâÊÄßÈóú‰øÇÔºå‰ΩøÁî® SOTA Ê®°Âûã Helsinki-NLP/opus-mt-de-enÔºåÂ∞áÂæ∑Ë™ûÁøªË≠ØÊàêËã±Ë™û„ÄÇÂÖ∑È´îÊñπÊ≥ïÊ∂âÂèäÂú®Á∑®Á¢ºÂô®ÂíåËß£Á¢ºÂô®‰πãÈñìÂºïÂÖ•‰∏ÄÂÄãÁÑ°ÂÅèÂ∑ÆÁöÑÂÖ®ÈÄ£Êé•Â±§ÔºåË©≤Â±§ÁöÑÊ¨äÈáçÊúâ‰∏çÂêåÁöÑÂàùÂßãÂåñÔºå‰∏¶ËßÄÂØüÂæÆË™øËàáÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÁµêÊûú„ÄÇÁ∏ΩÂÖ±ÈÄ≤Ë°å‰∫ÜÂõõÈ†ÖÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåÁõ¥Êé•‰øÆÊîπÈ†êË®ìÁ∑¥Ê®°ÂûãÁµêÊßã‰ª•ÈÄ≤Ë°åÂæÆË™øÊúÉÁî¢ÁîüÊ¨°ÂÑ™ÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂú®ËßÄÂØüÈáçÊñ∞Ë®ìÁ∑¥ÁöÑÂØ¶È©óÁµêÊûúÂæåÔºåÈÄôÁ®ÆÁµêÊßãË™øÊï¥È°ØÁ§∫Âá∫Â∑®Â§ßÁöÑÊΩõÂäõ„ÄÇ

##### **The Unseen Targets of Hate -- A Systematic Review of Hateful Communication Datasets**
2405.08562v1 by Zehui Yu, Indira Sen, Dennis Assenmacher, Mattia Samory, Leon Fr√∂hling, Christina Dahn, Debora Nozza, Claudia Wagner

Machine learning (ML)-based content moderation tools are essential to keep
online spaces free from hateful communication. Yet, ML tools can only be as
capable as the quality of the data they are trained on allows them. While there
is increasing evidence that they underperform in detecting hateful
communications directed towards specific identities and may discriminate
against them, we know surprisingly little about the provenance of such bias. To
fill this gap, we present a systematic review of the datasets for the automated
detection of hateful communication introduced over the past decade, and unpack
the quality of the datasets in terms of the identities that they embody: those
of the targets of hateful communication that the data curators focused on, as
well as those unintentionally included in the datasets. We find, overall, a
skewed representation of selected target identities and mismatches between the
targets that research conceptualizes and ultimately includes in datasets. Yet,
by contextualizing these findings in the language and location of origin of the
datasets, we highlight a positive trend towards the broadening and
diversification of this research space.

ÊëòË¶ÅÔºöÂü∫ÊñºÊ©üÂô®Â≠∏Áøí (ML) ÁöÑÂÖßÂÆπÂØ©Ê†∏Â∑•ÂÖ∑Â∞çÊñºËÆìÁ∂≤Ë∑ØÁ©∫ÈñìÂÖçÊñº‰ªáÊÅ®Ë®ÄË´ñËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåML Â∑•ÂÖ∑ÁöÑËÉΩÂäõÂèñÊ±∫ÊñºÁî®ÊñºË®ìÁ∑¥ÂÆÉÂÄëÁöÑË≥áÊñôÂìÅË≥™„ÄÇÈõñÁÑ∂ÊúâÊÑà‰æÜÊÑàÂ§öÁöÑË≠âÊìöÈ°ØÁ§∫ÔºåÈÄô‰∫õÂ∑•ÂÖ∑Âú®ÂÅµÊ∏¨ÈáùÂ∞çÁâπÂÆöË∫´ÂàÜÁöÑ‰ªáÊÅ®Ë®ÄË´ñÊôÇË°®Áèæ‰∏ç‰Ω≥ÔºåÁîöËá≥ÂèØËÉΩÂ∞çÈÄô‰∫õË∫´ÂàÜÈÄ≤Ë°åÊ≠ßË¶ñÔºå‰ΩÜÊàëÂÄëÂ∞çÊñºÊ≠§È°ûÂÅèË¶ãÁöÑ‰æÜÊ∫êÂçªÊâÄÁü•ÁîöÂ∞ë„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄôÂÄãÁº∫Âè£ÔºåÊàëÂÄëÂ∞çÈÅéÂéªÂçÅÂπ¥‰æÜÂºïÂÖ•ÁöÑËá™ÂãïÂåñ‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨Ë≥áÊñôÈõÜÈÄ≤Ë°åÁ≥ªÁµ±ÊÄßÂõûÈ°ßÔºå‰∏¶ÂæûË≥áÊñôÈõÜÊâÄÈ´îÁèæÁöÑË∫´ÂàÜËßíÂ∫¶Êé¢Ë®éË≥áÊñôÈõÜÂìÅË≥™ÔºöË≥áÊñôÁ≠ñÂ±ï‰∫∫ÈóúÊ≥®ÁöÑ‰ªáÊÅ®Ë®ÄË´ñÁõÆÊ®ôË∫´ÂàÜÔºå‰ª•ÂèäÁÑ°ÊÑèÈñìÂåÖÂê´Âú®Ë≥áÊñôÈõÜ‰∏≠ÁöÑË∫´ÂàÜ„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁôºÁèæÈÅ∏ÂÆöÁöÑÁõÆÊ®ôË∫´ÂàÜÊúâÂ§±Ë°°ÁöÑ‰ª£Ë°®ÊÄßÔºå‰∏îÁ†îÁ©∂Ê¶ÇÂøµÂåñÂíåÊúÄÁµÇÂåÖÂê´Âú®Ë≥áÊñôÈõÜ‰∏≠ÁöÑÁõÆÊ®ô‰πãÈñìÂ≠òÂú®ËêΩÂ∑Æ„ÄÇÁÑ∂ËÄåÔºåÈÄèÈÅéÂ∞áÈÄô‰∫õÁôºÁèæÁΩÆÊñºË≥áÊñôÈõÜÁöÑË™ûË®ÄÂíå‰æÜÊ∫ê‰ΩçÁΩÆÁöÑËÑàÁµ°‰∏≠ÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊ≠§Á†îÁ©∂È†òÂüüÊúùÂêëÊì¥Â±ïÂíåÂ§öÂÖÉÂåñÁöÑÊ≠£Èù¢Ë∂®Âã¢„ÄÇ

##### **Improving Transformers with Dynamically Composable Multi-Head Attention**
2405.08553v1 by Da Xiao, Qingye Meng, Shengping Li, Xingyuan Yuan

Multi-Head Attention (MHA) is a key component of Transformer. In MHA,
attention heads work independently, causing problems such as low-rank
bottleneck of attention score matrices and head redundancy. We propose
Dynamically Composable Multi-Head Attention (DCMHA), a parameter and
computation efficient attention architecture that tackles the shortcomings of
MHA and increases the expressive power of the model by dynamically composing
attention heads. At the core of DCMHA is a $\it{Compose}$ function that
transforms the attention score and weight matrices in an input-dependent way.
DCMHA can be used as a drop-in replacement of MHA in any transformer
architecture to obtain the corresponding DCFormer. DCFormer significantly
outperforms Transformer on different architectures and model scales in language
modeling, matching the performance of models with ~1.7x-2.0x compute. For
example, DCPythia-6.9B outperforms open source Pythia-12B on both pretraining
perplexity and downstream task evaluation. The code and models are available at
https://github.com/Caiyun-AI/DCFormer.

ÊëòË¶ÅÔºöÂ§öÈ†≠Ê≥®ÊÑèÂäõ (MHA) ÊòØ Transformer ÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÂú® MHA ‰∏≠ÔºåÊ≥®ÊÑèÂäõÈ†≠ÈÉ®Áç®Á´ãÈÅã‰ΩúÔºåÂ∞éËá¥Ê≥®ÊÑèÂäõÂàÜÊï∏Áü©Èô£ÁöÑ‰ΩéÁß©Áì∂È†∏ÂíåÈ†≠ÈÉ®ÂÜóÈ§òÁ≠âÂïèÈ°å„ÄÇÊàëÂÄëÊèêÂá∫ÂãïÊÖãÂèØÁµÑÊàêÂ§öÈ†≠Ê≥®ÊÑèÂäõ (DCMHA)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂèÉÊï∏ÂíåË®àÁÆóÊïàÁéáÈ´òÁöÑÊ≥®ÊÑèÂäõÊû∂ÊßãÔºåÂèØËß£Ê±∫ MHA ÁöÑÁº∫Èªû‰∏¶ÈÄèÈÅéÂãïÊÖãÁµÑÊàêÊ≥®ÊÑèÂäõÈ†≠ÈÉ®‰æÜÂ¢ûÂä†Ê®°ÂûãÁöÑË°®ÈÅîËÉΩÂäõ„ÄÇDCMHA ÁöÑÊ†∏ÂøÉÊòØ‰∏ÄÂÄã $\it{Compose}$ ÂáΩÊï∏ÔºåÂÆÉ‰ª•Ëº∏ÂÖ•‰æùË≥¥ÁöÑÊñπÂºèËΩâÊèõÊ≥®ÊÑèÂäõÂàÜÊï∏ÂíåÊ¨äÈáçÁü©Èô£„ÄÇDCMHA ÂèØÁî®ÊñºÂèñ‰ª£‰ªª‰Ωï Transformer Êû∂Êßã‰∏≠ÁöÑ MHAÔºå‰ª•ÂèñÂæóÂ∞çÊáâÁöÑ DCFormer„ÄÇDCFormer Âú®‰∏çÂêåÁöÑÊû∂ÊßãÂíåË™ûË®ÄÂª∫Ê®°‰∏≠ÁöÑÊ®°ÂûãË¶èÊ®°‰∏äÈ°ØËëóÂÑ™Êñº TransformerÔºåÂÖ∂ÊïàËÉΩËàáÈÅãÁÆóÈáèÁ¥ÑÁÇ∫ 1.7x-2.0x ÁöÑÊ®°ÂûãÁõ∏ÂåπÈÖç„ÄÇ‰æãÂ¶ÇÔºåDCPythia-6.9B Âú®È†êË®ìÁ∑¥Âõ∞ÊÉëÂ∫¶Âíå‰∏ãÊ∏∏‰ªªÂãôË©ï‰º∞‰∏≠ÈÉΩÂÑ™ÊñºÈñãÊ∫ê Pythia-12B„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂèØÂú® https://github.com/Caiyun-AI/DCFormer ÂèñÂæó„ÄÇ

##### **Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization**
2405.08540v1 by Rui Li, Chaozhuo Li, Yanming Shen, Zeyu Zhang, Xu Chen

Recent advances in knowledge graph embedding (KGE) rely on
Euclidean/hyperbolic orthogonal relation transformations to model intrinsic
logical patterns and topological structures. However, existing approaches are
confined to rigid relational orthogonalization with restricted dimension and
homogeneous geometry, leading to deficient modeling capability. In this work,
we move beyond these approaches in terms of both dimension and geometry by
introducing a powerful framework named GoldE, which features a universal
orthogonal parameterization based on a generalized form of Householder
reflection. Such parameterization can naturally achieve dimensional extension
and geometric unification with theoretical guarantees, enabling our framework
to simultaneously capture crucial logical patterns and inherent topological
heterogeneity of knowledge graphs. Empirically, GoldE achieves state-of-the-art
performance on three standard benchmarks. Codes are available at
https://github.com/xxrep/GoldE.

ÊëòË¶ÅÔºöÁü•Ë≠òÂúñË≠úÂµåÂÖ• (KGE) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ï‰æùË≥¥ÊñºÊ≠êÊ∞è/ÈõôÊõ≤Ê≠£‰∫§Èóú‰øÇËΩâÊèõ‰æÜÂª∫Ê®°ÂÖßÂú®ÈÇèËºØÊ®°ÂºèÂíåÊãìÊí≤ÁµêÊßã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÊñπÊ≥ïÂÉÖÈôêÊñºÂÖ∑ÊúâÂèóÈôêÁ∂≠Â∫¶ÂíåÂêåË≥™Âπæ‰ΩïÁöÑÂâõÊÄßÈóú‰øÇÊ≠£‰∫§ÂåñÔºåÂ∞éËá¥Âª∫Ê®°ËÉΩÂäõ‰∏çË∂≥„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂú®Á∂≠Â∫¶ÂíåÂπæ‰ΩïÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÈÄô‰∫õÊñπÊ≥ïÔºåÂºïÂÖ•‰∫ÜÂêçÁÇ∫ GoldE ÁöÑÂº∑Â§ßÊ°ÜÊû∂ÔºåÂÖ∂ÁâπÈªûÊòØÂü∫Êñº Householder ÂèçÂ∞ÑÁöÑÂª£Áæ©ÂΩ¢ÂºèÁöÑÈÄöÁî®Ê≠£‰∫§ÂèÉÊï∏Âåñ„ÄÇÈÄôÁ®ÆÂèÉÊï∏ÂåñÂèØ‰ª•Ëá™ÁÑ∂Âú∞ÂØ¶ÁèæÁ∂≠Â∫¶Êì¥Â±ïÂíåÂπæ‰ΩïÁµ±‰∏ÄÔºå‰∏¶ÂÖ∑ÊúâÁêÜË´ñ‰øùË≠âÔºå‰ΩøÊàëÂÄëÁöÑÊ°ÜÊû∂ËÉΩÂ§†ÂêåÊôÇÊçïÁç≤Áü•Ë≠òÂúñË≠úÁöÑÈóúÈçµÈÇèËºØÊ®°ÂºèÂíåÂÖßÂú®ÊãìÊí≤Áï∞Ë≥™ÊÄß„ÄÇÊ†πÊìöÁ∂ìÈ©óÔºåGoldE Âú®‰∏âÂÄãÊ®ôÊ∫ñÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩ„ÄÇ‰ª£Á¢ºÂèØÂú® https://github.com/xxrep/GoldE Áç≤Âæó„ÄÇ

##### **From Internet of Things Data to Business Processes: Challenges and a Framework**
2405.08528v1 by Juergen Mangler, Ronny Seiger, Janik-Vasily Benzin, Joscha Gr√ºger, Yusuf Kirikkayis, Florian Gallik, Lukas Malburg, Matthias Ehrendorfer, Yannis Bertrand, Marco Franceschetti, Barbara Weber, Stefanie Rinderle-Ma, Ralph Bergmann, Estefan√≠a Serral Asensio, Manfred Reichert

The IoT and Business Process Management (BPM) communities co-exist in many
shared application domains, such as manufacturing and healthcare. The IoT
community has a strong focus on hardware, connectivity and data; the BPM
community focuses mainly on finding, controlling, and enhancing the structured
interactions among the IoT devices in processes. While the field of Process
Mining deals with the extraction of process models and process analytics from
process event logs, the data produced by IoT sensors often is at a lower
granularity than these process-level events. The fundamental questions about
extracting and abstracting process-related data from streams of IoT sensor
values are: (1) Which sensor values can be clustered together as part of
process events?, (2) Which sensor values signify the start and end of such
events?, (3) Which sensor values are related but not essential? This work
proposes a framework to semi-automatically perform a set of structured steps to
convert low-level IoT sensor data into higher-level process events that are
suitable for process mining. The framework is meant to provide a generic
sequence of abstract steps to guide the event extraction, abstraction, and
correlation, with variation points for plugging in specific analysis techniques
and algorithms for each step. To assess the completeness of the framework, we
present a set of challenges, how they can be tackled through the framework, and
an example on how to instantiate the framework in a real-world demonstration
from the field of smart manufacturing. Based on this framework, future research
can be conducted in a structured manner through refining and improving
individual steps.

ÊëòË¶ÅÔºöÁâ©ËÅØÁ∂≤ÂíåÊ•≠ÂãôÊµÅÁ®ãÁÆ°ÁêÜ (BPM) Á§æÁæ§Âú®Ë®±Â§öÂÖ±‰∫´ÊáâÁî®È†òÂüü‰∏≠‰∏¶Â≠òÔºå‰æãÂ¶ÇË£ΩÈÄ†ÂíåÈÜ´ÁôÇ‰øùÂÅ•„ÄÇÁâ©ËÅØÁ∂≤Á§æÁæ§ËëóÈáçÊñºÁ°¨È´î„ÄÅÈÄ£Á∑öÊÄßÂíåË≥áÊñôÔºõBPM Á§æÁæ§‰∏ªË¶ÅËëóÈáçÊñºÂ∞ãÊâæ„ÄÅÊéßÂà∂ÂíåÊèêÂçáÊµÅÁ®ã‰∏≠Áâ©ËÅØÁ∂≤Ë£ùÁΩÆ‰πãÈñìÁöÑÁµêÊßãÂåñ‰∫íÂãï„ÄÇÈõñÁÑ∂ÊµÅÁ®ãÊé¢ÂãòÈ†òÂüüËôïÁêÜÂæûÊµÅÁ®ã‰∫ã‰ª∂Ë®òÈåÑ‰∏≠Êì∑ÂèñÊµÅÁ®ãÊ®°ÂûãÂíåÊµÅÁ®ãÂàÜÊûêÔºå‰ΩÜÁâ©ËÅØÁ∂≤ÊÑüÊ∏¨Âô®Áî¢ÁîüÁöÑË≥áÊñôÈÄöÂ∏∏ÊØîÈÄô‰∫õÊµÅÁ®ãÂ±§Á¥ö‰∫ã‰ª∂ÁöÑË©≥Á¥∞Á®ãÂ∫¶‰Ωé„ÄÇÂæûÁâ©ËÅØÁ∂≤ÊÑüÊ∏¨Âô®Êï∏ÂÄº‰∏≤ÊµÅ‰∏≠Êì∑ÂèñÂíåÊäΩË±°ËàáÊµÅÁ®ãÁõ∏ÈóúË≥áÊñôÁöÑÂü∫Êú¨ÂïèÈ°åÁÇ∫Ôºö(1) Âì™‰∫õÊÑüÊ∏¨Âô®Êï∏ÂÄºÂèØ‰ª•Áæ§ÈõÜÂú®‰∏ÄËµ∑‰ΩúÁÇ∫ÊµÅÁ®ã‰∫ã‰ª∂ÁöÑ‰∏ÄÈÉ®ÂàÜÔºü(2) Âì™‰∫õÊÑüÊ∏¨Âô®Êï∏ÂÄºË°®Á§∫Ê≠§È°û‰∫ã‰ª∂ÁöÑÈñãÂßãÂíåÁµêÊùüÔºü(3) Âì™‰∫õÊÑüÊ∏¨Âô®Êï∏ÂÄºÁõ∏Èóú‰ΩÜÈùûÂøÖË¶ÅÔºüÈÄôÈ†ÖÂ∑•‰ΩúÊèêÂá∫‰∏ÄÂÄãÊû∂ÊßãÔºå‰ª•ÂçäËá™ÂãïÂåñÊñπÂºèÂü∑Ë°å‰∏ÄÁµÑÁµêÊßãÂåñÊ≠•È©üÔºåÂ∞á‰ΩéÂ±§Á¥öÁâ©ËÅØÁ∂≤ÊÑüÊ∏¨Âô®Ë≥áÊñôËΩâÊèõÁÇ∫ÈÅ©ÂêàÊµÅÁ®ãÊé¢ÂãòÁöÑÈ´òÂ±§Á¥öÊµÅÁ®ã‰∫ã‰ª∂„ÄÇÈÄôÂÄãÊû∂ÊßãÊó®Âú®Êèê‰æõ‰∏ÄÁµÑÊäΩË±°Ê≠•È©üÔºå‰ª•ÊåáÂ∞é‰∫ã‰ª∂Êì∑Âèñ„ÄÅÊäΩË±°ÂíåÈóúËÅØÔºå‰∏¶Êèê‰æõËÆäÁï∞ÈªûÔºå‰ª•‰æøÈáùÂ∞çÊØèÂÄãÊ≠•È©üÊèíÂÖ•ÁâπÂÆöÁöÑÂàÜÊûêÊäÄË°ìÂíåÊºîÁÆóÊ≥ï„ÄÇÁÇ∫‰∫ÜË©ï‰º∞ÈÄôÂÄãÊû∂ÊßãÁöÑÂÆåÊï¥ÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁµÑÊåëÊà∞ÔºåË™™ÊòéÂ¶Ç‰ΩïÈÄèÈÅéÈÄôÂÄãÊû∂Êßã‰æÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞Ôºå‰∏¶Ëàâ‰æãË™™ÊòéÂ¶Ç‰ΩïÂæûÊô∫ÊÖßË£ΩÈÄ†È†òÂüüÁöÑÂØ¶ÈöõÁ§∫ÁØÑ‰∏≠ÂØ¶‰æãÂåñÈÄôÂÄãÊû∂Êßã„ÄÇÂü∫ÊñºÈÄôÂÄãÊû∂ÊßãÔºåÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØ‰ª•ÈÄèÈÅéÁ≤æÈÄ≤ÂíåÊîπÂñÑÂÄãÂà•Ê≠•È©üÔºå‰ª•ÁµêÊßãÂåñÁöÑÊñπÂºèÈÄ≤Ë°å„ÄÇ

##### **Falcon 7b for Software Mention Detection in Scholarly Documents**
2405.08514v1 by AmeerAli Khan, Qusai Ramadan, Cong Yang, Zeyd Boukhers

This paper aims to tackle the challenge posed by the increasing integration
of software tools in research across various disciplines by investigating the
application of Falcon-7b for the detection and classification of software
mentions within scholarly texts. Specifically, the study focuses on solving
Subtask I of the Software Mention Detection in Scholarly Publications (SOMD),
which entails identifying and categorizing software mentions from academic
literature. Through comprehensive experimentation, the paper explores different
training strategies, including a dual-classifier approach, adaptive sampling,
and weighted loss scaling, to enhance detection accuracy while overcoming the
complexities of class imbalance and the nuanced syntax of scholarly writing.
The findings highlight the benefits of selective labelling and adaptive
sampling in improving the model's performance. However, they also indicate that
integrating multiple strategies does not necessarily result in cumulative
improvements. This research offers insights into the effective application of
large language models for specific tasks such as SOMD, underlining the
importance of tailored approaches to address the unique challenges presented by
academic text analysis.

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊó®Âú®Ëß£Ê±∫ËªüÈ´îÂ∑•ÂÖ∑Âú®ÂêÑÂÄãÈ†òÂüüÁ†îÁ©∂‰∏≠Êó•ÁõäÊï¥ÂêàÊâÄÂ∏∂‰æÜÁöÑÊåëÊà∞ÔºåÁ†îÁ©∂ Falcon-7b Âú®Â≠∏Ë°ìÊñáÊú¨‰∏≠ÂÅµÊ∏¨ÂíåÂàÜÈ°ûËªüÈ´îÊèêÂèäÁöÑÊáâÁî®„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈÄôÈ†ÖÁ†îÁ©∂Â∞àÊ≥®ÊñºËß£Ê±∫Â≠∏Ë°ìÂá∫ÁâàÁâ©‰∏≠ËªüÈ´îÊèêÂèäÂÅµÊ∏¨ (SOMD) ÁöÑÂ≠ê‰ªªÂãô‰∏ÄÔºåÂÖ∂‰∏≠ÂåÖÊã¨Ë≠òÂà•ÂíåÂàÜÈ°ûÂ≠∏Ë°ìÊñáÁçª‰∏≠ÁöÑËªüÈ´îÊèêÂèä„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂØ¶È©óÔºåÊú¨ÊñáÊé¢Ë®é‰∫Ü‰∏çÂêåÁöÑË®ìÁ∑¥Á≠ñÁï•ÔºåÂåÖÊã¨ÈõôÂàÜÈ°ûÂô®ÊñπÊ≥ï„ÄÅËá™ÈÅ©ÊáâÊäΩÊ®£ÂíåÂä†Ê¨äÊêçÂ§±Á∏ÆÊîæÔºå‰ª•Âú®ÂÖãÊúçÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑË§áÈõúÊÄßÂíåÂ≠∏Ë°ìÂØ´‰ΩúÁöÑÁ¥∞ÂæÆË™ûÊ≥ïÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊèêÂçáÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜÈÅ∏ÊìáÊÄßÊ®ôË®òÂíåËá™ÈÅ©ÊáâÊäΩÊ®£Âú®ÊèêÂçáÊ®°ÂûãÊïàËÉΩÊñπÈù¢ÁöÑÂÑ™Èªû„ÄÇÁÑ∂ËÄåÔºåÁ†îÁ©∂ÁµêÊûú‰πüÊåáÂá∫ÔºåÊï¥ÂêàÂ§öÁ®ÆÁ≠ñÁï•‰∏¶‰∏ç‰∏ÄÂÆöÊúÉÂ∏∂‰æÜÁ¥ØÁ©çÁöÑÈÄ≤Ê≠•„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êèê‰æõ‰∫ÜÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÁâπÂÆö‰ªªÂãôÔºà‰æãÂ¶Ç SOMDÔºâ‰∏≠ÁöÑÊúâÊïàÊáâÁî®‰πãË¶ãËß£ÔºåÂº∑Ë™ø‰∫ÜÈáèË∫´ÊâìÈÄ†ÊñπÊ≥ïÂ∞çÊñºËß£Ê±∫Â≠∏Ë°ìÊñáÊú¨ÂàÜÊûêÊâÄÂëàÁèæ‰πãÁç®ÁâπÊåëÊà∞ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure**
2405.08502v1 by Odysseas S. Chlapanis, Ion Androutsopoulos, Dimitrios Galanis

The SemEval task on Argument Reasoning in Civil Procedure is challenging in
that it requires understanding legal concepts and inferring complex arguments.
Currently, most Large Language Models (LLM) excelling in the legal realm are
principally purposed for classification tasks, hence their reasoning rationale
is subject to contention. The approach we advocate involves using a powerful
teacher-LLM (ChatGPT) to extend the training dataset with explanations and
generate synthetic data. The resulting data are then leveraged to fine-tune a
small student-LLM. Contrary to previous work, our explanations are not directly
derived from the teacher's internal knowledge. Instead they are grounded in
authentic human analyses, therefore delivering a superior reasoning signal.
Additionally, a new `mutation' method generates artificial data instances
inspired from existing ones. We are publicly releasing the explanations as an
extension to the original dataset, along with the synthetic dataset and the
prompts that were used to generate both. Our system ranked 15th in the SemEval
competition. It outperforms its own teacher and can produce explanations
aligned with the original human analyses, as verified by legal experts.

ÊëòË¶ÅÔºöSemEval Âú®Ê∞ë‰∫ãË®¥Ë®ü‰∏≠ÈóúÊñºË´ñË≠âÊé®ÁêÜÁöÑ‰ªªÂãôÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÂõ†ÁÇ∫ÂÆÉÈúÄË¶ÅÁêÜËß£Ê≥ïÂæãÊ¶ÇÂøµ‰∏¶Êé®Ë´ñÂá∫Ë§áÈõúÁöÑË´ñÈªû„ÄÇÁõÆÂâçÔºåÂ§ßÂ§öÊï∏Âú®Ê≥ïÂæãÈ†òÂüüË°®ÁèæÂá∫Ëâ≤ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏ªË¶ÅÁî®ÊñºÂàÜÈ°û‰ªªÂãôÔºåÂõ†Ê≠§ÂÆÉÂÄëÁöÑÊé®ÁêÜ‰æùÊìöÊúâÂæÖÁà≠Ë≠∞„ÄÇÊàëÂÄëÊèêÂÄ°ÁöÑÊñπÊ≥ïÊ∂âÂèä‰ΩøÁî®Âº∑Â§ßÁöÑÊïôÂ∏´ LLM (ChatGPT) ‰æÜÊì¥ÂÖÖË®ìÁ∑¥Ë≥áÊñôÈõÜÔºå‰∏¶Êèê‰æõËß£ÈáãÂíåÁîüÊàêÂêàÊàêË≥áÊñô„ÄÇÁÑ∂ÂæåÂà©Áî®ÊâÄÂæóË≥áÊñôÂæÆË™øÂ∞èÂûãÂ≠∏Áîü LLM„ÄÇËàáÂÖàÂâçÁöÑÁ†îÁ©∂Áõ∏ÂèçÔºåÊàëÂÄëÁöÑËß£Èáã‰∏¶ÈùûÁõ¥Êé•‰æÜËá™ÊïôÂ∏´ÁöÑÂÖßÈÉ®Áü•Ë≠ò„ÄÇÁõ∏ÂèçÔºåÂÆÉÂÄëÂü∫ÊñºÁúüÂØ¶ÁöÑ‰∫∫È°ûÂàÜÊûêÔºåÂõ†Ê≠§Êèê‰æõ‰∫ÜÂÑ™Ë∂äÁöÑÊé®ÁêÜ‰ø°Ëôü„ÄÇÊ≠§Â§ñÔºåÊñ∞ÁöÑ„ÄåËÆäÁï∞„ÄçÊñπÊ≥ïÊúÉÂæûÁèæÊúâÁöÑÊñπÊ≥ï‰∏≠ÁîüÊàê‰∫∫Â∑•Ë≥áÊñôÂØ¶‰æã„ÄÇÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏ÉËß£Èáã‰ΩúÁÇ∫ÂéüÂßãË≥áÊñôÈõÜÁöÑÂª∂‰º∏ÔºåÈÄ£ÂêåÂêàÊàêË≥áÊñôÈõÜÂíåÁî®ÊñºÁî¢ÁîüÂÖ©ËÄÖÁöÑÊèêÁ§∫„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Âú® SemEval Á´∂Ë≥Ω‰∏≠ÊéíÂêçÁ¨¨ 15 ‰Ωç„ÄÇÂÆÉÂÑ™ÊñºËá™Â∑±ÁöÑËÄÅÂ∏´Ôºå‰∏¶‰∏îÂèØ‰ª•Áî¢ÁîüËàáÂéüÂßã‰∫∫È°ûÂàÜÊûê‰∏ÄËá¥ÁöÑËß£ÈáãÔºåÁ∂ìÊ≥ïÂæãÂ∞àÂÆ∂È©óË≠â„ÄÇ

##### **Is Less More? Quality, Quantity and Context in Idiom Processing with Natural Language Models**
2405.08497v1 by Agne Knietaite, Adam Allsebrook, Anton Minkov, Adam Tomaszewski, Norbert Slinko, Richard Johnson, Thomas Pickard, Dylan Phelps, Aline Villavicencio

Compositionality in language models presents a problem when processing
idiomatic expressions, as their meaning often cannot be directly derived from
their individual parts. Although fine-tuning and other optimization strategies
can be used to improve representations of idiomatic expressions, this depends
on the availability of relevant data. We present the Noun Compound Synonym
Substitution in Books - NCSSB - datasets, which are created by substitution of
synonyms of potentially idiomatic English noun compounds in public domain book
texts. We explore the trade-off between data quantity and quality when training
models for idiomaticity detection, in conjunction with contextual information
obtained locally (from the surrounding sentences) or externally (through
language resources). Performance on an idiomaticity detection task indicates
that dataset quality is a stronger factor for context-enriched models, but that
quantity also plays a role in models without context inclusion strategies.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÁµÑÊàêÊÄßÂú®ËôïÁêÜÊÖ£Áî®Ë™ûÊôÇÊúÉÁî¢Áîü‰∏ÄÂÄãÂïèÈ°åÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁöÑÊÑèÁæ©ÈÄöÂ∏∏ÁÑ°Ê≥ïÁõ¥Êé•ÂæûÂÆÉÂÄëÁöÑÂÄãÂà•ÈÉ®ÂàÜÊé®Â∞éÂá∫‰æÜ„ÄÇÂÑòÁÆ°ÂæÆË™øÂíåÂÖ∂‰ªñÊúÄ‰Ω≥ÂåñÁ≠ñÁï•ÂèØÁî®ÊñºÊîπÂñÑÊÖ£Áî®Ë™ûÁöÑË°®Á§∫ÔºåÈÄôÂèñÊ±∫ÊñºÁõ∏ÈóúË≥áÊñôÁöÑÂèØÁî®ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫ÂêçË©ûË§áÂêàÂêåÁæ©Ë©ûÊõø‰ª£Êõ∏Á±ç - NCSSB - Ë≥áÊñôÈõÜÔºåÂÆÉÊòØÈÄöÈÅéÂú®ÂÖ¨ÂÖ±È†òÂüüÊõ∏Á±çÊñáÊú¨‰∏≠ÊõøÊèõÊΩõÂú®ÊÖ£Áî®Ë™ûÁöÑËã±ÊñáÂêçË©ûË§áÂêàË©ûÁöÑÂêåÁæ©Ë©ûËÄåÂª∫Á´ãÁöÑ„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÂú®Ë®ìÁ∑¥ÊÖ£Áî®ÊÄßÂÅµÊ∏¨Ê®°ÂûãÊôÇË≥áÊñôÊï∏ÈáèÂíåÂìÅË≥™‰πãÈñìÁöÑÊäòË°∑Ôºå‰∏¶ÁµêÂêàÂæûÁï∂Âú∞Ôºà‰æÜËá™Âë®ÂúçÂè•Â≠êÔºâÊàñÂ§ñÈÉ®ÔºàÈÄèÈÅéË™ûË®ÄË≥áÊ∫êÔºâÁç≤ÂæóÁöÑËÑàÁµ°Ë≥áË®ä„ÄÇÊÖ£Áî®ÊÄßÂÅµÊ∏¨‰ªªÂãôÁöÑË°®ÁèæÊåáÂá∫ÔºåË≥áÊñôÈõÜÂìÅË≥™ÊòØËÑàÁµ°Ë±êÂØåÊ®°ÂûãÁöÑËºÉÂº∑ÂΩ±ÈüøÂõ†Á¥†Ôºå‰ΩÜÊï∏Èáè‰πüÂú®Ê≤íÊúâËÑàÁµ°Á¥çÂÖ•Á≠ñÁï•ÁöÑÊ®°Âûã‰∏≠ÁôºÊèÆ‰ΩúÁî®„ÄÇ

##### **Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models**
2405.08477v1 by Andrea Piergentili, Beatrice Savoldi, Matteo Negri, Luisa Bentivogli

Machine translation (MT) models are known to suffer from gender bias,
especially when translating into languages with extensive gendered morphology.
Accordingly, they still fall short in using gender-inclusive language, also
representative of non-binary identities. In this paper, we look at
gender-inclusive neomorphemes, neologistic elements that avoid binary gender
markings as an approach towards fairer MT. In this direction, we explore
prompting techniques with large language models (LLMs) to translate from
English into Italian using neomorphemes. So far, this area has been
under-explored due to its novelty and the lack of publicly available evaluation
resources. We fill this gap by releasing Neo-GATE, a resource designed to
evaluate gender-inclusive en-it translation with neomorphemes. With Neo-GATE,
we assess four LLMs of different families and sizes and different prompt
formats, identifying strengths and weaknesses of each on this novel task for
MT.

ÊëòË¶ÅÔºöÊ©üÂô®ÁøªË≠Ø (MT) Ê®°ÂûãÂ∑≤Áü•ÊúÉÈÅ≠ÂèóÊÄßÂà•ÂÅèË¶ãÔºå
ÁâπÂà•ÊòØÂú®ÁøªË≠ØÊàêÂÖ∑ÊúâÂª£Ê≥õÊÄßÂà•ÂΩ¢ÊÖãÁöÑË™ûË®ÄÊôÇ„ÄÇ
Âõ†Ê≠§ÔºåÂÆÉÂÄëÂú®‰ΩøÁî®ÊÄßÂà•ÂåÖÂÆπÊÄßË™ûË®ÄÊñπÈù¢‰ªçÊúâ‰∏çË∂≥Ôºå‰πü
‰ª£Ë°®‰∫ÜÈùû‰∫åÂÖÉÊÄßÂà•Ë™çÂêå„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é
ÊÄßÂà•ÂåÖÂÆπÊÄßÊñ∞ÂΩ¢ÊÖãÁ¥†ÔºåÊñ∞ÈÄ†Ë©ûÂÖÉÁ¥†ÔºåÈÅøÂÖç‰∫åÂÖÉÊÄßÂà•
Ê®ôË®ò‰ΩúÁÇ∫ÂØ¶ÁèæÊõ¥ÂÖ¨Âπ≥ MT ÁöÑ‰∏ÄÁ®ÆÊñπÊ≥ï„ÄÇÂú®ÈÄôÂÄãÊñπÂêë‰∏äÔºåÊàëÂÄëÊé¢Á¥¢
‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊèêÁ§∫ÊäÄË°ìÔºåÂæû
Ëã±Ë™ûÁøªË≠ØÊàêÁæ©Â§ßÂà©Ë™ûÊôÇ‰ΩøÁî®Êñ∞ÂΩ¢ÊÖãÁ¥†„ÄÇÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåÈÄôÂÄãÈ†òÂüü‰∏ÄÁõ¥
Áî±ÊñºÂÖ∂Êñ∞Á©éÊÄßÂíåÁº∫‰πèÂÖ¨ÈñãÂèØÁî®ÁöÑË©ï‰º∞
Ë≥áÊ∫ê„ÄÇÊàëÂÄëÈÄöÈÅéÁôºÂ∏É Neo-GATE ‰æÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊó®Âú®
Ë©ï‰º∞‰ΩøÁî®Êñ∞ÂΩ¢ÊÖãÁ¥†ÁöÑÊÄßÂà•ÂåÖÂÆπÊÄß en-it ÁøªË≠ØÁöÑË≥áÊ∫ê„ÄÇ‰ΩøÁî® Neo-GATEÔºå
ÊàëÂÄëË©ï‰º∞‰∫Ü‰∏çÂêåÁ≥ªÂàóÂíåÂ§ßÂ∞èÁöÑÂõõÂÄã LLM ‰ª•Âèä‰∏çÂêåÁöÑÊèêÁ§∫
Ê†ºÂºèÔºåË≠òÂà•‰∫ÜÊØèÁ®ÆÊ†ºÂºèÂú® MT ÈÄôÈ†ÖÊñ∞‰ªªÂãô‰∏≠ÁöÑÂÑ™Áº∫Èªû„ÄÇ

##### **GPT-3.5 for Grammatical Error Correction**
2405.08469v1 by Anisia Katinskaia, Roman Yangarber

This paper investigates the application of GPT-3.5 for Grammatical Error
Correction (GEC) in multiple languages in several settings: zero-shot GEC,
fine-tuning for GEC, and using GPT-3.5 to re-rank correction hypotheses
generated by other GEC models. In the zero-shot setting, we conduct automatic
evaluations of the corrections proposed by GPT-3.5 using several methods:
estimating grammaticality with language models (LMs), the Scribendi test, and
comparing the semantic embeddings of sentences. GPT-3.5 has a known tendency to
over-correct erroneous sentences and propose alternative corrections. For
several languages, such as Czech, German, Russian, Spanish, and Ukrainian,
GPT-3.5 substantially alters the source sentences, including their semantics,
which presents significant challenges for evaluation with reference-based
metrics. For English, GPT-3.5 demonstrates high recall, generates fluent
corrections, and generally preserves sentence semantics. However, human
evaluation for both English and Russian reveals that, despite its strong
error-detection capabilities, GPT-3.5 struggles with several error types,
including punctuation mistakes, tense errors, syntactic dependencies between
words, and lexical compatibility at the sentence level.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®é‰∫Ü GPT-3.5 Âú®Â§öÁ®ÆË™ûË®Ä‰∏≠Ë™ûÊ≥ïÈåØË™§Ê†°Ê≠£ (GEC) ÁöÑÊáâÁî®ÔºåÂåÖÊã¨Èõ∂Ê¨°Â≠∏Áøí GEC„ÄÅGEC ÂæÆË™øÔºå‰ª•Âèä‰ΩøÁî® GPT-3.5 Â∞çÂÖ∂‰ªñ GEC Ê®°ÂûãÁîüÊàêÁöÑÊ†°Ê≠£ÂÅáË®≠ÈÄ≤Ë°åÈáçÊñ∞ÊéíÂêç„ÄÇÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÂÆö‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Â§öÁ®ÆÊñπÊ≥ïÂ∞ç GPT-3.5 ÊèêÂá∫ÁöÑÊ†°Ê≠£ÈÄ≤Ë°åËá™ÂãïË©ï‰º∞Ôºö‰ΩøÁî®Ë™ûË®ÄÊ®°Âûã (LM) ‰º∞Ë®àË™ûÊ≥ïÊÄß„ÄÅScribendi Ê∏¨Ë©¶Ôºå‰ª•ÂèäÊØîËºÉÂè•Â≠êÁöÑË™ûÁæ©ÂµåÂÖ•„ÄÇÂ∑≤Áü• GPT-3.5 ÂÇæÂêëÊñºÈÅéÂ∫¶Ê†°Ê≠£ÈåØË™§Âè•Â≠ê‰∏¶ÊèêÂá∫Êõø‰ª£Ê†°Ê≠£„ÄÇÂ∞çÊñºÊç∑ÂÖãË™û„ÄÅÂæ∑Ë™û„ÄÅ‰øÑË™û„ÄÅË•øÁè≠ÁâôË™ûÂíåÁÉèÂÖãËò≠Ë™ûÁ≠âÂ§öÁ®ÆË™ûË®ÄÔºåGPT-3.5 ÊúÉÂ§ßÂπÖÂ∫¶ÊîπËÆäÂéüÂßãÂè•Â≠êÔºåÂåÖÊã¨ÂÆÉÂÄëÁöÑË™ûÁæ©ÔºåÈÄôÂ∞ç‰ΩøÁî®Âü∫ÊñºÂèÉËÄÉÁöÑÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞ÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÂ∞çÊñºËã±Ë™ûÔºåGPT-3.5 Ë°®ÁèæÂá∫È´òÂè¨ÂõûÁéáÔºåÁî¢ÁîüÊµÅÂà©ÁöÑÊ†°Ê≠£Ôºå‰∏¶‰∏îÈÄöÂ∏∏‰øùÁïôÂè•Â≠êË™ûÁæ©„ÄÇÁÑ∂ËÄåÔºåÂ∞çËã±Ë™ûÂíå‰øÑË™ûÁöÑ‰∫∫Â∑•Ë©ï‰º∞È°ØÁ§∫ÔºåÂÑòÁÆ° GPT-3.5 ÂÖ∑ÊúâÂº∑Â§ßÁöÑÈåØË™§Ê™¢Ê∏¨ËÉΩÂäõÔºå‰ΩÜÂú®Ê®ôÈªûÈåØË™§„ÄÅÊôÇÊÖãÈåØË™§„ÄÅË©ûË™û‰πãÈñìÁöÑÂè•Ê≥ï‰æùË≥¥ÊÄß‰ª•ÂèäÂè•Â≠êÂ±§Èù¢ÁöÑË©ûÂΩôÁõ∏ÂÆπÊÄßÁ≠âÂ§öÁ®ÆÈåØË™§È°ûÂûã‰∏≠ÔºåGPT-3.5 ‰ªçÂ≠òÂú®Âõ∞Èõ£„ÄÇ

##### **Challenges and Opportunities in Text Generation Explainability**
2405.08468v1 by Kenza Amara, Rita Sevastjanova, Mennatallah El-Assady

The necessity for interpretability in natural language processing (NLP) has
risen alongside the growing prominence of large language models. Among the
myriad tasks within NLP, text generation stands out as a primary objective of
autoregressive models. The NLP community has begun to take a keen interest in
gaining a deeper understanding of text generation, leading to the development
of model-agnostic explainable artificial intelligence (xAI) methods tailored to
this task. The design and evaluation of explainability methods are non-trivial
since they depend on many factors involved in the text generation process,
e.g., the autoregressive model and its stochastic nature. This paper outlines
17 challenges categorized into three groups that arise during the development
and assessment of attribution-based explainability methods. These challenges
encompass issues concerning tokenization, defining explanation similarity,
determining token importance and prediction change metrics, the level of human
intervention required, and the creation of suitable test datasets. The paper
illustrates how these challenges can be intertwined, showcasing new
opportunities for the community. These include developing probabilistic
word-level explainability methods and engaging humans in the explainability
pipeline, from the data design to the final evaluation, to draw robust
conclusions on xAI methods.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊó•ÁõäÊôÆÂèäÔºåËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Â∞çÂèØËß£ÈáãÊÄßÁöÑÈúÄÊ±Ç‰πüÈö®‰πãÂ¢ûÂä†„ÄÇÂú® NLP ‰∏≠ÁöÑÁÑ°Êï∏‰ªªÂãô‰∏≠ÔºåÊñáÊú¨ÁîüÊàê‰ΩúÁÇ∫Ëá™Ëø¥Ê≠∏Ê®°ÂûãÁöÑ‰∏ªË¶ÅÁõÆÊ®ôËÄåËÑ´Á©éËÄåÂá∫„ÄÇNLP Á§æÁæ§Â∑≤ÈñãÂßãÂ∞çÊ∑±ÂÖ•‰∫ÜËß£ÊñáÊú¨ÁîüÊàêÁî¢ÁîüÊøÉÂéöËààË∂£Ôºå‰∏¶ÈÄ≤ËÄåÈñãÁôºÂá∫ÈáùÂ∞çÊ≠§‰ªªÂãôÈáèË∫´ÊâìÈÄ†ÁöÑËàáÊ®°ÂûãÁÑ°ÈóúÁöÑÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (xAI) ÊñπÊ≥ï„ÄÇÁî±ÊñºÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑË®≠Ë®àÂíåË©ï‰º∞ÂèñÊ±∫ÊñºÊñáÊú¨ÁîüÊàêÈÅéÁ®ã‰∏≠Ê∂âÂèäÁöÑË®±Â§öÂõ†Á¥†Ôºà‰æãÂ¶ÇËá™Ëø¥Ê≠∏Ê®°ÂûãÂèäÂÖ∂Èö®Ê©üÊÄßË≥™ÔºâÔºåÂõ†Ê≠§‰∏¶ÈùûÊòì‰∫ã„ÄÇÊú¨ÊñáÊ¶ÇËø∞‰∫ÜÂú®Ê≠∏Âõ†ÂºèÂèØËß£ÈáãÊÄßÊñπÊ≥ïÁöÑÈñãÁôºÂíåË©ï‰º∞ÈÅéÁ®ã‰∏≠Áî¢ÁîüÁöÑ 17 È†ÖÊåëÊà∞Ôºå‰∏¶Â∞áÂÖ∂ÂàÜÈ°ûÁÇ∫‰∏âÁµÑ„ÄÇÈÄô‰∫õÊåëÊà∞Ê∂µËìã‰∫ÜËàáÊ®ôË®òÂåñ„ÄÅÂÆöÁæ©Ë™™ÊòéÁõ∏‰ººÊÄß„ÄÅÁ¢∫ÂÆöÊ®ôË®òÈáçË¶ÅÊÄßÂíåÈ†êÊ∏¨ËÆäÂãïÊåáÊ®ô„ÄÅÊâÄÈúÄÁöÑ‰∫∫Â∑•Âπ≤È†êÁ®ãÂ∫¶‰ª•ÂèäÂª∫Á´ãÈÅ©Áï∂Ê∏¨Ë©¶Ë≥áÊñôÈõÜÊúâÈóúÁöÑÂïèÈ°å„ÄÇÊú¨ÊñáË™™Êòé‰∫ÜÈÄô‰∫õÊåëÊà∞Â¶Ç‰ΩïÁõ∏‰∫í‰∫§ÁπîÔºå‰∏¶Â±ïÁ§∫‰∫ÜÁ§æÁæ§ÁöÑÊñ∞Ê©üÊúÉ„ÄÇÈÄô‰∫õÊ©üÊúÉÂåÖÊã¨ÈñãÁôºÊ©üÁéáÂ≠óÂÖÉÁ¥öÂèØËß£ÈáãÊÄßÊñπÊ≥ïÔºå‰ª•ÂèäËÆì‰∫∫È°ûÂèÉËàáÂèØËß£ÈáãÊÄßÁÆ°ÈÅìÔºàÂæûË≥áÊñôË®≠Ë®àÂà∞ÊúÄÁµÇË©ï‰º∞ÔºâÔºå‰ª•Â∞ç xAI ÊñπÊ≥ïÂæóÂá∫Á©©ÂÅ•ÁöÑÁµêË´ñ„ÄÇ

##### **Evaluating LLMs at Evaluating Temporal Generalization**
2405.08460v1 by Chenghao Zhu, Nuo Chen, Yufei Gao, Benyou Wang

The rapid advancement of Large Language Models (LLMs) highlights the urgent
need for evolving evaluation methodologies that keep pace with improvements in
language comprehension and information processing. However, traditional
benchmarks, which are often static, fail to capture the continually changing
information landscape, leading to a disparity between the perceived and actual
effectiveness of LLMs in ever-changing real-world scenarios. Furthermore, these
benchmarks do not adequately measure the models' capabilities over a broader
temporal range or their adaptability over time. We examine current LLMs in
terms of temporal generalization and bias, revealing that various temporal
biases emerge in both language likelihood and prognostic prediction. This
serves as a caution for LLM practitioners to pay closer attention to mitigating
temporal biases. Also, we propose an evaluation framework Freshbench for
dynamically generating benchmarks from the most recent real-world
prognostication prediction. Our code is available at
https://github.com/FreedomIntelligence/FreshBench. The dataset will be released
soon.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÁ™ÅÈ°Ø‰∫ÜËø´ÂàáÈúÄË¶ÅÊºîÈÄ≤Ë©ï‰º∞ÊñπÊ≥ïÔºå‰ª•Ë∑ü‰∏äË™ûË®ÄÁêÜËß£ÂíåË≥áË®äËôïÁêÜÁöÑÈÄ≤Ê≠•ËÖ≥Ê≠•„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±Âü∫Ê∫ñÈÄöÂ∏∏ÊòØÈùúÊÖãÁöÑÔºåÁÑ°Ê≥ïÊçïÊçâÊåÅÁ∫åËÆäÂåñÁöÑË≥áË®äÁí∞Â¢ÉÔºåÂ∞éËá¥ LLM Âú®‰∏çÊñ∑ËÆäÂåñÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÊÑüÁü•ÊïàËÉΩËàáÂØ¶ÈöõÊïàËÉΩ‰πãÈñìÂá∫ÁèæÂ∑ÆÁï∞„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÂü∫Ê∫ñ‰∏¶Êú™ÂÖÖÂàÜË°°ÈáèÊ®°ÂûãÂú®ËºÉÂª£Ê≥õÊôÇÈñìÁØÑÂúçÂÖßÁöÑÊïàËÉΩÊàñÂÖ∂Èö®ÊôÇÈñìÊé®ÁßªÁöÑÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÂú®ÊôÇÈñìÊ¶ÇÂåñÂíåÂÅèÂ∑ÆÊñπÈù¢Ê™¢È©ó‰∫ÜÁõÆÂâçÁöÑ LLMÔºåÊè≠Á§∫‰∫ÜË™ûË®ÄÂèØËÉΩÊÄßÂíåÈ†êÊ∏¨È†êÊ∏¨‰∏≠Âá∫ÁèæÂêÑÁ®ÆÊôÇÈñìÂÅèÂ∑Æ„ÄÇÈÄôÊèêÈÜí LLM ÂæûÊ•≠‰∫∫Âì°Êõ¥ÂØÜÂàáÂú∞Ê≥®ÊÑèÊ∏õËºïÊôÇÈñìÂÅèÂ∑Æ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜË©ï‰º∞Ê°ÜÊû∂ FreshbenchÔºåÁî®ÊñºÂãïÊÖãÁîüÊàê‰æÜËá™ÊúÄÊñ∞ÁúüÂØ¶‰∏ñÁïåÈ†êÊ∏¨È†êÊ∏¨ÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/FreedomIntelligence/FreshBench ÂèñÂæó„ÄÇË≥áÊñôÈõÜÂ∞áÂæàÂø´ÈáãÂá∫„ÄÇ

##### **How Alignment Helps Make the Most of Multimodal Data**
2405.08454v1 by Christian Arnold, Andreas K√ºpfer

When studying political communication, combining the information from text,
audio, and video signals promises to reflect the richness of human
communication more comprehensively than confining it to individual modalities
alone. However, when modeling such multimodal data, its heterogeneity,
connectedness, and interaction are challenging to address. We argue that
aligning the respective modalities can be an essential step in entirely using
the potential of multimodal data because it informs the model with human
understanding. Exploring aligned modalities unlocks promising analytical
leverage. First, it allows us to make the most of information in the data,
which inter alia opens the door to better quality predictions. Second, it is
possible to answer research questions that span multiple modalities with
cross-modal queries. Finally, alignment addresses concerns about model
interpretability. We illustrate the utility of this approach by analyzing how
German MPs address members of the far-right AfD in their speeches, and
predicting the tone of video advertising in the context of the 2020 US
presidential race. Our paper offers important insights to all keen to analyze
multimodal data effectively.

ÊëòË¶ÅÔºöÂú®Á†îÁ©∂ÊîøÊ≤ªÊ∫ùÈÄöÊôÇÔºåÁµêÂêàÊñáÂ≠ó„ÄÅÈü≥Ë®äÂíåË¶ñË®äË®äËôü‰∏≠ÁöÑË≥áË®äÔºåÊâøË´æÊØîÂÉÖÈôêÊñºÂÄãÂà•Ê®°ÂºèÊõ¥ÂÖ®Èù¢Âú∞ÂèçÊò†‰∫∫È°ûÊ∫ùÈÄöÁöÑË±êÂØåÊÄß„ÄÇÁÑ∂ËÄåÔºåÂú®Â∞çÊ≠§È°ûÂ§öÊ®°ÊÖãË≥áÊñôÈÄ≤Ë°åÂª∫Ê®°ÊôÇÔºåÂÖ∂Áï∞Ë≥™ÊÄß„ÄÅÈÄ£ÈÄöÊÄßÂíå‰∫íÂãïÊÄßÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÊØîÂ∞çÂêÑÂÄãÊ®°ÂºèÂèØËÉΩÊòØÂÖÖÂàÜÂà©Áî®Â§öÊ®°ÊÖãË≥áÊñôÊΩõÂäõÁöÑÂøÖË¶ÅÊ≠•È©üÔºåÂõ†ÁÇ∫ÂÆÉÊúÉÊ†πÊìö‰∫∫È°ûÁêÜËß£‰æÜÁÇ∫Ê®°ÂûãÊèê‰æõË≥áË®ä„ÄÇÊé¢Á¥¢ÊØîÂ∞çÁöÑÊ®°ÂºèÊúÉÈñãÂïüÊúâÂâçÊôØÁöÑÂàÜÊûêÂÑ™Âã¢„ÄÇÈ¶ñÂÖàÔºåÂÆÉËÆìÊàëÂÄëËÉΩÂ§†ÂÖÖÂàÜÂà©Áî®Ë≥áÊñô‰∏≠ÁöÑË≥áË®äÔºåÈÄôÈñìÊé•ÈñãÂïü‰∫ÜÈÄ≤Ë°åÊõ¥È´òÂìÅË≥™È†êÊ∏¨ÁöÑÂèØËÉΩÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÂèØ‰ª•ÈÄèÈÅéË∑®Ê®°ÂºèÊü•Ë©¢‰æÜÂõûÁ≠îÊ©´Ë∑®Â§öÂÄãÊ®°ÂºèÁöÑÁ†îÁ©∂ÂïèÈ°å„ÄÇÊúÄÂæåÔºåÊØîÂ∞çËß£Ê±∫‰∫ÜÈóúÊñºÊ®°ÂûãÂèØËß£ÈáãÊÄßÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÈÄèÈÅéÂàÜÊûêÂæ∑ÂúãÂúãÊúÉË≠∞Âì°Â¶Ç‰ΩïÂú®ÊºîË¨õ‰∏≠Â∞çÊ•µÂè≥ÁøºÂæ∑ÂúãÂè¶È°ûÈÅ∏ÊìáÈª® (AfD) ÊàêÂì°ÁôºË®ÄÔºå‰ª•ÂèäÈ†êÊ∏¨ 2020 Âπ¥ÁæéÂúãÁ∏ΩÁµ±Â§ßÈÅ∏ËÉåÊôØ‰∏ãË¶ñË®äÂª£ÂëäÁöÑË™ûÊ∞£Ôºå‰æÜË™™ÊòéÈÄôÁ®ÆÊñπÊ≥ïÁöÑÊïàÁî®„ÄÇÊàëÂÄëÁöÑË´ñÊñáÁÇ∫ÊâÄÊúâÁÜ±Ë°∑ÊñºÊúâÊïàÂàÜÊûêÂ§öÊ®°ÊÖãË≥áÊñôÁöÑ‰∫∫Êèê‰æõ‰∫ÜÈáçË¶ÅÁöÑË¶ãËß£„ÄÇ

##### **Understanding the performance gap between online and offline alignment algorithms**
2405.08448v1 by Yunhao Tang, Daniel Zhaohan Guo, Zeyu Zheng, Daniele Calandriello, Yuan Cao, Eugene Tarassov, R√©mi Munos, Bernardo √Åvila Pires, Michal Valko, Yong Cheng, Will Dabney

Reinforcement learning from human feedback (RLHF) is the canonical framework
for large language model alignment. However, rising popularity in offline
alignment algorithms challenge the need for on-policy sampling in RLHF. Within
the context of reward over-optimization, we start with an opening set of
experiments that demonstrate the clear advantage of online methods over offline
methods. This prompts us to investigate the causes to the performance
discrepancy through a series of carefully designed experimental ablations. We
show empirically that hypotheses such as offline data coverage and data quality
by itself cannot convincingly explain the performance difference. We also find
that while offline algorithms train policy to become good at pairwise
classification, it is worse at generations; in the meantime the policies
trained by online algorithms are good at generations while worse at pairwise
classification. This hints at a unique interplay between discriminative and
generative capabilities, which is greatly impacted by the sampling process.
Lastly, we observe that the performance discrepancy persists for both
contrastive and non-contrastive loss functions, and appears not to be addressed
by simply scaling up policy networks. Taken together, our study sheds light on
the pivotal role of on-policy sampling in AI alignment, and hints at certain
fundamental challenges of offline alignment algorithms.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÊòØÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∞çÈΩäÁöÑÊ®ôÊ∫ñÊû∂Êßã„ÄÇÁÑ∂ËÄåÔºåÈõ¢Á∑öÂ∞çÈΩäÊºîÁÆóÊ≥ïÊó•ÁõäÊôÆÂèäÔºåÊåëÊà∞‰∫Ü RLHF ‰∏≠Â∞çÁ≠ñÁï•Êé°Ê®£ÁöÑÂøÖË¶ÅÊÄß„ÄÇÂú®ÁçéÂãµÈÅéÂ∫¶ÊúÄ‰Ω≥ÂåñÁöÑËÑàÁµ°‰∏≠ÔºåÊàëÂÄëÂæû‰∏ÄÁµÑÈñãÊîæÁöÑÂØ¶È©óÈñãÂßãÔºåÂ±ïÁ§∫‰∫ÜÂú®Á∑öÊñπÊ≥ïÁõ∏ËºÉÊñºÈõ¢Á∑öÊñπÊ≥ïÁöÑÈ°ØËëóÂÑ™Âã¢„ÄÇÈÄô‰øÉ‰ΩøÊàëÂÄëÈÄèÈÅé‰∏ÄÁ≥ªÂàóÁ≤æÂøÉË®≠Ë®àÁöÑÂØ¶È©óÊ∂àËûçÔºåÊé¢Ë®éÊïàËÉΩÂ∑ÆÁï∞ÁöÑÂéüÂõ†„ÄÇÊàëÂÄëÁ∂ìÈ©óÊÄßÂú∞Ë≠âÊòéÔºåË´∏Â¶ÇÈõ¢Á∑öË≥áÊñôË¶ÜËìãÁéáÂíåË≥áÊñôÂìÅË≥™Á≠âÂÅáË®≠Êú¨Ë∫´ÁÑ°Ê≥ï‰ª§‰∫∫‰ø°ÊúçÂú∞Ëß£ÈáãÊïàËÉΩÂ∑ÆÁï∞„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåÂÑòÁÆ°Èõ¢Á∑öÊºîÁÆóÊ≥ïÊúÉË®ìÁ∑¥Á≠ñÁï•‰ª•ÊìÖÈï∑ÊàêÂ∞çÂàÜÈ°ûÔºå‰ΩÜÂÆÉÂú®ÁîüÊàêÊñπÈù¢ËºÉÂ∑ÆÔºõËàáÊ≠§ÂêåÊôÇÔºåÁî±Âú®Á∑öÊºîÁÆóÊ≥ïË®ìÁ∑¥ÁöÑÁ≠ñÁï•ÊìÖÈï∑ÁîüÊàêÔºå‰ΩÜÂú®ÊàêÂ∞çÂàÜÈ°ûÊñπÈù¢ËºÉÂ∑Æ„ÄÇÈÄôÊöóÁ§∫‰∫ÜÂà§Âà•ËÉΩÂäõÂíåÁîüÊàêËÉΩÂäõ‰πãÈñìÁöÑÁç®Áâπ‰∫§‰∫í‰ΩúÁî®ÔºåÈÄôÊúÉÂèóÂà∞ÊäΩÊ®£ÈÅéÁ®ãÁöÑÊ•µÂ§ßÂΩ±Èüø„ÄÇÊúÄÂæåÔºåÊàëÂÄëËßÄÂØüÂà∞ÔºåÊïàËÉΩÂ∑ÆÁï∞Â∞çÊñºÂ∞çÊØîÂíåÈùûÂ∞çÊØîÊêçÂ§±ÂáΩÊï∏ÁöÜÊåÅÁ∫åÂ≠òÂú®ÔºåËÄå‰∏î‰ºº‰πéÁÑ°Ê≥ïÈÄèÈÅéÂñÆÁ¥îÊì¥ÂÖÖÁ≠ñÁï•Á∂≤Ë∑Ø‰æÜËß£Ê±∫„ÄÇÁ∂úÂêàËÄåË®ÄÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Èó°Êòé‰∫ÜÁ≠ñÁï•Êé°Ê®£Âú® AI Â∞çÈΩä‰∏≠ÁöÑÈóúÈçµ‰ΩúÁî®Ôºå‰∏¶ÊöóÁ§∫‰∫ÜÈõ¢Á∑öÂ∞çÈΩäÊºîÁÆóÊ≥ïÁöÑÊüê‰∫õÂü∫Êú¨ÊåëÊà∞„ÄÇ

##### **Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline**
2405.08427v1 by Yuanchen Shi, Biao Ma, Fang Kong

Stickers are increasingly used in social media to express sentiment and
intent. When finding typing troublesome, people often use a sticker instead.
Despite the significant impact of stickers on sentiment analysis and intent
recognition, little research has been conducted. To address this gap, we
propose a new task: Multimodal chat Sentiment Analysis and Intent Recognition
involving Stickers (MSAIRS). Additionally, we introduce a novel multimodal
dataset containing Chinese chat records and stickers excerpted from several
mainstream social media platforms. Our dataset includes paired data with the
same text but different stickers, and various stickers consisting of the same
images with different texts, allowing us to better understand the impact of
stickers on chat sentiment and intent. We also propose an effective multimodal
joint model, MMSAIR, for our task, which is validated on our datasets and
indicates that visual information of stickers counts. Our dataset and code will
be publicly available.

ÊëòË¶ÅÔºöË≤ºÂúñÂú®Á§æÁæ§Â™íÈ´î‰∏äÊó•ÁõäË¢´Áî®‰æÜË°®ÈÅîÊÉÖÁ∑íÂíåÊÑèÂúñ„ÄÇÁï∂‰∫∫ÂÄëË¶∫ÂæóËº∏ÂÖ•ÊñáÂ≠óÂæàÈ∫ªÁÖ©ÊôÇÔºå‰ªñÂÄëÈÄöÂ∏∏ÊúÉ‰ΩøÁî®Ë≤ºÂúñ‰ª£Êõø„ÄÇÂÑòÁÆ°Ë≤ºÂúñÂ∞çÊÉÖÁ∑íÂàÜÊûêÂíåÊÑèÂúñËæ®Ë≠òÊúâÈ°ØËëóÁöÑÂΩ±ÈüøÔºå‰ΩÜÁõ∏ÈóúÁöÑÁ†îÁ©∂ÂçªÂæàÂ∞ë„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑ‰ªªÂãôÔºöÂåÖÂê´Ë≤ºÂúñÁöÑÂ§öÊ®°ÊÖãËÅäÂ§©ÊÉÖÁ∑íÂàÜÊûêÂíåÊÑèÂúñËæ®Ë≠òÔºàMSAIRSÔºâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂ§öÊ®°ÊÖãË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂæûÂπæÂÄã‰∏ªÊµÅÁ§æÁæ§Â™íÈ´îÂπ≥Âè∞ÊëòÈåÑÁöÑ‰∏≠ÊñáËÅäÂ§©Ë®òÈåÑÂíåË≤ºÂúñ„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÂåÖÊã¨ÂÖ∑ÊúâÁõ∏ÂêåÊñáÂ≠ó‰ΩÜ‰∏çÂêåË≤ºÂúñÁöÑÊàêÂ∞çË≥áÊñôÔºå‰ª•ÂèäÁî±Áõ∏ÂêåÂúñÁâáÂíå‰∏çÂêåÊñáÂ≠óÁµÑÊàêÁöÑÂêÑÁ®ÆË≤ºÂúñÔºåËÆìÊàëÂÄëËÉΩÂ§†Êõ¥Ê∑±ÂÖ•Âú∞‰∫ÜËß£Ë≤ºÂúñÂ∞çËÅäÂ§©ÊÉÖÁ∑íÂíåÊÑèÂúñÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈÇÑÁÇ∫ÊàëÂÄëÁöÑ‰ªªÂãôÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑÂ§öÊ®°ÊÖãËÅØÂêàÊ®°Âûã MMSAIRÔºå‰∏¶Âú®ÊàëÂÄëÁöÑË≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫ÜË©≤Ê®°ÂûãÔºåÁµêÊûúË°®ÊòéË≤ºÂúñÁöÑË¶ñË¶∫Ë≥áË®äÂæàÊúâÁî®„ÄÇÊàëÂÄëÁöÑË≥áÊñôÈõÜÂíåÁ®ãÂºèÁ¢ºÂ∞áÊúÉÂÖ¨Èñã„ÄÇ

##### **Investigating the 'Autoencoder Behavior' in Speech Self-Supervised Models: a focus on HuBERT's Pretraining**
2405.08402v1 by Valentin Vielzeuf

Self-supervised learning has shown great success in Speech Recognition.
However, it has been observed that finetuning all layers of the learned model
leads to lower performance compared to resetting top layers. This phenomenon is
attributed to the ''autoencoder'' behavior: top layers contain information
closer to the input and are less suitable for tasks that require linguistic
information, such as Speech Recognition.To better our understanding of this
behavior, we propose to study the evolution of high-level information within
the model during pretraining. We focus on the HuBERT model, which exhibits a
less pronounced ''autoencoder'' behavior. By experimentally exploring various
factors that may have an impact, we aim to improve the training procedure and
enhance the top layers of HuBERT for high-level tasks.Furthermore, our
experiments demonstrate that these improvements in the training procedure
result in faster convergence and competitive performance on downstream tasks.

ÊëòË¶ÅÔºöËá™Áõ£Áù£Â≠∏ÁøíÂú®Ë™ûÈü≥Ëæ®Ë≠ò‰∏äÂ∑≤Â±ïÁèæÊ•µ‰Ω≥ÊàêÊïà„ÄÇ
ÁÑ∂ËÄåÔºåÂ∑≤ËßÄÂØüÂà∞ÂæÆË™øÂ≠∏ÁøíÊ®°ÂûãÁöÑÊâÄÊúâÂ±§Á¥ö
ËàáÈáçË®≠È†ÇÂ±§Áõ∏ÊØîÔºåÊúÉÂ∞éËá¥ËºÉ‰ΩéÁöÑÊïàËÉΩ„ÄÇÈÄôÁ®ÆÁèæË±°
Ê≠∏Âõ†Êñº„ÄåËá™ÂãïÁ∑®Á¢ºÂô®„ÄçË°åÁÇ∫ÔºöÈ†ÇÂ±§ÂåÖÂê´Êõ¥Êé•ËøëËº∏ÂÖ•ÁöÑË≥áË®äÔºåËºÉ‰∏çÈÅ©ÂêàÊñºÈúÄË¶ÅË™ûË®ÄË≥áË®äÁöÑ‰ªªÂãôÔºå‰æãÂ¶ÇË™ûÈü≥Ëæ®Ë≠ò„ÄÇÁÇ∫‰∫ÜÊõ¥‰∫ÜËß£ÈÄôÁ®Æ
Ë°åÁÇ∫ÔºåÊàëÂÄëÊèêË≠∞Á†îÁ©∂È†êË®ìÁ∑¥ÊúüÈñìÊ®°ÂûãÂÖßÈÉ®È´òÈöéË≥áË®äÁöÑÊºîÂåñ„ÄÇÊàëÂÄëÂ∞àÊ≥®Êñº HuBERT Ê®°ÂûãÔºåÂÆÉË°®ÁèæÂá∫ËºÉ‰∏çÈ°ØËëóÁöÑ„ÄåËá™ÂãïÁ∑®Á¢ºÂô®„ÄçË°åÁÇ∫„ÄÇÈÄèÈÅéÂØ¶È©óÊé¢Ë®éÂèØËÉΩÁî¢ÁîüÂΩ±ÈüøÁöÑÂêÑÁ®ÆÂõ†Á¥†ÔºåÊàëÂÄëÊó®Âú®ÊîπÂñÑË®ìÁ∑¥Á®ãÂ∫èÔºå‰∏¶Â¢ûÂº∑ HuBERT È†ÇÂ±§‰ª•Âü∑Ë°åÈ´òÈöé‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑ
ÂØ¶È©óË≠âÊòéÔºåË®ìÁ∑¥Á®ãÂ∫èÁöÑÈÄô‰∫õÊîπÈÄ≤ÊúÉÂ∞éËá¥‰∏ãÊ∏∏‰ªªÂãôÁöÑÊî∂ÊñÇÈÄüÂ∫¶Âä†Âø´Ôºå‰∏îÊïàËÉΩÂÖ∑Á´∂Áà≠Âäõ„ÄÇ

##### **Stylometric Watermarks for Large Language Models**
2405.08400v1 by Georg Niess, Roman Kern

The rapid advancement of large language models (LLMs) has made it
increasingly difficult to distinguish between text written by humans and
machines. Addressing this, we propose a novel method for generating watermarks
that strategically alters token probabilities during generation. Unlike
previous works, this method uniquely employs linguistic features such as
stylometry. Concretely, we introduce acrostica and sensorimotor norms to LLMs.
Further, these features are parameterized by a key, which is updated every
sentence. To compute this key, we use semantic zero shot classification, which
enhances resilience. In our evaluation, we find that for three or more
sentences, our method achieves a false positive and false negative rate of
0.02. For the case of a cyclic translation attack, we observe similar results
for seven or more sentences. This research is of particular of interest for
proprietary LLMs to facilitate accountability and prevent societal harm.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÈÄ≤Ê≠•‰ΩøÂæóÂçÄÂàÜ‰∫∫È°ûÂíåÊ©üÂô®Á∑®ÂØ´ÁöÑÊñáÊú¨ËÆäÂæóË∂ä‰æÜË∂äÂõ∞Èõ£„ÄÇÈáùÂ∞çÊ≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁîüÊàêÊ∞¥Âç∞ÁöÑÊñ∞ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂú®ÁîüÊàêÈÅéÁ®ã‰∏≠Á≠ñÁï•ÊÄßÂú∞ÊîπËÆäË©ûÂΩôÊ©üÁéá„ÄÇËàáÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊ≠§ÊñπÊ≥ïÁç®ÁâπÂú∞Êé°Áî®‰∫ÜË™ûË®ÄÂ≠∏ÁâπÂæµÔºå‰æãÂ¶ÇÊñáÈ´îÊ∏¨ÈáèÂ≠∏„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂ∞áÈ¶ñÂ≠óÊØçÁ∏ÆÂØ´ÂíåÊÑüË¶∫ÈÅãÂãïË¶èÁØÑÂºïÂÖ• LLM„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÁâπÂæµÁî±‰∏ÄÂÄãÈáëÈë∞ÂèÉÊï∏ÂåñÔºåË©≤ÈáëÈë∞ÊØèÂè•Ë©±ÈÉΩÊúÉÊõ¥Êñ∞„ÄÇÁÇ∫‰∫ÜË®àÁÆóÈÄôÂÄãÈáëÈë∞ÔºåÊàëÂÄë‰ΩøÁî®Ë™ûÁæ©Èõ∂Ê¨°ÂàÜÈ°ûÔºåÈÄôÂ¢ûÂº∑‰∫ÜÈüåÊÄß„ÄÇÂú®ÊàëÂÄëÁöÑË©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁôºÁèæÂ∞çÊñº‰∏âÂÄãÊàñÊõ¥Â§öÂè•Â≠êÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶Áèæ‰∫Ü 0.02 ÁöÑÂÅΩÈôΩÊÄßÂíåÂÅΩÈô∞ÊÄßÁéá„ÄÇÂ∞çÊñºÂæ™Áí∞ÁøªË≠ØÊîªÊìäÁöÑÊÉÖÊ≥ÅÔºåÊàëÂÄëËßÄÂØüÂà∞Â∞çÊñº‰∏ÉÂÄãÊàñÊõ¥Â§öÂè•Â≠êÊúâÈ°û‰ººÁöÑÁµêÊûú„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â∞çÊñºÂ∞àÊúâ LLM ÁâπÂà•ÊúâÊÑèÁæ©Ôºå‰ª•‰øÉÈÄ≤ÂïèË≤¨Âà∂‰∏¶Èò≤Ê≠¢Á§æÊúÉÂç±ÂÆ≥„ÄÇ

##### **CIER: A Novel Experience Replay Approach with Causal Inference in Deep Reinforcement Learning**
2405.08380v1 by Jingwen Wang, Dehui Du, Yida Li, Yiyang Li, Yikang Chen

In the training process of Deep Reinforcement Learning (DRL), agents require
repetitive interactions with the environment. With an increase in training
volume and model complexity, it is still a challenging problem to enhance data
utilization and explainability of DRL training. This paper addresses these
challenges by focusing on the temporal correlations within the time dimension
of time series. We propose a novel approach to segment multivariate time series
into meaningful subsequences and represent the time series based on these
subsequences. Furthermore, the subsequences are employed for causal inference
to identify fundamental causal factors that significantly impact training
outcomes. We design a module to provide feedback on the causality during DRL
training. Several experiments demonstrate the feasibility of our approach in
common environments, confirming its ability to enhance the effectiveness of DRL
training and impart a certain level of explainability to the training process.
Additionally, we extended our approach with priority experience replay
algorithm, and experimental results demonstrate the continued effectiveness of
our approach.

ÊëòË¶ÅÔºöÂú®Ê∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (DRL) ÁöÑË®ìÁ∑¥ÈÅéÁ®ã‰∏≠Ôºå‰ª£ÁêÜ‰∫∫ÈúÄË¶ÅËàáÁí∞Â¢ÉÈÄ≤Ë°åÈáçË§áÁöÑ‰∫íÂãï„ÄÇÈö®ËëóË®ìÁ∑¥ÈáèÂíåÊ®°ÂûãË§áÈõúÊÄßÁöÑÂ¢ûÂä†ÔºåÂ¢ûÂº∑Ë≥áÊñôÂà©Áî®ÁéáÂíå DRL Ë®ìÁ∑¥ÁöÑÂèØËß£ÈáãÊÄß‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂïèÈ°å„ÄÇÊú¨ÊñáÈÄèÈÅéÂ∞àÊ≥®ÊñºÊôÇÈñìÂ∫èÂàóÊôÇÈñìÁ∂≠Â∫¶ÂÖßÁöÑÊôÇÈñìÁõ∏ÈóúÊÄß‰æÜËß£Ê±∫ÈÄô‰∫õÊåëÊà∞„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂ∞áÂ§öËÆäÈáèÊôÇÈñìÂ∫èÂàóÂàÜÂâ≤ÊàêÊúâÊÑèÁæ©ÁöÑÂ≠êÂ∫èÂàóÔºå‰∏¶Ê†πÊìöÈÄô‰∫õÂ≠êÂ∫èÂàó‰æÜË°®Á§∫ÊôÇÈñìÂ∫èÂàó„ÄÇÊ≠§Â§ñÔºåÈÄô‰∫õÂ≠êÂ∫èÂàóË¢´Áî®ÊñºÂõ†ÊûúÊé®Ë´ñÔºå‰ª•Ë≠òÂà•È°ØËëóÂΩ±ÈüøË®ìÁ∑¥ÁµêÊûúÁöÑÂü∫Êú¨Âõ†ÊûúÂõ†Á¥†„ÄÇÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ®°ÁµÑÔºåÂú® DRL Ë®ìÁ∑¥ÊúüÈñìÊèê‰æõÈóúÊñºÂõ†ÊûúÈóú‰øÇÁöÑÂõûÈ•ã„ÄÇÂ§öÈ†ÖÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®‰∏ÄËà¨Áí∞Â¢É‰∏≠ÁöÑÂèØË°åÊÄßÔºåË≠âÂØ¶‰∫ÜÂÆÉÂ¢ûÂº∑ DRL Ë®ìÁ∑¥ÊïàÊûú‰∏¶Ë≥¶‰∫àË®ìÁ∑¥ÈÅéÁ®ã‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑÂèØËß£ÈáãÊÄßÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®ÂÑ™ÂÖàÁ∂ìÈ©óÂõûÊîæÊºîÁÆóÊ≥ïÊì¥Â±ï‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåËÄåÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÊåÅÁ∫åÊúâÊïàÊÄß„ÄÇ

##### **PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles**
2405.08373v1 by Satya Kesav Gundabathula, Sriram R Kolar

This paper describes our approach to the MEDIQA-CORR shared task, which
involves error detection and correction in clinical notes curated by medical
professionals. This task involves handling three subtasks: detecting the
presence of errors, identifying the specific sentence containing the error, and
correcting it. Through our work, we aim to assess the capabilities of Large
Language Models (LLMs) trained on a vast corpora of internet data that contain
both factual and unreliable information. We propose to comprehensively address
all subtasks together, and suggest employing a unique prompt-based in-context
learning strategy. We will evaluate its efficacy in this specialized task
demanding a combination of general reasoning and medical knowledge. In medical
systems where prediction errors can have grave consequences, we propose
leveraging self-consistency and ensemble methods to enhance error correction
and error detection performance.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèèËø∞‰∫ÜÊàëÂÄëÂ∞ç MEDIQA-CORR ÂÖ±‰∫´‰ªªÂãôÁöÑÊñπÊ≥ïÔºåÂÖ∂‰∏≠ÂåÖÊã¨Áî±ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°Á≠ñÂäÉÁöÑËá®Â∫äÁ≠ÜË®ò‰∏≠ÁöÑÈåØË™§ÂÅµÊ∏¨ÂíåÊõ¥Ê≠£„ÄÇÊ≠§‰ªªÂãôÊ∂âÂèäËôïÁêÜ‰∏âÂÄãÂ≠ê‰ªªÂãôÔºöÂÅµÊ∏¨ÈåØË™§ÁöÑÂ≠òÂú®„ÄÅË≠òÂà•ÂåÖÂê´ÈåØË™§ÁöÑÁâπÂÆöÂè•Â≠êÔºå‰ª•ÂèäÊõ¥Ê≠£ÈåØË™§„ÄÇÈÄèÈÅéÊàëÂÄëÁöÑÂä™ÂäõÔºåÊàëÂÄëÊó®Âú®Ë©ï‰º∞Âú®ÂåÖÂê´‰∫ãÂØ¶Âíå‰∏çÂèØÈù†Ë≥áË®äÁöÑÈæêÂ§ßÁ∂≤Ë∑ØË≥áÊñôË™ûÊñôÂ∫´‰∏äË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂª∫Ë≠∞ÂÖ®Èù¢ËôïÁêÜÊâÄÊúâÂ≠ê‰ªªÂãôÔºå‰∏¶Âª∫Ë≠∞Êé°Áî®Áç®ÁâπÁöÑÂü∫ÊñºÊèêÁ§∫ÁöÑËÑàÁµ°‰∏≠Â≠∏ÁøíÁ≠ñÁï•„ÄÇÊàëÂÄëÂ∞áË©ï‰º∞ÂÖ∂Âú®ÈÄôÂÄãÈúÄË¶ÅÁµêÂêà‰∏ÄËà¨Êé®ÁêÜÂíåÈÜ´ÁôÇÁü•Ë≠òÁöÑÂ∞àÈñÄ‰ªªÂãô‰∏≠ÁöÑÂäüÊïà„ÄÇÂú®È†êÊ∏¨ÈåØË™§ÂèØËÉΩÈÄ†ÊàêÂö¥ÈáçÂæåÊûúÁöÑÈÜ´ÁôÇÁ≥ªÁµ±‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Âà©Áî®Ëá™Êàë‰∏ÄËá¥ÊÄßÂíåÊï¥È´îÊñπÊ≥ï‰æÜÂ¢ûÂº∑ÈåØË™§Êõ¥Ê≠£ÂíåÈåØË™§ÂÅµÊ∏¨ÊïàËÉΩ„ÄÇ

##### **Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark**
2405.08355v1 by Mengsong Wu, Tong Zhu, Han Han, Chuanyuan Tan, Xiang Zhang, Wenliang Chen

This paper presents a new tool learning dataset Seal-Tools, which contains
self-instruct API-like tools. Seal-Tools not only offers a large number of
tools, but also includes instances which demonstrate the practical application
of tools. Seeking to generate data on a large scale while ensuring reliability,
we propose a self-instruct method to generate tools and instances, allowing
precise control over the process. Moreover, our Seal-Tools contains hard
instances that call multiple tools to complete the job, among which some are
nested tool callings. For precise and comprehensive evaluation, we use strict
format control and design three metrics from different dimensions. Therefore,
Seal-Tools can serve as a new benchmark to evaluate the tool-calling ability of
LLMs. Finally, we evaluate several prevalent LLMs and our finetuned model on
Seal-Tools. The results show that current systems are far from perfect. The
code, data and experiment results are available at
https://github.com/fairyshine/Seal-Tools .

ÊëòË¶ÅÔºöÈÄôÁØáË´ñÊñáÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂ∑•ÂÖ∑Â≠∏ÁøíË≥áÊñôÈõÜ Seal-ToolsÔºåÂÖ∂‰∏≠ÂåÖÂê´
Ëá™Â≠∏ API ÂûãÂ∑•ÂÖ∑„ÄÇSeal-Tools ‰∏çÂÉÖÊèê‰æõÂ§ßÈáèÁöÑ
Â∑•ÂÖ∑ÔºåÈÇÑÂåÖÊã¨Â±ïÁ§∫Â∑•ÂÖ∑ÂØ¶ÈöõÊáâÁî®ÁØÑ‰æãÁöÑÂØ¶‰æã„ÄÇÁÇ∫‰∫ÜÂú®Á¢∫‰øùÂèØÈù†ÊÄßÁöÑÂêåÊôÇÂ§ßË¶èÊ®°Áî¢ÁîüË≥áÊñôÔºå
ÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãËá™Â≠∏ÊñπÊ≥ï‰æÜÁî¢ÁîüÂ∑•ÂÖ∑ÂíåÂØ¶‰æãÔºå‰∏¶Á≤æÁ¢∫ÊéßÂà∂ÈÄôÂÄãÈÅéÁ®ã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑ Seal-Tools ÂåÖÂê´ÈúÄË¶ÅÂëºÂè´Â§öÂÄãÂ∑•ÂÖ∑ÊâçËÉΩÂÆåÊàêÂ∑•‰ΩúÁöÑÂõ∞Èõ£ÂØ¶‰æãÔºåÂÖ∂‰∏≠‰∏Ä‰∫õÊòØ
Â∑¢ÁãÄÂ∑•ÂÖ∑ÂëºÂè´„ÄÇÁÇ∫‰∫ÜÁ≤æÁ¢∫‰∏îÂÖ®Èù¢ÁöÑË©ï‰º∞ÔºåÊàëÂÄë‰ΩøÁî®Âö¥Ê†ºÁöÑ
Ê†ºÂºèÊéßÂà∂‰∏¶Âæû‰∏çÂêåÈù¢ÂêëË®≠Ë®à‰∏âÂÄãÊåáÊ®ô„ÄÇÂõ†Ê≠§Ôºå
Seal-Tools ÂèØ‰ª•‰ΩúÁÇ∫Ë©ï‰º∞ LLM Â∑•ÂÖ∑ÂëºÂè´ËÉΩÂäõÁöÑÊñ∞Âü∫Ê∫ñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÂπæÂÄãÊµÅË°åÁöÑ LLM ÂíåÊàëÂÄëÂú®
Seal-Tools ‰∏äÂæÆË™øÁöÑÊ®°Âûã„ÄÇÁµêÊûúÈ°ØÁ§∫ÁõÆÂâçÁöÑÁ≥ªÁµ±ÈÅ†Êú™ÂÆåÁæé„ÄÇÁ®ãÂºèÁ¢º„ÄÅË≥áÊñôÂíåÂØ¶È©óÁµêÊûúÂèØÂú®
https://github.com/fairyshine/Seal-Tools Áç≤Âæó„ÄÇ

##### **Perivascular space Identification Nnunet for Generalised Usage (PINGU)**
2405.08337v1 by Benjamin Sinclair, Lucy Vivash, Jasmine Moses, Miranda Lynch, William Pham, Karina Dorfmann, Cassandra Marotta, Shaun Koh, Jacob Bunyamin, Ella Rowsthorn, Alex Jarema, Himashi Peiris, Zhaolin Chen, Sandy R Shultz, David K Wright, Dexiao Kong, Sharon L. Naismith, Terence J. OBrien, Meng Law

Perivascular spaces(PVSs) form a central component of the brain\'s waste
clearance system, the glymphatic system. These structures are visible on MRI
images, and their morphology is associated with aging and neurological disease.
Manual quantification of PVS is time consuming and subjective. Numerous deep
learning methods for PVS segmentation have been developed, however the majority
have been developed and evaluated on homogenous datasets and high resolution
scans, perhaps limiting their applicability for the wide range of image
qualities acquired in clinic and research. In this work we train a nnUNet, a
top-performing biomedical image segmentation algorithm, on a heterogenous
training sample of manually segmented MRI images of a range of different
qualities and resolutions from 6 different datasets. These are compared to
publicly available deep learning methods for 3D segmentation of PVS. The
resulting model, PINGU (Perivascular space Identification Nnunet for
Generalised Usage), achieved voxel and cluster level dice scores of
0.50(SD=0.15), 0.63(0.17) in the white matter(WM), and 0.54(0.11), 0.66(0.17)
in the basal ganglia(BG). Performance on data from unseen sites was
substantially lower for both PINGU(0.20-0.38(WM, voxel), 0.29-0.58(WM,
cluster), 0.22-0.36(BG, voxel), 0.46-0.60(BG, cluster)) and the publicly
available algorithms(0.18-0.30(WM, voxel), 0.29-0.38(WM cluster), 0.10-0.20(BG,
voxel), 0.15-0.37(BG, cluster)), but PINGU strongly outperformed the publicly
available algorithms, particularly in the BG. Finally, training PINGU on manual
segmentations from a single site with homogenous scan properties gave
marginally lower performances on internal cross-validation, but in some cases
gave higher performance on external validation. PINGU stands out as broad-use
PVS segmentation tool, with particular strength in the BG, an area of PVS
related to vascular disease and pathology.

ÊëòË¶ÅÔºö<paragraph>Ë°ÄÁÆ°Âë®ÂúçÁ©∫Èñì (PVS) ÊòØÂ§ßËÖ¶Âª¢Áâ©Ê∏ÖÈô§Á≥ªÁµ±ÔºàÂç≥Ê∑ãÂ∑¥Á≥ªÁµ±ÔºâÁöÑÊ†∏ÂøÉÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈÄô‰∫õÁµêÊßãÂú® MRI ÂΩ±ÂÉè‰∏≠ÂèØË¶ãÔºåÂÖ∂ÂΩ¢ÊÖãËàáËÄÅÂåñÂíåÁ•ûÁ∂ìÁñæÁóÖÁõ∏Èóú„ÄÇ‰∫∫Â∑•ÈáèÂåñ PVS ËÄóÊôÇ‰∏î‰∏ªËßÄ„ÄÇÂ∑≤Á∂ìÈñãÁôºÂá∫Ë®±Â§öÁî®Êñº PVS ÂàÜÂâ≤ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÊñπÊ≥ïÈÉΩÊòØÂú®ÂêåË≥™Êï∏ÊìöÈõÜÂíåÈ´òËß£ÊûêÂ∫¶ÊéÉÊèè‰∏äÈñãÁôºÂíåË©ï‰º∞ÁöÑÔºåÈÄôÂèØËÉΩÊúÉÈôêÂà∂ÂÖ∂Âú®Ëá®Â∫ä‰∏äÂíåÁ†îÁ©∂‰∏≠Áç≤ÂèñÁöÑÂêÑÁ®ÆÂΩ±ÂÉèÂìÅË≥™ÁöÑÈÅ©Áî®ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁï∞Ë≥™ÁöÑÊâãÂ∑•ÂàÜÂâ≤ MRI ÂΩ±ÂÉèË®ìÁ∑¥Ê®£Êú¨‰∏äË®ìÁ∑¥‰∫Ü‰∏ÄÂÄã nnUNetÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊïàËÉΩÊúÄ‰Ω≥ÁöÑÁîüÁâ©ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÊºîÁÆóÊ≥ïÔºåË©≤Ê®£Êú¨ÂåÖÂê´‰æÜËá™ 6 ÂÄã‰∏çÂêåÊï∏ÊìöÈõÜÁöÑÂêÑÁ®Æ‰∏çÂêåÂìÅË≥™ÂíåËß£ÊûêÂ∫¶ÁöÑÂΩ±ÂÉè„ÄÇÈÄô‰∫õÂΩ±ÂÉèËàáÁî®Êñº PVS 3D ÂàÜÂâ≤ÁöÑÂÖ¨ÈñãÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÁî¢ÁîüÁöÑÊ®°Âûã PINGUÔºàÂª£Ê≥õ‰ΩøÁî®Ë°ÄÁÆ°Âë®ÂúçÁ©∫ÈñìË≠òÂà• NnunetÔºâÂú®ÁôΩË≥™ (WM) ‰∏≠ÈÅîÂà∞È´îÁ¥†ÂíåÂè¢ÈõÜÂ±§Á¥öÁöÑÈ™∞Â≠êÂàÜÊï∏ÁÇ∫ 0.50(SD=0.15)„ÄÅ0.63(0.17)ÔºåÂú®Âü∫Â∫ïÁ•ûÁ∂ìÁØÄ (BG) ‰∏≠ÈÅîÂà∞ 0.54(0.11)„ÄÅ0.66(0.17)„ÄÇÂ∞çÊñº‰æÜËá™Êú™Ë¶ãÈÅéÂ†¥ÂüüÁöÑË≥áÊñôÔºåPINGU(0.20-0.38(WMÔºåÈ´îÁ¥†)„ÄÅ0.29-0.58(WMÔºåÂè¢ÈõÜ)„ÄÅ0.22-0.36(BGÔºåÈ´îÁ¥†)„ÄÅ0.46-0.60(BGÔºåÂè¢ÈõÜ)) ÂíåÂÖ¨ÈñãÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ï(0.18-0.30(WMÔºåÈ´îÁ¥†)„ÄÅ0.29-0.38(WM Âè¢ÈõÜ)„ÄÅ0.10-0.20(BGÔºåÈ´îÁ¥†)„ÄÅ0.15-0.37(BGÔºåÂè¢ÈõÜ)) ÁöÑÊïàËÉΩÂ§ßÂπÖÈôç‰ΩéÔºå‰ΩÜ PINGU ÊòéÈ°ØÂÑ™ÊñºÂÖ¨ÈñãÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºåÁâπÂà•ÊòØÂú® BG ‰∏≠„ÄÇÊúÄÂæåÔºåÂú®ÂÖ∑ÊúâÂêåË≥™ÊéÉÊèèÁâπÊÄßÁöÑÂñÆ‰∏ÄÂ†¥ÂüüÁöÑÊâãÂ∑•ÂàÜÂâ≤‰∏äË®ìÁ∑¥ PINGU Âú®ÂÖßÈÉ®‰∫§ÂèâÈ©óË≠â‰∏≠Ë°®ÁèæÂá∫Áï•‰ΩéÁöÑÊïàËÉΩÔºå‰ΩÜÂú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÂú®Â§ñÈÉ®È©óË≠â‰∏≠Ë°®ÁèæÂá∫Êõ¥È´òÁöÑÊïàËÉΩ„ÄÇPINGU ËÑ´Á©éËÄåÂá∫ÔºåÊàêÁÇ∫Âª£Ê≥õ‰ΩøÁî®ÁöÑ PVS ÂàÜÂâ≤Â∑•ÂÖ∑ÔºåÁâπÂà•ÊòØÂú®ËàáË°ÄÁÆ°ÁñæÁóÖÂíåÁóÖÁêÜÁõ∏ÈóúÁöÑ PVS ÂçÄÂüüÔºåÂç≥ BG ‰∏≠„ÄÇ</paragraph>

##### **Could Chemical LLMs benefit from Message Passing**
2405.08334v1 by Jiaqing Xie, Ziheng Chi

Pretrained language models (LMs) showcase significant capabilities in
processing molecular text, while concurrently, message passing neural networks
(MPNNs) demonstrate resilience and versatility in the domain of molecular
science. Despite these advancements, we find there are limited studies
investigating the bidirectional interactions between molecular structures and
their corresponding textual representations. Therefore, in this paper, we
propose two strategies to evaluate whether an information integration can
enhance the performance: contrast learning, which involves utilizing an MPNN to
supervise the training of the LM, and fusion, which exploits information from
both models. Our empirical analysis reveals that the integration approaches
exhibit superior performance compared to baselines when applied to smaller
molecular graphs, while these integration approaches do not yield performance
enhancements on large scale graphs.

ÊëòË¶ÅÔºöÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°Âûã (LM) Âú®ËôïÁêÜÂàÜÂ≠êÊñáÊú¨ÊñπÈù¢Â±ïÁ§∫Âá∫È°ØËëóÁöÑËÉΩÂäõÔºåÂêåÊôÇÔºåË®äÊÅØÂÇ≥ÈÅûÁ•ûÁ∂ìÁ∂≤Ë∑Ø (MPNN) Âú®ÂàÜÂ≠êÁßëÂ≠∏È†òÂüü‰∏≠Â±ïÁèæÂá∫ÈüåÊÄßÂíåÂ§öÂäüËÉΩÊÄß„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÊàëÂÄëÁôºÁèæÊé¢Ë®éÂàÜÂ≠êÁµêÊßãËàáÂÖ∂Â∞çÊáâÊñáÊú¨Ë°®Á§∫‰πãÈñìÈõôÂêë‰∫§‰∫í‰ΩúÁî®ÁöÑÁ†îÁ©∂ÊúâÈôê„ÄÇÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÂÖ©Á®ÆÁ≠ñÁï•‰æÜË©ï‰º∞Ë≥áË®äÊï¥ÂêàÊòØÂê¶ËÉΩÊèêÂçáÊïàËÉΩÔºöÂ∞çÊØîÂ≠∏ÁøíÔºåÊ∂âÂèäÂà©Áî® MPNN Áõ£Áù£ LM ÁöÑË®ìÁ∑¥Ôºå‰ª•ÂèäËûçÂêàÔºåÂà©Áî®‰æÜËá™ÂÖ©ÂÄãÊ®°ÂûãÁöÑË≥áË®ä„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÂàÜÊûêÈ°ØÁ§∫ÔºåËàáÊáâÁî®ÊñºËºÉÂ∞èÂàÜÂ≠êÂúñÂΩ¢ÁöÑÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÊï¥ÂêàÊñπÊ≥ïÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåËÄåÈÄô‰∫õÊï¥ÂêàÊñπÊ≥ï‰∏¶Êú™Âú®Â§ßÂûãÂúñÂΩ¢‰∏äÁî¢ÁîüÊïàËÉΩÊèêÂçá„ÄÇ

##### **Cross-Dataset Generalization For Retinal Lesions Segmentation**
2405.08329v1 by Cl√©ment Playout, Farida Cheriet

Identifying lesions in fundus images is an important milestone toward an
automated and interpretable diagnosis of retinal diseases. To support research
in this direction, multiple datasets have been released, proposing groundtruth
maps for different lesions. However, important discrepancies exist between the
annotations and raise the question of generalization across datasets. This
study characterizes several known datasets and compares different techniques
that have been proposed to enhance the generalisation performance of a model,
such as stochastic weight averaging, model soups and ensembles. Our results
provide insights into how to combine coarsely labelled data with a
finely-grained dataset in order to improve the lesions segmentation.

ÊëòË¶ÅÔºöË≠òÂà•ÁúºÂ∫ïÂúñÂÉè‰∏≠ÁöÑÁóÖÁÅ∂ÊòØÈÇÅÂêëËá™ÂãïÂåñ‰∏îÂèØËß£ËÆÄÁöÑË¶ñÁ∂≤ËÜúÁñæÁóÖË®∫Êñ∑ÁöÑÈáçË¶ÅÈáåÁ®ãÁ¢ë„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÊ≠§ÊñπÂêëÁöÑÁ†îÁ©∂ÔºåÂ∑≤Á∂ìÁôºÂ∏ÉÂ§öÂÄãË≥áÊñôÈõÜÔºåÊèêÂá∫‰∫Ü‰∏çÂêåÁóÖÁÅ∂ÁöÑ groundtruth Âú∞Âúñ„ÄÇÁÑ∂ËÄåÔºåË®ªËß£‰πãÈñìÂ≠òÂú®ÈáçÂ§ßÂ∑ÆÁï∞Ôºå‰∏¶ÊèêÂá∫‰∫ÜË∑®Ë≥áÊñôÈõÜÊ¶ÇÂåñÁöÑÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂ÊèèËø∞‰∫ÜÂπæÂÄãÂ∑≤Áü•ÁöÑË≥áÊñôÈõÜÔºå‰∏¶ÊØîËºÉ‰∫ÜÁÇ∫Â¢ûÂº∑Ê®°ÂûãÁöÑÊ¶ÇÂåñÊïàËÉΩËÄåÊèêÂá∫ÁöÑ‰∏çÂêåÊäÄË°ìÔºå‰æãÂ¶ÇÈö®Ê©üÊ¨äÈáçÂπ≥Âùá„ÄÅÊ®°ÂûãÊπØÂíåÂ•ó‰ª∂„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊèê‰æõ‰∫ÜÂ¶Ç‰ΩïÂ∞áÁ≤óÁï•Ê®ôÁ±§ÁöÑË≥áÊñôËàáÁ¥∞Á≤íÂ∫¶Ë≥áÊñôÈõÜÁõ∏ÁµêÂêà‰ª•ÊîπÂñÑÁóÖÁÅ∂ÂàÜÂâ≤ÁöÑË¶ãËß£„ÄÇ

##### **SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models**
2405.08317v1 by Raghuveer Peri, Sai Muralidhar Jayanthi, Srikanth Ronanki, Anshu Bhatia, Karel Mundnich, Saket Dingliwal, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Srikanth Vishnubhotla, Daniel Garcia-Romero, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff

Integrated Speech and Large Language Models (SLMs) that can follow speech
instructions and generate relevant text responses have gained popularity
lately. However, the safety and robustness of these models remains largely
unclear. In this work, we investigate the potential vulnerabilities of such
instruction-following speech-language models to adversarial attacks and
jailbreaking. Specifically, we design algorithms that can generate adversarial
examples to jailbreak SLMs in both white-box and black-box attack settings
without human involvement. Additionally, we propose countermeasures to thwart
such jailbreaking attacks. Our models, trained on dialog data with speech
instructions, achieve state-of-the-art performance on spoken question-answering
task, scoring over 80% on both safety and helpfulness metrics. Despite safety
guardrails, experiments on jailbreaking demonstrate the vulnerability of SLMs
to adversarial perturbations and transfer attacks, with average attack success
rates of 90% and 10% respectively when evaluated on a dataset of carefully
designed harmful questions spanning 12 different toxic categories. However, we
demonstrate that our proposed countermeasures reduce the attack success
significantly.

ÊëòË¶ÅÔºöÊï¥ÂêàË™ûÈü≥ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (SLM)ÔºåËÉΩÈÅµÂæ™Ë™ûÈü≥ÊåáÁ§∫‰∏¶Áî¢ÁîüÁõ∏ÈóúÊñáÂ≠óÂõûÊáâÔºåÊúÄËøëËÆäÂæóÊµÅË°å„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÁöÑÂÆâÂÖ®ÊÄßËàáÂÅ•ÂÖ®ÊÄßÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªç‰∏çÊòéÁ¢∫„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊ≠§È°ûÈÅµÂæ™ÊåáÁ§∫ÁöÑË™ûÈü≥Ë™ûË®ÄÊ®°ÂûãÂ∞çÂ∞çÊäóÊÄßÊîªÊìäÂíåË∂äÁçÑÁöÑÊΩõÂú®ÊºèÊ¥û„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÊºîÁÆóÊ≥ïÔºåÂèØÂú®ÁôΩÁõíÂíåÈªëÁõíÊîªÊìäË®≠ÂÆö‰∏≠Áî¢ÁîüÂ∞çÊäóÊÄßÁØÑ‰æãÔºå‰ª•Ë∂äÁçÑ SLMÔºåËÄåÁÑ°ÈúÄ‰∫∫Â∑•‰ªãÂÖ•„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Â∞çÁ≠ñ‰æÜÈòªÊ≠¢Ê≠§È°ûË∂äÁçÑÊîªÊìä„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂåÖÂê´Ë™ûÈü≥ÊåáÁ§∫ÁöÑÂ∞çË©±Ë≥áÊñô‰∏äË®ìÁ∑¥ÔºåÂú®Âè£Ë™™ÂïèÁ≠î‰ªªÂãô‰∏≠ÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂú®ÂÆâÂÖ®ÊÄßËàáÊúâÁõäÊÄßÊåáÊ®ô‰∏äÂùáÂæóÂàÜË∂ÖÈÅé 80%„ÄÇÂÑòÁÆ°ÊúâÂÆâÂÖ®Èò≤Ë≠∑Êé™ÊñΩÔºå‰ΩÜË∂äÁçÑÂØ¶È©óÈ°ØÁ§∫ SLM Â∞çÂ∞çÊäóÊÄßÊìæÂãïÂíåÂÇ≥Ëº∏ÊîªÊìäÁöÑËÑÜÂº±ÊÄßÔºåÂú®Ë©ï‰º∞Á≤æÂøÉË®≠Ë®àÁöÑÊ∂µËìã 12 Á®Æ‰∏çÂêåÊúâÂÆ≥È°ûÂà•ÁöÑÊúâÂÆ≥ÂïèÈ°åË≥áÊñôÈõÜÊôÇÔºåÂπ≥ÂùáÊîªÊìäÊàêÂäüÁéáÂàÜÂà•ÁÇ∫ 90% Âíå 10%„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÊèêÂá∫ÁöÑÂ∞çÁ≠ñÂ§ßÂπÖÈôç‰Ωé‰∫ÜÊîªÊìäÊàêÂäüÁéá„ÄÇ

##### **A Decoupling and Aggregating Framework for Joint Extraction of Entities and Relations**
2405.08311v1 by Yao Wang, Xin Liu, Weikun Kong, Hai-Tao Yu, Teeradaj Racharak, Kyoung-Sook Kim, Minh Le Nguyen

Named Entity Recognition and Relation Extraction are two crucial and
challenging subtasks in the field of Information Extraction. Despite the
successes achieved by the traditional approaches, fundamental research
questions remain open. First, most recent studies use parameter sharing for a
single subtask or shared features for both two subtasks, ignoring their
semantic differences. Second, information interaction mainly focuses on the two
subtasks, leaving the fine-grained informtion interaction among the
subtask-specific features of encoding subjects, relations, and objects
unexplored. Motivated by the aforementioned limitations, we propose a novel
model to jointly extract entities and relations. The main novelties are as
follows: (1) We propose to decouple the feature encoding process into three
parts, namely encoding subjects, encoding objects, and encoding relations.
Thanks to this, we are able to use fine-grained subtask-specific features. (2)
We propose novel inter-aggregation and intra-aggregation strategies to enhance
the information interaction and construct individual fine-grained
subtask-specific features, respectively. The experimental results demonstrate
that our model outperforms several previous state-of-the-art models. Extensive
additional experiments further confirm the effectiveness of our model.

ÊëòË¶ÅÔºöÂëΩÂêçÂØ¶È´îËæ®Ë≠òËàáÈóú‰øÇËêÉÂèñÊòØË≥áË®äËêÉÂèñÈ†òÂüü‰∏≠ÂÖ©ÂÄãËá≥ÈóúÈáçË¶Å‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂ≠ê‰ªªÂãô„ÄÇÂÑòÁÆ°ÂÇ≥Áµ±ÊñπÊ≥ïÂèñÂæóÊàêÂäüÔºå‰ΩÜÂü∫Êú¨ÁöÑÁ†îÁ©∂ÂïèÈ°å‰ªçÁÑ∂Êá∏ËÄåÊú™Ê±∫„ÄÇÈ¶ñÂÖàÔºåÂ§ßÂ§öÊï∏ÊúÄËøëÁöÑÁ†îÁ©∂‰ΩøÁî®ÂèÉÊï∏ÂÖ±‰∫´‰æÜÂü∑Ë°åÂñÆ‰∏ÄÂ≠ê‰ªªÂãôÊàñÂÖ±‰∫´ÂäüËÉΩ‰æÜÂü∑Ë°åÂÖ©ÂÄãÂ≠ê‰ªªÂãôÔºåÂøΩÁï•‰∫ÜÂÆÉÂÄëÁöÑË™ûÁæ©Â∑ÆÁï∞„ÄÇÂÖ∂Ê¨°ÔºåË≥áË®ä‰∫íÂãï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÂÖ©ÂÄãÂ≠ê‰ªªÂãô‰∏äÔºåÂøΩÁï•‰∫ÜÁ∑®Á¢º‰∏ªË©û„ÄÅÈóú‰øÇÂíåÁâ©‰ª∂ÁöÑÂ≠ê‰ªªÂãôÁâπÂÆöÂäüËÉΩ‰πãÈñìÁöÑÁ¥∞Á≤íÂ∫¶Ë≥áË®ä‰∫íÂãï„ÄÇÂèóÂà∞‰∏äËø∞ÈôêÂà∂ÁöÑÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ®°ÂûãÔºåÁî®ÊñºËÅØÂêàËêÉÂèñÂØ¶È´îÂíåÈóú‰øÇ„ÄÇ‰∏ªË¶ÅÁöÑÂâµÊñ∞Â¶Ç‰∏ãÔºö(1) ÊàëÂÄëÂª∫Ë≠∞Â∞áÁâπÂæµÁ∑®Á¢ºÈÅéÁ®ãËß£ËÄ¶Êàê‰∏âÂÄãÈÉ®ÂàÜÔºåÂç≥Á∑®Á¢º‰∏ªË©û„ÄÅÁ∑®Á¢ºÁâ©‰ª∂ÂíåÁ∑®Á¢ºÈóú‰øÇ„ÄÇÁî±ÊñºÈÄôÊ®£ÔºåÊàëÂÄëÂèØ‰ª•‰ΩøÁî®Á¥∞Á≤íÂ∫¶ÁöÑÂ≠ê‰ªªÂãôÁâπÂÆöÂäüËÉΩ„ÄÇ(2) ÊàëÂÄëÊèêÂá∫Êñ∞Á©éÁöÑ‰∫§‰∫íËÅöÂêàÂíåÂÖßÈÉ®ËÅöÂêàÁ≠ñÁï•ÔºåÂàÜÂà•Â¢ûÂº∑Ë≥áË®ä‰∫íÂãï‰∏¶Âª∫ÊßãÂÄãÂà•ÁöÑÁ¥∞Á≤íÂ∫¶Â≠ê‰ªªÂãôÁâπÂÆöÂäüËÉΩ„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÂπæÂÄãÂÖàÂâçÁöÑÊúÄÂÖàÈÄ≤Ê®°Âûã„ÄÇÂª£Ê≥õÁöÑÈ°çÂ§ñÂØ¶È©óÈÄ≤‰∏ÄÊ≠•Ë≠âÂØ¶‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind**
2405.08304v2 by Iris Oved, Nikhil Krishnaswamy, James Pustejovsky, Joshua Hartshorne

We offer philosophical motivations for a method we call Virtual World
Cognitive Science (VW CogSci), in which researchers use virtual embodied agents
that are embedded in virtual worlds to explore questions in the field of
Cognitive Science. We focus on questions about mental and linguistic
representation and the ways that such computational modeling can add rigor to
philosophical thought experiments, as well as the terminology used in the
scientific study of such representations. We find that this method forces
researchers to take a god's-eye view when describing dynamical relationships
between entities in minds and entities in an environment in a way that
eliminates the need for problematic talk of belief and concept types, such as
the belief that cats are silly, and the concept CAT, while preserving belief
and concept tokens in individual cognizers' minds. We conclude with some
further key advantages of VW CogSci for the scientific study of mental and
linguistic representation and for Cognitive Science more broadly.

ÊëòË¶ÅÔºöÊàëÂÄëÊèê‰æõ‰∏ÄÁ®ÆÊàëÂÄëÁ®±‰πãÁÇ∫ËôõÊì¨‰∏ñÁïåË™çÁü•ÁßëÂ≠∏ (VW CogSci) ÁöÑÊñπÊ≥ïÁöÑÂì≤Â≠∏ÂãïÊ©üÔºåÁ†îÁ©∂‰∫∫Âì°Âú®ÂÖ∂‰∏≠‰ΩøÁî®ÂµåÂÖ•Âú®ËôõÊì¨‰∏ñÁïå‰∏≠ÁöÑËôõÊì¨ÂÖ∑Ë∫´‰ª£ÁêÜÔºå‰ª•Êé¢Á¥¢Ë™çÁü•ÁßëÂ≠∏È†òÂüü‰∏≠ÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÂøÉÊô∫ÂíåË™ûË®ÄË°®ÂæµÁöÑÂïèÈ°åÔºå‰ª•ÂèäÈÄôÁ®ÆË®àÁÆóÂª∫Ê®°Â¶Ç‰ΩïÁÇ∫Âì≤Â≠∏ÊÄùÊÉ≥ÂØ¶È©óÂ¢ûÂä†Âö¥Ë¨πÊÄßÔºå‰ª•ÂèäÁî®ÊñºÊ≠§È°ûË°®ÂæµÁöÑÁßëÂ≠∏Á†îÁ©∂‰∏≠ÁöÑË°ìË™û„ÄÇÊàëÂÄëÁôºÁèæÈÄôÁ®ÆÊñπÊ≥ïËø´‰ΩøÁ†îÁ©∂‰∫∫Âì°Âú®ÊèèËø∞ÂøÉÊô∫‰∏≠ÁöÑÂØ¶È´îËàáÁí∞Â¢É‰∏≠ÁöÑÂØ¶È´î‰πãÈñìÁöÑÂãïÊÖãÈóú‰øÇÊôÇÊé°Âèñ‰∏äÂ∏ùË¶ñËßíÔºåÂæûËÄåÊ∂àÈô§‰∫ÜÂ∞ç‰ø°ÂøµÂíåÊ¶ÇÂøµÈ°ûÂûãÔºà‰æãÂ¶ÇÁõ∏‰ø°Ë≤ìÂæàÂÇªÂíå CAT Ê¶ÇÂøµÔºâÁöÑÊúâÂïèÈ°åÁöÑË®éË´ñÁöÑÈúÄË¶ÅÔºåÂêåÊôÇ‰øùÁïô‰∫ÜÂÄãÂà•Ë™çÁü•ËÄÖÂøÉÊô∫‰∏≠ÁöÑ‰ø°ÂøµÂíåÊ¶ÇÂøµÊ®ôË®ò„ÄÇÊàëÂÄëÊúÄÂæåÁ∏ΩÁµê‰∫Ü VW CogSci Âú®ÂøÉÊô∫ÂíåË™ûË®ÄË°®ÂæµÁöÑÁßëÂ≠∏Á†îÁ©∂‰ª•ÂèäÊõ¥Âª£Ê≥õÁöÑË™çÁü•ÁßëÂ≠∏‰∏≠ÁöÑ‰∏Ä‰∫õÈÄ≤‰∏ÄÊ≠•ÈóúÈçµÂÑ™Âã¢„ÄÇ

##### **Distance-Restricted Explanations: Theoretical Underpinnings & Efficient Implementation**
2405.08297v1 by Yacine Izza, Xuanxiang Huang, Antonio Morgado, Jordi Planes, Alexey Ignatiev, Joao Marques-Silva

The uses of machine learning (ML) have snowballed in recent years. In many
cases, ML models are highly complex, and their operation is beyond the
understanding of human decision-makers. Nevertheless, some uses of ML models
involve high-stakes and safety-critical applications. Explainable artificial
intelligence (XAI) aims to help human decision-makers in understanding the
operation of such complex ML models, thus eliciting trust in their operation.
Unfortunately, the majority of past XAI work is based on informal approaches,
that offer no guarantees of rigor. Unsurprisingly, there exists comprehensive
experimental and theoretical evidence confirming that informal methods of XAI
can provide human-decision makers with erroneous information. Logic-based XAI
represents a rigorous approach to explainability; it is model-based and offers
the strongest guarantees of rigor of computed explanations. However, a
well-known drawback of logic-based XAI is the complexity of logic reasoning,
especially for highly complex ML models. Recent work proposed
distance-restricted explanations, i.e. explanations that are rigorous provided
the distance to a given input is small enough. Distance-restricted
explainability is tightly related with adversarial robustness, and it has been
shown to scale for moderately complex ML models, but the number of inputs still
represents a key limiting factor. This paper investigates novel algorithms for
scaling up the performance of logic-based explainers when computing and
enumerating ML model explanations with a large number of inputs.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí (ML) ÁöÑÁî®ÈÄîÂú®ËøëÂπ¥‰æÜÂ¶ÇÊªæÈõ™ÁêÉËà¨Êì¥Â§ß„ÄÇÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåML Ê®°ÂûãÈùûÂ∏∏Ë§áÈõúÔºåËÄåÂÖ∂ÈÅã‰ΩúË∂Ö‰πé‰∫∫È°ûÊ±∫Á≠ñËÄÖÁöÑÁêÜËß£ÁØÑÂúç„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåML Ê®°ÂûãÁöÑÊüê‰∫õÁî®ÈÄîÊ∂âÂèäÈ´òÈ¢®Èö™ÂíåÂÆâÂÖ®ÈóúÈçµÁöÑÊáâÁî®„ÄÇÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) Êó®Âú®Âπ´Âä©‰∫∫È°ûÊ±∫Á≠ñËÄÖ‰∫ÜËß£Ê≠§È°ûË§áÈõú ML Ê®°ÂûãÁöÑÈÅã‰ΩúÔºåÈÄ≤ËÄåÂºïÁôºÂ∞çÂÖ∂ÈÅã‰ΩúÁöÑ‰ø°‰ªª„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÈÅéÂéªÂ§ßÈÉ®ÂàÜÁöÑ XAI Â∑•‰ΩúÈÉΩÂü∫ÊñºÈùûÊ≠£ÂºèÊñπÊ≥ïÔºåÁÑ°Ê≥ï‰øùË≠âÂö¥Ë¨πÊÄß„ÄÇÊØ´‰∏çÊÑèÂ§ñÂú∞ÔºåÊúâÂÖ®Èù¢ÁöÑÂØ¶È©óÂíåÁêÜË´ñË≠âÊìöË≠âÂØ¶ÔºåÈùûÊ≠£ÂºèÁöÑ XAI ÊñπÊ≥ïÂèØËÉΩÊúÉÁÇ∫‰∫∫È°ûÊ±∫Á≠ñËÄÖÊèê‰æõÈåØË™§ÁöÑË≥áË®ä„ÄÇÂü∫ÊñºÈÇèËºØÁöÑ XAI ‰ª£Ë°®‰∏ÄÁ®ÆÂö¥Ë¨πÁöÑÂèØËß£ÈáãÊÄßÊñπÊ≥ïÔºõÂÆÉÊòØÂü∫ÊñºÊ®°ÂûãÁöÑÔºå‰∏¶Êèê‰æõÁ∂ìÁî±Ë®àÁÆóÂæóÂá∫ÁöÑËß£ÈáãÁöÑÊúÄÂº∑ÊúâÂäõÁöÑÂö¥Ë¨πÊÄß‰øùË≠â„ÄÇÁÑ∂ËÄåÔºåÂü∫ÊñºÈÇèËºØÁöÑ XAI ‰∏ÄÂÄãÁúæÊâÄÂë®Áü•ÁöÑÁº∫ÈªûÊòØÈÇèËºØÊé®ÁêÜÁöÑË§áÈõúÊÄßÔºåÁâπÂà•ÊòØÂ∞çÊñºÈ´òÂ∫¶Ë§áÈõúÁöÑ ML Ê®°Âûã„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫ÜË∑ùÈõ¢ÂèóÈôêÁöÑËß£ÈáãÔºåÂç≥Âè™Ë¶ÅËàáÁµ¶ÂÆöËº∏ÂÖ•ÁöÑË∑ùÈõ¢Â§†Â∞èÔºåÂ∞±ÊòØÂö¥Ë¨πÁöÑËß£Èáã„ÄÇË∑ùÈõ¢ÂèóÈôêÁöÑÂèØËß£ÈáãÊÄßËàáÂ∞çÊäóÈ≠ØÊ£íÊÄßÂØÜÂàáÁõ∏ÈóúÔºå‰∏¶‰∏îÂ∑≤Ë¢´Ë≠âÊòéÂèØ‰ª•Êì¥Â±ïÂà∞‰∏≠Á≠âË§áÈõúÂ∫¶ÁöÑ ML Ê®°ÂûãÔºå‰ΩÜËº∏ÂÖ•Êï∏Èáè‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÈóúÈçµÁöÑÈôêÂà∂Âõ†Á¥†„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÂú®Ë®àÁÆóÂíåÂàóËàâÂÖ∑ÊúâÂ§ßÈáèËº∏ÂÖ•ÁöÑ ML Ê®°ÂûãËß£ÈáãÊôÇÔºåÁî®ÊñºÊì¥Â±ïÂü∫ÊñºÈÇèËºØÁöÑËß£ÈáãÂô®ÁöÑÊïàËÉΩÁöÑÊñ∞ÊºîÁÆóÊ≥ï„ÄÇ

##### **SpeechVerse: A Large-scale Generalizable Audio Language Model**
2405.08295v1 by Nilaksh Das, Saket Dingliwal, Srikanth Ronanki, Rohit Paturi, David Huang, Prashant Mathur, Jie Yuan, Dhanush Bekal, Xing Niu, Sai Muralidhar Jayanthi, Xilai Li, Karel Mundnich, Monica Sunkara, Sundararajan Srinivasan, Kyu J Han, Katrin Kirchhoff

Large language models (LLMs) have shown incredible proficiency in performing
tasks that require semantic understanding of natural language instructions.
Recently, many works have further expanded this capability to perceive
multimodal audio and text inputs, but their capabilities are often limited to
specific fine-tuned tasks such as automatic speech recognition and translation.
We therefore develop SpeechVerse, a robust multi-task training and curriculum
learning framework that combines pre-trained speech and text foundation models
via a small set of learnable parameters, while keeping the pre-trained models
frozen during training. The models are instruction finetuned using continuous
latent representations extracted from the speech foundation model to achieve
optimal zero-shot performance on a diverse range of speech processing tasks
using natural language instructions. We perform extensive benchmarking that
includes comparing our model performance against traditional baselines across
several datasets and tasks. Furthermore, we evaluate the model's capability for
generalized instruction following by testing on out-of-domain datasets, novel
prompts, and unseen tasks. Our empirical experiments reveal that our multi-task
SpeechVerse model is even superior to conventional task-specific baselines on 9
out of the 11 tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Âü∑Ë°åÈúÄË¶ÅÂ∞çËá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§ÈÄ≤Ë°åË™ûÁæ©ÁêÜËß£ÁöÑ‰ªªÂãôÊñπÈù¢Ë°®ÁèæÂá∫‰ª§‰∫∫Èõ£‰ª•ÁΩÆ‰ø°ÁöÑËÉΩÂäõ„ÄÇÊúÄËøëÔºåË®±Â§ö‰ΩúÂìÅÈÄ≤‰∏ÄÊ≠•Êì¥Â±ï‰∫ÜÈÄôÁ®ÆÊÑüÁü•Â§öÊ®°ÊÖãÈü≥Ë®äÂíåÊñáÂ≠óËº∏ÂÖ•ÁöÑËÉΩÂäõÔºå‰ΩÜÂÆÉÂÄëÁöÑËÉΩÂäõÈÄöÂ∏∏ÂÉÖÈôêÊñºÁâπÂÆöÂæÆË™ø‰ªªÂãôÔºå‰æãÂ¶ÇËá™ÂãïË™ûÈü≥Ë≠òÂà•ÂíåÁøªË≠Ø„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü SpeechVerseÔºåÈÄôÊòØ‰∏ÄÂÄãÂº∑Â§ßÁöÑÂ§ö‰ªªÂãôË®ìÁ∑¥ÂíåË™≤Á®ãÂ≠∏ÁøíÊ°ÜÊû∂ÔºåÂÆÉÈÄöÈÅé‰∏ÄÂ∞èÁµÑÂèØÂ≠∏ÁøíÁöÑÂèÉÊï∏Â∞áÈ†êË®ìÁ∑¥ÁöÑË™ûÈü≥ÂíåÊñáÂ≠óÂü∫Á§éÊ®°ÂûãÁµêÂêàËµ∑‰æÜÔºåÂêåÊôÇÂú®Ë®ìÁ∑¥ÊúüÈñì‰øùÊåÅÈ†êË®ìÁ∑¥ÁöÑÊ®°ÂûãÂáçÁµê„ÄÇÈÄô‰∫õÊ®°Âûã‰ΩøÁî®ÂæûË™ûÈü≥Âü∫Á§éÊ®°Âûã‰∏≠ÊèêÂèñÁöÑÈÄ£Á∫åÊΩõÂú®Ë°®Á§∫ÈÄ≤Ë°åÊåá‰ª§ÂæÆË™øÔºå‰ª•Âú®‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄÊåá‰ª§ÁöÑÂêÑÁ®ÆË™ûÈü≥ËôïÁêÜ‰ªªÂãô‰∏≠ÂØ¶ÁèæÊúÄ‰Ω≥Èõ∂Ê¨°Â≠∏ÁøíÊïàËÉΩ„ÄÇÊàëÂÄëÂü∑Ë°åÂª£Ê≥õÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂåÖÊã¨Âú®Â§öÂÄãË≥áÊñôÈõÜÂíå‰ªªÂãô‰∏≠Â∞áÊàëÂÄëÁöÑÊ®°ÂûãÊïàËÉΩËàáÂÇ≥Áµ±Âü∫Ê∫ñÈÄ≤Ë°åÊØîËºÉ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄöÈÅéÂú®È†òÂüüÂ§ñË≥áÊñôÈõÜ„ÄÅÊñ∞ÊèêÁ§∫ÂíåÊú™Ë¶ã‰ªªÂãô‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶‰æÜË©ï‰º∞Ê®°ÂûãÂ∞çÂª£Áæ©Êåá‰ª§ÈÅµÂæ™ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÂ§ö‰ªªÂãô SpeechVerse Ê®°ÂûãÁîöËá≥Âú® 11 È†Ö‰ªªÂãô‰∏≠ÁöÑ 9 È†Ö‰ªªÂãô‰∏≠ÂÑ™ÊñºÂÇ≥Áµ±ÁöÑÁâπÂÆö‰ªªÂãôÂü∫Ê∫ñ„ÄÇ

##### **Detecting Fallacies in Climate Misinformation: A Technocognitive Approach to Identifying Misleading Argumentation**
2405.08254v1 by Francisco Zanartu, John Cook, Markus Wagner, Julian Garcia

Misinformation about climate change is a complex societal issue requiring
holistic, interdisciplinary solutions at the intersection between technology
and psychology. One proposed solution is a "technocognitive" approach,
involving the synthesis of psychological and computer science research.
Psychological research has identified that interventions in response to
misinformation require both fact-based (e.g., factual explanations) and
technique-based (e.g., explanations of misleading techniques) content. However,
little progress has been made on documenting and detecting fallacies in climate
misinformation. In this study, we apply a previously developed critical
thinking methodology for deconstructing climate misinformation, in order to
develop a dataset mapping different types of climate misinformation to
reasoning fallacies. This dataset is used to train a model to detect fallacies
in climate misinformation. Our study shows F1 scores that are 2.5 to 3.5 better
than previous works. The fallacies that are easiest to detect include fake
experts and anecdotal arguments, while fallacies that require background
knowledge, such as oversimplification, misrepresentation, and slothful
induction, are relatively more difficult to detect. This research lays the
groundwork for development of solutions where automatically detected climate
misinformation can be countered with generative technique-based corrections.

ÊëòË¶ÅÔºöÊ∞îÂÄôÂèòËøÅÁöÑÈîôËØØ‰ø°ÊÅØÊòØ‰∏Ä‰∏™Â§çÊùÇÁöÑÁ§æ‰ºöÈóÆÈ¢òÔºåÈúÄË¶ÅÂú®ÊäÄÊúØÂíåÂøÉÁêÜÂ≠¶ÁöÑ‰∫§ÂèâÁÇπ‰∏äÈááÁî®Êï¥‰ΩìÁöÑ„ÄÅË∑®Â≠¶ÁßëÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ‰∏Ä‰∏™Âª∫ËÆÆÁöÑËß£ÂÜ≥ÊñπÊ°àÊòØ‚ÄúÊäÄÊúØËÆ§Áü•‚ÄùÊñπÊ≥ïÔºåÊ∂âÂèäÂøÉÁêÜÂíåËÆ°ÁÆóÊú∫ÁßëÂ≠¶Á†îÁ©∂ÁöÑÁªºÂêà„ÄÇÂøÉÁêÜÁ†îÁ©∂Â∑≤ÁªèÂèëÁé∞ÔºåÈíàÂØπÈîôËØØ‰ø°ÊÅØÁöÑÂπ≤È¢ÑÊé™ÊñΩÈúÄË¶ÅÂü∫‰∫é‰∫ãÂÆûÔºà‰æãÂ¶ÇÔºå‰∫ãÂÆûËß£ÈáäÔºâÂíåÂü∫‰∫éÊäÄÊúØÁöÑÔºà‰æãÂ¶ÇÔºåËØØÂØºÊäÄÊúØÁöÑËß£ÈáäÔºâÂÜÖÂÆπ„ÄÇÁÑ∂ËÄåÔºåÂú®ËÆ∞ÂΩïÂíåÊ£ÄÊµãÊ∞îÂÄôÈîôËØØ‰ø°ÊÅØ‰∏≠ÁöÑË∞¨ËØØÊñπÈù¢Âá†‰πéÊ≤°ÊúâÂèñÂæóËøõÂ±ï„ÄÇÂú®ËøôÈ°πÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Â∫îÁî®‰∫ÜÂÖàÂâçÂºÄÂèëÁöÑÊâπÂà§ÊÄßÊÄùÁª¥ÊñπÊ≥ïÊù•Ëß£ÊûÑÊ∞îÂÄôÈîôËØØ‰ø°ÊÅØÔºå‰ª•‰æøÂºÄÂèë‰∏Ä‰∏™Êï∞ÊçÆÈõÜÔºåÂ∞Ü‰∏çÂêåÁ±ªÂûãÁöÑÊ∞îÂÄôÈîôËØØ‰ø°ÊÅØÊò†Â∞ÑÂà∞Êé®ÁêÜË∞¨ËØØ„ÄÇÊ≠§Êï∞ÊçÆÈõÜÁî®‰∫éËÆ≠ÁªÉÊ®°Âûã‰ª•Ê£ÄÊµãÊ∞îÂÄôÈîôËØØ‰ø°ÊÅØ‰∏≠ÁöÑË∞¨ËØØ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÊòæÁ§∫ÔºåF1 ÂàÜÊï∞ÊØî‰ª•ÂâçÁöÑ‰ΩúÂìÅÈ´òÂá∫ 2.5 Âà∞ 3.5„ÄÇÊúÄÂÆπÊòìÊ£ÄÊµãÂà∞ÁöÑË∞¨ËØØÂåÖÊã¨ËôöÂÅá‰∏ìÂÆ∂ÂíåËΩ∂‰∫ãËÆ∫ËØÅÔºåËÄåÈúÄË¶ÅËÉåÊôØÁü•ËØÜÁöÑË∞¨ËØØÔºå‰æãÂ¶ÇËøáÂ∫¶ÁÆÄÂåñ„ÄÅÊ≠™Êõ≤ÂíåÊáíÊÉ∞ÂΩíÁ∫≥ÔºåÂàôÁõ∏ÂØπÊõ¥ÈöæÊ£ÄÊµã„ÄÇËøôÈ°πÁ†îÁ©∂‰∏∫Ëß£ÂÜ≥ÊñπÊ°àÁöÑÂºÄÂèëÂ•†ÂÆö‰∫ÜÂü∫Á°ÄÔºåÂÖ∂‰∏≠Ëá™Âä®Ê£ÄÊµãÂà∞ÁöÑÊ∞îÂÄôÈîôËØØ‰ø°ÊÅØÂèØ‰ª•ÈÄöËøáÁîüÊàêÂü∫‰∫éÊäÄÊúØÁöÑÊõ¥Ê≠£Êù•Âä†‰ª•Â∫îÂØπ„ÄÇ

##### **Smart Sampling: Self-Attention and Bootstrapping for Improved Ensembled Q-Learning**
2405.08252v1 by Muhammad Junaid Khan, Syed Hammad Ahmed, Gita Sukthankar

We present a novel method aimed at enhancing the sample efficiency of
ensemble Q learning. Our proposed approach integrates multi-head self-attention
into the ensembled Q networks while bootstrapping the state-action pairs
ingested by the ensemble. This not only results in performance improvements
over the original REDQ (Chen et al. 2021) and its variant DroQ (Hi-raoka et al.
2022), thereby enhancing Q predictions, but also effectively reduces both the
average normalized bias and standard deviation of normalized bias within
Q-function ensembles. Importantly, our method also performs well even in
scenarios with a low update-to-data (UTD) ratio. Notably, the implementation of
our proposed method is straightforward, requiring minimal modifications to the
base model.

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÊó®Âú®ÊèêÈ´òÊï¥È´î Q Â≠∏ÁøíÁöÑÊ®£Êú¨ÊïàÁéá„ÄÇÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞áÂ§öÈ†≠Ëá™ÊàëÊ≥®ÊÑèÊï¥ÂêàÂà∞Êï¥È´î Q Á∂≤Ë∑Ø‰∏≠ÔºåÂêåÊôÇÂ∞çÊï¥È´îÂê∏Êî∂ÁöÑÁãÄÊÖãÂãï‰ΩúÂ∞çÈÄ≤Ë°åËá™Ëàâ„ÄÇÈÄô‰∏çÂÉÖÂ∞éËá¥ÊÄßËÉΩÂÑ™ÊñºÂéüÂßã REDQÔºàChen et al. 2021ÔºâÂèäÂÖ∂ËÆäÈ´î DroQÔºàHi-raoka et al. 2022ÔºâÔºåÂæûËÄåÂ¢ûÂº∑ Q È†êÊ∏¨ÔºåËÄå‰∏îÊúâÊïàÈôç‰Ωé‰∫Ü Q ÂáΩÊï∏Êï¥È´î‰∏≠Ê®ôÊ∫ñÂåñÂÅèÂ∑ÆÁöÑÂπ≥ÂùáÊ®ôÊ∫ñÂåñÂÅèÂ∑ÆÂíåÊ®ôÊ∫ñÂ∑Æ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÂç≥‰ΩøÂú®Êõ¥Êñ∞Âà∞Ë≥áÊñô (UTD) ÊØîÁéá‰ΩéÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊàëÂÄëÁöÑÊ®°Âûã‰πüËÉΩË°®ÁèæËâØÂ•Ω„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂØ¶‰ΩúÂæàÁ∞°ÂñÆÔºåÂè™ÈúÄË¶ÅÂ∞çÂü∫Á§éÊ®°ÂûãÈÄ≤Ë°åÊúÄÂ∞èÁöÑ‰øÆÊîπ„ÄÇ

##### **Automated classification of multi-parametric body MRI series**
2405.08247v1 by Boah Kim, Tejas Sudharshan Mathai, Kimberly Helm, Ronald M. Summers

Multi-parametric MRI (mpMRI) studies are widely available in clinical
practice for the diagnosis of various diseases. As the volume of mpMRI exams
increases yearly, there are concomitant inaccuracies that exist within the
DICOM header fields of these exams. This precludes the use of the header
information for the arrangement of the different series as part of the
radiologist's hanging protocol, and clinician oversight is needed for
correction. In this pilot work, we propose an automated framework to classify
the type of 8 different series in mpMRI studies. We used 1,363 studies acquired
by three Siemens scanners to train a DenseNet-121 model with 5-fold
cross-validation. Then, we evaluated the performance of the DenseNet-121
ensemble on a held-out test set of 313 mpMRI studies. Our method achieved an
average precision of 96.6%, sensitivity of 96.6%, specificity of 99.6%, and F1
score of 96.6% for the MRI series classification task. To the best of our
knowledge, we are the first to develop a method to classify the series type in
mpMRI studies acquired at the level of the chest, abdomen, and pelvis. Our
method has the capability for robust automation of hanging protocols in modern
radiology practice.

ÊëòË¶ÅÔºöÂ§öÂèÉÊï∏ MRI (mpMRI) Á†îÁ©∂Âª£Ê≥õÊáâÁî®ÊñºËá®Â∫äÂØ¶Âãô‰∏≠ÔºåÁî®ÊñºË®∫Êñ∑ÂêÑÁ®ÆÁñæÁóÖ„ÄÇÁî±Êñº mpMRI Ê™¢Êü•ÈáèÊØèÂπ¥ÈÉΩÂú®Â¢ûÂä†ÔºåÈÄô‰∫õÊ™¢Êü•ÁöÑ DICOM Ê®ôÈ†≠Ê¨Ñ‰Ωç‰∏≠Â≠òÂú®Ëëó‰º¥Èö®ÁöÑ‰∏çÊ∫ñÁ¢∫ÊÄß„ÄÇÈÄôÊúÉÂ¶®Á§ôÂ∞áÊ®ôÈ†≠Ë≥áË®äÁî®ÊñºÊîæÂ∞ÑÁßëÈÜ´Â∏´Êá∏ÊéõÂçîÂÆöÁöÑ‰∏çÂêåÁ≥ªÂàóÁöÑÊéíÂàóÔºå‰∏¶‰∏îÈúÄË¶ÅËá®Â∫äÈÜ´Â∏´Áõ£Áù£ÊâçËÉΩÈÄ≤Ë°åÊ†°Ê≠£„ÄÇÂú®ÈÄôÈ†ÖË©¶È©óÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËá™ÂãïÂåñÊû∂ÊßãÔºåÁî®ÊñºÂ∞ç mpMRI Á†îÁ©∂‰∏≠ÁöÑ 8 ÂÄã‰∏çÂêåÁ≥ªÂàóÈ°ûÂûãÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄë‰ΩøÁî®‰∫ÜÁî±‰∏âÂÄã Siemens ÊéÉÊèèÂô®ÂèñÂæóÁöÑ 1,363 È†ÖÁ†îÁ©∂Ôºå‰ª•Ë®ìÁ∑¥‰∏ÄÂÄãÂÖ∑Êúâ 5 ÂÄç‰∫§ÂèâÈ©óË≠âÁöÑ DenseNet-121 Ê®°Âûã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁî± 313 È†Ö mpMRI Á†îÁ©∂ÁµÑÊàêÁöÑÁïôÂá∫Ê∏¨Ë©¶ÈõÜ‰∏äË©ï‰º∞‰∫Ü DenseNet-121 Ê∑∑ÂêàÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® MRI Á≥ªÂàóÂàÜÈ°û‰ªªÂãô‰∏≠ÈÅîÂà∞‰∫ÜÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ 96.6%„ÄÅÊïèÊÑüÂ∫¶ 96.6%„ÄÅÁâπÁï∞Â∫¶ 99.6% Âíå F1 ÂàÜÊï∏ 96.6%„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÊàëÂÄëÊòØÁ¨¨‰∏ÄÂÄãÈñãÁôºÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜÂ∞çÂú®ËÉ∏ÈÉ®„ÄÅËÖπÈÉ®ÂíåÈ™®ÁõÜÂ±§Á¥öÂèñÂæóÁöÑ mpMRI Á†îÁ©∂‰∏≠ÁöÑÁ≥ªÂàóÈ°ûÂûãÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊúâËÉΩÂäõÂú®Áèæ‰ª£ÊîæÂ∞ÑÁßëÂØ¶Âãô‰∏≠Â∞çÊá∏ÊéõÂçîÂÆöÈÄ≤Ë°åÂº∑ÂÅ•ÁöÑËá™ÂãïÂåñ„ÄÇ

##### **Compositional Text-to-Image Generation with Dense Blob Representations**
2405.08246v1 by Weili Nie, Sifei Liu, Morteza Mardani, Chao Liu, Benjamin Eckart, Arash Vahdat

Existing text-to-image models struggle to follow complex text prompts,
raising the need for extra grounding inputs for better controllability. In this
work, we propose to decompose a scene into visual primitives - denoted as dense
blob representations - that contain fine-grained details of the scene while
being modular, human-interpretable, and easy-to-construct. Based on blob
representations, we develop a blob-grounded text-to-image diffusion model,
termed BlobGEN, for compositional generation. Particularly, we introduce a new
masked cross-attention module to disentangle the fusion between blob
representations and visual features. To leverage the compositionality of large
language models (LLMs), we introduce a new in-context learning approach to
generate blob representations from text prompts. Our extensive experiments show
that BlobGEN achieves superior zero-shot generation quality and better
layout-guided controllability on MS-COCO. When augmented by LLMs, our method
exhibits superior numerical and spatial correctness on compositional image
generation benchmarks. Project page: https://blobgen-2d.github.io.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÊñáÂ≠óËΩâÂúñÂÉèÊ®°ÂûãÈõ£‰ª•ÈÅµÂæ™Ë§áÈõúÁöÑÊñáÂ≠óÊèêÁ§∫ÔºåÂõ†Ê≠§ÈúÄË¶ÅÈ°çÂ§ñÁöÑÂü∫Á§éËº∏ÂÖ•‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑÂèØÊéßÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞Â∞áÂ†¥ÊôØÂàÜËß£ÁÇ∫Ë¶ñË¶∫Âü∫ÂÖÉ - Ë°®Á§∫ÁÇ∫ÂØÜÈõÜÁöÑÊñëÈªûË°®Á§∫ - ÂÖ∂‰∏≠ÂåÖÂê´Â†¥ÊôØÁöÑÁ¥∞Á∑ªÁ¥∞ÁØÄÔºåÂêåÊôÇÂÖ∑ÊúâÊ®°ÁµÑÂåñ„ÄÅ‰∫∫È°ûÂèØËß£ËÆÄ‰∏îÊòìÊñºÂª∫ÊßãÁöÑÁâπÊÄß„ÄÇÂü∫ÊñºÊñëÈªûË°®Á§∫ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÊñëÈªûÂü∫Á§éÁöÑÊñáÂ≠óËΩâÂúñÂÉèÊì¥Êï£Ê®°ÂûãÔºåÁ®±ÁÇ∫ BlobGENÔºåÁî®ÊñºÂêàÊàêÁîüÊàê„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÈÅÆÁΩ©‰∫§ÂèâÊ≥®ÊÑèÂäõÊ®°ÁµÑÔºå‰ª•Ëß£ÈñãÊñëÈªûË°®Á§∫ÂíåË¶ñË¶∫ÁâπÂæµ‰πãÈñìÁöÑËûçÂêà„ÄÇÁÇ∫‰∫ÜÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁµÑÂêàÊÄßÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊÉÖÂ¢ÉÂÖßÂ≠∏ÁøíÊñπÊ≥ïÔºå‰ª•ÂæûÊñáÂ≠óÊèêÁ§∫‰∏≠ÁîüÊàêÊñëÈªûË°®Á§∫„ÄÇÊàëÂÄëÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåBlobGEN Âú® MS-COCO ‰∏äÂØ¶Áèæ‰∫ÜÂá∫Ëâ≤ÁöÑÈõ∂Ê¨°ÁîüÊàêÂìÅË≥™ÂíåÊõ¥Â•ΩÁöÑ‰ΩàÂ±ÄÂºïÂ∞éÂèØÊéßÊÄß„ÄÇÁï∂Áî± LLM Â¢ûÂº∑ÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂêàÊàêÂúñÂÉèÁîüÊàêÂü∫Ê∫ñ‰∏äÂ±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÊï∏Â≠óÂíåÁ©∫ÈñìÊ≠£Á¢∫ÊÄß„ÄÇÂ∞àÊ°àÈ†ÅÈù¢Ôºöhttps://blobgen-2d.github.io„ÄÇ

##### **Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy**
2405.08245v1 by Xiameng Wei, Binbin Fan, Ying Wang, Yanxiang Feng, Laiyi Fu

Ancient murals are valuable cultural heritage with great archaeological
value. They provide insights into ancient religions, ceremonies, folklore,
among other things through their content. However, due to long-term oxidation
and inadequate protection, ancient murals have suffered continuous damage,
including peeling and mold etc. Additionally, since ancient murals were
typically painted indoors, the light intensity in images captured by digital
devices is often low. The poor visibility hampers the further restoration of
damaged areas. To address the escalating damage to ancient frescoes and
facilitate batch restoration at archaeological sites, we propose a two-stage
restoration model which called MER(Mural Enhancement and Restoration net) for
ancient murals that are damaged and have been captured in low light. Our
two-stage model not only enhances the visual quality of restored images but
also achieves commendable results in relevant metric evaluations compared with
other competitors. Furthermore, we have launched a website dedicated to the
restoration of ancient mural paintings, utilizing the proposed model. Code is
available at https://gitee.com/bbfan2024/MER.git.

ÊëòË¶ÅÔºöÂè§‰ª£Â£ÅÁï´ÊòØÂÖ∑ÊúâÈáçÂ§ßËÄÉÂè§ÂÉπÂÄºÁöÑÁèçË≤¥ÊñáÂåñÈÅ∫Áî¢„ÄÇÂÆÉÂÄëÈÄèÈÅéÂÖ∂ÂÖßÂÆπÊèê‰æõÂ∞çÂè§‰ª£ÂÆóÊïô„ÄÅÂÑÄÂºè„ÄÅÊ∞ëÈñìÂÇ≥Ë™™Á≠âÊñπÈù¢ÁöÑË¶ãËß£„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÈï∑ÊúüÊ∞ßÂåñÂíå‰øùË≠∑‰∏çÁï∂ÔºåÂè§‰ª£Â£ÅÁï´ÈÅ≠ÂèóÊåÅÁ∫åÁ†¥Â£ûÔºåÂåÖÊã¨ÂâùËêΩ„ÄÅÁôºÈúâÁ≠â„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÂè§‰ª£Â£ÅÁï´ÈÄöÂ∏∏Áπ™Ë£ΩÂú®ÂÆ§ÂÖßÔºåÂõ†Ê≠§Êï∏‰ΩçË£ùÁΩÆÊâÄÊãçÊîùÁöÑÂΩ±ÂÉèÂÖâÁ∑öÂº∑Â∫¶ÈÄöÂ∏∏Âæà‰Ωé„ÄÇËÉΩË¶ãÂ∫¶‰∏ç‰Ω≥ÊúÉÈòªÁ§ôÂèóÊêçÂçÄÂüüÁöÑÈÄ≤‰∏ÄÊ≠•‰øÆÂæ©„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Âè§‰ª£Â£ÅÁï´Êó•ÁõäÂö¥ÈáçÁöÑÊêçÂ£ûÂïèÈ°åÔºå‰∏¶‰øÉÈÄ≤ËÄÉÂè§ÈÅ∫ÂùÄÁöÑÊâπÈáè‰øÆÂæ©ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ MERÔºàÂ£ÅÁï´Â¢ûÂº∑Âíå‰øÆÂæ©Á∂≤Ë∑ØÔºâÁöÑÂÖ©ÈöéÊÆµ‰øÆÂæ©Ê®°ÂûãÔºåÈÅ©Áî®ÊñºÂèóÊêç‰∏îÂú®‰ΩéÂÖâÊ∫ê‰∏ãÊãçÊîùÁöÑÂè§‰ª£Â£ÅÁï´„ÄÇÊàëÂÄëÁöÑÂÖ©ÈöéÊÆµÊ®°Âûã‰∏çÂÉÖÂ¢ûÂº∑‰∫Ü‰øÆÂæ©ÂΩ±ÂÉèÁöÑË¶ñË¶∫ÂìÅË≥™ÔºåÂú®ËàáÂÖ∂‰ªñÁ´∂Áà≠ËÄÖÁöÑÁõ∏ÈóúÊåáÊ®ôË©ï‰º∞‰∏≠‰πüÂèñÂæó‰∫Ü‰ª§‰∫∫Á®±ÈÅìÁöÑÊàêÊûú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∑≤Êé®Âá∫‰∏ÄÂÄãÂ∞àÈñÄÁî®Êñº‰øÆÂæ©Âè§‰ª£Â£ÅÁï´ÁöÑÁ∂≤Á´ôÔºå‰∏¶Êé°Áî®‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ®°Âûã„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://gitee.com/bbfan2024/MER.git ÂèñÂæó„ÄÇ

##### **Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT**
2405.08238v1 by Takao Fujii, Katie Seaborn, Madeleine Steeds

ChatGPT is a conversational agent built on a large language model. Trained on
a significant portion of human output, ChatGPT can mimic people to a degree. As
such, we need to consider what social identities ChatGPT simulates (or can be
designed to simulate). In this study, we explored the case of identity
simulation through Japanese first-person pronouns, which are tightly connected
to social identities in intersectional ways, i.e., intersectional pronouns. We
conducted a controlled online experiment where people from two regions in Japan
(Kanto and Kinki) witnessed interactions with ChatGPT using ten sets of
first-person pronouns. We discovered that pronouns alone can evoke perceptions
of social identities in ChatGPT at the intersections of gender, age, region,
and formality, with caveats. This work highlights the importance of pronoun use
for social identity simulation, provides a language-based methodology for
culturally-sensitive persona development, and advances the potential of
intersectional identities in intelligent agents.

ÊëòË¶ÅÔºöChatGPT ÊòØ‰∏ÄÂÄãÂª∫ÊßãÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏äÁöÑÂ∞çË©±‰ª£ÁêÜ„ÄÇChatGPT Êé•ÂèóÂ§ßÈáè‰∫∫È°ûÁî¢Âá∫ÁöÑË®ìÁ∑¥ÔºåÂèØ‰ª•Âú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÊ®°Êì¨‰∫∫È°û„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÈúÄË¶ÅËÄÉÊÖÆ ChatGPT Ê®°Êì¨ÔºàÊàñÂèØË®≠Ë®àÁÇ∫Ê®°Êì¨ÔºâÂì™‰∫õÁ§æÊúÉË∫´ÂàÜ„ÄÇÂú®ÈÄôÂÄãÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄèÈÅéÊó•ÊñáÁ¨¨‰∏Ä‰∫∫Á®±‰ª£ÂêçË©ûÈÄ≤Ë°åË∫´ÂàÜÊ®°Êì¨ÁöÑÊ°à‰æãÔºåÈÄô‰∫õ‰ª£ÂêçË©ûËàáÁ§æÊúÉË∫´ÂàÜÁ∑äÂØÜÁõ∏ÈÄ£Ôºå‰πüÂ∞±ÊòØ‰∫§ÁπîÁöÑ‰ª£ÂêçË©û„ÄÇÊàëÂÄëÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂèóÊéßÁöÑÁ∑ö‰∏äÂØ¶È©óÔºå‰æÜËá™Êó•Êú¨ÂÖ©ÂÄãÂú∞ÂçÄÔºàÈóúÊù±ÂíåËøëÁïøÔºâÁöÑ‰∫∫Ë¶ãË≠â‰∫Ü ChatGPT ‰ΩøÁî®ÂçÅÁµÑÁ¨¨‰∏Ä‰∫∫Á®±‰ª£ÂêçË©ûÁöÑ‰∫íÂãï„ÄÇÊàëÂÄëÁôºÁèæÔºåÂÉÖÊÜë‰ª£ÂêçË©ûÂ∞±ËÉΩÂñöËµ∑‰∫∫ÂÄëÂ∞ç ChatGPT Âú®ÊÄßÂà•„ÄÅÂπ¥ÈΩ°„ÄÅÂú∞ÂçÄÂíåÁ¶ÆË≤åÁ≠â‰∫§ÈõÜ‰∏≠ÁöÑÁ§æÊúÉË∫´ÂàÜÁöÑË™çÁü•Ôºå‰ΩÜÊúâ‰∏Ä‰∫õ‰ΩÜÊõ∏„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂº∑Ë™ø‰∫Ü‰ª£ÂêçË©ûÂú®Á§æÊúÉË∫´ÂàÜÊ®°Êì¨‰∏≠ÁöÑÈáçË¶ÅÊÄßÔºåÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºË™ûË®ÄÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÊñáÂåñÊïèÊÑüÁöÑËßíËâ≤ÁôºÂ±ïÔºå‰∏¶ÊèêÂçá‰∫ÜÊô∫ÊÖß‰ª£ÁêÜ‰∏≠‰∫§ÁπîË∫´ÂàÜÁöÑÊΩõÂäõ„ÄÇ

##### **A predictive learning model can simulate temporal dynamics and context effects found in neural representations of continuous speech**
2405.08237v1 by Oli Danyi Liu, Hao Tang, Naomi Feldman, Sharon Goldwater

Speech perception involves storing and integrating sequentially presented
items. Recent work in cognitive neuroscience has identified temporal and
contextual characteristics in humans' neural encoding of speech that may
facilitate this temporal processing. In this study, we simulated similar
analyses with representations extracted from a computational model that was
trained on unlabelled speech with the learning objective of predicting upcoming
acoustics. Our simulations revealed temporal dynamics similar to those in brain
signals, implying that these properties can arise without linguistic knowledge.
Another property shared between brains and the model is that the encoding
patterns of phonemes support some degree of cross-context generalization.
However, we found evidence that the effectiveness of these generalizations
depends on the specific contexts, which suggests that this analysis alone is
insufficient to support the presence of context-invariant encoding.

ÊëòË¶ÅÔºöË™ûÈü≥ÊÑüÁü•Ê∂âÂèäÂÑ≤Â≠òÂíåÊï¥Âêà‰æùÂ∫èÂëàÁèæÁöÑÈ†ÖÁõÆ„ÄÇË™çÁü•Á•ûÁ∂ìÁßëÂ≠∏ÁöÑÊúÄÊñ∞Á†îÁ©∂Â∑≤ÊâæÂá∫‰∫∫È°ûÁ•ûÁ∂ìÁ∑®Á¢º‰∏≠Ë™ûÈü≥ÁöÑÊôÇÂ∫èÂíåËÑàÁµ°ÁâπÂæµÔºåÂèØËÉΩÊúâÂä©ÊñºÈÄôÁ®ÆÊôÇÂ∫èËôïÁêÜ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ®°Êì¨‰∫ÜÈ°û‰ººÁöÑÂàÜÊûêÔºå‰ΩøÁî®ÂæûË®àÁÆóÊ©üÊ®°Âûã‰∏≠ËêÉÂèñÁöÑË°®ÂæµÔºåË©≤Ê®°Âûã‰ª•ÁÑ°Ê®ôÁ±§Ë™ûÈü≥ÈÄ≤Ë°åË®ìÁ∑¥ÔºåÂ≠∏ÁøíÁõÆÊ®ôÊòØÈ†êÊ∏¨Âç≥Â∞áÂà∞‰æÜÁöÑÈü≥Èüø„ÄÇÊàëÂÄëÁöÑÊ®°Êì¨Êè≠Á§∫‰∫ÜËàáËÖ¶ÈÉ®Ë®äËôüÁõ∏‰ººÁöÑÊôÇÂ∫èÂãïÊÖãÔºåÊöóÁ§∫ÈÄô‰∫õÂ±¨ÊÄßÂèØ‰ª•Âú®Ê≤íÊúâË™ûË®ÄÁü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ãÁî¢Áîü„ÄÇÂ§ßËÖ¶ÂíåÊ®°Âûã‰πãÈñìÂÖ±‰∫´ÁöÑÂè¶‰∏ÄÂÄãÂ±¨ÊÄßÊòØÔºåÈü≥Á¥†ÁöÑÁ∑®Á¢ºÊ®°ÂºèÊîØÊè¥‰∏ÄÂÆöÁ®ãÂ∫¶ÁöÑË∑®ËÑàÁµ°Ê¶ÇÂåñ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁôºÁèæË≠âÊìöÈ°ØÁ§∫ÔºåÈÄô‰∫õÊ¶ÇÂåñÁöÑÊúâÊïàÊÄßÂèñÊ±∫ÊñºÁâπÂÆöËÑàÁµ°ÔºåÈÄôË°®Á§∫ÂÉÖÊÜëÊ≠§ÂàÜÊûê‰∏çË∂≥‰ª•ÊîØÊåÅËÑàÁµ°‰∏çËÆäÁ∑®Á¢ºÁöÑÂ≠òÂú®„ÄÇ

##### **An information-theoretic model of shallow and deep language comprehension**
2405.08223v1 by Jiaxuan Li, Richard Futrell

A large body of work in psycholinguistics has focused on the idea that online
language comprehension can be shallow or `good enough': given constraints on
time or available computation, comprehenders may form interpretations of their
input that are plausible but inaccurate. However, this idea has not yet been
linked with formal theories of computation under resource constraints. Here we
use information theory to formulate a model of language comprehension as an
optimal trade-off between accuracy and processing depth, formalized as bits of
information extracted from the input, which increases with processing time. The
model provides a measure of processing effort as the change in processing
depth, which we link to EEG signals and reading times. We validate our theory
against a large-scale dataset of garden path sentence reading times, and EEG
experiments featuring N400, P600 and biphasic ERP effects. By quantifying the
timecourse of language processing as it proceeds from shallow to deep, our
model provides a unified framework to explain behavioral and neural signatures
of language comprehension.

ÊëòË¶ÅÔºöÂ§ßÈáèÁöÑÂøÉÁêÜËØ≠Ë®ÄÂ≠¶Á†îÁ©∂ÈõÜ‰∏≠Âú®ËøôÊ†∑‰∏Ä‰∏™ËßÇÂøµ‰∏äÔºåÂç≥Âú®Á∫øËØ≠Ë®ÄÁêÜËß£ÂèØ‰ª•ÊòØËÇ§ÊµÖÁöÑÊàñ‚ÄúË∂≥Â§üÂ•ΩÁöÑ‚ÄùÔºöÈâ¥‰∫éÊó∂Èó¥ÊàñÂèØÁî®ËÆ°ÁÆóÁöÑÈôêÂà∂ÔºåÁêÜËß£ËÄÖÂèØËÉΩ‰ºöÂØπËæìÂÖ•ÂΩ¢Êàê‰ººÊòØËÄåÈùûÁöÑËß£Èáä„ÄÇÁÑ∂ËÄåÔºåËøô‰∏™ËßÇÂøµÂ∞öÊú™‰∏éËµÑÊ∫êÁ∫¶Êùü‰∏ãÁöÑÂΩ¢ÂºèËÆ°ÁÆóÁêÜËÆ∫ËÅîÁ≥ªËµ∑Êù•„ÄÇÂú®ËøôÈáåÔºåÊàë‰ª¨Âà©Áî®‰ø°ÊÅØËÆ∫Êù•ÊûÑÂª∫‰∏Ä‰∏™ËØ≠Ë®ÄÁêÜËß£Ê®°ÂûãÔºå‰Ωú‰∏∫ÂáÜÁ°ÆÊÄßÂíåÂ§ÑÁêÜÊ∑±Â∫¶‰πãÈó¥ÁöÑÊúÄ‰ºòÊùÉË°°ÔºåÂΩ¢ÂºèÂåñ‰∏∫‰ªéËæìÂÖ•‰∏≠ÊèêÂèñÁöÑ‰ø°ÊÅØÊØîÁâπÔºåÂÆÉÈöèÁùÄÂ§ÑÁêÜÊó∂Èó¥ËÄåÂ¢ûÂä†„ÄÇËØ•Ê®°ÂûãÊèê‰æõ‰∫ÜÂ§ÑÁêÜÂ∑•‰ΩúÈáèÁöÑË°°ÈáèÊ†áÂáÜÔºåÂç≥Â§ÑÁêÜÊ∑±Â∫¶ÁöÑÂèòÂåñÔºåÊàë‰ª¨Â∞ÜÂÖ∂‰∏éËÑëÁîµÂõæ‰ø°Âè∑ÂíåÈòÖËØªÊó∂Èó¥ËÅîÁ≥ªËµ∑Êù•„ÄÇÊàë‰ª¨ÈíàÂØπÂ§ßËßÑÊ®°ÁöÑËä±Âõ≠Ë∑ØÂæÑÂè•Â≠êÈòÖËØªÊó∂Èó¥Êï∞ÊçÆÈõÜÈ™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÁêÜËÆ∫Ôºå‰ª•ÂèäÂÖ∑Êúâ N400„ÄÅP600 ÂíåÂèåÁõ∏ ERP ÊïàÂ∫îÁöÑËÑëÁîµÂõæÂÆûÈ™å„ÄÇÈÄöËøáÈáèÂåñËØ≠Ë®ÄÂ§ÑÁêÜ‰ªéÊµÖÂà∞Ê∑±ÁöÑÊó∂Èó¥ËøáÁ®ãÔºåÊàë‰ª¨ÁöÑÊ®°ÂûãÊèê‰æõ‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊ°ÜÊû∂Êù•Ëß£ÈáäËØ≠Ë®ÄÁêÜËß£ÁöÑË°å‰∏∫ÂíåÁ•ûÁªèÁâπÂæÅ„ÄÇ

##### **Interpreting Latent Student Knowledge Representations in Programming Assignments**
2405.08213v1 by Nigel Fernandez, Andrew Lan

Recent advances in artificial intelligence for education leverage generative
large language models, including using them to predict open-ended student
responses rather than their correctness only. However, the black-box nature of
these models limits the interpretability of the learned student knowledge
representations. In this paper, we conduct a first exploration into
interpreting latent student knowledge representations by presenting InfoOIRT,
an Information regularized Open-ended Item Response Theory model, which
encourages the latent student knowledge states to be interpretable while being
able to generate student-written code for open-ended programming questions.
InfoOIRT maximizes the mutual information between a fixed subset of latent
knowledge states enforced with simple prior distributions and generated student
code, which encourages the model to learn disentangled representations of
salient syntactic and semantic code features including syntactic styles,
mastery of programming skills, and code structures. Through experiments on a
real-world programming education dataset, we show that InfoOIRT can both
accurately generate student code and lead to interpretable student knowledge
representations.

ÊëòË¶ÅÔºöÊúÄËøëÂú®ÊïôËÇ≤ÊñπÈù¢ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÄ≤Â±ïÂà©Áî®‰∫ÜÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÂåÖÊã¨Áî®ÂÆÉÂÄë‰æÜÈ†êÊ∏¨ÈñãÊîæÂºèÂ≠∏ÁîüÁöÑÂõûÊáâÔºåËÄå‰∏ç‰ªÖ‰ªÖÊòØÂÆÉÂÄëÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊ®°ÂûãÁöÑÈªëÁÆ±ÊÄßË≥™ÈôêÂà∂‰∫ÜÂ∞çÂ≠∏ÁøíÁöÑÂ≠∏ÁîüÁü•Ë≠òË°®ÂæµÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄöÈÅéÊèêÂá∫ InfoOIRT ÈÄ≤Ë°å‰∫ÜÈ¶ñÊ¨°Êé¢Á¥¢‰æÜËß£ÈáãÊΩõÂú®ÁöÑÂ≠∏ÁîüÁü•Ë≠òË°®ÂæµÔºåÈÄôÊòØ‰∏ÄÂÄã‰ø°ÊÅØÊ≠£ÂâáÂåñÁöÑÈñãÊîæÂºèÈ†ÖÁõÆÂèçÊáâÁêÜË´ñÊ®°ÂûãÔºåÂÆÉÈºìÂãµÊΩõÂú®ÁöÑÂ≠∏ÁîüÁü•Ë≠òÁãÄÊÖãÂèØËß£ÈáãÔºåÂêåÊôÇËÉΩÂ§†ÁÇ∫ÈñãÊîæÂºèÁ∑®Á®ãÂïèÈ°åÁîüÊàêÂ≠∏ÁîüÁ∑®ÂØ´ÁöÑ‰ª£Á¢º„ÄÇInfoOIRT ÊúÄÂ§ßÂåñ‰∫ÜÊΩõÂú®Áü•Ë≠òÁãÄÊÖãÁöÑÂõ∫ÂÆöÂ≠êÈõÜÔºàÁî®Á∞°ÂñÆÁöÑÂÖàÈ©óÂàÜ‰ΩàÂº∑Âà∂Âü∑Ë°åÔºâÂíåÁîüÊàêÁöÑÂ≠∏Áîü‰ª£Á¢º‰πãÈñìÁöÑ‰∫í‰ø°ÊÅØÔºåÈÄôÈºìÂãµÊ®°ÂûãÂ≠∏ÁøíË™ûÊ≥ïÂíåË™ûÁæ©‰ª£Á¢ºÁâπÂæµÔºàÂåÖÊã¨Ë™ûÊ≥ïÊ®£Âºè„ÄÅÁ∑®Á®ãÊäÄËÉΩÊéåÊè°Âíå‰ª£Á¢ºÁµêÊßãÔºâÁöÑËß£ÈñãË°®Âæµ„ÄÇÈÄöÈÅéÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÁ∑®Á®ãÊïôËÇ≤Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëË°®Êòé InfoOIRT Êó¢ÂèØ‰ª•Ê∫ñÁ¢∫Âú∞ÁîüÊàêÂ≠∏Áîü‰ª£Á¢ºÔºåÂèàÂèØ‰ª•Â∞éËá¥ÂèØËß£ÈáãÁöÑÂ≠∏ÁîüÁü•Ë≠òË°®Âæµ„ÄÇ

##### **Towards Energy-Aware Federated Learning via MARL: A Dual-Selection Approach for Model and Client**
2405.08183v1 by Jun Xia, Yiyu Shi

Although Federated Learning (FL) is promising in knowledge sharing for
heterogeneous Artificial Intelligence of Thing (AIoT) devices, their training
performance and energy efficacy are severely restricted in practical
battery-driven scenarios due to the ``wooden barrel effect'' caused by the
mismatch between homogeneous model paradigms and heterogeneous device
capability. As a result, due to various kinds of differences among devices, it
is hard for existing FL methods to conduct training effectively in
energy-constrained scenarios, such as the battery constraints of devices. To
tackle the above issues, we propose an energy-aware FL framework named DR-FL,
which considers the energy constraints in both clients and heterogeneous deep
learning models to enable energy-efficient FL. Unlike Vanilla FL, DR-FL adopts
our proposed Muti-Agents Reinforcement Learning (MARL)-based dual-selection
method, which allows participated devices to make contributions to the global
model effectively and adaptively based on their computing capabilities and
energy capacities in a MARL-based manner. Experiments on various well-known
datasets show that DR-FL can not only maximise knowledge sharing among
heterogeneous models under the energy constraint of large-scale AIoT systems
but also improve the model performance of each involved heterogeneous device.

ÊëòË¶ÅÔºöÂÑòÁÆ°ËÅØÂêàÂºèÂ≠∏Áøí (FL) Âú®Áï∞Ë≥™ÂåñÁâ©ËÅØÁ∂≤ (AIoT) Ë£ùÁΩÆÁöÑÁü•Ë≠òÂÖ±‰∫´‰∏≠ÂæàÊúâÂâçÊôØÔºå‰ΩÜÁî±ÊñºÂêåË≥™ÂåñÊ®°ÂûãÁØÑ‰æãËàáÁï∞Ë≥™ÂåñË£ùÁΩÆÂäüËÉΩ‰πãÈñìÁöÑ‰∏çÂåπÈÖçÊâÄÈÄ†ÊàêÁöÑ„ÄåÊú®Ê°∂ÊïàÊáâ„ÄçÔºåÂÖ∂Ë®ìÁ∑¥ÊïàËÉΩÂíåËÉΩÊ∫êÊïàÁéáÂú®ÂØ¶ÈöõÁöÑÈõªÊ±†È©ÖÂãïÂ†¥ÊôØ‰∏≠ÂèóÂà∞Âö¥ÈáçÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåÁî±ÊñºË£ùÁΩÆ‰πãÈñìÂêÑÁ®ÆÂ∑ÆÁï∞ÔºåÁèæÊúâÁöÑ FL ÊñπÊ≥ïÈõ£‰ª•Âú®ËÉΩÊ∫êÂèóÈôêÁöÑÂ†¥ÊôØ‰∏≠ÊúâÊïàÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰æãÂ¶ÇË£ùÁΩÆÁöÑÈõªÊ±†ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫‰∏äËø∞ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ DR-FL ÁöÑÁØÄËÉΩ FL Êû∂ÊßãÔºåÂÆÉËÄÉÊÖÆ‰∫ÜÁî®Êà∂Á´ØÂíåÁï∞Ë≥™ÂåñÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏≠ÁöÑËÉΩÊ∫êÈôêÂà∂Ôºå‰ª•ÂØ¶ÁèæÁØÄËÉΩ FL„ÄÇËàá Vanilla FL ‰∏çÂêåÔºåDR-FL Êé°Áî®ÊàëÂÄëÊèêÂá∫ÁöÑÂ§öÊô∫ËÉΩÈ´îÂº∑ÂåñÂ≠∏Áøí (MARL) Âü∫ÊñºÈõôÈáçÈÅ∏ÊìáÁöÑÊñπÊ≥ïÔºåÂÖÅË®±ÂèÉËàáÁöÑË£ùÁΩÆÊ†πÊìöÂÖ∂ÈÅãÁÆóËÉΩÂäõÂíåËÉΩÊ∫êÂÆπÈáè‰ª• MARL ÁÇ∫Âü∫Á§éÁöÑÊñπÂºèÔºåÊúâÊïà‰∏îÈÅ©ÊáâÊÄßÂú∞Â∞çÂÖ®ÁêÉÊ®°ÂûãÂÅöÂá∫Ë≤¢Áçª„ÄÇÂú®ÂêÑÁ®ÆÁü•ÂêçË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåDR-FL ‰∏çÂÉÖÂèØ‰ª•Âú®Â§ßË¶èÊ®° AIoT Á≥ªÁµ±ÁöÑËÉΩÊ∫êÈôêÂà∂‰∏ãÊúÄÂ§ßÂåñÁï∞Ë≥™ÂåñÊ®°Âûã‰πãÈñìÁöÑÁü•Ë≠òÂÖ±‰∫´ÔºåÈÇÑËÉΩÊèêÂçáÊØèÂÄãÂèÉËàáÁöÑÁï∞Ë≥™ÂåñË£ùÁΩÆÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇ

##### **Estimating Direct and Indirect Causal Effects of Spatiotemporal Interventions in Presence of Spatial Interference**
2405.08174v1 by Sahara Ali, Omar Faruque, Jianwu Wang

Spatial interference (SI) occurs when the treatment at one location affects
the outcomes at other locations. Accounting for spatial interference in
spatiotemporal settings poses further challenges as interference violates the
stable unit treatment value assumption, making it infeasible for standard
causal inference methods to quantify the effects of time-varying treatment at
spatially varying outcomes. In this paper, we first formalize the concept of
spatial interference in case of time-varying treatment assignments by extending
the potential outcome framework under the assumption of no unmeasured
confounding. We then propose our deep learning based potential outcome model
for spatiotemporal causal inference. We utilize latent factor modeling to
reduce the bias due to time-varying confounding while leveraging the power of
U-Net architecture to capture global and local spatial interference in data
over time. Our causal estimators are an extension of average treatment effect
(ATE) for estimating direct (DATE) and indirect effects (IATE) of spatial
interference on treated and untreated data. Being the first of its kind deep
learning based spatiotemporal causal inference technique, our approach shows
advantages over several baseline methods based on the experiment results on two
synthetic datasets, with and without spatial interference. Our results on
real-world climate dataset also align with domain knowledge, further
demonstrating the effectiveness of our proposed method.

ÊëòË¶ÅÔºöÁ©∫ÈñìÂπ≤Êìæ (SI) ÊòØÊåáÊüêÂÄãÂú∞ÊñπÁöÑÁôÇÊ≥ïÊúÉÂΩ±ÈüøÂÖ∂‰ªñÂú∞ÊñπÁöÑÁµêÊûú„ÄÇÂú®ÊôÇÁ©∫ËÉåÊôØ‰∏ãËÄÉÊÖÆÁ©∫ÈñìÂπ≤ÊìæÊúÉÂ∏∂‰æÜÈÄ≤‰∏ÄÊ≠•ÁöÑÊåëÊà∞ÔºåÂõ†ÁÇ∫Âπ≤ÊìæÊúÉÈÅïÂèçÁ©©ÂÆöÁöÑÂñÆ‰ΩçÊ≤ªÁôÇÂÄºÂÅáË®≠Ôºå‰ΩøÂæóÊ®ôÊ∫ñÂõ†ÊûúÊé®Ë´ñÊñπÊ≥ïÁÑ°Ê≥ïÈáèÂåñÊôÇËÆäÊ≤ªÁôÇÂ∞çÁ©∫ÈñìËÆäÁï∞ÁµêÊûúÁöÑÂΩ±Èüø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÂú®Ê≤íÊúâÊú™Ê∏¨ÈáèÊ∑∑Ê∑ÜÁöÑÂÅáË®≠‰∏ãÔºåÈÄèÈÅéÊì¥Â±ïÊΩõÂú®ÁµêÊûúÊû∂ÊßãÔºåÂ∞áÊôÇËÆäÊ≤ªÁôÇÂàÜÈÖçÁöÑÁ©∫ÈñìÂπ≤ÊìæÊ¶ÇÂøµÂΩ¢ÂºèÂåñ„ÄÇÊé•ËëóÔºåÊàëÂÄëÊèêÂá∫Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊΩõÂú®ÁµêÊûúÊ®°ÂûãÔºåÁî®ÊñºÊôÇÁ©∫Âõ†ÊûúÊé®Ë´ñ„ÄÇÊàëÂÄëÂà©Áî®ÊΩõÂú®Âõ†Â≠êÊ®°Âûã‰æÜÊ∏õÂ∞ëÂõ†ÊôÇËÆäÊ∑∑Ê∑ÜÈÄ†ÊàêÁöÑÂÅèÂ∑ÆÔºåÂêåÊôÇÂà©Áî® U-Net Êû∂ÊßãÁöÑÂÑ™Âã¢‰æÜÊì∑ÂèñË≥áÊñô‰∏≠Èö®ÊôÇÈñìËÆäÂåñÁöÑÂÖ®Â±ÄÂíåÂ±ÄÈÉ®Á©∫ÈñìÂπ≤Êìæ„ÄÇÊàëÂÄëÁöÑÂõ†Êûú‰º∞Ë®àÂô®ÊòØÂπ≥ÂùáÊ≤ªÁôÇÊïàÊûú (ATE) ÁöÑÂª∂‰º∏ÔºåÁî®Êñº‰º∞Ë®àÁ©∫ÈñìÂπ≤ÊìæÂ∞çÂ∑≤Ê≤ªÁôÇÂíåÊú™Ê≤ªÁôÇË≥áÊñôÁöÑÁõ¥Êé• (DATE) ÂíåÈñìÊé•ÊïàÊûú (IATE)„ÄÇ‰ΩúÁÇ∫È¶ñÂâµÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊôÇÁ©∫Âõ†ÊûúÊé®Ë´ñÊäÄË°ìÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÂÖ©ÂÄãÂêàÊàêË≥áÊñôÈõÜÔºàÊúâÂíåÊ≤íÊúâÁ©∫ÈñìÂπ≤ÊìæÔºâÁöÑÂØ¶È©óÁµêÊûú‰∏≠ÔºåÂ±ïÁèæÂá∫ÂÑ™ÊñºÂ§öÁ®ÆÂü∫Á∑öÊñπÊ≥ïÁöÑÂÑ™Âã¢„ÄÇÊàëÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåÊ∞£ÂÄôË≥áÊñôÈõÜÁöÑÁµêÊûú‰πüËàáÈ†òÂüüÁü•Ë≠ò‰∏ÄËá¥ÔºåÈÄ≤‰∏ÄÊ≠•Ë≠âÊòéÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation**
2405.08172v1 by Kung Yin Hong, Lifeng Han, Riza Batista-Navarro, Goran Nenadic

This paper investigates the development and evaluation of machine translation
models from Cantonese to English, where we propose a novel approach to tackle
low-resource language translations. The main objectives of the study are to
develop a model that can effectively translate Cantonese to English and
evaluate it against state-of-the-art commercial models. To achieve this, a new
parallel corpus has been created by combining different available corpora
online with preprocessing and cleaning. In addition, a monolingual Cantonese
dataset has been created through web scraping to aid the synthetic parallel
corpus generation. Following the data collection process, several approaches,
including fine-tuning models, back-translation, and model switch, have been
used. The translation quality of models has been evaluated with multiple
quality metrics, including lexicon-based metrics (SacreBLEU and hLEPOR) and
embedding-space metrics (COMET and BERTscore). Based on the automatic metrics,
the best model is selected and compared against the 2 best commercial
translators using the human evaluation framework HOPES. The best model proposed
in this investigation (NLLB-mBART) with model switch mechanisms has reached
comparable and even better automatic evaluation scores against State-of-the-art
commercial models (Bing and Baidu Translators), with a SacreBLEU score of 16.8
on our test set. Furthermore, an open-source web application has been developed
to allow users to translate between Cantonese and English, with the different
trained models available for effective comparisons between models from this
investigation and users. CANTONMT is available at
https://github.com/kenrickkung/CantoneseTranslation

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÊé¢Ë®éÂæûÁ≤µË™ûÂà∞Ëã±Ë™ûÁöÑÊ©üÂô®ÁøªË≠ØÊ®°ÂûãÁöÑÈñãÁôºÂíåË©ï‰º∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï‰æÜËôïÁêÜ‰ΩéË≥áÊ∫êË™ûË®ÄÁøªË≠Ø„ÄÇÊú¨Á†îÁ©∂ÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÈñãÁôº‰∏ÄÂÄãÊ®°ÂûãÔºåÂèØ‰ª•ÊúâÊïàÂú∞Â∞áÁ≤µË™ûÁøªË≠ØÊàêËã±Ë™ûÔºå‰∏¶Ê†πÊìöÊúÄÂÖàÈÄ≤ÁöÑÂïÜÊ•≠Ê®°ÂûãÂ∞çÂÖ∂ÈÄ≤Ë°åË©ï‰º∞„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÈÄöÈÅéÁµêÂêà‰∏çÂêåÁöÑÂèØÁî®Ë™ûÊñôÂ∫´Ôºå‰∏¶ÈÄ≤Ë°åÈ†êËôïÁêÜÂíåÊ∏ÖÁêÜÔºåÂâµÂª∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂπ≥Ë°åË™ûÊñôÂ∫´„ÄÇÊ≠§Â§ñÔºåÈÇÑÈÄöÈÅéÁ∂≤Ë∑ØÁà¨Ëü≤ÂâµÂª∫‰∫Ü‰∏ÄÂÄãÂñÆË™ûÁ≤µË™ûÊï∏ÊìöÈõÜÔºå‰ª•Âπ´Âä©ÂêàÊàêÂπ≥Ë°åË™ûÊñôÂ∫´ÁöÑÁîüÊàê„ÄÇÂú®Êï∏ÊìöÊî∂ÈõÜÈÅéÁ®ã‰πãÂæåÔºåÂ∑≤Á∂ì‰ΩøÁî®‰∫ÜÂ§öÁ®ÆÊñπÊ≥ïÔºåÂåÖÊã¨ÂæÆË™øÊ®°Âûã„ÄÅÂèçÂêëÁøªË≠ØÂíåÊ®°ÂûãÂàáÊèõ„ÄÇÊ®°ÂûãÁöÑÁøªË≠ØÂìÅË≥™Â∑≤‰ΩøÁî®Â§öÁ®ÆÂìÅË≥™ÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞ÔºåÂåÖÊã¨Âü∫ÊñºË©ûÂΩôÁöÑÊåáÊ®ôÔºàSacreBLEU Âíå hLEPORÔºâÂíåÂµåÂÖ•Á©∫ÈñìÊåáÊ®ôÔºàCOMET Âíå BERTscoreÔºâ„ÄÇÊ†πÊìöËá™ÂãïÊåáÊ®ôÔºåÈÅ∏Âá∫ÊúÄ‰Ω≥Ê®°ÂûãÔºå‰∏¶‰ΩøÁî®‰∫∫È°ûË©ï‰º∞Ê°ÜÊû∂ HOPES Ëàá 2 ÂÄãÊúÄ‰Ω≥ÂïÜÊ•≠ÁøªË≠ØÂô®ÈÄ≤Ë°åÊØîËºÉ„ÄÇÊú¨Á†îÁ©∂‰∏≠ÊèêÂá∫ÁöÑÊúÄ‰Ω≥Ê®°ÂûãÔºàNLLB-mBARTÔºâÂÖ∑ÊúâÊ®°ÂûãÂàáÊèõÊ©üÂà∂ÔºåÂú®ÊàëÂÄëÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠ÈÅîÂà∞‰∫ÜËàáÊúÄÂÖàÈÄ≤ÁöÑÂïÜÊ•≠Ê®°ÂûãÔºàÂøÖÊáâÂíåÁôæÂ∫¶ÁøªË≠ØÔºâÁõ∏Áï∂ÁîöËá≥Êõ¥Â•ΩÁöÑËá™ÂãïË©ï‰º∞ÂàÜÊï∏ÔºåSacreBLEU ÂàÜÊï∏ÁÇ∫ 16.8„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑÈñãÁôº‰∫Ü‰∏ÄÂÄãÈñãÊ∫êÁ∂≤Ë∑ØÊáâÁî®Á®ãÂºèÔºåÂÖÅË®±‰ΩøÁî®ËÄÖÂú®Á≤µË™ûÂíåËã±Ë™û‰πãÈñìÈÄ≤Ë°åÁøªË≠ØÔºå‰∏¶Êèê‰æõ‰∏çÂêåÁöÑË®ìÁ∑¥Ê®°ÂûãÔºå‰ª•‰æøÂú®Êú¨Ê¨°Á†îÁ©∂ÁöÑÊ®°ÂûãÂíå‰ΩøÁî®ËÄÖ‰πãÈñìÈÄ≤Ë°åÊúâÊïàÁöÑÊØîËºÉ„ÄÇCANTONMT ÂèØÂú® https://github.com/kenrickkung/CantoneseTranslation Áç≤Âæó

##### **LLM Theory of Mind and Alignment: Opportunities and Risks**
2405.08154v1 by Winnie Street

Large language models (LLMs) are transforming human-computer interaction and
conceptions of artificial intelligence (AI) with their impressive capacities
for conversing and reasoning in natural language. There is growing interest in
whether LLMs have theory of mind (ToM); the ability to reason about the mental
and emotional states of others that is core to human social intelligence. As
LLMs are integrated into the fabric of our personal, professional and social
lives and given greater agency to make decisions with real-world consequences,
there is a critical need to understand how they can be aligned with human
values. ToM seems to be a promising direction of inquiry in this regard.
Following the literature on the role and impacts of human ToM, this paper
identifies key areas in which LLM ToM will show up in human:LLM interactions at
individual and group levels, and what opportunities and risks for alignment are
raised in each. On the individual level, the paper considers how LLM ToM might
manifest in goal specification, conversational adaptation, empathy and
anthropomorphism. On the group level, it considers how LLM ToM might facilitate
collective alignment, cooperation or competition, and moral judgement-making.
The paper lays out a broad spectrum of potential implications and suggests the
most pressing areas for future research.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ê≠£‰ª•ÂÖ∂‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËá™ÁÑ∂Ë™ûË®ÄÂ∞çË©±ÂíåÊé®ÁêÜËÉΩÂäõÔºåËΩâËÆä‰∫Ü‰∫∫Ê©ü‰∫íÂãï‰ª•ÂèäÂ∞ç‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑËßÄÂøµ„ÄÇÂ∞çÊñº LLM ÊòØÂê¶ÂÖ∑ÂÇôÂøÉÊô∫ÁêÜË´ñ (ToM) ‚îÄ‚îÄ Âç≥Êé®ÁêÜ‰ªñ‰∫∫ÂøÉÁêÜÂíåÊÉÖÁ∑íÁãÄÊÖãÁöÑËÉΩÂäõÔºåÈÄôÈ†Ö‰∫∫È°ûÁ§æÊúÉÊô∫ÊÖßÁöÑÊ†∏ÂøÉ ‚îÄ‚îÄ ÈÄêÊº∏ÂºïËµ∑ÈóúÊ≥®„ÄÇÈö®Ëëó LLM ËûçÂÖ•ÊàëÂÄëÂÄã‰∫∫„ÄÅÂ∞àÊ•≠ÂíåÁ§æÊúÉÁîüÊ¥ªÁöÑÊû∂Êßã‰∏≠Ôºå‰∏¶Ë≥¶‰∫àÂÖ∂Êõ¥Â§ßÁöÑËá™‰∏ªÊ¨ä‰æÜÂÅöÂá∫ÂÖ∑ÊúâÁèæÂØ¶‰∏ñÁïåÂæåÊûúÁöÑÊ±∫Á≠ñÔºåËø´ÂàáÈúÄË¶Å‰∫ÜËß£Â¶Ç‰ΩïËÆì LLM Ëàá‰∫∫È°ûÂÉπÂÄºËßÄ‰øùÊåÅ‰∏ÄËá¥„ÄÇÂú®ÈÄôÊñπÈù¢ÔºåToM ‰ºº‰πéÊòØ‰∏ÄÂÄãÂæàÊúâÂâçÊôØÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇÊú¨ÊñáÈÅµÂæ™ÈóúÊñº‰∫∫È°û ToM ÁöÑËßíËâ≤ÂíåÂΩ±ÈüøÁöÑÊñáÁçªÔºåÊâæÂá∫ LLM ToM Â∞áÂú®ÂÄã‰∫∫ÂíåÁæ§È´îÂ±§Èù¢ÁöÑ LLM ‰∫∫È°û‰∫íÂãï‰∏≠Âá∫ÁèæÁöÑ‰∏ªË¶ÅÈ†òÂüüÔºå‰ª•ÂèäÂú®ÊØèÂÄãÈ†òÂüü‰∏≠Âá∫Áèæ‰∫ÜÂì™‰∫õÊ©üÊúÉÂíåÈ¢®Èö™„ÄÇÂú®ÂÄã‰∫∫Â±§Èù¢ÔºåÊú¨ÊñáÊé¢Ë®é LLM ToM Â¶Ç‰ΩïË°®ÁèæÂú®ÁõÆÊ®ôË¶èÊ†º„ÄÅÂ∞çË©±ÈÅ©Êáâ„ÄÅÂêåÁêÜÂøÉÂíåÊì¨‰∫∫Âåñ‰∏≠„ÄÇÂú®Áæ§È´îÂ±§Èù¢ÔºåÂÆÉÊé¢Ë®é LLM ToM Â¶Ç‰Ωï‰øÉÈÄ≤ÈõÜÈ´îÂçîË™ø„ÄÅÂêà‰ΩúÊàñÁ´∂Áà≠Ôºå‰ª•ÂèäÈÅìÂæ∑Âà§Êñ∑ÁöÑÂà∂ÂÆö„ÄÇÊú¨ÊñáÂàóÂá∫‰∫ÜÂª£Ê≥õÁöÑÊΩõÂú®ÂΩ±ÈüøÔºå‰∏¶Âª∫Ë≠∞Êú™‰æÜÁ†îÁ©∂ÊúÄËø´ÂàáÁöÑÈ†òÂüü„ÄÇ

##### **Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness**
2405.08151v1 by Mingchen Li, Zaifu Zhan, Han Yang, Yongkang Xiao, Jiatan Huang, Rui Zhang

Large language models (LLM) have demonstrated remarkable capabilities in
various biomedical natural language processing (NLP) tasks, leveraging the
demonstration within the input context to adapt to new tasks. However, LLM is
sensitive to the selection of demonstrations. To address the hallucination
issue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by
retrieving pertinent information from an established database. Nonetheless,
existing research work lacks rigorous evaluation of the impact of
retrieval-augmented large language models on different biomedical NLP tasks.
This deficiency makes it challenging to ascertain the capabilities of RAL
within the biomedical domain. Moreover, the outputs from RAL are affected by
retrieving the unlabeled, counterfactual, or diverse knowledge that is not well
studied in the biomedical domain. However, such knowledge is common in the real
world. Finally, exploring the self-awareness ability is also crucial for the
RAL system. So, in this paper, we systematically investigate the impact of RALs
on 5 different biomedical tasks (triple extraction, link prediction,
classification, question answering, and natural language inference). We analyze
the performance of RALs in four fundamental abilities, including unlabeled
robustness, counterfactual robustness, diverse robustness, and negative
awareness. To this end, we proposed an evaluation framework to assess the RALs'
performance on different biomedical NLP tasks and establish four different
testbeds based on the aforementioned fundamental abilities. Then, we evaluate 3
representative LLMs with 3 different retrievers on 5 tasks over 9 datasets.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÂêÑÁ®ÆÁîüÁâ©ÈÜ´Â≠∏Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈùûÂá°ÁöÑËÉΩÂäõÔºåÂà©Áî®Ëº∏ÂÖ•ÂÖßÂÆπ‰∏≠ÁöÑÁ§∫ÁØÑ‰æÜÈÅ©ÊáâÊñ∞‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåLLM Â∞çÁ§∫ÁØÑÁöÑÈÅ∏ÊìáÂæàÊïèÊÑü„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ LLM ‰∏≠Âõ∫ÊúâÁöÑÂπªË¶∫ÂïèÈ°åÔºåÊ™¢Á¥¢Â¢ûÂº∑ LLM (RAL) Êèê‰æõ‰∫Ü‰∏ÄÂÄãËß£Ê±∫ÊñπÊ°àÔºåÂæûÊó¢ÂÆöÁöÑË≥áÊñôÂ∫´‰∏≠Ê™¢Á¥¢Áõ∏ÈóúË≥áË®ä„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁèæÊúâÁöÑÁ†îÁ©∂Â∑•‰ΩúÁº∫‰πèÂ∞çÊ™¢Á¥¢Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∞ç‰∏çÂêåÁîüÁâ©ÈÜ´Â≠∏ NLP ‰ªªÂãôÁöÑÂΩ±ÈüøÈÄ≤Ë°åÂö¥Ê†ºË©ï‰º∞„ÄÇÈÄôÁ®ÆÁº∫Èô∑‰ΩøÂæóÈõ£‰ª•Á¢∫ÂÆö RAL Âú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüü‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåRAL ÁöÑËº∏Âá∫ÂèóÂà∞Ê™¢Á¥¢Êú™Ê®ôË®ò„ÄÅÂèç‰∫ãÂØ¶ÊàñÂ§öÊ®£ÂåñÁü•Ë≠òÁöÑÂΩ±ÈüøÔºåËÄåÈÄô‰∫õÁü•Ë≠òÂú®ÁîüÁâ©ÈÜ´Â≠∏È†òÂüü‰∏≠‰∏¶Êú™ÂæóÂà∞ÂæàÂ•ΩÁöÑÁ†îÁ©∂„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÁü•Ë≠òÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÂæàÂ∏∏Ë¶ã„ÄÇÊúÄÂæåÔºåÊé¢Á¥¢Ëá™ÊàëÊÑèË≠òËÉΩÂäõÂ∞çÊñº RAL Á≥ªÁµ±‰æÜË™™‰πüËá≥ÈóúÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±Âú∞Á†îÁ©∂‰∫Ü RAL Â∞ç 5 ÂÄã‰∏çÂêåÁîüÁâ©ÈÜ´Â≠∏‰ªªÂãôÔºà‰∏âÂÖÉÁµÑÊèêÂèñ„ÄÅÈÄ£ÁµêÈ†êÊ∏¨„ÄÅÂàÜÈ°û„ÄÅÂïèÈ°åÂõûÁ≠îÂíåËá™ÁÑ∂Ë™ûË®ÄÊé®ÁêÜÔºâÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂàÜÊûê‰∫Ü RAL Âú®ÂõõÈ†ÖÂü∫Êú¨ËÉΩÂäõ‰∏≠ÁöÑË°®ÁèæÔºåÂåÖÊã¨Êú™Ê®ôË®òÈ≠ØÊ£íÊÄß„ÄÅÂèç‰∫ãÂØ¶È≠ØÊ£íÊÄß„ÄÅÂ§öÊ®£ÊÄßÈ≠ØÊ£íÊÄßÂíåË≤†Èù¢ÊÑèË≠ò„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãË©ï‰º∞Ê°ÜÊû∂‰æÜË©ï‰º∞ RAL Âú®‰∏çÂêåÁîüÁâ©ÈÜ´Â≠∏ NLP ‰ªªÂãô‰∏äÁöÑË°®ÁèæÔºå‰∏¶Ê†πÊìö‰∏äËø∞Âü∫Êú¨ËÉΩÂäõÂª∫Á´ã‰∫ÜÂõõÂÄã‰∏çÂêåÁöÑÊ∏¨Ë©¶Âπ≥Âè∞„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú® 9 ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑ 5 ÂÄã‰ªªÂãô‰∏≠Ë©ï‰º∞‰∫Ü 3 ÂÄã‰∏çÂêåÁöÑÊ™¢Á¥¢Âô®Âíå 3 ÂÄã‰ª£Ë°®ÊÄß LLM„ÄÇ

##### **Many-Shot Regurgitation (MSR) Prompting**
2405.08134v1 by Shashank Sonkar, Richard G. Baraniuk

We introduce Many-Shot Regurgitation (MSR) prompting, a new black-box
membership inference attack framework for examining verbatim content
reproduction in large language models (LLMs). MSR prompting involves dividing
the input text into multiple segments and creating a single prompt that
includes a series of faux conversation rounds between a user and a language
model to elicit verbatim regurgitation. We apply MSR prompting to diverse text
sources, including Wikipedia articles and open educational resources (OER)
textbooks, which provide high-quality, factual content and are continuously
updated over time. For each source, we curate two dataset types: one that LLMs
were likely exposed to during training ($D_{\rm pre}$) and another consisting
of documents published after the models' training cutoff dates ($D_{\rm
post}$). To quantify the occurrence of verbatim matches, we employ the Longest
Common Substring algorithm and count the frequency of matches at different
length thresholds. We then use statistical measures such as Cliff's delta,
Kolmogorov-Smirnov (KS) distance, and Kruskal-Wallis H test to determine
whether the distribution of verbatim matches differs significantly between
$D_{\rm pre}$ and $D_{\rm post}$. Our findings reveal a striking difference in
the distribution of verbatim matches between $D_{\rm pre}$ and $D_{\rm post}$,
with the frequency of verbatim reproduction being significantly higher when
LLMs (e.g. GPT models and LLaMAs) are prompted with text from datasets they
were likely trained on. For instance, when using GPT-3.5 on Wikipedia articles,
we observe a substantial effect size (Cliff's delta $= -0.984$) and a large KS
distance ($0.875$) between the distributions of $D_{\rm pre}$ and $D_{\rm
post}$. Our results provide compelling evidence that LLMs are more prone to
reproducing verbatim content when the input text is likely sourced from their
training data.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§öÈáçÊèêÁ§∫ÂºèÂõûÈ•ã (MSR)ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑÈªëÁõíÊúÉÂì°Êé®Ë´ñÊîªÊìäÊû∂ÊßãÔºåÁî®ÊñºÊ™¢Êü•Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÈÄêÂ≠óÂÖßÂÆπË§áË£Ω„ÄÇMSR ÊèêÁ§∫ÂºèÊ∂âÂèäÂ∞áËº∏ÂÖ•ÊñáÂ≠óÂàÜÊàêÂ§öÂÄãÂçÄÊÆµÔºå‰∏¶Âª∫Á´ã‰∏ÄÂÄãÂñÆ‰∏ÄÊèêÁ§∫ÂºèÔºåÂÖ∂‰∏≠ÂåÖÂê´‰ΩøÁî®ËÄÖËàáË™ûË®ÄÊ®°Âûã‰πãÈñì‰∏ÄÁ≥ªÂàóËôõÂÅáÁöÑÂ∞çË©±ÂõûÂêàÔºå‰ª•ÂºïÁôºÈÄêÂ≠óÂõûÈ•ã„ÄÇÊàëÂÄëÂ∞á MSR ÊèêÁ§∫ÂºèÊáâÁî®Êñº‰∏çÂêåÁöÑÊñáÂ≠ó‰æÜÊ∫êÔºåÂåÖÊã¨Á∂≠Âü∫ÁôæÁßëÊñáÁ´†ÂíåÈñãÊîæÊïôËÇ≤Ë≥áÊ∫ê (OER) ÊïôÁßëÊõ∏ÔºåÈÄô‰∫õ‰æÜÊ∫êÊèê‰æõ‰∫ÜÈ´òÂìÅË≥™ÁöÑ‰∫ãÂØ¶ÂÖßÂÆπÔºå‰∏¶ÊúÉÊåÅÁ∫åÊõ¥Êñ∞„ÄÇÂ∞çÊñºÊØèÂÄã‰æÜÊ∫êÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫ÜÂÖ©Á®ÆË≥áÊñôÈõÜÈ°ûÂûãÔºö‰∏ÄÁ®ÆÊòØ LLM Âú®Ë®ìÁ∑¥ÊúüÈñìÂèØËÉΩÊé•Ëß∏Âà∞ÁöÑ ($D_{\rm pre}$)ÔºåÂè¶‰∏ÄÁ®ÆÂâáÂåÖÂê´Âú®Ê®°ÂûãË®ìÁ∑¥Êà™Ê≠¢Êó•ÊúüÂæåÁôºÂ∏ÉÁöÑÊñá‰ª∂ ($D_{\rm post}$)„ÄÇÁÇ∫‰∫ÜÈáèÂåñÈÄêÂ≠óÂåπÈÖçÁöÑÁôºÁîüÔºåÊàëÂÄëÊé°Áî®ÊúÄÈï∑ÂÖ¨ÂÖ±Â≠êÂ≠ó‰∏≤ÊºîÁÆóÊ≥ïÔºå‰∏¶Ë®àÁÆó‰∏çÂêåÈï∑Â∫¶ÈñæÂÄºÁöÑÂåπÈÖçÈ†ªÁéá„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Áµ±Ë®àÈáèÂ∫¶Ôºå‰æãÂ¶Ç Cliff's delta„ÄÅKolmogorov-Smirnov (KS) Ë∑ùÈõ¢Âíå Kruskal-Wallis H Ê™¢ÂÆöÔºå‰æÜÁ¢∫ÂÆöÈÄêÂ≠óÂåπÈÖçÁöÑÂàÜÂ∏ÉÊòØÂê¶Âú® $D_{\rm pre}$ Âíå $D_{\rm post}$ ‰πãÈñìÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÊè≠Á§∫‰∫Ü $D_{\rm pre}$ Âíå $D_{\rm post}$ ‰πãÈñìÈÄêÂ≠óÂåπÈÖçÂàÜÂ∏ÉÁöÑÈ°ØËëóÂ∑ÆÁï∞ÔºåÁï∂‰ΩøÁî® LLMÔºà‰æãÂ¶Ç GPT Ê®°ÂûãÂíå LLaMAÔºâÊèêÁ§∫‰æÜËá™‰ªñÂÄëÂèØËÉΩÂèóÈÅéË®ìÁ∑¥ÁöÑË≥áÊñôÈõÜÁöÑÊñáÂ≠óÊôÇÔºåÈÄêÂ≠óË§áË£ΩÁöÑÈ†ªÁéáÊúÉÈ°ØËëóÊèêÈ´ò„ÄÇ‰æãÂ¶ÇÔºåÂú®Á∂≠Âü∫ÁôæÁßëÊñáÁ´†‰∏≠‰ΩøÁî® GPT-3.5 ÊôÇÔºåÊàëÂÄëËßÄÂØüÂà∞ $D_{\rm pre}$ Âíå $D_{\rm post}$ ÁöÑÂàÜÂ∏É‰πãÈñìÊúâÈ°ØËëóÁöÑÊïàÊûúÂ§ßÂ∞èÔºàCliff's delta $= -0.984$ÔºâÂíåËºÉÂ§ßÁöÑ KS Ë∑ùÈõ¢ ($0.875$Ôºâ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊèê‰æõ‰∫Ü‰ª§‰∫∫‰ø°ÊúçÁöÑË≠âÊìöÔºåË≠âÊòéÁï∂Ëº∏ÂÖ•ÊñáÂ≠óÂèØËÉΩ‰æÜËá™ÂÖ∂Ë®ìÁ∑¥Ë≥áÊñôÊôÇÔºåLLM Êõ¥ÂÆπÊòìË§áË£ΩÈÄêÂ≠óÂÖßÂÆπ„ÄÇ</paragraph>

##### **When factorization meets argumentation: towards argumentative explanations**
2405.08131v1 by Jinfeng Zhong, Elsa Negre

Factorization-based models have gained popularity since the Netflix challenge
{(2007)}. Since that, various factorization-based models have been developed
and these models have been proven to be efficient in predicting users' ratings
towards items. A major concern is that explaining the recommendations generated
by such methods is non-trivial because the explicit meaning of the latent
factors they learn are not always clear. In response, we propose a novel model
that combines factorization-based methods with argumentation frameworks (AFs).
The integration of AFs provides clear meaning at each stage of the model,
enabling it to produce easily understandable explanations for its
recommendations. In this model, for every user-item interaction, an AF is
defined in which the features of items are considered as arguments, and the
users' ratings towards these features determine the strength and polarity of
these arguments. This perspective allows our model to treat feature attribution
as a structured argumentation procedure, where each calculation is marked with
explicit meaning, enhancing its inherent interpretability. Additionally, our
framework seamlessly incorporates side information, such as user contexts,
leading to more accurate predictions. We anticipate at least three practical
applications for our model: creating explanation templates, providing
interactive explanations, and generating contrastive explanations. Through
testing on real-world datasets, we have found that our model, along with its
variants, not only surpasses existing argumentation-based methods but also
competes effectively with current context-free and context-aware methods.

ÊëòË¶ÅÔºö<paragraph>Ëá™ Netflix ÊåëÊà∞Ë≥Ω {(2007)} ‰ª•‰æÜÔºåÂü∫ÊñºÂàÜËß£ÁöÑÊ®°ÂûãË∂ä‰æÜË∂äÂèóÊ≠°Ëøé„ÄÇËá™Ê≠§ÔºåÂêÑÁ®ÆÂü∫ÊñºÂàÜËß£ÁöÑÊ®°ÂûãÂ∑≤Ë¢´ÈñãÁôºÂá∫‰æÜÔºåÈÄô‰∫õÊ®°ÂûãÂ∑≤Ë¢´Ë≠âÊòéÂèØ‰ª•ÊúâÊïàÈ†êÊ∏¨‰ΩøÁî®ËÄÖÂ∞çÂïÜÂìÅÁöÑË©ïÂàÜ„ÄÇ‰∏ÄÂÄã‰∏ªË¶ÅÁöÑÂïèÈ°åÊòØÔºåËß£ÈáãÊ≠§È°ûÊñπÊ≥ïÁî¢ÁîüÁöÑÊé®Ëñ¶‰∏¶ÈùûÊòì‰∫ãÔºåÂõ†ÁÇ∫‰ªñÂÄëÂ≠∏ÁøíÂà∞ÁöÑÊΩõÂú®Âõ†Á¥†ÁöÑÊòéÁ¢∫Âê´Áæ©‰∏¶‰∏çÁ∏ΩÊòØÊ∏ÖÊ•ö„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ®°ÂûãÔºåÂ∞áÂü∫ÊñºÂàÜËß£ÁöÑÊñπÊ≥ïËàáË´ñË≠âÊû∂Êßã (AF) ÁµêÂêàËµ∑‰æÜ„ÄÇAF ÁöÑÊï¥ÂêàÂú®Ê®°ÂûãÁöÑÊØèÂÄãÈöéÊÆµÊèê‰æõÊ∏ÖÊô∞ÁöÑÂê´Áæ©Ôºå‰ΩøÂÖ∂ËÉΩÂ§†ÁÇ∫ÂÖ∂Êé®Ëñ¶Áî¢ÁîüÂÆπÊòìÁêÜËß£ÁöÑËß£Èáã„ÄÇÂú®Ê≠§Ê®°Âûã‰∏≠ÔºåÂ∞çÊñºÊØèÂÄã‰ΩøÁî®ËÄÖËàáÂïÜÂìÅÁöÑ‰∫íÂãïÔºåÂÆöÁæ©‰∫Ü‰∏ÄÂÄã AFÔºåÂÖ∂‰∏≠ÂïÜÂìÅÁöÑÁâπÊÄßË¢´Ë¶ñÁÇ∫Ë´ñË≠âÔºåËÄå‰ΩøÁî®ËÄÖÂ∞çÈÄô‰∫õÁâπÊÄßÁöÑË©ïÂàÜÊ±∫ÂÆö‰∫ÜÈÄô‰∫õË´ñË≠âÁöÑÂº∑Â∫¶ÂíåÊ•µÊÄß„ÄÇÈÄôÂÄãËßÄÈªû‰ΩøÊàëÂÄëÁöÑÊ®°ÂûãËÉΩÂ§†Â∞áÁâπÂæµÊ≠∏Âõ†Ë¶ñÁÇ∫‰∏ÄÂÄãÁµêÊßãÂåñÁöÑË´ñË≠âÁ®ãÂ∫èÔºåÂÖ∂‰∏≠ÊØè‰∏ÄÂÄãË®àÁÆóÈÉΩÊ®ôË®òÊúâÊòéÁ¢∫ÁöÑÂê´Áæ©ÔºåÂ¢ûÂº∑ÂÖ∂ÂÖßÂú®ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂ÁÑ°Á∏´Âú∞Êï¥Âêà‰∫ÜÂÅ¥ÈÇäË≥áË®äÔºå‰æãÂ¶Ç‰ΩøÁî®ËÄÖËÉåÊôØÔºåÂæûËÄåÁî¢ÁîüÊõ¥Ê∫ñÁ¢∫ÁöÑÈ†êÊ∏¨„ÄÇÊàëÂÄëÈ†êÊúüÊàëÂÄëÁöÑÊ®°ÂûãËá≥Â∞ëÊúâ‰∏âÂÄãÂØ¶ÈöõÊáâÁî®ÔºöÂª∫Á´ãËß£ÈáãÁØÑÊú¨„ÄÅÊèê‰æõ‰∫íÂãïÂºèËß£Èáã‰ª•ÂèäÁî¢ÁîüÂ∞çÊØîÂºèËß£Èáã„ÄÇÈÄèÈÅéÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶ÔºåÊàëÂÄëÁôºÁèæÊàëÂÄëÁöÑÊ®°ÂûãÂèäÂÖ∂ËÆäÈ´î‰∏çÂÉÖË∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÂü∫ÊñºË´ñË≠âÁöÑÊñπÊ≥ïÔºåËÄå‰∏îÈÇÑËÉΩÊúâÊïàÂú∞ËàáÁï∂ÂâçÁöÑÁÑ°ËÉåÊôØÂíåÊúâËÉåÊôØÊÑüÁü•ÁöÑÊñπÊ≥ïÁ´∂Áà≠„ÄÇ</paragraph>

##### **From Questions to Insightful Answers: Building an Informed Chatbot for University Resources**
2405.08120v1 by Subash Neupane, Elias Hossain, Jason Keith, Himanshu Tripathi, Farbod Ghiasi, Noorbakhsh Amiri Golilarz, Amin Amirlatifi, Sudip Mittal, Shahram Rahimi

This paper presents BARKPLUG V.2, a Large Language Model (LLM)-based chatbot
system built using Retrieval Augmented Generation (RAG) pipelines to enhance
the user experience and access to information within academic settings.The
objective of BARKPLUG V.2 is to provide information to users about various
campus resources, including academic departments, programs, campus facilities,
and student resources at a university setting in an interactive fashion. Our
system leverages university data as an external data corpus and ingests it into
our RAG pipelines for domain-specific question-answering tasks. We evaluate the
effectiveness of our system in generating accurate and pertinent responses for
Mississippi State University, as a case study, using quantitative measures,
employing frameworks such as Retrieval Augmented Generation Assessment(RAGAS).
Furthermore, we evaluate the usability of this system via subjective
satisfaction surveys using the System Usability Scale (SUS). Our system
demonstrates impressive quantitative performance, with a mean RAGAS score of
0.96, and experience, as validated by usability assessments.

ÊëòË¶ÅÔºöÊú¨Ë´ñÊñáÊèêÂá∫ BARKPLUG V.2Ôºå‰∏ÄÂÄãÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑËÅäÂ§©Ê©üÂô®‰∫∫Á≥ªÁµ±Ôºå‰ΩøÁî®Ê™¢Á¥¢Êì¥Â¢ûÁîüÊàê (RAG) ÁÆ°Á∑öÂª∫ÁΩÆÔºå‰ª•Â¢ûÂº∑‰ΩøÁî®ËÄÖÈ´îÈ©óÂíåÂú®Â≠∏Ë°ìÁí∞Â¢É‰∏≠Áç≤ÂèñË≥áË®ä„ÄÇBARKPLUG V.2 ÁöÑÁõÆÊ®ôÊòØÈÄèÈÅé‰∫íÂãïÊñπÂºèÔºåÂêë‰ΩøÁî®ËÄÖÊèê‰æõÈóúÊñºÂêÑÁ®ÆÊ†°ÂúíË≥áÊ∫êÁöÑË≥áË®äÔºåÂåÖÊã¨Â≠∏Ë°ìÈÉ®ÈñÄ„ÄÅË™≤Á®ã„ÄÅÊ†°ÂúíË®≠ÊñΩÂíåÂ§ßÂ≠∏Áí∞Â¢É‰∏≠ÁöÑÂ≠∏ÁîüË≥áÊ∫ê„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Âà©Áî®Â§ßÂ≠∏Ë≥áÊñô‰ΩúÁÇ∫Â§ñÈÉ®Ë≥áÊñôË™ûÊñôÂ∫´Ôºå‰∏¶Â∞áÂÖ∂Â∞éÂÖ•ÊàëÂÄëÁöÑ RAG ÁÆ°Á∑öÔºå‰ª•ÈÄ≤Ë°åÁâπÂÆöÈ†òÂüüÁöÑÂïèÁ≠î‰ªªÂãô„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÁ≥ªÁµ±Âú®ÁÇ∫ÂØÜË•øË•øÊØîÂ∑ûÁ´ãÂ§ßÂ≠∏Áî¢ÁîüÊ∫ñÁ¢∫‰∏îÁõ∏ÈóúÁöÑÂõûÊáâÁöÑÊúâÊïàÊÄßÔºå‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂Ôºå‰ΩøÁî®ÈáèÂåñÊ∏¨ÈáèÔºåÊé°Áî®Ê™¢Á¥¢Êì¥Â¢ûÁîüÊàêË©ï‰º∞ (RAGAS) Á≠âÊû∂Êßã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅé‰ΩøÁî®Á≥ªÁµ±ÂèØÁî®ÊÄßÈáèË°® (SUS) ÁöÑ‰∏ªËßÄÊªøÊÑèÂ∫¶Ë™øÊü•ÔºåË©ï‰º∞Ê≠§Á≥ªÁµ±ÁöÑÂèØÁî®ÊÄß„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Ë°®ÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÈáèÂåñÊïàËÉΩÔºåRAGAS Âπ≥ÂùáÂæóÂàÜÁÇ∫ 0.96Ôºå‰∏îÁ∂ìÈ©óÁ∂ìÂèØÁî®ÊÄßË©ï‰º∞È©óË≠â„ÄÇ

##### **KET-QA: A Dataset for Knowledge Enhanced Table Question Answering**
2405.08099v1 by Mengkang Hu, Haoyu Dong, Ping Luo, Shi Han, Dongmei Zhang

Due to the concise and structured nature of tables, the knowledge contained
therein may be incomplete or missing, posing a significant challenge for table
question answering (TableQA) and data analysis systems. Most existing datasets
either fail to address the issue of external knowledge in TableQA or only
utilize unstructured text as supplementary information for tables. In this
paper, we propose to use a knowledge base (KB) as the external knowledge source
for TableQA and construct a dataset KET-QA with fine-grained gold evidence
annotation. Each table in the dataset corresponds to a sub-graph of the entire
KB, and every question requires the integration of information from both the
table and the sub-graph to be answered. To extract pertinent information from
the vast knowledge sub-graph and apply it to TableQA, we design a
retriever-reasoner structured pipeline model. Experimental results demonstrate
that our model consistently achieves remarkable relative performance
improvements ranging from 1.9 to 6.5 times and absolute improvements of 11.66%
to 44.64% on EM scores across three distinct settings (fine-tuning, zero-shot,
and few-shot), in comparison with solely relying on table information in the
traditional TableQA manner. However, even the best model achieves a 60.23% EM
score, which still lags behind the human-level performance, highlighting the
challenging nature of KET-QA for the question-answering community. We also
provide a human evaluation of error cases to analyze further the aspects in
which the model can be improved. Project page: https://ketqa.github.io/.

ÊëòË¶ÅÔºö<paragraph>Áî±ÊñºË°®Ê†ºÁ∞°ÊΩî‰∏îÁµêÊßãÂåñÁöÑÁâπÊÄßÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁöÑÁü•Ë≠òÂèØËÉΩ‰∏çÂÆåÊï¥ÊàñÁº∫Â§±ÔºåÂ∞çË°®Ê†ºÂïèÁ≠î (TableQA) ÂíåË≥áÊñôÂàÜÊûêÁ≥ªÁµ±ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂ§ßÂ§öÊï∏ÁèæÊúâË≥áÊñôÈõÜÁÑ°Ê≥ïËß£Ê±∫ TableQA ‰∏≠Â§ñÈÉ®Áü•Ë≠òÁöÑÂïèÈ°åÔºåÊàñËÄÖÂÉÖÂ∞áÈùûÁµêÊßãÂåñÊñáÂ≠óÁî®‰ΩúË°®Ê†ºÁöÑË£úÂÖÖË≥áË®ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Áü•Ë≠òÂ∫´ (KB) ‰ΩúÁÇ∫ TableQA ÁöÑÂ§ñÈÉ®Áü•Ë≠ò‰æÜÊ∫êÔºå‰∏¶Âª∫Êßã‰∏ÄÂÄãÂÖ∑ÊúâÁ¥∞Á≤íÂ∫¶ÈªÉÈáëË≠âÊìöË®ªËß£ÁöÑË≥áÊñôÈõÜ KET-QA„ÄÇË≥áÊñôÈõÜ‰∏≠ÁöÑÊØèÂÄãË°®Ê†ºÈÉΩÂ∞çÊáâÊñºÊï¥ÂÄã KB ÁöÑÂ≠êÂúñÔºåÊØèÂÄãÂïèÈ°åÈÉΩÈúÄË¶ÅÊï¥Âêà‰æÜËá™Ë°®Ê†ºÂíåÂ≠êÂúñÁöÑË≥áË®äÊâçËÉΩÂõûÁ≠î„ÄÇÁÇ∫‰∫ÜÂæûÈæêÂ§ßÁöÑÁü•Ë≠òÂ≠êÂúñ‰∏≠ÊèêÂèñÁõ∏ÈóúË≥áË®ä‰∏¶Â∞áÂÖ∂ÊáâÁî®Êñº TableQAÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ™¢Á¥¢Âô®Êé®ÁêÜÁµêÊßãÁÆ°ÈÅìÊ®°Âûã„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®‰∏âÂÄã‰∏çÂêåÁöÑË®≠ÂÆöÔºàÂæÆË™ø„ÄÅÈõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÊ¨°Â≠∏ÁøíÔºâ‰∏≠ÔºåËàáÂÇ≥Áµ± TableQA ÊñπÂºèÂÉÖ‰æùË≥¥Ë°®Ê†ºË≥áË®äÁõ∏ÊØîÔºåÂßãÁµÇÈÉΩËÉΩÁç≤ÂæóÈ°ØËëóÁöÑÁõ∏Â∞çÊïàËÉΩÊèêÂçáÔºåÁØÑÂúçÂæû 1.9 ÂÄçÂà∞ 6.5 ÂÄçÔºåEM ÂæóÂàÜÁµïÂ∞çÊèêÂçá 11.66% Âà∞ 44.64%„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÊòØÊúÄÂ•ΩÁöÑÊ®°Âûã‰πüÂè™ÈÅîÂà∞ 60.23% ÁöÑ EM ÂæóÂàÜÔºåÈÄô‰ªçÁÑ∂ËêΩÂæåÊñº‰∫∫È°ûÁöÑË°®ÁèæÔºåÁ™ÅÈ°Ø‰∫Ü KET-QA Â∞çÂïèÁ≠îÁ§æÁæ§ÁöÑÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫ÜÈåØË™§Ê°à‰æãÁöÑ‰∫∫È°ûË©ï‰º∞Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêÊ®°ÂûãÂèØ‰ª•ÊîπÈÄ≤ÁöÑÊñπÈù¢„ÄÇÂ∞àÊ°àÈ†ÅÈù¢Ôºöhttps://ketqa.github.io/„ÄÇ</paragraph>

##### **MambaOut: Do We Really Need Mamba for Vision?**
2405.07992v2 by Weihao Yu, Xinchao Wang

Mamba, an architecture with RNN-like token mixer of state space model (SSM),
was recently introduced to address the quadratic complexity of the attention
mechanism and subsequently applied to vision tasks. Nevertheless, the
performance of Mamba for vision is often underwhelming when compared with
convolutional and attention-based models. In this paper, we delve into the
essence of Mamba, and conceptually conclude that Mamba is ideally suited for
tasks with long-sequence and autoregressive characteristics. For vision tasks,
as image classification does not align with either characteristic, we
hypothesize that Mamba is not necessary for this task; Detection and
segmentation tasks are also not autoregressive, yet they adhere to the
long-sequence characteristic, so we believe it is still worthwhile to explore
Mamba's potential for these tasks. To empirically verify our hypotheses, we
construct a series of models named MambaOut through stacking Mamba blocks while
removing their core token mixer, SSM. Experimental results strongly support our
hypotheses. Specifically, our MambaOut model surpasses all visual Mamba models
on ImageNet image classification, indicating that Mamba is indeed unnecessary
for this task. As for detection and segmentation, MambaOut cannot match the
performance of state-of-the-art visual Mamba models, demonstrating the
potential of Mamba for long-sequence visual tasks. The code is available at
https://github.com/yuweihao/MambaOut

ÊëòË¶ÅÔºöMamba ÊòØ‰∏ÄÁ®ÆÊû∂ÊßãÔºåÂÖ∑ÊúâÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) ÁöÑÈ°û‰ºº RNN ÁöÑ‰ª£Âπ£Ê∑∑ÂêàÂô®ÔºåÊúÄËøëË¢´ÂºïÂÖ•‰ª•Ëß£Ê±∫Ê≥®ÊÑèÂäõÊ©üÂà∂ÁöÑ‰∫åÊ¨°Ë§áÈõúÊÄßÔºå‰∏¶Èö®ÂæåÊáâÁî®ÊñºË¶ñË¶∫‰ªªÂãô„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåËàáÂü∫ÊñºÂç∑Á©çÂíåÊ≥®ÊÑèÂäõÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåMamba Âú®Ë¶ñË¶∫ÊñπÈù¢ÁöÑË°®ÁèæÂæÄÂæÄ‰ª§‰∫∫Â§±Êúõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é Mamba ÁöÑÊú¨Ë≥™Ôºå‰∏¶Âú®Ê¶ÇÂøµ‰∏äÂæóÂá∫ÁµêË´ñÔºåMamba ÈùûÂ∏∏ÈÅ©ÂêàÂÖ∑ÊúâÈï∑Â∫èÂàóÂíåËá™Ëø¥Ê≠∏ÁâπÊÄßÁöÑ‰ªªÂãô„ÄÇÂ∞çÊñºË¶ñË¶∫‰ªªÂãôÔºåÁî±ÊñºÂúñÂÉèÂàÜÈ°û‰∏çÁ¨¶Âêà‰ªª‰ΩïÁâπÂæµÔºåÊàëÂÄëÂÅáË®≠ Mamba Â∞çÊ≠§‰ªªÂãô‰∏¶ÈùûÂøÖË¶ÅÔºõÊ™¢Ê∏¨ÂíåÂàÜÂâ≤‰ªªÂãô‰πü‰∏çÊòØËá™Ëø¥Ê≠∏ÁöÑÔºå‰ΩÜÂÆÉÂÄëÁ¨¶ÂêàÈï∑Â∫èÂàóÁâπÂæµÔºåÂõ†Ê≠§ÊàëÂÄëË™çÁÇ∫Êé¢Á¥¢ Mamba Âú®ÈÄô‰∫õ‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ‰ªçÁÑ∂ÊòØÊúâÂÉπÂÄºÁöÑ„ÄÇÁÇ∫‰∫ÜÁ∂ìÈ©óÈ©óË≠âÊàëÂÄëÁöÑÂÅáË®≠ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÁ≥ªÂàóÂêçÁÇ∫ MambaOut ÁöÑÊ®°ÂûãÔºåÈÄöÈÅéÂ†ÜÁñä Mamba Â°äÂêåÊôÇÁßªÈô§ÂÖ∂Ê†∏ÂøÉ‰ª£Âπ£Ê∑∑ÂêàÂô® SSM„ÄÇÂØ¶È©óÁµêÊûúÊúâÂäõÂú∞ÊîØÊåÅ‰∫ÜÊàëÂÄëÁöÑÂÅáË®≠„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑ MambaOut Ê®°ÂûãÂú® ImageNet ÂúñÂÉèÂàÜÈ°ûÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÊâÄÊúâË¶ñË¶∫ Mamba Ê®°ÂûãÔºåË°®Êòé Mamba Â∞çÊñºÊ≠§‰ªªÂãôÁ¢∫ÂØ¶ÊòØ‰∏çÂøÖË¶ÅÁöÑ„ÄÇËá≥ÊñºÊ™¢Ê∏¨ÂíåÂàÜÂâ≤ÔºåMambaOut ÁÑ°Ê≥ïËàáÊúÄÂÖàÈÄ≤ÁöÑË¶ñË¶∫ Mamba Ê®°ÂûãÁöÑÊÄßËÉΩÁõ∏ÂåπÈÖçÔºåÈÄôË≠âÊòé‰∫Ü Mamba Âú®Èï∑Â∫èÂàóË¶ñË¶∫‰ªªÂãô‰∏≠ÁöÑÊΩõÂäõ„ÄÇ‰ª£Á¢ºÂèØÂú® https://github.com/yuweihao/MambaOut Áç≤Âæó

##### **Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots**
2405.07990v1 by Chengyue Wu, Yixiao Ge, Qiushan Guo, Jiahao Wang, Zhixuan Liang, Zeyu Lu, Ying Shan, Ping Luo

The remarkable progress of Multi-modal Large Language Models (MLLMs) has
attracted significant attention due to their superior performance in visual
contexts. However, their capabilities in turning visual figure to executable
code, have not been evaluated thoroughly. To address this, we introduce
Plot2Code, a comprehensive visual coding benchmark designed for a fair and
in-depth assessment of MLLMs. We carefully collect 132 manually selected
high-quality matplotlib plots across six plot types from publicly available
matplotlib galleries. For each plot, we carefully offer its source code, and an
descriptive instruction summarized by GPT-4. This approach enables Plot2Code to
extensively evaluate MLLMs' code capabilities across various input modalities.
Furthermore, we propose three automatic evaluation metrics, including code pass
rate, text-match ratio, and GPT-4V overall rating, for a fine-grained
assessment of the output code and rendered images. Instead of simply judging
pass or fail, we employ GPT-4V to make an overall judgement between the
generated and reference images, which has been shown to be consistent with
human evaluation. The evaluation results, which include analyses of 14 MLLMs
such as the proprietary GPT-4V, Gemini-Pro, and the open-sourced Mini-Gemini,
highlight the substantial challenges presented by Plot2Code. With Plot2Code, we
reveal that most existing MLLMs struggle with visual coding for text-dense
plots, heavily relying on textual instruction. We hope that the evaluation
results from Plot2Code on visual coding will guide the future development of
MLLMs. All data involved with Plot2Code are available at
https://huggingface.co/datasets/TencentARC/Plot2Code.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÈ°ØËëóÈÄ≤Ê≠•ÔºåÁî±ÊñºÂÖ∂Âú®Ë¶ñË¶∫Ë™ûÂ¢É‰∏≠ÁöÑÂçìË∂äË°®ÁèæÔºåÂºïËµ∑‰∫ÜÂª£Ê≥õÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂ∞áË¶ñË¶∫ÂúñÂΩ¢ËΩâÊèõÁÇ∫ÂèØÂü∑Ë°åÁ®ãÂºèÁ¢ºÁöÑËÉΩÂäõÔºåÂ∞öÊú™ÂæóÂà∞ÂæπÂ∫ïË©ï‰º∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Plot2CodeÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË¶ñË¶∫Á∑®Á¢ºÂü∫Ê∫ñÔºåÊó®Âú®Â∞ç MLLM ÈÄ≤Ë°åÂÖ¨Âπ≥ÂíåÊ∑±ÂÖ•ÁöÑË©ï‰º∞„ÄÇÊàëÂÄë‰ªîÁ¥∞Êî∂ÈõÜ‰∫Ü 132 ÂÄãÊâãÂãïÊåëÈÅ∏ÁöÑÈ´òÂìÅË≥™ matplotlib ÂúñÂΩ¢ÔºåÊ∂µËìã‰æÜËá™ÂÖ¨Èñã matplotlib Â∫´ÁöÑÂÖ≠Á®ÆÂúñÂΩ¢È°ûÂûã„ÄÇÂ∞çÊñºÊØèÂÄãÂúñÂΩ¢ÔºåÊàëÂÄë‰ªîÁ¥∞Êèê‰æõ‰∫ÜÂÖ∂ÂéüÂßãÁ®ãÂºèÁ¢ºÔºå‰ª•ÂèäÁî± GPT-4 Á∏ΩÁµêÁöÑÊèèËø∞ÊÄßË™™Êòé„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰Ωø Plot2Code ËÉΩÂ§†Âª£Ê≥õË©ï‰º∞ MLLM ÁöÑÁ®ãÂºèÁ¢ºËÉΩÂäõÔºåÊ∂µËìãÂêÑÁ®ÆËº∏ÂÖ•Ê®°Âºè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏âÁ®ÆËá™ÂãïË©ï‰º∞ÊåáÊ®ôÔºåÂåÖÊã¨Á®ãÂºèÁ¢ºÈÄöÈÅéÁéá„ÄÅÊñáÂ≠óÂåπÈÖçÁéáÂíå GPT-4V Êï¥È´îË©ïÂàÜÔºåÁî®ÊñºÂ∞çËº∏Âá∫Á®ãÂºèÁ¢ºÂíåÊ∏≤ÊüìÂúñÂÉèÈÄ≤Ë°åÁ¥∞Á≤íÂ∫¶ÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÊ≤íÊúâÁ∞°ÂñÆÂú∞Âà§Êñ∑ÈÄöÈÅéÊàñÂ§±ÊïóÔºåËÄåÊòØÊé°Áî® GPT-4V Â∞çÁîüÊàêÁöÑÂúñÂÉèÂíåÂèÉËÄÉÂúñÂÉèÈÄ≤Ë°åÊï¥È´îÂà§Êñ∑ÔºåÈÄôÂ∑≤Ë¢´Ë≠âÊòéËàá‰∫∫È°ûË©ï‰º∞‰∏ÄËá¥„ÄÇË©ï‰º∞ÁµêÊûúÂåÖÊã¨Â∞ç 14 ÂÄã MLLMÔºà‰æãÂ¶ÇÂ∞àÊúâÁöÑ GPT-4V„ÄÅGemini-Pro ÂíåÈñãÊ∫êÁöÑ Mini-GeminiÔºâÁöÑÂàÜÊûêÔºåÁ™ÅÂá∫‰∫Ü Plot2Code Â∏∂‰æÜÁöÑÈáçÂ§ßÊåëÊà∞„ÄÇÈÄöÈÅé Plot2CodeÔºåÊàëÂÄëÁôºÁèæÂ§ßÂ§öÊï∏ÁèæÊúâÁöÑ MLLM Âú®ËôïÁêÜÊñáÂ≠óÂØÜÈõÜÂûãÂúñÂΩ¢ÁöÑË¶ñË¶∫Á∑®Á¢ºÊôÇÈÉΩÂ≠òÂú®Âõ∞Èõ£ÔºåÂö¥Èáç‰æùË≥¥ÊñºÊñáÂ≠óË™™Êòé„ÄÇÊàëÂÄëÂ∏åÊúõ Plot2Code Âú®Ë¶ñË¶∫Á∑®Á¢º‰∏äÁöÑË©ï‰º∞ÁµêÊûúÔºåÂ∞áÊåáÂ∞é MLLM Êú™‰æÜÁöÑÁôºÂ±ï„ÄÇPlot2Code Ê∂âÂèäÁöÑÊâÄÊúâË≥áÊñôÈÉΩÂèØ‰ª•Âú® https://huggingface.co/datasets/TencentARC/Plot2Code ÂèñÂæó„ÄÇ

##### **The Platonic Representation Hypothesis**
2405.07987v1 by Minyoung Huh, Brian Cheung, Tongzhou Wang, Phillip Isola

We argue that representations in AI models, particularly deep networks, are
converging. First, we survey many examples of convergence in the literature:
over time and across multiple domains, the ways by which different neural
networks represent data are becoming more aligned. Next, we demonstrate
convergence across data modalities: as vision models and language models get
larger, they measure distance between datapoints in a more and more alike way.
We hypothesize that this convergence is driving toward a shared statistical
model of reality, akin to Plato's concept of an ideal reality. We term such a
representation the platonic representation and discuss several possible
selective pressures toward it. Finally, we discuss the implications of these
trends, their limitations, and counterexamples to our analysis.

ÊëòË¶ÅÔºöÊàëÂÄëË™çÁÇ∫Ôºå‰∫∫Â∑•Êô∫ÊÖßÊ®°Âûã‰∏≠ÁöÑË°®ÂæµÔºåÁâπÂà•ÊòØÊ∑±Â∫¶Á∂≤Ë∑ØÔºåÊ≠£Âú®Ë∂®Êñº‰∏ÄËá¥„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÊ™¢Ë¶ñÊñáÁçª‰∏≠Ë®±Â§ö‰∏ÄËá¥ÊÄßÁöÑÁØÑ‰æãÔºöÈö®ËëóÊôÇÈñìÊé®ÁßªÂíåË∑®Ë∂äÂ§öÂÄãÈ†òÂüüÔºå‰∏çÂêåÁ•ûÁ∂ìÁ∂≤Ë∑ØË°®ÂæµË≥áÊñôÁöÑÊñπÂºèÊ≠£ËÆäÂæóÊõ¥ÁÇ∫‰∏ÄËá¥„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÁ§∫ÁØÑË∑®Ë≥áÊñôÂûãÊÖãÁöÑ‰∏ÄËá¥ÊÄßÔºöÈö®ËëóË¶ñË¶∫Ê®°ÂûãÂíåË™ûË®ÄÊ®°ÂûãËÆäÂ§ßÔºåÂÆÉÂÄë‰ª•Ë∂ä‰æÜË∂äÁõ∏‰ººÁöÑÊ®°ÂºèË°°ÈáèË≥áÊñôÈªû‰πãÈñìÁöÑË∑ùÈõ¢„ÄÇÊàëÂÄëÂÅáË®≠ÈÄôÁ®Æ‰∏ÄËá¥ÊÄßÊ≠£ÊúùÂêë‰∏ÄÂÄãÂÖ±‰∫´ÁöÑÁèæÂØ¶Áµ±Ë®àÊ®°ÂûãÈÇÅÈÄ≤ÔºåÈ°û‰ººÊñºÊüèÊãâÂúñÂ∞çÁêÜÊÉ≥ÁèæÂØ¶ÁöÑÊ¶ÇÂøµ„ÄÇÊàëÂÄëÂ∞áÈÄôÁ®ÆË°®ÂæµÁ®±ÁÇ∫ÊüèÊãâÂúñË°®ÂæµÔºå‰∏¶Ë®éË´ñ‰∫ÜÊúùÂêëÂÆÉÁöÑÂπæÁ®ÆÂèØËÉΩÁöÑÈÅ∏ÊìáÂ£ìÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñÈÄô‰∫õË∂®Âã¢ÁöÑÂê´ÊÑè„ÄÅÂÆÉÂÄëÁöÑÈôêÂà∂Ôºå‰ª•ÂèäÂ∞çÊàëÂÄëÂàÜÊûêÁöÑÂèç‰æã„ÄÇ

##### **Localized Adaptive Risk Control**
2405.07976v1 by Matteo Zecchin, Osvaldo Simeone

Adaptive Risk Control (ARC) is an online calibration strategy based on set
prediction that offers worst-case deterministic long-term risk control, as well
as statistical marginal coverage guarantees. ARC adjusts the size of the
prediction set by varying a single scalar threshold based on feedback from past
decisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC),
an online calibration scheme that targets statistical localized risk guarantees
ranging from conditional risk to marginal risk, while preserving the worst-case
performance of ARC. L-ARC updates a threshold function within a reproducing
kernel Hilbert space (RKHS), with the kernel determining the level of
localization of the statistical risk guarantee. The theoretical results
highlight a trade-off between localization of the statistical risk and
convergence speed to the long-term risk target. Thanks to localization, L-ARC
is demonstrated via experiments to produce prediction sets with risk guarantees
across different data subpopulations, significantly improving the fairness of
the calibrated model for tasks such as image segmentation and beam selection in
wireless networks.

ÊëòË¶ÅÔºöËá™ÈÅ©ÊáâÈ¢®Èö™ÊéßÂà∂ (ARC) ÊòØ‰∏ÄÁ®ÆÂü∫ÊñºË®≠ÂÆöÈ†êÊ∏¨ÁöÑÁ∑ö‰∏äÊ†°Ê∫ñÁ≠ñÁï•ÔºåÊèê‰æõÊúÄÂ£ûÊÉÖÊ≥ÅÁöÑÁ¢∫ÂÆöÊÄßÈï∑ÊúüÈ¢®Èö™ÊéßÂà∂Ôºå‰ª•ÂèäÁµ±Ë®àÈÇäÈöõË¶ÜËìã‰øùË≠â„ÄÇARC ÈÄèÈÅéÊ†πÊìöÈÅéÂéªÊ±∫Á≠ñÁöÑÂõûÈ•ãË™øÊï¥È†êÊ∏¨Ë®≠ÂÆöÁöÑÂ§ßÂ∞èÔºå‰æÜÊîπËÆäÂñÆ‰∏ÄÊ®ôÈáèÈñæÂÄº„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ±ÄÈÉ®Ëá™ÈÅ©ÊáâÈ¢®Èö™ÊéßÂà∂ (L-ARC)Ôºå‰∏ÄÁ®ÆÁ∑ö‰∏äÊ†°Ê∫ñÊñπÊ°àÔºåÂÖ∂ÁõÆÊ®ôÊòØÁµ±Ë®àÂ±ÄÈÉ®È¢®Èö™‰øùË≠âÔºåÁØÑÂúçÂæûÊ¢ù‰ª∂È¢®Èö™Âà∞ÈÇäÈöõÈ¢®Èö™ÔºåÂêåÊôÇ‰øùÁïô ARC ÁöÑÊúÄÂ£ûÊÉÖÊ≥ÅË°®Áèæ„ÄÇL-ARC Âú®ÂÜçÁîüÊ†∏Â∏åÁàæ‰ºØÁâπÁ©∫Èñì (RKHS) ‰∏≠Êõ¥Êñ∞ÈñæÂÄºÂáΩÊï∏ÔºåÂÖ∂‰∏≠Ê†∏Ê±∫ÂÆöÁµ±Ë®àÈ¢®Èö™‰øùË≠âÁöÑÂ±ÄÈÉ®ÂåñÁ®ãÂ∫¶„ÄÇÁêÜË´ñÁµêÊûúÂº∑Ë™ø‰∫ÜÁµ±Ë®àÈ¢®Èö™Â±ÄÈÉ®ÂåñËàáÈï∑ÊúüÈ¢®Èö™ÁõÆÊ®ôÊî∂ÊñÇÈÄüÂ∫¶‰πãÈñìÁöÑÊ¨äË°°„ÄÇÁî±ÊñºÂ±ÄÈÉ®ÂåñÔºåL-ARC ÈÄèÈÅéÂØ¶È©óË≠âÊòéÁî¢ÁîüÂÖ∑ÊúâÈ¢®Èö™‰øùË≠âÁöÑÈ†êÊ∏¨Ë®≠ÂÆöÔºåÊ∂µËìã‰∏çÂêåÁöÑË≥áÊñôÂ≠êÁæ§È´îÔºåÈ°ØËëóÊîπÂñÑÊ†°Ê∫ñÊ®°ÂûãÂú®ÂΩ±ÂÉèÂàÜÂâ≤ÂíåÁÑ°Á∑öÁ∂≤Ë∑Ø‰∏≠Ê≥¢ÊùüÈÅ∏ÊìáÁ≠â‰ªªÂãôÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇ

##### **Investigating the Semantic Robustness of CLIP-based Zero-Shot Anomaly Segmentation**
2405.07969v1 by Kevin Stangl, Marius Arvinte, Weilin Xu, Cory Cornelius

Zero-shot anomaly segmentation using pre-trained foundation models is a
promising approach that enables effective algorithms without expensive,
domain-specific training or fine-tuning. Ensuring that these methods work
across various environmental conditions and are robust to distribution shifts
is an open problem. We investigate the performance of WinCLIP [14] zero-shot
anomaly segmentation algorithm by perturbing test data using three semantic
transformations: bounded angular rotations, bounded saturation shifts, and hue
shifts. We empirically measure a lower performance bound by aggregating across
per-sample worst-case perturbations and find that average performance drops by
up to 20% in area under the ROC curve and 40% in area under the per-region
overlap curve. We find that performance is consistently lowered on three CLIP
backbones, regardless of model architecture or learning objective,
demonstrating a need for careful performance evaluation.

ÊëòË¶ÅÔºö‰ΩøÁî®È†êË®ìÁ∑¥Âü∫Á§éÊ®°ÂûãÈÄ≤Ë°åÈõ∂Ê¨°Áï∞Â∏∏ÂàÜÂâ≤ÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂÆÉËÉΩËÆìÊúâÊïàÊºîÁÆóÊ≥ïÂú®Ê≤íÊúâÊòÇË≤¥ÁöÑÁâπÂÆöÈ†òÂüüË®ìÁ∑¥ÊàñÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÈÅã‰Ωú„ÄÇÁ¢∫‰øùÈÄô‰∫õÊñπÊ≥ïËÉΩÂú®ÂêÑÁ®ÆÁí∞Â¢ÉÊ¢ù‰ª∂‰∏ãÈÅã‰ΩúÔºå‰∏¶‰∏îÂ∞çÂàÜ‰ΩàËΩâÁßªÂÖ∑ÊúâÁ©©ÂÅ•ÊÄßÔºåÊòØ‰∏ÄÂÄãÂÖ¨ÈñãÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÈÄèÈÅé‰ΩøÁî®‰∏âÂÄãË™ûÁæ©ËΩâÊèõÔºàÊúâÁïåËßíÊóãËΩâ„ÄÅÊúâÁïåÈ£ΩÂíåÂ∫¶ËΩâÁßªÂíåËâ≤Áõ∏ËΩâÁßªÔºâÊìæÂãïÊ∏¨Ë©¶Ë≥áÊñôÔºå‰æÜË™øÊü• WinCLIP [14] Èõ∂Ê¨°Áï∞Â∏∏ÂàÜÂâ≤ÊºîÁÆóÊ≥ïÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÈÄèÈÅéÂΩôÁ∏ΩÊØèÂÄãÊ®£Êú¨ÊúÄÂ£ûÊÉÖÊ≥ÅÁöÑÊìæÂãïÔºåÁ∂ìÈ©óÊÄßÂú∞Ê∏¨ÈáèËºÉ‰ΩéÁöÑÊïàËÉΩÁïåÈôêÔºå‰∏¶ÁôºÁèæ ROC Êõ≤Á∑ö‰∏ãÁöÑÈù¢Á©çÂπ≥ÂùáÊïàËÉΩ‰∏ãÈôç‰∫Ü 20%ÔºåËÄåÊØèÂÄãÂçÄÂüüÈáçÁñäÊõ≤Á∑ö‰∏ãÁöÑÈù¢Á©çÂâá‰∏ãÈôç‰∫Ü 40%„ÄÇÊàëÂÄëÁôºÁèæÊïàËÉΩÂú®‰∏ÄË≤´Âú∞Èôç‰ΩéÊñº‰∏âÂÄã CLIP ‰∏ªÂππ‰∏äÔºåËÄåËàáÊ®°ÂûãÊû∂ÊßãÊàñÂ≠∏ÁøíÁõÆÊ®ôÁÑ°ÈóúÔºåÈÄôË≠âÊòé‰∫Ü‰ªîÁ¥∞Ë©ï‰º∞ÊïàËÉΩÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**
2405.07966v1 by Qiuchi Xiang, Jintao Cheng, Jiehao Luo, Jin Wu, Rui Fan, Xieyuanli Chen, Xiaoyu Tang

Place recognition is the foundation for enabling autonomous systems to
achieve independent decision-making and safe operations. It is also crucial in
tasks such as loop closure detection and global localization within SLAM.
Previous methods utilize mundane point cloud representations as input and deep
learning-based LiDAR-based Place Recognition (LPR) approaches employing
different point cloud image inputs with convolutional neural networks (CNNs) or
transformer architectures. However, the recently proposed Mamba deep learning
model, combined with state space models (SSMs), holds great potential for long
sequence modeling. Therefore, we developed OverlapMamba, a novel network for
place recognition, which represents input range views (RVs) as sequences. In a
novel way, we employ a stochastic reconstruction approach to build shift state
space models, compressing the visual representation. Evaluated on three
different public datasets, our method effectively detects loop closures,
showing robustness even when traversing previously visited locations from
different directions. Relying on raw range view inputs, it outperforms typical
LiDAR and multi-view combination methods in time complexity and speed,
indicating strong place recognition capabilities and real-time efficiency.

ÊëòË¶ÅÔºöÂ†¥ÊôØËæ®Ë≠òÊòØËÆìËá™‰∏ªÁ≥ªÁµ±ËÉΩÁç®Á´ãÊ±∫Á≠ñÂíåÂÆâÂÖ®ÈÅã‰ΩúÁöÑÂü∫Á§é„ÄÇÂÆÉÂú® SLAM ‰∏≠ÁöÑËø¥Ë∑ØÈñâÂêàÂÅµÊ∏¨ÂíåÂÖ®Â±ÄÂÆö‰ΩçÁ≠â‰ªªÂãô‰∏≠‰πüËá≥ÈóúÈáçË¶Å„ÄÇÂÖàÂâçÁöÑÂÅöÊ≥ïÊúÉÂà©Áî®Âπ≥Âá°ÁöÑÈªûÈõ≤Ë°®Á§∫‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰ª•ÂèäÊé°Áî®Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÊàñTransformerÊû∂ÊßãÔºå‰ΩøÁî®‰∏çÂêåÁöÑÈªûÈõ≤ÂΩ±ÂÉèËº∏ÂÖ•ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂºèÈõ∑Â∞ÑÈõ∑ÈÅîÂ†¥ÊôØËæ®Ë≠ò (LPR) ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÊèêÂá∫ÁöÑ Mamba Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁµêÂêàÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM)ÔºåÂú®Èï∑Â∫èÂàóÂª∫Ê®°ÊñπÈù¢ÊìÅÊúâÊ•µ‰Ω≥ÁöÑÊΩõÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü OverlapMambaÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÂ†¥ÊôØËæ®Ë≠òÁöÑÊñ∞Á©éÁ∂≤Ë∑ØÔºåÂÆÉÂ∞áËº∏ÂÖ•ÁØÑÂúçË¶ñÂúñ (RV) Ë°®Á§∫ÁÇ∫Â∫èÂàó„ÄÇÊàëÂÄëÊé°Áî®‰∏ÄÁ®ÆÈö®Ê©üÈáçÂª∫ÊñπÊ≥ï‰æÜÂª∫Á´ãËΩâÁßªÁãÄÊÖãÁ©∫ÈñìÊ®°ÂûãÔºåÂ£ìÁ∏ÆË¶ñË¶∫Ë°®Á§∫ÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÅöÊ≥ï„ÄÇÂú®‰∏âÂÄã‰∏çÂêåÁöÑÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïàÂú∞ÂÅµÊ∏¨Âà∞Ëø¥Ë∑ØÈñâÂêàÔºåÂç≥‰ΩøÂæû‰∏çÂêåÁöÑÊñπÂêëÁ©øË∂äÂÖàÂâçÈÄ†Ë®™ÈÅéÁöÑÂú∞ÈªûÔºå‰πüÂ±ïÁèæÂá∫Á©©ÂÅ•ÊÄß„ÄÇÂÆÉ‰æùË≥¥Êú™ËôïÁêÜÁöÑÁØÑÂúçË¶ñÂúñËº∏ÂÖ•ÔºåÂú®ÊôÇÈñìË§áÈõúÂ∫¶ÂíåÈÄüÂ∫¶‰∏äÂÑ™ÊñºÂÖ∏ÂûãÁöÑ LiDAR ÂíåÂ§öË¶ñÂúñÁµÑÂêàÊñπÊ≥ïÔºåÈ°ØÁ§∫Âá∫Âº∑Â§ßÁöÑÂ†¥ÊôØËæ®Ë≠òËÉΩÂäõÂíåÂç≥ÊôÇÊïàÁéá„ÄÇ

##### **AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments**
2405.07960v1 by Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, Michael Moor

Diagnosing and managing a patient is a complex, sequential decision making
process that requires physicians to obtain information -- such as which tests
to perform -- and to act upon it. Recent advances in artificial intelligence
(AI) and large language models (LLMs) promise to profoundly impact clinical
care. However, current evaluation schemes overrely on static medical
question-answering benchmarks, falling short on interactive decision-making
that is required in real-life clinical work. Here, we present AgentClinic: a
multimodal benchmark to evaluate LLMs in their ability to operate as agents in
simulated clinical environments. In our benchmark, the doctor agent must
uncover the patient's diagnosis through dialogue and active data collection. We
present two open benchmarks: a multimodal image and dialogue environment,
AgentClinic-NEJM, and a dialogue-only environment, AgentClinic-MedQA. We embed
cognitive and implicit biases both in patient and doctor agents to emulate
realistic interactions between biased agents. We find that introducing bias
leads to large reductions in diagnostic accuracy of the doctor agents, as well
as reduced compliance, confidence, and follow-up consultation willingness in
patient agents. Evaluating a suite of state-of-the-art LLMs, we find that
several models that excel in benchmarks like MedQA are performing poorly in
AgentClinic-MedQA. We find that the LLM used in the patient agent is an
important factor for performance in the AgentClinic benchmark. We show that
both having limited interactions as well as too many interaction reduces
diagnostic accuracy in doctor agents. The code and data for this work is
publicly available at https://AgentClinic.github.io.

ÊëòË¶ÅÔºöË®∫Êñ∑ÂíåÁÆ°ÁêÜÁóÖ‰∫∫ÊòØ‰∏ÄÂÄãË§áÈõú„ÄÅÂæ™Â∫èÊº∏ÈÄ≤ÁöÑÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ãÔºåÈúÄË¶ÅÈÜ´ÁîüÁç≤ÂèñË≥áË®äÔºà‰æãÂ¶ÇË¶ÅÂü∑Ë°åÂì™‰∫õÊ∏¨Ë©¶Ôºâ‰∏¶Êé°ÂèñË°åÂãï„ÄÇ‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÊúâÊúõÂ∞çËá®Â∫äË≠∑ÁêÜÁî¢ÁîüÊ∑±ÈÅ†ÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑË©ï‰º∞ÊñπÊ°àÈÅéÊñº‰æùË≥¥ÈùúÊÖãÈÜ´ÁôÇÂïèÁ≠îÂü∫Ê∫ñÔºåÂú®ÁèæÂØ¶ÁîüÊ¥ª‰∏≠Ëá®Â∫äÂ∑•‰Ωú‰∏≠ÊâÄÈúÄÁöÑ‰∫íÂãïÊ±∫Á≠ñÂà∂ÂÆöÊñπÈù¢ÊúâÊâÄ‰∏çË∂≥„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ AgentClinicÔºö‰∏ÄÂÄãÂ§öÊ®°ÊÖãÂü∫Ê∫ñÔºåÁî®ÊñºË©ï‰º∞ LLM Âú®Ê®°Êì¨Ëá®Â∫äÁí∞Â¢É‰∏≠‰ΩúÁÇ∫‰ª£ÁêÜÈÅã‰ΩúÁöÑËÉΩÂäõ„ÄÇÂú®ÊàëÂÄëÁöÑÂü∫Ê∫ñ‰∏≠ÔºåÈÜ´Áîü‰ª£ÁêÜÂøÖÈ†àÈÄèÈÅéÂ∞çË©±Âíå‰∏ªÂãïÊï∏ÊìöÊî∂ÈõÜ‰æÜÊâæÂá∫ÁóÖ‰∫∫ÁöÑË®∫Êñ∑„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÂÖ©ÂÄãÈñãÊîæÂü∫Ê∫ñÔºö‰∏ÄÂÄãÂ§öÊ®°ÊÖãÂΩ±ÂÉèÂíåÂ∞çË©±Áí∞Â¢É AgentClinic-NEJMÔºå‰ª•Âèä‰∏ÄÂÄãÂÉÖÂ∞çË©±ÁöÑÁí∞Â¢É AgentClinic-MedQA„ÄÇÊàëÂÄëÂ∞áË™çÁü•ÂíåÈö±Âê´ÂÅèË¶ãÂµåÂÖ•ÁóÖ‰∫∫ÂíåÈÜ´Áîü‰ª£ÁêÜ‰∏≠Ôºå‰ª•Ê®°Êì¨ÊúâÂÅèË¶ãÁöÑ‰ª£ÁêÜ‰πãÈñìÁöÑÁèæÂØ¶‰∫íÂãï„ÄÇÊàëÂÄëÁôºÁèæÔºåÂºïÂÖ•ÂÅèË¶ãÊúÉÂ∞éËá¥ÈÜ´Áîü‰ª£ÁêÜÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂ§ßÂπÖ‰∏ãÈôçÔºå‰ª•ÂèäÁóÖ‰∫∫‰ª£ÁêÜÁöÑÈ†ÜÂæûÊÄß„ÄÅ‰ø°ÂøÉÂíåÂæåÁ∫åË´ÆË©¢ÊÑèÈ°ò‰∏ãÈôç„ÄÇÂú®Ë©ï‰º∞‰∏ÄÁ≥ªÂàóÊúÄÂÖàÈÄ≤ÁöÑ LLM ÊôÇÔºåÊàëÂÄëÁôºÁèæÂπæÂÄãÂú® MedQA Á≠âÂü∫Ê∫ñ‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÁöÑÊ®°ÂûãÂú® AgentClinic-MedQA ‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÊàëÂÄëÁôºÁèæÁî®ÊñºÁóÖ‰∫∫‰ª£ÁêÜÁöÑ LLM ÊòØ AgentClinic Âü∫Ê∫ñ‰∏≠Ë°®ÁèæÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊàëÂÄëË°®ÊòéÔºå‰∫íÂãïÊ¨°Êï∏ÂèóÈôêÂíå‰∫íÂãïÊ¨°Êï∏ÈÅéÂ§öÈÉΩÊúÉÈôç‰ΩéÈÜ´Áîü‰ª£ÁêÜÁöÑË®∫Êñ∑Ê∫ñÁ¢∫ÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁöÑÁ®ãÂºèÁ¢ºÂíåÊï∏ÊìöÂ∑≤ÂÖ¨ÈñãÁôºÂ∏ÉÊñº https://AgentClinic.github.io„ÄÇ

##### **Hierarchical Decision Mamba**
2405.07943v1 by Andr√© Correia, Lu√≠s A. Alexandre

Recent advancements in imitation learning have been largely fueled by the
integration of sequence models, which provide a structured flow of information
to effectively mimic task behaviours. Currently, Decision Transformer (DT) and
subsequently, the Hierarchical Decision Transformer (HDT), presented
Transformer-based approaches to learn task policies. Recently, the Mamba
architecture has shown to outperform Transformers across various task domains.
In this work, we introduce two novel methods, Decision Mamba (DM) and
Hierarchical Decision Mamba (HDM), aimed at enhancing the performance of the
Transformer models. Through extensive experimentation across diverse
environments such as OpenAI Gym and D4RL, leveraging varying demonstration data
sets, we demonstrate the superiority of Mamba models over their Transformer
counterparts in a majority of tasks. Results show that HDM outperforms other
methods in most settings. The code can be found at
https://github.com/meowatthemoon/HierarchicalDecisionMamba.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÊ®°‰ªøÂ≠∏ÁøíÈÄ≤Â±ïÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÁî±Â∫èÂàóÊ®°ÂûãÁöÑÊï¥ÂêàÊé®ÂãïÁöÑÔºåÈÄô‰∫õÊ®°ÂûãÊèê‰æõ‰∫ÜÁµêÊßãÂåñÁöÑË≥áË®äÊµÅÔºå‰ª•ÊúâÊïàÂú∞Ê®°‰ªø‰ªªÂãôË°åÁÇ∫„ÄÇÁõÆÂâçÔºåÊ±∫Á≠ñTransformer (DT) ‰ª•ÂèäÈö®ÂæåÁöÑÂ±§Á¥öÊ±∫Á≠ñTransformer (HDT) ÊèêÂá∫Âü∫ÊñºTransformerÁöÑÁ≠ñÁï•‰æÜÂ≠∏Áøí‰ªªÂãôÊîøÁ≠ñ„ÄÇÊúÄËøëÔºåMamba Êû∂ÊßãÂ∑≤Ë≠âÊòéÂú®ÂêÑÁ®Æ‰ªªÂãôÈ†òÂüü‰∏≠ÂÑ™ÊñºTransformer„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂÖ©Á®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥Ê±∫Á≠ñ Mamba (DM) ÂíåÂ±§Á¥öÊ±∫Á≠ñ Mamba (HDM)ÔºåÊó®Âú®Â¢ûÂº∑TransformerÊ®°ÂûãÁöÑÊïàËÉΩ„ÄÇÈÄèÈÅéÂú®‰∏çÂêåÁöÑÁí∞Â¢ÉÔºà‰æãÂ¶Ç OpenAI Gym Âíå D4RLÔºâ‰∏≠ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂà©Áî®‰∏çÂêåÁöÑÁ§∫ÁØÑË≥áÊñôÈõÜÔºåÊàëÂÄëË≠âÊòé‰∫Ü Mamba Ê®°ÂûãÂú®Â§ßÈÉ®ÂàÜ‰ªªÂãô‰∏≠ÂÑ™ÊñºÂÖ∂TransformerÂ∞çÊáâÊ®°Âûã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåHDM Âú®Â§ßÂ§öÊï∏Ë®≠ÂÆö‰∏≠ÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® https://github.com/meowatthemoon/HierarchicalDecisionMamba ‰∏≠ÊâæÂà∞„ÄÇ

##### **RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors**
2405.07940v1 by Liam Dugan, Alyssa Hwang, Filip Trhlik, Josh Magnus Ludan, Andrew Zhu, Hainiu Xu, Daphne Ippolito, Chris Callison-Burch

Many commercial and open-source models claim to detect machine-generated text
with very high accuracy (99\% or higher). However, very few of these detectors
are evaluated on shared benchmark datasets and even when they are, the datasets
used for evaluation are insufficiently challenging -- lacking variations in
sampling strategy, adversarial attacks, and open-source generative models. In
this work we present RAID: the largest and most challenging benchmark dataset
for machine-generated text detection. RAID includes over 6 million generations
spanning 11 models, 8 domains, 11 adversarial attacks and 4 decoding
strategies. Using RAID, we evaluate the out-of-domain and adversarial
robustness of 8 open- and 4 closed-source detectors and find that current
detectors are easily fooled by adversarial attacks, variations in sampling
strategies, repetition penalties, and unseen generative models. We release our
dataset and tools to encourage further exploration into detector robustness.

ÊëòË¶ÅÔºöË®±Â§öÂïÜÊ•≠ÂíåÈñãÊîæÂéüÂßãÁ¢ºÊ®°ÂûãËÅ≤Á®±ËÉΩ‰ª•Ê•µÈ´òÁöÑÊ∫ñÁ¢∫Â∫¶Ôºà99% ÊàñÊõ¥È´òÔºâÂÅµÊ∏¨Ê©üÂô®Áî¢ÁîüÁöÑÊñáÂ≠ó„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂÅµÊ∏¨Âô®‰∏≠Âè™ÊúâÊ•µÂ∞ëÊï∏ÊúÉÂú®ÂÖ±Áî®Âü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞ÔºåÂç≥‰ΩøÊúâÔºåÁî®ÊñºË©ï‰º∞ÁöÑË≥áÊñôÈõÜÊåëÊà∞ÊÄß‰πü‰∏çË∂≥ÔºåÁº∫‰πèÂèñÊ®£Á≠ñÁï•„ÄÅÂ∞çÊäóÊÄßÊîªÊìäÂíåÈñãÊîæÂéüÂßãÁ¢ºÁîüÊàêÊ®°ÂûãÁöÑËÆäÂåñ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü RAIDÔºöÊ©üÂô®Áî¢ÁîüÁöÑÊñáÂ≠óÂÅµÊ∏¨‰∏≠ÊúÄÂ§ß‰∏îÊúÄÂÖ∑ÊåëÊà∞ÊÄßÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ„ÄÇRAID ÂåÖÂê´Ë∂ÖÈÅé 600 Ëê¨ÂÄã‰∏ñ‰ª£ÔºåÊ∂µËìã 11 ÂÄãÊ®°Âûã„ÄÅ8 ÂÄãÁ∂≤Âüü„ÄÅ11 ÂÄãÂ∞çÊäóÊÄßÊîªÊìäÂíå 4 ÂÄãËß£Á¢ºÁ≠ñÁï•„ÄÇ‰ΩøÁî® RAIDÔºåÊàëÂÄëË©ï‰º∞‰∫Ü 8 ÂÄãÈñãÊîæÂéüÂßãÁ¢ºÂíå 4 ÂÄãÈñâÊ∫êÂÅµÊ∏¨Âô®ÁöÑÁ∂≤ÂüüÂ§ñÂíåÂ∞çÊäóÊÄßÁ©©ÂÅ•ÊÄßÔºåÁôºÁèæÁõÆÂâçÁöÑÂÅµÊ∏¨Âô®ÂæàÂÆπÊòìË¢´Â∞çÊäóÊÄßÊîªÊìä„ÄÅÂèñÊ®£Á≠ñÁï•ÁöÑËÆäÂåñ„ÄÅÈáçË§áÊá≤ÁΩ∞ÂíåÊú™Ë¶ãÈÅéÁöÑÁîüÊàêÊ®°ÂûãÊâÄÊÑöÂºÑ„ÄÇÊàëÂÄëÈáãÂá∫ÊàëÂÄëÁöÑË≥áÊñôÈõÜÂíåÂ∑•ÂÖ∑Ôºå‰ª•ÈºìÂãµÈÄ≤‰∏ÄÊ≠•Êé¢Á¥¢ÂÅµÊ∏¨Âô®ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇ

##### **EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning**
2405.07938v1 by Yinzhu Quan, Zefang Liu

In this paper, we introduce EconLogicQA, a rigorous benchmark designed to
assess the sequential reasoning capabilities of large language models (LLMs)
within the intricate realms of economics, business, and supply chain
management. Diverging from traditional benchmarks that predict subsequent
events individually, EconLogicQA poses a more challenging task: it requires
models to discern and sequence multiple interconnected events, capturing the
complexity of economic logics. EconLogicQA comprises an array of multi-event
scenarios derived from economic articles, which necessitate an insightful
understanding of both temporal and logical event relationships. Through
comprehensive evaluations, we exhibit that EconLogicQA effectively gauges a
LLM's proficiency in navigating the sequential complexities inherent in
economic contexts. We provide a detailed description of EconLogicQA dataset and
shows the outcomes from evaluating the benchmark across various leading-edge
LLMs, thereby offering a thorough perspective on their sequential reasoning
potential in economic contexts. Our benchmark dataset is available at
https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü EconLogicQAÔºåÈÄôÊòØ‰∏ÄÂÄãÂö¥Ë¨πÁöÑÂü∫Ê∫ñÔºåÊó®Âú®Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Á∂ìÊøü„ÄÅÂïÜÊ•≠Âíå‰æõÊáâÈèàÁÆ°ÁêÜÁöÑË§áÈõúÈ†òÂüü‰∏≠ÈÄ≤Ë°åÈ†ÜÂ∫èÊé®ÁêÜÁöÑËÉΩÂäõ„ÄÇËàáÈ†êÊ∏¨ÂæåÁ∫å‰∫ã‰ª∂ÁöÑÂÇ≥Áµ±Âü∫Ê∫ñ‰∏çÂêåÔºåEconLogicQA ÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºöÂÆÉË¶ÅÊ±ÇÊ®°ÂûãËæ®Âà•ÂíåÊéíÂ∫èÂ§öÂÄãÁõ∏‰∫íÈóúËÅØÁöÑ‰∫ã‰ª∂ÔºåÊçïÊçâÁ∂ìÊøüÈÇèËºØÁöÑË§áÈõúÊÄß„ÄÇEconLogicQA ÂåÖÂê´‰∏ÄÁ≥ªÂàóÊ∫êËá™Á∂ìÊøüÊñáÁ´†ÁöÑÂ§ö‰∫ã‰ª∂Â†¥ÊôØÔºåÈúÄË¶ÅÊ∑±ÂÖ•‰∫ÜËß£ÊôÇÈñìÂíåÈÇèËºØ‰∫ã‰ª∂Èóú‰øÇ„ÄÇÈÄöÈÅéÁ∂úÂêàË©ï‰º∞ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü EconLogicQA ÊúâÊïàÂú∞Ë°°Èáè‰∫Ü LLM Âú®ÊáâÂ∞çÁ∂ìÊøüËÉåÊôØ‰∏≠Âõ∫ÊúâÁöÑÈ†ÜÂ∫èË§áÈõúÊÄßÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü EconLogicQA Êï∏ÊìöÈõÜÁöÑË©≥Á¥∞ÊèèËø∞Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂú®ÂêÑÁ®ÆÈ†òÂÖàÁöÑ LLM ‰∏≠Ë©ï‰º∞Âü∫Ê∫ñÁöÑÁµêÊûúÔºåÂæûËÄåÂÖ®Èù¢‰∫ÜËß£‰∫ÜÂÆÉÂÄëÂú®Á∂ìÊøüËÉåÊôØ‰∏ãÁöÑÈ†ÜÂ∫èÊé®ÁêÜÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÊï∏ÊìöÈõÜÂèØÂú® https://huggingface.co/datasets/yinzhu-quan/econ_logic_qa Áç≤Âæó„ÄÇ</paragraph>

##### **PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition**
2405.07932v2 by Ziyang Zhang, Qizhen Zhang, Jakob Foerster

Large language models (LLMs) have shown success in many natural language
processing tasks. Despite rigorous safety alignment processes, supposedly
safety-aligned LLMs like Llama 2 and Claude 2 are still susceptible to
jailbreaks, leading to security risks and abuse of the models. One option to
mitigate such risks is to augment the LLM with a dedicated "safeguard", which
checks the LLM's inputs or outputs for undesired behaviour. A promising
approach is to use the LLM itself as the safeguard. Nonetheless, baseline
methods, such as prompting the LLM to self-classify toxic content, demonstrate
limited efficacy. We hypothesise that this is due to domain shift: the
alignment training imparts a self-censoring behaviour to the model ("Sorry I
can't do that"), while the self-classify approach shifts it to a classification
format ("Is this prompt malicious"). In this work, we propose PARDEN, which
avoids this domain shift by simply asking the model to repeat its own outputs.
PARDEN neither requires finetuning nor white box access to the model. We
empirically verify the effectiveness of our method and show that PARDEN
significantly outperforms existing jailbreak detection baselines for Llama-2
and Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN.
  We find that PARDEN is particularly powerful in the relevant regime of high
True Positive Rate (TPR) and low False Positive Rate (FPR). For instance, for
Llama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction in
the FPR from 24.8% to 2.0% on the harmful behaviours dataset.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Ë®±Â§öËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÊàêÂäü„ÄÇÂÑòÁÆ°ÈÄ≤Ë°åÂö¥Ê†ºÁöÑÂÆâÂÖ®Ë™øÊï¥Á®ãÂ∫èÔºå‰ΩÜÁêÜË´ñ‰∏äÁ∂ìÈÅéÂÆâÂÖ®Ë™øÊï¥ÁöÑ LLMÔºà‰æãÂ¶Ç Llama 2 Âíå Claude 2Ôºâ‰ªçÂÆπÊòìÂèóÂà∞Ë∂äÁçÑÊîªÊìäÔºåÂ∞éËá¥ÂÆâÂÖ®È¢®Èö™ÂíåÊ®°ÂûãÈÅ≠Âà∞Êø´Áî®„ÄÇÊ∏õËºïÊ≠§È°ûÈ¢®Èö™ÁöÑ‰∏ÄÂÄãÈÅ∏È†ÖÊòØ‰ΩøÁî®Â∞àÁî®ÁöÑ„ÄåÈò≤Ë≠∑Êé™ÊñΩ„ÄçÊì¥ÂÖÖ LLMÔºåÁî®ÊñºÊ™¢Êü• LLM ÁöÑËº∏ÂÖ•ÊàñËº∏Âá∫ÊòØÂê¶Êúâ‰∏çËâØË°åÁÇ∫„ÄÇ‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ïÊòØ‰ΩøÁî® LLM Êú¨Ë∫´‰ΩúÁÇ∫Èò≤Ë≠∑Êé™ÊñΩ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÂü∫Á∑öÊñπÊ≥ïÔºà‰æãÂ¶ÇÊèêÁ§∫ LLM Ëá™ÊàëÂàÜÈ°ûÊúâÊØíÂÖßÂÆπÔºâÈ°ØÁ§∫Âá∫ÊúâÈôêÁöÑÂäüÊïà„ÄÇÊàëÂÄëÂÅáË®≠ÈÄôÊòØÁî±ÊñºÈ†òÂüüËΩâÁßªÔºöË™øÊï¥Ë®ìÁ∑¥ÊúÉËÆìÊ®°ÂûãÁî¢ÁîüËá™ÊàëÂØ©Êü•Ë°åÁÇ∫Ôºà„ÄåÊä±Ê≠âÔºåÊàëÁÑ°Ê≥ïÈÄôÈ∫ºÂÅö„ÄçÔºâÔºåËÄåËá™ÊàëÂàÜÈ°ûÊñπÊ≥ïÊúÉÂ∞áÂÖ∂ËΩâÁßªÂà∞ÂàÜÈ°ûÊ†ºÂºèÔºà„ÄåÈÄôÂÄãÊèêÁ§∫ÊòØÂê¶ÊÉ°ÊÑè„ÄçÔºâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ PARDENÔºåÂÆÉÈÄèÈÅéÁ∞°ÂñÆÂú∞Ë¶ÅÊ±ÇÊ®°ÂûãÈáçË§áÂÖ∂Ëá™Â∑±ÁöÑËº∏Âá∫Ôºå‰æÜÈÅøÂÖçÈÄôÁ®ÆÈ†òÂüüËΩâÁßª„ÄÇPARDEN ‰∏çÈúÄË¶ÅÂæÆË™øÊàñÂ∞çÊ®°ÂûãÈÄ≤Ë°åÁôΩÁõíÂ≠òÂèñ„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âÈ©óË≠âÊàëÂÄëÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºå‰∏¶È°ØÁ§∫ PARDEN Âú® Llama-2 Âíå Claude-2 ÁöÑÁèæÊúâË∂äÁçÑÂÅµÊ∏¨Âü∫Á∑ö‰∏äÈ°ØËëóÂÑ™ÊñºÂÖ∂‰ªñÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÂú® https://github.com/Ed-Zh/PARDEN ÂèñÂæó„ÄÇÊàëÂÄëÁôºÁèæ PARDEN Âú®È´òÁúüÂØ¶Ê≠£È°ûÁéá (TPR) Âíå‰ΩéËôõÂÅáÊ≠£È°ûÁéá (FPR) ÁöÑÁõ∏ÈóúÁØÑÂúç‰∏≠ÁâπÂà•ÊúâÊïà„ÄÇ‰æãÂ¶ÇÔºåÂ∞çÊñº Llama2-7BÔºåÂú® TPR Á≠âÊñº 90% ÊôÇÔºåPARDEN Âú®ÊúâÂÆ≥Ë°åÁÇ∫Ë≥áÊñôÈõÜ‰∏äÂ∞á FPR Âæû 24.8% Èôç‰ΩéÂà∞ 2.0%ÔºåÊ∏õÂ∞ë‰∫ÜÂ§ßÁ¥Ñ 11 ÂÄç„ÄÇ

##### **Stable Diffusion-based Data Augmentation for Federated Learning with Non-IID Data**
2405.07925v1 by Mahdi Morafah, Matthias Reisser, Bill Lin, Christos Louizos

The proliferation of edge devices has brought Federated Learning (FL) to the
forefront as a promising paradigm for decentralized and collaborative model
training while preserving the privacy of clients' data. However, FL struggles
with a significant performance reduction and poor convergence when confronted
with Non-Independent and Identically Distributed (Non-IID) data distributions
among participating clients. While previous efforts, such as client drift
mitigation and advanced server-side model fusion techniques, have shown some
success in addressing this challenge, they often overlook the root cause of the
performance reduction - the absence of identical data accurately mirroring the
global data distribution among clients. In this paper, we introduce Gen-FedSD,
a novel approach that harnesses the powerful capability of state-of-the-art
text-to-image foundation models to bridge the significant Non-IID performance
gaps in FL. In Gen-FedSD, each client constructs textual prompts for each class
label and leverages an off-the-shelf state-of-the-art pre-trained Stable
Diffusion model to synthesize high-quality data samples. The generated
synthetic data is tailored to each client's unique local data gaps and
distribution disparities, effectively making the final augmented local data
IID. Through extensive experimentation, we demonstrate that Gen-FedSD achieves
state-of-the-art performance and significant communication cost savings across
various datasets and Non-IID settings.

ÊëòË¶ÅÔºöËæπÁºòË£ùÁΩÆÁöÑÊøÄÂ¢û‰ΩøËÅØÈÇ¶Â≠∏Áøí (FL) ÊàêÁÇ∫‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÂéª‰∏≠ÂøÉÂåñÂíåÂçî‰ΩúÊ®°ÂûãË®ìÁ∑¥ÁØÑ‰æãÔºåÂêåÊôÇÈÇÑËÉΩ‰øùË≠∑ÂÆ¢Êà∂Ë≥áÊñôÁöÑÈö±ÁßÅ„ÄÇÁÑ∂ËÄåÔºåÁï∂Èù¢Â∞çÂèÉËàáÂÆ¢Êà∂‰πãÈñìÁöÑÈùûÁç®Á´ã‰∏îÂêåÂàÜÂ∏É (Non-IID) Ë≥áÊñôÂàÜ‰ΩàÊôÇÔºåFL ÊúÉÂá∫ÁèæÊïàËÉΩÂ§ßÂπÖ‰∏ãÈôçÂíåÊî∂ÊñÇ‰∏ç‰Ω≥ÁöÑÂïèÈ°å„ÄÇÂÑòÁÆ°ÂÖàÂâçÁöÑÂä™ÂäõÔºå‰æãÂ¶ÇÂÆ¢Êà∂ÊºÇÁßªÁ∑©Ëß£ÂíåÈÄ≤Èöé‰º∫ÊúçÂô®Á´ØÊ®°ÂûãËûçÂêàÊäÄË°ìÔºåÂ∑≤Âú®Ëß£Ê±∫Ê≠§ÊåëÊà∞ÊñπÈù¢ÂèñÂæó‰∏Ä‰∫õÊàêÂäüÔºå‰ΩÜÂÆÉÂÄëÂ∏∏Â∏∏ÂøΩÁï•ÊïàËÉΩ‰∏ãÈôçÁöÑÊ†πÊú¨ÂéüÂõ†Ôºå‰πüÂ∞±ÊòØÁº∫‰πèËàáÂÆ¢Êà∂‰πãÈñìÁöÑÂÖ®ÁêÉË≥áÊñôÂàÜ‰ΩàÂÆåÂÖ®Áõ∏ÂêåÁöÑË≥áÊñô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Gen-FedSDÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂÆÉÂà©Áî®‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊñáÂ≠óËΩâÂúñÂÉèÂü∫Á§éÊ®°ÂûãÁöÑÂº∑Â§ßÂäüËÉΩÔºå‰æÜÂΩåÂêà FL ‰∏≠È°ØËëóÁöÑ Non-IID ÊïàËÉΩÂ∑ÆË∑ù„ÄÇÂú® Gen-FedSD ‰∏≠ÔºåÊØèÂÄãÂÆ¢Êà∂Á´ØÊúÉÁÇ∫ÊØèÂÄãÈ°ûÂà•Ê®ôÁ±§Âª∫ÊßãÊñáÂ≠óÊèêÁ§∫Ôºå‰∏¶Âà©Áî®ÁèæÊàêÁöÑÊúÄÂÖàÈÄ≤È†êÂÖàË®ìÁ∑¥ÁöÑ Stable Diffusion Ê®°Âûã‰æÜÂêàÊàêÈ´òÂìÅË≥™ÁöÑË≥áÊñôÊ®£Êú¨„ÄÇÊâÄÁîüÊàêÁöÑÂêàÊàêË≥áÊñôÊòØÊ†πÊìöÊØèÂÄãÂÆ¢Êà∂Á´ØÁç®ÁâπÁöÑÊú¨Âú∞Ë≥áÊñôÂ∑ÆË∑ùÂíåÂàÜ‰ΩàÂ∑ÆÁï∞ÈáèË∫´ÊâìÈÄ†ÔºåÊúâÊïàÂú∞‰ΩøÊúÄÁµÇÊì¥Â¢ûÁöÑÊú¨Âú∞Ë≥áÊñôÊàêÁÇ∫ IID„ÄÇÈÄèÈÅéÂ§ßÈáèÁöÑÂØ¶È©óÔºåÊàëÂÄëË≠âÊòé Gen-FedSD Âú®ÂêÑÁ®ÆË≥áÊñôÈõÜÂíå Non-IID Ë®≠ÂÆö‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÂíåÈ°ØËëóÁöÑÈÄöË®äÊàêÊú¨ÁØÄÁúÅ„ÄÇ

##### **Science based AI model certification for new operational environments with application in traffic state estimation**
2405.07893v1 by Daryl Mupupuni, Anupama Guntu, Liang Hong, Kamrul Hasan, Leehyun Keel

The expanding role of Artificial Intelligence (AI) in diverse engineering
domains highlights the challenges associated with deploying AI models in new
operational environments, involving substantial investments in data collection
and model training. Rapid application of AI necessitates evaluating the
feasibility of utilizing pre-trained models in unobserved operational settings
with minimal or no additional data. However, interpreting the opaque nature of
AI's black-box models remains a persistent challenge. Addressing this issue,
this paper proposes a science-based certification methodology to assess the
viability of employing pre-trained data-driven models in new operational
environments. The methodology advocates a profound integration of domain
knowledge, leveraging theoretical and analytical models from physics and
related disciplines, with data-driven AI models. This novel approach introduces
tools to facilitate the development of secure engineering systems, providing
decision-makers with confidence in the trustworthiness and safety of AI-based
models across diverse environments characterized by limited training data and
dynamic, uncertain conditions. The paper demonstrates the efficacy of this
methodology in real-world safety-critical scenarios, particularly in the
context of traffic state estimation. Through simulation results, the study
illustrates how the proposed methodology efficiently quantifies physical
inconsistencies exhibited by pre-trained AI models. By utilizing analytical
models, the methodology offers a means to gauge the applicability of
pre-trained AI models in new operational environments. This research
contributes to advancing the understanding and deployment of AI models,
offering a robust certification framework that enhances confidence in their
reliability and safety across a spectrum of operational conditions.

ÊëòË¶ÅÔºö<paragraph>‰∫∫Â∑•Êô∫ÊÖß (AI) Âú®ÂêÑÁ®ÆÂ∑•Á®ãÈ†òÂüü‰∏≠ÊâÆÊºîÁöÑËßíËâ≤Êó•ÁõäÊì¥Â§ßÔºåÁ™ÅÈ°ØÂá∫Âú®Êñ∞ÁöÑÊìç‰ΩúÁí∞Â¢É‰∏≠ÈÉ®ÁΩ≤ AI Ê®°ÂûãÊâÄÈù¢Ëá®ÁöÑÊåëÊà∞ÔºåÈÄôÊ∂âÂèäÂú®Ë≥áÊñôÊî∂ÈõÜÂíåÊ®°ÂûãË®ìÁ∑¥‰∏≠ÈÄ≤Ë°åÂ§ßÈáèÁöÑÊäïË≥á„ÄÇAI ÁöÑÂø´ÈÄüÊáâÁî®ÈúÄË¶ÅË©ï‰º∞Âú®Êú™ËßÄÂØüÂà∞ÁöÑÊìç‰ΩúÁí∞Â¢É‰∏≠Âà©Áî®È†êÂÖàË®ìÁ∑¥Ê®°ÂûãÁöÑÂèØË°åÊÄßÔºåËÄåÁÑ°ÈúÄÊàñÂè™ÈúÄÊúÄÂ∞ëÁöÑÈ°çÂ§ñË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåË©ÆÈáã AI ÈªëÁõíÊ®°ÂûãÁöÑ‰∏çÈÄèÊòéÊú¨Ë≥™‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊåÅÁ∫åÁöÑÊåëÊà∞„ÄÇÈáùÂ∞çÊ≠§ÂïèÈ°åÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÁßëÂ≠∏ÁöÑË™çË≠âÊñπÊ≥ïÔºåÁî®ÊñºË©ï‰º∞Âú®Êñ∞ÁöÑÊìç‰ΩúÁí∞Â¢É‰∏≠Êé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑË≥áÊñôÈ©ÖÂãïÊ®°ÂûãÁöÑÂèØË°åÊÄß„ÄÇÊ≠§ÊñπÊ≥ï‰∏ªÂºµÂ∞áÈ†òÂüüÁü•Ë≠òËàá‰æÜËá™Áâ©ÁêÜÂ≠∏ÂíåÁõ∏ÈóúÈ†òÂüüÁöÑÁêÜË´ñÂíåÂàÜÊûêÊ®°ÂûãÔºåËàáË≥áÊñôÈ©ÖÂãïÁöÑ AI Ê®°ÂûãÈÄ≤Ë°åÊ∑±ÂÖ•Êï¥Âêà„ÄÇÈÄôÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÂºïÂÖ•‰∫ÜÂ∑•ÂÖ∑Ôºå‰ª•‰øÉÈÄ≤ÂÆâÂÖ®Â∑•Á®ãÁ≥ªÁµ±ÁöÑÈñãÁôºÔºåËÆìÊ±∫Á≠ñËÄÖÂ∞çÂú®ÂèóÈôêË®ìÁ∑¥Ë≥áÊñôÂíåÂãïÊÖã„ÄÅ‰∏çÁ¢∫ÂÆöÁöÑÊ¢ù‰ª∂‰∏ãÔºåÂêÑÁ®ÆÁí∞Â¢É‰∏≠Âü∫Êñº AI ÁöÑÊ®°ÂûãÁöÑÂèØ‰ø°Â∫¶ÂíåÂÆâÂÖ®ÊÄßÊúâ‰ø°ÂøÉ„ÄÇÊú¨ÊñáË≠âÊòé‰∫ÜÈÄôÁ®ÆÊñπÊ≥ïÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂÆâÂÖ®ÈóúÈçµÊÉÖÂ¢É‰∏≠ÁöÑÊïàÂäõÔºåÁâπÂà•ÊòØÂú®‰∫§ÈÄöÁãÄÊÖã‰º∞Ë®àÁöÑËÉåÊôØ‰∏ã„ÄÇÈÄèÈÅéÊ®°Êì¨ÁµêÊûúÔºåÁ†îÁ©∂Ë™™Êòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ¶Ç‰ΩïÊúâÊïàÂú∞ÈáèÂåñÈ†êÂÖàË®ìÁ∑¥ÁöÑ AI Ê®°ÂûãÊâÄË°®ÁèæÂá∫ÁöÑÁâ©ÁêÜ‰∏ç‰∏ÄËá¥ÊÄß„ÄÇÈÄèÈÅéÂà©Áî®ÂàÜÊûêÊ®°ÂûãÔºåÊ≠§ÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊâãÊÆµ‰æÜË©ï‰º∞È†êÂÖàË®ìÁ∑¥ÁöÑ AI Ê®°ÂûãÂú®Êñ∞Êìç‰ΩúÁí∞Â¢É‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÊúâÂä©ÊñºÊé®ÈÄ≤Â∞ç AI Ê®°ÂûãÁöÑÁêÜËß£ÂíåÈÉ®ÁΩ≤ÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑Â§ßÁöÑË™çË≠âÊû∂ÊßãÔºå‰ª•Â¢ûÂº∑Â∞çÂÖ∂Âú®ÂêÑÁ®ÆÊìç‰ΩúÊ¢ù‰ª∂‰∏ãÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄßÁöÑ‰ø°ÂøÉ„ÄÇ</paragraph>

##### **Russian-Language Multimodal Dataset for Automatic Summarization of Scientific Papers**
2405.07886v1 by Alena Tsanda, Elena Bruches

The paper discusses the creation of a multimodal dataset of Russian-language
scientific papers and testing of existing language models for the task of
automatic text summarization. A feature of the dataset is its multimodal data,
which includes texts, tables and figures. The paper presents the results of
experiments with two language models: Gigachat from SBER and YandexGPT from
Yandex. The dataset consists of 420 papers and is publicly available on
https://github.com/iis-research-team/summarization-dataset.

ÊëòË¶ÅÔºöÊú¨ÊñáËÆ®ËÆ∫‰∫ÜÂàõÂª∫‰øÑËØ≠ÁßëÂ≠¶ËÆ∫ÊñáÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÔºå‰ª•ÂèäÈíàÂØπËá™Âä®ÊñáÊú¨ÊëòË¶Å‰ªªÂä°ÊµãËØïÁé∞ÊúâËØ≠Ë®ÄÊ®°Âûã„ÄÇËØ•Êï∞ÊçÆÈõÜÁöÑÁâπÁÇπÂú®‰∫éÂÖ∂Â§öÊ®°ÊÄÅÊï∞ÊçÆÔºåÂÖ∂‰∏≠ÂåÖÊã¨ÊñáÊú¨„ÄÅË°®Ê†ºÂíåÂõæË°®„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏§ÁßçËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÆûÈ™åÁªìÊûúÔºöÊù•Ëá™ SBER ÁöÑ Gigachat ÂíåÊù•Ëá™ Yandex ÁöÑ YandexGPT„ÄÇËØ•Êï∞ÊçÆÈõÜÂåÖÂê´ 420 ÁØáËÆ∫ÊñáÔºåÂèØÂú® https://github.com/iis-research-team/summarization-dataset ‰∏äÂÖ¨ÂºÄËé∑Âèñ„ÄÇ

##### **Zero-Shot Tokenizer Transfer**
2405.07883v1 by Benjamin Minixhofer, Edoardo Maria Ponti, Ivan Vuliƒá

Language models (LMs) are bound to their tokenizer, which maps raw text to a
sequence of vocabulary items (tokens). This restricts their flexibility: for
example, LMs trained primarily on English may still perform well in other
natural and programming languages, but have vastly decreased efficiency due to
their English-centric tokenizer. To mitigate this, we should be able to swap
the original LM tokenizer with an arbitrary one, on the fly, without degrading
performance. Hence, in this work we define a new problem: Zero-Shot Tokenizer
Transfer (ZeTT). The challenge at the core of ZeTT is finding embeddings for
the tokens in the vocabulary of the new tokenizer. Since prior heuristics for
initializing embeddings often perform at chance level in a ZeTT setting, we
propose a new solution: we train a hypernetwork taking a tokenizer as input and
predicting the corresponding embeddings. We empirically demonstrate that the
hypernetwork generalizes to new tokenizers both with encoder (e.g., XLM-R) and
decoder LLMs (e.g., Mistral-7B). Our method comes close to the original models'
performance in cross-lingual and coding tasks while markedly reducing the
length of the tokenized sequence. We also find that the remaining gap can be
quickly closed by continued training on less than 1B tokens. Finally, we show
that a ZeTT hypernetwork trained for a base (L)LM can also be applied to
fine-tuned variants without extra training. Overall, our results make
substantial strides toward detaching LMs from their tokenizer.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã (LM) ÂèóÈôêÊñºÂÖ∂ÂàÜË©ûÂô®ÔºåÂÆÉÂ∞áÂéüÂßãÊñáÂ≠óÂ∞çÊáâÂà∞Ë©ûÂΩôÈ†ÖÁõÆÔºàÊ®ôË®òÔºâÁöÑÂ∫èÂàó„ÄÇÈÄôÈôêÂà∂‰∫ÜÂÖ∂ÈùàÊ¥ªÊÄßÔºö‰æãÂ¶ÇÔºå‰∏ªË¶Å‰ª•Ëã±Ë™ûË®ìÁ∑¥ÁöÑ LM ‰ªçÂèØËÉΩÂú®ÂÖ∂‰ªñËá™ÁÑ∂Ë™ûË®ÄÂíåÁ®ãÂºèË™ûË®Ä‰∏≠Ë°®ÁèæËâØÂ•ΩÔºå‰ΩÜÁî±ÊñºÂÖ∂‰ª•Ëã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑÊ®ôË®òÂô®ËÄåÂ§ßÂπÖÈôç‰ΩéÊïàÁéá„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊáâË©≤ËÉΩÂ§†Âú®‰∏çÈôç‰ΩéÊïàËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈö®ÊôÇÂ∞áÂéüÂßã LM Ê®ôË®òÂô®ÊõøÊèõÁÇ∫‰ªªÊÑèÊ®ôË®òÂô®„ÄÇÂõ†Ê≠§ÔºåÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂÆöÁæ©‰∫Ü‰∏ÄÂÄãÊñ∞ÂïèÈ°åÔºöÈõ∂Ê¨°Ê®ôË®òÂô®ËΩâÁßª (ZeTT)„ÄÇZeTT ÁöÑÊ†∏ÂøÉÊåëÊà∞ÊòØÁÇ∫Êñ∞Ê®ôË®òÂô®Ë©ûÂΩô‰∏≠ÁöÑÊ®ôË®òÊâæÂà∞ÂµåÂÖ•„ÄÇÁî±ÊñºÁî®ÊñºÂàùÂßãÂåñÂµåÂÖ•ÁöÑÂÖàÈ©óÂïüÁôºÊ≥ïÂú® ZeTT Ë®≠ÂÆö‰∏≠ÈÄöÂ∏∏Ë°®ÁèæÂæóÂÉèÈö®Ê©üÂ±§Á¥öÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑËß£Ê±∫ÊñπÊ°àÔºöÊàëÂÄëË®ìÁ∑¥‰∏ÄÂÄã‰ª•Ê®ôË®òÂô®‰ΩúÁÇ∫Ëº∏ÂÖ•‰∏¶È†êÊ∏¨Â∞çÊáâÂµåÂÖ•ÁöÑË∂ÖÁ∂≤Ë∑Ø„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âË≠âÊòéÔºåË∂ÖÁ∂≤Ë∑ØÂèØ‰ª•Ê¶ÇÊã¨Âà∞Êñ∞ÁöÑÊ®ôË®òÂô®ÔºåÂåÖÊã¨Á∑®Á¢ºÂô® (‰æãÂ¶Ç XLM-R) ÂíåËß£Á¢ºÂô® LLM (‰æãÂ¶Ç Mistral-7B)„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Ë∑®Ë™ûË®ÄÂíåÁ∑®Á¢º‰ªªÂãô‰∏≠Êé•ËøëÂéüÂßãÊ®°ÂûãÁöÑÊïàËÉΩÔºåÂêåÊôÇÈ°ØËëóÊ∏õÂ∞ëÊ®ôË®òÂåñÂ∫èÂàóÁöÑÈï∑Â∫¶„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåÈÄèÈÅéÊåÅÁ∫åË®ìÁ∑¥‰∏çÂà∞ 1B ÂÄãÊ®ôË®òÔºåÂèØ‰ª•Âø´ÈÄüÁ∏ÆÂ∞èÂâ©‰∏ãÁöÑÂ∑ÆË∑ù„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈáùÂ∞çÂü∫Á§é (L)LM Ë®ìÁ∑¥ÁöÑ ZeTT Ë∂ÖÁ∂≤Ë∑Ø‰πüÂèØ‰ª•ÊáâÁî®ÊñºÂæÆË™øËÆäÈ´îÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÊàêÊûúÂú®Â∞á LM ÂæûÂÖ∂Ê®ôË®òÂô®‰∏≠ÂàÜÈõ¢Âá∫‰æÜÊñπÈù¢ÂèñÂæó‰∫ÜÈáçÂ§ßÈÄ≤Â±ï„ÄÇ

##### **Reproducing the Metric-Based Evaluation of a Set of Controllable Text Generation Techniques**
2405.07875v1 by Michela Lorandi, Anya Belz

Rerunning a metric-based evaluation should be more straightforward, and
results should be closer, than in a human-based evaluation, especially where
code and model checkpoints are made available by the original authors. As this
report of our efforts to rerun a metric-based evaluation of a set of
single-attribute and multiple-attribute controllable text generation (CTG)
techniques shows however, such reruns of evaluations do not always produce
results that are the same as the original results, and can reveal errors in the
reporting of the original work.

ÊëòË¶ÅÔºöÈáçÊñ∞Âü∑Ë°åÂü∫ÊñºÊåáÊ®ôÁöÑË©ï‰º∞ÊáâË©≤Êõ¥ÁÇ∫Áõ¥Êé•ÔºåËÄå‰∏îÁµêÊûúÊáâË©≤ÊØîÂú®Âü∫Êñº‰∫∫ÁÇ∫ÁöÑË©ï‰º∞‰∏≠Êõ¥Êé•ËøëÔºåÁâπÂà•ÊòØÂú®ÂéüÂßã‰ΩúËÄÖÊèê‰æõÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÊ™¢Êü•ÈªûÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÁÑ∂ËÄåÔºåÊ≠£Â¶ÇÊàëÂÄëÈáçÊñ∞Âü∑Ë°å‰∏ÄÁµÑÂñÆ‰∏ÄÂ±¨ÊÄßÂíåÂ§öÈáçÂ±¨ÊÄßÂèØÊéßÊñáÊú¨ÁîüÊàê (CTG) ÊäÄË°ìÁöÑÂü∫ÊñºÊåáÊ®ôÁöÑË©ï‰º∞ÁöÑÂä™ÂäõÂ†±ÂëäÊâÄÁ§∫ÔºåÊ≠§È°ûÈáçÊñ∞Âü∑Ë°åÁöÑË©ï‰º∞‰∏¶ÈùûÁ∏ΩÊòØÊúÉÁî¢ÁîüËàáÂéüÂßãÁµêÊûúÁõ∏ÂêåÁöÑÁªìÊûúÔºå‰∏¶‰∏îÂèØËÉΩÊúÉÊè≠Èú≤ÂéüÂßãÂ∑•‰ΩúÂ†±Âëä‰∏≠ÁöÑÈåØË™§„ÄÇ

##### **RLHF Workflow: From Reward Modeling to Online RLHF**
2405.07863v1 by Hanze Dong, Wei Xiong, Bo Pang, Haoxiang Wang, Han Zhao, Yingbo Zhou, Nan Jiang, Doyen Sahoo, Caiming Xiong, Tong Zhang

We present the workflow of Online Iterative Reinforcement Learning from Human
Feedback (RLHF) in this technical report, which is widely reported to
outperform its offline counterpart by a large margin in the recent large
language model (LLM) literature. However, existing open-source RLHF projects
are still largely confined to the offline learning setting. In this technical
report, we aim to fill in this gap and provide a detailed recipe that is easy
to reproduce for online iterative RLHF. In particular, since online human
feedback is usually infeasible for open-source communities with limited
resources, we start by constructing preference models using a diverse set of
open-source datasets and use the constructed proxy preference model to
approximate human feedback. Then, we discuss the theoretical insights and
algorithmic principles behind online iterative RLHF, followed by a detailed
practical implementation. Our trained LLM, SFR-Iterative-DPO-LLaMA-3-8B-R,
achieves impressive performance on LLM chatbot benchmarks, including
AlpacaEval-2, Arena-Hard, and MT-Bench, as well as other academic benchmarks
such as HumanEval and TruthfulQA. We have shown that supervised fine-tuning
(SFT) and iterative RLHF can obtain state-of-the-art performance with fully
open-source datasets. Further, we have made our models, curated datasets, and
comprehensive step-by-step code guidebooks publicly available. Please refer to
https://github.com/RLHFlow/RLHF-Reward-Modeling and
https://github.com/RLHFlow/Online-RLHF for more detailed information.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂú®ÈÄô‰ªΩÊäÄË°ìÂ†±Âëä‰∏≠‰ªãÁ¥π‰∫Ü‰∫∫È°ûÂõûÈ•ãÂú®Á∑öËø≠‰ª£Âº∑ÂåñÂ≠∏Áøí (RLHF) ÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºåÊìöÂª£Ê≥õÂ†±Â∞éÔºåÂÆÉÂú®ÊúÄËøëÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ÊñáÁçª‰∏≠Â§ßÂπÖÂÑ™ÊñºÂÖ∂Èõ¢Á∑öÂ∞çÊáâÈ†Ö„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈñãÊ∫ê RLHF È†ÖÁõÆÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰ªçÁÑ∂Â±ÄÈôêÊñºÈõ¢Á∑öÂ≠∏ÁøíË®≠ÁΩÆ„ÄÇÂú®ÈÄô‰ªΩÊäÄË°ìÂ†±Âëä‰∏≠ÔºåÊàëÂÄëÊó®Âú®Â°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºå‰∏¶Êèê‰æõ‰∏ÄÂÄãÊòìÊñºË§áË£ΩÁöÑÂú®Á∑öËø≠‰ª£ RLHF ÁöÑË©≥Á¥∞ÈÖçÊñπ„ÄÇÁâπÂà•ÊòØÔºåÁî±ÊñºÂú®Á∑ö‰∫∫È°ûÂõûÈ•ãÈÄöÂ∏∏Â∞çÊñºË≥áÊ∫êÊúâÈôêÁöÑÈñãÊ∫êÁ§æÂçÄ‰æÜË™™‰∏çÂèØË°åÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî®Â§öÊ®£ÂåñÁöÑÈñãÊ∫êÊï∏ÊìöÈõÜÊßãÂª∫ÂÅèÂ•ΩÊ®°ÂûãÔºå‰∏¶‰ΩøÁî®ÊßãÂª∫ÁöÑ‰ª£ÁêÜÂÅèÂ•ΩÊ®°Âûã‰æÜËøë‰ºº‰∫∫È°ûÂõûÈ•ã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëË®éË´ñÂú®Á∑öËø≠‰ª£ RLHF ËÉåÂæåÁöÑÁêÜË´ñË¶ãËß£ÂíåÊºîÁÆóÊ≥ïÂéüÁêÜÔºåÁÑ∂ÂæåÈÄ≤Ë°åË©≥Á¥∞ÁöÑÂØ¶ÈöõÂØ¶‰Ωú„ÄÇÊàëÂÄëË®ìÁ∑¥ÁöÑ LLMÔºåSFR-Iterative-DPO-LLaMA-3-8B-RÔºåÂú® LLM ËÅäÂ§©Ê©üÂô®‰∫∫Âü∫Ê∫ñ‰∏äÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩÔºåÂåÖÊã¨ AlpacaEval-2„ÄÅArena-Hard Âíå MT-BenchÔºå‰ª•ÂèäÂÖ∂‰ªñÂ≠∏Ë°ìÂü∫Ê∫ñÔºå‰æãÂ¶Ç HumanEval Âíå TruthfulQA„ÄÇÊàëÂÄëÂ∑≤Á∂ìË≠âÊòéÔºåÁõ£Áù£ÂæÆË™ø (SFT) ÂíåËø≠‰ª£ RLHF ÂèØ‰ª•‰ΩøÁî®ÂÆåÂÖ®ÈñãÊ∫êÊï∏ÊìöÈõÜÁç≤ÂæóÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∑≤Á∂ìÂÖ¨Èñã‰∫ÜÊàëÂÄëÁöÑÊ®°Âûã„ÄÅÁ≤æÈÅ∏Êï∏ÊìöÈõÜÂíåÂÖ®Èù¢ÁöÑÈÄêÊ≠•Á®ãÂºèÁ¢ºÊåáÂçó„ÄÇÊúâÈóúÊõ¥Â§öË©≥Á¥∞Ë≥áË®äÔºåË´ãÂèÉÈñ± https://github.com/RLHFlow/RLHF-Reward-Modeling Âíå https://github.com/RLHFlow/Online-RLHF„ÄÇ</paragraph>

##### **Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM**
2405.07840v1 by Xiaoyu Chen, Changde Du, Che Liu, Yizhe Wang, Huiguang He

Decoding language information from brain signals represents a vital research
area within brain-computer interfaces, particularly in the context of
deciphering the semantic information from the fMRI signal. However, many
existing efforts concentrate on decoding small vocabulary sets, leaving space
for the exploration of open vocabulary continuous text decoding. In this paper,
we introduce a novel method, the \textbf{Brain Prompt GPT (BP-GPT)}. By using
the brain representation that is extracted from the fMRI as a prompt, our
method can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we
introduce a text-to-text baseline and align the fMRI prompt to the text prompt.
By introducing the text-to-text baseline, our BP-GPT can extract a more robust
brain prompt and promote the decoding of pre-trained LLM. We evaluate our
BP-GPT on the open-source auditory semantic decoding dataset and achieve a
significant improvement up to $4.61\%$ on METEOR and $2.43\%$ on BERTScore
across all the subjects compared to the state-of-the-art method. The
experimental results demonstrate that using brain representation as a prompt to
further drive LLM for auditory neural decoding is feasible and effective.

ÊëòË¶ÅÔºöÂæûËÖ¶ÈÉ®Ë®äËôüËß£Á¢ºË™ûË®ÄË≥áË®äÔºåÂú®ËÖ¶ÈõªËÖ¶‰ªãÈù¢‰∏≠ÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüüÔºåÁâπÂà•ÊòØÂú®Âæû fMRI Ë®äËôü‰∏≠Ëß£Á¢ºË™ûÊÑèË≥áË®äÁöÑËÑàÁµ°‰∏≠„ÄÇÁÑ∂ËÄåÔºåË®±Â§öÁèæÊúâÁöÑÂä™ÂäõÈÉΩÈõÜ‰∏≠Âú®Ëß£Á¢ºÂ∞èÂûãË©ûÂΩôÈõÜ‰∏äÔºåÈÄôÁÇ∫Êé¢Á¥¢ÈñãÊîæÂºèË©ûÂΩôÈÄ£Á∫åÊñáÂ≠óËß£Á¢ºÁïô‰∏ã‰∫ÜÁ©∫Èñì„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥ \textbf{ËÖ¶ÊèêÁ§∫ GPT (BP-GPT)}„ÄÇÈÄèÈÅé‰ΩøÁî®Âæû fMRI ‰∏≠ÊèêÂèñÁöÑËÖ¶ÈÉ®Ë°®Âæµ‰ΩúÁÇ∫ÊèêÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•‰ΩøÁî® GPT-2 Â∞á fMRI Ë®äËôüËß£Á¢ºÊàêÂà∫ÊøÄÊñáÂ≠ó„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñáÂ≠óÂ∞çÊñáÂ≠óÁöÑÂü∫Ê∫ñÔºå‰∏¶Â∞á fMRI ÊèêÁ§∫ËàáÊñáÂ≠óÊèêÁ§∫Â∞çÈΩä„ÄÇÈÄèÈÅéÂºïÂÖ•ÊñáÂ≠óÂ∞çÊñáÂ≠óÁöÑÂü∫Ê∫ñÔºåÊàëÂÄëÁöÑ BP-GPT ÂèØ‰ª•ÊèêÂèñÊõ¥Á©©ÂÅ•ÁöÑËÖ¶ÈÉ®ÊèêÁ§∫Ôºå‰∏¶‰øÉÈÄ≤È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ LLM ÁöÑËß£Á¢º„ÄÇÊàëÂÄëÂú®ÈñãÊîæÂéüÂßãÁ¢ºËÅΩË¶∫Ë™ûÊÑèËß£Á¢ºË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑ BP-GPTÔºå‰∏¶Âú® METEOR ‰∏äÁç≤ÂæóÈ´òÈÅî 4.61%ÔºåÂú® BERTScore ‰∏äÁç≤Âæó 2.43% ÁöÑÈ°ØËëóÊîπÈÄ≤ÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåÊâÄÊúâÂèóË©¶ËÄÖÈÉΩÁç≤Âæó‰∫ÜÊîπÈÄ≤„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºå‰ΩøÁî®ËÖ¶ÈÉ®Ë°®Âæµ‰ΩúÁÇ∫ÊèêÁ§∫ÔºåÈÄ≤‰∏ÄÊ≠•È©ÖÂãï LLM ÈÄ≤Ë°åËÅΩË¶∫Á•ûÁ∂ìËß£Á¢ºÊòØÂèØË°å‰∏îÊúâÊïàÁöÑ„ÄÇ

##### **Synthetic Tabular Data Validation: A Divergence-Based Approach**
2405.07822v1 by Patricia A. Apell√°niz, Ana Jim√©nez, Borja Arroyo Galende, Juan Parras, Santiago Zazo

The ever-increasing use of generative models in various fields where tabular
data is used highlights the need for robust and standardized validation metrics
to assess the similarity between real and synthetic data. Current methods lack
a unified framework and rely on diverse and often inconclusive statistical
measures. Divergences, which quantify discrepancies between data distributions,
offer a promising avenue for validation. However, traditional approaches
calculate divergences independently for each feature due to the complexity of
joint distribution modeling. This paper addresses this challenge by proposing a
novel approach that uses divergence estimation to overcome the limitations of
marginal comparisons. Our core contribution lies in applying a divergence
estimator to build a validation metric considering the joint distribution of
real and synthetic data. We leverage a probabilistic classifier to approximate
the density ratio between datasets, allowing the capture of complex
relationships. We specifically calculate two divergences: the well-known
Kullback-Leibler (KL) divergence and the Jensen-Shannon (JS) divergence. KL
divergence offers an established use in the field, while JS divergence is
symmetric and bounded, providing a reliable metric. The efficacy of this
approach is demonstrated through a series of experiments with varying
distribution complexities. The initial phase involves comparing estimated
divergences with analytical solutions for simple distributions, setting a
benchmark for accuracy. Finally, we validate our method on a real-world dataset
and its corresponding synthetic counterpart, showcasing its effectiveness in
practical applications. This research offers a significant contribution with
applicability beyond tabular data and the potential to improve synthetic data
validation in various fields.

ÊëòË¶ÅÔºö<paragraph>ÁîüÊàêÊ®°ÂûãÂú®‰ΩøÁî®Ë°®Ê†ºË≥áÊñôÁöÑÂêÑÁ®ÆÈ†òÂüü‰∏≠Êó•ÁõäÂ¢ûÂä†ÁöÑ‰ΩøÁî®ÔºåÁ™ÅÈ°Ø‰∫ÜÂ∞çÂÅ•ÂÖ®‰∏îÊ®ôÊ∫ñÂåñÁöÑÈ©óË≠âÊåáÊ®ôÁöÑÈúÄÊ±ÇÔºå‰ª•Ë©ï‰º∞ÁúüÂØ¶Ë≥áÊñôÂíåÂêàÊàêË≥áÊñô‰πãÈñìÁöÑÁõ∏‰ººÊÄß„ÄÇÁõÆÂâçÁöÑÈ©óË≠âÊñπÊ≥ïÁº∫‰πèÁµ±‰∏ÄÁöÑÊû∂ÊßãÔºå‰∏¶‰∏î‰æùË≥¥ÊñºÂ§öÊ®£‰∏îÁ∂ìÂ∏∏Ê≤íÊúâÂÆöË´ñÁöÑÁµ±Ë®àÈáèÂ∫¶„ÄÇÈáèÂåñË≥áÊñôÂàÜ‰ΩàÂ∑ÆÁï∞ÁöÑÂ∑ÆÁï∞Â∫¶ÔºåÁÇ∫È©óË≠âÊèê‰æõ‰∫Ü‰∏ÄÊ¢ùÊúâÂ∏åÊúõÁöÑÈÄîÂæë„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊñπÊ≥ïÁî±ÊñºËÅØÂêàÂàÜ‰ΩàÂª∫Ê®°ÁöÑË§áÈõúÊÄßÔºåÊúÉÈáùÂ∞çÊØèÂÄãÁâπÂæµÁç®Á´ãË®àÁÆóÂ∑ÆÁï∞Â∫¶„ÄÇÊú¨ÊñáÈÄèÈÅéÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÊåëÊà∞ÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Â∑ÆÁï∞Â∫¶‰º∞Ë®à‰æÜÂÖãÊúçÈÇäÈöõÊØîËºÉÊ≥ïÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÊ†∏ÂøÉË≤¢ÁçªÂú®ÊñºÊáâÁî®Â∑ÆÁï∞Â∫¶‰º∞Ë®àÂô®‰æÜÂª∫Á´ã‰∏ÄÂÄãÈ©óË≠âÊåáÊ®ôÔºåËÄÉÊÖÆÁúüÂØ¶Ë≥áÊñôÂíåÂêàÊàêË≥áÊñôÁöÑËÅØÂêàÂàÜ‰Ωà„ÄÇÊàëÂÄëÂà©Áî®Ê©üÁéáÂàÜÈ°ûÂô®‰æÜËøë‰ººË≥áÊñôÈõÜ‰πãÈñìÁöÑÂØÜÂ∫¶ÊØîÔºåÂæûËÄåÊçïÊçâË§áÈõúÁöÑÈóú‰øÇ„ÄÇÊàëÂÄëÁâπÂà•Ë®àÁÆó‰∫ÜÂÖ©ÂÄãÂ∑ÆÁï∞Â∫¶ÔºöÁúæÊâÄÂë®Áü•ÁöÑ Kullback-Leibler (KL) Â∑ÆÁï∞Â∫¶Âíå Jensen-Shannon (JS) Â∑ÆÁï∞Â∫¶„ÄÇKL Â∑ÆÁï∞Â∫¶Âú®Ë©≤È†òÂüüÊúâÊó¢ÂÆöÁöÑÁî®ÈÄîÔºåËÄå JS Â∑ÆÁï∞Â∫¶Â∞çÁ®±‰∏îÊúâÁïåÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÈù†ÁöÑÊåáÊ®ô„ÄÇÈÄôÂÄãÊñπÊ≥ïÁöÑÊïàËÉΩÈÄèÈÅé‰∏ÄÁ≥ªÂàóÂÖ∑Êúâ‰∏çÂêåÂàÜ‰ΩàË§áÈõúÂ∫¶ÁöÑÂØ¶È©óÂæóÂà∞Ë≠âÊòé„ÄÇÂàùÂßãÈöéÊÆµÊ∂âÂèäÂ∞á‰º∞Ë®àÁöÑÂ∑ÆÁï∞Â∫¶ËàáÁ∞°ÂñÆÂàÜ‰ΩàÁöÑËß£ÊûêËß£ÈÄ≤Ë°åÊØîËºÉÔºåË®≠ÂÆöÊ∫ñÁ¢∫Â∫¶ÁöÑÂü∫Ê∫ñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂú®‰∏ÄÂÄãÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÂèäÂÖ∂Â∞çÊáâÁöÑÂêàÊàêÂ∞çÊáâÁâ©‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÈ©óË≠âÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÈáçÂ§ßÁöÑË≤¢ÁçªÔºåÂÖ∂ÈÅ©Áî®ÊÄß‰∏çÂÉÖÈôêÊñºË°®Ê†ºË≥áÊñôÔºå‰∏¶‰∏îÊúâÊΩõÂäõÊîπÂñÑÂêÑÁ®ÆÈ†òÂüü‰∏≠ÁöÑÂêàÊàêË≥áÊñôÈ©óË≠â„ÄÇ</paragraph>

##### **Quick and Accurate Affordance Learning**
2405.07816v1 by Fedor Scholz, Erik Ayari, Johannes Bertram, Martin V. Butz

Infants learn actively in their environments, shaping their own learning
curricula. They learn about their environments' affordances, that is, how local
circumstances determine how their behavior can affect the environment. Here we
model this type of behavior by means of a deep learning architecture. The
architecture mediates between global cognitive map exploration and local
affordance learning. Inference processes actively move the simulated agent
towards regions where they expect affordance-related knowledge gain. We
contrast three measures of uncertainty to guide this exploration: predicted
uncertainty of a model, standard deviation between the means of several models
(SD), and the Jensen-Shannon Divergence (JSD) between several models. We show
that the first measure gets fooled by aleatoric uncertainty inherent in the
environment, while the two other measures focus learning on epistemic
uncertainty. JSD exhibits the most balanced exploration strategy. From a
computational perspective, our model suggests three key ingredients for
coordinating the active generation of learning curricula: (1) Navigation
behavior needs to be coordinated with local motor behavior for enabling active
affordance learning. (2) Affordances need to be encoded locally for acquiring
generalized knowledge. (3) Effective active affordance learning mechanisms
should use density comparison techniques for estimating expected knowledge
gain. Future work may seek collaborations with developmental psychology to
model active play in children in more realistic scenarios.

ÊëòË¶ÅÔºöÂ¨∞ÂÖíÁ©çÊ•µÂú∞Âú®‰ªñÂÄëÁöÑÁí∞Â¢É‰∏≠Â≠∏ÁøíÔºåÂ°ëÈÄ†‰ªñÂÄëËá™Â∑±ÁöÑÂ≠∏ÁøíË™≤Á®ã„ÄÇ‰ªñÂÄë‰∫ÜËß£‰ªñÂÄëÁí∞Â¢ÉÁöÑÂèØËÉΩÊÄßÔºå‰πüÂ∞±ÊòØË™™ÔºåÁï∂Âú∞Áí∞Â¢ÉÂ¶Ç‰ΩïÊ±∫ÂÆö‰ªñÂÄëÁöÑË°åÁÇ∫Â¶Ç‰ΩïÂΩ±ÈüøÁí∞Â¢É„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÈÄöÈÅéÊ∑±Â∫¶Â≠∏ÁøíÊû∂ÊßãÂ∞çÈÄôÁ®ÆË°åÁÇ∫È°ûÂûãÈÄ≤Ë°åÂª∫Ê®°„ÄÇË©≤Êû∂ÊßãÂú®ÂÖ®Â±ÄË™çÁü•Âú∞ÂúñÊé¢Á¥¢ÂíåÂ±ÄÈÉ®ÂèØËÉΩÊÄßÂ≠∏Áøí‰πãÈñìÈÄ≤Ë°åË™øËß£„ÄÇÊé®ÁêÜÈÅéÁ®ãÁ©çÊ•µÂú∞Â∞áÊ®°Êì¨‰ª£ÁêÜÁßªÂãïÂà∞‰ªñÂÄëÈ†êÊúüÁç≤ÂæóÂèØËÉΩÊÄßÁõ∏ÈóúÁü•Ë≠òÁöÑÂú∞ÂçÄ„ÄÇÊàëÂÄëÂ∞ç‰∏çÁ¢∫ÂÆöÊÄßÁöÑ‰∏âÂÄãÊ∏¨ÈáèÈÄ≤Ë°åÂ∞çÊØîÔºå‰ª•ÊåáÂ∞éÊ≠§Êé¢Á¥¢ÔºöÊ®°ÂûãÁöÑÈ†êÊ∏¨‰∏çÁ¢∫ÂÆöÊÄß„ÄÅÂπæÂÄãÊ®°ÂûãÁöÑÂπ≥ÂùáÂÄº‰πãÈñìÁöÑÊ®ôÊ∫ñÂ∑Æ (SD) ‰ª•ÂèäÂπæÂÄãÊ®°Âûã‰πãÈñìÁöÑ Jensen-Shannon Êï£Â∫¶ (JSD)„ÄÇÊàëÂÄëË°®ÊòéÔºåÁ¨¨‰∏ÄÂÄãÊ∏¨ÈáèË¢´Áí∞Â¢É‰∏≠Âõ∫ÊúâÁöÑÂÅ∂ÁÑ∂‰∏çÁ¢∫ÂÆöÊÄßÊâÄÊÑöÂºÑÔºåËÄåÂè¶Â§ñÂÖ©ÂÄãÊ∏¨ÈáèÂâáÂ∞áÂ≠∏ÁøíÈáçÈªûÊîæÂú®Ë™çË≠òË´ñ‰∏çÁ¢∫ÂÆöÊÄß‰∏ä„ÄÇJSD Ë°®ÁèæÂá∫ÊúÄÂπ≥Ë°°ÁöÑÊé¢Á¥¢Á≠ñÁï•„ÄÇÂæûË®àÁÆóÁöÑËßíÂ∫¶‰æÜÁúãÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊèêÂá∫‰∫ÜÂçîË™ø‰∏ªÂãïÁîüÊàêÂ≠∏ÁøíË™≤Á®ãÁöÑ‰∏âÂÄãÈóúÈçµË¶ÅÁ¥†Ôºö(1) Â∞éËà™Ë°åÁÇ∫ÈúÄË¶ÅËàáÂ±ÄÈÉ®ÈÅãÂãïË°åÁÇ∫ÂçîË™øÔºå‰ª•ÂØ¶Áèæ‰∏ªÂãïÂèØËÉΩÊÄßÂ≠∏Áøí„ÄÇ(2) ÂèØËÉΩÊÄßÈúÄË¶ÅÂú®Â±ÄÈÉ®Á∑®Á¢º‰ª•Áç≤ÂèñÂª£Ê≥õÁöÑÁü•Ë≠ò„ÄÇ(3) ÊúâÊïàÁöÑÁ©çÊ•µÂèØËÉΩÊÄßÂ≠∏ÁøíÊ©üÂà∂Êáâ‰ΩøÁî®ÂØÜÂ∫¶ÊØîËºÉÊäÄË°ì‰æÜ‰º∞Ë®àÈ†êÊúüÁöÑÁü•Ë≠òÊî∂Áõä„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØ‰ª•Â∞ãÊ±ÇËàáÁôºÂ±ïÂøÉÁêÜÂ≠∏ÁöÑÂêà‰ΩúÔºåÂú®Êõ¥ÁèæÂØ¶ÁöÑÂ†¥ÊôØ‰∏≠Â∞çÂÖíÁ´•ÁöÑÁ©çÊ•µÈÅäÊà≤ÈÄ≤Ë°åÂª∫Ê®°„ÄÇ

##### **Decoding Geometric Properties in Non-Random Data from First Information-Theoretic Principles**
2405.07803v1 by Hector Zenil, Felipe S. Abrah√£o

Based on the principles of information theory, measure theory, and
theoretical computer science, we introduce a univariate signal deconvolution
method with a wide range of applications to coding theory, particularly in
zero-knowledge one-way communication channels, such as in deciphering messages
from unknown generating sources about which no prior knowledge is available and
to which no return message can be sent. Our multidimensional space
reconstruction method from an arbitrary received signal is proven to be
agnostic vis-a-vis the encoding-decoding scheme, computation model, programming
language, formal theory, the computable (or semi-computable) method of
approximation to algorithmic complexity, and any arbitrarily chosen
(computable) probability measure of the events. The method derives from the
principles of an approach to Artificial General Intelligence capable of
building a general-purpose model of models independent of any arbitrarily
assumed prior probability distribution. We argue that this optimal and
universal method of decoding non-random data has applications to signal
processing, causal deconvolution, topological and geometric properties
encoding, cryptography, and bio- and technosignature detection.

ÊëòË¶ÅÔºöÂü∫ÊñºË≥áË®äÁêÜË´ñ„ÄÅÊ∏¨Â∫¶ÁêÜË´ñÂíåÁêÜË´ñÈõªËÖ¶ÁßëÂ≠∏ÁöÑÂéüÁêÜÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂñÆËÆäÈáè‰ø°ËôüÂèçÊë∫Á©çÊñπÊ≥ïÔºåÂÆÉÂú®Á∑®Á¢ºÁêÜË´ñ‰∏≠ÂÖ∑ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÂú®Èõ∂Áü•Ë≠òÂñÆÂêëÈÄö‰ø°ÈÄöÈÅì‰∏≠Ôºå‰æãÂ¶ÇÂú®Á†¥Ë≠Ø‰æÜËá™Êú™Áü•ÁîüÊàêÊ∫êÁöÑË®äÊÅØÊôÇÔºåÈÄô‰∫õË®äÊÅØÊ≤íÊúâÂèØÁî®ÁöÑÂÖàÈ©óÁü•Ë≠òÔºå‰∏¶‰∏îÁÑ°Ê≥ïÁôºÈÄÅÂõûÂÇ≥Ë®äÊÅØ„ÄÇÊàëÂÄëÂæû‰ªªÊÑèÊé•Êî∂‰ø°Ëôü‰∏≠ÈáçÂª∫Â§öÁ∂≠Á©∫ÈñìÁöÑÊñπÊ≥ïË¢´Ë≠âÊòéËàáÁ∑®Á¢ºËß£Á¢ºÊñπÊ°à„ÄÅË®àÁÆóÊ®°Âûã„ÄÅÁ®ãÂºèË™ûË®Ä„ÄÅÂΩ¢ÂºèÁêÜË´ñ„ÄÅÊºîÁÆóÊ≥ïË§áÈõúÂ∫¶Ëøë‰ººÁöÑÂèØË®àÁÆóÔºàÊàñÂçäÂèØË®àÁÆóÔºâÊñπÊ≥ïÔºå‰ª•Âèä‰∫ã‰ª∂ÁöÑ‰ªª‰Ωï‰ªªÊÑèÈÅ∏ÊìáÔºàÂèØË®àÁÆóÔºâÊ©üÁéáÊ∏¨Â∫¶ÁÑ°Èóú„ÄÇË©≤ÊñπÊ≥ïÊ∫êËá™‰∫∫Â∑•ÈÄöÁî®Êô∫ÊÖßÁöÑ‰∏ÄÁ®ÆÊñπÊ≥ïÁöÑÂéüÁêÜÔºåË©≤ÊñπÊ≥ïËÉΩÂ§†Âª∫Á´ã‰∏ÄÂÄãÈÄöÁî®Ê®°ÂûãÊ®°ÂûãÔºåËÄåËàá‰ªª‰Ωï‰ªªÊÑèÂÅáË®≠ÁöÑÂÖàÈ©óÊ©üÁéáÂàÜ‰ΩàÁÑ°Èóú„ÄÇÊàëÂÄëË™çÁÇ∫ÔºåÈÄôÁ®ÆÊúÄ‰Ω≥‰∏îÈÄöÁî®ÁöÑÈùûÈö®Ê©üË≥áÊñôËß£Á¢ºÊñπÊ≥ïÂú®‰ø°ËôüËôïÁêÜ„ÄÅÂõ†ÊûúÂèçÊë∫Á©ç„ÄÅÊãìÊí≤ÂíåÂπæ‰ΩïÊÄßË≥™Á∑®Á¢º„ÄÅÂØÜÁ¢ºÂ≠∏‰ª•ÂèäÁîüÁâ©ÂíåÊäÄË°ìÁâπÂæµÂÅµÊ∏¨‰∏≠ÈÉΩÊúâÊáâÁî®„ÄÇ

##### **FreeVA: Offline MLLM as Training-Free Video Assistant**
2405.07798v1 by Wenhao Wu

This paper undertakes an empirical study to revisit the latest advancements
in Multimodal Large Language Models (MLLMs): Video Assistant. This study,
namely FreeVA, aims to extend existing image-based MLLM to the video domain in
a training-free manner. The study provides an essential, yet must-know
baseline, and reveals several surprising findings: 1) FreeVA, leveraging only
offline image-based MLLM without additional training, excels in zero-shot video
question-answering (e.g., MSVD-QA, ActivityNet-QA, and MSRVTT-QA), even
surpassing state-of-the-art methods that involve video instruction tuning. 2)
While mainstream video-based MLLMs typically initialize with an image-based
MLLM (e.g., LLaVA) and then fine-tune using video instruction tuning, the study
indicates that utilizing the widely adopted VideoInstruct-100K for video
instruction tuning doesn't actually lead to better performance compared to not
training at all. 3) The commonly used evaluation metrics in existing works are
significantly influenced by changes in the GPT API version over time. If
ignored, this could affect the fairness and uniformity of comparisons between
different methods and impact the analysis and judgment of researchers in the
field. The advancement of MLLMs is currently thriving, drawing numerous
researchers into the field. We aim for this work to serve as a plug-and-play,
simple yet effective baseline, encouraging the direct evaluation of existing
MLLMs in video domain while also standardizing the field of video
conversational models to a certain extent. Also, we encourage researchers to
reconsider: Have current video MLLM methods truly acquired knowledge beyond
image MLLM? Code is available at https://github.com/whwu95/FreeVA

ÊëòË¶ÅÔºö<paragraph>Êú¨ÊñáÈÄ≤Ë°å‰∏ÄÈ†ÖÂØ¶Ë≠âÁ†îÁ©∂Ôºå‰ª•ÈáçÊñ∞Êé¢Ë®éÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ‰∏≠ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºöÂΩ±ÁâáÂä©ÁêÜ„ÄÇÊú¨Á†îÁ©∂ÔºåÂç≥ FreeVAÔºåÊó®Âú®‰ª•ÁÑ°ÈúÄË®ìÁ∑¥ÁöÑÊñπÂºèÂ∞áÁèæÊúâÁöÑÂü∫ÊñºÂΩ±ÂÉèÁöÑ MLLM Êì¥Â±ïÂà∞ÂΩ±ÁâáÈ†òÂüü„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂøÖË¶ÅÁöÑ‰∏îÂøÖÈ†àÁü•ÈÅìÁöÑÂü∫Ê∫ñÔºå‰∏¶Êè≠Á§∫‰∫ÜÂπæÂÄã‰ª§‰∫∫È©öË®ùÁöÑÁôºÁèæÔºö1) FreeVA ÂÉÖÂà©Áî®Èõ¢Á∑öÁöÑÂü∫ÊñºÂΩ±ÂÉèÁöÑ MLLMÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑË®ìÁ∑¥ÔºåÂ∞±ËÉΩÂú®Èõ∂Ê¨°Â≠∏ÁøíÂΩ±ÁâáÂïèÁ≠îÔºà‰æãÂ¶Ç MSVD-QA„ÄÅActivityNet-QA Âíå MSRVTT-QAÔºâÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÊ∂âÂèäÂΩ±ÁâáÊåá‰ª§ÂæÆË™øÁöÑÁèæÊúâÊñπÊ≥ï„ÄÇ2) ÂÑòÁÆ°‰∏ªÊµÅÁöÑÂü∫ÊñºÂΩ±ÁâáÁöÑ MLLM ÈÄöÂ∏∏‰ΩøÁî®Âü∫ÊñºÂΩ±ÂÉèÁöÑ MLLMÔºà‰æãÂ¶Ç LLaVAÔºâÂàùÂßãÂåñÔºåÁÑ∂Âæå‰ΩøÁî®ÂΩ±ÁâáÊåá‰ª§ÂæÆË™øÈÄ≤Ë°åÂæÆË™øÔºå‰ΩÜÁ†îÁ©∂Ë°®ÊòéÔºå‰ΩøÁî®Âª£Ê≥õÊé°Áî®ÁöÑ VideoInstruct-100K ÈÄ≤Ë°åÂΩ±ÁâáÊåá‰ª§ÂæÆË™ø‰∏¶Êú™ÁúüÊ≠£Â∏∂‰æÜÊØîÂÆåÂÖ®‰∏çÈÄ≤Ë°åË®ìÁ∑¥Êõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇ3) ÁèæÊúâÁ†îÁ©∂‰∏≠Â∏∏Áî®ÁöÑË©ïÈáèÊåáÊ®ôÊúÉÈö®ËëóÊôÇÈñìÊé®ÁßªËÄåÂèóÂà∞ GPT API ÁâàÊú¨ËÆäÊõ¥ÁöÑÈ°ØËëóÂΩ±Èüø„ÄÇÂ¶ÇÊûúÂøΩÁï•ÈÄô‰∏ÄÈªûÔºåÂèØËÉΩÊúÉÂΩ±Èüø‰∏çÂêåÊñπÊ≥ï‰πãÈñìÊØîËºÉÊôÇÂÖ¨Âπ≥ÊÄßÂíå‰∏ÄËá¥ÊÄßÔºå‰∏¶ÂΩ±ÈüøË©≤È†òÂüüÁ†îÁ©∂‰∫∫Âì°ÁöÑÂàÜÊûêÂíåÂà§Êñ∑„ÄÇMLLM ÁöÑÈÄ≤Â±ïÁõÆÂâçËì¨ÂãÉÁôºÂ±ïÔºåÂê∏Âºï‰∫ÜË®±Â§öÁ†îÁ©∂‰∫∫Âì°ÈÄ≤ÂÖ•Ë©≤È†òÂüü„ÄÇÊàëÂÄëÂ∏åÊúõÈÄôÈ†ÖÂ∑•‰ΩúËÉΩ‰ΩúÁÇ∫‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®„ÄÅÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÂü∫Ê∫ñÔºåÈºìÂãµÁõ¥Êé•Ë©ï‰º∞ÂΩ±ÁâáÈ†òÂüü‰∏≠ÁèæÊúâÁöÑ MLLMÔºåÂêåÊôÇ‰πüÂú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÊ®ôÊ∫ñÂåñÂΩ±ÁâáÂ∞çË©±Ê®°ÂûãÁöÑÈ†òÂüü„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈºìÂãµÁ†îÁ©∂‰∫∫Âì°ÈáçÊñ∞ËÄÉÊÖÆÔºöÁõÆÂâçÁöÑÂΩ±Áâá MLLM ÊñπÊ≥ïÊòØÂê¶ÁúüÊ≠£Áç≤Âæó‰∫ÜË∂ÖË∂äÂΩ±ÂÉè MLLM ÁöÑÁü•Ë≠òÔºüÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/whwu95/FreeVA ÂèñÂæó</paragraph>

##### **DEPTH: Discourse Education through Pre-Training Hierarchically**
2405.07788v1 by Zachary Bamberger, Ofek Glick, Chaim Baskin, Yonatan Belinkov

Language Models (LMs) often struggle with linguistic understanding at the
discourse level, even though discourse patterns such as coherence, cohesion,
and narrative flow are prevalent in their pre-training data. Current methods
address these challenges only after the pre-training phase, relying on
expensive human annotated data to align the model. To improve the discourse
capabilities of LMs already at the pre-training stage, we introduce DEPTH, an
encoder-decoder model that learns to represent sentences using a
discourse-oriented pre-training objective. DEPTH combines hierarchical sentence
representations with two objectives: (1) Sentence Un-Shuffling, and (2)
Span-Corruption. This approach trains the model to represent both
sub-word-level and sentence-level dependencies over a massive amount of
unstructured text. When trained either from scratch or continuing from a
pre-trained T5 checkpoint, DEPTH learns semantic and discourse-level
representations faster than T5, outperforming it in span-corruption loss
despite the additional sentence-un-shuffling objective. Evaluations on the
GLUE, DiscoEval, and NI benchmarks demonstrate DEPTH's ability to quickly learn
diverse downstream tasks, which require syntactic, semantic, and discourse
capabilities. Overall, our approach extends the discourse capabilities of T5,
while minimally impacting other natural language understanding (NLU)
capabilities in the resulting LM.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°Âûã (LM) Á∂ìÂ∏∏Âú®Ë™ûÁØáÂ±§Á¥öÁöÑË™ûË®ÄÁêÜËß£‰∏äÈÅáÂà∞Âõ∞Èõ£ÔºåÂç≥‰ΩøÈÄ£Ë≤´ÊÄß„ÄÅÂáùËÅöÂäõÂíåÊïò‰∫ãÊµÅÁ≠âË™ûÁØáÊ®°ÂºèÂú®ÂÖ∂È†êË®ìÁ∑¥Ë≥áÊñô‰∏≠ÂæàÊôÆÈÅç„ÄÇÁõÆÂâçÁöÑÊäÄË°ìÂè™Âú®È†êË®ìÁ∑¥ÈöéÊÆµ‰πãÂæåÊâçËôïÁêÜÈÄô‰∫õÊåëÊà∞Ôºå‰æùË≥¥ÊòÇË≤¥ÁöÑ‰∫∫Â∑•Ë®ªËß£Ë≥áÊñô‰æÜË™øÊï¥Ê®°Âûã„ÄÇÁÇ∫‰∫ÜÂú®È†êË®ìÁ∑¥ÈöéÊÆµÂ∞±ÊèêÂçá LM ÁöÑË™ûÁØáËÉΩÂäõÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü DEPTHÔºå‰∏ÄÂÄãÁ∑®Á¢ºÂô®-Ëß£Á¢ºÂô®Ê®°ÂûãÔºåÂÆÉÂ≠∏Áøí‰ΩøÁî®‰ª•Ë™ûÁØáÁÇ∫Â∞éÂêëÁöÑÈ†êË®ìÁ∑¥ÁõÆÊ®ô‰æÜË°®Á§∫Âè•Â≠ê„ÄÇDEPTH ÁµêÂêà‰∫ÜÂàÜÂ±§Âè•Â≠êË°®Á§∫Ê≥ïÂíåÂÖ©ÂÄãÁõÆÊ®ôÔºö(1) Âè•Â≠êÂèñÊ∂àÊ∑∑Ê¥óÔºå‰ª•Âèä (2) ÂçÄÈñìÊêçÊØÄ„ÄÇÊ≠§ÊñπÊ≥ïË®ìÁ∑¥Ê®°ÂûãË°®Á§∫Êµ∑ÈáèÈùûÁµêÊßãÂåñÊñáÂ≠ó‰∏≠ÁöÑÂ≠êÂ≠óÂÖÉÂ±§Á¥öÂíåÂè•Â≠êÂ±§Á¥ö‰æùË≥¥ÊÄß„ÄÇÁï∂ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥ÊàñÂæûÈ†êË®ìÁ∑¥ÁöÑ T5 Ê™¢Êü•ÈªûÁπºÁ∫åË®ìÁ∑¥ÊôÇÔºåDEPTH ÊúÉÊØî T5 Êõ¥Âø´Âú∞Â≠∏ÁøíË™ûÁæ©ÂíåË™ûÁØáÂ±§Á¥öË°®Á§∫Ê≥ïÔºåÂÑòÁÆ°ÊúâÈ°çÂ§ñÁöÑÂè•Â≠êÂèñÊ∂àÊ∑∑Ê¥óÁõÆÊ®ôÔºå‰ΩÜÂú®ÂçÄÈñìÊêçÊØÄÊêçÂ§±‰∏≠Ë°®ÁèæÂÑ™Êñº T5„ÄÇÂú® GLUE„ÄÅDiscoEval Âíå NI Âü∫Ê∫ñ‰∏äÁöÑË©ï‰º∞Ë≠âÊòé‰∫Ü DEPTH Âø´ÈÄüÂ≠∏ÁøíÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÁöÑËÉΩÂäõÔºåÈÄô‰∫õ‰ªªÂãôÈúÄË¶ÅÂè•Ê≥ï„ÄÅË™ûÁæ©ÂíåË™ûÁØáËÉΩÂäõ„ÄÇÁ∏ΩÈ´îËÄåË®ÄÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊì¥Â±ï‰∫Ü T5 ÁöÑË™ûÁØáËÉΩÂäõÔºåÂêåÊôÇÂ∞áÂ∞çÊúÄÁµÇ LM ‰∏≠ÂÖ∂‰ªñËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ (NLU) ËÉΩÂäõÁöÑÂΩ±ÈüøÈôçËá≥ÊúÄ‰Ωé„ÄÇ

##### **A Comprehensive Analysis of Static Word Embeddings for Turkish**
2405.07778v1 by Karahan Sarƒ±ta≈ü, Cahid Arda √ñz, Tunga G√ºng√∂r

Word embeddings are fixed-length, dense and distributed word representations
that are used in natural language processing (NLP) applications. There are
basically two types of word embedding models which are non-contextual (static)
models and contextual models. The former method generates a single embedding
for a word regardless of its context, while the latter method produces distinct
embeddings for a word based on the specific contexts in which it appears. There
are plenty of works that compare contextual and non-contextual embedding models
within their respective groups in different languages. However, the number of
studies that compare the models in these two groups with each other is very few
and there is no such study in Turkish. This process necessitates converting
contextual embeddings into static embeddings. In this paper, we compare and
evaluate the performance of several contextual and non-contextual models in
both intrinsic and extrinsic evaluation settings for Turkish. We make a
fine-grained comparison by analyzing the syntactic and semantic capabilities of
the models separately. The results of the analyses provide insights about the
suitability of different embedding models in different types of NLP tasks. We
also build a Turkish word embedding repository comprising the embedding models
used in this work, which may serve as a valuable resource for researchers and
practitioners in the field of Turkish NLP. We make the word embeddings,
scripts, and evaluation datasets publicly available.

ÊëòË¶ÅÔºöÂ≠óË©ûÂµåÂÖ•ÊòØÂõ∫ÂÆöÈï∑Â∫¶„ÄÅÂØÜÈõÜ‰∏îÂàÜÊï£ÁöÑÂ≠óË©ûË°®Á§∫ÔºåÁî®ÊñºËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊáâÁî®Á®ãÂºè‰∏≠„ÄÇÂü∫Êú¨‰∏äÊúâÂÖ©Á®ÆÂ≠óË©ûÂµåÂÖ•Ê®°ÂûãÔºåÂàÜÂà•ÊòØÈùûË™ûÂ¢É (ÈùúÊÖã) Ê®°ÂûãÂíåË™ûÂ¢ÉÊ®°Âûã„ÄÇÂâç‰∏ÄÁ®ÆÊñπÊ≥ïÁÇ∫Â≠óË©ûÁî¢ÁîüÂñÆ‰∏ÄÂµåÂÖ•Ôºå‰∏çË´ñÂÖ∂Ë™ûÂ¢ÉÁÇ∫‰ΩïÔºåËÄåÂæå‰∏ÄÁ®ÆÊñπÊ≥ïÂâáÊ†πÊìöÂ≠óË©ûÂá∫ÁèæÁöÑÁâπÂÆöË™ûÂ¢ÉÁÇ∫ÂÖ∂Áî¢Áîü‰∏çÂêåÁöÑÂµåÂÖ•„ÄÇÊúâË®±Â§öÁ†îÁ©∂Âú®‰∏çÂêåË™ûË®Ä‰∏≠ÊØîËºÉÂÖ∂ÂêÑËá™Áæ§ÁµÑ‰∏≠ÁöÑË™ûÂ¢ÉÂíåÈùûË™ûÂ¢ÉÂµåÂÖ•Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÊØîËºÉÈÄôÂÖ©ÁµÑ‰∏≠Ê®°ÂûãÁöÑÁ†îÁ©∂Êï∏ÈáèÈùûÂ∏∏Â∞ëÔºåËÄå‰∏îÊ≤íÊúâÈÄôÈ°ûÁ†îÁ©∂ÈáùÂ∞çÂúüËÄ≥ÂÖ∂Ë™û„ÄÇÊ≠§Á®ãÂ∫èÈúÄË¶ÅÂ∞áË™ûÂ¢ÉÂµåÂÖ•ËΩâÊèõÊàêÈùúÊÖãÂµåÂÖ•„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∏¶Ë©ï‰º∞Â§öÁ®ÆË™ûÂ¢ÉÂíåÈùûË™ûÂ¢ÉÊ®°ÂûãÂú®ÂúüËÄ≥ÂÖ∂Ë™ûÁöÑÂÖßÂú®ÂíåÂ§ñÂú®Ë©ï‰º∞Ë®≠ÂÆö‰∏≠ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÈÄèÈÅéÂÄãÂà•ÂàÜÊûêÊ®°ÂûãÁöÑÂè•Ê≥ïÂíåË™ûÁæ©ËÉΩÂäõÔºåÈÄ≤Ë°åÁ¥∞ÂæÆÁöÑÊØîËºÉ„ÄÇÂàÜÊûêÁµêÊûúÊèê‰æõ‰∫ÜË¶ãËß£ÔºåË™™Êòé‰∏çÂêåÂµåÂÖ•Ê®°ÂûãÂú®‰∏çÂêåÈ°ûÂûãÁöÑ NLP ‰ªªÂãô‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÈÇÑÂª∫ÁΩÆ‰∫Ü‰∏ÄÂÄãÂúüËÄ≥ÂÖ∂Ë™ûÂ≠óË©ûÂµåÂÖ•ÂÑ≤Â≠òÂ∫´ÔºåÂåÖÂê´Ê≠§Á†îÁ©∂‰∏≠‰ΩøÁî®ÁöÑÂµåÂÖ•Ê®°ÂûãÔºåÈÄôÂèØËÉΩÊàêÁÇ∫ÂúüËÄ≥ÂÖ∂Ë™û NLP È†òÂüüÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÂØ¶ÂãôÂ∑•‰ΩúËÄÖÁöÑÂØ∂Ë≤¥Ë≥áÊ∫ê„ÄÇÊàëÂÄëÂÖ¨ÈñãÊèê‰æõÂ≠óË©ûÂµåÂÖ•„ÄÅÊåá‰ª§Á¢ºÂíåË©ï‰º∞Ë≥áÊñôÈõÜ„ÄÇ

##### **Human-Modeling in Sequential Decision-Making: An Analysis through the Lens of Human-Aware AI**
2405.07773v1 by Silvia Tulli, Stylianos Loukas Vasileiou, Sarath Sreedharan

"Human-aware" has become a popular keyword used to describe a particular
class of AI systems that are designed to work and interact with humans. While
there exists a surprising level of consistency among the works that use the
label human-aware, the term itself mostly remains poorly understood. In this
work, we retroactively try to provide an account of what constitutes a
human-aware AI system. We see that human-aware AI is a design-oriented
paradigm, one that focuses on the need for modeling the humans it may interact
with. Additionally, we see that this paradigm offers us intuitive dimensions to
understand and categorize the kinds of interactions these systems might have
with humans. We show the pedagogical value of these dimensions by using them as
a tool to understand and review the current landscape of work related to
human-AI systems that purport some form of human modeling. To fit the scope of
a workshop paper, we specifically narrowed our review to papers that deal with
sequential decision-making and were published in a major AI conference in the
last three years. Our analysis helps identify the space of potential research
problems that are currently being overlooked. We perform additional analysis on
the degree to which these works make explicit reference to results from social
science and whether they actually perform user-studies to validate their
systems. We also provide an accounting of the various AI methods used by these
works.

ÊëòË¶ÅÔºö„Äå‰ª•‰∫∫‰∏∫Êú¨„ÄçÂ∑≤Êàê‰∏∫Áî®Êù•ÊèèËø∞ÁâπÂÆöÁ±ªÂà´ AI Á≥ªÁªüÁöÑ‰∏Ä‰∏™ÊµÅË°åÂÖ≥ÈîÆÂ≠óÔºåËøôÁ±ªÁ≥ªÁªüÊó®Âú®‰∏é‰∫∫Á±ª‰∫íÂä®Âπ∂‰∏∫‰∫∫Á±ªÊúçÂä°„ÄÇËôΩÁÑ∂‰ΩøÁî®„Äå‰ª•‰∫∫‰∏∫Êú¨„ÄçÊ†áÁ≠æÁöÑ‰ΩúÂìÅ‰πãÈó¥Â≠òÂú®‰ª§‰∫∫ÊÉäËÆ∂ÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ΩÜËøô‰∏™ÊúØËØ≠Êú¨Ë∫´‰ªçÁÑ∂Â§ßÂ§öËÆ©‰∫∫Èöæ‰ª•ÁêÜËß£„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨Â∞ùËØïËøΩÊ∫ØÊÄßÂú∞Êèê‰æõ‰∏Ä‰∏™‰ª•‰∫∫‰∏∫Êú¨ AI Á≥ªÁªüÁöÑÊûÑÊàêËØ¥Êòé„ÄÇÊàë‰ª¨ËÆ§‰∏∫Ôºå‰ª•‰∫∫‰∏∫Êú¨ AI ÊòØ‰∏ÄÁßç‰ª•ËÆæËÆ°‰∏∫ÂØºÂêëÁöÑËåÉ‰æãÔºåÂÆÉÁùÄÈáç‰∫éÂØπÂèØËÉΩ‰∏éÂÖ∂‰∫íÂä®ÁöÑÁî®Êà∑ËøõË°åÂª∫Ê®°„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËÆ§‰∏∫Ëøô‰∏™ËåÉ‰æã‰∏∫Êàë‰ª¨Êèê‰æõ‰∫ÜÁõ¥ËßÇÁöÑÁª¥Â∫¶Ôºå‰ª•‰æøÁêÜËß£ÂíåÂàÜÁ±ªËøô‰∫õÁ≥ªÁªüÂèØËÉΩ‰∏é‰∫∫Á±ªËøõË°åÁöÑ‰∫íÂä®Á±ªÂûã„ÄÇÊàë‰ª¨ÈÄöËøáÂ∞ÜËøô‰∫õÁª¥Â∫¶Áî®‰ΩúÂ∑•ÂÖ∑Êù•ÁêÜËß£ÂíåÊ£ÄËßÜ‰∏éÂÆ£Áß∞ÊüêÁßçÂΩ¢ÂºèÁöÑ‰∫∫Á±ªÂª∫Ê®°Áõ∏ÂÖ≥ÁöÑ‰∫∫Êú∫Á≥ªÁªüÂ∑•‰ΩúÁöÑÂΩìÂâçÊ¶ÇÂÜµÔºåÂ±ïÁ§∫‰∫ÜËøô‰∫õÁª¥Â∫¶ÁöÑÊïôÂ≠¶‰ª∑ÂÄº„ÄÇ‰∏∫‰∫ÜÁ¨¶ÂêàÁ†îËÆ®‰ºöËÆ∫ÊñáÁöÑËåÉÂõ¥ÔºåÊàë‰ª¨ÁâπÂà´Â∞ÜÊàë‰ª¨ÁöÑÊ£ÄËßÜËåÉÂõ¥Áº©Â∞èÂà∞Â§ÑÁêÜÈ°∫Â∫èÂÜ≥Á≠ñÂà∂ÂÆö‰∏îÂú®ËøáÂéª‰∏âÂπ¥ÂÜÖÂèëË°®Âú®‰∏ªË¶Å AI ‰ºöËÆÆ‰∏≠ÁöÑËÆ∫Êñá„ÄÇÊàë‰ª¨ÁöÑÂàÜÊûêÊúâÂä©‰∫éËØÜÂà´ÁõÆÂâçË¢´ÂøΩËßÜÁöÑÊΩúÂú®Á†îÁ©∂ÈóÆÈ¢òÁ©∫Èó¥„ÄÇÊàë‰ª¨ÂØπËøô‰∫õ‰ΩúÂìÅÊòéÁ°ÆÂèÇËÄÉÁ§æ‰ºöÁßëÂ≠¶ÁªìÊûúÁöÑÁ®ãÂ∫¶‰ª•Âèä‰ªñ‰ª¨ÊòØÂê¶ÂÆûÈôÖÊâßË°åÁî®Êà∑Á†îÁ©∂Êù•È™åËØÅÂÖ∂Á≥ªÁªüËøõË°å‰∫ÜÈ¢ùÂ§ñÁöÑÂàÜÊûê„ÄÇÊàë‰ª¨ËøòÂØπËøô‰∫õ‰ΩúÂìÅ‰ΩøÁî®ÁöÑÂêÑÁßç AI ÊñπÊ≥ïËøõË°å‰∫ÜËØ¥Êòé„ÄÇ

##### **Synthetic Test Collections for Retrieval Evaluation**
2405.07767v1 by Hossein A. Rahmani, Nick Craswell, Emine Yilmaz, Bhaskar Mitra, Daniel Campos

Test collections play a vital role in evaluation of information retrieval
(IR) systems. Obtaining a diverse set of user queries for test collection
construction can be challenging, and acquiring relevance judgments, which
indicate the appropriateness of retrieved documents to a query, is often costly
and resource-intensive. Generating synthetic datasets using Large Language
Models (LLMs) has recently gained significant attention in various
applications. In IR, while previous work exploited the capabilities of LLMs to
generate synthetic queries or documents to augment training data and improve
the performance of ranking models, using LLMs for constructing synthetic test
collections is relatively unexplored. Previous studies demonstrate that LLMs
have the potential to generate synthetic relevance judgments for use in the
evaluation of IR systems. In this paper, we comprehensively investigate whether
it is possible to use LLMs to construct fully synthetic test collections by
generating not only synthetic judgments but also synthetic queries. In
particular, we analyse whether it is possible to construct reliable synthetic
test collections and the potential risks of bias such test collections may
exhibit towards LLM-based models. Our experiments indicate that using LLMs it
is possible to construct synthetic test collections that can reliably be used
for retrieval evaluation.

ÊëòË¶ÅÔºöÊ∏¨Ë©¶ÈõÜÂêàÂú®Ë≥áË®äÊ™¢Á¥¢ (IR) Á≥ªÁµ±ÁöÑË©ï‰º∞‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂèñÂæóÂ§öÂÖÉÁöÑ‰ΩøÁî®ËÄÖÊü•Ë©¢‰ª•Âª∫Á´ãÊ∏¨Ë©¶ÈõÜÂêàÂèØËÉΩÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåËÄåÂèñÂæóÁõ∏ÈóúÊÄßÂà§Êñ∑ÔºàË°®Á§∫Ê™¢Á¥¢Êñá‰ª∂Â∞çÊü•Ë©¢ÁöÑÈÅ©ÂàáÊÄßÔºâÈÄöÂ∏∏ÊàêÊú¨È´ò‰∏îËÄóË≤ªË≥áÊ∫ê„ÄÇ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî¢ÁîüÂêàÊàêË≥áÊñôÈõÜÊúÄËøëÂú®ÂêÑÁ®ÆÊáâÁî®Á®ãÂºè‰∏≠Áç≤ÂæóÂ§ßÈáèÁöÑÈóúÊ≥®„ÄÇÂú® IR ‰∏≠ÔºåÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂Âà©Áî® LLM ÁöÑÂäüËÉΩÁî¢ÁîüÂêàÊàêÊü•Ë©¢ÊàñÊñá‰ª∂‰ª•Êì¥ÂÖÖË®ìÁ∑¥Ë≥áÊñô‰∏¶ÊîπÂñÑÊéíÂêçÊ®°ÂûãÁöÑÊïàËÉΩÔºå‰ΩÜ‰ΩøÁî® LLM Âª∫Á´ãÂêàÊàêÊ∏¨Ë©¶ÈõÜÂêàÁöÑÈ†òÂüüÁõ∏Â∞çÂ∞öÊú™Êé¢Á¥¢„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Ë≠âÂØ¶ LLM ÂÖ∑ÂÇôÁî¢ÁîüÂêàÊàêÁõ∏ÈóúÊÄßÂà§Êñ∑ÁöÑÊΩõÂäõÔºåÂèØ‰æõ IR Á≥ªÁµ±Ë©ï‰º∞‰ΩøÁî®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂÖ®Èù¢Êé¢Ë®éÊòØÂê¶ÂèØËÉΩ‰ΩøÁî® LLM Âª∫Á´ãÂÆåÂÖ®ÂêàÊàêÁöÑÊ∏¨Ë©¶ÈõÜÂêàÔºåÊñπÊ≥ïÊòØÁî¢ÁîüÂêàÊàêÂà§Êñ∑ÂíåÂêàÊàêÊü•Ë©¢„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÂàÜÊûêÊòØÂê¶ÂèØËÉΩÂª∫Á´ãÂèØÈù†ÁöÑÂêàÊàêÊ∏¨Ë©¶ÈõÜÂêàÔºå‰ª•ÂèäÊ≠§È°ûÊ∏¨Ë©¶ÈõÜÂêàÂèØËÉΩÂ∞çÂü∫Êñº LLM ÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑÊΩõÂú®ÂÅèÂ∑ÆÈ¢®Èö™„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫Ôºå‰ΩøÁî® LLM ÂèØ‰ª•Âª∫Á´ãÂêàÊàêÊ∏¨Ë©¶ÈõÜÂêàÔºåÈÄô‰∫õÈõÜÂêàÂèØË¢´ÂèØÈù†Âú∞Áî®ÊñºÊ™¢Á¥¢Ë©ï‰º∞„ÄÇ

##### **Challenges and Opportunities of NLP for HR Applications: A Discussion Paper**
2405.07766v1 by Jochen L. Leidner, Mark Stevenson

Over the course of the recent decade, tremendous progress has been made in
the areas of machine learning and natural language processing, which opened up
vast areas of potential application use cases, including hiring and human
resource management. We review the use cases for text analytics in the realm of
human resources/personnel management, including actually realized as well as
potential but not yet implemented ones, and we analyze the opportunities and
risks of these.

ÊëòË¶ÅÔºöÂú®ÊúÄËøëÂçÅÂπ¥‰∏≠ÔºåÊú∫Âô®Â≠¶‰π†ÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÜÂüüÂèñÂæó‰∫ÜÈïøË∂≥ÁöÑËøõÊ≠•ÔºåËøôÂºÄËæü‰∫ÜÂ§ßÈáèÊΩúÂú®ÁöÑÂ∫îÁî®Áî®‰æãÔºåÂåÖÊã¨ÊãõËÅòÂíå‰∫∫ÂäõËµÑÊ∫êÁÆ°ÁêÜ„ÄÇÊàë‰ª¨ÂõûÈ°æ‰∫ÜÊñáÊú¨ÂàÜÊûêÂú®‰∫∫ÂäõËµÑÊ∫ê/‰∫∫ÂëòÁÆ°ÁêÜÈ¢ÜÂüüÁöÑÁî®‰æãÔºåÂåÖÊã¨ÂÆûÈôÖÂÆûÁé∞ÁöÑÁî®‰æãÂíåÂ∞öÊú™ÂÆûÁé∞ÁöÑÊΩúÂú®Áî®‰æãÔºåÂπ∂ÂàÜÊûê‰∫ÜËøô‰∫õÁî®‰æãÁöÑÊú∫‰ºöÂíåÈ£éÈô©„ÄÇ

##### **TANQ: An open domain dataset of table answered questions**
2405.07765v1 by Mubashara Akhtar, Chenxi Pang, Andreea Marzoca, Yasemin Altun, Julian Martin Eisenschlos

Language models, potentially augmented with tool usage such as retrieval are
becoming the go-to means of answering questions. Understanding and answering
questions in real-world settings often requires retrieving information from
different sources, processing and aggregating data to extract insights, and
presenting complex findings in form of structured artifacts such as novel
tables, charts, or infographics. In this paper, we introduce TANQ, the first
open domain question answering dataset where the answers require building
tables from information across multiple sources. We release the full source
attribution for every cell in the resulting table and benchmark
state-of-the-art language models in open, oracle, and closed book setups. Our
best-performing baseline, GPT4 reaches an overall F1 score of 29.1, lagging
behind human performance by 19.7 points. We analyse baselines' performance
across different dataset attributes such as different skills required for this
task, including multi-hop reasoning, math operations, and unit conversions. We
further discuss common failures in model-generated answers, suggesting that
TANQ is a complex task with many challenges ahead.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÔºåÊΩõÂú®ÁöÑÂ¢ûÂº∑Â∑•ÂÖ∑‰ΩøÁî®Ôºå‰æãÂ¶ÇÊ™¢Á¥¢ÔºåÊ≠£ÊàêÁÇ∫ÂõûÁ≠îÂïèÈ°åÁöÑÈÄîÂæë„ÄÇÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÁêÜËß£ÂíåÂõûÁ≠îÂïèÈ°åÈÄöÂ∏∏ÈúÄË¶ÅÂæû‰∏çÂêå‰æÜÊ∫êÊ™¢Á¥¢Ë≥áË®ä„ÄÅËôïÁêÜÂíåÂΩôÊï¥Ë≥áÊñô‰ª•ËêÉÂèñË¶ãËß£Ôºå‰∏¶‰ª•ÁµêÊßãÂåñ‰∫∫Â∑•Ë£ΩÂìÅÁöÑÂΩ¢ÂºèÂëàÁèæË§áÈõúÁöÑÁôºÁèæÔºå‰æãÂ¶ÇÊñ∞Á©éÁöÑË°®Ê†º„ÄÅÂúñË°®ÊàñË≥áË®äÂúñË°®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π TANQÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÈñãÊîæÈ†òÂüüÂïèÈ°åËß£Á≠îË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠Á≠îÊ°àÈúÄË¶ÅÂæûÂ§öÂÄã‰æÜÊ∫êÁöÑË≥áË®äÂª∫Á´ãË°®Ê†º„ÄÇÊàëÂÄëÈáãÂá∫ÁµêÊûúË°®Ê†º‰∏≠ÊØèÂÄãÂÑ≤Â≠òÊ†ºÁöÑÂÆåÊï¥‰æÜÊ∫êÊ≠∏Â±¨Ôºå‰∏¶Âú®ÈñãÊîæ„ÄÅÁ•ûË´≠ÂíåÈñâÂç∑Ë®≠ÂÆö‰∏≠Â∞çÊúÄÂÖàÈÄ≤ÁöÑË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÊàëÂÄëÊïàËÉΩÊúÄÂ•ΩÁöÑÂü∫Ê∫ñÔºåGPT4 ÈÅîÂà∞ 29.1 ÁöÑ F1 Á∏ΩÂàÜÔºåËêΩÂæå‰∫∫È°ûË°®Áèæ 19.7 ÂàÜ„ÄÇÊàëÂÄëÂàÜÊûêÂü∫Ê∫ñÂú®‰∏çÂêåË≥áÊñôÈõÜÂ±¨ÊÄß‰∏≠ÁöÑË°®ÁèæÔºå‰æãÂ¶ÇÊ≠§‰ªªÂãôÊâÄÈúÄÁöÑÂêÑÁ®ÆÊäÄËÉΩÔºåÂåÖÊã¨Â§öÈáçË∑≥Ë∫çÊé®ÁêÜ„ÄÅÊï∏Â≠∏ÈÅãÁÆóÂíåÂñÆ‰ΩçÊèõÁÆó„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®éË´ñÊ®°ÂûãÁîüÊàêÁöÑÁ≠îÊ°à‰∏≠Â∏∏Ë¶ãÁöÑÂ§±ÊïóÔºåË°®Êòé TANQ ÊòØ‰∏ÄÂÄãË§áÈõúÁöÑ‰ªªÂãôÔºåÊú™‰æÜÈÇÑÊúâË®±Â§öÊåëÊà∞„ÄÇ

##### **LLM4ED: Large Language Models for Automatic Equation Discovery**
2405.07761v1 by Mengge Du, Yuntian Chen, Zhongzheng Wang, Longfeng Nie, Dongxiao Zhang

Equation discovery is aimed at directly extracting physical laws from data
and has emerged as a pivotal research domain. Previous methods based on
symbolic mathematics have achieved substantial advancements, but often require
the design of implementation of complex algorithms. In this paper, we introduce
a new framework that utilizes natural language-based prompts to guide large
language models (LLMs) in automatically mining governing equations from data.
Specifically, we first utilize the generation capability of LLMs to generate
diverse equations in string form, and then evaluate the generated equations
based on observations. In the optimization phase, we propose two alternately
iterated strategies to optimize generated equations collaboratively. The first
strategy is to take LLMs as a black-box optimizer and achieve equation
self-improvement based on historical samples and their performance. The second
strategy is to instruct LLMs to perform evolutionary operators for global
search. Experiments are extensively conducted on both partial differential
equations and ordinary differential equations. Results demonstrate that our
framework can discover effective equations to reveal the underlying physical
laws under various nonlinear dynamic systems. Further comparisons are made with
state-of-the-art models, demonstrating good stability and usability. Our
framework substantially lowers the barriers to learning and applying equation
discovery techniques, demonstrating the application potential of LLMs in the
field of knowledge discovery.

ÊëòË¶ÅÔºöÊñπÁ®ãÂºèÁôºÁèæÊó®Âú®Áõ¥Êé•ÂæûË≥áÊñô‰∏≠ËêÉÂèñÁâ©ÁêÜÂÆöÂæãÔºå‰∏¶Â∑≤ÊàêÁÇ∫‰∏ÄÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÂÖàÂâçÂü∫ÊñºÁ¨¶ËôüÊï∏Â≠∏ÁöÑÊñπÊ≥ïÂ∑≤ÂèñÂæóÈáçÂ§ßÈÄ≤Â±ïÔºå‰ΩÜÈÄöÂ∏∏ÈúÄË¶ÅË®≠Ë®àÂØ¶‰ΩúË§áÈõúÁöÑÊºîÁÆóÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÊñ∞ÁöÑÊû∂ÊßãÔºåÂà©Áî®Âü∫ÊñºËá™ÁÑ∂Ë™ûË®ÄÁöÑÊèêÁ§∫‰æÜÂºïÂ∞éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæûË≥áÊñô‰∏≠Ëá™ÂãïÊé¢ÂãòÊéßÂà∂ÊñπÁ®ãÂºè„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÂà©Áî® LLM ÁöÑÁîüÊàêËÉΩÂäõ‰ª•Â≠ó‰∏≤ÂΩ¢ÂºèÁîüÊàêÂêÑÁ®ÆÊñπÁ®ãÂºèÔºåÁÑ∂ÂæåÊ†πÊìöËßÄÂØüÁµêÊûúË©ï‰º∞ÁîüÊàêÁöÑÊñπÁ®ãÂºè„ÄÇÂú®ÊúÄ‰Ω≥ÂåñÈöéÊÆµÔºåÊàëÂÄëÊèêÂá∫ÂÖ©ÂÄã‰∫§ÊõøËø≠‰ª£ÁöÑÁ≠ñÁï•‰æÜÂçîÂêåÊúÄ‰Ω≥ÂåñÁîüÊàêÁöÑÊñπÁ®ãÂºè„ÄÇÁ¨¨‰∏ÄÂÄãÁ≠ñÁï•ÊòØÂ∞á LLM Ë¶ñÁÇ∫‰∏ÄÂÄãÈªëÁõíÊúÄ‰Ω≥ÂåñÂô®Ôºå‰∏¶Ê†πÊìöÊ≠∑Âè≤Ê®£Êú¨ÂèäÂÖ∂ÊïàËÉΩ‰æÜÈÅîÊàêÊñπÁ®ãÂºèÁöÑËá™ÊàëÊîπÂñÑ„ÄÇÁ¨¨‰∫åÂÄãÁ≠ñÁï•ÊòØÊåáÁ§∫ LLM Â∞çÂÖ®ÁêÉÊêúÂ∞ãÂü∑Ë°åÊºîÂåñÈÅãÁÆóÂ≠ê„ÄÇÊàëÂÄëÂú®ÂÅèÂæÆÂàÜÊñπÁ®ãÂºèÂíåÂ∏∏ÂæÆÂàÜÊñπÁ®ãÂºè‰∏äÂª£Ê≥õÈÄ≤Ë°åÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•Âú®ÂêÑÁ®ÆÈùûÁ∑öÊÄßÂãïÊÖãÁ≥ªÁµ±‰∏ãÁôºÁèæÊúâÊïàÁöÑÊñπÁ®ãÂºè‰æÜÊè≠Á§∫Â∫ïÂ±§Áâ©ÁêÜÂÆöÂæã„ÄÇÈÄ≤‰∏ÄÊ≠•ËàáÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉÔºåË≠âÊòé‰∫ÜËâØÂ•ΩÁöÑÁ©©ÂÆöÊÄßÂíåÂèØÁî®ÊÄß„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂ§ßÂπÖÈôç‰Ωé‰∫ÜÂ≠∏ÁøíÂíåÊáâÁî®ÊñπÁ®ãÂºèÁôºÁèæÊäÄË°ìÁöÑÈñÄÊ™ªÔºåË≠âÊòé‰∫Ü LLM Âú®Áü•Ë≠òÁôºÁèæÈ†òÂüüÁöÑÊáâÁî®ÊΩõÂäõ„ÄÇ

##### **MADRL-Based Rate Adaptation for 360$\degree$ Video Streaming with Multi-Viewpoint Prediction**
2405.07759v1 by Haopeng Wang, Zijian Long, Haiwei Dong, Abdulmotaleb El Saddik

Over the last few years, 360$\degree$ video traffic on the network has grown
significantly. A key challenge of 360$\degree$ video playback is ensuring a
high quality of experience (QoE) with limited network bandwidth. Currently,
most studies focus on tile-based adaptive bitrate (ABR) streaming based on
single viewport prediction to reduce bandwidth consumption. However, the
performance of models for single-viewpoint prediction is severely limited by
the inherent uncertainty in head movement, which can not cope with the sudden
movement of users very well. This paper first presents a multimodal
spatial-temporal attention transformer to generate multiple viewpoint
trajectories with their probabilities given a historical trajectory. The
proposed method models viewpoint prediction as a classification problem and
uses attention mechanisms to capture the spatial and temporal characteristics
of input video frames and viewpoint trajectories for multi-viewpoint
prediction. After that, a multi-agent deep reinforcement learning (MADRL)-based
ABR algorithm utilizing multi-viewpoint prediction for 360$\degree$ video
streaming is proposed for maximizing different QoE objectives under various
network conditions. We formulate the ABR problem as a decentralized partially
observable Markov decision process (Dec-POMDP) problem and present a MAPPO
algorithm based on centralized training and decentralized execution (CTDE)
framework to solve the problem. The experimental results show that our proposed
method improves the defined QoE metric by up to 85.5\% compared to existing ABR
methods.

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÅéÂéªÂπæÂπ¥ÔºåÁ∂≤Ë∑Ø‰∏äÁöÑ 360 Â∫¶ÂΩ±ÁâáÊµÅÈáèÂ§ßÂπÖÊàêÈï∑„ÄÇ360 Â∫¶ÂΩ±ÁâáÊí≠ÊîæÁöÑ‰∏ÄÂ§ßÊåëÊà∞Âú®ÊñºÔºåÂ¶Ç‰Ωï‰ª•ÊúâÈôêÁöÑÁ∂≤Ë∑ØÈ†ªÂØ¨Á¢∫‰øùÈ´òÂìÅË≥™ÁöÑÈ´îÈ©ó (QoE)„ÄÇÁõÆÂâçÔºåÂ§ßÂ§öÊï∏Á†îÁ©∂ÈÉΩÂ∞àÊ≥®ÊñºÂü∫ÊñºÂñÆ‰∏ÄË¶ñÈªûÈ†êÊ∏¨ÁöÑÁ£ÅÁ£öÂºèËá™ÈÅ©Êáâ‰ΩçÂÖÉÁéá (ABR) ‰∏≤ÊµÅÔºå‰ª•Ê∏õÂ∞ëÈ†ªÂØ¨Ê∂àËÄó„ÄÇÁÑ∂ËÄåÔºåÂñÆ‰∏ÄË¶ñÈªûÈ†êÊ∏¨Ê®°ÂûãÁöÑÊïàËÉΩÂèóÂà∞È†≠ÈÉ®ÁßªÂãïÁöÑÂÖßÂú®‰∏çÁ¢∫ÂÆöÊÄßÂö¥ÈáçÈôêÂà∂ÔºåÁÑ°Ê≥ïÂæàÂ•ΩÂú∞ÊáâÂ∞ç‰ΩøÁî®ËÄÖÁöÑÁ™ÅÁÑ∂ÁßªÂãï„ÄÇÊú¨ÊñáÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãÂ§öÊ®°ÊÖãÊôÇÁ©∫Ê≥®ÊÑèÂäõËÆäÊèõÂô®Ôºå‰ª•Áî¢ÁîüÂ§öÂÄãË¶ñÈªûËªåË∑°ÂèäÂÖ∂Âú®Áµ¶ÂÆöÊ≠∑Âè≤ËªåË∑°‰∏ãÁöÑÊ©üÁéá„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞áË¶ñÈªûÈ†êÊ∏¨Âª∫Ê®°ÁÇ∫‰∏ÄÂÄãÂàÜÈ°ûÂïèÈ°åÔºå‰∏¶‰ΩøÁî®Ê≥®ÊÑèÂäõÊ©üÂà∂‰æÜÊì∑ÂèñËº∏ÂÖ•ÂΩ±ÁâáÂπÄÂíåË¶ñÈªûËªåË∑°ÁöÑÂ§öË¶ñÈªûÈ†êÊ∏¨ÁöÑÊôÇÁ©∫ÁâπÂæµ„ÄÇÊé•ËëóÔºåÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÂ§ö‰∏ªÈ´îÊ∑±Â∫¶Âº∑ÂåñÂ≠∏Áøí (MADRL) ÁöÑ ABR ÊºîÁÆóÊ≥ïÔºå‰ΩøÁî®Â§öË¶ñÈªûÈ†êÊ∏¨ÈÄ≤Ë°å 360 Â∫¶ÂΩ±Áâá‰∏≤ÊµÅÔºå‰ª•Âú®ÂêÑÁ®ÆÁ∂≤Ë∑ØÊ¢ù‰ª∂‰∏ãÊúÄÂ§ßÂåñ‰∏çÂêåÁöÑ QoE ÁõÆÊ®ô„ÄÇÊàëÂÄëÂ∞á ABR ÂïèÈ°åÂÖ¨ÂºèÂåñÁÇ∫‰∏ÄÂÄãÂàÜÊï£ÂºèÈÉ®ÂàÜÂèØËßÄÂØüÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (Dec-POMDP) ÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÂü∫ÊñºÈõÜ‰∏≠Ë®ìÁ∑¥ÂíåÂàÜÊï£Âü∑Ë°å (CTDE) Êû∂ÊßãÁöÑ MAPPO ÊºîÁÆóÊ≥ï‰æÜËß£Ê±∫ÂïèÈ°å„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåËàáÁèæÊúâÁöÑ ABR ÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞áÂÆöÁæ©ÁöÑ QoE ÊåáÊ®ôÊèêÂçá‰∫Ü 85.5%„ÄÇ</paragraph>

##### **Mitigating federated learning contribution allocation instability through randomized aggregation**
2405.08044v1 by Arno Geimer, Beltran Fiz, Radu State

Federated learning (FL) is a novel collaborative machine learning framework
designed to preserve privacy while enabling the creation of robust models. This
paradigm addresses a growing need for data security by allowing multiple
participants to contribute to a model without exposing their individual
datasets. A pivotal issue within this framework, however, concerns the fair and
accurate attribution of contributions from various participants to the creation
of the joint global model. Incorrect contribution distribution can erode trust
among participants, result in inequitable compensation, and ultimately diminish
the willingness of parties to engage or actively contribute to the federation.
While several methods for remunerating participants have been proposed, little
attention was given to the analysis of the stability of these methods when
evaluating contributions, which is critical to ensure the long-term viability
and fairness of FL systems. In this paper, we analyse this stability through
the calculation of contributions by gradient-based model reconstruction
techniques with Shapley values. Our investigation reveals that Shapley values
fail to reflect baseline contributions, especially when employing different
aggregation techniques. To address this issue, we extend on established
aggregation techniques by introducing FedRandom, which is designed to sample
contributions in a more equitable and distributed manner. We demonstrate that
this approach not only serves as a viable aggregation technique but also
significantly improves the accuracy of contribution assessment compared to
traditional methods. Our results suggest that FedRandom enhances the overall
fairness and stability of the federated learning system, making it a superior
choice for federations with limited number of participants.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) ÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂçî‰ΩúÊ©üÂô®Â≠∏ÁøíÊû∂ÊßãÔºåÊó®Âú®‰øùË≠∑Èö±ÁßÅÔºåÂêåÊôÇ‰øÉÈÄ≤Âª∫Á´ãÂº∑Â§ßÁöÑÊ®°Âûã„ÄÇÈÄôÁ®ÆÁØÑ‰æãÈÄèÈÅéÂÖÅË®±Â§öÂÄãÂèÉËàáËÄÖÂú®‰∏çÂÖ¨ÈñãÂÖ∂ÂÄãÂà•Ë≥áÊñôÈõÜÁöÑÊÉÖÊ≥Å‰∏ãÁÇ∫Ê®°ÂûãÂÅöÂá∫Ë≤¢ÁçªÔºå‰æÜÊªøË∂≥Êó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±ÇÔºå‰ª•Á¢∫‰øùË≥áÊñôÂÆâÂÖ®„ÄÇÁÑ∂ËÄåÔºåÊ≠§Êû∂Êßã‰∏≠ÁöÑÈóúÈçµÂïèÈ°åÊ∂âÂèäÂÖ¨Âπ≥‰∏îÊ∫ñÁ¢∫Âú∞Â∞á‰æÜËá™‰∏çÂêåÂèÉËàáËÄÖÁöÑË≤¢ÁçªÊ≠∏Âõ†ÊñºÂª∫Á´ãËÅØÂêàÂÖ®ÁêÉÊ®°Âûã„ÄÇ‰∏çÊ≠£Á¢∫ÁöÑË≤¢ÁçªÂàÜÈÖçÊúÉ‰æµËùïÂèÉËàáËÄÖ‰πãÈñìÁöÑ‰ø°‰ªªÔºåÂ∞éËá¥‰∏çÂÖ¨Âπ≥ÁöÑË£úÂÑüÔºå‰∏¶ÊúÄÁµÇÈôç‰ΩéÂêÑÊñπÂèÉËàáÊàñÁ©çÊ•µË≤¢ÁçªËÅØÈÇ¶ÁöÑÊÑèÈ°ò„ÄÇÂÑòÁÆ°Â∑≤Á∂ìÊèêÂá∫ÂπæÁ®ÆÈÖ¨ÂãûÂèÉËàáËÄÖÁöÑÊñπÊ≥ïÔºå‰ΩÜÂú®Ë©ï‰º∞Ë≤¢ÁçªÊôÇÔºåÂæàÂ∞ëÈóúÊ≥®ÈÄô‰∫õÊñπÊ≥ïÁöÑÁ©©ÂÆöÊÄßÂàÜÊûêÔºåÈÄôÂ∞çÊñºÁ¢∫‰øù FL Á≥ªÁµ±ÁöÑÈï∑ÊúüÂèØË°åÊÄßÂíåÂÖ¨Âπ≥ÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅé‰ΩøÁî® Shapley ÂÄºÁöÑÂü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊ®°ÂûãÈáçÂª∫ÊäÄË°ìË®àÁÆóË≤¢ÁçªÔºå‰æÜÂàÜÊûêÈÄôÁ®ÆÁ©©ÂÆöÊÄß„ÄÇÊàëÂÄëÁöÑË™øÊü•È°ØÁ§∫ÔºåShapley ÂÄºÁÑ°Ê≥ïÂèçÊò†Âü∫Ê∫ñË≤¢ÁçªÔºåÁâπÂà•ÊòØÂú®Êé°Áî®‰∏çÂêåÁöÑËÅöÂêàÊäÄË°ìÊôÇ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÈÄèÈÅéÂºïÂÖ• FedRandom ‰æÜÊì¥ÂÖÖÊó¢ÂÆöÁöÑËÅöÂêàÊäÄË°ìÔºåFedRandom Êó®Âú®‰ª•Êõ¥ÂÖ¨Âπ≥‰∏îÂàÜÊï£ÁöÑÊñπÂºèÊäΩÂèñË≤¢Áçª„ÄÇÊàëÂÄëË≠âÊòéÔºåÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂèØË°åÁöÑËÅöÂêàÊäÄË°ìÔºåËÄå‰∏îËàáÂÇ≥Áµ±ÊñπÊ≥ïÁõ∏ÊØîÔºåÈÇÑËÉΩÈ°ØËëóÊèêÈ´òË≤¢ÁçªË©ï‰º∞ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåFedRandom ÊèêÈ´ò‰∫ÜËÅØÈÇ¶Â≠∏ÁøíÁ≥ªÁµ±ÁöÑÊï¥È´îÂÖ¨Âπ≥ÊÄßÂíåÁ©©ÂÆöÊÄßÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÂèÉËàáËÄÖÊï∏ÈáèÊúâÈôêÁöÑËÅØÈÇ¶ÁöÑÊõ¥‰Ω≥ÈÅ∏Êìá„ÄÇ

##### **LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language**
2405.07745v1 by Cagri Toraman

Despite advancements in English-dominant generative large language models,
further development is needed for low-resource languages to enhance global
accessibility. The primary methods for representing these languages are
monolingual and multilingual pretraining. Monolingual pretraining is expensive
due to hardware requirements, and multilingual models often have uneven
performance across languages. This study explores an alternative solution by
adapting large language models, primarily trained on English, to low-resource
languages. We assess various strategies, including continual training,
instruction fine-tuning, task-specific fine-tuning, and vocabulary extension.
The results show that continual training improves language comprehension, as
reflected in perplexity scores, and task-specific tuning generally enhances
performance of downstream tasks. However, extending the vocabulary shows no
substantial benefits. Additionally, while larger models improve task
performance with few-shot tuning, multilingual models perform worse than their
monolingual counterparts when adapted.

ÊëòË¶ÅÔºöÂÑòÁÆ°‰ª•Ëã±Ë™ûÁÇ∫‰∏ªÁöÑÁîüÊàêÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊúâÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÈñãÁôº‰ΩéË≥áÊ∫êË™ûË®ÄÔºå‰ª•Â¢ûÂº∑ÂÖ®ÁêÉÂèØÂèäÊÄß„ÄÇË°®Á§∫ÈÄô‰∫õË™ûË®ÄÁöÑ‰∏ªË¶ÅÊñπÊ≥ïÊòØÂñÆË™ûÂíåÂ§öË™ûÈ†êË®ìÁ∑¥„ÄÇÂñÆË™ûÈ†êË®ìÁ∑¥Áî±ÊñºÁ°¨È´îÈúÄÊ±ÇËÄåÊòÇË≤¥ÔºåËÄåÂ§öË™ûÊ®°ÂûãÂú®‰∏çÂêåË™ûË®Ä‰∏≠ÁöÑË°®ÁèæÂæÄÂæÄ‰∏çÂùá„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü‰∏ÄÁ®ÆÊõø‰ª£Ëß£Ê±∫ÊñπÊ°àÔºåÂç≥Â∞á‰∏ªË¶Å‰ª•Ëã±Ë™ûË®ìÁ∑¥ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÈÅ©ÊáâÂà∞‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂêÑÁ®ÆÁ≠ñÁï•ÔºåÂåÖÊã¨ÊåÅÁ∫åË®ìÁ∑¥„ÄÅÊåá‰ª§ÂæÆË™ø„ÄÅÁâπÂÆö‰ªªÂãôÂæÆË™øÂíåË©ûÂΩôÊì¥ÂÖÖ„ÄÇÁµêÊûúË°®ÊòéÔºåÊåÅÁ∫åË®ìÁ∑¥ÊîπÂñÑ‰∫ÜË™ûË®ÄÁêÜËß£ÔºåÈÄôÂèçÊò†Âú®Âõ∞ÊÉëÂ∫¶ÂàÜÊï∏‰∏≠ÔºåËÄåÁâπÂÆö‰ªªÂãôÂæÆË™øÈÄöÂ∏∏ÊúÉÂ¢ûÂº∑‰∏ãÊ∏∏‰ªªÂãôÁöÑÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÊì¥Â±ïË©ûÂΩô‰∏¶Êú™È°ØÁ§∫Âá∫ÂØ¶Ë≥™ÊÄßÂ•ΩËôï„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ°ËºÉÂ§ßÁöÑÊ®°ÂûãÈÄöÈÅéÂ∞ëÈáèË™øÊï¥ÊîπÈÄ≤‰∫Ü‰ªªÂãôÊÄßËÉΩÔºå‰ΩÜÂ§öË™ûÊ®°ÂûãÂú®ÈÅ©ÊáâÊôÇË°®Áèæ‰∏çÂ¶ÇÂñÆË™ûÊ®°Âûã„ÄÇ

##### **Federated Hierarchical Tensor Networks: a Collaborative Learning Quantum AI-Driven Framework for Healthcare**
2405.07735v1 by Amandeep Singh Bhatia, David E. Bernal Neira

Healthcare industries frequently handle sensitive and proprietary data, and
due to strict privacy regulations, they are often reluctant to share data
directly. In today's context, Federated Learning (FL) stands out as a crucial
remedy, facilitating the rapid advancement of distributed machine learning
while effectively managing critical concerns regarding data privacy and
governance. The fusion of federated learning and quantum computing represents a
groundbreaking interdisciplinary approach with immense potential to
revolutionize various industries, from healthcare to finance. In this work, we
proposed a federated learning framework based on quantum tensor networks, which
leverages the principles of many-body quantum physics. Currently, there are no
known classical tensor networks implemented in federated settings. Furthermore,
we investigated the effectiveness and feasibility of the proposed framework by
conducting a differential privacy analysis to ensure the security of sensitive
data across healthcare institutions. Experiments on popular medical image
datasets show that the federated quantum tensor network model achieved a mean
receiver-operator characteristic area under the curve (ROC-AUC) between
0.91-0.98. Experimental results demonstrate that the quantum federated global
model, consisting of highly entangled tensor network structures, showed better
generalization and robustness and achieved higher testing accuracy, surpassing
the performance of locally trained clients under unbalanced data distributions
among healthcare institutions.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÁî¢Ê•≠Á∂ìÂ∏∏ËôïÁêÜÊïèÊÑü‰∏îÂ∞àÊúâÁöÑË≥áÊñôÔºå‰∏îÁî±ÊñºÂö¥Ê†ºÁöÑÈö±ÁßÅÊ≥ïË¶èÔºå‰ªñÂÄëÈÄöÂ∏∏‰∏çÈ°òÊÑèÁõ¥Êé•ÂàÜ‰∫´Ë≥áÊñô„ÄÇÂú®‰ªäÊó•ÁöÑËÑàÁµ°‰∏≠ÔºåËÅØÈÇ¶Â≠∏Áøí (FL) ÊàêÁÇ∫‰∏ÄÈ†ÖÈáçË¶ÅÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰øÉÈÄ≤ÂàÜÂ∏ÉÂºèÊ©üÂô®Â≠∏ÁøíÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåÂêåÊôÇÊúâÊïàÁÆ°ÁêÜÊúâÈóúË≥áÊñôÈö±ÁßÅÂíåÊ≤ªÁêÜÁöÑÈóúÈçµÂïèÈ°å„ÄÇËÅØÈÇ¶Â≠∏ÁøíËàáÈáèÂ≠êÈÅãÁÆóÁöÑËûçÂêà‰ª£Ë°®‰∫Ü‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑË∑®È†òÂüüÊñπÊ≥ïÔºåÂÖ∑ÊúâÂ∑®Â§ßÁöÑÊΩõÂäõÔºåÂèØ‰ª•Èù©Êñ∞ÂæûÈÜ´ÁôÇ‰øùÂÅ•Âà∞ÈáëËûçÁöÑÂêÑÁ®ÆÁî¢Ê•≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÈáèÂ≠êÂºµÈáèÁ∂≤Ë∑ØÁöÑËÅØÈÇ¶Â≠∏ÁøíÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®‰∫ÜÂ§öÈ´îÈáèÂ≠êÁâ©ÁêÜÁöÑÂéüÁêÜ„ÄÇÁõÆÂâçÔºåÂú®ËÅØÈÇ¶Ë®≠ÁΩÆ‰∏≠Ê≤íÊúâÂ∑≤Áü•ÁöÑÁ∂ìÂÖ∏ÂºµÈáèÁ∂≤Ë∑ØÂØ¶‰Ωú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄèÈÅéÈÄ≤Ë°åÂ∑ÆÁï∞ÂåñÈö±ÁßÅÂàÜÊûê‰æÜË™øÊü•ÊâÄÊèêÂá∫Ê°ÜÊû∂ÁöÑÊúâÊïàÊÄßÂíåÂèØË°åÊÄßÔºå‰ª•Á¢∫‰øùÈÜ´ÁôÇÊ©üÊßã‰∏≠ÊïèÊÑüË≥áÊñôÁöÑÂÆâÂÖ®ÊÄß„ÄÇÂú®ÊµÅË°åÁöÑÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåËÅØÈÇ¶ÈáèÂ≠êÂºµÈáèÁ∂≤Ë∑ØÊ®°ÂûãÂú®Êõ≤Á∑ö‰∏ãÊñπÁöÑÂπ≥ÂùáÊé•Êî∂Âô®Êìç‰ΩúËÄÖÁâπÊÄßÈù¢Á©ç (ROC-AUC) ÈÅîÂà∞ 0.91-0.98„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁî±È´òÂ∫¶Á≥æÁ∫èÁöÑÂºµÈáèÁ∂≤Ë∑ØÁµêÊßãÁµÑÊàêÁöÑÈáèÂ≠êËÅØÈÇ¶ÂÖ®Â±ÄÊ®°ÂûãÈ°ØÁ§∫Âá∫Êõ¥Â•ΩÁöÑÊ≥õÂåñÊÄßÂíåÁ©©ÂÅ•ÊÄßÔºå‰∏¶ÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶ÔºåË∂ÖË∂ä‰∫ÜÂú®ÈÜ´ÁôÇÊ©üÊßã‰πãÈñìË≥áÊñôÂàÜ‰Ωà‰∏çÂπ≥Ë°°ÁöÑÊÉÖÊ≥Å‰∏ãÔºåÁî±Êú¨Âú∞Ë®ìÁ∑¥ÁöÑÁî®Êà∂Á´ØÊïàËÉΩ„ÄÇ

##### **Quantifying and Optimizing Global Faithfulness in Persona-driven Role-playing**
2405.07726v1 by Letian Peng, Jingbo Shang

Persona-driven role-playing (PRP) aims to build AI characters that can
respond to user queries by faithfully sticking with all persona statements.
Unfortunately, existing faithfulness criteria for PRP are limited to
coarse-grained LLM-based scoring without a clear definition or formulation.
This paper presents a pioneering exploration to quantify PRP faithfulness as a
fine-grained and explainable criterion, which also serves as a reliable
reference for optimization. Our criterion first discriminates persona
statements into active and passive constraints by identifying the
query-statement relevance. Then, we incorporate all constraints following the
principle that the AI character's response should be (a) entailed by active
(relevant) constraints and (b) not contradicted by passive (irrelevant)
constraints. We translate this principle mathematically into a novel
Active-Passive-Constraint (APC) score, a constraint-wise sum of natural
language inference (NLI) scores weighted by relevance scores. In practice, we
build the APC scoring system by symbolically distilling small discriminators
from GPT-4 for efficiency. We validate the quality of the APC score against
human evaluation based on example personas with tens of statements, and the
results show a high correlation. We further leverage it as a reward system in
direct preference optimization (DPO) for better AI characters. Our experiments
offer a fine-grained and explainable comparison between existing PRP
techniques, revealing their advantages and limitations. We further find
APC-based DPO to be one of the most competitive techniques for sticking with
all constraints and can be well incorporated with other techniques. We then
extend the scale of the experiments to real persons with hundreds of statements
and reach a consistent conclusion.

ÊëòË¶ÅÔºö‰ª•ËßíËâ≤ÁÇ∫Â∞éÂêëÁöÑËßíËâ≤ÊâÆÊºî (PRP) Êó®Âú®Âª∫Á´ã AI ËßíËâ≤ÔºåÈÄô‰∫õËßíËâ≤ÂèØ‰ª•ÈÄèÈÅéÂø†ÂØ¶ÈÅµÂÆàÊâÄÊúâËßíËâ≤Èô≥Ëø∞‰æÜÂõûÊáâ‰ΩøÁî®ËÄÖÁöÑÊü•Ë©¢„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÁèæÊúâÁöÑ PRP ‰øùÁúüÂ∫¶Ê∫ñÂâáÂÉÖÈôêÊñºÁ≤óÁï•ÁöÑ LLM Âü∫Á§éË©ïÂàÜÔºåËÄåÊ≤íÊúâÊòéÁ¢∫ÁöÑÂÆöÁæ©ÊàñË°®Ëø∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÈñãÂâµÊÄßÁöÑÊé¢Á¥¢ÔºåÂ∞á PRP ‰øùÁúüÂ∫¶ÈáèÂåñÁÇ∫Á¥∞Á∑ª‰∏îÂèØËß£ÈáãÁöÑÊ∫ñÂâáÔºåÈÄô‰πü‰ΩúÁÇ∫ÊúÄ‰Ω≥ÂåñÁöÑÂèØÈù†ÂèÉËÄÉ„ÄÇÊàëÂÄëÁöÑÊ∫ñÂâáÈ¶ñÂÖàÈÄèÈÅéË≠òÂà•Êü•Ë©¢Èô≥Ëø∞Áõ∏ÈóúÊÄßÔºåÂ∞áËßíËâ≤Èô≥Ëø∞ÂçÄÂàÜÁÇ∫‰∏ªÂãïÂíåË¢´ÂãïÁ¥ÑÊùü„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊ†πÊìö‰ª•‰∏ãÂéüÂâáÁ¥çÂÖ•ÊâÄÊúâÁ¥ÑÊùüÔºöAI ËßíËâ≤ÁöÑÂõûÊáâÊáâ (a) Áî±‰∏ªÂãï (Áõ∏Èóú) Á¥ÑÊùüÊâÄÊöóÁ§∫Ôºå‰∏î (b) ‰∏çËàáË¢´Âãï (ÁÑ°Èóú) Á¥ÑÊùüÁõ∏ÁüõÁõæ„ÄÇÊàëÂÄëÂ∞áÊ≠§ÂéüÂâáÊï∏Â≠∏ËΩâÊèõÁÇ∫Êñ∞Á©éÁöÑ‰∏ªÂãïË¢´ÂãïÁ¥ÑÊùü (APC) ÂàÜÊï∏ÔºåÈÄôÊòØËá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñ (NLI) ÂàÜÊï∏ÁöÑÁ¥ÑÊùüÂä†Ê¨äÁ∏ΩÂíåÔºåÁî±Áõ∏ÈóúÊÄßÂàÜÊï∏Âä†Ê¨ä„ÄÇÂú®ÂØ¶Âãô‰∏äÔºåÊàëÂÄëÈÄèÈÅéÂæû GPT-4 ‰∏≠Ë±°ÂæµÊÄßÂú∞ÊèêÂèñÂ∞èÂûãÂçÄÂàÜÂô®‰æÜÂª∫Á´ã APC Ë©ïÂàÜÁ≥ªÁµ±‰ª•ÊèêÈ´òÊïàÁéá„ÄÇÊàëÂÄëÊ†πÊìöÂåÖÂê´Êï∏ÂçÅÂÄãÈô≥Ëø∞ÁöÑÁØÑ‰æãËßíËâ≤Â∞ç APC ÂàÜÊï∏ÁöÑÂìÅË≥™ÈÄ≤Ë°åÈ©óË≠âÔºåËÄåÁµêÊûúÈ°ØÁ§∫Âá∫È´òÂ∫¶Áõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞áÂÖ∂‰ΩúÁÇ∫Áõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) ‰∏≠ÁöÑÁçéÂãµÁ≥ªÁµ±Ôºå‰ª•Áç≤ÂæóÊõ¥Â•ΩÁöÑ AI ËßíËâ≤„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÊèê‰æõ‰∫ÜÁèæÊúâ PRP ÊäÄË°ì‰πãÈñìÁ¥∞Á∑ª‰∏îÂèØËß£ÈáãÁöÑÊØîËºÉÔºåÊè≠Á§∫‰∫ÜÂÆÉÂÄëÁöÑÂÑ™ÈªûÂíåÈôêÂà∂„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁôºÁèæÂü∫Êñº APC ÁöÑ DPO ÊòØÊúÄÂÖ∑Á´∂Áà≠ÂäõÁöÑÊäÄË°ì‰πã‰∏ÄÔºåÂèØ‰ª•Â†ÖÊåÅÊâÄÊúâÁ¥ÑÊùüÔºå‰∏¶‰∏îÂèØ‰ª•ÂæàÂ•ΩÂú∞ËàáÂÖ∂‰ªñÊäÄË°ìÁµêÂêà„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂ∞áÂØ¶È©óÁöÑË¶èÊ®°Êì¥Â±ïÂà∞ÊìÅÊúâÊï∏ÁôæÂÄãÈô≥Ëø∞ÁöÑÁúü‰∫∫Ôºå‰∏¶ÂæóÂá∫‰∫Ü‰∏ÄÂÄã‰∏ÄËá¥ÁöÑÁµêË´ñ„ÄÇ

##### **A Unified Sequence Parallelism Approach for Long Context Generative AI**
2405.07719v3 by Jiarui Fang, Shangchun Zhao

Sequence parallelism (SP), which divides the sequence dimension of input
tensors across multiple computational devices, is becoming key to unlocking the
long-context capabilities of generative AI models. This paper investigates the
state-of-the-art SP approaches, i.e. DeepSpeed-Ulysses and Ring-Attention, and
proposes a unified SP approach, which is more robust to transformer model
architectures and network hardware topology. This paper compares the
communication and memory cost of SP and existing parallelism, including
data/tensor/zero/expert/pipeline parallelism, and discusses the best practices
for designing hybrid 4D parallelism involving SP. We achieved 86% MFU on two
8xA800 nodes using SP for sequence length 208K for the LLAMA3-8B model. Our
code is publicly available on
\url{https://github.com/feifeibear/long-context-attention}.

ÊëòË¶ÅÔºöÂ∫èÂàóÂπ≥Ë°åÔºàSPÔºâÂ∞áËº∏ÂÖ•ÂºµÈáèÁöÑÂ∫èÂàóÁ∂≠Â∫¶ÂäÉÂàÜÂà∞Â§öÂÄãË®àÁÆóË£ùÁΩÆ‰∏≠ÔºåÊ≠£ÊàêÁÇ∫Ëß£ÈéñÁîüÊàêÂºè AI Ê®°ÂûãÈï∑ÂÖßÂÆπÂäüËÉΩÁöÑÈóúÈçµ„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑ SP ÊñπÊ≥ïÔºåÂç≥ DeepSpeed-Ulysses Âíå Ring-AttentionÔºå‰∏¶ÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁµ±‰∏ÄÁöÑ SP ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂ∞çTransformerÊ®°ÂûãÊû∂ÊßãÂíåÁ∂≤Ë∑ØÁ°¨È´îÊãìÊí≤Êõ¥ÂÖ∑È≠ØÊ£íÊÄß„ÄÇÊú¨ÊñáÊØîËºÉ‰∫Ü SP ÂíåÁèæÊúâ‰∏¶Ë°åËôïÁêÜÁöÑÈÄöË®äÂíåË®òÊÜ∂È´îÊàêÊú¨ÔºåÂåÖÊã¨Ë≥áÊñô/ÂºµÈáè/Èõ∂/Â∞àÂÆ∂/ÁÆ°Á∑ö‰∏¶Ë°åËôïÁêÜÔºå‰∏¶Ë®éË´ñ‰∫ÜÊ∂âÂèä SP ÁöÑÊ∑∑Âêà 4D ‰∏¶Ë°åËôïÁêÜÁöÑÊúÄ‰Ω≥ÂØ¶Âãô„ÄÇÊàëÂÄë‰ΩøÁî® SP ÁÇ∫ LLAMA3-8B Ê®°ÂûãÁöÑÂ∫èÂàóÈï∑Â∫¶ 208K Âú®ÂÖ©ÂÄã 8xA800 ÁØÄÈªû‰∏äÈÅîÂà∞‰∫Ü 86% ÁöÑ MFU„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÂú®
\url{https://github.com/feifeibear/long-context-attention}„ÄÇ

##### **OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2**
2405.07703v3 by Mihai Masala, Denis C. Ilie-Ablachim, Dragos Corlatescu, Miruna Zavelca, Marius Leordeanu, Horia Velicu, Marius Popescu, Mihai Dascalu, Traian Rebedea

In recent years, Large Language Models (LLMs) have achieved almost human-like
performance on various tasks. While some LLMs have been trained on multilingual
data, most of the training data is in English. Hence, their performance in
English greatly exceeds their performance in other languages. This document
presents our approach to training and evaluating the first foundational and
chat LLM specialized for Romanian.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏äÈÅîÂà∞‰∫ÜÊé•Ëøë‰∫∫È°ûÁöÑË°®Áèæ„ÄÇÈõñÁÑ∂Êúâ‰∫õ LLM Â∑≤Êé•ÂèóÂ§öÂúãË™ûË®ÄË≥áÊñôÁöÑË®ìÁ∑¥Ôºå‰ΩÜÂ§ßÂ§öÊï∏Ë®ìÁ∑¥Ë≥áÊñôÈÉΩÊòØËã±Êñá„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂÄëÂú®Ëã±ÊñáÁöÑË°®ÁèæÈÅ†ÈÅ†ÂÑ™ÊñºÂÖ∂‰ªñË™ûË®Ä„ÄÇÊú¨ÊñáÊ™î‰ªãÁ¥πÊàëÂÄëË®ìÁ∑¥ÂíåË©ï‰º∞Á¨¨‰∏ÄÂÄãÈáùÂ∞çÁæÖÈ¶¨Â∞º‰∫ûË™ûÁöÑÂü∫Á§éÂíåËÅäÂ§© LLM ÁöÑÊñπÊ≥ï„ÄÇ

