{"2410.07157": {"publish_time": "2024-10-09", "title": "InstructG2I: Synthesizing Images from Multimodal Attributed Graphs", "paper_summary": "In this paper, we approach an overlooked yet critical task Graph2Image:\ngenerating images from multimodal attributed graphs (MMAGs). This task poses\nsignificant challenges due to the explosion in graph size, dependencies among\ngraph entities, and the need for controllability in graph conditions. To\naddress these challenges, we propose a graph context-conditioned diffusion\nmodel called InstructG2I. InstructG2I first exploits the graph structure and\nmultimodal information to conduct informative neighbor sampling by combining\npersonalized page rank and re-ranking based on vision-language features. Then,\na Graph-QFormer encoder adaptively encodes the graph nodes into an auxiliary\nset of graph prompts to guide the denoising process of diffusion. Finally, we\npropose graph classifier-free guidance, enabling controllable generation by\nvarying the strength of graph guidance and multiple connected edges to a node.\nExtensive experiments conducted on three datasets from different domains\ndemonstrate the effectiveness and controllability of our approach. The code is\navailable at https://github.com/PeterGriffinJin/InstructG2I.", "paper_summary_zh": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63a2\u8ba8\u4e00\u9879\u88ab\u5ffd\u89c6\u4f46\u81f3\u5173\u91cd\u8981\u7684\u4efb\u52a1 Graph2Image\uff1a\n\u4ece\u591a\u6a21\u6001\u5c5e\u6027\u56fe (MMAG) \u751f\u6210\u56fe\u50cf\u3002\u7531\u4e8e\u56fe\u5927\u5c0f\u6fc0\u589e\u3001\u56fe\u5b9e\u4f53\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4ee5\u53ca\u5bf9\u56fe\u6761\u4ef6\u7684\u53ef\u63a7\u6027\u9700\u6c42\uff0c\u6b64\u4efb\u52a1\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a InstructG2I \u7684\u56fe\u4e0a\u4e0b\u6587\u6761\u4ef6\u6269\u6563\u6a21\u578b\u3002InstructG2I \u9996\u5148\u5229\u7528\u56fe\u7ed3\u6784\u548c\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u901a\u8fc7\u7ed3\u5408\u4e2a\u6027\u5316\u9875\u9762\u6392\u540d\u548c\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u7279\u5f81\u7684\u91cd\u65b0\u6392\u540d\u6765\u6267\u884c\u4fe1\u606f\u4e30\u5bcc\u7684\u90bb\u5c45\u91c7\u6837\u3002\u7136\u540e\uff0cGraph-QFormer \u7f16\u7801\u5668\u5c06\u56fe\u8282\u70b9\u81ea\u9002\u5e94\u5730\u7f16\u7801\u4e3a\u4e00\u7ec4\u8f85\u52a9\u56fe\u63d0\u793a\uff0c\u4ee5\u6307\u5bfc\u6269\u6563\u7684\u53bb\u566a\u8fc7\u7a0b\u3002\u6700\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u65e0\u56fe\u5206\u7c7b\u5668\u6307\u5bfc\uff0c\u901a\u8fc7\u6539\u53d8\u56fe\u6307\u5bfc\u7684\u5f3a\u5ea6\u548c\u4e0e\u8282\u70b9\u7684\u591a\u4e2a\u8fde\u63a5\u8fb9\u6765\u5b9e\u73b0\u53ef\u63a7\u751f\u6210\u3002\u5728\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u4e09\u7ec4\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u63a7\u6027\u3002\u4ee3\u7801\u53ef\u5728 https://github.com/PeterGriffinJin/InstructG2I \u83b7\u5f97\u3002", "author": "Bowen Jin et.al.", "authors": "Bowen Jin, Ziqi Pang, Bingjun Guo, Yu-Xiong Wang, Jiaxuan You, Jiawei Han", "id": "2410.07157v1", "paper_url": "http://arxiv.org/abs/2410.07157v1", "repo": "null"}}