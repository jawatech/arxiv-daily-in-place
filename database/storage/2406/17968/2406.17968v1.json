{"2406.17968": {"publish_time": "2024-06-25", "title": "Efficient Document Ranking with Learnable Late Interactions", "paper_summary": "Cross-Encoder (CE) and Dual-Encoder (DE) models are two fundamental\napproaches for query-document relevance in information retrieval. To predict\nrelevance, CE models use joint query-document embeddings, while DE models\nmaintain factorized query and document embeddings; usually, the former has\nhigher quality while the latter benefits from lower latency. Recently,\nlate-interaction models have been proposed to realize more favorable\nlatency-quality tradeoffs, by using a DE structure followed by a lightweight\nscorer based on query and document token embeddings. However, these lightweight\nscorers are often hand-crafted, and there is no understanding of their\napproximation power; further, such scorers require access to individual\ndocument token embeddings, which imposes an increased latency and storage\nburden. In this paper, we propose novel learnable late-interaction models\n(LITE) that resolve these issues. Theoretically, we prove that LITE is a\nuniversal approximator of continuous scoring functions, even for relatively\nsmall embedding dimension. Empirically, LITE outperforms previous\nlate-interaction models such as ColBERT on both in-domain and zero-shot\nre-ranking tasks. For instance, experiments on MS MARCO passage re-ranking show\nthat LITE not only yields a model with better generalization, but also lowers\nlatency and requires 0.25x storage compared to ColBERT.", "paper_summary_zh": "\u4ea4\u53c9\u7de8\u78bc\u5668 (CE) \u548c\u96d9\u7de8\u78bc\u5668 (DE) \u6a21\u578b\u662f\u8cc7\u8a0a\u6aa2\u7d22\u4e2d\u7528\u65bc\u67e5\u8a62\u6587\u4ef6\u76f8\u95dc\u6027\u7684\u5169\u7a2e\u57fa\u672c\u65b9\u6cd5\u3002\u70ba\u4e86\u9810\u6e2c\u76f8\u95dc\u6027\uff0cCE \u6a21\u578b\u4f7f\u7528\u806f\u5408\u67e5\u8a62\u6587\u4ef6\u5d4c\u5165\uff0c\u800c DE \u6a21\u578b\u5247\u7dad\u8b77\u5206\u89e3\u7684\u67e5\u8a62\u548c\u6587\u4ef6\u5d4c\u5165\uff1b\u901a\u5e38\uff0c\u524d\u8005\u54c1\u8cea\u8f03\u9ad8\uff0c\u800c\u5f8c\u8005\u5247\u53d7\u76ca\u65bc\u8f03\u4f4e\u7684\u5ef6\u9072\u3002\u6700\u8fd1\uff0c\u5df2\u7d93\u63d0\u51fa\u5f8c\u4e92\u52d5\u6a21\u578b\uff0c\u900f\u904e\u4f7f\u7528 DE \u7d50\u69cb\uff0c\u7136\u5f8c\u4f7f\u7528\u57fa\u65bc\u67e5\u8a62\u548c\u6587\u4ef6\u6a19\u8a18\u5d4c\u5165\u7684\u8f15\u91cf\u7d1a\u8a55\u5206\u5668\uff0c\u4f86\u5be6\u73fe\u66f4\u4f73\u7684\u5ef6\u9072\u54c1\u8cea\u6b0a\u8861\u3002\u7136\u800c\uff0c\u9019\u4e9b\u8f15\u91cf\u7d1a\u8a55\u5206\u5668\u901a\u5e38\u662f\u624b\u5de5\u88fd\u4f5c\u7684\uff0c\u800c\u4e14\u7121\u6cd5\u7406\u89e3\u5b83\u5011\u7684\u8fd1\u4f3c\u80fd\u529b\uff1b\u6b64\u5916\uff0c\u6b64\u985e\u8a55\u5206\u5668\u9700\u8981\u5b58\u53d6\u500b\u5225\u6587\u4ef6\u6a19\u8a18\u5d4c\u5165\uff0c\u9019\u6703\u589e\u52a0\u5ef6\u9072\u548c\u5132\u5b58\u8ca0\u64d4\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u65b0\u7a4e\u7684\u53ef\u5b78\u7fd2\u5f8c\u4e92\u52d5\u6a21\u578b (LITE)\uff0c\u4ee5\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\u3002\u5728\u7406\u8ad6\u4e0a\uff0c\u6211\u5011\u8b49\u660e LITE \u662f\u9023\u7e8c\u8a55\u5206\u51fd\u6578\u7684\u901a\u7528\u903c\u8fd1\u5668\uff0c\u5373\u4f7f\u5c0d\u65bc\u76f8\u5c0d\u8f03\u5c0f\u7684\u5d4c\u5165\u7dad\u5ea6\u4e5f\u662f\u5982\u6b64\u3002\u5728\u7d93\u9a57\u4e0a\uff0cLITE \u5728\u9818\u57df\u5167\u548c\u96f6\u6b21\u91cd\u65b0\u6392\u5e8f\u4efb\u52d9\u4e0a\u90fd\u512a\u65bc\u5148\u524d\u7684\u5f8c\u4e92\u52d5\u6a21\u578b\uff0c\u4f8b\u5982 ColBERT\u3002\u4f8b\u5982\uff0c\u5728 MS MARCO \u6bb5\u843d\u91cd\u65b0\u6392\u5e8f\u4e0a\u7684\u5be6\u9a57\u986f\u793a\uff0cLITE \u4e0d\u50c5\u7522\u751f\u5177\u6709\u66f4\u597d\u6cdb\u5316\u7684\u6a21\u578b\uff0c\u800c\u4e14\u9084\u964d\u4f4e\u5ef6\u9072\uff0c\u4e26\u8207 ColBERT \u76f8\u6bd4\uff0c\u9700\u8981 0.25 \u500d\u7684\u5132\u5b58\u7a7a\u9593\u3002", "author": "Ziwei Ji et.al.", "authors": "Ziwei Ji, Himanshu Jain, Andreas Veit, Sashank J. Reddi, Sadeep Jayasumana, Ankit Singh Rawat, Aditya Krishna Menon, Felix Yu, Sanjiv Kumar", "id": "2406.17968v1", "paper_url": "http://arxiv.org/abs/2406.17968v1", "repo": "null"}}