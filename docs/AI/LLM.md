
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-16**|**Learnings from Scaling Visual Tokenizers for Reconstruction and Generation**|Philippe Hansen-Estruch et.al.|[2501.09755v1](http://arxiv.org/abs/2501.09755v1)|null|
|**2025-01-16**|**OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking**|Zekun Xi et.al.|[2501.09751v1](http://arxiv.org/abs/2501.09751v1)|null|
|**2025-01-16**|**Enhancing Lexicon-Based Text Embeddings with Large Language Models**|Yibin Lei et.al.|[2501.09749v1](http://arxiv.org/abs/2501.09749v1)|null|
|**2025-01-16**|**Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models**|Bihui Jin et.al.|[2501.09745v1](http://arxiv.org/abs/2501.09745v1)|null|
|**2025-01-16**|**KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**|Hajung Kim et.al.|[2501.09744v1](http://arxiv.org/abs/2501.09744v1)|null|
|**2025-01-16**|**Attention based Bidirectional GRU hybrid model for inappropriate content detection in Urdu language**|Ezzah Shoukat et.al.|[2501.09722v1](http://arxiv.org/abs/2501.09722v1)|null|
|**2025-01-16**|**A Simple Aerial Detection Baseline of Multimodal Language Models**|Qingyun Li et.al.|[2501.09720v1](http://arxiv.org/abs/2501.09720v1)|[link](https://github.com/li-qingyun/mllm-mmrotate)|
|**2025-01-16**|**Comparative Insights from 12 Machine Learning Models in Extracting Economic Ideology from Political Text**|Jihed Ncib et.al.|[2501.09719v1](http://arxiv.org/abs/2501.09719v1)|null|
|**2025-01-16**|**CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education**|Tianyu Wang et.al.|[2501.09709v1](http://arxiv.org/abs/2501.09709v1)|null|
|**2025-01-16**|**The Goofus & Gallant Story Corpus for Practical Value Alignment**|Md Sultan Al Nahian et.al.|[2501.09707v1](http://arxiv.org/abs/2501.09707v1)|null|
|**2025-01-16**|**Domain Adaptation of Foundation LLMs for e-Commerce**|Christian Herold et.al.|[2501.09706v1](http://arxiv.org/abs/2501.09706v1)|null|
|**2025-01-16**|**Practical Continual Forgetting for Pre-trained Vision Models**|Hongbo Zhao et.al.|[2501.09705v1](http://arxiv.org/abs/2501.09705v1)|[link](https://github.com/bjzhb666/GS-LoRA)|
|**2025-01-16**|**Cueless EEG imagined speech for subject identification: dataset and benchmarks**|Ali Derakhshesh et.al.|[2501.09700v1](http://arxiv.org/abs/2501.09700v1)|[link](https://github.com/alidr79/cueless_eeg_subject_identification)|
|**2025-01-16**|**Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models**|Fengli Xu et.al.|[2501.09686v1](http://arxiv.org/abs/2501.09686v1)|null|
|**2025-01-16**|**Reward-Guided Controlled Generation for Inference-Time Alignment in Diffusion Models: Tutorial and Review**|Masatoshi Uehara et.al.|[2501.09685v1](http://arxiv.org/abs/2501.09685v1)|null|
|**2025-01-16**|**Authenticated Delegation and Authorized AI Agents**|Tobin South et.al.|[2501.09674v1](http://arxiv.org/abs/2501.09674v1)|null|
|**2025-01-16**|**Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark**|Alexis Roger et.al.|[2501.09672v1](http://arxiv.org/abs/2501.09672v1)|null|
|**2025-01-16**|**The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models**|Jonathan Katzy et.al.|[2501.09653v1](http://arxiv.org/abs/2501.09653v1)|null|
|**2025-01-16**|**Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments**|Lorenzo Bonanni et.al.|[2501.09649v1](http://arxiv.org/abs/2501.09649v1)|null|
|**2025-01-16**|**NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes**|Nathaniel S. Keplinger et.al.|[2501.09646v1](http://arxiv.org/abs/2501.09646v1)|[link](https://github.com/scope-lab-vu/ns_gym)|
|**2025-01-16**|**CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding**|Johannes Kirmayr et.al.|[2501.09645v1](http://arxiv.org/abs/2501.09645v1)|null|
|**2025-01-16**|**Electronic Health Records: Towards Digital Twins in Healthcare**|Muhammet Alkan et.al.|[2501.09640v1](http://arxiv.org/abs/2501.09640v1)|null|
|**2025-01-16**|**Platform-Aware Mission Planning**|Stefan Panjkovic et.al.|[2501.09632v1](http://arxiv.org/abs/2501.09632v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-16**|**Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment**|Chaoqi Wang et.al.|[2501.09620v1](http://arxiv.org/abs/2501.09620v1)|null|
|**2025-01-16**|**Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning**|Donghuo Zeng et.al.|[2501.09608v1](http://arxiv.org/abs/2501.09608v1)|null|
|**2025-01-16**|**From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs**|Hrithik Majumdar Shibu et.al.|[2501.09604v1](http://arxiv.org/abs/2501.09604v1)|[link](https://github.com/shibu4064/indonlp)|
|**2025-01-16**|**Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining**|Nathan Vaska et.al.|[2501.09597v1](http://arxiv.org/abs/2501.09597v1)|null|
|**2025-01-16**|**MatrixNet: Learning over symmetry groups using learned group representations**|Lucas Laird et.al.|[2501.09571v1](http://arxiv.org/abs/2501.09571v1)|[link](https://github.com/lucas-laird/matrixnet)|
|**2025-01-16**|**Stylomech: Unveiling Authorship via Computational Stylometry in English and Romanized Sinhala**|Nabeelah Faumi et.al.|[2501.09561v1](http://arxiv.org/abs/2501.09561v1)|null|
|**2025-01-16**|**Text-driven Adaptation of Foundation Models for Few-shot Surgical Workflow Analysis**|Tingxuan Chen et.al.|[2501.09555v1](http://arxiv.org/abs/2501.09555v1)|null|
|**2025-01-16**|**AI in Support of Diversity and Inclusion**|Çiçek Güven et.al.|[2501.09534v1](http://arxiv.org/abs/2501.09534v1)|null|
|**2025-01-16**|**Confidence Estimation for Error Detection in Text-to-SQL Systems**|Oleg Somov et.al.|[2501.09527v1](http://arxiv.org/abs/2501.09527v1)|null|
|**2025-01-16**|**Class Incremental Fault Diagnosis under Limited Fault Data via Supervised Contrastive Knowledge Distillation**|Hanrong Zhang et.al.|[2501.09525v1](http://arxiv.org/abs/2501.09525v1)|[link](https://github.com/zhang-henry/sclifd_tii)|
|**2025-01-16**|**Augmenting a Large Language Model with a Combination of Text and Visual Data for Conversational Visualization of Global Geospatial Data**|Omar Mena et.al.|[2501.09521v1](http://arxiv.org/abs/2501.09521v1)|null|
|**2025-01-16**|**PIER: A Novel Metric for Evaluating What Matters in Code-Switching**|Enes Yavuz Ugan et.al.|[2501.09512v1](http://arxiv.org/abs/2501.09512v1)|null|
|**2025-01-16**|**Exploring the Inquiry-Diagnosis Relationship with Advanced Patient Simulators**|Zhaocheng Liu et.al.|[2501.09484v1](http://arxiv.org/abs/2501.09484v1)|null|
|**2025-01-16**|**Predicting Air Temperature from Volumetric Urban Morphology with Machine Learning**|Berk Kıvılcım et.al.|[2501.09469v1](http://arxiv.org/abs/2501.09469v1)|null|
|**2025-01-16**|**RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection**|Jianrui Shi et.al.|[2501.09465v1](http://arxiv.org/abs/2501.09465v1)|null|
|**2025-01-16**|**Scaling Graph-Based Dependency Parsing with Arc Vectorization and Attention-Based Refinement**|Nicolas Floquet et.al.|[2501.09451v1](http://arxiv.org/abs/2501.09451v1)|null|
|**2025-01-16**|**Solving the unsolvable: Translating case law in Hong Kong**|King-kui Sin et.al.|[2501.09444v1](http://arxiv.org/abs/2501.09444v1)|null|
|**2025-01-16**|**A Survey on Responsible LLMs: Inherent Risk, Malicious Use, and Mitigation Strategy**|Huandong Wang et.al.|[2501.09431v1](http://arxiv.org/abs/2501.09431v1)|null|
|**2025-01-16**|**ADAGE: A generic two-layer framework for adaptive agent based modelling**|Benjamin Patrick Evans et.al.|[2501.09429v1](http://arxiv.org/abs/2501.09429v1)|null|
|**2025-01-16**|**AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling**|Ancheng Xu et.al.|[2501.09426v1](http://arxiv.org/abs/2501.09426v1)|null|
|**2025-01-16**|**Vision-Language Models Do Not Understand Negation**|Kumail Alhamoud et.al.|[2501.09425v1](http://arxiv.org/abs/2501.09425v1)|null|
|**2025-01-16**|**Dynamic Neural Style Transfer for Artistic Image Generation using VGG19**|Kapil Kashyap et.al.|[2501.09420v1](http://arxiv.org/abs/2501.09420v1)|null|
|**2025-01-16**|**MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models**|Lyudong Jin et.al.|[2501.09410v1](http://arxiv.org/abs/2501.09410v1)|null|
|**2025-01-16**|**mGeNTE: A Multilingual Resource for Gender-Neutral Language and Translation**|Beatrice Savoldi et.al.|[2501.09409v1](http://arxiv.org/abs/2501.09409v1)|null|
|**2025-01-16**|**Quantum-Enhanced Transformers for Robust Acoustic Scene Classification in IoT Environments**|Minh K. Quan et.al.|[2501.09394v1](http://arxiv.org/abs/2501.09394v1)|null|
|**2025-01-16**|**Evaluating LLM Abilities to Understand Tabular Electronic Health Records: A Comprehensive Study of Patient Data Extraction and Retrieval**|Jesus Lovon et.al.|[2501.09384v1](http://arxiv.org/abs/2501.09384v1)|null|
|**2025-01-16**|**Aligning Instruction Tuning with Pre-training**|Yiming Liang et.al.|[2501.09368v1](http://arxiv.org/abs/2501.09368v1)|null|
|**2025-01-16**|**YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks**|Saptarashmi Bandyopadhyay et.al.|[2501.09355v1](http://arxiv.org/abs/2501.09355v1)|null|
|**2025-01-16**|**Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems with Style and Shopping Cart Information**|Berke Ugurlu et.al.|[2501.09354v1](http://arxiv.org/abs/2501.09354v1)|null|
|**2025-01-16**|**ChartInsighter: An Approach for Mitigating Hallucination in Time-series Chart Summary Generation with A Benchmark Dataset**|Fen Wang et.al.|[2501.09349v1](http://arxiv.org/abs/2501.09349v1)|[link](https://github.com/wangfen01/chartinsighter)|
|**2025-01-16**|**Rational Tuning of LLM Cascades via Probabilistic Modeling**|Michael J. Zellinger et.al.|[2501.09345v1](http://arxiv.org/abs/2501.09345v1)|null|
|**2025-01-16**|**Prompt-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis**|Arpita Chowdhury et.al.|[2501.09333v1](http://arxiv.org/abs/2501.09333v1)|null|
|**2025-01-16**|**Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks**|Yixiao Xu et.al.|[2501.09328v1](http://arxiv.org/abs/2501.09328v1)|[link](https://github.com/neurht/neurht)|
|**2025-01-16**|**On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression**|Zichang Ge et.al.|[2501.09327v1](http://arxiv.org/abs/2501.09327v1)|[link](https://github.com/erasmo1015/vte)|
|**2025-01-16**|**Algorithm for Semantic Network Generation from Texts of Low Resource Languages Such as Kiswahili**|Barack Wamkaya Wanjawa et.al.|[2501.09326v1](http://arxiv.org/abs/2501.09326v1)|null|
|**2025-01-16**|**SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**|Anbang Ye et.al.|[2501.09316v1](http://arxiv.org/abs/2501.09316v1)|null|
|**2025-01-16**|**A Study of In-Context-Learning-Based Text-to-SQL Errors**|Jiawei Shen et.al.|[2501.09310v1](http://arxiv.org/abs/2501.09310v1)|null|
|**2025-01-16**|**Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**|Mohaiminul Islam Bhuiyan et.al.|[2501.09309v1](http://arxiv.org/abs/2501.09309v1)|null|
|**2025-01-16**|**Efficient Few-Shot Medical Image Analysis via Hierarchical Contrastive Vision-Language Learning**|Harrison Fuller et.al.|[2501.09294v1](http://arxiv.org/abs/2501.09294v1)|null|
|**2025-01-16**|**To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation**|Kaustubh D. Dhole et.al.|[2501.09292v1](http://arxiv.org/abs/2501.09292v1)|null|
|**2025-01-16**|**LAVCap: LLM-based Audio-Visual Captioning using Optimal Transport**|Kyeongha Rho et.al.|[2501.09291v1](http://arxiv.org/abs/2501.09291v1)|[link](https://github.com/naver-intel-co-lab/gaudi-lavcap)|
|**2025-01-16**|**SEAL: Entangled White-box Watermarks on Low-Rank Adaptation**|Giyeong Oh et.al.|[2501.09284v1](http://arxiv.org/abs/2501.09284v1)|null|
|**2025-01-16**|**Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**|Zijin Qiu et.al.|[2501.09279v1](http://arxiv.org/abs/2501.09279v1)|null|
|**2025-01-16**|**Large Language Model is Secretly a Protein Sequence Optimizer**|Yinkai Wang et.al.|[2501.09274v1](http://arxiv.org/abs/2501.09274v1)|null|
|**2025-01-16**|**Perspective Transition of Large Language Models for Solving Subjective Tasks**|Xiaolong Wang et.al.|[2501.09265v1](http://arxiv.org/abs/2501.09265v1)|null|
|**2025-01-16**|**Delayed Fusion: Integrating Large Language Models into First-Pass Decoding in End-to-end Speech Recognition**|Takaaki Hori et.al.|[2501.09258v1](http://arxiv.org/abs/2501.09258v1)|null|
|**2025-01-16**|**Clone-Robust AI Alignment**|Ariel D. Procaccia et.al.|[2501.09254v1](http://arxiv.org/abs/2501.09254v1)|null|
|**2025-01-16**|**Foundations of Large Language Models**|Tong Xiao et.al.|[2501.09223v1](http://arxiv.org/abs/2501.09223v1)|null|
|**2025-01-16**|**A Simple Graph Contrastive Learning Framework for Short Text Classification**|Yonghao Liu et.al.|[2501.09219v1](http://arxiv.org/abs/2501.09219v1)|[link](https://github.com/keaml-jlu/simstc)|
|**2025-01-16**|**Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**|Yuanyuan Wei et.al.|[2501.09218v1](http://arxiv.org/abs/2501.09218v1)|null|
|**2025-01-16**|**Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**|Yonghao Liu et.al.|[2501.09214v1](http://arxiv.org/abs/2501.09214v1)|[link](https://github.com/keaml-jlu/mi-delight)|
|**2025-01-16**|**FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training**|Hongzhou Yu et.al.|[2501.09213v1](http://arxiv.org/abs/2501.09213v1)|null|
|**2025-01-15**|**Grounding Text-To-Image Diffusion Models For Controlled High-Quality Image Generation**|Ahmad Süleyman et.al.|[2501.09194v1](http://arxiv.org/abs/2501.09194v1)|null|
|**2025-01-15**|**Patch-aware Vector Quantized Codebook Learning for Unsupervised Visual Defect Detection**|Qisen Cheng et.al.|[2501.09187v1](http://arxiv.org/abs/2501.09187v1)|null|
|**2025-01-15**|**Guiding Retrieval using LLM-based Listwise Rankers**|Mandeep Rathee et.al.|[2501.09186v1](http://arxiv.org/abs/2501.09186v1)|[link](https://github.com/mandeep-rathee/llmgar)|
|**2025-01-15**|**Attention is All You Need Until You Need Retention**|M. Murat Yaslioglu et.al.|[2501.09166v1](http://arxiv.org/abs/2501.09166v1)|null|
|**2025-01-15**|**The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and Lithuanian Short Answer Matching**|Yevhen Kostiuk et.al.|[2501.09164v1](http://arxiv.org/abs/2501.09164v1)|null|
|**2025-01-15**|**Towards Understanding Extrapolation: a Causal Lens**|Lingjing Kong et.al.|[2501.09163v1](http://arxiv.org/abs/2501.09163v1)|null|
|**2025-01-15**|**AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**|Assaf Lahiany et.al.|[2501.09160v1](http://arxiv.org/abs/2501.09160v1)|null|
|**2025-01-15**|**Evaluating GenAI for Simplifying Texts for Education: Improving Accuracy and Consistency for Enhanced Readability**|Stephanie L. Day et.al.|[2501.09158v1](http://arxiv.org/abs/2501.09158v1)|null|
|**2025-01-15**|**VCRScore: Image captioning metric based on V\&L Transformers, CLIP, and precision-recall**|Guillermo Ruiz et.al.|[2501.09155v1](http://arxiv.org/abs/2501.09155v1)|null|
|**2025-01-15**|**Towards Multilingual LLM Evaluation for Baltic and Nordic languages: A study on Lithuanian History**|Yevhen Kostiuk et.al.|[2501.09154v1](http://arxiv.org/abs/2501.09154v1)|null|
|**2025-01-15**|**Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG**|Aditi Singh et.al.|[2501.09136v1](http://arxiv.org/abs/2501.09136v1)|[link](https://github.com/asinghcsu/agenticrag-survey)|
|**2025-01-15**|**Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**|Demetrio Deanda et.al.|[2501.09134v1](http://arxiv.org/abs/2501.09134v1)|null|
|**2025-01-15**|**Multilingual LLMs Struggle to Link Orthography and Semantics in Bilingual Word Processing**|Eshaan Tanwar et.al.|[2501.09127v1](http://arxiv.org/abs/2501.09127v1)|[link](https://github.com/eshaant/bilingual_processing_llms)|
|**2025-01-15**|**Augmenting Human-Annotated Training Data with Large Language Model Generation and Distillation in Open-Response Assessment**|Conrad Borchers et.al.|[2501.09126v1](http://arxiv.org/abs/2501.09126v1)|null|
|**2025-01-15**|**Mantis Shrimp: Exploring Photometric Band Utilization in Computer Vision Networks for Photometric Redshift Estimation**|Andrew Engel et.al.|[2501.09112v1](http://arxiv.org/abs/2501.09112v1)|[link](https://github.com/pnnl/mantisshrimp)|
|**2025-01-15**|**A Non-autoregressive Model for Joint STT and TTS**|Vishal Sunder et.al.|[2501.09104v1](http://arxiv.org/abs/2501.09104v1)|null|
|**2025-01-15**|**Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites**|Hans W. A. Hanley et.al.|[2501.09102v1](http://arxiv.org/abs/2501.09102v1)|[link](https://github.com/hanshanley/tracking-takes)|
|**2025-01-15**|**SteLLA: A Structured Grading System Using LLMs with RAG**|Hefei Qiu et.al.|[2501.09092v1](http://arxiv.org/abs/2501.09092v1)|null|
|**2025-01-15**|**Inferring Transition Dynamics from Value Functions**|Jacob Adamczyk et.al.|[2501.09081v1](http://arxiv.org/abs/2501.09081v1)|null|
|**2025-01-15**|**How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias**|Tosin Fadahunsi et.al.|[2501.09014v1](http://arxiv.org/abs/2501.09014v1)|[link](https://github.com/giordanodaloisio/sd-bias)|
|**2025-01-15**|**Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**|Ruixiang Jiang et.al.|[2501.09012v1](http://arxiv.org/abs/2501.09012v1)|[link](https://github.com/songrise/mllm4art)|
|**2025-01-15**|**Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition**|Sneheel Sarangi et.al.|[2501.09056v1](http://arxiv.org/abs/2501.09056v1)|[link](https://github.com/xarangi/decompose-tom)|
|**2025-01-15**|**Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails**|Shaona Ghosh et.al.|[2501.09004v1](http://arxiv.org/abs/2501.09004v1)|null|
|**2025-01-15**|**Personality Modeling for Persuasion of Misinformation using AI Agent**|Qianmin Lou et.al.|[2501.08985v1](http://arxiv.org/abs/2501.08985v1)|null|

#### Abstracts
##### **Learnings from Scaling Visual Tokenizers for Reconstruction and Generation**
2501.09755v1 by Philippe Hansen-Estruch, David Yan, Ching-Yao Chung, Orr Zohar, Jialiang Wang, Tingbo Hou, Tao Xu, Sriram Vishwanath, Peter Vajda, Xinlei Chen

Visual tokenization via auto-encoding empowers state-of-the-art image and
video generative models by compressing pixels into a latent space. Although
scaling Transformer-based generators has been central to recent advances, the
tokenizer component itself is rarely scaled, leaving open questions about how
auto-encoder design choices influence both its objective of reconstruction and
downstream generative performance. Our work aims to conduct an exploration of
scaling in auto-encoders to fill in this blank. To facilitate this exploration,
we replace the typical convolutional backbone with an enhanced Vision
Transformer architecture for Tokenization (ViTok). We train ViTok on
large-scale image and video datasets far exceeding ImageNet-1K, removing data
constraints on tokenizer scaling. We first study how scaling the auto-encoder
bottleneck affects both reconstruction and generation -- and find that while it
is highly correlated with reconstruction, its relationship with generation is
more complex. We next explored the effect of separately scaling the
auto-encoders' encoder and decoder on reconstruction and generation
performance. Crucially, we find that scaling the encoder yields minimal gains
for either reconstruction or generation, while scaling the decoder boosts
reconstruction but the benefits for generation are mixed. Building on our
exploration, we design ViTok as a lightweight auto-encoder that achieves
competitive performance with state-of-the-art auto-encoders on ImageNet-1K and
COCO reconstruction tasks (256p and 512p) while outperforming existing
auto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x
fewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates
competitive performance on image generation for ImageNet-1K and sets new
state-of-the-art benchmarks for class-conditional video generation on UCF-101.

摘要：<paragraph>透過自動編碼進行視覺標記化，能將像素壓縮成潛在空間，進而增強最先進的影像和影片生成模型。儘管擴充基於 Transformer 的生成器已成為近期進展的核心，但標記化元件本身卻很少被擴充，因此對於自動編碼器設計選擇如何影響其重建目標和下游生成效能，仍有待探討。我們的研究旨在探索自動編碼器的擴充，以填補這項空白。為了促進此探索，我們將典型的卷積主幹替換為增強的 Tokenization 視覺 Transformer 架構 (ViTok)。我們在遠遠超過 ImageNet-1K 的大型影像和影片資料集上訓練 ViTok，消除了標記化擴充的資料限制。我們首先研究擴充自動編碼器瓶頸如何影響重建和生成，並發現儘管它與重建高度相關，但與生成之間的關係更為複雜。接下來，我們探討了分別擴充自動編碼器的編碼器和解碼器對重建和生成效能的影響。至關重要的是，我們發現擴充編碼器對重建或生成而言收益甚微，而擴充解碼器會提升重建，但對生成的益處則是好壞參半。根據我們的探索，我們將 ViTok 設計為一個輕量級自動編碼器，在 ImageNet-1K 和 COCO 重建任務 (256p 和 512p) 上，都能達到與最先進自動編碼器相媲美的效能，同時在 UCF-101 的 16 幀 128p 影片重建上優於現有的自動編碼器，且 FLOP 數減少 2-5 倍。與擴散 Transformer 整合後，ViTok 在 ImageNet-1K 的影像生成上展現了競爭力，並在 UCF-101 的類別條件影片生成上創下新的最先進基準。</paragraph>

##### **OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking**
2501.09751v1 by Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, Huajun Chen

Machine writing with large language models often relies on
retrieval-augmented generation. However, these approaches remain confined
within the boundaries of the model's predefined scope, limiting the generation
of content with rich information. Specifically, vanilla-retrieved information
tends to lack depth, utility, and suffers from redundancy, which negatively
impacts the quality of generated articles, leading to shallow, repetitive, and
unoriginal outputs. To address these issues, we propose OmniThink, a machine
writing framework that emulates the human-like process of iterative expansion
and reflection. The core idea behind OmniThink is to simulate the cognitive
behavior of learners as they progressively deepen their knowledge of the
topics. Experimental results demonstrate that OmniThink improves the knowledge
density of generated articles without compromising metrics such as coherence
and depth. Human evaluations and expert feedback further highlight the
potential of OmniThink to address real-world challenges in the generation of
long-form articles.

摘要：大型語言模型的機器寫作通常依賴於檢索增強生成。然而，這些方法仍侷限於模型預定義的範圍內，限制了產生具有豐富信息的內容。具體來說，香草檢索信息往往缺乏深度、實用性，並且存在冗餘，這對生成的條目品質產生負面影響，導致膚淺、重複且缺乏原創性的輸出。為了解決這些問題，我們提出了 OmniThink，這是一個模擬人類迭代擴展和反思過程的機器寫作框架。OmniThink 背後的主要思想是模擬學習者在逐漸加深對主題的了解時的認知行為。實驗結果表明，OmniThink 改善了生成條目的知識密度，同時不影響相干性和深度等指標。人類評估和專家回饋進一步突出了 OmniThink 在解決長篇條目生成中的現實世界挑戰的潛力。

##### **Enhancing Lexicon-Based Text Embeddings with Large Language Models**
2501.09749v1 by Yibin Lei, Tao Shen, Yu Cao, Andrew Yates

Recent large language models (LLMs) have demonstrated exceptional performance
on general-purpose text embedding tasks. While dense embeddings have dominated
related research, we introduce the first Lexicon-based EmbeddiNgS (LENS)
leveraging LLMs that achieve competitive performance on these tasks. Regarding
the inherent tokenization redundancy issue and unidirectional attention
limitations in traditional causal LLMs, LENS consolidates the vocabulary space
through token embedding clustering, and investigates bidirectional attention
and various pooling strategies. Specifically, LENS simplifies lexicon matching
by assigning each dimension to a specific token cluster, where semantically
similar tokens are grouped together, and unlocking the full potential of LLMs
through bidirectional attention. Extensive experiments demonstrate that LENS
outperforms dense embeddings on the Massive Text Embedding Benchmark (MTEB),
delivering compact feature representations that match the sizes of dense
counterparts. Notably, combining LENSE with dense embeddings achieves
state-of-the-art performance on the retrieval subset of MTEB (i.e. BEIR).

摘要：最近的大型语言模型 (LLM) 在通用文字嵌入任务中展现出非凡的性能。虽然稠密嵌入主导相关研究，但我们引入了第一个基于词典的嵌入 (LENS)，利用 LLM 在这些任务中实现有竞争力的性能。关于传统因果 LLM 中固有的标记化冗余问题和单向注意限制，LENS 通过标记嵌入聚类巩固词汇空间，并研究双向注意和各种池化策略。具体来说，LENS 通过将每个维度分配给一个特定的标记群集来简化词典匹配，其中语义相似的标记被分组在一起，并通过双向注意释放 LLM 的全部潜力。广泛的实验表明，LENS 在海量文本嵌入基准 (MTEB) 上优于稠密嵌入，提供了与稠密对应物大小匹配的紧凑特征表示。值得注意的是，将 LENSE 与稠密嵌入相结合在 MTEB 的检索子集（即 BEIR）上实现了最先进的性能。

##### **Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models**
2501.09745v1 by Bihui Jin, Jiayue Wang, Pengyu Nie

Machine learning developers frequently use interactive computational
notebooks, such as Jupyter notebooks, to host code for data processing and
model training. Jupyter notebooks provide a convenient tool for writing machine
learning pipelines and interactively observing outputs, however, maintaining
Jupyter notebooks, e.g., to add new features or fix bugs, can be challenging
due to the length and complexity of the notebooks. Moreover, there is no
existing benchmark related to developer edits on Jupyter notebooks. To address
this, we present the first dataset of 48,398 Jupyter notebook edits derived
from 20,095 revisions of 792 machine learning repositories on GitHub, and
perform the first study of the using LLMs to predict code edits in Jupyter
notebooks. Our dataset captures granular details of cell-level and line-level
modifications, offering a foundation for understanding real-world maintenance
patterns in machine learning workflows. We observed that the edits on Jupyter
notebooks are highly localized, with changes averaging only 166 lines of code
in repositories. While larger models outperform smaller counterparts in code
editing, all models have low accuracy on our dataset even after finetuning,
demonstrating the complexity of real-world machine learning maintenance tasks.
Our findings emphasize the critical role of contextual information in improving
model performance and point toward promising avenues for advancing large
language models' capabilities in engineering machine learning code.

摘要：機器學習開發人員經常使用互動式運算筆記本，例如 Jupyter 筆記本，來儲存資料處理和模型訓練的程式碼。Jupyter 筆記本提供了一個方便的工具來撰寫機器學習管線並互動式地觀察輸出，然而，維護 Jupyter 筆記本（例如，新增功能或修正錯誤）可能會很困難，因為筆記本的長度和複雜性。此外，目前沒有與 Jupyter 筆記本上開發人員編輯相關的基準測試。為了解決這個問題，我們提供了第一個資料集，其中包含來自 GitHub 上 792 個機器學習儲存庫的 20,095 次修訂中衍生的 48,398 次 Jupyter 筆記本編輯，並執行第一個使用 LLM 來預測 Jupyter 筆記本中程式碼編輯的研究。我們的資料集擷取了單元格層級和行層級修改的詳細資料，為了解機器學習工作流程中的真實世界維護模式提供了基礎。我們觀察到 Jupyter 筆記本上的編輯高度局部化，儲存庫中的變更平均只有 166 行程式碼。雖然較大的模型在程式碼編輯方面優於較小的模型，但在微調後，所有模型在我們的資料集上都具有低準確度，這證明了真實世界的機器學習維護任務的複雜性。我們的研究結果強調了背景資訊在改善模型效能方面的重要作用，並指出了推動大型語言模型在機器學習程式碼工程方面的能力的潛在途徑。

##### **KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**
2501.09744v1 by Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang

The objective of BioCreative8 Track 3 is to extract phenotypic key medical
findings embedded within EHR texts and subsequently normalize these findings to
their Human Phenotype Ontology (HPO) terms. However, the presence of diverse
surface forms in phenotypic findings makes it challenging to accurately
normalize them to the correct HPO terms. To address this challenge, we explored
various models for named entity recognition and implemented data augmentation
techniques such as synonym marginalization to enhance the normalization step.
Our pipeline resulted in an exact extraction and normalization F1 score 2.6\%
higher than the mean score of all submissions received in response to the
challenge. Furthermore, in terms of the normalization F1 score, our approach
surpassed the average performance by 1.9\%. These findings contribute to the
advancement of automated medical data extraction and normalization techniques,
showcasing potential pathways for future research and application in the
biomedical domain.

摘要：BioCreative8 軌道 3 的目標是從電子病歷文本中萃取表型關鍵醫療發現，並將這些發現標準化為人類表型本体 (HPO) 條款。然而，表型發現中存在多樣化的表面形式，這使得將其準確標準化為正確的 HPO 條款具有挑戰性。為了應對這一挑戰，我們探討了命名實體識別的各種模型，並實作了資料擴充技術，例如同義詞邊緣化，以增強標準化步驟。我們的管道產生了精確的萃取和標準化 F1 分數，比回應挑戰所收到的所有提交的平均分數高 2.6%。此外，在標準化 F1 分數方面，我們的做法比平均表現高出 1.9%。這些發現有助於自動化醫療資料萃取和標準化技術的進展，展示了生物醫學領域未來研究和應用的潛在途徑。

##### **Attention based Bidirectional GRU hybrid model for inappropriate content detection in Urdu language**
2501.09722v1 by Ezzah Shoukat, Rabia Irfan, Iqra Basharat, Muhammad Ali Tahir, Sameen Shaukat

With the increased use of the internet and social networks for online
discussions, the spread of toxic and inappropriate content on social networking
sites has also increased. Several studies have been conducted in different
languages. However, there is less work done for South Asian languages for
inappropriate content identification using deep learning techniques. In Urdu
language, the spellings are not unique, and people write different common
spellings for the same word, while mixing it other languages, like English in
the text makes it more challenging, and limited research work is available to
process such language with the finest algorithms. The use of attention layer
with a deep learning model can help handling the long-term dependencies and
increase its efficiency . To explore the effects of the attention layer, this
study proposes attention-based Bidirectional GRU hybrid model for identifying
inappropriate content in Urdu Unicode text language. Four different baseline
deep learning models; LSTM, Bi-LSTM, GRU, and TCN, are used to compare the
performance of the proposed model. The results of these models were compared
based on evaluation metrics, dataset size, and impact of the word embedding
layer. The pre-trained Urdu word2Vec embeddings were utilized for our case. Our
proposed model BiGRU-A outperformed all other baseline models by yielding 84\%
accuracy without using pre-trained word2Vec layer. From our experiments, we
have established that the attention layer improves the model's efficiency, and
pre-trained word2Vec embedding does not work well with an inappropriate content
dataset.

摘要：<paragraph>随着互联网和社交网络在线讨论的使用增加，社交网站上也会出现更多有毒和不当的内容。已经针对不同的语言进行了多项研究。然而，使用深度学习技术对南亚语言进行不当内容识别方面的工作较少。在乌尔都语中，拼写并不唯一，人们为同一个单词书写不同的常用拼写，同时在文本中将其与其他语言（如英语）混合，使其更具挑战性，并且有限的研究工作可以利用最好的算法来处理这种语言。在深度学习模型中使用注意力层可以帮助处理长期依赖关系并提高其效率。为了探索注意力层的效果，本研究提出了基于注意力的双向 GRU 混合模型，用于识别乌尔都语 Unicode 文本语言中的不当内容。四个不同的基线深度学习模型；LSTM、Bi-LSTM、GRU 和 TCN，用于比较所提出模型的性能。这些模型的结果基于评估指标、数据集大小和单词嵌入层的影响进行了比较。我们案例中使用了预训练的乌尔都语 word2Vec 嵌入。我们提出的模型 BiGRU-A 在不使用预训练的 word2Vec 层的情况下，以 84% 的准确率优于所有其他基线模型。从我们的实验中，我们已经确定注意力层提高了模型的效率，并且预训练的 word2Vec 嵌入与不当内容数据集配合得不好。</paragraph>

##### **A Simple Aerial Detection Baseline of Multimodal Language Models**
2501.09720v1 by Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang

The multimodal language models (MLMs) based on generative pre-trained
Transformer are considered powerful candidates for unifying various domains and
tasks. MLMs developed for remote sensing (RS) have demonstrated outstanding
performance in multiple tasks, such as visual question answering and visual
grounding. In addition to visual grounding that detects specific objects
corresponded to given instruction, aerial detection, which detects all objects
of multiple categories, is also a valuable and challenging task for RS
foundation models. However, aerial detection has not been explored by existing
RS MLMs because the autoregressive prediction mechanism of MLMs differs
significantly from the detection outputs. In this paper, we present a simple
baseline for applying MLMs to aerial detection for the first time, named
LMMRotate. Specifically, we first introduce a normalization method to transform
detection outputs into textual outputs to be compatible with the MLM framework.
Then, we propose a evaluation method, which ensures a fair comparison between
MLMs and conventional object detection models. We construct the baseline by
fine-tuning open-source general-purpose MLMs and achieve impressive detection
performance comparable to conventional detector. We hope that this baseline
will serve as a reference for future MLM development, enabling more
comprehensive capabilities for understanding RS images. Code is available at
https://github.com/Li-Qingyun/mllm-mmrotate.

摘要：基於生成式預訓練 Transformer 的多模態語言模型 (MLM) 被認為是統一各種領域和任務的有力候選者。為遙感 (RS) 開發的 MLM 已在多項任務中展現傑出的效能，例如視覺問題解答和視覺基礎。除了偵測特定物體以對應給定指令的視覺基礎外，偵測所有多類別的物體的空中偵測也是 RS 基礎模型中一項有價值且具有挑戰性的任務。然而，空中偵測尚未被現有的 RS MLM 探索，因為 MLM 的自迴歸預測機制與偵測輸出有顯著的差異。在本文中，我們提出了一個簡單的基準，首次將 MLM 應用於空中偵測，稱為 LMMRotate。具體來說，我們首先引入一種正規化方法，將偵測輸出轉換為文字輸出，以與 MLM 框架相容。然後，我們提出一個評估方法，以確保 MLM 與傳統物體偵測模型之間的公平比較。我們透過微調開源通用 MLM 來建構基準，並獲得與傳統偵測器相當的令人印象深刻的偵測效能。我們希望這個基準能作為未來 MLM 開發的參考，讓理解 RS 影像的能力更全面。程式碼可在 https://github.com/Li-Qingyun/mllm-mmrotate 取得。

##### **Comparative Insights from 12 Machine Learning Models in Extracting Economic Ideology from Political Text**
2501.09719v1 by Jihed Ncib

This study conducts a systematic assessment of the capabilities of 12 machine
learning models and model variations in detecting economic ideology. As an
evaluation benchmark, I use manifesto data spanning six elections in the United
Kingdom and pre-annotated by expert and crowd coders. The analysis assesses the
performance of several generative, fine-tuned, and zero-shot models at the
granular and aggregate levels. The results show that generative models such as
GPT-4o and Gemini 1.5 Flash consistently outperform other models against all
benchmarks. However, they pose issues of accessibility and resource
availability. Fine-tuning yielded competitive performance and offers a reliable
alternative through domain-specific optimization. But its dependency on
training data severely limits scalability. Zero-shot models consistently face
difficulties with identifying signals of economic ideology, often resulting in
negative associations with human coding. Using general knowledge for the
domain-specific task of ideology scaling proved to be unreliable. Other key
findings include considerable within-party variation, fine-tuning benefiting
from larger training data, and zero-shot's sensitivity to prompt content. The
assessments include the strengths and limitations of each model and derive
best-practices for automated analyses of political content.

摘要：本研究對 12 個機器學習模型和模型變異偵測經濟意識形態的能力進行系統性評估。作為評估基準，我使用跨越英國六次選舉的政綱資料，並由專家和群眾編碼員預先註解。分析評估了幾個生成式、微調和零次學習模型在細粒度和彙總層級的效能。結果顯示，GPT-4o 和 Gemini 1.5 Flash 等生成式模型在所有基準上始終優於其他模型。然而，它們提出了可及性和資源可用性的問題。微調產生了競爭力表現，並透過特定領域最佳化提供了一個可靠的替代方案。但它對訓練資料的依賴嚴重限制了可擴充性。零次學習模型始終難以識別經濟意識形態的訊號，通常會導致與人類編碼的負面關聯。使用一般知識來進行意識形態擴充的特定領域任務被證明不可靠。其他關鍵發現包括黨內變異相當大、微調受益於更大的訓練資料，以及零次學習對提示內容的敏感性。評估包括每個模型的優點和缺點，並為政治內容的自動化分析得出最佳實務。

##### **CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education**
2501.09709v1 by Tianyu Wang, Nianjun Zhou, Zhixiong Chen

Many non-traditional students in cybersecurity programs often lack access to
advice from peers, family members and professors, which can hinder their
educational experiences. Additionally, these students may not fully benefit
from various LLM-powered AI assistants due to issues like content relevance,
locality of advice, minimum expertise, and timing. This paper addresses these
challenges by introducing an application designed to provide comprehensive
support by answering questions related to knowledge, skills, and career
preparation advice tailored to the needs of these students. We developed a
learning tool platform, CyberMentor, to address the diverse needs and pain
points of students majoring in cybersecurity. Powered by agentic workflow and
Generative Large Language Models (LLMs), the platform leverages
Retrieval-Augmented Generation (RAG) for accurate and contextually relevant
information retrieval to achieve accessibility and personalization. We
demonstrated its value in addressing knowledge requirements for cybersecurity
education and for career marketability, in tackling skill requirements for
analytical and programming assignments, and in delivering real time on demand
learning support. Using three use scenarios, we showcased CyberMentor in
facilitating knowledge acquisition and career preparation and providing
seamless skill-based guidance and support. We also employed the LangChain
prompt-based evaluation methodology to evaluate the platform's impact,
confirming its strong performance in helpfulness, correctness, and
completeness. These results underscore the system's ability to support students
in developing practical cybersecurity skills while improving equity and
sustainability within higher education. Furthermore, CyberMentor's open-source
design allows for adaptation across other disciplines, fostering educational
innovation and broadening its potential impact.

摘要：<paragraph>許多非傳統的網路安全課程學生經常缺乏來自同儕、家人和教授的建議，這可能會阻礙他們的教育經驗。此外，由於內容相關性、建議的地域性、最低專業知識和時機等問題，這些學生可能無法充分受益於各種 LLM 驅動的 AI 助理。本文透過介紹一個應用程式來解決這些挑戰，該應用程式旨在透過回答與知識、技能和職業準備建議相關的問題，提供全面的支援，以滿足這些學生的需求。我們開發了一個學習工具平台 CyberMentor，以滿足主修網路安全的學生們的多元需求和痛點。該平台由代理工作流程和生成式大型語言模型 (LLM) 提供支援，利用檢索增強生成 (RAG) 來進行準確且與脈絡相關的資訊檢索，以實現可及性和個人化。我們展示了其在滿足網路安全教育和職業適銷性的知識需求、應對分析和編程作業的技能需求以及提供即時依需求學習支援方面的價值。使用三個使用情境，我們展示了 CyberMentor 在促進知識獲取和職業準備以及提供無縫的技能指導和支援方面的作用。我們還採用了基於提示的 LangChain 評估方法來評估平台的影響，確認其在有幫助性、正確性和完整性方面的強勁表現。這些結果強調了系統在培養學生實務網路安全技能的同時，還能提升高等教育中的公平性和永續性的能力。此外，CyberMentor 的開源設計允許跨其他學科進行調整，促進教育創新並擴大其潛在影響。</paragraph>

##### **The Goofus & Gallant Story Corpus for Practical Value Alignment**
2501.09707v1 by Md Sultan Al Nahian, Tasmia Tasrin, Spencer Frazier, Mark Riedl, Brent Harrison

Values or principles are key elements of human society that influence people
to behave and function according to an accepted standard set of social rules to
maintain social order. As AI systems are becoming ubiquitous in human society,
it is a major concern that they could violate these norms or values and
potentially cause harm. Thus, to prevent intentional or unintentional harm, AI
systems are expected to take actions that align with these principles. Training
systems to exhibit this type of behavior is difficult and often requires a
specialized dataset. This work presents a multi-modal dataset illustrating
normative and non-normative behavior in real-life situations described through
natural language and artistic images. This training set contains curated sets
of images that are designed to teach young children about social principles. We
argue that this is an ideal dataset to use for training socially normative
agents given this fact.

摘要：價值觀或原則是人類社會的關鍵元素，影響著人們根據一套公認的社會規則來行為和運作，以維持社會秩序。由於人工智慧系統在人類社會中正變得無處不在，因此它們可能違反這些規範或價值觀並可能造成傷害，這是一個主要的關注點。因此，為了防止故意或無意的傷害，預期人工智慧系統採取與這些原則一致的行動。訓練系統表現出這種類型的行為很困難，而且通常需要一個專業的資料集。這項工作提供了一個多模態資料集，說明了在透過自然語言和藝術圖像描述的真實生活中，規範性和非規範性行為。這個訓練集包含經過策展的圖像集，旨在教導幼兒有關社會原則。我們認為，鑑於這個事實，這是用於訓練社會規範代理人的理想資料集。

##### **Domain Adaptation of Foundation LLMs for e-Commerce**
2501.09706v1 by Christian Herold, Michael Kozielski, Tala Bazazo, Pavel Petrushkov, Hadi Hashemi, Patrycja Cieplicka, Dominika Basaj, Shahram Khadivi

We present the e-Llama models: 8 billion and 70 billion parameter large
language models that are adapted towards the e-commerce domain. These models
are meant as foundation models with deep knowledge about e-commerce, that form
a base for instruction- and fine-tuning. The e-Llama models are obtained by
continuously pretraining the Llama 3.1 base models on 1 trillion tokens of
domain-specific data.
  We discuss our approach and motivate our choice of hyperparameters with a
series of ablation studies. To quantify how well the models have been adapted
to the e-commerce domain, we define and implement a set of multilingual,
e-commerce specific evaluation tasks.
  We show that, when carefully choosing the training setup, the Llama 3.1
models can be adapted towards the new domain without sacrificing significant
performance on general domain tasks. We also explore the possibility of merging
the adapted model and the base model for a better control of the performance
trade-off between domains.

摘要：我們展示了 e-Llama 模型：80 億和 700 億個參數的大型語言模型，針對電子商務領域進行了調整。這些模型被視為基礎模型，對電子商務有深入的了解，並作為指導和微調的基礎。e-Llama 模型是透過持續對 Llama 3.1 基礎模型進行預訓練，使用 1 兆個特定領域資料的代幣來取得。
我們討論了我們的做法，並透過一系列消融研究說明我們選擇超參數的動機。為了量化模型對電子商務領域的適應程度，我們定義並實作了一組多語言、特定於電子商務的評估任務。
我們展示了，在仔細選擇訓練設定時，Llama 3.1 模型可以適應新領域，而不會犧牲一般領域任務的顯著效能。我們也探索了合併已適應的模型和基礎模型的可能性，以更好地控制領域間的效能取捨。

##### **Practical Continual Forgetting for Pre-trained Vision Models**
2501.09705v1 by Hongbo Zhao, Fei Zhu, Bolin Ni, Feng Zhu, Gaofeng Meng, Zhaoxiang Zhang

For privacy and security concerns, the need to erase unwanted information
from pre-trained vision models is becoming evident nowadays. In real-world
scenarios, erasure requests originate at any time from both users and model
owners, and these requests usually form a sequence. Therefore, under such a
setting, selective information is expected to be continuously removed from a
pre-trained model while maintaining the rest. We define this problem as
continual forgetting and identify three key challenges. (i) For unwanted
knowledge, efficient and effective deleting is crucial. (ii) For remaining
knowledge, the impact brought by the forgetting procedure should be minimal.
(iii) In real-world scenarios, the training samples may be scarce or partially
missing during the process of forgetting. To address them, we first propose
Group Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA
modules to fine-tune the FFN layers in Transformer blocks for each forgetting
task independently, and towards (ii), a simple group sparse regularization is
adopted, enabling automatic selection of specific LoRA groups and zeroing out
the others. To further extend GS-LoRA to more practical scenarios, we
incorporate prototype information as additional supervision and introduce a
more practical approach, GS-LoRA++. For each forgotten class, we move the
logits away from its original prototype. For the remaining classes, we pull the
logits closer to their respective prototypes. We conduct extensive experiments
on face recognition, object detection and image classification and demonstrate
that our method manages to forget specific classes with minimal impact on other
classes. Codes have been released on https://github.com/bjzhb666/GS-LoRA.

摘要：<paragraph>由於隱私和安全性考量，如今清除預訓練視覺模型中不需要的資訊的需求已變得明顯。在真實世界的場景中，清除請求隨時來自使用者和模型所有者，而且這些請求通常會形成一個序列。因此，在這樣的設定下，預期會持續從預訓練模型中移除選擇性資訊，同時保留其餘部分。我們將這個問題定義為持續遺忘，並找出三個關鍵挑戰。(i) 對於不需要的知識，有效率且有效的刪除至關重要。(ii) 對於保留的知識，遺忘程序帶來的影響應降到最低。(iii) 在真實世界的場景中，訓練樣本在遺忘過程中可能稀少或部分遺失。為了解決這些問題，我們首先提出群組稀疏 LoRA (GS-LoRA)。具體來說，針對 (i)，我們導入 LoRA 模組，以針對每個遺忘任務獨立微調 Transformer 區塊中的 FFN 層，而針對 (ii)，採用簡單的群組稀疏正則化，能夠自動選擇特定 LoRA 群組並將其他群組歸零。為了進一步將 GS-LoRA 延伸到更實際的場景，我們將原型資訊納入作為額外的監督，並導入更實用的方法，GS-LoRA++。對於每個被遺忘的類別，我們將 logit 遠離其原始原型。對於其餘類別，我們將 logit 拉近它們各自的原型。我們對人臉辨識、物件偵測和影像分類進行廣泛的實驗，並展示我們的模型設法遺忘特定類別，同時對其他類別的影響降到最低。程式碼已在 https://github.com/bjzhb666/GS-LoRA 上發布。</paragraph>

##### **Cueless EEG imagined speech for subject identification: dataset and benchmarks**
2501.09700v1 by Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee

Electroencephalogram (EEG) signals have emerged as a promising modality for
biometric identification. While previous studies have explored the use of
imagined speech with semantically meaningful words for subject identification,
most have relied on additional visual or auditory cues. In this study, we
introduce a cueless EEG-based imagined speech paradigm, where subjects imagine
the pronunciation of semantically meaningful words without any external cues.
This innovative approach addresses the limitations of prior methods by
requiring subjects to select and imagine words from a predefined list
naturally. The dataset comprises over 4,350 trials from 11 subjects across five
sessions. We assess a variety of classification methods, including traditional
machine learning techniques such as Support Vector Machines (SVM) and XGBoost,
as well as time-series foundation models and deep learning architectures
specifically designed for EEG classification, such as EEG Conformer and Shallow
ConvNet. A session-based hold-out validation strategy was employed to ensure
reliable evaluation and prevent data leakage. Our results demonstrate
outstanding classification accuracy, reaching 97.93%. These findings highlight
the potential of cueless EEG paradigms for secure and reliable subject
identification in real-world applications, such as brain-computer interfaces
(BCIs).

摘要：腦電圖 (EEG) 信號已成為生物識別中極具潛力的方式。雖然先前的研究已探討在主題識別中使用具有語義意義字詞的想像語言，但大多依賴額外的視覺或聽覺提示。在本研究中，我們引進一種無提示的 EEG 基於想像語言的範例，受試者在沒有任何外部提示的情況下想像有語義意義字詞的發音。這種創新方法透過要求受試者自然地從預先定義的清單中選擇和想像字詞，來解決先前方法的限制。該資料集包含來自 11 位受試者在五個階段中超過 4,350 次的試驗。我們評估了各種分類方法，包括傳統機器學習技術，例如支援向量機 (SVM) 和 XGBoost，以及專門設計用於 EEG 分類的時間序列基礎模型和深度學習架構，例如 EEG Conformer 和淺層 ConvNet。採用基於階段的保留驗證策略，以確保可靠的評估並防止資料外洩。我們的結果證明了出色的分類準確度，達到 97.93%。這些發現突顯了無提示 EEG 範例在實際應用中安全且可靠的主題識別潛力，例如腦電腦介面 (BCI)。

##### **Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models**
2501.09686v1 by Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, Chenyang Shao, Yuwei Yan, Qinglong Yang, Yiwen Song, Sijian Ren, Xinyuan Hu, Yu Li, Jie Feng, Chen Gao, Yong Li

Language has long been conceived as an essential tool for human reasoning.
The breakthrough of Large Language Models (LLMs) has sparked significant
research interest in leveraging these models to tackle complex reasoning tasks.
Researchers have moved beyond simple autoregressive token generation by
introducing the concept of "thought" -- a sequence of tokens representing
intermediate steps in the reasoning process. This innovative paradigm enables
LLMs' to mimic complex human reasoning processes, such as tree search and
reflective thinking. Recently, an emerging trend of learning to reason has
applied reinforcement learning (RL) to train LLMs to master reasoning
processes. This approach enables the automatic generation of high-quality
reasoning trajectories through trial-and-error search algorithms, significantly
expanding LLMs' reasoning capacity by providing substantially more training
data. Furthermore, recent studies demonstrate that encouraging LLMs to "think"
with more tokens during test-time inference can further significantly boost
reasoning accuracy. Therefore, the train-time and test-time scaling combined to
show a new research frontier -- a path toward Large Reasoning Model. The
introduction of OpenAI's o1 series marks a significant milestone in this
research direction. In this survey, we present a comprehensive review of recent
progress in LLM reasoning. We begin by introducing the foundational background
of LLMs and then explore the key technical components driving the development
of large reasoning models, with a focus on automated data construction,
learning-to-reason techniques, and test-time scaling. We also analyze popular
open-source projects at building large reasoning models, and conclude with open
challenges and future research directions.

摘要：<paragraph>語言一直被認為是人類推理的必要工具。
大型語言模型 (LLM) 的突破引起了顯著的研究興趣，以利用這些模型來解決複雜的推理任務。
研究人員已經超越了簡單的自動回歸符號生成，引入了「思考」的概念——一個代表推理過程中中間步驟的符號序列。這種創新的範式使 LLM 能夠模擬複雜的人類推理過程，例如樹狀搜索和反思性思考。最近，一種學習推理的新趨勢將強化學習 (RL) 應用於訓練 LLM 以掌握推理過程。這種方法能夠通過試錯搜索演算法自動生成高品質的推理軌跡，通過提供更多訓練資料顯著擴展 LLM 的推理能力。此外，最近的研究表明，鼓勵 LLM 在測試時推理時使用更多符號可以進一步顯著提高推理準確度。因此，訓練時間和測試時間的擴展結合起來展示了一個新的研究前沿——通往大型推理模型的道路。 OpenAI 的 o1 系列的推出標誌著這個研究方向的一個重要里程碑。在本次調查中，我們對 LLM 推理的最新進展進行了全面回顧。我們首先介紹 LLM 的基礎背景，然後探討推動大型推理模型發展的主要技術組成部分，重點關注自動化資料建構、學習推理技術和測試時擴展。我們還分析了構建大型推理模型的流行開源專案，並以開放的挑戰和未來的研究方向作為結論。</paragraph>

##### **Reward-Guided Controlled Generation for Inference-Time Alignment in Diffusion Models: Tutorial and Review**
2501.09685v1 by Masatoshi Uehara, Yulai Zhao, Chenyu Wang, Xiner Li, Aviv Regev, Sergey Levine, Tommaso Biancalani

This tutorial provides an in-depth guide on inference-time guidance and
alignment methods for optimizing downstream reward functions in diffusion
models. While diffusion models are renowned for their generative modeling
capabilities, practical applications in fields such as biology often require
sample generation that maximizes specific metrics (e.g., stability, affinity in
proteins, closeness to target structures). In these scenarios, diffusion models
can be adapted not only to generate realistic samples but also to explicitly
maximize desired measures at inference time without fine-tuning. This tutorial
explores the foundational aspects of such inference-time algorithms. We review
these methods from a unified perspective, demonstrating that current techniques
-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,
and classifier guidance -- aim to approximate soft optimal denoising processes
(a.k.a. policies in RL) that combine pre-trained denoising processes with value
functions serving as look-ahead functions that predict from intermediate states
to terminal rewards. Within this framework, we present several novel algorithms
not yet covered in the literature. Furthermore, we discuss (1) fine-tuning
methods combined with inference-time techniques, (2) inference-time algorithms
based on search algorithms such as Monte Carlo tree search, which have received
limited attention in current research, and (3) connections between
inference-time algorithms in language models and diffusion models. The code of
this tutorial on protein design is available at
https://github.com/masa-ue/AlignInversePro

摘要：本教程提供了一個關於推論時間指導和對齊方法的深入指南，用於最佳化擴散模型中的下游獎勵函數。儘管擴散模型以其生成模型的能力而聞名，但生物學等領域的實際應用通常需要最大化特定指標（例如穩定性、蛋白質中的親和力、接近目標結構）的樣本生成。在這些場景中，擴散模型不僅可以適應生成真實的樣本，還可以明確最大化推論時間中的所需測量，而無需進行微調。本教程探討了此類推論時間演算法的基本方面。我們從統一的角度回顧了這些方法，證明了當前的技術——例如基於序貫蒙地卡羅 (SMC) 的指導、基於價值的抽樣和分類器指導——旨在近似軟最佳去噪程序（又稱 RL 中的策略），該程序將預訓練的去噪程序與作為預測從中間狀態到終端獎勵的超前函數的值函數相結合。在此框架內，我們提出了幾種文獻中尚未涵蓋的新穎演算法。此外，我們討論了 (1) 與推論時間技術相結合的微調方法，(2) 基於搜尋演算法（例如蒙地卡羅樹搜尋）的推論時間演算法，這些演算法在當前研究中受到的關注有限，以及 (3) 語言模型和擴散模型中推論時間演算法之間的關聯。本蛋白質設計教程的程式碼可在 https://github.com/masa-ue/AlignInversePro 獲得

##### **Authenticated Delegation and Authorized AI Agents**
2501.09674v1 by Tobin South, Samuele Marro, Thomas Hardjono, Robert Mahari, Cedric Deslandes Whitney, Dazza Greenwood, Alan Chan, Alex Pentland

The rapid deployment of autonomous AI agents creates urgent challenges around
authorization, accountability, and access control in digital spaces. New
standards are needed to know whom AI agents act on behalf of and guide their
use appropriately, protecting online spaces while unlocking the value of task
delegation to autonomous agents. We introduce a novel framework for
authenticated, authorized, and auditable delegation of authority to AI agents,
where human users can securely delegate and restrict the permissions and scope
of agents while maintaining clear chains of accountability. This framework
builds on existing identification and access management protocols, extending
OAuth 2.0 and OpenID Connect with agent-specific credentials and metadata,
maintaining compatibility with established authentication and web
infrastructure. Further, we propose a framework for translating flexible,
natural language permissions into auditable access control configurations,
enabling robust scoping of AI agent capabilities across diverse interaction
modalities. Taken together, this practical approach facilitates immediate
deployment of AI agents while addressing key security and accountability
concerns, working toward ensuring agentic AI systems perform only appropriate
actions and providing a tool for digital service providers to enable AI agent
interactions without risking harm from scalable interaction.

摘要：自主 AI 代理的快速部署在數位空間中創造了有關授權、問責制和存取控制的迫切挑戰。需要新的標準來了解 AI 代理代表誰行事並適當地指導其使用，在保護線上空間的同時，釋放將任務委派給自主代理的價值。我們引進了一個創新的架構，用於對 AI 代理進行經過驗證、授權和可稽核的權限委派，其中人類使用者可以在維持明確的問責鏈的同時，安全地委派和限制代理的權限和範圍。此架構建立在現有的識別和存取管理協定上，並使用特定於代理的憑證和元資料來延伸 OAuth 2.0 和 OpenID Connect，同時與既定的驗證和網路基礎架構保持相容性。此外，我們提出一個架構，用於將彈性的自然語言權限轉換為可稽核的存取控制設定，讓 AI 代理功能能夠在各種互動方式中進行穩健的範圍設定。綜合來說，這種實務方法促進了 AI 代理的立即部署，同時解決了主要的安全性與問責問題，朝著確保代理式 AI 系統僅執行適當的動作，並提供數位服務供應商一個工具來啟用 AI 代理互動，而不會冒可擴充互動的風險邁進。

##### **Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark**
2501.09672v1 by Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony, Edwin Fennell, Irina Rish

The proliferation of Vision-Language Models (VLMs) in the past several years
calls for rigorous and comprehensive evaluation methods and benchmarks. This
work analyzes existing VLM evaluation techniques, including automated metrics,
AI-based assessments, and human evaluations across diverse tasks. We first
introduce Robin - a novel suite of VLMs that we built by combining Large
Language Models (LLMs) and Vision Encoders (VEs) at multiple scales, and use
Robin to identify shortcomings of current evaluation approaches across scales.
Next, to overcome the identified limitations, we introduce CHIRP - a new long
form response benchmark we developed for more robust and complete VLM
evaluation. We provide open access to the Robin training code, model suite, and
CHIRP benchmark to promote reproducibility and advance VLM research.

摘要：在過去幾年中，視覺語言模型 (VLM) 的激增
需要嚴謹且全面的評估方法和基準。這
項工作分析了現有的 VLM 評估技術，包括自動化指標、
基於 AI 的評估和跨不同任務的人類評估。我們首先
介紹 Robin - 我們通過結合大語言模型 (LLM) 和視覺編碼器 (VE) 在多個規模上構建的一組新穎的 VLM，並使用
Robin 來識別當前評估方法在不同規模上的缺點。
接下來，為了克服已識別的限制，我們引入了 CHIRP - 一個新的長
格式回應基準，我們為更健壯且完整的 VLM
評估而開發。我們提供對 Robin 訓練代碼、模型套件和
CHIRP 基準的開放訪問，以促進可複製性和推進 VLM 研究。

##### **The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models**
2501.09653v1 by Jonathan Katzy, Razvan Mihai Popescu, Arie van Deursen, Maliheh Izadi

The recent rise in the popularity of large language models has spurred the
development of extensive code datasets needed to train them. This has left
limited code available for collection and use in the downstream investigation
of specific behaviors, or evaluation of large language models without suffering
from data contamination. To address this problem, we release The Heap, a large
multilingual dataset covering 57 programming languages that has been
deduplicated with respect to other open datasets of code, enabling researchers
to conduct fair evaluations of large language models without significant data
cleaning overhead.

摘要：近期大型语言模型的普及促进了大量代码数据集的开发，这些数据集用于训练这些模型。这导致可供收集和用于下游特定行为调查的代码有限，或者在不遭受数据污染的情况下评估大型语言模型。为了解决这个问题，我们发布了 The Heap，这是一个包含 57 种编程语言的大型多语言数据集，该数据集已针对其他开放代码数据集进行去重，使研究人员能够在没有大量数据清理开销的情况下对大型语言模型进行公平评估。

##### **Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments**
2501.09649v1 by Lorenzo Bonanni, Daniele Meli, Alberto Castellini, Alessandro Farinelli

Online motion planning is a challenging problem for intelligent robots moving
in dense environments with dynamic obstacles, e.g., crowds. In this work, we
propose a novel approach for optimal and safe online motion planning with
minimal information about dynamic obstacles. Specifically, our approach
requires only the current position of the obstacles and their maximum speed,
but it does not need any information about their exact trajectories or dynamic
model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for
online optimal planning via model simulations, with Velocity Obstacles (VO),
for obstacle avoidance. We perform experiments in a cluttered simulated
environment with walls, and up to 40 dynamic obstacles moving with random
velocities and directions. With an ablation study, we show the key contribution
of VO in scaling up the efficiency of MCTS, selecting the safest and most
rewarding actions in the tree of simulations. Moreover, we show the superiority
of our methodology with respect to state-of-the-art planners, including
Non-linear Model Predictive Control (NMPC), in terms of improved collision
rate, computational and task performance.

摘要：線上運動規劃對於在充滿動態障礙物（例如人群）的密集環境中移動的智慧型機器人來說是一個具有挑戰性的問題。在這項工作中，我們提出了一個新的方法，用於在對動態障礙物知之甚少的情況下進行最佳且安全的線上運動規劃。具體來說，我們的做法僅需要障礙物的當前位置及其最大速度，但不需要任何有關其確切軌跡或動態模型的資訊。所提出的方法結合了蒙地卡羅樹狀搜尋（MCTS），用於透過模型模擬進行線上最佳規劃，以及速度障礙（VO），用於避免障礙物。我們在一個雜亂的模擬環境中進行實驗，其中有牆壁，以及多達 40 個以隨機速度和方向移動的動態障礙物。透過消融研究，我們展示了 VO 在擴充 MCTS 效率方面的關鍵貢獻，在模擬樹中選擇最安全且最有回報的動作。此外，我們展示了我們的方法優於最先進的規劃器，包括非線性模型預測控制（NMPC），在降低碰撞率、運算和任務執行效能方面表現優異。

##### **NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes**
2501.09646v1 by Nathaniel S. Keplinger, Baiting Luo, Iliyas Bektas, Yunuo Zhang, Kyle Hollins Wray, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay

In many real-world applications, agents must make sequential decisions in
environments where conditions are subject to change due to various exogenous
factors. These non-stationary environments pose significant challenges to
traditional decision-making models, which typically assume stationary dynamics.
Non-stationary Markov decision processes (NS-MDPs) offer a framework to model
and solve decision problems under such changing conditions. However, the lack
of standardized benchmarks and simulation tools has hindered systematic
evaluation and advance in this field. We present NS-Gym, the first simulation
toolkit designed explicitly for NS-MDPs, integrated within the popular
Gymnasium framework. In NS-Gym, we segregate the evolution of the environmental
parameters that characterize non-stationarity from the agent's decision-making
module, allowing for modular and flexible adaptations to dynamic environments.
We review prior work in this domain and present a toolkit encapsulating key
problem characteristics and types in NS-MDPs. This toolkit is the first effort
to develop a set of standardized interfaces and benchmark problems to enable
consistent and reproducible evaluation of algorithms under non-stationary
conditions. We also benchmark six algorithmic approaches from prior work on
NS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to
assess the adaptability and robustness of their decision-making algorithms to
non-stationary conditions.

摘要：在許多真實世界的應用中，代理人必須在環境中做出順序決策，而環境中的條件可能會因各種外生因素而改變。這些非平穩環境對傳統決策制定模型構成重大挑戰，這些模型通常假設平穩動態。非平穩馬可夫決策過程 (NS-MDP) 提供了一個框架，可以在這種變化的條件下對決策問題進行建模和求解。然而，缺乏標準化基準和模擬工具阻礙了系統評估和這一領域的進步。我們展示了 NS-Gym，這是第一個專門為 NS-MDP 設計的模擬工具包，並整合到了流行的 Gymnasium 框架中。在 NS-Gym 中，我們將表徵非平穩性的環境參數的演變與代理人的決策制定模組分開，允許對動態環境進行模組化和靈活的適應。我們回顧了這個領域的先前工作，並展示了一個工具包，其中封裝了 NS-MDP 中的關鍵問題特徵和類型。這個工具包是制定標準化介面和基準問題的第一個努力，以便在非平穩條件下對演算法進行一致且可重現的評估。我們還使用 NS-Gym 對 NS-MDP 中先前工作的六種演算法方法進行基準測試。我們的願景是 NS-Gym 將使研究人員能夠評估其決策制定演算法對非平穩條件的適應性和穩健性。

##### **CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding**
2501.09645v1 by Johannes Kirmayr, Lukas Stappen, Phillip Schneider, Florian Matthes, Elisabeth André

In today's assistant landscape, personalisation enhances interactions,
fosters long-term relationships, and deepens engagement. However, many systems
struggle with retaining user preferences, leading to repetitive user requests
and disengagement. Furthermore, the unregulated and opaque extraction of user
preferences in industry applications raises significant concerns about privacy
and trust, especially in regions with stringent regulations like Europe. In
response to these challenges, we propose a long-term memory system for voice
assistants, structured around predefined categories. This approach leverages
Large Language Models to efficiently extract, store, and retrieve preferences
within these categories, ensuring both personalisation and transparency. We
also introduce a synthetic multi-turn, multi-session conversation dataset
(CarMem), grounded in real industry data, tailored to an in-car voice assistant
setting. Benchmarked on the dataset, our system achieves an F1-score of .78 to
.95 in preference extraction, depending on category granularity. Our
maintenance strategy reduces redundant preferences by 95% and contradictory
ones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,
the results demonstrate the system's suitability for industrial applications.

摘要：在現今的助理領域中，個人化增強互動，促進長期關係，並加深參與。然而，許多系統在保留使用者偏好上遇到困難，導致重複的使用者要求和脫離。此外，產業應用中對使用者偏好的不受規範且不透明的提取引發了對隱私和信任的重大疑慮，特別是在像歐洲這樣法規嚴格的地區。為了應對這些挑戰，我們為語音助理提出了一個長期記憶系統，其結構圍繞預定義的類別。這種方法利用大型語言模型在這些類別中有效提取、儲存和檢索偏好，確保個人化和透明度。我們還引入了一個合成多輪、多會話對話資料集 (CarMem)，其基礎是真實的產業資料，專門用於車載語音助理設定。在資料集上進行基準測試後，我們的系統在偏好提取中取得了 .78 到 .95 的 F1 分數，具體取決於類別粒度。我們的維護策略將重複的偏好減少了 95%，將矛盾的偏好減少了 92%，而最佳檢索的準確度為 .87。總的來說，這些結果證明了該系統適用於產業應用。

##### **Electronic Health Records: Towards Digital Twins in Healthcare**
2501.09640v1 by Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni

The pivotal shift from traditional paper-based records to sophisticated
Electronic Health Records (EHR), enabled systematic collection and analysis of
patient data through descriptive statistics, providing insight into patterns
and trends across patient populations. This evolution continued toward
predictive analytics, allowing healthcare providers to anticipate patient
outcomes and potential complications before they occur. This progression from
basic digital record-keeping to sophisticated predictive modelling and digital
twins reflects healthcare's broader evolution toward more integrated,
patient-centred approaches that combine data-driven insights with personalized
care delivery. This chapter explores the evolution and significance of
healthcare information systems, beginning with an examination of the
implementation of EHR in the UK and the USA. It provides a comprehensive
overview of the International Classification of Diseases (ICD) system, tracing
its development from ICD-9 to ICD-10. Central to this discussion is the
MIMIC-III database, a landmark achievement in healthcare data sharing and
arguably the most comprehensive critical care database freely available to
researchers worldwide. MIMIC-III has democratized access to high-quality
healthcare data, enabling unprecedented opportunities for research and
analysis. The chapter examines its structure, clinical outcome analysis
capabilities, and practical applications through case studies, with a
particular focus on mortality and length of stay metrics, vital signs
extraction, and ICD coding. Through detailed entity-relationship diagrams and
practical examples, the text illustrates MIMIC's complex data structure and
demonstrates how different querying approaches can lead to subtly different
results, emphasizing the critical importance of understanding the database's
architecture for accurate data extraction.

摘要：從傳統紙本記錄轉變為先進的電子健康記錄（EHR），促使透過描述性統計系統性地收集和分析病患資料，進而深入了解病患族群的模式和趨勢。這項演進持續朝向預測分析發展，讓醫療保健提供者能夠在病患出現結果和潛在併發症之前預測這些狀況。從基本的數位記錄保存進展到先進的預測模型和數位雙胞胎，反映了醫療保健朝向更整合、以病患為中心的做法所做的更廣泛演進，這些做法結合了資料驅動的見解與個人化照護服務。本章探討醫療保健資訊系統的演進和重要性，從審查英國和美國實施 EHR 開始。它提供了疾病國際分類（ICD）系統的全面概述，追溯其從 ICD-9 發展到 ICD-10 的過程。此討論的核心是 MIMIC-III 資料庫，這是醫療保健資料共享的一項里程碑式成就，可以說是全球研究人員可以免費取得的最全面的重症照護資料庫。MIMIC-III 民主化了對高品質醫療保健資料的存取，為研究和分析創造了前所未有的機會。本章透過案例研究探討其結構、臨床結果分析能力和實際應用，特別關注死亡率和住院時間指標、生命徵象萃取和 ICD 編碼。透過詳細的實體關係圖和實務範例，本文說明了 MIMIC 複雜的資料結構，並展示了不同的查詢方法如何導致細微不同的結果，強調了了解資料庫架構對於準確萃取資料至關重要的重要性。

##### **Platform-Aware Mission Planning**
2501.09632v1 by Stefan Panjkovic, Alessandro Cimatti, Andrea Micheli, Stefano Tonetta

Planning for autonomous systems typically requires reasoning with models at
different levels of abstraction, and the harmonization of two competing sets of
objectives: high-level mission goals that refer to an interaction of the system
with the external environment, and low-level platform constraints that aim to
preserve the integrity and the correct interaction of the subsystems. The
complicated interplay between these two models makes it very hard to reason on
the system as a whole, especially when the objective is to find plans with
robustness guarantees, considering the non-deterministic behavior of the lower
layers of the system.
  In this paper, we introduce the problem of Platform-Aware Mission Planning
(PAMP), addressing it in the setting of temporal durative actions. The PAMP
problem differs from standard temporal planning for its exists-forall nature:
the high-level plan dealing with mission goals is required to satisfy safety
and executability constraints, for all the possible non-deterministic
executions of the low-level model of the platform and the environment. We
propose two approaches for solving PAMP. The first baseline approach
amalgamates the mission and platform levels, while the second is based on an
abstraction-refinement loop that leverages the combination of a planner and a
verification engine. We prove the soundness and completeness of the proposed
approaches and validate them experimentally, demonstrating the importance of
heterogeneous modeling and the superiority of the technique based on
abstraction-refinement.

摘要：<paragraph>規劃自主系統通常需要使用不同抽象層級的模型進行推理，以及調和兩組相互競爭的目標：指的是系統與外部環境互動的高層級任務目標，以及旨在保留子系統的完整性和正確互動的低層級平台約束。這兩種模型之間複雜的交互作用使得很難對系統整體進行推理，特別是在目標是找出具有穩健性保證的計畫時，考慮到系統較低層級的非確定性行為。
在本論文中，我們介紹了平台感知任務規劃 (PAMP) 的問題，並在時間持續動作的設定中加以解決。PAMP 問題與標準時間規劃不同，在於其存在forall性質：處理任務目標的高層級計畫必須滿足所有平台和環境的低層級模型可能非確定性執行的情況下的安全性和可執行性約束。我們提出了兩種解決 PAMP 的方法。第一種基線方法合併任務和平台層級，而第二種方法基於一個抽象精煉迴圈，該迴圈利用規劃器和驗證引擎的組合。我們證明了所提出的方法的健全性和完整性，並透過實驗驗證它們，證明了異質建模的重要性以及基於抽象精煉的技術的優越性。</paragraph>

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

摘要：隨著人工智慧 (AI) 在醫療保健中的應用日益普及，本章探討了開發可靠且符合道德標準的臨床決策支援系統 (CDSS) 的關鍵面向。從傳統統計模型到複雜機器學習方法的基本轉變開始，這項工作審查了嚴謹的驗證策略和效能評估方法，包括模型校準和決策曲線分析的關鍵角色。本章強調，在醫療保健中建立值得信賴的 AI 系統不只是技術上的準確性；它需要仔細考量公平性、可解釋性和隱私權。本章強調了透過 AI 確保公平的醫療保健服務的挑戰，並討論了識別和減輕臨床預測模型中偏差的方法。接著，本章深入探討可解釋性，作為以人為中心的 CDSS 的基石。這種關注反映了醫療保健專業人員不僅必須信任 AI 建議，還必須理解其背後的推理。討論進一步分析了醫療 AI 系統中的隱私漏洞，從深度學習模型中的資料外洩到針對模型解釋的複雜攻擊。本文探討了隱私保護策略，例如差分隱私和聯合學習，同時承認隱私保護和模型效能之間的固有取捨。這種從技術驗證到道德考量的進展，反映了開發 AI 系統的多面向挑戰，這些系統可以無縫且可靠地整合到日常臨床實務中，同時維持最高的病患照護和資料保護標準。

##### **Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment**
2501.09620v1 by Chaoqi Wang, Zhuokai Zhao, Yibo Jiang, Zhaorun Chen, Chen Zhu, Yuxin Chen, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Hao Ma, Sinong Wang

Recent advances in large language models (LLMs) have demonstrated significant
progress in performing complex tasks. While Reinforcement Learning from Human
Feedback (RLHF) has been effective in aligning LLMs with human preferences, it
is susceptible to spurious correlations in reward modeling. Consequently, it
often introduces biases-such as length bias, sycophancy, conceptual bias, and
discrimination that hinder the model's ability to capture true causal
relationships. To address this, we propose a novel causal reward modeling
approach that integrates causal inference to mitigate these spurious
correlations. Our method enforces counterfactual invariance, ensuring reward
predictions remain consistent when irrelevant variables are altered. Through
experiments on both synthetic and real-world datasets, we show that our
approach mitigates various types of spurious correlations effectively,
resulting in more reliable and fair alignment of LLMs with human preferences.
As a drop-in enhancement to the existing RLHF workflow, our causal reward
modeling provides a practical way to improve the trustworthiness and fairness
of LLM finetuning.

摘要：大型語言模型 (LLM) 的最新進展已證明在執行複雜任務方面取得顯著進展。雖然人類回饋強化學習 (RLHF) 已有效地將 LLM 與人類偏好保持一致，但它容易受到獎勵建模中的虛假相關性影響。因此，它常常會引入偏差，例如長度偏差、阿諛奉承、概念偏差和歧視，這些偏差會阻礙模型捕捉真實因果關係的能力。為了解決這個問題，我們提出了一種新穎的因果獎勵建模方法，它整合了因果推理來減輕這些虛假相關性。我們的模型強制執行反事實不變性，確保在改變無關變數時獎勵預測保持一致。透過在合成和真實世界資料集上進行實驗，我們證明了我們的模型有效減輕了各種類型的虛假相關性，從而更可靠、更公平地將 LLM 與人類偏好保持一致。作為對現有 RLHF 工作流程的直接增強，我們的因果獎勵建模提供了一種實用的方法來提升 LLM 微調的可信度和公平性。

##### **Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning**
2501.09608v1 by Donghuo Zeng, Kazushi Ikeda

Metric learning projects samples into an embedded space, where similarities
and dissimilarities are quantified based on their learned representations.
However, existing methods often rely on label-guided representation learning,
where representations of different modalities, such as audio and visual data,
are aligned based on annotated labels. This approach tends to underutilize
latent complex features and potential relationships inherent in the
distributions of audio and visual data that are not directly tied to the
labels, resulting in suboptimal performance in audio-visual embedding learning.
To address this issue, we propose a novel architecture that integrates
cross-modal triplet loss with progressive self-distillation. Our method
enhances representation learning by leveraging inherent distributions and
dynamically refining soft audio-visual alignments -- probabilistic alignments
between audio and visual data that capture the inherent relationships beyond
explicit labels. Specifically, the model distills audio-visual
distribution-based knowledge from annotated labels in a subset of each batch.
This self-distilled knowledge is used t

摘要：度量学习项目样本到一个嵌入空间中，其中相似性和相异性基于学习到的表示进行量化。
然而，现有方法通常依赖于标签指导表示学习，其中不同模态（如音频和视觉数据）的表示基于注释标签对齐。这种方法往往低估了潜在的复杂特征和音频和视觉数据分布中固有的潜在关系，这些关系与标签没有直接联系，导致音频视觉嵌入学习的性能不佳。
为了解决这个问题，我们提出了一种新的架构，它将跨模态三元损失与渐进式自蒸馏相结合。我们的方法通过利用固有分布和动态细化软音频视觉对齐来增强表示学习——音频和视觉数据之间的概率对齐，捕获了超出显式标签的固有关系。具体来说，该模型从每个批次的一个子集中的注释标签中提取基于音频视觉分布的知识。这种自蒸馏知识用于 t

##### **From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs**
2501.09604v1 by Hrithik Majumdar Shibu, Shrestha Datta, Md. Sumon Miah, Nasrullah Sami, Mahruba Sharmin Chowdhury, Md. Saiful Islam

The rapid spread of fake news presents a significant global challenge,
particularly in low-resource languages like Bangla, which lack adequate
datasets and detection tools. Although manual fact-checking is accurate, it is
expensive and slow to prevent the dissemination of fake news. Addressing this
gap, we introduce BanFakeNews-2.0, a robust dataset to enhance Bangla fake news
detection. This version includes 11,700 additional, meticulously curated fake
news articles validated from credible sources, creating a proportional dataset
of 47,000 authentic and 13,000 fake news items across 13 categories. In
addition, we created a manually curated independent test set of 460 fake and
540 authentic news items for rigorous evaluation. We invest efforts in
collecting fake news from credible sources and manually verified while
preserving the linguistic richness. We develop a benchmark system utilizing
transformer-based architectures, including fine-tuned Bidirectional Encoder
Representations from Transformers variants (F1-87\%) and Large Language Models
with Quantized Low-Rank Approximation (F1-89\%), that significantly outperforms
traditional methods. BanFakeNews-2.0 offers a valuable resource to advance
research and application in fake news detection for low-resourced languages. We
publicly release our dataset and model on Github to foster research in this
direction.

摘要：假新聞快速散播已成為全球性的重大挑戰，特別是在孟加拉語等資源貧乏的語言中，因為缺乏適當的資料集和偵測工具。儘管手動查證事實非常準確，但它昂貴且緩慢，無法有效防止假新聞散播。為了解決這個問題，我們推出了 BanFakeNews-2.0，一個強大的資料集，用於增強孟加拉語假新聞偵測。此版本包含 11,700 篇經過精心策劃的額外假新聞文章，並從可信來源驗證，建立了一個包含 13 個類別的 47,000 篇真實新聞和 13,000 篇假新聞的比例資料集。此外，我們還建立了一個手動策劃的獨立測試集，包含 460 篇假新聞和 540 篇真實新聞，用於嚴格評估。我們投入大量心力從可信來源收集假新聞，並在保留語言豐富性的同時進行手動驗證。我們開發了一個基準系統，利用基於Transformer的架構，包括微調的 Transformer 編碼器表示（F1-87%）和具有量化低秩近似的語言模型（F1-89%），其效能顯著優於傳統方法。BanFakeNews-2.0 為低資源語言的假新聞偵測研究和應用提供了寶貴的資源。我們在 Github 上公開發布我們的資料集和模型，以促進這方面的研究。

##### **Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining**
2501.09597v1 by Nathan Vaska, Justin Goodwin, Robin Walters, Rajmonda S. Caceres

Meshes are used to represent complex objects in high fidelity physics
simulators across a variety of domains, such as radar sensing and aerodynamics.
There is growing interest in using neural networks to accelerate physics
simulations, and also a growing body of work on applying neural networks
directly to irregular mesh data. Since multiple mesh topologies can represent
the same object, mesh augmentation is typically required to handle topological
variation when training neural networks. Due to the sensitivity of physics
simulators to small changes in mesh shape, it is challenging to use these
augmentations when training neural network-based physics simulators. In this
work, we show that variations in mesh topology can significantly reduce the
performance of neural network simulators. We evaluate whether pretraining can
be used to address this issue, and find that employing an established
autoencoder pretraining technique with graph embedding models reduces the
sensitivity of neural network simulators to variations in mesh topology.
Finally, we highlight future research directions that may further reduce neural
simulator sensitivity to mesh topology.

摘要：網格用於在各種領域中以高保真物理模擬器表示複雜的物件，例如雷達感測和空氣動力學。
對於使用神經網路來加速物理模擬的興趣與日俱增，而且也越來越多關於將神經網路直接應用於不規則網格資料的研究。由於多個網格拓撲可以表示相同的物件，因此在訓練神經網路時通常需要網格擴充來處理拓撲變化。由於物理模擬器對網格形狀的微小變化很敏感，因此在訓練基於神經網路的物理模擬器時使用這些擴充很具有挑戰性。在這項工作中，我們展示了網格拓撲的變化會顯著降低神經網路模擬器的效能。我們評估了預訓練是否可用於解決此問題，並發現採用已建立的自動編碼器預訓練技術與圖形嵌入模型會降低神經網路模擬器對網格拓撲變化的敏感性。最後，我們重點說明了未來可能進一步降低神經模擬器對網格拓撲敏感性的研究方向。

##### **MatrixNet: Learning over symmetry groups using learned group representations**
2501.09571v1 by Lucas Laird, Circe Hsu, Asilata Bapat, Robin Walters

Group theory has been used in machine learning to provide a theoretically
grounded approach for incorporating known symmetry transformations in tasks
from robotics to protein modeling. In these applications, equivariant neural
networks use known symmetry groups with predefined representations to learn
over geometric input data. We propose MatrixNet, a neural network architecture
that learns matrix representations of group element inputs instead of using
predefined representations. MatrixNet achieves higher sample efficiency and
generalization over several standard baselines in prediction tasks over the
several finite groups and the Artin braid group. We also show that MatrixNet
respects group relations allowing generalization to group elements of greater
word length than in the training set.

摘要：群論已用於機器學習，以提供一個理論性的基礎方法，用於在從機器人技術到蛋白質建模的任務中納入已知的對稱轉換。在這些應用中，等變神經網路使用已知的對稱群和預定義的表示，以學習幾何輸入數據。我們提出 MatrixNet，這是一種神經網路架構，它學習群元素輸入的矩陣表示，而不是使用預定義的表示。MatrixNet 在預測任務中對幾個標準基準線實現了更高的樣本效率和概括，這些任務涉及幾個有限群和 Artin 編織群。我們還表明，MatrixNet 尊重群關係，允許對比訓練集中詞長更大的群元素進行概括。

##### **Stylomech: Unveiling Authorship via Computational Stylometry in English and Romanized Sinhala**
2501.09561v1 by Nabeelah Faumi, Adeepa Gunathilake, Benura Wickramanayake, Deelaka Dias, TGDK Sumanathilaka

With the advent of Web 2.0, the development in social technology coupled with
global communication systematically brought positive and negative impacts to
society. Copyright claims and Author identification are deemed crucial as there
has been a considerable amount of increase in content violation owing to the
lack of proper ethics in society. The Author's attribution in both English and
Romanized Sinhala became a major requirement in the last few decades. As an
area largely unexplored, particularly within the context of Romanized Sinhala,
the research contributes significantly to the field of computational
linguistics. The proposed author attribution system offers a unique approach,
allowing for the comparison of only two sets of text: suspect author and
anonymous text, a departure from traditional methodologies which often rely on
larger corpora. This work focuses on using the numerical representation of
various pairs of the same and different authors allowing for, the model to
train on these representations as opposed to text, this allows for it to apply
to a multitude of authors and contexts, given that the suspected author text,
and the anonymous text are of reasonable quality. By expanding the scope of
authorship attribution to encompass diverse linguistic contexts, the work
contributes to fostering trust and accountability in digital communication,
especially in Sri Lanka. This research presents a pioneering approach to author
attribution in both English and Romanized Sinhala, addressing a critical need
for content verification and intellectual property rights enforcement in the
digital age.

摘要：隨著 Web 2.0 的出現，社交技術的發展與全球溝通系統性地為社會帶來正面和負面的影響。由於社會缺乏適當的道德規範，版權聲明和作者身分識別被視為至關重要，因為內容侵權事件大幅增加。在過去幾十年，作者在英文和羅馬化僧伽羅語中的署名已成為一項重要要求。作為一個尚未廣泛探索的領域，特別是在羅馬化僧伽羅語的脈絡中，這項研究對計算語言學領域做出了重大貢獻。所提出的作者署名系統提供了一種獨特的方法，允許僅比較兩組文本：可疑作者和匿名文本，這與傳統方法不同，傳統方法通常依賴於更大的語料庫。這項工作專注於使用相同和不同作者的各種配對的數字表示，允許模型在這些表示上進行訓練，而不是文本，這允許它應用於大量作者和脈絡，假設可疑作者文本和匿名文本具有合理的品質。透過擴大作者署名的範圍，涵蓋不同的語言脈絡，這項工作有助於培養數位溝通中的信任和責任感，特別是在斯里蘭卡。這項研究提出了一種在英文和羅馬化僧伽羅語中進行作者署名的先驅方法，滿足了數位時代對內容驗證和智慧財產權執行的迫切需求。

##### **Text-driven Adaptation of Foundation Models for Few-shot Surgical Workflow Analysis**
2501.09555v1 by Tingxuan Chen, Kun Yuan, Vinkle Srivastav, Nassir Navab, Nicolas Padoy

Purpose: Surgical workflow analysis is crucial for improving surgical
efficiency and safety. However, previous studies rely heavily on large-scale
annotated datasets, posing challenges in cost, scalability, and reliance on
expert annotations. To address this, we propose Surg-FTDA (Few-shot Text-driven
Adaptation), designed to handle various surgical workflow analysis tasks with
minimal paired image-label data.
  Methods: Our approach has two key components. First, Few-shot selection-based
modality alignment selects a small subset of images and aligns their embeddings
with text embeddings from the downstream task, bridging the modality gap.
Second, Text-driven adaptation leverages only text data to train a decoder,
eliminating the need for paired image-text data. This decoder is then applied
to aligned image embeddings, enabling image-related tasks without explicit
image-text pairs.
  Results: We evaluate our approach to generative tasks (image captioning) and
discriminative tasks (triplet recognition and phase recognition). Results show
that Surg-FTDA outperforms baselines and generalizes well across downstream
tasks.
  Conclusion: We propose a text-driven adaptation approach that mitigates the
modality gap and handles multiple downstream tasks in surgical workflow
analysis, with minimal reliance on large annotated datasets. The code and
dataset will be released in https://github.com/TingxuanSix/Surg-FTDA.

摘要：<paragraph>目的：手術工作流程分析對於提升手術效率和安全性至關重要。然而，先前的研究極度依賴於大規模的標註資料集，在成本、可擴充性以及對專家標註的依賴性方面面臨挑戰。為了解決這個問題，我們提出了 Surg-FTDA（小樣本文字驅動適應），旨在處理各種手術工作流程分析任務，且只需要最少的成對影像標籤資料。
方法：我們的做法有兩個關鍵組成部分。首先，基於小樣本選擇的模態對齊選擇一小部分影像，並將它們的嵌入與下游任務的文字嵌入對齊，從而彌合模態差距。其次，文字驅動適應僅利用文字資料來訓練一個解碼器，消除了對成對影像文字資料的需求。然後將此解碼器應用於對齊的影像嵌入，在沒有明確影像文字對的情況下實現與影像相關的任務。
結果：我們評估了我們對生成任務（影像標題）和判別任務（三元組識別和階段識別）的方法。結果表明，Surg-FTDA 優於基準，並且在各種下游任務中具有良好的泛化能力。
結論：我們提出了一種文字驅動適應方法，它可以緩解模態差距，並在手術工作流程分析中處理多個下游任務，且最少依賴於大型標註資料集。程式碼和資料集將在 https://github.com/TingxuanSix/Surg-FTDA 發布。</paragraph>

##### **AI in Support of Diversity and Inclusion**
2501.09534v1 by Çiçek Güven, Afra Alishahi, Henry Brighton, Gonzalo Nápoles, Juan Sebastian Olier, Marie Šafář, Eric Postma, Dimitar Shterionov, Mirella De Sisto, Eva Vanmassenhove

In this paper, we elaborate on how AI can support diversity and inclusion and
exemplify research projects conducted in that direction. We start by looking at
the challenges and progress in making large language models (LLMs) more
transparent, inclusive, and aware of social biases. Even though LLMs like
ChatGPT have impressive abilities, they struggle to understand different
cultural contexts and engage in meaningful, human like conversations. A key
issue is that biases in language processing, especially in machine translation,
can reinforce inequality. Tackling these biases requires a multidisciplinary
approach to ensure AI promotes diversity, fairness, and inclusion. We also
highlight AI's role in identifying biased content in media, which is important
for improving representation. By detecting unequal portrayals of social groups,
AI can help challenge stereotypes and create more inclusive technologies.
Transparent AI algorithms, which clearly explain their decisions, are essential
for building trust and reducing bias in AI systems. We also stress AI systems
need diverse and inclusive training data. Projects like the Child Growth
Monitor show how using a wide range of data can help address real world
problems like malnutrition and poverty. We present a project that demonstrates
how AI can be applied to monitor the role of search engines in spreading
disinformation about the LGBTQ+ community. Moreover, we discuss the SignON
project as an example of how technology can bridge communication gaps between
hearing and deaf people, emphasizing the importance of collaboration and mutual
trust in developing inclusive AI. Overall, with this paper, we advocate for AI
systems that are not only effective but also socially responsible, promoting
fair and inclusive interactions between humans and machines.

摘要：<paragraph>在這篇論文中，我們詳細說明 AI 如何支持多元性和包容性，並舉例說明朝著這個方向進行的研究專案。我們首先探討讓大型語言模型 (LLM) 更透明、更具包容性，並意識到社會偏見的挑戰和進展。即使像 ChatGPT 這樣的 LLM 具有令人印象深刻的能力，但它們仍難以理解不同的文化背景，並進行有意義的、類似人類的對話。一個關鍵問題是語言處理中的偏見，特別是在機器翻譯中，可能會加劇不平等。要解決這些偏見，需要採取多學科的方法，以確保 AI 能促進多元性、公平性和包容性。我們也強調 AI 在識別媒體中帶有偏見的內容方面所扮演的角色，這對於改善代表性非常重要。透過偵測對社會群體的不平等描繪，AI 可以幫助挑戰刻板印象，並創造更具包容性的技術。透明的 AI 演算法會清楚解釋其決策，對於建立信任和減少 AI 系統中的偏見至關重要。我們也強調 AI 系統需要多元且具包容性的訓練資料。像兒童成長監測器這樣的專案顯示，使用廣泛的資料如何有助於解決營養不良和貧窮等現實世界問題。我們提出了一個專案，展示 AI 如何應用於監控搜尋引擎在散布關於 LGBTQ+ 社群的錯誤資訊中所扮演的角色。此外，我們討論 SignON 專案，作為一個範例說明技術如何彌合聽人和聾人之間的溝通鴻溝，並強調在開發具包容性的 AI 時，合作和相互信任的重要性。總的來說，透過這篇論文，我們提倡 AI 系統不僅有效，而且具有社會責任，促進人類與機器之間公平且具包容性的互動。</paragraph>

##### **Confidence Estimation for Error Detection in Text-to-SQL Systems**
2501.09527v1 by Oleg Somov, Elena Tutubalina

Text-to-SQL enables users to interact with databases through natural
language, simplifying the retrieval and synthesis of information. Despite the
success of large language models (LLMs) in converting natural language
questions into SQL queries, their broader adoption is limited by two main
challenges: achieving robust generalization across diverse queries and ensuring
interpretative confidence in their predictions. To tackle these issues, our
research investigates the integration of selective classifiers into Text-to-SQL
systems. We analyse the trade-off between coverage and risk using entropy based
confidence estimation with selective classifiers and assess its impact on the
overall performance of Text-to-SQL models. Additionally, we explore the models'
initial calibration and improve it with calibration techniques for better model
alignment between confidence and accuracy. Our experimental results show that
encoder-decoder T5 is better calibrated than in-context-learning GPT 4 and
decoder-only Llama 3, thus the designated external entropy-based selective
classifier has better performance. The study also reveal that, in terms of
error detection, selective classifier with a higher probability detects errors
associated with irrelevant questions rather than incorrect query generations.

摘要：文字轉 SQL 使使用者能透過自然語言與資料庫互動，簡化了資訊的擷取與合成。儘管大型語言模型 (LLM) 在將自然語言問題轉換為 SQL 查詢方面獲得成功，但它們更廣泛的採用受到兩項主要挑戰的限制：在各種查詢中實現穩健的概括，並確保對其預測的解釋性信心。為了解決這些問題，我們的研究探討了將選擇性分類器整合到文字轉 SQL 系統中。我們使用基於熵的信心估計和選擇性分類器分析了覆蓋範圍和風險之間的權衡，並評估其對文字轉 SQL 模型整體效能的影響。此外，我們探討了模型的初始校準，並使用校準技術改善它，以在信心和準確性之間實現更好的模型對齊。我們的實驗結果顯示，編碼器解碼器 T5 的校準比情境內學習 GPT 4 和僅解碼器 Llama 3 更好，因此指定的外部基於熵的選擇性分類器具有更好的效能。研究還顯示，在錯誤偵測方面，具有較高機率的選擇性分類器會偵測與不相關問題相關的錯誤，而不是不正確的查詢產生。

##### **Class Incremental Fault Diagnosis under Limited Fault Data via Supervised Contrastive Knowledge Distillation**
2501.09525v1 by Hanrong Zhang, Yifei Yao, Zixuan Wang, Jiayuan Su, Mengxuan Li, Peng Peng, Hongwei Wang

Class-incremental fault diagnosis requires a model to adapt to new fault
classes while retaining previous knowledge. However, limited research exists
for imbalanced and long-tailed data. Extracting discriminative features from
few-shot fault data is challenging, and adding new fault classes often demands
costly model retraining. Moreover, incremental training of existing methods
risks catastrophic forgetting, and severe class imbalance can bias the model's
decisions toward normal classes. To tackle these issues, we introduce a
Supervised Contrastive knowledge distiLlation for class Incremental Fault
Diagnosis (SCLIFD) framework proposing supervised contrastive knowledge
distillation for improved representation learning capability and less
forgetting, a novel prioritized exemplar selection method for sample replay to
alleviate catastrophic forgetting, and the Random Forest Classifier to address
the class imbalance. Extensive experimentation on simulated and real-world
industrial datasets across various imbalance ratios demonstrates the
superiority of SCLIFD over existing approaches. Our code can be found at
https://github.com/Zhang-Henry/SCLIFD_TII.

摘要：類別增量式故障診斷需要一個模型來適應新的故障類別，同時保留先前的知識。然而，對於不平衡且長尾的資料，研究有限。從少次故障資料中提取區別性特徵具有挑戰性，而新增故障類別通常需要代價高昂的模型重新訓練。此外，現有方法的增量訓練有災難性遺忘的風險，而嚴重的類別不平衡可能會使模型的決策偏向正常類別。為了解決這些問題，我們引入了一個類別增量式故障診斷的監督對比知識蒸餾（SCLIFD）框架，提出了監督對比知識蒸餾，以提高表示學習能力並減少遺忘，一種新的優先範例選擇方法，用於樣本重播以減輕災難性遺忘，以及隨機森林分類器來解決類別不平衡。在各種不平衡率下對模擬和真實世界工業資料集進行的廣泛實驗證明了 SCLIFD 優於現有方法。我們的程式碼可以在 https://github.com/Zhang-Henry/SCLIFD_TII 找到。

##### **Augmenting a Large Language Model with a Combination of Text and Visual Data for Conversational Visualization of Global Geospatial Data**
2501.09521v1 by Omar Mena, Alexandre Kouyoumdjian, Lonni Besançon, Michael Gleicher, Ivan Viola, Anders Ynnerman

We present a method for augmenting a Large Language Model (LLM) with a
combination of text and visual data to enable accurate question answering in
visualization of scientific data, making conversational visualization possible.
LLMs struggle with tasks like visual data interaction, as they lack contextual
visual information. We address this problem by merging a text description of a
visualization and dataset with snapshots of the visualization. We extract their
essential features into a structured text file, highly compact, yet descriptive
enough to appropriately augment the LLM with contextual information, without
any fine-tuning. This approach can be applied to any visualization that is
already finally rendered, as long as it is associated with some textual
description.

摘要：我們提出了一種方法，可以通過文字和視覺資料的組合來擴充大型語言模型 (LLM)，以在科學資料視覺化中實現準確的問答，讓對話式視覺化成為可能。
LLM 在視覺資料互動等任務方面遇到困難，因為它們缺乏背景視覺資訊。我們透過將視覺化和資料集的文字描述與視覺化的快照合併，來解決這個問題。我們將它們的基本特徵萃取到一個結構化的文字檔案中，該檔案非常精簡，但足以適當地用背景資訊擴充 LLM，而無需任何微調。只要與一些文字描述相關聯，這種方法就可以應用於任何已經最終呈現的視覺化。

##### **PIER: A Novel Metric for Evaluating What Matters in Code-Switching**
2501.09512v1 by Enes Yavuz Ugan, Ngoc-Quan Pham, Leonard Bärmann, Alex Waibel

Code-switching, the alternation of languages within a single discourse,
presents a significant challenge for Automatic Speech Recognition. Despite the
unique nature of the task, performance is commonly measured with established
metrics such as Word-Error-Rate (WER). However, in this paper, we question
whether these general metrics accurately assess performance on code-switching.
Specifically, using both Connectionist-Temporal-Classification and
Encoder-Decoder models, we show fine-tuning on non-code-switched data from both
matrix and embedded language improves classical metrics on code-switching test
sets, although actual code-switched words worsen (as expected). Therefore, we
propose Point-of-Interest Error Rate (PIER), a variant of WER that focuses only
on specific words of interest. We instantiate PIER on code-switched utterances
and show that this more accurately describes the code-switching performance,
showing huge room for improvement in future work. This focused evaluation
allows for a more precise assessment of model performance, particularly in
challenging aspects such as inter-word and intra-word code-switching.

摘要：在單一語篇中交替使用語言的語碼轉換，對自動語音辨識來說是一項重大的挑戰。儘管這項任務的性質獨特，但效能通常會以既定的指標來衡量，例如字元錯誤率 (WER)。然而，在本文中，我們質疑這些通用指標是否能準確評估語碼轉換的效能。具體來說，我們使用連接主義時序分類和編碼器解碼器模型，證明在非語碼轉換的資料上進行微調，無論是矩陣語言或嵌入式語言，都能改善語碼轉換測試集的傳統指標，儘管實際的語碼轉換字詞會變差（正如預期）。因此，我們提出關注點錯誤率 (PIER)，這是 WER 的一種變體，只關注特定的關注字詞。我們在語碼轉換的語句上實例化 PIER，並證明這能更準確地描述語碼轉換的效能，顯示出未來工作有很大的改進空間。這種有焦點的評估能更精確地評估模型效能，特別是在單字間和單字內的語碼轉換等具有挑戰性的方面。

##### **Exploring the Inquiry-Diagnosis Relationship with Advanced Patient Simulators**
2501.09484v1 by Zhaocheng Liu, Quan Tu, Wen Ye, Yu Xiao, Zhishou Zhang, Hengfu Cui, Yalun Zhu, Qiang Ju, Shizheng Li, Jian Xie

Online medical consultation (OMC) restricts doctors to gathering patient
information solely through inquiries, making the already complex sequential
decision-making process of diagnosis even more challenging. Recently, the rapid
advancement of large language models has demonstrated a significant potential
to transform OMC. However, most studies have primarily focused on improving
diagnostic accuracy under conditions of relatively sufficient information,
while paying limited attention to the "inquiry" phase of the consultation
process. This lack of focus has left the relationship between "inquiry" and
"diagnosis" insufficiently explored. In this paper, we first extract real
patient interaction strategies from authentic doctor-patient conversations and
use these strategies to guide the training of a patient simulator that closely
mirrors real-world behavior. By inputting medical records into our patient
simulator to simulate patient responses, we conduct extensive experiments to
explore the relationship between "inquiry" and "diagnosis" in the consultation
process. Experimental results demonstrate that inquiry and diagnosis adhere to
the Liebig's law: poor inquiry quality limits the effectiveness of diagnosis,
regardless of diagnostic capability, and vice versa. Furthermore, the
experiments reveal significant differences in the inquiry performance of
various models. To investigate this phenomenon, we categorize the inquiry
process into four types: (1) chief complaint inquiry; (2) specification of
known symptoms; (3) inquiry about accompanying symptoms; and (4) gathering
family or medical history. We analyze the distribution of inquiries across the
four types for different models to explore the reasons behind their significant
performance differences. We plan to open-source the weights and related code of
our patient simulator at https://github.com/LIO-H-ZEN/PatientSimulator.

摘要：線上醫療諮詢 (OMC) 限制醫師僅能透過詢問來收集病患資訊，讓本來就複雜的診斷順序決策過程更加困難。最近，大型語言模型的快速進展已展現出轉型 OMC 的重大潛力。然而，大多數研究主要著重於在相對充足的資訊條件下提升診斷準確度，而較少關注諮詢過程中的「詢問」階段。這種缺乏關注的情況使得「詢問」與「診斷」之間的關係探索不足。在本文中，我們首先從真實的醫病對話中萃取真實的病患互動策略，並利用這些策略引導訓練一位與真實世界行為密切對應的病患模擬器。透過將病歷輸入我們的病患模擬器來模擬病患回應，我們進行廣泛的實驗來探討諮詢過程中「詢問」與「診斷」之間的關係。實驗結果證明詢問與診斷遵循李比希定律：無論診斷能力如何，不良的詢問品質都會限制診斷的有效性，反之亦然。此外，實驗揭示了各種模型在詢問表現上的顯著差異。為了調查這種現象，我們將詢問過程分類為四種類型：(1) 主訴詢問；(2) 已知症狀說明；(3) 伴隨症狀詢問；以及 (4) 家族或病史收集。我們分析不同模型在四種類型中的詢問分佈，以探討其顯著效能差異背後的原因。我們計畫在 https://github.com/LIO-H-ZEN/PatientSimulator 開源我們的病患模擬器的權重和相關程式碼。

##### **Predicting Air Temperature from Volumetric Urban Morphology with Machine Learning**
2501.09469v1 by Berk Kıvılcım, Patrick Erik Bradley

In this study, we firstly introduce a method that converts CityGML data into
voxels which works efficiently and fast in high resolution for large scale
datasets such as cities but by sacrificing some building details to overcome
the limitations of previous voxelization methodologies that have been
computationally intensive and inefficient at transforming large-scale urban
areas into voxel representations for high resolution. Those voxelized 3D city
data from multiple cities and corresponding air temperature data are used to
develop a machine learning model. Before the model training, Gaussian blurring
is implemented on input data to consider spatial relationships, as a result the
correlation rate between air temperature and volumetric building morphology is
also increased after the Gaussian blurring. After the model training, the
prediction results are not just evaluated with Mean Square Error (MSE) but some
image similarity metrics such as Structural Similarity Index Measure (SSIM) and
Learned Perceptual Image Patch Similarity (LPIPS) that are able to detect and
consider spatial relations during the evaluation process. This trained model is
capable of predicting the spatial distribution of air temperature by using
building volume information of corresponding pixel as input. By doing so, this
research aims to assist urban planners in incorporating environmental
parameters into their planning strategies, thereby facilitating more
sustainable and inhabitable urban environments.

摘要：在本研究中，我们首先介绍了一种方法，该方法将 CityGML 数据转换为体素，该方法在高分辨率下对大规模数据集（如城市）高效快速地工作，但通过牺牲一些建筑细节来克服以前体素化方法的局限性，这些方法在将大规模城市区域转换为高分辨率体素表示时计算密集且效率低下。这些来自多个城市体素化 3D 城市数据和相应的空气温度数据用于开发机器学习模型。在模型训练之前，对输入数据实施高斯模糊以考虑空间关系，因此，高斯模糊后空气温度与体积建筑形态之间的相关率也增加了。在模型训练之后，预测结果不仅通过均方误差 (MSE) 评估，而且还通过一些图像相似性指标（例如结构相似性指数度量 (SSIM) 和学习感知图像块相似性 (LPIPS)）评估，这些指标能够在评估过程中检测和考虑空间关系。该训练模型能够通过使用相应像素的建筑体积信息作为输入来预测空气温度的空间分布。通过这样做，本研究旨在帮助城市规划者将环境参数纳入其规划策略中，从而促进更可持续和宜居的城市环境。

##### **RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection**
2501.09465v1 by Jianrui Shi, Yong Zhao, Zeyang Cui, Xiaoming Shen, Minhang Zeng, Xiaojie Liu

Object detection plays a crucial role in smart video analysis, with
applications ranging from autonomous driving and security to smart cities.
However, achieving real-time object detection on edge devices presents
significant challenges due to their limited computational resources and the
high demands of deep neural network (DNN)-based detection models, particularly
when processing high-resolution video. Conventional strategies, such as input
down-sampling and network up-scaling, often compromise detection accuracy for
faster performance or lead to higher inference latency. To address these
issues, this paper introduces RE-POSE, a Reinforcement Learning (RL)-Driven
Partitioning and Edge Offloading framework designed to optimize the
accuracy-latency trade-off in resource-constrained edge environments. Our
approach features an RL-Based Dynamic Clustering Algorithm (RL-DCA) that
partitions video frames into non-uniform blocks based on object distribution
and the computational characteristics of DNNs. Furthermore, a parallel edge
offloading scheme is implemented to distribute these blocks across multiple
edge servers for concurrent processing. Experimental evaluations show that
RE-POSE significantly enhances detection accuracy and reduces inference
latency, surpassing existing methods.

摘要：物件偵測在智慧型影片分析中扮演著至關重要的角色，其應用範圍從自動駕駛和安全防護到智慧城市。然而，在邊緣裝置上實現即時物件偵測會面臨嚴峻的挑戰，因為邊緣裝置的運算資源有限，而且基於深度神經網路 (DNN) 的偵測模型需求極高，特別是在處理高解析度影片時。傳統策略（例如輸入降採樣和網路升頻）通常會犧牲偵測精確度以換取更快的效能，或導致更高的推論延遲。為了解決這些問題，本文介紹 RE-POSE，一個以強化學習 (RL) 為主的分割和邊緣卸載架構，旨在最佳化資源受限邊緣環境中的精確度延遲權衡。我們的做法具備一個基於 RL 的動態叢集演算法 (RL-DCA)，它會根據物件分佈和 DNN 的運算特性，將影片格拆分為非均勻區塊。此外，還實作了一個平行邊緣卸載架構，用於將這些區塊分配到多個邊緣伺服器進行並行處理。實驗評估顯示，RE-POSE 大幅提升了偵測精確度，並降低了推論延遲，超越了現有方法。

##### **Scaling Graph-Based Dependency Parsing with Arc Vectorization and Attention-Based Refinement**
2501.09451v1 by Nicolas Floquet, Joseph Le Roux, Nadi Tomeh, Thierry Charnois

We propose a novel architecture for graph-based dependency parsing that
explicitly constructs vectors, from which both arcs and labels are scored. Our
method addresses key limitations of the standard two-pipeline approach by
unifying arc scoring and labeling into a single network, reducing scalability
issues caused by the information bottleneck and lack of parameter sharing.
Additionally, our architecture overcomes limited arc interactions with
transformer layers to efficiently simulate higher-order dependencies.
Experiments on PTB and UD show that our model outperforms state-of-the-art
parsers in both accuracy and efficiency.

摘要：<paragraph>我們提出了一個基於圖的依賴句法分析的新穎架構，它明確地構造了向量，從中對弧和標籤進行評分。我們的
方法通過將弧評分和標籤統一到一個單一網路中來解決標準二管道方法的主要限制，從而減少了由資訊瓶頸和參數共享不足引起的擴充性問題。
此外，我們的架構克服了受限的弧互動與Transformer層的互動，以有效模擬高階依賴關係。
在 PTB 和 UD 上的實驗表明，我們的模型在準確性和效率方面都優於最先進的解析器。</paragraph>

##### **Solving the unsolvable: Translating case law in Hong Kong**
2501.09444v1 by King-kui Sin, Xi Xuan, Chunyu Kit, Clara Ho-yan Chan, Honic Ho-kin Ip

This paper addresses the challenges translating case law under Hong Kong's
bilingual legal system. It highlights the initial success of translating all
written statutes into Chinese before the 1997 handover, a task mandated by the
Basic Law. The effort involved significant collaboration among legal,
linguistic, and translation experts, resulting in a comprehensive and
culturally appropriate bilingual legal system. However, translating case law
remains a significant challenge due to the sheer volume and continuous growth
of judicial decisions. The paper critiques the governments and judiciarys
sporadic and uncoordinated efforts to translate case law, contrasting it with
the thorough approach previously taken for statute translation. Although the
government acknowledges the importance of legal bilingualism, it lacks a
sustainable strategy for translating case law. The Judiciarys position that
translating all judgments is unnecessary, unrealistic, and not cost-effectiveis
analyzed and critiqued for its impact on legal transparency and public trust. A
proposed solution involves leveraging machine translation technology through a
human-machine interactive translation platform, which undergoes two major
transitions. Initially based on a neural model, the platform transitions to
using a large language model for improved translation accuracy. Furthermore, it
evolves from a single-agent system to a multi-agent system, incorporating
Translator, Annotator, and Proofreader agents. This multi-agent approach,
supported by a grant, aims to facilitate efficient, high-quality translation of
judicial judgments by integrating advanced artificial intelligence and
continuous feedback mechanisms, thus better meeting the needs of a bilingual
legal system.

摘要：本文探討在香港雙語法律制度下翻譯判例所面臨的挑戰。重點說明在 1997 年回歸前將所有成文法規翻譯成中文的初步成功，這項任務是由基本法授權的。這項工作需要法律、語言和翻譯專家的大力合作，最終建立了一個全面且符合文化背景的雙語法律制度。然而，由於司法判決數量龐大且持續增加，翻譯判例仍然是一項重大挑戰。本文批判政府和司法機構在翻譯判例上的零星且不協調的努力，並將其與先前在法規翻譯上採取的徹底方法進行對比。儘管政府承認法律雙語化的重要性，但卻缺乏翻譯判例的可持續策略。本文分析並批判司法機構認為翻譯所有判決不必要、不切實際且不具成本效益的立場，探討其對法律透明度和公眾信任的影響。建議的解決方案包括透過人機互動翻譯平台運用機器翻譯技術，該平台經歷兩次重大轉變。最初基於神經網路模型，該平台轉而使用大型語言模型以提高翻譯準確度。此外，它從單一代理系統演變成多代理系統，包含翻譯者、註解者和校對者代理。這種多代理方法在補助金的支持下，旨在透過整合先進的人工智慧和持續回饋機制，促進司法判決的高品質翻譯，從而更好地滿足雙語法律制度的需求。

##### **A Survey on Responsible LLMs: Inherent Risk, Malicious Use, and Mitigation Strategy**
2501.09431v1 by Huandong Wang, Wenjie Fu, Yingzhou Tang, Zhilong Chen, Yuxi Huang, Jinghua Piao, Chen Gao, Fengli Xu, Tao Jiang, Yong Li

While large language models (LLMs) present significant potential for
supporting numerous real-world applications and delivering positive social
impacts, they still face significant challenges in terms of the inherent risk
of privacy leakage, hallucinated outputs, and value misalignment, and can be
maliciously used for generating toxic content and unethical purposes after been
jailbroken. Therefore, in this survey, we present a comprehensive review of
recent advancements aimed at mitigating these issues, organized across the four
phases of LLM development and usage: data collecting and pre-training,
fine-tuning and alignment, prompting and reasoning, and post-processing and
auditing. We elaborate on the recent advances for enhancing the performance of
LLMs in terms of privacy protection, hallucination reduction, value alignment,
toxicity elimination, and jailbreak defenses. In contrast to previous surveys
that focus on a single dimension of responsible LLMs, this survey presents a
unified framework that encompasses these diverse dimensions, providing a
comprehensive view of enhancing LLMs to better serve real-world applications.

摘要：儘管大型語言模型 (LLM) 在支援許多真實世界的應用程式和產生正面的社會影響方面具有顯著的潛力，但它們在固有的隱私外洩風險、虛構產出和價值偏差方面仍面臨重大的挑戰，而且在被破解後可能會被惡意用於產生有毒內容和不道德的目的。因此，在本次調查中，我們對旨在減輕這些問題的最新進展進行了全面的回顧，並針對 LLM 開發和使用的四個階段進行整理：資料收集和預訓練、微調和校準、提示和推理，以及後處理和稽核。我們詳細說明了在隱私保護、減少虛構、價值校準、消除毒性以及破解防禦方面增強 LLM 效能的最新進展。與先前僅關注負責任的 LLM 單一面向的調查相比，本調查提出了涵蓋這些不同面向的統一架構，提供了增強 LLM 以更好地服務於真實世界應用程式的全面觀點。

##### **ADAGE: A generic two-layer framework for adaptive agent based modelling**
2501.09429v1 by Benjamin Patrick Evans, Sihan Zeng, Sumitra Ganesh, Leo Ardon

Agent-based models (ABMs) are valuable for modelling complex, potentially
out-of-equilibria scenarios. However, ABMs have long suffered from the Lucas
critique, stating that agent behaviour should adapt to environmental changes.
Furthermore, the environment itself often adapts to these behavioural changes,
creating a complex bi-level adaptation problem. Recent progress integrating
multi-agent reinforcement learning into ABMs introduces adaptive agent
behaviour, beginning to address the first part of this critique, however, the
approaches are still relatively ad hoc, lacking a general formulation, and
furthermore, do not tackle the second aspect of simultaneously adapting
environmental level characteristics in addition to the agent behaviours. In
this work, we develop a generic two-layer framework for ADaptive AGEnt based
modelling (ADAGE) for addressing these problems. This framework formalises the
bi-level problem as a Stackelberg game with conditional behavioural policies,
providing a consolidated framework for adaptive agent-based modelling based on
solving a coupled set of non-linear equations. We demonstrate how this generic
approach encapsulates several common (previously viewed as distinct) ABM tasks,
such as policy design, calibration, scenario generation, and robust behavioural
learning under one unified framework. We provide example simulations on
multiple complex economic and financial environments, showing the strength of
the novel framework under these canonical settings, addressing long-standing
critiques of traditional ABMs.

摘要：基於代理的模型（ABM）對於建模複雜、潛在失衡的場景非常有價值。然而，ABM 長期以來一直受到盧卡斯批評，認為代理行為應適應環境變化。此外，環境本身通常會適應這些行為變化，從而產生一個複雜的雙層適應問題。最近將多代理強化學習整合到 ABM 中的進展引入了自適應代理行為，開始解決這一批評的第一部分，然而，這些方法仍然相對臨時，缺乏一般性表述，此外，除了代理行為之外，還沒有解決同時適應環境層次特徵的第二個方面。在這項工作中，我們開發了一個用於自適應代理基於模型（ADAGE）的通用兩層架構，以解決這些問題。這個框架將雙層問題形式化為一個具有條件行為策略的 Stackelberg 遊戲，提供了一個基於求解一組非線性方程的適應性基於代理的建模的綜合框架。我們展示了這個通用方法如何封裝幾個常見的（以前被視為不同的）ABM 任務，例如策略設計、校準、場景生成和在一個統一框架下的穩健行為學習。我們在多個複雜的經濟和金融環境中提供了範例模擬，展示了這個新框架在這些典型設定下的優勢，解決了傳統 ABM 的長期批評。

##### **AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling**
2501.09426v1 by Ancheng Xu, Di Yang, Renhao Li, Jingwei Zhu, Minghuan Tan, Min Yang, Wanxin Qiu, Mingchen Ma, Haihong Wu, Bingyu Li, Feng Sha, Chengming Li, Xiping Hu, Qiang Qu, Derek F. Wong, Ruifeng Xu

Traditional in-person psychological counseling remains primarily niche, often
chosen by individuals with psychological issues, while online automated
counseling offers a potential solution for those hesitant to seek help due to
feelings of shame. Cognitive Behavioral Therapy (CBT) is an essential and
widely used approach in psychological counseling. The advent of large language
models (LLMs) and agent technology enables automatic CBT diagnosis and
treatment. However, current LLM-based CBT systems use agents with a fixed
structure, limiting their self-optimization capabilities, or providing hollow,
unhelpful suggestions due to redundant response patterns. In this work, we
utilize Quora-like and YiXinLi single-round consultation models to build a
general agent framework that generates high-quality responses for single-turn
psychological consultation scenarios. We use a bilingual dataset to evaluate
the quality of single-response consultations generated by each framework. Then,
we incorporate dynamic routing and supervisory mechanisms inspired by real
psychological counseling to construct a CBT-oriented autonomous multi-agent
framework, demonstrating its general applicability. Experimental results
indicate that AutoCBT can provide higher-quality automated psychological
counseling services.

摘要：傳統面對面的心理諮商仍主要屬於利基市場，通常由有心理問題的個人選擇，而線上自動化諮商為那些因羞恥感而猶豫尋求幫助的人提供了一個潛在的解決方案。認知行為療法 (CBT) 是一種心理諮商中不可或缺且廣泛使用的方法。大型語言模型 (LLM) 和代理技術的出現，實現了自動 CBT 診斷和治療。然而，目前的基於 LLM 的 CBT 系統使用具有固定結構的代理，限制了它們的自我優化能力，或由於重複的回應模式而提供空洞、無益的建議。在這項工作中，我們利用 Quora 類似和易信理單輪諮詢模型，構建了一個通用代理框架，為單輪心理諮詢場景生成高品質的回應。我們使用雙語數據集來評估每個框架生成的單一回應諮詢的品質。然後，我們結合了受真實心理諮商啟發的動態路由和監督機制，構建了一個面向 CBT 的自主多代理框架，展示了其通用適用性。實驗結果表明，AutoCBT 可以提供更高品質的自動化心理諮商服務。

##### **Vision-Language Models Do Not Understand Negation**
2501.09425v1 by Kumail Alhamoud, Shaden Alshammari, Yonglong Tian, Guohao Li, Philip Torr, Yoon Kim, Marzyeh Ghassemi

Many practical vision-language applications require models that understand
negation, e.g., when using natural language to retrieve images which contain
certain objects but not others. Despite advancements in vision-language models
(VLMs) through large-scale training, their ability to comprehend negation
remains underexplored. This study addresses the question: how well do current
VLMs understand negation? We introduce NegBench, a new benchmark designed to
evaluate negation understanding across 18 task variations and 79k examples
spanning image, video, and medical datasets. The benchmark consists of two core
tasks designed to evaluate negation understanding in diverse multimodal
settings: Retrieval with Negation and Multiple Choice Questions with Negated
Captions. Our evaluation reveals that modern VLMs struggle significantly with
negation, often performing at chance level. To address these shortcomings, we
explore a data-centric approach wherein we finetune CLIP models on large-scale
synthetic datasets containing millions of negated captions. We show that this
approach can result in a 10% increase in recall on negated queries and a 40%
boost in accuracy on multiple-choice questions with negated captions.

摘要：許多實用的視覺語言應用程式需要模型來理解否定，例如，在使用自然語言來擷取包含特定物件但又不包含其他物件的影像時。儘管視覺語言模型 (VLM) 透過大規模訓練而獲得進展，它們理解否定能力的議題仍未被充分探討。本研究探討了以下問題：現今的 VLM 對否定的理解程度如何？我們引入了 NegBench，這是一個新的基準測試，旨在評估 18 種任務變異和橫跨影像、影片和醫療資料集的 79k 個範例中的否定理解能力。該基準測試包含兩個核心任務，旨在評估在不同的多模態設定中的否定理解能力：帶有否定的擷取和帶有否定字幕的多重選擇題。我們的評估顯示，現代 VLM 在否定方面顯著地掙扎，通常表現得像碰運氣。為了解決這些缺點，我們探討了一種以資料為中心的途徑，其中我們對包含數百萬個否定字幕的大規模合成資料集微調 CLIP 模型。我們展示了這種方法可以在否定的查詢中產生 10% 的召回率提升，以及在帶有否定字幕的多重選擇題中產生 40% 的準確度提升。

##### **Dynamic Neural Style Transfer for Artistic Image Generation using VGG19**
2501.09420v1 by Kapil Kashyap, Mehak Garg, Sean Fargose, Sindhu Nair

Throughout history, humans have created remarkable works of art, but
artificial intelligence has only recently started to make strides in generating
visually compelling art. Breakthroughs in the past few years have focused on
using convolutional neural networks (CNNs) to separate and manipulate the
content and style of images, applying texture synthesis techniques.
Nevertheless, a number of current techniques continue to encounter obstacles,
including lengthy processing times, restricted choices of style images, and the
inability to modify the weight ratio of styles. We proposed a neural style
transfer system that can add various artistic styles to a desired image to
address these constraints allowing flexible adjustments to style weight ratios
and reducing processing time. The system uses the VGG19 model for feature
extraction, ensuring high-quality, flexible stylization without compromising
content integrity.

摘要：縱觀歷史，人類創造出許多傑出的藝術作品，但人工智慧直到最近才開始在生成視覺上引人注目的藝術方面取得進展。過去幾年的突破集中在使用卷積神經網路 (CNN) 來分離和處理圖像的內容和風格，並運用紋理合成技術。然而，許多當前的技術仍會遇到障礙，包括處理時間冗長、風格圖像選擇受限，以及無法修改風格的權重比。我們提出了一種神經風格轉移系統，可以將各種藝術風格加入到目標圖像中，以解決這些限制，允許靈活調整風格權重比並縮短處理時間。該系統使用 VGG19 模型進行特徵提取，確保高品質、靈活的風格化，同時不損害內容的完整性。

##### **MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models**
2501.09410v1 by Lyudong Jin, Yanning Zhang, Yanhan Li, Shurong Wang, Howard H. Yang, Jian Wu, Meng Zhang

Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of natural language processing tasks. Exploiting the heterogeneous
capabilities of edge LLMs is crucial for diverse emerging applications, as it
enables greater cost-effectiveness and reduced latency. In this work, we
introduce \textit{Mixture-of-Edge-Experts (MoE$^2$)}, a novel collaborative
inference framework for edge LLMs. We formulate the joint gating and expert
selection problem to optimize inference performance under energy and latency
constraints. Unlike conventional MoE problems, LLM expert selection is
significantly more challenging due to the combinatorial nature and the
heterogeneity of edge LLMs across various attributes. To this end, we propose a
two-level expert selection mechanism through which we uncover an
optimality-preserving property of gating parameters across expert selections.
This property enables the decomposition of the training and selection
processes, significantly reducing complexity. Furthermore, we leverage the
objective's monotonicity and design a discrete monotonic optimization algorithm
for optimal expert selection. We implement edge servers with NVIDIA Jetson AGX
Orins and NVIDIA RTX 4090 GPUs, and perform extensive experiments. Our results
validate that performance improvements of various LLM models and show that our
MoE$^2$ method can achieve optimal trade-offs among different delay and energy
budgets, and outperforms baselines under various system resource constraints.

摘要：大型語言模型 (LLM) 已在各種自然語言處理任務中展現出非凡的能力。利用邊緣 LLM 的異質能力對於不同的新興應用至關重要，因為它能提高成本效益並降低延遲。在這項工作中，我們引入了 \textit{混合邊緣專家 (MoE$^2$)}，這是一種邊緣 LLM 的新型協作推論框架。我們制定了聯合閘控和專家選擇問題，以在能源和延遲限制下最佳化推論效能。與傳統的 MoE 問題不同，LLM 專家選擇由於組合性質和邊緣 LLM 在各種屬性上的異質性而具有更大的挑戰性。為此，我們提出了一種兩級專家選擇機制，透過該機制我們發現了閘控參數在專家選擇中具有保優性質。此性質使得訓練和選擇過程得以分解，大幅降低了複雜度。此外，我們利用目標函數的單調性，並設計了一種離散單調最佳化演算法，以進行最佳專家選擇。我們使用 NVIDIA Jetson AGX Orins 和 NVIDIA RTX 4090 GPU 實作邊緣伺服器，並執行廣泛的實驗。我們的結果驗證了各種 LLM 模型的效能提升，並顯示我們的 MoE$^2$ 方法可以在不同的延遲和能源預算之間達成最佳折衷，並在各種系統資源限制下優於基準。

##### **mGeNTE: A Multilingual Resource for Gender-Neutral Language and Translation**
2501.09409v1 by Beatrice Savoldi, Eleonora Cupin, Manjinder Thind, Anne Lauscher, Luisa Bentivogli

Gender-neutral language reflects societal and linguistic shifts towards
greater inclusivity by avoiding the implication that one gender is the norm
over others. This is particularly relevant for grammatical gender languages,
which heavily encode the gender of terms for human referents and over-relies on
masculine forms, even when gender is unspecified or irrelevant. Language
technologies are known to mirror these inequalities, being affected by a male
bias and perpetuating stereotypical associations when translating into
languages with extensive gendered morphology. In such cases, gender-neutral
language can help avoid undue binary assumptions. However, despite its
importance for creating fairer multi- and cross-lingual technologies, inclusive
language research remains scarce and insufficiently supported in current
resources. To address this gap, we present the multilingual mGeNTe dataset.
Derived from the bilingual GeNTE (Piergentili et al., 2023), mGeNTE extends the
original corpus to include the English-Italian/German/Spanish language pairs.
Since each language pair is English-aligned with gendered and neutral sentences
in the target languages, mGeNTE enables research in both automatic
Gender-Neutral Translation (GNT) and language modelling for three grammatical
gender languages.

摘要：性別中立語言反映社會和語言朝向更具包容性的轉變，避免暗示一種性別比其他性別更為常態。這對於語法性別語言特別相關，這種語言強烈編碼人類指稱物的性別，即使在性別未指定或不相關時，也會過度依賴陽性形式。語言技術已知會反映這些不平等，受到男性偏見的影響，並在翻譯成具有廣泛性別形態的語言時延續刻板印象的聯想。在這種情況下，性別中立語言有助於避免不適當的二元假設。然而，儘管性別中立語言對於創造更公平的多語言和跨語言技術很重要，但包容性語言研究仍然稀少，並且在當前資源中支持不足。為了解決這個差距，我們提出了多語言 mGeNTe 資料集。mGeNTe 衍生自雙語 GeNTE (Piergentili 等人，2023 年)，將原始語料庫延伸至包含英語-義大利語/德語/西班牙語語言對。由於每個語言對都是與目標語言中的性別化和中性句子對齊的英語，因此 mGeNTe 支援對三種語法性別語言的自動性別中立翻譯 (GNT) 和語言建模進行研究。

##### **Quantum-Enhanced Transformers for Robust Acoustic Scene Classification in IoT Environments**
2501.09394v1 by Minh K. Quan, Mayuri Wijayasundara, Sujeeva Setunge, Pubudu N. Pathirana

The proliferation of Internet of Things (IoT) devices equipped with acoustic
sensors necessitates robust acoustic scene classification (ASC) capabilities,
even in noisy and data-limited environments. Traditional machine learning
methods often struggle to generalize effectively under such conditions. To
address this, we introduce Q-ASC, a novel Quantum-Inspired Acoustic Scene
Classifier that leverages the power of quantum-inspired transformers. By
integrating quantum concepts like superposition and entanglement, Q-ASC
achieves superior feature learning and enhanced noise resilience compared to
classical models. Furthermore, we introduce a Quantum Variational Autoencoder
(QVAE) based data augmentation technique to mitigate the challenge of limited
labeled data in IoT deployments. Extensive evaluations on the Tampere
University of Technology (TUT) Acoustic Scenes 2016 benchmark dataset
demonstrate that Q-ASC achieves remarkable accuracy between 68.3% and 88.5%
under challenging conditions, outperforming state-of-the-art methods by over 5%
in the best case. This research paves the way for deploying intelligent
acoustic sensing in IoT networks, with potential applications in smart homes,
industrial monitoring, and environmental surveillance, even in adverse acoustic
environments.

摘要：物联网 (IoT) 设备的激增配备了声学传感器，需要强大的声学场景分类 (ASC) 功能，即使在嘈杂和数据有限的环境中也是如此。传统的机器学习方法在这些条件下通常难以有效地泛化。为了解决这个问题，我们引入了 Q-ASC，这是一种新颖的量子启发声学场景分类器，它利用了量子启发变换器的能力。通过整合叠加和纠缠等量子概念，与经典模型相比，Q-ASC 实现了卓越的特征学习和增强的抗噪能力。此外，我们引入了一种基于量子变分自动编码器 (QVAE) 的数据增强技术，以减轻物联网部署中标记数据有限的挑战。对坦佩雷理工大学 (TUT) 声学场景 2016 基准数据集的广泛评估表明，Q-ASC 在具有挑战性的条件下实现了 68.3% 到 88.5% 的显着准确性，在最佳情况下比最先进的方法高出 5% 以上。这项研究为在物联网网络中部署智能声学传感铺平了道路，即使在不利的声学环境中，在智能家居、工业监控和环境监测中也具有潜在应用。

##### **Evaluating LLM Abilities to Understand Tabular Electronic Health Records: A Comprehensive Study of Patient Data Extraction and Retrieval**
2501.09384v1 by Jesus Lovon, Martin Mouysset, Jo Oleiwan, Jose G. Moreno, Christine Damase-Michel, Lynda Tamine

Electronic Health Record (EHR) tables pose unique challenges among which is
the presence of hidden contextual dependencies between medical features with a
high level of data dimensionality and sparsity. This study presents the first
investigation into the abilities of LLMs to comprehend EHRs for patient data
extraction and retrieval. We conduct extensive experiments using the MIMICSQL
dataset to explore the impact of the prompt structure, instruction, context,
and demonstration, of two backbone LLMs, Llama2 and Meditron, based on task
performance. Through quantitative and qualitative analyses, our findings show
that optimal feature selection and serialization methods can enhance task
performance by up to 26.79% compared to naive approaches. Similarly, in-context
learning setups with relevant example selection improve data extraction
performance by 5.95%. Based on our study findings, we propose guidelines that
we believe would help the design of LLM-based models to support health search.

摘要：電子健康紀錄 (EHR) 表格會帶來獨特的挑戰，其中一個挑戰是具有高維度資料和稀疏性的醫療特徵之間存在隱藏的脈絡相關性。本研究首次探討大型語言模型 (LLM) 理解電子健康紀錄以進行患者資料萃取和檢索的能力。我們使用 MIMICSQL 資料集進行廣泛的實驗，以探討提示結構、指示、脈絡和示範對兩個主幹 LLM（Llama2 和 Meditron）的影響，並根據任務效能進行探討。透過量化和質化分析，我們的研究結果顯示，最佳特徵選擇和序列化的方式可將任務效能提升多達 26.79%，與天真的方法相比。類似地，具有相關範例選擇的脈絡學習設定可將資料萃取效能提升 5.95%。根據我們的研究結果，我們提出一些準則，我們相信這些準則有助於設計基於 LLM 的模型以支援健康搜尋。

##### **Aligning Instruction Tuning with Pre-training**
2501.09368v1 by Yiming Liang, Tianyu Zheng, Xinrun Du, Ge Zhang, Xingwei Qu, Xiang Yue, Chujie Zheng, Jiaheng Liu, Lei Ma, Wenhu Chen, Guoyin Wang, Zhaoxiang Zhang, Wenhao Huang, Jiajun Zhang

Instruction tuning enhances large language models (LLMs) to follow human
instructions across diverse tasks, relying on high-quality datasets to guide
behavior. However, these datasets, whether manually curated or synthetically
generated, are often narrowly focused and misaligned with the broad
distributions captured during pre-training, limiting LLM generalization and
effective use of pre-trained knowledge. We propose *Aligning Instruction Tuning
with Pre-training* (AITP), a method that bridges this gap by identifying
coverage shortfalls in instruction-tuning datasets and rewriting
underrepresented pre-training data into high-quality instruction-response
pairs. This approach enriches dataset diversity while preserving task-specific
objectives. Evaluations on three fully open LLMs across eight benchmarks
demonstrate consistent performance improvements with AITP. Ablations highlight
the benefits of adaptive data selection, controlled rewriting, and balanced
integration, emphasizing the importance of aligning instruction tuning with
pre-training distributions to unlock the full potential of LLMs.

摘要：指令微調增強大型語言模型 (LLM)，以遵循人類指令執行各種任務，並依賴於高品質的資料集來引導行為。然而，這些資料集無論是手動整理或合成產生，通常都過於狹隘，與預訓練期間擷取的廣泛分佈不一致，限制了 LLM 的概化和預訓練知識的有效使用。我們提出「將指令微調與預訓練對齊」(AITP)，這是一種透過找出指令微調資料集中的涵蓋範圍不足之處，並將代表性不足的預訓練資料改寫為高品質的指令回應配對，來彌補此差距的方法。這種方法豐富了資料集的多樣性，同時保留了特定任務的目標。在八個基準上對三個完全開放的 LLM 進行評估，證明 AITP 具有持續的效能提升。消融研究突出了自適應資料選擇、受控改寫和平衡整合的優點，強調將指令微調與預訓練分佈對齊，以發揮 LLM 的全部潛力。

##### **YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks**
2501.09355v1 by Saptarashmi Bandyopadhyay, Vikas Bahirwani, Lavisha Aggarwal, Bhanu Guda, Lin Li, Andrea Colaco

Multimodal AI Agents are AI models that have the capability of interactively
and cooperatively assisting human users to solve day-to-day tasks. Augmented
Reality (AR) head worn devices can uniquely improve the user experience of
solving procedural day-to-day tasks by providing egocentric multimodal (audio
and video) observational capabilities to AI Agents. Such AR capabilities can
help AI Agents see and listen to actions that users take which can relate to
multimodal capabilities of human users. Existing AI Agents, either Large
Language Models (LLMs) or Multimodal Vision-Language Models (VLMs) are reactive
in nature, which means that models cannot take an action without reading or
listening to the human user's prompts. Proactivity of AI Agents on the other
hand can help the human user detect and correct any mistakes in agent observed
tasks, encourage users when they do tasks correctly or simply engage in
conversation with the user - akin to a human teaching or assisting a user. Our
proposed YET to Intervene (YETI) multimodal agent focuses on the research
question of identifying circumstances that may require the agent to intervene
proactively. This allows the agent to understand when it can intervene in a
conversation with human users that can help the user correct mistakes on tasks,
like cooking, using AR. Our YETI Agent learns scene understanding signals based
on interpretable notions of Structural Similarity (SSIM) on consecutive video
frames. We also define the alignment signal which the AI Agent can learn to
identify if the video frames corresponding to the user's actions on the task
are consistent with expected actions. These signals are used by our AI Agent to
determine when it should proactively intervene. We compare our results on the
instances of proactive intervention in the HoloAssist multimodal benchmark for
an expert agent guiding a user to complete procedural tasks.

摘要：多模态 AI 代理是 AI 模型，它有能力交互式地和协作式地帮助人类用户解决日常任务。增强现实 (AR) 头戴设备可以通过向 AI 代理提供以自我为中心的多种模式（音频和视频）观察能力，来独特地改善用户解决日常程序任务的体验。此类 AR 能力可以帮助 AI 代理看到和听到用户采取的动作，而这些动作可以与人类用户的多种模式能力相关。现有的 AI 代理，无论是大型语言模型 (LLM) 还是多模态视觉语言模型 (VLM)，本质上都是反应性的，这意味着模型在不阅读或聆听人类用户的提示的情况下无法采取行动。另一方面，AI 代理的主动性可以帮助人类用户检测和纠正代理观察到的任务中的任何错误，在用户正确完成任务时鼓励他们，或者简单地与用户进行对话——类似于人类教授或协助用户。我们提出的 YET 干预 (YETI) 多模态代理专注于识别可能需要代理主动干预的情况的研究问题。这使得代理能够理解何时可以在与人类用户的对话中进行干预，这可以帮助用户纠正任务中的错误，例如使用 AR 做饭。我们的 YETI 代理根据连续视频帧上结构相似性 (SSIM) 的可解释概念学习场景理解信号。我们还定义了对齐信号，AI 代理可以通过学习识别与用户在任务上的动作相对应的视频帧是否与预期动作一致。我们的 AI 代理使用这些信号来确定何时应主动干预。我们在 HoloAssist 多模态基准中比较了我们关于主动干预实例的结果，该基准用于专家代理指导用户完成程序任务。

##### **Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems with Style and Shopping Cart Information**
2501.09354v1 by Berke Ugurlu, Ming-Yi Hong, Che Lin

Understanding users' product preferences is essential to the efficacy of a
recommendation system. Precision marketing leverages users' historical data to
discern these preferences and recommends products that align with them.
However, recent browsing and purchase records might better reflect current
purchasing inclinations. Transformer-based recommendation systems have made
strides in sequential recommendation tasks, but they often fall short in
utilizing product image style information and shopping cart data effectively.
In light of this, we propose Style4Rec, a transformer-based e-commerce
recommendation system that harnesses style and shopping cart information to
enhance existing transformer-based sequential product recommendation systems.
Style4Rec represents a significant step forward in personalized e-commerce
recommendations, outperforming benchmarks across various evaluation metrics.
Style4Rec resulted in notable improvements: HR@5 increased from 0.681 to 0.735,
NDCG@5 increased from 0.594 to 0.674, and MRR@5 increased from 0.559 to 0.654.
We tested our model using an e-commerce dataset from our partnering company and
found that it exceeded established transformer-based sequential recommendation
benchmarks across various evaluation metrics. Thus, Style4Rec presents a
significant step forward in personalized e-commerce recommendation systems.

摘要：了解用户的商品偏好对于推荐系统的成效至关重要。精准营销利用用户的历史数据来辨别这些偏好，并推荐符合这些偏好的商品。然而，最近的浏览和购买记录可能更好地反映当前的购买倾向。基于 Transformer 的推荐系统在顺序推荐任务中取得了长足的进步，但它们在有效利用商品图片样式信息和购物车数据方面往往做得不够。有鉴于此，我们提出了 Style4Rec，这是一种基于 Transformer 的电子商务推荐系统，它利用样式和购物车信息来增强现有的基于 Transformer 的顺序商品推荐系统。Style4Rec 代表了个性化电子商务推荐的重大一步，在各种评估指标中都优于基准。Style4Rec 带来了显著的改进：HR@5 从 0.681 增加到 0.735，NDCG@5 从 0.594 增加到 0.674，MRR@5 从 0.559 增加到 0.654。我们使用来自我们合作公司的电子商务数据集测试了我们的模型，发现它在各种评估指标中都超过了已建立的基于 Transformer 的顺序推荐基准。因此，Style4Rec 代表了个性化电子商务推荐系统向前迈出的重要一步。

##### **ChartInsighter: An Approach for Mitigating Hallucination in Time-series Chart Summary Generation with A Benchmark Dataset**
2501.09349v1 by Fen Wang, Bomiao Wang, Xueli Shu, Zhen Liu, Zekai Shao, Chao Liu, Siming Chen

Effective chart summary can significantly reduce the time and effort decision
makers spend interpreting charts, enabling precise and efficient communication
of data insights. Previous studies have faced challenges in generating accurate
and semantically rich summaries of time-series data charts. In this paper, we
identify summary elements and common hallucination types in the generation of
time-series chart summaries, which serve as our guidelines for automatic
generation. We introduce ChartInsighter, which automatically generates chart
summaries of time-series data, effectively reducing hallucinations in chart
summary generation. Specifically, we assign multiple agents to generate the
initial chart summary and collaborate iteratively, during which they invoke
external data analysis modules to extract insights and compile them into a
coherent summary. Additionally, we implement a self-consistency test method to
validate and correct our summary. We create a high-quality benchmark of charts
and summaries, with hallucination types annotated on a sentence-by-sentence
basis, facilitating the evaluation of the effectiveness of reducing
hallucinations. Our evaluations using our benchmark show that our method
surpasses state-of-the-art models, and that our summary hallucination rate is
the lowest, which effectively reduces various hallucinations and improves
summary quality. The benchmark is available at
https://github.com/wangfen01/ChartInsighter.

摘要：有效的圖表摘要可以大幅減少決策者花在解讀圖表的時間和精力，進而能精準有效地傳達資料洞察。先前的研究在產生時間序列資料圖表的精確且語意豐富的摘要時面臨挑戰。在本文中，我們找出時間序列圖表摘要產生的摘要元素和常見的幻覺類型，作為我們自動產生的準則。我們介紹 ChartInsighter，它會自動產生時間序列資料的圖表摘要，有效減少圖表摘要產生的幻覺。具體來說，我們指定多個代理產生初始圖表摘要並反覆合作，在此期間，他們會呼叫外部資料分析模組來萃取洞察，並將它們編譯成一個連貫的摘要。此外，我們實作一個自洽性測試方法來驗證並修正我們的摘要。我們建立了一個高品質的圖表和摘要基準，並逐句註解幻覺類型，有助於評估減少幻覺的有效性。我們使用基準進行的評估顯示，我們的模型超越了現有技術，我們的摘要幻覺率最低，這有效減少了各種幻覺並改善了摘要品質。基準可在 https://github.com/wangfen01/ChartInsighter 取得。

##### **Rational Tuning of LLM Cascades via Probabilistic Modeling**
2501.09345v1 by Michael J. Zellinger, Matt Thomson

Understanding the reliability of large language models (LLMs) has recently
garnered significant attention. Given LLMs' propensity to hallucinate, as well
as their high sensitivity to prompt design, it is already challenging to
predict the performance of an individual LLM. However, the problem becomes more
complex for compound LLM systems such as cascades, where in addition to each
model's standalone performance, we must understand how the error rates of
different models interact. In this paper, we present a probabilistic model for
the joint performance distribution of a sequence of LLMs, which enables a
framework for rationally tuning the confidence thresholds of a LLM cascade
using continuous optimization. Compared to selecting confidence thresholds
using grid search, our parametric Markov-copula model significantly improves
runtime scaling with respect to the length of the cascade and the desired
resolution of the cost-error curve, turning them from intractable into
low-order polynomial. In addition, the optimal thresholds computed using our
continuous optimization-based algorithm increasingly outperform those found via
grid search as cascade length grows, improving the area under the cost-error
curve by 1.9% on average for cascades consisting of at least three models.
Overall, our Markov-copula model provides a rational basis for tuning LLM
cascade performance and points to the potential of probabilistic methods in
analyzing LLM systems.

摘要：<paragraph>了解大型語言模型 (LLM) 的可靠性最近備受關注。由於 LLM 容易出現幻覺，並且對提示設計高度敏感，因此預測個別 LLM 的效能已經具有挑戰性。然而，對於複合式 LLM 系統（例如串聯），問題變得更加複雜，除了每個模型的獨立效能之外，我們還必須了解不同模型的錯誤率如何交互作用。在本文中，我們提出了一個機率模型，用於 LLM 序列的聯合效能分佈，這提供了一個架構，可以使用連續最佳化合理調整 LLM 串聯的信心閾值。與使用網格搜尋來選擇信心閾值相比，我們的參數化 Markov-copula 模型顯著改善了執行時間縮放，相對於串聯的長度和成本誤差曲線所需的解析度，將它們從難以處理轉變為低階多項式。此外，使用我們基於連續最佳化的演算法計算出的最佳閾值，隨著串聯長度的增加而優於透過網格搜尋找到的閾值，平均改善了至少包含三個模型的串聯的成本誤差曲線下的面積 1.9%。總體而言，我們的 Markov-copula 模型為調整 LLM 串聯效能提供了合理的基礎，並指出了機率方法在分析 LLM 系統中的潛力。</paragraph>

##### **Prompt-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis**
2501.09333v1 by Arpita Chowdhury, Dipanjyoti Paul, Zheda Mai, Jianyang Gu, Ziheng Zhang, Kazi Sajeed Mehrab, Elizabeth G. Campolongo, Daniel Rubenstein, Charles V. Stewart, Anuj Karpatne, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao

We present a simple usage of pre-trained Vision Transformers (ViTs) for
fine-grained analysis, aiming to identify and localize the traits that
distinguish visually similar categories, such as different bird species or dog
breeds. Pre-trained ViTs such as DINO have shown remarkable capabilities to
extract localized, informative features. However, using saliency maps like
Grad-CAM can hardly point out the traits: they often locate the whole object by
a blurred, coarse heatmap, not traits. We propose a novel approach Prompt Class
Attention Map (Prompt-CAM) to the rescue. Prompt-CAM learns class-specific
prompts to a pre-trained ViT and uses the corresponding outputs for
classification. To classify an image correctly, the true-class prompt must
attend to the unique image patches not seen in other classes' images, i.e.,
traits. As such, the true class's multi-head attention maps reveal traits and
their locations. Implementation-wise, Prompt-CAM is almost a free lunch by
simply modifying the prediction head of Visual Prompt Tuning (VPT). This makes
Prompt-CAM fairly easy to train and apply, sharply contrasting other
interpretable methods that design specific models and training processes. It is
even simpler than the recently published INterpretable TRansformer (INTR),
whose encoder-decoder architecture prevents it from leveraging pre-trained
ViTs. Extensive empirical studies on a dozen datasets from various domains
(e.g., birds, fishes, insects, fungi, flowers, food, and cars) validate
Prompt-CAM superior interpretation capability.

摘要：<paragraph>我們提出預訓練視覺Transformer (ViT) 的簡易用法，用於精細分析，旨在識別並定位區分視覺上類似類別的特徵，例如不同的鳥類物種或狗品種。預訓練的 ViT，例如 DINO，已展現出提取局部化資訊特徵的卓越能力。然而，使用像 Grad-CAM 的顯著性圖很難指出特徵：它們經常透過模糊、粗糙的熱圖定位整個物件，而不是特徵。我們提出了一種新穎的方法提示類別注意力圖 (Prompt-CAM) 來解決這個問題。Prompt-CAM 學習類別特定的提示，並將其提供給預訓練的 ViT，並使用對應的輸出進行分類。為了正確分類影像，真類提示必須注意其他類別影像中未見的獨特影像區塊，即特徵。因此，真類的多頭注意力圖揭示了特徵及其位置。在實作方面，Prompt-CAM 幾乎是免費的午餐，只需修改視覺提示調整 (VPT) 的預測頭部。這使得 Prompt-CAM 相當容易訓練和應用，與設計特定模型和訓練流程的其他可解釋方法形成鮮明對比。它甚至比最近發布的可解釋Transformer (INTR) 更簡單，其編碼器-解碼器架構使其無法利用預訓練的 ViT。對來自各種領域（例如鳥類、魚類、昆蟲、真菌、花卉、食物和汽車）的十幾個資料集進行的廣泛實證研究驗證了 Prompt-CAM 優越的解釋能力。</paragraph>

##### **Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks**
2501.09328v1 by Yixiao Xu, Binxing Fang, Rui Wang, Yinghai Zhou, Shouling Ji, Yuan Liu, Mohan Li, Zhihong Tian

Developing high-performance deep learning models is resource-intensive,
leading model owners to utilize Machine Learning as a Service (MLaaS) platforms
instead of publicly releasing their models. However, malicious users may
exploit query interfaces to execute model extraction attacks, reconstructing
the target model's functionality locally. While prior research has investigated
triggerable watermarking techniques for asserting ownership, existing methods
face significant challenges: (1) most approaches require additional training,
resulting in high overhead and limited flexibility, and (2) they often fail to
account for advanced attackers, leaving them vulnerable to adaptive attacks.
  In this paper, we propose Neural Honeytrace, a robust plug-and-play
watermarking framework against model extraction attacks. We first formulate a
watermark transmission model from an information-theoretic perspective,
providing an interpretable account of the principles and limitations of
existing triggerable watermarking. Guided by the model, we further introduce:
(1) a similarity-based training-free watermarking method for plug-and-play and
flexible watermarking, and (2) a distribution-based multi-step watermark
information transmission strategy for robust watermarking. Comprehensive
experiments on four datasets demonstrate that Neural Honeytrace outperforms
previous methods in efficiency and resisting adaptive attacks. Neural
Honeytrace reduces the average number of samples required for a worst-case
t-Test-based copyright claim from $12,000$ to $200$ with zero training cost.

摘要：開發高性能深度學習模型需要大量資源，因此模型所有者會使用機器學習即服務 (MLaaS) 平台，而不是公開發布他們的模型。但是，惡意使用者可能會利用查詢介面執行模型萃取攻擊，在本地重建目標模型的功能。雖然先前的研究已探討可觸發浮水印技術以宣示所有權，但現有方法面臨重大挑戰：(1) 大多數方法需要額外的訓練，導致高開銷和有限的彈性，以及 (2) 它們通常無法應對進階攻擊者，讓它們容易受到適應性攻擊。在本文中，我們提出 Neural Honeytrace，一個針對模型萃取攻擊的強大即插即用浮水印架構。我們首先從資訊理論的角度制定浮水印傳輸模型，提供可解釋的現有可觸發浮水印原理和限制說明。在模型的指導下，我們進一步介紹：(1) 一種基於相似性的免訓練浮水印方法，用於即插即用和彈性浮水印，以及 (2) 一種基於分佈的多步驟浮水印資訊傳輸策略，用於強大的浮水印。在四個資料集上的全面實驗表明，Neural Honeytrace 在效率和抵抗適應性攻擊方面優於先前的所有方法。Neural Honeytrace 將最差情況 t 測試版權聲明所需的平均範例數從 $12,000$ 減少到 $200$，且訓練成本為零。

##### **On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression**
2501.09327v1 by Zichang Ge, Changyu Chen, Arunesh Sinha, Pradeep Varakantham

In real-world sequential decision making tasks like autonomous driving,
robotics, and healthcare, learning from observed state-action trajectories is
critical for tasks like imitation, classification, and clustering. For example,
self-driving cars must replicate human driving behaviors, while robots and
healthcare systems benefit from modeling decision sequences, whether or not
they come from expert data. Existing trajectory encoding methods often focus on
specific tasks or rely on reward signals, limiting their ability to generalize
across domains and tasks. Inspired by the success of embedding models like CLIP
and BERT in static domains, we propose a novel method for embedding
state-action trajectories into a latent space that captures the skills and
competencies in the dynamic underlying decision-making processes. This method
operates without the need for reward labels, enabling better generalization
across diverse domains and tasks. Our contributions are threefold: (1) We
introduce a trajectory embedding approach that captures multiple abilities from
state-action data. (2) The learned embeddings exhibit strong representational
power across downstream tasks, including imitation, classification, clustering,
and regression. (3) The embeddings demonstrate unique properties, such as
controlling agent behaviors in IQ-Learn and an additive structure in the latent
space. Experimental results confirm that our method outperforms traditional
approaches, offering more flexible and powerful trajectory representations for
various applications. Our code is available at
https://github.com/Erasmo1015/vte.

摘要：在現實世界的順序決策制定任務中，例如自動駕駛、機器人和醫療保健，從觀察到的狀態動作軌跡中學習對於模仿、分類和群集等任務至關重要。例如，自動駕駛汽車必須複製人類駕駛行為，而機器人和醫療保健系統受益於對決策序列建模，無論這些序列是否來自專家數據。現有的軌跡編碼方法通常側重於特定任務或依賴獎勵信號，這限制了它們在不同領域和任務之間泛化的能力。受 CLIP 和 BERT 等嵌入模型在靜態領域中成功的啟發，我們提出了一種新方法，用於將狀態動作軌跡嵌入到一個潛在空間中，該空間捕獲了動態決策制定過程中技能和能力。此方法無需獎勵標籤，從而可以在不同的領域和任務中實現更好的泛化。我們的貢獻有三方面：（1）我們引入了一種軌跡嵌入方法，該方法從狀態動作數據中捕獲多種能力。（2）學習到的嵌入在包括模仿、分類、群集和回歸在內的下游任務中表現出強大的表示能力。（3）嵌入展示了獨特的屬性，例如在 IQ-Learn 中控制代理行為和在潛在空間中的加性結構。實驗結果證實，我們的方法優於傳統方法，為各種應用提供了更靈活、更強大的軌跡表示。我們的代碼可在 https://github.com/Erasmo1015/vte 中獲得。

##### **Algorithm for Semantic Network Generation from Texts of Low Resource Languages Such as Kiswahili**
2501.09326v1 by Barack Wamkaya Wanjawa, Lawrence Muchemi, Evans Miriti

Processing low-resource languages, such as Kiswahili, using machine learning
is difficult due to lack of adequate training data. However, such low-resource
languages are still important for human communication and are already in daily
use and users need practical machine processing tasks such as summarization,
disambiguation and even question answering (QA). One method of processing such
languages, while bypassing the need for training data, is the use semantic
networks. Some low resource languages, such as Kiswahili, are of the
subject-verb-object (SVO) structure, and similarly semantic networks are a
triple of subject-predicate-object, hence SVO parts of speech tags can map into
a semantic network triple. An algorithm to process raw natural language text
and map it into a semantic network is therefore necessary and desirable in
structuring low resource languages texts. This algorithm tested on the
Kiswahili QA task with upto 78.6% exact match.

摘要：處理低資源語言，例如斯瓦希里語，使用機器學習
由於缺乏足夠的訓練資料而困難。然而，這些低資源
語言對於人類溝通仍然很重要，並且已經在日常
使用，而使用者需要實用的機器處理任務，例如摘要、
消歧甚至問答 (QA)。處理此類語言的一種方法，同時繞過
訓練資料的需求，就是使用語義網路。一些低資源語言，例如斯瓦希里語，是主詞-動詞-受詞 (SVO) 結構，而語義網路類似地是主詞-謂詞-受詞的三元組，因此 SVO 詞性標記可以映射到語義網路三元組中。一種處理原始自然語言文字並將其映射到語義網路的演算法因此對於結構化低資源語言文字是必要且可取的。此演算法在斯瓦希里語問答任務上測試，最高可達 78.6% 的完全匹配。

##### **SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**
2501.09316v1 by Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You

Despite significant advancements in general-purpose AI agents, several
challenges still hinder their practical application in real-world scenarios.
First, the limited planning capabilities of Large Language Models (LLM)
restrict AI agents from effectively solving complex tasks that require
long-horizon planning. Second, general-purpose AI agents struggle to
efficiently utilize domain-specific knowledge and human expertise. In this
paper, we introduce the Standard Operational Procedure-guided Agent
(SOP-agent), a novel framework for constructing domain-specific agents through
pseudocode-style Standard Operational Procedures (SOPs) written in natural
language. Formally, we represent a SOP as a decision graph, which is traversed
to guide the agent in completing tasks specified by the SOP. We conduct
extensive experiments across tasks in multiple domains, including
decision-making, search and reasoning, code generation, data cleaning, and
grounded customer service. The SOP-agent demonstrates excellent versatility,
achieving performance superior to general-purpose agent frameworks and
comparable to domain-specific agent systems. Additionally, we introduce the
Grounded Customer Service Benchmark, the first benchmark designed to evaluate
the grounded decision-making capabilities of AI agents in customer service
scenarios based on SOPs.

摘要：儘管通用 AI 代理在一般用途上取得顯著進展，但仍有數項挑戰阻礙其在實際場景中的實用應用。
首先，大型語言模型 (LLM) 有限的規劃能力限制了 AI 代理有效解決需要長期規劃的複雜任務。其次，通用 AI 代理難以有效利用特定領域的知識和人類專業知識。在本文中，我們介紹了標準操作程序引導代理 (SOP-agent)，這是一個透過以自然語言撰寫的偽代碼風格標準操作程序 (SOP) 來建構特定領域代理的新穎架構。正式來說，我們將 SOP 表示為決策圖，並在其中穿梭以引導代理完成 SOP 指定的任務。我們在多個領域中的任務中進行廣泛的實驗，包括決策制定、搜尋和推理、程式碼生成、資料清理和基礎客戶服務。SOP-agent 展示出卓越的多功能性，其效能優於通用代理架構，且與特定領域代理系統相當。此外，我們介紹了基礎客戶服務基準，這是第一個基準，旨在評估 AI 代理在基於 SOP 的客戶服務場景中基礎決策制定能力。

##### **A Study of In-Context-Learning-Based Text-to-SQL Errors**
2501.09310v1 by Jiawei Shen, Chengcheng Wan, Ruoyi Qiao, Jiazhen Zou, Hang Xu, Yuchen Shao, Yueling Zhang, Weikai Miao, Geguang Pu

Large language models (LLMs) have been adopted to perform text-to-SQL tasks,
utilizing their in-context learning (ICL) capability to translate natural
language questions into structured query language (SQL). However, such a
technique faces correctness problems and requires efficient repairing
solutions. In this paper, we conduct the first comprehensive study of
text-to-SQL errors. Our study covers four representative ICL-based techniques,
five basic repairing methods, two benchmarks, and two LLM settings. We find
that text-to-SQL errors are widespread and summarize 29 error types of 7
categories. We also find that existing repairing attempts have limited
correctness improvement at the cost of high computational overhead with many
mis-repairs. Based on the findings, we propose MapleRepair, a novel text-to-SQL
error detection and repairing framework. The evaluation demonstrates that
MapleRepair outperforms existing solutions by repairing 13.8% more queries with
neglectable mis-repairs and 67.4% less overhead.

摘要：大型語言模型 (LLM) 已被採用來執行文字轉 SQL 任務，
利用其情境學習 (ICL) 能力將自然語言問題轉換為結構化查詢語言 (SQL)。然而，這種技術面臨正確性的問題，需要有效的修復解決方案。在本文中，我們進行了首次關於文字轉 SQL 錯誤的全面研究。我們的研究涵蓋四種具有代表性的基於 ICL 的技術、五種基本的修復方法、兩個基準測試和兩個 LLM 設定。我們發現文字轉 SQL 錯誤很普遍，並總結了 7 類別的 29 種錯誤類型。我們還發現，現有的修復嘗試以高運算成本為代價，導致許多錯誤修復，其正確性改進有限。根據這些發現，我們提出了 MapleRepair，一種新穎的文字轉 SQL 錯誤偵測和修復架構。評估結果證明，MapleRepair 優於現有解決方案，以可忽略的錯誤修復修復了多 13.8% 的查詢，並減少了 67.4% 的開銷。

##### **Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation**
2501.09309v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

This review underscores the critical need for effective strategies to
identify and support individuals with suicidal ideation, exploiting
technological innovations in ML and DL to further suicide prevention efforts.
The study details the application of these technologies in analyzing vast
amounts of unstructured social media data to detect linguistic patterns,
keywords, phrases, tones, and contextual cues associated with suicidal
thoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural
networks, and their effectiveness in interpreting complex data patterns and
emotional nuances within text data. The review discusses the potential of these
technologies to serve as a life-saving tool by identifying at-risk individuals
through their digital traces. Furthermore, it evaluates the real-world
effectiveness, limitations, and ethical considerations of employing these
technologies for suicide prevention, stressing the importance of responsible
development and usage. The study aims to fill critical knowledge gaps by
analyzing recent studies, methodologies, tools, and techniques in this field.
It highlights the importance of synthesizing current literature to inform
practical tools and suicide prevention efforts, guiding innovation in reliable,
ethical systems for early intervention. This research synthesis evaluates the
intersection of technology and mental health, advocating for the ethical and
responsible application of ML, DL, and NLP to offer life-saving potential
worldwide while addressing challenges like generalizability, biases, privacy,
and the need for further research to ensure these technologies do not
exacerbate existing inequities and harms.

摘要：這篇評論強調了有效策略的重要需求，以透過利用機器學習和深度學習的技術創新來識別和支持有自殺意念的人，進一步促進自殺防治工作。這項研究詳細說明了這些技術在分析大量非結構化社群媒體資料中的應用，以偵測與自殺念頭相關的語言模式、關鍵字、詞組、語氣和脈絡線索。它探討了各種機器學習和深度學習模型，例如支援向量機、卷積神經網路、長短期記憶網路、神經網路，以及它們在解讀文字資料中的複雜資料模式和情緒細微差別方面的效能。這篇評論討論了這些技術作為救命工具的潛力，透過數位足跡來識別有風險的個人。此外，它評估了採用這些技術進行自殺防治的實際效能、限制和道德考量，強調負責任的開發和使用的重要性。這項研究旨在透過分析這個領域的近期研究、方法、工具和技術，填補重要的知識差距。它強調了綜合現有文獻對於提供實用工具和自殺防治工作的重要性，引導在早期介入中建立可靠的、符合道德的系統的創新。這項研究綜合評估了技術和心理健康之間的交集，倡導道德且負責任地應用機器學習、深度學習和自然語言處理，以提供全球性的救命潛力，同時解決概括性、偏誤、隱私等挑戰，並需要進一步研究以確保這些技術不會加劇現有的不平等和傷害。

##### **Efficient Few-Shot Medical Image Analysis via Hierarchical Contrastive Vision-Language Learning**
2501.09294v1 by Harrison Fuller, Fernando Gabriela Garcia, Victor Flores

Few-shot learning in medical image classification presents a significant
challenge due to the limited availability of annotated data and the complex
nature of medical imagery. In this work, we propose Adaptive Vision-Language
Fine-tuning with Hierarchical Contrastive Alignment (HiCA), a novel framework
that leverages the capabilities of Large Vision-Language Models (LVLMs) for
medical image analysis. HiCA introduces a two-stage fine-tuning strategy,
combining domain-specific pretraining and hierarchical contrastive learning to
align visual and textual representations at multiple levels. We evaluate our
approach on two benchmark datasets, Chest X-ray and Breast Ultrasound,
achieving state-of-the-art performance in both few-shot and zero-shot settings.
Further analyses demonstrate the robustness, generalizability, and
interpretability of our method, with substantial improvements in performance
compared to existing baselines. Our work highlights the potential of
hierarchical contrastive strategies in adapting LVLMs to the unique challenges
of medical imaging tasks.

摘要：醫療影像分類中的少量學習由於標註資料的取得有限以及醫療影像的複雜性而產生了重大的挑戰。在這項工作中，我們提出了一個自適應視覺語言微調，具有分層對比對齊（HiCA），一個新穎的架構，它運用大型視覺語言模型（LVLMs）的能力進行醫療影像分析。HiCA 導入了一個兩階段微調策略，結合特定領域的預訓練和分層對比學習，以在多個層級對齊視覺和文字表徵。我們在兩個基準資料集，胸部 X 光和乳房超音波上評估我們的做法，在少量和零次學習設定中都達到最先進的表現。進一步的分析證明了我們方法的穩健性、概括性和可解釋性，與現有的基線相比，在表現上有了顯著的提升。我們的研究強調了分層對比策略在適應 LVLMs 以應對醫療影像任務的獨特挑戰上的潛力。

##### **To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation**
2501.09292v1 by Kaustubh D. Dhole

Retrieval-Augmented Generation equips large language models with the
capability to retrieve external knowledge, thereby mitigating hallucinations by
incorporating information beyond the model's intrinsic abilities. However, most
prior works have focused on invoking retrieval deterministically, which makes
it unsuitable for tasks such as long-form question answering. Instead,
dynamically performing retrieval by invoking it only when the underlying LLM
lacks the required knowledge can be more efficient. In this context, we delve
deeper into the question, "To Retrieve or Not to Retrieve?" by exploring
multiple uncertainty detection methods. We evaluate these methods for the task
of long-form question answering, employing dynamic retrieval, and present our
comparisons. Our findings suggest that uncertainty detection metrics, such as
Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval
calls by almost half, with only a slight reduction in question-answering
accuracy.

摘要：檢索增強生成為大型語言模型配備檢索外部知識的能力，從而通過整合模型內在能力之外的資訊來減輕幻覺。然而，大多數先前的研究都集中在確定性地調用檢索，這使得它不適合於長篇問題解答等任務。相反，僅在底層 LLM 缺乏所需知識時才通過調用它來動態執行檢索會更有效率。在此背景下，我們深入探討了「檢索還是不檢索？」這個問題，方法是探索多種不確定性檢測方法。我們評估了這些方法在長篇問題解答任務中的作用，採用動態檢索，並展示了我們的比較結果。我們的研究結果表明，不確定性檢測指標，例如度矩陣 Jaccard 和偏心率，可以將檢索呼叫的數量減少近一半，而問題解答準確性僅略有下降。

##### **LAVCap: LLM-based Audio-Visual Captioning using Optimal Transport**
2501.09291v1 by Kyeongha Rho, Hyeongkeun Lee, Valentio Iverson, Joon Son Chung

Automated audio captioning is a task that generates textual descriptions for
audio content, and recent studies have explored using visual information to
enhance captioning quality. However, current methods often fail to effectively
fuse audio and visual data, missing important semantic cues from each modality.
To address this, we introduce LAVCap, a large language model (LLM)-based
audio-visual captioning framework that effectively integrates visual
information with audio to improve audio captioning performance. LAVCap employs
an optimal transport-based alignment loss to bridge the modality gap between
audio and visual features, enabling more effective semantic extraction.
Additionally, we propose an optimal transport attention module that enhances
audio-visual fusion using an optimal transport assignment map. Combined with
the optimal training strategy, experimental results demonstrate that each
component of our framework is effective. LAVCap outperforms existing
state-of-the-art methods on the AudioCaps dataset, without relying on large
datasets or post-processing. Code is available at
https://github.com/NAVER-INTEL-Co-Lab/gaudi-lavcap.

摘要：自動化音訊字幕製作是一種為音訊內容產生文字描述的任務，而最近的研究已探討使用視覺資訊來提升字幕品質。然而，目前的技術通常無法有效融合音訊和視覺資料，錯失了各個方式的重要語意提示。為了解決這個問題，我們引入了 LAVCap，一個大型語言模型 (LLM) 為基礎的音訊視覺字幕製作架構，它有效地將視覺資訊與音訊整合，以提升音訊字幕製作的表現。LAVCap 採用基於最優傳輸的對齊損失來橋接音訊和視覺特徵之間的方式差距，進而實現更有效的語意萃取。此外，我們提出了一個最優傳輸注意力模組，它使用最優傳輸分配圖來提升音訊視覺融合。結合最優訓練策略，實驗結果證明了我們架構的各個組成部分都十分有效。LAVCap 在 AudioCaps 資料集上優於現有的最先進技術，而且並未依賴大型資料集或後處理。程式碼可於 https://github.com/NAVER-INTEL-Co-Lab/gaudi-lavcap 取得。

##### **SEAL: Entangled White-box Watermarks on Low-Rank Adaptation**
2501.09284v1 by Giyeong Oh, Seajin Kim, Woohyun Cho, Sangkyu Lee, Jiwan Chung, Dokyung Song, Youngjae Yu

Recently, LoRA and its variants have become the de facto strategy for
training and sharing task-specific versions of large pretrained models, thanks
to their efficiency and simplicity. However, the issue of copyright protection
for LoRA weights, especially through watermark-based techniques, remains
underexplored. To address this gap, we propose SEAL (SEcure wAtermarking on
LoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds a
secret, non-trainable matrix between trainable LoRA weights, serving as a
passport to claim ownership. SEAL then entangles the passport with the LoRA
weights through training, without extra loss for entanglement, and distributes
the finetuned weights after hiding the passport. When applying SEAL, we
observed no performance degradation across commonsense reasoning,
textual/visual instruction tuning, and text-to-image synthesis tasks. We
demonstrate that SEAL is robust against a variety of known attacks: removal,
obfuscation, and ambiguity attacks.

摘要：最近，LoRA 及其变体已成为训练和分享大型预训练模型的任务特定版本的实际策略，这要归功于其效率和简单性。然而，LoRA 权重的版权保护问题，特别是通过基于水印的技术，仍未得到充分探索。为了解决这一差距，我们提出了 SEAL（LoRA 权重的安全水印），即 LoRA 的通用白盒水印。SEAL 在可训练的 LoRA 权重之间嵌入了一个秘密的、不可训练的矩阵，作为索取所有权的护照。然后，SEAL 通过训练将护照与 LoRA 权重纠缠在一起，而无需额外的纠缠损失，并在隐藏护照后分发微调后的权重。在应用 SEAL 时，我们观察到在常识推理、文本/视觉指令微调和文本到图像合成任务中没有性能下降。我们证明了 SEAL 对于各种已知攻击是鲁棒的：移除、混淆和歧义攻击。

##### **Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**
2501.09279v1 by Zijin Qiu, Jiepeng Liu, Yi Xia, Hongtuo Qi, Pengkun Liu

Flexibility in the AI-based residential layout design remains a significant
challenge, as traditional methods like rule-based heuristics and graph-based
generation often lack flexibility and require substantial design knowledge from
users. To address these limitations, we propose a cross-modal design approach
based on the Stable Diffusion model for generating flexible residential
layouts. The method offers multiple input types for learning objectives,
allowing users to specify both boundaries and layouts. It incorporates natural
language as design constraints and introduces ControlNet to enable stable
layout generation through two distinct pathways. We also present a scheme that
encapsulates design expertise within a knowledge graph and translates it into
natural language, providing an interpretable representation of design
knowledge. This comprehensibility and diversity of input options enable
professionals and non-professionals to directly express design requirements,
enhancing flexibility and controllability. Finally, experiments verify the
flexibility of the proposed methods under multimodal constraints better than
state-of-the-art models, even when specific semantic information about room
areas or connections is incomplete.

摘要：在基於 AI 的住宅佈局設計中，靈活性仍是一項重大挑戰，因為基於規則的啟發法和基於圖形的產生等傳統方法通常缺乏靈活性，且需要使用者具備大量的設計知識。為了解決這些限制，我們提出一個跨模態設計方法，該方法基於 Stable Diffusion 模型，用於產生靈活的住宅佈局。此方法提供多種輸入類型以進行學習目標，使用戶能夠同時指定邊界和佈局。它將自然語言作為設計約束，並引入 ControlNet，以透過兩個不同的路徑實現穩定的佈局產生。我們還提出了一個將設計專業知識封裝在知識圖形中的方案，並將其轉換為自然語言，提供設計知識的可詮釋表示。這種可理解性和輸入選項的多樣性使專業人士和非專業人士能夠直接表達設計需求，從而增強靈活性與可控性。最後，實驗驗證了所提出的方法在多模態約束下的靈活性優於最先進的模型，即使關於房間區域或連接的特定語義資訊不完整時也是如此。

##### **Large Language Model is Secretly a Protein Sequence Optimizer**
2501.09274v1 by Yinkai Wang, Jiaxing He, Yuanqi Du, Xiaohui Chen, Jianan Canal Li, Li-Ping Liu, Xiaolin Xu, Soha Hassoun

We consider the protein sequence engineering problem, which aims to find
protein sequences with high fitness levels, starting from a given wild-type
sequence. Directed evolution has been a dominating paradigm in this field which
has an iterative process to generate variants and select via experimental
feedback. We demonstrate large language models (LLMs), despite being trained on
massive texts, are secretly protein sequence optimizers. With a directed
evolutionary method, LLM can perform protein engineering through Pareto and
experiment-budget constrained optimization, demonstrating success on both
synthetic and experimental fitness landscapes.

摘要：我們考慮蛋白質序列工程問題，其目標是從給定的野生型序列中找到具有高適應度等級的蛋白質序列。定向演化一直是此領域的主導範例，它有一個迭代過程，用於生成變體並透過實驗反饋進行選擇。我們證明了大型語言模型 (LLM)，儘管是在大量文字上訓練，但卻是秘密的蛋白質序列最佳化器。透過定向演化方法，LLM 可以透過帕累托和實驗預算受限最佳化執行蛋白質工程，證明在合成和實驗適應度環境中都獲得成功。

##### **Perspective Transition of Large Language Models for Solving Subjective Tasks**
2501.09265v1 by Xiaolong Wang, Yuanchi Zhang, Ziyue Wang, Yuzhuang Xu, Fuwen Luo, Yile Wang, Peng Li, Yang Liu

Large language models (LLMs) have revolutionized the field of natural
language processing, enabling remarkable progress in various tasks. Different
from objective tasks such as commonsense reasoning and arithmetic
question-answering, the performance of LLMs on subjective tasks is still
limited, where the perspective on the specific problem plays crucial roles for
better interpreting the context and giving proper response. For example, in
certain scenarios, LLMs may perform better when answering from an expert role
perspective, potentially eliciting their relevant domain knowledge. In
contrast, in some scenarios, LLMs may provide more accurate responses when
answering from a third-person standpoint, enabling a more comprehensive
understanding of the problem and potentially mitigating inherent biases. In
this paper, we propose Reasoning through Perspective Transition (RPT), a method
based on in-context learning that enables LLMs to dynamically select among
direct, role, and third-person perspectives for the best way to solve
corresponding subjective problem. Through extensive experiments on totally 12
subjective tasks by using both closed-source and open-source LLMs including
GPT-4, GPT-3.5, Llama-3, and Qwen-2, our method outperforms widely used single
fixed perspective based methods such as chain-of-thought prompting and expert
prompting, highlights the intricate ways that LLMs can adapt their perspectives
to provide nuanced and contextually appropriate responses for different
problems.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理領域，在各種任務中實現了顯著進展。與常識推理和算術問答等客觀任務不同，LLM 在主觀任務上的表現仍然有限，其中對特定問題的觀點對於更好地詮釋脈絡和給出適當的回應至關重要。例如，在某些情況下，LLM 在從專家角色的角度回答問題時可能會表現得更好，從而潛在地引發他們相關的領域知識。相比之下，在某些情況下，LLM 在從第三人稱角度回答問題時可能會提供更準確的回應，從而能夠更全面地理解問題並潛在地減輕固有偏見。在本文中，我們提出了基於情境學習的推理透視轉換 (RPT) 方法，使 LLM 能夠在直接、角色和第三人稱視角中動態選擇，以找到解決相應主觀問題的最佳方式。通過在使用閉源和開源 LLM（包括 GPT-4、GPT-3.5、Llama-3 和 Qwen-2）的 12 項主觀任務上進行廣泛的實驗，我們的模型優於廣泛使用的基於單一固定視角的方法，例如思想鏈提示和專家提示，突出了 LLM 可以調整其視角以針對不同的問題提供細緻入微且符合情境的回應的複雜方式。

##### **Delayed Fusion: Integrating Large Language Models into First-Pass Decoding in End-to-end Speech Recognition**
2501.09258v1 by Takaaki Hori, Martin Kocour, Adnan Haider, Erik McDermott, Xiaodan Zhuang

This paper presents an efficient decoding approach for end-to-end automatic
speech recognition (E2E-ASR) with large language models (LLMs). Although
shallow fusion is the most common approach to incorporate language models into
E2E-ASR decoding, we face two practical problems with LLMs. (1) LLM inference
is computationally costly. (2) There may be a vocabulary mismatch between the
ASR model and the LLM. To resolve this mismatch, we need to retrain the ASR
model and/or the LLM, which is at best time-consuming and in many cases not
feasible. We propose "delayed fusion," which applies LLM scores to ASR
hypotheses with a delay during decoding and enables easier use of pre-trained
LLMs in ASR tasks. This method can reduce not only the number of hypotheses
scored by the LLM but also the number of LLM inference calls. It also allows
re-tokenizion of ASR hypotheses during decoding if ASR and LLM employ different
tokenizations. We demonstrate that delayed fusion provides improved decoding
speed and accuracy compared to shallow fusion and N-best rescoring using the
LibriHeavy ASR corpus and three public LLMs, OpenLLaMA 3B & 7B and Mistral 7B.

摘要：本文提出了一個高效的解碼方法，用於具有大型語言模型 (LLM) 的端到端自動語音識別 (E2E-ASR)。儘管淺層融合是最常見的方法，可以將語言模型納入 E2E-ASR 解碼中，但我們在使用 LLM 時面臨兩個實際問題。(1) LLM 推論在計算上成本高昂。(2) ASR 模型和 LLM 之間可能存在詞彙不匹配。為了解決這種不匹配，我們需要重新訓練 ASR 模型和/或 LLM，這在最好的情況下很耗時，在許多情況下不可行。我們提出「延遲融合」，它在解碼過程中將 LLM 分數應用於 ASR 假設，並使在 ASR 任務中更輕鬆地使用預訓練的 LLM。此方法不僅可以減少 LLM 評分假設的數量，還可以減少 LLM 推論呼叫的數量。如果 ASR 和 LLM 使用不同的標記化，它還允許在解碼過程中重新對 ASR 假設進行標記化。我們證明，與使用 LibriHeavy ASR 語料庫和三個公共 LLM（OpenLLaMA 3B 和 7B 以及 Mistral 7B）的淺層融合和 N 最佳重新評分相比，延遲融合提供了改進的解碼速度和準確性。

##### **Clone-Robust AI Alignment**
2501.09254v1 by Ariel D. Procaccia, Benjamin Schiffer, Shirley Zhang

A key challenge in training Large Language Models (LLMs) is properly aligning
them with human preferences. Reinforcement Learning with Human Feedback (RLHF)
uses pairwise comparisons from human annotators to train reward functions and
has emerged as a popular alignment method. However, input datasets in RLHF are
not necessarily balanced in the types of questions and answers that are
included. Therefore, we want RLHF algorithms to perform well even when the set
of alternatives is not uniformly distributed. Drawing on insights from social
choice theory, we introduce robustness to approximate clones, a desirable
property of RLHF algorithms which requires that adding near-duplicate
alternatives does not significantly change the learned reward function. We
first demonstrate that the standard RLHF algorithm based on regularized maximum
likelihood estimation (MLE) fails to satisfy this property. We then propose the
weighted MLE, a new RLHF algorithm that modifies the standard regularized MLE
by weighting alternatives based on their similarity to other alternatives. This
new algorithm guarantees robustness to approximate clones while preserving
desirable theoretical properties.

摘要：訓練大型語言模型 (LLM) 時的一項關鍵挑戰是適當地將其與人類偏好結合。人類回饋強化學習 (RLHF) 使用來自人類註解者的成對比較來訓練獎勵函數，並已成為一種流行的結合方法。然而，RLHF 中的輸入資料集在所包含的問答類型中不一定平衡。因此，我們希望 RLHF 演算法即使在替代方案集沒有均勻分佈時也能表現良好。借鑒社會選擇理論的見解，我們引入了對近似克隆的穩健性，這是 RLHF 演算法的一項理想特性，它要求加入近似重複的替代方案不會顯著改變已學習的獎勵函數。我們首先證明基於正則化最大似然估計 (MLE) 的標準 RLHF 演算法無法滿足此特性。然後我們提出加權 MLE，這是一種新的 RLHF 演算法，它透過根據替代方案與其他替代方案的相似性對替代方案加權來修改標準正則化 MLE。這種新演算法保證了對近似克隆的穩健性，同時保留了理想的理論特性。

##### **Foundations of Large Language Models**
2501.09223v1 by Tong Xiao, Jingbo Zhu

This is a book about large language models. As indicated by the title, it
primarily focuses on foundational concepts rather than comprehensive coverage
of all cutting-edge technologies. The book is structured into four main
chapters, each exploring a key area: pre-training, generative models, prompting
techniques, and alignment methods. It is intended for college students,
professionals, and practitioners in natural language processing and related
fields, and can serve as a reference for anyone interested in large language
models.

摘要：這是一本關於大型語言模型的書。如標題所示，它主要關注基礎概念，而不是全面涵蓋所有尖端技術。本書分為四個主要章節，每個章節探討一個關鍵領域：預訓練、生成模型、提示技術和對齊方法。它適用於自然語言處理及相關領域的學生、專業人士和從業者，並可作為任何有興趣了解大型語言模型的人的參考。

##### **A Simple Graph Contrastive Learning Framework for Short Text Classification**
2501.09219v1 by Yonghao Liu, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan

Short text classification has gained significant attention in the information
age due to its prevalence and real-world applications. Recent advancements in
graph learning combined with contrastive learning have shown promising results
in addressing the challenges of semantic sparsity and limited labeled data in
short text classification. However, existing models have certain limitations.
They rely on explicit data augmentation techniques to generate contrastive
views, resulting in semantic corruption and noise. Additionally, these models
only focus on learning the intrinsic consistency between the generated views,
neglecting valuable discriminative information from other potential views. To
address these issues, we propose a Simple graph contrastive learning framework
for Short Text Classification (SimSTC). Our approach involves performing graph
learning on multiple text-related component graphs to obtain multi-view text
embeddings. Subsequently, we directly apply contrastive learning on these
embeddings. Notably, our method eliminates the need for data augmentation
operations to generate contrastive views while still leveraging the benefits of
multi-view contrastive learning. Despite its simplicity, our model achieves
outstanding performance, surpassing large language models on various datasets.

摘要：短文本分类在信息时代得到了广泛关注，因为它具有普遍性和现实世界的应用。最近，图学习与对比学习相结合的进步在解决短文本分类中语义稀疏性和标记数据有限的挑战方面显示出有希望的结果。然而，现有的模型具有一定的局限性。它们依赖于显式的数据增强技术来生成对比视图，从而导致语义损坏和噪声。此外，这些模型只关注学习生成视图之间的内在一致性，而忽略了其他潜在视图中有价值的判别信息。为了解决这些问题，我们提出了一个用于短文本分类的简单图对比学习框架 (SimSTC)。我们的方法涉及对多个文本相关组件图执行图学习以获得多视图文本嵌入。随后，我们直接对这些嵌入应用对比学习。值得注意的是，我们的方法消除了生成对比视图时对数据增强操作的需求，同时仍然利用了多视图对比学习的优势。尽管很简单，但我们的模型获得了出色的性能，在各种数据集上超越了大型语言模型。

##### **Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics**
2501.09218v1 by Yuanyuan Wei, Yucheng Wu, Fuyang Qu, Yao Mu, Yi-Ping Ho, Ho-Pui Ho, Wu Yuan, Mingkun Xu

Accurate molecular quantification is essential for advancing research and
diagnostics in fields such as infectious diseases, cancer biology, and genetic
disorders. Droplet digital PCR (ddPCR) has emerged as a gold standard for
achieving absolute quantification. While computational ddPCR technologies have
advanced significantly, achieving automatic interpretation and consistent
adaptability across diverse operational environments remains a challenge. To
address these limitations, we introduce the intelligent interpretable droplet
digital PCR (I2ddPCR) assay, a comprehensive framework integrating front-end
predictive models (for droplet segmentation and classification) with GPT-4o
multimodal large language model (MLLM, for context-aware explanations and
recommendations) to automate and enhance ddPCR image analysis. This approach
surpasses the state-of-the-art models, affording 99.05% accuracy in processing
complex ddPCR images containing over 300 droplets per image with varying
signal-to-noise ratios (SNRs). By combining specialized neural networks and
large language models, the I2ddPCR assay offers a robust and adaptable solution
for absolute molecular quantification, achieving a sensitivity capable of
detecting low-abundance targets as low as 90.32 copies/{\mu}L. Furthermore, it
improves model's transparency through detailed explanation and troubleshooting
guidance, empowering users to make informed decisions. This innovative
framework has the potential to benefit molecular diagnostics, disease research,
and clinical applications, especially in resource-constrained settings.

摘要：準確的分子量化對於推進傳染病、癌症生物學和遺傳疾病等領域的研究和診斷至關重要。飛沫數位 PCR (ddPCR) 已成為實現絕對量化的黃金標準。儘管運算式 ddPCR 技術已大幅進步，但在不同操作環境中實現自動化解讀和一致的適應性仍然是一項挑戰。為了解決這些限制，我們引入了智慧可解讀飛沫數位 PCR (I2ddPCR) 分析，一個整合前瞻性預測模型（用於飛沫分割和分類）與 GPT-4o 多模態大型語言模型（MLLM，用於情境感知解釋和建議）的綜合架構，以自動化並增強 ddPCR 影像分析。此方法超越了最先進的模型，在處理每張影像含有超過 300 個飛沫且信噪比 (SNR) 不同的複雜 ddPCR 影像時，準確度高達 99.05%。透過結合專門的神經網路和大型語言模型，I2ddPCR 分析提供了一個強健且適應性高的絕對分子量化解決方案，靈敏度高，能偵測低至 90.32 個拷貝數/{\mu}L 的低豐度目標。此外，它透過詳細的說明和故障排除指南來提升模型的透明度，使用戶能夠做出明智的決策。這個創新的架構有潛力造福分子診斷、疾病研究和臨床應用，特別是在資源受限的環境中。

##### **Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**
2501.09214v1 by Yonghao Liu, Mengyu Li, Wei Pang, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan

Short text classification, as a research subtopic in natural language
processing, is more challenging due to its semantic sparsity and insufficient
labeled samples in practical scenarios. We propose a novel model named
MI-DELIGHT for short text classification in this work. Specifically, it first
performs multi-source information (i.e., statistical information, linguistic
information, and factual information) exploration to alleviate the sparsity
issues. Then, the graph learning approach is adopted to learn the
representation of short texts, which are presented in graph forms. Moreover, we
introduce a dual-level (i.e., instance-level and cluster-level) contrastive
learning auxiliary task to effectively capture different-grained contrastive
information within massive unlabeled data. Meanwhile, previous models merely
perform the main task and auxiliary tasks in parallel, without considering the
relationship among tasks. Therefore, we introduce a hierarchical architecture
to explicitly model the correlations between tasks. We conduct extensive
experiments across various benchmark datasets, demonstrating that MI-DELIGHT
significantly surpasses previous competitive models. It even outperforms
popular large language models on several datasets.

摘要：短文本分類作為自然語言處理的研究子主題，由於其語義稀疏性和實際場景中標記樣本不足，因此更具挑戰性。在這項工作中，我們提出了一個名為 MI-DELIGHT 的新模型，用於短文本分類。具體來說，它首先執行多源信息（即統計信息、語言信息和事實信息）探索，以緩解稀疏性問題。然後，採用圖學習方法來學習以圖表形式呈現的短文本的表示。此外，我們引入了一個雙層級（即實例層級和群集層級）對比學習輔助任務，以有效捕獲大量未標記數據中的不同粒度對比信息。同時，以前的模型僅並行執行主任務和輔助任務，而沒有考慮任務之間的關係。因此，我們引入了一個分層架構來明確建模任務之間的相關性。我們在各種基準數據集上進行了廣泛的實驗，證明 MI-DELIGHT 明顯優於以前的競爭模型。它甚至在幾個數據集上優於流行的大語言模型。

##### **FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training**
2501.09213v1 by Hongzhou Yu, Tianhao Cheng, Ying Cheng, Rui Feng

Recent advancements in large language models (LLMs) have shown promise in
medical applications such as disease diagnosis and treatment planning. However,
most existing medical LLMs struggle with the advanced reasoning required for
complex clinical scenarios, such as differential diagnosis or personalized
treatment suggestions. We proposed FineMedLM-o1, which leverages high-quality
synthetic medical data and long-form reasoning data for Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO), enabling advanced dialogue and
deep reasoning capabilities. Additionally, we introduced Test-Time Training
(TTT) in the medical domain for the first time, facilitating domain adaptation
and ensuring reliable, accurate reasoning. Experimental results demonstrate
that FineMedLM-o1 achieves a 23% average performance improvement over prior
models on key medical benchmarks. Furthermore, the introduction of TTT provides
an additional 14% performance boost, highlighting its effectiveness in
enhancing medical reasoning capabilities. To support this process, we also
proposed a novel method for synthesizing medical dialogue. Compared to other
open-source datasets, our dataset stands out as superior in both quality and
complexity. The project and data will be released on GitHub.

摘要：大型語言模型 (LLM) 的最新進展已在疾病診斷和治療規劃等醫療應用中展現出前景。然而，現有的醫療 LLM 大多難以應對複雜臨床情境所需的進階推理，例如鑑別診斷或個人化治療建議。我們提出了 FineMedLM-o1，它利用優質的合成醫療數據和長篇推理數據進行監督微調 (SFT) 和直接偏好最佳化 (DPO)，實現進階對話和深度推理能力。此外，我們首次在醫療領域引入了測試時訓練 (TTT)，促進領域適應並確保推理可靠且準確。實驗結果表明，FineMedLM-o1 在主要醫療基準上比先前的模型平均提升了 23% 的效能。此外，TTT 的引入提供了額外的 14% 效能提升，凸顯其在增強醫療推理能力方面的有效性。為了支援此流程，我們還提出了一種合成醫療對話的新方法。與其他開源數據集相比，我們的數據集在品質和複雜性方面都脫穎而出。該專案和數據將在 GitHub 上發布。

##### **Grounding Text-To-Image Diffusion Models For Controlled High-Quality Image Generation**
2501.09194v1 by Ahmad Süleyman, Göksel Biricik

Large-scale text-to-image (T2I) diffusion models have demonstrated an
outstanding performance in synthesizing diverse high-quality visuals from
natural language text captions. Multiple layout-to-image models have been
developed to control the generation process by utilizing a broad array of
layouts such as segmentation maps, edges, and human keypoints. In this work, we
present ObjectDiffusion, a model that takes inspirations from the top
cutting-edge image generative frameworks to seamlessly condition T2I models
with new bounding boxes capabilities. Specifically, we make substantial
modifications to the network architecture introduced in ContorlNet to integrate
it with the condition processing and injection techniques proposed in GLIGEN.
ObjectDiffusion is initialized with pretraining parameters to leverage the
generation knowledge obtained from training on large-scale datasets. We
fine-tune ObjectDiffusion on the COCO2017 training dataset and evaluate it on
the COCO2017 validation dataset. Our model achieves an AP$_{50}$ of 46.6, an AR
of 44.5, and a FID of 19.8 outperforming the current SOTA model trained on
open-source datasets in all of the three metrics. ObjectDiffusion demonstrates
a distinctive capability in synthesizing diverse, high-quality, high-fidelity
images that seamlessly conform to the semantic and spatial control layout.
Evaluated in qualitative and quantitative tests, ObjectDiffusion exhibits
remarkable grounding abilities on closed-set and open-set settings across a
wide variety of contexts. The qualitative assessment verifies the ability of
ObjectDiffusion to generate multiple objects of different sizes and locations.

摘要：<paragraph>大型文本到图像 (T2I) 扩散模型已展示出从自然语言文本描述中合成各种高质量视觉效果的出色性能。已开发出多种布局到图像模型，通过利用分割图、边缘和人体关键点等广泛的布局来控制生成过程。在这项工作中，我们提出了 ObjectDiffusion，该模型从顶尖的图像生成框架中汲取灵感，以无缝的方式为 T2I 模型提供新的边界框功能。具体来说，我们对 ContorlNet 中引入的网络架构进行了实质性修改，以将其与 GLIGEN 中提出的条件处理和注入技术集成在一起。ObjectDiffusion 使用预训练参数进行初始化，以利用从大规模数据集训练中获得的生成知识。我们在 COCO2017 训练数据集上对 ObjectDiffusion 进行了微调，并在 COCO2017 验证数据集上对其进行了评估。我们的模型在所有三个指标上都优于在开源数据集上训练的当前 SOTA 模型，获得了 46.6 的 AP$_{50}$、44.5 的 AR 和 19.8 的 FID。ObjectDiffusion 展示了合成多样化、高质量、高保真图像的独特能力，这些图像无缝符合语义和空间控制布局。在定性和定量测试中进行评估，ObjectDiffusion 在各种背景下的封闭集和开放集设置中表现出非凡的基础能力。定性评估验证了 ObjectDiffusion 生成不同大小和位置的多个对象的能力。</paragraph>

##### **Patch-aware Vector Quantized Codebook Learning for Unsupervised Visual Defect Detection**
2501.09187v1 by Qisen Cheng, Shuhui Qu, Janghwan Lee

Unsupervised visual defect detection is critical in industrial applications,
requiring a representation space that captures normal data features while
detecting deviations. Achieving a balance between expressiveness and
compactness is challenging; an overly expressive space risks inefficiency and
mode collapse, impairing detection accuracy. We propose a novel approach using
an enhanced VQ-VAE framework optimized for unsupervised defect detection. Our
model introduces a patch-aware dynamic code assignment scheme, enabling
context-sensitive code allocation to optimize spatial representation. This
strategy enhances normal-defect distinction and improves detection accuracy
during inference. Experiments on MVTecAD, BTAD, and MTSD datasets show our
method achieves state-of-the-art performance.

摘要：無監督視覺缺陷偵測在工業應用中至關重要，
需要一個能擷取正常資料特徵並同時偵測偏差的表示空間。在表現力和緊湊性之間取得平衡是一項挑戰；過度表現的空間會造成效率低落和模式崩潰，進而損害偵測準確度。我們提出一個使用增強式 VQ-VAE 架構的新穎方法，該架構經過最佳化以進行無監督缺陷偵測。我們的模型引入了一個區塊感知動態程式碼分配架構，可針對空間表示進行最佳化，並執行與脈絡相關的程式碼配置。此策略增強了正常缺陷區分，並在推論期間提升偵測準確度。在 MVTecAD、BTAD 和 MTSD 資料集上進行的實驗顯示，我們的模型達到了最先進的效能。

##### **Guiding Retrieval using LLM-based Listwise Rankers**
2501.09186v1 by Mandeep Rathee, Sean MacAvaney, Avishek Anand

Large Language Models (LLMs) have shown strong promise as rerankers,
especially in ``listwise'' settings where an LLM is prompted to rerank several
search results at once. However, this ``cascading'' retrieve-and-rerank
approach is limited by the bounded recall problem: relevant documents not
retrieved initially are permanently excluded from the final ranking. Adaptive
retrieval techniques address this problem, but do not work with listwise
rerankers because they assume a document's score is computed independently from
other documents. In this paper, we propose an adaptation of an existing
adaptive retrieval method that supports the listwise setting and helps guide
the retrieval process itself (thereby overcoming the bounded recall problem for
LLM rerankers). Specifically, our proposed algorithm merges results both from
the initial ranking and feedback documents provided by the most relevant
documents seen up to that point. Through extensive experiments across diverse
LLM rerankers, first stage retrievers, and feedback sources, we demonstrate
that our method can improve nDCG@10 by up to 13.23% and recall by 28.02%--all
while keeping the total number of LLM inferences constant and overheads due to
the adaptive process minimal. The work opens the door to leveraging LLM-based
search in settings where the initial pool of results is limited, e.g., by
legacy systems, or by the cost of deploying a semantic first-stage.

摘要：大型語言模型 (LLM) 已展現出作為重新排序器的強大潛力，特別是在「清單式」設定中，其中 LLM 會收到提示，一次重新排序多個搜尋結果。然而，這種「串聯式」檢索和重新排序方法受到有界召回問題的限制：最初未檢索到的相關文件會永久排除在最終排名之外。自適應檢索技術可解決此問題，但無法與清單式重新排序器搭配使用，因為它們假設文件的評分會獨立於其他文件計算。在本文中，我們提出對現有自適應檢索方法的改編，支援清單式設定，並協助引導檢索程序本身（從而克服 LLM 重新排序器的有界召回問題）。具體來說，我們提出的演算法合併來自初始排名和迄今為止所見最相關文件的回饋文件中的結果。透過對不同的 LLM 重新排序器、第一階段檢索器和回饋來源進行廣泛的實驗，我們證明我們的模型可以將 nDCG@10 提高多達 13.23%，召回率提高 28.02%——同時保持 LLM 推論的總次數不變，並將自適應程序造成的額外負擔降至最低。這項工作開啟了在初始結果池有限的設定中利用基於 LLM 的搜尋的大門，例如，受到傳統系統或部署語意第一階段的成本限制。

##### **Attention is All You Need Until You Need Retention**
2501.09166v1 by M. Murat Yaslioglu

This work introduces a novel Retention Layer mechanism for Transformer based
architectures, addressing their inherent lack of intrinsic retention
capabilities. Unlike human cognition, which can encode and dynamically recall
symbolic templates, Generative Pretrained Transformers rely solely on fixed
pretrained weights and ephemeral context windows, limiting their adaptability.
The proposed Retention Layer incorporates a persistent memory module capable of
real time data population, dynamic recall, and guided output generation. This
enhancement allows models to store, update, and reuse observed patterns across
sessions, enabling incremental learning and bridging the gap between static
pretraining and dynamic, context sensitive adaptation. The Retention Layer
design parallels social learning processes, encompassing attention, retention,
reproduction, and motivation stages. Technically, it integrates a memory
attention mechanism and episodic buffers to manage memory scalability, mitigate
overfitting, and ensure efficient recall. Applications span adaptive personal
assistants, real time fraud detection, autonomous robotics, content moderation,
and healthcare diagnostics. In each domain, the retention mechanism enables
systems to learn incrementally, personalize outputs, and respond to evolving
real world challenges effectively. By emulating key aspects of human learning,
this retention enhanced architecture fosters a more fluid and responsive AI
paradigm, paving the way for dynamic, session aware models that extend the
capabilities of traditional Transformers into domains requiring continual
adaptation.

摘要：這項工作為基於 Transformer 的架構引入一種新穎的保留層機制，用以解決其固有的內在保留能力不足問題。與能夠編碼和動態回憶符號範本的人類認知不同，生成式預訓練 Transformer 僅依賴於固定的預訓練權重和短暫的上下文窗口，限制了其適應性。所提出的保留層包含一個持續的記憶體模組，能夠進行即時資料填充、動態回憶和引導式輸出產生。這種強化讓模型能夠在各個工作階段儲存、更新和重複使用觀察到的模式，實現增量學習並彌合靜態預訓練與動態、對上下文敏感的適應之間的差距。保留層設計與社會學習過程類似，包含注意力、保留、複製和動機階段。在技術上，它整合了一個記憶體注意力機制和情節緩衝區來管理記憶體的可擴充性，減輕過度擬合，並確保有效回憶。應用範圍涵蓋適應性個人助理、即時詐欺偵測、自主機器人、內容審核和醫療保健診斷。在每個領域中，保留機制都能讓系統增量學習、個人化輸出，並有效回應不斷變化的真實世界挑戰。透過模擬人類學習的主要面向，這種增強保留的架構促進了更流暢、更具回應性的 AI 典範，為動態、具備工作階段感知能力的模型鋪路，將傳統 Transformer 的能力延伸到需要持續適應的領域中。

##### **The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and Lithuanian Short Answer Matching**
2501.09164v1 by Yevhen Kostiuk, Oxana Vitman, Łukasz Gagała, Artur Kiulian

In this work, we address the challenge of evaluating large language models
(LLMs) on the short answer matching task for Latvian and Lithuanian languages.
We introduce novel datasets consisting of 502 Latvian and 690 Lithuanian
question-answer pairs. For each question-answer pair, we generated matched and
non-matched answers using a set of alteration rules specifically designed to
introduce small but meaningful changes in the text. These generated answers
serve as test cases to assess the ability of LLMs to detect subtle differences
in matching of the original answers. A subset of the datasets was manually
verified for quality and accuracy. Our results show that while larger LLMs,
such as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in
distinguishing matched and non-matched answers, smaller models show more
variance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot
examples, while Mistral Nemo 12b underperformed on detection of subtle text
alteration, particularly in Lithuanian, even with additional examples. QWEN2.5
7b and Mistral 7b were able to obtain a strong and comparable performance to
the larger 70b models in zero and few shot experiments. Moreover, the
performance of Mistral 7b was weaker in few shot experiments.

摘要：在這項工作中，我們解決了在拉脫維亞語和立陶宛語的簡答配對任務中評估大型語言模型 (LLM) 的挑戰。我們引入了由 502 個拉脫維亞語和 690 個立陶宛語問答對組成的新穎資料集。對於每個問答對，我們使用專門設計的一組變更規則生成了匹配和不匹配的答案，以在文本中引入細微但有意義的變更。這些生成的答案作為測試案例，用於評估 LLM 檢測原始答案匹配中的細微差異的能力。資料集的子集經過手動驗證以確保品質和準確性。我們的結果顯示，雖然較大的 LLM（例如 QWEN2.5 72b 和 LLaMa3.1 70b）在區分匹配和不匹配的答案方面表現接近完美，但較小的模型顯示出更多差異。例如，LLaMa3.1 8b 和 EuroLLM 9b 受益於少次嘗試的範例，而 Mistral Nemo 12b 在檢測細微文字變更方面表現不佳，特別是在立陶宛語中，即使有額外的範例也是如此。QWEN2.5 7b 和 Mistral 7b 能夠在零次和少次嘗試的實驗中獲得與較大的 70b 模型相當的強勁效能。此外，Mistral 7b 在少次嘗試的實驗中的效能較弱。

##### **Towards Understanding Extrapolation: a Causal Lens**
2501.09163v1 by Lingjing Kong, Guangyi Chen, Petar Stojanov, Haoxuan Li, Eric P. Xing, Kun Zhang

Canonical work handling distribution shifts typically necessitates an entire
target distribution that lands inside the training distribution. However,
practical scenarios often involve only a handful of target samples, potentially
lying outside the training support, which requires the capability of
extrapolation. In this work, we aim to provide a theoretical understanding of
when extrapolation is possible and offer principled methods to achieve it
without requiring an on-support target distribution. To this end, we formulate
the extrapolation problem with a latent-variable model that embodies the
minimal change principle in causal mechanisms. Under this formulation, we cast
the extrapolation problem into a latent-variable identification problem. We
provide realistic conditions on shift properties and the estimation objectives
that lead to identification even when only one off-support target sample is
available, tackling the most challenging scenarios. Our theory reveals the
intricate interplay between the underlying manifold's smoothness and the shift
properties. We showcase how our theoretical results inform the design of
practical adaptation algorithms. Through experiments on both synthetic and
real-world data, we validate our theoretical findings and their practical
implications.

摘要：典型情況下，正規的工作處理分配轉移通常需要一個完整的目標分配，該目標分配會落在訓練分配內。然而，實際情況通常只涉及少數目標範例，這些範例可能位於訓練支援之外，這需要外推能力。在這項工作中，我們旨在提供一個理論上的理解，說明何時可以外推，並提供有原則的方法來實現它，而不需要一個支援目標分配。為此，我們使用一個隱變數模型制定外推問題，該模型體現了因果機制中的最小變更原則。在這個公式下，我們將外推問題轉化為一個隱變數識別問題。我們提供了轉移屬性和估計目標的現實條件，這些條件即使只有一個非支援目標範例可用，也能導致識別，從而應對最具挑戰性的情況。我們的理論揭示了底層流形的平滑度和轉移屬性之間的複雜相互作用。我們展示了我們的理論結果如何為實用適應演算法的設計提供資訊。透過對合成和真實世界資料的實驗，我們驗證了我們的理論發現及其實務意涵。

##### **AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning**
2501.09160v1 by Assaf Lahiany, Oren Gal

Current visual SLAM systems face significant challenges in balancing
computational efficiency with robust loop closure handling. Traditional
approaches require careful manual tuning and incur substantial computational
overhead, while learning-based methods either lack explicit loop closure
capabilities or implement them through computationally expensive methods. We
present AutoLoop, a novel approach that combines automated curriculum learning
with efficient fine-tuning for visual SLAM systems. Our method employs a DDPG
(Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure
weights during training, eliminating the need for manual hyperparameter search
while significantly reducing the required training steps. The approach
pre-computes potential loop closure pairs offline and leverages them through an
agent-guided curriculum, allowing the model to adapt efficiently to new
scenarios. Experiments conducted on TartanAir for training and validated across
multiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate
that AutoLoop achieves comparable or superior performance while reducing
training time by an order of magnitude compared to traditional approaches.
AutoLoop provides a practical solution for rapid adaptation of visual SLAM
systems, automating the weight tuning process that traditionally requires
multiple manual iterations. Our results show that this automated curriculum
strategy not only accelerates training but also maintains or improves the
model's performance across diverse environmental conditions.

摘要：當前的視覺 SLAM 系統在平衡運算效率與穩健的迴路閉合處理上，面臨重大挑戰。傳統方法需要仔細的手動調整，並會產生大量的運算負擔，而基於學習的方法則缺乏明確的迴路閉合功能，或透過運算成本高昂的方法來實作。我們提出 AutoLoop，這是一種新穎的方法，它結合了自動化的課程學習與視覺 SLAM 系統的有效微調。我們的方法採用 DDPG（深度確定性策略梯度）代理，在訓練過程中動態調整迴路閉合權重，消除了人工超參數搜尋的需要，同時大幅減少了所需的訓練步驟。此方法會離線預先計算潛在的迴路閉合對，並透過代理導向的課程來利用它們，讓模型能夠有效地適應新的場景。在 TartanAir 上進行的實驗，用於訓練並驗證跨多個基準，包括 KITTI、EuRoC、ICL-NUIM 和 TUM RGB-D，證明 AutoLoop 達到相當或更佳的效能，同時將訓練時間減少了一個數量級，與傳統方法相比。AutoLoop 提供了一個實用的解決方案，用於快速適應視覺 SLAM 系統，自動化傳統上需要多次人工反覆運算的權重調整過程。我們的結果表明，這種自動化的課程策略不僅加速了訓練，還維持或改善了模型在各種環境條件下的效能。

##### **Evaluating GenAI for Simplifying Texts for Education: Improving Accuracy and Consistency for Enhanced Readability**
2501.09158v1 by Stephanie L. Day, Jacapo Cirica, Steven R. Clapp, Veronika Penkova, Amy E. Giroux, Abbey Banta, Catherine Bordeau, Poojitha Mutteneni, Ben D. Sawyer

Generative artificial intelligence (GenAI) holds great promise as a tool to
support personalized learning. Teachers need tools to efficiently and
effectively enhance content readability of educational texts so that they are
matched to individual students reading levels, while retaining key details.
Large Language Models (LLMs) show potential to fill this need, but previous
research notes multiple shortcomings in current approaches. In this study, we
introduced a generalized approach and metrics for the systematic evaluation of
the accuracy and consistency in which LLMs, prompting techniques, and a novel
multi-agent architecture to simplify sixty informational reading passages,
reducing each from the twelfth grade level down to the eighth, sixth, and
fourth grade levels. We calculated the degree to which each LLM and prompting
technique accurately achieved the targeted grade level for each passage,
percentage change in word count, and consistency in maintaining keywords and
key phrases (semantic similarity). One-sample t-tests and multiple regression
models revealed significant differences in the best performing LLM and prompt
technique for each of the four metrics. Both LLMs and prompting techniques
demonstrated variable utility in grade level accuracy and consistency of
keywords and key phrases when attempting to level content down to the fourth
grade reading level. These results demonstrate the promise of the application
of LLMs for efficient and precise automated text simplification, the
shortcomings of current models and prompting methods in attaining an ideal
balance across various evaluation criteria, and a generalizable method to
evaluate future systems.

摘要：生成式人工智慧 (GenAI) 作為支援個人化學習的工具極具潛力。教師需要工具來有效率且有效地提升教育文本的內容可讀性，以便與個別學生的閱讀程度相符，同時保留關鍵細節。大型語言模型 (LLM) 顯示出滿足此需求的潛力，但先前的研究指出目前方法有多項缺點。在本研究中，我們針對 LLM、提示技巧和一種簡化六十篇資訊性閱讀段落的創新多重代理架構，引進了一種概括性方法和指標來系統性評估準確性和一致性，將每篇段落從十二年級程度降低到八年級、六年級和四年級程度。我們計算了每種 LLM 和提示技巧準確達成每個段落目標年級程度的程度、字數變化的百分比，以及在維持關鍵字和關鍵片語（語義相似性）方面的一致性。單樣本 t 檢定和多元迴歸模型揭露了四項指標中表現最佳的 LLM 和提示技巧存在顯著差異。當嘗試將內容簡化到四年級閱讀程度時，LLM 和提示技巧在年級程度準確性和關鍵字及關鍵片語的一致性方面都展現出可變的效用。這些結果證明了 LLM 在有效且精確的自動化文字簡化方面的應用潛力，目前模型和提示方法在達成各種評量標準的理想平衡方面的缺點，以及評估未來系統的一般化方法。

##### **VCRScore: Image captioning metric based on V\&L Transformers, CLIP, and precision-recall**
2501.09155v1 by Guillermo Ruiz, Tania Ramírez, Daniela Moctezuma

Image captioning has become an essential Vision & Language research task. It
is about predicting the most accurate caption given a specific image or video.
The research community has achieved impressive results by continuously
proposing new models and approaches to improve the overall model's performance.
Nevertheless, despite increasing proposals, the performance metrics used to
measure their advances have remained practically untouched through the years. A
probe of that, nowadays metrics like BLEU, METEOR, CIDEr, and ROUGE are still
very used, aside from more sophisticated metrics such as BertScore and
ClipScore.
  Hence, it is essential to adjust how are measure the advances, limitations,
and scopes of the new image captioning proposals, as well as to adapt new
metrics to these new advanced image captioning approaches.
  This work proposes a new evaluation metric for the image captioning problem.
To do that, first, it was generated a human-labeled dataset to assess to which
degree the captions correlate with the image's content. Taking these human
scores as ground truth, we propose a new metric, and compare it with several
well-known metrics, from classical to newer ones. Outperformed results were
also found, and interesting insights were presented and discussed.

摘要：影像標題已成為視覺與語言研究的重要任務。目的是根據特定影像或影片預測最精確的標題。研究社群持續提出新的模型和方法來提升整體模型的效能，已獲得令人印象深刻的成果。儘管提出越來越多的建議，但多年來用於衡量其進展的效能指標實際上並未更動。其中一個探討是，如今像 BLEU、METEOR、CIDEr 和 ROUGE 等指標仍廣泛使用，除了 BertScore 和 ClipScore 等更精密的指標。因此，必須調整我們如何衡量新影像標題建議的進展、限制和範圍，以及調整新的指標以適應這些新的進階影像標題方法。這項研究針對影像標題問題提出新的評量指標。首先，產生一個由人類標記的資料集，以評估標題與影像內容相關的程度。將這些人類評分視為真實依據，我們提出一個新的指標，並將其與幾個著名的指標進行比較，從傳統指標到較新的指標。也發現表現優異的結果，並提出和討論了有趣的見解。

##### **Towards Multilingual LLM Evaluation for Baltic and Nordic languages: A study on Lithuanian History**
2501.09154v1 by Yevhen Kostiuk, Oxana Vitman, Łukasz Gagała, Artur Kiulian

In this work, we evaluated Lithuanian and general history knowledge of
multilingual Large Language Models (LLMs) on a multiple-choice
question-answering task. The models were tested on a dataset of Lithuanian
national and general history questions translated into Baltic, Nordic, and
other languages (English, Ukrainian, Arabic) to assess the knowledge sharing
from culturally and historically connected groups. We evaluated GPT-4o,
LLaMa3.1 8b and 70b, QWEN2.5 7b and 72b, Mistral Nemo 12b, LLaMa3 8b, Mistral
7b, LLaMa3.2 3b, and Nordic fine-tuned models (GPT-SW3 and LLaMa3 8b).
  Our results show that GPT-4o consistently outperformed all other models
across language groups, with slightly better results for Baltic and Nordic
languages. Larger open-source models like QWEN2.5 72b and LLaMa3.1 70b
performed well but showed weaker alignment with Baltic languages. Smaller
models (Mistral Nemo 12b, LLaMa3.2 3b, QWEN 7B, LLaMa3.1 8B, and LLaMa3 8b)
demonstrated gaps with LT-related alignment with Baltic languages while
performing better on Nordic and other languages. The Nordic fine-tuned models
did not surpass multilingual models, indicating that shared cultural or
historical context alone does not guarantee better performance.

摘要：在這項工作中，我們評估了多語言大型語言模型 (LLM) 在多選題問答任務中的立陶宛語和一般歷史知識。這些模型在立陶宛國家和一般歷史問題的數據集上進行測試，這些問題被翻譯成波羅的海、北歐和其他語言（英語、烏克蘭語、阿拉伯語），以評估來自文化和歷史相關群體的知識共享。我們評估了 GPT-4o、LLaMa3.1 8b 和 70b、QWEN2.5 7b 和 72b、Mistral Nemo 12b、LLaMa3 8b、Mistral 7b、LLaMa3.2 3b，以及北歐微調模型 (GPT-SW3 和 LLaMa3 8b)。
我們的結果顯示，GPT-4o 在所有語言群體中始終優於其他所有模型，波羅的海和北歐語言的結果略好。像 QWEN2.5 72b 和 LLaMa3.1 70b 這樣較大的開源模型表現良好，但與波羅的海語言的一致性較弱。較小的模型（Mistral Nemo 12b、LLaMa3.2 3b、QWEN 7B、LLaMa3.1 8B 和 LLaMa3 8b）在與波羅的海語言的 LT 相關一致性方面表現出差距，而在北歐和其他語言上表現得更好。北歐微調模型沒有超越多語言模型，這表明僅共享文化或歷史背景並不能保證更好的表現。

##### **Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG**
2501.09136v1 by Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei

Large Language Models (LLMs) have revolutionized artificial intelligence (AI)
by enabling human like text generation and natural language understanding.
However, their reliance on static training data limits their ability to respond
to dynamic, real time queries, resulting in outdated or inaccurate outputs.
Retrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs
by integrating real time data retrieval to provide contextually relevant and
up-to-date responses. Despite its promise, traditional RAG systems are
constrained by static workflows and lack the adaptability required for
multistep reasoning and complex task management.
  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these
limitations by embedding autonomous AI agents into the RAG pipeline. These
agents leverage agentic design patterns reflection, planning, tool use, and
multiagent collaboration to dynamically manage retrieval strategies,
iteratively refine contextual understanding, and adapt workflows to meet
complex task requirements. This integration enables Agentic RAG systems to
deliver unparalleled flexibility, scalability, and context awareness across
diverse applications.
  This survey provides a comprehensive exploration of Agentic RAG, beginning
with its foundational principles and the evolution of RAG paradigms. It
presents a detailed taxonomy of Agentic RAG architectures, highlights key
applications in industries such as healthcare, finance, and education, and
examines practical implementation strategies. Additionally, it addresses
challenges in scaling these systems, ensuring ethical decision making, and
optimizing performance for real-world applications, while providing detailed
insights into frameworks and tools for implementing Agentic RAG

摘要：大型語言模型 (LLM) 透過啟用類似人類的文字產生和自然語言理解，徹底革新了人工智慧 (AI)。
然而，它們依賴於靜態訓練資料，限制了它們回應動態、即時查詢的能力，導致過時或不準確的輸出。
檢索增強生成 (RAG) 已成為一種解決方案，透過整合即時資料檢索來增強 LLM，以提供與脈絡相關且最新的回應。儘管很有希望，傳統的 RAG 系統受到靜態工作流程的限制，並且缺乏多步驟推理和複雜任務管理所需的適應性。
主動檢索增強生成 (Agentic RAG) 透過將自主 AI 代理嵌入 RAG 管道中，超越了這些限制。這些代理利用主動設計模式反射、規劃、工具使用和多代理協作，動態管理檢索策略、反覆精煉脈絡理解，並調整工作流程以滿足複雜的任務需求。這種整合使 Agentic RAG 系統能夠在各種應用中提供無與倫比的靈活性、可擴充性和脈絡感知。
本調查對 Agentic RAG 進行全面探討，從其基本原理和 RAG 典範的演進開始。它提出了 Agentic RAG 架構的詳細分類，重點介紹了醫療保健、金融和教育等產業中的關鍵應用，並探討了實用的實作策略。此外，它還解決了擴充這些系統、確保道德決策制定和最佳化實際應用效能的挑戰，同時提供有關實作 Agentic RAG 的架構和工具的詳細見解

##### **Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval**
2501.09134v1 by Demetrio Deanda, Yuktha Priya Masupalli, Jeong Yang, Young Lee, Zechun Cao, Gongbo Liang

Medical images and reports offer invaluable insights into patient health. The
heterogeneity and complexity of these data hinder effective analysis. To bridge
this gap, we investigate contrastive learning models for cross-domain
retrieval, which associates medical images with their corresponding clinical
reports. This study benchmarks the robustness of four state-of-the-art
contrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We
introduce an occlusion retrieval task to evaluate model performance under
varying levels of image corruption. Our findings reveal that all evaluated
models are highly sensitive to out-of-distribution data, as evidenced by the
proportional decrease in performance with increasing occlusion levels. While
MedCLIP exhibits slightly more robustness, its overall performance remains
significantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a
general-purpose dataset, struggles with medical image-report retrieval,
highlighting the importance of domain-specific training data. The evaluation of
this work suggests that more effort needs to be spent on improving the
robustness of these models. By addressing these limitations, we can develop
more reliable cross-domain retrieval models for medical applications.

摘要：醫療影像和報告提供寶貴的見解，深入了解患者健康。這些數據的異質性和複雜性阻礙了有效的分析。為了彌補這個差距，我們研究對比學習模型進行跨領域檢索，將醫學影像與其對應的臨床報告聯繫起來。本研究對四種最先進的對比學習模型的健壯性進行了基準測試：CLIP、CXR-RePaiR、MedCLIP 和 CXR-CLIP。我們引入遮擋檢索任務，以評估模型在不同程度的影像損壞下的性能。我們的研究結果表明，所有評估的模型對分佈外數據都高度敏感，這從隨著遮擋程度的增加而導致的性能成比例下降就可以證明。雖然 MedCLIP 表現出稍高的健壯性，但其整體性能仍遠遠落後於 CXR-CLIP 和 CXR-RePaiR。CLIP 在通用數據集上進行訓練，在醫學影像報告檢索中遇到困難，突顯了特定領域訓練數據的重要性。這項工作的評估表明，需要花費更多精力來提高這些模型的健壯性。通過解決這些限制，我們可以為醫療應用開發更可靠的跨領域檢索模型。

##### **Multilingual LLMs Struggle to Link Orthography and Semantics in Bilingual Word Processing**
2501.09127v1 by Eshaan Tanwar, Gayatri Oke, Tanmoy Chakraborty

Bilingual lexical processing is shaped by the complex interplay of
phonological, orthographic, and semantic features of two languages within an
integrated mental lexicon. In humans, this is evident in the ease with which
cognate words - words similar in both orthographic form and meaning (e.g.,
blind, meaning "sightless" in both English and German) - are processed,
compared to the challenges posed by interlingual homographs, which share
orthographic form but differ in meaning (e.g., gift, meaning "present" in
English but "poison" in German). We investigate how multilingual Large Language
Models (LLMs) handle such phenomena, focusing on English-Spanish,
English-French, and English-German cognates, non-cognate, and interlingual
homographs. Specifically, we evaluate their ability to disambiguate meanings
and make semantic judgments, both when these word types are presented in
isolation or within sentence contexts. Our findings reveal that while certain
LLMs demonstrate strong performance in recognizing cognates and non-cognates in
isolation, they exhibit significant difficulty in disambiguating interlingual
homographs, often performing below random baselines. This suggests LLMs tend to
rely heavily on orthographic similarities rather than semantic understanding
when interpreting interlingual homographs. Further, we find LLMs exhibit
difficulty in retrieving word meanings, with performance in isolative
disambiguation tasks having no correlation with semantic understanding.
Finally, we study how the LLM processes interlingual homographs in incongruent
sentences. We find models to opt for different strategies in understanding
English and non-English homographs, highlighting a lack of a unified approach
to handling cross-lingual ambiguities.

摘要：雙語詞彙處理受到兩個語言在整合心智詞彙中音韻、正字法和語義特徵的複雜交互影響所形塑。在人類中，這在同源詞（在正字法形式和意義上都相似的詞彙，例如 blind，在英文和德文中都表示「失明的」）的處理上很明顯，與跨語言同形異義詞帶來的挑戰相比，跨語言同形異義詞共享正字法形式，但在意義上有所不同（例如 gift，在英文中表示「禮物」，但在德文中表示「毒藥」）。我們探討多語言大型語言模型 (LLM) 如何處理此類現象，重點關注英語-西班牙語、英語-法語和英語-德語同源詞、非同源詞和跨語言同形異義詞。具體來說，我們評估它們在這些字詞類型單獨呈現或在句子上下文中呈現時，消除歧義和做出語義判斷的能力。我們的研究結果顯示，儘管某些 LLM 在單獨辨識同源詞和非同源詞方面表現出色，但在消除跨語言同形異義詞歧義方面卻有顯著困難，其表現往往低於隨機基準線。這表明 LLM 在詮釋跨語言同形異義詞時，傾向於過度依賴正字法相似性，而不是語義理解。此外，我們發現 LLM 在擷取字詞意義方面有困難，在孤立消歧任務中的表現與語義理解無關。最後，我們研究 LLM 如何在不一致的句子中處理跨語言同形異義詞。我們發現模型在理解英語和非英語同形異義詞時會選擇不同的策略，突顯出在處理跨語言歧義時缺乏統一的方法。

##### **Augmenting Human-Annotated Training Data with Large Language Model Generation and Distillation in Open-Response Assessment**
2501.09126v1 by Conrad Borchers, Danielle R. Thomas, Jionghao Lin, Ralph Abboud, Kenneth R. Koedinger

Large Language Models (LLMs) like GPT-4o can help automate text
classification tasks at low cost and scale. However, there are major concerns
about the validity and reliability of LLM outputs. By contrast, human coding is
generally more reliable but expensive to procure at scale. In this study, we
propose a hybrid solution to leverage the strengths of both. We combine
human-coded data and synthetic LLM-produced data to fine-tune a classical
machine learning classifier, distilling both into a smaller BERT model. We
evaluate our method on a human-coded test set as a validity measure for LLM
output quality. In three experiments, we systematically vary LLM-generated
samples' size, variety, and consistency, informed by best practices in LLM
tuning. Our findings indicate that augmenting datasets with synthetic samples
improves classifier performance, with optimal results achieved at an 80%
synthetic to 20% human-coded data ratio. Lower temperature settings of 0.3,
corresponding to less variability in LLM generations, produced more stable
improvements but also limited model learning from augmented samples. In
contrast, higher temperature settings (0.7 and above) introduced greater
variability in performance estimates and, at times, lower performance. Hence,
LLMs may produce more uniform output that classifiers overfit to earlier or
produce more diverse output that runs the risk of deteriorating model
performance through information irrelevant to the prediction task. Filtering
out inconsistent synthetic samples did not enhance performance. We conclude
that integrating human and LLM-generated data to improve text classification
models in assessment offers a scalable solution that leverages both the
accuracy of human coding and the variety of LLM outputs.

摘要：大型語言模型 (LLM) 如 GPT-4o 可以協助自動化文本分類任務，成本低且可擴充。然而，對於 LLM 輸出的有效性和可靠性有很大的疑慮。相比之下，人工編碼通常更可靠，但大規模採購成本高。在本研究中，我們提出一個混合解決方案，以利用兩者的優點。我們結合人工編碼資料和 LLM 產生的合成資料，微調傳統機器學習分類器，將兩者精煉成較小的 BERT 模型。我們使用人工編碼的測試集評估我們的模型，作為 LLM 輸出品質的有效性指標。在三個實驗中，我們系統性地改變 LLM 產生的範例大小、種類和一致性，並根據 LLM 調校的最佳實務來進行。我們的研究結果顯示，使用合成範例擴充資料集可以提升分類器的效能，最佳結果出現在合成資料與人工編碼資料的比例為 80% 比 20% 時。溫度設定較低（0.3），代表 LLM 產生的變異性較低，可以產生較穩定的提升，但也會限制模型從擴充範例中學習。相反地，溫度設定較高（0.7 以上）會造成效能估計的變異性較大，有時效能也會較低。因此，LLM 產生的輸出可能較為一致，導致分類器過度擬合到較早的資料，或產生較多樣化的輸出，有風險會因為與預測任務無關的資訊而降低模型效能。過濾掉不一致的合成範例並未提升效能。我們的結論是，整合人工和 LLM 產生的資料來改善評估中的文本分類模型，提供了一個可擴充的解決方案，同時利用了人工編碼的準確性和 LLM 輸出的多樣性。

##### **Mantis Shrimp: Exploring Photometric Band Utilization in Computer Vision Networks for Photometric Redshift Estimation**
2501.09112v1 by Andrew Engel, Nell Byler, Adam Tsou, Gautham Narayan, Emmanuel Bonilla, Ian Smith

We present Mantis Shrimp, a multi-survey deep learning model for photometric
redshift estimation that fuses ultra-violet (GALEX), optical (PanSTARRS), and
infrared (UnWISE) imagery. Machine learning is now an established approach for
photometric redshift estimation, with generally acknowledged higher performance
in areas with a high density of spectroscopically identified galaxies over
template-based methods. Multiple works have shown that image-based
convolutional neural networks can outperform tabular-based color/magnitude
models. In comparison to tabular models, image models have additional design
complexities: it is largely unknown how to fuse inputs from different
instruments which have different resolutions or noise properties. The Mantis
Shrimp model estimates the conditional density estimate of redshift using
cutout images. The density estimates are well calibrated and the point
estimates perform well in the distribution of available spectroscopically
confirmed galaxies with (bias = 1e-2), scatter (NMAD = 2.44e-2) and
catastrophic outlier rate ($\eta$=17.53$\%$). We find that early fusion
approaches (e.g., resampling and stacking images from different instruments)
match the performance of late fusion approaches (e.g., concatenating latent
space representations), so that the design choice ultimately is left to the
user. Finally, we study how the models learn to use information across bands,
finding evidence that our models successfully incorporates information from all
surveys. The applicability of our model to the analysis of large populations of
galaxies is limited by the speed of downloading cutouts from external servers;
however, our model could be useful in smaller studies such as generating priors
over redshift for stellar population synthesis.

摘要：<paragraph>我們提出 Mantis Shrimp，一種多調查深度學習模型，用於光度紅移估計，它融合了紫外線 (GALEX)、光學 (PanSTARRS) 和紅外線 (UnWISE) 影像。機器學習現在是一種已確立的光度紅移估計方法，在光譜識別星系密度高的區域中，普遍承認比基於模板的方法具有更高的效能。多項研究表明，基於影像的卷積神經網路可以優於基於表格的顏色/星等模型。與表格模型相比，影像模型具有額外的設計複雜性：在很大程度上不知道如何融合來自不同儀器的輸入，這些儀器具有不同的解析度或雜訊特性。Mantis Shrimp 模型使用裁剪影像估計紅移的條件密度估計。密度估計經過良好校準，點估計在具有 (偏差 = 1e-2)、離散度 (NMAD = 2.44e-2) 和災難性離群值率 ($\eta$=17.53$\%$) 的可用光譜確認星系的分布中表現良好。我們發現早期融合方法 (例如，重新取樣和堆疊來自不同儀器的影像) 與後期融合方法 (例如，串接潛在空間表示) 的效能相匹配，因此設計選擇最終留給使用者。最後，我們研究模型如何學習使用跨波段資訊，發現證據表明我們的模型成功地納入了來自所有調查的資訊。我們的模型適用於分析大量星系，但受限於從外部伺服器下載裁剪的速度；然而，我們的模型可能有助於較小的研究，例如為恆星族合成產生紅移先驗。</paragraph>

##### **A Non-autoregressive Model for Joint STT and TTS**
2501.09104v1 by Vishal Sunder, Brian Kingsbury, George Saon, Samuel Thomas, Slava Shechtman Hagai Aronowitz, Eric Fosler-Lussier, Luis Lastras

In this paper, we take a step towards jointly modeling automatic speech
recognition (STT) and speech synthesis (TTS) in a fully non-autoregressive way.
We develop a novel multimodal framework capable of handling the speech and text
modalities as input either individually or together. The proposed model can
also be trained with unpaired speech or text data owing to its multimodal
nature. We further propose an iterative refinement strategy to improve the STT
and TTS performance of our model such that the partial hypothesis at the output
can be fed back to the input of our model, thus iteratively improving both STT
and TTS predictions. We show that our joint model can effectively perform both
STT and TTS tasks, outperforming the STT-specific baseline in all tasks and
performing competitively with the TTS-specific baseline across a wide range of
evaluation metrics.

摘要：在本文中，我们採取步驟以完全非自迴歸方式聯合建模自動語音辨識 (STT) 和語音合成 (TTS)。
我們開發了一個新穎的多模態框架，能夠將語音和文字模態個別或一起當作輸入處理。由於其多模態性質，所提出的模型也可以用未配對的語音或文字資料訓練。我們進一步提出一個反覆改進策略，以提升模型的 STT 和 TTS 效能，讓輸出端的局部假設可以回饋到模型的輸入端，從而反覆改進 STT 和 TTS 預測。我們展示了我們的聯合模型可以有效執行 STT 和 TTS 任務，在所有任務中都優於特定於 STT 的基準，並且在廣泛的評估指標中與特定於 TTS 的基準表現得具有競爭力。

##### **Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites**
2501.09102v1 by Hans W. A. Hanley, Emily Okabe, Zakir Durumeric

Understanding how misleading and outright false information enters news
ecosystems remains a difficult challenge that requires tracking how narratives
spread across thousands of fringe and mainstream news websites. To do this, we
introduce a system that utilizes encoder-based large language models and
zero-shot stance detection to scalably identify and track news narratives and
their attitudes across over 4,000 factually unreliable, mixed-reliability, and
factually reliable English-language news websites. Running our system over an
18 month period, we track the spread of 146K news stories. Using network-based
interference via the NETINF algorithm, we show that the paths of news
narratives and the stances of websites toward particular entities can be used
to uncover slanted propaganda networks (e.g., anti-vaccine and anti-Ukraine)
and to identify the most influential websites in spreading these attitudes in
the broader news ecosystem. We hope that increased visibility into our
distributed news ecosystem can help with the reporting and fact-checking of
propaganda and disinformation.

摘要：了解如何誤導和完全錯誤的訊息進入新聞生態系統仍然是一個困難的挑戰，需要追蹤敘述如何散佈在數千個邊緣和主流新聞網站上。為此，我們引入一個系統，利用基於編碼器的大型語言模型和零次態勢偵測來可擴充地識別和追蹤新聞敘述及其在超過 4,000 個事實上不可靠、可靠性混合和事實上可靠的英文新聞網站上的態度。在 18 個月期間執行我們的系統，我們追蹤了 146K 則新聞報導的散佈。使用透過 NETINF 演算法的基於網路的干擾，我們顯示新聞敘述的路徑和網站對特定實體的立場可用於揭露有偏見的宣傳網路（例如反疫苗和反烏克蘭），並識別在更廣泛的新聞生態系統中散佈這些態度的最有影響力的網站。我們希望對我們分散的新聞生態系統有更高的可見度有助於宣傳和錯誤訊息的報導和事實查核。

##### **SteLLA: A Structured Grading System Using LLMs with RAG**
2501.09092v1 by Hefei Qiu, Brian White, Ashley Ding, Reinaldo Costa, Ali Hachem, Wei Ding, Ping Chen

Large Language Models (LLMs) have shown strong general capabilities in many
applications. However, how to make them reliable tools for some specific tasks
such as automated short answer grading (ASAG) remains a challenge. We present
SteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval
Augmented Generation (RAG) approach is used to empower LLMs specifically on the
ASAG task by extracting structured information from the highly relevant and
reliable external knowledge based on the instructor-provided reference answer
and rubric, b) an LLM performs a structured and question-answering-based
evaluation of student answers to provide analytical grades and feedback. A
real-world dataset that contains students' answers in an exam was collected
from a college-level Biology course. Experiments show that our proposed system
can achieve substantial agreement with the human grader while providing
break-down grades and feedback on all the knowledge points examined in the
problem. A qualitative and error analysis of the feedback generated by GPT4
shows that GPT4 is good at capturing facts while may be prone to inferring too
much implication from the given text in the grading task which provides
insights into the usage of LLMs in the ASAG system.

摘要：大型語言模型 (LLM) 在許多應用中展現出強大的通用能力。然而，如何讓它們成為某些特定任務的可靠工具，例如自動化簡答評分 (ASAG)，仍然是一個挑戰。我們提出 SteLLA（使用 RAG 的結構化評分系統），其中 a) 檢索增強生成 (RAG) 方法用於賦能 LLM，特別是在 ASAG 任務中，藉由從高度相關且可靠的外部知識中提取結構化資訊，根據教師提供的參考答案和評分標準，b) LLM 執行結構化且基於問答的學生答案評估，以提供分析評分和回饋。從大學生物課程中收集了一個包含學生考試答案的真實世界資料集。實驗顯示，我們提出的系統可以與人類評分員達成實質性的一致，同時提供問題中所有知識點的細項評分和回饋。對 GPT4 生成的回饋進行定性和錯誤分析顯示，GPT4 擅長擷取事實，但在評分任務中可能容易從給定的文字中推論出過多的含義，這提供了 LLM 在 ASAG 系統中使用的見解。

##### **Inferring Transition Dynamics from Value Functions**
2501.09081v1 by Jacob Adamczyk

In reinforcement learning, the value function is typically trained to solve
the Bellman equation, which connects the current value to future values. This
temporal dependency hints that the value function may contain implicit
information about the environment's transition dynamics. By rearranging the
Bellman equation, we show that a converged value function encodes a model of
the underlying dynamics of the environment. We build on this insight to propose
a simple method for inferring dynamics models directly from the value function,
potentially mitigating the need for explicit model learning. Furthermore, we
explore the challenges of next-state identifiability, discussing conditions
under which the inferred dynamics model is well-defined. Our work provides a
theoretical foundation for leveraging value functions in dynamics modeling and
opens a new avenue for bridging model-free and model-based reinforcement
learning.

摘要：在強化學習中，價值函數通常會被訓練來解決貝爾曼方程式，這將目前的價值與未來的價值聯繫起來。這個時間依賴關係暗示價值函數可能包含環境轉換動態的內隱資訊。透過重新排列貝爾曼方程式，我們證明收斂的價值函數編碼了環境基礎動態的模型。我們建立在這個見解上，提出一個簡單的方法，直接從價值函數推斷動態模型，潛在地減輕對明確模型學習的需求。此外，我們探討下一個狀態可識別性的挑戰，討論推論動態模型定義良好的條件。我們的研究為在動態建模中利用價值函數提供了理論基礎，並為連接無模型和基於模型的強化學習開闢了一條新途徑。

##### **How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias**
2501.09014v1 by Tosin Fadahunsi, Giordano d'Aloisio, Antinisca Di Marco, Federica Sarro

Generative models are nowadays widely used to generate graphical content used
for multiple purposes, e.g. web, art, advertisement. However, it has been shown
that the images generated by these models could reinforce societal biases
already existing in specific contexts. In this paper, we focus on understanding
if this is the case when one generates images related to various software
engineering tasks. In fact, the Software Engineering (SE) community is not
immune from gender and ethnicity disparities, which could be amplified by the
use of these models. Hence, if used without consciousness, artificially
generated images could reinforce these biases in the SE domain. Specifically,
we perform an extensive empirical evaluation of the gender and ethnicity bias
exposed by three versions of the Stable Diffusion (SD) model (a very popular
open-source text-to-image model) - SD 2, SD XL, and SD 3 - towards SE tasks. We
obtain 6,720 images by feeding each model with two sets of prompts describing
different software-related tasks: one set includes the Software Engineer
keyword, and one set does not include any specification of the person
performing the task. Next, we evaluate the gender and ethnicity disparities in
the generated images. Results show how all models are significantly biased
towards male figures when representing software engineers. On the contrary,
while SD 2 and SD XL are strongly biased towards White figures, SD 3 is
slightly more biased towards Asian figures. Nevertheless, all models
significantly under-represent Black and Arab figures, regardless of the prompt
style used. The results of our analysis highlight severe concerns about
adopting those models to generate content for SE tasks and open the field for
future research on bias mitigation in this context.

摘要：生成模型現今廣泛用於產生圖形內容，用於多種目的，例如網路、藝術、廣告。然而，已顯示由這些模型產生的影像可能強化特定情境中已存在的社會偏見。在本文中，我們專注於了解在產生與各種軟體工程任務相關的影像時是否如此。事實上，軟體工程 (SE) 社群並非不受性別和種族差異影響，而這些差異可能會因使用這些模型而擴大。因此，如果在沒有意識的情況下使用，人工產生的影像可能會強化 SE 領域中的這些偏見。具體來說，我們對 Stable Diffusion (SD) 模型（一個非常流行的開源文字轉影像模型）的三個版本（SD 2、SD XL 和 SD 3）對 SE 任務所揭露的性別和種族偏見進行廣泛的實證評估。我們透過提供兩組描述不同軟體相關任務的提示給各個模型，取得 6,720 張影像：一組包含軟體工程師關鍵字，另一組則不包含執行任務的人員的任何說明。接下來，我們評估產生影像中的性別和種族差異。結果顯示，所有模型在代表軟體工程師時都顯著偏向男性角色。相反地，SD 2 和 SD XL 雖然強烈偏向白人角色，但 SD 3 稍微更偏向亞洲角色。然而，所有模型都顯著低估了黑人和阿拉伯人的角色，無論使用哪種提示樣式。我們的分析結果突顯了採用這些模型來產生 SE 任務內容的嚴重疑慮，並為未來在這個情境中減輕偏見的研究開啟了領域。

##### **Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**
2501.09012v1 by Ruixiang Jiang, Changwen Chen

We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability
shall be elicited to evaluate the aesthetics of artworks. To facilitate this
investigation, we construct MM-StyleBench, a novel high-quality dataset for
benchmarking artistic stylization. We then develop a principled method for
human preference modeling and perform a systematic correlation analysis between
MLLMs' responses and human preference. Our experiments reveal an inherent
hallucination issue of MLLMs in art evaluation, associated with response
subjectivity. ArtCoT is proposed, demonstrating that art-specific task
decomposition and the use of concrete language boost MLLMs' reasoning ability
for aesthetics. Our findings offer valuable insights into MLLMs for art and can
benefit a wide range of downstream applications, such as style transfer and
artistic image generation. Code available at
https://github.com/songrise/MLLM4Art.

摘要：我們提出第一個關於如何引發多模態 LLM (MLLM) 推理能力的研究，以評估藝術品的美感。為了促進這項調查，我們構建了 MM-StyleBench，這是一個用於基準化藝術風格化的全新高品質資料集。然後，我們開發了一種基於原則的方法進行人類偏好建模，並在 MLLM 的回應和人類偏好之間執行系統性的相關性分析。我們的實驗揭示了 MLLM 在藝術評估中固有的幻覺問題，與回應的主觀性有關。ArtCoT 被提出，證明特定於藝術的任務分解和具體語言的使用提升了 MLLM 對美學的推理能力。我們的研究結果為 MLLM 在藝術領域提供了寶貴的見解，並可以使廣泛的下游應用受益，例如風格轉移和藝術圖像生成。程式碼可在 https://github.com/songrise/MLLM4Art 取得。

##### **Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition**
2501.09056v1 by Sneheel Sarangi, Maha Elgarf, Hanan Salam

Theory of Mind (ToM) is the ability to understand and reflect on the mental
states of others. Although this capability is crucial for human interaction,
testing on Large Language Models (LLMs) reveals that they possess only a
rudimentary understanding of it. Although the most capable closed-source LLMs
have come close to human performance on some ToM tasks, they still perform
poorly on complex variations of the task that involve more structured
reasoning. In this work, we utilize the concept of "pretend-play", or
``Simulation Theory'' from cognitive psychology to propose ``Decompose-ToM'':
an LLM-based inference algorithm that improves model performance on complex ToM
tasks. We recursively simulate user perspectives and decompose the ToM task
into a simpler set of functions: subject identification, question-reframing,
world model updation, and knowledge availability. We test the algorithm on
higher-order ToM tasks and a task testing for ToM capabilities in a
conversational setting, demonstrating that our approach shows significant
improvement across models compared to baseline methods while requiring minimal
prompt tuning across tasks and no additional model training.

摘要：心智理論（ToM）是理解和反思他人心智狀態的能力。儘管這種能力對人類互動至關重要，但對大型語言模型（LLM）的測試表明，它們對此的理解僅僅是初步的。儘管功能最強的閉源 LLM 在某些 ToM 任務上接近人類表現，但它們在涉及更多結構化推理的任務的複雜變化上表現仍然很差。在這項工作中，我們利用認知心理學中的「假裝遊戲」或「模擬理論」的概念，提出「分解心智理論」：一種基於 LLM 的推理演算法，可以改善模型在複雜心智理論任務上的表現。我們遞迴模擬使用者觀點，並將心智理論任務分解為一組更簡單的功能：主體識別、問題重新建構、世界模型更新和知識可用性。我們在高階心智理論任務和在對話環境中測試心智理論能力的任務上測試了該演算法，證明與基線方法相比，我們的做法在各種模型上都顯示出顯著的改進，同時在各種任務中需要最少的提示調整，並且不需要額外的模型訓練。

##### **Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails**
2501.09004v1 by Shaona Ghosh, Prasoon Varshney, Makesh Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, Jibin Rajan Varghese, Christopher Parisien

As Large Language Models (LLMs) and generative AI become increasingly
widespread, concerns about content safety have grown in parallel. Currently,
there is a clear lack of high-quality, human-annotated datasets that address
the full spectrum of LLM-related safety risks and are usable for commercial
applications. To bridge this gap, we propose a comprehensive and adaptable
taxonomy for categorizing safety risks, structured into 12 top-level hazard
categories with an extension to 9 fine-grained subcategories. This taxonomy is
designed to meet the diverse requirements of downstream users, offering more
granular and flexible tools for managing various risk types. Using a hybrid
data generation pipeline that combines human annotations with a multi-LLM
"jury" system to assess the safety of responses, we obtain Aegis 2.0, a
carefully curated collection of 34,248 samples of human-LLM interactions,
annotated according to our proposed taxonomy. To validate its effectiveness, we
demonstrate that several lightweight models, trained using parameter-efficient
techniques on Aegis 2.0, achieve performance competitive with leading safety
models fully fine-tuned on much larger, non-commercial datasets. In addition,
we introduce a novel training blend that combines safety with topic following
data.This approach enhances the adaptability of guard models, enabling them to
generalize to new risk categories defined during inference. We plan to
open-source Aegis 2.0 data and models to the research community to aid in the
safety guardrailing of LLMs.

摘要：隨著大型語言模型 (LLM) 和生成式 AI 日益普及，內容安全方面的擔憂也同步增加。目前，顯著缺乏高品質、人工標註的資料集來解決與 LLM 相關的安全風險全貌，且可供商業應用使用。為了彌補這個差距，我們提出了一個全面且適應性強的分類法，用於分類安全風險，架構成 12 個頂層危害類別，並延伸到 9 個細緻的子類別。此分類法旨在滿足下游使用者的多元需求，提供更細緻且彈性的工具來管理各種風險類型。我們使用結合人工標註和多 LLM「評審團」系統的混合資料產生流程來評估回應的安全性，取得 Aegis 2.0，一個經過仔細整理、包含 34,248 個範例的人類 LLM 互動集合，並根據我們提出的分類法進行標註。為了驗證其有效性，我們示範了數個輕量級模型，使用參數有效技術在 Aegis 2.0 上訓練，其效能與在更大、非商業資料集上進行微調的領先安全模型不相上下。此外，我們引進一種新穎的訓練混合，結合安全性與主題追蹤資料。此方法增強了防護模型的適應性，讓它們能夠在推論期間概化到新的風險類別。我們計畫將 Aegis 2.0 資料和模型開源給研究社群，以協助 LLM 的安全防護。

##### **Personality Modeling for Persuasion of Misinformation using AI Agent**
2501.08985v1 by Qianmin Lou, Wentao Xu

The proliferation of misinformation on social media platforms has highlighted
the need to understand how individual personality traits influence
susceptibility to and propagation of misinformation. This study employs an
innovative agent-based modeling approach to investigate the relationship
between personality traits and misinformation dynamics. Using six AI agents
embodying different dimensions of the Big Five personality traits
(Extraversion, Agreeableness, and Neuroticism), we simulated interactions
across six diverse misinformation topics. The experiment, implemented through
the AgentScope framework using the GLM-4-Flash model, generated 90 unique
interactions, revealing complex patterns in how personality combinations affect
persuasion and resistance to misinformation. Our findings demonstrate that
analytical and critical personality traits enhance effectiveness in
evidence-based discussions, while non-aggressive persuasion strategies show
unexpected success in misinformation correction. Notably, agents with critical
traits achieved a 59.4% success rate in HIV-related misinformation discussions,
while those employing non-aggressive approaches maintained consistent
persuasion rates above 40% across different personality combinations. The study
also revealed a non-transitive pattern in persuasion effectiveness, challenging
conventional assumptions about personality-based influence. These results
provide crucial insights for developing personality-aware interventions in
digital environments and suggest that effective misinformation countermeasures
should prioritize emotional connection and trust-building over confrontational
approaches. The findings contribute to both theoretical understanding of
personality-misinformation dynamics and practical strategies for combating
misinformation in social media contexts.

摘要：社交媒體平台上錯誤訊息的激增，凸顯了了解個人人格特質如何影響對錯誤訊息的敏感度和傳播的重要性。本研究採用創新的基於代理的建模方法來探討人格特質與錯誤訊息動態之間的關係。我們使用六個體現大五人格特質不同面向（外向性、親和性和神經質）的人工智慧代理，模擬了六個不同錯誤訊息主題之間的互動。透過使用 GLM-4-Flash 模型，透過 AgentScope 框架執行的實驗產生了 90 個獨特互動，揭示了人格組合如何影響說服力和對錯誤訊息的抵抗力。我們的研究結果表明，分析和批判的人格特質可以提高基於證據的討論的有效性，而非侵略性的說服策略在錯誤訊息更正方面顯示出意想不到的成功。值得注意的是，具有批判特質的代理人在與 HIV 相關的錯誤訊息討論中取得了 59.4% 的成功率，而採用非侵略性方法的代理人在不同人格組合中維持了一致的說服率，高於 40%。該研究還揭示了說服有效性的非遞移模式，挑戰了基於人格的影響的傳統假設。這些結果為在數位環境中開發具有個性化的干預措施提供了重要的見解，並表明有效的錯誤訊息對策應優先考慮情感聯繫和建立信任，而不是對抗性方法。這些發現有助於對人格錯誤訊息動態的理論理解和在社交媒體背景下打擊錯誤訊息的實用策略。

