
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-30**|**MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning**|Haotian Zhang et.al.|[2409.20566v1](http://arxiv.org/abs/2409.20566v1)|null|
|**2024-09-30**|**Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments**|Iker De la Iglesia et.al.|[2409.20565v1](http://arxiv.org/abs/2409.20565v1)|null|
|**2024-09-30**|**LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner**|Xiaopan Zhang et.al.|[2409.20560v1](http://arxiv.org/abs/2409.20560v1)|null|
|**2024-09-30**|**Maia-2: A Unified Model for Human-AI Alignment in Chess**|Zhenwei Tang et.al.|[2409.20553v1](http://arxiv.org/abs/2409.20553v1)|null|
|**2024-09-30**|**LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation**|Ziyao Zhang et.al.|[2409.20550v1](http://arxiv.org/abs/2409.20550v1)|null|
|**2024-09-30**|**Robi Butler: Remote Multimodal Interactions with Household Robot Assistant**|Anxing Xiao et.al.|[2409.20548v1](http://arxiv.org/abs/2409.20548v1)|null|
|**2024-09-30**|**Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource**|Pablo Ortega et.al.|[2409.20524v1](http://arxiv.org/abs/2409.20524v1)|null|
|**2024-09-30**|**SMLE: Safe Machine Learning via Embedded Overapproximation**|Matteo Francobaldi et.al.|[2409.20517v1](http://arxiv.org/abs/2409.20517v1)|null|
|**2024-09-30**|**What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach**|Xingfang Wu et.al.|[2409.20503v1](http://arxiv.org/abs/2409.20503v1)|null|
|**2024-09-30**|**COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models**|Divyanshu Daiya et.al.|[2409.20502v1](http://arxiv.org/abs/2409.20502v1)|null|
|**2024-09-30**|**Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation**|Vlad-Cristian Matei et.al.|[2409.20498v1](http://arxiv.org/abs/2409.20498v1)|null|
|**2024-09-30**|**RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations**|Johannes Kruse et.al.|[2409.20483v1](http://arxiv.org/abs/2409.20483v1)|null|
|**2024-09-30**|**A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media**|Dung Ha Nguyen et.al.|[2409.20467v1](http://arxiv.org/abs/2409.20467v1)|null|
|**2024-09-30**|**Language Resources in Spanish for Automatic Text Simplification across Domains**|Antonio Moreno-Sandoval et.al.|[2409.20466v1](http://arxiv.org/abs/2409.20466v1)|null|
|**2024-09-30**|**POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator**|Eugenio Lomurno et.al.|[2409.20447v1](http://arxiv.org/abs/2409.20447v1)|null|
|**2024-09-30**|**Instance-adaptive Zero-shot Chain-of-Thought Prompting**|Xiaosong Yuan et.al.|[2409.20441v2](http://arxiv.org/abs/2409.20441v2)|null|
|**2024-09-30**|**QAEncoder: Towards Aligned Representation Learning in Question Answering System**|Zhengren Wang et.al.|[2409.20434v1](http://arxiv.org/abs/2409.20434v1)|null|
|**2024-09-30**|**HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding**|Fan Yuan et.al.|[2409.20429v1](http://arxiv.org/abs/2409.20429v1)|null|
|**2024-09-30**|**Sufficient and Necessary Explanations (and What Lies in Between)**|Beepul Bharti et.al.|[2409.20427v1](http://arxiv.org/abs/2409.20427v1)|null|
|**2024-09-30**|**World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering**|Jiacong Wang et.al.|[2409.20424v1](http://arxiv.org/abs/2409.20424v1)|null|
|**2024-09-30**|**Stream-level flow matching from a Bayesian decision theoretic perspective**|Ganchao Wei et.al.|[2409.20423v1](http://arxiv.org/abs/2409.20423v1)|null|
|**2024-09-30**|**Conformal Prediction for Dose-Response Models with Continuous Treatments**|Jarne Verhaeghe et.al.|[2409.20412v1](http://arxiv.org/abs/2409.20412v1)|null|
|**2024-09-30**|**Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing**|Connor Baumler et.al.|[2409.20390v1](http://arxiv.org/abs/2409.20390v1)|null|
|**2024-09-30**|**Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation**|Shan Chen et.al.|[2409.20385v1](http://arxiv.org/abs/2409.20385v1)|null|
|**2024-09-30**|**Word-wise intonation model for cross-language TTS systems**|Tomilov A. A. et.al.|[2409.20374v1](http://arxiv.org/abs/2409.20374v1)|null|
|**2024-09-30**|**Frequency Adaptive Normalization For Non-stationary Time Series Forecasting**|Weiwei Ye et.al.|[2409.20371v1](http://arxiv.org/abs/2409.20371v1)|null|
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Disentangling Singlish Discourse Particles with Task-Driven Representation**|Linus Tze En Foo et.al.|[2409.20366v1](http://arxiv.org/abs/2409.20366v1)|null|
|**2024-09-30**|**Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models**|Yizhou Huang et.al.|[2409.20364v1](http://arxiv.org/abs/2409.20364v1)|null|
|**2024-09-30**|**Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference**|Ke Yi et.al.|[2409.20361v1](http://arxiv.org/abs/2409.20361v1)|null|
|**2024-09-30**|**Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization**|Osama Mustafa et.al.|[2409.20340v2](http://arxiv.org/abs/2409.20340v2)|null|
|**2024-09-30**|**Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**|Takafumi Moriya et.al.|[2409.20313v1](http://arxiv.org/abs/2409.20313v1)|null|
|**2024-09-30**|**A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions**|Laurène Vaugrante et.al.|[2409.20303v1](http://arxiv.org/abs/2409.20303v1)|null|
|**2024-09-30**|**PersonalLLM: Tailoring LLMs to Individual Preferences**|Thomas P. Zollo et.al.|[2409.20296v1](http://arxiv.org/abs/2409.20296v1)|null|
|**2024-09-30**|**LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models**|Haitao Li et.al.|[2409.20288v1](http://arxiv.org/abs/2409.20288v1)|[link](https://github.com/cshaitao/lexeval)|
|**2024-09-30**|**Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis**|Stanley Mugisha. Mirko Job. Matteo Zoppi et.al.|[2409.20260v1](http://arxiv.org/abs/2409.20260v1)|null|
|**2024-09-30**|**What is the Role of Large Language Models in the Evolution of Astronomy Research?**|Morgan Fouesneau et.al.|[2409.20252v1](http://arxiv.org/abs/2409.20252v1)|null|
|**2024-09-30**|**Resource Allocation for Stable LLM Training in Mobile Edge Computing**|Chang Liu et.al.|[2409.20247v1](http://arxiv.org/abs/2409.20247v1)|null|
|**2024-09-30**|**Analysing Zero-Shot Readability-Controlled Sentence Simplification**|Abdullah Barayan et.al.|[2409.20246v1](http://arxiv.org/abs/2409.20246v1)|null|
|**2024-09-30**|**PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling**|Huachuan Qiu et.al.|[2409.20243v1](http://arxiv.org/abs/2409.20243v1)|[link](https://github.com/qiuhuachuan/psyguard)|
|**2024-09-30**|**Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models**|David Castillo-Bolado et.al.|[2409.20222v1](http://arxiv.org/abs/2409.20222v1)|null|
|**2024-09-30**|**Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach**|Aditi Dutta et.al.|[2409.20204v1](http://arxiv.org/abs/2409.20204v1)|null|
|**2024-09-30**|**AfriHuBERT: A self-supervised speech representation model for African languages**|Jesujoba O. Alabi et.al.|[2409.20201v1](http://arxiv.org/abs/2409.20201v1)|null|
|**2024-09-30**|**Melody Is All You Need For Music Generation**|Shaopeng Wei et.al.|[2409.20196v1](http://arxiv.org/abs/2409.20196v1)|[link](https://github.com/shaopengw/Awesome-Music-Generation)|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v1](http://arxiv.org/abs/2409.20195v1)|null|
|**2024-09-30**|**Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work**|Samuel Kernan Freire et.al.|[2409.20192v1](http://arxiv.org/abs/2409.20192v1)|null|
|**2024-09-30**|**TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks**|Areeg Fahad Rasheed et.al.|[2409.20189v1](http://arxiv.org/abs/2409.20189v1)|[link](https://github.com/AREEG94FAHAD/TaskComplexityEval-24)|
|**2024-09-30**|**Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth**|Joseph D. Ramsey et.al.|[2409.20187v1](http://arxiv.org/abs/2409.20187v1)|null|
|**2024-09-30**|**Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models**|Luohe Shi et.al.|[2409.20181v1](http://arxiv.org/abs/2409.20181v1)|null|
|**2024-09-30**|**Modelando procesos cognitivos de la lectura natural con GPT-2**|Bruno Bianchi et.al.|[2409.20174v1](http://arxiv.org/abs/2409.20174v1)|null|
|**2024-09-30**|**Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information**|Hyeongdon Moon et.al.|[2409.20167v1](http://arxiv.org/abs/2409.20167v1)|null|
|**2024-09-30**|**How Entangled is Factuality and Deception in German?**|Aswathy Velutharambath et.al.|[2409.20165v1](http://arxiv.org/abs/2409.20165v1)|null|
|**2024-09-30**|**MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants**|Zeyu Zhang et.al.|[2409.20163v1](http://arxiv.org/abs/2409.20163v1)|[link](https://github.com/nuster1128/memsim)|
|**2024-09-30**|**1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models**|Chanjun Park et.al.|[2409.20149v1](http://arxiv.org/abs/2409.20149v1)|null|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|null|
|**2024-09-30**|**Federated Instruction Tuning of LLMs with Domain Coverage Augmentation**|Zezhou Wang et.al.|[2409.20135v2](http://arxiv.org/abs/2409.20135v2)|null|
|**2024-09-30**|**ACE: Abstractions for Communicating Efficiently**|Jonathan D. Thomas et.al.|[2409.20120v1](http://arxiv.org/abs/2409.20120v1)|null|
|**2024-09-30**|**Aggressive Post-Training Compression on Extremely Large Language Models**|Zining Zhang et.al.|[2409.20094v1](http://arxiv.org/abs/2409.20094v1)|null|
|**2024-09-30**|**Robust LLM safeguarding via refusal feature adversarial training**|Lei Yu et.al.|[2409.20089v1](http://arxiv.org/abs/2409.20089v1)|null|
|**2024-09-30**|**BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain**|Kaisi Guan et.al.|[2409.20075v1](http://arxiv.org/abs/2409.20075v1)|null|
|**2024-09-30**|**Knowledge Discovery using Unsupervised Cognition**|Alfredo Ibias et.al.|[2409.20064v1](http://arxiv.org/abs/2409.20064v1)|null|
|**2024-09-30**|**Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis**|Hippolyte Gisserot-Boukhlef et.al.|[2409.20059v1](http://arxiv.org/abs/2409.20059v1)|null|
|**2024-09-30**|**Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis**|Luka Andrenšek et.al.|[2409.20054v1](http://arxiv.org/abs/2409.20054v1)|null|
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v1](http://arxiv.org/abs/2409.20053v1)|null|
|**2024-09-30**|**Mitigating Propensity Bias of Large Language Models for Recommender Systems**|Guixian Zhang et.al.|[2409.20052v1](http://arxiv.org/abs/2409.20052v1)|null|
|**2024-09-30**|**Depression detection in social media posts using transformer-based models and auxiliary features**|Marios Kerasiotis et.al.|[2409.20048v1](http://arxiv.org/abs/2409.20048v1)|null|
|**2024-09-30**|**Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback**|Menna Fateen et.al.|[2409.20042v1](http://arxiv.org/abs/2409.20042v1)|null|
|**2024-09-30**|**Towards Robust Multimodal Sentiment Analysis with Incomplete Data**|Haoyu Zhang et.al.|[2409.20012v1](http://arxiv.org/abs/2409.20012v1)|null|
|**2024-09-30**|**Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models**|Frank Wawrzik et.al.|[2409.20010v1](http://arxiv.org/abs/2409.20010v1)|null|
|**2024-09-30**|**Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data**|Ke-Han Lu et.al.|[2409.20007v1](http://arxiv.org/abs/2409.20007v1)|null|
|**2024-09-30**|**Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification**|Jiseok Lee et.al.|[2409.20005v1](http://arxiv.org/abs/2409.20005v1)|null|
|**2024-09-30**|**Do Influence Functions Work on Large Language Models?**|Zhe Li et.al.|[2409.19998v1](http://arxiv.org/abs/2409.19998v1)|null|
|**2024-09-30**|**Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges**|Qin Liu et.al.|[2409.19993v1](http://arxiv.org/abs/2409.19993v1)|null|
|**2024-09-30**|**Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**|Oswald Zink et.al.|[2409.19990v1](http://arxiv.org/abs/2409.19990v1)|null|
|**2024-09-30**|**CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models**|Eitan Wagner et.al.|[2409.19984v1](http://arxiv.org/abs/2409.19984v1)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-30**|**Knowledge Graph Embedding by Normalizing Flows**|Changyi Xiao et.al.|[2409.19977v1](http://arxiv.org/abs/2409.19977v1)|[link](https://github.com/changyi7231/nfe)|
|**2024-09-30**|**Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval**|Yabing Wang et.al.|[2409.19961v1](http://arxiv.org/abs/2409.19961v1)|null|
|**2024-09-30**|**TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning**|Joshua Feinglass et.al.|[2409.19960v1](http://arxiv.org/abs/2409.19960v1)|null|
|**2024-09-30**|**Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification**|Shiben Liu et.al.|[2409.19954v1](http://arxiv.org/abs/2409.19954v1)|null|
|**2024-09-30**|**Law of the Weakest Link: Cross Capabilities of Large Language Models**|Ming Zhong et.al.|[2409.19951v1](http://arxiv.org/abs/2409.19951v1)|[link](https://github.com/facebookresearch/llm-cross-capabilities)|
|**2024-09-30**|**Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner**|Chenyou Fan et.al.|[2409.19949v1](http://arxiv.org/abs/2409.19949v1)|null|
|**2024-09-30**|**JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers**|Masato Fujitake et.al.|[2409.19948v1](http://arxiv.org/abs/2409.19948v1)|null|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-30**|**Large Language Model Empowered Embedding Generator for Sequential Recommendation**|Qidong Liu et.al.|[2409.19925v1](http://arxiv.org/abs/2409.19925v1)|null|
|**2024-09-30**|**On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability**|Kevin Wang et.al.|[2409.19924v2](http://arxiv.org/abs/2409.19924v2)|[link](https://github.com/vita-group/o1-planning)|
|**2024-09-30**|**Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming**|Ming Li et.al.|[2409.19916v1](http://arxiv.org/abs/2409.19916v1)|null|
|**2024-09-30**|**Scaling Optimal LR Across Token Horizon**|Johan Bjorck et.al.|[2409.19913v1](http://arxiv.org/abs/2409.19913v1)|null|
|**2024-09-30**|**UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs**|Yuho Lee et.al.|[2409.19898v2](http://arxiv.org/abs/2409.19898v2)|[link](https://github.com/disl-lab/unisumeval-v1.0)|
|**2024-09-30**|**TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation**|Zhiqiang Yuan et.al.|[2409.19894v2](http://arxiv.org/abs/2409.19894v2)|null|
|**2024-09-30**|**RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models**|Shuhao Chen et.al.|[2409.19886v1](http://arxiv.org/abs/2409.19886v1)|[link](https://github.com/shuhao02/routerdc)|
|**2024-09-30**|**SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding**|Ziyang Zhang et.al.|[2409.19884v1](http://arxiv.org/abs/2409.19884v1)|[link](https://github.com/windowso/swim-asad)|
|**2024-09-30**|**Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation**|Huangyu Dai et.al.|[2409.19877v1](http://arxiv.org/abs/2409.19877v1)|null|
|**2024-09-30**|**TSI: A Multi-View Representation Learning Approach for Time Series Forecasting**|Wentao Gao et.al.|[2409.19871v1](http://arxiv.org/abs/2409.19871v1)|null|
|**2024-09-30**|**The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging**|Masanori Hirano et.al.|[2409.19854v1](http://arxiv.org/abs/2409.19854v1)|null|
|**2024-09-30**|**ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities**|Ezra Karger et.al.|[2409.19839v1](http://arxiv.org/abs/2409.19839v1)|null|
|**2024-09-29**|**Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation**|Mohamed A. Radwan et.al.|[2409.19824v1](http://arxiv.org/abs/2409.19824v1)|null|
|**2024-09-29**|**Calibrating Language Models with Adaptive Temperature Scaling**|Johnathan Xie et.al.|[2409.19817v1](http://arxiv.org/abs/2409.19817v1)|null|
|**2024-09-29**|**Grounded Curriculum Learning**|Linji Wang et.al.|[2409.19816v1](http://arxiv.org/abs/2409.19816v1)|null|
|**2024-09-29**|**Transforming Hidden States into Binary Semantic Features**|Tomáš Musil et.al.|[2409.19813v1](http://arxiv.org/abs/2409.19813v1)|null|

#### Abstracts
##### **MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning**
2409.20566v1 by Haotian Zhang, Mingfei Gao, Zhe Gan, Philipp Dufter, Nina Wenzel, Forrest Huang, Dhruti Shah, Xianzhi Du, Bowen Zhang, Yanghao Li, Sam Dodge, Keen You, Zhen Yang, Aleksei Timofeev, Mingze Xu, Hong-You Chen, Jean-Philippe Fauconnier, Zhengfeng Lai, Haoxuan You, Zirui Wang, Afshin Dehghan, Peter Grasch, Yinfei Yang

We present MM1.5, a new family of multimodal large language models (MLLMs)
designed to enhance capabilities in text-rich image understanding, visual
referring and grounding, and multi-image reasoning. Building upon the MM1
architecture, MM1.5 adopts a data-centric approach to model training,
systematically exploring the impact of diverse data mixtures across the entire
model training lifecycle. This includes high-quality OCR data and synthetic
captions for continual pre-training, as well as an optimized visual
instruction-tuning data mixture for supervised fine-tuning. Our models range
from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE)
variants, and demonstrate that careful data curation and training strategies
can yield strong performance even at small scales (1B and 3B). Additionally, we
introduce two specialized variants: MM1.5-Video, designed for video
understanding, and MM1.5-UI, tailored for mobile UI understanding. Through
extensive empirical studies and ablations, we provide detailed insights into
the training processes and decisions that inform our final designs, offering
valuable guidance for future research in MLLM development.

摘要：我們提出 MM1.5，一種新的多模態大型語言模型 (MLLM) 家族，旨在增強文本豐富影像理解、視覺指涉和基礎，以及多影像推理的能力。在 MM1 架構的基礎上，MM1.5 採用以資料為中心的模型訓練方法，系統性地探討各種資料混合對整個模型訓練生命週期的影響。這包括用於持續預訓練的高品質 OCR 資料和合成式字幕，以及用於監督微調的最佳化視覺指令調校資料混合。我們的模型範圍從 1B 到 30B 參數，包含密集和專家混合 (MoE) 變體，並證明仔細的資料策展和訓練策略即使在小規模 (1B 和 3B) 下也能產生強大的效能。此外，我們還引入了兩個專門的變體：MM1.5-Video，專為影片理解而設計，以及 MM1.5-UI，專為行動裝置 UI 理解而設計。透過廣泛的實證研究和消融，我們提供了對訓練流程和決策的詳細見解，這些見解說明了我們的最終設計，為 MLLM 開發的未來研究提供了寶貴的指導。

##### **Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments**
2409.20565v1 by Iker De la Iglesia, Iakes Goenaga, Johanna Ramirez-Romero, Jose Maria Villa-Gonzalez, Josu Goikoetxea, Ander Barrena

Evaluating LLM-generated text has become a key challenge, especially in
domain-specific contexts like the medical field. This work introduces a novel
evaluation methodology for LLM-generated medical explanatory arguments, relying
on Proxy Tasks and rankings to closely align results with human evaluation
criteria, overcoming the biases typically seen in LLMs used as judges. We
demonstrate that the proposed evaluators are robust against adversarial
attacks, including the assessment of non-argumentative text. Additionally, the
human-crafted arguments needed to train the evaluators are minimized to just
one example per Proxy Task. By examining multiple LLM-generated arguments, we
establish a methodology for determining whether a Proxy Task is suitable for
evaluating LLM-generated medical explanatory arguments, requiring only five
examples and two human experts.

摘要：評估 LLM 生成的文字已成為一項關鍵挑戰，特別是在醫療領域等特定領域中。這項工作介紹了一種針對 LLM 生成的醫學解釋性論點的新穎評估方法，依賴代理任務和排名，以將結果與人類評估標準緊密對齊，克服了通常在用作評判的 LLM 中看到的偏差。我們證明了所提出的評估員對對抗性攻擊具有魯棒性，包括對非論證性文字的評估。此外，訓練評估員所需的人工論證已最小化，每個代理任務僅一個範例。通過檢查多個 LLM 生成的論點，我們建立了一種方法來確定代理任務是否適合評估 LLM 生成的醫學解釋性論點，只需要五個範例和兩位人類專家。

##### **LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner**
2409.20560v1 by Xiaopan Zhang, Hao Qin, Fuquan Wang, Yue Dong, Jiachen Li

Language models (LMs) possess a strong capability to comprehend natural
language, making them effective in translating human instructions into detailed
plans for simple robot tasks. Nevertheless, it remains a significant challenge
to handle long-horizon tasks, especially in subtask identification and
allocation for cooperative heterogeneous robot teams. To address this issue, we
propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel
multi-agent task planning framework that achieves state-of-the-art performance
on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning
capability and the traditional heuristic search planner to achieve a high
success rate and efficiency while demonstrating strong generalization across
tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that
features household tasks with two different levels of complexity based on the
AI2-THOR environment. The experimental results demonstrate that LaMMA-P
achieves a 105% higher success rate and 36% higher efficiency than existing
LM-based multi-agent planners. The experimental videos, code, and datasets of
this work as well as the detailed prompts used in each module are available at
https://lamma-p.github.io.

摘要：語言模型 (LM) 擁有強大的理解自然語言的能力，這使得它們能夠有效地將人類指令轉換為簡單機器人任務的詳細計畫。儘管如此，處理長期任務仍然是一個重大的挑戰，特別是在合作異質機器人團隊的子任務識別和分配方面。為了解決這個問題，我們提出了一個語言模型驅動的多代理 PDDL 計畫器 (LaMMA-P)，這是一個新穎的多代理任務計畫框架，在長期任務上實現了最先進的效能。LaMMA-P 整合了 LM 推理能力和傳統啟發式搜尋計畫器的優勢，以實現高成功率和效率，同時在各項任務中展現出強大的泛化能力。此外，我們建立了 MAT-THOR，一個全面的基準測試，它具有基於 AI2-THOR 環境的兩個不同複雜程度的家務任務。實驗結果表明，與現有的基於 LM 的多代理計畫器相比，LaMMA-P 的成功率提高了 105%，效率提高了 36%。這項工作的實驗影片、程式碼和資料集以及每個模組中使用的詳細提示都可以在 https://lamma-p.github.io/ 獲得。

##### **Maia-2: A Unified Model for Human-AI Alignment in Chess**
2409.20553v1 by Zhenwei Tang, Difan Jiao, Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Ashton Anderson

There are an increasing number of domains in which artificial intelligence
(AI) systems both surpass human ability and accurately model human behavior.
This introduces the possibility of algorithmically-informed teaching in these
domains through more relatable AI partners and deeper insights into human
decision-making. Critical to achieving this goal, however, is coherently
modeling human behavior at various skill levels. Chess is an ideal model system
for conducting research into this kind of human-AI alignment, with its rich
history as a pivotal testbed for AI research, mature superhuman AI systems like
AlphaZero, and precise measurements of skill via chess rating systems. Previous
work in modeling human decision-making in chess uses completely independent
models to capture human style at different skill levels, meaning they lack
coherence in their ability to adapt to the full spectrum of human improvement
and are ultimately limited in their effectiveness as AI partners and teaching
tools. In this work, we propose a unified modeling approach for human-AI
alignment in chess that coherently captures human style across different skill
levels and directly captures how people improve. Recognizing the complex,
non-linear nature of human learning, we introduce a skill-aware attention
mechanism to dynamically integrate players' strengths with encoded chess
positions, enabling our model to be sensitive to evolving player skill. Our
experimental results demonstrate that this unified framework significantly
enhances the alignment between AI and human players across a diverse range of
expertise levels, paving the way for deeper insights into human decision-making
and AI-guided teaching tools.

摘要：<paragraph>在人工智能（AI）系統既超越人類能力，又能準確模擬人類行為的領域中，數量正不斷增加。這引入了在這些領域中通過更具關聯性的 AI 合作夥伴和更深入的人類決策制定見解，進行演算法知情教學的可能性。然而，實現此目標的關鍵在於以連貫的方式模擬不同技能級別的人類行為。西洋棋是一個理想的模型系統，可用於對此類人機對齊進行研究，它作為 AI 研究的關鍵測試平台，擁有豐富的歷史，成熟的超人類 AI 系統，例如 AlphaZero，以及通過西洋棋評分系統進行的精確技能測量。先前在西洋棋中模擬人類決策制定的工作使用完全獨立的模型來捕捉不同技能級別的人類風格，這表示它們在適應人類進步全光譜的能力上缺乏連貫性，並且最終在作為 AI 合作夥伴和教學工具方面的效能受到限制。在這項工作中，我們提出了一種統一的建模方法，用於西洋棋中的人機對齊，它以連貫的方式捕捉不同技能級別的人類風格，並直接捕捉人們如何進步。認識到人類學習的複雜、非線性本質，我們引入了一種技能感知注意力機制，以動態整合玩家的優勢與編碼西洋棋位置，使我們的模型能夠對不斷變化的玩家技能做出反應。我們的實驗結果表明，這個統一的框架顯著增強了 AI 和人類玩家在各種專業級別之間的對齊，為更深入了解人類決策制定和 AI 指導的教學工具鋪平了道路。</paragraph>

##### **LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation**
2409.20550v1 by Ziyao Zhang, Yanlin Wang, Chong Wang, Jiachi Chen, Zibin Zheng

Code generation aims to automatically generate code from input requirements,
significantly enhancing development efficiency. Recent large language models
(LLMs) based approaches have shown promising results and revolutionized code
generation task. Despite the promising performance, LLMs often generate
contents with hallucinations, especially for the code generation scenario
requiring the handling of complex contextual dependencies in practical
development process. Although previous study has analyzed hallucinations in
LLM-powered code generation, the study is limited to standalone function
generation. In this paper, we conduct an empirical study to study the
phenomena, mechanism, and mitigation of LLM hallucinations within more
practical and complex development contexts in repository-level generation
scenario. First, we manually examine the code generation results from six
mainstream LLMs to establish a hallucination taxonomy of LLM-generated code.
Next, we elaborate on the phenomenon of hallucinations, analyze their
distribution across different models. We then analyze causes of hallucinations
and identify four potential factors contributing to hallucinations. Finally, we
propose an RAG-based mitigation method, which demonstrates consistent
effectiveness in all studied LLMs. The replication package including code,
data, and experimental results is available at
https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination

摘要：程式碼生成旨在根據輸入需求自動產生程式碼，大幅提升開發效率。最近基於大型語言模型 (LLM) 的方法已展現出有希望的成果，並徹底改變了程式碼生成任務。儘管有令人期待的效能，LLM 經常會產生包含幻覺的內容，特別是在程式碼生成場景，需要處理實際開發過程中複雜的內容相關性。儘管先前的研究已分析 LLM 驅動的程式碼生成中的幻覺，但研究僅限於獨立函式生成。在本文中，我們進行一項實證研究來研究 LLM 幻覺在儲存庫層級生成場景中更實際且複雜的開發背景下的現象、機制和緩解。首先，我們手動檢查來自六個主流 LLM 的程式碼生成結果，以建立 LLM 生成的程式碼的幻覺分類法。接下來，我們詳細說明幻覺的現象，分析它們在不同模型中的分佈。然後，我們分析幻覺的原因，並找出導致幻覺的四個潛在因素。最後，我們提出一個基於 RAG 的緩解方法，在所有研究的 LLM 中都展現出一致的有效性。包含程式碼、資料和實驗結果的複製套件可在 https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination 取得

##### **Robi Butler: Remote Multimodal Interactions with Household Robot Assistant**
2409.20548v1 by Anxing Xiao, Nuwan Janaka, Tianrun Hu, Anshul Gupta, Kaixin Li, Cunjun Yu, David Hsu

In this paper, we introduce Robi Butler, a novel household robotic system
that enables multimodal interactions with remote users. Building on the
advanced communication interfaces, Robi Butler allows users to monitor the
robot's status, send text or voice instructions, and select target objects by
hand pointing. At the core of our system is a high-level behavior module,
powered by Large Language Models (LLMs), that interprets multimodal
instructions to generate action plans. These plans are composed of a set of
open vocabulary primitives supported by Vision Language Models (VLMs) that
handle both text and pointing queries. The integration of the above components
allows Robi Butler to ground remote multimodal instructions in the real-world
home environment in a zero-shot manner. We demonstrate the effectiveness and
efficiency of this system using a variety of daily household tasks that involve
remote users giving multimodal instructions. Additionally, we conducted a user
study to analyze how multimodal interactions affect efficiency and user
experience during remote human-robot interaction and discuss the potential
improvements.

摘要：在本文中，我們介紹了 Robi Butler，這是一個新穎的家用機器人系統，它能與遠端使用者進行多模式互動。Robi Butler 建立在先進的通訊介面上，讓使用者可以監控機器人的狀態、傳送文字或語音指令，以及用手指點選目標物件。我們系統的核心是一個高階行為模組，由大型語言模型 (LLM) 提供支援，它會解譯多模式指令以產生行動計畫。這些計畫由一組開放式詞彙基本元素組成，並由同時處理文字和指向查詢的視覺語言模型 (VLM) 提供支援。上述元件的整合讓 Robi Butler 能在零次學習的情況下，將遠端多模式指令應用於真實世界的居家環境中。我們使用各種涉及遠端使用者提供多模式指令的日常家務任務，來展示此系統的有效性和效率。此外，我們進行了一項使用者研究，以分析多模式互動如何影響遠端人機互動的效率和使用者體驗，並討論潛在的改進方式。

##### **Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource**
2409.20524v1 by Pablo Ortega, Jordi Luque, Luis Lamiable, Rodrigo López, Richard Benjamins

Human language, while aimed at conveying meaning, inherently carries
ambiguity. It poses challenges for speech and language processing, but also
serves crucial communicative functions. Efficiently solve ambiguity is both a
desired and a necessary characteristic. The lexical meaning of a word in
context can be determined automatically by Word Sense Disambiguation (WSD)
algorithms that rely on external knowledge often limited and biased toward
English. When adapting content to other languages, automated translations are
frequently inaccurate and a high degree of expert human validation is necessary
to ensure both accuracy and understanding. The current study addresses previous
limitations by introducing a new resource for Spanish WSD. It includes a sense
inventory and a lexical dataset sourced from the Diccionario de la Lengua
Espa\~nola which is maintained by the Real Academia Espa\~nola. We also review
current resources for Spanish and report metrics on them by a state-of-the-art
system.

摘要：人類語言雖然旨在傳達意義，但本質上卻充滿了歧義。它對語言和語言處理提出了挑戰，但也發揮了至關重要的溝通功能。有效解決歧義既是一種理想，也是一種必要的特質。語境中單詞的詞彙意義可以用詞義消歧 (WSD) 演算法自動確定，這些演算法依賴於外部知識，而這些知識通常有限且偏向於英語。在將內容改編為其他語言時，自動翻譯通常不準確，需要大量專家的人工驗證，以確保準確性和理解度。本研究通過引入西班牙語 WSD 的新資源來解決先前的限制。它包括一個語義庫和一個詞彙資料集，其來源是 Real Academia Espa\~nola 維護的 Diccionario de la Lengua Espa\~nola。我們還回顧了西班牙語的現有資源，並通過最先進的系統對它們進行了指標報告。

##### **SMLE: Safe Machine Learning via Embedded Overapproximation**
2409.20517v1 by Matteo Francobaldi, Michele Lombardi

Despite the extent of recent advances in Machine Learning (ML) and Neural
Networks, providing formal guarantees on the behavior of these systems is still
an open problem, and a crucial requirement for their adoption in regulated or
safety-critical scenarios. We consider the task of training differentiable ML
models guaranteed to satisfy designer-chosen properties, stated as input-output
implications. This is very challenging, due to the computational complexity of
rigorously verifying and enforcing compliance in modern neural models. We
provide an innovative approach based on three components: 1) a general, simple
architecture enabling efficient verification with a conservative semantic; 2) a
rigorous training algorithm based on the Projected Gradient Method; 3) a
formulation of the problem of searching for strong counterexamples. The
proposed framework, being only marginally affected by model complexity, scales
well to practical applications, and produces models that provide full property
satisfaction guarantees. We evaluate our approach on properties defined by
linear inequalities in regression, and on mutually exclusive classes in
multilabel classification. Our approach is competitive with a baseline that
includes property enforcement during preprocessing, i.e. on the training data,
as well as during postprocessing, i.e. on the model predictions. Finally, our
contributions establish a framework that opens up multiple research directions
and potential improvements.

摘要：儘管機器學習 (ML) 和神經網路最近有很大的進展，但要對這些系統的行為提供正式保證仍然是一個開放的問題，也是在受規範或安全關鍵情境中採用它們的關鍵要求。我們考慮訓練可微分 ML 模型的任務，保證滿足設計師選擇的屬性，並表示為輸入輸出蘊涵。由於嚴格驗證和強制現代神經模型的相容性在計算上很複雜，因此這是一個非常具有挑戰性的任務。我們提供了一種基於三個組成的創新方法：1) 一種通用、簡單的架構，能夠使用保守語義進行有效的驗證；2) 一種基於投影梯度法的嚴格訓練演算法；3) 一種尋找強反例的問題表述。所提出的架構僅受模型複雜性邊際影響，可以很好地擴展到實際應用，並且產生的模型提供了完全的屬性滿足保證。我們根據回歸中的線性不等式和多標籤分類中的互斥類別來評估我們的做法。我們的做法與基線具有競爭力，該基線在預處理（即在訓練資料上）和後處理（即在模型預測上）期間都包括屬性強制。最後，我們的貢獻建立了一個框架，為多個研究方向和潛在改進開闢了道路。

##### **What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach**
2409.20503v1 by Xingfang Wu, Heng Li, Foutse Khomh

Log data are generated from logging statements in the source code, providing
insights into the execution processes of software applications and systems.
State-of-the-art log-based anomaly detection approaches typically leverage deep
learning models to capture the semantic or sequential information in the log
data and detect anomalous runtime behaviors. However, the impacts of these
different types of information are not clear. In addition, existing approaches
have not captured the timestamps in the log data, which can potentially provide
more fine-grained temporal information than sequential information. In this
work, we propose a configurable transformer-based anomaly detection model that
can capture the semantic, sequential, and temporal information in the log data
and allows us to configure the different types of information as the model's
features. Additionally, we train and evaluate the proposed model using log
sequences of different lengths, thus overcoming the constraint of existing
methods that rely on fixed-length or time-windowed log sequences as inputs.
With the proposed model, we conduct a series of experiments with different
combinations of input features to evaluate the roles of different types of
information in anomaly detection. When presented with log sequences of varying
lengths, the model can attain competitive and consistently stable performance
compared to the baselines. The results indicate that the event occurrence
information plays a key role in identifying anomalies, while the impact of the
sequential and temporal information is not significant for anomaly detection in
the studied public datasets. On the other hand, the findings also reveal the
simplicity of the studied public datasets and highlight the importance of
constructing new datasets that contain different types of anomalies to better
evaluate the performance of anomaly detection models.

摘要：<paragraph>記錄資料是由原始程式碼中的記錄陳述所產生，提供軟體應用程式和系統執行程式的見解。
最先進的基於記錄的異常偵測方法通常利用深度學習模型來擷取記錄資料中的語義或順序資訊，並偵測異常的執行時間行為。然而，這些不同類型資訊的影響並不清楚。此外，現有的方法並未擷取記錄資料中的時間戳記，這可能會提供比順序資訊更精細的暫時資訊。在這項工作中，我們提出一個可組態的基於轉換器的異常偵測模型，它可以擷取記錄資料中的語義、順序和暫時資訊，並允許我們將不同類型的資訊組態為模型的特徵。此外，我們使用不同長度的記錄序列訓練和評估所提出的模型，從而克服現有方法的限制，這些方法依賴於固定長度或時間視窗的記錄序列作為輸入。使用所提出的模型，我們進行了一系列具有不同輸入特徵組合的實驗，以評估不同類型資訊在異常偵測中的角色。當提供長度不同的記錄序列時，與基線相比，該模型可以達到競爭且始終穩定的效能。結果表明，事件發生資訊在識別異常中扮演關鍵角色，而順序和暫時資訊的影響對於所研究的公開資料集中的異常偵測並不顯著。另一方面，這些發現也揭示了所研究的公開資料集的簡單性，並強調建構包含不同類型異常的新資料集以更好地評估異常偵測模型效能的重要性。</paragraph>

##### **COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models**
2409.20502v1 by Divyanshu Daiya, Damon Conover, Aniket Bera

We propose a novel framework COLLAGE for generating collaborative
agent-object-agent interactions by leveraging large language models (LLMs) and
hierarchical motion-specific vector-quantized variational autoencoders
(VQ-VAEs). Our model addresses the lack of rich datasets in this domain by
incorporating the knowledge and reasoning abilities of LLMs to guide a
generative diffusion model. The hierarchical VQ-VAE architecture captures
different motion-specific characteristics at multiple levels of abstraction,
avoiding redundant concepts and enabling efficient multi-resolution
representation. We introduce a diffusion model that operates in the latent
space and incorporates LLM-generated motion planning cues to guide the
denoising process, resulting in prompt-specific motion generation with greater
control and diversity. Experimental results on the CORE-4D, and InterHuman
datasets demonstrate the effectiveness of our approach in generating realistic
and diverse collaborative human-object-human interactions, outperforming
state-of-the-art methods. Our work opens up new possibilities for modeling
complex interactions in various domains, such as robotics, graphics and
computer vision.

摘要：我們提出一個名為 COLLAGE 的新框架，透過利用大型語言模型 (LLM) 和分層動作特定向量量化變異自動編碼器 (VQ-VAE) 來產生協作主體-物件-主體互動。我們的模型透過整合 LLM 的知識和推理能力來引導生成擴散模型，來解決此領域中缺乏豐富資料集的問題。分層 VQ-VAE 架構在多個抽象層級中擷取不同的動作特定特徵，避免冗餘概念並啟用有效率的多解析度表示。我們引入一個在潛在空間中運作的擴散模型，並整合 LLM 生成的動作規劃提示來引導去噪程序，產生具有更高控制和多樣性的提示特定動作。在 CORE-4D 和 InterHuman 資料集上的實驗結果證明了我們的方法在產生真實且多樣化的協作人體-物件-人體互動方面的有效性，優於最先進的方法。我們的研究為在各種領域（例如機器人技術、圖形和電腦視覺）中建模複雜互動開啟了新的可能性。

##### **Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation**
2409.20498v1 by Vlad-Cristian Matei, Iulian-Marius Tăiatu, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel

This paper highlights the significance of natural language processing (NLP)
within artificial intelligence, underscoring its pivotal role in comprehending
and modeling human language. Recent advancements in NLP, particularly in
conversational bots, have garnered substantial attention and adoption among
developers. This paper explores advanced methodologies for attaining smaller
and more efficient NLP models. Specifically, we employ three key approaches:
(1) training a Transformer-based neural network to detect offensive language,
(2) employing data augmentation and knowledge distillation techniques to
increase performance, and (3) incorporating multi-task learning with knowledge
distillation and teacher annealing using diverse datasets to enhance
efficiency. The culmination of these methods has yielded demonstrably improved
outcomes.

摘要：本文重点阐述自然语言处理 (NLP) 在人工智能中的重要性，强调其在理解和建模人类语言中至关重要的作用。NLP 的最新进展，尤其是在会话机器人方面，已引起开发人员的极大关注和采用。本文探讨了实现更小、更高效的 NLP 模型的高级方法。具体来说，我们采用了三种关键方法：(1) 训练基于 Transformer 的神经网络来检测攻击性语言，(2) 采用数据增强和知识蒸馏技术来提高性能，以及 (3) 结合多任务学习与知识蒸馏和教师退火，使用不同的数据集来提高效率。这些方法的结合产生了明显改善的结果。

##### **RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations**
2409.20483v1 by Johannes Kruse, Kasper Lindskow, Saikishore Kalloori, Marco Polignano, Claudio Pomo, Abhishek Srivastava, Anshuk Uppal, Michael Riis Andersen, Jes Frellsen

The RecSys Challenge 2024 aims to advance news recommendation by addressing
both the technical and normative challenges inherent in designing effective and
responsible recommender systems for news publishing. This paper describes the
challenge, including its objectives, problem setting, and the dataset provided
by the Danish news publishers Ekstra Bladet and JP/Politikens Media Group
("Ekstra Bladet"). The challenge explores the unique aspects of news
recommendation, such as modeling user preferences based on behavior, accounting
for the influence of the news agenda on user interests, and managing the rapid
decay of news items. Additionally, the challenge embraces normative
complexities, investigating the effects of recommender systems on news flow and
their alignment with editorial values. We summarize the challenge setup,
dataset characteristics, and evaluation metrics. Finally, we announce the
winners and highlight their contributions. The dataset is available at:
https://recsys.eb.dk.

摘要：RecSys Challenge 2024 旨在透過解決設計有效且負責任的新聞發布推薦系統時固有的技術和規範挑戰，來提升新聞推薦。本文說明了挑戰，包括其目標、問題設定，以及丹麥新聞出版商 Ekstra Bladet 和 JP/Politikens Media Group（「Ekstra Bladet」）提供的資料集。挑戰探討新聞推薦的獨特面向，例如根據行為建模使用者偏好、考量新聞議程對使用者興趣的影響，以及管理新聞項目快速衰退。此外，挑戰涵蓋規範的複雜性，調查推薦系統對新聞流程的影響，以及它們與編輯價值觀的一致性。我們總結挑戰設定、資料集特徵和評量指標。最後，我們宣布獲獎者並強調他們的貢獻。資料集可在以下網址取得：https://recsys.eb.dk。

##### **A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media**
2409.20467v1 by Dung Ha Nguyen, Anh Thi Hoang Nguyen, Kiet Van Nguyen

This study introduces an innovative automatic labeling framework to address
the challenges of lexical normalization in social media texts for low-resource
languages like Vietnamese. Social media data is rich and diverse, but the
evolving and varied language used in these contexts makes manual labeling
labor-intensive and expensive. To tackle these issues, we propose a framework
that integrates semi-supervised learning with weak supervision techniques. This
approach enhances the quality of training dataset and expands its size while
minimizing manual labeling efforts. Our framework automatically labels raw
data, converting non-standard vocabulary into standardized forms, thereby
improving the accuracy and consistency of the training data. Experimental
results demonstrate the effectiveness of our weak supervision framework in
normalizing Vietnamese text, especially when utilizing Pre-trained Language
Models. The proposed framework achieves an impressive F1-score of 82.72% and
maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally,
it effectively handles undiacritized text under various conditions. This
framework significantly enhances natural language normalization quality and
improves the accuracy of various NLP tasks, leading to an average accuracy
increase of 1-3%.

摘要：本研究提出一個創新的自動標籤框架，以解決越南語等低資源語言在社群媒體文字中詞彙標準化的挑戰。社群媒體資料豐富且多元，但這些情境中使用不斷演進且多變的語言，使得手動標籤費時且昂貴。為了應對這些問題，我們提出一個將半監督式學習與弱監督式技術整合的框架。此方法提升訓練資料集的品質並擴充其規模，同時將手動標籤工作降至最低。我們的框架自動標籤原始資料，將非標準詞彙轉換為標準化形式，進而提升訓練資料的準確度和一致性。實驗結果證明我們的弱監督式框架在標準化越南語文字上具有成效，特別是在使用預訓練語言模型時。提出的框架達到令人印象深刻的 82.72% F1 分數，並以高達 99.22% 的準確度維持詞彙完整性。此外，它在各種條件下有效處理未加附加符號的文字。這個框架顯著提升自然語言標準化的品質，並提升各種自然語言處理任務的準確度，導致平均準確度提升 1-3%。

##### **Language Resources in Spanish for Automatic Text Simplification across Domains**
2409.20466v1 by Antonio Moreno-Sandoval, Leonardo Campillos-Llanos, Ana García-Serrano

This work describes the language resources and models developed for automatic
simplification of Spanish texts in three domains: Finance, Medicine and History
studies. We created several corpora in each domain, annotation and
simplification guidelines, a lexicon of technical and simplified medical terms,
datasets used in shared tasks for the financial domain, and two simplification
tools. The methodology, resources and companion publications are shared
publicly on the web-site: https://clara-nlp.uned.es/.

摘要：本研究描述了为三个领域的西班牙语文本自动简化而开发的语言资源和模型：金融、医学和历史研究。我们在每个领域创建了多个语料库、注释和简化指南、技术和简化医学术语词典、用于金融领域共享任务的数据集以及两个简化工具。方法、资源和配套出版物在网站上公开共享：https://clara-nlp.uned.es/。

##### **POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator**
2409.20447v1 by Eugenio Lomurno, Samuele Mariani, Matteo Monti, Matteo Matteucci

Neural Architecture Search (NAS) automates neural network design, reducing
dependence on human expertise. While NAS methods are computationally intensive
and dataset-specific, auxiliary predictors reduce the models needing training,
decreasing search time. This strategy is used to generate architectures
satisfying multiple computational constraints. Recently, Transferable NAS has
emerged, generalizing the search process from dataset-dependent to
task-dependent. In this field, DiffusionNAG is a state-of-the-art method. This
diffusion-based approach streamlines computation, generating architectures
optimized for accuracy on unseen datasets without further adaptation. However,
by focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives
like model complexity, computational efficiency, and inference latency --
factors essential for deploying models in resource-constrained environments.
This paper introduces the Pareto-Optimal Many-Objective Neural Architecture
Generator (POMONAG), extending DiffusionNAG via a many-objective diffusion
process. POMONAG simultaneously considers accuracy, number of parameters,
multiply-accumulate operations (MACs), and inference latency. It integrates
Performance Predictor models to estimate these metrics and guide diffusion
gradients. POMONAG's optimization is enhanced by expanding its training
Meta-Dataset, applying Pareto Front Filtering, and refining embeddings for
conditional generation. These enhancements enable POMONAG to generate
Pareto-optimal architectures that outperform the previous state-of-the-art in
performance and efficiency. Results were validated on two search spaces --
NASBench201 and MobileNetV3 -- and evaluated across 15 image classification
datasets.

摘要：<paragraph>神經架構搜尋 (NAS) 自動化神經網路設計，減少對人類專業知識的依賴。儘管 NAS 方法在計算上很密集且特定於資料集，但輔助預測器可減少需要訓練的模型，縮短搜尋時間。此策略用於產生滿足多項運算限制的架構。近期，可轉移 NAS 已浮現，將搜尋程序從特定於資料集概括為特定於任務。在這個領域，DiffusionNAG 是一種最先進的方法。這種基於擴散的方法簡化了運算，產生了針對未見資料集最佳化準確度的架構，而無需進一步調整。然而，DiffusionNAG 僅專注於準確度，而忽略了其他關鍵目標，例如模型複雜度、運算效率和推論延遲，這些因素對於在資源受限的環境中部署模型至關重要。本文介紹了 Pareto 最佳多目標神經架構產生器 (POMONAG)，透過多目標擴散過程擴充 DiffusionNAG。POMONAG 同時考慮準確度、參數數量、乘累加運算 (MAC) 和推論延遲。它整合了效能預測器模型來估計這些指標並引導擴散梯度。POMONAG 的最佳化透過擴充其訓練元資料集、應用 Pareto 前緣過濾和精煉用於條件式產生的嵌入式元件而增強。這些增強功能讓 POMONAG 能夠產生 Pareto 最佳架構，其效能和效率優於先前的最先進技術。結果在兩個搜尋空間（NASBench201 和 MobileNetV3）上得到驗證，並在 15 個影像分類資料集上進行評估。</paragraph>

##### **Instance-adaptive Zero-shot Chain-of-Thought Prompting**
2409.20441v2 by Xiaosong Yuan, Chen Shen, Shaotian Yan, Xiaofeng Zhang, Liang Xie, Wenxiao Wang, Renchu Guan, Ying Wang, Jieping Ye

Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective
strategy for enhancing the performance of large language models (LLMs) in
real-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level
prompt uniformly applied across the whole of instances is inherently limited
since one prompt cannot be a good partner for all, a more appropriate approach
should consider the interaction between the prompt and each instance
meticulously. This work introduces an instance-adaptive prompting algorithm as
an alternative zero-shot CoT reasoning scheme by adaptively differentiating
good and bad prompts. Concretely, we first employ analysis on LLMs through the
lens of information flow to detect the mechanism under zero-shot CoT reasoning,
in which we discover that information flows from question to prompt and
question to rationale jointly influence the reasoning results most. We notice
that a better zero-shot CoT reasoning needs the prompt to obtain semantic
information from the question then the rationale aggregates sufficient
information from the question directly and via the prompt indirectly. On the
contrary, lacking any of those would probably lead to a bad one. Stem from
that, we further propose an instance-adaptive prompting strategy (IAP) for
zero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen
on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal
Judgement) obtain consistent improvement, demonstrating that the
instance-adaptive zero-shot CoT prompting performs better than other task-level
methods with some curated prompts or sophisticated procedures, showing the
significance of our findings in the zero-shot CoT reasoning mechanism.

摘要：零次發想鏈（CoT）提示作為一種簡單且有效的策略，用於增強大型語言模型（LLM）在現實世界推理任務中的表現。儘管如此，單一任務級別提示在所有實例中統一應用的效力本質上是有限的，因為一個提示無法成為所有提示的好夥伴，一個更適當的方法應該仔細考慮提示與每個實例之間的交互。這項工作引入了一個實例自適應提示演算法，作為一種替代的零次發想鏈推理方案，通過自適應地區分好提示和壞提示。具體來說，我們首先通過資訊流的視角對 LLM 進行分析，以檢測零次發想鏈推理下的機制，我們發現從問題到提示和從問題到理由的資訊流共同對推理結果影響最大。我們注意到，一個更好的零次發想鏈推理需要提示從問題中獲取語義資訊，然後理由直接從問題中聚合足夠的資訊，並通過提示間接聚合。相反，缺少任何一個都可能導致一個壞的推理。由此，我們進一步提出了一個實例自適應提示策略（IAP），用於零次發想鏈推理。使用 LLaMA-2、LLaMA-3 和 Qwen 在數學、邏輯和常識推理任務（例如 GSM8K、MMLU、因果判斷）上進行的實驗獲得了一致的改進，證明了實例自適應零次發想鏈提示比其他具有某些策展提示或複雜程序的任務級別方法表現得更好，顯示了我們的發現對於零次發想鏈推理機制的意義。

##### **QAEncoder: Towards Aligned Representation Learning in Question Answering System**
2409.20434v1 by Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu Li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang

Modern QA systems entail retrieval-augmented generation (RAG) for accurate
and trustworthy responses. However, the inherent gap between user queries and
relevant documents hinders precise matching. Motivated by our conical
distribution hypothesis, which posits that potential queries and documents form
a cone-like structure in the embedding space, we introduce QAEncoder, a
training-free approach to bridge this gap. Specifically, QAEncoder estimates
the expectation of potential queries in the embedding space as a robust
surrogate for the document embedding, and attaches document fingerprints to
effectively distinguish these embeddings. Extensive experiments on fourteen
embedding models across six languages and eight datasets validate QAEncoder's
alignment capability, which offers a plug-and-play solution that seamlessly
integrates with existing RAG architectures and training-based methods.

摘要：現代 QA 系統需要檢索增強生成 (RAG) 才能提供準確且值得信賴的回應。然而，使用者查詢與相關文件之間的固有差距阻礙了精確的配對。在我們的錐形分佈假設的激勵下，該假設認為潛在查詢和文件在嵌入空間中形成類錐形結構，我們引入了 QAEncoder，一種無需訓練的方法來彌合這一差距。具體來說，QAEncoder 將嵌入空間中潛在查詢的期望值估計為文件嵌入的強健替代，並附加文件指紋以有效區分這些嵌入。在六種語言和八個資料集上的十四個嵌入模型上的廣泛實驗驗證了 QAEncoder 的對齊能力，這提供了一個即插即用的解決方案，可以與現有的 RAG 架構和基於訓練的方法無縫整合。

##### **HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding**
2409.20429v1 by Fan Yuan, Chi Qin, Xiaogang Xu, Piji Li

Large Vision-Language Models (LVLMs) have shown remarkable performance on
many visual-language tasks. However, these models still suffer from multimodal
hallucination, which means the generation of objects or content that violates
the images. Many existing work detects hallucination by directly judging
whether an object exists in an image, overlooking the association between the
object and semantics. To address this issue, we propose Hierarchical Feedback
Learning with Vision-enhanced Penalty Decoding (HELPD). This framework
incorporates hallucination feedback at both object and sentence semantic
levels. Remarkably, even with a marginal degree of training, this approach can
alleviate over 15% of hallucination. Simultaneously, HELPD penalizes the output
logits according to the image attention window to avoid being overly affected
by generated text. HELPD can be seamlessly integrated with any LVLMs. Our
experiments demonstrate that the proposed framework yields favorable results
across multiple hallucination benchmarks. It effectively mitigates
hallucination for different LVLMs and concurrently improves their text
generation quality.

摘要：大型視覺語言模型 (LVLMs) 在許多視覺語言任務中表現出色。然而，這些模型仍然存在多模態幻覺，這表示產生的物件或內容違反了影像。許多現有工作透過直接判斷物件是否存在於影像中來偵測幻覺，忽略了物件與語義之間的關聯。為了解決這個問題，我們提出了具有視覺增強懲罰解碼的階層式回饋學習 (HELPD)。此架構在物件和句子語義層級中都納入了幻覺回饋。值得注意的是，即使訓練程度很低，這種方法也能減輕超過 15% 的幻覺。同時，HELPD 會根據影像注意力視窗懲罰輸出 logit，以避免受到生成文字過度影響。HELPD 可以與任何 LVLMs 無縫整合。我們的實驗證明，所提出的架構在多個幻覺基準中產生了良好的結果。它有效地減輕了不同 LVLMs 的幻覺，並同時提升其文字生成品質。

##### **Sufficient and Necessary Explanations (and What Lies in Between)**
2409.20427v1 by Beepul Bharti, Paul Yi, Jeremias Sulam

As complex machine learning models continue to find applications in
high-stakes decision-making scenarios, it is crucial that we can explain and
understand their predictions. Post-hoc explanation methods provide useful
insights by identifying important features in an input $\mathbf{x}$ with
respect to the model output $f(\mathbf{x})$. In this work, we formalize and
study two precise notions of feature importance for general machine learning
models: sufficiency and necessity. We demonstrate how these two types of
explanations, albeit intuitive and simple, can fall short in providing a
complete picture of which features a model finds important. To this end, we
propose a unified notion of importance that circumvents these limitations by
exploring a continuum along a necessity-sufficiency axis. Our unified notion,
we show, has strong ties to other popular definitions of feature importance,
like those based on conditional independence and game-theoretic quantities like
Shapley values. Crucially, we demonstrate how a unified perspective allows us
to detect important features that could be missed by either of the previous
approaches alone.

摘要：隨著複雜機器學習模型持續在高風險決策情境中找到應用，我們能夠解釋並了解其預測至關重要。事後解釋方法透過辨識輸入 $\mathbf{x}$ 中相對於模型輸出 $f(\mathbf{x})$ 的重要特徵，提供了有用的見解。在這項工作中，我們形式化並研究了兩種精確的機器學習模型特徵重要性概念：充分性和必要性。我們展示了這兩種類型的解釋，儘管直觀且簡單，但在提供模型認為重要的特徵的完整圖像方面可能會有所不足。為此，我們提出了統一的重要性概念，透過探索必要性-充分性軸上的連續統整體來規避這些限制。我們展示了統一概念與其他流行的特徵重要性定義有密切關聯，例如基於條件獨立性和博弈論量（如 Shapley 值）的定義。至關重要的是，我們展示了統一的觀點如何讓我們能夠偵測到以前任何一種方法都可能錯失的重要特徵。

##### **World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering**
2409.20424v1 by Jiacong Wang, Bohong Wu, Haiyong Jiang, Xun Zhou, Xin Xiao, Haoyuan Guo, Jun Xiao

Recent advances in Vision-Language Models (VLMs) and the scarcity of
high-quality multi-modal alignment data have inspired numerous researches on
synthetic VLM data generation. The conventional norm in VLM data construction
uses a mixture of specialists in caption and OCR, or stronger VLM APIs and
expensive human annotation. In this paper, we present World to Code (W2C), a
meticulously curated multi-modal data construction pipeline that organizes the
final generation output into a Python code format. The pipeline leverages the
VLM itself to extract cross-modal information via different prompts and filter
the generated outputs again via a consistency filtering strategy. Experiments
have demonstrated the high quality of W2C by improving various existing visual
question answering and visual grounding benchmarks across different VLMs.
Further analysis also demonstrates that the new code parsing ability of VLMs
presents better cross-modal equivalence than the commonly used detail caption
ability. Our code is available at
https://github.com/foundation-multimodal-models/World2Code.

摘要：近期在視覺語言模型 (VLM) 的進展以及高品質多模態對齊資料的稀缺，激發了許多關於合成 VLM 資料產生的研究。VLM 資料建構中的傳統規範使用標題和 OCR 專家，或更強大的 VLM API 和昂貴的人工標註的混合。在本文中，我們提出世界到程式碼 (W2C)，一個精心策劃的多模態資料建構管道，它將最終產生的輸出組織成 Python 程式碼格式。該管道利用 VLM 本身透過不同的提示來萃取跨模態資訊，並透過一致性過濾策略再次過濾產生的輸出。實驗已透過改善不同 VLM 中的各種現有視覺問答和視覺基礎基準來證明 W2C 的高品質。進一步的分析也證明 VLM 的新程式碼解析能力呈現出比一般使用的詳細標題能力更好的跨模態等價性。我們的程式碼可在 https://github.com/foundation-multimodal-models/World2Code 取得。

##### **Stream-level flow matching from a Bayesian decision theoretic perspective**
2409.20423v1 by Ganchao Wei, Li Ma

Flow matching (FM) is a family of training algorithms for fitting continuous
normalizing flows (CNFs). A standard approach to FM, called conditional flow
matching (CFM), exploits the fact that the marginal vector field of a CNF can
be learned by fitting least-square regression to the so-called conditional
vector field specified given one or both ends of the flow path. We show that
viewing CFM training from a Bayesian decision theoretic perspective on
parameter estimation opens the door to generalizations of CFM algorithms. We
propose one such extension by introducing a CFM algorithm based on defining
conditional probability paths given what we refer to as ``streams'', instances
of latent stochastic paths that connect pairs of noise and observed data.
Further, we advocates the modeling of these latent streams using Gaussian
processes (GPs). The unique distributional properties of GPs, and in particular
the fact that the velocities of a GP is still a GP, allows drawing samples from
the resulting stream-augmented conditional probability path without simulating
the actual streams, and hence the ``simulation-free" nature of CFM training is
preserved. We show that this generalization of the CFM can substantially reduce
the variance in the estimated marginal vector field at a moderate computational
cost, thereby improving the quality of the generated samples under common
metrics. Additionally, we show that adopting the GP on the streams allows for
flexibly linking multiple related training data points (e.g., time series) and
incorporating additional prior information. We empirically validate our claim
through both simulations and applications to two hand-written image datasets.

摘要：流匹配 (FM) 是用於擬合連續正規化流 (CNF) 的一組訓練演算法。一種稱為條件流匹配 (CFM) 的標準 FM 方法利用了 CNF 的邊際向量場可以透過擬合最小平方迴歸來學習，以指定給定流路徑一端或兩端的條件向量場。我們展示了從貝氏決策理論觀點檢視 CFM 訓練，在參數估計上開啟了 CFM 演算法的概括。我們提出一個這樣的延伸，透過引入基於定義條件機率路徑的 CFM 演算法，給定我們稱為「串流」的潛在隨機路徑，連接雜訊和觀察資料對。此外，我們主張使用高斯過程 (GP) 對這些潛在串流進行建模。GP 的獨特分佈特性，特別是 GP 的速度仍為 GP 的事實，允許從串流增強的條件機率路徑中抽取樣本，而無需模擬實際串流，因此 CFM 訓練的「無模擬」性質得以保留。我們展示了 CFM 的這種概括可以在適度的運算成本下大幅減少估計邊際向量場的變異，從而改善常見指標下產生樣本的品質。此外，我們展示了在串流上採用 GP 可以靈活地連結多個相關的訓練資料點（例如時間序列），並納入其他先驗資訊。我們透過模擬和應用於兩個手寫影像資料集，實證驗證了我們的說法。

##### **Conformal Prediction for Dose-Response Models with Continuous Treatments**
2409.20412v1 by Jarne Verhaeghe, Jef Jonkers, Sofie Van Hoecke

Understanding the dose-response relation between a continuous treatment and
the outcome for an individual can greatly drive decision-making, particularly
in areas like personalized drug dosing and personalized healthcare
interventions. Point estimates are often insufficient in these high-risk
environments, highlighting the need for uncertainty quantification to support
informed decisions. Conformal prediction, a distribution-free and
model-agnostic method for uncertainty quantification, has seen limited
application in continuous treatments or dose-response models. To address this
gap, we propose a novel methodology that frames the causal dose-response
problem as a covariate shift, leveraging weighted conformal prediction. By
incorporating propensity estimation, conformal predictive systems, and
likelihood ratios, we present a practical solution for generating prediction
intervals for dose-response models. Additionally, our method approximates local
coverage for every treatment value by applying kernel functions as weights in
weighted conformal prediction. Finally, we use a new synthetic benchmark
dataset to demonstrate the significance of covariate shift assumptions in
achieving robust prediction intervals for dose-response models.

摘要：了解连续治疗与个人结果之间的剂量反应关系可以极大地推动决策制定，尤其是在个性化药物给药和个性化医疗保健干预等领域。在这些高风险环境中，点估计通常是不够的，这突出了对不确定性量化的需求，以支持明智的决策。一致性预测是一种不依赖分布且与模型无关的不确定性量化方法，在连续治疗或剂量反应模型中的应用受到限制。为了解决这一差距，我们提出了一种新方法，将因果剂量反应问题构建为协变量转移，利用加权一致性预测。通过纳入倾向估计、一致性预测系统和似然比，我们提出了一个实用的解决方案，用于生成剂量反应模型的预测区间。此外，我们的方法通过在加权一致性预测中应用核函数作为权重，为每个治疗值近似局部覆盖。最后，我们使用一个新的合成基准数据集来证明协变量转移假设在实现剂量反应模型的稳健预测区间中的重要性。

##### **Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing**
2409.20390v1 by Connor Baumler, Hal Daumé III

AI-based systems such as language models can replicate and amplify social
biases reflected in their training data. Among other questionable behavior,
this can lead to LM-generated text--and text suggestions--that contain
normatively inappropriate stereotypical associations. In this paper, we
consider the question of how "debiasing" a language model impacts stories that
people write using that language model in a predictive text scenario. We find
that (n=414), in certain scenarios, language model suggestions that align with
common social stereotypes are more likely to be accepted by human authors.
Conversely, although anti-stereotypical language model suggestions sometimes
lead to an increased rate of anti-stereotypical stories, this influence is far
from sufficient to lead to "fully debiased" stories.

摘要：基於 AI 的系統，例如語言模型，可以複製和放大訓練資料中反映的社會偏見。在其他可疑行為中，這可能導致 LM 生成的文字和文字建議包含規範上不適當的刻板印象聯想。在本文中，我們考慮了「去偏見」語言模型如何影響人們在預測文字場景中使用該語言模型撰寫的故事的問題。我們發現 (n=414)，在某些情況下，與常見社會刻板印象一致的語言模型建議更有可能被人類作者接受。相反，儘管反刻板印象語言模型建議有時會導致反刻板印象故事的比率增加，但這種影響遠不足以導致「完全去偏見」的故事。

##### **Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation**
2409.20385v1 by Shan Chen, Mingye Gao, Kuleen Sasse, Thomas Hartvigsen, Brian Anthony, Lizhou Fan, Hugo Aerts, Jack Gallifant, Danielle Bitterman

Background: Large language models (LLMs) are trained to follow directions,
but this introduces a vulnerability to blindly comply with user requests even
if they generate wrong information. In medicine, this could accelerate the
generation of misinformation that impacts human well-being.
  Objectives/Methods: We analyzed compliance to requests to generate misleading
content about medications in settings where models know the request is
illogical. We investigated whether in-context directions and instruction-tuning
of LLMs to prioritize logical reasoning over compliance reduced misinformation
risk.
  Results: While all frontier LLMs complied with misinformation requests, both
prompt-based and parameter-based approaches can improve the detection of logic
flaws in requests and prevent the dissemination of medical misinformation.
  Conclusion: Shifting LLMs to prioritize logic over compliance could reduce
risks of exploitation for medical misinformation.

摘要：背景：大型語言模型 (LLM) 接受訓練以遵循指示，但這導致了一個漏洞，即使它們會產生錯誤資訊，也會盲目地遵守使用者的要求。在醫學領域，這可能會加速產生錯誤資訊，進而影響人類的健康。
目標/方法：我們分析了在模型知道請求不合理的情況下，對產生有關藥物的誤導內容請求的遵守情況。我們調查了情境指示和 LLM 的指令調整是否可以優先考慮邏輯推理，高於遵循指示，進而降低錯誤資訊的風險。
結果：雖然所有前沿 LLM 都遵守錯誤資訊請求，但基於提示和基於參數的方法都可以改善對請求中邏輯缺陷的偵測，並防止醫學錯誤資訊的傳播。
結論：將 LLM 轉移到優先考慮邏輯高於遵循指示，可以降低錯誤資訊被用於醫療目的的風險。

##### **Word-wise intonation model for cross-language TTS systems**
2409.20374v1 by Tomilov A. A., Gromova A. Y., Svischev A. N

In this paper we propose a word-wise intonation model for Russian language
and show how it can be generalized for other languages. The proposed model is
suitable for automatic data markup and its extended application to
text-to-speech systems. It can also be implemented for an intonation contour
modeling by using rule-based algorithms or by predicting contours with language
models. The key idea is a partial elimination of the variability connected with
different placements of a stressed syllable in a word. It is achieved with
simultaneous applying of pitch simplification with a dynamic time warping
clustering. The proposed model could be used as a tool for intonation research
or as a backbone for prosody description in text-to-speech systems. As the
advantage of the model, we show its relations with the existing intonation
systems as well as the possibility of using language models for prosody
prediction. Finally, we demonstrate some practical evidence of the system
robustness to parameter variations.

摘要：在本文中，我们提出了俄语单词级的语调模型，并展示了如何将其推广到其他语言。所提出的模型适用于自动数据标记及其在文本到语音系统的扩展应用。它还可以通过使用基于规则的算法或通过使用语言模型预测轮廓来实现语调轮廓建模。关键思想是部分消除与单词中重读音节不同位置相关的可变性。这是通过同时应用音高简化和动态时间扭曲聚类来实现的。所提出的模型可以用作语调研究的工具，或作为文本到语音系统中韵律描述的骨干。作为该模型的优点，我们展示了它与现有语调系统的关系，以及使用语言模型进行韵律预测的可能性。最后，我们展示了系统对参数变化的鲁棒性的实际证据。

##### **Frequency Adaptive Normalization For Non-stationary Time Series Forecasting**
2409.20371v1 by Weiwei Ye, Songgaojun Deng, Qiaosha Zou, Ning Gui

Time series forecasting typically needs to address non-stationary data with
evolving trend and seasonal patterns. To address the non-stationarity,
reversible instance normalization has been recently proposed to alleviate
impacts from the trend with certain statistical measures, e.g., mean and
variance. Although they demonstrate improved predictive accuracy, they are
limited to expressing basic trends and are incapable of handling seasonal
patterns. To address this limitation, this paper proposes a new instance
normalization solution, called frequency adaptive normalization (FAN), which
extends instance normalization in handling both dynamic trend and seasonal
patterns. Specifically, we employ the Fourier transform to identify
instance-wise predominant frequent components that cover most non-stationary
factors. Furthermore, the discrepancy of those frequency components between
inputs and outputs is explicitly modeled as a prediction task with a simple MLP
model. FAN is a model-agnostic method that can be applied to arbitrary
predictive backbones. We instantiate FAN on four widely used forecasting models
as the backbone and evaluate their prediction performance improvements on eight
benchmark datasets. FAN demonstrates significant performance advancement,
achieving 7.76% ~ 37.90% average improvements in MSE.

摘要：時間序列預測通常需要處理具有演化趨勢和季節性模式的非平穩數據。為了解決非平穩性，最近提出了可逆實例正規化，以使用某些統計量（例如平均值和變異數）減輕趨勢的影響。儘管它們展示了改進的預測準確性，但它們僅限於表達基本趨勢，並且無法處理季節性模式。為了解決這個限制，本文提出了一個新的實例正規化解決方案，稱為頻率自適應正規化 (FAN)，它擴展了實例正規化，以處理動態趨勢和季節性模式。具體來說，我們使用傅立葉轉換來識別覆蓋大多數非平穩因素的實例級主要頻率分量。此外，輸入和輸出之間這些頻率分量的差異被明確建模為具有簡單 MLP 模型的預測任務。FAN 是一個與模型無關的方法，可以應用於任意預測主幹。我們在四個廣泛使用的預測模型上實例化 FAN 作為主幹，並在八個基準數據集上評估它們的預測性能改進。FAN 展示了顯著的性能提升，在 MSE 中實現了 7.76% ~ 37.90% 的平均改進。

##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

摘要：人類回饋強化學習 (RLHF) 已成為微調大型語言模型 (LLM) 的領先方法。然而，RLHF 在多任務學習 (MTL) 中受到獎勵破解和極端多目標最佳化（例如，多重和/或有時相互衝突的目標之間的取捨）的挑戰而有所限制。目前，將 RLHF 應用於 MTL 需要仔細調整獎勵模型和資料組合的權重。這通常是透過人類直覺來完成，而且無法概括。在這項工作中，我們引入了一種新穎的訓練後範例，我們稱之為受約束生成策略最佳化 (CGPO)。CGPO 的核心是法官混合 (MoJ)，透過分層進行具有成本效益的受約束策略最佳化，它可以以原則性的方式找出 RLHF 中的完美融合。它在理論保證下展現強大的實證結果，不需要廣泛的超參數調整，並且可以即插即用於常見的訓練後管道。總之，它可以在極大量的目標中偵測和減輕獎勵破解行為，同時達到帕雷托最優點。我們的實證評估證明，CGPO 在各種任務中顯著優於標準 RLHF 演算法，例如一般聊天、STEM 問題、指令遵循和編碼。具體來說，CGPO 在 AlpacaEval-2（一般聊天）中提升了 7.4%，在 Arena-Hard（STEM 和推理）中提升了 12.5%，並且在數學和編碼等其他領域中持續獲得收益。值得注意的是，PPO 雖然普遍使用，但在流行的編碼基準中容易受到嚴重的獎勵破解，而 CGPO 成功地解決了這個問題。RLHF 的這項突破不僅解決了獎勵破解和極端多目標最佳化的挑戰，而且還推動了將通用 LLM 與各種應用程式相結合的最新技術。

##### **Disentangling Singlish Discourse Particles with Task-Driven Representation**
2409.20366v1 by Linus Tze En Foo, Lynnette Hui Xian Ng

Singlish, or formally Colloquial Singapore English, is an English-based
creole language originating from the SouthEast Asian country Singapore. The
language contains influences from Sinitic languages such as Chinese dialects,
Malay, Tamil and so forth. A fundamental task to understanding Singlish is to
first understand the pragmatic functions of its discourse particles, upon which
Singlish relies heavily to convey meaning. This work offers a preliminary
effort to disentangle the Singlish discourse particles (lah, meh and hor) with
task-driven representation learning. After disentanglement, we cluster these
discourse particles to differentiate their pragmatic functions, and perform
Singlish-to-English machine translation. Our work provides a computational
method to understanding Singlish discourse particles, and opens avenues towards
a deeper comprehension of the language and its usage.

摘要：星式英语，或正式名称为新加坡口语英语，是一种以英语为基础的克里奥尔语，起源于东南亚国家新加坡。该语言包含汉语方言、马来语、泰米尔语等汉语语言的影响。理解星式英语的一项基本任务是首先理解其话语粒子的语用功能，星式英语在很大程度上依赖于此来传达意义。这项工作提供了一项初步尝试，即利用任务驱动的表征学习来解开星式英语话语粒子（lah、meh 和 hor）。在解开纠缠后，我们将这些话语粒子进行聚类以区分它们的语用功能，并执行星式英语到英语的机器翻译。我们的工作提供了一种计算方法来理解星式英语话语粒子，并为更深入地理解该语言及其用法开辟了途径。

##### **Efficient Driving Behavior Narration and Reasoning on Edge Device Using Large Language Models**
2409.20364v1 by Yizhou Huang, Yihua Cheng, Kezhi Wang

Deep learning architectures with powerful reasoning capabilities have driven
significant advancements in autonomous driving technology. Large language
models (LLMs) applied in this field can describe driving scenes and behaviors
with a level of accuracy similar to human perception, particularly in visual
tasks. Meanwhile, the rapid development of edge computing, with its advantage
of proximity to data sources, has made edge devices increasingly important in
autonomous driving. Edge devices process data locally, reducing transmission
delays and bandwidth usage, and achieving faster response times. In this work,
we propose a driving behavior narration and reasoning framework that applies
LLMs to edge devices. The framework consists of multiple roadside units, with
LLMs deployed on each unit. These roadside units collect road data and
communicate via 5G NSR/NR networks. Our experiments show that LLMs deployed on
edge devices can achieve satisfactory response speeds. Additionally, we propose
a prompt strategy to enhance the narration and reasoning performance of the
system. This strategy integrates multi-modal information, including
environmental, agent, and motion data. Experiments conducted on the
OpenDV-Youtube dataset demonstrate that our approach significantly improves
performance across both tasks.

摘要：深度學習架構具備強大的推理能力，推動了自動駕駛技術的重大進展。應用於此領域的大型語言模型 (LLM) 可以描述駕駛場景和行為，其準確度與人類感知類似，特別是在視覺任務中。同時，邊緣運算的快速發展，因其靠近數據源的優勢，使得邊緣設備在自動駕駛中變得越來越重要。邊緣設備在本地處理數據，減少傳輸延遲和頻寬使用，並實現更快的響應時間。在這項工作中，我們提出了一個駕駛行為敘述和推理框架，將 LLM 應用於邊緣設備。該框架由多個路邊單元組成，每個單元上都部署了 LLM。這些路邊單元收集道路數據並通過 5G NSR/NR 網路進行通信。我們的實驗表明，部署在邊緣設備上的 LLM 可以實現令人滿意的響應速度。此外，我們提出了一種提示策略來增強系統的敘述和推理性能。此策略整合了多模態信息，包括環境、代理和運動數據。在 OpenDV-Youtube 數據集上進行的實驗表明，我們的方案顯著提高了這兩項任務的性能。

##### **Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference**
2409.20361v1 by Ke Yi, Zengke Liu, Jianwei Zhang, Chengyuan Li, Tong Zhang, Junyang Lin, Jingren Zhou

Large language models have demonstrated promising capabilities upon scaling
up parameters. However, serving large language models incurs substantial
computation and memory movement costs due to their large scale. Quantization
methods have been employed to reduce service costs and latency. Nevertheless,
outliers in activations hinder the development of INT4 weight-activation
quantization. Existing approaches separate outliers and normal values into two
matrices or migrate outliers from activations to weights, suffering from high
latency or accuracy degradation. Based on observing activations from large
language models, outliers can be classified into channel-wise and spike
outliers. In this work, we propose Rotated Runtime Smooth (RRS), a
plug-and-play activation smoother for quantization, consisting of Runtime
Smooth and the Rotation operation. Runtime Smooth (RS) is introduced to
eliminate channel-wise outliers by smoothing activations with channel-wise
maximums during runtime. The rotation operation can narrow the gap between
spike outliers and normal values, alleviating the effect of victims caused by
channel-wise smoothing. The proposed method outperforms the state-of-the-art
method in the LLaMA and Qwen families and improves WikiText-2 perplexity from
57.33 to 6.66 for INT4 inference.

摘要：大型语言模型在扩大参数时已展示出有希望的能力。然而，由于大规模，提供大型语言模型会产生大量的计算和内存移动成本。量化方法已被用来降低服务成本和延迟。尽管如此，激活中的异常值阻碍了 INT4 权重激活量化的发展。现有的方法将异常值和正常值分成两个矩阵，或将异常值从激活迁移到权重，从而导致高延迟或精度下降。基于对大型语言模型的激活观察，异常值可以分类为通道内异常值和尖峰异常值。在这项工作中，我们提出了旋转运行时平滑 (RRS)，这是一种即插即用的激活平滑器，用于量化，由运行时平滑和旋转操作组成。引入运行时平滑 (RS) 以通过在运行时使用通道内最大值平滑激活来消除通道内异常值。旋转操作可以缩小尖峰异常值和正常值之间的差距，减轻通道内平滑造成的受害影响。所提出的方法优于 LLaMA 和 Qwen 系列中的最先进方法，并将 WikiText-2 的困惑度从 57.33 提高到 6.66，用于 INT4 推断。

##### **Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization**
2409.20340v2 by Osama Mustafa

The application of deep learning in cancer research, particularly in early
diagnosis, case understanding, and treatment strategy design, emphasizes the
need for high-quality data. Generative AI, especially Generative Adversarial
Networks (GANs), has emerged as a leading solution to challenges like class
imbalance, robust learning, and model training, while addressing issues
stemming from patient privacy and the scarcity of real data. Despite their
promise, GANs face several challenges, both inherent and specific to
histopathology data. Inherent issues include training imbalance, mode collapse,
linear learning from insufficient discriminator feedback, and hard boundary
convergence due to stringent feedback. Histopathology data presents a unique
challenge with its complex representation, high spatial resolution, and
multiscale features. To address these challenges, we propose a framework
consisting of two components. First, we introduce a contrastive learning-based
Multistage Progressive Finetuning Siamese Neural Network (MFT-SNN) for
assessing the similarity between histopathology patches. Second, we implement a
Reinforcement Learning-based External Optimizer (RL-EO) within the GAN training
loop, serving as a reward signal generator. The modified discriminator loss
function incorporates a weighted reward, guiding the GAN to maximize this
reward while minimizing loss. This approach offers an external optimization
guide to the discriminator, preventing generator overfitting and ensuring
smooth convergence. Our proposed solution has been benchmarked against
state-of-the-art (SOTA) GANs and a Denoising Diffusion Probabilistic model,
outperforming previous SOTA across various metrics, including FID score, KID
score, Perceptual Path Length, and downstream classification tasks.

摘要：深度學習在癌症研究中的應用，特別是在早期診斷、案例理解和治療策略設計中，強調了對高品質數據的需求。生成式 AI，特別是生成式對抗網路 (GAN)，已成為解決類別不平衡、穩健學習和模型訓練等挑戰的領先解決方案，同時解決了患者隱私和真實數據稀缺的問題。儘管有其優點，但 GAN 面臨著多項挑戰，既有固有的，也有特定於組織病理學數據的。固有問題包括訓練不平衡、模式崩潰、判別器回饋不足導致的線性學習，以及由於嚴格回饋導致的硬邊界收斂。組織病理學數據以其複雜的表示、高空間解析度和多尺度特徵呈現出獨特的挑戰。為了應對這些挑戰，我們提出了一個由兩個組成部分組成的框架。首先，我們引入了一個基於對比學習的多階段漸進微調連體神經網路 (MFT-SNN)，用於評估組織病理學貼片之間的相似性。其次，我們在 GAN 訓練迴圈中實作了一個基於強化學習的外部優化器 (RL-EO)，作為獎勵訊號產生器。修改後的判別器損失函數包含一個加權獎勵，指導 GAN 在最小化損失的同時最大化這個獎勵。這種方法為判別器提供了外部優化指南，防止生成器過度擬合並確保平穩收斂。我們提出的解決方案已針對最先進 (SOTA) GAN 和去噪擴散概率模型進行了基準測試，在 FID 分數、KID 分數、感知路徑長度和下游分類任務等各種指標上優於先前的 SOTA。

##### **Boosting Hybrid Autoregressive Transducer-based ASR with Internal Acoustic Model Training and Dual Blank Thresholding**
2409.20313v1 by Takafumi Moriya, Takanori Ashihara, Masato Mimura, Hiroshi Sato, Kohei Matsuura, Ryo Masumura, Taichi Asami

A hybrid autoregressive transducer (HAT) is a variant of neural transducer
that models blank and non-blank posterior distributions separately. In this
paper, we propose a novel internal acoustic model (IAM) training strategy to
enhance HAT-based speech recognition. IAM consists of encoder and joint
networks, which are fully shared and jointly trained with HAT. This joint
training not only enhances the HAT training efficiency but also encourages IAM
and HAT to emit blanks synchronously which skips the more expensive non-blank
computation, resulting in more effective blank thresholding for faster
decoding. Experiments demonstrate that the relative error reductions of the HAT
with IAM compared to the vanilla HAT are statistically significant. Moreover,
we introduce dual blank thresholding, which combines both HAT- and IAM-blank
thresholding and a compatible decoding algorithm. This results in a 42-75%
decoding speed-up with no major performance degradation.

摘要：混合自迴歸轉換器 (HAT) 是神經轉換器的一種變體，它分別對空白和非空白後驗分佈進行建模。在本文中，我們提出了一種新穎的內部聲學模型 (IAM) 訓練策略，以增強基於 HAT 的語音識別。IAM 由編碼器和聯合網路組成，它們完全共享並與 HAT 聯合訓練。這種聯合訓練不僅提高了 HAT 訓練效率，還鼓勵 IAM 和 HAT 同步發出空白，從而跳過更昂貴的非空白計算，從而對更有效的空白閾值進行更快解碼。實驗表明，與香草 HAT 相比，帶有 IAM 的 HAT 的相對誤差減少具有統計學意義。此外，我們引入了雙空白閾值，它結合了 HAT 和 IAM 空白閾值和一個相容的解碼演算法。這導致解碼速度提高了 42-75%，而效能沒有明顯下降。

##### **A Looming Replication Crisis in Evaluating Behavior in Language Models? Evidence and Solutions**
2409.20303v1 by Laurène Vaugrante, Mathias Niepert, Thilo Hagendorff

In an era where large language models (LLMs) are increasingly integrated into
a wide range of everyday applications, research into these models' behavior has
surged. However, due to the novelty of the field, clear methodological
guidelines are lacking. This raises concerns about the replicability and
generalizability of insights gained from research on LLM behavior. In this
study, we discuss the potential risk of a replication crisis and support our
concerns with a series of replication experiments focused on prompt engineering
techniques purported to influence reasoning abilities in LLMs. We tested
GPT-3.5, GPT-4o, Gemini 1.5 Pro, Claude 3 Opus, Llama 3-8B, and Llama 3-70B, on
the chain-of-thought, EmotionPrompting, ExpertPrompting, Sandbagging, as well
as Re-Reading prompt engineering techniques, using manually double-checked
subsets of reasoning benchmarks including CommonsenseQA, CRT, NumGLUE,
ScienceQA, and StrategyQA. Our findings reveal a general lack of statistically
significant differences across nearly all techniques tested, highlighting,
among others, several methodological weaknesses in previous research. We
propose a forward-looking approach that includes developing robust
methodologies for evaluating LLMs, establishing sound benchmarks, and designing
rigorous experimental frameworks to ensure accurate and reliable assessments of
model outputs.

摘要：在大型語言模型（LLM）日益整合到各種日常應用程式的時代，對這些模型行為的研究激增。然而，由於該領域的新穎性，缺乏明確的方法論指南。這引起了對從 LLM 行為研究中獲得的見解的可複製性和概括性的擔憂。在本研究中，我們討論了複製危機的潛在風險，並通過一系列複製實驗支持我們的擔憂，這些實驗專注於據稱影響 LLM 推理能力的提示工程技術。我們在思想鏈、EmotionPrompting、ExpertPrompting、Sandbagging 以及 Re-Reading 提示工程技術上測試了 GPT-3.5、GPT-4o、Gemini 1.5 Pro、Claude 3 Opus、Llama 3-8B 和 Llama 3-70B，使用手動雙重檢查的推理基準子集，包括 CommonsenseQA、CRT、NumGLUE、ScienceQA 和 StrategyQA。我們的研究結果揭示了在幾乎所有測試技術中普遍缺乏統計學上的顯著差異，其中包括強調以前研究中存在的若干方法論弱點。我們提出了一種前瞻性的方法，包括開發用於評估 LLM 的健壯方法論、建立健全的基準以及設計嚴謹的實驗框架，以確保對模型輸出的準確且可靠的評估。

##### **PersonalLLM: Tailoring LLMs to Individual Preferences**
2409.20296v1 by Thomas P. Zollo, Andrew Wei Tung Siah, Naimeng Ye, Ang Li, Hongseok Namkoong

As LLMs become capable of complex tasks, there is growing potential for
personalized interactions tailored to the subtle and idiosyncratic preferences
of the user. We present a public benchmark, PersonalLLM, focusing on adapting
LLMs to provide maximal benefits for a particular user. Departing from existing
alignment benchmarks that implicitly assume uniform preferences, we curate
open-ended prompts paired with many high-quality answers over which users would
be expected to display heterogeneous latent preferences. Instead of
persona-prompting LLMs based on high-level attributes (e.g., user's race or
response length), which yields homogeneous preferences relative to humans, we
develop a method that can simulate a large user base with diverse preferences
from a set of pre-trained reward models. Our dataset and generated
personalities offer an innovative testbed for developing personalization
algorithms that grapple with continual data sparsity--few relevant feedback
from the particular user--by leveraging historical data from other (similar)
users. We explore basic in-context learning and meta-learning baselines to
illustrate the utility of PersonalLLM and highlight the need for future
methodological development. Our dataset is available at
https://huggingface.co/datasets/namkoong-lab/PersonalLLM

摘要：随着 LLM 能够执行复杂的任务，针对用户的微妙且独特的偏好量身定制个性化互动具有越来越大的潜力。我们提出了一个公共基准 PersonalLLM，重点是调整 LLM 以为特定用户提供最大的好处。与隐式假设统一偏好的现有对齐基准不同，我们策划了开放式提示，并配有许多高质量的答案，用户可能会对这些答案表现出异质的潜在偏好。我们没有根据高级属性（例如，用户的种族或响应长度）对 LLM 进行角色提示，这会产生相对于人类的同质偏好，而是开发了一种方法，该方法可以使用一组预先训练的奖励模型来模拟具有不同偏好的大量用户群。我们的数据集和生成的人格为开发个性化算法提供了一个创新的测试平台，该算法通过利用其他（相似）用户的历史数据来解决持续的数据稀疏性问题——来自特定用户的相关反馈很少。我们探索了基本的上下文学习和元学习基线，以说明 PersonalLLM 的效用，并强调未来方法论发展的必要性。我们的数据集可在 https://huggingface.co/datasets/namkoong-lab/PersonalLLM 获得

##### **LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models**
2409.20288v1 by Haitao Li, You Chen, Qingyao Ai, Yueyue Wu, Ruizhe Zhang, Yiqun Liu

Large language models (LLMs) have made significant progress in natural
language processing tasks and demonstrate considerable potential in the legal
domain. However, legal applications demand high standards of accuracy,
reliability, and fairness. Applying existing LLMs to legal systems without
careful evaluation of their potential and limitations could pose significant
risks in legal practice. To this end, we introduce a standardized comprehensive
Chinese legal benchmark LexEval. This benchmark is notable in the following
three aspects: (1) Ability Modeling: We propose a new taxonomy of legal
cognitive abilities to organize different tasks. (2) Scale: To our knowledge,
LexEval is currently the largest Chinese legal evaluation dataset, comprising
23 tasks and 14,150 questions. (3) Data: we utilize formatted existing
datasets, exam datasets and newly annotated datasets by legal experts to
comprehensively evaluate the various capabilities of LLMs. LexEval not only
focuses on the ability of LLMs to apply fundamental legal knowledge but also
dedicates efforts to examining the ethical issues involved in their
application. We evaluated 38 open-source and commercial LLMs and obtained some
interesting findings. The experiments and findings offer valuable insights into
the challenges and potential solutions for developing Chinese legal systems and
LLM evaluation pipelines. The LexEval dataset and leaderboard are publicly
available at \url{https://github.com/CSHaitao/LexEval} and will be continuously
updated.

摘要：大型語言模型 (LLM) 在自然語言處理任務方面取得了重大進展，並在法律領域展現了巨大的潛力。然而，法律應用要求極高的準確性、可靠性和公平性。在未仔細評估其潛力和限制的情況下將現有的 LLM 應用於法律系統，可能會在法律實務中造成重大風險。為此，我們引入了標準化的綜合中文法律基準 LexEval。此基準在以下三個方面值得注意：(1) 能力建模：我們提出了一種新的法律認知能力分類法，以組織不同的任務。(2) 規模：據我們所知，LexEval 目前是最大的中文法律評估資料集，包含 23 項任務和 14,150 個問題。(3) 資料：我們利用法律專家格式化的現有資料集、考試資料集和新註解資料集，以全面評估 LLM 的各種能力。LexEval 不僅專注於 LLM 應用基本法律知識的能力，還致力於審查其應用中涉及的倫理問題。我們評估了 38 個開源和商業 LLM，並獲得了一些有趣的發現。這些實驗和發現為開發中文法律系統和 LLM 評估管道提供了寶貴的見解。LexEval 資料集和排行榜公開於 \url{https://github.com/CSHaitao/LexEval}，並將持續更新。

##### **Computer-mediated therapies for stroke rehabilitation: a systematic review and meta-Analysis**
2409.20260v1 by Stanley Mugisha. Mirko Job. Matteo Zoppi, Marco Testa, Rezia Molfino

OBJECTIVE: To evaluate the efficacy of different forms of virtual reality
(VR) treatments as either immersive virtual reality (IVR) or non-immersive
virtual reality (NIVR) in comparison to conventional therapy (CT) in improving
physical and psychological status among stroke patients. METHODS: The
literature search was conducted on seven databases. ACM Digital Library,
Medline (via PubMed), Cochrane, IEEE Xplore, Web of Science, and Scopus. The
effect sizes of the main outcomes were calculated using Cohen's d. Pooled
results were used to present an overall estimate of the treatment effect using
a random-effects model. RESULTS: A total of 22 randomized controlled trials
were evaluated. 3 trials demonstrated that immersive virtual reality improved
upper limb activity, function and activity of daily life in a way comparable to
CT. 18 trials showed that NIVR had similar benefits to CT for upper limb
activity and function, balance and mobility, activities of daily living and
participation. A comparison between the different forms of VR showed that IVR
may be more beneficial than NIVR for upper limb training and activities of
daily life. CONCLUSIONS: This study found out that IVR therapies may be more
effective than NIVR but not CT to improve upper limb activity, function, and
daily life activities. However, there is no evidence of the durability of IVR
treatment. More research involving studies with larger samples is needed to
assess the long-term effects and promising benefits of immersive virtual
reality technology.

摘要：目標：評估不同形式的虛擬實境 (VR) 治療，例如沉浸式虛擬實境 (IVR) 或非沉浸式虛擬實境 (NIVR)，與傳統療法 (CT) 相比，在改善中風患者的身體和心理狀態方面的功效。方法：在七個資料庫中進行文獻搜尋。ACM 數位圖書館、Medline（透過 PubMed）、Cochrane、IEEE Xplore、Web of Science 和 Scopus。使用 Cohen's d 計算主要結果的效應值。匯總結果用於使用隨機效應模型呈現治療效果的整體估計。結果：總共評估了 22 項隨機對照試驗。3 項試驗表明，沉浸式虛擬實境改善了上肢活動、功能和日常生活活動，與 CT 相當。18 項試驗表明，NIVR 對上肢活動和功能、平衡和活動能力、日常生活活動和參與度具有與 CT 相似的益處。不同形式的 VR 之間的比較表明，IVR 可能比 NIVR 對上肢訓練和日常生活活動更有益。結論：本研究發現 IVR 治療可能比 NIVR 更有效，但不如 CT 能改善上肢活動、功能和日常生活活動。然而，沒有證據表明 IVR 治療的持久性。需要更多涉及更大樣本的研究來評估沉浸式虛擬實境技術的長期效果和有希望的益處。

##### **What is the Role of Large Language Models in the Evolution of Astronomy Research?**
2409.20252v1 by Morgan Fouesneau, Ivelina G. Momcheva, Urmila Chadayammuri, Mariia Demianenko, Antoine Dumont, Raphael E. Hviding, K. Angelique Kahle, Nadiia Pulatova, Bhavesh Rajpoot, Marten B. Scheuck, Rhys Seeburger, Dmitry Semenov, Jaime I. Villaseñor

ChatGPT and other state-of-the-art large language models (LLMs) are rapidly
transforming multiple fields, offering powerful tools for a wide range of
applications. These models, commonly trained on vast datasets, exhibit
human-like text generation capabilities, making them useful for research tasks
such as ideation, literature review, coding, drafting, and outreach. We
conducted a study involving 13 astronomers at different career stages and
research fields to explore LLM applications across diverse tasks over several
months and to evaluate their performance in research-related activities. This
work was accompanied by an anonymous survey assessing participants' experiences
and attitudes towards LLMs. We provide a detailed analysis of the tasks
attempted and the survey answers, along with specific output examples. Our
findings highlight both the potential and limitations of LLMs in supporting
research while also addressing general and research-specific ethical
considerations. We conclude with a series of recommendations, emphasizing the
need for researchers to complement LLMs with critical thinking and domain
expertise, ensuring these tools serve as aids rather than substitutes for
rigorous scientific inquiry.

摘要：ChatGPT 和其他最先進的大語言模型 (LLM) 正快速轉變多重領域，為廣泛的應用程式提供強大的工具。這些模型通常在龐大的資料集上訓練，展現出類似人類的文字生成能力，讓它們可用於研究任務，例如構思、文獻回顧、編碼、起草和外展。我們進行了一項研究，讓 13 位不同事業階段和研究領域的天文學家參與，在幾個月內探索 LLM 在不同任務中的應用，並評估它們在研究相關活動中的表現。這項工作附有一份匿名調查，評估參與者對 LLM 的經驗和態度。我們提供任務嘗試和調查答案的詳細分析，以及具體的輸出範例。我們的發現強調了 LLM 在支持研究方面的潛力和限制，同時也處理了一般性和研究特定的倫理考量。我們最後提出了一系列建議，強調研究人員需要以批判性思考和領域專業知識來補充 LLM，確保這些工具作為輔助工具，而不是嚴謹科學探究的替代品。

##### **Resource Allocation for Stable LLM Training in Mobile Edge Computing**
2409.20247v1 by Chang Liu, Jun Zhao

As mobile devices increasingly become focal points for advanced applications,
edge computing presents a viable solution to their inherent computational
limitations, particularly in deploying large language models (LLMs). However,
despite the advancements in edge computing, significant challenges remain in
efficient training and deploying LLMs due to the computational demands and data
privacy concerns associated with these models. This paper explores a
collaborative training framework that integrates mobile users with edge servers
to optimize resource allocation, thereby enhancing both performance and
efficiency. Our approach leverages parameter-efficient fine-tuning (PEFT)
methods, allowing mobile users to adjust the initial layers of the LLM while
edge servers handle the more demanding latter layers. Specifically, we
formulate a multi-objective optimization problem to minimize the total energy
consumption and delay during training. We also address the common issue of
instability in model performance by incorporating stability enhancements into
our objective function. Through novel fractional programming technique, we
achieve a stationary point for the formulated problem. Simulations demonstrate
that our method reduces the energy consumption as well as the latency, and
increases the reliability of LLMs across various mobile settings.

摘要：隨著行動裝置日益成為進階應用程式的重點，
邊緣運算為其固有的運算限制提供了可行的解決方案，特別是在部署大型語言模型 (LLM) 時。然而，儘管邊緣運算有進展，由於這些模型相關的運算需求和資料隱私問題，在訓練和部署 LLM 時仍有重大的挑戰。本文探討了一個協作訓練架構，將行動裝置使用者與邊緣伺服器整合，以最佳化資源配置，進而提升效能和效率。我們的做法利用了參數有效微調 (PEFT) 方法，讓行動裝置使用者調整 LLM 的初始層，而邊緣伺服器則處理要求較高的後續層。具體來說，我們制定了一個多目標最佳化問題，以最小化訓練期間的總能耗和延遲。我們也透過將穩定性強化納入我們的目標函數，來解決模型效能不穩定的常見問題。透過創新的分數規劃技術，我們為制定的問題達到了平穩點。模擬結果顯示，我們的做法減少了能耗和延遲，並提高了 LLM 在各種行動裝置設定中的可靠性。

##### **Analysing Zero-Shot Readability-Controlled Sentence Simplification**
2409.20246v1 by Abdullah Barayan, Jose Camacho-Collados, Fernando Alva-Manchego

Readability-controlled text simplification (RCTS) rewrites texts to lower
readability levels while preserving their meaning. RCTS models often depend on
parallel corpora with readability annotations on both source and target sides.
Such datasets are scarce and difficult to curate, especially at the sentence
level. To reduce reliance on parallel data, we explore using instruction-tuned
large language models for zero-shot RCTS. Through automatic and manual
evaluations, we examine: (1) how different types of contextual information
affect a model's ability to generate sentences with the desired readability,
and (2) the trade-off between achieving target readability and preserving
meaning. Results show that all tested models struggle to simplify sentences
(especially to the lowest levels) due to models' limitations and
characteristics of the source sentences that impede adequate rewriting. Our
experiments also highlight the need for better automatic evaluation metrics
tailored to RCTS, as standard ones often misinterpret common simplification
operations, and inaccurately assess readability and meaning preservation.

摘要：可讀性控制文本簡化 (RCTS) 會改寫文字，降低可讀性等級，同時保留其意義。RCTS 模型通常依賴於來源和目標兩側都有可讀性註解的平行語料庫。此類資料集稀少且難以整理，特別是在句子層級。為了減少對平行資料的依賴，我們探索使用指令調整的大型語言模型進行零次學習 RCTS。透過自動和手動評估，我們探討：(1) 不同類型的上下文資訊如何影響模型產生具有所需可讀性句子的能力，以及 (2) 達到目標可讀性與保留意義之間的取捨。結果顯示，所有測試模型都難以簡化句子（特別是到最低等級），原因在於模型的限制和阻礙充分改寫的來源句子特性。我們的實驗也強調需要針對 RCTS 量身打造更好的自動評估指標，因為標準指標通常會誤解常見的簡化操作，並錯誤評估可讀性和意義保留。

##### **PsyGUARD: An Automated System for Suicide Detection and Risk Assessment in Psychological Counseling**
2409.20243v1 by Huachuan Qiu, Lizhi Ma, Zhenzhong Lan

As awareness of mental health issues grows, online counseling support
services are becoming increasingly prevalent worldwide. Detecting whether users
express suicidal ideation in text-based counseling services is crucial for
identifying and prioritizing at-risk individuals. However, the lack of
domain-specific systems to facilitate fine-grained suicide detection and
corresponding risk assessment in online counseling poses a significant
challenge for automated crisis intervention aimed at suicide prevention. In
this paper, we propose PsyGUARD, an automated system for detecting suicide
ideation and assessing risk in psychological counseling. To achieve this, we
first develop a detailed taxonomy for detecting suicide ideation based on
foundational theories. We then curate a large-scale, high-quality dataset
called PsySUICIDE for suicide detection. To evaluate the capabilities of
automated systems in fine-grained suicide detection, we establish a range of
baselines. Subsequently, to assist automated services in providing safe,
helpful, and tailored responses for further assessment, we propose to build a
suite of risk assessment frameworks. Our study not only provides an insightful
analysis of the effectiveness of automated risk assessment systems based on
fine-grained suicide detection but also highlights their potential to improve
mental health services on online counseling platforms. Code, data, and models
are available at https://github.com/qiuhuachuan/PsyGUARD.

摘要：隨著心理健康問題意識的提升，線上諮詢服務正於全球各地日益普及。在基於文字的諮詢服務中，偵測使用者是否表達出自殺意念對於辨識並優先處理有風險的個人至關重要。然而，缺乏特定領域的系統來促進精細化的自殺偵測與相應的風險評估，對旨在預防自殺的自動化危機介入構成了重大的挑戰。在本文中，我們提出 PsyGUARD，一個用於偵測自殺意念與評估心理諮詢風險的自動化系統。為達成此目標，我們首先根據基礎理論，開發出一套詳細的自殺意念偵測分類法。接著，我們策劃了一個名為 PsySUICIDE 的大規模、高品質自殺偵測資料集。為了評估自動化系統在精細化自殺偵測中的能力，我們建立了一系列的基準。隨後，為了協助自動化服務提供安全、有幫助且客製化的回應以進行進一步的評估，我們提議建構一套風險評估架構。我們的研究不僅提供了基於精細化自殺偵測的自動化風險評估系統的有效性分析，也強調了它們改善線上諮詢平台的心理健康服務的潛力。程式碼、資料和模型可於 https://github.com/qiuhuachuan/PsyGUARD 取得。

##### **Beyond Prompts: Dynamic Conversational Benchmarking of Large Language Models**
2409.20222v1 by David Castillo-Bolado, Joseph Davidson, Finlay Gray, Marek Rosa

We introduce a dynamic benchmarking system for conversational agents that
evaluates their performance through a single, simulated, and lengthy
user$\leftrightarrow$agent interaction. The interaction is a conversation
between the user and agent, where multiple tasks are introduced and then
undertaken concurrently. We context switch regularly to interleave the tasks,
which constructs a realistic testing scenario in which we assess the Long-Term
Memory, Continual Learning, and Information Integration capabilities of the
agents. Results from both proprietary and open-source Large-Language Models
show that LLMs in general perform well on single-task interactions, but they
struggle on the same tasks when they are interleaved. Notably, short-context
LLMs supplemented with an LTM system perform as well as or better than those
with larger contexts. Our benchmark suggests that there are other challenges
for LLMs responding to more natural interactions that contemporary benchmarks
have heretofore not been able to capture.

摘要：我們引進了一套動態基準系統，用於對話代理，透過單一、模擬且冗長的使用者$\leftrightarrow$代理互動，評估其效能。互動是使用者與代理之間的對話，其中會導入多項任務，然後同時進行。我們會定期切換內容，以交錯任務，建構一個實際的測試情境，在其中評估代理的長期記憶、持續學習和資訊整合能力。來自專有和開放原始碼大型語言模型的結果顯示，LLM 在單一任務互動中通常表現良好，但當任務交錯時，它們在相同任務上會遇到困難。值得注意的是，補充 LTM 系統的短內容 LLM 的表現與較大內容的 LLM 一樣好，甚至更好。我們的基準表明，LLM 在回應更自然的互動時還有其他挑戰，而當代基準迄今無法掌握這些挑戰。

##### **Divided by discipline? A systematic literature review on the quantification of online sexism and misogyny using a semi-automated approach**
2409.20204v1 by Aditi Dutta, Susan Banducci, Chico Q. Camargo

In recent years, several computational tools have been developed to detect
and identify sexism, misogyny, and gender-based hate speech, especially on
online platforms. Though these tools intend to draw on knowledge from both
social science and computer science, little is known about the current state of
research in quantifying online sexism or misogyny. Given the growing concern
over the discrimination of women in online spaces and the rise in
interdisciplinary research on capturing the online manifestation of sexism and
misogyny, a systematic literature review on the research practices and their
measures is the need of the hour. We make three main contributions: (i) we
present a semi-automated way to narrow down the search results in the different
phases of selection stage in the PRISMA flowchart; (ii) we perform a systematic
literature review of research papers that focus on the quantification and
measurement of online gender-based hate speech, examining literature from
computer science and the social sciences from 2012 to 2022; and (iii) we
identify the opportunities and challenges for measuring gender-based online
hate speech. Our findings from topic analysis suggest a disciplinary divide
between the themes of research on sexism/misogyny. With evidence-based review,
we summarise the different approaches used by the studies who have explored
interdisciplinary approaches to bridge the knowledge gap. Coupled with both the
existing literature on social science theories and computational modeling, we
provide an analysis of the benefits and shortcomings of the methodologies used.
Lastly, we discuss the challenges and opportunities for future research
dedicated to measuring online sexism and misogyny.

摘要：<paragraph>近年來，已經開發出多種計算工具來偵測和辨識性別歧視、厭女症和基於性別的仇恨言論，特別是在線上平台上。儘管這些工具旨在利用社會科學和電腦科學的知識，但對於量化網路性別歧視或厭女症的研究現況所知甚少。鑑於對網路空間中女性遭受歧視的關注日益增加，以及捕捉性別歧視和厭女症網路表現的跨領域研究興起，對於研究實務及其衡量標準進行系統性的文獻回顧是當務之急。我們提出了三個主要的貢獻：(i) 提出一個半自動化的方式，縮小 PRISMA 流程圖中選擇階段不同階段的搜尋結果；(ii) 針對網路性別仇恨言論的量化和衡量進行系統性的文獻回顧，探討 2012 年至 2022 年間電腦科學和社會科學的文獻；(iii) 找出衡量網路性別仇恨言論的機會和挑戰。我們從主題分析中發現的結果顯示，性別歧視/厭女症研究主題之間存在學科鴻溝。透過循證回顧，我們總結了研究中用於彌合知識差距的跨領域方法。結合社會科學理論和計算模型的既有文獻，我們分析了所使用方法的優點和缺點。最後，我們討論了致力於衡量網路性別歧視和厭女症的未來研究的挑戰和機會。</paragraph>

##### **AfriHuBERT: A self-supervised speech representation model for African languages**
2409.20201v1 by Jesujoba O. Alabi, Xuechen Liu, Dietrich Klakow, Junichi Yamagishi

In this work, we present AfriHuBERT, an extension of mHuBERT-147, a
state-of-the-art (SOTA) and compact self-supervised learning (SSL) model,
originally pretrained on 147 languages. While mHuBERT-147 was pretrained on 16
African languages, we expand this to cover 39 African languages through
continued pretraining on 6,500+ hours of speech data aggregated from diverse
sources, including 23 newly added languages. We evaluate AfriHuBERT on two key
speech tasks: Language Identification (LID) and Automatic Speech Recognition
(ASR) using FLEURS dataset. Our results show a +4% F1 score improvement on
average for LID and a -1.2% average Word Error Rate (WER) reduction for ASR.
Further analysis shows that ASR models trained on AfriHuBERT exhibit improved
cross-corpus generalization. Additionally, the analysis indicates that the
FLEURS have data quality limitations that may affect their suitability for
evaluating low-resource African languages, suggesting the need for better
evaluation benchmarks for these languages.

摘要：在這項工作中，我們提出了 AfriHuBERT，這是 mHuBERT-147 的延伸，一種最先進 (SOTA) 且緊湊的自監督學習 (SSL) 模型，最初在 147 種語言上進行預訓練。雖然 mHuBERT-147 在 16 種非洲語言上進行了預訓練，但我們通過在從不同來源彙集的 6,500 多小時語音數據（包括 23 種新增加的語言）上持續預訓練，將其擴展到涵蓋 39 種非洲語言。我們在兩個主要的語音任務上評估了 AfriHuBERT：語言識別 (LID) 和自動語音識別 (ASR)，使用 FLEURS 數據集。我們的結果顯示，LID 的 F1 分數平均提高了 +4%，而 ASR 的平均字元錯誤率 (WER) 降低了 -1.2%。進一步的分析表明，在 AfriHuBERT 上訓練的 ASR 模型表現出更好的跨語料庫概括性。此外，分析表明 FLEURS 存在數據品質限制，這可能會影響它們評估低資源非洲語言的適用性，這表明需要針對這些語言制定更好的評估基準。

##### **Melody Is All You Need For Music Generation**
2409.20196v1 by Shaopeng Wei, Manzhen Wei, Haoyu Wang, Yu Zhao, Gang Kou

We present the Melody Guided Music Generation (MMGen) model, the first novel
approach using melody to guide the music generation that, despite a pretty
simple method and extremely limited resources, achieves excellent performance.
Specifically, we first align the melody with audio waveforms and their
associated descriptions using the multimodal alignment module. Subsequently, we
condition the diffusion module on the learned melody representations. This
allows MMGen to generate music that matches the style of the provided audio
while also producing music that reflects the content of the given text
description. To address the scarcity of high-quality data, we construct a
multi-modal dataset, MusicSet, which includes melody, text, and audio, and will
be made publicly available. We conduct extensive experiments which demonstrate
the superiority of the proposed model both in terms of experimental metrics and
actual performance quality.

摘要：我們提出旋律引導音樂生成（MMGen）模型，這是第一個使用旋律來引導音樂生成的新穎方法，儘管方法相當簡單且資源極為有限，但仍能達到極佳的表現。具體來說，我們首先使用多模態對齊模組將旋律與音訊波形及其相關描述對齊。隨後，我們對擴散模組進行條件處理，以學習旋律表示。這讓 MMGen 能夠生成符合所提供音訊風格的音樂，同時也能產生反映給定文字描述內容的音樂。為了解決高品質資料的稀缺問題，我們建構了一個包含旋律、文字和音訊的多模態資料集 MusicSet，並將公開提供。我們進行了廣泛的實驗，證明了所提出的模型在實驗指標和實際效能品質方面都具有優越性。

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v1 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunović

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

摘要：由於患者異質性以及不明顯或未知的影像生物標記，從醫學影像預測未來疾病進程風險具有挑戰性。
此外，用於存活分析的深度學習 (DL) 方法容易受到跨掃描儀的影像域轉移影響。我們在預測晚期乾性年齡相關性黃斑部病變 (dAMD) 從視網膜 OCT 掃描中發生的任務中解決這些問題。我們提出了一種新的 DL 方法，用於存活預測，以從當前掃描中共同預測風險評分，與轉換時間成反比，以及在時間間隔 $t$ 內轉換的機率。它使用一組平行超平面，這些超平面是透過將偏差項參數化為 $t$ 的函數而產生的。此外，我們根據受試者內影像對開發無監督損失，以確保風險評分隨著時間增加，並且未來的轉換預測與使用未來就診實際掃描的 AMD 階段預測一致。此類損失能夠對使用不同掃描儀取得的新未標籤資料集進行資料有效微調訓練模型。對使用不同掃描儀取得的兩個大型資料集進行廣泛評估，在 6、12 和 24 個月的預測區間內，資料集 1 的平均 AUROC 為 0.82，資料集 2 的平均 AUROC 為 0.83。

##### **Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work**
2409.20192v1 by Samuel Kernan Freire, Tianhao He, Chaofan Wang, Evangelos Niforatos, Alessandro Bozzon

In the shift towards human-centered manufacturing, our two-year longitudinal
study investigates the real-world impact of deploying Cognitive Assistants
(CAs) in factories. The CAs were designed to facilitate knowledge sharing among
factory operators. Our investigation focused on smartphone-based voice
assistants and LLM-powered chatbots, examining their usability and utility in a
real-world factory setting. Based on the qualitative feedback we collected
during the deployments of CAs at the factories, we conducted a thematic
analysis to investigate the perceptions, challenges, and overall impact on
workflow and knowledge sharing.
  Our results indicate that while CAs have the potential to significantly
improve efficiency through knowledge sharing and quicker resolution of
production issues, they also introduce concerns around workplace surveillance,
the types of knowledge that can be shared, and shortcomings compared to
human-to-human knowledge sharing. Additionally, our findings stress the
importance of addressing privacy, knowledge contribution burdens, and tensions
between factory operators and their managers.

摘要：在以人为本的制造业转型中，我们的两年纵向研究调查了在工厂部署认知助理 (CA) 的实际影响。CA 被设计为促进工厂操作员之间的知识共享。我们的调查重点关注基于智能手机的语音助手和 LLM 驱动的聊天机器人，考察了它们在真实工厂环境中的可用性和实用性。基于我们在工厂部署 CA 期间收集的定性反馈，我们进行了主题分析来调查对工作流程和知识共享的看法、挑战和总体影响。
我们的结果表明，虽然 CA 有可能通过知识共享和更快速地解决生产问题来显着提高效率，但它们也引发了对工作场所监控、可共享的知识类型以及与人际知识共享相比的不足的担忧。此外，我们的研究结果强调了解决隐私、知识贡献负担以及工厂操作员与其经理之间的紧张关系的重要性。

##### **TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks**
2409.20189v1 by Areeg Fahad Rasheed, M. Zarkoosh, Safa F. Abbas, Sana Sabah Al-Azzawi

This paper addresses the challenge of classifying and assigning programming
tasks to experts, a process that typically requires significant effort, time,
and cost. To tackle this issue, a novel dataset containing a total of 4,112
programming tasks was created by extracting tasks from various websites. Web
scraping techniques were employed to collect this dataset of programming
problems systematically. Specific HTML tags were tracked to extract key
elements of each issue, including the title, problem description, input-output,
examples, problem class, and complexity score. Examples from the dataset are
provided in the appendix to illustrate the variety and complexity of tasks
included. The dataset's effectiveness has been evaluated and benchmarked using
two approaches; the first approach involved fine-tuning the FLAN-T5 small model
on the dataset, while the second approach used in-context learning (ICL) with
the GPT-4o mini. The performance was assessed using standard metrics: accuracy,
recall, precision, and F1-score. The results indicated that in-context learning
with GPT-4o-mini outperformed the FLAN-T5 model.

摘要：本論文探討了對程式設計任務進行分類和指派給專家的挑戰，這是一個通常需要大量精力、時間和成本的過程。為了解決這個問題，建立了一個包含總共 4,112 個程式設計任務的新穎資料集，方法是從各種網站中擷取任務。使用網頁擷取技術系統地收集這個程式設計問題資料集。追蹤特定的 HTML 標籤，以擷取每個問題的關鍵元素，包括標題、問題說明、輸入輸出、範例、問題類別和複雜度分數。資料集中的範例在附錄中提供，以說明所包含任務的多樣性和複雜性。資料集的有效性已使用兩種方法進行評估和基準測試；第一種方法涉及在資料集上微調 FLAN-T5 小型模型，而第二種方法使用 GPT-4o mini 的情境內學習 (ICL)。使用標準指標評估效能：準確度、召回率、精確度和 F1 分數。結果表明，使用 GPT-4o-mini 的情境內學習優於 FLAN-T5 模型。

##### **Choosing DAG Models Using Markov and Minimal Edge Count in the Absence of Ground Truth**
2409.20187v1 by Joseph D. Ramsey, Bryan Andrews, Peter Spirtes

We give a novel nonparametric pointwise consistent statistical test (the
Markov Checker) of the Markov condition for directed acyclic graph (DAG) or
completed partially directed acyclic graph (CPDAG) models given a dataset. We
also introduce the Cross-Algorithm Frugality Search (CAFS) for rejecting DAG
models that either do not pass the Markov Checker test or that are not edge
minimal. Edge minimality has been used previously by Raskutti and Uhler as a
nonparametric simplicity criterion, though CAFS readily generalizes to other
simplicity conditions. Reference to the ground truth is not necessary for CAFS,
so it is useful for finding causal structure learning algorithms and tuning
parameter settings that output causal models that are approximately true from a
given data set. We provide a software tool for this analysis that is suitable
for even quite large or dense models, provided a suitably fast pointwise
consistent test of conditional independence is available. In addition, we show
in simulation that the CAFS procedure can pick approximately correct models
without knowing the ground truth.

摘要：我們提供了一個新穎的非參數點態一致性統計檢定（馬可夫檢驗器），用於有向非循環圖（DAG）或已完成的部分有向非循環圖（CPDAG）模型的馬可夫條件，給定一個資料集。我們還引入了交叉演算法節儉搜尋（CAFS），用於拒絕未通過馬可夫檢驗器檢定或邊緣非最小的 DAG 模型。邊緣最少性先前已被 Raskutti 和 Uhler 用作非參數簡潔性準則，儘管 CAFS 很容易概括到其他簡潔性條件。CAFS 不需要參考真實情況，因此對於尋找因果結構學習演算法和調整參數設定很有用，這些參數設定會從給定的資料集輸出近似真實的因果模型。我們提供了一個適用於相當大或密集模型的軟體工具，只要有適當的條件獨立點態一致性檢定可用即可。此外，我們在模擬中顯示，CAFS 程序可以在不知道真實情況下挑選近似正確的模型。

##### **Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models**
2409.20181v1 by Luohe Shi, Yao Yao, Zuchao Li, Lefei Zhang, Hai Zhao

Large language models (LLMs) have rapidly advanced and demonstrated
impressive capabilities. In-Context Learning (ICL) and Parameter-Efficient
Fine-Tuning (PEFT) are currently two mainstream methods for augmenting LLMs to
downstream tasks. ICL typically constructs a few-shot learning scenario, either
manually or by setting up a Retrieval-Augmented Generation (RAG) system,
helping models quickly grasp domain knowledge or question-answering patterns
without changing model parameters. However, this approach involves trade-offs,
such as slower inference speed and increased space occupancy. PEFT assists the
model in adapting to tasks through minimal parameter modifications, but the
training process still demands high hardware requirements, even with a small
number of parameters involved. To address these challenges, we propose
Reference Trustable Decoding (RTD), a paradigm that allows models to quickly
adapt to new tasks without fine-tuning, maintaining low inference costs. RTD
constructs a reference datastore from the provided training examples and
optimizes the LLM's final vocabulary distribution by flexibly selecting
suitable references based on the input, resulting in more trustable responses
and enabling the model to adapt to downstream tasks at a low cost. Experimental
evaluations on various LLMs using different benchmarks demonstrate that RTD
establishes a new paradigm for augmenting models to downstream tasks.
Furthermore, our method exhibits strong orthogonality with traditional methods,
allowing for concurrent usage.

摘要：大型語言模型 (LLM) 已快速進步並展現出令人印象深刻的能力。情境學習 (ICL) 和參數高效微調 (PEFT) 目前是擴充 LLM 以執行下游任務的兩種主流方法。ICL 通常會建構一個小樣本學習情境，可以手動或透過設定檢索擴充生成 (RAG) 系統來執行，協助模型快速掌握領域知識或問答模式，而無需變更模型參數。然而，這種方法會涉及取捨，例如推論速度變慢和空間佔用量增加。PEFT 協助模型透過最少的參數修改來適應任務，但訓練過程仍需要很高的硬體需求，即使涉及的參數數量很少。為了應對這些挑戰，我們提出參考可信解碼 (RTD)，這是一種典範，讓模型能夠快速適應新任務，而無需微調，並維持低推論成本。RTD 從提供的訓練範例建構參考資料儲存庫，並透過根據輸入靈活地選擇合適的參考來最佳化 LLM 的最終詞彙分佈，進而產生更可信的回應，並讓模型能夠以低成本適應下游任務。使用不同基準對各種 LLM 進行的實驗評估顯示，RTD 為擴充模型以執行下游任務建立了一個新的典範。此外，我們的方法展現出與傳統方法的強大正交性，允許同時使用。

##### **Modelando procesos cognitivos de la lectura natural con GPT-2**
2409.20174v1 by Bruno Bianchi, Alfredo Umfurer, Juan Esteban Kamienkowski

The advancement of the Natural Language Processing field has enabled the
development of language models with a great capacity for generating text. In
recent years, Neuroscience has been using these models to better understand
cognitive processes. In previous studies, we found that models like Ngrams and
LSTM networks can partially model Predictability when used as a co-variable to
explain readers' eye movements. In the present work, we further this line of
research by using GPT-2 based models. The results show that this architecture
achieves better outcomes than its predecessors.

摘要：自然語言處理領域的進步使得開發出具有巨大文本生成能力的語言模型成為可能。近年來，神經科學一直在使用這些模型來更好地理解認知過程。在先前的研究中，我們發現 Ngrams 和 LSTM 網路等模型可用作協變數來解釋讀者的眼球運動時，可以部分地模擬可預測性。在目前的工作中，我們通過使用基於 GPT-2 的模型進一步推進了這條研究路線。結果表明，這種架構比其前身取得了更好的成果。

##### **Using Large Multimodal Models to Extract Knowledge Components for Knowledge Tracing from Multimedia Question Information**
2409.20167v1 by Hyeongdon Moon, Richard Davis, Seyed Parsa Neshaei, Pierre Dillenbourg

Knowledge tracing models have enabled a range of intelligent tutoring systems
to provide feedback to students. However, existing methods for knowledge
tracing in learning sciences are predominantly reliant on statistical data and
instructor-defined knowledge components, making it challenging to integrate
AI-generated educational content with traditional established methods. We
propose a method for automatically extracting knowledge components from
educational content using instruction-tuned large multimodal models. We
validate this approach by comprehensively evaluating it against knowledge
tracing benchmarks in five domains. Our results indicate that the automatically
extracted knowledge components can effectively replace human-tagged labels,
offering a promising direction for enhancing intelligent tutoring systems in
limited-data scenarios, achieving more explainable assessments in educational
settings, and laying the groundwork for automated assessment.

摘要：知識追蹤模型讓一系列智慧教學系統能為學生提供回饋。然而，現有的知識追蹤方法在學習科學中主要依賴統計資料和由教師定義的知識成分，這使得將 AI 生成的教育內容與傳統既定方法整合起來具有挑戰性。我們提出了一種方法，使用針對教學調整過的大多模態模型從教育內容中自動提取知識成分。我們透過在五個領域的知識追蹤基準對其進行全面評估，驗證了這種方法。我們的結果表明，自動提取的知識成分可以有效取代人工標記的標籤，為在資料有限的情況下增強智慧教學系統、在教育環境中實現更具說明性的評量，以及為自動化評量奠定基礎提供了有希望的方向。

##### **How Entangled is Factuality and Deception in German?**
2409.20165v1 by Aswathy Velutharambath, Amelie Wührl, Roman Klinger

The statement "The earth is flat" is factually inaccurate, but if someone
truly believes and argues in its favor, it is not deceptive. Research on
deception detection and fact checking often conflates factual accuracy with the
truthfulness of statements. This assumption makes it difficult to (a) study
subtle distinctions and interactions between the two and (b) gauge their
effects on downstream tasks. The belief-based deception framework disentangles
these properties by defining texts as deceptive when there is a mismatch
between what people say and what they truly believe. In this study, we assess
if presumed patterns of deception generalize to German language texts. We test
the effectiveness of computational models in detecting deception using an
established corpus of belief-based argumentation. Finally, we gauge the impact
of deception on the downstream task of fact checking and explore if this
property confounds verification models. Surprisingly, our analysis finds no
correlation with established cues of deception. Previous work claimed that
computational models can outperform humans in deception detection accuracy,
however, our experiments show that both traditional and state-of-the-art models
struggle with the task, performing no better than random guessing. For fact
checking, we find that Natural Language Inference-based verification performs
worse on non-factual and deceptive content, while prompting Large Language
Models for the same task is less sensitive to these properties.

摘要：「地球是平的」這句話在事實上是不正確的，但如果有人真的相信並主張它的正確性，這並非欺騙。關於欺騙偵測和事實查核的研究，經常將事實正確性與陳述的真實性混為一談。這個假設使得（a）難以研究兩者之間的細微差異和交互作用，以及（b）衡量它們對下游任務的影響。基於信念的欺騙框架，透過定義在人們所說的話與他們真正相信的事情之間存在不匹配時，將這些屬性區分開來。在這項研究中，我們評估了欺騙的假定模式是否能推廣到德語文本。我們使用既定的基於信念的論證語料庫，測試了計算模型在偵測欺騙方面的有效性。最後，我們衡量了欺騙對事實查核下游任務的影響，並探討這個屬性是否會混淆驗證模型。令人驚訝的是，我們的分析沒有發現與既定的欺騙線索相關。先前的研究聲稱計算模型在欺騙偵測的準確性上可以優於人類，然而，我們的實驗顯示傳統和最先進的模型在這個任務上都表現不佳，表現不比隨機猜測好。對於事實查核，我們發現基於自然語言推論的驗證在非事實和欺騙性內容上表現較差，而提示大型語言模型執行相同的任務，對這些屬性較不敏感。

##### **MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants**
2409.20163v1 by Zeyu Zhang, Quanyu Dai, Luyu Chen, Zeren Jiang, Rui Li, Jieming Zhu, Xu Chen, Yi Xie, Zhenhua Dong, Ji-Rong Wen

LLM-based agents have been widely applied as personal assistants, capable of
memorizing information from user messages and responding to personal queries.
However, there still lacks an objective and automatic evaluation on their
memory capability, largely due to the challenges in constructing reliable
questions and answers (QAs) according to user messages. In this paper, we
propose MemSim, a Bayesian simulator designed to automatically construct
reliable QAs from generated user messages, simultaneously keeping their
diversity and scalability. Specifically, we introduce the Bayesian Relation
Network (BRNet) and a causal generation mechanism to mitigate the impact of LLM
hallucinations on factual information, facilitating the automatic creation of
an evaluation dataset. Based on MemSim, we generate a dataset in the daily-life
scenario, named MemDaily, and conduct extensive experiments to assess the
effectiveness of our approach. We also provide a benchmark for evaluating
different memory mechanisms in LLM-based agents with the MemDaily dataset. To
benefit the research community, we have released our project at
https://github.com/nuster1128/MemSim.

摘要：基於 LLM 的代理已廣泛用作個人助理，能夠記住使用者訊息中的資訊並回應個人查詢。然而，由於在根據使用者訊息建構可靠的問題和解答 (QA) 時面臨挑戰，因此仍缺乏對其記憶能力的客觀且自動化的評估。在本文中，我們提出 MemSim，這是一個貝氏模擬器，旨在從產生的使用者訊息中自動建構可靠的 QA，同時保持其多樣性和可擴充性。具體來說，我們引入了貝氏關係網路 (BRNet) 和因果生成機制，以減輕 LLM 幻覺對事實資訊的影響，促進自動建立評估資料集。基於 MemSim，我們在日常生活場景中產生了一個名為 MemDaily 的資料集，並進行廣泛的實驗以評估我們方法的有效性。我們還提供了使用 MemDaily 資料集評估 LLM 基礎代理中不同記憶機制的基準。為了造福研究社群，我們已在 https://github.com/nuster1128/MemSim 上發布了我們的專案。

##### **1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models**
2409.20149v1 by Chanjun Park, Hyunsoo Ha, Jihoo Kim, Yungi Kim, Dahyun Kim, Sukyung Lee, Seonghoon Yang

In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a
novel framework designed to facilitate efficient data sharing with a
transparent and equitable profit-sharing mechanism. The platform fosters
collaboration between data contributors, who provide otherwise non-disclosed
datasets, and a data consumer, who utilizes these datasets to enhance their own
services. Data contributors are compensated in monetary terms, receiving a
share of the revenue generated by the services of the data consumer. The data
consumer is committed to sharing a portion of the revenue with contributors,
according to predefined profit-sharing arrangements. By incorporating a
transparent profit-sharing paradigm to incentivize large-scale data sharing,
the 1TT Platform creates a collaborative environment to drive the advancement
of NLP and LLM technologies.

摘要：在本文中，我們提出了 1 兆個代幣平台 (1TT 平台)，這是一個新穎的框架，旨在透過透明且公平的利潤分享機制促進資料共享效率。該平台促進資料貢獻者（提供原本不會公開的資料集）與資料使用者（利用這些資料集來提升其自身服務）之間的合作。資料貢獻者會獲得金錢補償，並從資料使用者服務產生的收益中獲得一部分利潤。資料使用者承諾根據預先定義的利潤分享安排，與貢獻者分享部分收益。透過納入透明的利潤分享模式以激勵大規模資料共享，1TT 平台創造了一個協作環境，以推動 NLP 和 LLM 技術的進步。

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

摘要：自然語言處理 (NLP) 在醫療領域中，在涉及非英語語言中小型資料集、標記樣本少和類別不平衡的實際應用中表現不佳。對於如何解決這個問題，目前尚未達成共識。我們使用三組丹麥語癲癇患者磁共振影像的放射報告資料集，評估了一組 NLP 模型，包括類 BERT 轉換器、使用句子轉換器 (SetFit) 的少樣本學習，以及提示的大型語言模型 (LLM)。我們的結果表明，目前在放射報告目標領域中預訓練的類 BERT 模型為此情境提供最佳效能。值得注意的是，與類 BERT 模型相比，SetFit 和 LLM 模型表現不佳，而 LLM 表現最差。重要的是，所研究的模型中沒有一個足夠準確，可以在沒有任何監督的情況下進行文字分類。然而，它們顯示出資料過濾的潛力，這可以減少所需的手動標記量。

##### **Federated Instruction Tuning of LLMs with Domain Coverage Augmentation**
2409.20135v2 by Zezhou Wang, Yaxin Du, Zhuzhong Qian, Siheng Chen

Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited
cross-client private data alongside server-side public data for instruction
augmentation, ultimately enhancing model performance within specific domains.
While the factors affecting FedDIT remain unclear and existing instruction
augmentation methods mainly focus on the centralized setting without
considering the distributed environment. Our experiments reveal that the
cross-client domain coverage, rather than data heterogeneity, drives model
performance in FedDIT. In response, we propose FedDCA, which optimizes domain
coverage through greedy client center selection and retrieval-based
augmentation. To alleviate client-side computational burdens, FedDCA$^*$ uses
heterogeneous encoders with server-side feature alignment. Extensive
experiments across four distinct domains (code, medical, financial, and
mathematical) substantiate the effectiveness of both methods. Additionally, we
investigate privacy preservation against memory extraction attacks utilizing
varying amounts of public data. Results show no significant correlation between
the volume of public data and the privacy-preserving capability. However, as
the fine-tuning round increases, the risk of privacy leakage reduces or
converges.

摘要：聯邦領域特定指令調整 (FedDIT) 利用有限的跨用戶端私人數據以及伺服器端的公開數據進行指令擴充，最終增強特定領域內的模型效能。雖然影響 FedDIT 的因素仍不明確，現有的指令擴充方法主要著重於集中式設定，而未考慮分散式環境。我們的實驗顯示，跨用戶端領域涵蓋範圍，而非數據異質性，驅動了 FedDIT 中的模型效能。為此，我們提出 FedDCA，它透過貪婪用戶端中心選擇和基於檢索的擴充，最佳化領域涵蓋範圍。為了減輕用戶端端的運算負擔，FedDCA$^*$ 使用具有伺服器端特徵比對的異質編碼器。跨越四個不同領域（程式碼、醫療、金融和數學）的廣泛實驗證實了這兩種方法的有效性。此外，我們針對利用不同量公開數據的記憶體提取攻擊調查隱私保護。結果顯示公開數據量與隱私保護能力之間沒有顯著相關性。然而，隨著微調回合數增加，隱私洩漏的風險會降低或收斂。

##### **ACE: Abstractions for Communicating Efficiently**
2409.20120v1 by Jonathan D. Thomas, Andrea Silvi, Devdatt Dubhashi, Vikas Garg, Moa Johansson

A central but unresolved aspect of problem-solving in AI is the capability to
introduce and use abstractions, something humans excel at. Work in cognitive
science has demonstrated that humans tend towards higher levels of abstraction
when engaged in collaborative task-oriented communication, enabling gradually
shorter and more information-efficient utterances. Several computational
methods have attempted to replicate this phenomenon, but all make unrealistic
simplifying assumptions about how abstractions are introduced and learned. Our
method, Abstractions for Communicating Efficiently (ACE), overcomes these
limitations through a neuro-symbolic approach. On the symbolic side, we draw on
work from library learning for proposing abstractions. We combine this with
neural methods for communication and reinforcement learning, via a novel use of
bandit algorithms for controlling the exploration and exploitation trade-off in
introducing new abstractions. ACE exhibits similar tendencies to humans on a
collaborative construction task from the cognitive science literature, where
one agent (the architect) instructs the other (the builder) to reconstruct a
scene of block-buildings. ACE results in the emergence of an efficient language
as a by-product of collaborative communication. Beyond providing mechanistic
insights into human communication, our work serves as a first step to providing
conversational agents with the ability for human-like communicative
abstractions.

摘要：問題解決在 AI 中一個核心但尚未解決的面向是抽象化的引入和使用能力，這是人類擅長的事情。認知科學中的研究已證明，當人類從事協作任務導向溝通時，會傾向於較高層級的抽象化，這使得話語逐漸簡短且更具資訊效率。有幾種運算方法已嘗試複製此現象，但全部都對抽象化是如何引入和學習的做出不切實際的簡化假設。我們的抽象化有效溝通 (ACE) 方法透過神經符號方法克服了這些限制。在符號方面，我們利用來自程式庫學習的成果來提出抽象化。我們將此與神經方法結合起來，用於溝通和強化學習，透過一種新穎的強盜演算法使用方式來控制在引入新抽象化時探索和利用的權衡。ACE 在認知科學文獻中的一項協作建構任務中展現出與人類相似的傾向，在該任務中，一個代理人（建築師）指示另一個代理人（建造者）重建一個積木建築場景。ACE 導致一種有效語言的出現，作為協作溝通的副產品。除了提供人類溝通的機制見解外，我們的研究還作為提供對話代理人具有人類式溝通抽象化能力的第一步。

##### **Aggressive Post-Training Compression on Extremely Large Language Models**
2409.20094v1 by Zining Zhang, Yao Chen, Bingsheng He, Zhenjie Zhang

The increasing size and complexity of Large Language Models (LLMs) pose
challenges for their deployment on personal computers and mobile devices.
Aggressive post-training model compression is necessary to reduce the models'
size, but it often results in significant accuracy loss. To address this
challenge, we propose a novel network pruning technology that utilizes over 0.7
sparsity and less than 8 bits of quantization. Our approach enables the
compression of prevailing LLMs within a couple of hours while maintaining a
relatively small accuracy loss. In experimental evaluations, our method
demonstrates effectiveness and potential for practical deployment. By making
LLMs available on domestic devices, our work can facilitate a new era of
natural language processing applications with wide-ranging impacts.

摘要：大型語言模型 (LLM) 的規模和複雜性日益增加，對其在個人電腦和行動裝置上的部署構成挑戰。積極的訓練後模型壓縮對於縮小模型的規模是必要的，但它通常會導致顯著的準確性損失。為了應對這一挑戰，我們提出了一種新穎的網路修剪技術，它利用超過 0.7 的稀疏性和不到 8 位元的量化。我們的做法可以在幾個小時內壓縮主流的 LLM，同時保持相對較小的準確性損失。在實驗評估中，我們的模型證明了其在實際部署中的有效性和潛力。透過讓 LLM 可用於家用裝置，我們的研究可以促進自然語言處理應用程式的新時代，並產生廣泛的影響。

##### **Robust LLM safeguarding via refusal feature adversarial training**
2409.20089v1 by Lei Yu, Virginie Do, Karen Hambardzumyan, Nicola Cancedda

Large language models (LLMs) are vulnerable to adversarial attacks that can
elicit harmful responses. Defending against such attacks remains challenging
due to the opacity of jailbreaking mechanisms and the high computational cost
of training LLMs robustly. We demonstrate that adversarial attacks share a
universal mechanism for circumventing LLM safeguards that works by ablating a
dimension in the residual stream embedding space called the refusal feature. We
further show that the operation of refusal feature ablation (RFA) approximates
the worst-case perturbation of offsetting model safety. Based on these
findings, we propose Refusal Feature Adversarial Training (ReFAT), a novel
algorithm that efficiently performs LLM adversarial training by simulating the
effect of input-level attacks via RFA. Experiment results show that ReFAT
significantly improves the robustness of three popular LLMs against a wide
range of adversarial attacks, with considerably less computational overhead
compared to existing adversarial training methods.

摘要：大型語言模型 (LLM) 容易受到對抗性攻擊，這些攻擊會引發有害的回應。由於越獄機制的不透明性以及訓練穩健的 LLM 的高運算成本，防禦此類攻擊仍然具有挑戰性。我們證明對抗性攻擊共用一種通用機制來規避 LLM 保障措施，這種機制通過消融殘差串流嵌入空間中稱為拒絕特徵的維度來運作。我們進一步表明，拒絕特徵消融 (RFA) 的操作近似於抵消模型安全性的最壞情況擾動。基於這些發現，我們提出了拒絕特徵對抗性訓練 (ReFAT)，這是一種新穎的演算法，通過 RFA 模擬輸入級別攻擊的影響，有效地執行 LLM 對抗性訓練。實驗結果表明，與現有的對抗性訓練方法相比，ReFAT 大幅提高了三種流行的 LLM 對各種對抗性攻擊的穩健性，且運算負擔顯著降低。

##### **BSharedRAG: Backbone Shared Retrieval-Augmented Generation for the E-commerce Domain**
2409.20075v1 by Kaisi Guan, Qian Cao, Yuchong Sun, Xiting Wang, Ruihua Song

Retrieval Augmented Generation (RAG) system is important in domains such as
e-commerce, which has many long-tail entities and frequently updated
information. Most existing works adopt separate modules for retrieval and
generation, which may be suboptimal since the retrieval task and the generation
task cannot benefit from each other to improve performance. We propose a novel
Backbone Shared RAG framework (BSharedRAG). It first uses a domain-specific
corpus to continually pre-train a base model as a domain-specific backbone
model and then trains two plug-and-play Low-Rank Adaptation (LoRA) modules
based on the shared backbone to minimize retrieval and generation losses
respectively. Experimental results indicate that our proposed BSharedRAG
outperforms baseline models by 5% and 13% in Hit@3 upon two datasets in
retrieval evaluation and by 23% in terms of BLEU-3 in generation evaluation.
Our codes, models, and dataset are available at https://bsharedrag.github.io.

摘要：擷取增強生成（RAG）系統在電子商務等領域中非常重要，電子商務有許多長尾實體和經常更新的資訊。大多數現有作品採用獨立模組進行擷取和生成，這可能是次佳方案，因為擷取任務和生成任務無法互相受益以改善效能。我們提出了一種新穎的 Backbone 共享 RAG 架構（BSharedRAG）。它首先使用特定領域的語料庫持續預訓練基礎模型作為特定領域的 Backbone 模型，然後根據共享 Backbone 訓練兩個即插即用的低階適應（LoRA）模組，以分別最小化擷取和生成損失。實驗結果表明，我們提出的 BSharedRAG 在擷取評估中，於兩個資料集的 Hit@3 中優於基準模型 5% 和 13%，在生成評估中，以 BLEU-3 而言優於基準模型 23%。我們的程式碼、模型和資料集可在 https://bsharedrag.github.io/ 取得。

##### **Knowledge Discovery using Unsupervised Cognition**
2409.20064v1 by Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart

Knowledge discovery is key to understand and interpret a dataset, as well as
to find the underlying relationships between its components. Unsupervised
Cognition is a novel unsupervised learning algorithm that focus on modelling
the learned data. This paper presents three techniques to perform knowledge
discovery over an already trained Unsupervised Cognition model. Specifically,
we present a technique for pattern mining, a technique for feature selection
based on the previous pattern mining technique, and a technique for
dimensionality reduction based on the previous feature selection technique. The
final goal is to distinguish between relevant and irrelevant features and use
them to build a model from which to extract meaningful patterns. We evaluated
our proposals with empirical experiments and found that they overcome the
state-of-the-art in knowledge discovery.

摘要：知識發現是了解和詮釋資料集的關鍵，以及找出其組成部分之間的基礎關係。無監督認知是一種新穎的無監督學習演算法，專注於對學習到的資料進行建模。本文提出了三種技術，以對已訓練好的無監督認知模型執行知識發現。具體來說，我們提出了一種模式探勘技術、一種基於先前模式探勘技術的特徵選取技術，以及一種基於先前特徵選取技術的降維技術。最終目標是區分相關和無關特徵，並使用它們來建立一個模型，從中提取有意義的模式。我們使用經驗實驗評估了我們的提案，發現它們克服了知識發現的最新技術。

##### **Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis**
2409.20059v1 by Hippolyte Gisserot-Boukhlef, Ricardo Rei, Emmanuel Malherbe, Céline Hudelot, Pierre Colombo, Nuno M. Guerreiro

Neural metrics for machine translation (MT) evaluation have become
increasingly prominent due to their superior correlation with human judgments
compared to traditional lexical metrics. Researchers have therefore utilized
neural metrics through quality-informed decoding strategies, achieving better
results than likelihood-based methods. With the rise of Large Language Models
(LLMs), preference-based alignment techniques have gained attention for their
potential to enhance translation quality by optimizing model weights directly
on preferences induced by quality estimators. This study focuses on Contrastive
Preference Optimization (CPO) and conducts extensive experiments to evaluate
the impact of preference-based alignment on translation quality. Our findings
indicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT)
on high-quality data with regard to the alignment metric, it may lead to
instability across downstream evaluation metrics, particularly between neural
and lexical ones. Additionally, we demonstrate that relying solely on the base
model for generating candidate translations achieves performance comparable to
using multiple external systems, while ensuring better consistency across
downstream metrics.

摘要：神經機器翻譯 (MT) 評估指標由於與人類評分相比具有更高的相關性，因此越來越重要，而傳統的詞彙指標則不然。因此，研究人員透過品質導向的解碼策略來利用神經指標，達成比基於似然性的方法更好的結果。隨著大型語言模型 (LLM) 的興起，基於偏好的對齊技術因其透過品質估計器直接最佳化模型權重來提升翻譯品質的潛力而受到關注。本研究專注於對比偏好最佳化 (CPO)，並進行廣泛的實驗來評估基於偏好的對齊對翻譯品質的影響。我們的發現顯示，雖然 CPO 在對齊指標方面始終優於監督微調 (SFT) 的高品質資料，但它可能會導致下游評估指標的不穩定性，特別是在神經指標和詞彙指標之間。此外，我們證明僅依賴基礎模型來產生候選翻譯可達成與使用多個外部系統相當的效能，同時確保下游指標之間的一致性。

##### **Evaluating and explaining training strategies for zero-shot cross-lingual news sentiment analysis**
2409.20054v1 by Luka Andrenšek, Boshko Koloski, Andraž Pelicon, Nada Lavrač, Senja Pollak, Matthew Purver

We investigate zero-shot cross-lingual news sentiment detection, aiming to
develop robust sentiment classifiers that can be deployed across multiple
languages without target-language training data. We introduce novel evaluation
datasets in several less-resourced languages, and experiment with a range of
approaches including the use of machine translation; in-context learning with
large language models; and various intermediate training regimes including a
novel task objective, POA, that leverages paragraph-level information. Our
results demonstrate significant improvements over the state of the art, with
in-context learning generally giving the best performance, but with the novel
POA approach giving a competitive alternative with much lower computational
overhead. We also show that language similarity is not in itself sufficient for
predicting the success of cross-lingual transfer, but that similarity in
semantic content and structure can be equally important.

摘要：我們研究零次學習跨語言新聞情緒偵測，目標是開發強健的情緒分類器，可以在沒有目標語言訓練資料的情況下部署到多種語言中。我們在幾種資源較少的語言中引入了新穎的評估資料集，並嘗試了一系列的方法，包括使用機器翻譯；使用大型語言模型進行情境學習；以及各種中間訓練制度，包括利用段落層級資訊的新穎任務目標 POA。我們的結果證明了與現有技術相比有顯著的改進，其中情境學習通常能提供最佳效能，但新穎的 POA 方法提供了具有較低運算成本的競爭替代方案。我們還表明，語言相似性本身不足以預測跨語言轉移的成功，但語義內容和結構的相似性可能同樣重要。

##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v1 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

摘要：大型語言模型 (LLM) 在處理文本數據方面取得了令人印象深刻的成果，這激發了將這些模型應用於文本數據之外領域（例如圖表）的興趣。在圖表學習領域，利用 LLM 來理解和操作圖表結構數據的興趣與日俱增。現有的研究主要集中於具有豐富文本特徵的圖表，例如知識圖表或文本屬性圖表，利用 LLM 處理文本的能力，但未能充分解決圖表結構。這項工作特別旨在評估和增強 LLM 理解和利用圖表數據本身固有的結構知識的能力，而不是僅關注富含文本內容的圖表。為此，我們引入了自然語言驅動分析模型的圖表理解 (\model)。此模型改進了 LLM 以便更好地理解和參與圖表數據的結構，使其能夠通過利用圖表的結構本身來執行複雜的推理任務。我們對圖表推理基準的實驗評估不僅證實了 \model~ 優於用於比較的 SOTA 基準，還揭示了影響 LLM 圖表推理能力的主要因素。此外，我們提供了理論分析，說明推理路徑如何增強 LLM 的推理能力。

##### **Mitigating Propensity Bias of Large Language Models for Recommender Systems**
2409.20052v1 by Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang

The rapid development of Large Language Models (LLMs) creates new
opportunities for recommender systems, especially by exploiting the side
information (e.g., descriptions and analyses of items) generated by these
models. However, aligning this side information with collaborative information
from historical interactions poses significant challenges. The inherent biases
within LLMs can skew recommendations, resulting in distorted and potentially
unfair user experiences. On the other hand, propensity bias causes side
information to be aligned in such a way that it often tends to represent all
inputs in a low-dimensional subspace, leading to a phenomenon known as
dimensional collapse, which severely restricts the recommender system's ability
to capture user preferences and behaviours. To address these issues, we
introduce a novel framework named Counterfactual LLM Recommendation (CLLMR).
Specifically, we propose a spectrum-based side information encoder that
implicitly embeds structural information from historical interactions into the
side information representation, thereby circumventing the risk of dimension
collapse. Furthermore, our CLLMR approach explores the causal relationships
inherent in LLM-based recommender systems. By leveraging counterfactual
inference, we counteract the biases introduced by LLMs. Extensive experiments
demonstrate that our CLLMR approach consistently enhances the performance of
various recommender models.

摘要：大型語言模型 (LLM) 的快速發展為推薦系統創造了新的機會，特別是透過利用這些模型產生的附帶資訊 (例如，物品的描述和分析)。然而，將此附帶資訊與來自歷史互動的協作資訊相結合，會造成重大的挑戰。LLM 內部固有的偏見會扭曲推薦，導致失真且可能不公平的使用者體驗。另一方面，傾向偏見會導致附帶資訊以某種方式對齊，而這種方式通常傾向於在低維子空間中表示所有輸入，進而導致稱為維度崩潰的現象，這嚴重限制了推薦系統擷取使用者偏好和行為的能力。為了解決這些問題，我們引進一個名為反事實 LLM 推薦 (CLLMR) 的新穎架構。具體來說，我們提出一個基於頻譜的附帶資訊編碼器，它將來自歷史互動的結構資訊隱含地嵌入附帶資訊表示中，從而迴避維度崩潰的風險。此外，我們的 CLLMR 方法探討了基於 LLM 的推薦系統中固有的因果關係。透過利用反事實推論，我們抵銷 LLM 引入的偏見。廣泛的實驗證明，我們的 CLLMR 方法持續提升各種推薦模型的效能。

##### **Depression detection in social media posts using transformer-based models and auxiliary features**
2409.20048v1 by Marios Kerasiotis, Loukas Ilias, Dimitris Askounis

The detection of depression in social media posts is crucial due to the
increasing prevalence of mental health issues. Traditional machine learning
algorithms often fail to capture intricate textual patterns, limiting their
effectiveness in identifying depression. Existing studies have explored various
approaches to this problem but often fall short in terms of accuracy and
robustness. To address these limitations, this research proposes a neural
network architecture leveraging transformer-based models combined with metadata
and linguistic markers. The study employs DistilBERT, extracting information
from the last four layers of the transformer, applying learned weights, and
averaging them to create a rich representation of the input text. This
representation, augmented by metadata and linguistic markers, enhances the
model's comprehension of each post. Dropout layers prevent overfitting, and a
Multilayer Perceptron (MLP) is used for final classification. Data augmentation
techniques, inspired by the Easy Data Augmentation (EDA) methods, are also
employed to improve model performance. Using BERT, random insertion and
substitution of phrases generate additional training data, focusing on
balancing the dataset by augmenting underrepresented classes. The proposed
model achieves weighted Precision, Recall, and F1-scores of 84.26%, 84.18%, and
84.15%, respectively. The augmentation techniques significantly enhance model
performance, increasing the weighted F1-score from 72.59% to 84.15%.

摘要：由於心理健康問題的盛行，在社群媒體貼文中偵測憂鬱症至關重要。傳統機器學習演算法經常無法捕捉複雜的文字模式，限制了它們在辨識憂鬱症上的效能。現有的研究探索了各種解決此問題的方法，但往往在準確度和穩健性方面有所不足。為了解決這些限制，本研究提出了一種神經網路架構，它利用了基於轉換器的模型，並結合了元資料和語言標記。本研究採用 DistilBERT，從轉換器的最後四層提取資訊，套用學習到的權重，並將它們平均以建立輸入文字的豐富表徵。此表徵由元資料和語言標記增強，增強了模型對每則貼文的理解。中斷層防止過度擬合，並使用多層感知器 (MLP) 進行最終分類。資料擴充技術（受簡易資料擴充 (EDA) 方法啟發）也用於改善模型效能。使用 BERT，隨機插入和替換片語會產生額外的訓練資料，重點在透過擴充代表性不足的類別來平衡資料集。所提出的模型分別達到了加權準確率、召回率和 F1 分數 84.26%、84.18% 和 84.15%。擴充技術顯著提升了模型效能，將加權 F1 分數從 72.59% 提升至 84.15%。

##### **Beyond Scores: A Modular RAG-Based System for Automatic Short Answer Scoring with Feedback**
2409.20042v1 by Menna Fateen, Bo Wang, Tsunenori Mine

Automatic short answer scoring (ASAS) helps reduce the grading burden on
educators but often lacks detailed, explainable feedback. Existing methods in
ASAS with feedback (ASAS-F) rely on fine-tuning language models with limited
datasets, which is resource-intensive and struggles to generalize across
contexts. Recent approaches using large language models (LLMs) have focused on
scoring without extensive fine-tuning. However, they often rely heavily on
prompt engineering and either fail to generate elaborated feedback or do not
adequately evaluate it. In this paper, we propose a modular retrieval augmented
generation based ASAS-F system that scores answers and generates feedback in
strict zero-shot and few-shot learning scenarios. We design our system to be
adaptable to various educational tasks without extensive prompt engineering
using an automatic prompt generation framework. Results show an improvement in
scoring accuracy by 9\% on unseen questions compared to fine-tuning, offering a
scalable and cost-effective solution.

摘要：自動簡答評分 (ASAS) 有助於減輕教育者的評分負擔，但通常缺乏詳細且可說明的回饋。現有的 ASAS 附回饋 (ASAS-F) 方法仰賴微調語言模型，但資料集有限，這耗費資源且難以概括所有情境。近期使用大型語言模型 (LLM) 的方法專注於評分，而無需廣泛的微調。然而，它們通常過於依賴提示工程，而且無法產生精緻的回饋，或無法充分評估回饋。在本文中，我們提出一個模組化的檢索增強生成式 ASAS-F 系統，它能在嚴格的零次學習和少次學習情境中評分答案並產生回饋。我們設計系統以適應各種教育任務，而無需使用自動提示產生架構進行廣泛的提示工程。結果顯示，與微調相比，在未見過的問題上，評分準確度提升了 9%，提供了一個可擴充且具有成本效益的解決方案。

##### **Towards Robust Multimodal Sentiment Analysis with Incomplete Data**
2409.20012v1 by Haoyu Zhang, Wenbin Wang, Tianshu Yu

The field of Multimodal Sentiment Analysis (MSA) has recently witnessed an
emerging direction seeking to tackle the issue of data incompleteness.
Recognizing that the language modality typically contains dense sentiment
information, we consider it as the dominant modality and present an innovative
Language-dominated Noise-resistant Learning Network (LNLN) to achieve robust
MSA. The proposed LNLN features a dominant modality correction (DMC) module and
dominant modality based multimodal learning (DMML) module, which enhances the
model's robustness across various noise scenarios by ensuring the quality of
dominant modality representations. Aside from the methodical design, we perform
comprehensive experiments under random data missing scenarios, utilizing
diverse and meaningful settings on several popular datasets (\textit{e.g.,}
MOSI, MOSEI, and SIMS), providing additional uniformity, transparency, and
fairness compared to existing evaluations in the literature. Empirically, LNLN
consistently outperforms existing baselines, demonstrating superior performance
across these challenging and extensive evaluation metrics.

摘要：多模态情感分析 (MSA) 领域最近见证了一个新兴的方向，旨在解决数据不完整的问题。认识到语言模态通常包含密集的情感信息，我们将其视为主要模态，并提出了一种创新的语言主导抗噪学习网络 (LNLN) 来实现稳健的 MSA。所提出的 LNLN 具有主导模态校正 (DMC) 模块和基于主导模态的多模态学习 (DMML) 模块，通过确保主导模态表示的质量，增强了模型在各种噪声场景下的稳健性。除了方法设计之外，我们还在随机数据缺失场景下执行了综合实验，在几个流行的数据集（例如 MOSI、MOSEI 和 SIMS）上利用多样且有意义的设置，与文献中现有的评估相比，提供了额外的统一性、透明性和公平性。凭经验，LNLN 始终优于现有的基线，在这些具有挑战性和广泛的评估指标中展示了卓越的性能。

##### **Customized Information and Domain-centric Knowledge Graph Construction with Large Language Models**
2409.20010v1 by Frank Wawrzik, Matthias Plaue, Savan Vekariya, Christoph Grimm

In this paper we propose a novel approach based on knowledge graphs to
provide timely access to structured information, to enable actionable
technology intelligence, and improve cyber-physical systems planning. Our
framework encompasses a text mining process, which includes information
retrieval, keyphrase extraction, semantic network creation, and topic map
visualization. Following this data exploration process, we employ a selective
knowledge graph construction (KGC) approach supported by an electronics and
innovation ontology-backed pipeline for multi-objective decision-making with a
focus on cyber-physical systems. We apply our methodology to the domain of
automotive electrical systems to demonstrate the approach, which is scalable.
Our results demonstrate that our construction process outperforms GraphGPT as
well as our bi-LSTM and transformer REBEL with a pre-defined dataset by several
times in terms of class recognition, relationship construction and correct
"sublass of" categorization. Additionally, we outline reasoning applications
and provide a comparison with Wikidata to show the differences and advantages
of the approach.

摘要：在本文中，我們提出一個基於知識圖譜的新方法，以提供對結構化資訊的即時存取，以啟用可操作的技術情報，並改善網路實體系統規劃。我們的架構包含一個文字探勘程序，其中包括資訊檢索、關鍵字詞萃取、語意網路建立和主題地圖視覺化。在這個資料探勘程序之後，我們採用一個選擇性的知識圖譜建構 (KGC) 方法，由電子和創新本體支援的管道支援，用於以網路實體系統為重點的多目標決策制定。我們將我們的技術應用於汽車電氣系統領域，以展示這種可擴充的方法。我們的結果表明，我們的建構程序在類別辨識、關係建構和正確的「子類別」分類方面，比 GraphGPT 以及我們使用預定義資料集的雙向 LSTM 和 Transformer REBEL 快好幾倍。此外，我們概述推理應用，並提供與 Wikidata 的比較，以顯示這種方法的差異和優點。

##### **Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data**
2409.20007v1 by Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee

Recent end-to-end speech language models (SLMs) have expanded upon the
capabilities of large language models (LLMs) by incorporating pre-trained
speech models. However, these SLMs often undergo extensive speech
instruction-tuning to bridge the gap between speech and text modalities. This
requires significant annotation efforts and risks catastrophic forgetting of
the original language capabilities. In this work, we present a simple yet
effective automatic process for creating speech-text pair data that carefully
injects speech paralinguistic understanding abilities into SLMs while
preserving the inherent language capabilities of the text-based LLM. Our model
demonstrates general capabilities for speech-related tasks without the need for
speech instruction-tuning data, achieving impressive performance on
Dynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits
the ability to follow complex instructions derived from LLMs, such as specific
output formatting and chain-of-thought reasoning. Our approach not only
enhances the versatility and effectiveness of SLMs but also reduces reliance on
extensive annotated datasets, paving the way for more efficient and capable
speech understanding systems.

摘要：近期的端到端语音语言模型 (SLM) 已通过整合预先训练的语音模型，扩大了大型语言模型 (LLM) 的能力。然而，这些 SLM 经常进行广泛的语音指令微调，以弥合语音和文本模态之间的差距。这需要大量的标注工作，并且有灾难性遗忘原始语言能力的风险。在这项工作中，我们提出一个简单但有效的自动流程来创建语音文本对数据，该数据将语音副语言理解能力小心注入 SLM，同时保留基于文本的 LLM 的固有语言能力。我们的模型展示了对与语音相关的任务的一般能力，而不需要语音指令微调数据，在 Dynamic-SUPERB 和 AIR-Bench-Chat 基准测试中取得了令人印象深刻的性能。此外，我们的模型展示了遵循从 LLM 衍生的复杂指令的能力，例如特定的输出格式和思想链推理。我们的方法不仅增强了 SLM 的多功能性和有效性，而且减少了对大量标注数据集的依赖，为更高效、更强大的语音理解系统铺平了道路。

##### **Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification**
2409.20005v1 by Jiseok Lee, Brian Kenji Iwana

Transfer learning is a common practice that alleviates the need for extensive
data to train neural networks. It is performed by pre-training a model using a
source dataset and fine-tuning it for a target task. However, not every source
dataset is appropriate for each target dataset, especially for time series. In
this paper, we propose a novel method of selecting and using multiple datasets
for transfer learning for time series classification. Specifically, our method
combines multiple datasets as one source dataset for pre-training neural
networks. Furthermore, for selecting multiple sources, our method measures the
transferability of datasets based on shapelet discovery for effective source
selection. While traditional transferability measures require considerable time
for pre-training all the possible sources for source selection of each possible
architecture, our method can be repeatedly used for every possible architecture
with a single simple computation. Using the proposed method, we demonstrate
that it is possible to increase the performance of temporal convolutional
neural networks (CNN) on time series datasets.

摘要：遷移學習是一種常見的實務，可以減輕訓練神經網路時對大量資料的需求。它會使用來源資料集預訓練模型，並針對目標任務微調模型。然而，並非每個來源資料集都適用於每個目標資料集，特別是對於時間序列。在本文中，我們提出了一種新穎的方法，用於選擇和使用多個資料集，以進行時間序列分類的遷移學習。具體來說，我們的方法將多個資料集合併為一個來源資料集，以預訓練神經網路。此外，對於選擇多個來源，我們的方法會根據形狀特徵發現來衡量資料集的可轉移性，以進行有效的來源選擇。雖然傳統的可轉移性測量需要大量時間來預訓練所有可能的來源，以進行每個可能架構的來源選擇，但我們的方法可以重複用於每個可能的架構，只需進行一次簡單的運算。使用所提出的方法，我們證明了提高時間序列資料集上時序卷積神經網路 (CNN) 效能是可行的。

##### **Do Influence Functions Work on Large Language Models?**
2409.19998v1 by Zhe Li, Wei Zhao, Yige Li, Jun Sun

Influence functions aim to quantify the impact of individual training data
points on a model's predictions. While extensive research has been conducted on
influence functions in traditional machine learning models, their application
to large language models (LLMs) has been limited. In this work, we conduct a
systematic study to address a key question: do influence functions work on
LLMs? Specifically, we evaluate influence functions across multiple tasks and
find that they consistently perform poorly in most settings. Our further
investigation reveals that their poor performance can be attributed to: (1)
inevitable approximation errors when estimating the iHVP component due to the
scale of LLMs, (2) uncertain convergence during fine-tuning, and, more
fundamentally, (3) the definition itself, as changes in model parameters do not
necessarily correlate with changes in LLM behavior. Our study thus suggests the
need for alternative approaches for identifying influential samples. To support
future work, our code is made available at
https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs.

摘要：影響函數旨在量化個別訓練資料點對模型預測的影響。雖然針對傳統機器學習模型已進行廣泛的研究，但其在大型語言模型 (LLM) 中的應用受到限制。在這項工作中，我們進行一項系統性研究以解決一個關鍵問題：影響函數是否適用於 LLM？具體而言，我們跨多個任務評估影響函數，並發現它們在大多數設定中表現持續不佳。我們的進一步調查顯示，其表現不佳可歸因於：(1) 由於 LLM 的規模，在估計 iHVP 組成部分時出現不可避免的近似誤差，(2) 微調期間的不確定收斂，以及更根本地，(3) 定義本身，因為模型參數的變化並不一定與 LLM 行為的變化相關。因此，我們的研究表明需要採用替代方法來識別有影響力的樣本。為了支持未來的研究，我們的程式碼已於 https://github.com/plumprc/Failures-of-Influence-Functions-in-LLMs 公開。

##### **Mitigating Backdoor Threats to Large Language Models: Advancement and Challenges**
2409.19993v1 by Qin Liu, Wenjie Mo, Terry Tong, Jiashu Xu, Fei Wang, Chaowei Xiao, Muhao Chen

The advancement of Large Language Models (LLMs) has significantly impacted
various domains, including Web search, healthcare, and software development.
However, as these models scale, they become more vulnerable to cybersecurity
risks, particularly backdoor attacks. By exploiting the potent memorization
capacity of LLMs, adversaries can easily inject backdoors into LLMs by
manipulating a small portion of training data, leading to malicious behaviors
in downstream applications whenever the hidden backdoor is activated by the
pre-defined triggers. Moreover, emerging learning paradigms like instruction
tuning and reinforcement learning from human feedback (RLHF) exacerbate these
risks as they rely heavily on crowdsourced data and human feedback, which are
not fully controlled. In this paper, we present a comprehensive survey of
emerging backdoor threats to LLMs that appear during LLM development or
inference, and cover recent advancement in both defense and detection
strategies for mitigating backdoor threats to LLMs. We also outline key
challenges in addressing these threats, highlighting areas for future research.

摘要：大型語言模型 (LLM) 的進步顯著影響了各種領域，包括網路搜尋、醫療保健和軟體開發。然而，隨著這些模型的擴展，它們更容易受到網路安全風險的影響，特別是後門攻擊。透過利用 LLM 強大的記憶能力，對手可以透過操作一小部分訓練資料，輕鬆地將後門注入 LLM，導致惡意行為出現在下游應用程式中，只要預先定義的觸發器啟動了隱藏的後門。此外，新興的學習範例，例如指令微調和來自人類回饋的強化學習 (RLHF)，會加劇這些風險，因為它們嚴重依賴群眾外包資料和人類回饋，而這些資料和回饋並未受到完全控制。在本文中，我們針對 LLM 開發或推論期間出現的新興後門威脅提出全面的調查，並涵蓋了緩解後門威脅的防禦和偵測策略的最新進展。我們也概述了因應這些威脅的主要挑戰，並重點說明未來研究領域。

##### **Predictive Speech Recognition and End-of-Utterance Detection Towards Spoken Dialog Systems**
2409.19990v1 by Oswald Zink, Yosuke Higuchi, Carlos Mullov, Alexander Waibel, Tetsunori Kobayashi

Effective spoken dialog systems should facilitate natural interactions with
quick and rhythmic timing, mirroring human communication patterns. To reduce
response times, previous efforts have focused on minimizing the latency in
automatic speech recognition (ASR) to optimize system efficiency. However, this
approach requires waiting for ASR to complete processing until a speaker has
finished speaking, which limits the time available for natural language
processing (NLP) to formulate accurate responses. As humans, we continuously
anticipate and prepare responses even while the other party is still speaking.
This allows us to respond appropriately without missing the optimal time to
speak. In this work, as a pioneering study toward a conversational system that
simulates such human anticipatory behavior, we aim to realize a function that
can predict the forthcoming words and estimate the time remaining until the end
of an utterance (EOU), using the middle portion of an utterance. To achieve
this, we propose a training strategy for an encoder-decoder-based ASR system,
which involves masking future segments of an utterance and prompting the
decoder to predict the words in the masked audio. Additionally, we develop a
cross-attention-based algorithm that incorporates both acoustic and linguistic
information to accurately detect the EOU. The experimental results demonstrate
the proposed model's ability to predict upcoming words and estimate future EOU
events up to 300ms prior to the actual EOU. Moreover, the proposed training
strategy exhibits general improvements in ASR performance.

摘要：有效的口語對話系統應促進自然互動，節奏明快，反映人類溝通模式。為了縮短回應時間，先前的努力集中在最小化自動語音辨識 (ASR) 中的延遲，以最佳化系統效率。然而，這種方法需要等到 ASR 完成處理，直到說話者說完話為止，這限制了自然語言處理 (NLP) 可用於制定準確回應的時間。作為人類，我們會持續預期和準備回應，即使對方仍在說話。這讓我們能夠在不錯過最適說話時間的情況下適當地回應。在這項工作中，作為模擬這種人類預期行為的對話系統的開創性研究，我們旨在實現一項功能，該功能可以使用一段話的中間部分來預測接下來的字詞，並估計到話語結束 (EOU) 所剩的時間。為達成此目的，我們提出編碼器解碼器式 ASR 系統的訓練策略，其中涉及遮蔽一段話的未來片段，並提示解碼器預測遮蔽音訊中的字詞。此外，我們開發了一種基於交叉注意力的演算法，該演算法結合了聲學和語言資訊，以準確偵測 EOU。實驗結果證明了所提出的模型預測後續字詞和估計未來 EOU 事件的能力，在實際 EOU 之前最多可達 300 毫秒。此外，所提出的訓練策略在 ASR 效能方面展現了一般性的改進。

##### **CONTESTS: a Framework for Consistency Testing of Span Probabilities in Language Models**
2409.19984v1 by Eitan Wagner, Yuli Slavutsky, Omri Abend

Although language model scores are often treated as probabilities, their
reliability as probability estimators has mainly been studied through
calibration, overlooking other aspects. In particular, it is unclear whether
language models produce the same value for different ways of assigning joint
probabilities to word spans. Our work introduces a novel framework, ConTestS
(Consistency Testing over Spans), involving statistical tests to assess score
consistency across interchangeable completion and conditioning orders. We
conduct experiments on post-release real and synthetic data to eliminate
training effects. Our findings reveal that both Masked Language Models (MLMs)
and autoregressive models exhibit inconsistent predictions, with autoregressive
models showing larger discrepancies. Larger MLMs tend to produce more
consistent predictions, while autoregressive models show the opposite trend.
Moreover, for both model types, prediction entropies offer insights into the
true word span likelihood and therefore can aid in selecting optimal decoding
strategies. The inconsistencies revealed by our analysis, as well their
connection to prediction entropies and differences between model types, can
serve as useful guides for future research on addressing these limitations.

摘要：儘管語言模型分數通常被視為機率，但其作為機率估計器的可靠性主要透過校準來研究，忽視了其他面向。特別是不清楚語言模型是否對指定詞彙範圍的聯合機率的不同方式產生相同的值。我們的研究引入了一個新穎的架構，ConTestS（跨範圍的一致性測試），涉及統計測試以評估可互換完成和條件順序之間的分數一致性。我們對發布後的真實和合成資料進行實驗，以消除訓練效果。我們的研究結果顯示，遮蔽語言模型 (MLM) 和自迴歸模型都會產生不一致的預測，而自迴歸模型顯示出更大的差異。較大的 MLM 傾向於產生更一致的預測，而自迴歸模型則顯示相反的趨勢。此外，對於這兩種模型類型，預測熵提供了對真實詞彙範圍機率的見解，因此有助於選擇最佳解碼策略。我們的分析揭示的不一致性，以及它們與預測熵和模型類型之間的差異，可以作為未來研究解決這些限制的有用指南。

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

摘要：大型語言模型 (LLM) 已證明在推薦任務中具有顯著的推理能力，方法是將其轉換為文本生成任務。然而，現有方法不是忽略用戶項目高階互動，就是對其建模效果不佳。為此，本文提出了一種增強的基於 LLM 的推薦器 (ELMRec)。我們增強了全詞嵌入，以大幅增強 LLM 對圖形構建互動的解讀，用於推薦，而不需要圖形預訓練。這一發現可能會激勵將豐富的知識圖譜通過全詞嵌入整合到基於 LLM 的推薦器中的努力。我們還發現，LLM 通常根據用戶早期的互動而非最近的互動來推薦項目，並提出了一種重新排序的解決方案。我們的 ELMRec 在直接和順序推薦中都優於最先進 (SOTA) 方法。

##### **Knowledge Graph Embedding by Normalizing Flows**
2409.19977v1 by Changyi Xiao, Xiangnan He, Yixin Cao

A key to knowledge graph embedding (KGE) is to choose a proper representation
space, e.g., point-wise Euclidean space and complex vector space. In this
paper, we propose a unified perspective of embedding and introduce uncertainty
into KGE from the view of group theory. Our model can incorporate existing
models (i.e., generality), ensure the computation is tractable (i.e.,
efficiency) and enjoy the expressive power of complex random variables (i.e.,
expressiveness). The core idea is that we embed entities/relations as elements
of a symmetric group, i.e., permutations of a set. Permutations of different
sets can reflect different properties of embedding. And the group operation of
symmetric groups is easy to compute. In specific, we show that the embedding of
many existing models, point vectors, can be seen as elements of a symmetric
group. To reflect uncertainty, we first embed entities/relations as
permutations of a set of random variables. A permutation can transform a simple
random variable into a complex random variable for greater expressiveness,
called a normalizing flow. We then define scoring functions by measuring the
similarity of two normalizing flows, namely NFE. We construct several
instantiating models and prove that they are able to learn logical rules.
Experimental results demonstrate the effectiveness of introducing uncertainty
and our model. The code is available at https://github.com/changyi7231/NFE.

摘要：知識圖譜嵌入 (KGE) 的關鍵在於選擇適當的表示空間，例如點狀歐幾里得空間和複數向量空間。在本文中，我們提出了嵌入的統一觀點，並從群論的角度將不確定性引入 KGE。我們的模型可以整合現有模型（即一般性），確保計算是可行的（即效率），並享有複數隨機變數的表達能力（即表達性）。核心思想是我們將實體/關係嵌入為對稱群的元素，即集合的排列。不同集合的排列可以反映嵌入的不同屬性。而對稱群的群運算很容易計算。具體來說，我們表明許多現有模型的嵌入，點向量，可以看作是對稱群的元素。為了反映不確定性，我們首先將實體/關係嵌入為一組隨機變數的排列。一個排列可以將一個簡單的隨機變數轉換為一個複雜的隨機變數以獲得更大的表達能力，稱為正規化流。然後，我們通過測量兩個正規化流的相似性來定義評分函數，即 NFE。我們構建了幾個實例化模型，並證明它們能夠學習邏輯規則。實驗結果證明了引入不確定性和我們模型的有效性。程式碼可在 https://github.com/changyi7231/NFE 取得。

##### **Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval**
2409.19961v1 by Yabing Wang, Le Wang, Qiang Zhou, Zhibin Wang, Hao Li, Gang Hua, Wei Tang

Cross-lingual cross-modal retrieval (CCR) aims to retrieve visually relevant
content based on non-English queries, without relying on human-labeled
cross-modal data pairs during training. One popular approach involves utilizing
machine translation (MT) to create pseudo-parallel data pairs, establishing
correspondence between visual and non-English textual data. However, aligning
their representations poses challenges due to the significant semantic gap
between vision and text, as well as the lower quality of non-English
representations caused by pre-trained encoders and data noise. To overcome
these challenges, we propose LECCR, a novel solution that incorporates the
multi-modal large language model (MLLM) to improve the alignment between visual
and non-English representations. Specifically, we first employ MLLM to generate
detailed visual content descriptions and aggregate them into multi-view
semantic slots that encapsulate different semantics. Then, we take these
semantic slots as internal features and leverage them to interact with the
visual features. By doing so, we enhance the semantic information within the
visual features, narrowing the semantic gap between modalities and generating
local visual semantics for subsequent multi-level matching. Additionally, to
further enhance the alignment between visual and non-English features, we
introduce softened matching under English guidance. This approach provides more
comprehensive and reliable inter-modal correspondences between visual and
non-English features. Extensive experiments on four CCR benchmarks, \ie
Multi30K, MSCOCO, VATEX, and MSR-VTT-CN, demonstrate the effectiveness of our
proposed method. Code: \url{https://github.com/LiJiaBei-7/leccr}.

摘要：跨語言跨模態檢索 (CCR) 旨在根據非英語查詢檢索視覺相關內容，而無需在訓練過程中依賴人工標記的跨模態資料對。一種流行的方法涉及利用機器翻譯 (MT) 來建立偽平行資料對，建立視覺與非英語文本資料之間的對應關係。然而，由於視覺與文本之間存在顯著的語義差距，以及預訓練編碼器和資料雜訊造成的非英語表示品質較低，因此對齊其表示會帶來挑戰。為了克服這些挑戰，我們提出了 LECCR，這是一種結合多模態大型語言模型 (MLLM) 來改善視覺與非英語表示之間對齊的新穎解決方案。具體來說，我們首先使用 MLLM 來產生詳細的視覺內容描述，並將它們匯總到包含不同語義的多視角語義槽中。然後，我們將這些語義槽作為內部特徵，並利用它們與視覺特徵進行互動。透過這樣做，我們增強了視覺特徵中的語義資訊，縮小了模態之間的語義差距，並為後續的多層次匹配產生了局部視覺語義。此外，為了進一步增強視覺與非英語特徵之間的對齊，我們引入了在英語指導下的軟化匹配。這種方法提供了視覺與非英語特徵之間更全面且可靠的跨模態對應關係。在四個 CCR 基準上的廣泛實驗，即 Multi30K、MSCOCO、VATEX 和 MSR-VTT-CN，證明了我們提出的方法的有效性。程式碼：\url{https://github.com/LiJiaBei-7/leccr}。

##### **TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning**
2409.19960v1 by Joshua Feinglass, Yezhou Yang

Zero-shot inference, where pre-trained models perform tasks without specific
training data, is an exciting emergent ability of large models like CLIP.
Although there has been considerable exploration into enhancing zero-shot
abilities in image captioning (IC) for popular datasets such as MSCOCO and
Flickr8k, these approaches fall short with fine-grained datasets like CUB, FLO,
UCM-Captions, and Sydney-Captions. These datasets require captions to discern
between visually and semantically similar classes, focusing on detailed object
parts and their attributes. To overcome this challenge, we introduce
TRaining-Free Object-Part Enhancement (TROPE). TROPE enriches a base caption
with additional object-part details using object detector proposals and Natural
Language Processing techniques. It complements rather than alters the base
caption, allowing seamless integration with other captioning methods and
offering users enhanced flexibility. Our evaluations show that TROPE
consistently boosts performance across all tested zero-shot IC approaches and
achieves state-of-the-art results on fine-grained IC datasets.

摘要：零次學習推理，其中預訓練模型在沒有特定訓練資料的情況下執行任務，是 CLIP 等大型模型令人興奮的新興能力。儘管已經對增強流行資料集（例如 MSCOCO 和 Flickr8k）中影像標題（IC）的零次學習能力進行了大量的探索，但這些方法在 CUB、FLO、UCM-Captions 和 Sydney-Captions 等細粒度資料集上仍有不足。這些資料集需要標題來區分視覺上和語義上相似的類別，重點關注詳細的物件部分及其屬性。為了克服這個挑戰，我們引入了無訓練物件部分增強（TROPE）。TROPE 使用物件偵測建議和自然語言處理技術，使用額外的物件部分細節來豐富基本標題。它補充而不是改變基本標題，允許與其他標題方法無縫整合，並為使用者提供增強的靈活性。我們的評估表明，TROPE 在所有測試的零次學習 IC 方法中持續提升效能，並在細粒度 IC 資料集上取得最先進的結果。

##### **Attribute-Text Guided Forgetting Compensation for Lifelong Person Re-Identification**
2409.19954v1 by Shiben Liu, Huijie Fan, Qiang Wang, Weihong Ren, Yandong Tang

Lifelong person re-identification (LReID) aims to continuously learn from
non-stationary data to match individuals in different environments. Each task
is affected by variations in illumination and person-related information (such
as pose and clothing), leading to task-wise domain gaps. Current LReID methods
focus on task-specific knowledge and ignore intrinsic task-shared
representations within domain gaps, limiting model performance. Bridging
task-wise domain gaps is crucial for improving anti-forgetting and
generalization capabilities, especially when accessing limited old classes
during training. To address these issues, we propose a novel attribute-text
guided forgetting compensation (ATFC) model, which explores text-driven global
representations of identity-related information and attribute-related local
representations of identity-free information for LReID. Due to the lack of
paired text-image data, we design an attribute-text generator (ATG) to
dynamically generate a text descriptor for each instance. We then introduce a
text-guided aggregation network (TGA) to explore robust text-driven global
representations for each identity and knowledge transfer. Furthermore, we
propose an attribute compensation network (ACN) to investigate
attribute-related local representations, which distinguish similar identities
and bridge domain gaps. Finally, we develop an attribute anti-forgetting (AF)
loss and knowledge transfer (KT) loss to minimize domain gaps and achieve
knowledge transfer, improving model performance. Extensive experiments
demonstrate that our ATFC method achieves superior performance, outperforming
existing LReID methods by over 9.0$\%$/7.4$\%$ in average mAP/R-1 on the seen
dataset.

摘要：終身人物再識別 (LReID) 旨在持續從非平穩資料中學習，以在不同環境中比對個人。每個任務都會受到光照和個人相關資訊（例如姿勢和服裝）的變化影響，導致任務間的領域差距。目前的 LReID 方法專注於任務特定知識，而忽略領域差距內的內在任務共享表徵，限制了模型效能。彌合任務間的領域差距對於提升抗遺忘和概化能力至關重要，尤其是在訓練期間存取受限的舊類別時。為了解決這些問題，我們提出一個新穎的屬性文字引導遺忘補償 (ATFC) 模型，探索與身分相關資訊的文字驅動全局表徵，以及 LReID 身分無關資訊的屬性相關局部表徵。由於缺乏成對文字影像資料，我們設計了一個屬性文字產生器 (ATG) 來動態產生每個實例的文字描述符。然後，我們引入一個文字引導聚合網路 (TGA) 來探索每個身分的強健文字驅動全局表徵和知識傳遞。此外，我們提出一個屬性補償網路 (ACN) 來探討屬性相關的局部表徵，區分相似的身分並彌合領域差距。最後，我們開發了一個屬性抗遺忘 (AF) 損失和知識傳遞 (KT) 損失，以最小化領域差距並實現知識傳遞，提升模型效能。廣泛的實驗證明，我們的 ATFC 方法實現了卓越的效能，在已見資料集上以平均 mAP/R-1 超過 9.0% / 7.4% 的幅度優於現有的 LReID 方法。

##### **Law of the Weakest Link: Cross Capabilities of Large Language Models**
2409.19951v1 by Ming Zhong, Aston Zhang, Xuewei Wang, Rui Hou, Wenhan Xiong, Chenguang Zhu, Zhengxing Chen, Liang Tan, Chloe Bi, Mike Lewis, Sravya Popuri, Sharan Narang, Melanie Kambadur, Dhruv Mahajan, Sergey Edunov, Jiawei Han, Laurens van der Maaten

The development and evaluation of Large Language Models (LLMs) have largely
focused on individual capabilities. However, this overlooks the intersection of
multiple abilities across different types of expertise that are often required
for real-world tasks, which we term cross capabilities. To systematically
explore this concept, we first define seven core individual capabilities and
then pair them to form seven common cross capabilities, each supported by a
manually constructed taxonomy. Building on these definitions, we introduce
CrossEval, a benchmark comprising 1,400 human-annotated prompts, with 100
prompts for each individual and cross capability. To ensure reliable
evaluation, we involve expert annotators to assess 4,200 model responses,
gathering 8,400 human ratings with detailed explanations to serve as reference
examples. Our findings reveal that, in both static evaluations and attempts to
enhance specific abilities, current LLMs consistently exhibit the "Law of the
Weakest Link," where cross-capability performance is significantly constrained
by the weakest component. Specifically, across 58 cross-capability scores from
17 models, 38 scores are lower than all individual capabilities, while 20 fall
between strong and weak, but closer to the weaker ability. These results
highlight the under-performance of LLMs in cross-capability tasks, making the
identification and improvement of the weakest capabilities a critical priority
for future research to optimize performance in complex, multi-dimensional
scenarios.

摘要：大型語言模型 (LLM) 的開發和評估主要集中在個別能力上。然而，這忽略了在現實世界任務中通常需要的不同類型專業知識間多種能力的交集，我們稱之為交叉能力。為了系統性地探討這個概念，我們首先定義了七項核心個別能力，然後將它們配對形成七項常見的交叉能力，每項都由人工構建的分類法支持。建立在這些定義之上，我們引入了 CrossEval，一個包含 1,400 個人類註解提示的基準，每個個別和交叉能力有 100 個提示。為了確保可靠的評估，我們讓專家註解者評估 4,200 個模型回應，收集 8,400 個帶有詳細說明的人類評分作為參考範例。我們的研究結果顯示，在靜態評估和嘗試增強特定能力時，目前的 LLM 持續展現「最弱環節法則」，其中交叉能力的表現顯著地受到最弱組成的限制。具體來說，在 17 個模型的 58 個交叉能力分數中，有 38 個分數低於所有個別能力，而 20 個介於強和弱之間，但更接近較弱的能力。這些結果突顯了 LLM 在交叉能力任務中的表現不佳，使得識別和改善最弱的能力成為未來研究優化複雜、多維度場景中表現的關鍵優先事項。

##### **Task-agnostic Pre-training and Task-guided Fine-tuning for Versatile Diffusion Planner**
2409.19949v1 by Chenyou Fan, Chenjia Bai, Zhao Shan, Haoran He, Yang Zhang, Zhen Wang

Diffusion models have demonstrated their capabilities in modeling
trajectories of multi-tasks. However, existing multi-task planners or policies
typically rely on task-specific demonstrations via multi-task imitation, or
require task-specific reward labels to facilitate policy optimization via
Reinforcement Learning (RL). To address these challenges, we aim to develop a
versatile diffusion planner that can leverage large-scale inferior data that
contains task-agnostic sub-optimal trajectories, with the ability to fast adapt
to specific tasks. In this paper, we propose \textbf{SODP}, a two-stage
framework that leverages \textbf{S}ub-\textbf{O}ptimal data to learn a
\textbf{D}iffusion \textbf{P}lanner, which is generalizable for various
downstream tasks. Specifically, in the pre-training stage, we train a
foundation diffusion planner that extracts general planning capabilities by
modeling the versatile distribution of multi-task trajectories, which can be
sub-optimal and has wide data coverage. Then for downstream tasks, we adopt
RL-based fine-tuning with task-specific rewards to fast refine the diffusion
planner, which aims to generate action sequences with higher task-specific
returns. Experimental results from multi-task domains including Meta-World and
Adroit demonstrate that SODP outperforms state-of-the-art methods with only a
small amount of data for reward-guided fine-tuning.

摘要：擴散模型已展現其在模擬多任務軌跡上的能力。然而，現有的多任務規劃器或策略通常依賴於透過多任務模仿進行特定任務的示範，或需要特定任務的獎勵標籤以透過強化學習 (RL) 促進策略最佳化。為了解決這些挑戰，我們旨在開發一個多功能擴散規劃器，該規劃器可以利用包含與任務無關的次佳軌跡的大規模劣質資料，並具備快速適應特定任務的能力。在本文中，我們提出了一個兩階段架構 **SODP**，它利用 **S**ub-**O**ptimal 資料來學習一個 **D**iffusion **P**lanner，該規劃器可以泛化到各種下游任務。具體來說，在預訓練階段，我們訓練一個基礎擴散規劃器，它透過模擬多任務軌跡的多功能分佈來提取一般規劃能力，該分佈可以是次佳的，並且具有廣泛的資料涵蓋範圍。然後，對於下游任務，我們採用基於 RL 的微調，並使用特定任務的獎勵來快速微調擴散規劃器，其目的是生成具有較高任務特定回報的動作序列。來自多任務領域（包括 Meta-World 和 Adroit）的實驗結果表明，SODP 在僅使用少量資料進行獎勵引導微調的情況下，優於最先進的方法。

##### **JaPOC: Japanese Post-OCR Correction Benchmark using Vouchers**
2409.19948v1 by Masato Fujitake

In this paper, we create benchmarks and assess the effectiveness of error
correction methods for Japanese vouchers in OCR (Optical Character Recognition)
systems. It is essential for automation processing to correctly recognize
scanned voucher text, such as the company name on invoices. However, perfect
recognition is complex due to the noise, such as stamps. Therefore, it is
crucial to correctly rectify erroneous OCR results. However, no publicly
available OCR error correction benchmarks for Japanese exist, and methods have
not been adequately researched. In this study, we measured text recognition
accuracy by existing services on Japanese vouchers and developed a post-OCR
correction benchmark. Then, we proposed simple baselines for error correction
using language models and verified whether the proposed method could
effectively correct these errors. In the experiments, the proposed error
correction algorithm significantly improved overall recognition accuracy.

摘要：在本文中，我們建立基準並評估光學字元辨識 (OCR) 系統中日文憑證錯誤校正方法的有效性。正確辨識掃描的憑證文字（例如發票上的公司名稱）對於自動化處理至關重要。然而，由於印章等雜訊，完美的辨識很複雜。因此，正確修正錯誤的 OCR 結果至關重要。然而，目前沒有公開可用的日文 OCR 錯誤校正基準，且方法尚未得到充分研究。在本研究中，我們測量了現有服務對日文憑證的文字辨識準確度，並開發了一個 OCR 後校正基準。然後，我們提出了使用語言模型進行錯誤校正的簡單基線，並驗證所提出的方法是否可以有效校正這些錯誤。在實驗中，所提出的錯誤校正演算法顯著提高了整體辨識準確度。

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

摘要：醫療 AI 中的公平性日益被視為醫療保健提供中至關重要的一環。雖然大多數先前關於公平性的研究都強調同等表現的重要性，我們認為公平性的下降可能是有害的或無害的，具體取決於變化的類型和敏感屬性的使用方式。為此，我們引入了正和公平性的概念，它指出，只要不以犧牲個別子群體表現為代價，那麼導致群體差異更大的表現提升是可以接受的。這允許將與疾病相關的敏感屬性用於提高表現，而不會損害公平性。
我們通過比較四個在訓練階段對種族屬性使用不同的 CNN 模型來說明這個想法。結果顯示，從圖像中移除所有人口編碼有助於縮小不同子群體之間的表現差距，而將種族屬性用作模型的輸入會提高整體表現，同時擴大子群體之間的差異。然後，通過我們正和公平性的概念將這些更大的差距置於整體效益的角度，以區分有害和無害的差異。

##### **Large Language Model Empowered Embedding Generator for Sequential Recommendation**
2409.19925v1 by Qidong Liu, Xian Wu, Wanyu Wang, Yejing Wang, Yuanshao Zhu, Xiangyu Zhao, Feng Tian, Yefeng Zheng

Sequential Recommender Systems (SRS) are extensively applied across various
domains to predict users' next interaction by modeling their interaction
sequences. However, these systems typically grapple with the long-tail problem,
where they struggle to recommend items that are less popular. This challenge
results in a decline in user discovery and reduced earnings for vendors,
negatively impacting the system as a whole. Large Language Model (LLM) has the
potential to understand the semantic connections between items, regardless of
their popularity, positioning them as a viable solution to this dilemma. In our
paper, we present LLMEmb, an innovative technique that harnesses LLM to create
item embeddings that bolster the performance of SRS. To align the capabilities
of general-purpose LLM with the needs of the recommendation domain, we
introduce a method called Supervised Contrastive Fine-Tuning (SCFT). This
method involves attribute-level data augmentation and a custom contrastive loss
designed to tailor LLM for enhanced recommendation performance. Moreover, we
highlight the necessity of incorporating collaborative filtering signals into
LLM-generated embeddings and propose Recommendation Adaptation Training (RAT)
for this purpose. RAT refines the embeddings to be optimally suited for SRS.
The embeddings derived from LLMEmb can be easily integrated with any SRS model,
showcasing its practical utility. Extensive experimentation on three real-world
datasets has shown that LLMEmb significantly improves upon current methods when
applied across different SRS models.

摘要：序列推薦系統 (SRS) 廣泛應用於各種領域，透過建模使用者的互動序列來預測他們的下一個互動。然而，這些系統通常會遇到長尾問題，也就是難以推薦較不受歡迎的項目。此挑戰導致使用者探索減少，以及供應商收益降低，對系統整體造成負面影響。大型語言模型 (LLM) 有潛力了解項目之間的語義關聯，而不管其受歡迎程度如何，使其成為解決此困境的可行方案。在我們的論文中，我們提出 LLMEmb，這是一種創新的技術，利用 LLM 來建立項目嵌入，以提升 SRS 的效能。為了將通用 LLM 的功能與推薦領域的需求結合，我們引入一種稱為監督對比微調 (SCFT) 的方法。此方法涉及屬性層級資料擴充和自訂對比損失，旨在調整 LLM 以增強推薦效能。此外，我們強調將協同過濾訊號納入 LLM 生成的嵌入的必要性，並提出推薦適應訓練 (RAT) 以達到此目的。RAT 會調整嵌入，使其最適合 SRS。從 LLMEmb 衍生的嵌入可以輕鬆與任何 SRS 模型整合，展示其實用性。在三個真實世界資料集上進行的廣泛實驗顯示，LLMEmb 在應用於不同 SRS 模型時，顯著優於目前的方法。

##### **On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability**
2409.19924v2 by Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang

Recent advancements in Large Language Models (LLMs) have showcased their
ability to perform complex reasoning tasks, but their effectiveness in planning
remains underexplored. In this study, we evaluate the planning capabilities of
OpenAI's o1 models across a variety of benchmark tasks, focusing on three key
aspects: feasibility, optimality, and generalizability. Through empirical
evaluations on constraint-heavy tasks (e.g., $\textit{Barman}$,
$\textit{Tyreworld}$) and spatially complex environments (e.g.,
$\textit{Termes}$, $\textit{Floortile}$), we highlight o1-preview's strengths
in self-evaluation and constraint-following, while also identifying bottlenecks
in decision-making and memory management, particularly in tasks requiring
robust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4
in adhering to task constraints and managing state transitions in structured
environments. However, the model often generates suboptimal solutions with
redundant actions and struggles to generalize effectively in spatially complex
tasks. This pilot study provides foundational insights into the planning
limitations of LLMs, offering key directions for future research on improving
memory management, decision-making, and generalization in LLM-based planning.

摘要：大型語言模型 (LLM) 的最新進展展示了它們執行複雜推理任務的能力，但它們在規劃中的有效性仍未得到充分探討。在本研究中，我們評估了 OpenAI 的 o1 模型在各種基準任務中的規劃能力，重點關注三個關鍵方面：可行性、最優性和可概括性。通過對約束繁重的任務（例如，$\textit{Barman}$、$\textit{Tyreworld}$）和空間複雜環境（例如，$\textit{Termes}$、$\textit{Floortile}$）的經驗評估，我們強調了 o1-preview 在自我評估和約束遵循方面的優勢，同時也發現了決策制定和記憶體管理中的瓶頸，特別是在需要強大的空間推理能力的任務中。我們的結果表明，o1-preview 在遵守任務約束和管理結構化環境中的狀態轉換方面優於 GPT-4。然而，該模型通常會生成具有冗餘動作的次優解，並且難以在空間複雜的任務中有效概括。這項試點研究提供了對 LLM 規劃限制的基本見解，為改進基於 LLM 的規劃中的記憶體管理、決策制定和概括提供了未來研究的主要方向。

##### **Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Object-Oriented Programming**
2409.19916v1 by Ming Li, Ziqian Bi, Tianyang Wang, Keyu Chen, Jiawei Xu, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jinlang Wang, Pohsun Feng, Caitlyn Heqi Yin, Yizhu Wen, Ming Liu

Object-Oriented Programming (OOP) has become a crucial paradigm for managing
the growing complexity of modern software systems, particularly in fields like
machine learning, deep learning, large language models (LLM), and data
analytics. This work provides a comprehensive introduction to the integration
of OOP techniques within these domains, with a focus on improving code
modularity, maintainability, and scalability. We begin by outlining the
evolution of computing and the rise of OOP, followed by an in-depth discussion
of key OOP principles such as encapsulation, inheritance, polymorphism, and
abstraction. The practical application of these principles is demonstrated
using Python, a widely adopted language in AI and data science. Furthermore, we
examine how design patterns and modular programming can be employed to enhance
the structure and efficiency of machine learning systems. In subsequent
sections, we apply these OOP concepts to real-world AI tasks, including the
encapsulation of preprocessing workflows, machine learning model training, and
evaluation. Detailed examples illustrate how OOP can be used to build reusable,
scalable machine learning systems while maintaining code clarity and reducing
redundancy.This work is intended to serve as a bridge for both beginners and
experienced developers, equipping them with the necessary knowledge to apply
OOP methodologies in AI-driven projects, ultimately fostering the development
of more robust and maintainable systems.

摘要：<paragraph>物件導向程式設計（OOP）已成為管理現代軟體系統日益增加的複雜性的關鍵範例，特別是在機器學習、深度學習、大型語言模型（LLM）和資料分析等領域。這項工作提供了將 OOP 技術整合到這些領域的全面性介紹，重點在於改善程式碼的模組化、可維護性和可擴充性。我們從概述運算的演進和 OOP 的興起開始，接著深入探討封裝、繼承、多型和抽象化等 OOP 原則。這些原則的實際應用是使用 Python 來展示，Python 是 AI 和資料科學中廣泛採用的語言。此外，我們探討設計模式和模組化程式設計如何用於增強機器學習系統的結構和效率。在後續的章節中，我們將這些 OOP 概念應用於真實世界的 AI 任務，包括預處理工作流程的封裝、機器學習模型訓練和評估。詳細範例說明如何使用 OOP 來建構可重複使用、可擴充的機器學習系統，同時保持程式碼清晰度並減少重複性。這項工作旨在作為初學者和經驗豐富的開發人員的橋樑，讓他們具備在 AI 驅動專案中應用 OOP 方法論的必要知識，最終促進更強大且可維護的系統開發。</paragraph>

##### **Scaling Optimal LR Across Token Horizon**
2409.19913v1 by Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, Xia Song

State-of-the-art LLMs are powered by scaling -- scaling model size, dataset
size and cluster size. It is economically infeasible to extensively tune
hyperparameter for the largest runs. Instead, approximately optimal
hyperparameters must be inferred or \textit{transferred} from smaller
experiments. Hyperparameter transfer across model sizes has been studied in
Yang et al. However, hyperparameter transfer across dataset size -- or token
horizon -- has not been studied yet. To remedy this we conduct a large scale
empirical study on how optimal learning rate (LR) depends on token horizon in
LLM training. We first demonstrate that the optimal LR changes significantly
with token horizon -- longer training necessitates smaller LR. Secondly we
demonstrate the the optimal LR follows a scaling law, and that the optimal LR
for longer horizons can be accurately estimated from shorter horizons via our
scaling laws. We also provide a rule-of-thumb for transferring LR across token
horizons with zero overhead over current practices. Lastly we provide evidence
that LLama-1 used too high LR, and estimate the performance hit from this. We
thus argue that hyperparameter transfer across data size is an important and
overlooked component of LLM training.

摘要：最先进的 LLM 由以下方式提供支持：扩展模型大小、数据集大小和集群大小。广泛调整超参数以进行最大运行在经济上不可行。相反，必须从较小的实验中推断或“传输”近似最优超参数。Yang 等人研究了跨模型大小的超参数传输。然而，尚未研究跨数据集大小（或令牌范围）的超参数传输。为了解决这个问题，我们对最优学习率 (LR) 如何依赖 LLM 训练中的令牌范围进行了大规模实证研究。我们首先证明最优 LR 随令牌范围而显着变化——更长的训练需要更小的 LR。其次，我们证明最优 LR 遵循缩放定律，并且可以通过我们的缩放定律从较短的范围准确估计较长范围的最优 LR。我们还提供了一个经验法则，用于在令牌范围之间传输 LR，而无需对当前实践进行任何开销。最后，我们提供了证据表明 LLama-1 使用了过高的 LR，并估计了由此造成的性能损失。因此，我们认为跨数据大小的超参数传输是 LLM 训练的一个重要且被忽视的组成部分。

##### **UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional Summarization Evaluation for LLMs**
2409.19898v2 by Yuho Lee, Taewon Yun, Jason Cai, Hang Su, Hwanjun Song

Existing benchmarks for summarization quality evaluation often lack diverse
input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and
struggle with subjective and coarse-grained annotation schemes. To address
these shortcomings, we create UniSumEval benchmark, which extends the range of
input context (e.g., domain, length) and provides fine-grained,
multi-dimensional annotations. We use AI assistance in data creation,
identifying potentially hallucinogenic input texts, and also helping human
annotators reduce the difficulty of fine-grained annotation tasks. With
UniSumEval, we benchmark nine latest language models as summarizers, offering
insights into their performance across varying input contexts and evaluation
dimensions. Furthermore, we conduct a thorough comparison of SOTA automated
summary evaluators. Our benchmark data will be available at
https://github.com/DISL-Lab/UniSumEval-v1.0.

摘要：現有的摘要品質評估基準通常缺乏多樣化的輸入情境，專注於狹義的維度（例如忠實度），並與主觀且粗略的註解方案奮戰。為了解決這些缺點，我們建立了 UniSumEval 基準，它擴展了輸入內容的範圍（例如，領域、長度），並提供了細緻、多維度的註解。我們在資料建立中使用 AI 協助，識別潛在的幻覺輸入文字，並協助人工註解者降低細緻註解任務的難度。有了 UniSumEval，我們將九個最新的語言模型作為摘要者進行基準測試，提供對它們在不同輸入內容和評估維度中表現的見解。此外，我們對 SOTA 自動摘要評估器進行了徹底的比較。我們的基準資料將於 https://github.com/DISL-Lab/UniSumEval-v1.0 提供。

##### **TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation**
2409.19894v2 by Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou

Code translation converts code from one programming language to another while
maintaining its original functionality, which is crucial for software
migration, system refactoring, and cross-platform development. Traditional
rule-based methods rely on manually-written rules, which can be time-consuming
and often result in less readable code. To overcome this, learning-based
methods have been developed, leveraging parallel data to train models for
automated code translation. More recently, the advance of Large Language Models
(LLMs) further boosts learning-based code translation. Although promising,
LLM-translated program still suffers from diverse quality issues (e.g., syntax
errors and semantic errors). In particular, it can be challenging for LLMs to
self-debug these errors when simply provided with the corresponding error
messages.
  In this work, we propose a novel LLM-based multi-agent system TRANSAGENT,
which enhances LLM-based code translation by fixing the syntax errors and
semantic errors with the synergy between four LLM-based agents, including
Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error
Fixer. The main insight of TRANSAGENT is to first localize the error code block
in the target program based on the execution alignment between the target and
source program, which can narrow down the fixing space and thus lower down the
fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark
from recent programming tasks to mitigate the potential data leakage issue. On
our benchmark, TRANSAGENT outperforms the latest LLM-based code translation
technique UniTrans in both translation effectiveness and efficiency;
additionally, our evaluation on different LLMs show the generalization of
TRANSAGENT and our ablation study shows the contribution of each agent.

摘要：<paragraph>程式碼翻譯將程式碼從一種程式語言轉換成另一種程式語言，同時維持其原始功能，這對軟體遷移、系統重構和跨平台開發至關重要。傳統的基於規則的方法依賴於手寫規則，這可能會耗時，且經常導致可讀性較差的程式碼。為了克服這個問題，已經開發出基於學習的方法，利用平行資料來訓練自動化程式碼翻譯的模型。最近，大型語言模型 (LLM) 的進步進一步提升了基於學習的程式碼翻譯。儘管有希望，但 LLM 翻譯的程式仍然存在各種品質問題（例如，語法錯誤和語義錯誤）。特別是，當僅提供對應的錯誤訊息時，LLM 可能難以自行除錯這些錯誤。
在這項工作中，我們提出了一個新穎的基於 LLM 的多代理系統 TRANSAGENT，它透過修正語法錯誤和語義錯誤來增強基於 LLM 的程式碼翻譯，並結合了四個基於 LLM 的代理，包括初始程式碼翻譯器、語法錯誤修正器、程式碼對齊器和語義錯誤修正器。TRANSAGENT 的主要見解是首先根據目標程式與原始程式碼之間的執行對齊來定位目標程式中的錯誤程式碼區塊，這可以縮小修正空間，從而降低修正難度。為了評估 TRANSAGENT，我們首先從最近的程式設計任務中建構一個新的基準，以減輕潛在的資料外洩問題。在我們的基準上，TRANSAGENT 在翻譯效果和效率方面都優於最新的基於 LLM 的程式碼翻譯技術 UniTrans；此外，我們對不同 LLM 的評估顯示了 TRANSAGENT 的泛化性，而我們的消融研究顯示了每個代理的貢獻。</paragraph>

##### **RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models**
2409.19886v1 by Shuhao Chen, Weisen Jiang, Baijiong Lin, James T. Kwok, Yu Zhang

Recent works show that assembling multiple off-the-shelf large language
models (LLMs) can harness their complementary abilities. To achieve this,
routing is a promising method, which learns a router to select the most
suitable LLM for each query. However, existing routing models are ineffective
when multiple LLMs perform well for a query. To address this problem, in this
paper, we propose a method called query-based Router by Dual Contrastive
learning (RouterDC). The RouterDC model consists of an encoder and LLM
embeddings, and we propose two contrastive learning losses to train the
RouterDC model. Experimental results show that RouterDC is effective in
assembling LLMs and largely outperforms individual top-performing LLMs as well
as existing routing methods on both in-distribution (+2.76\%) and
out-of-distribution (+1.90\%) tasks. Source code is available at
https://github.com/shuhao02/RouterDC.

摘要：最近的研究表明，组装多个现成的、大型语言模型 (LLM) 可以利用它们的互补能力。为了实现这一目标，路由是一种很有前景的方法，它学习路由器为每个查询选择最合适的 LLM。然而，当多个 LLM 对查询执行良好时，现有的路由模型无效。为了解决这个问题，在本文中，我们提出了一种基于查询的路由器方法，即双对比学习 (RouterDC)。RouterDC 模型由编码器和 LLM 嵌入组成，我们提出了两种对比学习损失来训练 RouterDC 模型。实验结果表明，RouterDC 在组装 LLM 方面是有效的，并且在分布内 (+2.76%) 和分布外 (+1.90%) 任务中都大大优于单独的顶级 LLM 以及现有的路由方法。源代码可在 https://github.com/shuhao02/RouterDC 获得。

##### **SWIM: Short-Window CNN Integrated with Mamba for EEG-Based Auditory Spatial Attention Decoding**
2409.19884v1 by Ziyang Zhang, Andrew Thwaites, Alexandra Woolgar, Brian Moore, Chao Zhang

In complex auditory environments, the human auditory system possesses the
remarkable ability to focus on a specific speaker while disregarding others. In
this study, a new model named SWIM, a short-window convolution neural network
(CNN) integrated with Mamba, is proposed for identifying the locus of auditory
attention (left or right) from electroencephalography (EEG) signals without
relying on speech envelopes. SWIM consists of two parts. The first is a
short-window CNN (SW$_\text{CNN}$), which acts as a short-term EEG feature
extractor and achieves a final accuracy of 84.9% in the leave-one-speaker-out
setup on the widely used KUL dataset. This improvement is due to the use of an
improved CNN structure, data augmentation, multitask training, and model
combination. The second part, Mamba, is a sequence model first applied to
auditory spatial attention decoding to leverage the long-term dependency from
previous SW$_\text{CNN}$ time steps. By joint training SW$_\text{CNN}$ and
Mamba, the proposed SWIM structure uses both short-term and long-term
information and achieves an accuracy of 86.2%, which reduces the classification
errors by a relative 31.0% compared to the previous state-of-the-art result.
The source code is available at https://github.com/windowso/SWIM-ASAD.

摘要：在複雜的聽覺環境中，人類聽覺系統擁有專注於特定說話者，同時忽視其他說話者的非凡能力。在這項研究中，提出了一個名為 SWIM 的新模型，一個與 Mamba 整合的短時窗卷積神經網路 (CNN)，用於從腦電圖 (EEG) 信號中識別聽覺注意力的位置 (左或右)，而不依賴語音包絡。SWIM 由兩部分組成。第一個是短時窗 CNN (SW$_\text{CNN}$)，它充當短期 EEG 特徵提取器，並在廣泛使用的 KUL 資料集上在留一說話者法設定中達到 84.9% 的最終準確度。這種改進是歸功於使用改進的 CNN 結構、資料擴充、多任務訓練和模型組合。第二部分 Mamba 是一個序列模型，首先應用於聽覺空間注意力解碼，以利用來自先前 SW$_\text{CNN}$ 時間步長的長期依賴性。透過聯合訓練 SW$_\text{CNN}$ 和 Mamba，提出的 SWIM 結構使用短期和長期資訊，並達到 86.2% 的準確度，與先前的最先進結果相比，將分類錯誤減少了相對的 31.0%。原始碼可在 https://github.com/windowso/SWIM-ASAD 取得。

##### **Contrastive Token Learning with Similarity Decay for Repetition Suppression in Machine Translation**
2409.19877v1 by Huangyu Dai, Ben Chen, Kaidi Chen, Ying Han, Zihan Liang, Wen Jiang

For crosslingual conversation and trade, Neural Machine Translation (NMT) is
pivotal yet faces persistent challenges with monotony and repetition in
generated content. Traditional solutions that rely on penalizing text
redundancy or token reoccurrence have shown limited efficacy, particularly for
lengthy article and e-commerce descriptions with inherent redundancy, even with
the advent of Large Language Models (LLMs). This paper investigates the
underlying causes of textual repetition through the lens of information
entropy, attributing the phenomenon to the elevated uncertainty within the
input text. To address this, a novel algorithm named Contrastive Token Learning
with Similarity Decay (CTSD) is introduced, which modulates the suppression of
tokens dynamically, informed by varying attention weights and inter-token
distances. Furthermore, an e-commerce dataset comprised of title texts of
online real items is compiled and released susceptible to hallucination
translations to benchmark the algorithm. Extensive evaluations demonstrate that
CTSD significantly outperforms existing approaches in precision and
generalizability. Additional online A/B testing underscores its practical
value, showing marked improvements in user engagement and conversion. Notably,
this method has been implemented with full traffic on eight multilingual sites
of alibaba.com, the largest B2B e-commerce platform in the world.

摘要：對於跨語言對話和貿易而言，神經機器翻譯 (NMT) 至關重要，但仍面臨著生成內容中單調和重複的持續挑戰。傳統的解決方案依賴於懲罰文字冗餘或標記重現，已顯示出有限的功效，特別是對於具有內在冗餘的冗長文章和電子商務描述，即使出現了大型語言模型 (LLM)。本文通過資訊熵的視角探討了文字重複的根本原因，將這種現象歸因於輸入文字中較高的不確定性。為了解決這個問題，提出了一種名為對比標記學習與相似性衰減 (CTSD) 的新演算法，它根據不同的注意力權重和標記間距離，動態地調節標記的抑制。此外，編制並發布了一個由線上真實商品標題文字組成的電子商務資料集，容易產生幻覺翻譯，以作為演算法的基準。廣泛的評估表明，CTSD 在精準度和概括性方面明顯優於現有方法。額外的線上 A/B 測試強調了它的實用價值，顯示出使用者參與度和轉換率的顯著提升。值得注意的是，此方法已在全球最大的 B2B 電子商務平台 alibaba.com 的八個多語言網站上全面實施。

##### **TSI: A Multi-View Representation Learning Approach for Time Series Forecasting**
2409.19871v1 by Wentao Gao, Ziqi Xu, Jiuyong Li, Lin Liu, Jixue Liu, Thuc Duy Le, Debo Cheng, Yanchang Zhao, Yun Chen

As the growing demand for long sequence time-series forecasting in real-world
applications, such as electricity consumption planning, the significance of
time series forecasting becomes increasingly crucial across various domains.
This is highlighted by recent advancements in representation learning within
the field. This study introduces a novel multi-view approach for time series
forecasting that innovatively integrates trend and seasonal representations
with an Independent Component Analysis (ICA)-based representation. Recognizing
the limitations of existing methods in representing complex and
high-dimensional time series data, this research addresses the challenge by
combining TS (trend and seasonality) and ICA (independent components)
perspectives. This approach offers a holistic understanding of time series
data, going beyond traditional models that often miss nuanced, nonlinear
relationships. The efficacy of TSI model is demonstrated through comprehensive
testing on various benchmark datasets, where it shows superior performance over
current state-of-the-art models, particularly in multivariate forecasting. This
method not only enhances the accuracy of forecasting but also contributes
significantly to the field by providing a more in-depth understanding of time
series data. The research which uses ICA for a view lays the groundwork for
further exploration and methodological advancements in time series forecasting,
opening new avenues for research and practical applications.

摘要：隨著在實際應用中對長序列時間序列預測的需求日益增長，例如電力消耗規劃，時間序列預測的重要性在各個領域變得越來越關鍵。這一點從最近在該領域內表示學習的進展中得到了強調。本研究引入了一種新的時間序列預測多視角方法，該方法創新地將趨勢和季節表示與基於獨立成分分析 (ICA) 的表示相結合。認識到現有方法在表示複雜和高維時間序列數據方面的局限性，本研究通過結合 TS（趨勢和季節性）和 ICA（獨立成分）觀點來應對這一挑戰。這種方法提供了對時間序列數據的整體理解，超越了傳統模型，後者經常會遺漏細微的非線性關係。TSI 模型的功效通過在各種基準數據集上的全面測試得到證明，在其中它展示了優於當前最先進模型的性能，特別是在多變量預測中。這種方法不僅提高了預測的準確性，而且通過提供對時間序列數據的更深入理解，還為該領域做出了重大貢獻。使用 ICA 作為視角的研究為時間序列預測中的進一步探索和方法學進步奠定了基礎，為研究和實際應用開闢了新的途徑。

##### **The Construction of Instruction-tuned LLMs for Finance without Instruction Data Using Continual Pretraining and Model Merging**
2409.19854v1 by Masanori Hirano, Kentaro Imajo

This paper proposes a novel method for constructing instruction-tuned large
language models (LLMs) for finance without instruction data. Traditionally,
developing such domain-specific LLMs has been resource-intensive, requiring a
large dataset and significant computational power for continual pretraining and
instruction tuning. Our study proposes a simpler approach that combines
domain-specific continual pretraining with model merging. Given that
general-purpose pretrained LLMs and their instruction-tuned LLMs are often
publicly available, they can be leveraged to obtain the necessary instruction
task vector. By merging this with a domain-specific pretrained vector, we can
effectively create instruction-tuned LLMs for finance without additional
instruction data. Our process involves two steps: first, we perform continual
pretraining on financial data; second, we merge the instruction-tuned vector
with the domain-specific pretrained vector. Our experiments demonstrate the
successful construction of instruction-tuned LLMs for finance. One major
advantage of our method is that the instruction-tuned and domain-specific
pretrained vectors are nearly independent. This independence makes our approach
highly effective. The Japanese financial instruction-tuned LLMs we developed in
this study are available at
https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge.

摘要：本文提出了一种新方法，用于在没有指令数据的情况下构建针对金融领域的指令调整大型语言模型 (LLM)。传统上，开发此类特定领域的 LLM 需要大量资源，需要一个大型数据集和大量的计算能力来进行持续预训练和指令调整。我们的研究提出了一种更简单的方法，该方法将特定领域的持续预训练与模型合并相结合。鉴于通用预训练 LLM 及其指令调整的 LLM 通常是公开可用的，因此可以利用它们来获取必要的指令任务向量。通过将其与特定领域的预训练向量合并，我们可以有效地为金融领域创建指令调整的 LLM，而无需额外的指令数据。我们的流程包括两个步骤：首先，我们对金融数据执行持续预训练；其次，我们将指令调整向量与特定领域的预训练向量合并。我们的实验表明，成功构建了针对金融领域的指令调整 LLM。我们方法的一个主要优点是，指令调整的向量和特定领域的预训练向量几乎是独立的。这种独立性使我们的方法非常有效。我们在本研究中开发的日语金融指令调整 LLM 可在 https://huggingface.co/pfnet/nekomata-14b-pfn-qfin-inst-merge 获得。

##### **ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities**
2409.19839v1 by Ezra Karger, Houtan Bastani, Chen Yueh-Han, Zachary Jacobs, Danny Halawi, Fred Zhang, Philip E. Tetlock

Forecasts of future events are essential inputs into informed
decision-making. Machine learning (ML) systems have the potential to deliver
forecasts at scale, but there is no framework for evaluating the accuracy of ML
systems on a standardized set of forecasting questions. To address this gap, we
introduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML
systems on an automatically generated and regularly updated set of 1,000
forecasting questions. To avoid any possibility of data leakage, ForecastBench
is comprised solely of questions about future events that have no known answer
at the time of submission. We quantify the ability of current ML systems by
collecting forecasts from expert (human) forecasters, the general public, and
LLMs on a random subset of questions from the benchmark (N = 200). While LLMs
have achieved super-human performance on many benchmarks, they perform less
well here: expert forecasters outperform the top-performing LLM (p-values <=
0.01). We display system and human scores in a public leaderboard at
www.forecastbench.org.

摘要：未來事件預測是明智決策制定中的重要輸入。機器學習 (ML) 系統有潛力大規模提供預測，但沒有框架可以在標準化的預測問題集上評估 ML 系統的準確性。為了解決這個差距，我們引入了 ForecastBench：一個動態基準，它在自動生成並定期更新的 1,000 個預測問題集上評估 ML 系統的準確性。為了避免任何資料外洩的可能性，ForecastBench 僅包含關於未來事件的問題，這些問題在提交時沒有已知的答案。我們透過從專家（人類）預測員、一般大眾和 LLM 中收集預測，在基準中的隨機問題子集中（N = 200）量化當前 ML 系統的能力。雖然 LLM 在許多基準上都達到了超人類的表現，但它們在此表現不佳：專家預測員優於表現最佳的 LLM（p 值 <= 0.01）。我們在 www.forecastbench.org 上的公開排行榜中顯示系統和人類分數。

##### **Counterfactual Evaluation of Ads Ranking Models through Domain Adaptation**
2409.19824v1 by Mohamed A. Radwan, Himaghna Bhattacharjee, Quinn Lanners, Jiasheng Zhang, Serkan Karakulak, Houssam Nassif, Murat Ali Bayir

We propose a domain-adapted reward model that works alongside an Offline A/B
testing system for evaluating ranking models. This approach effectively
measures reward for ranking model changes in large-scale Ads recommender
systems, where model-free methods like IPS are not feasible. Our experiments
demonstrate that the proposed technique outperforms both the vanilla IPS method
and approaches using non-generalized reward models.

摘要：我們提出一個領域適應獎勵模型，與離線 A/B 測試系統一起使用，用於評估排名模型。此方法有效地衡量了在大型廣告推薦系統中排名模型變更的獎勵，其中像 IPS 等無模型方法不可行。我們的實驗表明，所提出的技術優於香草 IPS 方法和使用非廣義獎勵模型的方法。

##### **Calibrating Language Models with Adaptive Temperature Scaling**
2409.19817v1 by Johnathan Xie, Annie S. Chen, Yoonho Lee, Eric Mitchell, Chelsea Finn

The effectiveness of large language models (LLMs) is not only measured by
their ability to generate accurate outputs but also by their calibration-how
well their confidence scores reflect the probability of their outputs being
correct. While unsupervised pre-training has been shown to yield LLMs with
well-calibrated conditional probabilities, recent studies have shown that after
fine-tuning with reinforcement learning from human feedback (RLHF), the
calibration of these models degrades significantly. In this work, we introduce
Adaptive Temperature Scaling (ATS), a post-hoc calibration method that predicts
a temperature scaling parameter for each token prediction. The predicted
temperature values adapt based on token-level features and are fit over a
standard supervised fine-tuning (SFT) dataset. The adaptive nature of ATS
addresses the varying degrees of calibration shift that can occur after RLHF
fine-tuning. ATS improves calibration by over 10-50% across three downstream
natural language evaluation benchmarks compared to prior calibration methods
and does not impede performance improvements from RLHF.

摘要：大型語言模型 (LLM) 的效能不僅取決於它們產生準確輸出的能力，還取決於它們的校準能力，也就是它們的信心分數能多準確地反映其輸出的正確性。雖然已證實無監督預訓練可產生具有良好校準條件機率的 LLM，但最近的研究顯示，在經過人類回饋強化學習 (RLHF) 微調後，這些模型的校準會顯著下降。在這項研究中，我們引入了自適應溫度縮放 (ATS)，這是一種事後校準方法，可預測每個權杖預測的溫度縮放參數。預測的溫度值會根據權杖層級特徵進行調整，並針對標準監督式微調 (SFT) 資料集進行擬合。ATS 的自適應特性可處理 RLHF 微調後可能發生的校準轉移的程度差異。與先前的校準方法相比，ATS 可將三個下游自然語言評估基準的校準改善超過 10-50%，且不會阻礙 RLHF 的效能提升。

##### **Grounded Curriculum Learning**
2409.19816v1 by Linji Wang, Zifan Xu, Peter Stone, Xuesu Xiao

The high cost of real-world data for robotics Reinforcement Learning (RL)
leads to the wide usage of simulators. Despite extensive work on building
better dynamics models for simulators to match with the real world, there is
another, often-overlooked mismatch between simulations and the real world,
namely the distribution of available training tasks. Such a mismatch is further
exacerbated by existing curriculum learning techniques, which automatically
vary the simulation task distribution without considering its relevance to the
real world. Considering these challenges, we posit that curriculum learning for
robotics RL needs to be grounded in real-world task distributions. To this end,
we propose Grounded Curriculum Learning (GCL), which aligns the simulated task
distribution in the curriculum with the real world, as well as explicitly
considers what tasks have been given to the robot and how the robot has
performed in the past. We validate GCL using the BARN dataset on complex
navigation tasks, achieving a 6.8% and 6.5% higher success rate compared to a
state-of-the-art CL method and a curriculum designed by human experts,
respectively. These results show that GCL can enhance learning efficiency and
navigation performance by grounding the simulation task distribution in the
real world within an adaptive curriculum.

摘要：機器人強化學習 (RL) 中真實世界數據的高昂成本導致廣泛使用模擬器。儘管在建立更好的動態模型以使模擬器與真實世界相匹配方面做了大量工作，但模擬與真實世界之間還存在另一個經常被忽視的不匹配，即可用訓練任務的分布。現有的課程學習技術進一步加劇了這種不匹配，這些技術會自動改變模擬任務分佈，而不會考慮其與真實世界的相關性。考慮到這些挑戰，我們假設機器人 RL 的課程學習需要以真實世界的任務分佈為基礎。為此，我們提出了基於真實世界的課程學習 (GCL)，它將課程中的模擬任務分佈與真實世界保持一致，並明確考慮了機器人已獲得哪些任務以及機器人在過去的表現。我們使用 BARN 資料集驗證了 GCL 在複雜導航任務中，與最先進的 CL 方法和由人類專家設計的課程相比，分別實現了 6.8% 和 6.5% 的更高成功率。這些結果表明，GCL 能夠通過在自適應課程中將模擬任務分佈建立在真實世界中來提高學習效率和導航性能。

##### **Transforming Hidden States into Binary Semantic Features**
2409.19813v1 by Tomáš Musil, David Mareček

Large language models follow a lineage of many NLP applications that were
directly inspired by distributional semantics, but do not seem to be closely
related to it anymore. In this paper, we propose to employ the distributional
theory of meaning once again. Using Independent Component Analysis to overcome
some of its challenging aspects, we show that large language models represent
semantic features in their hidden states.

摘要：大型語言模型遵循許多 NLP 應用程式的譜系，這些應用程式直接受到分佈語義的啟發，但似乎不再與其密切相關。在本文中，我們建議再次採用分佈式的意義理論。我們使用獨立成分分析來克服其一些具有挑戰性的方面，我們表明大型語言模型在其隱藏狀態中表示語義特徵。

