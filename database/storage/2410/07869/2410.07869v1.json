{"2410.07869": {"publish_time": "2024-10-10", "title": "Benchmarking Agentic Workflow Generation", "paper_summary": "Large Language Models (LLMs), with their exceptional ability to handle a wide\nrange of tasks, have driven significant advancements in tackling reasoning and\nplanning tasks, wherein decomposing complex problems into executable workflows\nis a crucial step in this process. Existing workflow evaluation frameworks\neither focus solely on holistic performance or suffer from limitations such as\nrestricted scenario coverage, simplistic workflow structures, and lax\nevaluation standards. To this end, we introduce WorFBench, a unified workflow\ngeneration benchmark with multi-faceted scenarios and intricate graph workflow\nstructures. Additionally, we present WorFEval, a systemic evaluation protocol\nutilizing subsequence and subgraph matching algorithms to accurately quantify\nthe LLM agent's workflow generation capabilities. Through comprehensive\nevaluations across different types of LLMs, we discover distinct gaps between\nthe sequence planning capabilities and graph planning capabilities of LLM\nagents, with even GPT-4 exhibiting a gap of around 15%. We also train two\nopen-source models and evaluate their generalization abilities on held-out\ntasks. Furthermore, we observe that the generated workflows can enhance\ndownstream tasks, enabling them to achieve superior performance with less time\nduring inference. Code and dataset will be available at\nhttps://github.com/zjunlp/WorFBench.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u64c1\u6709\u8655\u7406\u5404\u7a2e\u4efb\u52d9\u7684\u975e\u51e1\u80fd\u529b\uff0c\u63a8\u52d5\u4e86\u89e3\u6c7a\u63a8\u7406\u548c\u898f\u5283\u4efb\u52d9\u7684\u986f\u8457\u9032\u5c55\uff0c\u5176\u4e2d\u5c07\u8907\u96dc\u554f\u984c\u5206\u89e3\u70ba\u53ef\u57f7\u884c\u5de5\u4f5c\u6d41\u7a0b\u662f\u6b64\u904e\u7a0b\u4e2d\u81f3\u95dc\u91cd\u8981\u7684\u4e00\u6b65\u3002\u73fe\u6709\u7684\u5de5\u4f5c\u6d41\u7a0b\u8a55\u4f30\u6846\u67b6\u53ea\u5c08\u6ce8\u65bc\u6574\u9ad4\u6548\u80fd\uff0c\u6216\u53d7\u5230\u60c5\u5883\u6db5\u84cb\u7bc4\u570d\u53d7\u9650\u3001\u5de5\u4f5c\u6d41\u7a0b\u7d50\u69cb\u7c21\u5316\u548c\u8a55\u4f30\u6a19\u6e96\u5bec\u9b06\u7b49\u9650\u5236\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 WorFBench\uff0c\u4e00\u500b\u7d71\u4e00\u7684\u5de5\u4f5c\u6d41\u7a0b\u751f\u6210\u57fa\u6e96\uff0c\u5177\u6709\u591a\u65b9\u9762\u7684\u5834\u666f\u548c\u8907\u96dc\u7684\u5716\u5f62\u5de5\u4f5c\u6d41\u7a0b\u7d50\u69cb\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e86 WorFEval\uff0c\u4e00\u500b\u5229\u7528\u5b50\u5e8f\u5217\u548c\u5b50\u5716\u5339\u914d\u6f14\u7b97\u6cd5\u4f86\u6e96\u78ba\u91cf\u5316 LLM \u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u751f\u6210\u80fd\u529b\u7684\u7cfb\u7d71\u6027\u8a55\u4f30\u5354\u5b9a\u3002\u900f\u904e\u5c0d\u4e0d\u540c\u985e\u578b LLM \u7684\u5168\u9762\u8a55\u4f30\uff0c\u6211\u5011\u767c\u73fe LLM \u4ee3\u7406\u7684\u5e8f\u5217\u898f\u5283\u80fd\u529b\u548c\u5716\u5f62\u898f\u5283\u80fd\u529b\u4e4b\u9593\u5b58\u5728\u660e\u986f\u7684\u5dee\u8ddd\uff0c\u5373\u4f7f\u662f GPT-4 \u4e5f\u8868\u73fe\u51fa\u7d04 15% \u7684\u5dee\u8ddd\u3002\u6211\u5011\u9084\u8a13\u7df4\u4e86\u5169\u500b\u958b\u6e90\u6a21\u578b\uff0c\u4e26\u8a55\u4f30\u4e86\u5b83\u5011\u5728\u4fdd\u7559\u4efb\u52d9\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u751f\u6210\u7684\u7684\u5de5\u4f5c\u6d41\u7a0b\u53ef\u4ee5\u589e\u5f37\u4e0b\u6e38\u4efb\u52d9\uff0c\u8b93\u5b83\u5011\u5728\u63a8\u7406\u671f\u9593\u4ee5\u66f4\u5c11\u7684\u6642\u9593\u7372\u5f97\u66f4\u597d\u7684\u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u5c07\u5728 https://github.com/zjunlp/WorFBench \u4e0a\u63d0\u4f9b\u3002", "author": "Shuofei Qiao et.al.", "authors": "Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen", "id": "2410.07869v1", "paper_url": "http://arxiv.org/abs/2410.07869v1", "repo": "null"}}