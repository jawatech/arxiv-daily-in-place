{"2406.05113": {"publish_time": "2024-06-07", "title": "LLavaGuard: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment", "paper_summary": "We introduce LlavaGuard, a family of VLM-based safeguard models, offering a\nversatile framework for evaluating the safety compliance of visual content.\nSpecifically, we designed LlavaGuard for dataset annotation and generative\nmodel safeguarding. To this end, we collected and annotated a high-quality\nvisual dataset incorporating a broad safety taxonomy, which we use to tune VLMs\non context-aware safety risks. As a key innovation, LlavaGuard's new responses\ncontain comprehensive information, including a safety rating, the violated\nsafety categories, and an in-depth rationale. Further, our introduced\ncustomizable taxonomy categories enable the context-specific alignment of\nLlavaGuard to various scenarios. Our experiments highlight the capabilities of\nLlavaGuard in complex and real-world applications. We provide checkpoints\nranging from 7B to 34B parameters demonstrating state-of-the-art performance,\nwith even the smallest models outperforming baselines like GPT-4. We make our\ndataset and model weights publicly available and invite further research to\naddress the diverse needs of communities and contexts.", "paper_summary_zh": "\u6211\u5011\u4ecb\u7d39 LlavaGuard\uff0c\u4e00\u500b\u57fa\u65bc VLM \u7684\u4fdd\u969c\u6a21\u578b\u5bb6\u65cf\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u591a\u529f\u80fd\u6846\u67b6\uff0c\u7528\u65bc\u8a55\u4f30\u8996\u89ba\u5167\u5bb9\u7684\u5b89\u5168\u6027\u5408\u898f\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u8a2d\u8a08 LlavaGuard \u7528\u65bc\u8cc7\u6599\u96c6\u8a3b\u89e3\u548c\u751f\u6210\u6a21\u578b\u4fdd\u969c\u3002\u70ba\u6b64\uff0c\u6211\u5011\u6536\u96c6\u4e26\u8a3b\u89e3\u4e86\u4e00\u500b\u5305\u542b\u5ee3\u6cdb\u5b89\u5168\u5206\u985e\u6cd5\u7684\u9ad8\u54c1\u8cea\u8996\u89ba\u8cc7\u6599\u96c6\uff0c\u6211\u5011\u4f7f\u7528\u5b83\u4f86\u8abf\u6574 VLM \u4ee5\u61c9\u5c0d\u8207\u60c5\u5883\u76f8\u95dc\u7684\u5b89\u5168\u98a8\u96aa\u3002\u4f5c\u70ba\u4e00\u9805\u95dc\u9375\u5275\u65b0\uff0cLlavaGuard \u7684\u65b0\u56de\u61c9\u5305\u542b\u7d9c\u5408\u8cc7\u8a0a\uff0c\u5305\u62ec\u5b89\u5168\u8a55\u7d1a\u3001\u9055\u898f\u7684\u5b89\u5168\u985e\u5225\u548c\u6df1\u5165\u7684\u4f9d\u64da\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u7684\u53ef\u81ea\u8a02\u5206\u985e\u6cd5\u985e\u5225\u80fd\u8b93 LlavaGuard \u8207\u5404\u7a2e\u60c5\u5883\u9032\u884c\u60c5\u5883\u7279\u5b9a\u7684\u6bd4\u5c0d\u3002\u6211\u5011\u7684\u5be6\u9a57\u7a81\u986f\u4e86 LlavaGuard \u5728\u8907\u96dc\u548c\u771f\u5be6\u4e16\u754c\u61c9\u7528\u4e2d\u7684\u80fd\u529b\u3002\u6211\u5011\u63d0\u4f9b\u5f9e 7B \u5230 34B \u53c3\u6578\u7684\u6aa2\u67e5\u9ede\uff0c\u5c55\u793a\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u5373\u4f7f\u662f\u6700\u5c0f\u7684\u6a21\u578b\u4e5f\u512a\u65bc GPT-4 \u7b49\u57fa\u6e96\u3002\u6211\u5011\u516c\u958b\u6211\u5011\u7684\u8cc7\u6599\u96c6\u548c\u6a21\u578b\u6b0a\u91cd\uff0c\u4e26\u9080\u8acb\u9032\u4e00\u6b65\u7684\u7814\u7a76\uff0c\u4ee5\u6eff\u8db3\u793e\u7fa4\u548c\u60c5\u5883\u7684\u5404\u7a2e\u9700\u6c42\u3002", "author": "Lukas Helff et.al.", "authors": "Lukas Helff, Felix Friedrich, Manuel Brack, Kristian Kersting, Patrick Schramowski", "id": "2406.05113v1", "paper_url": "http://arxiv.org/abs/2406.05113v1", "repo": "null"}}