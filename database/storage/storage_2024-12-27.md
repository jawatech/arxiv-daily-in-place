# arxiv-daily
 Automated deployment @ 2024-12-27 20:26:59 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-24**|**Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**|Derong Xu Xinhang Li et.al.|[2412.18537v1](http://arxiv.org/abs/2412.18537v1)|null|
|**2024-12-24**|**Is Large Language Model Good at Triple Set Prediction? An Empirical Study**|Yuan Yuan et.al.|[2412.18443v1](http://arxiv.org/abs/2412.18443v1)|null|
|**2024-12-24**|**Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**|Xuefeng Jiang et.al.|[2412.18260v1](http://arxiv.org/abs/2412.18260v1)|[link](https://github.com/sakirinn/llm4cvd)|
|**2024-12-24**|**An Automatic Graph Construction Framework based on Large Language Models for Recommendation**|Rong Shan et.al.|[2412.18241v1](http://arxiv.org/abs/2412.18241v1)|[link](https://github.com/lavieenrose365/autograph)|
|**2024-12-23**|**CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**|Ruibo Tu et.al.|[2412.17970v1](http://arxiv.org/abs/2412.17970v1)|[link](https://github.com/turuibo/cautabbench)|
|**2024-12-23**|**Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**|Ge Zhang et.al.|[2412.17963v1](http://arxiv.org/abs/2412.17963v1)|null|
|**2024-12-23**|**ResearchTown: Simulator of Human Research Community**|Haofei Yu et.al.|[2412.17767v1](http://arxiv.org/abs/2412.17767v1)|[link](https://github.com/ulab-uiuc/research-town)|
|**2024-12-23**|**RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**|Rishiraj Saha Roy et.al.|[2412.17690v2](http://arxiv.org/abs/2412.17690v2)|null|
|**2024-12-23**|**A Dual-Perspective Metaphor Detection Framework Using Large Language Models**|Yujie Lin et.al.|[2412.17332v1](http://arxiv.org/abs/2412.17332v1)|[link](https://github.com/deeplearnxmu/dmd)|
|**2024-12-22**|**GraphAgent: Agentic Graph Language Assistant**|Yuhao Yang et.al.|[2412.17029v1](http://arxiv.org/abs/2412.17029v1)|null|
|**2024-12-22**|**Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**|Bohan Jin et.al.|[2412.16922v1](http://arxiv.org/abs/2412.16922v1)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v1](http://arxiv.org/abs/2412.16833v1)|null|
|**2024-12-21**|**Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**|Christophe Debruyne et.al.|[2412.16766v1](http://arxiv.org/abs/2412.16766v1)|null|
|**2024-12-21**|**Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**|Chao-Chi Chen et.al.|[2412.16533v1](http://arxiv.org/abs/2412.16533v1)|null|
|**2024-12-21**|**Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**|Junyi Ye et.al.|[2412.16420v1](http://arxiv.org/abs/2412.16420v1)|[link](https://github.com/junyiye/textflow)|
|**2024-12-20**|**HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**|Meng-Chieh Lee et.al.|[2412.16311v1](http://arxiv.org/abs/2412.16311v1)|null|
|**2024-12-20**|**Logical Consistency of Large Language Models in Fact-checking**|Bishwamittra Ghosh et.al.|[2412.16100v1](http://arxiv.org/abs/2412.16100v1)|null|
|**2024-12-20**|**GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**|Heming Zhang et.al.|[2412.15790v1](http://arxiv.org/abs/2412.15790v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-19**|**SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**|Aakash Mahalingam et.al.|[2412.15443v1](http://arxiv.org/abs/2412.15443v1)|null|
|**2024-12-19**|**Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**|Imed Keraghel et.al.|[2412.14867v1](http://arxiv.org/abs/2412.14867v1)|null|
|**2024-12-19**|**Answer Set Networks: Casting Answer Set Programming into Deep Learning**|Arseny Skryagin et.al.|[2412.14814v1](http://arxiv.org/abs/2412.14814v1)|null|
|**2024-12-19**|**IOHunter: Graph Foundation Model to Uncover Online Information Operations**|Marco Minici et.al.|[2412.14663v1](http://arxiv.org/abs/2412.14663v1)|[link](https://github.com/mminici/socgfm)|
|**2024-12-19**|**GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**|Saumya Saxena et.al.|[2412.14480v1](http://arxiv.org/abs/2412.14480v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**|Stefano M. Nicoletti et.al.|[2412.13964v1](http://arxiv.org/abs/2412.13964v1)|null|
|**2024-12-18**|**Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question Answering**|Yifan Lu et.al.|[2412.13782v1](http://arxiv.org/abs/2412.13782v1)|null|
|**2024-12-18**|**Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**|Zheng Hu et.al.|[2412.13544v1](http://arxiv.org/abs/2412.13544v1)|[link](https://github.com/laowangzi/cikgrec)|
|**2024-12-18**|**Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**|Yingjie Zhu et.al.|[2412.13540v1](http://arxiv.org/abs/2412.13540v1)|[link](https://github.com/aaandy-zhu/vgcure)|
|**2024-12-18**|**Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**|Imam Nur Bani Yusuf et.al.|[2412.13467v1](http://arxiv.org/abs/2412.13467v1)|[link](https://github.com/imamnurby/transducer-tuning)|
|**2024-12-17**|**Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**|Konstantin Zaitsev et.al.|[2412.13283v1](http://arxiv.org/abs/2412.13283v1)|null|
|**2024-12-17**|**SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**|Yuzheng Cai et.al.|[2412.15272v1](http://arxiv.org/abs/2412.15272v1)|[link](https://github.com/YZ-Cai/SimGRAG)|
|**2024-12-17**|**Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**|Ziqi Qiu et.al.|[2412.12808v2](http://arxiv.org/abs/2412.12808v2)|null|
|**2024-12-17**|**LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**|Mufan Xu et.al.|[2412.12643v1](http://arxiv.org/abs/2412.12643v1)|null|
|**2024-12-17**|**SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**|Aman Tiwari et.al.|[2412.12612v1](http://arxiv.org/abs/2412.12612v1)|null|
|**2024-12-17**|**Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph**|Yibo Zhao et.al.|[2412.15268v2](http://arxiv.org/abs/2412.15268v2)|null|
|**2024-12-17**|**Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**|Xunkai Li et.al.|[2412.12456v1](http://arxiv.org/abs/2412.12456v1)|null|
|**2024-12-16**|**Graph-Guided Textual Explanation Generation Framework**|Shuzhou Yuan et.al.|[2412.12318v1](http://arxiv.org/abs/2412.12318v1)|null|
|**2024-12-16**|**Cost-Effective Label-free Node Classification with LLMs**|Taiyan Zhang et.al.|[2412.11983v1](http://arxiv.org/abs/2412.11983v1)|null|
|**2024-12-16**|**SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**|Tao Meng et.al.|[2412.11652v1](http://arxiv.org/abs/2412.11652v1)|null|
|**2024-12-16**|**EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**|Nuowei Liu et.al.|[2412.11618v1](http://arxiv.org/abs/2412.11618v1)|null|
|**2024-12-16**|**Embodied CoT Distillation From LLM To Off-the-shelf Agents**|Wonje Choi et.al.|[2412.11499v1](http://arxiv.org/abs/2412.11499v1)|null|
|**2024-12-16**|**Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**|Edward Kim et.al.|[2412.15256v1](http://arxiv.org/abs/2412.15256v1)|null|
|**2024-12-16**|**How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach**|Abdulrahman Althobaiti et.al.|[2412.11387v1](http://arxiv.org/abs/2412.11387v1)|null|
|**2024-12-15**|**Embracing Large Language Models in Traffic Flow Forecasting**|Yusheng Zhao et.al.|[2412.12201v1](http://arxiv.org/abs/2412.12201v1)|null|
|**2024-12-15**|**SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**|Hang Zhang et.al.|[2412.11026v1](http://arxiv.org/abs/2412.11026v1)|null|
|**2024-12-14**|**MedG-KRP: Medical Graph Knowledge Representation Probing**|Gabriel R. Rosenbaum et.al.|[2412.10982v2](http://arxiv.org/abs/2412.10982v2)|null|
|**2024-12-14**|**Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data**|Xue Wu et.al.|[2412.10654v1](http://arxiv.org/abs/2412.10654v1)|null|
|**2024-12-13**|**WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models**|Runsheng "Anson" Huang et.al.|[2412.10582v2](http://arxiv.org/abs/2412.10582v2)|null|
|**2024-12-13**|**A Decade of Deep Learning: A Survey on The Magnificent Seven**|Dilshod Azizov et.al.|[2412.16188v1](http://arxiv.org/abs/2412.16188v1)|null|
|**2024-12-13**|**Can LLMs Convert Graphs to Text-Attributed Graphs?**|Zehong Wang et.al.|[2412.10136v1](http://arxiv.org/abs/2412.10136v1)|[link](https://github.com/zehong-wang/tans)|
|**2024-12-13**|**Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**|George Arthur Baker et.al.|[2412.10079v1](http://arxiv.org/abs/2412.10079v1)|[link](https://github.com/spongeorge/long-context-multihop)|
|**2024-12-13**|**Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**|Yanxu Mao et.al.|[2412.09922v1](http://arxiv.org/abs/2412.09922v1)|null|
|**2024-12-12**|**MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media**|Muhammad Arslan Manzoor et.al.|[2412.10467v1](http://arxiv.org/abs/2412.10467v1)|[link](https://github.com/marslanm/mgm_code)|
|**2024-12-12**|**Uncommon Belief in Rationality**|Qi Shi et.al.|[2412.09407v1](http://arxiv.org/abs/2412.09407v1)|null|
|**2024-12-12**|**Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**|Sai Bhargav Rongali et.al.|[2412.09230v1](http://arxiv.org/abs/2412.09230v1)|null|
|**2024-12-12**|**Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**|Ben Liu et.al.|[2412.09094v1](http://arxiv.org/abs/2412.09094v1)|[link](https://github.com/lb0828/ftg)|
|**2024-12-12**|**Neural Interactive Proofs**|Lewis Hammond et.al.|[2412.08897v1](http://arxiv.org/abs/2412.08897v1)|null|
|**2024-12-12**|**A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**|Jiankang Wang et.al.|[2412.08864v1](http://arxiv.org/abs/2412.08864v1)|null|
|**2024-12-11**|**In-Context Learning with Topological Information for Knowledge Graph Completion**|Udari Madhushani Sehwag et.al.|[2412.08742v1](http://arxiv.org/abs/2412.08742v1)|null|
|**2024-12-11**|**VEL: A Formally Verified Reasoner for OWL2 EL Profile**|Atalay Mert Ileri et.al.|[2412.08739v1](http://arxiv.org/abs/2412.08739v1)|null|
|**2024-12-11**|**From communities to interpretable network and word embedding: an unified approach**|Thibault Prouteau et.al.|[2412.08187v1](http://arxiv.org/abs/2412.08187v1)|null|
|**2024-12-11**|**Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**|Zihao Li et.al.|[2412.08174v2](http://arxiv.org/abs/2412.08174v2)|null|
|**2024-12-11**|**GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction**|Rongzheng Wang et.al.|[2412.12152v1](http://arxiv.org/abs/2412.12152v1)|null|
|**2024-12-11**|**NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language**|Yuanyuan Liang et.al.|[2412.10434v1](http://arxiv.org/abs/2412.10434v1)|[link](https://github.com/leonyuancode/stockgql)|
|**2024-12-11**|**Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**|Xin-Cheng Wen et.al.|[2412.08068v1](http://arxiv.org/abs/2412.08068v1)|[link](https://github.com/Xin-Cheng-Wen/RepoSPD)|
|**2024-12-11**|**Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**|Hang Gao et.al.|[2412.08038v2](http://arxiv.org/abs/2412.08038v2)|null|
|**2024-12-10**|**Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education**|Chengshuai Zhao et.al.|[2412.14191v1](http://arxiv.org/abs/2412.14191v1)|null|
|**2024-12-10**|**Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**|Marcos Da Silveira et.al.|[2412.09644v1](http://arxiv.org/abs/2412.09644v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v2](http://arxiv.org/abs/2412.07618v2)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**RAG-based Question Answering over Heterogeneous Data and Text**|Philipp Christmann et.al.|[2412.07420v1](http://arxiv.org/abs/2412.07420v1)|null|
|**2024-12-10**|**Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**|Ahan Bhatt et.al.|[2412.07412v1](http://arxiv.org/abs/2412.07412v1)|null|
|**2024-12-10**|**My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**|Jian Liao et.al.|[2412.07367v1](http://arxiv.org/abs/2412.07367v1)|null|
|**2024-12-09**|**ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**|Jieyu Zhang et.al.|[2412.07012v2](http://arxiv.org/abs/2412.07012v2)|[link](https://github.com/jieyuz2/provision)|
|**2024-12-09**|**Generative Adversarial Reviews: When LLMs Become the Critic**|Nicolas Bougie et.al.|[2412.10415v1](http://arxiv.org/abs/2412.10415v1)|null|
|**2024-12-09**|**A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**|Zhepeng Wang et.al.|[2412.06212v1](http://arxiv.org/abs/2412.06212v1)|null|
|**2024-12-08**|**Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**|Vijayalaxmi Sahadevan et.al.|[2412.05868v1](http://arxiv.org/abs/2412.05868v1)|null|
|**2024-12-08**|**A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**|Aniruddha Salve et.al.|[2412.05838v1](http://arxiv.org/abs/2412.05838v1)|null|
|**2024-12-08**|**Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**|Faqian Guan et.al.|[2412.05830v1](http://arxiv.org/abs/2412.05830v1)|null|
|**2024-12-08**|**GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**|Haotong Yang et.al.|[2412.06849v1](http://arxiv.org/abs/2412.06849v1)|null|
|**2024-12-08**|**M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**|Siyuan Guo et.al.|[2412.06847v1](http://arxiv.org/abs/2412.06847v1)|[link](https://github.com/bz99bz/m-3)|
|**2024-12-07**|**HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**|Zihao Zhu et.al.|[2412.05685v1](http://arxiv.org/abs/2412.05685v1)|null|
|**2024-12-07**|**KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**|Weijie Chen et.al.|[2412.05547v1](http://arxiv.org/abs/2412.05547v1)|null|
|**2024-12-07**|**LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System**|Emmanuel A. Olowe et.al.|[2412.16172v1](http://arxiv.org/abs/2412.16172v1)|null|
|**2024-12-06**|**Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**|Krishnasai Addala et.al.|[2412.05453v2](http://arxiv.org/abs/2412.05453v2)|null|
|**2024-12-06**|**A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**|Savini Kashmira et.al.|[2412.05447v1](http://arxiv.org/abs/2412.05447v1)|null|
|**2024-12-06**|**KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**|Peng Yu et.al.|[2412.04948v1](http://arxiv.org/abs/2412.04948v1)|null|
|**2024-12-06**|**HyperGraphOS: A Meta Operating System for Science and Engineering**|Antonello Ceravola et.al.|[2412.04923v1](http://arxiv.org/abs/2412.04923v1)|null|
|**2024-12-06**|**Transformers Struggle to Learn to Search**|Abulhair Saparov et.al.|[2412.04703v1](http://arxiv.org/abs/2412.04703v1)|null|
|**2024-12-06**|**LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**|Xuan Chen et.al.|[2412.04690v1](http://arxiv.org/abs/2412.04690v1)|null|
|**2024-12-05**|**Retrieval-Augmented Machine Translation with Unstructured Knowledge**|Jiaan Wang et.al.|[2412.04342v1](http://arxiv.org/abs/2412.04342v1)|[link](https://github.com/krystalan/RAGtrans)|
|**2024-12-05**|**GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering**|Cristian-George Crăciun et.al.|[2412.04119v2](http://arxiv.org/abs/2412.04119v2)|null|
|**2024-12-05**|**MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**|Yunhe Pang et.al.|[2412.03930v1](http://arxiv.org/abs/2412.03930v1)|[link](https://github.com/thudm/whoiswho)|
|**2024-12-05**|**How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**|Patrick Ocheja et.al.|[2412.03856v1](http://arxiv.org/abs/2412.03856v1)|null|
|**2024-12-05**|**Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**|Samuel Abedu et.al.|[2412.03815v1](http://arxiv.org/abs/2412.03815v1)|null|
|**2024-12-05**|**Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**|Jialin Wang et.al.|[2412.03801v1](http://arxiv.org/abs/2412.03801v1)|null|
|**2024-12-04**|**Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**|Ximing Wen et.al.|[2412.03761v1](http://arxiv.org/abs/2412.03761v1)|null|
|**2024-12-04**|**How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**|Wenyi Wang et.al.|[2412.03624v1](http://arxiv.org/abs/2412.03624v1)|[link](https://github.com/hishamalyahya/semantic_backprop)|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|

#### Abstracts
##### **Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**
2412.18537v1 by Derong Xu Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen

Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.

摘要：大型語言模型 (LLM) 展示了非凡的能力，但當它們被賦予複雜的知識推理任務時，卻會陷入幻覺和過時知識的困境，導致事實上不正確的輸出。先前的研究已嘗試通過從大規模知識圖譜 (KG) 中擷取事實知識來減輕這種情況，以協助 LLM 進行邏輯推理和答案預測。然而，這種方法通常會引入雜訊和無關資料，特別是在具有來自多個知識面向的廣泛背景的情況下。通過這種方式，LLM 注意力可能會被問題和相關資訊誤導。在我們的研究中，我們引入了自適應多面向檢索增強的知識圖譜 (Amar) 架構。此方法擷取包括實體、關係和子圖的知識，並將每個擷取的文字轉換為提示嵌入。Amar 架構包含兩個關鍵子元件：1) 一個自我對齊模組，它對齊實體、關係和子圖之間的共性以增強擷取的文字，從而減少雜訊干擾；2) 一個相關性閘門模組，它採用軟閘門來學習問題與多面向擷取資料之間的相关性分數，以確定哪些資訊應被用來增強 LLM 的輸出，甚至完全過濾掉。我們的模型在兩個常見的資料集 WebQSP 和 CWQ 上達到了最先進的效能，與最佳競爭者相比，準確度提升了 1.9%，與直接使用擷取文字作為背景提示的方法相比，邏輯形式產生的改進為 6.6%。這些結果證明了 Amar 在改善 LLM 推理方面的有效性。

##### **Is Large Language Model Good at Triple Set Prediction? An Empirical Study**
2412.18443v1 by Yuan Yuan, Yajing Xu, Wen Zhang

The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.

摘要：知識圖譜完成 (KGC) 任務的核心是預測和完成 KG 中遺失的關係或節點。常見的 KGC 任務大多是關於推論未知元素，其中一個或兩個元素在三元組中已知。相比之下，三元組集合預測 (TSP) 任務是一個更實際的知識圖譜完成任務。它旨在根據已知三元組中的資訊預測未知三元組的所有元素。近年來，大型語言模型 (LLM) 在語言理解方面表現出顯著的進步，顯示出 KGC 任務的巨大潛力。然而，LLM 在 TSP 任務上的潛力尚未得到探討。因此，在本文中，我們提出了一個新的框架來探索 LLM 在 TSP 任務中的優勢和局限性。具體來說，該框架包含基於 LLM 的規則挖掘和基於 LLM 的三元組集合預測。嵌入豐富語義資訊的 KG 關係清單首先被利用來提示 LLM 生成規則。這個過程既有效率又獨立於統計資訊，使得挖掘有效且實際的規則變得更容易。對於每個子圖，指定規則與該子圖中相關的三元組結合使用，以指導 LLM 預測遺失的三元組。隨後，合併所有子圖的預測，以推導 KG 上預測三元組的完整集合。最後，該方法在相對完整的 CFamily 資料集上進行評估。實驗結果表明，當要求 LLM 遵循大量事實知識來預測遺失的三元組時，會發生顯著的幻覺，導致效能顯著下降。為了進一步探討這種現象的原因，本文提出了由詳細案例研究支援的全面分析。

##### **Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**
2412.18260v1 by Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu

Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.

摘要：程式碼漏洞偵測 (CVD) 對於解決和預防系統安全問題至關重要，在確保軟體安全中扮演著關鍵角色。先前的基於學習的漏洞偵測方法仰賴微調中等大小的序列模型或從頭訓練較小的神經網路。大型預訓練語言模型 (LLM) 的最新進展在各種程式碼智慧任務中展現了卓越的能力，包括程式碼理解和產生。然而，LLM 在偵測程式碼漏洞方面的有效性在很大程度上尚未被探索。本研究旨在透過微調 LLM 以執行 CVD 任務來探討這個差距，其中涉及四個廣泛使用的開源 LLM。我們也實作了其他五個先前的基於圖形的模型或中等大小的序列模型以供比較。實驗在五個常用的 CVD 資料集上進行，包括短範例和長範例的部分。此外，我們進行了量化實驗以探討類別不平衡問題和模型在不同長度範例上的效能，這些在先前的研究中很少被探討。為了更好地促進社群，我們在 https://github.com/SakiRinn/LLM4CVD 和 https://huggingface.co/datasets/xuefen/VulResource 開源了本研究的所有程式碼和資源。

##### **An Automatic Graph Construction Framework based on Large Language Models for Recommendation**
2412.18241v1 by Rong Shan, Jianghao Lin, Chenxu Zhu, Bo Chen, Menghui Zhu, Kangning Zhang, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

Graph neural networks (GNNs) have emerged as state-of-the-art methods to
learn from graph-structured data for recommendation. However, most existing
GNN-based recommendation methods focus on the optimization of model structures
and learning strategies based on pre-defined graphs, neglecting the importance
of the graph construction stage. Earlier works for graph construction usually
rely on speciffic rules or crowdsourcing, which are either too simplistic or
too labor-intensive. Recent works start to utilize large language models (LLMs)
to automate the graph construction, in view of their abundant open-world
knowledge and remarkable reasoning capabilities. Nevertheless, they generally
suffer from two limitations: (1) invisibility of global view (e.g., overlooking
contextual information) and (2) construction inefficiency. To this end, we
introduce AutoGraph, an automatic graph construction framework based on LLMs
for recommendation. Specifically, we first use LLMs to infer the user
preference and item knowledge, which is encoded as semantic vectors. Next, we
employ vector quantization to extract the latent factors from the semantic
vectors. The latent factors are then incorporated as extra nodes to link the
user/item nodes, resulting in a graph with in-depth global-view semantics. We
further design metapath-based message aggregation to effectively aggregate the
semantic and collaborative information. The framework is model-agnostic and
compatible with different backbone models. Extensive experiments on three
real-world datasets demonstrate the efficacy and efffciency of AutoGraph
compared to existing baseline methods. We have deployed AutoGraph in Huawei
advertising platform, and gain a 2.69% improvement on RPM and a 7.31%
improvement on eCPM in the online A/B test. Currently AutoGraph has been used
as the main trafffc model, serving hundreds of millions of people.

摘要：圖神經網路 (GNN) 已成為最先進的方法，可從圖形結構化資料中學習推薦。然而，現有的基於 GNN 的推薦方法大多側重於預定義圖形上的模型結構和學習策略的最佳化，忽略了圖形建構階段的重要性。早期圖形建構工作通常依賴於特定規則或群眾外包，這些方法過於簡化或過於勞動密集。最近的工作開始利用大型語言模型 (LLM) 來自動化圖形建構，因為它們具有豐富的開放世界知識和卓越的推理能力。儘管如此，它們通常存在兩個限制：(1) 全域檢視的不可見性（例如，忽略上下文資訊）和 (2) 建構效率低下。為此，我們引入了 AutoGraph，一個基於 LLM 的自動圖形建構框架，用於推薦。具體來說，我們首先使用 LLM 推斷使用者偏好和項目知識，並將其編碼為語義向量。接下來，我們採用向量量化從語義向量中提取潛在因子。然後將潛在因子作為額外節點加入，以連結使用者/項目節點，從而形成一個具有深入全域檢視語義的圖形。我們進一步設計了基於元路徑的訊息聚合，以有效聚合語義和協作資訊。該框架與模型無關，並與不同的主幹模型相容。在三個真實世界資料集上進行的廣泛實驗證明了 AutoGraph 與現有基準方法相比的效能和效率。我們已在華為廣告平台上部署了 AutoGraph，並在線上 A/B 測試中獲得了 RPM 提升 2.69% 和 eCPM 提升 7.31%。目前 AutoGraph 已被用作主要的流量模型，服務於數億人。

##### **CARL-GT: Evaluating Causal Reasoning Capabilities of Large Language Models**
2412.17970v1 by Ruibo Tu, Hedvig Kjellström, Gustav Eje Henter, Cheng Zhang

Causal reasoning capabilities are essential for large language models (LLMs)
in a wide range of applications, such as education and healthcare. But there is
still a lack of benchmarks for a better understanding of such capabilities.
Current LLM benchmarks are mainly based on conversational tasks, academic math
tests, and coding tests. Such benchmarks evaluate LLMs in well-regularized
settings, but they are limited in assessing the skills and abilities to solve
real-world problems. In this work, we provide a benchmark, named by CARL-GT,
which evaluates CAusal Reasoning capabilities of large Language models using
Graphs and Tabular data. The benchmark has a diverse range of tasks for
evaluating LLMs from causal graph reasoning, knowledge discovery, and
decision-making aspects. In addition, effective zero-shot learning prompts are
developed for the tasks. In our experiments, we leverage the benchmark for
evaluating open-source LLMs and provide a detailed comparison of LLMs for
causal reasoning abilities. We found that LLMs are still weak in casual
reasoning, especially with tabular data to discover new insights. Furthermore,
we investigate and discuss the relationships of different benchmark tasks by
analyzing the performance of LLMs. The experimental results show that LLMs have
different strength over different tasks and that their performance on tasks in
different categories, i.e., causal graph reasoning, knowledge discovery, and
decision-making, shows stronger correlation than tasks in the same category.

摘要：因果推理能力对于大型语言模型 (LLM) 至关重要，适用于广泛的应用，例如教育和医疗保健。但对于更好地理解此类能力，仍然缺乏基准。当前的 LLM 基准主要基于会话任务、学术数学测试和编码测试。此类基准在经过良好规范的环境中评估 LLM，但它们在评估解决实际问题的能力和技能方面受到限制。在这项工作中，我们提供了一个基准，名为 CARL-GT，它使用图和表格数据来评估大型语言模型的因果推理能力。该基准具有各种任务，用于从因果图推理、知识发现和决策方面评估 LLM。此外，针对这些任务开发了有效的零样本学习提示。在我们的实验中，我们利用基准来评估开源 LLM，并对 LLM 的因果推理能力进行了详细比较。我们发现 LLM 在因果推理方面仍然很弱，尤其是在使用表格数据发现新见解时。此外，我们通过分析 LLM 的性能来调查和讨论不同基准任务之间的关系。实验结果表明，LLM 在不同任务上具有不同的优势，并且它们在不同类别中的任务上的表现，即因果图推理、知识发现和决策，比同一类别中的任务表现出更强的相关性。

##### **Path-of-Thoughts: Extracting and Following Paths for Robust Relational Reasoning with Large Language Models**
2412.17963v1 by Ge Zhang, Mohammad Ali Alomrani, Hongjian Gu, Jiaming Zhou, Yaochen Hu, Bin Wang, Qun Liu, Mark Coates, Yingxue Zhang, Jianye Hao

Large language models (LLMs) possess vast semantic knowledge but often
struggle with complex reasoning tasks, particularly in relational reasoning
problems such as kinship or spatial reasoning. In this paper, we present
Path-of-Thoughts (PoT), a novel framework designed to tackle relation reasoning
by decomposing the task into three key stages: graph extraction, path
identification, and reasoning. Unlike previous approaches, PoT efficiently
extracts a task-agnostic graph that identifies crucial entities, relations, and
attributes within the problem context. Subsequently, PoT identifies relevant
reasoning chains within the graph corresponding to the posed question,
facilitating inference of potential answers. Experimental evaluations on four
benchmark datasets, demanding long reasoning chains, demonstrate that PoT
surpasses state-of-the-art baselines by a significant margin (maximum 21.3%)
without necessitating fine-tuning or extensive LLM calls. Furthermore, as
opposed to prior neuro-symbolic methods, PoT exhibits improved resilience
against LLM errors by leveraging the compositional nature of graphs.

摘要：大型語言模型 (LLM) 擁有廣泛的語義知識，但在複雜的推理任務中經常遇到困難，特別是在關係推理問題中，例如親屬關係或空間推理。在本文中，我們提出思考路徑 (PoT)，這是一個新穎的框架，旨在通過將任務分解為三個關鍵階段來解決關係推理：圖形提取、路徑識別和推理。與之前的做法不同，PoT 有效地提取了一個與任務無關的圖形，該圖形識別了問題背景中的關鍵實體、關係和屬性。隨後，PoT 在與所提出的問題相應的圖形中識別出相關的推理鏈，從而推斷出潛在答案。在需要長推理鏈的四個基準數據集上的實驗評估表明，PoT 以顯著的優勢（最大 21.3%）超越了最先進的基準，而無需微調或廣泛的 LLM 調用。此外，與先前的神經符號方法相反，PoT 通過利用圖形的組合特性表現出對 LLM 錯誤的增強的彈性。

##### **ResearchTown: Simulator of Human Research Community**
2412.17767v1 by Haofei Yu, Zhaochen Hong, Zirui Cheng, Kunlun Zhu, Keyang Xuan, Jinwei Yao, Tao Feng, Jiaxuan You

Large Language Models (LLMs) have demonstrated remarkable potential in
scientific domains, yet a fundamental question remains unanswered: Can we
simulate human research communities with LLMs? Addressing this question can
deepen our understanding of the processes behind idea brainstorming and inspire
the automatic discovery of novel scientific insights. In this work, we propose
ResearchTown, a multi-agent framework for research community simulation. Within
this framework, the human research community is simplified and modeled as an
agent-data graph, where researchers and papers are represented as agent-type
and data-type nodes, respectively, and connected based on their collaboration
relationships. We also introduce TextGNN, a text-based inference framework that
models various research activities (e.g., paper reading, paper writing, and
review writing) as special forms of a unified message-passing process on the
agent-data graph. To evaluate the quality of the research simulation, we
present ResearchBench, a benchmark that uses a node-masking prediction task for
scalable and objective assessment based on similarity. Our experiments reveal
three key findings: (1) ResearchTown can provide a realistic simulation of
collaborative research activities, including paper writing and review writing;
(2) ResearchTown can maintain robust simulation with multiple researchers and
diverse papers; (3) ResearchTown can generate interdisciplinary research ideas
that potentially inspire novel research directions.

摘要：大型語言模型 (LLM) 在科學領域展現了非凡的潛力，但仍有一個基本問題尚未解答：我們能用 LLM 模擬人類研究社群嗎？探討這個問題能加深我們對腦力激盪背後流程的理解，並激發自動發現新科學見解。在這項工作中，我們提出 ResearchTown，一個用於研究社群模擬的多代理架構。在這個架構中，人類研究社群被簡化並建模為代理資料圖，其中研究人員和論文分別表示為代理類型節點和資料類型節點，並根據他們的合作關係進行連接。我們還介紹了 TextGNN，一個基於文字的推論架構，它將各種研究活動（例如，閱讀論文、撰寫論文和撰寫評論）建模為代理資料圖上統一訊息傳遞過程的特殊形式。為了評估研究模擬的品質，我們提出了 ResearchBench，一個使用節點遮罩預測任務進行基於相似性的可擴充且客觀評估的基準。我們的實驗揭示了三個關鍵發現：(1) ResearchTown 可以提供協作研究活動的逼真模擬，包括撰寫論文和撰寫評論；(2) ResearchTown 可以維持多位研究人員和不同論文的穩健模擬；(3) ResearchTown 可以產生跨學科研究構想，潛在激發新的研究方向。

##### **RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF for Conversational QA over KGs with RAG**
2412.17690v2 by Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi, Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech

Conversational question answering (ConvQA) is a convenient means of searching
over RDF knowledge graphs (KGs), where a prevalent approach is to translate
natural language questions to SPARQL queries. However, SPARQL has certain
shortcomings: (i) it is brittle for complex intents and conversational
questions, and (ii) it is not suitable for more abstract needs. Instead, we
propose a novel two-pronged system where we fuse: (i) SQL-query results over a
database automatically derived from the KG, and (ii) text-search results over
verbalizations of KG facts. Our pipeline supports iterative retrieval: when the
results of any branch are found to be unsatisfactory, the system can
automatically opt for further rounds. We put everything together in a retrieval
augmented generation (RAG) setup, where an LLM generates a coherent response
from accumulated search results. We demonstrate the superiority of our proposed
system over several baselines on a knowledge graph of BMW automobiles.

摘要：對話式問答（ConvQA）是一種搜尋 RDF 知識圖譜 (KG) 的便利方法，其中一種普遍的方法是將自然語言問題轉換為 SPARQL 查詢。然而，SPARQL 有某些缺點：(i) 對於複雜的意圖和對話式問題來說，它很脆弱，(ii) 它不適合更抽象的需求。相反，我們提出了一個新穎的雙管齊下的系統，其中我們融合：(i) 從自動從 KG 衍生的資料庫上的 SQL 查詢結果，以及 (ii) KG 事實的文字化上的文字搜尋結果。我們的管道支援反覆檢索：當發現任何分支的結果不令人滿意時，系統可以自動選擇進一步的回合。我們將所有內容放在檢索擴充生成 (RAG) 設定中，其中 LLM 從累積的搜尋結果中生成連貫的回應。我們在 BMW 汽車的知識圖譜上展示了我們提出的系統優於幾個基準的優越性。

##### **A Dual-Perspective Metaphor Detection Framework Using Large Language Models**
2412.17332v1 by Yujie Lin, Jingyao Liu, Yan Gao, Ante Wang, Jinsong Su

Metaphor detection, a critical task in natural language processing, involves
identifying whether a particular word in a sentence is used metaphorically.
Traditional approaches often rely on supervised learning models that implicitly
encode semantic relationships based on metaphor theories. However, these
methods often suffer from a lack of transparency in their decision-making
processes, which undermines the reliability of their predictions. Recent
research indicates that LLMs (large language models) exhibit significant
potential in metaphor detection. Nevertheless, their reasoning capabilities are
constrained by predefined knowledge graphs. To overcome these limitations, we
propose DMD, a novel dual-perspective framework that harnesses both implicit
and explicit applications of metaphor theories to guide LLMs in metaphor
detection and adopts a self-judgment mechanism to validate the responses from
the aforementioned forms of guidance. In comparison to previous methods, our
framework offers more transparent reasoning processes and delivers more
reliable predictions. Experimental results prove the effectiveness of DMD,
demonstrating state-of-the-art performance across widely-used datasets.

摘要：隱喻偵測，在自然語言處理中是一項重要的任務，涉及辨識句子中特定字詞是否被隱喻使用。
傳統方法通常仰賴監督式學習模型，該模型會根據隱喻理論隱含編碼語意關係。
然而，這些方法通常在決策過程中缺乏透明度，這會損害其預測的可靠性。
最近的研究指出，LLM（大型語言模型）在隱喻偵測中展現出顯著的潛力。
儘管如此，其推理能力仍受到預先定義的知識圖表的限制。
為了克服這些限制，我們提出 DMD，一個新穎的雙重觀點架構，它利用隱喻理論的隱含和明確應用來引導 LLM 進行隱喻偵測，並採用自我判斷機制來驗證上述形式指導的回應。
與先前的模型相比，我們的架構提供了更透明的推理過程，並提供更可靠的預測。
實驗結果證明了 DMD 的有效性，在廣泛使用的資料集上展現出最先進的效能。

##### **GraphAgent: Agentic Graph Language Assistant**
2412.17029v1 by Yuhao Yang, Jiabin Tang, Lianghao Xia, Xingchen Zou, Yuxuan Liang, Chao Huang

Real-world data is represented in both structured (e.g., graph connections)
and unstructured (e.g., textual, visual information) formats, encompassing
complex relationships that include explicit links (such as social connections
and user behaviors) and implicit interdependencies among semantic entities,
often illustrated through knowledge graphs. In this work, we propose
GraphAgent, an automated agent pipeline that addresses both explicit graph
dependencies and implicit graph-enhanced semantic inter-dependencies, aligning
with practical data scenarios for predictive tasks (e.g., node classification)
and generative tasks (e.g., text generation). GraphAgent comprises three key
components: (i) a Graph Generator Agent that builds knowledge graphs to reflect
complex semantic dependencies; (ii) a Task Planning Agent that interprets
diverse user queries and formulates corresponding tasks through agentic
self-planning; and (iii) a Task Execution Agent that efficiently executes
planned tasks while automating tool matching and invocation in response to user
queries. These agents collaborate seamlessly, integrating language models with
graph language models to uncover intricate relational information and data
semantic dependencies. Through extensive experiments on various graph-related
predictive and text generative tasks on diverse datasets, we demonstrate the
effectiveness of our GraphAgent across various settings. We have made our
proposed GraphAgent open-source at: https://github.com/HKUDS/GraphAgent.

摘要：真實世界的資料以結構化（例如圖形連接）和非結構化（例如文字、視覺資訊）格式呈現，包含複雜的關係，包括明確的連結（例如社交連結和使用者行為）和語意實體之間的隱含相互依賴，通常透過知識圖表來說明。在這項工作中，我們提出 GraphAgent，一個自動化代理程式管道，它處理明確的圖形依賴關係和隱含的圖形增強語意相互依賴關係，與預測任務（例如節點分類）和生成任務（例如文字生成）的實際資料情境保持一致。GraphAgent 包含三個關鍵組成部分：(i) 一個圖形產生器代理程式，用來建構知識圖表以反映複雜的語意依賴關係；(ii) 一個任務規劃代理程式，用來詮釋不同的使用者查詢，並透過代理自規劃制定相應的任務；以及 (iii) 一個任務執行代理程式，用來在回應使用者查詢時，有效率地執行已規劃的任務，同時自動化工具配對和呼叫。這些代理程式無縫地協作，將語言模型與圖形語言模型整合在一起，以揭露複雜的關係資訊和資料語意依賴關係。透過在不同資料集上進行各種與圖形相關的預測和文字生成任務的廣泛實驗，我們證明了 GraphAgent 在各種設定中的有效性。我們已將我們提出的 GraphAgent 開源：https://github.com/HKUDS/GraphAgent。

##### **Enhancing Supply Chain Transparency in Emerging Economies Using Online Contents and LLMs**
2412.16922v1 by Bohan Jin, Qianyou Sun, Lihua Chen

In the current global economy, supply chain transparency plays a pivotal role
in ensuring this security by enabling companies to monitor supplier performance
and fostering accountability and responsibility. Despite the advancements in
supply chain relationship datasets like Bloomberg and FactSet, supply chain
transparency remains a significant challenge in emerging economies due to
issues such as information asymmetry and institutional gaps in regulation. This
study proposes a novel approach to enhance supply chain transparency in
emerging economies by leveraging online content and large language models
(LLMs). We develop a Supply Chain Knowledge Graph Mining System that integrates
advanced LLMs with web crawler technology to automatically collect and analyze
supply chain information. The system's effectiveness is validated through a
case study focusing on the semiconductor supply chain, a domain that has
recently gained significant attention due to supply chain risks. Our results
demonstrate that the proposed system provides greater applicability for
emerging economies, such as mainland China, complementing the data gaps in
existing datasets. However, challenges including the accurate estimation of
monetary and material flows, the handling of time series data, synonyms
disambiguation, and mitigating biases from online contents still remains.
Future research should focus on addressing these issues to further enhance the
system's capabilities and broaden its application to other emerging economies
and industries.

摘要：在當今全球經濟中，供應鏈透明度在確保此安全性方面發揮著關鍵作用，讓公司能夠監控供應商績效並促進問責制和責任感。儘管彭博社和 FactSet 等供應鏈關係數據集取得進展，但由於資訊不對稱和法規制度差距等問題，供應鏈透明度在開發中國家仍是一項重大挑戰。本研究提出了一種新方法，利用線上內容和大型語言模型 (LLM) 來加強開發中國家的供應鏈透明度。我們開發了一個供應鏈知識圖譜挖掘系統，將先進的 LLM 與網路爬蟲技術整合在一起，以自動收集和分析供應鏈資訊。該系統的有效性已通過針對半導體供應鏈的案例研究得到驗證，半導體供應鏈是一個由於供應鏈風險而最近受到極大關注的領域。我們的結果表明，所提出的系統為開發中國家（例如中國大陸）提供了更大的適用性，補充了現有數據集中的數據差距。然而，包括準確估計貨幣和物料流、處理時間序列數據、消除同義詞歧義和減輕線上內容偏見在內的挑戰仍然存在。未來的研究應專注於解決這些問題，以進一步增強系統的能力並擴大其在其他開發中國家和產業的應用。

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v1 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

摘要：整合大型語言模型 (LLM) 於醫療診斷中，需要系統化架構，能夠處理複雜的醫療場景，同時維持專業知識。我們提出 KG4Diagnosis，一個新穎的分層多代理架構，結合 LLM 與自動化知識圖譜建構，涵蓋醫療專業的 362 種常見疾病。我們的架構透過雙層架構反映真實世界的醫療系統：一位全科醫師 (GP) 代理負責初步評估和分流，並與專業代理協調，針對特定領域進行深入診斷。核心創新在於我們的端對端知識圖譜生成方法，結合：(1) 針對醫療術語最佳化的語意驅動實體和關係萃取，(2) 從非結構化醫療文本重建多面向決策關係，以及 (3) 人類引導的推理進行知識擴充。KG4Diagnosis 可作為專業醫療診斷系統的可擴充基礎，具備整合新疾病和醫療知識的能力。此架構的模組化設計能無縫整合特定領域的強化功能，使其對於開發目標導向的醫療診斷系統極具價值。我們提供架構準則和協定，以利於在醫療情境中採用。

##### **Apples to Apples: Establishing Comparability in Knowledge Generation Tasks Involving Users**
2412.16766v1 by Christophe Debruyne, Ademar Crotti Junior

Knowledge graph construction (KGC) from (semi-)structured data is
challenging, and facilitating user involvement is an issue frequently brought
up within this community. We cannot deny the progress we have made with respect
to (declarative) knowledge generation languages and tools to help build such
mappings. However, it is surprising that no two studies report on similar
protocols. This heterogeneity does not allow for a comparison of KGC languages,
techniques, and tools. This paper first analyses the various studies that
report on studies involving users to identify the points of comparison. These
gaps include a lack of systematic consistency in task design, participant
selection, and evaluation metrics. Moreover, there needs to be a systematic way
of analyzing the data and reporting the findings, which is also lacking. We
thus propose and introduce a user protocol for KGC designed to address this
challenge. Where possible, we draw and take elements from the literature we
deem fit for such a protocol. The protocol, as such, allows for the comparison
of languages and techniques for the RDF Mapping Languages core functionality,
which is covered by most of the other state-of-the-art techniques and tools. We
also propose how the protocol can be amended to compare extensions (of RML).
This protocol provides an important step towards a more comparable evaluation
of KGC user studies.

摘要：知識圖譜建構 (KGC) 從 (半) 結構化資料中進行非常具有挑戰性，而促進使用者參與是這個社群中經常提出的議題。我們無法否認我們在協助建構此類對應的 (宣告式) 知識產生語言和工具方面所做的進展。然而，令人驚訝的是，沒有兩項研究報告類似的協定。這種異質性不允許比較 KGC 語言、技術和工具。本文首先分析各種研究，這些研究報告涉及使用者的研究，以找出比較點。這些差距包括任務設計、參與者選擇和評量指標缺乏系統性的一致性。此外，需要有系統的方法來分析資料和報告結果，這也是所缺乏的。因此，我們提出並介紹一個使用者協定，用於 KGC，旨在解決這個挑戰。在可能的範圍內，我們從我們認為適合此類協定的文獻中汲取並採用元素。因此，該協定允許比較 RDF 對應語言核心功能的語言和技術，而大多數其他最先進的技術和工具都涵蓋了這一點。我們還提出如何修改協定以比較延伸 (RML)。此協定提供了一個重要的步驟，朝向更具可比較性的 KGC 使用者研究評量邁進。

##### **Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models**
2412.16533v1 by Chao-Chi Chen, Chin-Yuan Yeh, Hsi-Wen Chen, De-Nian Yang, Ming-Syan Chen

We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that
advances the capabilities of large language models (LLMs) beyond existing
paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of
Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),
which allows for an executable plan to be specified by LLMs for LLMs. LWT
allows these plans to be arbitrary networks, where single-step LLM operations
are nodes, and edges correspond to message passing between these steps.
Furthermore, LWT supports selection of individual elements through indexing,
facilitating kNoT to produce intricate plans where each LLM operation can be
limited to elementary operations, greatly enhancing reliability over extended
task sequences. We demonstrate that kNoT significantly outperforms the state of
the art on six use cases, while reducing the need for extensive prompt
engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over
12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less
task-specific prompts, respectively.

摘要：我們引入了思想知識網路 (kNoT)：一種提示架構，它將大型語言模型 (LLM) 的能力提升到了超越現有範例的境界，例如思想鏈 (CoT)、思想樹 (ToT) 和思想圖 (GoT)。kNoT 的關鍵創新是 LLM 工作流程範本 (LWT)，它允許 LLM 為 LLM 指定一個可執行的計畫。LWT 允許這些計畫成為任意網路，其中單步 LLM 操作為節點，而邊緣對應於這些步驟之間的訊息傳遞。此外，LWT 支援透過索引選取個別元素，進而讓 kNoT 能夠制定複雜的計畫，其中每個 LLM 操作都可以限制為基本操作，大幅提升延伸任務序列的可靠性。我們證明 kNoT 在六個用例上顯著優於現有技術，同時減少了對廣泛提示工程的需求。例如，kNoT 在對 32 個數字進行排序時發現 92% 的準確率，而 ToT 和 GoT 為 12% 和 31%，同時分別利用了少達 84.4% 和 87.3% 的特定任務提示。

##### **Beyond End-to-End VLMs: Leveraging Intermediate Text Representations for Superior Flowchart Understanding**
2412.16420v1 by Junyi Ye, Ankan Dash, Wenpeng Yin, Guiling Wang

Flowcharts are typically presented as images, driving the trend of using
vision-language models (VLMs) for end-to-end flowchart understanding. However,
two key challenges arise: (i) Limited controllability--users have minimal
influence over the downstream task, as they can only modify input images, while
the training of VLMs is often out of reach for most researchers. (ii) Lack of
explainability--it is difficult to trace VLM errors to specific causes, such as
failures in visual encoding or reasoning. We propose TextFlow, addressing
aforementioned issues with two stages: (i) Vision Textualizer--which generates
textual representations from flowchart images; and (ii) Textual Reasoner--which
performs question-answering based on the text representations. TextFlow offers
three key advantages: (i) users can select the type of text representations
(e.g., Graphviz, Mermaid, PlantUML), or further convert them into executable
graph object to call tools, enhancing performance and controllability; (ii) it
improves explainability by helping to attribute errors more clearly to visual
or textual processing components; and (iii) it promotes the modularization of
the solution, such as allowing advanced LLMs to be used in the Reasoner stage
when VLMs underperform in end-to-end fashion. Experiments on the FlowVQA and
FlowLearn benchmarks demonstrate TextFlow's state-of-the-art performance as
well as its robustness. All code is publicly available.

摘要：流程圖通常以影像呈現，推動了使用視覺語言模型 (VLM) 進行端對端流程圖理解的趨勢。然而，出現了兩個關鍵挑戰：(i) 可控性有限——使用者對下游任務的影響很小，因為他們只能修改輸入影像，而大多數研究人員往往無法訓練 VLM。(ii) 缺乏可解釋性——難以追溯 VLM 錯誤到具體原因，例如視覺編碼或推理失敗。我們提出 TextFlow，透過兩個階段來解決上述問題：(i) 視覺文字化器——從流程圖影像產生文字表示；(ii) 文字推理器——根據文字表示執行問答。TextFlow 提供了三個主要優點：(i) 使用者可以選擇文字表示的類型（例如 Graphviz、Mermaid、PlantUML），或進一步將它們轉換為可執行的圖形物件來呼叫工具，增強效能和可控性；(ii) 它透過幫助更清楚地將錯誤歸因於視覺或文字處理元件來改善可解釋性；(iii) 它促進了解決方案的模組化，例如允許在 VLM 在端對端模式下表現不佳時，在推理器階段使用進階 LLM。在 FlowVQA 和 FlowLearn 基準上的實驗證明了 TextFlow 的最先進效能以及其穩健性。所有程式碼都公開可用。

##### **HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases**
2412.16311v1 by Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos

Given a semi-structured knowledge base (SKB), where text documents are
interconnected by relations, how can we effectively retrieve relevant
information to answer user questions? Retrieval-Augmented Generation (RAG)
retrieves documents to assist large language models (LLMs) in question
answering; while Graph RAG (GRAG) uses structured knowledge bases as its
knowledge source. However, many questions require both textual and relational
information from SKB - referred to as "hybrid" questions - which complicates
the retrieval process and underscores the need for a hybrid retrieval method
that leverages both information. In this paper, through our empirical analysis,
we identify key insights that show why existing methods may struggle with
hybrid question answering (HQA) over SKB. Based on these insights, we propose
HybGRAG for HQA consisting of a retriever bank and a critic module, with the
following advantages: (1) Agentic, it automatically refines the output by
incorporating feedback from the critic module, (2) Adaptive, it solves hybrid
questions requiring both textual and relational information with the retriever
bank, (3) Interpretable, it justifies decision making with intuitive refinement
path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In
experiments on the STaRK benchmark, HybGRAG achieves significant performance
gains, with an average relative improvement in Hit@1 of 51%.

摘要：<paragraph>給定一個半結構化知識庫 (SKB)，其中文本文件由關係相互連接，我們如何有效地擷取相關資訊來回答使用者的問題？擷取增強生成 (RAG) 擷取文件以協助大型語言模型 (LLM) 回答問題；而圖形 RAG (GRAG) 使用結構化知識庫作為其知識來源。然而，許多問題需要來自 SKB 的文字和關係資訊，稱為「混合」問題，這使得擷取過程複雜化，並強調需要一種利用這兩種資訊的混合擷取方法。在本文中，透過我們的實證分析，我們找出顯示現有方法可能難以在 SKB 上進行混合問題解答 (HQA) 的關鍵見解。根據這些見解，我們提出由擷取器庫和批評模組組成、具有以下優點的 HQA HybGRAG：(1) 代理，它透過納入批評模組的回饋自動精煉輸出，(2) 適應，它使用擷取器庫解決需要文字和關係資訊的混合問題，(3) 可解釋，它以直覺的精煉路徑證明決策，以及 (4) 有效，它超越了 HQA 基準的所有基準。在 STaRK 基準的實驗中，HybGRAG 達到了顯著的效能提升，Hit@1 的平均相對改善為 51%。</paragraph>

##### **Logical Consistency of Large Language Models in Fact-checking**
2412.16100v1 by Bishwamittra Ghosh, Sarah Hasan, Naheed Anjum Arafat, Arijit Khan

In recent years, large language models (LLMs) have demonstrated significant
success in performing varied natural language tasks such as language
translation, question-answering, summarizing, fact-checking, etc. Despite LLMs'
impressive ability to generate human-like texts, LLMs are infamous for their
inconsistent responses -- a meaning-preserving change in the input query
results in an inconsistent response and attributes to vulnerabilities of LLMs
such as hallucination, jailbreaking, etc. Consequently, existing research
focuses on simple paraphrasing-based consistency assessment of LLMs, and
ignores complex queries that necessitates an even better understanding of
logical reasoning by an LLM. Our work therefore addresses the logical
inconsistency of LLMs under complex logical queries with primitive logical
operators, e.g., negation, conjunction, and disjunction. As a test bed, we
consider retrieval-augmented LLMs on a fact-checking task involving
propositional logic queries from real-world knowledge graphs (KGs). Our
contributions are three-fold. Benchmark: We introduce three logical
fact-checking datasets over KGs for community development towards logically
consistent LLMs. Assessment: We propose consistency measures of LLMs on
propositional logic queries as input and demonstrate that existing LLMs lack
logical consistency, specially on complex queries. Improvement: We employ
supervised fine-tuning to improve the logical consistency of LLMs on the
complex fact-checking task with KG contexts.

摘要：近年來，大型語言模型 (LLM) 在執行各種自然語言任務（例如語言翻譯、問答、摘要、事實查核等）方面展現出顯著的成功。儘管 LLM 能產生類似人類的文字，但 LLM 以其不一致的回應而臭名昭著——輸入查詢中一個保意改變會導致不一致的回應，並歸因於 LLM 的漏洞，例如幻覺、越獄等。因此，現有的研究專注於 LLM 的基於簡單改寫的一致性評估，而忽略了需要 LLM 更深入理解邏輯推理的複雜查詢。因此，我們的研究解決了 LLM 在具有基本邏輯運算元（例如否定、合取和析取）的複雜邏輯查詢下的邏輯不一致性。作為一個測試平台，我們考慮在一個涉及來自真實世界知識圖譜 (KG) 的命題邏輯查詢的事實查核任務中，檢索增強的 LLM。我們的貢獻有三方面。基準：我們在 KG 上引入了三個邏輯事實查核數據集，以促進社區開發邏輯一致的 LLM。評估：我們提出了 LLM 在命題邏輯查詢作為輸入上的一致性測量，並證明現有的 LLM 缺乏邏輯一致性，特別是在複雜查詢上。改進：我們採用監督微調來提高 LLM 在具有 KG 背景的複雜事實查核任務上的邏輯一致性。

##### **GraphSeqLM: A Unified Graph Language Framework for Omic Graph Learning**
2412.15790v1 by Heming Zhang, Di Huang, Yixin Chen, Fuhai Li

The integration of multi-omic data is pivotal for understanding complex
diseases, but its high dimensionality and noise present significant challenges.
Graph Neural Networks (GNNs) offer a robust framework for analyzing large-scale
signaling pathways and protein-protein interaction networks, yet they face
limitations in expressivity when capturing intricate biological relationships.
To address this, we propose Graph Sequence Language Model (GraphSeqLM), a
framework that enhances GNNs with biological sequence embeddings generated by
Large Language Models (LLMs). These embeddings encode structural and biological
properties of DNA, RNA, and proteins, augmenting GNNs with enriched features
for analyzing sample-specific multi-omic data. By integrating topological,
sequence-derived, and biological information, GraphSeqLM demonstrates superior
predictive accuracy and outperforms existing methods, paving the way for more
effective multi-omic data integration in precision medicine.

摘要：整合多組學資料對於理解複雜疾病至關重要，但其高維度和雜訊會造成顯著的挑戰。圖神經網路 (GNN) 提供了一個強健的架構，用於分析大規模信號路徑和蛋白質-蛋白質交互網路，然而它們在捕捉複雜的生物關係時，在表現力方面面臨限制。為了解決這個問題，我們提出了圖序列語言模型 (GraphSeqLM)，一個增強 GNN 的架構，透過大型語言模型 (LLM) 生成的生物序列嵌入。這些嵌入編碼了 DNA、RNA 和蛋白質的結構和生物特性，透過豐富的特性擴充 GNN，用於分析特定樣本的多組學資料。透過整合拓撲、序列衍生和生物資訊，GraphSeqLM 展現了優越的預測準確度，並優於現有方法，為精準醫療中更有效的多組學資料整合鋪路。

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

摘要：飲食在人類健康中扮演著至關重要的角色，然而根據個人健康狀況調整飲食推理仍然是一項重大的挑戰。營養問題問答 (QA) 已成為解決此問題的流行方法。不過，目前的研究面臨兩項重大的限制。一方面，缺乏包含使用者特定醫療資訊的資料集嚴重限制了「個人化」。這個挑戰進一步受到個人健康需求廣泛變異的影響。另一方面，雖然大型語言模型 (LLM) 是此任務的熱門解決方案，展示出強大的推理能力，但它們在個人化健康飲食推理的特定領域複雜性上仍有困難，而現有的基準也無法捕捉這些挑戰。為了解決這些差距，我們引入了營養圖表問答 (NGQA) 基準，這是第一個專為個人化營養健康推理設計的圖表問答資料集。NGQA 利用國家健康與營養檢查調查 (NHANES) 和飲食研究食物與營養資料庫 (FNDDS) 的資料，評估食物是否對特定使用者健康，並說明主要貢獻營養素。此基準納入了三個問題複雜度設定，並評估三個下游任務的推理。使用 LLM 主幹和基線模型進行的廣泛實驗證明，NGQA 基準有效挑戰了現有模型。總之，NGQA 解決了一個重大的現實世界問題，同時透過新穎的特定領域基準推動了 GraphQA 研究。

##### **SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval**
2412.15443v1 by Aakash Mahalingam, Vinesh Kumar Gande, Aman Chadha, Vinija Jain, Divya Chaudhary

Retrieval-Augmented Generation (RAG) systems have become pivotal in
leveraging vast corpora to generate informed and contextually relevant
responses, notably reducing hallucinations in Large Language Models. Despite
significant advancements, these systems struggle to efficiently process and
retrieve information from large datasets while maintaining a comprehensive
understanding of the context. This paper introduces SKETCH, a novel methodology
that enhances the RAG retrieval process by integrating semantic text retrieval
with knowledge graphs, thereby merging structured and unstructured data for a
more holistic comprehension. SKETCH, demonstrates substantial improvements in
retrieval performance and maintains superior context integrity compared to
traditional methods. Evaluated across four diverse datasets: QuALITY, QASPER,
NarrativeQA, and Italian Cuisine-SKETCH consistently outperforms baseline
approaches on key RAGAS metrics such as answer_relevancy, faithfulness,
context_precision and context_recall. Notably, on the Italian Cuisine dataset,
SKETCH achieved an answer relevancy of 0.94 and a context precision of 0.99,
representing the highest performance across all evaluated metrics. These
results highlight SKETCH's capability in delivering more accurate and
contextually relevant responses, setting new benchmarks for future retrieval
systems.

摘要：擷取增強生成 (RAG) 系統已成為利用龐大語料庫來產生明智且與情境相關回應的關鍵，特別是減少大型語言模型中的幻覺。儘管有顯著的進展，但這些系統在處理和擷取來自大型資料集的資訊時仍有困難，同時還要維持對情境的全面理解。本文介紹 SKETCH，一種透過將語意文字擷取與知識圖表整合，藉此合併結構化和非結構化資料以獲得更全面的理解，來增強 RAG 擷取程序的創新方法。SKETCH 在擷取效能方面展現出顯著的進步，並與傳統方法相比維持較佳的情境完整性。在四個不同的資料集：QuALITY、QASPER、NarrativeQA 和 Italian Cuisine 中進行評估，SKETCH 在關鍵的 RAGAS 指標（例如 answer_relevancy、faithfulness、context_precision 和 context_recall）上始終優於基準方法。值得注意的是，在 Italian Cuisine 資料集上，SKETCH 的 answer relevancy 達到 0.94，context precision 達到 0.99，代表在所有評估指標中表現最佳。這些結果突顯了 SKETCH 在提供更準確且與情境相關回應的能力，為未來的擷取系統樹立了新的基準。

##### **Graph-Convolutional Networks: Named Entity Recognition and Large Language Model Embedding in Document Clustering**
2412.14867v1 by Imed Keraghel, Mohamed Nadif

Recent advances in machine learning, particularly Large Language Models
(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve
text representation. However, current document clustering approaches often
ignore the deeper relationships between named entities (NEs) and the potential
of LLM embeddings. This paper proposes a novel approach that integrates Named
Entity Recognition (NER) and LLM embeddings within a graph-based framework for
document clustering. The method builds a graph with nodes representing
documents and edges weighted by named entity similarity, optimized using a
graph-convolutional network (GCN). This ensures a more effective grouping of
semantically related documents. Experimental results indicate that our approach
outperforms conventional co-occurrence-based methods in clustering, notably for
documents rich in named entities.

摘要：近期機器學習的進展，特別是大型語言模型 (LLM)，例如 BERT 和 GPT，提供了豐富的上下文嵌入，改進了文本表徵。然而，當前的文件分群方法通常忽略命名實體 (NE) 之間更深層的關係和 LLM 嵌入的潛力。本文提出了一種創新的方法，將命名實體辨識 (NER) 和 LLM 嵌入整合到基於圖形的架構中，以進行文件分群。該方法建立了一個圖形，其中節點代表文件，邊緣則由命名實體相似性加權，並使用圖形卷積網路 (GCN) 進行最佳化。這確保了語義相關文件更有效的分組。實驗結果表明，我們的做法優於傳統的共現方法在分群中的表現，特別是對於富含命名實體的文件。

##### **Answer Set Networks: Casting Answer Set Programming into Deep Learning**
2412.14814v1 by Arseny Skryagin, Daniel Ochs, Phillip Deibert, Simon Kohaut, Devendra Singh Dhami, Kristian Kersting

Although Answer Set Programming (ASP) allows constraining neural-symbolic
(NeSy) systems, its employment is hindered by the prohibitive costs of
computing stable models and the CPU-bound nature of state-of-the-art solvers.
To this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on
Graph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep
Probabilistic Logic Programming (DPPL). Specifically, we show how to translate
ASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded
problem by leveraging GPU's batching and parallelization capabilities. Our
experimental evaluations demonstrate that ASNs outperform state-of-the-art
CPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following
two contributions based on the strengths of ASNs. Namely, we are the first to
show the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs
to guide the training with logic. Further, we show the "constitutional
navigation" of drones, i.e., encoding public aviation laws in an ASN for
routing Unmanned Aerial Vehicles in uncertain environments.

摘要：儘管答案集程式設計（ASP）允許約束神經符號（NeSy）系統，但其應用受到計算穩定模型的過高成本和現有求解器受 CPU 限制的本質所阻礙。為此，我們提出答案集網路（ASN），一個 NeSy 求解器。ASN 基於圖神經網路（GNN），是一種基於 ASP 的深度機率邏輯程式設計（DPPL）的可擴充方法。具體來說，我們展示如何將 ASP 轉換為 ASN，並展示 ASN 如何透過利用 GPU 的批次處理和並行化功能有效地解決編碼問題。我們的實驗評估表明，ASN 在多項任務上優於現有的受 CPU 限制的 NeSy 系統。同時，我們根據 ASN 的優勢做出了以下兩項貢獻。也就是說，我們首次展示使用 DPPL 對大型語言模型（LLM）進行微調，使用 ASN 以邏輯引導訓練。此外，我們展示了無人機的「憲法導航」，即在 ASN 中編碼公共航空法，以便在不確定的環境中對無人機進行路由。

##### **IOHunter: Graph Foundation Model to Uncover Online Information Operations**
2412.14663v1 by Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara

Social media platforms have become vital spaces for public discourse, serving
as modern agor\'as where a wide range of voices influence societal narratives.
However, their open nature also makes them vulnerable to exploitation by
malicious actors, including state-sponsored entities, who can conduct
information operations (IOs) to manipulate public opinion. The spread of
misinformation, false news, and misleading claims threatens democratic
processes and societal cohesion, making it crucial to develop methods for the
timely detection of inauthentic activity to protect the integrity of online
discourse. In this work, we introduce a methodology designed to identify users
orchestrating information operations, a.k.a. \textit{IO drivers}, across
various influence campaigns. Our framework, named \texttt{IOHunter}, leverages
the combined strengths of Language Models and Graph Neural Networks to improve
generalization in \emph{supervised}, \emph{scarcely-supervised}, and
\emph{cross-IO} contexts. Our approach achieves state-of-the-art performance
across multiple sets of IOs originating from six countries, significantly
surpassing existing approaches. This research marks a step toward developing
Graph Foundation Models specifically tailored for the task of IO detection on
social media platforms.

摘要：社交媒體平台已成為公共論述的重要空間，作為現代廣場，各種聲音影響著社會敘事。然而，它們的開放性也使得它們容易受到惡意行為者的利用，包括國家資助的實體，他們可以進行信息操作 (IO) 以操縱輿論。錯誤信息的傳播、虛假新聞和誤導性說法威脅著民主進程和社會凝聚力，因此制定及時檢測虛假活動以保護在線論述的完整性的方法至關重要。在這項工作中，我們介紹了一種方法，旨在識別在各種影響力運動中策劃信息行動的用戶，即所謂的「IO 驅動程序」。我們的框架名為 \texttt{IOHunter}，它利用語言模型和圖神經網路的綜合優勢來改善「監督」、「稀疏監督」和「跨 IO」情境中的泛化能力。我們的做法在來自六個國家的多組 IO 中實現了最先進的性能，顯著超越了現有方法。這項研究標誌著專門針對社交媒體平台上的 IO 檢測任務開發圖基礎模型邁出了一步。

##### **GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question Answering**
2412.14480v1 by Saumya Saxena, Blake Buchanan, Chris Paxton, Bingqing Chen, Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer

In Embodied Question Answering (EQA), agents must explore and develop a
semantic understanding of an unseen environment in order to answer a situated
question with confidence. This remains a challenging problem in robotics, due
to the difficulties in obtaining useful semantic representations, updating
these representations online, and leveraging prior world knowledge for
efficient exploration and planning. Aiming to address these limitations, we
propose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic
scene graphs (3DSGs) and task relevant images as multi-modal memory for
grounding Vision-Language Models (VLMs) to perform EQA tasks in unseen
environments. We employ a hierarchical planning approach that exploits the
hierarchical nature of 3DSGs for structured planning and semantic-guided
exploration. Through experiments in simulation on the HM-EQA dataset and in the
real world in home and office environments, we demonstrate that our method
outperforms key baselines by completing EQA tasks with higher success rates and
fewer planning steps.

摘要：在具身問答 (EQA) 中，代理必須探索並發展對未見過環境的語義理解，才能有信心地回答情境問題。由於難以取得有用的語義表示、線上更新這些表示，以及利用先前的世界知識進行有效率的探索和規劃，這在機器人學中仍然是一個具有挑戰性的問題。為了解決這些限制，我們提出 GraphEQA，一種利用即時 3D 度量語義場景圖 (3DSG) 和與任務相關的影像作為多模式記憶體的新穎方法，以接地視覺語言模型 (VLM) 來執行未見過環境中的 EQA 任務。我們採用分層規劃方法，利用 3DSG 的分層性質進行結構化規劃和語義引導探索。透過在 HM-EQA 資料集上的模擬實驗，以及在家庭和辦公室環境中的真實世界中，我們證明我們的模型透過以較高的成功率和較少的規劃步驟完成 EQA 任務，優於主要的基線。

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

摘要：因果發現對於理解複雜系統至關重要，但傳統方法通常依賴於強而不可測試的假設，這使得這個過程充滿挑戰。大型語言模型 (LLM) 提供了一個從基於文本的元數據中提取因果見解的有希望的替代方案，它整合了領域專業知識。然而，LLM 容易出現不可靠性和幻覺，這需要考慮其限制的策略。一種這樣的策略涉及利用一致性度量來評估可靠性。此外，大多數文本元數據並未清楚地區分直接因果關係和間接因果關係，這進一步複雜化了因果圖的推論。因此，專注於因果順序，而不是因果圖，成為一種更實用、更穩健的方法。我們提出了一種新方法來推導無環錦標賽的分布（表示合理的因果順序），這最大化了一致性分數。我們的做法首先計算變量之間成對的一致性分數，產生一個彙總這些分數的循環錦標賽。從這個結構中，我們識別出與原始錦標賽相容的最佳無環錦標賽，優先考慮那些在所有配置中最大化一致性的錦標賽。我們在經典且完善的基準以及來自流行病學和公共衛生的真實世界數據集上測試了我們的模型。我們的結果證明了我們的方法在以最小誤差恢復因果順序分布方面的有效性。

##### **DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs**
2412.13964v1 by Stefano M. Nicoletti, E. Moritz Hahn, Mattia Fumagalli, Giancarlo Guizzardi, Mariëlle Stoelinga

When considering risky events or actions, we must not downplay the role of
involved objects: a charged battery in our phone averts the risk of being
stranded in the desert after a flat tyre, and a functional firewall mitigates
the risk of a hacker intruding the network. The Common Ontology of Value and
Risk (COVER) highlights how the role of objects and their relationships remains
pivotal to performing transparent, complete and accountable risk assessment. In
this paper, we operationalize some of the notions proposed by COVER -- such as
parthood between objects and participation of objects in events/actions -- by
presenting a new framework for risk assessment: DODGE. DODGE enriches the
expressivity of vetted formal models for risk -- i.e., fault trees and attack
trees -- by bridging the disciplines of ontology and formal methods into an
ontology-aware formal framework composed by a more expressive modelling
formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an
intermediate query language (ODGLang). With these, DODGE allows risk assessors
to pose questions about disruption propagation, disruption likelihood and risk
levels, keeping the fundamental role of objects at risk always in sight.

摘要：在考量高風險事件或行動時，我們不能低估所涉物件的角色：手機中的充電電池可避免在爆胎後受困沙漠的風險，而功能正常的防火牆則可降低駭客入侵網路的風險。價值與風險的共用本体論 (COVER) 強調物件及其關係的角色，對於執行透明、完整且負責任的風險評估仍然至關重要。在本文中，我們將 COVER 所提出的部分概念（例如物件之間的組成部分關係，以及物件參與事件/行動）具體化，藉由提出一個新的風險評估架構：DODGE。DODGE 透過將本体論與形式化方法橋接至一個本体論感知形式化架構中，豐富了風險驗證形式化模型（例如故障樹和攻擊樹）的表達力，該架構由更具表達力的建模形式主義、物件導向中斷圖 (ODG)、邏輯 (ODGLog) 和一個中間查詢語言 (ODGLang) 組成。透過這些，DODGE 讓風險評估者能夠提出有關中斷傳播、中斷可能性和風險層級的問題，同時始終保持對風險物件的基本角色的關注。

##### **Knowledge Editing with Dynamic Knowledge Graphs for Multi-hop Question Answering**
2412.13782v1 by Yifan Lu, Yigeng Zhou, Jing Li, Yequan Wang, Xuebo Liu, Daojing He, Fangming Liu, Min Zhang

Multi-hop question answering (MHQA) poses a significant challenge for large
language models (LLMs) due to the extensive knowledge demands involved.
Knowledge editing, which aims to precisely modify the LLMs to incorporate
specific knowledge without negatively impacting other unrelated knowledge,
offers a potential solution for addressing MHQA challenges with LLMs. However,
current solutions struggle to effectively resolve issues of knowledge
conflicts. Most parameter-preserving editing methods are hindered by inaccurate
retrieval and overlook secondary editing issues, which can introduce noise into
the reasoning process of LLMs. In this paper, we introduce KEDKG, a novel
knowledge editing method that leverages a dynamic knowledge graph for MHQA,
designed to ensure the reliability of answers. KEDKG involves two primary
steps: dynamic knowledge graph construction and knowledge graph augmented
generation. Initially, KEDKG autonomously constructs a dynamic knowledge graph
to store revised information while resolving potential knowledge conflicts.
Subsequently, it employs a fine-grained retrieval strategy coupled with an
entity and relation detector to enhance the accuracy of graph retrieval for LLM
generation. Experimental results on benchmarks show that KEDKG surpasses
previous state-of-the-art models, delivering more accurate and reliable answers
in environments with dynamic information.

摘要：多跳問題回答 (MHQA) 由於涉及廣泛的知識需求，對大型語言模型 (LLM) 構成重大挑戰。知識編輯旨在精確修改 LLM 以納入特定知識，而不會對其他不相關的知識產生負面影響，為了解決 LLM 的 MHQA 挑戰提供了潛在的解決方案。然而，目前的解決方案難以有效解決知識衝突的問題。大多數參數保留編輯方法受到不準確檢索的阻礙，並且忽視了次要編輯問題，這可能會在 LLM 的推理過程中引入雜訊。在本文中，我們介紹了 KEDKG，這是一種新穎的知識編輯方法，它利用動態知識圖譜進行 MHQA，旨在確保答案的可靠性。KEDKG 涉及兩個主要步驟：動態知識圖譜構建和知識圖譜增強生成。最初，KEDKG 自主構建動態知識圖譜以儲存修改後的資訊，同時解決潛在的知識衝突。隨後，它採用精細的檢索策略，結合實體和關係檢測器，以增強 LLM 生成的圖譜檢索的準確性。基準上的實驗結果表明，KEDKG 超越了以前最先進的模型，在動態資訊環境中提供了更準確和可靠的答案。

##### **Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models**
2412.13544v1 by Zheng Hu, Zhe Li, Ziyun Jiao, Satoshi Nakagawa, Jiawen Deng, Shimin Cai, Tao Zhou, Fuji Ren

In recent years, knowledge graphs have been integrated into recommender
systems as item-side auxiliary information, enhancing recommendation accuracy.
However, constructing and integrating structural user-side knowledge remains a
significant challenge due to the improper granularity and inherent scarcity of
user-side features. Recent advancements in Large Language Models (LLMs) offer
the potential to bridge this gap by leveraging their human behavior
understanding and extensive real-world knowledge. Nevertheless, integrating
LLM-generated information into recommender systems presents challenges,
including the risk of noisy information and the need for additional knowledge
transfer. In this paper, we propose an LLM-based user-side knowledge inference
method alongside a carefully designed recommendation framework to address these
challenges. Our approach employs LLMs to infer user interests based on
historical behaviors, integrating this user-side information with item-side and
collaborative data to construct a hybrid structure: the Collaborative Interest
Knowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation
framework that includes a user interest reconstruction module and a
cross-domain contrastive learning module to mitigate potential noise and
facilitate knowledge transfer. We conduct extensive experiments on three
real-world datasets to validate the effectiveness of our method. Our approach
achieves state-of-the-art performance compared to competitive baselines,
particularly for users with sparse interactions.

摘要：近年來，知識圖譜已整合到推薦系統中，作為項目側輔助資訊，提升推薦準確度。
然而，由於使用者側特徵的粒度不當和內在稀少性，建構和整合結構化使用者側知識仍然是一項重大挑戰。
大型語言模型 (LLM) 的最新進展提供了彌合此差距的潛力，方法是利用它們對人類行為的理解和廣泛的真實世界知識。
儘管如此，將 LLM 生成的資訊整合到推薦系統中會帶來挑戰，包括雜訊資訊的風險和需要額外的知識轉移。
在本文中，我們提出了一種基於 LLM 的使用者側知識推論方法，以及一個精心設計的推薦架構，以應對這些挑戰。
我們的做法採用 LLM 來推論基於歷史行為的使用者興趣，將此使用者側資訊與項目側和協作資料整合起來，以建構一個混合結構：協作興趣知識圖譜 (CIKG)。
此外，我們提出了一個基於 CIKG 的推薦架構，其中包括使用者興趣重建模組和跨網域對比學習模組，以減輕潛在雜訊並促進知識轉移。
我們對三個真實世界資料集進行了廣泛的實驗，以驗證我們方法的有效性。
與競爭基準相比，我們的做法達到了最先進的效能，特別是對於互動稀疏的使用者。

##### **Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning**
2412.13540v1 by Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Min Zhang

Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across diverse tasks. Despite great success, recent studies show that LVLMs
encounter substantial limitations when engaging with visual graphs. To study
the reason behind these limitations, we propose VGCure, a comprehensive
benchmark covering 22 tasks for examining the fundamental graph understanding
and reasoning capacities of LVLMs. Extensive evaluations conducted on 14 LVLMs
reveal that LVLMs are weak in basic graph understanding and reasoning tasks,
particularly those concerning relational or structurally complex information.
Based on this observation, we propose a structure-aware fine-tuning framework
to enhance LVLMs with structure learning abilities through 3 self-supervised
learning tasks. Experiments validate the effectiveness of our method in
improving LVLMs' zero-shot performance on fundamental graph learning tasks, as
well as enhancing the robustness of LVLMs against complex visual graphs.

摘要：大型視覺語言模型 (LVLMs) 已在各種任務中展現出非凡的表現。儘管獲得巨大的成功，最近的研究顯示，LVLMs 在處理視覺圖形時會遇到重大的限制。為了研究這些限制背後的原因，我們提出了 VGCure，這是一個涵蓋 22 項任務的綜合基準，用於檢查 LVLMs 的基本圖形理解和推理能力。對 14 個 LVLMs 進行的廣泛評估顯示，LVLMs 在基本的圖形理解和推理任務中較弱，特別是那些涉及關係或結構複雜資訊的任務。基於此觀察，我們提出了一個結構感知微調框架，以透過 3 個自我監督學習任務來增強 LVLMs 的結構學習能力。實驗驗證了我們的方法在提升 LVLMs 在基本圖形學習任務上的零次學習表現的有效性，以及增強 LVLMs 對複雜視覺圖形的魯棒性。

##### **Transducer Tuning: Efficient Model Adaptation for Software Tasks Using Code Property Graphs**
2412.13467v1 by Imam Nur Bani Yusuf, Lingxiao Jiang

Large language models have demonstrated promising performance across various
software engineering tasks. While fine-tuning is a common practice to adapt
these models for downstream tasks, it becomes challenging in
resource-constrained environments due to increased memory requirements from
growing trainable parameters in increasingly large language models. We
introduce \approach, a technique to adapt large models for downstream code
tasks using Code Property Graphs (CPGs). Our approach introduces a modular
component called \transducer that enriches code embeddings with structural and
dependency information from CPGs. The Transducer comprises two key components:
Graph Vectorization Engine (GVE) and Attention-Based Fusion Layer (ABFL). GVE
extracts CPGs from input source code and transforms them into graph feature
vectors. ABFL then fuses those graphs feature vectors with initial code
embeddings from a large language model. By optimizing these transducers for
different downstream tasks, our approach enhances the models without the need
to fine-tune them for specific tasks. We have evaluated \approach on three
downstream tasks: code summarization, assert generation, and code translation.
Our results demonstrate competitive performance compared to full parameter
fine-tuning while reducing up to 99\% trainable parameters to save memory.
\approach also remains competitive against other fine-tuning approaches (e.g.,
LoRA, Prompt-Tuning, Prefix-Tuning) while using only 1.5\%-80\% of their
trainable parameters. Our findings show that integrating structural and
dependency information through Transducer Tuning enables more efficient model
adaptation, making it easier for users to adapt large models in
resource-constrained settings.

摘要：大型語言模型已在各種軟體工程任務中展現出令人滿意的效能。雖然微調是調整這些模型以執行下游任務的常見做法，但由於大型語言模型中可訓練參數不斷增加，導致記憶體需求增加，因此在資源受限的環境中變得具有挑戰性。我們引入了 \approach，這是一種使用程式碼屬性圖 (CPG) 來調整大型模型以執行下游程式碼任務的技術。我們的做法引入了稱為 \transducer 的模組化元件，它使用來自 CPG 的結構和依賴關係資訊來豐富程式碼嵌入。Transducer 包含兩個關鍵元件：圖向量化引擎 (GVE) 和基於注意力的融合層 (ABFL)。GVE 從輸入原始碼中萃取 CPG，並將它們轉換為圖形特徵向量。ABFL 接著將這些圖形特徵向量與來自大型語言模型的初始程式碼嵌入融合。透過針對不同的下游任務最佳化這些轉換器，我們的做法增強了模型，而無需針對特定任務進行微調。我們已在三個下游任務中評估 \approach：程式碼摘要、斷言產生和程式碼翻譯。我們的結果顯示，與完全參數微調相比，具有競爭力的效能，同時減少了多達 99% 的可訓練參數以節省記憶體。\approach 在僅使用 1.5% - 80% 可訓練參數的情況下，仍然在與其他微調方法（例如 LoRA、Prompt-Tuning、Prefix-Tuning）的競爭中保持競爭力。我們的發現表明，透過 Transducer Tuning 整合結構和依賴關係資訊可以實現更有效率的模型調整，使用戶更容易在資源受限的設定中調整大型模型。

##### **Enhancing Persona Classification in Dialogue Systems: A Graph Neural Network Approach**
2412.13283v1 by Konstantin Zaitsev

In recent years, Large Language Models (LLMs) gain considerable attention for
their potential to enhance personalized experiences in virtual assistants and
chatbots. A key area of interest is the integration of personas into LLMs to
improve dialogue naturalness and user engagement. This study addresses the
challenge of persona classification, a crucial component in dialogue
understanding, by proposing a framework that combines text embeddings with
Graph Neural Networks (GNNs) for effective persona classification. Given the
absence of dedicated persona classification datasets, we create a manually
annotated dataset to facilitate model training and evaluation. Our method
involves extracting semantic features from persona statements using text
embeddings and constructing a graph where nodes represent personas and edges
capture their similarities. The GNN component uses this graph structure to
propagate relevant information, thereby improving classification performance.
Experimental results show that our approach, in particular the integration of
GNNs, significantly improves classification performance, especially with
limited data. Our contributions include the development of a persona
classification framework and the creation of a dataset.

摘要：近年來，大型語言模型 (LLM) 因其增強虛擬助理和聊天機器人中個人化體驗的潛力而備受關注。一個關鍵的興趣領域是將角色融入 LLM，以改善對話的自然性和使用者參與度。本研究探討角色分類的挑戰，這是對話理解中的關鍵組成部分，提出一個結合文本嵌入與圖神經網路 (GNN) 的架構，以進行有效的角色分類。鑑於缺乏專用的角色分類資料集，我們建立了一個手動標註的資料集，以利於模型訓練和評估。我們的方法包括使用文本嵌入從角色陳述中提取語義特徵，並建構一個圖，其中節點表示角色，而邊緣捕捉它們的相似性。GNN 組件使用這個圖結構來傳播相關資訊，從而改善分類效能。實驗結果顯示，我們的方法，特別是 GNN 的整合，顯著改善了分類效能，特別是在資料有限的情況下。我們的貢獻包括開發角色分類架構和建立資料集。

##### **SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation**
2412.15272v1 by Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng

Recent advancements in large language models (LLMs) have shown impressive
versatility across various tasks. To eliminate its hallucinations,
retrieval-augmented generation (RAG) has emerged as a powerful approach,
leveraging external knowledge sources like knowledge graphs (KGs). In this
paper, we study the task of KG-driven RAG and propose a novel Similar Graph
Enhanced Retrieval-Augmented Generation (SimGRAG) method. It effectively
addresses the challenge of aligning query texts and KG structures through a
two-stage process: (1) query-to-pattern, which uses an LLM to transform queries
into a desired graph pattern, and (2) pattern-to-subgraph, which quantifies the
alignment between the pattern and candidate subgraphs using a graph semantic
distance (GSD) metric. We also develop an optimized retrieval algorithm that
efficiently identifies the top-$k$ subgraphs within 1-second latency on a
10-million-scale KG. Extensive experiments show that SimGRAG outperforms
state-of-the-art KG-driven RAG methods in both question answering and fact
verification, offering superior plug-and-play usability and scalability.

摘要：大型語言模型（LLM）的最新進展在各種任務中展現出令人印象深刻的多功能性。為了消除其幻覺，擷取增強生成（RAG）已成為一種強大的方法，利用外部知識來源，例如知識圖譜（KG）。在本文中，我們研究了 KG 驅動 RAG 的任務，並提出了一種新穎的類似圖形增強擷取增強生成（SimGRAG）方法。它通過一個兩階段過程有效地應對了對齊查詢文本和 KG 結構的挑戰：(1) 查詢到模式，它使用 LLM 將查詢轉換為所需的圖形模式，以及 (2) 模式到子圖，它使用圖形語義距離 (GSD) 度量來量化模式和候選子圖之間的對齊。我們還開發了一種最佳化的擷取演算法，可以在 1000 萬規模的 KG 上以 1 秒的延遲有效地識別前 $k$ 個子圖。大量的實驗表明，SimGRAG 在問答和事實驗證方面都優於最先進的 KG 驅動 RAG 方法，提供了卓越的即插即用可用性和可擴展性。

##### **Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning**
2412.12808v2 by Ziqi Qiu, Jianxing Yu, Yufeng Zhang, Hanjiang Lai, Yanghui Rao, Qinliang Su, Jian Yin

This paper focuses on sarcasm detection, which aims to identify whether given
statements convey criticism, mockery, or other negative sentiment opposite to
the literal meaning. To detect sarcasm, humans often require a comprehensive
understanding of the semantics in the statement and even resort to external
commonsense to infer the fine-grained incongruity. However, existing methods
lack commonsense inferential ability when they face complex real-world
scenarios, leading to unsatisfactory performance. To address this problem, we
propose a novel framework for sarcasm detection, which conducts incongruity
reasoning based on commonsense augmentation, called EICR. Concretely, we first
employ retrieval-augmented large language models to supplement the missing but
indispensable commonsense background knowledge. To capture complex contextual
associations, we construct a dependency graph and obtain the optimized topology
via graph refinement. We further introduce an adaptive reasoning skeleton that
integrates prior rules to extract sentiment-inconsistent subgraphs explicitly.
To eliminate the possible spurious relations between words and labels, we
employ adversarial contrastive learning to enhance the robustness of the
detector. Experiments conducted on five datasets demonstrate the effectiveness
of EICR.

摘要：本文重点关注讽刺检测，其旨在识别给定的陈述是否传达了与字面意思相反的批评、嘲讽或其他消极情绪。为了检测讽刺，人类通常需要全面理解陈述中的语义，甚至诉诸外部常识来推断细粒度的矛盾。然而，现有方法在面对复杂的现实世界场景时缺乏常识推理能力，导致性能不佳。为了解决这个问题，我们提出了一种用于讽刺检测的新型框架，该框架基于常识增强进行不一致推理，称为 EICR。具体来说，我们首先采用检索增强的大语言模型来补充缺失但不可或缺的常识背景知识。为了捕捉复杂的上下文关联，我们构建了一个依赖图，并通过图细化获得了优化的拓扑。我们进一步引入了一个自适应推理框架，该框架集成了先验规则，以明确提取情绪不一致的子图。为了消除单词和标签之间可能的虚假关系，我们采用对抗对比学习来增强检测器的鲁棒性。在五个数据集上进行的实验证明了 EICR 的有效性。

##### **LLM-based Discriminative Reasoning for Knowledge Graph Question Answering**
2412.12643v1 by Mufan Xu, Kehai Chen, Xuefeng Bai, Muyun Yang, Tiejun Zhao, Min Zhang

Large language models (LLMs) based on generative pre-trained Transformer have
achieved remarkable performance on knowledge graph question-answering (KGQA)
tasks. However, LLMs often produce ungrounded subgraph planning or reasoning
results in KGQA due to the hallucinatory behavior brought by the generative
paradigm, which may hinder the advancement of the LLM-based KGQA model. To deal
with the issue, we propose a novel LLM-based Discriminative Reasoning (LDR)
method to explicitly model the subgraph retrieval and answer inference process.
By adopting discriminative strategies, the proposed LDR method not only
enhances the capability of LLMs to retrieve question-related subgraphs but also
alleviates the issue of ungrounded reasoning brought by the generative paradigm
of LLMs. Experimental results show that the proposed approach outperforms
multiple strong comparison methods, along with achieving state-of-the-art
performance on two widely used WebQSP and CWQ benchmarks.

摘要：大型語言模型（LLM）基於生成式預訓練 Transformer，在知識圖譜問答（KGQA）任務上已取得顯著的成效。然而，由於生成式範例帶來的幻覺行為，LLM 在 KGQA 中經常產生無根據的子圖規劃或推理結果，這可能會阻礙基於 LLM 的 KGQA 模型的進展。為了解決這個問題，我們提出了一種新穎的基於 LLM 的判別推理（LDR）方法，以明確建模子圖檢索和答案推論過程。通過採用判別策略，所提出的 LLM 方法不僅增強了 LLM 檢索與問題相關的子圖的能力，而且還緩解了 LLM 的生成式範例帶來的無根據推理問題。實驗結果表明，所提出的方法優於多種強大的比較方法，同時在兩個廣泛使用的 WebQSP 和 CWQ 基準測試中取得了最先進的效能。

##### **SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs**
2412.12612v1 by Aman Tiwari, Shiva Krishna Reddy Malay, Vikas Yadav, Masoud Hashemi, Sathwik Tejaswi Madhusudhan

Cypher, the query language for Neo4j graph databases, plays a critical role
in enabling graph-based analytics and data exploration. While substantial
research has been dedicated to natural language to SQL query generation
(Text2SQL), the analogous problem for graph databases referred to as
Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a
fully synthetic and automated data generation pipeline designed to address this
gap. SynthCypher employs a novel LLMSupervised Generation-Verification
framework, ensuring syntactically and semantically correct Cypher queries
across diverse domains and query complexities. Using this pipeline, we create
SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher
instances. Fine-tuning open-source large language models (LLMs), including
LLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant
performance improvements of up to 40% on the Text2Cypher test set and 30% on
the SPIDER benchmark adapted for graph databases. This work demonstrates that
high-quality synthetic data can effectively advance the state-of-the-art in
Text2Cypher tasks.

摘要：Cypher 是 Neo4j 圖形資料庫的查詢語言，在啟用以圖形為基礎的分析和資料探索方面發揮著至關重要的作用。儘管已經投入大量研究將自然語言轉換為 SQL 查詢生成 (Text2SQL)，但稱為 Text2Cypher 的圖形資料庫類比問題仍未得到充分探討。在這項工作中，我們介紹了 SynthCypher，這是一個完全合成且自動化的資料生成管道，旨在解決這個差距。SynthCypher 採用了一種新穎的 LLMSupervised 生成驗證框架，確保了跨越不同領域和查詢複雜性的 Cypher 查詢在語法和語義上正確。使用這個管道，我們創建了 SynthCypher 資料集，這是一個包含 29.8k Text2Cypher 實例的大規模基準。微調開源大型語言模型 (LLM)，包括 SynthCypher 上的 LLaMa-3.1- 8B、Mistral-7B 和 QWEN-7B，在 Text2Cypher 測試集中產生了高達 40% 的顯著性能提升，在適用於圖形資料庫的 SPIDER 基準上提升了 30%。這項工作證明了高品質的合成資料可以有效地推動 Text2Cypher 任務的最新技術。

##### **Enhancing LLM-based Hatred and Toxicity Detection with Meta-Toxic Knowledge Graph**
2412.15268v2 by Yibo Zhao, Jiapeng Zhu, Can Xu, Xiang Li

The rapid growth of social media platforms has raised significant concerns
regarding online content toxicity. When Large Language Models (LLMs) are used
for toxicity detection, two key challenges emerge: 1) the absence of
domain-specific toxic knowledge leads to false negatives; 2) the excessive
sensitivity of LLMs to toxic speech results in false positives, limiting
freedom of speech. To address these issues, we propose a novel method called
MetaTox, leveraging graph search on a meta-toxic knowledge graph to enhance
hatred and toxicity detection. First, we construct a comprehensive meta-toxic
knowledge graph by utilizing LLMs to extract toxic information through a
three-step pipeline, with toxic benchmark datasets serving as corpora. Second,
we query the graph via retrieval and ranking processes to supplement accurate,
relevant toxic knowledge. Extensive experiments and in-depth case studies
across multiple datasets demonstrate that our MetaTox significantly decreases
the false positive rate while boosting overall toxicity detection performance.
Our code will be available soon.

摘要：社群媒體平台快速成長，對於線上內容毒性引發高度關注。當大型語言模型 (LLM) 用於毒性偵測時，會出現兩個主要挑戰：1) 缺乏特定領域的毒性知識，導致假陰性；2) LLM 對毒性言論過度敏感，導致假陽性，限制言論自由。為了解決這些問題，我們提出了一種名為 MetaTox 的新方法，利用圖形搜尋在元毒性知識圖譜上，以增強仇恨和毒性偵測。首先，我們透過 LLM 利用三步驟管線萃取毒性資訊，建構全面的元毒性知識圖譜，並以毒性基準資料集作為語料庫。其次，我們透過檢索和排名程序查詢圖形，以補充準確且相關的毒性知識。跨多個資料集的廣泛實驗和深入案例研究顯示，我們的 MetaTox 大幅降低假陽性率，同時提升整體毒性偵測效能。我們的程式碼將很快提供。

##### **Graph Learning in the Era of LLMs: A Survey from the Perspective of Data, Models, and Tasks**
2412.12456v1 by Xunkai Li, Zhengyu Wu, Jiayi Wu, Hanwen Cui, Jishuo Jia, Rong-Hua Li, Guoren Wang

With the increasing prevalence of cross-domain Text-Attributed Graph (TAG)
Data (e.g., citation networks, recommendation systems, social networks, and
ai4science), the integration of Graph Neural Networks (GNNs) and Large Language
Models (LLMs) into a unified Model architecture (e.g., LLM as enhancer, LLM as
collaborators, LLM as predictor) has emerged as a promising technological
paradigm. The core of this new graph learning paradigm lies in the synergistic
combination of GNNs' ability to capture complex structural relationships and
LLMs' proficiency in understanding informative contexts from the rich textual
descriptions of graphs. Therefore, we can leverage graph description texts with
rich semantic context to fundamentally enhance Data quality, thereby improving
the representational capacity of model-centric approaches in line with
data-centric machine learning principles. By leveraging the strengths of these
distinct neural network architectures, this integrated approach addresses a
wide range of TAG-based Task (e.g., graph learning, graph reasoning, and graph
question answering), particularly in complex industrial scenarios (e.g.,
supervised, few-shot, and zero-shot settings). In other words, we can treat
text as a medium to enable cross-domain generalization of graph learning Model,
allowing a single graph model to effectively handle the diversity of downstream
graph-based Task across different data domains. This work serves as a
foundational reference for researchers and practitioners looking to advance
graph learning methodologies in the rapidly evolving landscape of LLM. We
consistently maintain the related open-source materials at
\url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers}.

摘要：<paragraph>隨著跨領域文本屬性圖 (TAG) 資料（例如引文網路、推薦系統、社交網路和 ai4science）的日益普及，將圖神經網路 (GNN) 和大型語言模型 (LLM) 整合到統一的模型架構（例如，LLM 作為增強器、LLM 作為協作者、LLM 作為預測器）中已成為一種有前途的技術典範。這種新的圖形學習典範的核心在於 GNN 捕捉複雜結構關係的能力與 LLM 從圖形的豐富文字描述中理解資訊豐富背景的熟練度的協同組合。因此，我們可以利用具有豐富語義背景的圖形描述文字，從根本上提升資料品質，從而改善以模型為中心的途徑的表示能力，並符合以資料為中心的機器學習原則。透過利用這些不同的神經網路架構的優點，這種整合方法解決了廣泛的基於 TAG 的任務（例如，圖形學習、圖形推理和圖形問答），特別是在複雜的產業場景（例如，監督式、少樣本和零樣本設定）中。換句話說，我們可以將文字視為一種媒介，以實現圖形學習模型的跨領域泛化，讓單一圖形模型能夠有效地處理不同資料領域中下游基於圖形的任務的多樣性。這項工作作為研究人員和實務工作者的基礎參考，他們希望在 LLM 快速演變的環境中推進圖形學習方法。我們持續在 \url{https://github.com/xkLi-Allen/Awesome-GNN-in-LLMs-Papers} 維護相關的開放原始碼資料。</paragraph>

##### **Graph-Guided Textual Explanation Generation Framework**
2412.12318v1 by Shuzhou Yuan, Jingyi Sun, Ran Zhang, Michael Färber, Steffen Eger, Pepa Atanasova, Isabelle Augenstein

Natural language explanations (NLEs) are commonly used to provide plausible
free-text explanations of a model's reasoning about its predictions. However,
recent work has questioned the faithfulness of NLEs, as they may not accurately
reflect the model's internal reasoning process regarding its predicted answer.
In contrast, highlight explanations -- input fragments identified as critical
for the model's predictions -- exhibit measurable faithfulness, which has been
incrementally improved through existing research. Building on this foundation,
we propose G-Tex, a Graph-Guided Textual Explanation Generation framework
designed to enhance the faithfulness of NLEs by leveraging highlight
explanations. Specifically, highlight explanations are extracted as highly
faithful cues representing the model's reasoning and are subsequently encoded
through a graph neural network layer, which explicitly guides the NLE
generation process. This alignment ensures that the generated explanations
closely reflect the model's underlying reasoning. Experiments on T5 and BART
using three reasoning datasets show that G-Tex improves NLE faithfulness by up
to 17.59% compared to baseline methods. Additionally, G-Tex generates NLEs with
greater semantic and lexical similarity to human-written ones. Human
evaluations show that G-Tex can decrease redundant content and enhance the
overall quality of NLEs. As our work introduces a novel method for explicitly
guiding NLE generation to improve faithfulness, we hope it will serve as a
stepping stone for addressing additional criteria for NLE and generated text
overall.

摘要：自然語言解釋 (NLE) 常用於提供模型對其預測的合理解釋。然而，最近的研究質疑 NLE 的忠實度，因為它們可能無法準確反映模型在其預測答案上的內部推理過程。相反，重點解釋——被識別為對模型預測至關重要的輸入片段——表現出可衡量的忠實度，這已通過現有研究逐步得到改進。在此基礎上，我們提出了 G-Tex，一個圖形引導文本解釋生成框架，旨在通過利用重點解釋來增強 NLE 的忠實度。具體來說，重點解釋被提取為代表模型推理的高度忠實線索，然後通過圖神經網路層進行編碼，這明確指導了 NLE 生成過程。這種對齊確保生成的解釋緊密反映模型的底層推理。使用三個推理數據集對 T5 和 BART 進行的實驗表明，與基線方法相比，G-Tex 將 NLE 的忠實度提高了 17.59%。此外，G-Tex 生成的 NLE 與人類編寫的 NLE 在語義和詞彙上具有更高的相似性。人類評估表明，G-Tex 可以減少冗餘內容並提高 NLE 的整體品質。由於我們的研究引入了一種明確指導 NLE 生成的創新方法來提高忠實度，我們希望它將作為解決 NLE 和整體生成文本的附加標準的墊腳石。

##### **Cost-Effective Label-free Node Classification with LLMs**
2412.11983v1 by Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui Lai

Graph neural networks (GNNs) have emerged as go-to models for node
classification in graph data due to their powerful abilities in fusing graph
structures and attributes. However, such models strongly rely on adequate
high-quality labeled data for training, which are expensive to acquire in
practice. With the advent of large language models (LLMs), a promising way is
to leverage their superb zero-shot capabilities and massive knowledge for node
labeling. Despite promising results reported, this methodology either demands
considerable queries to LLMs, or suffers from compromised performance caused by
noisy labels produced by LLMs.
  To remedy these issues, this work presents Cella, an active self-training
framework that integrates LLMs into GNNs in a cost-effective manner. The design
recipe of Cella is to iteratively identify small sets of "critical" samples
using GNNs and extract informative pseudo-labels for them with both LLMs and
GNNs as additional supervision signals to enhance model training. Particularly,
Cella includes three major components: (i) an effective active node selection
strategy for initial annotations; (ii) a judicious sample selection scheme to
sift out the "critical" nodes based on label disharmonicity and entropy; and
(iii) a label refinement module combining LLMs and GNNs with rewired topology.
Our extensive experiments over five benchmark text-attributed graph datasets
demonstrate that Cella significantly outperforms the state of the arts under
the same query budget to LLMs in terms of label-free node classification. In
particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an
8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost
of less than one cent.

摘要：圖形神經網路 (GNN) 已成為圖形資料中節點分類的熱門模型，因為它們在融合圖形結構和屬性方面具有強大的能力。然而，此類模型在訓練時高度依賴足夠的高品質標籤資料，而這些資料在實務上取得的成本很高。隨著大型語言模型 (LLM) 的出現，一個有前途的方法是利用其卓越的零次學習能力和海量知識進行節點標籤。儘管報告了有希望的結果，但此方法不是需要大量查詢 LLM，就是會因為 LLM 產生的標籤有雜訊而導致效能受損。
為了解決這些問題，本研究提出 Cella，一個主動自訓練架構，以具有成本效益的方式將 LLM 整合到 GNN 中。Cella 的設計秘訣是使用 GNN 迭代識別小組「關鍵」樣本，並使用 LLM 和 GNN 作為額外的監督訊號，為這些樣本萃取有意義的偽標籤，以增強模型訓練。特別是，Cella 包含三個主要組成部分：(i) 一個有效的節點主動選擇策略，用於初始註解；(ii) 一個明智的樣本選擇方案，根據標籤不協調性和熵篩選出「關鍵」節點；以及 (iii) 一個結合 LLM 和 GNN 以及重新連線拓撲的標籤精緻模組。我們在五個基準文字屬性圖形資料集上進行的廣泛實驗表明，在相同的 LLM 查詢預算下，Cella 在無標籤節點分類方面顯著優於現有技術。特別是在具有 14.3k 個節點的 DBLP 資料集上，Cella 能夠以低於一美分的成本，在準確度上比現有技術顯著提升 8.08%。

##### **SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation**
2412.11652v1 by Tao Meng, Wei Ai, Jianbin Li, Ze Wang, Yuntao Shou, Keqin Li

Text representation learning is significant as the cornerstone of natural
language processing. In recent years, graph contrastive learning (GCL) has been
widely used in text representation learning due to its ability to represent and
capture complex text information in a self-supervised setting. However, current
mainstream graph contrastive learning methods often require the incorporation
of domain knowledge or cumbersome computations to guide the data augmentation
process, which significantly limits the application efficiency and scope of
GCL. Additionally, many methods learn text representations only by constructing
word-document relationships, which overlooks the rich contextual semantic
information in the text. To address these issues and exploit representative
textual semantics, we present an event-based, simple, and effective graph
contrastive learning (SE-GCL) for text representation. Precisely, we extract
event blocks from text and construct internal relation graphs to represent
inter-semantic interconnections, which can ensure that the most critical
semantic information is preserved. Then, we devise a streamlined, unsupervised
graph contrastive learning framework to leverage the complementary nature of
the event semantic and structural information for intricate feature data
capture. In particular, we introduce the concept of an event skeleton for core
representation semantics and simplify the typically complex data augmentation
techniques found in existing graph contrastive learning to boost algorithmic
efficiency. We employ multiple loss functions to prompt diverse embeddings to
converge or diverge within a confined distance in the vector space, ultimately
achieving a harmonious equilibrium. We conducted experiments on the proposed
SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to
verify its effectiveness in text representation learning.

摘要：文本表徵學習作為自然語言處理的基石，具有重要的意義。近年來，圖形對比學習 (GCL) 因其在自我監督設定中表徵和擷取複雜文本資訊的能力，而被廣泛用於文本表徵學習。然而，當前的主流圖形對比學習方法通常需要加入領域知識或繁瑣的運算來引導資料擴充程序，這顯著地限制了 GCL 的應用效率和範圍。此外，許多方法僅透過建構字詞文件關係來學習文本表徵，這忽略了文本中豐富的脈絡語義資訊。為了解決這些問題並運用具代表性的文本語義，我們提出了一種基於事件、簡單且有效的圖形對比學習 (SE-GCL) 來進行文本表徵。具體來說，我們從文本中萃取事件區塊並建構內部關係圖形來表徵語義間的相互連結，這能確保保留最關鍵的語義資訊。接著，我們設計了一個簡化的無監督圖形對比學習架構，以利用事件語義和結構資訊的互補特性來擷取複雜的特徵資料。特別地，我們引入了事件骨架的概念，用於核心表徵語義，並簡化現有圖形對比學習中通常複雜的資料擴充技術，以提升演算法效率。我們採用多重損失函數來促使不同的嵌入在向量空間中受限距離內收斂或發散，最終達成和諧的平衡。我們在四個標準資料集 (AG News、20NG、SougouNews 和 THUCNews) 上對所提出的 SE-GCL 進行了實驗，以驗證其在文本表徵學習中的有效性。

##### **EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations**
2412.11618v1 by Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin Wu, Man Lan

Current Large Language Models (LLMs) for understanding proteins primarily
treats amino acid sequences as a text modality. Meanwhile, Protein Language
Models (PLMs), such as ESM-2, have learned massive sequential evolutionary
knowledge from the universe of natural protein sequences. Furthermore,
structure-based encoders like ProteinMPNN learn the structural information of
proteins through Graph Neural Networks. However, whether the incorporation of
protein encoders can enhance the protein understanding of LLMs has not been
explored. To bridge this gap, we propose EvoLlama, a multimodal framework that
connects a structure-based encoder, a sequence-based protein encoder and an LLM
for protein understanding. EvoLlama consists of a ProteinMPNN structure
encoder, an ESM-2 protein sequence encoder, a multimodal projector to align
protein and text representations and a Llama-3 text decoder. To train EvoLlama,
we fine-tune it on protein-oriented instructions and protein property
prediction datasets verbalized via natural language instruction templates. Our
experiments show that EvoLlama's protein understanding capabilities have been
significantly enhanced, outperforming other fine-tuned protein-oriented LLMs in
zero-shot settings by an average of 1%-8% and surpassing the state-of-the-art
baseline with supervised fine-tuning by an average of 6%. On protein property
prediction datasets, our approach achieves promising results that are
competitive with state-of-the-art task-specific baselines. We will release our
code in a future version.

摘要：目前用於理解蛋白質的大型語言模型 (LLM) 主要將胺基酸序列視為文字形式。同時，蛋白質語言模型 (PLM)，例如 ESM-2，已從自然蛋白質序列的宇宙中學習到大量的順序進化知識。此外，像 ProteinMPNN 等基於結構的編碼器透過圖形神經網路學習蛋白質的結構資訊。然而，尚未探討結合蛋白質編碼器是否能增強 LLM 對蛋白質的理解。為了彌合這個差距，我們提出 EvoLlama，一個多模態架構，它結合一個基於結構的編碼器、一個基於序列的蛋白質編碼器和一個用於理解蛋白質的 LLM。EvoLlama 包含一個 ProteinMPNN 結構編碼器、一個 ESM-2 蛋白質序列編碼器、一個多模態投影器，用於對齊蛋白質和文字表徵，以及一個 Llama-3 文字解碼器。為了訓練 EvoLlama，我們針對蛋白質導向的指令和透過自然語言指令範本表達的蛋白質屬性預測資料集微調它。我們的實驗顯示，EvoLlama 的蛋白質理解能力已獲得顯著提升，在零次學習設定中，平均優於其他微調的蛋白質導向 LLM 1%-8%，並在有監督的微調中平均優於最先進的基準 6%。在蛋白質屬性預測資料集上，我們的做法達到了有希望的結果，與最先進的特定任務基準相當。我們將在未來版本中釋出我們的程式碼。

##### **Embodied CoT Distillation From LLM To Off-the-shelf Agents**
2412.11499v1 by Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo

We address the challenge of utilizing large language models (LLMs) for
complex embodied tasks, in the environment where decision-making systems
operate timely on capacity-limited, off-the-shelf devices. We present DeDer, a
framework for decomposing and distilling the embodied reasoning capabilities
from LLMs to efficient, small language model (sLM)-based policies. In DeDer,
the decision-making process of LLM-based strategies is restructured into a
hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is
distilled from the data that is generated through the embodied in-context
learning and self-verification of an LLM, so it can produce effective
rationales. The planning-policy, guided by the rationales, can render optimized
plans efficiently. In turn, DeDer allows for adopting sLMs for both policies,
deployed on off-the-shelf devices. Furthermore, to enhance the quality of
intermediate rationales, specific to embodied tasks, we devise the embodied
knowledge graph, and to generate multiple rationales timely through a single
inference, we also use the contrastively prompted attention model. Our
experiments with the ALFRED benchmark demonstrate that DeDer surpasses leading
language planning and distillation approaches, indicating the applicability and
efficiency of sLM-based embodied policies derived through DeDer.

摘要：我們解決了在決策系統於容量有限的現成設備上即時運作的環境中，利用大型語言模型 (LLM) 執行複雜具身任務的挑戰。我們提出 DeDer，一個用於將具身推理能力從 LLM 分解並萃取出高效能、小型語言模型 (sLM) 為基礎的政策的框架。在 DeDer 中，基於 LLM 的策略的決策流程被重新結構為一個具有推理政策和規劃政策的階層。推理政策從透過 LLM 的具身情境學習和自我驗證所產生的資料中萃取出，因此它可以產生有效的依據。規劃政策在依據的引導下，可以有效率地呈現最佳化的計畫。反過來，DeDer 允許採用 sLM 來執行這兩個政策，並部署在現成設備上。此外，為了提升中間依據的品質，特別是針對具身任務，我們設計了具身知識圖譜，並透過單一推論即時產生多個依據，我們也使用了對比提示注意力模型。我們使用 ALFRED 基準進行的實驗證明，DeDer 超越了領先的語言規劃和萃取方法，這表示透過 DeDer 衍生的基於 sLM 的具身政策具有適用性和效率。

##### **Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**
2412.15256v1 by Edward Kim, Manil Shrestha, Richard Foty, Tom DeLay, Vicki Seyfert-Margolis

Creation and curation of knowledge graphs can accelerate disease discovery
and analysis in real-world data. While disease ontologies aid in biological
data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture
patient condition nuances or rare diseases. Multiple disease definitions across
data sources complicate ontology mapping and disease clustering. We propose
creating patient knowledge graphs using large language model extraction
techniques, allowing data extraction via natural language rather than rigid
ontological hierarchies. Our method maps to existing ontologies (MeSH,
SNOMED-CT, RxNORM, HPO) to ground extracted entities.
  Using a large ambulatory care EHR database with 33.6M patients, we
demonstrate our method through the patient search for Dravet syndrome, which
received ICD10 recognition in October 2020. We describe our construction of
patient-specific knowledge graphs and symptom-based patient searches. Using
confirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based
entity extraction to characterize patients in grounded ontologies. We then
apply this method to identify Beta-propeller protein-associated
neurodegeneration (BPAN) patients, demonstrating real-world discovery where no
ground truth exists.

摘要：知識圖譜的建立和策展可以加速疾病發現和分析真實世界中的資料。雖然疾病本體論有助於生物資料註釋，但編碼類別（SNOMED-CT、ICD10、CPT）可能無法捕捉患者狀況的細微差別或罕見疾病。跨資料來源的多重疾病定義使本體論對應和疾病群集複雜化。我們建議使用大型語言模型萃取技術建立患者知識圖譜，允許透過自然語言而不是僵化的本體論階層萃取資料。我們的模型對應到現有本體論（MeSH、SNOMED-CT、RxNORM、HPO）以建立萃取實體的基礎。使用一個擁有 3360 萬名患者的大型門診電子病歷資料庫，我們透過患者搜尋 Dravet 症候群來展示我們的模型，該症候群於 2020 年 10 月獲得 ICD10 認可。我們描述我們如何建構患者特定的知識圖譜和基於症狀的患者搜尋。使用已確認的 Dravet 症候群 ICD10 代碼作為基準，我們使用基於 LLM 的實體萃取來描述紮根於本體論中的患者。然後我們應用此模型來識別貝塔螺旋槳蛋白相關的神經退化（BPAN）患者，展示了在不存在基準的情況下進行真實世界發現。

##### **How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach**
2412.11387v1 by Abdulrahman Althobaiti, Angel Ayala, JingYing Gao, Ali Almutairi, Mohammad Deghat, Imran Razzak, Francisco Cruz

Large Language Models (LLMs) are transforming the robotics domain by enabling
robots to comprehend and execute natural language instructions. The cornerstone
benefits of LLM include processing textual data from technical manuals,
instructions, academic papers, and user queries based on the knowledge
provided. However, deploying LLM-generated code in robotic systems without
safety verification poses significant risks. This paper outlines a safety layer
that verifies the code generated by ChatGPT before executing it to control a
drone in a simulated environment. The safety layer consists of a fine-tuned
GPT-4o model using Few-Shot learning, supported by knowledge graph prompting
(KGP). Our approach improves the safety and compliance of robotic actions,
ensuring that they adhere to the regulations of drone operations.

摘要：大型語言模型 (LLM) 透過讓機器人理解並執行自然語言指令，轉變了機器人領域。LLM 的基石優點包括處理基於所提供知識的技術手冊、說明、學術論文和使用者查詢中的文字資料。然而，在沒有安全驗證的情況下，在機器人系統中部署 LLM 生成的程式碼會帶來顯著的風險。本文概述了一個安全層，在執行它以控制模擬環境中的無人機之前，驗證 ChatGPT 生成的程式碼。安全層由一個使用少次學習進行微調的 GPT-4o 模型組成，並由知識圖表提示 (KGP) 支援。我們的做法改善了機器人動作的安全性與合規性，確保它們符合無人機操作法規。

##### **Embracing Large Language Models in Traffic Flow Forecasting**
2412.12201v1 by Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang

Traffic flow forecasting aims to predict future traffic flows based on the
historical traffic conditions and the road network. It is an important problem
in intelligent transportation systems, with a plethora of methods been
proposed. Existing efforts mainly focus on capturing and utilizing
spatio-temporal dependencies to predict future traffic flows. Though promising,
they fall short in adapting to test-time environmental changes of traffic
conditions. To tackle this challenge, we propose to introduce large language
models (LLMs) to help traffic flow forecasting and design a novel method named
Large Language Model Enhanced Traffic Flow Predictor (LEAF). LEAF adopts two
branches, capturing different spatio-temporal relations using graph and
hypergraph structures respectively. The two branches are first pre-trained
individually, and during test-time, they yield different predictions. Based on
these predictions, a large language model is used to select the most likely
result. Then, a ranking loss is applied as the learning objective to enhance
the prediction ability of the two branches. Extensive experiments on several
datasets demonstrate the effectiveness of the proposed LEAF.

摘要：交通流量預測旨在根據歷史交通狀況和道路網路預測未來的交通流量。這是智慧運輸系統中一個重要的問題，已經提出了許多方法。現有努力主要集中在擷取和利用時空依賴性來預測未來的交通流量。儘管有前景，但它們在適應交通狀況的測試時間環境變化方面仍有不足。為了應對這一挑戰，我們建議引入大型語言模型 (LLM) 來幫助交通流量預測，並設計一種名為大型語言模型增強交通流量預測器 (LEAF) 的新方法。LEAF 採用兩個分支，分別使用圖形和超圖形結構擷取不同的時空關係。這兩個分支首先分別進行預訓練，在測試時，它們產生不同的預測。基於這些預測，使用大型語言模型選擇最有可能的結果。然後，將排名損失應用為學習目標，以增強兩個分支的預測能力。在幾個數據集上進行的廣泛實驗證明了所提出的 LEAF 的有效性。

##### **SceneLLM: Implicit Language Reasoning in LLM for Dynamic Scene Graph Generation**
2412.11026v1 by Hang Zhang, Zhuoling Li, Jun Liu

Dynamic scenes contain intricate spatio-temporal information, crucial for
mobile robots, UAVs, and autonomous driving systems to make informed decisions.
Parsing these scenes into semantic triplets <Subject-Predicate-Object> for
accurate Scene Graph Generation (SGG) is highly challenging due to the
fluctuating spatio-temporal complexity. Inspired by the reasoning capabilities
of Large Language Models (LLMs), we propose SceneLLM, a novel framework that
leverages LLMs as powerful scene analyzers for dynamic SGG. Our framework
introduces a Video-to-Language (V2L) mapping module that transforms video
frames into linguistic signals (scene tokens), making the input more
comprehensible for LLMs. To better encode spatial information, we devise a
Spatial Information Aggregation (SIA) scheme, inspired by the structure of
Chinese characters, which encodes spatial data into tokens. Using Optimal
Transport (OT), we generate an implicit language signal from the frame-level
token sequence that captures the video's spatio-temporal information. To
further improve the LLM's ability to process this implicit linguistic input, we
apply Low-Rank Adaptation (LoRA) to fine-tune the model. Finally, we use a
transformer-based SGG predictor to decode the LLM's reasoning and predict
semantic triplets. Our method achieves state-of-the-art results on the Action
Genome (AG) benchmark, and extensive experiments show the effectiveness of
SceneLLM in understanding and generating accurate dynamic scene graphs.

摘要：動態場景包含複雜的時空資訊，對於行動機器人、無人機和自動駕駛系統做出明智的決策至關重要。
由於時空複雜性波動，將這些場景解析成語義三元組 <主詞-謂詞-受詞> 以進行準確的場景圖生成 (SGG) 是一項極具挑戰性的任務。
受到大型語言模型 (LLM) 的推理能力啟發，我們提出了 SceneLLM，這是一個新穎的框架，利用 LLM 作為強大的場景分析器，用於動態 SGG。
我們的框架引入了一個影片轉語言 (V2L) 映射模組，將影片格轉換成語言訊號 (場景代幣)，讓 LLM 更容易理解輸入。
為了更好地編碼空間資訊，我們設計了一個空間資訊聚合 (SIA) 架構，其靈感來自漢字的結構，將空間資料編碼成代幣。
使用最佳傳輸 (OT)，我們從幀級代幣序列產生一個隱含的語言訊號，捕捉影片的時空資訊。
為了進一步提高 LLM 處理此隱含語言輸入的能力，我們應用低秩適應 (LoRA) 來微調模型。
最後，我們使用一個基於轉換器的 SGG 預測器來解碼 LLM 的推理並預測語義三元組。
我們的模型在動作基因組 (AG) 基準上取得了最先進的結果，廣泛的實驗顯示了 SceneLLM 在理解和生成準確的動態場景圖方面的有效性。

##### **MedG-KRP: Medical Graph Knowledge Representation Probing**
2412.10982v2 by Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann

Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.

摘要：大型語言模型 (LLM) 近期已成為強大的工具，在醫療領域中發現許多應用。LLM 從許多來源匯集大量資訊以產生回應的能力（此過程類似於人類專家的過程），已讓許多人看到將 LLM 部署於臨床用途的潛力。然而，醫學是一個準確推理至關重要的領域。許多研究人員質疑多選題回答 (MCQA) 基準的有效性，而這經常被用於測試 LLM。研究人員和臨床醫生都必須對 LLM 的能力有完全的信心，才能將其部署於醫療環境中。為了滿足這種理解需求，我們引入一個基於知識圖譜 (KG) 的方法來評估 LLM 的生物醫學推理能力。基本上，我們繪製 LLM 如何連結醫療概念，以更好地理解它們的推理方式。我們測試了 GPT-4、Llama3-70b 和 PalmyraMed-70b，這是一個專門的醫療模型。我們徵集了一組醫學生來檢閱總共 60 個 LLM 生成的圖表，並將這些圖表與 BIOS（一個大型生物醫學 KG）進行比較。我們觀察到 GPT-4 在我們的人工審查中表現最佳，但在我們的基本事實比較中表現最差；而專門的醫療模型 PalmyraMed 則相反。我們的研究提供了一種可視化 LLM 醫療推理路徑的方法，以便它們能夠安全有效地實作於臨床環境中。

##### **Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through Structured Data**
2412.10654v1 by Xue Wu, Kostas Tsioutsiouliklis

Large Language Models (LLMs) have demonstrated remarkable capabilities in
natural language understanding and generation. However, they often struggle
with complex reasoning tasks and are prone to hallucination. Recent research
has shown promising results in leveraging knowledge graphs (KGs) to enhance LLM
performance. KGs provide a structured representation of entities and their
relationships, offering a rich source of information that can enhance the
reasoning capabilities of LLMs. For this work, we have developed different
techniques that tightly integrate KG structures and semantics into LLM
representations. Our results show that we are able to significantly improve the
performance of LLMs in complex reasoning scenarios, and ground the reasoning
process with KGs. We are the first to represent KGs with programming language
and fine-tune pretrained LLMs with KGs. This integration facilitates more
accurate and interpretable reasoning processes, paving the way for more
advanced reasoning capabilities of LLMs.

摘要：大型語言模型 (LLM) 在自然語言理解和生成方面展現了非凡的能力。然而，它們經常在複雜的推理任務中掙扎，並且容易出現幻覺。最近的研究顯示出利用知識圖譜 (KG) 來增強 LLM 效能的良好結果。KG 提供實體及其關係的結構化表示，提供了豐富的資訊來源，可以增強 LLM 的推理能力。對於這項工作，我們開發了不同的技術，將 KG 結構和語義緊密整合到 LLM 表示中。我們的結果表明，我們能夠顯著提升 LLM 在複雜推理場景中的效能，並以 KG 為基礎進行推理過程。我們是第一個使用程式語言表示 KG，並使用 KG 微調預訓練 LLM 的人。這種整合有助於更準確且可解釋的推理過程，為 LLM 更先進的推理能力鋪路。

##### **WHAT-IF: Exploring Branching Narratives by Meta-Prompting Large Language Models**
2412.10582v2 by Runsheng "Anson" Huang, Lara J. Martin, Chris Callison-Burch

WHAT-IF -- Writing a Hero's Alternate Timeline through Interactive Fiction --
is a system that uses zero-shot meta-prompting to create branching narratives
from a prewritten story. Played as an interactive fiction (IF) game, WHAT-IF
lets the player choose between decisions that the large language model (LLM)
GPT-4 generates as possible branches in the story. Starting with an existing
linear plot as input, a branch is created at each key decision taken by the
main character. By meta-prompting the LLM to consider the major plot points
from the story, the system produces coherent and well-structured alternate
storylines. WHAT-IF stores the branching plot tree in a graph which helps it to
both keep track of the story for prompting and maintain the structure for the
final IF system. A video demo of our system can be found here:
https://youtu.be/8vBqjqtupcc.

摘要：WHAT-IF——透過互動小說撰寫英雄的另類時間線——
是一個使用零次提示來建立從預先撰寫的故事分歧敘事的系統。以互動小說 (IF) 遊戲的方式遊玩，WHAT-IF
讓玩家在大型語言模型 (LLM)
GPT-4 產生的故事中可能的支線中選擇決定。從現有的線性情節作為輸入開始，在主要角色做出的每個關鍵決定中產生一個支線。透過元提示 LLM 考量故事中的主要情節，系統產生連貫且結構良好的另類故事線。WHAT-IF 將分歧情節樹儲存在圖形中，這有助於它同時追蹤故事以提示和維護最終 IF 系統的結構。我們系統的影片示範可以在這裡找到：
https://youtu.be/8vBqjqtupcc。

##### **A Decade of Deep Learning: A Survey on The Magnificent Seven**
2412.16188v1 by Dilshod Azizov, Muhammad Arslan Manzoor, Velibor Bojkovic, Yingxu Wang, Zixiao Wang, Zangir Iklassov, Kailong Zhao, Liang Li, Siwei Liu, Yu Zhong, Wei Liu, Shangsong Liang

Deep learning has fundamentally reshaped the landscape of artificial
intelligence over the past decade, enabling remarkable achievements across
diverse domains. At the heart of these developments lie multi-layered neural
network architectures that excel at automatic feature extraction, leading to
significant improvements in machine learning tasks. To demystify these advances
and offer accessible guidance, we present a comprehensive overview of the most
influential deep learning algorithms selected through a broad-based survey of
the field. Our discussion centers on pivotal architectures, including Residual
Networks, Transformers, Generative Adversarial Networks, Variational
Autoencoders, Graph Neural Networks, Contrastive Language-Image Pre-training,
and Diffusion models. We detail their historical context, highlight their
mathematical foundations and algorithmic principles, and examine subsequent
variants, extensions, and practical considerations such as training
methodologies, normalization techniques, and learning rate schedules. Beyond
historical and technical insights, we also address their applications,
challenges, and potential research directions. This survey aims to serve as a
practical manual for both newcomers seeking an entry point into cutting-edge
deep learning methods and experienced researchers transitioning into this
rapidly evolving domain.

摘要：深度學習在過去十年中從根本上重塑了人工智慧的格局，在各個領域取得了顯著的成就。這些發展的核心是多層神經網路架構，它擅長自動特徵提取，從而顯著改進機器學習任務。為了揭開這些進步的神秘面紗並提供易於理解的指導，我們對通過廣泛的領域調查所選出的最有影響力的深度學習演算法進行了全面的概述。我們的討論集中在關鍵架構上，包括殘差網路、Transformer、生成對抗網路、變異自動編碼器、圖神經網路、對比語言影像預訓練和擴散模型。我們詳細說明了它們的歷史背景，重點介紹了它們的數學基礎和演算法原理，並探討了後續的變體、擴充和實務考量，例如訓練方法、正規化技術和學習率規劃。除了歷史和技術見解之外，我們還探討了它們的應用、挑戰和潛在的研究方向。本調查旨在作為一本實務手冊，既適合尋求進入尖端深度學習方法的新手，也適合轉型到這個快速發展領域的經驗豐富的研究人員。

##### **Can LLMs Convert Graphs to Text-Attributed Graphs?**
2412.10136v1 by Zehong Wang, Sidney Liu, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye

Graphs are ubiquitous data structures found in numerous real-world
applications, such as drug discovery, recommender systems, and social network
analysis. Graph neural networks (GNNs) have become a popular tool to learn node
embeddings through message passing on these structures. However, a significant
challenge arises when applying GNNs to multiple graphs with different feature
spaces, as existing GNN architectures are not designed for cross-graph feature
alignment. To address this, recent approaches introduce text-attributed graphs,
where each node is associated with a textual description, enabling the use of a
shared textual encoder to project nodes from different graphs into a unified
feature space. While promising, this method relies heavily on the availability
of text-attributed data, which can be difficult to obtain in practice. To
bridge this gap, we propose a novel method named Topology-Aware Node
description Synthesis (TANS), which leverages large language models (LLMs) to
automatically convert existing graphs into text-attributed graphs. The key idea
is to integrate topological information with each node's properties, enhancing
the LLMs' ability to explain how graph topology influences node semantics. We
evaluate our TANS on text-rich, text-limited, and text-free graphs,
demonstrating that it enables a single GNN to operate across diverse graphs.
Notably, on text-free graphs, our method significantly outperforms existing
approaches that manually design node features, showcasing the potential of LLMs
for preprocessing graph-structured data, even in the absence of textual
information. The code and data are available at
https://github.com/Zehong-Wang/TANS.

摘要：圖形是普遍存在於許多真實世界應用中的資料結構，例如藥物發現、推薦系統和社交網路分析。圖形神經網路 (GNN) 已成為一種流行的工具，可透過在這些結構上傳遞訊息來學習節點嵌入。然而，當將 GNN 應用於具有不同特徵空間的多個圖形時，會出現一個重大的挑戰，因為現有的 GNN 架構並非設計用於跨圖形特徵對齊。為了解決這個問題，最近的方法引入了文字屬性圖形，其中每個節點都與文字描述相關聯，從而可以使用共用文字編碼器將來自不同圖形的節點投影到統一的特徵空間中。儘管有希望，但此方法在很大程度上依賴於文字屬性資料的可用性，這在實務上可能難以取得。為了彌補這個差距，我們提出了一種名為拓撲感知節點描述合成 (TANS) 的新方法，該方法利用大型語言模型 (LLM) 將現有圖形自動轉換為文字屬性圖形。其關鍵思想是將拓撲資訊與每個節點的屬性整合在一起，增強 LLM 解釋圖形拓撲如何影響節點語義的能力。我們在文字豐富、文字受限和無文字圖形上評估我們的 TANS，證明它能讓單一 GNN 在不同的圖形中運作。值得注意的是，在無文字圖形上，我們的模型顯著優於手動設計節點特徵的現有方法，展示了 LLM 在預處理圖形結構資料方面的潛力，即使在沒有文字資訊的情況下也是如此。程式碼和資料可在 https://github.com/Zehong-Wang/TANS 取得。

##### **Lost in the Middle, and In-Between: Enhancing Language Models' Ability to Reason Over Long Contexts in Multi-Hop QA**
2412.10079v1 by George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter, Katharina von der Wense

Previous work finds that recent long-context language models fail to make
equal use of information in the middle of their inputs, preferring pieces of
information located at the tail ends which creates an undue bias in situations
where we would like models to be equally capable of using different parts of
the input. Thus far, the problem has mainly only been considered in settings
with single pieces of critical information, leading us to question what happens
when multiple necessary pieces of information are spread out over the inputs.
Here, we demonstrate the effects of the "lost in the middle" problem in the
multi-hop question answering setting -- in which multiple reasoning "hops" over
disconnected documents are required -- and show that performance degrades not
only with respect to the distance of information from the edges of the context,
but also between pieces of information. Additionally, we experiment with means
of alleviating the problem by reducing superfluous document contents through
knowledge graph triple extraction and summarization, and prompting models to
reason more thoroughly using chain-of-thought prompting.

摘要：先前的研究發現，最近的長語境語言模型無法平均利用其輸入中段的資訊，偏好位於尾端的資訊片段，這會造成不當的偏差，在我們希望模型能平均使用輸入不同部分的情況下。到目前為止，這個問題主要只在具有單一關鍵資訊片段的設定中被考慮，導致我們質疑當多個必要的資訊片段散佈在輸入中時會發生什麼情況。在此，我們示範了「遺失在中間」問題在多跳問答設定中的影響，其中需要跨越未連接文件的多次推理「跳躍」，並顯示效能不僅會隨著資訊與語境邊緣的距離而下降，也會隨著資訊片段之間的距離而下降。此外，我們實驗了透過知識圖譜三元組萃取和摘要來減少多餘文件內容，並提示模型使用思考鏈提示來更徹底地推理，以減輕問題的方法。

##### **Low-Resource Fast Text Classification Based on Intra-Class and Inter-Class Distance Calculation**
2412.09922v1 by Yanxu Mao, Peipei Liu, Tiehan Cui, Congying Liu, Datao You

In recent years, text classification methods based on neural networks and
pre-trained models have gained increasing attention and demonstrated excellent
performance. However, these methods still have some limitations in practical
applications: (1) They typically focus only on the matching similarity between
sentences. However, there exists implicit high-value information both within
sentences of the same class and across different classes, which is very crucial
for classification tasks. (2) Existing methods such as pre-trained language
models and graph-based approaches often consume substantial memory for training
and text-graph construction. (3) Although some low-resource methods can achieve
good performance, they often suffer from excessively long processing times. To
address these challenges, we propose a low-resource and fast text
classification model called LFTC. Our approach begins by constructing a
compressor list for each class to fully mine the regularity information within
intra-class data. We then remove redundant information irrelevant to the target
classification to reduce processing time. Finally, we compute the similarity
distance between text pairs for classification. We evaluate LFTC on 9 publicly
available benchmark datasets, and the results demonstrate significant
improvements in performance and processing time, especially under limited
computational and data resources, highlighting its superior advantages.

摘要：近年来，基于神经网络和预训练模型的文本分类方法越来越受到关注，并表现出优异的性能。然而，这些方法在实际应用中仍然存在一些局限性：(1) 它们通常只关注句子之间的匹配相似性。然而，同类句子内部和不同类句子之间都存在隐含的高价值信息，这对分类任务至关重要。(2) 预训练语言模型和基于图的方法等现有方法通常需要大量的内存用于训练和文本图构建。(3) 虽然一些低资源方法可以达到良好的性能，但它们通常处理时间过长。为了应对这些挑战，我们提出了一种低资源且快速的文本分类模型，称为 LFTC。我们的方法首先为每个类别构建一个压缩器列表，以充分挖掘类内数据中的规律性信息。然后，我们删除与目标分类无关的冗余信息，以减少处理时间。最后，我们计算文本对之间的相似性距离进行分类。我们在 9 个公开的基准数据集上评估了 LFTC，结果表明在有限的计算和数据资源下，其性能和处理时间都有显著提升，突出了其优越的优势。

##### **MGM: Global Understanding of Audience Overlap Graphs for Predicting the Factuality and the Bias of News Media**
2412.10467v1 by Muhammad Arslan Manzoor, Ruihong Zeng, Dilshod Azizov, Preslav Nakov, Shangsong Liang

In the current era of rapidly growing digital data, evaluating the political
bias and factuality of news outlets has become more important for seeking
reliable information online. In this work, we study the classification problem
of profiling news media from the lens of political bias and factuality.
Traditional profiling methods, such as Pre-trained Language Models (PLMs) and
Graph Neural Networks (GNNs) have shown promising results, but they face
notable challenges. PLMs focus solely on textual features, causing them to
overlook the complex relationships between entities, while GNNs often struggle
with media graphs containing disconnected components and insufficient labels.
To address these limitations, we propose MediaGraphMind (MGM), an effective
solution within a variational Expectation-Maximization (EM) framework. Instead
of relying on limited neighboring nodes, MGM leverages features, structural
patterns, and label information from globally similar nodes. Such a framework
not only enables GNNs to capture long-range dependencies for learning
expressive node representations but also enhances PLMs by integrating
structural information and therefore improving the performance of both models.
The extensive experiments demonstrate the effectiveness of the proposed
framework and achieve new state-of-the-art results. Further, we share our
repository1 which contains the dataset, code, and documentation

摘要：<paragraph>在數位資料快速成長的時代，評估新聞媒體的政治偏見和事實性，對於在網路上尋找可靠的資訊變得更加重要。在這項工作中，我們從政治偏見和事實性的角度研究新聞媒體的分類問題。傳統的分類方法，例如預先訓練的語言模型 (PLM) 和圖神經網路 (GNN)，已經展現出有前途的成果，但它們面臨著顯著的挑戰。PLM 僅專注於文字特徵，導致它們忽略了實體之間的複雜關係，而 GNN 則經常難以處理包含不連通元件和標籤不足的媒體圖。為了解決這些限制，我們提出了 MediaGraphMind (MGM)，這是一種在變異期望最大化 (EM) 框架內有效的解決方案。MGM 不依賴於有限的鄰近節點，而是利用特徵、結構模式和來自全球相似節點的標籤資訊。這種框架不僅使 GNN 能夠擷取長程依賴性以學習表達式節點表示，而且還通過整合結構資訊來增強 PLM，從而改善這兩種模型的效能。廣泛的實驗證明了所提出的框架的有效性，並達到了新的最先進成果。此外，我們分享了我們的儲存庫 1，其中包含資料集、程式碼和文件</paragraph>

##### **Uncommon Belief in Rationality**
2412.09407v1 by Qi Shi, Pavel Naumov

Common knowledge/belief in rationality is the traditional standard assumption
in analysing interaction among agents. This paper proposes a graph-based
language for capturing significantly more complicated structures of
higher-order beliefs that agents might have about the rationality of the other
agents. The two main contributions are a solution concept that captures the
reasoning process based on a given belief structure and an efficient algorithm
for compressing any belief structure into a unique minimal form.

摘要：在分析代理之間的互動時，理性中的常識/信念是傳統的標準假設。本文提出了一種基於圖形的語言，用於捕捉代理人可能對其他代理人的理性具有顯著更複雜的高階信念結構。兩項主要貢獻是捕捉基於給定信念結構的推理過程的解決方案概念，以及將任何信念結構壓縮成唯一最小形式的有效演算法。

##### **Foundation Models and Adaptive Feature Selection: A Synergistic Approach to Video Question Answering**
2412.09230v1 by Sai Bhargav Rongali, Mohamad Hassan N C, Ankit Jha, Neha Bhargava, Saurabh Prasad, Biplab Banerjee

This paper tackles the intricate challenge of video question-answering
(VideoQA). Despite notable progress, current methods fall short of effectively
integrating questions with video frames and semantic object-level abstractions
to create question-aware video representations. We introduce Local-Global
Question Aware Video Embedding (LGQAVE), which incorporates three major
innovations to integrate multi-modal knowledge better and emphasize semantic
visual concepts relevant to specific questions. LGQAVE moves beyond traditional
ad-hoc frame sampling by utilizing a cross-attention mechanism that precisely
identifies the most relevant frames concerning the questions. It captures the
dynamics of objects within these frames using distinct graphs, grounding them
in question semantics with the miniGPT model. These graphs are processed by a
question-aware dynamic graph transformer (Q-DGT), which refines the outputs to
develop nuanced global and local video representations. An additional
cross-attention module integrates these local and global embeddings to generate
the final video embeddings, which a language model uses to generate answers.
Extensive evaluations across multiple benchmarks demonstrate that LGQAVE
significantly outperforms existing models in delivering accurate multi-choice
and open-ended answers.

摘要：本文探討了影片問答 (VideoQA) 的複雜挑戰。儘管取得顯著進展，但目前的技術仍無法有效結合問題、影片畫面和語義物件層級抽象，以建立問題感知的影片表徵。我們引進了局部-全域問題感知影片嵌入 (LGQAVE)，它包含三項重大創新，以更好地整合多模式知識，並強調與特定問題相關的語義視覺概念。LGQAVE 超越了傳統的臨時畫面取樣，利用跨注意力機制精確找出與問題最相關的畫面。它使用不同的圖形捕捉這些畫面中物件的動態，並透過 miniGPT 模型將它們奠基於問題語義中。這些圖形由問題感知動態圖形轉換器 (Q-DGT) 處理，它會改善輸出，以開發細緻的全局和局部影片表徵。額外的跨注意力模組整合這些局部和全局嵌入，以產生最終的影片嵌入，語言模型使用這些嵌入來產生答案。跨多個基準的廣泛評估證明，LGQAVE 在提供準確的多選和開放式答案方面，明顯優於現有模型。

##### **Filter-then-Generate: Large Language Models with Structure-Text Adapter for Knowledge Graph Completion**
2412.09094v1 by Ben Liu, Jihai Zhang, Fangquan Lin, Cheng Yang, Min Peng

Large Language Models (LLMs) present massive inherent knowledge and superior
semantic comprehension capability, which have revolutionized various tasks in
natural language processing. Despite their success, a critical gap remains in
enabling LLMs to perform knowledge graph completion (KGC). Empirical evidence
suggests that LLMs consistently perform worse than conventional KGC approaches,
even through sophisticated prompt design or tailored instruction-tuning.
Fundamentally, applying LLMs on KGC introduces several critical challenges,
including a vast set of entity candidates, hallucination issue of LLMs, and
under-exploitation of the graph structure. To address these challenges, we
propose a novel instruction-tuning-based method, namely FtG. Specifically, we
present a \textit{filter-then-generate} paradigm and formulate the KGC task
into a multiple-choice question format. In this way, we can harness the
capability of LLMs while mitigating the issue casused by hallucinations.
Moreover, we devise a flexible ego-graph serialization prompt and employ a
structure-text adapter to couple structure and text information in a
contextualized manner. Experimental results demonstrate that FtG achieves
substantial performance gain compared to existing state-of-the-art methods. The
instruction dataset and code are available at
\url{https://github.com/LB0828/FtG}.

摘要：大型語言模型 (LLM) 具有龐大的內部知識和卓越的語義理解能力，這徹底改變了自然語言處理中的各種任務。儘管它們成功，但在使 LLM 能執行知識圖譜完成 (KGC) 方面仍存在一個關鍵差距。經驗證據表明，即使透過精密的提示設計或量身打造的指令調整，LLM 的表現也始終不如傳統的 KGC 方法。從根本上來說，在 KGC 上應用 LLM 會帶來幾個關鍵挑戰，包括大量的實體候選、LLM 的幻覺問題以及圖形結構的利用不足。為了應對這些挑戰，我們提出了一種新的基於指令調整的方法，即 FtG。具體來說，我們提出了「先過濾再生成」的範例，並將 KGC 任務制定為多選題格式。這樣，我們就能利用 LLM 的能力，同時減輕幻覺所造成的問題。此外，我們設計了一個靈活的自圖序列化提示，並採用結構文本適配器，以情境化的方式結合結構和文本資訊。實驗結果表明，與現有的最先進方法相比，FtG 獲得了顯著的效能提升。指令資料集和程式碼可在
\url{https://github.com/LB0828/FtG} 取得。

##### **Neural Interactive Proofs**
2412.08897v1 by Lewis Hammond, Sam Adam-Day

We consider the problem of how a trusted, but computationally bounded agent
(a 'verifier') can learn to interact with one or more powerful but untrusted
agents ('provers') in order to solve a given task. More specifically, we study
the case in which agents are represented using neural networks and refer to
solutions of this problem as neural interactive proofs. First we introduce a
unifying framework based on prover-verifier games, which generalises previously
proposed interaction protocols. We then describe several new protocols for
generating neural interactive proofs, and provide a theoretical comparison of
both new and existing approaches. Finally, we support this theory with
experiments in two domains: a toy graph isomorphism problem that illustrates
the key ideas, and a code validation task using large language models. In so
doing, we aim to create a foundation for future work on neural interactive
proofs and their application in building safer AI systems.

摘要：<paragraph>我們考慮一個問題，說明一個受信任但計算受限的代理（「驗證者」）如何學會與一個或多個強大但不可信的代理（「證明者」）互動，以解決給定的任務。更具體地說，我們研究代理使用神經網路表示的情況，並將此問題的解決方案稱為神經互動證明。首先，我們引入一個基於證明者驗證者遊戲的統一框架，它概括了先前提出的互動協議。然後，我們描述了幾個生成神經互動證明的新協議，並對新舊方法進行了理論比較。最後，我們在兩個領域中用實驗支持了這個理論：一個玩具圖同構問題，說明了關鍵思想，以及使用大型語言模型的代碼驗證任務。這樣做，我們旨在為神經互動證明及其在構建更安全的 AI 系統中的應用奠定基礎。</paragraph>

##### **A Graph-Based Synthetic Data Pipeline for Scaling High-Quality Reasoning Instructions**
2412.08864v1 by Jiankang Wang, Jianjun Xu, Xiaorui Wang, Yuxin Wang, Mengting Xing, Shancheng Fang, Zhineng Chen, Hongtao Xie, Yongdong Zhang

Synthesizing high-quality reasoning data for continual training has been
proven to be effective in enhancing the performance of Large Language Models
(LLMs). However, previous synthetic approaches struggle to easily scale up data
and incur high costs in the pursuit of high quality. In this paper, we propose
the Graph-based Synthetic Data Pipeline (GSDP), an economical and scalable
framework for high-quality reasoning data synthesis. Inspired by knowledge
graphs, we extracted knowledge points from seed data and constructed a
knowledge point relationships graph to explore their interconnections. By
exploring the implicit relationships among knowledge, our method achieves
$\times$255 data expansion. Furthermore, GSDP led by open-source models,
achieves synthesis quality comparable to GPT-4-0613 while maintaining
$\times$100 lower costs. To tackle the most challenging mathematical reasoning
task, we present the GSDP-MATH dataset comprising over 1.91 million pairs of
math problems and answers. After fine-tuning on GSDP-MATH, GSDP-7B based on
Mistral-7B achieves 37.7% accuracy on MATH and 78.4% on GSM8K, demonstrating
the effectiveness of our method. The dataset and models trained in this paper
will be available.

摘要：<paragraph>合成高品質推理資料以進行持續訓練已被證實能有效提升大型語言模型 (LLM) 的效能。然而，先前的合成方法難以輕易擴充資料，且在追求高品質的過程中會產生高成本。在本文中，我們提出基於圖表的合成資料管線 (GSDP)，一個經濟且可擴充的高品質推理資料合成架構。受知識圖表啟發，我們從種子資料中萃取知識點，並建構一個知識點關係圖表以探索它們的相互關聯性。透過探索知識中的隱含關係，我們的做法達到了 $\times$255 資料擴充。此外，由開源模型領導的 GSDP，達到了與 GPT-4-0613 相當的合成品質，同時將成本降低了 $\times$100。為了應對最具挑戰性的數學推理任務，我們提出了 GSDP-MATH 資料集，其中包含超過 191 萬對數學問題和答案。在 GSDP-MATH 上進行微調後，基於 Mistral-7B 的 GSDP-7B 在 MATH 上達到了 37.7% 的準確度，在 GSM8K 上達到了 78.4%，證明了我們方法的有效性。本文中訓練的資料集和模型將會公開。</paragraph>

##### **In-Context Learning with Topological Information for Knowledge Graph Completion**
2412.08742v1 by Udari Madhushani Sehwag, Kassiani Papasotiriou, Jared Vann, Sumitra Ganesh

Knowledge graphs (KGs) are crucial for representing and reasoning over
structured information, supporting a wide range of applications such as
information retrieval, question answering, and decision-making. However, their
effectiveness is often hindered by incompleteness, limiting their potential for
real-world impact. While knowledge graph completion (KGC) has been extensively
studied in the literature, recent advances in generative AI models,
particularly large language models (LLMs), have introduced new opportunities
for innovation. In-context learning has recently emerged as a promising
approach for leveraging pretrained knowledge of LLMs across a range of natural
language processing tasks and has been widely adopted in both academia and
industry. However, how to utilize in-context learning for effective KGC remains
relatively underexplored. We develop a novel method that incorporates
topological information through in-context learning to enhance KGC performance.
By integrating ontological knowledge and graph structure into the context of
LLMs, our approach achieves strong performance in the transductive setting
i.e., nodes in the test graph dataset are present in the training graph
dataset. Furthermore, we apply our approach to KGC in the more challenging
inductive setting, i.e., nodes in the training graph dataset and test graph
dataset are disjoint, leveraging the ontology to infer useful information about
missing nodes which serve as contextual cues for the LLM during inference. Our
method demonstrates superior performance compared to baselines on the
ILPC-small and ILPC-large datasets.

摘要：知識圖譜 (KG) 對於表示和推理結構化資訊至關重要，支援廣泛的應用程式，例如資訊檢索、問題解答和決策制定。然而，它們的效能經常受到不完整性的阻礙，限制了它們對現實世界影響的潛力。雖然知識圖譜完成 (KGC) 已在文獻中廣泛研究，但生成式 AI 模型的最新進展，特別是大型語言模型 (LLM)，為創新帶來了新的機會。情境學習最近已成為一種有前途的方法，用於跨越一系列自然語言處理任務利用 LLM 的預訓練知識，並已廣泛應用於學術界和產業。然而，如何利用情境學習進行有效的 KGC 仍然相對未被探討。我們開發了一種新方法，透過情境學習納入拓撲資訊來增強 KGC 效能。透過將本體知識和圖形結構整合到 LLM 的情境中，我們的做法在轉導式設定中取得強勁的效能，即測試圖形資料集中的節點存在於訓練圖形資料集中。此外，我們將我們的做法應用於更具挑戰性的歸納式設定中的 KGC，即訓練圖形資料集和測試圖形資料集中的節點是不相交的，利用本體來推斷有關遺失節點的有用資訊，這些節點在推理過程中作為 LLM 的情境提示。與 ILPC-small 和 ILPC-large 資料集上的基準相比，我們的做法展現出優異的效能。

##### **VEL: A Formally Verified Reasoner for OWL2 EL Profile**
2412.08739v1 by Atalay Mert Ileri, Nalen Rangarajan, Jack Cannell, Hande McGinty

Over the past two decades, the Web Ontology Language (OWL) has been
instrumental in advancing the development of ontologies and knowledge graphs,
providing a structured framework that enhances the semantic integration of
data. However, the reliability of deductive reasoning within these systems
remains challenging, as evidenced by inconsistencies among popular reasoners in
recent competitions. This evidence underscores the limitations of current
testing-based methodologies, particularly in high-stakes domains such as
healthcare. To mitigate these issues, in this paper, we have developed VEL, a
formally verified EL++ reasoner equipped with machine-checkable correctness
proofs that ensure the validity of outputs across all possible inputs. This
formalization, based on the algorithm of Baader et al., has been transformed
into executable OCaml code using the Coq proof assistant's extraction
capabilities. Our formalization revealed several errors in the original
completeness proofs, which led to changes to the algorithm to ensure its
completeness. Our work demonstrates the necessity of mechanization of reasoning
algorithms to ensure their correctness at theoretical and implementation
levels.

摘要：在過去二十年，Web Ontology Language (OWL) 已在推動本体和知識圖譜的發展中發揮關鍵作用，提供一個增強資料語意整合的結構化架構。然而，這些系統中演繹推理的可靠性仍然具有挑戰性，正如最近比賽中流行的推理機之間的不一致性所證明的那樣。這個證據突顯了當前基於測試的方法的局限性，特別是在醫療保健等高風險領域。為了減輕這些問題，我們在本文中開發了 VEL，一個正式驗證的 EL++ 推理機，配備了機器可檢查的正確性證明，以確保在所有可能的輸入中輸出的有效性。這個形式化，基於 Baader 等人的演算法，已使用 Coq 證明助手的提取功能轉換為可執行的 OCaml 程式碼。我們的形式化揭示了原始完整性證明中的幾個錯誤，這導致了演算法的改變以確保其完整性。我們的作品證明了推理演算法機械化的必要性，以確保它們在理論和實作層面的正確性。

##### **From communities to interpretable network and word embedding: an unified approach**
2412.08187v1 by Thibault Prouteau, Nicolas Dugué, Simon Guillot

Modelling information from complex systems such as humans social interaction
or words co-occurrences in our languages can help to understand how these
systems are organized and function. Such systems can be modelled by networks,
and network theory provides a useful set of methods to analyze them. Among
these methods, graph embedding is a powerful tool to summarize the interactions
and topology of a network in a vectorized feature space. When used in input of
machine learning algorithms, embedding vectors help with common graph problems
such as link prediction, graph matching, etc. Word embedding has the goal of
representing the sense of words, extracting it from large text corpora. Despite
differences in the structure of information in input of embedding algorithms,
many graph embedding approaches are adapted and inspired from methods in NLP.
Limits of these methods are observed in both domains. Most of these methods
require long and resource greedy training. Another downside to most methods is
that they are black-box, from which understanding how the information is
structured is rather complex. Interpretability of a model allows understanding
how the vector space is structured without the need for external information,
and thus can be audited more easily. With both these limitations in mind, we
propose a novel framework to efficiently embed network vertices in an
interpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)
leverages the bipartite projection of a network using cliques to reduce
dimensionality. Along with LDBGF, we introduce two implementations of this
framework that rely on communities instead of cliques: SINr-NR and SINr-MF. We
show that SINr-MF can perform well on classical graphs and SINr-NR can produce
high-quality graph and word embeddings that are interpretable and stable across
runs.

摘要：<paragraph>透過模擬人類社交互動或語言中詞彙共現等複雜系統中的資訊，有助於了解這些系統的組織和運作方式。這些系統可以用網路來建模，而網路理論提供了有用的方法集來分析它們。在這些方法中，圖形嵌入是一種強大的工具，可用於在向量化特徵空間中總結網路的交互和拓撲。當用於機器學習演算法的輸入時，嵌入向量有助於常見的圖形問題，例如連結預測、圖形配對等。詞嵌入的目標是表示詞彙的意義，從大型文字語料庫中萃取它。儘管嵌入演算法輸入資訊的結構不同，但許多圖形嵌入方法都是根據自然語言處理中的方法改編和啟發的。在兩個領域中都觀察到這些方法的限制。大多數這些方法需要漫長且耗費資源的訓練。大多數方法的另一個缺點是它們是黑盒子，從中理解資訊如何被結構化相當複雜。模型的可解釋性允許在不需要外部資訊的情況下了解向量空間是如何被結構化的，因此可以更容易地進行稽核。牢記這兩個限制，我們提出了一個新穎的框架，以有效的方式將網路頂點嵌入可解釋的向量空間中。我們的低維二部圖框架 (LDBGF) 利用網路的二部圖投影使用派系來降低維度。除了 LDBGF 之外，我們還介紹了兩個依賴社群而非派系的此框架實作：SINr-NR 和 SINr-MF。我們展示了 SINr-MF 在經典圖形上可以執行良好，而 SINr-NR 可以產生高品質的圖形和詞嵌入，這些嵌入在各次執行中都是可解釋且穩定的。</paragraph>

##### **Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?**
2412.08174v2 by Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han

While great success has been achieved in building vision models with
Contrastive Language-Image Pre-training (CLIP) over Internet-scale image-text
pairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is
challenging because of three fundamental issues: the scarcity of labeled data
and text supervision, different levels of downstream tasks, and the conceptual
gaps between domains. In this work, to address these issues, we leverage
multi-modal prompt learning to effectively adapt pre-trained GNN to downstream
tasks and data, given only a few semantically labeled samples, each with
extremely weak text supervision. Our new paradigm embeds the graphs directly in
the same space as the Large Language Models (LLMs) by learning both graph
prompts and text prompts simultaneously. To accomplish this, we improve
state-of-the-art graph prompt method, and then propose the first graph-language
multi-modal prompt learning approach for exploiting the knowledge in
pre-trained models. Notably, due to the insufficient supervision for
fine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,
so the learnable parameters are much fewer than fine-tuning any pre-trained
model. Through extensive experiments on real-world datasets, we demonstrate the
superior performance of our paradigm in few-shot, multi-task-level, and
cross-domain settings. Moreover, we build the first CLIP-style zero-shot
classification prototype that can generalize GNNs to unseen classes with
extremely weak text supervision.

摘要：<paragraph>儘管在使用網際網路規模的影像文字配對進行對比語言影像預訓練 (CLIP) 來建立視覺模型方面取得了巨大的成功，但使用 CLIP 管線建立可轉移圖形神經網路 (GNN) 卻很具挑戰性，原因在於三個根本問題：標記資料和文字監督的稀少性、不同層級的下游任務，以及不同領域之間的概念差距。在這項工作中，為了解決這些問題，我們利用多模態提示學習，在僅有少數語義標記範例的情況下，有效地調整預訓練的 GNN 以適用於下游任務和資料，每個範例都具有極其薄弱的文字監督。我們的新範例將圖形直接嵌入與大型語言模型 (LLM) 相同的空間中，方法是同時學習圖形提示和文字提示。為了達成這個目標，我們改進了最先進的圖形提示方法，然後提出第一個圖形語言多模態提示學習方法，以利用預訓練模型中的知識。值得注意的是，由於微調的監督不足，在我們的範例中，預訓練的 GNN 和 LLM 保持凍結狀態，因此可學習參數遠少於微調任何預訓練模型。透過對真實世界資料集進行廣泛的實驗，我們證明了我們的範例在少樣本、多任務層級和跨領域設定中的卓越效能。此外，我們建立了第一個 CLIP 風格的零樣本分類原型，它可以將 GNN 推廣到具有極其薄弱文字監督的未見類別。</paragraph>

##### **GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction**
2412.12152v1 by Rongzheng Wang, Shuang Liang, Qizhi Chen, Jiasheng Zhang, Ke Qin

Large language models (LLMs) have been demonstrated to possess the
capabilities to understand fundamental graph properties and address various
graph reasoning tasks. Existing methods fine-tune LLMs to understand and
execute graph reasoning tasks by specially designed task instructions. However,
these Text-Instruction methods generally exhibit poor performance. Inspired by
tool learning, researchers propose Tool-Instruction methods to solve various
graph problems by special tool calling (e.g., function, API and model),
achieving significant improvements in graph reasoning tasks. Nevertheless,
current Tool-Instruction approaches focus on the tool information and ignore
the graph structure information, which leads to significantly inferior
performance on small-scale LLMs (less than 13B). To tackle this issue, we
propose GraphTool-Instruction, an innovative Instruction-tuning approach that
decomposes the graph reasoning task into three distinct subtasks (i.e., graph
extraction, tool name identification and tool parameter extraction), and design
specialized instructions for each subtask. Our GraphTool-Instruction can be
used as a plug-and-play prompt for different LLMs without fine-tuning.
Moreover, building on GraphTool-Instruction, we develop GTools, a dataset that
includes twenty graph reasoning tasks, and create a graph reasoning LLM called
GraphForge based on Llama3-8B. We conduct extensive experiments on twenty graph
reasoning tasks with different graph types (e.g., graph size or graph
direction), and we find that GraphTool-Instruction achieves SOTA compared to
Text-Instruction and Tool-Instruction methods. Fine-tuned on GTools, GraphForge
gets further improvement of over 30% compared to the Tool-Instruction enhanced
GPT-3.5-turbo, and it performs comparably to the high-cost GPT-4o. Our codes
and data are available at
https://anonymous.4open.science/r/GraphTool-Instruction.

摘要：<paragraph>大型語言模型 (LLM) 已被證明具有理解基本圖形屬性和處理各種圖形推理任務的能力。現有方法微調 LLM 以通過專門設計的任務指令來理解和執行圖形推理任務。然而，這些文本指令方法通常表現出較差的性能。受工具學習的啟發，研究人員提出工具指令方法，通過特殊工具呼叫（例如函數、API 和模型）來解決各種圖形問題，從而顯著改進了圖形推理任務。儘管如此，當前的工具指令方法側重於工具資訊，而忽略了圖形結構資訊，這導致在小規模 LLM（小於 13B）上性能顯著下降。為了解決這個問題，我們提出了 GraphTool-Instruction，這是一種創新的指令調整方法，它將圖形推理任務分解為三個不同的子任務（即圖形提取、工具名稱識別和工具參數提取），並為每個子任務設計專門的指令。我們的 GraphTool-Instruction 可用作不同 LLM 的即插即用提示，而無需微調。此外，基於 GraphTool-Instruction，我們開發了 GTools，這是一個包含 20 個圖形推理任務的資料集，並基於 Llama3-8B 創建了一個名為 GraphForge 的圖形推理 LLM。我們對 20 個具有不同圖形類型（例如圖形大小或圖形方向）的圖形推理任務進行了廣泛的實驗，我們發現與文本指令和工具指令方法相比，GraphTool-Instruction 達到了 SOTA。在 GTools 上進行微調後，與工具指令增強的 GPT-3.5-turbo 相比，GraphForge 進一步改進了 30% 以上，並且其性能與高成本的 GPT-4o 相當。我們的程式碼和資料可在 https://anonymous.4open.science/r/GraphTool-Instruction 獲得。</paragraph>

##### **NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language**
2412.10434v1 by Yuanyuan Liang, Tingyu Xie, Gan Peng, Zihao Huang, Yunshi Lan, Weining Qian

The emergence of Large Language Models (LLMs) has revolutionized many fields,
not only traditional natural language processing (NLP) tasks. Recently,
research on applying LLMs to the database field has been booming, and as a
typical non-relational database, the use of LLMs in graph database research has
naturally gained significant attention. Recent efforts have increasingly
focused on leveraging LLMs to translate natural language into graph query
language (NL2GQL). Although some progress has been made, these methods have
clear limitations, such as their reliance on streamlined processes that often
overlook the potential of LLMs to autonomously plan and collaborate with other
LLMs in tackling complex NL2GQL challenges. To address this gap, we propose
NAT-NL2GQL, a novel multi-agent framework for translating natural language to
graph query language. Specifically, our framework consists of three synergistic
agents: the Preprocessor agent, the Generator agent, and the Refiner agent. The
Preprocessor agent manages data processing as context, including tasks such as
name entity recognition, query rewriting, path linking, and the extraction of
query-related schemas. The Generator agent is a fine-tuned LLM trained on
NL-GQL data, responsible for generating corresponding GQL statements based on
queries and their related schemas. The Refiner agent is tasked with refining
the GQL or context using error information obtained from the GQL execution
results. Given the scarcity of high-quality open-source NL2GQL datasets based
on nGQL syntax, we developed StockGQL, a dataset constructed from a financial
market graph database. It is available at:
https://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL
and SpCQL datasets reveal that our method significantly outperforms baseline
approaches, highlighting its potential for advancing NL2GQL research.

摘要：大型語言模型 (LLM) 的出現，不僅徹底改變了傳統的自然語言處理 (NLP) 任務，更對許多領域造成革命性的影響。最近，將 LLM 應用於資料庫領域的研究蓬勃發展，而作為典型的非關聯式資料庫，LLM 在圖形資料庫研究中的應用自然備受關注。最近的研究工作越來越著重於利用 LLM 將自然語言轉換成圖形查詢語言 (NL2GQL)。儘管已取得一些進展，但這些方法仍有明顯的限制，例如它們依賴簡化的流程，而這些流程往往忽略了 LLM 與其他 LLM 自主規劃和協作以應對複雜 NL2GQL 挑戰的潛力。為了解決這個差距，我們提出了 NAT-NL2GQL，這是一個用於將自然語言轉換成圖形查詢語言的新穎多重代理架構。具體來說，我們的架構包含三個協同運作的代理：預處理器代理、產生器代理和精煉器代理。預處理器代理管理資料處理作為背景，包括命名實體辨識、查詢重寫、路徑連結和提取與查詢相關的架構等任務。產生器代理是一個針對 NL-GQL 資料微調過的 LLM，負責根據查詢及其相關架構產生對應的 GQL 陳述。精煉器代理負責使用從 GQL 執行結果取得的錯誤資訊來精煉 GQL 或背景。鑑於基於 nGQL 語法的優質開源 NL2GQL 資料集稀少，我們開發了 StockGQL，這是一個從金融市場圖形資料庫建構的資料集。它可於以下位置取得：https://github.com/leonyuancode/StockGQL。在 StockGQL 和 SpCQL 資料集上的實驗結果顯示，我們的模型明顯優於基準方法，突顯了其在推動 NL2GQL 研究方面的潛力。

##### **Repository-Level Graph Representation Learning for Enhanced Security Patch Detection**
2412.08068v1 by Xin-Cheng Wen, Zirui Lin, Cuiyun Gao, Hongyu Zhang, Yong Wang, Qing Liao

Software vendors often silently release security patches without providing
sufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed
updates via resources (e.g., National Vulnerability Database). Therefore, it
has become crucial to detect these security patches to ensure secure software
maintenance. However, existing methods face the following challenges: (1) They
primarily focus on the information within the patches themselves, overlooking
the complex dependencies in the repository. (2) Security patches typically
involve multiple functions and files, increasing the difficulty in well
learning the representations. To alleviate the above challenges, this paper
proposes a Repository-level Security Patch Detection framework named RepoSPD,
which comprises three key components: 1) a repository-level graph construction,
RepoCPG, which represents software patches by merging pre-patch and post-patch
source code at the repository level; 2) a structure-aware patch representation,
which fuses the graph and sequence branch and aims at comprehending the
relationship among multiple code changes; 3) progressive learning, which
facilitates the model in balancing semantic and structural information. To
evaluate RepoSPD, we employ two widely-used datasets in security patch
detection: SPI-DB and PatchDB. We further extend these datasets to the
repository level, incorporating a total of 20,238 and 28,781 versions of
repository in C/C++ programming languages, respectively, denoted as SPI-DB* and
PatchDB*. We compare RepoSPD with six existing security patch detection methods
and five static tools. Our experimental results demonstrate that RepoSPD
outperforms the state-of-the-art baseline, with improvements of 11.90%, and
3.10% in terms of accuracy on the two datasets, respectively.

摘要：<paragraph>軟體供應商通常會在沒有提供足夠的諮詢（例如常見漏洞和曝險）或延遲透過資源（例如國家漏洞資料庫）更新的情況下，無聲地發布安全性修補程式。因此，偵測這些安全性修補程式以確保軟體維護安全至關重要。然而，現有方法面臨以下挑戰：(1) 它們主要關注修補程式本身的資訊，忽略了儲存庫中複雜的相依性。(2) 安全性修補程式通常涉及多個函式和檔案，增加了良好學習表示形式的難度。為了緩解上述挑戰，本文提出了一個名為 RepoSPD 的儲存庫層級安全性修補程式偵測架構，它包含三個關鍵元件：1) 儲存庫層級圖形建構，RepoCPG，它透過合併儲存庫層級的前修補程式和後修補程式原始碼來表示軟體修補程式；2) 結構感知修補程式表示形式，它融合了圖形和序列分支，旨在理解多個程式碼變更之間的關係；3) 漸進式學習，它有助於模型平衡語意和結構資訊。為了評估 RepoSPD，我們在安全性修補程式偵測中採用了兩個廣泛使用的資料集：SPI-DB 和 PatchDB。我們進一步將這些資料集擴充套件到儲存庫層級，分別納入了 C/C++ 程式語言中總計 20,238 和 28,781 個版本的儲存庫，表示為 SPI-DB* 和 PatchDB*。我們將 RepoSPD 與六種現有的安全性修補程式偵測方法和五種靜態工具進行比較。我們的實驗結果表明，RepoSPD 優於最先進的基準，在兩個資料集上的準確性分別提高了 11.90% 和 3.10%。</paragraph>

##### **Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach**
2412.08038v2 by Hang Gao, Chenhao Zhang, Fengge Wu, Junsuo Zhao, Changwen Zheng, Huaping Liu

Graph representation learning methods are highly effective in handling
complex non-Euclidean data by capturing intricate relationships and features
within graph structures. However, traditional methods face challenges when
dealing with heterogeneous graphs that contain various types of nodes and edges
due to the diverse sources and complex nature of the data. Existing
Heterogeneous Graph Neural Networks (HGNNs) have shown promising results but
require prior knowledge of node and edge types and unified node feature
formats, which limits their applicability. Recent advancements in graph
representation learning using Large Language Models (LLMs) offer new solutions
by integrating LLMs' data processing capabilities, enabling the alignment of
various graph representations. Nevertheless, these methods often overlook
heterogeneous graph data and require extensive preprocessing. To address these
limitations, we propose a novel method that leverages the strengths of both LLM
and GNN, allowing for the processing of graph data with any format and type of
nodes and edges without the need for type information or special preprocessing.
Our method employs LLM to automatically summarize and classify different data
formats and types, aligns node features, and uses a specialized GNN for
targeted learning, thus obtaining effective graph representations for
downstream tasks. Theoretical analysis and experimental validation have
demonstrated the effectiveness of our method.

摘要：圖表表徵學習方法在處理複雜非歐幾里得資料時非常有效，它能捕捉圖表結構中的複雜關係和特徵。然而，傳統方法在處理異質圖表時會面臨挑戰，因為異質圖表包含各種節點和邊緣類型，這是由於資料來源多樣且性質複雜。現有的異質圖神經網路 (HGNN) 已展現出有前景的成果，但需要事先知道節點和邊緣類型，以及統一的節點特徵格式，這限制了它們的適用性。最近在使用大型語言模型 (LLM) 進行圖表表徵學習方面取得的進展提供了新的解決方案，方法是整合 LLM 的資料處理功能，讓各種圖表表徵得以對齊。儘管如此，這些方法經常忽略異質圖表資料，而且需要廣泛的預處理。為了解決這些限制，我們提出了一種新方法，它同時利用了 LLM 和 GNN 的優點，允許處理任何格式和類型節點和邊緣的圖表資料，而不需要類型資訊或特殊預處理。我們的這個方法採用 LLM 自動摘要和分類不同的資料格式和類型，對齊節點特徵，並使用專門的 GNN 進行目標學習，從而為下游任務取得有效的圖表表徵。理論分析和實驗驗證已證明我們這個方法的有效性。

##### **Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education**
2412.14191v1 by Chengshuai Zhao, Garima Agrawal, Tharindu Kumarage, Zhen Tan, Yuli Deng, Ying-Chih Chen, Huan Liu

Integrating AI into education has the potential to transform the teaching of
science and technology courses, particularly in the field of cybersecurity.
AI-driven question-answering (QA) systems can actively manage uncertainty in
cybersecurity problem-solving, offering interactive, inquiry-based learning
experiences. Large language models (LLMs) have gained prominence in AI-driven
QA systems, offering advanced language understanding and user engagement.
However, they face challenges like hallucinations and limited domain-specific
knowledge, which reduce their reliability in educational settings. To address
these challenges, we propose CyberRAG, an ontology-aware retrieval-augmented
generation (RAG) approach for developing a reliable and safe QA system in
cybersecurity education. CyberRAG employs a two-step approach: first, it
augments the domain-specific knowledge by retrieving validated cybersecurity
documents from a knowledge base to enhance the relevance and accuracy of the
response. Second, it mitigates hallucinations and misuse by integrating a
knowledge graph ontology to validate the final answer. Experiments on publicly
available cybersecurity datasets show that CyberRAG delivers accurate, reliable
responses aligned with domain knowledge, demonstrating the potential of AI
tools to enhance education.

摘要：將 AI 整合到教育中，有潛力轉型科學和技術課程的教學，特別是在網路安全領域。AI 驅動的問題解答 (QA) 系統可以積極管理網路安全問題解決中的不確定性，提供互動式、基於探究的學習體驗。大型語言模型 (LLM) 在 AI 驅動的 QA 系統中獲得顯著地位，提供進階的語言理解和使用者參與。然而，它們面臨幻覺和特定領域知識有限的挑戰，這會降低它們在教育環境中的可靠性。為了應對這些挑戰，我們提出 CyberRAG，一種意識到本體論的檢索增強生成 (RAG) 方法，用於在網路安全教育中開發可靠且安全的 QA 系統。CyberRAG 採用兩步驟方法：首先，它透過從知識庫中檢索已驗證的網路安全文件來擴充特定領域的知識，以增強回應的相關性和準確性。其次，它透過整合知識圖譜本體論來驗證最終答案，以減輕幻覺和誤用。在公開的網路安全資料集上進行的實驗顯示，CyberRAG 提供準確、可靠的回應，符合領域知識，證明了 AI 工具增強教育的潛力。

##### **Combining knowledge graphs and LLMs for hazardous chemical information management and reuse**
2412.09644v1 by Marcos Da Silveira, Louis Deladiennee, Kheira Acem, Oona Freudenthal

Human health is increasingly threatened by exposure to hazardous substances,
particularly persistent and toxic chemicals. The link between these substances,
often encountered in complex mixtures, and various diseases are demonstrated in
scientific studies. However, this information is scattered across several
sources and hardly accessible by humans and machines. This paper evaluates
current practices for publishing/accessing information on hazardous chemicals
and proposes a novel platform designed to facilitate retrieval of critical
chemical data in urgent situations. The platform aggregates information from
multiple sources and organizes it into a structured knowledge graph. Users can
access this information through a visual interface such as Neo4J Bloom and
dashboards, or via natural language queries using a Chatbot. Our findings
demonstrate a significant reduction in the time and effort required to access
vital chemical information when datasets follow FAIR principles. Furthermore,
we discuss the lessons learned from the development and implementation of this
platform and provide recommendations for data owners and publishers to enhance
data reuse and interoperability. This work aims to improve the accessibility
and usability of chemical information by healthcare professionals, thereby
supporting better health outcomes and informed decision-making in the face of
patients exposed to chemical intoxication risks.

摘要：人類健康越來越受到接觸有害物質的威脅，尤其是持久性和有毒的化學物質。科學研究已證明這些物質（通常存在於複雜的混合物中）與各種疾病之間的關聯。然而，這些資訊分散在多個來源中，人類和機器都很難取得。本文評估了當前發布/取得有關有害化學物質資訊的慣例，並提出一個新穎的平台，旨在促進在緊急情況下取得關鍵化學資料。此平台匯集來自多個來源的資訊，並將其組織成結構化的知識圖譜。使用者可以透過視覺化介面（例如 Neo4J Bloom 和儀表板）或使用聊天機器人的自然語言查詢來取得這些資訊。我們的研究結果表明，當資料集遵循 FAIR 原則時，取得重要化學資訊所需的時間和精力會大幅減少。此外，我們討論從此平台的開發和實作中學到的經驗教訓，並為資料擁有者和發布者提供建議，以增強資料再利用和互操作性。這項工作旨在改善醫療保健專業人員取得和使用化學資訊的方式，從而支持更好的健康結果，並在面對接觸化學中毒風險的患者時做出明智的決策。

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v2 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多自然語言處理任務中表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，利用擷取增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，可以穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：非平穩環境的持續演變可能會導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。為了應對這些挑戰，我們引入了一個多目標多臂老虎機增強的 RAG 框架，由多種擷取方法支援，這些方法在實務中具有豐富且不斷演化的擷取背景下的不同功能。在此框架內，每種擷取方法都被視為一個不同的「臂」。該系統利用即時使用者回饋來適應動態環境，方法是根據輸入查詢和每個臂的歷史多目標效能來選擇適當的擷取方法。在兩個基準 KGQA 資料集上進行的廣泛實驗表明，我們的模型在非平穩環境中明顯優於基線模型，同時在平穩環境中實現了最先進的效能。程式碼和資料可在 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **RAG-based Question Answering over Heterogeneous Data and Text**
2412.07420v1 by Philipp Christmann, Gerhard Weikum

This article presents the QUASAR system for question answering over
unstructured text, structured tables, and knowledge graphs, with unified
treatment of all sources. The system adopts a RAG-based architecture, with a
pipeline of evidence retrieval followed by answer generation, with the latter
powered by a moderate-sized language model. Additionally and uniquely, QUASAR
has components for question understanding, to derive crisper input for evidence
retrieval, and for re-ranking and filtering the retrieved evidence before
feeding the most informative pieces into the answer generation. Experiments
with three different benchmarks demonstrate the high answering quality of our
approach, being on par with or better than large GPT models, while keeping the
computational cost and energy consumption orders of magnitude lower.

摘要：本文介紹 QUASAR 系統，用於回答非結構化文字、結構化表格和知識圖表中的問題，並統一處理所有來源。該系統採用基於 RAG 的架構，管道包括證據檢索後接答案生成，後者由中等規模的語言模型提供支援。此外，QUASAR 獨特地包含問題理解元件，以衍生更清晰的輸入進行證據檢索，以及在將最有資訊的片段輸入答案生成之前重新排序和過濾檢索到的證據。使用三個不同的基準進行的實驗證明了我們方法的高回答品質，與大型 GPT 模型相當或更好，同時將運算成本和能源消耗降低了幾個數量級。

##### **Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**
2412.07412v1 by Ahan Bhatt, Nandan Vaghela, Kush Dudhia

Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a
form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks
requiring structured reasoning and semantic understanding. However, creating
KGs for GraphRAGs remains a significant challenge due to accuracy and
scalability limitations of traditional methods. This paper introduces a novel
approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and
BERT to generate KGs directly from unstructured data, bypassing traditional
pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit
Distance, and Semantic Similarity, we evaluate the models' ability to generate
high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic
fidelity and structural accuracy, LLaMA 2 excels in lightweight,
domain-specific graphs, and BERT provides insights into challenges in
entity-relationship modeling. This study underscores the potential of LLMs to
streamline KG creation and enhance GraphRAG accessibility for real-world
applications, while setting a foundation for future advancements.

摘要：知識圖譜 (KG) 對於 GraphRAG 的功能至關重要，GraphRAG 是一種檢索增強式生成系統 (RAG)，在需要結構化推理和語義理解的任務中表現出色。然而，由於傳統方法的準確性和可擴充性限制，為 GraphRAG 建立 KG 仍然是一項重大挑戰。本文介紹了一種創新方法，利用大型語言模型 (LLM)，例如 GPT-4、LLaMA 2 (13B) 和 BERT，直接從非結構化數據生成 KG，繞過傳統管道。我們使用準確度、召回率、F1 分數、圖形編輯距離和語義相似性等指標，評估模型生成高品質 KG 的能力。結果表明，GPT-4 達到了卓越的語義保真度和結構準確性，LLaMA 2 在輕量級、特定領域的圖形中表現出色，而 BERT 則提供了對實體關係建模挑戰的見解。這項研究強調了 LLM 簡化 KG 建立和增強 GraphRAG 在現實世界應用中可及性的潛力，同時為未來的進展奠定了基礎。

##### **My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**
2412.07367v1 by Jian Liao, Yu Feng, Xiaoyu Wang, Suge Wang, Jianxing Zheng, Deyu Li

In implicit emotion analysis (IEA), the subtlety of emotional expressions
makes it particularly sensitive to user-specific characteristics. Existing
studies often inject personalization into the analysis by focusing on the
authorial dimension of the emotional text. However, these methods overlook the
potential influence of the intended reader on the reaction of implicit
emotions. In this paper, we refine the IEA task to Personalized Implicit
Emotion Analysis (PIEA) and introduce the RAPPIE model, a novel framework
designed to address the issue of missing user information within this task. In
particular, 1) we create reader agents based on the Large Language Model to
simulate reader reactions, to address challenges of the spiral of silence and
data incompleteness encountered when acquiring reader feedback information. 2)
We establish a reader propagation role system and develop a role-aware emotion
propagation multi-view graph learning model, which effectively deals with the
sparsity of reader information by utilizing the distribution of propagation
roles. 3) We annotate two Chinese PIEA datasets with detailed user metadata,
thereby addressing the limitation of prior datasets that primarily focus on
textual content annotation. Extensive experiments on these datasets indicate
that the RAPPIE model outperforms current state-of-the-art baselines,
highlighting the significance and efficacy of incorporating reader feedback
into the PIEA process.

摘要：在隐式情感分析 (IEA) 中，情感表达的微妙性使其对特定于用户的特征特别敏感。现有的研究通常通过关注情感文本的作者维度来将个性化注入到分析中。然而，这些方法忽略了预期读者对隐式情感反应的潜在影响。在本文中，我们将 IEA 任务细化为个性化隐式情感分析 (PIEA)，并引入 RAPPIE 模型，这是一个新颖的框架，旨在解决此任务中缺少用户信息的问题。特别是，1) 我们基于大型语言模型创建读者代理来模拟读者反应，以解决在获取读者反馈信息时遇到的沉默螺旋和数据不完整性的挑战。2) 我们建立了一个读者传播角色系统，并开发了一个角色感知情绪传播多视图图学习模型，该模型通过利用传播角色的分布有效地处理读者信息的稀疏性。3) 我们使用详细的用户元数据注释了两个中文 PIEA 数据集，从而解决了先前主要专注于文本内容注释的数据集的局限性。在这些数据集上进行的广泛实验表明，RAPPIE 模型优于当前最先进的基线，突出了将读者反馈纳入 PIEA 过程的重要性及有效性。

##### **ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models**
2412.07012v2 by Jieyu Zhang, Le Xue, Linxin Song, Jun Wang, Weikai Huang, Manli Shu, An Yan, Zixian Ma, Juan Carlos Niebles, silvio savarese, Caiming Xiong, Zeyuan Chen, Ranjay Krishna, Ran Xu

With the rise of multimodal applications, instruction data has become
critical for training multimodal language models capable of understanding
complex image-based queries. Existing practices rely on powerful but costly
large language models (LLMs) or multimodal language models (MLMs) to produce
instruction data. These are often prone to hallucinations, licensing issues and
the generation process is often hard to scale and interpret. In this work, we
present a programmatic approach that employs scene graphs as symbolic
representations of images and human-written programs to systematically
synthesize vision-centric instruction data. Our approach ensures the
interpretability and controllability of the data generation process and scales
efficiently while maintaining factual accuracy. By implementing a suite of 24
single-image, 14 multi-image instruction generators, and a scene graph
generation pipeline, we build a scalable, cost-effective system: ProVision
which produces diverse question-answer pairs concerning objects, attributes,
relations, depth, etc., for any given image. Applied to Visual Genome and
DataComp datasets, we generate over 10 million instruction data points,
ProVision-10M, and leverage them in both pretraining and instruction tuning
stages of MLMs. When adopted in the instruction tuning stage, our single-image
instruction data yields up to a 7% improvement on the 2D split and 8% on the 3D
split of CVBench, along with a 3% increase in performance on QBench2,
RealWorldQA, and MMMU. Our multi-image instruction data leads to an 8%
improvement on Mantis-Eval. Incorporation of our data in both pre-training and
fine-tuning stages of xGen-MM-4B leads to an averaged improvement of 1.6%
across 11 benchmarks.

摘要：<paragraph>隨著多模態應用程式興起，指令資料已成為訓練多模態語言模型的關鍵，該模型能夠理解基於複雜影像的查詢。現有做法依賴於強大但昂貴的大型語言模型 (LLM) 或多模態語言模型 (MLM) 來產生指令資料。這些方法經常容易出現幻覺、授權問題，且生成過程通常難以擴充和詮釋。在這項工作中，我們提出了一種程式化方法，使用場景圖形作為影像的符號表示，並使用人撰寫的程式系統性地合成以視覺為中心的指令資料。我們的做法確保了資料生成過程的可詮釋性和可控性，並在維持事實準確性的同時有效地擴充。透過實作一組 24 個單一影像、14 個多重影像指令產生器，以及一個場景圖形產生管線，我們建立了一個可擴充、具有成本效益的系統：ProVision，它針對任何給定的影像產生關於物件、屬性、關係、深度等的各種問答配對。應用於 Visual Genome 和 DataComp 資料集，我們產生了超過 1000 萬個指令資料點，ProVision-10M，並在 MLM 的預訓練和指令微調階段中加以利用。當在指令微調階段採用時，我們的單一影像指令資料在 CVBench 的 2D 分割中提升了 7%，在 3D 分割中提升了 8%，在 QBench2、RealWorldQA 和 MMMU 上的效能也提升了 3%。我們的多重影像指令資料在 Mantis-Eval 上提升了 8%。在 xGen-MM-4B 的預訓練和微調階段中納入我們的資料，在 11 個基準測試中平均提升了 1.6%。</paragraph>

##### **Generative Adversarial Reviews: When LLMs Become the Critic**
2412.10415v1 by Nicolas Bougie, Narimasa Watanabe

The peer review process is fundamental to scientific progress, determining
which papers meet the quality standards for publication. Yet, the rapid growth
of scholarly production and increasing specialization in knowledge areas strain
traditional scientific feedback mechanisms. In light of this, we introduce
Generative Agent Reviewers (GAR), leveraging LLM-empowered agents to simulate
faithful peer reviewers. To enable generative reviewers, we design an
architecture that extends a large language model with memory capabilities and
equips agents with reviewer personas derived from historical data. Central to
this approach is a graph-based representation of manuscripts, condensing
content and logically organizing information - linking ideas with evidence and
technical details. GAR's review process leverages external knowledge to
evaluate paper novelty, followed by detailed assessment using the graph
representation and multi-round assessment. Finally, a meta-reviewer aggregates
individual reviews to predict the acceptance decision. Our experiments
demonstrate that GAR performs comparably to human reviewers in providing
detailed feedback and predicting paper outcomes. Beyond mere performance
comparison, we conduct insightful experiments, such as evaluating the impact of
reviewer expertise and examining fairness in reviews. By offering early
expert-level feedback, typically restricted to a limited group of researchers,
GAR democratizes access to transparent and in-depth evaluation.

摘要：同行評審程序對於科學進展至關重要，它決定了哪些論文符合出版的品質標準。然而，學術著作的快速增長以及知識領域的日益專業化，對傳統的科學回饋機制造成壓力。有鑑於此，我們引入了生成式代理審查員 (GAR)，利用 LLM 賦能的代理來模擬忠實的同行審查員。為了啟用生成式審查員，我們設計了一種架構，將大型語言模型擴展到具備記憶能力，並使用從歷史數據中衍生的審查員角色來裝備代理。這種方法的核心是手稿的圖形化表示，濃縮內容並邏輯地組織資訊，將想法與證據和技術細節聯繫起來。GAR 的審查過程利用外部知識來評估論文的新穎性，然後使用圖形表示和多輪評估進行詳細評估。最後，一位元審查員彙總個別審查意見，以預測接受決定。我們的實驗表明，GAR 在提供詳細回饋和預測論文結果方面，表現與人類審查員相當。除了單純的性能比較之外，我們還進行了有見地的實驗，例如評估審查員專業知識的影響，以及審查公平性的檢視。透過提供早期專家級回饋，通常僅限於少數研究人員，GAR 民主化了對透明且深入評估的存取。

##### **A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases**
2412.06212v1 by Zhepeng Wang, Runxue Bao, Yawen Wu, Guodong Liu, Lei Yang, Liang Zhan, Feng Zheng, Weiwen Jiang, Yanfu Zhang

Graph neural networks (GNNs) are powerful machine learning models designed to
handle irregularly structured data. However, their generic design often proves
inadequate for analyzing brain connectomes in Alzheimer's Disease (AD),
highlighting the need to incorporate domain knowledge for optimal performance.
Infusing AD-related knowledge into GNNs is a complicated task. Existing methods
typically rely on collaboration between computer scientists and domain experts,
which can be both time-intensive and resource-demanding. To address these
limitations, this paper presents a novel self-guided, knowledge-infused
multimodal GNN that autonomously incorporates domain knowledge into the model
development process. Our approach conceptualizes domain knowledge as natural
language and introduces a specialized multimodal GNN capable of leveraging this
uncurated knowledge to guide the learning process of the GNN, such that it can
improve the model performance and strengthen the interpretability of the
predictions. To evaluate our framework, we curated a comprehensive dataset of
recent peer-reviewed papers on AD and integrated it with multiple real-world AD
datasets. Experimental results demonstrate the ability of our method to extract
relevant domain knowledge, provide graph-based explanations for AD diagnosis,
and improve the overall performance of the GNN. This approach provides a more
scalable and efficient alternative to inject domain knowledge for AD compared
with the manual design from the domain expert, advancing both prediction
accuracy and interpretability in AD diagnosis.

摘要：圖形神經網路 (GNN) 是一款強大的機器學習模型，專門用於處理結構不規則的資料。然而，它們的通用設計通常無法充分分析阿茲海默症 (AD) 中的腦連接體，突顯了加入領域知識以優化效能的需求。將 AD 相關知識融入 GNN 是一項複雜的任務。現有方法通常仰賴電腦科學家和領域專家之間的合作，這可能會耗費大量時間和資源。為了解決這些限制，本文提出了一種新穎的自導式、知識注入多模式 GNN，它能自主地將領域知識納入模型開發過程中。我們的做法將領域知識概念化為自然語言，並引入一個專門的多模式 GNN，它能利用這種未經整理的知識來指導 GNN 的學習過程，以便它能改善模型效能並加強預測的可解釋性。為了評估我們的架構，我們整理了一份關於 AD 的近期同行評審論文的全面資料集，並將其與多個真實世界的 AD 資料集整合。實驗結果證明了我們的方法能夠萃取相關的領域知識、提供 AD 診斷的圖形化說明，並改善 GNN 的整體效能。與領域專家的手動設計相比，這種方法提供了一個更具可擴充性和效率性的替代方案，用於注入 AD 的領域知識，進而提升 AD 診斷中的預測準確性和可解釋性。

##### **Automated Extraction and Creation of FBS Design Reasoning Knowledge Graphs from Structured Data in Product Catalogues Lacking Contextual Information**
2412.05868v1 by Vijayalaxmi Sahadevan, Sushil Mario, Yash Jaiswal, Divyanshu Bajpai, Vishal Singh, Hiralal Aggarwal, Suhas Suresh, Manjunath Maigur

Ontology-based knowledge graphs (KG) are desirable for effective knowledge
management and reuse in various decision making scenarios, including design.
Creating and populating extensive KG based on specific ontological models can
be highly labour and time-intensive unless automated processes are developed
for knowledge extraction and graph creation. Most research and development on
automated extraction and creation of KG is based on extensive unstructured data
sets that provide contextual information. However, some of the most useful
information about the products and services of a company has traditionally been
recorded as structured data. Such structured data sets rarely follow a standard
ontology, do not capture explicit mapping of relationships between the
entities, and provide no contextual information. Therefore, this research
reports a method and digital workflow developed to address this gap. The
developed method and workflow employ rule-based techniques to extract and
create a Function Behaviour-Structure (FBS) ontology-based KG from legacy
structured data, especially specification sheets and product catalogues. The
solution approach consists of two main components: a process for deriving
context and context-based classification rules for FBS ontology concepts and a
workflow for populating and retrieving the FBS ontology-based KG. KG and
Natural Language Processing (NLP) are used to automate knowledge extraction,
representation, and retrieval. The workflow's effectiveness is demonstrated via
pilot implementation in an industrial context. Insights gained from the pilot
study are reported regarding the challenges and opportunities, including
discussing the FBS ontology and concepts.

摘要：<paragraph>基於本体論的知識圖譜 (KG) 對於在各種決策制定情境（包括設計）中有效管理和重用知識是理想的。建立並填入基於特定本體模型的廣泛 KG 可能非常耗費人力和時間，除非開發出用於知識萃取和圖譜建立的自動化流程。大多數關於 KG 自動化萃取和建立的研究和開發都基於提供脈絡資訊的廣泛非結構化資料集。然而，關於公司產品和服務的一些最有用的資訊傳統上都是以結構化資料記錄的。此類結構化資料集很少遵循標準本體論，不會擷取實體之間關係的明確對應，也不會提供脈絡資訊。因此，本研究報告了一種方法和數位工作流程，用於解決此差距。開發的方法和工作流程採用基於規則的技術，從傳統結構化資料（特別是規格表和產品目錄）中萃取並建立功能行為結構 (FBS) 本體論基礎的 KG。解決方案方法包含兩個主要組成部分：一個用於推導 FBS 本體論概念的脈絡和基於脈絡的分類規則的流程，以及一個用於填入和檢索 FBS 本體論基礎的 KG 的工作流程。KG 和自然語言處理 (NLP) 用於自動化知識萃取、表示和檢索。工作流程的有效性透過在工業脈絡中的試點實作得到證明。報告了從試點研究中獲得的見解，包括討論 FBS 本體論和概念在內的挑戰和機會。</paragraph>

##### **A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data**
2412.05838v1 by Aniruddha Salve, Saba Attar, Mahesh Deshmukh, Sayali Shivpuje, Arnab Mitra Utsab

Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
incorporating external, domain-specific data into the generative process. While
LLMs are highly capable, they often rely on static, pre-trained datasets,
limiting their ability to integrate dynamic or private data. Traditional RAG
systems typically use a single-agent architecture to handle query generation,
data retrieval, and response synthesis. However, this approach becomes
inefficient when dealing with diverse data sources, such as relational
databases, document stores, and graph databases, often leading to performance
bottlenecks and reduced accuracy. This paper proposes a multi-agent RAG system
to address these limitations. Specialized agents, each optimized for a specific
data source, handle query generation for relational, NoSQL, and document-based
systems. These agents collaborate within a modular framework, with query
execution delegated to an environment designed for compatibility across various
database types. This distributed approach enhances query efficiency, reduces
token overhead, and improves response accuracy by ensuring that each agent
focuses on its specialized task. The proposed system is scalable and adaptable,
making it ideal for generative AI workflows that require integration with
diverse, dynamic, or private data sources. By leveraging specialized agents and
a modular execution environment, the system provides an efficient and robust
solution for handling complex, heterogeneous data environments in generative AI
applications.

摘要：檢索增強生成 (RAG) 透過將外部領域特定資料納入生成流程，增強大型語言模型 (LLM)。雖然 LLM 具有高度能力，但它們通常依賴於靜態的預訓練資料集，限制了它們整合動態或私人資料的能力。傳統的 RAG 系統通常使用單一代理架構來處理查詢生成、資料檢索和回應合成。然而，當處理多樣化的資料來源時，這種方法會變得沒有效率，例如關係資料庫、文件儲存和圖形資料庫，通常會導致效能瓶頸和降低準確性。本文提出一個多代理 RAG 系統來解決這些限制。針對特定資料來源最佳化的專門代理，負責關係、NoSQL 和基於文件系統的查詢生成。這些代理在一個模組化架構內協作，查詢執行委派給一個環境，該環境設計為與各種資料庫類型相容。這種分散式方法增強了查詢效率，減少了標記開銷，並透過確保每個代理專注於其專門任務，來改善回應準確性。所提出的系統具有可擴充性和適應性，使其成為需要與多樣化、動態或私人資料來源整合的生成式 AI 工作流程的理想選擇。透過利用專門代理和模組化執行環境，該系統為處理生成式 AI 應用程式中複雜、異質的資料環境，提供了一個有效且穩健的解決方案。

##### **Large Language Models Merging for Enhancing the Link Stealing Attack on Graph Neural Networks**
2412.05830v1 by Faqian Guan, Tianqing Zhu, Wenhan Chang, Wei Ren, Wanlei Zhou

Graph Neural Networks (GNNs), specifically designed to process the graph
data, have achieved remarkable success in various applications. Link stealing
attacks on graph data pose a significant privacy threat, as attackers aim to
extract sensitive relationships between nodes (entities), potentially leading
to academic misconduct, fraudulent transactions, or other malicious activities.
Previous studies have primarily focused on single datasets and did not explore
cross-dataset attacks, let alone attacks that leverage the combined knowledge
of multiple attackers. However, we find that an attacker can combine the data
knowledge of multiple attackers to create a more effective attack model, which
can be referred to cross-dataset attacks. Moreover, if knowledge can be
extracted with the help of Large Language Models (LLMs), the attack capability
will be more significant. In this paper, we propose a novel link stealing
attack method that takes advantage of cross-dataset and Large Language Models
(LLMs). The LLM is applied to process datasets with different data structures
in cross-dataset attacks. Each attacker fine-tunes the LLM on their specific
dataset to generate a tailored attack model. We then introduce a novel model
merging method to integrate the parameters of these attacker-specific models
effectively. The result is a merged attack model with superior generalization
capabilities, enabling effective attacks not only on the attackers' datasets
but also on previously unseen (out-of-domain) datasets. We conducted extensive
experiments in four datasets to demonstrate the effectiveness of our method.
Additional experiments with three different GNN and LLM architectures further
illustrate the generality of our approach.

摘要：圖神經網路 (GNN) 專門用於處理圖形資料，在各種應用中都取得了顯著的成功。連結竊取攻擊對圖形資料構成重大的隱私威脅，因為攻擊者旨在提取節點（實體）之間的敏感關係，可能導致學術不當行為、欺詐交易或其他惡意活動。先前的研究主要集中於單一資料集，並且沒有探討跨資料集攻擊，更不用說利用多個攻擊者的綜合知識的攻擊。然而，我們發現攻擊者可以結合多個攻擊者的資料知識來建立更有效的攻擊模型，這可以稱為跨資料集攻擊。此外，如果可以在大型語言模型 (LLM) 的幫助下提取知識，則攻擊能力將會更顯著。在本文中，我們提出了一種新穎的連結竊取攻擊方法，該方法利用跨資料集和大型語言模型 (LLM)。LLM 用於在跨資料集攻擊中處理具有不同資料結構的資料集。每個攻擊者針對其特定資料集微調 LLM 以產生量身打造的攻擊模型。然後，我們引入一種新穎的模型合併方法，以有效整合這些特定於攻擊者的模型的參數。結果是一個合併的攻擊模型，具有優異的泛化能力，不僅可以在攻擊者的資料集上進行有效攻擊，還可以在以前未見的（域外）資料集上進行有效攻擊。我們在四個資料集中進行了廣泛的實驗，以證明我們方法的有效性。使用三種不同的 GNN 和 LLM 架構進行的額外實驗進一步說明了我們方法的普遍性。

##### **GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model**
2412.06849v1 by Haotong Yang, Xiyuan Wang, Qian Tao, Shuxian Hu, Zhouchen Lin, Muhan Zhang

Recent research on integrating Large Language Models (LLMs) with Graph Neural
Networks (GNNs) typically follows two approaches: LLM-centered models, which
convert graph data into tokens for LLM processing, and GNN-centered models,
which use LLMs to encode text features into node and edge representations for
GNN input. LLM-centered models often struggle to capture graph structures
effectively, while GNN-centered models compress variable-length textual data
into fixed-size vectors, limiting their ability to understand complex
semantics. Additionally, GNN-centered approaches require converting tasks into
a uniform, manually-designed format, restricting them to classification tasks
and preventing language output. To address these limitations, we introduce a
new architecture that deeply integrates GNN with LLM, featuring three key
innovations: (1) Structure-Aware Transformers, which incorporate GNN's
message-passing capabilities directly into LLM's transformer layers, allowing
simultaneous processing of textual and structural information and generating
outputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes
full, uncompressed text from graph nodes and edges, ensuring complete semantic
integration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible
autoregressive generation alongside GNN's scalable one-pass prediction.
GL-Fusion achieves outstand performance on various tasks. Notably, it achieves
state-of-the-art performance on OGBN-Arxiv and OGBG-Code2.

摘要：<paragraph>將大型語言模型 (LLM) 與圖神經網路 (GNN) 整合的最新研究通常遵循兩種方法：以 LLM 為中心的模型，將圖形資料轉換為 LLM 處理的符號，以及以 GNN 為中心的模型，使用 LLM 將文字特徵編碼成節點和邊緣表示，作為 GNN 輸入。以 LLM 為中心的模型通常難以有效擷取圖形結構，而以 GNN 為中心的模型會將變長文字資料壓縮成固定大小的向量，限制它們理解複雜語意的能力。此外，以 GNN 為中心的模型需要將任務轉換成統一的手動設計格式，限制它們只能進行分類任務，且無法產生語言輸出。為了解決這些限制，我們引入一種新的架構，將 GNN 與 LLM 深度整合，具備三大關鍵創新：(1) 結構感知Transformer，將 GNN 的訊息傳遞功能直接整合到 LLM 的Transformer層中，允許同時處理文字和結構資訊，並從 GNN 和 LLM 產生輸出；(2) 圖形文字交叉注意力，處理來自圖形節點和邊緣的完整未壓縮文字，確保完整的語義整合；(3) GNN-LLM 雙重預測器，啟用 LLM 的彈性自迴歸產生，以及 GNN 的可擴充單次預測。GL-Fusion 在各種任務中達成傑出的效能。值得注意的是，它在 OGBN-Arxiv 和 OGBG-Code2 上達到了最先進的效能。</paragraph>

##### **M$^{3}$-20M: A Large-Scale Multi-Modal Molecule Dataset for AI-driven Drug Design and Discovery**
2412.06847v1 by Siyuan Guo, Lexuan Wang, Chang Jin, Jinxian Wang, Han Peng, Huayang Shi, Wengen Li, Jihong Guan, Shuigeng Zhou

This paper introduces M$^{3}$-20M, a large-scale Multi-Modal Molecular
dataset that contains over 20 million molecules. Designed to support AI-driven
drug design and discovery, M$^{3}$-20M is 71 times more in the number of
molecules than the largest existing dataset, providing an unprecedented scale
that can highly benefit training or fine-tuning large (language) models with
superior performance for drug design and discovery. This dataset integrates
one-dimensional SMILES, two-dimensional molecular graphs, three-dimensional
molecular structures, physicochemical properties, and textual descriptions
collected through web crawling and generated by using GPT-3.5, offering a
comprehensive view of each molecule. To demonstrate the power of M$^{3}$-20M in
drug design and discovery, we conduct extensive experiments on two key tasks:
molecule generation and molecular property prediction, using large language
models including GLM4, GPT-3.5, and GPT-4. Our experimental results show that
M$^{3}$-20M can significantly boost model performance in both tasks.
Specifically, it enables the models to generate more diverse and valid
molecular structures and achieve higher property prediction accuracy than the
existing single-modal datasets, which validates the value and potential of
M$^{3}$-20M in supporting AI-driven drug design and discovery. The dataset is
available at \url{https://github.com/bz99bz/M-3}.

摘要：這篇論文介紹了 M$^{3}$-20M，一個包含超過 2000 萬個分子的大型多模態分子資料集。M$^{3}$-20M 旨在支援 AI 驅動的藥物設計和發現，其分子數量是現有最大資料集的 71 倍，提供了前所未有的規模，可以極大地受益於訓練或微調大型（語言）模型，以在藥物設計和發現方面獲得卓越的效能。此資料集整合了透過網路爬取收集和使用 GPT-3.5 生成的單維 SMILES、二維分子圖、三維分子結構、物理化學性質和文字描述，提供了每個分子的全面檢視。為了展示 M$^{3}$-20M 在藥物設計和發現中的強大功能，我們對兩個關鍵任務進行了廣泛的實驗：分子生成和分子性質預測，使用包括 GLM4、GPT-3.5 和 GPT-4 在內的大型語言模型。我們的實驗結果表明，M$^{3}$-20M 可以顯著提升模型在兩個任務中的效能。具體來說，它使模型能夠產生更多樣化和有效的分子結構，並比現有的單模態資料集獲得更高的性質預測準確度，這驗證了 M$^{3}$-20M 在支援 AI 驅動的藥物設計和發現中的價值和潛力。資料集可在 \url{https://github.com/bz99bz/M-3} 取得。

##### **HMGIE: Hierarchical and Multi-Grained Inconsistency Evaluation for Vision-Language Data Cleansing**
2412.05685v1 by Zihao Zhu, Hongbao Zhang, Guanzong Wu, Siwei Lyu, Baoyuan Wu

Visual-textual inconsistency (VTI) evaluation plays a crucial role in
cleansing vision-language data. Its main challenges stem from the high variety
of image captioning datasets, where differences in content can create a range
of inconsistencies (\eg, inconsistencies in scene, entities, entity attributes,
entity numbers, entity interactions). Moreover, variations in caption length
can introduce inconsistencies at different levels of granularity as well. To
tackle these challenges, we design an adaptive evaluation framework, called
Hierarchical and Multi-Grained Inconsistency Evaluation (HMGIE), which can
provide multi-grained evaluations covering both accuracy and completeness for
various image-caption pairs. Specifically, the HMGIE framework is implemented
by three consecutive modules. Firstly, the semantic graph generation module
converts the image caption to a semantic graph for building a structural
representation of all involved semantic items. Then, the hierarchical
inconsistency evaluation module provides a progressive evaluation procedure
with a dynamic question-answer generation and evaluation strategy guided by the
semantic graph, producing a hierarchical inconsistency evaluation graph (HIEG).
Finally, the quantitative evaluation module calculates the accuracy and
completeness scores based on the HIEG, followed by a natural language
explanation about the detection results. Moreover, to verify the efficacy and
flexibility of the proposed framework on handling different image captioning
datasets, we construct MVTID, an image-caption dataset with diverse types and
granularities of inconsistencies. Extensive experiments on MVTID and other
benchmark datasets demonstrate the superior performance of the proposed HMGIE
to current state-of-the-art methods.

摘要：視覺文本不一致性 (VTI) 評估在清理視覺語言資料中扮演著至關重要的角色。其主要挑戰源自於圖像標題資料集的種類繁多，其中內容的差異可能會造成各種不一致性（例如場景、實體、實體屬性、實體數量、實體互動的不一致性）。此外，標題長度的變化也會在不同粒度層級引發不一致性。為了應對這些挑戰，我們設計了一個自適應評估架構，稱為階層式多粒度不一致性評估 (HMGIE)，它可以提供多粒度評估，涵蓋各種圖像標題對的準確性和完整性。具體來說，HMGIE 架構是由三個連續模組實作的。首先，語意圖形產生模組將圖像標題轉換為語意圖形，以建立所有相關語意項目的結構化表示。然後，階層式不一致性評估模組提供漸進式評估程序，並採用由語意圖形引導的動態問題解答產生和評估策略，產生階層式不一致性評估圖形 (HIEG)。最後，量化評估模組根據 HIEG 計算準確性和完整性分數，接著對偵測結果進行自然語言說明。此外，為了驗證所提出的架構在處理不同圖像標題資料集上的效能和靈活性，我們建構了 MVTID，一個具有不同類型和不一致性粒度的圖像標題資料集。在 MVTID 和其他基準資料集上的大量實驗證明了所提出的 HMGIE 優於當前最先進的方法。

##### **KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models**
2412.05547v1 by Weijie Chen, Ting Bai, Jinbo Su, Jian Luan, Wei Liu, Chuan Shi

Large language models with retrieval-augmented generation encounter a pivotal
challenge in intricate retrieval tasks, e.g., multi-hop question answering,
which requires the model to navigate across multiple documents and generate
comprehensive responses based on fragmented information. To tackle this
challenge, we introduce a novel Knowledge Graph-based RAG framework with a
hierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing
in KG-Retriever is constructed on a hierarchical index graph that consists of a
knowledge graph layer and a collaborative document layer. The associative
nature of graph structures is fully utilized to strengthen intra-document and
inter-document connectivity, thereby fundamentally alleviating the information
fragmentation problem and meanwhile improving the retrieval efficiency in
cross-document retrieval of LLMs. With the coarse-grained collaborative
information from neighboring documents and concise information from the
knowledge graph, KG-Retriever achieves marked improvements on five public QA
datasets, showing the effectiveness and efficiency of our proposed RAG
framework.

摘要：大型语言模型使用检索增强生成在复杂的检索任务中会遇到关键挑战，例如多跳问题解答，这要求模型跨多个文档导航并根据片段信息生成综合响应。为了应对这一挑战，我们引入了一个基于知识图谱的新型 RAG 框架，该框架具有分层知识检索器，称为 KG-Retriever。KG-Retriever 中的检索索引构建在分层索引图上，该图由知识图谱层和协作文档层组成。图结构的关联性质被充分利用以加强文档内和文档间连接性，从而从根本上缓解信息碎片化问题，同时提高 LLM 跨文档检索中的检索效率。通过来自相邻文档的粗粒度协作信息和来自知识图谱的简洁信息，KG-Retriever 在五个公共问答数据集上取得了显着改进，显示了我们提出的 RAG 框架的有效性和效率。

##### **LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System**
2412.16172v1 by Emmanuel A. Olowe, Danial Chitnis

The complexity of laboratory environments requires solutions that simplify
instrument interaction and enhance measurement automation. Traditional tools
often require configuration, software, and programming skills, creating
barriers to productivity. Previous approaches, including dedicated software
suites and custom scripts, frequently fall short in providing user-friendly
solutions that align with programming practices. We present LABIIUM, an
AI-enhanced, zero-configuration measurement automation system designed to
streamline experimental workflows and improve user productivity. LABIIUM
integrates an AI assistant powered by Large Language Models (LLMs) to generate
code. LABIIUM's Lab-Automation-Measurement Bridges (LAMBs) enable seamless
instrument connectivity using standard tools such as VSCode and Python,
eliminating setup overhead. To demonstrate its capabilities, we conducted
experiments involving the measurement of the parametric transfer curve of a
simple two-transistor inverting amplifier with a current source load. The AI
assistant was evaluated using different prompt scenarios and compared with
multiple models, including Claude Sonnet 3.5, Gemini Pro 1.5, and GPT-4o. An
expert solution implementing the Gradient-Weighted Adaptive Stochastic Sampling
(GWASS) method was used as a baseline. The solutions generated by the AI
assistant were compared with the expert solution and a uniform linear sweep
baseline with 10,000 points. The graph results show that the LLMs were able to
successfully complete the most basic uniform sweep, but LLMs were unable to
develop adaptive sweeping algorithms to compete with GWASS. The evaluation
underscores LABIIUM's ability to enhance laboratory productivity and support
digital transformation in research and industry, and emphasizes the future work
required to improve LLM performance in Electronic Measurement Science Tasks.

摘要：實驗室環境的複雜性需要簡化儀器互動並增強測量自動化的解決方案。傳統工具通常需要組態、軟體和程式設計技能，這會造成生產力障礙。包含專用軟體套件和自訂指令碼在內的先前方法，常常無法提供與程式設計實務相符的使用者友善解決方案。我們提出 LABIIUM，這是一個由 AI 增強的零組態測量自動化系統，旨在簡化實驗工作流程並提升使用者生產力。LABIIUM 整合由大型語言模型 (LLM) 提供動力的 AI 助理，以產生程式碼。LABIIUM 的實驗室自動化測量橋接器 (LAMBs) 使用標準工具（例如 VSCode 和 Python）實現無縫儀器連線，消除了設定負擔。為了展示其功能，我們進行了實驗，包括測量具有電流源負載的簡單二電晶體反相放大器的參數傳輸曲線。AI 助理使用不同的提示場景進行評估，並與包括 Claude Sonnet 3.5、Gemini Pro 1.5 和 GPT-4o 在內的多個模型進行比較。採用實作梯度加權適應性隨機取樣 (GWASS) 方法的專家解決方案作為基準。由 AI 助理產生的解決方案與專家解決方案和具有 10,000 個點的均勻線性掃描基準進行比較。圖形結果顯示 LLM 能夠成功完成最基本的均勻掃描，但 LLM 無法開發出適應性掃描演算法來與 GWASS 競爭。評估強調了 LABIIUM 增強實驗室生產力並支援研究和產業數位轉型的能力，並強調了在電子測量科學任務中提升 LLM 效能所需進行的後續工作。

##### **Knowledge Graphs are all you need: Leveraging KGs in Physics Question Answering**
2412.05453v2 by Krishnasai Addala, Kabir Dev Paul Baghel, Dhruv Jain, Chhavi Kirtani, Avinash Anand, Rajiv Ratn Shah

This study explores the effectiveness of using knowledge graphs generated by
large language models to decompose high school-level physics questions into
sub-questions. We introduce a pipeline aimed at enhancing model response
quality for Question Answering tasks. By employing LLMs to construct knowledge
graphs that capture the internal logic of the questions, these graphs then
guide the generation of subquestions. We hypothesize that this method yields
sub-questions that are more logically consistent with the original questions
compared to traditional decomposition techniques. Our results show that
sub-questions derived from knowledge graphs exhibit significantly improved
fidelity to the original question's logic. This approach not only enhances the
learning experience by providing clearer and more contextually appropriate
sub-questions but also highlights the potential of LLMs to transform
educational methodologies. The findings indicate a promising direction for
applying AI to improve the quality and effectiveness of educational content.

摘要：本研究探討使用大型語言模型產生的知識圖表，將高中物理題目分解成子問題的有效性。我們介紹了一個旨在提升模型回應品質的管道，用於問答任務。透過使用大型語言模型建構知識圖表，以擷取問題的內部邏輯，這些圖表接著引導子問題的產生。我們假設此方法產生的子問題，與傳統分解技術相比，在邏輯上與原始問題更一致。我們的結果顯示，從知識圖表衍生的子問題，在忠實度上顯著優於原始問題的邏輯。此方法不僅透過提供更清晰且更符合脈絡的子問題來提升學習體驗，也突顯大型語言模型轉型教育方法的潛力。這些發現指出一個有前景的方向，即應用人工智慧來提升教育內容的品質與有效性。

##### **A Graph-Based Approach for Conversational AI-Driven Personal Memory Capture and Retrieval in a Real-world Application**
2412.05447v1 by Savini Kashmira, Jayanaka L. Dantanarayana, Joshua Brodsky, Ashish Mahendra, Yiping Kang, Krisztian Flautner, Lingjia Tang, Jason Mars

TOBU is a novel mobile application that captures and retrieves `personal
memories' (pictures/videos together with stories and context around those
moments) in a user-engaging AI-guided conversational approach. Our initial
prototype showed that existing retrieval techniques such as retrieval-augmented
generation (RAG) systems fall short due to their limitations in understanding
memory relationships, causing low recall, hallucination, and unsatisfactory
user experience. We design TOBUGraph, a novel graph-based retrieval approach.
During capturing, TOBUGraph leverages large language models (LLMs) to
automatically create a dynamic knowledge graph of memories, establishing
context and relationships of those memories. During retrieval, TOBUGraph
combines LLMs with the memory graph to achieve comprehensive recall through
graph traversal. Our evaluation using real user data demonstrates that
TOBUGraph outperforms multiple RAG implementations in both precision and
recall, significantly improving user experience through improved retrieval
accuracy and reduced hallucination.

摘要：TOBU 是一款新颖的移动应用程序，它以用户参与式 AI 引导对话方式捕捉和检索“个人记忆”（图片/视频以及这些时刻周围的故事和背景）。我们的初始原型表明，现有的检索技术（例如检索增强生成 (RAG) 系统）由于它们在理解记忆关系方面的局限性而表现不佳，从而导致召回率低、出现幻觉和用户体验不佳。我们设计了 TOBUGraph，一种新颖的基于图的检索方法。在捕获期间，TOBUGraph 利用大型语言模型 (LLM) 自动创建动态知识图谱，建立这些记忆的背景和关系。在检索期间，TOBUGraph 将 LLM 与记忆图谱结合起来，通过图遍历实现全面召回。我们使用真实用户数据进行的评估表明，TOBUGraph 在精确度和召回率方面都优于多个 RAG 实现，通过提高检索准确度和减少幻觉，显著改善了用户体验。

##### **KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning**
2412.04948v1 by Peng Yu, Cheng Deng, Beiya Dai, Xinbing Wang, Ying Wen

Autoregressive large language models (LLMs) pre-trained by next token
prediction are inherently proficient in generative tasks. However, their
performance on knowledge-driven tasks such as factual knowledge querying
remains unsatisfactory. Knowledge graphs (KGs), as high-quality structured
knowledge bases, can provide reliable knowledge for LLMs, potentially
compensating for their knowledge deficiencies. Aligning LLMs with explicit,
structured knowledge from KGs has been a challenge; previous attempts either
failed to effectively align knowledge representations or compromised the
generative capabilities of LLMs, leading to less-than-optimal outcomes. This
paper proposes \textbf{KaLM}, a \textit{Knowledge-aligned Language Modeling}
approach, which fine-tunes autoregressive LLMs to align with KG knowledge via
the joint objective of explicit knowledge alignment and implicit knowledge
alignment. The explicit knowledge alignment objective aims to directly optimize
the knowledge representation of LLMs through dual-view knowledge graph
contrastive learning. The implicit knowledge alignment objective focuses on
incorporating textual patterns of knowledge into LLMs through triple completion
language modeling. Notably, our method achieves a significant performance boost
in evaluations of knowledge-driven tasks, specifically embedding-based
knowledge graph completion and generation-based knowledge graph question
answering.

摘要：<paragraph>自動回歸大型語言模型 (LLM) 經由下一個符號預測預先訓練，本質上擅長生成式任務。然而，它們在知識驅動任務（例如事實知識查詢）上的表現仍不盡人意。知識圖譜 (KG) 作為高品質的結構化知識庫，可以為 LLM 提供可靠的知識，潛在地彌補其知識不足。將 LLM 與來自 KG 的明確結構化知識對齊一直是一項挑戰；先前的嘗試要么無法有效對齊知識表示，要么損害 LLM 的生成能力，導致結果不盡理想。本文提出了一個**KaLM**，一種**知識對齊語言建模**方法，它微調自動回歸 LLM 以透過明確知識對齊和隱式知識對齊的聯合目標與 KG 知識對齊。明確知識對齊目標旨在透過雙視圖知識圖譜對比學習直接最佳化 LLM 的知識表示。隱式知識對齊目標專注於透過三元組完成語言建模將知識的文字模式納入 LLM。值得注意的是，我們的模型在知識驅動任務的評估中獲得顯著的效能提升，特別是基於嵌入的知識圖譜完成和基於生成的知識圖譜問題解答。</paragraph>

##### **HyperGraphOS: A Meta Operating System for Science and Engineering**
2412.04923v1 by Antonello Ceravola, Frank Joublin, Ahmed R. Sadik, Bram Bolder, Juha-Pekka Tolvanen

This paper presents HyperGraphOS, an innovative Operating System designed for
the scientific and engineering domains. It combines model based engineering,
graph modeling, data containers, and computational tools, offering users a
dynamic workspace for creating and managing complex models represented as
customizable graphs. Using a web based architecture, HyperGraphOS requires only
a modern browser to organize knowledge, documents, and content into
interconnected models. Domain Specific Languages drive workspace navigation,
code generation, AI integration, and process organization.The platform models
function as both visual drawings and data structures, enabling dynamic
modifications and inspection, both interactively and programmatically.
HyperGraphOS was evaluated across various domains, including virtual avatars,
robotic task planning using Large Language Models, and meta modeling for
feature based code development. Results show significant improvements in
flexibility, data management, computation, and document handling.

摘要：本文提出 HyperGraphOS，這是一個創新的作業系統，專為科學和工程領域設計。它結合了基於模型的工程、圖形建模、資料容器和計算工具，為使用者提供一個動態工作空間，用於建立和管理表示為可自訂圖形的複雜模型。HyperGraphOS 使用基於 Web 的架構，只需要一個現代瀏覽器即可將知識、文件和內容組織成互連模型。特定領域語言驅動工作空間導覽、程式碼產生、AI 整合和流程組織。平台模型同時作為視覺繪圖和資料結構，支援動態修改和檢查，無論是互動式還是以程式方式進行。HyperGraphOS 已在各種領域中進行評估，包括虛擬化身、使用大型語言模型的機器人任務規劃，以及用於基於特徵的程式碼開發的元建模。結果顯示出靈活性、資料管理、運算和文件處理方面的顯著改進。

##### **Transformers Struggle to Learn to Search**
2412.04703v1 by Abulhair Saparov, Srushti Pawar, Shreyas Pimpalgaonkar, Nitish Joshi, Richard Yuanzhe Pang, Vishakh Padmakumar, Seyed Mehran Kazemi, Najoung Kim, He He

Search is an ability foundational in many important tasks, and recent studies
have shown that large language models (LLMs) struggle to perform search
robustly. It is unknown whether this inability is due to a lack of data,
insufficient model parameters, or fundamental limitations of the transformer
architecture. In this work, we use the foundational graph connectivity problem
as a testbed to generate effectively limitless high-coverage data to train
small transformers and test whether they can learn to perform search. We find
that, when given the right training distribution, the transformer is able to
learn to search.
  We analyze the algorithm that the transformer has learned through a novel
mechanistic interpretability technique that enables us to extract the
computation graph from the trained model. We find that for each vertex in the
input graph, transformers compute the set of vertices reachable from that
vertex. Each layer then progressively expands these sets, allowing the model to
search over a number of vertices exponential in the number of layers.
  However, we find that as the input graph size increases, the transformer has
greater difficulty in learning the task. This difficulty is not resolved even
as the number of parameters is increased, suggesting that increasing model
scale will not lead to robust search abilities. We also find that performing
search in-context (i.e., chain-of-thought) does not resolve this inability to
learn to search on larger graphs.

摘要：搜尋是許多重要任務中的一項基礎能力，最近的研究表明，大型語言模型 (LLM) 難以穩健地執行搜尋。目前尚不清楚這種無能是源於資料不足、模型參數不足，還是 Transformer 架構的基本限制。在這項工作中，我們使用基礎圖形連通性問題作為測試平台，生成有效無限的高覆蓋率資料，以訓練小型 Transformer 並測試它們是否能學會執行搜尋。我們發現，當給予正確的訓練分佈時，Transformer 能夠學會搜尋。
我們透過一種新穎的機制可解釋性技術分析 Transformer 學到的演算法，這讓我們能夠從訓練好的模型中提取運算圖形。我們發現，對於輸入圖形中的每個頂點，Transformer 會計算從該頂點可到達的頂點集合。然後，每一層都會逐步擴充這些集合，讓模型能夠在與層數呈指數關係的頂點數目上進行搜尋。
然而，我們發現，隨著輸入圖形大小的增加，Transformer 在學習任務時會遇到更大的困難。即使增加參數數量，這種困難也不會得到解決，這表明增加模型規模不會帶來穩健的搜尋能力。我們還發現，在上下文中執行搜尋（即思考鏈）無法解決這種無法學習在較大圖形上搜尋的問題。

##### **LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs**
2412.04690v1 by Xuan Chen, Tong Lu, Zhichun Wang

Entity Alignment (EA) seeks to identify and match corresponding entities
across different Knowledge Graphs (KGs), playing a crucial role in knowledge
fusion and integration. Embedding-based entity alignment (EA) has recently
gained considerable attention, resulting in the emergence of many innovative
approaches. Initially, these approaches concentrated on learning entity
embeddings based on the structural features of knowledge graphs (KGs) as
defined by relation triples. Subsequent methods have integrated entities' names
and attributes as supplementary information to improve the embeddings used for
EA. However, existing methods lack a deep semantic understanding of entity
attributes and relations. In this paper, we propose a Large Language Model
(LLM) based Entity Alignment method, LLM-Align, which explores the
instruction-following and zero-shot capabilities of Large Language Models to
infer alignments of entities. LLM-Align uses heuristic methods to select
important attributes and relations of entities, and then feeds the selected
triples of entities to an LLM to infer the alignment results. To guarantee the
quality of alignment results, we design a multi-round voting mechanism to
mitigate the hallucination and positional bias issues that occur with LLMs.
Experiments on three EA datasets, demonstrating that our approach achieves
state-of-the-art performance compared to existing EA methods.

摘要：實體對齊 (EA) 旨在識別和匹配不同知識圖譜 (KG) 中對應的實體，在知識融合和整合中扮演著至關重要的角色。基於嵌入的實體對齊 (EA) 近來備受關注，進而催生出許多創新的方法。最初，這些方法專注於根據知識圖譜 (KG) 的結構特徵來學習實體嵌入，這些特徵由關係三元組定義。後續方法將實體名稱和屬性整合為補充資訊，以改善用於 EA 的嵌入。然而，現有方法缺乏對實體屬性和關係的深入語義理解。在本文中，我們提出了一種基於大型語言模型 (LLM) 的實體對齊方法 LLM-Align，該方法探索了大型語言模型的遵循指令和零次學習能力，以推論實體對齊。LLM-Align 使用啟發式方法來選擇實體的重要屬性和關係，然後將實體的選定三元組饋入 LLM 以推論對齊結果。為了保證對齊結果的品質，我們設計了一個多輪投票機制，以減輕 LLM 中出現的幻覺和位置偏差問題。在三個 EA 資料集上的實驗表明，與現有的 EA 方法相比，我們的做法達到了最先進的效能。

##### **Retrieval-Augmented Machine Translation with Unstructured Knowledge**
2412.04342v1 by Jiaan Wang, Fandong Meng, Yingxue Zhang, Jie Zhou

Retrieval-augmented generation (RAG) introduces additional information to
enhance large language models (LLMs). In machine translation (MT), previous
work typically retrieves in-context examples from paired MT corpora, or
domain-specific knowledge from knowledge graphs, to enhance models' MT ability.
However, a large amount of world knowledge is organized in unstructured
documents, and might not be fully paired across different languages. In this
paper, we study retrieval-augmented MT using unstructured documents.
Specifically, we build RAGtrans, the first benchmark to train and evaluate
LLMs' retrieval-augmented MT ability. RAGtrans contains 79K MT samples
collected via GPT-4o and human translators. Besides, documents from different
languages are also provided to supply the knowledge to these samples. Based on
RAGtrans, we further propose a multi-task training method to teach LLMs how to
use information from multilingual documents during their translation. The
method uses existing multilingual corpora to create auxiliary training
objectives without additional labeling requirements. Extensive experiments show
that the method improves LLMs by 1.58-3.09 BLEU and 1.00-2.03 COMET scores.

摘要：檢索增強產生 (RAG) 會引入額外資訊，以增強大型語言模型 (LLM)。在機器翻譯 (MT) 中，先前的作業通常會從配對的 MT 語料庫中檢索情境範例，或從知識圖表中檢索特定領域的知識，以增強模型的 MT 能力。然而，大量的世界知識都是以非結構化文件組織，而且可能無法完全配對到不同的語言中。在本文中，我們研究使用非結構化文件進行檢索增強 MT。具體來說，我們建立了 RAGtrans，這是第一個用於訓練和評估 LLM 的檢索增強 MT 能力的基準。RAGtrans 包含透過 GPT-4o 和人工翻譯人員收集的 79K 個 MT 範例。此外，也提供了不同語言的文件，以提供這些範例的知識。根據 RAGtrans，我們進一步提出了一個多任務訓練方法，以教導 LLM 如何在翻譯過程中使用多語言文件的資訊。該方法使用現有的多語言語料庫建立輔助訓練目標，而無需額外的標記需求。廣泛的實驗顯示，該方法將 LLM 的 BLEU 分數提高了 1.58-3.09，COMET 分數提高了 1.00-2.03。

##### **GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering**
2412.04119v2 by Cristian-George Crăciun, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel

Pre-trained Language Models (PLMs) have shown remarkable performances in
recent years, setting a new paradigm for NLP research and industry. The legal
domain has received some attention from the NLP community partly due to its
textual nature. Some tasks from this domain are represented by
question-answering (QA) tasks. This work explores the legal domain
Multiple-Choice QA (MCQA) for a low-resource language. The contribution of this
work is multi-fold. We first introduce JuRO, the first openly available
Romanian legal MCQA dataset, comprising three different examinations and a
number of 10,836 total questions. Along with this dataset, we introduce CROL,
an organized corpus of laws that has a total of 93 distinct documents with
their modifications from 763 time spans, that we leveraged in this work for
Information Retrieval (IR) techniques. Moreover, we are the first to propose
Law-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is
derived from the aforementioned corpus. Lastly, we propose a novel approach for
MCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive
results with generally accepted SOTA methods and even exceeds them in most
settings.

摘要：預訓練語言模型 (PLM) 在近年來展現了卓越的表現，為自然語言處理的研究和產業設定了新的典範。法律領域由於其文字性質，而受到自然語言處理社群的部分關注。此領域中的一些任務由問答 (QA) 任務表示。這項工作探討了低資源語言的法律領域多重選擇問答 (MCQA)。這項工作的貢獻是多方面的。我們首先介紹 JuRO，這是第一個公開可用的羅馬尼亞法律 MCQA 資料集，包含三次不同的考試和總共 10,836 個問題。隨著這個資料集，我們引入了 CROL，這是一個有組織的法律語料庫，總共有 93 份不同的文件，包含了它們在 763 個時間範圍內的修改，我們在這項工作中利用了這些文件進行資訊檢索 (IR) 技術。此外，我們是最早提出羅馬尼亞語知識圖譜 (KG) Law-RoG 的人，而這個 KG 是從上述語料庫衍生的。最後，我們提出了一種新的 MCQA 方法，由事實增強的圖形檢索 (GRAF)，它達到了與普遍接受的 SOTA 方法競爭的結果，甚至在大部分設定中超越了它們。

##### **MIND: Effective Incorrect Assignment Detection through a Multi-Modal Structure-Enhanced Language Model**
2412.03930v1 by Yunhe Pang, Bo Chen, Fanjin Zhang, Yanghui Rao, Jie Tang

The rapid growth of academic publications has exacerbated the issue of author
name ambiguity in online digital libraries. Despite advances in name
disambiguation algorithms, cumulative errors continue to undermine the
reliability of academic systems. It is estimated that over 10% paper-author
assignments are rectified when constructing the million-scale WhoIsWho
benchmark. Existing endeavors to detect incorrect assignments are either
semantic-based or graph-based approaches, which fall short of making full use
of the rich text attributes of papers and implicit structural features defined
via the co-occurrence of paper attributes. To this end, this paper introduces a
structure-enhanced language model that combines key structural features from
graph-based methods with fine-grained semantic features from rich paper
attributes to detect incorrect assignments. The proposed model is trained with
a highly effective multi-modal multi-turn instruction tuning framework, which
incorporates task-guided instruction tuning, text-attribute modality, and
structural modality. Experimental results demonstrate that our model
outperforms previous approaches, achieving top performance on the leaderboard
of KDD Cup 2024. Our code has been publicly available.

摘要：學術出版品的快速成長，加劇了線上數位圖書館中作者姓名歧義的問題。儘管姓名消歧演算法有進展，累積的錯誤仍持續破壞學術系統的可靠性。據估計，在建構百萬規模的 WhoIsWho 基準時，超過 10% 的論文作者指派被修正。現有的偵測不正確指派的努力，不是基於語意的，就是基於圖的，無法充分利用論文豐富的文字屬性和透過論文屬性共現定義的隱含結構特徵。為此，本文介紹了一個結構增強語言模型，將基於圖的方法中的關鍵結構特徵與豐富論文屬性中的細粒度語義特徵相結合，以偵測不正確的指派。所提出的模型使用一個高效的多模態多輪指令微調架構進行訓練，其中包含任務導向的指令微調、文字屬性模態和結構模態。實驗結果證明，我們的模型優於先前的模型，在 KDD Cup 2024 的排行榜上取得最佳效能。我們的程式碼已公開。

##### **How Good is ChatGPT in Giving Adaptive Guidance Using Knowledge Graphs in E-Learning Environments?**
2412.03856v1 by Patrick Ocheja, Brendan Flanagan, Yiling Dai, Hiroaki Ogata

E-learning environments are increasingly harnessing large language models
(LLMs) like GPT-3.5 and GPT-4 for tailored educational support. This study
introduces an approach that integrates dynamic knowledge graphs with LLMs to
offer nuanced student assistance. By evaluating past and ongoing student
interactions, the system identifies and appends the most salient learning
context to prompts directed at the LLM. Central to this method is the knowledge
graph's role in assessing a student's comprehension of topic prerequisites.
Depending on the categorized understanding (good, average, or poor), the LLM
adjusts its guidance, offering advanced assistance, foundational reviews, or
in-depth prerequisite explanations, respectively. Preliminary findings suggest
students could benefit from this tiered support, achieving enhanced
comprehension and improved task outcomes. However, several issues related to
potential errors arising from LLMs were identified, which can potentially
mislead students. This highlights the need for human intervention to mitigate
these risks. This research aims to advance AI-driven personalized learning
while acknowledging the limitations and potential pitfalls, thus guiding future
research in technology and data-driven education.

摘要：電子學習環境正日益利用大型語言模型 (LLM)，例如 GPT-3.5 和 GPT-4，提供量身打造的教育支援。本研究提出了一種方法，將動態知識圖與 LLM 整合，提供細緻入微的學生協助。系統會評估過去和正在進行的學生互動，找出並附加最顯著的學習脈絡，以提示 LLM。此方法的核心在於知識圖在評估學生對主題先備知識的理解程度方面所扮演的角色。LLM 會根據分類後的理解程度（良好、普通或差）調整其指導，分別提供進階協助、基礎回顧或深入的先備知識說明。初步發現表明，學生可以受益於這種分層支援，達到增強的理解力和改善的任務成果。然而，已找出與 LLM 產生的潛在錯誤相關的幾個問題，這些錯誤可能會誤導學生。這突顯了人類介入以降低這些風險的必要性。本研究旨在推進 AI 驅動的個人化學習，同時承認限制和潛在的陷阱，從而指導未來在技術和資料驅動教育方面的研究。

##### **Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering**
2412.03815v1 by Samuel Abedu, SayedHassan Khatoonabadi, Emad Shihab

Software repositories contain valuable information for gaining insights into
their development process. However, extracting insights from these repository
data is time-consuming and requires technical expertise. While software
engineering chatbots have been developed to facilitate natural language
interactions with repositories, they struggle with understanding natural
language and accurately retrieving relevant data. This study aims to improve
the accuracy of LLM-based chatbots in answering repository-related questions by
augmenting them with knowledge graphs. We achieve this in a two-step approach;
(1) constructing a knowledge graph from the repository data and (2) synergizing
the knowledge graph with LLM to allow for the natural language questions and
answers. We curated a set of 20 questions with different complexities and
evaluated our approach on five popular open-source projects. Our approach
achieved an accuracy of 65%. We further investigated the limitations and
identified six key issues, with the majority relating to the reasoning
capability of the LLM. We experimented with a few-shot chain-of-thought
prompting to determine if it could enhance our approach. This technique
improved the overall accuracy to 84%. Our findings demonstrate the synergy
between LLMs and knowledge graphs as a viable solution for making repository
data accessible to both technical and non-technical stakeholders.

摘要：軟體儲存庫包含有價值的資訊，可深入了解其開發流程。然而，從這些儲存庫資料中擷取見解既耗時又需要技術專業知識。儘管已開發出軟體工程聊天機器人來促進與儲存庫的自然語言互動，但它們在理解自然語言和準確擷取相關資料方面仍有困難。本研究旨在透過知識圖譜擴充 LLM 基礎聊天機器人，以提高其回答儲存庫相關問題的準確性。我們採用兩步驟方法來達成此目標：(1) 從儲存庫資料建構知識圖譜，以及 (2) 將知識圖譜與 LLM 結合，以允許自然語言問題和答案。我們策劃了一組 20 個具有不同複雜度的問題，並針對五個熱門的開源專案評估我們的做法。我們的做法達到了 65% 的準確度。我們進一步探討了限制，並找出六個關鍵問題，其中大部分與 LLM 的推理能力有關。我們實驗了少次數的思考鏈提示，以確定它是否可以增強我們的做法。此技術將整體準確度提高到 84%。我們的研究結果證明了 LLM 和知識圖譜之間的協同效應，作為讓技術和非技術利害關係人能夠存取儲存庫資料的可行解決方案。

##### **Agent AI with LangGraph: A Modular Framework for Enhancing Machine Translation Using Large Language Models**
2412.03801v1 by Jialin Wang, Zhihua Duan

This paper explores the transformative role of Agent AI and LangGraph in
advancing the automation and effectiveness of machine translation (MT). Agents
are modular components designed to perform specific tasks, such as translating
between particular languages, with specializations like TranslateEnAgent,
TranslateFrenchAgent, and TranslateJpAgent for English, French, and Japanese
translations, respectively. These agents leverage the powerful semantic
capabilities of large language models (LLMs), such as GPT-4o, to ensure
accurate, contextually relevant translations while maintaining modularity,
scalability, and context retention.
  LangGraph, a graph-based framework built on LangChain, simplifies the
creation and management of these agents and their workflows. It supports
dynamic state management, enabling agents to maintain dialogue context and
automates complex workflows by linking agents and facilitating their
collaboration. With flexibility, open-source community support, and seamless
integration with LLMs, LangGraph empowers agents to deliver high-quality
translations.
  Together, Agent AI and LangGraph create a cohesive system where LangGraph
orchestrates agent interactions, ensuring that user inputs are analyzed,
routed, and processed efficiently. Experimental results demonstrate the
potential of this system to enhance multilingual translation accuracy and
scalability. By highlighting modular design and automated workflows, this paper
sets the stage for further innovations in intelligent machine translation
services.

摘要：本文探討了 Agent AI 和 LangGraph 在推動機器翻譯 (MT) 的自動化和效率方面的變革性作用。Agent 是模組化元件，旨在執行特定任務，例如在特定語言之間翻譯，並具有專門領域，例如 TranslateEnAgent、TranslateFrenchAgent 和 TranslateJpAgent 分別用於英文、法文和日文的翻譯。這些 Agent 運用大型語言模型 (LLM) 的強大語義功能，例如 GPT-4o，以確保準確、與上下文相關的翻譯，同時保持模組化、可擴充性和上下文保留。
LangGraph 是建構於 LangChain 上的圖形化框架，簡化了這些 Agent 及其工作流程的建立和管理。它支援動態狀態管理，讓 Agent 能夠維護對話內容，並透過連結 Agent 和促進其協作，自動化複雜的工作流程。LangGraph 具有靈活性、開放原始碼社群支援和與 LLM 無縫整合等優點，讓 Agent 能夠提供高品質的翻譯。
Agent AI 和 LangGraph 共同建立了一個緊密的系統，其中 LangGraph 編排 Agent 互動，確保使用者輸入被有效地分析、路由和處理。實驗結果證明了這個系統在提升多語言翻譯準確性和可擴充性方面的潛力。透過強調模組化設計和自動化工作流程，本文為智慧型機器翻譯服務的進一步創新奠定了基礎。

##### **Language Model Meets Prototypes: Towards Interpretable Text Classification Models through Prototypical Networks**
2412.03761v1 by Ximing Wen

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on NLP tasks, but their black-box
nature, which leads to a lack of interpretability, has been a major concern. My
dissertation focuses on developing intrinsically interpretable models when
using LMs as encoders while maintaining their superior performance via
prototypical networks. I initiated my research by investigating enhancements in
performance for interpretable models of sarcasm detection. My proposed approach
focuses on capturing sentiment incongruity to enhance accuracy while offering
instance-based explanations for the classification decisions. Later, I
developed a novel white-box multi-head graph attention-based prototype network
designed to explain the decisions of text classification models without
sacrificing the accuracy of the original black-box LMs. In addition, I am
working on extending the attention-based prototype network with contrastive
learning to redesign an interpretable graph neural network, aiming to enhance
both the interpretability and performance of the model in document
classification.

摘要：預先訓練好的基於 Transformer 的語言模型 (LM) 以其在 NLP 任務中取得顯著進步的能力而聞名，但它們的黑盒性質導致缺乏可解釋性，一直是一個主要問題。我的論文重點在於在使用 LM 作為編碼器時開發內在可解釋的模型，同時通過原型網路維持其優異的效能。我透過研究諷刺偵測的可解釋模型的效能提升來啟動我的研究。我提出的方法專注於捕捉情緒不一致性，以提高準確度，同時為分類決策提供基於實例的解釋。後來，我開發了一個新穎的白盒多頭圖形注意力原型網路，旨在解釋文字分類模型的決策，而不會犧牲原始黑盒 LM 的準確度。此外，我正在努力將基於注意力的原型網路與對比學習擴展，以重新設計一個可解釋的圖形神經網路，旨在增強模型在文件分類中的可解釋性和效能。

##### **How to Correctly do Semantic Backpropagation on Language-based Agentic Systems**
2412.03624v1 by Wenyi Wang, Hisham A. Alyahya, Dylan R. Ashley, Oleg Serikov, Dmitrii Khizbullin, Francesco Faccio, Jürgen Schmidhuber

Language-based agentic systems have shown great promise in recent years,
transitioning from solving small-scale research problems to being deployed in
challenging real-world tasks. However, optimizing these systems often requires
substantial manual labor. Recent studies have demonstrated that these systems
can be represented as computational graphs, enabling automatic optimization.
Despite these advancements, most current efforts in Graph-based Agentic System
Optimization (GASO) fail to properly assign feedback to the system's components
given feedback on the system's output. To address this challenge, we formalize
the concept of semantic backpropagation with semantic gradients -- a
generalization that aligns several key optimization techniques, including
reverse-mode automatic differentiation and the more recent TextGrad by
exploiting the relationship among nodes with a common successor. This serves as
a method for computing directional information about how changes to each
component of an agentic system might improve the system's output. To use these
gradients, we propose a method called semantic gradient descent which enables
us to solve GASO effectively. Our results on both BIG-Bench Hard and GSM8K show
that our approach outperforms existing state-of-the-art methods for solving
GASO problems. A detailed ablation study on the LIAR dataset demonstrates the
parsimonious nature of our method. A full copy of our implementation is
publicly available at https://github.com/HishamAlyahya/semantic_backprop

摘要：<paragraph>近年來，基於語言的代理系統展現了極大的前景，
從解決小規模的研究問題，轉變為部署在
具有挑戰性的真實世界任務中。然而，最佳化這些系統通常需要
大量的人工勞力。最近的研究表明，這些系統
可以表示為計算圖，實現自動最佳化。
儘管有這些進展，但目前大多數基於圖形的代理系統
最佳化 (GASO) 的努力，都無法適當地將回饋分配給系統的組成部分
給予系統輸出的回饋。為了應對這一挑戰，我們正式化了
語義反向傳播的概念，並帶有語義梯度——一種
概括，它結合了幾種關鍵的最佳化技術，包括
反向模式自動微分和最近的 TextGrad，利用具有共同後繼者的節點之間的關係。這可以用作
一種計算方向資訊的方法，說明如何改變代理系統的每個
組成部分可能會改善系統的輸出。為了使用這些
梯度，我們提出了一種稱為語義梯度下降的方法，使我們能夠
有效地解決 GASO。我們在 BIG-Bench Hard 和 GSM8K 上的結果表明
我們的做法優於解決
GASO 問題的現有最先進方法。在 LIAR 資料集上進行的詳細消融研究證明了
我們方法的簡約性。我們的實作的完整副本公開於 https://github.com/HishamAlyahya/semantic_backprop</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

摘要：供應鏈風險管理中的一個關鍵障礙在於企業和政策制定者缺乏對相互依存供應網路關係的能見度。關係預測，也稱為連結預測，是供應鏈監控研究中一個新興領域，旨在使用資料驅動技術提高供應鏈的能見度。現有方法已成功預測關係，但難以提取這些關係所嵌入的背景，例如所供應的產品或供應地點。缺乏背景會妨礙從業者區分交易關係和既定的供應鏈關係，進而阻礙風險的準確評估。在這項工作中，我們開發了一個新的生成式人工智慧 (Gen AI) 增強機器學習架構，它利用預先訓練的語言模型作為嵌入模型，並結合機器學習模型來預測知識圖譜中的供應鏈關係。透過整合生成式 AI 技術，我們的做法捕捉到實體之間細微的語義關係，從而提高供應鏈能見度並促進更精確的風險管理。使用來自真實案例研究的資料，我們證明 GenAI 增強連結預測優於所有基準，並展示如何探索和有效地在供應鏈風險管理中使用 GenAI 模型。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-24**|**Long-Form Speech Generation with Spoken Language Models**|Se Jin Park et.al.|[2412.18603v1](http://arxiv.org/abs/2412.18603v1)|[link](https://github.com/google-deepmind/librispeech-long)|
|**2024-12-24**|**Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems**|Fernando Jia et.al.|[2412.18601v1](http://arxiv.org/abs/2412.18601v1)|null|
|**2024-12-24**|**DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**|Minghong Cai et.al.|[2412.18597v1](http://arxiv.org/abs/2412.18597v1)|[link](https://github.com/tencentarc/ditctrl)|
|**2024-12-24**|**A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs**|OpenMind et.al.|[2412.18588v1](http://arxiv.org/abs/2412.18588v1)|null|
|**2024-12-24**|**Exploring Embedding Priors in Prompt-Tuning for Improved Interpretability and Control**|Sergey Sedov et.al.|[2412.18582v1](http://arxiv.org/abs/2412.18582v1)|null|
|**2024-12-24**|**How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation**|Dewu Zheng et.al.|[2412.18573v1](http://arxiv.org/abs/2412.18573v1)|[link](https://github.com/deepsoftwareanalytics/multicodebench)|
|**2024-12-24**|**Zero-resource Speech Translation and Recognition with LLMs**|Karel Mundnich et.al.|[2412.18566v1](http://arxiv.org/abs/2412.18566v1)|null|
|**2024-12-24**|**Distilling Fine-grained Sentiment Understanding from Large Language Models**|Yice Zhang et.al.|[2412.18552v1](http://arxiv.org/abs/2412.18552v1)|[link](https://github.com/hitsz-hlt/fsa-distillation)|
|**2024-12-24**|**Libra-Leaderboard: Towards Responsible AI through a Balanced Leaderboard of Safety and Capability**|Haonan Li et.al.|[2412.18551v1](http://arxiv.org/abs/2412.18551v1)|null|
|**2024-12-24**|**Token-Budget-Aware LLM Reasoning**|Tingxu Han et.al.|[2412.18547v1](http://arxiv.org/abs/2412.18547v1)|[link](https://github.com/geniushtx/tale)|
|**2024-12-24**|**Consistency Checks for Language Model Forecasters**|Daniel Paleka et.al.|[2412.18544v1](http://arxiv.org/abs/2412.18544v1)|null|
|**2024-12-24**|**Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**|Derong Xu Xinhang Li et.al.|[2412.18537v1](http://arxiv.org/abs/2412.18537v1)|null|
|**2024-12-24**|**Characterizations of Language Generation With Breadth**|Alkis Kalavasis et.al.|[2412.18530v1](http://arxiv.org/abs/2412.18530v1)|null|
|**2024-12-24**|**Think or Remember? Detecting and Directing LLMs Towards Memorization or Generalization**|Yi-Fu Fu et.al.|[2412.18497v1](http://arxiv.org/abs/2412.18497v1)|null|
|**2024-12-24**|**Generating event descriptions under syntactic and semantic constraints**|Angela Cao et.al.|[2412.18496v1](http://arxiv.org/abs/2412.18496v1)|[link](https://github.com/superMereo/generating-event-descriptions)|
|**2024-12-24**|**How "Real" is Your Real-Time Simultaneous Speech-to-Text Translation System?**|Sara Papi et.al.|[2412.18495v1](http://arxiv.org/abs/2412.18495v1)|null|
|**2024-12-24**|**An Overview and Discussion of the Suitability of Existing Speech Datasets to Train Machine Learning Models for Collective Problem Solving**|Gnaneswar Villuri et.al.|[2412.18489v1](http://arxiv.org/abs/2412.18489v1)|null|
|**2024-12-24**|**Segment-Based Attention Masking for GPTs**|Shahar Katz et.al.|[2412.18487v1](http://arxiv.org/abs/2412.18487v1)|[link](https://github.com/shacharKZ/MAS-Segment-Based-Attention-Masking)|
|**2024-12-24**|**MotifGPL: Motif-Enhanced Graph Prototype Learning for Deciphering Urban Social Segregation**|Tengfei He et.al.|[2412.18464v1](http://arxiv.org/abs/2412.18464v1)|[link](https://github.com/tengfeihe/motifgpl)|
|**2024-12-24**|**GeFL: Model-Agnostic Federated Learning with Generative Models**|Honggu Kang et.al.|[2412.18460v1](http://arxiv.org/abs/2412.18460v1)|null|
|**2024-12-24**|**Multi-Agent Norm Perception and Induction in Distributed Healthcare**|Chao Li et.al.|[2412.18454v1](http://arxiv.org/abs/2412.18454v1)|null|
|**2024-12-24**|**Is Large Language Model Good at Triple Set Prediction? An Empirical Study**|Yuan Yuan et.al.|[2412.18443v1](http://arxiv.org/abs/2412.18443v1)|null|
|**2024-12-24**|**Unlocking the Potential of Multiple BERT Models for Bangla Question Answering in NCTB Textbooks**|Abdullah Khondoker et.al.|[2412.18440v1](http://arxiv.org/abs/2412.18440v1)|null|
|**2024-12-24**|**Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent**|Farhad Nooralahzadeh et.al.|[2412.18428v1](http://arxiv.org/abs/2412.18428v1)|null|
|**2024-12-24**|**GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent**|Kangjia Zhao et.al.|[2412.18426v1](http://arxiv.org/abs/2412.18426v1)|null|
|**2024-12-24**|**LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating**|Chao Deng et.al.|[2412.18424v1](http://arxiv.org/abs/2412.18424v1)|[link](https://github.com/dengc2023/longdocurl)|
|**2024-12-24**|**Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**|Zihan Zhou et.al.|[2412.18419v1](http://arxiv.org/abs/2412.18419v1)|null|
|**2024-12-24**|**Multilingual Mathematical Reasoning: Advancing Open-Source LLMs in Hindi and English**|Avinash Anand et.al.|[2412.18415v1](http://arxiv.org/abs/2412.18415v1)|[link](https://github.com/midas-research/Multilingual-Mathematical-Reasoning)|
|**2024-12-24**|**Exploring Flexible Scenario Generation in Godot Simulator**|Daniel Peraltai et.al.|[2412.18408v1](http://arxiv.org/abs/2412.18408v1)|null|
|**2024-12-24**|**A Statistical Framework for Ranking LLM-Based Chatbots**|Siavash Ameli et.al.|[2412.18407v1](http://arxiv.org/abs/2412.18407v1)|null|
|**2024-12-24**|**TPAoI: Ensuring Fresh Service Status at the Network Edge in Compute-First Networking**|Haosheng He et.al.|[2412.18391v1](http://arxiv.org/abs/2412.18391v1)|null|
|**2024-12-24**|**RDPM: Solve Diffusion Probabilistic Models via Recurrent Token Prediction**|Wu Xiaoping et.al.|[2412.18390v1](http://arxiv.org/abs/2412.18390v1)|null|
|**2024-12-24**|**Weak Scaling Capability in Token Space: An Observation from Large Vision Language Model**|Tenghui Li et.al.|[2412.18387v1](http://arxiv.org/abs/2412.18387v1)|null|
|**2024-12-24**|**ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots**|Shani Goren et.al.|[2412.18377v1](http://arxiv.org/abs/2412.18377v1)|[link](https://github.com/amazon-science/chaitea-chat-interaction-autocomplete)|
|**2024-12-24**|**Bidirectional Topic Matching: Quantifying Thematic Overlap Between Corpora Through Topic Modelling**|Raven Adam et.al.|[2412.18376v1](http://arxiv.org/abs/2412.18376v1)|null|
|**2024-12-24**|**Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors**|Jinhyeok Choi et.al.|[2412.18370v1](http://arxiv.org/abs/2412.18370v1)|[link](https://github.com/bdi-lab/monti)|
|**2024-12-24**|**Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset**|Jiarui Liu et.al.|[2412.18367v1](http://arxiv.org/abs/2412.18367v1)|null|
|**2024-12-24**|**Extracting triples from dialogues for conversational social agents**|Piek Vossen et.al.|[2412.18364v1](http://arxiv.org/abs/2412.18364v1)|null|
|**2024-12-24**|**Addressing Spatial-Temporal Data Heterogeneity in Federated Continual Learning via Tail Anchor**|Hao Yu et.al.|[2412.18355v1](http://arxiv.org/abs/2412.18355v1)|null|
|**2024-12-24**|**The Thousand Brains Project: A New Paradigm for Sensorimotor Intelligence**|Viviane Clay et.al.|[2412.18354v1](http://arxiv.org/abs/2412.18354v1)|[link](https://github.com/thousandbrainsproject/tbp.monty)|
|**2024-12-24**|**Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering**|Zhongjian Hu et.al.|[2412.18351v1](http://arxiv.org/abs/2412.18351v1)|null|
|**2024-12-24**|**Exploring Graph Mamba: A Comprehensive Survey on State-Space Models for Graph Learning**|Safa Ben Atitallah et.al.|[2412.18322v1](http://arxiv.org/abs/2412.18322v1)|null|
|**2024-12-24**|**Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search**|Huanjin Yao et.al.|[2412.18319v1](http://arxiv.org/abs/2412.18319v1)|[link](https://github.com/hjyao00/mulberry)|
|**2024-12-24**|**M-Ped: Multi-Prompt Ensemble Decoding for Large Language Models**|Jiaxin Guo et.al.|[2412.18299v1](http://arxiv.org/abs/2412.18299v1)|null|
|**2024-12-24**|**Quo Vadis, Anomaly Detection? LLMs and VLMs in the Spotlight**|Xi Ding et.al.|[2412.18298v1](http://arxiv.org/abs/2412.18298v1)|null|
|**2024-12-24**|**Navigating Data Corruption in Machine Learning: Balancing Quality, Quantity, and Imputation Strategies**|Qi Liu et.al.|[2412.18296v1](http://arxiv.org/abs/2412.18296v1)|null|
|**2024-12-24**|**Pirates of the RAG: Adaptively Attacking LLMs to Leak Knowledge Bases**|Christian Di Maio et.al.|[2412.18295v1](http://arxiv.org/abs/2412.18295v1)|null|
|**2024-12-24**|**MinsStudio: A Streamlined Package for Minecraft AI Agent Development**|Shaofei Cai et.al.|[2412.18293v1](http://arxiv.org/abs/2412.18293v1)|[link](https://github.com/craftjarvis/minestudio)|
|**2024-12-24**|**DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation**|Junyi Lu et.al.|[2412.18291v1](http://arxiv.org/abs/2412.18291v1)|null|
|**2024-12-24**|**Towards understanding how attention mechanism works in deep learning**|Tianyu Ruan et.al.|[2412.18288v1](http://arxiv.org/abs/2412.18288v1)|null|
|**2024-12-24**|**Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation**|Sheng Xiang et.al.|[2412.18287v1](http://arxiv.org/abs/2412.18287v1)|[link](https://github.com/ai4risk/antifraud)|
|**2024-12-24**|**Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization**|Jiacai Liu et.al.|[2412.18279v1](http://arxiv.org/abs/2412.18279v1)|null|
|**2024-12-24**|**GenAI Content Detection Task 2: AI vs. Human -- Academic Essay Authenticity Challenge**|Shammur Absar Chowdhury et.al.|[2412.18274v1](http://arxiv.org/abs/2412.18274v1)|null|
|**2024-12-24**|**Sampling Bag of Views for Open-Vocabulary Object Detection**|Hojun Choi et.al.|[2412.18273v1](http://arxiv.org/abs/2412.18273v1)|null|
|**2024-12-24**|**Annotating References to Mythological Entities in French Literature**|Thierry Poibeau et.al.|[2412.18270v1](http://arxiv.org/abs/2412.18270v1)|null|
|**2024-12-24**|**Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**|Xuefeng Jiang et.al.|[2412.18260v1](http://arxiv.org/abs/2412.18260v1)|[link](https://github.com/sakirinn/llm4cvd)|
|**2024-12-24**|**Fréchet regression for multi-label feature selection with implicit regularization**|Dou El Kefel Mansouri et.al.|[2412.18247v1](http://arxiv.org/abs/2412.18247v1)|null|
|**2024-12-24**|**An Automatic Graph Construction Framework based on Large Language Models for Recommendation**|Rong Shan et.al.|[2412.18241v1](http://arxiv.org/abs/2412.18241v1)|[link](https://github.com/lavieenrose365/autograph)|
|**2024-12-24**|**Expand VSR Benchmark for VLLM to Expertize in Spatial Rules**|Peijin Xie et.al.|[2412.18224v1](http://arxiv.org/abs/2412.18224v1)|[link](https://github.com/peijin360/vsre)|
|**2024-12-24**|**ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation**|Mengyang Wu et.al.|[2412.18216v1](http://arxiv.org/abs/2412.18216v1)|[link](https://github.com/zhaoyuzhi/icm-assistant)|
|**2024-12-24**|**Robustness-aware Automatic Prompt Optimization**|Zeru Shi et.al.|[2412.18196v1](http://arxiv.org/abs/2412.18196v1)|[link](https://github.com/vanpe20/BATprompt)|
|**2024-12-24**|**VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks**|Shiduo Zhang et.al.|[2412.18194v1](http://arxiv.org/abs/2412.18194v1)|null|
|**2024-12-24**|**An Analysis on Automated Metrics for Evaluating Japanese-English Chat Translation**|Andre Rusli et.al.|[2412.18190v1](http://arxiv.org/abs/2412.18190v1)|null|
|**2024-12-24**|**On the Applicability of Zero-Shot Cross-Lingual Transfer Learning for Sentiment Classification in Distant Language Pairs**|Andre Rusli et.al.|[2412.18188v1](http://arxiv.org/abs/2412.18188v1)|[link](https://github.com/arusl/anlp_nlp2022_a6-1)|
|**2024-12-24**|**TextMatch: Enhancing Image-Text Consistency Through Multimodal Optimization**|Yucong Luo et.al.|[2412.18185v1](http://arxiv.org/abs/2412.18185v1)|null|
|**2024-12-24**|**Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization**|Sihao Liu et.al.|[2412.18177v1](http://arxiv.org/abs/2412.18177v1)|null|
|**2024-12-24**|**Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation**|Yucong Luo et.al.|[2412.18176v1](http://arxiv.org/abs/2412.18176v1)|null|
|**2024-12-24**|**INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent**|Haohang Li et.al.|[2412.18174v1](http://arxiv.org/abs/2412.18174v1)|null|
|**2024-12-24**|**KunServe: Elastic and Efficient Large Language Model Serving with Parameter-centric Memory Management**|Rongxin Cheng et.al.|[2412.18169v1](http://arxiv.org/abs/2412.18169v1)|null|
|**2024-12-24**|**Survey of Pseudonymization, Abstractive Summarization & Spell Checker for Hindi and Marathi**|Rasika Ransing et.al.|[2412.18163v1](http://arxiv.org/abs/2412.18163v1)|null|
|**2024-12-24**|**VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities**|Shray Mathur et.al.|[2412.18161v1](http://arxiv.org/abs/2412.18161v1)|null|
|**2024-12-24**|**Smooth-Foley: Creating Continuous Sound for Video-to-Audio Generation Under Semantic Guidance**|Yaoyun Zhang et.al.|[2412.18157v1](http://arxiv.org/abs/2412.18157v1)|null|
|**2024-12-24**|**scReader: Prompting Large Language Models to Interpret scRNA-seq Data**|Cong Li et.al.|[2412.18156v1](http://arxiv.org/abs/2412.18156v1)|null|
|**2024-12-24**|**GeneSUM: Large Language Model-based Gene Summary Extraction**|Zhijian Chen et.al.|[2412.18154v1](http://arxiv.org/abs/2412.18154v1)|null|
|**2024-12-24**|**CoAM: Corpus of All-Type Multiword Expressions**|Yusuke Ide et.al.|[2412.18151v1](http://arxiv.org/abs/2412.18151v1)|null|
|**2024-12-24**|**EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation**|Shuhao Han et.al.|[2412.18150v1](http://arxiv.org/abs/2412.18150v1)|null|
|**2024-12-24**|**Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media**|Zhen Sun et.al.|[2412.18148v1](http://arxiv.org/abs/2412.18148v1)|null|
|**2024-12-24**|**Text-Aware Adapter for Few-Shot Keyword Spotting**|Youngmoon Jung et.al.|[2412.18142v1](http://arxiv.org/abs/2412.18142v1)|null|
|**2024-12-24**|**Ensuring Consistency for In-Image Translation**|Chengpeng Fu et.al.|[2412.18139v1](http://arxiv.org/abs/2412.18139v1)|null|
|**2024-12-24**|**LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment**|Binrui Zeng et.al.|[2412.18135v1](http://arxiv.org/abs/2412.18135v1)|null|
|**2024-12-24**|**Exact Acceleration of Subgraph Graph Neural Networks by Eliminating Computation Redundancy**|Qian Tao et.al.|[2412.18125v1](http://arxiv.org/abs/2412.18125v1)|null|
|**2024-12-24**|**AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models**|Yiming Wang et.al.|[2412.18123v1](http://arxiv.org/abs/2412.18123v1)|null|
|**2024-12-24**|**Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm**|Xiaoyang Hu et.al.|[2412.18120v1](http://arxiv.org/abs/2412.18120v1)|null|
|**2024-12-24**|**AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation**|Hao Wen et.al.|[2412.18116v1](http://arxiv.org/abs/2412.18116v1)|null|
|**2024-12-24**|**AIGT: AI Generative Table Based on Prompt**|Mingming Zhang et.al.|[2412.18111v1](http://arxiv.org/abs/2412.18111v1)|null|
|**2024-12-24**|**SlimGPT: Layer-wise Structured Pruning for Large Language Models**|Gui Ling et.al.|[2412.18110v1](http://arxiv.org/abs/2412.18110v1)|null|
|**2024-12-24**|**SongGLM: Lyric-to-Melody Generation with 2D Alignment Encoding and Multi-Task Pre-Training**|Jiaxing Yu et.al.|[2412.18107v1](http://arxiv.org/abs/2412.18107v1)|null|
|**2024-12-24**|**Tackling the Dynamicity in a Production LLM Serving System with SOTA Optimizations via Hybrid Prefill/Decode/Verify Scheduling on Efficient Meta-kernels**|Mingcong Song et.al.|[2412.18106v1](http://arxiv.org/abs/2412.18106v1)|null|
|**2024-12-24**|**EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent**|Suyuan Wang et.al.|[2412.18100v1](http://arxiv.org/abs/2412.18100v1)|null|
|**2024-12-24**|**An Attention-based Framework with Multistation Information for Earthquake Early Warnings**|Yu-Ming Huang et.al.|[2412.18099v1](http://arxiv.org/abs/2412.18099v1)|null|
|**2024-12-24**|**LangYa: Revolutionizing Cross-Spatiotemporal Ocean Forecasting**|Nan Yang et.al.|[2412.18097v1](http://arxiv.org/abs/2412.18097v1)|null|
|**2024-12-24**|**Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**|Yu He Ke et.al.|[2412.18096v1](http://arxiv.org/abs/2412.18096v1)|null|
|**2024-12-24**|**Molly: Making Large Language Model Agents Solve Python Problem More Logically**|Rui Xiao et.al.|[2412.18093v1](http://arxiv.org/abs/2412.18093v1)|null|
|**2024-12-24**|**BRIDGE: Bundle Recommendation via Instruction-Driven Generation**|Tuan-Nghia Bui et.al.|[2412.18092v1](http://arxiv.org/abs/2412.18092v1)|null|
|**2024-12-24**|**AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning**|Lixian Jing et.al.|[2412.18091v1](http://arxiv.org/abs/2412.18091v1)|null|
|**2024-12-24**|**Multi-Point Positional Insertion Tuning for Small Object Detection**|Kanoko Goto et.al.|[2412.18090v1](http://arxiv.org/abs/2412.18090v1)|null|
|**2024-12-24**|**Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner**|Aizierjiang Aiersilan et.al.|[2412.18086v1](http://arxiv.org/abs/2412.18086v1)|[link](https://github.com/Ezharjan/AutoSceneGen)|
|**2024-12-24**|**Property Enhanced Instruction Tuning for Multi-task Molecule Generation with Large Language Models**|Xuan Lin et.al.|[2412.18084v1](http://arxiv.org/abs/2412.18084v1)|[link](https://github.com/chenlong164/peit)|
|**2024-12-24**|**Prompt Tuning for Item Cold-start Recommendation**|Yuezihan Jiang et.al.|[2412.18082v1](http://arxiv.org/abs/2412.18082v1)|[link](https://github.com/promorec/promo)|
|**2024-12-24**|**COMO: Cross-Mamba Interaction and Offset-Guided Fusion for Multimodal Object Detection**|Chang Liu et.al.|[2412.18076v1](http://arxiv.org/abs/2412.18076v1)|null|

#### Abstracts
##### **Long-Form Speech Generation with Spoken Language Models**
2412.18603v1 by Se Jin Park, Julian Salazar, Aren Jansen, Keisuke Kinoshita, Yong Man Ro, RJ Skerry-Ryan

We consider the generative modeling of speech over multiple minutes, a
requirement for long-form multimedia generation and audio-native voice
assistants. However, current spoken language models struggle to generate
plausible speech past tens of seconds, from high temporal resolution of speech
tokens causing loss of coherence, to architectural issues with long-sequence
training or extrapolation, to memory costs at inference time. With these
considerations we propose SpeechSSM, the first speech language model to learn
from and sample long-form spoken audio (e.g., 16 minutes of read or
extemporaneous speech) in a single decoding session without text intermediates,
based on recent advances in linear-time sequence modeling. Furthermore, to
address growing challenges in spoken language evaluation, especially in this
new long-form setting, we propose: new embedding-based and LLM-judged metrics;
quality measurements over length and time; and a new benchmark for long-form
speech processing and generation, LibriSpeech-Long. Speech samples and the
dataset are released at
https://google.github.io/tacotron/publications/speechssm/

摘要：我們考慮多分鐘的語音生成模型，這是長篇多媒體生成和音訊原生語音助理的要求。然而，目前的口語語言模型難以生成超過數十秒的可信語音，從語音標記的高時間解析度導致一致性喪失，到長序列訓練或外推的架構問題，再到推理時間的記憶體成本。考量這些因素，我們提出 SpeechSSM，這是第一個從長篇口語音訊（例如，16 分鐘的朗讀或即興演講）學習並取樣的語音語言模型，在單一解碼會話中，沒有文字中間產物，基於線性時間序列建模的最新進展。此外，為了解決口語語言評估中日益嚴峻的挑戰，特別是在這個新的長篇設定中，我們提出：新的基於嵌入和 LLM 判斷的指標；長度和時間的品質測量；以及長篇語音處理和生成的新的基準，LibriSpeech-Long。語音範例和資料集已於 https://google.github.io/tacotron/publications/speechssm/ 發布。

##### **Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems**
2412.18601v1 by Fernando Jia, Jade Zheng, Florence Li

In the rapidly evolving landscape of GameFi, a fusion of gaming and
decentralized finance (DeFi), there exists a critical need to enhance player
engagement and economic interaction within gaming ecosystems. Our GameFi
ecosystem aims to fundamentally transform this landscape by integrating
advanced embodied AI agents into GameFi platforms. These AI agents, developed
using cutting-edge large language models (LLMs), such as GPT-4 and Claude AI,
are capable of proactive, adaptive, and contextually rich interactions with
players. By going beyond traditional scripted responses, these agents become
integral participants in the game's narrative and economic systems, directly
influencing player strategies and in-game economies. We address the limitations
of current GameFi platforms, which often lack immersive AI interactions and
mechanisms for community engagement or creator monetization. Through the deep
integration of AI agents with blockchain technology, we establish a
consensus-driven, decentralized GameFi ecosystem. This ecosystem empowers
creators to monetize their contributions and fosters democratic collaboration
among players and creators. Furthermore, by embedding DeFi mechanisms into the
gaming experience, we enhance economic participation and provide new
opportunities for financial interactions within the game. Our approach enhances
player immersion and retention and advances the GameFi ecosystem by bridging
traditional gaming with Web3 technologies. By integrating sophisticated AI and
DeFi elements, we contribute to the development of more engaging, economically
robust, and community-centric gaming environments. This project represents a
significant advancement in the state-of-the-art in GameFi, offering insights
and methodologies that can be applied throughout the gaming industry.

摘要：在 GameFi 快速演進的環境中，遊戲與去中心化金融 (DeFi) 的融合，亟需提升玩家參與度和遊戲生態系統中的經濟互動。我們的 GameFi 生態系統旨在透過將進階的具身 AI 代理整合到 GameFi 平台中，從根本上轉變這種環境。這些 AI 代理使用尖端的巨量語言模型 (LLM)（例如 GPT-4 和 Claude AI）開發，能夠與玩家進行主動、適應性和豐富的互動。這些代理超越傳統腳本回應，成為遊戲敘事和經濟系統中不可或缺的參與者，直接影響玩家策略和遊戲經濟。我們解決了當前 GameFi 平台的限制，這些平台通常缺乏身歷其境的 AI 互動和社群參與或創作者獲利機制。透過將 AI 代理與區塊鏈技術深度整合，我們建立了一個共識驅動的、去中心化的 GameFi 生態系統。此生態系統讓創作者能夠將他們的貢獻獲利化，並促進玩家和創作者之間的民主合作。此外，透過將 DeFi 機制嵌入遊戲體驗中，我們加強了經濟參與，並在遊戲中提供了新的金融互動機會。我們的做法增強了玩家的沉浸感和留存率，並透過將傳統遊戲與 Web3 技術連結起來，提升了 GameFi 生態系統。透過整合先進的 AI 和 DeFi 元素，我們為更具吸引力、經濟強健且以社群為中心的遊戲環境的發展做出貢獻。這個專案代表了 GameFi 最先進技術的重大進展，提供了可在整個遊戲產業應用的見解和方法。

##### **DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**
2412.18597v1 by Minghong Cai, Xiaodong Cun, Xiaoyu Li, Wenze Liu, Zhaoyang Zhang, Yong Zhang, Ying Shan, Xiangyu Yue

Sora-like video generation models have achieved remarkable progress with a
Multi-Modal Diffusion Transformer MM-DiT architecture. However, the current
video generation models predominantly focus on single-prompt, struggling to
generate coherent scenes with multiple sequential prompts that better reflect
real-world dynamic scenarios. While some pioneering works have explored
multi-prompt video generation, they face significant challenges including
strict training data requirements, weak prompt following, and unnatural
transitions. To address these problems, we propose DiTCtrl, a training-free
multi-prompt video generation method under MM-DiT architectures for the first
time. Our key idea is to take the multi-prompt video generation task as
temporal video editing with smooth transitions. To achieve this goal, we first
analyze MM-DiT's attention mechanism, finding that the 3D full attention
behaves similarly to that of the cross/self-attention blocks in the UNet-like
diffusion models, enabling mask-guided precise semantic control across
different prompts with attention sharing for multi-prompt video generation.
Based on our careful design, the video generated by DiTCtrl achieves smooth
transitions and consistent object motion given multiple sequential prompts
without additional training. Besides, we also present MPVBench, a new benchmark
specially designed for multi-prompt video generation to evaluate the
performance of multi-prompt generation. Extensive experiments demonstrate that
our method achieves state-of-the-art performance without additional training.

摘要：類 Sora 的影片生成模型在多模態擴散Transformer MM-DiT 架構中取得顯著進展。然而，目前的影片生成模型主要專注於單一提示，難以生成包含多個循序提示的連貫場景，而這些提示更能反映真實世界的動態場景。儘管一些開創性的作品已探索多提示影片生成，但它們面臨嚴峻的挑戰，包括嚴格的訓練資料需求、提示追蹤能力不佳以及不自然的轉換。為了解決這些問題，我們提出 DiTCtrl，這是一種在 MM-DiT 架構下首次使用的免訓練多提示影片生成方法。我們的關鍵想法是將多提示影片生成任務視為具有平滑轉換的時序影片編輯。為了達成此目標，我們首先分析 MM-DiT 的注意力機制，發現 3D 全注意力與 UNet 類擴散模型中的交叉/自我注意力區塊有類似的行為，這使得我們能夠透過注意力共享進行遮罩導引的精確語意控制，以進行多提示影片生成。根據我們的精細設計，DiTCtrl 生成的影片在給定多個循序提示的情況下，可以實現平滑的轉換和一致的物件動作，而不需要額外的訓練。此外，我們還提出了 MPVBench，這是一個專門設計用於多提示影片生成的新基準，用於評估多提示生成的效果。廣泛的實驗證明，我們的方法在沒有額外訓練的情況下，達到了最先進的效能。

##### **A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs**
2412.18588v1 by OpenMind, Shaohong Zhong, Adam Zhou, Boyuan Chen, Homin Luo, Jan Liphardt

Large Language Models (LLMs) are compact representations of all public
knowledge of our physical environment and animal and human behaviors. The
application of LLMs to robotics may offer a path to highly capable robots that
perform well across most human tasks with limited or even zero tuning. Aside
from increasingly sophisticated reasoning and task planning, networks of
(suitably designed) LLMs offer ease of upgrading capabilities and allow humans
to directly observe the robot's thinking. Here we explore the advantages,
limitations, and particularities of using LLMs to control physical robots. The
basic system consists of four LLMs communicating via a human language data bus
implemented via web sockets and ROS2 message passing. Surprisingly, rich robot
behaviors and good performance across different tasks could be achieved despite
the robot's data fusion cycle running at only 1Hz and the central data bus
running at the extremely limited rates of the human brain, of around 40 bits/s.
The use of natural language for inter-LLM communication allowed the robot's
reasoning and decision making to be directly observed by humans and made it
trivial to bias the system's behavior with sets of rules written in plain
English. These rules were immutably written into Ethereum, a global, public,
and censorship resistant Turing-complete computer. We suggest that by using
natural language as the data bus among interacting AIs, and immutable public
ledgers to store behavior constraints, it is possible to build robots that
combine unexpectedly rich performance, upgradability, and durable alignment
with humans.

摘要：大型語言模型 (LLM) 濃縮了我們對物理環境、動物和人類行為的所有公開知識。將 LLM 應用於機器人技術，可能為功能強大的機器人提供一條途徑，這些機器人在大多數人類任務中表現良好，調整有限甚至為零。除了日益複雜的推理和任務規劃之外，（適當設計的）LLM 網路提供輕鬆升級功能，並允許人類直接觀察機器人的思考。在這裡，我們探討了使用 LLM 控制物理機器人的優點、限制和特殊性。基本系統由四個 LLM 組成，它們通過人類語言數據匯流排進行通信，該匯流排通過網路套接字和 ROS2 訊息傳遞來實現。令人驚訝的是，儘管機器人的數據融合週期僅以 1Hz 運行，而中央數據匯流排以人類大腦極其有限的速度（約 40 位元/秒）運行，但仍可以在不同的任務中實現豐富的機器人行為和良好的性能。使用自然語言進行 LLM 間通信，允許人類直接觀察機器人的推理和決策制定，並使系統行為偏向於用簡單英語編寫的規則集變得微不足道。這些規則不可變地寫入以太坊，這是一個全球性的、公開的、且抗審查的圖靈完備電腦。我們建議，通過使用自然語言作為互動 AI 之間的數據匯流排，以及不可變的公共帳本來儲存行為約束，有可能建立結合了意外豐富的性能、可升級性和與人類持久一致性的機器人。

##### **Exploring Embedding Priors in Prompt-Tuning for Improved Interpretability and Control**
2412.18582v1 by Sergey Sedov, Sumanth Bharadwaj Hachalli Karanam, Venu Gopal Kadamba

Prompt-Tuning is an efficient method for adapting pre-trained language models
to new tasks with minimal computational overhead by modifying prompt
embeddings. In this work, we investigate how crucial the phenomenon of
embedding collapse, frequently observed in Prompt-Tuning, is for the final
performance of the model. To address this question, we designed embedding
priors and compared them with posteriors of the converged Soft and Deep
Prompt-Tuning methods. Our findings suggest that priors strongly affect the
position of the tuned embeddings, and models can effectively work with
embeddings from different parts of activation spaces, including completely new
regions. As the final Prompt-Tuning capabilities are limited, we hypothesize
that controllable Prompt-Tuning posteriors may serve as a good starting point
for tasks such as chain-of-thought (COT) distillation. Our experiments also
show that generated trajectories are not localized in the activation space of
the models. However, there are distinct clusters of activations for distant
tasks (e.g., NLP and arithmetic), while activations between NLP tasks (e.g.,
Question-Answering and MLM) lie in the same cluster. These observations raise
questions about the importance of a single activation cluster for the
generalization abilities of large language models.

摘要：提示調整是一種有效的方法，可透過修改提示嵌入來調整預先訓練的語言模型以適應新任務，且計算量開銷極小。在這項工作中，我們探討在提示調整中經常觀察到的嵌入式折疊現象對模型的最終效能有多麼關鍵。為了解決這個問題，我們設計了嵌入式先驗，並將它們與收斂的軟提示調整和深度提示調整方法的事後驗證進行比較。我們的研究結果表明，先驗會強烈影響調整嵌入式的位置，而模型可以有效地使用來自啟動空間不同部分的嵌入式，包括全新的區域。由於最終提示調整功能受到限制，我們假設可控提示調整事後驗證可以作為鏈式思考 (COT) 蒸餾等任務的良好起點。我們的實驗也顯示，產生的軌跡並未局限在模型的啟動空間中。然而，遠程任務（例如 NLP 和算術）有不同的啟動群集，而 NLP 任務（例如問答和 MLM）之間的啟動則位於同一個群集。這些觀察引發了問題，即對於大型語言模型的泛化能力而言，單一啟動群集的重要性為何。

##### **How Well Do LLMs Generate Code for Different Application Domains? Benchmark and Evaluation**
2412.18573v1 by Dewu Zheng, Yanlin Wang, Ensheng Shi, Hongyu Zhang, Zibin Zheng

Recently, an increasing number of AI-driven programming assistants powered by
code LLMs have been integrated into various real-world software development
environments, significantly boosting developer productivity. However, existing
code generation benchmarks primarily focus on general-purpose scenarios,
leaving the code generation performance of LLMs for specific application
domains largely unknown. In this paper, we introduce a new benchmark,
MultiCodeBench, to fill this gap. MultiCodeBench comprises 2,400 programming
tasks, covering 12 popular software development domains and 15 programming
languages. Specifically, we perform in-depth research to identify these 12
application domains. Given that each domain may involve multiple technical
frameworks, and that different frameworks present distinct challenges in the
coding process, we categorize the commonly used frameworks and platforms within
each domain. We then sample programming problems from GitHub repositories
related to these subdomains. To ensure the quality of the tasks and mitigate
data leakage issues, we invite annotators to rewrite the docstrings for each
task in MultiCodeBench. Additionally, we build a static analysis-based
dependency parsing tool to extract the dependencies in the ground truth for
each task, enabling deeper performance analysis. Through extensive experiments
on MultiCodeBench with eleven representative mainstream LLMs, we reveal the
code generation performance of the LLMs across different application domains,
providing practical insights for developers in downstream fields when selecting
LLMs. Furthermore, we analyze the reasons behind the models' failures in
completing software application development tasks, offering guidance for model
developers to enhance domain-specific code generation capabilities.

摘要：<paragraph>最近，由代码 LLM 提供支持的越来越多的 AI 驱动的编程助手已集成到各种实际软件开发环境中，极大地提高了开发人员的生产力。然而，现有的代码生成基准主要关注通用场景，在很大程度上忽略了 LLM 在特定应用程序领域中的代码生成性能。在本文中，我们引入了一个新的基准 MultiCodeBench 来填补这一空白。MultiCodeBench 包含 2,400 个编程任务，涵盖 12 个流行的软件开发领域和 15 种编程语言。具体来说，我们进行了深入的研究以识别这 12 个应用程序领域。鉴于每个领域可能涉及多个技术框架，并且不同的框架在编码过程中提出了不同的挑战，因此我们对每个领域中常用的框架和平台进行了分类。然后，我们从与这些子域相关的 GitHub 存储库中抽取编程问题。为了确保任务的质量并减轻数据泄露问题，我们邀请注释员重写 MultiCodeBench 中每个任务的文档字符串。此外，我们构建了一个基于静态分析的依赖项解析工具，以提取每个任务的基本事实中的依赖项，从而实现更深入的性能分析。通过在 MultiCodeBench 上使用 11 个有代表性的主流 LLM 进行广泛的实验，我们揭示了 LLM 在不同应用程序领域中的代码生成性能，为下游领域的开发人员在选择 LLM 时提供了实用的见解。此外，我们分析了模型在完成软件应用程序开发任务时失败的原因，为模型开发人员提供了增强特定领域代码生成能力的指导。</paragraph>

##### **Zero-resource Speech Translation and Recognition with LLMs**
2412.18566v1 by Karel Mundnich, Xing Niu, Prashant Mathur, Srikanth Ronanki, Brady Houston, Veera Raghavendra Elluru, Nilaksh Das, Zejiang Hou, Goeric Huybrechts, Anshu Bhatia, Daniel Garcia-Romero, Kyu J. Han, Katrin Kirchhoff

Despite recent advancements in speech processing, zero-resource speech
translation (ST) and automatic speech recognition (ASR) remain challenging
problems. In this work, we propose to leverage a multilingual Large Language
Model (LLM) to perform ST and ASR in languages for which the model has never
seen paired audio-text data. We achieve this by using a pre-trained
multilingual speech encoder, a multilingual LLM, and a lightweight adaptation
module that maps the audio representations to the token embedding space of the
LLM. We perform several experiments both in ST and ASR to understand how to
best train the model and what data has the most impact on performance in
previously unseen languages. In ST, our best model is capable to achieve BLEU
scores over 23 in CoVoST2 for two previously unseen languages, while in ASR, we
achieve WERs of up to 28.2\%. We finally show that the performance of our
system is bounded by the ability of the LLM to output text in the desired
language.

摘要：儘管在語音處理方面有近期的進展，零資源語音翻譯 (ST) 和自動語音辨識 (ASR) 仍然是具有挑戰性的問題。在這項工作中，我們提議利用多語言大型語言模型 (LLM) 來執行 ST 和 ASR，這些語言的模型從未見過配對的音訊文字資料。我們透過使用預先訓練的多語言語音編碼器、多語言 LLM 和輕量級適應模組來達成此目標，該模組會將音訊表示對應到 LLM 的標記嵌入空間。我們執行多項 ST 和 ASR 實驗，以了解如何最佳訓練模型，以及哪些資料對先前未見語言的效能影響最大。在 ST 中，我們的最佳模型能夠在 CoVoST2 中針對兩種先前未見的語言達成超過 23 的 BLEU 分數，而在 ASR 中，我們達成高達 28.2% 的 WER。我們最後顯示，我們系統的效能受限於 LLM 以所需語言輸出文字的能力。

##### **Distilling Fine-grained Sentiment Understanding from Large Language Models**
2412.18552v1 by Yice Zhang, Guangyu Xie, Hongling Xu, Kaiheng Hou, Jianzhu Bao, Qianlong Wang, Shiwei Chen, Ruifeng Xu

Fine-grained sentiment analysis (FSA) aims to extract and summarize user
opinions from vast opinionated text. Recent studies demonstrate that large
language models (LLMs) possess exceptional sentiment understanding
capabilities. However, directly deploying LLMs for FSA applications incurs high
inference costs. Therefore, this paper investigates the distillation of
fine-grained sentiment understanding from LLMs into small language models
(SLMs). We prompt LLMs to examine and interpret the sentiments of given reviews
and then utilize the generated content to pretrain SLMs. Additionally, we
develop a comprehensive FSA benchmark to evaluate both SLMs and LLMs. Extensive
experiments on this benchmark reveal that: (1) distillation significantly
enhances the performance of SLMs in FSA tasks, achieving a 6.00\% improvement
in $F_1$-score, and the distilled model can outperform Llama-2-7b with only
220M parameters; (2) distillation equips SLMs with excellent zero-shot
sentiment classification capabilities, enabling them to match or even exceed
their teacher models. These results suggest that distillation from LLMs is a
highly promising direction for FSA. We will release our code, data, and
pretrained model weights at
\url{https://github.com/HITSZ-HLT/FSA-Distillation}.

摘要：細粒度情緒分析 (FSA) 旨在從大量的意見文本中提取和總結使用者的意見。最近的研究表明，大型語言模型 (LLM) 具有卓越的情緒理解能力。然而，直接部署 LLM 進行 FSA 應用會產生高昂的推論成本。因此，本文探討將 LLM 中的細粒度情緒理解蒸餾到小型語言模型 (SLM) 中。我們提示 LLM 檢查和詮釋給定評論的情緒，然後利用產生的內容預訓練 SLM。此外，我們開發了一個全面的 FSA 基準來評估 SLM 和 LLM。在這個基準上的廣泛實驗揭示：(1) 蒸餾顯著提升 SLM 在 FSA 任務中的表現，在 $F_1$-score 中提升 6.00%，而且蒸餾模型僅使用 220M 個參數就能超越 Llama-2-7b；(2) 蒸餾賦予 SLM 優異的零次學習情緒分類能力，使其能夠匹配甚至超越其教師模型。這些結果表明，從 LLM 進行蒸餾是 FSA 一個極具前景的方向。我們將在
\url{https://github.com/HITSZ-HLT/FSA-Distillation} 發布我們的程式碼、資料和預訓練模型權重。

##### **Libra-Leaderboard: Towards Responsible AI through a Balanced Leaderboard of Safety and Capability**
2412.18551v1 by Haonan Li, Xudong Han, Zenan Zhai, Honglin Mu, Hao Wang, Zhenxuan Zhang, Yilin Geng, Shom Lin, Renxi Wang, Artem Shelmanov, Xiangyu Qi, Yuxia Wang, Donghai Hong, Youliang Yuan, Meng Chen, Haoqin Tu, Fajri Koto, Tatsuki Kuribayashi, Cong Zeng, Rishabh Bhardwaj, Bingchen Zhao, Yawen Duan, Yi Liu, Emad A. Alghamdi, Yaodong Yang, Yinpeng Dong, Soujanya Poria, Pengfei Liu, Zhengzhong Liu, Xuguang Ren, Eduard Hovy, Iryna Gurevych, Preslav Nakov, Monojit Choudhury, Timothy Baldwin

To address this gap, we introduce Libra-Leaderboard, a comprehensive
framework designed to rank LLMs through a balanced evaluation of performance
and safety. Combining a dynamic leaderboard with an interactive LLM arena,
Libra-Leaderboard encourages the joint optimization of capability and safety.
Unlike traditional approaches that average performance and safety metrics,
Libra-Leaderboard uses a distance-to-optimal-score method to calculate the
overall rankings. This approach incentivizes models to achieve a balance rather
than excelling in one dimension at the expense of some other ones. In the first
release, Libra-Leaderboard evaluates 26 mainstream LLMs from 14 leading
organizations, identifying critical safety challenges even in state-of-the-art
models.

摘要：為了彌補此差距，我們引進了 Libra-Leaderboard，這是一個綜合性框架，旨在透過平衡效能和安全性的評估來對 LLM 進行排名。Libra-Leaderboard 結合了動態排行榜和互動式 LLM 競技場，鼓勵對能力和安全性進行聯合最佳化。與平均效能和安全性指標的傳統方法不同，Libra-Leaderboard 使用距離最佳分數的方法來計算整體排名。這種方法鼓勵模型取得平衡，而不是在某個面向表現出色而犧牲其他面向。在第一個版本中，Libra-Leaderboard 從 14 個領先組織中評估了 26 個主流 LLM，即使在最先進的模型中也找出了重大的安全性挑戰。

##### **Token-Budget-Aware LLM Reasoning**
2412.18547v1 by Tingxu Han, Chunrong Fang, Shiyu Zhao, Shiqing Ma, Zhenyu Chen, Zhenting Wang

Reasoning is critical for large language models (LLMs) to excel in a wide
range of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM
performance by decomposing problems into intermediate steps, they also incur
significant overhead in token usage, leading to increased costs. We find that
the reasoning process of current LLMs is unnecessarily lengthy and it can be
compressed by including a reasonable token budget in the prompt, but the choice
of token budget plays a crucial role in the actual compression effectiveness.
We then propose a token-budget-aware LLM reasoning framework, which dynamically
estimates token budgets for different problems based on reasoning complexity
and uses the estimated token budgets to guide the reasoning process.
Experiments show that our method effectively reduces token costs in CoT
reasoning with only a slight performance reduction, offering a practical
solution to balance efficiency and accuracy in LLM reasoning. Code:
https://github.com/GeniusHTX/TALE.

摘要：推理對於大型語言模型 (LLM) 在廣泛任務中表現出色至關重要。雖然像思想鏈 (CoT) 推理等方法透過將問題分解成中間步驟來增強 LLM 效能，但它們也會造成代幣使用上的顯著負擔，導致成本增加。我們發現，目前 LLM 的推理過程過於冗長，而且可以透過在提示中包含合理的代幣預算來壓縮，但代幣預算的選擇在實際壓縮效果中扮演關鍵角色。我們接著提出一個具備代幣預算感知功能的 LLM 推理架構，它會根據推理複雜度動態估計不同問題的代幣預算，並使用估計的代幣預算來引導推理過程。實驗顯示，我們的方法有效降低了 CoT 推理中的代幣成本，效能僅略微下降，提供了一個在 LLM 推理中平衡效率與精確度的實用解決方案。程式碼：https://github.com/GeniusHTX/TALE。

##### **Consistency Checks for Language Model Forecasters**
2412.18544v1 by Daniel Paleka, Abhimanyu Pallavi Sudhir, Alejandro Alvarez, Vineeth Bhat, Adam Shen, Evan Wang, Florian Tramèr

Forecasting is a task that is difficult to evaluate: the ground truth can
only be known in the future. Recent work showing LLM forecasters rapidly
approaching human-level performance begs the question: how can we benchmark and
evaluate these forecasters instantaneously? Following the consistency check
framework, we measure the performance of forecasters in terms of the
consistency of their predictions on different logically-related questions. We
propose a new, general consistency metric based on arbitrage: for example, if a
forecasting AI illogically predicts that both the Democratic and Republican
parties have 60% probability of winning the 2024 US presidential election, an
arbitrageur can trade against the forecaster's predictions and make a profit.
We build an automated evaluation system that generates a set of base questions,
instantiates consistency checks from these questions, elicits the predictions
of the forecaster, and measures the consistency of the predictions. We then
build a standard, proper-scoring-rule forecasting benchmark, and show that our
(instantaneous) consistency metrics correlate with LLM forecasters' ground
truth Brier scores (which are only known in the future). We also release a
consistency benchmark that resolves in 2028, providing a long-term evaluation
tool for forecasting.

摘要：預測是一項難以評估的任務：只有在未來才能知道真實情況。最近的研究顯示，LLM 預測員正迅速接近人類層級的表現，這引發了一個問題：我們如何立即對這些預測員進行基準測試和評估？遵循一致性檢查架構，我們根據預測員在不同邏輯相關問題上的預測一致性來衡量其表現。我們提出了一個新的、基於套利的通用一致性指標：例如，如果一個預測 AI 沒有邏輯地預測民主黨和共和黨在 2024 年美國總統大選中都有 60% 的獲勝機率，套利者可以針對預測員的預測進行交易並獲利。我們建立了一個自動化評估系統，用於產生一組基本問題，從這些問題中實例化一致性檢查，引出預測員的預測，並衡量預測的一致性。然後，我們建立了一個標準的、適當計分規則預測基準，並表明我們的（即時）一致性指標與 LLM 預測員的真實布賴爾得分（僅在未來才知道）相關。我們還發布了一個在 2028 年解決的一致性基準，提供了一個用於預測的長期評估工具。

##### **Harnessing Large Language Models for Knowledge Graph Question Answering via Adaptive Multi-Aspect Retrieval-Augmentation**
2412.18537v1 by Derong Xu Xinhang Li, Ziheng Zhang, Zhenxi Lin, Zhihong Zhu, Zhi Zheng, Xian Wu, Xiangyu Zhao, Tong Xu, Enhong Chen

Large Language Models (LLMs) demonstrate remarkable capabilities, yet
struggle with hallucination and outdated knowledge when tasked with complex
knowledge reasoning, resulting in factually incorrect outputs. Previous studies
have attempted to mitigate it by retrieving factual knowledge from large-scale
knowledge graphs (KGs) to assist LLMs in logical reasoning and prediction of
answers. However, this kind of approach often introduces noise and irrelevant
data, especially in situations with extensive context from multiple knowledge
aspects. In this way, LLM attention can be potentially mislead from question
and relevant information. In our study, we introduce an Adaptive Multi-Aspect
Retrieval-augmented over KGs (Amar) framework. This method retrieves knowledge
including entities, relations, and subgraphs, and converts each piece of
retrieved text into prompt embeddings. The Amar framework comprises two key
sub-components: 1) a self-alignment module that aligns commonalities among
entities, relations, and subgraphs to enhance retrieved text, thereby reducing
noise interference; 2) a relevance gating module that employs a soft gate to
learn the relevance score between question and multi-aspect retrieved data, to
determine which information should be used to enhance LLMs' output, or even
filtered altogether. Our method has achieved state-of-the-art performance on
two common datasets, WebQSP and CWQ, showing a 1.9\% improvement in accuracy
over its best competitor and a 6.6\% improvement in logical form generation
over a method that directly uses retrieved text as context prompts. These
results demonstrate the effectiveness of Amar in improving the reasoning of
LLMs.

摘要：大型語言模型 (LLM) 展示了非凡的能力，但當它們被賦予複雜的知識推理任務時，卻會陷入幻覺和過時知識的困境，導致事實上不正確的輸出。先前的研究已嘗試通過從大規模知識圖譜 (KG) 中擷取事實知識來減輕這種情況，以協助 LLM 進行邏輯推理和答案預測。然而，這種方法通常會引入雜訊和無關資料，特別是在具有來自多個知識面向的廣泛背景的情況下。通過這種方式，LLM 注意力可能會被問題和相關資訊誤導。在我們的研究中，我們引入了自適應多面向檢索增強的知識圖譜 (Amar) 架構。此方法擷取包括實體、關係和子圖的知識，並將每個擷取的文字轉換為提示嵌入。Amar 架構包含兩個關鍵子元件：1) 一個自我對齊模組，它對齊實體、關係和子圖之間的共性以增強擷取的文字，從而減少雜訊干擾；2) 一個相關性閘門模組，它採用軟閘門來學習問題與多面向擷取資料之間的相关性分數，以確定哪些資訊應被用來增強 LLM 的輸出，甚至完全過濾掉。我們的模型在兩個常見的資料集 WebQSP 和 CWQ 上達到了最先進的效能，與最佳競爭者相比，準確度提升了 1.9%，與直接使用擷取文字作為背景提示的方法相比，邏輯形式產生的改進為 6.6%。這些結果證明了 Amar 在改善 LLM 推理方面的有效性。

##### **Characterizations of Language Generation With Breadth**
2412.18530v1 by Alkis Kalavasis, Anay Mehrotra, Grigoris Velegkas

We study language generation in the limit, introduced by Kleinberg and
Mullainathan [KM24], building on classical works of Gold [Gol67] and Angluin
[Ang79]. [KM24] proposed an algorithm that generates strings from any countable
language collection in the limit. While their algorithm eventually outputs
strings from the target language $K$, it sacrifices breadth, i.e., the ability
to generate all strings in $K$. A key open question in [KM24] is whether this
trade-off between consistency and breadth is inherrent.
  Recent works proposed different notions of consistent generation with
breadth. Kalavasis, Mehrotra, and Velegkas [KVM24] introduced three
definitions: generation with exact breadth, approximate breadth, and
unambiguous generation. Concurrently and independently, Charikar and Pabbaraju
[CP24a] proposed exhaustive generation. Both works examined when generation
with these notions of breadth is possible.
  Building on [CP24a, KVM24], we fully characterize language generation for
these notions and their natural combinations. For exact breadth, we provide an
unconditional lower bound, removing a technical condition from [KVM24] and
extending the result of [CP24a] that holds for specific collections of
languages. We show that generation with exact breadth is characterized by
Angluin's condition for identification. We further introduce a weaker version
of Angluin's condition that tightly characterizes both approximate breadth and
exhaustive generation, proving their equivalence. Additionally, we show that
unambiguous generation is also characterized by Angluin's condition as a
special case of a broader result. Finally, we strengthen [KVM24] by giving
unconditional lower bounds for stable generators, showing that Angluin's
condition characterizes the previous breadth notions for stable generators.
This shows a separation between stable and unstable generation with approximate
breadth.

摘要：<paragraph>我們研究語言生成極限，由 Kleinberg 和 Mullainathan [KM24] 提出，建立在 Gold [Gol67] 和 Angluin [Ang79] 的經典著作之上。[KM24] 提出了一種演算法，可以從任何可數語言集合中生成字串。雖然他們的演算法最終會輸出目標語言 $K$ 中的字串，但它犧牲了廣度，也就是生成 $K$ 中所有字串的能力。[KM24] 中一個關鍵的開放問題是，一致性和廣度之間的這種權衡是否固有。
近期著作提出了廣度一致生成的不同概念。Kalavasis、Mehrotra 和 Velegkas [KVM24] 介紹了三個定義：廣度精確生成、廣度近似生成和無歧義生成。同時獨立地，Charikar 和 Pabbaraju [CP24a] 提出窮盡生成。兩項著作都探討了廣度的這些概念何時可能產生。
建立在 [CP24a, KVM24] 之上，我們完全描述了這些概念的語言生成及其自然組合。對於廣度精確，我們提供了無條件的下限，從 [KVM24] 中移除技術條件，並擴充套件 [CP24a] 對特定語言集合成立的結果。我們表明，廣度精確的生成是由 Angluin 的識別條件特徵化的。我們進一步引入 Angluin 條件的較弱版本，它緊密地特徵化了近似廣度和窮盡生成，證明了它們的等價性。此外，我們表明無歧義生成也由 Angluin 條件特徵化，作為廣泛結果的特殊情況。最後，我們通過提供穩定生成器的無條件下限來加強 [KVM24]，表明 Angluin 條件特徵化了穩定生成器先前的廣度概念。這顯示了近似廣度穩定和不穩定生成之間的分離。</paragraph>

##### **Think or Remember? Detecting and Directing LLMs Towards Memorization or Generalization**
2412.18497v1 by Yi-Fu Fu, Yu-Chieh Tu, Tzu-Ling Cheng, Cheng-Yu Lin, Yi-Ting Yang, Heng-Yi Liu, Keng-Te Liao, Da-Cheng Juan, Shou-De Lin

In this paper, we explore the foundational mechanisms of memorization and
generalization in Large Language Models (LLMs), inspired by the functional
specialization observed in the human brain. Our investigation serves as a case
study leveraging specially designed datasets and experimental-scale LLMs to lay
the groundwork for understanding these behaviors. Specifically, we aim to first
enable LLMs to exhibit both memorization and generalization by training with
the designed dataset, then (a) examine whether LLMs exhibit neuron-level
spatial differentiation for memorization and generalization, (b) predict these
behaviors using model internal representations, and (c) steer the behaviors
through inference-time interventions. Our findings reveal that neuron-wise
differentiation of memorization and generalization is observable in LLMs, and
targeted interventions can successfully direct their behavior.

摘要：在本文中，我們探討了大型語言模型 (LLM) 中記憶和概括的基本機制，靈感來自於人類大腦中觀察到的功能專門化。我們的研究作為一個案例研究，利用專門設計的資料集和實驗規模的 LLM，為理解這些行為奠定基礎。具體來說，我們的目標是首先讓 LLM 通過使用設計的資料集進行訓練來展示記憶和概括，然後 (a) 檢查 LLM 是否表現出神經元級別的空間區分以進行記憶和概括，(b) 使用模型內部表示預測這些行為，以及 (c) 引導行為通過推理時間干預。我們的研究結果表明，在 LLM 中可以觀察到記憶和概括的神經元差異，並且有針對性的干預可以成功地指導它們的行為。

##### **Generating event descriptions under syntactic and semantic constraints**
2412.18496v1 by Angela Cao, Faye Holt, Jonas Chan, Stephanie Richter, Lelia Glass, Aaron Steven White

With the goal of supporting scalable lexical semantic annotation, analysis,
and theorizing, we conduct a comprehensive evaluation of different methods for
generating event descriptions under both syntactic constraints -- e.g. desired
clause structure -- and semantic constraints -- e.g. desired verb sense. We
compare three different methods -- (i) manual generation by experts; (ii)
sampling from a corpus annotated for syntactic and semantic information; and
(iii) sampling from a language model (LM) conditioned on syntactic and semantic
information -- along three dimensions of the generated event descriptions: (a)
naturalness, (b) typicality, and (c) distinctiveness. We find that all methods
reliably produce natural, typical, and distinctive event descriptions, but that
manual generation continues to produce event descriptions that are more
natural, typical, and distinctive than the automated generation methods. We
conclude that the automated methods we consider produce event descriptions of
sufficient quality for use in downstream annotation and analysis insofar as the
methods used for this annotation and analysis are robust to a small amount of
degradation in the resulting event descriptions.

摘要：为了支持可扩展的词汇语义注释、分析和理论化，我们对在语法限制（例如所需的从句结构）和语义限制（例如所需的动词意义）下生成事件描述的不同方法进行了全面评估。我们比较了三种不同的方法——（i）专家手动生成；（ii）从为句法和语义信息注释的语料库中抽样；（iii）从以句法和语义信息为条件的语言模型（LM）中抽样——沿着生成事件描述的三个维度：（a）自然性、（b）典型性，和（c）独特性。我们发现所有方法都能可靠地生成自然、典型和独特的事件描述，但手动生成持续生成比自动化生成方法更自然、更典型和更独特的事件描述。我们得出结论，我们考虑的自动化方法产生的事件描述质量足以用于下游注释和分析，只要用于此注释和分析的方法对生成的事件描述中少量的退化具有鲁棒性。

##### **How "Real" is Your Real-Time Simultaneous Speech-to-Text Translation System?**
2412.18495v1 by Sara Papi, Peter Polak, Ondřej Bojar, Dominik Macháček

Simultaneous speech-to-text translation (SimulST) translates source-language
speech into target-language text concurrently with the speaker's speech,
ensuring low latency for better user comprehension. Despite its intended
application to unbounded speech, most research has focused on human
pre-segmented speech, simplifying the task and overlooking significant
challenges. This narrow focus, coupled with widespread terminological
inconsistencies, is limiting the applicability of research outcomes to
real-world applications, ultimately hindering progress in the field. Our
extensive literature review of 110 papers not only reveals these critical
issues in current research but also serves as the foundation for our key
contributions. We 1) define the steps and core components of a SimulST system,
proposing a standardized terminology and taxonomy; 2) conduct a thorough
analysis of community trends, and 3) offer concrete recommendations and future
directions to bridge the gaps in existing literature, from evaluation
frameworks to system architectures, for advancing the field towards more
realistic and effective SimulST solutions.

摘要：同聲傳譯（SimulST）在講者說話的同時，將源語言的語音轉換為目標語言的文字，確保低延遲以利使用者更佳地理解。儘管其預期應用於無限制的語音，但多數研究都專注於人類預先分段的語音，簡化了任務並忽略了重要的挑戰。這種狹隘的焦點，加上廣泛的術語不一致，限制了研究成果在現實世界中的應用，最終阻礙了該領域的進展。我們對 110 篇論文進行的廣泛文獻回顧，不僅揭示了當前研究中的這些關鍵問題，也作為我們關鍵貢獻的基礎。我們 1) 定義 SimulST 系統的步驟和核心組成部分，提出標準化術語和分類法；2) 徹底分析社群趨勢，以及 3) 提供具體建議和未來方向，以彌合現有文獻中的差距，從評估架構到系統架構，以推動該領域朝向更實際且有效的 SimulST 解決方案。

##### **An Overview and Discussion of the Suitability of Existing Speech Datasets to Train Machine Learning Models for Collective Problem Solving**
2412.18489v1 by Gnaneswar Villuri, Alex Doboli

This report characterized the suitability of existing datasets for devising
new Machine Learning models, decision making methods, and analysis algorithms
to improve Collaborative Problem Solving and then enumerated requirements for
future datasets to be devised. Problem solving was assumed to be performed in
teams of about three, four members, which talked to each other. A dataset
consists of the speech recordings of such teams. The characterization
methodology was based on metrics that capture cognitive, social, and emotional
activities and situations. The report presented the analysis of a large group
of datasets developed for Spoken Language Understanding, a research area with
some similarity to Collaborative Problem Solving.

摘要：本報告描述了現有資料集的適用性，用於設計新的機器學習模型、決策方法和分析演算法，以改善協作問題解決，然後列舉了未來資料集設計的要求。問題解決被假設為由約三到四名成員組成的團隊執行，這些成員會彼此交談。資料集包含這些團隊的語音記錄。描述方法基於捕捉認知、社會和情緒活動和情境的指標。報告提出了對一組大型資料集的分析，這些資料集是為語音語言理解而開發的，這是一個與協作問題解決有些類似的研究領域。

##### **Segment-Based Attention Masking for GPTs**
2412.18487v1 by Shahar Katz, Liran Ringel, Yaniv Romano, Lior Wolf

Modern Language Models (LMs) owe much of their success to masked causal
attention, the backbone of Generative Pre-Trained Transformer (GPT) models.
Although GPTs can process the entire user prompt at once, the causal masking is
applied to all input tokens step-by-step, mimicking the generation process.
This imposes an unnecessary constraint during the initial "prefill" phase when
the model processes the input prompt and generates the internal representations
before producing any output tokens. In this work, attention is masked based on
the known block structure at the prefill phase, followed by the conventional
token-by-token autoregressive process after that. For example, in a typical
chat prompt, the system prompt is treated as one block, and the user prompt as
the next one. Each of these is treated as a unit for the purpose of masking,
such that the first tokens in each block can access the subsequent tokens in a
non-causal manner. Then, the model answer is generated in the conventional
causal manner. This Segment-by-Segment scheme entails no additional
computational overhead. When integrating it into models such as Llama and Qwen,
state-of-the-art performance is consistently achieved.

摘要：現代語言模型 (LM) 的成功在很大程度上歸功於遮蔽式因果注意力，這是生成式預訓練Transformer (GPT) 模型的骨幹。
儘管 GPT 可以一次處理整個使用者提示，但因果遮蔽會逐步應用於所有輸入標記，模擬產生過程。
當模型處理輸入提示並在產生任何輸出標記之前產生內部表示時，這會在初始「預填」階段施加不必要的約束。在這項工作中，注意力會根據預填階段已知的區塊結構進行遮蔽，然後再進行傳統的逐一標記自迴歸過程。例如，在典型的聊天提示中，系統提示被視為一個區塊，而使用者提示被視為下一個區塊。這些中的每一個都被視為遮蔽目的的單位，使得每個區塊中的第一個標記可以非因果方式存取後續標記。然後，模型答案會以傳統的因果方式產生。這種逐段架構不需要額外的運算開銷。當將其整合到 Llama 和 Qwen 等模型中時，始終能達到最先進的效能。

##### **MotifGPL: Motif-Enhanced Graph Prototype Learning for Deciphering Urban Social Segregation**
2412.18464v1 by Tengfei He, Xiao Zhou

Social segregation in cities, spanning racial, residential, and income
dimensions, is becoming more diverse and severe. As urban spaces and social
relations grow more complex, residents in metropolitan areas experience varying
levels of social segregation. If left unaddressed, this could lead to increased
crime rates, heightened social tensions, and other serious issues. Effectively
quantifying and analyzing the structures within urban spaces and resident
interactions is crucial for addressing segregation. Previous studies have
mainly focused on surface-level indicators of urban segregation, lacking
comprehensive analyses of urban structure and mobility. This limitation fails
to capture the full complexity of segregation. To address this gap, we propose
a framework named Motif-Enhanced Graph Prototype Learning (MotifGPL),which
consists of three key modules: prototype-based graph structure extraction,
motif distribution discovery, and urban graph structure reconstruction.
Specifically, we use graph structure prototype learning to extract key
prototypes from both the urban spatial graph and the origin-destination graph,
incorporating key urban attributes such as points of interest, street view
images, and flow indices. To enhance interpretability, the motif distribution
discovery module matches each prototype with similar motifs, representing
simpler graph structures reflecting local patterns. Finally, we use the motif
distribution results to guide the reconstruction of the two graphs. This model
enables a detailed exploration of urban spatial structures and resident
mobility patterns, helping identify and analyze motif patterns that influence
urban segregation, guiding the reconstruction of urban graph structures.
Experimental results demonstrate that MotifGPL effectively reveals the key
motifs affecting urban social segregation and offer robust guidance for
mitigating this issue.

摘要：<paragraph>城市中的社會隔離，跨越種族、居住和收入層面，正變得更加多元且嚴重。隨著城市空間和社會關係日益複雜，大都會地區的居民經歷著不同程度的社會隔離。如果不加以解決，這可能會導致犯罪率上升、社會緊張加劇以及其他嚴重問題。有效量化和分析城市空間內部的結構和居民互動對於解決隔離至關重要。先前的研究主要集中於城市隔離的表面指標，缺乏對城市結構和流動性的全面分析。這種限制未能捕捉到隔離的全部複雜性。為了解決這一差距，我們提出了一個名為 Motif 增強圖原型學習 (MotifGPL) 的框架，它包含三個關鍵模組：基於原型的圖結構提取、主題分佈發現和城市圖結構重建。具體來說，我們使用圖結構原型學習從城市空間圖和起點目的地圖中提取關鍵原型，並整合了關鍵的城市屬性，例如興趣點、街景圖像和流動指數。為了增強可解釋性，主題分佈發現模組將每個原型與相似的主題進行匹配，表示反映局部模式的更簡單的圖結構。最後，我們使用主題分佈結果來指導兩個圖的重建。這個模型可以詳細探索城市空間結構和居民流動模式，有助於識別和分析影響城市隔離的主題模式，指導城市圖結構的重建。實驗結果表明，MotifGPL 有效地揭示了影響城市社會隔離的關鍵主題，並為緩解這一問題提供了強有力的指導。</paragraph>

##### **GeFL: Model-Agnostic Federated Learning with Generative Models**
2412.18460v1 by Honggu Kang, Seohyeon Cha, Joonhyuk Kang

Federated learning (FL) is a promising paradigm in distributed learning while
preserving the privacy of users. However, the increasing size of recent models
makes it unaffordable for a few users to encompass the model. It leads the
users to adopt heterogeneous models based on their diverse computing
capabilities and network bandwidth. Correspondingly, FL with heterogeneous
models should be addressed, given that FL typically involves training a single
global model. In this paper, we propose Generative Model-Aided Federated
Learning (GeFL), incorporating a generative model that aggregates global
knowledge across users of heterogeneous models. Our experiments on various
classification tasks demonstrate notable performance improvements of GeFL
compared to baselines, as well as limitations in terms of privacy and
scalability. To tackle these concerns, we introduce a novel framework, GeFL-F.
It trains target networks aided by feature-generative models. We empirically
demonstrate the consistent performance gains of GeFL-F, while demonstrating
better privacy preservation and robustness to a large number of clients. Codes
are available at [1].

摘要：聯盟學習 (FL) 是分布式學習中的一個有前途的範例，同時保護使用者的隱私。然而，近期模型的尺寸越來越大，使得少數使用者無法涵蓋模型。這導致使用者採用基於其不同的運算能力和網路頻寬的異質模型。相應地，應該解決具有異質模型的 FL，因為 FL 通常涉及訓練單一的全域模型。在本文中，我們提出生成模型輔助聯盟學習 (GeFL)，它結合了一個生成模型，該模型彙總了異質模型使用者的全域知識。我們在各種分類任務上進行的實驗表明，與基線相比，GeFL 的效能有顯著的提升，以及在隱私和可擴充性方面的限制。為了解決這些問題，我們引入了一個新的架構 GeFL-F。它訓練目標網路，並輔以特徵生成模型。我們經驗性地證明了 GeFL-F 的效能持續提升，同時證明了更好的隱私保護和對大量客戶的穩健性。程式碼可在 [1] 取得。

##### **Multi-Agent Norm Perception and Induction in Distributed Healthcare**
2412.18454v1 by Chao Li, Olga Petruchik, Elizaveta Grishanina, Sergey Kovalchuk

This paper presents a Multi-Agent Norm Perception and Induction Learning
Model aimed at facilitating the integration of autonomous agent systems into
distributed healthcare environments through dynamic interaction processes. The
nature of the medical norm system and its sharing channels necessitates
distinct approaches for Multi-Agent Systems to learn two types of norms.
Building on this foundation, the model enables agents to simultaneously learn
descriptive norms, which capture collective tendencies, and prescriptive norms,
which dictate ideal behaviors. Through parameterized mixed probability density
models and practice-enhanced Markov games, the multi-agent system perceives
descriptive norms in dynamic interactions and captures emergent prescriptive
norms. We conducted experiments using a dataset from a neurological medical
center spanning from 2016 to 2020.

摘要：本文提出了一個多主體規範感知與歸納學習模型，旨在透過動態互動程序促進自主主體系統整合到分散式醫療保健環境中。醫療規範系統的本質及其共享管道需要不同的方法，讓多主體系統學習兩種規範。基於此基礎，該模型讓主體能夠同時學習描述性規範（捕捉集體傾向）和規範性規範（規定理想行為）。透過參數化混合機率密度模型和實務增強馬可夫博弈，多主體系統在動態互動中感知描述性規範，並捕捉新興的規範性規範。我們使用 2016 年至 2020 年期間一個神經醫學醫療中心的数据集進行了實驗。

##### **Is Large Language Model Good at Triple Set Prediction? An Empirical Study**
2412.18443v1 by Yuan Yuan, Yajing Xu, Wen Zhang

The core of the Knowledge Graph Completion (KGC) task is to predict and
complete the missing relations or nodes in a KG. Common KGC tasks are mostly
about inferring unknown elements with one or two elements being known in a
triple. In comparison, the Triple Set Prediction (TSP) task is a more realistic
knowledge graph completion task. It aims to predict all elements of unknown
triples based on the information from known triples. In recent years, large
language models (LLMs) have exhibited significant advancements in language
comprehension, demonstrating considerable potential for KGC tasks. However, the
potential of LLM on the TSP task has not yet to be investigated. Thus in this
paper we proposed a new framework to explore the strengths and limitations of
LLM in the TSP task. Specifically, the framework consists of LLM-based rule
mining and LLM-based triple set prediction. The relation list of KG embedded
within rich semantic information is first leveraged to prompt LLM in the
generation of rules. This process is both efficient and independent of
statistical information, making it easier to mine effective and realistic
rules. For each subgraph, the specified rule is applied in conjunction with the
relevant triples within that subgraph to guide the LLM in predicting the
missing triples. Subsequently, the predictions from all subgraphs are
consolidated to derive the complete set of predicted triples on KG. Finally,
the method is evaluated on the relatively complete CFamily dataset. The
experimental results indicate that when LLMs are required to adhere to a large
amount of factual knowledge to predict missing triples, significant
hallucinations occurs, leading to a noticeable decline in performance. To
further explore the causes of this phenomenon, this paper presents a
comprehensive analysis supported by a detailed case study.

摘要：知識圖譜完成 (KGC) 任務的核心是預測和完成 KG 中遺失的關係或節點。常見的 KGC 任務大多是關於推論未知元素，其中一個或兩個元素在三元組中已知。相比之下，三元組集合預測 (TSP) 任務是一個更實際的知識圖譜完成任務。它旨在根據已知三元組中的資訊預測未知三元組的所有元素。近年來，大型語言模型 (LLM) 在語言理解方面表現出顯著的進步，顯示出 KGC 任務的巨大潛力。然而，LLM 在 TSP 任務上的潛力尚未得到探討。因此，在本文中，我們提出了一個新的框架來探索 LLM 在 TSP 任務中的優勢和局限性。具體來說，該框架包含基於 LLM 的規則挖掘和基於 LLM 的三元組集合預測。嵌入豐富語義資訊的 KG 關係清單首先被利用來提示 LLM 生成規則。這個過程既有效率又獨立於統計資訊，使得挖掘有效且實際的規則變得更容易。對於每個子圖，指定規則與該子圖中相關的三元組結合使用，以指導 LLM 預測遺失的三元組。隨後，合併所有子圖的預測，以推導 KG 上預測三元組的完整集合。最後，該方法在相對完整的 CFamily 資料集上進行評估。實驗結果表明，當要求 LLM 遵循大量事實知識來預測遺失的三元組時，會發生顯著的幻覺，導致效能顯著下降。為了進一步探討這種現象的原因，本文提出了由詳細案例研究支援的全面分析。

##### **Unlocking the Potential of Multiple BERT Models for Bangla Question Answering in NCTB Textbooks**
2412.18440v1 by Abdullah Khondoker, Enam Ahmed Taufik, Md Iftekhar Islam Tashik, S M Ishtiak mahmud, Antara Firoz Parsa

Evaluating text comprehension in educational settings is critical for
understanding student performance and improving curricular effectiveness. This
study investigates the capability of state-of-the-art language models-RoBERTa
Base, Bangla-BERT, and BERT Base-in automatically assessing Bangla
passage-based question-answering from the National Curriculum and Textbook
Board (NCTB) textbooks for classes 6-10. A dataset of approximately 3,000
Bangla passage-based question-answering instances was compiled, and the models
were evaluated using F1 Score and Exact Match (EM) metrics across various
hyperparameter configurations. Our findings revealed that Bangla-BERT
consistently outperformed the other models, achieving the highest F1 (0.75) and
EM (0.53) scores, particularly with smaller batch sizes, the inclusion of stop
words, and a moderate learning rate. In contrast, RoBERTa Base demonstrated the
weakest performance, with the lowest F1 (0.19) and EM (0.27) scores under
certain configurations. The results underscore the importance of fine-tuning
hyperparameters for optimizing model performance and highlight the potential of
machine learning models in evaluating text comprehension in educational
contexts. However, limitations such as dataset size, spelling inconsistencies,
and computational constraints emphasize the need for further research to
enhance the robustness and applicability of these models. This study lays the
groundwork for the future development of automated evaluation systems in
educational institutions, providing critical insights into model performance in
the context of Bangla text comprehension.

摘要：<paragraph>評估教育環境中的文本理解力對於了解學生表現和改善課程成效至關重要。本研究探討了最先進的語言模型 RoBERTa Base、Bangla-BERT 和 BERT Base 在自動評估國家課程和教科書委員會 (NCTB) 6-10 年級教科書中的孟加拉語段落式問答的能力。編制了一個包含大約 3,000 個孟加拉語段落式問答實例的資料集，並使用 F1 分數和完全匹配 (EM) 指標在各種超參數配置中評估模型。我們的研究結果顯示，Bangla-BERT 持續優於其他模型，獲得了最高的 F1（0.75）和 EM（0.53）分數，特別是在批次大小較小、包含停用詞和適度的學習率時。相比之下，RoBERTa Base 的表現最差，在某些配置下獲得了最低的 F1（0.19）和 EM（0.27）分數。這些結果強調了微調超參數以最佳化模型效能的重要性，並突顯了機器學習模型在評估教育環境中的文本理解力的潛力。然而，資料集大小、拼寫不一致和計算限制等限制強調了進一步研究以增強這些模型的穩健性和適用性的必要性。本研究為教育機構中自動化評估系統的未來發展奠定了基礎，提供了孟加拉語文本理解語境中模型效能的重要見解。</paragraph>

##### **Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent**
2412.18428v1 by Farhad Nooralahzadeh, Yi Zhang, Jonathan Furst, Kurt Stockinger

International enterprises, organizations, or hospitals collect large amounts
of multi-modal data stored in databases, text documents, images, and videos.
While there has been recent progress in the separate fields of multi-modal data
exploration as well as in database systems that automatically translate natural
language questions to database query languages, the research challenge of
querying database systems combined with other unstructured modalities such as
images in natural language is widely unexplored.
  In this paper, we propose XMODE - a system that enables explainable,
multi-modal data exploration in natural language. Our approach is based on the
following research contributions: (1) Our system is inspired by a real-world
use case that enables users to explore multi-modal information systems. (2)
XMODE leverages a LLM-based agentic AI framework to decompose a natural
language question into subtasks such as text-to-SQL generation and image
analysis. (3) Experimental results on multi-modal datasets over relational data
and images demonstrate that our system outperforms state-of-the-art multi-modal
exploration systems, excelling not only in accuracy but also in various
performance metrics such as query latency, API costs, planning efficiency, and
explanation quality, thanks to the more effective utilization of the reasoning
capabilities of LLMs.

摘要：國際企業、組織或醫院收集大量儲存在資料庫、文字文件、圖片和影片中的多模態資料。雖然多模態資料探勘的獨立領域以及自動將自然語言問題轉換成資料庫查詢語言的資料庫系統最近已有進展，但結合其他非結構化模態（例如圖片）以自然語言查詢資料庫系統的研究挑戰仍鮮少探討。在此篇論文中，我們提出 XMODE，一個能使用自然語言進行可解釋多模態資料探勘的系統。我們的做法基於以下研究貢獻：(1) 我們的系統靈感來自一個能讓使用者探索多模態資訊系統的真實世界使用案例。(2) XMODE 利用一個基於 LLM 的代理 AI 架構，將自然語言問題分解成文字轉 SQL 產生和圖片分析等子任務。(3) 在關聯資料和圖片的多模態資料集上的實驗結果顯示，我們的系統優於最先進的多模態探勘系統，不僅在準確度上表現出色，在各種效能指標（例如查詢延遲、API 成本、規劃效率和說明品質）上也表現出色，這要歸功於更有效地利用 LLM 的推理能力。

##### **GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent**
2412.18426v1 by Kangjia Zhao, Jiahui Song, Leigang Sha, Haozhan Shen, Zhi Chen, Tiancheng Zhao, Xiubo Liang, Jianwei Yin

Nowadays, research on GUI agents is a hot topic in the AI community. However,
current research focuses on GUI task automation, limiting the scope of
applications in various GUI scenarios. In this paper, we propose a formalized
and comprehensive environment to evaluate the entire process of automated GUI
Testing (GTArena), offering a fair, standardized environment for consistent
operation of diverse multimodal large language models. We divide the testing
process into three key subtasks: test intention generation, test task
execution, and GUI defect detection, and construct a benchmark dataset based on
these to conduct a comprehensive evaluation. It evaluates the performance of
different models using three data types: real mobile applications, mobile
applications with artificially injected defects, and synthetic data, thoroughly
assessing their capabilities in this relevant task. Additionally, we propose a
method that helps researchers explore the correlation between the performance
of multimodal language large models in specific scenarios and their general
capabilities in standard benchmark tests. Experimental results indicate that
even the most advanced models struggle to perform well across all sub-tasks of
automated GUI Testing, highlighting a significant gap between the current
capabilities of Autonomous GUI Testing and its practical, real-world
applicability. This gap provides guidance for the future direction of GUI Agent
development. Our code is available at
https://github.com/ZJU-ACES-ISE/ChatUITest.

摘要：當今，GUI 代理的研究是 AI 社群中的熱門話題。然而，目前的
研究專注於 GUI 任務自動化，限制了在各種 GUI 場景中的應用範圍。在本文中，我們提出一個形式化且全面的環境來評估自動化 GUI
測試的整個過程 (GTArena)，為不同多模態大型語言模型的一致操作提供一個公平、標準化的環境。我們將測試過程分為三個關鍵的子任務：測試意圖產生、測試任務執行和 GUI 缺陷偵測，並根據這些任務建構一個基準資料集來進行全面的評估。它使用三種類型的資料來評估不同模型的效能：真實的行動應用程式、人工注入缺陷的行動應用程式，以及合成資料，徹底評估它們在這個相關任務中的能力。此外，我們提出一個方法，幫助研究人員探索特定場景中多模態大型語言模型的效能與其在標準基準測試中的整體能力之間的關聯性。實驗結果表明，即使是最先進的模型也很難在自動化 GUI 測試的所有子任務中表現良好，這突顯了當前自動化 GUI 測試的能力與其實際的真實世界適用性之間的顯著差距。這個差距為 GUI 代理開發的未來方向提供了指導。我們的程式碼可在
https://github.com/ZJU-ACES-ISE/ChatUITest 取得。

##### **LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating**
2412.18424v1 by Chao Deng, Jiale Yuan, Pi Bu, Peijie Wang, Zhong-Zhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, Cheng-Lin Liu

Large vision language models (LVLMs) have improved the document understanding
capabilities remarkably, enabling the handling of complex document elements,
longer contexts, and a wider range of tasks. However, existing document
understanding benchmarks have been limited to handling only a small number of
pages and fail to provide a comprehensive analysis of layout elements locating.
In this paper, we first define three primary task categories: Long Document
Understanding, numerical Reasoning, and cross-element Locating, and then
propose a comprehensive benchmark, LongDocURL, integrating above three primary
tasks and comprising 20 sub-tasks categorized based on different primary tasks
and answer evidences. Furthermore, we develop a semi-automated construction
pipeline and collect 2,325 high-quality question-answering pairs, covering more
than 33,000 pages of documents, significantly outperforming existing
benchmarks. Subsequently, we conduct comprehensive evaluation experiments on
both open-source and closed-source models across 26 different configurations,
revealing critical performance gaps in this field.

摘要：大型視覺語言模型 (LVLMs) 已顯著提升文件理解能力，能處理複雜的文件元素、較長的脈絡以及更廣泛的任務。然而，現有的文件理解基準僅限於處理少數頁面，且無法提供版面元素定位的全面分析。在本文中，我們首先定義三個主要的任務類別：長文件理解、數字推理和跨元素定位，然後提出一個全面的基準 LongDocURL，整合上述三個主要任務並包含 20 個子任務，根據不同的主要任務和答案證據進行分類。此外，我們開發了一個半自動化建構管道，並收集了 2,325 個高品質問答對，涵蓋超過 33,000 頁的文件，大幅優於現有的基準。隨後，我們對 26 種不同配置的開源和閉源模型進行全面的評估實驗，揭露了此領域的關鍵效能差距。

##### **Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**
2412.18419v1 by Zihan Zhou, Ziyi Zeng, Wenhao Jiang, Yihui Zhu, Jiaxin Mao, Yonggui Yuan, Min Xia, Shubin Zhao, Mengyu Yao, Yunqian Chen

As social changes accelerate, the incidence of psychosomatic disorders has
significantly increased, becoming a major challenge in global health issues.
This necessitates an innovative knowledge system and analytical methods to aid
in diagnosis and treatment. Here, we establish the ontology model and entity
types, using the BERT model and LoRA-tuned LLM for named entity recognition,
constructing the knowledge graph with 9668 triples. Next, by analyzing the
network distances between disease, symptom, and drug modules, it was found that
closer network distances among diseases can predict greater similarities in
their clinical manifestations, treatment approaches, and psychological
mechanisms, and closer distances between symptoms indicate that they are more
likely to co-occur. Lastly, by comparing the proximity d and proximity z score,
it was shown that symptom-disease pairs in primary diagnostic relationships
have a stronger association and are of higher referential value than those in
diagnostic relationships. The research results revealed the potential
connections between diseases, co-occurring symptoms, and similarities in
treatment strategies, providing new perspectives for the diagnosis and
treatment of psychosomatic disorders and valuable information for future mental
health research and practice.

摘要：隨著社會變遷加速，心身疾病發生率顯著增加，成為全球衛生議題上的重大挑戰。這需要創新的知識體系與分析方法，以協助診斷與治療。在此，我們建立了本体模型與實體類型，利用 BERT 模型與 LoRA 調校過的 LLM 進行命名實體辨識，建構出 9668 個三元組的知識圖譜。接著，透過分析疾病、症狀、藥物模組間的網路距離，發現疾病間較近的網路距離，可預測其臨床表現、治療方式、心理機轉的相似性較高；而症狀間距離較近，則表示較可能共現。最後，透過比較接近度 d 與接近度 z 分數，發現初次診斷關係中的症狀-疾病對，其關聯性較強、參考價值較高，優於診斷關係中的症狀-疾病對。研究成果揭示了疾病、共現症狀、治療策略間的潛在關聯，為心身疾病的診斷與治療提供了新的觀點，也為未來心理健康研究與實務提供了寶貴的資訊。

##### **Multilingual Mathematical Reasoning: Advancing Open-Source LLMs in Hindi and English**
2412.18415v1 by Avinash Anand, Kritarth Prasad, Chhavi Kirtani, Ashwin R Nair, Manvendra Kumar Nema, Raj Jaiswal, Rajiv Ratn Shah

Large Language Models (LLMs) excel in linguistic tasks but struggle with
mathematical reasoning, particularly in non English languages like Hindi. This
research aims to enhance the mathematical reasoning skills of smaller, resource
efficient open-source LLMs in both Hindi and English. We evaluate models like
OpenHathi 7B, LLaMA-2 7B, WizardMath 7B, Mistral 7B, LLeMMa 7B, MAmmoTH 7B,
Gemini Pro, and GPT-4 using zero-shot, few-shot chain-of-thought (CoT) methods,
and supervised fine-tuning. Our approach incorporates curriculum learning,
progressively training models on increasingly difficult problems, a novel
Decomposition Strategy to simplify complex arithmetic operations, and a
Structured Solution Design that divides solutions into phases. Our experiments
result in notable performance enhancements. WizardMath 7B exceeds Gemini's
accuracy on English datasets by +6% and matches Gemini's performance on Hindi
datasets. Adopting a bilingual approach that combines English and Hindi samples
achieves results comparable to individual language models, demonstrating the
capability to learn mathematical reasoning in both languages. This research
highlights the potential for improving mathematical reasoning in open-source
LLMs.

摘要：大型語言模型 (LLM) 在語言任務中表現出色，但在數學推理方面卻有困難，特別是在印地語等非英語語言中。這項研究旨在增強印地語和英語中較小、資源效率高的開源 LLM 的數學推理技能。我們使用零次、少次思考鏈 (CoT) 方法和監督微調來評估 OpenHathi 7B、LLaMA-2 7B、WizardMath 7B、Mistral 7B、LLeMMa 7B、MAmmoTH 7B、Gemini Pro 和 GPT-4 等模型。我們的做法結合了課程學習，逐漸訓練模型來解決越來越困難的問題，一種簡化複雜算術運算的新分解策略，以及將解法分為階段的結構化解法設計。我們的實驗產生了顯著的效能提升。WizardMath 7B 在英語資料集上的準確率比 Gemini 高出 +6%，並在印地語資料集上與 Gemini 的效能相匹配。採用結合英語和印地語範例的雙語方法，取得了與個別語言模型相當的結果，證明了學習兩種語言中數學推理的能力。這項研究突出了改善開源 LLM 中數學推理的潛力。

##### **Exploring Flexible Scenario Generation in Godot Simulator**
2412.18408v1 by Daniel Peraltai, Xin Qin

Cyber-physical systems (CPS) combine cyber and physical components engineered
to make decisions and interact within dynamic environments. Ensuring the safety
of CPS is of great importance, requiring extensive testing across diverse and
complex scenarios. To generate as many testing scenarios as possible, previous
efforts have focused on describing scenarios using formal languages to generate
scenes. In this paper, we introduce an alternative approach: reconstructing
scenes inside the open-source game engine, Godot. We have developed a pipeline
that enables the reconstruction of testing scenes directly from provided images
of scenarios. These reconstructed scenes can then be deployed within simulated
environments to assess a CPS. This approach offers a scalable and flexible
solution for testing CPS in realistic environments.

摘要：網路物理系統（CPS）結合網路和物理元件，旨在做出決策並在動態環境中進行互動。確保 CPS 的安全性非常重要，需要在多樣且複雜的場景中進行廣泛測試。為了產生儘可能多的測試場景，先前的努力著重於使用形式語言描述場景以產生場景。在本文中，我們介紹一種替代方法：在開源遊戲引擎 Godot 中重建場景。我們開發了一個管道，可以根據提供的場景影像直接重建測試場景。然後，這些重建的場景可以在模擬環境中部署，以評估 CPS。此方法提供了一個可擴充且靈活的解決方案，用於在真實環境中測試 CPS。

##### **A Statistical Framework for Ranking LLM-Based Chatbots**
2412.18407v1 by Siavash Ameli, Siyuan Zhuang, Ion Stoica, Michael W. Mahoney

Large language models (LLMs) have transformed natural language processing,
with frameworks like Chatbot Arena providing pioneering platforms for
evaluating these models. By facilitating millions of pairwise comparisons based
on human judgments, Chatbot Arena has become a cornerstone in LLM evaluation,
offering rich datasets for ranking models in open-ended conversational tasks.
Building upon this foundation, we propose a statistical framework that
incorporates key advancements to address specific challenges in pairwise
comparison analysis. First, we introduce a factored tie model that enhances the
ability to handle ties -- an integral aspect of human-judged comparisons --
significantly improving the model's fit to observed data. Second, we extend the
framework to model covariance between competitors, enabling deeper insights
into performance relationships and facilitating intuitive groupings into
performance tiers. Third, we resolve optimization challenges arising from
parameter non-uniqueness by introducing novel constraints, ensuring stable and
interpretable parameter estimation. Through rigorous evaluation and extensive
experimentation, our framework demonstrates substantial improvements over
existing methods in modeling pairwise comparison data. To support
reproducibility and practical adoption, we release leaderbot, an open-source
Python package implementing our models and analyses.

摘要：大型語言模型（LLM）已經轉變了自然語言處理，
像 Chatbot Arena 這樣的架構提供了開創性的平台來評估這些模型。透過協助基於人類判斷的數百萬成對比較，Chatbot Arena 已成為 LLM 評估的基石，提供豐富的資料集來對開放式對話任務中的模型進行排名。在此基礎上，我們提出了一個統計框架，其中包含了關鍵進展，以應對成對比較分析中的特定挑戰。首先，我們引入了一個分解的平手模型，它增強了處理平手（人類判斷比較的一個組成部分）的能力，顯著改善了模型對觀察到的資料的擬合度。其次，我們擴展了框架來對競爭者之間的協方差進行建模，從而深入了解績效關係，並促進直觀地將其分組為績效層級。第三，我們透過引入新的約束來解決由參數非唯一性產生的最佳化挑戰，確保參數估計的穩定性和可解釋性。透過嚴謹的評估和廣泛的實驗，我們的框架證明了在對成對比較資料建模方面，比現有方法有顯著的改進。為了支援可複製性和實際採用，我們發布了 leaderbot，這是一個開源的 Python 套件，用於實作我們的模型和分析。

##### **TPAoI: Ensuring Fresh Service Status at the Network Edge in Compute-First Networking**
2412.18391v1 by Haosheng He, Jianpeng Qi, Chao Liu, Junyu Dong, Yanwei Yu

In compute-first networking, maintaining fresh and accurate status
information at the network edge is crucial for effective access to remote
services. This process typically involves three phases: Status updating, user
accessing, and user requesting. However, current studies on status
effectiveness, such as Age of Information at Query (QAoI), do not
comprehensively cover all these phases. Therefore, this paper introduces a
novel metric, TPAoI, aimed at optimizing update decisions by measuring the
freshness of service status. The stochastic nature of edge environments,
characterized by unpredictable communication delays in updating, requesting,
and user access times, poses a significant challenge when modeling. To address
this, we model the problem as a Markov Decision Process (MDP) and employ a
Dueling Double Deep Q-Network (D3QN) algorithm for optimization. Extensive
experiments demonstrate that the proposed TPAoI metric effectively minimizes
AoI, ensuring timely and reliable service updates in dynamic edge environments.
Results indicate that TPAoI reduces AoI by an average of 47\% compared to QAoI
metrics and decreases update frequency by an average of 48\% relative to
conventional AoI metrics, showing significant improvement.

摘要：在計算優先網路中，在網路邊緣維護最新且準確的狀態資訊對於有效存取遠端服務至關重要。此程序通常包含三個階段：狀態更新、使用者存取和使用者要求。但是，目前關於狀態有效性的研究，例如查詢資訊年齡（QAoI），並未全面涵蓋所有這些階段。因此，本文介紹了一種新的指標 TPAoI，旨在透過衡量服務狀態的新鮮度來最佳化更新決策。邊緣環境的隨機性質，其特徵是在更新、要求和使用者存取時間中具有不可預測的通訊延遲，在建模時會構成重大挑戰。為了解決這個問題，我們將問題建模為馬可夫決策過程（MDP），並採用決鬥雙深度 Q 網路（D3QN）演算法進行最佳化。廣泛的實驗證明，所提出的 TPAoI 指標可有效最小化 AoI，確保在動態邊緣環境中及時且可靠的服務更新。結果表明，與 QAoI 指標相比，TPAoI 將 AoI 降低了平均 47%，並且與傳統 AoI 指標相比，將更新頻率降低了平均 48%，顯示出顯著的改善。

##### **RDPM: Solve Diffusion Probabilistic Models via Recurrent Token Prediction**
2412.18390v1 by Wu Xiaoping, Hu Jie, Wei Xiaoming

Diffusion Probabilistic Models (DPMs) have emerged as the de facto approach
for high-fidelity image synthesis, operating diffusion processes on continuous
VAE latent, which significantly differ from the text generation methods
employed by Large Language Models (LLMs). In this paper, we introduce a novel
generative framework, the Recurrent Diffusion Probabilistic Model (RDPM), which
enhances the diffusion process through a recurrent token prediction mechanism,
thereby pioneering the field of Discrete Diffusion. By progressively
introducing Gaussian noise into the latent representations of images and
encoding them into vector-quantized tokens in a recurrent manner, RDPM
facilitates a unique diffusion process on discrete-value domains. This process
iteratively predicts the token codes for subsequent timesteps, transforming the
initial standard Gaussian noise into the source data distribution, aligning
with GPT-style models in terms of the loss function. RDPM demonstrates superior
performance while benefiting from the speed advantage of requiring only a few
inference steps. This model not only leverages the diffusion process to ensure
high-quality generation but also converts continuous signals into a series of
high-fidelity discrete tokens, thereby maintaining a unified optimization
strategy with other discrete tokens, such as text. We anticipate that this work
will contribute to the development of a unified model for multimodal
generation, specifically by integrating continuous signal domains such as
images, videos, and audio with text. We will release the code and model weights
to the open-source community.

摘要：擴散機率模型 (DPM) 已經成為高保真影像合成的實際方法，在連續 VAE 潛在變數上操作擴散程序，這與大型語言模型 (LLM) 所採用的文字生成方法有顯著差異。在本文中，我們介紹了一個新穎的生成架構，稱為遞迴擴散機率模型 (RDPM)，它透過遞迴符號預測機制增強擴散程序，從而開創了離散擴散領域。透過逐步將高斯雜訊引入影像的潛在表示中，並以遞迴方式將其編碼為向量量化的符號，RDPM 在離散值域上促進了獨特的擴散程序。此程序會反覆預測後續時間步長的符號碼，將初始的標準高斯雜訊轉換為來源資料分佈，在損失函數方面與 GPT 類型的模型對齊。RDPM 展現出優異的效能，同時受益於僅需要幾個推論步驟的速度優勢。此模型不僅利用擴散程序確保高品質的生成，還將連續訊號轉換為一系列高保真離散符號，從而與其他離散符號（例如文字）保持統一的最佳化策略。我們預期這項工作將有助於開發多模態生成的統一模型，特別是透過將影像、影片和音訊等連續訊號域與文字整合在一起。我們將向開源社群釋出程式碼和模型權重。

##### **Weak Scaling Capability in Token Space: An Observation from Large Vision Language Model**
2412.18387v1 by Tenghui Li, Guoxu Zhou, Xuyang Zhao, Qibin Zhao

The scaling capability has been widely validated with respect to the number
of parameters and the size of training data. One important question that is
unexplored is that does scaling capability also exists similarly with respect
to the number of vision tokens? This study fills the gap by investigating the
relationship between the number of vision tokens and the performance of
vision-language models. Our theoretical analysis and empirical evaluations
reveal that the model exhibits weak scaling capabilities on the length \(N_l\),
with performance approximately \(S(N_l) \approx (c/N_l)^{\alpha}\), where \(c,
\alpha\) are hyperparameters. Interestingly, this scaling behavior remains
largely unaffected by the inclusion or exclusion of the user's question in the
input. Furthermore, fusing the user's question with the vision token can
enhance model performance when the question is relevant to the task. To address
the computational challenges associated with large-scale vision tokens, we
propose a novel architecture that efficiently reduces the token count while
integrating user question tokens into the representation. Our findings may
offer insights for developing more efficient and effective vision-language
models under specific task constraints.

摘要：在参数数量和训练数据大小方面，缩放能力已经得到广泛验证。一个尚未探索的重要问题是，缩放能力是否在视觉标记数量方面也类似存在？本研究通过调查视觉标记数量与视觉语言模型性能之间的关系来填补这一空白。我们的理论分析和实证评估表明，该模型在长度 \(N_l\) 上表现出较弱的缩放能力，性能约为 \(S(N_l) \approx (c/N_l)^{\alpha}\)，其中 \(c, \alpha\) 是超参数。有趣的是，这种缩放行为在很大程度上不受输入中是否包含用户问题的影响。此外，当问题与任务相关时，将用户问题与视觉标记融合可以提高模型性能。为了解决与大规模视觉标记相关的计算挑战，我们提出了一种新颖的架构，该架构在将用户问题标记集成到表示中时有效地减少了标记计数。我们的发现可能会为在特定任务约束下开发更有效率和更有效的视觉语言模型提供见解。

##### **ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots**
2412.18377v1 by Shani Goren, Oren Kalinsky, Tomer Stav, Yuri Rapoport, Yaron Fairstein, Ram Yazdy, Nachshon Cohen, Alexander Libov, Guy Kushilevitz

The rise of LLMs has deflected a growing portion of human-computer
interactions towards LLM-based chatbots. The remarkable abilities of these
models allow users to interact using long, diverse natural language text
covering a wide range of topics and styles. Phrasing these messages is a time
and effort consuming task, calling for an autocomplete solution to assist
users. We introduce the task of chatbot interaction autocomplete. We present
ChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework
for LLM-based chatbot interactions. The framework includes a formal definition
of the task, coupled with suitable datasets and metrics. We use the framework
to evaluate After formally defining the task along with suitable datasets and
metrics, we test 9 models on the defined auto completion task, finding that
while current off-the-shelf models perform fairly, there is still much room for
improvement, mainly in ranking of the generated suggestions. We provide
insights for practitioners working on this task and open new research
directions for researchers in the field. We release our framework to serve as a
foundation for future research.

摘要：大型語言模型的興起將越來越多的人機互動轉向基於大型語言模型的聊天機器人。這些模型的卓越能力讓使用者能夠使用涵蓋廣泛主題和風格的長篇、多樣化的自然語言文字進行互動。表述這些訊息是一項耗時且費力的任務，需要一個自動完成的解決方案來協助使用者。我們引入了聊天機器人互動自動完成的任務。我們提出 ChaI-TeA：聊天互動自動完成；一個基於大型語言模型的聊天機器人互動的自動完成評估架構。該架構包含任務的正式定義，並結合適當的資料集和指標。我們使用該架構在定義的自動完成任務上評估 9 個模型，發現雖然現成的模型表現得相當好，但仍有很大的改進空間，特別是在生成建議的排名上。我們為從事這項任務的實務工作者提供見解，並為該領域的研究人員開啟新的研究方向。我們發布我們的架構，作為未來研究的基礎。

##### **Bidirectional Topic Matching: Quantifying Thematic Overlap Between Corpora Through Topic Modelling**
2412.18376v1 by Raven Adam, Marie Lisa Kogler

This study introduces Bidirectional Topic Matching (BTM), a novel method for
cross-corpus topic modeling that quantifies thematic overlap and divergence
between corpora. BTM is a flexible framework that can incorporate various topic
modeling approaches, including BERTopic, Top2Vec, and Latent Dirichlet
Allocation (LDA). BTM employs a dual-model approach, training separate topic
models for each corpus and applying them reciprocally to enable comprehensive
cross-corpus comparisons. This methodology facilitates the identification of
shared themes and unique topics, providing nuanced insights into thematic
relationships. Validation against cosine similarity-based methods demonstrates
the robustness of BTM, with strong agreement metrics and distinct advantages in
handling outlier topics. A case study on climate news articles showcases BTM's
utility, revealing significant thematic overlaps and distinctions between
corpora focused on climate change and climate action. BTM's flexibility and
precision make it a valuable tool for diverse applications, from political
discourse analysis to interdisciplinary studies. By integrating shared and
unique topic analyses, BTM offers a comprehensive framework for exploring
thematic relationships, with potential extensions to multilingual and dynamic
datasets. This work highlights BTM's methodological contributions and its
capacity to advance discourse analysis across various domains.

摘要：本研究引入了雙向主題匹配 (BTM)，這是一種跨語料庫主題建模的新方法，用於量化語料庫之間的主題重疊和差異。BTM 是一個靈活的框架，可以整合各種主題建模方法，包括 BERTopic、Top2Vec 和潛在狄利克雷分配 (LDA)。BTM 採用雙模型方法，針對每個語料庫訓練單獨的主題模型，並將它們互惠地應用於全面跨語料庫比較。這種方法有助於識別共用主題和獨特主題，從而提供對主題關係的細微見解。針對基於餘弦相似性的方法進行驗證，證明了 BTM 的穩健性，具有很強的一致性指標，並且在處理異常值主題方面具有顯著優勢。關於氣候新聞文章的案例研究展示了 BTM 的效用，揭示了專注於氣候變化和氣候行動的語料庫之間顯著的主題重疊和區別。BTM 的靈活性與精確性使其成為各種應用程序的寶貴工具，從政治話語分析到跨學科研究。通過整合共用和獨特的主題分析，BTM 為探索主題關係提供了一個全面的框架，並可能擴展到多語言和動態數據集。這項工作突出了 BTM 的方法論貢獻及其在各個領域推進話語分析的能力。

##### **Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors**
2412.18370v1 by Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang

Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.

摘要：圖形神經網路 (GNN) 已成為一種有效的欺詐偵測工具，用於識別欺詐使用者並揭露惡意行為。然而，針對基於 GNN 的欺詐偵測器及其風險的攻擊鮮少受到研究，因此潛在威脅未獲得解決。最近的研究結果顯示，欺詐行為正日益以幫派或團體的方式組織起來。在這項研究中，我們設計了攻擊場景，其中欺詐幫派旨在透過共謀偽裝其非法活動，讓他們的欺詐節點被誤分類為良性。基於這些場景，我們透過模擬三起真實世界的欺詐案件（垃圾評論、假新聞和醫療保險欺詐）中欺詐幫派的攻擊，研究針對基於 GNN 的欺詐偵測器的對抗性攻擊。我們將這些攻擊定義為多目標圖形注入攻擊，並提出 MonTi，一種基於 Transformer 的多目標一次性圖形注入攻擊模型。MonTi 同時利用 Transformer 編碼器生成所有攻擊節點的屬性和邊緣，比大多數現有的圖形注入攻擊方法更有效地捕捉屬性和邊緣之間的相互依賴性，這些方法會依序生成這些元素。此外，與固定所有攻擊節點的度數預算的現有方法不同，MonTi 會自適應地分配每個攻擊節點的度數預算，以探索涉及目標、候選和攻擊節點的多樣化注入結構。實驗顯示，MonTi 在五個真實世界的圖形上優於最先進的圖形注入攻擊方法。

##### **Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset**
2412.18367v1 by Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona Diab

The field of machine translation has achieved significant advancements, yet
domain-specific terminology translation, particularly in AI, remains
challenging. We introduced GIST, a large-scale multilingual AI terminology
dataset containing 5K terms extracted from top AI conference papers spanning
2000 to 2023. The terms were translated into Arabic, Chinese, French, Japanese,
and Russian using a hybrid framework that combines LLMs for extraction with
human expertise for translation. The dataset's quality was benchmarked against
existing resources, demonstrating superior translation accuracy through
crowdsourced evaluation. GIST was integrated into translation workflows using
post-translation refinement methods that required no retraining, where LLM
prompting consistently improved BLEU and COMET scores. A web demonstration on
the ACL Anthology platform highlights its practical application, showcasing
improved accessibility for non-English speakers. This work aims to address
critical gaps in AI terminology resources and fosters global inclusivity and
collaboration in AI research.

摘要：機器翻譯領域已取得重大進展，然而，特定領域術語翻譯，特別是在 AI 中，仍然具有挑戰性。我們引入了 GIST，一個大型多語言 AI 術語資料集，其中包含從 2000 年到 2023 年頂尖 AI 會議論文中提取的 5K 個術語。這些術語使用結合 LLM 進行提取和人類專業知識進行翻譯的混合框架翻譯成阿拉伯語、中文、法語、日語和俄語。該資料集的品質根據現有資源進行基準測試，通過眾包評估證明了卓越的翻譯準確性。GIST 被整合到翻譯工作流程中，使用不需要重新訓練的翻譯後改進方法，其中 LLM 提示持續改善 BLEU 和 COMET 分數。在 ACL Anthology 平台上的網路展示突出了其實際應用，展示了對非英語人士的改進的可及性。這項工作旨在解決 AI 術語資源中的關鍵差距，並促進 AI 研究中的全球包容性和協作。

##### **Extracting triples from dialogues for conversational social agents**
2412.18364v1 by Piek Vossen, Selene Báez Santamaría, Lenka Bajčetić, Thomas Belluci

Obtaining an explicit understanding of communication within a Hybrid
Intelligence collaboration is essential to create controllable and transparent
agents. In this paper, we describe a number of Natural Language Understanding
models that extract explicit symbolic triples from social conversation. Triple
extraction has mostly been developed and tested for Knowledge Base Completion
using Wikipedia text and data for training and testing. However, social
conversation is very different as a genre in which interlocutors exchange
information in sequences of utterances that involve statements, questions, and
answers. Phenomena such as co-reference, ellipsis, coordination, and implicit
and explicit negation or confirmation are more prominent in conversation than
in Wikipedia text. We therefore describe an attempt to fill this gap by
releasing data sets for training and testing triple extraction from social
conversation. We also created five triple extraction models and tested them in
our evaluation data. The highest precision is 51.14 for complete triples and
69.32 for triple elements when tested on single utterances. However, scores for
conversational triples that span multiple turns are much lower, showing that
extracting knowledge from true conversational data is much more challenging.

摘要：在混合智能協作中取得對溝通的明確理解對於建立可控且透明的代理非常重要。在本文中，我們描述了許多自然語言理解模型，這些模型從社交對話中提取明確的符號三元組。三元組提取主要針對知識庫完成進行開發和測試，使用維基百科文字和數據進行訓練和測試。然而，社交對話作為一種體裁非常不同，其中對話者在涉及陳述、問題和答案的言論序列中交換信息。在對話中，共指、省略、協調以及隱含和明確的否定或確認等現象比在維基百科文字中更為突出。因此，我們描述了一項嘗試，通過發布用於訓練和測試從社交對話中提取三元組的數據集來填補這一空白。我們還創建了五個三元組提取模型，並在我們的評估數據中對它們進行了測試。在單個語句上進行測試時，完整三元組的最高精度為 51.14，三元組元素的最高精度為 69.32。然而，跨多個回合的對話三元組的分數要低得多，這表明從真正的對話數據中提取知識更具挑戰性。

##### **Addressing Spatial-Temporal Data Heterogeneity in Federated Continual Learning via Tail Anchor**
2412.18355v1 by Hao Yu, Xin Yang, Le Zhang, Hanlin Gu, Tianrui Li, Lixin Fan, Qiang Yang

Federated continual learning (FCL) allows each client to continually update
its knowledge from task streams, enhancing the applicability of federated
learning in real-world scenarios. However, FCL needs to address not only
spatial data heterogeneity between clients but also temporal data heterogeneity
between tasks. In this paper, empirical experiments demonstrate that such
input-level heterogeneity significantly affects the model's internal parameters
and outputs, leading to severe spatial-temporal catastrophic forgetting of
local and previous knowledge. To this end, we propose Federated Tail Anchor
(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust
their position in the feature space, thereby overcoming parameter-forgetting
and output-forgetting. Moreover, three novel components are also included in
FedTA: Input Enhancement for improving the performance of pre-trained models on
downstream tasks; Selective Input Knowledge Fusion for fusion of heterogeneous
local knowledge on the server side; and Best Global Prototype Selection for
finding the best anchor point for each class in the feature space. Extensive
experiments demonstrate that FedTA not only outperforms existing FCL methods
but also effectively preserves the relative positions of features, remaining
unaffected by spatial and temporal changes.

摘要：联邦持续学习 (FCL) 允许每个客户端持续从任务流更新其知识，从而增强联邦学习在真实世界场景中的适用性。然而，FCL 不仅需要解决客户端之间的空间数据异质性，还需要解决任务之间的时序数据异质性。本文中的实证实验表明，这种输入级异质性会显著影响模型的内部参数和输出，导致局部和先前知识的严重时空灾难性遗忘。为此，我们提出了联邦尾锚 (FedTA)，将可训练尾锚与冻结的输出特征混合，以调整它们在特征空间中的位置，从而克服参数遗忘和输出遗忘。此外，FedTA 中还包含三个新颖组件：用于提高预训练模型在下游任务上的性能的输入增强；用于在服务器端融合异构局部知识的选择性输入知识融合；以及用于在特征空间中为每个类别找到最佳锚点的最佳全局原型选择。大量的实验表明，FedTA 不仅优于现有的 FCL 方法，而且有效地保留了特征的相对位置，不受空间和时间变化的影响。

##### **The Thousand Brains Project: A New Paradigm for Sensorimotor Intelligence**
2412.18354v1 by Viviane Clay, Niels Leadholm, Jeff Hawkins

Artificial intelligence has advanced rapidly in the last decade, driven
primarily by progress in the scale of deep-learning systems. Despite these
advances, the creation of intelligent systems that can operate effectively in
diverse, real-world environments remains a significant challenge. In this white
paper, we outline the Thousand Brains Project, an ongoing research effort to
develop an alternative, complementary form of AI, derived from the operating
principles of the neocortex. We present an early version of a thousand-brains
system, a sensorimotor agent that is uniquely suited to quickly learn a wide
range of tasks and eventually implement any capabilities the human neocortex
has. Core to its design is the use of a repeating computational unit, the
learning module, modeled on the cortical columns found in mammalian brains.
Each learning module operates as a semi-independent unit that can model entire
objects, represents information through spatially structured reference frames,
and both estimates and is able to effect movement in the world. Learning is a
quick, associative process, similar to Hebbian learning in the brain, and
leverages inductive biases around the spatial structure of the world to enable
rapid and continual learning. Multiple learning modules can interact with one
another both hierarchically and non-hierarchically via a "cortical messaging
protocol" (CMP), creating more abstract representations and supporting
multimodal integration. We outline the key principles motivating the design of
thousand-brains systems and provide details about the implementation of Monty,
our first instantiation of such a system. Code can be found at
https://github.com/thousandbrainsproject/tbp.monty, along with more detailed
documentation at https://thousandbrainsproject.readme.io/.

摘要：<paragraph>人工智慧在過去十年中進展神速，主要是因為深度學習系統規模的進展。儘管有這些進展，但在多樣化的現實環境中有效運作的智慧系統的建立仍是一項重大的挑戰。在白皮書中，我們概述了千腦計畫，一項正在進行的研究工作，旨在開發一種替代性的、互補的人工智慧形式，其源自新皮質的運作原理。我們展示了千腦系統的早期版本，一種感官運動代理，它特別適合快速學習各種任務，並最終實施人類新皮質所具有的任何能力。其設計的核心是使用重複的計算單元，即學習模組，其模型是哺乳動物大腦中發現的皮質柱。每個學習模組都作為一個半獨立的單元運作，它可以對整個物體建模，透過空間結構參考框架表示資訊，並估計和影響世界中的運動。學習是一個快速的聯想過程，類似於大腦中的赫布學習，並利用世界空間結構周圍的歸納偏差，以實現快速和持續的學習。多個學習模組可以透過「皮質訊息傳遞協定」(CMP) 以階層式和非階層式的方式相互作用，建立更抽象的表示，並支援多模態整合。我們概述了激勵千腦系統設計的主要原則，並提供了關於 Monty 的實作細節，這是我們此類系統的首次實例。程式碼可以在 https://github.com/thousandbrainsproject/tbp.monty 找到，以及更詳細的文件在 https://thousandbrainsproject.readme.io/。</paragraph>

##### **Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering**
2412.18351v1 by Zhongjian Hu, Peng Yang, Bing Li, Zhenqi Wang

Large Language Models (LLMs) have achieved impressive results in
knowledge-based Visual Question Answering (VQA). However existing methods still
have challenges: the inability to use external tools autonomously, and the
inability to work in teams. Humans tend to know whether they need to use
external tools when they encounter a new question, e.g., they tend to be able
to give a direct answer to a familiar question, whereas they tend to use tools
such as search engines when they encounter an unfamiliar question. In addition,
humans also tend to collaborate and discuss with others to get better answers.
Inspired by this, we propose the multi-agent voting framework. We design three
LLM-based agents that simulate different levels of staff in a team, and assign
the available tools according to the levels. Each agent provides the
corresponding answer, and finally all the answers provided by the agents are
voted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our
approach outperforms other baselines by 2.2 and 1.0, respectively.

摘要：大型語言模型 (LLM) 在基於知識的視覺問答 (VQA) 中取得令人印象深刻的成果。然而，現有方法仍有挑戰：無法自主使用外部工具，以及無法團隊合作。人類傾向於知道在遇到新問題時是否需要使用外部工具，例如，他們傾向於能夠直接回答熟悉的問題，而當他們遇到不熟悉的問題時，他們傾向於使用搜索引擎等工具。此外，人類也傾向於與他人合作和討論以獲得更好的答案。受此啟發，我們提出了多主體投票框架。我們設計了三個基於 LLM 的主體，模擬團隊中不同層級的員工，並根據層級分配可用工具。每個主體提供相應的答案，最後所有主體提供的答案都經過投票以獲得最終答案。OK-VQA 和 A-OKVQA 上的實驗表明，我們的做法分別比其他基準高出 2.2 和 1.0。

##### **Exploring Graph Mamba: A Comprehensive Survey on State-Space Models for Graph Learning**
2412.18322v1 by Safa Ben Atitallah, Chaima Ben Rabah, Maha Driss, Wadii Boulila, Anis Koubaa

Graph Mamba, a powerful graph embedding technique, has emerged as a
cornerstone in various domains, including bioinformatics, social networks, and
recommendation systems. This survey represents the first comprehensive study
devoted to Graph Mamba, to address the critical gaps in understanding its
applications, challenges, and future potential. We start by offering a detailed
explanation of the original Graph Mamba architecture, highlighting its key
components and underlying mechanisms. Subsequently, we explore the most recent
modifications and enhancements proposed to improve its performance and
applicability. To demonstrate the versatility of Graph Mamba, we examine its
applications across diverse domains. A comparative analysis of Graph Mamba and
its variants is conducted to shed light on their unique characteristics and
potential use cases. Furthermore, we identify potential areas where Graph Mamba
can be applied in the future, highlighting its potential to revolutionize data
analysis in these fields. Finally, we address the current limitations and open
research questions associated with Graph Mamba. By acknowledging these
challenges, we aim to stimulate further research and development in this
promising area. This survey serves as a valuable resource for both newcomers
and experienced researchers seeking to understand and leverage the power of
Graph Mamba.

摘要：圖形 Mamba 是一種強大的圖形嵌入技術，已成為各種領域的基石，包括生物資訊學、社交網路和推薦系統。這項調查代表了第一個針對圖形 Mamba 的全面性研究，以解決理解其應用、挑戰和未來潛力的關鍵差距。我們從提供圖形 Mamba 原始架構的詳細說明開始，重點說明其關鍵組成部分和基礎機制。隨後，我們探討了為改善其效能和適用性而提出的最新修改和增強功能。為了展示圖形 Mamba 的多功能性，我們檢視了它在不同領域的應用。對圖形 Mamba 及其變體進行比較分析，以闡明其獨特特徵和潛在用例。此外，我們找出圖形 Mamba 未來可以應用的潛在領域，強調其在這些領域革新資料分析的潛力。最後，我們探討與圖形 Mamba 相關的當前限制和開放式研究問題。透過承認這些挑戰，我們旨在激勵這個有前途的領域進一步研究和開發。這項調查對於希望了解和利用圖形 Mamba 威力的新手和經驗豐富的研究人員來說，是一個有價值的資源。

##### **Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search**
2412.18319v1 by Huanjin Yao, Jiaxing Huang, Wenhao Wu, Jingyi Zhang, Yibo Wang, Shunyu Liu, Yingjie Wang, Yuxin Song, Haocheng Feng, Li Shen, Dacheng Tao

In this work, we aim to develop an MLLM that understands and solves questions
by learning to create each intermediate step of the reasoning involved till the
final answer. To this end, we propose Collective Monte Carlo Tree Search
(CoMCTS), a new learning-to-reason method for MLLMs, which introduces the
concept of collective learning into ``tree search'' for effective and efficient
reasoning-path searching and learning. The core idea of CoMCTS is to leverage
collective knowledge from multiple models to collaboratively conjecture, search
and identify effective reasoning paths toward correct answers via four
iterative operations including Expansion, Simulation and Error Positioning,
Backpropagation, and Selection. Using CoMCTS, we construct Mulberry-260k, a
multimodal dataset with a tree of rich, explicit and well-defined reasoning
nodes for each question. With Mulberry-260k, we perform collective SFT to train
our model, Mulberry, a series of MLLMs with o1-like step-by-step Reasoning and
Reflection capabilities. Extensive experiments demonstrate the superiority of
our proposed methods on various benchmarks. Code will be available at
https://github.com/HJYao00/Mulberry

摘要：在這項工作中，我們旨在開發一個 MLLM，透過學習建立推理中每個中間步驟，直到最終答案，來理解並解決問題。為此，我們提出了集體蒙地卡羅樹狀搜尋 (CoMCTS)，這是 MLLM 的一種新的學習推理方法，將集體學習的概念引入「樹狀搜尋」，以進行有效且高效的推理路徑搜尋和學習。CoMCTS 的核心思想是利用來自多個模型的集體知識，透過四個反覆運算（包括擴充、模擬和錯誤定位、反向傳播和選擇）來協作推測、搜尋和找出通往正確答案的有效推理路徑。使用 CoMCTS，我們構建了 Mulberry-260k，這是一個多模態資料集，其中包含每個問題的豐富、明確且定義良好的推理節點樹。透過 Mulberry-260k，我們執行集體 SFT 來訓練我們的模型 Mulberry，這是一系列具有 o1 類型逐步推理和反思能力的 MLLM。廣泛的實驗證明了我們提出的方法在各種基準上的優越性。程式碼將在 https://github.com/HJYao00/Mulberry 提供

##### **M-Ped: Multi-Prompt Ensemble Decoding for Large Language Models**
2412.18299v1 by Jiaxin Guo, Daimeng Wei, Yuanchang Luo, Shimin Tao, Hengchao Shang, Zongyao Li, Shaojun Li, Jinlong Yang, Zhanglin Wu, Zhiqiang Rao, Hao Yang

With the widespread application of Large Language Models (LLMs) in the field
of Natural Language Processing (NLP), enhancing their performance has become a
research hotspot. This paper presents a novel multi-prompt ensemble decoding
approach designed to bolster the generation quality of LLMs by leveraging the
aggregation of outcomes from multiple prompts. Given a unique input $X$, we
submit $n$ variations of prompts with $X$ to LLMs in batch mode to decode and
derive probability distributions. For each token prediction, we calculate the
ensemble probability by averaging the $n$ probability distributions within the
batch, utilizing this aggregated probability to generate the token. This
technique is dubbed Inner-Batch Ensemble. To facilitate efficient batch
inference, we implement a Left-Padding strategy to maintain uniform input
lengths across the n prompts. Through extensive experimentation on diverse NLP
tasks, including machine translation, code generation, and text simplification,
we demonstrate the efficacy of our method in enhancing LLM performance. The
results show substantial improvements in BLEU scores, pass@$k$ rates, and LENS
metrics over conventional methods.

摘要：隨著大型語言模型 (LLM) 在自然語言處理 (NLP) 領域的廣泛應用，提升其效能已成為研究熱點。本文提出了一種新穎的多提示集合解碼方法，旨在透過利用多個提示結果的聚合來提升 LLM 的生成品質。給定一個獨特的輸入 $X$，我們會以批次模式將 $X$ 的 $n$ 個提示變形提交給 LLM 以進行解碼並推導機率分布。對於每個標記預測，我們會計算批次中 $n$ 個機率分布的平均值來計算集合機率，並利用這個聚合機率來生成標記。此技術稱為批次內集合。為了促進有效批次推論，我們實作了一個左邊補齊策略，以維護 $n$ 個提示間的輸入長度一致。透過對各種 NLP 任務（包括機器翻譯、程式碼生成和文字簡化）進行廣泛的實驗，我們證明了我們的方法在提升 LLM 效能方面的效力。結果顯示，與傳統方法相比，BLEU 分數、pass@$k$ 率和 LENS 指標均有顯著提升。

##### **Quo Vadis, Anomaly Detection? LLMs and VLMs in the Spotlight**
2412.18298v1 by Xi Ding, Lei Wang

Video anomaly detection (VAD) has witnessed significant advancements through
the integration of large language models (LLMs) and vision-language models
(VLMs), addressing critical challenges such as interpretability, temporal
reasoning, and generalization in dynamic, open-world scenarios. This paper
presents an in-depth review of cutting-edge LLM-/VLM-based methods in 2024,
focusing on four key aspects: (i) enhancing interpretability through semantic
insights and textual explanations, making visual anomalies more understandable;
(ii) capturing intricate temporal relationships to detect and localize dynamic
anomalies across video frames; (iii) enabling few-shot and zero-shot detection
to minimize reliance on large, annotated datasets; and (iv) addressing
open-world and class-agnostic anomalies by using semantic understanding and
motion features for spatiotemporal coherence. We highlight their potential to
redefine the landscape of VAD. Additionally, we explore the synergy between
visual and textual modalities offered by LLMs and VLMs, highlighting their
combined strengths and proposing future directions to fully exploit the
potential in enhancing video anomaly detection.

摘要：影片異常偵測 (VAD) 透過整合大型語言模型 (LLM) 和視覺語言模型 (VLM)，在可解釋性、時序推理和動態開放世界場景中的概括等關鍵挑戰上取得顯著進展。本文深入探討 2024 年尖端的 LLM-/VLM- 基礎方法，重點關注四個面向：(i) 透過語意見解和文字說明增強可解釋性，讓視覺異常更易於理解；(ii) 捕捉複雜的時間關係，以偵測和定位影片格中的動態異常；(iii) 啟用少樣本和零樣本偵測，以減少對大型標註資料集的依賴；(iv) 透過語意理解和動作特徵解決開放世界和與類別無關的異常，以實現時空一致性。我們強調它們重新定義 VAD 領域的潛力。此外，我們探討 LLM 和 VLM 提供的視覺和文字模態之間的綜效，重點說明它們結合的優勢，並提出未來方向，以充分發揮增強影片異常偵測的潛力。

##### **Navigating Data Corruption in Machine Learning: Balancing Quality, Quantity, and Imputation Strategies**
2412.18296v1 by Qi Liu, Wanjing Ma

Data corruption, including missing and noisy data, poses significant
challenges in real-world machine learning. This study investigates the effects
of data corruption on model performance and explores strategies to mitigate
these effects through two experimental setups: supervised learning with NLP
tasks (NLP-SL) and deep reinforcement learning for traffic signal optimization
(Signal-RL). We analyze the relationship between data corruption levels and
model performance, evaluate the effectiveness of data imputation methods, and
assess the utility of enlarging datasets to address data corruption.
  Our results show that model performance under data corruption follows a
diminishing return curve, modeled by the exponential function. Missing data,
while detrimental, is less harmful than noisy data, which causes severe
performance degradation and training instability, particularly in sequential
decision-making tasks like Signal-RL. Imputation strategies involve a
trade-off: they recover missing information but may introduce noise. Their
effectiveness depends on imputation accuracy and corruption ratio. We identify
distinct regions in the imputation advantage heatmap, including an "imputation
advantageous corner" and an "imputation disadvantageous edge" and classify
tasks as "noise-sensitive" or "noise-insensitive" based on their decision
boundaries.
  Furthermore, we find that increasing dataset size mitigates but cannot fully
overcome the effects of data corruption. The marginal utility of additional
data diminishes as corruption increases. An empirical rule emerges:
approximately 30% of the data is critical for determining performance, while
the remaining 70% has minimal impact.
  These findings provide actionable insights into data preprocessing,
imputation strategies, and data collection practices, guiding the development
of robust machine learning systems in noisy environments.

摘要：資料毀損，包括遺失和有雜訊的資料，對現實世界的機器學習構成重大挑戰。本研究探討資料毀損對模型效能的影響，並透過兩個實驗設定探討減輕這些影響的策略：有監督學習與 NLP 任務 (NLP-SL)，以及深度強化學習用於交通號誌最佳化 (Signal-RL)。我們分析資料毀損程度與模型效能之間的關係，評估資料填補方法的有效性，並評估擴充資料集的效用，以解決資料毀損問題。
我們的結果顯示，資料毀損下的模型效能遵循遞減報酬曲線，以指數函數建模。遺失資料雖然有害，但不如有雜訊的資料有害，後者會導致嚴重的效能下降和訓練不穩定，特別是在像 Signal-RL 的順序決策任務中。填補策略涉及權衡取捨：它們會復原遺失的資訊，但可能會引入雜訊。它們的有效性取決於填補準確度和毀損率。我們在填補優勢熱圖中找出不同的區域，包括「填補優勢角」和「填補劣勢邊緣」，並根據決策邊界將任務分類為「對雜訊敏感」或「對雜訊不敏感」。
此外，我們發現增加資料集大小可以減輕資料毀損的影響，但無法完全克服。隨著毀損增加，額外資料的邊際效用會遞減。出現一條經驗法則：大約 30% 的資料對於決定效能至關重要，而其餘 70% 的影響很小。
這些發現提供可行的見解，用於資料前處理、填補策略和資料收集實務，指導在有雜訊的環境中開發穩健的機器學習系統。

##### **Pirates of the RAG: Adaptively Attacking LLMs to Leak Knowledge Bases**
2412.18295v1 by Christian Di Maio, Cristian Cosci, Marco Maggini, Valentina Poggioni, Stefano Melacci

The growing ubiquity of Retrieval-Augmented Generation (RAG) systems in
several real-world services triggers severe concerns about their security. A
RAG system improves the generative capabilities of a Large Language Models
(LLM) by a retrieval mechanism which operates on a private knowledge base,
whose unintended exposure could lead to severe consequences, including breaches
of private and sensitive information. This paper presents a black-box attack to
force a RAG system to leak its private knowledge base which, differently from
existing approaches, is adaptive and automatic. A relevance-based mechanism and
an attacker-side open-source LLM favor the generation of effective queries to
leak most of the (hidden) knowledge base. Extensive experimentation proves the
quality of the proposed algorithm in different RAG pipelines and domains,
comparing to very recent related approaches, which turn out to be either not
fully black-box, not adaptive, or not based on open-source models. The findings
from our study remark the urgent need for more robust privacy safeguards in the
design and deployment of RAG systems.

摘要：檢索增強生成 (RAG) 系統在多項實際服務中日益普及，引發了人們對其安全性嚴重的擔憂。RAG 系統透過運作於私人知識庫的檢索機制來提升大型語言模型 (LLM) 的生成能力，其意外曝光可能會導致嚴重後果，包括私人和敏感資訊的洩漏。本文提出了一種黑盒攻擊，以強制 RAG 系統洩漏其私人知識庫，這不同於現有方法，它是自適應且自動化的。基於相關性的機制和攻擊者端的開源 LLM 有利於產生有效的查詢，以洩漏大部分（隱藏的）知識庫。廣泛的實驗證明了所提出的演算法在不同 RAG 管線和領域中的品質，與最近相關的方法相比，後者結果證明不是完全黑盒的、非自適應的，或不是基於開源模型。我們的研究結果強調了在 RAG 系統的設計和部署中迫切需要更強大的隱私保障措施。

##### **MinsStudio: A Streamlined Package for Minecraft AI Agent Development**
2412.18293v1 by Shaofei Cai, Zhancun Mu, Kaichen He, Bowei Zhang, Xinyue Zheng, Anji Liu, Yitao Liang

Minecraft has emerged as a valuable testbed for embodied intelligence and
sequential decision-making research, yet the development and validation of
novel agents remains hindered by significant engineering challenges. This paper
presents MineStudio, an open-source software package designed to streamline
embodied policy development in Minecraft. MineStudio represents the first
comprehensive integration of seven critical engineering components: simulator,
data, model, offline pretraining, online finetuning, inference, and benchmark,
thereby allowing users to concentrate their efforts on algorithm innovation. We
provide a user-friendly API design accompanied by comprehensive documentation
and tutorials. The complete codebase is publicly available at
https://github.com/CraftJarvis/MineStudio.

摘要：Minecraft 已成為具象智能和序貫決策研究的寶貴測試平台，但新代理的開發和驗證仍受到重大工程挑戰的阻礙。本文介紹 MineStudio，這是一個開源軟體套件，旨在簡化 Minecraft 中具象政策的開發。MineStudio 代表了七個關鍵工程組件的首次全面整合：模擬器、資料、模型、離線預訓練、線上微調、推論和基準，從而使用戶能夠將精力集中在演算法創新上。我們提供使用者友善的 API 設計，並附有全面的文件和教學課程。完整的程式碼庫可在 https://github.com/CraftJarvis/MineStudio 公開取得。

##### **DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation**
2412.18291v1 by Junyi Lu, Xiaojia Li, Zihan Hua, Lei Yu, Shiqi Cheng, Li Yang, Fengjun Zhang, Chun Zuo

Code review is a vital but demanding aspect of software development,
generating significant interest in automating review comments. Traditional
evaluation methods for these comments, primarily based on text similarity, face
two major challenges: inconsistent reliability of human-authored comments in
open-source projects and the weak correlation of text similarity with
objectives like enhancing code quality and detecting defects.
  This study empirically analyzes benchmark comments using a novel set of
criteria informed by prior research and developer interviews. We then similarly
revisit the evaluation of existing methodologies. Our evaluation framework,
DeepCRCEval, integrates human evaluators and Large Language Models (LLMs) for a
comprehensive reassessment of current techniques based on the criteria set.
Besides, we also introduce an innovative and efficient baseline, LLM-Reviewer,
leveraging the few-shot learning capabilities of LLMs for a target-oriented
comparison.
  Our research highlights the limitations of text similarity metrics, finding
that less than 10% of benchmark comments are high quality for automation. In
contrast, DeepCRCEval effectively distinguishes between high and low-quality
comments, proving to be a more reliable evaluation mechanism. Incorporating LLM
evaluators into DeepCRCEval significantly boosts efficiency, reducing time and
cost by 88.78% and 90.32%, respectively. Furthermore, LLM-Reviewer demonstrates
significant potential of focusing task real targets in comment generation.

摘要：程式碼檢閱是軟體開發中至關重要但要求嚴格的一環，因此自動化檢閱評論引起了極大的興趣。這些評論的傳統評估方法主要基於文字相似度，面臨兩大挑戰：開源專案中人工撰寫評論的不一致可靠性，以及文字相似度與提升程式碼品質和偵測缺陷等目標之間的關聯性薄弱。本研究使用一組新穎的標準對基準評論進行實證分析，這些標準來自於先前的研究和開發人員訪談。然後，我們以類似的方式重新檢視現有方法論的評估。我們的評估架構 DeepCRCEval 整合了人工評估員和大型語言模型 (LLM)，以根據標準集對目前的技術進行全面重新評估。此外，我們還引入了一個創新且高效的基準，LLM-Reviewer，利用 LLM 的少次學習能力進行目標導向的比較。我們的研究突顯了文字相似度指標的限制，發現不到 10% 的基準評論對於自動化而言是高品質的。相比之下，DeepCRCEval 有效地區分了高品質和低品質評論，證明是一種更可靠的評估機制。將 LLM 評估員納入 DeepCRCEval 可顯著提升效率，分別將時間和成本降低 88.78% 和 90.32%。此外，LLM-Reviewer 證明了在評論產生中關注任務真實目標的巨大潛力。

##### **Towards understanding how attention mechanism works in deep learning**
2412.18288v1 by Tianyu Ruan, Shihua Zhang

Attention mechanism has been extensively integrated within mainstream neural
network architectures, such as Transformers and graph attention networks. Yet,
its underlying working principles remain somewhat elusive. What is its essence?
Are there any connections between it and traditional machine learning
algorithms? In this study, we inspect the process of computing similarity using
classic metrics and vector space properties in manifold learning, clustering,
and supervised learning. We identify the key characteristics of similarity
computation and information propagation in these methods and demonstrate that
the self-attention mechanism in deep learning adheres to the same principles
but operates more flexibly and adaptively. We decompose the self-attention
mechanism into a learnable pseudo-metric function and an information
propagation process based on similarity computation. We prove that the
self-attention mechanism converges to a drift-diffusion process through
continuous modeling provided the pseudo-metric is a transformation of a metric
and certain reasonable assumptions hold. This equation could be transformed
into a heat equation under a new metric. In addition, we give a first-order
analysis of attention mechanism with a general pseudo-metric function. This
study aids in understanding the effects and principle of attention mechanism
through physical intuition. Finally, we propose a modified attention mechanism
called metric-attention by leveraging the concept of metric learning to
facilitate the ability to learn desired metrics more effectively. Experimental
results demonstrate that it outperforms self-attention regarding training
efficiency, accuracy, and robustness.

摘要：注意力机制已被广泛集成到主流神经网络架构中，例如 Transformer 和图注意力网络。然而，其底层工作原理仍然有些难以捉摸。它的本质是什么？它与传统机器学习算法之间有什么联系？在这项研究中，我们考察了使用经典度量和流形学习、聚类和监督学习中的向量空间属性计算相似性的过程。我们识别了这些方法中相似性计算和信息传播的关键特征，并证明了深度学习中的自注意力机制遵循相同的原则，但操作更灵活和自适应。我们将自注意力机制分解为可学习的伪度量函数和基于相似性计算的信息传播过程。我们证明了自注意力机制通过连续建模收敛到漂移扩散过程，前提是伪度量是度量的变换，并且某些合理的假设成立。该方程可以在新度量下转换为热方程。此外，我们对具有通用伪度量函数的注意力机制进行了**一阶分析**。本研究有助于通过物理直觉理解注意力机制的影响和原理。最后，我们提出了一种称为度量注意力的修改注意力机制，通过利用度量学习的概念来促进更有效地学习所需度量的能力。实验结果表明，它在训练效率、准确性和鲁棒性方面优于自注意力。

##### **Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation**
2412.18287v1 by Sheng Xiang, Mingzhi Zhu, Dawei Cheng, Enxia Li, Ruihui Zhao, Yi Ouyang, Ling Chen, Yefeng Zheng

Credit card fraud incurs a considerable cost for both cardholders and issuing
banks. Contemporary methods apply machine learning-based classifiers to detect
fraudulent behavior from labeled transaction records. But labeled data are
usually a small proportion of billions of real transactions due to expensive
labeling costs, which implies that they do not well exploit many natural
features from unlabeled data. Therefore, we propose a semi-supervised graph
neural network for fraud detection. Specifically, we leverage transaction
records to construct a temporal transaction graph, which is composed of
temporal transactions (nodes) and interactions (edges) among them. Then we pass
messages among the nodes through a Gated Temporal Attention Network (GTAN) to
learn the transaction representation. We further model the fraud patterns
through risk propagation among transactions. The extensive experiments are
conducted on a real-world transaction dataset and two publicly available fraud
detection datasets. The result shows that our proposed method, namely GTAN,
outperforms other state-of-the-art baselines on three fraud detection datasets.
Semi-supervised experiments demonstrate the excellent fraud detection
performance of our model with only a tiny proportion of labeled data.

摘要：信用卡诈骗对持卡人和发卡银行来说都是一笔不小的开支。当代方法应用基于机器学习的分类器来从标记的交易记录中检测欺诈行为。但由于标记成本高昂，标记数据通常只占数十亿笔真实交易的一小部分，这意味着它们并没有很好地利用未标记数据中的许多自然特征。因此，我们提出了一种用于欺诈检测的半监督图神经网络。具体来说，我们利用交易记录构建了一个时间交易图，该图由时间交易（节点）和它们之间的交互（边）组成。然后，我们通过门控时间注意力网络 (GTAN) 在节点之间传递消息，以学习交易表示。我们进一步通过交易之间的风险传播对欺诈模式进行建模。广泛的实验是在一个真实世界的交易数据集和两个公开可用的欺诈检测数据集上进行的。结果表明，我们提出的方法，即 GTAN，在三个欺诈检测数据集上优于其他最先进的基线。半监督实验表明，我们的模型仅使用一小部分标记数据就表现出出色的欺诈检测性能。

##### **Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization**
2412.18279v1 by Jiacai Liu, Chaojie Wang, Chris Yuhao Liu, Liang Zeng, Rui Yan, Yiwen Sun, Yang Liu, Yahui Zhou

The role of reinforcement learning (RL) in enhancing the reasoning of large
language models (LLMs) is becoming increasingly significant. Despite the
success of RL in many scenarios, there are still many challenges in improving
the reasoning of LLMs. One challenge is the sparse reward, which makes
optimization difficult for RL and necessitates a large amount of data samples.
Another challenge stems from the inherent instability of RL, particularly when
using Actor-Critic (AC) methods to derive optimal policies, which often leads
to unstable training processes. To address these issues, we introduce Direct
Advantage Policy Optimization (DAPO), an novel step-level offline RL algorithm.
Unlike standard alignment that rely solely outcome rewards to optimize policies
(such as DPO), DAPO employs a critic function to predict the reasoning accuracy
at each step, thereby generating dense signals to refine the generation
strategy. Additionally, the Actor and Critic components in DAPO are trained
independently, avoiding the co-training instability observed in standard AC
algorithms like PPO. We train DAPO on mathematical and code query datasets and
then evaluate its performance on multiple benchmarks. Our results show that
DAPO can effectively enhance the mathematical and code capabilities on both SFT
models and RL models, demonstrating the effectiveness of DAPO.

摘要：強化學習 (RL) 在提升大型語言模型 (LLM) 推論中的角色正變得越來越重要。儘管 RL 在許多場景中都獲得成功，但在改善 LLM 推論方面仍有許多挑戰。其中一項挑戰是稀疏獎勵，這使得 RL 的最佳化變得困難，並且需要大量的資料樣本。另一項挑戰源於 RL 的內在不穩定性，特別是在使用 Actor-Critic (AC) 方法來推導最佳策略時，這通常會導致不穩定的訓練過程。為了解決這些問題，我們引入了直接優勢策略最佳化 (DAPO)，一種新穎的步驟級離線 RL 演算法。與僅依賴結果獎勵來最佳化策略的標準對齊不同（例如 DPO），DAPO 使用一個評論函數來預測每個步驟的推論準確度，從而產生密集的訊號來優化生成策略。此外，DAPO 中的 Actor 和 Critic 組件是獨立訓練的，避免了在標準 AC 演算法中觀察到的共同訓練不穩定性，例如 PPO。我們在數學和程式碼查詢資料集上訓練 DAPO，然後評估其在多個基準測試上的效能。我們的結果表明，DAPO 可以有效提升 SFT 模型和 RL 模型上的數學和程式碼能力，證明了 DAPO 的有效性。

##### **GenAI Content Detection Task 2: AI vs. Human -- Academic Essay Authenticity Challenge**
2412.18274v1 by Shammur Absar Chowdhury, Hind Almerekhi, Mucahid Kutlu, Kaan Efe Keles, Fatema Ahmad, Tasnim Mohiuddin, George Mikros, Firoj Alam

This paper presents a comprehensive overview of the first edition of the
Academic Essay Authenticity Challenge, organized as part of the GenAI Content
Detection shared tasks collocated with COLING 2025. This challenge focuses on
detecting machine-generated vs. human-authored essays for academic purposes.
The task is defined as follows: "Given an essay, identify whether it is
generated by a machine or authored by a human.'' The challenge involves two
languages: English and Arabic. During the evaluation phase, 25 teams submitted
systems for English and 21 teams for Arabic, reflecting substantial interest in
the task. Finally, seven teams submitted system description papers. The
majority of submissions utilized fine-tuned transformer-based models, with one
team employing Large Language Models (LLMs) such as Llama 2 and Llama 3. This
paper outlines the task formulation, details the dataset construction process,
and explains the evaluation framework. Additionally, we present a summary of
the approaches adopted by participating teams. Nearly all submitted systems
outperformed the n-gram-based baseline, with the top-performing systems
achieving F1 scores exceeding 0.98 for both languages, indicating significant
progress in the detection of machine-generated text.

摘要：這篇論文全面概述了 GenAI 內容偵測共享任務的一部分，作為 COLING 2025 協辦的學術論文真實性挑戰賽的第一版。這個挑戰專注於偵測機器產生的文章與人類撰寫的學術文章。任務定義如下：「給定一篇論文，找出它是機器產生的還是人類撰寫的。」這個挑戰涉及兩種語言：英語和阿拉伯語。在評估階段，25 個團隊提交了英語系統，21 個團隊提交了阿拉伯語系統，反映出對這個任務的濃厚興趣。最後，七個團隊提交了系統說明文件。大多數提交的文件都利用了微調的Transformer模型，其中一個團隊採用了大型語言模型 (LLM)，例如 Llama 2 和 Llama 3。這篇論文概述了任務的制定，詳細說明了資料集的建構過程，並解釋了評估架構。此外，我們還簡要說明了參賽團隊採用的方法。幾乎所有提交的系統都優於基於 n-gram 的基準，表現最佳的系統在兩種語言中都達到了超過 0.98 的 F1 分數，這表示在機器產生的文字偵測方面取得了顯著進展。

##### **Sampling Bag of Views for Open-Vocabulary Object Detection**
2412.18273v1 by Hojun Choi, Junsuk Choe, Hyunjung Shim

Existing open-vocabulary object detection (OVD) develops methods for testing
unseen categories by aligning object region embeddings with corresponding VLM
features. A recent study leverages the idea that VLMs implicitly learn
compositional structures of semantic concepts within the image. Instead of
using an individual region embedding, it utilizes a bag of region embeddings as
a new representation to incorporate compositional structures into the OVD task.
However, this approach often fails to capture the contextual concepts of each
region, leading to noisy compositional structures. This results in only
marginal performance improvements and reduced efficiency. To address this, we
propose a novel concept-based alignment method that samples a more powerful and
efficient compositional structure. Our approach groups contextually related
``concepts'' into a bag and adjusts the scale of concepts within the bag for
more effective embedding alignment. Combined with Faster R-CNN, our method
achieves improvements of 2.6 box AP50 and 0.5 mask AP over prior work on novel
categories in the open-vocabulary COCO and LVIS benchmarks. Furthermore, our
method reduces CLIP computation in FLOPs by 80.3% compared to previous
research, significantly enhancing efficiency. Experimental results demonstrate
that the proposed method outperforms previous state-of-the-art models on the
OVD datasets.

摘要：現有的開放式詞彙目標偵測 (OVD) 發展出透過將目標區域嵌入與對應的 VLM 特徵對齊，來測試未見類別的方法。最近的研究利用 VLM 隱含地學習影像中語意概念的組合結構這個想法。它使用區域嵌入的袋子作為新的表示，來將組合結構納入 OVD 任務，而不是使用個別區域嵌入。然而，這種方法通常無法捕捉每個區域的脈絡概念，導致組合結構有雜訊。這只會帶來邊際效能改善和降低效率。為了解決這個問題，我們提出一個新穎的基於概念的對齊方法，來取樣更強大且有效的組合結構。我們的做法將脈絡相關的「概念」分組成一個袋子，並調整袋子中概念的規模，以進行更有效的嵌入對齊。我們的做法結合了 Faster R-CNN，在開放式詞彙 COCO 和 LVIS 基準中，針對新類別取得了 2.6 個框 AP50 和 0.5 個遮罩 AP 的改進。此外，與先前的研究相比，我們的做法將 FLOP 中的 CLIP 計算減少了 80.3%，大幅提升了效率。實驗結果證明，所提出的方法在 OVD 資料集上優於先前的最先進模型。

##### **Annotating References to Mythological Entities in French Literature**
2412.18270v1 by Thierry Poibeau

In this paper, we explore the relevance of large language models (LLMs) for
annotating references to Roman and Greek mythological entities in modern and
contemporary French literature. We present an annotation scheme and demonstrate
that recent LLMs can be directly applied to follow this scheme effectively,
although not without occasionally making significant analytical errors.
Additionally, we show that LLMs (and, more specifically, ChatGPT) are capable
of offering interpretative insights into the use of mythological references by
literary authors. However, we also find that LLMs struggle to accurately
identify relevant passages in novels (when used as an information retrieval
engine), often hallucinating and generating fabricated examples-an issue that
raises significant ethical concerns. Nonetheless, when used carefully, LLMs
remain valuable tools for performing annotations with high accuracy, especially
for tasks that would be difficult to annotate comprehensively on a large scale
through manual methods alone.

摘要：在本文中，我們探討大型語言模型 (LLM) 對現代和當代法語文學中羅馬和希臘神話實體引用的註解相關性。我們提出一個註解方案，並展示最近的 LLM 可以直接應用於有效遵循此方案，儘管偶爾會出現重大的分析錯誤。此外，我們展示了 LLM（更具體地說，是 ChatGPT）能夠提供對文學作者使用神話引用的詮釋見解。然而，我們也發現 LLM 難以準確識別小說中的相關段落（當用作資訊檢索引擎時），經常出現幻覺並產生虛構的範例，這是一個引發重大道德問題的問題。儘管如此，在小心使用時，LLM 仍然是執行高準確度註解的寶貴工具，特別是對於僅透過手動方法難以全面註解的大規模任務。

##### **Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study**
2412.18260v1 by Xuefeng Jiang, Lvhua Wu, Sheng Sun, Jia Li, Jingjing Xue, Yuwei Wang, Tingting Wu, Min Liu

Code vulnerability detection (CVD) is essential for addressing and preventing
system security issues, playing a crucial role in ensuring software security.
Previous learning-based vulnerability detection methods rely on either
fine-tuning medium-size sequence models or training smaller neural networks
from scratch. Recent advancements in large pre-trained language models (LLMs)
have showcased remarkable capabilities in various code intelligence tasks
including code understanding and generation. However, the effectiveness of LLMs
in detecting code vulnerabilities is largely under-explored. This work aims to
investigate the gap by fine-tuning LLMs for the CVD task, involving four
widely-used open-source LLMs. We also implement other five previous graph-based
or medium-size sequence models for comparison. Experiments are conducted on
five commonly-used CVD datasets, including both the part of short samples and
long samples. In addition, we conduct quantitative experiments to investigate
the class imbalance issue and the model's performance on samples of different
lengths, which are rarely studied in previous works. To better facilitate
communities, we open-source all codes and resources of this study in
https://github.com/SakiRinn/LLM4CVD and
https://huggingface.co/datasets/xuefen/VulResource.

摘要：程式碼漏洞偵測 (CVD) 對於解決和預防系統安全問題至關重要，在確保軟體安全中扮演著關鍵角色。先前的基於學習的漏洞偵測方法仰賴微調中等大小的序列模型或從頭訓練較小的神經網路。大型預訓練語言模型 (LLM) 的最新進展在各種程式碼智慧任務中展現了卓越的能力，包括程式碼理解和產生。然而，LLM 在偵測程式碼漏洞方面的有效性在很大程度上尚未被探索。本研究旨在透過微調 LLM 以執行 CVD 任務來探討這個差距，其中涉及四個廣泛使用的開源 LLM。我們也實作了其他五個先前的基於圖形的模型或中等大小的序列模型以供比較。實驗在五個常用的 CVD 資料集上進行，包括短範例和長範例的部分。此外，我們進行了量化實驗以探討類別不平衡問題和模型在不同長度範例上的效能，這些在先前的研究中很少被探討。為了更好地促進社群，我們在 https://github.com/SakiRinn/LLM4CVD 和 https://huggingface.co/datasets/xuefen/VulResource 開源了本研究的所有程式碼和資源。

##### **Fréchet regression for multi-label feature selection with implicit regularization**
2412.18247v1 by Dou El Kefel Mansouri, Seif-Eddine Benkabou, Khalid Benabdeslem

Fr\'echet regression extends linear regression to model complex responses
  in metric spaces, making it particularly relevant for multi-label regression,
  where each instance can have multiple associated labels. However, variable
  selection within this framework remains underexplored. In this paper, we pro
pose a novel variable selection method that employs implicit regularization
  instead of traditional explicit regularization approaches, which can
introduce
  bias. Our method effectively captures nonlinear interactions between predic
tors and responses while promoting model sparsity. We provide theoretical
  results demonstrating selection consistency and illustrate the performance of
  our approach through numerical examples

摘要：Fréchet 回歸將線性回歸延伸到模型複雜回應
在度量空間中，使其特別適用於多標籤回歸，
其中每個實例可以有多個關聯標籤。但是，變量
在這個框架內的選擇仍然未被充分探討。在本文中，我們提出
一種新穎的變量選擇方法，它採用隱式正則化
而不是傳統的顯式正則化方法，這可能會
引入
偏差。我們的模型有效地捕捉了預測器和響應之間的非線性交互，同時促進了模型的稀疏性。我們提供理論
結果證明了選擇的一致性，並通過數值示例說明了我們的方法的性能

##### **An Automatic Graph Construction Framework based on Large Language Models for Recommendation**
2412.18241v1 by Rong Shan, Jianghao Lin, Chenxu Zhu, Bo Chen, Menghui Zhu, Kangning Zhang, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

Graph neural networks (GNNs) have emerged as state-of-the-art methods to
learn from graph-structured data for recommendation. However, most existing
GNN-based recommendation methods focus on the optimization of model structures
and learning strategies based on pre-defined graphs, neglecting the importance
of the graph construction stage. Earlier works for graph construction usually
rely on speciffic rules or crowdsourcing, which are either too simplistic or
too labor-intensive. Recent works start to utilize large language models (LLMs)
to automate the graph construction, in view of their abundant open-world
knowledge and remarkable reasoning capabilities. Nevertheless, they generally
suffer from two limitations: (1) invisibility of global view (e.g., overlooking
contextual information) and (2) construction inefficiency. To this end, we
introduce AutoGraph, an automatic graph construction framework based on LLMs
for recommendation. Specifically, we first use LLMs to infer the user
preference and item knowledge, which is encoded as semantic vectors. Next, we
employ vector quantization to extract the latent factors from the semantic
vectors. The latent factors are then incorporated as extra nodes to link the
user/item nodes, resulting in a graph with in-depth global-view semantics. We
further design metapath-based message aggregation to effectively aggregate the
semantic and collaborative information. The framework is model-agnostic and
compatible with different backbone models. Extensive experiments on three
real-world datasets demonstrate the efficacy and efffciency of AutoGraph
compared to existing baseline methods. We have deployed AutoGraph in Huawei
advertising platform, and gain a 2.69% improvement on RPM and a 7.31%
improvement on eCPM in the online A/B test. Currently AutoGraph has been used
as the main trafffc model, serving hundreds of millions of people.

摘要：圖神經網路 (GNN) 已成為最先進的方法，可從圖形結構化資料中學習推薦。然而，現有的基於 GNN 的推薦方法大多側重於預定義圖形上的模型結構和學習策略的最佳化，忽略了圖形建構階段的重要性。早期圖形建構工作通常依賴於特定規則或群眾外包，這些方法過於簡化或過於勞動密集。最近的工作開始利用大型語言模型 (LLM) 來自動化圖形建構，因為它們具有豐富的開放世界知識和卓越的推理能力。儘管如此，它們通常存在兩個限制：(1) 全域檢視的不可見性（例如，忽略上下文資訊）和 (2) 建構效率低下。為此，我們引入了 AutoGraph，一個基於 LLM 的自動圖形建構框架，用於推薦。具體來說，我們首先使用 LLM 推斷使用者偏好和項目知識，並將其編碼為語義向量。接下來，我們採用向量量化從語義向量中提取潛在因子。然後將潛在因子作為額外節點加入，以連結使用者/項目節點，從而形成一個具有深入全域檢視語義的圖形。我們進一步設計了基於元路徑的訊息聚合，以有效聚合語義和協作資訊。該框架與模型無關，並與不同的主幹模型相容。在三個真實世界資料集上進行的廣泛實驗證明了 AutoGraph 與現有基準方法相比的效能和效率。我們已在華為廣告平台上部署了 AutoGraph，並在線上 A/B 測試中獲得了 RPM 提升 2.69% 和 eCPM 提升 7.31%。目前 AutoGraph 已被用作主要的流量模型，服務於數億人。

##### **Expand VSR Benchmark for VLLM to Expertize in Spatial Rules**
2412.18224v1 by Peijin Xie, Lin Sun, Bingquan Liu, Dexin Wang, Xiangzheng Zhang, Chengjie Sun, Jiajia Zhang

Distinguishing spatial relations is a basic part of human cognition which
requires fine-grained perception on cross-instance. Although benchmarks like
MME, MMBench and SEED comprehensively have evaluated various capabilities which
already include visual spatial reasoning(VSR). There is still a lack of
sufficient quantity and quality evaluation and optimization datasets for Vision
Large Language Models(VLLMs) specifically targeting visual positional
reasoning. To handle this, we first diagnosed current VLLMs with the VSR
dataset and proposed a unified test set. We found current VLLMs to exhibit a
contradiction of over-sensitivity to language instructions and
under-sensitivity to visual positional information. By expanding the original
benchmark from two aspects of tunning data and model structure, we mitigated
this phenomenon. To our knowledge, we expanded spatially positioned image data
controllably using diffusion models for the first time and integrated original
visual encoding(CLIP) with other 3 powerful visual encoders(SigLIP, SAM and
DINO). After conducting combination experiments on scaling data and models, we
obtained a VLLM VSR Expert(VSRE) that not only generalizes better to different
instructions but also accurately distinguishes differences in visual positional
information. VSRE achieved over a 27\% increase in accuracy on the VSR test
set. It becomes a performant VLLM on the position reasoning of both the VSR
dataset and relevant subsets of other evaluation benchmarks. We open-sourced
the expanded model with data and Appendix at
\url{https://github.com/peijin360/vsre} and hope it will accelerate
advancements in VLLM on VSR learning.

摘要：區分空間關係是人類認知的基本部分，這需要跨例子的精細感知。儘管像 MME、MMBench 和 SEED 這樣的基準全面評估了各種能力，其中已包含視覺空間推理 (VSR)。但仍然缺乏針對視覺位置推理的、數量和質量足夠的評估和優化資料集，特別是針對視覺大型語言模型 (VLLM)。為了處理這個問題，我們首先使用 VSR 資料集診斷了目前的 VLLM，並提出了一個統一的測試集。我們發現目前的 VLLM 表現出對語言指令過度敏感和對視覺位置資訊過度不敏感的矛盾現象。透過從調整資料和模型結構兩個方面擴展原始基準，我們減輕了這種現象。據我們所知，我們首次使用擴散模型可控地擴展了空間定位的影像資料，並將原始視覺編碼 (CLIP) 與其他 3 個強大的視覺編碼器 (SigLIP、SAM 和 DINO) 整合在一起。在對資料和模型的擴充進行組合實驗後，我們獲得了一個 VLLM VSR 專家 (VSRE)，它不僅能對不同的指令進行更好的概括，還能準確區分視覺位置資訊的差異。VSRE 在 VSR 測試集中準確率提高了 27% 以上。它成為了 VSR 資料集和其它評估基準相關子集的定位推理中效能良好的 VLLM。我們在 \url{https://github.com/peijin360/vsre} 開源了擴展模型、資料和附錄，並希望它能加速 VLLM 在 VSR 學習方面的進展。

##### **ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation**
2412.18216v1 by Mengyang Wu, Yuzhi Zhao, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, Chi-Wing Fu

Controversial contents largely inundate the Internet, infringing various
cultural norms and child protection standards. Traditional Image Content
Moderation (ICM) models fall short in producing precise moderation decisions
for diverse standards, while recent multimodal large language models (MLLMs),
when adopted to general rule-based ICM, often produce classification and
explanation results that are inconsistent with human moderators. Aiming at
flexible, explainable, and accurate ICM, we design a novel rule-based dataset
generation pipeline, decomposing concise human-defined rules and leveraging
well-designed multi-stage prompts to enrich short explicit image annotations.
Our ICM-Instruct dataset includes detailed moderation explanation and
moderation Q-A pairs. Built upon it, we create our ICM-Assistant model in the
framework of rule-based ICM, making it readily applicable in real practice. Our
ICM-Assistant model demonstrates exceptional performance and flexibility.
Specifically, it significantly outperforms existing approaches on various
sources, improving both the moderation classification (36.8\% on average) and
moderation explanation quality (26.6\% on average) consistently over existing
MLLMs. Code/Data is available at https://github.com/zhaoyuzhi/ICM-Assistant.

摘要：有爭議的內容大量充斥在網路上，侵犯各種文化規範和兒童保護標準。傳統的影像內容審核 (ICM) 模型無法針對不同的標準提出精確的審核決定，而最近的多模態大型語言模型 (MLLM) 在採用一般基於規則的 ICM 時，通常會產生與人工審核員不一致的分類和說明結果。為了實現彈性、可解釋和精確的 ICM，我們設計了一個新穎的基於規則的資料集生成管道，分解簡潔的人類定義規則，並利用設計良好的多階段提示來豐富簡短的明確影像註解。我們的 ICM-Instruct 資料集包含詳細的審核說明和審核問答對。建立在它的基礎上，我們在基於規則的 ICM 的架構中建立了我們的 ICM-Assistant 模型，使其易於應用於實際操作中。我們的 ICM-Assistant 模型展示出卓越的效能和彈性。具體來說，它在各種來源上都顯著優於現有方法，持續改善審核分類（平均 36.8%）和審核說明品質（平均 26.6%），優於現有的 MLLM。程式碼/資料可在 https://github.com/zhaoyuzhi/ICM-Assistant 取得。

##### **Robustness-aware Automatic Prompt Optimization**
2412.18196v1 by Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Fan Yang, Yongfeng Zhang

The performance of Large Language Models (LLMs) is based on the quality of
the prompts and the semantic and structural integrity information of the input
data. However, current prompt generation methods primarily focus on generating
prompts for clean input data, often overlooking the impact of perturbed inputs
on prompt performance. To address this limitation, we propose BATprompt (By
Adversarial Training prompt), a novel method for prompt generation designed to
withstand input perturbations (such as typos in the input). Inspired by
adversarial training techniques, BATprompt demonstrates strong performance on a
variety of perturbed tasks through a two-step process: adversarial perturbation
and iterative optimization on unperturbed input via LLM. Unlike conventional
adversarial attack methods, BATprompt avoids reliance on real gradients or
model parameters. Instead, it leverages the advanced reasoning, language
understanding and self reflection capabilities of LLMs to simulate gradients,
guiding the generation of adversarial perturbations and optimizing prompt
performance. In our experiments, we evaluate BATprompt on multiple datasets
across both language understanding and generation tasks. The results indicate
that BATprompt outperforms existing prompt generation methods, delivering
superior robustness and performance under diverse perturbation scenarios.

摘要：大型語言模型 (LLM) 的效能取決於提示的品質，以及輸入資料的語意和結構完整性資訊。然而，目前的提示產生方法主要專注於為乾淨的輸入資料產生提示，常常忽略擾動輸入對提示效能的影響。為了解決這個限制，我們提出 BATprompt（對抗訓練提示），這是一種新穎的提示產生方法，旨在承受輸入擾動（例如輸入中的錯字）。受到對抗訓練技術的啟發，BATprompt 透過一個兩步驟的過程在各種擾動任務上展現強大的效能：對抗擾動和透過 LLM 對未擾動輸入進行反覆最佳化。與傳統的對抗攻擊方法不同，BATprompt 避免依賴真實梯度或模型參數。相反地，它利用 LLM 的進階推理、語言理解和自我反省能力來模擬梯度，引導對抗擾動的產生並最佳化提示效能。在我們的實驗中，我們在跨語言理解和產生任務的多個資料集上評估 BATprompt。結果表明，BATprompt 優於現有的提示產生方法，在不同的擾動場景下提供卓越的穩健性和效能。

##### **VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks**
2412.18194v1 by Shiduo Zhang, Zhe Xu, Peiju Liu, Xiaopeng Yu, Yuan Li, Qinghui Gao, Zhaoye Fei, Zhangyue Yin, Zuxuan Wu, Yu-Gang Jiang, Xipeng Qiu

General-purposed embodied agents are designed to understand the users'
natural instructions or intentions and act precisely to complete universal
tasks. Recently, methods based on foundation models especially
Vision-Language-Action models (VLAs) have shown a substantial potential to
solve language-conditioned manipulation (LCM) tasks well. However, existing
benchmarks do not adequately meet the needs of VLAs and relative algorithms. To
better define such general-purpose tasks in the context of LLMs and advance the
research in VLAs, we present VLABench, an open-source benchmark for evaluating
universal LCM task learning. VLABench provides 100 carefully designed
categories of tasks, with strong randomization in each category of task and a
total of 2000+ objects. VLABench stands out from previous benchmarks in four
key aspects: 1) tasks requiring world knowledge and common sense transfer, 2)
natural language instructions with implicit human intentions rather than
templates, 3) long-horizon tasks demanding multi-step reasoning, and 4)
evaluation of both action policies and language model capabilities. The
benchmark assesses multiple competencies including understanding of
mesh\&texture, spatial relationship, semantic instruction, physical laws,
knowledge transfer and reasoning, etc. To support the downstream finetuning, we
provide high-quality training data collected via an automated framework
incorporating heuristic skills and prior information. The experimental results
indicate that both the current state-of-the-art pretrained VLAs and the
workflow based on VLMs face challenges in our tasks.

摘要：<paragraph>通用具身代理旨在了解使用者的自然指令或意圖，並準確執行以完成通用任務。最近，基於基礎模型的方法，尤其是視覺語言動作模型 (VLA)，已展現出解決語言條件操作 (LCM) 任務的巨大潛力。然而，現有的基準並未充分滿足 VLA 和相關演算法的需求。為了在 LLM 的背景下更好地定義此類通用任務並推動 VLA 的研究，我們提出了 VLABench，一個用於評估通用 LCM 任務學習的開源基準。VLABench 提供 100 個精心設計的任務類別，每個任務類別都有強大的隨機性，總共有 2000 多個物件。VLABench 在四個關鍵方面優於以前的基準：1) 需要世界知識和常識轉移的任務，2) 具有隱含人類意圖的自然語言指令，而不是範本，3) 要求多步驟推理的長時程任務，以及 4) 動作策略和語言模型能力的評估。該基準評估了多項能力，包括對網格和紋理、空間關係、語義指令、物理定律、知識轉移和推理等的理解。為了支援下游微調，我們透過結合啟發式技能和先驗資訊的自動化框架，提供了高品質的訓練資料。實驗結果表明，目前最先進的預訓練 VLA 和基於 VLM 的工作流程在我們的任務中都面臨挑戰。</paragraph>

##### **An Analysis on Automated Metrics for Evaluating Japanese-English Chat Translation**
2412.18190v1 by Andre Rusli, Makoto Shishido

This paper analyses how traditional baseline metrics, such as BLEU and TER,
and neural-based methods, such as BERTScore and COMET, score several NMT models
performance on chat translation and how these metrics perform when compared to
human-annotated scores. The results show that for ranking NMT models in chat
translations, all metrics seem consistent in deciding which model outperforms
the others. This implies that traditional baseline metrics, which are faster
and simpler to use, can still be helpful. On the other hand, when it comes to
better correlation with human judgment, neural-based metrics outperform
traditional metrics, with COMET achieving the highest correlation with the
human-annotated score on a chat translation. However, we show that even the
best metric struggles when scoring English translations from sentences with
anaphoric zero-pronoun in Japanese.

摘要：本文分析了傳統基準指標（例如 BLEU 和 TER）和基於神經網路的方法（例如 BERTScore 和 COMET）如何評分多個 NMT 模型在聊天翻譯上的表現，以及這些指標與人工評分相比的表現。結果顯示，在對聊天翻譯中的 NMT 模型進行排名時，所有指標在決定哪個模型優於其他模型方面似乎都一致。這意味著傳統基準指標（使用起來更快速、更簡單）仍然可能有所幫助。另一方面，在與人類判斷相關性較高的方面，基於神經網路的指標優於傳統指標，COMET 在聊天翻譯中與人工評分相關性最高。然而，我們顯示，即使是最好的指標在評分日文中有指代性零代名詞的句子所翻譯的英文時也會遇到困難。

##### **On the Applicability of Zero-Shot Cross-Lingual Transfer Learning for Sentiment Classification in Distant Language Pairs**
2412.18188v1 by Andre Rusli, Makoto Shishido

This research explores the applicability of cross-lingual transfer learning
from English to Japanese and Indonesian using the XLM-R pre-trained model. The
results are compared with several previous works, either by models using a
similar zero-shot approach or a fully-supervised approach, to provide an
overview of the zero-shot transfer learning approach's capability using XLM-R
in comparison with existing models. Our models achieve the best result in one
Japanese dataset and comparable results in other datasets in Japanese and
Indonesian languages without being trained using the target language.
Furthermore, the results suggest that it is possible to train a multi-lingual
model, instead of one model for each language, and achieve promising results.

摘要：本研究探討使用預先訓練的 XLM-R 模型，從英語轉移學習到日語和印尼語的可行性。
結果與之前數項作品進行比較，無論是使用類似零次學習方法或完全監督學習方法的模型，以提供使用 XLM-R 的零次學習轉移學習方法的能力概觀，與現有模型進行比較。我們的模型在一個日語資料集取得最佳結果，在其他日語和印尼語資料集取得可比較的結果，而沒有使用目標語言進行訓練。
此外，結果表明有可能訓練多語言模型，而不是針對每種語言訓練一個模型，並取得有希望的結果。

##### **TextMatch: Enhancing Image-Text Consistency Through Multimodal Optimization**
2412.18185v1 by Yucong Luo, Mingyue Cheng, Jie Ouyang, Xiaoyu Tao, Qi Liu

Text-to-image generative models excel in creating images from text but
struggle with ensuring alignment and consistency between outputs and prompts.
This paper introduces TextMatch, a novel framework that leverages multimodal
optimization to address image-text discrepancies in text-to-image (T2I)
generation and editing. TextMatch employs a scoring strategy powered by large
language models (LLMs) and visual question-answering (VQA) models to evaluate
semantic consistency between prompts and generated images. By integrating
multimodal in-context learning and chain of thought reasoning, our method
dynamically refines prompts through iterative optimization. This process
ensures that the generated images better capture user intent of, resulting in
higher fidelity and relevance. Extensive experiments demonstrate that TextMatch
significantly improves text-image consistency across multiple benchmarks,
establishing a reliable framework for advancing the capabilities of
text-to-image generative models. Our code is available at
https://anonymous.4open.science/r/TextMatch-F55C/.

摘要：文字到影像生成模型在根據文字建立影像方面表現優異，但難以確保輸出與提示之間的一致性和對齊。本文介紹 TextMatch，一個創新的架構，利用多模態最佳化來解決文字到影像 (T2I) 生成和編輯中的影像文字差異。TextMatch 採用由大型語言模型 (LLM) 和視覺問答 (VQA) 模型提供支援的評分策略，以評估提示和生成影像之間的語義一致性。透過整合多模態情境學習和思維鏈推理，我們的模型透過反覆最佳化動態地改善提示。這個程序可確保生成的影像更能捕捉使用者的意圖，帶來更高的保真度和相關性。廣泛的實驗證明 TextMatch 大幅改善了多個基準中的文字影像一致性，為提升文字到影像生成模型的能力建立了一個可靠的架構。我們的程式碼可在 https://anonymous.4open.science/r/TextMatch-F55C/ 取得。

##### **Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization**
2412.18177v1 by Sihao Liu, Yibo Yang, Xiaojie Li, David A. Clifton, Bernard Ghanem

Online continual learning (OCL) seeks to learn new tasks from data streams
that appear only once, while retaining knowledge of previously learned tasks.
Most existing methods rely on replay, focusing on enhancing memory retention
through regularization or distillation. However, they often overlook the
adaptability of the model, limiting the ability to learn generalizable and
discriminative features incrementally from online training data. To address
this, we introduce a plug-and-play module, S6MOD, which can be integrated into
most existing methods and directly improve adaptability. Specifically, S6MOD
introduces an extra branch after the backbone, where a mixture of
discretization selectively adjusts parameters in a selective state space model,
enriching selective scan patterns such that the model can adaptively select the
most sensitive discretization method for current dynamics. We further design a
class-conditional routing algorithm for dynamic, uncertainty-based adjustment
and implement a contrastive discretization loss to optimize it. Extensive
experiments combining our module with various models demonstrate that S6MOD
significantly enhances model adaptability, leading to substantial performance
gains and achieving the state-of-the-art results.

摘要：線上持續學習 (OCL) 旨在從只出現一次的資料串流中學習新任務，同時保留先前學習任務的知識。
現有的方法大多依賴於重播，專注於透過正規化或知識萃取來增強記憶保留。然而，它們經常忽略模型的適應性，這限制了從線上訓練資料中逐步學習可概化和具區辨力的特徵的能力。為了解決這個問題，我們引入了一個即插即用的模組 S6MOD，它可以整合到大多數現有方法中並直接改善適應性。具體來說，S6MOD 在主幹網路後引入一個額外的分支，其中離散化的混合在選擇性狀態空間模型中選擇性地調整參數，豐富選擇性掃描模式，以便模型可以根據當前動態自適應地選擇最敏感的離散化方法。我們進一步設計了一個類條件路由演算法，用於動態、基於不確定性的調整，並實作一個對比離散化損失來最佳化它。將我們的模組與各種模型結合的廣泛實驗表明，S6MOD 大幅增強了模型適應性，從而顯著提升效能並達成最先進的結果。

##### **Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation**
2412.18176v1 by Yucong Luo, Qitao Qin, Hao Zhang, Mingyue Cheng, Ruiran Yan, Kefan Wang, Jie Ouyang

Sequential recommendation (SR) systems have evolved significantly over the
past decade, transitioning from traditional collaborative filtering to deep
learning approaches and, more recently, to large language models (LLMs). While
the adoption of LLMs has driven substantial advancements, these models
inherently lack collaborative filtering information, relying primarily on
textual content data neglecting other modalities and thus failing to achieve
optimal recommendation performance. To address this limitation, we propose
Molar, a Multimodal large language sequential recommendation framework that
integrates multiple content modalities with ID information to capture
collaborative signals effectively. Molar employs an MLLM to generate unified
item representations from both textual and non-textual data, facilitating
comprehensive multimodal modeling and enriching item embeddings. Additionally,
it incorporates collaborative filtering signals through a post-alignment
mechanism, which aligns user representations from content-based and ID-based
models, ensuring precise personalization and robust performance. By seamlessly
combining multimodal content with collaborative filtering insights, Molar
captures both user interests and contextual semantics, leading to superior
recommendation accuracy. Extensive experiments validate that Molar
significantly outperforms traditional and LLM-based baselines, highlighting its
strength in utilizing multimodal data and collaborative signals for sequential
recommendation tasks. The source code is available at
https://anonymous.4open.science/r/Molar-8B06/.

摘要：序列推薦 (SR) 系統在過去十年間大幅演進，從傳統的協同過濾轉變為深度學習方法，最近則轉變為大型語言模型 (LLM)。雖然採用 LLM 已經推動了大幅進展，但這些模型本質上缺乏協同過濾資訊，主要依賴文字內容資料，忽略其他模式，因此無法達成最佳的推薦成效。為了解決這個限制，我們提出 Molar，一個多模態大型語言序列推薦架構，它整合多種內容模式與 ID 資訊，以有效擷取協同訊號。Molar 使用 MLLM 從文字和非文字資料產生統一的項目表徵，促進全面的多模態建模，並豐富項目嵌入。此外，它透過後對齊機制納入協同過濾訊號，這個機制會對齊基於內容和基於 ID 的模型中的使用者表徵，確保精確的個人化和強健的效能。透過無縫結合多模態內容與協同過濾見解，Molar 擷取使用者興趣和脈絡語意，進而提升推薦的精確度。廣泛的實驗驗證 Molar 明顯優於傳統和基於 LLM 的基準，突顯其在利用多模態資料和協同訊號進行序列推薦任務的強項。原始程式碼可在 https://anonymous.4open.science/r/Molar-8B06/ 取得。

##### **INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent**
2412.18174v1 by Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, Koduvayur Subbalakshmi, Guojun Xiong, Jimin Huang, Lingfei Qian, Xueqing Peng, Qianqian Xie, Jordan W. Suchow

Recent advancements have underscored the potential of large language model
(LLM)-based agents in financial decision-making. Despite this progress, the
field currently encounters two main challenges: (1) the lack of a comprehensive
LLM agent framework adaptable to a variety of financial tasks, and (2) the
absence of standardized benchmarks and consistent datasets for assessing agent
performance. To tackle these issues, we introduce \textsc{InvestorBench}, the
first benchmark specifically designed for evaluating LLM-based agents in
diverse financial decision-making contexts. InvestorBench enhances the
versatility of LLM-enabled agents by providing a comprehensive suite of tasks
applicable to different financial products, including single equities like
stocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we
assess the reasoning and decision-making capabilities of our agent framework
using thirteen different LLMs as backbone models, across various market
environments and tasks. Furthermore, we have curated a diverse collection of
open-source, multi-modal datasets and developed a comprehensive suite of
environments for financial decision-making. This establishes a highly
accessible platform for evaluating financial agents' performance across various
scenarios.

摘要：<paragraph>最近的進展強調了大型語言模型 (LLM) 基礎代理在財務決策中的潛力。儘管有這些進展，該領域目前遇到兩個主要挑戰：(1) 缺乏可適應各種財務任務的綜合 LLM 代理架構，以及 (2) 缺乏標準化基準和一致的數據集來評估代理效能。為了解決這些問題，我們引入了 \textsc{InvestorBench}，這是第一個專門設計用於評估 LLM 基礎代理在各種財務決策情境中的基準。InvestorBench 透過提供適用於不同金融產品的綜合任務套件，增強了 LLM 啟用代理的多功能性，包括股票、加密貨幣和交易所買賣基金 (ETF) 等單一股票。此外，我們使用十三種不同的 LLM 作為主幹模型，在各種市場環境和任務中評估我們代理架構的推理和決策能力。此外，我們策劃了多模態開源數據集的多樣化集合，並開發了一套全面的財務決策環境。這建立了一個高度可存取的平台，用於評估金融代理在各種情境中的表現。</paragraph>

##### **KunServe: Elastic and Efficient Large Language Model Serving with Parameter-centric Memory Management**
2412.18169v1 by Rongxin Cheng, Yifan Peng, Yuxin Lai, Xingda Wei, Rong Chen, Haibo Chen

The stateful nature of large language model (LLM) servingcan easily throttle
precious GPU memory under load burstor long-generation requests like
chain-of-thought reasoning,causing latency spikes due to queuing incoming
requests. However, state-of-the-art KVCache centric approaches handleload
spikes by dropping, migrating, or swapping KVCache,which faces an essential
tradeoff between the performance ofongoing vs. incoming requests and thus still
severely violatesSLO.This paper makes a key observation such that model
param-eters are independent of the requests and are replicated acrossGPUs, and
thus proposes a parameter-centric approach byselectively dropping replicated
parameters to leave preciousmemory for requests. However, LLM requires KVCache
tobe saved in bound with model parameters and thus droppingparameters can cause
either huge computation waste or longnetwork delay, affecting all ongoing
requests. Based on the ob-servation that attention operators can be decoupled
from otheroperators, this paper further proposes a novel remote
attentionmechanism through pipeline parallelism so as to serve up-coming
requests with the additional memory borrowed fromparameters on remote GPUs.
This paper further addresses sev-eral other challenges including lively
exchanging KVCachewith incomplete parameters, generating an appropriate
planthat balances memory requirements with cooperative exe-cution overhead, and
seamlessly restoring parameters whenthe throttling has gone. Evaluations show
thatKUNSERVEreduces the tail TTFT of requests under throttling by up to 27.3x
compared to the state-of-the-art.

摘要：大型語言模型 (LLM) 服務的狀態性質在負載突然增加或長生成請求（例如思考鏈推理）的情況下，容易限制寶貴的 GPU 記憶體，導致排隊的傳入請求產生延遲高峰。然而，最先進的 KVCache 中心化方法透過捨棄、遷移或交換 KVCache 來處理負載高峰，這在正在進行的請求與傳入請求的效能之間面臨著本質上的權衡，因此仍然嚴重違反 SLO。本文提出一個關鍵觀察，即模型參數與請求無關，並跨 GPU 複製，因此提出一個以參數為中心的策略，透過選擇性地捨棄複製的參數，為請求留下寶貴的記憶體。然而，LLM 要求 KVCache 與模型參數一起儲存，因此捨棄參數可能會導致大量的運算浪費或長的網路延遲，影響所有正在進行的請求。基於注意力運算子可以與其他運算子分離的觀察，本文進一步透過管線平行化提出一個新穎的遠端注意力機制，以便使用從遠端 GPU 上參數借來的額外記憶體來服務即將到來的請求。本文進一步解決了其他幾個挑戰，包括與不完整參數交換 KVCache、產生一個平衡記憶體需求與合作執行負擔的適當計畫，以及在限制解除時無縫還原參數。評估顯示，與最先進的技術相比，KUNSERVE 將在限制下的請求尾端 TTFT 減少了多達 27.3 倍。

##### **Survey of Pseudonymization, Abstractive Summarization & Spell Checker for Hindi and Marathi**
2412.18163v1 by Rasika Ransing, Mohammed Amaan Dhamaskar, Ayush Rajpurohit, Amey Dhoke, Sanket Dalvi

India's vast linguistic diversity presents unique challenges and
opportunities for technological advancement, especially in the realm of Natural
Language Processing (NLP). While there has been significant progress in NLP
applications for widely spoken languages, the regional languages of India, such
as Marathi and Hindi, remain underserved. Research in the field of NLP for
Indian regional languages is at a formative stage and holds immense
significance. The paper aims to build a platform which enables the user to use
various features like text anonymization, abstractive text summarization and
spell checking in English, Hindi and Marathi language. The aim of these tools
is to serve enterprise and consumer clients who predominantly use Indian
Regional Languages.

摘要：印度廣泛的語言多元性為技術進步帶來了獨特的挑戰和機遇，特別是在自然語言處理 (NLP) 領域。儘管廣泛使用的語言的 NLP 應用已取得顯著進展，但印度的區域語言，如馬拉地語和印地語，仍未得到充分利用。印度區域語言 NLP 領域的研究處於形成階段，具有重大意義。本文旨在建立一個平台，使用戶能夠使用各種功能，例如英文、印地語和馬拉地語的文本匿名化、抽象文本摘要和拼寫檢查。這些工具的目的是為主要使用印度區域語言的企業和消費者客戶提供服務。

##### **VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities**
2412.18161v1 by Shray Mathur, Noah van der Vleuten, Kevin Yager, Esther Tsai

Scientific user facilities, such as synchrotron beamlines, are equipped with
a wide array of hardware and software tools that require a codebase for
human-computer-interaction. This often necessitates developers to be involved
to establish connection between users/researchers and the complex
instrumentation. The advent of generative AI presents an opportunity to bridge
this knowledge gap, enabling seamless communication and efficient experimental
workflows. Here we present a modular architecture for the Virtual Scientific
Companion (VISION) by assembling multiple AI-enabled cognitive blocks that each
scaffolds large language models (LLMs) for a specialized task. With VISION, we
performed LLM-based operation on the beamline workstation with low latency and
demonstrated the first voice-controlled experiment at an X-ray scattering
beamline. The modular and scalable architecture allows for easy adaptation to
new instrument and capabilities. Development on natural language-based
scientific experimentation is a building block for an impending future where a
science exocortex -- a synthetic extension to the cognition of scientists --
may radically transform scientific practice and discovery.

摘要：科學使用者設施，例如同步加速器光束線，配備了廣泛的硬體和軟體工具，需要一個用於人機互動的程式碼庫。這通常需要開發人員參與，才能在使用者/研究人員和複雜的儀器之間建立連接。生成式 AI 的出現提供了一個彌合知識差距的機會，實現無縫的溝通和高效的實驗工作流程。在此，我們提出了一個虛擬科學伴侶 (VISION) 的模組化架構，通過組裝多個 AI 驅動的認知區塊，每個區塊都為特定任務提供大型語言模型 (LLM) 的支架。使用 VISION，我們在光束線工作站上執行了基於 LLM 的操作，具有低延遲，並展示了在 X 射線散射光束線上進行的首次語音控制實驗。模組化和可擴充的架構允許輕鬆適應新的儀器和功能。基於自然語言的科學實驗的開發是一個即將到來的未來的基石，在這個未來中，科學外皮層（科學家認知的合成延伸）可能會徹底改變科學實踐和發現。

##### **Smooth-Foley: Creating Continuous Sound for Video-to-Audio Generation Under Semantic Guidance**
2412.18157v1 by Yaoyun Zhang, Xuenan Xu, Mengyue Wu

The video-to-audio (V2A) generation task has drawn attention in the field of
multimedia due to the practicality in producing Foley sound. Semantic and
temporal conditions are fed to the generation model to indicate sound events
and temporal occurrence. Recent studies on synthesizing immersive and
synchronized audio are faced with challenges on videos with moving visual
presence. The temporal condition is not accurate enough while low-resolution
semantic condition exacerbates the problem. To tackle these challenges, we
propose Smooth-Foley, a V2A generative model taking semantic guidance from the
textual label across the generation to enhance both semantic and temporal
alignment in audio. Two adapters are trained to leverage pre-trained
text-to-audio generation models. A frame adapter integrates high-resolution
frame-wise video features while a temporal adapter integrates temporal
conditions obtained from similarities of visual frames and textual labels. The
incorporation of semantic guidance from textual labels achieves precise
audio-video alignment. We conduct extensive quantitative and qualitative
experiments. Results show that Smooth-Foley performs better than existing
models on both continuous sound scenarios and general scenarios. With semantic
guidance, the audio generated by Smooth-Foley exhibits higher quality and
better adherence to physical laws.

摘要：影片轉音訊 (V2A) 生成任務在多媒體領域中備受關注，因為在製作 Foley 音效方面實用。語意和時間條件會提供給生成模型，以表示音效事件和時間發生。最近關於合成沉浸式和同步音訊的研究面臨影片中移動視覺存在性的挑戰。時間條件不夠準確，而低解析度語意條件會加劇問題。為了應對這些挑戰，我們提出 Smooth-Foley，一個 V2A 生成模型，從生成過程中文字標籤中獲取語意指導，以增強音訊中的語意和時間對齊。訓練兩個適配器，以利用預先訓練的文字轉音訊生成模型。一個框架適配器整合高解析度逐幀影片特徵，而時間適配器整合從視覺幀和文字標籤相似性中獲得的時間條件。從文字標籤中加入語意指導可達成精準的音訊視訊對齊。我們進行廣泛的量化和定性實驗。結果顯示，Smooth-Foley 在連續音訊場景和一般場景中都比現有模型表現得更好。有了語意指導，Smooth-Foley 生成的音訊品質更高，且更符合物理定律。

##### **scReader: Prompting Large Language Models to Interpret scRNA-seq Data**
2412.18156v1 by Cong Li, Qingqing Long, Yuanchun Zhou, Meng Xiao

Large language models (LLMs) have demonstrated remarkable advancements,
primarily due to their capabilities in modeling the hidden relationships within
text sequences. This innovation presents a unique opportunity in the field of
life sciences, where vast collections of single-cell omics data from multiple
species provide a foundation for training foundational models. However, the
challenge lies in the disparity of data scales across different species,
hindering the development of a comprehensive model for interpreting genetic
data across diverse organisms. In this study, we propose an innovative hybrid
approach that integrates the general knowledge capabilities of LLMs with
domain-specific representation models for single-cell omics data
interpretation. We begin by focusing on genes as the fundamental unit of
representation. Gene representations are initialized using functional
descriptions, leveraging the strengths of mature language models such as
LLaMA-2. By inputting single-cell gene-level expression data with prompts, we
effectively model cellular representations based on the differential expression
levels of genes across various species and cell types. In the experiments, we
constructed developmental cells from humans and mice, specifically targeting
cells that are challenging to annotate. We evaluated our methodology through
basic tasks such as cell annotation and visualization analysis. The results
demonstrate the efficacy of our approach compared to other methods using LLMs,
highlighting significant improvements in accuracy and interoperability. Our
hybrid approach enhances the representation of single-cell data and offers a
robust framework for future research in cross-species genetic analysis.

摘要：大型語言模型 (LLM) 已展現出顯著的進步，這主要歸因於它們在建模文字序列中隱藏關係的能力。這項創新為生命科學領域帶來了獨特的契機，其中來自多個物種的單細胞組學數據的龐大集合為訓練基礎模型提供了基礎。然而，挑戰在於不同物種之間的數據規模差異，這阻礙了開發一個用於解釋不同生物體遺傳數據的綜合模型。在本研究中，我們提出了一種創新的混合方法，它將 LLM 的一般知識能力與單細胞組學數據解釋的特定領域表示模型相結合。我們從將基因作為表示的基本單位開始。基因表示是使用功能描述初始化的，利用了成熟語言模型（例如 LLaMA-2）的優勢。通過使用提示輸入單細胞基因層級的表達數據，我們有效地根據不同物種和細胞類型的基因差異表達層級對細胞表示進行建模。在實驗中，我們構建了人類和小鼠的發育細胞，特別針對難以註解的細胞。我們透過細胞註解和視覺化分析等基本任務評估了我們的技術。結果證明，與使用 LLM 的其他方法相比，我們的技術方法有效，突顯了準確性和互操作性的顯著改進。我們的混合方法增強了單細胞數據的表示，並為跨物種遺傳分析的未來研究提供了強大的架構。

##### **GeneSUM: Large Language Model-based Gene Summary Extraction**
2412.18154v1 by Zhijian Chen, Chuan Hu, Min Wu, Qingqing Long, Xuezhi Wang, Yuanchun Zhou, Meng Xiao

Emerging topics in biomedical research are continuously expanding, providing
a wealth of information about genes and their function. This rapid
proliferation of knowledge presents unprecedented opportunities for scientific
discovery and formidable challenges for researchers striving to keep abreast of
the latest advancements. One significant challenge is navigating the vast
corpus of literature to extract vital gene-related information, a
time-consuming and cumbersome task. To enhance the efficiency of this process,
it is crucial to address several key challenges: (1) the overwhelming volume of
literature, (2) the complexity of gene functions, and (3) the automated
integration and generation. In response, we propose GeneSUM, a two-stage
automated gene summary extractor utilizing a large language model (LLM). Our
approach retrieves and eliminates redundancy of target gene literature and then
fine-tunes the LLM to refine and streamline the summarization process. We
conducted extensive experiments to validate the efficacy of our proposed
framework. The results demonstrate that LLM significantly enhances the
integration of gene-specific information, allowing more efficient
decision-making in ongoing research.

摘要：生物醫學研究中不斷擴展的新興主題，提供了大量關於基因及其功能的資訊。知識的快速擴散為科學發現提供了前所未有的機會，也為努力跟上最新進展的研究人員帶來了巨大的挑戰。其中一項重大挑戰是瀏覽大量的文獻，以提取重要的基因相關資訊，這項任務既耗時又繁瑣。為了提高此流程的效率，必須解決幾個關鍵挑戰：(1) 大量的文獻，(2) 基因功能的複雜性，以及 (3) 自動整合和生成。為了解決這些問題，我們提出了 GeneSUM，這是一個利用大型語言模型 (LLM) 的兩階段自動基因摘要萃取器。我們的做法是擷取並消除目標基因文獻的冗餘，然後微調 LLM 以優化和簡化摘要流程。我們進行了廣泛的實驗，以驗證我們提出的架構的功效。結果表明，LLM 大幅增強了基因特定資訊的整合，讓正在進行的研究能夠更有效率地進行決策。

##### **CoAM: Corpus of All-Type Multiword Expressions**
2412.18151v1 by Yusuke Ide, Joshua Tanner, Adam Nohejl, Jacob Hoffman, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe

Multiword expressions (MWEs) refer to idiomatic sequences of multiple words.
MWE identification, i.e., detecting MWEs in text, can play a key role in
downstream tasks such as machine translation. Existing datasets for MWE
identification are inconsistently annotated, limited to a single type of MWE,
or limited in size. To enable reliable and comprehensive evaluation, we created
CoAM: Corpus of All-Type Multiword Expressions, a dataset of 1.3K sentences
constructed through a multi-step process to enhance data quality consisting of
human annotation, human review, and automated consistency checking. MWEs in
CoAM are tagged with MWE types, such as Noun and Verb, to enable fine-grained
error analysis. Annotations for CoAM were collected using a new interface
created with our interface generator, which allows easy and flexible annotation
of MWEs in any form, including discontinuous ones. Through experiments using
CoAM, we find that a fine-tuned large language model outperforms the current
state-of-the-art approach for MWE identification. Furthermore, analysis using
our MWE type tagged data reveals that Verb MWEs are easier than Noun MWEs to
identify across approaches.

摘要：多字詞表達（MWE）指的是多個單字的慣用語序列。
MWE 識別，即在文字中偵測 MWE，可以在機器翻譯等下游任務中扮演關鍵角色。現有的 MWE 識別資料集標註不一致，僅限於單一類型的 MWE，或規模有限。為了進行可靠且全面的評估，我們建立了 CoAM：全類型多字詞表達語料庫，這是一個包含 1.3K 個句子的資料集，透過多步驟流程建構而成，以提升資料品質，包括人工標註、人工審查和自動化一致性檢查。CoAM 中的 MWE 標註有 MWE 類型，例如名詞和動詞，以進行細緻的錯誤分析。CoAM 的標註是使用我們介面產生器建立的新介面收集而來，它允許輕鬆且彈性地標註任何形式的 MWE，包括不連續的 MWE。透過使用 CoAM 進行實驗，我們發現經過微調的大語言模型優於 MWE 識別的現有最新方法。此外，使用我們標註的 MWE 類型資料進行分析顯示，動詞 MWE 比名詞 MWE 更容易透過各種方法識別。

##### **EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation**
2412.18150v1 by Shuhao Han, Haotian Fan, Jiachen Fu, Liang Li, Tao Li, Junhui Cui, Yunqiu Wang, Yang Tai, Jingwei Sun, Chunle Guo, Chongyi Li

Recently, Text-to-Image (T2I) generation models have achieved significant
advancements. Correspondingly, many automated metrics have emerged to evaluate
the image-text alignment capabilities of generative models. However, the
performance comparison among these automated metrics is limited by existing
small datasets. Additionally, these datasets lack the capacity to assess the
performance of automated metrics at a fine-grained level. In this study, we
contribute an EvalMuse-40K benchmark, gathering 40K image-text pairs with
fine-grained human annotations for image-text alignment-related tasks. In the
construction process, we employ various strategies such as balanced prompt
sampling and data re-annotation to ensure the diversity and reliability of our
benchmark. This allows us to comprehensively evaluate the effectiveness of
image-text alignment metrics for T2I models. Meanwhile, we introduce two new
methods to evaluate the image-text alignment capabilities of T2I models:
FGA-BLIP2 which involves end-to-end fine-tuning of a vision-language model to
produce fine-grained image-text alignment scores and PN-VQA which adopts a
novel positive-negative VQA manner in VQA models for zero-shot fine-grained
evaluation. Both methods achieve impressive performance in image-text alignment
evaluations. We also use our methods to rank current AIGC models, in which the
results can serve as a reference source for future study and promote the
development of T2I generation. The data and code will be made publicly
available.

摘要：<paragraph>近期，文本到图像 (T2I) 生成模型取得了显著进展。相应地，许多自动化指标也随之出现，用于评估生成模型的图像文本对齐能力。然而，在现有的小型数据集的限制下，这些自动化指标之间的性能比较受到限制。此外，这些数据集缺乏在细粒度级别评估自动化指标性能的能力。在本研究中，我们贡献了一个 EvalMuse-40K 基准，收集了 40K 个图像文本对，并针对图像文本对齐相关任务进行细粒度的标注。在构建过程中，我们采用了平衡提示采样和数据重新标注等多种策略，以确保基准的多样性和可靠性。这使我们能够全面评估图像文本对齐指标对 T2I 模型的有效性。同时，我们引入了两种新的方法来评估 T2I 模型的图像文本对齐能力：FGA-BLIP2，它涉及端到端微调视觉语言模型以生成细粒度的图像文本对齐分数；以及 PN-VQA，它在 VQA 模型中采用了一种新颖的正负 VQA 方式进行零样本细粒度评估。两种方法在图像文本对齐评估中都取得了令人瞩目的性能。我们还使用我们的方法对当前的 AIGC 模型进行排名，其结果可以作为未来研究的参考来源，并促进 T2I 生成的发展。数据和代码将公开提供。</paragraph>

##### **Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media**
2412.18148v1 by Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He

Social media platforms are experiencing a growing presence of AI-Generated
Texts (AIGTs). However, the misuse of AIGTs could have profound implications
for public opinion, such as spreading misinformation and manipulating
narratives. Despite its importance, a systematic study to assess the prevalence
of AIGTs on social media is still lacking. To address this gap, this paper aims
to quantify, monitor, and analyze the AIGTs on online social media platforms.
We first collect a dataset (SM-D) with around 2.4M posts from 3 major social
media platforms: Medium, Quora, and Reddit. Then, we construct a diverse
dataset (AIGTBench) to train and evaluate AIGT detectors. AIGTBench combines
popular open-source datasets and our AIGT datasets generated from social media
texts by 12 LLMs, serving as a benchmark for evaluating mainstream detectors.
With this setup, we identify the best-performing detector (OSM-Det). We then
apply OSM-Det to SM-D to track AIGTs over time and observe different trends of
AI Attribution Rate (AAR) across social media platforms from January 2022 to
October 2024. Specifically, Medium and Quora exhibit marked increases in AAR,
rising from 1.77% to 37.03% and 2.06% to 38.95%, respectively. In contrast,
Reddit shows slower growth, with AAR increasing from 1.31% to 2.45% over the
same period. Our further analysis indicates that AIGTs differ from
human-written texts across several dimensions, including linguistic patterns,
topic distributions, engagement levels, and the follower distribution of
authors. We envision our analysis and findings on AIGTs in social media can
shed light on future research in this domain.

摘要：<paragraph>社群媒體平台上出現越來越多由 AI 所產生的文字 (AIGT)。然而，AIGT 的誤用可能會對輿論造成深遠影響，例如散布錯誤資訊和操縱敘述。儘管其重要性，但仍缺乏系統性的研究來評估 AIGT 在社群媒體上的盛行程度。為了解決這個差距，本文旨在量化、監控和分析線上社群媒體平台上的 AIGT。我們首先從 3 個主要的社群媒體平台：Medium、Quora 和 Reddit 收集了包含約 240 萬則貼文的資料集 (SM-D)。然後，我們建構了一個多元化的資料集 (AIGTBench) 來訓練和評估 AIGT 偵測器。AIGTBench 結合了熱門的開源資料集和我們從社群媒體文字中生成的 AIGT 資料集，由 12 個 LLM 產生，作為評估主流偵測器的基準。透過此設定，我們找出效能最佳的偵測器 (OSM-Det)。接著，我們將 OSM-Det 套用至 SM-D 以追蹤 AIGT，並觀察從 2022 年 1 月到 2024 年 10 月不同社群媒體平台的 AI 歸因率 (AAR) 趨勢。具體來說，Medium 和 Quora 的 AAR 顯著增加，分別從 1.77% 上升至 37.03% 和 2.06% 上升至 38.95%。相比之下，Reddit 的成長較慢，AAR 在同一時期從 1.31% 上升至 2.45%。我們的進一步分析指出，AIGT 在語言模式、主題分佈、參與度和作者的追蹤者分佈等多個面向與人類撰寫的文字不同。我們預見我們對社群媒體中 AIGT 的分析和發現，可以為此領域的未來研究提供啟發。</paragraph>

##### **Text-Aware Adapter for Few-Shot Keyword Spotting**
2412.18142v1 by Youngmoon Jung, Jinyoung Lee, Seungjin Lee, Myunghun Jung, Yong-Hyeok Lee, Hoon-Young Cho

Recent advances in flexible keyword spotting (KWS) with text enrollment allow
users to personalize keywords without uttering them during enrollment. However,
there is still room for improvement in target keyword performance. In this
work, we propose a novel few-shot transfer learning method, called text-aware
adapter (TA-adapter), designed to enhance a pre-trained flexible KWS model for
specific keywords with limited speech samples. To adapt the acoustic encoder,
we leverage a jointly pre-trained text encoder to generate a text embedding
that acts as a representative vector for the keyword. By fine-tuning only a
small portion of the network while keeping the core components' weights intact,
the TA-adapter proves highly efficient for few-shot KWS, enabling a seamless
return to the original pre-trained model. In our experiments, the TA-adapter
demonstrated significant performance improvements across 35 distinct keywords
from the Google Speech Commands V2 dataset, with only a 0.14% increase in the
total number of parameters.

摘要：近來在具有文字註冊的彈性關鍵字點選 (KWS) 中的進展，讓使用者在註冊期間無需說出關鍵字即可個人化關鍵字。然而，目標關鍵字的表現仍有進步空間。在這項工作中，我們提出一個稱為文字感知適配器 (TA-adapter) 的新穎小樣本轉移學習方法，其設計用於增強預先訓練好的彈性 KWS 模型，以處理具有有限語音範例的特定關鍵字。為了適應音訊編碼器，我們利用一個共同預先訓練好的文字編碼器來產生文字嵌入，作為關鍵字的代表向量。透過微調網路中僅一小部分，同時保持核心元件的權重不變，TA-adapter 證明對於小樣本 KWS 而言非常有效率，讓無縫返回至原始預先訓練好的模型成為可能。在我們的實驗中，TA-adapter 在 Google 語音指令 V2 資料集中的 35 個不同關鍵字中展示出顯著的效能提升，而參數總數僅增加了 0.14%。

##### **Ensuring Consistency for In-Image Translation**
2412.18139v1 by Chengpeng Fu, Xiaocheng Feng, Yichong Huang, Wenshuai Huo, Baohang Li, Zhirui Zhang, Yunfei Lu, Dandan Tu, Duyu Tang, Hui Wang, Bing Qin, Ting Liu

The in-image machine translation task involves translating text embedded
within images, with the translated results presented in image format. While
this task has numerous applications in various scenarios such as film poster
translation and everyday scene image translation, existing methods frequently
neglect the aspect of consistency throughout this process. We propose the need
to uphold two types of consistency in this task: translation consistency and
image generation consistency. The former entails incorporating image
information during translation, while the latter involves maintaining
consistency between the style of the text-image and the original image,
ensuring background integrity. To address these consistency requirements, we
introduce a novel two-stage framework named HCIIT (High-Consistency In-Image
Translation) which involves text-image translation using a multimodal
multilingual large language model in the first stage and image backfilling with
a diffusion model in the second stage. Chain of thought learning is utilized in
the first stage to enhance the model's ability to leverage image information
during translation. Subsequently, a diffusion model trained for
style-consistent text-image generation ensures uniformity in text style within
images and preserves background details. A dataset comprising 400,000
style-consistent pseudo text-image pairs is curated for model training. Results
obtained on both curated test sets and authentic image test sets validate the
effectiveness of our framework in ensuring consistency and producing
high-quality translated images.

摘要：圖像內機器翻譯任務包含翻譯嵌入在圖像中的文字，翻譯結果以圖像格式呈現。雖然此任務在各種場景中都有許多應用，例如電影海報翻譯和日常場景圖像翻譯，現有方法經常忽略整個過程中一致性的方面。我們提出需要在此任務中維持兩種一致性：翻譯一致性和圖像生成一致性。前者需要在翻譯過程中納入圖像資訊，而後者則涉及維持文字圖像與原始圖像的風格一致性，確保背景完整性。為了滿足這些一致性需求，我們引進一個名為 HCIIT（高一致性圖像內翻譯）的新穎兩階段架構，其中包含在第一階段使用多模態多語言大型語言模型進行文字圖像翻譯，以及在第二階段使用擴散模型進行圖像回填。在第一階段利用思考鏈學習來增強模型在翻譯過程中利用圖像資訊的能力。隨後，針對風格一致的文字圖像生成訓練的擴散模型確保圖像中文字風格的一致性，並保留背景細節。整理了一個包含 400,000 個風格一致的偽文字圖像對的資料集，以進行模型訓練。在整理好的測試集和真實圖像測試集上獲得的結果驗證了我們架構在確保一致性並產生高品質翻譯圖像方面的有效性。

##### **LSAQ: Layer-Specific Adaptive Quantization for Large Language Model Deployment**
2412.18135v1 by Binrui Zeng, Bin Ji, Xiaodong Liu, Jie Yu, Shasha Li, Jun Ma, Xiaopeng Li, Shangwen Wang, Xinran Hong

As large language models (LLMs) demonstrate exceptional performance across
various domains, the deployment of these models on edge devices has emerged as
a new trend. Quantization techniques, which reduce the size and memory
footprint of LLMs, are effective for enabling deployment on
resource-constrained edge devices. However, existing one-size-fits-all
quantization methods often fail to dynamically adjust the memory consumption of
LLMs based on specific hardware characteristics and usage scenarios. To address
this limitation, we propose LSAQ (Layer-Specific Adaptive Quantization), a
system for adaptive quantization and dynamic deployment of LLMs based on layer
importance. LSAQ evaluates layer importance by constructing top-k token sets
from the inputs and outputs of each layer and calculating their Jaccard
coefficient. Using this evaluation, the system adaptively adjusts quantization
strategies in real time according to the resource availability of edge devices,
assigning different precision levels to layers of varying importance. This
approach significantly reduces the storage requirements of LLMs while
maintaining model performance, enabling efficient deployment across diverse
hardware platforms and usage scenarios.

摘要：隨著大型語言模型 (LLM) 在各種領域展現出卓越的效能，在邊緣裝置部署這些模型已成為一種新趨勢。量化技術可縮小 LLM 的大小和記憶體佔用空間，對於在資源受限的邊緣裝置上部署 LLM 來說十分有效。不過，現有的統一量化方法通常無法根據特定的硬體特性和使用情境，動態調整 LLM 的記憶體消耗。為了解決這個限制，我們提出 LSAQ（特定層自適應量化），這是一個基於層重要性的 LLM 自適應量化和動態部署系統。LSAQ 透過從每個層的輸入和輸出建構前 K 個權杖組，並計算其 Jaccard 係數，來評估層的重要性。系統使用此評估，根據邊緣裝置的資源可用性，即時自適應調整量化策略，並將不同的精確度等級指定給不同重要性的層。這種方法大幅降低了 LLM 的儲存需求，同時維持模型效能，可以在不同的硬體平台和使用情境中進行有效率的部署。

##### **Exact Acceleration of Subgraph Graph Neural Networks by Eliminating Computation Redundancy**
2412.18125v1 by Qian Tao, Xiyuan Wang, Muhan Zhang, Shuxian Hu, Wenyuan Yu, Jingren Zhou

Graph neural networks (GNNs) have become a prevalent framework for graph
tasks. Many recent studies have proposed the use of graph convolution methods
over the numerous subgraphs of each graph, a concept known as subgraph graph
neural networks (subgraph GNNs), to enhance GNNs' ability to distinguish
non-isomorphic graphs. To maximize the expressiveness, subgraph GNNs often
require each subgraph to have equal size to the original graph. Despite their
impressive performance, subgraph GNNs face challenges due to the vast number
and large size of subgraphs which lead to a surge in training data, resulting
in both storage and computational inefficiencies. In response to this problem,
this paper introduces Ego-Nets-Fit-All (ENFA), a model that uniformly takes the
smaller ego nets as subgraphs, thereby providing greater storage and
computational efficiency, while at the same time guarantees identical outputs
to the original subgraph GNNs even taking the whole graph as subgraphs. The key
is to identify and eliminate the redundant computation among subgraphs. For
example, a node $v_i$ may appear in multiple subgraphs but is far away from all
of their centers (the unsymmetric part between subgraphs). Therefore, its first
few rounds of message passing within each subgraph can be computed once in the
original graph instead of being computed multiple times within each subgraph.
Such strategy enables our ENFA to accelerate subgraph GNNs in an exact way,
unlike previous sampling approaches that often lose the performance. Extensive
experiments across various datasets reveal that compared with the conventional
subgraph GNNs, ENFA can reduce storage space by 29.0% to 84.5% and improve
training efficiency by up to 1.66x.

摘要：圖形神經網絡 (GNN) 已成為圖形任務的流行框架。許多近期研究建議在每個圖形的眾多子圖上使用圖形卷積方法，這是一個稱為子圖圖形神經網絡 (subgraph GNN) 的概念，用以提升 GNN 區分非同構圖形的能力。為了最大化表達力，子圖 GNN 通常要求每個子圖的大小與原始圖形相同。儘管效能令人印象深刻，但由於子圖數量龐大且大小不一，導致訓練資料激增，造成儲存和運算效率不彰，因此子圖 GNN 面臨挑戰。為了應對這個問題，本文介紹了 Ego-Nets-Fit-All (ENFA)，這是一個模型，它將較小的自我網路視為子圖，從而提供更大的儲存和運算效率，同時保證與原始子圖 GNN 相同的輸出，即使將整個圖形視為子圖。關鍵在於識別和消除子圖之間的重複運算。例如，節點 $v_i$ 可能出現在多個子圖中，但距離所有子圖中心都很遠（子圖之間的不對稱部分）。因此，它在每個子圖中的前幾輪訊息傳遞可以在原始圖形中計算一次，而不是在每個子圖中計算多次。這種策略使我們的 ENFA 能夠以精確的方式加速子圖 GNN，這與通常會降低效能的先前抽樣方法不同。在各種資料集上的廣泛實驗顯示，與傳統的子圖 GNN 相比，ENFA 可將儲存空間減少 29.0% 至 84.5%，並將訓練效率提升多達 1.66 倍。

##### **AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models**
2412.18123v1 by Yiming Wang, Jiahao Chen, Qingming Li, Xing Yang, Shouling Ji

As text-to-image (T2I) models continue to advance and gain widespread
adoption, their associated safety issues are becoming increasingly prominent.
Malicious users often exploit these models to generate Not-Safe-for-Work (NSFW)
images using harmful or adversarial prompts, highlighting the critical need for
robust safeguards to ensure the integrity and compliance of model outputs.
Current internal safeguards frequently degrade image quality, while external
detection methods often suffer from low accuracy and inefficiency.
  In this paper, we introduce AEIOU, a defense framework that is Adaptable,
Efficient, Interpretable, Optimizable, and Unified against NSFW prompts in T2I
models. AEIOU extracts NSFW features from the hidden states of the model's text
encoder, utilizing the separable nature of these features to detect NSFW
prompts. The detection process is efficient, requiring minimal inference time.
AEIOU also offers real-time interpretation of results and supports optimization
through data augmentation techniques. The framework is versatile, accommodating
various T2I architectures. Our extensive experiments show that AEIOU
significantly outperforms both commercial and open-source moderation tools,
achieving over 95% accuracy across all datasets and improving efficiency by at
least tenfold. It effectively counters adaptive attacks and excels in few-shot
and multi-label scenarios.

摘要：<paragraph>隨著文字到影像 (T2I) 模型持續進步並獲得廣泛採用，它們相關的安全問題也越來越突出。惡意使用者經常利用這些模型使用有害或對抗性的提示來產生不適合工作 (NSFW) 的影像，突顯了確保模型輸出完整性和合規性的強大防護措施的迫切需要。目前的內部防護措施經常會降低影像品質，而外部偵測方法則經常有準確度低和效率差的問題。在本文中，我們介紹了 AEIOU，這是一個在 T2I 模型中針對 NSFW 提示具有適應性、效率、可解釋性、可最佳化和統一性的防禦架構。AEIOU 從模型文字編碼器的隱藏狀態中提取 NSFW 特徵，利用這些特徵的可分離性質來偵測 NSFW 提示。偵測過程很有效率，只需要最少的推論時間。AEIOU 還提供結果的即時解釋，並透過資料擴充技術支援最佳化。這個架構很靈活，可以容納各種 T2I 架構。我們廣泛的實驗顯示，AEIOU 在所有資料集中的準確度都超過 95%，並且效率至少提高了十倍，顯著優於商業和開源的審核工具。它有效地對抗適應性攻擊，並在少次嘗試和多標籤場景中表現出色。</paragraph>

##### **Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm**
2412.18120v1 by Xiaoyang Hu, Richard L. Lewis

Cognitive tasks originally developed for humans are now increasingly used to
study language models. While applying these tasks is often straightforward,
interpreting their results can be challenging. In particular, when a model
underperforms, it's often unclear whether this results from a limitation in the
cognitive ability being tested or a failure to understand the task itself. A
recent study argued that GPT 3.5's declining performance on 2-back and 3-back
tasks reflects a working memory capacity limit similar to humans. By analyzing
a range of open-source language models of varying performance levels on these
tasks, we show that the poor performance instead reflects a limitation in task
comprehension and task set maintenance. In addition, we push the best
performing model to higher n values and experiment with alternative prompting
strategies, before analyzing model attentions. Our larger aim is to contribute
to the ongoing conversation around refining methodologies for the cognitive
evaluation of language models.

摘要：原本為人類開發的認知任務，現在越來越常被用來研究語言模型。雖然應用這些任務通常很直接，但要解讀其結果可能具有挑戰性。特別是當模型表現不佳時，通常不清楚這是否源於所測試認知能力的限制，或未能理解任務本身。最近的一項研究認為，GPT 3.5 在 2-back 和 3-back 任務中的表現下降反映出與人類相似的作業記憶容量限制。透過分析在這些任務中表現水準不一的各種開源語言模型，我們發現表現不佳反而反映出任務理解和任務設定維護的限制。此外，我們將表現最佳的模型推升至更高的 n 值，並嘗試使用替代提示策略，然後再分析模型注意力。我們更大的目標是為圍繞語言模型認知評估方法論的精進進行中的對話做出貢獻。

##### **AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation**
2412.18116v1 by Hao Wen, Shizuo Tian, Borislav Pavlov, Wenjie Du, Yixuan Li, Ge Chang, Shanhui Zhao, Jiacheng Liu, Yunxin Liu, Ya-Qin Zhang, Yuanchun Li

Large language models (LLMs) have brought exciting new advances to mobile UI
agents, a long-standing research field that aims to complete arbitrary natural
language tasks through mobile UI interactions. However, existing UI agents
usually demand high reasoning capabilities of powerful large models that are
difficult to be deployed locally on end-users' devices, which raises huge
concerns about user privacy and centralized serving cost. One way to reduce the
required model size is to customize a smaller domain-specific model with
high-quality training data, e.g. large-scale human demonstrations of diverse
types of apps and tasks, while such datasets are extremely difficult to obtain.
Inspired by the remarkable coding abilities of recent small language models
(SLMs), we propose to convert the UI task automation problem to a code
generation problem, which can be effectively solved by an on-device SLM and
efficiently executed with an on-device code interpreter. Unlike normal coding
tasks that can be extensively pretrained with public datasets, generating UI
automation code is challenging due to the diversity, complexity, and
variability of target apps. Therefore, we adopt a document-centered approach
that automatically builds fine-grained API documentation for each app and
generates diverse task samples based on this documentation. By guiding the
agent with the synthetic documents and task samples, it learns to generate
precise and efficient scripts to complete unseen tasks. Based on detailed
comparisons with state-of-the-art mobile UI agents, our approach effectively
improves the mobile task automation with significantly higher success rates and
lower latency/token consumption. Code will be open-sourced.

摘要：大型語言模型 (LLM) 為行動裝置使用者介面代理程式帶來令人興奮的新進展，這是一個長久以來的研究領域，旨在透過行動裝置使用者介面互動來完成任意的自然語言任務。然而，現有的使用者介面代理程式通常需要強大的大型模型的高推理能力，而這些模型難以在終端使用者的裝置上進行本地部署，這引發了對使用者隱私和集中式服務成本的極大疑慮。縮小所需模型規模的一種方法是使用高品質訓練資料自訂較小的特定領域模型，例如，各種應用程式和任務的大規模人類示範，而此類資料集極難取得。受到近期小型語言模型 (SLM) 傑出的編碼能力的啟發，我們提議將使用者介面任務自動化問題轉換為程式碼產生問題，而這可以用裝置上的 SLM 有效解決，並使用裝置上的程式碼詮釋器有效執行。與可以透過公開資料集進行廣泛預訓練的一般編碼任務不同，產生使用者介面自動化程式碼具有挑戰性，原因在於目標應用程式的多樣性、複雜性和可變性。因此，我們採用以文件為中心的途徑，為每個應用程式自動建立細緻的 API 文件，並根據此文件產生多樣化的任務範例。透過使用合成的文件和任務範例引導代理程式，它會學習產生精確且有效的指令碼，以完成前所未見的任務。根據與現今最先進的行動裝置使用者介面代理程式的詳細比較，我們的途徑有效提升了行動裝置任務自動化，成功率顯著提高，且延遲時間/權杖消耗降低。程式碼將開放原始碼。

##### **AIGT: AI Generative Table Based on Prompt**
2412.18111v1 by Mingming Zhang, Zhiqing Xiao, Guoshan Lu, Sai Wu, Weiqiang Wang, Xing Fu, Can Yi, Junbo Zhao

Tabular data, which accounts for over 80% of enterprise data assets, is vital
in various fields. With growing concerns about privacy protection and
data-sharing restrictions, generating high-quality synthetic tabular data has
become essential. Recent advancements show that large language models (LLMs)
can effectively gener-ate realistic tabular data by leveraging semantic
information and overcoming the challenges of high-dimensional data that arise
from one-hot encoding. However, current methods do not fully utilize the rich
information available in tables. To address this, we introduce AI Generative
Table (AIGT) based on prompt enhancement, a novel approach that utilizes meta
data information, such as table descriptions and schemas, as prompts to
generate ultra-high quality synthetic data. To overcome the token limit
constraints of LLMs, we propose long-token partitioning algorithms that enable
AIGT to model tables of any scale. AIGT achieves state-of-the-art performance
on 14 out of 20 public datasets and two real industry datasets within the
Alipay risk control system.

摘要：表格資料佔企業資料資產的 80% 以上，在各個領域都至關重要。隨著隱私保護和資料共享限制的疑慮日益增加，產生高品質的合成表格資料已變得至關重要。最近的進展顯示，大型語言模型 (LLM) 可以有效地透過利用語義資訊並克服由 one-hot 編碼產生的高維度資料挑戰，來產生逼真的表格資料。然而，目前的技術並未充分利用表格中豐富的資訊。為了解決這個問題，我們引入了基於提示增強的 AI 生成表格 (AIGT)，這是一種新穎的方法，它利用元資料資訊，例如表格描述和架構，作為提示來產生極高品質的合成資料。為了克服 LLM 的 token 數量限制，我們提出了長 token 分割演算法，讓 AIGT 能夠建模任何規模的表格。在 20 個公開資料集和 Alipay 風險控制系統中的兩個實際產業資料集上，AIGT 達到了 14 個最先進的效能。

##### **SlimGPT: Layer-wise Structured Pruning for Large Language Models**
2412.18110v1 by Gui Ling, Ziyang Wang, Yuliang Yan, Qingwen Liu

Large language models (LLMs) have garnered significant attention for their
remarkable capabilities across various domains, whose vast parameter scales
present challenges for practical deployment. Structured pruning is an effective
method to balance model performance with efficiency, but performance
restoration under computational resource constraints is a principal challenge
in pruning LLMs. Therefore, we present a low-cost and fast structured pruning
method for LLMs named SlimGPT based on the Optimal Brain Surgeon framework. We
propose Batched Greedy Pruning for rapid and near-optimal pruning, which
enhances the accuracy of head-wise pruning error estimation through grouped
Cholesky decomposition and improves the pruning efficiency of FFN via Dynamic
Group Size, thereby achieving approximate local optimal pruning results within
one hour. Besides, we explore the limitations of layer-wise pruning from the
perspective of error accumulation and propose Incremental Pruning Ratio, a
non-uniform pruning strategy to reduce performance degradation. Experimental
results on the LLaMA benchmark show that SlimGPT outperforms other methods and
achieves state-of-the-art results.

摘要：大型語言模型 (LLM) 因其在各個領域的卓越能力而備受關注，其龐大的參數規模對實際部署提出了挑戰。結構化剪枝是一種平衡模型效能與效率的有效方法，但在計算資源受限的情況下，效能還原是剪枝 LLM 的主要挑戰。因此，我們提出了一種名為 SlimGPT 的低成本且快速的 LLM 結構化剪枝方法，該方法基於 Optimal Brain Surgeon 框架。我們提出批次貪婪剪枝以進行快速且近乎最佳的剪枝，透過群組 Cholesky 分解來提升頭部剪枝誤差估計的準確性，並透過動態群組大小來提升 FFN 的剪枝效率，從而在大約一小時內達成近似局部最佳剪枝結果。此外，我們從誤差累積的角度探討了層級剪枝的限制，並提出增量剪枝率，這是一種非均勻的剪枝策略，可減少效能下降。LLaMA 基準上的實驗結果顯示，SlimGPT 優於其他方法，並達到了最先進的結果。

##### **SongGLM: Lyric-to-Melody Generation with 2D Alignment Encoding and Multi-Task Pre-Training**
2412.18107v1 by Jiaxing Yu, Xinda Wu, Yunfei Xu, Tieyao Zhang, Songruoyao Wu, Le Ma, Kejun Zhang

Lyric-to-melody generation aims to automatically create melodies based on
given lyrics, requiring the capture of complex and subtle correlations between
them. However, previous works usually suffer from two main challenges: 1)
lyric-melody alignment modeling, which is often simplified to
one-syllable/word-to-one-note alignment, while others have the problem of low
alignment accuracy; 2) lyric-melody harmony modeling, which usually relies
heavily on intermediates or strict rules, limiting model's capabilities and
generative diversity. In this paper, we propose SongGLM, a lyric-to-melody
generation system that leverages 2D alignment encoding and multi-task
pre-training based on the General Language Model (GLM) to guarantee the
alignment and harmony between lyrics and melodies. Specifically, 1) we
introduce a unified symbolic song representation for lyrics and melodies with
word-level and phrase-level (2D) alignment encoding to capture the lyric-melody
alignment; 2) we design a multi-task pre-training framework with hierarchical
blank infilling objectives (n-gram, phrase, and long span), and incorporate
lyric-melody relationships into the extraction of harmonized n-grams to ensure
the lyric-melody harmony. We also construct a large-scale lyric-melody paired
dataset comprising over 200,000 English song pieces for pre-training and
fine-tuning. The objective and subjective results indicate that SongGLM can
generate melodies from lyrics with significant improvements in both alignment
and harmony, outperforming all the previous baseline methods.

摘要：歌詞轉旋律的生成旨在根據給定的歌詞自動建立旋律，需要捕捉歌詞之間複雜且微妙的關聯性。然而，先前的作品通常面臨兩個主要挑戰：1) 歌詞旋律對齊建模，通常簡化為一音節/字對一音符對齊，而其他則有對齊準確度低的問題；2) 歌詞旋律和諧建模，通常嚴重依賴中間體或嚴格規則，限制了模型的能力和生成的多樣性。在本文中，我們提出了 SongGLM，一個歌詞轉旋律生成系統，利用 2D 對齊編碼和基於通用語言模型 (GLM) 的多任務預訓練來保證歌詞和旋律之間的對齊和和諧。具體來說，1) 我們引入了一個統一的符號歌曲表示，用於歌詞和旋律，並使用字級和短語級 (2D) 對齊編碼來捕捉歌詞旋律對齊；2) 我們設計了一個多任務預訓練框架，具有分層空白填充目標（n-gram、短語和長跨度），並將歌詞旋律關係納入和諧 n-gram 的提取中，以確保歌詞旋律和諧。我們還構建了一個包含超過 200,000 首英文歌曲的大規模歌詞旋律配對數據集，用於預訓練和微調。客觀和主觀結果表明，SongGLM 可以從歌詞中生成旋律，在對齊和和諧方面都有顯著改進，優於所有先前的基準方法。

##### **Tackling the Dynamicity in a Production LLM Serving System with SOTA Optimizations via Hybrid Prefill/Decode/Verify Scheduling on Efficient Meta-kernels**
2412.18106v1 by Mingcong Song, Xinru Tang, Fengfan Hou, Jing Li, Wei Wei, Yipeng Ma, Runqiu Xiao, Hongjie Si, Dingcheng Jiang, Shouyi Yin, Yang Hu, Guoping Long

Meeting growing demands for low latency and cost efficiency in
production-grade large language model (LLM) serving systems requires
integrating advanced optimization techniques. However, dynamic and
unpredictable input-output lengths of LLM, compounded by these optimizations,
exacerbate the issues of workload variability, making it difficult to maintain
high efficiency on AI accelerators, especially DSAs with tile-based programming
models. To address this challenge, we introduce XY-Serve, a versatile, Ascend
native, end-to-end production LLM-serving system. The core idea is an
abstraction mechanism that smooths out the workload variability by decomposing
computations into unified, hardware-friendly, fine-grained meta primitives. For
attention, we propose a meta-kernel that computes the basic pattern of
matmul-softmax-matmul with architectural-aware tile sizes. For GEMM, we
introduce a virtual padding scheme that adapts to dynamic shape changes while
using highly efficient GEMM primitives with assorted fixed tile sizes. XY-Serve
sits harmoniously with vLLM. Experimental results show up to 89% end-to-end
throughput improvement compared with current publicly available baselines on
Ascend NPUs. Additionally, our approach outperforms existing GEMM (average
14.6% faster) and attention (average 21.5% faster) kernels relative to existing
libraries. While the work is Ascend native, we believe the approach can be
readily applicable to SIMT architectures as well.

摘要：<paragraph>为了满足生产级大语言模型 (LLM) 服务系统对低延迟和成本效率不断增长的需求，需要集成先进的优化技术。然而，LLM 动态且不可预测的输入输出长度，加上这些优化，加剧了工作负载可变性的问题，这使得难以在 AI 加速器上保持高效率，尤其是具有基于图块的编程模型的 DSA。为了应对这一挑战，我们引入了 XY-Serve，这是一个多功能的、Ascend 原生的端到端生产 LLM 服务系统。核心思想是一种抽象机制，它通过将计算分解为统一的、硬件友好的、细粒度的元基元来平滑工作负载的可变性。对于注意力，我们提出了一个元内核，它计算具有架构感知图块大小的 matmul-softmax-matmul 的基本模式。对于 GEMM，我们引入了一种虚拟填充方案，它可以适应动态形状变化，同时使用具有各种固定图块大小的高效 GEMM 基元。XY-Serve 与 vLLM 完美契合。实验结果表明，与 Ascend NPU 上当前公开可用的基线相比，端到端吞吐量提高了 89%。此外，我们的方法优于现有的 GEMM（平均快 14.6%）和注意力（平均快 21.5%）内核，相对于现有的库而言。虽然这项工作是 Ascend 原生的，但我们相信该方法也可以很容易地应用于 SIMT 架构。</paragraph>

##### **EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent**
2412.18100v1 by Suyuan Wang, Xueqian Yin, Menghao Wang, Ruofeng Guo, Kai Nan

The rapid growth of scientific techniques and knowledge is reflected in the
exponential increase in new patents filed annually. While these patents drive
innovation, they also present significant burden for researchers and engineers,
especially newcomers. To avoid the tedious work of navigating a vast and
complex landscape to identify trends and breakthroughs, researchers urgently
need efficient tools to summarize, evaluate, and contextualize patents,
revealing their innovative contributions and underlying scientific
principles.To address this need, we present EvoPat, a multi-LLM-based patent
agent designed to assist users in analyzing patents through Retrieval-Augmented
Generation (RAG) and advanced search strategies. EvoPat leverages multiple
Large Language Models (LLMs), each performing specialized roles such as
planning, identifying innovations, and conducting comparative evaluations. The
system integrates data from local databases, including patents, literature,
product catalogous, and company repositories, and online searches to provide
up-to-date insights. The ability to collect information not included in
original database automatically is also implemented. Through extensive testing
in the natural language processing (NLP) domain, we demonstrate that EvoPat
outperforms GPT-4 in tasks such as patent summarization, comparative analysis,
and technical evaluation. EvoPat represents a significant step toward creating
AI-powered tools that empower researchers and engineers to efficiently navigate
the complexities of the patent landscape.

摘要：科學技術和知識的快速增長反映在每年申請的新專利呈指數級增長中。雖然這些專利推動了創新，但它們也給研究人員和工程師帶來了重大負擔，特別是新人。為了避免在廣闊而複雜的領域中尋找趨勢和突破的繁瑣工作，研究人員迫切需要高效的工具來總結、評估和語境化專利，揭示它們的創新貢獻和基礎科學原理。為了滿足這一需求，我們提出了 EvoPat，這是一種基於多 LLM 的專利代理，旨在通過檢索增強生成 (RAG) 和先進的搜索策略幫助用戶分析專利。EvoPat 利用多個大型語言模型 (LLM)，每個模型執行專業角色，例如規劃、識別創新和進行比較評估。該系統整合了來自本地數據庫的數據，包括專利、文獻、產品目錄和公司存儲庫，以及在線搜索，以提供最新的見解。還實現了自動收集原始數據庫中未包含的信息的能力。通過在自然語言處理 (NLP) 領域進行廣泛的測試，我們證明 EvoPat 在專利摘要、比較分析和技術評估等任務中優於 GPT-4。EvoPat 代表著邁向創造 AI 驅動工具的重要一步，這些工具使研究人員和工程師能夠有效應對專利領域的複雜性。

##### **An Attention-based Framework with Multistation Information for Earthquake Early Warnings**
2412.18099v1 by Yu-Ming Huang, Kuan-Yu Chen, Wen-Wei Lin, Da-Yi Chen

Earthquake early warning systems play crucial roles in reducing the risk of
seismic disasters. Previously, the dominant modeling system was the
single-station models. Such models digest signal data received at a given
station and predict earth-quake parameters, such as the p-phase arrival time,
intensity, and magnitude at that location. Various methods have demonstrated
adequate performance. However, most of these methods present the challenges of
the difficulty of speeding up the alarm time, providing early warning for
distant areas, and considering global information to enhance performance.
Recently, deep learning has significantly impacted many fields, including
seismology. Thus, this paper proposes a deep learning-based framework, called
SENSE, for the intensity prediction task of earthquake early warning systems.
To explicitly consider global information from a regional or national
perspective, the input to SENSE comprises statistics from a set of stations in
a given region or country. The SENSE model is designed to learn the
relationships among the set of input stations and the locality-specific
characteristics of each station. Thus, SENSE is not only expected to provide
more reliable forecasts by considering multistation data but also has the
ability to provide early warnings to distant areas that have not yet received
signals. This study conducted extensive experiments on datasets from Taiwan and
Japan. The results revealed that SENSE can deliver competitive or even better
performances compared with other state-of-the-art methods.

摘要：<paragraph>地震預警系統在降低地震災害風險中扮演著至關重要的角色。過去，最主要的建模系統是單站模型。此類模型會消化特定站接收到的訊號資料，並預測地震參數，例如該位置的 P 波到達時間、強度和規模。各種方法都已展現出足夠的效能。然而，這些方法大多面臨難以縮短警報時間、提供遠地區的預警以及考量全球資訊以提升效能的挑戰。近年來，深度學習已對許多領域產生重大影響，包括地震學。因此，本文提出一個名為 SENSE 的基於深度學習的架構，用於地震預警系統的強度預測任務。為了明確地考量區域或國家觀點的全球資訊，SENSE 的輸入包含特定區域或國家一組站的統計資料。SENSE 模型旨在學習輸入站組與每個站的特定位置特徵之間的關係。因此，預期 SENSE 不僅能透過考量多站資料提供更可靠的預測，還能提供尚未收到訊號的遠地區預警。本研究對來自臺灣和日本的資料集進行廣泛的實驗。結果顯示，與其他最先進的方法相比，SENSE 能提供具有競爭力甚至更好的效能。</paragraph>

##### **LangYa: Revolutionizing Cross-Spatiotemporal Ocean Forecasting**
2412.18097v1 by Nan Yang, Chong Wang, Meihua Zhao, Zimeng Zhao, Huiling Zheng, Bin Zhang, Jianing Wang, Xiaofeng Li

Ocean forecasting is crucial for both scientific research and societal
benefits. Currently, the most accurate forecasting systems are global ocean
forecasting systems (GOFSs), which represent the ocean state variables (OSVs)
as discrete grids and solve partial differential equations (PDEs) governing the
transitions of oceanic state variables using numerical methods. However, GOFSs
processes are computationally expensive and prone to cumulative errors.
Recently, large artificial intelligence (AI)-based models significantly boosted
forecasting speed and accuracy. Unfortunately, building a large AI ocean
forecasting system that can be considered cross-spatiotemporal and air-sea
coupled forecasts remains a significant challenge. Here, we introduce LangYa, a
cross-spatiotemporal and air-sea coupled ocean forecasting system. Results
demonstrate that the time embedding module in LangYa enables a single model to
make forecasts with lead times ranging from 1 to 7 days. The air-sea coupled
module effectively simulates air-sea interactions. The ocean self-attention
module improves network stability and accelerates convergence during training,
and the adaptive thermocline loss function improves the accuracy of thermocline
forecasting. Compared to existing numerical and AI-based ocean forecasting
systems, LangYa uses 27 years of global ocean data from the Global Ocean
Reanalysis and Simulation version 12 (GLORYS12) for training and achieves more
reliable deterministic forecasting results for OSVs. LangYa forecasting system
provides global ocean researchers with access to a powerful software tool for
accurate ocean forecasting and opens a new paradigm for ocean science.

摘要：海洋預報對於科學研究和社會效益至關重要。目前最準確的預報系統是全球海洋預報系統 (GOFS)，它將海洋狀態變數 (OSV) 表示為離散網格，並使用數值方法求解控制海洋狀態變數轉換的偏微分方程式 (PDE)。然而，GOFS 的程序在運算上很昂貴，而且容易產生累積誤差。最近，大型人工智慧 (AI) 模型大幅提升了預報速度和準確度。不幸的是，建立一個大型 AI 海洋預報系統（可以被視為跨時空耦合的空海預報）仍然是一項重大的挑戰。在此，我們介紹 LangYa，一個跨時空耦合的空海預報系統。結果證明，LangYa 中的時間嵌入模組讓單一模型能夠進行預報，領先時間從 1 到 7 天不等。空海耦合模組有效地模擬了空海交互作用。海洋自注意力模組改善了網路穩定性，並在訓練期間加速收斂，而自適應溫躍層損失函數則改善了溫躍層預報的準確度。與現有的數值和 AI 海洋預報系統相比，LangYa 使用了全球海洋再分析和模擬第 12 版 (GLORYS12) 中 27 年的全球海洋資料進行訓練，並為 OSV 達到了更可靠的確定性預報結果。LangYa 預報系統為全球海洋研究人員提供了強大的軟體工具，可以用於精確的海洋預報，並為海洋科學開啟了一個新的典範。

##### **Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**
2412.18096v1 by Yu He Ke, Liyuan Jin, Kabilan Elangovan, Bryan Wen Xi Ong, Chin Yang Oh, Jacqueline Sim, Kenny Wei-Tsen Loh, Chai Rick Soh, Jonathan Ming Hua Cheng, Aaron Kwang Yang Lee, Daniel Shu Wei Ting, Nan Liu, Hairil Rizal Abdullah

Large Language Models (LLMs) are emerging as powerful tools in healthcare,
particularly for complex, domain-specific tasks. This study describes the
development and evaluation of the PErioperative AI CHatbot (PEACH), a secure
LLM-based system integrated with local perioperative guidelines to support
preoperative clinical decision-making. PEACH was embedded with 35 institutional
perioperative protocols in the secure Claude 3.5 Sonet LLM framework within
Pair Chat (developed by Singapore Government) and tested in a silent deployment
with real-world data. Accuracy, safety, and usability were assessed. Deviations
and hallucinations were categorized based on potential harm, and user feedback
was evaluated using the Technology Acceptance Model (TAM). Updates were made
after the initial silent deployment to amend one protocol.
  In 240 real-world clinical iterations, PEACH achieved a first-generation
accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across
three iterations. The updated PEACH demonstrated improved accuracy of 97.9%
(235/240), with a statistically significant difference from the null hypothesis
of 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and
deviations were observed (both 1/240 and 2/240, respectively). Clinicians
reported that PEACH expedited decisions in 95% of cases, and inter-rater
reliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among
attendings.
  PEACH is an accurate, adaptable tool that enhances consistency and efficiency
in perioperative decision-making. Future research should explore its
scalability across specialties and its impact on clinical outcomes.

摘要：大型語言模型 (LLM) 正成為醫療保健領域強大的工具，特別適用於複雜的特定領域任務。本研究描述了圍手術期 AI 聊天機器人 (PEACH) 的開發和評估，這是一個安全的 LLM 基礎系統，與本地的圍手術期準則整合，以支援術前臨床決策制定。PEACH 嵌入 35 個機構圍手術期協定，在新加坡政府開發的 Pair Chat 中，採用安全的 Claude 3.5 Sonet LLM 架構，並在靜默部署中使用真實世界資料進行測試。評估了準確性、安全性及可用性。偏差和幻覺依潛在危害進行分類，並使用技術接受模型 (TAM) 評估使用者回饋。在最初的靜默部署後，進行更新以修正一個協定。
  在 240 個真實世界的臨床迭代中，PEACH 在三個迭代中取得 97.5% (78/80) 的第一代準確性，以及 96.7% (232/240) 的整體準確性。更新後的 PEACH 展示出 97.9% (235/240) 的準確性提升，與 95% 準確性的空假設有統計上的顯著差異 (p = 0.018，95% CI：0.952-0.991)。觀察到最小的幻覺和偏差 (分別為 1/240 和 2/240)。臨床醫生回報 PEACH 在 95% 的案例中加速了決策，而評分者間信度在 PEACH 內介於 kappa 0.772-0.893，在主治醫師之間介於 0.610-0.784。
  PEACH 是一個準確且適應性強的工具，可增進圍手術期決策制定的一致性和效率。未來的研究應探索其跨專業的可擴展性，以及其對臨床結果的影響。

##### **Molly: Making Large Language Model Agents Solve Python Problem More Logically**
2412.18093v1 by Rui Xiao, Jiong Wang, Lu Han, Na Zong, Han Wu

Applying large language models (LLMs) as teaching assists has attracted much
attention as an integral part of intelligent education, particularly in
computing courses. To reduce the gap between the LLMs and the computer
programming education expert, fine-tuning and retrieval augmented generation
(RAG) are the two mainstream methods in existing researches. However,
fine-tuning for specific tasks is resource-intensive and may diminish the
model`s generalization capabilities. RAG can perform well on reducing the
illusion of LLMs, but the generation of irrelevant factual content during
reasoning can cause significant confusion for learners. To address these
problems, we introduce the Molly agent, focusing on solving the proposed
problem encountered by learners when learning Python programming language. Our
agent automatically parse the learners' questioning intent through a
scenario-based interaction, enabling precise retrieval of relevant documents
from the constructed knowledge base. At generation stage, the agent reflect on
the generated responses to ensure that they not only align with factual content
but also effectively answer the user's queries. Extensive experimentation on a
constructed Chinese Python QA dataset shows the effectiveness of the Molly
agent, indicating an enhancement in its performance for providing useful
responses to Python questions.

摘要：將大型語言模型 (LLM) 作為教學助理已廣受關注，視為智慧教育不可或缺的一部分，特別是在運算課程中。為了縮小 LLM 與電腦程式設計教育專家之間的差距，微調和檢索擴增生成 (RAG) 是現有研究中的兩種主流方法。然而，針對特定任務進行微調需要大量資源，且可能會降低模型的概括能力。RAG 能有效降低 LLM 的錯覺，但推理過程中產生無關的事實內容可能會對學習者造成顯著的混淆。為了解決這些問題，我們引入了 Molly 代理，專注於解決學習者在學習 Python 程式語言時遇到的提議問題。我們的代理透過基於情境的互動自動解析學習者的提問意圖，從建構的知識庫中精確檢索相關文件。在生成階段，代理會反思產生的回應，以確保它們不僅與事實內容一致，還能有效回答使用者的查詢。在建構的中文 Python 問答資料集上進行廣泛的實驗，顯示了 Molly 代理的有效性，表明其在提供對 Python 問題有用的回應方面的效能有所提升。

##### **BRIDGE: Bundle Recommendation via Instruction-Driven Generation**
2412.18092v1 by Tuan-Nghia Bui, Huy-Son Nguyen, Cam-Van Nguyen Thi, Hoang-Quynh Le, Duc-Trong Le

Bundle recommendation aims to suggest a set of interconnected items to users.
However, diverse interaction types and sparse interaction matrices often pose
challenges for previous approaches in accurately predicting user-bundle
adoptions. Inspired by the distant supervision strategy and generative
paradigm, we propose BRIDGE, a novel framework for bundle recommendation. It
consists of two main components namely the correlation-based item clustering
and the pseudo bundle generation modules. Inspired by the distant supervision
approach, the former is to generate more auxiliary information, e.g.,
instructive item clusters, for training without using external data. This
information is subsequently aggregated with collaborative signals from user
historical interactions to create pseudo `ideal' bundles. This capability
allows BRIDGE to explore all aspects of bundles, rather than being limited to
existing real-world bundles. It effectively bridging the gap between user
imagination and predefined bundles, hence improving the bundle recommendation
performance. Experimental results validate the superiority of our models over
state-of-the-art ranking-based methods across five benchmark datasets.

摘要：組合推薦旨在向使用者建議一組相互關聯的項目。
然而，不同的互動類型和稀疏的互動矩陣經常對先前在準確預測使用者組合採用的方法構成挑戰。受遠程監督策略和生成範例的啟發，我們提出一個新的組合推薦框架 BRIDGE。它包含兩個主要組成部分，分別是基於相關性的項目分群和偽組合生成模組。前者受遠程監督方法的啟發，目的是在不使用外部資料的情況下產生更多輔助資訊，例如具有指導意義的項目分群，以進行訓練。此資訊隨後與來自使用者歷史互動的協作訊號彙總在一起，以建立偽的「理想」組合。此功能讓 BRIDGE 能夠探索組合的所有面向，而不僅限於現有的真實世界組合。它有效地彌合了使用者想像力和預先定義的組合之間的差距，從而提升了組合推薦的效能。實驗結果驗證了我們的模型優於五個基準資料集中的最新排名方法。

##### **AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning**
2412.18091v1 by Lixian Jing, Jianpeng Qi, Junyu Dong, Yanwei Yu

As deep neural networks (DNNs) are increasingly deployed on edge devices,
optimizing models for constrained computational resources is critical. Existing
auto-pruning methods face challenges due to the diversity of DNN models,
various operators (e.g., filters), and the difficulty in balancing pruning
granularity with model accuracy. To address these limitations, we introduce
AutoSculpt, a pattern-based automated pruning framework designed to enhance
efficiency and accuracy by leveraging graph learning and deep reinforcement
learning (DRL). AutoSculpt automatically identifies and prunes regular patterns
within DNN architectures that can be recognized by existing inference engines,
enabling runtime acceleration. Three key steps in AutoSculpt include: (1)
Constructing DNNs as graphs to encode their topology and parameter
dependencies, (2) embedding computationally efficient pruning patterns, and (3)
utilizing DRL to iteratively refine auto-pruning strategies until the optimal
balance between compression and accuracy is achieved. Experimental results
demonstrate the effectiveness of AutoSculpt across various architectures,
including ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning
rates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming
all baselines. The codes can be available at
https://anonymous.4open.science/r/AutoSculpt-DDA0

摘要：随着深度神经网络 (DNN) 越来越多地部署在边缘设备上，针对受限计算资源优化模型至关重要。现有的自动剪枝方法由于 DNN 模型的多样性、各种运算符（例如过滤器）以及平衡剪枝粒度与模型准确性的难度而面临挑战。为了解决这些限制，我们引入了 AutoSculpt，这是一个基于模式的自动剪枝框架，旨在通过利用图学习和深度强化学习 (DRL) 来提高效率和准确性。AutoSculpt 自动识别和剪枝 DNN 架构中的规则模式，这些模式可以被现有的推理引擎识别，从而实现运行时加速。AutoSculpt 中的三个关键步骤包括：(1) 将 DNN 构建为图以编码其拓扑和参数依赖关系，(2) 嵌入计算高效的剪枝模式，以及 (3) 利用 DRL 迭代优化自动剪枝策略，直到实现压缩和准确性之间的最佳平衡。实验结果证明了 AutoSculpt 在各种架构（包括 ResNet、MobileNet、VGG 和 Vision Transformer）中的有效性，实现了高达 90% 的剪枝率和近 18% 的 FLOP 减少改进，优于所有基线。代码可在 https://anonymous.4open.science/r/AutoSculpt-DDA0 获得

##### **Multi-Point Positional Insertion Tuning for Small Object Detection**
2412.18090v1 by Kanoko Goto, Takumi Karasawa, Takumi Hirose, Rei Kawakami, Nakamasa Inoue

Small object detection aims to localize and classify small objects within
images. With recent advances in large-scale vision-language pretraining,
finetuning pretrained object detection models has emerged as a promising
approach. However, finetuning large models is computationally and memory
expensive. To address this issue, this paper introduces multi-point positional
insertion (MPI) tuning, a parameter-efficient finetuning (PEFT) method for
small object detection. Specifically, MPI incorporates multiple positional
embeddings into a frozen pretrained model, enabling the efficient detection of
small objects by providing precise positional information to latent features.
Through experiments, we demonstrated the effectiveness of the proposed method
on the SODA-D dataset. MPI performed comparably to conventional PEFT methods,
including CoOp and VPT, while significantly reducing the number of parameters
that need to be tuned.

摘要：小型物件偵測旨在定位和分類影像中的小型物件。隨著大規模視覺語言預訓練的最新進展，微調預訓練物件偵測模型已成為一種有前途的方法。然而，微調大型模型在運算和記憶體方面成本很高。為了解決這個問題，本文介紹多點位置插入 (MPI) 調整，這是一種針對小型物件偵測的參數有效微調 (PEFT) 方法。具體來說，MPI 將多個位置嵌入整合到凍結的預訓練模型中，透過提供精準的位置資訊給潛在特徵，進而有效偵測小型物件。透過實驗，我們在 SODA-D 資料集上證明了所提出方法的有效性。MPI 的表現與傳統的 PEFT 方法相當，包括 CoOp 和 VPT，同時大幅減少需要調整的參數量。

##### **Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner**
2412.18086v1 by Aizierjiang Aiersilan

Motion planning is a crucial component in autonomous driving.
State-of-the-art motion planners are trained on meticulously curated datasets,
which are not only expensive to annotate but also insufficient in capturing
rarely seen critical scenarios. Failing to account for such scenarios poses a
significant risk to motion planners and may lead to incidents during testing.
An intuitive solution is to manually compose such scenarios by programming and
executing a simulator (e.g., CARLA). However, this approach incurs substantial
human costs. Motivated by this, we propose an inexpensive method for generating
diverse critical traffic scenarios to train more robust motion planners. First,
we represent traffic scenarios as scripts, which are then used by the simulator
to generate traffic scenarios. Next, we develop a method that accepts
user-specified text descriptions, which a Large Language Model (LLM) translates
into scripts using in-context learning. The output scripts are sent to the
simulator that produces the corresponding traffic scenarios. As our method can
generate abundant safety-critical traffic scenarios, we use them as synthetic
training data for motion planners. To demonstrate the value of generated
scenarios, we train existing motion planners on our synthetic data, real-world
datasets, and a combination of both. Our experiments show that motion planners
trained with our data significantly outperform those trained solely on
real-world data, showing the usefulness of our synthetic data and the
effectiveness of our data generation method. Our source code is available at
https://ezharjan.github.io/AutoSceneGen.

摘要：自動駕駛中，路徑規劃是一項關鍵的組成部分。
最先進的路徑規劃器會在經過精心策劃的資料集上進行訓練，
這些資料集的註解不僅昂貴，而且不足以捕捉
罕見的關鍵場景。無法考量這些場景會對路徑規劃器構成
重大風險，並可能在測試期間導致事故。
一個直覺的解決方案是透過程式設計和
執行模擬器（例如 CARLA）來手動撰寫這些場景。然而，這種方法會產生大量的
人力成本。有鑑於此，我們提出了一種低成本的方法來產生
各種關鍵交通場景，以訓練更強大的路徑規劃器。首先，
我們將交通場景表示為腳本，然後由模擬器
用來產生交通場景。接下來，我們開發了一種方法，接受
使用者指定的文字描述，大型語言模型 (LLM) 會使用
脈絡學習將其轉換為腳本。產出的腳本會傳送給
模擬器，模擬器會產生對應的交通場景。由於我們的
方法可以產生大量的安全關鍵交通場景，我們將其用作路徑規劃器的合成
訓練資料。為了證明生成場景的價值，我們使用我們的合成資料、真實世界
資料集以及兩者的組合，訓練現有的路徑規劃器。我們的實驗顯示，使用我們的資料訓練的路徑規劃器
明顯優於僅使用
真實世界資料訓練的路徑規劃器，這顯示了我們合成資料的用途以及
我們資料生成方法的有效性。我們的原始程式碼可在
https://ezharjan.github.io/AutoSceneGen 取得。

##### **Property Enhanced Instruction Tuning for Multi-task Molecule Generation with Large Language Models**
2412.18084v1 by Xuan Lin, Long Chen, Yile Wang, Xiangxiang Zeng, Philip S. Yu

Large language models (LLMs) are widely applied in various natural language
processing tasks such as question answering and machine translation. However,
due to the lack of labeled data and the difficulty of manual annotation for
biochemical properties, the performance for molecule generation tasks is still
limited, especially for tasks involving multi-properties constraints. In this
work, we present a two-step framework PEIT (Property Enhanced Instruction
Tuning) to improve LLMs for molecular-related tasks. In the first step, we use
textual descriptions, SMILES, and biochemical properties as multimodal inputs
to pre-train a model called PEIT-GEN, by aligning multi-modal representations
to synthesize instruction data. In the second step, we fine-tune existing
open-source LLMs with the synthesized data, the resulting PEIT-LLM can handle
molecule captioning, text-based molecule generation, molecular property
prediction, and our newly proposed multi-constraint molecule generation tasks.
Experimental results show that our pre-trained PEIT-GEN outperforms MolT5 and
BioT5 in molecule captioning, demonstrating modalities align well between
textual descriptions, structures, and biochemical properties. Furthermore,
PEIT-LLM shows promising improvements in multi-task molecule generation,
proving the scalability of the PEIT framework for various molecular tasks. We
release the code, constructed instruction data, and model checkpoints in
https://github.com/chenlong164/PEIT.

摘要：大型語言模型 (LLM) 廣泛應用於各種自然語言處理任務，例如問答和機器翻譯。然而，由於缺乏標記數據和人工標註生化特性的難度，分子生成任務的性能仍然有限，特別是對於涉及多重屬性約束的任務。在這項工作中，我們提出了一個兩步框架 PEIT（屬性增強指令調整），以改進 LLM 以進行與分子相關的任務。在第一步中，我們使用文本描述、SMILES 和生化特性作為多模態輸入，通過對齊多模態表示來預訓練一個名為 PEIT-GEN 的模型，以合成指令數據。在第二步中，我們使用合成的數據對現有的開源 LLM 進行微調，生成的 PEIT-LLM 可以處理分子標題、基於文本的分子生成、分子屬性預測以及我們新提出的多約束分子生成任務。實驗結果表明，我們預先訓練的 PEIT-GEN 在分子標題中優於 MolT5 和 BioT5，證明了文本描述、結構和生化特性之間的模態很好地對齊。此外，PEIT-LLM 在多任務分子生成中顯示出有希望的改進，證明了 PEIT 框架對各種分子任務的可擴展性。我們在 https://github.com/chenlong164/PEIT 中發布了代碼、構建的指令數據和模型檢查點。

##### **Prompt Tuning for Item Cold-start Recommendation**
2412.18082v1 by Yuezihan Jiang, Gaode Chen, Wenhan Zhang, Jingchi Wang, Yinjie Jiang, Qi Zhang, Jingjian Lin, Peng Jiang, Kaigui Bian

The item cold-start problem is crucial for online recommender systems, as the
success of the cold-start phase determines whether items can transition into
popular ones. Prompt learning, a powerful technique used in natural language
processing (NLP) to address zero- or few-shot problems, has been adapted for
recommender systems to tackle similar challenges. However, existing methods
typically rely on content-based properties or text descriptions for prompting,
which we argue may be suboptimal for cold-start recommendations due to 1)
semantic gaps with recommender tasks, 2) model bias caused by warm-up items
contribute most of the positive feedback to the model, which is the core of the
cold-start problem that hinders the recommender quality on cold-start items. We
propose to leverage high-value positive feedback, termed pinnacle feedback as
prompt information, to simultaneously resolve the above two problems. We
experimentally prove that compared to the content description proposed in
existing works, the positive feedback is more suitable to serve as prompt
information by bridging the semantic gaps. Besides, we propose item-wise
personalized prompt networks to encode pinnaclce feedback to relieve the model
bias by the positive feedback dominance problem. Extensive experiments on four
real-world datasets demonstrate the superiority of our model over
state-of-the-art methods. Moreover, PROMO has been successfully deployed on a
popular short-video sharing platform, a billion-user scale commercial
short-video application, achieving remarkable performance gains across various
commercial metrics within cold-start scenarios

摘要：物品冷啟動問題對於線上推薦系統至關重要，因為冷啟動階段的成功與否決定了物品是否能轉變為熱門物品。提示學習是一種用於自然語言處理 (NLP) 的強大技術，用於解決零次或少次嘗試問題，已經改編用於推薦系統來應對類似的挑戰。然而，現有方法通常依賴於基於內容的屬性或文字描述來提示，我們認為這對於冷啟動推薦來說可能不是最佳的，原因有 1) 與推薦任務的語義差距，2) 由於暖身物品造成模型偏差，對模型造成大部分正向回饋，這是冷啟動問題的核心，會阻礙推薦系統對冷啟動物品的推薦品質。我們提議利用高價值正向回饋，稱為頂尖回饋，作為提示資訊，同時解決上述兩個問題。我們透過實驗證明，與現有作品中提出的內容描述相比，正向回饋更適合作為提示資訊，因為它能彌合語義差距。此外，我們提出逐一物品個人化提示網路，對頂尖回饋進行編碼，以透過正向回饋主導問題來緩解模型偏差。在四個真實世界資料集上的大量實驗證明了我們的模型優於最先進的方法。此外，PROMO 已成功部署在一個熱門的短影音分享平台上，一個擁有十億使用者的商業短影音應用程式，在各種冷啟動情境下的商業指標中都獲得了顯著的效能提升

##### **COMO: Cross-Mamba Interaction and Offset-Guided Fusion for Multimodal Object Detection**
2412.18076v1 by Chang Liu, Xin Ma, Xiaochen Yang, Yuxiang Zhang, Yanni Dong

Single-modal object detection tasks often experience performance degradation
when encountering diverse scenarios. In contrast, multimodal object detection
tasks can offer more comprehensive information about object features by
integrating data from various modalities. Current multimodal object detection
methods generally use various fusion techniques, including conventional neural
networks and transformer-based models, to implement feature fusion strategies
and achieve complementary information. However, since multimodal images are
captured by different sensors, there are often misalignments between them,
making direct matching challenging. This misalignment hinders the ability to
establish strong correlations for the same object across different modalities.
In this paper, we propose a novel approach called the CrOss-Mamba interaction
and Offset-guided fusion (COMO) framework for multimodal object detection
tasks. The COMO framework employs the cross-mamba technique to formulate
feature interaction equations, enabling multimodal serialized state
computation. This results in interactive fusion outputs while reducing
computational overhead and improving efficiency. Additionally, COMO leverages
high-level features, which are less affected by misalignment, to facilitate
interaction and transfer complementary information between modalities,
addressing the positional offset challenges caused by variations in camera
angles and capture times. Furthermore, COMO incorporates a global and local
scanning mechanism in the cross-mamba module to capture features with local
correlation, particularly in remote sensing images. To preserve low-level
features, the offset-guided fusion mechanism ensures effective multiscale
feature utilization, allowing the construction of a multiscale fusion data cube
that enhances detection performance.

摘要：單模態目標偵測任務在遇到不同的場景時，經常會遇到效能下降的問題。相比之下，多模態目標偵測任務可以透過整合來自不同模態的資料，提供更全面的物體特徵資訊。目前的模態目標偵測方法通常會使用各種融合技術，包括傳統的神經網路和基於 transformer 的模型，來實作特徵融合策略和達成互補資訊。然而，由於多模態影像是由不同的感測器所擷取，因此它們之間經常會有未對齊的情況，使得直接比對具有挑戰性。這種未對齊會阻礙在不同模態中為同一個物體建立強關聯的能力。在本文中，我們提出了一個名為 CrOss-Mamba 交互和位移引導融合 (COMO) 架構的新方法，用於多模態目標偵測任務。COMO 架構採用 cross-mamba 技術來制定特徵交互方程式，實現多模態序列化狀態計算。這會產生互動式融合輸出，同時減少運算負擔並提高效率。此外，COMO 利用較不受未對齊影響的高階特徵，來促進交互並在模態之間傳遞互補資訊，解決因相機角度和擷取時間的變化而造成的定位偏移挑戰。此外，COMO 在 cross-mamba 模組中加入了全域和局部掃描機制，以擷取具有局部相關性的特徵，特別是在遙測影像中。為了保留低階特徵，位移引導融合機制確保有效的多尺度特徵利用，允許建構一個增強偵測效能的多尺度融合資料立方體。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|

#### Abstracts
##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

摘要：本研究提出了一個創新的癌症診斷和預測方法，使用可解釋的人工智慧 (XAI) 和深度學習技術。由於癌症在 2020 年造成全球近 1,000 萬人死亡，因此早期準確的診斷至關重要。傳統方法通常面臨成本、準確性和效率方面的挑戰。我們的研究開發了一個 AI 模型，它提供精確的結果並清楚地了解其決策過程，解決了深度學習模型的「黑箱」問題。通過採用 XAI 技術，我們增強了解釋性和透明度，在醫療專業人員和患者之間建立信任。我們的做法利用神經網路分析廣泛的數據集，識別癌症檢測模式。這個模型有可能通過提高醫療決策的準確性、可及性和清晰度來革新診斷，可能導致更早的檢測和更個性化的治療策略。此外，它可以使更多人獲得高品質的診斷，特別是在資源有限的環境中，有助於全球健康公平。該模型的應用範圍不僅限於癌症診斷，還可能轉變醫療決策的各個方面，並拯救全球數百萬人的生命。

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

摘要：深度學習已進步了醫學影像分類，但可解釋性挑戰阻礙了其臨床採用。本研究透過使用概念瓶頸模型 (CBM) 和多重代理檢索增強生成 (RAG) 系統進行報告生成，增強了胸部 X 光 (CXR) 分類的可解釋性。透過對視覺特徵和臨床概念之間的關係進行建模，我們建立了可解釋的概念向量，用來引導多重代理 RAG 系統生成放射科報告，以增強臨床相關性、可解釋性和透明性。使用 LLM 作為判斷者對生成的報告進行評估，確認了我們模型輸出的可解釋性和臨床實用性。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確度，並展示了強健的報告生成效能，五項關鍵指標介於 84% 到 90% 之間。這個可解釋的多重代理架構彌合了高性能 AI 與在臨床環境中進行可靠 AI 驅動 CXR 分析所需的可解釋性之間的差距。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

摘要：機器學習和人工智慧在電子健康紀錄 (EHR) 上的應用具有
臨床見解的巨大潛力。然而，這種方法由於資料異質性、稀疏性、時間錯位和標記結果有限，因此面臨重大挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特郡和南格洛斯特郡的大約一百萬名去識別化個人的連結式 EHR 資料集，以描述泌尿道感染 (UTI) 並開發專注於資料品質、公平性和透明度的預測模型。全面的資料前處理和整理管道將原始 EHR 資料轉換為適合 AI 建模的結構化格式。鑑於實際 UTI 結果的可用性有限和偏見，我們引入了一個由臨床專業知識提供資訊的 UTI 風險評估架構，以估計個人患者時間線上的 UTI 風險。使用此架構，我們建立了成對的 XGBoost 模型，以區分 UTI 風險類別，並使用可解釋的 AI 技術來識別關鍵預測因子，同時確保可解釋性。我們的研究結果揭示了不同風險群組的臨床和人口統計因素的差異，提供了對 UTI 風險分層和進展的見解。本研究展示了 AI 驅動的見解在 UTI 臨床決策中的附加價值，同時優先考慮可解釋性、透明度和公平性，強調了健全資料實務在促進健康結果中的重要性。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折的風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動能力至關重要。然而，醫療保健提供者面臨著標記數據有限和處理醫學影像困難等挑戰。本研究提出了一個新穎的多模式學習框架，該框架整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練的網路，VGG19、InceptionV3 和 ResNet50，從 X 射線影像中提取深度特徵。這些特徵使用 PCA 轉換以降低維度並專注於最相關的組成部分。基於聚類的選擇過程識別出最具代表性的組成部分，然後將這些組成部分與預處理的臨床數據結合，並通過全連接網路 (FCN) 進行最終分類。特徵重要性圖突出了關鍵變數，表明病史、BMI 和身高是主要貢獻因素，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。此框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷在臨床整合中的信任。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

摘要：<paragraph>目的：調查臨床醫生對目前自動化心電圖解讀和新的人工智慧技術的態度，以及他們對電腦輔助解讀的看法。材料和方法：我們對英國的臨床醫生進行了一系列訪談。我們的研究：(i) 探討人工智慧的潛力，特別是未來的「類人類」運算方法，以促進心電圖解讀並支持臨床決策制定，以及 (ii) 徵求他們對人工智慧演算法的可解釋性和可信度的看法。結果：我們對 23 位臨床醫生的訪談記錄進行了歸納主題分析，並找出以下主題：(i) 對目前系統缺乏信任，(ii) 對未來人工智慧應用和對這些應用的要求持正面態度，(iii) 演算法的準確性和可解釋性之間的關係，以及 (iv) 對教育、可能的技能退化，以及人工智慧對臨床能力的影響的看法。討論：臨床醫生不信任目前的電腦化方法，但歡迎未來的「人工智慧」技術。在臨床醫生相信未來的 AI 解讀準確的情況下，他們不太擔心它是否可解釋。他們也比較喜歡能以視覺方式呈現演算法結果的心電圖解讀。雖然臨床醫生不害怕失業，但他們擔心技能退化，以及需要教育員工負責任地使用人工智慧。結論：臨床醫生對人工智慧在臨床決策制定中的未來應用持正面態度。準確性是採用人工智慧的一個關鍵因素，而視覺化比目前的電腦化方法更受青睞。這被視為一種潛在的培訓和提升技能的方法，與自動化可能帶來的技能退化形成對比。</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenmüller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Compérat, Andreas Gocht, Monika Hämmerle, Niels J. Rupp, Jula Westhoff, Irene Krücken, Maximillian Seidl, Christian M. Schürch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian Hörner, Kirsten D. Mertz, Constanze Döring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

摘要：前列腺癌是全球男性最常見的癌症，其惡性程度主要根據 Gleason 評分系統使用組織病理學數據進行評估。雖然人工智慧 (AI) 在準確預測 Gleason 評分方面已展現潛力，但這些預測通常缺乏內在的可解釋性，可能會導致對人機互動的不信任。為了解決這個問題，我們引進了一個由 54 位病理學家組成的國際團隊註解的 1,015 個組織微陣列核心影像的新穎資料集。這些註解提供了詳細的局部模式描述，用於符合國際準則的 Gleason 分級。利用這個資料集，我們開發了一個基於 U-Net 架構的內在可解釋 AI 系統，該系統提供了利用病理學家術語進行預測。這種方法規避了事後可解釋性方法，同時維持或超越了直接訓練用於 Gleason 模式分割的方法的效能（Dice 分數：0.713 ± 0.003，訓練於解釋，相對於 0.691 ± 0.010，訓練於 Gleason 模式）。透過在訓練期間採用軟標籤，我們捕捉了資料中的內在不確定性，即使在觀察者間變異性高的情況下，也能在 Gleason 模式分割中產生強大的結果。透過釋出這個資料集，我們旨在鼓勵進一步研究主觀性高的醫療任務中的分割，並增進對病理學家推理過程的理解。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的一項關鍵任務，及時且準確地識別醫療狀況會對患者的結果產生重大影響。傳統機器學習和深度學習模型已在此領域取得顯著成功，但通常缺乏可解釋性，這是臨床環境中的關鍵要求。在本研究中，我們探討了神經符號方法，特別是邏輯神經網路 (LNN)，以開發可解釋的診斷預測模型。基本上，我們設計並實作了基於 LNN 的模型，該模型透過邏輯規則和可學習的閾值整合領域特定的知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（如邏輯迴歸、SVM 和隨機森林）的卓越效能，在糖尿病預測的案例研究中，達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不損害預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於精準醫療的進步，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報資料，結合先進機器學習與深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD) 的可能性。我們分析一家大型健康保險組織提供的 10 年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長期短期記憶 (LSTM) 網路）開發多個觀察視窗的預測模型。我們的研究結果顯示，LSTM 模型（尤其是 24 個月觀察視窗）在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 可加性解釋 (SHAP) 分析以增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政申報資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中已達到整體高準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知且未標籤的群體。此外，此類觀察到的效能差異的根本原因通常難以發現，阻礙了緩解措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳子集，並針對觀察到的效能差異原因制定假設。我們引入一種新的 SDM，並在胸部 X 光片中肺炎和肺不張分類的案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對廣泛使用的胸部 X 光片資料集和模型中先前觀察到但無法解釋的男性和女性患者之間的效能差異提供了解釋。我們的發現表明，在分類任務中，透過胸腔引流管和心電圖導線的存在，存在捷徑學習。這些捷徑特徵的盛行率存在基於性別的差異，似乎會導致觀察到的分類效能差距，這代表捷徑學習和模型公平性分析之間先前未受到重視的交互作用。

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人做出決定的 AI 系統都有一群利害關係人
受到這些決定的親身影響。然而，AI
系統的解釋很少能滿足這群利害關係人的資訊需求，而他們
通常都是 AI 新手。這造成了傳達資訊與
受到系統決策影響的人士（例如領域專家和決策主體）重視的資訊之間的落差。為了解決這個問題，我們提出了
「XAI 新手問題庫」，它是 XAI 問題庫的延伸，包含來自 AI 新手在兩個使用案例中的資訊需求目錄：就業
預測和健康監測。目錄涵蓋了資料、
系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在訪談中詢問了兩個 AI 系統的問題，以決定是否採用它們，並收到口頭
解釋作為回應。我們的分析顯示，參與者在收到解釋後信心有所提升，但他們的理解卻面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包
理解。此外，參與者對系統風險和好處的先前回饋影響了他們的資訊需求。認為風險高的參與者尋求解釋系統部署背後的意圖，而認為風險低的人則詢問系統的
操作。我們的研究旨在透過強調 AI 新手的資訊需求、目標和
挑戰，來支持將 AI 新手納入可解釋性工作中。我們將我們的研究結果總結為五個關鍵啟示，這些啟示可以為未來針對非專業利害關係人受眾的解釋設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

摘要：<paragraph>重要性估計器是一種可解釋性方法，用於量化深度神經網路 (DNN) 的特徵重要性。在視覺Transformer (ViT) 中，自我注意機制自然會導致注意力圖，有時會將其解釋為重要性分數，表示 ViT 模型關注哪些輸入特徵。然而，注意力圖並未考慮來自下游任務的信號。為了產生對下游任務敏感的解釋，我們開發了類別區分注意力圖 (CDAM)，這是一種基於梯度的擴充，用於估計相對於已知類別或潛在概念的特徵重要性。CDAM 根據對應的符號與分類器頭的預測相關程度，調整注意力分數。除了針對監督分類器外，CDAM 還可以通過測量 ViT 的潛在空間中的相似性來解釋選定樣本共有的任意概念。此外，我們引入了平滑 CDAM 和積分 CDAM，它們對一系列具有略微改變的符號的 CDAM 進行平均。我們的量化基準包括正確性、緊湊性和類別敏感性，與其他 7 個重要性估計器相比。香草、平滑和積分 CDAM 在所有三個基準中表現出色。特別是，我們的結果表明現有的重要性估計器可能無法提供足夠的類別敏感性。我們通過基於肺部電腦斷層掃描 (CT) 掃描訓練和解釋惡性腫瘤和生物標記預測模型，證明了 CDAM 在醫學影像中的效用。總的來說，CDAM 被證明具有高度類別區分性和語義相關性，同時提供簡潔的解釋。</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-24**|**DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**|Minghong Cai et.al.|[2412.18597v1](http://arxiv.org/abs/2412.18597v1)|[link](https://github.com/tencentarc/ditctrl)|
|**2024-12-24**|**Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention**|Mingyuan Meng et.al.|[2412.18545v1](http://arxiv.org/abs/2412.18545v1)|null|
|**2024-12-24**|**Multi-Agent Norm Perception and Induction in Distributed Healthcare**|Chao Li et.al.|[2412.18454v1](http://arxiv.org/abs/2412.18454v1)|null|
|**2024-12-24**|**Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**|Zihan Zhou et.al.|[2412.18419v1](http://arxiv.org/abs/2412.18419v1)|null|
|**2024-12-24**|**Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors**|Jinhyeok Choi et.al.|[2412.18370v1](http://arxiv.org/abs/2412.18370v1)|[link](https://github.com/bdi-lab/monti)|
|**2024-12-24**|**Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**|Yu He Ke et.al.|[2412.18096v1](http://arxiv.org/abs/2412.18096v1)|null|
|**2024-12-23**|**Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review**|Yidong Gan et.al.|[2412.18043v1](http://arxiv.org/abs/2412.18043v1)|null|
|**2024-12-23**|**Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks**|Victor Júnio Alcântara Cardoso et.al.|[2412.17975v1](http://arxiv.org/abs/2412.17975v1)|[link](https://github.com/larissafrodrigues/sickle-cell-classification-ENIAC2023)|
|**2024-12-23**|**A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON**|Vansh Nagpal et.al.|[2412.17910v1](http://arxiv.org/abs/2412.17910v1)|null|
|**2024-12-23**|**Detecting anxiety and depression in dialogues: a multi-label and explainable approach**|Francisco de Arriba-Pérez et.al.|[2412.17651v1](http://arxiv.org/abs/2412.17651v1)|null|
|**2024-12-23**|**Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey**|Zixuan Shanggua et.al.|[2412.17616v1](http://arxiv.org/abs/2412.17616v1)|null|
|**2024-12-23**|**V$^2$-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy**|Long Bai et.al.|[2412.17595v1](http://arxiv.org/abs/2412.17595v1)|null|
|**2024-12-23**|**Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework**|Aswini Kumar Patra et.al.|[2412.17587v1](http://arxiv.org/abs/2412.17587v1)|null|
|**2024-12-23**|**Empathetic Response in Audio-Visual Conversations Using Emotion Preference Optimization and MambaCompressor**|Yeonju Kim et.al.|[2412.17572v1](http://arxiv.org/abs/2412.17572v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-23**|**Applying LLM and Topic Modelling in Psychotherapeutic Contexts**|Alexander Vanin et.al.|[2412.17449v1](http://arxiv.org/abs/2412.17449v1)|null|
|**2024-12-23**|**FFA Sora, video generation as fundus fluorescein angiography simulator**|Xinyuan Wu et.al.|[2412.17346v1](http://arxiv.org/abs/2412.17346v1)|null|
|**2024-12-23**|**QTSeg: A Query Token-Based Architecture for Efficient 2D Medical Image Segmentation**|Phuong-Nam Tran et.al.|[2412.17241v1](http://arxiv.org/abs/2412.17241v1)|[link](https://github.com/tpnam0901/QTSeg)|
|**2024-12-23**|**MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching**|Ethan Cerami et.al.|[2412.17228v1](http://arxiv.org/abs/2412.17228v1)|null|
|**2024-12-22**|**COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations**|Vanessa Su et.al.|[2412.17180v1](http://arxiv.org/abs/2412.17180v1)|null|
|**2024-12-22**|**AI-Based Teat Shape and Skin Condition Prediction for Dairy Management**|Yuexing Hao et.al.|[2412.17142v1](http://arxiv.org/abs/2412.17142v1)|null|
|**2024-12-22**|**An OpenMind for 3D medical vision self-supervised learning**|Tassilo Wald et.al.|[2412.17041v1](http://arxiv.org/abs/2412.17041v1)|null|
|**2024-12-22**|**On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora**|Tzu-Chieh Chen et.al.|[2412.16976v1](http://arxiv.org/abs/2412.16976v1)|null|
|**2024-12-22**|**Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index**|Nirmalya Thakur et.al.|[2412.16925v1](http://arxiv.org/abs/2412.16925v1)|null|
|**2024-12-22**|**PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health**|Huy Vu et.al.|[2412.16882v1](http://arxiv.org/abs/2412.16882v1)|null|
|**2024-12-22**|**KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**|Kaiwen Zuo et.al.|[2412.16833v1](http://arxiv.org/abs/2412.16833v1)|null|
|**2024-12-21**|**A Comparative Study on Machine Learning Models to Classify Diseases Based on Patient Behaviour and Habits**|Elham Musaaed et.al.|[2412.16768v1](http://arxiv.org/abs/2412.16768v1)|null|
|**2024-12-21**|**From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer**|Zijiang Yang et.al.|[2412.16715v1](http://arxiv.org/abs/2412.16715v1)|null|
|**2024-12-21**|**STAMPsy: Towards SpatioTemporal-Aware Mixed-Type Dialogues for Psychological Counseling**|Jieyi Wang et.al.|[2412.16674v1](http://arxiv.org/abs/2412.16674v1)|null|
|**2024-12-21**|**Automated Bleeding Detection and Classification in Wireless Capsule Endoscopy with YOLOv8-X**|Pavan C Shekar et.al.|[2412.16624v1](http://arxiv.org/abs/2412.16624v1)|[link](https://github.com/pavan98765/auto-wcebleedgen)|
|**2024-12-21**|**Patherea: Cell Detection and Classification for the 2020s**|Dejan Štepec et.al.|[2412.16425v1](http://arxiv.org/abs/2412.16425v1)|null|
|**2024-12-21**|**Technical Report: Small Language Model for Japanese Clinical and Medicine**|Shogo Watanabe et.al.|[2412.16423v1](http://arxiv.org/abs/2412.16423v1)|null|
|**2024-12-20**|**Learning Disease Progression Models That Capture Health Disparities**|Erica Chiang et.al.|[2412.16406v1](http://arxiv.org/abs/2412.16406v1)|null|
|**2024-12-20**|**Ethics and Technical Aspects of Generative AI Models in Digital Content Creation**|Atahan Karagoz et.al.|[2412.16389v1](http://arxiv.org/abs/2412.16389v1)|null|
|**2024-12-20**|**VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation**|Bangwei Guo et.al.|[2412.16381v1](http://arxiv.org/abs/2412.16381v1)|[link](https://github.com/bangwayne/verse)|
|**2024-12-20**|**FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification**|Yicheng Gao et.al.|[2412.16373v1](http://arxiv.org/abs/2412.16373v1)|null|
|**2024-12-20**|**Improving Object Detection for Time-Lapse Imagery Using Temporal Features in Wildlife Monitoring**|Marcus Jenkins et.al.|[2412.16329v1](http://arxiv.org/abs/2412.16329v1)|[link](https://github.com/marcusjenkins01/yolov7-temporal)|
|**2024-12-20**|**Benchmarking LLMs and SLMs for patient reported outcomes**|Matteo Marengo et.al.|[2412.16291v1](http://arxiv.org/abs/2412.16291v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v1](http://arxiv.org/abs/2412.16086v1)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Applying Predictive Analytics to Occupational Health and Safety in India**|Ritwik Raj Saxena et.al.|[2412.16038v1](http://arxiv.org/abs/2412.16038v1)|null|
|**2024-12-20**|**Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**|Simon Langer et.al.|[2412.15967v1](http://arxiv.org/abs/2412.15967v1)|null|
|**2024-12-20**|**From General to Specific: Tailoring Large Language Models for Personalized Healthcare**|Ruize Shi et.al.|[2412.15957v1](http://arxiv.org/abs/2412.15957v1)|null|
|**2024-12-20**|**Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**|Yosuke Yamagishi et.al.|[2412.15907v1](http://arxiv.org/abs/2412.15907v1)|null|
|**2024-12-20**|**Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**|Jonathan Heitz et.al.|[2412.15772v1](http://arxiv.org/abs/2412.15772v1)|[link](https://github.com/jheitz/coling2025_gpt_paper)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-20**|**NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**|Zheyuan Zhang et.al.|[2412.15547v1](http://arxiv.org/abs/2412.15547v1)|null|
|**2024-12-20**|**The First Multilingual Model For The Detection of Suicide Texts**|Rodolfo Zevallos et.al.|[2412.15498v1](http://arxiv.org/abs/2412.15498v1)|null|
|**2024-12-19**|**AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**|Angela Mastrianni et.al.|[2412.15444v1](http://arxiv.org/abs/2412.15444v1)|null|
|**2024-12-19**|**GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**|G. Andrade-Miranda et.al.|[2412.15054v1](http://arxiv.org/abs/2412.15054v1)|[link](https://github.com/andrade-miranda/girafe)|
|**2024-12-19**|**RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**|Junyu Luo et.al.|[2412.14922v1](http://arxiv.org/abs/2412.14922v1)|[link](https://github.com/luo-junyu/robustft)|
|**2024-12-19**|**Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**|Pir Bakhsh Khokhar et.al.|[2412.14736v1](http://arxiv.org/abs/2412.14736v1)|null|
|**2024-12-19**|**Pitfalls of topology-aware image segmentation**|Alexander H. Berger et.al.|[2412.14619v1](http://arxiv.org/abs/2412.14619v1)|[link](https://github.com/alexanderhberger/topo-pitfalls)|
|**2024-12-19**|**CwA-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**|Youshen Zhao et.al.|[2412.14522v2](http://arxiv.org/abs/2412.14522v2)|[link](https://github.com/yossizhao/cae-t)|
|**2024-12-19**|**GenHMR: Generative Human Mesh Recovery**|Muhammad Usama Saleem et.al.|[2412.14444v1](http://arxiv.org/abs/2412.14444v1)|null|
|**2024-12-19**|**FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**|Pramit Saha et.al.|[2412.14424v1](http://arxiv.org/abs/2412.14424v1)|null|
|**2024-12-18**|**Clinical Trials Ontology Engineering with Large Language Models**|Berkan Çakır et.al.|[2412.14387v1](http://arxiv.org/abs/2412.14387v1)|null|
|**2024-12-18**|**Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**|David Restrepo et.al.|[2412.14304v1](http://arxiv.org/abs/2412.14304v1)|null|
|**2024-12-18**|**Discovering maximally consistent distribution of causal tournaments with Large Language Models**|Federico Baldo et.al.|[2412.14019v1](http://arxiv.org/abs/2412.14019v1)|null|
|**2024-12-18**|**SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**|Tong Chen et.al.|[2412.14018v1](http://arxiv.org/abs/2412.14018v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-12-18**|**Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**|Jincheol Jung et.al.|[2412.13720v1](http://arxiv.org/abs/2412.13720v1)|null|
|**2024-12-18**|**Clio: Privacy-Preserving Insights into Real-World AI Use**|Alex Tamkin et.al.|[2412.13678v1](http://arxiv.org/abs/2412.13678v1)|null|
|**2024-12-18**|**Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**|ChengAo Shen et.al.|[2412.13667v1](http://arxiv.org/abs/2412.13667v1)|null|
|**2024-12-17**|**BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**|He Cheng et.al.|[2412.13324v1](http://arxiv.org/abs/2412.13324v1)|null|
|**2024-12-17**|**In-context learning for medical image segmentation**|Eichi Takaya et.al.|[2412.13299v1](http://arxiv.org/abs/2412.13299v1)|null|
|**2024-12-17**|**Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**|Paolo Gabriel et.al.|[2412.13152v1](http://arxiv.org/abs/2412.13152v1)|[link](https://github.com/lookdeep/ai-norms-2024)|
|**2024-12-17**|**Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**|Qingqing Fang et.al.|[2412.12850v1](http://arxiv.org/abs/2412.12850v1)|[link](https://github.com/Faustinaqq/CKAAD)|
|**2024-12-17**|**Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**|Chengzhou Yu et.al.|[2412.12778v1](http://arxiv.org/abs/2412.12778v1)|null|
|**2024-12-17**|**MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**|Hritik Bansal et.al.|[2412.12661v1](http://arxiv.org/abs/2412.12661v1)|[link](https://github.com/Hritikbansal/medmax)|
|**2024-12-17**|**a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**|Pranav Rajpurkar et.al.|[2412.12629v1](http://arxiv.org/abs/2412.12629v1)|null|
|**2024-12-17**|**A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**|Deep Bhatt et.al.|[2412.12538v1](http://arxiv.org/abs/2412.12538v1)|null|
|**2024-12-17**|**Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**|Iman Khazrak et.al.|[2412.12532v1](http://arxiv.org/abs/2412.12532v1)|[link](https://github.com/imankhazrak/DDPM_X-Ray)|
|**2024-12-17**|**RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment**|Xuanzhong Chen et.al.|[2412.12475v1](http://arxiv.org/abs/2412.12475v1)|null|
|**2024-12-17**|**ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports**|Romain Hardy et.al.|[2412.15264v1](http://arxiv.org/abs/2412.15264v1)|null|
|**2024-12-16**|**Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**|Tuka Alhanai et.al.|[2412.12417v1](http://arxiv.org/abs/2412.12417v1)|[link](https://github.com/InstituteforDiseaseModeling/Bridging-the-Gap-Low-Resource-African-Languages)|
|**2024-12-16**|**The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports**|Julián N. Acosta et.al.|[2412.12042v1](http://arxiv.org/abs/2412.12042v1)|null|
|**2024-12-16**|**Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**|Devika Venugopalan et.al.|[2412.11995v1](http://arxiv.org/abs/2412.11995v1)|[link](https://github.com/devika-prog/caregiver-conversational-support-tool)|
|**2024-12-16**|**LLMs Can Simulate Standardized Patients via Agent Coevolution**|Zhuoyun Du et.al.|[2412.11716v1](http://arxiv.org/abs/2412.11716v1)|[link](https://github.com/zjumai/evopatient)|
|**2024-12-16**|**Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**|Abdelbaki Souid et.al.|[2412.11681v1](http://arxiv.org/abs/2412.11681v1)|null|
|**2024-12-16**|**BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**|Jangyeong Jeon et.al.|[2412.11671v1](http://arxiv.org/abs/2412.11671v1)|[link](https://github.com/jjy961228/biobridge)|
|**2024-12-16**|**Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases**|Purity Mugambi et.al.|[2412.11472v1](http://arxiv.org/abs/2412.11472v1)|null|
|**2024-12-16**|**FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning**|Minjun Kim et.al.|[2412.11463v1](http://arxiv.org/abs/2412.11463v1)|[link](https://github.com/danny0628/fedcar)|
|**2024-12-16**|**ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models**|Xiechi Zhang et.al.|[2412.11453v1](http://arxiv.org/abs/2412.11453v1)|null|
|**2024-12-16**|**Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**|Edward Kim et.al.|[2412.15256v1](http://arxiv.org/abs/2412.15256v1)|null|
|**2024-12-15**|**Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model**|Dafna Schwartz et.al.|[2412.11286v1](http://arxiv.org/abs/2412.11286v1)|[link](https://github.com/dafnaschwartz/hd_gait_detection_with_ssl)|
|**2024-12-15**|**Wearable Accelerometer Foundation Models for Health via Knowledge Distillation**|Salar Abbaspourazad et.al.|[2412.11276v1](http://arxiv.org/abs/2412.11276v1)|null|
|**2024-12-15**|**TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**|Lanxiang Hu et.al.|[2412.11242v2](http://arxiv.org/abs/2412.11242v2)|null|
|**2024-12-15**|**Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment**|Haisheng Lu et.al.|[2412.11186v1](http://arxiv.org/abs/2412.11186v1)|[link](https://github.com/avc2-uestc/qmedsam)|
|**2024-12-15**|**AD-LLM: Benchmarking Large Language Models for Anomaly Detection**|Tiankai Yang et.al.|[2412.11142v1](http://arxiv.org/abs/2412.11142v1)|[link](https://github.com/usc-fortis/ad-llm)|
|**2024-12-15**|**Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners**|Hezha O. Rasul et.al.|[2412.11137v1](http://arxiv.org/abs/2412.11137v1)|null|
|**2024-12-14**|**MedG-KRP: Medical Graph Knowledge Representation Probing**|Gabriel R. Rosenbaum et.al.|[2412.10982v2](http://arxiv.org/abs/2412.10982v2)|null|
|**2024-12-14**|**LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages**|Murat Gunay et.al.|[2412.10918v1](http://arxiv.org/abs/2412.10918v1)|null|
|**2024-12-14**|**Superhuman performance of a large language model on the reasoning tasks of a physician**|Peter G. Brodeur et.al.|[2412.10849v1](http://arxiv.org/abs/2412.10849v1)|null|
|**2024-12-14**|**Large Language Models for Medical Forecasting -- Foresight 2**|Zeljko Kraljevic et.al.|[2412.10848v1](http://arxiv.org/abs/2412.10848v1)|null|
|**2024-12-14**|**Transfer Learning with Active Sampling for Rapid Training and Calibration in BCI-P300 Across Health States and Multi-centre Data**|Christian Flores et.al.|[2412.17833v1](http://arxiv.org/abs/2412.17833v1)|null|
|**2024-12-14**|**Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation**|Sharmin Akter et.al.|[2412.10826v1](http://arxiv.org/abs/2412.10826v1)|null|
|**2024-12-14**|**Medical Manifestation-Aware De-Identification**|Yuan Tian et.al.|[2412.10804v1](http://arxiv.org/abs/2412.10804v1)|[link](https://github.com/tianyuan168326/mema-pytorch)|
|**2024-12-14**|**Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement**|Di Xu et.al.|[2412.10629v1](http://arxiv.org/abs/2412.10629v1)|null|
|**2024-12-14**|**A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options**|Peilong Wang et.al.|[2412.10622v1](http://arxiv.org/abs/2412.10622v1)|null|
|**2024-12-13**|**MANGO: Multimodal Acuity traNsformer for intelliGent ICU Outcomes**|Jiaqing Zhang et.al.|[2412.17832v1](http://arxiv.org/abs/2412.17832v1)|null|

#### Abstracts
##### **DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**
2412.18597v1 by Minghong Cai, Xiaodong Cun, Xiaoyu Li, Wenze Liu, Zhaoyang Zhang, Yong Zhang, Ying Shan, Xiangyu Yue

Sora-like video generation models have achieved remarkable progress with a
Multi-Modal Diffusion Transformer MM-DiT architecture. However, the current
video generation models predominantly focus on single-prompt, struggling to
generate coherent scenes with multiple sequential prompts that better reflect
real-world dynamic scenarios. While some pioneering works have explored
multi-prompt video generation, they face significant challenges including
strict training data requirements, weak prompt following, and unnatural
transitions. To address these problems, we propose DiTCtrl, a training-free
multi-prompt video generation method under MM-DiT architectures for the first
time. Our key idea is to take the multi-prompt video generation task as
temporal video editing with smooth transitions. To achieve this goal, we first
analyze MM-DiT's attention mechanism, finding that the 3D full attention
behaves similarly to that of the cross/self-attention blocks in the UNet-like
diffusion models, enabling mask-guided precise semantic control across
different prompts with attention sharing for multi-prompt video generation.
Based on our careful design, the video generated by DiTCtrl achieves smooth
transitions and consistent object motion given multiple sequential prompts
without additional training. Besides, we also present MPVBench, a new benchmark
specially designed for multi-prompt video generation to evaluate the
performance of multi-prompt generation. Extensive experiments demonstrate that
our method achieves state-of-the-art performance without additional training.

摘要：類 Sora 的影片生成模型在多模態擴散Transformer MM-DiT 架構中取得顯著進展。然而，目前的影片生成模型主要專注於單一提示，難以生成包含多個循序提示的連貫場景，而這些提示更能反映真實世界的動態場景。儘管一些開創性的作品已探索多提示影片生成，但它們面臨嚴峻的挑戰，包括嚴格的訓練資料需求、提示追蹤能力不佳以及不自然的轉換。為了解決這些問題，我們提出 DiTCtrl，這是一種在 MM-DiT 架構下首次使用的免訓練多提示影片生成方法。我們的關鍵想法是將多提示影片生成任務視為具有平滑轉換的時序影片編輯。為了達成此目標，我們首先分析 MM-DiT 的注意力機制，發現 3D 全注意力與 UNet 類擴散模型中的交叉/自我注意力區塊有類似的行為，這使得我們能夠透過注意力共享進行遮罩導引的精確語意控制，以進行多提示影片生成。根據我們的精細設計，DiTCtrl 生成的影片在給定多個循序提示的情況下，可以實現平滑的轉換和一致的物件動作，而不需要額外的訓練。此外，我們還提出了 MPVBench，這是一個專門設計用於多提示影片生成的新基準，用於評估多提示生成的效果。廣泛的實驗證明，我們的方法在沒有額外訓練的情況下，達到了最先進的效能。

##### **Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention**
2412.18545v1 by Mingyuan Meng, Michael Fulham, Lei Bi, Jinman Kim

Deformable image registration is a fundamental requirement for medical image
analysis. Recently, transformers have been widely used in deep learning-based
registration methods for their ability to capture long-range dependency via
self-attention (SA). However, the high computation and memory loads of SA
(growing quadratically with the spatial resolution) hinder transformers from
processing subtle textural information in high-resolution image features, e.g.,
at the full and half image resolutions. This limits deformable registration as
the high-resolution textural information is crucial for finding precise
pixel-wise correspondence between subtle anatomical structures.
Cross-covariance Attention (XCA), as a "transposed" version of SA that operates
across feature channels, has complexity growing linearly with the spatial
resolution, providing the feasibility of capturing long-range dependency among
high-resolution image features. However, existing XCA-based transformers merely
capture coarse global long-range dependency, which are unsuitable for
deformable image registration relying primarily on fine-grained local
correspondence. In this study, we propose to improve existing deep
learning-based registration methods by embedding a new XCA mechanism. To this
end, we design an XCA-based transformer block optimized for deformable medical
image registration, named Multi-Axis XCA (MAXCA). Our MAXCA serves as a general
network block that can be embedded into various registration network
architectures. It can capture both global and local long-range dependency among
high-resolution image features by applying regional and dilated XCA in parallel
via a multi-axis design. Extensive experiments on two well-benchmarked
inter-/intra-patient registration tasks with seven public medical datasets
demonstrate that our MAXCA block enables state-of-the-art registration
performance.

摘要：可變形影像配準是醫學影像分析的基本需求。最近，Transformer已廣泛用於基於深度學習的配準方法，因為它們能透過自我注意 (SA) 擷取長程依賴性。然而，SA 的高運算和記憶體負載（隨著空間解析度呈二次成長）會阻礙Transformer處理高解析度影像特徵中的細微紋理資訊，例如在完整和半影像解析度中。這限制了可變形配準，因為高解析度紋理資訊對於在細微解剖結構之間找到精確的像素對應至關重要。跨協方差注意 (XCA) 作為 SA 的「轉置」版本，其運作跨特徵通道，複雜度隨著空間解析度呈線性成長，提供擷取高解析度影像特徵之間長程依賴性的可行性。然而，現有的基於 XCA 的Transformer僅擷取粗略的全局長程依賴性，這不適合主要依賴細粒度局部對應的可變形影像配準。在本研究中，我們提出透過嵌入新的 XCA 機制來改善現有的基於深度學習的配準方法。為此，我們設計了一個針對可變形醫學影像配準最佳化的基於 XCA 的Transformer區塊，稱為多軸 XCA (MAXCA)。我們的 MAXCA 是一個通用網路區塊，可以嵌入到各種配準網路架構中。它可以透過多軸設計並行應用區域和膨脹的 XCA，來擷取高解析度影像特徵之間的全局和局部長程依賴性。在兩個廣泛基準化的患者間/患者內配準任務中，使用七個公共醫學資料集進行的廣泛實驗證明，我們的 MAXCA 區塊能實現最先進的配準效能。

##### **Multi-Agent Norm Perception and Induction in Distributed Healthcare**
2412.18454v1 by Chao Li, Olga Petruchik, Elizaveta Grishanina, Sergey Kovalchuk

This paper presents a Multi-Agent Norm Perception and Induction Learning
Model aimed at facilitating the integration of autonomous agent systems into
distributed healthcare environments through dynamic interaction processes. The
nature of the medical norm system and its sharing channels necessitates
distinct approaches for Multi-Agent Systems to learn two types of norms.
Building on this foundation, the model enables agents to simultaneously learn
descriptive norms, which capture collective tendencies, and prescriptive norms,
which dictate ideal behaviors. Through parameterized mixed probability density
models and practice-enhanced Markov games, the multi-agent system perceives
descriptive norms in dynamic interactions and captures emergent prescriptive
norms. We conducted experiments using a dataset from a neurological medical
center spanning from 2016 to 2020.

摘要：本文提出了一個多主體規範感知與歸納學習模型，旨在透過動態互動程序促進自主主體系統整合到分散式醫療保健環境中。醫療規範系統的本質及其共享管道需要不同的方法，讓多主體系統學習兩種規範。基於此基礎，該模型讓主體能夠同時學習描述性規範（捕捉集體傾向）和規範性規範（規定理想行為）。透過參數化混合機率密度模型和實務增強馬可夫博弈，多主體系統在動態互動中感知描述性規範，並捕捉新興的規範性規範。我們使用 2016 年至 2020 年期間一個神經醫學醫療中心的数据集進行了實驗。

##### **Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models**
2412.18419v1 by Zihan Zhou, Ziyi Zeng, Wenhao Jiang, Yihui Zhu, Jiaxin Mao, Yonggui Yuan, Min Xia, Shubin Zhao, Mengyu Yao, Yunqian Chen

As social changes accelerate, the incidence of psychosomatic disorders has
significantly increased, becoming a major challenge in global health issues.
This necessitates an innovative knowledge system and analytical methods to aid
in diagnosis and treatment. Here, we establish the ontology model and entity
types, using the BERT model and LoRA-tuned LLM for named entity recognition,
constructing the knowledge graph with 9668 triples. Next, by analyzing the
network distances between disease, symptom, and drug modules, it was found that
closer network distances among diseases can predict greater similarities in
their clinical manifestations, treatment approaches, and psychological
mechanisms, and closer distances between symptoms indicate that they are more
likely to co-occur. Lastly, by comparing the proximity d and proximity z score,
it was shown that symptom-disease pairs in primary diagnostic relationships
have a stronger association and are of higher referential value than those in
diagnostic relationships. The research results revealed the potential
connections between diseases, co-occurring symptoms, and similarities in
treatment strategies, providing new perspectives for the diagnosis and
treatment of psychosomatic disorders and valuable information for future mental
health research and practice.

摘要：隨著社會變遷加速，心身疾病發生率顯著增加，成為全球衛生議題上的重大挑戰。這需要創新的知識體系與分析方法，以協助診斷與治療。在此，我們建立了本体模型與實體類型，利用 BERT 模型與 LoRA 調校過的 LLM 進行命名實體辨識，建構出 9668 個三元組的知識圖譜。接著，透過分析疾病、症狀、藥物模組間的網路距離，發現疾病間較近的網路距離，可預測其臨床表現、治療方式、心理機轉的相似性較高；而症狀間距離較近，則表示較可能共現。最後，透過比較接近度 d 與接近度 z 分數，發現初次診斷關係中的症狀-疾病對，其關聯性較強、參考價值較高，優於診斷關係中的症狀-疾病對。研究成果揭示了疾病、共現症狀、治療策略間的潛在關聯，為心身疾病的診斷與治療提供了新的觀點，也為未來心理健康研究與實務提供了寶貴的資訊。

##### **Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks against GNN-Based Fraud Detectors**
2412.18370v1 by Jinhyeok Choi, Heehyeon Kim, Joyce Jiyoung Whang

Graph neural networks (GNNs) have emerged as an effective tool for fraud
detection, identifying fraudulent users, and uncovering malicious behaviors.
However, attacks against GNN-based fraud detectors and their risks have rarely
been studied, thereby leaving potential threats unaddressed. Recent findings
suggest that frauds are increasingly organized as gangs or groups. In this
work, we design attack scenarios where fraud gangs aim to make their fraud
nodes misclassified as benign by camouflaging their illicit activities in
collusion. Based on these scenarios, we study adversarial attacks against
GNN-based fraud detectors by simulating attacks of fraud gangs in three
real-world fraud cases: spam reviews, fake news, and medical insurance frauds.
We define these attacks as multi-target graph injection attacks and propose
MonTi, a transformer-based Multi-target one-Time graph injection attack model.
MonTi simultaneously generates attributes and edges of all attack nodes with a
transformer encoder, capturing interdependencies between attributes and edges
more effectively than most existing graph injection attack methods that
generate these elements sequentially. Additionally, MonTi adaptively allocates
the degree budget for each attack node to explore diverse injection structures
involving target, candidate, and attack nodes, unlike existing methods that fix
the degree budget across all attack nodes. Experiments show that MonTi
outperforms the state-of-the-art graph injection attack methods on five
real-world graphs.

摘要：圖形神經網路 (GNN) 已成為一種有效的欺詐偵測工具，用於識別欺詐使用者並揭露惡意行為。然而，針對基於 GNN 的欺詐偵測器及其風險的攻擊鮮少受到研究，因此潛在威脅未獲得解決。最近的研究結果顯示，欺詐行為正日益以幫派或團體的方式組織起來。在這項研究中，我們設計了攻擊場景，其中欺詐幫派旨在透過共謀偽裝其非法活動，讓他們的欺詐節點被誤分類為良性。基於這些場景，我們透過模擬三起真實世界的欺詐案件（垃圾評論、假新聞和醫療保險欺詐）中欺詐幫派的攻擊，研究針對基於 GNN 的欺詐偵測器的對抗性攻擊。我們將這些攻擊定義為多目標圖形注入攻擊，並提出 MonTi，一種基於 Transformer 的多目標一次性圖形注入攻擊模型。MonTi 同時利用 Transformer 編碼器生成所有攻擊節點的屬性和邊緣，比大多數現有的圖形注入攻擊方法更有效地捕捉屬性和邊緣之間的相互依賴性，這些方法會依序生成這些元素。此外，與固定所有攻擊節點的度數預算的現有方法不同，MonTi 會自適應地分配每個攻擊節點的度數預算，以探索涉及目標、候選和攻擊節點的多樣化注入結構。實驗顯示，MonTi 在五個真實世界的圖形上優於最先進的圖形注入攻擊方法。

##### **Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine**
2412.18096v1 by Yu He Ke, Liyuan Jin, Kabilan Elangovan, Bryan Wen Xi Ong, Chin Yang Oh, Jacqueline Sim, Kenny Wei-Tsen Loh, Chai Rick Soh, Jonathan Ming Hua Cheng, Aaron Kwang Yang Lee, Daniel Shu Wei Ting, Nan Liu, Hairil Rizal Abdullah

Large Language Models (LLMs) are emerging as powerful tools in healthcare,
particularly for complex, domain-specific tasks. This study describes the
development and evaluation of the PErioperative AI CHatbot (PEACH), a secure
LLM-based system integrated with local perioperative guidelines to support
preoperative clinical decision-making. PEACH was embedded with 35 institutional
perioperative protocols in the secure Claude 3.5 Sonet LLM framework within
Pair Chat (developed by Singapore Government) and tested in a silent deployment
with real-world data. Accuracy, safety, and usability were assessed. Deviations
and hallucinations were categorized based on potential harm, and user feedback
was evaluated using the Technology Acceptance Model (TAM). Updates were made
after the initial silent deployment to amend one protocol.
  In 240 real-world clinical iterations, PEACH achieved a first-generation
accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across
three iterations. The updated PEACH demonstrated improved accuracy of 97.9%
(235/240), with a statistically significant difference from the null hypothesis
of 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and
deviations were observed (both 1/240 and 2/240, respectively). Clinicians
reported that PEACH expedited decisions in 95% of cases, and inter-rater
reliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among
attendings.
  PEACH is an accurate, adaptable tool that enhances consistency and efficiency
in perioperative decision-making. Future research should explore its
scalability across specialties and its impact on clinical outcomes.

摘要：大型語言模型 (LLM) 正成為醫療保健領域強大的工具，特別適用於複雜的特定領域任務。本研究描述了圍手術期 AI 聊天機器人 (PEACH) 的開發和評估，這是一個安全的 LLM 基礎系統，與本地的圍手術期準則整合，以支援術前臨床決策制定。PEACH 嵌入 35 個機構圍手術期協定，在新加坡政府開發的 Pair Chat 中，採用安全的 Claude 3.5 Sonet LLM 架構，並在靜默部署中使用真實世界資料進行測試。評估了準確性、安全性及可用性。偏差和幻覺依潛在危害進行分類，並使用技術接受模型 (TAM) 評估使用者回饋。在最初的靜默部署後，進行更新以修正一個協定。
  在 240 個真實世界的臨床迭代中，PEACH 在三個迭代中取得 97.5% (78/80) 的第一代準確性，以及 96.7% (232/240) 的整體準確性。更新後的 PEACH 展示出 97.9% (235/240) 的準確性提升，與 95% 準確性的空假設有統計上的顯著差異 (p = 0.018，95% CI：0.952-0.991)。觀察到最小的幻覺和偏差 (分別為 1/240 和 2/240)。臨床醫生回報 PEACH 在 95% 的案例中加速了決策，而評分者間信度在 PEACH 內介於 kappa 0.772-0.893，在主治醫師之間介於 0.610-0.784。
  PEACH 是一個準確且適應性強的工具，可增進圍手術期決策制定的一致性和效率。未來的研究應探索其跨專業的可擴展性，以及其對臨床結果的影響。

##### **Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review**
2412.18043v1 by Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld

Clinical coding is crucial for healthcare billing and data analysis. Manual
clinical coding is labour-intensive and error-prone, which has motivated
research towards full automation of the process. However, our analysis, based
on US English electronic health records and automated coding research using
these records, shows that widely used evaluation methods are not aligned with
real clinical contexts. For example, evaluations that focus on the top 50 most
common codes are an oversimplification, as there are thousands of codes used in
practice. This position paper aims to align AI coding research more closely
with practical challenges of clinical coding. Based on our analysis, we offer
eight specific recommendations, suggesting ways to improve current evaluation
methods. Additionally, we propose new AI-based methods beyond automated coding,
suggesting alternative approaches to assist clinical coders in their workflows.

摘要：臨床編碼對於醫療保健計費和數據分析至關重要。手動臨床編碼勞力密集且容易出錯，這促使研究朝向流程的全面自動化。然而，我們的分析基於美國英文電子健康記錄和使用這些記錄的自動編碼研究，顯示廣泛使用的評估方法與實際臨床背景不符。例如，專注於前 50 個最常見代碼的評估過於簡化，因為實務上使用了數千個代碼。本立場文件旨在讓 AI 編碼研究更貼近臨床編碼的實際挑戰。根據我們的分析，我們提出八項具體建議，提出改善目前評估方法的方法。此外，我們提出超越自動編碼的新 AI 方法，提出協助臨床編碼人員進行工作流程的替代方法。

##### **Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks**
2412.17975v1 by Victor Júnio Alcântara Cardoso, Rodrigo Moreira, João Fernando Mari, Larissa Ferreira Rodrigues Moreira

Sickle cell anemia, which is characterized by abnormal erythrocyte
morphology, can be detected using microscopic images. Computational techniques
in medicine enhance the diagnosis and treatment efficiency. However, many
computational techniques, particularly those based on Convolutional Neural
Networks (CNNs), require high resources and time for training, highlighting the
research opportunities in methods with low computational overhead. In this
paper, we propose a novel approach combining conventional classifiers,
segmented images, and CNNs for the automated classification of sickle cell
disease. We evaluated the impact of segmented images on classification,
providing insight into deep learning integration. Our results demonstrate that
using segmented images and CNN features with an SVM achieves an accuracy of
96.80%. This finding is relevant for computationally efficient scenarios,
paving the way for future research and advancements in medical-image analysis.

摘要：镰状细胞贫血症的特征是红细胞形态异常，可通过显微镜图像检测。医学中的计算技术提高了诊断和治疗效率。然而，许多计算技术，特别是基于卷积神经网络 (CNN) 的技术，需要大量的资源和时间进行训练，这突出了低计算开销方法的研究机会。在本文中，我们提出了一种新颖的方法，结合传统分类器、分割图像和 CNN，用于镰状细胞病的自动化分类。我们评估了分割图像对分类的影响，提供了对深度学习集成的见解。我们的结果表明，使用分割图像和 CNN 特征与 SVM 一起使用可实现 96.80% 的准确率。这一发现与计算效率高的场景相关，为医学图像分析的未来研究和进步铺平了道路。

##### **A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON**
2412.17910v1 by Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Nitin Gupta, Zach Abdulrahman, Andrew Davison, Biplav Srivastava

"A common decision made by people, whether healthy or with health conditions,
is choosing meals like breakfast, lunch, and dinner, comprising combinations of
foods for appetizer, main course, side dishes, desserts, and beverages. Often,
this decision involves tradeoffs between nutritious choices (e.g., salt and
sugar levels, nutrition content) and convenience (e.g., cost and accessibility,
cuisine type, food source type). We present a data-driven solution for meal
recommendations that considers customizable meal configurations and time
horizons. This solution balances user preferences while accounting for food
constituents and cooking processes. Our contributions include introducing
goodness measures, a recipe conversion method from text to the recently
introduced multimodal rich recipe representation (R3) format, learning methods
using contextual bandits that show promising preliminary results, and the
prototype, usage-inspired, BEACON system."

摘要：「無論是健康或患有健康狀況的人，都會做出的常見決定，
是選擇像早餐、午餐和晚餐等餐點，包括開胃菜、主菜、配菜、甜點和飲料的組合。通常，
這個決定涉及營養選擇（例如鹽和糖的含量、營養成分）和便利性（例如成本和可取得性、菜系類型、食物來源類型）之間的權衡。我們提出一個資料驅動的解決方案，用於餐點推薦，它考量了可自訂的餐點配置和時間範圍。這個解決方案在考量食物成分和烹飪過程的同時，平衡了使用者的喜好。我們的貢獻包括引進優良措施、從文字到最近推出的多模式豐富食譜表示法 (R3) 格式的食譜轉換方法、使用情境強盜的學習方法，這些方法顯示出有希望的初步結果，以及原型、使用靈感的 BEACON 系統。」

##### **Detecting anxiety and depression in dialogues: a multi-label and explainable approach**
2412.17651v1 by Francisco de Arriba-Pérez, Silvia García-Méndez

Anxiety and depression are the most common mental health issues worldwide,
affecting a non-negligible part of the population. Accordingly, stakeholders,
including governments' health systems, are developing new strategies to promote
early detection and prevention from a holistic perspective (i.e., addressing
several disorders simultaneously). In this work, an entirely novel system for
the multi-label classification of anxiety and depression is proposed. The input
data consists of dialogues from user interactions with an assistant chatbot.
Another relevant contribution lies in using Large Language Models (LLMs) for
feature extraction, provided the complexity and variability of language. The
combination of LLMs, given their high capability for language understanding,
and Machine Learning (ML) models, provided their contextual knowledge about the
classification problem thanks to the labeled data, constitute a promising
approach towards mental health assessment. To promote the solution's
trustworthiness, reliability, and accountability, explainability descriptions
of the model's decision are provided in a graphical dashboard. Experimental
results on a real dataset attain 90 % accuracy, improving those in the prior
literature. The ultimate objective is to contribute in an accessible and
scalable way before formal treatment occurs in the healthcare systems.

摘要：焦慮和憂鬱症是全球最常見的心理健康問題，
影響著人口中不可忽視的一部分。因此，利益相關者，
包括政府的衛生系統，正在制定新的策略來促進
從整體角度及早發現和預防（即同時解決
多種疾病）。在這項工作中，一個完全新穎的系統
用於焦慮和憂鬱症的多標籤分類。輸入
資料包含使用者與助理聊天機器人互動的對話。
另一個相關的貢獻在於使用大型語言模型 (LLM) 進行
特徵萃取，提供了語言的複雜性和可變性。LLM 的組合，
由於它們對語言理解的高能力，以及機器學習 (ML) 模型，
由於它們對分類問題的背景知識，這要歸功於標籤資料，
構成了一種有希望的心理健康評估方法。為了促進解決方案的
可信度、可靠性和問責制，模型決策的可解釋性描述
在圖形儀表板中提供。在真實資料集上的實驗結果達到 90% 的準確度，
改進了先前文獻中的準確度。最終目標是以一種可訪問且
可擴展的方式做出貢獻，在醫療保健系統中進行正式治療之前。

##### **Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey**
2412.17616v1 by Zixuan Shanggua, Yanjie Dong, Song Guo, Victor C. M. Leung, M. Jamal Deen, Xiping Hu

Facial expressions convey human emotions and can be categorized into
macro-expressions (MaEs) and micro-expressions (MiEs) based on duration and
intensity. While MaEs are voluntary and easily recognized, MiEs are
involuntary, rapid, and can reveal concealed emotions. The integration of
facial expression analysis with Internet-of-Thing (IoT) systems has significant
potential across diverse scenarios. IoT-enhanced MaE analysis enables real-time
monitoring of patient emotions, facilitating improved mental health care in
smart healthcare. Similarly, IoT-based MiE detection enhances surveillance
accuracy and threat detection in smart security. This work aims at providing a
comprehensive overview of research progress in facial expression analysis and
explores its integration with IoT systems. We discuss the distinctions between
our work and existing surveys, elaborate on advancements in MaE and MiE
techniques across various learning paradigms, and examine their potential
applications in IoT. We highlight challenges and future directions for the
convergence of facial expression-based technologies and IoT systems, aiming to
foster innovation in this domain. By presenting recent developments and
practical applications, this study offers a systematic understanding of how
facial expression analysis can enhance IoT systems in healthcare, security, and
beyond.

摘要：面部表情傳達人類的情緒，並可根據持續時間和強度分為宏觀表情（MaE）和微表情（MiE）。雖然 MaE 是自願且易於識別的，但 MiE 是非自願的、快速的，並且可以揭示隱藏的情緒。面部表情分析與物聯網（IoT）系統的整合在不同場景中具有顯著的潛力。增強型 MaE 分析的 IoT 可實現對患者情緒的實時監控，促進智慧醫療中的心理保健改善。類似地，基於 IoT 的 MiE 檢測增強了智慧安全中的監控準確性和威脅檢測。這項工作旨在提供面部表情分析研究進展的全面概述，並探討其與 IoT 系統的整合。我們討論了我們的工作與現有調查之間的區別，闡述了各種學習範例中 MaE 和 MiE 技術的進步，並探討了它們在 IoT 中的潛在應用。我們強調了基於面部表情的技術與 IoT 系統融合的挑戰和未來方向，旨在促進這一領域的創新。通過展示最近的發展和實際應用，本研究提供了面部表情分析如何增強醫療保健、安全等方面的 IoT 系統的系統性理解。

##### **V$^2$-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy**
2412.17595v1 by Long Bai, Beilei Cui, Liangyu Wang, Yanheng Li, Shilong Yao, Sishen Yuan, Yanan Wu, Yang Zhang, Max Q. -H. Meng, Zhen Li, Weiping Ding, Hongliang Ren

Deep learning can predict depth maps and capsule ego-motion from capsule
endoscopy videos, aiding in 3D scene reconstruction and lesion localization.
However, the collisions of the capsule endoscopies within the gastrointestinal
tract cause vibration perturbations in the training data. Existing solutions
focus solely on vision-based processing, neglecting other auxiliary signals
like vibrations that could reduce noise and improve performance. Therefore, we
propose V$^2$-SfMLearner, a multimodal approach integrating vibration signals
into vision-based depth and capsule motion estimation for monocular capsule
endoscopy. We construct a multimodal capsule endoscopy dataset containing
vibration and visual signals, and our artificial intelligence solution develops
an unsupervised method using vision-vibration signals, effectively eliminating
vibration perturbations through multimodal learning. Specifically, we carefully
design a vibration network branch and a Fourier fusion module, to detect and
mitigate vibration noises. The fusion framework is compatible with popular
vision-only algorithms. Extensive validation on the multimodal dataset
demonstrates superior performance and robustness against vision-only
algorithms. Without the need for large external equipment, our V$^2$-SfMLearner
has the potential for integration into clinical capsule robots, providing
real-time and dependable digestive examination tools. The findings show promise
for practical implementation in clinical settings, enhancing the diagnostic
capabilities of doctors.

摘要：深度學習可以從膠囊內視鏡影片預測深度圖和膠囊自我運動，協助進行 3D 場景重建和病灶定位。
然而，膠囊內視鏡在胃腸道內的碰撞會造成訓練資料中的振動擾動。現有的解決方案僅專注於基於視覺的處理，忽略了其他輔助訊號，例如可以降低雜訊和提升效能的振動。因此，我們提出 V$^2$-SfMLearner，這是一種多模態方法，將振動訊號整合到基於視覺的深度和膠囊運動估計中，用於單眼膠囊內視鏡。我們建構了一個包含振動和視覺訊號的多模態膠囊內視鏡資料集，而我們的人工智慧解決方案使用視覺振動訊號開發了一種非監督式方法，透過多模態學習有效消除振動擾動。具體來說，我們仔細設計了一個振動網路分支和一個傅立葉融合模組，以偵測和減輕振動雜訊。融合架構與常見的純視覺演算法相容。在多模態資料集上的廣泛驗證證明了與純視覺演算法相比，其具有優異的效能和穩健性。我們的 V$^2$-SfMLearner 無需大型外部設備，有潛力整合到臨床膠囊機器人中，提供即時且可靠的消化道檢查工具。研究結果顯示在臨床環境中實際執行的可能性，提升醫師的診斷能力。

##### **Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework**
2412.17587v1 by Aswini Kumar Patra, Tejashwini Gajurel

Cotton crops, often called "white gold," face significant production
challenges, primarily due to various leaf-affecting diseases. As a major global
source of fiber, timely and accurate disease identification is crucial to
ensure optimal yields and maintain crop health. While deep learning and machine
learning techniques have been explored to address this challenge, there remains
a gap in developing lightweight models with fewer parameters which could be
computationally effective for agricultural practitioners. To address this, we
propose an innovative deep learning framework integrating a subset of trainable
layers from MobileNet, transfer learning, data augmentation, a learning rate
decay schedule, model checkpoints, and early stopping mechanisms. Our model
demonstrates exceptional performance, accurately classifying seven cotton
disease types with an overall accuracy of 98.42% and class-wise precision
ranging from 96% to 100%. This results in significantly enhanced efficiency,
surpassing recent approaches in accuracy and model complexity. The existing
models in the literature have yet to attain such high accuracy, even when
tested on data sets with fewer disease types. The substantial performance
improvement, combined with the lightweight nature of the model, makes it
practically suitable for real-world applications in smart farming. By offering
a high-performing and efficient solution, our framework can potentially address
challenges in cotton cultivation, contributing to sustainable agricultural
practices.

摘要：棉花作物常被称为「白色黄金」，但會面臨重大的生產挑戰，主要是因為各種影響葉子的疾病。作為全球主要的纖維來源，及時且準確地辨識疾病對於確保最佳產量和維持作物健康至關重要。儘管深度學習和機器學習技術已被探索用於解決此挑戰，但對於開發具有較少參數的輕量級模型仍存在差距，而這些模型對於農業從業者而言在運算上可能有效。為了解決此問題，我們提出一個創新的深度學習架構，整合了來自 MobileNet 的可訓練層子集、遷移學習、資料擴充、學習率衰減時間表、模型檢查點和早期停止機制。我們的模型展現了非凡的效能，準確地分類了七種棉花疾病類型，整體準確度為 98.42%，且類別準確度介於 96% 到 100% 之間。這導致顯著提升的效率，在準確度和模型複雜度上超越了最近的方法。文獻中的現有模型尚未達到如此高的準確度，即使在較少疾病類型的資料集上進行測試時也是如此。大幅提升的效能，加上模型的輕量級特性，使其在智慧農業的實際應用中具有實用性。透過提供高性能且高效的解決方案，我們的架構有可能解決棉花種植中的挑戰，進而促成永續的農業實務。

##### **Empathetic Response in Audio-Visual Conversations Using Emotion Preference Optimization and MambaCompressor**
2412.17572v1 by Yeonju Kim, Se Jin Park, Yong Man Ro

Chatbot research is advancing with the growing importance of chatbots in
fields that require human interactions, such as customer support and mental
health care. Despite these advancements, chatbots still face significant
challenges in understanding subtle nuances and managing long conversation
histories. To address these issues, our study introduces a dual approach:
firstly, we employ Emotional Preference Optimization (EPO) to train chatbots
not only with correct responses but also with counter-emotional responses-those
that are contextually similar but emotionally divergent. This training enables
the model to discern fine nuance distinctions between correct and
counter-emotional responses, thereby enhancing the quality of its responses.
Secondly, we introduce MambaCompressor to effectively compress and manage
extensive conversation histories, significantly reducing time and memory
complexities while improving the chatbot's contextual understanding. Our
comprehensive experiments across multiple datasets demonstrate that our model
significantly outperforms existing models in generating empathetic responses
and efficiently managing lengthy dialogues.

摘要：聊天機器人的研究隨著聊天機器人在需要人類互動的領域（例如客戶支援和心理保健）中日益重要而進展。儘管有這些進展，聊天機器人在理解微妙的細微差別和管理冗長的對話記錄方面仍然面臨重大挑戰。為了解決這些問題，我們的研究引入了一個雙重方法：首先，我們採用情緒偏好最佳化 (EPO) 來訓練聊天機器人，不僅使用正確的回應，還使用反情緒回應——那些在語境上相似但在情緒上不同的回應。這種訓練使模型能夠辨別正確和反情緒回應之間的細微差別，從而提高其回應的品質。其次，我們引入了 MambaCompressor 來有效壓縮和管理廣泛的對話記錄，大幅減少時間和記憶體複雜度，同時改善聊天機器人的語境理解。我們在多個資料集上的全面實驗表明，我們的模型在產生同理心回應和有效管理冗長的對話方面明顯優於現有的模型。

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

摘要：本研究提出了一個創新的癌症診斷和預測方法，使用可解釋的人工智慧 (XAI) 和深度學習技術。由於癌症在 2020 年造成全球近 1,000 萬人死亡，因此早期準確的診斷至關重要。傳統方法通常面臨成本、準確性和效率方面的挑戰。我們的研究開發了一個 AI 模型，它提供精確的結果並清楚地了解其決策過程，解決了深度學習模型的「黑箱」問題。通過採用 XAI 技術，我們增強了解釋性和透明度，在醫療專業人員和患者之間建立信任。我們的做法利用神經網路分析廣泛的數據集，識別癌症檢測模式。這個模型有可能通過提高醫療決策的準確性、可及性和清晰度來革新診斷，可能導致更早的檢測和更個性化的治療策略。此外，它可以使更多人獲得高品質的診斷，特別是在資源有限的環境中，有助於全球健康公平。該模型的應用範圍不僅限於癌症診斷，還可能轉變醫療決策的各個方面，並拯救全球數百萬人的生命。

##### **Applying LLM and Topic Modelling in Psychotherapeutic Contexts**
2412.17449v1 by Alexander Vanin, Vadim Bolshev, Anastasia Panfilova

This study explores the use of Large language models to analyze therapist
remarks in a psychotherapeutic setting. The paper focuses on the application of
BERTopic, a machine learning-based topic modeling tool, to the dialogue of two
different groups of therapists (classical and modern), which makes it possible
to identify and describe a set of topics that consistently emerge across these
groups. The paper describes in detail the chosen algorithm for BERTopic, which
included creating a vector space from a corpus of therapist remarks, reducing
its dimensionality, clustering the space, and creating and optimizing topic
representation. Along with the automatic topical modeling by the BERTopic, the
research involved an expert assessment of the findings and manual topic
structure optimization. The topic modeling results highlighted the most common
and stable topics in therapists speech, offering insights into how language
patterns in therapy develop and remain stable across different therapeutic
styles. This work contributes to the growing field of machine learning in
psychotherapy by demonstrating the potential of automated methods to improve
both the practice and training of therapists. The study highlights the value of
topic modeling as a tool for gaining a deeper understanding of therapeutic
dialogue and offers new opportunities for improving therapeutic effectiveness
and clinical supervision.

摘要：本研究探討使用大型語言模型來分析心理治療環境中的治療師評論。本文重點關注將基於機器學習的主題建模工具 BERTopic 應用於兩組不同治療師（古典和現代）的對話，這使得識別和描述一組在這些組中持續出現的主題成為可能。本文詳細描述了 BERTopic 的選擇演算法，其中包括從治療師評論語料庫建立向量空間、降低其維度、對空間進行分群，以及建立和最佳化主題表示。除了 BERTopic 的自動主題建模外，該研究還包括對研究結果的專家評估和手動主題結構最佳化。主題建模結果突出了治療師言語中最常見且穩定的主題，提供了有關治療中的語言模式如何發展並在不同的治療風格中保持穩定的見解。這項工作透過展示自動化方法在改善治療師實務和訓練方面的潛力，為心理治療中機器學習的成長領域做出貢獻。本研究強調了主題建模作為深入了解治療對話的工具的價值，並為改善治療效果和臨床督導提供了新的機會。

##### **FFA Sora, video generation as fundus fluorescein angiography simulator**
2412.17346v1 by Xinyuan Wu, Lili Wang, Ruoyu Chen, Bowen Liu, Weiyi Zhang, Xi Yang, Yifan Feng, Mingguang He, Danli Shi

Fundus fluorescein angiography (FFA) is critical for diagnosing retinal
vascular diseases, but beginners often struggle with image interpretation. This
study develops FFA Sora, a text-to-video model that converts FFA reports into
dynamic videos via a Wavelet-Flow Variational Autoencoder (WF-VAE) and a
diffusion transformer (DiT). Trained on an anonymized dataset, FFA Sora
accurately simulates disease features from the input text, as confirmed by
objective metrics: Frechet Video Distance (FVD) = 329.78, Learned Perceptual
Image Patch Similarity (LPIPS) = 0.48, and Visual-question-answering Score
(VQAScore) = 0.61. Specific evaluations showed acceptable alignment between the
generated videos and textual prompts, with BERTScore of 0.35. Additionally, the
model demonstrated strong privacy-preserving performance in retrieval
evaluations, achieving an average Recall@K of 0.073. Human assessments
indicated satisfactory visual quality, with an average score of 1.570(scale: 1
= best, 5 = worst). This model addresses privacy concerns associated with
sharing large-scale FFA data and enhances medical education.

摘要：眼底螢光血管攝影 (FFA) 對診斷視網膜血管疾病至關重要，但初學者常常難以解讀影像。本研究開發出 FFA Sora，一個文字轉影片模型，可透過小波流變動自編碼器 (WF-VAE) 和擴散轉換器 (DiT) 將 FFA 報告轉換成動態影片。FFA Sora 在匿名資料集上訓練，能準確模擬輸入文字中的疾病特徵，並由客觀指標證實：Fréchet 影片距離 (FVD) = 329.78、學習知覺影像區塊相似度 (LPIPS) = 0.48 和視覺問答分數 (VQAScore) = 0.61。特定評估顯示產生的影片和文字提示之間有可接受的一致性，BERTScore 為 0.35。此外，該模型在檢索評估中展現出強大的隱私保護效能，平均 Recall@K 達到 0.073。人類評估顯示令人滿意的視覺品質，平均分數為 1.570（量表：1 = 最佳，5 = 最差）。此模型解決了與分享大規模 FFA 資料相關的隱私疑慮，並增進醫學教育。

##### **QTSeg: A Query Token-Based Architecture for Efficient 2D Medical Image Segmentation**
2412.17241v1 by Phuong-Nam Tran, Nhat Truong Pham, Duc Ngoc Minh Dang, Eui-Nam Huh, Choong Seon Hong

Medical image segmentation is crucial in assisting medical doctors in making
diagnoses and enabling accurate automatic diagnosis. While advanced
convolutional neural networks (CNNs) excel in segmenting regions of interest
with pixel-level precision, they often struggle with long-range dependencies,
which is crucial for enhancing model performance. Conversely, transformer
architectures leverage attention mechanisms to excel in handling long-range
dependencies. However, the computational complexity of transformers grows
quadratically, posing resource-intensive challenges, especially with
high-resolution medical images. Recent research aims to combine CNN and
transformer architectures to mitigate their drawbacks and enhance performance
while keeping resource demands low. Nevertheless, existing approaches have not
fully leveraged the strengths of both architectures to achieve high accuracy
with low computational requirements. To address this gap, we propose a novel
architecture for 2D medical image segmentation (QTSeg) that leverages a feature
pyramid network (FPN) as the image encoder, a multi-level feature fusion (MLFF)
as the adaptive module between encoder and decoder and a multi-query mask
decoder (MQM Decoder) as the mask decoder. In the first step, an FPN model
extracts pyramid features from the input image. Next, MLFF is incorporated
between the encoder and decoder to adapt features from different encoder stages
to the decoder. Finally, an MQM Decoder is employed to improve mask generation
by integrating query tokens with pyramid features at all stages of the mask
decoder. Our experimental results show that QTSeg outperforms state-of-the-art
methods across all metrics with lower computational demands than the baseline
and the existing methods. Code is available at
https://github.com/tpnam0901/QTSeg (v0.1.0)

摘要：醫療影像分割對於協助醫生診斷和實現精確的自動診斷至關重要。儘管先進的卷積神經網路 (CNN) 在以像素層級精準度分割感興趣區域方面表現出色，但它們通常難以處理長距離依賴性，這對於提升模型效能至關重要。相反地，變形器架構利用注意力機制在處理長距離依賴性方面表現出色。然而，變形器的運算複雜度呈二次方成長，造成資源密集型的挑戰，特別是在處理高解析度醫療影像時。最近的研究旨在結合 CNN 和變形器架構，以減輕其缺點並提升效能，同時保持低資源需求。儘管如此，現有方法尚未充分利用這兩種架構的優點，以在低運算需求下達成高準確度。為了解決這個差距，我們提出了一種針對 2D 醫療影像分割的創新架構 (QTSeg)，它利用特徵金字塔網路 (FPN) 作為影像編碼器，多層級特徵融合 (MLFF) 作為編碼器和解碼器之間的自適應模組，以及多查詢遮罩解碼器 (MQM Decoder) 作為遮罩解碼器。在第一步，FPN 模型從輸入影像中萃取金字塔特徵。接下來，MLFF 被整合在編碼器和解碼器之間，以將來自不同編碼器階段的特徵適應到解碼器。最後，採用 MQM 解碼器，透過在遮罩解碼器的所有階段將查詢權杖與金字塔特徵整合，來改善遮罩生成。我們的實驗結果顯示，QTSeg 在所有指標上都優於最先進的方法，且運算需求低於基線和現有方法。程式碼可在 https://github.com/tpnam0901/QTSeg (v0.1.0) 取得

##### **MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching**
2412.17228v1 by Ethan Cerami, Pavel Trukhanov, Morgan A. Paul, Michael J. Hassett, Irbaz B. Riaz, James Lindsay, Emily Mallaber, Harry Klein, Gufran Gungor, Matthew Galvin, Stephen C. Van Nostrand, Joyce Yu, Tali Mazor, Kenneth L. Kehl

Clinical trials drive improvements in cancer treatments and outcomes.
However, most adults with cancer do not participate in trials, and trials often
fail to enroll enough patients to answer their scientific questions. Artificial
intelligence could accelerate matching of patients to appropriate clinical
trials. Here, we describe the development and evaluation of the MatchMiner-AI
pipeline for clinical trial searching and ranking. MatchMiner-AI focuses on
matching patients to potential trials based on core criteria describing
clinical "spaces," or disease contexts, targeted by a trial. It aims to
accelerate the human work of identifying potential matches, not to fully
automate trial screening. The pipeline includes modules for extraction of key
information from a patient's longitudinal electronic health record; rapid
ranking of candidate trial-patient matches based on embeddings in vector space;
and classification of whether a candidate match represents a reasonable
clinical consideration. Code and synthetic data are available at
https://huggingface.co/ksg-dfci/MatchMiner-AI . Model weights based on
synthetic data are available at https://huggingface.co/ksg-dfci/TrialSpace and
https://huggingface.co/ksg-dfci/TrialChecker . A simple cancer clinical trial
search engine to demonstrate pipeline components is available at
https://huggingface.co/spaces/ksg-dfci/trial_search_alpha .

摘要：臨床試驗推動癌症治療和成果的進展。
然而，大多數癌症成年患者並未參與試驗，而試驗也常無法招募足夠的患者來回答其科學問題。人工
智慧可以加速將患者與適當的臨床試驗配對。在此，我們描述 MatchMiner-AI
管線的開發和評估，用於臨床試驗搜尋和排名。MatchMiner-AI 專注於根據描述
臨床「空間」或試驗針對的疾病背景的核心標準，將患者與潛在試驗配對。其目標是
加速找出潛在配對的人工工作，而非完全自動化試驗篩選。此管線包含模組，用於
從患者的縱向電子健康紀錄中萃取關鍵資訊；根據向量空間中的嵌入快速排名候選試驗
與患者的配對；以及分類候選配對是否代表合理的臨床考量。程式碼和合成資料可於
https://huggingface.co/ksg-dfci/MatchMiner-AI 取得。根據合成資料的模型權重可於
https://huggingface.co/ksg-dfci/TrialSpace 和
https://huggingface.co/ksg-dfci/TrialChecker 取得。一個簡單的癌症臨床試驗
搜尋引擎用於展示管線組成，可於
https://huggingface.co/spaces/ksg-dfci/trial_search_alpha 取得。

##### **COVID-19 on YouTube: A Data-Driven Analysis of Sentiment, Toxicity, and Content Recommendations**
2412.17180v1 by Vanessa Su, Nirmalya Thakur

This study presents a data-driven analysis of COVID-19 discourse on YouTube,
examining the sentiment, toxicity, and thematic patterns of video content
published between January 2023 and October 2024. The analysis involved applying
advanced natural language processing (NLP) techniques: sentiment analysis with
VADER, toxicity detection with Detoxify, and topic modeling using Latent
Dirichlet Allocation (LDA). The sentiment analysis revealed that 49.32% of
video descriptions were positive, 36.63% were neutral, and 14.05% were
negative, indicating a generally informative and supportive tone in
pandemic-related content. Toxicity analysis identified only 0.91% of content as
toxic, suggesting minimal exposure to toxic content. Topic modeling revealed
two main themes, with 66.74% of the videos covering general health information
and pandemic-related impacts and 33.26% focused on news and real-time updates,
highlighting the dual informational role of YouTube. A recommendation system
was also developed using TF-IDF vectorization and cosine similarity, refined by
sentiment, toxicity, and topic filters to ensure relevant and context-aligned
video recommendations. This system achieved 69% aggregate coverage, with
monthly coverage rates consistently above 85%, demonstrating robust performance
and adaptability over time. Evaluation across recommendation sizes showed
coverage reaching 69% for five video recommendations and 79% for ten video
recommendations per video. In summary, this work presents a framework for
understanding COVID-19 discourse on YouTube and a recommendation system that
supports user engagement while promoting responsible and relevant content
related to COVID-19.

摘要：本研究透過資料驅動分析 YouTube 上與 COVID-19 相關的論述，探討 2023 年 1 月至 2024 年 10 月間發布的影片內容中的情緒、毒性與主題模式。分析中採用進階自然語言處理 (NLP) 技術：使用 VADER 進行情緒分析、使用 Detoxify 進行毒性偵測，以及使用隱含狄利克雷配置 (LDA) 進行主題建模。情緒分析顯示，49.32% 的影片說明為正面、36.63% 為中立、14.05% 為負面，表示與疫情相關的內容通常具有資訊性且具支持性。毒性分析指出僅有 0.91% 的內容具有毒性，表示接觸到有毒內容的機率很低。主題建模顯示出兩個主要主題，其中 66.74% 的影片涵蓋一般健康資訊與疫情相關影響，而 33.26% 則著重於新聞和即時更新，突顯出 YouTube 的雙重資訊角色。我們也使用 TF-IDF 向量化和餘弦相似度開發了一套推薦系統，並透過情緒、毒性和主題篩選器進行調整，以確保推薦的影片相關且符合脈絡。此系統達到 69% 的總體覆蓋率，且每月的覆蓋率穩定維持在 85% 以上，顯示出穩健的效能和適應力。針對不同推薦數量進行評估，結果顯示推薦五部影片的覆蓋率達到 69%，推薦十部影片的覆蓋率則達到 79%。總之，這項研究提出一個架構，用於了解 YouTube 上與 COVID-19 相關的論述，並提出一個推薦系統，在促進使用者參與的同時，也能宣傳與 COVID-19 相關的負責任且相關的內容。

##### **AI-Based Teat Shape and Skin Condition Prediction for Dairy Management**
2412.17142v1 by Yuexing Hao, Tiancheng Yuan, Yuting Yang, Aarushi Gupta, Matthias Wieland, Ken Birman, Parminder S. Basran

Dairy owners spend significant effort to keep their animals healthy. There is
good reason to hope that technologies such as computer vision and artificial
intelligence (AI) could reduce these costs, yet obstacles arise when adapting
advanced tools to farming environments. In this work, we adapt AI tools to
dairy cow teat localization, teat shape, and teat skin condition
classifications. We also curate a data collection and analysis methodology for
a Machine Learning (ML) pipeline. The resulting teat shape prediction model
achieves a mean Average Precision (mAP) of 0.783, and the teat skin condition
model achieves a mean average precision of 0.828. Our work leverages existing
ML vision models to facilitate the individualized identification of teat health
and skin conditions, applying AI to the dairy management industry.

摘要：乳製品業者投入大量心力保持動物健康。有充分理由期待電腦視覺與人工智慧 (AI) 等技術可以降低這些成本，然而在將先進工具應用於農業環境時會遇到障礙。在這項工作中，我們將 AI 工具應用於乳牛乳頭定位、乳頭形狀和乳頭皮膚狀況分類。我們也為機器學習 (ML) 管線整理資料收集和分析方法。產生的乳頭形狀預測模型達到 0.783 的平均準確度 (mAP)，而乳頭皮膚狀況模型達到 0.828 的平均準確度。我們的研究利用現有的 ML 視覺模型，促進乳頭健康和皮膚狀況的個別辨識，將 AI 應用於乳製品管理產業。

##### **An OpenMind for 3D medical vision self-supervised learning**
2412.17041v1 by Tassilo Wald, Constantin Ulrich, Jonathan Suprijadi, Michal Nohel, Robin Peretzke, Klaus H. Maier-Hein

The field of 3D medical vision self-supervised learning lacks consistency and
standardization. While many methods have been developed it is impossible to
identify the current state-of-the-art, due to i) varying and small pre-training
datasets, ii) varying architectures, and iii) being evaluated on differing
downstream datasets. In this paper we bring clarity to this field and lay the
foundation for further method advancements: We a) publish the largest publicly
available pre-training dataset comprising 114k 3D brain MRI volumes and b)
benchmark existing SSL methods under common architectures and c) provide the
code of our framework publicly to facilitate rapid adoption and reproduction.
This pre-print \textit{only describes} the dataset contribution (a); Data,
benchmark, and codebase will be made available shortly.

摘要：3D 醫療視覺自監督學習領域缺乏一致性和標準化。雖然已經開發出許多方法，但由於 i) 變化且較小的預訓練資料集、ii) 不同的架構，以及 iii) 在不同的下游資料集上進行評估，因此無法識別目前的最新技術。在本文中，我們為這個領域帶來清晰度，並為進一步的方法進展奠定基礎：我們 a) 發布最大的公開可用預訓練資料集，包含 114k 個 3D 大腦 MRI 卷，以及 b) 在常見架構下對現有的 SSL 方法進行基準測試，以及 c) 公開提供我們架構的程式碼，以促進快速採用和複製。這個預印本\textit{僅描述}資料集貢獻 (a)；資料、基準測試和程式碼庫將很快提供。

##### **On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora**
2412.16976v1 by Tzu-Chieh Chen, Wen-Yang Lin

Named Entity Recognition has traditionally been a key task in natural
language processing, aiming to identify and extract important terms from
unstructured text data. However, a notable challenge for contemporary
deep-learning NER models has been identifying discontinuous entities, which are
often fragmented within the text. To date, methods to address Discontinuous
Named Entity Recognition have not been explored using ensemble learning to the
best of our knowledge. Furthermore, the rise of large language models, such as
ChatGPT in recent years, has shown significant effectiveness across many NLP
tasks. Most existing approaches, however, have primarily utilized ChatGPT as a
problem-solving tool rather than exploring its potential as an integrative
element within ensemble learning algorithms. In this study, we investigated the
integration of ChatGPT as an arbitrator within an ensemble method, aiming to
enhance performance on DNER tasks. Our method combines five state-of-the-art
NER models with ChatGPT using custom prompt engineering to assess the
robustness and generalization capabilities of the ensemble algorithm. We
conducted experiments on three benchmark medical datasets, comparing our method
against the five SOTA models, individual applications of GPT-3.5 and GPT-4, and
a voting ensemble method. The results indicate that our proposed fusion of
ChatGPT with the ensemble learning algorithm outperforms the SOTA results in
the CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance
NLP applications in the healthcare domain.

摘要：命名實體辨識一直是自然語言處理中的關鍵任務，旨在從非結構化文字資料中辨識並擷取重要詞彙。然而，當代深度學習命名實體辨識模型面臨的一項顯著挑戰，就是辨識非連續實體，這些實體通常在文字中呈片段化。迄今為止，我們所知，並未探索使用整體學習來解決非連續命名實體辨識的方法。此外，近年來大型語言模型（如 ChatGPT）的興起，已在許多自然語言處理任務中展現顯著的效能。然而，現有方法大多將 ChatGPT 視為解決問題的工具，而非探索其作為整體學習演算法中整合元素的潛力。在本研究中，我們探討了將 ChatGPT 整合為整體方法中的仲裁者，旨在提升非連續命名實體辨識任務的效能。我們的方法結合了五種最先進的命名實體辨識模型和 ChatGPT，使用自訂提示工程來評估整體演算法的穩健性和泛化能力。我們針對三個基準醫療資料集進行實驗，將我們的方法與五種最先進的模型、GPT-3.5 和 GPT-4 的個別應用，以及投票整體方法進行比較。結果表明，我們提出的將 ChatGPT 與整體學習演算法融合的方法，在 CADEC、ShARe13 和 ShARe14 資料集中的表現優於最先進的結果，展示了其在醫療領域增強自然語言處理應用程式的潛力。

##### **Quantifying Public Response to COVID-19 Events: Introducing the Community Sentiment and Engagement Index**
2412.16925v1 by Nirmalya Thakur, Kesha A. Patel, Audrey Poon, Shuqi Cui, Nazif Azizi, Rishika Shah, Riyan Shah

This study introduces the Community Sentiment and Engagement Index (CSEI),
developed to capture nuanced public sentiment and engagement variations on
social media, particularly in response to major events related to COVID-19.
Constructed with diverse sentiment indicators, CSEI integrates features like
engagement, daily post count, compound sentiment, fine-grain sentiments (fear,
surprise, joy, sadness, anger, disgust, and neutral), readability,
offensiveness, and domain diversity. Each component is systematically weighted
through a multi-step Principal Component Analysis (PCA)-based framework,
prioritizing features according to their variance contributions across temporal
sentiment shifts. This approach dynamically adjusts component importance,
enabling CSEI to precisely capture high-sensitivity shifts in public sentiment.
The development of CSEI showed statistically significant correlations with its
constituent features, underscoring internal consistency and sensitivity to
specific sentiment dimensions. CSEI's responsiveness was validated using a
dataset of 4,510,178 Reddit posts about COVID-19. The analysis focused on 15
major events, including the WHO's declaration of COVID-19 as a pandemic, the
first reported cases of COVID-19 across different countries, national
lockdowns, vaccine developments, and crucial public health measures. Cumulative
changes in CSEI revealed prominent peaks and valleys aligned with these events,
indicating significant patterns in public sentiment across different phases of
the pandemic. Pearson correlation analysis further confirmed a statistically
significant relationship between CSEI daily fluctuations and these events (p =
0.0428), highlighting the capacity of CSEI to infer and interpret shifts in
public sentiment and engagement in response to major events related to
COVID-19.

摘要：本研究引入了社群情緒和參與指數 (CSEI)，其旨在捕捉社群媒體上細微的公眾情緒和參與變化，特別是針對與 COVID-19 相關的重大事件。CSEI 以多樣化的情緒指標建構，整合了參與度、每日發文數、複合情緒、細緻情緒（恐懼、驚訝、快樂、悲傷、憤怒、厭惡和中立）、可讀性、冒犯性和網域多樣性等特徵。每個組成部分都透過多步驟主成分分析 (PCA) 為基礎的架構進行系統性加權，根據特徵對時間情緒變化的貢獻度對特徵進行優先排序。此方法動態調整組成部分的重要性，使 CSEI 能夠精準捕捉公眾情緒中的高敏感度變化。CSEI 的發展顯示出與其組成特徵具有統計顯著相關性，強調了內部一致性和對特定情緒面向的敏感性。CSEI 的反應能力已使用包含 4,510,178 則關於 COVID-19 的 Reddit 貼文的資料集進行驗證。分析重點關注 15 個重大事件，包括 WHO 宣布 COVID-19 為一場大流行病、不同國家首次報告 COVID-19 病例、國家封鎖、疫苗開發和重要的公共衛生措施。CSEI 的累積變化顯示出與這些事件相符的顯著高峰和低谷，表明在疫情的不同階段中公眾情緒存在顯著模式。皮爾森相關分析進一步證實了 CSEI 每日的波動與這些事件之間存在統計顯著相關性 (p = 0.0428)，突顯出 CSEI 推論和詮釋公眾情緒變化以及對與 COVID-19 相關的重大事件參與度變化的能力。

##### **PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health**
2412.16882v1 by Huy Vu, Huy Anh Nguyen, Adithya V Ganesan, Swanie Juhng, Oscar N. E. Kjell, Joao Sedoc, Margaret L. Kern, Ryan L. Boyd, Lyle Ungar, H. Andrew Schwartz, Johannes C. Eichstaedt

Artificial intelligence-based language generators are now a part of most
people's lives. However, by default, they tend to generate "average" language
without reflecting the ways in which people differ. Here, we propose a
lightweight modification to the standard language model transformer
architecture - "PsychAdapter" - that uses empirically derived trait-language
patterns to generate natural language for specified personality, demographic,
and mental health characteristics (with or without prompting). We applied
PsychAdapters to modify OpenAI's GPT-2, Google's Gemma, and Meta's Llama 3 and
found generated text to reflect the desired traits. For example, expert raters
evaluated PsychAdapter's generated text output and found it matched intended
trait levels with 87.3% average accuracy for Big Five personalities, and 96.7%
for depression and life satisfaction. PsychAdapter is a novel method to
introduce psychological behavior patterns into language models at the
foundation level, independent of prompting, by influencing every transformer
layer. This approach can create chatbots with specific personality profiles,
clinical training tools that mirror language associated with psychological
conditionals, and machine translations that match an authors reading or
education level without taking up LLM context windows. PsychAdapter also allows
for the exploration psychological constructs through natural language
expression, extending the natural language processing toolkit to study human
psychology.

摘要：基於人工智慧的語言生成器現在已經成為大多數人生活中的一部分。然而，預設情況下，它們傾向於產生「普通」的語言，而沒有反映出人們的差異性。在此，我們提出了一個對標準語言模型轉換器架構的輕量級修改 - 「PsychAdapter」 - 它使用經驗派生的特質語言模式為指定的人格、人口統計和心理健康特徵（有或沒有提示）生成自然語言。我們將 PsychAdapter 應用於修改 OpenAI 的 GPT-2、Google 的 Gemma 和 Meta 的 Llama 3，發現生成的文字反映了所需的特質。例如，專家評分員評估了 PsychAdapter 生成的文字輸出，發現它與預期的特質水準相符，五大性格特質的平均準確度為 87.3%，而憂鬱症和生活滿意度的準確度為 96.7%。PsychAdapter 是一種新穎的方法，可以將心理行為模式引入語言模型的基本層級，不受提示的影響，並影響每個轉換器層級。這種方法可以建立具有特定個性特徵的聊天機器人、反映與心理條件相關語言的臨床訓練工具，以及與作者的閱讀或教育水準相符的機器翻譯，而不需要使用 LLM 上下文視窗。PsychAdapter 也允許透過自然語言表達來探索心理建構，將自然語言處理工具包延伸到研究人類心理學。

##### **KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis**
2412.16833v1 by Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio

Integrating Large Language Models (LLMs) in healthcare diagnosis demands
systematic frameworks that can handle complex medical scenarios while
maintaining specialized expertise. We present KG4Diagnosis, a novel
hierarchical multi-agent framework that combines LLMs with automated knowledge
graph construction, encompassing 362 common diseases across medical
specialties. Our framework mirrors real-world medical systems through a
two-tier architecture: a general practitioner (GP) agent for initial assessment
and triage, coordinating with specialized agents for in-depth diagnosis in
specific domains. The core innovation lies in our end-to-end knowledge graph
generation methodology, incorporating: (1) semantic-driven entity and relation
extraction optimized for medical terminology, (2) multi-dimensional decision
relationship reconstruction from unstructured medical texts, and (3)
human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an
extensible foundation for specialized medical diagnosis systems, with
capabilities to incorporate new diseases and medical knowledge. The framework's
modular design enables seamless integration of domain-specific enhancements,
making it valuable for developing targeted medical diagnosis systems. We
provide architectural guidelines and protocols to facilitate adoption across
medical contexts.

摘要：整合大型語言模型 (LLM) 於醫療診斷中，需要系統化架構，能夠處理複雜的醫療場景，同時維持專業知識。我們提出 KG4Diagnosis，一個新穎的分層多代理架構，結合 LLM 與自動化知識圖譜建構，涵蓋醫療專業的 362 種常見疾病。我們的架構透過雙層架構反映真實世界的醫療系統：一位全科醫師 (GP) 代理負責初步評估和分流，並與專業代理協調，針對特定領域進行深入診斷。核心創新在於我們的端對端知識圖譜生成方法，結合：(1) 針對醫療術語最佳化的語意驅動實體和關係萃取，(2) 從非結構化醫療文本重建多面向決策關係，以及 (3) 人類引導的推理進行知識擴充。KG4Diagnosis 可作為專業醫療診斷系統的可擴充基礎，具備整合新疾病和醫療知識的能力。此架構的模組化設計能無縫整合特定領域的強化功能，使其對於開發目標導向的醫療診斷系統極具價值。我們提供架構準則和協定，以利於在醫療情境中採用。

##### **A Comparative Study on Machine Learning Models to Classify Diseases Based on Patient Behaviour and Habits**
2412.16768v1 by Elham Musaaed, Nabil Hewahi, Abdulla Alasaadi

In recent years, ML algorithms have been shown to be useful for predicting
diseases based on health data and posed a potential application area for these
algorithms such as modeling of diseases. The majority of these applications
employ supervised rather than unsupervised ML algorithms. In addition, each
year, the amount of data in medical science grows rapidly. Moreover, these data
include clinical and Patient-Related Factors (PRF), such as height, weight,
age, other physical characteristics, blood sugar, lipids, insulin, etc., all of
which will change continually over time. Analysis of historical data can help
identify disease risk factors and their interactions, which is useful for
disease diagnosis and prediction. This wealth of valuable information in these
data will help doctors diagnose accurately and people can become more aware of
the risk factors and key indicators to act proactively. The purpose of this
study is to use six supervised ML approaches to fill this gap by conducting a
comprehensive experiment to investigate the correlation between PRF and
Diabetes, Stroke, Heart Disease (HD), and Kidney Disease (KD). Moreover, it
will investigate the link between Diabetes, Stroke, and KD and PRF with HD.
Further, the research aims to compare and evaluate various ML algorithms for
classifying diseases based on the PRF. Additionally, it aims to compare and
evaluate ML algorithms for classifying HD based on PRF as well as Diabetes,
Stroke, Asthma, Skin Cancer, and KD as attributes. Lastly, HD predictions will
be provided through a Web-based application on the most accurate classifier,
which allows the users to input their values and predict the output.

摘要：近年來，已證明 ML 演算法可根據健康資料預測疾病，並為這些演算法提出了潛在應用領域，例如疾病建模。這些應用程式大多數採用有監督式而非無監督式的 ML 演算法。此外，每年醫學科學中的資料量都快速成長。而且，這些資料包括臨床和患者相關因素 (PRF)，例如身高、體重、年齡、其他身體特徵、血糖、脂質、胰島素等，所有這些都會隨著時間持續變化。分析歷史資料有助於找出疾病風險因子及其交互作用，這對於疾病診斷和預測很有用。這些資料中豐富的寶貴資訊將有助於醫生準確診斷，而人們可以更了解風險因子和關鍵指標，以採取積極行動。本研究的目的是使用六種有監督式 ML 方法，透過執行全面實驗來填補此差距，以探討 PRF 與糖尿病、中風、心臟病 (HD) 和腎臟病 (KD) 之間的關聯性。此外，它將探討糖尿病、中風和 KD 與 PRF 與 HD 之間的關聯性。此外，該研究旨在比較和評估各種 ML 演算法，以根據 PRF 對疾病進行分類。此外，它旨在比較和評估 ML 演算法，以根據 PRF 對 HD 進行分類，以及將糖尿病、中風、氣喘、皮膚癌和 KD 作為屬性。最後，將透過最準確分類器的網路應用程式提供 HD 預測，使用戶可以輸入其數值並預測輸出。

##### **From Histopathology Images to Cell Clouds: Learning Slide Representations with Hierarchical Cell Transformer**
2412.16715v1 by Zijiang Yang, Zhongwei Qiu, Tiancheng Lin, Hanqing Chao, Wanxing Chang, Yelin Yang, Yunshuo Zhang, Wenpei Jiao, Yixuan Shen, Wenbin Liu, Dongmei Fu, Dakai Jin, Ke Yan, Le Lu, Hui Jiang, Yun Bian

It is clinically crucial and potentially very beneficial to be able to
analyze and model directly the spatial distributions of cells in histopathology
whole slide images (WSI). However, most existing WSI datasets lack cell-level
annotations, owing to the extremely high cost over giga-pixel images. Thus, it
remains an open question whether deep learning models can directly and
effectively analyze WSIs from the semantic aspect of cell distributions. In
this work, we construct a large-scale WSI dataset with more than 5 billion
cell-level annotations, termed WSI-Cell5B, and a novel hierarchical Cell Cloud
Transformer (CCFormer) to tackle these challenges. WSI-Cell5B is based on 6,998
WSIs of 11 cancers from The Cancer Genome Atlas Program, and all WSIs are
annotated per cell by coordinates and types. To the best of our knowledge,
WSI-Cell5B is the first WSI-level large-scale dataset integrating cell-level
annotations. On the other hand, CCFormer formulates the collection of cells in
each WSI as a cell cloud and models cell spatial distribution. Specifically,
Neighboring Information Embedding (NIE) is proposed to characterize the
distribution of cells within the neighborhood of each cell, and a novel
Hierarchical Spatial Perception (HSP) module is proposed to learn the spatial
relationship among cells in a bottom-up manner. The clinical analysis indicates
that WSI-Cell5B can be used to design clinical evaluation metrics based on
counting cells that effectively assess the survival risk of patients. Extensive
experiments on survival prediction and cancer staging show that learning from
cell spatial distribution alone can already achieve state-of-the-art (SOTA)
performance, i.e., CCFormer strongly outperforms other competing methods.

摘要：在组织病理学全切片图像（WSI）中直接分析和建模细胞的空间分布在临床上至关重要，并且可能非常有益。然而，由于千兆像素图像的成本极高，大多数现有的 WSI 数据集缺乏细胞级别的注释。因此，深度学习模型能否从细胞分布的语义方面直接有效地分析 WSI 仍然是一个悬而未决的问题。在这项工作中，我们构建了一个包含超过 50 亿个细胞级注释的大规模 WSI 数据集，称为 WSI-Cell5B，以及一个新颖的分层细胞云 Transformer（CCFormer）来应对这些挑战。WSI-Cell5B 基于癌症基因组图谱计划的 11 种癌症的 6,998 个 WSI，并且所有 WSI 都按细胞坐标和类型进行注释。据我们所知，WSI-Cell5B 是第一个整合细胞级注释的 WSI 级大规模数据集。另一方面，CCFormer 将每个 WSI 中的细胞集合表述为细胞云，并对细胞空间分布进行建模。具体来说，提出了邻域信息嵌入（NIE）来表征每个细胞邻域内细胞的分布，并提出了一个新颖的分层空间感知（HSP）模块来以自下而上的方式学习细胞之间的空间关系。临床分析表明，WSI-Cell5B 可用于设计基于计数细胞的临床评估指标，该指标可有效评估患者的生存风险。在生存预测和癌症分期上的大量实验表明，仅从细胞空间分布中学习就已经可以达到最先进（SOTA）的性能，即 CCFormer 明显优于其他竞争方法。

##### **STAMPsy: Towards SpatioTemporal-Aware Mixed-Type Dialogues for Psychological Counseling**
2412.16674v1 by Jieyi Wang, Yue Huang, Zeming Liu, Dexuan Xu, Chuan Wang, Xiaoming Shi, Ruiyuan Guan, Hongxing Wang, Weihua Yue, Yu Huang

Online psychological counseling dialogue systems are trending, offering a
convenient and accessible alternative to traditional in-person therapy.
However, existing psychological counseling dialogue systems mainly focus on
basic empathetic dialogue or QA with minimal professional knowledge and without
goal guidance. In many real-world counseling scenarios, clients often seek
multi-type help, such as diagnosis, consultation, therapy, console, and common
questions, but existing dialogue systems struggle to combine different dialogue
types naturally. In this paper, we identify this challenge as how to construct
mixed-type dialogue systems for psychological counseling that enable clients to
clarify their goals before proceeding with counseling. To mitigate the
challenge, we collect a mixed-type counseling dialogues corpus termed STAMPsy,
covering five dialogue types, task-oriented dialogue for diagnosis,
knowledge-grounded dialogue, conversational recommendation, empathetic
dialogue, and question answering, over 5,000 conversations. Moreover,
spatiotemporal-aware knowledge enables systems to have world awareness and has
been proven to affect one's mental health. Therefore, we link dialogues in
STAMPsy to spatiotemporal state and propose a spatiotemporal-aware mixed-type
psychological counseling dataset. Additionally, we build baselines on STAMPsy
and develop an iterative self-feedback psychological dialogue generation
framework, named Self-STAMPsy. Results indicate that clarifying dialogue goals
in advance and utilizing spatiotemporal states are effective.

摘要：線上心理諮商對話系統正夯，提供便利且容易取得的傳統面對面治療替代方案。
然而，現有的心理諮商對話系統主要專注於基本的同理對話或問答，專業知識最少且沒有目標引導。在許多真實世界的諮商情境中，客戶常尋求多種類型的協助，例如診斷、諮詢、治療、安慰和常見問題，但現有的對話系統難以自然地結合不同的對話類型。在本文中，我們將此挑戰界定為如何建構心理諮商的混合類型對話系統，讓客戶在進行諮商前釐清他們的目標。為了減輕此挑戰，我們收集了一個稱為 STAMPsy 的混合類型諮商對話語料庫，涵蓋五種類型的對話，包括診斷任務導向對話、知識基礎對話、對話式推薦、同理對話和問答，超過 5,000 場對話。此外，時空感知知識讓系統具備世界感知，並已被證實會影響一個人的心理健康。因此，我們將 STAMPsy 中的對話連結到時空狀態，並提出一個時空感知的混合類型心理諮商資料集。此外，我們在 STAMPsy 上建立基線，並開發一個名為 Self-STAMPsy 的迭代式自我回饋心理對話產生架構。結果顯示，事先釐清對話目標和利用時空狀態是有效的。

##### **Automated Bleeding Detection and Classification in Wireless Capsule Endoscopy with YOLOv8-X**
2412.16624v1 by Pavan C Shekar, Vivek Kanhangad, Shishir Maheshwari, T Sunil Kumar

Gastrointestinal (GI) bleeding, a critical indicator of digestive system
disorders, re quires efficient and accurate detection methods. This paper
presents our solution to the Auto-WCEBleedGen Version V1 Challenge, where we
achieved the consolation position. We developed a unified YOLOv8-X model for
both detection and classification of bleeding regions in Wireless Capsule
Endoscopy (WCE) images. Our approach achieved 96.10% classification accuracy
and 76.8% mean Average Precision (mAP) at 0.5 IoU on the val idation dataset.
Through careful dataset curation and annotation, we assembled and trained on
6,345 diverse images to ensure robust model performance. Our implementa tion
code and trained models are publicly available at
https://github.com/pavan98765/Auto-WCEBleedGen.

摘要：胃腸道 (GI) 出血是消化系統疾病的重要指標，需要有效且準確的檢測方法。本文提出我們對 Auto-WCEBleedGen 版本 V1 挑戰的解決方案，我們在其中取得了安慰獎。我們開發了一個統一的 YOLOv8-X 模型，用於無線膠囊內視鏡 (WCE) 影像中出血區域的檢測和分類。我們的做法在驗證資料集上以 0.5 IoU 達到了 96.10% 的分類準確度和 76.8% 的平均平均精度 (mAP)。透過仔細的資料集策劃和註解，我們收集並訓練了 6,345 張不同的影像，以確保模型的強健效能。我們的實作程式碼和訓練模型已公開於 https://github.com/pavan98765/Auto-WCEBleedGen。

##### **Patherea: Cell Detection and Classification for the 2020s**
2412.16425v1 by Dejan Štepec, Maja Jerše, Snežana Đokić, Jera Jeruc, Nina Zidar, Danijel Skočaj

This paper presents a Patherea, a framework for point-based cell detection
and classification that provides a complete solution for developing and
evaluating state-of-the-art approaches. We introduce a large-scale dataset
collected to directly replicate a clinical workflow for Ki-67 proliferation
index estimation and use it to develop an efficient point-based approach that
directly predicts point-based predictions, without the need for intermediate
representations. The proposed approach effectively utilizes point proposal
candidates with the hybrid Hungarian matching strategy and a flexible
architecture that enables the usage of various backbones and (pre)training
strategies. We report state-of-the-art results on existing public datasets -
Lizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that
the performance on existing public datasets is saturated and that the newly
proposed Patherea dataset represents a significantly harder challenge for the
recently proposed approaches. We also demonstrate the effectiveness of recently
proposed pathology foundational models that our proposed approach can natively
utilize and benefit from. We also revisit the evaluation protocol that is used
in the broader field of cell detection and classification and identify the
erroneous calculation of performance metrics. Patherea provides a benchmarking
utility that addresses the identified issues and enables a fair comparison of
different approaches. The dataset and the code will be publicly released upon
acceptance.

摘要：本文介紹 Patherea，一個基於點的細胞偵測和分類架構，提供一個完整的解決方案，用於開發和評估最先進的方法。我們引入了一個大規模的資料集，用於直接複製 Ki-67 增殖指數估計的臨床工作流程，並使用它來開發一種有效的基於點的方法，該方法直接預測基於點的預測，無需中間表示。所提出的方法有效地利用了具有混合匈牙利匹配策略的點建議候選者和一個靈活的架構，該架構可以使用各種骨幹和（預）訓練策略。我們報告了現有公共資料集的最新結果 - Lizard、BRCA-M2C、BCData 和新提出的 Patherea 資料集。我們表明現有公共資料集上的效能已經飽和，並且新提出的 Patherea 資料集對最近提出的方法來說是一個顯著更困難的挑戰。我們還展示了最近提出的病理基礎模型的有效性，我們的建議方法可以原生利用並受益於這些模型。我們還重新審視了在細胞偵測和分類的廣泛領域中使用的評估協定，並找出效能指標的錯誤計算。Patherea 提供了一個基準測試工具，可以解決已識別的問題，並允許公平地比較不同的方法。在獲得接受後，資料集和程式碼將公開釋出。

##### **Technical Report: Small Language Model for Japanese Clinical and Medicine**
2412.16423v1 by Shogo Watanabe

This report presents a small language model (SLM) for Japanese clinical and
medicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese
text classified to be of high-quality. Moreover, NCVC-slm-1 was augmented with
respect to clinical and medicine content that includes the variety of diseases,
drugs, and examinations. Using a carefully designed pre-processing, a
specialized morphological analyzer and tokenizer, this small and light-weight
model performed not only to generate text but also indicated the feasibility of
understanding clinical and medicine text. In comparison to other large language
models, a fine-tuning NCVC-slm-1 demonstrated the highest scores on 6 tasks of
total 8 on JMED-LLM. According to this result, SLM indicated the feasibility of
performing several downstream tasks in the field of clinical and medicine.
Hopefully, NCVC-slm-1 will be contributed to develop and accelerate the field
of clinical and medicine for a bright future.

摘要：本報告提出一個針對日文臨床和醫學的小型語言模型 (SLM)，名為 NCVC-slm-1。這個 1B 參數模型是使用被分類為高品質的日文文本訓練的。此外，NCVC-slm-1 還針對臨床和醫學內容進行擴充，其中包含各種疾病、藥物和檢查。使用精心設計的預處理、專業形態分析器和分詞器，這個小而輕的模型不僅可以生成文字，還表示了理解臨床和醫學文本的可行性。與其他大型語言模型相比，微調後的 NCVC-slm-1 在 JMED-LLM 的 8 個任務中有 6 個任務上表現出最高的得分。根據這個結果，SLM 表示了執行臨床和醫學領域中多項下游任務的可行性。希望 NCVC-slm-1 能為臨床和醫學領域的發展和加速做出貢獻，邁向光明的未來。

##### **Learning Disease Progression Models That Capture Health Disparities**
2412.16406v1 by Erica Chiang, Divya Shanmugam, Ashley N. Beecy, Gabriel Sayer, Nir Uriel, Deborah Estrin, Nikhil Garg, Emma Pierson

Disease progression models are widely used to inform the diagnosis and
treatment of many progressive diseases. However, a significant limitation of
existing models is that they do not account for health disparities that can
bias the observed data. To address this, we develop an interpretable Bayesian
disease progression model that captures three key health disparities: certain
patient populations may (1) start receiving care only when their disease is
more severe, (2) experience faster disease progression even while receiving
care, or (3) receive follow-up care less frequently conditional on disease
severity. We show theoretically and empirically that failing to account for
disparities produces biased estimates of severity (underestimating severity for
disadvantaged groups, for example). On a dataset of heart failure patients, we
show that our model can identify groups that face each type of health
disparity, and that accounting for these disparities meaningfully shifts which
patients are considered high-risk.

摘要：疾病進程模型廣泛用於告知許多進行性疾病的診斷和治療。然而，現有模型的一個重大限制是它們沒有考慮可能使觀察到的資料產生偏差的健康差異。為了解決這個問題，我們開發了一個可解釋的貝氏疾病進程模型，該模型捕獲了三個主要的健康差異：某些患者群體可能 (1) 只有在他們的疾病更嚴重時才開始接受照護，(2) 即使在接受照護時，疾病進程也更快，或 (3) 根據疾病嚴重程度，接受追蹤照護的頻率較低。我們在理論上和經驗上證明，未能考慮差異會產生嚴重程度的偏差估計（例如，低估弱勢群體的嚴重程度）。在心臟衰竭患者的資料集中，我們證明我們的模型可以識別面對每種類型健康差異的群體，並且考慮這些差異會顯著改變哪些患者被認為是高風險。

##### **Ethics and Technical Aspects of Generative AI Models in Digital Content Creation**
2412.16389v1 by Atahan Karagoz

Generative AI models like GPT-4o and DALL-E 3 are reshaping digital content
creation, offering industries tools to generate diverse and sophisticated text
and images with remarkable creativity and efficiency. This paper examines both
the capabilities and challenges of these models within creative workflows.
While they deliver high performance in generating content with creativity,
diversity, and technical precision, they also raise significant ethical
concerns. Our study addresses two key research questions: (a) how these models
perform in terms of creativity, diversity, accuracy, and computational
efficiency, and (b) the ethical risks they present, particularly concerning
bias, authenticity, and potential misuse. Through a structured series of
experiments, we analyze their technical performance and assess the ethical
implications of their outputs, revealing that although generative models
enhance creative processes, they often reflect biases from their training data
and carry ethical vulnerabilities that require careful oversight. This research
proposes ethical guidelines to support responsible AI integration into industry
practices, fostering a balance between innovation and ethical integrity.

摘要：生成式 AI 模型，例如 GPT-4o 和 DALL-E 3，正在重塑數位內容的創作，為各產業提供工具，以非凡的創造力和效率產生多元且精密的文字和影像。本文探討這些模型在創作工作流程中的功能和挑戰。儘管它們在產生具有創造力、多樣性和技術精確度的內容方面表現出色，但它們也引發了重大的道德問題。我們的研究探討了兩個關鍵的研究問題：(a) 這些模型在創造力、多樣性、準確性和計算效率方面的表現，以及 (b) 它們所帶來的道德風險，特別是關於偏見、真實性和潛在的濫用。透過一連串結構化的實驗，我們分析了它們的技術效能，並評估了它們的輸出結果的道德影響，揭示了儘管生成式模型增強了創作流程，但它們通常會反映其訓練資料的偏見，並存在需要仔細監督的道德漏洞。本研究提出了道德準則，以支援負責任的 AI 整合到產業實務中，在創新和道德操守之間取得平衡。

##### **VerSe: Integrating Multiple Queries as Prompts for Versatile Cardiac MRI Segmentation**
2412.16381v1 by Bangwei Guo, Meng Ye, Yunhe Gao, Bingyu Xin, Leon Axel, Dimitris Metaxas

Despite the advances in learning-based image segmentation approach, the
accurate segmentation of cardiac structures from magnetic resonance imaging
(MRI) remains a critical challenge. While existing automatic segmentation
methods have shown promise, they still require extensive manual corrections of
the segmentation results by human experts, particularly in complex regions such
as the basal and apical parts of the heart. Recent efforts have been made on
developing interactive image segmentation methods that enable human-in-the-loop
learning. However, they are semi-automatic and inefficient, due to their
reliance on click-based prompts, especially for 3D cardiac MRI volumes. To
address these limitations, we propose VerSe, a Versatile Segmentation framework
to unify automatic and interactive segmentation through mutiple queries. Our
key innovation lies in the joint learning of object and click queries as
prompts for a shared segmentation backbone. VerSe supports both fully automatic
segmentation, through object queries, and interactive mask refinement, by
providing click queries when needed. With the proposed integrated prompting
scheme, VerSe demonstrates significant improvement in performance and
efficiency over existing methods, on both cardiac MRI and out-of-distribution
medical imaging datasets. The code is available at
https://github.com/bangwayne/Verse.

摘要：儘管在基於學習的影像分割方法有進展，但從磁振造影 (MRI) 中準確分割出心臟結構仍然是一項關鍵挑戰。雖然現有的自動分割方法已展現出前景，但它們仍然需要人類專家對分割結果進行廣泛的手動修正，特別是在心臟的基底和心尖等複雜區域。最近已針對開發互動式影像分割方法做出努力，這些方法讓人類參與迴圈學習。然而，由於它們依賴於基於點擊的提示，因此它們是半自動且低效率的，特別是對於 3D 心臟 MRI 影像量。為了解決這些限制，我們提出了 VerSe，一個多重查詢的通用分割框架，用於統一自動和互動式分割。我們的關鍵創新在於將物件和點擊查詢作為提示，共同學習共享分割主幹。VerSe 支援透過物件查詢進行全自動分割，並在需要時提供點擊查詢，進行互動式遮罩精煉。透過所提出的整合式提示機制，VerSe 在心臟 MRI 和非分布式醫療影像資料集上，都證明了在效能和效率方面有顯著的進步。程式碼可在 https://github.com/bangwayne/Verse 取得。

##### **FairREAD: Re-fusing Demographic Attributes after Disentanglement for Fair Medical Image Classification**
2412.16373v1 by Yicheng Gao, Jinkui Hao, Bo Zhou

Recent advancements in deep learning have shown transformative potential in
medical imaging, yet concerns about fairness persist due to performance
disparities across demographic subgroups. Existing methods aim to address these
biases by mitigating sensitive attributes in image data; however, these
attributes often carry clinically relevant information, and their removal can
compromise model performance-a highly undesirable outcome. To address this
challenge, we propose Fair Re-fusion After Disentanglement (FairREAD), a novel,
simple, and efficient framework that mitigates unfairness by re-integrating
sensitive demographic attributes into fair image representations. FairREAD
employs orthogonality constraints and adversarial training to disentangle
demographic information while using a controlled re-fusion mechanism to
preserve clinically relevant details. Additionally, subgroup-specific threshold
adjustments ensure equitable performance across demographic groups.
Comprehensive evaluations on a large-scale clinical X-ray dataset demonstrate
that FairREAD significantly reduces unfairness metrics while maintaining
diagnostic accuracy, establishing a new benchmark for fairness and performance
in medical image classification.

摘要：深度學習的最新進展已在醫學影像中展現出變革的潛力，但由於不同人口子群體間的效能差異，公平性的疑慮仍然存在。現有方法旨在通過減輕影像資料中的敏感屬性來解決這些偏差；然而，這些屬性通常包含臨床相關資訊，而移除它們可能會損害模型效能，這是一個非常不理想的結果。為了應對這個挑戰，我們提出公平解糾後重新融合 (FairREAD)，這是一個新穎、簡單且高效的架構，它透過將敏感的人口統計屬性重新整合到公平的影像表示中，來減輕不公平性。FairREAD 使用正交約束和對抗訓練來解開人口統計資訊，同時使用受控重新融合機制來保留臨床相關的細節。此外，特定子群的閾值調整可確保不同人口群體之間的效能公平。在大型臨床 X 光資料集上的全面評估證明，FairREAD 在維持診斷準確性的同時，顯著降低了不公平性指標，為醫學影像分類中的公平性和效能建立了新的基準。

##### **Improving Object Detection for Time-Lapse Imagery Using Temporal Features in Wildlife Monitoring**
2412.16329v1 by Marcus Jenkins, Kirsty A. Franklin, Malcolm A. C. Nicoll, Nik C. Cole, Kevin Ruhomaun, Vikash Tatayah, Michal Mackiewicz

Monitoring animal populations is crucial for assessing the health of
ecosystems. Traditional methods, which require extensive fieldwork, are
increasingly being supplemented by time-lapse camera-trap imagery combined with
an automatic analysis of the image data. The latter usually involves some
object detector aimed at detecting relevant targets (commonly animals) in each
image, followed by some postprocessing to gather activity and population data.
In this paper, we show that the performance of an object detector in a single
frame of a time-lapse sequence can be improved by including spatio-temporal
features from the prior frames. We propose a method that leverages temporal
information by integrating two additional spatial feature channels which
capture stationary and non-stationary elements of the scene and consequently
improve scene understanding and reduce the number of stationary false
positives. The proposed technique achieves a significant improvement of 24\% in
mean average precision (mAP@0.05:0.95) over the baseline (temporal
feature-free, single frame) object detector on a large dataset of breeding
tropical seabirds. We envisage our method will be widely applicable to other
wildlife monitoring applications that use time-lapse imaging.

摘要：監控動物族群對於評估生態系統的健康至關重要。傳統方法需要大量實地工作，現正逐漸由結合自動化影像資料分析的時間縮時相機陷阱影像所補充。後者通常涉及一些目標偵測器，用於偵測每張影像中相關目標（通常是動物），接著進行一些後處理以收集活動和族群資料。在本文中，我們展示了在時間縮時序列的單一影格中，目標偵測器的效能可透過納入先前影格的時空特徵而獲得改善。我們提出了一種方法，透過整合兩個額外的空間特徵通道來利用時間資訊，這些通道捕捉場景的靜態和非靜態元素，並因此改善場景理解，並減少靜態誤報的數量。所提出的技術在大型熱帶海鳥繁殖數據集上，平均準確度 (mAP@0.05:0.95) 較基線（無時間特徵的單一影格）目標偵測器顯著提升了 24%。我們預見我們的技術將廣泛應用於其他使用時間縮時影像的野生動物監控應用程式。

##### **Benchmarking LLMs and SLMs for patient reported outcomes**
2412.16291v1 by Matteo Marengo, Jarod Lévy, Jean-Emmanuel Bibault

LLMs have transformed the execution of numerous tasks, including those in the
medical domain. Among these, summarizing patient-reported outcomes (PROs) into
concise natural language reports is of particular interest to clinicians, as it
enables them to focus on critical patient concerns and spend more time in
meaningful discussions. While existing work with LLMs like GPT-4 has shown
impressive results, real breakthroughs could arise from leveraging SLMs as they
offer the advantage of being deployable locally, ensuring patient data privacy
and compliance with healthcare regulations. This study benchmarks several SLMs
against LLMs for summarizing patient-reported Q\&A forms in the context of
radiotherapy. Using various metrics, we evaluate their precision and
reliability. The findings highlight both the promise and limitations of SLMs
for high-stakes medical tasks, fostering more efficient and privacy-preserving
AI-driven healthcare solutions.

摘要：大型語言模型 (LLM) 已轉變了許多任務的執行方式，包括醫療領域的任務。其中，將患者報告的結果 (PRO) 摘要成簡潔的自然語言報告對臨床醫生特別有幫助，因為這能讓他們專注於患者的關鍵問題，並花更多時間在有意義的討論上。雖然像 GPT-4 等大型語言模型的現有研究成果令人印象深刻，但真正的突破可能來自於利用小型語言模型 (SLM)，因為它們具有可於本地部署的優點，確保患者資料的隱私和符合醫療法規。本研究針對放射治療情境中患者報告的問答表，將多個小型語言模型與大型語言模型進行比較。我們使用各種指標來評估它們的精確度和可靠性。研究結果突顯了小型語言模型在高風險醫療任務中的優點和限制，促進更有效率且能保護隱私的 AI 驅動醫療保健解決方案。

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v1 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings.

摘要：深度學習已進步了醫學影像分類，但可解釋性挑戰阻礙了其臨床採用。本研究透過使用概念瓶頸模型 (CBM) 和多重代理檢索增強生成 (RAG) 系統進行報告生成，增強了胸部 X 光 (CXR) 分類的可解釋性。透過對視覺特徵和臨床概念之間的關係進行建模，我們建立了可解釋的概念向量，用來引導多重代理 RAG 系統生成放射科報告，以增強臨床相關性、可解釋性和透明性。使用 LLM 作為判斷者對生成的報告進行評估，確認了我們模型輸出的可解釋性和臨床實用性。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確度，並展示了強健的報告生成效能，五項關鍵指標介於 84% 到 90% 之間。這個可解釋的多重代理架構彌合了高性能 AI 與在臨床環境中進行可靠 AI 驅動 CXR 分析所需的可解釋性之間的差距。

##### **Applying Predictive Analytics to Occupational Health and Safety in India**
2412.16038v1 by Ritwik Raj Saxena

Predictive analytics is revolutionizing occupational health and safety (OHS).
It offers evidence-based insights. These insights enable proactive risk
management and informed, data-driven decision-making in organizational
settings. This paper explores the key components of predictive analytics in
OHS, beginning with data collection, management, and preparation, and moving
through to advanced predictive modelling techniques. We emphasize the
importance of data integrity through processes such as missing value
imputation, anomaly detection, and feature engineering to ensure accurate model
predictions. Risk prioritization identifies and ranks hazards across various
factors, including employee behaviours, organizational policies, environmental
conditions, and operational practices. We posit that insights derived from
predictive models must be effectively interpreted and implemented. These
insights guide organizations to focus on high-impact areas for accident
prevention and resource optimization. The integration of predictive analytics
in OHS brings notable benefits, including enhanced decision-making, greater
operational efficiency, cost savings, and improved compliance with safety
standards. We examine applications of predictive analytics in OHS in Indian
settings. India has the largest workforce in the world, and the predominance of
it is in the informal sector - a sector largely unprotected by the already
inadequate OHS laws. Ethical considerations, data privacy concerns, and the
risk of overdependence on predictive models are discussed. We conclude with a
discussion on the potential for predictive analytics to create a data-oriented,
adaptive approach to OHS in India. We posit that, using predictive analytics,
India can develop high safety standards while traversing the complexities of
its workforce setting.

摘要：預測分析正在革新職業健康與安全 (OHS)。
它提供基於證據的見解。這些見解能讓組織環境中的風險管理更具前瞻性，並能做出明智的、資料驅動的決策。本文探討了 OHS 中預測分析的關鍵組成部分，從資料收集、管理和準備開始，並進展到進階預測建模技術。我們強調資料完整性的重要性，透過遺失值插補、異常偵測和特徵工程等流程來確保準確的模型預測。風險優先順序會根據員工行為、組織政策、環境條件和作業慣例等各種因素來識別和排名危害。我們認為，從預測模型中得出的見解必須得到有效的詮釋和實施。這些見解引導組織專注於事故預防和資源最佳化的影響重大領域。預測分析在 OHS 中的整合帶來了顯著的優勢，包括增強決策制定、提高營運效率、節省成本和改善對安全標準的遵循。我們探討了預測分析在印度環境中 OHS 中的應用。印度擁有全球最大的勞動力，其中大部分屬於非正式部門，這個部門在很大程度上不受本已不足的 OHS 法律保護。本文討論了倫理考量、資料隱私問題和過度依賴預測模型的風險。我們最後討論了預測分析在印度創造以資料為導向、適應性強的 OHS 方法的潛力。我們認為，透過使用預測分析，印度可以在其勞動力環境的複雜性中發展出高安全標準。

##### **Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?**
2412.15967v1 by Simon Langer, Jessica Ritter, Rickmer Braren, Daniel Rueckert, Paul Hager

Modern deep learning-based clinical imaging workflows rely on accurate labels
of the examined anatomical region. Knowing the anatomical region is required to
select applicable downstream models and to effectively generate cohorts of high
quality data for future medical and machine learning research efforts. However,
this information may not be available in externally sourced data or generally
contain data entry errors. To address this problem, we show the effectiveness
of self-supervised methods such as SimCLR and BYOL as well as supervised
contrastive deep learning methods in assigning one of 14 anatomical region
classes in our in-house dataset of 48,434 skeletal radiographs. We achieve a
strong linear evaluation accuracy of 96.6% with a single model and 97.7% using
an ensemble approach. Furthermore, only a few labeled instances (1% of the
training set) suffice to achieve an accuracy of 92.2%, enabling usage in
low-label and thus low-resource scenarios. Our model can be used to correct
data entry mistakes: a follow-up analysis of the test set errors of our
best-performing single model by an expert radiologist identified 35% incorrect
labels and 11% out-of-domain images. When accounted for, the radiograph
anatomical region labelling performance increased -- without and with an
ensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.

摘要：現代的深度學習臨床影像工作流程依賴於檢查解剖區域的準確標籤。了解解剖區域是必要的，用於選擇適用的下游模型，並有效地為未來的醫療和機器學習研究工作生成高品質資料群組。然而，此資訊可能無法在外部來源的資料中取得，或通常包含資料輸入錯誤。為了解決這個問題，我們展示了自監督方法（例如 SimCLR 和 BYOL）以及監督對比深度學習方法在我們內部 48,434 張骨骼 X 光片的資料集中分配 14 個解剖區域類別之一的有效性。我們使用單一模型達到了 96.6% 的強線性評估準確度，並使用整體方法達到了 97.7%。此外，僅有少數標記實例（訓練組的 1%）就足以達到 92.2% 的準確度，這使得在標籤少且資源少的情況下使用成為可能。我們的模型可用於更正資料輸入錯誤：由專業放射科醫師對我們效能最佳的單一模型的測試組錯誤進行後續分析，識別出 35% 的錯誤標籤和 11% 的領域外影像。在考慮到的情況下，X 光片解剖區域標籤效能提高了（分別在沒有和有整體的情況下）達到 98.0% 和 98.8% 的理論準確度。

##### **From General to Specific: Tailoring Large Language Models for Personalized Healthcare**
2412.15957v1 by Ruize Shi, Hong Huang, Wei Zhou, Kehan Yin, Kai Zhao, Yun Zhao

The rapid development of large language models (LLMs) has transformed many
industries, including healthcare. However, previous medical LLMs have largely
focused on leveraging general medical knowledge to provide responses, without
accounting for patient variability and lacking true personalization at the
individual level. To address this, we propose a novel method called
personalized medical language model (PMLM), which explores and optimizes
personalized LLMs through recommendation systems and reinforcement learning
(RL). Specifically, by utilizing self-informed and peer-informed
personalization, PMLM captures changes in behaviors and preferences to design
initial personalized prompts tailored to individual needs. We further refine
these initial personalized prompts through RL, ultimately enhancing the
precision of LLM guidance. Notably, the personalized prompt are hard prompt,
which grants PMLM high adaptability and reusability, allowing it to directly
leverage high-quality proprietary LLMs. We evaluate PMLM using real-world
obstetrics and gynecology data, and the experimental results demonstrate that
PMLM achieves personalized responses, and it provides more refined and
individualized services, offering a potential way for personalized medical
LLMs.

摘要：大型語言模型 (LLM) 的快速發展已轉變許多產業，包括醫療保健。然而，先前的醫療 LLM 主要專注於利用一般醫療知識提供回應，並未考量病患的變異性，且缺乏個人層級的真正個人化。為了解決此問題，我們提出了一種稱為個人化醫療語言模型 (PMLM) 的新方法，透過推薦系統和強化學習 (RL) 來探索和最佳化個人化的 LLM。具體來說，PMLM 透過利用自我知情和同儕知情的個人化，擷取行為和偏好的變化，以設計符合個人需求的初始個人化提示。我們進一步透過 RL 調整這些初始個人化提示，最終提升 LLM 指導的精確度。值得注意的是，個人化提示是硬提示，這賦予 PMLM 高度的適應性和可重複使用性，使其能夠直接利用高品質的專有 LLM。我們使用真實世界的產科和婦科資料評估 PMLM，實驗結果顯示 PMLM 達到了個人化的回應，並提供了更精緻和個人化的服務，為個人化的醫療 LLM 提供了一種潛在的方法。

##### **Development of a Large-scale Dataset of Chest Computed Tomography Reports in Japanese and a High-performance Finding Classification Model**
2412.15907v1 by Yosuke Yamagishi, Yuta Nakamura, Tomohiro Kikuchi, Yuki Sonoda, Hiroshi Hirakawa, Shintaro Kano, Satoshi Nakamura, Shouhei Hanaoka, Takeharu Yoshikawa, Osamu Abe

Background: Recent advances in large language models highlight the need for
high-quality multilingual medical datasets. While Japan leads globally in CT
scanner deployment and utilization, the lack of large-scale Japanese radiology
datasets has hindered the development of specialized language models for
medical imaging analysis. Objective: To develop a comprehensive Japanese CT
report dataset through machine translation and establish a specialized language
model for structured finding classification. Additionally, to create a
rigorously validated evaluation dataset through expert radiologist review.
Methods: We translated the CT-RATE dataset (24,283 CT reports from 21,304
patients) into Japanese using GPT-4o mini. The training dataset consisted of
22,778 machine-translated reports, while the validation dataset included 150
radiologist-revised reports. We developed CT-BERT-JPN based on
"tohoku-nlp/bert-base-japanese-v3" architecture for extracting 18 structured
findings from Japanese radiology reports. Results: Translation metrics showed
strong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores
ranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression
sections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in
11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular
septal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1
scores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in
four conditions. Conclusions: Our study establishes a robust Japanese CT report
dataset and demonstrates the effectiveness of a specialized language model for
structured finding classification. The hybrid approach of machine translation
and expert validation enables the creation of large-scale medical datasets
while maintaining high quality.

摘要：背景：大型語言模型的最新進展凸顯了對高品質多語言醫療資料集的需求。日本在 CT 掃描儀的部署和使用方面處於全球領先地位，但缺乏大規模的日語放射科資料集阻礙了針對醫學影像分析的專門語言模型的開發。目標：透過機器翻譯開發一個全面的日語 CT 報告資料集，並建立一個專門的語言模型，用於結構化結果分類。此外，透過專家放射科醫師的審查，建立一個嚴格驗證的評估資料集。方法：我們使用 GPT-4o mini 將 CT-RATE 資料集（來自 21,304 名患者的 24,283 份 CT 報告）翻譯成日語。訓練資料集包含 22,778 份機器翻譯報告，而驗證資料集包含 150 份放射科醫師修改過的報告。我們基於「tohoku-nlp/bert-base-japanese-v3」架構開發了 CT-BERT-JPN，用於從日語放射科報告中提取 18 項結構化結果。結果：翻譯指標顯示強勁的表現，BLEU 分數為 0.731 和 0.690，而 ROUGE 分數從結果的 0.770 到 0.876，從印象部分的 0.748 到 0.857 不等。與 GPT-4o 相比，CT-BERT-JPN 在 18 種情況中的 11 種情況下表現出優異的表現，包括淋巴腺病變（+14.2%）、小葉間隔增厚（+10.9%）和肺不張（+7.4%）。該模型在 18 種情況中的 14 種情況下維持 F1 分數超過 0.95，並在四種情況下達到完美分數。結論：我們的研究建立了一個強大的日語 CT 報告資料集，並展示了一個專門的語言模型在結構化結果分類方面的有效性。機器翻譯和專家驗證的混合方法能夠建立大規模的醫療資料集，同時保持高品質。

##### **Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease Detection based on Spontaneous Speech**
2412.15772v1 by Jonathan Heitz, Gerold Schneider, Nicolas Langer

Alzheimer's Disease (AD) is a significant and growing public health concern.
Investigating alterations in speech and language patterns offers a promising
path towards cost-effective and non-invasive early detection of AD on a large
scale. Large language models (LLMs), such as GPT, have enabled powerful new
possibilities for semantic text analysis. In this study, we leverage GPT-4 to
extract five semantic features from transcripts of spontaneous patient speech.
The features capture known symptoms of AD, but they are difficult to quantify
effectively using traditional methods of computational linguistics. We
demonstrate the clinical significance of these features and further validate
one of them ("Word-Finding Difficulties") against a proxy measure and human
raters. When combined with established linguistic features and a Random Forest
classifier, the GPT-derived features significantly improve the detection of AD.
Our approach proves effective for both manually transcribed and automatically
generated transcripts, representing a novel and impactful use of recent
advancements in LLMs for AD speech analysis.

摘要：阿茲海默症 (AD) 是個重大的且持續增加的公共衛生問題。
調查言語和語言模式的變化提供了一個有前景的途徑，可以大規模地對 AD 進行經濟有效且非侵入性的早期偵測。大型語言模型 (LLM)，例如 GPT，已經為語義文字分析開啟了強大的新可能性。在這項研究中，我們利用 GPT-4 從自發性患者言語的轉錄中提取五個語義特徵。這些特徵捕捉了 AD 的已知症狀，但使用傳統的計算語言學方法很難有效地量化它們。我們展示了這些特徵的臨床意義，並進一步驗證了其中一個特徵（「詞彙尋找困難」）與代理測量和人類評分員的結果。當與既定的語言特徵和隨機森林分類器結合時，GPT 衍生的特徵顯著改善了 AD 的偵測。我們的做法證明了手動轉錄和自動產生的轉錄都是有效的，這代表了 LLM 在 AD 語言分析中最新進展的一種新穎且有影響力的應用。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning**
2412.15547v1 by Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Diet plays a critical role in human health, yet tailoring dietary reasoning
to individual health conditions remains a major challenge. Nutrition Question
Answering (QA) has emerged as a popular method for addressing this problem.
However, current research faces two critical limitations. On one hand, the
absence of datasets involving user-specific medical information severely limits
\textit{personalization}. This challenge is further compounded by the wide
variability in individual health needs. On the other hand, while large language
models (LLMs), a popular solution for this task, demonstrate strong reasoning
abilities, they struggle with the domain-specific complexities of personalized
healthy dietary reasoning, and existing benchmarks fail to capture these
challenges. To address these gaps, we introduce the Nutritional Graph Question
Answering (NGQA) benchmark, the first graph question answering dataset designed
for personalized nutritional health reasoning. NGQA leverages data from the
National Health and Nutrition Examination Survey (NHANES) and the Food and
Nutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is
healthy for a specific user, supported by explanations of the key contributing
nutrients. The benchmark incorporates three question complexity settings and
evaluates reasoning across three downstream tasks. Extensive experiments with
LLM backbones and baseline models demonstrate that the NGQA benchmark
effectively challenges existing models. In sum, NGQA addresses a critical
real-world problem while advancing GraphQA research with a novel
domain-specific benchmark.

摘要：飲食在人類健康中扮演著至關重要的角色，然而根據個人健康狀況調整飲食推理仍然是一項重大的挑戰。營養問題問答 (QA) 已成為解決此問題的流行方法。不過，目前的研究面臨兩項重大的限制。一方面，缺乏包含使用者特定醫療資訊的資料集嚴重限制了「個人化」。這個挑戰進一步受到個人健康需求廣泛變異的影響。另一方面，雖然大型語言模型 (LLM) 是此任務的熱門解決方案，展示出強大的推理能力，但它們在個人化健康飲食推理的特定領域複雜性上仍有困難，而現有的基準也無法捕捉這些挑戰。為了解決這些差距，我們引入了營養圖表問答 (NGQA) 基準，這是第一個專為個人化營養健康推理設計的圖表問答資料集。NGQA 利用國家健康與營養檢查調查 (NHANES) 和飲食研究食物與營養資料庫 (FNDDS) 的資料，評估食物是否對特定使用者健康，並說明主要貢獻營養素。此基準納入了三個問題複雜度設定，並評估三個下游任務的推理。使用 LLM 主幹和基線模型進行的廣泛實驗證明，NGQA 基準有效挑戰了現有模型。總之，NGQA 解決了一個重大的現實世界問題，同時透過新穎的特定領域基準推動了 GraphQA 研究。

##### **The First Multilingual Model For The Detection of Suicide Texts**
2412.15498v1 by Rodolfo Zevallos, Annika Schoene, John E. Ortega

Suicidal ideation is a serious health problem affecting millions of people
worldwide. Social networks provide information about these mental health
problems through users' emotional expressions. We propose a multilingual model
leveraging transformer architectures like mBERT, XML-R, and mT5 to detect
suicidal text across posts in six languages - Spanish, English, German,
Catalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was
translated into five other languages using SeamlessM4T. Each model was
fine-tuned on this multilingual data and evaluated across classification
metrics. Results showed mT5 achieving the best performance overall with F1
scores above 85%, highlighting capabilities for cross-lingual transfer
learning. The English and Spanish translations also displayed high quality
based on perplexity. Our exploration underscores the importance of considering
linguistic diversity in developing automated multilingual tools to identify
suicidal risk. Limitations exist around semantic fidelity in translations and
ethical implications which provide guidance for future human-in-the-loop
evaluations.

摘要：自殺意念是一個嚴重的健康問題，影響全球數百萬人。社交網路透過使用者的情緒表達，提供這些心理健康問題的資訊。我們提出一個多語言模型，利用像 mBERT、XML-R 和 mT5 的轉換器架構，來偵測六種語言（西班牙文、英文、德文、加泰隆尼亞文、葡萄牙文和義大利文）貼文中具有自殺傾向的文字。一個西班牙文自殺意念推文資料集使用 SeamlessM4T 翻譯成其他五種語言。每個模型都針對這個多語言資料進行微調，並評估分類指標。結果顯示，mT5 在整體表現上達到最佳，F1 分數高於 85%，突顯跨語言轉移學習的能力。英文和西班牙文的翻譯也根據困惑度顯示出高品質。我們的探索強調在開發自動化多語言工具以識別自殺風險時，考慮語言多樣性的重要性。翻譯中的語義忠實度和倫理意涵存在限制，這些限制為未來的人類參與評估提供了指導。

##### **AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals**
2412.15444v1 by Angela Mastrianni, Hope Twede, Aleksandra Sarcevic, Jeremiah Wander, Christina Austin-Tse, Scott Saponas, Heidi Rehm, Ashley Mae Conard, Amanda K. Hall

Generative AI has the potential to transform knowledge work, but further
research is needed to understand how knowledge workers envision using and
interacting with generative AI. We investigate the development of generative AI
tools to support domain experts in knowledge work, examining task delegation
and the design of human-AI interactions. Our research focused on designing a
generative AI assistant to aid genetic professionals in analyzing whole genome
sequences (WGS) and other clinical data for rare disease diagnosis. Through
interviews with 17 genetics professionals, we identified current challenges in
WGS analysis. We then conducted co-design sessions with six genetics
professionals to determine tasks that could be supported by an AI assistant and
considerations for designing interactions with the AI assistant. From our
findings, we identified sensemaking as both a current challenge in WGS analysis
and a process that could be supported by AI. We contribute an understanding of
how domain experts envision interacting with generative AI in their knowledge
work, a detailed empirical study of WGS analysis, and three design
considerations for using generative AI to support domain experts in sensemaking
during knowledge work.
  CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical
studies in HCI
  Additional Keywords and Phrases: whole genome sequencing, generative AI,
large language models, knowledge work, sensemaking, co-design, rare disease
  Contact Author: Angela Mastrianni (This work was done during the author's
internship at Microsoft Research)
  Ashley Mae Conard and Amanda K. Hall contributed equally

摘要：<paragraph>生成式 AI 有可能轉換知識工作，但需要進一步的研究來了解知識工作者如何設想使用和與生成式 AI 互動。我們研究了生成式 AI 工具的開發，以支援領域專家進行知識工作，探討任務委派和人機互動的設計。我們的研究重點在於設計一個生成式 AI 助理，以協助遺傳學專業人士分析全基因體序列 (WGS) 和其他臨床資料，以診斷罕見疾病。透過訪談 17 位遺傳學專業人士，我們找出 WGS 分析中的現有挑戰。然後，我們與六位遺傳學專業人士進行共同設計會議，以確定 AI 助理可以支援的任務，以及設計與 AI 助理互動的考量因素。根據我們的研究結果，我們將意義建構認定為 WGS 分析中的現有挑戰，以及 AI 可以支援的流程。我們有助於了解領域專家如何設想在知識工作中與生成式 AI 互動，WGS 分析的詳細實證研究，以及在知識工作中使用生成式 AI 支援領域專家進行意義建構的三個設計考量因素。
CCS 概念：以人為本的運算、人機互動、HCI 中的實證研究
其他關鍵字和詞組：全基因體定序、生成式 AI、大型語言模型、知識工作、意義建構、共同設計、罕見疾病
聯絡作者：Angela Mastrianni（這項工作是在作者於 Microsoft Research 實習期間完成的）
Ashley Mae Conard 和 Amanda K. Hall 貢獻相同</paragraph>

##### **GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation**
2412.15054v1 by G. Andrade-Miranda, K. Chatzipapas, J. D. Arias-Londoño, J. I. Godino-Llorente

The advances in the development of Facilitative Playbacks extracted from
High-Speed videoendoscopic sequences of the vocal folds are hindered by a
notable lack of publicly available datasets annotated with the semantic
segmentations corresponding to the area of the glottal gap. This fact also
limits the reproducibility and further exploration of existing research in this
field.
  To address this gap, GIRAFE is a data repository designed to facilitate the
development of advanced techniques for the semantic segmentation, analysis, and
fast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The
repository includes 65 high-speed videoendoscopic recordings from a cohort of
50 patients (30 female, 20 male). The dataset comprises 15 recordings from
healthy controls, 26 from patients with diagnosed voice disorders, and 24 with
an unknown health condition. All of them were manually annotated by an expert,
including the masks corresponding to the semantic segmentation of the glottal
gap. The repository is also complemented with the automatic segmentation of the
glottal area using different state-of-the-art approaches.
  This data set has already supported several studies, which demonstrates its
usefulness for the development of new glottal gap segmentation algorithms from
High-Speed-Videoendoscopic sequences to improve or create new Facilitative
Playbacks. Despite these advances and others in the field, the broader
challenge of performing an accurate and completely automatic semantic
segmentation method of the glottal area remains open.

摘要：<paragraph>從高速聲門內視鏡序列中提取的促進性回放的發展進展受到明顯缺乏公開可用資料集的阻礙，這些資料集帶有與聲門間隙區域相應的語義分割註解。這個事實也限制了現有研究在此領域的可重現性和進一步探索。
  為了解決這個差距，GIRAFE 是旨在促進語義分割、分析和高速聲門內視鏡序列快速評估的先進技術開發的資料庫。這個資料庫包含來自 50 位患者（30 位女性，20 位男性）的 65 份高速聲門內視鏡錄音。該資料集包含 15 份來自健康對照組的錄音、26 份來自被診斷出患有聲音障礙的患者的錄音，以及 24 份來自健康狀況不明的患者的錄音。所有這些錄音都由專家手動註解，包括與聲門間隙語義分割相應的遮罩。該資料庫還使用不同的最先進方法補充了聲門區域的自動分割。
  此資料集已經支援多項研究，這證明了它對於從高速視頻內視鏡序列開發新的聲門間隙分割演算法以改善或建立新的促進性回放很有用。儘管在該領域取得了這些進展和其他進展，但執行準確且完全自動化的聲門區域語義分割方法的更廣泛挑戰仍然存在。</paragraph>

##### **RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response**
2412.14922v1 by Junyu Luo, Xiao Luo, Kaize Ding, Jingyang Yuan, Zhiping Xiao, Ming Zhang

Supervised fine-tuning (SFT) plays a crucial role in adapting large language
models (LLMs) to specific domains or tasks. However, as demonstrated by
empirical experiments, the collected data inevitably contains noise in
practical applications, which poses significant challenges to model performance
on downstream tasks. Therefore, there is an urgent need for a noise-robust SFT
framework to enhance model capabilities in downstream tasks. To address this
challenge, we introduce a robust SFT framework (RobustFT) that performs noise
detection and relabeling on downstream task data. For noise identification, our
approach employs a multi-expert collaborative system with inference-enhanced
models to achieve superior noise detection. In the denoising phase, we utilize
a context-enhanced strategy, which incorporates the most relevant and confident
knowledge followed by careful assessment to generate reliable annotations.
Additionally, we introduce an effective data selection mechanism based on
response entropy, ensuring only high-quality samples are retained for
fine-tuning. Extensive experiments conducted on multiple LLMs across five
datasets demonstrate RobustFT's exceptional performance in noisy scenarios.

摘要：監督式微調（SFT）在將大型語言模型（LLM）適應到特定領域或任務中扮演著至關重要的角色。然而，正如經驗實驗所證明，在實際應用中收集到的資料不可避免地包含雜訊，這對下游任務的模型效能構成了重大挑戰。因此，迫切需要一個抗雜訊的 SFT 框架，以增強模型在下游任務中的能力。為了應對這一挑戰，我們引入了穩健的 SFT 框架（RobustFT），它對下游任務資料執行雜訊偵測和重新標記。對於雜訊識別，我們的方法採用多專家協作系統，並使用增強推論的模型來實現優異的雜訊偵測。在去雜訊階段，我們利用一種情境增強策略，它結合了最相關和最確信的知識，然後進行仔細評估以產生可靠的註解。此外，我們還引入了一種基於回應熵的有效資料選取機制，確保僅保留高品質的樣本進行微調。在五個資料集上對多個 LLM 進行的廣泛實驗證明了 RobustFT 在雜訊情境中的出色效能。

##### **Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review**
2412.14736v1 by Pir Bakhsh Khokhar, Carmine Gravino, Fabio Palomba

This systematic review explores the use of machine learning (ML) in
predicting diabetes, focusing on datasets, algorithms, training methods, and
evaluation metrics. It examines datasets like the Singapore National Diabetic
Retinopathy Screening program, REPLACE-BG, National Health and Nutrition
Examination Survey, and Pima Indians Diabetes Database. The review assesses the
performance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in
predicting diabetes outcomes. The study emphasizes the importance of
interdisciplinary collaboration and ethical considerations in ML-based diabetes
prediction models.

摘要：這項系統性回顧探討了機器學習 (ML) 在糖尿病預測中的應用，重點在於資料集、演算法、訓練方法和評估指標。它檢驗了資料集，例如新加坡國家糖尿病視網膜病變篩檢計畫、REPLACE-BG、國家健康與營養檢查調查和皮馬印第安人糖尿病資料庫。該回顧評估了 ML 演算法（例如 CNN、SVM、邏輯迴歸和 XGBoost）在預測糖尿病結果方面的表現。這項研究強調了跨領域合作和在基於 ML 的糖尿病預測模型中進行道德考量的重要性。

##### **Pitfalls of topology-aware image segmentation**
2412.14619v1 by Alexander H. Berger, Laurin Lux, Alexander Weers, Martin Menten, Daniel Rueckert, Johannes C. Paetzold

Topological correctness, i.e., the preservation of structural integrity and
specific characteristics of shape, is a fundamental requirement for medical
imaging tasks, such as neuron or vessel segmentation. Despite the recent surge
in topology-aware methods addressing this challenge, their real-world
applicability is hindered by flawed benchmarking practices. In this paper, we
identify critical pitfalls in model evaluation that include inadequate
connectivity choices, overlooked topological artifacts in ground truth
annotations, and inappropriate use of evaluation metrics. Through detailed
empirical analysis, we uncover these issues' profound impact on the evaluation
and ranking of segmentation methods. Drawing from our findings, we propose a
set of actionable recommendations to establish fair and robust evaluation
standards for topology-aware medical image segmentation methods.

摘要：拓撲正確性，即形狀結構完整性和特定特徵的保留，是醫學影像任務（例如神經元或血管分割）的基本要求。儘管最近解決此挑戰的拓撲感知方法激增，但其真實世界的適用性受到有缺陷的基準測試實務的阻礙。在本文中，我們確定了模型評估中的關鍵缺陷，包括不適當的連接選擇、基本事實標註中被忽略的拓撲人工製品，以及評估指標的不適當使用。透過詳細的經驗分析，我們揭示了這些問題對分割方法的評估和排名產生的深遠影響。根據我們的研究結果，我們提出了一組可行的建議，以建立公平且穩健的評估標準，用於拓撲感知醫學影像分割方法。

##### **CwA-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection**
2412.14522v2 by Youshen Zhao, Keiji Iramina

Electroencephalogram (EEG) signals are critical for detecting abnormal brain
activity, but their high dimensionality and complexity pose significant
challenges for effective analysis. In this paper, we propose CwA-T, a novel
framework that combines a channelwise CNN-based autoencoder with a single-head
transformer classifier for efficient EEG abnormality detection. The channelwise
autoencoder compresses raw EEG signals while preserving channel independence,
reducing computational costs and retaining biologically meaningful features.
The compressed representations are then fed into the transformer-based
classifier, which efficiently models long-term dependencies to distinguish
between normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,
the proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%
specificity at the per-case level, outperforming baseline models such as
EEGNet, Deep4Conv, and FusionCNN. Furthermore, CwA-T requires only 202M FLOPs
and 2.9M parameters, making it significantly more efficient than
transformer-based alternatives. The framework retains interpretability through
its channelwise design, demonstrating great potential for future applications
in neuroscience research and clinical practice. The source code is available at
https://github.com/YossiZhao/CAE-T.

摘要：腦電圖 (EEG) 訊號對於偵測異常腦部活動至關重要，但其高維度和複雜性對有效分析構成重大挑戰。在本文中，我們提出 CwA-T，一個結合通道式 CNN 自動編碼器與單頭轉換器分類器的創新架構，以進行有效的腦電圖異常偵測。通道式自動編碼器壓縮原始腦電圖訊號，同時保留通道獨立性，降低運算成本並保留具有生物意義的特徵。壓縮後的表示接著被輸入到基於轉換器的分類器中，該分類器有效地建模長期依賴性，以區分正常和異常訊號。在 TUH 異常腦電圖語料庫上進行評估，所提出的模型在個案層級達到 85.0% 的準確度、76.2% 的敏感度和 91.2% 的特異性，優於基線模型，例如 EEGNet、Deep4Conv 和 FusionCNN。此外，CwA-T 只需要 202M FLOP 和 2.9M 參數，使其比基於轉換器的替代方案更有效率。該架構透過其通道式設計保留了解釋性，展示了在神經科學研究和臨床實務中未來應用上的巨大潛力。原始程式碼可在 https://github.com/YossiZhao/CAE-T 取得。

##### **GenHMR: Generative Human Mesh Recovery**
2412.14444v1 by Muhammad Usama Saleem, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen

Human mesh recovery (HMR) is crucial in many computer vision applications;
from health to arts and entertainment. HMR from monocular images has
predominantly been addressed by deterministic methods that output a single
prediction for a given 2D image. However, HMR from a single image is an
ill-posed problem due to depth ambiguity and occlusions. Probabilistic methods
have attempted to address this by generating and fusing multiple plausible 3D
reconstructions, but their performance has often lagged behind deterministic
approaches. In this paper, we introduce GenHMR, a novel generative framework
that reformulates monocular HMR as an image-conditioned generative task,
explicitly modeling and mitigating uncertainties in the 2D-to-3D mapping
process. GenHMR comprises two key components: (1) a pose tokenizer to convert
3D human poses into a sequence of discrete tokens in a latent space, and (2) an
image-conditional masked transformer to learn the probabilistic distributions
of the pose tokens, conditioned on the input image prompt along with randomly
masked token sequence. During inference, the model samples from the learned
conditional distribution to iteratively decode high-confidence pose tokens,
thereby reducing 3D reconstruction uncertainties. To further refine the
reconstruction, a 2D pose-guided refinement technique is proposed to directly
fine-tune the decoded pose tokens in the latent space, which forces the
projected 3D body mesh to align with the 2D pose clues. Experiments on
benchmark datasets demonstrate that GenHMR significantly outperforms
state-of-the-art methods. Project website can be found at
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html

摘要：人體網格重建（HMR）在許多電腦視覺應用中至關重要；
從健康到藝術和娛樂。單目影像的 HMR 主要由確定性方法解決，
該方法針對給定的 2D 影像輸出單一預測。然而，由於深度模糊和遮擋，
單一影像的 HMR 是個病態問題。機率方法嘗試透過產生和融合多個合理的 3D
重建來解決此問題，但其效能通常落後於確定性方法。在本文中，我們介紹
GenHMR，這是一個新穎的生成式架構，將單目 HMR 重新表述為一個影像條件生成任務，
明確建模和減輕 2D 到 3D 對應過程中的不確定性。GenHMR 包含兩個關鍵組成部分：
（1）姿勢標記化器，將 3D 人體姿勢轉換為潛在空間中的離散標記序列，以及
（2）影像條件遮罩轉換器，以輸入影像提示以及隨機遮罩標記序列為條件，
學習姿勢標記的機率分佈。在推論期間，模型從學習到的條件分佈中取樣，
以反覆解碼高置信度姿勢標記，從而減少 3D 重建的不確定性。為了進一步優化
重建，提出了一種 2D 姿勢引導的優化技術，以直接微調潛在空間中解碼的姿勢標記，
這迫使投影的 3D 身體網格與 2D 姿勢線索對齊。基準資料集上的實驗證明，
GenHMR 明顯優於最先進的方法。專案網站可以在
https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html 找到

##### **FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning**
2412.14424v1 by Pramit Saha, Divyanshu Mishra, Felix Wagner, Konstantinos Kamnitsas, J. Alison Noble

Large Vision-Language Models typically require large text and image datasets
for effective fine-tuning. However, collecting data from various sites,
especially in healthcare, is challenging due to strict privacy regulations. An
alternative is to fine-tune these models on end-user devices, such as in
medical clinics, without sending data to a server. These local clients
typically have limited computing power and small datasets, which are not enough
for fully fine-tuning large VLMs on their own. A naive solution to these
scenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and
apply federated learning (FL) algorithms to combine the learned adapter
weights, thereby respecting the resource limitations and data privacy. However,
this approach does not fully leverage the knowledge from multiple adapters
trained on diverse data distributions and for diverse tasks. The adapters are
adversely impacted by data heterogeneity and task heterogeneity across clients
resulting in suboptimal convergence. To this end, we propose a novel framework
called FedPIA that improves upon the naive combinations of FL and PEFT by
introducing Permutation and Integration of the local Adapters in the server and
global Adapters in the clients exploiting Wasserstein barycenters for improved
blending of client-specific and client-agnostic knowledge. This layerwise
permutation helps to bridge the gap in the parameter space of local and global
adapters before integration. We conduct over 2000 client-level experiments
utilizing 48 medical image datasets across five different medical
vision-language FL task settings encompassing visual question answering as well
as image and report-based multi-label disease detection. Our experiments
involving diverse client settings, ten different modalities, and two VLM
backbones demonstrate that FedPIA consistently outperforms the state-of-the-art
PEFT-FL baselines.

摘要：大型視覺語言模型通常需要大型文字和影像資料集才能進行有效的微調。然而，由於嚴格的隱私法規，從各種網站收集資料，特別是在醫療保健方面，是一項挑戰。另一種方法是在終端使用者裝置上微調這些模型，例如在醫療診所，而不將資料傳送至伺服器。這些本機用戶端通常具有受限的運算能力和小型資料集，不足以自行對大型 VLM 進行完全微調。針對這些場景的一個天真解決方案是利用參數有效微調 (PEFT) 策略，並套用聯邦學習 (FL) 演算法來結合學習到的適配器權重，從而尊重資源限制和資料隱私。然而，此方法並未充分利用從訓練於不同資料分佈和不同任務的多個適配器中獲得的知識。適配器受到客戶端間資料異質性和任務異質性的不利影響，導致次佳收斂。為此，我們提出了一個名為 FedPIA 的新架構，透過在伺服器中引入局部適配器的排列和整合，以及在客戶端中引入全球適配器，並利用 Wasserstein 重心來改善客戶端特定和客戶端不可知知識的混合，從而改進 FL 和 PEFT 的天真組合。這種逐層排列有助於在整合之前彌合局部和全球適配器參數空間的差距。我們利用 48 個醫學影像資料集在五個不同的醫學視覺語言 FL 任務設定中進行了 2000 多個客戶端層級實驗，包括視覺問題解答以及基於影像和報告的多標籤疾病檢測。我們涉及不同客戶端設定、十種不同模式和兩個 VLM 主幹的實驗表明，FedPIA 持續優於最先進的 PEFT-FL 基準。

##### **Clinical Trials Ontology Engineering with Large Language Models**
2412.14387v1 by Berkan Çakır

Managing clinical trial information is currently a significant challenge for
the medical industry, as traditional methods are both time-consuming and
costly. This paper proposes a simple yet effective methodology to extract and
integrate clinical trial data in a cost-effective and time-efficient manner.
Allowing the medical industry to stay up-to-date with medical developments.
Comparing time, cost, and quality of the ontologies created by humans, GPT3.5,
GPT4, and Llama3 (8b & 70b). Findings suggest that large language models (LLM)
are a viable option to automate this process both from a cost and time
perspective. This study underscores significant implications for medical
research where real-time data integration from clinical trials could become the
norm.

摘要：管理臨床試驗資訊目前是醫療產業的一項重大挑戰，因為傳統方法既耗時又昂貴。本文提出一個簡單但有效的方法，以經濟有效且省時的方式提取和整合臨床試驗資料。讓醫療產業能隨時掌握醫療發展。比較人類、GPT3.5、GPT4 和 Llama3（8b 和 70b）建立的本体的時間、成本和品質。研究結果表明，大型語言模型 (LLM) 是從成本和時間角度自動化此流程的可行選項。這項研究強調了對醫療研究的重要影響，其中臨床試驗的即時資料整合可能會成為常態。

##### **Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing LLM Ophthalmological QA in LMICs**
2412.14304v1 by David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao, Jose Carlo Artiaga, André Hiroshi Bando, Carolina Pelegrini Barbosa Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G Morley, Luis Filipe Nakayama

Current ophthalmology clinical workflows are plagued by over-referrals, long
waits, and complex and heterogeneous medical records. Large language models
(LLMs) present a promising solution to automate various procedures such as
triaging, preliminary tests like visual acuity assessment, and report
summaries. However, LLMs have demonstrated significantly varied performance
across different languages in natural language question-answering tasks,
potentially exacerbating healthcare disparities in Low and Middle-Income
Countries (LMICs). This study introduces the first multilingual
ophthalmological question-answering benchmark with manually curated questions
parallel across languages, allowing for direct cross-lingual comparisons. Our
evaluation of 6 popular LLMs across 7 different languages reveals substantial
bias across different languages, highlighting risks for clinical deployment of
LLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought
or Retrieval-augmented generation (RAG) by themselves fall short of closing
this performance gap, often failing to improve performance across all languages
and lacking specificity for the medical domain. To address this issue, We
propose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time
de-biasing method leveraging retrieval augmented generation and
self-verification. Our approach not only improves performance across all
languages but also significantly reduces the multilingual bias gap,
facilitating equitable LLM application across the globe.

摘要：<paragraph>當前眼科臨床工作流程飽受過度轉診、漫長等待時間以及複雜且異質的醫療記錄所苦。大型語言模型 (LLM) 提供了一個有前景的解決方案，可自動化各種程序，例如分流、視力評估等初步測試和報告摘要。然而，LLM 已在自然語言問答任務中展現出跨不同語言的顯著差異效能，這可能會加劇低收入和中等收入國家 (LMIC) 的醫療保健差異。本研究引入了首個多語言眼科問答基準，其中包含手動策劃且跨語言平行的問題，允許直接進行跨語言比較。我們對 7 種不同語言中的 6 個熱門 LLM 進行評估，結果顯示不同語言之間存在顯著偏差，突顯出在 LMIC 中部署 LLM 的臨床風險。現有的去偏方法，例如翻譯思維鏈或檢索增強生成 (RAG)，本身無法縮小此效能差距，通常無法改善所有語言的效能，且缺乏針對醫療領域的專一性。為了解決此問題，我們提出 CLARA (跨語言反射代理系統)，這是一種新穎的推理時間去偏方法，利用檢索增強生成和自我驗證。我們的做法不僅改善了所有語言的效能，還顯著縮小了多語言偏見差距，促進了 LLM 在全球範圍內的公平應用。</paragraph>

##### **Discovering maximally consistent distribution of causal tournaments with Large Language Models**
2412.14019v1 by Federico Baldo, Simon Ferreira, Charles K. Assaad

Causal discovery is essential for understanding complex systems, yet
traditional methods often depend on strong, untestable assumptions, making the
process challenging. Large Language Models (LLMs) present a promising
alternative for extracting causal insights from text-based metadata, which
consolidates domain expertise. However, LLMs are prone to unreliability and
hallucinations, necessitating strategies that account for their limitations.
One such strategy involves leveraging a consistency measure to evaluate
reliability. Additionally, most text metadata does not clearly distinguish
direct causal relationships from indirect ones, further complicating the
inference of causal graphs. As a result, focusing on causal orderings, rather
than causal graphs, emerges as a more practical and robust approach. We propose
a novel method to derive a distribution of acyclic tournaments (representing
plausible causal orders) that maximizes a consistency score. Our approach
begins by computing pairwise consistency scores between variables, yielding a
cyclic tournament that aggregates these scores. From this structure, we
identify optimal acyclic tournaments compatible with the original tournament,
prioritizing those that maximize consistency across all configurations. We
tested our method on both classical and well-established bechmarks, as well as
real-world datasets from epidemiology and public health. Our results
demonstrate the effectiveness of our approach in recovering distributions
causal orders with minimal error.

摘要：因果發現對於理解複雜系統至關重要，但傳統方法通常依賴於強而不可測試的假設，這使得這個過程充滿挑戰。大型語言模型 (LLM) 提供了一個從基於文本的元數據中提取因果見解的有希望的替代方案，它整合了領域專業知識。然而，LLM 容易出現不可靠性和幻覺，這需要考慮其限制的策略。一種這樣的策略涉及利用一致性度量來評估可靠性。此外，大多數文本元數據並未清楚地區分直接因果關係和間接因果關係，這進一步複雜化了因果圖的推論。因此，專注於因果順序，而不是因果圖，成為一種更實用、更穩健的方法。我們提出了一種新方法來推導無環錦標賽的分布（表示合理的因果順序），這最大化了一致性分數。我們的做法首先計算變量之間成對的一致性分數，產生一個彙總這些分數的循環錦標賽。從這個結構中，我們識別出與原始錦標賽相容的最佳無環錦標賽，優先考慮那些在所有配置中最大化一致性的錦標賽。我們在經典且完善的基準以及來自流行病學和公共衛生的真實世界數據集上測試了我們的模型。我們的結果證明了我們的方法在以最小誤差恢復因果順序分布方面的有效性。

##### **SurgSora: Decoupled RGBD-Flow Diffusion Model for Controllable Surgical Video Generation**
2412.14018v1 by Tong Chen, Shuya Yang, Junyi Wang, Long Bai, Hongliang Ren, Luping Zhou

Medical video generation has transformative potential for enhancing surgical
understanding and pathology insights through precise and controllable visual
representations. However, current models face limitations in controllability
and authenticity. To bridge this gap, we propose SurgSora, a
motion-controllable surgical video generation framework that uses a single
input frame and user-controllable motion cues. SurgSora consists of three key
modules: the Dual Semantic Injector (DSI), which extracts object-relevant RGB
and depth features from the input frame and integrates them with segmentation
cues to capture detailed spatial features of complex anatomical structures; the
Decoupled Flow Mapper (DFM), which fuses optical flow with semantic-RGB-D
features at multiple scales to enhance temporal understanding and object
spatial dynamics; and the Trajectory Controller (TC), which allows users to
specify motion directions and estimates sparse optical flow, guiding the video
generation process. The fused features are used as conditions for a frozen
Stable Diffusion model to produce realistic, temporally coherent surgical
videos. Extensive evaluations demonstrate that SurgSora outperforms
state-of-the-art methods in controllability and authenticity, showing its
potential to advance surgical video generation for medical education, training,
and research.

摘要：醫療影片生成具有變革性的潛力，可透過精確且可控的視覺表現來增強手術理解和病理見解。然而，目前的模型在可控性和真實性方面面臨限制。為了彌合這個差距，我們提出了 SurgSora，一個動作可控的手術影片生成框架，使用單一輸入幀和使用者可控的動作提示。SurgSora 包含三個關鍵模組：雙語意注入器 (DSI)，它從輸入幀中提取與物件相關的 RGB 和深度特徵，並將其與分割提示整合，以擷取複雜解剖結構的詳細空間特徵；解耦流對應器 (DFM)，它在多個尺度上將光流與語意 RGB-D 特徵融合，以增強時間理解和物件空間動態；以及軌跡控制器 (TC)，它允許使用者指定動作方向並估計稀疏光流，引導影片生成過程。融合的特徵用作凍結的 Stable Diffusion 模型的條件，以產生逼真、時間連貫的手術影片。廣泛的評估表明，SurgSora 在可控性和真實性方面優於最先進的方法，顯示其在推進手術影片生成以用於醫學教育、培訓和研究方面的潛力。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **Federated Learning and RAG Integration: A Scalable Approach for Medical Large Language Models**
2412.13720v1 by Jincheol Jung, Hongju Jeong, Eui-Nam Huh

This study analyzes the performance of domain-specific Large Language Models
(LLMs) for the medical field by integrating Retrieval-Augmented Generation
(RAG) systems within a federated learning framework. Leveraging the inherent
advantages of federated learning, such as preserving data privacy and enabling
distributed computation, this research explores the integration of RAG systems
with models trained under varying client configurations to optimize
performance. Experimental results demonstrate that the federated learning-based
models integrated with RAG systems consistently outperform their non-integrated
counterparts across all evaluation metrics. This study highlights the potential
of combining federated learning and RAG systems for developing domain-specific
LLMs in the medical field, providing a scalable and privacy-preserving solution
for enhancing text generation capabilities.

摘要：本研究透過在聯邦學習架構中整合檢索擴增生成 (RAG) 系統，分析特定領域的大語言模型 (LLM) 在醫療領域的表現。利用聯邦學習的內在優勢，例如維護資料隱私和啟用分散式運算，本研究探討將 RAG 系統與在不同客戶端組態下訓練的模型整合，以最佳化效能。實驗結果顯示，與 RAG 系統整合的基於聯邦學習的模型在所有評估指標上都持續優於未整合的對應模型。本研究強調在醫療領域結合聯邦學習和 RAG 系統以開發特定領域 LLM 的潛力，提供可擴充且維護隱私的解決方案，以增強文字生成能力。

##### **Clio: Privacy-Preserving Insights into Real-World AI Use**
2412.13678v1 by Alex Tamkin, Miles McCain, Kunal Handa, Esin Durmus, Liane Lovitt, Ankur Rathi, Saffron Huang, Alfred Mountfield, Jerry Hong, Stuart Ritchie, Michael Stern, Brian Clarke, Landon Goldberg, Theodore R. Sumers, Jared Mueller, William McEachen, Wes Mitchell, Shan Carter, Jack Clark, Jared Kaplan, Deep Ganguli

How are AI assistants being used in the real world? While model providers in
theory have a window into this impact via their users' data, both privacy
concerns and practical challenges have made analyzing this data difficult. To
address these issues, we present Clio (Claude insights and observations), a
privacy-preserving platform that uses AI assistants themselves to analyze and
surface aggregated usage patterns across millions of conversations, without the
need for human reviewers to read raw conversations. We validate this can be
done with a high degree of accuracy and privacy by conducting extensive
evaluations. We demonstrate Clio's usefulness in two broad ways. First, we
share insights about how models are being used in the real world from one
million Claude.ai Free and Pro conversations, ranging from providing advice on
hairstyles to providing guidance on Git operations and concepts. We also
identify the most common high-level use cases on Claude.ai (coding, writing,
and research tasks) as well as patterns that differ across languages (e.g.,
conversations in Japanese discuss elder care and aging populations at
higher-than-typical rates). Second, we use Clio to make our systems safer by
identifying coordinated attempts to abuse our systems, monitoring for unknown
unknowns during critical periods like launches of new capabilities or major
world events, and improving our existing monitoring systems. We also discuss
the limitations of our approach, as well as risks and ethical concerns. By
enabling analysis of real-world AI usage, Clio provides a scalable platform for
empirically grounded AI safety and governance.

摘要：人工智能助理在現實世界中如何使用？雖然理論上模型供應商可以透過使用者的資料了解這種影響，但隱私問題和實際挑戰都讓分析這些資料變得困難。為了解決這些問題，我們提出了 Clio（Claude 見解與觀察），一個隱私保護平台，它使用人工智能助理本身來分析並浮出數百萬次對話中的彙整使用模式，而不需要人類審查員閱讀原始對話。我們透過進行廣泛的評估，驗證這可以用高度準確和隱私來完成。我們以兩種廣泛的方式展示 Clio 的用途。首先，我們分享關於模型在現實世界中如何使用的一百萬個 Claude.ai 免費和專業對話的見解，範圍從提供髮型建議到提供有關 Git 操作和概念的指導。我們還找出 Claude.ai 上最常見的高階使用案例（編碼、寫作和研究任務），以及不同語言之間的模式差異（例如，日語對話討論老年照護和老齡化人口的比率高於一般）。其次，我們使用 Clio 透過找出協調濫用我們系統的嘗試、在啟動新功能或重大世界事件等關鍵時期監控未知的未知數，以及改善我們現有的監控系統，讓我們的系統更安全。我們也討論我們方法的限制，以及風險和道德問題。透過啟用對現實世界人工智能使用的分析，Clio 提供了一個可擴充的平台，用於以經驗為基礎的人工智能安全和治理。

##### **Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery**
2412.13667v1 by ChengAo Shen, Zhengzhang Chen, Dongsheng Luo, Dongkuan Xu, Haifeng Chen, Jingchao Ni

Causal inference is an imperative foundation for decision-making across
domains, such as smart health, AI for drug discovery and AIOps. Traditional
statistical causal discovery methods, while well-established, predominantly
rely on observational data and often overlook the semantic cues inherent in
cause-and-effect relationships. The advent of Large Language Models (LLMs) has
ushered in an affordable way of leveraging the semantic cues for
knowledge-driven causal discovery, but the development of LLMs for causal
discovery lags behind other areas, particularly in the exploration of
multi-modality data. To bridge the gap, we introduce MATMCD, a multi-agent
system powered by tool-augmented LLMs. MATMCD has two key agents: a Data
Augmentation agent that retrieves and processes modality-augmented data, and a
Causal Constraint agent that integrates multi-modal data for knowledge-driven
inference. Delicate design of the inner-workings ensures successful cooperation
of the agents. Our empirical study across seven datasets suggests the
significant potential of multi-modality enhanced causal discovery.

摘要：因果推論是跨領域決策制定中的必要基礎，例如智慧醫療、用於藥物發現的人工智慧和 AIOps。傳統的統計因果發現方法雖然已經確立，但主要依賴於觀察資料，且常常忽略因果關係中固有的語意線索。大型語言模型 (LLM) 的出現，開啟了一種利用語意線索進行知識驅動因果發現的方法，但用於因果發現的 LLM 發展落後於其他領域，特別是在多模態資料的探索方面。為了彌補差距，我們引入了 MATMCD，這是一個由工具增強的 LLM 驅動的多主體系統。MATMCD 有兩個關鍵主體：一個資料擴充主體，用於擷取和處理模態擴充資料，以及一個因果約束主體，用於整合多模態資料進行知識驅動推論。內部運作的精細設計確保了主體之間的成功合作。我們對七個資料集的實證研究表明，多模態增強因果發現具有顯著的潛力。

##### **BadSAD: Clean-Label Backdoor Attacks against Deep Semi-Supervised Anomaly Detection**
2412.13324v1 by He Cheng, Depeng Xu, Shuhan Yuan

Image anomaly detection (IAD) is essential in applications such as industrial
inspection, medical imaging, and security. Despite the progress achieved with
deep learning models like Deep Semi-Supervised Anomaly Detection (DeepSAD),
these models remain susceptible to backdoor attacks, presenting significant
security challenges. In this paper, we introduce BadSAD, a novel backdoor
attack framework specifically designed to target DeepSAD models. Our approach
involves two key phases: trigger injection, where subtle triggers are embedded
into normal images, and latent space manipulation, which positions and clusters
the poisoned images near normal images to make the triggers appear benign.
Extensive experiments on benchmark datasets validate the effectiveness of our
attack strategy, highlighting the severe risks that backdoor attacks pose to
deep learning-based anomaly detection systems.

摘要：影像異常偵測（IAD）在工業檢查、醫療影像和安全等應用中至關重要。儘管深度學習模型（如深度半監督異常偵測（DeepSAD））已取得進展，但這些模型仍然容易受到後門攻擊，造成重大的安全挑戰。在本文中，我們介紹 BadSAD，一個專門針對 DeepSAD 模型設計的新型後門攻擊架構。我們的做法包含兩個關鍵階段：觸發注入，其中將細微觸發嵌入到正常影像中，以及潛在空間操作，將中毒影像定位並群集在正常影像附近，以使觸發看起來是良性的。在基準資料集上進行的廣泛實驗驗證了我們攻擊策略的有效性，突顯了後門攻擊對基於深度學習的異常偵測系統造成的嚴重風險。

##### **In-context learning for medical image segmentation**
2412.13299v1 by Eichi Takaya, Shinnosuke Yamamoto

Annotation of medical images, such as MRI and CT scans, is crucial for
evaluating treatment efficacy and planning radiotherapy. However, the extensive
workload of medical professionals limits their ability to annotate large image
datasets, posing a bottleneck for AI applications in medical imaging. To
address this, we propose In-context Cascade Segmentation (ICS), a novel method
that minimizes annotation requirements while achieving high segmentation
accuracy for sequential medical images. ICS builds on the UniverSeg framework,
which performs few-shot segmentation using support images without additional
training. By iteratively adding the inference results of each slice to the
support set, ICS propagates information forward and backward through the
sequence, ensuring inter-slice consistency. We evaluate the proposed method on
the HVSMR dataset, which includes segmentation tasks for eight cardiac regions.
Experimental results demonstrate that ICS significantly improves segmentation
performance in complex anatomical regions, particularly in maintaining boundary
consistency across slices, compared to baseline methods. The study also
highlights the impact of the number and position of initial support slices on
segmentation accuracy. ICS offers a promising solution for reducing annotation
burdens while delivering robust segmentation results, paving the way for its
broader adoption in clinical and research applications.

摘要：醫學影像的註解，例如 MRI 和 CT 掃描，對於評估治療效果和規劃放射治療至關重要。然而，醫護人員龐大的工作量限制了他們註解大型影像資料集的能力，對醫學影像中的 AI 應用構成瓶頸。為了解決這個問題，我們提出情境串聯分割 (ICS)，這是一種新方法，可最大程度減少註解需求，同時為順序醫學影像實現高分割準確度。ICS 建立在 UniverSeg 架構之上，該架構使用支援影像執行少量分割，而無需額外訓練。透過反覆將每個切片的推論結果新增到支援集，ICS 透過序列向前和向後傳播資訊，確保切片間的一致性。我們在 HVSMR 資料集上評估所提出的方法，其中包括八個心臟區域的分割任務。實驗結果表明，與基準方法相比，ICS 在複雜的解剖區域顯著改善了分割效能，特別是在維護切片間的邊界一致性方面。該研究還強調了初始支援切片的數量和位置對分割準確度的影響。ICS 提供了一個有希望的解決方案，可以在提供穩健的分割結果的同時減少註解負擔，為其在臨床和研究應用中的更廣泛採用鋪平道路。

##### **Continuous Patient Monitoring with AI: Real-Time Analysis of Video in Hospital Care Settings**
2412.13152v1 by Paolo Gabriel, Peter Rehani, Tyler Troy, Tiffany Wyatt, Michael Choma, Narinder Singh

This study introduces an AI-driven platform for continuous and passive
patient monitoring in hospital settings, developed by LookDeep Health.
Leveraging advanced computer vision, the platform provides real-time insights
into patient behavior and interactions through video analysis, securely storing
inference results in the cloud for retrospective evaluation. The dataset,
compiled in collaboration with 11 hospital partners, encompasses over 300
high-risk fall patients and over 1,000 days of inference, enabling applications
such as fall detection and safety monitoring for vulnerable patient
populations. To foster innovation and reproducibility, an anonymized subset of
this dataset is publicly available. The AI system detects key components in
hospital rooms, including individual presence and role, furniture location,
motion magnitude, and boundary crossings. Performance evaluation demonstrates
strong accuracy in object detection (macro F1-score = 0.92) and patient-role
classification (F1-score = 0.98), as well as reliable trend analysis for the
"patient alone" metric (mean logistic regression accuracy = 0.82 \pm 0.15).
These capabilities enable automated detection of patient isolation, wandering,
or unsupervised movement-key indicators for fall risk and other adverse events.
This work establishes benchmarks for validating AI-driven patient monitoring
systems, highlighting the platform's potential to enhance patient safety and
care by providing continuous, data-driven insights into patient behavior and
interactions.

摘要：本研究介紹了一個由 LookDeep Health 開發的 AI 驅動平台，用於在醫院環境中持續且被動地監控患者。該平台利用先進的電腦視覺技術，透過影片分析提供患者行為和互動的即時見解，並將推論結果安全地儲存在雲端以供回顧性評估。該資料集與 11 家合作醫院共同編制，包含 300 多名高風險跌倒患者和 1,000 多天的推論，適用於跌倒偵測和脆弱患者族群的安全監控等應用。為了促進創新和可複製性，這份資料集的匿名子集已公開提供。AI 系統會偵測醫院房間中的關鍵組成部分，包括個人存在和角色、家具位置、動作幅度和邊界穿越。效能評估顯示物件偵測（巨觀 F1 分數 = 0.92）和患者角色分類（F1 分數 = 0.98）具有很高的準確性，以及「患者獨自一人」指標的可靠趨勢分析（平均邏輯迴歸準確性 = 0.82 ± 0.15）。這些功能可自動偵測患者隔離、遊走或無監督的移動，這些都是跌倒風險和其他不良事件的關鍵指標。這項工作為驗證 AI 驅動的患者監控系統建立了基準，突顯了該平台透過提供持續且資料驅動的患者行為和互動見解，增強患者安全和照護的潛力。

##### **Boosting Fine-Grained Visual Anomaly Detection with Coarse-Knowledge-Aware Adversarial Learning**
2412.12850v1 by Qingqing Fang, Qinliang Su, Wenxi Lv, Wenchao Xu, Jianxing Yu

Many unsupervised visual anomaly detection methods train an auto-encoder to
reconstruct normal samples and then leverage the reconstruction error map to
detect and localize the anomalies. However, due to the powerful modeling and
generalization ability of neural networks, some anomalies can also be well
reconstructed, resulting in unsatisfactory detection and localization accuracy.
In this paper, a small coarsely-labeled anomaly dataset is first collected.
Then, a coarse-knowledge-aware adversarial learning method is developed to
align the distribution of reconstructed features with that of normal features.
The alignment can effectively suppress the auto-encoder's reconstruction
ability on anomalies and thus improve the detection accuracy. Considering that
anomalies often only occupy very small areas in anomalous images, a patch-level
adversarial learning strategy is further developed. Although no patch-level
anomalous information is available, we rigorously prove that by simply viewing
any patch features from anomalous images as anomalies, the proposed
knowledge-aware method can also align the distribution of reconstructed patch
features with the normal ones. Experimental results on four medical datasets
and two industrial datasets demonstrate the effectiveness of our method in
improving the detection and localization performance.

摘要：許多無監督視覺異常偵測方法會訓練自動編碼器來重建正常樣本，然後利用重建誤差圖來偵測和定位異常。然而，由於神經網路強大的建模和概化能力，一些異常也可以被良好地重建，導致不令人滿意的偵測和定位準確度。在本文中，首先收集了一個小型粗略標記的異常資料集。然後，開發了一個粗略知識感知對抗學習方法，以將重建特徵的分布與正常特徵的分布對齊。對齊可以有效地抑制自動編碼器對異常的重建能力，從而提高偵測準確度。考慮到異常通常只佔異常影像中很小的區域，進一步開發了區塊級對抗學習策略。儘管沒有區塊級異常資訊可用，但我們嚴格證明，只需將異常影像中的任何區塊特徵視為異常，所提出的知識感知方法也可以將重建區塊特徵的分布與正常特徵對齊。在四個醫學資料集和兩個工業資料集上的實驗結果證明了我們的方法在改善偵測和定位效能方面的有效性。

##### **Rethinking Diffusion-Based Image Generators for Fundus Fluorescein Angiography Synthesis on Limited Data**
2412.12778v1 by Chengzhou Yu, Huihui Fang, Hongqiu Wang, Ting Deng, Qing Du, Yanwu Xu, Weihua Yang

Fundus imaging is a critical tool in ophthalmology, with different imaging
modalities offering unique advantages. For instance, fundus fluorescein
angiography (FFA) can accurately identify eye diseases. However, traditional
invasive FFA involves the injection of sodium fluorescein, which can cause
discomfort and risks. Generating corresponding FFA images from non-invasive
fundus images holds significant practical value but also presents challenges.
First, limited datasets constrain the performance and effectiveness of models.
Second, previous studies have primarily focused on generating FFA for single
diseases or single modalities, often resulting in poor performance for patients
with various ophthalmic conditions. To address these issues, we propose a novel
latent diffusion model-based framework, Diffusion, which introduces a
fine-tuning protocol to overcome the challenge of limited medical data and
unleash the generative capabilities of diffusion models. Furthermore, we
designed a new approach to tackle the challenges of generating across different
modalities and disease types. On limited datasets, our framework achieves
state-of-the-art results compared to existing methods, offering significant
potential to enhance ophthalmic diagnostics and patient care. Our code will be
released soon to support further research in this field.

摘要：眼底成像技術是眼科中的一項重要工具，不同的成像方式各有優勢。例如，眼底螢光素血管攝影 (FFA) 可精準辨識眼部疾病。然而，傳統侵入式的 FFA 會注射螢光素鈉，可能會造成不適和風險。從非侵入式眼底影像中產生相對應的 FFA 影像具有重要的實用價值，但也存在挑戰。首先，有限的資料集會限制模型的效能和效果。其次，先前的研究主要集中在為單一疾病或單一方式產生 FFA，對於患有多種眼科疾病的患者，效能通常不佳。為了解決這些問題，我們提出一個新穎的潛在擴散模型架構，稱為 Diffusion，它引入一個微調協定，以克服醫療資料有限的挑戰，並釋放擴散模型的生成能力。此外，我們設計了一種新方法來應對跨不同方式和疾病類型生成影像的挑戰。在有限的資料集上，與現有方法相比，我們的架構達到了最先進的結果，為增強眼科診斷和患者照護提供了顯著的潛力。我們的程式碼將很快釋出，以支持此領域的進一步研究。

##### **MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants**
2412.12661v1 by Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover

Recent advancements in mixed-modal generative models have enabled flexible
integration of information across image-text content. These models have opened
new avenues for developing unified biomedical assistants capable of analyzing
biomedical images, answering complex questions about them, and predicting the
impact of medical procedures on a patient's health. However, existing resources
face challenges such as limited data availability, narrow domain coverage, and
restricted sources (e.g., medical papers). To address these gaps, we present
MedMax, the first large-scale multimodal biomedical instruction-tuning dataset
for mixed-modal foundation models. With 1.47 million instances, MedMax
encompasses a diverse range of tasks, including multimodal content generation
(interleaved image-text data), biomedical image captioning and generation,
visual chatting, and report understanding. These tasks span diverse medical
domains such as radiology and histopathology. Subsequently, we fine-tune a
mixed-modal foundation model on the MedMax dataset, achieving significant
performance improvements: a 26% gain over the Chameleon model and an 18.3%
improvement over GPT-4o across 12 downstream biomedical visual
question-answering tasks. Additionally, we introduce a unified evaluation suite
for biomedical tasks, providing a robust framework to guide the development of
next-generation mixed-modal biomedical AI assistants.

摘要：混合模式生成模型的最新进展使得跨图像文本内容灵活整合信息成为可能。这些模型为开发统一的生物医学助手开辟了新途径，这些助手能够分析生物医学图像、回答有关图像的复杂问题，并预测医疗程序对患者健康的影响。然而，现有资源面临着数据可用性有限、领域覆盖范围狭窄和来源受限（例如医学论文）等挑战。为了解决这些差距，我们提出了 MedMax，这是第一个用于混合模式基础模型的大规模多模态生物医学指令微调数据集。MedMax 拥有 147 万个实例，涵盖了各种任务，包括多模态内容生成（交错图像文本数据）、生物医学图像标题和生成、可视化聊天和报告理解。这些任务跨越了放射学和组织病理学等不同的医学领域。随后，我们在 MedMax 数据集上对混合模式基础模型进行微调，取得了显著的性能提升：在 12 个下游生物医学视觉问答任务中，比 Chameleon 模型提升了 26%，比 GPT-4o 提升了 18.3%。此外，我们还引入了用于生物医学任务的统一评估套件，为指导下一代混合模式生物医学 AI 助手的发展提供了稳健的框架。

##### **a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions**
2412.12629v1 by Pranav Rajpurkar, Julian N. Acosta, Siddhant Dogra, Jaehwan Jeong, Deepanshu Jindal, Michael Moritz, Samir Rajpurkar

We present a comprehensive evaluation of a2z-1, an artificial intelligence
(AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive
and actionable findings. Our study focuses on rigorous assessment of the
model's performance and generalizability. Large-scale retrospective analysis
demonstrates an average AUC of 0.931 across 21 conditions. External validation
across two distinct health systems confirms consistent performance (AUC 0.923),
establishing generalizability to different evaluation scenarios, with notable
performance in critical findings such as small bowel obstruction (AUC 0.958)
and acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy
across patient sex, age groups, and varied imaging protocols, including
different slice thicknesses and contrast administration types. Comparison of
high-confidence model outputs to radiologist reports reveals instances where
a2z-1 identified overlooked findings, suggesting potential for quality
assurance applications.

摘要：我們提出 a2z-1 的全面評估，這是一個人工智慧 (AI) 模型，旨在分析腹部骨盆電腦斷層掃描，以找出 21 項時間敏感且可採取行動的發現。我們的研究重點在於嚴格評估模型的效能和概括性。大規模回顧性分析顯示，21 種疾病的平均 AUC 為 0.931。兩個不同醫療系統的外部驗證確認效能一致（AUC 0.923），建立了對不同評估情境的概括性，在小腸阻塞（AUC 0.958）和急性胰臟炎（AUC 0.961）等關鍵發現中表現出色。次群體分析顯示，在患者性別、年齡組和不同的影像協議（包括不同的切片厚度和對比劑施用類型）中，準確度一致。將高信賴度模型輸出與放射科醫師報告進行比較，揭示了 a2z-1 找出被忽略發現的範例，表示有潛力用於品質保證應用。

##### **A Scalable Approach to Benchmarking the In-Conversation Differential Diagnostic Accuracy of a Health AI**
2412.12538v1 by Deep Bhatt, Surya Ayyagari, Anuruddh Mishra

Diagnostic errors in healthcare persist as a critical challenge, with
increasing numbers of patients turning to online resources for health
information. While AI-powered healthcare chatbots show promise, there exists no
standardized and scalable framework for evaluating their diagnostic
capabilities. This study introduces a scalable benchmarking methodology for
assessing health AI systems and demonstrates its application through August, an
AI-driven conversational chatbot. Our methodology employs 400 validated
clinical vignettes across 14 medical specialties, using AI-powered patient
actors to simulate realistic clinical interactions. In systematic testing,
August achieved a top-one diagnostic accuracy of 81.8% (327/400 cases) and a
top-two accuracy of 85.0% (340/400 cases), significantly outperforming
traditional symptom checkers. The system demonstrated 95.8% accuracy in
specialist referrals and required 47% fewer questions compared to conventional
symptom checkers (mean 16 vs 29 questions), while maintaining empathetic
dialogue throughout consultations. These findings demonstrate the potential of
AI chatbots to enhance healthcare delivery, though implementation challenges
remain regarding real-world validation and integration of objective clinical
data. This research provides a reproducible framework for evaluating healthcare
AI systems, contributing to the responsible development and deployment of AI in
clinical settings.

摘要：醫療保健中的診斷錯誤持續成為一項重大挑戰，越來越多的患者求助於線上資源來取得健康資訊。儘管由人工智慧驅動的醫療保健聊天機器人展現出前景，但目前還沒有標準化且可擴充的架構來評估其診斷能力。本研究介紹了一種可擴充的基準測試方法，用於評估健康人工智慧系統，並透過由人工智慧驅動的對話式聊天機器人 August，展示其應用。我們的做法採用了 14 個醫療專科的 400 個已驗證臨床小故事，並使用由人工智慧驅動的患者角色模擬實際的臨床互動。在系統性測試中，August 達到了 81.8% 的前一項診斷準確度（327/400 個案例）和 85.0% 的前兩項準確度（340/400 個案例），顯著優於傳統的症狀檢查器。該系統在專科轉診方面表現出 95.8% 的準確度，並且與傳統症狀檢查器相比，所需的提問數量減少了 47%（平均 16 個問題，相較於 29 個問題），同時在諮詢過程中維持同理的對話。這些發現證明了人工智慧聊天機器人增強醫療保健服務的潛力，儘管在實際驗證和整合客觀臨床數據方面仍存在實作挑戰。本研究提供了一個可複製的架構，用於評估醫療保健人工智慧系統，有助於在臨床環境中負責任地開發和部署人工智慧。

##### **Addressing Small and Imbalanced Medical Image Datasets Using Generative Models: A Comparative Study of DDPM and PGGANs with Random and Greedy K Sampling**
2412.12532v1 by Iman Khazrak, Shakhnoza Takhirova, Mostafa M. Rezaee, Mehrdad Yadollahi, Robert C. Green II, Shuteng Niu

The development of accurate medical image classification models is often
constrained by privacy concerns and data scarcity for certain conditions,
leading to small and imbalanced datasets. To address these limitations, this
study explores the use of generative models, such as Denoising Diffusion
Probabilistic Models (DDPM) and Progressive Growing Generative Adversarial
Networks (PGGANs), for dataset augmentation. The research introduces a
framework to assess the impact of synthetic images generated by DDPM and PGGANs
on the performance of four models: a custom CNN, Untrained VGG16, Pretrained
VGG16, and Pretrained ResNet50. Experiments were conducted using Random
Sampling and Greedy K Sampling to create small, imbalanced datasets. The
synthetic images were evaluated using Frechet Inception Distance (FID) and
compared to original datasets through classification metrics. The results show
that DDPM consistently generated more realistic images with lower FID scores
and significantly outperformed PGGANs in improving classification metrics
across all models and datasets. Incorporating DDPM-generated images into the
original datasets increased accuracy by up to 6%, enhancing model robustness
and stability, particularly in imbalanced scenarios. Random Sampling
demonstrated superior stability, while Greedy K Sampling offered diversity at
the cost of higher FID scores. This study highlights the efficacy of DDPM in
augmenting small, imbalanced medical image datasets, improving model
performance by balancing the dataset and expanding its size.

摘要：<paragraph>準確醫療影像分類模型的開發常受限於隱私疑慮和特定狀況資料的稀缺，這導致資料集規模小且不平衡。為了解決這些限制，本研究探討生成模型，例如去噪擴散機率模型 (DDPM) 和漸進式生成對抗網路 (PGGAN)，用於資料集擴充。本研究引進一個架構，評估由 DDPM 和 PGGAN 生成的合成影像對四個模型效能的影響：自訂 CNN、Untrained VGG16、Pretrained VGG16 和 Pretrained ResNet50。實驗使用隨機取樣和貪婪 K 取樣進行，以建立小規模的不平衡資料集。合成影像使用 Fréchet 起始距離 (FID) 進行評估，並透過分類指標與原始資料集進行比較。結果顯示，DDPM 持續產生較逼真的影像，FID 分數較低，且在改善所有模型和資料集的分類指標方面，表現明顯優於 PGGAN。將 DDPM 生成的影像納入原始資料集，可將準確度提升多達 6%，增強模型的穩健性和穩定性，特別是在不平衡的情況下。隨機取樣展現出優異的穩定性，而貪婪 K 取樣則以較高的 FID 分數為代價，提供了多樣性。本研究強調 DDPM 在擴充小規模、不平衡醫療影像資料集方面的效能，透過平衡資料集和擴充其規模，改善模型效能。</paragraph>

##### **RareAgents: Autonomous Multi-disciplinary Team for Rare Disease Diagnosis and Treatment**
2412.12475v1 by Xuanzhong Chen, Ye Jin, Xiaohao Mao, Lun Wang, Shuyang Zhang, Ting Chen

Rare diseases, despite their low individual incidence, collectively impact
around 300 million people worldwide due to the huge number of diseases. The
complexity of symptoms and the shortage of specialized doctors with relevant
experience make diagnosing and treating rare diseases more challenging than
common diseases. Recently, agents powered by large language models (LLMs) have
demonstrated notable improvements across various domains. In the medical field,
some agent methods have outperformed direct prompts in question-answering tasks
from medical exams. However, current agent frameworks lack adaptation for
real-world clinical scenarios, especially those involving the intricate demands
of rare diseases. To address these challenges, we present RareAgents, the first
multi-disciplinary team of LLM-based agents tailored to the complex clinical
context of rare diseases. RareAgents integrates advanced planning capabilities,
memory mechanisms, and medical tools utilization, leveraging Llama-3.1-8B/70B
as the base model. Experimental results show that RareAgents surpasses
state-of-the-art domain-specific models, GPT-4o, and existing agent frameworks
in both differential diagnosis and medication recommendation for rare diseases.
Furthermore, we contribute a novel dataset, MIMIC-IV-Ext-Rare, derived from
MIMIC-IV, to support further advancements in this field.

摘要：儘管罕見疾病的個別發生率很低，但由於疾病數量龐大，在全球影響了約 3 億人。症狀的複雜性和相關經驗的專科醫生短缺，使得診斷和治療罕見疾病比常見疾病更具挑戰性。最近，由大型語言模型 (LLM) 驅動的代理已在各個領域展示出顯著的改進。在醫學領域，一些代理方法在醫學考試的問答任務中優於直接提示。然而，當前的代理架構缺乏適應現實世界的臨床場景，特別是那些涉及罕見疾病複雜需求的場景。為了應對這些挑戰，我們提出了 RareAgents，這是第一個針對罕見疾病複雜臨床背景量身打造的 LLM 為基礎的多學科代理團隊。RareAgents 整合了先進的規劃能力、記憶機制和醫療工具利用，利用 Llama-3.1-8B/70B 作為基礎模型。實驗結果表明，RareAgents 在罕見疾病的鑑別診斷和藥物推薦方面都超越了最先進的特定領域模型 GPT-4o 和現有的代理架構。此外，我們貢獻了一個新的數據集 MIMIC-IV-Ext-Rare，它來自 MIMIC-IV，以支持該領域的進一步發展。

##### **ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports**
2412.15264v1 by Romain Hardy, Sung Eun Kim, Pranav Rajpurkar

The increasing adoption of AI-generated radiology reports necessitates robust
methods for detecting hallucinations--false or unfounded statements that could
impact patient care. We present ReXTrust, a novel framework for fine-grained
hallucination detection in AI-generated radiology reports. Our approach
leverages sequences of hidden states from large vision-language models to
produce finding-level hallucination risk scores. We evaluate ReXTrust on a
subset of the MIMIC-CXR dataset and demonstrate superior performance compared
to existing approaches, achieving an AUROC of 0.8751 across all findings and
0.8963 on clinically significant findings. Our results show that white-box
approaches leveraging model hidden states can provide reliable hallucination
detection for medical AI systems, potentially improving the safety and
reliability of automated radiology reporting.

摘要：隨著 AI 生成的放射科報告採用率的提升，需要有穩健的方法來偵測幻覺，也就是可能會影響患者照護的虛假或不實的陳述。我們提出 ReXTrust，一個用於偵測 AI 生成的放射科報告中精細幻覺的新框架。我們的做法利用大型視覺語言模型中隱藏狀態的序列，以產生發現層級的幻覺風險評分。我們在 MIMIC-CXR 資料集的子集上評估 ReXTrust，並展示出比現有方法更好的效能，在所有發現中達到 0.8751 的 AUROC，在臨床上重要的發現中達到 0.8963。我們的結果顯示，利用模型隱藏狀態的白盒方法可以為醫療 AI 系統提供可靠的幻覺偵測，進而潛在地改善自動化放射科報告的安全性及可靠性。

##### **Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**
2412.12417v1 by Tuka Alhanai, Adam Kasumovic, Mohammad Ghassemi, Aven Zitzelberger, Jessica Lundin, Guillaume Chabot-Couture

Large Language Models (LLMs) have shown remarkable performance across various
tasks, yet significant disparities remain for non-English languages, and
especially native African languages. This paper addresses these disparities by
creating approximately 1 million human-translated words of new benchmark data
in 8 low-resource African languages, covering a population of over 160 million
speakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho
(Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of
Winogrande and three sections of MMLU: college medicine, clinical knowledge,
and virology. Using the translated benchmarks, we report previously unknown
performance gaps between state-of-the-art (SOTA) LLMs in English and African
languages. Finally, using results from over 400 fine-tuned models, we explore
several methods to reduce the LLM performance gap, including high-quality
dataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and
cultural appropriateness adjustments. Key findings include average mono-lingual
improvements of 5.6% with fine-tuning (with 5.4% average mono-lingual
improvements when using high-quality data over low-quality data), 2.9% average
gains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost
on culturally appropriate questions. The publicly available benchmarks,
translations, and code from this study support further research and development
aimed at creating more inclusive and effective language technologies.

摘要：大型語言模型 (LLM) 在各種任務中展現出卓越的表現，但非英語語言，尤其是原生非洲語言，仍存在顯著的差異。本文透過在 8 種資源匱乏的非洲語言中建立約 100 萬個人類翻譯的單字作為新的基準資料，來解決這些差異，涵蓋超過 1.6 億人口的使用者：阿姆哈拉語、班巴拉語、伊博語、北索托語、紹納語、南索托語、茨瓦納語和聰加語。我們的基準是對 Winogrande 和 MMLU 的三個部分進行翻譯：大學醫學、臨床知識和病毒學。透過翻譯的基準，我們報告了先前未知的效能差距，在英語和非洲語言的最新 (SOTA) LLM 之間。最後，使用來自 400 多個微調模型的結果，我們探討了幾種方法來縮小 LLM 效能差距，包括高品質資料集微調（使用 LLM 作為註解者）、跨語言轉移和文化適宜性調整。主要發現包括微調後平均單語改善 5.6%（使用高品質資料比低品質資料時，平均單語改善 5.4%）、跨語言轉移平均提升 2.9%，以及在文化適宜問題上即時效能提升 3.0%。本研究中公開提供的基準、翻譯和程式碼支援進一步的研究和開發，旨在建立更具包容性和有效性的語言技術。

##### **The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports**
2412.12042v1 by Julián N. Acosta, Siddhant Dogra, Subathra Adithan, Kay Wu, Michael Moritz, Stephen Kwak, Pranav Rajpurkar

Radiologists face increasing workload pressures amid growing imaging volumes,
creating risks of burnout and delayed reporting times. While artificial
intelligence (AI) based automated radiology report generation shows promise for
reporting workflow optimization, evidence of its real-world impact on clinical
accuracy and efficiency remains limited. This study evaluated the effect of
draft reports on radiology reporting workflows by conducting a three reader
multi-case study comparing standard versus AI-assisted reporting workflows. In
both workflows, radiologists reviewed the cases and modified either a standard
template (standard workflow) or an AI-generated draft report (AI-assisted
workflow) to create the final report. For controlled evaluation, we used GPT-4
to generate simulated AI drafts and deliberately introduced 1-3 errors in half
the cases to mimic real AI system performance. The AI-assisted workflow
significantly reduced average reporting time from 573 to 435 seconds (p=0.003),
without a statistically significant difference in clinically significant errors
between workflows. These findings suggest that AI-generated drafts can
meaningfully accelerate radiology reporting while maintaining diagnostic
accuracy, offering a practical solution to address mounting workload challenges
in clinical practice.

摘要：放射科醫師在影像量不斷增加的情況下，面臨工作量壓力增加，
造成倦怠和報告時間延誤的風險。雖然基於人工智慧 (AI) 的自動化放射科報告生成顯示出優化報告工作流程的希望，但其對臨床準確性和效率的實際影響證據仍然有限。本研究透過進行三名讀者多案例研究，比較標準與 AI 輔助報告工作流程，評估草稿報告對放射科報告工作流程的影響。在兩種工作流程中，放射科醫師檢閱病例並修改標準範本 (標準工作流程) 或 AI 生成的草稿報告 (AI 輔助工作流程) 以建立最終報告。為了進行受控評估，我們使用 GPT-4 產生模擬的 AI 草稿，並故意在半數病例中引入 1-3 個錯誤，以模擬真實的 AI 系統效能。AI 輔助工作流程將平均報告時間從 573 秒顯著減少到 435 秒 (p=0.003)，而工作流程之間在臨床顯著錯誤方面沒有統計上的顯著差異。這些發現表明，AI 生成的草稿可以在維持診斷準確性的同時，有意義地加速放射科報告，為解決臨床實務中不斷增加的工作量挑戰提供實際的解決方案。

##### **Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support**
2412.11995v1 by Devika Venugopalan, Ziwen Yan, Conrad Borchers, Jionghao Lin, Vincent Aleven

Caregivers (i.e., parents and members of a child's caring community) are
underappreciated stakeholders in learning analytics. Although caregiver
involvement can enhance student academic outcomes, many obstacles hinder
involvement, most notably knowledge gaps with respect to modern school
curricula. An emerging topic of interest in learning analytics is hybrid
tutoring, which includes instructional and motivational support. Caregivers
assert similar roles in homework, yet it is unknown how learning analytics can
support them. Our past work with caregivers suggested that conversational
support is a promising method of providing caregivers with the guidance needed
to effectively support student learning. We developed a system that provides
instructional support to caregivers through conversational recommendations
generated by a Large Language Model (LLM). Addressing known instructional
limitations of LLMs, we use instructional intelligence from tutoring systems
while conducting prompt engineering experiments with the open-source Llama 3
LLM. This LLM generated message recommendations for caregivers supporting their
child's math practice via chat. Few-shot prompting and combining real-time
problem-solving context from tutoring systems with examples of tutoring
practices yielded desirable message recommendations. These recommendations were
evaluated with ten middle school caregivers, who valued recommendations
facilitating content-level support and student metacognition through
self-explanation. We contribute insights into how tutoring systems can best be
merged with LLMs to support hybrid tutoring settings through conversational
assistance, facilitating effective caregiver involvement in tutoring systems.

摘要：照顧者（即父母和兒童照顧社群的成員）是學習分析中未獲充分重視的利害關係人。儘管照顧者的參與可以提升學生的學業成績，但許多障礙阻礙了參與，最顯著的是關於現代學校課程的知識差距。學習分析中一個新興的關注主題是混合式輔導，其中包括教學和動機支持。照顧者在家庭作業中扮演類似的角色，但目前尚不清楚學習分析如何能支持他們。我們過去與照顧者的合作表明，對話式支持是提供照顧者有效支持學生學習所需的指導的一種有前途的方法。我們開發了一個系統，透過大型語言模型 (LLM) 產生的對話式建議，為照顧者提供教學支援。為了解決 LLM 已知的教學限制，我們在對開源 Llama 3 LLM 進行提示工程實驗時，使用了來自輔導系統的教學智慧。此 LLM 為照顧者透過聊天支援其子女的數學練習生成了訊息建議。少量提示並結合來自輔導系統的即時問題解決背景與輔導實務範例，產生了理想的訊息建議。這些建議經過十位國中照顧者的評估，他們重視促進內容層級支援和學生透過自我解釋進行元認知的建議。我們提供見解，說明輔導系統如何能透過對話式協助與 LLM 最佳整合，以支援混合式輔導設定，促進照顧者有效參與輔導系統。

##### **LLMs Can Simulate Standardized Patients via Agent Coevolution**
2412.11716v1 by Zhuoyun Du, Lujie Zheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haohao Ying

Training medical personnel using standardized patients (SPs) remains a
complex challenge, requiring extensive domain expertise and role-specific
practice. Most research on Large Language Model (LLM)-based simulated patients
focuses on improving data retrieval accuracy or adjusting prompts through human
feedback. However, this focus has overlooked the critical need for patient
agents to learn a standardized presentation pattern that transforms data into
human-like patient responses through unsupervised simulations. To address this
gap, we propose EvoPatient, a novel simulated patient framework in which a
patient agent and doctor agents simulate the diagnostic process through
multi-turn dialogues, simultaneously gathering experience to improve the
quality of both questions and answers, ultimately enabling human doctor
training. Extensive experiments on various cases demonstrate that, by providing
only overall SP requirements, our framework improves over existing reasoning
methods by more than 10% in requirement alignment and better human preference,
while achieving an optimal balance of resource consumption after evolving over
200 cases for 10 hours, with excellent generalizability. The code will be
available at https://github.com/ZJUMAI/EvoPatient.

摘要：使用标准化患者 (SP) 培训医疗人员仍然是一项复杂的挑战，需要广泛的领域专业知识和针对特定角色的实践。大多数关于基于大语言模型 (LLM) 的模拟患者的研究都集中在提高数据检索准确性或通过人工反馈调整提示上。然而，这种关注忽视了患者代理学习标准化陈述模式的关键需求，该模式通过无监督模拟将数据转换为类人的患者反应。为了解决这一差距，我们提出了 EvoPatient，这是一个新颖的模拟患者框架，其中患者代理和医生代理通过多轮对话模拟诊断过程，同时收集经验以提高问题和答案的质量，最终实现人类医生培训。对各种案例进行的广泛实验表明，通过仅提供整体 SP 要求，我们的框架在需求对齐和更好的人类偏好方面比现有的推理方法提高了 10% 以上，同时在经过 200 个案例演化 10 小时后实现了资源消耗的最佳平衡，具有出色的可概括性。代码可在 https://github.com/ZJUMAI/EvoPatient 获得。

##### **Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection**
2412.11681v1 by Abdelbaki Souid, Mohamed Hamroun, Soufiene Ben Othman, Hedi Sakli, Naceur Abdelkarim

Pulmonary pathologies are a significant global health concern, often leading
to fatal outcomes if not diagnosed and treated promptly. Chest radiography
serves as a primary diagnostic tool, but the availability of experienced
radiologists remains limited. Advances in Artificial Intelligence (AI) and
machine learning, particularly in computer vision, offer promising solutions to
address this challenge.
  This research evaluates a deep learning model designed to detect lung cancer,
specifically pulmonary nodules, along with eight other lung pathologies, using
chest radiographs. The study leverages diverse datasets comprising over 135,120
frontal chest radiographs to train a Convolutional Neural Network (CNN). A
two-stage classification system, utilizing ensemble methods and transfer
learning, is employed to first triage images into Normal or Abnormal categories
and then identify specific pathologies, including lung nodules.
  The deep learning model achieves notable results in nodule classification,
with a top-performing accuracy of 77%, a sensitivity of 0.713, a specificity of
0.776 during external validation, and an AUC score of 0.888. Despite these
successes, some misclassifications were observed, primarily false negatives.
  In conclusion, the model demonstrates robust potential for generalization
across diverse patient populations, attributed to the geographic diversity of
the training dataset. Future work could focus on integrating ETL data
distribution strategies and expanding the dataset with additional nodule-type
samples to further enhance diagnostic accuracy.

摘要：肺部病變是全球重要的健康問題，若未及時診斷和治療，常會導致致命後果。胸部 X 光攝影可用作主要的診斷工具，但經驗豐富的放射科醫師數量有限。人工智慧 (AI) 和機器學習的進展，特別是在電腦視覺方面，提供了有望解決此挑戰的方案。
本研究評估了一個深度學習模型，該模型旨在使用胸部 X 光片檢測肺癌，特別是肺結節，以及其他八種肺部病變。此研究利用包含超過 135,120 張正面胸部 X 光片的不同資料集來訓練卷積神經網路 (CNN)。採用兩階段分類系統，利用整體方法和遷移學習，首先將影像分類為正常或異常類別，然後識別特定病變，包括肺結節。
深度學習模型在結節分類方面取得顯著成果，在外部驗證期間，其準確率最高達到 77%，靈敏度為 0.713，特異度為 0.776，AUC 分數為 0.888。儘管有這些成功，但仍觀察到一些錯誤分類，主要是假陰性。
總之，該模型展示了在不同患者族群中概括的強大潛力，這歸功於訓練資料集的地理多樣性。未來的研究可以專注於整合 ETL 資料分佈策略，並使用額外的結節類型樣本擴充資料集，以進一步提高診斷準確性。

##### **BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR**
2412.11671v1 by Jangyeong Jeon, Sangyeon Cho, Dongjoon Lee, Changhee Lee, Junyeong Kim

Pediatric Emergency Department (PED) overcrowding presents a significant
global challenge, prompting the need for efficient solutions. This paper
introduces the BioBridge framework, a novel approach that applies Natural
Language Processing (NLP) to Electronic Medical Records (EMRs) in written
free-text form to enhance decision-making in PED. In non-English speaking
countries, such as South Korea, EMR data is often written in a Code-Switching
(CS) format that mixes the native language with English, with most
code-switched English words having clinical significance. The BioBridge
framework consists of two core modules: "bridging modality in context" and
"unified bio-embedding." The "bridging modality in context" module improves the
contextual understanding of bilingual and code-switched EMRs. In the "unified
bio-embedding" module, the knowledge of the model trained in the medical domain
is injected into the encoder-based model to bridge the gap between the medical
and general domains. Experimental results demonstrate that the proposed
BioBridge significantly performance traditional machine learning and
pre-trained encoder-based models on several metrics, including F1 score, area
under the receiver operating characteristic curve (AUROC), area under the
precision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM
achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,
along with a notable 3.04% decrease in the Brier score, demonstrating marked
improvements in accuracy, reliability, and prediction calibration over the
baseline XLM model. The source code will be made publicly available.

摘要：<paragraph>小兒急診部（PED）人滿為患是一個重大的全球性挑戰，促使我們需要找出有效率的解決方案。本文介紹 BioBridge 架構，這是一種創新的方法，將自然語言處理（NLP）應用於以自由文字形式撰寫的電子病歷（EMR），以增強在 PED 中的決策制定。在非英語系國家/地區（例如南韓），EMR 資料通常以代碼轉換（CS）格式撰寫，將母語與英語混合，而大多數代碼轉換的英語單字具有臨床意義。BioBridge 架構包含兩個核心模組：「語境中的橋接方式」和「統一生物嵌入」。「語境中的橋接方式」模組改善了雙語和代碼轉換 EMR 的語境理解。在「統一生物嵌入」模組中，將在醫療領域訓練的模型知識注入到基於編碼器的模型中，以彌合醫療和一般領域之間的差距。實驗結果證明，所提出的 BioBridge 在多項指標（包括 F1 分數、受試者操作特徵曲線下面積（AUROC）、精確度召回率曲線下面積（AUPRC）和布賴爾分數）上顯著優於傳統機器學習和預先訓練的基於編碼器的模型。具體來說，BioBridge-XLM 在 F1 分數上提升了 0.85%，在 AUROC 上提升了 0.75%，在 AUPRC 上提升了 0.76%，同時布賴爾分數顯著下降了 3.04%，證明在準確度、可靠性和預測校準方面，與基準 XLM 模型相比都有顯著的改善。原始碼將公開提供。</paragraph>

##### **Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases**
2412.11472v1 by Purity Mugambi, Alexandra Meliou, Madalina Fiterau

A crucial step in cohort studies is to extract the required cohort from one
or more study datasets. This step is time-consuming, especially when a
researcher is presented with a dataset that they have not previously worked
with. When the cohort has to be extracted from multiple datasets, cohort
extraction can be extremely laborious. In this study, we present an approach
for partially automating cohort extraction from multiple electronic health
record (EHR) databases. We formulate the guided multi-dataset cohort extraction
problem in which selection criteria are first converted into queries,
translating them from natural language text to language that maps to database
entities. Then, using FLMs, columns of interest identified from the queries are
automatically matched between the study databases. Finally, the generated
queries are run across all databases to extract the study cohort. We propose
and evaluate an algorithm for automating column matching on two large, popular
and publicly-accessible EHR databases -- MIMIC-III and eICU. Our approach
achieves a high top-three accuracy of $92\%$, correctly matching $12$ out of
the $13$ columns of interest, when using a small, pre-trained general purpose
language model. Furthermore, this accuracy is maintained even as the search
space (i.e., size of the database) increases.

摘要：在队列研究中，从一个或多个研究数据集提取所需的队列是至关重要的一步。此步骤非常耗时，特别是当研究人员使用之前未处理过的数据集时。当必须从多个数据集提取队列时，队列提取可能会非常费力。在本研究中，我们提出了一种从多个电子健康记录 (EHR) 数据库中部分自动化队列提取的方法。我们制定了引导式多数据集队列提取问题，其中选择标准首先转换为查询，将它们从自然语言文本转换为映射到数据库实体的语言。然后，使用 FLM，从查询中识别出的目标列在研究数据库之间自动匹配。最后，在所有数据库中运行生成的查询以提取研究队列。我们提出并评估了一种算法，用于在两个大型、流行且可公开访问的 EHR 数据库（MIMIC-III 和 eICU）上自动执行列匹配。我们的方法实现了 92% 的高前三准确度，在使用小型、预先训练的通用语言模型时，正确匹配了 13 个目标列中的 12 个。此外，即使搜索空间（即数据库大小）增加，也能保持这种准确性。

##### **FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning**
2412.11463v1 by Minjun Kim, Minjee Kim, Jinhoon Jeong

Generative models trained on multi-institutional datasets can provide an
enriched understanding through diverse data distributions. However, training
the models on medical images is often challenging due to hospitals' reluctance
to share data for privacy reasons. Federated learning(FL) has emerged as a
privacy-preserving solution for training distributed datasets across data
centers by aggregating model weights from multiple clients instead of sharing
raw data. Previous research has explored the adaptation of FL to generative
models, yet effective aggregation algorithms specifically tailored for
generative models remain unexplored. We hereby propose a novel algorithm aimed
at improving the performance of generative models within FL. Our approach
adaptively re-weights the contribution of each client, resulting in
well-trained shared parameters. In each round, the server side measures the
distribution distance between fake images generated by clients instead of
directly comparing the Fr\'echet Inception Distance per client, thereby
enhancing efficiency of the learning. Experimental results on three public
chest X-ray datasets show superior performance in medical image generation,
outperforming both centralized learning and conventional FL algorithms. Our
code is available at https://github.com/danny0628/FedCAR.

摘要：在多機構資料集上訓練的生成模型能透過多樣化的資料分佈提供豐富的理解。然而，由於醫院基於隱私原因不願意分享資料，因此在醫學影像上訓練模型通常具有挑戰性。聯合學習 (FL) 已成為一種隱私保護解決方案，透過彙總多個用戶端的模型權重，而非分享原始資料，就能在資料中心間訓練分散式資料集。先前的研究已探討將 FL 改編到生成模型，但專門為生成模型量身打造的有效彙總演算法仍未被探討。我們在此提出一個新演算法，旨在改善 FL 內生成模型的效能。我們的做法是自適應地重新加權每個用戶端的貢獻，進而產生訓練良好的共用參數。在每一回合中，伺服器端測量用戶端產生的假影像之間的分配距離，而非直接比較每個用戶端的 Fr\'echet Inception Distance，從而提升學習效率。在三個公開胸部 X 光資料集上的實驗結果顯示，在醫學影像生成方面有優異的效能，優於集中式學習和傳統的 FL 演算法。我們的程式碼可以在 https://github.com/danny0628/FedCAR 取得。

##### **ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models**
2412.11453v1 by Xiechi Zhang, Shunfan Zheng, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Liang He

As multimodal large language models (MLLMs) gain prominence in the medical
field, the need for precise evaluation methods to assess their effectiveness
has become critical. While benchmarks provide a reliable means to evaluate the
capabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for
open domain evaluation only focus on token overlap and may not align with human
judgment. Although human evaluation is more reliable, it is labor-intensive,
costly, and not scalable. LLM-based evaluation methods have proven promising,
but to date, there is still an urgent need for open-source multimodal LLM-based
evaluators in the medical field. To address this issue, we introduce ACE-$M^3$,
an open-sourced \textbf{A}utomatic \textbf{C}apability \textbf{E}valuator for
\textbf{M}ultimodal \textbf{M}edical \textbf{M}odels specifically designed to
assess the question answering abilities of medical MLLMs. It first utilizes a
branch-merge architecture to provide both detailed analysis and a concise final
score based on standard medical evaluation criteria. Subsequently, a reward
token-based direct preference optimization (RTDPO) strategy is incorporated to
save training time without compromising performance of our model. Extensive
experiments have demonstrated the effectiveness of our ACE-$M^3$
model\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}
in evaluating the capabilities of medical MLLMs.

摘要：<paragraph>隨著多模態大型語言模型 (MLLM) 在醫療領域的重要性日益提升，評估其效能的精準評量方法的需求也變得至關重要。雖然基準測試提供了評估 MLLM 能力的可靠方法，但用於開放領域評量的傳統指標，例如 ROUGE 和 BLEU，僅著重於權標重疊，可能與人類判斷不符。儘管人類評量較為可靠，但它卻勞力密集、成本高昂且無法擴充。基於 LLM 的評量方法已被證實具有前景，但迄今為止，醫療領域仍迫切需要開放原始碼的多模態基於 LLM 的評量器。為了解決這個問題，我們引入了 ACE-$M^3$，一個開放原始碼的**A**utomatic **C**apability **E**valuator for **M**ultimodal **M**edical **M**odels，專門設計用於評估醫療 MLLM 的問答能力。它首先利用分支合併架構提供詳細分析和基於標準醫療評量標準的簡潔最終評分。隨後，納入了基於獎勵權標的直接偏好最佳化 (RTDPO) 策略，以節省訓練時間，同時不影響我們模型的效能。廣泛的實驗證明了我們的 ACE-$M^3$ 模型\footnote{\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}} 在評估醫療 MLLM 能力方面的效能。</paragraph>

##### **Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search**
2412.15256v1 by Edward Kim, Manil Shrestha, Richard Foty, Tom DeLay, Vicki Seyfert-Margolis

Creation and curation of knowledge graphs can accelerate disease discovery
and analysis in real-world data. While disease ontologies aid in biological
data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture
patient condition nuances or rare diseases. Multiple disease definitions across
data sources complicate ontology mapping and disease clustering. We propose
creating patient knowledge graphs using large language model extraction
techniques, allowing data extraction via natural language rather than rigid
ontological hierarchies. Our method maps to existing ontologies (MeSH,
SNOMED-CT, RxNORM, HPO) to ground extracted entities.
  Using a large ambulatory care EHR database with 33.6M patients, we
demonstrate our method through the patient search for Dravet syndrome, which
received ICD10 recognition in October 2020. We describe our construction of
patient-specific knowledge graphs and symptom-based patient searches. Using
confirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based
entity extraction to characterize patients in grounded ontologies. We then
apply this method to identify Beta-propeller protein-associated
neurodegeneration (BPAN) patients, demonstrating real-world discovery where no
ground truth exists.

摘要：知識圖譜的建立和策展可以加速疾病發現和分析真實世界中的資料。雖然疾病本體論有助於生物資料註釋，但編碼類別（SNOMED-CT、ICD10、CPT）可能無法捕捉患者狀況的細微差別或罕見疾病。跨資料來源的多重疾病定義使本體論對應和疾病群集複雜化。我們建議使用大型語言模型萃取技術建立患者知識圖譜，允許透過自然語言而不是僵化的本體論階層萃取資料。我們的模型對應到現有本體論（MeSH、SNOMED-CT、RxNORM、HPO）以建立萃取實體的基礎。使用一個擁有 3360 萬名患者的大型門診電子病歷資料庫，我們透過患者搜尋 Dravet 症候群來展示我們的模型，該症候群於 2020 年 10 月獲得 ICD10 認可。我們描述我們如何建構患者特定的知識圖譜和基於症狀的患者搜尋。使用已確認的 Dravet 症候群 ICD10 代碼作為基準，我們使用基於 LLM 的實體萃取來描述紮根於本體論中的患者。然後我們應用此模型來識別貝塔螺旋槳蛋白相關的神經退化（BPAN）患者，展示了在不存在基準的情況下進行真實世界發現。

##### **Detecting Daily Living Gait Amid Huntington's Disease Chorea using a Foundation Deep Learning Model**
2412.11286v1 by Dafna Schwartz, Lori Quinn, Nora E. Fritz, Lisa M. Muratori, Jeffery M. Hausdorff, Ran Gilad Bachrach

Wearable sensors offer a non-invasive way to collect physical activity (PA)
data, with walking as a key component. Existing models often struggle to detect
gait bouts in individuals with neurodegenerative diseases (NDDs) involving
involuntary movements. We developed J-Net, a deep learning model inspired by
U-Net, which uses a pre-trained self-supervised foundation model fine-tuned
with Huntington`s disease (HD) in-lab data and paired with a segmentation head
for gait detection. J-Net processes wrist-worn accelerometer data to detect
gait during daily living. We evaluated J-Net on in-lab and daily-living data
from HD, Parkinson`s disease (PD), and controls. J-Net achieved a 10-percentage
point improvement in ROC-AUC for HD over existing methods, reaching 0.97 for
in-lab data. In daily-living environments, J-Net estimates showed no
significant differences in median daily walking time between HD and controls (p
= 0.23), in contrast to other models, which indicated counterintuitive results
(p < 0.005). Walking time measured by J-Net correlated with the UHDRS-TMS
clinical severity score (r=-0.52; p=0.02), confirming its clinical relevance.
Fine-tuning J-Net on PD data also improved gait detection over current methods.
J-Net`s architecture effectively addresses the challenges of gait detection in
severe chorea and offers robust performance in daily living. The dataset and
J-Net model are publicly available, providing a resource for further research
into NDD-related gait impairments.

摘要：<paragraph>穿戴式感測器提供收集身體活動 (PA) 資料的非侵入式方法，其中步行為關鍵組成部分。現有模型通常難以偵測患有神經退化性疾病 (NDD) 並伴隨非自主運動的個體的步態發作。我們開發了 J-Net，一種受 U-Net 啟發的深度學習模型，它使用經過預先訓練的自監督基礎模型，並使用亨丁頓舞蹈症 (HD) 實驗室資料進行微調，並與用於步態偵測的分段頭部配對。J-Net 處理手腕配戴的加速度計資料，以偵測日常生活中的步態。我們在 HD、帕金森氏症 (PD) 和對照組的實驗室和日常生活資料上評估 J-Net。J-Net 在 HD 的 ROC-AUC 上比現有方法提高了 10 個百分點，對於實驗室資料達到 0.97。在日常生活環境中，J-Net 估計值顯示 HD 和對照組之間的每日平均步行時間沒有顯著差異 (p = 0.23)，這與其他模型形成對比，後者顯示出違背直覺的結果 (p < 0.005)。J-Net 測量的步行時間與 UHDRS-TMS 臨床嚴重程度評分相關 (r=-0.52；p=0.02)，證實其臨床相關性。在 PD 資料上微調 J-Net 也改善了對現有方法的步態偵測。J-Net 的架構有效解決了嚴重舞蹈症中步態偵測的挑戰，並在日常生活中提供穩健的效能。該資料集和 J-Net 模型公開提供，為進一步研究 NDD 相關步態障礙提供資源。</paragraph>

##### **Wearable Accelerometer Foundation Models for Health via Knowledge Distillation**
2412.11276v1 by Salar Abbaspourazad, Anshuman Mishra, Joseph Futoma, Andrew C. Miller, Ian Shapiro

Modern wearable devices can conveniently and continuously record various
biosignals in the many different environments of daily living, ultimately
enabling a rich view of individual health. However, not all biosignals are the
same: high-fidelity measurements, such as photoplethysmography (PPG), contain
more physiological information, but require optical sensors with a high power
footprint. In a resource-constrained setting, such biosignals may be
unavailable. Alternatively, a lower-fidelity biosignal, such as accelerometry
that captures minute cardiovascular information during low-motion periods, has
a significantly smaller power footprint and is available in almost any wearable
device. Here, we demonstrate that we can distill representational knowledge
across biosignals, i.e., from PPG to accelerometry, using 20 million minutes of
unlabeled data, collected from ~172K participants in the Apple Heart and
Movement Study under informed consent. We first pre-train PPG encoders via
self-supervised learning, and then distill their representational knowledge to
accelerometry encoders. We demonstrate strong cross-modal alignment on unseen
data, e.g., 99.2% top-1 accuracy for retrieving PPG embeddings from
accelerometry embeddings. We show that distilled accelerometry encoders have
significantly more informative representations compared to self-supervised or
supervised encoders trained directly on accelerometry data, observed by at
least 23%-49% improved performance for predicting heart rate and heart rate
variability. We also show that distilled accelerometry encoders are readily
predictive of a wide array of downstream health targets, i.e., they are
generalist foundation models. We believe accelerometry foundation models for
health may unlock new opportunities for developing digital biomarkers from any
wearable device, and help individuals track their health more frequently and
conveniently.

摘要：<paragraph>現代的可穿戴裝置可以在日常生活的許多不同環境中方便且持續地記錄各種生物訊號，最終能全面了解個人的健康狀況。然而，並非所有生物訊號都相同：高保真測量值（例如光電容積描記法 (PPG)）包含更多生理資訊，但需要具有高功率佔用的光學感測器。在資源受限的環境中，這些生物訊號可能無法取得。或者，低保真生物訊號（例如加速度計，可在低動作期間擷取細微的心血管資訊）具有明顯更小的功率佔用，且幾乎可以在任何可穿戴裝置中取得。在這裡，我們證明我們可以跨生物訊號（即從 PPG 到加速度計）萃取出表徵知識，使用從 Apple 心臟和運動研究中約 172K 名參與者收集的 2000 萬分鐘未標記資料，在知情同意下進行。我們先透過自我監督式學習預先訓練 PPG 編碼器，然後將其表徵知識萃取到加速度計編碼器。我們在未見過的資料上展示了強大的跨模態對齊，例如從加速度計嵌入中擷取 PPG 嵌入的 99.2% 最高 1 精確度。我們表明，與直接在加速度計資料上訓練的自我監督式或監督式編碼器相比，萃取的加速度計編碼器具有更多資訊豐富的表徵，從預測心率和心率變異性的表現改善至少 23%-49% 可見。我們還表明，萃取的加速度計編碼器很容易預測廣泛的下游健康目標，即它們是一般化的基礎模型。我們相信，用於健康的加速度計基礎模型可能會開啟從任何可穿戴裝置開發數位生物標記的新機會，並幫助個人更頻繁且更方便地追蹤他們的健康狀況。</paragraph>

##### **TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs**
2412.11242v2 by Lanxiang Hu, Tajana Rosing, Hao Zhang

Specializing large language models (LLMs) for local deployment in
domain-specific use cases is necessary for strong performance while meeting
latency and privacy constraints. However, conventional task-specific adaptation
approaches do not show simultaneous memory saving and inference speedup at
deployment time. Practical compression techniques like quantization and pruning
require dedicated hardware or kernel support to achieve measured inference
speedup. We develop TrimLLM based on the layer-wise specialization phenomenon
we empirically observed and verified on contemporary LLMs. TrimLLM reduces the
depth of LLMs via progressive layer dropping. We show it retains LLMs' capacity
in specific domains and achieves inference speedup irrespective of hardware and
deep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for
inference; models adapted on medical, legal, and financial datasets all
demonstrate $2.1-5.7\times$ inference speedup on consumer GPUs and up to
$3.1\times$ speedup on A100 when compared to state-of-the-art model compression
algorithms, with no loss in accuracy at 50$\sim$60\% model compression ratio.

摘要：針對特定領域的使用案例，將大型語言模型 (LLM) 專門化為本地部署對於在滿足延遲和隱私限制的同時，實現強大的效能十分必要。然而，傳統的特定任務適應方法並未在部署時同時展現記憶體節省和推論加速。量化和剪枝等實用的壓縮技術需要專用的硬體或核心支援，才能實現已測量的推論加速。我們根據在當代 LLM 上經驗觀察並驗證的分層專門化現象，開發了 TrimLLM。TrimLLM 透過漸進式層級捨棄來減少 LLM 的深度。我們展示它保留了 LLM 在特定領域中的容量，並在不考慮硬體和深度學習架構的情況下實現了推論加速。我們針對不同大小的 LLM 評估了 TrimLLM 的推論；在醫療、法律和財務資料集上適應的模型，與最先進的模型壓縮演算法相比，在消費級 GPU 上都展現了 $2.1-5.7\times$ 的推論加速，而 A100 上的加速則高達 $3.1\times$，且在 50$\sim$60% 的模型壓縮率下，準確度沒有損失。

##### **Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment**
2412.11186v1 by Haisheng Lu, Yujie Fu, Fan Zhang, Le Zhang

Medical image segmentation is a critical component of clinical practice, and
the state-of-the-art MedSAM model has significantly advanced this field.
Nevertheless, critiques highlight that MedSAM demands substantial computational
resources during inference. To address this issue, the CVPR 2024 MedSAM on
Laptop Challenge was established to find an optimal balance between accuracy
and processing speed. In this paper, we introduce a quantization-aware training
pipeline designed to efficiently quantize the Segment Anything Model for
medical images and deploy it using the OpenVINO inference engine. This pipeline
optimizes both training time and disk storage. Our experimental results confirm
that this approach considerably enhances processing speed over the baseline,
while still achieving an acceptable accuracy level. The training script,
inference script, and quantized model are publicly accessible at
https://github.com/AVC2-UESTC/QMedSAM.

摘要：醫學影像分割是臨床實務中至關重要的組成部分，而最先進的 MedSAM 模型已大幅提升此領域。儘管如此，批評者強調 MedSAM 在推論期間需要大量的計算資源。為了解決這個問題，CVPR 2024 MedSAM on Laptop 挑戰賽因而成立，以期在準確度與處理速度之間取得最佳平衡。在本文中，我們介紹了一種量化感知訓練管道，用於有效量化 Segment Anything Model 以處理醫學影像，並使用 OpenVINO 推論引擎進行部署。此管道同時最佳化了訓練時間與磁碟儲存空間。我們的實驗結果證實，此方法大幅提升了處理速度，同時仍達到可接受的準確度等級。訓練腳本、推論腳本和量化模型已公開於 https://github.com/AVC2-UESTC/QMedSAM。

##### **AD-LLM: Benchmarking Large Language Models for Anomaly Detection**
2412.11142v1 by Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi, Kaize Ding, Xia Hu, Yue Zhao

Anomaly detection (AD) is an important machine learning task with many
real-world uses, including fraud detection, medical diagnosis, and industrial
monitoring. Within natural language processing (NLP), AD helps detect issues
like spam, misinformation, and unusual user activity. Although large language
models (LLMs) have had a strong impact on tasks such as text generation and
summarization, their potential in AD has not been studied enough. This paper
introduces AD-LLM, the first benchmark that evaluates how LLMs can help with
NLP anomaly detection. We examine three key tasks: (i) zero-shot detection,
using LLMs' pre-trained knowledge to perform AD without tasks-specific
training; (ii) data augmentation, generating synthetic data and category
descriptions to improve AD models; and (iii) model selection, using LLMs to
suggest unsupervised AD models. Through experiments with different datasets, we
find that LLMs can work well in zero-shot AD, that carefully designed
augmentation methods are useful, and that explaining model selection for
specific datasets remains challenging. Based on these results, we outline six
future research directions on LLMs for AD.

摘要：異常偵測 (AD) 是一項重要的機器學習任務，在現實世界中有許多用途，包括詐欺偵測、醫療診斷和工業監控。在自然語言處理 (NLP) 中，AD 有助於偵測垃圾郵件、錯誤訊息和異常使用者活動等問題。儘管大型語言模型 (LLM) 對文字生成和摘要等任務產生了重大影響，但它們在 AD 中的潛力尚未得到充分研究。本文介紹了 AD-LLM，這是第一個評估 LLM 如何協助 NLP 異常偵測的基準。我們探討了三個關鍵任務：(i) 零次學習偵測，使用 LLM 的預訓練知識在沒有特定任務訓練的情況下執行 AD；(ii) 資料擴充，生成合成資料和類別描述以改善 AD 模型；以及 (iii) 模型選擇，使用 LLM 來建議無監督 AD 模型。透過使用不同資料集進行的實驗，我們發現 LLM 可以很好地用於零次學習 AD，精心設計的擴充方法很有用，並且針對特定資料集解釋模型選擇仍然具有挑戰性。根據這些結果，我們概述了有關 AD 的 LLM 未來六個研究方向。

##### **Decoding Drug Discovery: Exploring A-to-Z In silico Methods for Beginners**
2412.11137v1 by Hezha O. Rasul, Dlzar D. Ghafour, Bakhtyar K. Aziz, Bryar A. Hassan, Tarik A. Rashid, Arif Kivrak

The drug development process is a critical challenge in the pharmaceutical
industry due to its time-consuming nature and the need to discover new drug
potentials to address various ailments. The initial step in drug development,
drug target identification, often consumes considerable time. While valid,
traditional methods such as in vivo and in vitro approaches are limited in
their ability to analyze vast amounts of data efficiently, leading to wasteful
outcomes. To expedite and streamline drug development, an increasing reliance
on computer-aided drug design (CADD) approaches has merged. These sophisticated
in silico methods offer a promising avenue for efficiently identifying viable
drug candidates, thus providing pharmaceutical firms with significant
opportunities to uncover new prospective drug targets. The main goal of this
work is to review in silico methods used in the drug development process with a
focus on identifying therapeutic targets linked to specific diseases at the
genetic or protein level. This article thoroughly discusses A-to-Z in silico
techniques, which are essential for identifying the targets of bioactive
compounds and their potential therapeutic effects. This review intends to
improve drug discovery processes by illuminating the state of these
cutting-edge approaches, thereby maximizing the effectiveness and duration of
clinical trials for novel drug target investigation.

摘要：藥物開發過程是製藥產業的一項關鍵挑戰，因為它耗時且需要找出新的藥物潛力來解決各種疾病。藥物開發的第一步，藥物目標識別，通常會花費大量時間。雖然有效，但傳統方法（例如體內和體外方法）在有效分析大量資料的能力上受到限制，導致浪費結果。為了加快和簡化藥物開發，越來越依賴電腦輔助藥物設計 (CADD) 方法。這些先進的 in silico 方法提供了一個有前途的途徑，可以有效地識別可行的候選藥物，從而為製藥公司提供顯著的機會來發現新的潛在藥物目標。這項工作的目標是回顧藥物開發過程中使用的 in silico 方法，重點是找出與特定疾病在基因或蛋白質層面相關的治療目標。本文徹底討論了 A-to-Z in silico 技術，這些技術對於識別生物活性化合物的目標及其潛在治療效果至關重要。這篇評論旨在透過闡明這些尖端方法的狀態來改進藥物發現過程，從而最大化新藥物目標研究的有效性和持續時間。

##### **MedG-KRP: Medical Graph Knowledge Representation Probing**
2412.10982v2 by Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker, Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon, John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice Yang, Eric Karl Oermann

Large language models (LLMs) have recently emerged as powerful tools, finding
many medical applications. LLMs' ability to coalesce vast amounts of
information from many sources to generate a response-a process similar to that
of a human expert-has led many to see potential in deploying LLMs for clinical
use. However, medicine is a setting where accurate reasoning is paramount. Many
researchers are questioning the effectiveness of multiple choice question
answering (MCQA) benchmarks, frequently used to test LLMs. Researchers and
clinicians alike must have complete confidence in LLMs' abilities for them to
be deployed in a medical setting. To address this need for understanding, we
introduce a knowledge graph (KG)-based method to evaluate the biomedical
reasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts
in order to better understand how they reason. We test GPT-4, Llama3-70b, and
PalmyraMed-70b, a specialized medical model. We enlist a panel of medical
students to review a total of 60 LLM-generated graphs and compare these graphs
to BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human
review but worst in our ground truth comparison; vice-versa with PalmyraMed,
the medical model. Our work provides a means of visualizing the medical
reasoning pathways of LLMs so they can be implemented in clinical settings
safely and effectively.

摘要：大型語言模型 (LLM) 近期已成為強大的工具，在醫療領域中發現許多應用。LLM 從許多來源匯集大量資訊以產生回應的能力（此過程類似於人類專家的過程），已讓許多人看到將 LLM 部署於臨床用途的潛力。然而，醫學是一個準確推理至關重要的領域。許多研究人員質疑多選題回答 (MCQA) 基準的有效性，而這經常被用於測試 LLM。研究人員和臨床醫生都必須對 LLM 的能力有完全的信心，才能將其部署於醫療環境中。為了滿足這種理解需求，我們引入一個基於知識圖譜 (KG) 的方法來評估 LLM 的生物醫學推理能力。基本上，我們繪製 LLM 如何連結醫療概念，以更好地理解它們的推理方式。我們測試了 GPT-4、Llama3-70b 和 PalmyraMed-70b，這是一個專門的醫療模型。我們徵集了一組醫學生來檢閱總共 60 個 LLM 生成的圖表，並將這些圖表與 BIOS（一個大型生物醫學 KG）進行比較。我們觀察到 GPT-4 在我們的人工審查中表現最佳，但在我們的基本事實比較中表現最差；而專門的醫療模型 PalmyraMed 則相反。我們的研究提供了一種可視化 LLM 醫療推理路徑的方法，以便它們能夠安全有效地實作於臨床環境中。

##### **LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages**
2412.10918v1 by Murat Gunay, Bunyamin Keles, Raife Hizlan

The rise of chronic diseases and pandemics like COVID-19 has emphasized the
need for effective patient data processing while ensuring privacy through
anonymization and de-identification of protected health information (PHI).
Anonymized data facilitates research without compromising patient
confidentiality. This paper introduces expert small AI models developed using
the LLM-in-the-loop methodology to meet the demand for domain-specific
de-identification NER models. These models overcome the privacy risks
associated with large language models (LLMs) used via APIs by eliminating the
need to transmit or store sensitive data. More importantly, they consistently
outperform LLMs in de-identification tasks, offering superior performance and
reliability. Our de-identification NER models, developed in eight languages
(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)
achieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,
0.978, and 0.953 respectively. These results establish them as the most
accurate healthcare anonymization solutions, surpassing existing small models
and even general-purpose LLMs such as GPT-4o. While Part-1 of this series
introduced the LLM-in-the-loop methodology for bio-medical document
translation, this second paper showcases its success in developing
cost-effective expert small NER models in de-identification tasks. Our findings
lay the groundwork for future healthcare AI innovations, including biomedical
entity and relation extraction, demonstrating the value of specialized models
for domain-specific challenges.

摘要：慢性疾病和 COVID-19 等流行病的興起強調了有效處理患者資料的必要性，同時透過匿名化和移除受保護健康資訊 (PHI) 的識別資訊來確保隱私。匿名化資料有助於研究，而不會損害患者的機密性。本文介紹使用 LLM-in-the-loop 方法開發的專家小型 AI 模型，以滿足特定領域去識別化 NER 模型的需求。這些模型克服了透過 API 使用大型語言模型 (LLM) 所帶來的隱私風險，消除了傳輸或儲存敏感資料的需要。更重要的是，它們在去識別化任務中始終優於 LLM，提供卓越的效能和可靠性。我們以八種語言（英語、德語、義大利語、法語、羅馬尼亞語、土耳其語、西班牙語和阿拉伯語）開發的去識別化 NER 模型分別達到 f1-micro 分數平均值 0.966、0.975、0.976、0.970、0.964、0.974、0.978 和 0.953。這些結果確立了它們作為最準確的醫療保健匿名化解決方案，超越了現有的小模型，甚至超越了 GPT-4o 等通用 LLM。雖然本系列的第一部分介紹了用於生物醫學文件翻譯的 LLM-in-the-loop 方法，但第二篇論文展示了其在去識別化任務中開發具有成本效益的專家小型 NER 模型的成功。我們的研究結果為未來的醫療保健 AI 創新奠定了基礎，包括生物醫學實體和關係萃取，證明了專門化模型在特定領域挑戰中的價值。

##### **Superhuman performance of a large language model on the reasoning tasks of a physician**
2412.10849v1 by Peter G. Brodeur, Thomas A. Buckley, Zahir Kanjee, Ethan Goh, Evelyn Bin Ling, Priyank Jain, Stephanie Cabral, Raja-Elie Abdulnour, Adrian Haimovich, Jason A. Freed, Andrew Olson, Daniel J. Morgan, Jason Hom, Robert Gallo, Eric Horvitz, Jonathan Chen, Arjun K. Manrai, Adam Rodman

Performance of large language models (LLMs) on medical tasks has
traditionally been evaluated using multiple choice question benchmarks.
However, such benchmarks are highly constrained, saturated with repeated
impressive performance by LLMs, and have an unclear relationship to performance
in real clinical scenarios. Clinical reasoning, the process by which physicians
employ critical thinking to gather and synthesize clinical data to diagnose and
manage medical problems, remains an attractive benchmark for model performance.
Prior LLMs have shown promise in outperforming clinicians in routine and
complex diagnostic scenarios. We sought to evaluate OpenAI's o1-preview model,
a model developed to increase run-time via chain of thought processes prior to
generating a response. We characterize the performance of o1-preview with five
experiments including differential diagnosis generation, display of diagnostic
reasoning, triage differential diagnosis, probabilistic reasoning, and
management reasoning, adjudicated by physician experts with validated
psychometrics. Our primary outcome was comparison of the o1-preview output to
identical prior experiments that have historical human controls and benchmarks
of previous LLMs. Significant improvements were observed with differential
diagnosis generation and quality of diagnostic and management reasoning. No
improvements were observed with probabilistic reasoning or triage differential
diagnosis. This study highlights o1-preview's ability to perform strongly on
tasks that require complex critical thinking such as diagnosis and management
while its performance on probabilistic reasoning tasks was similar to past
models. New robust benchmarks and scalable evaluation of LLM capabilities
compared to human physicians are needed along with trials evaluating AI in real
clinical settings.

摘要：大型語言模型 (LLM) 在醫療任務中的表現通常使用多選題基準進行評估。然而，此類基準受到高度限制，充斥著 LLM 重複且令人印象深刻的表現，且與實際臨床場景中的表現關係不明確。臨床推理，即醫師運用批判性思考收集和綜合臨床資料以診斷和管理醫療問題的過程，仍然是模型表現的誘人基準。先前的 LLM 已展現出在常規和複雜診斷場景中優於臨床醫師的潛力。我們試圖評估 OpenAI 的 o1-preview 模型，這是一個在產生回應之前透過思考過程鏈來增加執行時間的模型。我們透過五項實驗來描述 o1-preview 的表現，包括鑑別診斷產生、診斷推理顯示、分流鑑別診斷、機率推理和管理推理，並由經過驗證的心理測量學的醫師專家進行判定。我們的主要結果是將 o1-preview 輸出與具有歷史人類控制和先前 LLM 基準的相同先前實驗進行比較。在鑑別診斷產生和診斷和管理推理品質方面觀察到顯著的進步。在機率推理或分流鑑別診斷方面沒有觀察到進步。這項研究突顯了 o1-preview 在執行需要複雜批判性思考的任務（例如診斷和管理）方面的強大能力，而它在機率推理任務中的表現則與過去的模型類似。需要新的穩健基準和 LLM 能力的可擴充評估，與人類醫師進行比較，以及評估 AI 在實際臨床環境中的試驗。

##### **Large Language Models for Medical Forecasting -- Foresight 2**
2412.10848v1 by Zeljko Kraljevic, Joshua Au Yeung, Daniel Bean, James Teo, Richard J. Dobson

Foresight 2 (FS2) is a large language model fine-tuned on hospital data for
modelling patient timelines (GitHub 'removed for anon'). It can understand
patients' clinical notes and predict SNOMED codes for a wide range of
biomedical use cases, including diagnosis suggestions, risk forecasting, and
procedure and medication recommendations. FS2 is trained on the free text
portion of the MIMIC-III dataset, firstly through extracting biomedical
concepts and then creating contextualised patient timelines, upon which the
model is then fine-tuned. The results show significant improvement over the
previous state-of-the-art for the next new biomedical concept prediction (P/R -
0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new
disorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of
risk forecast, we compare our model to GPT-4-turbo (and a range of open-source
biomedical LLMs) and show that FS2 performs significantly better on such tasks
(P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data
into LLMs and shows that small models outperform much larger ones when
fine-tuned on high-quality, specialised data.

摘要：Foresight 2 (FS2) 是一個大型語言模型，針對醫院數據進行微調，用於建模患者時間軸（GitHub「已移除匿名」）。它可以了解患者的臨床記錄，並預測各種生物醫學用例的 SNOMED 代碼，包括診斷建議、風險預測以及程序和藥物建議。FS2 在 MIMIC-III 數據集的自由文本部分上進行訓練，首先通過提取生物醫學概念，然後創建情境化的患者時間軸，然後對模型進行微調。結果表明，與先前最先進的下一新生物醫學概念預測（P/R - 0.73/0.66 對 0.52/0.32）相比，有顯著改進，並且特別是對於下一新疾病預測（P/R - 0.69/0.62 對 0.46/0.25）也有類似的改進。最後，在風險預測任務上，我們將我們的模型與 GPT-4-turbo（和一系列開源生物醫學 LLM）進行比較，並表明 FS2 在此類任務上表現顯著優於（P@5 - 0.90 對 0.65）。這突顯了將醫院數據納入 LLM 的必要性，並表明在針對高品質專門數據進行微調時，小型模型的表現優於大型模型。

##### **Transfer Learning with Active Sampling for Rapid Training and Calibration in BCI-P300 Across Health States and Multi-centre Data**
2412.17833v1 by Christian Flores, Marcelo Contreras, Ichiro Macedo, Javier Andreu-Perez

Machine learning and deep learning advancements have boosted Brain-Computer
Interface (BCI) performance, but their wide-scale applicability is limited due
to factors like individual health, hardware variations, and cultural
differences affecting neural data. Studies often focus on uniform single-site
experiments in uniform settings, leading to high performance that may not
translate well to real-world diversity. Deep learning models aim to enhance BCI
classification accuracy, and transfer learning has been suggested to adapt
models to individual neural patterns using a base model trained on others'
data. This approach promises better generalizability and reduced overfitting,
yet challenges remain in handling diverse and imbalanced datasets from
different equipment, subjects, multiple centres in different countries, and
both healthy and patient populations for effective model transfer and tuning.
  In a setting characterized by maximal heterogeneity, we proposed P300 wave
detection in BCIs employing a convolutional neural network fitted with adaptive
transfer learning based on Poison Sampling Disk (PDS) called Active Sampling
(AS), which flexibly adjusts the transition from source data to the target
domain. Our results reported for subject adaptive with 40% of adaptive
fine-tuning that the averaged classification accuracy improved by 5.36% and
standard deviation reduced by 12.22% using two distinct, internationally
replicated datasets. These results outperformed in classification accuracy,
computational time, and training efficiency, mainly due to the proposed Active
Sampling (AS) method for transfer learning.

摘要：機器學習與深度學習的進展提升了腦機介面（BCI）的效能，但其廣泛的適用性受到個人健康、硬體差異和影響神經資料的文化差異等因素的限制。研究通常專注於統一地點的單一地點實驗，導致高性能可能無法很好地轉化為現實世界的多樣性。深度學習模型旨在增強 BCI 分類準確度，並且已經建議轉移學習使用在其他人資料上訓練的基礎模型來適應模型以符合個別神經模式。這種方法承諾更好的泛化能力和減少過度擬合，但在處理來自不同設備、受試者、不同國家/地區的多個中心以及健康和患者人群的多樣化且不平衡的資料集以進行有效的模型轉移和調整時，仍然存在挑戰。在以最大異質性為特徵的設定中，我們提出了 P300 波檢測，在 BCI 中採用具備基於毒藥抽樣盤 (PDS) 的自適應轉移學習的卷積神經網路，稱為主動抽樣 (AS)，它靈活地調整從原始資料到目標網域的轉換。我們針對主體自適應報告的結果，其中 40% 的自適應微調，使用兩個不同的國際複製資料集，平均分類準確度提高了 5.36%，標準差降低了 12.22%。這些結果在分類準確度、計算時間和訓練效率方面表現出色，這主要是由於提出的主動抽樣 (AS) 方法用於轉移學習。

##### **Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation**
2412.10826v1 by Sharmin Akter

Chest radiography is climacteric in identifying different pulmonary diseases,
yet radiologist workload and inefficiency can lead to misdiagnoses. Automatic,
accurate, and efficient segmentation of lung from X-ray images of chest is
paramount for early disease detection. This study develops a deep learning
framework using a Pix2pix Generative Adversarial Network (GAN) to segment
pulmonary abnormalities from CXR images. This framework's image preprocessing
and augmentation techniques were properly incorporated with a U-Net-inspired
generator-discriminator architecture. Initially, it loaded the CXR images and
manual masks from the Montgomery and Shenzhen datasets, after which
preprocessing and resizing were performed. A U-Net generator is applied to the
processed CXR images that yield segmented masks; then, a Discriminator Network
differentiates between the generated and real masks. Montgomery dataset served
as the model's training set in the study, and the Shenzhen dataset was used to
test its robustness, which was used here for the first time. An adversarial
loss and an L1 distance were used to optimize the model in training. All
metrics, which assess precision, recall, F1 score, and Dice coefficient, prove
the effectiveness of this framework in pulmonary abnormality segmentation. It,
therefore, sets the basis for future studies to be performed shortly using
diverse datasets that could further confirm its clinical applicability in
medical imaging.

摘要：胸部 X 光攝影在辨識不同的肺部疾病中具有決定性，然而放射科醫師的工作負擔和效率不彰可能會導致誤診。自動、準確且有效率地從胸部 X 光影像中分割出肺部，對於早期疾病偵測至關重要。本研究開發一個深度學習架構，使用 Pix2pix 生成對抗網路 (GAN) 從 CXR 影像中分割出肺部異常。此架構的影像前處理和擴充技術與一個受 U-Net 啟發的生成器-判別器架構適當地整合。最初，它載入 CXR 影像和 Montgomery 及深圳資料集的手動遮罩，之後執行前處理和調整大小。將 U-Net 生成器應用於已處理的 CXR 影像，產生分割遮罩；然後，判別器網路區分生成的遮罩和真實遮罩。Montgomery 資料集作為本研究模型的訓練集，而深圳資料集用於測試其穩健性，這是首次使用於此。對抗損失和 L1 距離用於在訓練中最佳化模型。所有評估精準度、召回率、F1 分數和 Dice 係數的指標都證明此架構在肺部異常分割中的有效性。因此，它為不久後使用更多元資料集進行的未來研究奠定基礎，這些研究進一步確認其在醫學影像中的臨床適用性。

##### **Medical Manifestation-Aware De-Identification**
2412.10804v1 by Yuan Tian, Shuo Wang, Guangtao Zhai

Face de-identification (DeID) has been widely studied for common scenes, but
remains under-researched for medical scenes, mostly due to the lack of
large-scale patient face datasets. In this paper, we release MeMa, consisting
of over 40,000 photo-realistic patient faces. MeMa is re-generated from massive
real patient photos. By carefully modulating the generation and data-filtering
procedures, MeMa avoids breaching real patient privacy, while ensuring rich and
plausible medical manifestations. We recruit expert clinicians to annotate MeMa
with both coarse- and fine-grained labels, building the first medical-scene
DeID benchmark. Additionally, we propose a baseline approach for this new
medical-aware DeID task, by integrating data-driven medical semantic priors
into the DeID procedure. Despite its conciseness and simplicity, our approach
substantially outperforms previous ones. Dataset is available at
https://github.com/tianyuan168326/MeMa-Pytorch.

摘要：人脸去識別 (DeID) 已被廣泛研究用於常見場景，但
對於醫療場景的研究仍然不足，主要是由於缺乏
大規模的患者人臉數據集。在本文中，我們發布了 MeMa，其中
包含超過 40,000 張逼真的患者人臉。MeMa 是從大量的
真實患者照片中重新生成的。通過仔細調節生成和數據過濾
程序，MeMa 避免侵犯真實患者的隱私，同時確保豐富且
合理的醫療表現。我們招募專家臨床醫生為 MeMa 添加粗略和精細標籤，建立第一個醫療場景
DeID 基準。此外，我們提出了一種針對此新的
醫療感知 DeID 任務的基線方法，通過將數據驅動的醫療語義先驗
整合到 DeID 程序中。儘管簡潔且簡單，但我們的做法
大幅優於先前的做法。數據集可在
https://github.com/tianyuan168326/MeMa-Pytorch 中獲得。

##### **Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement**
2412.10629v1 by Di Xu, Xin Miao, Hengjie Liu, Jessica E. Scholey, Wensha Yang, Mary Feng, Michael Ohliger, Hui Lin, Yi Lao, Yang Yang, Ke Sheng

Abstract Purpose: High-quality 4D MRI requires an impractically long scanning
time for dense k-space signal acquisition covering all respiratory phases.
Accelerated sparse sampling followed by reconstruction enhancement is desired
but often results in degraded image quality and long reconstruction time. We
hereby propose the chained iterative reconstruction network (CIRNet) for
efficient sparse-sampling reconstruction while maintaining clinically
deployable quality. Methods: CIRNet adopts the denoising diffusion
probabilistic framework to condition the image reconstruction through a
stochastic iterative denoising process. During training, a forward Markovian
diffusion process is designed to gradually add Gaussian noise to the densely
sampled ground truth (GT), while CIRNet is optimized to iteratively reverse the
Markovian process from the forward outputs. At the inference stage, CIRNet
performs the reverse process solely to recover signals from noise, conditioned
upon the undersampled input. CIRNet processed the 4D data (3D+t) as temporal
slices (2D+t). The proposed framework is evaluated on a data cohort consisting
of 48 patients (12332 temporal slices) who underwent free-breathing liver 4D
MRI. 3-, 6-, 10-, 20- and 30-times acceleration were examined with a
retrospective random undersampling scheme. Compressed sensing (CS)
reconstruction with a spatiotemporal constraint and a recently proposed deep
network, Re-Con-GAN, are selected as baselines. Results: CIRNet consistently
achieved superior performance compared to CS and Re-Con-GAN. The inference time
of CIRNet, CS, and Re-Con-GAN are 11s, 120s, and 0.15s. Conclusion: A novel
framework, CIRNet, is presented. CIRNet maintains useable image quality for
acceleration up to 30 times, significantly reducing the burden of 4DMRI.

摘要：<paragraph>摘要目的：高品質 4D MRI 需要極不切實際的長時間掃描，才能獲得涵蓋所有呼吸階段的密集 k 空間訊號。加速稀疏取樣後再進行重建增強固然理想，但通常會導致影像品質下降，且重建時間過長。在此，我們提出鏈式反覆重建網路 (CIRNet)，以在維持臨床可部署品質的同時，進行有效率的稀疏取樣重建。方法：CIRNet 採用去噪擴散機率架構，透過隨機反覆去噪程序，對影像重建進行條件化。在訓練期間，正向馬可夫擴散程序會逐漸將高斯雜訊加入密集取樣的真實值 (GT) 中，而 CIRNet 則最佳化，以反覆逆轉正向輸出的馬可夫程序。在推論階段，CIRNet 僅執行逆向程序，以從雜訊中復原訊號，並以欠取樣輸入為條件。CIRNet 將 4D 資料 (3D+t) 處理為時間切片 (2D+t)。所提出的架構在一個資料群組中進行評估，該群組包含 48 位接受自由呼吸肝臟 4D MRI 的患者 (12332 個時間切片)。使用回溯隨機欠取樣方案，檢查 3、6、10、20 和 30 倍加速。選擇具有時空約束的壓縮感測 (CS) 重建和最近提出的深度網路 Re-Con-GAN 作為基準。結果：與 CS 和 Re-Con-GAN 相比，CIRNet 持續獲得較佳的效能。CIRNet、CS 和 Re-Con-GAN 的推論時間分別為 11 秒、120 秒和 0.15 秒。結論：提出了一個新穎的架構 CIRNet。CIRNet 可維持可用影像品質，加速率最高達 30 倍，大幅降低 4DMRI 的負擔。</paragraph>

##### **A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options**
2412.10622v1 by Peilong Wang, Jason Holmes, Zhengliang Liu, Dequan Chen, Tianming Liu, Jiajian Shen, Wei Liu

Purpose: We present an updated study evaluating the performance of large
language models (LLMs) in answering radiation oncology physics questions,
focusing on the latest released models.
  Methods: A set of 100 multiple-choice radiation oncology physics questions,
previously created by us, was used for this study. The answer options of the
questions were randomly shuffled to create "new" exam sets. Five LLMs -- OpenAI
o1-preview, GPT-4o, LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude 3.5 Sonnet --
with the versions released before September 30, 2024, were queried using these
new exams. To evaluate their deductive reasoning abilities, the correct answer
options in the questions were replaced with "None of the above." Then, the
explain-first and step-by-step instruction prompt was used to test if it
improved their reasoning abilities. The performance of the LLMs was compared to
medical physicists in majority-vote scenarios.
  Results: All models demonstrated expert-level performance on these questions,
with o1-preview even surpassing medical physicists in majority-vote scenarios.
When substituting the correct answer options with "None of the above," all
models exhibited a considerable decline in performance, suggesting room for
improvement. The explain-first and step-by-step instruction prompt helped
enhance the reasoning abilities of LLaMA 3.1 (405B), Gemini 1.5 Pro, and Claude
3.5 Sonnet models.
  Conclusion: These latest LLMs demonstrated expert-level performance in
answering radiation oncology physics questions, exhibiting great potential for
assisting in radiation oncology physics education.

摘要：<paragraph>目的：我们提出了一项更新的研究，评估大型语言模型 (LLM) 在回答放射肿瘤物理学问题方面的性能，重点关注最新发布的模型。
方法：我们之前创建的一组 100 道多项选择放射肿瘤物理学问题用于这项研究。问题的答案选项被随机打乱以创建“新”的考试集。五个 LLM——OpenAI o1-preview、GPT-4o、LLaMA 3.1 (405B)、Gemini 1.5 Pro 和 Claude 3.5 Sonnet——在 2024 年 9 月 30 日之前发布的版本中，使用这些新考试进行了查询。为了评估它们的演绎推理能力，问题中的正确答案选项被替换为“以上皆非”。然后，使用先解释和逐步说明的提示来测试它是否提高了它们的推理能力。LLM 的性能与大多数投票场景中的医学物理学家进行了比较。
结果：所有模型在这些问题上都表现出专家级性能，o1-preview 甚至在大多数投票场景中超过了医学物理学家。当用“以上皆非”替换正确的答案选项时，所有模型的性能都大幅下降，这表明有改进的空间。先解释和逐步说明的提示有助于增强 LLaMA 3.1 (405B)、Gemini 1.5 Pro 和 Claude 3.5 Sonnet 模型的推理能力。
结论：这些最新的 LLM 在回答放射肿瘤物理学问题方面表现出专家级性能，展示了在放射肿瘤物理学教育中提供帮助的巨大潜力。</paragraph>

##### **MANGO: Multimodal Acuity traNsformer for intelliGent ICU Outcomes**
2412.17832v1 by Jiaqing Zhang, Miguel Contreras, Sabyasachi Bandyopadhyay, Andrea Davidson, Jessica Sena, Yuanfang Ren, Ziyuan Guan, Tezcan Ozrazgat-Baslanti, Tyler J. Loftus, Subhash Nerella, Azra Bihorac, Parisa Rashidi

Estimation of patient acuity in the Intensive Care Unit (ICU) is vital to
ensure timely and appropriate interventions. Advances in artificial
intelligence (AI) technologies have significantly improved the accuracy of
acuity predictions. However, prior studies using machine learning for acuity
prediction have predominantly relied on electronic health records (EHR) data,
often overlooking other critical aspects of ICU stay, such as patient mobility,
environmental factors, and facial cues indicating pain or agitation. To address
this gap, we present MANGO: the Multimodal Acuity traNsformer for intelliGent
ICU Outcomes, designed to enhance the prediction of patient acuity states,
transitions, and the need for life-sustaining therapy. We collected a
multimodal dataset ICU-Multimodal, incorporating four key modalities, EHR data,
wearable sensor data, video of patient's facial cues, and ambient sensor data,
which we utilized to train MANGO. The MANGO model employs a multimodal feature
fusion network powered by Transformer masked self-attention method, enabling it
to capture and learn complex interactions across these diverse data modalities
even when some modalities are absent. Our results demonstrated that integrating
multiple modalities significantly improved the model's ability to predict
acuity status, transitions, and the need for life-sustaining therapy. The
best-performing models achieved an area under the receiver operating
characteristic curve (AUROC) of 0.76 (95% CI: 0.72-0.79) for predicting
transitions in acuity status and the need for life-sustaining therapy, while
0.82 (95% CI: 0.69-0.89) for acuity status prediction...

摘要：在重症監護病房 (ICU) 中評估病患的敏銳度至關重要，以確保及時且適當的介入。人工智慧 (AI) 技術的進步已顯著提高敏銳度預測的準確度。然而，先前使用機器學習進行敏銳度預測的研究主要依賴電子健康紀錄 (EHR) 數據，通常忽略了 ICU 住院期間的其他關鍵面向，例如病患的活動力、環境因素和表示疼痛或激動的面部線索。為了解決這個差距，我們提出 MANGO：用於智慧 ICU 結果的多模式敏銳度轉換器，旨在增強對病患敏銳度狀態、轉變和對維持生命治療需求的預測。我們蒐集了一個多模式資料集 ICU-Multimodal，包含四個關鍵模式：EHR 數據、可穿戴式感測器數據、病患面部線索的影片和環境感測器數據，我們利用這些數據訓練 MANGO。MANGO 模型採用由 Transformer 遮罩式自我注意方法驅動的多模式特徵融合網路，即使某些模式不存在，也能捕捉並學習這些不同數據模式之間的複雜互動。我們的結果表明，整合多種模式顯著提升了模型預測敏銳度狀態、轉變和對維持生命治療需求的能力。表現最佳的模型在預測敏銳度狀態的轉變和對維持生命治療的需求方面，接收器操作特徵曲線 (AUROC) 下方的面積達到 0.76 (95% CI：0.72-0.79)，而敏銳度狀態預測則達到 0.82 (95% CI：0.69-0.89) ...

