{"2501.14276": {"publish_time": "2025-01-24", "title": "Global Semantic-Guided Sub-image Feature Weight Allocation in High-Resolution Large Vision-Language Models", "paper_summary": "As the demand for high-resolution image processing in Large Vision-Language\nModels (LVLMs) grows, sub-image partitioning has become a popular approach for\nmitigating visual information loss associated with fixed-resolution processing.\nHowever, existing partitioning methods uniformly process sub-images, resulting\nin suboptimal image understanding. In this work, we reveal that the sub-images\nwith higher semantic relevance to the entire image encapsulate richer visual\ninformation for preserving the model's visual understanding ability. Therefore,\nwe propose the Global Semantic-guided Weight Allocator (GSWA) module, which\ndynamically allocates weights to sub-images based on their relative information\ndensity, emulating human visual attention mechanisms. This approach enables the\nmodel to focus on more informative regions, overcoming the limitations of\nuniform treatment. We integrate GSWA into the InternVL2-2B framework to create\nSleighVL, a lightweight yet high-performing model. Extensive experiments\ndemonstrate that SleighVL outperforms models with comparable parameters and\nremains competitive with larger models. Our work provides a promising direction\nfor more efficient and contextually aware high-resolution image processing in\nLVLMs, advancing multimodal system development.", "paper_summary_zh": "\u968f\u7740\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (LVLMs) \u4e2d\u5bf9\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5904\u7406\u7684\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u5b50\u56fe\u50cf\u5206\u533a\u5df2\u6210\u4e3a\u7f13\u89e3\u4e0e\u56fa\u5b9a\u5206\u8fa8\u7387\u5904\u7406\u76f8\u5173\u7684\u89c6\u89c9\u4fe1\u606f\u4e22\u5931\u7684\u6d41\u884c\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5206\u533a\u65b9\u6cd5\u7edf\u4e00\u5904\u7406\u5b50\u56fe\u50cf\uff0c\u5bfc\u81f4\u5b50\u56fe\u50cf\u7406\u89e3\u4e0d\u4f73\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63ed\u793a\u4e86\u4e0e\u6574\u4e2a\u56fe\u50cf\u5177\u6709\u8f83\u9ad8\u8bed\u4e49\u76f8\u5173\u6027\u7684\u5b50\u56fe\u50cf\u5c01\u88c5\u4e86\u66f4\u4e30\u5bcc\u7684\u89c6\u89c9\u4fe1\u606f\uff0c\u4ee5\u4fdd\u7559\u6a21\u578b\u7684\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5168\u5c40\u8bed\u4e49\u5f15\u5bfc\u6743\u91cd\u5206\u914d\u5668 (GSWA) \u6a21\u5757\uff0c\u8be5\u6a21\u5757\u6839\u636e\u5b50\u56fe\u50cf\u7684\u76f8\u5bf9\u4fe1\u606f\u5bc6\u5ea6\u52a8\u6001\u5206\u914d\u6743\u91cd\uff0c\u6a21\u62df\u4eba\u7c7b\u89c6\u89c9\u6ce8\u610f\u529b\u673a\u5236\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6a21\u578b\u80fd\u591f\u4e13\u6ce8\u4e8e\u66f4\u591a\u4fe1\u606f\u4e30\u5bcc\u7684\u533a\u57df\uff0c\u514b\u670d\u4e86\u7edf\u4e00\u5904\u7406\u7684\u5c40\u9650\u6027\u3002\u6211\u4eec\u5c06 GSWA \u96c6\u6210\u5230 InternVL2-2B \u6846\u67b6\u4e2d\u4ee5\u521b\u5efa SleighVL\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4f46\u9ad8\u6027\u80fd\u7684\u6a21\u578b\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSleighVL \u4f18\u4e8e\u5177\u6709\u53ef\u6bd4\u53c2\u6570\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u4e0e\u66f4\u5927\u6a21\u578b\u4fdd\u6301\u7ade\u4e89\u529b\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a LVLMs \u4e2d\u66f4\u9ad8\u6548\u4e14\u5177\u6709\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u7684\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5904\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u65b9\u5411\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u591a\u6a21\u6001\u7cfb\u7edf\u5f00\u53d1\u3002", "author": "Yuxuan Liang et.al.", "authors": "Yuxuan Liang, Xu Li, Xiaolei Chen, Haotian Chen, Yi Zheng, Chenghang Lai, Bin Li, Xiangyang Xue", "id": "2501.14276v1", "paper_url": "http://arxiv.org/abs/2501.14276v1", "repo": "null"}}