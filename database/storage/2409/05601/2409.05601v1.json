{"2409.05601": {"publish_time": "2024-09-09", "title": "Longer is (Not Necessarily) Stronger: Punctuated Long-Sequence Training for Enhanced Speech Recognition and Translation", "paper_summary": "This paper presents a new method for training sequence-to-sequence models for\nspeech recognition and translation tasks. Instead of the traditional approach\nof training models on short segments containing only lowercase or partial\npunctuation and capitalization (PnC) sentences, we propose training on longer\nutterances that include complete sentences with proper punctuation and\ncapitalization. We achieve this by using the FastConformer architecture which\nallows training 1 Billion parameter models with sequences up to 60 seconds long\nwith full attention. However, while training with PnC enhances the overall\nperformance, we observed that accuracy plateaus when training on sequences\nlonger than 40 seconds across various evaluation settings. Our proposed method\nsignificantly improves punctuation and capitalization accuracy, showing a 25%\nrelative word error rate (WER) improvement on the Earnings-21 and Earnings-22\nbenchmarks. Additionally, training on longer audio segments increases the\noverall model accuracy across speech recognition and translation benchmarks.\nThe model weights and training code are open-sourced though NVIDIA NeMo.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u65b9\u6cd5\u4f86\u8a13\u7df4\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\uff0c\u4ee5\u9032\u884c\u8a9e\u97f3\u8fa8\u8b58\u548c\u7ffb\u8b6f\u4efb\u52d9\u3002\u6211\u5011\u5efa\u8b70\u5728\u5305\u542b\u5b8c\u6574\u53e5\u5b50\u3001\u9069\u7576\u6a19\u9ede\u7b26\u865f\u548c\u5927\u5beb\u5b57\u6bcd (PnC) \u7684\u8f03\u9577\u8a9e\u53e5\u4e2d\u9032\u884c\u8a13\u7df4\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u50b3\u7d71\u65b9\u6cd5\u5728\u50c5\u5305\u542b\u5c0f\u5beb\u5b57\u6bcd\u6216\u90e8\u5206\u6a19\u9ede\u7b26\u865f\u548c\u5927\u5c0f\u5beb\u5b57\u6bcd\u7684\u77ed\u5340\u6bb5\u4e0a\u8a13\u7df4\u6a21\u578b\u3002\u6211\u5011\u900f\u904e\u4f7f\u7528 FastConformer \u67b6\u69cb\u4f86\u9054\u6210\u6b64\u76ee\u6a19\uff0c\u8a72\u67b6\u69cb\u5141\u8a31\u4f7f\u7528\u9577\u9054 60 \u79d2\u7684\u5e8f\u5217\u8a13\u7df4 10 \u5104\u500b\u53c3\u6578\u6a21\u578b\uff0c\u4e26\u5177\u6709\u5b8c\u5168\u7684\u6ce8\u610f\u529b\u3002\u7136\u800c\uff0c\u96d6\u7136\u4f7f\u7528 PnC \u9032\u884c\u8a13\u7df4\u6703\u589e\u5f37\u6574\u9ad4\u6548\u80fd\uff0c\u4f46\u6211\u5011\u89c0\u5bdf\u5230\u5728\u5404\u7a2e\u8a55\u4f30\u8a2d\u5b9a\u4e2d\uff0c\u7576\u5728\u9577\u65bc 40 \u79d2\u7684\u5e8f\u5217\u4e0a\u9032\u884c\u8a13\u7df4\u6642\uff0c\u6e96\u78ba\u5ea6\u6703\u9054\u5230\u5e73\u7a69\u671f\u3002\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u986f\u8457\u6539\u5584\u4e86\u6a19\u9ede\u7b26\u865f\u548c\u5927\u5beb\u5b57\u6bcd\u7684\u6e96\u78ba\u5ea6\uff0c\u5728 Earnings-21 \u548c Earnings-22 \u57fa\u6e96\u4e0a\u986f\u793a\u51fa 25% \u7684\u76f8\u5c0d\u5b57\u5143\u932f\u8aa4\u7387 (WER) \u6539\u9032\u3002\u6b64\u5916\uff0c\u5728\u8f03\u9577\u7684\u97f3\u8a0a\u5340\u6bb5\u4e0a\u9032\u884c\u8a13\u7df4\u6703\u63d0\u9ad8\u8a9e\u97f3\u8fa8\u8b58\u548c\u7ffb\u8b6f\u57fa\u6e96\u4e0a\u7684\u6574\u9ad4\u6a21\u578b\u6e96\u78ba\u5ea6\u3002\u6a21\u578b\u6b0a\u91cd\u548c\u8a13\u7df4\u7a0b\u5f0f\u78bc\u900f\u904e NVIDIA NeMo \u958b\u6e90\u3002", "author": "Nithin Rao Koluguri et.al.", "authors": "Nithin Rao Koluguri, Travis Bartley, Hainan Xu, Oleksii Hrinchuk, Jagadeesh Balam, Boris Ginsburg, Georg Kucsko", "id": "2409.05601v1", "paper_url": "http://arxiv.org/abs/2409.05601v1", "repo": "null"}}