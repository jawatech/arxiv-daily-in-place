{"2412.17498": {"publish_time": "2024-12-23", "title": "DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought", "paper_summary": "Recently, O1-like models have emerged as representative examples,\nillustrating the effectiveness of long chain-of-thought (CoT) in reasoning\ntasks such as math and coding tasks. In this paper, we introduce DRT-o1, an\nattempt to bring the success of long CoT to neural machine translation (MT).\nSpecifically, in view of the literature books that might involve similes and\nmetaphors, translating these texts to a target language is very difficult in\npractice due to cultural differences. In such cases, literal translation often\nfails to convey the intended meaning effectively. Even for professional human\ntranslators, considerable thought must be given to preserving semantics\nthroughout the translation process. To simulate LLMs' long thought ability in\nMT, we first mine sentences containing similes or metaphors from existing\nliterature books, and then develop a multi-agent framework to translate these\nsentences via long thought. In the multi-agent framework, a translator is used\nto iteratively translate the source sentence under the suggestions provided by\nan advisor. To ensure the effectiveness of the long thoughts, an evaluator is\nalso employed to judge whether the translation in the current round is better\nthan the previous one or not. In this manner, we collect tens of thousands of\nlong-thought MT data, which is used to train our DRT-o1. The experimental\nresults on literature translation demonstrate the effectiveness of the DRT-o1.\nUsing Qwen2.5-7B and Qwen2.5-14B as the backbones, the improvement brought by\nDRT-o1 achieves 7.33~8.26 BLEU and 1.66~3.36 CometScore. Besides, DRT-o1-7B can\noutperform QwQ-32B-Preview by 7.82 BLEU and 1.46 CometScore, showing its\neffectiveness. The project is available at https://github.com/krystalan/DRT-o1", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0cO1 \u985e\u6a21\u578b\u5df2\u6210\u70ba\u4ee3\u8868\u6027\u7bc4\u4f8b\uff0c\u8aaa\u660e\u9577\u601d\u7dad\u93c8 (CoT) \u5728\u63a8\u7406\u4efb\u52d9\uff08\u4f8b\u5982\u6578\u5b78\u548c\u7de8\u78bc\u4efb\u52d9\uff09\u4e2d\u7684\u6709\u6548\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 DRT-o1\uff0c\u5617\u8a66\u5c07\u9577 CoT \u7684\u6210\u529f\u5e36\u5165\u795e\u7d93\u6a5f\u5668\u7ffb\u8b6f (MT)\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6709\u9451\u65bc\u53ef\u80fd\u6d89\u53ca\u660e\u55bb\u548c\u96b1\u55bb\u7684\u6587\u5b78\u66f8\u7c4d\uff0c\u7531\u65bc\u6587\u5316\u5dee\u7570\uff0c\u5c07\u9019\u4e9b\u6587\u672c\u7ffb\u8b6f\u6210\u76ee\u6a19\u8a9e\u8a00\u5728\u5be6\u52d9\u4e0a\u975e\u5e38\u56f0\u96e3\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u9010\u5b57\u7ffb\u8b6f\u901a\u5e38\u7121\u6cd5\u6709\u6548\u50b3\u9054\u9810\u671f\u7684\u610f\u7fa9\u3002\u5373\u4f7f\u5c0d\u65bc\u5c08\u696d\u7684\u4eba\u985e\u7ffb\u8b6f\u4eba\u54e1\uff0c\u5728\u6574\u500b\u7ffb\u8b6f\u904e\u7a0b\u4e2d\u4e5f\u5fc5\u9808\u4ed4\u7d30\u8003\u616e\u5982\u4f55\u4fdd\u7559\u8a9e\u7fa9\u3002\u70ba\u4e86\u6a21\u64ec LLM \u5728 MT \u4e2d\u7684\u9577\u601d\u7dad\u80fd\u529b\uff0c\u6211\u5011\u9996\u5148\u5f9e\u73fe\u6709\u7684\u6587\u5b78\u66f8\u7c4d\u4e2d\u6316\u6398\u5305\u542b\u660e\u55bb\u6216\u96b1\u55bb\u7684\u53e5\u5b50\uff0c\u7136\u5f8c\u958b\u767c\u4e00\u500b\u591a\u4ee3\u7406\u67b6\u69cb\uff0c\u900f\u904e\u9577\u601d\u7dad\u7ffb\u8b6f\u9019\u4e9b\u53e5\u5b50\u3002\u5728\u591a\u4ee3\u7406\u67b6\u69cb\u4e2d\uff0c\u7ffb\u8b6f\u4eba\u54e1\u7528\u65bc\u5728\u9867\u554f\u63d0\u4f9b\u7684\u5efa\u8b70\u4e0b\u53cd\u8986\u7ffb\u8b6f\u539f\u59cb\u53e5\u5b50\u3002\u70ba\u4e86\u78ba\u4fdd\u9577\u601d\u7dad\u7684\u6709\u6548\u6027\uff0c\u4e5f\u4f7f\u7528\u8a55\u4f30\u5668\u4f86\u5224\u65b7\u7576\u524d\u56de\u5408\u7684\u7ffb\u8b6f\u662f\u5426\u512a\u65bc\u524d\u4e00\u500b\u56de\u5408\u3002\u900f\u904e\u9019\u7a2e\u65b9\u5f0f\uff0c\u6211\u5011\u6536\u96c6\u4e86\u6578\u842c\u500b\u9577\u601d\u7dad MT \u8cc7\u6599\uff0c\u7528\u65bc\u8a13\u7df4\u6211\u5011\u7684 DRT-o1\u3002\u6587\u5b78\u7ffb\u8b6f\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86 DRT-o1 \u7684\u6709\u6548\u6027\u3002\u4f7f\u7528 Qwen2.5-7B \u548c Qwen2.5-14B \u4f5c\u70ba\u4e3b\u5e79\uff0cDRT-o1 \u5e36\u4f86\u7684\u6539\u9032\u9054\u5230\u4e86 7.33~8.26 BLEU \u548c 1.66~3.36 CometScore\u3002\u6b64\u5916\uff0cDRT-o1-7B \u53ef\u4ee5\u6bd4 QwQ-32B-Preview \u9ad8\u51fa 7.82 BLEU \u548c 1.46 CometScore\uff0c\u986f\u793a\u5176\u6709\u6548\u6027\u3002\u5c08\u6848\u53ef\u5728 https://github.com/krystalan/DRT-o1 \u53d6\u5f97</paragraph>", "author": "Jiaan Wang et.al.", "authors": "Jiaan Wang, Fandong Meng, Yunlong Liang, Jie Zhou", "id": "2412.17498v1", "paper_url": "http://arxiv.org/abs/2412.17498v1", "repo": "https://github.com/krystalan/drt-o1"}}