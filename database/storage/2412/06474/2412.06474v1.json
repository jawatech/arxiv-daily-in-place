{"2412.06474": {"publish_time": "2024-12-09", "title": "From Uncertainty to Trust: Enhancing Reliability in Vision-Language Models with Uncertainty-Guided Dropout Decoding", "paper_summary": "Large vision-language models (LVLMs) demonstrate remarkable capabilities in\nmultimodal tasks but are prone to misinterpreting visual inputs, often\nresulting in hallucinations and unreliable outputs. To address these\nchallenges, we propose Dropout Decoding, a novel inference-time approach that\nquantifies the uncertainty of visual tokens and selectively masks uncertain\ntokens to improve decoding. Our method measures the uncertainty of each visual\ntoken by projecting it onto the text space and decomposing it into aleatoric\nand epistemic components. Specifically, we focus on epistemic uncertainty,\nwhich captures perception-related errors more effectively. Inspired by dropout\nregularization, we introduce uncertainty-guided token dropout, which applies\nthe dropout principle to input visual tokens instead of model parameters, and\nduring inference rather than training. By aggregating predictions from an\nensemble of masked decoding contexts, Dropout Decoding robustly mitigates\nerrors arising from visual token misinterpretations. Evaluations on benchmarks\nincluding CHAIR, THRONE, and MMBench demonstrate that Dropout Decoding\nsignificantly reduces object hallucinations (OH) and enhances both reliability\nand quality of LVLM outputs across diverse visual contexts.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u5728\u591a\u6a21\u614b\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u4f46\u5bb9\u6613\u8aa4\u89e3\u8996\u89ba\u8f38\u5165\uff0c\u7d93\u5e38\u5c0e\u81f4\u5e7b\u89ba\u548c\u4e0d\u53ef\u9760\u7684\u8f38\u51fa\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa Dropout Decoding\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u63a8\u8ad6\u6642\u9593\u65b9\u6cd5\uff0c\u5b83\u91cf\u5316\u8996\u89ba\u7b26\u865f\u7684\u4e0d\u78ba\u5b9a\u6027\uff0c\u4e26\u9078\u64c7\u6027\u5730\u906e\u7f69\u4e0d\u78ba\u5b9a\u7684\u7b26\u865f\u4ee5\u6539\u5584\u89e3\u78bc\u3002\u6211\u5011\u7684\u6a21\u578b\u901a\u904e\u5c07\u6bcf\u500b\u8996\u89ba\u7b26\u865f\u6295\u5c04\u5230\u6587\u672c\u7a7a\u9593\u4e26\u5c07\u5176\u5206\u89e3\u70ba\u96a8\u6a5f\u548c\u8a8d\u8b58\u8ad6\u7d44\u6210\u90e8\u5206\uff0c\u4f86\u8861\u91cf\u6bcf\u500b\u8996\u89ba\u7b26\u865f\u7684\u4e0d\u78ba\u5b9a\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u8a8d\u8b58\u8ad6\u4e0d\u78ba\u5b9a\u6027\uff0c\u5b83\u66f4\u6709\u6548\u5730\u6355\u6349\u8207\u611f\u77e5\u76f8\u95dc\u7684\u932f\u8aa4\u3002\u5728 Dropout \u6b63\u5247\u5316\u7684\u555f\u767c\u4e0b\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e0d\u78ba\u5b9a\u6027\u5f15\u5c0e\u7b26\u865f Dropout\uff0c\u5b83\u5c07 Dropout \u539f\u7406\u61c9\u7528\u65bc\u8f38\u5165\u8996\u89ba\u7b26\u865f\uff0c\u800c\u4e0d\u662f\u6a21\u578b\u53c3\u6578\uff0c\u4e26\u4e14\u5728\u63a8\u8ad6\u671f\u9593\u800c\u4e0d\u662f\u8a13\u7df4\u671f\u9593\u3002\u901a\u904e\u532f\u7e3d\u4f86\u81ea\u906e\u7f69\u89e3\u78bc\u4e0a\u4e0b\u6587\u7684\u9810\u6e2c\uff0cDropout Decoding \u5f37\u6709\u529b\u5730\u6e1b\u8f15\u4e86\u6e90\u81ea\u8996\u89ba\u7b26\u865f\u8aa4\u89e3\u7684\u932f\u8aa4\u3002\u5728\u5305\u62ec CHAIR\u3001THRONE \u548c MMBench \u5728\u5167\u7684\u57fa\u6e96\u4e0a\u7684\u8a55\u4f30\u8868\u660e\uff0cDropout Decoding \u5927\u5e45\u6e1b\u5c11\u4e86\u7269\u4ef6\u5e7b\u89ba (OH)\uff0c\u4e26\u589e\u5f37\u4e86 LVLM \u8f38\u51fa\u5728\u5404\u7a2e\u8996\u89ba\u74b0\u5883\u4e2d\u7684\u53ef\u9760\u6027\u548c\u54c1\u8cea\u3002", "author": "Yixiong Fang et.al.", "authors": "Yixiong Fang, Ziran Yang, Zhaorun Chen, Zhuokai Zhao, Jiawei Zhou", "id": "2412.06474v1", "paper_url": "http://arxiv.org/abs/2412.06474v1", "repo": "https://github.com/kigb/dropoutdecoding"}}