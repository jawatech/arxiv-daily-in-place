{"2406.07017": {"publish_time": "2024-06-11", "title": "MoreauPruner: Robust Pruning of Large Language Models against Weight Perturbations", "paper_summary": "Few-shot gradient methods have been extensively utilized in existing model\npruning methods, where the model weights are regarded as static values and the\neffects of potential weight perturbations are not considered. However, the\nwidely used large language models (LLMs) have several billion model parameters,\nwhich could increase the fragility of few-shot gradient pruning. In this work,\nwe experimentally show that one-shot gradient pruning algorithms could lead to\nunstable results under perturbations to model weights. And the minor error of\nswitching between data formats bfloat16 and float16 could result in drastically\ndifferent outcomes. To address such instabilities, we leverage optimization\nanalysis and propose an LLM structural pruning method, called MoreauPruner,\nwith provable robustness against weight perturbations. In MoreauPruner, the\nmodel weight importance is estimated based on the neural network's Moreau\nenvelope, which can be flexibly combined with $\\ell_1$-norm regularization\ntechniques to induce the sparsity required in the pruning task. We extensively\nevaluate the MoreauPruner algorithm on several well-known LLMs, including\nLLaMA-7B, LLaMA-13B, LLaMA3-8B, and Vicuna-7B. Our numerical results suggest\nthe robustness of MoreauPruner against weight perturbations, and indicate the\nMoreauPruner's successful accuracy-based scores in comparison to several\nexisting pruning methods. We have released the code in\n\\url{https://github.com/ShiningSord/MoreauPruner}.", "paper_summary_zh": "<paragraph>\u73fe\u6709\u7684\u6a21\u578b\u526a\u679d\u65b9\u6cd5\u4e2d\u5ee3\u6cdb\u63a1\u7528\u4e86\u5c11\u6b21\u68af\u5ea6\u6cd5\uff0c\u5176\u4e2d\u6a21\u578b\u6b0a\u91cd\u88ab\u8996\u70ba\u975c\u614b\u503c\uff0c\u800c\u6f5b\u5728\u6b0a\u91cd\u64fe\u52d5\u7684\u5f71\u97ff\u5247\u672a\u88ab\u8003\u616e\u3002\u7136\u800c\uff0c\u5ee3\u6cdb\u4f7f\u7528\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u5177\u6709\u6578\u5341\u5104\u500b\u6a21\u578b\u53c3\u6578\uff0c\u9019\u53ef\u80fd\u6703\u589e\u52a0\u5c11\u6b21\u68af\u5ea6\u526a\u679d\u7684\u8106\u5f31\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u900f\u904e\u5be6\u9a57\u8868\u660e\uff0c\u4e00\u6b21\u68af\u5ea6\u526a\u679d\u6f14\u7b97\u6cd5\u53ef\u80fd\u6703\u5c0e\u81f4\u6a21\u578b\u6b0a\u91cd\u64fe\u52d5\u4e0b\u7684\u4e0d\u7a69\u5b9a\u7d50\u679c\u3002\u800c\u8cc7\u6599\u683c\u5f0f bfloat16 \u548c float16 \u4e4b\u9593\u7684\u5fae\u5c0f\u932f\u8aa4\u53ef\u80fd\u6703\u5c0e\u81f4\u622a\u7136\u4e0d\u540c\u7684\u7d50\u679c\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u7a2e\u4e0d\u7a69\u5b9a\u6027\uff0c\u6211\u5011\u5229\u7528\u6700\u4f73\u5316\u5206\u6790\u4e26\u63d0\u51fa\u4e86\u4e00\u7a2e LLM \u7d50\u69cb\u526a\u679d\u65b9\u6cd5\uff0c\u7a31\u70ba MoreauPruner\uff0c\u5b83\u5177\u6709\u53ef\u8b49\u660e\u5c0d\u6297\u6b0a\u91cd\u64fe\u52d5\u7684\u7a69\u5065\u6027\u3002\u5728 MoreauPruner \u4e2d\uff0c\u6a21\u578b\u6b0a\u91cd\u91cd\u8981\u6027\u662f\u6839\u64da\u795e\u7d93\u7db2\u8def\u7684 Moreau \u51fd\u6578\u4f30\u8a08\u7684\uff0c\u5b83\u53ef\u4ee5\u9748\u6d3b\u5730\u8207 $\\ell_1$-norm \u6b63\u5247\u5316\u6280\u8853\u76f8\u7d50\u5408\uff0c\u4ee5\u8a98\u5c0e\u526a\u679d\u4efb\u52d9\u4e2d\u6240\u9700\u7684\u7a00\u758f\u6027\u3002\u6211\u5011\u5728\u5e7e\u500b\u8457\u540d\u7684 LLM \u4e0a\u5ee3\u6cdb\u8a55\u4f30\u4e86 MoreauPruner \u6f14\u7b97\u6cd5\uff0c\u5305\u62ec LLaMA-7B\u3001LLaMA-13B\u3001LLaMA3-8B \u548c Vicuna-7B\u3002\u6211\u5011\u7684\u6578\u503c\u7d50\u679c\u8868\u660e MoreauPruner \u5c0d\u6297\u6b0a\u91cd\u64fe\u52d5\u7684\u7a69\u5065\u6027\uff0c\u4e26\u8868\u660e MoreauPruner \u5728\u8207\u73fe\u6709\u5e7e\u7a2e\u526a\u679d\u65b9\u6cd5\u7684\u6bd4\u8f03\u4e2d\u7372\u5f97\u4e86\u6210\u529f\u7684\u57fa\u65bc\u6e96\u78ba\u6027\u7684\u8a55\u5206\u3002\u6211\u5011\u5df2\u5728\\url{https://github.com/ShiningSord/MoreauPruner}\u91cb\u51fa\u7a0b\u5f0f\u78bc\u3002</paragraph>", "author": "Zixiao Wang et.al.", "authors": "Zixiao Wang, Jingwei Zhang, Wenqian Zhao, Farzan Farnia, Bei Yu", "id": "2406.07017v1", "paper_url": "http://arxiv.org/abs/2406.07017v1", "repo": "https://github.com/shiningsord/moreaupruner"}}