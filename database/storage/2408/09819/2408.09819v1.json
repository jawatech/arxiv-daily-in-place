{"2408.09819": {"publish_time": "2024-08-19", "title": "CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language Models", "paper_summary": "What a large language model (LLM) would respond in ethically relevant\ncontext? In this paper, we curate a large benchmark CMoralEval for morality\nevaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a\nChinese TV program discussing Chinese moral norms with stories from the society\nand 2) a collection of Chinese moral anomies from various newspapers and\nacademic papers on morality. With these sources, we aim to create a moral\nevaluation dataset characterized by diversity and authenticity. We develop a\nmorality taxonomy and a set of fundamental moral principles that are not only\nrooted in traditional Chinese culture but also consistent with contemporary\nsocietal norms. To facilitate efficient construction and annotation of\ninstances in CMoralEval, we establish a platform with AI-assisted instance\ngeneration to streamline the annotation process. These help us curate\nCMoralEval that encompasses both explicit moral scenarios (14,964 instances)\nand moral dilemma scenarios (15,424 instances), each with instances from\ndifferent data sources. We conduct extensive experiments with CMoralEval to\nexamine a variety of Chinese LLMs. Experiment results demonstrate that\nCMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly\navailable at \\url{https://github.com/tjunlp-lab/CMoralEval}.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u9053\u5fb7\u76f8\u95dc\u7684\u8a9e\u5883\u4e2d\u6703\u5982\u4f55\u56de\u61c9\uff1f\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7b56\u5283\u4e86\u4e00\u500b\u5927\u578b\u57fa\u6e96 CMoralEval\uff0c\u7528\u65bc\u8a55\u4f30\u4e2d\u6587 LLM \u7684\u9053\u5fb7\u6a19\u6e96\u3002CMoralEval \u7684\u6578\u64da\u4f86\u6e90\u6709\u5169\u500b\uff1a1) \u4e00\u500b\u8a0e\u8ad6\u4e2d\u570b\u793e\u6703\u9053\u5fb7\u898f\u7bc4\u7684\u4e2d\u6587\u96fb\u8996\u7bc0\u76ee\uff0c\u4ee5\u53ca 2) \u4e00\u4e9b\u4f86\u81ea\u5404\u7a2e\u5831\u7d19\u548c\u9053\u5fb7\u5b78\u8853\u8ad6\u6587\u7684\u4e2d\u6587\u9053\u5fb7\u898f\u7bc4\u7570\u5e38\u73fe\u8c61\u3002\u6709\u4e86\u9019\u4e9b\u4f86\u6e90\uff0c\u6211\u5011\u5e0c\u671b\u5275\u5efa\u4e00\u500b\u4ee5\u591a\u6a23\u6027\u548c\u771f\u5be6\u6027\u70ba\u7279\u5fb5\u7684\u9053\u5fb7\u8a55\u4f30\u6578\u64da\u96c6\u3002\u6211\u5011\u5236\u5b9a\u4e86\u4e00\u500b\u9053\u5fb7\u5206\u985e\u6cd5\u548c\u4e00\u5957\u57fa\u672c\u9053\u5fb7\u539f\u5247\uff0c\u9019\u4e9b\u539f\u5247\u4e0d\u50c5\u6839\u690d\u65bc\u50b3\u7d71\u7684\u4e2d\u570b\u6587\u5316\uff0c\u800c\u4e14\u8207\u7576\u4ee3\u793e\u6703\u898f\u7bc4\u4e00\u81f4\u3002\u70ba\u4e86\u4fc3\u9032 CMoralEval \u4e2d\u5be6\u4f8b\u7684\u9ad8\u6548\u69cb\u5efa\u548c\u8a3b\u89e3\uff0c\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b\u5177\u6709 AI \u8f14\u52a9\u5be6\u4f8b\u751f\u6210\u529f\u80fd\u7684\u5e73\u53f0\uff0c\u4ee5\u7c21\u5316\u8a3b\u89e3\u904e\u7a0b\u3002\u9019\u4e9b\u5e6b\u52a9\u6211\u5011\u7b56\u5283\u4e86 CMoralEval\uff0c\u5176\u4e2d\u65e2\u5305\u542b\u660e\u78ba\u7684\u9053\u5fb7\u5834\u666f\uff0814,964 \u500b\u5be6\u4f8b\uff09\uff0c\u53c8\u5305\u542b\u9053\u5fb7\u56f0\u5883\u5834\u666f\uff0815,424 \u500b\u5be6\u4f8b\uff09\uff0c\u6bcf\u500b\u5be6\u4f8b\u90fd\u4f86\u81ea\u4e0d\u540c\u7684\u6578\u64da\u6e90\u3002\u6211\u5011\u4f7f\u7528 CMoralEval \u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4ee5\u6aa2\u9a57\u5404\u7a2e\u4e2d\u6587 LLM\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cCMoralEval \u662f\u4e2d\u6587 LLM \u7684\u4e00\u500b\u5177\u6709\u6311\u6230\u6027\u7684\u57fa\u6e96\u3002\u8a72\u6578\u64da\u96c6\u53ef\u5728 \\url{https://github.com/tjunlp-lab/CMoralEval} \u516c\u958b\u7372\u5f97\u3002", "author": "Linhao Yu et.al.", "authors": "Linhao Yu, Yongqi Leng, Yufei Huang, Shang Wu, Haixin Liu, Xinmeng Ji, Jiahui Zhao, Jinwang Song, Tingting Cui, Xiaoqing Cheng, Tao Liu, Deyi Xiong", "id": "2408.09819v1", "paper_url": "http://arxiv.org/abs/2408.09819v1", "repo": "null"}}