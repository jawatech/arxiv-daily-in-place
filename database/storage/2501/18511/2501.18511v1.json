{"2501.18511": {"publish_time": "2025-01-30", "title": "WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training", "paper_summary": "Language model (LLM) post-training, from DPO to distillation, can refine\nbehaviors and unlock new skills, but the open science supporting these\npost-training techniques is still in its infancy. One limiting factor has been\nthe difficulty of conducting large-scale comparative analyses of synthetic data\ngenerating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,\nthe largest public chat dataset to date. We extend the existing WildChat\ndataset to include responses not only from GPT, but from over 50 different\nopen-weight models, ranging in size from 0.5B to 104B parameters. We conduct an\nextensive comparative analysis and demonstrate the potential of this dataset by\ncreating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3\nSFT mixture from Allen AI with only 40% as many samples. Our dataset, samples\nand code are available at https://github.com/penfever/wildchat-50m.", "paper_summary_zh": "\u8a9e\u8a00\u6a21\u578b (LLM) \u5f8c\u8a13\u7df4\uff0c\u5f9e DPO \u5230\u84b8\u993e\uff0c\u53ef\u4ee5\u6539\u5584\u884c\u70ba\u4e26\u89e3\u9396\u65b0\u6280\u80fd\uff0c\u4f46\u652f\u63f4\u9019\u4e9b\u5f8c\u8a13\u7df4\u6280\u8853\u7684\u958b\u653e\u79d1\u5b78\u4ecd\u8655\u65bc\u8d77\u6b65\u968e\u6bb5\u3002\u4e00\u500b\u9650\u5236\u56e0\u7d20\u662f\u96e3\u4ee5\u5c0d\u5408\u6210\u8cc7\u6599\u7522\u751f\u6a21\u578b\u548c LLM \u8a55\u5be9\u9032\u884c\u5927\u898f\u6a21\u6bd4\u8f03\u5206\u6790\u3002\u70ba\u4e86\u7e2e\u5c0f\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 WILDCHAT-50M\uff0c\u9019\u662f\u8fc4\u4eca\u70ba\u6b62\u6700\u5927\u7684\u516c\u958b\u804a\u5929\u8cc7\u6599\u96c6\u3002\u6211\u5011\u64f4\u5145\u73fe\u6709\u7684 WildChat \u8cc7\u6599\u96c6\uff0c\u4e0d\u50c5\u5305\u542b\u4f86\u81ea GPT \u7684\u56de\u61c9\uff0c\u9084\u5305\u542b\u4f86\u81ea 50 \u591a\u7a2e\u4e0d\u540c\u7684\u958b\u653e\u6b0a\u91cd\u6a21\u578b\u7684\u56de\u61c9\uff0c\u898f\u6a21\u5f9e 0.5B \u5230 104B \u53c3\u6578\u4e0d\u7b49\u3002\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u6bd4\u8f03\u5206\u6790\uff0c\u4e26\u900f\u904e\u5efa\u7acb\u6211\u5011\u81ea\u5df1\u7684\u516c\u958b SFT \u6df7\u5408 RE-WILD \u4f86\u5c55\u793a\u6b64\u8cc7\u6599\u96c6\u7684\u6f5b\u529b\uff0c\u5b83\u4ee5\u50c5 40% \u7684\u6a23\u672c\u6578\u91cf\u5c31\u512a\u65bc Allen AI \u6700\u8fd1\u7684 Tulu-3 SFT \u6df7\u5408\u3002\u6211\u5011\u7684\u8cc7\u6599\u96c6\u3001\u7bc4\u4f8b\u548c\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/penfever/wildchat-50m \u53d6\u5f97\u3002", "author": "Benjamin Feuer et.al.", "authors": "Benjamin Feuer, Chinmay Hegde", "id": "2501.18511v1", "paper_url": "http://arxiv.org/abs/2501.18511v1", "repo": "https://github.com/penfever/wildchat-50m"}}