# arxiv-daily
 Automated deployment @ 2025-02-04 20:29:18 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-27**|**An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**|Shaheer Ahmad Khan et.al.|[2501.15969v1](http://arxiv.org/abs/2501.15969v1)|null|
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-19**|**Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**|Mohaiminul Islam Bhuiyan et.al.|[2501.11094v1](http://arxiv.org/abs/2501.11094v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-12**|**MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**|Sadia Kamal et.al.|[2501.06887v1](http://arxiv.org/abs/2501.06887v1)|null|
|**2025-01-06**|**Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**|Mary Ogbuka Kenneth et.al.|[2501.02891v1](http://arxiv.org/abs/2501.02891v1)|null|
|**2024-12-28**|**The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**|Alessandro De Grandi et.al.|[2412.20068v1](http://arxiv.org/abs/2412.20068v1)|null|
|**2024-12-27**|**A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**|Jana Zakall et.al.|[2412.19688v1](http://arxiv.org/abs/2412.19688v1)|null|
|**2024-12-23**|**Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**|Badaru I. Olumuyiwa et.al.|[2412.17527v1](http://arxiv.org/abs/2412.17527v1)|null|
|**2024-12-20**|**Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**|Hasan Md Tusfiqur Alam et.al.|[2412.16086v2](http://arxiv.org/abs/2412.16086v2)|[link](https://github.com/tifat58/irr-with-cbm-rag)|
|**2024-12-20**|**Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**|Shamus Sim et.al.|[2412.15748v1](http://arxiv.org/abs/2412.15748v1)|null|
|**2024-12-18**|**Cognition Chain for Explainable Psychological Stress Detection on Social Media**|Xin Wang et.al.|[2412.14009v1](http://arxiv.org/abs/2412.14009v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v2](http://arxiv.org/abs/2411.17645v2)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v2](http://arxiv.org/abs/2410.01855v2)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-13**|**Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**|Mercy Asiedu et.al.|[2409.09201v3](http://arxiv.org/abs/2409.09201v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v2](http://arxiv.org/abs/2406.06728v2)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v2](http://arxiv.org/abs/2405.02334v2)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|

#### Abstracts
##### **An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**
2501.15969v1 by Shaheer Ahmad Khan, Muhammad Usamah Shahid, Ahmad Abdullah, Ibrahim Hashmat, Muddassar Farooq

This study addresses a critical gap in the healthcare system by developing a
clinically meaningful, practical, and explainable disease surveillance system
for multiple chronic diseases, utilizing routine EHR data from multiple U.S.
practices integrated with CureMD's EMR/EHR system. Unlike traditional
systems--using AI models that rely on features from patients' labs--our
approach focuses on routinely available data, such as medical history, vitals,
diagnoses, and medications, to preemptively assess the risks of chronic
diseases in the next year. We trained three distinct models for each chronic
disease: prediction models that forecast the risk of a disease 3, 6, and 12
months before a potential diagnosis. We developed Random Forest models, which
were internally validated using F1 scores and AUROC as performance metrics and
further evaluated by a panel of expert physicians for clinical relevance based
on inferences grounded in medical knowledge. Additionally, we discuss our
implementation of integrating these models into a practical EMR system. Beyond
using Shapley attributes and surrogate models for explainability, we also
introduce a new rule-engineering framework to enhance the intrinsic
explainability of Random Forests.

摘要：本研究透過開發一個臨床有意義、實用且可解釋的多重慢性疾病疾病監測系統，來解決醫療保健系統中的重大缺口，利用整合 CureMD 的 EMR/EHR 系統，來自多個美國實務的例行 EHR 資料。與傳統系統不同的是，我們的做法著重在例行可得的資料，例如病歷、生命徵象、診斷和藥物，以預先評估未來一年慢性疾病的風險，而非仰賴病患實驗室特徵的 AI 模型。我們針對每種慢性疾病訓練了三個不同的模型：預測模型，用以預測在潛在診斷前 3、6 和 12 個月的疾病風險。我們開發了隨機森林模型，並使用 F1 分數和 AUROC 作為效能指標，進行內部驗證，並進一步由專家醫師小組根據植基於醫學知識的推論，評估其臨床相關性。此外，我們討論了將這些模型整合到實用 EMR 系統中的實作方式。除了使用 Shapley 屬性和代理模型來解釋外，我們還引進了一個新的規則工程架構，以增強隨機森林的內在可解釋性。

##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

摘要：深度神经网络越来越多地用于高风险医疗应用中，尽管它们在存在虚假相关性的情况下倾向于捷径学习，这在实践中可能产生致命的后果。检测和缓解捷径行为是一项艰巨的任务，通常需要领域专家的大量标记工作。为了缓解这个问题，我们引入了一个半自动框架，用于从数据和模型的角度识别虚假行为，方法是利用可解释人工智能 (XAI) 的见解。这允许检索虚假数据点并检测对关联预测规则进行编码的模型电路。此外，我们演示了如何使用这些捷径编码进行基于 XAI 的样本和像素级数据注释，为偏差缓解方法提供有价值的信息，以消除不需要的捷径行为。我们使用跨越两种方式的四个医学数据集展示了我们框架的适用性，这些数据集具有由数据伪像引起的受控和真实世界虚假相关性。我们成功地识别并减轻了 VGG16、ResNet50 和当代 Vision Transformer 模型中的这些偏差，最终提高了它们的鲁棒性和在真实世界医疗任务中的适用性。

##### **Enhanced Suicidal Ideation Detection from Social Media Using a CNN-BiLSTM Hybrid Model**
2501.11094v1 by Mohaiminul Islam Bhuiyan, Nur Shazwani Kamarudin, Nur Hafieza Ismail

Suicidal ideation detection is crucial for preventing suicides, a leading
cause of death worldwide. Many individuals express suicidal thoughts on social
media, offering a vital opportunity for early detection through advanced
machine learning techniques. The identification of suicidal ideation in social
media text is improved by utilising a hybrid framework that integrates
Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory
(BiLSTM), enhanced with an attention mechanism. To enhance the interpretability
of the model's predictions, Explainable AI (XAI) methods are applied, with a
particular focus on SHapley Additive exPlanations (SHAP), are incorporated. At
first, the model managed to reach an accuracy of 92.81%. By applying
fine-tuning and early stopping techniques, the accuracy improved to 94.29%. The
SHAP analysis revealed key features influencing the model's predictions, such
as terms related to mental health struggles. This level of transparency boosts
the model's credibility while helping mental health professionals understand
and trust the predictions. This work highlights the potential for improving the
accuracy and interpretability of detecting suicidal tendencies, making a
valuable contribution to the progress of mental health monitoring systems. It
emphasizes the significance of blending powerful machine learning methods with
explainability to develop reliable and impactful mental health solutions.

摘要：自殺意念偵測對於預防自殺至關重要，而自殺是全球主要的死亡原因。許多人在社群媒體上表達自殺念頭，這提供了透過進階機器學習技術進行早期偵測的重要機會。透過整合卷積神經網路 (CNN) 和雙向長短期記憶 (BiLSTM) 的混合架構，並加入注意力機制，可以提升在社群媒體文字中辨識自殺意念的能力。為了加強模型預測的可解釋性，我們採用可解釋人工智慧 (XAI) 方法，特別著重於 SHapley 加法解釋 (SHAP)。一開始，模型成功達到 92.81% 的準確度。透過套用微調和早期停止技術，準確度提升至 94.29%。SHAP 分析揭露了影響模型預測的關鍵特徵，例如與心理健康困境相關的詞彙。這種透明度提升了模型的可信度，同時協助心理健康專業人員理解和信賴預測結果。這項工作突顯了提升偵測自殺傾向的準確度和可解釋性的潛力，為心理健康監控系統的進展做出寶貴的貢獻。它強調了將強大的機器學習方法與可解釋性相結合以開發可靠且有影響力的心理健康解決方案的重要性。

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, Léa Maître, Rémy Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

摘要：在流行病學中，傳統的統計方法，例如邏輯迴歸、線性迴歸和其他參數模型通常用於調查預測因子與健康結果之間的關聯。然而，非參數機器學習技術，例如深度神經網路 (DNN)，結合可解釋的 AI (XAI) 工具，為這項任務提供了新的機會。儘管這些方法具有潛力，但由於該領域缺乏高品質、高數量資料，因此這些方法面臨挑戰。為了應對這些挑戰，我們引入了 SEANN，這是一種新穎的方法，用於獲取知識的 DNN，它利用了一種流行的領域特定知識形式：彙總效應量 (PES)。PES 通常以不同的形式出現在已發表的 Meta 分析研究中，並代表科學共識的量化形式。通過使用自訂損失函數直接整合在學習程序中，我們以實驗方式證明了預測效能的概括性以及與從缺乏領域知識的神經網路中提取的關係相比，科學合理性的顯著提升，且是在稀少且有雜訊的資料設定中。

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

摘要：隨著人工智慧 (AI) 在醫療保健中的應用日益普及，本章探討了開發可靠且符合道德標準的臨床決策支援系統 (CDSS) 的關鍵面向。從傳統統計模型到複雜機器學習方法的基本轉變開始，這項工作審查了嚴謹的驗證策略和效能評估方法，包括模型校準和決策曲線分析的關鍵角色。本章強調，在醫療保健中建立值得信賴的 AI 系統不只是技術上的準確性；它需要仔細考量公平性、可解釋性和隱私權。本章強調了透過 AI 確保公平的醫療保健服務的挑戰，並討論了識別和減輕臨床預測模型中偏差的方法。接著，本章深入探討可解釋性，作為以人為中心的 CDSS 的基石。這種關注反映了醫療保健專業人員不僅必須信任 AI 建議，還必須理解其背後的推理。討論進一步分析了醫療 AI 系統中的隱私漏洞，從深度學習模型中的資料外洩到針對模型解釋的複雜攻擊。本文探討了隱私保護策略，例如差分隱私和聯合學習，同時承認隱私保護和模型效能之間的固有取捨。這種從技術驗證到道德考量的進展，反映了開發 AI 系統的多面向挑戰，這些系統可以無縫且可靠地整合到日常臨床實務中，同時維持最高的病患照護和資料保護標準。

##### **MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis**
2501.06887v1 by Sadia Kamal, Tim Oates

As deep learning models gain attraction in medical data, ensuring transparent
and trustworthy decision-making is essential. In skin cancer diagnosis, while
advancements in lesion detection and classification have improved accuracy, the
black-box nature of these methods poses challenges in understanding their
decision processes, leading to trust issues among physicians. This study
leverages the CLIP (Contrastive Language-Image Pretraining) model, trained on
different skin lesion datasets, to capture meaningful relationships between
visual features and diagnostic criteria terms. To further enhance transparency,
we propose a method called MedGrad E-CLIP, which builds on gradient-based
E-CLIP by incorporating a weighted entropy mechanism designed for complex
medical imaging like skin lesions. This approach highlights critical image
regions linked to specific diagnostic descriptions. The developed integrated
pipeline not only classifies skin lesions by matching corresponding
descriptions but also adds an essential layer of explainability developed
especially for medical data. By visually explaining how different features in
an image relates to diagnostic criteria, this approach demonstrates the
potential of advanced vision-language models in medical image analysis,
ultimately improving transparency, robustness, and trust in AI-driven
diagnostic systems.

摘要：随着深度学习模型在医学数据中获得关注，确保透明且值得信赖的决策至关重要。在皮肤癌诊断中，虽然病灶检测和分类的进步提高了准确性，但这些方法的黑盒性质对理解其决策过程构成了挑战，导致医生之间的信任问题。本研究利用在不同皮肤病变数据集上训练的 CLIP（对比语言图像预训练）模型，以捕捉视觉特征和诊断标准术语之间的有意义关系。为了进一步提高透明度，我们提出了一种名为 MedGrad E-CLIP 的方法，该方法通过结合专为皮肤病变等复杂医学影像设计的加权熵机制，建立在基于梯度的 E-CLIP 之上。此方法突出了与特定诊断描述相关联的关键图像区域。开发的集成管道不仅通过匹配相应的描述对皮肤病变进行分类，还添加了一层专门为医学数据开发的基本可解释性。通过直观地解释图像中不同特征与诊断标准的关系，这种方法展示了高级视觉语言模型在医学图像分析中的潜力，最终提高了透明度、稳健性和对人工智能驱动的诊断系统的信任。

##### **Explaining Humour Style Classifications: An XAI Approach to Understanding Computational Humour Analysis**
2501.02891v1 by Mary Ogbuka Kenneth, Foaad Khosmood, Abbas Edalat

Humour styles can have either a negative or a positive impact on well-being.
Given the importance of these styles to mental health, significant research has
been conducted on their automatic identification. However, the automated
machine learning models used for this purpose are black boxes, making their
prediction decisions opaque. Clarity and transparency are vital in the field of
mental health. This paper presents an explainable AI (XAI) framework for
understanding humour style classification, building upon previous work in
computational humour analysis. Using the best-performing single model
(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to
analyse how linguistic, emotional, and semantic features contribute to humour
style classification decisions. Our analysis reveals distinct patterns in how
different humour styles are characterised and misclassified, with particular
emphasis on the challenges in distinguishing affiliative humour from other
styles. Through detailed examination of feature importance, error patterns, and
misclassification cases, we identify key factors influencing model decisions,
including emotional ambiguity, context misinterpretation, and target
identification. The framework demonstrates significant utility in understanding
model behaviour, achieving interpretable insights into the complex interplay of
features that define different humour styles. Our findings contribute to both
the theoretical understanding of computational humour analysis and practical
applications in mental health, content moderation, and digital humanities
research.

摘要：幽默風格對幸福感可能產生負面或正面的影響。
鑑於這些風格對心理健康的重要性，已經對其自動識別進行了大量研究。然而，用於此目的的自動機器學習模型是黑盒子，使得其預測決策不透明。清晰度和透明度在心理健康領域至關重要。本文提出了一個可解釋的 AI (XAI) 框架，用於理解幽默風格分類，建立在計算幽默分析的先前工作之上。使用先前研究中表現最好的單一模型 (ALI+XGBoost)，我們應用全面的 XAI 技術來分析語言、情緒和語義特徵如何影響幽默風格分類決策。我們的分析揭示了不同幽默風格如何被表徵和錯誤分類的不同模式，特別強調了區分聯屬幽默與其他風格的挑戰。通過仔細檢查特徵重要性、錯誤模式和錯誤分類案例，我們確定了影響模型決策的關鍵因素，包括情緒模糊、情境誤解和目標識別。該框架展示了在理解模型行為方面的顯著效用，實現了對定義不同幽默風格的特徵之間複雜相互作用的可解釋見解。我們的發現有助於計算幽默分析的理論理解和心理健康、內容審核和數字人文研究中的實際應用。

##### **The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support**
2412.20068v1 by Alessandro De Grandi, Federico Ravenda, Andrea Raballo, Fabio Crestani

The increasing demand for mental health services has highlighted the need for
innovative solutions, particularly in the realm of psychological conversational
AI, where the availability of sensitive data is scarce. In this work, we
explored the development of a system tailored for mental health support with a
novel approach to psychological assessment based on explainable emotional
profiles in combination with empathetic conversational models, offering a
promising tool for augmenting traditional care, particularly where immediate
expertise is unavailable. Our work can be divided into two main parts,
intrinsecaly connected to each other. First, we present RACLETTE, a
conversational system that demonstrates superior emotional accuracy compared to
state-of-the-art benchmarks in both understanding users' emotional states and
generating empathetic responses during conversations, while progressively
building an emotional profile of the user through their interactions. Second,
we show how the emotional profiles of a user can be used as interpretable
markers for mental health assessment. These profiles can be compared with
characteristic emotional patterns associated with different mental disorders,
providing a novel approach to preliminary screening and support.

摘要：隨著對心理健康服務需求的增加，凸顯了創新解決方案的需求，特別是在心理對話式人工智慧領域，那裡缺乏敏感資料。在這項工作中，我們探索了開發一個針對心理健康支持的系統，採用一種基於可解釋的情緒特徵的新方法進行心理評估，結合同理心對話模式，提供了一個有前途的工具，用於擴充傳統照護，特別是在無法立即獲得專業知識的情況下。我們的工作可以分為兩個主要部分，彼此內在相關。首先，我們展示了 RACLETTE，一個對話系統，與最先進的基準相比，在理解使用者情緒狀態和在對話中產生同理心回應方面表現出優越的情緒準確性，同時透過他們的互動逐漸建立使用者的情緒特徵。其次，我們展示了使用者的情緒特徵如何可用作心理健康評估的可解釋標記。這些特徵可以與與不同心理疾病相關的典型情緒模式進行比較，提供了一種初步篩選和支持的新方法。

##### **A Review on the Integration of Artificial Intelligence and Medical Imaging in IVF Ovarian Stimulation**
2412.19688v1 by Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia

Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.

摘要：人工智慧（AI）已成為增強體外受精（IVF）決策制定和優化治療方案的強大工具。特別是，AI 在支持 IVF 過程中卵巢刺激階段的決策制定方面顯示出顯著的前景。本綜述評估了專注於 AI 結合卵巢刺激中的醫學影像應用、檢驗方法、結果和當前限制的研究。我們對 13 項關於此主題的研究分析顯示，雖然 AI 演算法在預測最佳荷爾蒙劑量、觸發時機和卵子取出結果方面表現出顯著的潛力，但所利用的醫學影像數據主要來自於二次元（2D）超音波，而二次元超音波主要涉及基本量化，例如濾泡大小和數量，且有限使用直接特徵提取或進階影像分析技術。這指向一個尚未探索的機會，例如深度學習等進階影像分析方法，以及更多元的影像模式，例如三維（3D）超音波，可以解鎖更深入的見解。此外，大多數研究缺乏可解釋 AI（XAI），這引起了人們對 AI 驅動決策的透明度和可追溯性的擔憂，而透明度和可追溯性是臨床採用和信任的關鍵因素。此外，許多研究依賴於單中心設計和小型數據集，這限制了其發現的普遍性。本綜述強調了將進階影像分析技術與可解釋 AI 方法整合起來的必要性，以及利用多中心合作和大型數據集的重要性。解決這些差距有可能增強卵巢刺激管理，為有效、個人化和數據驅動的治療途徑鋪平道路，進而改善 IVF 結果。

##### **Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models**
2412.17527v1 by Badaru I. Olumuyiwa, The Anh Han, Zia U. Shamszaman

This research presents an innovative approach to cancer diagnosis and
prediction using explainable Artificial Intelligence (XAI) and deep learning
techniques. With cancer causing nearly 10 million deaths globally in 2020,
early and accurate diagnosis is crucial. Traditional methods often face
challenges in cost, accuracy, and efficiency. Our study develops an AI model
that provides precise outcomes and clear insights into its decision-making
process, addressing the "black box" problem of deep learning models. By
employing XAI techniques, we enhance interpretability and transparency,
building trust among healthcare professionals and patients. Our approach
leverages neural networks to analyse extensive datasets, identifying patterns
for cancer detection. This model has the potential to revolutionise diagnosis
by improving accuracy, accessibility, and clarity in medical decision-making,
possibly leading to earlier detection and more personalised treatment
strategies. Furthermore, it could democratise access to high-quality
diagnostics, particularly in resource-limited settings, contributing to global
health equity. The model's applications extend beyond cancer diagnosis,
potentially transforming various aspects of medical decision-making and saving
millions of lives worldwide.

摘要：本研究提出了一個創新的癌症診斷和預測方法，使用可解釋的人工智慧 (XAI) 和深度學習技術。由於癌症在 2020 年造成全球近 1,000 萬人死亡，因此早期準確的診斷至關重要。傳統方法通常面臨成本、準確性和效率方面的挑戰。我們的研究開發了一個 AI 模型，它提供精確的結果並清楚地了解其決策過程，解決了深度學習模型的「黑箱」問題。通過採用 XAI 技術，我們增強了解釋性和透明度，在醫療專業人員和患者之間建立信任。我們的做法利用神經網路分析廣泛的數據集，識別癌症檢測模式。這個模型有可能通過提高醫療決策的準確性、可及性和清晰度來革新診斷，可能導致更早的檢測和更個性化的治療策略。此外，它可以使更多人獲得高品質的診斷，特別是在資源有限的環境中，有助於全球健康公平。該模型的應用範圍不僅限於癌症診斷，還可能轉變醫療決策的各個方面，並拯救全球數百萬人的生命。

##### **Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG**
2412.16086v2 by Hasan Md Tusfiqur Alam, Devansh Srivastav, Md Abdul Kadir, Daniel Sonntag

Deep learning has advanced medical image classification, but interpretability
challenges hinder its clinical adoption. This study enhances interpretability
in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)
and a multi-agent Retrieval-Augmented Generation (RAG) system for report
generation. By modeling relationships between visual features and clinical
concepts, we create interpretable concept vectors that guide a multi-agent RAG
system to generate radiology reports, enhancing clinical relevance,
explainability, and transparency. Evaluation of the generated reports using an
LLM-as-a-judge confirmed the interpretability and clinical utility of our
model's outputs. On the COVID-QU dataset, our model achieved 81% classification
accuracy and demonstrated robust report generation performance, with five key
metrics ranging between 84% and 90%. This interpretable multi-agent framework
bridges the gap between high-performance AI and the explainability required for
reliable AI-driven CXR analysis in clinical settings. Our code is available at
https://github.com/tifat58/IRR-with-CBM-RAG.git.

摘要：深度學習已提升醫學影像分類，但可解釋性挑戰阻礙其臨床應用。本研究透過使用概念瓶頸模型 (CBM) 和多代理檢索增強生成 (RAG) 系統進行報告生成，來增強胸部 X 光 (CXR) 分類的可解釋性。透過建模視覺特徵與臨床概念之間的關係，我們建立可解釋的概念向量，引導多代理 RAG 系統生成放射報告，增強臨床相關性、可解釋性和透明度。使用 LLM 作為評審員對生成報告進行評估，確認了我們模型輸出的可解釋性和臨床效用。在 COVID-QU 資料集上，我們的模型達到了 81% 的分類準確率，並展示了穩健的報告生成效能，五項關鍵指標介於 84% 至 90% 之間。這個可解釋的多代理架構彌合了高性能 AI 與臨床環境中可靠的 AI 驅動 CXR 分析所需的解釋性之間的差距。我們的程式碼可於 https://github.com/tifat58/IRR-with-CBM-RAG.git 取得。

##### **Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models**
2412.15748v1 by Shamus Sim, Tyrone Chen

Background: Despite the current ubiquity of Large Language Models (LLMs)
across the medical domain, there is a surprising lack of studies which address
their reasoning behaviour. We emphasise the importance of understanding
reasoning behaviour as opposed to high-level prediction accuracies, since it is
equivalent to explainable AI (XAI) in this context. In particular, achieving
XAI in medical LLMs used in the clinical domain will have a significant impact
across the healthcare sector. Results: Therefore, we define the concept of
reasoning behaviour in the specific context of medical LLMs. We then categorise
and discuss the current state of the art of methods which evaluate reasoning
behaviour in medical LLMs. Finally, we propose theoretical frameworks which can
empower medical professionals or machine learning engineers to gain insight
into the low-level reasoning operations of these previously obscure models.
Conclusion: The subsequent increased transparency and trust in medical machine
learning models by clinicians as well as patients will accelerate the
integration, application as well as further development of medical AI for the
healthcare system as a whole

摘要：背景：儘管大型語言模型 (LLM) 目前在醫療領域無所不在，但令人驚訝的是，探討其推理行為的研究卻相當缺乏。我們強調了解推理行為而非高層級的預測準確度非常重要，因為在這種情況下，這等同於可解釋 AI (XAI)。尤其是在臨床領域中使用的醫療 LLM 中實現 XAI，將對整個醫療保健產業產生重大影響。結果：因此，我們在醫療 LLM 的特定背景下定義了推理行為的概念。接著我們分類並探討當前評估醫療 LLM 中推理行為的方法的最新技術。最後，我們提出理論架構，讓醫療專業人員或機器學習工程師得以深入了解這些先前模糊模型的低層級推理運算。結論：臨床醫生和患者對醫療機器學習模型的透明度和信任度隨之提升，將加速醫療 AI 在整個醫療保健系統中的整合、應用和進一步發展。

##### **Cognition Chain for Explainable Psychological Stress Detection on Social Media**
2412.14009v1 by Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton

Stress is a pervasive global health issue that can lead to severe mental
health problems. Early detection offers timely intervention and prevention of
stress-related disorders. The current early detection models perform "black
box" inference suffering from limited explainability and trust which blocks the
real-world clinical application. Thanks to the generative properties introduced
by the Large Language Models (LLMs), the decision and the prediction from such
models are semi-interpretable through the corresponding description. However,
the existing LLMs are mostly trained for general purposes without the guidance
of psychological cognitive theory. To this end, we first highlight the
importance of prior theory with the observation of performance boosted by the
chain-of-thoughts tailored for stress detection. This method termed Cognition
Chain explicates the generation of stress through a step-by-step cognitive
perspective based on cognitive appraisal theory with a progress pipeline:
Stimulus $\rightarrow$ Evaluation $\rightarrow$ Reaction $\rightarrow$ Stress
State, guiding LLMs to provide comprehensive reasoning explanations. We further
study the benefits brought by the proposed Cognition Chain format by utilising
it as a synthetic dataset generation template for LLMs instruction-tuning and
introduce CogInstruct, an instruction-tuning dataset for stress detection. This
dataset is developed using a three-stage self-reflective annotation pipeline
that enables LLMs to autonomously generate and refine instructional data. By
instruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable
stress detection model. Evaluations demonstrate that CogLLM achieves
outstanding performance while enhancing explainability. Our work contributes a
novel approach by integrating cognitive theories into LLM reasoning processes,
offering a promising direction for future explainable AI research.

摘要：壓力是一個普遍的全球性健康問題，可能會導致嚴重的精神
健康問題。早期發現提供及時的干預和預防
壓力相關疾病。目前的早期發現模型執行「黑
盒子」推論，存在可解釋性和信任度有限的問題，阻礙了
現實世界的臨床應用。多虧了大型語言模型 (LLM) 引入的生成屬性，此類
模型的決策和預測通過對應描述具有半可解釋性。然而，
現有的 LLM 主要針對一般用途進行訓練，沒有心理認知理論的指導。為此，我們首先強調
先驗理論的重要性，並觀察到針對壓力檢測量身定制的思想鏈提升了性能。這種方法稱為認知
鏈通過基於認知評估理論的循序漸進的認知視角闡明了壓力的產生，並具有進度管道：
刺激 $\rightarrow$ 評估 $\rightarrow$ 反應 $\rightarrow$ 壓力
狀態，指導 LLM 提供全面的推理解釋。我們進一步
通過將其用作 LLM 指令調整的合成數據集生成模板來研究所提出的認知鏈格式帶來的優點，並介紹 CogInstruct，這是一個針對壓力檢測的指令調整數據集。這個
數據集是使用一個三階段的自省標註管道開發的，使 LLM 能夠自主生成和優化指令數據。通過
使用 CogInstruct 對 Llama3 進行指令調整，我們開發了 CogLLM，這是一個可解釋的
壓力檢測模型。評估表明，CogLLM 在提高可解釋性的同時實現了出色的性能。我們的研究通過將認知理論整合到 LLM 推理過程中，提出了一種新穎的方法，
為未來的可解釋人工智能研究提供了一個有希望的方向。

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v2 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
challenges due to data heterogeneity, sparsity, temporal misalignment, and
limited labeled outcomes. In this context, we leverage a linked EHR dataset of
approximately one million de-identified individuals from Bristol, North
Somerset, and South Gloucestershire, UK, to characterize urinary tract
infections (UTIs). We implemented a data pre-processing and curation pipeline
that transforms the raw EHR data into a structured format suitable for
developing predictive models focused on data fairness, accountability and
transparency. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Pairwise
XGBoost models are trained using this framework to differentiate UTI risk
categories with explainable AI techniques applied to identify key predictors
and support interpretability. Our findings reveal differences in clinical and
demographic predictors across risk groups. While this study highlights the
potential of AI-driven insights to support UTI clinical decision-making,
further investigation of patient sub-strata and extensive validation are needed
to ensure robustness and applicability in clinical practice.

摘要：電子健康紀錄 (EHR) 中機器學習和 AI 的使用對於臨床見解具有相當大的潛力。然而，由於資料異質性、稀疏性、時間錯位和標籤結果有限，此方法面臨挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特和南格洛斯特郡約一百萬名去識別個人連結的 EHR 資料集，來描述尿路感染 (UTI)。我們實施了將原始 EHR 資料轉換為結構化格式的資料前處理和整理管線，適合開發專注於資料公平性、問責制和透明度的預測模型。鑑於 UTI 真實結果的可用性有限和偏差，我們引入了由臨床專業知識告知的 UTI 風險評估架構，以估計個別患者時間軸上的 UTI 風險。成對的 XGBoost 模型使用此架構進行訓練，以區分 UTI 風險類別，並應用可解釋的 AI 技術來識別關鍵預測因子並支持可解釋性。我們的研究結果揭示了不同風險群組在臨床和人口統計預測因子上的差異。雖然這項研究強調了 AI 驅動見解在支援 UTI 臨床決策制定方面的潛力，但仍需要進一步調查患者子群體和廣泛驗證，以確保在臨床實務中的穩健性和適用性。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折的風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動能力至關重要。然而，醫療保健提供者面臨著標記數據有限和處理醫學影像困難等挑戰。本研究提出了一個新穎的多模式學習框架，該框架整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練的網路，VGG19、InceptionV3 和 ResNet50，從 X 射線影像中提取深度特徵。這些特徵使用 PCA 轉換以降低維度並專注於最相關的組成部分。基於聚類的選擇過程識別出最具代表性的組成部分，然後將這些組成部分與預處理的臨床數據結合，並通過全連接網路 (FCN) 進行最終分類。特徵重要性圖突出了關鍵變數，表明病史、BMI 和身高是主要貢獻因素，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。此框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷在臨床整合中的信任。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

摘要：<paragraph>目的：調查臨床醫生對目前自動化心電圖解讀和新的人工智慧技術的態度，以及他們對電腦輔助解讀的看法。材料和方法：我們對英國的臨床醫生進行了一系列訪談。我們的研究：(i) 探討人工智慧的潛力，特別是未來的「類人類」運算方法，以促進心電圖解讀並支持臨床決策制定，以及 (ii) 徵求他們對人工智慧演算法的可解釋性和可信度的看法。結果：我們對 23 位臨床醫生的訪談記錄進行了歸納主題分析，並找出以下主題：(i) 對目前系統缺乏信任，(ii) 對未來人工智慧應用和對這些應用的要求持正面態度，(iii) 演算法的準確性和可解釋性之間的關係，以及 (iv) 對教育、可能的技能退化，以及人工智慧對臨床能力的影響的看法。討論：臨床醫生不信任目前的電腦化方法，但歡迎未來的「人工智慧」技術。在臨床醫生相信未來的 AI 解讀準確的情況下，他們不太擔心它是否可解釋。他們也比較喜歡能以視覺方式呈現演算法結果的心電圖解讀。雖然臨床醫生不害怕失業，但他們擔心技能退化，以及需要教育員工負責任地使用人工智慧。結論：臨床醫生對人工智慧在臨床決策制定中的未來應用持正面態度。準確性是採用人工智慧的一個關鍵因素，而視覺化比目前的電腦化方法更受青睞。這被視為一種潛在的培訓和提升技能的方法，與自動化可能帶來的技能退化形成對比。</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenmüller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Compérat, Andreas Gocht, Monika Hämmerle, Niels J. Rupp, Jula Westhoff, Irene Krücken, Maximillian Seidl, Christian M. Schürch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian Hörner, Kirsten D. Mertz, Constanze Döring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

摘要：前列腺癌是全球男性最常見的癌症，其惡性程度主要根據 Gleason 評分系統使用組織病理學數據進行評估。雖然人工智慧 (AI) 在準確預測 Gleason 評分方面已展現潛力，但這些預測通常缺乏內在的可解釋性，可能會導致對人機互動的不信任。為了解決這個問題，我們引進了一個由 54 位病理學家組成的國際團隊註解的 1,015 個組織微陣列核心影像的新穎資料集。這些註解提供了詳細的局部模式描述，用於符合國際準則的 Gleason 分級。利用這個資料集，我們開發了一個基於 U-Net 架構的內在可解釋 AI 系統，該系統提供了利用病理學家術語進行預測。這種方法規避了事後可解釋性方法，同時維持或超越了直接訓練用於 Gleason 模式分割的方法的效能（Dice 分數：0.713 ± 0.003，訓練於解釋，相對於 0.691 ± 0.010，訓練於 Gleason 模式）。透過在訓練期間採用軟標籤，我們捕捉了資料中的內在不確定性，即使在觀察者間變異性高的情況下，也能在 Gleason 模式分割中產生強大的結果。透過釋出這個資料集，我們旨在鼓勵進一步研究主觀性高的醫療任務中的分割，並增進對病理學家推理過程的理解。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v2 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的關鍵任務，及時且準確地識別醫療狀況會顯著影響患者的結果。傳統的機器學習和深度學習模型已在這個領域取得顯著成功，但通常缺乏可解釋性，這在臨床環境中是一項關鍵要求。在本研究中，我們探討了神經符號方法的應用，特別是邏輯神經網路 (LNN)，以開發用於診斷預測的可解釋模型。基本上，我們設計並實作了基於 LNN 的模型，這些模型透過具有可學習閾值的邏輯規則整合領域特定知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（例如邏輯迴歸、SVM 和隨機森林）的優異效能，在糖尿病預測的案例研究中達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習到的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不影響預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於推進精準醫療，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報資料，結合先進機器學習與深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD) 的可能性。我們分析一家大型健康保險組織提供的 10 年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長期短期記憶 (LSTM) 網路）開發多個觀察視窗的預測模型。我們的研究結果顯示，LSTM 模型（尤其是 24 個月觀察視窗）在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 可加性解釋 (SHAP) 分析以增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政申報資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**
2409.09201v3 by Mercy Asiedu, Nenad Tomasev, Chintan Ghate, Tiya Tiyasirichokchai, Awa Dieng, Oluwatosin Akande, Geoffrey Siwo, Steve Adudans, Sylvanus Aitkins, Odianosen Ehiakhamen, Eric Ndombi, Katherine Heller

While large language models (LLMs) have shown promise for medical question
answering, there is limited work focused on tropical and infectious
disease-specific exploration. We build on an opensource tropical and infectious
diseases (TRINDs) dataset, expanding it to include demographic and semantic
clinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM
performance on these, comparing generalist and medical LLMs, as well as LLM
outcomes to human experts. We demonstrate through systematic experimentation,
the benefit of contextual information such as demographics, location, gender,
risk factors for optimal LLM response. Finally we develop a prototype of
TRINDs-LM, a research tool that provides a playground to navigate how context
impacts LLM outputs for health.

摘要：儘管大型語言模型 (LLM) 在醫療問題解答方面展現出前景，但專注於熱帶和傳染病特定探索的研究有限。我們建立在一個開放原始碼熱帶和傳染病 (TRINDs) 資料集上，並將其擴展為納入人口統計和語義臨床和消費者擴充，產生超過 11000 個提示。我們評估了 LLM 在這些方面的效能，比較了通才和醫療 LLM，以及 LLM 結果與人類專家的比較。我們透過系統性實驗證明了背景資訊（例如人口統計、位置、性別、最佳 LLM 回應的風險因素）的好處。最後，我們開發了 TRINDs-LM 的原型，這是一個研究工具，提供一個探索背景如何影響 LLM 健康輸出的平台。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中已達到整體高準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知且未標籤的群體。此外，此類觀察到的效能差異的根本原因通常難以發現，阻礙了緩解措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳子集，並針對觀察到的效能差異原因制定假設。我們引入一種新的 SDM，並在胸部 X 光片中肺炎和肺不張分類的案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對廣泛使用的胸部 X 光片資料集和模型中先前觀察到但無法解釋的男性和女性患者之間的效能差異提供了解釋。我們的發現表明，在分類任務中，透過胸腔引流管和心電圖導線的存在，存在捷徑學習。這些捷徑特徵的盛行率存在基於性別的差異，似乎會導致觀察到的分類效能差距，這代表捷徑學習和模型公平性分析之間先前未受到重視的交互作用。

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v2 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad, Lamia Ashraf

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病 (CKD) 是一種廣泛的慢性疾病，目前尚未找到最終的治療方法，且發病率很高。研究表明，進行性慢性腎臟病 (CKD) 是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病演變成一種嚴重程度不一的常見疾病。本研究的目標是使用整體學習和可解釋的 AI 來視覺化支配性特徵、特徵分數和值，以進行 CKD 的早期預後和檢測。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式的修改建議，以降低此疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命徵象中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未見的 CKD 病例。我們的研究結果在與腎臟科醫師進行長時間諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多的特徵作為顯著的貢獻者。可解釋性 (I) 衡量重要特徵與被遮蔽特徵的比率，表明我們的 XgBoost 模型在此指標中取得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v2 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In recent years, machine learning-based clinical decision support systems
(CDSS) have played a key role in the analysis of several medical conditions.
Despite their promising capabilities, the lack of transparency in AI models
poses significant challenges, particularly in medical contexts where
reliability is a mandatory aspect. However, it appears that explainability is
inversely proportional to accuracy. For this reason, achieving transparency
without compromising predictive accuracy remains a key challenge. This paper
presents a novel method, namely Rad4XCNN, to enhance the predictive power of
CNN-derived features with the inherent interpretability of radiomic features.
Rad4XCNN diverges from conventional methods based on saliency maps, by
associating intelligible meaning to CNN-derived features by means of Radiomics,
offering new perspectives on explanation methods beyond visualization maps.
Using a breast cancer classification task as a case study, we evaluated
Rad4XCNN on ultrasound imaging datasets, including an online dataset and two
in-house datasets for internal and external validation. Some key results are:
i) CNN-derived features guarantee more robust accuracy when compared against
ViT-derived and radiomic features; ii) conventional visualization map methods
for explanation present several pitfalls; iii) Rad4XCNN does not sacrifice
model accuracy for their explainability; iv) Rad4XCNN provides a global
explanation enabling the physician to extract global insights and findings. Our
method can mitigate some concerns related to the explainability-accuracy
trade-off. This study highlighted the importance of proposing new methods for
model explanation without affecting their accuracy.

摘要：<paragraph>近年来，基于机器学习的临床决策支持系统 (CDSS) 在多种疾病的分析中扮演了关键角色。尽管它们具有广阔的前景，但 AI 模型缺乏透明度，尤其在医疗领域，可靠性是强制性方面，这带来了重大挑战。然而，解释性似乎与准确性成反比。因此，在不影响预测准确性的情况下实现透明度仍然是一个关键挑战。本文提出了一种新方法，即 Rad4XCNN，以通过放射组学的内在可解释性来增强 CNN 衍生特征的预测能力。Rad4XCNN 通过放射组学将可理解的含义与 CNN 衍生特征关联起来，从而偏离了基于显着性图的传统方法，为超越可视化图的解释方法提供了新的视角。使用乳腺癌分类任务作为案例研究，我们在超声成像数据集上评估了 Rad4XCNN，包括一个在线数据集和两个用于内部和外部验证的内部数据集。一些关键结果是：i) 与 ViT 衍生和放射组学特征相比，CNN 衍生特征保证了更稳健的准确性；ii) 用于解释的传统可视化图方法存在一些缺陷；iii) Rad4XCNN 不会为了可解释性而牺牲模型准确性；iv) Rad4XCNN 提供全局解释，使医生能够提取全局见解和发现。我们的方法可以减轻一些与可解释性-准确性权衡相关的担忧。本研究强调了提出新方法来解释模型而不影响其准确性的重要性。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人做出決定的 AI 系統都有一群利害關係人
受到這些決定的親身影響。然而，AI
系統的解釋很少能滿足這群利害關係人的資訊需求，而他們
通常都是 AI 新手。這造成了傳達資訊與
受到系統決策影響的人士（例如領域專家和決策主體）重視的資訊之間的落差。為了解決這個問題，我們提出了
「XAI 新手問題庫」，它是 XAI 問題庫的延伸，包含來自 AI 新手在兩個使用案例中的資訊需求目錄：就業
預測和健康監測。目錄涵蓋了資料、
系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在訪談中詢問了兩個 AI 系統的問題，以決定是否採用它們，並收到口頭
解釋作為回應。我們的分析顯示，參與者在收到解釋後信心有所提升，但他們的理解卻面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包
理解。此外，參與者對系統風險和好處的先前回饋影響了他們的資訊需求。認為風險高的參與者尋求解釋系統部署背後的意圖，而認為風險低的人則詢問系統的
操作。我們的研究旨在透過強調 AI 新手的資訊需求、目標和
挑戰，來支持將 AI 新手納入可解釋性工作中。我們將我們的研究結果總結為五個關鍵啟示，這些啟示可以為未來針對非專業利害關係人受眾的解釋設計提供參考。</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-31**|**Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**|Misha P. T Kaandorp et.al.|[2501.19338v1](http://arxiv.org/abs/2501.19338v1)|null|
|**2025-01-31**|**Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**|Halil Ibrahim Aysel et.al.|[2501.19271v1](http://arxiv.org/abs/2501.19271v1)|null|
|**2025-01-31**|**Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using Generative Artificial Intelligence**|Aurora Rofena et.al.|[2501.19176v1](http://arxiv.org/abs/2501.19176v1)|null|
|**2025-01-31**|**Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**|Xiangyu Sun et.al.|[2501.19086v1](http://arxiv.org/abs/2501.19086v1)|null|
|**2025-01-30**|**Survey and Improvement Strategies for Gene Prioritization with Large Language Models**|Matthew Neeley et.al.|[2501.18794v1](http://arxiv.org/abs/2501.18794v1)|null|
|**2025-01-30**|**Synthetic Data Generation for Augmenting Small Samples**|Dan Liu et.al.|[2501.18741v1](http://arxiv.org/abs/2501.18741v1)|null|
|**2025-01-30**|**A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series**|Yifan Wang et.al.|[2501.18367v1](http://arxiv.org/abs/2501.18367v1)|null|
|**2025-01-30**|**MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding**|Yuxin Zuo et.al.|[2501.18362v1](http://arxiv.org/abs/2501.18362v1)|null|
|**2025-01-30**|**CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized Codes**|Yicheng Wu et.al.|[2501.18328v1](http://arxiv.org/abs/2501.18328v1)|null|
|**2025-01-30**|**A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification**|Shayli Farshchiha et.al.|[2501.18294v1](http://arxiv.org/abs/2501.18294v1)|null|
|**2025-01-30**|**The iToBoS dataset: skin region images extracted from 3D total body photographs for lesion detection**|Anup Saha et.al.|[2501.18270v1](http://arxiv.org/abs/2501.18270v1)|null|
|**2025-01-30**|**Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers**|Malte Tölle et.al.|[2501.18237v1](http://arxiv.org/abs/2501.18237v1)|null|
|**2025-01-30**|**Investigating an Intelligent System to Monitor \& Explain Abnormal Activity Patterns of Older Adults**|Min Hun Lee et.al.|[2501.18108v1](http://arxiv.org/abs/2501.18108v1)|null|
|**2025-01-30**|**Normative Evaluation of Large Language Models with Everyday Moral Dilemmas**|Pratik S. Sachdeva et.al.|[2501.18081v1](http://arxiv.org/abs/2501.18081v1)|null|
|**2025-01-30**|**Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence**|Pir Bakhsh Khokhar et.al.|[2501.18071v1](http://arxiv.org/abs/2501.18071v1)|null|
|**2025-01-29**|**Current Pathology Foundation Models are unrobust to Medical Center Differences**|Edwin D. de Jong et.al.|[2501.18055v2](http://arxiv.org/abs/2501.18055v2)|null|
|**2025-01-29**|**Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**|Zijie Liu et.al.|[2501.17860v1](http://arxiv.org/abs/2501.17860v1)|null|
|**2025-01-29**|**GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**|Ziang Liu et.al.|[2501.17855v1](http://arxiv.org/abs/2501.17855v1)|null|
|**2025-01-29**|**Tonguescape: Exploring Language Models Understanding of Vowel Articulation**|Haruki Sakajo et.al.|[2501.17643v1](http://arxiv.org/abs/2501.17643v1)|[link](https://github.com/sj-h4/tonguescape-builder)|
|**2025-01-29**|**Layered Chain-of-Thought Prompting for Multi-Agent LLM Systems: A Comprehensive Approach to Explainable Large Language Models**|Manish Sanwal et.al.|[2501.18645v1](http://arxiv.org/abs/2501.18645v1)|null|
|**2025-01-29**|**An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**|Wenqi Li et.al.|[2501.17555v1](http://arxiv.org/abs/2501.17555v1)|null|
|**2025-01-29**|**LLM Assistance for Pediatric Depression**|Mariia Ignashina et.al.|[2501.17510v1](http://arxiv.org/abs/2501.17510v1)|null|
|**2025-01-28**|**Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**|Chongyu Qu et.al.|[2501.17343v1](http://arxiv.org/abs/2501.17343v1)|null|
|**2025-01-28**|**Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**|Mingyu Derek Ma et.al.|[2501.17338v1](http://arxiv.org/abs/2501.17338v1)|null|
|**2025-01-28**|**Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**|Mingyu Derek Ma et.al.|[2501.17326v1](http://arxiv.org/abs/2501.17326v1)|null|
|**2025-01-28**|**Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**|Peilong Wang et.al.|[2501.17286v1](http://arxiv.org/abs/2501.17286v1)|null|
|**2025-01-28**|**ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification**|Mohammadreza Saraei et.al.|[2501.17260v1](http://arxiv.org/abs/2501.17260v1)|[link](https://github.com/mrsaraei/vit-2spn)|
|**2025-01-28**|**A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**|Suresh Babu Nettur et.al.|[2501.17160v1](http://arxiv.org/abs/2501.17160v1)|null|
|**2025-01-28**|**Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**|Reza Ghorbani et.al.|[2501.17152v1](http://arxiv.org/abs/2501.17152v1)|null|
|**2025-01-28**|**Irony Detection, Reasoning and Understanding in Zero-shot Learning**|Peiling Yi et.al.|[2501.16884v1](http://arxiv.org/abs/2501.16884v1)|null|
|**2025-01-28**|**Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?**|Keqi Han et.al.|[2501.17207v1](http://arxiv.org/abs/2501.17207v1)|[link](https://github.com/learningkeqi/rethinkingbca)|
|**2025-01-28**|**Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care**|Fengpei Yuan et.al.|[2501.17206v1](http://arxiv.org/abs/2501.17206v1)|null|
|**2025-01-28**|**Efficient Knowledge Distillation of SAM for Medical Image Segmentation**|Kunal Dasharath Patil et.al.|[2501.16740v1](http://arxiv.org/abs/2501.16740v1)|null|
|**2025-01-28**|**VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records**|Philip Chung et.al.|[2501.16672v1](http://arxiv.org/abs/2501.16672v1)|[link](https://github.com/philipchung/verifact)|
|**2025-01-28**|**Vision-based autonomous structural damage detection using data-driven methods**|Seyyed Taghi Ataei et.al.|[2501.16662v2](http://arxiv.org/abs/2501.16662v2)|null|
|**2025-01-28**|**Molecular-driven Foundation Model for Oncologic Pathology**|Anurag Vaidya et.al.|[2501.16652v1](http://arxiv.org/abs/2501.16652v1)|null|
|**2025-01-27**|**Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models**|Jing Zhang et.al.|[2501.16282v1](http://arxiv.org/abs/2501.16282v1)|null|
|**2025-01-27**|**Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models**|Huayu Li et.al.|[2501.16215v1](http://arxiv.org/abs/2501.16215v1)|[link](https://github.com/HuayuLiArizona/Conformalized-Multiple-Instance-Learning-For-MedTS)|
|**2025-01-27**|**Atla Selene Mini: A General Purpose Evaluation Model**|Andrei Alexandru et.al.|[2501.17195v1](http://arxiv.org/abs/2501.17195v1)|[link](https://huggingface.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B)|
|**2025-01-27**|**An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**|Shaheer Ahmad Khan et.al.|[2501.15969v1](http://arxiv.org/abs/2501.15969v1)|null|
|**2025-01-27**|**Leveraging Video Vision Transformer for Alzheimer's Disease Diagnosis from 3D Brain MRI**|Taymaz Akan et.al.|[2501.15733v1](http://arxiv.org/abs/2501.15733v1)|null|
|**2025-01-27**|**A Survey on Computational Pathology Foundation Models: Datasets, Adaptation Strategies, and Evaluation Tasks**|Dong Li et.al.|[2501.15724v1](http://arxiv.org/abs/2501.15724v1)|null|
|**2025-01-26**|**Beyond Benchmarks: On The False Promise of AI Regulation**|Gabriel Stanovsky et.al.|[2501.15693v1](http://arxiv.org/abs/2501.15693v1)|null|
|**2025-01-26**|**Comparative clinical evaluation of "memory-efficient" synthetic 3d generative adversarial networks (gan) head-to-head to state of art: results on computed tomography of the chest**|Mahshid shiri et.al.|[2501.15572v1](http://arxiv.org/abs/2501.15572v1)|null|
|**2025-01-26**|**AI in Oncology: Transforming Cancer Detection through Machine Learning and Deep Learning Applications**|Muhammad Aftab et.al.|[2501.15489v1](http://arxiv.org/abs/2501.15489v1)|null|
|**2025-01-26**|**Identifying Critical Tokens for Accurate Predictions in Transformer-based Medical Imaging Models**|Solha Kang et.al.|[2501.15452v1](http://arxiv.org/abs/2501.15452v1)|null|
|**2025-01-25**|**An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis**|Arya Rahgozar et.al.|[2501.17181v1](http://arxiv.org/abs/2501.17181v1)|null|
|**2025-01-25**|**Feedback-Aware Monte Carlo Tree Search for Efficient Information Seeking in Goal-Oriented Conversations**|Harshita Chopra et.al.|[2501.15056v1](http://arxiv.org/abs/2501.15056v1)|null|
|**2025-01-24**|**Motion-enhancement to Echocardiography Segmentation via Inserting a Temporal Attention Module: An Efficient, Adaptable, and Scalable Approach**|Md. Kamrul Hasan et.al.|[2501.14929v1](http://arxiv.org/abs/2501.14929v1)|null|
|**2025-01-24**|**Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**|Hang Luo et.al.|[2501.14892v1](http://arxiv.org/abs/2501.14892v1)|null|
|**2025-01-24**|**Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**|Ipek Baris Schlicht et.al.|[2501.14719v1](http://arxiv.org/abs/2501.14719v1)|null|
|**2025-01-24**|**GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**|Ziwen Li et.al.|[2501.16382v1](http://arxiv.org/abs/2501.16382v1)|[link](https://github.com/aaronli43/grappi)|
|**2025-01-24**|**Rethinking Table Instruction Tuning**|Naihao Deng et.al.|[2501.14693v1](http://arxiv.org/abs/2501.14693v1)|null|
|**2025-01-24**|**Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**|Dmitry Ryabtsev et.al.|[2501.14689v1](http://arxiv.org/abs/2501.14689v1)|null|
|**2025-01-24**|**Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**|Fuping Wu et.al.|[2501.14685v1](http://arxiv.org/abs/2501.14685v1)|null|
|**2025-01-24**|**MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**|Yixing Jiang et.al.|[2501.14654v1](http://arxiv.org/abs/2501.14654v1)|[link](https://github.com/stanfordmlgroup/medagentbench)|
|**2025-01-24**|**Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis**|Xu Chen et.al.|[2501.18614v1](http://arxiv.org/abs/2501.18614v1)|null|
|**2025-01-24**|**Registration of Longitudinal Liver Examinations for Tumor Progress Assessment**|Walid Yassine et.al.|[2501.14483v1](http://arxiv.org/abs/2501.14483v1)|null|
|**2025-01-24**|**Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**|Taehan Kim et.al.|[2501.14469v1](http://arxiv.org/abs/2501.14469v1)|null|
|**2025-01-24**|**ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**|Yoni Schirris et.al.|[2501.14379v1](http://arxiv.org/abs/2501.14379v1)|[link](https://github.com/nki-ai/ectil)|
|**2025-01-24**|**Optimal Signal Decomposition-based Multi-Stage Learning for Battery Health Estimation**|Vijay Babu Pamshetti et.al.|[2501.16377v1](http://arxiv.org/abs/2501.16377v1)|null|
|**2025-01-24**|**Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**|Cong-Duy Nguyen et.al.|[2501.14166v1](http://arxiv.org/abs/2501.14166v1)|null|
|**2025-01-24**|**Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration**|Mojtaba Safari et.al.|[2501.14158v2](http://arxiv.org/abs/2501.14158v2)|[link](https://github.com/mosaf/awesome-dl-based-cs-mri)|
|**2025-01-23**|**MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**|Joshua Davis et.al.|[2501.14105v1](http://arxiv.org/abs/2501.14105v1)|[link](https://github.com/lindvalllab/medslice)|
|**2025-01-23**|**Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**|Jakob Krogh Petersen et.al.|[2501.14051v1](http://arxiv.org/abs/2501.14051v1)|[link](https://github.com/jakekrogh/3d-clip-for-brain-mri)|
|**2025-01-23**|**Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT: Utility for Pancreas Segmentation**|Xinya Wang et.al.|[2501.14013v1](http://arxiv.org/abs/2501.14013v1)|null|
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-23**|**Question Answering on Patient Medical Records with Private Fine-Tuned LLMs**|Sara Kothari et.al.|[2501.13687v1](http://arxiv.org/abs/2501.13687v1)|null|
|**2025-01-23**|**How to Complete Domain Tuning while Keeping General Ability in LLM: Adaptive Layer-wise and Element-wise Regularization**|Shezheng Song et.al.|[2501.13669v1](http://arxiv.org/abs/2501.13669v1)|null|
|**2025-01-23**|**Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management**|Yuxuan Liu et.al.|[2501.13587v2](http://arxiv.org/abs/2501.13587v2)|null|
|**2025-01-23**|**LLMs Can Plan Only If We Tell Them**|Bilgehan Sel et.al.|[2501.13545v1](http://arxiv.org/abs/2501.13545v1)|null|
|**2025-01-23**|**Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**|Bhumika Gupta et.al.|[2501.13984v1](http://arxiv.org/abs/2501.13984v1)|null|
|**2025-01-23**|**A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability**|Bishwash Paneru et.al.|[2501.13369v1](http://arxiv.org/abs/2501.13369v1)|null|
|**2025-01-23**|**Unveiling Discrete Clues: Superior Healthcare Predictions for Rare Diseases**|Chuang Zhao et.al.|[2501.16373v1](http://arxiv.org/abs/2501.16373v1)|[link](https://github.com/data-designer/udchealth)|
|**2025-01-22**|**QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**|Naman Jain et.al.|[2501.13165v1](http://arxiv.org/abs/2501.13165v1)|null|
|**2025-01-22**|**AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks**|Qiongyan Wang et.al.|[2501.13141v1](http://arxiv.org/abs/2501.13141v1)|null|
|**2025-01-22**|**Estimating the Conformal Prediction Threshold from Noisy Labels**|Coby Penso et.al.|[2501.12749v1](http://arxiv.org/abs/2501.12749v1)|[link](https://github.com/cobypenso/noise-aware-conformal-prediction)|
|**2025-01-22**|**Applications and Challenges of AI and Microscopy in Life Science Research: A Review**|Himanshu Buckchash et.al.|[2501.13135v1](http://arxiv.org/abs/2501.13135v1)|null|
|**2025-01-22**|**FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis**|Haoxuan Che et.al.|[2501.13967v2](http://arxiv.org/abs/2501.13967v2)|null|
|**2025-01-22**|**CAND: Cross-Domain Ambiguity Inference for Early Detecting Nuanced Illness Deterioration**|Lo Pang-Yun Ting et.al.|[2501.16365v1](http://arxiv.org/abs/2501.16365v1)|null|
|**2025-01-21**|**Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related to Post COVID-19 Condition**|Juan Andres Medina Florez et.al.|[2501.12538v2](http://arxiv.org/abs/2501.12538v2)|null|
|**2025-01-21**|**Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**|Jiaqi Guo et.al.|[2501.12524v1](http://arxiv.org/abs/2501.12524v1)|[link](https://github.com/guojiaqi-1020/medivlad)|
|**2025-01-21**|**FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**|Phuoc Duong Huy Chu et.al.|[2501.12336v1](http://arxiv.org/abs/2501.12336v1)|null|
|**2025-01-21**|**CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**|Cristiano Patrício et.al.|[2501.12266v1](http://arxiv.org/abs/2501.12266v1)|null|
|**2025-01-21**|**Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**|Stefan Lenz et.al.|[2501.12106v1](http://arxiv.org/abs/2501.12106v1)|[link](https://github.com/stefan-m-lenz/urollmeval)|
|**2025-01-21**|**Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**|Fatih Aksu et.al.|[2501.12425v1](http://arxiv.org/abs/2501.12425v1)|null|
|**2025-01-21**|**Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**|Shramana Dey et.al.|[2501.12048v1](http://arxiv.org/abs/2501.12048v1)|null|
|**2025-01-21**|**Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**|Yonghao Zhao et.al.|[2501.12421v1](http://arxiv.org/abs/2501.12421v1)|[link](https://github.com/yonghaozhao722/tsf)|
|**2025-01-21**|**Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)**|Jadon Geathers et.al.|[2501.13957v1](http://arxiv.org/abs/2501.13957v1)|null|
|**2025-01-21**|**Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**|Saeid Ataei et.al.|[2501.11836v1](http://arxiv.org/abs/2501.11836v1)|null|
|**2025-01-20**|**GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**|Wenjie Kang et.al.|[2501.11715v1](http://arxiv.org/abs/2501.11715v1)|null|
|**2025-01-20**|**Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**|Brian E. Perron et.al.|[2501.11705v1](http://arxiv.org/abs/2501.11705v1)|null|
|**2025-01-20**|**Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**|Majid Farhadloo et.al.|[2501.11695v1](http://arxiv.org/abs/2501.11695v1)|null|
|**2025-01-20**|**Multilinguality in LLM-Designed Reward Functions for Restless Bandits: Effects on Task Performance and Fairness**|Ambreesh Parthasarathy et.al.|[2501.13120v1](http://arxiv.org/abs/2501.13120v1)|null|
|**2025-01-20**|**Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**|Yuxing Lu et.al.|[2501.11632v2](http://arxiv.org/abs/2501.11632v2)|null|
|**2025-01-20**|**Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**|Chaoqing Tang et.al.|[2501.11592v2](http://arxiv.org/abs/2501.11592v2)|[link](https://github.com/billttzqgbt/cscoefficientslearning)|
|**2025-01-20**|**Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**|Jakub Nalepa et.al.|[2501.11428v1](http://arxiv.org/abs/2501.11428v1)|null|
|**2025-01-20**|**Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations**|Alicia Vidler et.al.|[2501.16356v1](http://arxiv.org/abs/2501.16356v1)|null|
|**2025-01-20**|**RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**|Haotian Xu et.al.|[2501.11284v1](http://arxiv.org/abs/2501.11284v1)|null|
|**2025-01-20**|**Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**|Osama Ahmad et.al.|[2501.11270v1](http://arxiv.org/abs/2501.11270v1)|null|

#### Abstracts
##### **Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**
2501.19338v1 by Misha P. T Kaandorp, Damola Agbelese, Hosna Asma-ull, Hyun-Gi Kim, Kelly Payette, Patrice Grehten, Gennari Antonio Giulio, Levente István Lánczi, Andras Jakab

Developing new methods for the automated analysis of clinical fetal and
neonatal MRI data is limited by the scarcity of annotated pathological datasets
and privacy concerns that often restrict data sharing, hindering the
effectiveness of deep learning models. We address this in two ways. First, we
introduce Fetal&Neonatal-DDPM, a novel diffusion model framework designed to
generate high-quality synthetic pathological fetal and neonatal MRIs from
semantic label images. Second, we enhance training data by modifying healthy
label images through morphological alterations to simulate conditions such as
ventriculomegaly, cerebellar and pontocerebellar hypoplasia, and microcephaly.
By leveraging Fetal&Neonatal-DDPM, we synthesize realistic pathological MRIs
from these modified pathological label images. Radiologists rated the synthetic
MRIs as significantly (p < 0.05) superior in quality and diagnostic value
compared to real MRIs, demonstrating features such as blood vessels and choroid
plexus, and improved alignment with label annotations. Synthetic pathological
data enhanced state-of-the-art nnUNet segmentation performance, particularly
for severe ventriculomegaly cases, with the greatest improvements achieved in
ventricle segmentation (Dice scores: 0.9253 vs. 0.7317). This study underscores
the potential of generative AI as transformative tool for data augmentation,
offering improved segmentation performance in pathological cases. This
development represents a significant step towards improving analysis and
segmentation accuracy in prenatal imaging, and also offers new ways for data
anonymization through the generation of pathologic image data.

摘要：<paragraph>開發用於自動分析臨床胎兒和新生兒 MRI 資料的新方法受到標註病理資料集稀少和隱私問題的限制，這些問題通常會限制資料共享，從而阻礙深度學習模型的有效性。我們以兩種方式解決這個問題。首先，我們引入了 Fetal&Neonatal-DDPM，這是一個新穎的擴散模型架構，旨在從語義標籤影像生成高品質的合成病理胎兒和新生兒 MRI。其次，我們透過形態改變來修改健康的標籤影像，以模擬腦室擴大、小腦和橋腦小腦發育不全以及小頭畸形等情況，從而增強訓練資料。透過利用 Fetal&Neonatal-DDPM，我們從這些修改後的病理標籤影像中合成了逼真的病理 MRI。放射科醫師評估合成 MRI 的品質和診斷價值顯著優於真實 MRI（p < 0.05），展示了血管和脈絡叢等特徵，並改善了與標籤註解的一致性。合成病理資料增強了最先進的 nnUNet 分割效能，特別是對於嚴重的腦室擴大病例，其中腦室分割（Dice 分數：0.9253 對 0.7317）的改善最大。這項研究強調了生成式 AI 作為資料擴充轉型工具的潛力，在病理病例中提供了改善的分割效能。這項發展代表了改善產前影像分析和分割準確性的重要一步，也為透過生成病理影像資料來進行資料匿名化提供了新方法。</paragraph>

##### **Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**
2501.19271v1 by Halil Ibrahim Aysel, Xiaohao Cai, Adam Prugel-Bennett

Concept-based explanation methods, such as concept bottleneck models (CBMs),
aim to improve the interpretability of machine learning models by linking their
decisions to human-understandable concepts, under the critical assumption that
such concepts can be accurately attributed to the network's feature space.
However, this foundational assumption has not been rigorously validated, mainly
because the field lacks standardised metrics and benchmarks to assess the
existence and spatial alignment of such concepts. To address this, we propose
three metrics: the concept global importance metric, the concept existence
metric, and the concept location metric, including a technique for visualising
concept activations, i.e., concept activation mapping. We benchmark post-hoc
CBMs to illustrate their capabilities and challenges. Through qualitative and
quantitative experiments, we demonstrate that, in many cases, even the most
important concepts determined by post-hoc CBMs are not present in input images;
moreover, when they are present, their saliency maps fail to align with the
expected regions by either activating across an entire object or misidentifying
relevant concept-specific regions. We analyse the root causes of these
limitations, such as the natural correlation of concepts. Our findings
underscore the need for more careful application of concept-based explanation
techniques especially in settings where spatial interpretability is critical.

摘要：基於概念的解釋方法，例如概念瓶頸模型 (CBM)，旨在透過將機器學習模型的決策與人類可理解的概念連結，來提升機器學習模型的可解釋性，其關鍵假設為此類概念可以準確地歸因於網路的特徵空間。然而，此項基礎假設尚未經過嚴格驗證，主要是因為該領域缺乏標準化指標和基準來評估此類概念的存在和空間對齊。為了解決這個問題，我們提出三項指標：概念整體重要性指標、概念存在指標和概念位置指標，包括一種用於視覺化概念活化，即概念活化對應的技術。我們對事後 CBM 進行基準測試，以說明它們的能力和挑戰。透過定性和定量實驗，我們證明，在許多情況下，即使是由事後 CBM 確定的最重要概念也不存在於輸入影像中；此外，當它們存在時，它們的顯著性圖無法與預期的區域對齊，原因可能是它們在整個物件中活化，或錯誤辨識出相關的概念特定區域。我們分析了這些限制的根本原因，例如概念的自然相關性。我們的研究結果強調需要更小心地應用基於概念的解釋技術，特別是在空間可解釋性至關重要的設定中。

##### **Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using Generative Artificial Intelligence**
2501.19176v1 by Aurora Rofena, Claudia Lucia Piccolo, Bruno Beomonte Zobel, Paolo Soda, Valerio Guarrasi

Full-Field Digital Mammography (FFDM) is the primary imaging modality for
routine breast cancer screening; however, its effectiveness is limited in
patients with dense breast tissue or fibrocystic conditions. Contrast-Enhanced
Spectral Mammography (CESM), a second-level imaging technique, offers enhanced
accuracy in tumor detection. Nonetheless, its application is restricted due to
higher radiation exposure, the use of contrast agents, and limited
accessibility. As a result, CESM is typically reserved for select cases,
leaving many patients to rely solely on FFDM despite the superior diagnostic
performance of CESM. While biopsy remains the gold standard for definitive
diagnosis, it is an invasive procedure that can cause discomfort for patients.
We introduce a multimodal, multi-view deep learning approach for virtual
biopsy, integrating FFDM and CESM modalities in craniocaudal and mediolateral
oblique views to classify lesions as malignant or benign. To address the
challenge of missing CESM data, we leverage generative artificial intelligence
to impute CESM images from FFDM scans. Experimental results demonstrate that
incorporating the CESM modality is crucial to enhance the performance of
virtual biopsy. When real CESM data is missing, synthetic CESM images proved
effective, outperforming the use of FFDM alone, particularly in multimodal
configurations that combine FFDM and CESM modalities. The proposed approach has
the potential to improve diagnostic workflows, providing clinicians with
augmented intelligence tools to improve diagnostic accuracy and patient care.
Additionally, as a contribution to the research community, we publicly release
the dataset used in our experiments, facilitating further advancements in this
field.

摘要：全視野數位乳房攝影 (FFDM) 是常規乳癌篩檢的主要影像模式；然而，對於乳房組織緻密或纖維囊腫病變的患者，其有效性受到限制。對比增強光譜乳房攝影 (CESM) 是一種二級影像技術，可提升腫瘤偵測的準確度。儘管如此，由於較高的輻射曝露、對比劑的使用和有限的可及性，限制了其應用。因此，CESM 通常僅保留在特定情況下使用，儘管 CESM 的診斷效能較佳，但許多患者仍只能依賴 FFDM。雖然切片檢查仍然是明確診斷的黃金標準，但這是一種侵入性程序，可能會讓患者感到不適。我們引入一種多模式、多視圖的深度學習方法進行虛擬切片檢查，將 FFDM 和 CESM 模式整合在頭尾向和內外側斜視圖中，以將病灶分類為惡性或良性。為了解決 CESM 資料缺失的挑戰，我們利用生成式人工智慧從 FFDM 掃描中推算 CESM 影像。實驗結果證明，整合 CESM 模式對於提升虛擬切片檢查的效能至關重要。當真實 CESM 資料缺失時，合成 CESM 影像被證明是有效的，其效能優於單獨使用 FFDM，特別是在結合 FFDM 和 CESM 模式的多模式配置中。所提出的方法有潛力改善診斷工作流程，為臨床醫師提供增強的智慧工具，以提高診斷準確度和患者照護。此外，作為對研究社群的貢獻，我們公開發布在實驗中使用的資料集，以促進此領域的進一步進展。

##### **Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**
2501.19086v1 by Xiangyu Sun, Xiaoguang Zou, Yuanquan Wu, Guotai Wang, Shaoting Zhang

X-ray imaging is pivotal in medical diagnostics, offering non-invasive
insights into a range of health conditions. Recently, vision-language models,
such as the Contrastive Language-Image Pretraining (CLIP) model, have
demonstrated potential in improving diagnostic accuracy by leveraging
large-scale image-text datasets. However, since CLIP was not initially designed
for medical images, several CLIP-like models trained specifically on medical
images have been developed. Despite their enhanced performance, issues of
fairness - particularly regarding demographic attributes - remain largely
unaddressed. In this study, we perform a comprehensive fairness analysis of
CLIP-like models applied to X-ray image classification. We assess their
performance and fairness across diverse patient demographics and disease
categories using zero-shot inference and various fine-tuning techniques,
including Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation
(LoRA), and full fine-tuning. Our results indicate that while fine-tuning
improves model accuracy, fairness concerns persist, highlighting the need for
further fairness interventions in these foundational models.

摘要：X 光影像在醫療診斷中至關重要，能提供各種健康狀況的非侵入性見解。最近，視覺語言模型（例如對比語言影像預訓練 (CLIP) 模型）已證明有潛力透過利用大規模影像文字資料集來改善診斷準確性。然而，由於 CLIP 最初並非設計用於醫療影像，因此已經開發了數個特別針對醫療影像訓練的類似 CLIP 模型。儘管它們的效能有所提升，但公平性的問題（特別是關於人口統計屬性）仍大多未獲解決。在本研究中，我們對應用於 X 光影像分類的類似 CLIP 模型執行全面的公平性分析。我們使用零次學習推論和各種微調技術（包括線性探查、多層感知器 (MLP)、低秩適應 (LoRA) 和完整微調）來評估它們在不同患者人口統計和疾病類別中的效能和公平性。我們的結果表明，雖然微調會改善模型準確性，但公平性問題仍然存在，強調需要在這些基礎模型中進一步採取公平性干預措施。

##### **Survey and Improvement Strategies for Gene Prioritization with Large Language Models**
2501.18794v1 by Matthew Neeley, Guantong Qi, Guanchu Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, Fan Xia, Pengfei Liu, Zhandong Liu, Xia Hu

Rare diseases are challenging to diagnose due to limited patient data and
genetic diversity. Despite advances in variant prioritization, many cases
remain undiagnosed. While large language models (LLMs) have performed well in
medical exams, their effectiveness in diagnosing rare genetic diseases has not
been assessed. To identify causal genes, we benchmarked various LLMs for gene
prioritization. Using multi-agent and Human Phenotype Ontology (HPO)
classification, we categorized patients based on phenotypes and solvability
levels. As gene set size increased, LLM performance deteriorated, so we used a
divide-and-conquer strategy to break the task into smaller subsets. At
baseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking
causal genes correctly. The multi-agent and HPO approaches helped distinguish
confidently solved cases from challenging ones, highlighting the importance of
known gene-phenotype associations and phenotype specificity. We found that
cases with specific phenotypes or clear associations were more accurately
solved. However, we observed biases toward well-studied genes and input order
sensitivity, which hindered gene prioritization. Our divide-and-conquer
strategy improved accuracy by overcoming these biases. By utilizing HPO
classification, novel multi-agent techniques, and our LLM strategy, we improved
causal gene identification accuracy compared to our baseline evaluation. This
approach streamlines rare disease diagnosis, facilitates reanalysis of unsolved
cases, and accelerates gene discovery, supporting the development of targeted
diagnostics and therapies.

摘要：罕見疾病由於患者數據有限和遺傳多樣性，診斷起來具有挑戰性。儘管變異優先級排序技術進步，但許多病例仍未得到診斷。儘管大型語言模型 (LLM) 在醫學考試中表現良好，但它們在診斷罕見遺傳疾病方面的有效性尚未得到評估。為了識別致病基因，我們對各種 LLM 進行了基因優先級排序基準測試。使用多智能體和人類表型本体 (HPO) 分類，我們根據表型和可解決性對患者進行了分類。隨著基因組大小的增加，LLM 性能下降，因此我們使用分而治之策略將任務分解為更小的子集。在基線中，GPT-4 優於其他 LLM，在正確排序致病基因方面達到近 30% 的準確度。多智能體和 HPO 方法有助於區分解決有信心的病例和具有挑戰性的病例，強調已知基因-表型關聯和表型特異性的重要性。我們發現具有特定表型或明確關聯的病例得到更準確的解決。然而，我們觀察到對研究充分的基因和輸入順序敏感性的偏差，這阻礙了基因優先級排序。我們的分而治之策略通過克服這些偏差來提高準確性。通過利用 HPO 分類、新穎的多智能體技術和我們的 LLM 策略，我們與我們的基線評估相比提高了致病基因識別準確性。這種方法簡化了罕見疾病的診斷，促進了對未解決病例的重新分析，並加速了基因發現，支持了靶向診斷和治療的開發。

##### **Synthetic Data Generation for Augmenting Small Samples**
2501.18741v1 by Dan Liu, Samer El Kababji, Nicholas Mitsakakis, Lisa Pilgram, Thomas Walters, Mark Clemons, Greg Pond, Alaa El-Hussuna, Khaled El Emam

Small datasets are common in health research. However, the generalization
performance of machine learning models is suboptimal when the training datasets
are small. To address this, data augmentation is one solution. Augmentation
increases sample size and is seen as a form of regularization that increases
the diversity of small datasets, leading them to perform better on unseen data.
We found that augmentation improves prognostic performance for datasets that:
have fewer observations, with smaller baseline AUC, have higher cardinality
categorical variables, and have more balanced outcome variables. No specific
generative model consistently outperformed the others. We developed a decision
support model that can be used to inform analysts if augmentation would be
useful. For seven small application datasets, augmenting the existing data
results in an increase in AUC between 4.31% (AUC from 0.71 to 0.75) and 43.23%
(AUC from 0.51 to 0.73), with an average 15.55% relative improvement,
demonstrating the nontrivial impact of augmentation on small datasets
(p=0.0078). Augmentation AUC was higher than resampling only AUC (p=0.016). The
diversity of augmented datasets was higher than the diversity of resampled
datasets (p=0.046).

摘要：在健康研究中，小型数据集很常见。然而，当训练数据集较小时，机器学习模型的泛化性能并不理想。为了解决这个问题，数据增强是一种解决方案。增强增加了样本量，并被视为一种正则化形式，它增加了小型数据集的多样性，从而使其在未见数据上表现得更好。我们发现，增强提高了以下数据集的预测性能：具有较少的观测值、较小的基线 AUC、较高的基数分类变量以及更平衡的结果变量。没有特定的生成模型始终优于其他模型。我们开发了一个决策支持模型，可用于告知分析师增强是否有用。对于七个小型应用程序数据集，增强现有数据导致 AUC 增加 4.31%（AUC 从 0.71 增加到 0.75）和 43.23%（AUC 从 0.51 增加到 0.73），平均相对改进 15.55%，这表明了增强对小型数据集的非平凡影响（p=0.0078）。增强 AUC 高于仅重新采样的 AUC（p=0.016）。增强数据集的多样性高于重新采样数据集的多样性（p=0.046）。

##### **A Learnable Multi-views Contrastive Framework with Reconstruction Discrepancy for Medical Time-Series**
2501.18367v1 by Yifan Wang, Hongfeng Ai, Ruiqi Li, Maowei Jiang, Cheng Jiang, Chenzhong Li

In medical time series disease diagnosis, two key challenges are
identified.First, the high annotation cost of medical data leads to overfitting
in models trained on label-limited, single-center datasets. To address this, we
propose incorporating external data from related tasks and leveraging AE-GAN to
extract prior knowledge,providing valuable references for downstream tasks.
Second, many existing studies employ contrastive learning to derive more
generalized medical sequence representations for diagnostic tasks, usually
relying on manually designed diverse positive and negative sample
pairs.However, these approaches are complex, lack generalizability, and fail to
adaptively capture disease-specific features across different conditions.To
overcome this, we introduce LMCF (Learnable Multi-views Contrastive Framework),
a framework that integrates a multi-head attention mechanism and adaptively
learns representations from different views through inter-view and intra-view
contrastive learning strategies.Additionally, the pre-trained AE-GAN is used to
reconstruct discrepancies in the target data as disease probabilities, which
are then integrated into the contrastive learning process.Experiments on three
target datasets demonstrate that our method consistently outperforms seven
other baselines, highlighting its significant impact on healthcare applications
such as the diagnosis of myocardial infarction, Alzheimer's disease, and
Parkinson's disease.

摘要：在医疗时间序列疾病诊断中，确定了两个关键挑战。首先，医疗数据的标注成本高，导致在标签受限的单中心数据集上训练的模型出现过拟合。为了解决这个问题，我们建议合并来自相关任务的外部数据，并利用 AE-GAN 提取先验知识，为下游任务提供有价值的参考。其次，许多现有的研究采用对比学习来推导出更通用的医疗序列表示，用于诊断任务，通常依赖于手动设计的各种正负样本对。然而，这些方法复杂，缺乏通用性，并且无法自适应地捕获不同条件下的特定疾病特征。为了克服这个问题，我们引入了 LMCF（可学习的多视图对比框架），这是一个集成了多头注意机制的框架，并通过视图间和视图内对比学习策略自适应地学习来自不同视图的表示。此外，预训练的 AE-GAN 用于重建目标数据中的差异作为疾病概率，然后将其集成到对比学习过程中。在三个目标数据集上的实验表明，我们的方法始终优于其他七个基线，突出了其对医疗保健应用（如心肌梗塞、阿尔茨海默病和帕金森病的诊断）的重大影响。

##### **MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding**
2501.18362v1 by Yuxin Zuo, Shang Qu, Yifei Li, Zhangren Chen, Xuekai Zhu, Ermo Hua, Kaiyan Zhang, Ning Ding, Bowen Zhou

We introduce MedXpertQA, a highly challenging and comprehensive benchmark to
evaluate expert-level medical knowledge and advanced reasoning. MedXpertQA
includes 4,460 questions spanning 17 specialties and 11 body systems. It
includes two subsets, Text for text evaluation and MM for multimodal
evaluation. Notably, MM introduces expert-level exam questions with diverse
images and rich clinical information, including patient records and examination
results, setting it apart from traditional medical multimodal benchmarks with
simple QA pairs generated from image captions. MedXpertQA applies rigorous
filtering and augmentation to address the insufficient difficulty of existing
benchmarks like MedQA, and incorporates specialty board questions to improve
clinical relevance and comprehensiveness. We perform data synthesis to mitigate
data leakage risk and conduct multiple rounds of expert reviews to ensure
accuracy and reliability. We evaluate 16 leading models on MedXpertQA.
Moreover, medicine is deeply connected to real-world decision-making, providing
a rich and representative setting for assessing reasoning abilities beyond
mathematics and code. To this end, we develop a reasoning-oriented subset to
facilitate the assessment of o1-like models.

摘要：我們推出了 MedXpertQA，這是一個極具挑戰性且全面的基準，用於評估專家級的醫學知識和先進的推理能力。MedXpertQA 包含 4,460 個問題，涵蓋 17 個專科和 11 個身體系統。它包含兩個子集，文本用於文本評估，MM 用於多模式評估。值得注意的是，MM 引入了專家級考試題目，其中包含多樣化的影像和豐富的臨床資訊，包括患者記錄和檢查結果，這讓它有別於傳統的醫學多模式基準，後者是從影像標題中產生的簡單問答對。MedXpertQA 採用嚴格的過濾和擴充，以解決 MedQA 等現有基準的難度不足問題，並納入專科委員會問題以提高臨床相關性和全面性。我們執行資料合成以降低資料外洩風險，並進行多輪專家審查以確保準確性和可靠性。我們在 MedXpertQA 上評估了 16 個領先的模型。此外，醫學與現實世界的決策制定有密切的聯繫，提供了豐富且具代表性的環境，用於評估超越數學和程式碼的推理能力。為此，我們開發了一個以推理為導向的子集，以利於評估類 o1 的模型。

##### **CodeBrain: Impute Any Brain MRI via Instance-specific Scalar-quantized Codes**
2501.18328v1 by Yicheng Wu, Tao Song, Zhonghua Wu, Zongyuan Ge, Zhaolin Chen, Jianfei Cai

MRI imputation aims to synthesize the missing modality from one or more
available ones, which is highly desirable since it reduces scanning costs and
delivers comprehensive MRI information to enhance clinical diagnosis. In this
paper, we propose a unified model, CodeBrain, designed to adapt to various
brain MRI imputation scenarios. The core design lies in casting various
inter-modality transformations as a full-modality code prediction task. To this
end, CodeBrain is trained in two stages: Reconstruction and Code Prediction.
First, in the Reconstruction stage, we reconstruct each MRI modality, which is
mapped into a shared latent space followed by a scalar quantization. Since such
quantization is lossy and the code is low dimensional, another MRI modality
belonging to the same subject is randomly selected to generate common features
to supplement the code and boost the target reconstruction. In the second
stage, we train another encoder by a customized grading loss to predict the
full-modality codes from randomly masked MRI samples, supervised by the
corresponding quantized codes generated from the first stage. In this way, the
inter-modality transformation is achieved by mapping the instance-specific
codes in a finite scalar space. We evaluated the proposed CodeBrain model on
two public brain MRI datasets (i.e., IXI and BraTS 2023). Extensive experiments
demonstrate that our CodeBrain model achieves superior imputation performance
compared to four existing methods, establishing a new state of the art for
unified brain MRI imputation. Codes will be released.

摘要：MRI 補完旨在從一個或多個可用方式中合成遺失的模態，這是非常理想的，因為它降低了掃描成本，並提供了全面的 MRI 資訊以增強臨床診斷。在本文中，我們提出了一個統一模型 CodeBrain，旨在適應各種腦部 MRI 補完場景。核心設計在於將各種模態間轉換轉換為全模態碼預測任務。為此，CodeBrain 分兩個階段進行訓練：重建和碼預測。首先，在重建階段，我們重建每個 MRI 模態，它被映射到一個共享潛在空間，然後進行標量量化。由於這種量化是有損的，並且碼的維度很低，因此隨機選擇屬於同一個受試者的另一個 MRI 模態來產生共同特徵以補充碼並提升目標重建。在第二階段，我們通過自訂分級損失訓練另一個編碼器，從隨機遮罩的 MRI 樣本預測全模態碼，並由第一階段產生的對應量化碼進行監督。這樣，模態間轉換是通過將特定於例項的碼映射到一個有限的標量空間來實現的。我們在兩個公開的腦部 MRI 資料集（即 IXI 和 BraTS 2023）上評估了所提出的 CodeBrain 模型。大量的實驗證明，與四種現有方法相比，我們的 CodeBrain 模型實現了優異的補完效能，為統一的腦部 MRI 補完建立了新的技術水準。碼將會釋出。

##### **A Comprehensive Analysis on Machine Learning based Methods for Lung Cancer Level Classification**
2501.18294v1 by Shayli Farshchiha, Salman Asoudeh, Maryam Shavali Kuhshuri, Mehrshad Eisaeid, Mohamadreza Azadie, Saba Hesaraki

Lung cancer is a major issue in worldwide public health, requiring early
diagnosis using stable techniques. This work begins a thorough investigation of
the use of machine learning (ML) methods for precise classification of lung
cancer stages. A cautious analysis is performed to overcome overfitting issues
in model performance, taking into account minimum child weight and learning
rate. A set of machine learning (ML) models including XGBoost (XGB), LGBM,
Adaboost, Logistic Regression (LR), Decision Tree (DT), Random Forest (RF),
CatBoost, and k-Nearest Neighbor (k-NN) are run methodically and contrasted.
Furthermore, the correlation between features and targets is examined using the
deep neural network (DNN) model and thus their capability in detecting complex
patternsis established. It is argued that several ML models can be capable of
classifying lung cancer stages with great accuracy. In spite of the complexity
of DNN architectures, traditional ML models like XGBoost, LGBM, and Logistic
Regression excel with superior performance. The models perform better than the
others in lung cancer prediction on the complete set of comparative metrics
like accuracy, precision, recall, and F-1 score

摘要：肺癌是全球公共衛生的一大問題，需要使用穩定的技術進行早期診斷。這項工作開始徹底調查使用機器學習 (ML) 方法精確分類肺癌分期的使用情況。執行謹慎的分析以克服模型效能中的過度擬合問題，並考慮最小子權重和學習率。一組機器學習 (ML) 模型，包括 XGBoost (XGB)、LGBM、Adaboost、邏輯迴歸 (LR)、決策樹 (DT)、隨機森林 (RF)、CatBoost 和 k 最近鄰 (k-NN)，以有條理的方式執行並進行對比。此外，使用深度神經網路 (DNN) 模型檢查特徵和目標之間的關聯性，從而建立它們在檢測複雜模式中的能力。有人認為，多個 ML 模型能夠以很高的準確度對肺癌分期進行分類。儘管 DNN 架構很複雜，但傳統 ML 模型（如 XGBoost、LGBM 和邏輯迴歸）表現出色，效能優異。這些模型在肺癌預測中表現優於其他模型，在準確度、精確度、召回率和 F-1 分數等完整的比較指標中表現出色。

##### **The iToBoS dataset: skin region images extracted from 3D total body photographs for lesion detection**
2501.18270v1 by Anup Saha, Joseph Adeola, Nuria Ferrera, Adam Mothershaw, Gisele Rezze, Séraphin Gaborit, Brian D'Alessandro, James Hudson, Gyula Szabó, Balazs Pataki, Hayat Rajani, Sana Nazari, Hassan Hayat, Clare Primiero, H. Peter Soyer, Josep Malvehy, Rafael Garcia

Artificial intelligence has significantly advanced skin cancer diagnosis by
enabling rapid and accurate detection of malignant lesions. In this domain,
most publicly available image datasets consist of single, isolated skin lesions
positioned at the center of the image. While these lesion-centric datasets have
been fundamental for developing diagnostic algorithms, they lack the context of
the surrounding skin, which is critical for improving lesion detection. The
iToBoS dataset was created to address this challenge. It includes 16,954 images
of skin regions from 100 participants, captured using 3D total body
photography. Each image roughly corresponds to a $7 \times 9$ cm section of
skin with all suspicious lesions annotated using bounding boxes. Additionally,
the dataset provides metadata such as anatomical location, age group, and sun
damage score for each image. This dataset aims to facilitate training and
benchmarking of algorithms, with the goal of enabling early detection of skin
cancer and deployment of this technology in non-clinical environments.

摘要：人工智慧透過快速且準確偵測惡性病灶，大幅提升皮膚癌的診斷。在這個領域中，大多數公開的影像資料集都包含單一、孤立的皮膚病灶，置於影像的中央。儘管這些以病灶為中心的資料集對於開發診斷演算法至關重要，但它們卻缺乏周圍皮膚的背景，這對於改善病灶偵測至關重要。iToBoS 資料集的建立就是為了應對這個挑戰。它包含 100 位參與者的 16,954 張皮膚區域影像，使用 3D 全身攝影技術擷取。每張影像大致對應於 $7 \times 9$ 公分的皮膚區域，所有可疑病灶都使用邊界框標註。此外，該資料集還提供每張影像的元資料，例如解剖位置、年齡組和日曬損傷評分。此資料集旨在促進演算法的訓練和基準測試，目標是實現皮膚癌的早期偵測，並將此技術部署在非臨床環境中。

##### **Arbitrary Data as Images: Fusion of Patient Data Across Modalities and Irregular Intervals with Vision Transformers**
2501.18237v1 by Malte Tölle, Mohamad Scharaf, Samantha Fischer, Christoph Reich, Silav Zeid, Christoph Dieterich, Benjamin Meder, Norbert Frey, Philipp Wild, Sandy Engelhardt

A patient undergoes multiple examinations in each hospital stay, where each
provides different facets of the health status. These assessments include
temporal data with varying sampling rates, discrete single-point measurements,
therapeutic interventions such as medication administration, and images. While
physicians are able to process and integrate diverse modalities intuitively,
neural networks need specific modeling for each modality complicating the
training procedure. We demonstrate that this complexity can be significantly
reduced by visualizing all information as images along with unstructured text
and subsequently training a conventional vision-text transformer. Our approach,
Vision Transformer for irregular sampled Multi-modal Measurements (ViTiMM), not
only simplifies data preprocessing and modeling but also outperforms current
state-of-the-art methods in predicting in-hospital mortality and phenotyping,
as evaluated on 6,175 patients from the MIMIC-IV dataset. The modalities
include patient's clinical measurements, medications, X-ray images, and
electrocardiography scans. We hope our work inspires advancements in
multi-modal medical AI by reducing the training complexity to (visual) prompt
engineering, thus lowering entry barriers and enabling no-code solutions for
training. The source code will be made publicly available.

摘要：在每次住院期間，患者會接受多項檢查，每一項檢查都能提供健康狀態的不同面向。這些評估包括具有不同取樣率的時間資料、離散單點測量值、治療介入（如藥物管理）和影像。雖然醫生能夠直觀地處理和整合不同的模式，但神經網路需要針對每種模式進行特定的建模，這使得訓練程序變得複雜。我們證明，通過將所有資訊視覺化為影像，並結合非結構化文字，隨後訓練一個傳統的視覺文字轉換器，可以大幅降低這種複雜性。我們的做法，即用於不規則採樣多模式測量的視覺轉換器 (ViTiMM)，不僅簡化了資料預處理和建模，而且在預測院內死亡率和表型方面也優於目前的最新方法，這是根據 MIMIC-IV 資料集中的 6,175 名患者評估的。這些模式包括患者的臨床測量值、藥物、X 光影像和心電圖掃描。我們希望我們的工作能透過降低訓練複雜度到（視覺）提示工程，從而降低進入門檻，並為訓練啟用無程式碼解決方案，進而激勵多模式醫療 AI 的進步。原始程式碼將公開提供。

##### **Investigating an Intelligent System to Monitor \& Explain Abnormal Activity Patterns of Older Adults**
2501.18108v1 by Min Hun Lee, Daniel P. Siewiorek, Alexandre Bernardino

Despite the growing potential of older adult care technologies, the adoption
of these technologies remains challenging. In this work, we conducted a
focus-group session with family caregivers to scope designs of the older adult
care technology. We then developed a high-fidelity prototype and conducted its
qualitative study with professional caregivers and older adults to understand
their perspectives on the system functionalities. This system monitors abnormal
activity patterns of older adults using wireless motion sensors and machine
learning models and supports interactive dialogue responses to explain abnormal
activity patterns of older adults to caregivers and allow older adults
proactively sharing their status with caregivers for an adequate intervention.
Both older adults and professional caregivers appreciated that our system can
provide a faster, personalized service while proactively controlling what
information is to be shared through interactive dialogue responses. We further
discuss other considerations to realize older adult technology in practice.

摘要：儘管老年人照護技術的潛力日益增長，但採用這些技術仍具有挑戰性。在這項研究中，我們與家庭照護者進行焦點小組會議，以界定老年人照護技術的設計範圍。接著，我們開發了一個高保真原型，並與專業照護者和老年人進行質性研究，以了解他們對系統功能的觀點。此系統使用無線動作感測器和機器學習模型監控老年人的異常活動模式，並支援互動式對話回應，向照護者解釋老年人的異常活動模式，並讓老年人主動與照護者分享他們的狀態，以進行適當的介入。老年人和專業照護者都讚賞我們的系統能提供更快速、個人化的服務，同時透過互動式對話回應主動控制要分享哪些資訊。我們進一步討論其他考量因素，以在實務中實現老年人技術。

##### **Normative Evaluation of Large Language Models with Everyday Moral Dilemmas**
2501.18081v1 by Pratik S. Sachdeva, Tom van Nuenen

The rapid adoption of large language models (LLMs) has spurred extensive
research into their encoded moral norms and decision-making processes. Much of
this research relies on prompting LLMs with survey-style questions to assess
how well models are aligned with certain demographic groups, moral beliefs, or
political ideologies. While informative, the adherence of these approaches to
relatively superficial constructs tends to oversimplify the complexity and
nuance underlying everyday moral dilemmas. We argue that auditing LLMs along
more detailed axes of human interaction is of paramount importance to better
assess the degree to which they may impact human beliefs and actions. To this
end, we evaluate LLMs on complex, everyday moral dilemmas sourced from the "Am
I the Asshole" (AITA) community on Reddit, where users seek moral judgments on
everyday conflicts from other community members. We prompted seven LLMs to
assign blame and provide explanations for over 10,000 AITA moral dilemmas. We
then compared the LLMs' judgments and explanations to those of Redditors and to
each other, aiming to uncover patterns in their moral reasoning. Our results
demonstrate that large language models exhibit distinct patterns of moral
judgment, varying substantially from human evaluations on the AITA subreddit.
LLMs demonstrate moderate to high self-consistency but low inter-model
agreement. Further analysis of model explanations reveals distinct patterns in
how models invoke various moral principles. These findings highlight the
complexity of implementing consistent moral reasoning in artificial systems and
the need for careful evaluation of how different models approach ethical
judgment. As LLMs continue to be used in roles requiring ethical
decision-making such as therapists and companions, careful evaluation is
crucial to mitigate potential biases and limitations.

摘要：大型語言模型 (LLM) 的快速採用已促使人們深入研究其編碼的道德規範和決策過程。許多這類研究依賴於以調查式問題提示 LLM，以評估模型與特定人口群體、道德信念或政治意識形態的契合程度。儘管有提供資訊，但這些方法對相對膚淺的結構的堅持傾向於過度簡化日常道德困境背後的複雜性和細微差別。我們認為，沿著更詳細的人類互動軸線審查 LLM 對於更好地評估它們可能影響人類信念和行為的程度至關重要。為此，我們根據 Reddit 上「我是混蛋嗎」(AITA) 社群評估 LLM 在複雜的日常道德困境中，使用者在其中尋求其他社群成員對日常衝突的道德判斷。我們提示七個 LLM 對超過 10,000 個 AITA 道德困境分配責任並提供解釋。然後，我們將 LLM 的判斷和解釋與 Reddit 使用者的判斷和解釋以及彼此進行比較，旨在揭示其道德推理中的模式。我們的結果表明，大型語言模型展現出不同的道德判斷模式，與 AITA 子版塊上的人類評估有很大差異。LLM 表現出中度到高度的自我一致性，但模型間協議低。進一步分析模型解釋揭示了模型如何援引各種道德原則的不同模式。這些發現突顯了在人工系統中實施一致的道德推理的複雜性，以及仔細評估不同模型如何進行道德判斷的必要性。隨著 LLM 持續用於需要道德決策的角色，例如治療師和伴侶，仔細評估對於減輕潛在偏見和限制至關重要。

##### **Towards Transparent and Accurate Diabetes Prediction Using Machine Learning and Explainable Artificial Intelligence**
2501.18071v1 by Pir Bakhsh Khokhar, Viviana Pentangelo, Fabio Palomba, Carmine Gravino

Diabetes mellitus (DM) is a global health issue of significance that must be
diagnosed as early as possible and managed well. This study presents a
framework for diabetes prediction using Machine Learning (ML) models,
complemented with eXplainable Artificial Intelligence (XAI) tools, to
investigate both the predictive accuracy and interpretability of the
predictions from ML models. Data Preprocessing is based on the Synthetic
Minority Oversampling Technique (SMOTE) and feature scaling used on the
Diabetes Binary Health Indicators dataset to deal with class imbalance and
variability of clinical features. The ensemble model provided high accuracy,
with a test accuracy of 92.50% and an ROC-AUC of 0.975. BMI, Age, General
Health, Income, and Physical Activity were the most influential predictors
obtained from the model explanations. The results of this study suggest that ML
combined with XAI is a promising means of developing accurate and
computationally transparent tools for use in healthcare systems.

摘要：糖尿病 (DM) 是一項重要的全球健康議題，必須盡早診斷並妥善管理。本研究提出一個糖尿病預測架構，使用機器學習 (ML) 模型，並搭配可解釋人工智慧 (XAI) 工具，來探討 ML 模型預測的準確度和可解釋性。資料前處理基於合成少數過採樣技術 (SMOTE) 和特徵縮放，用於糖尿病二元健康指標資料集，以處理類別不平衡和臨床特徵的可變性。整合模型提供了高準確度，測試準確度為 92.50%，ROC-AUC 為 0.975。根據模型解釋，BMI、年齡、一般健康狀況、收入和身體活動是最具影響力的預測因子。本研究結果表明，ML 結合 XAI 是一種有前途的方式，可以開發出準確且在運算上透明的工具，用於醫療保健系統。

##### **Current Pathology Foundation Models are unrobust to Medical Center Differences**
2501.18055v2 by Edwin D. de Jong, Eric Marcus, Jonas Teuwen

Pathology Foundation Models (FMs) hold great promise for healthcare. Before
they can be used in clinical practice, it is essential to ensure they are
robust to variations between medical centers. We measure whether pathology FMs
focus on biological features like tissue and cancer type, or on the well known
confounding medical center signatures introduced by staining procedure and
other differences. We introduce the Robustness Index. This novel robustness
metric reflects to what degree biological features dominate confounding
features. Ten current publicly available pathology FMs are evaluated. We find
that all current pathology foundation models evaluated represent the medical
center to a strong degree. Significant differences in the robustness index are
observed. Only one model so far has a robustness index greater than one,
meaning biological features dominate confounding features, but only slightly. A
quantitative approach to measure the influence of medical center differences on
FM-based prediction performance is described. We analyze the impact of
unrobustness on classification performance of downstream models, and find that
cancer-type classification errors are not random, but specifically attributable
to same-center confounders: images of other classes from the same medical
center. We visualize FM embedding spaces, and find these are more strongly
organized by medical centers than by biological factors. As a consequence, the
medical center of origin is predicted more accurately than the tissue source
and cancer type. The robustness index introduced here is provided with the aim
of advancing progress towards clinical adoption of robust and reliable
pathology FMs.

摘要：病理基礎模型 (FM) 對醫療保健而言極具潛力。在臨床實務中使用之前，必須確保它們能應對醫療中心之間的差異。我們衡量病理 FM 是否著重於組織和癌症類型等生物特徵，或著重於染色程序和其他差異所導致的眾所周知混淆醫療中心特徵。我們引進了穩健性指標。這項新穎的穩健性指標反映了生物特徵主導混淆特徵的程度。評估了十項目前公開提供的病理 FM。我們發現，所有目前評估的病理基礎模型在很大程度上代表了醫療中心。觀察到穩健性指標有顯著差異。到目前為止，只有一項模型的穩健性指標大於一，表示生物特徵主導混淆特徵，但僅略微主導。描述了衡量醫療中心差異對基於 FM 的預測效能影響的量化方法。我們分析了不穩健性對下游模型分類效能的影響，發現癌症類型分類錯誤並非隨機，而是特別歸因於同中心混淆因子：來自同一醫療中心的其他類別影像。我們視覺化 FM 嵌入空間，發現這些空間是由醫療中心而非生物因素更強有力地組織。因此，比組織來源和癌症類型更準確地預測了醫療中心的來源。在此引入穩健性指標，目的是推進朝著臨床採用穩健且可靠的病理 FM 的進展。

##### **Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**
2501.17860v1 by Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen

Current medical AI systems often fail to replicate real-world clinical
reasoning, as they are predominantly trained and evaluated on static text and
question-answer tasks. These tuning methods and benchmarks overlook critical
aspects like evidence-based reasoning and handling distracting information. To
bridge this gap, we introduce a novel benchmark that simulates real-world
diagnostic scenarios, integrating noise and difficulty levels aligned with
USMLE standards. Moreover, we explore dialogue-based fine-tuning, which
transforms static datasets into conversational formats to better capture
iterative reasoning processes. Experiments show that dialogue-tuned models
outperform traditional methods, with improvements of $9.64\%$ in multi-round
reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our
findings highlight dialogue tuning as a promising approach for advancing
clinically aligned and robust medical AI systems.

摘要：目前的醫療 AI 系統常無法複製真實世界的臨床推理，因為它們主要在靜態文字和問答任務上受訓和評估。這些調整方法和基準忽略了基於證據的推理和處理分散資訊等關鍵面向。為了彌補這個差距，我們提出一個模擬真實世界診斷情境的全新基準，整合與 USMLE 標準一致的雜訊和難度等級。此外，我們探索以對話為基礎的微調，將靜態資料集轉換為對話格式，以更好地捕捉反覆的推理過程。實驗顯示，對話微調模型優於傳統方法，在多輪推理情境中提升了 9.64%，在有雜訊的環境中提升了 6.18% 的準確度。我們的發現強調對話微調是一種有望推進與臨床相符且強健的醫療 AI 系統的方法。

##### **GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**
2501.17855v1 by Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee

Robot caregiving should be personalized to meet the diverse needs of care
recipients -- assisting with tasks as needed, while taking user agency in
action into account. In physical tasks such as handover, bathing, dressing, and
rehabilitation, a key aspect of this diversity is the functional range of
motion (fROM), which can vary significantly between individuals. In this work,
we learn to predict personalized fROM as a way to generalize robot
decision-making in a wide range of caregiving tasks. We propose a novel
data-driven method for predicting personalized fROM using functional assessment
scores from occupational therapy. We develop a neural model that learns to
embed functional assessment scores into a latent representation of the user's
physical function. The model is trained using motion capture data collected
from users with emulated mobility limitations. After training, the model
predicts personalized fROM for new users without motion capture. Through
simulated experiments and a real-robot user study, we show that the
personalized fROM predictions from our model enable the robot to provide
personalized and effective assistance while improving the user's agency in
action. See our website for more visualizations:
https://emprise.cs.cornell.edu/grace/.

摘要：機器人照護應根據照護對象的不同需求進行客製化，在需要時協助執行任務，同時考量使用者的自主行動。在移交、沐浴、穿衣和復健等身體任務中，這種多樣性的關鍵面向是功能性動作範圍 (fROM)，而這在不同個體之間可能差異很大。在這項工作中，我們學習預測客製化 fROM，作為在廣泛照護任務中概化機器人決策制定的一種方式。我們提出了一種使用職能治療功能評估分數來預測客製化 fROM 的新穎資料驅動方法。我們開發了一個神經模型，學習將功能評估分數嵌入到使用者的身體功能潛在表徵中。該模型使用從具有模擬行動限制的使用者收集的動作擷取資料進行訓練。訓練後，該模型會為沒有動作擷取的新使用者預測客製化 fROM。透過模擬實驗和真實機器人使用者研究，我們展示了我們模型的客製化 fROM 預測使機器人能夠提供客製化且有效的協助，同時提高使用者的自主行動。請參閱我們的網站以取得更多視覺化資料：https://emprise.cs.cornell.edu/grace/。

##### **Tonguescape: Exploring Language Models Understanding of Vowel Articulation**
2501.17643v1 by Haruki Sakajo, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

Vowels are primarily characterized by tongue position. Humans have discovered
these features of vowel articulation through their own experience and explicit
objective observation such as using MRI. With this knowledge and our
experience, we can explain and understand the relationship between tongue
positions and vowels, and this knowledge is helpful for language learners to
learn pronunciation. Since language models (LMs) are trained on a large amount
of data that includes linguistic and medical fields, our preliminary studies
indicate that an LM is able to explain the pronunciation mechanisms of vowels.
However, it is unclear whether multi-modal LMs, such as vision LMs, align
textual information with visual information. One question arises: do LMs
associate real tongue positions with vowel articulation? In this study, we
created video and image datasets from the existing real-time MRI dataset and
investigated whether LMs can understand vowel articulation based on tongue
positions using vision-based information. Our findings suggest that LMs exhibit
potential for understanding vowels and tongue positions when reference examples
are provided while they have difficulties without them. Our code for dataset
building is available on GitHub.

摘要：元音主要由舌頭位置決定。人類透過自己的經驗和明確的客觀觀察（例如使用 MRI）發現了元音發音的這些特徵。有了這些知識和經驗，我們可以解釋和理解舌頭位置和元音之間的關係，而這些知識對語言學習者學習發音很有幫助。由於語言模型 (LM) 是在包含語言學和醫學領域的大量資料上訓練的，我們的初步研究表明，LM 能夠解釋元音的發音機制。然而，尚不清楚多模態 LM（例如視覺 LM）是否將文字資訊與視覺資訊對齊。一個問題產生了：LM 是否將真實的舌頭位置與元音發音聯繫起來？在這項研究中，我們從現有的即時 MRI 資料集中建立了影片和影像資料集，並探討 LM 是否能根據舌頭位置使用基於視覺的資訊來理解元音發音。我們的研究結果表明，當提供參考範例時，LM 具有理解元音和舌頭位置的潛力，而沒有參考範例時則有困難。我們用於建立資料集的程式碼可在 GitHub 上取得。

##### **Layered Chain-of-Thought Prompting for Multi-Agent LLM Systems: A Comprehensive Approach to Explainable Large Language Models**
2501.18645v1 by Manish Sanwal

Large Language Models (LLMs) leverage chain-of-thought (CoT) prompting to
provide step-by-step rationales, improving performance on complex tasks.
Despite its benefits, vanilla CoT often fails to fully verify intermediate
inferences and can produce misleading explanations. In this work, we propose
Layered Chain-of-Thought (Layered-CoT) Prompting, a novel framework that
systematically segments the reasoning process into multiple layers, each
subjected to external checks and optional user feedback. We expand on the key
concepts, present three scenarios -- medical triage, financial risk assessment,
and agile engineering -- and demonstrate how Layered-CoT surpasses vanilla CoT
in terms of transparency, correctness, and user engagement. By integrating
references from recent arXiv papers on interactive explainability, multi-agent
frameworks, and agent-based collaboration, we illustrate how Layered-CoT paves
the way for more reliable and grounded explanations in high-stakes domains.

摘要：大型語言模型 (LLM) 利用思想鏈 (CoT) 提示提供逐步的理由，從而提高複雜任務的執行效能。儘管有其好處，但香草 CoT 經常無法完全驗證中間推論，並且可能產生誤導性的解釋。在這項工作中，我們提出分層思想鏈 (Layered-CoT) 提示，這是一個新穎的框架，它系統性地將推理過程分段成多個層次，每個層次都經過外部檢查和可選的使用者回饋。我們擴展了關鍵概念，提出了三種場景——醫療分流、財務風險評估和敏捷工程——並展示了分層 CoT 在透明度、正確性和使用者參與度方面如何超越香草 CoT。透過整合來自近期 arXiv 論文關於互動可解釋性、多主體框架和基於主體的協作的參考，我們說明了分層 CoT 如何為高風險領域提供更可靠且有根據的解釋鋪路。

##### **An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**
2501.17555v1 by Wenqi Li, Yingli Chen, Keyang Zhou, Xiaoxiao Hu, Zilu Zheng, Yue Yan, Xinpeng Zhang, Wei Tang, Zhenxing Qian

Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms
that account for less than 5% of all pancreatic malignancies, with an incidence
of only 1-1.5 cases per 100,000. Early detection of pNETs is critical for
improving patient survival, but the rarity of pNETs makes segmenting them from
CT a very challenging problem. So far, there has not been a dataset
specifically for pNETs available to researchers. To address this issue, we
propose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography
(CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors,
containing data from 469 patients. This is the first dataset solely dedicated
to pNETs, distinguishing it from previous collections. Additionally, we provide
the baseline detection networks with a new slice-wise weight loss function
designed for the UNet-based model, improving the overall pNET segmentation
performance. We hope that our dataset can enhance the understanding and
diagnosis of pNET Tumors within the medical community, facilitate the
development of more accurate diagnostic tools, and ultimately improve patient
outcomes and advance the field of oncology.

摘要：胰臟神經內分泌腫瘤 (pNETs) 是非常罕見的內分泌腫瘤，僅佔所有胰臟惡性腫瘤的不到 5%，每 100,000 人中僅發生 1-1.5 個病例。早期發現 pNETs 對改善患者存活率至關重要，但 pNETs 的罕見性使得從 CT 中分割它們成為一個非常具有挑戰性的問題。到目前為止，還沒有專門針對 pNETs 的數據集可供研究人員使用。為了解決這個問題，我們提出了一個 pNETs 數據集，一個專注於胰臟神經內分泌腫瘤的標註良好的對比增強電腦斷層掃描 (CECT) 數據集，包含來自 469 名患者的數據。這是第一個專門針對 pNETs 的數據集，這使其有別於之前的收集。此外，我們為基線檢測網路提供了一個新的基於 UNet 模型設計的切片加權損失函數，改善了整體 pNET 分割性能。我們希望我們的數據集能夠增強醫學界對 pNET 腫瘤的理解和診斷，促進更準確的診斷工具的開發，最終改善患者的預後並推進腫瘤學領域。

##### **LLM Assistance for Pediatric Depression**
2501.17510v1 by Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive

Traditional depression screening methods, such as the PHQ-9, are particularly
challenging for children in pediatric primary care due to practical
limitations. AI has the potential to help, but the scarcity of annotated
datasets in mental health, combined with the computational costs of training,
highlights the need for efficient, zero-shot approaches. In this work, we
investigate the feasibility of state-of-the-art LLMs for depressive symptom
extraction in pediatric settings (ages 6-24). This approach aims to complement
traditional screening and minimize diagnostic errors.
  Our findings show that all LLMs are 60% more efficient than word match, with
Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the
extraction of more rare symptoms like "sleep problems" (F1: 0.92) and
"self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and
recall (0.60), performing well in categories like "Feeling depressed" (0.69)
and "Weight change" (0.78). Llama 3, with the highest recall (0.90),
overgeneralizes symptoms, making it less suitable for this type of analysis.
Challenges include the complexity of clinical notes and overgeneralization from
PHQ-9 scores. The main challenges faced by LLMs include navigating the complex
structure of clinical notes with content from different times in the patient
trajectory, as well as misinterpreting elevated PHQ-9 scores.
  We finally demonstrate the utility of symptom annotations provided by Flan as
features in an ML algorithm, which differentiates depression cases from
controls with high precision of 0.78, showing a major performance boost
compared to a baseline that does not use these features.

摘要：<paragraph>傳統的憂鬱症篩檢方法，例如 PHQ-9，由於實際限制，對於小兒科初級照護中的兒童來說特別具有挑戰性。AI 有可能提供幫助，但心理健康中註解資料集的稀少，加上訓練的運算成本，突顯了對有效率的零次學習方法的需求。在這項工作中，我們探討了最先進的 LLM 在小兒科環境（6-24 歲）中提取憂鬱症狀的可行性。這種方法旨在補充傳統篩檢並將診斷錯誤降至最低。我們的研究結果顯示，所有 LLM 的效率都比字詞比對高出 60%，而 Flan 在精確度方面領先（平均 F1：0.65，精確度：0.78），在提取較罕見的症狀方面表現出色，例如「睡眠問題」（F1：0.92）和「自我厭惡」（F1：0.8）。Phi 在精確度（0.44）和召回率（0.60）之間取得平衡，在「感到沮喪」（0.69）和「體重改變」（0.78）等類別中表現良好。擁有最高召回率（0.90）的 Llama 3 會過度概括症狀，使其不太適合此類分析。挑戰包括臨床筆記的複雜性和 PHQ-9 分數的過度概括。LLM 面臨的主要挑戰包括在患者歷程中不同時間的內容中導航臨床筆記的複雜結構，以及誤解 PHQ-9 分數升高。我們最後展示了 Flan 提供的症狀註解作為機器學習演算法中特徵的效用，它以 0.78 的高精確度將憂鬱症病例與對照組區分開來，與不使用這些特徵的基準相比，顯示出主要的效能提升。</paragraph>

##### **Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**
2501.17343v1 by Chongyu Qu, Ritchie Zhao, Ye Yu, Bin Liu, Tianyuan Yao, Junchao Zhu, Bennett A. Landman, Yucheng Tang, Yuankai Huo

Quantizing deep neural networks ,reducing the precision (bit-width) of their
computations, can remarkably decrease memory usage and accelerate processing,
making these models more suitable for large-scale medical imaging applications
with limited computational resources. However, many existing methods studied
"fake quantization", which simulates lower precision operations during
inference, but does not actually reduce model size or improve real-world
inference speed. Moreover, the potential of deploying real 3D low-bit
quantization on modern GPUs is still unexplored. In this study, we introduce a
real post-training quantization (PTQ) framework that successfully implements
true 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation
models, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet,
ST-UNet,and VISTA3D. Our approach involves two main steps. First, we use
TensorRT to perform fake quantization for both weights and activations with
unlabeled calibration dataset. Second, we convert this fake quantization into
real quantization via TensorRT engine on real GPUs, resulting in real-world
reductions in model size and inference latency. Extensive experiments
demonstrate that our framework effectively performs 8-bit quantization on GPUs
without sacrificing model performance. This advancement enables the deployment
of efficient deep learning models in medical imaging applications where
computational resources are constrained. The code and models have been
released, including U-Net, TransUNet pretrained on the BTCV dataset for
abdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset
for whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and
VISTA3D pretrained on TotalSegmentator V2 for full body (104-label)
segmentation. https://github.com/hrlblab/PTQ.

摘要：<paragraph>量化深度神经网络，降低其计算的精度（位宽），可以显著减少内存使用量并加速处理，使这些模型更适合于具有有限计算资源的大规模医学影像应用。然而，许多现有方法研究了“伪量化”，它在推理期间模拟较低精度的操作，但实际上并没有减少模型大小或提高实际推理速度。此外，在现代 GPU 上部署真正的 3D 低位量化的潜力仍未得到探索。在这项研究中，我们引入了一个真正的训练后量化 (PTQ) 框架，该框架成功地在最先进的 (SOTA) 3D 医学分割模型（即 U-Net、SegResNet、SwinUNETR、nnU-Net、UNesT、TransUNet、ST-UNet 和 VISTA3D）上实现了真正的 8 位量化。我们的方法涉及两个主要步骤。首先，我们使用 TensorRT 对权重和激活进行伪量化，并使用未标记的校准数据集。其次，我们将这种伪量化通过真实 GPU 上的 TensorRT 引擎转换为真正的量化，从而在模型大小和推理延迟方面实现了实际的减少。大量的实验表明，我们的框架在 GPU 上有效地执行 8 位量化，而不会牺牲模型性能。这一进步使得在计算资源受限的医学影像应用中部署高效的深度学习模型成为可能。代码和模型已经发布，包括 U-Net、TransUNET，在 BTCV 数据集上预训练用于腹部（13 标签）分割，UNesT 在 Whole Brain 数据集上预训练用于全脑（133 标签）分割，以及 nnU-Net、SegResNet、SwinUNETR 和 VISTA3D 在 TotalSegmentator V2 上预训练用于全身（104 标签）分割。https://github.com/hrlblab/PTQ。</paragraph>

##### **Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**
2501.17338v1 by Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang

Generative Language Models rely on autoregressive decoding to produce the
output sequence token by token. Many tasks such as preference optimization,
require the model to produce task-level output consisting of multiple tokens
directly by selecting candidates from a pool as predictions. Determining a
task-level prediction from candidates using the ordinary token-level decoding
mechanism is constrained by time-consuming decoding and interrupted gradients
by discrete token selection. Existing works have been using decoding-free
candidate selection methods to obtain candidate probability from initial output
logits over vocabulary. Though these estimation methods are widely used, they
are not systematically evaluated, especially on end tasks. We introduce an
evaluation of a comprehensive collection of decoding-free candidate selection
approaches on a comprehensive set of tasks, including five multiple-choice QA
tasks with a small candidate pool and four clinical decision tasks with a
massive amount of candidates, some with 10k+ options. We evaluate the
estimation methods paired with a wide spectrum of foundation LMs covering
different architectures, sizes and training paradigms. The results and insights
from our analysis inform the future model design.

摘要：生成語言模型依靠自迴歸解碼來逐個符號產生輸出序列。許多任務（如偏好最佳化）要求模型直接從候選池中選擇預測，產生由多個符號組成的任務級別輸出。使用一般的符號級別解碼機制從候選者中確定任務級別預測受到耗時的解碼和離散符號選擇中斷的梯度的約束。現有工作一直使用無解碼候選者選擇方法從初始輸出邏輯值中獲得候選者機率。儘管這些估計方法被廣泛使用，但它們並未經過系統評估，特別是在最終任務上。我們針對全面的任務集，包括五個具有小型候選者池的多選題問答任務和四個具有大量候選者的臨床決策任務（其中一些有 10k+ 選項），對全面的無解碼候選者選擇方法進行評估。我們評估與廣泛基礎語言模型配對的估計方法，這些模型涵蓋不同的架構、大小和訓練範例。我們分析的結果和見解為未來的模型設計提供了資訊。

##### **Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**
2501.17326v1 by Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang

Clinical diagnosis prediction models, when provided with a patient's medical
history, aim to detect potential diseases early, facilitating timely
intervention and improving prognostic outcomes. However, the inherent scarcity
of patient data and large disease candidate space often pose challenges in
developing satisfactory models for this intricate task. The exploration of
leveraging Large Language Models (LLMs) for encapsulating clinical decision
processes has been limited. We introduce MERA, a clinical diagnosis prediction
model that bridges pertaining natural language knowledge with medical practice.
We apply hierarchical contrastive learning on a disease candidate ranking list
to alleviate the large decision space issue. With concept memorization through
fine-tuning, we bridge the natural language clinical knowledge with medical
codes. Experimental results on MIMIC-III and IV datasets show that MERA
achieves the state-of-the-art diagnosis prediction performance and dramatically
elevates the diagnosis prediction capabilities of generative LMs.

摘要：臨床診斷預測模型在提供患者病歷的同時，旨在及早發現潛在疾病，促進及時干預並改善預後結果。然而，患者數據的固有稀缺性和大量的疾病候選空間通常對開發令人滿意的模型以應對這項複雜的任務構成挑戰。利用大型語言模型 (LLM) 來封裝臨床決策流程的探索受到限制。我們引入了 MERA，這是一個臨床診斷預測模型，它將相關的自然語言知識與醫療實踐聯繫起來。我們在疾病候選排名清單上應用分層對比學習，以緩解大型決策空間問題。通過微調概念記憶，我們將自然語言臨床知識與醫療代碼聯繫起來。在 MIMIC-III 和 IV 數據集上的實驗結果表明，MERA 達到了最先進的診斷預測性能，並顯著提升了生成式 LM 的診斷預測能力。

##### **Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**
2501.17286v1 by Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu

Background: The radiation oncology clinical practice involves many steps
relying on the dynamic interplay of abundant text data. Large language models
have displayed remarkable capabilities in processing complex text information.
But their direct applications in specific fields like radiation oncology remain
underexplored.
  Purpose: This study aims to investigate whether fine-tuning LLMs with domain
knowledge can improve the performance on Task (1) treatment regimen generation,
Task (2) treatment modality selection (photon, proton, electron, or
brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.
  Methods: Data for 15,724 patient cases were extracted. Cases where patients
had a single diagnostic record, and a clearly identifiable primary treatment
plan were selected for preprocessing and manual annotation to have 7,903 cases
of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.
Each case was used to construct a pair consisting of patient diagnostics
details and an answer (treatment regimen, treatment modality, or ICD-10 code
respectively) for the supervised fine-tuning of these three tasks. Open source
LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the
Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for
the fine-tuned models and original models. Clinical evaluation was performed on
Task (1) by radiation oncologists, while precision, recall, and F-1 score were
evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used
to statistically analyze the results.
  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with
p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the
fine-tuned LLMs-generated treatment regimens were clinically acceptable.
Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.

摘要：<paragraph>背景：放射肿瘤临床实践涉及许多步骤，这些步骤依赖于丰富文本数据的动态交互。大型语言模型在处理复杂的文本信息方面表现出了卓越的能力。但它们在放射肿瘤等特定领域的直接应用仍未得到充分探索。
目的：本研究旨在调查通过领域知识微调 LLM 是否可以提高任务 (1) 治疗方案生成、任务 (2) 治疗方式选择（光子、质子、电子或近距离放射治疗）和任务 (3) 放射肿瘤中 ICD-10 代码预测的性能。
方法：提取了 15,724 例患者病例的数据。选择了患者有单一诊断记录且有明确可识别的主要治疗计划的病例，进行预处理和手动注释，得到 7,903 例患者诊断、治疗计划、治疗方式和 ICD-10 代码。每个病例都用于构建一对，包括患者诊断详情和答案（分别是治疗方案、治疗方式或 ICD-10 代码），用于这三个任务的监督微调。开源 LLaMA2-7B 和 Mistral-7B 模型被用于使用低秩逼近方法进行微调。报告了微调模型和原始模型的准确性和 ROUGE-1 分数。任务 (1) 由放射肿瘤科医师进行临床评估，而任务 (2) 和 (3) 则评估了精确度、召回率和 F-1 分数。单侧 Wilcoxon 符号秩检验用于对结果进行统计分析。
结果：微调后的 LLM 在所有任务中都优于原始 LLM，p 值 <= 0.001。临床评估表明，超过 60% 的微调 LLM 生成的治疗方案在临床上是可接受的。精确度、召回率和 F1 分数显示微调后的 LLM 性能得到改善。</paragraph>

##### **ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification**
2501.17260v1 by Mohammadreza Saraei, Igor Kozak, Eung-Joo Lee

Optical Coherence Tomography (OCT) is a non-invasive imaging modality
essential for diagnosing various eye diseases. Despite its clinical
significance, developing OCT-based diagnostic tools faces challenges, such as
limited public datasets, sparse annotations, and privacy concerns. Although
deep learning has made progress in automating OCT analysis, these challenges
remain unresolved. To address these limitations, we introduce the Vision
Transformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a
novel framework designed to enhance feature extraction and improve diagnostic
accuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining,
Self-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining
phase leverages the OCTMNIST dataset (97,477 unlabeled images across four
disease classes) with data augmentation to create dual-augmented views. A
Vision Transformer (ViT-Base) backbone extracts features, while a negative
cosine similarity loss aligns feature representations. Pretraining is conducted
over 50 epochs with a learning rate of 0.0001 and momentum of 0.999.
Fine-tuning is performed on a stratified 5.129% subset of OCTMNIST using
10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of
0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming
existing SSP-based methods.

摘要：光學相干斷層掃描（OCT）是一種非侵入式影像模式，對於診斷各種眼疾至關重要。儘管其臨床意義重大，但開發基於 OCT 的診斷工具面臨挑戰，例如公共數據集有限、註解稀疏和隱私問題。儘管深度學習在自動化 OCT 分析方面取得了進展，但這些挑戰仍然沒有解決。為了應對這些限制，我們引入了基於 Vision Transformer 的雙流自監督預訓練網路（ViT-2SPN），這是一個新穎的框架，旨在增強特徵提取並提高診斷準確性。ViT-2SPN 採用三階段工作流程：監督預訓練、自監督預訓練（SSP）和監督微調。預訓練階段利用 OCTMNIST 數據集（跨越四個疾病類別的 97,477 張未標記影像）和數據擴充來建立雙重擴充的檢視。視覺轉換器（ViT-Base）主幹提取特徵，而負餘弦相似度損失則校準特徵表示。預訓練在 50 個世代中進行，學習率為 0.0001，動能為 0.999。微調在 OCTMNIST 的分層 5.129% 子集上執行，使用 10 倍交叉驗證。ViT-2SPN 達到了 0.93 的平均 AUC、0.77 的準確率、0.81 的精確度、0.75 的召回率和 0.76 的 F1 分數，優於現有的基於 SSP 的方法。

##### **A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**
2501.17160v1 by Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham

Early detection of COVID-19 is crucial for effective treatment and
controlling its spread. This study proposes a novel hybrid deep learning model
for detecting COVID-19 from CT scan images, designed to assist overburdened
medical professionals. Our proposed model leverages the strengths of VGG16,
DenseNet121, and MobileNetV2 to extract features, followed by Principal
Component Analysis (PCA) for dimensionality reduction, after which the features
are stacked and classified using a Support Vector Classifier (SVC). We
conducted comparative analysis between the proposed hybrid model and individual
pre-trained CNN models, using a dataset of 2,108 training images and 373 test
images comprising both COVID-positive and non-COVID images. Our proposed hybrid
model achieved an accuracy of 98.93%, outperforming the individual models in
terms of precision, recall, F1 scores, and ROC curve performance.

摘要：早期偵測 COVID-19 對有效治療和控制其傳播至關重要。本研究提出一個新穎的深度學習混合模型，用於從電腦斷層掃描影像中偵測 COVID-19，旨在協助負擔過重的醫療專業人員。我們提出的模型利用 VGG16、DenseNet121 和 MobileNetV2 的優點來萃取特徵，接著進行主成分分析 (PCA) 以進行降維，然後將特徵堆疊並使用支持向量分類器 (SVC) 進行分類。我們對提出的混合模型和個別預訓練的 CNN 模型進行比較分析，使用包含 2,108 張訓練影像和 373 張測試影像的資料集，其中包含 COVID-19 陽性影像和非 COVID-19 影像。我們提出的混合模型達到了 98.93% 的準確度，在精準度、召回率、F1 分數和 ROC 曲線效能方面優於個別模型。

##### **Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**
2501.17152v1 by Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani

Three-dimensional (3D) multi-slab acquisition is a technique frequently
employed in high-resolution diffusion-weighted MRI in order to achieve the best
signal-to-noise ratio (SNR) efficiency. However, this technique is limited by
slab boundary artifacts that cause intensity fluctuations and aliasing between
slabs which reduces the accuracy of anatomical imaging. Addressing this issue
is crucial for advancing diffusion MRI quality and making high-resolution
imaging more feasible for clinical and research applications. In this work, we
propose a regularized slab profile encoding (PEN) method within a Plug-and-Play
ADMM framework, incorporating multi-scale energy (MuSE) regularization to
effectively improve the slab combined reconstruction. Experimental results
demonstrate that the proposed method significantly improves image quality
compared to non-regularized and TV-regularized PEN approaches. The regularized
PEN framework provides a more robust and efficient solution for high-resolution
3D diffusion MRI, potentially enabling clearer, more reliable anatomical
imaging across various applications.

摘要：三維 (3D) 多層板擷取是一種技術，經常使用於高解析度擴散加權 MRI，以達到最佳的訊號雜訊比 (SNR) 效率。然而，此技術受到層板邊界偽影的限制，會造成強度波動和層板之間的混疊，降低解剖影像的準確度。解決這個問題對於提升擴散 MRI 品質至關重要，並使高解析度影像更適用於臨床和研究應用。在這項工作中，我們在 Plug-and-Play ADMM 架構內提出正規化的層板輪廓編碼 (PEN) 方法，並結合多尺度能量 (MuSE) 正規化，以有效改善層板組合重建。實驗結果證明，與非正規化和 TV 正規化 PEN 方法相比，所提出的方法顯著提升了影像品質。正規化的 PEN 架構為高解析度 3D 擴散 MRI 提供更強固且有效率的解決方案，潛在可實現更清晰、更可靠的解剖影像，適用於各種應用。

##### **Irony Detection, Reasoning and Understanding in Zero-shot Learning**
2501.16884v1 by Peiling Yi, Yuhan Xia

Irony is a powerful figurative language (FL) on social media that can
potentially mislead various NLP tasks, such as recommendation systems,
misinformation checks, and sentiment analysis. Understanding the implicit
meaning of this kind of subtle language is essential to mitigate irony's
negative impact on NLP tasks. However, building models to understand irony
presents a unique set of challenges, because irony is a complex form of
language that often relies on context, tone, and subtle cues to convey meaning
that is opposite or different from the literal interpretation. Large language
models, such as ChatGPT, are increasingly able to capture implicit and
contextual information. In this study, we investigate the generalization,
reasoning and understanding ability of ChatGPT on irony detection across six
different genre irony detection datasets. Our findings suggest that ChatGPT
appears to show an enhanced language understanding and reasoning ability. But
it needs to be very careful in prompt engineering design. Thus, we propose a
prompt engineering design framework IDADP to achieve higher irony detection
accuracy, improved understanding of irony, and more effective explanations
compared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain
via experiments that the practice generated under the framework is likely to be
the promised solution to resolve the generalization issues of LLMs.

摘要：反諷是一種強大的社交媒體比喻語言 (FL)，可能會誤導各種 NLP 任務，例如推薦系統、錯誤訊息檢查和情緒分析。理解這種微妙語言的隱含含義對於減輕反諷對 NLP 任務的負面影響至關重要。然而，建立模型來理解反諷會帶來一系列獨特的挑戰，因為反諷是一種複雜的語言形式，通常依賴於上下文、語氣和微妙的線索來傳達與字面解釋相反或不同的含義。大型語言模型，例如 ChatGPT，越來越能夠捕捉隱含和上下文信息。在本研究中，我們探討了 ChatGPT 在六個不同類型反諷檢測數據集上的反諷檢測的概括、推理和理解能力。我們的研究結果表明，ChatGPT 似乎表現出增強的語言理解和推理能力。但它需要在提示工程設計中非常小心。因此，我們提出了一個提示工程設計框架 IDADP，以實現更高的反諷檢測準確度、改進的反諷理解以及與其他最先進的 ChatGPT 零次學習方法相比更有效的解釋。並通過實驗確定在該框架下產生的實踐很可能是解決 LLM 概括問題的承諾解決方案。

##### **Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?**
2501.17207v1 by Keqi Han, Yao Su, Lifang He, Liang Zhan, Sergey Plis, Vince Calhoun, Carl Yang

Functional brain connectome is crucial for deciphering the neural mechanisms
underlying cognitive functions and neurological disorders. Graph deep learning
models have recently gained tremendous popularity in this field. However, their
actual effectiveness in modeling the brain connectome remains unclear. In this
study, we re-examine graph deep learning models based on four large-scale
neuroimaging studies encompassing diverse cognitive and clinical outcomes.
Surprisingly, we find that the message aggregation mechanism, a hallmark of
graph deep learning models, does not help with predictive performance as
typically assumed, but rather consistently degrades it. To address this issue,
we propose a hybrid model combining a linear model with a graph attention
network through dual pathways, achieving robust predictions and enhanced
interpretability by revealing both localized and global neural connectivity
patterns. Our findings urge caution in adopting complex deep learning models
for functional brain connectome analysis, emphasizing the need for rigorous
experimental designs to establish tangible performance gains and perhaps more
importantly, to pursue improvements in model interpretability.

摘要：功能性腦連接體對於破譯認知功能和神經疾病背後的機制至關重要。圖形深度學習模型最近在這個領域獲得極大的歡迎。然而，它們在建模腦連接體的實際效能仍不明確。在這項研究中，我們根據四項涵蓋不同認知和臨床結果的大規模神經影像研究，重新檢視圖形深度學習模型。令人驚訝的是，我們發現訊息聚合機制（圖形深度學習模型的標誌）並不像通常假設的那樣有助於預測效能，反而持續降低效能。為了解決這個問題，我們提出一個混合模型，透過雙路徑結合線性模型與圖形注意力網路，達成穩健的預測和增強的可解釋性，方法是揭露局部和整體的神經連接模式。我們的發現敦促在採用複雜的深度學習模型進行功能性腦連接體分析時保持謹慎，強調需要嚴謹的實驗設計，以建立具體的效能增益，或許更重要的是，追求模型可解釋性的改進。

##### **Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care**
2501.17206v1 by Fengpei Yuan, Nehal Hasnaeen, Ran Zhang, Bryce Bible, Joseph Riley Taylor, Hairong Qi, Fenghui Yao, Xiaopeng Zhao

This study explores a novel approach to advancing dementia care by
integrating socially assistive robotics, reinforcement learning (RL), large
language models (LLMs), and clinical domain expertise within a simulated
environment. This integration addresses the critical challenge of limited
experimental data in socially assistive robotics for dementia care, providing a
dynamic simulation environment that realistically models interactions between
persons living with dementia (PLWDs) and robotic caregivers. The proposed
framework introduces a probabilistic model to represent the cognitive and
emotional states of PLWDs, combined with an LLM-based behavior simulation to
emulate their responses. We further develop and train an adaptive RL system
enabling humanoid robots, such as Pepper, to deliver context-aware and
personalized interactions and assistance based on PLWDs' cognitive and
emotional states. The framework also generalizes to computer-based agents,
highlighting its versatility. Results demonstrate that the RL system, enhanced
by LLMs, effectively interprets and responds to the complex needs of PLWDs,
providing tailored caregiving strategies. This research contributes to
human-computer and human-robot interaction by offering a customizable AI-driven
caregiving platform, advancing understanding of dementia-related challenges,
and fostering collaborative innovation in assistive technologies. The proposed
approach has the potential to enhance the independence and quality of life for
PLWDs while alleviating caregiver burden, underscoring the transformative role
of interaction-focused AI systems in dementia care.

摘要：本研究探索一種創新的方法，透過整合社會輔助機器人、強化學習 (RL)、大型語言模型 (LLM) 和臨床領域專業知識於模擬環境中，以推進失智症照護。這種整合解決了失智症照護中社會輔助機器人實驗數據有限的重大挑戰，提供了一個動態的模擬環境，真實地模擬失智症患者 (PLWD) 和機器人照護者之間的互動。所提出的架構引入了機率模型來表示 PLWD 的認知和情緒狀態，並結合了基於 LLM 的行為模擬來模擬他們的反應。我們進一步開發並訓練了一個適應性 RL 系統，使 Pepper 等人形機器人能夠根據 PLWD 的認知和情緒狀態提供情境感知和個人化的互動和協助。該架構也概括到電腦代理，突顯了它的多功能性。結果表明，由 LLM 增強的 RL 系統有效地解釋和回應 PLWD 的複雜需求，提供量身打造的照護策略。這項研究透過提供一個可自訂的 AI 驅動照護平台，促進對失智症相關挑戰的了解，並促進輔助技術的協作創新，為人機互動和人機互動做出貢獻。所提出的方法有可能提高 PLWD 的獨立性和生活品質，同時減輕照護者的負擔，強調了互動導向 AI 系統在失智症照護中的轉型作用。

##### **Efficient Knowledge Distillation of SAM for Medical Image Segmentation**
2501.16740v1 by Kunal Dasharath Patil, Gowthamaan Palani, Ganapathy Krishnamurthi

The Segment Anything Model (SAM) has set a new standard in interactive image
segmentation, offering robust performance across various tasks. However, its
significant computational requirements limit its deployment in real-time or
resource-constrained environments. To address these challenges, we propose a
novel knowledge distillation approach, KD SAM, which incorporates both encoder
and decoder optimization through a combination of Mean Squared Error (MSE) and
Perceptual Loss. This dual-loss framework captures structural and semantic
features, enabling the student model to maintain high segmentation accuracy
while reducing computational complexity. Based on the model evaluation on
datasets, including Kvasir-SEG, ISIC 2017, Fetal Head Ultrasound, and Breast
Ultrasound, we demonstrate that KD SAM achieves comparable or superior
performance to the baseline models, with significantly fewer parameters. KD SAM
effectively balances segmentation accuracy and computational efficiency, making
it well-suited for real-time medical image segmentation applications in
resource-constrained environments.

摘要：分段任何模型 (SAM) 已在互動式影像分割中樹立新標準，在各項任務中皆能提供穩健的效能。然而，其龐大的運算需求限制了它在即時或資源受限環境中的部署。為了應對這些挑戰，我們提出了一種新穎的知識蒸餾方法，KD SAM，它透過結合均方誤差 (MSE) 和感知損失，將編碼器和解碼器最佳化納入其中。此雙重損失架構擷取結構和語義特徵，讓學生模型能夠在降低運算複雜度的同時，維持高分割準確度。根據在 Kvasir-SEG、ISIC 2017、胎兒頭部超音波和乳房超音波等資料集上的模型評估，我們證明 KD SAM 達到了與基準模型相當或更優異的效能，且參數明顯更少。KD SAM 有效地平衡了分割準確度和運算效率，使其非常適合在資源受限環境中的即時醫學影像分割應用。

##### **VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records**
2501.16672v1 by Philip Chung, Akshay Swaminathan, Alex J. Goodell, Yeasul Kim, S. Momsen Reincke, Lichy Han, Ben Deverett, Mohammad Amin Sadeghi, Abdel-Badih Ariss, Marc Ghanem, David Seong, Andrew A. Lee, Caitlin E. Coombes, Brad Bradshaw, Mahir A. Sufian, Hyo Jung Hong, Teresa P. Nguyen, Mohammad R. Rasouli, Komal Kamra, Mark A. Burbridge, James C. McAvoy, Roya Saffary, Stephen P. Ma, Dev Dash, James Xie, Ellen Y. Wang, Clifford A. Schmiesing, Nigam Shah, Nima Aghaeepour

Methods to ensure factual accuracy of text generated by large language models
(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence
system that combines retrieval-augmented generation and LLM-as-a-Judge to
verify whether LLM-generated text is factually supported by a patient's medical
history based on their electronic health record (EHR). To evaluate this system,
we introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course
narratives from discharge summaries into a set of simple statements with
clinician annotations for whether each statement is supported by the patient's
EHR clinical notes. Whereas highest agreement between clinicians was 88.5%,
VeriFact achieves up to 92.7% agreement when compared to a denoised and
adjudicated average human clinican ground truth, suggesting that VeriFact
exceeds the average clinician's ability to fact-check text against a patient's
medical record. VeriFact may accelerate the development of LLM-based EHR
applications by removing current evaluation bottlenecks.

摘要：大型語言模型 (LLM) 在臨床醫學中生成文本的事實準確性，缺乏確保的方法。VeriFact 是一種人工智慧系統，結合了檢索增強生成和 LLM-as-a-Judge，用於驗證 LLM 生成的文本是否基於病人的電子健康記錄 (EHR) 獲得病人的病歷事實支持。為了評估這個系統，我們引入了 VeriFact-BHC，這是一個新的資料集，將出院摘要中的簡要住院病程分解成一組簡單的陳述，並由臨床醫生註解每一個陳述是否獲得病人的 EHR 病歷摘要支持。儘管臨床醫生之間的最高一致性為 88.5%，但與去噪和裁決的平均人類臨床醫生基本事實相比，VeriFact 的一致性高達 92.7%，這表明 VeriFact 超越了平均臨床醫生根據病人的病歷檢查文本事實的能力。VeriFact 可能會透過移除目前的評估瓶頸，加速基於 LLM 的 EHR 應用程式的開發。

##### **Vision-based autonomous structural damage detection using data-driven methods**
2501.16662v2 by Seyyed Taghi Ataei, Parviz Mohammad Zadeh, Saeid Ataei

This study addresses the urgent need for efficient and accurate damage
detection in wind turbine structures, a crucial component of renewable energy
infrastructure. Traditional inspection methods, such as manual assessments and
non-destructive testing (NDT), are often costly, time-consuming, and prone to
human error. To tackle these challenges, this research investigates advanced
deep learning algorithms for vision-based structural health monitoring (SHM). A
dataset of wind turbine surface images, featuring various damage types and
pollution, was prepared and augmented for enhanced model training. Three
algorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed to
detect and classify surface damage. The models were trained and evaluated on a
dataset split into training, testing, and evaluation subsets (80%-10%-10%).
Results indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50
and high processing speed, making it suitable for real-time inspections. By
optimizing hyperparameters like learning rate and batch size, the models'
accuracy and efficiency improved further. YOLOv7 demonstrated significant
advancements in detection precision and execution speed, especially for
real-time applications. However, challenges such as dataset limitations and
environmental variability were noted, suggesting future work on segmentation
methods and larger datasets. This research underscores the potential of
vision-based deep learning techniques to transform SHM practices by reducing
costs, enhancing safety, and improving reliability, thus contributing to the
sustainable maintenance of critical infrastructure and supporting the longevity
of wind energy systems.

摘要：本研究解決了風力渦輪機結構中迫切需要的有效且準確的損傷檢測，這是可再生能源基礎設施的關鍵組成部分。傳統的檢查方法，例如手動評估和非破壞性檢測 (NDT)，通常成本高昂、耗時且容易出錯。為了應對這些挑戰，本研究調查了用於基於視覺的結構健康監測 (SHM) 的先進深度學習演算法。準備了一組風力渦輪機表面影像的資料集，其中包含各種損壞類型和污染，並擴充了增強模型訓練。採用了三種演算法——YOLOv7、其輕量級變體和 Faster R-CNN——來檢測和分類表面損壞。這些模型在分割成訓練、測試和評估子集（80%-10%-10%）的資料集上進行訓練和評估。結果表明，YOLOv7 優於其他演算法，實現了 82.4% 的 mAP@50 和較高的處理速度，使其適用於即時檢查。通過最佳化學習率和批次大小等超參數，模型的準確性和效率進一步提高。YOLOv7 在檢測精度和執行速度方面表現出顯著的進步，特別是對於即時應用程式。然而，注意到資料集限制和環境變異性等挑戰，這表明未來在分割方法和更大的資料集方面的工作。本研究強調了基於視覺的深度學習技術在轉換 SHM 實務方面的潛力，方法是降低成本、增強安全性並提高可靠性，從而有助於維護關鍵基礎設施的可持續性並支持風能系統的長壽命。

##### **Molecular-driven Foundation Model for Oncologic Pathology**
2501.16652v1 by Anurag Vaidya, Andrew Zhang, Guillaume Jaume, Andrew H. Song, Tong Ding, Sophia J. Wagner, Ming Y. Lu, Paul Doucet, Harry Robertson, Cristina Almagro-Perez, Richard J. Chen, Dina ElHarouni, Georges Ayoub, Connor Bossi, Keith L. Ligon, Georg Gerber, Long Phi Le, Faisal Mahmood

Foundation models are reshaping computational pathology by enabling transfer
learning, where models pre-trained on vast datasets can be adapted for
downstream diagnostic, prognostic, and therapeutic response tasks. Despite
these advances, foundation models are still limited in their ability to encode
the entire gigapixel whole-slide images without additional training and often
lack complementary multimodal data. Here, we introduce Threads, a slide-level
foundation model capable of generating universal representations of whole-slide
images of any size. Threads was pre-trained using a multimodal learning
approach on a diverse cohort of 47,171 hematoxylin and eosin (H&E)-stained
tissue sections, paired with corresponding genomic and transcriptomic profiles
- the largest such paired dataset to be used for foundation model development
to date. This unique training paradigm enables Threads to capture the tissue's
underlying molecular composition, yielding powerful representations applicable
to a wide array of downstream tasks. In extensive benchmarking across 54
oncology tasks, including clinical subtyping, grading, mutation prediction,
immunohistochemistry status determination, treatment response prediction, and
survival prediction, Threads outperformed all baselines while demonstrating
remarkable generalizability and label efficiency. It is particularly well
suited for predicting rare events, further emphasizing its clinical utility. We
intend to make the model publicly available for the broader community.

摘要：基礎模型透過啟用轉移學習來重塑計算病理學，其中預先在龐大資料集上訓練的模型可適應於下游診斷、預後和治療反應任務。儘管有這些進展，基礎模型在編碼整個千兆像素全幻燈片影像的能力上仍有限，且經常缺乏補充多模式資料。在此，我們介紹 Threads，這是一個幻燈片層級基礎模型，能夠產生任何大小的全幻燈片影像的通用表示。Threads 使用多模式學習方法預先訓練，並針對 47,171 個蘇木精和曙紅 (H&E) 染色的組織切片的多元群組進行訓練，並搭配對應的基因體和轉錄組特徵檔，這是迄今為止用於基礎模型開發的最大此類配對資料集。這種獨特的訓練範例使 Threads 能夠擷取組織的基礎分子組成，產生強大的表示，適用於廣泛的下游任務。在涵蓋 54 個腫瘤學任務的廣泛基準測試中，包括臨床分型、分級、突變預測、免疫組織化學狀態判定、治療反應預測和存活預測，Threads 優於所有基準，同時展現出顯著的概括性和標籤效率。它特別適合預測罕見事件，進一步強調其臨床效用。我們打算讓該模型公開，供更廣泛的社群使用。

##### **Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models**
2501.16282v1 by Jing Zhang, Xiaowei Yu, Yanjun Lyu, Lu Zhang, Tong Chen, Chao Cao, Yan Zhuang, Minheng Chen, Tianming Liu, Dajiang Zhu

Understanding brain disorders is crucial for accurate clinical diagnosis and
treatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a
promising approach to interpreting medical images with the support of text
descriptions. However, previous research has primarily focused on 2D medical
images, leaving richer spatial information of 3D images under-explored, and
single-modality-based methods are limited by overlooking the critical clinical
information contained in other modalities. To address this issue, this paper
proposes Brain-Adapter, a novel approach that incorporates an extra bottleneck
layer to learn new knowledge and instill it into the original pre-trained
knowledge. The major idea is to incorporate a lightweight bottleneck layer to
train fewer parameters while capturing essential information and utilize a
Contrastive Language-Image Pre-training (CLIP) strategy to align multimodal
data within a unified representation space. Extensive experiments demonstrated
the effectiveness of our approach in integrating multimodal data to
significantly improve the diagnosis accuracy without high computational costs,
highlighting the potential to enhance real-world diagnostic workflows.

摘要：了解腦部疾病對於準確的臨床診斷和治療至關重要。多模態大型語言模型 (MLLM) 的最新進展提供了一個有前途的方法，可以在文本描述的支援下詮釋醫學影像。然而，先前的研究主要集中在 2D 醫學影像，忽略了 3D 影像更豐富的空間資訊，而單一模態方法受到忽視其他模態中關鍵臨床資訊的限制。為了解決這個問題，本文提出了 Brain-Adapter，這是一種新的方法，它結合了一個額外的瓶頸層來學習新知識並將其灌輸到原始預訓練的知識中。主要的想法是結合一個輕量級瓶頸層，在擷取必要資訊的同時訓練較少的參數，並利用對比語言影像預訓練 (CLIP) 策略在統一的表示空間中對齊多模態資料。廣泛的實驗證明了我們的方法在整合多模態資料以顯著提高診斷準確性方面的有效性，而不會造成高運算成本，突顯了增強真實世界診斷工作流程的潛力。

##### **Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models**
2501.16215v1 by Huayu Li, Xiwen Chen, Ci Zhang, Stuart F. Quan, William D. S. Killgore, Shu-Fen Wung, Chen X. Chen, Geng Yuan, Jin Lu, Ao Li

Large language models (LLMs) exhibit remarkable capabilities in visual
inspection of medical time-series data, achieving proficiency comparable to
human clinicians. However, their broad scope limits domain-specific precision,
and proprietary weights hinder fine-tuning for specialized datasets. In
contrast, small specialized models (SSMs) excel in targeted tasks but lack the
contextual reasoning required for complex clinical decision-making. To address
these challenges, we propose ConMIL (Conformalized Multiple Instance Learning),
a decision-support SSM that integrates seamlessly with LLMs. By using Multiple
Instance Learning (MIL) to identify clinically significant signal segments and
conformal prediction for calibrated set-valued outputs, ConMIL enhances LLMs'
interpretative capabilities for medical time-series analysis. Experimental
results demonstrate that ConMIL significantly improves the performance of
state-of-the-art LLMs, such as ChatGPT4.0 and Qwen2-VL-7B. Specifically,
\ConMIL{}-supported Qwen2-VL-7B achieves 94.92% and 96.82% precision for
confident samples in arrhythmia detection and sleep staging, compared to
standalone LLM accuracy of 46.13% and 13.16%. These findings highlight the
potential of ConMIL to bridge task-specific precision and broader contextual
reasoning, enabling more reliable and interpretable AI-driven clinical decision
support.

摘要：大型語言模型 (LLM) 在醫療時間序列資料的視覺檢查中展現出非凡的能力，達到了與人類臨床醫生相當的熟練度。然而，它們的廣泛範圍限制了特定領域的精確度，而專有權重阻礙了針對特定資料集的微調。相比之下，小型專用模型 (SSM) 在目標任務中表現出色，但缺乏複雜臨床決策制定所需的背景推理。為了應對這些挑戰，我們提出了 ConMIL（共形多實例學習），這是一個與 LLM 無縫整合的決策支援 SSM。透過使用多實例學習 (MIL) 來識別臨床顯著訊號區段，並對校準的集合值輸出進行共形預測，ConMIL 增強了 LLM 對醫療時間序列分析的解釋能力。實驗結果表明，ConMIL 明顯改善了最先進 LLM 的效能，例如 ChatGPT4.0 和 Qwen2-VL-7B。具體來說，\ConMIL{}- 支援的 Qwen2-VL-7B 在心律不整偵測和睡眠分期中，對於有信心的樣本達到了 94.92% 和 96.82% 的精確度，而獨立 LLM 的準確度僅為 46.13% 和 13.16%。這些發現突顯了 ConMIL 在橋接特定任務的精確度和更廣泛的背景推理方面的潛力，從而實現更可靠且可解釋的 AI 驅動臨床決策支援。

##### **Atla Selene Mini: A General Purpose Evaluation Model**
2501.17195v1 by Andrei Alexandru, Antonia Calvi, Henry Broomfield, Jackson Golden, Kyle Dai, Mathias Leys, Maurice Burger, Max Bartolo, Roman Engeler, Sashank Pisupati, Toby Drane, Young Sun Park

We introduce Atla Selene Mini, a state-of-the-art small language
model-as-a-judge (SLMJ). Selene Mini is a general-purpose evaluator that
outperforms the best SLMJs and GPT-4o-mini on overall performance across 11
out-of-distribution benchmarks, spanning absolute scoring, classification, and
pairwise preference tasks. It is the highest-scoring 8B generative model on
RewardBench, surpassing strong baselines like GPT-4o and specialized judges. To
achieve this, we develop a principled data curation strategy that augments
public datasets with synthetically generated critiques and ensures high quality
through filtering and dataset ablations. We train our model on a combined
direct preference optimization (DPO) and supervised fine-tuning (SFT) loss, and
produce a highly promptable evaluator that excels in real-world scenarios.
Selene Mini shows dramatically improved zero-shot agreement with human expert
evaluations on financial and medical industry datasets. It is also robust to
variations in prompt format. Preliminary results indicate that Selene Mini is
the top-ranking evaluator in a live, community-driven Judge Arena. We release
the model weights on HuggingFace
(https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B) and Ollama to encourage
widespread community adoption.

摘要：我們介紹 Atla Selene Mini，這是一個最先進的小型語言模型評審 (SLMJ)。Selene Mini 是一個通用評估器，在 11 個分佈外基準測試（包含絕對評分、分類和成對偏好任務）的整體效能上優於最佳的 SLMJ 和 GPT-4o-mini。它是 RewardBench 上得分最高的 8B 生成模型，超越了 GPT-4o 和專業評審等強大的基準。為了達成此目標，我們開發了一種有原則的資料策展策略，利用合成產生的評論擴充公開資料集，並透過篩選和資料集消融確保高品質。我們在結合直接偏好最佳化 (DPO) 和監督微調 (SFT) 損失的資料集上訓練我們的模型，並產生一個高度可提示的評估器，在實際場景中表現出色。Selene Mini 在財務和醫療產業資料集上顯示出顯著改善的零次學習與人類專家評估的一致性。它也對提示格式的變化具有穩健性。初步結果顯示 Selene Mini 是社群驅動的 Judge Arena 中排名第一的評估器。我們在 HuggingFace (https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B) 和 Ollama 上釋出模型權重，以鼓勵廣泛的社群採用。

##### **An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases**
2501.15969v1 by Shaheer Ahmad Khan, Muhammad Usamah Shahid, Ahmad Abdullah, Ibrahim Hashmat, Muddassar Farooq

This study addresses a critical gap in the healthcare system by developing a
clinically meaningful, practical, and explainable disease surveillance system
for multiple chronic diseases, utilizing routine EHR data from multiple U.S.
practices integrated with CureMD's EMR/EHR system. Unlike traditional
systems--using AI models that rely on features from patients' labs--our
approach focuses on routinely available data, such as medical history, vitals,
diagnoses, and medications, to preemptively assess the risks of chronic
diseases in the next year. We trained three distinct models for each chronic
disease: prediction models that forecast the risk of a disease 3, 6, and 12
months before a potential diagnosis. We developed Random Forest models, which
were internally validated using F1 scores and AUROC as performance metrics and
further evaluated by a panel of expert physicians for clinical relevance based
on inferences grounded in medical knowledge. Additionally, we discuss our
implementation of integrating these models into a practical EMR system. Beyond
using Shapley attributes and surrogate models for explainability, we also
introduce a new rule-engineering framework to enhance the intrinsic
explainability of Random Forests.

摘要：本研究透過開發一個臨床有意義、實用且可解釋的多重慢性疾病疾病監測系統，來解決醫療保健系統中的重大缺口，利用整合 CureMD 的 EMR/EHR 系統，來自多個美國實務的例行 EHR 資料。與傳統系統不同的是，我們的做法著重在例行可得的資料，例如病歷、生命徵象、診斷和藥物，以預先評估未來一年慢性疾病的風險，而非仰賴病患實驗室特徵的 AI 模型。我們針對每種慢性疾病訓練了三個不同的模型：預測模型，用以預測在潛在診斷前 3、6 和 12 個月的疾病風險。我們開發了隨機森林模型，並使用 F1 分數和 AUROC 作為效能指標，進行內部驗證，並進一步由專家醫師小組根據植基於醫學知識的推論，評估其臨床相關性。此外，我們討論了將這些模型整合到實用 EMR 系統中的實作方式。除了使用 Shapley 屬性和代理模型來解釋外，我們還引進了一個新的規則工程架構，以增強隨機森林的內在可解釋性。

##### **Leveraging Video Vision Transformer for Alzheimer's Disease Diagnosis from 3D Brain MRI**
2501.15733v1 by Taymaz Akan, Sait Alp, Md. Shenuarin Bhuiyan, Elizabeth A. Disbrow, Steven A. Conrad, John A. Vanchiere, Christopher G. Kevil, Mohammad A. N. Bhuiyan

Alzheimer's disease (AD) is a neurodegenerative disorder affecting millions
worldwide, necessitating early and accurate diagnosis for optimal patient
management. In recent years, advancements in deep learning have shown
remarkable potential in medical image analysis. Methods In this study, we
present "ViTranZheimer," an AD diagnosis approach which leverages video vision
transformers to analyze 3D brain MRI data. By treating the 3D MRI volumes as
videos, we exploit the temporal dependencies between slices to capture
intricate structural relationships. The video vision transformer's
self-attention mechanisms enable the model to learn long-range dependencies and
identify subtle patterns that may indicate AD progression. Our proposed deep
learning framework seeks to enhance the accuracy and sensitivity of AD
diagnosis, empowering clinicians with a tool for early detection and
intervention. We validate the performance of the video vision transformer using
the ADNI dataset and conduct comparative analyses with other relevant models.
Results The proposed ViTranZheimer model is compared with two hybrid models,
CNN-BiLSTM and ViT-BiLSTM. CNN-BiLSTM is the combination of a convolutional
neural network (CNN) and a bidirectional long-short-term memory network
(BiLSTM), while ViT-BiLSTM is the combination of a vision transformer (ViT)
with BiLSTM. The accuracy levels achieved in the ViTranZheimer, CNN-BiLSTM, and
ViT-BiLSTM models are 98.6%, 96.479%, and 97.465%, respectively. ViTranZheimer
demonstrated the highest accuracy at 98.6%, outperforming other models in this
evaluation metric, indicating its superior performance in this specific
evaluation metric. Conclusion This research advances the understanding of
applying deep learning techniques in neuroimaging and Alzheimer's disease
research, paving the way for earlier and less invasive clinical diagnosis.

摘要：阿茲海默症 (AD) 是一種神經退化性疾病，影響著全球數百萬人，因此需要早期準確診斷以進行最佳患者管理。近年來，深度學習的進步在醫學影像分析中展現了非凡的潛力。方法在這個研究中，我們提出「ViTranZheimer」，一種 AD 診斷方法，它利用影片視覺轉換器來分析 3D 大腦 MRI 資料。透過將 3D MRI 體積視為影片，我們利用切片之間的時間依賴性來捕捉複雜的結構關係。影片視覺轉換器的自注意力機制使模型能夠學習長程依賴性，並識別可能表示 AD 進展的細微模式。我們提出的深度學習架構旨在提高 AD 診斷的準確性和敏感性，為臨床醫生提供早期檢測和干預的工具。我們使用 ADNI 資料集驗證影片視覺轉換器的效能，並與其他相關模型進行比較分析。結果所提出的 ViTranZheimer 模型與兩個混合模型 CNN-BiLSTM 和 ViT-BiLSTM 進行比較。CNN-BiLSTM 是卷積神經網路 (CNN) 和雙向長短期記憶網路 (BiLSTM) 的組合，而 ViT-BiLSTM 是視覺轉換器 (ViT) 與 BiLSTM 的組合。在 ViTranZheimer、CNN-BiLSTM 和 ViT-BiLSTM 模型中達到的準確度分別為 98.6%、96.479% 和 97.465%。ViTranZheimer 以 98.6% 的準確度表現最佳，在這個評估指標中優於其他模型，顯示出其在這個特定評估指標中的卓越效能。結論這項研究促進了在神經影像和阿茲海默症研究中應用深度學習技術的理解，為更早、更低侵入性的臨床診斷鋪路。

##### **A Survey on Computational Pathology Foundation Models: Datasets, Adaptation Strategies, and Evaluation Tasks**
2501.15724v1 by Dong Li, Guihong Wan, Xintao Wu, Xinyu Wu, Ajit J. Nirmal, Christine G. Lian, Peter K. Sorger, Yevgeniy R. Semenov, Chen Zhao

Computational pathology foundation models (CPathFMs) have emerged as a
powerful approach for analyzing histopathological data, leveraging
self-supervised learning to extract robust feature representations from
unlabeled whole-slide images. These models, categorized into uni-modal and
multi-modal frameworks, have demonstrated promise in automating complex
pathology tasks such as segmentation, classification, and biomarker discovery.
However, the development of CPathFMs presents significant challenges, such as
limited data accessibility, high variability across datasets, the necessity for
domain-specific adaptation, and the lack of standardized evaluation benchmarks.
This survey provides a comprehensive review of CPathFMs in computational
pathology, focusing on datasets, adaptation strategies, and evaluation tasks.
We analyze key techniques, such as contrastive learning and multi-modal
integration, and highlight existing gaps in current research. Finally, we
explore future directions from four perspectives for advancing CPathFMs. This
survey serves as a valuable resource for researchers, clinicians, and AI
practitioners, guiding the advancement of CPathFMs toward robust and clinically
applicable AI-driven pathology solutions.

摘要：計算病理基礎模型 (CPathFM) 已成為分析組織病理學數據的一種強大方法，利用自我監督學習從未標記的全幻燈片影像中提取穩健的特色表徵。這些模型分為單模態和多模態框架，已證明有望自動化複雜的病理任務，例如分割、分類和生物標記發現。然而，CPathFM 的開發提出了重大挑戰，例如數據可及性有限、數據集之間變異性高、需要特定領域的適應性，以及缺乏標準化的評估基準。這項調查對計算病理學中的 CPathFM 進行了全面的回顧，重點關注數據集、適應策略和評估任務。我們分析了對比學習和多模態整合等關鍵技術，並強調了當前研究中存在的差距。最後，我們從四個角度探討了推進 CPathFM 的未來方向。這項調查作為研究人員、臨床醫生和人工智能從業人員的寶貴資源，指導 CPathFM 朝著穩健且臨床上適用的 AI 驅動病理解決方案邁進。

##### **Beyond Benchmarks: On The False Promise of AI Regulation**
2501.15693v1 by Gabriel Stanovsky, Renana Keydar, Gadi Perl, Eliya Habba

The rapid advancement of artificial intelligence (AI) systems in critical
domains like healthcare, justice, and social services has sparked numerous
regulatory initiatives aimed at ensuring their safe deployment. Current
regulatory frameworks, exemplified by recent US and EU efforts, primarily focus
on procedural guidelines while presuming that scientific benchmarking can
effectively validate AI safety, similar to how crash tests verify vehicle
safety or clinical trials validate drug efficacy. However, this approach
fundamentally misunderstands the unique technical challenges posed by modern AI
systems. Through systematic analysis of successful technology regulation case
studies, we demonstrate that effective scientific regulation requires a causal
theory linking observable test outcomes to future performance - for instance,
how a vehicle's crash resistance at one speed predicts its safety at lower
speeds. We show that deep learning models, which learn complex statistical
patterns from training data without explicit causal mechanisms, preclude such
guarantees. This limitation renders traditional regulatory approaches
inadequate for ensuring AI safety. Moving forward, we call for regulators to
reckon with this limitation, and propose a preliminary two-tiered regulatory
framework that acknowledges these constraints: mandating human oversight for
high-risk applications while developing appropriate risk communication
strategies for lower-risk uses. Our findings highlight the urgent need to
reconsider fundamental assumptions in AI regulation and suggest a concrete path
forward for policymakers and researchers.

摘要：人工智慧 (AI) 系統在醫療保健、司法和社會服務等關鍵領域的快速進展，引發了許多法規倡議，旨在確保其安全部署。以最近美國和歐盟的努力為例，當前的法規框架主要關注程序指南，同時假設科學基準測試可以有效驗證 AI 安全性，類似於碰撞測試驗證車輛安全性或臨床試驗驗證藥物功效。然而，這種方法根本誤解了現代 AI 系統帶來的獨特技術挑戰。透過對成功的技術法規案例研究進行系統分析，我們證明有效的科學法規需要一個因果理論，將可觀察的測試結果與未來的效能聯繫起來——例如，車輛在某一速度下的抗撞性如何預測其在較低速度下的安全性。我們表明深度學習模型從訓練資料中學習複雜的統計模式，而沒有明確的因果機制，排除了這樣的保證。這種限制使得傳統的法規方法不足以確保 AI 安全性。展望未來，我們呼籲監管機構正視這一限制，並提出一個初步的兩層法規框架，承認這些約束：對高風險應用強制人工監督，同時為低風險用途制定適當的風險溝通策略。我們的發現強調了重新考慮 AI 法規中基本假設的迫切需要，並為政策制定者和研究人員提出了具體的進展道路。

##### **Comparative clinical evaluation of "memory-efficient" synthetic 3d generative adversarial networks (gan) head-to-head to state of art: results on computed tomography of the chest**
2501.15572v1 by Mahshid shiri, Chandra Bortolotto, Alessandro Bruno, Alessio Consonni, Daniela Maria Grasso, Leonardo Brizzi, Daniele Loiacono, Lorenzo Preda

Introduction: Generative Adversarial Networks (GANs) are increasingly used to
generate synthetic medical images, addressing the critical shortage of
annotated data for training Artificial Intelligence (AI) systems. This study
introduces a novel memory-efficient GAN architecture, incorporating Conditional
Random Fields (CRFs) to generate high-resolution 3D medical images and
evaluates its performance against the state-of-the-art hierarchical (HA)-GAN
model.
  Materials and Methods: The CRF-GAN was trained using the open-source lung CT
LUNA16 dataset. The architecture was compared to HA-GAN through a quantitative
evaluation, using Frechet Inception Distance (FID) and Maximum Mean Discrepancy
(MMD) metrics, and a qualitative evaluation, through a two-alternative forced
choice (2AFC) test completed by a pool of 12 resident radiologists, in order to
assess the realism of the generated images.
  Results: CRF-GAN outperformed HA-GAN with lower FID (0.047 vs. 0.061) and MMD
(0.084 vs. 0.086) scores, indicating better image fidelity. The 2AFC test
showed a significant preference for images generated by CRF-Gan over those
generated by HA-GAN with a p-value of 1.93e-05. Additionally, CRF-GAN
demonstrated 9.34% lower memory usage at 256 resolution and achieved up to
14.6% faster training speeds, offering substantial computational savings.
  Discussion: CRF-GAN model successfully generates high-resolution 3D medical
images with non-inferior quality to conventional models, while being more
memory-efficient and faster. Computational power and time saved can be used to
improve the spatial resolution and anatomical accuracy of generated images,
which is still a critical factor limiting their direct clinical applicability.

摘要：<paragraph>引言：生成對抗網路 (GAN) 愈來愈常被用於生成合成醫學影像，以解決人工智慧 (AI) 系統訓練中標註資料嚴重短缺的問題。本研究提出了一種新穎的記憶體高效 GAN 架構，結合條件隨機場 (CRF) 來生成高解析度 3D 醫學影像，並評估其相對於最先進的分層 (HA)-GAN 模型的效能。
材料和方法：CRF-GAN 使用開源肺部電腦斷層掃描 LUNA16 資料集進行訓練。透過使用 Fréchet Inception Distance (FID) 和 Maximum Mean Discrepancy (MMD) 指標進行量化評估，以及由 12 位住院放射科醫師組成的團隊完成的兩擇一強制選擇 (2AFC) 測試進行定性評估，將該架構與 HA-GAN 進行比較，以評估生成影像的真實性。
結果：CRF-GAN 以較低的 FID (0.047 對 0.061) 和 MMD (0.084 對 0.086) 分數優於 HA-GAN，表示影像保真度較佳。2AFC 測試顯示，受試者顯著偏好由 CRF-GAN 生成的影像，而非由 HA-GAN 生成的影像，p 值為 1.93e-05。此外，CRF-GAN 在解析度為 256 時的記憶體使用量降低了 9.34%，並將訓練速度提升了 14.6%，提供了大量的運算節省。
討論：CRF-GAN 模型成功地生成了高解析度 3D 醫學影像，其品質不遜於傳統模型，同時更省記憶體且速度更快。節省的運算能力和時間可用於提升生成影像的空間解析度和解剖精確度，這仍然是限制其直接臨床應用性的關鍵因素。</paragraph>

##### **AI in Oncology: Transforming Cancer Detection through Machine Learning and Deep Learning Applications**
2501.15489v1 by Muhammad Aftab, Faisal Mehmood, Chengjuan Zhang, Alishba Nadeem, Zigang Dong, Yanan Jiang, Kangdongs Liu

Artificial intelligence (AI) has potential to revolutionize the field of
oncology by enhancing the precision of cancer diagnosis, optimizing treatment
strategies, and personalizing therapies for a variety of cancers. This review
examines the limitations of conventional diagnostic techniques and explores the
transformative role of AI in diagnosing and treating cancers such as lung,
breast, colorectal, liver, stomach, esophageal, cervical, thyroid, prostate,
and skin cancers. The primary objective of this paper is to highlight the
significant advancements that AI algorithms have brought to oncology within the
medical industry. By enabling early cancer detection, improving diagnostic
accuracy, and facilitating targeted treatment delivery, AI contributes to
substantial improvements in patient outcomes. The integration of AI in medical
imaging, genomic analysis, and pathology enhances diagnostic precision and
introduces a novel, less invasive approach to cancer screening. This not only
boosts the effectiveness of medical facilities but also reduces operational
costs. The study delves into the application of AI in radiomics for detailed
cancer characterization, predictive analytics for identifying associated risks,
and the development of algorithm-driven robots for immediate diagnosis.
Furthermore, it investigates the impact of AI on addressing healthcare
challenges, particularly in underserved and remote regions. The overarching
goal of this platform is to support the development of expert recommendations
and to provide universal, efficient diagnostic procedures. By reviewing
existing research and clinical studies, this paper underscores the pivotal role
of AI in improving the overall cancer care system. It emphasizes how AI-enabled
systems can enhance clinical decision-making and expand treatment options,
thereby underscoring the importance of AI in advancing precision oncology

摘要：人工智能（AI）有潛力透過提升癌症診斷的準確性、優化治療策略，以及為各種癌症提供個人化療法，來徹底改變腫瘤學領域。本篇評論探討傳統診斷技術的限制，並探討 AI 在診斷和治療肺癌、乳癌、大腸直腸癌、肝癌、胃癌、食道癌、子宮頸癌、甲狀腺癌、攝護腺癌和皮膚癌等癌症中轉變性的角色。本文的主要目的是強調 AI 演算法在醫療產業腫瘤學領域帶來的重大進展。透過實現早期癌症偵測、提升診斷準確性，以及促進標靶治療的提供，AI 有助於大幅改善病患的治療結果。AI 整合在醫學影像、基因體分析和病理學中，提升了診斷的準確性，並引進了一種創新、侵入性較低的方法來進行癌症篩檢。這不僅提升了醫療機構的效率，也降低了營運成本。本研究探討了 AI 在放射線組學中的應用，以進行詳細的癌症特徵分析、預測分析以找出相關風險，以及開發演算法驅動的機器人進行立即診斷。此外，它還探討了 AI 在解決醫療保健挑戰中的影響，特別是在服務不足和偏遠地區。此平台的總體目標是支援專家建議的發展，並提供普遍、有效的診斷程序。透過檢視現有的研究和臨床試驗，本文強調了 AI 在改善整體癌症照護系統中的關鍵作用。它強調了 AI 驅動的系統如何能提升臨床決策制定，並擴展治療選項，從而強調了 AI 在推進精準腫瘤學中的重要性。

##### **Identifying Critical Tokens for Accurate Predictions in Transformer-based Medical Imaging Models**
2501.15452v1 by Solha Kang, Joris Vankerschaver, Utku Ozbulak

With the advancements in self-supervised learning (SSL), transformer-based
computer vision models have recently demonstrated superior results compared to
convolutional neural networks (CNNs) and are poised to dominate the field of
artificial intelligence (AI)-based medical imaging in the upcoming years.
Nevertheless, similar to CNNs, unveiling the decision-making process of
transformer-based models remains a challenge. In this work, we take a step
towards demystifying the decision-making process of transformer-based medical
imaging models and propose Token Insight, a novel method that identifies the
critical tokens that contribute to the prediction made by the model. Our method
relies on the principled approach of token discarding native to
transformer-based models, requires no additional module, and can be applied to
any transformer model. Using the proposed approach, we quantify the importance
of each token based on its contribution to the prediction and enable a more
nuanced understanding of the model's decisions. Our experimental results which
are showcased on the problem of colonic polyp identification using both
supervised and self-supervised pretrained vision transformers indicate that
Token Insight contributes to a more transparent and interpretable
transformer-based medical imaging model, fostering trust and facilitating
broader adoption in clinical settings.

摘要：隨著自監督學習 (SSL) 的進展，基於 Transformer 的電腦視覺模型最近已展示出優於卷積神經網路 (CNN) 的卓越成果，並準備在未來幾年主導基於人工智慧 (AI) 的醫學影像領域。儘管如此，與 CNN 類似，揭示基於 Transformer 的模型的決策過程仍然是一項挑戰。在這項工作中，我們朝著揭開基於 Transformer 的醫學影像模型的決策過程邁出了一步，並提出了 Token Insight，這是一種新穎的方法，可以識別對模型所做的預測有貢獻的關鍵 Token。我們的模型依賴於基於 Transformer 的模型的原生 Token 捨棄原理化方法，不需要額外的模組，並且可以應用於任何 Transformer 模型。使用所提出的方法，我們根據每個 Token 對預測的貢獻量化其重要性，並能更細緻地了解模型的決策。我們的實驗結果展示在使用有監督和自監督預訓練視覺 Transformer 的結腸息肉識別問題上，表明 Token Insight 有助於建立更透明且可解釋的基於 Transformer 的醫學影像模型，培養信任並促進在臨床環境中的更廣泛採用。

##### **An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome: Minimizing Research Waste and Advancing Evidence Synthesis**
2501.17181v1 by Arya Rahgozar, Pouria Mortezaagha, Jodi Edwards, Douglas Manuel, Jessie McGowen, Merrick Zwarenstein, Dean Fergusson, Andrea Tricco, Kelly Cobey, Margaret Sampson, Malcolm King, Dawn Richards, Alexandra Bodnaruc, David Moher

The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but
is hindered by inefficiencies in evidence synthesis, poor adherence to quality
standards, and research waste. To address these challenges, we developed an
AI-driven system to enhance systematic reviews in the BHI domain. The system
integrates automated detection of Population, Intervention, Comparator,
Outcome, and Study design (PICOS), semantic search using vector embeddings,
graph-based querying, and topic modeling to identify redundancies and
underexplored areas. Core components include a Bi-LSTM model achieving 87%
accuracy for PICOS compliance, a study design classifier with 95.7% accuracy,
and Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4
for graph-based and topic-driven queries. The system provides real-time
updates, reducing research waste through a living database and offering an
interactive interface with dashboards and conversational AI. While initially
developed for BHI, the system's adaptable architecture enables its application
across various biomedical fields, supporting rigorous evidence synthesis,
efficient resource allocation, and informed clinical decision-making.

摘要：腦心交互組學 (BHI) 結合神經學和心臟學，但受到證據合成效率低、對品質標準的遵守度不佳和研究浪費的阻礙。為了應對這些挑戰，我們開發了一個 AI 驅動系統，以增強 BHI 領域中的系統性回顧。此系統整合了人口、干預、比較、結果和研究設計 (PICOS) 的自動檢測，使用向量嵌入的語義搜尋、基於圖形查詢和主題建模，以識別冗餘和未充分探索的領域。核心組成包括一個雙向 LSTM 模型，PICOS 合規性達到 87% 的準確度，研究設計分類器準確度為 95.7%，以及使用 GPT-3.5 的檢索增強生成 (RAG)，其在基於圖形和主題驅動的查詢方面優於 GPT-4。該系統提供即時更新，透過動態資料庫減少研究浪費，並提供具有儀表板和對話式 AI 的互動介面。儘管最初是為 BHI 開發，但該系統的可適應架構使其能夠應用於各種生物醫學領域，支援嚴謹的證據合成、有效的資源配置和明智的臨床決策制定。

##### **Feedback-Aware Monte Carlo Tree Search for Efficient Information Seeking in Goal-Oriented Conversations**
2501.15056v1 by Harshita Chopra, Chirag Shah

The ability to identify and acquire missing information is a critical
component of effective decision making and problem solving. With the rise of
conversational artificial intelligence (AI) systems, strategically formulating
information-seeking questions becomes crucial and demands efficient methods to
guide the search process. We introduce a novel approach to adaptive
question-asking through a combination of Large Language Models (LLM) for
generating questions that maximize information gain, Monte Carlo Tree Search
(MCTS) for constructing and leveraging a decision tree across multiple samples,
and a hierarchical feedback mechanism to learn from past interactions. We
present two key innovations: (1) an adaptive MCTS algorithm that balances
exploration and exploitation for efficient search over potential questions; and
(2) a clustering-based feedback algorithm that leverages prior experience to
guide future interactions. Each incoming sample is assigned to a cluster based
on its semantic similarity with previously observed samples. Our UCT (Upper
Confidence bound for Trees) formulation selects optimal questions by combining
expected rewards, a function of information gain, with a cluster-specific bonus
that decays with depth, to emphasize the importance of early-stage questions
that have proven effective for narrowing the solution space in similar samples.
Experiments across three domains, including medical diagnosis and
troubleshooting, demonstrate that our method leads to an average of 12%
improvement in success rates and a 10x reduction in the average number of LLM
calls made per conversation for the search process, in comparison to the state
of the art.

摘要：具備辨識與取得遺漏資訊的能力是有效決策和問題解決的關鍵組成部分。隨著對話式人工智慧 (AI) 系統的崛起，策略性地擬定尋求資訊的問題變得至關重要，並需要有效率的方法來引導搜尋流程。我們透過結合大型語言模型 (LLM) 來產生最大化資訊獲取的問題、蒙地卡羅樹狀搜尋 (MCTS) 來建構並利用多個樣本的決策樹，以及分層回饋機制來從過去的互動中學習，提出了一種自適應提問的新方法。我們提出了兩項關鍵創新：(1) 一種自適應 MCTS 演算法，用於平衡探索和利用，以有效搜尋潛在問題；以及 (2) 一種基於聚類的回饋演算法，用於利用先前的經驗來引導未來的互動。每個輸入樣本會根據其與先前觀察到的樣本的語義相似性分配到一個群集。我們的 UCT (樹狀結構的上置信界) 公式透過結合預期的回饋（資訊獲取函數）和隨著深度衰減的特定群集加成，來選擇最佳問題，以強調早期階段問題對於縮小類似樣本中的解空間的重要性。在包括醫療診斷和故障排除在內的三個領域中的實驗證明，與現有技術相比，我們的技術可將成功率平均提升 12%，並將搜尋流程中每次對話所進行的 LLM 呼叫平均次數減少 10 倍。

##### **Motion-enhancement to Echocardiography Segmentation via Inserting a Temporal Attention Module: An Efficient, Adaptable, and Scalable Approach**
2501.14929v1 by Md. Kamrul Hasan, Guang Yang, Choon Hwai Yap

Cardiac anatomy segmentation is essential for clinical assessment of cardiac
function and disease diagnosis to inform treatment and intervention. In
performing segmentation, deep learning (DL) algorithms improved accuracy
significantly compared to traditional image processing approaches. More
recently, studies showed that enhancing DL segmentation with motion information
can further improve it. A range of methods for injecting motion information has
been proposed, but many of them increase the dimensionality of input images
(which is computationally expensive) or have not used an optimal method to
insert motion information, such as non-DL registration, non-attention-based
networks or single-headed attention. Here, we present a novel,
computation-efficient alternative where a novel, scalable temporal attention
module (TAM) extracts temporal feature interactions multiple times and where
TAM has a multi-headed, KQV projection cross-attention architecture. The module
can be seamlessly integrated into a wide range of existing CNN- or
Transformer-based networks, providing novel flexibility for inclusion in future
implementations. Extensive evaluations on different cardiac datasets, 2D
echocardiography (CAMUS), and 3D echocardiography (MITEA) demonstrate the
model's effectiveness when integrated into well-established backbone networks
like UNet, FCN8s, UNetR, SwinUNetR, and the recent I2UNet. We further find that
the optimized TAM-enhanced FCN8s network performs well compared to contemporary
alternatives. Our results confirm TAM's robustness, scalability, and
generalizability across diverse datasets and backbones.

摘要：<paragraph>心臟解剖分割對於評估心臟功能和疾病診斷以提供治療和介入資訊至關重要。在執行分割時，深度學習 (DL) 演算法與傳統影像處理方法相比，準確度顯著提升。最近的研究顯示，透過動作資訊強化 DL 分割可以進一步提升分割效果。已經提出許多用於注入動作資訊的方法，但其中許多方法會增加輸入影像的維度（在運算上很耗費成本），或未使用最佳方法來插入動作資訊，例如非 DL 配準、非基於注意力的網路或單頭注意力。在此，我們提出一個新穎且運算效率高的替代方案，其中一個新穎且可擴充的時序注意力模組 (TAM) 多次提取時序特徵互動，且 TAM 具有多頭、KQV 投影交叉注意力的架構。此模組可以無縫整合到各種現有的基於 CNN 或 Transformer 的網路中，為未來實作的納入提供新穎的靈活性。在不同的心臟資料集、2D 超音波心動圖 (CAMUS) 和 3D 超音波心動圖 (MITEA) 上進行的廣泛評估證明了此模型在整合到 UNet、FCN8s、UNetR、SwinUNetR 和最近的 I2UNet 等完善的主幹網路中的效能。我們進一步發現，經過最佳化的 TAM 增強 FCN8s 網路與當代替代方案相比表現良好。我們的結果證實了 TAM 在不同資料集和主幹中的穩健性、可擴充性和泛化性。</paragraph>

##### **Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**
2501.14892v1 by Hang Luo, Jian Zhang, Chujun Li

In knowledge-intensive tasks, especially in high-stakes domains like medicine
and law, it is critical not only to retrieve relevant information but also to
provide causal reasoning and explainability. Large language models (LLMs) have
achieved remarkable performance in natural language understanding and
generation tasks. However, they often suffer from limitations such as
difficulty in incorporating new knowledge, generating hallucinations, and
explaining their reasoning process. To address these challenges, integrating
knowledge graphs with Graph Retrieval-Augmented Generation (Graph RAG) has
emerged as an effective solution. Traditional Graph RAG methods often rely on
simple graph traversal or semantic similarity, which do not capture causal
relationships or align well with the model's internal reasoning steps. This
paper proposes a novel pipeline that filters large knowledge graphs to
emphasize cause-effect edges, aligns the retrieval process with the model's
chain-of-thought (CoT), and enhances reasoning through multi-stage path
improvements. Experiments on medical question-answering tasks show consistent
gains, with up to a 10\% absolute improvement across multiple large language
models (LLMs). This approach demonstrates the value of combining causal
reasoning with stepwise retrieval, leading to more interpretable and logically
grounded solutions for complex queries.

摘要：在知識密集型任務中，特別是在醫學和法律等高風險領域，不僅檢索相關資訊至關重要，還必須提供因果推理和可解釋性。大型語言模型 (LLM) 在自然語言理解和生成任務中取得了顯著的表現。然而，它們通常會遇到一些限制，例如難以納入新知識、產生幻覺，以及解釋其推理過程。為了應對這些挑戰，將知識圖與圖形檢索增強生成 (Graph RAG) 整合在一起已成為一種有效的解決方案。傳統的 Graph RAG 方法通常依賴於簡單的圖形遍歷或語義相似性，這無法捕捉因果關係或與模型的內部推理步驟很好地對齊。本文提出了一個新穎的管道，該管道過濾大型知識圖以強調因果邊緣，將檢索過程與模型的思想鏈 (CoT) 對齊，並通過多階段路徑改進來增強推理。在醫療問題解答任務上的實驗顯示出一致的收益，在多個大型語言模型 (LLM) 中絕對改進幅度高達 10%。這種方法展示了將因果推理與逐步檢索相結合的價值，從而為複雜查詢提供更具可解釋性和邏輯依據的解決方案。

##### **Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?**
2501.14719v1 by Ipek Baris Schlicht, Zhixue Zhao, Burcu Sayin, Lucie Flek, Paolo Rosso

Equitable access to reliable health information is vital for public health,
but the quality of online health resources varies by language, raising concerns
about inconsistencies in Large Language Models (LLMs) for healthcare. In this
study, we examine the consistency of responses provided by LLMs to
health-related questions across English, German, Turkish, and Chinese. We
largely expand the HealthFC dataset by categorizing health-related questions by
disease type and broadening its multilingual scope with Turkish and Chinese
translations. We reveal significant inconsistencies in responses that could
spread healthcare misinformation. Our main contributions are 1) a multilingual
health-related inquiry dataset with meta-information on disease categories, and
2) a novel prompt-based evaluation workflow that enables sub-dimensional
comparisons between two languages through parsing. Our findings highlight key
challenges in deploying LLM-based tools in multilingual contexts and emphasize
the need for improved cross-lingual alignment to ensure accurate and equitable
healthcare information.

摘要：可靠的健康資訊的公平取得對公共衛生至關重要，
但網路健康資源的品質因語言而異，這引發了對大型語言模型 (LLM) 在醫療保健方面的不一致性的擔憂。在這項研究中，我們探討了 LLM 對英語、德語、土耳其語和中文的健康相關問題所提供回應的一致性。我們透過依疾病類型分類健康相關問題，並透過土耳其語和中文翻譯擴展其多語言範圍，大幅擴展了 HealthFC 資料集。我們揭露了回應中存在顯著的不一致性，這可能會散布醫療保健錯誤資訊。我們的貢獻主要有 1) 一個包含疾病類別元資訊的多語言健康相關查詢資料集，以及 2) 一個新穎的提示式評估工作流程，它能透過解析在兩種語言之間進行次維度比較。我們的研究結果突顯了在多語言環境中部署基於 LLM 的工具的主要挑戰，並強調需要改善跨語言對齊以確保準確且公平的醫療保健資訊。

##### **GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**
2501.16382v1 by Ziwen Li, Xiang 'Anthony' Chen, Youngseung Jeon

Drug discovery (DD) has tremendously contributed to maintaining and improving
public health. Hypothesizing that inhibiting protein misfolding can slow
disease progression, researchers focus on target identification (Target ID) to
find protein structures for drug binding. While Large Language Models (LLMs)
and Retrieval-Augmented Generation (RAG) frameworks have accelerated drug
discovery, integrating models into cohesive workflows remains challenging. We
conducted a user study with drug discovery researchers to identify the
applicability of LLMs and RAGs in Target ID. We identified two main findings:
1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on
an initial protein and protein candidates that have a therapeutic impact; 2)
the model must provide the PPI and relevant explanations for better
understanding. Based on these observations, we identified three limitations in
previous approaches for Target ID: 1) semantic ambiguity, 2) lack of
explainability, and 3) short retrieval units. To address these issues, we
propose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve
agent pipeline RAG framework to support large-scale PPI signaling pathway
exploration in understanding therapeutic impacts by decomposing the analysis of
entire PPI pathways into sub-tasks focused on the analysis of PPI edges.

摘要：药物发现 (DD) 极大地促进了公共卫生的维护和改善。研究人员假设抑制蛋白质错误折叠可以减缓疾病进展，因此专注于靶点识别 (Target ID) 以找到用于药物结合的蛋白质结构。虽然大型语言模型 (LLM) 和检索增强生成 (RAG) 框架加速了药物发现，但将模型整合到内聚工作流中仍然具有挑战性。我们与药物发现研究人员进行了一项用户研究，以确定 LLM 和 RAG 在 Target ID 中的适用性。我们确定了两个主要发现：1) LLM 应该基于初始蛋白质和具有治疗作用的蛋白质候选物提供多个蛋白质-蛋白质相互作用 (PPI)；2) 该模型必须提供 PPI 和相关解释以更好地理解。基于这些观察，我们发现了先前 Target ID 方法中的三个局限性：1) 语义歧义，2) 缺乏可解释性，3) 检索单元短。为了解决这些问题，我们提出了 GraPPI，这是一种基于大规模知识图 (KG) 的检索-分解-求解代理管道 RAG 框架，以支持大规模 PPI 信号通路探索，通过将整个 PPI 通路的分析分解为专注于 PPI 边缘分析的子任务来理解治疗影响。

##### **Rethinking Table Instruction Tuning**
2501.14693v1 by Naihao Deng, Rada Mihalcea

Recent advances in table understanding have focused on instruction-tuning
large language models (LLMs) for table-related tasks. However, existing
research has overlooked the impact of hyperparameter choices and lacks a
comprehensive evaluation of the out-of-domain table understanding ability and
the general capabilities of these table LLMs. In this paper, we evaluate these
abilities in existing table LLMs, and reveal significant declines in both
out-of-domain table understanding and general capabilities compared to their
base models. Through systematic analysis, we show that hyperparameters, such as
learning rate, can significantly influence both table-specific and general
capabilities. Contrary to the existing table instruction-tuning works, we
demonstrate that smaller learning rates and fewer training instances can
enhance table understanding while preserving general capabilities. Based on our
findings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B
Instruct, which achieves performance on par with, or surpassing GPT-3.5 and
GPT-4 on table tasks, while maintaining strong out-of-domain generalization and
general capabilities. Our findings highlight the potential for reduced data
annotation costs and more efficient model development through careful
hyperparameter selection.

摘要：最近表理解的進展集中在指令調校大型語言模型 (LLM) 以執行與表格相關的任務。然而，現有的研究忽略了超參數選擇的影響，並且缺乏對領域外表格理解能力和這些表格 LLM 的一般能力的全面評估。在本文中，我們評估了現有表格 LLM 中的這些能力，並揭示了與其基礎模型相比，領域外表格理解和一般能力都有顯著下降。透過系統分析，我們表明超參數（例如學習率）可以顯著影響特定表格和一般能力。與現有表格指令調校工作相反，我們證明較小的學習率和較少的訓練實例可以在保留一般能力的同時增強表格理解。根據我們的發現，我們引入了 TAMA，這是一個從 LLaMA 3.1 8B Instruct 調校的表格 LLM，它在表格任務上實現了與 GPT-3.5 和 GPT-4 相當或超越的效能，同時保持強大的領域外概化和一般能力。我們的發現強調了透過仔細選擇超參數，降低資料標註成本和更有效率的模型開發的可能性。

##### **Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI**
2501.14689v1 by Dmitry Ryabtsev, Boris Vasilyev, Sergey Shershakov

This paper introduces an innovative software system for fundus image analysis
that deliberately diverges from the conventional screening approach, opting not
to predict specific diagnoses. Instead, our methodology mimics the diagnostic
process by thoroughly analyzing both normal and pathological features of fundus
structures, leaving the ultimate decision-making authority in the hands of
healthcare professionals. Our initiative addresses the need for objective
clinical analysis and seeks to automate and enhance the clinical workflow of
fundus image examination. The system, from its overarching architecture to the
modular analysis design powered by artificial intelligence (AI) models, aligns
seamlessly with ophthalmological practices. Our unique approach utilizes a
combination of state-of-the-art deep learning methods and traditional computer
vision algorithms to provide a comprehensive and nuanced analysis of fundus
structures. We present a distinctive methodology for designing medical
applications, using our system as an illustrative example. Comprehensive
verification and validation results demonstrate the efficacy of our approach in
revolutionizing fundus image analysis, with potential applications across
various medical domains.

摘要：本論文介紹了一種創新的軟體系統，用於眼底影像分析，它刻意偏離傳統的篩檢方法，選擇不預測具體的診斷。相反地，我們的分析方法模擬診斷過程，徹底分析眼底結構的正常和病理特徵，將最終的決策權交到醫療保健專業人員手中。我們的計畫旨在滿足客觀臨床分析的需求，並尋求自動化和強化眼底影像檢查的臨床工作流程。該系統從其整體架構到由人工智慧 (AI) 模型驅動的模組化分析設計，都與眼科實務無縫對齊。我們獨特的方法結合了最先進的深度學習方法和傳統的電腦視覺演算法，提供眼底結構的全面且細緻的分析。我們提出了一種獨特的設計醫療應用方法，並以我們的系統作為說明範例。全面的驗證和驗證結果證明了我們的方法在革新眼底影像分析方面的效力，並具有在各種醫療領域的潛在應用。

##### **Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST**
2501.14685v1 by Fuping Wu, Bartlomiej W. Papiez

Foundation models are widely employed in medical image analysis, due to their
high adaptability and generalizability for downstream tasks. With the
increasing number of foundation models being released, model selection has
become an important issue. In this work, we study the capabilities of
foundation models in medical image classification tasks by conducting a
benchmark study on the MedMNIST dataset. Specifically, we adopt various
foundation models ranging from convolutional to Transformer-based models and
implement both end-to-end training and linear probing for all classification
tasks. The results demonstrate the significant potential of these pre-trained
models when transferred for medical image classification. We further conduct
experiments with different image sizes and various sizes of training data. By
analyzing all the results, we provide preliminary, yet useful insights and
conclusions on this topic.

摘要：基礎模型廣泛用於醫學影像分析，因為它們對下游任務具有高度的適應性和概括性。隨著發布的基礎模型數量越來越多，模型選擇已成為一個重要問題。在這項工作中，我們通過對 MedMNIST 資料集進行基準研究來研究基礎模型在醫學影像分類任務中的能力。具體來說，我們採用了從卷積到基於 Transformer 的模型等各種基礎模型，並對所有分類任務實施端到端訓練和線性探測。結果證明了這些預訓練模型在轉移到醫學影像分類時具有顯著的潛力。我們進一步進行了不同影像大小和各種訓練資料大小的實驗。通過分析所有結果，我們對此主題提供了初步但有用的見解和結論。

##### **MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications**
2501.14654v1 by Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, Andrew Y. Ng, Jonathan H. Chen

Recent large language models (LLMs) have demonstrated significant
advancements, particularly in their ability to serve as agents thereby
surpassing their traditional role as chatbots. These agents can leverage their
planning and tool utilization capabilities to address tasks specified at a high
level. However, a standardized dataset to benchmark the agent capabilities of
LLMs in medical applications is currently lacking, making the evaluation of
LLMs on complex tasks in interactive healthcare environments challenging. To
address this gap, we introduce MedAgentBench, a broad evaluation suite designed
to assess the agent capabilities of large language models within medical
records contexts. MedAgentBench encompasses 100 patient-specific
clinically-derived tasks from 10 categories written by human physicians,
realistic profiles of 100 patients with over 700,000 data elements, a
FHIR-compliant interactive environment, and an accompanying codebase. The
environment uses the standard APIs and communication infrastructure used in
modern EMR systems, so it can be easily migrated into live EMR systems.
MedAgentBench presents an unsaturated agent-oriented benchmark that current
state-of-the-art LLMs exhibit some ability to succeed at. The best model
(GPT-4o) achieves a success rate of 72%. However, there is still substantial
space for improvement to give the community a next direction to optimize.
Furthermore, there is significant variation in performance across task
categories. MedAgentBench establishes this and is publicly available at
https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable
framework for model developers to track progress and drive continuous
improvements in the agent capabilities of large language models within the
medical domain.

摘要：<paragraph>最近的大型语言模型 (LLM) 已展示出显著的进步，特别是在其作为代理的能力方面，从而超越了其作为聊天机器人的传统角色。这些代理可以利用其规划和工具利用能力来解决在高层指定的任务。然而，目前缺乏用于对医疗应用中 LLM 的代理能力进行基准测试的标准化数据集，这使得在交互式医疗保健环境中对 LLM 在复杂任务上的评估具有挑战性。为了解决这一差距，我们引入了 MedAgentBench，这是一个广泛的评估套件，旨在评估大型语言模型在医疗记录背景下的代理能力。MedAgentBench 包含 100 个由人类医生编写的来自 10 个类别的特定于患者的临床任务、100 个患者的真实个人资料（包含超过 700,000 个数据元素）、一个符合 FHIR 的交互式环境以及一个配套的代码库。该环境使用现代 EMR 系统中使用的标准 API 和通信基础设施，因此可以轻松地迁移到实时 EMR 系统中。MedAgentBench 呈现了一个未饱和的以代理为导向的基准，当前最先进的 LLM 表现出一定程度的成功能力。最好的模型 (GPT-4o) 的成功率达到 72%。然而，仍然有很大的改进空间，可以为社区提供优化方向。此外，不同任务类别之间的性能差异很大。MedAgentBench 建立了这一点，并在 https://github.com/stanfordmlgroup/MedAgentBench 公开提供，为模型开发者提供了一个有价值的框架，用于跟踪进度并推动大型语言模型在医疗领域的代理能力的持续改进。</paragraph>

##### **Review and Recommendations for using Artificial Intelligence in Intracoronary Optical Coherence Tomography Analysis**
2501.18614v1 by Xu Chen, Yuan Huang, Benn Jessney, Jason Sangha, Sophie Gu, Carola-Bibiane Schönlieb, Martin Bennett, Michael Roberts

Artificial intelligence (AI) methodologies hold great promise for the rapid
and accurate diagnosis of coronary artery disease (CAD) from intravascular
optical coherent tomography (IVOCT) images. Numerous papers have been published
describing AI-based models for different diagnostic tasks, yet it remains
unclear which models have potential clinical utility and have been properly
validated. This systematic review considered published literature between
January 2015 and February 2023 describing AI-based diagnosis of CAD using
IVOCT. Our search identified 5,576 studies, with 513 included after initial
screening and 35 studies included in the final systematic review after quality
screening. Our findings indicate that most of the identified models are not
currently suitable for clinical use, primarily due to methodological flaws and
underlying biases. To address these issues, we provide recommendations to
improve model quality and research practices to enhance the development of
clinically useful AI products.

摘要：人工智慧 (AI) 方法論對於從血管內光學相干斷層掃描 (IVOCT) 影像快速且準確診斷冠狀動脈疾病 (CAD) 而言，具有很大的前景。許多論文已發表，說明了用於不同診斷任務的 AI 基礎模型，但仍不清楚哪些模型具有潛在的臨床用途，且已獲得適當驗證。這項系統性回顧考量了 2015 年 1 月至 2023 年 2 月間發表的文獻，說明了使用 IVOCT 的 CAD AI 基礎診斷。我們的搜尋辨識出 5,576 項研究，在初步篩選後納入 513 項，在品質篩選後納入 35 項研究進行最終的系統性回顧。我們的發現顯示，大多數已辨識出的模型目前不適合用於臨床，主要是因為方法論上的缺陷和潛在偏差。為了解決這些問題，我們提供建議來改善模型品質和研究實務，以增強臨床有用 AI 產品的開發。

##### **Registration of Longitudinal Liver Examinations for Tumor Progress Assessment**
2501.14483v1 by Walid Yassine, Martin Charachon, Céline Hudelot, Roberto Ardon

Assessing cancer progression in liver CT scans is a clinical challenge,
requiring a comparison of scans at different times for the same patient.
Practitioners must identify existing tumors, compare them with prior exams,
identify new tumors, and evaluate overall disease evolution. This process is
particularly complex in liver examinations due to misalignment between exams
caused by several factors. Indeed, longitudinal liver examinations can undergo
different non-pathological and pathological changes due to non-rigid
deformations, the appearance or disappearance of pathologies, and other
variations. In such cases, existing registration approaches, mainly based on
intrinsic features may distort tumor regions, biasing the tumor progress
evaluation step and the corresponding diagnosis. This work proposes a
registration method based only on geometrical and anatomical information from
liver segmentation, aimed at aligning longitudinal liver images for aided
diagnosis. The proposed method is trained and tested on longitudinal liver CT
scans, with 317 patients for training and 53 for testing. Our experimental
results support our claims by showing that our method is better than other
registration techniques by providing a smoother deformation while preserving
the tumor burden (total volume of tissues considered as tumor) within the
volume. Qualitative results emphasize the importance of smooth deformations in
preserving tumor appearance.

摘要：評估肝臟電腦斷層掃描中的癌症進程是一項臨床上的挑戰，
需要比較同一病患在不同時間點的掃描結果。
從業人員必須辨識現有的腫瘤，將其與先前的檢查結果進行比較，
辨識新的腫瘤，並評估整體疾病的演變。由於種種因素造成檢查結果之間的錯位，這個過程在肝臟檢查中特別複雜。事實上，縱向的肝臟檢查可能會因為非剛性變形、病理的出現或消失，以及其他變化而產生不同的非病理性和病理性的變化。在這種情況下，現有的配準方法（主要基於內在特徵）可能會扭曲腫瘤區域，造成腫瘤進程評估步驟和相應診斷的偏差。本研究提出了一種僅基於肝臟分割的幾何和解剖資訊的配準方法，旨在對縱向肝臟影像進行配準，以協助診斷。所提出的方法在縱向肝臟電腦斷層掃描上進行訓練和測試，訓練資料有 317 位病患，測試資料有 53 位。我們的實驗結果支持我們的說法，證明我們的配準方法比其他配準技術更好，因為它在保留腫瘤負擔（被視為腫瘤的組織總體積）的同時，提供了更平滑的變形。定性結果強調了平滑變形在保留腫瘤外觀方面的重要性。

##### **Pesti-Gen: Unleashing a Generative Molecule Approach for Toxicity Aware Pesticide Design**
2501.14469v1 by Taehan Kim, Wonduk Seo

Global climate change has reduced crop resilience and pesticide efficacy,
making reliance on synthetic pesticides inevitable, even though their
widespread use poses significant health and environmental risks. While these
pesticides remain a key tool in pest management, previous machine-learning
applications in pesticide and agriculture have focused on classification or
regression, leaving the fundamental challenge of generating new molecular
structures or designing novel candidates unaddressed. In this paper, we propose
Pesti-Gen, a novel generative model based on variational auto-encoders,
designed to create pesticide candidates with optimized properties for the first
time. Specifically, Pesti-Gen leverages a two-stage learning process: an
initial pre-training phase that captures a generalized chemical structure
representation, followed by a fine-tuning stage that incorporates
toxicity-specific information. The model simultaneously optimizes over multiple
toxicity metrics, such as (1) livestock toxicity and (2) aqua toxicity to
generate environmentally friendly pesticide candidates. Notably, Pesti-Gen
achieves approximately 68\% structural validity in generating new molecular
structures, demonstrating the model's effectiveness in producing optimized and
feasible pesticide candidates, thereby providing a new way for safer and more
sustainable pest management solutions.

摘要：全球氣候變遷降低了作物的復原力與殺蟲劑的效力，
使得仰賴合成殺蟲劑成為無可避免的趨勢，儘管它們的廣泛使用會帶來重大的健康和環境風險。儘管這些殺蟲劑仍然是蟲害管理中的關鍵工具，過去在殺蟲劑和農業方面的機器學習應用都著重於分類或迴歸，而未解決產生新的分子結構或設計新候選藥劑的基本挑戰。在本文中，我們提出 Pesti-Gen，一種基於變異自動編碼器的創新生成模型，旨在首次建立具有最佳化特性的殺蟲劑候選藥劑。具體來說，Pesti-Gen 採用兩階段學習流程：一個擷取廣義化學結構表示的初始預訓練階段，接著是一個納入毒性特定資訊的微調階段。此模型同時針對多種毒性指標進行最佳化，例如 (1) 牲畜毒性和 (2) 水生毒性，以產生對環境友善的殺蟲劑候選藥劑。值得注意的是，Pesti-Gen 在產生新的分子結構方面達到了約 68% 的結構效度，證明了此模型在產生最佳化且可行的殺蟲劑候選藥劑方面的效能，進而為更安全且更永續的蟲害管理解決方案提供了一種新方法。

##### **ECTIL: Label-efficient Computational Tumour Infiltrating Lymphocyte (TIL) assessment in breast cancer: Multicentre validation in 2,340 patients with breast cancer**
2501.14379v1 by Yoni Schirris, Rosie Voorthuis, Mark Opdam, Marte Liefaard, Gabe S Sonke, Gwen Dackus, Vincent de Jong, Yuwei Wang, Annelot Van Rossum, Tessa G Steenbruggen, Lars C Steggink, Liesbeth G. E. de Vries, Marc van de Vijver, Roberto Salgado, Efstratios Gavves, Paul J van Diest, Sabine C Linn, Jonas Teuwen, Renee Menezes, Marleen Kok, Hugo Horlings

The level of tumour-infiltrating lymphocytes (TILs) is a prognostic factor
for patients with (triple-negative) breast cancer (BC). Computational TIL
assessment (CTA) has the potential to assist pathologists in this
labour-intensive task, but current CTA models rely heavily on many detailed
annotations. We propose and validate a fundamentally simpler deep learning
based CTA that can be trained in only ten minutes on hundredfold fewer
pathologist annotations. We collected whole slide images (WSIs) with TILs
scores and clinical data of 2,340 patients with BC from six cohorts including
three randomised clinical trials. Morphological features were extracted from
whole slide images (WSIs) using a pathology foundation model. Our
label-efficient Computational stromal TIL assessment model (ECTIL) directly
regresses the TILs score from these features. ECTIL trained on only a few
hundred samples (ECTIL-TCGA) showed concordance with the pathologist over five
heterogeneous external cohorts (r=0.54-0.74, AUROC=0.80-0.94). Training on all
slides of five cohorts (ECTIL-combined) improved results on a held-out test set
(r=0.69, AUROC=0.85). Multivariable Cox regression analyses indicated that
every 10% increase of ECTIL scores was associated with improved overall
survival independent of clinicopathological variables (HR 0.86, p<0.01),
similar to the pathologist score (HR 0.87, p<0.001). We demonstrate that ECTIL
is highly concordant with an expert pathologist and obtains a similar hazard
ratio. ECTIL has a fundamentally simpler design than existing methods and can
be trained on orders of magnitude fewer annotations. Such a CTA may be used to
pre-screen patients for, e.g., immunotherapy clinical trial inclusion, or as a
tool to assist clinicians in the diagnostic work-up of patients with BC. Our
model is available under an open source licence
(https://github.com/nki-ai/ectil).

摘要：肿瘤浸润淋巴细胞 (TIL) 的水平是 (三阴性) 乳腺癌 (BC) 患者的预后因素。计算 TIL 评估 (CTA) 有可能协助病理学家完成这项劳动密集型任务，但目前的 CTA 模型严重依赖于许多详细的注释。我们提出并验证了一个基于深度学习的 CTA，它可以在几百倍更少的病理学家注释上仅在十分钟内进行训练。我们从六个队列中收集了 2,340 名 BC 患者的 TILs 评分和临床数据的全玻片图像 (WSI)，其中包括三项随机临床试验。使用病理基础模型从全玻片图像 (WSI) 中提取形态学特征。我们的标签高效计算基质 TIL 评估模型 (ECTIL) 直接从这些特征中回归 TILs 评分。仅在几百个样本上进行训练的 ECTIL（ECTIL-TCGA）显示出与病理学家在五个异质外部队列中的一致性（r=0.54-0.74，AUROC=0.80-0.94）。在五个队列的所有玻片上进行训练（ECTIL-combined）改善了保留测试集上的结果（r=0.69，AUROC=0.85）。多变量 Cox 回归分析表明，ECTIL 评分每增加 10%，与临床病理学变量无关的总体生存率就会提高（HR 0.86，p<0.01），类似于病理学家评分（HR 0.87，p<0.001）。我们证明 ECTIL 与专家病理学家高度一致，并获得了类似的风险比。ECTIL 的设计比现有方法从根本上更简单，并且可以在数量级更少的注释上进行训练。这种 CTA 可用于对患者进行预筛选，例如免疫治疗临床试验纳入，或作为一种工具来帮助临床医生对 BC 患者进行诊断检查。我们的模型可在开放源代码许可下获得 (https://github.com/nki-ai/ectil)。

##### **Optimal Signal Decomposition-based Multi-Stage Learning for Battery Health Estimation**
2501.16377v1 by Vijay Babu Pamshetti, Wei Zhang, King Jet Tseng, Bor Kiat Ng, Qingyu Yan

Battery health estimation is fundamental to ensure battery safety and reduce
cost. However, achieving accurate estimation has been challenging due to the
batteries' complex nonlinear aging patterns and capacity regeneration
phenomena. In this paper, we propose OSL, an optimal signal decomposition-based
multi-stage machine learning for battery health estimation. OSL treats battery
signals optimally. It uses optimized variational mode decomposition to extract
decomposed signals capturing different frequency bands of the original battery
signals. It also incorporates a multi-stage learning process to analyze both
spatial and temporal battery features effectively. An experimental study is
conducted with a public battery aging dataset. OSL demonstrates exceptional
performance with a mean error of just 0.26%. It significantly outperforms
comparison algorithms, both those without and those with suboptimal signal
decomposition and analysis. OSL considers practical battery challenges and can
be integrated into real-world battery management systems, offering a good
impact on battery monitoring and optimization.

摘要：電池健康評估對於確保電池安全和降低成本至關重要。然而，由於電池複雜的非線性老化模式和容量再生現象，要實現準確的評估一直是一項挑戰。在本文中，我們提出 OSL，一種基於最佳信號分解的多階段機器學習，用於電池健康評估。OSL 最佳化處理電池信號。它使用最佳化的變分模式分解來提取分解信號，捕捉原始電池信號的不同頻率帶。它還結合了一個多階段學習過程，以有效分析電池的空間和時間特徵。使用公開電池老化數據集進行了一項實驗研究。OSL 表現出卓越的性能，平均誤差僅為 0.26%。它明顯優於比較演算法，包括沒有次優信號分解和分析的演算法和具有次優信號分解和分析的演算法。OSL 考慮了實際電池挑戰，可以整合到實際電池管理系統中，對電池監控和最佳化產生良好的影響。

##### **Enhancing Multimodal Entity Linking with Jaccard Distance-based Conditional Contrastive Learning and Contextual Visual Augmentation**
2501.14166v1 by Cong-Duy Nguyen, Xiaobao Wu, Thong Nguyen, Shuai Zhao, Khoi Le, Viet-Anh Nguyen, Feng Yichao, Anh Tuan Luu

Previous research on multimodal entity linking (MEL) has primarily employed
contrastive learning as the primary objective. However, using the rest of the
batch as negative samples without careful consideration, these studies risk
leveraging easy features and potentially overlook essential details that make
entities unique. In this work, we propose JD-CCL (Jaccard Distance-based
Conditional Contrastive Learning), a novel approach designed to enhance the
ability to match multimodal entity linking models. JD-CCL leverages
meta-information to select negative samples with similar attributes, making the
linking task more challenging and robust. Additionally, to address the
limitations caused by the variations within the visual modality among mentions
and entities, we introduce a novel method, CVaCPT (Contextual Visual-aid
Controllable Patch Transform). It enhances visual representations by
incorporating multi-view synthetic images and contextual textual
representations to scale and shift patch representations. Experimental results
on benchmark MEL datasets demonstrate the strong effectiveness of our approach.

摘要：先前針對多模態實體連結 (MEL) 的研究主要採用對比學習作為主要目標。然而，這些研究在未經仔細考量的情況下將批次其餘部分用作負樣本，因此有風險會利用容易辨識的特徵，並可能忽略使實體獨一無二的重要細節。在本文中，我們提出 JD-CCL（Jaccard 距離基礎條件對比學習），這是一種新穎的方法，旨在增強多模態實體連結模型的匹配能力。JD-CCL 利用元資訊來選擇具有類似屬性的負樣本，使連結任務更具挑戰性和穩健性。此外，為了解決在提及和實體之間的視覺模式中變異所造成的限制，我們引入了一種新方法，稱為 CVaCPT（脈絡視覺輔助可控區塊轉換）。它透過結合多視角合成影像和脈絡文字表徵來增強視覺表徵，以縮放和轉移區塊表徵。在基準 MEL 資料集上的實驗結果證明了我們方法的強大效能。

##### **Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration**
2501.14158v2 by Mojtaba Safari, Zach Eidex, Chih-Wei Chang, Richard L. J. Qiu, Xiaofeng Yang

Magnetic resonance imaging (MRI) is a non-invasive imaging modality and
provides comprehensive anatomical and functional insights into the human body.
However, its long acquisition times can lead to patient discomfort, motion
artifacts, and limiting real-time applications. To address these challenges,
strategies such as parallel imaging have been applied, which utilize multiple
receiver coils to speed up the data acquisition process. Additionally,
compressed sensing (CS) is a method that facilitates image reconstruction from
sparse data, significantly reducing image acquisition time by minimizing the
amount of data collection needed. Recently, deep learning (DL) has emerged as a
powerful tool for improving MRI reconstruction. It has been integrated with
parallel imaging and CS principles to achieve faster and more accurate MRI
reconstructions. This review comprehensively examines DL-based techniques for
MRI reconstruction. We categorize and discuss various DL-based methods,
including end-to-end approaches, unrolled optimization, and federated learning,
highlighting their potential benefits. Our systematic review highlights
significant contributions and underscores the potential of DL in MRI
reconstruction. Additionally, we summarize key results and trends in DL-based
MRI reconstruction, including quantitative metrics, the dataset, acceleration
factors, and the progress of and research interest in DL techniques over time.
Finally, we discuss potential future directions and the importance of DL-based
MRI reconstruction in advancing medical imaging. To facilitate further research
in this area, we provide a GitHub repository that includes up-to-date DL-based
MRI reconstruction publications and public
datasets-https://github.com/mosaf/Awesome-DL-based-CS-MRI.

摘要：磁振造影 (MRI) 是一種非侵入式影像模式，能提供人體的全面解剖與功能見解。然而，其漫長的擷取時間可能會導致患者不適、動作偽影，並限制即時應用。為了應對這些挑戰，已應用平行影像等策略，利用多個接收器線圈來加速資料擷取過程。此外，壓縮感測 (CS) 是一種促進從稀疏資料重建影像的方法，透過將所需的資料收集量減至最少，大幅減少影像擷取時間。最近，深度學習 (DL) 已成為改善 MRI 重建的強大工具。它已與平行影像和 CS 原則整合，以實現更快、更準確的 MRI 重建。本篇評論全面探討了基於 DL 的 MRI 重建技術。我們分類並討論了各種基於 DL 的方法，包括端對端方法、展開式最佳化和聯盟式學習，並強調了它們的潛在優點。我們的系統性評論突出了重要的貢獻，並強調了 DL 在 MRI 重建中的潛力。此外，我們總結了基於 DL 的 MRI 重建的主要結果和趨勢，包括量化指標、資料集、加速因子，以及隨著時間推移對 DL 技術的進展和研究興趣。最後，我們討論了潛在的未來方向，以及基於 DL 的 MRI 重建在推進醫學影像中的重要性。為了促進這方面的進一步研究，我們提供了一個 GitHub 儲存庫，其中包括最新的基於 DL 的 MRI 重建出版品和公開資料集-https://github.com/mosaf/Awesome-DL-based-CS-MRI。

##### **MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning**
2501.14105v1 by Joshua Davis, Thomas Sounack, Kate Sciacca, Jessie M Brain, Brigitte N Durieux, Nicole D Agaronnik, Charlotta Lindvall

Extracting sections from clinical notes is crucial for downstream analysis
but is challenging due to variability in formatting and labor-intensive nature
of manual sectioning. While proprietary large language models (LLMs) have shown
promise, privacy concerns limit their accessibility. This study develops a
pipeline for automated note sectioning using open-source LLMs, focusing on
three sections: History of Present Illness, Interval History, and Assessment
and Plan. We fine-tuned three open-source LLMs to extract sections using a
curated dataset of 487 progress notes, comparing results relative to
proprietary models (GPT-4o, GPT-4o mini). Internal and external validity were
assessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B
outperformed GPT-4o (F1=0.92). On the external validity test set, performance
remained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary
models in clinical note sectioning, offering advantages in cost, performance,
and accessibility.

摘要：從臨床記錄中萃取區塊對於下游分析至關重要，但由於格式變異和手動分區的勞力密集性質，這是一項挑戰。專有大型語言模型 (LLM) 已展現潛力，但隱私問題限制了其可及性。本研究開發了一個使用開放原始碼 LLM 的自動化記錄分區管線，專注於三個區塊：現病史、間隔病史以及評估和計畫。我們微調了三個開放原始碼 LLM 以使用 487 個進度記錄的精選資料集萃取區塊，並將結果與專有模型 (GPT-4o、GPT-4o mini) 進行比較。內部和外部效度透過準確度、召回率和 F1 分數進行評估。微調後的 Llama 3.1 8B 優於 GPT-4o (F1=0.92)。在外部效度測試集中，效能仍然很高 (F1= 0.85)。微調後的開放原始碼 LLM 能在臨床記錄分區中超越專有模型，在成本、效能和可及性方面提供優勢。

##### **Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models**
2501.14051v1 by Jakob Krogh Petersen, Valdemar Licht, Mads Nielsen, Asbjørn Munk

Multi-modal models require aligned, shared embedding spaces. However, common
CLIP-based approaches need large amounts of samples and do not natively support
3D or tabular data, both of which are crucial in the medical domain. To address
these issues, we revisit CLIP-style alignment by training a domain-specific 3D
foundation model as an image encoder and demonstrate that modality alignment is
feasible with only 62 MRI scans. Our approach is enabled by a simple embedding
accumulation strategy required for training in 3D, which scales the amount of
negative pairs across batches in order to stabilize training. We perform a
thorough evaluation of various design choices, including the choice of backbone
and loss functions, and evaluate the proposed methodology on zero-shot
classification and image-retrieval tasks. While zero-shot image-retrieval
remains challenging, zero-shot classification results demonstrate that the
proposed approach can meaningfully align the representations of 3D MRI with
tabular data.

摘要：多模態模型需要對齊的共用嵌入空間。然而，常見的基於 CLIP 的方法需要大量的樣本，並且原生不支援 3D 或表格資料，而這兩者在醫療領域中都至關重要。為了解決這些問題，我們透過訓練一個領域特定的 3D 基礎模型作為影像編碼器，重新檢視 CLIP 風格的對齊，並證明只要 62 個 MRI 掃描即可達成模態對齊。我們的做法得益於一個簡單的嵌入累積策略，這是 3D 訓練所必需的，它會調整批次中的負對數量以穩定訓練。我們對各種設計選擇進行了徹底的評估，包括主幹和損失函數的選擇，並在零樣本分類和影像檢索任務上評估所提出的方法。儘管零樣本影像檢索仍然具有挑戰性，但零樣本分類結果證明，所提出的方法可以有意義地將 3D MRI 的表示與表格資料對齊。

##### **Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT: Utility for Pancreas Segmentation**
2501.14013v1 by Xinya Wang, Tejas Sudharshan Mathai, Boah Kim, Ronald M. Summers

Multiphase CT studies are routinely obtained in clinical practice for
diagnosis and management of various diseases, such as cancer. However, the CT
studies can be acquired with low radiation doses, different scanners, and are
frequently affected by motion and metal artifacts. Prior approaches have
targeted the quality improvement of one specific CT phase (e.g., non-contrast
CT). In this work, we hypothesized that leveraging multiple CT phases for the
quality enhancement of one phase may prove advantageous for downstream tasks,
such as segmentation. A 3D progressive fusion and non-local (PFNL) network was
developed. It was trained with three degraded (low-quality) phases
(non-contrast, arterial, and portal venous) to enhance the quality of the
portal venous phase. Then, the effect of scan quality enhancement was evaluated
using a proxy task of pancreas segmentation, which is useful for tracking
pancreatic cancer. The proposed approach improved the pancreas segmentation by
3% over the corresponding low-quality CT scan. To the best of our knowledge, we
are the first to harness multiphase CT for scan quality enhancement and
improved pancreas segmentation.

摘要：多相電腦斷層掃描研究在臨床實務中常規取得，用於診斷和管理各種疾病，例如癌症。然而，電腦斷層掃描研究可以用低輻射劑量、不同的掃描儀取得，且經常受到運動和金屬製品影響。先前的做法已針對特定電腦斷層掃描相位（例如非對比電腦斷層掃描）的品質改善。在這項工作中，我們假設利用多個電腦斷層掃描相位來改善一個相位的品質，可能會對下游任務（例如分割）有利。開發了一個 3D 漸進融合和非局部 (PFNL) 網路。它使用三個退化的（低品質）相位（非對比、動脈和門靜脈）進行訓練，以增強門靜脈相位的品質。然後，使用胰臟分割的代理任務評估掃描品質改善的效果，這對於追蹤胰臟癌很有用。所提出的方法將胰臟分割改善了 3%，高於對應的低品質電腦斷層掃描。據我們所知，我們是第一個利用多相電腦斷層掃描進行掃描品質改善和改善胰臟分割的人。

##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

摘要：深度神经网络越来越多地用于高风险医疗应用中，尽管它们在存在虚假相关性的情况下倾向于捷径学习，这在实践中可能产生致命的后果。检测和缓解捷径行为是一项艰巨的任务，通常需要领域专家的大量标记工作。为了缓解这个问题，我们引入了一个半自动框架，用于从数据和模型的角度识别虚假行为，方法是利用可解释人工智能 (XAI) 的见解。这允许检索虚假数据点并检测对关联预测规则进行编码的模型电路。此外，我们演示了如何使用这些捷径编码进行基于 XAI 的样本和像素级数据注释，为偏差缓解方法提供有价值的信息，以消除不需要的捷径行为。我们使用跨越两种方式的四个医学数据集展示了我们框架的适用性，这些数据集具有由数据伪像引起的受控和真实世界虚假相关性。我们成功地识别并减轻了 VGG16、ResNet50 和当代 Vision Transformer 模型中的这些偏差，最终提高了它们的鲁棒性和在真实世界医疗任务中的适用性。

##### **Question Answering on Patient Medical Records with Private Fine-Tuned LLMs**
2501.13687v1 by Sara Kothari, Ayush Gupta

Healthcare systems continuously generate vast amounts of electronic health
records (EHRs), commonly stored in the Fast Healthcare Interoperability
Resources (FHIR) standard. Despite the wealth of information in these records,
their complexity and volume make it difficult for users to retrieve and
interpret crucial health insights. Recent advances in Large Language Models
(LLMs) offer a solution, enabling semantic question answering (QA) over medical
data, allowing users to interact with their health records more effectively.
However, ensuring privacy and compliance requires edge and private deployments
of LLMs.
  This paper proposes a novel approach to semantic QA over EHRs by first
identifying the most relevant FHIR resources for a user query (Task1) and
subsequently answering the query based on these resources (Task2). We explore
the performance of privately hosted, fine-tuned LLMs, evaluating them against
benchmark models such as GPT-4 and GPT-4o. Our results demonstrate that
fine-tuned LLMs, while 250x smaller in size, outperform GPT-4 family models by
0.55% in F1 score on Task1 and 42% on Meteor Task in Task2. Additionally, we
examine advanced aspects of LLM usage, including sequential fine-tuning, model
self-evaluation (narcissistic evaluation), and the impact of training data size
on performance. The models and datasets are available here:
https://huggingface.co/genloop

摘要：醫療保健系統持續產生大量的電子健康紀錄 (EHR)，通常儲存在快速醫療互通性資源 (FHIR) 標準中。儘管這些紀錄中包含豐富的資訊，但其複雜性和龐大數量讓使用者難以擷取和詮釋重要的健康見解。大型語言模型 (LLM) 的最新進展提供了解決方案，能對醫療資料進行語義問答 (QA)，讓使用者能更有效地與其健康紀錄互動。然而，確保隱私和相容性需要 LLM 的邊緣和私人部署。本文提出了語義問答的新方法，先找出與使用者查詢最相關的 FHIR 資源 (任務 1)，然後根據這些資源回答查詢 (任務 2)。我們探討了私人主機、微調 LLM 的效能，並根據 GPT-4 和 GPT-4o 等基準模型評估它們。我們的結果顯示，微調 LLM 的大小雖然小 250 倍，但在任務 1 的 F1 分數上優於 GPT-4 系列模型 0.55%，在任務 2 的 Meteor 任務中優於 42%。此外，我們探討了 LLM 使用的高階面向，包括循序微調、模型自我評估（自戀式評估）和訓練資料大小對效能的影響。模型和資料集在此處提供：https://huggingface.co/genloop

##### **How to Complete Domain Tuning while Keeping General Ability in LLM: Adaptive Layer-wise and Element-wise Regularization**
2501.13669v1 by Shezheng Song, Hao Xu, Jun Ma, Shasha Li, Long Peng, Qian Wan, Xiaodong Liu, Jie Yu

Large Language Models (LLMs) exhibit strong general-purpose language
capabilities. However, fine-tuning these models on domain-specific tasks often
leads to catastrophic forgetting, where the model overwrites or loses essential
knowledge acquired during pretraining. This phenomenon significantly limits the
broader applicability of LLMs. To address this challenge, we propose a novel
approach to compute the element-wise importance of model parameters crucial for
preserving general knowledge during fine-tuning. Our method utilizes a
dual-objective optimization strategy: (1) regularization loss to retain the
parameter crucial for general knowledge; (2) cross-entropy loss to adapt to
domain-specific tasks. Additionally, we introduce layer-wise coefficients to
account for the varying contributions of different layers, dynamically
balancing the dual-objective optimization. Extensive experiments on scientific,
medical, and physical tasks using GPT-J and LLaMA-3 demonstrate that our
approach mitigates catastrophic forgetting while enhancing model adaptability.
Compared to previous methods, our solution is approximately 20 times faster and
requires only 10%-15% of the storage, highlighting the practical efficiency.
The code will be released.

摘要：大型語言模型 (LLM) 展現強大的通用語言能力。然而，針對特定領域任務微調這些模型時，常常會導致災難性遺忘，模型會覆寫或遺失預訓練期間習得的基本知識。這種現象大幅限制了 LLM 的廣泛適用性。為了應對這項挑戰，我們提出了一種新穎方法，用於計算模型參數的元素級重要性，這些參數對於在微調期間保留一般知識至關重要。我們的做法採用雙目標優化策略：(1) 正則化損失，用於保留對一般知識至關重要的參數；(2) 交叉熵損失，用於適應特定領域的任務。此外，我們引入了層級係數，用於考量不同層的變異貢獻，並動態平衡雙目標優化。使用 GPT-J 和 LLaMA-3 在科學、醫療和物理任務上進行的廣泛實驗證明，我們的做法減輕了災難性遺忘，同時增強了模型適應性。與之前的做法相比，我們的解決方案速度快了約 20 倍，而且只需要 10%-15% 的儲存空間，突顯了其實用的效率。程式碼將會釋出。

##### **Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management**
2501.13587v2 by Yuxuan Liu, Jinpei Han, Padmanabhan Ramnarayan, A. Aldo Faisal

Clinical machine learning deployment across institutions faces significant
challenges when patient populations and clinical practices differ
substantially. We present a systematic framework for cross-institutional
knowledge transfer in clinical time series, demonstrated through pediatric
ventilation management between a general pediatric intensive care unit (PICU)
and a cardiac-focused unit. Using contrastive predictive coding (CPC) for
representation learning, we investigate how different data regimes and
fine-tuning strategies affect knowledge transfer across institutional
boundaries. Our results show that while direct model transfer performs poorly,
CPC with appropriate fine-tuning enables effective knowledge sharing between
institutions, with benefits particularly evident in limited data scenarios.
Analysis of transfer patterns reveals an important asymmetry: temporal
progression patterns transfer more readily than point-of-care decisions,
suggesting practical pathways for cross-institutional deployment. Through a
systematic evaluation of fine-tuning approaches and transfer patterns, our work
provides insights for developing more generalizable clinical decision support
systems while enabling smaller specialized units to leverage knowledge from
larger centers.

摘要：臨床機器學習部署在機構間面臨重大挑戰，當患者群體和臨床實務有顯著差異時。我們提出了臨床時間序列跨機構知識轉移的系統性框架，透過一般兒科加護病房 (PICU) 和以心臟為主的病房之間的兒科通氣管理進行示範。透過使用對比預測編碼 (CPC) 進行表徵學習，我們探討不同的資料制度和微調策略如何影響機構間的知識轉移。我們的結果顯示，雖然直接模型轉移表現不佳，但適當微調的 CPC 能夠在機構間進行有效的知識分享，在資料有限的情況下，其優點特別明顯。轉移模式的分析揭示了一個重要的不對稱性：時間進程模式比照護點決策更容易轉移，這表示跨機構部署的實際途徑。透過對微調方法和轉移模式進行系統性評估，我們的研究提供了見解，以便開發更具概括性的臨床決策支援系統，同時讓較小的專科單位能夠利用較大型中心的知識。

##### **LLMs Can Plan Only If We Tell Them**
2501.13545v1 by Bilgehan Sel, Ruoxi Jia, Ming Jin

Large language models (LLMs) have demonstrated significant capabilities in
natural language processing and reasoning, yet their effectiveness in
autonomous planning has been under debate. While existing studies have utilized
LLMs with external feedback mechanisms or in controlled environments for
planning, these approaches often involve substantial computational and
development resources due to the requirement for careful design and iterative
backprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to
match human performance on standard planning benchmarks, such as the
Blocksworld, without additional support. This paper investigates whether LLMs
can independently generate long-horizon plans that rival human baselines. Our
novel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help
achieve state-of-the-art results in planning benchmarks out-competing prior
methods and human baselines all autonomously.

摘要：大型語言模型 (LLM) 在自然語言處理和推理方面展示了顯著的能力，但它們在自主規劃中的有效性一直存在爭議。儘管現有研究已將 LLM 與外部回饋機制結合使用，或在受控環境中進行規劃，但由於需要仔細設計和反覆提示，這些方法通常涉及大量的計算和開發資源。此外，即使是最先進的 LLM（例如 GPT-4）在沒有額外支援的情況下，也很難在標準規劃基準（例如 Blocksworld）上達到人類的表現。本文探討 LLM 是否能獨立生成與人類基準相媲美的長遠計畫。我們對思想演算法 (AoT) 的創新強化（我們稱之為 AoT+）有助於在規劃基準中取得最先進的成果，在完全自主的情況下勝過先前的各種方法和人類基準。

##### **Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**
2501.13984v1 by Bhumika Gupta, Pralaypati Ta, Keerthi Ram, Mohanasankar Sivaprakasam

The updated recommendations on diagnostic procedures and treatment pathways
for a medical condition are documented as graphical flows in Clinical Practice
Guidelines (CPGs). For effective use of the CPGs in helping medical
professionals in the treatment decision process, it is necessary to fully
capture the guideline knowledge, particularly the contexts and their
relationships in the graph. While several existing works have utilized these
guidelines to create rule bases for Clinical Decision Support Systems, limited
work has been done toward directly capturing the full medical knowledge
contained in CPGs. This work proposes an approach to create a contextually
enriched, faithful digital representation of National Comprehensive Cancer
Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and
node & relationship classification. We also implement semantic enrichment of
the model by using Large Language Models (LLMs) for node classification,
achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot
learning, respectively. Additionally, we introduce a methodology for answering
natural language questions with constraints to guideline text by leveraging
LLMs to extract the relevant subgraph from the guideline knowledge base. By
generating natural language answers based on subgraph paths and semantic
information, we mitigate the risk of incorrect answers and hallucination
associated with LLMs, ensuring factual accuracy in medical domain Question
Answering.

摘要：已更新的醫療狀況診斷程序和治療途徑建議，以臨床實務指南 (CPG) 中的圖形流程記錄。為了有效使用 CPG 協助醫療專業人員進行治療決策，必須完整擷取指南知識，特別是圖表中的脈絡及其關係。雖然現有許多研究已利用這些指南為臨床決策支援系統建立規則基礎，但直接擷取 CPG 中包含的完整醫療知識的工作卻有限。這項研究提出了一種方法，以自動化擷取和節點與關係分類的方式，建立脈絡豐富、忠實的國家綜合癌症網路 (NCCN) 癌症 CPG 圖形數位表示。我們也透過使用大型語言模型 (LLM) 進行節點分類，實作模型的語意豐富化，分別在零次學習和少次學習中達到 80.86% 和 88.47% 的準確度。此外，我們引進了一種方法，透過運用 LLM 從指南知識庫中擷取相關子圖，來回答具有指南文字限制的自然語言問題。透過根據子圖路徑和語意資訊產生自然語言答案，我們降低了與 LLM 相關的錯誤答案和幻覺風險，確保了醫療領域問題解答中的事實準確性。

##### **A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability**
2501.13369v1 by Bishwash Paneru, Biplov Paneru, Tanka Mukhiya, Khem Narayan Poudyal

In Nepal, air pollution is a serious public health concern, especially in
cities like Kathmandu where particulate matter (PM2.5 and PM10) has a major
influence on respiratory health and air quality. The Air Quality Index (AQI) is
predicted in this work using a Random Forest Regressor, and the model's
predictions are interpreted using SHAP (SHapley Additive exPlanations)
analysis. With the lowest Testing RMSE (0.23) and flawless R2 scores (1.00),
CatBoost performs better than other models, demonstrating its greater accuracy
and generalization which is cross validated using a nested cross validation
approach. NowCast Concentration and Raw Concentration are the most important
elements influencing AQI values, according to SHAP research, which shows that
the machine learning results are highly accurate. Their significance as major
contributors to air pollution is highlighted by the fact that high values of
these characteristics significantly raise the AQI. This study investigates the
Hydrogen-Alpha (HA) biodegradable filter as a novel way to reduce the related
health hazards. With removal efficiency of more than 98% for PM2.5 and 99.24%
for PM10, the HA filter offers exceptional defense against dangerous airborne
particles. These devices, which are biodegradable face masks and cigarette
filters, address the environmental issues associated with traditional filters'
non-biodegradable trash while also lowering exposure to air contaminants.

摘要：在尼泊爾，空氣污染是一個嚴重的公共衛生問題，特別是在加德滿都等城市，那裡的懸浮微粒（PM2.5 和 PM10）對呼吸系統健康和空氣品質有重大影響。這項工作使用隨機森林回歸器預測空氣品質指數 (AQI)，並使用 SHAP（SHapley 加法解釋）分析來解釋模型的預測。CatBoost 的測試 RMSE 最低（0.23），R2 分數完美（1.00），表現優於其他模型，證明其具有更高的準確性和泛化性，並使用嵌套交叉驗證方法進行交叉驗證。根據 SHAP 研究，現在濃度和原始濃度是影響 AQI 值最重要的元素，這表明機器學習結果非常準確。它們作為空氣污染的主要貢獻者的重要性在於，這些特徵的高值會顯著提高 AQI。本研究探討了氫-α（HA）可生物降解過濾器作為減少相關健康危害的一種新方法。HA 過濾器對 PM2.5 的去除效率超過 98%，對 PM10 的去除效率超過 99.24%，可提供防範危險空氣懸浮微粒的出色防護。這些可生物降解口罩和香菸過濾器的裝置解決了傳統過濾器不可生物降解垃圾相關的環境問題，同時也降低了接觸空氣污染物的風險。

##### **Unveiling Discrete Clues: Superior Healthcare Predictions for Rare Diseases**
2501.16373v1 by Chuang Zhao, Hui Tang, Jiheng Zhang, Xiaomeng Li

Accurate healthcare prediction is essential for improving patient outcomes.
Existing work primarily leverages advanced frameworks like attention or graph
networks to capture the intricate collaborative (CO) signals in electronic
health records. However, prediction for rare diseases remains challenging due
to limited co-occurrence and inadequately tailored approaches. To address this
issue, this paper proposes UDC, a novel method that unveils discrete clues to
bridge consistent textual knowledge and CO signals within a unified semantic
space, thereby enriching the representation semantics of rare diseases.
Specifically, we focus on addressing two key sub-problems: (1) acquiring
distinguishable discrete encodings for precise disease representation and (2)
achieving semantic alignment between textual knowledge and the CO signals at
the code level. For the first sub-problem, we refine the standard vector
quantized process to include condition awareness. Additionally, we develop an
advanced contrastive approach in the decoding stage, leveraging synthetic and
mixed-domain targets as hard negatives to enrich the perceptibility of the
reconstructed representation for downstream tasks. For the second sub-problem,
we introduce a novel codebook update strategy using co-teacher distillation.
This approach facilitates bidirectional supervision between textual knowledge
and CO signals, thereby aligning semantically equivalent information in a
shared discrete latent space. Extensive experiments on three datasets
demonstrate our superiority.

摘要：準確的醫療保健預測對於改善患者的治療結果至關重要。
現有的工作主要利用注意力或圖形網路等先進的框架來捕捉電子健康記錄中複雜的協作 (CO) 信號。然而，由於共現有限和方法調整不足，罕見疾病的預測仍然具有挑戰性。為了解決這個問題，本文提出了 UDC，這是一種新的方法，它揭示了離散線索，以在統一的語義空間中橋接一致的文本知識和 CO 信號，從而豐富罕見疾病的表示語義。
具體來說，我們專注於解決兩個關鍵的子問題：(1) 獲取可區分的離散編碼以進行精確的疾病表示，以及 (2) 在代碼層級上實現文本知識和 CO 信號之間的語義對齊。對於第一個子問題，我們改進了標準向量量化流程以包含條件感知。此外，我們在解碼階段開發了一種先進的對比方法，利用合成和混合域目標作為硬負例來豐富重建表示對下游任務的可感知性。對於第二個子問題，我們使用共同教師蒸餾引入了一種新的代碼簿更新策略。這種方法促進了文本知識和 CO 信號之間的雙向監督，從而在共享的離散潛在空間中對齊語義等價資訊。在三個資料集上的大量實驗證明了我們的優越性。

##### **QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**
2501.13165v1 by Naman Jain, Amir Kalev

We introduce Quantum Feature Extraction (QuFeX), a novel quantum machine
learning module. The proposed module enables feature extraction in a
reduced-dimensional space, significantly decreasing the number of parallel
evaluations required in typical quantum convolutional neural network
architectures. Its design allows seamless integration into deep classical
neural networks, making it particularly suitable for hybrid quantum-classical
models. As an application of QuFeX, we propose Qu-Net -- a hybrid architecture
which integrates QuFeX at the bottleneck of a U-Net architecture. The latter is
widely used for image segmentation tasks such as medical imaging and autonomous
driving. Our numerical analysis indicates that the Qu-Net can achieve superior
segmentation performance compared to a U-Net baseline. These results highlight
the potential of QuFeX to enhance deep neural networks by leveraging hybrid
computational paradigms, providing a path towards a robust framework for
real-world applications requiring precise feature extraction.

摘要：我們引入了量子特徵萃取 (QuFeX)，這是一個創新的量子機器學習模組。所提出的模組可以在降維空間中進行特徵萃取，大幅減少典型量子卷積神經網路架構中所需的並行評估數量。其設計允許無縫整合到深度古典神經網路中，使其特別適合於混合量子古典模型。作為 QuFeX 的應用，我們提出了 Qu-Net，這是一種混合架構，它在 U-Net 架構的瓶頸處整合了 QuFeX。後者廣泛用於影像分割任務，例如醫學影像和自動駕駛。我們的數值分析表明，與 U-Net 基準相比，Qu-Net 可以實現優異的分割效能。這些結果突顯了 QuFeX 透過利用混合運算範例來增強深度神經網路的潛力，為需要精確特徵萃取的真實世界應用程式提供了一個邁向穩健架構的途徑。

##### **AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks**
2501.13141v1 by Qiongyan Wang, Yutong Xia, Siru ZHong, Weichuang Li, Yuankai Wu, Shifen Cheng, Junbo Zhang, Yu Zheng, Yuxuan Liang

Monitoring real-time air quality is essential for safeguarding public health
and fostering social progress. However, the widespread deployment of air
quality monitoring stations is constrained by their significant costs. To
address this limitation, we introduce \emph{AirRadar}, a deep neural network
designed to accurately infer real-time air quality in locations lacking
monitoring stations by utilizing data from existing ones. By leveraging
learnable mask tokens, AirRadar reconstructs air quality features in
unmonitored regions. Specifically, it operates in two stages: first capturing
spatial correlations and then adjusting for distribution shifts. We validate
AirRadar's efficacy using a year-long dataset from 1,085 monitoring stations
across China, demonstrating its superiority over multiple baselines, even with
varying degrees of unobserved data. The source code can be accessed at
https://github.com/CityMind-Lab/AirRadar.

摘要：監控即時空氣品質對於保障公共健康和促進社會進步至關重要。然而，空氣品質監測站的廣泛部署受到其高昂成本的限制。為了解決這個限制，我們引入了 \emph{AirRadar}，這是一個深度神經網路，旨在利用現有監測站的資料，精準推論沒有監測站的地區的即時空氣品質。透過利用可學習的遮罩符號，AirRadar 重建未監控區域的空氣品質特徵。具體來說，它分兩個階段運作：首先擷取空間關聯性，然後調整分佈轉移。我們使用來自中國 1,085 個監測站一整年的資料集驗證了 AirRadar 的功效，證明了它優於多個基準，即使在不同程度的未觀察資料中也是如此。可以在 https://github.com/CityMind-Lab/AirRadar 取得原始程式碼。

##### **Estimating the Conformal Prediction Threshold from Noisy Labels**
2501.12749v1 by Coby Penso, Jacob Goldberger, Ethan Fetaya

Conformal Prediction (CP) is a method to control prediction uncertainty by
producing a small prediction set, ensuring a predetermined probability that the
true class lies within this set. This is commonly done by defining a score,
based on the model predictions, and setting a threshold on this score using a
validation set. In this study, we address the problem of CP calibration when we
only have access to a validation set with noisy labels. We show how we can
estimate the noise-free conformal threshold based on the noisy labeled data.
Our solution is flexible and can accommodate various modeling assumptions
regarding the label contamination process, without needing any information
about the underlying data distribution or the internal mechanisms of the
machine learning classifier. We develop a coverage guarantee for uniform noise
that is effective even in tasks with a large number of classes. We dub our
approach Noise-Aware Conformal Prediction (NACP) and show on several natural
and medical image classification datasets, including ImageNet, that it
significantly outperforms current noisy label methods and achieves results
comparable to those obtained with a clean validation set.

摘要：共形预测 (CP) 是一種透過產生一個小型預測集合來控制預測不確定性的方法，確保真正的類別落在這個集合內的預先確定的機率。這通常是透過定義一個基於模型預測的分數來完成，並使用驗證集合對這個分數設定一個閾值。在本研究中，我們探討了當我們只能存取具有雜訊標籤的驗證集合時，CP 校正的問題。我們展示了如何根據雜訊標籤資料估計無雜訊的共形閾值。我們的解決方案具有彈性，並且可以適應關於標籤污染過程的各種建模假設，而不需要任何關於底層資料分佈或機器學習分類器內部機制的資訊。我們開發了一個對於均勻雜訊的覆蓋保證，即使在具有大量類別的任務中也很有效。我們將我們的做法稱為雜訊感知共形預測 (NACP)，並在幾個自然和醫學影像分類資料集（包括 ImageNet）上展示了它顯著優於目前的雜訊標籤方法，並且達到了與使用乾淨驗證集合獲得的結果相當的結果。

##### **Applications and Challenges of AI and Microscopy in Life Science Research: A Review**
2501.13135v1 by Himanshu Buckchash, Gyanendra Kumar Verma, Dilip K. Prasad

The complexity of human biology and its intricate systems holds immense
potential for advancing human health, disease treatment, and scientific
discovery. However, traditional manual methods for studying biological
interactions are often constrained by the sheer volume and complexity of
biological data. Artificial Intelligence (AI), with its proven ability to
analyze vast datasets, offers a transformative approach to addressing these
challenges. This paper explores the intersection of AI and microscopy in life
sciences, emphasizing their potential applications and associated challenges.
We provide a detailed review of how various biological systems can benefit from
AI, highlighting the types of data and labeling requirements unique to this
domain. Particular attention is given to microscopy data, exploring the
specific AI techniques required to process and interpret this information. By
addressing challenges such as data heterogeneity and annotation scarcity, we
outline potential solutions and emerging trends in the field. Written primarily
from an AI perspective, this paper aims to serve as a valuable resource for
researchers working at the intersection of AI, microscopy, and biology. It
summarizes current advancements, key insights, and open problems, fostering an
understanding that encourages interdisciplinary collaborations. By offering a
comprehensive yet concise synthesis of the field, this paper aspires to
catalyze innovation, promote cross-disciplinary engagement, and accelerate the
adoption of AI in life science research.

摘要：人類生物學及其複雜系統的複雜性蘊藏著促進人類健康、疾病治療和科學發現的巨大潛力。然而，傳統的人工生物交互研究方法通常受到生物數據龐大的數量和複雜性的限制。人工智慧 (AI) 已被證實具有分析龐大數據集的能力，它提供了一種變革性的方法來應對這些挑戰。本文探討了 AI 和顯微鏡在生命科學中的交集，強調了它們的潛在應用和相關挑戰。我們詳細回顧了各種生物系統如何從 AI 中受益，重點介紹了此領域獨有的數據類型和標記要求。特別關注顯微鏡數據，探討處理和解釋此信息的特定 AI 技術。通過應對數據異質性和註釋稀缺性等挑戰，我們概述了該領域的潛在解決方案和新趨勢。本文主要從 AI 的角度撰寫，旨在為在 AI、顯微鏡和生物學交叉領域工作的研究人員提供寶貴的資源。它總結了當前的進展、關鍵見解和未解決的問題，培養了鼓勵跨學科合作的理解。通過提供該領域全面而簡潔的綜合，本文旨在催化創新、促進跨學科參與，並加速 AI 在生命科學研究中的採用。

##### **FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis**
2501.13967v2 by Haoxuan Che, Yifei Wu, Haibo Jin, Yong Xia, Hao Chen

Federated domain generalization aims to train a global model from multiple
source domains and ensure its generalization ability to unseen target domains.
Due to the target domain being with unknown domain shifts, attempting to
approximate these gaps by source domains may be the key to improving model
generalization capability. Existing works mainly focus on sharing and
recombining local domain-specific attributes to increase data diversity and
simulate potential domain shifts. However, these methods may be insufficient
since only the local attribute recombination can be hard to touch the
out-of-distribution of global data. In this paper, we propose a
simple-yet-efficient framework named Federated Domain Adversarial Generation
(FedDAG). It aims to simulate the domain shift and improve the model
generalization by adversarially generating novel domains different from local
and global source domains. Specifically, it generates novel-style images by
maximizing the instance-level feature discrepancy between original and
generated images and trains a generalizable task model by minimizing their
feature discrepancy. Further, we observed that FedDAG could cause different
performance improvements for local models. It may be due to inherent data
isolation and heterogeneity among clients, exacerbating the imbalance in their
generalization contributions to the global model. Ignoring this imbalance can
lead the global model's generalization ability to be sub-optimal, further
limiting the novel domain generation procedure. Thus, to mitigate this
imbalance, FedDAG hierarchically aggregates local models at the within-client
and across-client levels by using the sharpness concept to evaluate client
model generalization contributions. Extensive experiments across four medical
benchmarks demonstrate FedDAG's ability to enhance generalization in federated
medical scenarios.

摘要：聯邦領域泛化旨在從多個來源領域訓練一個全球模型，並確保其對未見目標領域的泛化能力。由於目標領域具有未知的領域轉移，因此嘗試通過來源領域來近似這些差距可能是改進模型泛化能力的關鍵。現有工作主要集中於共享和重新組合本地特定領域屬性，以增加數據多樣性和模擬潛在的領域轉移。然而，這些方法可能不足，因為僅本地屬性重新組合可能難以觸及全球數據的分布外。在本文中，我們提出了一個簡單而高效的框架，稱為聯邦領域對抗生成（FedDAG）。它旨在模擬領域轉移，並通過對抗性地生成不同於本地和全球來源領域的新穎領域來提高模型泛化能力。具體來說，它通過最大化原始圖像和生成圖像之間的實例級別特徵差異來生成新風格的圖像，並通過最小化它們的特徵差異來訓練一個可泛化的任務模型。此外，我們觀察到 FedDAG 可能對本地模型造成不同的性能改進。這可能是由於客戶端之間固有的數據隔離和異質性，加劇了它們對全球模型泛化貢獻的不平衡。忽視這種不平衡可能會導致全球模型的泛化能力次優，進一步限制新域生成過程。因此，為了減輕這種不平衡，FedDAG 使用清晰度概念評估客戶端模型泛化貢獻，在客戶端內和跨客戶端層級分層聚合本地模型。在四個醫學基準上的廣泛實驗證明了 FedDAG 增強聯邦醫療場景中泛化的能力。

##### **CAND: Cross-Domain Ambiguity Inference for Early Detecting Nuanced Illness Deterioration**
2501.16365v1 by Lo Pang-Yun Ting, Zhen Tan, Hong-Pei Chen, Cheng-Te Li, Po-Lin Chen, Kun-Ta Chuang, Huan Liu

Early detection of patient deterioration is essential for timely treatment,
with vital signs like heart rates being key health indicators. Existing methods
tend to solely analyze vital sign waveforms, ignoring transition relationships
of waveforms within each vital sign and the correlation strengths among various
vital signs. Such studies often overlook nuanced illness deterioration, which
is the early sign of worsening health but is difficult to detect. In this
paper, we introduce CAND, a novel method that organizes the transition
relationships and the correlations within and among vital signs as
domain-specific and cross-domain knowledge. CAND jointly models these knowledge
in a unified representation space, considerably enhancing the early detection
of nuanced illness deterioration. In addition, CAND integrates a Bayesian
inference method that utilizes augmented knowledge from domain-specific and
cross-domain knowledge to address the ambiguities in correlation strengths.
With this architecture, the correlation strengths can be effectively inferred
to guide joint modeling and enhance representations of vital signs. This allows
a more holistic and accurate interpretation of patient health. Our experiments
on a real-world ICU dataset demonstrate that CAND significantly outperforms
existing methods in both effectiveness and earliness in detecting nuanced
illness deterioration. Moreover, we conduct a case study for the interpretable
detection process to showcase the practicality of CAND.

摘要：早期發現病患惡化情形對於及時治療至關重要，
而像心率等生命徵象是關鍵的健康指標。現有方法
傾向於只分析生命徵象波形，忽略各生命徵象內波形的轉換關係
以及各種生命徵象之間的關聯強度。此類研究往往忽略細微的病況惡化，
這是健康惡化的早期徵兆，但難以偵測。在本文中，
我們介紹 CAND，這是一種新方法，可整理生命徵象內部和之間的轉換
關係和關聯，作為特定領域和跨領域知識。CAND 聯合建模這些知識
在統一的表示空間中，大幅提升細微病況惡化的早期偵測。此外，CAND 整合貝氏
推論方法，利用來自特定領域和跨領域知識的擴充知識來解決關聯強度中的模糊性。
有了這個架構，關聯強度可以有效推論，以引導聯合建模並增強生命徵象的表示。這允許
更全面且準確地詮釋病患健康。我們在真實世界 ICU 資料集上的實驗
證明 CAND 在偵測細微病況惡化方面，無論在有效性還是早期發現上都明顯優於
現有方法。此外，我們進行一個可詮釋偵測過程的案例研究，以展示 CAND 的實用性。

##### **Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related to Post COVID-19 Condition**
2501.12538v2 by Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi

Understanding the prevalence, disparities, and symptom variations of Post
COVID-19 Condition (PCC) for vulnerable populations is crucial to improving
care and addressing intersecting inequities. This study aims to develop a
comprehensive framework for integrating social determinants of health (SDOH)
into PCC research by leveraging NLP techniques to analyze disparities and
variations in SDOH representation within PCC case reports. Following
construction of a PCC Case Report Corpus, comprising over 7,000 case reports
from the LitCOVID repository, a subset of 709 reports were annotated with 26
core SDOH-related entity types using pre-trained named entity recognition (NER)
models, human review, and data augmentation to improve quality, diversity and
representation of entity types. An NLP pipeline integrating NER, natural
language inference (NLI), trigram and frequency analyses was developed to
extract and analyze these entities. Both encoder-only transformer models and
RNN-based models were assessed for the NER objective.
  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models
in generalizability to distinct sentence structures and greater class sparsity.
Exploratory analysis revealed variability in entity richness, with prevalent
entities like condition, age, and access to care, and underrepresentation of
sensitive categories like race and housing status. Trigram analysis highlighted
frequent co-occurrences among entities, including age, gender, and condition.
The NLI objective (entailment and contradiction analysis) showed attributes
like "Experienced violence or abuse" and "Has medical insurance" had high
entailment rates (82.4%-80.3%), while attributes such as "Is
female-identifying," "Is married," and "Has a terminal condition" exhibited
high contradiction rates (70.8%-98.5%).

摘要：了解脆弱人群的 COVID-19 後遺症 (PCC) 的流行狀況、差異和症狀變化對於改善照護和解決交織的不平等至關重要。本研究旨在透過利用自然語言處理技術分析 PCC 病例報告中 SDOH 的代表性差異和變化，為將社會健康決定因素 (SDOH) 整合到 PCC 研究中建立一個全面的架構。在建構包含來自 LitCOVID 儲存庫的 7,000 多份病例報告的 PCC 病例報告語料庫後，使用預先訓練的名稱實體識別 (NER) 模型、人工審查和資料擴充對 709 份報告的 26 個核心 SDOH 相關實體類型進行註解，以提高實體類型的品質、多樣性和代表性。開發了一個整合 NER、自然語言推理 (NLI)、三元組和頻率分析的 NLP 管線來萃取和分析這些實體。評估了僅編碼器轉換器模型和基於 RNN 的模型的 NER 目標。經過微調的僅編碼器 BERT 模型在對不同句子結構和更大的類別稀疏性的概括性方面優於傳統的基於 RNN 的模型。探索性分析揭示了實體豐富度的變異性，其中盛行的實體包括狀況、年齡和獲得照護的機會，而種族和住房狀況等敏感類別的代表性不足。三元組分析突出了實體之間的頻繁共現，包括年齡、性別和狀況。NLI 目標（蘊涵和矛盾分析）顯示「經歷過暴力或虐待」和「有醫療保險」等屬性具有很高的蘊涵率（82.4%-80.3%），而「認同自己是女性」、「已婚」和「有末期疾病」等屬性則表現出很高的矛盾率（70.8%-98.5%）。

##### **Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor**
2501.12524v1 by Jiaqi Guo, Yunnan Wu, Evangelos Kaimakamis, Georgios Petmezas, Vasileios E. Papageorgiou, Nicos Maglaveras, Aggelos K. Katsaggelos

With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a
promising technique for COVID-19 detection, due to its non-invasive nature,
affordability, and portability. In response, researchers have focused on
developing AI-based scoring systems to provide real-time diagnostic support.
However, the limited size and lack of proper annotation in publicly available
ultrasound datasets pose significant challenges for training a robust AI model.
This paper proposes MeDiVLAD, a novel pipeline to address the above issue for
multi-level lung-ultrasound (LUS) severity scoring. In particular, we leverage
self-knowledge distillation to pretrain a vision transformer (ViT) without
label and aggregate frame-level features via dual-level VLAD aggregation. We
show that with minimal finetuning, MeDiVLAD outperforms conventional
fully-supervised methods in both frame- and video-level scoring, while offering
classification reasoning with exceptional quality. This superior performance
enables key applications such as the automatic identification of critical lung
pathology areas and provides a robust solution for broader medical video
classification tasks.

摘要：隨著 COVID-19 大流行的到來，超音波影像已成為一種有前途的 COVID-19 檢測技術，因為它具有非侵入性、價格實惠且可攜帶等特性。有鑑於此，研究人員專注於開發基於 AI 的評分系統，以提供即時的診斷支援。然而，公開可用的超音波資料集規模有限且缺乏適當的註解，這對訓練穩健的 AI 模型構成重大挑戰。本文提出 MeDiVLAD，這是一種新穎的管道，用於解決上述多層級肺部超音波 (LUS) 嚴重度評分的議題。具體來說，我們利用自我知識蒸餾技術，在沒有標籤的情況下預訓練視覺轉換器 (ViT)，並透過雙層級 VLAD 聚合來彙總幀級特徵。我們證明，透過最小的微調，MeDiVLAD 在幀級和影片級評分中都優於傳統的全監督式方法，同時提供品質極佳的分類推理。這種優異的效能支援了關鍵應用，例如自動識別肺部病灶區域，並為更廣泛的醫學影片分類任務提供穩健的解決方案。

##### **FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression**
2501.12336v1 by Phuoc Duong Huy Chu

This paper presents results of our system for CoMeDi Shared Task, focusing on
Subtask 2: Disagreement Ranking. Our system leverages sentence embeddings
generated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep
neural regression model incorporating batch normalization and dropout for
improved generalization. By predicting the mean of pairwise judgment
differences between annotators, our method explicitly targets disagreement
ranking, diverging from traditional "gold label" aggregation approaches. We
optimized our system with a customized architecture and training procedure,
achieving competitive performance in Spearman correlation against mean
disagreement labels. Our results highlight the importance of robust embeddings,
effective model architecture, and careful handling of judgment differences for
ranking disagreement in multilingual contexts. These findings provide insights
into the use of contextualized representations for ordinal judgment tasks and
open avenues for further refinement of disagreement prediction models.

摘要：本文展示了我們在 CoMeDi 共享任務系統中的結果，重點在
子任務 2：分歧排名。我們的系統利用 paraphrase-xlm-r-multilingual-v1 模型產生的句子嵌入，結合深度
神經迴歸模型，並加入批次正規化和中斷以改善概化。透過預測註解者之間成對判斷差異的平均值，我們的
方法明確針對分歧排名，偏離傳統的「黃金標籤」聚合方法。我們使用自訂架構和訓練程序優化系統，
在與平均分歧標籤的 Spearman 相關性中獲得競爭力表現。我們的結果強調了穩健嵌入、有效模型架構和
謹慎處理判斷差異對於在多語言環境中對分歧進行排名的重要性。這些發現提供了使用情境化表徵進行序數判斷任務的見解，並為進一步優化分歧預測模型開闢了道路。

##### **CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification**
2501.12266v1 by Cristiano Patrício, Isabel Rio-Torto, Jaime S. Cardoso, Luís F. Teixeira, João C. Neves

The main challenges limiting the adoption of deep learning-based solutions in
medical workflows are the availability of annotated data and the lack of
interpretability of such systems. Concept Bottleneck Models (CBMs) tackle the
latter by constraining the final disease prediction on a set of predefined and
human-interpretable concepts. However, the increased interpretability achieved
through these concept-based explanations implies a higher annotation burden.
Moreover, if a new concept needs to be added, the whole system needs to be
retrained. Inspired by the remarkable performance shown by Large
Vision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet
effective, methodology, CBVLM, which tackles both of the aforementioned
challenges. First, for each concept, we prompt the LVLM to answer if the
concept is present in the input image. Then, we ask the LVLM to classify the
image based on the previous concept predictions. Moreover, in both stages, we
incorporate a retrieval module responsible for selecting the best examples for
in-context learning. By grounding the final diagnosis on the predicted
concepts, we ensure explainability, and by leveraging the few-shot capabilities
of LVLMs, we drastically lower the annotation cost. We validate our approach
with extensive experiments across four medical datasets and twelve LVLMs (both
generic and medical) and show that CBVLM consistently outperforms CBMs and
task-specific supervised methods without requiring any training and using just
a few annotated examples. More information on our project page:
https://cristianopatricio.github.io/CBVLM/.

摘要：限制在醫療工作流程中採用基於深度學習的解決方案的主要挑戰是標記資料的可用性以及此類系統的可解釋性不足。概念瓶頸模型 (CBM) 透過限制一組預定義且人類可解釋的概念對最終疾病預測，來解決後者。然而，透過這些基於概念的解釋所實現的可解釋性提升，意味著更高的標記負擔。此外，如果需要新增一個新概念，則需要重新訓練整個系統。受到大型視覺語言模型 (LVLMs) 在小樣本設定中展現的卓越效能啟發，我們提出了一個簡單但有效的 CBVLM 方法，來解決上述兩個挑戰。首先，對於每個概念，我們提示 LVLM 回答輸入影像中是否包含該概念。然後，我們要求 LVLM 根據先前的概念預測對影像進行分類。此外，在兩個階段中，我們都納入一個檢索模組，負責選出最適合於情境學習的範例。透過將最終診斷建立在預測概念之上，我們確保了可解釋性，並透過利用 LVLMs 的小樣本能力，我們大幅降低了標記成本。我們透過四個醫療資料集和十二個 LVLM（通用和醫療）的廣泛實驗驗證了我們的作法，並顯示 CBVLM 在無需任何訓練且僅使用少數標記範例的情況下，始終優於 CBM 和特定於任務的監督式方法。更多資訊請見我們的專案頁面：https://cristianopatricio.github.io/CBVLM/。

##### **Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes**
2501.12106v1 by Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Torsten Panholzer

Tumor documentation in Germany is largely done manually, requiring reading
patient records and entering data into structured databases. Large language
models (LLMs) could potentially enhance this process by improving efficiency
and reliability. This evaluation tests eleven different open source LLMs with
sizes ranging from 1-70 billion model parameters on three basic tasks of the
tumor documentation process: identifying tumor diagnoses, assigning ICD-10
codes, and extracting the date of first diagnosis. For evaluating the LLMs on
these tasks, a dataset of annotated text snippets based on anonymized doctors'
notes from urology was prepared. Different prompting strategies were used to
investigate the effect of the number of examples in few-shot prompting and to
explore the capabilities of the LLMs in general. The models Llama 3.1 8B,
Mistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.
Models with less extensive training data or having fewer than 7 billion
parameters showed notably lower performance, while larger models did not
display performance gains. Examples from a different medical domain than
urology could also improve the outcome in few-shot prompting, which
demonstrates the ability of LLMs to handle tasks needed for tumor
documentation. Open source LLMs show a strong potential for automating tumor
documentation. Models from 7-12 billion parameters could offer an optimal
balance between performance and resource efficiency. With tailored fine-tuning
and well-designed prompting, these models might become important tools for
clinical documentation in the future. The code for the evaluation is available
from https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset
as a new valuable resource that addresses the shortage of authentic and easily
accessible benchmarks in German-language medical NLP.

摘要：德國的腫瘤文件記錄大部分是手動完成，需要閱讀病歷並將資料輸入結構化的資料庫中。大型語言模型 (LLM) 可能透過提升效率和可靠性來增強此程序。此評量測試了 11 個不同的開源 LLM，模型參數大小從 10 億到 700 億不等，針對腫瘤文件記錄程序的三項基本任務：識別腫瘤診斷、指定 ICD-10 代碼，以及擷取首次診斷日期。為了針對這些任務評估 LLM，準備了一個基於泌尿科醫生匿名筆記的註解文字片段資料集。使用不同的提示策略來調查少量提示中範例數量的影響，並探索 LLM 的一般能力。Llama 3.1 8B、Mistral 7B 和 Mistral NeMo 12 B 等模型在這些任務中表現相當好。訓練資料較少或參數少於 70 億的模型表現明顯較差，而較大的模型並未展現效能提升。與泌尿科不同的醫療領域的範例也可以改善少量提示的結果，這證明了 LLM 處理腫瘤文件記錄所需任務的能力。開源 LLM 在自動化腫瘤文件記錄方面顯示出強大的潛力。參數介於 70 億到 120 億的模型可以在效能和資源效率之間提供最佳平衡。透過量身打造微調和精心設計的提示，這些模型未來可能會成為臨床文件記錄的重要工具。評估程式碼可從 https://github.com/stefan-m-lenz/UroLlmEval 取得。我們也釋出資料集作為一個新的有價值資源，用於解決德語醫療自然語言處理中真實且易於取得的基準短缺問題。

##### **Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET**
2501.12425v1 by Fatih Aksu, Fabrizia Gelardi, Arturo Chiti, Paolo Soda

Accurate classification of histological subtypes of non-small cell lung
cancer (NSCLC) is essential in the era of precision medicine, yet current
invasive techniques are not always feasible and may lead to clinical
complications. This study presents a multi-stage intermediate fusion approach
to classify NSCLC subtypes from CT and PET images. Our method integrates the
two modalities at different stages of feature extraction, using voxel-wise
fusion to exploit complementary information across varying abstraction levels
while preserving spatial correlations. We compare our method against unimodal
approaches using only CT or PET images to demonstrate the benefits of modality
fusion, and further benchmark it against early and late fusion techniques to
highlight the advantages of intermediate fusion during feature extraction.
Additionally, we compare our model with the only existing intermediate fusion
method for histological subtype classification using PET/CT images. Our results
demonstrate that the proposed method outperforms all alternatives across key
metrics, with an accuracy and AUC equal to 0.724 and 0.681, respectively. This
non-invasive approach has the potential to significantly improve diagnostic
accuracy, facilitate more informed treatment decisions, and advance
personalized care in lung cancer management.

摘要：在精準醫療的時代，準確分類非小細胞肺癌 (NSCLC) 的組織學亞型至關重要，但目前的侵入性技術並不總是可行，且可能會導致臨床併發症。本研究提出了一種多階段中間融合方法，從電腦斷層 (CT) 和正子斷層掃描 (PET) 影像中分類 NSCLC 亞型。我們的技術在特徵萃取的不同階段整合這兩種方式，利用逐體素融合來利用不同抽象層級的互補資訊，同時保留空間相關性。我們將我們的技術與僅使用電腦斷層或正子斷層掃描影像的單一模式方法進行比較，以證明模式融合的優點，並進一步將其與早期和晚期融合技術進行比較，以強調特徵萃取期間中間融合的優點。此外，我們將我們的模型與唯一現有的中間融合方法進行比較，該方法使用正子斷層掃描/電腦斷層掃描影像進行組織學亞型分類。我們的結果表明，所提出的方法在所有替代方案中表現優異，準確率和 AUC 分別等於 0.724 和 0.681。這種非侵入性方法有可能顯著提高診斷準確率，促進更明智的治療決策，並推進肺癌管理中的個人化照護。

##### **Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye**
2501.12048v1 by Shramana Dey, Pallabi Dutta, Riddhasree Bhattacharyya, Surochita Pal, Sushmita Mitra, Rajiv Raman

The prevalence of ocular illnesses is growing globally, presenting a
substantial public health challenge. Early detection and timely intervention
are crucial for averting visual impairment and enhancing patient prognosis.
This research introduces a new framework called Class Extension with Limited
Data (CELD) to train a classifier to categorize retinal fundus images. The
classifier is initially trained to identify relevant features concerning
Healthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to
the task of classifying the input images into three classes: Healthy, DR, and
Glaucoma. This strategy allows the model to gradually enhance its
classification capabilities, which is beneficial in situations where there are
only a limited number of labeled datasets available. Perturbation methods are
also used to identify the input image characteristics responsible for
influencing the models decision-making process. We achieve an overall accuracy
of 91% on publicly available datasets.

摘要：全球眼疾患病率持續上升，對公共衛生造成重大挑戰。早期發現和及時干預對於預防視力障礙和改善患者預後至關重要。本研究提出了一個名為有限數據類別擴展 (CELD) 的新框架，用於訓練分類器對視網膜眼底圖像進行分類。該分類器最初接受訓練以識別與健康和糖尿病視網膜病變 (DR) 類別相關的特徵，然後進行微調以適應將輸入圖像分類為三類的任務：健康、DR 和青光眼。此策略允許模型逐步增強其分類能力，這在標記數據集數量有限的情況下是有益的。擾動方法也用於識別負責影響模型決策過程的輸入圖像特徵。我們在公開數據集上實現了 91% 的整體準確度。

##### **Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis**
2501.12421v1 by Yonghao Zhao, Changtao Li, Chi Shu, Qingbin Wu, Hong Li, Chuan Xu, Tianrui Li, Ziqiang Wang, Zhipeng Luo, Yazhou He

Survival prognosis is crucial for medical informatics. Practitioners often
confront small-sized clinical data, especially cancer patient cases, which can
be insufficient to induce useful patterns for survival predictions. This study
deals with small sample survival analysis by leveraging transfer learning, a
useful machine learning technique that can enhance the target analysis with
related knowledge pre-learned from other data. We propose and develop various
transfer learning methods designed for common survival models. For parametric
models such as DeepSurv, Cox-CC (Cox-based neural networks), and DeepHit
(end-to-end deep learning model), we apply standard transfer learning
techniques like pretraining and fine-tuning. For non-parametric models such as
Random Survival Forest, we propose a new transfer survival forest (TSF) model
that transfers tree structures from source tasks and fine-tunes them with
target data. We evaluated the transfer learning methods on colorectal cancer
(CRC) prognosis. The source data are 27,379 SEER CRC stage I patients, and the
target data are 728 CRC stage I patients from the West China Hospital. When
enhanced by transfer learning, Cox-CC's $C^{td}$ value was boosted from 0.7868
to 0.8111, DeepHit's from 0.8085 to 0.8135, DeepSurv's from 0.7722 to 0.8043,
and RSF's from 0.7940 to 0.8297 (the highest performance). All models trained
with data as small as 50 demonstrated even more significant improvement.
Conclusions: Therefore, the current survival models used for cancer prognosis
can be enhanced and improved by properly designed transfer learning techniques.
The source code used in this study is available at
https://github.com/YonghaoZhao722/TSF.

摘要：<paragraph>存活預測對醫療資訊學至關重要。實務工作者經常面對小規模的臨床資料，特別是癌症病患個案，這些資料可能不足以誘發有用的模式來進行存活預測。此研究透過利用轉移學習來處理小樣本存活分析，這是一種有用的機器學習技術，可以透過從其他資料預先學習到的相關知識來增強目標分析。我們提出並開發各種專為常見存活模型設計的轉移學習方法。對於參數化模型，例如 DeepSurv、Cox-CC（基於 Cox 的神經網路）和 DeepHit（端到端深度學習模型），我們應用標準轉移學習技術，例如預訓練和微調。對於非參數化模型，例如隨機存活森林，我們提出一個新的轉移存活森林（TSF）模型，它從來源任務傳輸樹狀結構，並使用目標資料微調它們。我們在結直腸癌（CRC）預後上評估了轉移學習方法。來源資料為 27,379 名 SEER CRC 第一期患者，目標資料為來自中國西部醫院的 728 名 CRC 第一期患者。在透過轉移學習增強後，Cox-CC 的 $C^{td}$ 值從 0.7868 提升到 0.8111，DeepHit 的從 0.8085 提升到 0.8135，DeepSurv 的從 0.7722 提升到 0.8043，RSF 的從 0.7940 提升到 0.8297（最高效能）。所有以小至 50 的資料訓練的模型都展示出更顯著的進步。結論：因此，目前用於癌症預後的存活模型可以透過適當設計的轉移學習技術來增強和改善。本研究中使用的原始碼可在 https://github.com/YonghaoZhao722/TSF 取得。</paragraph>

##### **Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)**
2501.13957v1 by Jadon Geathers, Yann Hicke, Colleen Chan, Niroop Rajashekar, Justin Sewell, Susannah Cornes, Rene Kizilcec, Dennis Shung

Introduction. Objective Structured Clinical Examinations (OSCEs) are widely
used to assess medical students' communication skills, but scoring
interview-based assessments is time-consuming and potentially subject to human
bias. This study explored the potential of large language models (LLMs) to
automate OSCE evaluations using the Master Interview Rating Scale (MIRS).
  Methods. We compared the performance of four state-of-the-art LLMs (GPT-4o,
Claude 3.5, Llama 3.1, and Gemini 1.5 Pro) in evaluating OSCE transcripts
across all 28 items of the MIRS under the conditions of zero-shot,
chain-of-thought (CoT), few-shot, and multi-step prompting. The models were
benchmarked against a dataset of 10 OSCE cases with 174 expert consensus scores
available. Model performance was measured using three accuracy metrics (exact,
off-by-one, thresholded).
  Results. Averaging across all MIRS items and OSCE cases, LLMs performed with
low exact accuracy (0.27 to 0.44), and moderate to high off-by-one accuracy
(0.67 to 0.87) and thresholded accuracy (0.75 to 0.88). A zero temperature
parameter ensured high intra-rater reliability ($\alpha = 0.98$ for GPT-4o).
CoT, few-shot, and multi-step techniques proved valuable when tailored to
specific assessment items. The performance was consistent across MIRS items
independent of encounter phases and communication domains.
  Conclusion. We demonstrated the feasibility of AI-assisted OSCE evaluation
and provided benchmarking of multiple LLMs across multiple prompt techniques.
Our work provides a baseline performance assessment for LLMs that lays a
foundation for future research in automated assessment of clinical
communication skills.

摘要：<paragraph>緒論。客觀結構化臨床考試 (OSCE) 廣泛用於評量醫學生的溝通技巧，但評分基於訪談的評量非常耗時，且潛在受到人類偏見的影響。本研究探討大型語言模型 (LLM) 使用大師訪談評分量表 (MIRS) 自動化 OSCE 評量的可能性。
方法。我們比較了四種最先進的 LLM（GPT-4o、Claude 3.5、Llama 3.1 和 Gemini 1.5 Pro）在評量 OSCE 成績單的表現，範圍涵蓋 MIRS 的所有 28 個項目，條件為零次學習、思考鏈 (CoT)、少次學習和多步驟提示。這些模型以 10 個 OSCE 案例的資料集為基準，其中有 174 個專家共識分數可用。模型表現使用三個準確性指標（完全、偏離一、閾值）進行衡量。
結果。平均所有 MIRS 項目和 OSCE 案例，LLM 的完全準確性低（0.27 到 0.44），偏離一準確性中等至高（0.67 到 0.87），閾值準確性高（0.75 到 0.88）。零溫度參數確保了很高的評分者內部信度（GPT-4o 的 α = 0.98）。當針對特定評量項目進行調整時，CoT、少次學習和多步驟技術被證明是有價值的。表現與 MIRS 項目一致，與遭遇階段和溝通領域無關。
結論。我們展示了 AI 輔助 OSCE 評量的可行性，並提供了多種提示技術的 LLM 基準測試。我們的研究為 LLM 提供了基準表現評量，為臨床溝通技巧自動化評量的未來研究奠定了基礎。</paragraph>

##### **Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision**
2501.11836v1 by Saeid Ataei, Saeed Adibnazari, Seyyed Taghi Ataei

Structural integrity is vital for maintaining the safety and longevity of
concrete infrastructures such as bridges, tunnels, and walls. Traditional
methods for detecting damages like cracks and spalls are labor-intensive,
time-consuming, and prone to human error. To address these challenges, this
study explores advanced data-driven techniques using deep learning for
automated damage detection and analysis. Two state-of-the-art instance
segmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were
evaluated using a dataset comprising 400 images, augmented to 10,995 images
through geometric and color-based transformations to enhance robustness. The
models were trained and validated using a dataset split into 90% training set,
validation and test set 10%. Performance metrics such as precision, recall,
mean average precision (mAP@0.5), and frames per second (FPS) were used for
evaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,
outperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower
processing speed of 18 FPS. The findings recommend YOLO-v7 instance
segmentation model for real-time, high-speed structural health monitoring,
while Mask R-CNN is better suited for detailed offline assessments. This study
demonstrates the potential of deep learning to revolutionize infrastructure
maintenance, offering a scalable and efficient solution for automated damage
detection.

摘要：結構完整性對於維護橋樑、隧道和牆壁等混凝土基礎設施的安全性和使用壽命至關重要。傳統的損壞檢測方法，例如裂縫和剝落，需要大量人工，耗時且容易出現人為錯誤。為了應對這些挑戰，本研究探討了使用深度學習的先進數據驅動技術，用於自動損壞檢測和分析。使用包含 400 張圖像的數據集評估了兩個最先進的實例分割模型，YOLO-v7 實例分割和 Mask R-CNN，通過幾何和基於顏色的轉換擴展到 10,995 張圖像，以增強魯棒性。使用分為 90% 訓練集、驗證和測試集 10% 的數據集訓練和驗證模型。使用精確度、召回率、平均平均精確度 (mAP@0.5) 和每秒幀數 (FPS) 等性能指標進行評估。YOLO-v7 達到了 96.1% 的優異 mAP@0.5，並處理了 40 FPS，優於 Mask R-CNN，後者以 18 FPS 的較慢處理速度達到了 92.1% 的 mAP@0.5。研究結果推薦使用 YOLO-v7 實例分割模型進行實時、高速結構健康監測，而 Mask R-CNN 更適合詳細的離線評估。本研究展示了深度學習在基礎設施維護方面具有革命性的潛力，為自動損壞檢測提供了一個可擴展且高效的解決方案。

##### **GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease**
2501.11715v1 by Wenjie Kang, Lize Jiskoot, Peter De Deyn, Geert Biessels, Huiberdina Koek, Jurgen Claassen, Huub Middelkoop, Wiesje Flier, Willemijn J. Jansen, Stefan Klein, Esther Bron

Deep learning methods based on Convolutional Neural Networks (CNNs) have
shown great potential to improve early and accurate diagnosis of Alzheimer's
disease (AD) dementia based on imaging data. However, these methods have yet to
be widely adopted in clinical practice, possibly due to the limited
interpretability of deep learning models. The Explainable Boosting Machine
(EBM) is a glass-box model but cannot learn features directly from input
imaging data. In this study, we propose a novel interpretable model that
combines CNNs and EBMs for the diagnosis and prediction of AD. We develop an
innovative training strategy that alternatingly trains the CNN component as a
feature extractor and the EBM component as the output block to form an
end-to-end model. The model takes imaging data as input and provides both
predictions and interpretable feature importance measures. We validated the
proposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)
dataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)
as an external testing set. The proposed model achieved an area-under-the-curve
(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction
of conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The
proposed model is a glass-box model that achieves a comparable performance with
other state-of-the-art black-box models. Our code is publicly available at:
https://anonymous.4open.science/r/GL-ICNN.

摘要：<paragraph>基於卷積神經網路 (CNN) 的深度學習方法已顯示出極大的潛力，可根據影像資料改善阿茲海默症 (AD) 失智症的早期準確診斷。然而，這些方法尚未廣泛應用於臨床實務中，這可能是由於深度學習模型的可解釋性有限。可解釋提升機 (EBM) 是個玻璃盒模型，但無法直接從輸入影像資料中學習特徵。在這項研究中，我們提出一個結合 CNN 和 EBM 的新可解釋模型，用於診斷和預測 AD。我們開發了一種創新的訓練策略，交替訓練 CNN 組件作為特徵萃取器，並訓練 EBM 組件作為輸出區塊，以形成端對端模型。此模型將影像資料作為輸入，並提供預測和可解釋的特徵重要性測量。我們在阿茲海默症神經影像倡議 (ADNI) 資料集和 Health-RI Parelsnoer 神經退化疾病生物資料庫 (PND) 上驗證了所提出的模型，作為外部測試集。所提出的模型在 AD 和對照分類中達到了 0.956 的曲線下面積 (AUC)，並在 ADNI 隊列中預測輕度認知障礙 (MCI) 轉化為 AD 時達到了 0.694。所提出的模型是一個玻璃盒模型，其效能與其他最先進的黑盒模型相當。我們的程式碼可在以下網址公開取得：https://anonymous.4open.science/r/GL-ICNN。</paragraph>

##### **Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)**
2501.11705v1 by Brian E. Perron, Lauri Goldkind, Zia Qi, Bryan G. Victor

This paper examines the responsible integration of artificial intelligence
(AI) in human services organizations (HSOs), proposing a nuanced framework for
evaluating AI applications across multiple dimensions of risk. The authors
argue that ethical concerns about AI deployment -- including professional
judgment displacement, environmental impact, model bias, and data laborer
exploitation -- vary significantly based on implementation context and specific
use cases. They challenge the binary view of AI adoption, demonstrating how
different applications present varying levels of risk that can often be
effectively managed through careful implementation strategies. The paper
highlights promising solutions, such as local large language models, that can
facilitate responsible AI integration while addressing common ethical concerns.
The authors propose a dimensional risk assessment approach that considers
factors like data sensitivity, professional oversight requirements, and
potential impact on client wellbeing. They conclude by outlining a path forward
that emphasizes empirical evaluation, starting with lower-risk applications and
building evidence-based understanding through careful experimentation. This
approach enables organizations to maintain high ethical standards while
thoughtfully exploring how AI might enhance their capacity to serve clients and
communities effectively.

摘要：本文探討了人工智慧 (AI) 在人類服務組織 (HSO) 中負責任的整合，提出了一個細緻的框架，用於評估 AI 應用在多個風險維度。作者認為，對 AI 部署的道德考量——包括專業判斷的取代、環境影響、模型偏差和資料工作者的剝削——會根據實施背景和具體使用案例而有顯著的不同。他們挑戰了 AI 採用二元論的觀點，說明了不同的應用如何呈現不同程度的風險，而這些風險通常可以透過仔細的實施策略來有效管理。本文重點介紹了有前景的解決方案，例如本地大型語言模型，它可以在解決常見的道德問題的同時，促進負責任的 AI 整合。作者提出了一種維度風險評估方法，該方法考慮了資料敏感度、專業監督需求和對客戶福祉的潛在影響等因素。他們最後概述了一條前進的道路，強調實證評估，從低風險應用開始，並透過仔細的實驗建立基於證據的理解。這種方法使組織能夠在深思熟慮地探討 AI 如何增強其有效服務客戶和社群的能力的同時，維持高道德標準。

##### **Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data**
2501.11695v1 by Majid Farhadloo, Arun Sharma, Alexey Leontovich, Svetomir N. Markovic, Shashi Shekhar

Given multi-type point maps from different place-types (e.g., tumor regions),
our objective is to develop a classifier trained on the source place-type to
accurately distinguish between two classes of the target place-type based on
their point arrangements. This problem is societally important for many
applications, such as generating clinical hypotheses for designing new
immunotherapies for cancer treatment. The challenge lies in the spatial
variability, the inherent heterogeneity and variation observed in spatial
properties or arrangements across different locations (i.e., place-types).
Previous techniques focus on self-supervised tasks to learn domain-invariant
features and mitigate domain differences; however, they often neglect the
underlying spatial arrangements among data points, leading to significant
discrepancies across different place-types. We explore a novel multi-task
self-learning framework that targets spatial arrangements, such as spatial
mix-up masking and spatial contrastive predictive coding, for
spatially-delineated domain-adapted AI classification. Experimental results on
real-world datasets (e.g., oncology data) show that the proposed framework
provides higher prediction accuracy than baseline methods.

摘要：從不同類型的點圖（例如，腫瘤區域）中給定多類型點圖，
我們的目標是開發一個在來源類型上訓練的分類器，以
根據其點排列準確區分目標類型中的兩類。這個問題對於許多
應用來說具有社會重要性，例如為癌症治療設計新的免疫療法而生成臨床假設。挑戰在於空間
變異性、固有的異質性和在不同位置（即類型）中觀察到的空間
屬性或排列的變化。先前的技術專注於自監督任務以學習不變領域
特徵並減輕領域差異；然而，它們通常忽視數據點之間的
底層空間排列，導致不同類型之間存在顯著差異。我們探索了一種新穎的多任務
自學習框架，以針對空間排列，例如空間混合掩蔽和空間對比預測編碼，用於
空間劃分的領域適應 AI 分類。在
真實世界數據集（例如，腫瘤學數據）上的實驗結果表明，所提出的框架
提供的預測準確度高於基線方法。

##### **Multilinguality in LLM-Designed Reward Functions for Restless Bandits: Effects on Task Performance and Fairness**
2501.13120v1 by Ambreesh Parthasarathy, Chandrasekar Subramanian, Ganesh Senrayan, Shreyash Adappanavar, Aparna Taneja, Balaraman Ravindran, Milind Tambe

Restless Multi-Armed Bandits (RMABs) have been successfully applied to
resource allocation problems in a variety of settings, including public health.
With the rapid development of powerful large language models (LLMs), they are
increasingly used to design reward functions to better match human preferences.
Recent work has shown that LLMs can be used to tailor automated allocation
decisions to community needs using language prompts. However, this has been
studied primarily for English prompts and with a focus on task performance
only. This can be an issue since grassroots workers, especially in developing
countries like India, prefer to work in local languages, some of which are
low-resource. Further, given the nature of the problem, biases along population
groups unintended by the user are also undesirable. In this work, we study the
effects on both task performance and fairness when the DLM algorithm, a recent
work on using LLMs to design reward functions for RMABs, is prompted with
non-English language commands. Specifically, we run the model on a synthetic
environment for various prompts translated into multiple languages. The prompts
themselves vary in complexity. Our results show that the LLM-proposed reward
functions are significantly better when prompted in English compared to other
languages. We also find that the exact phrasing of the prompt impacts task
performance. Further, as prompt complexity increases, performance worsens for
all languages; however, it is more robust with English prompts than with
lower-resource languages. On the fairness side, we find that low-resource
languages and more complex prompts are both highly likely to create unfairness
along unintended dimensions.

摘要：<paragraph>不安分的多臂賭徒 (RMAB) 已成功應用於各種環境中的資源分配問題，包括公共衛生。隨著強大大型語言模型 (LLM) 的快速發展，它們正越來越多地用於設計獎勵函數，以更好地匹配人類偏好。最近的研究表明，LLM 可用於使用語言提示根據社區需求調整自動分配決策。然而，這主要針對英語提示進行了研究，並且僅關注任務績效。這可能是一個問題，因為基層工作者，特別是像印度這樣的發展中國家的工作者，更願意使用當地語言，其中一些語言是低資源的。此外，鑑於問題的性質，用戶無意中對人口群體產生的偏見也是不受歡迎的。在這項工作中，我們研究了當 DLM 演算法（最近使用 LLM 為 RMAB 設計獎勵函數的工作）收到非英語語言命令時，對任務績效和公平性的影響。具體來說，我們在合成環境中運行模型，對翻譯成多種語言的各種提示進行運行。提示本身的複雜性各不相同。我們的結果表明，與其他語言相比，用英語提示時，LLM 提出的獎勵函數顯著更好。我們還發現提示的確切措辭會影響任務績效。此外，隨著提示複雜性的增加，所有語言的性能都會下降；然而，它比低資源語言更健壯。在公平性方面，我們發現低資源語言和更複雜的提示都極有可能在意外的維度上造成不公平。</paragraph>

##### **Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications**
2501.11632v2 by Yuxing Lu, Sin Yee Goi, Xukai Zhao, Jinzhuo Wang

Biomedical knowledge graphs (BKGs) have emerged as powerful tools for
organizing and leveraging the vast and complex data found across the biomedical
field. Yet, current reviews of BKGs often limit their scope to specific domains
or methods, overlooking the broader landscape and the rapid technological
progress reshaping it. In this survey, we address this gap by offering a
systematic review of BKGs from three core perspectives: domains, tasks, and
applications. We begin by examining how BKGs are constructed from diverse data
sources, including molecular interactions, pharmacological datasets, and
clinical records. Next, we discuss the essential tasks enabled by BKGs,
focusing on knowledge management, retrieval, reasoning, and interpretation.
Finally, we highlight real-world applications in precision medicine, drug
discovery, and scientific research, illustrating the translational impact of
BKGs across multiple sectors. By synthesizing these perspectives into a unified
framework, this survey not only clarifies the current state of BKG research but
also establishes a foundation for future exploration, enabling both innovative
methodological advances and practical implementations.

摘要：生物医学知识图谱（BKG）已成为组织和利用生物医学领域中发现的庞大且复杂数据的强大工具。然而，当前对 BKG 的审查通常将其范围限制在特定领域或方法，忽视了更广泛的格局和正在重塑它的快速技术进步。在这项调查中，我们通过从三个核心角度（领域、任务和应用）对 BKG 进行系统审查来解决这一差距。我们首先检查如何从包括分子相互作用、药理数据集和临床记录在内的各种数据源构建 BKG。接下来，我们讨论 BKG 启用的基本任务，重点关注知识管理、检索、推理和解释。最后，我们重点介绍了精准医疗、药物发现和科学研究中的实际应用，说明了 BKG 在多个领域的转化影响。通过将这些观点综合到一个统一的框架中，本调查不仅阐明了 BKG 研究的现状，还为未来的探索奠定了基础，既促进了创新方法的进步，也促进了实际实施。

##### **Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing**
2501.11592v2 by Chaoqing Tang, Huanze Zhuang, Guiyun Tian, Zhenli Zeng, Yi Ding, Wenzhong Liu, Xiang Bai

Pre-trained large models attract widespread attention in recent years, but
they face challenges in applications that require high interpretability or have
limited resources, such as physical sensing, medical imaging, and
bioinformatics. Compressed Sensing (CS) is a well-proved theory that drives
many recent breakthroughs in these applications. However, as a typical
under-determined linear system, CS suffers from excessively long sparse
reconstruction times when using traditional iterative methods, particularly
with large-scale data. Current AI methods like deep unfolding fail to
substitute them because pre-trained models exhibit poor generality beyond their
training conditions and dataset distributions, or lack interpretability.
Instead of following the big model fervor, this paper proposes ultra-small
artificial neural models called coefficients learning (CL), enabling
training-free and rapid sparse reconstruction while perfectly inheriting the
generality and interpretability of traditional iterative methods, bringing new
feature of incorporating prior knowledges. In CL, a signal of length $n$ only
needs a minimal of $n$ trainable parameters. A case study model called CLOMP is
implemented for evaluation. Experiments are conducted on both synthetic and
real one-dimensional and two-dimensional signals, demonstrating significant
improvements in efficiency and accuracy. Compared to representative iterative
methods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.
Test results on eight diverse image datasets indicate that CLOMP improves
structural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,
0.5, respectively. We believe this method can truly usher CS reconstruction
into the AI era, benefiting countless under-determined linear systems that rely
on sparse solution.

摘要：<paragraph>預訓練大型模型近年來廣受關注，但它們在需要高可解釋性或資源受限的應用中面臨挑戰，例如物理感測、醫學影像和生物資訊學。壓縮感測 (CS) 是一個經過驗證的理論，推動了這些應用中的許多近期突破。然而，作為一個典型的欠定線性系統，CS 在使用傳統迭代方法時會導致過長的稀疏重建時間，特別是在大規模資料的情況下。像深度展開等當前 AI 方法無法取代它們，因為預訓練模型在訓練條件和資料集分佈之外表現出較差的概括性，或缺乏可解釋性。本論文沒有追隨大型模型熱潮，而是提出了稱為係數學習 (CL) 的超小型人工神經網路模型，實現無訓練且快速的稀疏重建，同時完美繼承傳統迭代方法的概括性和可解釋性，帶來結合先驗知識的新特點。在 CL 中，長度為 $n$ 的信號只需要最少 $n$ 個可訓練參數。實作了一個稱為 CLOMP 的案例研究模型進行評估。在合成和真實的一維和二維信號上進行了實驗，證明了效率和準確性的顯著提升。與具代表性的迭代方法相比，CLOMP 將大型資料的效率提升了 100 到 1000 倍。在八個不同的影像資料集上的測試結果表明，CLOMP 分別將採樣率為 0.1、0.3、0.5 的結構相似性指標提升了 292%、98%、45%。我們相信這種方法可以真正將 CS 重建帶入 AI 時代，使依賴稀疏解的無數欠定線性系統受益。</paragraph>

##### **Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography**
2501.11428v1 by Jakub Nalepa, Tomasz Bartczak, Mariusz Bujny, Jarosław Gośliński, Katarzyna Jesionek, Wojciech Malara, Filip Malawski, Karol Miszalski-Jamka, Patrycja Rewa, Marcin Kostur

Despite coronary artery calcium scoring being considered a largely solved
problem within the realm of medical artificial intelligence, this paper argues
that significant improvements can still be made. By shifting the focus from
pathology detection to a deeper understanding of anatomy, the novel algorithm
proposed in the paper both achieves high accuracy in coronary artery calcium
scoring and offers enhanced interpretability of the results. This approach not
only aids in the precise quantification of calcifications in coronary arteries,
but also provides valuable insights into the underlying anatomical structures.
Through this anatomically-informed methodology, the paper shows how a nuanced
understanding of the heart's anatomy can lead to more accurate and
interpretable results in the field of cardiovascular health. We demonstrate the
superior accuracy of the proposed method by evaluating it on an open-source
multi-vendor dataset, where we obtain results at the inter-observer level,
surpassing the current state of the art. Finally, the qualitative analyses show
the practical value of the algorithm in such tasks as labeling coronary artery
calcifications, identifying aortic calcifications, and filtering out false
positive detections due to noise.

摘要：儘管冠狀動脈鈣化評分在醫學人工智慧領域被認為是一個已解決的問題，但本文論證仍有顯著進步的空間。透過將焦點從病理檢測轉移到對解剖結構的更深入理解，本文提出的新演算法在冠狀動脈鈣化評分中獲得高準確度，並提供了增強的結果可解釋性。這種方法不僅有助於精確量化冠狀動脈的鈣化，還提供了對底層解剖結構的寶貴見解。透過這種解剖學方法，本文展示了對心臟解剖結構的細緻理解如何能導致心血管健康領域更準確且可解釋的結果。我們透過在開放原始碼的多廠商資料集上評估所提出的方法，證明了其優越的準確度，我們在觀察者間層級獲得的結果超越了目前的技術水準。最後，定性分析顯示了該演算法在標記冠狀動脈鈣化、識別主動脈鈣化以及過濾掉因雜訊而產生的假陽性偵測等任務中的實用價值。

##### **Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations**
2501.16356v1 by Alicia Vidler, Toby Walsh

Large Language Models (LLMs) are increasingly being used to simulate
human-like decision making in agent-based financial market models (ABMs). As
models become more powerful and accessible, researchers can now incorporate
individual LLM decisions into ABM environments. However, integration may
introduce inherent biases that need careful evaluation. In this paper we test
three state-of-the-art GPT models for bias using two model sampling approaches:
one-shot and few-shot API queries. We observe significant variations in
distributions of outputs between specific models, and model sub versions, with
GPT-4o-Mini-2024-07-18 showing notably better performance (32-43% yes
responses) compared to GPT-4-0125-preview's extreme bias (98-99% yes
responses). We show that sampling methods and model sub-versions significantly
impact results: repeated independent API calls produce different distributions
compared to batch sampling within a single call. While no current GPT model can
simultaneously achieve a uniform distribution and Markovian properties in
one-shot testing, few-shot sampling can approach uniform distributions under
certain conditions. We explore the Temperature parameter, providing a
definition and comparative results. We further compare our results to true
random binary series and test specifically for the common human bias of
Negative Recency - finding LLMs have a mixed ability to 'beat' humans in this
one regard. These findings emphasise the critical importance of careful LLM
integration into ABMs for financial markets and more broadly.

摘要：大型語言模型 (LLM)  zunehmend zur Simulation
menschlicher Entscheidungsfindung in agentenbasierten Finanzmarktmodellen (ABM) eingesetzt. Da
Modelle leistungsfähiger und zugänglicher werden, können Forscher jetzt
einzelne LLM-Entscheidungen in ABM-Umgebungen integrieren. Die Integration kann jedoch
inhärente Verzerrungen einführen, die sorgfältig bewertet werden müssen. In diesem Artikel testen wir
drei hochmoderne GPT-Modelle auf Verzerrungen unter Verwendung zweier Modell-Sampling-Ansätze:
One-Shot- und Few-Shot-API-Abfragen. Wir beobachten signifikante Unterschiede in
Verteilungen von Ausgaben zwischen bestimmten Modellen und Modellunterversionen, wobei
GPT-4o-Mini-2024-07-18 eine deutlich bessere Leistung zeigt (32-43 % Ja-Antworten) im Vergleich zu GPT-4-0125-Vorschau extreme Verzerrung (98-99 % Ja-Antworten). Wir zeigen, dass Sampling-Methoden und Modellunterversionen die Ergebnisse erheblich beeinflussen: Wiederholte unabhängige API-Aufrufe erzeugen unterschiedliche Verteilungen im Vergleich zur Batch-Abtastung innerhalb eines einzelnen Aufrufs. Zwar kann kein aktuelles GPT-Modell gleichzeitig eine gleichmäßige Verteilung und markovsche Eigenschaften im One-Shot-Test erreichen, aber Few-Shot-Sampling kann sich unter bestimmten Bedingungen gleichmäßigen Verteilungen annähern. Wir untersuchen den Temperaturparameter und liefern eine
Definition und Vergleichsergebnisse. Darüber hinaus vergleichen wir unsere Ergebnisse mit echten
zufälligen Binärreihen und testen speziell auf die häufige menschliche Verzerrung von
Negative Rezenz - Feststellung, dass LLMs eine gemischte Fähigkeit haben, Menschen in diesem Fall zu „schlagen“.
eine Hinsicht. Diese Ergebnisse unterstreichen die entscheidende Bedeutung einer sorgfältigen LLM-Integration in ABMs für Finanzmärkte und darüber hinaus.

##### **RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?**
2501.11284v1 by Haotian Xu, Xing Wu, Weinong Wang, Zhongzhi Li, Da Zheng, Boyuan Chen, Yi Hu, Shijia Kang, Jiaming Ji, Yingying Zhang, Zhijiang Guo, Yaodong Yang, Muhan Zhang, Debing Zhang

Can scaling transform reasoning? In this work, we explore the untapped
potential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples,
pioneering the development of a slow-thinking model, RedStar. Through extensive
experiments with various LLMs and different sizes, we uncover the ingredients
for specialization and scale for Long-CoT training. Surprisingly, even smaller
models show significant performance gains with limited data, revealing the
sample efficiency of Long-CoT and the critical role of sample difficulty in the
learning process. Our findings demonstrate that Long-CoT reasoning can be
effectively triggered with just a few thousand examples, while larger models
achieve unparalleled improvements. We also introduce reinforcement learning
(RL)-scale training as a promising direction for advancing slow-thinking
systems. RedStar shines across domains: on the MATH-Hard benchmark,
RedStar-code-math boosts performance from 66.2\% to 81.6\%, and on the USA Math
Olympiad (AIME), it solves 46.7\% of problems using only 21k mixed-code-math
datasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo
achieves competitive results with minimal Long-CoT data, outperforming other
slow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the
perfect balance between reasoning and generalizability. Our work highlights
that, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning
capabilities-even with limited dataset and set a new standard for slow-thinking
models across diverse challenges. Our data and models are released at
https://huggingface.co/RedStar-Reasoning.

摘要：<paragraph>縮放可以轉換推理嗎？在這項工作中，我們探索將長鏈思考（Long-CoT）資料縮放到 1000k 範例的未開發潛力，率先開發慢思考模型 RedStar。透過使用各種 LLM 和不同大小進行廣泛實驗，我們揭示了 Long-CoT 訓練的專業化和規模要素。令人驚訝的是，即使較小的模型在資料有限的情況下也展現出顯著的效能提升，揭示了 Long-CoT 的範例效率和範例難度在學習過程中扮演的關鍵角色。我們的發現證明，只要有數千個範例，就可以有效觸發 Long-CoT 推理，而較大的模型則可獲得無與倫比的改進。我們還導入強化學習 (RL) 規模訓練，作為推進慢思考系統的一個有前途的方向。RedStar 在各個領域中表現出色：在 MATH-Hard 基準測試中，RedStar-code-math 將效能從 66.2% 提升至 81.6%，而在美國數學奧林匹克（AIME）中，它僅使用 21k 個混合程式碼數學資料集就解決了 46.7% 的問題。在 GeoQA 和 MathVista-GEO 等多模態任務中，RedStar-Geo 在 Long-CoT 資料最少的情況下取得競爭力的結果，優於其他慢思考系統，例如 QvQ-Preview。與 QwQ 相比，RedStar 在推理和概括性之間取得了完美的平衡。我們的研究重點在於，透過仔細調整，縮放 Long-CoT 可以解鎖非凡的推理能力，即使在資料集有限的情況下，也能為各種挑戰設定慢思考模型的新標準。我們的資料和模型已於 https://huggingface.co/RedStar-Reasoning 發布。</paragraph>

##### **Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features**
2501.11270v1 by Osama Ahmad, Zubair Khalid, Muhammad Tahir, Momin Uppal

Monitoring air pollution is crucial for protecting human health from exposure
to harmful substances. Traditional methods of air quality monitoring, such as
ground-based sensors and satellite-based remote sensing, face limitations due
to high deployment costs, sparse sensor coverage, and environmental
interferences. To address these challenges, this paper proposes a framework for
high-resolution spatiotemporal Air Quality Index (AQI) mapping using sparse
sensor data, satellite imagery, and various spatiotemporal factors. By
leveraging Graph Neural Networks (GNNs), we estimate AQI values at unmonitored
locations based on both spatial and temporal dependencies. The framework
incorporates a wide range of environmental features, including meteorological
data, road networks, points of interest (PoIs), population density, and urban
green spaces, which enhance prediction accuracy. We illustrate the use of our
approach through a case study in Lahore, Pakistan, where multi-resolution data
is used to generate the air quality index map at a fine spatiotemporal scale.

摘要：監控空氣污染對於保護人類健康免於接觸有害物質至關重要。傳統的空氣品質監測方法，例如地面感測器和衛星遙測，由於部署成本高、感測器覆蓋範圍稀疏以及環境干擾而面臨限制。為了應對這些挑戰，本文提出了一個使用稀疏感測器資料、衛星影像和各種時空因子來繪製高解析度時空空氣品質指數 (AQI) 的架構。透過利用圖形神經網路 (GNN)，我們根據空間和時間依賴性來估計未監控地點的 AQI 值。該架構結合了廣泛的環境特徵，包括氣象資料、道路網路、興趣點 (PoI)、人口密度和城市綠地，這些特徵增強了預測準確度。我們透過巴基斯坦拉合爾的一個案例研究來說明我們方法的使用，其中使用多解析度資料來生成精細時空尺度的空氣品質指數地圖。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-31**|**Redefining Machine Unlearning: A Conformal Prediction-Motivated Approach**|Yingdan Shi et.al.|[2501.19403v1](http://arxiv.org/abs/2501.19403v1)|null|
|**2025-01-31**|**Vintix: Action Model via In-Context Reinforcement Learning**|Andrey Polubarov et.al.|[2501.19400v1](http://arxiv.org/abs/2501.19400v1)|[link](https://github.com/dunnolab/vintix)|
|**2025-01-31**|**Scalable-Softmax Is Superior for Attention**|Ken M. Nakanishi et.al.|[2501.19399v1](http://arxiv.org/abs/2501.19399v1)|null|
|**2025-01-31**|**Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game**|Mustafa O. Karabag et.al.|[2501.19398v1](http://arxiv.org/abs/2501.19398v1)|[link](https://github.com/mustafakarabag/llmchameleon)|
|**2025-01-31**|**s1: Simple test-time scaling**|Niklas Muennighoff et.al.|[2501.19393v2](http://arxiv.org/abs/2501.19393v2)|[link](https://github.com/simplescaling/s1)|
|**2025-01-31**|**Decoding-based Regression**|Xingyou Song et.al.|[2501.19383v1](http://arxiv.org/abs/2501.19383v1)|[link](https://github.com/google-research/optformer)|
|**2025-01-31**|**TableMaster: A Recipe to Advance Table Understanding with Language Models**|Lang Cao et.al.|[2501.19378v1](http://arxiv.org/abs/2501.19378v1)|null|
|**2025-01-31**|**SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions**|Dominik Wagner et.al.|[2501.19377v2](http://arxiv.org/abs/2501.19377v2)|null|
|**2025-01-31**|**CoSTI: Consistency Models for (a faster) Spatio-Temporal Imputation**|Javier Solís-García et.al.|[2501.19364v1](http://arxiv.org/abs/2501.19364v1)|[link](https://github.com/javiersgjavi/costi)|
|**2025-01-31**|**We're Different, We're the Same: Creative Homogeneity Across LLMs**|Emily Wenger et.al.|[2501.19361v1](http://arxiv.org/abs/2501.19361v1)|null|
|**2025-01-31**|**Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SCICAP Challenge 2023**|Ting-Yao E. Hsu et.al.|[2501.19353v1](http://arxiv.org/abs/2501.19353v1)|null|
|**2025-01-31**|**PixelWorld: Towards Perceiving Everything as Pixels**|Zhiheng Lyu et.al.|[2501.19339v1](http://arxiv.org/abs/2501.19339v1)|null|
|**2025-01-31**|**Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**|Misha P. T Kaandorp et.al.|[2501.19338v1](http://arxiv.org/abs/2501.19338v1)|null|
|**2025-01-31**|**Homogeneity Bias as Differential Sampling Uncertainty in Language Models**|Messi H. J. Lee et.al.|[2501.19337v1](http://arxiv.org/abs/2501.19337v1)|null|
|**2025-01-31**|**What is causal about causal models and representations?**|Frederik Hytting Jørgensen et.al.|[2501.19335v2](http://arxiv.org/abs/2501.19335v2)|null|
|**2025-01-31**|**Capturing Temporal Dynamics in Large-Scale Canopy Tree Height Estimation**|Jan Pauls et.al.|[2501.19328v1](http://arxiv.org/abs/2501.19328v1)|null|
|**2025-01-31**|**Reward-Guided Speculative Decoding for Efficient LLM Reasoning**|Baohao Liao et.al.|[2501.19324v1](http://arxiv.org/abs/2501.19324v1)|null|
|**2025-01-31**|**Language Bias in Self-Supervised Learning For Automatic Speech Recognition**|Edward Storey et.al.|[2501.19321v1](http://arxiv.org/abs/2501.19321v1)|null|
|**2025-01-31**|**MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems**|Anirudh Chari et.al.|[2501.19318v1](http://arxiv.org/abs/2501.19318v1)|null|
|**2025-01-31**|**LLM-based Affective Text Generation Quality Based on Different Quantization Values**|Yarik Menchaca Resendiz et.al.|[2501.19317v1](http://arxiv.org/abs/2501.19317v1)|null|
|**2025-01-31**|**Reverse Probing: Evaluating Knowledge Transfer via Finetuned Task Embeddings for Coreference Resolution**|Tatiana Anikina et.al.|[2501.19316v1](http://arxiv.org/abs/2501.19316v1)|null|
|**2025-01-31**|**An Efficient Approach for Machine Translation on Low-resource Languages: A Case Study in Vietnamese-Chinese**|Tran Ngoc Son et.al.|[2501.19314v1](http://arxiv.org/abs/2501.19314v1)|null|
|**2025-01-31**|**Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment**|Gregor Bachmann et.al.|[2501.19309v1](http://arxiv.org/abs/2501.19309v1)|null|
|**2025-01-31**|**SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling**|Jiefeng Chen et.al.|[2501.19306v2](http://arxiv.org/abs/2501.19306v2)|null|
|**2025-01-31**|**Beyond checkmate: exploring the creative chokepoints in AI text**|Nafis Irtiza Tripto et.al.|[2501.19301v1](http://arxiv.org/abs/2501.19301v1)|[link](https://github.com/tripto03/chess_inspired_human_ai_text_distinction)|
|**2025-01-31**|**Synthetic User Behavior Sequence Generation with Large Language Models for Smart Homes**|Zhiyao Xu et.al.|[2501.19298v1](http://arxiv.org/abs/2501.19298v1)|null|
|**2025-01-31**|**Analysis of LLMs vs Human Experts in Requirements Engineering**|Cory Hymel et.al.|[2501.19297v1](http://arxiv.org/abs/2501.19297v1)|null|
|**2025-01-31**|**Pheromone-based Learning of Optimal Reasoning Paths**|Anirudh Chari et.al.|[2501.19278v1](http://arxiv.org/abs/2501.19278v1)|null|
|**2025-01-31**|**Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**|Halil Ibrahim Aysel et.al.|[2501.19271v1](http://arxiv.org/abs/2501.19271v1)|null|
|**2025-01-31**|**Jackpot! Alignment as a Maximal Lottery**|Roberto-Rafael Maura-Rivero et.al.|[2501.19266v1](http://arxiv.org/abs/2501.19266v1)|null|
|**2025-01-31**|**mFollowIR: a Multilingual Benchmark for Instruction Following in Retrieval**|Orion Weller et.al.|[2501.19264v1](http://arxiv.org/abs/2501.19264v1)|[link](https://github.com/orionw/followir)|
|**2025-01-31**|**VisualSpeech: Enhance Prosody with Visual Context in TTS**|Shumin Que et.al.|[2501.19258v1](http://arxiv.org/abs/2501.19258v1)|null|
|**2025-01-31**|**SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments**|Hüseyin Aydın et.al.|[2501.19245v2](http://arxiv.org/abs/2501.19245v2)|null|
|**2025-01-31**|**A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation**|Yunzhe Li et.al.|[2501.19232v1](http://arxiv.org/abs/2501.19232v1)|null|
|**2025-01-31**|**Integrating Semi-Supervised and Active Learning for Semantic Segmentation**|Wanli Ma et.al.|[2501.19227v1](http://arxiv.org/abs/2501.19227v1)|null|
|**2025-01-31**|**Improving the Robustness of Representation Misdirection for Large Language Model Unlearning**|Dang Huu-Tien et.al.|[2501.19202v2](http://arxiv.org/abs/2501.19202v2)|[link](https://github.com/rebelsnlu-jaist/llmu-robustness)|
|**2025-01-31**|**Efficient Reasoning with Hidden Thinking**|Xuan Shen et.al.|[2501.19201v1](http://arxiv.org/abs/2501.19201v1)|[link](https://github.com/shawnricecake/heima)|
|**2025-01-31**|**Secured Communication Schemes for UAVs in 5G: CRYSTALS-Kyber and IDS**|Taneya Sharma et.al.|[2501.19191v1](http://arxiv.org/abs/2501.19191v1)|[link](https://github.com/taneya1987/crystals-kyber-and-ids)|
|**2025-01-31**|**Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning**|Xianglin Yang et.al.|[2501.19180v1](http://arxiv.org/abs/2501.19180v1)|null|
|**2025-01-31**|**Improving Multi-Label Contrastive Learning by Leveraging Label Distribution**|Ning Chen et.al.|[2501.19145v1](http://arxiv.org/abs/2501.19145v1)|null|
|**2025-01-31**|**Imitation Game for Adversarial Disillusion with Multimodal Generative Chain-of-Thought Role-Play**|Ching-Chun Chang et.al.|[2501.19143v1](http://arxiv.org/abs/2501.19143v1)|null|
|**2025-01-31**|**A Metric for the Balance of Information in Graph Learning**|Alex O. Davies et.al.|[2501.19137v1](http://arxiv.org/abs/2501.19137v1)|null|
|**2025-01-31**|**Mixed Feelings: Cross-Domain Sentiment Classification of Patient Feedback**|Egil Rønningstad et.al.|[2501.19134v1](http://arxiv.org/abs/2501.19134v1)|null|
|**2025-01-31**|**FedRTS: Federated Robust Pruning via Combinatorial Thompson Sampling**|Hong Huang et.al.|[2501.19122v1](http://arxiv.org/abs/2501.19122v1)|null|
|**2025-01-31**|**Principal Components for Neural Network Initialization**|Nhan Phan et.al.|[2501.19114v1](http://arxiv.org/abs/2501.19114v1)|null|
|**2025-01-31**|**PathE: Leveraging Entity-Agnostic Paths for Parameter-Efficient Knowledge Graph Embeddings**|Ioannis Reklos et.al.|[2501.19095v1](http://arxiv.org/abs/2501.19095v1)|[link](https://github.com/ireklos/pathe)|
|**2025-01-31**|**Improving Low-Resource Sequence Labeling with Knowledge Fusion and Contextual Label Explanations**|Peichao Lai et.al.|[2501.19093v1](http://arxiv.org/abs/2501.19093v1)|null|
|**2025-01-31**|**Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**|Xiangyu Sun et.al.|[2501.19086v1](http://arxiv.org/abs/2501.19086v1)|null|
|**2025-01-31**|**Improving vision-language alignment with graph spiking hybrid Networks**|Siyu Zhang et.al.|[2501.19069v1](http://arxiv.org/abs/2501.19069v1)|null|
|**2025-01-31**|**BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting**|Zhixuan Li et.al.|[2501.19065v1](http://arxiv.org/abs/2501.19065v1)|null|
|**2025-01-31**|**Enabling Autonomic Microservice Management through Self-Learning Agents**|Fenglin Yu et.al.|[2501.19056v1](http://arxiv.org/abs/2501.19056v1)|null|
|**2025-01-31**|**Towards Physiologically Sensible Predictions via the Rule-based Reinforcement Learning Layer**|Lingwei Zhu et.al.|[2501.19055v1](http://arxiv.org/abs/2501.19055v1)|null|
|**2025-01-31**|**Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)**|Maja Pavlovic et.al.|[2501.19047v2](http://arxiv.org/abs/2501.19047v2)|null|
|**2025-01-31**|**Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors**|Simon Idoko et.al.|[2501.19042v1](http://arxiv.org/abs/2501.19042v1)|[link](https://github.com/cisimon7/swarmgen)|
|**2025-01-31**|**On the Impact of Noise in Differentially Private Text Rewriting**|Stephen Meisenbacher et.al.|[2501.19022v1](http://arxiv.org/abs/2501.19022v1)|[link](https://github.com/sjmeis/privfill)|
|**2025-01-31**|**Scalable Multi-phase Word Embedding Using Conjunctive Propositional Clauses**|Ahmed K. Kadhim et.al.|[2501.19018v2](http://arxiv.org/abs/2501.19018v2)|null|
|**2025-01-31**|**Calling a Spade a Heart: Gaslighting Multimodal Large Language Models via Negation**|Bin Zhu et.al.|[2501.19017v1](http://arxiv.org/abs/2501.19017v1)|null|
|**2025-01-31**|**Importing Phantoms: Measuring LLM Package Hallucination Vulnerabilities**|Arjun Krishna et.al.|[2501.19012v1](http://arxiv.org/abs/2501.19012v1)|null|
|**2025-01-31**|**DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition**|Wonjun Lee et.al.|[2501.19010v2](http://arxiv.org/abs/2501.19010v2)|null|
|**2025-01-31**|**Virtual airways heatmaps to optimize point of entry location in lung biopsy planning systems**|Debora Gil et.al.|[2501.19003v1](http://arxiv.org/abs/2501.19003v1)|null|
|**2025-01-31**|**Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings**|Ahmed K. Kadhim et.al.|[2501.18998v1](http://arxiv.org/abs/2501.18998v1)|null|
|**2025-01-31**|**VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian Extended Kalman Filter Integration**|Jian-Yu Chen et.al.|[2501.18994v1](http://arxiv.org/abs/2501.18994v1)|[link](https://github.com/ipclab/vkfpos)|
|**2025-01-31**|**Symmetric Pruning of Large Language Models**|Kai Yi et.al.|[2501.18980v1](http://arxiv.org/abs/2501.18980v1)|null|
|**2025-01-31**|**GPO-VAE: Modeling Explainable Gene Perturbation Responses utilizing GRN-Aligned Parameter Optimization**|Seungheun Baek et.al.|[2501.18973v1](http://arxiv.org/abs/2501.18973v1)|[link](https://github.com/dmis-lab/gpo-vae)|
|**2025-01-31**|**Intrinsic Tensor Field Propagation in Large Language Models: A Novel Approach to Contextual Information Flow**|Alfred Bexley et.al.|[2501.18957v1](http://arxiv.org/abs/2501.18957v1)|null|
|**2025-01-31**|**Deep Learning based Quasi-consciousness Training for Robot Intelligent Model**|Yuchun Li et.al.|[2501.18955v1](http://arxiv.org/abs/2501.18955v1)|null|
|**2025-01-31**|**Fantastic Targets for Concept Erasure in Diffusion Models and Where To Find Them**|Anh Bui et.al.|[2501.18950v1](http://arxiv.org/abs/2501.18950v1)|[link](https://github.com/tuananhbui89/adaptive-guided-erasure)|
|**2025-01-31**|**Language Games as the Pathway to Artificial Superhuman Intelligence**|Ying Wen et.al.|[2501.18924v1](http://arxiv.org/abs/2501.18924v1)|null|
|**2025-01-31**|**KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search**|Haoran Luo et.al.|[2501.18922v1](http://arxiv.org/abs/2501.18922v1)|[link](https://github.com/lhrlab/kbqa-o1)|
|**2025-01-31**|**Deepfake Detection of Singing Voices With Whisper Encodings**|Falguni Sharma et.al.|[2501.18919v1](http://arxiv.org/abs/2501.18919v1)|null|
|**2025-01-31**|**Lightspeed Geometric Dataset Distance via Sliced Optimal Transport**|Khai Nguyen et.al.|[2501.18901v1](http://arxiv.org/abs/2501.18901v1)|null|
|**2025-01-31**|**Efficient Supernet Training with Orthogonal Softmax for Scalable ASR Model Compression**|Jingjing Xu et.al.|[2501.18895v1](http://arxiv.org/abs/2501.18895v1)|null|
|**2025-01-31**|**Building Bridges, Not Walls -- Advancing Interpretability by Unifying Feature, Data, and Model Component Attribution**|Shichang Zhang et.al.|[2501.18887v1](http://arxiv.org/abs/2501.18887v1)|null|
|**2025-01-31**|**UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent**|Jianke Zhang et.al.|[2501.18867v2](http://arxiv.org/abs/2501.18867v2)|null|
|**2025-01-31**|**REG: Rectified Gradient Guidance for Conditional Diffusion Models**|Zhengqi Gao et.al.|[2501.18865v1](http://arxiv.org/abs/2501.18865v1)|null|
|**2025-01-31**|**BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning**|Han Zhong et.al.|[2501.18858v1](http://arxiv.org/abs/2501.18858v1)|null|
|**2025-01-31**|**Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities**|Yaping Chai et.al.|[2501.18845v1](http://arxiv.org/abs/2501.18845v1)|null|
|**2025-01-31**|**Partially Rewriting a Transformer in Natural Language**|Gonçalo Paulo et.al.|[2501.18838v1](http://arxiv.org/abs/2501.18838v1)|[link](https://github.com/eleutherai/sae-auto-interp)|
|**2025-01-31**|**Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming**|Mrinank Sharma et.al.|[2501.18837v1](http://arxiv.org/abs/2501.18837v1)|null|
|**2025-01-31**|**Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential**|Chenyu Gao et.al.|[2501.18834v1](http://arxiv.org/abs/2501.18834v1)|null|
|**2025-01-31**|**Structural Embedding Projection for Contextual Large Language Model Inference**|Vincent Enoasmo et.al.|[2501.18826v1](http://arxiv.org/abs/2501.18826v1)|null|
|**2025-01-31**|**Memory-Efficient Fine-Tuning of Transformers via Token Selection**|Antoine Simoulin et.al.|[2501.18824v1](http://arxiv.org/abs/2501.18824v1)|null|
|**2025-01-31**|**An Optimal Cascade Feature-Level Spatiotemporal Fusion Strategy for Anomaly Detection in CAN Bus**|Mohammad Fatahi et.al.|[2501.18821v1](http://arxiv.org/abs/2501.18821v1)|null|
|**2025-01-31**|**Bridging the Reasoning Gap: Small LLMs Can Plan with Generalised Strategies**|Andrey Borro et.al.|[2501.18817v1](http://arxiv.org/abs/2501.18817v1)|[link](https://github.com/andrey-borro/reasoning-gap)|
|**2025-01-31**|**Large Language Models as Common-Sense Heuristics**|Andrey Borro et.al.|[2501.18816v1](http://arxiv.org/abs/2501.18816v1)|null|
|**2025-01-31**|**An Adversarial Approach to Register Extreme Resolution Tissue Cleared 3D Brain Images**|Abdullah Naziba et.al.|[2501.18815v1](http://arxiv.org/abs/2501.18815v1)|[link](https://github.com/BioMedIA/IRTK)|
|**2025-01-30**|**Every Image Listens, Every Image Dances: Music-Driven Image Animation**|Zhikang Dong et.al.|[2501.18801v1](http://arxiv.org/abs/2501.18801v1)|null|
|**2025-01-30**|**Compositional Generalization Requires More Than Disentangled Representations**|Qiyao Liang et.al.|[2501.18797v1](http://arxiv.org/abs/2501.18797v1)|null|
|**2025-01-30**|**Rope to Nope and Back Again: A New Hybrid Attention Strategy**|Bowen Yang et.al.|[2501.18795v1](http://arxiv.org/abs/2501.18795v1)|null|
|**2025-01-30**|**Survey and Improvement Strategies for Gene Prioritization with Large Language Models**|Matthew Neeley et.al.|[2501.18794v1](http://arxiv.org/abs/2501.18794v1)|null|
|**2025-01-30**|**OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization**|Kelvin Kan et.al.|[2501.18793v1](http://arxiv.org/abs/2501.18793v1)|null|
|**2025-01-30**|**LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?**|Alexander Tuisov et.al.|[2501.18784v1](http://arxiv.org/abs/2501.18784v1)|null|
|**2025-01-30**|**Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact on Machine Translation**|Muhammed Yusuf Kocyigit et.al.|[2501.18771v1](http://arxiv.org/abs/2501.18771v1)|null|
|**2025-01-30**|**Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization**|Michael S. Yao et.al.|[2501.18768v1](http://arxiv.org/abs/2501.18768v1)|[link](https://github.com/michael-s-yao/dynamo)|
|**2025-01-30**|**Breaking the Fake News Barrier: Deep Learning Approaches in Bangla Language**|Pronoy Kumar Mondal et.al.|[2501.18766v1](http://arxiv.org/abs/2501.18766v1)|null|
|**2025-01-30**|**Revisiting Projection-based Data Transfer for Cross-Lingual Named Entity Recognition in Low-Resource Languages**|Andrei Politov et.al.|[2501.18750v1](http://arxiv.org/abs/2501.18750v1)|[link](https://github.com/cross-lingual-ner/projection-data-transfer-cross-lingual-ner)|
|**2025-01-30**|**Synthetic Data Generation for Augmenting Small Samples**|Dan Liu et.al.|[2501.18741v1](http://arxiv.org/abs/2501.18741v1)|null|
|**2025-01-30**|**Neural Graph Pattern Machine**|Zehong Wang et.al.|[2501.18739v1](http://arxiv.org/abs/2501.18739v1)|null|
|**2025-01-30**|**Examining the Robustness of Large Language Models across Language Complexity**|Jiayi Zhang et.al.|[2501.18738v1](http://arxiv.org/abs/2501.18738v1)|null|
|**2025-01-30**|**Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation**|Yuelei Li et.al.|[2501.18733v1](http://arxiv.org/abs/2501.18733v1)|null|

#### Abstracts
##### **Redefining Machine Unlearning: A Conformal Prediction-Motivated Approach**
2501.19403v1 by Yingdan Shi, Ren Wang

Machine unlearning seeks to systematically remove specified data from a
trained model, effectively achieving a state as though the data had never been
encountered during training. While metrics such as Unlearning Accuracy (UA) and
Membership Inference Attack (MIA) provide a baseline for assessing unlearning
performance, they fall short of evaluating the completeness and reliability of
forgetting. This is because the ground truth labels remain potential candidates
within the scope of uncertainty quantification, leaving gaps in the evaluation
of true forgetting. In this paper, we identify critical limitations in existing
unlearning metrics and propose enhanced evaluation metrics inspired by
conformal prediction. Our metrics can effectively capture the extent to which
ground truth labels are excluded from the prediction set. Furthermore, we
observe that many existing machine unlearning methods do not achieve
satisfactory forgetting performance when evaluated with our new metrics. To
address this, we propose an unlearning framework that integrates conformal
prediction insights into Carlini & Wagner adversarial attack loss. Extensive
experiments on the image classification task demonstrate that our enhanced
metrics offer deeper insights into unlearning effectiveness, and that our
unlearning framework significantly improves the forgetting quality of
unlearning methods.

摘要：機器去學習旨在系統性地從訓練好的模型中移除指定的資料，有效地達成一種狀態，就好像在訓練過程中從未遇到過資料一樣。雖然指標例如去學習準確度 (UA) 和成員推論攻擊 (MIA) 提供了一個評估去學習效能的基準，但他們無法評估遺忘的完整性和可靠性。這是因為基本事實標籤仍然是未確定量化範圍內的潛在候選者，在評估真正的遺忘時留下了空白。在本文中，我們找出現有去學習指標中的關鍵限制，並提出受共形預測啟發的增強評估指標。我們的指標可以有效捕捉基本事實標籤從預測集合中被排除的程度。此外，我們觀察到許多現有的機器去學習方法在使用我們的新指標評估時，無法達成令人滿意的遺忘效能。為了解決這個問題，我們提出一個去學習架構，將共形預測見解整合到 Carlini & Wagner 對抗攻擊損失中。在影像分類任務上的廣泛實驗證明，我們增強的指標對去學習有效性提供了更深入的見解，而且我們的去學習架構顯著地改善了去學習方法的遺忘品質。

##### **Vintix: Action Model via In-Context Reinforcement Learning**
2501.19400v1 by Andrey Polubarov, Nikita Lyubaykin, Alexander Derevyagin, Ilya Zisman, Denis Tarasov, Alexander Nikulin, Vladislav Kurenkov

In-Context Reinforcement Learning (ICRL) represents a promising paradigm for
developing generalist agents that learn at inference time through
trial-and-error interactions, analogous to how large language models adapt
contextually, but with a focus on reward maximization. However, the scalability
of ICRL beyond toy tasks and single-domain settings remains an open challenge.
In this work, we present the first steps toward scaling ICRL by introducing a
fixed, cross-domain model capable of learning behaviors through in-context
reinforcement learning. Our results demonstrate that Algorithm Distillation, a
framework designed to facilitate ICRL, offers a compelling and competitive
alternative to expert distillation to construct versatile action models. These
findings highlight the potential of ICRL as a scalable approach for generalist
decision-making systems. Code to be released at
https://github.com/dunnolab/vintix

摘要：情境強化學習 (ICRL) 代表一種有前途的典範，用於開發在推理時間透過試錯互動進行學習的通才代理，類似於大型語言模型如何根據情境進行調整，但重點在於獎勵最大化。然而，ICRL 的可擴展性超越玩具任務和單一領域設定仍然是一個公開的挑戰。在這項工作中，我們介紹了擴展 ICRL 的第一步，方法是引入一個固定的跨領域模型，能夠透過情境強化學習學習行為。我們的結果證明了演算法蒸餾（一種旨在促進 ICRL 的架構）提供了一個引人注目且具有競爭力的替代方案，可以用於專家蒸餾來建構多功能動作模型。這些發現突顯了 ICRL 作為通才決策系統的可擴展方法的潛力。程式碼將在 https://github.com/dunnolab/vintix 發布

##### **Scalable-Softmax Is Superior for Attention**
2501.19399v1 by Ken M. Nakanishi

The maximum element of the vector output by the Softmax function approaches
zero as the input vector size increases. Transformer-based language models rely
on Softmax to compute attention scores, causing the attention distribution to
flatten as the context size grows. This reduces the model's ability to
prioritize key information effectively and potentially limits its length
generalization. To address this problem, we propose Scalable-Softmax (SSMax),
which replaces Softmax in scenarios where the input vector size varies. SSMax
can be seamlessly integrated into existing Transformer-based architectures.
Experimental results in language modeling show that models using SSMax not only
achieve faster loss reduction during pretraining but also significantly improve
performance in long contexts and key information retrieval. Furthermore, an
analysis of attention scores reveals that SSMax enables the model to focus
attention on key information even in long contexts. Additionally, although
models that use SSMax from the beginning of pretraining achieve better length
generalization, those that have already started pretraining can still gain some
of this ability by replacing Softmax in the attention layers with SSMax, either
during or after pretraining.

摘要：随着输入向量大小的增加，Softmax 函数输出向量的最大元素接近于零。基于 Transformer 的语言模型依赖 Softmax 来计算注意力分数，导致注意力分布在上下文大小增长时趋于平坦。这降低了模型有效优先考虑关键信息的的能力，并可能限制其长度泛化。为了解决这个问题，我们提出了可扩展 Softmax (SSMax)，它在输入向量大小变化的情况下替换 Softmax。SSMax 可以无缝集成到现有的基于 Transformer 的架构中。语言建模的实验结果表明，使用 SSMax 的模型不仅在预训练期间实现了更快的损失降低，而且在长上下文和关键信息检索方面也显著提高了性能。此外，对注意力分数的分析表明，SSMax 使模型能够即使在长上下文中也能将注意力集中在关键信息上。此外，尽管从预训练开始就使用 SSMax 的模型实现了更好的长度泛化，但已经开始预训练的模型仍然可以通过在注意力层中用 SSMax 替换 Softmax（在预训练期间或之后）来获得一些这种能力。

##### **Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game**
2501.19398v1 by Mustafa O. Karabag, Ufuk Topcu

Large language model-based (LLM-based) agents have become common in settings
that include non-cooperative parties. In such settings, agents' decision-making
needs to conceal information from their adversaries, reveal information to
their cooperators, and infer information to identify the other agents'
characteristics. To investigate whether LLMs have these information control and
decision-making capabilities, we make LLM agents play the language-based
hidden-identity game, The Chameleon. In the game, a group of non-chameleon
agents who do not know each other aim to identify the chameleon agent without
revealing a secret. The game requires the aforementioned information control
capabilities both as a chameleon and a non-chameleon. The empirical results
show that while non-chameleon LLM agents identify the chameleon, they fail to
conceal the secret from the chameleon, and their winning probability is far
from the levels of even trivial strategies. To formally explain this behavior,
we give a theoretical analysis for a spectrum of strategies, from concealing to
revealing, and provide bounds on the non-chameleons' winning probability. Based
on the empirical results and theoretical analysis of different strategies, we
deduce that LLM-based non-chameleon agents reveal excessive information to
agents of unknown identities. Our results point to a weakness of contemporary
LLMs, including GPT-4, GPT-4o, Gemini 1.5, and Claude 3.5 Sonnet, in strategic
interactions.

摘要：<paragraph>基於大型語言模型 (LLM) 的代理已在包含非合作方的設定中變得常見。在這種設定中，代理的決策制定需要對其對手隱藏資訊、向其合作夥伴揭露資訊，並推論資訊以識別其他代理的特徵。為了調查 LLM 是否具備這些資訊控制和決策制定能力，我們讓 LLM 代理玩基於語言的隱藏身分遊戲，變色龍。在遊戲中，一群互不認識的非變色龍代理旨在識別變色龍代理，同時不透露秘密。該遊戲需要上述資訊控制能力，無論是作為變色龍還是非變色龍。實證結果表明，雖然非變色龍 LLM 代理識別出變色龍，但他們未能對變色龍隱藏秘密，而且他們的獲勝機率遠低於甚至微不足道的策略。為了正式解釋這種行為，我們對一系列策略進行了理論分析，從隱藏到揭露，並對非變色龍的獲勝機率提供了界限。根據不同策略的實證結果和理論分析，我們推論出基於 LLM 的非變色龍代理會向身分不明的代理透露過多資訊。我們的結果指出，當代 LLM 的一個弱點，包括 GPT-4、GPT-4o、Gemini 1.5 和 Claude 3.5 Sonnet，在策略互動中。</paragraph>

##### **s1: Simple test-time scaling**
2501.19393v2 by Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candès, Tatsunori Hashimoto

Test-time scaling is a promising new approach to language modeling that uses
extra test-time compute to improve performance. Recently, OpenAI's o1 model
showed this capability but did not publicly share its methodology, leading to
many replication efforts. We seek the simplest approach to achieve test-time
scaling and strong reasoning performance. First, we curate a small dataset s1K
of 1,000 questions paired with reasoning traces relying on three criteria we
validate through ablations: difficulty, diversity, and quality. Second, we
develop budget forcing to control test-time compute by forcefully terminating
the model's thinking process or lengthening it by appending "Wait" multiple
times to the model's generation when it tries to end. This can lead the model
to double-check its answer, often fixing incorrect reasoning steps. After
supervised finetuning the Qwen2.5-32B-Instruct language model on s1K and
equipping it with budget forcing, our model s1-32B exceeds o1-preview on
competition math questions by up to 27% (MATH and AIME24). Further, scaling
s1-32B with budget forcing allows extrapolating beyond its performance without
test-time intervention: from 50% to 57% on AIME24. Our model, data, and code
are open-source at https://github.com/simplescaling/s1

摘要：測試時間縮放是語言建模的一種有前途的新方法，它使用額外的測試時間計算來提升效能。最近，OpenAI 的 o1 模型展示了這種能力，但沒有公開分享其方法，導致許多複製工作。我們尋求最簡單的方法來實現測試時間縮放和強大的推理效能。首先，我們整理一個包含 1,000 個問題的小型資料集 s1K，並根據我們透過消融驗證的三個準則配對推理追蹤：難度、多樣性和品質。其次，我們開發預算強制來控制測試時間計算，方法是強制終止模型的思考過程，或在模型嘗試結束時多次附加「等待」來延長思考過程。這可能會導致模型仔細檢查其答案，通常會修正不正確的推理步驟。在對 Qwen2.5-32B-Instruct 語言模型進行監督微調並配備預算強制後，我們的模型 s1-32B 在競賽數學問題上超過 o1-preview，最多達 27%（MATH 和 AIME24）。此外，使用預算強制縮放 s1-32B 可以推演出超越其效能的表現，而無需測試時間介入：在 AIME24 上從 50% 提升到 57%。我們的模型、資料和程式碼在 https://github.com/simplescaling/s1 以開放原始碼形式提供

##### **Decoding-based Regression**
2501.19383v1 by Xingyou Song, Dara Bahri

Language models have recently been shown capable of performing regression
tasks wherein numeric predictions are represented as decoded strings. In this
work, we provide theoretical grounds for this capability and furthermore
investigate the utility of causal auto-regressive sequence models when they are
applied to any feature representation. We find that, despite being trained in
the usual way - for next-token prediction via cross-entropy loss -
decoding-based regression is as performant as traditional approaches for
tabular regression tasks, while being flexible enough to capture arbitrary
distributions, such as in the task of density estimation.

摘要：最近已證明語言模型有能力執行回歸任務，其中數值預測表示為解碼字串。在這項工作中，我們為此能力提供理論基礎，並進一步探討因果自回歸序列模型在應用於任何特徵表示時之效用。我們發現，儘管以傳統方式進行訓練（透過交叉熵損失進行下一個符號預測），但基於解碼的回歸與傳統方法一樣適用於表格回歸任務，同時足夠靈活以捕捉任意分佈，例如在密度估計任務中。

##### **TableMaster: A Recipe to Advance Table Understanding with Language Models**
2501.19378v1 by Lang Cao

Tables serve as a fundamental format for representing structured relational
data. While current language models (LMs) excel at many text-based tasks, they
still face challenges in table understanding due to the complex characteristics
of tabular data, such as their structured nature. In this paper, we aim to
enhance LMs for improved table understanding. We identify four key challenges:
1) difficulty in locating target data, 2) deficiency in table semantics, 3)
numerical inaccuracies in textual reasoning, and 4) semantic inflexibility in
symbolic reasoning. To address these issues, we propose TableMaster, a recipe
and comprehensive framework that integrates multiple solutions to overcome
these obstacles. TableMaster first extracts relevant table content and
verbalizes it with enriched semantic context. Additionally, we introduce
adaptive reasoning, a flexible approach that dynamically adjusts between
textual and symbolic reasoning, tailoring the reasoning process to each query.
Extensive analyses and experiments demonstrate our findings and the
effectiveness of TableMaster. On the WikiTQ dataset, TableMaster achieves an
accuracy of 78.13% using GPT-4o-mini, surpassing existing baselines.

摘要：表格作為表示結構化關係數據的基本格式。雖然目前的語言模型 (LM) 在許多基於文字的任務中表現出色，但由於表格數據的複雜特性（例如其結構化性質），它們在表格理解方面仍然面臨挑戰。在本文中，我們旨在增強 LM 以改善表格理解。我們確定了四個關鍵挑戰：1) 難以找到目標數據，2) 表格語義的不足，3) 文本推理中的數值不準確，以及 4) 符號推理中的語義不靈活性。為了解決這些問題，我們提出了 TableMaster，這是一個食譜和綜合框架，它整合了多種解決方案來克服這些障礙。TableMaster 首先提取相關的表格內容，並用豐富的語義上下文對其進行口頭化。此外，我們引入了自適應推理，這是一種靈活的方法，可在文本推理和符號推理之間動態調整，根據每個查詢定制推理過程。廣泛的分析和實驗證明了我們的發現和 TableMaster 的有效性。在 WikiTQ 數據集上，TableMaster 使用 GPT-4o-mini 達到了 78.13% 的準確度，超過了現有的基準。

##### **SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions**
2501.19377v2 by Dominik Wagner, Alexander Churchill, Siddharth Sigtia, Erik Marchi

In this work, we present and evaluate SELMA, a Speech-Enabled Language Model
for virtual Assistant interactions that integrates audio and text as inputs to
a Large Language Model (LLM). SELMA is designed to handle three primary and two
auxiliary tasks related to interactions with virtual assistants simultaneously
within a single end-to-end model. We employ low-rank adaptation modules for
parameter-efficient training of both the audio encoder and the LLM.
Additionally, we implement a feature pooling strategy enabling the system to
recognize global patterns and improve accuracy on tasks less reliant on
individual sequence elements. Experimental results on Voice Trigger (VT)
detection, Device-Directed Speech Detection (DDSD), and Automatic Speech
Recognition (ASR), demonstrate that our approach both simplifies the typical
input processing pipeline of virtual assistants significantly and also improves
performance compared to dedicated models for each individual task. SELMA yields
relative Equal-Error Rate improvements of 64% on the VT detection task, and 22%
on DDSD, while also achieving word error rates close to the baseline.

摘要：在這項工作中，我們提出並評估了 SELMA，一個語音啟用語言模型，用於虛擬助理互動，它將音訊和文字整合為大型語言模型 (LLM) 的輸入。SELMA 被設計為同時處理與虛擬助理互動相關的三個主要任務和兩個輔助任務，所有任務都在單一端到端模型中進行。我們採用低秩適應模組，用於音訊編碼器和 LLM 的參數有效率訓練。此外，我們實作了一個特徵池化策略，讓系統能辨識全域模式，並提升對不太依賴個別序列元素的任務的準確度。語音觸發 (VT) 偵測、裝置導向語音偵測 (DDSD) 和自動語音辨識 (ASR) 的實驗結果顯示，我們的做法大幅簡化了虛擬助理的典型輸入處理管線，而且也提升了效能，優於針對每個個別任務的專用模型。SELMA 在 VT 偵測任務上產生了 64% 的相對等錯誤率改進，在 DDSD 上產生了 22% 的改進，同時也在字元錯誤率上達到接近基線的表現。

##### **CoSTI: Consistency Models for (a faster) Spatio-Temporal Imputation**
2501.19364v1 by Javier Solís-García, Belén Vega-Márquez, Juan A. Nepomuceno, Isabel A. Nepomuceno-Chamorro

Multivariate Time Series Imputation (MTSI) is crucial for many applications,
such as healthcare monitoring and traffic management, where incomplete data can
compromise decision-making. Existing state-of-the-art methods, like Denoising
Diffusion Probabilistic Models (DDPMs), achieve high imputation accuracy;
however, they suffer from significant computational costs and are notably
time-consuming due to their iterative nature. In this work, we propose CoSTI,
an innovative adaptation of Consistency Models (CMs) for the MTSI domain. CoSTI
employs Consistency Training to achieve comparable imputation quality to DDPMs
while drastically reducing inference times, making it more suitable for
real-time applications. We evaluate CoSTI across multiple datasets and missing
data scenarios, demonstrating up to a 98% reduction in imputation time with
performance on par with diffusion-based models. This work bridges the gap
between efficiency and accuracy in generative imputation tasks, providing a
scalable solution for handling missing data in critical spatio-temporal
systems.

摘要：多變量時序插補 (MTSI) 對許多應用至關重要，例如醫療保健監測和交通管理，其中不完整數據可能會影響決策制定。現有的最先進方法，例如去噪擴散機率模型 (DDPM)，可實現高插補準確度；然而，它們的運算成本很高，而且由於其迭代性質，顯著耗時。在這項工作中，我們提出 CoSTI，這是相容性模型 (CM) 在 MTSI 領域的創新改編。CoSTI 使用相容性訓練來實現與 DDPM 相當的插補品質，同時大幅減少推理時間，使其更適合於即時應用。我們在多個資料集和缺失數據場景中評估 CoSTI，證明插補時間最多減少 98%，且效能與基於擴散的模型相當。這項工作彌合了生成插補任務中效率和準確性之間的差距，為處理關鍵時空系統中的缺失數據提供了可擴充的解決方案。

##### **We're Different, We're the Same: Creative Homogeneity Across LLMs**
2501.19361v1 by Emily Wenger, Yoed Kenett

Numerous powerful large language models (LLMs) are now available for use as
writing support tools, idea generators, and beyond. Although these LLMs are
marketed as helpful creative assistants, several works have shown that using an
LLM as a creative partner results in a narrower set of creative outputs.
However, these studies only consider the effects of interacting with a single
LLM, begging the question of whether such narrowed creativity stems from using
a particular LLM -- which arguably has a limited range of outputs -- or from
using LLMs in general as creative assistants. To study this question, we elicit
creative responses from humans and a broad set of LLMs using standardized
creativity tests and compare the population-level diversity of responses. We
find that LLM responses are much more similar to other LLM responses than human
responses are to each other, even after controlling for response structure and
other key variables. This finding of significant homogeneity in creative
outputs across the LLMs we evaluate adds a new dimension to the ongoing
conversation about creativity and LLMs. If today's LLMs behave similarly, using
them as a creative partners -- regardless of the model used -- may drive all
users towards a limited set of "creative" outputs.

摘要：現今有許多功能強大的大型語言模型 (LLM) 可用於書寫輔助工具、點子產生器等用途。儘管這些 LLM 被標榜為有用的創意助手，但多項研究顯示，將 LLM 用作創意夥伴會導致創意產出範圍較窄。然而，這些研究僅考慮與單一 LLM 互動的影響，因此引發了一個問題，即這種狹隘的創意是否源自使用特定 LLM（其產出範圍可能有限），或源自普遍將 LLM 用作創意助手。為了研究這個問題，我們使用標準化的創意測試從人類和廣泛的 LLM 中引出創意回應，並比較回應的族群層級多樣性。我們發現，即使在控制回應結構和其他關鍵變數後，LLM 回應與其他 LLM 回應的相似程度遠高於人類回應彼此的相似程度。我們評估的 LLM 在創意產出方面具有顯著同質性的發現，為關於創意和 LLM 的持續對話增添了一個新面向。如果現今的 LLM 行為類似，將它們用作創意夥伴（無論使用哪個模型）可能會驅使所有使用者朝著有限的「創意」產出邁進。

##### **Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SCICAP Challenge 2023**
2501.19353v1 by Ting-Yao E. Hsu, Yi-Li Hsu, Shaurya Rohatgi, Chieh-Yang Huang, Ho Yin Sam Ng, Ryan Rossi, Sungchul Kim, Tong Yu, Lun-Wei Ku, C. Lee Giles, Ting-Hao K. Huang

Since the SCICAP datasets launch in 2021, the research community has made
significant progress in generating captions for scientific figures in scholarly
articles. In 2023, the first SCICAP Challenge took place, inviting global teams
to use an expanded SCICAP dataset to develop models for captioning diverse
figure types across various academic fields. At the same time, text generation
models advanced quickly, with many powerful pre-trained large multimodal models
(LMMs) emerging that showed impressive capabilities in various
vision-and-language tasks. This paper presents an overview of the first SCICAP
Challenge and details the performance of various models on its data, capturing
a snapshot of the fields state. We found that professional editors
overwhelmingly preferred figure captions generated by GPT-4V over those from
all other models and even the original captions written by authors. Following
this key finding, we conducted detailed analyses to answer this question: Have
advanced LMMs solved the task of generating captions for scientific figures?

摘要：自 2021 年 SCICAP 資料集推出以來，研究社群在為學術期刊中的科學圖表產生標題方面取得了顯著進展。2023 年，第一屆 SCICAP 挑戰賽舉行，邀請全球團隊使用擴充的 SCICAP 資料集，為各個學術領域中不同的圖表類型開發標題模型。同時，文字生成模型快速進步，出現許多功能強大的預訓練大型多模態模型 (LMM)，在各種視覺和語言任務中展現出令人印象深刻的能力。本文概述了第一屆 SCICAP 挑戰賽，並詳細說明了各種模型在其資料上的表現，捕捉了該領域的現況。我們發現，專業編輯人員普遍偏好由 GPT-4V 生成的圖表標題，勝過所有其他模型，甚至勝過作者撰寫的原始標題。根據這一關鍵發現，我們進行了詳細分析，以回答這個問題：先進的 LMM 是否已解決為科學圖表產生標題的任務？

##### **PixelWorld: Towards Perceiving Everything as Pixels**
2501.19339v1 by Zhiheng Lyu, Xueguang Ma, Wenhu Chen

Existing foundation models typically process visual input as pixels and
textual input as tokens, a paradigm that contrasts with human perception, where
both modalities are processed in a unified manner. With the rise of embodied
and agentic AI, where inputs primarily come from camera pixels, the need for a
unified perception framework becomes increasingly evident. In this paper, we
propose to unify all modalities (text, tables, code, diagrams, images, etc) as
pixel inputs, i.e. "Perceive Everything as Pixels" (PEAP). We introduce
PixelWorld, a novel evaluation suite that unifies all the mentioned modalities
into pixel space to gauge the existing models' performance. Our findings show
that (1) PEAP outperforms baseline with token-based input in multimodal
datasets, benefiting from unified input for better disambiguation, (2)
significant declines in reasoning and coding capabilities across all models
when processing pixel-based input, underscoring the need to enhance foundation
models' perceptual abilities, (3) larger models can maintain strong performance
on non-reasoning tasks under PEAP, while smaller models like Phi-3.5-V suffer
significant performance degradation, (4) the attention pattern of PEAP is
highly aligned with text token input, (5) PEAP can be accelerated significantly
by exploiting the spatial sparsity. We conclude that the existing frontier
models are competent in pixel perception, however, there is still headroom for
improvement. Our code, dataset will be released upon acceptance.

摘要：現有的基礎模型通常將視覺輸入處理為像素，將文本輸入處理為符號，這種範例與人類感知形成對比，人類以統一的方式處理這兩種模式。隨著具身和能動 AI 的興起，其輸入主要來自相機像素，對統一感知架構的需求變得越來越明顯。在本文中，我們建議將所有模式（文本、表格、代碼、圖表、圖像等）統一為像素輸入，即「將所有內容視為像素」（PEAP）。我們介紹了 PixelWorld，這是一個新穎的評估套件，它將所有提到的模式統一到像素空間中，以評估現有模型的效能。我們的發現顯示：(1) PEAP 在多模式資料集中的表現優於基於符號輸入的基準，受益於統一輸入以獲得更好的消歧義，(2) 在處理基於像素的輸入時，所有模型的推理和編碼能力均大幅下降，這強調了增強基礎模型感知能力的必要性，(3) 較大的模型可以在 PEAP 下維持非推理任務的強勁效能，而較小的模型（如 Phi-3.5-V）則會遭受顯著的效能下降，(4) PEAP 的注意力模式與文本符號輸入高度一致，(5) PEAP 可以透過利用空間稀疏性來顯著加速。我們得出結論，現有的前沿模型在像素感知方面是勝任的，然而，仍有進步的空間。我們的程式碼和資料集將在獲得接受後釋出。

##### **Pathological MRI Segmentation by Synthetic Pathological Data Generation in Fetuses and Neonates**
2501.19338v1 by Misha P. T Kaandorp, Damola Agbelese, Hosna Asma-ull, Hyun-Gi Kim, Kelly Payette, Patrice Grehten, Gennari Antonio Giulio, Levente István Lánczi, Andras Jakab

Developing new methods for the automated analysis of clinical fetal and
neonatal MRI data is limited by the scarcity of annotated pathological datasets
and privacy concerns that often restrict data sharing, hindering the
effectiveness of deep learning models. We address this in two ways. First, we
introduce Fetal&Neonatal-DDPM, a novel diffusion model framework designed to
generate high-quality synthetic pathological fetal and neonatal MRIs from
semantic label images. Second, we enhance training data by modifying healthy
label images through morphological alterations to simulate conditions such as
ventriculomegaly, cerebellar and pontocerebellar hypoplasia, and microcephaly.
By leveraging Fetal&Neonatal-DDPM, we synthesize realistic pathological MRIs
from these modified pathological label images. Radiologists rated the synthetic
MRIs as significantly (p < 0.05) superior in quality and diagnostic value
compared to real MRIs, demonstrating features such as blood vessels and choroid
plexus, and improved alignment with label annotations. Synthetic pathological
data enhanced state-of-the-art nnUNet segmentation performance, particularly
for severe ventriculomegaly cases, with the greatest improvements achieved in
ventricle segmentation (Dice scores: 0.9253 vs. 0.7317). This study underscores
the potential of generative AI as transformative tool for data augmentation,
offering improved segmentation performance in pathological cases. This
development represents a significant step towards improving analysis and
segmentation accuracy in prenatal imaging, and also offers new ways for data
anonymization through the generation of pathologic image data.

摘要：<paragraph>開發用於自動分析臨床胎兒和新生兒 MRI 資料的新方法受到標註病理資料集稀少和隱私問題的限制，這些問題通常會限制資料共享，從而阻礙深度學習模型的有效性。我們以兩種方式解決這個問題。首先，我們引入了 Fetal&Neonatal-DDPM，這是一個新穎的擴散模型架構，旨在從語義標籤影像生成高品質的合成病理胎兒和新生兒 MRI。其次，我們透過形態改變來修改健康的標籤影像，以模擬腦室擴大、小腦和橋腦小腦發育不全以及小頭畸形等情況，從而增強訓練資料。透過利用 Fetal&Neonatal-DDPM，我們從這些修改後的病理標籤影像中合成了逼真的病理 MRI。放射科醫師評估合成 MRI 的品質和診斷價值顯著優於真實 MRI（p < 0.05），展示了血管和脈絡叢等特徵，並改善了與標籤註解的一致性。合成病理資料增強了最先進的 nnUNet 分割效能，特別是對於嚴重的腦室擴大病例，其中腦室分割（Dice 分數：0.9253 對 0.7317）的改善最大。這項研究強調了生成式 AI 作為資料擴充轉型工具的潛力，在病理病例中提供了改善的分割效能。這項發展代表了改善產前影像分析和分割準確性的重要一步，也為透過生成病理影像資料來進行資料匿名化提供了新方法。</paragraph>

##### **Homogeneity Bias as Differential Sampling Uncertainty in Language Models**
2501.19337v1 by Messi H. J. Lee, Soyeon Jeon

Prior research show that Large Language Models (LLMs) and Vision-Language
Models (VLMs) represent marginalized groups more homogeneously than dominant
groups. However, the mechanisms underlying this homogeneity bias remain
relatively unexplored. We propose that this bias emerges from systematic
differences in the probability distributions from which tokens are sampled at
inference-time. Analyzing three measures of uncertainty in token sampling
distributions-entropy, perplexity, and probability of differentiation-we find
that in some models, specifically GPT-4 Turbo and Llama-3.2, tokens are sampled
more deterministically when generating texts about marginalized groups (i.e.,
Black Americans and women) compared to their dominant group counterparts (i.e.,
White Americans and men). While these findings may help explain homogeneity
bias in certain models, the patterns did not replicate across all VLMs tested,
suggesting multiple mechanisms may contribute to homogeneity bias in AI.

摘要：先前的研究表明，大型語言模型 (LLM) 和視覺語言模型 (VLM) 以比主流群體更同質的方式呈現邊緣群體。然而，這種同質性偏誤的底層機制仍然相對未被探討。我們提出這種偏誤源於在推論時間對令牌進行抽樣的機率分佈中的系統性差異。分析令牌抽樣分佈中的三個不確定性測量值——熵、困惑度和差異機率——我們發現，在某些模型中，特別是 GPT-4 Turbo 和 Llama-3.2，與其主流群體對應者（即白人美國人和男性）相比，在生成有關邊緣群體（即黑人美國人和女性）的文本時，令牌的抽樣更具確定性。雖然這些發現可能有助於解釋某些模型中的同質性偏誤，但這些模式並未在所有測試的 VLM 中複製，這表明多種機制可能導致 AI 中的同質性偏誤。

##### **What is causal about causal models and representations?**
2501.19335v2 by Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald

Causal Bayesian networks are 'causal' models since they make predictions
about interventional distributions. To connect such causal model predictions to
real-world outcomes, we must determine which actions in the world correspond to
which interventions in the model. For example, to interpret an action as an
intervention on a treatment variable, the action will presumably have to a)
change the distribution of treatment in a way that corresponds to the
intervention, and b) not change other aspects, such as how the outcome depends
on the treatment; while the marginal distributions of some variables may change
as an effect. We introduce a formal framework to make such requirements for
different interpretations of actions as interventions precise. We prove that
the seemingly natural interpretation of actions as interventions is circular:
Under this interpretation, every causal Bayesian network that correctly models
the observational distribution is trivially also interventionally valid, and no
action yields empirical data that could possibly falsify such a model. We prove
an impossibility result: No interpretation exists that is non-circular and
simultaneously satisfies a set of natural desiderata. Instead, we examine
non-circular interpretations that may violate some desiderata and show how this
may in turn enable the falsification of causal models. By rigorously examining
how a causal Bayesian network could be a 'causal' model of the world instead of
merely a mathematical object, our formal framework contributes to the
conceptual foundations of causal representation learning, causal discovery, and
causal abstraction, while also highlighting some limitations of existing
approaches.

摘要：因果貝氏網路是「因果」模型，因為它們會對介入分佈做出預測。為了將此類因果模型預測與真實世界的結果連結，我們必須確定世界中的哪些動作對應於模型中的哪些介入。例如，要將動作解讀為對治療變數的介入，則該動作可能必須 a) 以對應於介入的方式來改變治療分佈，以及 b) 不改變其他面向，例如結果如何取決於治療；而某些變數的邊際分佈可能會因為效應而改變。我們引入一個正式架構來對動作作為介入的不同解讀做出此類要求。我們證明，將動作解讀為介入的看似自然解讀是循環的：在此解讀下，正確建模觀察分佈的每個因果貝氏網路在介入上也微不足道地有效，而且沒有動作會產生經驗資料，可能證偽此類模型。我們證明了一個不可能的結果：沒有解讀是非循環的，同時滿足一組自然的理想。相反地，我們檢視可能違反某些理想的非循環解讀，並展示這反過來如何能夠證偽因果模型。透過嚴謹地檢視因果貝氏網路如何成為世界的「因果」模型，而不是僅僅是一個數學物件，我們的正式架構有助於因果表徵學習、因果發現和因果抽象的概念基礎，同時也突顯了現有方法的一些限制。

##### **Capturing Temporal Dynamics in Large-Scale Canopy Tree Height Estimation**
2501.19328v1 by Jan Pauls, Max Zimmer, Berkant Turan, Sassan Saatchi, Philippe Ciais, Sebastian Pokutta, Fabian Gieseke

With the rise in global greenhouse gas emissions, accurate large-scale tree
canopy height maps are essential for understanding forest structure, estimating
above-ground biomass, and monitoring ecological disruptions. To this end, we
present a novel approach to generate large-scale, high-resolution canopy height
maps over time. Our model accurately predicts canopy height over multiple years
given Sentinel-2 time series satellite data. Using GEDI LiDAR data as the
ground truth for training the model, we present the first 10m resolution
temporal canopy height map of the European continent for the period 2019-2022.
As part of this product, we also offer a detailed canopy height map for 2020,
providing more precise estimates than previous studies. Our pipeline and the
resulting temporal height map are publicly available, enabling comprehensive
large-scale monitoring of forests and, hence, facilitating future research and
ecological analyses. For an interactive viewer, see
https://europetreemap.projects.earthengine.app/view/temporalcanopyheight.

摘要：隨著全球溫室氣體排放量的增加，準確的大規模樹冠高度圖對於理解森林結構、估計地上生物量和監測生態破壞至關重要。為此，我們提出了一種新的方法來生成大規模、高解析度的樹冠高度圖。我們的模型準確預測了多年來給定 Sentinel-2 時間序列衛星數據的樹冠高度。使用 GEDI LiDAR 數據作為訓練模型的真實情況，我們展示了第一個 2019-2022 年期間歐洲大陸 10m 解析度的時間樹冠高度圖。作為該產品的一部分，我們還提供 2020 年的詳細樹冠高度圖，提供比以前的研究更精確的估計。我們的管道和生成的時態高度圖是公開的，可以對森林進行全面的大規模監控，從而促進未來的研究和生態分析。有關互動查看器，請參閱 https://europetreemap.projects.earthengine.app/view/temporalcanopyheight。

##### **Reward-Guided Speculative Decoding for Efficient LLM Reasoning**
2501.19324v1 by Baohao Liao, Yuhui Xu, Hanze Dong, Junnan Li, Christof Monz, Silvio Savarese, Doyen Sahoo, Caiming Xiong

We introduce Reward-Guided Speculative Decoding (RSD), a novel framework
aimed at improving the efficiency of inference in large language models (LLMs).
RSD synergistically combines a lightweight draft model with a more powerful
target model, incorporating a controlled bias to prioritize high-reward
outputs, in contrast to existing speculative decoding methods that enforce
strict unbiasedness. RSD employs a process reward model to evaluate
intermediate decoding steps and dynamically decide whether to invoke the target
model, optimizing the trade-off between computational cost and output quality.
We theoretically demonstrate that a threshold-based mixture strategy achieves
an optimal balance between resource utilization and performance. Extensive
evaluations on challenging reasoning benchmarks, including Olympiad-level
tasks, show that RSD delivers significant efficiency gains against decoding
with the target model only (up to 4.4x fewer FLOPs), while achieving
significant better accuracy than parallel decoding method on average (up to
+3.5). These results highlight RSD as a robust and cost-effective approach for
deploying LLMs in resource-intensive scenarios.

摘要：<paragraph>我們引入了獎勵引導式推測解碼 (RSD)，一種旨在提高大型語言模型 (LLM) 推論效率的新框架。RSD 協同結合輕量級草稿模型和更強大的目標模型，並納入受控偏差以優先考慮高獎勵輸出，這與現有的推測解碼方法形成對比，後者強制執行嚴格的無偏差性。RSD 使用過程獎勵模型來評估中間解碼步驟，並動態決定是否調用目標模型，從而優化計算成本和輸出質量之間的權衡。我們在理論上證明，基於閾值的混合策略在資源利用和性能之間實現了最佳平衡。在具有挑戰性的推理基準上的廣泛評估，包括奧林匹克級別的任務，表明 RSD 在僅使用目標模型進行解碼的情況下提供了顯著的效率提升（最多減少 4.4 倍的 FLOP），同時比並行解碼方法平均獲得顯著更好的準確度（最多 +3.5）。這些結果突出了 RSD 作為一種強大且經濟高效的方法，用於在資源密集型場景中部署 LLM。</paragraph>

##### **Language Bias in Self-Supervised Learning For Automatic Speech Recognition**
2501.19321v1 by Edward Storey, Naomi Harte, Peter Bell

Self-supervised learning (SSL) is used in deep learning to train on large
datasets without the need for expensive labelling of the data. Recently, large
Automatic Speech Recognition (ASR) models such as XLS-R have utilised SSL to
train on over one hundred different languages simultaneously. However, deeper
investigation shows that the bulk of the training data for XLS-R comes from a
small number of languages. Biases learned through SSL have been shown to exist
in multiple domains, but language bias in multilingual SSL ASR has not been
thoroughly examined. In this paper, we utilise the Lottery Ticket Hypothesis
(LTH) to identify language-specific subnetworks within XLS-R and test the
performance of these subnetworks on a variety of different languages. We are
able to show that when fine-tuning, XLS-R bypasses traditional linguistic
knowledge and builds only on weights learned from the languages with the
largest data contribution to the pretraining data.

摘要：自監督學習 (SSL) 用於深度學習，在無需昂貴資料標籤的情況下，訓練大型資料集。最近，大型自動語音辨識 (ASR) 模型（例如 XLS-R）已利用 SSL 同時訓練超過一百種不同的語言。然而，更深入的研究顯示，XLS-R 的大部分訓練資料來自少數語言。已證明透過 SSL 學習的偏見存在於多個領域，但尚未徹底檢驗多語言 SSL ASR 中的語言偏見。在本文中，我們利用樂透券假說 (LTH) 來識別 XLS-R 中特定語言的子網路，並測試這些子網路在各種不同語言上的效能。我們能夠證明，在微調時，XLS-R 繞過傳統語言知識，僅建構在從對預訓練資料貢獻最大資料的語言中學習到的權重上。

##### **MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems**
2501.19318v1 by Anirudh Chari, Suraj Reddy, Aditya Tiwari, Richard Lian, Brian Zhou

While large language models (LLMs) have shown promising capabilities as
zero-shot planners for embodied agents, their inability to learn from
experience and build persistent mental models limits their robustness in
complex open-world environments like Minecraft. We introduce MINDSTORES, an
experience-augmented planning framework that enables embodied agents to build
and leverage mental models through natural interaction with their environment.
Drawing inspiration from how humans construct and refine cognitive mental
models, our approach extends existing zero-shot LLM planning by maintaining a
database of past experiences that informs future planning iterations. The key
innovation is representing accumulated experiences as natural language
embeddings of (state, task, plan, outcome) tuples, which can then be
efficiently retrieved and reasoned over by an LLM planner to generate insights
and guide plan refinement for novel states and tasks. Through extensive
experiments in the MineDojo environment, a simulation environment for agents in
Minecraft that provides low-level controls for Minecraft, we find that
MINDSTORES learns and applies its knowledge significantly better than existing
memory-based LLM planners while maintaining the flexibility and generalization
benefits of zero-shot approaches, representing an important step toward more
capable embodied AI systems that can learn continuously through natural
experience.

摘要：儘管大型語言模型 (LLM) 已展現出作為具身代理人的零次規劃器的潛在能力，但它們無法從經驗中學習和建立持續的心理模型，限制了它們在 Minecraft 等複雜的開放世界環境中的穩健性。我們引入了 MINDSTORES，一個經驗增強規劃框架，讓具身代理人能夠透過與環境的自然互動建立和利用心理模型。我們的做法汲取了人類建構和精進認知心理模型的方式，透過維護一個過去經驗的資料庫，為未來的規劃迭代提供資訊，來擴充現有的零次 LLM 規劃。關鍵創新是將累積的經驗表示為 (狀態、任務、計畫、結果) 元組的自然語言嵌入，然後 LLM 規劃器可以有效地擷取和推理這些嵌入，以產生見解並引導新狀態和任務的計畫精進。透過在 MineDojo 環境中進行廣泛的實驗，這是一個為 Minecraft 中的代理人提供的模擬環境，提供 Minecraft 的低階控制，我們發現 MINDSTORES 的學習和應用知識顯著優於現有的基於記憶的 LLM 規劃器，同時保持零次方法的靈活性與泛化優點，代表著邁向更強大的具身 AI 系統的重要一步，這些系統可以透過自然經驗持續學習。

##### **LLM-based Affective Text Generation Quality Based on Different Quantization Values**
2501.19317v1 by Yarik Menchaca Resendiz, Roman Klinger

Large language models exhibit a remarkable capacity in language generation
and comprehension. These advances enable AI systems to produce more human-like
and emotionally engaging text. However, these models rely on a large number of
parameters, requiring significant computational resources for training and
inference. In some scenarios, accessing these resources can be challenging
(e.g., budget or hardware limitations). Techniques like reducing precision bits
can make models more memory-efficient, reducing the computational resources
needed, at the cost of reduced accuracy. This paper addresses the trade-off
between different quantization values, GPU RAM utilization, and text quality in
affective text generation (e.g., "I really enjoy running in the snow-covered
forest"). To evaluate, we use an emotion classifier and ten seed prompts to
generate affective text. We test three setups of precision bits (8, 16, and 32)
across five open-weight language models from two different families. Our
findings demonstrate that bit reductions lead to memory savings, achieving a
reduction of 76%. However, this optimization comes with a trade-off, leading to
a decrease of up to 10 pp in F1 score for larger models and an increase of 10
pp for smaller models, along with roughly double the inference time. In terms
of text quality, larger models at lower quantization levels generally
outperform smaller, higher-precision models -- while requiring similar memory.

摘要：大型語言模型在語言生成和理解方面表現出非凡的能力。這些進展使 AI 系統能夠產生更接近人類語言和情感參與度更高的文字。然而，這些模型依賴於大量的參數，需要大量的計算資源進行訓練和推論。在某些情況下，存取這些資源可能具有挑戰性（例如，預算或硬體限制）。像降低精確度位元數這樣的技術可以使模型更省記憶體，減少所需的計算資源，但代價是降低準確度。本文探討了在情感文字生成（例如，「我真的很享受在白雪覆蓋的森林中跑步」）中不同量化值、GPU RAM 使用率和文字品質之間的取捨。為了評估，我們使用情緒分類器和十個種子提示來生成情感文字。我們測試了來自兩個不同系列的五個開放權重語言模型的精確度位元數（8、16 和 32）的三種設定。我們的研究結果表明，位元數減少會導致記憶體節省，節省幅度達到 76%。然而，這種最佳化是有代價的，導致較大模型的 F1 分數降低多達 10 個百分點，較小模型的 F1 分數增加 10 個百分點，同時推論時間大約增加一倍。在文字品質方面，量化等級較低的較大模型通常優於量化等級較高的較小模型——同時需要類似的記憶體。

##### **Reverse Probing: Evaluating Knowledge Transfer via Finetuned Task Embeddings for Coreference Resolution**
2501.19316v1 by Tatiana Anikina, Arne Binder, David Harbecke, Stalin Varanasi, Leonhard Hennig, Simon Ostermann, Sebastian Möller, Josef van Genabith

In this work, we reimagine classical probing to evaluate knowledge transfer
from simple source to more complex target tasks. Instead of probing frozen
representations from a complex source task on diverse simple target probing
tasks (as usually done in probing), we explore the effectiveness of embeddings
from multiple simple source tasks on a single target task. We select
coreference resolution, a linguistically complex problem requiring contextual
understanding, as focus target task, and test the usefulness of embeddings from
comparably simpler tasks tasks such as paraphrase detection, named entity
recognition, and relation extraction. Through systematic experiments, we
evaluate the impact of individual and combined task embeddings.
  Our findings reveal that task embeddings vary significantly in utility for
coreference resolution, with semantic similarity tasks (e.g., paraphrase
detection) proving most beneficial. Additionally, representations from
intermediate layers of fine-tuned models often outperform those from final
layers. Combining embeddings from multiple tasks consistently improves
performance, with attention-based aggregation yielding substantial gains. These
insights shed light on relationships between task-specific representations and
their adaptability to complex downstream tasks, encouraging further exploration
of embedding-level task transfer.

摘要：在這項工作中，我們重新構想經典探查，以評估從簡單來源到更複雜目標任務的知識轉移。我們沒有在各種簡單目標探查任務中探查來自複雜來源任務的凍結表示（如探查中通常所做的那樣），而是探討來自多個簡單來源任務的嵌入在單一目標任務上的有效性。我們選擇了指稱消解，這是一個需要上下文理解的語言複雜問題，作為重點目標任務，並測試了來自相對簡單任務（例如語句改寫偵測、命名實體辨識和關係萃取）的嵌入的效用。透過系統性的實驗，我們評估了個別和組合任務嵌入的影響。我們的發現表明，任務嵌入在指稱消解的效用上差異很大，其中語義相似性任務（例如語句改寫偵測）被證明最有益。此外，微調模型的中間層表示通常優於最後一層的表示。結合來自多個任務的嵌入始終能改善效能，其中基於注意力的聚合產生了顯著的增益。這些見解闡明了特定任務表示與其對複雜下游任務的適應性之間的關係，鼓勵進一步探索嵌入層級任務轉移。

##### **An Efficient Approach for Machine Translation on Low-resource Languages: A Case Study in Vietnamese-Chinese**
2501.19314v1 by Tran Ngoc Son, Nguyen Anh Tu, Nguyen Minh Tri

Despite the rise of recent neural networks in machine translation, those
networks do not work well if the training data is insufficient. In this paper,
we proposed an approach for machine translation in low-resource languages such
as Vietnamese-Chinese. Our proposed method leveraged the power of the
multilingual pre-trained language model (mBART) and both Vietnamese and Chinese
monolingual corpus. Firstly, we built an early bird machine translation model
using the bilingual training dataset. Secondly, we used TF-IDF technique to
select sentences from the monolingual corpus which are the most related to
domains of the parallel dataset. Finally, the first model was used to
synthesize the augmented training data from the selected monolingual corpus for
the translation model. Our proposed scheme showed that it outperformed 8%
compared to the transformer model. The augmented dataset also pushed the model
performance.

摘要：儘管最近機器翻譯中的神經網路興起，如果訓練資料不足，這些網路就無法順利運作。在本文中，我們提出了一個用於低資源語言（例如越南語-中文）的機器翻譯方法。我們提出的方法利用了多語言預訓練語言模型 (mBART) 和越南語和中文單語語料庫的力量。首先，我們使用雙語訓練資料集建立了一個早期機器翻譯模型。其次，我們使用 TF-IDF 技術從單語語料庫中選擇與平行資料集領域最相關的句子。最後，第一個模型用於從所選的單語語料庫中合成擴充訓練資料，以供翻譯模型使用。我們提出的方案顯示，與Transformer模型相比，它的表現優異 8%。擴充資料集也提升了模型效能。

##### **Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment**
2501.19309v1 by Gregor Bachmann, Sotiris Anagnostidis, Albert Pumarola, Markos Georgopoulos, Artsiom Sanakoyeu, Yuming Du, Edgar Schönfeld, Ali Thabet, Jonas Kohler

The performance of large language models (LLMs) is closely linked to their
underlying size, leading to ever-growing networks and hence slower inference.
Speculative decoding has been proposed as a technique to accelerate
autoregressive generation, leveraging a fast draft model to propose candidate
tokens, which are then verified in parallel based on their likelihood under the
target model. While this approach guarantees to reproduce the target output, it
incurs a substantial penalty: many high-quality draft tokens are rejected, even
when they represent objectively valid continuations. Indeed, we show that even
powerful draft models such as GPT-4o, as well as human text cannot achieve high
acceptance rates under the standard verification scheme. This severely limits
the speedup potential of current speculative decoding methods, as an early
rejection becomes overwhelmingly likely when solely relying on alignment of
draft and target.
  We thus ask the following question: Can we adapt verification to recognize
correct, but non-aligned replies? To this end, we draw inspiration from the
LLM-as-a-judge framework, which demonstrated that LLMs are able to rate answers
in a versatile way. We carefully design a dataset to elicit the same capability
in the target model by training a compact module on top of the embeddings to
produce ``judgements" of the current continuation. We showcase our strategy on
the Llama-3.1 family, where our 8b/405B-Judge achieves a speedup of 9x over
Llama-405B, while maintaining its quality on a large range of benchmarks. These
benefits remain present even in optimized inference frameworks, where our
method reaches up to 141 tokens/s for 8B/70B-Judge and 129 tokens/s for 8B/405B
on 2 and 8 H100s respectively.

摘要：大型語言模型 (LLM) 的效能與其基礎大小密切相關，導致網路不斷擴大，進而降低推理速度。
推測性解碼已被提出作為一種加速自迴歸生成的技術，利用快速草稿模型來建議候選詞元，然後根據目標模型下的可能性並行驗證這些詞元。雖然這種方法保證重現目標輸出，但它會產生大量的懲罰：許多高品質的草稿詞元會被拒絕，即使它們代表客觀有效的延續。事實上，我們證明了即使是強大的草稿模型，例如 GPT-4o，以及人類文字，在標準驗證方案下也無法達到高接受率。這嚴重限制了當前推測性解碼方法的加速潛力，因為當僅依賴草稿和目標的一致性時，早期拒絕的可能性會變得極大。
因此，我們提出以下問題：我們能調整驗證以識別正確但未對齊的回覆嗎？為此，我們從 LLM 作為評判者框架中汲取靈感，該框架證明 LLM 能夠以多樣化的方式評分答案。我們仔細設計了一個數據集，以在目標模型中引發相同的性能，方法是在嵌入之上訓練一個精簡模組，以對當前延續產生「判斷」。我們在 Llama-3.1 系列中展示了我們的策略，其中我們的 8b/405B-Judge 在 Llama-405B 上實現了 9 倍的加速，同時在大量的基準測試中保持其品質。這些優點即使在最佳化的推理框架中仍然存在，其中我們的方法分別在 2 個和 8 個 H100 上，針對 8B/70B-Judge 達到了每秒 141 個詞元，針對 8B/405B 達到了每秒 129 個詞元。

##### **SETS: Leveraging Self-Verification and Self-Correction for Improved Test-Time Scaling**
2501.19306v2 by Jiefeng Chen, Jie Ren, Xinyun Chen, Chengrun Yang, Ruoxi Sun, Sercan Ö Arık

Recent advancements in Large Language Models (LLMs) have created new
opportunities to enhance performance on complex reasoning tasks by leveraging
test-time computation. However, conventional approaches such as repeated
sampling with majority voting or reward model scoring, often face diminishing
returns as test-time compute scales, in addition to requiring costly
task-specific reward model training. In this paper, we present Self-Enhanced
Test-Time Scaling (SETS), a novel method that leverages the self-verification
and self-correction capabilities of recent advanced LLMs to overcome these
limitations. SETS integrates sampling, self-verification, and self-correction
into a unified framework, enabling efficient and scalable test-time computation
for improved capabilities at complex tasks. Through extensive experiments on
challenging planning and reasoning benchmarks, compared to the alternatives, we
demonstrate that SETS achieves significant performance improvements and more
favorable test-time scaling laws.

摘要：大型語言模型 (LLM) 的近期進展創造了新的機會，可透過利用測試時間運算來增強複雜推理任務的效能。然而，傳統方法（例如重複抽樣搭配多數決或獎勵模型評分）通常會面臨報酬遞減，因為測試時間運算會擴展，而且需要代價高昂的特定任務獎勵模型訓練。在本文中，我們提出自我增強測試時間擴展 (SETS)，這是一種新方法，可利用近期進階 LLM 的自我驗證和自我修正功能來克服這些限制。SETS 將抽樣、自我驗證和自我修正整合到統一架構中，讓複雜任務的測試時間運算得以有效率且具擴充性，進而提升功能。透過在具挑戰性的規劃和推理基準上進行廣泛實驗，與其他方法相比，我們證明 SETS 可達成顯著的效能提升，並有更理想的測試時間擴展定律。

##### **Beyond checkmate: exploring the creative chokepoints in AI text**
2501.19301v1 by Nafis Irtiza Tripto, Saranya Venkatraman, Mahjabin Nahar, Dongwon Lee

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) and Artificial Intelligence (AI), unlocking unprecedented capabilities.
This rapid advancement has spurred research into various aspects of LLMs, their
text generation & reasoning capability, and potential misuse, fueling the
necessity for robust detection methods. While numerous prior research has
focused on detecting LLM-generated text (AI text) and thus checkmating them,
our study investigates a relatively unexplored territory: portraying the
nuanced distinctions between human and AI texts across text segments. Whether
LLMs struggle with or excel at incorporating linguistic ingenuity across
different text segments carries substantial implications for determining their
potential as effective creative assistants to humans. Through an analogy with
the structure of chess games-comprising opening, middle, and end games-we
analyze text segments (introduction, body, and conclusion) to determine where
the most significant distinctions between human and AI texts exist. While AI
texts can approximate the body segment better due to its increased length, a
closer examination reveals a pronounced disparity, highlighting the importance
of this segment in AI text detection. Additionally, human texts exhibit higher
cross-segment differences compared to AI texts. Overall, our research can shed
light on the intricacies of human-AI text distinctions, offering novel insights
for text detection and understanding.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理 (NLP) 和人工智慧 (AI)，釋放了前所未有的能力。
這項快速進展促使對 LLM 的各個方面進行研究，包括它們的文本生成和推理能力，以及潛在的誤用，進而推動了對健全偵測方法的需求。雖然許多先前的研究都專注於偵測 LLM 生成的文字 (AI 文字)，並因此將它們將死，但我們的研究探討了一個相對未開發的領域：描繪人類和 AI 文字在不同文字區段之間的細微差異。LLM 是否難以或擅長在不同的文字區段中融入語言創意，對於確定它們作為人類有效創意助理的潛力具有重大影響。透過類比於西洋棋比賽的結構，包括開局、中局和殘局，我們分析文字區段（引言、內文和結論），以確定人類和 AI 文字之間最顯著的差異存在於何處。雖然 AI 文字由於長度較長而能更接近內文區段，但更仔細的檢查揭示了明顯的差異，突顯了這個區段在 AI 文字偵測中的重要性。此外，與 AI 文字相比，人類文字展現出更高的跨區段差異。總體而言，我們的研究可以闡明人類和 AI 文字區分的複雜性，為文字偵測和理解提供新的見解。

##### **Synthetic User Behavior Sequence Generation with Large Language Models for Smart Homes**
2501.19298v1 by Zhiyao Xu, Dan Zhao, Qingsong Zou, Jingyu Xiao, Yong Jiang, Zhenhui Yuan, Qing Li

In recent years, as smart home systems have become more widespread, security
concerns within these environments have become a growing threat. Currently,
most smart home security solutions, such as anomaly detection and behavior
prediction models, are trained using fixed datasets that are precollected.
However, the process of dataset collection is time-consuming and lacks the
flexibility needed to adapt to the constantly evolving smart home environment.
Additionally, the collection of personal data raises significant privacy
concerns for users. Lately, large language models (LLMs) have emerged as a
powerful tool for a wide range of tasks across diverse application domains,
thanks to their strong capabilities in natural language processing, reasoning,
and problem-solving. In this paper, we propose an LLM-based synthetic dataset
generation IoTGen framework to enhance the generalization of downstream smart
home intelligent models. By generating new synthetic datasets that reflect
changes in the environment, smart home intelligent models can be retrained to
overcome the limitations of fixed and outdated data, allowing them to better
align with the dynamic nature of real-world home environments. Specifically, we
first propose a Structure Pattern Perception Compression (SPPC) method tailored
for IoT behavior data, which preserves the most informative content in the data
while significantly reducing token consumption. Then, we propose a systematic
approach to create prompts and implement data generation to automatically
generate IoT synthetic data with normative and reasonable properties, assisting
task models in adaptive training to improve generalization and real-world
performance.

摘要：<paragraph>近年來，隨著智慧家庭系統日益普及，這些環境中的安全問題已成為日益嚴重的威脅。目前，大多數智慧家庭安全解決方案（例如異常偵測和行為預測模型）都是使用預先收集的固定資料集進行訓練。然而，資料集收集的過程耗時，且缺乏適應不斷變化的智慧家庭環境所需的靈活性。此外，個人資料的收集也對使用者造成重大的隱私問題。最近，大型語言模型 (LLM) 已成為各種應用領域中廣泛任務的強大工具，這要歸功於它們在自然語言處理、推理和問題解決方面的強大功能。在本文中，我們提出了一個基於 LLM 的合成資料集生成 IoTGen 架構，以增強下游智慧家庭智慧模型的泛化。透過產生反映環境變化的新合成資料集，可以重新訓練智慧家庭智慧模型，以克服固定和過時資料的限制，讓它們能更好地與真實世界家庭環境的動態性質保持一致。具體來說，我們首先提出針對 IoT 行為資料量身打造的結構模式感知壓縮 (SPPC) 方法，它保留了資料中最具資訊性的內容，同時大幅減少符號消耗。然後，我們提出了一種系統化方法來建立提示並實作資料生成，以自動產生具有規範性和合理性的 IoT 合成資料，協助任務模型進行適應性訓練，以改善泛化和真實世界效能。</paragraph>

##### **Analysis of LLMs vs Human Experts in Requirements Engineering**
2501.19297v1 by Cory Hymel, Hiroe Johnson

The majority of research around Large Language Models (LLM) application to
software development has been on the subject of code generation. There is
little literature on LLMs' impact on requirements engineering (RE), which deals
with the process of developing and verifying the system requirements. Within
RE, there is a subdiscipline of requirements elicitation, which is the practice
of discovering and documenting requirements for a system from users, customers,
and other stakeholders. In this analysis, we compare LLM's ability to elicit
requirements of a software system, as compared to that of a human expert in a
time-boxed and prompt-boxed study. We found LLM-generated requirements were
evaluated as more aligned (+1.12) than human-generated requirements with a
trend of being more complete (+10.2%). Conversely, we found users tended to
believe that solutions they perceived as more aligned had been generated by
human experts. Furthermore, while LLM-generated documents scored higher and
performed at 720x the speed, their cost was, on average, only 0.06% that of a
human expert. Overall, these findings indicate that LLMs will play an
increasingly important role in requirements engineering by improving
requirements definitions, enabling more efficient resource allocation, and
reducing overall project timelines.

摘要：大型語言模型 (LLM) 應用於軟體開發的研究大部分都集中在程式碼生成的主題上。關於 LLM 對需求工程 (RE) 的影響，也就是處理開發和驗證系統需求的流程，則鮮少有文獻探討。在 RE 中，有一個需求引導的子領域，其做法是從使用者、客戶和其他利害關係人找出並記錄系統的需求。在這個分析中，我們比較了 LLM 引導軟體系統需求的能力，以及在時間限制和提示限制的研究中，人類專家的能力。我們發現 LLM 生成的需求被評為比人類生成的更一致 (+1.12)，且有趨勢顯示更完整 (+10.2%)。相反地，我們發現使用者傾向於相信他們認為比較一致的解決方案是由人類專家產生的。此外，雖然 LLM 生成的文件得分較高，且執行速度快 720 倍，但其成本平均來說僅為人類專家的 0.06%。整體而言，這些發現顯示 LLM 將在需求工程中扮演越來越重要的角色，方法是改善需求定義、讓資源配置更有效率，以及縮短整體專案時程。

##### **Pheromone-based Learning of Optimal Reasoning Paths**
2501.19278v1 by Anirudh Chari, Aditya Tiwari, Richard Lian, Suraj Reddy, Brian Zhou

Large Language Models (LLMs) have demonstrated remarkable reasoning
capabilities through chain-of-thought prompting, yet discovering effective
reasoning methods for complex problems remains challenging due to the vast
space of possible intermediate steps. We introduce Ant Colony
Optimization-guided Tree of Thought (ACO-ToT), a novel algorithm that combines
ACO with LLMs to discover optimal reasoning paths for complex problems
efficiently. Drawing inspiration from Hebbian learning in neurological systems,
our method employs a collection of distinctly fine-tuned LLM "ants" to traverse
and lay pheromone trails through a centralized tree of thought, with each ant's
movement governed by a weighted combination of existing pheromone trails and
its own specialized expertise. The algorithm evaluates complete reasoning paths
using a mixture-of-experts-based scoring function, with pheromones reinforcing
productive reasoning paths across iterations. Experiments on three challenging
reasoning tasks (GSM8K, ARC-Challenge, and MATH) demonstrate that ACO-ToT
performs significantly better than existing chain-of-thought optimization
approaches, suggesting that incorporating biologically inspired collective
search mechanisms into LLM inference can substantially enhance reasoning
capabilities.

摘要：大型語言模型 (LLM) 已透過思考鏈提示展現出非凡的推理能力，但由於可能的步驟空間龐大，因此找出複雜問題的有效推理方法仍然具有挑戰性。我們引入了螞蟻群最佳化引導的思考樹 (ACO-ToT)，這是一種新穎的演算法，它將 ACO 與 LLM 結合，以有效找出複雜問題的最佳推理路徑。我們的演算法從神經系統中的赫布學習中汲取靈感，採用一組經過微調的 LLM「螞蟻」來穿越並在集中式思考樹中留下費洛蒙軌跡，每個螞蟻的移動都受到既有費洛蒙軌跡和其自身專業知識的加權組合所控制。該演算法使用基於專家混合的評分函數來評估完整的推理路徑，費洛蒙會在反覆運算中強化有成效的推理路徑。在三項具有挑戰性的推理任務（GSM8K、ARC-Challenge 和 MATH）上的實驗證明，ACO-ToT 的表現明顯優於現有的思考鏈最佳化方法，這表明將受生物啟發的集體搜尋機制納入 LLM 推論可以大幅提升推理能力。

##### **Concept-Based Explainable Artificial Intelligence: Metrics and Benchmarks**
2501.19271v1 by Halil Ibrahim Aysel, Xiaohao Cai, Adam Prugel-Bennett

Concept-based explanation methods, such as concept bottleneck models (CBMs),
aim to improve the interpretability of machine learning models by linking their
decisions to human-understandable concepts, under the critical assumption that
such concepts can be accurately attributed to the network's feature space.
However, this foundational assumption has not been rigorously validated, mainly
because the field lacks standardised metrics and benchmarks to assess the
existence and spatial alignment of such concepts. To address this, we propose
three metrics: the concept global importance metric, the concept existence
metric, and the concept location metric, including a technique for visualising
concept activations, i.e., concept activation mapping. We benchmark post-hoc
CBMs to illustrate their capabilities and challenges. Through qualitative and
quantitative experiments, we demonstrate that, in many cases, even the most
important concepts determined by post-hoc CBMs are not present in input images;
moreover, when they are present, their saliency maps fail to align with the
expected regions by either activating across an entire object or misidentifying
relevant concept-specific regions. We analyse the root causes of these
limitations, such as the natural correlation of concepts. Our findings
underscore the need for more careful application of concept-based explanation
techniques especially in settings where spatial interpretability is critical.

摘要：基於概念的解釋方法，例如概念瓶頸模型 (CBM)，旨在透過將機器學習模型的決策與人類可理解的概念連結，來提升機器學習模型的可解釋性，其關鍵假設為此類概念可以準確地歸因於網路的特徵空間。然而，此項基礎假設尚未經過嚴格驗證，主要是因為該領域缺乏標準化指標和基準來評估此類概念的存在和空間對齊。為了解決這個問題，我們提出三項指標：概念整體重要性指標、概念存在指標和概念位置指標，包括一種用於視覺化概念活化，即概念活化對應的技術。我們對事後 CBM 進行基準測試，以說明它們的能力和挑戰。透過定性和定量實驗，我們證明，在許多情況下，即使是由事後 CBM 確定的最重要概念也不存在於輸入影像中；此外，當它們存在時，它們的顯著性圖無法與預期的區域對齊，原因可能是它們在整個物件中活化，或錯誤辨識出相關的概念特定區域。我們分析了這些限制的根本原因，例如概念的自然相關性。我們的研究結果強調需要更小心地應用基於概念的解釋技術，特別是在空間可解釋性至關重要的設定中。

##### **Jackpot! Alignment as a Maximal Lottery**
2501.19266v1 by Roberto-Rafael Maura-Rivero, Marc Lanctot, Francesco Visin, Kate Larson

Reinforcement Learning from Human Feedback (RLHF), the standard for aligning
Large Language Models (LLMs) with human values, is known to fail to satisfy
properties that are intuitively desirable, such as respecting the preferences
of the majority \cite{ge2024axioms}. To overcome these issues, we propose the
use of a probabilistic Social Choice rule called \emph{maximal lotteries} as a
replacement for RLHF. We show that a family of alignment techniques, namely
Nash Learning from Human Feedback (NLHF) \cite{munos2023nash} and variants,
approximate maximal lottery outcomes and thus inherit its beneficial
properties.
  We confirm experimentally that our proposed methodology handles situations
that arise when working with preferences more robustly than standard RLHF,
including supporting the preferences of the majority, providing principled ways
of handling non-transitivities in the preference data, and robustness to
irrelevant alternatives. This results in systems that better incorporate human
values and respect human intentions.

摘要：人類回饋強化學習 (RLHF) 是調整大型語言模型 (LLM) 與人類價值觀的標準，已知無法滿足直觀上理想的屬性，例如尊重大多數人的偏好 \cite{ge2024axioms}。為了克服這些問題，我們建議使用稱為「最大樂透」的機率性社會選擇規則，作為 RLHF 的替代方案。我們證明了一系列調整技術，即人類回饋納許學習 (NLHF) \cite{munos2023nash} 及其變體，近似於最大樂透結果，因此繼承了其有益屬性。
我們透過實驗確認，我們提出的方法比標準 RLHF 更穩健地處理使用偏好時出現的情況，包括支持大多數人的偏好、提供處理偏好資料中非遞移性的原則性方法，以及對無關選項的穩健性。這會產生更好的納入人類價值觀並尊重人類意圖的系統。

##### **mFollowIR: a Multilingual Benchmark for Instruction Following in Retrieval**
2501.19264v1 by Orion Weller, Benjamin Chang, Eugene Yang, Mahsa Yarmohammadi, Sam Barham, Sean MacAvaney, Arman Cohan, Luca Soldaini, Benjamin Van Durme, Dawn Lawrie

Retrieval systems generally focus on web-style queries that are short and
underspecified. However, advances in language models have facilitated the
nascent rise of retrieval models that can understand more complex queries with
diverse intents. However, these efforts have focused exclusively on English;
therefore, we do not yet understand how they work across languages. We
introduce mFollowIR, a multilingual benchmark for measuring
instruction-following ability in retrieval models. mFollowIR builds upon the
TREC NeuCLIR narratives (or instructions) that span three diverse languages
(Russian, Chinese, Persian) giving both query and instruction to the retrieval
models. We make small changes to the narratives and isolate how well retrieval
models can follow these nuanced changes. We present results for both
multilingual (XX-XX) and cross-lingual (En-XX) performance. We see strong
cross-lingual performance with English-based retrievers that trained using
instructions, but find a notable drop in performance in the multilingual
setting, indicating that more work is needed in developing data for
instruction-based multilingual retrievers.

摘要：檢索系統通常專注於簡短且未指定之網路式查詢。然而，語言模型的進展促成了檢索模型的初步興起，這些模型能夠理解具有不同意圖的更複雜查詢。然而，這些努力專注於英文；因此，我們尚未了解它們如何跨語言運作。我們引入了 mFollowIR，這是一個多語言基準，用於衡量檢索模型中遵循指令的能力。mFollowIR 建立在 TREC NeuCLIR 敘事（或指令）之上，這些敘事跨越三種不同的語言（俄語、中文、波斯語），為檢索模型提供查詢和指令。我們對敘事進行了微小的更改，並隔離檢索模型遵循這些細微更改的程度。我們針對多語言 (XX-XX) 和跨語言 (En-XX) 效能呈現結果。我們看到使用指令訓練的基於英文的檢索器具有強大的跨語言效能，但在多語言環境中發現效能顯著下降，這表明需要在開發用於基於指令的多語言檢索器的資料方面投入更多工作。

##### **VisualSpeech: Enhance Prosody with Visual Context in TTS**
2501.19258v1 by Shumin Que, Anton Ragni

Text-to-Speech (TTS) synthesis faces the inherent challenge of producing
multiple speech outputs with varying prosody from a single text input. While
previous research has addressed this by predicting prosodic information from
both text and speech, additional contextual information, such as visual
features, remains underutilized. This paper investigates the potential of
integrating visual context to enhance prosody prediction. We propose a novel
model, VisualSpeech, which incorporates both visual and textual information for
improved prosody generation. Empirical results demonstrate that visual features
provide valuable prosodic cues beyond the textual input, significantly
enhancing the naturalness and accuracy of the synthesized speech. Audio samples
are available at https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/.

摘要：文字轉語音（TTS）合成面臨著一個固有挑戰，即從單一文字輸入產生具有不同語調的多個語音輸出。雖然先前的研究已透過從文字和語音預測語調資訊來解決這個問題，但額外的脈絡資訊（例如視覺特徵）仍未得到充分利用。本文探討了整合視覺脈絡以增強語調預測的潛力。我們提出了一個創新的模型 VisualSpeech，它結合了視覺和文字資訊，以改善語調產生。實證結果表明，視覺特徵提供了超越文字輸入的寶貴語調線索，顯著提高了合成語音的自然性和準確性。音訊範例可在 https://ariameetgit.github.io/VISUALSPEECH-SAMPLES/ 取得。

##### **SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments**
2501.19245v2 by Hüseyin Aydın, Kevin Godin-Dubois, Libio Goncalvez Braz, Floris den Hengst, Kim Baraka, Mustafa Mert Çelikok, Andreas Sauter, Shihan Wang, Frans A. Oliehoek

Reinforcement learning (RL) offers a general approach for modeling and
training AI agents, including human-AI interaction scenarios. In this paper, we
propose SHARPIE (Shared Human-AI Reinforcement Learning Platform for
Interactive Experiments) to address the need for a generic framework to support
experiments with RL agents and humans. Its modular design consists of a
versatile wrapper for RL environments and algorithm libraries, a
participant-facing web interface, logging utilities, deployment on popular
cloud and participant recruitment platforms. It empowers researchers to study a
wide variety of research questions related to the interaction between humans
and RL agents, including those related to interactive reward specification and
learning, learning from human feedback, action delegation, preference
elicitation, user-modeling, and human-AI teaming. The platform is based on a
generic interface for human-RL interactions that aims to standardize the field
of study on RL in human contexts.

摘要：強化學習 (RL) 提供一種通用方法，用於建模和訓練 AI 代理，包括人機互動場景。在本文中，我們提出 SHARPIE（共享人機強化學習平台，用於互動式實驗），以滿足支援 RL 代理和人類實驗的通用框架需求。其模組化設計包含一個通用包裝器，用於 RL 環境和演算法函式庫、一個與參與者互動的網路介面、記錄公用程式、部署在熱門雲端和參與者招募平台上。它讓研究人員能夠研究各種與人類和 RL 代理互動相關的研究問題，包括與互動式獎勵規格和學習、從人類回饋中學習、動作委派、偏好引導、使用者建模和人機團隊合作相關的問題。該平台基於人機 RL 互動的通用介面，旨在標準化人類環境中 RL 的研究領域。

##### **A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation**
2501.19232v1 by Yunzhe Li, Junting Wang, Hari Sundaram, Zhining Liu

Zero-shot cross-domain sequential recommendation (ZCDSR) enables predictions
in unseen domains without the need for additional training or fine-tuning,
making it particularly valuable in data-sparse environments where traditional
models struggle. Recent advancements in large language models (LLMs) have
greatly improved ZCDSR by leveraging rich pretrained representations to
facilitate cross-domain knowledge transfer. However, a key challenge persists:
domain semantic bias, which arises from variations in vocabulary and content
focus across domains. This misalignment leads to inconsistencies in item
embeddings and hinders generalization.
  To address this issue, we propose a novel framework designed to enhance
LLM-based ZCDSR by improving cross-domain alignment at both the item and
sequential levels. At the item level, we introduce a generalization loss that
promotes inter-domain compactness by aligning embeddings of similar items
across domains while maintaining intra-domain diversity to preserve unique item
characteristics. This prevents embeddings from becoming overly generic while
ensuring effective transferability. At the sequential level, we develop a
method for transferring user behavioral patterns by clustering user sequences
in the source domain and applying attention-based aggregation for target domain
inference. This dynamic adaptation of user embeddings allows effective
zero-shot recommendations without requiring target-domain interactions.
  Comprehensive experiments across multiple datasets and domains demonstrate
that our framework significantly improves sequential recommendation performance
in the ZCDSR setting. By mitigating domain bias and enhancing the
transferability of sequential patterns, our method provides a scalable and
robust approach for achieving more effective zero-shot recommendations across
domains.

摘要：<paragraph>零次學習跨網域序貫推薦 (ZCDSR) 可在無需額外訓練或微調的情況下對不可見網域進行預測，這使其在傳統模型難以應付的資料稀疏環境中特別有價值。大型語言模型 (LLM) 的最新進展已大幅改善 ZCDSR，方法是利用豐富的預訓練表示來促進跨網域知識轉移。然而，一個關鍵挑戰仍然存在：網域語義偏差，這源於網域間詞彙和內容焦點的變化。這種錯位導致項目嵌入的不一致，並阻礙概括。
  為了解決這個問題，我們提出了一個新穎的框架，旨在透過改善項目和序貫層級的跨網域對齊來增強基於 LLM 的 ZCDSR。在項目層級，我們引入一個概括損失，透過在網域間對齊相似項目的嵌入來促進網域間的緊密性，同時維持網域內的差異性以保留獨特的項目特徵。這可防止嵌入變得過於通用，同時確保有效的可轉移性。在序貫層級，我們開發了一種方法來轉移使用者行為模式，方法是在來源網域中對使用者序列進行分群，並對目標網域推論應用基於注意力的聚合。這種使用者嵌入的動態適應允許有效的零次學習推薦，而不需要目標網域互動。
  跨多個資料集和網域的全面實驗證明，我們的框架顯著改善了 ZCDSR 設定中的序貫推薦效能。透過減輕網域偏差並增強序貫模式的可轉移性，我們的模型提供了一個可擴充且穩健的方法，用於在網域間實現更有效的零次學習推薦。</paragraph>

##### **Integrating Semi-Supervised and Active Learning for Semantic Segmentation**
2501.19227v1 by Wanli Ma, Oktay Karakus, Paul L. Rosin

In this paper, we propose a novel active learning approach integrated with an
improved semi-supervised learning framework to reduce the cost of manual
annotation and enhance model performance. Our proposed approach effectively
leverages both the labelled data selected through active learning and the
unlabelled data excluded from the selection process. The proposed active
learning approach pinpoints areas where the pseudo-labels are likely to be
inaccurate. Then, an automatic and efficient pseudo-label auto-refinement
(PLAR) module is proposed to correct pixels with potentially erroneous
pseudo-labels by comparing their feature representations with those of labelled
regions. This approach operates without increasing the labelling budget and is
based on the cluster assumption, which states that pixels belonging to the same
class should exhibit similar representations in feature space. Furthermore,
manual labelling is only applied to the most difficult and uncertain areas in
unlabelled data, where insufficient information prevents the PLAR module from
making a decision. We evaluated the proposed hybrid semi-supervised active
learning framework on two benchmark datasets, one from natural and the other
from remote sensing imagery domains. In both cases, it outperformed
state-of-the-art methods in the semantic segmentation task.

摘要：在本文中，我们提出了一种新穎主動學習方法，並與一個改良的半監督學習框架整合，以降低人工標註的成本並提升模型效能。我們提出的方法有效地利用了主動學習中選取的標籤資料，以及從選擇過程中排除的未標籤資料。所提出的主動學習方法精確指出偽標籤可能不準確的地方。然後，提出一個自動且有效率的偽標籤自動精煉 (PLAR) 模組，透過將其特徵表示與標籤區域的特徵表示進行比較來修正具有潛在錯誤偽標籤的像素。此方法在不增加標籤預算的情況下運作，並基於叢集假設，該假設指出屬於同一類別的像素應在特徵空間中呈現類似的表示。此外，人工標籤僅用於未標籤資料中最困難且最不確定的區域，在這些區域中，資訊不足以讓 PLAR 模組做出決定。我們在兩個基準資料集上評估了所提出的混合半監督主動學習框架，一個來自自然，另一個來自遙感影像領域。在兩種情況下，它在語意分割任務中都優於最先進的方法。

##### **Improving the Robustness of Representation Misdirection for Large Language Model Unlearning**
2501.19202v2 by Dang Huu-Tien, Hoang Thanh-Tung, Le-Minh Nguyen, Naoya Inoue

Representation Misdirection (RM) and variants are established large language
model (LLM) unlearning methods with state-of-the-art performance. In this
paper, we show that RM methods inherently reduce models' robustness, causing
them to misbehave even when a single non-adversarial forget-token is in the
retain-query. Toward understanding underlying causes, we reframe the unlearning
process as backdoor attacks and defenses: forget-tokens act as backdoor
triggers that, when activated in retain-queries, cause disruptions in RM
models' behaviors, similar to successful backdoor attacks. To mitigate this
vulnerability, we propose Random Noise Augmentation -- a model and method
agnostic approach with theoretical guarantees for improving the robustness of
RM methods. Extensive experiments demonstrate that RNA significantly improves
the robustness of RM models while enhancing the unlearning performances.

摘要：表徵誤導 (RM) 及其變體是已建立的大型語言模型 (LLM) 忘記方法，具有最先進的效能。在本文中，我們展示 RM 方法本質上會降低模型的穩健性，導致它們在保留查詢中即使只有一個非對抗性的遺忘代碼也會出現異常行為。為了理解背後的原因，我們將忘記過程重新定義為後門攻擊和防禦：遺忘代碼充當後門觸發器，當在保留查詢中被啟動時，會造成 RM 模型行為的中斷，類似於成功的後門攻擊。為了減輕此漏洞，我們提出隨機雜訊擴充——一種模型和方法不可知的方法，具有提高 RM 方法穩健性的理論保證。廣泛的實驗表明，RNA 在增強忘記效能的同時，顯著提高了 RM 模型的穩健性。

##### **Efficient Reasoning with Hidden Thinking**
2501.19201v1 by Xuan Shen, Yizhou Wang, Xiangxi Shi, Yanzhi Wang, Pu Zhao, Jiuxiang Gu

Chain-of-Thought (CoT) reasoning has become a powerful framework for
improving complex problem-solving capabilities in Multimodal Large Language
Models (MLLMs). However, the verbose nature of textual reasoning introduces
significant inefficiencies. In this work, we propose $\textbf{Heima}$ (as
hidden llama), an efficient reasoning framework that leverages reasoning CoTs
at hidden latent space. We design the Heima Encoder to condense each
intermediate CoT into a compact, higher-level hidden representation using a
single thinking token, effectively minimizing verbosity and reducing the
overall number of tokens required during the reasoning process. Meanwhile, we
design corresponding Heima Decoder with traditional Large Language Models
(LLMs) to adaptively interpret the hidden representations into variable-length
textual sequence, reconstructing reasoning processes that closely resemble the
original CoTs. Experimental results across diverse reasoning MLLM benchmarks
demonstrate that Heima model achieves higher generation efficiency while
maintaining or even better zero-shot task accuracy. Moreover, the effective
reconstruction of multimodal reasoning processes with Heima Decoder validates
both the robustness and interpretability of our approach.

摘要：鏈式思考 (CoT) 推理已成為一種強大的框架，用於改善多模態大型語言模型 (MLLM) 中的複雜問題解決能力。然而，文本推理的冗長性質會造成顯著的低效率。在這項工作中，我們提出了 $\textbf{Heima}$（作為隱藏的羊駝），這是一個高效的推理框架，它利用隱藏潛在空間中的推理 CoT。我們設計了 Heima 編碼器，使用單一的思考標記將每個中間 CoT 壓縮成一個緊湊、更高級別的隱藏表示，有效地最小化冗長並減少推理過程中所需的總標記數。同時，我們設計了對應的 Heima 解碼器與傳統的大型語言模型 (LLM) 一起，自適應地將隱藏表示解釋為可變長度的文本序列，重建與原始 CoT 非常相似的推理過程。跨不同推理 MLLM 基準的實驗結果表明，Heima 模型在保持或甚至提高零次任務準確性的同時，實現了更高的生成效率。此外，使用 Heima 解碼器有效重建多模態推理過程驗證了我們方法的魯棒性和可解釋性。

##### **Secured Communication Schemes for UAVs in 5G: CRYSTALS-Kyber and IDS**
2501.19191v1 by Taneya Sharma, Seyed Ahmad Soleymani, Mohammad Shojafar, Rahim Tafazolli

This paper introduces a secure communication architecture for Unmanned Aerial
Vehicles (UAVs) and ground stations in 5G networks, addressing critical
challenges in network security. The proposed solution integrates the Advanced
Encryption Standard (AES) with Elliptic Curve Cryptography (ECC) and
CRYSTALS-Kyber for key encapsulation, offering a hybrid cryptographic approach.
By incorporating CRYSTALS-Kyber, the framework mitigates vulnerabilities in ECC
against quantum attacks, positioning it as a quantum-resistant alternative. The
architecture is based on a server-client model, with UAVs functioning as
clients and the ground station acting as the server. The system was rigorously
evaluated in both VPN and 5G environments. Experimental results confirm that
CRYSTALS-Kyber delivers strong protection against quantum threats with minimal
performance overhead, making it highly suitable for UAVs with resource
constraints. Moreover, the proposed architecture integrates an Artificial
Intelligence (AI)-based Intrusion Detection System (IDS) to further enhance
security. In performance evaluations, the IDS demonstrated strong results
across multiple models with XGBoost, particularly in more demanding scenarios,
outperforming other models with an accuracy of 97.33% and an AUC of 0.94. These
findings underscore the potential of combining quantum-resistant encryption
mechanisms with AI-driven IDS to create a robust, scalable, and secure
communication framework for UAV networks, particularly within the
high-performance requirements of 5G environments.

摘要：本文介紹了一個適用於 5G 網路中的無人機 (UAV) 和地面站的安全性通訊架構，用於解決網路安全中的重大挑戰。建議的解決方案將進階加密標準 (AES) 與橢圓曲線密碼學 (ECC) 和 CRYSTALS-Kyber 整合，用於金鑰封裝，提供混合式密碼學方法。透過整合 CRYSTALS-Kyber，架構可減輕 ECC 在量子攻擊中的漏洞，將其定位為抗量子替代方案。此架構基於伺服器-用戶端模型，其中無人機運作為用戶端，而地面站則作為伺服器。此系統在 VPN 和 5G 環境中都經過嚴格評估。實驗結果證實，CRYSTALS-Kyber 能在效能負擔最小的情況下提供強大的量子威脅防護，使其非常適合具有資源限制的無人機。此外，建議的架構整合了一個基於人工智慧 (AI) 的入侵偵測系統 (IDS)，以進一步增強安全性。在效能評估中，IDS 在多個模型中展現強勁的結果，尤其是在更嚴苛的場景中，以 97.33% 的準確率和 0.94 的 AUC 優於其他模型。這些發現強調了將抗量子加密機制與 AI 驅動的 IDS 結合起來的潛力，以建立一個強固、可擴充且安全的無人機網路通訊架構，特別是在 5G 環境的高效能需求中。

##### **Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning**
2501.19180v1 by Xianglin Yang, Gelei Deng, Jieming Shi, Tianwei Zhang, Jin Song Dong

Large language models (LLMs) are vital for a wide range of applications yet
remain susceptible to jailbreak threats, which could lead to the generation of
inappropriate responses. Conventional defenses, such as refusal and adversarial
training, often fail to cover corner cases or rare domains, leaving LLMs still
vulnerable to more sophisticated attacks. We propose a novel defense strategy,
Safety Chain-of-Thought (SCoT), which harnesses the enhanced \textit{reasoning
capabilities} of LLMs for proactive assessment of harmful inputs, rather than
simply blocking them. SCoT augments any refusal training datasets to critically
analyze the intent behind each request before generating answers. By employing
proactive reasoning, SCoT enhances the generalization of LLMs across varied
harmful queries and scenarios not covered in the safety alignment corpus.
Additionally, it generates detailed refusals specifying the rules violated.
Comparative evaluations show that SCoT significantly surpasses existing
defenses, reducing vulnerability to out-of-distribution issues and adversarial
manipulations while maintaining strong general capabilities.

摘要：大型語言模型 (LLM) 對廣泛的應用至關重要，但仍容易受到越獄威脅，這可能會導致產生不適當的回應。傳統防禦措施，例如拒絕和對抗訓練，通常無法涵蓋邊緣案例或罕見領域，這使得 LLM 仍然容易受到更複雜的攻擊。我們提出了一種新穎的防禦策略，即安全思考鏈 (SCoT)，它利用 LLM 增強的推理能力來主動評估有害輸入，而不是簡單地阻止它們。SCoT 擴充任何拒絕訓練資料集，以便在產生答案之前批判性地分析每個請求背後的意圖。通過採用主動推理，SCoT 增強了 LLM 對安全對齊語料庫中未涵蓋的各種有害查詢和場景的概括。此外，它還會產生詳細的拒絕，說明所違反的規則。比較評估表明，SCoT 明顯優於現有防禦措施，降低了對分佈外問題和對抗操作的脆弱性，同時保持了強大的通用能力。

##### **Improving Multi-Label Contrastive Learning by Leveraging Label Distribution**
2501.19145v1 by Ning Chen, Shen-Huan Lyu, Tian-Shuang Wu, Yanyan Wang, Bin Tang

In multi-label learning, leveraging contrastive learning to learn better
representations faces a key challenge: selecting positive and negative samples
and effectively utilizing label information. Previous studies selected positive
and negative samples based on the overlap between labels and used them for
label-wise loss balancing. However, these methods suffer from a complex
selection process and fail to account for the varying importance of different
labels. To address these problems, we propose a novel method that improves
multi-label contrastive learning through label distribution. Specifically, when
selecting positive and negative samples, we only need to consider whether there
is an intersection between labels. To model the relationships between labels,
we introduce two methods to recover label distributions from logical labels,
based on Radial Basis Function (RBF) and contrastive loss, respectively. We
evaluate our method on nine widely used multi-label datasets, including image
and vector datasets. The results demonstrate that our method outperforms
state-of-the-art methods in six evaluation metrics.

摘要：在多標籤學習中，利用對比學習來學習更好的表示會面臨一個關鍵挑戰：選擇正負樣本並有效利用標籤資訊。先前的研究根據標籤之間的重疊來選擇正負樣本，並將它們用於標籤明智的損失平衡。然而，這些方法會產生複雜的選擇過程，而且無法考量不同標籤的重要性差異。為了解決這些問題，我們提出了一種新方法，透過標籤分佈來改善多標籤對比學習。具體來說，在選擇正負樣本時，我們只需要考慮標籤之間是否有交集。為了建立標籤之間的關係，我們引入了兩種方法，分別根據徑向基函數 (RBF) 和對比損失從邏輯標籤中恢復標籤分佈。我們在九個廣泛使用的多標籤資料集上評估了我們的方法，包括影像和向量資料集。結果表明，我們的模型在六個評估指標上優於最先進的方法。

##### **Imitation Game for Adversarial Disillusion with Multimodal Generative Chain-of-Thought Role-Play**
2501.19143v1 by Ching-Chun Chang, Fan-Yun Chen, Shih-Hong Gu, Kai Gao, Hanrui Wang, Isao Echizen

As the cornerstone of artificial intelligence, machine perception confronts a
fundamental threat posed by adversarial illusions. These adversarial attacks
manifest in two primary forms: deductive illusion, where specific stimuli are
crafted based on the victim model's general decision logic, and inductive
illusion, where the victim model's general decision logic is shaped by specific
stimuli. The former exploits the model's decision boundaries to create a
stimulus that, when applied, interferes with its decision-making process. The
latter reinforces a conditioned reflex in the model, embedding a backdoor
during its learning phase that, when triggered by a stimulus, causes aberrant
behaviours. The multifaceted nature of adversarial illusions calls for a
unified defence framework, addressing vulnerabilities across various forms of
attack. In this study, we propose a disillusion paradigm based on the concept
of an imitation game. At the heart of the imitation game lies a multimodal
generative agent, steered by chain-of-thought reasoning, which observes,
internalises and reconstructs the semantic essence of a sample, liberated from
the classic pursuit of reversing the sample to its original state. As a proof
of concept, we conduct experimental simulations using a multimodal generative
dialogue agent and evaluates the methodology under a variety of attack
scenarios.

摘要：作為人工智慧的基石，機器感知面臨對抗性幻覺所帶來的根本威脅。這些對抗性攻擊主要表現為兩種形式：演繹幻覺，其中特定刺激是根據受害者模型的通用決策邏輯而設計的，以及歸納幻覺，其中受害者模型的通用決策邏輯是由特定刺激形成的。前者利用模型的決策邊界來創建一個刺激，當應用時會干擾其決策過程。後者在模型中強化條件反射，在其學習階段嵌入一個後門，當被刺激觸發時，會導致異常行為。對抗性幻覺的多方面性質需要一個統一的防禦框架，以解決各種形式的攻擊中的漏洞。在本研究中，我們提出了一個基於模仿遊戲概念的幻滅範例。模仿遊戲的核心是一個多模態生成代理，由思想鏈推理引導，它觀察、內化和重建樣本的語義本質，擺脫了將樣本恢復到其原始狀態的經典追求。作為概念驗證，我們使用多模態生成對話代理進行實驗模擬，並在各種攻擊場景下評估該方法。

##### **A Metric for the Balance of Information in Graph Learning**
2501.19137v1 by Alex O. Davies, Nirav S. Ajmeri, Telmo de Menezes e Silva Filho

Graph learning on molecules makes use of information from both the molecular
structure and the features attached to that structure. Much work has been
conducted on biasing either towards structure or features, with the aim that
bias bolsters performance. Identifying which information source a dataset
favours, and therefore how to approach learning that dataset, is an open issue.
Here we propose Noise-Noise Ratio Difference (NNRD), a quantitative metric for
whether there is more useful information in structure or features. By employing
iterative noising on features and structure independently, leaving the other
intact, NNRD measures the degradation of information in each. We employ NNRD
over a range of molecular tasks, and show that it corresponds well to a loss of
information, with intuitive results that are more expressive than simple
performance aggregates. Our future work will focus on expanding data domains,
tasks and types, as well as refining our choice of baseline model.

摘要：分子上的圖形學習利用分子結構和附加到該結構上的特徵中的資訊。許多工作已針對結構或特徵進行偏向，目的是偏向能增強效能。識別資料集偏好的資訊來源，因此如何著手學習該資料集，是一個開放性的問題。在此，我們提出雜訊雜訊比差異 (NNRD)，一個量化指標，用於判斷結構或特徵中是否有更多有用的資訊。透過獨立地對特徵和結構進行反覆雜訊處理，讓另一個保持完整，NNRD 測量每個資訊的劣化程度。我們在各種分子任務上採用 NNRD，並顯示它與資訊損失非常吻合，其直觀的結果比簡單的效能彙總更具表達力。我們的未來工作將專注於擴充資料領域、任務和類型，以及精進我們對基線模型的選擇。

##### **Mixed Feelings: Cross-Domain Sentiment Classification of Patient Feedback**
2501.19134v1 by Egil Rønningstad, Lilja Charlotte Storset, Petter Mæhlum, Lilja Øvrelid, Erik Velldal

Sentiment analysis of patient feedback from the public health domain can aid
decision makers in evaluating the provided services. The current paper focuses
on free-text comments in patient surveys about general practitioners and
psychiatric healthcare, annotated with four sentence-level polarity classes --
positive, negative, mixed and neutral -- while also attempting to alleviate
data scarcity by leveraging general-domain sources in the form of reviews. For
several different architectures, we compare in-domain and out-of-domain
effects, as well as the effects of training joint multi-domain models.

摘要：從公共衛生領域收集的患者回饋意見的情緒分析，可以協助決策者評估所提供的服務。本篇論文重點關注患者針對一般科醫師和精神科醫療保健所進行的調查中的自由文字評論，並註記了四種句子層級的極性分類 -- 正面、負面、混合和中立 -- 同時也試圖透過利用評論形式的通用領域來源來緩解資料的稀少性。對於幾個不同的架構，我們比較了領域內和領域外的影響，以及訓練聯合多領域模型的影響。

##### **FedRTS: Federated Robust Pruning via Combinatorial Thompson Sampling**
2501.19122v1 by Hong Huang, Hai Yang, Yuan Chen, Jiaxun Ye, Dapeng Wu

Federated Learning (FL) enables collaborative model training across
distributed clients without data sharing, but its high computational and
communication demands strain resource-constrained devices. While existing
methods use dynamic pruning to improve efficiency by periodically adjusting
sparse model topologies while maintaining sparsity, these approaches suffer
from issues such as greedy adjustments, unstable topologies, and communication
inefficiency, resulting in less robust models and suboptimal performance under
data heterogeneity and partial client availability. To address these
challenges, we propose Federated Robust pruning via combinatorial Thompson
Sampling (FedRTS), a novel framework designed to develop robust sparse models.
FedRTS enhances robustness and performance through its Thompson Sampling-based
Adjustment (TSAdj) mechanism, which uses probabilistic decisions informed by
stable, farsighted information instead of deterministic decisions reliant on
unstable and myopic information in previous methods. Extensive experiments
demonstrate that FedRTS achieves state-of-the-art performance in computer
vision and natural language processing tasks while reducing communication
costs, particularly excelling in scenarios with heterogeneous data
distributions and partial client participation. Our codes are available at:
https://github.com/Little0o0/FedRTS

摘要：聯邦學習 (FL) 能在無資料分享的情況下，讓分散式客戶端進行協作模型訓練，但其高運算和通訊需求會對資源受限裝置造成負擔。現有方法使用動態剪枝，透過定期調整稀疏模型拓撲並維持稀疏性來提升效率，但這些方法有貪婪調整、拓撲不穩定、通訊效率低落等問題，導致模型穩健性較低，且在資料異質性和部分客戶端可用性的情況下，效能不佳。為了應對這些挑戰，我們提出透過組合式 Thompson 採樣進行聯邦穩健剪枝 (FedRTS)，這是一個旨在開發穩健稀疏模型的新穎架構。FedRTS 透過其基於 Thompson 採樣的調整 (TSAdj) 機制提升穩健性和效能，此機制使用由穩定、有遠見的資訊所提供的機率決策，而非仰賴先前方法中不穩定且短視的資訊所做的確定性決策。大量的實驗證明 FedRTS 在電腦視覺和自然語言處理任務中達到最先進的效能，同時降低通訊成本，特別是在資料分佈異質且客戶端參與度不完整的情況下表現出色。我們的程式碼可於以下網址取得：https://github.com/Little0o0/FedRTS

##### **Principal Components for Neural Network Initialization**
2501.19114v1 by Nhan Phan, Thu Nguyen, Pål Halvorsen, Michael A. Riegler

Principal Component Analysis (PCA) is a commonly used tool for dimension
reduction and denoising. Therefore, it is also widely used on the data prior to
training a neural network. However, this approach can complicate the
explanation of explainable AI (XAI) methods for the decision of the model. In
this work, we analyze the potential issues with this approach and propose
Principal Components-based Initialization (PCsInit), a strategy to incorporate
PCA into the first layer of a neural network via initialization of the first
layer in the network with the principal components, and its two variants
PCsInit-Act and PCsInit-Sub. Explanations using these strategies are as direct
and straightforward as for neural networks and are simpler than using PCA prior
to training a neural network on the principal components. Moreover, as will be
illustrated in the experiments, such training strategies can also allow further
improvement of training via backpropagation.

摘要：主成分分析 (PCA) 是一種常用的降維和去噪工具。因此，它也廣泛用於訓練神經網路之前對資料進行處理。然而，這種方法會使可解釋 AI (XAI) 方法對模型決策的解釋變得複雜。在這項工作中，我們分析了這種方法的潛在問題，並提出了基於主成分的初始化 (PCsInit)，這是一種通過使用主成分對網路中的第一層進行初始化，將 PCA 納入神經網路第一層的策略，以及它的兩個變體 PCsInit-Act 和 PCsInit-Sub。使用這些策略的解釋與神經網路一樣直接且簡潔，並且比在對主成分訓練神經網路之前使用 PCA 更簡單。此外，正如實驗中所展示的那樣，這種訓練策略還可以進一步提高通過反向傳播進行的訓練。

##### **PathE: Leveraging Entity-Agnostic Paths for Parameter-Efficient Knowledge Graph Embeddings**
2501.19095v1 by Ioannis Reklos, Jacopo de Berardinis, Elena Simperl, Albert Meroño-Peñuela

Knowledge Graphs (KGs) store human knowledge in the form of entities (nodes)
and relations, and are used extensively in various applications. KG embeddings
are an effective approach to addressing tasks like knowledge discovery, link
prediction, and reasoning. This is often done by allocating and learning
embedding tables for all or a subset of the entities. As this scales linearly
with the number of entities, learning embedding models in real-world KGs with
millions of nodes can be computationally intractable. To address this
scalability problem, our model, PathE, only allocates embedding tables for
relations (which are typically orders of magnitude fewer than the entities) and
requires less than 25% of the parameters of previous parameter efficient
methods. Rather than storing entity embeddings, we learn to compute them by
leveraging multiple entity-relation paths to contextualise individual entities
within triples. Evaluated on four benchmarks, PathE achieves state-of-the-art
performance in relation prediction, and remains competitive in link prediction
on path-rich KGs while training on consumer-grade hardware. We perform ablation
experiments to test our design choices and analyse the sensitivity of the model
to key hyper-parameters. PathE is efficient and cost-effective for relationally
diverse and well-connected KGs commonly found in real-world applications.

摘要：知識圖譜 (KG) 以實體 (節點) 和關係的形式儲存人類知識，並廣泛用於各種應用程式中。KG 嵌入是一種有效的方法，可解決知識發現、連結預測和推理等任務。這通常透過配置和學習所有實體或實體子集的嵌入式表格來完成。由於這會隨著實體數量線性擴充，在擁有數百萬個節點的真實世界 KG 中學習嵌入式模型在計算上可能難以處理。為了解決這個可擴充性問題，我們的模型 PathE 只配置關係的嵌入式表格 (通常數量比實體少幾個數量級)，並且所需參數少於先前參數有效率方法的 25%。我們並非儲存實體嵌入，而是學習透過利用多個實體關係路徑來計算它們，以將個別實體在三元組中脈絡化。在四個基準上進行評估，PathE 在關係預測中達到最先進的效能，並在路徑豐富的 KG 上的連結預測中保持競爭力，同時在消費級硬體上進行訓練。我們執行消融實驗來測試我們的設計選擇，並分析模型對關鍵超參數的敏感性。PathE 對於在真實世界應用中常見的關係多樣且連線良好的 KG 而言，既有效率又具有成本效益。

##### **Improving Low-Resource Sequence Labeling with Knowledge Fusion and Contextual Label Explanations**
2501.19093v1 by Peichao Lai, Jiaxin Gan, Feiyang Ye, Yilei Wang, Bin Cui

Sequence labeling remains a significant challenge in low-resource,
domain-specific scenarios, particularly for character-dense languages like
Chinese. Existing methods primarily focus on enhancing model comprehension and
improving data diversity to boost performance. However, these approaches still
struggle with inadequate model applicability and semantic distribution biases
in domain-specific contexts. To overcome these limitations, we propose a novel
framework that combines an LLM-based knowledge enhancement workflow with a
span-based Knowledge Fusion for Rich and Efficient Extraction (KnowFREE) model.
Our workflow employs explanation prompts to generate precise contextual
interpretations of target entities, effectively mitigating semantic biases and
enriching the model's contextual understanding. The KnowFREE model further
integrates extension label features, enabling efficient nested entity
extraction without relying on external knowledge during inference. Experiments
on multiple Chinese domain-specific sequence labeling datasets demonstrate that
our approach achieves state-of-the-art performance, effectively addressing the
challenges posed by low-resource settings.

摘要：序列標籤在低資源、特定領域場景中仍然是一個重大的挑戰，特別是對於像中文這樣的字元密集語言而言。現有方法主要著重於增強模型理解並改善資料多樣性以提升效能。然而，這些方法在特定領域脈絡中仍受限於模型適用性不足和語義分佈偏差。為了克服這些限制，我們提出一個新的框架，結合基於 LLM 的知識增強工作流程和基於 span 的豐富且有效抽取知識融合 (KnowFREE) 模型。我們的流程採用解釋提示來產生目標實體的精確脈絡詮釋，有效減輕語義偏差並豐富模型的脈絡理解。KnowFREE 模型進一步整合延伸標籤功能，在推理期間無需依賴外部知識即可進行有效的巢狀實體抽取。在多個中文特定領域序列標籤資料集上的實驗表明，我們的做法達到了最先進的效能，有效地應對了低資源設定所帶來的挑戰。

##### **Fairness Analysis of CLIP-Based Foundation Models for X-Ray Image Classification**
2501.19086v1 by Xiangyu Sun, Xiaoguang Zou, Yuanquan Wu, Guotai Wang, Shaoting Zhang

X-ray imaging is pivotal in medical diagnostics, offering non-invasive
insights into a range of health conditions. Recently, vision-language models,
such as the Contrastive Language-Image Pretraining (CLIP) model, have
demonstrated potential in improving diagnostic accuracy by leveraging
large-scale image-text datasets. However, since CLIP was not initially designed
for medical images, several CLIP-like models trained specifically on medical
images have been developed. Despite their enhanced performance, issues of
fairness - particularly regarding demographic attributes - remain largely
unaddressed. In this study, we perform a comprehensive fairness analysis of
CLIP-like models applied to X-ray image classification. We assess their
performance and fairness across diverse patient demographics and disease
categories using zero-shot inference and various fine-tuning techniques,
including Linear Probing, Multilayer Perceptron (MLP), Low-Rank Adaptation
(LoRA), and full fine-tuning. Our results indicate that while fine-tuning
improves model accuracy, fairness concerns persist, highlighting the need for
further fairness interventions in these foundational models.

摘要：X 光影像在醫療診斷中至關重要，能提供各種健康狀況的非侵入性見解。最近，視覺語言模型（例如對比語言影像預訓練 (CLIP) 模型）已證明有潛力透過利用大規模影像文字資料集來改善診斷準確性。然而，由於 CLIP 最初並非設計用於醫療影像，因此已經開發了數個特別針對醫療影像訓練的類似 CLIP 模型。儘管它們的效能有所提升，但公平性的問題（特別是關於人口統計屬性）仍大多未獲解決。在本研究中，我們對應用於 X 光影像分類的類似 CLIP 模型執行全面的公平性分析。我們使用零次學習推論和各種微調技術（包括線性探查、多層感知器 (MLP)、低秩適應 (LoRA) 和完整微調）來評估它們在不同患者人口統計和疾病類別中的效能和公平性。我們的結果表明，雖然微調會改善模型準確性，但公平性問題仍然存在，強調需要在這些基礎模型中進一步採取公平性干預措施。

##### **Improving vision-language alignment with graph spiking hybrid Networks**
2501.19069v1 by Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen

To bridge the semantic gap between vision and language (VL), it is necessary
to develop a good alignment strategy, which includes handling semantic
diversity, abstract representation of visual information, and generalization
ability of models. Recent works use detector-based bounding boxes or patches
with regular partitions to represent visual semantics. While current paradigms
have made strides, they are still insufficient for fully capturing the nuanced
contextual relations among various objects. This paper proposes a comprehensive
visual semantic representation module, necessitating the utilization of
panoptic segmentation to generate coherent fine-grained semantic features.
Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that
integrates the complementary advantages of Spiking Neural Networks (SNNs) and
Graph Attention Networks (GATs) to encode visual semantic information.
Intriguingly, the model not only encodes the discrete and continuous latent
variables of instances but also adeptly captures both local and global
contextual features, thereby significantly enhancing the richness and diversity
of semantic representations. Leveraging the spatiotemporal properties inherent
in SNNs, we employ contrastive learning (CL) to enhance the similarity-based
representation of embeddings. This strategy alleviates the computational
overhead of the model and enriches meaningful visual representations by
constructing positive and negative sample pairs. We design an innovative
pre-training method, Spiked Text Learning (STL), which uses text features to
improve the encoding ability of discrete semantics. Experiments show that the
proposed GSHN exhibits promising results on multiple VL downstream tasks.

摘要：<paragraph>為了彌合視覺和語言 (VL) 之間的語意差距，必須制定良好的對齊策略，其中包括處理語意多樣性、視覺資訊的抽象表示以及模型的泛化能力。最近的研究使用基於偵測器的邊界框或具有規則分割的區塊來表示視覺語意。雖然目前的範例已取得進展，但對於完全捕捉各種物件之間的細微脈絡關係仍不足夠。本文提出了一個全面的視覺語意表示模組，需要利用全景分割來產生連貫的細粒度語意特徵。此外，我們提出了一個新穎的圖形脈衝混合網路 (GSHN)，它整合了脈衝神經網路 (SNN) 和圖形注意力網路 (GAT) 的互補優勢來編碼視覺語意資訊。有趣的是，該模型不僅編碼實例的離散和連續潛在變數，還能巧妙地捕捉局部和全域脈絡特徵，從而顯著增強語意表示的豐富性和多樣性。利用 SNN 中固有的時空特性，我們採用對比學習 (CL) 來增強嵌入的基於相似性的表示。此策略減輕了模型的計算負擔，並透過建構正負樣本對來豐富有意義的視覺表示。我們設計了一個創新的預訓練方法，脈衝文本學習 (STL)，它使用文本特徵來提高離散語意的編碼能力。實驗表明，所提出的 GSHN 在多個 VL 下游任務上展現出有希望的結果。</paragraph>

##### **BEAT: Balanced Frequency Adaptive Tuning for Long-Term Time-Series Forecasting**
2501.19065v1 by Zhixuan Li, Naipeng Chen, Seonghwa Choi, Sanghoon Lee, Weisi Lin

Time-series forecasting is crucial for numerous real-world applications
including weather prediction and financial market modeling. While
temporal-domain methods remain prevalent, frequency-domain approaches can
effectively capture multi-scale periodic patterns, reduce sequence
dependencies, and naturally denoise signals. However, existing approaches
typically train model components for all frequencies under a unified training
objective, often leading to mismatched learning speeds: high-frequency
components converge faster and risk overfitting, while low-frequency components
underfit due to insufficient training time. To deal with this challenge, we
propose BEAT (Balanced frEquency Adaptive Tuning), a novel framework that
dynamically monitors the training status for each frequency and adaptively
adjusts their gradient updates. By recognizing convergence, overfitting, or
underfitting for each frequency, BEAT dynamically reallocates learning
priorities, moderating gradients for rapid learners and increasing those for
slower ones, alleviating the tension between competing objectives across
frequencies and synchronizing the overall learning process. Extensive
experiments on seven real-world datasets demonstrate that BEAT consistently
outperforms state-of-the-art approaches.

摘要：時序預測對於許多實際應用至關重要，包括天氣預測和金融市場建模。雖然時域方法仍然普遍，但頻域方法可以有效捕捉多尺度週期模式，減少序列依賴性，並自然地對訊號進行去雜訊。然而，現有方法通常在統一訓練目標下為所有頻率訓練模型組件，這通常會導致學習速度不匹配：高頻組件收斂得更快，有過擬合的風險，而低頻組件由於訓練時間不足而欠擬合。為了應對這一挑戰，我們提出了 BEAT（平衡頻率自適應調整），這是一個新的框架，可以動態監控每個頻率的訓練狀態，並自適應地調整它們的梯度更新。通過識別每個頻率的收斂、過擬合或欠擬合，BEAT 動態重新分配學習優先級，調節快速學習者的梯度，並增加慢速學習者的梯度，緩解了跨頻率競爭目標之間的緊張關係，並同步了整體學習過程。在七個真實世界資料集上的大量實驗表明，BEAT 持續優於最先進的方法。

##### **Enabling Autonomic Microservice Management through Self-Learning Agents**
2501.19056v1 by Fenglin Yu, Fangkai Yang, Xiaoting Qin, Zhiyang Zhang, Jue Zhang, Qingwei Lin, Hongyu Zhang, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

The increasing complexity of modern software systems necessitates robust
autonomic self-management capabilities. While Large Language Models (LLMs)
demonstrate potential in this domain, they often face challenges in adapting
their general knowledge to specific service contexts. To address this
limitation, we propose ServiceOdyssey, a self-learning agent system that
autonomously manages microservices without requiring prior knowledge of
service-specific configurations. By leveraging curriculum learning principles
and iterative exploration, ServiceOdyssey progressively develops a deep
understanding of operational environments, reducing dependence on human input
or static documentation. A prototype built with the Sock Shop microservice
demonstrates the potential of this approach for autonomic microservice
management.

摘要：現代軟體系統日益複雜，需要強大的自主自我管理能力。儘管大型語言模型 (LLM) 在此領域展現潛力，但它們在將一般知識調整至特定服務情境時，經常面臨挑戰。為了解決此限制，我們提出 ServiceOdyssey，一個自學代理系統，可自主管理微服務，而無需事先了解特定服務的組態。透過利用課程學習原則和反覆探索，ServiceOdyssey 逐步培養對作業環境的深入了解，減少對人工輸入或靜態文件依賴。使用 Sock Shop 微服務建構的原型展示了此方法在自主微服務管理方面的潛力。

##### **Towards Physiologically Sensible Predictions via the Rule-based Reinforcement Learning Layer**
2501.19055v1 by Lingwei Zhu, Zheng Chen, Yukie Nagai, Jimeng Sun

This paper adds to the growing literature of reinforcement learning (RL) for
healthcare by proposing a novel paradigm: augmenting any predictor with
Rule-based RL Layer (RRLL) that corrects the model's physiologically impossible
predictions. Specifically, RRLL takes as input states predicted labels and
outputs corrected labels as actions. The reward of the state-action pair is
evaluated by a set of general rules. RRLL is efficient, general and
lightweight: it does not require heavy expert knowledge like prior work but
only a set of impossible transitions. This set is much smaller than all
possible transitions; yet it can effectively reduce physiologically impossible
mistakes made by the state-of-the-art predictor models. We verify the utility
of RRLL on a variety of important healthcare classification problems and
observe significant improvements using the same setup, with only the
domain-specific set of impossibility changed. In-depth analysis shows that RRLL
indeed improves accuracy by effectively reducing the presence of
physiologically impossible predictions.

摘要：這篇論文透過提出一個新的範例，為醫療保健的強化學習 (RL) 不斷增加的文獻增添內容：用基於規則的 RL 層 (RRLL) 來擴充任何預測器，以修正模型在生理上不可能的預測。具體來說，RRLL 以預測標籤作為輸入狀態，並輸出修正標籤作為動作。狀態動作對的獎勵是由一組一般規則所評估。RRLL 既有效率、一般性又輕量級：它不需要像先前的研究那樣具備大量的專家知識，而只需要一組不可能的轉換。這組轉換比所有可能的轉換小得多；但它可以有效減少最先進的預測器模型所產生的生理上不可能的錯誤。我們驗證了 RRLL 在各種重要的醫療保健分類問題上的效用，並觀察到在使用相同設定的情況下，只有特定領域的不可能性集有所改變，便有顯著的改善。深入分析顯示，RRLL 確實透過有效減少生理上不可能的預測，來提升準確度。

##### **Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)**
2501.19047v2 by Maja Pavlovic

To be considered reliable, a model must be calibrated so that its confidence
in each decision closely reflects its true outcome. In this blogpost we'll take
a look at the most commonly used definition for calibration and then dive into
a frequently used evaluation measure for model calibration. We'll then cover
some of the drawbacks of this measure and how these surfaced the need for
additional notions of calibration, which require their own new evaluation
measures. This post is not intended to be an in-depth dissection of all works
on calibration, nor does it focus on how to calibrate models. Instead, it is
meant to provide a gentle introduction to the different notions and their
evaluation measures as well as to re-highlight some issues with a measure that
is still widely used to evaluate calibration.

摘要：要被認為是可靠的，模型必須經過校準，以便它在每個決策中的信心準確反映其真實結果。在這個部落格文章中，我們將探討校準最常用的定義，然後深入探討模型校準常用的評估指標。然後，我們將涵蓋此指標的一些缺點，以及這些缺點如何浮現出對校準的其他概念的需求，這些概念需要自己的新評估指標。這篇文章並非旨在深入探討所有關於校準的作品，也不著重於如何校準模型。相反，它的目的是溫和地介紹不同的概念及其評估指標，並重新強調一個仍然廣泛用於評估校準的指標的一些問題。

##### **Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors**
2501.19042v1 by Simon Idoko, B. Bhanu Teja, K. Madhava Krishna, Arun Kumar Singh

Coordination behavior in robot swarms is inherently multi-modal in nature.
That is, there are numerous ways in which a swarm of robots can avoid
inter-agent collisions and reach their respective goals. However, the problem
of generating diverse and feasible swarm behaviors in a scalable manner remains
largely unaddressed. In this paper, we fill this gap by combining generative
models with a safety-filter (SF). Specifically, we sample diverse trajectories
from a learned generative model which is subsequently projected onto the
feasible set using the SF. We experiment with two choices for generative
models, namely: Conditional Variational Autoencoder (CVAE) and Vector-Quantized
Variational Autoencoder (VQ-VAE). We highlight the trade-offs these two models
provide in terms of computation time and trajectory diversity. We develop a
custom solver for our SF and equip it with a neural network that predicts
context-specific initialization. Thecinitialization network is trained in a
self-supervised manner, taking advantage of the differentiability of the SF
solver. We provide two sets of empirical results. First, we demonstrate that we
can generate a large set of multi-modal, feasible trajectories, simulating
diverse swarm behaviors, within a few tens of milliseconds. Second, we show
that our initialization network provides faster convergence of our SF solver
vis-a-vis other alternative heuristics.

摘要：機器人蜂群中的協調行為本質上是多模態的。
也就是說，機器人蜂群有許多方法可以避免機器人之間的碰撞並到達各自的目標。然而，以可擴充的方式產生多樣化且可行的蜂群行為的問題在很大程度上仍未解決。在本文中，我們透過結合生成模型和安全過濾器 (SF) 來填補此空白。具體來說，我們從一個學習的生成模型中取樣多樣化的軌跡，然後使用 SF 將其投影到可行集合上。我們實驗了兩種生成模型的選擇，即條件變異自動編碼器 (CVAE) 和向量量化變異自動編碼器 (VQ-VAE)。我們強調了這兩個模型在計算時間和軌跡多樣性方面的權衡取捨。我們為我們的 SF 開發了一個自訂求解器，並配備了一個預測特定於情境初始化的神經網路。初始化網路以自監督的方式進行訓練，利用 SF 求解器的可微分性。我們提供了兩組經驗結果。首先，我們證明我們可以在幾十毫秒內生成大量多模態、可行的軌跡，模擬多樣化的蜂群行為。其次，我們證明我們的初始化網路提供比其他替代啟發式方法更快的 SF 求解器收斂性。

##### **On the Impact of Noise in Differentially Private Text Rewriting**
2501.19022v1 by Stephen Meisenbacher, Maulik Chevli, Florian Matthes

The field of text privatization often leverages the notion of
$\textit{Differential Privacy}$ (DP) to provide formal guarantees in the
rewriting or obfuscation of sensitive textual data. A common and nearly
ubiquitous form of DP application necessitates the addition of calibrated noise
to vector representations of text, either at the data- or model-level, which is
governed by the privacy parameter $\varepsilon$. However, noise addition almost
undoubtedly leads to considerable utility loss, thereby highlighting one major
drawback of DP in NLP. In this work, we introduce a new sentence infilling
privatization technique, and we use this method to explore the effect of noise
in DP text rewriting. We empirically demonstrate that non-DP privatization
techniques excel in utility preservation and can find an acceptable empirical
privacy-utility trade-off, yet cannot outperform DP methods in empirical
privacy protections. Our results highlight the significant impact of noise in
current DP rewriting mechanisms, leading to a discussion of the merits and
challenges of DP in NLP, as well as the opportunities that non-DP methods
present.

摘要：文本私有化领域通常利用
$\textit{差分隐私}$ (DP) 的概念在敏感文本数据的重写或混淆中提供正式保证。一种常见且几乎无处不在的 DP 应用形式需要在文本的向量表示中添加校准噪声，无论是在数据级还是模型级，这由隐私参数 $\varepsilon$ 控制。然而，添加噪声几乎毫无疑问地会导致相当大的效用损失，从而突出了 DP 在 NLP 中的一个主要缺点。在这项工作中，我们引入了一种新的句子填充私有化技术，并使用这种方法来探索噪声在 DP 文本重写中的影响。我们凭经验证明，非 DP 私有化技术在效用保留方面表现出色，并且可以找到可接受的经验隐私效用权衡，但无法在经验隐私保护中优于 DP 方法。我们的结果突出了噪声在当前 DP 重写机制中的重大影响，从而引发了对 DP 在 NLP 中的优点和挑战的讨论，以及非 DP 方法带来的机会。

##### **Scalable Multi-phase Word Embedding Using Conjunctive Propositional Clauses**
2501.19018v2 by Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo, Bimal Bhattarai

The Tsetlin Machine (TM) architecture has recently demonstrated effectiveness
in Machine Learning (ML), particularly within Natural Language Processing
(NLP). It has been utilized to construct word embedding using conjunctive
propositional clauses, thereby significantly enhancing our understanding and
interpretation of machine-derived decisions. The previous approach performed
the word embedding over a sequence of input words to consolidate the
information into a cohesive and unified representation. However, that approach
encounters scalability challenges as the input size increases. In this study,
we introduce a novel approach incorporating two-phase training to discover
contextual embeddings of input sequences. Specifically, this method
encapsulates the knowledge for each input word within the dataset's vocabulary,
subsequently constructing embeddings for a sequence of input words utilizing
the extracted knowledge. This technique not only facilitates the design of a
scalable model but also preserves interpretability. Our experimental findings
revealed that the proposed method yields competitive performance compared to
the previous approaches, demonstrating promising results in contrast to
human-generated benchmarks. Furthermore, we applied the proposed approach to
sentiment analysis on the IMDB dataset, where the TM embedding and the TM
classifier, along with other interpretable classifiers, offered a transparent
end-to-end solution with competitive performance.

摘要：Tsetlin 機器 (TM) 架構最近在機器學習 (ML) 中展現了其效能，特別是在自然語言處理 (NLP) 領域。它已被用於建構詞嵌入，使用連接命題子句，從而顯著增強我們對機器衍生決策的理解和詮釋。先前的做法對輸入字詞的序列執行詞嵌入，將資訊整合到一個有凝聚力和統一性的表徵中。然而，隨著輸入大小的增加，該做法會遇到可擴充性的挑戰。在本研究中，我們介紹一種新穎的做法，結合兩階段訓練來發現輸入序列的脈絡嵌入。具體來說，此方法將資料集詞彙中每個輸入字詞的知識封裝起來，然後利用提取的知識為輸入字詞的序列建構嵌入。此技術不僅有助於設計可擴充性的模型，還能保留可解釋性。我們的實驗結果顯示，與先前的做法相比，所提出的方法產出了有競爭力的效能，與人為產生的基準相比，展現了有希望的結果。此外，我們將所提出的做法應用於 IMDB 資料集的情緒分析，其中 TM 嵌入和 TM 分類器，以及其他可解釋的分類器，提供了一個透明的端到端解決方案，具有競爭力的效能。

##### **Calling a Spade a Heart: Gaslighting Multimodal Large Language Models via Negation**
2501.19017v1 by Bin Zhu, Hui yan Qi, Yinxuan Gui, Jingjing Chen, Chong-Wah Ngo, Ee Peng Lim

Multimodal Large Language Models (MLLMs) have exhibited remarkable
advancements in integrating different modalities, excelling in complex
understanding and generation tasks. Despite their success, MLLMs remain
vulnerable to conversational adversarial inputs, particularly negation
arguments. This paper systematically evaluates state-of-the-art MLLMs across
diverse benchmarks, revealing significant performance drops when negation
arguments are introduced to initially correct responses. We show critical
vulnerabilities in the reasoning and alignment mechanisms of these models.
Proprietary models such as GPT-4o and Claude-3.5-Sonnet demonstrate better
resilience compared to open-source counterparts like Qwen2-VL and LLaVA.
However, all evaluated MLLMs struggle to maintain logical consistency under
negation arguments during conversation. This paper aims to offer valuable
insights for improving the robustness of MLLMs against adversarial inputs,
contributing to the development of more reliable and trustworthy multimodal AI
systems.

摘要：多模态大型语言模型 (MLLM) 在整合不同模态方面表现出显着的进步，在复杂的理解和生成任务中表现出色。尽管取得了成功，但 MLLM 仍然容易受到会话对抗输入的影响，尤其是否定论证。本文系统地评估了最先进的 MLLM 在不同基准上的表现，揭示了在最初正确的响应中引入否定论证时性能大幅下降。我们展示了这些模型在推理和对齐机制中的关键漏洞。与 Qwen2-VL 和 LLaVA 等开源对应项相比，GPT-4o 和 Claude-3.5-Sonnet 等专有模型表现出更好的弹性。然而，所有评估过的 MLLM 在对话中都难以在否定论证下保持逻辑一致性。本文旨在为提高 MLLM 对对抗输入的鲁棒性提供有价值的见解，为开发更可靠、更可信的多模态 AI 系统做出贡献。

##### **Importing Phantoms: Measuring LLM Package Hallucination Vulnerabilities**
2501.19012v1 by Arjun Krishna, Erick Galinkin, Leon Derczynski, Jeffrey Martin

Large Language Models (LLMs) have become an essential tool in the
programmer's toolkit, but their tendency to hallucinate code can be used by
malicious actors to introduce vulnerabilities to broad swathes of the software
supply chain. In this work, we analyze package hallucination behaviour in LLMs
across popular programming languages examining both existing package references
and fictional dependencies. By analyzing this package hallucination behaviour
we find potential attacks and suggest defensive strategies to defend against
these attacks. We discover that package hallucination rate is predicated not
only on model choice, but also programming language, model size, and
specificity of the coding task request. The Pareto optimality boundary between
code generation performance and package hallucination is sparsely populated,
suggesting that coding models are not being optimized for secure code.
Additionally, we find an inverse correlation between package hallucination rate
and the HumanEval coding benchmark, offering a heuristic for evaluating the
propensity of a model to hallucinate packages. Our metrics, findings and
analyses provide a base for future models, securing AI-assisted software
development workflows against package supply chain attacks.

摘要：大型語言模型 (LLM) 已成為程式設計師工具箱中不可或缺的工具，但惡意行為者可能會利用其產生代碼的傾向，在軟體供應鏈的廣泛範圍內引入漏洞。在本文中，我們分析了 LLM 中的套件產生行為，探討了現有套件參考和虛構依賴關係，並涵蓋了多種流行的程式語言。透過分析這個套件產生行為，我們發現潛在的攻擊，並提出防禦策略來抵禦這些攻擊。我們發現，套件產生率不僅取決於模型選擇，還取決於程式語言、模型大小和編碼任務請求的具體性。代碼產生效能和套件產生之間的帕累托最優邊界人口稀少，這表示編碼模型並未針對安全代碼進行最佳化。此外，我們發現套件產生率與 HumanEval 編碼基準之間存在反比關係，這提供了一個評估模型產生套件傾向的啟發式方法。我們的指標、發現和分析為未來的模型提供了基礎，確保了 AI 協助的軟體開發工作流程免於套件供應鏈攻擊。

##### **DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition**
2501.19010v2 by Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee

Dysarthric speech recognition often suffers from performance degradation due
to the intrinsic diversity of dysarthric severity and extrinsic disparity from
normal speech. To bridge these gaps, we propose a Dynamic Phoneme-level
Contrastive Learning (DyPCL) method, which leads to obtaining invariant
representations across diverse speakers. We decompose the speech utterance into
phoneme segments for phoneme-level contrastive learning, leveraging dynamic
connectionist temporal classification alignment. Unlike prior studies focusing
on utterance-level embeddings, our granular learning allows discrimination of
subtle parts of speech. In addition, we introduce dynamic curriculum learning,
which progressively transitions from easy negative samples to
difficult-to-distinguishable negative samples based on phonetic similarity of
phoneme. Our approach to training by difficulty levels alleviates the inherent
variability of speakers, better identifying challenging speeches. Evaluated on
the UASpeech dataset, DyPCL outperforms baseline models, achieving an average
22.10\% relative reduction in word error rate (WER) across the overall
dysarthria group.

摘要：構音障礙的語音辨識常常會因為構音障礙嚴重程度的內在差異和與正常語音的外在差異而導致效能下降。為了彌補這些差距，我們提出了一個動態音素層對比學習 (DyPCL) 方法，這會導致獲得不同說話者之間的不變表示。我們將語音話語分解成音素片段，以進行音素層對比學習，利用動態連接主義時序分類對齊。與專注於話語層級嵌入的先前研究不同，我們的細粒度學習允許區分語音的細微部分。此外，我們引入了動態課程學習，它會根據音素的語音相似性，從容易的負面樣本逐漸過渡到難以區分的負面樣本。我們透過難度等級進行訓練的方法減輕了說話者的內在變異性，能更好地識別有挑戰性的語音。在 UASpeech 資料集上進行評估，DyPCL 優於基線模型，在整體構音障礙組中，字元錯誤率 (WER) 平均降低了 22.10%。

##### **Virtual airways heatmaps to optimize point of entry location in lung biopsy planning systems**
2501.19003v1 by Debora Gil, Pere Lloret, Marta Diez-Ferrer, Carles Sanchez

Purpose: We present a virtual model to optimize point of entry (POE) in lung
biopsy planning systems. Our model allows to compute the quality of a biopsy
sample taken from potential POE, taking into account the margin of error that
arises from discrepancies between the orientation in the planning simulation
and the actual orientation during the operation. Additionally, the study
examines the impact of the characteristics of the lesion. Methods: The quality
of the biopsy is given by a heatmap projected onto the skeleton of a
patient-specific model of airways. The skeleton provides a 3D representation of
airways structure, while the heatmap intensity represents the potential amount
of tissue that it could be extracted from each POE. This amount of tissue is
determined by the intersection of the lesion with a cone that represents the
uncertainty area in the introduction of biopsy instruments. The cone, lesion,
and skeleton are modelled as graphical objects that define a 3D scene of the
intervention. Results: We have simulated different settings of the intervention
scene from a single anatomy extracted from a CT scan and two lesions with
regular and irregular shapes. The different scenarios are simulated by
systematic rotation of each lesion placed at different distances from airways.
Analysis of the heatmaps for the different settings show a strong impact of
lesion orientation for irregular shape and the distance for both shapes.
Conclusion: The proposed heatmaps help to visually assess the optimal POE and
identify whether multiple optimal POEs exist in different zones of the bronchi.
They also allow us to model the maximum allowable error in navigation systems
and study which variables have the greatest influence on the success of the
operation. Additionally, they help determine at what point this influence could
potentially jeopardize the operation.

摘要：<paragraph>目的：我們提出一個虛擬模型來優化肺部活檢計畫系統中的切入點 (POE)。我們的模型可以計算從潛在 POE 採集的活檢樣本品質，考量到計畫模擬與實際操作期間方向之間的誤差範圍。此外，這項研究探討病灶特徵的影響。方法：活檢品質由熱圖提供，投影到特定患者氣道模型的骨架上。骨架提供氣道結構的 3D 表示，而熱圖強度表示從每個 POE 能萃取的潛在組織量。此組織量由病灶與錐體的交集決定，錐體表示活檢器械導入的不確定區域。錐體、病灶和骨架建模為圖形物件，定義介入的 3D 場景。結果：我們模擬了從電腦斷層掃描中萃取的單一解剖結構，以及兩個形狀規則和不規則的病灶，模擬了介入場景的不同設定。不同的場景是透過系統性旋轉置於不同氣道距離的每個病灶來模擬。針對不同設定的熱圖分析顯示，不規則形狀的病灶方向和兩種形狀的距離有很大的影響。結論：建議的熱圖有助於視覺評估最佳 POE，並找出支氣管不同區域中是否存在多個最佳 POE。它們也讓我們能夠建模導航系統中最大的容許誤差，並研究哪個變數對手術成功有最大的影響。此外，它們有助於確定在什麼時候這種影響可能會危害手術。</paragraph>

##### **Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings**
2501.18998v1 by Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo

In recent years, text generation tools utilizing Artificial Intelligence (AI)
have occasionally been misused across various domains, such as generating
student reports or creative writings. This issue prompts plagiarism detection
services to enhance their capabilities in identifying AI-generated content.
Adversarial attacks are often used to test the robustness of AI-text generated
detectors. This work proposes a novel textual adversarial attack on the
detection models such as Fast-DetectGPT. The method employs embedding models
for data perturbation, aiming at reconstructing the AI generated texts to
reduce the likelihood of detection of the true origin of the texts.
Specifically, we employ different embedding techniques, including the Tsetlin
Machine (TM), an interpretable approach in machine learning for this purpose.
By combining synonyms and embedding similarity vectors, we demonstrates the
state-of-the-art reduction in detection scores against Fast-DetectGPT.
Particularly, in the XSum dataset, the detection score decreased from 0.4431 to
0.2744 AUROC, and in the SQuAD dataset, it dropped from 0.5068 to 0.3532 AUROC.

摘要：近年来，利用人工智能 (AI) 的文本生成工具偶尔会遭到滥用，例如生成学生报告或创意写作。这个问题促使剽窃检测服务增强其识别 AI 生成的内容的能力。对抗性攻击通常用于测试 AI 文本生成检测器的鲁棒性。这项工作提出了一种针对 Fast-DetectGPT 等检测模型的新型文本对抗性攻击。该方法采用嵌入模型进行数据扰动，旨在重建 AI 生成的文本，以降低检测文本真实来源的可能性。具体来说，我们采用了不同的嵌入技术，包括 Tsetlin 机器 (TM)，这是一种机器学习中可解释的方法。通过结合同义词和嵌入相似度向量，我们展示了针对 Fast-DetectGPT 的检测分数的最新减少。特别是，在 XSum 数据集中，检测分数从 0.4431 下降到 0.2744 AUROC，在 SQuAD 数据集中，它从 0.5068 下降到 0.3532 AUROC。

##### **VKFPos: A Learning-Based Monocular Positioning with Variational Bayesian Extended Kalman Filter Integration**
2501.18994v1 by Jian-Yu Chen, Yi-Ru Chen, Yin-Qiao Chang, Che-Ming Li, Jann-Long Chern, Chih-Wei Huang

This paper addresses the challenges in learning-based monocular positioning
by proposing VKFPos, a novel approach that integrates Absolute Pose Regression
(APR) and Relative Pose Regression (RPR) via an Extended Kalman Filter (EKF)
within a variational Bayesian inference framework. Our method shows that the
essential posterior probability of the monocular positioning problem can be
decomposed into APR and RPR components. This decomposition is embedded in the
deep learning model by predicting covariances in both APR and RPR branches,
allowing them to account for associated uncertainties. These covariances
enhance the loss functions and facilitate EKF integration. Experimental
evaluations on both indoor and outdoor datasets show that the single-shot APR
branch achieves accuracy on par with state-of-the-art methods. Furthermore, for
temporal positioning, where consecutive images allow for RPR and EKF
integration, VKFPos outperforms temporal APR and model-based integration
methods, achieving superior accuracy.

摘要：本論文探討了基於學習的單眼定位挑戰，提出 VKFPos，一種透過擴展卡爾曼濾波器 (EKF) 在變分貝氏推論框架內整合絕對位姿回歸 (APR) 和相對位姿回歸 (RPR) 的新方法。我們的模型顯示，單眼定位問題的基本後驗機率可以分解成 APR 和 RPR 組成。此分解透過預測 APR 和 RPR 分支中的共變異數來嵌入深度學習模型，讓它們能考量相關的不確定性。這些共變異數增強了損失函數並促進 EKF 整合。在室內和室外資料集上的實驗評估顯示，單次 APR 分支達到了與最先進方法同等的準確度。此外，對於時序定位，連續影像允許 RPR 和 EKF 整合，VKFPos 優於時序 APR 和基於模型的整合方法，達到了更高的準確度。

##### **Symmetric Pruning of Large Language Models**
2501.18980v1 by Kai Yi, Peter Richtárik

Popular post-training pruning methods such as Wanda and RIA are known for
their simple, yet effective, designs that have shown exceptional empirical
performance. Wanda optimizes performance through calibrated activations during
pruning, while RIA emphasizes the relative, rather than absolute, importance of
weight elements. Despite their practical success, a thorough theoretical
foundation explaining these outcomes has been lacking. This paper introduces
new theoretical insights that redefine the standard minimization objective for
pruning, offering a deeper understanding of the factors contributing to their
success. Our study extends beyond these insights by proposing complementary
strategies that consider both input activations and weight significance. We
validate these approaches through rigorous experiments, demonstrating
substantial enhancements over existing methods. Furthermore, we introduce a
novel training-free fine-tuning approach $R^2$-DSnoT that incorporates relative
weight importance and a regularized decision boundary within a dynamic
pruning-and-growing framework, significantly outperforming strong baselines and
establishing a new state of the art.

摘要：常見的後訓練剪枝方法，例如 Wanda 和 RIA，以其簡單但有效的設計而聞名，這些設計已展現出卓越的經驗效能。Wanda 在剪枝期間透過校準激活來最佳化效能，而 RIA 則強調權重元素的相對重要性，而非絕對重要性。儘管在實務上獲得成功，但缺乏徹底的理論基礎來解釋這些結果。本文介紹新的理論見解，重新定義剪枝的標準最小化目標，提供對促成其成功的因素更深入的了解。我們的研究超越這些見解，提出考量輸入激活和權重顯著性的互補策略。我們透過嚴謹的實驗驗證這些方法，證明其大幅優於現有方法。此外，我們介紹一種新穎的免訓練微調方法 $R^2$-DSnoT，它在動態剪枝與成長架構中納入相對權重重要性和正規化的決策邊界，顯著優於強大的基準，並建立新的技術水準。

##### **GPO-VAE: Modeling Explainable Gene Perturbation Responses utilizing GRN-Aligned Parameter Optimization**
2501.18973v1 by Seungheun Baek, Soyon Park, Yan Ting Chok, Mogan Gim, Jaewoo Kang

Motivation: Predicting cellular responses to genetic perturbations is
essential for understanding biological systems and developing targeted
therapeutic strategies. While variational autoencoders (VAEs) have shown
promise in modeling perturbation responses, their limited explainability poses
a significant challenge, as the learned features often lack clear biological
meaning. Nevertheless, model explainability is one of the most important
aspects in the realm of biological AI. One of the most effective ways to
achieve explainability is incorporating the concept of gene regulatory networks
(GRNs) in designing deep learning models such as VAEs. GRNs elicit the
underlying causal relationships between genes and are capable of explaining the
transcriptional responses caused by genetic perturbation treatments. Results:
We propose GPO-VAE, an explainable VAE enhanced by GRN-aligned Parameter
Optimization that explicitly models gene regulatory networks in the latent
space. Our key approach is to optimize the learnable parameters related to
latent perturbation effects towards GRN-aligned explainability. Experimental
results on perturbation prediction show our model achieves state-of-the-art
performance in predicting transcriptional responses across multiple benchmark
datasets. Furthermore, additional results on evaluating the GRN inference task
reveal our model's ability to generate meaningful GRNs compared to other
methods. According to qualitative analysis, GPO-VAE posseses the ability to
construct biologically explainable GRNs that align with experimentally
validated regulatory pathways. GPO-VAE is available at
https://github.com/dmis-lab/GPO-VAE

摘要：**動機：**預測細胞對遺傳擾動的反應對於理解生物系統和開發目標治療策略至關重要。儘管變分自動編碼器 (VAE) 在建模擾動反應方面已展現前景，但其解釋力有限，這是一個重大挑戰，因為學習到的特徵經常缺乏明確的生物學意義。儘管如此，模型的可解釋性是生物 AI 領域中最重要的方面之一。實現可解釋性的最有效方法之一是在設計深度學習模型（例如 VAE）時納入基因調控網路 (GRN) 的概念。GRN 引發基因之間的潛在因果關係，並能夠解釋由遺傳擾動治療引起的轉錄反應。**結果：**我們提出 GPO-VAE，一種可解釋的 VAE，通過 GRN 對齊參數優化增強，在潛在空間中明確建模基因調控網路。我們的關鍵方法是針對 GRN 對齊的可解釋性，優化與潛在擾動效應相關的可學習參數。擾動預測的實驗結果表明，我們的模型在預測多個基準資料集的轉錄反應方面達到了最先進的效能。此外，評估 GRN 推論任務的額外結果揭示了我們的模型與其他方法相比，具備產生有意義 GRN 的能力。根據定性分析，GPO-VAE 具有構建生物可解釋 GRN 的能力，這些 GRN 與經過實驗驗證的調控途徑一致。GPO-VAE 可在 https://github.com/dmis-lab/GPO-VAE 獲得

##### **Intrinsic Tensor Field Propagation in Large Language Models: A Novel Approach to Contextual Information Flow**
2501.18957v1 by Alfred Bexley, Lukas Radcliffe, Giles Weatherstone, Joseph Sakau

Context propagation remains a central challenge in language model
architectures, particularly in tasks requiring the retention of long-range
dependencies. Conventional attention mechanisms, while effective in many
applications, exhibit limitations in maintaining coherent contextual
representations over extended sequences due to their reliance on discrete token
interactions. A novel approach is introduced through the formulation of
Intrinsic Tensor Field Propagation (ITFP), which models contextual
relationships as continuous tensor fields distributed across token embeddings.
The propagation dynamics are governed through differential equations that
enable a structured flow of contextual information, augmenting the standard
attention mechanism to enhance coherence and recall. A series of experiments
conducted on an open-source transformer-based model demonstrate that ITFP
provides measurable improvements in contextual retention, dependency
resolution, and inference stability across various linguistic structures.
Comparisons with baseline models reveal a reduction in syntactic
inconsistencies and factual errors, while ablation studies indicate that the
choice of propagation depth and integration strength significantly impacts
model performance. Additional evaluations assessing domain generalization
suggest that ITFP effectively adapts across different text genres, reinforcing
its applicability beyond conventional language modeling tasks. Although
computational trade-offs are introduced through the inclusion of tensor field
computations, empirical findings suggest that the benefits in accuracy and
coherence outweigh the increased processing demands.

摘要：語境傳播在語言模型架構中仍然是一個核心挑戰，特別是在需要保留長程依賴關係的任務中。傳統的注意力機制雖然在許多應用中很有效，但由於依賴離散的符號交互作用，在維持擴展序列上連貫的語境表示方面表現出局限性。通過制定內在張量場傳播 (ITFP) 來引入一種新方法，它將語境關係建模為分佈在符號嵌入中的連續張量場。傳播動態由微分方程式控制，這些方程式能夠結構化語境資訊的流動，加強標準注意力機制以增強連貫性和召回率。在一系列在開源Transformer模型上進行的實驗中證明，ITFP 在各種語言結構中提供了語境保留、依賴關係解析和推論穩定性的可測量改進。與基線模型的比較顯示句法不一致性和事實錯誤減少，而消融研究表明，傳播深度和整合強度的選擇會顯著影響模型效能。評估領域泛化的其他評估表明，ITFP 能夠有效地適應不同的文字類型，加強其適用性，超越傳統的語言建模任務。儘管透過納入張量場計算引入了計算權衡，但經驗發現，準確性和連貫性方面的優點大於增加的處理需求。

##### **Deep Learning based Quasi-consciousness Training for Robot Intelligent Model**
2501.18955v1 by Yuchun Li, Fang Zhang

This paper explores a deep learning based robot intelligent model that
renders robots learn and reason for complex tasks. First, by constructing a
network of environmental factor matrix to stimulate the learning process of the
robot intelligent model, the model parameters must be subjected to coarse &
fine tuning to optimize the loss function for minimizing the loss score,
meanwhile robot intelligent model can fuse all previously known concepts
together to represent things never experienced before, which need robot
intelligent model can be generalized extensively. Secondly, in order to
progressively develop a robot intelligent model with primary consciousness,
every robot must be subjected to at least 1~3 years of special school for
training anthropomorphic behaviour patterns to understand and process complex
environmental information and make rational decisions. This work explores and
delivers the potential application of deep learning-based quasi-consciousness
training in the field of robot intelligent model.

摘要：本文探討一個基於深度學習的機器人智能模型，它能讓機器人學習並推理複雜的任務。首先，透過建構一個環境因子矩陣網路來刺激機器人智能模型的學習過程，模型參數必須經過粗調和微調，以最佳化損失函數以最小化損失分數，同時機器人智能模型可以將所有先前已知的概念融合在一起，以表示以前從未經歷過的事物，這需要機器人智能模型可以廣泛地概括。其次，為了逐步開發具有基本意識的機器人智能模型，每個機器人都必須接受至少 1~3 年的特殊學校訓練，以訓練擬人化的行為模式，以了解和處理複雜的環境資訊並做出合理的決策。這項工作探討並提供了基於深度學習的類意識訓練在機器人智能模型領域的潛在應用。

##### **Fantastic Targets for Concept Erasure in Diffusion Models and Where To Find Them**
2501.18950v1 by Anh Bui, Trang Vu, Long Vuong, Trung Le, Paul Montague, Tamas Abraham, Junae Kim, Dinh Phung

Concept erasure has emerged as a promising technique for mitigating the risk
of harmful content generation in diffusion models by selectively unlearning
undesirable concepts. The common principle of previous works to remove a
specific concept is to map it to a fixed generic concept, such as a neutral
concept or just an empty text prompt. In this paper, we demonstrate that this
fixed-target strategy is suboptimal, as it fails to account for the impact of
erasing one concept on the others. To address this limitation, we model the
concept space as a graph and empirically analyze the effects of erasing one
concept on the remaining concepts. Our analysis uncovers intriguing geometric
properties of the concept space, where the influence of erasing a concept is
confined to a local region. Building on this insight, we propose the Adaptive
Guided Erasure (AGE) method, which \emph{dynamically} selects optimal target
concepts tailored to each undesirable concept, minimizing unintended side
effects. Experimental results show that AGE significantly outperforms
state-of-the-art erasure methods on preserving unrelated concepts while
maintaining effective erasure performance. Our code is published at
{https://github.com/tuananhbui89/Adaptive-Guided-Erasure}.

摘要：概念擦除已成為一種有前途的技術，可用於透過選擇性地取消學習不良概念，來減輕擴散模型中產生有害內容的風險。先前移除特定概念的共同原則，是將其對應到一個固定的通用概念，例如中立概念或僅為一個空文字提示。在本文中，我們證明此一固定目標策略並非最佳，因為它無法考量到擦除一個概念對其他概念的影響。為了解決此一限制，我們將概念空間建模為一個圖形，並實證分析擦除一個概念對其餘概念的影響。我們的分析揭示了概念空間的有趣幾何特性，其中擦除一個概念的影響侷限於一個區域。根據此一洞見，我們提出自適應引導擦除 (AGE) 方法，此方法會根據每個不良概念，動態選擇最佳目標概念，將意外的副作用降至最低。實驗結果顯示，AGE 在保留無關概念的同時，在維持有效擦除效能方面，明顯優於最先進的擦除方法。我們的程式碼已發布於 {https://github.com/tuananhbui89/Adaptive-Guided-Erasure}。

##### **Language Games as the Pathway to Artificial Superhuman Intelligence**
2501.18924v1 by Ying Wen, Ziyu Wan, Shao Zhang

The evolution of large language models (LLMs) toward artificial superhuman
intelligence (ASI) hinges on data reproduction, a cyclical process in which
models generate, curate and retrain on novel data to refine capabilities.
Current methods, however, risk getting stuck in a data reproduction trap:
optimizing outputs within fixed human-generated distributions in a closed loop
leads to stagnation, as models merely recombine existing knowledge rather than
explore new frontiers. In this paper, we propose language games as a pathway to
expanded data reproduction, breaking this cycle through three mechanisms: (1)
\textit{role fluidity}, which enhances data diversity and coverage by enabling
multi-agent systems to dynamically shift roles across tasks; (2) \textit{reward
variety}, embedding multiple feedback criteria that can drive complex
intelligent behaviors; and (3) \textit{rule plasticity}, iteratively evolving
interaction constraints to foster learnability, thereby injecting continual
novelty. By scaling language games into global sociotechnical ecosystems,
human-AI co-evolution generates unbounded data streams that drive open-ended
exploration. This framework redefines data reproduction not as a closed loop
but as an engine for superhuman intelligence.

摘要：大型語言模型 (LLM) 朝向人工超人類智慧 (ASI) 的演進，取決於資料複製，這是一個循環過程，模型在其中生成、策展和重新訓練新資料，以改善能力。然而，目前的技術有陷入資料複製陷阱的風險：在封閉迴路中最佳化固定的人類產生分配中的輸出，導致停滯，因為模型只是重新組合既有知識，而不是探索新領域。在本文中，我們提出語言遊戲作為擴展資料複製的途徑，透過三種機制打破這個循環：(1) \textit{角色流動性}，透過讓多重代理系統在任務中動態地轉換角色，來提升資料的多樣性和涵蓋範圍；(2) \textit{獎勵多樣性}，嵌入多重回饋準則，可以驅動複雜的智慧行為；以及 (3) \textit{規則可塑性}，反覆地演化互動限制，以促進可學習性，進而注入持續的新穎性。透過將語言遊戲擴展到全球社會技術生態系統，人類與 AI 的共同演化產生無邊界資料串流，驅動開放式探索。此架構重新定義資料複製，使其不再是封閉迴路，而是超人類智慧的引擎。

##### **KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search**
2501.18922v1 by Haoran Luo, Haihong E, Yikai Guo, Qika Lin, Xiaobao Wu, Xinyu Mu, Wenhao Liu, Meina Song, Yifan Zhu, Luu Anh Tuan

Knowledge Base Question Answering (KBQA) aims to answer natural language
questions with a large-scale structured knowledge base (KB). Despite
advancements with large language models (LLMs), KBQA still faces challenges in
weak KB awareness, imbalance between effectiveness and efficiency, and high
reliance on annotated data. To address these challenges, we propose KBQA-o1, a
novel agentic KBQA method with Monte Carlo Tree Search (MCTS). It introduces a
ReAct-based agent process for stepwise logical form generation with KB
environment exploration. Moreover, it employs MCTS, a heuristic search method
driven by policy and reward models, to balance agentic exploration's
performance and search space. With heuristic exploration, KBQA-o1 generates
high-quality annotations for further improvement by incremental fine-tuning.
Experimental results show that KBQA-o1 outperforms previous low-resource KBQA
methods with limited annotated data, boosting Llama-3.1-8B model's GrailQA F1
performance to 78.5% compared to 48.5% of the previous sota method with
GPT-3.5-turbo.

摘要：知識庫問答 (KBQA) 的目標是使用大規模結構化知識庫 (KB) 來回答自然語言問題。儘管大型語言模型 (LLM) 已有進展，但 KBQA 仍面臨 KB 意識薄弱、效能與效率失衡，以及高度依賴註釋資料的挑戰。為了應對這些挑戰，我們提出 KBQA-o1，一種結合蒙地卡羅樹狀搜尋 (MCTS) 的新穎智能 KBQA 方法。它引入了基於 ReAct 的代理程序流程，用於逐步產生邏輯形式並探索 KB 環境。此外，它採用 MCTS，一種由策略和獎勵模型驅動的啟發式搜尋方法，以平衡代理探索的效能和搜尋空間。透過啟發式探索，KBQA-o1 會產生高品質的註釋，以便透過漸進式微調進一步改善。實驗結果顯示，KBQA-o1 在註釋資料有限的情況下，優於先前的低資源 KBQA 方法，將 Llama-3.1-8B 模型的 GrailQA F1 效能提升至 78.5%，而先前使用 GPT-3.5-turbo 的 sota 方法僅為 48.5%。

##### **Deepfake Detection of Singing Voices With Whisper Encodings**
2501.18919v1 by Falguni Sharma, Priyanka Gupta

The deepfake generation of singing vocals is a concerning issue for artists
in the music industry. In this work, we propose a singing voice deepfake
detection (SVDD) system, which uses noise-variant encodings of open-AI's
Whisper model. As counter-intuitive as it may sound, even though the Whisper
model is known to be noise-robust, the encodings are rich in non-speech
information, and are noise-variant. This leads us to evaluate Whisper encodings
as feature representations for the SVDD task. Therefore, in this work, the SVDD
task is performed on vocals and mixtures, and the performance is evaluated in
\%EER over varying Whisper model sizes and two classifiers- CNN and ResNet34,
under different testing conditions.

摘要：人聲歌唱的深度偽造生成對音樂產業的藝術家來說是一個令人擔憂的問題。在這項工作中，我們提出了一個歌唱聲音深度偽造偵測 (SVDD) 系統，它使用 open-AI 的 Whisper 模型的雜訊變異編碼。儘管 Whisper 模型已知對雜訊具有魯棒性，但編碼富含非語音資訊，而且是雜訊變異的，這聽起來可能違反直覺。這使得我們可以評估 Whisper 編碼作為 SVDD 任務的特徵表示。因此，在這項工作中，SVDD 任務在人聲和混合音上執行，並在不同的測試條件下評估在不同的 Whisper 模型大小和兩個分類器（CNN 和 ResNet34）上 \%EER 的效能。

##### **Lightspeed Geometric Dataset Distance via Sliced Optimal Transport**
2501.18901v1 by Khai Nguyen, Hai Nguyen, Tuan Pham, Nhat Ho

We introduce sliced optimal transport dataset distance (s-OTDD), a
model-agnostic, embedding-agnostic approach for dataset comparison that
requires no training, is robust to variations in the number of classes, and can
handle disjoint label sets. The core innovation is Moment Transform Projection
(MTP), which maps a label, represented as a distribution over features, to a
real number. Using MTP, we derive a data point projection that transforms
datasets into one-dimensional distributions. The s-OTDD is defined as the
expected Wasserstein distance between the projected distributions, with respect
to random projection parameters. Leveraging the closed form solution of
one-dimensional optimal transport, s-OTDD achieves (near-)linear computational
complexity in the number of data points and feature dimensions and is
independent of the number of classes. With its geometrically meaningful
projection, s-OTDD strongly correlates with the optimal transport dataset
distance while being more efficient than existing dataset discrepancy measures.
Moreover, it correlates well with the performance gap in transfer learning and
classification accuracy in data augmentation.

摘要：我們引入了切片最優傳輸資料集距離 (s-OTDD)，這是一種與模型無關、與嵌入無關的方法，用於資料集比較，不需要訓練，對類別數量的變化具有魯棒性，並且可以處理不相交的標籤集。核心的創新是矩轉換投影 (MTP)，它將標籤（表示為特徵上的分佈）映射到實數。使用 MTP，我們推導出一個資料點投影，將資料集轉換為一維分佈。s-OTDD 被定義為投影分佈之間的預期 Wasserstein 距離，相對於隨機投影參數。利用一維最優傳輸的閉合形式解，s-OTDD 在資料點數和特徵維度上實現了（接近）線性計算複雜度，並且與類別數無關。通過其幾何意義明確的投影，s-OTDD 與最優傳輸資料集距離密切相關，同時比現有的資料集差異度量更有效率。此外，它與傳輸學習中的效能差距和資料擴充中的分類準確度密切相關。

##### **Efficient Supernet Training with Orthogonal Softmax for Scalable ASR Model Compression**
2501.18895v1 by Jingjing Xu, Eugen Beck, Zijian Yang, Ralf Schlüter

ASR systems are deployed across diverse environments, each with specific
hardware constraints. We use supernet training to jointly train multiple
encoders of varying sizes, enabling dynamic model size adjustment to fit
hardware constraints without redundant training. Moreover, we introduce a novel
method called OrthoSoftmax, which applies multiple orthogonal softmax functions
to efficiently identify optimal subnets within the supernet, avoiding
resource-intensive search. This approach also enables more flexible and precise
subnet selection by allowing selection based on various criteria and levels of
granularity. Our results with CTC on Librispeech and TED-LIUM-v2 show that
FLOPs-aware component-wise selection achieves the best overall performance.
With the same number of training updates from one single job, WERs for all
model sizes are comparable to or slightly better than those of individually
trained models. Furthermore, we analyze patterns in the selected components and
reveal interesting insights.

摘要：ASR 系統部署在各種環境中，每個環境都有特定的硬體限制。我們使用超網路訓練來聯合訓練各種大小的編碼器，從而能夠根據硬體限制動態調整模型大小，而無需進行冗餘訓練。此外，我們引入了一種稱為 OrthoSoftmax 的新方法，該方法應用多個正交 softmax 函數來有效識別超網路中的最佳子網路，從而避免資源密集型搜索。這種方法還允許根據各種標準和粒度級別進行選擇，從而實現更靈活和精確的子網路選擇。我們在 Librispeech 和 TED-LIUM-v2 上使用 CTC 獲得的結果表明，考慮 FLOP 的組件級別選擇可實現最佳整體效能。在同一個工作中進行相同次數的訓練更新，所有模型大小的 WER 都與單獨訓練的模型相當或略好。此外，我們分析了所選組件中的模式，並揭示了有趣的見解。

##### **Building Bridges, Not Walls -- Advancing Interpretability by Unifying Feature, Data, and Model Component Attribution**
2501.18887v1 by Shichang Zhang, Tessa Han, Usha Bhalla, Hima Lakkaraju

The increasing complexity of AI systems has made understanding their behavior
a critical challenge. Numerous methods have been developed to attribute model
behavior to three key aspects: input features, training data, and internal
model components. However, these attribution methods are studied and applied
rather independently, resulting in a fragmented landscape of approaches and
terminology. This position paper argues that feature, data, and component
attribution methods share fundamental similarities, and bridging them can
benefit interpretability research. We conduct a detailed analysis of successful
methods across three domains and present a unified view to demonstrate that
these seemingly distinct methods employ similar approaches, such as
perturbations, gradients, and linear approximations, differing primarily in
their perspectives rather than core techniques. Our unified perspective
enhances understanding of existing attribution methods, identifies shared
concepts and challenges, makes this field more accessible to newcomers, and
highlights new directions not only for attribution and interpretability but
also for broader AI research, including model editing, steering, and
regulation.

摘要：隨著人工智慧系統日益複雜，理解其行為已成為一項關鍵挑戰。許多方法已被開發出來，用於將模型行為歸因於三個關鍵面向：輸入特徵、訓練資料和內部模型組件。然而，這些歸因方法的研究和應用相當獨立，導致方法和術語的應用環境支離破碎。本文認為特徵、資料和組件歸因方法有根本上的相似性，而將它們連結起來有助於可解釋性研究。我們對三個領域的成功方法進行詳細分析，並提出一個統一的觀點，以證明這些看似不同的方法採用了類似的途徑，例如擾動、梯度和線性近似，其差異主要在於觀點，而非核心技術。我們統一的觀點增強了對現有歸因方法的理解，找出共同的概念和挑戰，讓這個領域更容易讓新手理解，並不僅標示出歸因和可解釋性的新方向，也標示出更廣泛的人工智慧研究的新方向，包括模型編輯、引導和法規。

##### **UP-VLA: A Unified Understanding and Prediction Model for Embodied Agent**
2501.18867v2 by Jianke Zhang, Yanjiang Guo, Yucheng Hu, Xiaoyu Chen, Xiang Zhu, Jianyu Chen

Recent advancements in Vision-Language-Action (VLA) models have leveraged
pre-trained Vision-Language Models (VLMs) to improve the generalization
capabilities. VLMs, typically pre-trained on vision-language understanding
tasks, provide rich semantic knowledge and reasoning abilities. However, prior
research has shown that VLMs often focus on high-level semantic content and
neglect low-level features, limiting their ability to capture detailed spatial
information and understand physical dynamics. These aspects, which are crucial
for embodied control tasks, remain underexplored in existing pre-training
paradigms. In this paper, we investigate the training paradigm for VLAs, and
introduce \textbf{UP-VLA}, a \textbf{U}nified VLA model training with both
multi-modal \textbf{U}nderstanding and future \textbf{P}rediction objectives,
enhancing both high-level semantic comprehension and low-level spatial
understanding. Experimental results show that UP-VLA achieves a 33% improvement
on the Calvin ABC-D benchmark compared to the previous state-of-the-art method.
Additionally, UP-VLA demonstrates improved success rates in real-world
manipulation tasks, particularly those requiring precise spatial information.

摘要：近期在視覺語言動作 (VLA) 模型的進展中，利用預先訓練好的視覺語言模型 (VLM) 來提升概化能力。VLM 通常預先訓練於視覺語言理解任務，提供豐富的語義知識和推理能力。然而，先前的研究顯示，VLM 通常專注於高層級的語義內容，而忽略低層級特徵，限制了其擷取詳細空間資訊和理解物理動態的能力。這些面向對於具體控制任務至關重要，但在現有的預先訓練範例中仍未獲得充分探討。在本文中，我們探討 VLA 的訓練範例，並介紹 UP-VLA，一個統一的 VLA 模型訓練，同時具備多模態理解和未來預測目標，提升高層級語義理解和低層級空間理解。實驗結果顯示，與先前的最先進方法相比，UP-VLA 在 Calvin ABC-D 基準上獲得了 33% 的提升。此外，UP-VLA 在真實世界操作任務中展現出更高的成功率，特別是那些需要精確空間資訊的任務。

##### **REG: Rectified Gradient Guidance for Conditional Diffusion Models**
2501.18865v1 by Zhengqi Gao, Kaiwen Zha, Tianyuan Zhang, Zihui Xue, Duane S. Boning

Guidance techniques are simple yet effective for improving conditional
generation in diffusion models. Albeit their empirical success, the practical
implementation of guidance diverges significantly from its theoretical
motivation. In this paper, we reconcile this discrepancy by replacing the
scaled marginal distribution target, which we prove theoretically invalid, with
a valid scaled joint distribution objective. Additionally, we show that the
established guidance implementations are approximations to the intractable
optimal solution under no future foresight constraint. Building on these
theoretical insights, we propose rectified gradient guidance (REG), a versatile
enhancement designed to boost the performance of existing guidance methods.
Experiments on 1D and 2D demonstrate that REG provides a better approximation
to the optimal solution than prior guidance techniques, validating the proposed
theoretical framework. Extensive experiments on class-conditional ImageNet and
text-to-image generation tasks show that incorporating REG consistently
improves FID and Inception/CLIP scores across various settings compared to its
absence.

摘要：引導技術對於改善擴散模型中的條件生成簡單卻有效。儘管它們在經驗上取得成功，但引導的實際實作與其理論動機有顯著差異。在本文中，我們透過替換經證明在理論上無效的縮放邊際分布目標，以有效的縮放聯合分布目標，來調和這種差異。此外，我們表明既定的引導實作是在沒有未來預見約束的情況下，對難以處理的最佳解的近似值。根據這些理論見解，我們提出修正梯度引導 (REG)，這是一種旨在提升現有引導方法效能的多功能強化技術。1D 和 2D 的實驗證明，與先前的引導技術相比，REG 提供了對最佳解的更好近似，驗證了所提出的理論架構。對類條件 ImageNet 和文字轉圖像生成任務的廣泛實驗表明，與沒有 REG 相比，加入 REG 在各種設定中持續改善 FID 和 Inception/CLIP 分數。

##### **BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning**
2501.18858v1 by Han Zhong, Yutong Yin, Shenao Zhang, Xiaojun Xu, Yuanxin Liu, Yifei Zuo, Zhihan Liu, Boyi Liu, Sirui Zheng, Hongyi Guo, Liwei Wang, Mingyi Hong, Zhaoran Wang

Large Language Models (LLMs) have demonstrated remarkable capabilities in
complex reasoning tasks, yet generating reliable reasoning processes remains a
significant challenge. We present a unified probabilistic framework that
formalizes LLM reasoning through a novel graphical model incorporating latent
thinking processes and evaluation signals. Within this framework, we introduce
the Bootstrapping Reinforced Thinking Process (BRiTE) algorithm, which works in
two steps. First, it generates high-quality rationales by approximating the
optimal thinking process through reinforcement learning, using a novel reward
shaping mechanism. Second, it enhances the base LLM by maximizing the joint
probability of rationale generation with respect to the model's parameters.
Theoretically, we demonstrate BRiTE's convergence at a rate of $1/T$ with $T$
representing the number of iterations. Empirical evaluations on math and coding
benchmarks demonstrate that our approach consistently improves performance
across different base models without requiring human-annotated thinking
processes. In addition, BRiTE demonstrates superior performance compared to
existing algorithms that bootstrap thinking processes use alternative methods
such as rejection sampling, and can even match or exceed the results achieved
through supervised fine-tuning with human-annotated data.

摘要：大型語言模型 (LLM) 已在複雜推理任務中展現出非凡的能力，但產生可靠的推理過程仍然是一項重大挑戰。我們提出一個統一的機率架構，透過一個結合潛在思考過程和評估訊號的新穎圖形模型，將 LLM 推理形式化。在此架構中，我們引入了自舉強化思考過程 (BRiTE) 演算法，其運作分為兩個步驟。首先，它透過強化學習近似最佳思考過程來產生高品質的基本原理，並使用新穎的獎勵塑造機制。其次，它透過最大化基本原理產生和模型參數相關的聯合機率，來增強基礎 LLM。在理論上，我們證明了 BRiTE 以 $1/T$ 的速率收斂，其中 $T$ 代表迭代次數。在數學和編碼基準上的經驗評估表明，我們的做法持續改善了不同基礎模型的效能，而無需人工標註的思考過程。此外，與使用拒絕採樣等替代方法來自舉思考過程的現有演算法相比，BRiTE 展現出優異的效能，甚至可以達到或超越透過有人工標註資料的監督微調所獲得的結果。

##### **Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities**
2501.18845v1 by Yaping Chai, Haoran Xie, Joe S. Qin

The increasing size and complexity of pre-trained language models have
demonstrated superior performance in many applications, but they usually
require large training datasets to be adequately trained. Insufficient training
sets could unexpectedly make the model overfit and fail to cope with complex
tasks. Large language models (LLMs) trained on extensive corpora have prominent
text generation capabilities, which improve the quality and quantity of data
and play a crucial role in data augmentation. Specifically, distinctive prompt
templates are given in personalised tasks to guide LLMs in generating the
required content. Recent promising retrieval-based techniques further improve
the expressive performance of LLMs in data augmentation by introducing external
knowledge to enable them to produce more grounded-truth data. This survey
provides an in-depth analysis of data augmentation in LLMs, classifying the
techniques into Simple Augmentation, Prompt-based Augmentation, Retrieval-based
Augmentation and Hybrid Augmentation. We summarise the post-processing
approaches in data augmentation, which contributes significantly to refining
the augmented data and enabling the model to filter out unfaithful content.
Then, we provide the common tasks and evaluation metrics. Finally, we introduce
existing challenges and future opportunities that could bring further
improvement to data augmentation.

摘要：隨著預訓練語言模型規模和複雜性的提升，已在許多應用中展現出優異的效能，但它們通常需要龐大的訓練資料集才能獲得充分的訓練。不足的訓練集可能意外地使模型過度擬合，而無法應付複雜的任務。在廣泛語料庫上訓練的大型語言模型 (LLM) 具有突出的文字生成能力，這能提升資料的品質和數量，並在資料擴充中扮演至關重要的角色。具體來說，在個人化任務中給予獨特的提示範本，以引導 LLM 產生所需的內容。最近有前途的基於檢索的技術進一步提升了 LLM 在資料擴充中的表達效能，透過引入外部知識，讓它們能產生更多真實的資料。這份調查提供了 LLM 中資料擴充的深入分析，將技術分類為：簡單擴充、基於提示的擴充、基於檢索的擴充和混合擴充。我們總結了資料擴充中的後處理方法，這對精煉擴充資料和讓模型過濾掉不忠實的內容有顯著的貢獻。接著，我們提供了常見的任務和評估指標。最後，我們介紹了現有的挑戰和未來的機會，這些都有可能進一步改善資料擴充。

##### **Partially Rewriting a Transformer in Natural Language**
2501.18838v1 by Gonçalo Paulo, Nora Belrose

The greatest ambition of mechanistic interpretability is to completely
rewrite deep neural networks in a format that is more amenable to human
understanding, while preserving their behavior and performance. In this paper,
we attempt to partially rewrite a large language model using simple natural
language explanations. We first approximate one of the feedforward networks in
the LLM with a wider MLP with sparsely activating neurons - a transcoder - and
use an automated interpretability pipeline to generate explanations for these
neurons. We then replace the first layer of this sparse MLP with an LLM-based
simulator, which predicts the activation of each neuron given its explanation
and the surrounding context. Finally, we measure the degree to which these
modifications distort the model's final output. With our pipeline, the model's
increase in loss is statistically similar to entirely replacing the sparse MLP
output with the zero vector. We employ the same protocol, this time using a
sparse autoencoder, on the residual stream of the same layer and obtain similar
results. These results suggest that more detailed explanations are needed to
improve performance substantially above the zero ablation baseline.

摘要：機械可解釋性的最大目標是將深度神經網路完全改寫成更適合人類理解的格式，同時保留其行為和效能。在本文中，我們嘗試使用簡單的自然語言解釋部分改寫大型語言模型。我們首先使用具有稀疏激活神經元的較寬 MLP（轉碼器）近似 LLM 中的一個前饋網路，並使用自動化可解釋性管道為這些神經元生成解釋。然後，我們用基於 LLM 的模擬器替換這個稀疏 MLP 的第一層，該模擬器會根據每個神經元的解釋和周圍的上下文預測其激活。最後，我們測量這些修改在多大程度上扭曲了模型的最終輸出。使用我們的管道，模型損失的增加在統計上與將稀疏 MLP 輸出完全替換為零向量相似。我們使用相同的協定，這次在同一層的殘差串流上使用稀疏自動編碼器，並獲得類似的結果。這些結果表明，需要更詳細的解釋才能將效能顯著提高到零消融基準線之上。

##### **Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming**
2501.18837v1 by Mrinank Sharma, Meg Tong, Jesse Mu, Jerry Wei, Jorrit Kruthoff, Scott Goodfriend, Euan Ong, Alwin Peng, Raj Agarwal, Cem Anil, Amanda Askell, Nathan Bailey, Joe Benton, Emma Bluemke, Samuel R. Bowman, Eric Christiansen, Hoagy Cunningham, Andy Dau, Anjali Gopal, Rob Gilson, Logan Graham, Logan Howard, Nimit Kalra, Taesung Lee, Kevin Lin, Peter Lofgren, Francesco Mosconi, Clare O'Hara, Catherine Olsson, Linda Petrini, Samir Rajani, Nikhil Saxena, Alex Silverstein, Tanya Singh, Theodore Sumers, Leonard Tang, Kevin K. Troy, Constantin Weisser, Ruiqi Zhong, Giulio Zhou, Jan Leike, Jared Kaplan, Ethan Perez

Large language models (LLMs) are vulnerable to universal jailbreaks-prompting
strategies that systematically bypass model safeguards and enable users to
carry out harmful processes that require many model interactions, like
manufacturing illegal substances at scale. To defend against these attacks, we
introduce Constitutional Classifiers: safeguards trained on synthetic data,
generated by prompting LLMs with natural language rules (i.e., a constitution)
specifying permitted and restricted content. In over 3,000 estimated hours of
red teaming, no red teamer found a universal jailbreak that could extract
information from an early classifier-guarded LLM at a similar level of detail
to an unguarded model across most target queries. On automated evaluations,
enhanced classifiers demonstrated robust defense against held-out
domain-specific jailbreaks. These classifiers also maintain deployment
viability, with an absolute 0.38% increase in production-traffic refusals and a
23.7% inference overhead. Our work demonstrates that defending against
universal jailbreaks while maintaining practical deployment viability is
tractable.

摘要：大型語言模型 (LLM) 容易受到通用越獄的影響，這些策略系統性地繞過模型防護措施，讓使用者得以執行需要許多模型互動的有害程序，例如大規模製造非法物質。為了防禦這些攻擊，我們引入了憲法分類器：在合成資料上訓練的防護措施，透過提示 LLM 自然語言規則（即憲法）來產生，說明允許和限制的內容。在超過 3,000 小時估計的紅隊演練中，沒有紅隊成員找到一個通用越獄，能夠從早期分類器保護的 LLM 中提取資訊，其詳細程度與大多數目標查詢中未受保護的模型類似。在自動化評估中，增強的分類器展現了對特定領域越獄的強大防禦力。這些分類器也維持部署可行性，生產流量拒絕率絕對增加 0.38%，推論負擔增加 23.7%。我們的研究證明，在維持實際部署可行性的同時防禦通用越獄是可行的。

##### **Pitfalls of defacing whole-head MRI: re-identification risk with diffusion models and compromised research potential**
2501.18834v1 by Chenyu Gao, Kaiwen Xu, Michael E. Kim, Lianrui Zuo, Zhiyuan Li, Derek B. Archer, Timothy J. Hohman, Ann Zenobia Moore, Luigi Ferrucci, Lori L. Beason-Held, Susan M. Resnick, Christos Davatzikos, Jerry L. Prince, Bennett A. Landman

Defacing is often applied to head magnetic resonance image (MRI) datasets
prior to public release to address privacy concerns. The alteration of facial
and nearby voxels has provoked discussions about the true capability of these
techniques to ensure privacy as well as their impact on downstream tasks. With
advancements in deep generative models, the extent to which defacing can
protect privacy is uncertain. Additionally, while the altered voxels are known
to contain valuable anatomical information, their potential to support research
beyond the anatomical regions directly affected by defacing remains uncertain.
To evaluate these considerations, we develop a refacing pipeline that recovers
faces in defaced head MRIs using cascaded diffusion probabilistic models
(DPMs). The DPMs are trained on images from 180 subjects and tested on images
from 484 unseen subjects, 469 of whom are from a different dataset. To assess
whether the altered voxels in defacing contain universally useful information,
we also predict computed tomography (CT)-derived skeletal muscle radiodensity
from facial voxels in both defaced and original MRIs. The results show that
DPMs can generate high-fidelity faces that resemble the original faces from
defaced images, with surface distances to the original faces significantly
smaller than those of a population average face (p < 0.05). This performance
also generalizes well to previously unseen datasets. For skeletal muscle
radiodensity predictions, using defaced images results in significantly weaker
Spearman's rank correlation coefficients compared to using original images (p <
10-4). For shin muscle, the correlation is statistically significant (p < 0.05)
when using original images but not statistically significant (p > 0.05) when
any defacing method is applied, suggesting that defacing might not only fail to
protect privacy but also eliminate valuable information.

摘要：<paragraph>在公開發布前，通常會對頭部磁振造影 (MRI) 資料集進行去識別化處理，以解決隱私問題。面部和附近體素的變更引發了關於這些技術確保隱私的真正能力及其對下游任務的影響的討論。隨著深度生成模型的進步，去識別化在多大程度上可以保護隱私尚不確定。此外，儘管已知被改變的體素包含有價值的解剖學資訊，但它們在支持超越去識別化直接影響的解剖區域的研究方面的潛力仍不確定。為了評估這些考量，我們開發了一個重新識別管道，使用串聯擴散機率模型 (DPM) 在去識別化的頭部 MRI 中恢復面部。DPM 在來自 180 個受試者的影像上進行訓練，並在來自 484 個未見受試者的影像上進行測試，其中 469 個來自不同的資料集。為了評估去識別化中被改變的體素是否包含普遍有用的資訊，我們也從去識別化和原始 MRI 中的面部體素預測電腦斷層掃描 (CT) 衍生的骨骼肌放射密度。結果顯示，DPM 可以生成高保真面部，這些面部與去識別化影像中的原始面部相似，與原始面部的表面距離顯著小於一般人臉 (p < 0.05)。此效能也很好地概括到先前未見的資料集。對於骨骼肌放射密度預測，與使用原始影像相比，使用去識別化影像會導致顯著較弱的斯皮爾曼等級相關係數 (p < 10-4)。對於小腿肌肉，在使用原始影像時，相關性具有統計顯著性 (p < 0.05)，但當應用任何去識別化方法時，相關性沒有統計顯著性 (p > 0.05)，這表明去識別化不僅可能無法保護隱私，還會消除有價值的資訊。</paragraph>

##### **Structural Embedding Projection for Contextual Large Language Model Inference**
2501.18826v1 by Vincent Enoasmo, Cedric Featherstonehaugh, Xavier Konstantinopoulos, Zacharias Huntington

Structured embedding transformations offer a promising approach for enhancing
the efficiency and coherence of language model inference. The introduction of
Structural Embedding Projection (SEP) provides a mechanism for refining token
representations through projection matrices that integrate hierarchical and
relational dependencies. The mathematical formulation of SEP enables embedding
spaces to capture structured contextual relationships, thereby improving
semantic fidelity without significantly increasing computational overhead.
Experimental evaluations conducted on a range of linguistic datasets revealed
that SEP contributed to reductions in perplexity and enhanced contextual
coherence, demonstrating its potential to refine language model outputs.
Computational efficiency assessments highlighted variations across different
datasets, suggesting that the integration of structured embeddings introduced
dataset-dependent trade-offs between inference speed and representational
richness. The qualitative analysis of generated responses indicated that SEP
enhanced narrative consistency and topic alignment, leading to improved fluency
in multi-sentence text generation. The modifications to embedding layers
required precise optimization to ensure stable training dynamics, as the
introduction of structured transformations altered the traditional
representation-learning process. The architectural adjustments necessary for
SEP implementation influenced inference latency and memory consumption,
requiring a balance between efficiency gains and additional processing demands.
The impact of SEP on lexical diversity suggested that embedding modifications
influenced the model's vocabulary usage, reflecting a more context-aware
selection of generated tokens.

摘要：結構化嵌入轉換提供了一種有前途的方法，用於增強語言模型推理的效率和一致性。結構嵌入投影 (SEP) 的引入提供了一種通過投影矩陣改進令牌表示的機制，該矩陣整合了層級和關係依賴性。SEP 的數學公式使嵌入空間能夠捕捉結構化上下文關係，從而提高語義保真度，而不會顯著增加計算開銷。在各種語言數據集上進行的實驗評估表明，SEP 有助於降低困惑度並增強上下文一致性，展示了其改進語言模型輸出的潛力。計算效率評估突出了不同數據集之間的差異，表明結構化嵌入的整合引入了推理速度和表示豐富性之間依賴於數據集的權衡。對生成響應的定性分析表明，SEP 增強了敘事一致性和主題對齊，從而提高了多句文本生成的流暢性。嵌入層的修改需要精確的優化，以確保穩定的訓練動態，因為結構化轉換的引入改變了傳統的表示學習過程。SEP 實施所需的架構調整影響了推理延遲和內存消耗，需要在效率提升和額外的處理需求之間取得平衡。SEP 對詞彙多樣性的影響表明，嵌入修改影響了模型的詞彙使用，反映了對生成令牌更具上下文感知的選擇。

##### **Memory-Efficient Fine-Tuning of Transformers via Token Selection**
2501.18824v1 by Antoine Simoulin, Namyong Park, Xiaoyi Liu, Grey Yang

Fine-tuning provides an effective means to specialize pre-trained models for
various downstream tasks. However, fine-tuning often incurs high memory
overhead, especially for large transformer-based models, such as LLMs. While
existing methods may reduce certain parts of the memory required for
fine-tuning, they still require caching all intermediate activations computed
in the forward pass to update weights during the backward pass. In this work,
we develop TokenTune, a method to reduce memory usage, specifically the memory
to store intermediate activations, in the fine-tuning of transformer-based
models. During the backward pass, TokenTune approximates the gradient
computation by backpropagating through just a subset of input tokens. Thus,
with TokenTune, only a subset of intermediate activations are cached during the
forward pass. Also, TokenTune can be easily combined with existing methods like
LoRA, further reducing the memory cost. We evaluate our approach on pre-trained
transformer models with up to billions of parameters, considering the
performance on multiple downstream tasks such as text classification and
question answering in a few-shot learning setup. Overall, TokenTune achieves
performance on par with full fine-tuning or representative memory-efficient
fine-tuning methods, while greatly reducing the memory footprint, especially
when combined with other methods with complementary memory reduction
mechanisms. We hope that our approach will facilitate the fine-tuning of large
transformers, in specializing them for specific domains or co-training them
with other neural components from a larger system. Our code is available at
https://github.com/facebookresearch/tokentune.

摘要：微调提供了一种有效的方法，可针对各种下游任务专门化预训练模型。然而，微调通常会产生较高的内存开销，特别是对于基于大型转换器的模型，例如 LLM。虽然现有方法可以减少微调所需的某些内存部分，但它们仍然需要缓存正向传递中计算的所有中间激活，以便在反向传递期间更新权重。在这项工作中，我们开发了 TokenTune，这是一种减少内存使用量的方法，特别是存储中间激活的内存，用于基于转换器的模型的微调。在反向传递期间，TokenTune 通过仅反向传播输入令牌的子集来逼近梯度计算。因此，使用 TokenTune，仅在正向传递期间缓存中间激活的子集。此外，TokenTune 可以轻松地与现有方法（如 LoRA）相结合，进一步降低内存成本。我们对拥有数十亿个参数的预训练转换器模型评估了我们的方法，考虑了在少数镜头学习设置中对文本分类和问题解答等多个下游任务的性能。总体而言，TokenTune 在与完全微调或具有代表性的节能微调方法相当的性能上取得了成就，同时大幅减少了内存占用，尤其是在与其他具有互补内存减少机制的方法相结合时。我们希望我们的方法将有助于对大型转换器进行微调，使它们专门用于特定领域或与来自更大系统中的其他神经组件进行联合训练。我们的代码可在 https://github.com/facebookresearch/tokentune 中获得。

##### **An Optimal Cascade Feature-Level Spatiotemporal Fusion Strategy for Anomaly Detection in CAN Bus**
2501.18821v1 by Mohammad Fatahi, Danial Sadrian Zadeh, Benyamin Ghojogh, Behzad Moshiri, Otman Basir

Autonomous vehicles represent a revolutionary advancement driven by the
integration of artificial intelligence within intelligent transportation
systems. However, they remain vulnerable due to the absence of robust security
mechanisms in the Controller Area Network (CAN) bus. In order to mitigate the
security issue, many machine learning models and strategies have been proposed,
which primarily focus on a subset of dominant patterns of anomalies and lack
rigorous evaluation in terms of reliability and robustness. Therefore, to
address the limitations of previous works and mitigate the security
vulnerability in CAN bus, the current study develops a model based on the
intrinsic nature of the problem to cover all dominant patterns of anomalies. To
achieve this, a cascade feature-level fusion strategy optimized by a
two-parameter genetic algorithm is proposed to combine temporal and spatial
information. Subsequently, the model is evaluated using a paired t-test to
ensure reliability and robustness. Finally, a comprehensive comparative
analysis conducted on two widely used datasets advocates that the proposed
model outperforms other models and achieves superior accuracy and F1-score,
demonstrating the best performance among all models presented to date.

摘要：自動駕駛車輛代表著一項革命性的進展，它是由在智慧運輸系統中整合人工智慧所推動的。然而，由於控制器區域網路 (CAN) 總線中缺乏強大的安全機制，它們仍然容易受到攻擊。為了減輕安全問題，已經提出了許多機器學習模型和策略，這些模型和策略主要關注異常的主要模式子集，並且缺乏在可靠性和穩健性方面的嚴格評估。因此，為了解決先前工作的限制並減輕 CAN 總線中的安全漏洞，目前的研究基於問題的內在性質開發了一個模型，以涵蓋所有主要的異常模式。為此，提出了一個由兩參數遺傳演算法最佳化的串聯特徵層級融合策略，以結合時間和空間資訊。隨後，使用配對 t 檢定評估模型，以確保可靠性和穩健性。最後，在兩個廣泛使用的資料集上進行的全面比較分析證明，所提出的模型優於其他模型，並實現了更高的準確度和 F1 分數，展示了迄今為止提出的所有模型中最佳的效能。

##### **Bridging the Reasoning Gap: Small LLMs Can Plan with Generalised Strategies**
2501.18817v1 by Andrey Borro, Patricia J Riddle, Michael W Barley, Michael J Witbrock

Recent advancements in the reasoning skills of Large Language Models (LLMs)
demonstrate an increase in the ability of LLMs to solve simple planning tasks.
However, as long as the driving force behind improved reasoning capability is
the size and complexity of the model, the financial and computational costs
associated with running them will also increase. This trend raises questions
about continued accessibility and whether these improvements will increase at
the same pace as models continue to grow in size and expense. We propose two
approaches to enhance the reasoning ability of less resource-intensive LLMs.
(1) Provide them with a generalised strategy for solving tasks within a given
domain, generated by a more resource-intensive LLM. (2) Exploit their
cost-effectiveness by iteratively prompting these models to correct errors in
their proposed solutions. Our empirical results from planning and mathematical
reasoning tasks demonstrate that these methods improve the performance of less
resource-intensive LLMs to levels comparable with their more resource-intensive
counterparts, at a fraction of the cost. Additionally, we show that the
utilisation of generalised strategies in our experiments reduced the cost of
the less resource-intensive model by nearly 30 percent on average.

摘要：大型語言模型 (LLM) 推理技能的最新進展
展示了 LLM 解決簡單規劃任務的能力提升。
然而，只要改進推理能力的驅動力是
模型的大小和複雜性，運行它們的財務和計算成本也會增加。這個趨勢引發了關於持續可及性的問題，以及這些改進是否會隨著模型規模和成本的持續增長而以相同的步伐增加。我們提出了兩種方法來增強資源密集度較低 LLM 的推理能力。
(1) 為他們提供在特定領域內解決任務的概括策略，由資源密集度較高的 LLM 生成。(2) 利用他們的成本效益，反覆提示這些模型糾正其提出的解決方案中的錯誤。我們從規劃和數學推理任務中獲得的實證結果表明，這些方法將資源密集度較低 LLM 的性能提升到與資源密集度較高的同類產品相當的水平，成本卻只是後者的零頭。此外，我們展示了在我們的實驗中利用概括策略平均將資源密集度較低模型的成本降低了近 30%。

##### **Large Language Models as Common-Sense Heuristics**
2501.18816v1 by Andrey Borro, Patricia J Riddle, Michael W Barley, Michael J Witbrock

While systems designed for solving planning tasks vastly outperform Large
Language Models (LLMs) in this domain, they usually discard the rich semantic
information embedded within task descriptions. In contrast, LLMs possess
parametrised knowledge across a wide range of topics, enabling them to leverage
the natural language descriptions of planning tasks in their solutions.
However, current research in this direction faces challenges in generating
correct and executable plans. Furthermore, these approaches depend on the LLM
to output solutions in an intermediate language, which must be translated into
the representation language of the planning task. We introduce a novel planning
method, which leverages the parametrised knowledge of LLMs by using their
output as a heuristic for Hill-Climbing Search. This approach is further
enhanced by prompting the LLM to generate a solution estimate to guide the
search. Our method outperforms the task success rate of similar systems within
a common household environment by 22 percentage points, with consistently
executable plans. All actions are encoded in their original representation,
demonstrating that strong results can be achieved without an intermediate
language, thus eliminating the need for a translation step.

摘要：儘管為了解決規劃任務而設計的系統在這個領域中大大優於大型語言模型 (LLM)，但它們通常會捨棄任務描述中嵌入的豐富語義資訊。相比之下，LLM 擁有跨越廣泛主題的參數化知識，使它們能夠在解決方案中利用規劃任務的自然語言描述。然而，目前朝這個方向進行的研究在產生正確且可執行的計畫時會面臨挑戰。此外，這些方法依賴於 LLM 以中間語言輸出解決方案，而該解決方案必須轉換為規劃任務的表示語言。我們引入了一種新穎的規劃方法，透過使用 LLM 的輸出作為爬山搜尋的啟發式方法來利用 LLM 的參數化知識。這種方法進一步透過提示 LLM 產生解決方案估計值來引導搜尋而得到加強。我們的 method 在常見家庭環境中，以始終可執行的計畫將類似系統的任務成功率提高了 22 個百分點。所有動作都以其原始表示進行編碼，證明無需中間語言也能獲得強大的結果，從而消除了轉換步驟的需要。

##### **An Adversarial Approach to Register Extreme Resolution Tissue Cleared 3D Brain Images**
2501.18815v1 by Abdullah Naziba, Clinton Fookes, Dimitri Perrin

We developed a generative patch based 3D image registration model that can
register very high resolution images obtained from a biochemical process name
tissue clearing. Tissue clearing process removes lipids and fats from the
tissue and make the tissue transparent. When cleared tissues are imaged with
Light-sheet fluorescent microscopy, the resulting images give a clear window to
the cellular activities and dynamics inside the tissue.Thus the images obtained
are very rich with cellular information and hence their resolution is extremely
high (eg .2560x2160x676). Analyzing images with such high resolution is a
difficult task for any image analysis pipeline.Image registration is a common
step in image analysis pipeline when comparison between images are required.
Traditional image registration methods fail to register images with such
extant. In this paper we addressed this very high resolution image registration
issue by proposing a patch-based generative network named InvGAN. Our proposed
network can register very high resolution tissue cleared images. The tissue
cleared dataset used in this paper are obtained from a tissue clearing protocol
named CUBIC. We compared our method both with traditional and deep-learning
based registration methods.Two different versions of CUBIC dataset are used,
representing two different resolutions 25% and 100% respectively. Experiments
on two different resolutions clearly show the impact of resolution on the
registration quality. At 25% resolution, our method achieves comparable
registration accuracy with very short time (7 minutes approximately). At 100%
resolution, most of the traditional registration methods fail except Elastix
registration tool.Elastix takes 28 hours to register where proposed InvGAN
takes only 10 minutes.

摘要：<paragraph>我們開發了一個基於生成性補丁的 3D 影像配準模型，可以配準從名為組織透明化的生化過程中獲得的極高解析度影像。組織透明化過程會去除組織中的脂質和脂肪，並使組織透明。當以光片螢光顯微鏡對透明化組織進行成像時，產生的影像會提供一個清晰的視窗，以觀察組織內部的細胞活動和動力。因此，獲得的影像非常豐富細胞資訊，因此其解析度極高 (例如 .2560x2160x676)。使用如此高解析度分析影像對任何影像分析管道而言都是一項艱鉅的任務。影像配準是影像分析管道中的一個常見步驟，當需要比較影像時。傳統的影像配準方法無法配準具有如此程度的影像。在本文中，我們透過提出名為 InvGAN 的基於補丁的生成網路，來解決這個極高解析度影像配準問題。我們提出的網路可以配準極高解析度的組織透明化影像。本文中使用的組織透明化資料集是從名為 CUBIC 的組織透明化協定中獲得的。我們將我們的方法與傳統和基於深度學習的配準方法進行比較。使用了兩個不同版本的 CUBIC 資料集，分別代表兩個不同的解析度 25% 和 100%。在兩個不同解析度上進行的實驗清楚地顯示了解析度對配準品質的影響。在 25% 解析度下，我們的的方法在極短的時間內 (大約 7 分鐘) 達到了相當的配準精度。在 100% 解析度下，除了 Elastix 配準工具外，大多數傳統配準方法都失敗了。Elastix 花費 28 小時進行配準，而所提出的 InvGAN 只花了 10 分鐘。</paragraph>

##### **Every Image Listens, Every Image Dances: Music-Driven Image Animation**
2501.18801v1 by Zhikang Dong, Weituo Hao, Ju-Chiang Wang, Peng Zhang, Pawel Polak

Image animation has become a promising area in multimodal research, with a
focus on generating videos from reference images. While prior work has largely
emphasized generic video generation guided by text, music-driven dance video
generation remains underexplored. In this paper, we introduce MuseDance, an
innovative end-to-end model that animates reference images using both music and
text inputs. This dual input enables MuseDance to generate personalized videos
that follow text descriptions and synchronize character movements with the
music. Unlike existing approaches, MuseDance eliminates the need for complex
motion guidance inputs, such as pose or depth sequences, making flexible and
creative video generation accessible to users of all expertise levels. To
advance research in this field, we present a new multimodal dataset comprising
2,904 dance videos with corresponding background music and text descriptions.
Our approach leverages diffusion-based methods to achieve robust
generalization, precise control, and temporal consistency, setting a new
baseline for the music-driven image animation task.

摘要：影像動畫已成為多模態研究中一個有前景的領域，重點在於從參考影像中產生影片。儘管先前的研究在很大程度上強調由文字引導的通用影片產生，但由音樂驅動的舞蹈影片產生仍未被充分探討。在本文中，我們介紹了 MuseDance，一個創新的端到端模型，它使用音樂和文字輸入對參考影像進行動畫處理。這種雙重輸入使 MuseDance 能夠產生符合文字描述並將角色動作與音樂同步的個人化影片。與現有方法不同，MuseDance 消除了對複雜動作指導輸入（例如姿勢或深度序列）的需求，讓各個專業水準的使用者都能輕鬆進行靈活且有創意的影片產生。為了推進此領域的研究，我們提出了包含 2,904 個舞蹈影片的新多模態資料集，其中包含對應的背景音樂和文字描述。我們的做法利用基於擴散的方法來實現穩健的泛化、精確控制和時間一致性，為由音樂驅動的影像動畫任務設定了新的基準。

##### **Compositional Generalization Requires More Than Disentangled Representations**
2501.18797v1 by Qiyao Liang, Daoyuan Qian, Liu Ziyin, Ila Fiete

Composition-the ability to generate myriad variations from finite means-is
believed to underlie powerful generalization. However, compositional
generalization remains a key challenge for deep learning. A widely held
assumption is that learning disentangled (factorized) representations naturally
supports this kind of extrapolation. Yet, empirical results are mixed, with
many generative models failing to recognize and compose factors to generate
out-of-distribution (OOD) samples. In this work, we investigate a controlled 2D
Gaussian "bump" generation task, demonstrating that standard generative
architectures fail in OOD regions when training with partial data, even when
supplied with fully disentangled $(x, y)$ coordinates, re-entangling them
through subsequent layers. By examining the model's learned kernels and
manifold geometry, we show that this failure reflects a "memorization" strategy
for generation through the superposition of training data rather than by
combining the true factorized features. We show that models forced-through
architectural modifications with regularization or curated training data-to
create disentangled representations in the full-dimensional representational
(pixel) space can be highly data-efficient and effective at learning to compose
in OOD regions. These findings underscore that bottlenecks with
factorized/disentangled representations in an abstract representation are
insufficient: the model must actively maintain or induce factorization directly
in the representational space in order to achieve robust compositional
generalization.

摘要：組合性——從有限手段產生無數變化的能力——被認為是強大泛化的基礎。然而，組合泛化仍然是深度學習的一項關鍵挑戰。一個廣泛的假設是學習解開（分解）表示自然地支持這種外推。然而，經驗結果好壞參半，許多生成模型無法識別和組合因子來生成分布外 (OOD) 樣本。在這項工作中，我們研究了一個受控的 2D 高斯「凸起」生成任務，證明了標準生成架構在使用部分數據訓練時會在 OOD 區域中失敗，即使提供了完全解開的 $(x, y)$ 坐標，也會通過後續層重新糾纏它們。通過檢查模型學習的核和流形幾何，我們表明這種失敗反映了通過訓練數據的疊加而不是通過組合真實分解特徵來生成「記憶」策略。我們表明，通過架構修改強制通過正則化或策劃訓練數據的模型——在全維表示（像素）空間中創建解開的表示——在學習 OOD 區域中的組合方面可以具有很高的數據效率和有效性。這些發現強調，抽象表示中具有分解/解開表示的瓶頸是不夠的：模型必須主動維護或直接在表示空間中誘導分解，才能實現穩健的組合泛化。

##### **Rope to Nope and Back Again: A New Hybrid Attention Strategy**
2501.18795v1 by Bowen Yang, Bharat Venkitesh, Dwarak Talupuru, Hangyu Lin, David Cairuz, Phil Blunsom, Acyr Locatelli

Long-context large language models (LLMs) have achieved remarkable
advancements, driven by techniques like Rotary Position Embedding (RoPE) (Su et
al., 2023) and its extensions (Chen et al., 2023; Liu et al., 2024c; Peng et
al., 2023). By adjusting RoPE parameters and incorporating training data with
extended contexts, we can train performant models with considerably longer
input sequences. However, existing RoPE-based methods exhibit performance
limitations when applied to extended context lengths. This paper presents a
comprehensive analysis of various attention mechanisms, including RoPE, No
Positional Embedding (NoPE), and Query-Key Normalization (QK-Norm), identifying
their strengths and shortcomings in long-context modeling. Our investigation
identifies distinctive attention patterns in these methods and highlights their
impact on long-context performance, providing valuable insights for
architectural design. Building on these findings, we propose a novel
architectural based on a hybrid attention mechanism that not only surpasses
conventional RoPE-based transformer models in long context tasks but also
achieves competitive performance on benchmarks requiring shorter context
lengths.

摘要：長文本大型語言模型 (LLM) 已取得顯著進展，這歸功於旋轉位置嵌入 (RoPE) (Su 等人，2023 年) 及其延伸技術 (Chen 等人，2023 年；Liu 等人，2024c；Peng 等人，2023 年)。透過調整 RoPE 參數並結合具有延伸文本的訓練資料，我們可以訓練出具有相當長輸入序列的效能模型。然而，現有的基於 RoPE 的方法在應用於延伸文本長度時會出現效能限制。本文針對各種注意力機制進行全面分析，包括 RoPE、無位置嵌入 (NoPE) 和查詢鍵正規化 (QK-Norm)，找出它們在長文本建模中的優點和缺點。我們的調查找出這些方法中獨特的注意力模式，並強調它們對長文本效能的影響，為架構設計提供寶貴的見解。根據這些發現，我們提出一個新穎的架構，基於一種混合注意力機制，它不僅在長文本任務中超越傳統的基於 RoPE 的 Transformer 模型，而且在需要較短文本長度的基準測試中也取得競爭力的效能。

##### **Survey and Improvement Strategies for Gene Prioritization with Large Language Models**
2501.18794v1 by Matthew Neeley, Guantong Qi, Guanchu Wang, Ruixiang Tang, Dongxue Mao, Chaozhong Liu, Sasidhar Pasupuleti, Bo Yuan, Fan Xia, Pengfei Liu, Zhandong Liu, Xia Hu

Rare diseases are challenging to diagnose due to limited patient data and
genetic diversity. Despite advances in variant prioritization, many cases
remain undiagnosed. While large language models (LLMs) have performed well in
medical exams, their effectiveness in diagnosing rare genetic diseases has not
been assessed. To identify causal genes, we benchmarked various LLMs for gene
prioritization. Using multi-agent and Human Phenotype Ontology (HPO)
classification, we categorized patients based on phenotypes and solvability
levels. As gene set size increased, LLM performance deteriorated, so we used a
divide-and-conquer strategy to break the task into smaller subsets. At
baseline, GPT-4 outperformed other LLMs, achieving near 30% accuracy in ranking
causal genes correctly. The multi-agent and HPO approaches helped distinguish
confidently solved cases from challenging ones, highlighting the importance of
known gene-phenotype associations and phenotype specificity. We found that
cases with specific phenotypes or clear associations were more accurately
solved. However, we observed biases toward well-studied genes and input order
sensitivity, which hindered gene prioritization. Our divide-and-conquer
strategy improved accuracy by overcoming these biases. By utilizing HPO
classification, novel multi-agent techniques, and our LLM strategy, we improved
causal gene identification accuracy compared to our baseline evaluation. This
approach streamlines rare disease diagnosis, facilitates reanalysis of unsolved
cases, and accelerates gene discovery, supporting the development of targeted
diagnostics and therapies.

摘要：罕見疾病由於患者數據有限和遺傳多樣性，診斷起來具有挑戰性。儘管變異優先級排序技術進步，但許多病例仍未得到診斷。儘管大型語言模型 (LLM) 在醫學考試中表現良好，但它們在診斷罕見遺傳疾病方面的有效性尚未得到評估。為了識別致病基因，我們對各種 LLM 進行了基因優先級排序基準測試。使用多智能體和人類表型本体 (HPO) 分類，我們根據表型和可解決性對患者進行了分類。隨著基因組大小的增加，LLM 性能下降，因此我們使用分而治之策略將任務分解為更小的子集。在基線中，GPT-4 優於其他 LLM，在正確排序致病基因方面達到近 30% 的準確度。多智能體和 HPO 方法有助於區分解決有信心的病例和具有挑戰性的病例，強調已知基因-表型關聯和表型特異性的重要性。我們發現具有特定表型或明確關聯的病例得到更準確的解決。然而，我們觀察到對研究充分的基因和輸入順序敏感性的偏差，這阻礙了基因優先級排序。我們的分而治之策略通過克服這些偏差來提高準確性。通過利用 HPO 分類、新穎的多智能體技術和我們的 LLM 策略，我們與我們的基線評估相比提高了致病基因識別準確性。這種方法簡化了罕見疾病的診斷，促進了對未解決病例的重新分析，並加速了基因發現，支持了靶向診斷和治療的開發。

##### **OT-Transformer: A Continuous-time Transformer Architecture with Optimal Transport Regularization**
2501.18793v1 by Kelvin Kan, Xingjian Li, Stanley Osher

Transformers have achieved state-of-the-art performance in numerous tasks. In
this paper, we propose a continuous-time formulation of transformers.
Specifically, we consider a dynamical system whose governing equation is
parametrized by transformer blocks. We leverage optimal transport theory to
regularize the training problem, which enhances stability in training and
improves generalization of the resulting model. Moreover, we demonstrate in
theory that this regularization is necessary as it promotes uniqueness and
regularity of solutions. Our model is flexible in that almost any existing
transformer architectures can be adopted to construct the dynamical system with
only slight modifications to the existing code. We perform extensive numerical
experiments on tasks motivated by natural language processing, image
classification, and point cloud classification. Our experimental results show
that the proposed method improves the performance of its discrete counterpart
and outperforms relevant comparing models.

摘要：Transformer在許多任務中都達到了最先進的表現。在本文中，我們提出Transformer的連續時間公式。具體來說，我們考慮一個動態系統，其控制方程式由Transformer塊參數化。我們利用最優傳輸理論來規範訓練問題，這增強了訓練的穩定性，並改進了所得模型的泛化能力。此外，我們在理論上證明了這種規範化是必要的，因為它促进了解的唯一性和規律性。我們的模型很靈活，因為幾乎任何現有的Transformer架構都可以採用來構建動態系統，而現有代碼只需稍作修改。我們對自然語言處理、圖像分類和點雲分類等任務進行了廣泛的數值實驗。我們的實驗結果表明，所提出的方法改進了其離散對應項的性能，並且優於相關的比較模型。

##### **LLM-Generated Heuristics for AI Planning: Do We Even Need Domain-Independence Anymore?**
2501.18784v1 by Alexander Tuisov, Yonatan Vernik, Alexander Shleyfman

Domain-independent heuristics have long been a cornerstone of AI planning,
offering general solutions applicable across a wide range of tasks without
requiring domain-specific engineering. However, the advent of large language
models (LLMs) presents an opportunity to generate heuristics tailored to
specific planning problems, potentially challenging the necessity of domain
independence as a strict design principle. In this paper, we explore the use of
LLMs to automatically derive planning heuristics from task descriptions
represented as successor generators and goal tests written in general purpose
programming language. We investigate the trade-offs between domain-specific
LLM-generated heuristics and traditional domain-independent methods in terms of
computational efficiency and explainability. Our experiments demonstrate that
LLMs can create heuristics that achieve state-of-the-art performance on some
standard IPC domains, as well as their ability to solve problems that lack an
adequate Planning Domain Definition Language ({\sc pddl}) representation. We
discuss whether these results signify a paradigm shift and how they can
complement existing approaches.

摘要：領域無關的啟發式方法一直是 AI 規劃的基石，提供適用於各種任務的通用解決方案，而無需領域特定的工程。然而，大型語言模型 (LLM) 的出現提供了一個機會來生成針對特定規劃問題量身定制的啟發式方法，這可能會挑戰領域獨立性作為嚴格設計原則的必要性。在本文中，我們探討了使用 LLM 從後繼生成器和目標測試中自動推導規劃啟發式方法，這些後繼生成器和目標測試是用通用程式語言編寫的。我們研究了領域特定的 LLM 生成的啟發式方法和傳統的領域無關方法在計算效率和可解釋性方面的取捨。我們的實驗表明，LLM 可以建立啟發式方法，在一些標準 IPC 領域上實現最先進的效能，以及它們解決缺少適當規劃領域定義語言 ({\sc pddl}) 表示的問題的能力。我們討論這些結果是否表示範例轉移，以及它們如何補充現有方法。

##### **Overestimation in LLM Evaluation: A Controlled Large-Scale Study on Data Contamination's Impact on Machine Translation**
2501.18771v1 by Muhammed Yusuf Kocyigit, Eleftheria Briakou, Daniel Deutsch, Jiaming Luo, Colin Cherry, Markus Freitag

Data contamination -- the accidental consumption of evaluation examples
within the pre-training data -- can undermine the validity of evaluation
benchmarks. In this paper, we present a rigorous analysis of the effects of
contamination on language models at 1B and 8B scales on the machine translation
task. Starting from a carefully decontaminated train-test split, we
systematically introduce contamination at various stages, scales, and data
formats to isolate its effect and measure its impact on performance metrics.
Our experiments reveal that contamination with both source and target
substantially inflates BLEU scores, and this inflation is 2.5 times larger (up
to 30 BLEU points) for 8B compared to 1B models. In contrast, source-only and
target-only contamination generally produce smaller, less consistent
over-estimations. Finally, we study how the temporal distribution and frequency
of contaminated samples influence performance over-estimation across languages
with varying degrees of data resources.

摘要：資料污染 -- 在預訓練資料中意外使用評估範例 -- 可能會破壞評估基準的效度。在本文中，我們提出對 1B 和 8B 規模語言模型在機器翻譯任務中受到污染影響的嚴謹分析。從仔細去汙的訓練測試分割開始，我們系統性地引進不同階段、規模和資料格式的污染，以孤立其影響並衡量其對效能指標的衝擊。我們的實驗顯示，來源和目標的污染都會大幅提升 BLEU 分數，而 8B 模型的這種提升比 1B 模型大了 2.5 倍（最多 30 個 BLEU 點）。相較之下，只有來源或只有目標的污染通常會產生較小、較不一致的高估。最後，我們研究受污染樣本的時間分佈和頻率如何影響不同資料資源程度的語言效能高估。

##### **Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization**
2501.18768v1 by Michael S. Yao, James C. Gee, Osbert Bastani

The goal of offline model-based optimization (MBO) is to propose new designs
that maximize a reward function given only an offline dataset. However, an
important desiderata is to also propose a diverse set of final candidates that
capture many optimal and near-optimal design configurations. We propose
Diversity in Adversarial Model-based Optimization (DynAMO) as a novel method to
introduce design diversity as an explicit objective into any MBO problem. Our
key insight is to formulate diversity as a distribution matching problem where
the distribution of generated designs captures the inherent diversity contained
within the offline dataset. Extensive experiments spanning multiple scientific
domains show that DynAMO can be used with common optimization methods to
significantly improve the diversity of proposed designs while still discovering
high-quality candidates.

摘要：離線模型優化 (MBO) 的目標是提出新的設計，在僅提供離線資料集的情況下最大化回報函數。然而，一個重要的條件是提出多樣化的最終候選集，其中包含許多最佳和接近最佳的設計配置。我們提出在對抗模型優化 (DynAMO) 中的多樣性，作為一種新穎的方法，將設計多樣性作為明確的目標引入任何 MBO 問題。我們的關鍵見解是將多樣性表述為一個分佈匹配問題，其中生成設計的分佈捕捉了離線資料集中包含的固有多樣性。跨越多個科學領域的廣泛實驗表明，DynAMO 可與常見的最佳化方法一起使用，以顯著提高所提出設計的多樣性，同時仍能發現高品質的候選者。

##### **Breaking the Fake News Barrier: Deep Learning Approaches in Bangla Language**
2501.18766v1 by Pronoy Kumar Mondal, Sadman Sadik Khan, Md. Masud Rana, Shahriar Sultan Ramit, Abdus Sattar, Md. Sadekur Rahman

The rapid development of digital stages has greatly compounded the dispersal
of untrue data, dissolving certainty and judgment in society, especially among
the Bengali-speaking community. Our ponder addresses this critical issue by
presenting an interesting strategy that utilizes a profound learning
innovation, particularly the Gated Repetitive Unit (GRU), to recognize fake
news within the Bangla dialect. The strategy of our proposed work incorporates
intensive information preprocessing, which includes lemmatization,
tokenization, and tending to course awkward nature by oversampling. This comes
about in a dataset containing 58,478 passages. We appreciate the creation of a
demonstration based on GRU (Gated Repetitive Unit) that illustrates remarkable
execution with a noteworthy precision rate of 94%. This ponder gives an
intensive clarification of the methods included in planning the information,
selecting the show, preparing it, and assessing its execution. The performance
of the model is investigated by reliable metrics like precision, recall, F1
score, and accuracy. The commitment of the work incorporates making a huge fake
news dataset in Bangla and a demonstration that has outperformed other Bangla
fake news location models.

摘要：數位舞台的快速發展極大地加劇了不實資料的散播，消解了社會中的確定性和判斷力，特別是在講孟加拉語的社群中。我們的思考透過提出一個有趣的策略來解決這個關鍵問題，該策略利用了深度學習創新，特別是門控迴圈單元 (GRU)，來辨識孟加拉方言中的假新聞。我們提出的工作策略包含密集的資料前處理，其中包括詞形還原、標記化和透過過度抽樣來處理課程不平衡。這產生了一個包含 58,478 段落之資料集。我們很欣賞基於 GRU (門控迴圈單元) 的示範的建立，它以 94% 的顯著精確度率說明了非凡的執行。這項思考提供了對規劃資料、選擇特徵、準備資料和評估其執行的所包含方法的深入說明。該模型的效能是由精確度、召回率、F1 分數和準確度等可靠指標來調查的。這項工作的承諾包括製作一個龐大的孟加拉語假新聞資料集，以及一個表現優於其他孟加拉語假新聞定位模型的示範。

##### **Revisiting Projection-based Data Transfer for Cross-Lingual Named Entity Recognition in Low-Resource Languages**
2501.18750v1 by Andrei Politov, Oleh Shkalikov, René Jäkel, Michael Färber

Cross-lingual Named Entity Recognition (NER) leverages knowledge transfer
between languages to identify and classify named entities, making it
particularly useful for low-resource languages. We show that the data-based
cross-lingual transfer method is an effective technique for crosslingual NER
and can outperform multilingual language models for low-resource languages.
This paper introduces two key enhancements to the annotation projection step in
cross-lingual NER for low-resource languages. First, we explore refining word
alignments using back-translation to improve accuracy. Second, we present a
novel formalized projection approach of matching source entities with extracted
target candidates. Through extensive experiments on two datasets spanning 57
languages, we demonstrated that our approach surpasses existing projectionbased
methods in low-resource settings. These findings highlight the robustness of
projection-based data transfer as an alternative to model-based methods for
crosslingual named entity recognition in lowresource languages.

摘要：跨語言命名實體辨識 (NER) 利用語言之間的知識轉移來辨識和分類命名實體，這對於低資源語言特別有用。我們展示基於資料的跨語言轉移方法是跨語言 NER 的一種有效技術，並且可以優於多語言語言模型的低資源語言。本文介紹了低資源語言跨語言 NER 中註解投影步驟的兩項關鍵改進。首先，我們探討使用反向翻譯來改善準確度，以改善詞彙對齊。其次，我們提出一個新的形式化投影方法，用於將來源實體與提取的目標候選項目相匹配。透過對橫跨 57 種語言的兩個資料集進行廣泛的實驗，我們證明了我們的做法在低資源設定中超越了現有的基於投影的方法。這些發現突顯了基於投影的資料轉移作為低資源語言中基於模型方法的跨語言命名實體辨識的替代方案的穩健性。

##### **Synthetic Data Generation for Augmenting Small Samples**
2501.18741v1 by Dan Liu, Samer El Kababji, Nicholas Mitsakakis, Lisa Pilgram, Thomas Walters, Mark Clemons, Greg Pond, Alaa El-Hussuna, Khaled El Emam

Small datasets are common in health research. However, the generalization
performance of machine learning models is suboptimal when the training datasets
are small. To address this, data augmentation is one solution. Augmentation
increases sample size and is seen as a form of regularization that increases
the diversity of small datasets, leading them to perform better on unseen data.
We found that augmentation improves prognostic performance for datasets that:
have fewer observations, with smaller baseline AUC, have higher cardinality
categorical variables, and have more balanced outcome variables. No specific
generative model consistently outperformed the others. We developed a decision
support model that can be used to inform analysts if augmentation would be
useful. For seven small application datasets, augmenting the existing data
results in an increase in AUC between 4.31% (AUC from 0.71 to 0.75) and 43.23%
(AUC from 0.51 to 0.73), with an average 15.55% relative improvement,
demonstrating the nontrivial impact of augmentation on small datasets
(p=0.0078). Augmentation AUC was higher than resampling only AUC (p=0.016). The
diversity of augmented datasets was higher than the diversity of resampled
datasets (p=0.046).

摘要：在健康研究中，小型数据集很常见。然而，当训练数据集较小时，机器学习模型的泛化性能并不理想。为了解决这个问题，数据增强是一种解决方案。增强增加了样本量，并被视为一种正则化形式，它增加了小型数据集的多样性，从而使其在未见数据上表现得更好。我们发现，增强提高了以下数据集的预测性能：具有较少的观测值、较小的基线 AUC、较高的基数分类变量以及更平衡的结果变量。没有特定的生成模型始终优于其他模型。我们开发了一个决策支持模型，可用于告知分析师增强是否有用。对于七个小型应用程序数据集，增强现有数据导致 AUC 增加 4.31%（AUC 从 0.71 增加到 0.75）和 43.23%（AUC 从 0.51 增加到 0.73），平均相对改进 15.55%，这表明了增强对小型数据集的非平凡影响（p=0.0078）。增强 AUC 高于仅重新采样的 AUC（p=0.016）。增强数据集的多样性高于重新采样数据集的多样性（p=0.046）。

##### **Neural Graph Pattern Machine**
2501.18739v1 by Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye

Graph learning tasks require models to comprehend essential substructure
patterns relevant to downstream tasks, such as triadic closures in social
networks and benzene rings in molecular graphs. Due to the non-Euclidean nature
of graphs, existing graph neural networks (GNNs) rely on message passing to
iteratively aggregate information from local neighborhoods. Despite their
empirical success, message passing struggles to identify fundamental
substructures, such as triangles, limiting its expressiveness. To overcome this
limitation, we propose the Neural Graph Pattern Machine (GPM), a framework
designed to learn directly from graph patterns. GPM efficiently extracts and
encodes substructures while identifying the most relevant ones for downstream
tasks. We also demonstrate that GPM offers superior expressivity and improved
long-range information modeling compared to message passing. Empirical
evaluations on node classification, link prediction, graph classification, and
regression show the superiority of GPM over state-of-the-art baselines. Further
analysis reveals its desirable out-of-distribution robustness, scalability, and
interpretability. We consider GPM to be a step toward going beyond message
passing.

摘要：圖形學習任務需要模型理解與下游任務相關的基本子結構模式，例如社交網路中的三元封閉和分子圖形中的苯環。由於圖形的非歐幾何性質，現有的圖形神經網路 (GNN) 依賴訊息傳遞來反覆聚合來自局部鄰域的資訊。儘管在經驗上獲得成功，訊息傳遞仍難以識別基本子結構，例如三角形，這限制了其表達能力。為了克服這個限制，我們提出神經圖形模式機器 (GPM)，一個旨在直接從圖形模式學習的框架。GPM 在識別對下游任務最相關的子結構時，有效地提取並編碼子結構。我們也證明，與訊息傳遞相比，GPM 提供了卓越的表達能力和改進的長距離資訊建模。在節點分類、連結預測、圖形分類和回歸上的經驗評估顯示，GPM 優於最先進的基準。進一步的分析揭示了其理想的分布外穩健性、可擴充性和可解釋性。我們認為 GPM 是超越訊息傳遞的一步。

##### **Examining the Robustness of Large Language Models across Language Complexity**
2501.18738v1 by Jiayi Zhang

With the advancement of large language models (LLMs), an increasing number of
student models have leveraged LLMs to analyze textual artifacts generated by
students to understand and evaluate their learning. These student models
typically employ pre-trained LLMs to vectorize text inputs into embeddings and
then use the embeddings to train models to detect the presence or absence of a
construct of interest. However, how reliable and robust are these models at
processing language with different levels of complexity? In the context of
learning where students may have different language backgrounds with various
levels of writing skills, it is critical to examine the robustness of such
models to ensure that these models work equally well for text with varying
levels of language complexity. Coincidentally, a few (but limited) research
studies show that the use of language can indeed impact the performance of
LLMs. As such, in the current study, we examined the robustness of several
LLM-based student models that detect student self-regulated learning (SRL) in
math problem-solving. Specifically, we compared how the performance of these
models vary using texts with high and low lexical, syntactic, and semantic
complexity measured by three linguistic measures.

摘要：隨著大型語言模型 (LLM) 的進步，越來越多的學生模型利用 LLM 來分析學生產生的文本製品，以了解和評估他們的學習情況。這些學生模型通常採用預先訓練的 LLM，將文本輸入向量化為嵌入，然後使用嵌入來訓練模型，以檢測目標結構是否存在。然而，這些模型在處理不同複雜程度的語言時，其可靠性和穩健性如何？在學生可能具有不同語言背景和各種寫作技能的學習背景下，審查此類模型的穩健性至關重要，以確保這些模型對語言複雜程度不同的文本同樣有效。巧合的是，一些（但有限的）研究表明，語言的使用確實會影響 LLM 的效能。因此，在當前的研究中，我們檢驗了幾個基於 LLM 的學生模型的穩健性，這些模型可以檢測數學問題解決中的學生自我調節學習 (SRL)。具體來說，我們比較了這些模型使用語言複雜度由三種語言測量測得的高低詞彙、句法和語義複雜度的文本時，效能如何變化。

##### **Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation**
2501.18733v1 by Yuelei Li, Ge Yan, Annabella Macaluso, Mazeyu Ji, Xueyan Zou, Xiaolong Wang

The recent advancements in visual reasoning capabilities of large multimodal
models (LMMs) and the semantic enrichment of 3D feature fields have expanded
the horizons of robotic capabilities. These developments hold significant
potential for bridging the gap between high-level reasoning from LMMs and
low-level control policies utilizing 3D feature fields. In this work, we
introduce LMM-3DP, a framework that can integrate LMM planners and 3D skill
Policies. Our approach consists of three key perspectives: high-level planning,
low-level control, and effective integration. For high-level planning, LMM-3DP
supports dynamic scene understanding for environment disturbances, a critic
agent with self-feedback, history policy memorization, and reattempts after
failures. For low-level control, LMM-3DP utilizes a semantic-aware 3D feature
field for accurate manipulation. In aligning high-level and low-level control
for robot actions, language embeddings representing the high-level policy are
jointly attended with the 3D feature field in the 3D transformer for seamless
integration. We extensively evaluate our approach across multiple skills and
long-horizon tasks in a real-world kitchen environment. Our results show a
significant 1.45x success rate increase in low-level control and an approximate
1.5x improvement in high-level planning accuracy compared to LLM-based
baselines. Demo videos and an overview of LMM-3DP are available at
https://lmm-3dp-release.github.io.

摘要：<paragraph>大型多模態模型 (LMM) 的視覺推理能力和 3D 特徵場的語義豐富化最近的進展擴展了機器人能力的視野。這些發展具有巨大的潛力，可以彌合 LMM 的高階推理和利用 3D 特徵場的低階控制策略之間的差距。在這項工作中，我們介紹了 LMM-3DP，一個可以整合 LMM 計畫器和 3D 技能策略的框架。我們的做法包含三個關鍵觀點：高階規劃、低階控制和有效整合。對於高階規劃，LMM-3DP 支援環境干擾的動態場景理解、具有自我回饋的批評代理、歷史策略記憶以及失敗後的重試。對於低階控制，LMM-3DP 利用語義感知的 3D 特徵場進行準確的操縱。在調整機器人動作的高階和低階控制時，表示高階策略的語言嵌入與 3D 特徵場在 3D 轉換器中共同關注，以實現無縫整合。我們在真實世界的廚房環境中廣泛評估了我們的方法，涉及多項技能和長時程任務。我們的結果顯示，與基於 LLM 的基線相比，低階控制的成功率顯著提升了 1.45 倍，高階規劃準確度提升了約 1.5 倍。展示影片和 LMM-3DP 的概述可以在 https://lmm-3dp-release.github.io/ 取得。</paragraph>


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-31**|**Improving vision-language alignment with graph spiking hybrid Networks**|Siyu Zhang et.al.|[2501.19069v1](http://arxiv.org/abs/2501.19069v1)|null|
|**2025-01-30**|**Semantic Web and Creative AI -- A Technical Report from ISWS 2023**|Raia Abu Ahmad et.al.|[2501.18542v1](http://arxiv.org/abs/2501.18542v1)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**|Tianpeng Pan et.al.|[2501.18320v1](http://arxiv.org/abs/2501.18320v1)|null|
|**2025-01-30**|**Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**|Wanlong Liu et.al.|[2501.18154v1](http://arxiv.org/abs/2501.18154v1)|null|
|**2025-01-30**|**Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**|Qika Lin et.al.|[2501.18119v1](http://arxiv.org/abs/2501.18119v1)|null|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**|Wooyoung Kim et.al.|[2501.17549v1](http://arxiv.org/abs/2501.17549v1)|null|
|**2025-01-29**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403v1](http://arxiv.org/abs/2501.17403v1)|[link](https://github.com/honghd16/gsa-vln)|
|**2025-01-28**|**Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**|Saloni Potdar et.al.|[2501.17270v1](http://arxiv.org/abs/2501.17270v1)|null|
|**2025-01-28**|**FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**|Deren Lei et.al.|[2501.17144v1](http://arxiv.org/abs/2501.17144v1)|[link](https://github.com/derenlei/factcg)|
|**2025-01-28**|**LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**|Li Yin et.al.|[2501.16673v2](http://arxiv.org/abs/2501.16673v2)|[link](https://github.com/sylphai-inc/adalflow)|
|**2025-01-27**|**360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation**|Hamed Firooz et.al.|[2501.16450v2](http://arxiv.org/abs/2501.16450v2)|null|
|**2025-01-27**|**Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**|Antony Bartlett et.al.|[2501.16191v1](http://arxiv.org/abs/2501.16191v1)|null|
|**2025-01-27**|**Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs**|Yu Li et.al.|[2501.15791v1](http://arxiv.org/abs/2501.15791v1)|[link](https://github.com/kse-eleven/makged)|
|**2025-01-27**|**Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs**|Momoka Furuhashi et.al.|[2501.15777v1](http://arxiv.org/abs/2501.15777v1)|null|
|**2025-01-26**|**Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts**|Haodi Ma et.al.|[2501.15688v1](http://arxiv.org/abs/2501.15688v1)|null|
|**2025-01-26**|**How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback**|Manzong Huang et.al.|[2501.15378v1](http://arxiv.org/abs/2501.15378v1)|null|
|**2025-01-24**|**Explaining Categorical Feature Interactions Using Graph Covariance and LLMs**|Cencheng Shen et.al.|[2501.14932v1](http://arxiv.org/abs/2501.14932v1)|null|
|**2025-01-24**|**Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**|Hang Luo et.al.|[2501.14892v1](http://arxiv.org/abs/2501.14892v1)|null|
|**2025-01-24**|**GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**|Ziwen Li et.al.|[2501.16382v1](http://arxiv.org/abs/2501.16382v1)|[link](https://github.com/aaronli43/grappi)|
|**2025-01-24**|**Evaluating and Improving Graph to Text Generation with Large Language Models**|Jie He et.al.|[2501.14497v1](http://arxiv.org/abs/2501.14497v1)|[link](https://github.com/probe2/kg_text)|
|**2025-01-24**|**Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**|Xujian Liang et.al.|[2501.14300v1](http://arxiv.org/abs/2501.14300v1)|[link](https://github.com/dosonleung/fasttog)|
|**2025-01-24**|**Top Ten Challenges Towards Agentic Neural Graph Databases**|Jiaxin Bai et.al.|[2501.14224v1](http://arxiv.org/abs/2501.14224v1)|null|
|**2025-01-23**|**GraphRAG under Fire**|Jiacheng Liang et.al.|[2501.14050v1](http://arxiv.org/abs/2501.14050v1)|null|
|**2025-01-23**|**EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**|Yuhui Yun et.al.|[2501.13746v1](http://arxiv.org/abs/2501.13746v1)|null|
|**2025-01-23**|**Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**|Chang Gong et.al.|[2501.13731v1](http://arxiv.org/abs/2501.13731v1)|null|
|**2025-01-23**|**CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**|Hamza Landolsi et.al.|[2501.13993v1](http://arxiv.org/abs/2501.13993v1)|null|
|**2025-01-23**|**Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**|Hy Nguyen et.al.|[2501.13992v1](http://arxiv.org/abs/2501.13992v1)|null|
|**2025-01-23**|**Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**|Bhumika Gupta et.al.|[2501.13984v1](http://arxiv.org/abs/2501.13984v1)|null|
|**2025-01-21**|**LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**|Hasan Abu-Rasheed et.al.|[2501.12300v1](http://arxiv.org/abs/2501.12300v1)|null|
|**2025-01-21**|**Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**|Dongsheng Zhu et.al.|[2501.12432v1](http://arxiv.org/abs/2501.12432v1)|null|
|**2025-01-21**|**InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**|Pha Nguyen et.al.|[2501.12231v1](http://arxiv.org/abs/2501.12231v1)|null|
|**2025-01-21**|**Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**|Maya Medjad et.al.|[2501.11977v1](http://arxiv.org/abs/2501.11977v1)|[link](https://github.com/reecall/graphtod)|
|**2025-01-21**|**Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**|Jie Zhao et.al.|[2501.11968v1](http://arxiv.org/abs/2501.11968v1)|null|
|**2025-01-21**|**A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**|Qinggang Zhang et.al.|[2501.13958v1](http://arxiv.org/abs/2501.13958v1)|[link](https://github.com/deep-polyu/awesome-graphrag)|
|**2025-01-21**|**Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**|Nikos Kanakaris et.al.|[2501.11849v2](http://arxiv.org/abs/2501.11849v2)|[link](https://github.com/nkanak/brag-fake-news-campaigns)|
|**2025-01-21**|**Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning**|Haoran Song et.al.|[2501.16361v1](http://arxiv.org/abs/2501.16361v1)|null|
|**2025-01-20**|**Zep: A Temporal Knowledge Graph Architecture for Agent Memory**|Preston Rasmussen et.al.|[2501.13956v1](http://arxiv.org/abs/2501.13956v1)|[link](https://github.com/getzep/graphiti)|
|**2025-01-20**|**Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**|M. Manzour et.al.|[2501.11560v1](http://arxiv.org/abs/2501.11560v1)|null|
|**2025-01-20**|**Each Graph is a New Language: Graph Learning with LLMs**|Huachi Zhou et.al.|[2501.11478v2](http://arxiv.org/abs/2501.11478v2)|null|
|**2025-01-20**|**Few-shot Policy (de)composition in Conversational Question Answering**|Kyle Erwin et.al.|[2501.11335v1](http://arxiv.org/abs/2501.11335v1)|null|
|**2025-01-20**|**Reasoning Language Models: A Blueprint**|Maciej Besta et.al.|[2501.11223v3](http://arxiv.org/abs/2501.11223v3)|[link](https://github.com/spcl/x1)|
|**2025-01-19**|**IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**|Elad Levi et.al.|[2501.11067v1](http://arxiv.org/abs/2501.11067v1)|[link](https://github.com/plurai-ai/intellagent)|
|**2025-01-18**|**A Method for Multi-Hop Question Answering on Persian Knowledge Graph**|Arash Ghafouri et.al.|[2501.16350v1](http://arxiv.org/abs/2501.16350v1)|null|
|**2025-01-17**|**Agent-as-Judge for Factual Summarization of Long Narratives**|Yeonseok Jeong et.al.|[2501.09993v1](http://arxiv.org/abs/2501.09993v1)|[link](https://github.com/yeonseokjeong/narrativefactscore)|
|**2025-01-17**|**FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**|Zengyi Gao et.al.|[2501.09957v2](http://arxiv.org/abs/2501.09957v2)|null|
|**2025-01-16**|**SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**|Anbang Ye et.al.|[2501.09316v1](http://arxiv.org/abs/2501.09316v1)|null|
|**2025-01-16**|**Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**|Zijin Qiu et.al.|[2501.09279v1](http://arxiv.org/abs/2501.09279v1)|null|
|**2025-01-16**|**A Simple Graph Contrastive Learning Framework for Short Text Classification**|Yonghao Liu et.al.|[2501.09219v1](http://arxiv.org/abs/2501.09219v1)|[link](https://github.com/keaml-jlu/simstc)|
|**2025-01-16**|**Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**|Yonghao Liu et.al.|[2501.09214v1](http://arxiv.org/abs/2501.09214v1)|[link](https://github.com/keaml-jlu/mi-delight)|
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|[link](https://github.com/qinyuma316/retrosynthesisagent)|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|[link](https://github.com/machuangtao/kg-rag4sm)|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v2](http://arxiv.org/abs/2501.08613v2)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**|Markus J. Buehler et.al.|[2501.08120v1](http://arxiv.org/abs/2501.08120v1)|[link](https://github.com/lamm-mit/PRefLexOR)|
|**2025-01-14**|**Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**|Haoyu Han et.al.|[2501.07845v1](http://arxiv.org/abs/2501.07845v1)|null|
|**2025-01-14**|**Flow: A Modular Approach to Automated Agentic Workflow Generation**|Boye Niu et.al.|[2501.07834v1](http://arxiv.org/abs/2501.07834v1)|null|
|**2025-01-14**|**Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**|Bingchen Liu et.al.|[2501.07766v1](http://arxiv.org/abs/2501.07766v1)|null|
|**2025-01-13**|**SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**|Fabien Bernier et.al.|[2501.07639v1](http://arxiv.org/abs/2501.07639v1)|null|
|**2025-01-13**|**ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**|Jiayang Wu et.al.|[2501.07078v1](http://arxiv.org/abs/2501.07078v1)|[link](https://github.com/csjywu1/adkgd)|
|**2025-01-12**|**Causal Claims in Economics**|Prashant Garg et.al.|[2501.06873v1](http://arxiv.org/abs/2501.06873v1)|null|
|**2025-01-12**|**MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**|Tianyu Fan et.al.|[2501.06713v3](http://arxiv.org/abs/2501.06713v3)|[link](https://github.com/hkuds/minirag)|
|**2025-01-12**|**Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**|Aidan Hogan et.al.|[2501.06699v1](http://arxiv.org/abs/2501.06699v1)|null|
|**2025-01-11**|**Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**|Mohammed Maree et.al.|[2501.06628v1](http://arxiv.org/abs/2501.06628v1)|null|
|**2025-01-11**|**MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**|Ye Chen et.al.|[2501.06465v2](http://arxiv.org/abs/2501.06465v2)|null|
|**2025-01-10**|**Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**|Mumin Jia et.al.|[2501.06382v2](http://arxiv.org/abs/2501.06382v2)|null|
|**2025-01-10**|**Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**|Zuyuan Zhang et.al.|[2501.05673v1](http://arxiv.org/abs/2501.05673v1)|null|
|**2025-01-08**|**FlairGPT: Repurposing LLMs for Interior Designs**|Gabrielle Littlefair et.al.|[2501.04648v1](http://arxiv.org/abs/2501.04648v1)|null|
|**2025-01-08**|**CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**|Ruijun Feng et.al.|[2501.04510v1](http://arxiv.org/abs/2501.04510v1)|null|
|**2025-01-08**|**S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**|Prashant Verma et.al.|[2501.05485v1](http://arxiv.org/abs/2501.05485v1)|[link](https://github.com/Vprashant/s2-chunking-lib)|
|**2025-01-08**|**Multimodal Graph Constrastive Learning and Prompt for ChartQA**|Yue Dai et.al.|[2501.04303v1](http://arxiv.org/abs/2501.04303v1)|null|
|**2025-01-07**|**Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**|Wen-Dong Jiang et.al.|[2501.06224v2](http://arxiv.org/abs/2501.06224v2)|null|
|**2025-01-07**|**Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**|Benedikt Reitemeyer et.al.|[2501.03566v1](http://arxiv.org/abs/2501.03566v1)|null|
|**2025-01-07**|**KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**|Zelin Zhou et.al.|[2501.03560v1](http://arxiv.org/abs/2501.03560v1)|null|
|**2025-01-06**|**Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**|Ali Al-Lawati et.al.|[2501.03166v1](http://arxiv.org/abs/2501.03166v1)|[link](https://github.com/aliwister/ast-icl)|
|**2025-01-06**|**Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**|Chongxian Chen et.al.|[2501.03085v1](http://arxiv.org/abs/2501.03085v1)|null|
|**2025-01-06**|**Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**|Yubo Wang et.al.|[2501.02844v1](http://arxiv.org/abs/2501.02844v1)|null|
|**2025-01-06**|**KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**|Zaiyi Zheng et.al.|[2501.02711v1](http://arxiv.org/abs/2501.02711v1)|null|
|**2025-01-04**|**Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**|Markus J. Buehler et.al.|[2501.02393v2](http://arxiv.org/abs/2501.02393v2)|[link](https://github.com/lamm-mit/graph-aware-transformers)|
|**2025-01-04**|**What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**|Yutao Jiang et.al.|[2501.02268v1](http://arxiv.org/abs/2501.02268v1)|[link](https://github.com/jytmelon/g-prune)|
|**2025-01-04**|**Personalized Graph-Based Retrieval for Large Language Models**|Steven Au et.al.|[2501.02157v1](http://arxiv.org/abs/2501.02157v1)|[link](https://github.com/pgraphrag-benchmark/pgr-llm)|
|**2025-01-03**|**Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**|Weizhi Zhang et.al.|[2501.01945v2](http://arxiv.org/abs/2501.01945v2)|[link](https://github.com/yuanchenbei/awesome-cold-start-recommendation)|
|**2025-01-03**|**Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**|Tien Dang et.al.|[2501.01644v1](http://arxiv.org/abs/2501.01644v1)|[link](https://github.com/hysonlab/biomedkg)|
|**2025-01-02**|**Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**|Kedi Chen et.al.|[2501.02020v1](http://arxiv.org/abs/2501.02020v1)|null|
|**2025-01-01**|**Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**|Weiqi Wu et.al.|[2501.00888v1](http://arxiv.org/abs/2501.00888v1)|[link](https://github.com/Alibaba-NLP/CHRONOS)|
|**2025-01-01**|**Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**|Wei Zhang et.al.|[2501.03257v1](http://arxiv.org/abs/2501.03257v1)|null|
|**2025-01-01**|**SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**|Mao Xun Huang et.al.|[2501.01998v1](http://arxiv.org/abs/2501.01998v1)|null|
|**2024-12-31**|**Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**|Yipeng Kang et.al.|[2501.00581v1](http://arxiv.org/abs/2501.00581v1)|null|
|**2024-12-31**|**CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**|Michael Gubanov et.al.|[2501.00223v1](http://arxiv.org/abs/2501.00223v1)|null|
|**2024-12-31**|**The Potential of LLMs in Automating Software Testing: From Generation to Reporting**|Betim Sherifi et.al.|[2501.00217v1](http://arxiv.org/abs/2501.00217v1)|null|
|**2024-12-30**|**Detection-Fusion for Knowledge Graph Extraction from Videos**|Taniya Das et.al.|[2501.00136v1](http://arxiv.org/abs/2501.00136v1)|[link](https://github.com/Taniya-Das/video_annotation)|
|**2024-12-30**|**Machine Learning-Based Security Policy Analysis**|Krish Jain et.al.|[2501.00085v2](http://arxiv.org/abs/2501.00085v2)|null|
|**2024-12-30**|**KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**|Siyuan Fang et.al.|[2412.20995v1](http://arxiv.org/abs/2412.20995v1)|null|
|**2024-12-30**|**Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**|Xiaohan Feng et.al.|[2412.20942v1](http://arxiv.org/abs/2412.20942v1)|null|
|**2024-12-29**|**ICLR: In-Context Learning of Representations**|Core Francisco Park et.al.|[2501.00070v1](http://arxiv.org/abs/2501.00070v1)|null|
|**2024-12-28**|**Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**|Minhye Jeon et.al.|[2412.20163v2](http://arxiv.org/abs/2412.20163v2)|null|
|**2024-12-28**|**From Generalist to Specialist: A Survey of Large Language Models for Chemistry**|Yang Han et.al.|[2412.19994v1](http://arxiv.org/abs/2412.19994v1)|[link](https://github.com/opendfm/llm4chemistry)|
|**2024-12-27**|**Toward Adaptive Reasoning in Large Language Models with Thought Rollback**|Sijia Chen et.al.|[2412.19707v1](http://arxiv.org/abs/2412.19707v1)|[link](https://github.com/iQua/llmpebase)|

#### Abstracts
##### **Improving vision-language alignment with graph spiking hybrid Networks**
2501.19069v1 by Siyu Zhang, Heming Zheng, Yiming Wu, Yeming Chen

To bridge the semantic gap between vision and language (VL), it is necessary
to develop a good alignment strategy, which includes handling semantic
diversity, abstract representation of visual information, and generalization
ability of models. Recent works use detector-based bounding boxes or patches
with regular partitions to represent visual semantics. While current paradigms
have made strides, they are still insufficient for fully capturing the nuanced
contextual relations among various objects. This paper proposes a comprehensive
visual semantic representation module, necessitating the utilization of
panoptic segmentation to generate coherent fine-grained semantic features.
Furthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that
integrates the complementary advantages of Spiking Neural Networks (SNNs) and
Graph Attention Networks (GATs) to encode visual semantic information.
Intriguingly, the model not only encodes the discrete and continuous latent
variables of instances but also adeptly captures both local and global
contextual features, thereby significantly enhancing the richness and diversity
of semantic representations. Leveraging the spatiotemporal properties inherent
in SNNs, we employ contrastive learning (CL) to enhance the similarity-based
representation of embeddings. This strategy alleviates the computational
overhead of the model and enriches meaningful visual representations by
constructing positive and negative sample pairs. We design an innovative
pre-training method, Spiked Text Learning (STL), which uses text features to
improve the encoding ability of discrete semantics. Experiments show that the
proposed GSHN exhibits promising results on multiple VL downstream tasks.

摘要：<paragraph>為了彌合視覺和語言 (VL) 之間的語意差距，必須制定良好的對齊策略，其中包括處理語意多樣性、視覺資訊的抽象表示以及模型的泛化能力。最近的研究使用基於偵測器的邊界框或具有規則分割的區塊來表示視覺語意。雖然目前的範例已取得進展，但對於完全捕捉各種物件之間的細微脈絡關係仍不足夠。本文提出了一個全面的視覺語意表示模組，需要利用全景分割來產生連貫的細粒度語意特徵。此外，我們提出了一個新穎的圖形脈衝混合網路 (GSHN)，它整合了脈衝神經網路 (SNN) 和圖形注意力網路 (GAT) 的互補優勢來編碼視覺語意資訊。有趣的是，該模型不僅編碼實例的離散和連續潛在變數，還能巧妙地捕捉局部和全域脈絡特徵，從而顯著增強語意表示的豐富性和多樣性。利用 SNN 中固有的時空特性，我們採用對比學習 (CL) 來增強嵌入的基於相似性的表示。此策略減輕了模型的計算負擔，並透過建構正負樣本對來豐富有意義的視覺表示。我們設計了一個創新的預訓練方法，脈衝文本學習 (STL)，它使用文本特徵來提高離散語意的編碼能力。實驗表明，所提出的 GSHN 在多個 VL 下游任務上展現出有希望的結果。</paragraph>

##### **Semantic Web and Creative AI -- A Technical Report from ISWS 2023**
2501.18542v1 by Raia Abu Ahmad, Reham Alharbi, Roberto Barile, Martin Böckling, Francisco Bolanos, Sara Bonfitto, Oleksandra Bruns, Irene Celino, Yashrajsinh Chudasama, Martin Critelli, Claudia d'Amato, Giada D'Ippolito, Ioannis Dasoulas, Stefano De Giorgis, Vincenzo De Leo, Chiara Di Bonaventura, Marco Di Panfilo, Daniil Dobriy, John Domingue, Xuemin Duan, Michel Dumontier, Sefika Efeoglu, Ruben Eschauzier, Fakih Ginwa, Nicolas Ferranti, Arianna Graciotti, Philipp Hanisch, George Hannah, Golsa Heidari, Aidan Hogan, Hassan Hussein, Alexane Jouglar, Jan-Christoph Kalo, Manoé Kieffer, Antonis Klironomos, Inês Koch, Weronika Lajewska, Nicolas Lazzari, Mikael Lindekrans, Anna Sofia Lippolis, Majlinda Llugiqi, Eleonora Mancini, Eleonora Marzi, Laura Menotti, Daniela Milon Flores, Soulakshmee Nagowah, Kerstin Neubert, Emetis Niazmand, Ebrahim Norouzi, Beatriz Olarte Martinez, Anouk Michelle Oudshoorn, Andrea Poltronieri, Valentina Presutti, Disha Purohit, Ensiyeh Raoufi, Celian Ringwald, Johanna Rockstroh, Sebastian Rudolph, Harald Sack, Zafar Saeed, Mohammad Javad Saeedizade, Aya Sahbi, Cristian Santini, Aleksandra Simic, Dennis Sommer, Rita Sousa, Mary Ann Tan, Vidyashree Tarikere, Tabea Tietz, Liam Tirpitz, Arnaldo Tomasino, Frank van Harmelen, Joao Vissoci, Caitlin Woods, Bohui Zhang, Xinyue Zhang, Heng Zheng

The International Semantic Web Research School (ISWS) is a week-long
intensive program designed to immerse participants in the field. This document
reports a collaborative effort performed by ten teams of students, each guided
by a senior researcher as their mentor, attending ISWS 2023. Each team provided
a different perspective to the topic of creative AI, substantiated by a set of
research questions as the main subject of their investigation. The 2023 edition
of ISWS focuses on the intersection of Semantic Web technologies and Creative
AI. ISWS 2023 explored various intersections between Semantic Web technologies
and creative AI. A key area of focus was the potential of LLMs as support tools
for knowledge engineering. Participants also delved into the multifaceted
applications of LLMs, including legal aspects of creative content production,
humans in the loop, decentralised approaches to multimodal generative AI
models, nanopublications and AI for personal scientific knowledge graphs,
commonsense knowledge in automatic story and narrative completion, generative
AI for art critique, prompt engineering, automatic music composition,
commonsense prototyping and conceptual blending, and elicitation of tacit
knowledge. As Large Language Models and semantic technologies continue to
evolve, new exciting prospects are emerging: a future where the boundaries
between creative expression and factual knowledge become increasingly permeable
and porous, leading to a world of knowledge that is both informative and
inspiring.

摘要：國際語意網路研究學校 (ISWS) 是一個為期一週的密集課程，旨在讓參與者沉浸在該領域中。本文件報告了由十個學生團隊進行的合作成果，每個團隊都由一位資深研究員作為導師，參加了 2023 年 ISWS。每個團隊都從不同的角度探討了創意 AI 主題，並以一系列研究問題作為調查的主要主題。2023 年版的 ISWS 關注於語意網路技術和創意 AI 的交集。ISWS 2023 探索了語意網路技術和創意 AI 之間的各種交集。一個重點關注領域是 LLM 作為知識工程的支援工具的潛力。參與者還深入探討了 LLM 的多方面應用，包括創意內容製作的法律方面、循環中的人類、多模態生成式 AI 模型的分散式方法、納米出版物和用於個人科學知識圖譜的 AI、自動故事和敘述完成中的常識知識、生成式 AI 用於藝術評論、提示工程、自動音樂創作、常識原型和概念混合，以及對默會知識的引導。隨著大型語言模型和語意技術的持續發展，新的令人興奮的前景正在出現：一個創意表達和事實知識之間的界限變得越來越可滲透和多孔的未來，從而導致一個既有資訊性又有啟發性的知識世界。

##### **Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach**
2501.18320v1 by Tianpeng Pan, Wenqiang Pu, Licheng Zhao, Rui Zhou

Automated optimization modeling (AOM) has evoked considerable interest with
the rapid evolution of large language models (LLMs). Existing approaches
predominantly rely on prompt engineering, utilizing meticulously designed
expert response chains or structured guidance. However, prompt-based techniques
have failed to perform well in the sensor array signal processing (SASP) area
due the lack of specific domain knowledge. To address this issue, we propose an
automated modeling approach based on retrieval-augmented generation (RAG)
technique, which consists of two principal components: a multi-agent (MA)
structure and a graph-based RAG (Graph-RAG) process. The MA structure is
tailored for the architectural AOM process, with each agent being designed
based on principles of human modeling procedure. The Graph-RAG process serves
to match user query with specific SASP modeling knowledge, thereby enhancing
the modeling result. Results on ten classical signal processing problems
demonstrate that the proposed approach (termed as MAG-RAG) outperforms several
AOM benchmarks.

摘要：自動化最佳化建模 (AOM) 隨著大型語言模型 (LLM) 的快速演進而引起相當大的興趣。現有方法主要依賴提示工程，利用精心設計的專家回應鏈或結構化指導。然而，基於提示的技術由於缺乏特定領域知識，無法在感測器陣列訊號處理 (SASP) 領域中表現良好。為了解決這個問題，我們提出一個基於檢索增強生成 (RAG) 技術的自動化建模方法，它包含兩個主要組成部分：多代理 (MA) 結構和基於圖形的 RAG (Graph-RAG) 程序。MA 結構是針對架構 AOM 程序量身打造，每個代理都是根據人類建模程序的原理設計的。Graph-RAG 程序用於將使用者查詢與特定的 SASP 建模知識相匹配，從而增強建模結果。在十個經典訊號處理問題上的結果表明，所提出的方法（稱為 MAG-RAG）優於多個 AOM 基準。

##### **Mixed-Precision Graph Neural Quantization for Low Bit Large Language Models**
2501.18154v1 by Wanlong Liu, Yichen Xiao, Dingyi Zeng, Hongyang Zhao, Wenyu Chen, Malu Zhang

Post-Training Quantization (PTQ) is pivotal for deploying large language
models (LLMs) within resource-limited settings by significantly reducing
resource demands. However, existing PTQ strategies underperform at low bit
levels < 3 bits due to the significant difference between the quantized and
original weights. To enhance the quantization performance at low bit widths, we
introduce a Mixed-precision Graph Neural PTQ (MG-PTQ) approach, employing a
graph neural network (GNN) module to capture dependencies among weights and
adaptively assign quantization bit-widths. Through the information propagation
of the GNN module, our method more effectively captures dependencies among
target weights, leading to a more accurate assessment of weight importance and
optimized allocation of quantization strategies. Extensive experiments on the
WikiText2 and C4 datasets demonstrate that our MG-PTQ method outperforms
previous state-of-the-art PTQ method GPTQ, setting new benchmarks for
quantization performance under low-bit conditions.

摘要：訓練後量化 (PTQ) 對於在資源受限的設定中部署大型語言模型 (LLM) 至關重要，因為它能顯著降低資源需求。然而，現有的 PTQ 策略在低位元層級 < 3 位元時表現不佳，因為量化後的權重與原始權重之間有顯著的差異。為了提升低位元寬度的量化效能，我們提出混合精度圖神經網路 PTQ (MG-PTQ) 方法，採用圖神經網路 (GNN) 模組來擷取權重之間的依存關係，並動態分配量化位元寬度。透過 GNN 模組的資訊傳播，我們的方法能更有效地擷取目標權重之間的依存關係，進而更準確地評估權重重要性，並最佳化量化策略的配置。在 WikiText2 和 C4 資料集上的廣泛實驗證明，我們的 MG-PTQ 方法優於先前的最先進 PTQ 方法 GPTQ，在低位元條件下設定了量化效能的新基準。

##### **Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models**
2501.18119v1 by Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng

Due to the presence of the natural gap between Knowledge Graph (KG)
structures and the natural language, the effective integration of holistic
structural information of KGs with Large Language Models (LLMs) has emerged as
a significant question. To this end, we propose a two-stage framework to learn
and apply quantized codes for each entity, aiming for the seamless integration
of KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)
method is proposed to compress both KG structural and semantic knowledge into
discrete codes (\ie, tokens) that align the format of language sentences. We
further design KG instruction-following data by viewing these learned codes as
features to directly input to LLMs, thereby achieving seamless integration. The
experiment results demonstrate that SSQR outperforms existing unsupervised
quantized methods, producing more distinguishable codes. Further, the
fine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link
prediction and triple classification tasks, utilizing only 16 tokens per entity
instead of thousands in conventional prompting methods.

摘要：由於知識圖譜 (KG) 結構與自然語言之間存在自然差距，將 KG 的整體結構資訊與大型語言模型 (LLM) 有效整合已成為一個重要的問題。為此，我們提出了一個兩階段架構來學習和應用每個實體的量化碼，旨在將 KG 與 LLM 無縫整合。首先，提出了一個自監督量化表示 (SSQR) 方法，將 KG 結構和語義知識壓縮成離散碼（即，符號），以對齊語言句子的格式。我們進一步設計 KG 指令遵循資料，將這些學習到的碼視為直接輸入 LLM 的特徵，從而實現無縫整合。實驗結果表明，SSQR 優於現有的無監督量化方法，產生更具區別性的碼。此外，微調後的 LLaMA2 和 LLaMA3.1 在 KG 連結預測和三元分類任務上也具有優異的性能，每個實體僅使用 16 個符號，而不是傳統提示方法中的數千個。

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

摘要：回答需要對結構化（表格）和非結構化（原始文字）資料來源進行推理和彙總的問題會帶來重大挑戰。目前的辦法仰賴微調和高品質、人工整理的資料，而這很難取得。大型語言模型（LLM）的最新進展已針對零次學習設定的單一來源文字資料多跳問題回答（QA）展現出有希望的結果，但對多來源表格文字 QA 的探討仍然有限。在本文中，我們提出了一種新穎的基於混合圖表的表格文字 QA 方法，它利用 LLM 而無需微調。我們的辦法從文字和表格資料建構一個統一的混合圖表，根據輸入問題修剪資訊，以簡潔地為 LLM 提供相關脈絡。我們使用最先進的 LLM，包括 GPT-3.5、GPT-4 和 LLaMA-3，針對具有挑戰性的 Hybrid-QA 和 OTT-QA 資料集評估我們的辦法。我們的辦法在兩個資料集上都達到了最佳的零次學習效能，在 Hybrid-QA 上將完全比對分數提高了 10%，在 OTT-QA 上將完全比對分數提高了 5.4%。此外，與原始脈絡相比，我們的辦法將符號使用量減少了 53%。

##### **Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**
2501.17549v1 by Wooyoung Kim, Byungyoon Park, Wooju Kim

Graph-structured data plays a vital role in numerous domains, such as social
networks, citation networks, commonsense reasoning graphs and knowledge graphs.
While graph neural networks have been employed for graph processing, recent
advancements have explored integrating large language models for graph-based
tasks. In this paper, we propose a novel approach named Learnable Graph Pooling
Token (LGPT), which addresses the limitations of the scalability issues in
node-level projection and information loss in graph-level projection. LGPT
enables flexible and efficient graph representation by introducing learnable
parameters that act as tokens in large language models, balancing fine-grained
and global graph information. Additionally, we investigate an Early Query
Fusion technique, which fuses query context before constructing the graph
representation, leading to more effective graph embeddings. Our method achieves
a 4.13\% performance improvement on the GraphQA benchmark without training the
large language model, demonstrating significant gains in handling complex
textual-attributed graph data.

摘要：圖形結構資料在許多領域中扮演著至關重要的角色，例如社交網路、引用網路、常識推理圖形和知識圖形。雖然圖形神經網路已用於圖形處理，但最近的進展已探討整合大型語言模型以進行基於圖形的任務。在本文中，我們提出了一種名為可學習圖形池化令牌 (LGPT) 的新方法，它解決了節點層級投影中的可擴充性問題和圖形層級投影中的資訊遺失限制。LGPT 透過引入可學習的參數（在大型語言模型中作為令牌運作）來啟用彈性和高效的圖形表示，平衡細粒度和整體圖形資訊。此外，我們研究了一種早期查詢融合技術，它在建構圖形表示之前融合查詢內容，進而產生更有效的圖形嵌入。我們的方法在 GraphQA 基準上達到了 4.13% 的效能提升，而無需訓練大型語言模型，證明了在處理複雜的文字屬性圖形資料方面有顯著的進展。

##### **General Scene Adaptation for Vision-and-Language Navigation**
2501.17403v1 by Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu

Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on
one-time execution of individual instructions across multiple environments,
aiming to develop agents capable of functioning in any environment in a
zero-shot manner. However, real-world navigation robots often operate in
persistent environments with relatively consistent physical layouts, visual
observations, and language styles from instructors. Such a gap in the task
setting presents an opportunity to improve VLN agents by incorporating
continuous adaptation to specific environments. To better reflect these
real-world conditions, we introduce GSA-VLN, a novel task requiring agents to
execute navigation instructions within a specific scene and simultaneously
adapt to it for improved performance over time. To evaluate the proposed task,
one has to address two challenges in existing VLN datasets: the lack of OOD
data, and the limited number and style diversity of instructions for each
scene. Therefore, we propose a new dataset, GSA-R2R, which significantly
expands the diversity and quantity of environments and instructions for the R2R
dataset to evaluate agent adaptability in both ID and OOD contexts.
Furthermore, we design a three-stage instruction orchestration pipeline that
leverages LLMs to refine speaker-generated instructions and apply role-playing
techniques to rephrase instructions into different speaking styles. This is
motivated by the observation that each individual user often has consistent
signatures or preferences in their instructions. We conducted extensive
experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various
methods. Based on our findings, we propose a novel method, GR-DUET, which
incorporates memory-based navigation graphs with an environment-specific
training strategy, achieving state-of-the-art results on all GSA-R2R splits.

摘要：視覺語言導航 (VLN) 任務主要根據代理程式在多個環境中執行個別指令的一次性執行來評估代理程式，旨在開發能夠在任何環境中以零次學習的方式運作的代理程式。然而，真實世界的導航機器人通常在持續性的環境中運作，而這些環境具有相對一致的物理配置、視覺觀察和指令的語言風格。任務設定中的這種差距提供了一個機會，可以透過將連續適應特定環境納入其中來改善 VLN 代理程式。為了更好地反映這些真實世界的條件，我們推出了 GSA-VLN，這是一個新任務，要求代理程式在特定場景中執行導航指令，並同時適應該場景，以隨著時間推移而提高效能。為了評估所提出的任務，必須解決現有 VLN 資料集中的兩個挑戰：缺乏 OOD 資料，以及每個場景的指令數量和風格多樣性有限。因此，我們提出了一個新的資料集 GSA-R2R，它顯著擴展了 R2R 資料集的環境和指令的多樣性和數量，以評估代理程式在 ID 和 OOD 背景下的適應能力。此外，我們設計了一個三階段指令編排管道，該管道利用大型語言模型 (LLM) 來精煉由說話者產生的指令，並應用角色扮演技巧將指令改寫成不同的說話風格。這項技術的靈感來自於觀察到每個個別使用者通常在其指令中具有相符的簽名或偏好。我們針對 GSA-R2R 進行了大量的實驗，以徹底評估我們的資料集和基準各種方法。根據我們的研究結果，我們提出了一種新的方法 GR-DUET，它將基於記憶的導航圖表與特定於環境的訓練策略結合在一起，在所有 GSA-R2R 分割中取得了最先進的結果。

##### **Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**
2501.17270v1 by Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li

Question answering systems for knowledge graph (KGQA), answer factoid
questions based on the data in the knowledge graph. KGQA systems are complex
because the system has to understand the relations and entities in the
knowledge-seeking natural language queries and map them to structured queries
against the KG to answer them. In this paper, we introduce Chronos, a
comprehensive evaluation framework for KGQA at industry scale. It is designed
to evaluate such a multi-component system comprehensively, focusing on (1)
end-to-end and component-level metrics, (2) scalable to diverse datasets and
(3) a scalable approach to measure the performance of the system prior to
release. In this paper, we discuss the unique challenges associated with
evaluating KGQA systems at industry scale, review the design of Chronos, and
how it addresses these challenges. We will demonstrate how it provides a base
for data-driven decisions and discuss the challenges of using it to measure and
improve a real-world KGQA system.

摘要：知識圖譜問答系統 (KGQA) 根據知識圖譜中的資料回答事實問題。KGQA 系統很複雜，因為系統必須理解知識尋求自然語言查詢中的關係和實體，並將它們對映到針對知識圖譜的結構化查詢，才能回答這些查詢。在本文中，我們介紹了 Chronos，這是一個用於產業規模 KGQA 的全面評估框架。它旨在全面評估這種多組件系統，重點關注：(1) 端對端和組件層級指標，(2) 可擴充至各種資料集，以及 (3) 可擴充的方法，用於在釋出前衡量系統的效能。在本文中，我們討論了與產業規模 KGQA 系統評估相關的獨特挑戰，檢視 Chronos 的設計，以及它如何應對這些挑戰。我們將展示它如何提供資料驅動決策的基礎，並討論使用它來衡量和改善真實世界 KGQA 系統的挑戰。

##### **FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**
2501.17144v1 by Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng

Prior research on training grounded factuality classification models to
detect hallucinations in large language models (LLMs) has relied on public
natural language inference (NLI) data and synthetic data. However, conventional
NLI datasets are not well-suited for document-level reasoning, which is
critical for detecting LLM hallucinations. Recent approaches to document-level
synthetic data generation involve iteratively removing sentences from documents
and annotating factuality using LLM-based prompts. While effective, this method
is computationally expensive for long documents and limited by the LLM's
capabilities. In this work, we analyze the differences between existing
synthetic training data used in state-of-the-art models and real LLM output
claims. Based on our findings, we propose a novel approach for synthetic data
generation, CG2C, that leverages multi-hop reasoning on context graphs
extracted from documents. Our fact checker model, FactCG, demonstrates improved
performance with more connected reasoning, using the same backbone models.
Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark
with much smaller model size.

摘要：先前的研究訓練了基於事實的分類模型，以偵測大型語言模型 (LLM) 中的幻覺，依賴於公開的自然語言推論 (NLI) 資料和合成資料。然而，傳統的 NLI 資料集並不適合文件層級的推理，這對於偵測 LLM 的幻覺至關重要。最近的文件層級合成資料生成方法涉及從文件中反覆移除句子，並使用基於 LLM 的提示註解事實。雖然有效，但此方法對於長文件來說在運算上很昂貴，且受限於 LLM 的能力。在這項工作中，我們分析了現有合成訓練資料與最先進模型中使用的真實 LLM 輸出宣告之間的差異。根據我們的研究結果，我們提出了一個用於合成資料生成的創新方法 CG2C，它利用從文件中提取的內容圖表進行多跳推理。我們的查核模型 FactCG 使用相同的骨幹模型，展示了在更多連結的推理下改進的效能。實驗表明，它甚至在 LLM-Aggrefact 基準上優於 GPT-4-o，且模型大小小得多。

##### **LLM-AutoDiff: Auto-Differentiate Any LLM Workflow**
2501.16673v2 by Li Yin, Zhangyang Wang

Large Language Models (LLMs) have reshaped natural language processing,
powering applications from multi-hop retrieval and question answering to
autonomous agent workflows. Yet, prompt engineering -- the task of crafting
textual inputs to effectively direct LLMs -- remains difficult and
labor-intensive, particularly for complex pipelines that combine multiple LLM
calls with functional operations like retrieval and data formatting. We
introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering
(APE) that extends textual gradient-based methods (such as Text-Grad) to
multi-component, potentially cyclic LLM architectures. Implemented within the
AdalFlow library, LLM-AutoDiff treats each textual input as a trainable
parameter and uses a frozen backward engine LLM to generate feedback-akin to
textual gradients -- that guide iterative prompt updates. Unlike prior
single-node approaches, LLM-AutoDiff inherently accommodates functional nodes,
preserves time-sequential behavior in repeated calls (e.g., multi-hop loops),
and combats the "lost-in-the-middle" problem by isolating distinct sub-prompts
(instructions, formats, or few-shot examples). It further boosts training
efficiency by focusing on error-prone samples through selective gradient
computation. Across diverse tasks, including single-step classification,
multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff
consistently outperforms existing textual gradient baselines in both accuracy
and training cost. By unifying prompt optimization through a graph-centric
lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating
LLM workflows - mirroring the transformative role that automatic
differentiation libraries have long played in neural network research.

摘要：大型語言模型 (LLM) 已重塑自然語言處理，
為從多跳檢索和問答到
自主代理工作流程的應用提供動力。然而，提示工程 -- 編寫
文本輸入以有效指導 LLM 的任務 -- 仍然困難且
勞動密集，特別是對於將多個 LLM
呼叫與檢索和數據格式化等功能操作相結合的複雜管道。我們
介紹 LLM-AutoDiff：一個用於自動提示工程 (APE) 的新框架，它將基於文本梯度的
方法（例如 Text-Grad）擴展到多組件、潛在循環 LLM 架構中。在
AdalFlow 庫中實施，LLM-AutoDiff 將每個文本輸入視為一個可訓練
參數，並使用凍結的後向引擎 LLM 生成反饋——類似於
文本梯度——指導迭代提示更新。與先前的
單節點方法不同，LLM-AutoDiff 本質上適應功能節點，
在重複呼叫（例如，多跳循環）中保留時間順序行為，
並通過隔離不同的子提示（說明、格式或少數鏡頭示例）來解決“迷失在中間”問題。它進一步提高訓練
效率，通過選擇性梯度
計算專注於容易出錯的樣本。在包括單步分類、
多跳基於檢索的問答和代理驅動管道在內的各種任務中，LLM-AutoDiff
在準確性和訓練成本方面始終優於現有的文本梯度基準。通過圖形中心化
視角統一提示優化，LLM-AutoDiff 為擴展和自動化
LLM 工作流程提供了一個強大的新範例——反映了自動
微分庫在神經網絡研究中長期扮演的變革性角色。

##### **360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation**
2501.16450v2 by Hamed Firooz, Maziar Sanjabi, Adrian Englhardt, Aman Gupta, Ben Levine, Dre Olgiati, Gungor Polatkan, Iuliia Melnychuk, Karthik Ramgopal, Kirill Talanine, Kutta Srinivasan, Luke Simon, Natesh Sivasubramoniapillai, Necip Fazil Ayan, Qingquan Song, Samira Sriram, Souvik Ghosh, Tao Song, Vignesh Kothapalli, Xiaoling Zhai, Ya Xu, Yu Wang, Yun Dai

Ranking and recommendation systems are the foundation for numerous online
experiences, ranging from search results to personalized content delivery.
These systems have evolved into complex, multilayered architectures that
leverage vast datasets and often incorporate thousands of predictive models.
The maintenance and enhancement of these models is a labor intensive process
that requires extensive feature engineering. This approach not only exacerbates
technical debt but also hampers innovation in extending these systems to
emerging problem domains. In this report, we present our research to address
these challenges by utilizing a large foundation model with a textual interface
for ranking and recommendation tasks. We illustrate several key advantages of
our approach: (1) a single model can manage multiple predictive tasks involved
in ranking and recommendation, (2) decoder models with textual interface due to
their comprehension of reasoning capabilities, can generalize to new
recommendation surfaces and out-of-domain problems, and (3) by employing
natural language interfaces for task definitions and verbalizing member
behaviors and their social connections, we eliminate the need for feature
engineering and the maintenance of complex directed acyclic graphs of model
dependencies. We introduce our research pre-production model, 360Brew V1.0, a
150B parameter, decoder-only model that has been trained and fine-tuned on
LinkedIn's data and tasks. This model is capable of solving over 30 predictive
tasks across various segments of the LinkedIn platform, achieving performance
levels comparable to or exceeding those of current production systems based on
offline metrics, without task-specific fine-tuning. Notably, each of these
tasks is conventionally addressed by dedicated models that have been developed
and maintained over multiple years by teams of a similar or larger size than
our own.

摘要：排名和推薦系統是許多線上體驗的基礎，從搜尋結果到個人化內容傳遞。這些系統已演變成複雜的多層架構，利用大量的資料集，並經常整合數千個預測模型。這些模型的維護和增強是一個勞力密集的過程，需要廣泛的特徵工程。這種方法不僅會加劇技術債務，還會阻礙將這些系統擴展到新興問題領域的創新。在本文中，我們介紹我們的研究，以利用具有文本介面的大型基礎模型來解決這些挑戰，以進行排名和推薦任務。我們說明了我們方法的幾個主要優點：(1) 單一模型可以管理排名和推薦中涉及的多個預測任務，(2) 由於其對推理能力的理解，具有文本介面的解碼器模型可以概括到新的推薦表面和領域外問題，以及 (3) 通過採用自然語言介面進行任務定義和表達成員行為及其社交連結，我們消除了對特徵工程和維護複雜的模型相依關係的有向無環圖的需求。我們介紹了我們的研究前置生產模型 360Brew V1.0，一個經過在 LinkedIn 的資料和任務上訓練和微調的 150B 參數、僅解碼器模型。此模型能夠解決 LinkedIn 平台各個區塊中超過 30 個預測任務，在不進行特定任務微調的情況下，達到與基於離線指標的現行生產系統相當或超越的效能等級。值得注意的是，這些任務中的每一個通常都由專用模型處理，這些模型是由與我們規模相當或更大的團隊在多年間開發和維護的。

##### **Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs**
2501.16191v1 by Antony Bartlett, Cynthia Liem, Annibale Panichella

Fixing Python dependency issues is a tedious and error-prone task for
developers, who must manually identify and resolve environment dependencies and
version constraints of third-party modules and Python interpreters. Researchers
have attempted to automate this process by relying on large knowledge graphs
and database lookup tables. However, these traditional approaches face
limitations due to the variety of dependency error types, large sets of
possible module versions, and conflicts among transitive dependencies. This
study explores the potential of using large language models (LLMs) to
automatically fix dependency issues in Python programs. We introduce PLLM
(pronounced "plum"), a novel technique that employs retrieval-augmented
generation (RAG) to help an LLM infer Python versions and required modules for
a given Python file. PLLM builds a testing environment that iteratively (1)
prompts the LLM for module combinations, (2) tests the suggested changes, and
(3) provides feedback (error messages) to the LLM to refine the fix. This
feedback cycle leverages natural language processing (NLP) to intelligently
parse and interpret build error messages. We benchmark PLLM on the Gistable
HG2.9K dataset, a collection of challenging single-file Python gists. We
compare PLLM against two state-of-the-art automatic dependency inference
approaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependency
issues. Our results indicate that PLLM can fix more dependency issues than the
two baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)
over PyEGo. Our deeper analyses suggest that PLLM is particularly beneficial
for projects with many dependencies and for specific third-party numerical and
machine-learning modules. Our findings demonstrate the potential of LLM-based
approaches to iteratively resolve Python dependency issues.

摘要：<paragraph>修復 Python 依賴項問題對開發人員來說是一項繁瑣且容易出錯的任務，他們必須手動識別和解決第三方模組和 Python 解譯器的環境依賴項和版本限制。研究人員已嘗試透過依賴大型知識圖譜和資料庫查詢表來自動化此程序。然而，這些傳統方法由於依賴項錯誤類型多樣、可能的模組版本數量龐大，以及傳遞依賴項之間的衝突，而面臨限制。本研究探討使用大型語言模型 (LLM) 自動修復 Python 程式中的依賴項問題的可能性。我們介紹 PLLM（發音為「plum」），這是一種新穎的技術，採用檢索增強生成 (RAG) 來協助 LLM 推論 Python 版本和給定 Python 檔案所需的模組。PLLM 建立一個測試環境，反覆 (1) 提示 LLM 模組組合，(2) 測試建議的變更，以及 (3) 提供回饋（錯誤訊息）給 LLM 以改善修正。此回饋循環利用自然語言處理 (NLP) 來智慧解析和詮釋建置錯誤訊息。我們在 Gistable HG2.9K 資料集上對 PLLM 進行基準測試，該資料集是一個具有挑戰性的單一檔案 Python gist 集合。我們將 PLLM 與兩種最先進的自動依賴項推論方法進行比較，即 PyEGo 和 ReadPyE，以比較解決依賴項問題的能力。我們的結果顯示，PLLM 可以修復比這兩個基準更多的依賴項問題，比 ReadPyE 多修復了 +218 (+15.97%) 個，比 PyEGo 多修復了 +281 (+21.58%) 個。我們更深入的分析表明，PLLM 對具有許多依賴項的專案以及特定第三方數值和機器學習模組特別有益。我們的研究結果證明了基於 LLM 的方法反覆解決 Python 依賴項問題的可能性。</paragraph>

##### **Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs**
2501.15791v1 by Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu

Knowledge graphs are widely used in industrial applications, making error
detection crucial for ensuring the reliability of downstream applications.
Existing error detection methods often fail to effectively leverage
fine-grained subgraph information and rely solely on fixed graph structures,
while also lacking transparency in their decision-making processes, which
results in suboptimal detection performance. In this paper, we propose a novel
Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that
utilizes multiple large language models (LLMs) in a collaborative setting. By
concatenating fine-grained, bidirectional subgraph embeddings with LLM-based
query embeddings during training, our framework integrates these
representations to produce four specialized agents. These agents utilize
subgraph information from different dimensions to engage in multi-round
discussions, thereby improving error detection accuracy and ensuring a
transparent decision-making process. Extensive experiments on FB15K and WN18RR
demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the
accuracy and robustness of KG evaluation. For specific industrial scenarios,
our framework can facilitate the training of specialized agents using
domain-specific knowledge graphs for error detection, which highlights the
potential industrial application value of our framework. Our code and datasets
are available at https://github.com/kse-ElEvEn/MAKGED.

摘要：知識圖譜廣泛應用於工業應用中，使得錯誤偵測對於確保下游應用的可靠性至關重要。現有的錯誤偵測方法通常無法有效利用細粒度的子圖資訊，並且僅依賴於固定的圖形結構，同時在它們的決策過程中也缺乏透明度，這導致次佳的偵測效能。在本文中，我們提出了一個用於知識圖譜錯誤偵測 (MAKGED) 的新多代理架構，它在協作設定中利用了多個大型語言模型 (LLM)。透過在訓練期間將細粒度、雙向子圖嵌入與基於 LLM 的查詢嵌入串接，我們的架構整合了這些表示以產生四個專門代理。這些代理利用不同維度的子圖資訊參與多輪討論，從而提高錯誤偵測準確度並確保透明的決策過程。在 FB15K 和 WN18RR 上的廣泛實驗表明，MAKGED 優於最先進的方法，增強了 KG 評估的準確性和穩健性。對於特定產業情境，我們的架構可以利用特定領域的知識圖譜來促進專門代理的訓練以進行錯誤偵測，這突顯了我們架構的潛在產業應用價值。我們的程式碼和資料集可在 https://github.com/kse-ElEvEn/MAKGED 取得。

##### **Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs**
2501.15777v1 by Momoka Furuhashi, Hiroaki Funayama, Yuya Iwase, Yuichiroh Matsubayashi, Yoriko Isobe, Toru Nagahama, Saku Sugawara, Kentaro Inui

Short-reading comprehension questions help students understand text structure
but lack effective feedback. Students struggle to identify and correct errors,
while manual feedback creation is labor-intensive. This highlights the need for
automated feedback linking responses to a scoring rubric for deeper
comprehension.
  Despite advances in Natural Language Processing (NLP), research has focused
on automatic grading, with limited work on feedback generation. To address
this, we propose a system that generates feedback for student responses.
  Our contributions are twofold. First, we introduce the first system for
feedback on short-answer reading comprehension. These answers are derived from
the text, requiring structural understanding. We propose an "answer diagnosis
graph," integrating the text's logical structure with feedback templates. Using
this graph and NLP techniques, we estimate students' comprehension and generate
targeted feedback.
  Second, we evaluate our feedback through an experiment with Japanese high
school students (n=39). They answered two 70-80 word questions and were divided
into two groups with minimal academic differences. One received a model answer,
the other system-generated feedback. Both re-answered the questions, and we
compared score changes. A questionnaire assessed perceptions and motivation.
  Results showed no significant score improvement between groups, but
system-generated feedback helped students identify errors and key points in the
text. It also significantly increased motivation. However, further refinement
is needed to enhance text structure understanding.

摘要：短篇閱讀理解題目有助學生理解文章結構，但缺乏有效的回饋。學生難以找出並更正錯誤，而手動建立回饋又很費力。這突顯了自動化回饋的必要性，將回應連結到評分標準，以獲得更深入的理解。

儘管自然語言處理 (NLP) 有所進展，但研究一直集中在自動評分上，而回饋生成的工作有限。為了解決這個問題，我們提出了一個系統，用於為學生的回答產生回饋。

我們的貢獻有兩個方面。首先，我們引入了第一個針對簡答閱讀理解提供回饋的系統。這些答案來自於文本，需要結構化的理解。我們提出了一個「答案診斷圖」，將文本的邏輯結構與回饋範本整合在一起。使用這個圖表和 NLP 技術，我們估計學生的理解力並產生有針對性的回饋。

其次，我們透過一項針對日本高中生的實驗（n=39）來評估我們的回饋。他們回答了兩個 70-80 字的問題，並被分成兩組，學術差異最小。一組收到範本答案，另一組收到系統產生的回饋。兩組都重新回答了問題，我們比較了分數的變化。一份問卷評估了認知和動機。

結果顯示兩組之間沒有顯著的分數進步，但系統產生的回饋有助於學生找出文本中的錯誤和重點。它也顯著地提高了動機。然而，需要進一步的改進來增強對文本結構的理解。

##### **Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts**
2501.15688v1 by Haodi Ma, Dzmitry Kasinets, Daisy Zhe Wang

Multimodal knowledge graph completion (MMKGC) aims to predict missing links
in multimodal knowledge graphs (MMKGs) by leveraging information from various
modalities alongside structural data. Existing MMKGC approaches primarily
extend traditional knowledge graph embedding (KGE) models, which often require
creating an embedding for every entity. This results in large model sizes and
inefficiencies in integrating multimodal information, particularly for
real-world graphs. Meanwhile, Transformer-based models have demonstrated
competitive performance in knowledge graph completion (KGC). However, their
focus on single-modal knowledge limits their capacity to utilize cross-modal
information. Recently, Large vision-language models (VLMs) have shown potential
in cross-modal tasks but are constrained by the high cost of training. In this
work, we propose a novel approach that integrates Transformer-based KGE models
with cross-modal context generated by pre-trained VLMs, thereby extending their
applicability to MMKGC. Specifically, we employ a pre-trained VLM to transform
relevant visual information from entities and their neighbors into textual
sequences. We then frame KGC as a sequence-to-sequence task, fine-tuning the
model with the generated cross-modal context. This simple yet effective method
significantly reduces model size compared to traditional KGE approaches while
achieving competitive performance across multiple large-scale datasets with
minimal hyperparameter tuning.

摘要：多模態知識圖譜補全 (MMKGC) 旨在透過利用來自各種模態與結構化資料的資訊，來預測多模態知識圖譜 (MMKG) 中的缺失連結。現有的 MMKGC 方法主要擴充傳統的知識圖譜嵌入 (KGE) 模型，這些模型通常需要為每個實體建立一個嵌入。這會導致模型尺寸過大，且在整合多模態資訊時效率低下，特別是對於真實世界的圖譜。與此同時，基於 Transformer 的模型已在知識圖譜補全 (KGC) 中展現出競爭力。然而，它們著重於單模態知識，限制了它們利用跨模態資訊的能力。最近，大型視覺語言模型 (VLM) 已在跨模態任務中展現潛力，但受限於訓練成本過高。在這項工作中，我們提出了一種創新的方法，它將基於 Transformer 的 KGE 模型與預先訓練的 VLM 所產生的跨模態內容整合在一起，從而擴展它們在 MMKGC 中的適用性。具體來說，我們採用預先訓練的 VLM，將實體及其鄰居相關的視覺資訊轉換成文字序列。然後，我們將 KGC 架構成一個序列到序列的任務，並使用產生的跨模態內容微調模型。這種簡單但有效的方法，與傳統的 KGE 方法相比，大幅減少了模型尺寸，同時在多個大型資料集上達到了競爭力的效能，且只需最少的超參數調整。

##### **How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback**
2501.15378v1 by Manzong Huang, Chenyang Bu, Yi He, Xindong Wu

Knowledge Graph (KG)-augmented Large Language Models (LLMs) have recently
propelled significant advances in complex reasoning tasks, thanks to their
broad domain knowledge and contextual awareness. Unfortunately, current methods
often assume KGs to be complete, which is impractical given the inherent
limitations of KG construction and the potential loss of contextual cues when
converting unstructured text into entity-relation triples. In response, this
paper proposes the Triple Context Restoration and Query-driven Feedback
(TCR-QF) framework, which reconstructs the textual context underlying each
triple to mitigate information loss, while dynamically refining the KG
structure by iteratively incorporating query-relevant missing knowledge.
Experiments on five benchmark question-answering datasets substantiate the
effectiveness of TCR-QF in KG and LLM integration, where itachieves a 29.1%
improvement in Exact Match and a 15.5% improvement in F1 over its
state-of-the-art GraphRAG competitors.

摘要：知識圖譜 (KG) 增強大型語言模型 (LLM) 最近推動複雜推理任務的重大進展，這要歸功於它們廣泛的領域知識和語境感知。不幸的是，目前的模型通常假設 KG 是完整的，這在考慮到 KG 建構的固有限制和在將非結構化文字轉換為實體關係三元組時潛在的語境線索損失時是不切實際的。為了解決這個問題，本文提出了三元組語境還原和查詢驅動回饋 (TCR-QF) 架構，它重建每個三元組底層的文字語境以減輕資訊損失，同時透過反覆納入與查詢相關的遺失知識來動態優化 KG 結構。在五個基準問題回答資料集上的實驗證實了 TCR-QF 在 KG 和 LLM 整合方面的有效性，它在 Exact Match 中獲得 29.1% 的改進，在 F1 中獲得 15.5% 的改進，優於最先進的 GraphRAG 競爭對手。

##### **Explaining Categorical Feature Interactions Using Graph Covariance and LLMs**
2501.14932v1 by Cencheng Shen, Darren Edge, Jonathan Larson, Carey E. Priebe

Modern datasets often consist of numerous samples with abundant features and
associated timestamps. Analyzing such datasets to uncover underlying events
typically requires complex statistical methods and substantial domain
expertise. A notable example, and the primary data focus of this paper, is the
global synthetic dataset from the Counter Trafficking Data Collaborative (CTDC)
-- a global hub of human trafficking data containing over 200,000 anonymized
records spanning from 2002 to 2022, with numerous categorical features for each
record. In this paper, we propose a fast and scalable method for analyzing and
extracting significant categorical feature interactions, and querying large
language models (LLMs) to generate data-driven insights that explain these
interactions. Our approach begins with a binarization step for categorical
features using one-hot encoding, followed by the computation of graph
covariance at each time. This graph covariance quantifies temporal changes in
dependence structures within categorical data and is established as a
consistent dependence measure under the Bernoulli distribution. We use this
measure to identify significant feature pairs, such as those with the most
frequent trends over time or those exhibiting sudden spikes in dependence at
specific moments. These extracted feature pairs, along with their timestamps,
are subsequently passed to an LLM tasked with generating potential explanations
of the underlying events driving these dependence changes. The effectiveness of
our method is demonstrated through extensive simulations, and its application
to the CTDC dataset reveals meaningful feature pairs and potential data stories
underlying the observed feature interactions.

摘要：現代資料集通常包含許多具有豐富特徵和關聯時間戳的樣本。分析此類資料集以揭示底層事件通常需要複雜的統計方法和大量的領域專業知識。一個值得注意的範例，也是本文的主要資料重點，是來自反人口販運資料合作組織 (CTDC) 的全球合成資料集，這是全球人口販運資料的樞紐，包含超過 200,000 筆從 2002 年到 2022 年的匿名記錄，每個記錄都有許多分類特徵。在本文中，我們提出了一種快速且可擴充的方法，用於分析和提取重要的分類特徵交互作用，並查詢大型語言模型 (LLM)，以產生資料驅動的見解來解釋這些交互作用。我們的做法從使用獨熱編碼對分類特徵進行二元化步驟開始，然後在每個時間點計算圖形共變異數。此圖形共變異數量化了分類資料中依賴結構的時間變化，並在伯努利分佈下建立為一致的依賴度量。我們使用此度量來識別重要的特徵對，例如隨時間推移趨勢最頻繁的特徵對，或在特定時刻表現出依賴性突然激增的特徵對。這些提取的特徵對及其時間戳隨後傳遞給 LLM，後者負責產生對驅動這些依賴性變化的底層事件的潛在解釋。我們的方法的有效性已通過廣泛的模擬得到證明，其在 CTDC 資料集中的應用揭示了有意義的特徵對和潛在的資料故事，這些故事是觀察到的特徵交互作用的基礎。

##### **Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs**
2501.14892v1 by Hang Luo, Jian Zhang, Chujun Li

In knowledge-intensive tasks, especially in high-stakes domains like medicine
and law, it is critical not only to retrieve relevant information but also to
provide causal reasoning and explainability. Large language models (LLMs) have
achieved remarkable performance in natural language understanding and
generation tasks. However, they often suffer from limitations such as
difficulty in incorporating new knowledge, generating hallucinations, and
explaining their reasoning process. To address these challenges, integrating
knowledge graphs with Graph Retrieval-Augmented Generation (Graph RAG) has
emerged as an effective solution. Traditional Graph RAG methods often rely on
simple graph traversal or semantic similarity, which do not capture causal
relationships or align well with the model's internal reasoning steps. This
paper proposes a novel pipeline that filters large knowledge graphs to
emphasize cause-effect edges, aligns the retrieval process with the model's
chain-of-thought (CoT), and enhances reasoning through multi-stage path
improvements. Experiments on medical question-answering tasks show consistent
gains, with up to a 10\% absolute improvement across multiple large language
models (LLMs). This approach demonstrates the value of combining causal
reasoning with stepwise retrieval, leading to more interpretable and logically
grounded solutions for complex queries.

摘要：在知識密集型任務中，特別是在醫學和法律等高風險領域，不僅檢索相關資訊至關重要，還必須提供因果推理和可解釋性。大型語言模型 (LLM) 在自然語言理解和生成任務中取得了顯著的表現。然而，它們通常會遇到一些限制，例如難以納入新知識、產生幻覺，以及解釋其推理過程。為了應對這些挑戰，將知識圖與圖形檢索增強生成 (Graph RAG) 整合在一起已成為一種有效的解決方案。傳統的 Graph RAG 方法通常依賴於簡單的圖形遍歷或語義相似性，這無法捕捉因果關係或與模型的內部推理步驟很好地對齊。本文提出了一個新穎的管道，該管道過濾大型知識圖以強調因果邊緣，將檢索過程與模型的思想鏈 (CoT) 對齊，並通過多階段路徑改進來增強推理。在醫療問題解答任務上的實驗顯示出一致的收益，在多個大型語言模型 (LLM) 中絕對改進幅度高達 10%。這種方法展示了將因果推理與逐步檢索相結合的價值，從而為複雜查詢提供更具可解釋性和邏輯依據的解決方案。

##### **GraPPI: A Retrieve-Divide-Solve GraphRAG Framework for Large-scale Protein-protein Interaction Exploration**
2501.16382v1 by Ziwen Li, Xiang 'Anthony' Chen, Youngseung Jeon

Drug discovery (DD) has tremendously contributed to maintaining and improving
public health. Hypothesizing that inhibiting protein misfolding can slow
disease progression, researchers focus on target identification (Target ID) to
find protein structures for drug binding. While Large Language Models (LLMs)
and Retrieval-Augmented Generation (RAG) frameworks have accelerated drug
discovery, integrating models into cohesive workflows remains challenging. We
conducted a user study with drug discovery researchers to identify the
applicability of LLMs and RAGs in Target ID. We identified two main findings:
1) an LLM should provide multiple Protein-Protein Interactions (PPIs) based on
an initial protein and protein candidates that have a therapeutic impact; 2)
the model must provide the PPI and relevant explanations for better
understanding. Based on these observations, we identified three limitations in
previous approaches for Target ID: 1) semantic ambiguity, 2) lack of
explainability, and 3) short retrieval units. To address these issues, we
propose GraPPI, a large-scale knowledge graph (KG)-based retrieve-divide-solve
agent pipeline RAG framework to support large-scale PPI signaling pathway
exploration in understanding therapeutic impacts by decomposing the analysis of
entire PPI pathways into sub-tasks focused on the analysis of PPI edges.

摘要：药物发现 (DD) 极大地促进了公共卫生的维护和改善。研究人员假设抑制蛋白质错误折叠可以减缓疾病进展，因此专注于靶点识别 (Target ID) 以找到用于药物结合的蛋白质结构。虽然大型语言模型 (LLM) 和检索增强生成 (RAG) 框架加速了药物发现，但将模型整合到内聚工作流中仍然具有挑战性。我们与药物发现研究人员进行了一项用户研究，以确定 LLM 和 RAG 在 Target ID 中的适用性。我们确定了两个主要发现：1) LLM 应该基于初始蛋白质和具有治疗作用的蛋白质候选物提供多个蛋白质-蛋白质相互作用 (PPI)；2) 该模型必须提供 PPI 和相关解释以更好地理解。基于这些观察，我们发现了先前 Target ID 方法中的三个局限性：1) 语义歧义，2) 缺乏可解释性，3) 检索单元短。为了解决这些问题，我们提出了 GraPPI，这是一种基于大规模知识图 (KG) 的检索-分解-求解代理管道 RAG 框架，以支持大规模 PPI 信号通路探索，通过将整个 PPI 通路的分析分解为专注于 PPI 边缘分析的子任务来理解治疗影响。

##### **Evaluating and Improving Graph to Text Generation with Large Language Models**
2501.14497v1 by Jie He, Yijun Yang, Wanqiu Long, Deyi Xiong, Victor Gutierrez Basulto, Jeff Z. Pan

Large language models (LLMs) have demonstrated immense potential across
various tasks. However, research for exploring and improving the capabilities
of LLMs in interpreting graph structures remains limited. To address this gap,
we conduct a comprehensive evaluation of prompting current open-source LLMs on
graph-to-text generation tasks. Although we explored the optimal prompting
strategies and proposed a novel and effective diversity-difficulty-based
few-shot sample selection method, we found that the improvements from
tuning-free approaches were incremental, as LLMs struggle with planning on
complex graphs, particularly those with a larger number of triplets. To further
improve LLMs in planning with graph sequences and grounding in truth, we
introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks:
reordering and attribution. Through extensive automatic and human evaluations,
we demonstrate significant improvements in the quality of generated text from
both few-shot learning and fine-tuning perspectives using the PlanGTG dataset.
Our study paves the way for new research directions in graph-to-text
generation. PlanGTG datasets can be found in https://github.com/probe2/kg_text.

摘要：大型語言模型（LLM）已在各種任務中展現出巨大的潛力。然而，探索和提升 LLM 在詮釋圖形結構方面的能力的研究仍然有限。為了解決這個差距，我們對提示目前開源的 LLM 執行圖形轉文字生成任務進行全面評估。儘管我們探索了最佳提示策略並提出了一種新穎且有效的基於多樣性難度的少樣本選擇方法，但我們發現無調校方法的改進是漸進的，因為 LLM 難以規劃複雜的圖形，特別是那些具有較多三元組的圖形。為了進一步提升 LLM 在圖形序列規劃和真實依據方面的能力，我們引入了一個新的圖形轉文字資料集 PlanGTG，並註解了兩個子任務：重新排序和歸因。透過廣泛的自動化和人工評估，我們證明了使用 PlanGTG 資料集從少樣本學習和微調角度產生文字的品質有顯著提升。我們的研究為圖形轉文字生成中的新研究方向鋪路。PlanGTG 資料集可以在 https://github.com/probe2/kg_text 中找到。

##### **Fast Think-on-Graph: Wider, Deeper and Faster Reasoning of Large Language Model on Knowledge Graph**
2501.14300v1 by Xujian Liang, Zhaoquan Gu

Graph Retrieval Augmented Generation (GRAG) is a novel paradigm that takes
the naive RAG system a step further by integrating graph information, such as
knowledge graph (KGs), into large-scale language models (LLMs) to mitigate
hallucination. However, existing GRAG still encounter limitations: 1) simple
paradigms usually fail with the complex problems due to the narrow and shallow
correlations capture from KGs 2) methods of strong coupling with KGs tend to be
high computation cost and time consuming if the graph is dense. In this paper,
we propose the Fast Think-on-Graph (FastToG), an innovative paradigm for
enabling LLMs to think ``community by community" within KGs. To do this,
FastToG employs community detection for deeper correlation capture and two
stages community pruning - coarse and fine pruning for faster retrieval.
Furthermore, we also develop two Community-to-Text methods to convert the graph
structure of communities into textual form for better understanding by LLMs.
Experimental results demonstrate the effectiveness of FastToG, showcasing
higher accuracy, faster reasoning, and better explainability compared to the
previous works.

摘要：圖表檢索增強生成 (GRAG) 是一種新穎的範例，它透過將圖表資訊（例如知識圖表 (KG)) 整合到大型語言模型 (LLM) 中，進一步提升了樸素的 RAG 系統以減輕幻覺。然而，現有的 GRAG 仍會遇到限制：1) 簡單的範例通常會因從 KG 中擷取的關聯性狹隘且淺薄而無法解決複雜的問題 2) 如果圖表很密集，與 KG 強耦合的方法往往會導致高運算成本和耗時。在本文中，我們提出了 Fast Think-on-Graph (FastToG)，這是一種創新的範例，可讓 LLM 在 KG 中「逐個社群」進行思考。為此，FastToG 使用社群偵測來擷取更深入的關聯性，並使用兩個階段的社群修剪（粗略修剪和精細修剪）來加快檢索速度。此外，我們還開發了兩種社群到文字的方法，將社群的圖表結構轉換為文字形式，以便 LLM 更容易理解。實驗結果證明了 FastToG 的有效性，與先前的研究相比，展示出更高的準確性、更快的推理速度和更好的可解釋性。

##### **Top Ten Challenges Towards Agentic Neural Graph Databases**
2501.14224v1 by Jiaxin Bai, Zihao Wang, Yukun Zhou, Hang Yin, Weizhi Fei, Qi Hu, Zheye Deng, Jiayang Cheng, Tianshi Zheng, Hong Ting Tsang, Yisen Gao, Zhongwei Xie, Yufei Li, Lixin Fan, Binhang Yuan, Wei Wang, Lei Chen, Xiaofang Zhou, Yangqiu Song

Graph databases (GDBs) like Neo4j and TigerGraph excel at handling
interconnected data but lack advanced inference capabilities. Neural Graph
Databases (NGDBs) address this by integrating Graph Neural Networks (GNNs) for
predictive analysis and reasoning over incomplete or noisy data. However, NGDBs
rely on predefined queries and lack autonomy and adaptability. This paper
introduces Agentic Neural Graph Databases (Agentic NGDBs), which extend NGDBs
with three core functionalities: autonomous query construction, neural query
execution, and continuous learning. We identify ten key challenges in realizing
Agentic NGDBs: semantic unit representation, abductive reasoning, scalable
query execution, and integration with foundation models like large language
models (LLMs). By addressing these challenges, Agentic NGDBs can enable
intelligent, self-improving systems for modern data-driven applications, paving
the way for adaptable and autonomous data management solutions.

摘要：圖形資料庫（GDB），例如 Neo4j 和 TigerGraph，擅長處理相互連接的資料，但缺乏進階的推論能力。神經圖形資料庫（NGDB）透過整合圖形神經網路（GNN）來解決這個問題，以進行預測分析和對不完整或有雜訊的資料進行推理。然而，NGDB 依賴於預先定義的查詢，並且缺乏自主性和適應性。本文介紹了代理神經圖形資料庫（Agentic NGDB），它以三項核心功能擴充了 NGDB：自動查詢建構、神經查詢執行和持續學習。我們找出實現 Agentic NGDB 的十大關鍵挑戰：語義單元表示、演繹推理、可擴充查詢執行，以及與基礎模型（例如大型語言模型 (LLM)）整合。透過解決這些挑戰，Agentic NGDB 可以為現代資料驅動應用打造智慧且自我改善的系統，為適應性和自主資料管理解決方案鋪路。

##### **GraphRAG under Fire**
2501.14050v1 by Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang

GraphRAG advances retrieval-augmented generation (RAG) by structuring
external knowledge as multi-scale knowledge graphs, enabling language models to
integrate both broad context and granular details in their reasoning. While
GraphRAG has demonstrated success across domains, its security implications
remain largely unexplored. To bridge this gap, this work examines GraphRAG's
vulnerability to poisoning attacks, uncovering an intriguing security paradox:
compared to conventional RAG, GraphRAG's graph-based indexing and retrieval
enhance resilience against simple poisoning attacks; meanwhile, the same
features also create new attack surfaces. We present GRAGPoison, a novel attack
that exploits shared relations in the knowledge graph to craft poisoning text
capable of compromising multiple queries simultaneously. GRAGPoison employs
three key strategies: i) relation injection to introduce false knowledge, ii)
relation enhancement to amplify poisoning influence, and iii) narrative
generation to embed malicious content within coherent text. Empirical
evaluation across diverse datasets and models shows that GRAGPoison
substantially outperforms existing attacks in terms of effectiveness (up to 98%
success rate) and scalability (using less than 68% poisoning text). We also
explore potential defensive measures and their limitations, identifying
promising directions for future research.

摘要：GraphRAG 透過將外部知識結構化為多尺度知識圖譜，推動了檢索增強生成 (RAG)，使語言模型能夠在其推理中整合廣泛的背景和細微的細節。儘管 GraphRAG 在各個領域都已展現出成功，但其安全性影響在很大程度上仍未被探索。為了彌補這一差距，本研究探討了 GraphRAG 對投毒攻擊的脆弱性，揭示了一個有趣的安全悖論：與傳統的 RAG 相比，GraphRAG 基於圖表的索引和檢索增強了對簡單投毒攻擊的韌性；同時，相同的特徵也創造了新的攻擊面。我們提出了 GRAGPoison，這是一種新穎的攻擊，它利用知識圖譜中的共享關係來製作中毒文本，能夠同時危害多個查詢。GRAGPoison 採用了三項關鍵策略：i) 關係注入以引入錯誤的知識，ii) 關係增強以擴大投毒影響，以及 iii) 敘事生成以將惡意內容嵌入連貫的文本中。在各種數據集和模型上的經驗評估表明，GRAGPoison 在有效性（成功率高達 98%）和可擴展性（使用不到 68% 的投毒文本）方面都明顯優於現有的攻擊。我們還探討了潛在的防禦措施及其局限性，確定了未來研究的有希望的方向。

##### **EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**
2501.13746v1 by Yuhui Yun, Huilong Ye, Xinru Li, Ruojia Li, Jingfeng Deng, Li Li, Haoyi Xiong

The paper introduces EICopilot, an novel agent-based solution enhancing
search and exploration of enterprise registration data within extensive online
knowledge graphs like those detailing legal entities, registered capital, and
major shareholders. Traditional methods necessitate text-based queries and
manual subgraph explorations, often resulting in time-consuming processes.
EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this
landscape by utilizing Large Language Models (LLMs) to interpret natural
language queries. This solution automatically generates and executes Gremlin
scripts, providing efficient summaries of complex enterprise relationships.
Distinct feature a data pre-processing pipeline that compiles and annotates
representative queries into a vector database of examples for In-context
learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought
with ICL to enhance Gremlin script generation for knowledge graph search and
exploration, and a novel query masking strategy that improves intent
recognition for heightened script accuracy. Empirical evaluations demonstrate
the superior performance of EICopilot, including speed and accuracy, over
baseline methods, with the \emph{Full Mask} variant achieving a syntax error
rate reduction to as low as 10.00% and an execution correctness of up to
82.14%. These components collectively contribute to superior querying
capabilities and summarization of intricate datasets, positioning EICopilot as
a groundbreaking tool in the exploration and exploitation of large-scale
knowledge graphs for enterprise information search.

摘要：本文介紹了 EICopilot，這是一種基於代理的新型解決方案，可增強在廣泛的線上知識圖譜中搜尋和探索企業註冊資料，例如詳細說明法律實體、註冊資本和主要股東的資料。傳統方法需要基於文字的查詢和手動子圖探索，通常會導致耗時的流程。EICopilot 部署為百度企業搜尋的聊天機器人，透過利用大型語言模型 (LLM) 來詮釋自然語言查詢，進而改善這項技術。此解決方案會自動產生並執行 Gremlin 腳本，提供複雜企業關係的有效摘要。其獨特功能為資料前處理管線，可將具代表性的查詢編譯並註解到範例的向量資料庫中，以進行脈絡中學習 (ICL)，這是一個結合了思考鏈與 ICL 的綜合推理管線，用於增強 Gremlin 腳本產生，以進行知識圖譜搜尋和探索，以及一種新穎的查詢遮罩策略，可改善意圖辨識，進而提高腳本準確度。實證評估顯示，EICopilot 的效能優於基線方法，包括速度和準確度，其中「完整遮罩」變體將語法錯誤率降低至低於 10.00%，執行正確率高達 82.14%。這些元件共同促成了優異的查詢功能和複雜資料集的摘要，將 EICopilot 定位為探索和利用大規模知識圖譜進行企業資訊搜尋的創新工具。

##### **Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**
2501.13731v1 by Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng

Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.

摘要：圖表計算任務本質上具有挑戰性，而且通常需要開發先進的演算法才能有效解決。隨著大型語言模型 (LLM) 的出現，研究人員已開始探討其解決這些任務的可能性。然而，現有方法受到 LLM 理解複雜圖形結構的能力有限以及其高推理成本的限制，這使得它們不切實際地處理大規模圖形。受到人類解決圖形問題的方法啟發，我們引入了 PIE（偽代碼注入增強 LLM 圖形計算任務推理）這個新框架，它包含三個關鍵步驟：問題理解、提示設計和代碼生成。在此框架中，LLM 的任務是理解問題並擷取相關資訊以產生正確的代碼。分析圖形結構和執行代碼的責任委派給解釋器。我們將與任務相關的偽代碼注入提示中，以進一步協助 LLM 產生有效的代碼。我們還採用具有成本效益的試錯技術，以確保 LLM 生成的代碼正確執行。與需要為每個個別測試案例呼叫 LLM 的其他方法不同，PIE 僅在代碼產生階段呼叫 LLM，允許重複使用產生的代碼並大幅降低推理成本。大量的實驗證明，PIE 在準確性和計算效率方面都優於現有的基準。

##### **CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation**
2501.13993v1 by Hamza Landolsi, Kais Letaief, Nizar Taghouti, Ines Abdeljaoued-Tej

The introduction of new features and services in the banking sector often
overwhelms customers, creating an opportunity for banks to enhance user
experience through financial chatbots powered by large language models (LLMs).
We initiated an AI agent designed to provide customers with relevant
information about banking services and insights from annual reports. We
proposed a hybrid Customer Analysis Pipeline Retrieval-Augmented Generation
(CAPRAG) that effectively addresses both relationship-based and contextual
queries, thereby improving customer engagement in the digital banking
landscape. To implement this, we developed a processing pipeline to refine text
data, which we utilized in two main frameworks: Vector RAG and Graph RAG. This
dual approach enables us to populate both vector and graph databases with
processed data for efficient retrieval. The Cypher query component is employed
to effectively query the graph database. When a user submits a query, it is
first expanded by a query expansion module before being routed to construct a
final query from the hybrid Knowledge Base (KB). This final query is then sent
to an open-source LLM for response generation. Overall, our innovative,
designed to international banks, serves bank's customers in an increasingly
complex digital environment, enhancing clarity and accessibility of
information.

摘要：銀行業中新功能和服務的推出經常讓客戶感到不知所措，這為銀行透過大型語言模型 (LLM) 驅動的金融聊天機器人來提升使用者體驗創造了機會。我們啟動了一個人工智慧代理，旨在為客戶提供有關銀行服務和年度報告見解的相關資訊。我們提出了一個混合式客戶分析管道檢索擴充生成 (CAPRAG)，它有效地處理基於關係和情境式的查詢，從而提升數位銀行環境中的客戶參與度。為了實作這一點，我們開發了一個處理管道來精煉文字資料，我們在兩個主要架構中使用它：Vector RAG 和 Graph RAG。這種雙管齊下的方法讓我們能夠使用處理過的資料來填補向量和圖形資料庫，以利於有效檢索。Cypher 查詢元件用於有效查詢圖形資料庫。當使用者提交查詢時，它會先由查詢擴充模組擴充，然後再路由到混合式知識庫 (KB) 中建構最終查詢。然後這個最終查詢會傳送給開源 LLM 以產生回應。整體而言，我們創新的設計服務於國際銀行，在日益複雜的數位環境中服務銀行客戶，提升資訊的清晰度和可及性。

##### **Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization**
2501.13992v1 by Hy Nguyen, Nguyen Hung Nguyen, Nguyen Linh Bao Nguyen, Srikanth Thudumu, Hung Du, Rajesh Vasa, Kon Mouzakis

The Hierarchical Navigable Small World (HNSW) algorithm is widely used for
approximate nearest neighbor (ANN) search, leveraging the principles of
navigable small-world graphs. However, it faces some limitations. The first is
the local optima problem, which arises from the algorithm's greedy search
strategy, selecting neighbors based solely on proximity at each step. This
often leads to cluster disconnections. The second limitation is that HNSW
frequently fails to achieve logarithmic complexity, particularly in
high-dimensional datasets, due to the exhaustive traversal through each layer.
To address these limitations, we propose a novel algorithm that mitigates local
optima and cluster disconnections while enhancing the construction speed,
maintaining inference speed. The first component is a dual-branch HNSW
structure with LID-based insertion mechanisms, enabling traversal from multiple
directions. This improves outlier node capture, enhances cluster connectivity,
accelerates construction speed and reduces the risk of local minima. The second
component incorporates a bridge-building technique that bypasses redundant
intermediate layers, maintaining inference and making up the additional
computational overhead introduced by the dual-branch structure. Experiments on
various benchmarks and datasets showed that our algorithm outperforms the
original HNSW in both accuracy and speed. We evaluated six datasets across
Computer Vision (CV), and Natural Language Processing (NLP), showing recall
improvements of 18\% in NLP, and up to 30\% in CV tasks while reducing the
construction time by up to 20\% and maintaining the inference speed. We did not
observe any trade-offs in our algorithm. Ablation studies revealed that
LID-based insertion had the greatest impact on performance, followed by the
dual-branch structure and bridge-building components.

摘要：分層可導航小世界 (HNSW) 演算法廣泛用於近似最近鄰居 (ANN) 搜尋，並利用可導航小世界圖形的原理。然而，它面臨一些限制。第一個是局部最佳化問題，這源自於演算法的貪婪搜尋策略，在每個步驟中僅根據鄰近度來選擇鄰居。這通常會導致群集斷線。第二個限制是，由於透過每一層的窮舉式遍歷，HNSW 常常無法在高維度資料集中達成對數複雜度。為了解決這些限制，我們提出了一種新的演算法，它可以減輕局部最佳化和群集斷線，同時提高建構速度，並維持推論速度。第一個組成部分是一個具有基於 LID 的插入機制的雙分支 HNSW 結構，它能從多個方向進行遍歷。這改善了異常值節點的擷取，增強了群集連通性，加速了建構速度，並降低了局部最小值的風險。第二個組成部分包含一種橋樑建構技術，它繞過了多餘的中間層，維持推論並彌補了雙分支結構所帶來的額外運算負擔。在各種基準和資料集上的實驗顯示，我們的演算法在準確度和速度上都優於原始的 HNSW。我們評估了電腦視覺 (CV) 和自然語言處理 (NLP) 中的六個資料集，顯示 NLP 中的召回率提高了 18%，CV 任務中提高了 30%，同時將建構時間縮短了 20%，並維持了推論速度。我們沒有在我們的演算法中觀察到任何取捨。消融研究顯示，基於 LID 的插入對效能的影響最大，其次是雙分支結構和橋樑建構組成部分。

##### **Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs**
2501.13984v1 by Bhumika Gupta, Pralaypati Ta, Keerthi Ram, Mohanasankar Sivaprakasam

The updated recommendations on diagnostic procedures and treatment pathways
for a medical condition are documented as graphical flows in Clinical Practice
Guidelines (CPGs). For effective use of the CPGs in helping medical
professionals in the treatment decision process, it is necessary to fully
capture the guideline knowledge, particularly the contexts and their
relationships in the graph. While several existing works have utilized these
guidelines to create rule bases for Clinical Decision Support Systems, limited
work has been done toward directly capturing the full medical knowledge
contained in CPGs. This work proposes an approach to create a contextually
enriched, faithful digital representation of National Comprehensive Cancer
Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and
node & relationship classification. We also implement semantic enrichment of
the model by using Large Language Models (LLMs) for node classification,
achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot
learning, respectively. Additionally, we introduce a methodology for answering
natural language questions with constraints to guideline text by leveraging
LLMs to extract the relevant subgraph from the guideline knowledge base. By
generating natural language answers based on subgraph paths and semantic
information, we mitigate the risk of incorrect answers and hallucination
associated with LLMs, ensuring factual accuracy in medical domain Question
Answering.

摘要：已更新的醫療狀況診斷程序和治療途徑建議，以臨床實務指南 (CPG) 中的圖形流程記錄。為了有效使用 CPG 協助醫療專業人員進行治療決策，必須完整擷取指南知識，特別是圖表中的脈絡及其關係。雖然現有許多研究已利用這些指南為臨床決策支援系統建立規則基礎，但直接擷取 CPG 中包含的完整醫療知識的工作卻有限。這項研究提出了一種方法，以自動化擷取和節點與關係分類的方式，建立脈絡豐富、忠實的國家綜合癌症網路 (NCCN) 癌症 CPG 圖形數位表示。我們也透過使用大型語言模型 (LLM) 進行節點分類，實作模型的語意豐富化，分別在零次學習和少次學習中達到 80.86% 和 88.47% 的準確度。此外，我們引進了一種方法，透過運用 LLM 從指南知識庫中擷取相關子圖，來回答具有指南文字限制的自然語言問題。透過根據子圖路徑和語意資訊產生自然語言答案，我們降低了與 LLM 相關的錯誤答案和幻覺風險，確保了醫療領域問題解答中的事實準確性。

##### **LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations**
2501.12300v1 by Hasan Abu-Rasheed, Constance Jumbo, Rashed Al Amin, Christian Weber, Veit Wiese, Roman Obermaisser, Madjid Fathi

While learning personalization offers great potential for learners, modern
practices in higher education require a deeper consideration of domain models
and learning contexts, to develop effective personalization algorithms. This
paper introduces an innovative approach to higher education curriculum
modelling that utilizes large language models (LLMs) for knowledge graph (KG)
completion, with the goal of creating personalized learning-path
recommendations. Our research focuses on modelling university subjects and
linking their topics to corresponding domain models, enabling the integration
of learning modules from different faculties and institutions in the student's
learning path. Central to our approach is a collaborative process, where LLMs
assist human experts in extracting high-quality, fine-grained topics from
lecture materials. We develop a domain, curriculum, and user models for
university modules and stakeholders. We implement this model to create the KG
from two study modules: Embedded Systems and Development of Embedded Systems
Using FPGA. The resulting KG structures the curriculum and links it to the
domain models. We evaluate our approach through qualitative expert feedback and
quantitative graph quality metrics. Domain experts validated the relevance and
accuracy of the model, while the graph quality metrics measured the structural
properties of our KG. Our results show that the LLM-assisted graph completion
approach enhances the ability to connect related courses across disciplines to
personalize the learning experience. Expert feedback also showed high
acceptance of the proposed collaborative approach for concept extraction and
classification.

摘要：<paragraph>在學習個人化提供學習者巨大潛力的同時，高等教育中的現代實務需要更深入地考慮領域模型和學習情境，以開發有效的個人化演算法。本文介紹了一種創新的高等教育課程建模方法，該方法利用大型語言模型 (LLM) 來完成知識圖譜 (KG)，目的是建立個人化的學習路徑建議。我們的研究重點在於建模大學科目，並將它們的主題連結到對應的領域模型，從而能夠將來自不同院系和機構的學習模組整合到學生的學習路徑中。我們的做法核心是一個協作流程，其中 LLM 協助人類專家從講義材料中萃取高品質、細緻的主題。我們為大學模組和利害關係人開發了領域、課程和使用者模型。我們實作這個模型，從兩個研究模組建立 KG：嵌入式系統和使用 FPGA 的嵌入式系統開發。產生的 KG 建構了課程並將其連結到領域模型。我們透過定性專家回饋和定量圖形品質指標來評估我們的做法。領域專家驗證了模型的相關性和準確性，而圖形品質指標則測量了我們 KG 的結構特性。我們的結果顯示，LLM 輔助的圖形完成方法增強了跨學科連結相關課程的能力，以個人化學習體驗。專家回饋也顯示高度接受所提出的協作方法，用於概念萃取和分類。</paragraph>

##### **Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation**
2501.12432v1 by Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin

Although current Large Language Models (LLMs) exhibit impressive
capabilities, performing complex real-world tasks still requires tool learning.
Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to
interact with external environments, but they are limited in perceptual scope
and lack adequate task-planning capability. To address these limitations, other
studies introduce the first Search-based Decision Tree (DFSDT), which still
suffers from the high computational cost. In this paper, we introduce a novel
parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).
First, we transform traditional tree-based tool search paths into Directed
Acyclic Graph (DAG) structure, generating a high-quality parallel tool
invocation dataset. The DTA-Llama is then trained on the dataset to learn to
iteratively divide the current task into several parallel tool invocation
sub-tasks and aggregate the invocation results to decide the next actions.
Furthermore, we introduce an efficient inference framework inspired by the
Process/Threads mechanism when applying the DTA-Llama to practical tasks.
Experimental results show that our approach substantially enhances task
performance while reducing token consumption and inference time. Llama2-7B,
using our method, is comparable to the official parallel function calling
method of GPT-3.5. The relevant code, dataset, and model weights are available
at https://corn0205.github.io/

摘要：儘管目前的大型語言模型 (LLM) 展現出令人印象深刻的能力，但執行複雜的真實世界任務仍需要工具學習。主流方法（例如 CoT/ReAct）依賴逐步工具呼叫與外部環境互動，但它們的感知範圍有限，且缺乏足夠的任務規劃能力。為了解決這些限制，其他研究引入了第一個基於搜尋的決策樹 (DFSDT)，但仍有很高的運算成本。在本文中，我們介紹了一種新穎的平行工具呼叫範例，DTA-Llama（分而合之 Llama）。首先，我們將傳統的基於樹的工具搜尋路徑轉換為有向無環圖 (DAG) 結構，產生高品質的平行工具呼叫資料集。然後在資料集上訓練 DTA-Llama，學習反覆將當前任務分成幾個平行工具呼叫子任務，並彙總呼叫結果以決定後續動作。此外，我們在將 DTA-Llama 應用於實際任務時，引入了一個受 Process/Threads 機制啟發的高效推論框架。實驗結果表明，我們的做法大幅提升了任務效能，同時減少了符號消耗和推論時間。使用我們方法的 Llama2-7B，可與 GPT-3.5 的官方平行函式呼叫方法相媲美。相關程式碼、資料集和模型權重可在 https://corn0205.github.io/ 取得

##### **InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models**
2501.12231v1 by Pha Nguyen, Sailik Sengupta, Girik Malik, Arshit Gupta, Bonan Min

The improved competence of generative models can help building multi-modal
virtual assistants that leverage modalities beyond language. By observing
humans performing multi-step tasks, one can build assistants that have
situational awareness of actions and tasks being performed, enabling them to
cater assistance based on this understanding. In this paper, we develop a
Context-aware Instructional Task Assistant with Multi-modal Large Language
Models (InsTALL) that leverages an online visual stream (e.g. a user's screen
share or video recording) and responds in real-time to user queries related to
the task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal
model on task videos and paired textual data, and 2) automatically extracts
task graph from video data and leverages it at training and inference time. We
show InsTALL achieves state-of-the-art performance across proposed sub-tasks
considered for multimodal activity understanding -- task recognition (TR),
action recognition (AR), next action prediction (AP), and plan prediction (PP)
-- and outperforms existing baselines on two novel sub-tasks related to
automatic error identification.

摘要：生成模型能力的提升有助于构建利用语言之外的多模态虚拟助手。通过观察人类执行多步骤任务，可以构建对正在执行的动作和任务有情境感知的助手，使他们能够根据这种理解提供帮助。在本文中，我们开发了一个具有多模态大语言模型的上下文感知指令任务助手 (InsTALL)，该助手利用在线视觉流（例如用户的屏幕共享或视频录制），并实时响应与手头任务相关的用户查询。为了提供有用的帮助，InsTALL 1) 在任务视频和配对文本数据上训练多模态模型，以及 2) 从视频数据中自动提取任务图，并在训练和推理时间利用它。我们展示了 InsTALL 在考虑用于多模态活动理解的提议子任务中实现了最先进的性能——任务识别 (TR)、动作识别 (AR)、下一个动作预测 (AP) 和计划预测 (PP)——并且在与自动错误识别相关的两个新子任务上优于现有的基准。

##### **Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues**
2501.11977v1 by Maya Medjad, Hugo Imbert, Bruno Yun, Raphaël Szymocha, Frédéric Armetta

Training task-oriented dialogue systems is both costly and time-consuming,
due to the need for high-quality datasets encompassing diverse intents.
Traditional methods depend on extensive human annotation, while recent
advancements leverage large language models (LLMs) to generate synthetic data.
However, these approaches often require custom prompts or code, limiting
accessibility for non-technical users. We introduce GraphTOD, an end-to-end
framework that simplifies the generation of task-oriented dialogues. Users can
create dialogues by specifying transition graphs in JSON format. Our evaluation
demonstrates that GraphTOD generates high-quality dialogues across various
domains, significantly lowering the cost and complexity of dataset creation.

摘要：訓練任務導向對話系統既昂貴又耗時，
因為需要包含各種意圖的高品質資料集。
傳統方法依賴於廣泛的人工標註，而最近
的進展利用大型語言模型 (LLM) 來產生合成資料。
然而，這些方法通常需要自訂提示或程式碼，限制
非技術使用者的可及性。我們介紹 GraphTOD，一個端對端的
架構，簡化了任務導向對話的產生。使用者可以
透過指定 JSON 格式的轉換圖表來建立對話。我們的評估
證明 GraphTOD 在各種領域產生高品質對話，顯著降低資料集建立的成本和複雜性。

##### **Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization**
2501.11968v1 by Jie Zhao, Kang Hao Cheong, Witold Pedrycz

Graph-structured combinatorial challenges are inherently difficult due to
their nonlinear and intricate nature, often rendering traditional computational
methods ineffective or expensive. However, these challenges can be more
naturally tackled by humans through visual representations that harness our
innate ability for spatial reasoning. In this study, we propose transforming
graphs into images to preserve their higher-order structural features
accurately, revolutionizing the representation used in solving graph-structured
combinatorial tasks. This approach allows machines to emulate human-like
processing in addressing complex combinatorial challenges. By combining the
innovative paradigm powered by multimodal large language models (MLLMs) with
simple search techniques, we aim to develop a novel and effective framework for
tackling such problems. Our investigation into MLLMs spanned a variety of
graph-based tasks, from combinatorial problems like influence maximization to
sequential decision-making in network dismantling, as well as addressing six
fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit
exceptional spatial intelligence and a distinctive capability for handling
these problems, significantly advancing the potential for machines to
comprehend and analyze graph-structured data with a depth and intuition akin to
human cognition. These results also imply that integrating MLLMs with simple
optimization strategies could form a novel and efficient approach for
navigating graph-structured combinatorial challenges without complex
derivations, computationally demanding training and fine-tuning.

摘要：圖形結構的組合挑戰本質上很困難，因為它們的非線性和複雜性，通常會使傳統的計算方法無效或昂貴。然而，人類可以透過利用我們天生的空間推理能力的視覺表徵，更自然地應對這些挑戰。在本研究中，我們建議將圖形轉換為影像，以準確保留它們的高階結構特徵，從而革新用於解決圖形結構組合任務的表徵。這種方法允許機器在解決複雜的組合挑戰時模擬類人的處理。透過結合由多模態大型語言模型 (MLLM) 提供動力的創新範例與簡單的搜尋技術，我們旨在為解決此類問題開發一個新穎且有效的架構。我們對 MLLM 的研究涵蓋了各種基於圖形的任務，從組合問題（如影響力最大化）到網路拆除中的順序決策制定，以及解決六個基本的圖形相關問題。我們的研究結果表明，MLLM 表現出非凡的空間智能和處理這些問題的獨特能力，顯著提升了機器以類似人類認知的深度和直覺來理解和分析圖形結構資料的潛力。這些結果還暗示，將 MLLM 與簡單的最佳化策略整合在一起，可以形成一種新穎且有效的方法，用於在沒有複雜推導、計算需求量大的訓練和微調的情況下應對圖形結構的組合挑戰。

##### **A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**
2501.13958v1 by Qinggang Zhang, Shengyuan Chen, Yuanchen Bei, Zheng Yuan, Huachi Zhou, Zijin Hong, Junnan Dong, Hao Chen, Yi Chang, Xiao Huang

Large language models (LLMs) have demonstrated remarkable capabilities in a
wide range of tasks, yet their application to specialized domains remains
challenging due to the need for deep expertise. Retrieval-augmented generation
(RAG) has emerged as a promising solution to customize LLMs for professional
fields by seamlessly integrating external knowledge bases, enabling real-time
access to domain-specific expertise during inference. Despite its potential,
traditional RAG systems, based on flat text retrieval, face three critical
challenges: (i) complex query understanding in professional contexts, (ii)
difficulties in knowledge integration across distributed sources, and (iii)
system efficiency bottlenecks at scale. This survey presents a systematic
analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new
paradigm that revolutionizes domain-specific LLM applications. GraphRAG
addresses traditional RAG limitations through three key innovations: (i)
graph-structured knowledge representation that explicitly captures entity
relationships and domain hierarchies, (ii) efficient graph-based retrieval
techniques that enable context-preserving knowledge retrieval with multihop
reasoning ability, and (iii) structure-aware knowledge integration algorithms
that leverage retrieved knowledge for accurate and logical coherent generation
of LLMs. In this survey, we systematically analyze the technical foundations of
GraphRAG and examine current implementations across various professional
domains, identifying key technical challenges and promising research
directions. All the related resources of GraphRAG, including research papers,
open-source data, and projects, are collected for the community in
\textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.

摘要：大型語言模型 (LLM) 已在各種任務中展現出非凡的能力，但由於需要深入的專業知識，因此將其應用於專業領域仍具有挑戰性。檢索增強生成 (RAG) 已成為一種有前途的解決方案，可通過無縫整合外部知識庫來客製化 LLM 以適用於專業領域，從而在推理過程中即時存取特定領域的專業知識。儘管有其潛力，但基於平面文字檢索的傳統 RAG 系統面臨三項關鍵挑戰：(i) 在專業情境中進行複雜的查詢理解，(ii) 難以整合分散來源的知識，以及 (iii) 系統效率瓶頸會隨著規模擴大而產生。本調查系統性地分析了圖形化檢索增強生成 (GraphRAG) 的技術基礎，GraphRAG 是一個新的典範，它徹底改變了特定領域的 LLM 應用。GraphRAG 透過三項關鍵創新來解決傳統 RAG 的限制：(i) 圖形結構化的知識表述，明確擷取實體關係和領域階層，(ii) 有效的圖形化檢索技術，可進行保留脈絡的知識檢索，並具備多跳推理能力，以及 (iii) 結構感知知識整合演算法，可利用檢索到的知識來進行 LLM 的準確且邏輯一致的生成。在本調查中，我們系統性地分析了 GraphRAG 的技術基礎，並檢視了在各種專業領域中的現有實作，找出關鍵技術挑戰和有前景的研究方向。所有 GraphRAG 的相關資源，包括研究論文、開放原始碼資料和專案，都已在 \textcolor{blue}{\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}} 中為社群收集。

##### **Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance**
2501.11849v2 by Nikos Kanakaris, Heng Ping, Xiongye Xiao, Nesreen K. Ahmed, Luca Luceri, Emilio Ferrara, Paul Bogdan

Detecting organized political campaigns is of paramount importance in
fighting against disinformation on social media. Existing approaches for the
identification of such organized actions employ techniques mostly from network
science, graph machine learning and natural language processing. Their ultimate
goal is to analyze the relationships and interactions (e.g. re-posting) among
users and the textual similarities of their posts. Despite their effectiveness
in recognizing astroturf campaigns, these methods face significant challenges,
notably the class imbalance in available training datasets. To mitigate this
issue, recent methods usually resort to data augmentation or increasing the
number of positive samples, which may not always be feasible or sufficient in
real-world settings. Following a different path, in this paper, we propose a
novel framework for identifying astroturf campaigns based solely on large
language models (LLMs), introducing a Balanced Retrieval-Augmented Generation
(Balanced RAG) component. Our approach first gives both textual information
concerning the posts (in our case tweets) and the user interactions of the
social network as input to a language model. Then, through prompt engineering
and the proposed Balanced RAG method, it effectively detects coordinated
disinformation campaigns on X (Twitter). The proposed framework does not
require any training or fine-tuning of the language model. Instead, by
strategically harnessing the strengths of prompt engineering and Balanced RAG,
it facilitates LLMs to overcome the effects of class imbalance and effectively
identify coordinated political campaigns. The experimental results demonstrate
that by incorporating the proposed prompt engineering and Balanced RAG methods,
our framework outperforms the traditional graph-based baselines, achieving
2x-3x improvements in terms of precision, recall and F1 scores.

摘要：<paragraph>在社交媒體上對抗錯誤資訊，偵測有組織的政治宣傳活動至關重要。現有的此類有組織行動識別方法，大多採用網路科學、圖形機器學習和自然語言處理的技術。它們的最終目標是分析使用者之間的關係和互動（例如轉發），以及他們貼文的文字相似性。儘管這些方法在辨識草根運動宣傳活動方面很有效，但它們面臨嚴峻的挑戰，特別是可用訓練資料集中的類別不平衡。為了減輕這個問題，最近的方法通常訴諸於資料擴充或增加正向樣本數量，但在現實世界中可能並非總是可行或足夠。本文採取不同的途徑，我們提出了一個基於大型語言模型 (LLM) 的辨識草根運動宣傳活動的新架構，並引入了平衡檢索擴充產生 (Balanced RAG) 組件。我們的做法首先將有關貼文（在我們的案例中是推文）的文字資訊和社交網路的使用者互動作為輸入，輸入到語言模型中。然後，透過提示工程和提出的平衡檢索擴充產生方法，它有效地偵測 X（Twitter）上協調的不實資訊宣傳活動。提出的架構不需要任何語言模型的訓練或微調。相反地，透過策略性地利用提示工程和平衡檢索擴充產生方法的優勢，它使大型語言模型能夠克服類別不平衡的影響，並有效地識別協調的政治宣傳活動。實驗結果證明，透過整合提出的提示工程和平衡檢索擴充產生方法，我們的架構優於傳統的基於圖形的基準，在精確度、召回率和 F1 分數方面獲得 2x-3x 的改進。</paragraph>

##### **Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning**
2501.16361v1 by Haoran Song, Jiarui Feng, Guangfu Li, Michael Province, Philip Payne, Yixin Chen, Fuhai Li

In real-world scientific discovery, human beings always make use of the
accumulated prior knowledge with imagination pick select one or a few most
promising hypotheses from large and noisy data analysis results. In this study,
we introduce a new type of graph structure, the text-numeric graph (TNG), which
is defined as graph entities and associations have both text-attributed
information and numeric information. The TNG is an ideal data structure model
for novel scientific discovery via graph reasoning because it integrates
human-understandable textual annotations or prior knowledge, with numeric
values that represent the observed or activation levels of graph entities or
associations in different samples. Together both the textual information and
numeric values determine the importance of graph entities and associations in
graph reasoning for novel scientific knowledge discovery. We further propose
integrating large language models (LLMs) and graph neural networks (GNNs) to
analyze the TNGs for graph understanding and reasoning. To demonstrate the
utility, we generated the text-omic(numeric) signaling graphs (TOSG), as one
type of TNGs, in which all graphs have the same entities, associations and
annotations, but have sample-specific entity numeric (omic) values using single
cell RNAseq (scRNAseq) datasets of different diseases. We proposed joint
LLM-GNN models for key entity mining and signaling pathway mining on the TOSGs.
The evaluation results showed the LLM-GNN and TNGs models significantly improve
classification accuracy and network inference. In conclusion, the TNGs and
joint LLM-GNN models are important approaches for scientific discovery.

摘要：<paragraph>在現實世界的科學發現中，人類總是利用累積的先驗知識，並運用想像力從大量且雜訊的資料分析結果中挑選出一個或幾個最有希望的假設。在本研究中，我們介紹了一種新型態的圖形結構，稱為文字數值圖 (TNG)，定義為圖形實體和關聯具有文字屬性資訊和數值資訊。TNG 是透過圖形推理進行新科學發現的理想資料結構模型，因為它整合了人類可理解的文字註解或先驗知識，以及代表圖形實體或不同樣本中關聯的觀察值或活化程度的數值。文字資訊和數值一起決定了圖形實體和關聯在圖形推理中對於新科學知識發現的重要性。我們進一步提出整合大型語言模型 (LLM) 和圖形神經網路 (GNN) 來分析 TNG，以進行圖形理解和推理。為了展示其效用，我們生成了文字組學（數值）訊號圖 (TOSG)，作為一種 TNG，其中所有圖形都具有相同的實體、關聯和註解，但具有特定於樣本的實體數值（組學）值，使用不同疾病的單細胞 RNAseq (scRNAseq) 資料集。我們針對 TOSG 提出聯合 LLM-GNN 模型，用於關鍵實體探勘和訊號路徑探勘。評估結果顯示，LLM-GNN 和 TNG 模型顯著提升了分類準確度和網路推論。結論而言，TNG 和聯合 LLM-GNN 模型是科學發現的重要方法。</paragraph>

##### **Zep: A Temporal Knowledge Graph Architecture for Agent Memory**
2501.13956v1 by Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, Daniel Chalef

We introduce Zep, a novel memory layer service for AI agents that outperforms
the current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR)
benchmark. Additionally, Zep excels in more comprehensive and challenging
evaluations than DMR that better reflect real-world enterprise use cases. While
existing retrieval-augmented generation (RAG) frameworks for large language
model (LLM)-based agents are limited to static document retrieval, enterprise
applications demand dynamic knowledge integration from diverse sources
including ongoing conversations and business data. Zep addresses this
fundamental limitation through its core component Graphiti -- a
temporally-aware knowledge graph engine that dynamically synthesizes both
unstructured conversational data and structured business data while maintaining
historical relationships. In the DMR benchmark, which the MemGPT team
established as their primary evaluation metric, Zep demonstrates superior
performance (94.8% vs 93.4%). Beyond DMR, Zep's capabilities are further
validated through the more challenging LongMemEval benchmark, which better
reflects enterprise use cases through complex temporal reasoning tasks. In this
evaluation, Zep achieves substantial results with accuracy improvements of up
to 18.5% while simultaneously reducing response latency by 90% compared to
baseline implementations. These results are particularly pronounced in
enterprise-critical tasks such as cross-session information synthesis and
long-term context maintenance, demonstrating Zep's effectiveness for deployment
in real-world applications.

摘要：我們推出 Zep，這是一種新穎的記憶層服務，適用於 AI 代理，其在深度記憶擷取 (DMR) 基準測試中優於現行的最先進系統 MemGPT。此外，Zep 在比 DMR 更全面且更具挑戰性的評估中表現出色，這些評估更能反映真實世界的企業用例。雖然現有的檢索增強生成 (RAG) 架構僅限於大型語言模型 (LLM) 基於代理的靜態文件檢索，但企業應用需要從包括正在進行的對話和業務數據在內的不同來源動態整合知識。Zep 通過其核心組件 Graphiti 來解決這個基本限制，Graphiti 是一個時間感知知識圖譜引擎，可以在維護歷史關係的同時動態綜合非結構化對話數據和結構化業務數據。在 MemGPT 團隊確立為其主要評估指標的 DMR 基準測試中，Zep 表現出優異的效能（94.8% 對 93.4%）。除了 DMR 之外，Zep 的功能還通過更具挑戰性的 LongMemEval 基準測試進一步得到驗證，該基準測試通過複雜的時間推理任務更好地反映了企業用例。在這個評估中，Zep 以高達 18.5% 的準確度改進取得了顯著的成果，同時與基線實作相比，將回應延遲降低了 90%。這些成果在企業關鍵任務中尤為明顯，例如跨會話資訊綜合和長期脈絡維護，證明了 Zep 在實際應用中部署的有效性。

##### **Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation**
2501.11560v1 by M. Manzour, A. Ballardini, R. Izquierdo, M. Á. Sotelo

Lane-changing maneuvers, particularly those executed abruptly or in risky
situations, are a significant cause of road traffic accidents. However, current
research mainly focuses on predicting safe lane changes. Furthermore, existing
accident datasets are often based on images only and lack comprehensive sensory
data. In this work, we focus on predicting risky lane changes using the CRASH
dataset (our own collected dataset specifically for risky lane changes), and
safe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian
inference to predict these maneuvers using linguistic contextual information,
enhancing the model's interpretability and transparency. The model achieved a
91.5% f1-score with anticipation time extending to four seconds for risky lane
changes, and a 90.0% f1-score for predicting safe lane changes with the same
anticipation time. We validate our model by integrating it into a vehicle
within the CARLA simulator in scenarios that involve risky lane changes. The
model managed to anticipate sudden lane changes, thus providing automated
vehicles with further time to plan and execute appropriate safe reactions.
Finally, to enhance the explainability of our model, we utilize RAG to provide
clear and natural language explanations for the given prediction.

摘要：換車道動作，尤其是突然或在風險情況下執行的動作，是道路交通事故的重要原因。然而，目前的研究所主要集中在預測安全的換車道。此外，現有的事故資料集通常僅基於影像，且缺乏全面的感測資料。在這項工作中，我們專注於使用 CRASH 資料集（我們自己收集的專門針對風險換車道資料集）來預測風險換車道，以及安全換車道（使用 HighD 資料集）。然後，我們利用 KG 和貝氏推理來使用語言背景資訊預測這些動作，增強模型的可解釋性和透明度。該模型在風險換車道的預測時間延長至四秒時，達到了 91.5% 的 f1 分數，在預測安全換車道時，在相同的預測時間內達到了 90.0% 的 f1 分數。我們透過將模型整合到 CARLA 模擬器中的車輛中，在涉及風險換車道的場景中驗證我們的模型。該模型設法預測突然的換車道，從而為自動駕駛車輛提供了更多時間來規劃和執行適當的安全反應。最後，為了增強我們模型的可解釋性，我們利用 RAG 為給定的預測提供清晰且自然的語言解釋。

##### **Each Graph is a New Language: Graph Learning with LLMs**
2501.11478v2 by Huachi Zhou, Jiahe Du, Chuang Zhou, Chang Yang, Yilin Xiao, Yuxuan Xie, Xiao Huang

Recent efforts leverage Large Language Models (LLMs) for modeling
text-attributed graph structures in node classification tasks. These approaches
describe graph structures for LLMs to understand or aggregate LLM-generated
textual attribute embeddings through graph structure. However, these approaches
face two main limitations in modeling graph structures with LLMs. (i) Graph
descriptions become verbose in describing high-order graph structure. (ii)
Textual attributes alone do not contain adequate graph structure information.
It is challenging to model graph structure concisely and adequately with LLMs.
LLMs lack built-in mechanisms to model graph structures directly. They also
struggle with complex long-range dependencies between high-order nodes and
target nodes.
  Inspired by the observation that LLMs pre-trained on one language can achieve
exceptional performance on another with minimal additional training, we propose
\textbf{G}raph-\textbf{D}efined \textbf{L}anguage for \textbf{L}arge
\textbf{L}anguage \textbf{M}odel (GDL4LLM). This novel framework enables LLMs
to transfer their powerful language understanding capabilities to
graph-structured data. GDL4LLM translates graphs into a graph language corpus
instead of graph descriptions and pre-trains LLMs on this corpus to adequately
understand graph structures. During fine-tuning, this corpus describes the
structural information of target nodes concisely with only a few tokens. By
treating graphs as a new language, GDL4LLM enables LLMs to model graph
structures adequately and concisely for node classification tasks. Extensive
experiments on three real-world datasets demonstrate that GDL4LLM outperforms
description-based and textual attribute embeddings-based baselines by
efficiently modeling different orders of graph structure with LLMs.

摘要：<paragraph>最近的研究利用大型语言模型 (LLM) 对节点分类任务中的文本属性图结构进行建模。这些方法描述图结构，以便 LLM 理解或通过图结构聚合 LLM 生成的文本属性嵌入。然而，这些方法在使用 LLM 对图结构进行建模时面临两个主要限制。(i) 图描述在描述高阶图结构时变得冗长。(ii) 仅文本属性不包含足够的图结构信息。使用 LLM 对图结构进行简洁且充分的建模具有挑战性。LLM 缺乏直接对图结构进行建模的内置机制。它们还难以处理高阶节点和目标节点之间复杂的远程依赖关系。
受 LLM 在一种语言上进行预训练后，只需进行最少的额外训练即可在另一种语言上实现卓越性能的观察结果的启发，我们提出了**G**raph-**D**efined **L**anguage for **L**arge **L**anguage **M**odel (GDL4LLM)。此新框架使 LLM 能够将其强大的语言理解能力转移到结构化数据图。GDL4LLM 将图翻译成图语言语料库，而不是图描述，并在该语料库上对 LLM 进行预训练，以充分理解图结构。在微调期间，此语料库仅使用几个标记简洁地描述目标节点的结构信息。通过将图视为一种新语言，GDL4LLM 使 LLM 能够充分且简洁地对图结构进行建模，以用于节点分类任务。在三个真实世界数据集上进行的广泛实验表明，GDL4LLM 通过使用 LLM 有效地对不同阶的图结构进行建模，优于基于描述和基于文本属性嵌入的基线。</paragraph>

##### **Few-shot Policy (de)composition in Conversational Question Answering**
2501.11335v1 by Kyle Erwin, Guy Axelrod, Maria Chang, Achille Fokoue, Maxwell Crouse, Soham Dan, Tian Gao, Rosario Uceda-Sosa, Ndivhuwo Makondo, Naweed Khan, Alexander Gray

The task of policy compliance detection (PCD) is to determine if a scenario
is in compliance with respect to a set of written policies. In a conversational
setting, the results of PCD can indicate if clarifying questions must be asked
to determine compliance status. Existing approaches usually claim to have
reasoning capabilities that are latent or require a large amount of annotated
data. In this work, we propose logical decomposition for policy compliance
(LDPC): a neuro-symbolic framework to detect policy compliance using large
language models (LLMs) in a few-shot setting. By selecting only a few exemplars
alongside recently developed prompting techniques, we demonstrate that our
approach soundly reasons about policy compliance conversations by extracting
sub-questions to be answered, assigning truth values from contextual
information, and explicitly producing a set of logic statements from the given
policies. The formulation of explicit logic graphs can in turn help answer
PCDrelated questions with increased transparency and explainability. We apply
this approach to the popular PCD and conversational machine reading benchmark,
ShARC, and show competitive performance with no task-specific finetuning. We
also leverage the inherently interpretable architecture of LDPC to understand
where errors occur, revealing ambiguities in the ShARC dataset and highlighting
the challenges involved with reasoning for conversational question answering.

摘要：策略合規偵測 (PCD) 的任務是確定場景是否符合一組書面策略。在對話設定中，PCD 的結果可以指出是否必須提出澄清問題以確定合規狀態。現有的方法通常聲稱具有潛在的推理能力，或需要大量的註釋資料。在這項工作中，我們提出策略合規的邏輯分解 (LDPC)：一種使用大型語言模型 (LLM) 在少次嘗試中偵測策略合規的神經符號框架。透過僅選擇少數範例以及最近開發的提示技術，我們證明我們的做法透過提取要回答的子問題、從脈絡資訊指派真值，以及從給定的策略明確產生一組邏輯陳述，對策略合規對話進行合理的推理。明確邏輯圖表的制定反過來可以幫助回答 PCD 相關問題，並提高透明度和可解釋性。我們將此方法應用於熱門的 PCD 和對話式機器閱讀基準 ShARC，並在沒有特定任務微調的情況下展現出競爭力。我們也利用 LDPC 固有的可解釋架構來了解錯誤發生在哪裡，揭露 ShARC 資料集中的歧義，並強調對話式問題解答推理的挑戰。

##### **Reasoning Language Models: A Blueprint**
2501.11223v3 by Maciej Besta, Julia Barth, Eric Schreiber, Ales Kubicek, Afonso Catarino, Robert Gerstenberger, Piotr Nyczyk, Patrick Iff, Yueling Li, Sam Houliston, Tomasz Sternal, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Łukasz Flis, Hannes Eberhard, Hubert Niewiadomski, Torsten Hoefler

Reasoning language models (RLMs), also known as Large Reasoning Models
(LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have
redefined AI's problem-solving capabilities by extending LLMs with advanced
reasoning mechanisms. Yet, their high costs, proprietary nature, and complex
architectures - uniquely combining Reinforcement Learning (RL), search
heuristics, and LLMs - present accessibility and scalability challenges. To
address these, we propose a comprehensive blueprint that organizes RLM
components into a modular framework, based on a survey and analysis of all RLM
works. This blueprint incorporates diverse reasoning structures (chains, trees,
graphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search,
Beam Search), RL concepts (policy, value models and others), supervision
schemes (Outcome-Based and Process-Based Supervision), and other related
concepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agent
tools). We also provide detailed mathematical formulations and algorithmic
specifications to simplify RLM implementation. By showing how schemes like
LLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases,
we demonstrate the blueprint's versatility and unifying potential. To
illustrate its utility, we introduce x1, a modular implementation for rapid RLM
prototyping and experimentation. Using x1 and a literature review, we provide
key insights, such as multi-phase training for policy and value models, and the
importance of familiar training distributions. Finally, we discuss scalable RLM
cloud deployments and we outline how RLMs can integrate with a broader LLM
ecosystem. Our work demystifies RLM construction, democratizes advanced
reasoning capabilities, and fosters innovation, aiming to mitigate the gap
between "rich AI" and "poor AI" by lowering barriers to RLM design and
experimentation.

摘要：推理語言模型 (RLM)，又稱為大型推理模型 (LRM)，例如 OpenAI 的 o1 和 o3、DeepSeek-V3 以及阿里巴巴的 QwQ，透過擴充 LLM 的先進推理機制，重新定義了 AI 的問題解決能力。然而，它們的高成本、專有性質和複雜架構（獨特地結合了強化學習 (RL)、搜尋啟發法和 LLM）提出了可及性和可擴充性的挑戰。為了解決這些問題，我們提出了一個全面的藍圖，將 RLM 組件組織成一個模組化架構，這是基於對所有 RLM 作品的調查和分析。此藍圖包含多樣化的推理結構（鏈、樹、圖和巢狀形式）、推理策略（例如蒙地卡羅樹搜尋、波束搜尋）、RL 概念（策略、價值模型等）、監督方案（基於結果和基於流程的監督）和其他相關概念（例如測試時間運算、檢索增強生成、代理工具）。我們還提供了詳細的數學公式和演算法規範，以簡化 RLM 的實作。透過展示 LLaMA-Berry、QwQ、Journey Learning 和 Graph of Thoughts 等方案如何作為特殊情況，我們展示了藍圖的多功能性和統一潛力。為了說明其效用，我們介紹了 x1，這是一個模組化實作，用於快速 RLM 原型製作和實驗。使用 x1 和文獻回顧，我們提供了關鍵見解，例如策略和價值模型的多階段訓練，以及熟悉訓練分佈的重要性。最後，我們討論了可擴充的 RLM 雲端部署，並概述了 RLM 如何與更廣泛的 LLM 生態系統整合。我們的研究揭開了 RLM 建構的神秘面紗，使先進的推理能力民主化，並促進創新，旨在透過降低 RLM 設計和實驗的障礙，來縮小「富裕 AI」和「貧窮 AI」之間的差距。

##### **IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems**
2501.11067v1 by Elad Levi, Ilan Kadar

Large Language Models (LLMs) are transforming artificial intelligence,
evolving into task-oriented systems capable of autonomous planning and
execution. One of the primary applications of LLMs is conversational AI
systems, which must navigate multi-turn dialogues, integrate domain-specific
APIs, and adhere to strict policy constraints. However, evaluating these agents
remains a significant challenge, as traditional methods fail to capture the
complexity and variability of real-world interactions. We introduce
IntellAgent, a scalable, open-source multi-agent framework designed to evaluate
conversational AI systems comprehensively. IntellAgent automates the creation
of diverse, synthetic benchmarks by combining policy-driven graph modeling,
realistic event generation, and interactive user-agent simulations. This
innovative approach provides fine-grained diagnostics, addressing the
limitations of static and manually curated benchmarks with coarse-grained
metrics. IntellAgent represents a paradigm shift in evaluating conversational
AI. By simulating realistic, multi-policy scenarios across varying levels of
complexity, IntellAgent captures the nuanced interplay of agent capabilities
and policy constraints. Unlike traditional methods, it employs a graph-based
policy model to represent relationships, likelihoods, and complexities of
policy interactions, enabling highly detailed diagnostics. IntellAgent also
identifies critical performance gaps, offering actionable insights for targeted
optimization. Its modular, open-source design supports seamless integration of
new domains, policies, and APIs, fostering reproducibility and community
collaboration. Our findings demonstrate that IntellAgent serves as an effective
framework for advancing conversational AI by addressing challenges in bridging
research and deployment. The framework is available at
https://github.com/plurai-ai/intellagent

摘要：大型語言模型 (LLM) 正在轉變人工智慧，演變成具備自主規劃和執行能力的任務導向系統。LLM 的主要應用之一是對話式 AI 系統，它必須應對多輪對話、整合特定領域的 API，並遵守嚴格的政策約束。然而，評估這些代理仍然是一項重大挑戰，因為傳統方法無法捕捉現實世界互動的複雜性和變異性。我們引入了 IntellAgent，一個可擴充、開放原始碼的多代理架構，旨在全面評估對話式 AI 系統。IntellAgent 自動化建立多樣化、合成的基準，方法是結合策略驅動的圖形建模、逼真的事件產生和互動使用者代理模擬。這種創新方法提供了細緻的診斷，解決了具有粗略指標的靜態和手動策劃基準的限制。IntellAgent 代表了評估對話式 AI 的典範轉移。通過模擬不同層級複雜性的逼真多策略場景，IntellAgent 捕捉到了代理功能和策略約束之間的細微交互。與傳統方法不同，它採用基於圖形的策略模型來表示策略交互的關係、可能性和複雜性，從而實現高度詳細的診斷。IntellAgent 還識別出關鍵效能差距，提供可行的見解，以進行目標最佳化。其模組化、開放原始碼的設計支援無縫整合新的領域、策略和 API，促進了可複製性和社群協作。我們的研究結果表明，IntellAgent 可作為一個有效的框架，透過解決研究和部署之間的挑戰來推進對話式 AI。這個框架可在 https://github.com/plurai-ai/intellagent 取得

##### **A Method for Multi-Hop Question Answering on Persian Knowledge Graph**
2501.16350v1 by Arash Ghafouri, Mahdi Firouzmandi, Hasan Naderi

Question answering systems are the latest evolution in information retrieval
technology, designed to accept complex queries in natural language and provide
accurate answers using both unstructured and structured knowledge sources.
Knowledge Graph Question Answering (KGQA) systems fulfill users' information
needs by utilizing structured data, representing a vast number of facts as a
graph. However, despite significant advancements, major challenges persist in
answering multi-hop complex questions, particularly in Persian. One of the main
challenges is the accurate understanding and transformation of these multi-hop
complex questions into semantically equivalent SPARQL queries, which allows for
precise answer retrieval from knowledge graphs. In this study, to address this
issue, a dataset of 5,600 Persian multi-hop complex questions was developed,
along with their decomposed forms based on the semantic representation of the
questions. Following this, Persian language models were trained using this
dataset, and an architecture was proposed for answering complex questions using
a Persian knowledge graph. Finally, the proposed method was evaluated against
similar systems on the PeCoQ dataset. The results demonstrated the superiority
of our approach, with an improvement of 12.57% in F1-score and 12.06% in
accuracy compared to the best comparable method.

摘要：問答系統是資訊檢索技術的最新演進，旨在接受自然語言的複雜查詢，並使用非結構化和結構化知識來源提供準確的答案。知識圖譜問答 (KGQA) 系統透過利用結構化資料，將大量的資訊以圖譜的形式呈現，來滿足使用者的資訊需求。然而，儘管有顯著的進展，在回答多跳複雜問題時仍存在著重大的挑戰，特別是在波斯語中。其中一項主要挑戰是將這些多跳複雜問題準確地理解並轉換成語義等效的 SPARQL 查詢，這能從知識圖譜中精確地擷取答案。在本研究中，為了解決這個問題，我們開發了一個包含 5,600 個波斯語多跳複雜問題的資料集，以及它們根據問題的語義表示所分解的形式。接著，我們使用此資料集訓練了波斯語語言模型，並提出了一個使用波斯語知識圖譜回答複雜問題的架構。最後，我們在 PeCoQ 資料集上針對類似的系統評估了所提出的方法。結果證明了我們方法的優越性，與最佳的可比較方法相比，F1 分數提升了 12.57%，準確度提升了 12.06%。

##### **Agent-as-Judge for Factual Summarization of Long Narratives**
2501.09993v1 by Yeonseok Jeong, Minsoo Kim, Seung-won Hwang, Byung-Hak Kim

Large Language Models (LLMs) have demonstrated near-human performance in
summarization tasks based on traditional metrics such as ROUGE and BERTScore.
However, these metrics do not adequately capture critical aspects of
summarization quality, such as factual accuracy, particularly for long
narratives (>100K tokens). Recent advances, such as LLM-as-a-Judge, address the
limitations of metrics based on lexical similarity but still exhibit factual
inconsistencies, especially in understanding character relationships and
states. In this work, we introduce NarrativeFactScore, a novel
"Agent-as-a-Judge" framework for evaluating and refining summaries. By
leveraging a Character Knowledge Graph (CKG) extracted from input and generated
summaries, NarrativeFactScore assesses the factual consistency and provides
actionable guidance for refinement, such as identifying missing or erroneous
facts. We demonstrate the effectiveness of NarrativeFactScore through a
detailed workflow illustration and extensive validation on widely adopted
benchmarks, achieving superior performance compared to competitive methods. Our
results highlight the potential of agent-driven evaluation systems to improve
the factual reliability of LLM-generated summaries.

摘要：大型語言模型 (LLM) 在摘要任務中展現出接近人類的表現，根據傳統指標，例如 ROUGE 和 BERTScore。然而，這些指標並未充分掌握摘要品質的關鍵面向，例如事實準確性，特別是針對長篇敘事 (>100K 個符號)。最近的進展，例如 LLM-as-a-Judge，解決了基於詞彙相似性的指標限制，但仍然表現出事實上的不一致性，特別是在理解角色關係和狀態方面。在這項工作中，我們引入了 NarrativeFactScore，一種新穎的「代理人作為評審」架構，用於評估和精煉摘要。透過利用從輸入和產生的摘要中萃取的角色知識圖譜 (CKG)，NarrativeFactScore 評估事實一致性，並提供可行的精煉指南，例如識別遺漏或錯誤的事實。我們透過詳細的工作流程說明和廣泛驗證在廣泛採用的基準上，證明了 NarrativeFactScore 的有效性，與競爭方法相比，達到了卓越的表現。我們的結果突顯了代理人驅動評估系統的潛力，以改善 LLM 生成的摘要的事實可靠性。

##### **FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**
2501.09957v2 by Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, S Kevin Zhou

To mitigate the hallucination and knowledge deficiency in large language
models (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)
has shown promising potential by utilizing KGs as external resource to enhance
LLMs reasoning. However, existing KG-RAG approaches struggle with a trade-off
between flexibility and retrieval quality. Modular methods prioritize
flexibility by avoiding the use of KG-fine-tuned models during retrieval,
leading to fixed retrieval strategies and suboptimal retrieval quality.
Conversely, coupled methods embed KG information within models to improve
retrieval quality, but at the expense of flexibility. In this paper, we propose
a novel flexible modular KG-RAG framework, termed FRAG, which synergizes the
advantages of both approaches. FRAG estimates the hop range of reasoning paths
based solely on the query and classify it as either simple or complex. To match
the complexity of the query, tailored pipelines are applied to ensure efficient
and accurate reasoning path retrieval, thus fostering the final reasoning
process. By using the query text instead of the KG to infer the structural
information of reasoning paths and employing adaptable retrieval strategies,
FRAG improves retrieval quality while maintaining flexibility. Moreover, FRAG
does not require extra LLMs fine-tuning or calls, significantly boosting
efficiency and conserving resources. Extensive experiments show that FRAG
achieves state-of-the-art performance with high efficiency and low resource
consumption.

摘要：<paragraph>為了減輕大型語言模型 (LLM) 中的幻覺和知識不足，基於知識圖譜 (KG) 的檢索增強生成 (RAG) 已展現出利用 KG 作為外部資源來增強 LLM 推理的潛力。然而，現有的 KG-RAG 方法在靈活性與檢索品質之間面臨取捨。模組化方法透過避免在檢索期間使用 KG 微調模型來優先考慮靈活性，導致固定的檢索策略和次佳的檢索品質。相反地，耦合方法將 KG 資訊嵌入模型中以改善檢索品質，但犧牲了靈活性。在本文中，我們提出了一個新穎的靈活模組化 KG-RAG 框架，稱為 FRAG，它協同了兩種方法的優點。FRAG 僅根據查詢估計推理路徑的跳躍範圍，並將其分類為簡單或複雜。為了匹配查詢的複雜性，應用客製化管道以確保有效且準確的推理路徑檢索，從而促進最終的推理過程。FRAG 使用查詢文字而非 KG 來推斷推理路徑的結構化資訊，並採用可適應的檢索策略，從而改善檢索品質，同時保持靈活性。此外，FRAG 不需要額外的 LLM 微調或呼叫，顯著提升效率並節省資源。大量的實驗表明，FRAG 以高效率和低資源消耗實現了最先進的效能。</paragraph>

##### **SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs**
2501.09316v1 by Anbang Ye, Qianran Ma, Jia Chen, Muqi Li, Tong Li, Fujiao Liu, Siqi Mai, Meichen Lu, Haitao Bao, Yang You

Despite significant advancements in general-purpose AI agents, several
challenges still hinder their practical application in real-world scenarios.
First, the limited planning capabilities of Large Language Models (LLM)
restrict AI agents from effectively solving complex tasks that require
long-horizon planning. Second, general-purpose AI agents struggle to
efficiently utilize domain-specific knowledge and human expertise. In this
paper, we introduce the Standard Operational Procedure-guided Agent
(SOP-agent), a novel framework for constructing domain-specific agents through
pseudocode-style Standard Operational Procedures (SOPs) written in natural
language. Formally, we represent a SOP as a decision graph, which is traversed
to guide the agent in completing tasks specified by the SOP. We conduct
extensive experiments across tasks in multiple domains, including
decision-making, search and reasoning, code generation, data cleaning, and
grounded customer service. The SOP-agent demonstrates excellent versatility,
achieving performance superior to general-purpose agent frameworks and
comparable to domain-specific agent systems. Additionally, we introduce the
Grounded Customer Service Benchmark, the first benchmark designed to evaluate
the grounded decision-making capabilities of AI agents in customer service
scenarios based on SOPs.

摘要：儘管通用 AI 代理在一般用途上取得顯著進展，但仍有數項挑戰阻礙其在實際場景中的實用應用。
首先，大型語言模型 (LLM) 有限的規劃能力限制了 AI 代理有效解決需要長期規劃的複雜任務。其次，通用 AI 代理難以有效利用特定領域的知識和人類專業知識。在本文中，我們介紹了標準操作程序引導代理 (SOP-agent)，這是一個透過以自然語言撰寫的偽代碼風格標準操作程序 (SOP) 來建構特定領域代理的新穎架構。正式來說，我們將 SOP 表示為決策圖，並在其中穿梭以引導代理完成 SOP 指定的任務。我們在多個領域中的任務中進行廣泛的實驗，包括決策制定、搜尋和推理、程式碼生成、資料清理和基礎客戶服務。SOP-agent 展示出卓越的多功能性，其效能優於通用代理架構，且與特定領域代理系統相當。此外，我們介紹了基礎客戶服務基準，這是第一個基準，旨在評估 AI 代理在基於 SOP 的客戶服務場景中基礎決策制定能力。

##### **Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model**
2501.09279v1 by Zijin Qiu, Jiepeng Liu, Yi Xia, Hongtuo Qi, Pengkun Liu

Flexibility in the AI-based residential layout design remains a significant
challenge, as traditional methods like rule-based heuristics and graph-based
generation often lack flexibility and require substantial design knowledge from
users. To address these limitations, we propose a cross-modal design approach
based on the Stable Diffusion model for generating flexible residential
layouts. The method offers multiple input types for learning objectives,
allowing users to specify both boundaries and layouts. It incorporates natural
language as design constraints and introduces ControlNet to enable stable
layout generation through two distinct pathways. We also present a scheme that
encapsulates design expertise within a knowledge graph and translates it into
natural language, providing an interpretable representation of design
knowledge. This comprehensibility and diversity of input options enable
professionals and non-professionals to directly express design requirements,
enhancing flexibility and controllability. Finally, experiments verify the
flexibility of the proposed methods under multimodal constraints better than
state-of-the-art models, even when specific semantic information about room
areas or connections is incomplete.

摘要：在基於 AI 的住宅佈局設計中，靈活性仍是一項重大挑戰，因為基於規則的啟發法和基於圖形的產生等傳統方法通常缺乏靈活性，且需要使用者具備大量的設計知識。為了解決這些限制，我們提出一個跨模態設計方法，該方法基於 Stable Diffusion 模型，用於產生靈活的住宅佈局。此方法提供多種輸入類型以進行學習目標，使用戶能夠同時指定邊界和佈局。它將自然語言作為設計約束，並引入 ControlNet，以透過兩個不同的路徑實現穩定的佈局產生。我們還提出了一個將設計專業知識封裝在知識圖形中的方案，並將其轉換為自然語言，提供設計知識的可詮釋表示。這種可理解性和輸入選項的多樣性使專業人士和非專業人士能夠直接表達設計需求，從而增強靈活性與可控性。最後，實驗驗證了所提出的方法在多模態約束下的靈活性優於最先進的模型，即使關於房間區域或連接的特定語義資訊不完整時也是如此。

##### **A Simple Graph Contrastive Learning Framework for Short Text Classification**
2501.09219v1 by Yonghao Liu, Fausto Giunchiglia, Lan Huang, Ximing Li, Xiaoyue Feng, Renchu Guan

Short text classification has gained significant attention in the information
age due to its prevalence and real-world applications. Recent advancements in
graph learning combined with contrastive learning have shown promising results
in addressing the challenges of semantic sparsity and limited labeled data in
short text classification. However, existing models have certain limitations.
They rely on explicit data augmentation techniques to generate contrastive
views, resulting in semantic corruption and noise. Additionally, these models
only focus on learning the intrinsic consistency between the generated views,
neglecting valuable discriminative information from other potential views. To
address these issues, we propose a Simple graph contrastive learning framework
for Short Text Classification (SimSTC). Our approach involves performing graph
learning on multiple text-related component graphs to obtain multi-view text
embeddings. Subsequently, we directly apply contrastive learning on these
embeddings. Notably, our method eliminates the need for data augmentation
operations to generate contrastive views while still leveraging the benefits of
multi-view contrastive learning. Despite its simplicity, our model achieves
outstanding performance, surpassing large language models on various datasets.

摘要：短文本分类在信息时代得到了广泛关注，因为它具有普遍性和现实世界的应用。最近，图学习与对比学习相结合的进步在解决短文本分类中语义稀疏性和标记数据有限的挑战方面显示出有希望的结果。然而，现有的模型具有一定的局限性。它们依赖于显式的数据增强技术来生成对比视图，从而导致语义损坏和噪声。此外，这些模型只关注学习生成视图之间的内在一致性，而忽略了其他潜在视图中有价值的判别信息。为了解决这些问题，我们提出了一个用于短文本分类的简单图对比学习框架 (SimSTC)。我们的方法涉及对多个文本相关组件图执行图学习以获得多视图文本嵌入。随后，我们直接对这些嵌入应用对比学习。值得注意的是，我们的方法消除了生成对比视图时对数据增强操作的需求，同时仍然利用了多视图对比学习的优势。尽管很简单，但我们的模型获得了出色的性能，在各种数据集上超越了大型语言模型。

##### **Boosting Short Text Classification with Multi-Source Information Exploration and Dual-Level Contrastive Learning**
2501.09214v1 by Yonghao Liu, Mengyu Li, Wei Pang, Fausto Giunchiglia, Lan Huang, Xiaoyue Feng, Renchu Guan

Short text classification, as a research subtopic in natural language
processing, is more challenging due to its semantic sparsity and insufficient
labeled samples in practical scenarios. We propose a novel model named
MI-DELIGHT for short text classification in this work. Specifically, it first
performs multi-source information (i.e., statistical information, linguistic
information, and factual information) exploration to alleviate the sparsity
issues. Then, the graph learning approach is adopted to learn the
representation of short texts, which are presented in graph forms. Moreover, we
introduce a dual-level (i.e., instance-level and cluster-level) contrastive
learning auxiliary task to effectively capture different-grained contrastive
information within massive unlabeled data. Meanwhile, previous models merely
perform the main task and auxiliary tasks in parallel, without considering the
relationship among tasks. Therefore, we introduce a hierarchical architecture
to explicitly model the correlations between tasks. We conduct extensive
experiments across various benchmark datasets, demonstrating that MI-DELIGHT
significantly surpasses previous competitive models. It even outperforms
popular large language models on several datasets.

摘要：短文本分類作為自然語言處理的研究子主題，由於其語義稀疏性和實際場景中標記樣本不足，因此更具挑戰性。在這項工作中，我們提出了一個名為 MI-DELIGHT 的新模型，用於短文本分類。具體來說，它首先執行多源信息（即統計信息、語言信息和事實信息）探索，以緩解稀疏性問題。然後，採用圖學習方法來學習以圖表形式呈現的短文本的表示。此外，我們引入了一個雙層級（即實例層級和群集層級）對比學習輔助任務，以有效捕獲大量未標記數據中的不同粒度對比信息。同時，以前的模型僅並行執行主任務和輔助任務，而沒有考慮任務之間的關係。因此，我們引入了一個分層架構來明確建模任務之間的相關性。我們在各種基準數據集上進行了廣泛的實驗，證明 MI-DELIGHT 明顯優於以前的競爭模型。它甚至在幾個數據集上優於流行的大語言模型。

##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

摘要：辨識材料化學中可靠的合成路徑是一項複雜的任務，特別是在聚合物科學中，因為巨分子的命名法錯綜複雜且經常不唯一。為了應對這個挑戰，我們提出一個整合大型語言模型 (LLM) 與知識圖譜 (KG) 的代理系統。透過利用 LLM 強大的化學物質名稱萃取和辨識能力，並將萃取的資料儲存在結構化的知識圖譜中，我們的系統可完全自動化相關文獻的檢索、反應資料的萃取、資料庫查詢、逆合成路徑樹的建構、透過檢索額外文獻進一步擴充，以及最佳反應路徑的建議。一種新穎的多分支反應路徑搜尋 (MBRPS) 演算法能探索所有路徑，特別專注於多分支路徑，協助 LLM 克服多分支路徑中的弱推理。這項工作代表首次嘗試開發一種完全自動化的逆合成規劃代理，專門針對由 LLM 驅動的巨分子量身打造。應用於聚醯亞胺合成，我們的新方法建構了一個包含數百條路徑的逆合成路徑樹，並建議最佳化路徑，包括已知和新穎的路徑，證明其在更廣泛應用中的效能和潛力。

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, Bálint Molnár

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

摘要：傳統基於相似度的模式比對方法無法解決特定領域複雜比對場景中的語意模糊性和衝突，這是因為缺乏常識和特定領域知識。大型語言模型 (LLM) 的幻覺問題也使得基於 LLM 的模式比對難以解決上述問題。因此，我們提出一個基於知識圖譜的檢索增強生成模型，用於模式比對，稱為 KG-RAG4SM。具體而言，KG-RAG4SM 引入了基於向量的、基於圖形遍歷的和基於查詢的圖形檢索，以及一種混合方法和排名方案，這些方案從外部大型知識圖譜 (KG) 中識別最相關的子圖。我們展示了基於 KG 的檢索增強 LLM 能夠在不進行任何重新訓練的情況下為複雜的比對案例生成更準確的結果。我們的實驗結果表明，在 MIMIC 資料集上，KG-RAG4SM 在準確度和 F1 分數方面分別比基於 LLM 的最新 (SOTA) 方法 (例如 Jellyfish-8B) 高出 35.89% 和 30.50%；具有 GPT-4o-mini 的 KG-RAG4SM 在準確度和 F1 分數方面分別比基於預先訓練語言模型 (PLM) 的 SOTA 方法 (例如 SMAT) 高出 69.20% 和 21.97% 在 Synthea 資料集上。結果還表明，我們的做法在端到端模式比對中更有效率，並且可以擴展到從大型 KG 中檢索。我們對來自現實世界模式比對場景的資料集進行的案例研究表明，我們的解決方案很好地緩解了 LLM 在模式比對中的幻覺問題。

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v2 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

摘要：近期成功解決邏輯推理問題的範例，利用了工具增強式大型語言模型 (LLM)，將自然語言陳述翻譯成一階邏輯 (FOL) 和外部定理證明器。
然而，FOL 陳述的正確性包含運算子與文字謂詞，由於缺乏用於比較已產生與真實 FOL 的可靠評估指標，因此經常無法驗證。在本文中，我們提出對現有指標敏感度和其與人類對 FOL 評估判斷一致性的全面研究。使用真實 FOL，我們仔細設計了真實 FOL 的各種擾動，以評估指標敏感度。我們對自然語言陳述取樣 FOL 翻譯候選項，並衡量自動指標與人類註解者之間的排名一致性。我們的經驗發現強調 n-gram 指標 BLEU 對文字擾動的過度敏感性，語義圖形指標 Smatch++ 對結構擾動的過度敏感性，以及 FOL 指標對運算子擾動的過度敏感性。我們還觀察到 BertScore 與人類判斷之間更緊密的對齊。此外，我們表明，與使用個別指標相比，組合指標可增強對齊和敏感度。

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

摘要：隨著 REST API 在現代網路服務中廣泛使用，對這些 API 進行全面的測試變得越來越重要。由於廣大的搜尋空間包含操作、參數和參數值以及它們複雜的依賴關係和約束，目前的測試工具存在程式碼覆蓋率低的問題，導致故障偵測不佳。為了解決這個限制，我們提出一個新工具 AutoRestTest，它整合了語義操作依賴圖 (SODG) 與多智能體強化學習 (MARL) 和大型語言模型 (LLM)，以進行有效的 REST API 測試。AutoRestTest 使用 SODG 確定依賴於操作的參數，並使用五個專門的代理 (操作、參數、值、依賴關係和標頭) 來識別操作的依賴關係並產生操作序列、參數組合和值。AutoRestTest 提供命令列介面和持續遙測，包括成功操作次數、偵測到的唯一伺服器錯誤和經過時間。完成後，AutoRestTest 會產生一份詳細報告，重點說明偵測到的錯誤和執行的操作。在本文中，我們介紹我們的工具並提出初步結果。

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

摘要：現有的低秩適應 (LoRA) 方法由於無法維持稀疏性，在稀疏大型語言模型 (LLM) 上面臨挑戰。最近的作品引入了透過使用額外的遮罩機制來擴充 LoRA 技術的方法來維持稀疏性。儘管有這些成功，但這些方法會增加記憶體和運算的開銷，這會影響 LoRA 方法的效率。為了回應這個限制，我們引入了 LoRS，這是一種創新的方法，旨在在微調稀疏 LLM 時同時實現記憶體和運算效率。為了減輕與維持稀疏性相關的龐大記憶體和運算需求，我們的做法結合了權重重新計算和計算圖形重新排列的策略。此外，我們還透過更好的適配器初始化來提高 LoRS 的有效性。這些創新在微調階段顯著減少了記憶體和運算消耗，同時實現了優於現有 LoRA 方法的效能等級。

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

摘要：在機器學習的當代，Transformer 已成為各種領域的事實標準方法，例如電腦視覺和自然語言處理。基於 Transformer 的解決方案是當前語言生成、影像和影片分類、分割、動作和物件辨識等最新方法的骨幹。有趣的是，雖然這些最新方法在其各自的領域中產生令人印象深刻的結果，但理解視覺和語言之間關係的問題仍然超出了我們的理解範圍。在這項工作中，我們以可解釋且以程式為基礎的方式，在時空中的事件之間提出了視覺和語言的共同基礎，以連接基於學習的視覺和語言最新模型，並提供描述影片的自然語言長期問題的解決方案。我們驗證了我們的演算法方法能夠在從各種資料集收集的影片中產生連貫、豐富且相關的文字描述，同時使用標準指標（例如 Bleu、ROUGE）和現代 LLM 作為評審方法。

##### **In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR**
2501.08120v1 by Markus J. Buehler

The pursuit of automated scientific discovery has fueled progress from
symbolic logic to modern AI, forging new frontiers in reasoning and pattern
recognition. Transformers function as potential systems, where every possible
relationship remains latent potentiality until tasks impose constraints, akin
to measurement. Yet, refining their sampling requires more than probabilistic
selection: solutions must conform to specific structures or rules, ensuring
consistency and the invocation of general principles. We present
Graph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for
Exploratory Optimization of Reasoning), a framework that combines graph
reasoning with symbolic abstraction to dynamically expand domain knowledge.
Inspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a
structured mapping, where tasks yield knowledge graphs, abstract patterns, and
ultimately, final answers. Inspired by category theory, it encodes concepts as
nodes and their relationships as edges, supporting hierarchical inference and
adaptive learning through isomorphic representations. Demonstrations include
hypothesis generation, materials design, and creative reasoning, such as
discovering relationships between mythological concepts like 'thin places' with
materials science. We propose a 'knowledge garden growth' strategy that
integrates insights across domains, promoting interdisciplinary connections.
Results with a 3-billion-parameter Graph-PReFLexOR model show superior
reasoning depth and adaptability, underscoring the potential for transparent,
multidisciplinary AI-driven discovery. It lays the groundwork for general
autonomous reasoning solutions.

摘要：<paragraph>追求自動化科學發現已經推動了從符號邏輯到現代 AI 的進展，在推理和模式識別中開闢了新的領域。Transformer 作為潛在系統運作，其中每種可能的關係都保持潛在潛力，直到任務施加約束，類似於測量。然而，優化其採樣需要的不只是機率選擇：解決方案必須符合特定結構或規則，以確保一致性並呼應一般原則。我們提出了 Graph-PReFLexOR（基於圖形的基於偏好的遞迴語言建模，用於推理的探索性優化），一個將圖形推理與符號抽象相結合以動態擴展領域知識的框架。受強化學習的啟發，Graph-PReFLexOR 將推理定義為結構化對應，任務產生知識圖形、抽象模式以及最終答案。受範疇論的啟發，它將概念編碼為節點，將它們的關係編碼為邊緣，通過同構表示支持階層式推論和自適應學習。示範包括假設生成、材料設計和創造性推理，例如發現神話概念（如「薄弱點」）與材料科學之間的關係。我們提出了一種「知識花園成長」策略，它整合了跨領域的見解，促進了跨學科的聯繫。使用 30 億參數 Graph-PReFLexOR 模型的結果顯示出優異的推理深度和適應性，強調了透明、多學科 AI 驅動發現的潛力。它為通用的自主推理解決方案奠定了基礎。</paragraph>

##### **Reasoning with Graphs: Structuring Implicit Knowledge to Enhance LLMs Reasoning**
2501.07845v1 by Haoyu Han, Yaochen Xie, Hui Liu, Xianfeng Tang, Sreyashi Nag, William Headden, Hui Liu, Yang Li, Chen Luo, Shuiwang Ji, Qi He, Jiliang Tang

Large language models (LLMs) have demonstrated remarkable success across a
wide range of tasks; however, they still encounter challenges in reasoning
tasks that require understanding and inferring relationships between distinct
pieces of information within text sequences. This challenge is particularly
pronounced in tasks involving multi-step processes, such as logical reasoning
and multi-hop question answering, where understanding implicit relationships
between entities and leveraging multi-hop connections in the given context are
crucial. Graphs, as fundamental data structures, explicitly represent pairwise
relationships between entities, thereby offering the potential to enhance LLMs'
reasoning capabilities. External graphs have proven effective in supporting
LLMs across multiple tasks. However, in many reasoning tasks, no pre-existing
graph structure is provided. Can we structure implicit knowledge derived from
context into graphs to assist LLMs in reasoning? In this paper, we propose
Reasoning with Graphs (RwG) by first constructing explicit graphs from the
context and then leveraging these graphs to enhance LLM reasoning performance
on reasoning tasks. Extensive experiments demonstrate the effectiveness of the
proposed method in improving both logical reasoning and multi-hop question
answering tasks.

摘要：大型語言模型 (LLM) 已在各種任務中展現出顯著的成功；然而，它們在推理任務中仍會遇到挑戰，這些任務需要理解和推論文字序列中不同資訊片段之間的關係。這個挑戰在涉及多步驟程序的任務中特別明顯，例如邏輯推理和多跳問題解答，其中理解實體之間的隱含關係並利用給定脈絡中的多跳連接至關重要。圖形作為基本的資料結構，明確表示實體之間成對的關係，從而提供增強 LLM 推理能力的潛力。外部圖形已被證明可以有效支援 LLM 執行多項任務。然而，在許多推理任務中，並沒有提供預先存在的圖形結構。我們能將從脈絡中衍生的隱含知識結構成圖形，以協助 LLM 進行推理嗎？在本文中，我們提出使用圖形進行推理 (RwG)，方法是首先從脈絡中建構明確的圖形，然後利用這些圖形來增強 LLM 在推理任務中的推理效能。廣泛的實驗證明了所提出的方法在改進邏輯推理和多跳問題解答任務方面的有效性。

##### **Flow: A Modular Approach to Automated Agentic Workflow Generation**
2501.07834v1 by Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, Kun Zhang, Tongliang Liu

Multi-agent frameworks powered by large language models (LLMs) have
demonstrated great success in automated planning and task execution. However,
the effective adjustment of Agentic workflows during execution has not been
well-studied. A effective workflow adjustment is crucial, as in many real-world
scenarios, the initial plan must adjust to unforeseen challenges and changing
conditions in real-time to ensure the efficient execution of complex tasks. In
this paper, we define workflows as an activity-on-vertex (AOV) graphs. We
continuously refine the workflow by dynamically adjusting task allocations
based on historical performance and previous AOV with LLM agents. To further
enhance system performance, we emphasize modularity in workflow design based on
measuring parallelism and dependence complexity. Our proposed multi-agent
framework achieved efficient sub-task concurrent execution, goal achievement,
and error tolerance. Empirical results across different practical tasks
demonstrate dramatic improvements in the efficiency of multi-agent frameworks
through dynamic workflow updating and modularization.

摘要：大型語言模型（LLM）驅動的多代理架構已在自動化規劃和任務執行中展現出巨大的成功。然而，在執行期間有效調整代理工作流程尚未得到充分研究。有效的工作流程調整至關重要，因為在許多實際場景中，初始計畫必須即時調整以應對無法預見的挑戰和不斷變化的條件，以確保複雜任務的有效執行。在本文中，我們將工作流程定義為頂點上的活動（AOV）圖形。我們根據歷史績效和先前的 AOV 與 LLM 代理，透過動態調整任務分配，持續優化工作流程。為了進一步提升系統效能，我們強調基於測量並行性和依賴複雜性的工作流程設計中的模組化。我們提出的多代理架構達到了有效子任務並行執行、目標達成和容錯。跨不同實際任務的實證結果證明，透過動態工作流程更新和模組化，多代理架構的效率有了顯著的提升。

##### **Large Language Models for Knowledge Graph Embedding Techniques, Methods, and Challenges: A Survey**
2501.07766v1 by Bingchen Liu, Xin Li

Large Language Models (LLMs) have attracted a lot of attention in various
fields due to their superior performance, aiming to train hundreds of millions
or more parameters on large amounts of text data to understand and generate
natural language. As the superior performance of LLMs becomes apparent, they
are increasingly being applied to knowledge graph embedding (KGE) related tasks
to improve the processing results. As a deep learning model in the field of
Natural Language Processing (NLP), it learns a large amount of textual data to
predict the next word or generate content related to a given text. However,
LLMs have recently been invoked to varying degrees in different types of KGE
related scenarios such as multi-modal KGE and open KGE according to their task
characteristics. In this paper, we investigate a wide range of approaches for
performing LLMs-related tasks in different types of KGE scenarios. To better
compare the various approaches, we summarize each KGE scenario in a
classification. In addition to the categorization methods, we provide a tabular
overview of the methods and their source code links for a more direct
comparison. In the article we also discuss the applications in which the
methods are mainly used and suggest several forward-looking directions for the
development of this new research area.

摘要：大型語言模型 (LLM) 由於其優異的性能，在各個領域中引起了許多關注，目標是訓練數億或更多參數，以理解和產生大量文本資料中的自然語言。隨著 LLM 優異性能的顯現，它們正越來越廣泛地應用於知識圖譜嵌入 (KGE) 相關任務，以改善處理結果。作為自然語言處理 (NLP) 領域中的深度學習模型，它學習大量的文本資料，以預測下一個單字或產生與給定文本相關的內容。然而，根據任務特性，LLM 最近已在不同類型的 KGE 相關場景（例如多模態 KGE 和開放式 KGE）中以不同程度被採用。在本文中，我們探討了在不同類型的 KGE 場景中執行與 LLM 相關任務的各種方法。為了更好地比較各種方法，我們在分類中總結了每個 KGE 場景。除了分類方法之外，我們還提供了方法及其原始碼連結的表格概觀，以便進行更直接的比較。在本文中，我們還討論了這些方法主要用於哪些應用，並建議了幾個這個新研究領域發展的前瞻性方向。

##### **SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models**
2501.07639v1 by Fabien Bernier, Jun Cao, Maxime Cordy, Salah Ghamizi

Efficiently solving Optimal Power Flow (OPF) problems in power systems is
crucial for operational planning and grid management. There is a growing need
for scalable algorithms capable of handling the increasing variability,
constraints, and uncertainties in modern power networks while providing
accurate and fast solutions. To address this, machine learning techniques,
particularly Graph Neural Networks (GNNs) have emerged as promising approaches.
This letter introduces SafePowerGraph-LLM, the first framework explicitly
designed for solving OPF problems using Large Language Models (LLM)s. The
proposed approach combines graph and tabular representations of power grids to
effectively query LLMs, capturing the complex relationships and constraints in
power systems. A new implementation of in-context learning and fine-tuning
protocols for LLMs is introduced, tailored specifically for the OPF problem.
SafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.
Our study reveals the impact of LLM architecture, size, and fine-tuning and
demonstrates our framework's ability to handle realistic grid components and
constraints.

摘要：在電力系統中有效解決最佳電力流 (OPF) 問題對於運營規劃和電網管理至關重要。對於能夠處理現代電力網路中日益增加的可變性、約束和不確定性的可擴充演算法，同時提供準確且快速的解決方案，需求與日俱增。為了解決此問題，機器學習技術，特別是圖神經網路 (GNN) 已成為有前景的方法。本信介紹了 SafePowerGraph-LLM，這是第一個明確設計用於使用大型語言模型 (LLM) 解決 OPF 問題的框架。所提出的方法結合了電力網路的圖形和表格表示，以有效查詢 LLM，捕捉電力系統中的複雜關係和約束。引入了針對 LLM 的情境學習和微調協定的新實作，專門針對 OPF 問題量身打造。SafePowerGraph-LLM 使用現成的 LLM 展示了可靠的效能。我們的研究揭示了 LLM 架構、大小和微調的影響，並展示了我們的框架處理現實電網組成和約束的能力。

##### **ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training**
2501.07078v1 by Jiayang Wu, Wensheng Gan, Jiahao Zhang, Philip S. Yu

In the current development of large language models (LLMs), it is important
to ensure the accuracy and reliability of the underlying data sources. LLMs are
critical for various applications, but they often suffer from hallucinations
and inaccuracies due to knowledge gaps in the training data. Knowledge graphs
(KGs), as a powerful structural tool, could serve as a vital external
information source to mitigate the aforementioned issues. By providing a
structured and comprehensive understanding of real-world data, KGs enhance the
performance and reliability of LLMs. However, it is common that errors exist in
KGs while extracting triplets from unstructured data to construct KGs. This
could lead to degraded performance in downstream tasks such as
question-answering and recommender systems. Therefore, anomaly detection in KGs
is essential to identify and correct these errors. This paper presents an
anomaly detection algorithm in knowledge graphs with dual-channel learning
(ADKGD). ADKGD leverages a dual-channel learning approach to enhance
representation learning from both the entity-view and triplet-view
perspectives. Furthermore, using a cross-layer approach, our framework
integrates internal information aggregation and context information
aggregation. We introduce a kullback-leibler (KL)-loss component to improve the
accuracy of the scoring function between the dual channels. To evaluate ADKGD's
performance, we conduct empirical studies on three real-world KGs: WN18RR,
FB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms
the state-of-the-art anomaly detection algorithms. The source code and datasets
are publicly available at https://github.com/csjywu1/ADKGD.

摘要：<paragraph>在大語言模型（LLM）的當前發展中，確保基礎數據來源的準確性和可靠性非常重要。LLM 對於各種應用至關重要，但由於訓練數據中的知識差距，它們經常會出現幻覺和不準確的情況。知識圖譜 (KG) 作為一種強大的結構化工具，可以作為一個重要的外部信息來源，以減輕上述問題。通過提供對現實世界數據的結構化和全面理解，KG 提高了 LLM 的性能和可靠性。然而，在從非結構化數據中提取三元組以構建 KG 時，KG 中存在錯誤是很常見的。這可能會導致下游任務（例如問答和推薦系統）的性能下降。因此，KG 中的異常檢測對於識別和糾正這些錯誤至關重要。本文提出了一個具有雙通道學習的知識圖譜異常檢測算法 (ADKGD)。ADKGD 利用雙通道學習方法從實體視角和三元組視角增強表示學習。此外，我們的框架使用跨層方法整合了內部信息聚合和上下文信息聚合。我們引入了 Kullback-Leibler (KL) 損失組件，以提高雙通道之間評分函數的準確性。為了評估 ADKGD 的性能，我們對三個真實世界 KG：WN18RR、FB15K 和 NELL-995 進行了實證研究。實驗結果表明，ADKGD 優於最先進的異常檢測算法。源代碼和數據集可在 https://github.com/csjywu1/ADKGD 公開獲得。</paragraph>

##### **Causal Claims in Economics**
2501.06873v1 by Prashant Garg, Thiemo Fetzer

We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a
custom language model to construct knowledge graphs that map economic concepts
and their relationships. We distinguish between general claims and those
documented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document
a substantial rise in the share of causal claims-from roughly 4% in 1990 to
nearly 28% in 2020-reflecting the growing influence of the "credibility
revolution." We find that causal narrative complexity (e.g., the depth of
causal chains) strongly predicts both publication in top-5 journals and higher
citation counts, whereas non-causal complexity tends to be uncorrelated or
negatively associated with these outcomes. Novelty is also pivotal for top-5
publication, but only when grounded in credible causal methods: introducing
genuinely new causal edges or paths markedly increases both the likelihood of
acceptance at leading outlets and long-run citations, while non-causal novelty
exhibits weak or even negative effects. Papers engaging with central, widely
recognized concepts tend to attract more citations, highlighting a divergence
between factors driving publication success and long-term academic impact.
Finally, bridging underexplored concept pairs is rewarded primarily when
grounded in causal methods, yet such gap filling exhibits no consistent link
with future citations. Overall, our findings suggest that methodological rigor
and causal innovation are key drivers of academic recognition, but sustained
impact may require balancing novel contributions with conceptual integration
into established economic discourse.

摘要：<paragraph>我們使用自訂語言模型分析了 1980 年至 2023 年超過 44,000 份 NBER 和 CEPR 工作論文，以建構知識圖譜，對經濟概念及其關係進行對應。我們區分一般性論述和透過因果推論方法（例如 DiD、IV、RDD、RCT）記錄的論述。我們記錄到因果論述的份額大幅上升，從 1990 年的約 4% 上升到 2020 年的近 28%，反映了「可信度革命」的影響力日益增強。我們發現因果敘述的複雜性（例如因果鏈的深度）強烈預測了在頂尖 5 大期刊的發表和較高的引用次數，而非因果複雜性則往往與這些結果無關或呈負相關。新穎性對於頂尖 5 大期刊的發表也至關重要，但前提是建立在可信的因果方法的基礎上：引入真正新的因果邊緣或路徑顯著增加了在頂尖媒體上被接受的可能性和長期引用，而非因果新穎性則表現出微弱甚至負面的影響。探討中心、廣泛認可的概念的論文往往會吸引更多引用，突顯出推動發表成功和長期學術影響的因素之間的差異。最後，填補探索不足的概念對時，主要是建立在因果方法的基礎上，但這種差距填補並未表現出與未來引用的一致關聯。總的來說，我們的研究結果表明，方法論嚴謹性和因果創新是學術認可的主要驅動力，但持續的影響可能需要平衡新穎貢獻與融入既定的經濟論述中的概念整合。</paragraph>

##### **MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation**
2501.06713v3 by Tianyu Fan, Jingyuan Wang, Xubin Ren, Chao Huang

The growing demand for efficient and lightweight Retrieval-Augmented
Generation (RAG) systems has highlighted significant challenges when deploying
Small Language Models (SLMs) in existing RAG frameworks. Current approaches
face severe performance degradation due to SLMs' limited semantic understanding
and text processing capabilities, creating barriers for widespread adoption in
resource-constrained scenarios. To address these fundamental limitations, we
present MiniRAG, a novel RAG system designed for extreme simplicity and
efficiency. MiniRAG introduces two key technical innovations: (1) a
semantic-aware heterogeneous graph indexing mechanism that combines text chunks
and named entities in a unified structure, reducing reliance on complex
semantic understanding, and (2) a lightweight topology-enhanced retrieval
approach that leverages graph structures for efficient knowledge discovery
without requiring advanced language capabilities. Our extensive experiments
demonstrate that MiniRAG achieves comparable performance to LLM-based methods
even when using SLMs while requiring only 25\% of the storage space.
Additionally, we contribute a comprehensive benchmark dataset for evaluating
lightweight RAG systems under realistic on-device scenarios with complex
queries. We fully open-source our implementation and datasets at:
https://github.com/HKUDS/MiniRAG.

摘要：隨著高效且輕量的檢索增強生成 (RAG) 系統需求不斷增加，在現有 RAG 架構中部署小型語言模型 (SLM) 時突顯出重大挑戰。由於 SLM 受限的語義理解和文字處理能力，目前的方法面臨嚴重的效能下降，這為在資源受限的情況下廣泛採用創造了障礙。為了解決這些基本限制，我們提出了 MiniRAG，這是一個專為極致簡潔性和效率而設計的新穎 RAG 系統。MiniRAG 引入了兩項關鍵技術創新：(1) 一個語義感知異質圖形索引機制，它在統一結構中結合了文字區塊和命名實體，減少了對複雜語義理解的依賴，以及 (2) 一種輕量級拓撲增強檢索方法，它利用圖形結構進行有效知識發現，而不需要先進的語言能力。我們廣泛的實驗證明，即使在使用 SLM 時，MiniRAG 也能達到與基於 LLM 的方法相當的效能，同時只需要 25% 的儲存空間。此外，我們為評估輕量級 RAG 系統在具有複雜查詢的實際裝置場景中做出了全面的基準資料集貢獻。我們在以下位置完全開放原始碼實作和資料集：https://github.com/HKUDS/MiniRAG。

##### **Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions**
2501.06699v1 by Aidan Hogan, Xin Luna Dong, Denny Vrandečić, Gerhard Weikum

Much has been discussed about how Large Language Models, Knowledge Graphs and
Search Engines can be combined in a synergistic manner. A dimension largely
absent from current academic discourse is the user perspective. In particular,
there remain many open questions regarding how best to address the diverse
information needs of users, incorporating varying facets and levels of
difficulty. This paper introduces a taxonomy of user information needs, which
guides us to study the pros, cons and possible synergies of Large Language
Models, Knowledge Graphs and Search Engines. From this study, we derive a
roadmap for future research.

摘要：對於大型語言模型、知識圖譜和搜尋引擎如何能以協同的方式結合，已經有許多討論。目前學術論述中很大程度上忽略了一個面向，那就是使用者的觀點。特別是，關於如何最好地滿足使用者多元的資訊需求，並納入不同面向和難度層級，仍有許多未解決的問題。本文介紹了一個使用者資訊需求的分類法，引導我們研究大型語言模型、知識圖譜和搜尋引擎的優缺點和可能的協同作用。從這項研究中，我們衍生出未來研究的路線圖。

##### **Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach**
2501.06628v1 by Mohammed Maree

This paper introduces a neuro-symbolic approach for relational exploration in
cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for
explanation generation and a novel mathematical framework to quantify the
interestingness of relationships. We demonstrate the importance of
interestingness measure using a quantitative analysis, by highlighting its
impact on the overall performance of our proposed system, particularly in terms
of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked
Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of
0.68, and an F1-score of 0.69, representing an improvement compared to
graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based
baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our
LLM-powered explanations exhibit better quality, reflected in BLEU (0.52),
ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline
approaches. We show a strong correlation (0.65) between interestingness measure
and the quality of generated explanations, validating its effectiveness. The
findings highlight the importance of LLMs and a mathematical formalization for
interestingness in enhancing the effectiveness of relational exploration in
cultural heritage knowledge graphs, with results that are measurable and
testable. We further show that the system enables more effective exploration
compared to purely knowledge-based and graph-based methods.

摘要：這篇論文介紹了一種神經符號方法，用於文化遺產知識圖譜中的關係探索，利用大型語言模型 (LLM) 進行解釋生成，並利用一種新穎的數學框架來量化關係的趣味性。我們透過定量分析展示了趣味性測量的重要性，強調它對我們所提出的系統整體效能的影響，特別是在精確度、召回率和 F1 分數方面。使用 Wikidata 文化遺產連結開放資料 (WCH-LOD) 資料集，我們的做法產生了 0.70 的精確度、0.68 的召回率和 0.69 的 F1 分數，與基於圖形 (精確度：0.28、召回率：0.25、F1 分數：0.26) 和基於知識的基線 (精確度：0.45、召回率：0.42、F1 分數：0.43) 相比，這是一個進步。此外，我們由 LLM 促成的解釋展現出更好的品質，反映在 BLEU (0.52)、ROUGE-L (0.58) 和 METEOR (0.63) 分數上，都高於基線方法。我們顯示了趣味性測量和產生的解釋品質之間強烈的相關性 (0.65)，驗證了它的有效性。這些發現突顯了 LLM 和趣味性的數學形式化在增強文化遺產知識圖譜中關係探索的有效性方面的重要性，其結果是可以衡量和測試的。我們進一步表明，與純粹基於知識和基於圖形的方法相比，該系統能進行更有效的探索。

##### **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare**
2501.06465v2 by Ye Chen, Dongdong Huang, Haoyun Xu, Cong Fu, Lin Sheng, Qingli Zhou, Yuqiang Shen, Kai Wang

We introduce the world's first clinical terminology for the Chinese
healthcare community, namely MedCT, accompanied by a clinical foundation model
MedBERT and an entity linking model MedLink. The MedCT system enables
standardized and programmable representation of Chinese clinical data,
successively stimulating the development of new medicines, treatment pathways,
and better patient outcomes for the populous Chinese community. Moreover, the
MedCT knowledge graph provides a principled mechanism to minimize the
hallucination problem of large language models (LLMs), therefore achieving
significant levels of accuracy and safety in LLM-based clinical applications.
By leveraging the LLMs' emergent capabilities of generativeness and
expressiveness, we were able to rapidly built a production-quality terminology
system and deployed to real-world clinical field within three months, while
classical terminologies like SNOMED CT have gone through more than twenty years
development. Our experiments show that the MedCT system achieves
state-of-the-art (SOTA) performance in semantic matching and entity linking
tasks, not only for Chinese but also for English. We also conducted a
longitudinal field experiment by applying MedCT and LLMs in a representative
spectrum of clinical tasks, including electronic health record (EHR)
auto-generation and medical document search for diagnostic decision making. Our
study shows a multitude of values of MedCT for clinical workflows and patient
outcomes, especially in the new genre of clinical LLM applications. We present
our approach in sufficient engineering detail, such that implementing a
clinical terminology for other non-English societies should be readily
reproducible. We openly release our terminology, models and algorithms, along
with real-world clinical datasets for the development.

摘要：<paragraph>我們為中文醫療社群引入了全球首創的臨床術語，即 MedCT，並附帶臨床基礎模型 MedBERT 和實體連結模型 MedLink。MedCT 系統能標準化並以程式設計方式呈現中文臨床資料，進而刺激新藥、治療途徑的開發，並為人口眾多的華人社群帶來更好的病人治療成果。此外，MedCT 知識圖譜提供一個有原則的機制，以最小化大型語言模型 (LLM) 的幻覺問題，因此在基於 LLM 的臨床應用中達到了顯著的準確性和安全性。透過利用 LLM 生成和表達能力的新興功能，我們得以快速建置一個生產品質的術語系統，並在三個月內部署到實際臨床領域，而像 SNOMED CT 這樣的傳統術語系統則經歷了二十多年的開發。我們的實驗顯示，MedCT 系統在語義匹配和實體連結任務中達到了最先進 (SOTA) 的效能，不只適用於中文，也適用於英文。我們還透過在具代表性的臨床任務中應用 MedCT 和 LLM 來進行縱向實地實驗，包括電子健康紀錄 (EHR) 自動產生和用於診斷決策的醫療文件搜尋。我們的研究顯示 MedCT 對臨床工作流程和病人治療成果有許多價值，特別是在新型態的臨床 LLM 應用中。我們以充分的工程細節說明了我們的做法，因此實作其他非英語社會的臨床術語應易於複製。我們開放釋出我們的術語、模型和演算法，以及用於開發的實際臨床資料集。</paragraph>

##### **Dynamics of "Spontaneous" Topic Changes in Next Token Prediction with Self-Attention**
2501.06382v2 by Mumin Jia, Jairo Diaz-Rodriguez

Human cognition can spontaneously shift conversation topics, often triggered
by emotional or contextual signals. In contrast, self-attention-based language
models depend on structured statistical cues from input tokens for next-token
prediction, lacking this spontaneity. Motivated by this distinction, we
investigate the factors that influence the next-token prediction to change the
topic of the input sequence. We define concepts of topic continuity, ambiguous
sequences, and change of topic, based on defining a topic as a set of token
priority graphs (TPGs). Using a simplified single-layer self-attention
architecture, we derive analytical characterizations of topic changes.
Specifically, we demonstrate that (1) the model maintains the priority order of
tokens related to the input topic, (2) a topic change can occur only if
lower-priority tokens outnumber all higher-priority tokens of the input topic,
and (3) unlike human cognition, longer context lengths and overlapping topics
reduce the likelihood of spontaneous redirection. These insights highlight
differences between human cognition and self-attention-based models in
navigating topic changes and underscore the challenges in designing
conversational AI capable of handling "spontaneous" conversations more
naturally. To the best of our knowledge, no prior work has explored these
questions with a focus as closely aligned to human conversation and thought.

摘要：人類認知可以自發轉換對話主題，通常是由情緒或語境信號觸發。相比之下，基於自我注意力的語言模型依賴於輸入詞元的結構化統計線索來預測下一個詞元，缺乏這種自發性。受此區別的啟發，我們研究了影響下一個詞元預測以改變輸入序列主題的因素。我們根據將主題定義為一組詞元優先級圖 (TPG) 來定義主題連續性、模棱兩可的序列和主題變化的概念。使用簡化的單層自我注意力架構，我們推導出主題變化的分析表徵。具體來說，我們證明了 (1) 模型維護與輸入主題相關的詞元的優先順序，(2) 只有當低優先順序的詞元多於輸入主題的所有高優先順序的詞元時，才會發生主題變化，以及 (3) 與人類認知不同，較長的上下文長度和重疊的主題會降低自發重定向的可能性。這些見解突顯了人類認知和基於自我注意力的模型在導航主題變化方面的差異，並強調了設計能夠更自然地處理「自發」對話的對話式 AI 所面臨的挑戰。據我們所知，沒有先前的研究以如此緊密貼近人類對話和思維的方式探討這些問題。

##### **Network Diffuser for Placing-Scheduling Service Function Chains with Inverse Demonstration**
2501.05673v1 by Zuyuan Zhang, Vaneet Aggarwal, Tian Lan

Network services are increasingly managed by considering chained-up virtual
network functions and relevant traffic flows, known as the Service Function
Chains (SFCs). To deal with sequential arrivals of SFCs in an online fashion,
we must consider two closely-coupled problems - an SFC placement problem that
maps SFCs to servers/links in the network and an SFC scheduling problem that
determines when each SFC is executed. Solving the whole SFC problem targeting
these two optimizations jointly is extremely challenging. In this paper, we
propose a novel network diffuser using conditional generative modeling for this
SFC placing-scheduling optimization. Recent advances in generative AI and
diffusion models have made it possible to generate high-quality images/videos
and decision trajectories from language description. We formulate the SFC
optimization as a problem of generating a state sequence for planning and
perform graph diffusion on the state trajectories to enable extraction of SFC
decisions, with SFC optimization constraints and objectives as conditions. To
address the lack of demonstration data due to NP-hardness and exponential
problem space of the SFC optimization, we also propose a novel and somewhat
maverick approach -- Rather than solving instances of this difficult
optimization, we start with randomly-generated solutions as input, and then
determine appropriate SFC optimization problems that render these solutions
feasible. This inverse demonstration enables us to obtain sufficient expert
demonstrations, i.e., problem-solution pairs, through further optimization. In
our numerical evaluations, the proposed network diffuser outperforms learning
and heuristic baselines, by $\sim$20\% improvement in SFC reward and $\sim$50\%
reduction in SFC waiting time and blocking rate.

摘要：網路服務越來越透過考慮串連的虛擬網路功能和相關流量進行管理，稱為服務功能鏈 (SFC)。為了以線上方式處理 SFC 的順序到達，我們必須考慮兩個緊密結合的問題：將 SFC 對應到網路中的伺服器/連結的 SFC 配置問題，以及決定每個 SFC 何時執行的 SFC 排程問題。同時針對這兩個最佳化來解決整個 SFC 問題極具挑戰性。在本文中，我們提出一個使用條件生成模型的創新網路擴散器，用於此 SFC 配置排程最佳化。生成式 AI 和擴散模型的最新進展使得從語言描述中產生高品質的影像/影片和決策軌跡成為可能。我們將 SFC 最佳化制定為產生一個狀態序列的問題，用於規劃，並對狀態軌跡執行圖形擴散，以提取 SFC 決策，並以 SFC 最佳化約束和目標作為條件。為了解決由於 NP 難度和 SFC 最佳化的指數問題空間而導致的示範資料不足，我們也提出一個創新且有點特立獨行的做法：不是解決這個困難最佳化的實例，而是從隨機產生的解作為輸入開始，然後決定適當的 SFC 最佳化問題，讓這些解可行。這個逆向示範讓我們能夠透過進一步最佳化，獲得足夠的專家示範，也就是問題解決配對。在我們的數值評估中，所提出的網路擴散器優於學習和啟發式基準，SFC 獎勵提升了約 20%，SFC 等待時間和封鎖率降低了約 50%。

##### **FlairGPT: Repurposing LLMs for Interior Designs**
2501.04648v1 by Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra

Interior design involves the careful selection and arrangement of objects to
create an aesthetically pleasing, functional, and harmonized space that aligns
with the client's design brief. This task is particularly challenging, as a
successful design must not only incorporate all the necessary objects in a
cohesive style, but also ensure they are arranged in a way that maximizes
accessibility, while adhering to a variety of affordability and usage
considerations. Data-driven solutions have been proposed, but these are
typically room- or domain-specific and lack explainability in their design
design considerations used in producing the final layout. In this paper, we
investigate if large language models (LLMs) can be directly utilized for
interior design. While we find that LLMs are not yet capable of generating
complete layouts, they can be effectively leveraged in a structured manner,
inspired by the workflow of interior designers. By systematically probing LLMs,
we can reliably generate a list of objects along with relevant constraints that
guide their placement. We translate this information into a design layout
graph, which is then solved using an off-the-shelf constrained optimization
setup to generate the final layouts. We benchmark our algorithm in various
design configurations against existing LLM-based methods and human designs, and
evaluate the results using a variety of quantitative and qualitative metrics
along with user studies. In summary, we demonstrate that LLMs, when used in a
structured manner, can effectively generate diverse high-quality layouts,
making them a viable solution for creating large-scale virtual scenes. Project
webpage at https://flairgpt.github.io/

摘要：室內設計涉及仔細挑選和安排物件，以創造一個美觀、實用且和諧的空間，符合客戶的設計簡報。這項任務特別具有挑戰性，因為成功的設計不僅必須以一致的風格納入所有必要的物件，還必須確保它們的排列方式能最大化可及性，同時符合各種負擔能力和使用考量。已經提出了資料驅動的解決方案，但這些解決方案通常是特定於房間或領域，而且缺乏在產生最終佈局時所使用的設計考量的可解釋性。在本文中，我們探討大型語言模型 (LLM) 是否可以直接用於室內設計。雖然我們發現 LLM 尚未能夠產生完整的佈局，但它們可以有效地以結構化的方式利用，靈感來自室內設計師的工作流程。透過系統性地探查 LLM，我們可以可靠地產生一個物件清單，以及指導它們放置位置的相关約束。我們將這些資訊轉換成設計佈局圖，然後使用現成的約束式最佳化設定來解決，以產生最終佈局。我們在各種設計配置中將我們的演算法與現有的基於 LLM 的方法和人類設計進行基準測試，並使用各種量化和質化指標以及使用者研究來評估結果。總之，我們證明了 LLM 在以結構化的方式使用時，可以有效地產生多樣化的高品質佈局，使其成為創造大型虛擬場景的可行解決方案。專案網頁在 https://flairgpt.github.io/

##### **CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection**
2501.04510v1 by Ruijun Feng, Hammond Pearce, Pietro Liguori, Yulei Sui

Large language models (LLMs) have been proposed as powerful tools for
detecting software vulnerabilities, where task-specific fine-tuning is
typically employed to provide vulnerability-specific knowledge to the LLMs for
this purpose. However, traditional full-parameter fine-tuning is inefficient
for modern, complex LLMs, which contain billions of parameters.
  Soft prompt tuning has been suggested as a more efficient alternative for
fine-tuning LLMs in general cases. However, pure soft prompt tuning treats
source code as plain text, losing structural information inherent in source
code. Meanwhile, graph-enhanced soft prompt tuning methods, which aim to
address this issue, are unable to preserve the rich semantic information within
code graphs, as they are primarily designed for general graph-related tasks and
focus more on adjacency information. They also fail to ensure computational
efficiency while accounting for graph-text interactions.
  This paper, therefore, introduces a new code graph-enhanced, structure-aware
soft prompt tuning method for vulnerability detection, referred to as
CGP-Tuning. It employs innovative type-aware embeddings to capture the rich
semantic information within code graphs, along with a novel and efficient
cross-modal alignment module that achieves linear computational cost while
incorporating graph-text interactions. The proposed CGP-Tuning is evaluated on
the latest DiverseVul dataset and the most recent open-source code LLMs,
CodeLlama and CodeGemma. Experimental results demonstrate that CGP-Tuning
outperforms the best state-of-the-art method by an average of 3.5 percentage
points in accuracy, without compromising its vulnerability detection
capabilities for long source code.

摘要：大型語言模型 (LLM) 已被提出用於偵測軟體漏洞的強大工具，其中任務特定微調通常用於提供漏洞特定知識給 LLM 以達到此目的。然而，傳統的完整參數微調對於包含數十億個參數的現代複雜 LLM 來說效率低下。
軟提示微調已被建議作為一般情況下微調 LLM 的更有效替代方案。然而，純軟提示微調將原始碼視為純文字，失去了原始碼中固有的結構資訊。同時，旨在解決此問題的圖形增強軟提示微調方法無法保留程式碼圖形中的豐富語義資訊，因為它們主要設計用於一般的圖形相關任務，且更專注於鄰接資訊。它們也無法在考量圖形文字互動的同時確保運算效率。
因此，本文介紹了一種新的程式碼圖形增強、結構感知軟提示微調方法來偵測漏洞，稱為 CGP-Tuning。它採用創新的類型感知嵌入來擷取程式碼圖形中的豐富語義資訊，以及一個新穎且有效的跨模態對齊模組，該模組在納入圖形文字互動的同時實現線性運算成本。提議的 CGP-Tuning 在最新的 DiverseVul 資料集和最新的開源程式碼 LLM（CodeLlama 和 CodeGemma）上進行評估。實驗結果證明，CGP-Tuning 在準確度方面平均比最佳的現有技術高出 3.5 個百分點，同時不損害其對長原始碼的漏洞偵測能力。

##### **S2 Chunking: A Hybrid Framework for Document Segmentation Through Integrated Spatial and Semantic Analysis**
2501.05485v1 by Prashant Verma

Document chunking is a critical task in natural language processing (NLP)
that involves dividing a document into meaningful segments. Traditional methods
often rely solely on semantic analysis, ignoring the spatial layout of
elements, which is crucial for understanding relationships in complex
documents. This paper introduces a novel hybrid approach that combines layout
structure, semantic analysis, and spatial relationships to enhance the cohesion
and accuracy of document chunks. By leveraging bounding box information (bbox)
and text embeddings, our method constructs a weighted graph representation of
document elements, which is then clustered using spectral clustering.
Experimental results demonstrate that this approach outperforms traditional
methods, particularly in documents with diverse layouts such as reports,
articles, and multi-column designs. The proposed method also ensures that no
chunk exceeds a specified token length, making it suitable for use cases where
token limits are critical (e.g., language models with input size limitations)

摘要：文件分塊是自然語言處理 (NLP) 中的一項關鍵任務，涉及將文件分割成有意義的區塊。傳統方法通常僅依賴語義分析，忽略元素的空間佈局，而這對於理解複雜文件中的關係至關重要。本文介紹一種新穎的混合方法，結合佈局結構、語義分析和空間關係，以增強文件區塊的內聚性和準確性。透過利用邊界框資訊 (bbox) 和文字嵌入，我們的模型建構文件元素的加權圖表表示，然後使用譜聚類進行聚類。實驗結果表明，此方法優於傳統方法，特別是在具有不同佈局的文件中，例如報告、文章和多欄設計。所提出的方法還確保沒有任何區塊超過指定的令牌長度，使其適用於令牌限制至關重要的使用案例（例如，具有輸入大小限制的語言模型）

##### **Multimodal Graph Constrastive Learning and Prompt for ChartQA**
2501.04303v1 by Yue Dai, Soyeon Caren Han, Wei Liu

ChartQA presents significant challenges due to the complex distribution of
chart elements and the implicit patterns embedded within the underlying data.
In this chapter, we have developed a joint multimodal scene graph for charts,
explicitly representing the relationships between chart elements and their
associated patterns.
  Our proposed multimodal scene graph consists of two components: a visual
graph and a textual graph, each designed to capture the structural and semantic
information within the chart. To unify representations across these different
modalities, we introduce a multimodal graph contrastive learning approach that
learns unified representations by maximizing similarity between nodes
representing the same object across multimodal graphs. The learned graph
representations can be seamlessly incorporated into a transformer decoder as a
soft prompt.
  Additionally, given the growing need for Multimodal Large Language Models
(MLLMs) in zero-shot scenarios, we have designed Chain-of-Thought (CoT) prompts
for MLLMs to reduce hallucinations. We tested both methods on public benchmarks
such as ChartQA, OpenCQA, and ChartX, demonstrating improved performance and
validating the effectiveness of our proposed methods.

摘要：ChartQA 因圖表元素的複雜分佈和基礎資料中內嵌的隱含模式而面臨重大挑戰。
在本章中，我們為圖表開發了一個聯合多模態場景圖形，明確表示圖表元素之間的關係及其關聯模式。
我們提出的多模態場景圖形包含兩個組成部分：一個視覺圖形和一個文本圖形，每個組成部分都旨在擷取圖表中的結構化和語義資訊。
為了統一這些不同模態的表示，我們引入了一個多模態圖形對比學習方法，透過最大化跨多模態圖形表示相同物件的節點之間的相似性來學習統一的表示。
學習到的圖形表示可以無縫地整合到Transformer解碼器中，作為一個軟提示。
此外，鑑於多模態大型語言模型 (MLLM) 在零次學習場景中的需求日益增加，我們為 MLLM 設計了思考鏈 (CoT) 提示，以減少幻覺。
我們在公眾基準上測試了這兩種方法，例如 ChartQA、OpenCQA 和 ChartX，證明了效能的提升，並驗證了我們提出的方法的有效性。

##### **Detection, Retrieval, and Explanation Unified: A Violence Detection System Based on Knowledge Graphs and GAT**
2501.06224v2 by Wen-Dong Jiang, Chih-Yung Chang, Diptendu Sinha Roy

Recently, violence detection systems developed using unified multimodal
models have achieved significant success and attracted widespread attention.
However, most of these systems face two critical challenges: the lack of
interpretability as black-box models and limited functionality, offering only
classification or retrieval capabilities. To address these challenges, this
paper proposes a novel interpretable violence detection system, termed the
Three-in-One (TIO) System. The TIO system integrates knowledge graphs (KG) and
graph attention networks (GAT) to provide three core functionalities:
detection, retrieval, and explanation. Specifically, the system processes each
video frame along with text descriptions generated by a large language model
(LLM) for videos containing potential violent behavior. It employs ImageBind to
generate high-dimensional embeddings for constructing a knowledge graph, uses
GAT for reasoning, and applies lightweight time series modules to extract video
embedding features. The final step connects a classifier and retriever for
multi-functional outputs. The interpretability of KG enables the system to
verify the reasoning process behind each output. Additionally, the paper
introduces several lightweight methods to reduce the resource consumption of
the TIO system and enhance its efficiency. Extensive experiments conducted on
the XD-Violence and UCF-Crime datasets validate the effectiveness of the
proposed system. A case study further reveals an intriguing phenomenon: as the
number of bystanders increases, the occurrence of violent behavior tends to
decrease.

摘要：<paragraph>最近，使用統一多模態模型開發的暴力偵測系統取得顯著成功，並引起廣泛關注。然而，大多數這些系統面臨兩個關鍵挑戰：作為黑盒模型缺乏可解釋性，以及功能有限，僅提供分類或檢索功能。為了應對這些挑戰，本文提出了一種新穎的可解釋暴力檢測系統，稱為三合一 (TIO) 系統。TIO 系統整合了知識圖 (KG) 和圖注意力網路 (GAT)，以提供三項核心功能：偵測、檢索和解釋。具體來說，系統處理每個影片幀以及由大型語言模型 (LLM) 為包含潛在暴力行為的影片產生的文字描述。它採用 ImageBind 為構建知識圖產生高維度嵌入，使用 GAT 進行推理，並應用輕量級時間序列模組來提取影片嵌入特徵。最後一步連接分類器和檢索器以取得多功能輸出。KG 的可解釋性使系統能夠驗證每個輸出背後的推理過程。此外，本文介紹了幾種輕量級方法，以減少 TIO 系統的資源消耗並提高其效率。在 XD-Violence 和 UCF-Crime 資料集上進行的廣泛實驗驗證了所提出系統的有效性。案例研究進一步揭示了一個有趣的現象：隨著旁觀者人數的增加，暴力行為的發生趨勢下降。</paragraph>

##### **Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**
2501.03566v1 by Benedikt Reitemeyer, Hans-Georg Fill

The role of large language models (LLMs) in enterprise modeling has recently
started to shift from academic research to that of industrial applications.
Thereby, LLMs represent a further building block for the machine-supported
generation of enterprise models. In this paper we employ a knowledge
graph-based approach for enterprise modeling and investigate the potential
benefits of LLMs in this context. In addition, the findings of an expert survey
and ChatGPT-4o-based experiments demonstrate that LLM-based model generations
exhibit minimal variability, yet remain constrained to specific tasks, with
reliability declining for more intricate tasks. The survey results further
suggest that the supervision and intervention of human modeling experts are
essential to ensure the accuracy and integrity of the generated models.

摘要：大型語言模型 (LLM) 在企業建模中的角色最近已開始從學術研究轉變為產業應用。因此，LLM 代表了機器支援的企業模型生成的進一步建構模組。在本文中，我們採用基於知識圖表的企業建模方法，並探討 LLM 在此脈絡中的潛在效益。此外，專家調查和基於 ChatGPT-4o 的實驗結果表明，基於 LLM 的模型生成展現最小的可變性，但仍侷限於特定任務，而可靠性會隨著任務的複雜性而下降。調查結果進一步表明，人類建模專家的監督和介入對於確保生成模型的準確性和完整性至關重要。

##### **KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**
2501.03560v1 by Zelin Zhou, Simone Conia, Daniel Lee, Min Li, Shenglei Huang, Umar Farooq Minhas, Saloni Potdar, Henry Xiao, Yunyao Li

Multilingual knowledge graphs (KGs) provide high-quality relational and
textual information for various NLP applications, but they are often
incomplete, especially in non-English languages. Previous research has shown
that combining information from KGs in different languages aids either
Knowledge Graph Completion (KGC), the task of predicting missing relations
between entities, or Knowledge Graph Enhancement (KGE), the task of predicting
missing textual information for entities. Although previous efforts have
considered KGC and KGE as independent tasks, we hypothesize that they are
interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a
novel sequence-to-sequence framework that unifies the tasks of textual and
relational information completion for multilingual KGs. KG-TRICK demonstrates
that: i) it is possible to unify the tasks of KGC and KGE into a single
framework, and ii) combining textual information from multiple languages is
beneficial to improve the completeness of a KG. As part of our contributions,
we also introduce WikiKGE10++, the largest manually-curated benchmark for
textual information completion of KGs, which features over 25,000 entities
across 10 diverse languages.

摘要：多語言知識圖譜 (KG) 為各種 NLP 應用程式提供高品質的關係和文字資訊，但它們通常是不完整的，特別是非英語語言。先前的研究顯示，結合不同語言中 KG 的資訊有助於知識圖譜完成功能 (KGC)，即預測實體之間遺失的關係，或知識圖譜增強 (KGE)，即預測實體遺失的文字資訊。儘管先前的努力將 KGC 和 KGE 視為獨立的任務，我們假設它們是相互依賴且互利的。為此，我們引入了 KG-TRICK，一個新穎的序列到序列架構，它統一了多語言 KG 的文字和關係資訊完成任務。KG-TRICK 證明：i) 可以將 KGC 和 KGE 的任務統一到單一架構中，以及 ii) 結合多種語言的文字資訊有助於提高 KG 的完整性。作為我們貢獻的一部分，我們還引入了 WikiKGE10++，這是 KG 文字資訊完成最大的手動整理基準，其特點是超過 10 種不同語言中的 25,000 個實體。

##### **Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**
2501.03166v1 by Ali Al-Lawati, Jason Lucas, Prasenjit Mitra

Large Language Models (LLMs) have demonstrated remarkable performance in
various NLP tasks, including semantic parsing, which trans lates natural
language into formal code representations. However, the reverse process,
translating code into natural language, termed semantic captioning, has
received less attention. This task is becoming increasingly important as LLMs
are integrated into platforms for code generation, security analysis, and
educational purposes. In this paper, we focus on the captioning of SQL query
(SQL2Text) to address the critical need for understanding and explaining SQL
queries in an era where LLM-generated code poses potential security risks. We
repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt
using GPT-4o to generate multiple additional utterances, which enhances the
robustness of the datasets for the reverse task. We conduct our experiments
using in-context learning (ICL) based on different sample selection methods,
emphasizing smaller, more computationally efficient LLMs. Our findings
demonstrate that leveraging the inherent graph properties of SQL for ICL sample
selection significantly outperforms random selection by up to 39% on BLEU score
and provides better results than alternative methods. Dataset and codes are
published: \url{https://github.com/aliwister/ast-icl}.

摘要：大型語言模型 (LLM) 已在各種 NLP 任務中展現出驚人的效能，包括語意分析，它將自然語言轉換為正式的程式碼表示。然而，反向過程，將程式碼轉換為自然語言，稱為語意標題，則較少受到關注。隨著 LLM 整合到程式碼產生、安全性分析和教育目的的平台中，這項任務正變得越來越重要。在本文中，我們專注於 SQL 查詢的標題 (SQL2Text)，以滿足在 LLM 產生的程式碼構成潛在安全風險的時代中，理解和解釋 SQL 查詢的關鍵需求。我們透過使用 GPT-4o 導入反覆的 ICL 提示來產生多個額外的語句，重新調整 Text2SQL 資料集以用於 SQL2Text，這增強了資料集對反向任務的穩健性。我們使用基於不同範例選取方法的情境學習 (ICL) 進行實驗，強調較小、計算效率較高的 LLM。我們的研究結果證明，利用 SQL 的內在圖形屬性進行 ICL 範例選取，在 BLEU 分數上顯著優於隨機選取，最多可達 39%，並提供比其他方法更好的結果。資料集和程式碼已發布：\url{https://github.com/aliwister/ast-icl}。

##### **Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**
2501.03085v1 by Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana

Personalized fashion recommendation is a difficult task because 1) the
decisions are highly correlated with users' aesthetic appetite, which previous
work frequently overlooks, and 2) many new items are constantly rolling out
that cause strict cold-start problems in the popular identity (ID)-based
recommendation methods. These new items are critical to recommend because of
trend-driven consumerism. In this work, we aim to provide more accurate
personalized fashion recommendations and solve the cold-start problem by
converting available information, especially images, into two attribute graphs
focusing on optimized image utilization and noise-reducing user modeling.
Compared with previous methods that separate image and text as two components,
the proposed method combines image and text information to create a richer
attributes graph. Capitalizing on the advancement of large language and vision
models, we experiment with extracting fine-grained attributes efficiently and
as desired using two different prompts. Preliminary experiments on the IQON3000
dataset have shown that the proposed method achieves competitive accuracy
compared with baselines.

摘要：客製化時尚推薦是一項困難的任務，因為 1) 決策與使用者的美學喜好高度相關，而先前的研究經常忽略這一點，以及 2) 許多新商品不斷推出，這會在流行的身分 (ID) 為基礎的推薦方法中造成嚴重的冷啟動問題。這些新商品對於推薦至關重要，因為它們會引領消費趨勢。在這項研究中，我們旨在提供更準確的客製化時尚推薦，並透過將可用資訊（尤其是圖片）轉換成兩個屬性圖表來解決冷啟動問題，重點在於最佳化圖片使用和降低雜訊的使用者建模。與將圖片和文字分開為兩個組成的先前方法相比，所提出的方法結合圖片和文字資訊，以建立更豐富的屬性圖表。利用大型語言和視覺模型的進步，我們嘗試使用兩種不同的提示有效率且如預期般地萃取細緻的屬性。在 IQON3000 資料集上的初步實驗顯示，與基準相比，所提出的方法達到了競爭力的準確度。

##### **Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification**
2501.02844v1 by Yubo Wang, Haoyang Li, Fei Teng, Lei Chen

Text classification is a fundamental task in natural language processing,
pivotal to various applications such as query optimization, data integration,
and schema matching. While neural network-based models, such as CNN and BERT,
have demonstrated remarkable performance in text classification, their
effectiveness heavily relies on abundant labeled training data. This dependency
makes these models less effective in dynamic few-shot text classification,
where labeled data is scarce, and target labels frequently evolve based on
application needs. Recently, large language models (LLMs) have shown promise
due to their extensive pretraining and contextual understanding. Current
approaches provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to predict text labels. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. GORAG constructs and maintains an
adaptive information graph by extracting side information across all target
texts, rather than treating each input independently. It employs a weighted
edge mechanism to prioritize the importance and reliability of extracted
information and dynamically retrieves relevant context using a minimum-cost
spanning tree tailored for each text input. Empirical evaluations demonstrate
that GORAG outperforms existing approaches by providing more comprehensive and
accurate contextual information.

摘要：文本分類是自然語言處理中的基本任務，
對於各種應用至關重要，例如查詢優化、資料整合，
和模式匹配。雖然基於神經網路的模型，例如 CNN 和 BERT，
在文本分類中表現出色，但其
有效性在很大程度上依賴於大量的標籤訓練資料。這個依賴性
使得這些模型在動態少樣本文本分類中效果較差，
其中標籤資料稀缺，並且目標標籤會根據
應用需求頻繁演變。最近，大型語言模型 (LLM) 由於其廣泛的預訓練和上下文理解而顯示出前景。目前
方法為 LLM 提供文本輸入、候選標籤和附加側邊
資訊（例如，描述）以預測文本標籤。然而，其
有效性受到輸入大小增加和側邊資訊處理引入的雜訊的阻礙。為了解決這些限制，我們提出一個
基於圖表的線上檢索增強生成架構，即 GORAG，用於
動態少樣本文本分類。GORAG 通過提取所有目標的側邊資訊來建構並維護一個
自適應資訊圖表
文本，而不是獨立處理每個輸入。它採用加權
邊緣機制來優先考慮提取資訊的重要性及可靠性，並使用針對每個文本輸入量身打造的最小成本
生成樹動態檢索相關的上下文。實證評估表明
GORAG 通過提供更全面且準確的上下文資訊，優於現有方法。

##### **KG-CF: Knowledge Graph Completion with Context Filtering under the Guidance of Large Language Models**
2501.02711v1 by Zaiyi Zheng, Yushun Dong, Song Wang, Haochen Liu, Qi Wang, Jundong Li

Large Language Models (LLMs) have shown impressive performance in various
tasks, including knowledge graph completion (KGC). However, current studies
mostly apply LLMs to classification tasks, like identifying missing triplets,
rather than ranking-based tasks, where the model ranks candidate entities based
on plausibility. This focus limits the practical use of LLMs in KGC, as
real-world applications prioritize highly plausible triplets. Additionally,
while graph paths can help infer the existence of missing triplets and improve
completion accuracy, they often contain redundant information. To address these
issues, we propose KG-CF, a framework tailored for ranking-based KGC tasks.
KG-CF leverages LLMs' reasoning abilities to filter out irrelevant contexts,
achieving superior results on real-world datasets. The code and datasets are
available at \url{https://anonymous.4open.science/r/KG-CF}.

摘要：大型語言模型 (LLM) 在各種任務中展現出令人印象深刻的表現，包括知識圖譜完成功能 (KGC)。然而，目前的研究大多將 LLM 應用於分類任務，例如識別遺漏的三元組，而非基於排名的任務，其中模型根據合理性對候選實體進行排名。這種重點限制了 LLM 在 KGC 中的實際應用，因為現實世界的應用優先考慮高度合理的的三元組。此外，儘管圖形路徑有助於推斷遺漏的三元組的存在並提高完成的準確性，但它們通常包含冗餘資訊。為了解決這些問題，我們提出 KG-CF，一個專門針對基於排名的 KGC 任務的框架。KG-CF 利用 LLM 的推理能力來過濾不相關的上下文，在現實世界的資料集上取得卓越的成果。程式碼和資料集可在 \url{https://anonymous.4open.science/r/KG-CF} 取得。

##### **Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers**
2501.02393v2 by Markus J. Buehler

We present an approach to modifying Transformer architectures by integrating
graph-aware relational reasoning into the attention mechanism, merging concepts
from graph neural networks and language modeling. Building on the inherent
connection between attention and graph theory, we reformulate the Transformer's
attention mechanism as a graph operation and propose Graph-Aware Isomorphic
Attention. This method leverages advanced graph modeling strategies, including
Graph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),
to enrich the representation of relational structures. Our approach captures
complex dependencies and generalizes across tasks, as evidenced by a reduced
generalization gap and improved learning performance. Additionally, we expand
the concept of graph-aware attention to introduce Sparse GIN-Attention, a
fine-tuning approach that employs sparse GINs. By interpreting attention
matrices as sparse adjacency graphs, this technique enhances the adaptability
of pre-trained foundational models with minimal computational overhead,
endowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning
achieves improved training dynamics and better generalization compared to
alternative methods like low-rank adaption (LoRA). We discuss latent graph-like
structures within traditional attention mechanisms, offering a new lens through
which Transformers can be understood. By evolving Transformers as hierarchical
GIN models for relational reasoning. This perspective suggests profound
implications for foundational model development, enabling the design of
architectures that dynamically adapt to both local and global dependencies.
Applications in bioinformatics, materials science, language modeling, and
beyond could benefit from this synthesis of relational and sequential data
modeling, setting the stage for interpretable and generalizable modeling
strategies.

摘要：<paragraph>我們提出了一種修改 Transformer 架構的方法，方法是將圖感知關聯推理整合到注意力機制中，合併圖神經網路和語言模型的概念。基於注意力和圖論之間的內在聯繫，我們將 Transformer 的注意力機制重新表述為圖操作，並提出圖感知同構注意力。此方法利用先進的圖模型策略，包括圖同構網路 (GIN) 和主鄰域聚合 (PNA)，以豐富關係結構的表示。我們的做法捕捉了複雜的依賴關係，並在各項任務中進行概括，這從縮小的概括差距和改善的學習表現中得到證明。此外，我們擴展了圖感知注意力的概念，引入了稀疏 GIN 注意力，這是一種採用稀疏 GIN 的微調方法。通過將注意力矩陣解釋為稀疏鄰接圖，此技術以最小的計算開銷增強了預訓練基礎模型的適應性，賦予它們圖感知能力。與低秩適應 (LoRA) 等替代方法相比，稀疏 GIN 注意力微調實現了改進的訓練動態和更好的概括。我們討論了傳統注意力機制中的潛在圖形結構，提供了一個新的視角，通過它可以理解 Transformer。通過將 Transformer 演化為用於關係推理的分層 GIN 模型。這種觀點對基礎模型的開發具有深遠的影響，可以設計出動態適應局部和全局依賴關係的架構。生物資訊學、材料科學、語言建模等領域的應用可以從這種關係和序列資料建模的綜合中受益，為可解釋和可概括的建模策略奠定基礎。</paragraph>

##### **What Kind of Visual Tokens Do We Need? Training-free Visual Token Pruning for Multi-modal Large Language Models from the Perspective of Graph**
2501.02268v1 by Yutao Jiang, Qiong Wu, Wenhao Lin, Wei Yu, Yiyi Zhou

Recent Multimodal Large Language Models(MLLMs) often use a large number of
visual tokens to compensate their visual shortcoming, leading to excessive
computation and obvious visual redundancy. In this paper, we investigate what
kind of visual tokens are needed for MLLMs, and reveal that both foreground and
background tokens are critical for MLLMs given the varying difficulties of
examples. Based on this observation, we propose a graph-based method towards
training-free visual token pruning, termed G-Prune.In particular, G-Prune
regards visual tokens as nodes, and construct their connections based on their
semantic similarities. Afterwards, the information flow is propagated via
weighted links, and the most important tokens after iterations are kept for
MLLMs, which can be front or background.To validate G-Prune, we apply it to a
recent MLLM called LLaVA-NeXT, and conduct extensive experiments on a set of
benchmarks.The experiment results show that G-Prune can greatly reduce
computation overhead while retaining high performance on both coarse- and
fine-grained tasks. For instance, G-Prune can reduce 63.57\% FLOPs of
LLaVA-NeXT on VQA2.0 and TextVQA with only 0.95\% and 2.34\% accuracy drops,
respectively.

摘要：最近的多模态大型语言模型 (MLLM) 经常使用大量的视觉标记来弥补其视觉上的缺点，导致过度的计算和明显的视觉冗余。在本文中，我们调查了 MLLM 需要哪种视觉标记，并揭示了鉴于示例的难度不同，前景标记和背景标记对于 MLLM 都是至关重要的。基于此观察，我们提出了一种基于图的无训练视觉标记剪枝方法，称为 G-Prune。特别是，G-Prune 将视觉标记视为节点，并根据其语义相似性构建它们的连接。之后，信息流通过加权链接传播，并且在迭代后最重要的标记保留用于 MLLM，它可以是前景或背景。为了验证 G-Prune，我们将其应用于称为 LLaVA-NeXT 的最新 MLLM，并在一组基准上进行了广泛的实验。实验结果表明，G-Prune 可以极大地减少计算开销，同时在粗粒度和细粒度任务上保持高性能。例如，G-Prune 可以将 LLaVA-NeXT 在 VQA2.0 和 TextVQA 上的 FLOP 减少 63.57%，而准确度分别仅下降 0.95% 和 2.34%。

##### **Personalized Graph-Based Retrieval for Large Language Models**
2501.02157v1 by Steven Au, Cameron J. Dimacali, Ojasmitha Pedirappagari, Namyong Park, Franck Dernoncourt, Yu Wang, Nikos Kanakaris, Hanieh Deilamsalehy, Ryan A. Rossi, Nesreen K. Ahmed

As large language models (LLMs) evolve, their ability to deliver personalized
and context-aware responses offers transformative potential for improving user
experiences. Existing personalization approaches, however, often rely solely on
user history to augment the prompt, limiting their effectiveness in generating
tailored outputs, especially in cold-start scenarios with sparse data. To
address these limitations, we propose Personalized Graph-based
Retrieval-Augmented Generation (PGraphRAG), a framework that leverages
user-centric knowledge graphs to enrich personalization. By directly
integrating structured user knowledge into the retrieval process and augmenting
prompts with user-relevant context, PGraphRAG enhances contextual understanding
and output quality. We also introduce the Personalized Graph-based Benchmark
for Text Generation, designed to evaluate personalized text generation tasks in
real-world settings where user history is sparse or unavailable. Experimental
results show that PGraphRAG significantly outperforms state-of-the-art
personalization methods across diverse tasks, demonstrating the unique
advantages of graph-based retrieval for personalization.

摘要：隨著大型語言模型 (LLM) 的演進，它們提供個人化和情境感知回應的能力，為提升使用者體驗提供了變革潛力。然而，現有的個人化方法通常僅依賴使用者記錄來擴充提示，這限制了它們在產生客製化輸出的效能，特別是在資料稀疏的冷啟動情境中。為了解決這些限制，我們提出了「個人化圖形化檢索擴充產生」(PGraphRAG)，一個利用以使用者為中心的知識圖形來豐富個人化的架構。透過將結構化的使用者知識直接整合到檢索程序中，並使用與使用者相關的內容擴充提示，PGraphRAG 增強了情境理解和輸出品質。我們也引入了「個人化圖形化基準文本產生」，旨在評估在使用者記錄稀疏或不可用的真實世界設定中的個人化文本產生任務。實驗結果顯示，PGraphRAG 在各種任務中顯著優於最先進的個人化方法，證明了圖形化檢索在個人化方面的獨特優勢。

##### **Cold-Start Recommendation towards the Era of Large Language Models (LLMs): A Comprehensive Survey and Roadmap**
2501.01945v2 by Weizhi Zhang, Yuanchen Bei, Liangwei Yang, Henry Peng Zou, Peilin Zhou, Aiwei Liu, Yinghui Li, Hao Chen, Jianling Wang, Yu Wang, Feiran Huang, Sheng Zhou, Jiajun Bu, Allen Lin, James Caverlee, Fakhri Karray, Irwin King, Philip S. Yu

Cold-start problem is one of the long-standing challenges in recommender
systems, focusing on accurately modeling new or interaction-limited users or
items to provide better recommendations. Due to the diversification of internet
platforms and the exponential growth of users and items, the importance of
cold-start recommendation (CSR) is becoming increasingly evident. At the same
time, large language models (LLMs) have achieved tremendous success and possess
strong capabilities in modeling user and item information, providing new
potential for cold-start recommendations. However, the research community on
CSR still lacks a comprehensive review and reflection in this field. Based on
this, in this paper, we stand in the context of the era of large language
models and provide a comprehensive review and discussion on the roadmap,
related literature, and future directions of CSR. Specifically, we have
conducted an exploration of the development path of how existing CSR utilizes
information, from content features, graph relations, and domain information, to
the world knowledge possessed by large language models, aiming to provide new
insights for both the research and industrial communities on CSR. Related
resources of cold-start recommendations are collected and continuously updated
for the community in
https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation.

摘要：冷啟動問題是推薦系統中長期存在的挑戰之一，專注於準確建模新的或互動受限的使用者或項目，以提供更好的建議。由於網路平台的多樣化以及使用者和項目的指數級增長，冷啟動推薦 (CSR) 的重要性正變得越來越明顯。同時，大型語言模型 (LLM) 已取得巨大的成功，並具備建模使用者和項目資訊的強大能力，為冷啟動推薦提供了新的潛力。然而，CSR 的研究社群在這個領域仍然缺乏全面的回顧和反思。基於此，在本文中，我們站在大型語言模型的時代背景下，對 CSR 的路線圖、相關文獻和未來方向提供全面的回顧和討論。具體來說，我們對現有 CSR 如何利用資訊進行了探索，從內容特徵、圖關係和領域資訊，到大型語言模型所擁有的世界知識，旨在為研究和產業社群提供 CSR 的新見解。冷啟動推薦的相關資源已收集並持續更新，供社群在 https://github.com/YuanchenBei/Awesome-Cold-Start-Recommendation 中使用。

##### **Multimodal Contrastive Representation Learning in Augmented Biomedical Knowledge Graphs**
2501.01644v1 by Tien Dang, Viet Thanh Duy Nguyen, Minh Tuan Le, Truong-Son Hy

Biomedical Knowledge Graphs (BKGs) integrate diverse datasets to elucidate
complex relationships within the biomedical field. Effective link prediction on
these graphs can uncover valuable connections, such as potential novel
drug-disease relations. We introduce a novel multimodal approach that unifies
embeddings from specialized Language Models (LMs) with Graph Contrastive
Learning (GCL) to enhance intra-entity relationships while employing a
Knowledge Graph Embedding (KGE) model to capture inter-entity relationships for
effective link prediction. To address limitations in existing BKGs, we present
PrimeKG++, an enriched knowledge graph incorporating multimodal data, including
biological sequences and textual descriptions for each entity type. By
combining semantic and relational information in a unified representation, our
approach demonstrates strong generalizability, enabling accurate link
predictions even for unseen nodes. Experimental results on PrimeKG++ and the
DrugBank drug-target interaction dataset demonstrate the effectiveness and
robustness of our method across diverse biomedical datasets. Our source code,
pre-trained models, and data are publicly available at
https://github.com/HySonLab/BioMedKG

摘要：生物医学知識圖譜 (BKG) 整合多樣化的資料集，以闡明生物醫學領域內的複雜關係。在這些圖譜上進行有效的連結預測，可以發現有價值的連結，例如潛在的新藥物-疾病關係。我們引入了一種新穎的多模態方法，它將來自專用語言模型 (LM) 的嵌入與圖形對比學習 (GCL) 統一起來，以增強實體內關係，同時採用知識圖形嵌入 (KGE) 模型來捕捉實體間關係，以進行有效的連結預測。為了解決現有 BKG 中的限制，我們提出了 PrimeKG++，這是一個豐富的知識圖形，它結合了多模態數據，包括每種類型實體的生物序列和文字描述。通過在統一表示中結合語義和關係資訊，我們的做法展示了強大的概括性，即使對於未見節點也能進行準確的連結預測。在 PrimeKG++ 和 DrugBank 藥物-標靶交互作用資料集上的實驗結果證明了我們的方法在各種生物醫學資料集中的有效性和穩健性。我們的原始碼、預訓練模型和資料可在 https://github.com/HySonLab/BioMedKG 公開取得。

##### **Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection**
2501.02020v1 by Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He

Large Language Models (LLMs) are prone to hallucination with non-factual or
unfaithful statements, which undermines the applications in real-world
scenarios. Recent researches focus on uncertainty-based hallucination
detection, which utilizes the output probability of LLMs for uncertainty
calculation and does not rely on external knowledge or frequent sampling from
LLMs. Whereas, most approaches merely consider the uncertainty of each
independent token, while the intricate semantic relations among tokens and
sentences are not well studied, which limits the detection of hallucination
that spans over multiple tokens and sentences in the passage. In this paper, we
propose a method to enhance uncertainty modeling with semantic graph for
hallucination detection. Specifically, we first construct a semantic graph that
well captures the relations among entity tokens and sentences. Then, we
incorporate the relations between two entities for uncertainty propagation to
enhance sentence-level hallucination detection. Given that hallucination occurs
due to the conflict between sentences, we further present a graph-based
uncertainty calibration method that integrates the contradiction probability of
the sentence with its neighbors in the semantic graph for uncertainty
calculation. Extensive experiments on two datasets show the great advantages of
our proposed approach. In particular, we obtain substantial improvements with
19.78% in passage-level hallucination detection.

摘要：大型語言模型 (LLM) 容易出現非事實性或不忠實的陳述，這會破壞現實世界場景中的應用。最近的研究重點關注基於不確定性的幻覺檢測，它利用 LLM 的輸出機率進行不確定性計算，並且不依賴於外部知識或從 LLM 中頻繁取樣。然而，大多數方法僅考慮每個獨立符號的不確定性，而符號和句子之間的複雜語義關係尚未得到很好的研究，這限制了對跨越段落中多個符號和句子的幻覺的檢測。在本文中，我們提出了一種使用語義圖增強不確定性建模以進行幻覺檢測的方法。具體來說，我們首先構建一個語義圖，它很好地捕捉了實體符號和句子之間的關係。然後，我們將兩個實體之間的關係納入不確定性傳播，以增強句子級別的幻覺檢測。由於幻覺是因句子之間的衝突而發生的，因此我們進一步提出了一種基於圖的不確定性校準方法，它將句子的矛盾機率與其在語義圖中的鄰居結合起來進行不確定性計算。在兩個數據集上的廣泛實驗顯示了我們提出的方法的巨大優勢。特別是，我們在段落級別的幻覺檢測中獲得了 19.78% 的顯著改進。

##### **Unfolding the Headline: Iterative Self-Questioning for News Retrieval and Timeline Summarization**
2501.00888v1 by Weiqi Wu, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Hai Zhao

In the fast-changing realm of information, the capacity to construct coherent
timelines from extensive event-related content has become increasingly
significant and challenging. The complexity arises in aggregating related
documents to build a meaningful event graph around a central topic. This paper
proposes CHRONOS - Causal Headline Retrieval for Open-domain News Timeline
SummarizatiOn via Iterative Self-Questioning, which offers a fresh perspective
on the integration of Large Language Models (LLMs) to tackle the task of
Timeline Summarization (TLS). By iteratively reflecting on how events are
linked and posing new questions regarding a specific news topic to gather
information online or from an offline knowledge base, LLMs produce and refresh
chronological summaries based on documents retrieved in each round.
Furthermore, we curate Open-TLS, a novel dataset of timelines on recent news
topics authored by professional journalists to evaluate open-domain TLS where
information overload makes it impossible to find comprehensive relevant
documents from the web. Our experiments indicate that CHRONOS is not only adept
at open-domain timeline summarization, but it also rivals the performance of
existing state-of-the-art systems designed for closed-domain applications,
where a related news corpus is provided for summarization.

摘要：在資訊快速變遷的領域中，從大量的事件相關內容建構連貫的時間軸的能力變得越來越重要且具有挑戰性。複雜性在於彙總相關文件，以圍繞中心主題建立有意義的事件圖。本文提出了 CHRONOS - 開放領域新聞時間軸摘要的因果標題檢索，透過反覆自我提問，提供整合大型語言模型 (LLM) 來處理時間軸摘要 (TLS) 任務的新觀點。透過反覆思考事件如何連結，並對特定新聞主題提出新問題，以從線上或離線知識庫收集資訊，LLM 會根據每輪檢索的文件產生並更新時間摘要。此外，我們策劃了 Open-TLS，一個由專業記者編寫的近期新聞主題時間軸的新穎資料集，以評估開放領域的 TLS，其中資訊過載使得無法從網路上找到全面的相關文件。我們的實驗表明，CHRONOS 不僅擅長開放領域的時間軸摘要，而且還與專為封閉領域應用設計的現有最先進系統的效能相媲美，其中提供了相關的新聞語料庫用於摘要。

##### **Breaking Through the Spike: Spike Window Decoding for Accelerated and Precise Automatic Speech Recognition**
2501.03257v1 by Wei Zhang, Tian-Hao Zhang, Chao Luo, Hui Zhou, Chao Yang, Xinyuan Qian, Xu-Cheng Yin

Recently, end-to-end automatic speech recognition has become the mainstream
approach in both industry and academia. To optimize system performance in
specific scenarios, the Weighted Finite-State Transducer (WFST) is extensively
used to integrate acoustic and language models, leveraging its capacity to
implicitly fuse language models within static graphs, thereby ensuring robust
recognition while also facilitating rapid error correction. However, WFST
necessitates a frame-by-frame search of CTC posterior probabilities through
autoregression, which significantly hampers inference speed. In this work, we
thoroughly investigate the spike property of CTC outputs and further propose
the conjecture that adjacent frames to non-blank spikes carry semantic
information beneficial to the model. Building on this, we propose the Spike
Window Decoding algorithm, which greatly improves the inference speed by making
the number of frames decoded in WFST linearly related to the number of spiking
frames in the CTC output, while guaranteeing the recognition performance. Our
method achieves SOTA recognition accuracy with significantly accelerates
decoding speed, proven across both AISHELL-1 and large-scale In-House datasets,
establishing a pioneering approach for integrating CTC output with WFST.

摘要：近年来，端到端的自动语音识别已成为工业界和学术界的流行方法。为了优化特定场景中的系统性能，加权有限状态转换器 (WFST) 被广泛用于集成声学和语言模型，利用其在静态图中隐式融合语言模型的能力，从而确保稳健的识别，同时促进快速纠错。然而，WFST 需要通过自回归逐帧搜索 CTC 后验概率，这极大地阻碍了推理速度。在这项工作中，我们彻底研究了 CTC 输出的尖峰特性，并进一步提出一个猜想，即非空白尖峰的相邻帧携带对模型有益的语义信息。在此基础上，我们提出了 Spike Window 解码算法，该算法通过使 WFST 中解码的帧数与 CTC 输出中尖峰帧数线性相关，同时保证识别性能，极大地提高了推理速度。我们的方法在 AISHELL-1 和大规模内部数据集上都实现了 SOTA 识别准确度，并显著加快了解码速度，为将 CTC 输出与 WFST 集成建立了先驱方法。

##### **SmartSpatial: Enhancing the 3D Spatial Arrangement Capabilities of Stable Diffusion Models and Introducing a Novel 3D Spatial Evaluation Framework**
2501.01998v1 by Mao Xun Huang, Hen-Hsen Huang

Stable Diffusion models have made remarkable strides in generating
photorealistic images from text prompts but often falter when tasked with
accurately representing complex spatial arrangements, particularly involving
intricate 3D relationships. To address this limitation, we introduce
SmartSpatial, an innovative approach that enhances the spatial arrangement
capabilities of Stable Diffusion models through 3D-aware conditioning and
attention-guided mechanisms. SmartSpatial incorporates depth information and
employs cross-attention control to ensure precise object placement, delivering
notable improvements in spatial accuracy metrics. In conjunction with
SmartSpatial, we present SmartSpatialEval, a comprehensive evaluation framework
designed to assess spatial relationships. This framework utilizes
vision-language models and graph-based dependency parsing for performance
analysis. Experimental results on the COCO and SpatialPrompts datasets show
that SmartSpatial significantly outperforms existing methods, setting new
benchmarks for spatial arrangement accuracy in image generation.

摘要：Stable Diffusion 模型在根據文字提示生成逼真的影像方面取得了顯著進展，但在準確呈現複雜的空間配置時，特別是涉及複雜的 3D 關係時，常常會失敗。為了解決這個限制，我們引入了 SmartSpatial，這是一個創新的方法，透過 3D 感知條件和注意力引導機制，增強 Stable Diffusion 模型的空間配置能力。SmartSpatial 結合深度資訊並採用交叉注意力控制，以確保精確的物件放置，在空間準確度指標方面帶來顯著的改進。結合 SmartSpatial，我們提出了 SmartSpatialEval，這是一個全面的評估架構，旨在評估空間關係。這個架構利用視覺語言模型和基於圖形的依存分析進行效能分析。在 COCO 和 SpatialPrompts 資料集上的實驗結果顯示，SmartSpatial 明顯優於現有方法，為影像生成的空間配置準確度設定了新的基準。

##### **Causal Graph Guided Steering of LLM Values via Prompts and Sparse Autoencoders**
2501.00581v1 by Yipeng Kang, Junqi Wang, Yexin Li, Fangwei Zhong, Xue Feng, Mengmeng Wang, Wenming Tu, Quansen Wang, Hengli Li, Zilong Zheng

As large language models (LLMs) become increasingly integrated into critical
applications, aligning their behavior with human values presents significant
challenges. Current methods, such as Reinforcement Learning from Human Feedback
(RLHF), often focus on a limited set of values and can be resource-intensive.
Furthermore, the correlation between values has been largely overlooked and
remains underutilized. Our framework addresses this limitation by mining a
causal graph that elucidates the implicit relationships among various values
within the LLMs. Leveraging the causal graph, we implement two lightweight
mechanisms for value steering: prompt template steering and Sparse Autoencoder
feature steering, and analyze the effects of altering one value dimension on
others. Extensive experiments conducted on Gemma-2B-IT and Llama3-8B-IT
demonstrate the effectiveness and controllability of our steering methods.

摘要：隨著大型語言模型 (LLM) 日益整合到關鍵應用程式中，讓其行為與人類價值觀一致會帶來重大挑戰。現有的方法，例如人類回饋強化學習 (RLHF)，通常專注於有限的價值觀，且可能耗費大量資源。此外，價值觀之間的關聯性在很大程度上被忽視，且未被充分利用。我們的架構透過探勘因果圖表來解決此限制，該圖表闡明了 LLM 中各種價值觀之間的隱含關係。利用因果圖表，我們實作了兩種輕量級的價值引導機制：提示範本引導和稀疏自編碼器特徵引導，並分析了改變一個價值維度對其他維度的影響。在 Gemma-2B-IT 和 Llama3-8B-IT 上進行的廣泛實驗證明了我們的引導方法的有效性和可控性。

##### **CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care**
2501.00223v1 by Michael Gubanov, Anna Pyayt, Aleksandra Karolak

Here, we describe one of the first Web-scale hybrid Knowledge Graph
(KG)-Large Language Model (LLM), populated with the latest peer-reviewed
medical knowledge on colorectal Cancer. It is currently being evaluated to
assist with both medical research and clinical information retrieval tasks at
Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and
in the world. Our hybrid is remarkable as it serves the user needs better than
just an LLM, KG or a search-engine in isolation. LLMs as is are known to
exhibit hallucinations and catastrophic forgetting as well as are trained on
outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,
ChEMBL, NCBI, and other require manual curation, hence are quickly getting
stale. CancerKG is unsupervised and is capable of automatically ingesting and
organizing the latest medical findings. To alleviate the LLMs shortcomings, the
verified KG serves as a Retrieval Augmented Generation (RAG) guardrail.
CancerKG exhibits 5 different advanced user interfaces, each tailored to serve
different data modalities better and more convenient for the user.

摘要：在此，我们描述了第一个 Web 级混合知识图谱 (KG) - 大型语言模型 (LLM)，其中充斥着有关结直肠癌的最新同行评审医学知识。目前正在评估它以协助 Moffitt 癌症中心进行医学研究和临床信息检索任务，该中心是美国和世界顶级癌症中心之一。我们的混合体非常出色，因为它比孤立的 LLM、KG 或搜索引擎更好地满足用户需求。众所周知，LLM 会出现幻觉和灾难性遗忘，并且是在过时的语料库上进行训练的。最先进的 KG，例如 PrimeKG、cBioPortal、ChEMBL、NCBI 等需要人工整理，因此很快就会过时。CancerKG 无需监督，能够自动摄取和组织最新的医学发现。为了减轻 LLM 的缺点，经过验证的 KG 充当检索增强生成 (RAG) 护栏。CancerKG 展示了 5 种不同的高级用户界面，每种界面都针对服务不同的数据模式，为用户提供更好、更方便的服务。

##### **The Potential of LLMs in Automating Software Testing: From Generation to Reporting**
2501.00217v1 by Betim Sherifi, Khaled Slhoub, Fitzroy Nembhard

Having a high quality software is essential in software engineering, which
requires robust validation and verification processes during testing
activities. Manual testing, while effective, can be time consuming and costly,
leading to an increased demand for automated methods. Recent advancements in
Large Language Models (LLMs) have significantly influenced software
engineering, particularly in areas like requirements analysis, test automation,
and debugging. This paper explores an agent-oriented approach to automated
software testing, using LLMs to reduce human intervention and enhance testing
efficiency. The proposed framework integrates LLMs to generate unit tests,
visualize call graphs, and automate test execution and reporting. Evaluations
across multiple applications in Python and Java demonstrate the system's high
test coverage and efficient operation. This research underscores the potential
of LLM-powered agents to streamline software testing workflows while addressing
challenges in scalability and accuracy.

摘要：在軟體工程中，擁有高品質的軟體至關重要，這需要在測試活動中進行強健的驗證和驗證程序。手動測試雖然有效，但可能耗時且成本高昂，導致對自動化方法的需求增加。大型語言模型 (LLM) 的最新進展顯著影響了軟體工程，特別是在需求分析、測試自動化和除錯等領域。本文探討了一種面向代理的自動化軟體測試方法，使用 LLM 來減少人工干預並提高測試效率。所提出的框架整合了 LLM 來產生單元測試、視覺化呼叫圖表以及自動化測試執行和報告。在 Python 和 Java 中的跨多個應用程式的評估證明了系統的高測試覆蓋率和高效運作。這項研究強調了 LLM 驅動的代理在簡化軟體測試工作流程方面的潛力，同時應對可擴充性和準確性方面的挑戰。

##### **Detection-Fusion for Knowledge Graph Extraction from Videos**
2501.00136v1 by Taniya Das, Louis Mahon, Thomas Lukasiewicz

One of the challenging tasks in the field of video understanding is
extracting semantic content from video inputs. Most existing systems use
language models to describe videos in natural language sentences, but this has
several major shortcomings. Such systems can rely too heavily on the language
model component and base their output on statistical regularities in natural
language text rather than on the visual contents of the video. Additionally,
natural language annotations cannot be readily processed by a computer, are
difficult to evaluate with performance metrics and cannot be easily translated
into a different natural language. In this paper, we propose a method to
annotate videos with knowledge graphs, and so avoid these problems.
Specifically, we propose a deep-learning-based model for this task that first
predicts pairs of individuals and then the relations between them.
Additionally, we propose an extension of our model for the inclusion of
background knowledge in the construction of knowledge graphs.

摘要：影片理解領域中一項具有挑戰性的任務，是從影片輸入中萃取語意內容。現有的大部分系統使用語言模型以自然語言句子描述影片，但這有幾個主要的缺點。此類系統可能過度依賴語言模型組件，並根據自然語言文字中的統計規律，而非影片的視覺內容，來建構其輸出。此外，自然語言註解無法輕易地由電腦處理，難以使用效能指標進行評估，且無法輕易翻譯成不同的自然語言。在本文中，我們提出一個使用知識圖表為影片加上註解的方法，並藉此避免這些問題。具體來說，我們提出一個基於深度學習的模型來執行這項任務，它會先預測個體對，然後再預測個體之間的關係。此外，我們提出一個模型延伸，以將背景知識納入知識圖表的建構中。

##### **Machine Learning-Based Security Policy Analysis**
2501.00085v2 by Krish Jain, Joann Sum, Pranav Kapoor, Amir Eaman

Security-Enhanced Linux (SELinux) is a robust security mechanism that
enforces mandatory access controls (MAC), but its policy language's complexity
creates challenges for policy analysis and management. This research
investigates the automation of SELinux policy analysis using graph-based
techniques combined with machine learning approaches to detect policy
anomalies. The study addresses two key questions: Can SELinux policy analysis
be automated through graph analysis, and how do different anomaly detection
models compare in analyzing SELinux policies? We will be comparing different
machine learning models by evaluating their effectiveness in detecting policy
violations and anomalies. Our approach utilizes Neo4j for graph representation
of policies, with Node2vec transforming these graph structures into meaningful
vector embeddings that can be processed by our machine learning models. In our
results, the MLP Neural Network consistently demonstrated superior performance
across different dataset sizes, achieving 95% accuracy with balanced precision
and recall metrics, while both Random Forest and SVM models showed competitive
but slightly lower performance in detecting policy violations. This combination
of graph-based modeling and machine learning provides a more sophisticated and
automated approach to understanding and analyzing complex SELinux policies
compared to traditional manual analysis methods.

摘要：SELinux（安全強化型 Linux）是一種強大的安全機制，它強制執行強制訪問控制 (MAC)，但其政策語言的複雜性對政策分析和管理提出了挑戰。本研究探討了使用基於圖形技術結合機器學習方法來自動化 SELinux 政策分析，以檢測政策異常。本研究解決了兩個關鍵問題：是否能透過圖形分析自動化 SELinux 政策分析，以及不同的異常檢測模型在分析 SELinux 政策時有何比較？我們將比較不同的機器學習模型，評估它們在檢測政策違規和異常方面的有效性。我們的做法利用 Neo4j 進行政策的圖形表示，Node2vec 將這些圖形結構轉換成有意義的向量嵌入，我們的機器學習模型可以處理這些嵌入。在我們的結果中，MLP 神經網路在不同的資料集大小中始終表現出優異的效能，在平衡的準確度、精確度和召回率指標下達到 95% 的準確度，而隨機森林和 SVM 模型在檢測政策違規方面表現出競爭力，但效能略低。這種基於圖形建模和機器學習的組合提供了一個更精緻且自動化的方式，與傳統的手動分析方法相比，可以理解和分析複雜的 SELinux 政策。

##### **KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation**
2412.20995v1 by Siyuan Fang, Kaijing Ma, Tianyu Zheng, Xinrun Du, Ningxuan Lu, Ge Zhang, Qingkun Tang

Large language models (LLMs) demonstrate exceptional performance across a
variety of tasks, yet they are often affected by hallucinations and the
timeliness of knowledge. Leveraging knowledge graphs (KGs) as external
knowledge sources has emerged as a viable solution, but existing methods for
LLM-based knowledge graph question answering (KGQA) are often limited by
step-by-step decision-making on KGs, restricting the global planning and
reasoning capabilities of LLMs, or they require fine-tuning or pre-training on
specific KGs. To address these challenges, we propose Knowledge graph Assisted
Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global
planning abilities of LLMs for efficient and accurate KG reasoning. KARPA
operates in three steps: pre-planning relation paths using the LLM's global
planning capabilities, matching semantically relevant paths via an embedding
model, and reasoning over these paths to generate answers. Unlike existing KGQA
methods, KARPA avoids stepwise traversal, requires no additional training, and
is adaptable to various LLM architectures. Extensive experimental results show
that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both
high efficiency and accuracy. Our code will be available on Github.

摘要：大型語言模型 (LLM) 在各種任務中表現出色的表現，但它們經常受到幻覺和知識時效性的影響。利用知識圖譜 (KG) 作為外部知識來源已成為一個可行的解決方案，但現有的 LLM 基於知識圖譜問答 (KGQA) 的方法通常受到 KG 上逐步決策的限制，限制了 LLM 的全局規劃和推理能力，或者它們需要針對特定 KG 進行微調或預訓練。為了應對這些挑戰，我們提出了知識圖譜輔助推理路徑聚合 (KARPA)，這是一個新穎的框架，利用 LLM 的全局規劃能力進行高效且準確的 KG 推理。KARPA 分三步操作：使用 LLM 的全局規劃能力預先規劃關係路徑、通過嵌入模型匹配語義相關路徑，以及推理這些路徑以產生答案。與現有的 KGQA 方法不同，KARPA 避免逐步遍歷，不需要額外的訓練，並且可以適應各種 LLM 架構。大量的實驗結果表明，KARPA 在 KGQA 任務中實現了最先進的性能，既提供了高效率又提供了高準確度。我們的程式碼將在 Github 上提供。

##### **Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema**
2412.20942v1 by Xiaohan Feng, Xixin Wu, Helen Meng

We propose an ontology-grounded approach to Knowledge Graph (KG) construction
using Large Language Models (LLMs) on a knowledge base. An ontology is authored
by generating Competency Questions (CQ) on knowledge base to discover knowledge
scope, extracting relations from CQs, and attempt to replace equivalent
relations by their counterpart in Wikidata. To ensure consistency and
interpretability in the resulting KG, we ground generation of KG with the
authored ontology based on extracted relations. Evaluation on benchmark
datasets demonstrates competitive performance in knowledge graph construction
task. Our work presents a promising direction for scalable KG construction
pipeline with minimal human intervention, that yields high quality and
human-interpretable KGs, which are interoperable with Wikidata semantics for
potential knowledge base expansion.

摘要：我們提出一個以本体為基礎的方法來建構知識圖譜（KG），方法是使用大型語言模型（LLM）在知識庫上。本体是由在知識庫上產生能力問題（CQ）來發現知識範圍，從 CQ 中提取關係，並嘗試用 Wikidata 中的對應關係替換等效關係而編寫的。為了確保結果 KG 的一致性和可解釋性，我們根據提取的關係，以編寫的本体為基礎來建立 KG 的產生。在基準資料集上的評估顯示在知識圖譜建構任務中有競爭力的效能。我們的研究提出了一個有希望的方向，可以透過極少的人工介入來建構可擴充的 KG 管線，產生高品質且人類可解釋的 KG，這些 KG 與 Wikidata 語義可以互通，以擴充潛在的知識庫。

##### **ICLR: In-Context Learning of Representations**
2501.00070v1 by Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka

Recent work has demonstrated that semantics specified by pretraining data
influence how representations of different concepts are organized in a large
language model (LLM). However, given the open-ended nature of LLMs, e.g., their
ability to in-context learn, we can ask whether models alter these pretraining
semantics to adopt alternative, context-specified ones. Specifically, if we
provide in-context exemplars wherein a concept plays a different role than what
the pretraining data suggests, do models reorganize their representations in
accordance with these novel semantics? To answer this question, we take
inspiration from the theory of conceptual role semantics and define a toy
"graph tracing" task wherein the nodes of the graph are referenced via concepts
seen during training (e.g., apple, bird, etc.) and the connectivity of the
graph is defined via some predefined structure (e.g., a square grid). Given
exemplars that indicate traces of random walks on the graph, we analyze
intermediate representations of the model and find that as the amount of
context is scaled, there is a sudden re-organization from pretrained semantic
representations to in-context representations aligned with the graph structure.
Further, we find that when reference concepts have correlations in their
semantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure
is still present in the representations, but is unable to dominate the
pretrained structure. To explain these results, we analogize our task to energy
minimization for a predefined graph topology, providing evidence towards an
implicit optimization process to infer context-specified semantics. Overall,
our findings indicate scaling context-size can flexibly re-organize model
representations, possibly unlocking novel capabilities.

摘要：<paragraph>最近的研究表明，由预训练数据指定的语义会影响大型语言模型 (LLM) 中不同概念的表征组织方式。然而，鉴于 LLM 的开放式本质，例如它们在语境中学习的能力，我们可以询问模型是否会改变这些预训练语义以采用替代的、语境指定的语义。具体来说，如果我们在语境中提供示例，其中一个概念扮演的角色与预训练数据所暗示的不同，模型是否会根据这些新语义重新组织它们的表征？为了回答这个问题，我们从概念角色语义理论中汲取灵感，并定义了一个玩具“图示追踪”任务，其中图的节点通过训练期间看到的概念（例如，苹果、鸟等）进行引用，并且图的连通性是通过一些预定义的结构（例如，正方形网格）定义的。给定指示在图上随机游走的轨迹的示例，我们分析了模型的中间表征，发现随着语境量的增加，从预训练语义表征到与图结构对齐的语境表征突然发生了重新组织。此外，我们发现当参考概念在其语义中具有相关性（例如，星期一、星期二等）时，语境指定的图结构仍然存在于表征中，但无法支配预训练结构。为了解释这些结果，我们将我们的任务类比为预定义图拓扑的能量最小化，为推断语境指定语义的隐式优化过程提供了证据。总体而言，我们的研究结果表明，扩展语境大小可以灵活地重新组织模型表征，有可能解锁新的功能。</paragraph>

##### **Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems**
2412.20163v2 by Minhye Jeon, Seokho Ahn, Young-Duk Seo

The use of knowledge graphs in recommender systems has become one of the
common approaches to addressing data sparsity and cold start problems. Recent
advances in large language models (LLMs) offer new possibilities for processing
side and context information within knowledge graphs. However, consistent
integration across various systems remains challenging due to the need for
domain expert intervention and differences in system characteristics. To
address these issues, we propose a consistent approach that extracts both
general and specific topics from both side and context information using LLMs.
First, general topics are iteratively extracted and updated from side
information. Then, specific topics are extracted using context information.
Finally, to address synonymous topics generated during the specific topic
extraction process, a refining algorithm processes and resolves these issues
effectively. This approach allows general topics to capture broad knowledge
across diverse item characteristics, while specific topics emphasize detailed
attributes, providing a more comprehensive understanding of the semantic
features of items and the preferences of users. Experimental results
demonstrate significant improvements in recommendation performance across
diverse knowledge graphs.

摘要：知識圖譜在推薦系統中的使用已成為解決資料稀疏性和冷啟動問題的常見方法之一。大型語言模型 (LLM) 的最新進展為處理知識圖譜中的側邊和背景資訊提供了新的可能性。然而，由於需要領域專家的介入以及系統特性的差異，跨各種系統的一致整合仍然具有挑戰性。為了解決這些問題，我們提出了一種一致的方法，它使用 LLM 從側邊和背景資訊中提取一般和特定主題。首先，從側邊資訊中反覆提取和更新一般主題。然後，使用背景資訊提取特定主題。最後，為了處理在特定主題提取過程中產生的同義主題，一種精煉演算法有效地處理並解決了這些問題。這種方法允許一般主題擷取各種項目特性的廣泛知識，而特定主題則強調詳細屬性，從而更全面地了解項目的語義特徵和使用者的偏好。實驗結果表明，在各種知識圖譜中，推薦效能都有顯著的提升。

##### **From Generalist to Specialist: A Survey of Large Language Models for Chemistry**
2412.19994v1 by Yang Han, Ziping Wan, Lu Chen, Kai Yu, Xin Chen

Large Language Models (LLMs) have significantly transformed our daily life
and established a new paradigm in natural language processing (NLP). However,
the predominant pretraining of LLMs on extensive web-based texts remains
insufficient for advanced scientific discovery, particularly in chemistry. The
scarcity of specialized chemistry data, coupled with the complexity of
multi-modal data such as 2D graph, 3D structure and spectrum, present distinct
challenges. Although several studies have reviewed Pretrained Language Models
(PLMs) in chemistry, there is a conspicuous absence of a systematic survey
specifically focused on chemistry-oriented LLMs. In this paper, we outline
methodologies for incorporating domain-specific chemistry knowledge and
multi-modal information into LLMs, we also conceptualize chemistry LLMs as
agents using chemistry tools and investigate their potential to accelerate
scientific research. Additionally, we conclude the existing benchmarks to
evaluate chemistry ability of LLMs. Finally, we critically examine the current
challenges and identify promising directions for future research. Through this
comprehensive survey, we aim to assist researchers in staying at the forefront
of developments in chemistry LLMs and to inspire innovative applications in the
field.

摘要：大型語言模型 (LLM) 已顯著改變我們的日常生活，並在自然語言處理 (NLP) 中建立了一個新的典範。然而，LLM 在廣泛的基於網路的文本上進行的盛行預訓練對於先進的科學發現仍然不足，特別是在化學領域。專業化學數據的稀缺，加上 2D 圖形、3D 結構和光譜等多模態數據的複雜性，提出了不同的挑戰。儘管一些研究回顧了化學中的預訓練語言模型 (PLM)，但顯著缺乏專注於以化學為導向的 LLM 的系統性調查。在本文中，我們概述了將特定領域的化學知識和多模態資訊納入 LLM 的方法，我們還將化學 LLM 概念化為使用化學工具的代理，並研究它們加速科學研究的潛力。此外，我們總結了現有的基準來評估 LLM 的化學能力。最後，我們批判性地審查了當前的挑戰，並確定了未來研究的有希望的方向。通過這項全面的調查，我們旨在協助研究人員掌握化學 LLM 發展的最前沿，並激發該領域的創新應用。

##### **Toward Adaptive Reasoning in Large Language Models with Thought Rollback**
2412.19707v1 by Sijia Chen, Baochun Li

Large language models (LLMs) have been routinely used to solve various tasks
using step-by-step reasoning. However, the structure of intermediate reasoning
steps, or thoughts, is rigid and unidirectional, such as chains, trees, or
acyclic-directed graphs. Consequently, the resulting inflexible and
forward-only reasoning may not address challenging tasks and fail when the LLM
frequently gives false responses, i.e., ``hallucinations''. This paper proposes
a new reasoning framework, called Thought Rollback (TR), allowing LLMs to
adaptively build thought structure while maintaining effective reasoning toward
problem-solving under ``hallucinations''. The core mechanism of TR is rolling
back thoughts, which allows LLMs to perform error analysis on thoughts, and
thus roll back to any previously mistaken thought for revision. Subsequently,
by including such trial-and-error in the prompt to guide the LLM, each rollback
leads to one more reliable reasoning path. Therefore, starting with a simple
prompt without human annotations, LLM with TR adaptively and gradually explores
thoughts for a correct solution. Comprehensive experiments on mathematical
problems and multi-task reasoning demonstrate the state-of-the-art performance
of TR in terms of problem-solving rate and interaction cost. For instance, the
solving rate of GPT-4 with TR outperforms the current best by $9\%$ on the MATH
dataset.

摘要：大型語言模型（LLM）已常規用於解決各種任務，使用逐步推理。然而，中間推理步驟或想法的結構是僵化且單向的，例如鏈、樹或無環有向圖。因此，產生的僵化且僅向前推理可能無法解決具有挑戰性的任務，並且當 LLM 頻繁給出錯誤的回應（即「幻覺」）時會失敗。本文提出了一個新的推理框架，稱為 Thought Rollback（TR），允許 LLM 在解決「幻覺」問題時自適應地構建思想結構，同時保持有效的推理。TR 的核心機制是回滾思想，它允許 LLM 對思想執行錯誤分析，並因此回滾到任何先前錯誤的思想進行修改。隨後，通過在提示中包含此類試錯來指導 LLM，每次回滾都會導致一條更可靠的推理路徑。因此，從一個沒有人工註釋的簡單提示開始，帶有 TR 的 LLM 自適應地逐漸探索思想以獲得正確的解決方案。在數學問題和多任務推理上的綜合實驗證明了 TR 在問題解決率和交互成本方面的最先進性能。例如，帶有 TR 的 GPT-4 的求解率在 MATH 數據集上比目前的最佳性能高出 9%。

