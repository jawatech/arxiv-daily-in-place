{"2408.07401": {"publish_time": "2024-08-14", "title": "DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization", "paper_summary": "Data visualization (DV) is the fundamental and premise tool to improve the\nefficiency in conveying the insights behind the big data, which has been widely\naccepted in existing data-driven world. Task automation in DV, such as\nconverting natural language queries to visualizations (i.e., text-to-vis),\ngenerating explanations from visualizations (i.e., vis-to-text), answering\nDV-related questions in free form (i.e. FeVisQA), and explicating tabular data\n(i.e., table-to-text), is vital for advancing the field. Despite their\npotential, the application of pre-trained language models (PLMs) like T5 and\nBERT in DV has been limited by high costs and challenges in handling\ncross-modal information, leading to few studies on PLMs for DV. We introduce\n\\textbf{DataVisT5}, a novel PLM tailored for DV that enhances the T5\narchitecture through a hybrid objective pre-training and multi-task fine-tuning\nstrategy, integrating text and DV datasets to effectively interpret cross-modal\nsemantics. Extensive evaluations on public datasets show that DataVisT5\nconsistently outperforms current state-of-the-art models on various DV-related\ntasks. We anticipate that DataVisT5 will not only inspire further research on\nvertical PLMs but also expand the range of applications for PLMs.", "paper_summary_zh": "\u8cc7\u6599\u8996\u89ba\u5316 (DV) \u662f\u5728\u73fe\u4eca\u8cc7\u6599\u9a45\u52d5\u7684\u4e16\u754c\u4e2d\uff0c\u5ee3\u6cdb\u88ab\u63a5\u53d7\u7684\u50b3\u9054\u5927\u6578\u64da\u4e2d\u898b\u89e3\u7684\u57fa\u672c\u4e14\u524d\u63d0\u6027\u7684\u5de5\u5177\uff0c\u4ee5\u63d0\u5347\u50b3\u9054\u6548\u7387\u3002DV \u4e2d\u7684\u4efb\u52d9\u81ea\u52d5\u5316\uff0c\u4f8b\u5982\u5c07\u81ea\u7136\u8a9e\u8a00\u67e5\u8a62\u8f49\u63db\u70ba\u8996\u89ba\u5316\uff08\u5373\u6587\u5b57\u8f49\u8996\u89ba\u5316\uff09\u3001\u5f9e\u8996\u89ba\u5316\u4e2d\u7522\u751f\u8aaa\u660e\uff08\u5373\u8996\u89ba\u5316\u8f49\u6587\u5b57\uff09\u3001\u4ee5\u81ea\u7531\u5f62\u5f0f\u56de\u7b54\u8207 DV \u76f8\u95dc\u7684\u554f\u984c\uff08\u5373 FeVisQA\uff09\u4ee5\u53ca\u95e1\u660e\u8868\u683c\u8cc7\u6599\uff08\u5373\u8868\u683c\u8f49\u6587\u5b57\uff09\uff0c\u5c0d\u65bc\u63a8\u9032\u8a72\u9818\u57df\u81f3\u95dc\u91cd\u8981\u3002\u5118\u7ba1\u6709\u5176\u6f5b\u529b\uff0cT5 \u548c BERT \u7b49\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b (PLM) \u5728 DV \u4e2d\u7684\u61c9\u7528\u53d7\u5230\u9ad8\u6210\u672c\u548c\u8655\u7406\u8de8\u6a21\u614b\u8cc7\u8a0a\u7684\u6311\u6230\u6240\u9650\u5236\uff0c\u5c0e\u81f4\u91dd\u5c0d DV \u7684 PLM \u7814\u7a76\u5f88\u5c11\u3002\u6211\u5011\u4ecb\u7d39\u4e86 \\textbf{DataVisT5}\uff0c\u9019\u662f\u4e00\u500b\u5c08\u70ba DV \u91cf\u8eab\u6253\u9020\u7684\u65b0\u7a4e PLM\uff0c\u5b83\u900f\u904e\u6df7\u5408\u76ee\u6a19\u9810\u8a13\u7df4\u548c\u591a\u4efb\u52d9\u5fae\u8abf\u7b56\u7565\u4f86\u589e\u5f37 T5 \u67b6\u69cb\uff0c\u6574\u5408\u6587\u5b57\u548c DV \u8cc7\u6599\u96c6\u4ee5\u6709\u6548\u8a6e\u91cb\u8de8\u6a21\u614b\u8a9e\u610f\u3002\u5c0d\u516c\u958b\u8cc7\u6599\u96c6\u7684\u5ee3\u6cdb\u8a55\u4f30\u986f\u793a\uff0cDataVisT5 \u5728\u5404\u7a2e\u8207 DV \u76f8\u95dc\u7684\u4efb\u52d9\u4e0a\u59cb\u7d42\u512a\u65bc\u7576\u524d\u6700\u5148\u9032\u7684\u6a21\u578b\u3002\u6211\u5011\u9810\u671f DataVisT5 \u4e0d\u50c5\u5c07\u6fc0\u52f5\u9032\u4e00\u6b65\u7814\u7a76\u5782\u76f4 PLM\uff0c\u9084\u5c07\u64f4\u5c55 PLM \u7684\u61c9\u7528\u7bc4\u570d\u3002", "author": "Zhuoyue Wan et.al.", "authors": "Zhuoyue Wan, Yuanfeng Song, Shuaimin Li, Chen Jason Zhang, Raymond Chi-Wing Wong", "id": "2408.07401v1", "paper_url": "http://arxiv.org/abs/2408.07401v1", "repo": "null"}}