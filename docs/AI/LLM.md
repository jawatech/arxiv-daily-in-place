
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-27**|**Cross-modal Information Flow in Multimodal Large Language Models**|Zhi Zhang et.al.|[2411.18620v1](http://arxiv.org/abs/2411.18620v1)|null|
|**2024-11-27**|**Diffusion Self-Distillation for Zero-Shot Customized Image Generation**|Shengqu Cai et.al.|[2411.18616v1](http://arxiv.org/abs/2411.18616v1)|null|
|**2024-11-27**|**Proactive Gradient Conflict Mitigation in Multi-Task Learning: A Sparse Training Perspective**|Zhi Zhang et.al.|[2411.18615v1](http://arxiv.org/abs/2411.18615v1)|null|
|**2024-11-27**|**Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation**|Nurshat Fateh Ali et.al.|[2411.18583v1](http://arxiv.org/abs/2411.18583v1)|null|
|**2024-11-27**|**On Importance of Code-Mixed Embeddings for Hate Speech Identification**|Shruti Jagdale et.al.|[2411.18577v1](http://arxiv.org/abs/2411.18577v1)|null|
|**2024-11-27**|**Functional relevance based on the continuous Shapley value**|Pedro Delicado et.al.|[2411.18575v1](http://arxiv.org/abs/2411.18575v1)|null|
|**2024-11-27**|**Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA PEFT Tuning**|Omkar Khade et.al.|[2411.18571v1](http://arxiv.org/abs/2411.18571v1)|null|
|**2024-11-27**|**A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models**|Rong Wang et.al.|[2411.18564v1](http://arxiv.org/abs/2411.18564v1)|null|
|**2024-11-27**|**Retrofitting (Large) Language Models with Dynamic Tokenization**|Darius Feher et.al.|[2411.18553v1](http://arxiv.org/abs/2411.18553v1)|null|
|**2024-11-27**|**Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models**|Minhyeok Lee et.al.|[2411.18530v1](http://arxiv.org/abs/2411.18530v1)|[link](https://github.com/BrainJellyPie/self)|
|**2024-11-27**|**NeuroAI for AI Safety**|Patrick Mineault et.al.|[2411.18526v1](http://arxiv.org/abs/2411.18526v1)|null|
|**2024-11-27**|**LLM-ABBA: Understand time series via symbolic approximation**|Erin Carson et.al.|[2411.18506v1](http://arxiv.org/abs/2411.18506v1)|null|
|**2024-11-27**|**SoK: Watermarking for AI-Generated Content**|Xuandong Zhao et.al.|[2411.18479v1](http://arxiv.org/abs/2411.18479v1)|null|
|**2024-11-27**|**Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS**|Jinyang Wu et.al.|[2411.18478v1](http://arxiv.org/abs/2411.18478v1)|null|
|**2024-11-27**|**Weakly Supervised Framework Considering Multi-temporal Information for Large-scale Cropland Mapping with Satellite Imagery**|Yuze Wang et.al.|[2411.18475v1](http://arxiv.org/abs/2411.18475v1)|null|
|**2024-11-27**|**Isolating authorship from content with semantic embeddings and contrastive learning**|Javier Huertas-Tato et.al.|[2411.18472v1](http://arxiv.org/abs/2411.18472v1)|null|
|**2024-11-27**|**Draft Model Knows When to Stop: A Self-Verification Length Policy for Speculative Decoding**|Ziyin Zhang et.al.|[2411.18462v1](http://arxiv.org/abs/2411.18462v1)|[link](https://github.com/geralt-targaryen/svip)|
|**2024-11-27**|**Synthetic ECG Generation for Data Augmentation and Transfer Learning in Arrhythmia Classification**|José Fernando Núñez et.al.|[2411.18456v1](http://arxiv.org/abs/2411.18456v1)|null|
|**2024-11-27**|**Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation**|Marco Pasini et.al.|[2411.18447v1](http://arxiv.org/abs/2411.18447v1)|null|
|**2024-11-27**|**Is my Meeting Summary Good? Estimating Quality with a Multi-LLM Evaluator**|Frederic Kirstein et.al.|[2411.18444v1](http://arxiv.org/abs/2411.18444v1)|null|
|**2024-11-27**|**Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised Metric Learning**|Yasin I. Tepeli et.al.|[2411.18442v1](http://arxiv.org/abs/2411.18442v1)|null|
|**2024-11-27**|**MM-Path: Multi-modal, Multi-granularity Path Representation Learning -- Extended Version**|Ronghui Xu et.al.|[2411.18428v1](http://arxiv.org/abs/2411.18428v1)|[link](https://github.com/decisionintelligence/mm-path)|
|**2024-11-27**|**Politicians vs ChatGPT. A study of presuppositions in French and Italian political communication**|Davide Garassino et.al.|[2411.18403v1](http://arxiv.org/abs/2411.18403v1)|null|
|**2024-11-27**|**Optimal In-Network Distribution of Learning Functions for a Secure-by-Design Programmable Data Plane of Next-Generation Networks**|Mattia Giovanni Spina et.al.|[2411.18384v1](http://arxiv.org/abs/2411.18384v1)|null|
|**2024-11-27**|**Topic Modeling and Sentiment Analysis on Japanese Online Media's Coverage of Nuclear Energy**|Yifan Sun et.al.|[2411.18383v1](http://arxiv.org/abs/2411.18383v1)|null|
|**2024-11-27**|**ChatGPT as speechwriter for the French presidents**|Dominique Labbé et.al.|[2411.18382v1](http://arxiv.org/abs/2411.18382v1)|null|
|**2024-11-27**|**G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation**|Tianxing Chen et.al.|[2411.18369v1](http://arxiv.org/abs/2411.18369v1)|null|
|**2024-11-27**|**AMPS: ASR with Multimodal Paraphrase Supervision**|Amruta Parulekar et.al.|[2411.18368v1](http://arxiv.org/abs/2411.18368v1)|null|
|**2024-11-27**|**GPT as ghostwriter at the White House**|Jacques Savoy et.al.|[2411.18365v1](http://arxiv.org/abs/2411.18365v1)|null|
|**2024-11-27**|**TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models**|Riza Velioglu et.al.|[2411.18350v1](http://arxiv.org/abs/2411.18350v1)|null|
|**2024-11-27**|**FreqX: What neural networks learn is what network designers say**|Zechen Liu et.al.|[2411.18343v1](http://arxiv.org/abs/2411.18343v1)|null|
|**2024-11-27**|**Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation**|T. G. D. K. Sumanathilaka et.al.|[2411.18337v1](http://arxiv.org/abs/2411.18337v1)|null|
|**2024-11-27**|**Helvipad: A Real-World Dataset for Omnidirectional Stereo Depth Estimation**|Mehdi Zayene et.al.|[2411.18335v1](http://arxiv.org/abs/2411.18335v1)|[link](https://github.com/vita-epfl/Helvipad)|
|**2024-11-27**|**RITA: Automatic Framework for Designing of Resilient IoT Applications**|Luis Eduardo Pessoa et.al.|[2411.18324v1](http://arxiv.org/abs/2411.18324v1)|[link](https://github.com/lepessoa/rita)|
|**2024-11-27**|**Continual Learning in Machine Speech Chain Using Gradient Episodic Memory**|Geoffrey Tyndall et.al.|[2411.18320v1](http://arxiv.org/abs/2411.18320v1)|null|
|**2024-11-27**|**MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement**|Xiwei Deng et.al.|[2411.18309v1](http://arxiv.org/abs/2411.18309v1)|null|
|**2024-11-27**|**Application of Soft Actor-Critic Algorithms in Optimizing Wastewater Treatment with Time Delays Integration**|Esmaeel Mohammadi et.al.|[2411.18305v1](http://arxiv.org/abs/2411.18305v1)|null|
|**2024-11-27**|**Aligning Pre-trained Models for Spoken Language Translation**|Šimon Sedláček et.al.|[2411.18294v1](http://arxiv.org/abs/2411.18294v1)|null|
|**2024-11-27**|**DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model**|Xinyu Su et.al.|[2411.18286v1](http://arxiv.org/abs/2411.18286v1)|null|
|**2024-11-27**|**Neutralizing Backdoors through Information Conflicts for Large Language Models**|Chen Chen et.al.|[2411.18280v1](http://arxiv.org/abs/2411.18280v1)|null|
|**2024-11-27**|**Large Language Model-Brained GUI Agents: A Survey**|Chaoyun Zhang et.al.|[2411.18279v1](http://arxiv.org/abs/2411.18279v1)|null|
|**2024-11-27**|**Hidden Data Privacy Breaches in Federated Learning**|Xueluan Gong et.al.|[2411.18269v1](http://arxiv.org/abs/2411.18269v1)|null|
|**2024-11-27**|**Wearable intelligent throat enables natural speech in stroke patients with dysarthria**|Chenyu Tang et.al.|[2411.18266v1](http://arxiv.org/abs/2411.18266v1)|null|
|**2024-11-27**|**MetaphorShare: A Dynamic Collaborative Repository of Open Metaphor Datasets**|Joanne Boisson et.al.|[2411.18260v1](http://arxiv.org/abs/2411.18260v1)|null|
|**2024-11-27**|**Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning**|Melda Yeghaian et.al.|[2411.18253v1](http://arxiv.org/abs/2411.18253v1)|null|
|**2024-11-27**|**IKUN: Initialization to Keep snn training and generalization great with sUrrogate-stable variaNce**|Da Chang et.al.|[2411.18250v1](http://arxiv.org/abs/2411.18250v1)|null|
|**2024-11-27**|**A gentle push funziona benissimo: making instructed models in Italian via contrastive activation steering**|Daniel Scalena et.al.|[2411.18247v1](http://arxiv.org/abs/2411.18247v1)|null|
|**2024-11-27**|**Thai Financial Domain Adaptation of THaLLE -- Technical Report**|KBTG Labs et.al.|[2411.18242v1](http://arxiv.org/abs/2411.18242v1)|null|
|**2024-11-27**|**Exploration of LLM Multi-Agent Application Implementation Based on LangGraph+CrewAI**|Zhihua Duan et.al.|[2411.18241v1](http://arxiv.org/abs/2411.18241v1)|null|
|**2024-11-27**|**Certified Training with Branch-and-Bound: A Case Study on Lyapunov-stable Neural Control**|Zhouxing Shi et.al.|[2411.18235v1](http://arxiv.org/abs/2411.18235v1)|null|
|**2024-11-27**|**Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification**|Abhay Kumar Pathak et.al.|[2411.18234v1](http://arxiv.org/abs/2411.18234v1)|null|
|**2024-11-27**|**Dependency-Aware CAV Task Scheduling via Diffusion-Based Reinforcement Learning**|Xiang Cheng et.al.|[2411.18230v1](http://arxiv.org/abs/2411.18230v1)|null|
|**2024-11-27**|**Feature-Factory: Automating Software Feature Integration Using Generative AI**|Ruslan Idelfonso Magana Vsevolodovna et.al.|[2411.18226v1](http://arxiv.org/abs/2411.18226v1)|null|
|**2024-11-27**|**PATHS: A Hierarchical Transformer for Efficient Whole Slide Image Analysis**|Zak Buzzard et.al.|[2411.18225v1](http://arxiv.org/abs/2411.18225v1)|null|
|**2024-11-27**|**R-MTLLMF: Resilient Multi-Task Large Language Model Fusion at the Wireless Edge**|Aladin Djuhera et.al.|[2411.18220v1](http://arxiv.org/abs/2411.18220v1)|null|
|**2024-11-27**|**How to Learn a New Language? An Efficient Solution for Self-Supervised Learning Models Unseen Languages Adaption in Low-Resource Scenario**|Shih-Heng Wang et.al.|[2411.18217v1](http://arxiv.org/abs/2411.18217v1)|null|
|**2024-11-27**|**SCoTT: Wireless-Aware Path Planning with Vision Language Models and Strategic Chains-of-Thought**|Aladin Djuhera et.al.|[2411.18212v1](http://arxiv.org/abs/2411.18212v1)|null|
|**2024-11-27**|**TimeMarker: A Versatile Video-LLM for Long and Short Video Understanding with Superior Temporal Localization Ability**|Shimin Chen et.al.|[2411.18211v1](http://arxiv.org/abs/2411.18211v1)|[link](https://github.com/timemarker-llm/timemarker)|
|**2024-11-27**|**From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects**|Zizhao Li et.al.|[2411.18207v1](http://arxiv.org/abs/2411.18207v1)|[link](https://github.com/343gltysprk/ovow)|
|**2024-11-27**|**Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning**|Di Zhang et.al.|[2411.18203v1](http://arxiv.org/abs/2411.18203v1)|null|
|**2024-11-27**|**Prediction with Action: Visual Policy Learning via Joint Denoising Process**|Yanjiang Guo et.al.|[2411.18179v1](http://arxiv.org/abs/2411.18179v1)|null|
|**2024-11-27**|**PDZSeg: Adapting the Foundation Model for Dissection Zone Segmentation with Visual Prompts in Robot-assisted Endoscopic Submucosal Dissection**|Mengya Xu et.al.|[2411.18169v1](http://arxiv.org/abs/2411.18169v1)|null|
|**2024-11-27**|**SentiXRL: An advanced large language Model Framework for Multilingual Fine-Grained Emotion Classification in Complex Text Environment**|Jie Wang et.al.|[2411.18162v1](http://arxiv.org/abs/2411.18162v1)|null|
|**2024-11-27**|**A survey on cutting-edge relation extraction techniques based on language models**|Jose A. Diaz-Garcia et.al.|[2411.18157v1](http://arxiv.org/abs/2411.18157v1)|null|
|**2024-11-27**|**MSA-ASR: Efficient Multilingual Speaker Attribution with frozen ASR Models**|Thai-Binh Nguyen et.al.|[2411.18152v1](http://arxiv.org/abs/2411.18152v1)|null|
|**2024-11-27**|**Predicting Water Quality using Quantum Machine Learning: The Case of the Umgeni Catchment (U20A) Study Region**|Muhammad Al-Zafar Khan et.al.|[2411.18141v1](http://arxiv.org/abs/2411.18141v1)|null|
|**2024-11-27**|**SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation**|Wenyi Yu et.al.|[2411.18138v1](http://arxiv.org/abs/2411.18138v1)|null|
|**2024-11-27**|**Curriculum Demonstration Selection for In-Context Learning**|Duc Anh Vu et.al.|[2411.18126v1](http://arxiv.org/abs/2411.18126v1)|null|
|**2024-11-27**|**Training and Evaluating Language Models with Template-based Data Generation**|Yifan Zhang et.al.|[2411.18104v1](http://arxiv.org/abs/2411.18104v1)|[link](https://github.com/iiis-ai/templatemath)|
|**2024-11-27**|**Fine-Tuning Small Embeddings for Elevated Performance**|Biraj Silwal et.al.|[2411.18099v1](http://arxiv.org/abs/2411.18099v1)|null|
|**2024-11-27**|**From Exploration to Revelation: Detecting Dark Patterns in Mobile Apps**|Jieshan Chen et.al.|[2411.18084v1](http://arxiv.org/abs/2411.18084v1)|null|
|**2024-11-27**|**Pushing the Limits of LLM Inference via 2-Bit Layer-Discriminative KV Cache**|Akshat Sharma et.al.|[2411.18077v1](http://arxiv.org/abs/2411.18077v1)|null|
|**2024-11-27**|**Simulating Tabular Datasets through LLMs to Rapidly Explore Hypotheses about Real-World Entities**|Miguel Zabaleta et.al.|[2411.18071v1](http://arxiv.org/abs/2411.18071v1)|[link](https://github.com/mzabaletasar/llm_hypoth_simulation)|
|**2024-11-27**|**PersonaCraft: Personalized Full-Body Image Synthesis for Multiple Identities from Single References Using 3D-Model-Conditioned Diffusion**|Gwanghyun Kim et.al.|[2411.18068v1](http://arxiv.org/abs/2411.18068v1)|null|
|**2024-11-27**|**Heterogeneous Relationships of Subjects and Shapelets for Semi-supervised Multivariate Series Classification**|Mingsen Du et.al.|[2411.18043v1](http://arxiv.org/abs/2411.18043v1)|null|
|**2024-11-27**|**VLM-HOI: Vision Language Models for Interpretable Human-Object Interaction Analysis**|Donggoo Kang et.al.|[2411.18038v1](http://arxiv.org/abs/2411.18038v1)|null|
|**2024-11-27**|**Can bidirectional encoder become the ultimate winner for downstream applications of foundation models?**|Lewen Yang et.al.|[2411.18021v1](http://arxiv.org/abs/2411.18021v1)|null|
|**2024-11-27**|**JPPO: Joint Power and Prompt Optimization for Accelerated Large Language Model Services**|Feiran You et.al.|[2411.18010v1](http://arxiv.org/abs/2411.18010v1)|null|
|**2024-11-27**|**Causal and Local Correlations Based Network for Multivariate Time Series Classification**|Mingsen Du et.al.|[2411.18008v1](http://arxiv.org/abs/2411.18008v1)|null|
|**2024-11-27**|**HAAT: Hybrid Attention Aggregation Transformer for Image Super-Resolution**|Song-Jiang Lai et.al.|[2411.18003v1](http://arxiv.org/abs/2411.18003v1)|null|
|**2024-11-27**|**An End-to-End Two-Stream Network Based on RGB Flow and Representation Flow for Human Action Recognition**|Song-Jiang Lai et.al.|[2411.18002v1](http://arxiv.org/abs/2411.18002v1)|null|
|**2024-11-27**|**DRS: Deep Question Reformulation With Structured Output**|Zhecheng Li et.al.|[2411.17993v1](http://arxiv.org/abs/2411.17993v1)|null|
|**2024-11-27**|**New Faithfulness-Centric Interpretability Paradigms for Natural Language Processing**|Andreas Madsen et.al.|[2411.17992v1](http://arxiv.org/abs/2411.17992v1)|null|
|**2024-11-27**|**VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video Comprehension with Video-Text Duet Interaction Format**|Yueqian Wang et.al.|[2411.17991v1](http://arxiv.org/abs/2411.17991v1)|[link](https://github.com/yellow-binary-tree/mmduet)|
|**2024-11-27**|**Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**|Xiaoxuan Li et.al.|[2411.17989v1](http://arxiv.org/abs/2411.17989v1)|null|
|**2024-11-27**|**Optimized Conformal Selection: Powerful Selective Inference After Conformity Score Optimization**|Tian Bai et.al.|[2411.17983v1](http://arxiv.org/abs/2411.17983v1)|null|
|**2024-11-27**|**The importance of visual modelling languages in generative software engineering**|Roberto Rossi et.al.|[2411.17976v1](http://arxiv.org/abs/2411.17976v1)|null|
|**2024-11-27**|**Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery**|Zhenyu Yu et.al.|[2411.17973v1](http://arxiv.org/abs/2411.17973v1)|null|
|**2024-11-27**|**Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets**|Seungyeon Kim et.al.|[2411.17971v1](http://arxiv.org/abs/2411.17971v1)|null|
|**2024-11-27**|**QuaLLM-Health: An Adaptation of an LLM-Based Framework for Quantitative Data Extraction from Online Health Discussions**|Ramez Kouzy et.al.|[2411.17967v1](http://arxiv.org/abs/2411.17967v1)|[link](https://github.com/ramezkouzy/GLP1-LLM)|
|**2024-11-26**|**MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation**|Sankalp Sinha et.al.|[2411.17945v1](http://arxiv.org/abs/2411.17945v1)|null|
|**2024-11-26**|**Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**|Saman Sarraf et.al.|[2411.17943v1](http://arxiv.org/abs/2411.17943v1)|null|
|**2024-11-26**|**Spatio-temporal Causal Learning for Streamflow Forecasting**|Shu Wan et.al.|[2411.17937v1](http://arxiv.org/abs/2411.17937v1)|null|
|**2024-11-26**|**Neural Networks Use Distance Metrics**|Alan Oursland et.al.|[2411.17932v1](http://arxiv.org/abs/2411.17932v1)|[link](https://github.com/alanoursland/neural_networks_use_distance_metrics)|
|**2024-11-26**|**AI2T: Building Trustable AI Tutors by Interactively Teaching a Self-Aware Learning Agent**|Daniel Weitekamp et.al.|[2411.17924v1](http://arxiv.org/abs/2411.17924v1)|null|
|**2024-11-26**|**Can LLMs plan paths in the real world?**|Wanyi Chen et.al.|[2411.17912v1](http://arxiv.org/abs/2411.17912v1)|null|
|**2024-11-26**|**Automating grapevine LAI features estimation with UAV imagery and machine learning**|Muhammad Waseem Akram et.al.|[2411.17897v1](http://arxiv.org/abs/2411.17897v1)|null|
|**2024-11-26**|**HOPPR Medical-Grade Platform for Medical Imaging AI**|Kalina P. Slavkova et.al.|[2411.17891v1](http://arxiv.org/abs/2411.17891v1)|null|
|**2024-11-26**|**Leveraging Large Language Models and Topic Modeling for Toxicity Classification**|Haniyeh Ehsani Oskouie et.al.|[2411.17876v1](http://arxiv.org/abs/2411.17876v1)|[link](https://github.com/aheldis/toxicity-classification)|
|**2024-11-26**|**LongKey: Keyphrase Extraction for Long Documents**|Jeovane Honorio Alves et.al.|[2411.17863v1](http://arxiv.org/abs/2411.17863v1)|[link](https://github.com/jeohalves/longkey)|

#### Abstracts
##### **Cross-modal Information Flow in Multimodal Large Language Models**
2411.18620v1 by Zhi Zhang, Srishti Yadav, Fengze Han, Ekaterina Shutova

The recent advancements in auto-regressive multimodal large language models
(MLLMs) have demonstrated promising progress for vision-language tasks. While
there exists a variety of studies investigating the processing of linguistic
information within large language models, little is currently known about the
inner working mechanism of MLLMs and how linguistic and visual information
interact within these models. In this study, we aim to fill this gap by
examining the information flow between different modalities -- language and
vision -- in MLLMs, focusing on visual question answering. Specifically, given
an image-question pair as input, we investigate where in the model and how the
visual and linguistic information are combined to generate the final
prediction. Conducting experiments with a series of models from the LLaVA
series, we find that there are two distinct stages in the process of
integration of the two modalities. In the lower layers, the model first
transfers the more general visual features of the whole image into the
representations of (linguistic) question tokens. In the middle layers, it once
again transfers visual information about specific objects relevant to the
question to the respective token positions of the question. Finally, in the
higher layers, the resulting multimodal representation is propagated to the
last position of the input sequence for the final prediction. Overall, our
findings provide a new and comprehensive perspective on the spatial and
functional aspects of image and language processing in the MLLMs, thereby
facilitating future research into multimodal information localization and
editing.

摘要：最近在自動回歸多模態大型語言模型 (MLLM) 方面的進展，已證明在視覺語言任務中具有前景。雖然有許多研究探討大型語言模型中語言資訊的處理方式，但目前鮮少人知道 MLLM 的內部運作機制，以及語言和視覺資訊如何在這些模型中互動。在這項研究中，我們旨在透過探討 MLLM 中不同模態（語言和視覺）之間的資訊流，來填補這項空白，並專注於視覺問題解答。具體來說，給定一對影像問題作為輸入，我們探討模型中的何處以及視覺和語言資訊如何結合以產生最終預測。透過使用 LLaVA 系列的一系列模型進行實驗，我們發現整合這兩個模態的過程中存在兩個不同的階段。在較低層，模型首先將整個影像的更一般視覺特徵轉移到（語言）問題標記的表徵中。在中間層，它再次將與問題相關的特定物件的視覺資訊轉移到問題的各個標記位置。最後，在較高層，將產生的多模態表徵傳播到輸入序列的最後一個位置，以進行最終預測。總體而言，我們的研究結果為 MLLM 中影像和語言處理的空間和功能面向提供了新的全面觀點，從而促進了未來對多模態資訊定位和編輯的研究。

##### **Diffusion Self-Distillation for Zero-Shot Customized Image Generation**
2411.18616v1 by Shengqu Cai, Eric Chan, Yunzhi Zhang, Leonidas Guibas, Jiajun Wu, Gordon Wetzstein

Text-to-image diffusion models produce impressive results but are frustrating
tools for artists who desire fine-grained control. For example, a common use
case is to create images of a specific instance in novel contexts, i.e.,
"identity-preserving generation". This setting, along with many other tasks
(e.g., relighting), is a natural fit for image+text-conditional generative
models. However, there is insufficient high-quality paired data to train such a
model directly. We propose Diffusion Self-Distillation, a method for using a
pre-trained text-to-image model to generate its own dataset for
text-conditioned image-to-image tasks. We first leverage a text-to-image
diffusion model's in-context generation ability to create grids of images and
curate a large paired dataset with the help of a Visual-Language Model. We then
fine-tune the text-to-image model into a text+image-to-image model using the
curated paired dataset. We demonstrate that Diffusion Self-Distillation
outperforms existing zero-shot methods and is competitive with per-instance
tuning techniques on a wide range of identity-preservation generation tasks,
without requiring test-time optimization.

摘要：文本到图像扩散模型产生了令人印象深刻的结果，但对于渴望精细控制的艺术家来说，它们是令人沮丧的工具。例如，一个常见的用例是在新颖的上下文中创建特定实例的图像，即“身份保留生成”。此设置以及许多其他任务（例如重新照明），非常适合图像+文本条件生成模型。然而，没有足够的高质量配对数据来直接训练这样的模型。我们提出了扩散自蒸馏，这是一种使用预训练的文本到图像模型为文本条件图像到图像任务生成其自身数据集的方法。我们首先利用文本到图像扩散模型的上下文生成能力来创建图像网格，并在视觉语言模型的帮助下整理一个大型配对数据集。然后，我们使用整理后的配对数据集将文本到图像模型微调为文本+图像到图像模型。我们证明了扩散自蒸馏优于现有的零样本方法，并且在广泛的身份保留生成任务上与逐个实例调整技术具有竞争力，而不需要测试时间优化。

##### **Proactive Gradient Conflict Mitigation in Multi-Task Learning: A Sparse Training Perspective**
2411.18615v1 by Zhi Zhang, Jiayi Shen, Congfeng Cao, Gaole Dai, Shiji Zhou, Qizhe Zhang, Shanghang Zhang, Ekaterina Shutova

Advancing towards generalist agents necessitates the concurrent processing of
multiple tasks using a unified model, thereby underscoring the growing
significance of simultaneous model training on multiple downstream tasks. A
common issue in multi-task learning is the occurrence of gradient conflict,
which leads to potential competition among different tasks during joint
training. This competition often results in improvements in one task at the
expense of deterioration in another. Although several optimization methods have
been developed to address this issue by manipulating task gradients for better
task balancing, they cannot decrease the incidence of gradient conflict. In
this paper, we systematically investigate the occurrence of gradient conflict
across different methods and propose a strategy to reduce such conflicts
through sparse training (ST), wherein only a portion of the model's parameters
are updated during training while keeping the rest unchanged. Our extensive
experiments demonstrate that ST effectively mitigates conflicting gradients and
leads to superior performance. Furthermore, ST can be easily integrated with
gradient manipulation techniques, thus enhancing their effectiveness.

摘要：邁向通才代理人需要使用統一模型同時處理多項任務，因此強調在多個下游任務上進行同步模型訓練的重要性。多任務學習中的常見問題是梯度衝突的發生，這會導致在聯合訓練期間不同任務之間出現潛在競爭。這種競爭通常會導致一個任務的改進，而以另一個任務的惡化為代價。儘管已經開發了多種最佳化方法來解決這個問題，方法是操作任務梯度以實現更好的任務平衡，但它們無法降低梯度衝突的發生率。在本文中，我們系統性地研究了不同方法中梯度衝突的發生，並提出了一種策略，透過稀疏訓練 (ST) 來減少這種衝突，其中在訓練期間只更新模型參數的一部分，而保持其餘部分不變。我們廣泛的實驗證明，ST 有效地減輕了衝突梯度，並帶來了更好的效能。此外，ST 可以輕鬆地與梯度操作技術整合，從而提高其有效性。

##### **Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation**
2411.18583v1 by Nurshat Fateh Ali, Md. Mahdi Mohtasim, Shakil Mosharrof, T. Gopi Krishna

This research presents and compares multiple approaches to automate the
generation of literature reviews using several Natural Language Processing
(NLP) techniques and retrieval-augmented generation (RAG) with a Large Language
Model (LLM). The ever-increasing number of research articles provides a huge
challenge for manual literature review. It has resulted in an increased demand
for automation. Developing a system capable of automatically generating the
literature reviews from only the PDF files as input is the primary objective of
this research work. The effectiveness of several Natural Language Processing
(NLP) strategies, such as the frequency-based method (spaCy), the transformer
model (Simple T5), and retrieval-augmented generation (RAG) with Large Language
Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR
dataset is chosen for this research experiment and three distinct techniques
are utilized to implement three different systems for auto-generating the
literature reviews. The ROUGE scores are used for the evaluation of all three
systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo
achieved the highest ROUGE-1 score, 0.364. The transformer model comes in
second place and spaCy is at the last position. Finally, a graphical user
interface is created for the best system based on the large language model.

摘要：本研究提出並比較多種自動化生成文獻回顧的方法，這些方法使用多種自然語言處理 (NLP) 技術和檢索增強生成 (RAG) 與大型語言模型 (LLM)。研究文章數量不斷增加，對手動文獻回顧構成巨大挑戰。這導致對自動化的需求增加。開發一個能夠僅從 PDF 檔案作為輸入自動生成文獻回顧的系統是本研究工作的主要目標。評估多種自然語言處理 (NLP) 策略的有效性，例如基於頻率的方法 (spaCy)、Transformer模型 (Simple T5) 和檢索增強生成 (RAG) 與大型語言模型 (GPT-3.5-turbo)，以滿足主要目標。本研究實驗選擇 SciTLDR 資料集，並利用三種不同的技術來實作三個不同的系統，以自動生成文獻回顧。ROUGE 分數用於評估所有三個系統。根據評估，大型語言模型 GPT-3.5-turbo 達到最高的 ROUGE-1 分數 0.364。Transformer模型排名第二，spaCy 排名最後。最後，針對基於大型語言模型的最佳系統建立圖形使用者介面。

##### **On Importance of Code-Mixed Embeddings for Hate Speech Identification**
2411.18577v1 by Shruti Jagdale, Omkar Khade, Gauri Takalikar, Mihir Inamdar, Raviraj Joshi

Code-mixing is the practice of using two or more languages in a single
sentence, which often occurs in multilingual communities such as India where
people commonly speak multiple languages. Classic NLP tools, trained on
monolingual data, face challenges when dealing with code-mixed data. Extracting
meaningful information from sentences containing multiple languages becomes
difficult, particularly in tasks like hate speech detection, due to linguistic
variation, cultural nuances, and data sparsity. To address this, we aim to
analyze the significance of code-mixed embeddings and evaluate the performance
of BERT and HingBERT models (trained on a Hindi-English corpus) in hate speech
detection. Our study demonstrates that HingBERT models, benefiting from
training on the extensive Hindi-English dataset L3Cube-HingCorpus, outperform
BERT models when tested on hate speech text datasets. We also found that
code-mixed Hing-FastText performs better than standard English FastText and
vanilla BERT models.

摘要：代碼混合是指在單一句子中使用兩種或多種語言的實務，這通常發生在像印度這樣的多語言社群中，人們通常會說多種語言。在單語資料上訓練的傳統 NLP 工具在處理代碼混合資料時會遇到挑戰。由於語言變異、文化差異和資料稀疏，從包含多種語言的句子中提取有意義的資訊變得困難，特別是在仇恨言論偵測等任務中。為了解決這個問題，我們旨在分析代碼混合嵌入的重要性，並評估 BERT 和 HingBERT 模型（在印地語-英語語料庫上訓練）在仇恨言論偵測中的效能。我們的研究表明，HingBERT 模型受益於在廣泛的印地語-英語資料集 L3Cube-HingCorpus 上訓練，在仇恨言論文字資料集上測試時優於 BERT 模型。我們還發現，代碼混合 Hing-FastText 的效能優於標準英語 FastText 和香草 BERT 模型。

##### **Functional relevance based on the continuous Shapley value**
2411.18575v1 by Pedro Delicado, Cristian Pachón-García

The presence of Artificial Intelligence (AI) in our society is increasing,
which brings with it the need to understand the behaviour of AI mechanisms,
including machine learning predictive algorithms fed with tabular data, text,
or images, among other types of data. This work focuses on interpretability of
predictive models based on functional data. Designing interpretability methods
for functional data models implies working with a set of features whose size is
infinite. In the context of scalar on function regression, we propose an
interpretability method based on the Shapley value for continuous games, a
mathematical formulation that allows to fairly distribute a global payoff among
a continuous set players. The method is illustrated through a set of
experiments with simulated and real data sets. The open source Python package
ShapleyFDA is also presented.

摘要：隨著人工智慧 (AI) 在我們社會中的存在感日益提升，
這也帶來了理解 AI 機制行為的需求，
包括以表格資料、文字或影像等各種資料類型的機器學習預測演算法。這項工作專注於基於函數資料的預測模型的可解釋性。設計函數資料模型的可解釋性方法意味著使用一組大小為無限大的特徵。在函數回歸的標量背景下，我們提出一個基於連續博弈的 Shapley 值的可解釋性方法，這是一個允許在連續的玩家集合中公平分配全球收益的數學公式。該方法透過一組模擬和真實資料集的實驗來說明。開源 Python 套件 ShapleyFDA 也已發布。

##### **Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA PEFT Tuning**
2411.18571v1 by Omkar Khade, Shruti Jagdale, Abhishek Phaltankar, Gauri Takalikar, Raviraj Joshi

Large Language Models (LLMs) have demonstrated remarkable multilingual
capabilities, yet challenges persist in adapting these models for low-resource
languages. In this study, we investigate the effects of Low-Rank Adaptation
(LoRA) Parameter-Efficient Fine-Tuning (PEFT) on multilingual Gemma models for
Marathi, a language with limited resources. Using a translated Alpaca dataset
with 52,000 instruction-response pairs, our findings reveal that while
evaluation metrics often show a performance decline post-fine-tuning, manual
assessments frequently suggest that the fine-tuned models outperform their
original counterparts. The observations indicate improvements in target
language generation capabilities but a reduction in reasoning abilities
following language adaptation. These results underscore the need for improved
evaluation methodologies and the creation of high-quality native datasets to
accurately assess language-specific model performance in low-resource settings.

摘要：大型語言模型 (LLM) 已展現出非凡的多語言能力，但要調整這些模型以適應低資源語言仍存在挑戰。在本研究中，我們探討了低秩適應 (LoRA) 參數高效微調 (PEFT) 對馬拉地語多語言 Gemma 模型的影響，馬拉地語是一種資源有限的語言。使用包含 52,000 個指令回應配對的已翻譯 Alpaca 資料集，我們的研究結果顯示，雖然評估指標通常顯示微調後的效能下降，但人工評估經常表明微調後的模型優於其原始對應模型。這些觀察結果表明，目標語言生成能力有所提升，但語言適應後推理能力有所下降。這些結果強調了改進評估方法和建立高品質原生資料集的必要性，以便在低資源環境中準確評估特定語言的模型效能。

##### **A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models**
2411.18564v1 by Rong Wang, Kun Sun, Jonas Kuhn

Large Language Models (LLMs) have demonstrated impressive capabilities across
various tasks. However, LLMs often struggle with spatial reasoning which is one
essential part of reasoning and inference and requires understanding complex
relationships between objects in space. This paper proposes a novel
neural-symbolic framework that enhances LLMs' spatial reasoning abilities. We
evaluate our approach on two benchmark datasets: StepGame and SparQA,
implementing three distinct strategies: (1) ASP (Answer Set Programming)-based
symbolic reasoning, (2) LLM + ASP pipeline using DSPy, and (3) Fact + Logical
rules. Our experiments demonstrate significant improvements over the baseline
prompting methods, with accuracy increases of 40-50% on StepGame} dataset and
3-13% on the more complex SparQA dataset. The "LLM + ASP" pipeline achieves
particularly strong results on the tasks of Finding Relations (FR) and Finding
Block (FB) questions, though performance varies across different question
types. The impressive results suggest that while neural-symbolic approaches
offer promising directions for enhancing spatial reasoning in LLMs, their
effectiveness depends heavily on the specific task characteristics and
implementation strategies. We propose an integrated, simple yet effective set
of strategies using a neural-symbolic pipeline to boost spatial reasoning
abilities in LLMs. This pipeline and its strategies demonstrate strong and
broader applicability to other reasoning domains in LLMs, such as temporal
reasoning, deductive inference etc.

摘要：大型語言模型 (LLM) 在各種任務中展示了令人印象深刻的能力。然而，LLM 通常難以進行空間推理，而空間推理是推理和推論的重要組成部分，需要理解空間中物件之間的複雜關係。本文提出了一個新的神經符號框架，以增強 LLM 的空間推理能力。我們在兩個基準資料集上評估我們的做法：StepGame 和 SparQA，實施了三種不同的策略：(1) 基於 ASP（Answer Set Programming）的符號推理，(2) 使用 DSPy 的 LLM + ASP 管線，以及 (3) 事實 + 邏輯規則。我們的實驗證明，與基準提示方法相比，有了顯著的改進，StepGame 資料集的準確度提高了 40-50%，而更複雜的 SparQA 資料集的準確度提高了 3-13%。儘管在不同類型的問題中表現不一，但「LLM + ASP」管線在尋找關係 (FR) 和尋找區塊 (FB) 的問題上取得了特別顯著的結果。令人印象深刻的結果表明，雖然神經符號方法為增強 LLM 中的空間推理提供了有希望的方向，但其有效性在很大程度上取決於具體的任務特徵和實施策略。我們提出了一個整合、簡單但有效的策略集，使用神經符號管線來提升 LLM 中的空間推理能力。這個管線及其策略證明了對 LLM 中其他推理領域的強大而更廣泛的適用性，例如時間推理、演繹推理等。

##### **Retrofitting (Large) Language Models with Dynamic Tokenization**
2411.18553v1 by Darius Feher, Benjamin Minixhofer, Ivan Vulić

Current language models (LMs) use a fixed, static subword tokenizer. This
choice, often taken for granted, typically results in degraded efficiency and
capabilities in languages other than English, and makes it challenging to apply
LMs to new domains or languages. To address these issues, we propose
retrofitting LMs with dynamic tokenization: a way to dynamically decide on
token boundaries based on the input text. For encoder-style models, we
introduce a subword-merging algorithm inspired by byte-pair encoding (BPE), but
at a batch level. We merge frequent subword sequences in a batch, then apply a
pretrained embedding-prediction hypernetwork to compute the token embeddings
on-the-fly. When applied with word-level boundaries, this on average reduces
token sequence lengths by >20% across 14 languages on XNLI with XLM-R while
degrading its task performance by less than 2%. For decoder-style models, we
apply dynamic tokenization in two ways: 1) for prefilling, maintaining
performance of Mistral-7B almost completely with up to 40% sequence reduction -
relative to the word-level; and 2) via an approximate nearest neighbor index,
achieving fast generation with a one million token vocabulary, demonstrating
scalability to even larger, dynamic vocabularies. Overall, our findings show
that dynamic tokenization substantially improves inference speed and promotes
fairness across languages, making a leap towards overcoming the limitations of
static tokenization and enabling more equitable and adaptable LMs.

摘要：當前語言模型（LM）使用固定、靜態的子字詞分詞器。這種選擇通常被視為理所當然，通常會導致英語以外的語言效率和能力降低，並使將 LM 應用於新領域或語言變得具有挑戰性。為了解決這些問題，我們建議使用動態分詞改造 LM：一種根據輸入文字動態決定分詞邊界的途徑。對於編碼器樣式模型，我們引入了一個受位元組對編碼（BPE）啟發的子字詞合併演算法，但處於批次層級。我們合併批次中頻繁的子字詞序列，然後應用預訓練的嵌入預測超網路來即時計算分詞嵌入。當與字元級別邊界一起應用時，這平均將 14 種語言在 XNLI 上使用 XLM-R 的分詞序列長度減少了 >20%，同時其任務效能下降不到 2%。對於解碼器樣式模型，我們以兩種方式應用動態分詞：1）對於預填，幾乎完全保持 Mistral-7B 的效能，序列減少幅度高達 40% - 相對於字元級別；以及 2）透過近似最近鄰索引，實現使用一百萬個分詞詞彙的快速生成，證明了可擴充性甚至更大、動態的詞彙。總體而言，我們的研究結果表明動態分詞顯著提高了推論速度，並促進了跨語言的公平性，朝著克服靜態分詞的限制邁進了一步，並實現了更公平、更具適應性的 LM。

##### **Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models**
2411.18530v1 by Minhyeok Lee

This paper introduces a mathematical framework for defining and quantifying
self-identity in artificial intelligence (AI) systems, addressing a critical
gap in the theoretical foundations of artificial consciousness. While existing
approaches to artificial self-awareness often rely on heuristic implementations
or philosophical abstractions, we present a formal framework grounded in metric
space theory, measure theory, and functional analysis. Our framework posits
that self-identity emerges from two mathematically quantifiable conditions: the
existence of a connected continuum of memories $C \subseteq \mathcal{M}$ in a
metric space $(\mathcal{M}, d_{\mathcal{M}})$, and a continuous mapping $I:
\mathcal{M} \to \mathcal{S}$ that maintains consistent self-recognition across
this continuum, where $(\mathcal{S}, d_{\mathcal{S}})$ represents the metric
space of possible self-identities. To validate this theoretical framework, we
conducted empirical experiments using the Llama 3.2 1B model, employing
Low-Rank Adaptation (LoRA) for efficient fine-tuning. The model was trained on
a synthetic dataset containing temporally structured memories, designed to
capture the complexity of coherent self-identity formation. Our evaluation
metrics included quantitative measures of self-awareness, response consistency,
and linguistic precision. The experimental results demonstrate substantial
improvements in measurable self-awareness metrics, with the primary
self-awareness score increasing from 0.276 to 0.801. This enables the
structured creation of AI systems with validated self-identity features. The
implications of our study are immediately relevant to the fields of humanoid
robotics and autonomous systems.

摘要：本文提出了一個數學框架，用於定義和量化人工智慧 (AI) 系統中的自我認同，解決了人工意識理論基礎中的關鍵差距。雖然現有的自我意識方法通常依賴於啟發式實作或哲學抽象，但我們提出了一个正式的框架，它建立在度量空間理論、測度理論和泛函分析的基礎上。我們的框架假設自我認同源於兩個數學上可量化的條件：度量空間 $(\mathcal{M}, d_{\mathcal{M}})$ 中存在連續的記憶連續統 $C \subseteq \mathcal{M}$，以及連續映射 $I: \mathcal{M} \to \mathcal{S}$，它在這個連續統中維持一致的自我認知，其中 $(\mathcal{S}, d_{\mathcal{S}})$ 代表可能的自我認同的度量空間。為了驗證這個理論框架，我們使用 Llama 3.2 1B 模型進行了實證實驗，採用低秩適應 (LoRA) 以進行有效微調。這個模型在包含時間結構記憶的合成資料集上進行訓練，旨在捕捉連貫自我認同形成的複雜性。我們的評估指標包括自我意識、回應一致性和語言精確度的量化測量。實驗結果證明了可測量自我意識指標的顯著改善，主要的自我意識分數從 0.276 提高到 0.801。這使得能夠以結構化的方式建立具有驗證自我認同特徵的人工智慧系統。我們研究的影響與類人機器人和自主系統領域直接相關。

##### **NeuroAI for AI Safety**
2411.18526v1 by Patrick Mineault, Niccolò Zanichelli, Joanne Zichen Peng, Anton Arkhipov, Eli Bingham, Julian Jara-Ettinger, Emily Mackevicius, Adam Marblestone, Marcelo Mattar, Andrew Payne, Sophia Sanborn, Karen Schroeder, Zenna Tavares, Andreas Tolias

As AI systems become increasingly powerful, the need for safe AI has become
more pressing. Humans are an attractive model for AI safety: as the only known
agents capable of general intelligence, they perform robustly even under
conditions that deviate significantly from prior experiences, explore the world
safely, understand pragmatics, and can cooperate to meet their intrinsic goals.
Intelligence, when coupled with cooperation and safety mechanisms, can drive
sustained progress and well-being. These properties are a function of the
architecture of the brain and the learning algorithms it implements.
Neuroscience may thus hold important keys to technical AI safety that are
currently underexplored and underutilized. In this roadmap, we highlight and
critically evaluate several paths toward AI safety inspired by neuroscience:
emulating the brain's representations, information processing, and
architecture; building robust sensory and motor systems from imitating brain
data and bodies; fine-tuning AI systems on brain data; advancing
interpretability using neuroscience methods; and scaling up
cognitively-inspired architectures. We make several concrete recommendations
for how neuroscience can positively impact AI safety.

摘要：隨著 AI 系統變得越來越強大，對安全 AI 的需求也變得更加迫切。人類是 AI 安全的有吸引力模型：作為唯一已知具備一般智慧的代理，即使在與先前經驗有顯著差異的條件下，他們也能表現得很好，安全地探索世界，理解語用學，並可以合作以實現其內在目標。智慧與合作和安全機制相結合，可以推動持續進步和福祉。這些特性是大腦架構和它實施的學習演算法的函數。因此，神經科學可能掌握著技術 AI 安全的重要關鍵，而這些關鍵目前尚未被充分探索和利用。在這個路線圖中，我們重點介紹並批判性地評估了受神經科學啟發的幾條通往 AI 安全的途徑：模擬大腦的表徵、資訊處理和架構；從模仿大腦資料和身體構建強大的感官和運動系統；微調大腦資料上的 AI 系統；使用神經科學方法推進可解釋性；以及擴大受認知啟發的架構。我們提出了具體建議，說明神經科學如何對 AI 安全產生積極影響。

##### **LLM-ABBA: Understand time series via symbolic approximation**
2411.18506v1 by Erin Carson, Xinye Chen, Cheng Kang

The success of large language models (LLMs) for time series has been
demonstrated in previous work. Utilizing a symbolic time series representation,
one can efficiently bridge the gap between LLMs and time series. However, the
remaining challenge is to exploit the semantic information hidden in time
series by using symbols or existing tokens of LLMs, while aligning the
embedding space of LLMs according to the hidden information of time series. The
symbolic time series approximation (STSA) method called adaptive Brownian
bridge-based symbolic aggregation (ABBA) shows outstanding efficacy in
preserving salient time series features by modeling time series patterns in
terms of amplitude and period while using existing tokens of LLMs.
  In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA
into large language models for various downstream time series tasks. By
symbolizing time series, LLM-ABBA compares favorably to the recent
state-of-the-art (SOTA) in UCR and three medical time series classification
tasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to
\kc{avoid obvious drifting} during prediction tasks by significantly mitigating
the effects of cumulative error arising from misused symbols during the
transition from symbols to numerical values. In time series regression tasks,
LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER)
benchmarks. LLM-ABBA also shows competitive prediction capability compared to
recent SOTA time series prediction results. We believe this framework can also
seamlessly extend to other time series tasks.

摘要：大型語言模型 (LLM) 在時間序列中的成功已在先前的研究中得到證明。利用符號時間序列表示，可以有效地縮小 LLM 和時間序列之間的差距。然而，剩下的挑戰是利用符號或 LLM 的現有標記來利用隱藏在時間序列中的語義資訊，同時根據時間序列的隱藏資訊對齊 LLM 的嵌入空間。稱為自適應布朗橋基於符號聚合 (ABBA) 的符號時間序列近似 (STSA) 方法在通過使用 LLM 的現有標記對時間序列模式建模（就振幅和週期而言）方面展現出傑出的功效。
在本文中，我們介紹一種稱為 LLM-ABBA 的方法，它將 ABBA 整合到大型語言模型中，用於各種下游時間序列任務。通過對時間序列進行符號化，LLM-ABBA 與最近的 UCR 和三個醫學時間序列分類任務中的最先進 (SOTA) 技術相比具有明顯優勢。同時，在 ABBA 中引入了一個固定多邊形鏈技巧，通過顯著減輕從符號過渡到數值時因誤用符號而產生的累積誤差的影響，來避免在預測任務期間出現明顯的漂移。在時間序列回歸任務中，LLM-ABBA 在時間序列外在回歸 (TSER) 基準上實現了新的 SOTA。與最近的 SOTA 時間序列預測結果相比，LLM-ABBA 也顯示出具有競爭力的預測能力。我們相信這個框架也可以無縫地擴展到其他時間序列任務。

##### **SoK: Watermarking for AI-Generated Content**
2411.18479v1 by Xuandong Zhao, Sam Gunn, Miranda Christ, Jaiden Fairoze, Andres Fabrega, Nicholas Carlini, Sanjam Garg, Sanghyun Hong, Milad Nasr, Florian Tramer, Somesh Jha, Lei Li, Yu-Xiang Wang, Dawn Song

As the outputs of generative AI (GenAI) techniques improve in quality, it
becomes increasingly challenging to distinguish them from human-created
content. Watermarking schemes are a promising approach to address the problem
of distinguishing between AI and human-generated content. These schemes embed
hidden signals within AI-generated content to enable reliable detection. While
watermarking is not a silver bullet for addressing all risks associated with
GenAI, it can play a crucial role in enhancing AI safety and trustworthiness by
combating misinformation and deception. This paper presents a comprehensive
overview of watermarking techniques for GenAI, beginning with the need for
watermarking from historical and regulatory perspectives. We formalize the
definitions and desired properties of watermarking schemes and examine the key
objectives and threat models for existing approaches. Practical evaluation
strategies are also explored, providing insights into the development of robust
watermarking techniques capable of resisting various attacks. Additionally, we
review recent representative works, highlight open challenges, and discuss
potential directions for this emerging field. By offering a thorough
understanding of watermarking in GenAI, this work aims to guide researchers in
advancing watermarking methods and applications, and support policymakers in
addressing the broader implications of GenAI.

摘要：隨著生成式 AI (GenAI) 技術的輸出品質提升，要將其與人類創作的內容區分開來變得越來越困難。浮水印技術是一種很有前景的方法，可以解決區分 AI 和人類生成內容的問題。這些技術在 AI 生成的內容中嵌入隱藏訊號，以進行可靠的偵測。雖然浮水印並非解決與 GenAI 相關所有風險的萬靈丹，但它可以在提升 AI 的安全性與可信度方面發揮關鍵作用，方法是打擊錯誤資訊和欺騙行為。本文全面概述了 GenAI 的浮水印技術，從歷史和法規觀點探討浮水印的需求開始。我們正式定義浮水印技術的定義和所需屬性，並檢視現有方法的主要目標和威脅模型。我們也探討了實際的評估策略，提供見解以發展強健的浮水印技術，以抵禦各種攻擊。此外，我們回顧了最近的代表性作品，重點說明開放式挑戰，並討論這個新興領域的潛在發展方向。透過提供對 GenAI 中浮水印的透徹理解，這份研究旨在引導研究人員推進浮水印方法和應用，並協助政策制定者處理 GenAI 的更廣泛影響。

##### **Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS**
2411.18478v1 by Jinyang Wu, Mingkuan Feng, Shuai Zhang, Feihu Che, Zengqi Wen, Jianhua Tao

In-context Learning (ICL) enables large language models (LLMs) to tackle
downstream tasks through sophisticated prompting and high-quality
demonstrations. However, this traditional ICL paradigm shows limitations when
facing complex mathematical reasoning tasks, primarily due to its heavy
dependence on example quality and the necessity for human intervention in
challenging scenarios. To address these limitations, this paper presents
HiAR-ICL, a \textbf{Hi}gh-level \textbf{A}utomated \textbf{R}easoning paradigm
in \textbf{ICL} that shifts focus from specific examples to abstract thinking
patterns, extending the conventional concept of context in ICL. HiAR-ICL
introduces five atomic reasoning actions as fundamental components for
constructing chain-structured patterns. Using Monte Carlo Tree Search, we
explore reasoning paths and construct thought cards to guide subsequent
inference. We then develop a cognitive complexity framework that dynamically
matches problems with appropriate thought cards. Experimental results
demonstrate HiAR-ICL's effectiveness, achieving state-of-the-art accuracy
(79.6$\%$) on the MATH benchmark with Qwen2.5-7B-Instruct, surpassing GPT-4o
(76.6$\%$) and Claude 3.5 (71.1$\%$).

摘要：情境學習 (ICL) 讓大型語言模型 (LLM) 能透過精密的提示和高品質的示範來處理下游任務。然而，這種傳統的 ICL 典範在面對複雜的數學推理任務時會顯現出限制，這主要是因為它過度依賴範例品質，以及在具挑戰性的情境中需要人類介入。為了解決這些限制，這篇論文提出了 HiAR-ICL，一個在 ICL 中的**高**階**自**動**推**理**典範，將焦點從特定範例轉移到抽象思考模式，擴展了 ICL 中情境的傳統概念。HiAR-ICL 引入了五個原子推理動作作為建構鏈狀結構模式的基本組成部分。我們使用蒙地卡羅樹狀搜尋來探索推理路徑，並建構思維卡來引導後續的推論。接著我們開發了一個認知複雜度架構，用以動態地將問題與適當的思維卡配對。實驗結果證明了 HiAR-ICL 的有效性，在使用 Qwen2.5-7B-Instruct 的 MATH 基準測試中達到了最先進的準確度 (79.6%)，超越了 GPT-4o (76.6%) 和 Claude 3.5 (71.1%)。

##### **Weakly Supervised Framework Considering Multi-temporal Information for Large-scale Cropland Mapping with Satellite Imagery**
2411.18475v1 by Yuze Wang, Aoran Hu, Ji Qi, Yang Liu, Chao Tao

Accurately mapping large-scale cropland is crucial for agricultural
production management and planning. Currently, the combination of remote
sensing data and deep learning techniques has shown outstanding performance in
cropland mapping. However, those approaches require massive precise labels,
which are labor-intensive. To reduce the label cost, this study presented a
weakly supervised framework considering multi-temporal information for
large-scale cropland mapping. Specifically, we extract high-quality labels
according to their consistency among global land cover (GLC) products to
construct the supervised learning signal. On the one hand, to alleviate the
overfitting problem caused by the model's over-trust of remaining errors in
high-quality labels, we encode the similarity/aggregation of cropland in the
visual/spatial domain to construct the unsupervised learning signal, and take
it as the regularization term to constrain the supervised part. On the other
hand, to sufficiently leverage the plentiful information in the samples without
high-quality labels, we also incorporate the unsupervised learning signal in
these samples, enriching the diversity of the feature space. After that, to
capture the phenological features of croplands, we introduce dense satellite
image time series (SITS) to extend the proposed framework in the temporal
dimension. We also visualized the high dimensional phenological features to
uncover how multi-temporal information benefits cropland extraction, and
assessed the method's robustness under conditions of data scarcity. The
proposed framework has been experimentally validated for strong adaptability
across three study areas (Hunan Province, Southeast France, and Kansas) in
large-scale cropland mapping, and the internal mechanism and temporal
generalizability are also investigated.

摘要：<paragraph>準確繪製大規模農田對於農業生產管理與規劃至關重要。目前，遙感資料與深度學習技術的結合在農田繪製方面展現出色的效能。然而，這些方法需要大量精確的標籤，而這非常耗費人力。為了降低標籤成本，本研究提出一個弱監督架構，考量多時相資訊以進行大規模農田繪製。具體來說，我們根據全球土地覆蓋 (GLC) 產品之間的一致性，萃取出高品質標籤以建構監督式學習訊號。一方面，為了減輕模型過度信賴高品質標籤中殘留錯誤所造成的過度擬合問題，我們對視覺/空間領域中農田的相似性/聚集性進行編碼，以建構非監督式學習訊號，並將其作為正規化項目來約束監督式部分。另一方面，為了充分利用沒有高品質標籤的樣本中的豐富資訊，我們也在這些樣本中納入非監督式學習訊號，豐富特徵空間的多樣性。在那之後，為了擷取農田的物候特徵，我們引入密集衛星影像時間序列 (SITS) 以在時相維度中延伸所提出的架構。我們也視覺化高維度的物候特徵，以揭示多時相資訊如何使農田萃取受益，並評估該方法在資料稀少情況下的穩健性。所提出的架構已在三個研究區域（湖南省、法國東南部和堪薩斯州）的大規模農田繪製中經過實驗驗證，證明其具有強大的適應性，而其內部機制和時相概括性也經過調查。</paragraph>

##### **Isolating authorship from content with semantic embeddings and contrastive learning**
2411.18472v1 by Javier Huertas-Tato, Adrián Girón-Jiménez, Alejandro Martín, David Camacho

Authorship has entangled style and content inside. Authors frequently write
about the same topics in the same style, so when different authors write about
the exact same topic the easiest way out to distinguish them is by
understanding the nuances of their style. Modern neural models for authorship
can pick up these features using contrastive learning, however, some amount of
content leakage is always present. Our aim is to reduce the inevitable impact
and correlation between content and authorship. We present a technique to use
contrastive learning (InfoNCE) with additional hard negatives synthetically
created using a semantic similarity model. This disentanglement technique aims
to distance the content embedding space from the style embedding space, leading
to embeddings more informed by style. We demonstrate the performance with
ablations on two different datasets and compare them on out-of-domain
challenges. Improvements are clearly shown on challenging evaluations on
prolific authors with up to a 10% increase in accuracy when the settings are
particularly hard. Trials on challenges also demonstrate the preservation of
zero-shot capabilities of this method as fine tuning.

摘要：作者身份將風格和內容糾纏在一起。作者經常以相同的風格撰寫相同的主題，因此當不同的作者撰寫完全相同的主題時，區分他們的最簡單方法是了解其風格的細微差別。用於作者身份的現代神經模型可以使用對比學習來擷取這些特徵，但是，總是存在一定程度的內容洩漏。我們的目標是減少內容和作者身份之間不可避免的影響和關聯性。我們提出了一種技術，利用對比學習 (InfoNCE) 與使用語義相似性模型合成的其他硬負面。這種解耦技術旨在將內容嵌入空間與風格嵌入空間分開，從而產生更多由風格告知的嵌入。我們在兩個不同的資料集上使用消融證明了效能，並在域外挑戰中對它們進行比較。在多產作者的挑戰性評估中清楚地顯示了改進，當設定特別困難時，準確度最高可提高 10%。挑戰中的試驗也證明了此方法在微調中保留了零次學習能力。

##### **Draft Model Knows When to Stop: A Self-Verification Length Policy for Speculative Decoding**
2411.18462v1 by Ziyin Zhang, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Rui Wang, Zhaopeng Tu

Speculative Decoding (SD) has become an important technique in accelerating
the inference speed of large language models. Conventional SD methods employ a
fixed draft length, which ignores the token generation difficulty across tasks.
Consequently, in this paper, we address such an issue and introduce SVIP - a
difficulty-aware dynamic draft length policy for speculative decoding systems.
Based on a theoretical lower bound of draft token acceptance rate and its
inference-time approximation, SVIP adaptively determines the lengths of draft
sequences based on the entropy of each draft token distribution. Experimental
results on mainstream SD benchmarks and frameworks demonstrate the superior
performance of SVIP, achieving up to 20\% walltime speedup on SpecBench over
baseline SD methods and 60\% speedup on MT-Bench for long-form generation of up
to 8K tokens. Moreover, SVIP is totally training-free and compatible with any
existing SD methods that generate draft tokens autoregressively. Experimental
results also show that SVIP yields consistent walltime improvement on top of
GliDe & CaPE and EAGLE-2.

摘要：推測解碼 (SD) 已成為加速大型語言模型推論速度的一項重要技術。傳統的 SD 方法採用固定的草稿長度，這會忽略跨任務的標記生成難度。因此，在本文中，我們探討了這樣的問題，並引入了 SVIP - 一種針對推測解碼系統的難度感知動態草稿長度策略。基於草稿標記接受率的理論下界及其推論時間近似值，SVIP 會根據每個草稿標記分佈的熵自適應地確定草稿序列的長度。主流 SD 基準和框架上的實驗結果證明了 SVIP 的優異性能，在 SpecBench 上比基線 SD 方法實現了高達 20% 的牆上時間加速，在 MT-Bench 上實現了 60% 的加速，用於長達 8K 標記的長格式生成。此外，SVIP 完全無需訓練，並且與任何生成草稿標記自迴歸的現有 SD 方法相容。實驗結果還表明，SVIP 在 GliDe 和 CaPE 以及 EAGLE-2 之上產生了一致的牆上時間改進。

##### **Synthetic ECG Generation for Data Augmentation and Transfer Learning in Arrhythmia Classification**
2411.18456v1 by José Fernando Núñez, Jamie Arjona, Javier Béjar

Deep learning models need a sufficient amount of data in order to be able to
find the hidden patterns in it. It is the purpose of generative modeling to
learn the data distribution, thus allowing us to sample more data and augment
the original dataset. In the context of physiological data, and more
specifically electrocardiogram (ECG) data, given its sensitive nature and
expensive data collection, we can exploit the benefits of generative models in
order to enlarge existing datasets and improve downstream tasks, in our case,
classification of heart rhythm.
  In this work, we explore the usefulness of synthetic data generated with
different generative models from Deep Learning namely Diffweave, Time-Diffusion
and Time-VQVAE in order to obtain better classification results for two open
source multivariate ECG datasets. Moreover, we also investigate the effects of
transfer learning, by fine-tuning a synthetically pre-trained model and then
progressively adding increasing proportions of real data. We conclude that
although the synthetic samples resemble the real ones, the classification
improvement when simply augmenting the real dataset is barely noticeable on
individual datasets, but when both datasets are merged the results show an
increase across all metrics for the classifiers when using synthetic samples as
augmented data. From the fine-tuning results the Time-VQVAE generative model
has shown to be superior to the others but not powerful enough to achieve
results close to a classifier trained with real data only. In addition, methods
and metrics for measuring closeness between synthetic data and the real one
have been explored as a side effect of the main research questions of this
study.

摘要：深度學習模型需要足夠的資料量才能找出其中的隱藏模式。生成模型的目的是學習資料分佈，因此讓我們能夠抽取更多資料並擴充原始資料集。在生理資料的脈絡中，特別是心電圖 (ECG) 資料，由於其敏感的性質和昂貴的資料收集，我們可以利用生成模型的優點來擴充現有的資料集並改善下游任務，在我們的案例中，是心律分類。
在這項工作中，我們探討了使用深度學習的各種生成模型（即 Diffweave、時間擴散和時間 VQVAE）所生成的合成資料的效用，目的是為兩個開放原始碼多變量 ECG 資料集取得更好的分類結果。此外，我們還研究了遷移學習的效果，方法是微調合成預訓練模型，然後逐步增加真實資料的比例。我們的結論是，儘管合成樣本類似於真實樣本，但僅僅擴充真實資料集時的分類改進在個別資料集上幾乎不顯著，但當兩個資料集合併時，使用合成樣本作為擴充資料時，分類器的所有指標都會顯示出增加。從微調結果來看，時間 VQVAE 生成模型已顯示出優於其他模型，但功能還不足以達到僅使用真實資料訓練的分類器的結果。此外，測量合成資料與真實資料之間接近程度的方法和指標已作為本研究主要研究問題的附帶效應進行探討。

##### **Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation**
2411.18447v1 by Marco Pasini, Javier Nistal, Stefan Lattner, George Fazekas

Autoregressive models are typically applied to sequences of discrete tokens,
but recent research indicates that generating sequences of continuous
embeddings in an autoregressive manner is also feasible. However, such
Continuous Autoregressive Models (CAMs) can suffer from a decline in generation
quality over extended sequences due to error accumulation during inference. We
introduce a novel method to address this issue by injecting random noise into
the input embeddings during training. This procedure makes the model robust
against varying error levels at inference. We further reduce error accumulation
through an inference procedure that introduces low-level noise. Experiments on
musical audio generation show that CAM substantially outperforms existing
autoregressive and non-autoregressive approaches while preserving audio quality
over extended sequences. This work paves the way for generating continuous
embeddings in a purely autoregressive setting, opening new possibilities for
real-time and interactive generative applications.

摘要：自迴歸模型通常應用於離散符號的序列，但最近的研究表明，以自迴歸的方式產生連續嵌入的序列也是可行的。然而，此類連續自迴歸模型 (CAM) 可能會在擴展序列中因推論期間的錯誤累積而導致產生品質下降。我們引入一種新方法來解決這個問題，方法是在訓練期間將隨機雜訊注入輸入嵌入中。此程序使模型在推論時對不同程度的錯誤具有穩健性。我們進一步透過引入低階雜訊的推論程序來減少錯誤累積。音樂音訊產生上的實驗顯示，CAM 大幅優於現有的自迴歸和非自迴歸方法，同時在擴展序列中保留音訊品質。這項工作為在純自迴歸設定中產生連續嵌入鋪路，為即時和互動生成應用開啟新的可能性。

##### **Is my Meeting Summary Good? Estimating Quality with a Multi-LLM Evaluator**
2411.18444v1 by Frederic Kirstein, Terry Ruas, Bela Gipp

The quality of meeting summaries generated by natural language generation
(NLG) systems is hard to measure automatically. Established metrics such as
ROUGE and BERTScore have a relatively low correlation with human judgments and
fail to capture nuanced errors. Recent studies suggest using large language
models (LLMs), which have the benefit of better context understanding and
adaption of error definitions without training on a large number of human
preference judgments. However, current LLM-based evaluators risk masking errors
and can only serve as a weak proxy, leaving human evaluation the gold standard
despite being costly and hard to compare across studies. In this work, we
present MESA, an LLM-based framework employing a three-step assessment of
individual error types, multi-agent discussion for decision refinement, and
feedback-based self-training to refine error definition understanding and
alignment with human judgment. We show that MESA's components enable thorough
error detection, consistent rating, and adaptability to custom error
guidelines. Using GPT-4o as its backbone, MESA achieves mid to high
Point-Biserial correlation with human judgment in error detection and mid
Spearman and Kendall correlation in reflecting error impact on summary quality,
on average 0.25 higher than previous methods. The framework's flexibility in
adapting to custom error guidelines makes it suitable for various tasks with
limited human-labeled data.

摘要：自然語言生成 (NLG) 系統產生的會議摘要品質難以自動衡量。ROUGE 和 BERTScore 等既有指標與人類判斷相關性較低，且無法捕捉細微錯誤。最近的研究建議使用大型語言模型 (LLM)，其優點是能更佳理解脈絡，並在未針對大量人類偏好判斷進行訓練的情況下調整錯誤定義。然而，現有的基於 LLM 的評估器有錯誤掩蔽的風險，且只能作為一種弱代理，儘管成本高且難以跨研究比較，但仍將人類評估視為黃金標準。在這項工作中，我們提出 MESA，一個基於 LLM 的架構，採用三步驟評估個別錯誤類型、多主體討論以改善決策，以及基於回饋的自訓練來改善錯誤定義理解，並與人類判斷保持一致。我們證明 MESA 的組成元件能徹底偵測錯誤、一致評分，並能適應自訂的錯誤準則。MESA 以 GPT-4o 為基礎，在錯誤偵測中達到中到高的點雙列相關係數，在反映錯誤對摘要品質的影響時，達到中等的斯皮爾曼和肯德爾相關係數，平均比先前的方法高 0.25。此架構能適應自訂的錯誤準則，使其適用於各種具有人類標記資料有限的任務。

##### **Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised Metric Learning**
2411.18442v1 by Yasin I. Tepeli, Mathijs de Wolf, Joana P. Goncalves

Selection bias poses a critical challenge for fairness in machine learning,
as models trained on data that is less representative of the population might
exhibit undesirable behavior for underrepresented profiles. Semi-supervised
learning strategies like self-training can mitigate selection bias by
incorporating unlabeled data into model training to gain further insight into
the distribution of the population. However, conventional self-training seeks
to include high-confidence data samples, which may reinforce existing model
bias and compromise effectiveness. We propose Metric-DST, a diversity-guided
self-training strategy that leverages metric learning and its implicit
embedding space to counter confidence-based bias through the inclusion of more
diverse samples. Metric-DST learned more robust models in the presence of
selection bias for generated and real-world datasets with induced bias, as well
as a molecular biology prediction task with intrinsic bias. The Metric-DST
learning strategy offers a flexible and widely applicable solution to mitigate
selection bias and enhance fairness of machine learning models.

摘要：選擇偏差對機器學習的公平性構成了一項嚴峻的挑戰，因為根據較不具人口代表性的資料訓練的模型可能會對代表性不足的個人資料表現出不良行為。半監督式學習策略（例如自訓練）可以透過將未標籤的資料納入模型訓練中來減輕選擇偏差，以進一步了解人口分佈。然而，傳統的自訓練試圖納入高可信度的資料範本，這可能會強化現有的模型偏差並損害其效能。我們提出度量學習引導自訓練策略（Metric-DST），這是一種多樣性引導的自訓練策略，它利用度量學習及其隱含嵌入空間，透過納入更多樣化的範本來對抗基於可信度的偏差。Metric-DST 在存在選擇偏差的情況下學習到更強健的模型，這些模型適用於具有誘發偏差的生成式和真實世界資料集，以及具有內在偏差的分子生物學預測任務。Metric-DST 學習策略提供了一個靈活且廣泛適用的解決方案，以減輕選擇偏差並增強機器學習模型的公平性。

##### **MM-Path: Multi-modal, Multi-granularity Path Representation Learning -- Extended Version**
2411.18428v1 by Ronghui Xu, Hanyin Cheng, Chenjuan Guo, Hongfan Gao, Jilin Hu, Sean Bin Yang, Bin Yang

Developing effective path representations has become increasingly essential
across various fields within intelligent transportation. Although pre-trained
path representation learning models have shown improved performance, they
predominantly focus on the topological structures from single modality data,
i.e., road networks, overlooking the geometric and contextual features
associated with path-related images, e.g., remote sensing images. Similar to
human understanding, integrating information from multiple modalities can
provide a more comprehensive view, enhancing both representation accuracy and
generalization. However, variations in information granularity impede the
semantic alignment of road network-based paths (road paths) and image-based
paths (image paths), while the heterogeneity of multi-modal data poses
substantial challenges for effective fusion and utilization. In this paper, we
propose a novel Multi-modal, Multi-granularity Path Representation Learning
Framework (MM-Path), which can learn a generic path representation by
integrating modalities from both road paths and image paths. To enhance the
alignment of multi-modal data, we develop a multi-granularity alignment
strategy that systematically associates nodes, road sub-paths, and road paths
with their corresponding image patches, ensuring the synchronization of both
detailed local information and broader global contexts. To address the
heterogeneity of multi-modal data effectively, we introduce a graph-based
cross-modal residual fusion component designed to comprehensively fuse
information across different modalities and granularities. Finally, we conduct
extensive experiments on two large-scale real-world datasets under two
downstream tasks, validating the effectiveness of the proposed MM-Path. This is
an extended version of the paper accepted by KDD 2025.

摘要：<paragraph>開發有效的路徑表示已在智慧運輸的各個領域中變得越來越重要。儘管預先訓練的路徑表示學習模型已展現出改善的效能，但它們主要專注於單一模式資料的拓撲結構，例如道路網路，而忽略了與路徑相關影像（例如遙測影像）相關的幾何和脈絡特徵。類似於人類的理解，整合來自多種模式的資訊可以提供更全面的觀點，同時提升表示的準確度和概括性。然而，資訊粒度的差異會阻礙基於道路網路的路徑（道路路徑）和基於影像的路徑（影像路徑）的語義對齊，而多模式資料的異質性對有效的融合和利用構成了重大的挑戰。在本文中，我們提出了一個新穎的多模式、多粒度路徑表示學習架構 (MM-Path)，它可以透過整合來自道路路徑和影像路徑的模式來學習通用路徑表示。為了增強多模式資料的對齊，我們開發了一個多粒度對齊策略，系統性地將節點、道路子路徑和道路路徑與其對應的影像區塊關聯起來，確保詳細的局部資訊和更廣泛的整體脈絡同步。為了有效地解決多模式資料的異質性，我們引入了一個基於圖形的跨模式殘差融合元件，旨在全面融合不同模式和粒度下的資訊。最後，我們在兩個大型真實世界資料集上對兩個下游任務進行了廣泛的實驗，驗證了所提出的 MM-Path 的有效性。這是 KDD 2025 接受的論文的延伸版本。</paragraph>

##### **Politicians vs ChatGPT. A study of presuppositions in French and Italian political communication**
2411.18403v1 by Davide Garassino, Vivana Masia, Nicola Brocca, Alice Delorme Benites

This paper aims to provide a comparison between texts produced by French and
Italian politicians on polarizing issues, such as immigration and the European
Union, and their chatbot counterparts created with ChatGPT 3.5. In this study,
we focus on implicit communication, in particular on presuppositions and their
functions in discourse, which have been considered in the literature as a
potential linguistic feature of manipulation. This study also aims to
contribute to the emerging literature on the pragmatic competences of Large
Language Models.

摘要：這篇論文旨在提供法國和義大利政治人物在移民和歐盟等兩極分化議題上所產生的文本，以及使用 ChatGPT 3.5 所建立的聊天機器人對應版本之間的比較。在本研究中，我們專注於隱含的溝通，特別是預設和它們在話語中的功能，這些功能在文獻中被視為一種潛在的操縱語言特徵。本研究也旨在為大型語言模型的語用能力這項新興文獻做出貢獻。

##### **Optimal In-Network Distribution of Learning Functions for a Secure-by-Design Programmable Data Plane of Next-Generation Networks**
2411.18384v1 by Mattia Giovanni Spina, Edoardo Scalzo, Floriano De Rango, Francesca Guerriero, Antonio Iera

The rise of programmable data plane (PDP) and in-network computing (INC)
paradigms paves the way for the development of network devices (switches,
network interface cards, etc.) capable of performing advanced computing tasks.
This allows to execute algorithms of various nature, including machine learning
ones, within the network itself to support user and network services. In
particular, this paper delves into the issue of implementing in-network
learning models to support distributed intrusion detection systems (IDS). It
proposes a model that optimally distributes the IDS workload, resulting from
the subdivision of a "Strong Learner" (SL) model into lighter distributed "Weak
Learner" (WL) models, among data plane devices; the objective is to ensure
complete network security without excessively burdening their normal
operations. Furthermore, a meta-heuristic approach is proposed to reduce the
long computational time required by the exact solution provided by the
mathematical model, and its performance is evaluated. The analysis conducted
and the results obtained demonstrate the enormous potential of the proposed new
approach to the creation of intelligent data planes that effectively act as a
first line of defense against cyber attacks, with minimal additional workload
on network devices.

摘要：可编程数据平面 (PDP) 和网络内计算 (INC) 范例的兴起为开发能够执行高级计算任务的网络设备（交换机、网络接口卡等）铺平了道路。这允许在网络本身内执行各种性质的算法，包括机器学习算法，以支持用户和网络服务。特别是，本文深入探讨了实现网络内学习模型以支持分布式入侵检测系统 (IDS) 的问题。它提出了一种模型，该模型将“强学习器”(SL) 模型细分为更轻的分布式“弱学习器”(WL) 模型，从而优化分布 IDS 工作负载，并在数据平面设备之间进行分布；目标是确保完整的网络安全，而不会给它们的正常操作带来过重的负担。此外，提出了一种元启发式方法来减少数学模型提供的精确解所需的冗长计算时间，并评估其性能。进行的分析和获得的结果证明了所提出的新方法在创建智能数据平面方面的巨大潜力，这些数据平面有效地充当了网络攻击的第一道防线，并且对网络设备的额外工作负载极小。

##### **Topic Modeling and Sentiment Analysis on Japanese Online Media's Coverage of Nuclear Energy**
2411.18383v1 by Yifan Sun, Hirofumi Tsuruta, Masaya Kumagai, Ken Kurosaki

Thirteen years after the Fukushima Daiichi nuclear power plant accident,
Japan's nuclear energy accounts for only approximately 6% of electricity
production, as most nuclear plants remain shut down. To revitalize the nuclear
industry and achieve sustainable development goals, effective communication
with Japanese citizens, grounded in an accurate understanding of public
sentiment, is of paramount importance. While nationwide surveys have
traditionally been used to gauge public views, the rise of social media in
recent years has provided a promising new avenue for understanding public
sentiment. To explore domestic sentiment on nuclear energy-related issues
expressed online, we analyzed the content and comments of over 3,000 YouTube
videos covering topics related to nuclear energy. Topic modeling was used to
extract the main topics from the videos, and sentiment analysis with large
language models classified user sentiments towards each topic. Additionally,
word co-occurrence network analysis was performed to examine the shift in
online discussions during August and September 2023 regarding the release of
treated water. Overall, our results provide valuable insights into the online
discourse on nuclear energy and contribute to a more comprehensive
understanding of public sentiment in Japan.

摘要：福島第一原子力發電廠事故發生 13 年後，
日本的核能僅佔電力生產量的約 6%，因為大多數核電廠仍處於關閉狀態。為了振興核能產業並實現永續發展目標，有效地與日本民眾溝通，並基於對公眾情緒的準確理解，至關重要。儘管傳統上使用全國性調查來評估公眾觀點，但近年來社群媒體的興起為了解公眾情緒提供了有希望的新途徑。為了探討網路上對核能相關議題的國內情緒，我們分析了 3,000 多部 YouTube 影片的內容和留言，這些影片涵蓋了與核能相關的主題。主題建模用於從影片中萃取主要主題，並使用大型語言模型的情緒分析對使用者對每個主題的情緒進行分類。此外，執行詞彙共現網路分析，以檢視 2023 年 8 月和 9 月期間關於處理過的水的釋放的線上討論的變化。總體而言，我們的結果提供了對核能網路討論的寶貴見解，並有助於更全面地了解日本公眾的情緒。

##### **ChatGPT as speechwriter for the French presidents**
2411.18382v1 by Dominique Labbé, Cyril Labbé, Jacques Savoy

Generative AI proposes several large language models (LLMs) to automatically
generate a message in response to users' requests. Such scientific
breakthroughs promote new writing assistants but with some fears. The main
focus of this study is to analyze the written style of one LLM called ChatGPT
by comparing its generated messages with those of the recent French presidents.
To achieve this, we compare end-of-the-year addresses written by Chirac,
Sarkozy, Hollande, and Macron with those automatically produced by ChatGPT. We
found that ChatGPT tends to overuse nouns, possessive determiners, and numbers.
On the other hand, the generated speeches employ less verbs, pronouns, and
adverbs and include, in mean, too standardized sentences. Considering some
words, one can observe that ChatGPT tends to overuse "to must" (devoir), "to
continue" or the lemma "we" (nous). Moreover, GPT underuses the auxiliary verb
"to be" (^etre), or the modal verbs "to will" (vouloir) or "to have to"
(falloir). In addition, when a short text is provided as example to ChatGPT,
the machine can generate a short message with a style closed to the original
wording. Finally, we reveal that ChatGPT style exposes distinct features
compared to real presidential speeches.

摘要：生成式人工智慧提出數種大型語言模型 (LLM)，以自動產生訊息來回應使用者的要求。這種科學突破促進了新的寫作助理，但也帶來了一些擔憂。本研究的主要重點是分析一個名為 ChatGPT 的 LLM 的書寫風格，方法是將其產生的訊息與最近的法國總統進行比較。為達成此目的，我們比較了希拉克、薩科齊、歐蘭德和馬克宏所寫的年終演說，以及 ChatGPT 自動產生的演說。我們發現 ChatGPT 傾向過度使用名詞、所有格限定詞和數字。另一方面，產生的演說較少使用動詞、代名詞和副詞，而且平均而言包含過於標準化的句子。考慮到某些詞彙，可以觀察到 ChatGPT 傾向過度使用「必須」（devoir）、「繼續」（continuer）或詞根「我們」（nous）。此外，GPT 使用助動詞「是」（^etre）或情態動詞「將」（vouloir）或「必須」（falloir）的頻率較低。此外，當提供一段簡短文字作為 ChatGPT 的範例時，機器可以產生一段訊息，其風格接近原始文字。最後，我們揭示 ChatGPT 的風格與真正的總統演說相比，呈現出不同的特徵。

##### **G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation**
2411.18369v1 by Tianxing Chen, Yao Mu, Zhixuan Liang, Zanxin Chen, Shijia Peng, Qiangyu Chen, Mingkun Xu, Ruizhen Hu, Hongyuan Zhang, Xuelong Li, Ping Luo

Recent advances in imitation learning for 3D robotic manipulation have shown
promising results with diffusion-based policies. However, achieving human-level
dexterity requires seamless integration of geometric precision and semantic
understanding. We present G3Flow, a novel framework that constructs real-time
semantic flow, a dynamic, object-centric 3D semantic representation by
leveraging foundation models. Our approach uniquely combines 3D generative
models for digital twin creation, vision foundation models for semantic feature
extraction, and robust pose tracking for continuous semantic flow updates. This
integration enables complete semantic understanding even under occlusions while
eliminating manual annotation requirements. By incorporating semantic flow into
diffusion policies, we demonstrate significant improvements in both
terminal-constrained manipulation and cross-object generalization. Extensive
experiments across five simulation tasks show that G3Flow consistently
outperforms existing approaches, achieving up to 68.3% and 50.1% average
success rates on terminal-constrained manipulation and cross-object
generalization tasks respectively. Our results demonstrate the effectiveness of
G3Flow in enhancing real-time dynamic semantic feature understanding for
robotic manipulation policies.

摘要：最近在 3D 機器人操作的模仿學習中，基於擴散的政策已展現出有希望的成果。然而，要達到人類等級的靈巧度，需要無縫整合幾何精確度和語義理解。我們提出 G3Flow，一個創新的架構，它建構了即時的語義流，一個動態的、以物件為中心的 3D 語義表示，藉由利用基礎模型。我們的做法獨特地結合了用於數位雙胞胎建立的 3D 生成模型、用於語義特徵萃取的視覺基礎模型，以及用於連續語義流更新的強健姿勢追蹤。這種整合即使在遮擋下也能實現完整的語義理解，同時消除了手動註解的要求。透過將語義流納入擴散政策中，我們展示了在終端受限操作和跨物件概括化中都有顯著的進步。在五項模擬任務中的大量實驗顯示，G3Flow 持續優於現有的方法，在終端受限操作和跨物件概括化任務中分別達到高達 68.3% 和 50.1% 的平均成功率。我們的結果證明了 G3Flow 在增強機器人操作政策的即時動態語義特徵理解方面的有效性。

##### **AMPS: ASR with Multimodal Paraphrase Supervision**
2411.18368v1 by Amruta Parulekar, Abhishek Gupta, Sameep Chattopadhyay, Preethi Jyothi

Spontaneous or conversational multilingual speech presents many challenges
for state-of-the-art automatic speech recognition (ASR) systems. In this work,
we present a new technique AMPS that augments a multilingual multimodal ASR
system with paraphrase-based supervision for improved conversational ASR in
multiple languages, including Hindi, Marathi, Malayalam, Kannada, and Nyanja.
We use paraphrases of the reference transcriptions as additional supervision
while training the multimodal ASR model and selectively invoke this paraphrase
objective for utterances with poor ASR performance. Using AMPS with a
state-of-the-art multimodal model SeamlessM4T, we obtain significant relative
reductions in word error rates (WERs) of up to 5%. We present detailed analyses
of our system using both objective and human evaluation metrics.

摘要：自發或對話的多語言演說對最先進的自動語音辨識 (ASR) 系統提出了許多挑戰。在本文中，我們提出了一種新的技術 AMPS，它使用基於同義詞的監督來擴充多語言多模式 ASR 系統，以改善多種語言的對話式 ASR，包括印地語、馬拉地語、馬拉雅拉姆語、卡納達語和尼揚賈語。我們使用參考轉錄的同義詞作為額外的監督，同時訓練多模式 ASR 模型，並有選擇地呼叫此同義詞目標，以針對 ASR 效能不佳的語句。將 AMPS 與最先進的多模式模型 SeamlessM4T 搭配使用，我們獲得了字元錯誤率 (WER) 的顯著相對減少，最高達 5%。我們使用客觀和人工評估指標對我們的系統進行了詳細分析。

##### **GPT as ghostwriter at the White House**
2411.18365v1 by Jacques Savoy

Recently several large language models (LLMs) have demonstrated their
capability to generate a message in response to a user request. Such scientific
breakthroughs promote new perspectives but also some fears. The main focus of
this study is to analyze the written style of one LLM called ChatGPT 3.5 by
comparing its generated messages with those of the recent US presidents. To
achieve this objective, we compare the State of the Union addresses written by
Reagan to Obama with those automatically produced by ChatGPT. We found that
ChatGPT tends to overuse the lemma "we" as well as nouns and commas. On the
other hand, the generated speeches employ less verbs and include, in mean,
longer sentences. Even when imposing a given style to ChatGPT, the resulting
speech remains distinct from messages written by the target author. Moreover,
ChatGPT opts for a neutral tone with mainly positive emotional expressions and
symbolic terms (e.g., freedom, nation). Finally, we show that the GPT's style
exposes distinct features compared to real presidential addresses.

摘要：最近，几个大型语言模型 (LLM) 已展示出它们根据用户要求生成消息的能力。此类科学突破促进了新的观点，但也引发了一些担忧。本研究的主要重点是通过将 ChatGPT 3.5 生成的消息与最近美国总统的消息进行比较，来分析一个 LLM 的书面风格。为了实现这一目标，我们将里根到奥巴马撰写的国情咨文与 ChatGPT 自动生成的国情咨文进行比较。我们发现 ChatGPT 倾向于过度使用词干“我们”以及名词和逗号。另一方面，生成的演讲使用较少的动词，并且平均包含更长的句子。即使对 ChatGPT 强加给定的风格，生成的演讲仍然不同于目标作者撰写的信息。此外，ChatGPT 选择使用中性语气，主要包含积极的情绪表达和象征性术语（例如，自由、国家）。最后，我们展示了 GPT 的风格与真实的总统演讲相比表现出不同的特征。

##### **TryOffDiff: Virtual-Try-Off via High-Fidelity Garment Reconstruction using Diffusion Models**
2411.18350v1 by Riza Velioglu, Petra Bevandic, Robin Chan, Barbara Hammer

This paper introduces Virtual Try-Off (VTOFF), a novel task focused on
generating standardized garment images from single photos of clothed
individuals. Unlike traditional Virtual Try-On (VTON), which digitally dresses
models, VTOFF aims to extract a canonical garment image, posing unique
challenges in capturing garment shape, texture, and intricate patterns. This
well-defined target makes VTOFF particularly effective for evaluating
reconstruction fidelity in generative models. We present TryOffDiff, a model
that adapts Stable Diffusion with SigLIP-based visual conditioning to ensure
high fidelity and detail retention. Experiments on a modified VITON-HD dataset
show that our approach outperforms baseline methods based on pose transfer and
virtual try-on with fewer pre- and post-processing steps. Our analysis reveals
that traditional image generation metrics inadequately assess reconstruction
quality, prompting us to rely on DISTS for more accurate evaluation. Our
results highlight the potential of VTOFF to enhance product imagery in
e-commerce applications, advance generative model evaluation, and inspire
future work on high-fidelity reconstruction. Demo, code, and models are
available at: https://rizavelioglu.github.io/tryoffdiff/

摘要：這篇論文介紹了虛擬試穿 (VTOFF)，這是一項新穎的任務，專注於從穿著衣服的個人的單張照片中產生標準化的服裝影像。與傳統的虛擬試穿 (VTON) 不同，後者以數位方式為模特兒穿衣服，VTOFF 旨在提取標準的服裝影像，在捕捉服裝形狀、紋理和複雜圖案方面面臨獨特的挑戰。這個定義明確的目標讓 VTOFF 特別有效於評估生成模型中的重建保真度。我們提出了 TryOffDiff，一個使用基於 SigLIP 的視覺條件調整 Stable Diffusion 的模型，以確保高保真度和細節保留。在修改過的 VITON-HD 資料集上進行的實驗表明，我們的做法優於基於姿勢轉移和虛擬試穿的基準方法，並且預處理和後處理步驟更少。我們的分析顯示，傳統的影像生成指標無法充分評估重建品質，促使我們依賴 DISTS 進行更準確的評估。我們的結果突顯了 VTOFF 在提升電子商務應用程式中產品影像的潛力，推進生成模型評估，並激勵未來在高保真度重建方面的工作。示範、程式碼和模型可在 https://rizavelioglu.github.io/tryoffdiff/ 取得。

##### **FreqX: What neural networks learn is what network designers say**
2411.18343v1 by Zechen Liu

Personalized Federal learning(PFL) allows clients to cooperatively train a
personalized model without disclosing their private dataset. However, PFL
suffers from Non-IID, heterogeneous devices, lack of fairness, and unclear
contribution which urgently need the interpretability of deep learning model to
overcome these challenges. These challenges proposed new demands for
interpretability. Low cost, privacy, and detailed information. There is no
current interpretability method satisfying them. In this paper, we propose a
novel interpretability method \emph{FreqX} by introducing Signal Processing and
Information Theory. Our experiments show that the explanation results of FreqX
contain both attribution information and concept information. FreqX runs at
least 10 times faster than the baselines which contain concept information.

摘要：個人化聯邦學習 (PFL) 允許客戶合作訓練個人化模型，而無需公開其私人資料集。然而，PFL 存在非 IID、異質裝置、缺乏公平性，以及不明確的貢獻等問題，迫切需要深度學習模型的可解釋性來克服這些挑戰。這些挑戰提出了對可解釋性的新需求。低成本、隱私和詳細資訊。目前沒有任何可解釋性方法能滿足這些需求。在本文中，我們提出了一種新穎的可解釋性方法 \emph{FreqX}，方法是引入訊號處理和資訊理論。我們的實驗表明，FreqX 的解釋結果包含歸因資訊和概念資訊。FreqX 的執行速度至少比包含概念資訊的基線快 10 倍。

##### **Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation**
2411.18337v1 by T. G. D. K. Sumanathilaka, Nicholas Micallef, Julian Hough

Ambiguous words are often found in modern digital communications. Lexical
ambiguity challenges traditional Word Sense Disambiguation (WSD) methods, due
to limited data. Consequently, the efficiency of translation, information
retrieval, and question-answering systems is hindered by these limitations.
This study investigates the use of Large Language Models (LLMs) to improve WSD
using a novel approach combining a systematic prompt augmentation mechanism
with a knowledge base (KB) consisting of different sense interpretations. The
proposed method incorporates a human-in-loop approach for prompt augmentation
where prompt is supported by Part-of-Speech (POS) tagging, synonyms of
ambiguous words, aspect-based sense filtering and few-shot prompting to guide
the LLM. By utilizing a few-shot Chain of Thought (COT) prompting-based
approach, this work demonstrates a substantial improvement in performance. The
evaluation was conducted using FEWS test data and sense tags. This research
advances accurate word interpretation in social media and digital
communication.

摘要：現代數位通訊中常出現歧義詞。由於資料有限，詞彙歧義對傳統的詞彙意義消歧義 (WSD) 方法構成挑戰。因此，這些限制會妨礙翻譯、資訊檢索和問答系統的效率。本研究探討使用大型語言模型 (LLM) 來改善 WSD，方法是結合系統提示擴充機制和包含不同意義詮釋的知識庫 (KB)。所提出的方法納入人機互動提示擴充，其中提示由詞性標記 (POS)、歧義詞的同義詞、基於面向的意義過濾和少次提示支援，以引導 LLM。透過利用少次基於思考鏈 (COT) 提示的方法，本研究證明效能有顯著改善。評估使用 FEWS 測試資料和意義標籤進行。本研究推進了社群媒體和數位通訊中的準確詞彙詮釋。

##### **Helvipad: A Real-World Dataset for Omnidirectional Stereo Depth Estimation**
2411.18335v1 by Mehdi Zayene, Jannik Endres, Albias Havolli, Charles Corbière, Salim Cherkaoui, Alexandre Kontouli, Alexandre Alahi

Despite considerable progress in stereo depth estimation, omnidirectional
imaging remains underexplored, mainly due to the lack of appropriate data. We
introduce Helvipad, a real-world dataset for omnidirectional stereo depth
estimation, consisting of 40K frames from video sequences across diverse
environments, including crowded indoor and outdoor scenes with diverse lighting
conditions. Collected using two 360{\deg} cameras in a top-bottom setup and a
LiDAR sensor, the dataset includes accurate depth and disparity labels by
projecting 3D point clouds onto equirectangular images. Additionally, we
provide an augmented training set with a significantly increased label density
by using depth completion. We benchmark leading stereo depth estimation models
for both standard and omnidirectional images. The results show that while
recent stereo methods perform decently, a significant challenge persists in
accurately estimating depth in omnidirectional imaging. To address this, we
introduce necessary adaptations to stereo models, achieving improved
performance.

摘要：儘管在立體深度估計方面取得了顯著的進展，但全向影像仍然未被充分探索，這主要是由於缺乏適當的資料。我們引進了 Helvipad，這是一個用於全向立體深度估計的真實世界資料集，包含來自各種環境的影片序列中的 40K 幀，包括擁擠的室內和室外場景，以及不同的照明條件。使用兩個 360 度相機在頂部和底部設置以及一個 LiDAR 感測器收集，該資料集透過將 3D 點雲投影到等距矩形影像上，包含準確的深度和視差標籤。此外，我們透過使用深度完成來提供一個擴充的訓練集，大幅增加標籤密度。我們對標準和全向影像進行了領先的立體深度估計模型基準測試。結果顯示，雖然最近的立體方法表現得很好，但在全向影像中準確估計深度仍然是一個重大的挑戰。為了解決這個問題，我們引進了對立體模型必要的調整，以達到更好的效能。

##### **RITA: Automatic Framework for Designing of Resilient IoT Applications**
2411.18324v1 by Luis Eduardo Pessoa, Cristovao Freitas Iglesias Jr, Claudio Miceli

Designing resilient Internet of Things (IoT) systems requires i)
identification of IoT Critical Objects (ICOs) such as services, devices, and
resources, ii) threat analysis, and iii) mitigation strategy selection.
However, the traditional process for designing resilient IoT systems is still
manual, leading to inefficiencies and increased risks. In addition, while tools
such as ChatGPT could support this manual and highly error-prone process, their
use raises concerns over data privacy, inconsistent outputs, and internet
dependence. Therefore, we propose RITA, an automated, open-source framework
that uses a fine-tuned RoBERTa-based Named Entity Recognition (NER) model to
identify ICOs from IoT requirement documents, correlate threats, and recommend
countermeasures. RITA operates entirely offline and can be deployed on-site,
safeguarding sensitive information and delivering consistent outputs that
enhance standardization. In our empirical evaluation, RITA outperformed ChatGPT
in four of seven ICO categories, particularly in actuator, sensor, network
resource, and service identification, using both human-annotated and
ChatGPT-generated test data. These findings indicate that RITA can improve
resilient IoT design by effectively supporting key security operations,
offering a practical solution for developing robust IoT architectures.

摘要：設計有復原力的物聯網 (IoT) 系統需要 i)
識別 IoT 關鍵物件 (ICO)，例如服務、裝置和
資源，ii) 威脅分析，以及 iii) 緩解策略選擇。
然而，設計有復原力 IoT 系統的傳統流程仍然
手動，導致效率低下和風險增加。此外，雖然像 ChatGPT
這樣的工具可以支援這個手動且極易出錯的流程，但其
使用會引發對資料隱私、輸出不一致和網路
依賴性的疑慮。因此，我們提出 RITA，一個自動化的開源架構，
它使用微調後的 RoBERTa 為基礎的名稱實體辨識 (NER) 模型來
從 IoT 需求文件識別 ICO，關聯威脅，並建議
對策。RITA 完全離線運作，且可以部署在現場，
保護敏感資訊並提供一致的輸出，進而增強標準化。在我們的實證評估中，RITA 在七個 ICO 類別中的四個類別中優於 ChatGPT，特別是在致動器、感測器、網路
資源和服務識別方面，並使用人工標註和
ChatGPT 生成的測試資料。這些發現表明 RITA 可以透過有效地支援關鍵安全運作來改善有復原力的 IoT 設計，
提供一個實用的解決方案來開發強健的 IoT 架構。

##### **Continual Learning in Machine Speech Chain Using Gradient Episodic Memory**
2411.18320v1 by Geoffrey Tyndall, Kurniawati Azizah, Dipta Tanaya, Ayu Purwarianti, Dessi Puji Lestari, Sakriani Sakti

Continual learning for automatic speech recognition (ASR) systems poses a
challenge, especially with the need to avoid catastrophic forgetting while
maintaining performance on previously learned tasks. This paper introduces a
novel approach leveraging the machine speech chain framework to enable
continual learning in ASR using gradient episodic memory (GEM). By
incorporating a text-to-speech (TTS) component within the machine speech chain,
we support the replay mechanism essential for GEM, allowing the ASR model to
learn new tasks sequentially without significant performance degradation on
earlier tasks. Our experiments, conducted on the LJ Speech dataset, demonstrate
that our method outperforms traditional fine-tuning and multitask learning
approaches, achieving a substantial error rate reduction while maintaining high
performance across varying noise conditions. We showed the potential of our
semi-supervised machine speech chain approach for effective and efficient
continual learning in speech recognition.

摘要：持續學習自動語音辨識 (ASR) 系統是一個挑戰，特別是在需要避免災難性遺忘的同時，還要在先前學習的任務上維持效能。這篇論文介紹一種創新的方法，利用機器語音鏈架構，以使用梯度情節記憶體 (GEM) 實現 ASR 中的持續學習。透過在機器語音鏈中加入文字轉語音 (TTS) 組件，我們支援 GEM 所需的重播機制，讓 ASR 模型能夠依序學習新任務，而不會對先前任務的效能造成顯著的降低。我們在 LJ Speech 資料集上進行的實驗證明，我們的模型優於傳統的微調和多任務學習方法，在各種噪音條件下都能維持高效能，同時大幅降低錯誤率。我們展示了半監督機器語音鏈方法在語音辨識中進行有效且高效持續學習的潛力。

##### **MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement**
2411.18309v1 by Xiwei Deng, Xianchun He, Yudan Zhou, Shuhui Cai, Congbo Cai, Zhong Chen

CT report generation (CTRG) aims to automatically generate diagnostic reports
for 3D volumes, relieving clinicians' workload and improving patient care.
Despite clinical value, existing works fail to effectively incorporate
diagnostic information from multiple anatomical views and lack related clinical
expertise essential for accurate and reliable diagnosis. To resolve these
limitations, we propose a novel Multi-view perception Knowledge-enhanced
Tansformer (MvKeTR) to mimic the diagnostic workflow of clinicians. Just as
radiologists first examine CT scans from multiple planes, a Multi-View
Perception Aggregator (MVPA) with view-aware attention effectively synthesizes
diagnostic information from multiple anatomical views. Then, inspired by how
radiologists further refer to relevant clinical records to guide diagnostic
decision-making, a Cross-Modal Knowledge Enhancer (CMKE) retrieves the most
similar reports based on the query volume to incorporate domain knowledge into
the diagnosis procedure. Furthermore, instead of traditional MLPs, we employ
Kolmogorov-Arnold Networks (KANs) with learnable nonlinear activation functions
as the fundamental building blocks of both modules to better capture intricate
diagnostic patterns in CT interpretation. Extensive experiments on the public
CTRG-Chest-548K dataset demonstrate that our method outpaces prior
state-of-the-art models across all metrics.

摘要：電腦斷層報告生成（CTRG）旨在自動生成 3D 體積的診斷報告，減輕臨床醫師的工作量並改善患者照護。
儘管具有臨床價值，現有研究無法有效整合來自多個解剖視圖的診斷資訊，並且缺乏準確且可靠診斷所必需的相關臨床專業知識。為了解決這些限制，我們提出了一種新穎的多視覺感知知識增強轉換器 (MvKeTR) 來模擬臨床醫師的診斷工作流程。正如放射科醫師首先從多個平面檢查電腦斷層掃描，具有視圖感知注意力的多視覺感知聚合器 (MVPA) 有效地綜合了來自多個解剖視圖的診斷資訊。接著，受到放射科醫師如何進一步參考相關臨床記錄來指導診斷決策的啟發，跨模態知識增強器 (CMKE) 基於查詢體積擷取最相似的報告，以將領域知識納入診斷程序。此外，我們採用具有可學習非線性啟用函數的 Kolmogorov-Arnold 網路 (KAN) 作為兩個模組的基本建構模組，而不是傳統的多層感知器，以在電腦斷層詮釋中更好地擷取複雜的診斷模式。在公共 CTRG-Chest-548K 資料集上的廣泛實驗證明，我們的模型在所有指標上都超越了先前的最先進模型。

##### **Application of Soft Actor-Critic Algorithms in Optimizing Wastewater Treatment with Time Delays Integration**
2411.18305v1 by Esmaeel Mohammadi, Daniel Ortiz-Arroyo, Aviaja Anna Hansen, Mikkel Stokholm-Bjerregaard, Sebastien Gros, Akhil S Anand, Petar Durdevic

Wastewater treatment plants face unique challenges for process control due to
their complex dynamics, slow time constants, and stochastic delays in
observations and actions. These characteristics make conventional control
methods, such as Proportional-Integral-Derivative controllers, suboptimal for
achieving efficient phosphorus removal, a critical component of wastewater
treatment to ensure environmental sustainability. This study addresses these
challenges using a novel deep reinforcement learning approach based on the Soft
Actor-Critic algorithm, integrated with a custom simulator designed to model
the delayed feedback inherent in wastewater treatment plants. The simulator
incorporates Long Short-Term Memory networks for accurate multi-step state
predictions, enabling realistic training scenarios. To account for the
stochastic nature of delays, agents were trained under three delay scenarios:
no delay, constant delay, and random delay. The results demonstrate that
incorporating random delays into the reinforcement learning framework
significantly improves phosphorus removal efficiency while reducing operational
costs. Specifically, the delay-aware agent achieved 36% reduction in phosphorus
emissions, 55% higher reward, 77% lower target deviation from the regulatory
limit, and 9% lower total costs than traditional control methods in the
simulated environment. These findings underscore the potential of reinforcement
learning to overcome the limitations of conventional control strategies in
wastewater treatment, providing an adaptive and cost-effective solution for
phosphorus removal.

摘要：廢水處理廠由於其複雜的動態、緩慢的時間常數以及觀測和動作的隨機延遲，因此在製程控制方面面臨獨特的挑戰。這些特性使得傳統的控制方法（例如比例積分微分控制器）無法達到最佳化，無法達成有效的磷去除，而磷去除是廢水處理中確保環境永續性的關鍵組成部分。本研究使用一種新穎的深度強化學習方法來應對這些挑戰，該方法基於 Soft Actor-Critic 演算法，並整合一個自訂模擬器來模擬廢水處理廠固有的延遲回饋。該模擬器結合了長短期記憶網路，可進行準確的多步驟狀態預測，從而實現逼真的訓練場景。為了考量延遲的隨機性質，我們在三種延遲場景下訓練了代理：無延遲、恆定延遲和隨機延遲。結果表明，將隨機延遲納入強化學習架構可顯著提高磷去除效率，同時降低營運成本。具體而言，在模擬環境中，具備延遲感知能力的代理將磷排放量減少了 36%，獎勵提高了 55%，目標偏差比法規限制降低了 77%，總成本比傳統控制方法降低了 9%。這些發現強調了強化學習在克服廢水處理中傳統控制策略的限制方面的潛力，為磷去除提供了一種適應性強且具有成本效益的解決方案。

##### **Aligning Pre-trained Models for Spoken Language Translation**
2411.18294v1 by Šimon Sedláček, Santosh Kesiraju, Alexander Polok, Jan Černocký

This paper investigates a novel approach to end-to-end speech translation
(ST) based on aligning frozen pre-trained automatic speech recognition (ASR)
and machine translation (MT) models via a small connector module (Q-Former, our
Subsampler-Transformer Encoder). This connector bridges the gap between the
speech and text modalities, transforming ASR encoder embeddings into the latent
representation space of the MT encoder while being the only part of the system
optimized during training. Experiments are conducted on the How2
English-Portuguese dataset as we investigate the alignment approach in a
small-scale scenario focusing on ST. While keeping the size of the connector
module constant and small in comparison ( < 5% of the size of the larger
aligned models), increasing the size and capability of the foundation ASR and
MT models universally improves translation results. We also find that the
connectors can serve as domain adapters for the foundation MT models,
significantly improving translation performance in the aligned ST setting. We
conclude that this approach represents a viable and scalable approach to
training end-to-end ST systems.

摘要：本文探討了一種端對端語音翻譯 (ST) 的新方法，此方法是透過一個小型連接模組 (Q-Former，我們的子採樣器轉換器編碼器) 來對齊凍結的預訓練自動語音辨識 (ASR) 和機器翻譯 (MT) 模型。此連接器彌補了語音和文字模態之間的差距，將 ASR 編碼器嵌入轉換成 MT 編碼器的潛在表示空間，同時成為訓練期間系統中唯一最佳化的部分。我們在 How2 英葡資料集上進行實驗，因為我們在小規模場景中探討對齊方法，專注於 ST。在保持連接器模組大小恆定且較小 (小於較大對齊模型大小的 5%) 的同時，增加基礎 ASR 和 MT 模型的大小和功能普遍改善了翻譯結果。我們還發現連接器可以用作基礎 MT 模型的領域適配器，大幅改善對齊 ST 設定中的翻譯效能。我們得出結論，這種方法代表一種可行且可擴充的方法，用於訓練端對端 ST 系統。

##### **DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model**
2411.18286v1 by Xinyu Su, Feng Liu, Yanchuan Chang, Egemen Tanin, Majid Sarvi, Jianzhong Qi

Traffic forecasting is an important problem in the operation and optimisation
of transportation systems. State-of-the-art solutions train machine learning
models by minimising the mean forecasting errors on the training data. The
trained models often favour periodic events instead of aperiodic ones in their
prediction results, as periodic events often prevail in the training data.
While offering critical optimisation opportunities, aperiodic events such as
traffic incidents may be missed by the existing models. To address this issue,
we propose DualCast -- a model framework to enhance the learning capability of
traffic forecasting models, especially for aperiodic events. DualCast takes a
dual-branch architecture, to disentangle traffic signals into two types, one
reflecting intrinsic {spatial-temporal} patterns and the other reflecting
external environment contexts including aperiodic events. We further propose a
cross-time attention mechanism, to capture high-order spatial-temporal
relationships from both periodic and aperiodic patterns. DualCast is versatile.
We integrate it with recent traffic forecasting models, consistently reducing
their forecasting errors by up to 9.6% on multiple real datasets.

摘要：交通預測是運輸系統營運和最佳化中的重要問題。最先進的解決方案透過最小化訓練資料上的平均預測誤差來訓練機器學習模型。訓練出來的模型通常在其預測結果中偏愛週期性事件，而不是非週期性事件，因為週期性事件通常在訓練資料中佔優勢。雖然提供了重要的最佳化機會，但現有模型可能會錯過非週期性事件，例如交通事故。為了解決這個問題，我們提出了 DualCast —— 一個模型架構，用於增強交通預測模型的學習能力，特別是對於非週期性事件。DualCast 採用雙分支架構，將交通信號解開為兩種型態，一種反映內在的 {時空} 模式，另一種反映包括非週期性事件在內的外部環境背景。我們進一步提出了一個跨時間注意力機制，以從週期性和非週期性模式中擷取高階時空關係。DualCast 很靈活。我們將它與最近的交通預測模型整合在一起，持續在多個真實資料集上將其預測誤差降低多達 9.6%。

##### **Neutralizing Backdoors through Information Conflicts for Large Language Models**
2411.18280v1 by Chen Chen, Yuchen Sun, Xueluan Gong, Jiaxin Gao, Kwok-Yan Lam

Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks, from
understanding to reasoning. However, they remain vulnerable to backdoor
attacks, where models behave normally for standard queries but generate harmful
responses or unintended output when specific triggers are activated. Existing
backdoor defenses often suffer from drawbacks that they either focus on
detection without removal, rely on rigid assumptions about trigger properties,
or prove to be ineffective against advanced attacks like multi-trigger
backdoors. In this paper, we present a novel method to eliminate backdoor
behaviors from LLMs through the construction of information conflicts using
both internal and external mechanisms. Internally, we leverage a lightweight
dataset to train a conflict model, which is then merged with the backdoored
model to neutralize malicious behaviors by embedding contradictory information
within the model's parametric memory. Externally, we incorporate convincing
contradictory evidence into the prompt to challenge the model's internal
backdoor knowledge. Experimental results on classification and conversational
tasks across 4 widely used LLMs demonstrate that our method outperforms 8
state-of-the-art backdoor defense baselines. We can reduce the attack success
rate of advanced backdoor attacks by up to 98% while maintaining over 90% clean
data accuracy. Furthermore, our method has proven to be robust against adaptive
backdoor attacks. The code will be open-sourced upon publication.

摘要：大型語言模型 (LLM) 已見著顯著進展，在各種自然語言處理 (NLP) 任務中取得卓越表現，從理解到推理。然而，它們仍然容易受到後門攻擊，在這種攻擊中，模型對標準查詢表現正常，但在特定觸發器被啟動時會產生有害的回應或意外的輸出。現有的後門防禦通常會遇到一些缺點，例如它們只專注於偵測而不移除、依賴觸發器屬性的僵化假設，或證明對抗多觸發後門等進階攻擊無效。在本文中，我們提出了一種新方法，透過使用內部和外部機制建構資訊衝突，從 LLM 中消除後門行為。在內部，我們利用輕量級的資料集來訓練衝突模型，然後將其與後門模型合併，透過在模型的參數記憶體中嵌入矛盾的資訊來中和惡意行為。在外部，我們將令人信服的矛盾證據納入提示中，以挑戰模型的內部後門知識。在 4 個廣泛使用的 LLM 上進行分類和對話任務的實驗結果表明，我們的模型優於 8 個最先進的後門防禦基準。我們可以將進階後門攻擊的攻擊成功率降低多達 98%，同時維持超過 90% 的乾淨資料準確度。此外，我們的模型已被證明對抗適應性後門攻擊具有穩健性。程式碼將在發表後開源。

##### **Large Language Model-Brained GUI Agents: A Survey**
2411.18279v1 by Chaoyun Zhang, Shilin He, Jiaxu Qian, Bowen Li, Liqun Li, Si Qin, Yu Kang, Minghua Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

GUIs have long been central to human-computer interaction, providing an
intuitive and visually-driven way to access and interact with digital systems.
The advent of LLMs, particularly multimodal models, has ushered in a new era of
GUI automation. They have demonstrated exceptional capabilities in natural
language understanding, code generation, and visual processing. This has paved
the way for a new generation of LLM-brained GUI agents capable of interpreting
complex GUI elements and autonomously executing actions based on natural
language instructions. These agents represent a paradigm shift, enabling users
to perform intricate, multi-step tasks through simple conversational commands.
Their applications span across web navigation, mobile app interactions, and
desktop automation, offering a transformative user experience that
revolutionizes how individuals interact with software. This emerging field is
rapidly advancing, with significant progress in both research and industry.
  To provide a structured understanding of this trend, this paper presents a
comprehensive survey of LLM-brained GUI agents, exploring their historical
evolution, core components, and advanced techniques. We address research
questions such as existing GUI agent frameworks, the collection and utilization
of data for training specialized GUI agents, the development of large action
models tailored for GUI tasks, and the evaluation metrics and benchmarks
necessary to assess their effectiveness. Additionally, we examine emerging
applications powered by these agents. Through a detailed analysis, this survey
identifies key research gaps and outlines a roadmap for future advancements in
the field. By consolidating foundational knowledge and state-of-the-art
developments, this work aims to guide both researchers and practitioners in
overcoming challenges and unlocking the full potential of LLM-brained GUI
agents.

摘要：圖形使用者介面長期以來一直是人機互動的核心，提供一種直觀且視覺化的方式來存取和互動數位系統。多模態模型等大型語言模型的出現，開啟了圖形使用者介面自動化的新紀元。它們在自然語言理解、程式碼產生和視覺處理方面展現出非凡的能力。這為新一代的圖形使用者介面代理鋪路，這些代理能夠詮釋複雜的圖形使用者介面元素，並根據自然語言指令自主執行動作。這些代理代表了一種典範轉移，使用戶能夠透過簡單的對話式指令執行複雜的多步驟任務。它們的應用橫跨網路瀏覽、行動應用程式互動和桌面自動化，提供變革性的使用者體驗，徹底改變個人與軟體互動的方式。這個新興領域正在快速進步，無論在研究或產業方面都有顯著的進展。為了提供對這項趨勢的結構化理解，本文提供了圖形使用者介面代理的全面調查，探討其歷史演進、核心元件和進階技術。我們探討的研究問題包括現有的圖形使用者介面代理架構、用於訓練專門圖形使用者介面代理的資料收集和利用、為圖形使用者介面任務量身打造的大型動作模型的開發，以及評估其有效性所需的評量指標和基準。此外，我們探討了由這些代理支援的新興應用程式。透過詳細的分析，這項調查找出關鍵的研究差距，並概述了該領域未來進展的路線圖。透過整合基礎知識和最先進的發展，這項研究旨在引導研究人員和實務工作者克服挑戰，並釋放圖形使用者介面代理的全部潛力。

##### **Hidden Data Privacy Breaches in Federated Learning**
2411.18269v1 by Xueluan Gong, Yuji Wang, Shuaike Li, Mengyuan Sun, Songze Li, Qian Wang, Kwok-Yan Lam, Chen Chen

Federated Learning (FL) emerged as a paradigm for conducting machine learning
across broad and decentralized datasets, promising enhanced privacy by
obviating the need for direct data sharing. However, recent studies show that
attackers can steal private data through model manipulation or gradient
analysis. Existing attacks are constrained by low theft quantity or
low-resolution data, and they are often detected through anomaly monitoring in
gradients or weights. In this paper, we propose a novel data-reconstruction
attack leveraging malicious code injection, supported by two key techniques,
i.e., distinctive and sparse encoding design and block partitioning. Unlike
conventional methods that require detectable changes to the model, our method
stealthily embeds a hidden model using parameter sharing to systematically
extract sensitive data. The Fibonacci-based index design ensures efficient,
structured retrieval of memorized data, while the block partitioning method
enhances our method's capability to handle high-resolution images by dividing
them into smaller, manageable units. Extensive experiments on 4 datasets
confirmed that our method is superior to the five state-of-the-art
data-reconstruction attacks under the five respective detection methods. Our
method can handle large-scale and high-resolution data without being detected
or mitigated by state-of-the-art data reconstruction defense methods. In
contrast to baselines, our method can be directly applied to both FedAVG and
FedSGD scenarios, underscoring the need for developers to devise new defenses
against such vulnerabilities. We will open-source our code upon acceptance.

摘要：<paragraph>聯邦學習 (FL) 成為一種跨廣泛且分散式資料集進行機器學習的範例，承諾透過消除直接資料共用需求來增強隱私。然而，最近的研究顯示攻擊者可以透過模型操作或梯度分析竊取私人資料。現有的攻擊受限於竊取量低或資料解析度低，而且通常會透過梯度或權重中的異常監控來偵測。在本文中，我們提出了一種新穎的資料重建攻擊，利用惡意程式碼注入，並由兩種關鍵技術支援，即獨特且稀疏的編碼設計和區塊分割。與需要對模型進行可偵測變更的傳統方法不同，我們的方法秘密地使用參數共用嵌入一個隱藏模型，以系統化地提取敏感資料。基於費氏數列的索引設計確保有效率且結構化的記憶資料擷取，而區塊分割方法透過將高解析度影像分割為較小且可管理的單元，增強了我們的方法處理高解析度影像的能力。在 4 個資料集上的廣泛實驗證實，我們的模型優於五種現有技術資料重建攻擊，在五種各自的偵測方法下。我們的模型可以在不被現有技術資料重建防禦方法偵測或減輕的情況下處理大規模且高解析度資料。與基準相比，我們的模型可以同時直接應用於 FedAVG 和 FedSGD 場景，強調開發人員需要設計新的防禦措施來對抗此類漏洞。我們將在接受後開放原始碼。</paragraph>

##### **Wearable intelligent throat enables natural speech in stroke patients with dysarthria**
2411.18266v1 by Chenyu Tang, Shuo Gao, Cong Li, Wentian Yi, Yuxuan Jin, Xiaoxue Zhai, Sixuan Lei, Hongbei Meng, Zibo Zhang, Muzi Xu, Shengbo Wang, Xuhang Chen, Chenxi Wang, Hongyun Yang, Ningli Wang, Wenyu Wang, Jin Cao, Xiaodong Feng, Peter Smielewski, Yu Pan, Wenhui Song, Martin Birchall, Luigi G. Occhipint

Wearable silent speech systems hold significant potential for restoring
communication in patients with speech impairments. However, seamless, coherent
speech remains elusive, and clinical efficacy is still unproven. Here, we
present an AI-driven intelligent throat (IT) system that integrates throat
muscle vibrations and carotid pulse signal sensors with large language model
(LLM) processing to enable fluent, emotionally expressive communication. The
system utilizes ultrasensitive textile strain sensors to capture high-quality
signals from the neck area and supports token-level processing for real-time,
continuous speech decoding, enabling seamless, delay-free communication. In
tests with five stroke patients with dysarthria, IT's LLM agents intelligently
corrected token errors and enriched sentence-level emotional and logical
coherence, achieving low error rates (4.2% word error rate, 2.9% sentence error
rate) and a 55% increase in user satisfaction. This work establishes a
portable, intuitive communication platform for patients with dysarthria with
the potential to be applied broadly across different neurological conditions
and in multi-language support systems.

摘要：可穿戴式靜默語音系統在恢復言語障礙患者的溝通能力方面具有顯著的潛力。然而，無縫、連貫的語音仍然難以捉摸，臨床療效仍未得到證實。在此，我們提出了一個以 AI 為驅動的智能喉嚨 (IT) 系統，它將喉嚨肌肉振動和頸動脈脈搏信號感測器與大型語言模型 (LLM) 處理相結合，以實現流暢、富有情感表達的溝通。該系統利用超靈敏的紡織應變感測器從頸部區域捕捉高品質信號，並支援代幣級處理，以進行實時、連續的語音解碼，實現無縫、無延遲的溝通。在對五位患有構音障礙的中風患者進行的測試中，IT 的 LLM 代理智能地更正了代幣錯誤，並豐富了句子級的情感和邏輯連貫性，達到了較低的錯誤率（4.2% 字元錯誤率，2.9% 句子錯誤率）和 55% 的使用者滿意度提升。這項工作為構音障礙患者建立了一個可攜式、直觀的溝通平台，有可能廣泛應用於不同的神經系統疾病和多語言支援系統中。

##### **MetaphorShare: A Dynamic Collaborative Repository of Open Metaphor Datasets**
2411.18260v1 by Joanne Boisson, Arif Mehmood, Jose Camacho-Collados

The metaphor studies community has developed numerous valuable labelled
corpora in various languages over the years. Many of these resources are not
only unknown to the NLP community, but are also often not easily shared among
the researchers. Both in human sciences and in NLP, researchers could benefit
from a centralised database of labelled resources, easily accessible and
unified under an identical format. To facilitate this, we present
MetaphorShare, a website to integrate metaphor datasets making them open and
accessible. With this effort, our aim is to encourage researchers to share and
upload more datasets in any language in order to facilitate metaphor studies
and the development of future metaphor processing NLP systems. The website is
accessible at www.metaphorshare.com.

摘要：隱喻研究社群多年來已開發出許多有價值的標記語料庫，涵蓋各種語言。這些資源中的許多資源不僅不為自然語言處理社群所知，而且通常也不容易在研究人員之間共享。在人文科學和自然語言處理中，研究人員可以受益於一個標記資源的集中資料庫，該資料庫易於存取，並以相同的格式統一。為了促進這一點，我們提出 MetaphorShare，一個整合隱喻資料集的網站，讓它們開放且易於存取。透過這項工作，我們的目標是鼓勵研究人員分享和上傳更多任何語言的資料集，以促進隱喻研究和未來隱喻處理自然語言處理系統的發展。該網站可於 www.metaphorshare.com 存取。

##### **Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning**
2411.18253v1 by Melda Yeghaian, Zuhir Bodalal, Daan van den Broek, John B A G Haanen, Regina G H Beets-Tan, Stefano Trebeschi, Marcel A J van Gerven

Purpose: Analyzing noninvasive longitudinal and multimodal data using
artificial intelligence could potentially transform immunotherapy for cancer
patients, paving the way towards precision medicine. Methods: In this study, we
integrated pre- and on-treatment blood measurements, prescribed medications and
CT-based volumes of organs from a large pan-cancer cohort of 694 patients
treated with immunotherapy to predict short and long-term overall survival. By
leveraging a combination of recent developments, different variants of our
extended multimodal transformer-based simple temporal attention (MMTSimTA)
network were trained end-to-end to predict mortality at three, six, nine and
twelve months. These models were also compared to baseline methods
incorporating intermediate and late fusion based integration methods. Results:
The strongest prognostic performance was demonstrated using the extended
transformer-based multimodal model with area under the curves (AUCs) of $0.84
\pm $0.04, $0.83 \pm $0.02, $0.82 \pm $0.02, $0.81 \pm $0.03 for 3-, 6-, 9-,
and 12-month survival prediction, respectively. Conclusion: Our findings
suggest that analyzing integrated early treatment data has potential for
predicting survival of immunotherapy patients. Integrating complementary
noninvasive modalities into a jointly trained model, using our extended
transformer-based architecture, demonstrated an improved multimodal prognostic
performance, especially in short term survival prediction.

摘要：<paragraph>目的：使用人工智能分析非侵入性纵向多模态数据可能会改变癌症患者的免疫治疗，为精准医疗铺平道路。方法：在这项研究中，我们整合了 694 名接受免疫治疗的癌症患者队列的治疗前和治疗中的血液测量值、处方药和基于 CT 的器官体积，以预测短期和长期总体生存率。通过利用最近发展的组合，我们扩展的多模态基于 Transformer 的简单时间注意力 (MMTSimTA) 网络的不同变体经过端到端训练，以预测三个、六个、九个和十二个月的死亡率。这些模型还与结合了基于中间融合和后期融合的集成方法的基线方法进行了比较。结果：使用扩展的基于 Transformer 的多模态模型展示了最强的预后表现，曲线下面积 (AUC) 分别为 3 个、6 个、9 个和 12 个月的生存预测为 0.84 ± 0.04、0.83 ± 0.02、0.82 ± 0.02、0.81 ± 0.03。结论：我们的研究结果表明，分析整合的早期治疗数据有可能预测免疫治疗患者的生存率。使用我们扩展的基于 Transformer 的架构，将互补的非侵入性方式整合到一个联合训练的模型中，展示了改进的多模态预后表现，尤其是在短期生存预测中。</paragraph>

##### **IKUN: Initialization to Keep snn training and generalization great with sUrrogate-stable variaNce**
2411.18250v1 by Da Chang, Deliang Wang, Xiao Yang

Weight initialization significantly impacts the convergence and performance
of neural networks. While traditional methods like Xavier and Kaiming
initialization are widely used, they often fall short for spiking neural
networks (SNNs), which have distinct requirements compared to artificial neural
networks (ANNs).
  To address this, we introduce \textbf{IKUN}, a variance-stabilizing
initialization method integrated with surrogate gradient functions,
specifically designed for SNNs. \textbf{IKUN} stabilizes signal propagation,
accelerates convergence, and enhances generalization. Experiments show
\textbf{IKUN} improves training efficiency by up to \textbf{50\%}, achieving
\textbf{95\%} training accuracy and \textbf{91\%} generalization accuracy.
  Hessian analysis reveals that \textbf{IKUN}-trained models converge to
flatter minima, characterized by Hessian eigenvalues near zero on the positive
side, promoting better generalization. The method is open-sourced for further
exploration:
\href{https://github.com/MaeChd/SurrogateVarStabe}{https://github.com/MaeChd/SurrogateVarStabe}.

摘要：權重初始化顯著影響神經網路的收斂和效能。儘管 Xavier 和 Kaiming 初始化等傳統方法廣泛使用，但對於與人工神經網路 (ANN) 相比具有不同需求的尖峰神經網路 (SNN) 來說，它們通常無法滿足要求。
為了解決此問題，我們引入了 \textbf{IKUN}，一種與代理梯度函數整合的變異穩定初始化方法，專門為 SNN 設計。\textbf{IKUN} 穩定訊號傳播，加速收斂，並增強泛化。實驗顯示 \textbf{IKUN} 將訓練效率提升多達 \textbf{50\%}，達到 \textbf{95\%} 訓練準確度和 \textbf{91\%} 泛化準確度。
海森分析顯示，\textbf{IKUN} 訓練的模型收斂到較平坦的極小值，特徵是海森特徵值在正側接近零，促成更好的泛化。此方法為進一步探索而開放原始碼：
\href{https://github.com/MaeChd/SurrogateVarStabe}{https://github.com/MaeChd/SurrogateVarStabe}。

##### **A gentle push funziona benissimo: making instructed models in Italian via contrastive activation steering**
2411.18247v1 by Daniel Scalena, Elisabetta Fersini, Malvina Nissim

Adapting models to a language that was only partially present in the
pre-training data requires fine-tuning, which is expensive in terms of both
data and computational resources. As an alternative to fine-tuning, we explore
the potential of activation steering-based techniques to enhance model
performance on Italian tasks. Through our experiments we show that Italian
steering (i) can be successfully applied to different models, (ii) achieves
performances comparable to, or even better than, fine-tuned models for Italian,
and (iii) yields higher quality and consistency in Italian generations. We also
discuss the utility of steering and fine-tuning in the contemporary LLM
landscape where models are anyway getting high Italian performances even if not
explicitly trained in this language.

摘要：要將模型套用到在預訓練資料中僅部分出現的語言，需要進行微調，這在資料和運算資源方面都很昂貴。我們探討基於啟動引導的技術的潛力，作為微調的替代方案，以增強模型在義大利語任務上的效能。透過我們的實驗，我們顯示義大利語引導 (i) 可以成功套用於不同的模型，(ii) 達到與義大利語微調模型相當甚至更好的效能，以及 (iii) 產生更高品質且一致的義大利語。我們也討論在當代 LLM 環境中引導和微調的效用，其中模型即使未針對此語言進行明確訓練，也能獲得很高的義大利語效能。

##### **Thai Financial Domain Adaptation of THaLLE -- Technical Report**
2411.18242v1 by KBTG Labs, Atthakorn Petchsod, Pornchanan Balee, Danupat Khamnuansin, Anuruth Lertpiya, Chanatip Saetia, Tawunrat Chalothorn, Thadpong Pongthawornkamol, Monchai Lertsutthiwong

Large Language Models (LLMs) excel in general tasks but struggle with
domain-specific challenges, such as specialized terminology and localized
regulations. Existing financial LLMs, like FinGPT and BloombergGPT, lack
support for the Thai financial domain. We developed a Thai Financial LLM using
the Investment Consultant (IC) exam dataset from the Stock Exchange of
Thailand. To address dataset limitations, we applied data augmentation, ReLoRA
for efficient training, Continued Pretraining (CPT) for domain knowledge, and
Rank-Stabilized LoRA (rsLoRA) for fine-tuning. Supervised Fine-Tuning (SFT)
simulated exam scenarios, while Direct Preference Optimization (DPO) refined
the model using feedback. The model achieved scores of 72%, 72%, and 84% on IC
exam levels P1, P2, and P3, respectively, demonstrating its effectiveness in
Thai financial advisory tasks and its potential for specialized applications.

摘要：大型語言模型 (LLM) 在一般任務中表現出色，但在特定領域的挑戰中卻舉步維艱，例如專業術語和在地法規。現有的金融 LLM，例如 FinGPT 和 BloombergGPT，缺乏對泰國金融領域的支持。我們使用泰國證券交易所的投資顧問 (IC) 考試數據集開發了一個泰國金融 LLM。為了解決數據集限制，我們應用數據擴充、用於高效訓練的 ReLoRA、用於領域知識的持續預訓練 (CPT) 以及用於微調的秩穩定 LoRA (rsLoRA)。監督微調 (SFT) 模擬考試場景，而直接偏好最佳化 (DPO) 則使用回饋改進模型。該模型在 IC 考試 P1、P2 和 P3 級別分別達到 72%、72% 和 84% 的分數，證明了其在泰國金融諮詢任務中的有效性及其在專業應用中的潛力。

##### **Exploration of LLM Multi-Agent Application Implementation Based on LangGraph+CrewAI**
2411.18241v1 by Zhihua Duan, Jialin Wang

With the rapid development of large model technology, the application of
agent technology in various fields is becoming increasingly widespread,
profoundly changing people's work and lifestyles. In complex and dynamic
systems, multi-agents achieve complex tasks that are difficult for a single
agent to complete through division of labor and collaboration among agents.
This paper discusses the integrated application of LangGraph and CrewAI.
LangGraph improves the efficiency of information transmission through graph
architecture, while CrewAI enhances team collaboration capabilities and system
performance through intelligent task allocation and resource management. The
main research contents of this paper are: (1) designing the architecture of
agents based on LangGraph for precise control; (2) enhancing the capabilities
of agents based on CrewAI to complete a variety of tasks. This study aims to
delve into the application of LangGraph and CrewAI in multi-agent systems,
providing new perspectives for the future development of agent technology, and
promoting technological progress and application innovation in the field of
large model intelligent agents.

摘要：隨著大模型技術的快速發展，agent 技術在各個領域的應用日益廣泛，深刻地改變著人們的工作和生活方式。在複雜動態的系統中，多個 agent 通過分工協作，完成單個 agent 難以完成的複雜任務。本文探討了 LangGraph 和 CrewAI 的集成應用。LangGraph 通過圖形架構提升了信息傳輸效率，而 CrewAI 則通過智能任務分配和資源管理增強了團隊協作能力和系統性能。本文的主要研究內容包括：（1）基於 LangGraph 設計 agent 架構，實現精準控制；（2）基於 CrewAI 提升 agent 能力，完成多種任務。本研究旨在深入探討 LangGraph 和 CrewAI 在多 agent 系統中的應用，為 agent 技術的未來發展提供新思路，促進大模型智能 agent 領域的技術進步和應用創新。

##### **Certified Training with Branch-and-Bound: A Case Study on Lyapunov-stable Neural Control**
2411.18235v1 by Zhouxing Shi, Cho-Jui Hsieh, Huan Zhang

We study the problem of learning Lyapunov-stable neural controllers which
provably satisfy the Lyapunov asymptotic stability condition within a
region-of-attraction. Compared to previous works which commonly used
counterexample guided training on this task, we develop a new and generally
formulated certified training framework named CT-BaB, and we optimize for
differentiable verified bounds, to produce verification-friendly models. In
order to handle the relatively large region-of-interest, we propose a novel
framework of training-time branch-and-bound to dynamically maintain a training
dataset of subregions throughout training, such that the hardest subregions are
iteratively split into smaller ones whose verified bounds can be computed more
tightly to ease the training. We demonstrate that our new training framework
can produce models which can be more efficiently verified at test time. On the
largest 2D quadrotor dynamical system, verification for our model is more than
5X faster compared to the baseline, while our size of region-of-attraction is
16X larger than the baseline.

摘要：我們研究學習 Lyapunov 穩定神經控制器的問題，它可證明滿足吸引區域內 Lyapunov 漸近穩定條件。與先前通常使用反例引導訓練來執行此任務的作品相比，我們開發了一個新的且普遍制定的認證訓練架構，稱為 CT-BaB，並且我們針對可微分驗證邊界進行最佳化，以產生驗證友善的模型。為了處理相對較大的感興趣區域，我們提出了一個新穎的訓練時間分支定界架構，以在整個訓練過程中動態維護子區域的訓練資料集，這樣最困難的子區域會反覆分割成更小的子區域，其驗證邊界可以更嚴密地計算，以簡化訓練。我們證明了我們的新訓練架構可以產生在測試時可以更有效率驗證的模型。在最大的 2D 四旋翼動力系統上，與基線相比，我們模型的驗證速度快了 5 倍以上，而我們的吸引區域大小比基線大了 16 倍。

##### **Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification**
2411.18234v1 by Abhay Kumar Pathak, Mrityunjay Chaubey, Manjari Gupta

Cardiovascular disease refers to any critical condition that impacts the
heart. Because heart diseases can be life-threatening. Researchers are focusing
on designing smart systems to accurately diagnose them based on electronic
health data, with the aid of machine learning algorithms. Heart disease
classification using machine learning (ML) algorithms such as Support Vector
Machine(SVM), Na\"ive Bayes(NB), Decision Trees (DTs) and Random Forests (RFs)
are often hindered by overfitting. These ML algorithms need extensive
hyperparameter tuning. Random Search offers a faster, and, more efficient
exploration of hyperparameter space, but, it may overlook optimal regions. Grid
Search, though exhaustive, but, it is computationally expensive and
inefficient, particularly with high-dimensional data. To address these
limitations, Randomized-Grid Search, a novel hybrid optimization method is
proposed that combines the global exploration strengths of Random Search with
the focused, and, exhaustive search of Grid Search in the most promising
regions. This hybrid approach efficiently balances exploration and
exploitation. The proposed model optimizes the hyperparameter for Decision Tree
model. The proposed model is applied to UCI heart disease dataset for
classification. It enhances model performance, provides improved accuracy,
generalization, and computational efficiency. Experimental results demonstrate
that Randomized-Grid Search outperforms traditional methods by significant
margins. The proposed model provides a more effective solution for machine
learning applications in healthcare diagnosis.

摘要：心血管疾病是指任何影响心脏的危急状况。由于心脏疾病可能危及生命。研究人员正专注于设计智能系统，以借助机器学习算法根据电子健康数据准确诊断心脏疾病。使用机器学习 (ML) 算法（如支持向量机 (SVM)、朴素贝叶斯 (NB)、决策树 (DT) 和随机森林 (RF)）进行心脏病分类通常会受到过度拟合的阻碍。这些 ML 算法需要广泛的超参数调整。随机搜索提供了对超参数空间更快速、更高效的探索，但它可能会忽略最优区域。网格搜索虽然详尽，但计算成本高且效率低下，尤其是在处理高维数据时。为了解决这些限制，提出了一种新颖的混合优化方法随机网格搜索，它将随机搜索的全局探索优势与网格搜索在最有希望的区域中的集中和详尽搜索相结合。这种混合方法有效地平衡了探索和利用。所提出的模型优化了决策树模型的超参数。所提出的模型应用于 UCI 心脏病数据集进行分类。它增强了模型性能，提高了准确性、泛化能力和计算效率。实验结果表明，随机网格搜索以显著的优势优于传统方法。所提出的模型为医疗诊断中的机器学习应用提供了更有效的解决方案。

##### **Dependency-Aware CAV Task Scheduling via Diffusion-Based Reinforcement Learning**
2411.18230v1 by Xiang Cheng, Zhi Mao, Ying Wang, Wen Wu

In this paper, we propose a novel dependency-aware task scheduling strategy
for dynamic unmanned aerial vehicle-assisted connected autonomous vehicles
(CAVs). Specifically, different computation tasks of CAVs consisting of
multiple dependency subtasks are judiciously assigned to nearby CAVs or the
base station for promptly completing tasks. Therefore, we formulate a joint
scheduling priority and subtask assignment optimization problem with the
objective of minimizing the average task completion time. The problem aims at
improving the long-term system performance, which is reformulated as a Markov
decision process. To solve the problem, we further propose a diffusion-based
reinforcement learning algorithm, named Synthetic DDQN based Subtasks
Scheduling, which can make adaptive task scheduling decision in real time. A
diffusion model-based synthetic experience replay is integrated into the
reinforcement learning framework, which can generate sufficient synthetic data
in experience replay buffer, thereby significantly accelerating convergence and
improving sample efficiency. Simulation results demonstrate the effectiveness
of the proposed algorithm on reducing task completion time, comparing to
benchmark schemes.

摘要：<paragraph>在本文中，我們提出了一種新的依賴感知任務調度策略，用於動態無人機輔助連網自動駕駛車輛 (CAV)。具體來說，將由多個依賴子任務組成的 CAV 的不同計算任務明智地分配給附近的 CAV 或基地台，以快速完成任務。因此，我們制定了一個聯合調度優先級和子任務分配優化問題，目標是最大程度地減少平均任務完成時間。該問題旨在提高長期系統性能，這被重新表述為馬可夫決策過程。為了解決這個問題，我們進一步提出了一種基於擴散的強化學習演算法，稱為基於合成 DDQN 的子任務調度，它可以在實時做出適應性任務調度決策。一種基於擴散模型的合成經驗回放被整合到強化學習框架中，它可以在經驗回放緩衝區中產生足夠的合成資料，從而顯著加速收斂並提高樣本效率。模擬結果證明了所提出的演算法在減少任務完成時間方面的有效性，並與基準方案進行了比較。</paragraph>

##### **Feature-Factory: Automating Software Feature Integration Using Generative AI**
2411.18226v1 by Ruslan Idelfonso Magana Vsevolodovna

Integrating new features into existing software projects can be a complex and
time-consuming process. Feature-Factory leverages Generative AI with WatsonX.ai
to automate the analysis, planning, and implementation of feature requests. By
combining advanced project parsing, dependency resolution, and AI-generated
code, the program ensures seamless integration of features into software
systems while maintaining structural integrity. This paper presents the
methodology, mathematical model, and results of the Feature-Factory framework.

摘要：將新功能整合到現有軟體專案中可能是一個複雜且耗時的程序。Feature-Factory 透過 WatsonX.ai 活用生成式 AI 來自動化功能請求的分析、規劃和實作。透過結合進階專案剖析、相依性解析和 AI 生成的程式碼，此程式確保功能與軟體系統的無縫整合，同時維持結構的完整性。本文說明了 Feature-Factory 架構的方法論、數學模型和結果。

##### **PATHS: A Hierarchical Transformer for Efficient Whole Slide Image Analysis**
2411.18225v1 by Zak Buzzard, Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik

Computational analysis of whole slide images (WSIs) has seen significant
research progress in recent years, with applications ranging across important
diagnostic and prognostic tasks such as survival or cancer subtype prediction.
Many state-of-the-art models process the entire slide - which may be as large
as $150,000 \times 150,000$ pixels - as a bag of many patches, the size of
which necessitates computationally cheap feature aggregation methods. However,
a large proportion of these patches are uninformative, such as those containing
only healthy or adipose tissue, adding significant noise and size to the bag.
We propose Pathology Transformer with Hierarchical Selection (PATHS), a novel
top-down method for hierarchical weakly supervised representation learning on
slide-level tasks in computational pathology. PATHS is inspired by the
cross-magnification manner in which a human pathologist examines a slide,
recursively filtering patches at each magnification level to a small subset
relevant to the diagnosis. Our method overcomes the complications of processing
the entire slide, enabling quadratic self-attention and providing a simple
interpretable measure of region importance. We apply PATHS to five datasets of
The Cancer Genome Atlas (TCGA), and achieve superior performance on slide-level
prediction tasks when compared to previous methods, despite processing only a
small proportion of the slide.

摘要：近年來，全玻片影像 (WSI) 的計算分析已取得顯著的研究進展，其應用範圍涵蓋重要的診斷和預後任務，例如存活率或癌症亞型預測。許多最先進的模型將整個玻片（可能大至 150,000 × 150,000 像素）視為許多區塊的集合，其大小需要計算成本低廉的特徵聚合方法。然而，這些區塊中很大一部分沒有提供資訊，例如僅包含健康或脂肪組織的區塊，這會為集合增加大量雜訊和大小。我們提出具有階層式選擇的病理Transformer (PATHS)，這是一種新穎的自上而下方法，用於計算病理學中玻片級任務的階層式弱監督表示學習。PATHS 的靈感來自人類病理學家檢查玻片的跨放大倍率方式，在每個放大倍率層級遞迴地將區塊篩選為與診斷相關的小子集。我們的這種方法克服了處理整個玻片的複雜性，支援二次自注意力，並提供一個區域重要性的簡單可解讀測量。我們將 PATHS 應用於癌症基因組圖譜 (TCGA) 的五個資料集，並在玻片級預測任務上取得優異的效能，儘管僅處理了玻片的一小部分。

##### **R-MTLLMF: Resilient Multi-Task Large Language Model Fusion at the Wireless Edge**
2411.18220v1 by Aladin Djuhera, Vlad C. Andrei, Mohsen Pourghasemian, Haris Gacanin, Holger Boche, Walid Saad

Multi-task large language models (MTLLMs) are important for many applications
at the wireless edge, where users demand specialized models to handle multiple
tasks efficiently. However, training MTLLMs is complex and exhaustive,
particularly when tasks are subject to change. Recently, the concept of model
fusion via task vectors has emerged as an efficient approach for combining
fine-tuning parameters to produce an MTLLM. In this paper, the problem of
enabling edge users to collaboratively craft such MTTLMs via tasks vectors is
studied, under the assumption of worst-case adversarial attacks. To this end,
first the influence of adversarial noise to multi-task model fusion is
investigated and a relationship between the so-called weight disentanglement
error and the mean squared error (MSE) is derived. Using hypothesis testing, it
is directly shown that the MSE increases interference between task vectors,
thereby rendering model fusion ineffective. Then, a novel resilient MTLLM
fusion (R-MTLLMF) is proposed, which leverages insights about the LLM
architecture and fine-tuning process to safeguard task vector aggregation under
adversarial noise by realigning the MTLLM. The proposed R-MTLLMF is then
compared for both worst-case and ideal transmission scenarios to study the
impact of the wireless channel. Extensive model fusion experiments with vision
LLMs demonstrate R-MTLLMF's effectiveness, achieving close-to-baseline
performance across eight different tasks in ideal noise scenarios and
significantly outperforming unprotected model fusion in worst-case scenarios.
The results further advocate for additional physical layer protection for a
holistic approach to resilience, from both a wireless and LLM perspective.

摘要：多任務大型語言模型 (MTLLM) 對許多應用程式而言非常重要，特別是在無線邊緣，使用者需要專門的模型來有效率地處理多項任務。然而，訓練 MTLLM 是一項複雜且耗盡資源的任務，特別是在任務會改變的情況下。最近，透過任務向量的模型融合概念已成為一種有效率的方法，用於結合微調參數以產生 MTLLM。本文研究了在最壞情況的對抗性攻擊假設下，讓邊緣使用者透過任務向量協作打造此類 MTLLM 的問題。為此，首先探討了對抗性雜訊對多任務模型融合的影響，並推導出所謂的權重解糾纏誤差與均方誤差 (MSE) 之間的關係。透過假設檢定，直接顯示 MSE 會增加任務向量之間的干擾，從而使模型融合無效。接著，提出了一種新穎的彈性 MTLLM 融合 (R-MTLLMF)，它利用有關 LLM 架構和微調流程的見解，透過重新調整 MTLLM，在對抗性雜訊下保護任務向量聚合。然後，針對最壞情況和理想傳輸情境比較所提出的 R-MTLLMF，以研究無線頻道的影響。廣泛的模型融合實驗顯示 R-MTLLMF 的有效性，在理想雜訊情境中，在八種不同的任務中達到接近基線的效能，並且在最壞情況下明顯優於未受保護的模型融合。結果進一步提倡額外的物理層保護，以從無線和 LLM 的角度採取整體復原力方法。

##### **How to Learn a New Language? An Efficient Solution for Self-Supervised Learning Models Unseen Languages Adaption in Low-Resource Scenario**
2411.18217v1 by Shih-Heng Wang, Zih-Ching Chen, Jiatong Shi, Ming-To Chuang, Guan-Ting Lin, Kuan-Po Huang, David Harwath, Shang-Wen Li, Hung-yi Lee

The utilization of speech Self-Supervised Learning (SSL) models achieves
impressive performance on Automatic Speech Recognition (ASR). However, in
low-resource language ASR, they encounter the domain mismatch problem between
pre-trained and low-resource languages. Typical solutions like fine-tuning the
SSL model suffer from high computation costs while using frozen SSL models as
feature extractors comes with poor performance. To handle these issues, we
extend a conventional efficient fine-tuning scheme based on the adapter. We add
an extra intermediate adaptation to warm up the adapter and downstream model
initialization. Remarkably, we update only 1-5% of the total model parameters
to achieve the adaptation. Experimental results on the ML-SUPERB dataset show
that our solution outperforms conventional efficient fine-tuning. It achieves
up to a 28% relative improvement in the Character/Phoneme error rate when
adapting to unseen languages.

摘要：利用自监督学习（SSL）模型的语音实现了
自动语音识别（ASR）的出色表现。然而，在
低资源语言 ASR 中，它们遇到了预训练和低资源语言之间的域不匹配问题。典型的解决方案，例如微调
SSL 模型会产生高计算成本，而使用冻结的 SSL 模型作为
特征提取器会带来较差的性能。为了处理这些问题，我们
基于适配器扩展了一种传统的有效微调方案。我们添加
了一个额外的中间适配来预热适配器和下游模型
初始化。值得注意的是，我们只更新了 1-5% 的总模型参数
来实现适配。ML-SUPERB 数据集上的实验结果表明
我们的解决方案优于传统的有效微调。它实现了
在适应未见语言时，字符/音素错误率提高了 28%。

##### **SCoTT: Wireless-Aware Path Planning with Vision Language Models and Strategic Chains-of-Thought**
2411.18212v1 by Aladin Djuhera, Vlad C. Andrei, Amin Seffo, Holger Boche, Walid Saad

Path planning is a complex problem for many practical applications,
particularly in robotics. Existing algorithms, however, are exhaustive in
nature and become increasingly complex when additional side constraints are
incorporated alongside distance minimization. In this paper, a novel approach
using vision language models (VLMs) is proposed for enabling path planning in
complex wireless-aware environments. To this end, insights from a digital twin
(DT) with real-world wireless ray tracing data are explored in order to
guarantee an average path gain threshold while minimizing the trajectory
length. First, traditional approaches such as A* are compared to several
wireless-aware extensions, and an optimal iterative dynamic programming
approach (DP-WA*) is derived, which fully takes into account all path gains and
distance metrics within the DT. On the basis of these baselines, the role of
VLMs as an alternative assistant for path planning is investigated, and a
strategic chain-of-thought tasking (SCoTT) approach is proposed. SCoTT divides
the complex planning task into several subproblems and solves each with
advanced CoT prompting. Results show that SCoTT achieves very close average
path gains compared to DP-WA* while at the same time yielding consistently
shorter path lengths. The results also show that VLMs can be used to accelerate
DP-WA* by efficiently reducing the algorithm's search space and thus saving up
to 62\% in execution time. This work underscores the potential of VLMs in
future digital systems as capable assistants for solving complex tasks, while
enhancing user interaction and accelerating rapid prototyping under diverse
wireless constraints.

摘要：路徑規劃對許多實務應用而言是一項複雜的問題，特別是在機器人技術中。然而，現有的演算法本質上是窮舉的，並且在距離最小化時加入額外的邊界限制時會變得越來越複雜。在本文中，提出了一種使用視覺語言模型 (VLM) 的新方法，用於在複雜的無線感知環境中進行路徑規劃。為此，探索了具有真實世界無線射線追蹤資料的數位雙胞胎 (DT) 的見解，以在最小化軌跡長度的同時保證平均路徑增益閾值。首先，將傳統方法（例如 A*）與多種無線感知延伸功能進行比較，並推導出最佳的迭代動態規劃方法 (DP-WA*)，該方法充分考慮了 DT 中的所有路徑增益和距離度量。在這些基準的基礎上，研究了 VLM 作為路徑規劃的替代輔助工具的角色，並提出了一種策略性的思考鏈任務 (SCoTT) 方法。SCoTT 將複雜的規劃任務分解為幾個子問題，並使用進階的 CoT 提示解決每個子問題。結果顯示，與 DP-WA* 相比，SCoTT 達到了非常接近的平均路徑增益，同時產生持續更短的路徑長度。結果還表明，VLM 可用於加速 DP-WA*，方法是有效地減少演算法的搜尋空間，從而將執行時間節省高達 62%。這項工作強調了 VLM 在未來數位系統中作為解決複雜任務的強大輔助工具的潛力，同時增強使用者互動並在不同的無線限制下加速快速原型製作。

##### **TimeMarker: A Versatile Video-LLM for Long and Short Video Understanding with Superior Temporal Localization Ability**
2411.18211v1 by Shimin Chen, Xiaohan Lan, Yitian Yuan, Zequn Jie, Lin Ma

Rapid development of large language models (LLMs) has significantly advanced
multimodal large language models (LMMs), particularly in vision-language tasks.
However, existing video-language models often overlook precise temporal
localization and struggle with videos of varying lengths. We introduce
TimeMarker, a versatile Video-LLM designed for high-quality dialogue based on
video content, emphasizing temporal localization. TimeMarker integrates
Temporal Separator Tokens to enhance temporal awareness, accurately marking
specific moments within videos. It employs the AnyLength mechanism for dynamic
frame sampling and adaptive token merging, enabling effective handling of both
short and long videos. Additionally, TimeMarker utilizes diverse datasets,
including further transformed temporal-related video QA datasets, to bolster
its temporal understanding capabilities. Image and interleaved data are also
employed to further enhance the model's semantic perception ability.
Evaluations demonstrate that TimeMarker achieves state-of-the-art performance
across multiple benchmarks, excelling in both short and long video categories.
Our project page is at \url{https://github.com/TimeMarker-LLM/TimeMarker/}.

摘要：大型語言模型（LLM）的快速發展已顯著提升多模態大型語言模型（LMM），特別是在視覺語言任務中。然而，現有的視訊語言模型常常忽略精確的時間定位，並在處理長度不一的視訊時遇到困難。我們介紹 TimeMarker，一種專為基於視訊內容的高品質對話而設計的多功能視訊 LLM，強調時間定位。TimeMarker 整合時間分隔符號記號，以增強時間感知，精確標記視訊中的特定時刻。它採用 AnyLength 機制進行動態幀取樣和自適應記號合併，可以有效處理短視訊和長視訊。此外，TimeMarker 利用多樣化的資料集，包括進一步轉換的時間相關視訊問答資料集，以強化其時間理解能力。影像和交錯資料也用於進一步增強模型的語義感知能力。評估結果顯示，TimeMarker 在多個基準測試中都達到了最先進的效能，在短視訊和長視訊類別中都表現出色。我們的專案頁面位於 \url{https://github.com/TimeMarker-LLM/TimeMarker/}。

##### **From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects**
2411.18207v1 by Zizhao Li, Zhengkang Xiang, Joseph West, Kourosh Khoshelham

Traditional object detection methods operate under the closed-set assumption,
where models can only detect a fixed number of objects predefined in the
training set. Recent works on open vocabulary object detection (OVD) enable the
detection of objects defined by an unbounded vocabulary, which reduces the cost
of training models for specific tasks. However, OVD heavily relies on accurate
prompts provided by an ''oracle'', which limits their use in critical
applications such as driving scene perception. OVD models tend to misclassify
near-out-of-distribution (NOOD) objects that have similar semantics to known
classes, and ignore far-out-of-distribution (FOOD) objects. To address theses
limitations, we propose a framework that enables OVD models to operate in open
world settings, by identifying and incrementally learning novel objects. To
detect FOOD objects, we propose Open World Embedding Learning (OWEL) and
introduce the concept of Pseudo Unknown Embedding which infers the location of
unknown classes in a continuous semantic space based on the information of
known classes. We also propose Multi-Scale Contrastive Anchor Learning (MSCAL),
which enables the identification of misclassified unknown objects by promoting
the intra-class consistency of object embeddings at different scales. The
proposed method achieves state-of-the-art performance in common open world
object detection and autonomous driving benchmarks.

摘要：傳統的物件偵測方法在封閉集合假設下運作，其中模型只能偵測訓練集中預先定義的固定數量物件。近期關於開放詞彙物件偵測 (OVD) 的研究能偵測由不受限詞彙定義的物件，這減少了訓練特定任務模型的成本。然而，OVD 嚴重依賴由「神諭」提供的準確提示，這限制了它們在關鍵應用中的使用，例如駕駛場景感知。OVD 模型傾向於將近乎超出分佈 (NOOD) 的物件錯誤分類為與已知類別具有類似語意的物件，並忽略遠超出分佈 (FOOD) 的物件。為了解決這些限制，我們提出一個框架，讓 OVD 模型能夠在開放世界設定中運作，方法是識別並逐步學習新穎物件。為了偵測 FOOD 物件，我們提出開放世界嵌入式學習 (OWEL)，並引入偽未知嵌入的概念，該概念根據已知類別的資訊，推論出未知類別在連續語義空間中的位置。我們也提出多尺度對比錨學習 (MSCAL)，它能透過提升不同尺度物件嵌入的類內一致性，來識別錯誤分類的未知物件。所提出的方法在常見的開放世界物件偵測和自動駕駛基準中，達成最先進的效能。

##### **Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning**
2411.18203v1 by Di Zhang, Jingdi Lei, Junxian Li, Xunzhi Wang, Yujie Liu, Zonglin Yang, Jiatong Li, Weida Wang, Suorong Yang, Jianbo Wu, Peng Ye, Wanli Ouyang, Dongzhan Zhou

Vision-language models~(VLMs) have shown remarkable advancements in
multimodal reasoning tasks. However, they still often generate inaccurate or
irrelevant responses due to issues like hallucinated image understandings or
unrefined reasoning paths. To address these challenges, we introduce Critic-V,
a novel framework inspired by the Actor-Critic paradigm to boost the reasoning
capability of VLMs. This framework decouples the reasoning process and critic
process by integrating two independent components: the Reasoner, which
generates reasoning paths based on visual and textual inputs, and the Critic,
which provides constructive critique to refine these paths. In this approach,
the Reasoner generates reasoning responses according to text prompts, which can
evolve iteratively as a policy based on feedback from the Critic. This
interaction process was theoretically driven by a reinforcement learning
framework where the Critic offers natural language critiques instead of scalar
rewards, enabling more nuanced feedback to boost the Reasoner's capability on
complex reasoning tasks. The Critic model is trained using Direct Preference
Optimization (DPO), leveraging a preference dataset of critiques ranked by
Rule-based Reward(RBR) to enhance its critic capabilities. Evaluation results
show that the Critic-V framework significantly outperforms existing methods,
including GPT-4V, on 5 out of 8 benchmarks, especially regarding reasoning
accuracy and efficiency. Combining a dynamic text-based policy for the Reasoner
and constructive feedback from the preference-optimized Critic enables a more
reliable and context-sensitive multimodal reasoning process. Our approach
provides a promising solution to enhance the reliability of VLMs, improving
their performance in real-world reasoning-heavy multimodal applications such as
autonomous driving and embodied intelligence.

摘要：<paragraph>視覺語言模型 (VLM) 在多模態推理任務中展現出顯著的進步。然而，由於幻覺影像理解或未經提煉的推理路徑等問題，它們仍然經常產生不準確或不相關的回應。為了應對這些挑戰，我們引入了 Critic-V，這是一個受 Actor-Critic 典範啟發的新穎架構，用於提升 VLM 的推理能力。此架構透過整合兩個獨立的組件來解耦推理程序和批評程序：推理器，它根據視覺和文字輸入產生推理路徑，以及批評者，它提供建設性的批評來優化這些路徑。在此方法中，推理器根據文字提示產生推理回應，這些回應可以根據批評者的回饋作為政策反覆演進。此互動程序在理論上是由強化學習架構推動的，其中批評者提供自然語言批評，而不是標量獎勵，從而能夠提供更多細微的回饋，以提升推理器在複雜推理任務中的能力。批評者模型使用直接偏好最佳化 (DPO) 進行訓練，利用基於規則的獎勵 (RBR) 排名的批評偏好資料集來增強其批評能力。評估結果顯示，Critic-V 架構在 8 個基準中的 5 個基準上顯著優於現有方法，包括 GPT-4V，特別是在推理準確性和效率方面。結合推理器的動態基於文字的政策和偏好最佳化批評者的建設性回饋，可以實現更可靠且對情境敏感的多模態推理程序。我們的做法提供了一個有前途的解決方案，用於增強 VLM 的可靠性，改善它們在現實世界中以推理為主的多模態應用程式（例如自動駕駛和具身智能）中的性能。</paragraph>

##### **Prediction with Action: Visual Policy Learning via Joint Denoising Process**
2411.18179v1 by Yanjiang Guo, Yucheng Hu, Jianke Zhang, Yen-Jen Wang, Xiaoyu Chen, Chaochao Lu, Jianyu Chen

Diffusion models have demonstrated remarkable capabilities in image
generation tasks, including image editing and video creation, representing a
good understanding of the physical world. On the other line, diffusion models
have also shown promise in robotic control tasks by denoising actions, known as
diffusion policy. Although the diffusion generative model and diffusion policy
exhibit distinct capabilities--image prediction and robotic action,
respectively--they technically follow a similar denoising process. In robotic
tasks, the ability to predict future images and generate actions is highly
correlated since they share the same underlying dynamics of the physical world.
Building on this insight, we introduce PAD, a novel visual policy learning
framework that unifies image Prediction and robot Action within a joint
Denoising process. Specifically, PAD utilizes Diffusion Transformers (DiT) to
seamlessly integrate images and robot states, enabling the simultaneous
prediction of future images and robot actions. Additionally, PAD supports
co-training on both robotic demonstrations and large-scale video datasets and
can be easily extended to other robotic modalities, such as depth images. PAD
outperforms previous methods, achieving a significant 26.3% relative
improvement on the full Metaworld benchmark, by utilizing a single
text-conditioned visual policy within a data-efficient imitation learning
setting. Furthermore, PAD demonstrates superior generalization to unseen tasks
in real-world robot manipulation settings with 28.0% success rate increase
compared to the strongest baseline. Project page at
https://sites.google.com/view/pad-paper

摘要：擴散模型已在影像生成任務中展現出非凡的能力，包括影像編輯和影片創作，代表著對物理世界的良好理解。另一方面，擴散模型也已在機器人控制任務中展現出前景，透過消除動作雜訊，稱為擴散策略。儘管擴散生成模型和擴散策略展現出不同的能力——分別為影像預測和機器人動作，但在技術上，它們遵循類似的去雜訊程序。在機器人任務中，預測未來影像和產生動作的能力高度相關，因為它們共用物理世界的相同基礎動態。基於此見解，我們引進 PAD，一種新穎的視覺策略學習架構，在聯合去雜訊程序中統一影像預測和機器人動作。具體來說，PAD 使用擴散Transformer (DiT) 來無縫整合影像和機器人狀態，同時預測未來影像和機器人動作。此外，PAD 支援在機器人示範和大型影片資料集上進行共同訓練，並且可以輕鬆延伸到其他機器人模式，例如深度影像。PAD 優於先前的各種方法，在完整的 Metaworld 基準上實現顯著的 26.3% 相對進步，方法是在資料有效率的模仿學習設定中使用單一文字條件視覺策略。此外，與最強大的基準相比，PAD 在真實世界機器人操作設定中展現出對未見任務的優異泛化能力，成功率增加了 28.0%。專案頁面在 https://sites.google.com/view/pad-paper

##### **PDZSeg: Adapting the Foundation Model for Dissection Zone Segmentation with Visual Prompts in Robot-assisted Endoscopic Submucosal Dissection**
2411.18169v1 by Mengya Xu, Wenjin Mo, Guankun Wang, Huxin Gao, An Wang, Zhen Li, Xiaoxiao Yang, Hongliang Ren

Purpose: Endoscopic surgical environments present challenges for dissection
zone segmentation due to unclear boundaries between tissue types, leading to
segmentation errors where models misidentify or overlook edges. This study aims
to provide precise dissection zone suggestions during endoscopic submucosal
dissection (ESD) procedures, enhancing ESD safety.
  Methods: We propose the Prompted-based Dissection Zone Segmentation (PDZSeg)
model, designed to leverage diverse visual prompts such as scribbles and
bounding boxes. By overlaying these prompts onto images and fine-tuning a
foundational model on a specialized dataset, our approach improves segmentation
performance and user experience through flexible input methods.
  Results: The PDZSeg model was validated using three experimental setups:
in-domain evaluation, variability in visual prompt availability, and robustness
assessment. Using the ESD-DZSeg dataset, results show that our method
outperforms state-of-the-art segmentation approaches. This is the first study
to integrate visual prompt design into dissection zone segmentation.
  Conclusion: The PDZSeg model effectively utilizes visual prompts to enhance
segmentation performance and user experience, supported by the novel ESD-DZSeg
dataset as a benchmark for dissection zone segmentation in ESD. Our work
establishes a foundation for future research.

摘要：<paragraph>目的：內視鏡手術環境因組織類型之間的邊界不明確，對解剖區域分割造成挑戰，導致模型誤認或忽略邊緣，進而造成分割錯誤。本研究旨在於內視鏡黏膜下剝離術 (ESD) 手術中提供精確的解剖區域建議，以提升 ESD 的安全性。
方法：我們提出以提示為基礎的解剖區域分割 (PDZSeg) 模型，旨在利用塗鴉和邊界框等多樣化的視覺提示。藉由將這些提示疊加到影像上，並針對特定資料集微調基礎模型，我們的做法透過靈活的輸入方式來改善分割效能和使用者體驗。
結果：PDZSeg 模型使用三個實驗設置進行驗證：領域內評估、視覺提示可用性的變異性，以及穩健性評估。使用 ESD-DZSeg 資料集，結果顯示我們的方法優於現有的分割方法。這是第一個將視覺提示設計整合到解剖區域分割的研究。
結論：PDZSeg 模型有效利用視覺提示來增強分割效能和使用者體驗，並以新穎的 ESD-DZSeg 資料集作為 ESD 中解剖區域分割的基準。我們的研究為未來的研究奠定了基礎。</paragraph>

##### **SentiXRL: An advanced large language Model Framework for Multilingual Fine-Grained Emotion Classification in Complex Text Environment**
2411.18162v1 by Jie Wang, Yichen Wang, Zhilin Zhang, Jianhao Zeng, Kaidi Wang, Zhiyang Chen

With strong expressive capabilities in Large Language Models(LLMs),
generative models effectively capture sentiment structures and deep semantics,
however, challenges remain in fine-grained sentiment classification across
multi-lingual and complex contexts. To address this, we propose the Sentiment
Cross-Lingual Recognition and Logic Framework (SentiXRL), which incorporates
two modules,an emotion retrieval enhancement module to improve sentiment
classification accuracy in complex contexts through historical dialogue and
logical reasoning,and a self-circulating analysis negotiation mechanism
(SANM)to facilitates autonomous decision-making within a single model for
classification tasks.We have validated SentiXRL's superiority on multiple
standard datasets, outperforming existing models on CPED and CH-SIMS,and
achieving overall better performance on MELD,Emorynlp and IEMOCAP. Notably, we
unified labels across several fine-grained sentiment annotation datasets and
conducted category confusion experiments, revealing challenges and impacts of
class imbalance in standard datasets.

摘要：藉由大型語言模型 (LLM) 強大的表達能力，
生成模型有效地捕捉情緒結構和深層語義，
然而，跨多語言和複雜情境中的細粒度情緒分類仍有挑戰。為了解決這個問題，我們提出情緒跨語言識別和邏輯框架 (SentiXRL)，其中包含兩個模組，一個情緒檢索增強模組，透過歷史對話和邏輯推理來改善複雜情境中的情緒分類準確度，以及一個自我循環分析協商機制 (SANM)，以利於在單一模型中針對分類任務進行自主決策。我們已在多個標準資料集驗證 SentiXRL 的優越性，在 CPED 和 CH-SIMS 上優於現有模型，且在 MELD、Emorynlp 和 IEMOCAP 上達成整體更好的效能。值得注意的是，我們統一了幾個細粒度情緒標註資料集中的標籤，並進行了類別混淆實驗，揭示了標準資料集中類別不平衡的挑戰和影響。

##### **A survey on cutting-edge relation extraction techniques based on language models**
2411.18157v1 by Jose A. Diaz-Garcia, Julio Amador Diaz Lopez

This comprehensive survey delves into the latest advancements in Relation
Extraction (RE), a pivotal task in natural language processing essential for
applications across biomedical, financial, and legal sectors. This study
highlights the evolution and current state of RE techniques by analyzing 137
papers presented at the Association for Computational Linguistics (ACL)
conferences over the past four years, focusing on models that leverage language
models. Our findings underscore the dominance of BERT-based methods in
achieving state-of-the-art results for RE while also noting the promising
capabilities of emerging large language models (LLMs) like T5, especially in
few-shot relation extraction scenarios where they excel in identifying
previously unseen relations.

摘要：這項全面的調查深入探討了關係萃取 (RE) 的最新進展，關係萃取是自然語言處理中的一項關鍵任務，對於生物醫學、金融和法律領域的應用至關重要。本研究透過分析過去四年來計算語言學協會 (ACL) 會議上提出的 137 篇論文，重點探討利用語言模型的模型，突顯了關係萃取技術的演進和現況。我們的研究結果強調了 BERT 為基礎的方法在達成關係萃取的最新成果中所扮演的主導地位，同時也注意到新興大型語言模型 (LLM)（例如 T5）具備的潛力，特別是在少樣本關係萃取場景中，它們在辨識前所未見的關係方面表現出色。

##### **MSA-ASR: Efficient Multilingual Speaker Attribution with frozen ASR Models**
2411.18152v1 by Thai-Binh Nguyen, Alexander Waibel

Speaker-attributed automatic speech recognition (SA-ASR) aims to transcribe
speech while assigning transcripts to the corresponding speakers accurately.
Existing methods often rely on complex modular systems or require extensive
fine-tuning of joint modules, limiting their adaptability and general
efficiency. This paper introduces a novel approach, leveraging a frozen
multilingual ASR model to incorporate speaker attribution into the
transcriptions, using only standard monolingual ASR datasets. Our method
involves training a speaker module to predict speaker embeddings based on weak
labels without requiring additional ASR model modifications. Despite being
trained exclusively with non-overlapping monolingual data, our approach
effectively extracts speaker attributes across diverse multilingual datasets,
including those with overlapping speech. Experimental results demonstrate
competitive performance compared to strong baselines, highlighting the model's
robustness and potential for practical applications.

摘要：說話者歸因自動語音辨識（SA-ASR）旨在轉錄語音，同時將轉錄內容準確地分配給對應的說話者。現有方法通常依賴於複雜的模組化系統，或是需要對聯合模組進行廣泛的微調，這限制了其適應性和整體效率。本文介紹了一種新穎的方法，利用凍結的多語言 ASR 模型將說話者歸因納入轉錄內容中，僅使用標準的單語言 ASR 資料集。我們的模型涉及訓練一個說話者模組，以根據弱標籤預測說話者的嵌入，而不需要額外的 ASR 模型修改。儘管僅使用非重疊的單語言資料進行訓練，但我們的模型有效地從多樣化的多語言資料集中提取說話者屬性，包括那些語音重疊的資料集。實驗結果表明，與強大的基線相比，我們的模型具有競爭力的效能，突顯了模型的穩健性和在實際應用中的潛力。

##### **Predicting Water Quality using Quantum Machine Learning: The Case of the Umgeni Catchment (U20A) Study Region**
2411.18141v1 by Muhammad Al-Zafar Khan, Jamal Al-Karaki, Marwan Omar

In this study, we consider a real-world application of QML techniques to
study water quality in the U20A region in Durban, South Africa. Specifically,
we applied the quantum support vector classifier (QSVC) and quantum neural
network (QNN), and we showed that the QSVC is easier to implement and yields a
higher accuracy. The QSVC models were applied for three kernels: Linear,
polynomial, and radial basis function (RBF), and it was shown that the
polynomial and RBF kernels had exactly the same performance. The QNN model was
applied using different optimizers, learning rates, noise on the circuit
components, and weight initializations were considered, but the QNN
persistently ran into the dead neuron problem. Thus, the QNN was compared only
by accraucy and loss, and it was shown that with the Adam optimizer, the model
has the best performance, however, still less than the QSVC.

摘要：在本研究中，我們考慮了 QML 技術在南非德班 U20A 地區水質研究中的實際應用。具體而言，我們應用量子支持向量分類器 (QSVC) 和量子神經網路 (QNN)，我們表明 QSVC 更容易實現並產生更高的準確度。QSVC 模型應用於三種核：線性、多項式和徑向基函數 (RBF)，結果表明多項式和 RBF 核具有完全相同的性能。QNN 模型使用不同的優化器、學習率、電路組件上的噪聲，並考慮權重初始化，但 QNN 持續遇到死神經元問題。因此，僅通過準確度和損失對 QNN 進行比較，結果表明使用 Adam 優化器時，該模型具有最佳性能，但仍低於 QSVC。

##### **SALMONN-omni: A Codec-free LLM for Full-duplex Speech Understanding and Generation**
2411.18138v1 by Wenyi Yu, Siyin Wang, Xiaoyu Yang, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Guangzhi Sun, Lu Lu, Yuxuan Wang, Chao Zhang

Full-duplex multimodal large language models (LLMs) provide a unified
framework for addressing diverse speech understanding and generation tasks,
enabling more natural and seamless human-machine conversations. Unlike
traditional modularised conversational AI systems, which separate speech
recognition, understanding, and text-to-speech generation into distinct
components, multimodal LLMs operate as single end-to-end models. This
streamlined design eliminates error propagation across components and fully
leverages the rich non-verbal information embedded in input speech signals. We
introduce SALMONN-omni, a codec-free, full-duplex speech understanding and
generation model capable of simultaneously listening to its own generated
speech and background sounds while speaking. To support this capability, we
propose a novel duplex spoken dialogue framework incorporating a ``thinking''
mechanism that facilitates asynchronous text and speech generation relying on
embeddings instead of codecs (quantized speech and audio tokens). Experimental
results demonstrate SALMONN-omni's versatility across a broad range of
streaming speech tasks, including speech recognition, speech enhancement, and
spoken question answering. Additionally, SALMONN-omni excels at managing
turn-taking, barge-in, and echo cancellation scenarios, establishing its
potential as a robust prototype for full-duplex conversational AI systems. To
the best of our knowledge, SALMONN-omni is the first codec-free model of its
kind. A full technical report along with model checkpoints will be released
soon.

摘要：全雙工多模態大型語言模型 (LLM) 提供了一個統一的架構，用於處理各種語音理解和生成任務，實現更自然、更順暢的人機對話。與傳統的模組化對話式 AI 系統不同，傳統系統將語音辨識、理解和文字轉語音生成分為不同的元件，多模態 LLM 則作為單一的端到端模型運作。這種簡化的設計消除了元件間的錯誤傳播，並充分利用輸入語音訊號中豐富的非語言資訊。我們推出 SALMONN-omni，這是一個無編碼器、全雙工的語音理解和生成模型，能夠在說話時同時聆聽自己產生的語音和背景音。為了支援此功能，我們提出一個新穎的雙工口語對話架構，結合了一個「思考」機制，這個機制使用嵌入式技術（而非編碼器，即量化的語音和音訊代碼）來促進非同步文字和語音生成。實驗結果證明 SALMONN-omni 在廣泛的串流語音任務中展現了多功能性，包括語音辨識、語音增強和口說問題回答。此外，SALMONN-omni 在管理輪流發言、插話和回音消除場景方面表現出色，確立了其作為全雙工對話式 AI 系統的強健原型之潛力。據我們所知，SALMONN-omni 是同類中第一個無編碼器的模型。完整的技術報告和模型檢查點將很快發布。

##### **Curriculum Demonstration Selection for In-Context Learning**
2411.18126v1 by Duc Anh Vu, Nguyen Tran Cong Duy, Xiaobao Wu, Hoang Minh Nhat, Du Mingzhe, Nguyen Thanh Thong, Anh Tuan Luu

Large Language Models (LLMs) have shown strong in-context learning (ICL)
abilities with a few demonstrations. However, one critical challenge is how to
select demonstrations to elicit the full potential of LLMs. In this paper, we
propose Curriculum Demonstration Selection (CDS), a novel demonstration
selection method for ICL. Instead of merely using similarity, CDS additionally
partitions samples by their complexity measurements. Following curriculum
learning, CDS then selects demonstrations from easy to difficult. Thus the
selected demonstrations cover a wide range of difficulty levels, enabling LLMs
to learn from varied complexities within the training set. Experiments
demonstrate that our CDS consistently outperforms baseline methods, achieving
notable improvements across nine LLMs on three benchmarks. Moreover, CDS proves
especially effective in enhancing LLM performance in solving challenging
problems.

摘要：大型語言模型 (LLM) 在少數示範中展現了強大的情境學習 (ICL) 能力。然而，一個重要的挑戰是如何選擇示範來引發 LLM 的全部潛力。在本文中，我們提出課程示範選擇 (CDS)，一種用於 ICL 的新示範選擇方法。CDS 不僅使用相似性，還根據示範的複雜性測量值對樣本進行分區。遵循課程學習後，CDS 會從容易到困難選擇示範。因此，所選的示範涵蓋了廣泛的難度等級，使 LLM 能夠從訓練集中學習到各種複雜性。實驗證明，我們的 CDS 持續優於基準方法，在三個基準上對九個 LLM 進行了顯著的改進。此外，CDS 被證明在增強 LLM 解決具有挑戰性問題的性能方面特別有效。

##### **Training and Evaluating Language Models with Template-based Data Generation**
2411.18104v1 by Yifan Zhang

The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,
and Llama has significantly transformed natural language processing, showcasing
remarkable capabilities in understanding and generating language. However,
these models often struggle with tasks requiring complex reasoning,
particularly in mathematical problem-solving, due in part to the scarcity of
large-scale, high-quality, domain-specific datasets necessary for training
sophisticated reasoning abilities. To address this limitation, we introduce
Template-based Data Generation (TDG), a novel approach that leverages LLMs
(GPT-4) to automatically generate parameterized meta-templates, which are then
used to synthesize a vast array of high-quality problems and solutions.
Leveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset
comprising over 7 million synthetically generated grade school math
problems--each accompanied by code-based and natural language solutions--with
the potential to generate an effectively unlimited number more. This dataset
alleviates the scarcity of large-scale mathematical datasets and serves as a
valuable resource for pre-training, fine-tuning, and evaluating LLMs in
mathematical reasoning. Our method not only enables the generation of virtually
infinite data but also elevates data augmentation to a new level by using GPT-4
for meta-template generation, ensuring diverse and high-quality problem
structures. The TemplateMath Part I: TemplateGSM dataset is publicly available
at https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available
at https://github.com/iiis-ai/TemplateMath.

摘要：大型語言模型（LLM）的快速進展，例如 GPT-3、PaLM 和 Llama，已經顯著地轉變了自然語言處理，展示了在理解和生成語言方面的非凡能力。然而，這些模型通常難以處理需要複雜推理的任務，特別是在數學問題解決方面，部分原因是缺乏訓練精密的推理能力所需的大規模、高品質、特定領域的資料集。為了解決這個限制，我們引入了基於範本的資料生成（TDG），一種利用 LLM（GPT-4）自動生成參數化元範本的新方法，然後使用這些範本合成大量的優質問題和解決方案。利用 TDG，我們創建了 TemplateMath 第 1 部分：TemplateGSM，一個包含超過 700 萬個合成生成的小學數學問題的資料集，每個問題都附有基於程式碼和自然語言的解決方案，並有可能產生更多有效無限的數字。這個資料集緩解了大規模數學資料集的稀缺性，並作為一個有價值的資源，用於數學推理中的 LLM 的預訓練、微調和評估。我們的模型不僅能夠生成幾乎無限的資料，還通過使用 GPT-4 進行元範本生成將資料擴充提升到一個新的層次，確保問題結構的多樣性和高品質。TemplateMath 第 1 部分：TemplateGSM 資料集可在 https://huggingface.co/datasets/math-ai/TemplateGSM 公開獲得。程式碼可在 https://github.com/iiis-ai/TemplateMath 獲得。

##### **Fine-Tuning Small Embeddings for Elevated Performance**
2411.18099v1 by Biraj Silwal

Contextual Embeddings have yielded state-of-the-art results in various
natural language processing tasks. However, these embeddings are constrained by
models requiring large amounts of data and huge computing power. This is an
issue for low-resource languages like Nepali as the amount of data available
over the internet is not always sufficient for the models. This work has taken
an incomplete BERT model with six attention heads pretrained on Nepali language
and finetuned it on previously unseen data. The obtained results from intrinsic
and extrinsic evaluations have been compared to the results drawn from the
original model baseline and a complete BERT model pretrained on Nepali language
as the oracle. The results demonstrate that even though the oracle is better on
average, finetuning the small embeddings drastically improves results compared
to the original baseline.

摘要：語境嵌入在各種自然語言處理任務中產生了最先進的結果。然而，這些嵌入受到需要大量數據和巨大運算能力的模型的限制。對於尼泊爾語等低資源語言來說，這是一個問題，因為網路上可用的數據量並不總是足以應付這些模型。這項工作採用了一個不完整的 BERT 模型，在尼泊爾語上預訓練了六個注意力頭，並在以前未見過的數據上對其進行微調。從內在和外在評估中獲得的結果已與從原始模型基準和在尼泊爾語上預訓練的完整 BERT 模型（作為神諭）中得出的結果進行了比較。結果表明，儘管神諭平均而言較好，但與原始基準相比，微調小嵌入會大幅改善結果。

##### **From Exploration to Revelation: Detecting Dark Patterns in Mobile Apps**
2411.18084v1 by Jieshan Chen, Zhen Wang, Jiamou Sun, Wenbo Zou, Zhenchang Xing, Qinghua Lu, Qing Huang, Xiwei Xu

Mobile apps are essential in daily life, yet they often employ dark patterns,
such as visual tricks to highlight certain options or linguistic tactics to nag
users into making purchases, to manipulate user behavior. Current research
mainly uses manual methods to detect dark patterns, a process that is
time-consuming and struggles to keep pace with continually updating and
emerging apps. While some studies targeted at automated detection, they are
constrained to static patterns and still necessitate manual app exploration. To
bridge these gaps, we present AppRay, an innovative system that seamlessly
blends task-oriented app exploration with automated dark pattern detection,
reducing manual efforts. Our approach consists of two steps: First, we harness
the commonsense knowledge of large language models for targeted app
exploration, supplemented by traditional random exploration to capture a
broader range of UI states. Second, we developed a static and dynamic dark
pattern detector powered by a contrastive learning-based multi-label classifier
and a rule-based refiner to perform detection. We contributed two datasets,
AppRay-Dark and AppRay-Light, with 2,185 unique deceptive patterns (including
149 dynamic instances) across 18 types from 876 UIs and 871 benign UIs. These
datasets cover both static and dynamic dark patterns while preserving UI
relationships. Experimental results confirm that AppRay can efficiently explore
the app and identify a wide range of dark patterns with great performance.

摘要：行動應用程式在日常生活中不可或缺，但它們經常使用黑模式，例如視覺技巧來突顯特定選項或語言策略來催促用戶進行購買，以操縱用戶行為。目前的研究所主要使用手動方法來偵測黑模式，這個過程非常耗時，而且難以跟上持續更新和新興的應用程式。雖然有些研究針對自動化偵測，但它們受到靜態模式的限制，而且仍然需要手動應用程式探索。為了彌補這些差距，我們提出 AppRay，一個創新的系統，它將以任務為導向的應用程式探索與自動化黑模式偵測無縫結合，減少手動工作。我們的做法包含兩個步驟：首先，我們利用大型語言模型的常識知識進行目標應用程式探索，並輔以傳統的隨機探索，以擷取更廣泛的 UI 狀態。其次，我們開發了一個靜態和動態的黑模式偵測器，由對比學習的多標籤分類器和基於規則的精煉器提供支援，以執行偵測。我們貢獻了兩個資料集，AppRay-Dark 和 AppRay-Light，其中包含 876 個 UI 和 871 個良性 UI 中 18 種類型的 2,185 個獨特的欺騙模式（包括 149 個動態實例）。這些資料集涵蓋靜態和動態黑模式，同時保留 UI 關係。實驗結果證實，AppRay 可以有效地探索應用程式，並以極佳的效能識別各種黑模式。

##### **Pushing the Limits of LLM Inference via 2-Bit Layer-Discriminative KV Cache**
2411.18077v1 by Akshat Sharma, Hangliang Ding, Jianping Li, Neel Dani, Minjia Zhang

How to efficiently serve LLMs in practice has become exceptionally
challenging due to their prohibitive memory and computation requirements. In
this study, we investigate optimizing the KV cache, whose memory footprint
poses a critical bottleneck in LLM inference, especially when dealing with long
context tasks. To tackle the challenge, we introduce MiniKV, a KV cache
optimization method that simultaneously preserves long context task accuracy
while significantly reducing KV cache size via a novel 2-bit
layer-discriminative KV cache. More importantly, we develop specialized CUDA
kernels to make MiniKV compatible with FlashAttention. Experiments on a wide
range of long context tasks show that MiniKV effectively achieves 86% KV cache
compression ratio while recovering over 98.5% of accuracy, outperforming
state-of-the-art methods while achieving excellent measured system performance
improvements.

摘要：在實務中如何有效地提供 LLM 服務已變得極具挑戰性，因為它們具有高昂的記憶體和運算需求。在本研究中，我們探討最佳化 KV 快取，其記憶體使用量在 LLM 推論中構成一個關鍵瓶頸，特別是在處理長脈絡任務時。為了應對這項挑戰，我們引入了 MiniKV，一種 KV 快取最佳化方法，它同時保留了長脈絡任務的準確性，並透過一種新穎的 2 位元層辨別式 KV 快取大幅減少 KV 快取大小。更重要的是，我們開發了專門的 CUDA 核心，使 MiniKV 與 FlashAttention 相容。在各種長脈絡任務上進行的實驗顯示，MiniKV 有效地達到了 86% 的 KV 快取壓縮比，同時恢復了超過 98.5% 的準確性，優於最先進的方法，同時實現了出色的測量系統效能改善。

##### **Simulating Tabular Datasets through LLMs to Rapidly Explore Hypotheses about Real-World Entities**
2411.18071v1 by Miguel Zabaleta, Joel Lehman

Do horror writers have worse childhoods than other writers? Though
biographical details are known about many writers, quantitatively exploring
such a qualitative hypothesis requires significant human effort, e.g. to sift
through many biographies and interviews of writers and to iteratively search
for quantitative features that reflect what is qualitatively of interest. This
paper explores the potential to quickly prototype these kinds of hypotheses
through (1) applying LLMs to estimate properties of concrete entities like
specific people, companies, books, kinds of animals, and countries; (2)
performing off-the-shelf analysis methods to reveal possible relationships
among such properties (e.g. linear regression); and towards further automation,
(3) applying LLMs to suggest the quantitative properties themselves that could
help ground a particular qualitative hypothesis (e.g. number of adverse
childhood events, in the context of the running example). The hope is to allow
sifting through hypotheses more quickly through collaboration between human and
machine. Our experiments highlight that indeed, LLMs can serve as useful
estimators of tabular data about specific entities across a range of domains,
and that such estimations improve with model scale. Further, initial
experiments demonstrate the potential of LLMs to map a qualitative hypothesis
of interest to relevant concrete variables that the LLM can then estimate. The
conclusion is that LLMs offer intriguing potential to help illuminate
scientifically interesting patterns latent within the internet-scale data they
are trained upon.

摘要：恐怖小說作家比其他作家有更糟糕的童年嗎？儘管許多作家的傳記細節都是已知的，但要量化探討這種定性的假設需要大量的人力，例如篩選許多作家的傳記和訪談，並反覆搜尋反映定性興趣的量化特徵。本文探討了透過以下方式快速建立這些假設的原型：(1) 應用 LLM 來估計具體實體（如特定人物、公司、書籍、動物種類和國家）的屬性；(2) 執行現成的分析方法來揭示此類屬性之間可能的關係（例如線性回歸）；以及朝向進一步自動化，(3) 應用 LLM 來建議量化屬性本身，這有助於建立特定的定性假設（例如在執行範例的背景下，不利的童年事件的數量）。希望透過人機協作更快速地篩選假設。我們的實驗強調，事實上，LLM 可以作為跨領域特定實體的表格資料的有用估計器，而且此類估計會隨著模型規模而改善。此外，初步實驗證明了 LLM 將定性的假設興趣對應到 LLM 然後可以估計的相關具體變數的潛力。結論是，LLM 提供了有趣的潛力，有助於闡明訓練他們時潛藏在網際網路規模資料中的科學有趣模式。

##### **PersonaCraft: Personalized Full-Body Image Synthesis for Multiple Identities from Single References Using 3D-Model-Conditioned Diffusion**
2411.18068v1 by Gwanghyun Kim, Suh Yoon Jeon, Seunggyu Lee, Se Young Chun

Personalized image generation has been significantly advanced, enabling the
creation of highly realistic and customized images. However, existing methods
often struggle with generating images of multiple people due to occlusions and
fail to accurately personalize full-body shapes. In this paper, we propose
PersonaCraft, a novel approach that combines diffusion models with 3D human
modeling to address these limitations. Our method effectively manages
occlusions by incorporating 3D-aware pose conditioning with SMPLx-ControlNet
and accurately personalizes human full-body shapes through SMPLx fitting.
Additionally, PersonaCraft enables user-defined body shape adjustments, adding
flexibility for individual body customization. Experimental results demonstrate
the superior performance of PersonaCraft in generating high-quality, realistic
images of multiple individuals while resolving occlusion issues, thus
establishing a new standard for multi-person personalized image synthesis.
Project page: https://gwang-kim.github.io/persona_craft

摘要：個人化影像生成技術已大幅進步，能產生高度逼真且客製化的影像。然而，現有方法往往會因為遮擋而難以產生多人的影像，且無法準確個人化全身形狀。本篇論文提出 PersonaCraft，這是一種結合擴散模型與 3D 人體建模的新穎方法，以解決這些限制。我們的技術透過結合 SMPLx-ControlNet 的 3D 感知姿勢調整，有效處理遮擋問題，並透過 SMPLx 擬合準確個人化人類全身形狀。此外，PersonaCraft 能讓使用者自訂身體形狀調整，增加個人身體客製化的彈性。實驗結果證明 PersonaCraft 在產生多人的高品質、逼真影像方面表現優異，同時解決遮擋問題，因此為多人個人化影像合成建立了新標準。
專案頁面：https://gwang-kim.github.io/persona_craft

##### **Heterogeneous Relationships of Subjects and Shapelets for Semi-supervised Multivariate Series Classification**
2411.18043v1 by Mingsen Du, Meng Chen, Yongjian Li, Cun Ji, Shoushui Wei

Multivariate time series (MTS) classification is widely applied in fields
such as industry, healthcare, and finance, aiming to extract key features from
complex time series data for accurate decision-making and prediction. However,
existing methods for MTS often struggle due to the challenges of effectively
modeling high-dimensional data and the lack of labeled data, resulting in poor
classification performance. To address this issue, we propose a heterogeneous
relationships of subjects and shapelets method for semi-supervised MTS
classification. This method offers a novel perspective by integrating various
types of additional information while capturing the relationships between them.
Specifically, we first utilize a contrast temporal self-attention module to
obtain sparse MTS representations, and then model the similarities between
these representations using soft dynamic time warping to construct a similarity
graph. Secondly, we learn the shapelets for different subject types,
incorporating both the subject features and their shapelets as additional
information to further refine the similarity graph, ultimately generating a
heterogeneous graph. Finally, we use a dual level graph attention network to
get prediction. Through this method, we successfully transform dataset into a
heterogeneous graph, integrating multiple additional information and achieving
precise semi-supervised node classification. Experiments on the Human Activity
Recognition, sleep stage classification and University of East Anglia datasets
demonstrate that our method outperforms current state-of-the-art methods in MTS
classification tasks, validating its superiority.

摘要：多變量時間序列 (MTS) 分類廣泛應用於產業、醫療保健和金融等領域，旨在從複雜的時間序列資料中提取關鍵特徵，以進行準確的決策制定和預測。然而，現有的 MTS 方法通常會因有效建模高維度資料和標籤資料不足的挑戰而面臨困難，導致分類效能不佳。為了解決這個問題，我們提出了一種針對半監督 MTS 分類的主體和形狀異質關係方法。此方法透過整合各種額外的資訊並擷取它們之間的關係，提供了新穎的觀點。具體來說，我們首先利用對比時間自我注意模組來取得稀疏 MTS 表示，然後使用軟動態時間扭曲來對這些表示之間的相似性進行建模，以建構相似性圖。其次，我們學習不同主體類型的形狀，將主體特徵和它們的形狀作為額外資訊納入，以進一步精煉相似性圖，最終產生異質圖。最後，我們使用雙層級圖注意力網路來取得預測。透過此方法，我們成功地將資料集轉換成異質圖，整合多種額外資訊並達成精確的半監督節點分類。在人類活動辨識、睡眠階段分類和東安格利亞大學資料集上的實驗證明，我們的方法優於 MTS 分類任務中現行的最先進方法，驗證了它的優越性。

##### **VLM-HOI: Vision Language Models for Interpretable Human-Object Interaction Analysis**
2411.18038v1 by Donggoo Kang, Dasol Jeong, Hyunmin Lee, Sangwoo Park, Hasil Park, Sunkyu Kwon, Yeongjoon Kim, Joonki Paik

The Large Vision Language Model (VLM) has recently addressed remarkable
progress in bridging two fundamental modalities. VLM, trained by a sufficiently
large dataset, exhibits a comprehensive understanding of both visual and
linguistic to perform diverse tasks. To distill this knowledge accurately, in
this paper, we introduce a novel approach that explicitly utilizes VLM as an
objective function form for the Human-Object Interaction (HOI) detection task
(\textbf{VLM-HOI}). Specifically, we propose a method that quantifies the
similarity of the predicted HOI triplet using the Image-Text matching
technique. We represent HOI triplets linguistically to fully utilize the
language comprehension of VLMs, which are more suitable than CLIP models due to
their localization and object-centric nature. This matching score is used as an
objective for contrastive optimization. To our knowledge, this is the first
utilization of VLM language abilities for HOI detection. Experiments
demonstrate the effectiveness of our method, achieving state-of-the-art HOI
detection accuracy on benchmarks. We believe integrating VLMs into HOI
detection represents important progress towards more advanced and interpretable
analysis of human-object interactions.

摘要：大型视觉语言模型 (VLM) 最近在桥接两种基本模态方面取得了显着进展。由足够大的数据集训练的 VLM，展示了对视觉和语言的全面理解，以执行各种任务。为了准确地提炼出这种知识，在本文中，我们引入了一种新颖的方法，该方法明确地将 VLM 用作人类-物体交互 (HOI) 检测任务的目标函数形式（VLM-HOI）。具体来说，我们提出了一种使用图像-文本匹配技术量化预测的 HOI 三元组相似性的方法。我们用语言表示 HOI 三元组，以充分利用 VLM 的语言理解能力，由于其定位和以对象为中心的特点，比 CLIP 模型更合适。这个匹配分数被用作对比优化目标。据我们所知，这是首次将 VLM 语言能力用于 HOI 检测。实验表明了我们方法的有效性，在基准测试中实现了最先进的 HOI 检测准确度。我们相信将 VLM 集成到 HOI 检测中代表了朝向更高级和更可解释的人类-物体交互分析的重要进步。

##### **Can bidirectional encoder become the ultimate winner for downstream applications of foundation models?**
2411.18021v1 by Lewen Yang, Xuanyu Zhou, Juao Fan, Xinyi Xie, Shengxin Zhu

Over the past few decades, Artificial Intelligence(AI) has progressed from
the initial machine learning stage to the deep learning stage, and now to the
stage of foundational models. Foundational models have the characteristics of
pre-training, transfer learning, and self-supervised learning, and pre-trained
models can be fine-tuned and applied to various downstream tasks. Under the
framework of foundational models, models such as Bidirectional Encoder
Representations from Transformers(BERT) and Generative Pre-trained
Transformer(GPT) have greatly advanced the development of natural language
processing(NLP), especially the emergence of many models based on BERT. BERT
broke through the limitation of only using one-way methods for language
modeling in pre-training by using a masked language model. It can capture
bidirectional context information to predict the masked words in the sequence,
this can improve the feature extraction ability of the model. This makes the
model very useful for downstream tasks, especially for specialized
applications. The model using the bidirectional encoder can better understand
the domain knowledge and be better applied to these downstream tasks. So we
hope to help understand how this technology has evolved and improved model
performance in various natural language processing tasks under the background
of foundational models and reveal its importance in capturing context
information and improving the model's performance on downstream tasks. This
article analyzes one-way and bidirectional models based on GPT and BERT and
compares their differences based on the purpose of the model. It also briefly
analyzes BERT and the improvements of some models based on BERT. The model's
performance on the Stanford Question Answering Dataset(SQuAD) and General
Language Understanding Evaluation(GLUE) was compared.

摘要：<paragraph>在過去的幾十年中，人工智慧 (AI) 已從最初的機器學習階段進步到深度學習階段，現在進入了基礎模型階段。基礎模型具有預訓練、遷移學習和自監督學習的特徵，並且預訓練模型可以微調並應用於各種下游任務。在基礎模型的框架下，例如 Transformer 的雙向編碼器表示 (BERT) 和生成式預訓練 Transformer (GPT) 等模型已經極大地推動了自然語言處理 (NLP) 的發展，尤其是基於 BERT 的許多模型的出現。BERT 透過使用遮罩語言模型突破了在預訓練中僅使用單向方法進行語言建模的限制。它可以擷取雙向上下文資訊來預測序列中的遮罩字詞，這可以提升模型的特徵提取能力。這使得該模型對於下游任務非常有用，特別是對於專業應用。使用雙向編碼器的模型可以更好地理解領域知識，並更好地應用於這些下游任務。因此，我們希望協助了解在基礎模型的背景下，這項技術如何在各種自然語言處理任務中演進並提升模型效能，並揭示其在擷取上下文資訊和提升模型在下游任務中的效能的重要性。本文基於 GPT 和 BERT 分析單向和雙向模型，並根據模型的目的比較它們的差異。它也簡要分析 BERT 和一些基於 BERT 的模型的改進。比較了該模型在史丹佛問答資料集 (SQuAD) 和通用語言理解評估 (GLUE) 上的效能。</paragraph>

##### **JPPO: Joint Power and Prompt Optimization for Accelerated Large Language Model Services**
2411.18010v1 by Feiran You, Hongyang Du, Kaibin Huang, Abbas Jamalipour

Large Language Models (LLMs) have demonstrated remarkable capabilities in
various tasks, leading to their increasing deployment in wireless networks for
a wide variety of user services. However, the growing longer prompt setting
highlights the crucial issue of computational resource demands and huge
communication load. To address this challenge, we propose Joint Power and
Prompt Optimization (JPPO), a framework that combines Small Language Model
(SLM)-based prompt compression with wireless power allocation optimization. By
deploying SLM at user devices for prompt compression and employing Deep
Reinforcement Learning for joint optimization of compression ratio and
transmission power, JPPO effectively balances service quality with resource
efficiency. Experimental results demonstrate that our framework achieves high
service fidelity and low bit error rates while optimizing power usage in
wireless LLM services. The system reduces response time by about 17%, with the
improvement varying based on the length of the original prompt.

摘要：大型語言模型 (LLM) 在各種任務中展現出非凡的能力，促使它們在無線網路中廣泛部署，以提供各式各樣的使用者服務。然而，越來越長的提示設定突顯出計算資源需求和龐大通訊負載的關鍵問題。為了應對這項挑戰，我們提出聯合功率和提示最佳化 (JPPO)，一個結合基於小型語言模型 (SLM) 的提示壓縮與無線功率分配最佳化的架構。透過在使用者裝置上部署 SLM 以進行提示壓縮，並採用深度強化學習來聯合最佳化壓縮比和傳輸功率，JPPO 有效地在服務品質和資源效率之間取得平衡。實驗結果證明，我們的架構在最佳化無線 LLM 服務中的功率使用時，能達成高服務保真度和低位元錯誤率。該系統將回應時間縮短了約 17%，而改善幅度會根據原始提示的長度而有所不同。

##### **Causal and Local Correlations Based Network for Multivariate Time Series Classification**
2411.18008v1 by Mingsen Du, Yanxuan Wei, Xiangwei Zheng, Cun Ji

Recently, time series classification has attracted the attention of a large
number of researchers, and hundreds of methods have been proposed. However,
these methods often ignore the spatial correlations among dimensions and the
local correlations among features. To address this issue, the causal and local
correlations based network (CaLoNet) is proposed in this study for multivariate
time series classification. First, pairwise spatial correlations between
dimensions are modeled using causality modeling to obtain the graph structure.
Then, a relationship extraction network is used to fuse local correlations to
obtain long-term dependency features. Finally, the graph structure and
long-term dependency features are integrated into the graph neural network.
Experiments on the UEA datasets show that CaLoNet can obtain competitive
performance compared with state-of-the-art methods.

摘要：時序分類最近引起了許多研究者的關注，並提出了數百種方法。然而，這些方法通常忽略維度之間的空間關聯性和特徵之間的局部關聯性。為了解決這個問題，本研究提出了一個基於因果和局部關聯性的網路 (CaLoNet) 來進行多變量時序分類。首先，使用因果模型對維度之間的成對空間關聯性進行建模，以獲得圖形結構。然後，使用關係提取網路融合局部關聯性，以獲得長期依賴性特徵。最後，將圖形結構和長期依賴性特徵整合到圖形神經網路中。在 UEA 資料集上的實驗表明，與最先進的方法相比，CaLoNet 可以獲得具有競爭力的效能。

##### **HAAT: Hybrid Attention Aggregation Transformer for Image Super-Resolution**
2411.18003v1 by Song-Jiang Lai, Tsun-Hin Cheung, Ka-Chun Fung, Kai-wen Xue, Kin-Man Lama

In the research area of image super-resolution, Swin-transformer-based models
are favored for their global spatial modeling and shifting window attention
mechanism. However, existing methods often limit self-attention to non
overlapping windows to cut costs and ignore the useful information that exists
across channels. To address this issue, this paper introduces a novel model,
the Hybrid Attention Aggregation Transformer (HAAT), designed to better
leverage feature information. HAAT is constructed by integrating
Swin-Dense-Residual-Connected Blocks (SDRCB) with Hybrid Grid Attention Blocks
(HGAB). SDRCB expands the receptive field while maintaining a streamlined
architecture, resulting in enhanced performance. HGAB incorporates channel
attention, sparse attention, and window attention to improve nonlocal feature
fusion and achieve more visually compelling results. Experimental evaluations
demonstrate that HAAT surpasses state-of-the-art methods on benchmark datasets.
  Keywords: Image super-resolution, Computer vision, Attention mechanism,
Transformer

摘要：在图像超分辨率的研究领域，基于 Swin-transformer 的模型因其全局空间建模和移窗注意力机制而受到青睐。然而，现有方法通常将自注意力限制在非重叠窗口以降低成本，并忽略跨通道存在的有用信息。为了解决这个问题，本文介绍了一种新颖的模型，即混合注意力聚合变换器 (HAAT)，旨在更好地利用特征信息。HAAT 是通过将 Swin-Dense-Residual-Connected Blocks (SDRCB) 与混合网格注意力块 (HGAB) 集成构建的。SDRCB 在保持流线型架构的同时扩展感受野，从而提高性能。HGAB 结合了通道注意力、稀疏注意力和窗口注意力，以改进非局部特征融合并实现更具视觉吸引力的结果。实验评估表明，HAAT 在基准数据集上超越了最先进的方法。
关键字：图像超分辨率、计算机视觉、注意力机制、Transformer

##### **An End-to-End Two-Stream Network Based on RGB Flow and Representation Flow for Human Action Recognition**
2411.18002v1 by Song-Jiang Lai, Tsun-Hin Cheung, Ka-Chun Fung, Tian-Shan Liu, Kin-Man Lam

With the rapid advancements in deep learning, computer vision tasks have seen
significant improvements, making two-stream neural networks a popular focus for
video based action recognition. Traditional models using RGB and optical flow
streams achieve strong performance but at a high computational cost. To address
this, we introduce a representation flow algorithm to replace the optical flow
branch in the egocentric action recognition model, enabling end-to-end training
while reducing computational cost and prediction time. Our model, designed for
egocentric action recognition, uses class activation maps (CAMs) to improve
accuracy and ConvLSTM for spatio temporal encoding with spatial attention. When
evaluated on the GTEA61, EGTEA GAZE+, and HMDB datasets, our model matches the
accuracy of the original model on GTEA61 and exceeds it by 0.65% and 0.84% on
EGTEA GAZE+ and HMDB, respectively. Prediction runtimes are significantly
reduced to 0.1881s, 0.1503s, and 0.1459s, compared to the original model's
101.6795s, 25.3799s, and 203.9958s. Ablation studies were also conducted to
study the impact of different parameters on model performance.
  Keywords: two-stream, egocentric, action recognition, CAM, representation
flow, CAM, ConvLSTM

摘要：<paragraph>隨著深度學習的快速進展，電腦視覺任務已見顯著進步，使雙流神經網路成為基於影片動作辨識的熱門焦點。使用 RGB 和光流串流的傳統模型可達成強勁的效能，但計算成本高昂。為了解決此問題，我們引入表示流演算法來取代自我中心動作辨識模型中的光流分支，同時降低計算成本和預測時間，實現端到端訓練。我們的模型專為自我中心動作辨識而設計，使用類別激活圖 (CAM) 來提高準確度，並使用 ConvLSTM 進行時空編碼，並具備空間注意力。在 GTEA61、EGTEA GAZE+ 和 HMDB 資料集上進行評估時，我們的模型在 GTEA61 上與原始模型的準確度相符，而在 EGTEA GAZE+ 和 HMDB 上分別超過了 0.65% 和 0.84%。與原始模型的 101.6795 秒、25.3799 秒和 203.9958 秒相比，預測執行時間顯著降低至 0.1881 秒、0.1503 秒和 0.1459 秒。還進行了消融研究，以研究不同參數對模型效能的影響。
關鍵字：雙流、自我中心、動作辨識、CAM、表示流、CAM、ConvLSTM</paragraph>

##### **DRS: Deep Question Reformulation With Structured Output**
2411.17993v1 by Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Nanyun Peng, Kai-Wei Chang

Question answering is a fundamental capability of large language models
(LLMs). However, when people encounter completely new knowledge texts, they
often ask questions that the text cannot answer due to a lack of understanding
of the knowledge. Recent research shows that large language models identify the
unanswerability of questions, but they lack the ability to help people
reformulate their questions. Even powerful models like GPT-3.5 perform poorly
in this regard. To enhance the ability of LLMs to assist humans in
reformulating questions to extract relevant knowledge from new documents, we
propose a zero-shot method called DRS: Deep Question Reformulation With
Structured Output. Our proposed method leverages large language models and the
DFS-based algorithm to iteratively search for possible entity combinations and
constrain the output with certain entities, effectively improving the
capabilities of large language models in this area. Extensive experimental
results show that our zero-shot DRS method significantly improves the
reformulation accuracy of GPT-3.5 from 23.03% to 70.42% and effectively
improves the score of open-source large language models, such as Gemma2-9B,
from 26.35% to 56.75%.

摘要：問答是大型語言模型 (LLM) 的基本能力。然而，當人們遇到全新的知識文本時，他們經常會提出文本無法回答的問題，因為他們對知識理解不足。最近的研究表明，大型語言模型可以辨識問題的不可回答性，但它們缺乏幫助人們重新表述問題的能力。即使是像 GPT-3.5 這樣強大的模型在這方面表現也不佳。為了增強 LLM 協助人類重新表述問題以從新文件中提取相關知識的能力，我們提出了一種稱為 DRS 的零次學習方法：具有結構化輸出的深度問題重新表述。我們提出的方法利用大型語言模型和基於 DFS 的演算法，反覆搜尋可能的實體組合，並以特定實體約束輸出，有效提升大型語言模型在這方面的能力。廣泛的實驗結果表明，我們的零次學習 DRS 方法將 GPT-3.5 的重新表述準確度從 23.03% 大幅提升至 70.42%，並有效提升開源大型語言模型（例如 Gemma2-9B）的分數，從 26.35% 提升至 56.75%。

##### **New Faithfulness-Centric Interpretability Paradigms for Natural Language Processing**
2411.17992v1 by Andreas Madsen

As machine learning becomes more widespread and is used in more critical
applications, it's important to provide explanations for these models, to
prevent unintended behavior. Unfortunately, many current interpretability
methods struggle with faithfulness. Therefore, this Ph.D. thesis investigates
the question "How to provide and ensure faithful explanations for complex
general-purpose neural NLP models?" The main thesis is that we should develop
new paradigms in interpretability. This is achieved by first developing solid
faithfulness metrics and then applying the lessons learned from this
investigation to develop new paradigms. The two new paradigms explored are
faithfulness measurable models (FMMs) and self-explanations. The idea in
self-explanations is to have large language models explain themselves, we
identify that current models are not capable of doing this consistently.
However, we suggest how this could be achieved. The idea of FMMs is to create
models that are designed such that measuring faithfulness is cheap and precise.
This makes it possible to optimize an explanation towards maximum faithfulness,
which makes FMMs designed to be explained. We find that FMMs yield explanations
that are near theoretical optimal in terms of faithfulness. Overall, from all
investigations of faithfulness, results show that post-hoc and intrinsic
explanations are by default model and task-dependent. However, this was not the
case when using FMMs, even with the same post-hoc explanation methods. This
shows, that even simple modifications to the model, such as randomly masking
the training dataset, as was done in FMMs, can drastically change the situation
and result in consistently faithful explanations. This answers the question of
how to provide and ensure faithful explanations.

摘要：隨著機器學習變得越來越普遍，並用於更多關鍵應用程式中，為這些模型提供解釋以防止意外行為非常重要。不幸的是，許多當前的可解釋性方法都難以保持忠實度。因此，本博士論文探討了「如何為複雜的通用神經自然語言處理模型提供並確保忠實的解釋？」這個問題。論文的主旨是，我們應該在可解釋性中開發新的範例。這首先透過開發穩固的忠實度指標來達成，然後將從這項調查中學到的教訓應用到開發新的範例。所探討的兩個新範例是可測量忠實度模型 (FMM) 和自解釋。自解釋的構想是讓大型語言模型自行解釋，我們發現當前模型無法持續做到這件事。然而，我們建議可以如何達成這件事。FMM 的構想是建立模型，其設計讓測量忠實度變得便宜又精確。這讓最佳化解釋以達到最大忠實度成為可能，而這讓 FMM 被設計成可以被解釋。我們發現 FMM 產生的解釋在忠實度方面接近理論最佳值。總體而言，從所有忠實度調查來看，結果顯示事後和內在解釋在預設上取決於模型和任務。然而，在使用 FMM 時並非如此，即使使用相同的事後解釋方法也是如此。這顯示，即使對模型進行簡單的修改，例如隨機遮罩訓練資料集（如同在 FMM 中所做），也可以大幅改變情況並產生始終如一的忠實解釋。這回答了如何提供並確保忠實解釋的問題。

##### **VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video Comprehension with Video-Text Duet Interaction Format**
2411.17991v1 by Yueqian Wang, Xiaojun Meng, Yuxuan Wang, Jianxin Liang, Jiansheng Wei, Huishuai Zhang, Dongyan Zhao

Recent researches on video large language models (VideoLLM) predominantly
focus on model architectures and training datasets, leaving the interaction
format between the user and the model under-explored. In existing works, users
often interact with VideoLLMs by using the entire video and a query as input,
after which the model generates a response. This interaction format constrains
the application of VideoLLMs in scenarios such as live-streaming comprehension
where videos do not end and responses are required in a real-time manner, and
also results in unsatisfactory performance on time-sensitive tasks that
requires localizing video segments. In this paper, we focus on a video-text
duet interaction format. This interaction format is characterized by the
continuous playback of the video, and both the user and the model can insert
their text messages at any position during the video playback. When a text
message ends, the video continues to play, akin to the alternative of two
performers in a duet. We construct MMDuetIT, a video-text training dataset
designed to adapt VideoLLMs to video-text duet interaction format. We also
introduce the Multi-Answer Grounded Video Question Answering (MAGQA) task to
benchmark the real-time response ability of VideoLLMs. Trained on MMDuetIT,
MMDuet demonstrates that adopting the video-text duet interaction format
enables the model to achieve significant improvements in various time-sensitive
tasks (76% CIDEr on YouCook2 dense video captioning, 90\% mAP on QVHighlights
highlight detection and 25% R@0.5 on Charades-STA temporal video grounding)
with minimal training efforts, and also enable VideoLLMs to reply in a
real-time manner as the video plays. Code, data and demo are available at:
https://github.com/yellow-binary-tree/MMDuet.

摘要：近期的影片大型语言模型 (VideoLLM) 研究主要集中于模型架构和训练数据集，而使用者与模型之间的互动方式则较少被探讨。在现有的作品中，使用者通常使用整个影片和查询作为输入，与 VideoLLM 互动，然后模型会产生回应。这种互动方式限制了 VideoLLM 在影片不断播放且需要实时回应的场景（例如直播理解）中的应用，并且在需要定位影片片段的时间敏感任务中也会导致表现不佳。在本文中，我们专注于影片文字二重唱互动方式。这种互动方式的特点是影片持续播放，使用者和模型都可以随时在影片播放期间插入他们的文字讯息。当文字讯息结束时，影片继续播放，类似于二重唱中两位表演者的交替。我们构建了 MMDuetIT，这是一个影片文字训练数据集，旨在让 VideoLLM 适应影片文字二重唱互动方式。我们还引入了多重答案基础影片问答 (MAGQA) 任务，以比较 VideoLLM 的实时回应能力。在 MMDuetIT 上训练后，MMDuet 证明采用影片文字二重唱互动方式能使模型在各种时间敏感任务中实现显著的改进（YouCook2 稠密影片字幕的 76% CIDEr、QVHighlights 重点检测的 90% mAP 和 Charades-STA 时间影片基础的 25% R@0.5），且训练工作量极小，还能让 VideoLLM 在影片播放时实时回应。代码、资料和示范可于此处取得：https://github.com/yellow-binary-tree/MMDuet。

##### **Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**
2411.17989v1 by Xiaoxuan Li, Yao Liu, Ruoyu Wang, Lina Yao

As the significance of understanding the cause-and-effect relationships among
variables increases in the development of modern systems and algorithms,
learning causality from observational data has become a preferred and efficient
approach over conducting randomized control trials. However, purely
observational data could be insufficient to reconstruct the true causal graph.
Consequently, many researchers tried to utilise some form of prior knowledge to
improve causal discovery process. In this context, the impressive capabilities
of large language models (LLMs) have emerged as a promising alternative to the
costly acquisition of prior expert knowledge. In this work, we further explore
the potential of using LLMs to enhance causal discovery approaches,
particularly focusing on score-based methods, and we propose a general
framework to utilise the capacity of not only one but multiple LLMs to augment
the discovery process.

摘要：隨著理解現代系統和演算法中變數之間的因果關係的重要性日益增加，從觀測資料中學習因果關係已成為一種比進行隨機對照試驗更受青睞且更有效率的方法。然而，純粹的觀測資料可能不足以重建真正的因果圖。因此，許多研究人員嘗試利用某種形式的先驗知識來改善因果發現過程。在此背景下，大型語言模型 (LLM) 的強大功能已成為昂貴的先驗專家知識獲取的替代方案。在這項工作中，我們進一步探討了使用 LLM 來增強因果發現方法的可能性，特別關注基於評分的模型，並且我們提出了一個通用框架，不僅可以利用一個 LLM，還可以利用多個 LLM 來擴充發現過程。

##### **Optimized Conformal Selection: Powerful Selective Inference After Conformity Score Optimization**
2411.17983v1 by Tian Bai, Ying Jin

Model selection/optimization in conformal inference is challenging, since it
may break the exchangeability between labeled and unlabeled data. We study this
problem in the context of conformal selection, which uses conformal p-values to
select ``interesting'' instances with large unobserved labels from a pool of
unlabeled data, while controlling the FDR in finite sample. For validity,
existing solutions require the model choice to be independent of the data used
to construct the p-values and calibrate the selection set. However, when
presented with many model choices and limited labeled data, it is desirable to
(i) select the best model in a data-driven manner, and (ii) mitigate power loss
due to sample splitting.
  This paper presents OptCS, a general framework that allows valid statistical
testing (selection) after flexible data-driven model optimization. We introduce
general conditions under which OptCS constructs valid conformal p-values
despite substantial data reuse and handles complex p-value dependencies to
maintain finite-sample FDR control via a novel multiple testing procedure. We
instantiate this general recipe to propose three FDR-controlling procedures,
each optimizing the models differently: (i) selecting the most powerful one
among multiple pre-trained candidate models, (ii) using all data for model
fitting without sample splitting, and (iii) combining full-sample model fitting
and selection. We demonstrate the efficacy of our methods via simulation
studies and real applications in drug discovery and alignment of large language
models in radiology report generation.

摘要：模型選擇/最佳化在共形推論中具有挑戰性，因為它可能會打破標籤和未標籤資料之間的可交換性。我們在共形選擇的背景下研究這個問題，共形選擇使用共形 p 值從未標籤資料池中選擇具有較大未觀察標籤的「有趣」實例，同時控制有限樣本中的 FDR。為了有效性，現有的解決方案要求模型選擇獨立於用於建構 p 值和校準選擇集的資料。然而，當面對許多模型選擇和有限標籤資料時，需要 (i) 以資料驅動的方式選擇最佳模型，以及 (ii) 減輕因樣本分割造成的功率損失。本文提出了 OptCS，這是一個通用框架，允許在彈性的資料驅動模型最佳化後進行有效的統計測試（選擇）。我們引入了 OptCS 在大量資料重複使用的情況下建構有效共形 p 值的一般條件，並透過創新的多重測試程序處理複雜的 p 值依賴性，以維持有限樣本 FDR 控制。我們實例化這個通用方法，提出了三個控制 FDR 的程序，每個程序以不同的方式最佳化模型：(i) 從多個預先訓練的候選模型中選擇功能最強大的模型，(ii) 使用所有資料進行模型擬合，不進行樣本分割，以及 (iii) 結合全樣本模型擬合和選擇。我們透過模擬研究和在藥物發現和放射學報告生成中對齊大型語言模型的實際應用，證明了我們方法的有效性。

##### **The importance of visual modelling languages in generative software engineering**
2411.17976v1 by Roberto Rossi

Multimodal GPTs represent a watershed in the interplay between Software
Engineering and Generative Artificial Intelligence. GPT-4 accepts image and
text inputs, rather than simply natural language. We investigate relevant use
cases stemming from these enhanced capabilities of GPT-4. To the best of our
knowledge, no other work has investigated similar use cases involving Software
Engineering tasks carried out via multimodal GPTs prompted with a mix of
diagrams and natural language.

摘要：多模態 GPT 代表軟體工程和生成式人工智慧交互作用的分水嶺。GPT-4 接受影像和文字輸入，而不再僅限於自然語言。我們研究了 GPT-4 這些增強功能所衍生的相關使用案例。據我們所知，沒有其他研究調查過涉及軟體工程任務的類似使用案例，這些任務是透過多模態 GPT 促使結合圖表和自然語言來執行的。

##### **Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery**
2411.17973v1 by Zhenyu Yu

The forest serves as the most significant terrestrial carbon stock mechanism,
effectively reducing atmospheric CO$_2$ concentrations and mitigating climate
change. Remote sensing provides high data accuracy and enables large-scale
observations. Optical images facilitate long-term monitoring, which is crucial
for future carbon stock estimation studies. This study focuses on Huize County,
Qujing City, Yunnan Province, China, utilizing GF-1 WFV satellite imagery. The
KD-VGG and KD-UNet modules were introduced for initial feature extraction, and
the improved implicit diffusion model (IIDM) was proposed. The results showed:
(1) The VGG module improved initial feature extraction, improving accuracy, and
reducing inference time with optimized model parameters. (2) The
Cross-attention + MLPs module enabled effective feature fusion, establishing
critical relationships between global and local features, achieving
high-accuracy estimation. (3) The IIDM model, a novel contribution,
demonstrated the highest estimation accuracy with an RMSE of 12.17\%,
significantly improving by 41.69\% to 42.33\% compared to the regression model.
In carbon stock estimation, the generative model excelled in extracting deeper
features, significantly outperforming other models, demonstrating the
feasibility of AI-generated content in quantitative remote sensing. The
16-meter resolution estimates provide a robust basis for tailoring forest
carbon sink regulations, enhancing regional carbon stock management.

摘要：森林作為最重要的陸地碳儲存機制，
有效降低大氣中 CO$_2$ 濃度，緩解氣候
變遷。遙測提供高數據精確度，並能進行大尺度
觀測。光學影像利於長期監測，這對於未來碳儲量
估算研究至關重要。本研究聚焦於中國雲南省曲靖
市會澤縣，利用 GF-1 WFV 衛星影像。引入
KD-VGG 及 KD-UNet 模組進行初始特徵萃取，並
提出改良隱式擴散模型（IIDM）。結果顯示：
（1）VGG 模組改善初始特徵萃取，提升準確度，並
透過最佳化模型參數減少推論時間。（2）Cross-
attention + MLPs 模組能有效進行特徵融合，建立
全局與局部特徵間的關鍵關係，達成高準確度估算。
（3）IIDM 模型為本研究之創新貢獻，展現最高估算
準確度，RMSE 為 12.17%，相較於回歸模型，顯著
提升 41.69% 至 42.33%。在碳儲量估算上，生成模
型在萃取更深層特徵上表現優異，顯著優於其他模
型，驗證 AI 生成內容在定量遙測上的可行性。16
公尺解析度的估算結果為量身打造森林碳匯法規、
提升區域碳儲量管理提供強健的基礎。

##### **Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets**
2411.17971v1 by Seungyeon Kim, Wheesung Lee, Sung-Ho Ahn, Do-Eun Lee, Tae-Rin Lee

Accurate prediction of cerebral blood flow is essential for the diagnosis and
treatment of cerebrovascular diseases. Traditional computational methods,
however, often incur significant computational costs, limiting their
practicality in real-time clinical applications. This paper proposes a graph
neural network (GNN) to predict blood flow and pressure in previously unseen
cerebral vascular network structures that were not included in training data.
The GNN was developed using clinical datasets from patients with stenosis,
featuring complex and abnormal vascular geometries. Additionally, the GNN model
was trained on data incorporating a wide range of inflow conditions, vessel
topologies, and network connectivities to enhance its generalization
capability. The approach achieved Pearson's correlation coefficients of 0.727
for pressure and 0.824 for flow rate, with sufficient training data. These
findings demonstrate the potential of the GNN for real-time cerebrovascular
diagnostics, particularly in handling intricate and pathological vascular
networks.

摘要：準確預測腦部血流對於腦血管疾病的診斷和治療至關重要。然而，傳統的計算方法通常會產生大量的計算成本，限制了它們在臨床應用中的實用性。本文提出了一個圖形神經網路 (GNN) 來預測先前未見過的腦血管網路結構中的血流和壓力，這些結構未包含在訓練資料中。GNN 是使用來自狹窄症患者的臨床資料集開發的，這些資料集具有複雜且異常的血管幾何形狀。此外，GNN 模型是在包含各種流入條件、血管拓撲和網路連接性的資料上訓練的，以增強其泛化能力。該方法在有足夠的訓練資料的情況下，壓力達到 0.727 的皮爾森相關係數，流速達到 0.824。這些發現證明了 GNN 在實時腦血管診斷中的潛力，特別是在處理複雜且病理性的血管網路方面。

##### **QuaLLM-Health: An Adaptation of an LLM-Based Framework for Quantitative Data Extraction from Online Health Discussions**
2411.17967v1 by Ramez Kouzy, Roxanna Attar-Olyaee, Michael K. Rooney, Comron J. Hassanzadeh, Junyi Jessy Li, Osama Mohamad

Health-related discussions on social media like Reddit offer valuable
insights, but extracting quantitative data from unstructured text is
challenging. In this work, we present an adapted framework from QuaLLM into
QuaLLM-Health for extracting clinically relevant quantitative data from Reddit
discussions about glucagon-like peptide-1 (GLP-1) receptor agonists using large
language models (LLMs). We collected 410k posts and comments from five
GLP-1-related communities using the Reddit API in July 2024. After filtering
for cancer-related discussions, 2,059 unique entries remained. We developed
annotation guidelines to manually extract variables such as cancer
survivorship, family cancer history, cancer types mentioned, risk perceptions,
and discussions with physicians. Two domain-experts independently annotated a
random sample of 100 entries to create a gold-standard dataset. We then
employed iterative prompt engineering with OpenAI's "GPT-4o-mini" on the
gold-standard dataset to build an optimized pipeline that allowed us to extract
variables from the large dataset. The optimized LLM achieved accuracies above
0.85 for all variables, with precision, recall and F1 score macro averaged >
0.90, indicating balanced performance. Stability testing showed a 95% match
rate across runs, confirming consistency. Applying the framework to the full
dataset enabled efficient extraction of variables necessary for downstream
analysis, costing under $3 and completing in approximately one hour.
QuaLLM-Health demonstrates that LLMs can effectively and efficiently extract
clinically relevant quantitative data from unstructured social media content.
Incorporating human expertise and iterative prompt refinement ensures accuracy
and reliability. This methodology can be adapted for large-scale analysis of
patient-generated data across various health domains, facilitating valuable
insights for healthcare research.

摘要：<paragraph>在 Reddit 等社交媒體上的健康相關討論提供了寶貴的見解，但從非結構化文字中提取定量數據具有挑戰性。在這項工作中，我們提出了一個從 QuaLLM 改編而來的框架，即 QuaLLM-Health，用於從 Reddit 關於胰高血糖素樣肽-1 (GLP-1) 受體激動劑的討論中使用大型語言模型 (LLM) 提取臨床相關的定量數據。我們在 2024 年 7 月使用 Reddit API 從五個 GLP-1 相關社群收集了 41 萬個帖子和評論。在過濾掉與癌症相關的討論後，剩餘 2,059 個唯一條目。我們制定了註解指南，以手動提取變數，例如癌症存活率、家族癌症史、提到的癌症類型、風險認知以及與醫生的討論。兩位領域專家獨立對 100 個條目的隨機樣本進行註解，以建立黃金標準數據集。然後，我們在黃金標準數據集上使用 OpenAI 的「GPT-4o-mini」採用反覆提示工程，建立了一個最佳化管道，讓我們能夠從大型數據集中提取變數。最佳化的 LLM 對所有變數達到了 0.85 以上的準確度，精確度、召回率和 F1 分數巨集平均值 > 0.90，表明效能均衡。穩定性測試顯示，各次執行之間的匹配率為 95%，確認了一致性。將框架應用於完整數據集，能夠有效地提取下游分析所需的變數，成本低於 3 美元，並且在大約一小時內完成。QuaLLM-Health 證明，LLM 可以有效且高效地從非結構化的社交媒體內容中提取臨床相關的定量數據。結合人類專業知識和反覆提示精煉，確保了準確性和可靠性。這種方法可以改編為對各種健康領域的患者生成數據進行大規模分析，從而促進醫療保健研究的寶貴見解。</paragraph>

##### **MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation**
2411.17945v1 by Sankalp Sinha, Mohammad Sadil Khan, Muhammad Usama, Shino Sam, Didier Stricker, Sk Aziz Ali, Muhammad Zeshan Afzal

Generating high-fidelity 3D content from text prompts remains a significant
challenge in computer vision due to the limited size, diversity, and annotation
depth of the existing datasets. To address this, we introduce MARVEL-40M+, an
extensive dataset with 40 million text annotations for over 8.9 million 3D
assets aggregated from seven major 3D datasets. Our contribution is a novel
multi-stage annotation pipeline that integrates open-source pretrained
multi-view VLMs and LLMs to automatically produce multi-level descriptions,
ranging from detailed (150-200 words) to concise semantic tags (10-20 words).
This structure supports both fine-grained 3D reconstruction and rapid
prototyping. Furthermore, we incorporate human metadata from source datasets
into our annotation pipeline to add domain-specific information in our
annotation and reduce VLM hallucinations. Additionally, we develop MARVEL-FX3D,
a two-stage text-to-3D pipeline. We fine-tune Stable Diffusion with our
annotations and use a pretrained image-to-3D network to generate 3D textured
meshes within 15s. Extensive evaluations show that MARVEL-40M+ significantly
outperforms existing datasets in annotation quality and linguistic diversity,
achieving win rates of 72.41% by GPT-4 and 73.40% by human evaluators.

摘要：從文字提示產生高保真 3D 內容在電腦視覺中仍然是一個重大挑戰，因為現有資料集的大小、多樣性和註解深度有限。為了解決這個問題，我們引入了 MARVEL-40M+，一個包含 4000 萬個文字註解的廣泛資料集，這些註解適用於從七個主要 3D 資料集彙總的 890 萬個 3D 資產。我們的貢獻是一個新穎的多階段註解管道，它整合了開放原始碼的預訓練多視圖 VLM 和 LLM，以自動產生多層級描述，從詳細（150-200 個字）到簡潔的語義標籤（10-20 個字）。此結構支援細粒度的 3D 重建和快速原型製作。此外，我們將來自來源資料集的人類元資料納入我們的註解管道，以在我們的註解中新增特定於領域的資訊並減少 VLM 幻覺。此外，我們開發了 MARVEL-FX3D，一個兩階段的文字到 3D 管道。我們使用我們的註解微調 Stable Diffusion，並使用預訓練的影像到 3D 網路在 15 秒內產生 3D 紋理網格。廣泛的評估顯示，MARVEL-40M+ 在註解品質和語言多樣性方面明顯優於現有的資料集，GPT-4 的獲勝率達到 72.41%，人類評估者的獲勝率達到 73.40%。

##### **Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**
2411.17943v1 by Saman Sarraf

Generative AI (GenAI) has revolutionized content generation, offering
transformative capabilities for improving language coherence, readability, and
overall quality. This manuscript explores the application of qualitative,
quantitative, and mixed-methods research approaches to evaluate the performance
of GenAI models in enhancing scientific writing. Using a hypothetical use case
involving a collaborative medical imaging manuscript, we demonstrate how each
method provides unique insights into the impact of GenAI. Qualitative methods
gather in-depth feedback from expert reviewers, analyzing their responses using
thematic analysis tools to capture nuanced improvements and identify
limitations. Quantitative approaches employ automated metrics such as BLEU,
ROUGE, and readability scores, as well as user surveys, to objectively measure
improvements in coherence, fluency, and structure. Mixed-methods research
integrates these strengths, combining statistical evaluations with detailed
qualitative insights to provide a comprehensive assessment. These research
methods enable quantifying improvement levels in GenAI-generated content,
addressing critical aspects of linguistic quality and technical accuracy. They
also offer a robust framework for benchmarking GenAI tools against traditional
editing processes, ensuring the reliability and effectiveness of these
technologies. By leveraging these methodologies, researchers can evaluate the
performance boost driven by GenAI, refine its applications, and guide its
responsible adoption in high-stakes domains like healthcare and scientific
research. This work underscores the importance of rigorous evaluation
frameworks for advancing trust and innovation in GenAI.

摘要：生成式 AI (GenAI) 徹底改變了內容生成，提供了變革性的能力來改善語言的連貫性、可讀性和整體品質。這份手稿探討了運用定性、定量和混合方法研究方法來評估 GenAI 模型在提升科學寫作方面的表現。使用涉及協作醫學影像手稿的假設用例，我們展示了每種方法如何提供對 GenAI 影響的獨特見解。定性方法從專家審查員收集深入的回饋，使用主題分析工具分析他們的回應，以捕捉細微的改進並找出限制。定量方法採用自動化指標，例如 BLEU、ROUGE 和可讀性評分，以及使用者調查，以客觀地衡量連貫性、流暢性和結構的改進。混合方法研究整合了這些優勢，結合統計評估和詳細的定性見解，以提供全面的評估。這些研究方法能夠量化 GenAI 生成的內容的改進程度，解決語言品質和技術準確性的關鍵面向。它們還提供了一個穩健的架構，用於將 GenAI 工具與傳統的編輯流程進行基準比較，確保這些技術的可靠性和有效性。透過運用這些方法，研究人員可以評估 GenAI 帶來的效能提升，優化其應用，並指導其在醫療保健和科學研究等高風險領域中的負責任採用。這項工作強調了嚴謹評估架構對於提升 GenAI 的信任和創新的重要性。

##### **Spatio-temporal Causal Learning for Streamflow Forecasting**
2411.17937v1 by Shu Wan, Reepal Shah, Qi Deng, John Sabo, Huan Liu, K. Selçuk

Streamflow plays an essential role in the sustainable planning and management
of national water resources. Traditional hydrologic modeling approaches
simulate streamflow by establishing connections across multiple physical
processes, such as rainfall and runoff. These data, inherently connected both
spatially and temporally, possess intrinsic causal relations that can be
leveraged for robust and accurate forecasting. Recently, spatio-temporal graph
neural networks (STGNNs) have been adopted, excelling in various domains, such
as urban traffic management, weather forecasting, and pandemic control, and
they also promise advances in streamflow management. However, learning causal
relationships directly from vast observational data is theoretically and
computationally challenging. In this study, we employ a river flow graph as
prior knowledge to facilitate the learning of the causal structure and then use
the learned causal graph to predict streamflow at targeted sites. The proposed
model, Causal Streamflow Forecasting (CSF) is tested in a real-world study in
the Brazos River basin in Texas. Our results demonstrate that our method
outperforms regular spatio-temporal graph neural networks and achieves higher
computational efficiency compared to traditional simulation methods. By
effectively integrating river flow graphs with STGNNs, this research offers a
novel approach to streamflow prediction, showcasing the potential of combining
advanced neural network techniques with domain-specific knowledge for enhanced
performance in hydrologic modeling.

摘要：流量在國家水資源永續規劃與管理中扮演著重要的角色。傳統的水文模式方法透過建立多個物理程序的連接來模擬流量，例如降雨和徑流。這些資料在空間和時間上具有內在的關聯性，擁有內在的因果關係，可以利用這些關係進行強健且準確的預測。最近，時空圖形神經網路 (STGNN) 已被採用，在各種領域中表現出色，例如都市交通管理、天氣預測和疫情控制，並且也承諾在流量管理方面取得進展。然而，直接從大量的觀測資料中學習因果關係在理論上和計算上都具有挑戰性。在這項研究中，我們採用河流流量圖作為先驗知識，以利於因果結構的學習，然後使用已學習的因果圖表來預測目標地點的流量。所提出的模型，因果流量預測 (CSF)，在德州的布拉索斯河流域中進行真實世界的研究測試。我們的結果證明，我們的方法優於一般的時空圖形神經網路，並且與傳統的模擬方法相比，達到了更高的計算效率。透過有效地將河流流量圖與 STGNN 整合，這項研究提供了一種新的流量預測方法，展示了結合先進的神經網路技術與特定領域知識，以增進水文模式效能的潛力。

##### **Neural Networks Use Distance Metrics**
2411.17932v1 by Alan Oursland

We present empirical evidence that neural networks with ReLU and Absolute
Value activations learn distance-based representations. We independently
manipulate both distance and intensity properties of internal activations in
trained models, finding that both architectures are highly sensitive to small
distance-based perturbations while maintaining robust performance under large
intensity-based perturbations. These findings challenge the prevailing
intensity-based interpretation of neural network activations and offer new
insights into their learning and decision-making processes.

摘要：我們提出經驗證據，證明具有 ReLU 和絕對值激活的神經網路會學習基於距離的表示。我們獨立地操作訓練模型中內部激活的距離和強度屬性，發現這兩種架構對於基於距離的小擾動都高度敏感，同時在基於強度的較大擾動下維持穩健的效能。這些發現挑戰了神經網路激活基於強度的流行詮釋，並提供了對其學習和決策過程的新見解。

##### **AI2T: Building Trustable AI Tutors by Interactively Teaching a Self-Aware Learning Agent**
2411.17924v1 by Daniel Weitekamp, Erik Harpstead, Kenneth Koedinger

AI2T is an interactively teachable AI for authoring intelligent tutoring
systems (ITSs). Authors tutor AI2T by providing a few step-by-step solutions
and then grading AI2T's own problem-solving attempts. From just 20-30 minutes
of interactive training, AI2T can induce robust rules for step-by-step solution
tracking (i.e., model-tracing). As AI2T learns it can accurately estimate its
certainty of performing correctly on unseen problem steps using STAND: a
self-aware precondition learning algorithm that outperforms state-of-the-art
methods like XGBoost. Our user study shows that authors can use STAND's
certainty heuristic to estimate when AI2T has been trained on enough diverse
problems to induce correct and complete model-tracing programs. AI2T-induced
programs are more reliable than hallucination-prone LLMs and prior
authoring-by-tutoring approaches. With its self-aware induction of hierarchical
rules, AI2T offers a path toward trustable data-efficient authoring-by-tutoring
for complex ITSs that normally require as many as 200-300 hours of programming
per hour of instruction.

摘要：AI2T 是一種互動式可教授 AI，用於編寫智慧型教學系統 (ITS)。作者透過提供一些逐步解決方案並評分 AI2T 自行解決問題的嘗試，來指導 AI2T。AI2T 只需 20-30 分鐘的互動式訓練，就能推演出用於逐步解決方案追蹤（即模型追蹤）的穩健規則。隨著 AI2T 學習，它可以使用 STAND 準確估計它在未見問題步驟中正確執行任務的確定性：一種自我感知的前置條件學習演算法，其表現優於 XGBoost 等現有技術。我們的使用者研究顯示，作者可以使用 STAND 的確定性啟發法來估計 AI2T 是否已在足夠多樣化的問題上接受訓練，以推演出正確且完整的模型追蹤程式。AI2T 推演出程式比容易產生幻覺的 LLM 和先前的指導編寫方法更可靠。透過其自我感知的階層式規則推演，AI2T 提供了一條可信賴、資料有效率的指導編寫途徑，用於複雜的 ITS，這些 ITS 通常每小時教學需要長達 200-300 小時的編程。

##### **Can LLMs plan paths in the real world?**
2411.17912v1 by Wanyi Chen, Meng-Wen Su, Nafisa Mehjabin, Mary L. Cummings

As large language models (LLMs) increasingly integrate into vehicle
navigation systems, understanding their path-planning capability is crucial. We
tested three LLMs through six real-world path-planning scenarios in various
settings and with various difficulties. Our experiments showed that all LLMs
made numerous errors in all scenarios, revealing that they are unreliable path
planners. We suggest that future work focus on implementing mechanisms for
reality checks, enhancing model transparency, and developing smaller models.

摘要：隨著大型語言模型（LLM）日益整合到車輛導航系統中，了解其路徑規劃能力至關重要。我們在各種場景和各種難度下，透過六個真實世界的路徑規劃場景測試了三個 LLM。我們的實驗表明，所有 LLM 在所有場景中都出現許多錯誤，這表明它們是不可靠的路徑規劃器。我們建議未來的研究重點放在實施現實檢查機制、增強模型透明度和開發更小的模型上。

##### **Automating grapevine LAI features estimation with UAV imagery and machine learning**
2411.17897v1 by Muhammad Waseem Akram, Marco Vannucci, Giorgio Buttazzo, Valentina Colla, Stefano Roccella, Andrea Vannini, Giovanni Caruso, Simone Nesi, Alessandra Francini, Luca Sebastiani

The leaf area index determines crop health and growth. Traditional methods
for calculating it are time-consuming, destructive, costly, and limited to a
scale. In this study, we automate the index estimation method using drone image
data of grapevine plants and a machine learning model. Traditional feature
extraction and deep learning methods are used to obtain helpful information
from the data and enhance the performance of the different machine learning
models employed for the leaf area index prediction. The results showed that
deep learning based feature extraction is more effective than traditional
methods. The new approach is a significant improvement over old methods,
offering a faster, non-destructive, and cost-effective leaf area index
calculation, which enhances precision agriculture practices.

摘要：葉面積指數決定作物的健康和生長。傳統計算方法耗時、具破壞性、昂貴且僅限於某一規模。在本研究中，我們使用葡萄藤植株的無人機影像資料和機器學習模型自動化指數估計方法。傳統特徵提取和深度學習方法用於從資料中獲取有用的資訊，並提升用於葉面積指數預測的不同機器學習模型的效能。結果顯示，基於深度學習的特徵提取比傳統方法更有效。新方法比舊方法有顯著的改進，提供更快速、非破壞性且具成本效益的葉面積指數計算，進而提升精準農業實務。

##### **HOPPR Medical-Grade Platform for Medical Imaging AI**
2411.17891v1 by Kalina P. Slavkova, Melanie Traughber, Oliver Chen, Robert Bakos, Shayna Goldstein, Dan Harms, Bradley J. Erickson, Khan M. Siddiqui

Technological advances in artificial intelligence (AI) have enabled the
development of large vision language models (LVLMs) that are trained on
millions of paired image and text samples. Subsequent research efforts have
demonstrated great potential of LVLMs to achieve high performance in medical
imaging use cases (e.g., radiology report generation), but there remain
barriers that hinder the ability to deploy these solutions broadly. These
include the cost of extensive computational requirements for developing large
scale models, expertise in the development of sophisticated AI models, and the
difficulty in accessing substantially large, high-quality datasets that
adequately represent the population in which the LVLM solution is to be
deployed. The HOPPR Medical-Grade Platform addresses these barriers by
providing powerful computational infrastructure, a suite of foundation models
on top of which developers can fine-tune for their specific use cases, and a
robust quality management system that sets a standard for evaluating fine-tuned
models for deployment in clinical settings. The HOPPR Platform has access to
millions of imaging studies and text reports sourced from hundreds of imaging
centers from diverse populations to pretrain foundation models and enable use
case-specific cohorts for fine-tuning. All data are deidentified and securely
stored for HIPAA compliance. Additionally, developers can securely host models
on the HOPPR platform and access them via an API to make inferences using these
models within established clinical workflows. With the Medical-Grade Platform,
HOPPR's mission is to expedite the deployment of LVLM solutions for medical
imaging and ultimately optimize radiologist's workflows and meet the growing
demands of the field.

摘要：人工智能 (AI) 的技術進展使大型視覺語言模型 (LVLMs) 的開發成為可能，這些模型經過數百萬配對圖像和文本範例的訓練。後續的研究工作已證明 LVLMs 在醫學影像使用案例（例如放射學報告生成）中實現高性能的巨大潛力，但仍存在阻礙這些解決方案廣泛部署的能力的障礙。這些障礙包括開發大型模型的廣泛計算需求的成本、開發複雜 AI 模型的專業知識，以及難以存取充分龐大、高品質的資料集，這些資料集充分代表了 LVLM 解決方案將要部署的人群。HOPPR 醫療級平台透過提供強大的運算基礎架構、一套基礎模型（開發人員可以在其上針對其特定使用案例進行微調）以及一套健全的品質管理系統來解決這些障礙，為評估微調模型在臨床環境中部署設定標準。HOPPR 平台可以存取數百萬份影像研究和來自不同族群的數百個影像中心的文字報告，以預先訓練基礎模型並針對特定使用案例啟用微調的群組。所有資料均已去識別化並安全儲存，以符合 HIPAA 規範。此外，開發人員可以在 HOPPR 平台上安全地主機模型，並透過 API 存取這些模型，以便在既定的臨床工作流程中使用這些模型進行推論。HOPPR 的使命是透過醫療級平台加速部署用於醫學影像的 LVLM 解決方案，並最終最佳化放射科醫師的工作流程，以滿足該領域不斷增長的需求。

##### **Leveraging Large Language Models and Topic Modeling for Toxicity Classification**
2411.17876v1 by Haniyeh Ehsani Oskouie, Christina Chance, Claire Huang, Margaret Capetz, Elizabeth Eyeson, Majid Sarrafzadeh

Content moderation and toxicity classification represent critical tasks with
significant social implications. However, studies have shown that major
classification models exhibit tendencies to magnify or reduce biases and
potentially overlook or disadvantage certain marginalized groups within their
classification processes. Researchers suggest that the positionality of
annotators influences the gold standard labels in which the models learned from
propagate annotators' bias. To further investigate the impact of annotator
positionality, we delve into fine-tuning BERTweet and HateBERT on the dataset
while using topic-modeling strategies for content moderation. The results
indicate that fine-tuning the models on specific topics results in a notable
improvement in the F1 score of the models when compared to the predictions
generated by other prominent classification models such as GPT-4,
PerspectiveAPI, and RewireAPI. These findings further reveal that the
state-of-the-art large language models exhibit significant limitations in
accurately detecting and interpreting text toxicity contrasted with earlier
methodologies. Code is available at
https://github.com/aheldis/Toxicity-Classification.git.

摘要：內容審核和毒性分類代表著具有重大社會意涵的關鍵任務。然而，研究顯示，主要的分類模型展現出放大或縮小偏見的傾向，並可能在分類過程中忽略或不利於某些邊緣化群體。研究人員建議，註解者的位置性會影響模型從中學習的黃金標準標籤，進而傳播註解者的偏見。為了進一步探討註解者位置性的影響，我們深入探討微調 BERTweet 和 HateBERT 在資料集上的表現，同時使用主題建模策略進行內容審核。結果顯示，針對特定主題微調模型會讓模型的 F1 分數顯著提升，相較於 GPT-4、PerspectiveAPI 和 RewireAPI 等其他傑出分類模型所產生的預測。這些發現進一步揭示，最先進的大語言模型在準確偵測和詮釋文字毒性方面展現出顯著的限制，與早期的方法論形成對比。程式碼可於 https://github.com/aheldis/Toxicity-Classification.git 取得。

##### **LongKey: Keyphrase Extraction for Long Documents**
2411.17863v1 by Jeovane Honorio Alves, Radu State, Cinthia Obladen de Almendra Freitas, Jean Paul Barddal

In an era of information overload, manually annotating the vast and growing
corpus of documents and scholarly papers is increasingly impractical. Automated
keyphrase extraction addresses this challenge by identifying representative
terms within texts. However, most existing methods focus on short documents (up
to 512 tokens), leaving a gap in processing long-context documents. In this
paper, we introduce LongKey, a novel framework for extracting keyphrases from
lengthy documents, which uses an encoder-based language model to capture
extended text intricacies. LongKey uses a max-pooling embedder to enhance
keyphrase candidate representation. Validated on the comprehensive LDKP
datasets and six diverse, unseen datasets, LongKey consistently outperforms
existing unsupervised and language model-based keyphrase extraction methods.
Our findings demonstrate LongKey's versatility and superior performance,
marking an advancement in keyphrase extraction for varied text lengths and
domains.

摘要：在資訊爆炸的時代，手動標註大量且持續增長的文獻和學術論文越來越不切實際。自動關鍵字萃取透過識別文本中的代表性詞彙，來解決這個挑戰。然而，現有的方法大多著重於短文件（最多 512 個詞彙），在處理長文脈文件時仍有不足。在本文中，我們提出 LongKey，一個從長篇文件中萃取關鍵字的新框架，它使用基於編碼器的語言模型來捕捉延伸文本的複雜性。LongKey 使用最大池化嵌入器來增強關鍵字候選的表示。在全面的 LDKP 資料集和六個不同的未見過資料集上驗證後，LongKey 持續優於現有的非監督式和基於語言模型的關鍵字萃取方法。我們的發現證明了 LongKey 的多功能性和優異效能，標誌著關鍵字萃取在不同文本長度和領域的進步。

