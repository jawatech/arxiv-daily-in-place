{"2502.03461": {"publish_time": "2025-02-05", "title": "Do Large Language Model Benchmarks Test Reliability?", "paper_summary": "When deploying large language models (LLMs), it is important to ensure that\nthese models are not only capable, but also reliable. Many benchmarks have been\ncreated to track LLMs' growing capabilities, however there has been no similar\nfocus on measuring their reliability. To understand the potential ramifications\nof this gap, we investigate how well current benchmarks quantify model\nreliability. We find that pervasive label errors can compromise these\nevaluations, obscuring lingering model failures and hiding unreliable behavior.\n  Motivated by this gap in the evaluation of reliability, we then propose the\nconcept of so-called platinum benchmarks, i.e., benchmarks carefully curated to\nminimize label errors and ambiguity. As a first attempt at constructing such\nbenchmarks, we revise examples from fifteen existing popular benchmarks. We\nevaluate a wide range of models on these platinum benchmarks and find that,\nindeed, frontier LLMs still exhibit failures on simple tasks such as\nelementary-level math word problems. Analyzing these failures further reveals\npreviously unidentified patterns of problems on which frontier models\nconsistently struggle. We provide code at\nhttps://github.com/MadryLab/platinum-benchmarks", "paper_summary_zh": "\u5728\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u65f6\uff0c\u91cd\u8981\u7684\u662f\u8981\u786e\u4fdd\u8fd9\u4e9b\u6a21\u578b\u4e0d\u4ec5\u6709\u80fd\u529b\uff0c\u800c\u4e14\u53ef\u9760\u3002\u5df2\u7ecf\u521b\u5efa\u4e86\u8bb8\u591a\u57fa\u51c6\u6765\u8ddf\u8e2a LLM \u4e0d\u65ad\u589e\u957f\u7684\u80fd\u529b\uff0c\u7136\u800c\uff0c\u6ca1\u6709\u7c7b\u4f3c\u7684\u91cd\u70b9\u6765\u8861\u91cf\u5b83\u4eec\u7684\u53ef\u9760\u6027\u3002\u4e3a\u4e86\u4e86\u89e3\u8fd9\u4e00\u5dee\u8ddd\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u6211\u4eec\u8c03\u67e5\u4e86\u5f53\u524d\u57fa\u51c6\u5bf9\u6a21\u578b\u53ef\u9760\u6027\u7684\u91cf\u5316\u7a0b\u5ea6\u3002\u6211\u4eec\u53d1\u73b0\u666e\u904d\u7684\u6807\u7b7e\u9519\u8bef\u4f1a\u635f\u5bb3\u8fd9\u4e9b\u8bc4\u4f30\uff0c\u63a9\u76d6\u6301\u7eed\u7684\u6a21\u578b\u6545\u969c\u5e76\u9690\u85cf\u4e0d\u53ef\u9760\u7684\u884c\u4e3a\u3002\u53d7\u8bc4\u4f30\u53ef\u9760\u6027\u5dee\u8ddd\u7684\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6240\u8c13\u7684\u94c2\u91d1\u57fa\u51c6\u7684\u6982\u5ff5\uff0c\u5373\u7cbe\u5fc3\u7b56\u5212\u4ee5\u6700\u5927\u7a0b\u5ea6\u51cf\u5c11\u6807\u7b7e\u9519\u8bef\u548c\u6b67\u4e49\u7684\u57fa\u51c6\u3002\u4f5c\u4e3a\u6784\u5efa\u6b64\u7c7b\u57fa\u51c6\u7684\u9996\u6b21\u5c1d\u8bd5\uff0c\u6211\u4eec\u4fee\u6539\u4e86\u5341\u4e94\u4e2a\u73b0\u6709\u6d41\u884c\u57fa\u51c6\u4e2d\u7684\u793a\u4f8b\u3002\u6211\u4eec\u5728\u8fd9\u4e9b\u94c2\u91d1\u57fa\u51c6\u4e0a\u8bc4\u4f30\u4e86\u5e7f\u6cdb\u7684\u6a21\u578b\uff0c\u5e76\u53d1\u73b0\u6700\u524d\u6cbf\u7684 LLM \u786e\u5b9e\u4ecd\u7136\u5728\u7b80\u5355\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u5931\u8d25\uff0c\u4f8b\u5982\u5c0f\u5b66\u6570\u5b66\u6587\u5b57\u9898\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8fd9\u4e9b\u5931\u8d25\u63ed\u793a\u4e86\u4ee5\u524d\u672a\u8bc6\u522b\u7684\u6a21\u578b\u95ee\u9898\u6a21\u5f0f\uff0c\u6700\u524d\u6cbf\u7684\u6a21\u578b\u59cb\u7ec8\u5728\u8fd9\u4e9b\u95ee\u9898\u4e0a\u82e6\u82e6\u6323\u624e\u3002\u6211\u4eec\u5728 https://github.com/MadryLab/platinum-benchmarks \u63d0\u4f9b\u4ee3\u7801", "author": "Joshua Vendrow et.al.", "authors": "Joshua Vendrow, Edward Vendrow, Sara Beery, Aleksander Madry", "id": "2502.03461v1", "paper_url": "http://arxiv.org/abs/2502.03461v1", "repo": "null"}}