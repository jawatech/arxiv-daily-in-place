{"2406.11668": {"publish_time": "2024-06-17", "title": "\"Not Aligned\" is Not \"Malicious\": Being Careful about Hallucinations of Large Language Models' Jailbreak", "paper_summary": "\"Jailbreak\" is a major safety concern of Large Language Models (LLMs), which\noccurs when malicious prompts lead LLMs to produce harmful outputs, raising\nissues about the reliability and safety of LLMs. Therefore, an effective\nevaluation of jailbreaks is very crucial to develop its mitigation strategies.\nHowever, our research reveals that many jailbreaks identified by current\nevaluations may actually be hallucinations-erroneous outputs that are mistaken\nfor genuine safety breaches. This finding suggests that some perceived\nvulnerabilities might not represent actual threats, indicating a need for more\nprecise red teaming benchmarks. To address this problem, we propose the\n$\\textbf{B}$enchmark for reli$\\textbf{AB}$ilit$\\textbf{Y}$ and\njail$\\textbf{B}$reak ha$\\textbf{L}$l$\\textbf{U}$cination $\\textbf{E}$valuation\n(BabyBLUE). BabyBLUE introduces a specialized validation framework including\nvarious evaluators to enhance existing jailbreak benchmarks, ensuring outputs\nare useful malicious instructions. Additionally, BabyBLUE presents a new\ndataset as an augmentation to the existing red teaming benchmarks, specifically\naddressing hallucinations in jailbreaks, aiming to evaluate the true potential\nof jailbroken LLM outputs to cause harm to human society.", "paper_summary_zh": "\u300c\u8d8a\u7344\u300d\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e3b\u8981\u5b89\u5168\u554f\u984c\uff0c\u5b83\u767c\u751f\u5728\u60e1\u610f\u63d0\u793a\u5c0e\u81f4 LLM \u7522\u751f\u6709\u5bb3\u8f38\u51fa\u6642\uff0c\u5f15\u767c\u4e86\u95dc\u65bc LLM \u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u554f\u984c\u3002\u56e0\u6b64\uff0c\u5c0d\u8d8a\u7344\u9032\u884c\u6709\u6548\u7684\u8a55\u4f30\u5c0d\u65bc\u5236\u5b9a\u5176\u7de9\u89e3\u7b56\u7565\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u6211\u5011\u7684\u7814\u7a76\u8868\u660e\uff0c\u7576\u524d\u8a55\u4f30\u4e2d\u8b58\u5225\u51fa\u7684\u8a31\u591a\u8d8a\u7344\u5be6\u969b\u4e0a\u53ef\u80fd\u662f\u5e7b\u89ba\u2014\u2014\u932f\u8aa4\u7684\u8f38\u51fa\uff0c\u88ab\u8aa4\u8a8d\u70ba\u771f\u6b63\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u9019\u4e00\u767c\u73fe\u8868\u660e\uff0c\u4e00\u4e9b\u611f\u77e5\u5230\u7684\u6f0f\u6d1e\u53ef\u80fd\u4e26\u4e0d\u80fd\u4ee3\u8868\u5be6\u969b\u5a01\u8105\uff0c\u9019\u8868\u660e\u9700\u8981\u66f4\u7cbe\u78ba\u7684\u7d05\u968a\u57fa\u6e96\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86$\\textbf{B}$enchmark for reli$\\textbf{AB}$ilit$\\textbf{Y}$ and jail$\\textbf{B}$reak ha$\\textbf{L}$l$\\textbf{U}$cination $\\textbf{E}$valuation\uff08BabyBLUE\uff09\u3002BabyBLUE \u5f15\u5165\u4e86\u4e00\u500b\u5c08\u9580\u7684\u9a57\u8b49\u6846\u67b6\uff0c\u5305\u62ec\u5404\u7a2e\u8a55\u4f30\u5668\uff0c\u4ee5\u589e\u5f37\u73fe\u6709\u7684\u8d8a\u7344\u57fa\u6e96\uff0c\u78ba\u4fdd\u8f38\u51fa\u662f\u6709\u7528\u7684\u60e1\u610f\u6307\u4ee4\u3002\u6b64\u5916\uff0cBabyBLUE \u9084\u63d0\u4f9b\u4e86\u4e00\u500b\u65b0\u6578\u64da\u96c6\u4f5c\u70ba\u5c0d\u73fe\u6709\u7d05\u968a\u57fa\u6e96\u7684\u64f4\u5145\uff0c\u7279\u5225\u91dd\u5c0d\u8d8a\u7344\u4e2d\u7684\u5e7b\u89ba\uff0c\u65e8\u5728\u8a55\u4f30\u8d8a\u7344 LLM \u8f38\u51fa\u5c0d\u4eba\u985e\u793e\u6703\u9020\u6210\u50b7\u5bb3\u7684\u771f\u6b63\u6f5b\u529b\u3002", "author": "Lingrui Mei et.al.", "authors": "Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Jiayi Mao, Xueqi Cheng", "id": "2406.11668v1", "paper_url": "http://arxiv.org/abs/2406.11668v1", "repo": "null"}}