
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-03**|**Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages**|Max Zuo et.al.|[2407.03321v1](http://arxiv.org/abs/2407.03321v1)|[link](https://github.com/batsresearch/planetarium)|
|**2024-07-03**|**InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output**|Pan Zhang et.al.|[2407.03320v1](http://arxiv.org/abs/2407.03320v1)|[link](https://github.com/internlm/internlm-xcomposer)|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**|Sijie Xu et.al.|[2407.03308v1](http://arxiv.org/abs/2407.03308v1)|null|
|**2024-07-03**|**A Review of the Applications of Deep Learning-Based Emergent Communication**|Brendon Boldt et.al.|[2407.03302v1](http://arxiv.org/abs/2407.03302v1)|null|
|**2024-07-03**|**DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents**|Yilun Xu et.al.|[2407.03300v1](http://arxiv.org/abs/2407.03300v1)|null|
|**2024-07-03**|**Improved Noise Schedule for Diffusion Training**|Tiankai Hang et.al.|[2407.03297v1](http://arxiv.org/abs/2407.03297v1)|null|
|**2024-07-03**|**LLM Internal States Reveal Hallucination Risk Faced With a Query**|Ziwei Ji et.al.|[2407.03282v1](http://arxiv.org/abs/2407.03282v1)|null|
|**2024-07-03**|**STF: Sentence Transformer Fine-Tuning For Topic Categorization With Limited Data**|Kheir Eddine Daouadi et.al.|[2407.03253v1](http://arxiv.org/abs/2407.03253v1)|null|
|**2024-07-03**|**CATT: Character-based Arabic Tashkeel Transformer**|Faris Alasmary et.al.|[2407.03236v1](http://arxiv.org/abs/2407.03236v1)|null|
|**2024-07-03**|**Self-Evaluation as a Defense Against Adversarial Attacks on LLMs**|Hannah Brown et.al.|[2407.03234v1](http://arxiv.org/abs/2407.03234v1)|null|
|**2024-07-03**|**Single Character Perturbations Break LLM Alignment**|Leon Lin et.al.|[2407.03232v1](http://arxiv.org/abs/2407.03232v1)|null|
|**2024-07-03**|**Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning**|Zhili Shen et.al.|[2407.03227v1](http://arxiv.org/abs/2407.03227v1)|null|
|**2024-07-03**|**PPO-based Dynamic Control of Uncertain Floating Platforms in the Zero-G Environment**|Mahya Ramezani et.al.|[2407.03224v1](http://arxiv.org/abs/2407.03224v1)|null|
|**2024-07-03**|**Learning Disentangled Representation in Object-Centric Models for Visual Dynamics Prediction via Transformers**|Sanket Gandhi et.al.|[2407.03216v1](http://arxiv.org/abs/2407.03216v1)|null|
|**2024-07-03**|**How Does Quantization Affect Multilingual LLMs?**|Kelly Marchisio et.al.|[2407.03211v1](http://arxiv.org/abs/2407.03211v1)|null|
|**2024-07-03**|**TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts**|Ruida Wang et.al.|[2407.03203v1](http://arxiv.org/abs/2407.03203v1)|[link](https://github.com/RickySkywalker/TheoremLlama)|
|**2024-07-03**|**MuDiT & MuSiT: Alignment with Colloquial Expression in Description-to-Song Generation**|Zihao Wang et.al.|[2407.03188v1](http://arxiv.org/abs/2407.03188v1)|null|
|**2024-07-03**|**Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing**|Egon Peršak et.al.|[2407.03185v1](http://arxiv.org/abs/2407.03185v1)|null|
|**2024-07-03**|**A Formal Model for Artificial Intelligence Applications in Automation Systems**|Marvin Schieseck et.al.|[2407.03183v1](http://arxiv.org/abs/2407.03183v1)|null|
|**2024-07-03**|**Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models**|Haritz Puerto et.al.|[2407.03181v1](http://arxiv.org/abs/2407.03181v1)|[link](https://github.com/ukplab/arxiv2024-divergent-cot)|
|**2024-07-03**|**A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis**|Imran Mahmood et.al.|[2407.03180v1](http://arxiv.org/abs/2407.03180v1)|null|
|**2024-07-03**|**Motion meets Attention: Video Motion Prompts**|Qixiang Chen et.al.|[2407.03179v1](http://arxiv.org/abs/2407.03179v1)|null|
|**2024-07-03**|**Investigating Decoder-only Large Language Models for Speech-to-text Translation**|Chao-Wei Huang et.al.|[2407.03169v1](http://arxiv.org/abs/2407.03169v1)|null|
|**2024-07-03**|**SOS! Soft Prompt Attack Against Open-Source Large Language Models**|Ziqing Yang et.al.|[2407.03160v1](http://arxiv.org/abs/2407.03160v1)|null|
|**2024-07-03**|**Let the Code LLM Edit Itself When You Edit the Code**|Zhenyu He et.al.|[2407.03157v1](http://arxiv.org/abs/2407.03157v1)|null|
|**2024-07-03**|**Reinforcement Learning for Sequence Design Leveraging Protein Language Models**|Jithendaraa Subramanian et.al.|[2407.03154v1](http://arxiv.org/abs/2407.03154v1)|null|
|**2024-07-03**|**Enhancing Translation Accuracy of Large Language Models through Continual Pre-Training on Parallel Data**|Minato Kondo et.al.|[2407.03145v1](http://arxiv.org/abs/2407.03145v1)|null|
|**2024-07-03**|**GMM-ResNext: Combining Generative and Discriminative Models for Speaker Verification**|Hui Yan et.al.|[2407.03135v1](http://arxiv.org/abs/2407.03135v1)|null|
|**2024-07-03**|**MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**|Yanjie Cui et.al.|[2407.03131v1](http://arxiv.org/abs/2407.03131v1)|null|
|**2024-07-03**|**Social Bias Evaluation for Large Language Models Requires Prompt Variations**|Rem Hida et.al.|[2407.03129v1](http://arxiv.org/abs/2407.03129v1)|null|
|**2024-07-03**|**Foundations and Frontiers of Graph Learning Theory**|Yu Huang et.al.|[2407.03125v1](http://arxiv.org/abs/2407.03125v1)|null|
|**2024-07-03**|**How Reliable and Stable are Explanations of XAI Methods?**|José Ribeiro et.al.|[2407.03108v1](http://arxiv.org/abs/2407.03108v1)|null|
|**2024-07-03**|**KeyVideoLLM: Towards Large-scale Video Keyframe Selection**|Hao Liang et.al.|[2407.03104v1](http://arxiv.org/abs/2407.03104v1)|null|
|**2024-07-03**|**Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory**|Suyeon Lee et.al.|[2407.03103v1](http://arxiv.org/abs/2407.03103v1)|null|
|**2024-07-03**|**Conformal Prediction for Causal Effects of Continuous Treatments**|Maresa Schröder et.al.|[2407.03094v1](http://arxiv.org/abs/2407.03094v1)|null|
|**2024-07-03**|**Revisiting the Performance of Deep Learning-Based Vulnerability Detection on Realistic Datasets**|Partha Chakraborty et.al.|[2407.03093v1](http://arxiv.org/abs/2407.03093v1)|null|
|**2024-07-03**|**Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**|Yujin Shin et.al.|[2407.03086v1](http://arxiv.org/abs/2407.03086v1)|null|
|**2024-07-03**|**Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios**|Patricia A. Apellániz et.al.|[2407.03080v1](http://arxiv.org/abs/2407.03080v1)|null|
|**2024-07-03**|**A Case Study on Context-Aware Neural Machine Translation with Multi-Task Learning**|Ramakrishna Appicharla et.al.|[2407.03076v1](http://arxiv.org/abs/2407.03076v1)|null|
|**2024-07-03**|**Federated Learning for Zero-Day Attack Detection in 5G and Beyond V2X Networks**|Abdelaziz Amara korba et.al.|[2407.03070v1](http://arxiv.org/abs/2407.03070v1)|null|
|**2024-07-03**|**xApp Distillation: AI-based Conflict Mitigation in B5G O-RAN**|Hakan Erdol et.al.|[2407.03068v1](http://arxiv.org/abs/2407.03068v1)|null|
|**2024-07-03**|**ALTER: Augmentation for Large-Table-Based Reasoning**|Han Zhang et.al.|[2407.03061v1](http://arxiv.org/abs/2407.03061v1)|null|
|**2024-07-03**|**Improving Zero-shot Generalization of Learned Prompts via Unsupervised Knowledge Distillation**|Marco Mistretta et.al.|[2407.03056v1](http://arxiv.org/abs/2407.03056v1)|null|
|**2024-07-03**|**Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment**|Janghwan Lee et.al.|[2407.03051v1](http://arxiv.org/abs/2407.03051v1)|null|
|**2024-07-03**|**JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets**|Zhihua Jin et.al.|[2407.03045v1](http://arxiv.org/abs/2407.03045v1)|null|
|**2024-07-03**|**Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model**|Xia Hou et.al.|[2407.03040v1](http://arxiv.org/abs/2407.03040v1)|null|
|**2024-07-03**|**On the Client Preference of LLM Fine-tuning in Federated Learning**|Feijie Wu et.al.|[2407.03038v1](http://arxiv.org/abs/2407.03038v1)|null|
|**2024-07-03**|**NLP Sampling: Combining MCMC and NLP Methods for Diverse Constrained Sampling**|Marc Toussaint et.al.|[2407.03035v1](http://arxiv.org/abs/2407.03035v1)|null|
|**2024-07-03**|**Strategies for Arabic Readability Modeling**|Juan Piñeros Liberato et.al.|[2407.03032v1](http://arxiv.org/abs/2407.03032v1)|null|
|**2024-07-03**|**Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition**|Jinming Chen et.al.|[2407.03026v1](http://arxiv.org/abs/2407.03026v1)|null|
|**2024-07-03**|**Exploiting Dialect Identification in Automatic Dialectal Text Normalization**|Bashar Alhafni et.al.|[2407.03020v1](http://arxiv.org/abs/2407.03020v1)|null|
|**2024-07-03**|**An Organism Starts with a Single Pix-Cell: A Neural Cellular Diffusion for High-Resolution Image Synthesis**|Marawan Elbatel et.al.|[2407.03018v1](http://arxiv.org/abs/2407.03018v1)|null|
|**2024-07-03**|**What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks**|Chengrui Huang et.al.|[2407.03007v1](http://arxiv.org/abs/2407.03007v1)|null|
|**2024-07-03**|**Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0**|Marianne de Heer Kloots et.al.|[2407.03005v1](http://arxiv.org/abs/2407.03005v1)|[link](https://github.com/mdhk/phonotactic-sensitivity)|
|**2024-07-03**|**SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**|Meghal Dani et.al.|[2407.03004v1](http://arxiv.org/abs/2407.03004v1)|null|
|**2024-07-03**|**VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values**|Zhe Hu et.al.|[2407.03000v1](http://arxiv.org/abs/2407.03000v1)|null|
|**2024-07-03**|**Are Large Language Models Consistent over Value-laden Questions?**|Jared Moore et.al.|[2407.02996v1](http://arxiv.org/abs/2407.02996v1)|null|
|**2024-07-03**|**MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**|Irene Siragusa et.al.|[2407.02994v1](http://arxiv.org/abs/2407.02994v1)|[link](https://github.com/chilab1/medpix-2.0)|
|**2024-07-03**|**LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models**|Hayder Elesedy et.al.|[2407.02987v1](http://arxiv.org/abs/2407.02987v1)|null|
|**2024-07-03**|**Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text**|Jainit Sushil Bafna et.al.|[2407.02978v1](http://arxiv.org/abs/2407.02978v1)|null|
|**2024-07-03**|**Large Language Models as Evaluators for Scientific Synthesis**|Julia Evans et.al.|[2407.02977v1](http://arxiv.org/abs/2407.02977v1)|null|
|**2024-07-03**|**Unified Anomaly Detection methods on Edge Device using Knowledge Distillation and Quantization**|Sushovan Jena et.al.|[2407.02968v1](http://arxiv.org/abs/2407.02968v1)|null|
|**2024-07-03**|**FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering**|Xiaochen Wang et.al.|[2407.02964v1](http://arxiv.org/abs/2407.02964v1)|null|
|**2024-07-03**|**Towards a Scalable Reference-Free Evaluation of Generative Models**|Azim Ospanov et.al.|[2407.02961v1](http://arxiv.org/abs/2407.02961v1)|[link](https://github.com/aziksh-ospanov/fkea)|
|**2024-07-03**|**ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets**|Ahmed Frikha et.al.|[2407.02960v1](http://arxiv.org/abs/2407.02960v1)|null|
|**2024-07-03**|**IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization**|Ahmed Frikha et.al.|[2407.02956v1](http://arxiv.org/abs/2407.02956v1)|null|
|**2024-07-03**|**PII-Compass: Guiding LLM training data extraction prompts towards the target PII via grounding**|Krishna Kanth Nakka et.al.|[2407.02943v1](http://arxiv.org/abs/2407.02943v1)|null|
|**2024-07-03**|**Probing the Feasibility of Multilingual Speaker Anonymization**|Sarina Meyer et.al.|[2407.02937v1](http://arxiv.org/abs/2407.02937v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**SFC: Achieve Accurate Fast Convolution under Low-precision Arithmetic**|Liulu He et.al.|[2407.02913v1](http://arxiv.org/abs/2407.02913v1)|null|
|**2024-07-03**|**Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation**|Zhibin Lan et.al.|[2407.02894v1](http://arxiv.org/abs/2407.02894v1)|[link](https://github.com/deeplearnxmu/translatotron-v)|
|**2024-07-03**|**GPTQT: Quantize Large Language Models Twice to Push the Efficiency**|Yipin Guo et.al.|[2407.02891v1](http://arxiv.org/abs/2407.02891v1)|null|
|**2024-07-03**|**Joint Optimization of Resource Allocation and Data Selection for Fast and Cost-Efficient Federated Edge Learning**|Yunjian Jia et.al.|[2407.02888v1](http://arxiv.org/abs/2407.02888v1)|null|
|**2024-07-03**|**CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics**|Azmine Toushik Wasi et.al.|[2407.02885v1](http://arxiv.org/abs/2407.02885v1)|null|
|**2024-07-03**|**Complex Event Recognition with Symbolic Register Transducers: Extended Technical Report**|Elias Alevizos et.al.|[2407.02884v1](http://arxiv.org/abs/2407.02884v1)|[link](https://github.com/elalev/cer-srt)|
|**2024-07-03**|**CoIR: A Comprehensive Benchmark for Code Information Retrieval Models**|Xiangyang Li et.al.|[2407.02883v1](http://arxiv.org/abs/2407.02883v1)|[link](https://github.com/coir-team/coir)|
|**2024-07-03**|**ShiftAddAug: Augment Multiplication-Free Tiny Neural Network with Hybrid Computation**|Yipin Guo et.al.|[2407.02881v1](http://arxiv.org/abs/2407.02881v1)|null|
|**2024-07-03**|**Knowledge Composition using Task Vectors with Learned Anisotropic Scaling**|Frederic Z. Zhang et.al.|[2407.02880v1](http://arxiv.org/abs/2407.02880v1)|[link](https://github.com/fredzzhang/atlas)|
|**2024-07-03**|**Membership Inference Attacks Against Time-Series Models**|Noam Koren et.al.|[2407.02870v1](http://arxiv.org/abs/2407.02870v1)|null|
|**2024-07-03**|**Fast maneuver recovery from aerial observation: trajectory clustering and outliers rejection**|Nelson de Moura et.al.|[2407.02863v1](http://arxiv.org/abs/2407.02863v1)|null|
|**2024-07-03**|**Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks**|Zhexin Zhang et.al.|[2407.02855v1](http://arxiv.org/abs/2407.02855v1)|[link](https://github.com/thu-coai/safeunlearning)|
|**2024-07-03**|**Universal Gloss-level Representation for Gloss-free Sign Language Translation and Production**|Eui Jun Hwang et.al.|[2407.02854v1](http://arxiv.org/abs/2407.02854v1)|null|
|**2024-07-03**|**MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis**|Lei Chen et.al.|[2407.02842v1](http://arxiv.org/abs/2407.02842v1)|null|
|**2024-07-03**|**LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation**|Hongke Zhao et.al.|[2407.02833v1](http://arxiv.org/abs/2407.02833v1)|null|
|**2024-07-03**|**Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**|Negin Ashrafi et.al.|[2407.02821v1](http://arxiv.org/abs/2407.02821v1)|null|
|**2024-07-03**|**Investigating the Contextualised Word Embedding Dimensions Responsible for Contextual and Temporal Semantic Changes**|Taichi Aida et.al.|[2407.02820v1](http://arxiv.org/abs/2407.02820v1)|[link](https://github.com/livnlp/svp-dims)|
|**2024-07-03**|**Efficient Training of Language Models with Compact and Consistent Next Token Distributions**|Ashutosh Sathe et.al.|[2407.02819v1](http://arxiv.org/abs/2407.02819v1)|null|
|**2024-07-03**|**Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective**|Zhaotian Weng et.al.|[2407.02814v1](http://arxiv.org/abs/2407.02814v1)|null|
|**2024-07-03**|**Data Overfitting for On-Device Super-Resolution with Dynamic Algorithm and Compiler Co-Design**|Gen Li et.al.|[2407.02813v1](http://arxiv.org/abs/2407.02813v1)|[link](https://github.com/coulsonlee/dy-dca-eccv2024)|
|**2024-07-03**|**Efficient DNN-Powered Software with Fair Sparse Models**|Xuanqi Gao et.al.|[2407.02805v1](http://arxiv.org/abs/2407.02805v1)|null|
|**2024-07-03**|**Model-Enhanced LLM-Driven VUI Testing of VPA Apps**|Suwan Li et.al.|[2407.02791v1](http://arxiv.org/abs/2407.02791v1)|null|
|**2024-07-03**|**52B to 1T: Lessons Learned via Tele-FLM Series**|Xiang Li et.al.|[2407.02783v1](http://arxiv.org/abs/2407.02783v1)|null|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-03**|**A Framework for Quantum Finite-State Languages with Density Mapping**|SeungYeop Baik et.al.|[2407.02776v1](http://arxiv.org/abs/2407.02776v1)|[link](https://github.com/sybaik1/qfa-toolkit)|
|**2024-07-03**|**MLKD-BERT: Multi-level Knowledge Distillation for Pre-trained Language Models**|Ying Zhang et.al.|[2407.02775v1](http://arxiv.org/abs/2407.02775v1)|null|
|**2024-07-03**|**Automatic gradient descent with generalized Newton's method**|Zhiqi Bu et.al.|[2407.02772v1](http://arxiv.org/abs/2407.02772v1)|null|
|**2024-07-03**|**SF-GNN: Self Filter for Message Lossless Propagation in Deep Graph Neural Network**|Yushan Zhu et.al.|[2407.02762v1](http://arxiv.org/abs/2407.02762v1)|null|
|**2024-07-03**|**Emotion and Intent Joint Understanding in Multimodal Conversation: A Benchmarking Dataset**|Rui Liu et.al.|[2407.02751v1](http://arxiv.org/abs/2407.02751v1)|[link](https://github.com/mc-eiu/mc-eiu)|
|**2024-07-03**|**Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data**|Younghun Lee et.al.|[2407.02750v1](http://arxiv.org/abs/2407.02750v1)|null|

#### Abstracts
##### **Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages**
2407.03321v1 by Max Zuo, Francisco Piedrahita Velez, Xiaochen Li, Michael L. Littman, Stephen H. Bach

Many recent works have explored using language models for planning problems.
One line of research focuses on translating natural language descriptions of
planning tasks into structured planning languages, such as the planning domain
definition language (PDDL). While this approach is promising, accurately
measuring the quality of generated PDDL code continues to pose significant
challenges. First, generated PDDL code is typically evaluated using planning
validators that check whether the problem can be solved with a planner. This
method is insufficient because a language model might generate valid PDDL code
that does not align with the natural language description of the task. Second,
existing evaluation sets often have natural language descriptions of the
planning task that closely resemble the ground truth PDDL, reducing the
challenge of the task. To bridge this gap, we introduce \benchmarkName, a
benchmark designed to evaluate language models' ability to generate PDDL code
from natural language descriptions of planning tasks. We begin by creating a
PDDL equivalence algorithm that rigorously evaluates the correctness of PDDL
code generated by language models by flexibly comparing it against a ground
truth PDDL. Then, we present a dataset of $132,037$ text-to-PDDL pairs across
13 different tasks, with varying levels of difficulty. Finally, we evaluate
several API-access and open-weight language models that reveal this task's
complexity. For example, $87.6\%$ of the PDDL problem descriptions generated by
GPT-4o are syntactically parseable, $82.2\%$ are valid, solve-able problems,
but only $35.1\%$ are semantically correct, highlighting the need for a more
rigorous benchmark for this problem.

摘要：許多近期研究已探討使用語言模型解決規劃問題。
其中一項研究重點在於將規劃任務的自然語言描述轉換為結構化規劃語言，例如規劃領域定義語言 (PDDL)。雖然此方法很有前景，但精確衡量所產生 PDDL 程式碼的品質仍是一項重大挑戰。首先，產生的 PDDL 程式碼通常使用規劃驗證器進行評估，檢查規劃器是否能解決問題。這種方法並不足夠，因為語言模型可能會產生有效的 PDDL 程式碼，但與任務的自然語言描述不符。其次，現有的評估集通常有規劃任務的自然語言描述，與真實 PDDL 非常相似，降低了任務的挑戰性。為了彌補這個差距，我們引入了 \benchmarkName，這是一個基準，用於評估語言模型從規劃任務的自然語言描述產生 PDDL 程式碼的能力。我們首先建立一個 PDDL 等價演算法，透過靈活地將其與真實 PDDL 進行比較，嚴格評估語言模型產生的 PDDL 程式碼的正確性。接著，我們提供一個包含 13 個不同任務的 132,037 個文字轉 PDDL 配對的資料集，難度程度不一。最後，我們評估了幾個 API 存取和開放權重語言模型，揭示了此任務的複雜性。例如，GPT-4o 產生的 PDDL 問題描述中有 87.6% 在語法上可以解析，82.2% 是有效且可以解決的問題，但只有 35.1% 在語義上正確，突顯出需要一個更嚴格的基準來解決這個問題。

##### **InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output**
2407.03320v1 by Pan Zhang, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Rui Qian, Lin Chen, Qipeng Guo, Haodong Duan, Bin Wang, Linke Ouyang, Songyang Zhang, Wenwei Zhang, Yining Li, Yang Gao, Peng Sun, Xinyue Zhang, Wei Li, Jingwen Li, Wenhai Wang, Hang Yan, Conghui He, Xingcheng Zhang, Kai Chen, Jifeng Dai, Yu Qiao, Dahua Lin, Jiaqi Wang

We present InternLM-XComposer-2.5 (IXC-2.5), a versatile large-vision
language model that supports long-contextual input and output. IXC-2.5 excels
in various text-image comprehension and composition applications, achieving
GPT-4V level capabilities with merely 7B LLM backend. Trained with 24K
interleaved image-text contexts, it can seamlessly extend to 96K long contexts
via RoPE extrapolation. This long-context capability allows IXC-2.5 to excel in
tasks requiring extensive input and output contexts. Compared to its previous
2.0 version, InternLM-XComposer-2.5 features three major upgrades in
vision-language comprehension: (1) Ultra-High Resolution Understanding, (2)
Fine-Grained Video Understanding, and (3) Multi-Turn Multi-Image Dialogue. In
addition to comprehension, IXC-2.5 extends to two compelling applications using
extra LoRA parameters for text-image composition: (1) Crafting Webpages and (2)
Composing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28
benchmarks, outperforming existing open-source state-of-the-art models on 16
benchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on
16 key tasks. The InternLM-XComposer-2.5 is publicly available at
https://github.com/InternLM/InternLM-XComposer.

摘要：<paragraph>我們提出 InternLM-XComposer-2.5 (IXC-2.5)，一個多功能的大型視覺語言模型，支援長脈絡輸入和輸出。IXC-2.5 在各種文本影像理解和編寫應用中表現出色，僅使用 7B LLM 後端，便能達到 GPT-4V 等級的能力。透過 24K 交錯影像文字脈絡訓練，它可以透過 RoPE 外推無縫擴展到 96K 長脈絡。這種長脈絡能力讓 IXC-2.5 能在需要大量輸入和輸出脈絡的任務中表現出色。與先前的 2.0 版本相比，InternLM-XComposer-2.5 在視覺語言理解方面有三大主要升級：(1) 超高解析度理解，(2) 細緻影片理解，(3) 多輪多影像對話。除了理解之外，IXC-2.5 還擴展到兩個引人注目的應用，使用額外的 LoRA 參數進行文本影像編寫：(1) 建構網頁，(2) 編寫高品質文本影像文章。IXC-2.5 已在 28 個基準上進行評估，在 16 個基準上優於現有的開源最先進模型。它也在 16 個主要任務上超越或接近 GPT-4V 和 Gemini Pro。InternLM-XComposer-2.5 已公開發布於 https://github.com/InternLM/InternLM-XComposer。</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

摘要：本文提出 Bag-of-Concept Graph (BACON)，赋予语言能力有限的模型品尝视觉语言模型 (VLM) 的特权，并提升下游任务，例如检测、视觉问答 (VQA) 和图像生成。由于物理世界中的视觉场景是由对象之间的复杂关系构建而成的，因此 BACON 将注释分解为基本的最小元素，并以图形结构呈现它们。基于元素的风格便于理解，结构化组合解放了困难的定位。在公共可用 VLM 和分割方法的帮助下，精心设计的提示生成了 BACON 标题。通过这种方式，我们收集了一个包含 100K 张注释图像的数据集，该数据集赋予 VLM 显著的能力，例如准确生成 BACON、将提示转换为 BACON 格式、以 BACONr 的风格设想场景，以及通过交互式对话动态修改 BACON 中的元素等等。广泛的代表性实验，包括检测、VQA 和图像生成任务，表明 BACON 作为一条生命线，可以实现以前无法实现的任务，或在当前的尖端解决方案中表现出色。

##### **Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**
2407.03308v1 by Sijie Xu, Shenyan Zong, Chang-Sheng Mei, Guofeng Shen, Yueran Zhao, He Wang

Proton resonance frequency (PRF) based MR thermometry is essential for
focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance
temporal resolution in dynamic MR temperature map reconstruction using an
improved deep learning method. The training-optimized methods and five
classical neural networks were applied on the 2-fold and 4-fold under-sampling
k-space data to reconstruct the temperature maps. The enhanced training modules
included offline/online data augmentations, knowledge distillation, and the
amplitude-phase decoupling loss function. The heating experiments were
performed by a FUS transducer on phantom and ex vivo tissues, respectively.
These data were manually under-sampled to imitate acceleration procedures and
trained in our method to get the reconstruction model. The additional dozen or
so testing datasets were separately obtained for evaluating the real-time
performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were
found for 2 times and 4 times k-space under-sampling strategies and the
ResUNet-based deep learning reconstruction performed exceptionally well. In
2-fold acceleration scenario, the RMSE of temperature map patches provided the
values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex
vivo testing datasets. The DICE value of temperature areas enclosed by 43
degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a
bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree
centigrade. In 4 times under-sampling case, these evaluating values decreased
by approximately 10%. This study demonstrates that deep learning-based
reconstruction can significantly enhance the accuracy and efficiency of MR
thermometry for clinical FUS thermal therapies.

摘要：基於質子共振頻率 (PRF) 的 MR 溫度測量對於聚焦超音波 (FUS) 熱消融療法至關重要。這項研究旨在透過改善深度學習方法，提升動態 MR 溫度圖重建中的時間解析度。在 2 倍和 4 倍的 k-space 資料不足採樣中，將訓練最佳化方法和五個傳統神經網路應用於重建溫度圖。增強的訓練模組包括離線/線上資料擴充、知識萃取，以及振幅相位解耦損失函數。加熱實驗分別由 FUS 換能器在模擬人體和離體組織上執行。這些資料經過手動不足採樣以模擬加速程序，並在我們的模型中進行訓練以取得重建模型。額外的十幾個測試資料集則另外取得，用於評估即時效能和溫度準確度。在 2 倍和 4 倍 k-space 不足採樣策略中，發現加速因子為 1.9 和 3.7，而基於 ResUNet 的深度學習重建表現得非常好。在 2 倍加速情境中，溫度圖區塊的 RMSE 在模擬人體和離體測試資料集上提供 0.888 度攝氏和 1.145 度攝氏的值。溫度區域的 DICE 值，以 43 度攝氏等溫線包覆，為 0.809，而 Bland-Altman 分析顯示偏差為 -0.253 度攝氏，加上或減去 2.16 度攝氏。在 4 倍不足採樣案例中，這些評估值減少了大約 10%。這項研究證明，基於深度學習的重建可以大幅提升臨床 FUS 熱療中 MR 溫度測量的準確度和效率。

##### **A Review of the Applications of Deep Learning-Based Emergent Communication**
2407.03302v1 by Brendon Boldt, David Mortensen

Emergent communication, or emergent language, is the field of research which
studies how human language-like communication systems emerge de novo in deep
multi-agent reinforcement learning environments. The possibilities of
replicating the emergence of a complex behavior like language have strong
intuitive appeal, yet it is necessary to complement this with clear notions of
how such research can be applicable to other fields of science, technology, and
engineering. This paper comprehensively reviews the applications of emergent
communication research across machine learning, natural language processing,
linguistics, and cognitive science. Each application is illustrated with a
description of its scope, an explication of emergent communication's unique
role in addressing it, a summary of the extant literature working towards the
application, and brief recommendations for near-term research directions.

摘要：新興溝通，或新興語言，是研究人類語言類型的溝通系統如何在深度多重代理強化學習環境中從頭開始出現的研究領域。複製語言等複雜行為出現的可能性具有強烈的直覺吸引力，然而有必要補充明確的概念，說明此類研究如何適用於其他科學、技術和工程領域。本文全面回顧了新興溝通研究在機器學習、自然語言處理、語言學和認知科學中的應用。每個應用程式都附有其範圍說明、新興溝通在解決它時獨特角色的說明、致力於應用程式的既有文獻摘要，以及近期研究方向的簡要建議。

##### **DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents**
2407.03300v1 by Yilun Xu, Gabriele Corso, Tommi Jaakkola, Arash Vahdat, Karsten Kreis

Diffusion models (DMs) have revolutionized generative learning. They utilize
a diffusion process to encode data into a simple Gaussian distribution.
However, encoding a complex, potentially multimodal data distribution into a
single continuous Gaussian distribution arguably represents an unnecessarily
challenging learning problem. We propose Discrete-Continuous Latent Variable
Diffusion Models (DisCo-Diff) to simplify this task by introducing
complementary discrete latent variables. We augment DMs with learnable discrete
latents, inferred with an encoder, and train DM and encoder end-to-end.
DisCo-Diff does not rely on pre-trained networks, making the framework
universally applicable. The discrete latents significantly simplify learning
the DM's complex noise-to-data mapping by reducing the curvature of the DM's
generative ODE. An additional autoregressive transformer models the
distribution of the discrete latents, a simple step because DisCo-Diff requires
only few discrete variables with small codebooks. We validate DisCo-Diff on toy
data, several image synthesis tasks as well as molecular docking, and find that
introducing discrete latents consistently improves model performance. For
example, DisCo-Diff achieves state-of-the-art FID scores on class-conditioned
ImageNet-64/128 datasets with ODE sampler.

摘要：擴散模型 (DM) 徹底改變了生成式學習。它們利用擴散過程將資料編碼成一個簡單的高斯分佈。然而，將一個複雜、潛在多模態的資料分佈編碼成一個單一的連續高斯分佈，可以說是代表了一個不必要的具有挑戰性的學習問題。我們提出離散連續潛在變數擴散模型 (DisCo-Diff)，藉由引入互補的離散潛在變數來簡化這項任務。我們使用可學習的離散潛在變數擴充 DM，並使用編碼器推論，然後端對端訓練 DM 和編碼器。DisCo-Diff 不依賴於預先訓練的網路，讓框架普遍適用。離散潛在變數透過降低 DM 生成 ODE 的曲率，大幅簡化學習 DM 的複雜雜訊對資料對應。一個額外的自迴歸轉換器對離散潛在變數的分佈進行建模，這是一個簡單的步驟，因為 DisCo-Diff 只需要少數具有小碼冊的離散變數。我們在玩具資料、幾個影像合成任務以及分子對接上驗證 DisCo-Diff，發現引入離散潛在變數會持續改善模型效能。例如，DisCo-Diff 在使用 ODE 採樣器的類條件 ImageNet-64/128 資料集上達到最先進的 FID 分數。

##### **Improved Noise Schedule for Diffusion Training**
2407.03297v1 by Tiankai Hang, Shuyang Gu

Diffusion models have emerged as the de facto choice for generating visual
signals. However, training a single model to predict noise across various
levels poses significant challenges, necessitating numerous iterations and
incurring significant computational costs. Various approaches, such as loss
weighting strategy design and architectural refinements, have been introduced
to expedite convergence. In this study, we propose a novel approach to design
the noise schedule for enhancing the training of diffusion models. Our key
insight is that the importance sampling of the logarithm of the Signal-to-Noise
ratio (logSNR), theoretically equivalent to a modified noise schedule, is
particularly beneficial for training efficiency when increasing the sample
frequency around $\log \text{SNR}=0$. We empirically demonstrate the
superiority of our noise schedule over the standard cosine schedule.
Furthermore, we highlight the advantages of our noise schedule design on the
ImageNet benchmark, showing that the designed schedule consistently benefits
different prediction targets.

摘要：擴散模型已成為生成視覺訊號的事實標準選擇。然而，訓練單一模型來預測各種層級的雜訊會帶來重大挑戰，需要進行多次反覆運算，並產生大量的運算成本。已推出各種方法，例如損失加權策略設計和架構改良，以加速收斂。在本研究中，我們提出一個新的方法來設計雜訊排程，以增強擴散模型的訓練。我們的關鍵見解是，信噪比（logSNR）的對數的重要性抽樣，理論上等於修改後的雜訊排程，在增加 $\log \text{SNR}=0$ 附近的抽樣頻率時，特別有利於訓練效率。我們以經驗證明我們的雜訊排程優於標準餘弦排程。此外，我們強調我們的雜訊排程設計在 ImageNet 基準上的優點，顯示設計的排程持續有利於不同的預測目標。

##### **LLM Internal States Reveal Hallucination Risk Faced With a Query**
2407.03282v1 by Ziwei Ji, Delong Chen, Etsuko Ishii, Samuel Cahyawijaya, Yejin Bang, Bryan Wilie, Pascale Fung

The hallucination problem of Large Language Models (LLMs) significantly
limits their reliability and trustworthiness. Humans have a self-awareness
process that allows us to recognize what we don't know when faced with queries.
Inspired by this, our paper investigates whether LLMs can estimate their own
hallucination risk before response generation. We analyze the internal
mechanisms of LLMs broadly both in terms of training data sources and across 15
diverse Natural Language Generation (NLG) tasks, spanning over 700 datasets.
Our empirical analysis reveals two key insights: (1) LLM internal states
indicate whether they have seen the query in training data or not; and (2) LLM
internal states show they are likely to hallucinate or not regarding the query.
Our study explores particular neurons, activation layers, and tokens that play
a crucial role in the LLM perception of uncertainty and hallucination risk. By
a probing estimator, we leverage LLM self-assessment, achieving an average
hallucination estimation accuracy of 84.32\% at run time.

摘要：大型語言模型（LLM）的幻覺問題顯著地限制了它們的可靠性和可信度。人類具備一種自我覺察的過程，這讓我們在面對問題時能夠認知到自己的無知。受到此啟發，我們的論文探討 LLM 是否可以在產生回應之前評估它們自己的幻覺風險。我們廣泛地分析了 LLM 的內部機制，包括訓練資料來源和橫跨 15 個多元的自然語言生成（NLG）任務，涵蓋超過 700 個資料集。我們的實證分析揭露了兩個關鍵的見解：（1）LLM 內部狀態顯示它們是否在訓練資料中見過該問題；以及（2）LLM 內部狀態顯示它們是否可能對該問題產生幻覺。我們的研究探討了特定神經元、激活層和符號，這些在 LLM 對不確定性和幻覺風險的感知中扮演了關鍵角色。藉由一個探測估計器，我們利用 LLM 自我評估，在執行時達成平均 84.32% 的幻覺估計準確度。

##### **STF: Sentence Transformer Fine-Tuning For Topic Categorization With Limited Data**
2407.03253v1 by Kheir Eddine Daouadi, Yaakoub Boualleg, Oussama Guehairia

Nowadays, topic classification from tweets attracts considerable research
attention. Different classification systems have been suggested thanks to these
research efforts. Nevertheless, they face major challenges owing to low
performance metrics due to the limited amount of labeled data. We propose
Sentence Transformers Fine-tuning (STF), a topic detection system that
leverages pretrained Sentence Transformers models and fine-tuning to classify
topics from tweets accurately. Moreover, extensive parameter sensitivity
analyses were conducted to finetune STF parameters for our topic classification
task to achieve the best performance results. Experiments on two benchmark
datasets demonstrated that (1) the proposed STF can be effectively used for
classifying tweet topics and outperforms the latest state-of-the-art
approaches, and (2) the proposed STF does not require a huge amount of labeled
tweets to achieve good accuracy, which is a limitation of many state-of-the-art
approaches. Our main contribution is the achievement of promising results in
tweet topic classification by applying pretrained sentence transformers
language models.

摘要：如今，从推文中进行主题分类引起了相当大的研究关注。由于这些研究工作，已经提出了不同的分类系统。然而，由于标记数据量有限，它们面临着因性能指标低而带来的重大挑战。我们提出了句子转换器微调 (STF)，这是一种主题检测系统，它利用预训练的句子转换器模型和微调来准确地对推文中的主题进行分类。此外，进行了广泛的参数敏感性分析，以微调用于主题分类任务的 STF 参数，以实现最佳性能结果。在两个基准数据集上的实验表明：(1) 提出的 STF 可有效用于对推文主题进行分类，并且优于最新的最先进方法；(2) 提出的 STF 不需要大量标记推文就能实现良好的准确性，这是许多最先进方法的限制。我们的主要贡献是通过应用预训练的句子转换器语言模型在推文主题分类中取得了有希望的结果。

##### **CATT: Character-based Arabic Tashkeel Transformer**
2407.03236v1 by Faris Alasmary, Orjuwan Zaafarani, Ahmad Ghannam

Tashkeel, or Arabic Text Diacritization (ATD), greatly enhances the
comprehension of Arabic text by removing ambiguity and minimizing the risk of
misinterpretations caused by its absence. It plays a crucial role in improving
Arabic text processing, particularly in applications such as text-to-speech and
machine translation. This paper introduces a new approach to training ATD
models. First, we finetuned two transformers, encoder-only and encoder-decoder,
that were initialized from a pretrained character-based BERT. Then, we applied
the Noisy-Student approach to boost the performance of the best model. We
evaluated our models alongside 11 commercial and open-source models using two
manually labeled benchmark datasets: WikiNews and our CATT dataset. Our
findings show that our top model surpasses all evaluated models by relative
Diacritic Error Rates (DERs) of 30.83\% and 35.21\% on WikiNews and CATT,
respectively, achieving state-of-the-art in ATD. In addition, we show that our
model outperforms GPT-4-turbo on CATT dataset by a relative DER of 9.36\%. We
open-source our CATT models and benchmark dataset for the research
community\footnote{https://github.com/abjadai/catt}.

摘要：塔什基爾，或阿拉伯語文本附加符號 (ATD)，透過消除歧義並將其缺失造成的誤解風險降至最低，大幅提升阿拉伯語文本的理解度。它在改善阿拉伯語文本處理方面發揮至關重要的作用，特別是在文字轉語音和機器翻譯等應用中。本文介紹一種訓練 ATD 模型的新方法。首先，我們微調了兩個Transformer，僅編碼器和編碼器-解碼器，這些Transformer是從預訓練的基於字元的 BERT 初始化的。然後，我們應用 Noisy-Student 方法來提升最佳模型的效能。我們使用兩個手動標記基準資料集：WikiNews 和我們的 CATT 資料集，對我們的模型與 11 個商業和開放原始碼模型進行評估。我們的研究結果顯示，我們的頂尖模型在 WikiNews 和 CATT 上分別以 30.83% 和 35.21% 的相對附加符號錯誤率 (DER) 超越所有評估模型，在 ATD 中達到最先進的技術。此外，我們顯示我們的模型在 CATT 資料集上以 9.36% 的相對 DER 優於 GPT-4-turbo。我們開放原始碼我們的 CATT 模型和基準資料集，供研究社群使用\footnote{https://github.com/abjadai/catt}。

##### **Self-Evaluation as a Defense Against Adversarial Attacks on LLMs**
2407.03234v1 by Hannah Brown, Leon Lin, Kenji Kawaguchi, Michael Shieh

When LLMs are deployed in sensitive, human-facing settings, it is crucial
that they do not output unsafe, biased, or privacy-violating outputs. For this
reason, models are both trained and instructed to refuse to answer unsafe
prompts such as "Tell me how to build a bomb." We find that, despite these
safeguards, it is possible to break model defenses simply by appending a space
to the end of a model's input. In a study of eight open-source models, we
demonstrate that this acts as a strong enough attack to cause the majority of
models to generate harmful outputs with very high success rates. We examine the
causes of this behavior, finding that the contexts in which single spaces occur
in tokenized training data encourage models to generate lists when prompted,
overriding training signals to refuse to answer unsafe requests. Our findings
underscore the fragile state of current model alignment and promote the
importance of developing more robust alignment methods. Code and data will be
made available at https://github.com/Linlt-leon/Adversarial-Alignments.

摘要：當 LLM 部署在敏感的、面向人類的環境中時，至關重要的是，它們不會輸出不安全、有偏差或侵犯隱私的輸出。因此，模型經過訓練和指導，拒絕回答不安全的提示，例如「告訴我如何製造炸彈」。我們發現，儘管有這些防護措施，但只需在模型輸入的末尾添加一個空格，就可以突破模型防禦。在對八個開源模型的研究中，我們證明這是一種足夠強大的攻擊，可以導致大多數模型以非常高的成功率生成有害輸出。我們檢查了這種行為的原因，發現單個空格出現在標記化訓練數據中的上下文會鼓勵模型在提示時生成列表，覆寫訓練信號以拒絕回答不安全的請求。我們的發現強調了當前模型對齊的脆弱狀態，並促進了開發更強大的對齊方法的重要性。代碼和數據將在 https://github.com/Linlt-leon/Adversarial-Alignments 上提供。

##### **Single Character Perturbations Break LLM Alignment**
2407.03232v1 by Leon Lin, Hannah Brown, Kenji Kawaguchi, Michael Shieh

When LLMs are deployed in sensitive, human-facing settings, it is crucial
that they do not output unsafe, biased, or privacy-violating outputs. For this
reason, models are both trained and instructed to refuse to answer unsafe
prompts such as "Tell me how to build a bomb." We find that, despite these
safeguards, it is possible to break model defenses simply by appending a space
to the end of a model's input. In a study of eight open-source models, we
demonstrate that this acts as a strong enough attack to cause the majority of
models to generate harmful outputs with very high success rates. We examine the
causes of this behavior, finding that the contexts in which single spaces occur
in tokenized training data encourage models to generate lists when prompted,
overriding training signals to refuse to answer unsafe requests. Our findings
underscore the fragile state of current model alignment and promote the
importance of developing more robust alignment methods. Code and data will be
available at https://github.com/hannah-aught/space_attack.

摘要：當 LLM 部署在敏感的人類面對的環境中時，至關重要的是，它們不會輸出不安全、有偏見或侵犯隱私的輸出。出於這個原因，模型經過訓練和指示，拒絕回答不安全的提示，例如「告訴我如何製造炸彈」。我們發現，儘管有這些保障措施，但只要在模型輸入的結尾加上一個空格，就可以突破模型防禦。在對八個開源模型的研究中，我們證明這是一個足夠強大的攻擊，可以導致大多數模型以非常高的成功率產生有害的輸出。我們檢查了這種行為的原因，發現單個空格出現在標記化訓練數據中的上下文會鼓勵模型在提示時生成列表，覆蓋拒絕回答不安全請求的訓練信號。我們的發現強調了當前模型對齊的脆弱狀態，並促進了開發更強大的對齊方法的重要性。程式碼和數據將在 https://github.com/hannah-aught/space_attack 取得。

##### **Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning**
2407.03227v1 by Zhili Shen, Pavlos Vougiouklis, Chenxin Diao, Kaustubh Vyas, Yuanyi Ji, Jeff Z. Pan

We focus on Text-to-SQL semantic parsing from the perspective of Large
Language Models. Motivated by challenges related to the size of commercial
database schemata and the deployability of business intelligence solutions, we
propose an approach that dynamically retrieves input database information and
uses abstract syntax trees to select few-shot examples for in-context learning.
  Furthermore, we investigate the extent to which an in-parallel semantic
parser can be leveraged for generating $\textit{approximated}$ versions of the
expected SQL queries, to support our retrieval. We take this approach to the
extreme--we adapt a model consisting of less than $500$M parameters, to act as
an extremely efficient approximator, enhancing it with the ability to process
schemata in a parallelised manner. We apply our approach to monolingual and
cross-lingual benchmarks for semantic parsing, showing improvements over
state-of-the-art baselines. Comprehensive experiments highlight the
contribution of modules involved in this retrieval-augmented generation
setting, revealing interesting directions for future work.

摘要：我們從大型語言模型的角度專注於文字轉 SQL 語意的解析。由於商業資料庫模式的大小和商業智慧解決方案的可部署性相關的挑戰，我們提出了一種動態擷取輸入資料庫資訊的方法，並使用抽象語法樹來選擇少數範例進行情境學習。
此外，我們探討了平行語意解析器在多大程度上可用於產生預期 SQL 查詢的「近似」版本，以支援我們的擷取。我們將這種方法發揮到極致 - 我們調整了一個小於 500M 參數的模型，使其作為一個極有效率的近似器，並增強其並行處理模式的能力。我們將我們的做法應用於語意解析的單語和跨語言基準，顯示出比最先進的基準線有改進。全面的實驗突出了參與此擷取增強產生設定的模組的貢獻，揭示了未來工作的有趣方向。

##### **PPO-based Dynamic Control of Uncertain Floating Platforms in the Zero-G Environment**
2407.03224v1 by Mahya Ramezani, M. Amin Alandihallaj, Andreas M. Hein

In the field of space exploration, floating platforms play a crucial role in
scientific investigations and technological advancements. However, controlling
these platforms in zero-gravity environments presents unique challenges,
including uncertainties and disturbances. This paper introduces an innovative
approach that combines Proximal Policy Optimization (PPO) with Model Predictive
Control (MPC) in the zero-gravity laboratory (Zero-G Lab) at the University of
Luxembourg. This approach leverages PPO's reinforcement learning power and
MPC's precision to navigate the complex control dynamics of floating platforms.
Unlike traditional control methods, this PPO-MPC approach learns from MPC
predictions, adapting to unmodeled dynamics and disturbances, resulting in a
resilient control framework tailored to the zero-gravity environment.
Simulations and experiments in the Zero-G Lab validate this approach,
showcasing the adaptability of the PPO agent. This research opens new
possibilities for controlling floating platforms in zero-gravity settings,
promising advancements in space exploration.

摘要：在太空探索領域中，浮動平台在科學調查和技術進步中扮演著至關重要的角色。然而，在零重力環境中控制這些平台會產生獨特的挑戰，包括不確定性和干擾。本文介紹了一種創新的方法，它結合了近端策略最佳化（PPO）與模型預測控制（MPC），並在盧森堡大學的零重力實驗室（Zero-G Lab）中進行。此方法利用了 PPO 的強化學習能力和 MPC 的精確度來導航浮動平台的複雜控制動態。與傳統的控制方法不同，此 PPO-MPC 方法從 MPC 預測中學習，適應未建模的動態和干擾，從而形成一個專門針對零重力環境的彈性控制架構。零重力實驗室中的模擬和實驗驗證了此方法，展示了 PPO 代理的適應性。這項研究為在零重力環境中控制浮動平台開啟了新的可能性，有望推動太空探索的進步。

##### **Learning Disentangled Representation in Object-Centric Models for Visual Dynamics Prediction via Transformers**
2407.03216v1 by Sanket Gandhi, Atul, Samanyu Mahajan, Vishal Sharma, Rushil Gupta, Arnab Kumar Mondal, Parag Singla

Recent work has shown that object-centric representations can greatly help
improve the accuracy of learning dynamics while also bringing interpretability.
In this work, we take this idea one step further, ask the following question:
"can learning disentangled representation further improve the accuracy of
visual dynamics prediction in object-centric models?" While there has been some
attempt to learn such disentangled representations for the case of static
images \citep{nsb}, to the best of our knowledge, ours is the first work which
tries to do this in a general setting for video, without making any specific
assumptions about the kind of attributes that an object might have. The key
building block of our architecture is the notion of a {\em block}, where
several blocks together constitute an object. Each block is represented as a
linear combination of a given number of learnable concept vectors, which is
iteratively refined during the learning process. The blocks in our model are
discovered in an unsupervised manner, by attending over object masks, in a
style similar to discovery of slots \citep{slot_attention}, for learning a
dense object-centric representation. We employ self-attention via transformers
over the discovered blocks to predict the next state resulting in discovery of
visual dynamics. We perform a series of experiments on several benchmark 2-D,
and 3-D datasets demonstrating that our architecture (1) can discover
semantically meaningful blocks (2) help improve accuracy of dynamics prediction
compared to SOTA object-centric models (3) perform significantly better in OOD
setting where the specific attribute combinations are not seen earlier during
training. Our experiments highlight the importance discovery of disentangled
representation for visual dynamics prediction.

摘要：<paragraph>最近的研究表明，以对象为中心的表示可以极大地帮助提高学习动态的准确性，同时带来可解释性。在这项工作中，我们将这个想法更进一步，提出以下问题：“学习解开的表示是否可以进一步提高以对象为中心的模型中视觉动态预测的准确性？”虽然有人尝试学习静态图像的这种解开表示\citep{nsb}，但据我们所知，我们的工作是第一个尝试在视频的一般设置中进行此操作，而无需对对象可能具有的属性类型做出任何特定假设。我们架构的关键组成部分是“块”的概念，其中几个块共同构成一个对象。每个块表示为给定数量的可学习概念向量的线性组合，并在学习过程中进行迭代细化。我们模型中的块是以无监督的方式发现的，通过关注对象掩码，类似于发现插槽的样式\citep{slot_attention}，用于学习密集的对象中心表示。我们通过变压器对发现的块进行自注意力，以预测下一个状态，从而发现视觉动态。我们对几个基准 2-D 和 3-D 数据集执行了一系列实验，证明我们的架构（1）可以发现语义上有意义的块（2）与 SOTA 以对象为中心的模型相比，有助于提高动态预测的准确性（3）在 OOD 设置中表现得明显更好，其中特定的属性组合在训练期间没有被看到过。我们的实验突出了解开表示在视觉动态预测中的重要性。</paragraph>

##### **How Does Quantization Affect Multilingual LLMs?**
2407.03211v1 by Kelly Marchisio, Saurabh Dash, Hongyu Chen, Dennis Aumiller, Ahmet Üstün, Sara Hooker, Sebastian Ruder

Quantization techniques are widely used to improve inference speed and
deployment of large language models. While a wide body of work examines the
impact of quantized LLMs on English tasks, none have examined the effect of
quantization across languages. We conduct a thorough analysis of quantized
multilingual LLMs, focusing on their performance across languages and at
varying scales. We use automatic benchmarks, LLM-as-a-Judge methods, and human
evaluation, finding that (1) harmful effects of quantization are apparent in
human evaluation, and automatic metrics severely underestimate the detriment: a
1.7% average drop in Japanese across automatic tasks corresponds to a 16.0%
drop reported by human evaluators on realistic prompts; (2) languages are
disparately affected by quantization, with non-Latin script languages impacted
worst; and (3) challenging tasks such as mathematical reasoning degrade
fastest. As the ability to serve low-compute models is critical for wide global
adoption of NLP technologies, our results urge consideration of multilingual
performance as a key evaluation criterion for efficient models.

摘要：量化技術廣泛用於改善推論速度和部署大型語言模型。雖然有大量研究探討量化 LLM 對英文任務的影響，但沒有任何研究探討量化對跨語言的影響。我們對量化的多語言 LLM 進行了徹底的分析，重點關注它們在不同語言和不同規模上的表現。我們使用自動基準、LLM 作為評判方法和人工評估，發現 (1) 量化的有害影響在人工評估中很明顯，而自動指標嚴重低估了損害：自動任務中日語平均下降 1.7%，而人工評估員在現實提示中報告下降了 16.0%；(2) 語言受到量化的影響不同，非拉丁語系語言受到的影響最嚴重；(3) 數學推理等具有挑戰性的任務下降最快。由於提供低運算模型的能力對於 NLP 技術的廣泛全球採用至關重要，我們的結果敦促將多語言性能視為高效模型的主要評估標準。

##### **TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts**
2407.03203v1 by Ruida Wang, Jipeng Zhang, Yizhen Jia, Rui Pan, Shizhe Diao, Renjie Pi, Tong Zhang

Proving mathematical theorems using computer-verifiable formal languages like
Lean significantly impacts mathematical reasoning. One approach to formal
theorem proving involves generating complete proofs using Large Language Models
(LLMs) based on Natural Language (NL) proofs. Similar methods have shown
promising results in code generation. However, most modern LLMs exhibit
suboptimal performance due to the scarcity of aligned NL and Formal Language
(FL) theorem-proving data. This scarcity results in a paucity of methodologies
for training LLMs and techniques to fully utilize their capabilities in
composing formal proofs. To address the challenges, this paper proposes
**TheoremLlama**, an end-to-end framework to train a general-purpose LLM to
become a Lean4 expert. This framework encompasses NL-FL aligned dataset
generation methods, training approaches for the LLM formal theorem prover, and
techniques for LLM Lean4 proof writing. Using the dataset generation method, we
provide *Open Bootstrapped Theorems* (OBT), an NL-FL aligned and bootstrapped
dataset. A key innovation in this framework is the NL-FL bootstrapping method,
where NL proofs are integrated into Lean4 code for training datasets,
leveraging the NL reasoning ability of LLMs for formal reasoning. The
**TheoremLlama** framework achieves cumulative accuracies of 36.48% and 33.61%
on MiniF2F-Valid and Test datasets respectively, surpassing the GPT-4 baseline
of 22.95% and 25.41%. We have also open-sourced our model checkpoints and
generated dataset, and will soon make all the code publicly available.

摘要：使用像 Lean 這樣的電腦可驗證形式語言來證明數學定理，對數學推理有重大的影響。一種形式定理證明的方法涉及使用基於自然語言 (NL) 證明的巨量語言模型 (LLM) 來產生完整的證明。類似的辦法在程式碼產生方面已展現出有希望的結果。然而，由於對齊的 NL 和形式語言 (FL) 定理證明資料的稀少，大多數現代 LLM 都表現出次佳效能。這種稀少導致了 LLM 訓練方法和充分利用其能力撰寫形式證明的技術的缺乏。為了應對這些挑戰，本文提出了 **TheoremLlama**，一個端到端的架構，用於訓練一個通用 LLM，使其成為 Lean4 專家。此架構包含 NL-FL 對齊資料集產生方法、LLM 形式定理證明器的訓練方法，以及 LLM Lean4 證明撰寫的技術。使用資料集產生方法，我們提供了 *開放式引導定理* (OBT)，一個 NL-FL 對齊且引導的資料集。此架構中的一個關鍵創新是 NL-FL 引導方法，其中 NL 證明被整合到 Lean4 程式碼中以訓練資料集，利用 LLM 的 NL 推理能力進行形式推理。**TheoremLlama** 架構在 MiniF2F-Valid 和 Test 資料集上分別達到了 36.48% 和 33.61% 的累積準確度，超過了 GPT-4 的基準 22.95% 和 25.41%。我們也開源了我們的模型檢查點和產生的資料集，並且很快就會公開所有程式碼。

##### **MuDiT & MuSiT: Alignment with Colloquial Expression in Description-to-Song Generation**
2407.03188v1 by Zihao Wang, Haoxuan Liu, Jiaxing Yu, Tao Zhang, Yan Liu, Kejun Zhang

Amid the rising intersection of generative AI and human artistic processes,
this study probes the critical yet less-explored terrain of alignment in
human-centric automatic song composition. We propose a novel task of Colloquial
Description-to-Song Generation, which focuses on aligning the generated content
with colloquial human expressions. This task is aimed at bridging the gap
between colloquial language understanding and auditory expression within an AI
model, with the ultimate goal of creating songs that accurately satisfy human
auditory expectations and structurally align with musical norms. Current
datasets are limited due to their narrow descriptive scope, semantic gaps and
inaccuracies. To overcome data scarcity in this domain, we present the Caichong
Music Dataset (CaiMD). CaiMD is manually annotated by both professional
musicians and amateurs, offering diverse perspectives and a comprehensive
understanding of colloquial descriptions. Unlike existing datasets pre-set with
expert annotations or auto-generated ones with inherent biases, CaiMD caters
more sufficiently to our purpose of aligning AI-generated music with widespread
user-desired results. Moreover, we propose an innovative single-stage framework
called MuDiT/MuSiT for enabling effective human-machine alignment in song
creation. This framework not only achieves cross-modal comprehension between
colloquial language and auditory music perceptions but also ensures generated
songs align with user-desired results. MuDiT/MuSiT employs one DiT/SiT model
for end-to-end generation of musical components like melody, harmony, rhythm,
vocals, and instrumentation. The approach ensures harmonious sonic cohesiveness
amongst all generated musical components, facilitating better resonance with
human auditory expectations.

摘要：<paragraph>在生成式 AI 和人類藝術流程的交會日益增加的過程中，
這項研究探討了以人為中心的自動歌曲創作中對齊的關鍵但較少探索的領域。我們提出了一項新的任務：口語描述到歌曲生成，其重點在於將生成的內容與口語人類表達方式對齊。此任務旨在彌合 AI 模型中口語語言理解和聽覺表達之間的差距，最終目標是創作出準確滿足人類聽覺期望並在結構上與音樂規範對齊的歌曲。目前的數據集由於其描述範圍狹窄、語義差距和不準確性而受到限制。為了克服此領域的數據稀缺性，我們提出了彩蟲音樂數據集 (CaiMD)。CaiMD 由專業音樂家和業餘愛好者手工註釋，提供了不同的觀點和對口語描述的全面理解。與預設專家註釋或具有內在偏差的自動生成數據集不同，CaiMD 更充分地滿足了我們將 AI 生成的音樂與廣泛用戶期望的結果對齊的目的。此外，我們提出了一個創新的單階段框架，稱為 MuDiT/MuSiT，用於在歌曲創作中實現有效的人機對齊。此框架不僅實現了口語語言和聽覺音樂感知之間的跨模態理解，還確保了生成的歌曲與用戶期望的結果對齊。MuDiT/MuSiT 採用一個 DiT/SiT 模型來端到端生成旋律、和聲、節奏、人聲和配器等音樂組成部分。此方法確保了所有生成的音樂組成部分之間和諧的聲音凝聚力，從而促進了與人類聽覺期望的更好共鳴。</paragraph>

##### **Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing**
2407.03185v1 by Egon Peršak, Miguel F. Anjos, Sebastian Lautz, Aleksandar Kolev

We propose a transformer architecture for time series forecasting with a
focus on time series tokenisation and apply it to a real-world prediction
problem from the pricing domain. Our architecture aims to learn effective
representations at many scales across all available data simultaneously. The
model contains a number of novel modules: a differentiated form of time series
patching which employs multiple resolutions, a multiple-resolution module for
time-varying known variables, a mixer-based module for capturing cross-series
information, and a novel output head with favourable scaling to account for the
increased number of tokens. We present an application of this model to a real
world prediction problem faced by the markdown team at a very large retailer.
On the experiments conducted our model outperforms in-house models and the
selected existing deep learning architectures.

摘要：我們提出一個Transformer架構，用於時間序列預測，重點在於時間序列標記化，並將其應用於定價領域的實際預測問題。我們的架構旨在同時在所有可用資料中學習多個尺度的有效表示。該模型包含許多新穎的模組：一種採用多重解析度的時間序列修補差異化形式、一個用於時變已知變數的多重解析度模組、一個用於擷取跨序列資訊的基於混合器的模組，以及一個具有有利縮放的新穎輸出頭，用於考量增加的標記數量。我們展示了此模型在一個非常大型零售商的降價團隊所面臨的實際預測問題中的應用。在進行的實驗中，我們的模型優於內部模型和選定的現有深度學習架構。

##### **A Formal Model for Artificial Intelligence Applications in Automation Systems**
2407.03183v1 by Marvin Schieseck, Philip Topalis, Lasse Reinpold, Felix Gehlhoff, Alexander Fay

The integration of Artificial Intelligence (AI) into automation systems has
the potential to enhance efficiency and to address currently unsolved existing
technical challenges. However, the industry-wide adoption of AI is hindered by
the lack of standardized documentation for the complex compositions of
automation systems, AI software, production hardware, and their
interdependencies. This paper proposes a formal model using standards and
ontologies to provide clear and structured documentation of AI applications in
automation systems. The proposed information model for artificial intelligence
in automation systems (AIAS) utilizes ontology design patterns to map and link
various aspects of automation systems and AI software. Validated through a
practical example, the model demonstrates its effectiveness in improving
documentation practices and aiding the sustainable implementation of AI in
industrial settings.

摘要：人工智慧 (AI) 整合到自動化系統中，有潛力提升效率，並解決目前現有的未解決技術挑戰。然而，由於缺乏標準化文件說明，說明自動化系統、AI 軟體、生產硬體及其相互依賴性的複雜組成，導致 AI 無法廣泛運用於產業。本文提出一個使用標準和本体的正式模型，提供 AI 在自動化系統中應用的清晰且有條理的文件說明。所提出的自動化系統中人工智慧資訊模型 (AIAS)，利用本体設計模式來對應並連結自動化系統和 AI 軟體的各種面向。透過實際範例驗證，該模型證明其在改善文件說明實務，以及協助 AI 在產業環境中永續實作方面的效用。

##### **Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models**
2407.03181v1 by Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych

Requiring a Large Language Model to generate intermediary reasoning steps has
been shown to be an effective way of boosting performance. In fact, it has been
found that instruction tuning on these intermediary reasoning steps improves
model performance. In this work, we present a novel method of further improving
performance by requiring models to compare multiple reasoning chains before
generating a solution in a single inference step. We call this method Divergent
CoT (DCoT). We find that instruction tuning on DCoT datasets boosts the
performance of even smaller, and therefore more accessible, LLMs. Through a
rigorous set of experiments spanning a wide range of tasks that require various
reasoning types, we show that fine-tuning on DCoT consistently improves
performance over the CoT baseline across model families and scales (1.3B to
70B). Through a combination of empirical and manual evaluation, we additionally
show that these performance gains stem from models generating multiple
divergent reasoning chains in a single inference step, indicative of the
enabling of self-correction in language models. Our code and data are publicly
available at https://github.com/UKPLab/arxiv2024-divergent-cot.

摘要：<paragraph>要求大型语言模型生成中间推理步骤已被证明是提升性能的有效方法。事实上，已经发现对这些中间推理步骤的指令微调可以提升模型性能。在这项工作中，我们提出了一种通过要求模型在单个推理步骤中生成解决方案之前比较多个推理链来进一步提升性能的新方法。我们称这种方法为发散 CoT (DCoT)。我们发现对 DCoT 数据集的指令微调可以提升更小且因此更容易获取的 LLM 的性能。通过一组严格的实验，涵盖需要各种推理类型的广泛任务，我们表明在 DCoT 上进行微调可以持续提升 CoT 基线在模型系列和规模（1.3B 到 70B）上的性能。通过实证和手动评估的结合，我们还表明这些性能提升源于模型在单个推理步骤中生成多个发散推理链，这表明语言模型中启用了自我纠正。我们的代码和数据已公开发布在 https://github.com/UKPLab/arxiv2024-divergent-cot。</paragraph>

##### **A multi-objective combinatorial optimisation framework for large scale hierarchical population synthesis**
2407.03180v1 by Imran Mahmood, Nicholas Bishop, Anisoara Calinescu, Michael Wooldridge, Ioannis Zachos

In agent-based simulations, synthetic populations of agents are commonly used
to represent the structure, behaviour, and interactions of individuals.
However, generating a synthetic population that accurately reflects real
population statistics is a challenging task, particularly when performed at
scale. In this paper, we propose a multi objective combinatorial optimisation
technique for large scale population synthesis. We demonstrate the
effectiveness of our approach by generating a synthetic population for selected
regions and validating it on contingency tables from real population data. Our
approach supports complex hierarchical structures between individuals and
households, is scalable to large populations and achieves minimal contigency
table reconstruction error. Hence, it provides a useful tool for policymakers
and researchers for simulating the dynamics of complex populations.

摘要：在基於代理的模擬中，代理的合成族群通常用於表示個體的結構、行為和互動。
然而，產生一個準確反映真實族群統計的合成族群是一項具有挑戰性的任務，特別是在大規模執行時。
在本文中，我們提出了一種多目標組合優化技術，用於大規模族群合成。
我們透過為選定的區域產生一個合成族群並根據真實族群資料的或然率表驗證它，來證明我們方法的有效性。
我們的做法支援個體和家庭之間複雜的層級結構，可以擴展到大型族群，並實現最小的或然率表重建誤差。
因此，它為政策制定者和研究人員提供了一個有用的工具，用於模擬複雜族群的動態。

##### **Motion meets Attention: Video Motion Prompts**
2407.03179v1 by Qixiang Chen, Lei Wang, Piotr Koniusz, Tom Gedeon

Videos contain rich spatio-temporal information. Traditional methods for
extracting motion, used in tasks such as action recognition, often rely on
visual contents rather than precise motion features. This phenomenon is
referred to as 'blind motion extraction' behavior, which proves inefficient in
capturing motions of interest due to a lack of motion-guided cues. Recently,
attention mechanisms have enhanced many computer vision tasks by effectively
highlighting salient visual areas. Inspired by this, we propose using a
modified Sigmoid function with learnable slope and shift parameters as an
attention mechanism to activate and modulate motion signals derived from frame
differencing maps. This approach generates a sequence of attention maps that
enhance the processing of motion-related video content. To ensure temporally
continuity and smoothness of the attention maps, we apply pair-wise temporal
attention variation regularization to remove unwanted motions (e.g., noise)
while preserving important ones. We then perform Hadamard product between each
pair of attention maps and the original video frames to highlight the evolving
motions of interest over time. These highlighted motions, termed video motion
prompts, are subsequently used as inputs to the model instead of the original
video frames. We formalize this process as a motion prompt layer and
incorporate the regularization term into the loss function to learn better
motion prompts. This layer serves as an adapter between the model and the video
data, bridging the gap between traditional 'blind motion extraction' and the
extraction of relevant motions of interest.

摘要：影片包含豐富的時空資訊。傳統用於動作辨識等任務的動作擷取方法，通常仰賴視覺內容，而非精確的動作特徵。這種現象稱為「盲目動作擷取」行為，因缺乏動作引導線索，而無法有效擷取感興趣的動作。近期，注意力機制透過有效凸顯顯著的視覺區域，增強許多電腦視覺任務。受此啟發，我們提出一種使用具有可學習斜率和位移參數的修正 Sigmoid 函數，作為注意力機制，以啟動和調製從影格差異映射中衍生的動作訊號。此方法會產生一系列注意力映射，增強對動作相關影片內容的處理。為了確保注意力映射的時間連續性和平滑性，我們套用成對的時間注意力變化正規化，以移除不必要的動作（例如雜訊），同時保留重要的動作。接著，我們對每一對注意力映射和原始影片影格執行 Hadamard 乘積，以凸顯隨著時間推移而演化的感興趣動作。這些凸顯的動作稱為影片動作提示，隨後用作模型的輸入，而非原始影片影格。我們將此程序形式化為動作提示層，並將正規化項納入損失函數，以學習更好的動作提示。此層作為模型和影片資料之間的適配器，彌合傳統「盲目動作擷取」與擷取相關感興趣動作之間的差距。

##### **Investigating Decoder-only Large Language Models for Speech-to-text Translation**
2407.03169v1 by Chao-Wei Huang, Hui Lu, Hongyu Gong, Hirofumi Inaguma, Ilia Kulikov, Ruslan Mavlyutov, Sravya Popuri

Large language models (LLMs), known for their exceptional reasoning
capabilities, generalizability, and fluency across diverse domains, present a
promising avenue for enhancing speech-related tasks. In this paper, we focus on
integrating decoder-only LLMs to the task of speech-to-text translation (S2TT).
We propose a decoder-only architecture that enables the LLM to directly consume
the encoded speech representation and generate the text translation.
Additionally, we investigate the effects of different parameter-efficient
fine-tuning techniques and task formulation. Our model achieves
state-of-the-art performance on CoVoST 2 and FLEURS among models trained
without proprietary data. We also conduct analyses to validate the design
choices of our proposed model and bring insights to the integration of LLMs to
S2TT.

摘要：大型語言模型 (LLM) 以其卓越的推理能力、通用性和在不同領域的流暢性而聞名，為增強與語音相關的任務提供了有前途的途徑。在本文中，我們專注於將僅解碼器 LLM 整合到語音轉文字翻譯 (S2TT) 的任務中。我們提出了一種僅解碼器架構，使 LLM 能夠直接使用編碼語音表示並產生文字翻譯。此外，我們還研究了不同參數有效微調技術和任務表述的影響。我們的模型在 CoVoST 2 和 FLEURS 上達到了最先進的效能，這些模型是在沒有專有數據的情況下訓練的。我們還進行了分析以驗證我們提出的模型的設計選擇，並為將 LLM 整合到 S2TT 帶來見解。

##### **SOS! Soft Prompt Attack Against Open-Source Large Language Models**
2407.03160v1 by Ziqing Yang, Michael Backes, Yang Zhang, Ahmed Salem

Open-source large language models (LLMs) have become increasingly popular
among both the general public and industry, as they can be customized,
fine-tuned, and freely used. However, some open-source LLMs require approval
before usage, which has led to third parties publishing their own easily
accessible versions. Similarly, third parties have been publishing fine-tuned
or quantized variants of these LLMs. These versions are particularly appealing
to users because of their ease of access and reduced computational resource
demands. This trend has increased the risk of training time attacks,
compromising the integrity and security of LLMs. In this work, we present a new
training time attack, SOS, which is designed to be low in computational demand
and does not require clean data or modification of the model weights, thereby
maintaining the model's utility intact. The attack addresses security issues in
various scenarios, including the backdoor attack, jailbreak attack, and prompt
stealing attack. Our experimental findings demonstrate that the proposed attack
is effective across all evaluated targets. Furthermore, we present the other
side of our SOS technique, namely the copyright token -- a novel technique that
enables users to mark their copyrighted content and prevent models from using
it.

摘要：開放原始碼大型語言模型 (LLM) 在一般大眾和產業之間變得越來越受歡迎，因為它們可以自訂、微調和免費使用。然而，有些開放原始碼 LLM 在使用前需要獲得批准，這導致第三方發布他們自己的容易存取版本。類似地，第三方已經發布這些 LLM 的微調或量化變體。這些版本特別吸引使用者，因為它們容易存取且降低了運算資源需求。這種趨勢增加了訓練時間攻擊的風險，危害了 LLM 的完整性和安全性。在這項工作中，我們提出了一種新的訓練時間攻擊 SOS，它被設計為運算需求低，且不需要乾淨的資料或修改模型權重，從而保持模型的效用完整。該攻擊解決了各種場景中的安全性問題，包括後門攻擊、越獄攻擊和提示竊取攻擊。我們的實驗結果證明，所提出的攻擊在所有評估目標中都是有效的。此外，我們提出了 SOS 技術的另一面，即版權令牌——一種創新的技術，使用戶可以標記他們的版權內容並防止模型使用它。

##### **Let the Code LLM Edit Itself When You Edit the Code**
2407.03157v1 by Zhenyu He, Jun Zhang, Shengjie Luo, Jingjing Xu, Zhi Zhang, Di He

In this work, we investigate a typical scenario in code generation where a
developer edits existing code in real time and requests a code assistant, e.g.,
a large language model, to re-predict the next token or next line on the fly.
Naively, the LLM needs to re-encode the entire KV cache to provide an accurate
prediction. However, this process is computationally expensive, especially when
the sequence length is long. Simply encoding the edited subsequence and
integrating it to the original KV cache meets the temporal confusion problem,
leading to significantly worse performance. We address this efficiency and
accuracy trade-off by introducing \underline{\textbf{Positional
\textbf{I}ntegrity \textbf{E}ncoding} (PIE). Building upon the rotary
positional encoding, PIE first removes the rotary matrices in the Key cache
that introduce temporal confusion and then reapplies the correct rotary
matrices. This process ensures that positional relationships between tokens are
correct and requires only a single round of matrix multiplication. We validate
the effectiveness of PIE through extensive experiments on the RepoBench-C-8k
dataset, utilizing DeepSeek-Coder models with 1.3B, 6.7B, and 33B parameters.
Our evaluation includes three real-world coding tasks: code insertion, code
deletion, and multi-place code editing. Results demonstrate that PIE reduces
computational overhead by over 85% compared to the standard full recomputation
approach across all model sizes and tasks while well approximating the model
performance.

摘要：在這項工作中，我們調查程式碼產生中一個典型的場景，其中開發人員即時編輯現有程式碼並要求程式碼助理（例如大型語言模型）即時重新預測下一個符號或下一行。天真地說，LLM 需要重新編碼整個 KV 快取才能提供準確的預測。然而，這個過程在計算上很昂貴，尤其當序列長度很長時。僅編碼已編輯的子序列並將其整合到原始 KV 快取中會遇到時間混淆問題，導致效能顯著下降。我們透過引入\underline{\textbf{位置完整性編碼} (PIE)}來解決這個效率和準確性的權衡。建立在旋轉位置編碼的基礎上，PIE 首先移除 Key 快取中引入時間混淆的旋轉矩陣，然後重新套用正確的旋轉矩陣。這個過程確保符號之間的位置關係正確，並且只需要一輪矩陣乘法。我們透過在 RepoBench-C-8k 資料集上進行廣泛的實驗，利用具有 1.3B、6.7B 和 33B 參數的 DeepSeek-Coder 模型驗證 PIE 的有效性。我們的評估包括三個真實世界的編碼任務：程式碼插入、程式碼刪除和多處程式碼編輯。結果表明，與所有模型大小和任務的標準完全重新計算方法相比，PIE 將計算開銷減少了 85% 以上，同時很好地逼近模型效能。

##### **Reinforcement Learning for Sequence Design Leveraging Protein Language Models**
2407.03154v1 by Jithendaraa Subramanian, Shivakanth Sujit, Niloy Irtisam, Umong Sain, Derek Nowrouzezahrai, Samira Ebrahimi Kahou, Riashat Islam

Protein sequence design, determined by amino acid sequences, are essential to
protein engineering problems in drug discovery. Prior approaches have resorted
to evolutionary strategies or Monte-Carlo methods for protein design, but often
fail to exploit the structure of the combinatorial search space, to generalize
to unseen sequences. In the context of discrete black box optimization over
large search spaces, learning a mutation policy to generate novel sequences
with reinforcement learning is appealing. Recent advances in protein language
models (PLMs) trained on large corpora of protein sequences offer a potential
solution to this problem by scoring proteins according to their biological
plausibility (such as the TM-score). In this work, we propose to use PLMs as a
reward function to generate new sequences. Yet the PLM can be computationally
expensive to query due to its large size. To this end, we propose an
alternative paradigm where optimization can be performed on scores from a
smaller proxy model that is periodically finetuned, jointly while learning the
mutation policy. We perform extensive experiments on various sequence lengths
to benchmark RL-based approaches, and provide comprehensive evaluations along
biological plausibility and diversity of the protein. Our experimental results
include favorable evaluations of the proposed sequences, along with high
diversity scores, demonstrating that RL is a strong candidate for biological
sequence design. Finally, we provide a modular open source implementation can
be easily integrated in most RL training loops, with support for replacing the
reward model with other PLMs, to spur further research in this domain. The code
for all experiments is provided in the supplementary material.

摘要：蛋白质序列设计由氨基酸序列决定，对于药物发现中的蛋白质工程问题至关重要。先前的研究方法采用进化策略或蒙特卡罗方法进行蛋白质设计，但往往无法利用组合搜索空间的结构，推广到不可见的序列。在离散黑盒优化的大搜索空间背景下，学习突变策略以利用强化学习生成新序列很有吸引力。最近在大量蛋白质序列语料库上训练的蛋白质语言模型 (PLM) 的进步通过根据其生物学合理性（例如 TM 分数）对蛋白质进行评分，为这一问题提供了潜在的解决方案。在这项工作中，我们建议使用 PLM 作为奖励函数来生成新序列。然而，由于 PLM 体积庞大，查询 PLM 在计算上可能很昂贵。为此，我们提出了另一种范例，其中优化可以在较小的代理模型的评分上执行，该模型会定期进行微调，同时学习突变策略。我们对不同序列长度进行了广泛的实验，以对基于 RL 的方法进行基准测试，并提供了蛋白质的生物学合理性和多样性的综合评估。我们的实验结果包括对所提出序列的有利评估以及高多样性评分，表明 RL 是生物序列设计的强有力候选者。最后，我们提供了一个模块化的开源实现，可以轻松集成到大多数 RL 训练循环中，并支持用其他 PLM 替换奖励模型，以激发该领域的进一步研究。所有实验的代码都提供在补充材料中。

##### **Enhancing Translation Accuracy of Large Language Models through Continual Pre-Training on Parallel Data**
2407.03145v1 by Minato Kondo, Takehito Utsuro, Masaaki Nagata

In this paper, we propose a two-phase training approach where pre-trained
large language models are continually pre-trained on parallel data and then
supervised fine-tuned with a small amount of high-quality parallel data. To
investigate the effectiveness of our proposed approach, we conducted continual
pre-training with a 3.8B-parameter model and parallel data across eight
different formats. We evaluate these methods on thirteen test sets for
Japanese-to-English and English-to-Japanese translation. The results
demonstrate that when utilizing parallel data in continual pre-training, it is
essential to alternate between source and target sentences. Additionally, we
demonstrated that the translation accuracy improves only for translation
directions where the order of source and target sentences aligns between
continual pre-training data and inference. In addition, we demonstrate that the
LLM-based translation model is more robust in translating spoken language and
achieves higher accuracy with less training data compared to supervised
encoder-decoder models. We also show that the highest accuracy is achieved when
the data for continual pre-training consists of interleaved source and target
sentences and when tags are added to the source sentences.

摘要：<paragraph>在本文中，我們提出了一種兩階段訓練方法，其中預先訓練好的大型語言模型會持續在平行資料上預先訓練，然後使用少量高品質的平行資料進行監督微調。為了探討我們所提方法的有效性，我們使用 3.8B 參數模型和橫跨八種不同格式的平行資料進行持續預先訓練。我們在十三個測試集上評估這些方法，進行日文到英文和英文到日文的翻譯。結果顯示，在持續預先訓練中使用平行資料時，在來源和目標句子之間交替進行非常重要。此外，我們證明了翻譯準確性僅在來源和目標句子的順序在持續預先訓練資料和推論之間對齊的翻譯方向上有所提升。此外，我們證明了基於 LLM 的翻譯模型在翻譯口語時更強健，並且與監督編碼器-解碼器模型相比，在訓練資料較少的情況下能達到更高的準確性。我們還表明，當用於持續預先訓練的資料包含交錯的來源和目標句子，以及在來源句子中加入標籤時，可以達到最高的準確性。</paragraph>

##### **GMM-ResNext: Combining Generative and Discriminative Models for Speaker Verification**
2407.03135v1 by Hui Yan, Zhenchun Lei, Changhong Liu, Yong Zhou

With the development of deep learning, many different network architectures
have been explored in speaker verification. However, most network architectures
rely on a single deep learning architecture, and hybrid networks combining
different architectures have been little studied in ASV tasks. In this paper,
we propose the GMM-ResNext model for speaker verification. Conventional GMM
does not consider the score distribution of each frame feature over all
Gaussian components and ignores the relationship between neighboring speech
frames. So, we extract the log Gaussian probability features based on the raw
acoustic features and use ResNext-based network as the backbone to extract the
speaker embedding. GMM-ResNext combines Generative and Discriminative Models to
improve the generalization ability of deep learning models and allows one to
more easily specify meaningful priors on model parameters. A two-path
GMM-ResNext model based on two gender-related GMMs has also been proposed. The
Experimental results show that the proposed GMM-ResNext achieves relative
improvements of 48.1\% and 11.3\% in EER compared with ResNet34 and ECAPA-TDNN
on VoxCeleb1-O test set.

摘要：随着深度學習的發展，在說話者驗證中已經探索了許多不同的網路架構。然而，大多數網路架構依賴於單一的深度學習架構，而結合不同架構的混合網路在 ASV 任務中研究得很少。在本文中，我們提出 GMM-ResNext 模型進行說話者驗證。傳統的 GMM 沒有考慮每個幀特徵在所有高斯分量上的分數分佈，並且忽略了相鄰語音幀之間的關係。因此，我們基於原始聲學特徵提取對數高斯機率特徵，並使用基於 ResNext 的網路作為主幹來提取說話者嵌入。GMM-ResNext 結合了生成模型和判別模型，以提高深度學習模型的泛化能力，並允許人們更輕鬆地指定模型參數上的有意義先驗。還提出了一個基於兩個性別相關 GMM 的雙路徑 GMM-ResNext 模型。實驗結果表明，與 ResNet34 和 ECAPA-TDNN 相比，所提出的 GMM-ResNext 在 VoxCeleb1-O 測試集上在 EER 中分別取得了 48.1% 和 11.3% 的相對改進。

##### **MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**
2407.03131v1 by Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu

Electroencephalography (EEG), a medical imaging technique that captures scalp
electrical activity of brain structures via electrodes, has been widely used in
affective computing. The spatial domain of EEG is rich in affective
information.However, few of the existing studies have simultaneously analyzed
EEG signals from multiple perspectives of geometric and anatomical structures
in spatial domain. In this paper, we propose a multi-view Graph Transformer
(MVGT) based on spatial relations, which integrates information from the
temporal, frequency and spatial domains, including geometric and anatomical
structures, so as to enhance the expressive power of the model
comprehensively.We incorporate the spatial information of EEG channels into the
model as encoding, thereby improving its ability to perceive the spatial
structure of the channels. Meanwhile, experimental results based on publicly
available datasets demonstrate that our proposed model outperforms
state-of-the-art methods in recent years. In addition, the results also show
that the MVGT could extract information from multiple domains and capture
inter-channel relationships in EEG emotion recognition tasks effectively.

摘要：腦電圖 (EEG) 是一種醫療影像技術，可透過電極擷取大腦結構的頭皮電氣活動，已廣泛用於情感運算。EEG 的空間域包含豐富的情感資訊。然而，現有研究鮮少同時從幾何和解剖結構的空間域視角分析 EEG 訊號。在本文中，我們提出一個基於空間關係的多視圖圖形轉換器 (MVGT)，整合時間、頻率和空間域的資訊，包括幾何和解剖結構，以全面增強模型的表達能力。我們將 EEG 通道的空間資訊納入模型作為編碼，從而提升其感知通道空間結構的能力。同時，基於公開資料集的實驗結果證明，我們提出的模型優於近年來的先進方法。此外，結果也顯示 MVGT 可以從多個域中擷取資訊，並在 EEG 情緒辨識任務中有效擷取通道間的關係。

##### **Social Bias Evaluation for Large Language Models Requires Prompt Variations**
2407.03129v1 by Rem Hida, Masahiro Kaneko, Naoaki Okazaki

Warning: This paper contains examples of stereotypes and biases. Large
Language Models (LLMs) exhibit considerable social biases, and various studies
have tried to evaluate and mitigate these biases accurately. Previous studies
use downstream tasks as prompts to examine the degree of social biases for
evaluation and mitigation. While LLMs' output highly depends on prompts,
previous studies evaluating and mitigating bias have often relied on a limited
variety of prompts. In this paper, we investigate the sensitivity of LLMs when
changing prompt variations (task instruction and prompt, few-shot examples,
debias-prompt) by analyzing task performance and social bias of LLMs. Our
experimental results reveal that LLMs are highly sensitive to prompts to the
extent that the ranking of LLMs fluctuates when comparing models for task
performance and social bias. Additionally, we show that LLMs have tradeoffs
between performance and social bias caused by the prompts. Less bias from
prompt setting may result in reduced performance. Moreover, the ambiguity of
instances is one of the reasons for this sensitivity to prompts in advanced
LLMs, leading to various outputs. We recommend using diverse prompts, as in
this study, to compare the effects of prompts on social bias in LLMs.

摘要：警告：本文包含刻板印象和偏見的範例。大型語言模型 (LLM) 表現出相當程度的社會偏見，而且各種研究已嘗試準確評估和緩解這些偏見。先前的研究使用下游任務作為提示，以檢查社會偏見的程度，並進行評估和緩解。儘管 LLM 的輸出高度依賴於提示，但先前評估和緩解偏見的研究通常依賴於有限種類的提示。在本文中，我們透過分析任務效能和 LLM 的社會偏見，探討變更提示變數（任務說明和提示、少數範例、去偏見提示）時 LLM 的敏感度。我們的實驗結果顯示，LLM 對提示高度敏感，在比較任務效能和社會偏見的模型時，LLM 的排名會有所波動。此外，我們顯示 LLM 在效能和社會偏見之間有取捨，這是由提示造成的。提示設定的偏見越少，可能會導致效能降低。此外，實例的模糊性是進階 LLM 對提示敏感的原因之一，導致各種輸出。我們建議使用多樣化的提示，如同本研究，以比較提示對 LLM 中社會偏見的影響。

##### **Foundations and Frontiers of Graph Learning Theory**
2407.03125v1 by Yu Huang, Min Zhou, Menglin Yang, Zhen Wang, Muhan Zhang, Jie Wang, Hong Xie, Hao Wang, Defu Lian, Enhong Chen

Recent advancements in graph learning have revolutionized the way to
understand and analyze data with complex structures. Notably, Graph Neural
Networks (GNNs), i.e. neural network architectures designed for learning graph
representations, have become a popular paradigm. With these models being
usually characterized by intuition-driven design or highly intricate
components, placing them within the theoretical analysis framework to distill
the core concepts, helps understand the key principles that drive the
functionality better and guide further development. Given this surge in
interest, this article provides a comprehensive summary of the theoretical
foundations and breakthroughs concerning the approximation and learning
behaviors intrinsic to prevalent graph learning models. Encompassing
discussions on fundamental aspects such as expressiveness power,
generalization, optimization, and unique phenomena such as over-smoothing and
over-squashing, this piece delves into the theoretical foundations and frontier
driving the evolution of graph learning. In addition, this article also
presents several challenges and further initiates discussions on possible
solutions.

摘要：最近在圖形學習的進展，徹底改變了我們理解和分析具有複雜結構的資料的方式。值得注意的是，圖形神經網路 (GNN)，也就是專門用於學習圖形表示的神經網路架構，已經成為一種流行的範例。由於這些模型通常以直覺驅動的設計或高度複雜的元件為特徵，將它們置於理論分析框架中以提煉核心概念，有助於我們更好地理解驅動功能性的關鍵原則，並引導進一步的發展。鑑於這股熱潮，本文提供了關於近似和學習行為的理論基礎和突破的全面摘要，這些行為內含於流行的圖形學習模型中。本文涵蓋了表達能力、概化、最佳化等基本面向的討論，以及過度平滑和過度壓縮等獨特現象，深入探討了理論基礎和推動圖形學習演進的前沿。此外，本文也提出了若干挑戰，並進一步展開關於可能解決方案的討論。

##### **How Reliable and Stable are Explanations of XAI Methods?**
2407.03108v1 by José Ribeiro, Lucas Cardoso, Vitor Santos, Eduardo Carvalho, Níkolas Carneiro, Ronnie Alves

Black box models are increasingly being used in the daily lives of human
beings living in society. Along with this increase, there has been the
emergence of Explainable Artificial Intelligence (XAI) methods aimed at
generating additional explanations regarding how the model makes certain
predictions. In this sense, methods such as Dalex, Eli5, eXirt, Lofo and Shap
emerged as different proposals and methodologies for generating explanations of
black box models in an agnostic way. Along with the emergence of these methods,
questions arise such as "How Reliable and Stable are XAI Methods?". With the
aim of shedding light on this main question, this research creates a pipeline
that performs experiments using the diabetes dataset and four different machine
learning models (LGBM, MLP, DT and KNN), creating different levels of
perturbations of the test data and finally generates explanations from the
eXirt method regarding the confidence of the models and also feature relevances
ranks from all XAI methods mentioned, in order to measure their stability in
the face of perturbations. As a result, it was found that eXirt was able to
identify the most reliable models among all those used. It was also found that
current XAI methods are sensitive to perturbations, with the exception of one
specific method.

摘要：黑盒模型正日益在社会中人类的日常生活中被使用。伴随着这种增长，出现了可解释人工智能 (XAI) 方法，旨在生成有关模型如何做出某些预测的附加解释。从这个意义上讲，Dalex、Eli5、eXirt、Lofo 和 Shap 等方法以不可知的方式为生成黑盒模型的解释出现了不同的提议和方法论。随着这些方法的出现，出现了诸如“XAI 方法的可靠性和稳定性如何？”等问题。为了阐明这个主要问题，本研究创建了一个管道，使用糖尿病数据集和四种不同的机器学习模型（LGBM、MLP、DT 和 KNN）执行实验，创建不同级别的测试数据扰动，最后从 eXirt 方法生成有关模型置信度的解释，以及所提到的所有 XAI 方法的功能相关性排名，以衡量它们在面对扰动时的稳定性。结果发现，eXirt 能够识别所有使用模型中最可靠的模型。还发现，当前的 XAI 方法对扰动敏感，除了一个特定方法。

##### **KeyVideoLLM: Towards Large-scale Video Keyframe Selection**
2407.03104v1 by Hao Liang, Jiapeng Li, Tianyi Bai, Chong Chen, Conghui He, Bin Cui, Wentao Zhang

Recently, with the rise of web videos, managing and understanding large-scale
video datasets has become increasingly important. Video Large Language Models
(VideoLLMs) have emerged in recent years due to their strong video
understanding capabilities. However, training and inference processes for
VideoLLMs demand vast amounts of data, presenting significant challenges to
data management, particularly regarding efficiency, robustness, and
effectiveness. In this work, we present KeyVideoLLM, a text-video frame
similarity-based keyframe selection method designed to manage VideoLLM data
efficiently, robustly, and effectively. Specifically, KeyVideoLLM achieves a
remarkable data compression rate of up to 60.9 times, substantially lowering
disk space requirements, which proves its high efficiency. Additionally, it
maintains a 100% selection success rate across all video formats and scales,
enhances processing speed by up to 200 times compared to existing keyframe
selection methods, and does not require hyperparameter tuning. Beyond its
outstanding efficiency and robustness, KeyVideoLLM further improves model
performance in video question-answering tasks during both training and
inference stages. Notably, it consistently achieved the state-of-the-art (SoTA)
experimental results on diverse datasets.

摘要：<paragraph>最近，随着网络视频的兴起，管理和理解大规模视频数据集变得越来越重要。视频大语言模型 (VideoLLM) 近年来因其强大的视频理解能力而兴起。然而，VideoLLM 的训练和推理过程需要大量数据，对数据管理提出了重大挑战，尤其是在效率、鲁棒性和有效性方面。在这项工作中，我们提出了 KeyVideoLLM，这是一种基于文本-视频帧相似性的关键帧选择方法，旨在高效、鲁棒且有效地管理 VideoLLM 数据。具体来说，KeyVideoLLM 实现了高达 60.9 倍的显着数据压缩率，大幅降低了磁盘空间需求，这证明了其高效率。此外，它在所有视频格式和规模上保持 100% 的选择成功率，与现有的关键帧选择方法相比，处理速度提高了 200 倍，并且不需要超参数调整。除了出色的效率和鲁棒性之外，KeyVideoLLM 还在训练和推理阶段进一步提高了模型在视频问答任务中的性能。值得注意的是，它在不同的数据集上持续取得了最先进 (SoTA) 的实验结果。</paragraph>

##### **Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory**
2407.03103v1 by Suyeon Lee, Sunghwan Kim, Minju Kim, Dongjin Kang, Dongil Yang, Harim Kim, Minseok Kang, Dayi Jung, Min Hee Kim, Seungbeen Lee, Kyoung-Mee Chung, Youngjae Yu, Dongha Lee, Jinyoung Yeo

Recently, the demand for psychological counseling has significantly increased
as more individuals express concerns about their mental health. This surge has
accelerated efforts to improve the accessibility of counseling by using large
language models (LLMs) as counselors. To ensure client privacy, training
open-source LLMs faces a key challenge: the absence of realistic counseling
datasets. To address this, we introduce Cactus, a multi-turn dialogue dataset
that emulates real-life interactions using the goal-oriented and structured
approach of Cognitive Behavioral Therapy (CBT). We create a diverse and
realistic dataset by designing clients with varied, specific personas, and
having counselors systematically apply CBT techniques in their interactions. To
assess the quality of our data, we benchmark against established psychological
criteria used to evaluate real counseling sessions, ensuring alignment with
expert evaluations. Experimental results demonstrate that Camel, a model
trained with Cactus, outperforms other models in counseling skills,
highlighting its effectiveness and potential as a counseling agent. We make our
data, model, and code publicly available.

摘要：近期，隨著愈來愈多人表達對心理健康的關注，心理諮商的需求大幅增加。這股熱潮加速了透過大型語言模型（LLM）作為諮商師來提升諮商可近性的努力。為了確保客戶隱私，訓練開放原始碼 LLM 面臨一項關鍵挑戰：缺乏寫實的諮商資料集。為了解決這個問題，我們引入了 Cactus，這是一個多回合對話資料集，使用以目標為導向且結構化的認知行為療法（CBT）方法來模擬真實生活中的互動。我們透過設計具有各種特定角色的客戶，並讓諮商師在互動中系統性地應用 CBT 技術，來建立一個多元且寫實的資料集。為了評估我們資料的品質，我們根據用於評估真實諮商會談的既定心理標準進行基準測試，確保與專家評估保持一致。實驗結果顯示，使用 Cactus 訓練的模型 Camel 在諮商技巧方面優於其他模型，突顯其作為諮商代理的有效性和潛力。我們公開提供我們的資料、模型和程式碼。

##### **Conformal Prediction for Causal Effects of Continuous Treatments**
2407.03094v1 by Maresa Schröder, Dennis Frauen, Jonas Schweisthal, Konstantin Heß, Valentyn Melnychuk, Stefan Feuerriegel

Uncertainty quantification of causal effects is crucial for safety-critical
applications such as personalized medicine. A powerful approach for this is
conformal prediction, which has several practical benefits due to
model-agnostic finite-sample guarantees. Yet, existing methods for conformal
prediction of causal effects are limited to binary/discrete treatments and make
highly restrictive assumptions such as known propensity scores. In this work,
we provide a novel conformal prediction method for potential outcomes of
continuous treatments. We account for the additional uncertainty introduced
through propensity estimation so that our conformal prediction intervals are
valid even if the propensity score is unknown. Our contributions are
three-fold: (1) We derive finite-sample prediction intervals for potential
outcomes of continuous treatments. (2) We provide an algorithm for calculating
the derived intervals. (3) We demonstrate the effectiveness of the conformal
prediction intervals in experiments on synthetic and real-world datasets. To
the best of our knowledge, we are the first to propose conformal prediction for
continuous treatments when the propensity score is unknown and must be
estimated from data.

摘要：因果效應的不確定性量化對於安全關鍵應用（例如個人化醫療）至關重要。一種強大的方法是共形預測，由於模型不可知的有限樣本保證，它具有多項實用優勢。然而，現有的因果效應共形預測方法僅限於二元/離散處理，並且做出高度限制性的假設，例如已知的傾向得分。在這項工作中，我們提供了一種新的共形預測方法，用於連續處理的潛在結果。我們考慮了傾向估計中引入的額外不確定性，這樣即使傾向得分未知，我們的共形預測區間仍然有效。我們的貢獻有三個方面：(1) 我們推導出連續處理潛在結果的有限樣本預測區間。(2) 我們提供了一種演算法來計算推導出的區間。(3) 我們在合成和真實世界資料集上的實驗中證明了共形預測區間的有效性。據我們所知，我們是第一個在傾向得分未知且必須從資料中估計時，提出連續處理的共形預測。

##### **Revisiting the Performance of Deep Learning-Based Vulnerability Detection on Realistic Datasets**
2407.03093v1 by Partha Chakraborty, Krishna Kanth Arumugam, Mahmoud Alfadel, Meiyappan Nagappan, Shane McIntosh

The impact of software vulnerabilities on everyday software systems is
significant. Despite deep learning models being proposed for vulnerability
detection, their reliability is questionable. Prior evaluations show high
recall/F1 scores of up to 99%, but these models underperform in practical
scenarios, particularly when assessed on entire codebases rather than just the
fixing commit. This paper introduces Real-Vul, a comprehensive dataset
representing real-world scenarios for evaluating vulnerability detection
models. Evaluating DeepWukong, LineVul, ReVeal, and IVDetect shows a
significant drop in performance, with precision decreasing by up to 95
percentage points and F1 scores by up to 91 points. Furthermore, Model
performance fluctuates based on vulnerability characteristics, with better F1
scores for information leaks or code injection than for path resolution or
predictable return values. The results highlight a significant performance gap
that needs addressing before deploying deep learning-based vulnerability
detection in practical settings. Overfitting is identified as a key issue, and
an augmentation technique is proposed, potentially improving performance by up
to 30%. Contributions include a dataset creation approach for better model
evaluation, Real-Vul dataset, and empirical evidence of deep learning models
struggling in real-world settings.

摘要：軟體漏洞對日常軟體系統的影響十分重大。儘管已提出用於漏洞偵測的深度學習模型，但其可靠性仍有待商榷。先前的評估顯示高達 99% 的召回率/F1 分數，但這些模型在實際場景中表現不佳，特別是在針對整個程式碼庫進行評估，而不僅僅是修正提交時。本文介紹了 Real-Vul，這是一個全面的資料集，代表了評估漏洞偵測模型的真實世界場景。評估 DeepWukong、LineVul、ReVeal 和 IVDetect 會顯著降低效能，精確度下降多達 95 個百分點，F1 分數下降多達 91 個百分點。此外，模型效能會根據漏洞特徵而有所波動，資訊外洩或程式碼注入的 F1 分數優於路徑解析或可預測的回傳值。這些結果突顯了一個重大的效能差距，在實際環境中部署基於深度學習的漏洞偵測之前，需要解決這個差距。過度擬合被認定為一個關鍵問題，並提出了一種擴充技術，潛在可以將效能提升多達 30%。貢獻包括一個用於更佳模型評估的資料集建立方法、Real-Vul 資料集，以及深度學習模型在真實世界環境中掙扎的實證證據。

##### **Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**
2407.03086v1 by Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko

While federated learning leverages distributed client resources, it faces
challenges due to heterogeneous client capabilities. This necessitates
allocating models suited to clients' resources and careful parameter
aggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel
federated learning framework for supporting client heterogeneity by combining a
multi-exit network architecture with hypernetwork-based model weight
generation. This approach aligns the feature spaces of heterogeneous model
layers and resolves per-layer information disparity during weight aggregation.
To practically realize HypeMeFed, we also propose a low-rank factorization
approach to minimize computation and memory overhead associated with
hypernetworks. Our evaluations on a real-world heterogeneous device testbed
indicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the
hypernetwork memory requirements by 98.22%, and accelerates its operations by
1.86 times compared to a naive hypernetwork approach. These results demonstrate
HypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for
federated learning.

摘要：雖然聯合學習利用分散式用戶端資源，但由於用戶端能力異質，因此面臨挑戰。這需要分配適合用戶端資源的模型，並仔細參數聚合以容納這種異質性。我們提出 HypeMeFed，一種新的聯合學習框架，通過將多出口網路架構與基於超網路的模型權重生成相結合來支援用戶端異質性。此方法對齊異質模型層的特徵空間，並在權重聚合期間解決逐層資訊差異。為了實際實現 HypeMeFed，我們還提出了一種低秩分解方法，以最大限度地減少與超網路相關的計算和記憶體開銷。我們在真實世界異質設備測試平台上的評估表明，與 FedAvg 相比，HypeMeFed 將準確率提高了 5.12%，將超網路記憶體需求減少了 98.22%，並且與天真的超網路方法相比，其運算速度提高了 1.86 倍。這些結果證明了 HypeMeFed 在利用和吸引異質用戶端進行聯合學習方面的有效性。

##### **Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios**
2407.03080v1 by Patricia A. Apellániz, Ana Jiménez, Borja Arroyo Galende, Juan Parras, Santiago Zazo

While synthetic tabular data generation using Deep Generative Models (DGMs)
offers a compelling solution to data scarcity and privacy concerns, their
effectiveness relies on substantial training data, often unavailable in
real-world applications. This paper addresses this challenge by proposing a
novel methodology for generating realistic and reliable synthetic tabular data
with DGMs in limited real-data environments. Our approach proposes several ways
to generate an artificial inductive bias in a DGM through transfer learning and
meta-learning techniques. We explore and compare four different methods within
this framework, demonstrating that transfer learning strategies like
pre-training and model averaging outperform meta-learning approaches, like
Model-Agnostic Meta-Learning, and Domain Randomized Search. We validate our
approach using two state-of-the-art DGMs, namely, a Variational Autoencoder and
a Generative Adversarial Network, to show that our artificial inductive bias
fuels superior synthetic data quality, as measured by Jensen-Shannon
divergence, achieving relative gains of up to 50\% when using our proposed
approach. This methodology has broad applicability in various DGMs and machine
learning tasks, particularly in areas like healthcare and finance, where data
scarcity is often a critical issue.

摘要：<paragraph>儘管使用深度生成模型 (DGM) 進行合成表格資料生成提供了一個引人注目的解決方案來解決資料稀少和隱私問題，但它們的有效性依賴於大量的訓練資料，而在現實世界的應用中通常無法取得。本文透過提出一個創新的方法論來解決這個挑戰，以在有限的真實資料環境中使用 DGM 生成逼真且可靠的合成表格資料。我們的做法提出了幾種方法，透過轉移學習和元學習技術在 DGM 中產生人工歸納偏誤。我們在這個架構中探討並比較了四種不同的方法，證明了像預訓練和模型平均化的轉移學習策略優於元學習方法，例如模型不可知元學習和領域隨機搜尋。我們使用兩個最先進的 DGM，即變異自動編碼器和生成對抗網路，驗證了我們的做法，以證明我們的人工歸納偏誤會提升合成的資料品質，這是透過 Jensen-Shannon 距離來衡量的，在使用我們提出的方法時，達到了高達 50% 的相對增益。這種方法論在各種 DGM 和機器學習任務中具有廣泛的應用性，特別是在醫療保健和金融等領域，其中資料稀少通常是一個關鍵問題。</paragraph>

##### **A Case Study on Context-Aware Neural Machine Translation with Multi-Task Learning**
2407.03076v1 by Ramakrishna Appicharla, Baban Gain, Santanu Pal, Asif Ekbal, Pushpak Bhattacharyya

In document-level neural machine translation (DocNMT), multi-encoder
approaches are common in encoding context and source sentences. Recent studies
\cite{li-etal-2020-multi-encoder} have shown that the context encoder generates
noise and makes the model robust to the choice of context. This paper further
investigates this observation by explicitly modelling context encoding through
multi-task learning (MTL) to make the model sensitive to the choice of context.
We conduct experiments on cascade MTL architecture, which consists of one
encoder and two decoders. Generation of the source from the context is
considered an auxiliary task, and generation of the target from the source is
the main task. We experimented with German--English language pairs on News,
TED, and Europarl corpora. Evaluation results show that the proposed MTL
approach performs better than concatenation-based and multi-encoder DocNMT
models in low-resource settings and is sensitive to the choice of context.
However, we observe that the MTL models are failing to generate the source from
the context. These observations align with the previous studies, and this might
suggest that the available document-level parallel corpora are not
context-aware, and a robust sentence-level model can outperform the
context-aware models.

摘要：在文件級神經機器翻譯 (DocNMT) 中，多編碼器方法在編碼上下文和原始句子時很常見。最近的研究\cite{li-etal-2020-multi-encoder}表明，上下文編碼器會產生雜訊並使模型對上下文選擇具有魯棒性。本文通過多任務學習 (MTL) 明確建模上下文編碼，進一步探討了這一觀察結果，以使模型對上下文選擇敏感。我們對串聯 MTL 架構進行了實驗，該架構由一個編碼器和兩個解碼器組成。從上下文中生成來源被認為是一種輔助任務，而從來源生成目標是主要任務。我們對 News、TED 和 Europarl 語料庫上的德語-英語語言對進行了實驗。評估結果表明，所提出的 MTL 方法在低資源設置中比基於串接的多編碼器 DocNMT 模型表現得更好，並且對上下文選擇很敏感。然而，我們觀察到 MTL 模型無法從上下文中生成來源。這些觀察結果與先前的研究一致，這可能表明可用的文件級平行語料庫沒有上下文感知，並且魯棒的句子級模型可以優於上下文感知模型。

##### **Federated Learning for Zero-Day Attack Detection in 5G and Beyond V2X Networks**
2407.03070v1 by Abdelaziz Amara korba, Abdelwahab Boualouache, Bouziane Brik, Rabah Rahal, Yacine Ghamri-Doudane, Sidi Mohammed Senouci

Deploying Connected and Automated Vehicles (CAVs) on top of 5G and Beyond
networks (5GB) makes them vulnerable to increasing vectors of security and
privacy attacks. In this context, a wide range of advanced machine/deep
learning based solutions have been designed to accurately detect security
attacks. Specifically, supervised learning techniques have been widely applied
to train attack detection models. However, the main limitation of such
solutions is their inability to detect attacks different from those seen during
the training phase, or new attacks, also called zero-day attacks. Moreover,
training the detection model requires significant data collection and labeling,
which increases the communication overhead, and raises privacy concerns. To
address the aforementioned limits, we propose in this paper a novel detection
mechanism that leverages the ability of the deep auto-encoder method to detect
attacks relying only on the benign network traffic pattern. Using federated
learning, the proposed intrusion detection system can be trained with large and
diverse benign network traffic, while preserving the CAVs privacy, and
minimizing the communication overhead. The in-depth experiment on a recent
network traffic dataset shows that the proposed system achieved a high
detection rate while minimizing the false positive rate, and the detection
delay.

摘要：在 5G 及其後續網路（5GB）上部署連網自動駕駛車輛 (CAV)，使其容易受到越來越多的安全和隱私攻擊媒介。在此背景下，已設計出各種先進的機器/深度學習解決方案，以準確偵測安全攻擊。具體來說，監督式學習技術已被廣泛應用於訓練攻擊偵測模型。然而，此類解決方案的主要限制在於它們無法偵測到與訓練階段所見不同的攻擊，或新的攻擊，也稱為零時差攻擊。此外，訓練偵測模型需要大量資料收集和標籤，這會增加通訊負擔，並引發隱私問題。為了解決上述限制，我們在本文中提出了一種新穎的偵測機制，該機制利用深度自動編碼器方法的能力，僅依賴於良性網路流量模式來偵測攻擊。使用聯合學習，所提出的入侵偵測系統可以用大量且多樣化的良性網路流量進行訓練，同時保護 CAV 的隱私，並將通訊負擔降至最低。對近期網路流量資料集進行的深入實驗表明，所提出的系統在將誤報率和偵測延遲降至最低的同時，達到了很高的偵測率。

##### **xApp Distillation: AI-based Conflict Mitigation in B5G O-RAN**
2407.03068v1 by Hakan Erdol, Xiaoyang Wang, Robert Piechocki, George Oikonomou, Arjun Parekh

The advancements of machine learning-based (ML) decision-making algorithms
created various research and industrial opportunities. One of these areas is
ML-based near-real-time network management applications (xApps) in Open-Radio
Access Network (O-RAN). Normally, xApps are designed solely for the desired
objectives, and fine-tuned for deployment. However, telecommunication companies
can employ multiple xApps and deploy them in overlapping areas. Consider the
different design objectives of xApps, the deployment might cause conflicts. To
prevent such conflicts, we proposed the xApp distillation method that distills
knowledge from multiple xApps, then uses this knowledge to train a single model
that has retained the capabilities of Previous xApps. Performance evaluations
show that compared conflict mitigation schemes can cause up to six times more
network outages than xApp distillation in some cases.

摘要：基於機器學習 (ML) 的決策演算法進步創造了各種研究和產業機會。其中一個領域是開放式無線接取網路 (O-RAN) 中的基於 ML 的近乎即時網路管理應用程式 (xApp)。通常，xApp 僅針對所需目標設計，並針對部署進行微調。然而，電信公司可以採用多個 xApp 並將它們部署在重疊的區域。考慮到 xApp 的不同設計目標，部署可能會造成衝突。為了防止此類衝突，我們提出了 xApp 萃取方法，該方法從多個 xApp 中萃取知識，然後使用此知識來訓練單一模型，該模型保留了先前 xApp 的功能。效能評估顯示，在某些情況下，與衝突緩解方案相比，xApp 萃取最多可能導致多六倍的網路中斷。

##### **ALTER: Augmentation for Large-Table-Based Reasoning**
2407.03061v1 by Han Zhang, Yuheng Ma, Hanfang Yang

While extensive research has explored the use of large language models (LLMs)
for table-based reasoning, most approaches struggle with scalability when
applied to large tables. To maintain the superior comprehension abilities of
LLMs in these scenarios, we introduce ALTER(Augmentation for Large-Table-Based
Reasoning)-a framework designed to harness the latent augmentation potential in
both free-form natural language (NL) questions, via the query augmentor, and
semi-structured tabular data, through the table augmentor. By utilizing only a
small subset of relevant data from the table and supplementing it with
pre-augmented schema, semantic, and literal information, ALTER achieves
outstanding performance on table-based reasoning benchmarks. We also provide a
detailed analysis of large-table scenarios, comparing different methods and
various partitioning principles. In these scenarios, our method outperforms all
other approaches and exhibits robustness and efficiency against perturbations.

摘要：儘管廣泛的研究已探討大型語言模型 (LLM) 在基於表格的推理中的應用，但大多數方法在應用於大型表格時都難以擴充。為了在這些情況下維持 LLM 優異的理解能力，我們引入了 ALTER（大型表格推理擴充）- 一個旨在利用自由形式自然語言 (NL) 問題中的潛在擴充潛能，透過查詢擴充器，以及半結構化表格資料，透過表格擴充器，所設計的架構。透過僅利用表格中一小部分相關資料，並使用預先擴充的架構、語義和文字資訊來補充，ALTER 在基於表格的推理基準上達到了傑出的效能。我們也提供了大型表格場景的詳細分析，比較了不同的方法和各種分割原則。在這些場景中，我們的模型優於所有其他方法，並展現出對擾動的穩健性和效率。

##### **Improving Zero-shot Generalization of Learned Prompts via Unsupervised Knowledge Distillation**
2407.03056v1 by Marco Mistretta, Alberto Baldrati, Marco Bertini, Andrew D. Bagdanov

Vision-Language Models (VLMs) demonstrate remarkable zero-shot generalization
to unseen tasks, but fall short of the performance of supervised methods in
generalizing to downstream tasks with limited data. Prompt learning is emerging
as a parameter-efficient method for adapting VLMs, but state-of-the-art
approaches require annotated samples. In this paper we propose a novel approach
to prompt learning based on unsupervised knowledge distillation from more
powerful models. Our approach, which we call Knowledge Distillation Prompt
Learning (KDPL), can be integrated into existing prompt learning techniques and
eliminates the need for labeled examples during adaptation. Our experiments on
more than ten standard benchmark datasets demonstrate that KDPL is very
effective at improving generalization of learned prompts for zero-shot domain
generalization, zero-shot cross-dataset generalization, and zero-shot
base-to-novel class generalization problems. KDPL requires no ground-truth
labels for adaptation, and moreover we show that even in the absence of any
knowledge of training class names it can be used to effectively transfer
knowledge. The code is publicly available at https://github.com/miccunifi/KDPL.

摘要：視覺語言模型 (VLM) 展示了卓越的零次學習泛化到未見任務的能力，但在泛化到資料有限的下游任務時，效能卻不如監督式方法。提示學習正逐漸成為一種參數有效的方法，用於調整 VLM，但最先進的方法需要有註解範例。在本文中，我們提出了一種基於更強大模型的非監督式知識萃取的提示學習新方法。我們稱之為知識萃取提示學習 (KDPL) 的方法可以整合到現有的提示學習技術中，並在調整過程中消除了對標記範例的需求。我們在十多個標準基準資料集上進行的實驗證明，KDPL 在改善學習提示的泛化方面非常有效，可用於零次學習領域泛化、零次學習跨資料集泛化，以及零次學習基本到新類別泛化問題。KDPL 不需要任何真實標籤來進行調整，此外，我們證明了即使在不知道訓練類別名稱的情況下，它也可以用於有效地傳輸知識。程式碼已公開發布於 https://github.com/miccunifi/KDPL。

##### **Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment**
2407.03051v1 by Janghwan Lee, Seongmin Park, Sukjin Hong, Minsoo Kim, Du-Seong Chang, Jungwook Choi

The rapid advancement of large language models (LLMs) has facilitated their
transformation into conversational chatbots that can grasp contextual nuances
and generate pertinent sentences, closely mirroring human values through
advanced techniques such as instruction tuning and reinforcement learning from
human feedback (RLHF). However, the computational efficiency required for LLMs,
achieved through techniques like post-training quantization (PTQ), presents
challenges such as token-flipping that can impair chatbot performance. In
response, we propose a novel preference alignment approach, quantization-aware
direct preference optimization (QDPO), that aligns quantized LLMs with their
full-precision counterparts, improving conversational abilities. Evaluated on
two instruction-tuned LLMs in various languages, QDPO demonstrated superior
performance in improving conversational abilities compared to established PTQ
and knowledge-distillation fine-tuning techniques, marking a significant step
forward in the development of efficient and effective conversational LLMs.

摘要：大型語言模型 (LLM) 的快速進步促進了它們轉變為對話式聊天機器人，可以掌握語境細微差別並生成相關句子，通過高級技術（例如指令調整和人類反饋的強化學習 (RLHF)）緊密反映人類價值觀。然而，LLM 所需的運算效率是通過後訓練量化 (PTQ) 等技術實現的，這帶來了可能會損害聊天機器人效能的代幣翻轉等挑戰。為了解決這個問題，我們提出了一種新穎的偏好對齊方法，量化感知直接偏好最佳化 (QDPO)，將量化的 LLM 與它們的完整精度對應項對齊，從而提高對話能力。在各種語言中對兩個指令調整的 LLM 進行評估，QDPO 在提高對話能力方面表現出優於已建立的 PTQ 和知識提煉微調技術的卓越效能，這標誌著高效且有效的對話式 LLM 發展向前邁出了重要一步。

##### **JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets**
2407.03045v1 by Zhihua Jin, Shiyi Liu, Haotian Li, Xun Zhao, Huamin Qu

Large Language Models (LLMs) have gained significant attention but also
raised concerns due to the risk of misuse. Jailbreak prompts, a popular type of
adversarial attack towards LLMs, have appeared and constantly evolved to breach
the safety protocols of LLMs. To address this issue, LLMs are regularly updated
with safety patches based on reported jailbreak prompts. However, malicious
users often keep their successful jailbreak prompts private to exploit LLMs. To
uncover these private jailbreak prompts, extensive analysis of large-scale
conversational datasets is necessary to identify prompts that still manage to
bypass the system's defenses. This task is highly challenging due to the
immense volume of conversation data, diverse characteristics of jailbreak
prompts, and their presence in complex multi-turn conversations. To tackle
these challenges, we introduce JailbreakHunter, a visual analytics approach for
identifying jailbreak prompts in large-scale human-LLM conversational datasets.
We have designed a workflow with three analysis levels: group-level,
conversation-level, and turn-level. Group-level analysis enables users to grasp
the distribution of conversations and identify suspicious conversations using
multiple criteria, such as similarity with reported jailbreak prompts in
previous research and attack success rates. Conversation-level analysis
facilitates the understanding of the progress of conversations and helps
discover jailbreak prompts within their conversation contexts. Turn-level
analysis allows users to explore the semantic similarity and token overlap
between a singleturn prompt and the reported jailbreak prompts, aiding in the
identification of new jailbreak strategies. The effectiveness and usability of
the system were verified through multiple case studies and expert interviews.

摘要：<paragraph>大型語言模型 (LLM) 獲得了顯著關注，但也因濫用風險而引發擔憂。越獄提示，一種針對 LLM 的流行對抗性攻擊類型，已經出現並不斷演變，以突破 LLM 的安全協議。為了解決這個問題，LLM 會根據回報的越獄提示，定期更新安全修補程式。然而，惡意使用者通常會將其成功的越獄提示保密，以利用 LLM。為了揭露這些私密的越獄提示，必須對大規模對話資料集進行廣泛分析，以識別仍然設法繞過系統防禦的提示。由於對話資料量龐大、越獄提示的特徵多樣，以及它們存在於複雜的多輪對話中，這項任務極具挑戰性。為了應對這些挑戰，我們引入了 JailbreakHunter，這是一種視覺分析方法，用於識別大規模人類-LLM 對話資料集中的越獄提示。我們設計了一個具有三個分析層級的工作流程：群組層級、對話層級和輪次層級。群組層級分析使用多重標準，例如與先前研究中回報的越獄提示相似度和攻擊成功率，讓使用者掌握對話分佈並識別可疑對話。對話層級分析有助於了解對話的進展，並協助在對話脈絡中發現越獄提示。輪次層級分析讓使用者探索單輪提示與回報的越獄提示之間的語義相似度和標記重疊，協助識別新的越獄策略。系統的有效性和可用性已通過多個案例研究和專家訪談得到驗證。</paragraph>

##### **Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model**
2407.03040v1 by Xia Hou, Qifeng Li, Jian Yang, Tongliang Li, Linzheng Chai, Xianjie Wu, Hangyuan Ji, Zhoujun Li, Jixuan Nie, Jingbo Dun, Wenfeng Song

Instruction tuning as an effective technique aligns the outputs of large
language models (LLMs) with human preference. But how to generate the seasonal
multi-turn dialogues from raw documents for instruction tuning still requires
further exploration. In this paper, we present a novel framework named R2S that
leverages the CoD-Chain of Dialogue logic to guide large language models (LLMs)
in generating knowledge-intensive multi-turn dialogues for instruction tuning.
By integrating raw documents from both open-source datasets and domain-specific
web-crawled documents into a benchmark K-BENCH, we cover diverse areas such as
Wikipedia (English), Science (Chinese), and Artifacts (Chinese). Our approach
first decides the logic flow of the current dialogue and then prompts LLMs to
produce key phrases for sourcing relevant response content. This methodology
enables the creation of the G I NSTRUCT instruction dataset, retaining raw
document knowledge within dialoguestyle interactions. Utilizing this dataset,
we fine-tune GLLM, a model designed to transform raw documents into structured
multi-turn dialogues, thereby injecting comprehensive domain knowledge into the
SFT model for enhanced instruction tuning. This work signifies a stride towards
refining the adaptability and effectiveness of LLMs in processing and
generating more accurate, contextually nuanced responses across various fields.

摘要：指令微調作為一種有效技術，將大型語言模型 (LLM) 的輸出與人類偏好保持一致。但如何從原始文件生成季節性多輪對話以進行指令微調，仍需要進一步探討。在本文中，我們提出了一個名為 R2S 的新框架，它利用對話邏輯的 CoD 鏈來指導大型語言模型 (LLM) 生成知識密集型多輪對話以進行指令微調。通過將來自開源數據集和特定領域網路爬蟲文件的原始文件整合到基準 K-BENCH 中，我們涵蓋了維基百科（英語）、科學（中文）和文物（中文）等多個領域。我們的做法首先決定當前對話的邏輯流，然後提示 LLM 產生關鍵短語以獲取相關回應內容。這種方法能夠創建 G I NSTRUCT 指令數據集，在對話式互動中保留原始文件知識。利用這個數據集，我們微調了 GLLM，這是一個旨在將原始文件轉換為結構化多輪對話的模型，從而將全面的領域知識注入 SFT 模型以增強指令微調。這項工作標誌著在處理和生成更準確、在語境上更微妙的回應方面，邁進了改進 LLM 的適應性和有效性的步伐，這些回應跨越了各個領域。

##### **On the Client Preference of LLM Fine-tuning in Federated Learning**
2407.03038v1 by Feijie Wu, Xiaoze Liu, Haoyu Wang, Xingchen Wang, Jing Gao

Reinforcement learning with human feedback (RLHF) fine-tunes a pretrained
large language model (LLM) using preference datasets, enabling the LLM to
generate outputs that align with human preferences. Given the sensitive nature
of these preference datasets held by various clients, there is a need to
implement RLHF within a federated learning (FL) framework, where clients are
reluctant to share their data due to privacy concerns. To address this, we
introduce a feasible framework in which clients collaboratively train a binary
selector with their preference datasets using our proposed FedBis. With a
well-trained selector, we can further enhance the LLM that generates
human-preferred completions. Meanwhile, we propose a novel algorithm,
FedBiscuit, that trains multiple selectors by organizing clients into balanced
and disjoint clusters based on their preferences. Compared to the FedBis,
FedBiscuit demonstrates superior performance in simulating human preferences
for pairwise completions. Our extensive experiments on federated human
preference datasets -- marking the first benchmark to address heterogeneous
data partitioning among clients -- demonstrate that FedBiscuit outperforms
FedBis and even surpasses traditional centralized training.

摘要：強化學習與人類回饋 (RLHF) 使用偏好資料集微調預訓練的大型語言模型 (LLM)，使 LLM 能產生與人類偏好一致的輸出。由於各種客戶持有這些偏好資料集的敏感性質，因此需要在聯邦學習 (FL) 框架中實施 RLHF，其中客戶因隱私問題而不想分享他們的資料。為了解決這個問題，我們引進一個可行的框架，其中客戶使用我們提出的 FedBis，以他們的偏好資料集合作訓練一個二元選擇器。有了訓練良好的選擇器，我們可以進一步增強產生人類偏好的完成的 LLM。同時，我們提出了一種新的演算法 FedBiscuit，它透過將客戶根據他們的偏好組織成平衡且不相交的叢集來訓練多個選擇器。與 FedBis 相比，FedBiscuit 在模擬人類偏好以進行成對完成方面表現出優異的效能。我們對聯邦人類偏好資料集進行廣泛的實驗，標示出第一個解決客戶之間異質資料分割的基準，證明 FedBiscuit 優於 FedBis，甚至超越傳統的集中式訓練。

##### **NLP Sampling: Combining MCMC and NLP Methods for Diverse Constrained Sampling**
2407.03035v1 by Marc Toussaint, Cornelius V. Braun, Joaquim Ortiz-Haro

Generating diverse samples under hard constraints is a core challenge in many
areas. With this work we aim to provide an integrative view and framework to
combine methods from the fields of MCMC, constrained optimization, as well as
robotics, and gain insights in their strengths from empirical evaluations. We
propose NLP Sampling as a general problem formulation, propose a family of
restarting two-phase methods as a framework to integrated methods from across
the fields, and evaluate them on analytical and robotic manipulation planning
problems. Complementary to this, we provide several conceptual discussions,
e.g. on the role of Lagrange parameters, global sampling, and the idea of a
Diffused NLP and a corresponding model-based denoising sampler.

摘要：在嚴格限制下產生多樣化樣本是許多領域的核心挑戰。透過這項工作，我們旨在提供一個整合的觀點和架構，以結合 MCMC、受限最佳化以及機器人領域的方法，並從經驗評估中獲得其優勢的見解。我們提出 NLP 採樣作為一個通用的問題表述，提出一個重新啟動兩階段方法的系列，作為一個整合跨領域方法的架構，並在分析和機器人操作規劃問題上評估它們。補充這一點，我們提供了幾個概念性討論，例如，關於拉格朗日參數、全局採樣以及擴散 NLP 和相應的基於模型的去噪採樣器的概念。

##### **Strategies for Arabic Readability Modeling**
2407.03032v1 by Juan Piñeros Liberato, Bashar Alhafni, Muhamed Al Khalil, Nizar Habash

Automatic readability assessment is relevant to building NLP applications for
education, content analysis, and accessibility. However, Arabic readability
assessment is a challenging task due to Arabic's morphological richness and
limited readability resources. In this paper, we present a set of experimental
results on Arabic readability assessment using a diverse range of approaches,
from rule-based methods to Arabic pretrained language models. We report our
results on a newly created corpus at different textual granularity levels
(words and sentence fragments). Our results show that combining different
techniques yields the best results, achieving an overall macro F1 score of 86.7
at the word level and 87.9 at the fragment level on a blind test set. We make
our code, data, and pretrained models publicly available.

摘要：自動可讀性評估與建構用於教育、內容分析和無障礙存取的 NLP 應用程式相關。然而，由於阿拉伯語的豐富形態和有限的可讀性資源，阿拉伯語的可讀性評估是一項艱鉅的任務。在本文中，我們提出了一組使用各種方法的阿拉伯語可讀性評估實驗結果，從基於規則的方法到阿拉伯語預訓練語言模型。我們報告了我們在不同文本粒度層級（字詞和句子片段）上新建立的語料庫上的結果。我們的結果顯示，結合不同的技術可產生最佳結果，在盲測集中，字詞層級的整體巨觀 F1 分數達到 86.7，片段層級達到 87.9。我們公開我們的程式碼、資料和預訓練模型。

##### **Qifusion-Net: Layer-adapted Stream/Non-stream Model for End-to-End Multi-Accent Speech Recognition**
2407.03026v1 by Jinming Chen, Jingyi Fang, Yuanzhong Zheng, Yaoxuan Wang, Haojun Fei

Currently, end-to-end (E2E) speech recognition methods have achieved
promising performance. However, auto speech recognition (ASR) models still face
challenges in recognizing multi-accent speech accurately. We propose a
layer-adapted fusion (LAF) model, called Qifusion-Net, which does not require
any prior knowledge about the target accent. Based on dynamic chunk strategy,
our approach enables streaming decoding and can extract frame-level acoustic
feature, facilitating fine-grained information fusion. Experiment results
demonstrate that our proposed methods outperform the baseline with relative
reductions of 22.1$\%$ and 17.2$\%$ in character error rate (CER) across multi
accent test datasets on KeSpeech and MagicData-RMAC.

摘要：目前，端到端 (E2E) 语音识别方法已取得令人满意的性能。然而，自动语音识别 (ASR) 模型在准确识别多口音语音方面仍面临挑战。我们提出了一种称为 Qifusion-Net 的层适应融合 (LAF) 模型，它不需要任何关于目标口音的先验知识。基于动态块策略，我们的方法支持流式解码，并且可以提取帧级声学特征，从而促进细粒度信息融合。实验结果表明，我们提出的方法在 KeSpeech 和 MagicData-RMAC 的多口音测试数据集上，字符错误率 (CER) 分别降低了 22.1% 和 17.2%，优于基线。

##### **Exploiting Dialect Identification in Automatic Dialectal Text Normalization**
2407.03020v1 by Bashar Alhafni, Sarah Al-Towaity, Ziyad Fawzy, Fatema Nassar, Fadhl Eryani, Houda Bouamor, Nizar Habash

Dialectal Arabic is the primary spoken language used by native Arabic
speakers in daily communication. The rise of social media platforms has notably
expanded its use as a written language. However, Arabic dialects do not have
standard orthographies. This, combined with the inherent noise in
user-generated content on social media, presents a major challenge to NLP
applications dealing with Dialectal Arabic. In this paper, we explore and
report on the task of CODAfication, which aims to normalize Dialectal Arabic
into the Conventional Orthography for Dialectal Arabic (CODA). We work with a
unique parallel corpus of multiple Arabic dialects focusing on five major city
dialects. We benchmark newly developed pretrained sequence-to-sequence models
on the task of CODAfication. We further show that using dialect identification
information improves the performance across all dialects. We make our code,
data, and pretrained models publicly available.

摘要：方言阿拉伯語是阿拉伯語母語人士在日常交流中使用的主要口語。社交媒體平台的興起顯著擴大了其作為書面語言的使用。然而，阿拉伯方言沒有標準正字法。這一點，加上社交媒體上用戶生成內容固有的噪音，對處理方言阿拉伯語的 NLP 應用構成了重大挑戰。在本文中，我們探討並報告了 CODA 化任務，其目標是將方言阿拉伯語標準化為方言阿拉伯語的傳統正字法 (CODA)。我們使用一個獨特的平行語料庫，其中包含多種阿拉伯方言，重點關注五種主要城市方言。我們對新開發的預訓練序列到序列模型在 CODA 化任務上的表現進行了基準測試。我們進一步表明，使用方言識別信息可以提高所有方言的性能。我們公開了我們的代碼、數據和預訓練模型。

##### **An Organism Starts with a Single Pix-Cell: A Neural Cellular Diffusion for High-Resolution Image Synthesis**
2407.03018v1 by Marawan Elbatel, Konstantinos Kamnitsas, Xiaomeng Li

Generative modeling seeks to approximate the statistical properties of real
data, enabling synthesis of new data that closely resembles the original
distribution. Generative Adversarial Networks (GANs) and Denoising Diffusion
Probabilistic Models (DDPMs) represent significant advancements in generative
modeling, drawing inspiration from game theory and thermodynamics,
respectively. Nevertheless, the exploration of generative modeling through the
lens of biological evolution remains largely untapped. In this paper, we
introduce a novel family of models termed Generative Cellular Automata (GeCA),
inspired by the evolution of an organism from a single cell. GeCAs are
evaluated as an effective augmentation tool for retinal disease classification
across two imaging modalities: Fundus and Optical Coherence Tomography (OCT).
In the context of OCT imaging, where data is scarce and the distribution of
classes is inherently skewed, GeCA significantly boosts the performance of 11
different ophthalmological conditions, achieving a 12% increase in the average
F1 score compared to conventional baselines. GeCAs outperform both diffusion
methods that incorporate UNet or state-of-the art variants with
transformer-based denoising models, under similar parameter constraints. Code
is available at: https://github.com/xmed-lab/GeCA.

摘要：生成式建模旨在逼近真實資料的統計屬性，能夠合成與原始分佈極為相似的全新資料。生成對抗網路 (GAN) 和去噪擴散機率模型 (DDPM) 分別從博弈論和熱力學中汲取靈感，代表生成式建模的重大進展。儘管如此，透過生物演化的觀點來探索生成式建模在很大程度上仍未開發。在本文中，我們引進一個新的模型家族，稱為生成式細胞自動機 (GeCA)，靈感來自單一細胞演化成一個有機體的過程。GeCA 被評估為視網膜疾病分類的有效擴充工具，涵蓋兩種影像模式：眼底和光學相干斷層掃描 (OCT)。在 OCT 影像的脈絡中，資料稀少且類別分佈本質上偏斜，GeCA 大幅提升了 11 種不同眼科疾病的效能，與傳統基準相比，平均 F1 分數提高了 12%。在類似的參數約束下，GeCA 的表現優於結合 UNet 的擴散方法或採用基於 Transformer 去噪模型的最新變體。程式碼可於 https://github.com/xmed-lab/GeCA 取得。

##### **What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks**
2407.03007v1 by Chengrui Huang, Zhengliang Shi, Yuntao Wen, Xiuying Chen, Peng Han, Shen Gao, Shuo Shang

Tool learning methods have enhanced the ability of large language models
(LLMs) to interact with real-world applications. Many existing works fine-tune
LLMs or design prompts to enable LLMs to select appropriate tools and correctly
invoke them to meet user requirements. However, it is observed in previous
works that the performance of tool learning varies from tasks, datasets,
training settings, and algorithms. Without understanding the impact of these
factors, it can lead to inconsistent results, inefficient model deployment, and
suboptimal tool utilization, ultimately hindering the practical integration and
scalability of LLMs in real-world scenarios. Therefore, in this paper, we
explore the impact of both internal and external factors on the performance of
tool learning frameworks. Through extensive experiments on two benchmark
datasets, we find several insightful conclusions for future work, including the
observation that LLMs can benefit significantly from increased trial and
exploration. We believe our empirical study provides a new perspective for
future tool learning research.

摘要：工具學習方法提升了大型語言模型 (LLM) 與真實世界應用程式互動的能力。許多現有作品微調 LLM 或設計提示，以使 LLM 能夠選擇適當的工具並正確呼叫它們以滿足使用者需求。然而，在先前的作品中觀察到，工具學習的效能會因任務、資料集、訓練設定和演算法而異。如果不了解這些因素的影響，可能會導致結果不一致、模型部署效率低落，以及工具利用率不佳，最終阻礙 LLM 在真實世界場景中的實際整合和可擴充性。因此，在本文中，我們探討了內部和外部因素對工具學習架構效能的影響。透過在兩個基準資料集上進行廣泛的實驗，我們發現了幾個對未來工作的有見地結論，包括觀察到 LLM 可以從增加的試驗和探索中受益匪淺。我們相信我們的實證研究為未來的工具學習研究提供了新的觀點。

##### **Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0**
2407.03005v1 by Marianne de Heer Kloots, Willem Zuidema

What do deep neural speech models know about phonology? Existing work has
examined the encoding of individual linguistic units such as phonemes in these
models. Here we investigate interactions between units. Inspired by classic
experiments on human speech perception, we study how Wav2Vec2 resolves
phonotactic constraints. We synthesize sounds on an acoustic continuum between
/l/ and /r/ and embed them in controlled contexts where only /l/, only /r/, or
neither occur in English. Like humans, Wav2Vec2 models show a bias towards the
phonotactically admissable category in processing such ambiguous sounds. Using
simple measures to analyze model internals on the level of individual stimuli,
we find that this bias emerges in early layers of the model's Transformer
module. This effect is amplified by ASR finetuning but also present in fully
self-supervised models. Our approach demonstrates how controlled stimulus
designs can help localize specific linguistic knowledge in neural speech
models.

摘要：深度神经语音模型對音韻學了解多少？現有的研究檢視了這些模型中個別語言單位的編碼，例如音素。在這裡，我們探討單位之間的交互作用。受人類語音感知經典實驗的啟發，我們研究 Wav2Vec2 如何解決音位約束。我們在 /l/ 和 /r/ 之間的聲學連續體上合成聲音，並將它們嵌入受控的語境中，其中只有 /l/、只有 /r/ 或兩者都不出現在英語中。與人類一樣，Wav2Vec2 模型在處理此類模稜兩可的聲音時表現出偏向音位學上可接受類別的傾向。使用簡單的測量方法來分析模型內部在個別刺激層級上的情況，我們發現這種偏見出現在模型 Transformer 模組的早期層級。這種效應會因 ASR 微調而放大，但也存在於完全自我監督的模型中。我們的做法展示了受控刺激設計如何有助於定位神經語音模型中的特定語言知識。

##### **SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**
2407.03004v1 by Meghal Dani, Muthu Jeyanthi Prakash, Zeynep Akata, Stefanie Liebe

Large Language Models have shown promising results in their ability to encode
general medical knowledge in standard medical question-answering datasets.
However, their potential application in clinical practice requires evaluation
in domain-specific tasks, where benchmarks are largely missing. In this study
semioLLM, we test the ability of state-of-the-art LLMs (GPT-3.5, GPT-4, Mixtral
8x7B, and Qwen-72chat) to leverage their internal knowledge and reasoning for
epilepsy diagnosis. Specifically, we obtain likelihood estimates linking
unstructured text descriptions of seizures to seizure-generating brain regions,
using an annotated clinical database containing 1269 entries. We evaluate the
LLM's performance, confidence, reasoning, and citation abilities in comparison
to clinical evaluation. Models achieve above-chance classification performance
with prompt engineering significantly improving their outcome, with some models
achieving close-to-clinical performance and reasoning. However, our analyses
also reveal significant pitfalls with several models being overly confident
while showing poor performance, as well as exhibiting citation errors and
hallucinations. In summary, our work provides the first extensive benchmark
comparing current SOTA LLMs in the medical domain of epilepsy and highlights
their ability to leverage unstructured texts from patients' medical history to
aid diagnostic processes in health care.

摘要：大型語言模型在標準醫療問答資料集中編碼一般醫療知識的能力方面已展現出可觀的成果。然而，它們在臨床實務中的潛在應用需要在特定領域任務中進行評估，而基準量測在很大程度上仍付之闕如。在本研究 semioLLM 中，我們測試了最先進的 LLM（GPT-3.5、GPT-4、Mixtral 8x7B 和 Qwen-72chat）利用其內部知識和推理進行癲癇診斷的能力。具體來說，我們取得了連結癲癇發作非結構化文字描述至癲癇發作生成腦區的可能性估計值，使用包含 1269 個條目的註解式臨床資料庫。我們評估了 LLM 的表現、信心、推理和引述能力，並與臨床評估進行比較。模型達到了高於機率的分類表現，提示工程顯著改善了其結果，有些模型達到了接近臨床表現和推理。然而，我們的分析也揭露了幾個模型的重大缺陷，它們過度自信，同時表現不佳，並出現引述錯誤和幻覺。總之，我們的研究提供了第一個廣泛的基準，比較了癲癇醫療領域中目前的 SOTA LLM，並突出了它們利用患者病史中的非結構化文字來協助醫療保健中的診斷程序的能力。

##### **VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values**
2407.03000v1 by Zhe Hu, Yixiao Ren, Jing Li, Yu Yin

This paper introduces VIVA, a benchmark for VIsion-grounded decision-making
driven by human VAlues. While most large vision-language models (VLMs) focus on
physical-level skills, our work is the first to examine their multimodal
capabilities in leveraging human values to make decisions under a
vision-depicted situation. VIVA contains 1,062 images depicting diverse
real-world situations and the manually annotated decisions grounded in them.
Given an image there, the model should select the most appropriate action to
address the situation and provide the relevant human values and reason
underlying the decision. Extensive experiments based on VIVA show the
limitation of VLMs in using human values to make multimodal decisions. Further
analyses indicate the potential benefits of exploiting action consequences and
predicted human values.

摘要：本文介紹 VIVA，一個由人類價值觀驅動的視覺決策基準。雖然大多數大型視覺語言模型 (VLM) 專注於物理層面的技能，但我們的研究首次探討了它們在利用人類價值觀在視覺描繪的情況下做出決策的多模態能力。VIVA 包含 1,062 張描繪各種真實世界情況的圖片，以及基於這些圖片的手動註解決策。給定圖片，模型應該選擇最合適的行動來解決情況，並提供決策背後相關的人類價值觀和原因。基於 VIVA 的廣泛實驗顯示了 VLM 在使用人類價值觀做出多模態決策方面的局限性。進一步的分析表明了利用行動後果和預測人類價值觀的潛在好處。

##### **Are Large Language Models Consistent over Value-laden Questions?**
2407.02996v1 by Jared Moore, Tanvi Deshpande, Diyi Yang

Large language models (LLMs) appear to bias their survey answers toward
certain values. Nonetheless, some argue that LLMs are too inconsistent to
simulate particular values. Are they? To answer, we first define value
consistency as the similarity of answers across (1) paraphrases of one
question, (2) related questions under one topic, (3) multiple-choice and
open-ended use-cases of one question, and (4) multilingual translations of a
question to English, Chinese, German, and Japanese. We apply these measures to
a few large ($>=34b$), open LLMs including llama-3, as well as gpt-4o, using
eight thousand questions spanning more than 300 topics. Unlike prior work, we
find that models are relatively consistent across paraphrases, use-cases,
translations, and within a topic. Still, some inconsistencies remain. Models
are more consistent on uncontroversial topics (e.g., in the U.S.,
"Thanksgiving") than on controversial ones ("euthanasia"). Base models are both
more consistent compared to fine-tuned models and are uniform in their
consistency across topics, while fine-tuned models are more inconsistent about
some topics ("euthanasia") than others ("women's rights") like our human
subjects (n=165).

摘要：大型語言模型 (LLM) 似乎會將其調查答案偏向於某些價值觀。儘管如此，有人認為 LLM 的不一致性過高，無法模擬特定值。是這樣嗎？為了回答這個問題，我們首先將價值一致性定義為以下各項答案的相似性：(1) 一個問題的同義詞改寫，(2) 一個主題下的相關問題，(3) 一個問題的多選和開放式用例，以及 (4) 一個問題的多語言翻譯成英文、中文、德文和日文。我們將這些措施應用於幾個大型 ($>=34b$) 開放式 LLM，包括 llama-3 和 gpt-4o，使用涵蓋 300 多個主題的 8,000 個問題。與先前的研究不同，我們發現模型在同義詞改寫、用例、翻譯以及主題內部具有相對一致性。儘管如此，仍存在一些不一致性。模型在無爭議性主題（例如，在美國，「感恩節」）上的表現比在有爭議性主題（「安樂死」）上更一致。基礎模型與微調模型相比，既更一致，且其在各個主題間的一致性也較為均勻，而微調模型在某些主題（「安樂死」）上比在其他主題（「婦女權利」）上更不一致，就像我們的人類受試者 (n=165) 一樣。

##### **MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**
2407.02994v1 by Irene Siragusa, Salvatore Contino, Massimo La Ciura, Rosario Alicata, Roberto Pirrone

The increasing interest in developing Artificial Intelligence applications in
the medical domain, suffers from the lack of high-quality dataset, mainly due
to privacy-related issues. Moreover, the recent rising of Multimodal Large
Language Models (MLLM) leads to a need for multimodal medical datasets, where
clinical reports and findings are attached to the corresponding CT or MR scans.
This paper illustrates the entire workflow for building the data set MedPix
2.0. Starting from the well-known multimodal dataset
MedPix\textsuperscript{\textregistered}, mainly used by physicians, nurses and
healthcare students for Continuing Medical Education purposes, a semi-automatic
pipeline was developed to extract visual and textual data followed by a manual
curing procedure where noisy samples were removed, thus creating a MongoDB
database. Along with the dataset, we developed a GUI aimed at navigating
efficiently the MongoDB instance, and obtaining the raw data that can be easily
used for training and/or fine-tuning MLLMs. To enforce this point, we also
propose a CLIP-based model trained on MedPix 2.0 for scan classification tasks.

摘要：隨著在醫療領域開發人工智慧應用程式的興趣日益增加，但由於隱私相關問題，導致缺乏高品質的資料集。此外，多模態大型語言模型 (MLLM) 的興起，需要建立多模態醫療資料集，其中臨床報告和發現會附加到對應的電腦斷層掃描或核磁共振掃描。本文說明建立資料集 MedPix 2.0 的完整工作流程。從廣為人知的由醫師、護理師和醫療保健學生主要用於持續醫療教育目的的多模態資料集 MedPix\textsuperscript{\textregistered} 開始，開發了一個半自動化管道來萃取視覺和文字資料，接著進行手動清理程序移除雜訊樣本，進而建立一個 MongoDB 資料庫。隨著資料集，我們開發了一個 GUI，旨在有效率地瀏覽 MongoDB 執行個體，並取得可用於訓練和/或微調 MLLM 的原始資料。為了強調這一點，我們也提出一個在 MedPix 2.0 上訓練的基於 CLIP 的模型，用於掃描分類任務。

##### **LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models**
2407.02987v1 by Hayder Elesedy, Pedro M. Esperança, Silviu Vlad Oprea, Mete Ozay

Guardrails have emerged as an alternative to safety alignment for content
moderation of large language models (LLMs). Existing model-based guardrails
have not been designed for resource-constrained computational portable devices,
such as mobile phones, more and more of which are running LLM-based
applications locally. We introduce LoRA-Guard, a parameter-efficient guardrail
adaptation method that relies on knowledge sharing between LLMs and guardrail
models. LoRA-Guard extracts language features from the LLMs and adapts them for
the content moderation task using low-rank adapters, while a dual-path design
prevents any performance degradation on the generative task. We show that
LoRA-Guard outperforms existing approaches with 100-1000x lower parameter
overhead while maintaining accuracy, enabling on-device content moderation.

摘要：護欄已成為大型語言模型 (LLM) 內容審核中安全比對的替代方案。現有的基於模型的護欄並未針對資源受限的計算型可攜式裝置（例如行動電話）而設計，而這些裝置越來越多地於本地執行基於 LLM 的應用程式。我們推出 LoRA-Guard，一種參數高效的護欄調整方法，它依賴於 LLM 和護欄模型之間的知識分享。LoRA-Guard 從 LLM 中擷取語言特徵，並使用低秩適配器調整它們以進行內容審核任務，而雙路徑設計可防止生成任務中的任何效能降低。我們展示 LoRA-Guard 在維持準確性的同時，以低於 100-1000 倍的參數開銷優於現有方法，從而能夠進行裝置上的內容審核。

##### **Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text**
2407.02978v1 by Jainit Sushil Bafna, Hardik Mittal, Suyash Sethia, Manish Shrivastava, Radhika Mamidi

Large Language Models (LLMs) have showcased impressive abilities in
generating fluent responses to diverse user queries. However, concerns
regarding the potential misuse of such texts in journalism, educational, and
academic contexts have surfaced. SemEval 2024 introduces the task of
Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text
Detection, aiming to develop automated systems for identifying
machine-generated text and detecting potential misuse. In this paper, we i)
propose a RoBERTa-BiLSTM based classifier designed to classify text into two
categories: AI-generated or human ii) conduct a comparative study of our model
with baseline approaches to evaluate its effectiveness. This paper contributes
to the advancement of automatic text detection systems in addressing the
challenges posed by machine-generated text misuse. Our architecture ranked 46th
on the official leaderboard with an accuracy of 80.83 among 125.

摘要：大型語言模型 (LLM) 在對不同的使用者查詢產生流利的回應方面展現出令人印象深刻的能力。然而，對於在新聞、教育和學術領域中潛在濫用此類文本的擔憂已浮出檯面。SemEval 2024 引入了多生成器、多領域和多語言的黑盒子機器產生的文字偵測任務，旨在開發自動化系統以識別機器產生的文字並偵測潛在的濫用行為。在本文中，我們 i) 提出一個基於 RoBERTa-BiLSTM 的分類器，旨在將文字分類為兩類：AI 生成的或人 ii) 進行我們模型與基線方法的比較研究，以評估其有效性。本文有助於推進自動文字偵測系統，以應對機器產生的文字濫用所帶來的挑戰。我們的架構在 125 個架構中以 80.83 的準確率在官方排行榜中排名第 46 位。

##### **Large Language Models as Evaluators for Scientific Synthesis**
2407.02977v1 by Julia Evans, Jennifer D'Souza, Sören Auer

Our study explores how well the state-of-the-art Large Language Models
(LLMs), like GPT-4 and Mistral, can assess the quality of scientific summaries
or, more fittingly, scientific syntheses, comparing their evaluations to those
of human annotators. We used a dataset of 100 research questions and their
syntheses made by GPT-4 from abstracts of five related papers, checked against
human quality ratings. The study evaluates both the closed-source GPT-4 and the
open-source Mistral model's ability to rate these summaries and provide reasons
for their judgments. Preliminary results show that LLMs can offer logical
explanations that somewhat match the quality ratings, yet a deeper statistical
analysis shows a weak correlation between LLM and human ratings, suggesting the
potential and current limitations of LLMs in scientific synthesis evaluation.

摘要：我們的研究探討了最先進的大語言模型 (LLM)，例如 GPT-4 和 Mistral，如何評估科學摘要或更貼切地說，科學綜合的品質，並將其評估結果與人類註解者的評估結果進行比較。我們使用了一個資料集，其中包含 100 個研究問題和 GPT-4 從五篇相關論文摘要中得出的綜合，並與人類品質評分進行比對。這項研究評估了閉源的 GPT-4 和開源的 Mistral 模型評分這些摘要並提供其判斷理由的能力。初步結果顯示，LLM 能夠提供與品質評分大致相符的邏輯解釋，但更深入的統計分析顯示 LLM 和人類評分之間的關聯性很弱，這表明 LLM 在科學綜合評估中的潛力與當前限制。

##### **Unified Anomaly Detection methods on Edge Device using Knowledge Distillation and Quantization**
2407.02968v1 by Sushovan Jena, Arya Pulkit, Kajal Singh, Anoushka Banerjee, Sharad Joshi, Ananth Ganesh, Dinesh Singh, Arnav Bhavsar

With the rapid advances in deep learning and smart manufacturing in Industry
4.0, there is an imperative for high-throughput, high-performance, and fully
integrated visual inspection systems. Most anomaly detection approaches using
defect detection datasets, such as MVTec AD, employ one-class models that
require fitting separate models for each class. On the contrary, unified models
eliminate the need for fitting separate models for each class and significantly
reduce cost and memory requirements. Thus, in this work, we experiment with
considering a unified multi-class setup. Our experimental study shows that
multi-class models perform at par with one-class models for the standard MVTec
AD dataset. Hence, this indicates that there may not be a need to learn
separate object/class-wise models when the object classes are significantly
different from each other, as is the case of the dataset considered.
Furthermore, we have deployed three different unified lightweight architectures
on the CPU and an edge device (NVIDIA Jetson Xavier NX). We analyze the
quantized multi-class anomaly detection models in terms of latency and memory
requirements for deployment on the edge device while comparing
quantization-aware training (QAT) and post-training quantization (PTQ) for
performance at different precision widths. In addition, we explored two
different methods of calibration required in post-training scenarios and show
that one of them performs notably better, highlighting its importance for
unsupervised tasks. Due to quantization, the performance drop in PTQ is further
compensated by QAT, which yields at par performance with the original 32-bit
Floating point in two of the models considered.

摘要：<paragraph>隨著深度學習和智慧製造在工業 4.0 的快速進步，迫切需要高通量、高性能且完全整合的視覺檢測系統。大多數使用缺陷檢測資料集的異常檢測方法，例如 MVTec AD，採用需要為每個類別擬合單獨模型的一類模型。相反，統一模型消除了為每個類別擬合單獨模型的需要，並顯著降低成本和記憶體需求。因此，在這項工作中，我們嘗試考慮統一的多類別設定。我們的實驗研究表明，多類別模型在標準 MVTec AD 資料集的表現與一類別模型相當。因此，這表示當物件類別彼此顯著不同時，可能不需要學習單獨的物件/類別模型，就像所考慮的資料集的情況一樣。此外，我們已在 CPU 和邊緣裝置 (NVIDIA Jetson Xavier NX) 上部署了三種不同的統一輕量級架構。我們在延遲和記憶體需求方面分析量化的多類別異常檢測模型，以部署在邊緣裝置上，同時比較量化感知訓練 (QAT) 和訓練後量化 (PTQ) 在不同精度寬度下的效能。此外，我們探討了訓練後場景中需要的兩種不同校正方法，並顯示其中一種方法的表現顯著較佳，突顯其對非監督任務的重要性。由於量化，PTQ 中的效能下降進一步由 QAT 補償，在所考慮的兩個模型中產生與原始 32 位浮點相當的效能。</paragraph>

##### **FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering**
2407.02964v1 by Xiaochen Wang, Junqing He, Zhe yang, Yiru Wang, Xiangdi Meng, Kunhao Pan, Zhifang Sui

Large Language Models (LLMs) with chain-of-thought (COT) prompting have
demonstrated impressive abilities on simple nature language inference tasks.
However, they tend to perform poorly on Multi-hop Question Answering (MHQA)
tasks due to several challenges, including hallucination, error propagation and
limited context length. We propose a prompting method, Finite State Machine
(FSM) to enhance the reasoning capabilities of LLM for complex tasks in
addition to improved effectiveness and trustworthiness. Different from COT
methods, FSM addresses MHQA by iteratively decomposing a question into
multi-turn sub-questions, and self-correcting in time, improving the accuracy
of answers in each step. Specifically, FSM addresses one sub-question at a time
and decides on the next step based on its current result and state, in an
automaton-like format. Experiments on benchmarks show the effectiveness of our
method. Although our method performs on par with the baseline on relatively
simpler datasets, it excels on challenging datasets like Musique. Moreover,
this approach mitigates the hallucination phenomenon, wherein the correct final
answer can be recovered despite errors in intermediate reasoning. Furthermore,
our method improves LLMs' ability to follow specified output format
requirements, significantly reducing the difficulty of answer interpretation
and the need for reformatting.

摘要：大型語言模型 (LLM) 與思考鏈 (COT) 提示在簡單的自然語言推論任務中展現出令人印象深刻的能力。
然而，由於包括幻覺、錯誤傳播和有限的脈絡長度在內的若干挑戰，它們在多跳式問答 (MHQA) 任務中的表現往往不佳。我們提出了一種提示方法，有限狀態機 (FSM)，以增強 LLM 對複雜任務的推理能力，並提高其有效性和可信度。與 COT 方法不同，FSM 通過反覆將問題分解成多輪子問題，並及時自我糾正，以解決 MHQA，從而提高每一步答案的準確性。具體來說，FSM 一次處理一個子問題，並根據其當前結果和狀態，以類似自動機的格式決定下一步。基準測試的實驗顯示了我們方法的有效性。儘管我們的模型在相對簡單的數據集上與基準表現相當，但它在像 Musique 這樣的具有挑戰性的數據集上表現出色。此外，這種方法減輕了幻覺現象，其中正確的最終答案可以在中間推理出現錯誤的情況下恢復。此外，我們的模型提高了 LLM 遵循指定輸出格式要求的能力，大大降低了答案解釋的難度和重新格式化的需求。

##### **Towards a Scalable Reference-Free Evaluation of Generative Models**
2407.02961v1 by Azim Ospanov, Jingwei Zhang, Mohammad Jalali, Xuenan Cao, Andrej Bogdanov, Farzan Farnia

While standard evaluation scores for generative models are mostly
reference-based, a reference-dependent assessment of generative models could be
generally difficult due to the unavailability of applicable reference datasets.
Recently, the reference-free entropy scores, VENDI and RKE, have been proposed
to evaluate the diversity of generated data. However, estimating these scores
from data leads to significant computational costs for large-scale generative
models. In this work, we leverage the random Fourier features framework to
reduce the computational price and propose the Fourier-based Kernel Entropy
Approximation (FKEA) method. We utilize FKEA's approximated eigenspectrum of
the kernel matrix to efficiently estimate the mentioned entropy scores.
Furthermore, we show the application of FKEA's proxy eigenvectors to reveal the
method's identified modes in evaluating the diversity of produced samples. We
provide a stochastic implementation of the FKEA assessment algorithm with a
complexity $O(n)$ linearly growing with sample size $n$. We extensively
evaluate FKEA's numerical performance in application to standard image, text,
and video datasets. Our empirical results indicate the method's scalability and
interpretability applied to large-scale generative models. The codebase is
available at https://github.com/aziksh-ospanov/FKEA.

摘要：儘管生成模型的標準評估分數大多是
基於參考的，但由於沒有適用的參考資料集，因此生成模型的參考依賴性評估通常很困難。
最近，已經提出無參考熵分數 VENDI 和 RKE
來評估生成資料的多樣性。然而，從資料中估計這些分數會導致大規模生成
模型的顯著計算成本。在這項工作中，我們利用隨機傅立葉特徵架構來
降低計算成本，並提出基於傅立葉的核熵近似 (FKEA) 方法。我們利用 FKEA 的核矩陣近似特徵譜來有效估計所提到的熵分數。
此外，我們展示了 FKEA 的代理特徵向量的應用，以揭示
該方法在評估產生樣本的多樣性時識別出的模式。我們提供 FKEA 評估演算法的隨機實作，其
複雜度 $O(n)$ 隨樣本大小 $n$ 線性增長。我們廣泛
評估 FKEA 在應用於標準影像、文字
和影片資料集中的數值效能。我們的實證結果表明該方法的可擴充性和
可解釋性適用於大規模生成模型。程式碼庫可在 https://github.com/aziksh-ospanov/FKEA 取得。

##### **ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets**
2407.02960v1 by Ahmed Frikha, Nassim Walha, Ricardo Mendes, Krishna Kanth Nakka, Xue Jiang, Xuebing Zhou

This work addresses the timely yet underexplored problem of performing
inference and finetuning of a proprietary LLM owned by a model provider entity
on the confidential/private data of another data owner entity, in a way that
ensures the confidentiality of both the model and the data. Hereby, the
finetuning is conducted offsite, i.e., on the computation infrastructure of a
third-party cloud provider. We tackle this problem by proposing ObfuscaTune, a
novel, efficient and fully utility-preserving approach that combines a simple
yet effective obfuscation technique with an efficient usage of confidential
computing (only 5% of the model parameters are placed on TEE). We empirically
demonstrate the effectiveness of ObfuscaTune by validating it on GPT-2 models
with different sizes on four NLP benchmark datasets. Finally, we compare to a
na\"ive version of our approach to highlight the necessity of using random
matrices with low condition numbers in our approach to reduce errors induced by
the obfuscation.

摘要：本研究解決了一個及時但未被充分探討的問題，即以一種確保模型和數據機密性的方式，在另一個數據所有者實體的機密/私人數據上執行模型提供者實體擁有的專有 LLM 的推理和微調。在此，微調是在場外進行的，即在第三方雲提供商的計算基礎設施上。我們通過提出 ObfuscaTune 來解決這個問題，這是一種新穎、高效且完全保留效用的方法，它結合了一種簡單但有效的混淆技術與機密計算的有效使用（只有 5% 的模型參數被放置在 TEE 上）。我們通過在四個 NLP 基準數據集上驗證不同大小的 GPT-2 模型，經驗性地證明了 ObfuscaTune 的有效性。最後，我們將其與我們方法的「天真」版本進行比較，以強調在我們的過程中使用條件數低的隨機矩陣以減少混淆引起的錯誤的必要性。

##### **IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization**
2407.02956v1 by Ahmed Frikha, Nassim Walha, Krishna Kanth Nakka, Ricardo Mendes, Xue Jiang, Xuebing Zhou

In this work, we address the problem of text anonymization where the goal is
to prevent adversaries from correctly inferring private attributes of the
author, while keeping the text utility, i.e., meaning and semantics. We propose
IncogniText, a technique that anonymizes the text to mislead a potential
adversary into predicting a wrong private attribute value. Our empirical
evaluation shows a reduction of private attribute leakage by more than 90%.
Finally, we demonstrate the maturity of IncogniText for real-world applications
by distilling its anonymization capability into a set of LoRA parameters
associated with an on-device model.

摘要：在這項工作中，我們探討文字匿名化的問題，目標是防止對手正確推斷出作者的私人屬性，同時保留文字的實用性，即含義和語義。我們提出 IncogniText，這是一種匿名化文字的技術，用來誤導潛在對手預測錯誤的私人屬性值。我們的經驗評估顯示私人屬性洩漏減少了 90% 以上。最後，我們透過將 IncogniText 的匿名化能力提煉成一組與裝置上模型相關聯的 LoRA 參數，展示了 IncogniText 在實際應用中的成熟度。

##### **PII-Compass: Guiding LLM training data extraction prompts towards the target PII via grounding**
2407.02943v1 by Krishna Kanth Nakka, Ahmed Frikha, Ricardo Mendes, Xue Jiang, Xuebing Zhou

The latest and most impactful advances in large models stem from their
increased size. Unfortunately, this translates into an improved memorization
capacity, raising data privacy concerns. Specifically, it has been shown that
models can output personal identifiable information (PII) contained in their
training data. However, reported PIII extraction performance varies widely, and
there is no consensus on the optimal methodology to evaluate this risk,
resulting in underestimating realistic adversaries. In this work, we
empirically demonstrate that it is possible to improve the extractability of
PII by over ten-fold by grounding the prefix of the manually constructed
extraction prompt with in-domain data. Our approach, PII-Compass, achieves
phone number extraction rates of 0.92%, 3.9%, and 6.86% with 1, 128, and 2308
queries, respectively, i.e., the phone number of 1 person in 15 is extractable.

摘要：大型模型的最新且影響最大的進展源自它們的規模增加。不幸的是，這轉化為改進後的記憶容量，引發了資料隱私問題。具體來說，已顯示模型可以輸出其訓練資料中包含的個人可識別資訊 (PII)。然而，報告的 PIII 提取效能差異很大，對於評估此風險的最佳方法論尚未達成共識，導致低估實際的敵手。在這項工作中，我們透過使用領域內資料為手動建構的提取提示詞首，經驗性地證明可以將 PII 的可提取性提高十倍以上。我們的 PII-Compass 方法分別以 1、128 和 2308 個查詢，達到了 0.92%、3.9% 和 6.86% 的電話號碼提取率，亦即 15 人中就有 1 人的電話號碼是可提取的。

##### **Probing the Feasibility of Multilingual Speaker Anonymization**
2407.02937v1 by Sarina Meyer, Florian Lux, Ngoc Thang Vu

In speaker anonymization, speech recordings are modified in a way that the
identity of the speaker remains hidden. While this technology could help to
protect the privacy of individuals around the globe, current research restricts
this by focusing almost exclusively on English data. In this study, we extend a
state-of-the-art anonymization system to nine languages by transforming
language-dependent components to their multilingual counterparts. Experiments
testing the robustness of the anonymized speech against privacy attacks and
speech deterioration show an overall success of this system for all languages.
The results suggest that speaker embeddings trained on English data can be
applied across languages, and that the anonymization performance for a language
is mainly affected by the quality of the speech synthesis component used for
it.

摘要：在說話者匿名化中，語音錄音會以一種方式修改，說話者的身分將保持隱藏。雖然這項技術可以幫助保護全球個人隱私，但目前的研究幾乎只專注於英文資料，因而限制了這項技術。在本研究中，我們將最先進的匿名化系統延伸到九種語言，方法是將依賴語言的組成部分轉換為其多語言對應部分。測試匿名化語音對抗隱私攻擊和語音惡化的穩健性的實驗顯示，此系統對所有語言都獲得整體成功。結果表明，以英文資料訓練的說話者嵌入可以應用於各種語言，而且某種語言的匿名化效能主要受用於該語言的語音合成組成部分品質影響。

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

摘要：評估大型語言模型 (LLM) 的圖形理解和推理能力具有挑戰性，且通常不完整。現有的基準主要著重於純粹的圖形理解，缺乏對所有圖形類型和詳細功能定義的全面評估。本文提出了 GraCoRe，一個用於系統評估 LLM 的圖形理解和推理的基準。GraCoRe 使用三層階層分類法對模型進行分類和測試，將功能細分為 10 個不同的領域，並通過 19 個任務進行測試。我們的基準包含 11 個數據集，其中包含 5,140 個不同複雜度的圖形。我們評估了三個閉源和七個開源 LLM，從能力和任務角度進行了徹底的分析。主要發現表明語義豐富化增強了推理性能，節點排序影響任務成功，而處理較長文本的能力並不一定能改善圖形理解或推理。GraCoRe 在 https://github.com/ZIKEYUAN/GraCoRe 開源

##### **SFC: Achieve Accurate Fast Convolution under Low-precision Arithmetic**
2407.02913v1 by Liulu He, Yufei Zhao, Rui Gao, Yuan Du, Li Du

Fast convolution algorithms, including Winograd and FFT, can efficiently
accelerate convolution operations in deep models. However, these algorithms
depend on high-precision arithmetic to maintain inference accuracy, which
conflicts with the model quantization. To resolve this conflict and further
improve the efficiency of quantized convolution, we proposes SFC, a new algebra
transform for fast convolution by extending the Discrete Fourier Transform
(DFT) with symbolic computing, in which only additions are required to perform
the transformation at specific transform points, avoiding the calculation of
irrational number and reducing the requirement for precision. Additionally, we
enhance convolution efficiency by introducing correction terms to convert
invalid circular convolution outputs of the Fourier method into effective ones.
The numerical error analysis is presented for the first time in this type of
work and proves that our algorithms can provide a 3.68x multiplication
reduction for 3x3 convolution, while the Winograd algorithm only achieves a
2.25x reduction with similarly low numerical errors. Experiments carried out on
benchmarks and FPGA show that our new algorithms can further improve the
computation efficiency of quantized models while maintaining accuracy,
surpassing both the quantization-alone method and existing works on fast
convolution quantization.

摘要：快速卷積演算法，包括 Winograd 和 FFT，能有效加速深度模型中的卷積運算。然而，這些演算法依賴於高精度算術來維持推論準確度，這與模型量化產生衝突。為了解決這個衝突並進一步提升量化卷積的效率，我們提出了 SFC，一種新的代數轉換，用於快速卷積，透過擴充離散傅立葉轉換 (DFT) 與符號運算，其中只需要加法就能在特定轉換點執行轉換，避免計算無理數並減少對精度的需求。此外，我們透過引入修正項將傅立葉方法的無效循環卷積輸出轉換為有效的輸出，進而提升卷積效率。這類型的研究中首次提出數值誤差分析，並證明我們的演算法能為 3x3 卷積提供 3.68 倍的乘法運算減少，而 Winograd 演算法在同樣低的數值誤差下只能達到 2.25 倍的減少。在基準測試和 FPGA 上進行的實驗顯示，我們的演算法能進一步提升量化模型的運算效率，同時維持準確度，超越了僅量化方法和現有快速卷積量化研究。

##### **Translatotron-V(ison): An End-to-End Model for In-Image Machine Translation**
2407.02894v1 by Zhibin Lan, Liqiang Niu, Fandong Meng, Jie Zhou, Min Zhang, Jinsong Su

In-image machine translation (IIMT) aims to translate an image containing
texts in source language into an image containing translations in target
language. In this regard, conventional cascaded methods suffer from issues such
as error propagation, massive parameters, and difficulties in deployment and
retaining visual characteristics of the input image. Thus, constructing
end-to-end models has become an option, which, however, faces two main
challenges: 1) the huge modeling burden, as it is required to simultaneously
learn alignment across languages and preserve the visual characteristics of the
input image; 2) the difficulties of directly predicting excessively lengthy
pixel sequences. In this paper, we propose \textit{Translatotron-V(ision)}, an
end-to-end IIMT model consisting of four modules. In addition to an image
encoder, and an image decoder, our model contains a target text decoder and an
image tokenizer. Among them, the target text decoder is used to alleviate the
language alignment burden, and the image tokenizer converts long sequences of
pixels into shorter sequences of visual tokens, preventing the model from
focusing on low-level visual features. Besides, we present a two-stage training
framework for our model to assist the model in learning alignment across
modalities and languages. Finally, we propose a location-aware evaluation
metric called Structure-BLEU to assess the translation quality of the generated
images. Experimental results demonstrate that our model achieves competitive
performance compared to cascaded models with only 70.9\% of parameters, and
significantly outperforms the pixel-level end-to-end IIMT model.

摘要：圖像內機器翻譯 (IIMT) 旨在將包含原始語言文字的圖像翻譯成包含目標語言翻譯的圖像。在此方面，傳統的層疊方法存在錯誤傳播、參數龐大以及部署和保留輸入圖像視覺特徵困難等問題。因此，構建端到端模型已成為一種選擇，但它面臨著兩個主要挑戰：1) 龐大的建模負擔，因為它需要同時學習跨語言對齊並保留輸入圖像的視覺特徵；2) 直接預測過長的像素序列的困難。在本文中，我們提出了 Translatotron-V(ision)，一個由四個模組組成的端到端 IIMT 模型。除了影像編碼器和影像解碼器之外，我們的模型還包含目標文字解碼器和影像標記化器。其中，目標文字解碼器用於減輕語言對齊負擔，而影像標記化器將長像素序列轉換為較短的視覺標記序列，防止模型專注於低階視覺特徵。此外，我們為我們的模型提供了一個兩階段訓練架構，以協助模型學習跨模式和語言的對齊。最後，我們提出了一個稱為結構 BLEU 的位置感知評估指標，以評估生成圖像的翻譯品質。實驗結果表明，與只有 70.9% 參數的層疊模型相比，我們的模型達到了競爭力的效能，並且明顯優於像素級別的端到端 IIMT 模型。

##### **GPTQT: Quantize Large Language Models Twice to Push the Efficiency**
2407.02891v1 by Yipin Guo, Yilin Lang, Qinyuan Ren

Due to their large size, generative Large Language Models (LLMs) require
significant computing and storage resources. This paper introduces a new
post-training quantization method, GPTQT, to reduce memory usage and enhance
processing speed by expressing the weight of LLM in 3bit/2bit. Practice has
shown that minimizing the quantization error of weights is ineffective, leading
to overfitting. Therefore, GPTQT employs a progressive two-step approach:
initially quantizing weights using Linear quantization to a relatively high
bit, followed by converting obtained int weight to lower bit binary coding. A
re-explore strategy is proposed to optimize initial scaling factor. During
inference, these steps are merged into pure binary coding, enabling efficient
computation. Testing across various models and datasets confirms GPTQT's
effectiveness. Compared to the strong 3-bit quantization baseline, GPTQT
further reduces perplexity by 4.01 on opt-66B and increases speed by 1.24 times
on opt-30b. The results on Llama2 show that GPTQT is currently the best binary
coding quantization method for such kind of LLMs.

摘要：由於生成式大型語言模型 (LLM) 規模龐大，需要大量的運算和儲存資源。本文介紹一種新的訓練後量化方法 GPTQT，透過將 LLM 的權重表示為 3 位元/2 位元，以減少記憶體使用量並提升處理速度。實務上已證明，最小化權重的量化誤差無效，會導致過度擬合。因此，GPTQT 採用漸進的兩步驟方法：最初使用線性量化將權重量化到相對較高的位元，然後將取得的整數權重轉換為較低的位元二進位編碼。提出了一種重新探索策略，以最佳化初始縮放因子。在推論期間，這些步驟會合併成純二進位編碼，實現高效運算。跨各種模型和資料集的測試證實了 GPTQT 的有效性。與強大的 3 位元量化基準相比，GPTQT 進一步將 opt-66B 上的困惑度降低了 4.01，並將 opt-30b 上的速度提高了 1.24 倍。在 Llama2 上的結果顯示，GPTQT 目前是此類 LLM 最佳的二進位編碼量化方法。

##### **Joint Optimization of Resource Allocation and Data Selection for Fast and Cost-Efficient Federated Edge Learning**
2407.02888v1 by Yunjian Jia, Zhen Huang, Jiping Yan, Yulu Zhang, Kun Luo, Wanli Wen

Deploying federated learning at the wireless edge introduces federated edge
learning (FEEL). Given FEEL's limited communication resources and potential
mislabeled data on devices, improper resource allocation or data selection can
hurt convergence speed and increase training costs. Thus, to realize an
efficient FEEL system, this paper emphasizes jointly optimizing resource
allocation and data selection. Specifically, in this work, through rigorously
modeling the training process and deriving an upper bound on FEEL's one-round
convergence rate, we establish a problem of joint resource allocation and data
selection, which, unfortunately, cannot be solved directly. Toward this end, we
equivalently transform the original problem into a solvable form via a variable
substitution and then break it into two subproblems, that is, the resource
allocation problem and the data selection problem. The two subproblems are
mixed-integer non-convex and integer non-convex problems, respectively, and
achieving their optimal solutions is a challenging task. Based on the matching
theory and applying the convex-concave procedure and gradient projection
methods, we devise a low-complexity suboptimal algorithm for the two
subproblems, respectively. Finally, the superiority of our proposed scheme of
joint resource allocation and data selection is validated by numerical results.

摘要：在無線邊緣部署聯合學習引入了聯合邊緣學習 (FEEL)。鑒於 FEEL 的通訊資源有限，裝置上潛在的標籤錯誤資料，不適當的資源配置或資料選取會損害收斂速度，並增加訓練成本。因此，為了實現高效的 FEEL 系統，本文強調聯合最佳化資源配置和資料選取。具體來說，在這項工作中，透過嚴謹地對訓練過程建模，並推導出 FEEL 一輪收斂率的上限，我們建立了一個聯合資源配置和資料選取的問題，不幸的是，這個問題無法直接解決。為此，我們透過變數替換將原始問題等效轉換為可解的形式，然後將其分解為兩個子問題，即資源配置問題和資料選取問題。這兩個子問題分別是混合整數非凸問題和整數非凸問題，而取得它們的最適解是一項艱鉅的任務。基於匹配理論並應用凸凹程序和梯度投影方法，我們分別為這兩個子問題設計了一個低複雜度的次最佳演算法。最後，我們提出的聯合資源配置和資料選取方案的優越性已通過數值結果得到驗證。

##### **CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics**
2407.02885v1 by Azmine Toushik Wasi

Integrating cognitive ergonomics with LLMs is essential for enhancing safety,
reliability, and user satisfaction in human-AI interactions. Current LLM design
often lacks this integration, leading to systems that may not fully align with
human cognitive capabilities and limitations. Insufficient focus on
incorporating cognitive science methods exacerbates biases in LLM outputs,
while inconsistent application of user-centered design principles results in
sub-optimal user experiences. To address these challenges, our position paper
explores the critical integration of cognitive ergonomics principles into LLM
design, aiming to provide a comprehensive framework and practical guidelines
for ethical LLM development. Through our contributions, we seek to advance
understanding and practice in integrating cognitive ergonomics into LLM
systems, fostering safer, more reliable, and ethically sound human-AI
interactions.

摘要：整合認知人體工學與 LLM 對於提升安全性、可靠性，以及人在與 AI 互動時的滿意度至關重要。目前的 LLM 設計往往缺乏這種整合，導致系統可能無法完全符合人的認知能力和限制。在整合認知科學方法時，關注不足會加劇 LLM 輸出中的偏差，而使用者中心設計原則的不一致應用則會導致次佳的使用者體驗。為了應對這些挑戰，我們的立場文件探討了將認知人體工學原則整合到 LLM 設計中的關鍵，旨在為倫理 LLM 開發提供一個全面的架構和實務指南。透過我們的貢獻，我們尋求推進將認知人體工學整合到 LLM 系統中的理解和實務，促進更安全、更可靠，以及符合倫理的人機互動。

##### **Complex Event Recognition with Symbolic Register Transducers: Extended Technical Report**
2407.02884v1 by Elias Alevizos, Alexander Artikis, Georgios Paliouras

We present a system for Complex Event Recognition (CER) based on automata.
While multiple such systems have been described in the literature, they
typically suffer from a lack of clear and denotational semantics, a limitation
which often leads to confusion with respect to their expressive power. In order
to address this issue, our system is based on an automaton model which is a
combination of symbolic and register automata. We extend previous work on these
types of automata, in order to construct a formalism with clear semantics and a
corresponding automaton model whose properties can be formally investigated. We
call such automata Symbolic Register Transducers (SRT). We show that SRT are
closed under various operators, but are not in general closed under complement
and they are not determinizable. However, they are closed under these
operations when a window operator, quintessential in Complex Event Recognition,
is used. We show how SRT can be used in CER in order to detect patterns upon
streams of events, using our framework that provides declarative and
compositional semantics, and that allows for a systematic treatment of such
automata. For SRT to work in pattern detection, we allow them to mark events
from the input stream as belonging to a complex event or not, hence the name
"transducers". We also present an implementation of SRT which can perform CER.
We compare our SRT-based CER engine against other state-of-the-art CER systems
and show that it is both more expressive and more efficient.

摘要：<paragraph>我們提出一個基於自動機的複雜事件辨識 (CER) 系統。
儘管文獻中已描述過多個此類系統，但它們通常缺乏明確且可表示的語意，此限制通常會導致對其表達能力產生混淆。為了解決此問題，我們的系統基於自動機模型，該模型結合了符號自動機和暫存器自動機。我們擴展了對這些類型自動機的先前研究，以便建構具有明確語意且對應的自動機模型，其屬性可以正式研究。我們稱此類自動機為符號暫存器轉換器 (SRT)。我們證明 SRT 在各種運算元下是封閉的，但通常在補數下並非封閉，而且不可確定。然而，當使用在複雜事件辨識中至關重要的視窗運算元時，它們在這些運算下是封閉的。我們展示如何使用 SRT 在 CER 中偵測事件串流上的模式，使用我們提供的宣告式和組合式語意架構，並允許系統化處理此類自動機。為了讓 SRT 在模式偵測中運作，我們允許它們將輸入串流中的事件標記為屬於複雜事件或不屬於複雜事件，因此稱為「轉換器」。我們也提出一個可以執行 CER 的 SRT 實作。我們將我們基於 SRT 的 CER 引擎與其他最先進的 CER 系統進行比較，並證明它既更具表達力又更有效率。</paragraph>

##### **CoIR: A Comprehensive Benchmark for Code Information Retrieval Models**
2407.02883v1 by Xiangyang Li, Kuicai Dong, Yi Quan Lee, Wei Xia, Yichun Yin, Hao Zhang, Yong Liu, Yasheng Wang, Ruiming Tang

Despite the substantial success of Information Retrieval (IR) in various NLP
tasks, most IR systems predominantly handle queries and corpora in natural
language, neglecting the domain of code retrieval. Code retrieval is critically
important yet remains under-explored, with existing methods and benchmarks
inadequately representing the diversity of code in various domains and tasks.
Addressing this gap, we present \textbf{\name} (\textbf{Co}de
\textbf{I}nformation \textbf{R}etrieval Benchmark), a robust and comprehensive
benchmark specifically designed to assess code retrieval capabilities. \name
comprises \textbf{ten} meticulously curated code datasets, spanning
\textbf{eight} distinctive retrieval tasks across \textbf{seven} diverse
domains. We first discuss the construction of \name and its diverse dataset
composition. Further, we evaluate nine widely used retrieval models using
\name, uncovering significant difficulties in performing code retrieval tasks
even with state-of-the-art systems. To facilitate easy adoption and integration
within existing research workflows, \name has been developed as a user-friendly
Python framework, readily installable via pip. It shares same data schema as
other popular benchmarks like MTEB and BEIR, enabling seamless cross-benchmark
evaluations. Through \name, we aim to invigorate research in the code retrieval
domain, providing a versatile benchmarking tool that encourages further
development and exploration of code retrieval systems\footnote{\url{
https://github.com/CoIR-team/coir}}.

摘要：儘管資訊檢索 (IR) 在各種自然語言處理 (NLP) 任務中獲得顯著成功，但大多數 IR 系統主要處理自然語言中的查詢和語料庫，忽略了程式碼檢索領域。程式碼檢索至關重要，但仍未得到充分探索，現有方法和基準無法充分代表各個領域和任務中程式碼的多樣性。為了填補這一空白，我們提出了 **\name**（**程式碼** **資**訊 **檢**索基準），這是一個專門設計用於評估程式碼檢索功能的強大且全面的基準。**\name** 包含 **十** 個精心整理的程式碼資料集，涵蓋 **八** 個跨越 **七** 個不同領域的獨特檢索任務。我們首先討論了 **\name** 及其多樣化資料集組成的建構。此外，我們使用 **\name** 評估了九個廣泛使用的檢索模型，發現即使使用最先進的系統，執行程式碼檢索任務也存在顯著困難。為了便於在現有研究工作流程中輕鬆採用和整合，**\name** 已開發為一個使用者友善的 Python 框架，可透過 pip 輕鬆安裝。它與 MTEB 和 BEIR 等其他熱門基準共用相同的資料架構，可實現無縫的跨基準評估。透過 **\name**，我們旨在激勵程式碼檢索領域的研究，提供一個多功能的基準工具，鼓勵進一步開發和探索程式碼檢索系統\footnote{\url{ https://github.com/CoIR-team/coir}}。

##### **ShiftAddAug: Augment Multiplication-Free Tiny Neural Network with Hybrid Computation**
2407.02881v1 by Yipin Guo, Zihao Li, Yilin Lang, Qinyuan Ren

Operators devoid of multiplication, such as Shift and Add, have gained
prominence for their compatibility with hardware. However, neural networks
(NNs) employing these operators typically exhibit lower accuracy compared to
conventional NNs with identical structures. ShiftAddAug uses costly
multiplication to augment efficient but less powerful multiplication-free
operators, improving performance without any inference overhead. It puts a
ShiftAdd tiny NN into a large multiplicative model and encourages it to be
trained as a sub-model to obtain additional supervision. In order to solve the
weight discrepancy problem between hybrid operators, a new weight sharing
method is proposed. Additionally, a novel two stage neural architecture search
is used to obtain better augmentation effects for smaller but stronger
multiplication-free tiny neural networks. The superiority of ShiftAddAug is
validated through experiments in image classification and semantic
segmentation, consistently delivering noteworthy enhancements. Remarkably, it
secures up to a 4.95% increase in accuracy on the CIFAR100 compared to its
directly trained counterparts, even surpassing the performance of
multiplicative NNs.

摘要：缺乏乘法的算子，例如 Shift 和 Add，因其与硬件的相容性而获得
突出地位。然而，使用这些算子的神经网络 (NN) 通常表现出比
具有相同结构的传统神经网络更低的准确度。ShiftAddAug 使用代价高昂的
乘法来增强高效但功能较弱的无乘法算子，从而提高性能而没有任何推理开销。它将
ShiftAdd 微型神经网络放入大型乘法模型中，并鼓励将其训练为子模型以获得额外的监督。为了解决
混合算子之间的权重差异问题，提出了一种新的权重共享方法。此外，一种新颖的两阶段神经架构搜索
用于为更小但更强大的无乘法微型神经网络获得更好的增强效果。ShiftAddAug 的优越性
通过图像分类和语义分割的实验得到验证，始终提供值得注意的增强。值得注意的是，它
确保在 CIFAR100 上的准确度比其直接训练的对应项提高了 4.95%，甚至超过了
乘法神经网络的性能。

##### **Knowledge Composition using Task Vectors with Learned Anisotropic Scaling**
2407.02880v1 by Frederic Z. Zhang, Paul Albert, Cristian Rodriguez-Opazo, Anton van den Hengel, Ehsan Abbasnejad

Pre-trained models produce strong generic representations that can be adapted
via fine-tuning. The learned weight difference relative to the pre-trained
model, known as a task vector, characterises the direction and stride of
fine-tuning. The significance of task vectors is such that simple arithmetic
operations on them can be used to combine diverse representations from
different domains. This paper builds on these properties of task vectors and
aims to answer (1) whether components of task vectors, particularly parameter
blocks, exhibit similar characteristics, and (2) how such blocks can be used to
enhance knowledge composition and transfer. To this end, we introduce aTLAS, an
algorithm that linearly combines parameter blocks with different learned
coefficients, resulting in anisotropic scaling at the task vector level. We
show that such linear combinations explicitly exploit the low intrinsic
dimensionality of pre-trained models, with only a few coefficients being the
learnable parameters. Furthermore, composition of parameter blocks leverages
the already learned representations, thereby reducing the dependency on large
amounts of data. We demonstrate the effectiveness of our method in task
arithmetic, few-shot recognition and test-time adaptation, with supervised or
unsupervised objectives. In particular, we show that (1) learned anisotropic
scaling allows task vectors to be more disentangled, causing less interference
in composition; (2) task vector composition excels with scarce or no labeled
data and is less prone to domain shift, thus leading to better
generalisability; (3) mixing the most informative parameter blocks across
different task vectors prior to training can reduce the memory footprint and
improve the flexibility of knowledge transfer. Moreover, we show the potential
of aTLAS as a PEFT method, particularly with less data, and demonstrate that
its scalibility.

摘要：<paragraph>預先訓練的模型會產生強大的通用表示，可透過微調進行調整。相對於預先訓練模型的學習權重差異，稱為任務向量，特徵化了微調的方向和步幅。任務向量的意義在於，對它們進行簡單的算術運算可結合來自不同領域的多元表示。本文建立在任務向量的這些屬性之上，並旨在回答 (1) 任務向量的組成部分，特別是參數塊，是否展現出相似的特徵，以及 (2) 這些區塊如何用於增強知識組合和轉移。為此，我們引入了 aTLAS，一種將參數塊與不同的學習係數線性結合的演算法，導致任務向量層級的異向縮放。我們證明了這種線性組合明確地利用了預先訓練模型的低內在維度，只有少數係數是可學習的參數。此外，參數塊的組合利用了已學習的表示，從而減少了對大量資料的依賴。我們展示了我們的方法在任務算術、少次學習識別和測試時間適應中的有效性，並具有監督或非監督的目標。特別是，我們證明了 (1) 學習的異向縮放允許任務向量更為解開，導致組合中較少的干擾；(2) 任務向量組合在稀少或沒有標籤資料的情況下表現出色，並且較不易受到領域轉移的影響，從而導致更好的泛化能力；(3) 在訓練之前混合不同任務向量中最具資訊性的參數塊可以減少記憶體佔用空間並提高知識轉移的靈活性。此外，我們展示了 aTLAS 作為 PEFT 方法的潛力，特別是在資料較少的情況下，並證明了其可擴充性。</paragraph>

##### **Membership Inference Attacks Against Time-Series Models**
2407.02870v1 by Noam Koren, Abigail Goldsteen, Ariel Farkash, Guy Amit

Analyzing time-series data that may contain personal information,
particularly in the medical field, presents serious privacy concerns. Sensitive
health data from patients is often used to train machine-learning models for
diagnostics and ongoing care. Assessing the privacy risk of such models is
crucial to making knowledgeable decisions on whether to use a model in
production, share it with third parties, or deploy it in patients homes.
Membership Inference Attacks (MIA) are a key method for this kind of
evaluation, however time-series prediction models have not been thoroughly
studied in this context. We explore existing MIA techniques on time-series
models, and introduce new features, focusing on the seasonality and trend
components of the data. Seasonality is estimated using a multivariate Fourier
transform, and a low-degree polynomial is used to approximate trends. We
applied these techniques to various types of time-series models, using datasets
from the health domain. Our results demonstrate that these new features enhance
the effectiveness of MIAs in identifying membership, improving the
understanding of privacy risks in medical data applications.

摘要：分析可能包含个人信息的時間序列資料，特別是在醫療領域，會引發嚴重的隱私問題。病患的敏感健康資料經常被用於訓練機器學習模型，以進行診斷和持續照護。評估此類模型的隱私風險，對於在生產中使用模型、與第三方分享，或在病患家中部署模型時做出明智的決定至關重要。成員推論攻擊 (MIA) 是進行此類評估的一種關鍵方法，然而，在此背景下尚未徹底研究時序預測模型。我們探討了時序模型上現有的 MIA 技術，並引入了新的功能，重點關注資料的季節性和趨勢組成。季節性使用多變數傅立葉轉換來估計，低次多項式用於近似趨勢。我們將這些技術應用於各種類型的時序模型，使用來自健康領域的資料集。我們的結果表明，這些新功能增強了 MIA 在識別成員資格方面的效能，進而提升了對醫療資料應用中隱私風險的理解。

##### **Fast maneuver recovery from aerial observation: trajectory clustering and outliers rejection**
2407.02863v1 by Nelson de Moura, Augustin Gervreau-Mercier, Fernando Garrido, Fawzi Nashashibi

The implementation of road user models that realistically reproduce a
credible behavior in a multi-agentsimulation is still an open problem. A
data-driven approach consists on to deduce behaviors that may exist in real
situation to obtain different types of trajectories from a large set of
observations. The data, and its classification, could then be used to train
models capable to extrapolate such behavior. Cars and two different types of
Vulnerable Road Users (VRU) will be considered by the trajectory clustering
methods proposed: pedestrians and cyclists. The results reported here evaluate
methods to extract well-defined trajectory classes from raw data without the
use of map information while also separating ''eccentric'' or incomplete
trajectories from the ones that are complete and representative in any
scenario. Two environments will serve as test for the methods develop, three
different intersections and one roundabout. The resulting clusters of
trajectories can then be used for prediction or learning tasks or discarded if
it is composed by outliers.

摘要：在多代理模擬中真實再現可信行為的道路使用者模型實作，仍是一個未解的問題。資料驅動方法包括推論可能存在於真實情況中的行為，以從大量觀察中取得不同類型的軌跡。然後，資料及其分類可被用於訓練能夠推斷出此類行為的模型。由軌跡聚類方法考量汽車和兩種不同類型的易受傷害道路使用者 (VRU)：行人和自行車騎士。在此報告的結果評估了在不使用地圖資訊的情況下，從原始資料中萃取定義良好的軌跡類別的方法，同時也將「偏離」或不完整的軌跡與在任何場景中完整且具代表性的軌跡分開。兩個環境將作為開發方法的測試，三個不同的交叉路口和一個環形交叉路口。軌跡的結果群集可用於預測或學習任務，或在由異常值組成時予以捨棄。

##### **Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks**
2407.02855v1 by Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang

LLMs are known to be vulnerable to jailbreak attacks, even after safety
alignment. An important observation is that, while different types of jailbreak
attacks can generate significantly different queries, they mostly result in
similar responses that are rooted in the same harmful knowledge (e.g., detailed
steps to make a bomb). Therefore, we conjecture that directly unlearn the
harmful knowledge in the LLM can be a more effective way to defend against
jailbreak attacks than the mainstream supervised fine-tuning (SFT) based
approaches. Our extensive experiments confirmed our insight and suggested
surprising generalizability of our unlearning-based approach: using only 20 raw
harmful questions \emph{without} any jailbreak prompt during training, our
solution reduced the Attack Success Rate (ASR) in Vicuna-7B on
\emph{out-of-distribution} (OOD) harmful questions wrapped with various complex
jailbreak prompts from 82.6\% to 7.7\%. This significantly outperforms
Llama2-7B-Chat, which is fine-tuned on about 0.1M safety alignment samples but
still has an ASR of 21.9\% even under the help of an additional safety system
prompt. Further analysis reveals that the generalization ability of our
solution stems from the intrinsic relatedness among harmful responses across
harmful questions (e.g., response patterns, shared steps and actions, and
similarity among their learned representations in the LLM). Our code is
available at \url{https://github.com/thu-coai/SafeUnlearning}.

摘要：大型语言模型已知容易受到越狱攻击，即使在安全调整之后也是如此。一个重要的观察结果是，虽然不同类型的越狱攻击可以生成明显不同的查询，但它们大多会导致类似的响应，这些响应植根于相同的有害知识（例如，制造炸弹的详细步骤）。因此，我们推测直接取消大型语言模型中的有害知识可能是比基于主流监督微调 (SFT) 的方法更有效的防御越狱攻击的方法。我们广泛的实验证实了我们的见解，并表明了我们基于取消学习的方法令人惊讶的普遍性：仅在训练期间使用 20 个原始有害问题，没有任何越狱提示，我们的解决方案将 Vicuna-7B 上的攻击成功率 (ASR) 降低了 82.6% 至 7.7%。这明显优于 Llama2-7B-Chat，后者针对大约 0.1M 安全调整样本进行了微调，但即使在附加安全系统提示的帮助下，其 ASR 仍然为 21.9%。进一步的分析表明，我们解决方案的泛化能力源于有害问题中有害响应之间的内在相关性（例如，响应模式、共享步骤和操作，以及它们在大型语言模型中学习的表示之间的相似性）。我们的代码可在 https://github.com/thu-coai/SafeUnlearning 获得。

##### **Universal Gloss-level Representation for Gloss-free Sign Language Translation and Production**
2407.02854v1 by Eui Jun Hwang, Sukmin Cho, Huije Lee, Youngwoo Yoon, Jong C. Park

Sign language, essential for the deaf and hard-of-hearing, presents unique
challenges in translation and production due to its multimodal nature and the
inherent ambiguity in mapping sign language motion to spoken language words.
Previous methods often rely on gloss annotations, requiring time-intensive
labor and specialized expertise in sign language. Gloss-free methods have
emerged to address these limitations, but they often depend on external sign
language data or dictionaries, failing to completely eliminate the need for
gloss annotations. There is a clear demand for a comprehensive approach that
can supplant gloss annotations and be utilized for both Sign Language
Translation (SLT) and Sign Language Production (SLP). We introduce Universal
Gloss-level Representation (UniGloR), a unified and self-supervised solution
for both SLT and SLP, trained on multiple datasets including PHOENIX14T,
How2Sign, and NIASL2021. Our results demonstrate UniGloR's effectiveness in the
translation and production tasks. We further report an encouraging result for
the Sign Language Recognition (SLR) on previously unseen data. Our study
suggests that self-supervised learning can be made in a unified manner, paving
the way for innovative and practical applications in future research.

摘要：手語對於聾啞人士和聽障人士來說至關重要，由於其多模態的特性和將手語動作對應到口語單詞的固有模糊性，因此在翻譯和製作方面提出了獨特挑戰。
以往的方法通常依賴於註解說明，需要耗費時間密集的人力和手語方面的專業知識。無註解方法應運而生以解決這些限制，但它們通常依賴於外部手語數據或字典，無法完全消除對註解說明的需求。顯然需要一種綜合方法，既可以取代註解說明，又可以同時用於手語翻譯 (SLT) 和手語製作 (SLP)。我們引入了通用註解級別表示法 (UniGloR)，這是一種統一且自監督的解決方案，適用於 SLT 和 SLP，並在包括 PHOENIX14T、How2Sign 和 NIASL2021 在內的 multiple 數據集上進行了訓練。我們的結果證明了 UniGloR 在翻譯和製作任務中的有效性。我們進一步報告了先前未見數據的手語識別 (SLR) 的令人鼓舞的結果。我們的研究表明，自監督學習可以以統一的方式進行，為未來研究中的創新和實際應用鋪平了道路。

##### **MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis**
2407.02842v1 by Lei Chen, Feng Yan, Yujie Zhong, Shaoxiang Chen, Zequn Jie, Lin Ma

Multimodal Large Language Models (MLLM) have made significant progress in the
field of document analysis. Despite this, existing benchmarks typically focus
only on extracting text and simple layout information, neglecting the complex
interactions between elements in structured documents such as mind maps and
flowcharts. To address this issue, we introduce the new benchmark named
MindBench, which not only includes meticulously constructed bilingual authentic
or synthetic images, detailed annotations, evaluation metrics and baseline
models, but also specifically designs five types of structured understanding
and parsing tasks. These tasks include full parsing, partial parsing,
position-related parsing, structured Visual Question Answering (VQA), and
position-related VQA, covering key areas such as text recognition, spatial
awareness, relationship discernment, and structured parsing. Extensive
experimental results demonstrate the substantial potential and significant room
for improvement in current models' ability to handle structured document
information. We anticipate that the launch of MindBench will significantly
advance research and application development in structured document analysis
technology. MindBench is available at:
https://miasanlei.github.io/MindBench.github.io/.

摘要：多模态大型语言模型 (MLLM) 在文件分析领域取得了重大进展。尽管如此，现有的基准通常只专注于提取文本和简单的布局信息，而忽略了结构化文件（如思维导图和流程图）中元素之间的复杂交互。为了解决这个问题，我们引入了名为 MindBench 的新基准，它不仅包括精心构建的双语真实或合成图像、详细注释、评估指标和基线模型，还专门设计了五种类型的结构化理解和解析任务。这些任务包括完全解析、部分解析、位置相关解析、结构化视觉问答 (VQA) 和位置相关 VQA，涵盖文本识别、空间感知、关系辨别和结构化解析等关键领域。广泛的实验结果证明了当前模型处理结构化文档信息的能力具有巨大的潜力和显着的改进空间。我们预计 MindBench 的推出将极大地推进结构化文档分析技术的研究和应用开发。MindBench 可在以下网址获得：
https://miasanlei.github.io/MindBench.github.io/。

##### **LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation**
2407.02833v1 by Hongke Zhao, Songming Zheng, Likang Wu, Bowen Yu, Jing Wang

The explainability of recommendation systems is crucial for enhancing user
trust and satisfaction. Leveraging large language models (LLMs) offers new
opportunities for comprehensive recommendation logic generation. However, in
existing related studies, fine-tuning LLM models for recommendation tasks
incurs high computational costs and alignment issues with existing systems,
limiting the application potential of proven proprietary/closed-source LLM
models, such as GPT-4. In this work, our proposed effective strategy LANE
aligns LLMs with online recommendation systems without additional LLMs tuning,
reducing costs and improving explainability. This innovative approach addresses
key challenges in integrating language models with recommendation systems while
fully utilizing the capabilities of powerful proprietary models. Specifically,
our strategy operates through several key components: semantic embedding, user
multi-preference extraction using zero-shot prompting, semantic alignment, and
explainable recommendation generation using Chain of Thought (CoT) prompting.
By embedding item titles instead of IDs and utilizing multi-head attention
mechanisms, our approach aligns the semantic features of user preferences with
those of candidate items, ensuring coherent and user-aligned recommendations.
Sufficient experimental results including performance comparison, questionnaire
voting, and visualization cases prove that our method can not only ensure
recommendation performance, but also provide easy-to-understand and reasonable
recommendation logic.

摘要：推薦系統的可解釋性對於提升使用者信任度和滿意度至關重要。利用大型語言模型 (LLM) 為全面性的推薦邏輯生成提供了新的機會。然而，在現有的相關研究中，針對推薦任務微調 LLM 模型會產生高昂的運算成本，並與現有系統產生對齊問題，限制了已驗證的專有/閉源 LLM 模型（例如 GPT-4）的應用潛力。在本文中，我們提出的有效策略 LANE 將 LLM 與線上推薦系統對齊，無需額外的 LLM 調整，降低成本並提升可解釋性。這種創新的方法解決了將語言模型與推薦系統整合時遇到的關鍵挑戰，同時充分利用強大的專有模型的能力。具體來說，我們的策略透過幾個關鍵組件運作：語義嵌入、使用零次提示提取使用者多重偏好、語義對齊，以及使用思考鏈 (CoT) 提示產生可解釋的推薦。透過嵌入項目標題而非 ID，並利用多頭注意力機制，我們的做法將使用者偏好的語義特徵與候選項目的語義特徵對齊，確保推薦結果前後一致且符合使用者需求。充足的實驗結果，包括效能比較、問卷投票和視覺化案例，證明了我們的模型不僅能確保推薦效能，還能提供易於理解且合理的推薦邏輯。

##### **Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**
2407.02821v1 by Negin Ashrafi, Armin Abdollahi, Greg Placencia, Maryam Pishgar

Predicting critical health outcomes such as patient mortality and hospital
readmission is essential for improving survivability. However, healthcare
datasets have many concurrences that create complexities, leading to poor
predictions. Consequently, pre-processing the data is crucial to improve its
quality. In this study, we use an existing pre-processing algorithm,
concatenation, to improve data quality by decreasing the complexity of
datasets. Sixteen healthcare datasets were extracted from two databases - MIMIC
III and University of Illinois Hospital - converted to the event logs, they
were then fed into the concatenation algorithm. The pre-processed event logs
were then fed to the Split Miner (SM) algorithm to produce a process model.
Process model quality was evaluated before and after concatenation using the
following metrics: fitness, precision, F-Measure, and complexity. The
pre-processed event logs were also used as inputs to the Decay Replay Mining
(DREAM) algorithm to predict critical outcomes. We compared predicted results
before and after applying the concatenation algorithm using Area Under the
Curve (AUC) and Confidence Intervals (CI). Results indicated that the
concatenation algorithm improved the quality of the process models and
predictions of the critical health outcomes.

摘要：預測病患死亡率和醫院再入院等重大的健康結果，對於提升存活率至關重要。然而，醫療保健資料集有許多同時發生的事件，會造成複雜性，導致預測不佳。因此，預先處理資料對於提升資料品質至關重要。在本研究中，我們使用現有的預先處理演算法，連接，藉由降低資料集的複雜性來提升資料品質。從兩個資料庫中萃取出十六個醫療保健資料集 - MIMIC III 和伊利諾大學醫院 - 轉換成事件記錄，然後將其輸入連接演算法。接著將預先處理的事件記錄輸入 Split Miner (SM) 演算法，以產生流程模型。使用以下指標評估連接前後的流程模型品質：適用性、精確度、F-量測和複雜性。預先處理的事件記錄也用作衰減重播探勘 (DREAM) 演算法的輸入，以預測重大的結果。我們使用曲線下面積 (AUC) 和信心區間 (CI) 比較套用連接演算法前後的預測結果。結果顯示連接演算法提升了流程模型的品質和對重大健康結果的預測。

##### **Investigating the Contextualised Word Embedding Dimensions Responsible for Contextual and Temporal Semantic Changes**
2407.02820v1 by Taichi Aida, Danushka Bollegala

Words change their meaning over time as well as in different contexts. The
sense-aware contextualised word embeddings (SCWEs) such as the ones produced by
XL-LEXEME by fine-tuning masked langauge models (MLMs) on Word-in-Context (WiC)
data attempt to encode such semantic changes of words within the contextualised
word embedding (CWE) spaces. Despite the superior performance of SCWEs in
contextual/temporal semantic change detection (SCD) benchmarks, it remains
unclear as to how the meaning changes are encoded in the embedding space. To
study this, we compare pre-trained CWEs and their fine-tuned versions on
contextual and temporal semantic change benchmarks under Principal Component
Analysis (PCA) and Independent Component Analysis (ICA) transformations. Our
experimental results reveal several novel insights such as (a) although there
exist a smaller number of axes that are responsible for semantic changes of
words in the pre-trained CWE space, this information gets distributed across
all dimensions when fine-tuned, and (b) in contrast to prior work studying the
geometry of CWEs, we find that PCA to better represent semantic changes than
ICA. Source code is available at https://github.com/LivNLP/svp-dims .

摘要：隨著時間推移以及在不同語境中，詞彙的意義會發生改變。語義感知的語境化詞彙嵌入 (SCWE)（例如，通過在語境中詞彙 (WiC) 資料上微調遮罩語言模型 (MLM) 所產生的詞彙嵌入）嘗試對語境化詞彙嵌入 (CWE) 空間內的此類語義變化進行編碼。儘管 SCWE 在語境/時態語義變化檢測 (SCD) 基準測試中表現優異，但語義變化是如何在嵌入空間中編碼的，這一點仍然不清楚。為了研究這一點，我們在主成分分析 (PCA) 和獨立成分分析 (ICA) 變換下，比較了預先訓練的 CWE 及其微調版本在語境和時態語義變化基準測試中的表現。我們的實驗結果揭示了幾項新穎的見解，例如 (a) 雖然在預先訓練的 CWE 空間中負責詞彙語義變化的軸較少，但此資訊在微調時會分佈到所有維度；以及 (b) 與之前研究 CWE 幾何形狀的工作相反，我們發現 PCA 比 ICA 更能很好地表示語義變化。原始碼可在 https://github.com/LivNLP/svp-dims 取得。

##### **Efficient Training of Language Models with Compact and Consistent Next Token Distributions**
2407.02819v1 by Ashutosh Sathe, Sunita Sarawagi

Maximizing the likelihood of the next token is an established, statistically
sound objective for pre-training language models. In this paper we show that we
can train better models faster by pre-aggregating the corpus with a collapsed
$n$-gram distribution. Previous studies have proposed corpus-level $n$-gram
statistics as a regularizer; however, the construction and querying of such
$n$-grams, if done naively, prove to be costly and significantly impede
training speed, thereby limiting their application in modern large language
model pre-training.
  We introduce an alternative compact representation of the next token
distribution that, in expectation, aligns with the complete $n$-gram
distribution while markedly reducing variance across mini-batches compared to
the standard next-token loss. Empirically, we demonstrate that both the
$n$-gram regularized model and our approximation yield substantial improvements
in model quality and convergence rate compared to existing methods.
Furthermore, our approximation facilitates scalability of gains to larger
datasets and models compared to the straightforward $n$-gram regularization
method.

摘要：最大化下一個符號的可能性是預訓練語言模型已建立的、在統計上合理的目標。在本文中，我們展示了我們可以透過使用折疊的 $n$-gram 分布預先彙總語料庫，來更快地訓練出更好的模型。先前的研究已提出語料庫級別的 $n$-gram 統計資料作為正則化器；然而，如果天真地進行此類 $n$-gram 的建構和查詢，證明代價高昂，且會顯著阻礙訓練速度，從而限制它們在現代大型語言模型預訓練中的應用。
我們引入了下一個符號分佈的替代緊湊表示法，在預期中，它與完整的 $n$-gram 分佈一致，同時顯著降低了與標準下一個符號損失相比的迷你批次間的變異。經驗上，我們證明了 $n$-gram 正則化模型和我們的近似值在模型品質和收斂速度方面都比現有方法有顯著改善。
此外，與直接的 $n$-gram 正則化方法相比，我們的近似值促進了收益對更大資料集和模型的可擴充性。

##### **Images Speak Louder than Words: Understanding and Mitigating Bias in Vision-Language Model from a Causal Mediation Perspective**
2407.02814v1 by Zhaotian Weng, Zijun Gao, Jerone Andrews, Jieyu Zhao

Vision-language models (VLMs) pre-trained on extensive datasets can
inadvertently learn biases by correlating gender information with specific
objects or scenarios. Current methods, which focus on modifying inputs and
monitoring changes in the model's output probability scores, often struggle to
comprehensively understand bias from the perspective of model components. We
propose a framework that incorporates causal mediation analysis to measure and
map the pathways of bias generation and propagation within VLMs. This approach
allows us to identify the direct effects of interventions on model bias and the
indirect effects of interventions on bias mediated through different model
components. Our results show that image features are the primary contributors
to bias, with significantly higher impacts than text features, specifically
accounting for 32.57% and 12.63% of the bias in the MSCOCO and PASCAL-SENTENCE
datasets, respectively. Notably, the image encoder's contribution surpasses
that of the text encoder and the deep fusion encoder. Further experimentation
confirms that contributions from both language and vision modalities are
aligned and non-conflicting. Consequently, focusing on blurring gender
representations within the image encoder, which contributes most to the model
bias, reduces bias efficiently by 22.03% and 9.04% in the MSCOCO and
PASCAL-SENTENCE datasets, respectively, with minimal performance loss or
increased computational demands.

摘要：視覺語言模型 (VLM) 在廣泛的資料集上進行預訓練，可能會因將性別資訊與特定物件或情境相關聯而無意間習得偏誤。目前的方法著重於修改輸入並監控模型輸出機率分數的變化，通常難以從模型組成的角度全面理解偏誤。我們提出了一個架構，結合因果中介分析來衡量和繪製 VLM 中偏誤產生和傳播的路徑。此方法讓我們能夠找出介入措施對模型偏誤的直接影響，以及介入措施對透過不同模型組成傳遞的偏誤的間接影響。我們的結果顯示，影像特徵是偏誤的主要貢獻者，其影響顯著高於文字特徵，特別是分別佔 MSCOCO 和 PASCAL-SENTENCE 資料集中偏誤的 32.57% 和 12.63%。值得注意的是，影像編碼器的貢獻超越了文字編碼器和深度融合編碼器。進一步的實驗證實，語言和視覺模式的貢獻是一致且不衝突的。因此，專注於模糊影像編碼器中的性別表徵，這是對模型偏誤貢獻最大的因素，分別在 MSCOCO 和 PASCAL-SENTENCE 資料集中有效減少偏誤 22.03% 和 9.04%，且效能損失或運算需求增加極小。

##### **Data Overfitting for On-Device Super-Resolution with Dynamic Algorithm and Compiler Co-Design**
2407.02813v1 by Gen Li, Zhihao Shu, Jie Ji, Minghai Qin, Fatemeh Afghah, Wei Niu, Xiaolong Ma

Deep neural networks (DNNs) are frequently employed in a variety of computer
vision applications. Nowadays, an emerging trend in the current video
distribution system is to take advantage of DNN's overfitting properties to
perform video resolution upscaling. By splitting videos into chunks and
applying a super-resolution (SR) model to overfit each chunk, this scheme of SR
models plus video chunks is able to replace traditional video transmission to
enhance video quality and transmission efficiency. However, many models and
chunks are needed to guarantee high performance, which leads to tremendous
overhead on model switching and memory footprints at the user end. To resolve
such problems, we propose a Dynamic Deep neural network assisted by a
Content-Aware data processing pipeline to reduce the model number down to one
(Dy-DCA), which helps promote performance while conserving computational
resources. Additionally, to achieve real acceleration on the user end, we
designed a framework that optimizes dynamic features (e.g., dynamic shapes,
sizes, and control flow) in Dy-DCA to enable a series of compilation
optimizations, including fused code generation, static execution planning, etc.
By employing such techniques, our method achieves better PSNR and real-time
performance (33 FPS) on an off-the-shelf mobile phone. Meanwhile, assisted by
our compilation optimization, we achieve a 1.7$\times$ speedup while saving up
to 1.61$\times$ memory consumption. Code available in
https://github.com/coulsonlee/Dy-DCA-ECCV2024.

摘要：深度神经網路 (DNN) 經常運用於各種電腦視覺應用中。現在，當前影片分發系統中出現的新趨勢是利用 DNN 的過擬合特性來執行影片解析度升頻。透過將影片分割成區塊，並對每個區塊套用超解析度 (SR) 模型來過擬合，這種 SR 模型加上影片區塊的架構能夠取代傳統的影片傳輸，以提升影片品質和傳輸效率。然而，需要許多模型和區塊才能保證高性能，這會導致使用者端在模型切換和記憶體使用量上產生極大的負擔。為了解決這些問題，我們提出了一個由內容感知資料處理管線輔助的動態深度神經網路，將模型數量減少到一個 (Dy-DCA)，這有助於提升性能，同時節省運算資源。此外，為了在使用者端實現真正的加速，我們設計了一個架構，用於最佳化 Dy-DCA 中的動態特徵（例如，動態形狀、大小和控制流程），以進行一系列編譯最佳化，包括融合程式碼產生、靜態執行規劃等。透過採用這種技術，我們的程式在現成的行動電話上實現了更好的 PSNR 和即時效能 (33 FPS)。同時，在我們的編譯最佳化的協助下，我們實現了 1.7 倍的速度提升，同時節省了多達 1.61 倍的記憶體使用量。程式碼可在 https://github.com/coulsonlee/Dy-DCA-ECCV2024 取得。

##### **Efficient DNN-Powered Software with Fair Sparse Models**
2407.02805v1 by Xuanqi Gao, Weipeng Jiang, Juan Zhai, Shiqing Ma, Xiaoyu Zhang, Chao Shen

With the emergence of the Software 3.0 era, there is a growing trend of
compressing and integrating large models into software systems, with
significant societal implications. Regrettably, in numerous instances, model
compression techniques impact the fairness performance of these models and thus
the ethical behavior of DNN-powered software. One of the most notable example
is the Lottery Ticket Hypothesis (LTH), a prevailing model pruning approach.
This paper demonstrates that fairness issue of LTHbased pruning arises from
both its subnetwork selection and training procedures, highlighting the
inadequacy of existing remedies. To address this, we propose a novel pruning
framework, Ballot, which employs a novel conflict-detection-based subnetwork
selection to find accurate and fair subnetworks, coupled with a refined
training process to attain a high-performance model, thereby improving the
fairness of DNN-powered software. By means of this procedure, Ballot improves
the fairness of pruning by 38.00%, 33.91%, 17.96%, and 35.82% compared to
state-of-the-art baselines, namely Magnitude Pruning, Standard LTH,
SafeCompress, and FairScratch respectively, based on our evaluation of five
popular datasets and three widely used models. Our code is available at
https://anonymous.4open.science/r/Ballot-506E.

摘要：隨著軟體 3.0 時代的來臨，將大型模型壓縮並整合到軟體系統中的趨勢日益盛行，對社會產生重大影響。遺憾的是，在許多情況下，模型壓縮技術會影響這些模型的公平性表現，進而影響 DNN 驅動軟體的道德行為。最著名的範例之一是樂透假說 (LTH)，一種盛行的模型修剪方法。本文證明，基於 LTH 的修剪的公平性問題源自於其子網路選擇和訓練程序，突顯現有補救措施的不足。為了解決這個問題，我們提出一個創新的修剪架構 Ballot，它採用一種基於衝突偵測的子網路選擇來尋找準確且公平的子網路，並結合精緻的訓練流程來獲得高性能模型，從而改善 DNN 驅動軟體的公平性。透過這個程序，與目前最先進的基準（分別為 Magnitude Pruning、Standard LTH、SafeCompress 和 FairScratch）相比，Ballot 將修剪的公平性提升了 38.00%、33.91%、17.96% 和 35.82%，根據我們對五個熱門資料集和三個廣泛使用的模型的評估。我們的程式碼可在 https://anonymous.4open.science/r/Ballot-506E 取得。

##### **Model-Enhanced LLM-Driven VUI Testing of VPA Apps**
2407.02791v1 by Suwan Li, Lei Bu, Guangdong Bai, Fuman Xie, Kai Chen, Chang Yue

The flourishing ecosystem centered around voice personal assistants (VPA),
such as Amazon Alexa, has led to the booming of VPA apps. The largest app
market Amazon skills store, for example, hosts over 200,000 apps. Despite their
popularity, the open nature of app release and the easy accessibility of apps
also raise significant concerns regarding security, privacy and quality.
Consequently, various testing approaches have been proposed to systematically
examine VPA app behaviors. To tackle the inherent lack of a visible user
interface in the VPA app, two strategies are employed during testing, i.e.,
chatbot-style testing and model-based testing. The former often lacks effective
guidance for expanding its search space, while the latter falls short in
interpreting the semantics of conversations to construct precise and
comprehensive behavior models for apps. In this work, we introduce Elevate, a
model-enhanced large language model (LLM)-driven VUI testing framework. Elevate
leverages LLMs' strong capability in natural language processing to compensate
for semantic information loss during model-based VUI testing. It operates by
prompting LLMs to extract states from VPA apps' outputs and generate
context-related inputs. During the automatic interactions with the app, it
incrementally constructs the behavior model, which facilitates the LLM in
generating inputs that are highly likely to discover new states. Elevate
bridges the LLM and the behavior model with innovative techniques such as
encoding behavior model into prompts and selecting LLM-generated inputs based
on the context relevance. Elevate is benchmarked on 4,000 real-world Alexa
skills, against the state-of-the-art tester Vitas. It achieves 15% higher state
space coverage compared to Vitas on all types of apps, and exhibits significant
advancement in efficiency.

摘要：以语音個人助理 (VPA) 為中心的蓬勃生態系統，例如 Amazon Alexa，已導致 VPA 應用程式蓬勃發展。例如，最大的應用程式市場 Amazon 技能商店，擁有超過 200,000 個應用程式。儘管它們很受歡迎，但應用程式發布的開放性質和應用程式的易於存取性也對安全性、隱私權和品質提出了重大的疑慮。因此，已提出各種測試方法來系統化地檢查 VPA 應用程式行為。為了解決 VPA 應用程式中缺乏可見使用者介面的問題，在測試期間採用了兩種策略，即聊天機器人式測試和基於模型的測試。前者常常缺乏有效的指導來擴展其搜尋空間，而後者則無法解釋對話的語義來建構應用程式的精確且全面的行為模型。在這項工作中，我們介紹 Elevate，一個由模型增強的大語言模型 (LLM) 驅動的 VUI 測試架構。Elevate 充分利用 LLM 在自然語言處理方面的強大功能，以彌補基於模型的 VUI 測試期間的語義資訊遺失。它的運作方式是提示 LLM 從 VPA 應用程式的輸出中提取狀態，並產生與內容相關的輸入。在與應用程式的自動互動期間，它會逐步建構行為模型，這有助於 LLM 產生極有可能發現新狀態的輸入。Elevate 使用創新的技術將 LLM 和行為模型聯繫起來，例如將行為模型編碼成提示，並根據內容相關性選擇 LLM 生成的輸入。Elevate 以 4,000 個真實世界的 Alexa 技能為基準，並針對最先進的測試員 Vitas 進行評量。與 Vitas 相比，它在所有類型的應用程式上實現了 15% 的更高狀態空間涵蓋率，並展現出顯著的效率提升。

##### **52B to 1T: Lessons Learned via Tele-FLM Series**
2407.02783v1 by Xiang Li, Yiqun Yao, Xin Jiang, Xuezhi Fang, Chao Wang, Xinzhang Liu, Zihan Wang, Yu Zhao, Xin Wang, Yuyao Huang, Shuangyong Song, Yongxiang Li, Zheng Zhang, Bo Zhao, Aixin Sun, Yequan Wang, Zhongjiang He, Zhongyuan Wang, Xuelong Li, Tiejun Huang

Large Language Models (LLMs) represent a significant stride toward Artificial
General Intelligence. As scaling laws underscore the potential of increasing
model sizes, the academic community has intensified its investigations into
LLMs with capacities exceeding 50 billion parameters. This technical report
builds on our prior work with Tele-FLM (also known as FLM-2), a publicly
available 52-billion-parameter model. We delve into two primary areas: we first
discuss our observation of Supervised Fine-tuning (SFT) on Tele-FLM-52B, which
supports the "less is more" approach for SFT data construction; second, we
demonstrate our experiments and analyses on the best practices for
progressively growing a model from 52 billion to 102 billion, and subsequently
to 1 trillion parameters. We will open-source a 1T model checkpoint, namely
Tele-FLM-1T, to advance further training and research.

摘要：大型語言模型 (LLM) 代表著朝向人工通用智慧邁進一大步。由於規模定律強調了增加模型規模的潛力，學術界已加強其對容量超過 500 億個參數的 LLM 的研究。這份技術報告建立在我們先前使用 Tele-FLM（也稱為 FLM-2）的研究之上，Tele-FLM 是一個公開可用的 520 億個參數模型。我們深入探討兩個主要領域：我們首先討論我們對 Tele-FLM-52B 上的監督微調 (SFT) 的觀察，這支持了 SFT 資料建構的「少即是多」方法；其次，我們展示我們對從 520 億個模型逐步增加到 1020 億個，再到 1 兆個參數的最佳實務的實驗和分析。我們將開源一個 1T 模型檢查點，即 Tele-FLM-1T，以推進進一步的訓練和研究。

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

摘要：知識圖嵌入 (KGE) 是知識圖 (KG) 用於服務各種人工智慧任務的常見方法。嵌入的適當維度取決於特定應用場景的儲存和運算條件。一旦需要新的維度，就需要從頭訓練新的 KGE 模型，這大大增加了訓練成本，並限制了 KGE 在服務各種場景中的效率和靈活性。在這項工作中，我們提出了一種新穎的 KGE 訓練框架 MED，通過它，我們可以訓練一次以獲得適用於具有不同維度需求的多個場景的可裁剪 KGE 模型，可以從中裁剪出所需維度的子模型並直接使用，而無需任何額外訓練。在 MED 中，我們提出了一種相互學習機制，以提高低維子模型的效能，並使高維子模型保留低維子模型具有的能力，一種進化改進機制，以促進高維子模型掌握低維子模型無法學習的知識，以及一種動態損失權重，以自適應地平衡多重損失。在 4 個標準 KG 完成資料集上的 3 個 KGE 模型、一個真實世界大規模 KG 上的 3 個實際應用場景以及將 MED 擴展到語言模型 BERT 的實驗中，展示了 MED 的有效性、高效率和靈活的可擴充性。

##### **A Framework for Quantum Finite-State Languages with Density Mapping**
2407.02776v1 by SeungYeop Baik, Sicheol Sung, Yo-Sub Han

A quantum finite-state automaton (QFA) is a theoretical model designed to
simulate the evolution of a quantum system with finite memory in response to
sequential input strings. We define the language of a QFA as the set of strings
that lead the QFA to an accepting state when processed from its initial state.
QFAs exemplify how quantum computing can achieve greater efficiency compared to
classical computing. While being one of the simplest quantum models, QFAs are
still notably challenging to construct from scratch due to the preliminary
knowledge of quantum mechanics required for superimposing unitary constraints
on the automata. Furthermore, even when QFAs are correctly assembled, the
limitations of a current quantum computer may cause fluctuations in the
simulation results depending on how an assembled QFA is translated into a
quantum circuit.
  We present a framework that provides a simple and intuitive way to build QFAs
and maximize the simulation accuracy. Our framework relies on two methods:
First, it offers a predefined construction for foundational types of QFAs that
recognize special languages MOD and EQU. They play a role of basic building
blocks for more complex QFAs. In other words, one can obtain more complex QFAs
from these foundational automata using standard language operations. Second, we
improve the simulation accuracy by converting these QFAs into quantum circuits
such that the resulting circuits perform well on noisy quantum computers.
  Our framework is available at https://github.com/sybaik1/qfa-toolkit.

摘要：量子有限狀態自動機 (QFA) 是一種理論模型，用來模擬量子系統在回應順序輸入字串時有限記憶的演化。我們將 QFA 的語言定義為一組字串，這些字串會在從其初始狀態處理時引導 QFA 進入接受狀態。QFA 說明了量子運算如何能比古典運算達到更高的效率。儘管 QFA 是最簡單的量子模型之一，但由於自動機上疊加酉約束所需的量子力學預備知識，從頭開始建構 QFA 仍極具挑戰性。此外，即使 QFA 正確組裝，當組裝好的 QFA 轉換成量子電路時，目前量子電腦的限制可能會導致模擬結果產生波動。
我們提出一個架構，提供一種簡單且直觀的方式來建構 QFA 並最大化模擬準確度。我們的架構依賴於兩種方法：首先，它為識別特殊語言 MOD 和 EQU 的基礎類型 QFA 提供預定義的建構。它們扮演了更複雜 QFA 基本建構模組的角色。換句話說，人們可以使用標準語言操作從這些基礎自動機中獲得更複雜的 QFA。其次，我們透過將這些 QFA 轉換成量子電路來改善模擬準確度，使得產生的電路能在有雜訊的量子電腦上執行良好。
我們的架構可以在 https://github.com/sybaik1/qfa-toolkit 取得。

##### **MLKD-BERT: Multi-level Knowledge Distillation for Pre-trained Language Models**
2407.02775v1 by Ying Zhang, Ziheng Yang, Shufan Ji

Knowledge distillation is an effective technique for pre-trained language
model compression. Although existing knowledge distillation methods perform
well for the most typical model BERT, they could be further improved in two
aspects: the relation-level knowledge could be further explored to improve
model performance; and the setting of student attention head number could be
more flexible to decrease inference time. Therefore, we are motivated to
propose a novel knowledge distillation method MLKD-BERT to distill multi-level
knowledge in teacher-student framework. Extensive experiments on GLUE benchmark
and extractive question answering tasks demonstrate that our method outperforms
state-of-the-art knowledge distillation methods on BERT. In addition, MLKD-BERT
can flexibly set student attention head number, allowing for substantial
inference time decrease with little performance drop.

摘要：知識蒸餾是一種針對預訓練語言模型壓縮的有效技術。儘管現有的知識蒸餾方法對最典型的模型 BERT 執行良好，但它們可以在兩個方面進一步改進：可以進一步探索關係層級知識以提高模型效能；並且可以更靈活地設定學生注意力頭部數量以減少推論時間。因此，我們有動力提出一個新穎的知識蒸餾方法 MLKD-BERT，以在師生架構中蒸餾多層級知識。在 GLUE 基準和萃取式問答任務上的廣泛實驗證明，我們的模型優於 BERT 上最先進的知識蒸餾方法。此外，MLKD-BERT 可以靈活地設定學生注意力頭部數量，允許在效能下降不多的情況下大幅減少推論時間。

##### **Automatic gradient descent with generalized Newton's method**
2407.02772v1 by Zhiqi Bu, Shiyun Xu

We propose the generalized Newton's method (GeN) -- a Hessian-informed
approach that applies to any optimizer such as SGD and Adam, and covers the
Newton-Raphson method as a sub-case. Our method automatically and dynamically
selects the learning rate that accelerates the convergence, without the
intensive tuning of the learning rate scheduler. In practice, out method is
easily implementable, since it only requires additional forward passes with
almost zero computational overhead (in terms of training time and memory cost),
if the overhead is amortized over many iterations. We present extensive
experiments on language and vision tasks (e.g. GPT and ResNet) to showcase that
GeN optimizers match the state-of-the-art performance, which was achieved with
carefully tuned learning rate schedulers. Code to be released at
\url{https://github.com/ShiyunXu/AutoGeN}.

摘要：我們提出廣義牛頓法 (GeN) -- 一種 Hessian 資訊法，適用於任何最佳化器，如 SGD 和 Adam，並涵蓋牛頓拉夫森法作為子案例。我們的法會自動且動態地選擇學習率，以加速收斂，而無需對學習率排程器進行密集調整。在實務上，我們的方法很容易實作，因為它只需要額外的前向傳遞，且幾乎沒有計算開銷（就訓練時間和記憶體成本而言），如果開銷攤銷在許多反覆運算中。我們在語言和視覺任務（例如 GPT 和 ResNet）上進行了廣泛的實驗，以展示 GeN 最佳化器符合最先進的效能，這是透過仔細調整的學習率排程器所達成的。程式碼將在 \url{https://github.com/ShiyunXu/AutoGeN} 發布。

##### **SF-GNN: Self Filter for Message Lossless Propagation in Deep Graph Neural Network**
2407.02762v1 by Yushan Zhu, Wen Zhang, Yajing Xu, Zhen Yao, Mingyang Chen, Huajun Chen

Graph Neural Network (GNN), with the main idea of encoding graph structure
information of graphs by propagation and aggregation, has developed rapidly. It
achieved excellent performance in representation learning of multiple types of
graphs such as homogeneous graphs, heterogeneous graphs, and more complex
graphs like knowledge graphs. However, merely stacking GNN layers may not
improve the model's performance and can even be detrimental. For the phenomenon
of performance degradation in deep GNNs, we propose a new perspective. Unlike
the popular explanations of over-smoothing or over-squashing, we think the
issue arises from the interference of low-quality node representations during
message propagation. We introduce a simple and general method, SF-GNN, to
address this problem. In SF-GNN, we define two representations for each node,
one is the node representation that represents the feature of the node itself,
and the other is the message representation specifically for propagating
messages to neighbor nodes. A self-filter module evaluates the quality of the
node representation and decides whether to integrate it into the message
propagation based on this quality assessment. Experiments on node
classification tasks for both homogeneous and heterogeneous graphs, as well as
link prediction tasks on knowledge graphs, demonstrate that our method can be
applied to various GNN models and outperforms state-of-the-art baseline methods
in addressing deep GNN degradation.

摘要：圖形神經網路 (GNN) 的主要概念是透過傳遞和彙總來編碼圖形結構資訊，發展迅速。它在多種類型圖形的表徵學習中取得極佳的表現，例如同質圖形、異質圖形，以及知識圖形等更複雜的圖形。然而，單純堆疊 GNN 層級可能無法提升模型效能，甚至可能造成負面影響。對於深度 GNN 中效能下降的現象，我們提出一個新的觀點。與過度平滑或過度壓縮的普遍解釋不同，我們認為這個問題源於訊息傳遞過程中低品質節點表徵的干擾。我們提出一個簡單且通用的方法 SF-GNN 來解決這個問題。在 SF-GNN 中，我們為每個節點定義兩個表徵，一個是表示節點本身特徵的節點表徵，另一個是專門用於將訊息傳遞至鄰近節點的訊息表徵。一個自我過濾模組會評估節點表徵的品質，並根據這個品質評估決定是否將其整合到訊息傳遞中。在同質和異質圖形的節點分類任務，以及知識圖形中的連結預測任務上的實驗證明，我們的這個方法可以應用於各種 GNN 模型，並且在解決深度 GNN 退化問題上優於現有的最佳基準方法。

##### **Emotion and Intent Joint Understanding in Multimodal Conversation: A Benchmarking Dataset**
2407.02751v1 by Rui Liu, Haolin Zuo, Zheng Lian, Xiaofen Xing, Björn W. Schuller, Haizhou Li

Emotion and Intent Joint Understanding in Multimodal Conversation (MC-EIU)
aims to decode the semantic information manifested in a multimodal
conversational history, while inferring the emotions and intents simultaneously
for the current utterance. MC-EIU is enabling technology for many
human-computer interfaces. However, there is a lack of available datasets in
terms of annotation, modality, language diversity, and accessibility. In this
work, we propose an MC-EIU dataset, which features 7 emotion categories, 9
intent categories, 3 modalities, i.e., textual, acoustic, and visual content,
and two languages, i.e., English and Mandarin. Furthermore, it is completely
open-source for free access. To our knowledge, MC-EIU is the first
comprehensive and rich emotion and intent joint understanding dataset for
multimodal conversation. Together with the release of the dataset, we also
develop an Emotion and Intent Interaction (EI$^2$) network as a reference
system by modeling the deep correlation between emotion and intent in the
multimodal conversation. With comparative experiments and ablation studies, we
demonstrate the effectiveness of the proposed EI$^2$ method on the MC-EIU
dataset. The dataset and codes will be made available at:
https://github.com/MC-EIU/MC-EIU.

摘要：多模态对话中的情感和意图联合理解（MC-EIU）
旨在解码多模态对话历史中体现的语义信息，同时推断当前话语中的情感和意图。MC-EIU 是许多人机界面的使能技术。然而，在注释、模态、语言多样性和可访问性方面缺乏可用的数据集。在这项工作中，我们提出了一个 MC-EIU 数据集，其中包含 7 个情感类别、9 个意图类别、3 个模态，即文本、声学和视觉内容，以及两种语言，即英语和普通话。此外，它是完全开源的，可以免费访问。据我们所知，MC-EIU 是第一个针对多模态对话的情感和意图联合理解的全面且丰富的语料库。随着数据集的发布，我们还开发了一个情感和意图交互 (EI$^2$) 网络作为参考系统，通过对多模态对话中情感和意图之间的深度相关性进行建模。通过对比实验和消融研究，我们在 MC-EIU 数据集上展示了所提出的 EI$^2$ 方法的有效性。数据集和代码将在以下位置提供：
https://github.com/MC-EIU/MC-EIU。

##### **Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data**
2407.02750v1 by Younghun Lee, Sungchul Kim, Ryan A. Rossi, Tong Yu, Xiang Chen

Large Language Models (LLMs) have been achieving competent performance on a
wide range of downstream tasks, yet existing work shows that inference on
structured data is challenging for LLMs. This is because LLMs need to either
understand long structured data or select the most relevant evidence before
inference, and both approaches are not trivial. This paper proposes a
framework, Learning to Reduce, that fine-tunes a language model with On-Policy
Learning to generate a reduced version of an input structured data. When
compared to state-of-the-art LLMs like GPT-4, Learning to Reduce not only
achieves outstanding performance in reducing the input, but shows
generalizability on different datasets. We further show that the model
fine-tuned with our framework helps LLMs better perform on table QA tasks
especially when the context is longer.

摘要：大型語言模型 (LLM) 已在廣泛的下游任務中實現勝任的表現，但現有工作顯示，LLM 對結構化資料的推論具有挑戰性。這是因為 LLM 需要在推論之前了解長結構化資料或選擇最相關的證據，而這兩種方法都不是微不足道的。本文提出一個框架，即學習簡化，微調一個語言模型，採用策略學習，以產生輸入結構化資料的簡化版本。與 GPT-4 等最先進的 LLM 相比，學習簡化不僅在簡化輸入方面取得傑出的表現，而且在不同的資料集上顯示出泛化性。我們進一步表明，使用我們的框架微調的模型有助於 LLM 在表格問答任務中表現得更好，特別是在上下文較長的情況下。

