{"2408.02964": {"publish_time": "2024-08-06", "title": "Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval", "paper_summary": "Large language models (LLMs) are fundamentally transforming human-facing\napplications in the health and well-being domains: boosting patient engagement,\naccelerating clinical decision-making, and facilitating medical education.\nAlthough state-of-the-art LLMs have shown superior performance in several\nconversational applications, evaluations within nutrition and diet applications\nare still insufficient. In this paper, we propose to employ the Registered\nDietitian (RD) exam to conduct a standard and comprehensive evaluation of\nstate-of-the-art LLMs, GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, assessing\nboth accuracy and consistency in nutrition queries. Our evaluation includes\n1050 RD exam questions encompassing several nutrition topics and proficiency\nlevels. In addition, for the first time, we examine the impact of Zero-Shot\n(ZS), Chain of Thought (CoT), Chain of Thought with Self Consistency (CoT-SC),\nand Retrieval Augmented Prompting (RAP) on both accuracy and consistency of the\nresponses. Our findings revealed that while these LLMs obtained acceptable\noverall performance, their results varied considerably with different prompts\nand question domains. GPT-4o with CoT-SC prompting outperformed the other\napproaches, whereas Gemini 1.5 Pro with ZS recorded the highest consistency.\nFor GPT-4o and Claude 3.5, CoT improved the accuracy, and CoT-SC improved both\naccuracy and consistency. RAP was particularly effective for GPT-4o to answer\nExpert level questions. Consequently, choosing the appropriate LLM and\nprompting technique, tailored to the proficiency level and specific domain, can\nmitigate errors and potential risks in diet and nutrition chatbots.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6b63\u5728\u5f9e\u6839\u672c\u4e0a\u8f49\u8b8a\u5065\u5eb7\u548c\u798f\u7949\u9818\u57df\u4e2d\u9762\u5411\u4eba\u985e\u7684\u61c9\u7528\uff1a\u63d0\u5347\u60a3\u8005\u53c3\u8207\u5ea6\u3001\u52a0\u901f\u81e8\u5e8a\u6c7a\u7b56\u5236\u5b9a\uff0c\u4e26\u4fc3\u9032\u91ab\u5b78\u6559\u80b2\u3002\u5118\u7ba1\u6700\u5148\u9032\u7684 LLM \u5df2\u5728\u591a\u9805\u5c0d\u8a71\u5f0f\u61c9\u7528\u4e2d\u5c55\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\uff0c\u4f46\u5728\u71df\u990a\u548c\u98f2\u98df\u61c9\u7528\u4e2d\u7684\u8a55\u4f30\u4ecd\u4e0d\u8db3\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u8b70\u63a1\u7528\u8a3b\u518a\u71df\u990a\u5e2b (RD) \u8003\u8a66\u4f86\u5c0d\u6700\u5148\u9032\u7684 LLM\u3001GPT-4o\u3001Claude 3.5 Sonnet \u548c Gemini 1.5 Pro \u9032\u884c\u6a19\u6e96\u4e14\u5168\u9762\u7684\u8a55\u4f30\uff0c\u8a55\u4f30\u71df\u990a\u67e5\u8a62\u7684\u6e96\u78ba\u6027\u548c\u4e00\u81f4\u6027\u3002\u6211\u5011\u7684\u8a55\u4f30\u5305\u542b 1050 \u500b RD \u8003\u8a66\u984c\u76ee\uff0c\u6db5\u84cb\u591a\u500b\u71df\u990a\u4e3b\u984c\u548c\u719f\u7df4\u7a0b\u5ea6\u3002\u6b64\u5916\uff0c\u6211\u5011\u9996\u6b21\u63a2\u8a0e\u96f6\u6b21\u5b78\u7fd2 (ZS)\u3001\u601d\u8003\u93c8 (CoT)\u3001\u5177\u6709\u81ea\u6211\u4e00\u81f4\u6027\u7684\u601d\u8003\u93c8 (CoT-SC) \u548c\u6aa2\u7d22\u589e\u5f37\u63d0\u793a (RAP) \u5c0d\u56de\u61c9\u6e96\u78ba\u6027\u548c\u4e00\u81f4\u6027\u7684\u5f71\u97ff\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u5118\u7ba1\u9019\u4e9b LLM \u7372\u5f97\u53ef\u63a5\u53d7\u7684\u6574\u9ad4\u6548\u80fd\uff0c\u4f46\u5176\u7d50\u679c\u56e0\u4e0d\u540c\u7684\u63d0\u793a\u548c\u554f\u984c\u9818\u57df\u800c\u6709\u5f88\u5927\u5dee\u7570\u3002\u4f7f\u7528 CoT-SC \u63d0\u793a\u7684 GPT-4o \u512a\u65bc\u5176\u4ed6\u65b9\u6cd5\uff0c\u800c\u4f7f\u7528 ZS \u7684 Gemini 1.5 Pro \u5247\u8a18\u9304\u5230\u6700\u9ad8\u7684\u4e00\u81f4\u6027\u3002\u5c0d\u65bc GPT-4o \u548c Claude 3.5\uff0cCoT \u63d0\u9ad8\u4e86\u6e96\u78ba\u6027\uff0c\u800c CoT-SC \u5247\u540c\u6642\u63d0\u9ad8\u4e86\u6e96\u78ba\u6027\u548c\u4e00\u81f4\u6027\u3002RAP \u5c0d\u65bc GPT-4o \u56de\u7b54\u5c08\u5bb6\u7d1a\u5225\u7684\u554f\u984c\u7279\u5225\u6709\u6548\u3002\u56e0\u6b64\uff0c\u9078\u64c7\u9069\u7576\u7684 LLM \u548c\u63d0\u793a\u6280\u5de7\uff0c\u4e26\u6839\u64da\u719f\u7df4\u7a0b\u5ea6\u548c\u7279\u5b9a\u9818\u57df\u9032\u884c\u8abf\u6574\uff0c\u53ef\u4ee5\u6e1b\u8f15\u98f2\u98df\u548c\u71df\u990a\u804a\u5929\u6a5f\u5668\u4eba\u7684\u932f\u8aa4\u548c\u6f5b\u5728\u98a8\u96aa\u3002", "author": "Iman Azimi et.al.", "authors": "Iman Azimi, Mohan Qi, Li Wang, Amir M. Rahmani, Youlin Li", "id": "2408.02964v1", "paper_url": "http://arxiv.org/abs/2408.02964v1", "repo": "null"}}