{"2405.15202": {"publish_time": "2024-05-24", "title": "Cross-Task Defense: Instruction-Tuning LLMs for Content Safety", "paper_summary": "Recent studies reveal that Large Language Models (LLMs) face challenges in\nbalancing safety with utility, particularly when processing long texts for NLP\ntasks like summarization and translation. Despite defenses against malicious\nshort questions, the ability of LLMs to safely handle dangerous long content,\nsuch as manuals teaching illicit activities, remains unclear. Our work aims to\ndevelop robust defenses for LLMs in processing malicious documents alongside\nbenign NLP task queries. We introduce a defense dataset comprised of\nsafety-related examples and propose single-task and mixed-task losses for\ninstruction tuning. Our empirical results demonstrate that LLMs can\nsignificantly enhance their capacity to safely manage dangerous content with\nappropriate instruction tuning. Additionally, strengthening the defenses of\ntasks most susceptible to misuse is effective in protecting LLMs against\nprocessing harmful information. We also observe that trade-offs between utility\nand safety exist in defense strategies, where Llama2, utilizing our proposed\napproach, displays a significantly better balance compared to Llama1.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5e73\u8861\u5b89\u5168\u6027\u8207\u5be6\u7528\u6027\u65b9\u9762\u9762\u81e8\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u8655\u7406\u9577\u7bc7\u6587\u5b57\u4ee5\u9032\u884c\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\uff08\u4f8b\u5982\u6458\u8981\u548c\u7ffb\u8b6f\uff09\u6642\u3002\u5118\u7ba1\u63a1\u53d6\u4e86\u9632\u7bc4\u60e1\u610f\u7c21\u77ed\u554f\u984c\u7684\u63aa\u65bd\uff0c\u4f46 LLM \u5b89\u5168\u8655\u7406\u5371\u96aa\u9577\u7bc7\u5167\u5bb9\uff08\u4f8b\u5982\u6559\u6388\u975e\u6cd5\u6d3b\u52d5\u7684\u624b\u518a\uff09\u7684\u80fd\u529b\u4ecd\u4e0d\u660e\u78ba\u3002\u6211\u5011\u7684\u7814\u7a76\u65e8\u5728\u70ba LLM \u8655\u7406\u60e1\u610f\u6587\u4ef6\u548c\u826f\u6027 NLP \u4efb\u52d9\u67e5\u8a62\u6642\u958b\u767c\u5f37\u5927\u7684\u9632\u79a6\u63aa\u65bd\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u5305\u542b\u8207\u5b89\u5168\u6027\u76f8\u95dc\u7bc4\u4f8b\u7684\u9632\u79a6\u6578\u64da\u96c6\uff0c\u4e26\u63d0\u51fa\u55ae\u4efb\u52d9\u548c\u6df7\u5408\u4efb\u52d9\u640d\u5931\u7528\u65bc\u6307\u4ee4\u8abf\u6574\u3002\u6211\u5011\u7684\u5be6\u8b49\u7d50\u679c\u8868\u660e\uff0cLLM \u53ef\u4ee5\u900f\u904e\u9069\u7576\u7684\u6307\u4ee4\u8abf\u6574\uff0c\u5927\u5e45\u63d0\u5347\u5176\u5b89\u5168\u7ba1\u7406\u5371\u96aa\u5167\u5bb9\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u52a0\u5f37\u6700\u5bb9\u6613\u88ab\u8aa4\u7528\u7684\u4efb\u52d9\u7684\u9632\u79a6\u63aa\u65bd\uff0c\u6709\u52a9\u65bc\u4fdd\u8b77 LLM \u4e0d\u8655\u7406\u6709\u5bb3\u8cc7\u8a0a\u3002\u6211\u5011\u9084\u89c0\u5bdf\u5230\uff0c\u5728\u9632\u79a6\u7b56\u7565\u4e2d\uff0c\u5be6\u7528\u6027\u548c\u5b89\u5168\u6027\u4e4b\u9593\u5b58\u5728\u6b0a\u8861\uff0c\u5176\u4e2d\u63a1\u7528\u6211\u5011\u63d0\u8b70\u65b9\u6cd5\u7684 Llama2\uff0c\u8207 Llama1 \u76f8\u6bd4\uff0c\u5c55\u73fe\u51fa\u660e\u986f\u66f4\u597d\u7684\u5e73\u8861\u3002", "author": "Yu Fu et.al.", "authors": "Yu Fu, Wen Xiao, Jia Chen, Jiachen Li, Evangelos Papalexakis, Aichi Chien, Yue Dong", "id": "2405.15202v1", "paper_url": "http://arxiv.org/abs/2405.15202v1", "repo": "null"}}