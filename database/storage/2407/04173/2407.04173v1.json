{"2407.04173": {"publish_time": "2024-07-04", "title": "Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs", "paper_summary": "Fine-tuning large language models (LLMs) on limited tabular data for\nclassification tasks can lead to \\textit{fine-tuning multiplicity}, where\nequally well-performing models make conflicting predictions on the same inputs\ndue to variations in the training process (i.e., seed, random weight\ninitialization, retraining on additional or deleted samples). This raises\ncritical concerns about the robustness and reliability of Tabular LLMs,\nparticularly when deployed for high-stakes decision-making, such as finance,\nhiring, education, healthcare, etc. This work formalizes the challenge of\nfine-tuning multiplicity in Tabular LLMs and proposes a novel metric to\nquantify the robustness of individual predictions without expensive model\nretraining. Our metric quantifies a prediction's stability by analyzing\n(sampling) the model's local behavior around the input in the embedding space.\nInterestingly, we show that sampling in the local neighborhood can be leveraged\nto provide probabilistic robustness guarantees against a broad class of\nfine-tuned models. By leveraging Bernstein's Inequality, we show that\npredictions with sufficiently high robustness (as defined by our measure) will\nremain consistent with high probability. We also provide empirical evaluation\non real-world datasets to support our theoretical results. Our work highlights\nthe importance of addressing fine-tuning instabilities to enable trustworthy\ndeployment of LLMs in high-stakes and safety-critical applications.", "paper_summary_zh": "\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4ee5\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u7684\u6709\u9650\u8868\u683c\u6570\u636e\u53ef\u80fd\u5bfc\u81f4\u201c\u5fae\u8c03\u591a\u91cd\u6027\u201d\uff0c\u5176\u4e2d\u6027\u80fd\u540c\u6837\u826f\u597d\u7684\u6a21\u578b\u5bf9\u76f8\u540c\u7684\u8f93\u5165\u505a\u51fa\u76f8\u4e92\u77db\u76fe\u7684\u9884\u6d4b\uff0c\u8fd9\u662f\u7531\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\uff08\u5373\u79cd\u5b50\u3001\u968f\u673a\u6743\u91cd\u521d\u59cb\u5316\u3001\u5728\u9644\u52a0\u6216\u5df2\u5220\u9664\u7684\u6837\u672c\u4e0a\u91cd\u65b0\u8bad\u7ec3\uff09\u3002\u8fd9\u5f15\u53d1\u4e86\u5bf9\u8868\u683c LLM \u7684\u7a33\u5065\u6027\u548c\u53ef\u9760\u6027\u7684\u5173\u952e\u62c5\u5fe7\uff0c\u5c24\u5176\u662f\u5728\u90e8\u7f72\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\u65f6\uff0c\u4f8b\u5982\u91d1\u878d\u3001\u62db\u8058\u3001\u6559\u80b2\u3001\u533b\u7597\u4fdd\u5065\u7b49\u3002\u8fd9\u9879\u5de5\u4f5c\u5c06\u8868\u683c LLM \u4e2d\u5fae\u8c03\u591a\u91cd\u6027\u7684\u6311\u6218\u5f62\u5f0f\u5316\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6307\u6807\u6765\u91cf\u5316\u5355\u4e2a\u9884\u6d4b\u7684\u7a33\u5065\u6027\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u6602\u8d35\u7684\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u3002\u6211\u4eec\u7684\u6307\u6807\u901a\u8fc7\u5206\u6790\uff08\u91c7\u6837\uff09\u6a21\u578b\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u56f4\u7ed5\u8f93\u5165\u7684\u5c40\u90e8\u884c\u4e3a\u6765\u91cf\u5316\u9884\u6d4b\u7684\u7a33\u5b9a\u6027\u3002\u6709\u8da3\u7684\u662f\uff0c\u6211\u4eec\u8868\u660e\u5728\u5c40\u90e8\u90bb\u57df\u4e2d\u91c7\u6837\u53ef\u4ee5\u7528\u6765\u9488\u5bf9\u5e7f\u6cdb\u7684\u5fae\u8c03\u6a21\u578b\u63d0\u4f9b\u6982\u7387\u7a33\u5065\u6027\u4fdd\u8bc1\u3002\u901a\u8fc7\u5229\u7528\u4f2f\u6069\u65af\u5766\u4e0d\u7b49\u5f0f\uff0c\u6211\u4eec\u8868\u660e\u5177\u6709\u8db3\u591f\u9ad8\u7a33\u5065\u6027\uff08\u7531\u6211\u4eec\u7684\u5ea6\u91cf\u5b9a\u4e49\uff09\u7684\u9884\u6d4b\u5c06\u59cb\u7ec8\u4fdd\u6301\u9ad8\u6982\u7387\u3002\u6211\u4eec\u8fd8\u63d0\u4f9b\u5bf9\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u7ecf\u9a8c\u8bc4\u4f30\u6765\u652f\u6301\u6211\u4eec\u7684\u7406\u8bba\u7ed3\u679c\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u5f3a\u8c03\u4e86\u89e3\u51b3\u5fae\u8c03\u4e0d\u7a33\u5b9a\u6027\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u4fbf\u5728\u9ad8\u98ce\u9669\u548c\u5b89\u5168\u5173\u952e\u578b\u5e94\u7528\u4e2d\u53ef\u4fe1\u5730\u90e8\u7f72 LLM\u3002", "author": "Faisal Hamman et.al.", "authors": "Faisal Hamman, Pasan Dissanayake, Saumitra Mishra, Freddy Lecue, Sanghamitra Dutta", "id": "2407.04173v1", "paper_url": "http://arxiv.org/abs/2407.04173v1", "repo": "null"}}