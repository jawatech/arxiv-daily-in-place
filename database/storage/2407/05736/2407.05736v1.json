{"2407.05736": {"publish_time": "2024-07-08", "title": "TransMA: an explainable multi-modal deep learning model for predicting properties of ionizable lipid nanoparticles in mRNA delivery", "paper_summary": "As the primary mRNA delivery vehicles, ionizable lipid nanoparticles (LNPs)\nexhibit excellent safety, high transfection efficiency, and strong immune\nresponse induction. However, the screening process for LNPs is time-consuming\nand costly. To expedite the identification of high-transfection-efficiency mRNA\ndrug delivery systems, we propose an explainable LNPs transfection efficiency\nprediction model, called TransMA. TransMA employs a multi-modal molecular\nstructure fusion architecture, wherein the fine-grained atomic spatial\nrelationship extractor named molecule 3D Transformer captures three-dimensional\nspatial features of the molecule, and the coarse-grained atomic sequence\nextractor named molecule Mamba captures one-dimensional molecular features. We\ndesign the mol-attention mechanism block, enabling it to align coarse and\nfine-grained atomic features and captures relationships between atomic spatial\nand sequential structures. TransMA achieves state-of-the-art performance in\npredicting transfection efficiency using the scaffold and cliff data splitting\nmethods on the current largest LNPs dataset, including Hela and RAW cell lines.\nMoreover, we find that TransMA captures the relationship between subtle\nstructural changes and significant transfection efficiency variations,\nproviding valuable insights for LNPs design. Additionally, TransMA's\npredictions on external transfection efficiency data maintain a consistent\norder with actual transfection efficiencies, demonstrating its robust\ngeneralization capability. The code, model and data are made publicly available\nat https://github.com/wklix/TransMA/tree/master. We hope that high-accuracy\ntransfection prediction models in the future can aid in LNPs design and initial\nscreening, thereby assisting in accelerating the mRNA design process.", "paper_summary_zh": "<paragraph>\u4f5c\u70ba\u4e3b\u8981\u7684 mRNA \u50b3\u905e\u8f09\u9ad4\uff0c\u53ef\u96fb\u96e2\u8102\u8cea\u5948\u7c73\u9846\u7c92 (LNP) \u5c55\u73fe\u51fa\u7d55\u4f73\u7684\u5b89\u5168\u6027\u3001\u9ad8\u8f49\u67d3\u6548\u7387\u548c\u5f37\u70c8\u7684\u514d\u75ab\u53cd\u61c9\u8a98\u5c0e\u3002\u7136\u800c\uff0cLNP \u7684\u7be9\u9078\u904e\u7a0b\u8017\u6642\u4e14\u6210\u672c\u9ad8\u6602\u3002\u70ba\u4e86\u52a0\u901f\u8b58\u5225\u9ad8\u8f49\u67d3\u6548\u7387 mRNA \u85e5\u7269\u50b3\u905e\u7cfb\u7d71\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u53ef\u89e3\u91cb\u7684 LNP \u8f49\u67d3\u6548\u7387\u9810\u6e2c\u6a21\u578b\uff0c\u7a31\u70ba TransMA\u3002TransMA \u63a1\u7528\u591a\u6a21\u614b\u5206\u5b50\u7d50\u69cb\u878d\u5408\u67b6\u69cb\uff0c\u5176\u4e2d\u540d\u70ba\u5206\u5b50 3D Transformer \u7684\u7d30\u7c92\u5316\u539f\u5b50\u7a7a\u9593\u95dc\u4fc2\u8403\u53d6\u5668\u64f7\u53d6\u5206\u5b50\u7684\u4e09\u7dad\u7a7a\u9593\u7279\u5fb5\uff0c\u800c\u540d\u70ba\u5206\u5b50 Mamba \u7684\u7c97\u7c92\u5316\u539f\u5b50\u5e8f\u5217\u8403\u53d6\u5668\u5247\u64f7\u53d6\u4e00\u7dad\u5206\u5b50\u7279\u5fb5\u3002\u6211\u5011\u8a2d\u8a08\u4e86 mol-attention \u6a5f\u5236\u5340\u584a\uff0c\u4f7f\u5176\u80fd\u5920\u6bd4\u5c0d\u7c97\u7c92\u5316\u548c\u7d30\u7c92\u5316\u7684\u539f\u5b50\u7279\u5fb5\uff0c\u4e26\u64f7\u53d6\u539f\u5b50\u7a7a\u9593\u548c\u5e8f\u5217\u7d50\u69cb\u4e4b\u9593\u7684\u95dc\u4fc2\u3002TransMA \u5728\u4f7f\u7528\u652f\u67b6\u548c\u61f8\u5d16\u8cc7\u6599\u5206\u5272\u65b9\u6cd5\u9810\u6e2c\u8f49\u67d3\u6548\u7387\u65b9\u9762\uff0c\u5728\u76ee\u524d\u6700\u5927\u7684 LNP \u8cc7\u6599\u96c6\u4e0a\uff08\u5305\u62ec Hela \u548c RAW \u7d30\u80de\u682a\uff09\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe TransMA \u64f7\u53d6\u4e86\u7d30\u5fae\u7d50\u69cb\u8b8a\u5316\u8207\u986f\u8457\u8f49\u67d3\u6548\u7387\u8b8a\u5316\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u70ba LNP \u8a2d\u8a08\u63d0\u4f9b\u4e86\u5bf6\u8cb4\u7684\u898b\u89e3\u3002\u6b64\u5916\uff0cTransMA \u5c0d\u5916\u90e8\u8f49\u67d3\u6548\u7387\u8cc7\u6599\u7684\u9810\u6e2c\u8207\u5be6\u969b\u8f49\u67d3\u6548\u7387\u4fdd\u6301\u4e00\u81f4\u7684\u9806\u5e8f\uff0c\u8b49\u660e\u4e86\u5176\u7a69\u5065\u7684\u6982\u5316\u80fd\u529b\u3002\u7a0b\u5f0f\u78bc\u3001\u6a21\u578b\u548c\u8cc7\u6599\u5df2\u5728 https://github.com/wklix/TransMA/tree/master \u516c\u958b\u3002\u6211\u5011\u5e0c\u671b\u672a\u4f86\u7684\u9ad8\u6e96\u78ba\u5ea6\u8f49\u67d3\u9810\u6e2c\u6a21\u578b\u80fd\u5354\u52a9 LNP \u8a2d\u8a08\u548c\u521d\u6b65\u7be9\u9078\uff0c\u5f9e\u800c\u5354\u52a9\u52a0\u901f mRNA \u8a2d\u8a08\u6d41\u7a0b\u3002</paragraph>", "author": "Kun Wu et.al.", "authors": "Kun Wu, Zixu Wang, Xiulong Yang, Yangyang Chen, Zhenqi Han, Jialu Zhang, Lizhuang Liu", "id": "2407.05736v1", "paper_url": "http://arxiv.org/abs/2407.05736v1", "repo": "null"}}