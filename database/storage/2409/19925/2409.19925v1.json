{"2409.19925": {"publish_time": "2024-09-30", "title": "Large Language Model Empowered Embedding Generator for Sequential Recommendation", "paper_summary": "Sequential Recommender Systems (SRS) are extensively applied across various\ndomains to predict users' next interaction by modeling their interaction\nsequences. However, these systems typically grapple with the long-tail problem,\nwhere they struggle to recommend items that are less popular. This challenge\nresults in a decline in user discovery and reduced earnings for vendors,\nnegatively impacting the system as a whole. Large Language Model (LLM) has the\npotential to understand the semantic connections between items, regardless of\ntheir popularity, positioning them as a viable solution to this dilemma. In our\npaper, we present LLMEmb, an innovative technique that harnesses LLM to create\nitem embeddings that bolster the performance of SRS. To align the capabilities\nof general-purpose LLM with the needs of the recommendation domain, we\nintroduce a method called Supervised Contrastive Fine-Tuning (SCFT). This\nmethod involves attribute-level data augmentation and a custom contrastive loss\ndesigned to tailor LLM for enhanced recommendation performance. Moreover, we\nhighlight the necessity of incorporating collaborative filtering signals into\nLLM-generated embeddings and propose Recommendation Adaptation Training (RAT)\nfor this purpose. RAT refines the embeddings to be optimally suited for SRS.\nThe embeddings derived from LLMEmb can be easily integrated with any SRS model,\nshowcasing its practical utility. Extensive experimentation on three real-world\ndatasets has shown that LLMEmb significantly improves upon current methods when\napplied across different SRS models.", "paper_summary_zh": "\u5e8f\u5217\u63a8\u85a6\u7cfb\u7d71 (SRS) \u5ee3\u6cdb\u61c9\u7528\u65bc\u5404\u7a2e\u9818\u57df\uff0c\u900f\u904e\u5efa\u6a21\u4f7f\u7528\u8005\u7684\u4e92\u52d5\u5e8f\u5217\u4f86\u9810\u6e2c\u4ed6\u5011\u7684\u4e0b\u4e00\u500b\u4e92\u52d5\u3002\u7136\u800c\uff0c\u9019\u4e9b\u7cfb\u7d71\u901a\u5e38\u6703\u9047\u5230\u9577\u5c3e\u554f\u984c\uff0c\u4e5f\u5c31\u662f\u96e3\u4ee5\u63a8\u85a6\u8f03\u4e0d\u53d7\u6b61\u8fce\u7684\u9805\u76ee\u3002\u6b64\u6311\u6230\u5c0e\u81f4\u4f7f\u7528\u8005\u63a2\u7d22\u6e1b\u5c11\uff0c\u4ee5\u53ca\u4f9b\u61c9\u5546\u6536\u76ca\u964d\u4f4e\uff0c\u5c0d\u7cfb\u7d71\u6574\u9ad4\u9020\u6210\u8ca0\u9762\u5f71\u97ff\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6709\u6f5b\u529b\u4e86\u89e3\u9805\u76ee\u4e4b\u9593\u7684\u8a9e\u7fa9\u95dc\u806f\uff0c\u800c\u4e0d\u7ba1\u5176\u53d7\u6b61\u8fce\u7a0b\u5ea6\u5982\u4f55\uff0c\u4f7f\u5176\u6210\u70ba\u89e3\u6c7a\u6b64\u56f0\u5883\u7684\u53ef\u884c\u65b9\u6848\u3002\u5728\u6211\u5011\u7684\u8ad6\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa LLMEmb\uff0c\u9019\u662f\u4e00\u7a2e\u5275\u65b0\u7684\u6280\u8853\uff0c\u5229\u7528 LLM \u4f86\u5efa\u7acb\u9805\u76ee\u5d4c\u5165\uff0c\u4ee5\u63d0\u5347 SRS \u7684\u6548\u80fd\u3002\u70ba\u4e86\u5c07\u901a\u7528 LLM \u7684\u529f\u80fd\u8207\u63a8\u85a6\u9818\u57df\u7684\u9700\u6c42\u7d50\u5408\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u7a31\u70ba\u76e3\u7763\u5c0d\u6bd4\u5fae\u8abf (SCFT) \u7684\u65b9\u6cd5\u3002\u6b64\u65b9\u6cd5\u6d89\u53ca\u5c6c\u6027\u5c64\u7d1a\u8cc7\u6599\u64f4\u5145\u548c\u81ea\u8a02\u5c0d\u6bd4\u640d\u5931\uff0c\u65e8\u5728\u8abf\u6574 LLM \u4ee5\u589e\u5f37\u63a8\u85a6\u6548\u80fd\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f37\u8abf\u5c07\u5354\u540c\u904e\u6ffe\u8a0a\u865f\u7d0d\u5165 LLM \u751f\u6210\u7684\u5d4c\u5165\u7684\u5fc5\u8981\u6027\uff0c\u4e26\u63d0\u51fa\u63a8\u85a6\u9069\u61c9\u8a13\u7df4 (RAT) \u4ee5\u9054\u5230\u6b64\u76ee\u7684\u3002RAT \u6703\u8abf\u6574\u5d4c\u5165\uff0c\u4f7f\u5176\u6700\u9069\u5408 SRS\u3002\u5f9e LLMEmb \u884d\u751f\u7684\u5d4c\u5165\u53ef\u4ee5\u8f15\u9b06\u8207\u4efb\u4f55 SRS \u6a21\u578b\u6574\u5408\uff0c\u5c55\u793a\u5176\u5be6\u7528\u6027\u3002\u5728\u4e09\u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0cLLMEmb \u5728\u61c9\u7528\u65bc\u4e0d\u540c SRS \u6a21\u578b\u6642\uff0c\u986f\u8457\u512a\u65bc\u76ee\u524d\u7684\u65b9\u6cd5\u3002", "author": "Qidong Liu et.al.", "authors": "Qidong Liu, Xian Wu, Wanyu Wang, Yejing Wang, Yuanshao Zhu, Xiangyu Zhao, Feng Tian, Yefeng Zheng", "id": "2409.19925v1", "paper_url": "http://arxiv.org/abs/2409.19925v1", "repo": "null"}}