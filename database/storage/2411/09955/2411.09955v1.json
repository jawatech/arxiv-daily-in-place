{"2411.09955": {"publish_time": "2024-11-15", "title": "Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era", "paper_summary": "The rapid advancement of large language models (LLMs) and multimodal learning\nhas transformed digital content creation and manipulation. Traditional visual\nediting tools require significant expertise, limiting accessibility. Recent\nstrides in instruction-based editing have enabled intuitive interaction with\nvisual content, using natural language as a bridge between user intent and\ncomplex editing operations. This survey provides an overview of these\ntechniques, focusing on how LLMs and multimodal models empower users to achieve\nprecise visual modifications without deep technical knowledge. By synthesizing\nover 100 publications, we explore methods from generative adversarial networks\nto diffusion models, examining multimodal integration for fine-grained content\ncontrol. We discuss practical applications across domains such as fashion, 3D\nscene manipulation, and video synthesis, highlighting increased accessibility\nand alignment with human intuition. Our survey compares existing literature,\nemphasizing LLM-empowered editing, and identifies key challenges to stimulate\nfurther research. We aim to democratize powerful visual editing across various\nindustries, from entertainment to education. Interested readers are encouraged\nto access our repository at\nhttps://github.com/tamlhp/awesome-instruction-editing.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u591a\u6a21\u614b\u5b78\u7fd2\u7684\u5feb\u901f\u9032\u5c55\u5df2\u7d93\u8f49\u8b8a\u4e86\u6578\u4f4d\u5167\u5bb9\u7684\u5efa\u7acb\u548c\u64cd\u4f5c\u3002\u50b3\u7d71\u7684\u8996\u89ba\u7de8\u8f2f\u5de5\u5177\u9700\u8981\u5927\u91cf\u7684\u5c08\u696d\u77e5\u8b58\uff0c\u9650\u5236\u4e86\u53ef\u53ca\u6027\u3002\u6700\u8fd1\u5728\u57fa\u65bc\u6307\u4ee4\u7684\u7de8\u8f2f\u4e0a\u53d6\u5f97\u7684\u9032\u5c55\uff0c\u4f7f\u7528\u81ea\u7136\u8a9e\u8a00\u4f5c\u70ba\u4f7f\u7528\u8005\u610f\u5716\u548c\u8907\u96dc\u7de8\u8f2f\u64cd\u4f5c\u4e4b\u9593\u7684\u6a4b\u6881\uff0c\u5be6\u73fe\u4e86\u8207\u8996\u89ba\u5167\u5bb9\u7684\u76f4\u89ba\u4e92\u52d5\u3002\u9019\u9805\u8abf\u67e5\u63d0\u4f9b\u4e86\u9019\u4e9b\u6280\u8853\u7684\u6982\u8ff0\uff0c\u91cd\u9ede\u5728\u65bc LLM \u548c\u591a\u6a21\u614b\u6a21\u578b\u5982\u4f55\u8b93\u4f7f\u7528\u8005\u5728\u6c92\u6709\u6df1\u5165\u6280\u8853\u77e5\u8b58\u7684\u60c5\u6cc1\u4e0b\uff0c\u5be6\u73fe\u7cbe\u78ba\u7684\u8996\u89ba\u4fee\u6539\u3002\u900f\u904e\u7d9c\u5408\u8d85\u904e 100 \u7bc7\u51fa\u7248\u54c1\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u5f9e\u751f\u6210\u5c0d\u6297\u7db2\u8def\u5230\u64f4\u6563\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u6aa2\u8996\u591a\u6a21\u614b\u6574\u5408\u4ee5\u9032\u884c\u7d30\u7dfb\u7684\u5167\u5bb9\u63a7\u5236\u3002\u6211\u5011\u8a0e\u8ad6\u4e86\u5728\u6642\u5c1a\u30013D \u5834\u666f\u64cd\u4f5c\u548c\u5f71\u7247\u5408\u6210\u7b49\u9818\u57df\u7684\u5be6\u969b\u61c9\u7528\uff0c\u5f37\u8abf\u4e86\u53ef\u53ca\u6027\u7684\u63d0\u5347\u548c\u8207\u4eba\u985e\u76f4\u89ba\u7684\u4e00\u81f4\u6027\u3002\u6211\u5011\u7684\u8abf\u67e5\u6bd4\u8f03\u4e86\u73fe\u6709\u7684\u6587\u737b\uff0c\u5f37\u8abf\u4e86 LLM \u8ce6\u80fd\u7684\u7de8\u8f2f\uff0c\u4e26\u627e\u51fa\u95dc\u9375\u6311\u6230\u4ee5\u6fc0\u52f5\u9032\u4e00\u6b65\u7684\u7814\u7a76\u3002\u6211\u5011\u7684\u76ee\u6a19\u662f\u8b93\u5f37\u5927\u7684\u8996\u89ba\u7de8\u8f2f\u5728\u5404\u7a2e\u7522\u696d\u4e2d\u6c11\u4e3b\u5316\uff0c\u5f9e\u5a1b\u6a02\u5230\u6559\u80b2\u3002\u6211\u5011\u9f13\u52f5\u6709\u8208\u8da3\u7684\u8b80\u8005\u5b58\u53d6\u6211\u5011\u7684\u8cc7\u6e90\u5eab\uff1a\nhttps://github.com/tamlhp/awesome-instruction-editing\u3002", "author": "Thanh Tam Nguyen et.al.", "authors": "Thanh Tam Nguyen, Zhao Ren, Trinh Pham, Phi Le Nguyen, Hongzhi Yin, Quoc Viet Hung Nguyen", "id": "2411.09955v1", "paper_url": "http://arxiv.org/abs/2411.09955v1", "repo": "null"}}