{"2410.12777": {"publish_time": "2024-10-16", "title": "Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts", "paper_summary": "With the rapid progress of diffusion-based content generation, significant\nefforts are being made to unlearn harmful or copyrighted concepts from\npretrained diffusion models (DMs) to prevent potential model misuse. However,\nit is observed that even when DMs are properly unlearned before release,\nmalicious finetuning can compromise this process, causing DMs to relearn the\nunlearned concepts. This occurs partly because certain benign concepts (e.g.,\n\"skin\") retained in DMs are related to the unlearned ones (e.g., \"nudity\"),\nfacilitating their relearning via finetuning. To address this, we propose\nmeta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an\nunlearned DM when used as is; moreover, if the meta-unlearned DM undergoes\nmalicious finetuning on unlearned concepts, the related benign concepts\nretained within it will be triggered to self-destruct, hindering the relearning\nof unlearned concepts. Our meta-unlearning framework is compatible with most\nexisting unlearning methods, requiring only the addition of an\neasy-to-implement meta objective. We validate our approach through empirical\nexperiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4\nand SDXL), supported by extensive ablation studies. Our code is available at\nhttps://github.com/sail-sg/Meta-Unlearning.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u57fa\u65bc\u64f4\u6563\u7684\u5167\u5bb9\u751f\u6210\u6280\u8853\u7684\u5feb\u901f\u9032\u5c55\uff0c\u4eba\u5011\u6b63\u81f4\u529b\u65bc\u89e3\u9664\u9810\u8a13\u7df4\u64f4\u6563\u6a21\u578b (DM) \u4e2d\u6709\u5bb3\u6216\u53d7\u7248\u6b0a\u4fdd\u8b77\u7684\u6982\u5ff5\uff0c\u4ee5\u9632\u6b62\u6f5b\u5728\u7684\u6a21\u578b\u8aa4\u7528\u3002\u7136\u800c\uff0c\u89c0\u5bdf\u767c\u73fe\uff0c\u5373\u4f7f\u5728 DM \u5728\u767c\u5e03\u524d\u5df2\u9069\u7576\u5730\u89e3\u9664\u5b78\u7fd2\uff0c\u60e1\u610f\u7684\u5fae\u8abf\u4ecd\u53ef\u80fd\u640d\u5bb3\u6b64\u7a0b\u5e8f\uff0c\u5c0e\u81f4 DM \u91cd\u65b0\u5b78\u7fd2\u5df2\u89e3\u9664\u5b78\u7fd2\u7684\u6982\u5ff5\u3002\u9019\u90e8\u5206\u662f\u56e0\u70ba DM \u4e2d\u4fdd\u7559\u7684\u67d0\u4e9b\u826f\u6027\u6982\u5ff5\uff08\u4f8b\u5982\u300c\u76ae\u819a\u300d\uff09\u8207\u5df2\u89e3\u9664\u5b78\u7fd2\u7684\u6982\u5ff5\uff08\u4f8b\u5982\u300c\u88f8\u9732\u300d\uff09\u76f8\u95dc\uff0c\u5f9e\u800c\u901a\u904e\u5fae\u8abf\u4fc3\u9032\u5b83\u5011\u7684\u91cd\u65b0\u5b78\u7fd2\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u5c0d DM \u9032\u884c\u5143\u89e3\u9664\u5b78\u7fd2\u3002\u76f4\u89c0\u5730\u8aaa\uff0c\u4e00\u500b\u7d93\u904e\u5143\u89e3\u9664\u5b78\u7fd2\u7684 DM \u5728\u6309\u539f\u6a23\u4f7f\u7528\u6642\u61c9\u8a72\u8868\u73fe\u5f97\u50cf\u4e00\u500b\u672a\u89e3\u9664\u5b78\u7fd2\u7684 DM\uff1b\u6b64\u5916\uff0c\u5982\u679c\u7d93\u904e\u5143\u89e3\u9664\u5b78\u7fd2\u7684 DM \u5c0d\u672a\u89e3\u9664\u5b78\u7fd2\u7684\u6982\u5ff5\u9032\u884c\u60e1\u610f\u5fae\u8abf\uff0c\u5176\u4e2d\u4fdd\u7559\u7684\u76f8\u95dc\u826f\u6027\u6982\u5ff5\u5c07\u88ab\u89f8\u767c\u81ea\u6bc0\uff0c\u5f9e\u800c\u963b\u7919\u91cd\u65b0\u5b78\u7fd2\u672a\u89e3\u9664\u5b78\u7fd2\u7684\u6982\u5ff5\u3002\u6211\u5011\u7684\u5143\u89e3\u9664\u5b78\u7fd2\u6846\u67b6\u8207\u5927\u591a\u6578\u73fe\u6709\u7684\u89e3\u9664\u5b78\u7fd2\u65b9\u6cd5\u76f8\u5bb9\uff0c\u53ea\u9700\u8981\u65b0\u589e\u4e00\u500b\u6613\u65bc\u5be6\u73fe\u7684\u5143\u76ee\u6a19\u3002\u6211\u5011\u901a\u904e\u5c0d Stable Diffusion \u6a21\u578b\uff08SD-v1-4 \u548c SDXL\uff09\u7684\u5143\u89e3\u9664\u5b78\u7fd2\u6982\u5ff5\u9032\u884c\u5be6\u8b49\u5be6\u9a57\u4f86\u9a57\u8b49\u6211\u5011\u7684\u505a\u6cd5\uff0c\u4e26\u5f97\u5230\u5ee3\u6cdb\u7684\u6d88\u878d\u7814\u7a76\u7684\u652f\u63f4\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/sail-sg/Meta-Unlearning \u53d6\u5f97\u3002</paragraph>", "author": "Hongcheng Gao et.al.", "authors": "Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin", "id": "2410.12777v1", "paper_url": "http://arxiv.org/abs/2410.12777v1", "repo": "null"}}