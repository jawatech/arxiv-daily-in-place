{"2411.02791": {"publish_time": "2024-11-05", "title": "Language Models and Cycle Consistency for Self-Reflective Machine Translation", "paper_summary": "This paper introduces a novel framework that leverages large language models\n(LLMs) for machine translation (MT). We start with one conjecture: an ideal\ntranslation should contain complete and accurate information for a strong\nenough LLM to recover the original sentence. We generate multiple translation\ncandidates from a source language A to a target language B, and subsequently\ntranslate these candidates back to the original language A. By evaluating the\ncycle consistency between the original and back-translated sentences using\nmetrics such as token-level precision and accuracy, we implicitly estimate the\ntranslation quality in language B, without knowing its ground-truth. This also\nhelps to evaluate the LLM translation capability, only with monolingual\ncorpora. For each source sentence, we identify the translation candidate with\noptimal cycle consistency with the original sentence as the final answer. Our\nexperiments demonstrate that larger LLMs, or the same LLM with more forward\npasses during inference, exhibit increased cycle consistency, aligning with the\nLLM model size scaling law and test-time computation scaling law. This work\nprovide methods for, 1) to implicitly evaluate translation quality of a\nsentence in the target language, 2), to evaluate capability of LLM for\nany-to-any-language translation, and 3), how to generate a better translation\nfor a specific LLM.", "paper_summary_zh": "\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9032\u884c\u6a5f\u5668\u7ffb\u8b6f (MT)\u3002\u6211\u5011\u5f9e\u4e00\u500b\u731c\u60f3\u958b\u59cb\uff1a\u7406\u60f3\u7684\u7ffb\u8b6f\u61c9\u5305\u542b\u5b8c\u6574\u4e14\u6e96\u78ba\u7684\u8cc7\u8a0a\uff0c\u8b93\u8db3\u5920\u5f37\u5927\u7684 LLM \u80fd\u5920\u9084\u539f\u539f\u59cb\u53e5\u5b50\u3002\u6211\u5011\u5f9e\u539f\u59cb\u8a9e\u8a00 A \u7522\u751f\u591a\u500b\u7ffb\u8b6f\u5019\u9078\uff0c\u518d\u5c07\u9019\u4e9b\u5019\u9078\u7ffb\u8b6f\u56de\u539f\u59cb\u8a9e\u8a00 A\u3002\u900f\u904e\u4f7f\u7528\u6307\u6a19\uff08\u4f8b\u5982\uff1a\u6a19\u8a18\u5c64\u7d1a\u7684\u7cbe\u78ba\u5ea6\u548c\u6e96\u78ba\u6027\uff09\u8a55\u4f30\u539f\u59cb\u53e5\u5b50\u548c\u56de\u8b6f\u53e5\u5b50\u7684\u5faa\u74b0\u4e00\u81f4\u6027\uff0c\u6211\u5011\u96b1\u542b\u5730\u4f30\u8a08\u8a9e\u8a00 B \u7684\u7ffb\u8b6f\u54c1\u8cea\uff0c\u800c\u4e0d\u77e5\u9053\u5176\u771f\u5be6\u60c5\u6cc1\u3002\u9019\u4e5f\u6709\u52a9\u65bc\u53ea\u4f7f\u7528\u55ae\u8a9e\u6599\u5eab\u8a55\u4f30 LLM \u7ffb\u8b6f\u80fd\u529b\u3002\u5c0d\u65bc\u6bcf\u500b\u539f\u59cb\u53e5\u5b50\uff0c\u6211\u5011\u627e\u51fa\u8207\u539f\u59cb\u53e5\u5b50\u5faa\u74b0\u4e00\u81f4\u6027\u6700\u4f73\u7684\u7ffb\u8b6f\u5019\u9078\uff0c\u4f5c\u70ba\u6700\u7d42\u7b54\u6848\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u8f03\u5927\u7684 LLM\uff0c\u6216\u63a8\u7406\u671f\u9593\u5177\u6709\u66f4\u591a\u524d\u5411\u50b3\u905e\u7684\u76f8\u540c LLM\uff0c\u6703\u8868\u73fe\u51fa\u66f4\u9ad8\u7684\u5faa\u74b0\u4e00\u81f4\u6027\uff0c\u8207 LLM \u6a21\u578b\u5927\u5c0f\u7e2e\u653e\u5b9a\u5f8b\u548c\u6e2c\u8a66\u6642\u9593\u904b\u7b97\u7e2e\u653e\u5b9a\u5f8b\u4e00\u81f4\u3002\u9019\u9805\u5de5\u4f5c\u63d0\u4f9b\u7684\u65b9\u6cd5\u5305\u62ec\uff1a1) \u96b1\u542b\u5730\u8a55\u4f30\u76ee\u6a19\u8a9e\u8a00\u4e2d\u53e5\u5b50\u7684\u7ffb\u8b6f\u54c1\u8cea\uff0c2) \u8a55\u4f30 LLM \u5728\u4efb\u610f\u8a9e\u8a00\u9593\u7ffb\u8b6f\u7684\u80fd\u529b\uff0c\u4ee5\u53ca 3) \u5982\u4f55\u70ba\u7279\u5b9a\u7684 LLM \u7522\u751f\u66f4\u597d\u7684\u7ffb\u8b6f\u3002", "author": "Jianqiao Wangni et.al.", "authors": "Jianqiao Wangni", "id": "2411.02791v1", "paper_url": "http://arxiv.org/abs/2411.02791v1", "repo": "null"}}