{"2405.17382": {"publish_time": "2024-05-27", "title": "ReMoDetect: Reward Models Recognize Aligned LLM's Generations", "paper_summary": "The remarkable capabilities and easy accessibility of large language models\n(LLMs) have significantly increased societal risks (e.g., fake news\ngeneration), necessitating the development of LLM-generated text (LGT)\ndetection methods for safe usage. However, detecting LGTs is challenging due to\nthe vast number of LLMs, making it impractical to account for each LLM\nindividually; hence, it is crucial to identify the common characteristics\nshared by these models. In this paper, we draw attention to a common feature of\nrecent powerful LLMs, namely the alignment training, i.e., training LLMs to\ngenerate human-preferable texts. Our key finding is that as these aligned LLMs\nare trained to maximize the human preferences, they generate texts with higher\nestimated preferences even than human-written texts; thus, such texts are\neasily detected by using the reward model (i.e., an LLM trained to model human\npreference distribution). Based on this finding, we propose two training\nschemes to further improve the detection ability of the reward model, namely\n(i) continual preference fine-tuning to make the reward model prefer aligned\nLGTs even further and (ii) reward modeling of Human/LLM mixed texts (a\nrephrased texts from human-written texts using aligned LLMs), which serves as a\nmedian preference text corpus between LGTs and human-written texts to learn the\ndecision boundary better. We provide an extensive evaluation by considering six\ntext domains across twelve aligned LLMs, where our method demonstrates\nstate-of-the-art results. Code is available at\nhttps://github.com/hyunseoklee-ai/reward_llm_detect.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5353\u8d8a\u529f\u80fd\u548c\u6613\u65bc\u53d6\u5f97\uff0c\u5927\u5e45\u589e\u52a0\u4e86\u793e\u6703\u98a8\u96aa\uff08\u4f8b\u5982\uff0c\u5047\u65b0\u805e\u7522\u751f\uff09\uff0c\u9019\u4f7f\u5f97\u5fc5\u9808\u958b\u767c LLM \u751f\u6210\u7684\u6587\u5b57 (LGT) \u5075\u6e2c\u65b9\u6cd5\uff0c\u4ee5\u5b89\u5168\u4f7f\u7528\u3002\u7136\u800c\uff0c\u5075\u6e2c LGT \u5177\u6709\u6311\u6230\u6027\uff0c\u539f\u56e0\u5728\u65bc LLM \u6578\u91cf\u9f90\u5927\uff0c\u8981\u500b\u5225\u8003\u91cf\u6bcf\u500b LLM \u90fd\u662f\u4e0d\u5207\u5be6\u969b\u7684\uff1b\u56e0\u6b64\uff0c\u627e\u51fa\u9019\u4e9b\u6a21\u578b\u5171\u6709\u7684\u7279\u5fb5\u81f3\u95dc\u91cd\u8981\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c07\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\u8fd1\u671f\u5f37\u5927\u7684 LLM \u7684\u5171\u540c\u7279\u5fb5\uff0c\u5373\u5c0d\u9f4a\u8a13\u7df4\uff0c\u4e5f\u5c31\u662f\u8a13\u7df4 LLM \u7522\u751f\u4eba\u985e\u504f\u597d\u7684\u6587\u5b57\u3002\u6211\u5011\u7684\u95dc\u9375\u767c\u73fe\u662f\uff0c\u7531\u65bc\u9019\u4e9b\u5c0d\u9f4a\u7684 LLM \u7d93\u904e\u8a13\u7df4\u4ee5\u6700\u5927\u5316\u4eba\u985e\u504f\u597d\uff0c\u56e0\u6b64\u5b83\u5011\u7522\u751f\u7684\u6587\u5b57\u4f30\u8a08\u504f\u597d\u751a\u81f3\u9ad8\u65bc\u4eba\u985e\u64b0\u5beb\u7684\u6587\u5b57\uff1b\u56e0\u6b64\uff0c\u6b64\u985e\u6587\u5b57\u5f88\u5bb9\u6613\u4f7f\u7528\u56de\u994b\u6a21\u578b\uff08\u4e5f\u5c31\u662f\u8a13\u7df4 LLM \u4ee5\u5efa\u69cb\u4eba\u985e\u504f\u597d\u5206\u4f48\uff09\u4f86\u5075\u6e2c\u3002\u57fa\u65bc\u6b64\u767c\u73fe\uff0c\u6211\u5011\u63d0\u51fa\u5169\u7a2e\u8a13\u7df4\u67b6\u69cb\uff0c\u4ee5\u9032\u4e00\u6b65\u63d0\u5347\u56de\u994b\u6a21\u578b\u7684\u5075\u6e2c\u80fd\u529b\uff0c\u5373 (i) \u6301\u7e8c\u504f\u597d\u5fae\u8abf\uff0c\u8b93\u56de\u994b\u6a21\u578b\u9032\u4e00\u6b65\u504f\u597d\u5c0d\u9f4a\u7684 LGT\uff0c\u4ee5\u53ca (ii) \u4eba\u985e/LLM \u6df7\u5408\u6587\u5b57\u7684\u56de\u994b\u5efa\u6a21\uff08\u4f7f\u7528\u5c0d\u9f4a\u7684 LLM \u5f9e\u4eba\u985e\u64b0\u5beb\u7684\u6587\u5b57\u91cd\u65b0\u8868\u8ff0\u7684\u6587\u5b57\uff09\uff0c\u9019\u4f5c\u70ba LGT \u548c\u4eba\u985e\u64b0\u5beb\u7684\u6587\u5b57\u4e4b\u9593\u7684\u504f\u597d\u6587\u5b57\u8a9e\u6599\u5eab\u7684\u4e2d\u9593\u503c\uff0c\u4ee5\u66f4\u597d\u5730\u5b78\u7fd2\u6c7a\u7b56\u908a\u754c\u3002\u6211\u5011\u8003\u91cf\u516d\u500b\u6587\u672c\u9818\u57df\u548c\u5341\u4e8c\u500b\u5c0d\u9f4a\u7684 LLM\uff0c\u63d0\u4f9b\u5ee3\u6cdb\u7684\u8a55\u4f30\uff0c\u800c\u6211\u5011\u7684\u6a21\u578b\u5c55\u793a\u4e86\u6700\u5148\u9032\u7684\u7d50\u679c\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/hyunseoklee-ai/reward_llm_detect \u53d6\u5f97\u3002", "author": "Hyunseok Lee et.al.", "authors": "Hyunseok Lee, Jihoon Tack, Jinwoo Shin", "id": "2405.17382v1", "paper_url": "http://arxiv.org/abs/2405.17382v1", "repo": "null"}}