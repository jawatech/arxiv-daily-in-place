{"2501.03643": {"publish_time": "2025-01-07", "title": "Effective and Efficient Mixed Precision Quantization of Speech Foundation Models", "paper_summary": "This paper presents a novel mixed-precision quantization approach for speech\nfoundation models that tightly integrates mixed-precision learning and\nquantized model parameter estimation into one single model compression stage.\nExperiments conducted on LibriSpeech dataset with fine-tuned wav2vec2.0-base\nand HuBERT-large models suggest the resulting mixed-precision quantized models\nincreased the lossless compression ratio by factors up to 1.7x and 1.9x over\nthe respective uniform-precision and two-stage mixed-precision quantized\nbaselines that perform precision learning and model parameters quantization in\nseparate and disjointed stages, while incurring no statistically word error\nrate (WER) increase over the 32-bit full-precision models. The system\ncompression time of wav2vec2.0-base and HuBERT-large models is reduced by up to\n1.9 and 1.5 times over the two-stage mixed-precision baselines, while both\nproduce lower WERs. The best-performing 3.5-bit mixed-precision quantized\nHuBERT-large model produces a lossless compression ratio of 8.6x over the\n32-bit full-precision system.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff0c\u5c06\u6df7\u5408\u7cbe\u5ea6\u5b66\u4e60\u548c\u91cf\u5316\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u7d27\u5bc6\u96c6\u6210\u5230\u4e00\u4e2a\u6a21\u578b\u538b\u7f29\u9636\u6bb5\u3002\u5728\u7ecf\u8fc7\u5fae\u8c03\u7684 wav2vec2.0-base \u548c HuBERT-large \u6a21\u578b\u4e0a\u8fdb\u884c\u7684 LibriSpeech \u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0c\u7531\u6b64\u4ea7\u751f\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6a21\u578b\u5c06\u65e0\u635f\u538b\u7f29\u6bd4\u63d0\u9ad8\u4e86 1.7 \u500d\u548c 1.9 \u500d\uff0c\u5206\u522b\u9ad8\u4e8e\u6267\u884c\u7cbe\u5ea6\u5b66\u4e60\u548c\u6a21\u578b\u53c2\u6570\u91cf\u5316\u7684\u7edf\u4e00\u7cbe\u5ea6\u548c\u4e24\u9636\u6bb5\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u57fa\u7ebf\u3002\u5728\u5355\u72ec\u548c\u4e0d\u8fde\u7eed\u7684\u9636\u6bb5\uff0c\u540c\u65f6\u4e0d\u4f1a\u589e\u52a0 32 \u4f4d\u5168\u7cbe\u5ea6\u6a21\u578b\u7684\u7edf\u8ba1\u8bcd\u9519\u8bef\u7387 (WER)\u3002wav2vec2.0-base \u548c HuBERT-large \u6a21\u578b\u7684\u7cfb\u7edf\u538b\u7f29\u65f6\u95f4\u6bd4\u4e24\u9636\u6bb5\u6df7\u5408\u7cbe\u5ea6\u57fa\u7ebf\u51cf\u5c11\u4e86 1.9 \u500d\u548c 1.5 \u500d\uff0c\u540c\u65f6\u4e24\u8005\u90fd\u4ea7\u751f\u4e86\u8f83\u4f4e\u7684 WER\u3002\u6027\u80fd\u6700\u597d\u7684 3.5 \u4f4d\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316 HuBERT-large \u6a21\u578b\u5bf9 32 \u4f4d\u5168\u7cbe\u5ea6\u7cfb\u7edf\u4ea7\u751f\u4e86 8.6 \u500d\u7684\u65e0\u635f\u538b\u7f29\u6bd4\u3002", "author": "Haoning Xu et.al.", "authors": "Haoning Xu, Zhaoqing Li, Zengrui Jin, Huimeng Wang, Youjun Chen, Guinan Li, Mengzhe Geng, Shujie Hu, Jiajun Deng, Xunying Liu", "id": "2501.03643v1", "paper_url": "http://arxiv.org/abs/2501.03643v1", "repo": "null"}}