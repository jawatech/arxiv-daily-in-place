{"2408.08685": {"publish_time": "2024-08-16", "title": "Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?", "paper_summary": "Graph neural networks (GNNs) are vulnerable to adversarial perturbations,\nespecially for topology attacks, and many methods that improve the robustness\nof GNNs have received considerable attention. Recently, we have witnessed the\nsignificant success of large language models (LLMs), leading many to explore\nthe great potential of LLMs on GNNs. However, they mainly focus on improving\nthe performance of GNNs by utilizing LLMs to enhance the node features.\nTherefore, we ask: Will the robustness of GNNs also be enhanced with the\npowerful understanding and inference capabilities of LLMs? By presenting the\nempirical results, we find that despite that LLMs can improve the robustness of\nGNNs, there is still an average decrease of 23.1% in accuracy, implying that\nthe GNNs remain extremely vulnerable against topology attack. Therefore,\nanother question is how to extend the capabilities of LLMs on graph adversarial\nrobustness. In this paper, we propose an LLM-based robust graph structure\ninference framework, LLM4RGNN, which distills the inference capabilities of\nGPT-4 into a local LLM for identifying malicious edges and an LM-based edge\npredictor for finding missing important edges, so as to recover a robust graph\nstructure. Extensive experiments demonstrate that LLM4RGNN consistently\nimproves the robustness across various GNNs. Even in some cases where the\nperturbation ratio increases to 40%, the accuracy of GNNs is still better than\nthat on the clean graph.", "paper_summary_zh": "\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u5bb9\u6613\u53d7\u5230\u5c0d\u6297\u6027\u64fe\u52d5\u7684\u5f71\u97ff\uff0c\n\u7279\u5225\u662f\u62d3\u64b2\u653b\u64ca\uff0c\u8a31\u591a\u6539\u5584 GNN \u9b6f\u68d2\u6027\u7684\u65b9\u6cd5\u90fd\u5099\u53d7\u95dc\u6ce8\u3002\u6700\u8fd1\uff0c\u6211\u5011\u898b\u8b49\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u986f\u8457\u6210\u529f\uff0c\u5c0e\u81f4\u8a31\u591a\u4eba\u63a2\u7d22 LLM \u5728 GNN \u4e0a\u7684\u5de8\u5927\u6f5b\u529b\u3002\u7136\u800c\uff0c\u4ed6\u5011\u4e3b\u8981\u5c08\u6ce8\u65bc\u5229\u7528 LLM \u589e\u5f37\u7bc0\u9ede\u7279\u5fb5\u4f86\u6539\u5584 GNN \u7684\u6548\u80fd\u3002\n\u56e0\u6b64\uff0c\u6211\u5011\u554f\uff1aLLM \u5f37\u5927\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u662f\u5426\u4e5f\u6703\u589e\u5f37 GNN \u7684\u9b6f\u68d2\u6027\uff1f\u900f\u904e\u5448\u73fe\u5be6\u8b49\u7d50\u679c\uff0c\u6211\u5011\u767c\u73fe\u5118\u7ba1 LLM \u53ef\u4ee5\u6539\u5584 GNN \u7684\u9b6f\u68d2\u6027\uff0c\u4f46\u6e96\u78ba\u5ea6\u4ecd\u5e73\u5747\u4e0b\u964d 23.1%\uff0c\u9019\u8868\u793a GNN \u4ecd\u7136\u6975\u5bb9\u6613\u53d7\u5230\u62d3\u64b2\u653b\u64ca\u3002\u56e0\u6b64\uff0c\u53e6\u4e00\u500b\u554f\u984c\u662f\u5982\u4f55\u64f4\u5c55 LLM \u5728\u5716\u5f62\u5c0d\u6297\u9b6f\u68d2\u6027\u4e0a\u7684\u80fd\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc LLM \u7684\u9b6f\u68d2\u5716\u5f62\u7d50\u69cb\u63a8\u7406\u6846\u67b6 LLM4RGNN\uff0c\u5b83\u5c07 GPT-4 \u7684\u63a8\u7406\u80fd\u529b\u63d0\u7149\u6210\u4e00\u500b\u7528\u65bc\u8b58\u5225\u60e1\u610f\u908a\u7de3\u7684\u672c\u5730 LLM\uff0c\u4ee5\u53ca\u4e00\u500b\u7528\u65bc\u5c0b\u627e\u907a\u5931\u91cd\u8981\u908a\u7de3\u7684\u57fa\u65bc LM \u7684\u908a\u7de3\u9810\u6e2c\u5668\uff0c\u4ee5\u4fbf\u6062\u5fa9\u4e00\u500b\u9b6f\u68d2\u7684\u5716\u5f62\u7d50\u69cb\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0cLLM4RGNN \u6301\u7e8c\u6539\u5584\u5404\u7a2e GNN \u7684\u9b6f\u68d2\u6027\u3002\u5373\u4f7f\u5728\u67d0\u4e9b\u64fe\u52d5\u7387\u589e\u52a0\u5230 40% \u7684\u60c5\u6cc1\u4e0b\uff0cGNN \u7684\u6e96\u78ba\u5ea6\u4ecd\u7136\u512a\u65bc\u4e7e\u6de8\u5716\u5f62\u3002", "author": "Zhongjian Zhang et.al.", "authors": "Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi", "id": "2408.08685v1", "paper_url": "http://arxiv.org/abs/2408.08685v1", "repo": "null"}}