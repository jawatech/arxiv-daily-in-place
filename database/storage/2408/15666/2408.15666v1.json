{"2408.15666": {"publish_time": "2024-08-28", "title": "StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements", "paper_summary": "Authorship obfuscation, rewriting a text to intentionally obscure the\nidentity of the author, is an important but challenging task. Current methods\nusing large language models (LLMs) lack interpretability and controllability,\noften ignoring author-specific stylistic features, resulting in less robust\nperformance overall.\n  To address this, we develop StyleRemix, an adaptive and interpretable\nobfuscation method that perturbs specific, fine-grained style elements of the\noriginal input text. StyleRemix uses pre-trained Low Rank Adaptation (LoRA)\nmodules to rewrite an input specifically along various stylistic axes (e.g.,\nformality and length) while maintaining low computational cost. StyleRemix\noutperforms state-of-the-art baselines and much larger LLMs in a variety of\ndomains as assessed by both automatic and human evaluation.\n  Additionally, we release AuthorMix, a large set of 30K high-quality,\nlong-form texts from a diverse set of 14 authors and 4 domains, and DiSC, a\nparallel corpus of 1,500 texts spanning seven style axes in 16 unique\ndirections", "paper_summary_zh": "\u4f5c\u8005\u6df7\u6dc6\uff0c\u91cd\u5199\u6587\u672c\u4ee5\u6545\u610f\u6a21\u7cca\u4f5c\u8005\u8eab\u4efd\uff0c\u662f\u4e00\u9879\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002\u5f53\u524d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\uff0c\u901a\u5e38\u4f1a\u5ffd\u7565\u4f5c\u8005\u7279\u5b9a\u7684\u6587\u4f53\u7279\u5f81\uff0c\u4ece\u800c\u5bfc\u81f4\u6574\u4f53\u6027\u80fd\u4e0d\u591f\u7a33\u5065\u3002\n\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u5f00\u53d1\u4e86 StyleRemix\uff0c\u8fd9\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u4e14\u53ef\u89e3\u91ca\u7684\u6df7\u6dc6\u65b9\u6cd5\uff0c\u5b83\u6270\u4e71\u4e86\u539f\u59cb\u8f93\u5165\u6587\u672c\u4e2d\u7279\u5b9a\u3001\u7ec6\u7c92\u5ea6\u7684\u98ce\u683c\u5143\u7d20\u3002StyleRemix \u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u4f4e\u79e9\u81ea\u9002\u5e94 (LoRA) \u6a21\u5757\u6765\u4e13\u95e8\u6cbf\u7740\u5404\u79cd\u6587\u4f53\u8f74\uff08\u4f8b\u5982\uff0c\u6b63\u5f0f\u6027\u548c\u957f\u5ea6\uff09\u91cd\u5199\u8f93\u5165\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002StyleRemix \u5728\u5404\u79cd\u9886\u57df\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u548c\u66f4\u5927\u7684 LLM\uff0c\u8fd9\u662f\u901a\u8fc7\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u5f97\u51fa\u7684\u3002\n\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u5e03\u4e86 AuthorMix\uff0c\u8fd9\u662f\u4e00\u7ec4\u6765\u81ea 14 \u4f4d\u4f5c\u8005\u548c 4 \u4e2a\u9886\u57df\u7684\u5927\u91cf 30K \u9ad8\u8d28\u91cf\u957f\u7bc7\u6587\u672c\uff0c\u4ee5\u53ca DiSC\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b 1500 \u7bc7\u6587\u672c\u7684\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u8de8\u8d8a 16 \u4e2a\u72ec\u7279\u65b9\u5411\u7684\u4e03\u4e2a\u98ce\u683c\u8f74", "author": "Jillian Fisher et.al.", "authors": "Jillian Fisher, Skyler Hallinan, Ximing Lu, Mitchell Gordon, Zaid Harchaoui, Yejin Choi", "id": "2408.15666v1", "paper_url": "http://arxiv.org/abs/2408.15666v1", "repo": "https://github.com/jfisher52/StyleRemix"}}