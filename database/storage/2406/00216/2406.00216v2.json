{"2406.00216": {"publish_time": "2024-05-31", "title": "The Explanation Necessity for Healthcare AI", "paper_summary": "Explainability is a critical factor in enhancing the trustworthiness and\nacceptance of artificial intelligence (AI) in healthcare, where decisions\ndirectly impact patient outcomes. Despite advancements in AI interpretability,\nclear guidelines on when and to what extent explanations are required in\nmedical applications remain lacking. We propose a novel categorization system\ncomprising four classes of explanation necessity (self-explainable,\nsemi-explainable, non-explainable, and new-patterns discovery), guiding the\nrequired level of explanation; whether local (patient or sample level), global\n(cohort or dataset level), or both. To support this system, we introduce a\nmathematical formulation that incorporates three key factors: (i) robustness of\nthe evaluation protocol, (ii) variability of expert observations, and (iii)\nrepresentation dimensionality of the application. This framework provides a\npractical tool for researchers to determine the appropriate depth of\nexplainability needed, addressing the critical question: When does an AI\nmedical application need to be explained, and at what level of detail?", "paper_summary_zh": "<paragraph>\u53ef\u89e3\u91cb\u6027\u662f\u589e\u5f37\u91ab\u7642\u4fdd\u5065\u9818\u57df\u4e2d\u4eba\u5de5\u667a\u6167 (AI) \u4fe1\u4efb\u5ea6\u548c\u63a5\u53d7\u5ea6\u7684\u95dc\u9375\u56e0\u7d20\uff0c\u56e0\u70ba\u5728\u91ab\u7642\u4fdd\u5065\u4e2d\uff0c\u6c7a\u7b56\u6703\u76f4\u63a5\u5f71\u97ff\u75c5\u4eba\u7684\u7d50\u679c\u3002\u5118\u7ba1 AI \u53ef\u89e3\u91cb\u6027\u6709\u6240\u9032\u5c55\uff0c\u4f46\u5728\u91ab\u7642\u61c9\u7528\u4e2d\u4f55\u6642\u4ee5\u53ca\u5728\u4f55\u7a2e\u7a0b\u5ea6\u4e0a\u9700\u8981\u89e3\u91cb\u7684\u660e\u78ba\u6307\u5357\u4ecd\u7136\u7f3a\u4e4f\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7684\u5206\u985e\u7cfb\u7d71\uff0c\u5305\u542b\u56db\u985e\u89e3\u91cb\u5fc5\u8981\u6027\uff08\u81ea\u89e3\u91cb\u3001\u534a\u89e3\u91cb\u3001\u4e0d\u53ef\u89e3\u91cb\u548c\u65b0\u6a21\u5f0f\u767c\u73fe\uff09\uff0c\u6307\u5c0e\u6240\u9700\u7684\u89e3\u91cb\u7d1a\u5225\uff1b\u7121\u8ad6\u662f\u5c40\u90e8\uff08\u60a3\u8005\u6216\u6a23\u672c\u7d1a\u5225\uff09\u3001\u5168\u5c40\uff08\u968a\u5217\u6216\u6578\u64da\u96c6\u7d1a\u5225\uff09\u9084\u662f\u5169\u8005\u517c\u800c\u6709\u4e4b\u3002\u70ba\u4e86\u652f\u6301\u8a72\u7cfb\u7d71\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u6578\u5b78\u516c\u5f0f\uff0c\u5176\u4e2d\u5305\u542b\u4e09\u500b\u95dc\u9375\u56e0\u7d20\uff1a(i) \u8a55\u4f30\u65b9\u6848\u7684\u7a69\u5065\u6027\uff0c(ii) \u5c08\u5bb6\u89c0\u5bdf\u7684\u8b8a\u7570\u6027\uff0c\u4ee5\u53ca (iii) \u61c9\u7528\u7a0b\u5e8f\u7684\u8868\u793a\u7dad\u5ea6\u3002\u6b64\u6846\u67b6\u70ba\u7814\u7a76\u4eba\u54e1\u63d0\u4f9b\u4e86\u4e00\u500b\u5be6\u7528\u7684\u5de5\u5177\uff0c\u7528\u65bc\u78ba\u5b9a\u6240\u9700\u7684\u5408\u9069\u7684\u53ef\u89e3\u91cb\u6027\u6df1\u5ea6\uff0c\u89e3\u6c7a\u4e86\u9019\u500b\u95dc\u9375\u554f\u984c\uff1aAI \u91ab\u7642\u61c9\u7528\u4f55\u6642\u9700\u8981\u89e3\u91cb\uff0c\u4ee5\u53ca\u9700\u8981\u4f55\u7a2e\u8a73\u7d30\u7a0b\u5ea6\uff1f</paragraph>\n", "author": "Michail Mamalakis et.al.", "authors": "Michail Mamalakis, H\u00e9lo\u00efse de Vareilles, Graham Murray, Pietro Lio, John Suckling", "id": "2406.00216v2", "paper_url": "http://arxiv.org/abs/2406.00216v2", "repo": "null"}}