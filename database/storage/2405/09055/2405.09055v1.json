{"2405.09055": {"publish_time": "2024-05-15", "title": "A safety realignment framework via subspace-oriented model fusion for large language models", "paper_summary": "The current safeguard mechanisms for large language models (LLMs) are indeed\nsusceptible to jailbreak attacks, making them inherently fragile. Even the\nprocess of fine-tuning on apparently benign data for downstream tasks can\njeopardize safety. One potential solution is to conduct safety fine-tuning\nsubsequent to downstream fine-tuning. However, there's a risk of catastrophic\nforgetting during safety fine-tuning, where LLMs may regain safety measures but\nlose the task-specific knowledge acquired during downstream fine-tuning. In\nthis paper, we introduce a safety realignment framework through\nsubspace-oriented model fusion (SOMF), aiming to combine the safeguard\ncapabilities of initially aligned model and the current fine-tuned model into a\nrealigned model. Our approach begins by disentangling all task vectors from the\nweights of each fine-tuned model. We then identify safety-related regions\nwithin these vectors by subspace masking techniques. Finally, we explore the\nfusion of the initial safely aligned LLM with all task vectors based on the\nidentified safety subspace. We validate that our safety realignment framework\nsatisfies the safety requirements of a single fine-tuned model as well as\nmultiple models during their fusion. Our findings confirm that SOMF preserves\nsafety without notably compromising performance on downstream tasks, including\ninstruction following in Chinese, English, and Hindi, as well as\nproblem-solving capabilities in Code and Math.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u76ee\u524d\u7528\u65bc\u9632\u8b77\u6a5f\u5236\u7684\u78ba\u5bb9\u6613\u53d7\u5230\u8d8a\u7344\u653b\u64ca\uff0c\u4f7f\u5f97\u5b83\u5011\u672c\u8cea\u4e0a\u5f88\u8106\u5f31\u3002\u5373\u4f7f\u5728\u770b\u4f3c\u826f\u5584\u7684\u8cc7\u6599\u4e0a\u9032\u884c\u5fae\u8abf\u4ee5\u57f7\u884c\u4e0b\u6e38\u4efb\u52d9\u7684\u7a0b\u5e8f\u4e5f\u53ef\u80fd\u5371\u53ca\u5b89\u5168\u6027\u3002\u4e00\u500b\u6f5b\u5728\u7684\u89e3\u6c7a\u65b9\u6848\u662f\u5728\u4e0b\u6e38\u5fae\u8abf\u5f8c\u9032\u884c\u5b89\u5168\u5fae\u8abf\u3002\u7136\u800c\uff0c\u5728\u5b89\u5168\u5fae\u8abf\u904e\u7a0b\u4e2d\u5b58\u5728\u707d\u96e3\u6027\u907a\u5fd8\u7684\u98a8\u96aa\uff0cLLM \u53ef\u80fd\u6703\u91cd\u65b0\u7372\u5f97\u5b89\u5168\u63aa\u65bd\uff0c\u4f46\u6703\u5931\u53bb\u5728\u4e0b\u6e38\u5fae\u8abf\u671f\u9593\u7372\u5f97\u7684\u7279\u5b9a\u4efb\u52d9\u77e5\u8b58\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u9762\u5411\u5b50\u7a7a\u9593\u7684\u6a21\u578b\u878d\u5408 (SOMF) \u5f15\u5165\u5b89\u5168\u91cd\u65b0\u8abf\u6574\u67b6\u69cb\uff0c\u65e8\u5728\u7d50\u5408\u6700\u521d\u8abf\u6574\u6a21\u578b\u548c\u76ee\u524d\u5fae\u8abf\u6a21\u578b\u7684\u9632\u8b77\u80fd\u529b\uff0c\u5f62\u6210\u91cd\u65b0\u8abf\u6574\u6a21\u578b\u3002\u6211\u5011\u7684\u505a\u6cd5\u9996\u5148\u5f9e\u6bcf\u500b\u5fae\u8abf\u6a21\u578b\u7684\u6b0a\u91cd\u4e2d\u89e3\u958b\u6240\u6709\u4efb\u52d9\u5411\u91cf\u3002\u7136\u5f8c\uff0c\u6211\u5011\u900f\u904e\u5b50\u7a7a\u9593\u906e\u7f69\u6280\u8853\u8b58\u5225\u9019\u4e9b\u5411\u91cf\u4e2d\u7684\u5b89\u5168\u76f8\u95dc\u5340\u57df\u3002\u6700\u5f8c\uff0c\u6211\u5011\u6839\u64da\u8b58\u5225\u51fa\u7684\u5b89\u5168\u5b50\u7a7a\u9593\uff0c\u63a2\u7d22\u6700\u521d\u5b89\u5168\u8abf\u6574\u7684 LLM \u8207\u6240\u6709\u4efb\u52d9\u5411\u91cf\u7684\u878d\u5408\u3002\u6211\u5011\u9a57\u8b49\u6211\u5011\u7684\u5b89\u5168\u91cd\u65b0\u8abf\u6574\u67b6\u69cb\u6eff\u8db3\u55ae\u4e00\u5fae\u8abf\u6a21\u578b\u4ee5\u53ca\u5728\u878d\u5408\u671f\u9593\u591a\u500b\u6a21\u578b\u7684\u5b89\u5168\u9700\u6c42\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8b49\u5be6\uff0cSOMF \u53ef\u5728\u4e0d\u986f\u8457\u640d\u5bb3\u4e0b\u6e38\u4efb\u52d9\u6548\u80fd\u7684\u60c5\u6cc1\u4e0b\u7dad\u8b77\u5b89\u5168\u6027\uff0c\u5305\u62ec\u4e2d\u6587\u3001\u82f1\u6587\u548c\u5370\u5730\u6587\u7684\u6307\u4ee4\u9075\u5faa\uff0c\u4ee5\u53ca\u7a0b\u5f0f\u78bc\u548c\u6578\u5b78\u4e2d\u7684\u554f\u984c\u89e3\u6c7a\u80fd\u529b\u3002", "author": "Xin Yi et.al.", "authors": "Xin Yi, Shunfan Zheng, Linlin Wang, Xiaoling Wang, Liang He", "id": "2405.09055v1", "paper_url": "http://arxiv.org/abs/2405.09055v1", "repo": "null"}}