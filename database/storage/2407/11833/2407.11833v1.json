{"2407.11833": {"publish_time": "2024-07-16", "title": "LoFTI: Localization and Factuality Transfer to Indian Locales", "paper_summary": "Large language models (LLMs) encode vast amounts of world knowledge acquired\nvia training on large web-scale datasets crawled from the internet. However,\nthese datasets typically exhibit a geographical bias towards English-speaking\nWestern countries. This results in LLMs producing biased or hallucinated\nresponses to queries that require answers localized to other geographical\nregions. In this work, we introduce a new benchmark named LoFTI (Localization\nand Factuality Transfer to Indian Locales) that can be used to evaluate an\nLLM's localization and factual text transfer capabilities. LoFTI consists of\nfactual statements about entities in source and target locations; the source\nlocations are spread across the globe and the target locations are all within\nIndia with varying degrees of hyperlocality (country, states, cities). The\nentities span a wide variety of categories. We use LoFTI to evaluate Mixtral,\nGPT-4 and two other Mixtral-based approaches well-suited to the task of\nlocalized factual transfer. We demonstrate that LoFTI is a high-quality\nevaluation benchmark and all the models, including GPT-4, produce skewed\nresults across varying levels of hyperlocality.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7de8\u78bc\u4e86\u5927\u91cf\u4e16\u754c\u77e5\u8b58\uff0c\u9019\u4e9b\u77e5\u8b58\u662f\u900f\u904e\u8a13\u7df4\u5927\u578b\u7db2\u8def\u898f\u6a21\u8cc7\u6599\u96c6\uff08\u5f9e\u7db2\u969b\u7db2\u8def\u722c\u53d6\uff09\u800c\u7372\u5f97\u7684\u3002\u7136\u800c\uff0c\u9019\u4e9b\u8cc7\u6599\u96c6\u901a\u5e38\u6703\u5c0d\u82f1\u8a9e\u7cfb\u897f\u65b9\u570b\u5bb6\u8868\u73fe\u51fa\u5730\u7406\u504f\u898b\u3002\u9019\u5c0e\u81f4 LLM \u5c0d\u9700\u8981\u5c07\u7b54\u6848\u5728\u5730\u7406\u5340\u57df\u672c\u5730\u5316\u7684\u67e5\u8a62\u7522\u751f\u6709\u504f\u898b\u6216\u865b\u69cb\u7684\u56de\u61c9\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u540d\u70ba LoFTI\uff08\u672c\u5730\u5316\u548c\u4e8b\u5be6\u50b3\u8f38\u5230\u5370\u5ea6\u672c\u5730\uff09\u7684\u65b0\u57fa\u6e96\uff0c\u53ef\u7528\u65bc\u8a55\u4f30 LLM \u7684\u672c\u5730\u5316\u548c\u4e8b\u5be6\u6587\u672c\u50b3\u8f38\u80fd\u529b\u3002LoFTI \u5305\u542b\u95dc\u65bc\u4f86\u6e90\u548c\u76ee\u6a19\u4f4d\u7f6e\u5be6\u9ad4\u7684\u4e8b\u5be6\u9673\u8ff0\uff1b\u4f86\u6e90\u4f4d\u7f6e\u904d\u5e03\u5168\u7403\uff0c\u800c\u76ee\u6a19\u4f4d\u7f6e\u5747\u5728\u5370\u5ea6\u5883\u5167\uff0c\u5177\u6709\u4e0d\u540c\u7a0b\u5ea6\u7684\u8d85\u5730\u65b9\u6027\uff08\u570b\u5bb6\u3001\u5dde\u3001\u57ce\u5e02\uff09\u3002\u5be6\u9ad4\u6db5\u84cb\u4e86\u5ee3\u6cdb\u7684\u985e\u5225\u3002\u6211\u5011\u4f7f\u7528 LoFTI \u4f86\u8a55\u4f30 Mixtral\u3001GPT-4 \u548c\u5176\u4ed6\u5169\u7a2e\u975e\u5e38\u9069\u5408\u65bc\u672c\u5730\u5316\u4e8b\u5be6\u50b3\u8f38\u4efb\u52d9\u7684\u57fa\u65bc Mixtral \u7684\u65b9\u6cd5\u3002\u6211\u5011\u8b49\u660e LoFTI \u662f\u500b\u9ad8\u54c1\u8cea\u7684\u8a55\u4f30\u57fa\u6e96\uff0c\u5305\u62ec GPT-4 \u5728\u5167\u7684\u6240\u6709\u6a21\u578b\u5728\u4e0d\u540c\u5c64\u7d1a\u7684\u8d85\u5730\u65b9\u6027\u4e2d\u90fd\u7522\u751f\u4e86\u504f\u659c\u7684\u7d50\u679c\u3002", "author": "Sona Elza Simon et.al.", "authors": "Sona Elza Simon, Soumen Kumar Mondal, Abhishek Singhania, Sayambhu Sen, Preethi Jyothi", "id": "2407.11833v1", "paper_url": "http://arxiv.org/abs/2407.11833v1", "repo": "https://github.com/csalt-research/lofti"}}