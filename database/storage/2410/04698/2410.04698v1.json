{"2410.04698": {"publish_time": "2024-10-07", "title": "MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning in LLMs", "paper_summary": "Recent large language models (LLMs) have demonstrated versatile capabilities\nin long-context scenarios. Although some recent benchmarks have been developed\nto evaluate the long-context capabilities of LLMs, there is a lack of\nbenchmarks evaluating the mathematical reasoning abilities of LLMs over long\ncontexts, which is crucial for LLMs' application in real-world scenarios. In\nthis paper, we introduce MathHay, an automated benchmark designed to assess the\nlong-context mathematical reasoning capabilities of LLMs. Unlike previous\nbenchmarks like Needle in a Haystack, which focus primarily on information\nretrieval within long texts, MathHay demands models with both\ninformation-seeking and complex mathematical reasoning abilities. We conduct\nextensive experiments on MathHay to assess the long-context mathematical\nreasoning abilities of eight top-performing LLMs. Even the best-performing\nmodel, Gemini-1.5-Pro-002, still struggles with mathematical reasoning over\nlong contexts, achieving only 51.26% accuracy at 128K tokens. This highlights\nthe significant room for improvement on the MathHay benchmark.", "paper_summary_zh": "\u6700\u8fd1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u957f\u6587\u672c\u60c5\u5883\u4e2d\u5c55\u793a\u51fa\u591a\u529f\u80fd\u7684\u80fd\u529b\u3002\u867d\u7136\u6700\u8fd1\u5df2\u5f00\u53d1\u51fa\u4e00\u4e9b\u57fa\u51c6\u6765\u8bc4\u4f30 LLM \u7684\u957f\u6587\u672c\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u8bc4\u4f30 LLM \u5728\u957f\u6587\u672c\u4e2d\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u8fd9\u5bf9 LLM \u5728\u73b0\u5b9e\u4e16\u754c\u60c5\u5883\u4e2d\u7684\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86 MathHay\uff0c\u4e00\u4e2a\u81ea\u52a8\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30 LLM \u7684\u957f\u6587\u672c\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u4e0e\u4e3b\u8981\u4e13\u6ce8\u4e8e\u957f\u6587\u672c\u4e2d\u4fe1\u606f\u68c0\u7d22\u7684 Needle in a Haystack \u7b49\u5148\u524d\u57fa\u51c6\u4e0d\u540c\uff0cMathHay \u8981\u6c42\u6a21\u578b\u540c\u65f6\u5177\u6709\u4fe1\u606f\u641c\u7d22\u548c\u590d\u6742\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u6211\u4eec\u5bf9 MathHay \u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u4ee5\u8bc4\u4f30\u516b\u79cd\u6027\u80fd\u6700\u4f73\u7684 LLM \u7684\u957f\u6587\u672c\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u5373\u4f7f\u662f\u6027\u80fd\u6700\u4f73\u7684\u6a21\u578b Gemini-1.5-Pro-002\uff0c\u5728\u957f\u6587\u672c\u4e2d\u8fdb\u884c\u6570\u5b66\u63a8\u7406\u65f6\u4ecd\u7136\u56f0\u96be\uff0c\u5728 128K \u4e2a\u6807\u8bb0\u4e2d\u4ec5\u8fbe\u5230 51.26% \u7684\u51c6\u786e\u7387\u3002\u8fd9\u7a81\u663e\u4e86\u5728 MathHay \u57fa\u51c6\u4e0a\u6539\u8fdb\u7684\u5de8\u5927\u7a7a\u95f4\u3002", "author": "Lei Wang et.al.", "authors": "Lei Wang, Shan Dong, Yuhui Xu, Hanze Dong, Yalu Wang, Amrita Saha, Ee-Peng Lim, Caiming Xiong, Doyen Sahoo", "id": "2410.04698v1", "paper_url": "http://arxiv.org/abs/2410.04698v1", "repo": "null"}}