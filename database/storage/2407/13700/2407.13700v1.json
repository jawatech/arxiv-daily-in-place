{"2407.13700": {"publish_time": "2024-07-18", "title": "Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift", "paper_summary": "Studying adversarial attacks on artificial intelligence (AI) systems helps\ndiscover model shortcomings, enabling the construction of a more robust system.\nMost existing adversarial attack methods only concentrate on single-task\nsingle-model or single-task cross-model scenarios, overlooking the multi-task\ncharacteristic of artificial intelligence systems. As a result, most of the\nexisting attacks do not pose a practical threat to a comprehensive and\ncollaborative AI system. However, implementing cross-task attacks is highly\ndemanding and challenging due to the difficulty in obtaining the real labels of\ndifferent tasks for the same picture and harmonizing the loss functions across\ndifferent tasks. To address this issue, we propose a self-supervised Cross-Task\nAttack framework (CTA), which utilizes co-attention and anti-attention maps to\ngenerate cross-task adversarial perturbation. Specifically, the co-attention\nmap reflects the area to which different visual task models pay attention,\nwhile the anti-attention map reflects the area that different visual task\nmodels neglect. CTA generates cross-task perturbations by shifting the\nattention area of samples away from the co-attention map and closer to the\nanti-attention map. We conduct extensive experiments on multiple vision tasks\nand the experimental results confirm the effectiveness of the proposed design\nfor adversarial attacks.", "paper_summary_zh": "\u7814\u7a76\u4eba\u5de5\u667a\u6167 (AI) \u7cfb\u7d71\u7684\u5c0d\u6297\u653b\u64ca\u6709\u52a9\u65bc\n\u767c\u73fe\u6a21\u578b\u7684\u7f3a\u9ede\uff0c\u5f9e\u800c\u80fd\u5920\u5efa\u69cb\u66f4\u5f37\u5927\u7684\u7cfb\u7d71\u3002\n\u73fe\u6709\u7684\u5c0d\u6297\u653b\u64ca\u65b9\u6cd5\u5927\u591a\u53ea\u5c08\u6ce8\u65bc\u55ae\u4e00\u4efb\u52d9\n\u55ae\u4e00\u6a21\u578b\u6216\u55ae\u4e00\u4efb\u52d9\u8de8\u6a21\u578b\u5834\u666f\uff0c\u5ffd\u7565\u4e86\u4eba\u5de5\u667a\u6167\u7cfb\u7d71\u7684\u591a\u4efb\u52d9\n\u7279\u6027\u3002\u56e0\u6b64\uff0c\u73fe\u6709\u7684\u653b\u64ca\u5927\u591a\u5c0d\u5168\u9762\u4e14\n\u5354\u4f5c\u5f0f AI \u7cfb\u7d71\u4e0d\u69cb\u6210\u5be6\u969b\u5a01\u8105\u3002\u7136\u800c\uff0c\u7531\u65bc\u96e3\u4ee5\u53d6\u5f97\n\u540c\u4e00\u5f35\u5716\u7247\u4e0d\u540c\u4efb\u52d9\u7684\u771f\u5be6\u6a19\u7c64\uff0c\u4ee5\u53ca\u8abf\u548c\u4e0d\u540c\u4efb\u52d9\u7684\u640d\u5931\u51fd\u6578\uff0c\u56e0\u6b64\u5be6\u4f5c\u8de8\u4efb\u52d9\u653b\u64ca\u975e\u5e38\n\u8981\u6c42\u4e14\u5177\u6709\u6311\u6230\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u81ea\u6211\u76e3\u7763\u7684\u8de8\u4efb\u52d9\n\u653b\u64ca\u67b6\u69cb (CTA)\uff0c\u5b83\u5229\u7528\u5171\u540c\u6ce8\u610f\u548c\u53cd\u6ce8\u610f\u5730\u5716\u4f86\n\u7522\u751f\u8de8\u4efb\u52d9\u5c0d\u6297\u64fe\u52d5\u3002\u7279\u5225\u662f\uff0c\u5171\u540c\u6ce8\u610f\u5730\u5716\u53cd\u6620\u4e0d\u540c\u8996\u89ba\u4efb\u52d9\u6a21\u578b\u6ce8\u610f\u5230\u7684\u5340\u57df\uff0c\n\u800c\u53cd\u6ce8\u610f\u5730\u5716\u53cd\u6620\u4e0d\u540c\u8996\u89ba\u4efb\u52d9\u6a21\u578b\u5ffd\u7565\u7684\u5340\u57df\u3002CTA \u900f\u904e\u5c07\n\u6a23\u672c\u7684\u6ce8\u610f\u5340\u57df\u5f9e\u5171\u540c\u6ce8\u610f\u5730\u5716\u79fb\u958b\u4e26\u9760\u8fd1\n\u53cd\u6ce8\u610f\u5730\u5716\u4f86\u7522\u751f\u8de8\u4efb\u52d9\u64fe\u52d5\u3002\u6211\u5011\u5c0d\u591a\u500b\u8996\u89ba\u4efb\u52d9\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\n\u4e26\u4e14\u5be6\u9a57\u7d50\u679c\u8b49\u5be6\u4e86\u6240\u63d0\u51fa\u7684\u8a2d\u8a08\u5c0d\u65bc\u5c0d\u6297\u653b\u64ca\u7684\u6709\u6548\u6027\u3002", "author": "Qingyuan Zeng et.al.", "authors": "Qingyuan Zeng, Yunpeng Gong, Min Jiang", "id": "2407.13700v1", "paper_url": "http://arxiv.org/abs/2407.13700v1", "repo": "null"}}