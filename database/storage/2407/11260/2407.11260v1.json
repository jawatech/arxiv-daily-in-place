{"2407.11260": {"publish_time": "2024-07-15", "title": "Quality Scalable Quantization Methodology for Deep Learning on Edge", "paper_summary": "Deep Learning Architectures employ heavy computations and bulk of the\ncomputational energy is taken up by the convolution operations in the\nConvolutional Neural Networks. The objective of our proposed work is to reduce\nthe energy consumption and size of CNN for using machine learning techniques in\nedge computing on ubiquitous computing devices. We propose Systematic Quality\nScalable Design Methodology consisting of Quality Scalable Quantization on a\nhigher abstraction level and Quality Scalable Multipliers at lower abstraction\nlevel. The first component consists of parameter compression where we\napproximate representation of values in filters of deep learning models by\nencoding in 3 bits. A shift and scale based on-chip decoding hardware is\nproposed which can decode these 3-bit representations to recover approximate\nfilter values. The size of the DNN model is reduced this way and can be sent\nover a communication channel to be decoded on the edge computing devices. This\nway power is reduced by limiting data bits by approximation. In the second\ncomponent we propose a quality scalable multiplier which reduces the number of\npartial products by converting numbers in canonic sign digit representations\nand further approximating the number by reducing least significant bits. These\nquantized CNNs provide almost same ac-curacy as network with original weights\nwith little or no fine-tuning. The hardware for the adaptive multipliers\nutilize gate clocking for reducing energy consumption during multiplications.\nThe proposed methodology greatly reduces the memory and power requirements of\nDNN models making it a feasible approach to deploy Deep Learning on edge\ncomputing. The experiments done on LeNet and ConvNets show an increase upto 6%\nof zeros and memory savings upto 82.4919% while keeping the accuracy near the\nstate of the art.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\u63a1\u7528\u5927\u91cf\u7684\u904b\u7b97\uff0c\u800c\u5927\u90e8\u5206\u7684\u904b\u7b97\u80fd\u91cf\u90fd\u88ab\u5377\u7a4d\u795e\u7d93\u7db2\u8def\u4e2d\u7684\u5377\u7a4d\u904b\u7b97\u6240\u5438\u6536\u3002\u6211\u5011\u63d0\u51fa\u7684\u5de5\u4f5c\u76ee\u6a19\u662f\u964d\u4f4e CNN \u7684\u80fd\u8017\u548c\u5927\u5c0f\uff0c\u4ee5\u4fbf\u5728\u666e\u9069\u904b\u7b97\u88dd\u7f6e\u4e0a\u7684\u908a\u7de3\u904b\u7b97\u4e2d\u4f7f\u7528\u6a5f\u5668\u5b78\u7fd2\u6280\u8853\u3002\u6211\u5011\u63d0\u51fa\u7cfb\u7d71\u5316\u54c1\u8cea\u53ef\u64f4\u5145\u8a2d\u8a08\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u542b\u8f03\u9ad8\u62bd\u8c61\u5c64\u7d1a\u7684\u54c1\u8cea\u53ef\u64f4\u5145\u91cf\u5316\u548c\u8f03\u4f4e\u62bd\u8c61\u5c64\u7d1a\u7684\u54c1\u8cea\u53ef\u64f4\u5145\u4e58\u6cd5\u5668\u3002\u7b2c\u4e00\u500b\u7d44\u4ef6\u5305\u542b\u53c3\u6578\u58d3\u7e2e\uff0c\u5176\u4e2d\u6211\u5011\u900f\u904e 3 \u4f4d\u5143\u7de8\u78bc\u4f86\u8fd1\u4f3c\u8868\u793a\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u4e2d\u6ffe\u6ce2\u5668\u7684\u503c\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u4f4d\u79fb\u548c\u7e2e\u653e\u7684\u6676\u7247\u89e3\u78bc\u786c\u9ad4\uff0c\u5b83\u53ef\u4ee5\u89e3\u78bc\u9019\u4e9b 3 \u4f4d\u5143\u8868\u793a\u4ee5\u9084\u539f\u8fd1\u4f3c\u7684\u6ffe\u6ce2\u5668\u503c\u3002DNN \u6a21\u578b\u7684\u5927\u5c0f\u6703\u4ee5\u9019\u7a2e\u65b9\u5f0f\u7e2e\u5c0f\uff0c\u4e26\u4e14\u53ef\u4ee5\u900f\u904e\u901a\u8a0a\u7ba1\u9053\u50b3\u9001\uff0c\u4ee5\u4fbf\u5728\u908a\u7de3\u904b\u7b97\u88dd\u7f6e\u4e0a\u89e3\u78bc\u3002\u9019\u7a2e\u65b9\u5f0f\u53ef\u900f\u904e\u8fd1\u4f3c\u4f86\u9650\u5236\u8cc7\u6599\u4f4d\u5143\uff0c\u9032\u800c\u964d\u4f4e\u529f\u8017\u3002\u5728\u7b2c\u4e8c\u500b\u7d44\u4ef6\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u54c1\u8cea\u53ef\u64f4\u5145\u4e58\u6cd5\u5668\uff0c\u5b83\u900f\u904e\u5c07\u6578\u5b57\u8f49\u63db\u70ba\u6b63\u898f\u7b26\u865f\u4f4d\u5143\u8868\u793a\uff0c\u4e26\u9032\u4e00\u6b65\u900f\u904e\u6e1b\u5c11\u6700\u4f4e\u6709\u6548\u4f4d\u5143\u4f86\u8fd1\u4f3c\u6578\u5b57\uff0c\u9032\u800c\u6e1b\u5c11\u90e8\u5206\u4e58\u7a4d\u7684\u6578\u91cf\u3002\u9019\u4e9b\u91cf\u5316\u7684 CNN \u63d0\u4f9b\u5e7e\u4e4e\u8207\u539f\u59cb\u6b0a\u91cd\u7684\u7db2\u8def\u76f8\u540c\u7684\u6e96\u78ba\u5ea6\uff0c\u5e7e\u4e4e\u4e0d\u9700\u8981\u5fae\u8abf\u3002\u81ea\u9069\u61c9\u4e58\u6cd5\u5668\u7684\u786c\u9ad4\u5229\u7528\u9598\u6975\u6642\u8108\u4f86\u964d\u4f4e\u4e58\u6cd5\u904b\u7b97\u4e2d\u7684\u80fd\u8017\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u4e86 DNN \u6a21\u578b\u7684\u8a18\u61b6\u9ad4\u548c\u529f\u8017\u9700\u6c42\uff0c\u4f7f\u5176\u6210\u70ba\u5728\u908a\u7de3\u904b\u7b97\u4e2d\u90e8\u7f72\u6df1\u5ea6\u5b78\u7fd2\u7684\u53ef\u884c\u65b9\u6cd5\u3002\u5728 LeNet \u548c ConvNets \u4e0a\u9032\u884c\u7684\u5be6\u9a57\u986f\u793a\uff0c\u96f6\u7684\u589e\u52a0\u5e45\u5ea6\u9ad8\u9054 6%\uff0c\u8a18\u61b6\u9ad4\u7bc0\u7701\u5e45\u5ea6\u9ad8\u9054 82.4919%\uff0c\u540c\u6642\u5c07\u6e96\u78ba\u5ea6\u7dad\u6301\u5728\u63a5\u8fd1\u6700\u5148\u9032\u7684\u6c34\u5e73\u3002", "author": "Salman Abdul Khaliq et.al.", "authors": "Salman Abdul Khaliq, Rehan Hafiz", "id": "2407.11260v1", "paper_url": "http://arxiv.org/abs/2407.11260v1", "repo": "null"}}