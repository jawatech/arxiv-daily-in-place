{"2410.16251": {"publish_time": "2024-10-21", "title": "Can Knowledge Editing Really Correct Hallucinations?", "paper_summary": "Large Language Models (LLMs) suffer from hallucinations, referring to the\nnon-factual information in generated content, despite their superior capacities\nacross tasks. Meanwhile, knowledge editing has been developed as a new popular\nparadigm to correct the erroneous factual knowledge encoded in LLMs with the\nadvantage of avoiding retraining from scratch. However, one common issue of\nexisting evaluation datasets for knowledge editing is that they do not ensure\nLLMs actually generate hallucinated answers to the evaluation questions before\nediting. When LLMs are evaluated on such datasets after being edited by\ndifferent techniques, it is hard to directly adopt the performance to assess\nthe effectiveness of different knowledge editing methods in correcting\nhallucinations. Thus, the fundamental question remains insufficiently\nvalidated: Can knowledge editing really correct hallucinations in LLMs? We\nproposed HalluEditBench to holistically benchmark knowledge editing methods in\ncorrecting real-world hallucinations. First, we rigorously construct a massive\nhallucination dataset with 9 domains, 26 topics and more than 6,000\nhallucinations. Then, we assess the performance of knowledge editing methods in\na holistic way on five dimensions including Efficacy, Generalization,\nPortability, Locality, and Robustness. Through HalluEditBench, we have provided\nnew insights into the potentials and limitations of different knowledge editing\nmethods in correcting hallucinations, which could inspire future improvements\nand facilitate the progress in the field of knowledge editing.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5118\u7ba1\u5728\u5404\u9805\u4efb\u52d9\u4e2d\u8868\u73fe\u512a\u7570\uff0c\u4f46\u4ecd\u5b58\u5728\u7522\u751f\u7684\u5167\u5bb9\u4e2d\u51fa\u73fe\u975e\u4e8b\u5be6\u8cc7\u8a0a\u7684\u5e7b\u89ba\u554f\u984c\u3002\u8207\u6b64\u540c\u6642\uff0c\u77e5\u8b58\u7de8\u8f2f\u5df2\u88ab\u958b\u767c\u70ba\u4e00\u7a2e\u65b0\u7684\u6d41\u884c\u7bc4\u4f8b\uff0c\u7528\u65bc\u4fee\u6b63 LLM \u4e2d\u7de8\u78bc\u7684\u932f\u8aa4\u4e8b\u5be6\u77e5\u8b58\uff0c\u4e26\u5177\u6709\u907f\u514d\u5f9e\u982d\u958b\u59cb\u91cd\u65b0\u8a13\u7df4\u7684\u512a\u9ede\u3002\u7136\u800c\uff0c\u73fe\u6709\u77e5\u8b58\u7de8\u8f2f\u8a55\u4f30\u8cc7\u6599\u96c6\u7684\u4e00\u500b\u5e38\u898b\u554f\u984c\u662f\uff0c\u5b83\u5011\u4e26\u672a\u78ba\u4fdd LLM \u5728\u7de8\u8f2f\u524d\u5be6\u969b\u5c0d\u8a55\u4f30\u554f\u984c\u7522\u751f\u5e7b\u89ba\u7b54\u6848\u3002\u7576 LLM \u5728\u7d93\u904e\u4e0d\u540c\u6280\u8853\u7de8\u8f2f\u5f8c\u5728\u9019\u4e9b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u8a55\u4f30\u6642\uff0c\u5f88\u96e3\u76f4\u63a5\u63a1\u7528\u6548\u80fd\u4f86\u8a55\u4f30\u4e0d\u540c\u77e5\u8b58\u7de8\u8f2f\u65b9\u6cd5\u5728\u4fee\u6b63\u5e7b\u89ba\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u56e0\u6b64\uff0c\u4e00\u500b\u57fa\u672c\u554f\u984c\u4ecd\u7136\u9a57\u8b49\u4e0d\u8db3\uff1a\u77e5\u8b58\u7de8\u8f2f\u662f\u5426\u771f\u7684\u53ef\u4ee5\u4fee\u6b63 LLM \u4e2d\u7684\u5e7b\u89ba\uff1f\u6211\u5011\u63d0\u51fa\u4e86 HalluEditBench\uff0c\u4ee5\u5168\u9762\u8a55\u91cf\u77e5\u8b58\u7de8\u8f2f\u65b9\u6cd5\u5728\u4fee\u6b63\u771f\u5be6\u4e16\u754c\u5e7b\u89ba\u65b9\u9762\u7684\u8868\u73fe\u3002\u9996\u5148\uff0c\u6211\u5011\u56b4\u8b39\u5730\u5efa\u69cb\u4e86\u4e00\u500b\u5305\u542b 9 \u500b\u9818\u57df\u300126 \u500b\u4e3b\u984c\u548c\u8d85\u904e 6,000 \u500b\u5e7b\u89ba\u7684\u9f90\u5927\u5e7b\u89ba\u8cc7\u6599\u96c6\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5728\u5305\u62ec\u6548\u80fd\u3001\u6982\u5316\u3001\u53ef\u651c\u6027\u3001\u5c40\u90e8\u6027\u548c\u5065\u5168\u6027\u7b49\u4e94\u500b\u9762\u5411\u5168\u9762\u8a55\u4f30\u77e5\u8b58\u7de8\u8f2f\u65b9\u6cd5\u7684\u8868\u73fe\u3002\u900f\u904e HalluEditBench\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u5c0d\u4e0d\u540c\u77e5\u8b58\u7de8\u8f2f\u65b9\u6cd5\u5728\u4fee\u6b63\u5e7b\u89ba\u65b9\u9762\u7684\u6f5b\u529b\u548c\u9650\u5236\u7684\u65b0\u898b\u89e3\uff0c\u9019\u53ef\u4ee5\u6fc0\u52f5\u672a\u4f86\u7684\u6539\u9032\uff0c\u4e26\u4fc3\u9032\u77e5\u8b58\u7de8\u8f2f\u9818\u57df\u7684\u9032\u5c55\u3002", "author": "Baixiang Huang et.al.", "authors": "Baixiang Huang, Canyu Chen, Xiongxiao Xu, Ali Payani, Kai Shu", "id": "2410.16251v1", "paper_url": "http://arxiv.org/abs/2410.16251v1", "repo": "https://github.com/llm-editing/HalluEditBench"}}